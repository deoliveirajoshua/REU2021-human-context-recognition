{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 tBodyAcc-mean()-X</th>\n",
       "      <th>2 tBodyAcc-mean()-Y</th>\n",
       "      <th>3 tBodyAcc-mean()-Z</th>\n",
       "      <th>4 tBodyAcc-std()-X</th>\n",
       "      <th>5 tBodyAcc-std()-Y</th>\n",
       "      <th>6 tBodyAcc-std()-Z</th>\n",
       "      <th>7 tBodyAcc-mad()-X</th>\n",
       "      <th>8 tBodyAcc-mad()-Y</th>\n",
       "      <th>9 tBodyAcc-mad()-Z</th>\n",
       "      <th>10 tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>112 tBodyAccJerk-arCoeff()-Y,3</th>\n",
       "      <th>113 tBodyAccJerk-arCoeff()-Y,4</th>\n",
       "      <th>114 tBodyAccJerk-arCoeff()-Z,1</th>\n",
       "      <th>115 tBodyAccJerk-arCoeff()-Z,2</th>\n",
       "      <th>116 tBodyAccJerk-arCoeff()-Z,3</th>\n",
       "      <th>117 tBodyAccJerk-arCoeff()-Z,4</th>\n",
       "      <th>118 tBodyAccJerk-correlation()-X,Y</th>\n",
       "      <th>119 tBodyAccJerk-correlation()-X,Z</th>\n",
       "      <th>120 tBodyAccJerk-correlation()-Y,Z</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264177</td>\n",
       "      <td>0.373439</td>\n",
       "      <td>0.341778</td>\n",
       "      <td>-0.569791</td>\n",
       "      <td>0.265399</td>\n",
       "      <td>-0.477875</td>\n",
       "      <td>-0.385300</td>\n",
       "      <td>0.033644</td>\n",
       "      <td>-0.126511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370493</td>\n",
       "      <td>0.413548</td>\n",
       "      <td>0.122216</td>\n",
       "      <td>0.180613</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>0.166573</td>\n",
       "      <td>-0.208772</td>\n",
       "      <td>0.084104</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>0.437623</td>\n",
       "      <td>0.257891</td>\n",
       "      <td>0.070030</td>\n",
       "      <td>0.186973</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>-0.120105</td>\n",
       "      <td>-0.110026</td>\n",
       "      <td>-0.039953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.484244</td>\n",
       "      <td>0.357657</td>\n",
       "      <td>-0.187032</td>\n",
       "      <td>0.298069</td>\n",
       "      <td>0.451870</td>\n",
       "      <td>-0.127495</td>\n",
       "      <td>-0.083278</td>\n",
       "      <td>0.457060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477454</td>\n",
       "      <td>0.417966</td>\n",
       "      <td>0.389537</td>\n",
       "      <td>-0.030309</td>\n",
       "      <td>0.163261</td>\n",
       "      <td>0.180189</td>\n",
       "      <td>-0.272884</td>\n",
       "      <td>0.103065</td>\n",
       "      <td>0.064729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>0.299665</td>\n",
       "      <td>-0.057193</td>\n",
       "      <td>-0.181233</td>\n",
       "      <td>-0.195387</td>\n",
       "      <td>0.039905</td>\n",
       "      <td>0.077078</td>\n",
       "      <td>-0.282301</td>\n",
       "      <td>0.043616</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>0.210795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080322</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>-0.448491</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>-0.349855</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>-0.523499</td>\n",
       "      <td>-0.263124</td>\n",
       "      <td>0.333620</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>0.273853</td>\n",
       "      <td>-0.007749</td>\n",
       "      <td>-0.147468</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-0.322552</td>\n",
       "      <td>-0.029456</td>\n",
       "      <td>0.080585</td>\n",
       "      <td>0.117440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020136</td>\n",
       "      <td>0.218178</td>\n",
       "      <td>-0.327139</td>\n",
       "      <td>-0.108303</td>\n",
       "      <td>-0.065145</td>\n",
       "      <td>0.042680</td>\n",
       "      <td>-0.460900</td>\n",
       "      <td>-0.178567</td>\n",
       "      <td>0.355012</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>0.273387</td>\n",
       "      <td>-0.017011</td>\n",
       "      <td>-0.045022</td>\n",
       "      <td>-0.218218</td>\n",
       "      <td>-0.103822</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>-0.304515</td>\n",
       "      <td>-0.098913</td>\n",
       "      <td>0.332584</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102722</td>\n",
       "      <td>0.236469</td>\n",
       "      <td>-0.393169</td>\n",
       "      <td>-0.041687</td>\n",
       "      <td>-0.214678</td>\n",
       "      <td>-0.005115</td>\n",
       "      <td>-0.534302</td>\n",
       "      <td>-0.102262</td>\n",
       "      <td>0.387323</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>0.289654</td>\n",
       "      <td>-0.018843</td>\n",
       "      <td>-0.158281</td>\n",
       "      <td>-0.219139</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>0.268893</td>\n",
       "      <td>-0.310487</td>\n",
       "      <td>-0.068200</td>\n",
       "      <td>0.319473</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180158</td>\n",
       "      <td>0.175288</td>\n",
       "      <td>-0.439943</td>\n",
       "      <td>0.024245</td>\n",
       "      <td>-0.332076</td>\n",
       "      <td>-0.117280</td>\n",
       "      <td>-0.551732</td>\n",
       "      <td>-0.020034</td>\n",
       "      <td>0.263609</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>0.351503</td>\n",
       "      <td>-0.012423</td>\n",
       "      <td>-0.203867</td>\n",
       "      <td>-0.269270</td>\n",
       "      <td>-0.087212</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>-0.377404</td>\n",
       "      <td>-0.038678</td>\n",
       "      <td>0.229430</td>\n",
       "      <td>0.269013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077490</td>\n",
       "      <td>0.156481</td>\n",
       "      <td>-0.342625</td>\n",
       "      <td>-0.112329</td>\n",
       "      <td>-0.050668</td>\n",
       "      <td>-0.348724</td>\n",
       "      <td>-0.420532</td>\n",
       "      <td>-0.166305</td>\n",
       "      <td>0.166394</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1 tBodyAcc-mean()-X  2 tBodyAcc-mean()-Y  3 tBodyAcc-mean()-Z  \\\n",
       "0                0.288585            -0.020294            -0.132905   \n",
       "1                0.278419            -0.016411            -0.123520   \n",
       "2                0.279653            -0.019467            -0.113462   \n",
       "3                0.279174            -0.026201            -0.123283   \n",
       "4                0.276629            -0.016570            -0.115362   \n",
       "...                   ...                  ...                  ...   \n",
       "7347             0.299665            -0.057193            -0.181233   \n",
       "7348             0.273853            -0.007749            -0.147468   \n",
       "7349             0.273387            -0.017011            -0.045022   \n",
       "7350             0.289654            -0.018843            -0.158281   \n",
       "7351             0.351503            -0.012423            -0.203867   \n",
       "\n",
       "      4 tBodyAcc-std()-X  5 tBodyAcc-std()-Y  6 tBodyAcc-std()-Z  \\\n",
       "0              -0.995279           -0.983111           -0.913526   \n",
       "1              -0.998245           -0.975300           -0.960322   \n",
       "2              -0.995380           -0.967187           -0.978944   \n",
       "3              -0.996091           -0.983403           -0.990675   \n",
       "4              -0.998139           -0.980817           -0.990482   \n",
       "...                  ...                 ...                 ...   \n",
       "7347           -0.195387            0.039905            0.077078   \n",
       "7348           -0.235309            0.004816            0.059280   \n",
       "7349           -0.218218           -0.103822            0.274533   \n",
       "7350           -0.219139           -0.111412            0.268893   \n",
       "7351           -0.269270           -0.087212            0.177404   \n",
       "\n",
       "      7 tBodyAcc-mad()-X  8 tBodyAcc-mad()-Y  9 tBodyAcc-mad()-Z  \\\n",
       "0              -0.995112           -0.983185           -0.923527   \n",
       "1              -0.998807           -0.974914           -0.957686   \n",
       "2              -0.996520           -0.963668           -0.977469   \n",
       "3              -0.997099           -0.982750           -0.989302   \n",
       "4              -0.998321           -0.979672           -0.990441   \n",
       "...                  ...                 ...                 ...   \n",
       "7347           -0.282301            0.043616            0.060410   \n",
       "7348           -0.322552           -0.029456            0.080585   \n",
       "7349           -0.304515           -0.098913            0.332584   \n",
       "7350           -0.310487           -0.068200            0.319473   \n",
       "7351           -0.377404           -0.038678            0.229430   \n",
       "\n",
       "      10 tBodyAcc-max()-X  ...  112 tBodyAccJerk-arCoeff()-Y,3  \\\n",
       "0               -0.934724  ...                        0.264177   \n",
       "1               -0.943068  ...                        0.370493   \n",
       "2               -0.938692  ...                        0.327470   \n",
       "3               -0.938692  ...                        0.194679   \n",
       "4               -0.942469  ...                        0.477454   \n",
       "...                   ...  ...                             ...   \n",
       "7347             0.210795  ...                       -0.080322   \n",
       "7348             0.117440  ...                       -0.020136   \n",
       "7349             0.043999  ...                        0.102722   \n",
       "7350             0.101702  ...                        0.180158   \n",
       "7351             0.269013  ...                       -0.077490   \n",
       "\n",
       "      113 tBodyAccJerk-arCoeff()-Y,4  114 tBodyAccJerk-arCoeff()-Z,1  \\\n",
       "0                           0.373439                        0.341778   \n",
       "1                           0.413548                        0.122216   \n",
       "2                           0.437623                        0.257891   \n",
       "3                           0.484244                        0.357657   \n",
       "4                           0.417966                        0.389537   \n",
       "...                              ...                             ...   \n",
       "7347                        0.126940                       -0.448491   \n",
       "7348                        0.218178                       -0.327139   \n",
       "7349                        0.236469                       -0.393169   \n",
       "7350                        0.175288                       -0.439943   \n",
       "7351                        0.156481                       -0.342625   \n",
       "\n",
       "      115 tBodyAccJerk-arCoeff()-Z,2  116 tBodyAccJerk-arCoeff()-Z,3  \\\n",
       "0                          -0.569791                        0.265399   \n",
       "1                           0.180613                        0.047424   \n",
       "2                           0.070030                        0.186973   \n",
       "3                          -0.187032                        0.298069   \n",
       "4                          -0.030309                        0.163261   \n",
       "...                              ...                             ...   \n",
       "7347                        0.100100                       -0.349855   \n",
       "7348                       -0.108303                       -0.065145   \n",
       "7349                       -0.041687                       -0.214678   \n",
       "7350                        0.024245                       -0.332076   \n",
       "7351                       -0.112329                       -0.050668   \n",
       "\n",
       "      117 tBodyAccJerk-arCoeff()-Z,4  118 tBodyAccJerk-correlation()-X,Y  \\\n",
       "0                          -0.477875                           -0.385300   \n",
       "1                           0.166573                           -0.208772   \n",
       "2                           0.246800                           -0.120105   \n",
       "3                           0.451870                           -0.127495   \n",
       "4                           0.180189                           -0.272884   \n",
       "...                              ...                                 ...   \n",
       "7347                        0.003027                           -0.523499   \n",
       "7348                        0.042680                           -0.460900   \n",
       "7349                       -0.005115                           -0.534302   \n",
       "7350                       -0.117280                           -0.551732   \n",
       "7351                       -0.348724                           -0.420532   \n",
       "\n",
       "      119 tBodyAccJerk-correlation()-X,Z  120 tBodyAccJerk-correlation()-Y,Z  \\\n",
       "0                               0.033644                           -0.126511   \n",
       "1                               0.084104                           -0.268554   \n",
       "2                              -0.110026                           -0.039953   \n",
       "3                              -0.083278                            0.457060   \n",
       "4                               0.103065                            0.064729   \n",
       "...                                  ...                                 ...   \n",
       "7347                           -0.263124                            0.333620   \n",
       "7348                           -0.178567                            0.355012   \n",
       "7349                           -0.102262                            0.387323   \n",
       "7350                           -0.020034                            0.263609   \n",
       "7351                           -0.166305                            0.166394   \n",
       "\n",
       "      Subject  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "7347       30  \n",
       "7348       30  \n",
       "7349       30  \n",
       "7350       30  \n",
       "7351       30  \n",
       "\n",
       "[7352 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "\n",
    "y_train = pd.read_csv('../data/subject_train.txt', header = None)\n",
    "y_train.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data.loc[:,'1 tBodyAcc-mean()-X':'40 tBodyAcc-correlation()-Y,Z']\n",
    "X_train_2 = train_data.loc[:,'81 tBodyAccJerk-mean()-X':'120 tBodyAccJerk-correlation()-Y,Z']\n",
    "X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train = pd.concat([X_train, y_train], axis = 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[(X_train['Subject'] == 1) | (X_train['Subject'] == 3) | (X_train['Subject'] == 5)]\n",
    "X_train = X_train.iloc[:,:-1].values\n",
    "\n",
    "y_train = y_train[(y_train['Subject'] == 1) | (y_train['Subject'] == 3) | (y_train['Subject'] == 5)]\n",
    "y_train = y_train.values\n",
    "y_train = y_train.flatten()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = 80):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 60),\n",
    "            classifier_block(60, 40),\n",
    "            classifier_block(40, 20),\n",
    "            classifier_block(20, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 8000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.429519534111023, Final Batch Loss: 1.1081305742263794\n",
      "Epoch 2, Loss: 4.418404459953308, Final Batch Loss: 1.1000921726226807\n",
      "Epoch 3, Loss: 4.410670280456543, Final Batch Loss: 1.104386329650879\n",
      "Epoch 4, Loss: 4.40073561668396, Final Batch Loss: 1.098145842552185\n",
      "Epoch 5, Loss: 4.397031545639038, Final Batch Loss: 1.0981534719467163\n",
      "Epoch 6, Loss: 4.390538215637207, Final Batch Loss: 1.096826434135437\n",
      "Epoch 7, Loss: 4.383747220039368, Final Batch Loss: 1.0934010744094849\n",
      "Epoch 8, Loss: 4.372615337371826, Final Batch Loss: 1.0884158611297607\n",
      "Epoch 9, Loss: 4.3619548082351685, Final Batch Loss: 1.090421199798584\n",
      "Epoch 10, Loss: 4.338091015815735, Final Batch Loss: 1.078393578529358\n",
      "Epoch 11, Loss: 4.314881682395935, Final Batch Loss: 1.0830198526382446\n",
      "Epoch 12, Loss: 4.287543535232544, Final Batch Loss: 1.0730994939804077\n",
      "Epoch 13, Loss: 4.21557343006134, Final Batch Loss: 1.0368967056274414\n",
      "Epoch 14, Loss: 4.150383234024048, Final Batch Loss: 1.0215120315551758\n",
      "Epoch 15, Loss: 4.099750638008118, Final Batch Loss: 1.0217236280441284\n",
      "Epoch 16, Loss: 3.9893398880958557, Final Batch Loss: 0.982749879360199\n",
      "Epoch 17, Loss: 3.8867642283439636, Final Batch Loss: 0.9733539819717407\n",
      "Epoch 18, Loss: 3.745570659637451, Final Batch Loss: 0.9181079864501953\n",
      "Epoch 19, Loss: 3.6550923585891724, Final Batch Loss: 0.9384828209877014\n",
      "Epoch 20, Loss: 3.5186855792999268, Final Batch Loss: 0.8793107867240906\n",
      "Epoch 21, Loss: 3.3589794039726257, Final Batch Loss: 0.8094453811645508\n",
      "Epoch 22, Loss: 3.2352861166000366, Final Batch Loss: 0.7581541538238525\n",
      "Epoch 23, Loss: 3.170358180999756, Final Batch Loss: 0.7391767501831055\n",
      "Epoch 24, Loss: 3.1955917477607727, Final Batch Loss: 0.85597163438797\n",
      "Epoch 25, Loss: 3.042669355869293, Final Batch Loss: 0.7352312803268433\n",
      "Epoch 26, Loss: 2.962764859199524, Final Batch Loss: 0.7283597588539124\n",
      "Epoch 27, Loss: 2.948967456817627, Final Batch Loss: 0.769244372844696\n",
      "Epoch 28, Loss: 2.885334312915802, Final Batch Loss: 0.8082839846611023\n",
      "Epoch 29, Loss: 2.8162408471107483, Final Batch Loss: 0.681876003742218\n",
      "Epoch 30, Loss: 2.7440483570098877, Final Batch Loss: 0.6676303744316101\n",
      "Epoch 31, Loss: 2.671086370944977, Final Batch Loss: 0.6099690198898315\n",
      "Epoch 32, Loss: 2.6305320858955383, Final Batch Loss: 0.6639513373374939\n",
      "Epoch 33, Loss: 2.59268981218338, Final Batch Loss: 0.6762091517448425\n",
      "Epoch 34, Loss: 2.503113031387329, Final Batch Loss: 0.6198216676712036\n",
      "Epoch 35, Loss: 2.4931520819664, Final Batch Loss: 0.5931305885314941\n",
      "Epoch 36, Loss: 2.4042015075683594, Final Batch Loss: 0.6193082332611084\n",
      "Epoch 37, Loss: 2.376241683959961, Final Batch Loss: 0.6210548877716064\n",
      "Epoch 38, Loss: 2.409590184688568, Final Batch Loss: 0.6796109676361084\n",
      "Epoch 39, Loss: 2.2258500456809998, Final Batch Loss: 0.4757564663887024\n",
      "Epoch 40, Loss: 2.202159345149994, Final Batch Loss: 0.5397076606750488\n",
      "Epoch 41, Loss: 2.2402538061141968, Final Batch Loss: 0.6294914484024048\n",
      "Epoch 42, Loss: 2.248108208179474, Final Batch Loss: 0.5993183851242065\n",
      "Epoch 43, Loss: 2.1236088573932648, Final Batch Loss: 0.480353981256485\n",
      "Epoch 44, Loss: 2.170131742954254, Final Batch Loss: 0.5778524279594421\n",
      "Epoch 45, Loss: 2.04014128446579, Final Batch Loss: 0.48758307099342346\n",
      "Epoch 46, Loss: 2.0820699334144592, Final Batch Loss: 0.5343892574310303\n",
      "Epoch 47, Loss: 2.0544034838676453, Final Batch Loss: 0.528363823890686\n",
      "Epoch 48, Loss: 2.045772820711136, Final Batch Loss: 0.4989202320575714\n",
      "Epoch 49, Loss: 1.9067622423171997, Final Batch Loss: 0.43479257822036743\n",
      "Epoch 50, Loss: 1.9932181537151337, Final Batch Loss: 0.518454372882843\n",
      "Epoch 51, Loss: 1.8690136969089508, Final Batch Loss: 0.4690888822078705\n",
      "Epoch 52, Loss: 1.8803397417068481, Final Batch Loss: 0.4983748495578766\n",
      "Epoch 53, Loss: 1.8456979095935822, Final Batch Loss: 0.4374926686286926\n",
      "Epoch 54, Loss: 1.915752500295639, Final Batch Loss: 0.5048902630805969\n",
      "Epoch 55, Loss: 1.7850771248340607, Final Batch Loss: 0.3971630036830902\n",
      "Epoch 56, Loss: 1.820742279291153, Final Batch Loss: 0.4073692858219147\n",
      "Epoch 57, Loss: 1.8220894038677216, Final Batch Loss: 0.5099518299102783\n",
      "Epoch 58, Loss: 1.7055686116218567, Final Batch Loss: 0.35318076610565186\n",
      "Epoch 59, Loss: 1.7562521696090698, Final Batch Loss: 0.4786718189716339\n",
      "Epoch 60, Loss: 1.718107134103775, Final Batch Loss: 0.5057397484779358\n",
      "Epoch 61, Loss: 1.722425490617752, Final Batch Loss: 0.43577805161476135\n",
      "Epoch 62, Loss: 1.6147371232509613, Final Batch Loss: 0.34291866421699524\n",
      "Epoch 63, Loss: 1.6162680983543396, Final Batch Loss: 0.38846755027770996\n",
      "Epoch 64, Loss: 1.7081659436225891, Final Batch Loss: 0.4231795370578766\n",
      "Epoch 65, Loss: 1.5968324840068817, Final Batch Loss: 0.3930014371871948\n",
      "Epoch 66, Loss: 1.5937738418579102, Final Batch Loss: 0.38525816798210144\n",
      "Epoch 67, Loss: 1.698332130908966, Final Batch Loss: 0.5619304180145264\n",
      "Epoch 68, Loss: 1.5614688098430634, Final Batch Loss: 0.3896341919898987\n",
      "Epoch 69, Loss: 1.5048986971378326, Final Batch Loss: 0.3452230989933014\n",
      "Epoch 70, Loss: 1.5676332414150238, Final Batch Loss: 0.43554532527923584\n",
      "Epoch 71, Loss: 1.4805337488651276, Final Batch Loss: 0.32858535647392273\n",
      "Epoch 72, Loss: 1.526537835597992, Final Batch Loss: 0.3841274678707123\n",
      "Epoch 73, Loss: 1.5236769318580627, Final Batch Loss: 0.40116244554519653\n",
      "Epoch 74, Loss: 1.463748037815094, Final Batch Loss: 0.3544829785823822\n",
      "Epoch 75, Loss: 1.436767429113388, Final Batch Loss: 0.3582496643066406\n",
      "Epoch 76, Loss: 1.5254850387573242, Final Batch Loss: 0.3712989389896393\n",
      "Epoch 77, Loss: 1.4264390766620636, Final Batch Loss: 0.3638353943824768\n",
      "Epoch 78, Loss: 1.495716780424118, Final Batch Loss: 0.4286537170410156\n",
      "Epoch 79, Loss: 1.4205612242221832, Final Batch Loss: 0.38383084535598755\n",
      "Epoch 80, Loss: 1.4151663184165955, Final Batch Loss: 0.35362106561660767\n",
      "Epoch 81, Loss: 1.43983593583107, Final Batch Loss: 0.3839327096939087\n",
      "Epoch 82, Loss: 1.3999262750148773, Final Batch Loss: 0.35988423228263855\n",
      "Epoch 83, Loss: 1.4142087996006012, Final Batch Loss: 0.24662724137306213\n",
      "Epoch 84, Loss: 1.357681155204773, Final Batch Loss: 0.31049227714538574\n",
      "Epoch 85, Loss: 1.2545162290334702, Final Batch Loss: 0.19614998996257782\n",
      "Epoch 86, Loss: 1.3867114782333374, Final Batch Loss: 0.40425634384155273\n",
      "Epoch 87, Loss: 1.3220860064029694, Final Batch Loss: 0.309355765581131\n",
      "Epoch 88, Loss: 1.3253661394119263, Final Batch Loss: 0.28158771991729736\n",
      "Epoch 89, Loss: 1.2345319539308548, Final Batch Loss: 0.23246832191944122\n",
      "Epoch 90, Loss: 1.3617677688598633, Final Batch Loss: 0.33255666494369507\n",
      "Epoch 91, Loss: 1.251908004283905, Final Batch Loss: 0.28385722637176514\n",
      "Epoch 92, Loss: 1.2598395943641663, Final Batch Loss: 0.22463345527648926\n",
      "Epoch 93, Loss: 1.2206672132015228, Final Batch Loss: 0.2714955806732178\n",
      "Epoch 94, Loss: 1.340894877910614, Final Batch Loss: 0.37620070576667786\n",
      "Epoch 95, Loss: 1.268897533416748, Final Batch Loss: 0.27100756764411926\n",
      "Epoch 96, Loss: 1.3224656581878662, Final Batch Loss: 0.36129263043403625\n",
      "Epoch 97, Loss: 1.3393874168395996, Final Batch Loss: 0.44043266773223877\n",
      "Epoch 98, Loss: 1.2469232976436615, Final Batch Loss: 0.24352553486824036\n",
      "Epoch 99, Loss: 1.348201334476471, Final Batch Loss: 0.3652900159358978\n",
      "Epoch 100, Loss: 1.2364876866340637, Final Batch Loss: 0.319728821516037\n",
      "Epoch 101, Loss: 1.2056212723255157, Final Batch Loss: 0.28895366191864014\n",
      "Epoch 102, Loss: 1.2118849754333496, Final Batch Loss: 0.29979825019836426\n",
      "Epoch 103, Loss: 1.1468336880207062, Final Batch Loss: 0.2484026849269867\n",
      "Epoch 104, Loss: 1.3118863999843597, Final Batch Loss: 0.3301681578159332\n",
      "Epoch 105, Loss: 1.205121248960495, Final Batch Loss: 0.30833080410957336\n",
      "Epoch 106, Loss: 1.1789896190166473, Final Batch Loss: 0.28764745593070984\n",
      "Epoch 107, Loss: 1.1079181879758835, Final Batch Loss: 0.23478473722934723\n",
      "Epoch 108, Loss: 1.1277631223201752, Final Batch Loss: 0.28269723057746887\n",
      "Epoch 109, Loss: 1.282717078924179, Final Batch Loss: 0.4519871175289154\n",
      "Epoch 110, Loss: 1.189753234386444, Final Batch Loss: 0.3629838824272156\n",
      "Epoch 111, Loss: 1.1415508687496185, Final Batch Loss: 0.3009190261363983\n",
      "Epoch 112, Loss: 1.1767484992742538, Final Batch Loss: 0.3096861243247986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113, Loss: 1.1594400703907013, Final Batch Loss: 0.28685417771339417\n",
      "Epoch 114, Loss: 1.1523360908031464, Final Batch Loss: 0.29124101996421814\n",
      "Epoch 115, Loss: 1.198165476322174, Final Batch Loss: 0.3437636196613312\n",
      "Epoch 116, Loss: 1.192902222275734, Final Batch Loss: 0.34896156191825867\n",
      "Epoch 117, Loss: 1.126171886920929, Final Batch Loss: 0.3165285289287567\n",
      "Epoch 118, Loss: 1.0919226855039597, Final Batch Loss: 0.2557685673236847\n",
      "Epoch 119, Loss: 1.0369969606399536, Final Batch Loss: 0.22076952457427979\n",
      "Epoch 120, Loss: 1.0082968324422836, Final Batch Loss: 0.20901742577552795\n",
      "Epoch 121, Loss: 1.048444226384163, Final Batch Loss: 0.24983876943588257\n",
      "Epoch 122, Loss: 1.1761692017316818, Final Batch Loss: 0.4663386940956116\n",
      "Epoch 123, Loss: 1.0677658766508102, Final Batch Loss: 0.2747367024421692\n",
      "Epoch 124, Loss: 1.0679975748062134, Final Batch Loss: 0.2619493305683136\n",
      "Epoch 125, Loss: 0.9948744475841522, Final Batch Loss: 0.23203474283218384\n",
      "Epoch 126, Loss: 0.9913794547319412, Final Batch Loss: 0.23110535740852356\n",
      "Epoch 127, Loss: 1.016429677605629, Final Batch Loss: 0.3023871183395386\n",
      "Epoch 128, Loss: 1.0694254040718079, Final Batch Loss: 0.27957579493522644\n",
      "Epoch 129, Loss: 0.9995821267366409, Final Batch Loss: 0.20819510519504547\n",
      "Epoch 130, Loss: 0.9650126844644547, Final Batch Loss: 0.17282772064208984\n",
      "Epoch 131, Loss: 1.0689480751752853, Final Batch Loss: 0.23158244788646698\n",
      "Epoch 132, Loss: 1.1368977427482605, Final Batch Loss: 0.35381418466567993\n",
      "Epoch 133, Loss: 0.978025883436203, Final Batch Loss: 0.299560010433197\n",
      "Epoch 134, Loss: 0.947443887591362, Final Batch Loss: 0.21613739430904388\n",
      "Epoch 135, Loss: 0.9696235209703445, Final Batch Loss: 0.20968778431415558\n",
      "Epoch 136, Loss: 0.9069924354553223, Final Batch Loss: 0.17974145710468292\n",
      "Epoch 137, Loss: 0.9656204283237457, Final Batch Loss: 0.21104086935520172\n",
      "Epoch 138, Loss: 0.9223213791847229, Final Batch Loss: 0.231255441904068\n",
      "Epoch 139, Loss: 0.9795832335948944, Final Batch Loss: 0.29910808801651\n",
      "Epoch 140, Loss: 0.9070757329463959, Final Batch Loss: 0.19280937314033508\n",
      "Epoch 141, Loss: 1.029329389333725, Final Batch Loss: 0.3347289264202118\n",
      "Epoch 142, Loss: 0.8481728285551071, Final Batch Loss: 0.20382994413375854\n",
      "Epoch 143, Loss: 0.886819452047348, Final Batch Loss: 0.1690690666437149\n",
      "Epoch 144, Loss: 1.0263935029506683, Final Batch Loss: 0.2781604826450348\n",
      "Epoch 145, Loss: 0.9811755269765854, Final Batch Loss: 0.28752246499061584\n",
      "Epoch 146, Loss: 0.8775117546319962, Final Batch Loss: 0.19853025674819946\n",
      "Epoch 147, Loss: 0.9805452227592468, Final Batch Loss: 0.21590669453144073\n",
      "Epoch 148, Loss: 0.8643363565206528, Final Batch Loss: 0.18246665596961975\n",
      "Epoch 149, Loss: 0.8956619799137115, Final Batch Loss: 0.20149467885494232\n",
      "Epoch 150, Loss: 0.9169892519712448, Final Batch Loss: 0.23932543396949768\n",
      "Epoch 151, Loss: 0.9205436259508133, Final Batch Loss: 0.19410644471645355\n",
      "Epoch 152, Loss: 0.893349215388298, Final Batch Loss: 0.18337975442409515\n",
      "Epoch 153, Loss: 0.9159194529056549, Final Batch Loss: 0.2923101484775543\n",
      "Epoch 154, Loss: 0.9856505542993546, Final Batch Loss: 0.22128912806510925\n",
      "Epoch 155, Loss: 0.8994082361459732, Final Batch Loss: 0.30547022819519043\n",
      "Epoch 156, Loss: 0.8354205936193466, Final Batch Loss: 0.17347528040409088\n",
      "Epoch 157, Loss: 0.7733263820409775, Final Batch Loss: 0.13527198135852814\n",
      "Epoch 158, Loss: 0.8340408802032471, Final Batch Loss: 0.2020500749349594\n",
      "Epoch 159, Loss: 0.7265101820230484, Final Batch Loss: 0.14423273503780365\n",
      "Epoch 160, Loss: 0.7618052661418915, Final Batch Loss: 0.1990729123353958\n",
      "Epoch 161, Loss: 0.7383845746517181, Final Batch Loss: 0.15831997990608215\n",
      "Epoch 162, Loss: 0.7796486914157867, Final Batch Loss: 0.16182251274585724\n",
      "Epoch 163, Loss: 0.7816822975873947, Final Batch Loss: 0.15935561060905457\n",
      "Epoch 164, Loss: 0.7627408504486084, Final Batch Loss: 0.19010967016220093\n",
      "Epoch 165, Loss: 0.7873602360486984, Final Batch Loss: 0.199940487742424\n",
      "Epoch 166, Loss: 0.8135124295949936, Final Batch Loss: 0.20408840477466583\n",
      "Epoch 167, Loss: 0.843364417552948, Final Batch Loss: 0.21093297004699707\n",
      "Epoch 168, Loss: 0.7311568260192871, Final Batch Loss: 0.2113686501979828\n",
      "Epoch 169, Loss: 0.7921368032693863, Final Batch Loss: 0.19519414007663727\n",
      "Epoch 170, Loss: 0.7821142673492432, Final Batch Loss: 0.2340853065252304\n",
      "Epoch 171, Loss: 0.7273179888725281, Final Batch Loss: 0.13848504424095154\n",
      "Epoch 172, Loss: 0.7342735528945923, Final Batch Loss: 0.16575981676578522\n",
      "Epoch 173, Loss: 0.7494756877422333, Final Batch Loss: 0.21079930663108826\n",
      "Epoch 174, Loss: 0.7447243183851242, Final Batch Loss: 0.2089289426803589\n",
      "Epoch 175, Loss: 0.742859959602356, Final Batch Loss: 0.1695859730243683\n",
      "Epoch 176, Loss: 0.6953124701976776, Final Batch Loss: 0.186386376619339\n",
      "Epoch 177, Loss: 0.7046976834535599, Final Batch Loss: 0.2125176191329956\n",
      "Epoch 178, Loss: 0.7497584819793701, Final Batch Loss: 0.1706889122724533\n",
      "Epoch 179, Loss: 0.682073101401329, Final Batch Loss: 0.18360154330730438\n",
      "Epoch 180, Loss: 0.6919160783290863, Final Batch Loss: 0.19712761044502258\n",
      "Epoch 181, Loss: 0.6313934326171875, Final Batch Loss: 0.12644162774085999\n",
      "Epoch 182, Loss: 0.720223642885685, Final Batch Loss: 0.16799801588058472\n",
      "Epoch 183, Loss: 0.8423575758934021, Final Batch Loss: 0.2422141581773758\n",
      "Epoch 184, Loss: 0.881821483373642, Final Batch Loss: 0.1874183565378189\n",
      "Epoch 185, Loss: 0.6793964803218842, Final Batch Loss: 0.13500447571277618\n",
      "Epoch 186, Loss: 0.706193134188652, Final Batch Loss: 0.12144027650356293\n",
      "Epoch 187, Loss: 0.7574996203184128, Final Batch Loss: 0.16269391775131226\n",
      "Epoch 188, Loss: 0.7941111028194427, Final Batch Loss: 0.2531629204750061\n",
      "Epoch 189, Loss: 0.7349085658788681, Final Batch Loss: 0.13814295828342438\n",
      "Epoch 190, Loss: 0.7482221275568008, Final Batch Loss: 0.22519457340240479\n",
      "Epoch 191, Loss: 0.6516687497496605, Final Batch Loss: 0.11668672412633896\n",
      "Epoch 192, Loss: 0.6028527021408081, Final Batch Loss: 0.0935540497303009\n",
      "Epoch 193, Loss: 0.6067610830068588, Final Batch Loss: 0.1329738050699234\n",
      "Epoch 194, Loss: 0.7479802817106247, Final Batch Loss: 0.22272536158561707\n",
      "Epoch 195, Loss: 0.7059600651264191, Final Batch Loss: 0.16102401912212372\n",
      "Epoch 196, Loss: 0.6857162192463875, Final Batch Loss: 0.1135428324341774\n",
      "Epoch 197, Loss: 0.6359947770833969, Final Batch Loss: 0.16626128554344177\n",
      "Epoch 198, Loss: 0.6997507959604263, Final Batch Loss: 0.15953384339809418\n",
      "Epoch 199, Loss: 0.6596401929855347, Final Batch Loss: 0.1502000093460083\n",
      "Epoch 200, Loss: 0.6227601021528244, Final Batch Loss: 0.14380666613578796\n",
      "Epoch 201, Loss: 0.566571056842804, Final Batch Loss: 0.1403999924659729\n",
      "Epoch 202, Loss: 0.5295163094997406, Final Batch Loss: 0.07062947750091553\n",
      "Epoch 203, Loss: 0.5255305245518684, Final Batch Loss: 0.12602177262306213\n",
      "Epoch 204, Loss: 0.6212643384933472, Final Batch Loss: 0.14774470031261444\n",
      "Epoch 205, Loss: 0.6238978505134583, Final Batch Loss: 0.18807056546211243\n",
      "Epoch 206, Loss: 0.5889083296060562, Final Batch Loss: 0.15578795969486237\n",
      "Epoch 207, Loss: 0.5948726683855057, Final Batch Loss: 0.14700248837471008\n",
      "Epoch 208, Loss: 0.6808033734560013, Final Batch Loss: 0.15433457493782043\n",
      "Epoch 209, Loss: 0.6441100984811783, Final Batch Loss: 0.16739968955516815\n",
      "Epoch 210, Loss: 0.5896335765719414, Final Batch Loss: 0.11416182667016983\n",
      "Epoch 211, Loss: 0.5522758811712265, Final Batch Loss: 0.11187669634819031\n",
      "Epoch 212, Loss: 0.5909795463085175, Final Batch Loss: 0.16052713990211487\n",
      "Epoch 213, Loss: 0.5672017484903336, Final Batch Loss: 0.09260419756174088\n",
      "Epoch 214, Loss: 0.6429188996553421, Final Batch Loss: 0.1575057953596115\n",
      "Epoch 215, Loss: 0.5585142597556114, Final Batch Loss: 0.09755926579236984\n",
      "Epoch 216, Loss: 0.6243341490626335, Final Batch Loss: 0.19349314272403717\n",
      "Epoch 217, Loss: 0.5713107287883759, Final Batch Loss: 0.1372150480747223\n",
      "Epoch 218, Loss: 0.59618279337883, Final Batch Loss: 0.11270837485790253\n",
      "Epoch 219, Loss: 0.5507547780871391, Final Batch Loss: 0.1045989915728569\n",
      "Epoch 220, Loss: 0.5922633334994316, Final Batch Loss: 0.11600824445486069\n",
      "Epoch 221, Loss: 0.5368081405758858, Final Batch Loss: 0.07654417306184769\n",
      "Epoch 222, Loss: 0.5806017741560936, Final Batch Loss: 0.12880094349384308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223, Loss: 0.5580393075942993, Final Batch Loss: 0.16977985203266144\n",
      "Epoch 224, Loss: 0.5685061141848564, Final Batch Loss: 0.11000904440879822\n",
      "Epoch 225, Loss: 0.603473111987114, Final Batch Loss: 0.14562997221946716\n",
      "Epoch 226, Loss: 0.49700891971588135, Final Batch Loss: 0.12543950974941254\n",
      "Epoch 227, Loss: 0.49424413591623306, Final Batch Loss: 0.15556110441684723\n",
      "Epoch 228, Loss: 0.4767419919371605, Final Batch Loss: 0.11266468465328217\n",
      "Epoch 229, Loss: 0.5247196182608604, Final Batch Loss: 0.1421515792608261\n",
      "Epoch 230, Loss: 0.4996417164802551, Final Batch Loss: 0.14761503040790558\n",
      "Epoch 231, Loss: 0.5837041139602661, Final Batch Loss: 0.1328551322221756\n",
      "Epoch 232, Loss: 0.5275368168950081, Final Batch Loss: 0.1394357830286026\n",
      "Epoch 233, Loss: 0.5321181938052177, Final Batch Loss: 0.10655701905488968\n",
      "Epoch 234, Loss: 0.530876025557518, Final Batch Loss: 0.15651164948940277\n",
      "Epoch 235, Loss: 0.5408825278282166, Final Batch Loss: 0.2160322517156601\n",
      "Epoch 236, Loss: 0.44617797434329987, Final Batch Loss: 0.09911885857582092\n",
      "Epoch 237, Loss: 0.4925764128565788, Final Batch Loss: 0.10425485670566559\n",
      "Epoch 238, Loss: 0.516173243522644, Final Batch Loss: 0.1390407383441925\n",
      "Epoch 239, Loss: 0.47583911567926407, Final Batch Loss: 0.15028277039527893\n",
      "Epoch 240, Loss: 0.5605636835098267, Final Batch Loss: 0.19103515148162842\n",
      "Epoch 241, Loss: 0.47791242599487305, Final Batch Loss: 0.11218295991420746\n",
      "Epoch 242, Loss: 0.39611563086509705, Final Batch Loss: 0.09121044725179672\n",
      "Epoch 243, Loss: 0.4330170080065727, Final Batch Loss: 0.09788580238819122\n",
      "Epoch 244, Loss: 0.5164509862661362, Final Batch Loss: 0.09264674782752991\n",
      "Epoch 245, Loss: 0.45412351936101913, Final Batch Loss: 0.09817012399435043\n",
      "Epoch 246, Loss: 0.43765484169125557, Final Batch Loss: 0.060416411608457565\n",
      "Epoch 247, Loss: 0.4740941599011421, Final Batch Loss: 0.14220251142978668\n",
      "Epoch 248, Loss: 0.48668377101421356, Final Batch Loss: 0.1762520670890808\n",
      "Epoch 249, Loss: 0.47290197759866714, Final Batch Loss: 0.14286047220230103\n",
      "Epoch 250, Loss: 0.4038344472646713, Final Batch Loss: 0.0725141316652298\n",
      "Epoch 251, Loss: 0.4755995497107506, Final Batch Loss: 0.13581429421901703\n",
      "Epoch 252, Loss: 0.43272893130779266, Final Batch Loss: 0.12149221450090408\n",
      "Epoch 253, Loss: 0.4865884855389595, Final Batch Loss: 0.17083284258842468\n",
      "Epoch 254, Loss: 0.4826492816209793, Final Batch Loss: 0.10558363795280457\n",
      "Epoch 255, Loss: 0.515024870634079, Final Batch Loss: 0.1907169371843338\n",
      "Epoch 256, Loss: 0.46131063252687454, Final Batch Loss: 0.13771164417266846\n",
      "Epoch 257, Loss: 0.5883332714438438, Final Batch Loss: 0.18641692399978638\n",
      "Epoch 258, Loss: 0.44798092544078827, Final Batch Loss: 0.12096967548131943\n",
      "Epoch 259, Loss: 0.5137852355837822, Final Batch Loss: 0.1315397471189499\n",
      "Epoch 260, Loss: 0.40575675666332245, Final Batch Loss: 0.12654487788677216\n",
      "Epoch 261, Loss: 0.4681890681385994, Final Batch Loss: 0.16074331104755402\n",
      "Epoch 262, Loss: 0.4504837952554226, Final Batch Loss: 0.047602128237485886\n",
      "Epoch 263, Loss: 0.39770011603832245, Final Batch Loss: 0.09736590087413788\n",
      "Epoch 264, Loss: 0.41419436037540436, Final Batch Loss: 0.08876127749681473\n",
      "Epoch 265, Loss: 0.38019634038209915, Final Batch Loss: 0.09911207854747772\n",
      "Epoch 266, Loss: 0.35651468858122826, Final Batch Loss: 0.04293197765946388\n",
      "Epoch 267, Loss: 0.4129784405231476, Final Batch Loss: 0.09754034876823425\n",
      "Epoch 268, Loss: 0.4614308625459671, Final Batch Loss: 0.14989522099494934\n",
      "Epoch 269, Loss: 0.44758687168359756, Final Batch Loss: 0.1552957147359848\n",
      "Epoch 270, Loss: 0.4018826298415661, Final Batch Loss: 0.05589909479022026\n",
      "Epoch 271, Loss: 0.44216880202293396, Final Batch Loss: 0.1117110624909401\n",
      "Epoch 272, Loss: 0.40037792921066284, Final Batch Loss: 0.109212227165699\n",
      "Epoch 273, Loss: 0.4039857089519501, Final Batch Loss: 0.04533054679632187\n",
      "Epoch 274, Loss: 0.43794407695531845, Final Batch Loss: 0.1318989396095276\n",
      "Epoch 275, Loss: 0.402683287858963, Final Batch Loss: 0.12142585217952728\n",
      "Epoch 276, Loss: 0.4176616072654724, Final Batch Loss: 0.07279796898365021\n",
      "Epoch 277, Loss: 0.4268904775381088, Final Batch Loss: 0.08140408247709274\n",
      "Epoch 278, Loss: 0.4853101372718811, Final Batch Loss: 0.1240287646651268\n",
      "Epoch 279, Loss: 0.34269583597779274, Final Batch Loss: 0.07294472306966782\n",
      "Epoch 280, Loss: 0.38635918498039246, Final Batch Loss: 0.06949751824140549\n",
      "Epoch 281, Loss: 0.376763716340065, Final Batch Loss: 0.1112232431769371\n",
      "Epoch 282, Loss: 0.4317261651158333, Final Batch Loss: 0.14671815931797028\n",
      "Epoch 283, Loss: 0.3966699093580246, Final Batch Loss: 0.08918008953332901\n",
      "Epoch 284, Loss: 0.4294080212712288, Final Batch Loss: 0.10809146612882614\n",
      "Epoch 285, Loss: 0.37030835449695587, Final Batch Loss: 0.10317274183034897\n",
      "Epoch 286, Loss: 0.3589728847146034, Final Batch Loss: 0.07383488863706589\n",
      "Epoch 287, Loss: 0.3849814757704735, Final Batch Loss: 0.10007923096418381\n",
      "Epoch 288, Loss: 0.33004842698574066, Final Batch Loss: 0.11700552701950073\n",
      "Epoch 289, Loss: 0.40469320118427277, Final Batch Loss: 0.09328901767730713\n",
      "Epoch 290, Loss: 0.3188662864267826, Final Batch Loss: 0.05229071155190468\n",
      "Epoch 291, Loss: 0.40380698442459106, Final Batch Loss: 0.12479769438505173\n",
      "Epoch 292, Loss: 0.4351908564567566, Final Batch Loss: 0.15880349278450012\n",
      "Epoch 293, Loss: 0.3511796183884144, Final Batch Loss: 0.06143442168831825\n",
      "Epoch 294, Loss: 0.3597211688756943, Final Batch Loss: 0.042998574674129486\n",
      "Epoch 295, Loss: 0.3847169727087021, Final Batch Loss: 0.11068622022867203\n",
      "Epoch 296, Loss: 0.33072082698345184, Final Batch Loss: 0.0898507609963417\n",
      "Epoch 297, Loss: 0.38894718885421753, Final Batch Loss: 0.10032586008310318\n",
      "Epoch 298, Loss: 0.5283999815583229, Final Batch Loss: 0.12588635087013245\n",
      "Epoch 299, Loss: 0.3742247000336647, Final Batch Loss: 0.06297184526920319\n",
      "Epoch 300, Loss: 0.4284827783703804, Final Batch Loss: 0.17055504024028778\n",
      "Epoch 301, Loss: 0.4753696694970131, Final Batch Loss: 0.09437833726406097\n",
      "Epoch 302, Loss: 0.48043321818113327, Final Batch Loss: 0.13202054798603058\n",
      "Epoch 303, Loss: 0.37270480394363403, Final Batch Loss: 0.10818561166524887\n",
      "Epoch 304, Loss: 0.4651535376906395, Final Batch Loss: 0.05900121480226517\n",
      "Epoch 305, Loss: 0.3855000212788582, Final Batch Loss: 0.06734766066074371\n",
      "Epoch 306, Loss: 0.3370954394340515, Final Batch Loss: 0.07861407101154327\n",
      "Epoch 307, Loss: 0.3751913830637932, Final Batch Loss: 0.062491998076438904\n",
      "Epoch 308, Loss: 0.37008511275053024, Final Batch Loss: 0.12656272947788239\n",
      "Epoch 309, Loss: 0.34441545978188515, Final Batch Loss: 0.029848460108041763\n",
      "Epoch 310, Loss: 0.39869823306798935, Final Batch Loss: 0.08330808579921722\n",
      "Epoch 311, Loss: 0.35786937549710274, Final Batch Loss: 0.04942266270518303\n",
      "Epoch 312, Loss: 0.36969874799251556, Final Batch Loss: 0.10845547169446945\n",
      "Epoch 313, Loss: 0.37471953779459, Final Batch Loss: 0.07197616249322891\n",
      "Epoch 314, Loss: 0.4415142834186554, Final Batch Loss: 0.07774495333433151\n",
      "Epoch 315, Loss: 0.34176045656204224, Final Batch Loss: 0.07806414365768433\n",
      "Epoch 316, Loss: 0.416323646903038, Final Batch Loss: 0.13274246454238892\n",
      "Epoch 317, Loss: 0.35730428621172905, Final Batch Loss: 0.09203392267227173\n",
      "Epoch 318, Loss: 0.48054341599345207, Final Batch Loss: 0.20568206906318665\n",
      "Epoch 319, Loss: 0.3193620629608631, Final Batch Loss: 0.035450298339128494\n",
      "Epoch 320, Loss: 0.3151838295161724, Final Batch Loss: 0.05898542329668999\n",
      "Epoch 321, Loss: 0.332709476351738, Final Batch Loss: 0.08238828182220459\n",
      "Epoch 322, Loss: 0.4552186504006386, Final Batch Loss: 0.1582130789756775\n",
      "Epoch 323, Loss: 0.37841738015413284, Final Batch Loss: 0.15010513365268707\n",
      "Epoch 324, Loss: 0.3627694621682167, Final Batch Loss: 0.07217801362276077\n",
      "Epoch 325, Loss: 0.3750981464982033, Final Batch Loss: 0.10288624465465546\n",
      "Epoch 326, Loss: 0.510486826300621, Final Batch Loss: 0.21391193568706512\n",
      "Epoch 327, Loss: 0.40098781883716583, Final Batch Loss: 0.11462277919054031\n",
      "Epoch 328, Loss: 0.3347550481557846, Final Batch Loss: 0.06367374956607819\n",
      "Epoch 329, Loss: 0.3869803510606289, Final Batch Loss: 0.03278138116002083\n",
      "Epoch 330, Loss: 0.3450380824506283, Final Batch Loss: 0.0584920309484005\n",
      "Epoch 331, Loss: 0.36577604338526726, Final Batch Loss: 0.060873355716466904\n",
      "Epoch 332, Loss: 0.36124980449676514, Final Batch Loss: 0.10563445836305618\n",
      "Epoch 333, Loss: 0.38331929221749306, Final Batch Loss: 0.13158129155635834\n",
      "Epoch 334, Loss: 0.34164873883128166, Final Batch Loss: 0.06010844185948372\n",
      "Epoch 335, Loss: 0.302306842058897, Final Batch Loss: 0.09455565363168716\n",
      "Epoch 336, Loss: 0.2602585479617119, Final Batch Loss: 0.04720926284790039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337, Loss: 0.3679651767015457, Final Batch Loss: 0.041943423449993134\n",
      "Epoch 338, Loss: 0.2722722068428993, Final Batch Loss: 0.043426986783742905\n",
      "Epoch 339, Loss: 0.30665768682956696, Final Batch Loss: 0.053815651684999466\n",
      "Epoch 340, Loss: 0.42026007920503616, Final Batch Loss: 0.09872868657112122\n",
      "Epoch 341, Loss: 0.424738809466362, Final Batch Loss: 0.06868200749158859\n",
      "Epoch 342, Loss: 0.3880073353648186, Final Batch Loss: 0.10653308033943176\n",
      "Epoch 343, Loss: 0.2785641923546791, Final Batch Loss: 0.040013425052165985\n",
      "Epoch 344, Loss: 0.3112856410443783, Final Batch Loss: 0.07380969077348709\n",
      "Epoch 345, Loss: 0.346934549510479, Final Batch Loss: 0.09254349023103714\n",
      "Epoch 346, Loss: 0.40221892669796944, Final Batch Loss: 0.04187425598502159\n",
      "Epoch 347, Loss: 0.33285941183567047, Final Batch Loss: 0.08648843318223953\n",
      "Epoch 348, Loss: 0.3751654885709286, Final Batch Loss: 0.0848463922739029\n",
      "Epoch 349, Loss: 0.3518651984632015, Final Batch Loss: 0.10124078392982483\n",
      "Epoch 350, Loss: 0.29243054240942, Final Batch Loss: 0.06270276755094528\n",
      "Epoch 351, Loss: 0.33708561956882477, Final Batch Loss: 0.0900845155119896\n",
      "Epoch 352, Loss: 0.3279712349176407, Final Batch Loss: 0.060767047107219696\n",
      "Epoch 353, Loss: 0.3893875926733017, Final Batch Loss: 0.13501280546188354\n",
      "Epoch 354, Loss: 0.30297013372182846, Final Batch Loss: 0.08882150799036026\n",
      "Epoch 355, Loss: 0.36562297493219376, Final Batch Loss: 0.12496925890445709\n",
      "Epoch 356, Loss: 0.23542393743991852, Final Batch Loss: 0.045023877173662186\n",
      "Epoch 357, Loss: 0.36507438868284225, Final Batch Loss: 0.08839999884366989\n",
      "Epoch 358, Loss: 0.3392903432250023, Final Batch Loss: 0.057803601026535034\n",
      "Epoch 359, Loss: 0.323084220290184, Final Batch Loss: 0.09837508946657181\n",
      "Epoch 360, Loss: 0.32341181486845016, Final Batch Loss: 0.08204711973667145\n",
      "Epoch 361, Loss: 0.30007945001125336, Final Batch Loss: 0.11149721592664719\n",
      "Epoch 362, Loss: 0.3547902964055538, Final Batch Loss: 0.052530743181705475\n",
      "Epoch 363, Loss: 0.3154018223285675, Final Batch Loss: 0.034826286137104034\n",
      "Epoch 364, Loss: 0.3794156238436699, Final Batch Loss: 0.07567736506462097\n",
      "Epoch 365, Loss: 0.33352429792284966, Final Batch Loss: 0.1138954758644104\n",
      "Epoch 366, Loss: 0.3896608166396618, Final Batch Loss: 0.14286820590496063\n",
      "Epoch 367, Loss: 0.40247223526239395, Final Batch Loss: 0.07284428179264069\n",
      "Epoch 368, Loss: 0.3157874792814255, Final Batch Loss: 0.02904108539223671\n",
      "Epoch 369, Loss: 0.3173079639673233, Final Batch Loss: 0.05069015175104141\n",
      "Epoch 370, Loss: 0.24869222566485405, Final Batch Loss: 0.03859453275799751\n",
      "Epoch 371, Loss: 0.29177453368902206, Final Batch Loss: 0.01796622946858406\n",
      "Epoch 372, Loss: 0.2621812727302313, Final Batch Loss: 0.022734539583325386\n",
      "Epoch 373, Loss: 0.27003148198127747, Final Batch Loss: 0.06850749999284744\n",
      "Epoch 374, Loss: 0.2784353196620941, Final Batch Loss: 0.06346169859170914\n",
      "Epoch 375, Loss: 0.24040848389267921, Final Batch Loss: 0.04364342242479324\n",
      "Epoch 376, Loss: 0.32761741429567337, Final Batch Loss: 0.07129926979541779\n",
      "Epoch 377, Loss: 0.356224425137043, Final Batch Loss: 0.12177158892154694\n",
      "Epoch 378, Loss: 0.27141712233424187, Final Batch Loss: 0.050543222576379776\n",
      "Epoch 379, Loss: 0.33737992495298386, Final Batch Loss: 0.10875674337148666\n",
      "Epoch 380, Loss: 0.2690685838460922, Final Batch Loss: 0.07229092717170715\n",
      "Epoch 381, Loss: 0.35960521548986435, Final Batch Loss: 0.10438380390405655\n",
      "Epoch 382, Loss: 0.30839284136891365, Final Batch Loss: 0.04683896526694298\n",
      "Epoch 383, Loss: 0.36371272429823875, Final Batch Loss: 0.09174615144729614\n",
      "Epoch 384, Loss: 0.2301198523491621, Final Batch Loss: 0.047444820404052734\n",
      "Epoch 385, Loss: 0.25895054265856743, Final Batch Loss: 0.06068595498800278\n",
      "Epoch 386, Loss: 0.3217695504426956, Final Batch Loss: 0.07744024693965912\n",
      "Epoch 387, Loss: 0.2878912687301636, Final Batch Loss: 0.09886131435632706\n",
      "Epoch 388, Loss: 0.24793488159775734, Final Batch Loss: 0.06758309155702591\n",
      "Epoch 389, Loss: 0.2208904903382063, Final Batch Loss: 0.0443941093981266\n",
      "Epoch 390, Loss: 0.3082784153521061, Final Batch Loss: 0.06891706585884094\n",
      "Epoch 391, Loss: 0.3177749328315258, Final Batch Loss: 0.03644156828522682\n",
      "Epoch 392, Loss: 0.32924724370241165, Final Batch Loss: 0.07130151242017746\n",
      "Epoch 393, Loss: 0.3561473712325096, Final Batch Loss: 0.06617026031017303\n",
      "Epoch 394, Loss: 0.3324720449745655, Final Batch Loss: 0.07243433594703674\n",
      "Epoch 395, Loss: 0.3384464345872402, Final Batch Loss: 0.12606707215309143\n",
      "Epoch 396, Loss: 0.4564487487077713, Final Batch Loss: 0.129214346408844\n",
      "Epoch 397, Loss: 0.39982661977410316, Final Batch Loss: 0.13486336171627045\n",
      "Epoch 398, Loss: 0.3816096931695938, Final Batch Loss: 0.11503587663173676\n",
      "Epoch 399, Loss: 0.34939874336123466, Final Batch Loss: 0.07602229714393616\n",
      "Epoch 400, Loss: 0.41249334812164307, Final Batch Loss: 0.07257825881242752\n",
      "Epoch 401, Loss: 0.4249429628252983, Final Batch Loss: 0.0498211607336998\n",
      "Epoch 402, Loss: 0.49632520228624344, Final Batch Loss: 0.15632423758506775\n",
      "Epoch 403, Loss: 0.3822384253144264, Final Batch Loss: 0.11838214099407196\n",
      "Epoch 404, Loss: 0.29846692830324173, Final Batch Loss: 0.04834618791937828\n",
      "Epoch 405, Loss: 0.44123197346925735, Final Batch Loss: 0.16076603531837463\n",
      "Epoch 406, Loss: 0.28897393494844437, Final Batch Loss: 0.08428382128477097\n",
      "Epoch 407, Loss: 0.5349968895316124, Final Batch Loss: 0.20354363322257996\n",
      "Epoch 408, Loss: 0.29463472217321396, Final Batch Loss: 0.043204858899116516\n",
      "Epoch 409, Loss: 0.3989192321896553, Final Batch Loss: 0.11571897566318512\n",
      "Epoch 410, Loss: 0.30414171144366264, Final Batch Loss: 0.07909093797206879\n",
      "Epoch 411, Loss: 0.3760058619081974, Final Batch Loss: 0.18172337114810944\n",
      "Epoch 412, Loss: 0.29694104194641113, Final Batch Loss: 0.10223906487226486\n",
      "Epoch 413, Loss: 0.30127494037151337, Final Batch Loss: 0.08194518089294434\n",
      "Epoch 414, Loss: 0.28774917498230934, Final Batch Loss: 0.11801183223724365\n",
      "Epoch 415, Loss: 0.38993722945451736, Final Batch Loss: 0.13484443724155426\n",
      "Epoch 416, Loss: 0.5252339988946915, Final Batch Loss: 0.1952236145734787\n",
      "Epoch 417, Loss: 0.4052155017852783, Final Batch Loss: 0.1337921917438507\n",
      "Epoch 418, Loss: 0.28237271308898926, Final Batch Loss: 0.04831589758396149\n",
      "Epoch 419, Loss: 0.35572998225688934, Final Batch Loss: 0.08681734651327133\n",
      "Epoch 420, Loss: 0.27537430822849274, Final Batch Loss: 0.09564825147390366\n",
      "Epoch 421, Loss: 0.39265214651823044, Final Batch Loss: 0.16435407102108002\n",
      "Epoch 422, Loss: 0.3607882522046566, Final Batch Loss: 0.048743169754743576\n",
      "Epoch 423, Loss: 0.302309513092041, Final Batch Loss: 0.11102960258722305\n",
      "Epoch 424, Loss: 0.2647148370742798, Final Batch Loss: 0.03932490944862366\n",
      "Epoch 425, Loss: 0.2434940356761217, Final Batch Loss: 0.02815895341336727\n",
      "Epoch 426, Loss: 0.2930906191468239, Final Batch Loss: 0.08209241181612015\n",
      "Epoch 427, Loss: 0.2810713015496731, Final Batch Loss: 0.0671771988272667\n",
      "Epoch 428, Loss: 0.2374490611255169, Final Batch Loss: 0.03374156728386879\n",
      "Epoch 429, Loss: 0.23500939831137657, Final Batch Loss: 0.04586658999323845\n",
      "Epoch 430, Loss: 0.2025384809821844, Final Batch Loss: 0.04112538322806358\n",
      "Epoch 431, Loss: 0.29967717453837395, Final Batch Loss: 0.08440624922513962\n",
      "Epoch 432, Loss: 0.224947739392519, Final Batch Loss: 0.05252012237906456\n",
      "Epoch 433, Loss: 0.2990989685058594, Final Batch Loss: 0.10931292921304703\n",
      "Epoch 434, Loss: 0.1915462501347065, Final Batch Loss: 0.03640170022845268\n",
      "Epoch 435, Loss: 0.24830476939678192, Final Batch Loss: 0.08503484725952148\n",
      "Epoch 436, Loss: 0.209748987108469, Final Batch Loss: 0.04137904569506645\n",
      "Epoch 437, Loss: 0.2841058820486069, Final Batch Loss: 0.08862028270959854\n",
      "Epoch 438, Loss: 0.2327626757323742, Final Batch Loss: 0.07157985121011734\n",
      "Epoch 439, Loss: 0.25980503484606743, Final Batch Loss: 0.04165356606245041\n",
      "Epoch 440, Loss: 0.25889603421092033, Final Batch Loss: 0.07336240261793137\n",
      "Epoch 441, Loss: 0.2457101196050644, Final Batch Loss: 0.07145444303750992\n",
      "Epoch 442, Loss: 0.2784479707479477, Final Batch Loss: 0.03545944392681122\n",
      "Epoch 443, Loss: 0.2577678896486759, Final Batch Loss: 0.05572928860783577\n",
      "Epoch 444, Loss: 0.25417453050613403, Final Batch Loss: 0.05160396173596382\n",
      "Epoch 445, Loss: 0.20958823710680008, Final Batch Loss: 0.10567213594913483\n",
      "Epoch 446, Loss: 0.26325029134750366, Final Batch Loss: 0.09165257960557938\n",
      "Epoch 447, Loss: 0.25455962121486664, Final Batch Loss: 0.0709739699959755\n",
      "Epoch 448, Loss: 0.25950144976377487, Final Batch Loss: 0.06349381804466248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449, Loss: 0.18082491867244244, Final Batch Loss: 0.02787732519209385\n",
      "Epoch 450, Loss: 0.3576309382915497, Final Batch Loss: 0.03638197109103203\n",
      "Epoch 451, Loss: 0.25059161335229874, Final Batch Loss: 0.012643605470657349\n",
      "Epoch 452, Loss: 0.1880396604537964, Final Batch Loss: 0.0715208351612091\n",
      "Epoch 453, Loss: 0.2326345182955265, Final Batch Loss: 0.05190045386552811\n",
      "Epoch 454, Loss: 0.2307808268815279, Final Batch Loss: 0.02955770678818226\n",
      "Epoch 455, Loss: 0.1699357070028782, Final Batch Loss: 0.04377445951104164\n",
      "Epoch 456, Loss: 0.20653123408555984, Final Batch Loss: 0.041959185153245926\n",
      "Epoch 457, Loss: 0.24039877206087112, Final Batch Loss: 0.04434892535209656\n",
      "Epoch 458, Loss: 0.21155273169279099, Final Batch Loss: 0.055476099252700806\n",
      "Epoch 459, Loss: 0.18291443958878517, Final Batch Loss: 0.048129595816135406\n",
      "Epoch 460, Loss: 0.1680188737809658, Final Batch Loss: 0.01848217099905014\n",
      "Epoch 461, Loss: 0.2529754638671875, Final Batch Loss: 0.06599961966276169\n",
      "Epoch 462, Loss: 0.18036896362900734, Final Batch Loss: 0.039089053869247437\n",
      "Epoch 463, Loss: 0.2027219422161579, Final Batch Loss: 0.018468819558620453\n",
      "Epoch 464, Loss: 0.29225512593984604, Final Batch Loss: 0.0725478008389473\n",
      "Epoch 465, Loss: 0.17552724480628967, Final Batch Loss: 0.035812992602586746\n",
      "Epoch 466, Loss: 0.2012514304369688, Final Batch Loss: 0.05839228257536888\n",
      "Epoch 467, Loss: 0.1972808688879013, Final Batch Loss: 0.04164304584264755\n",
      "Epoch 468, Loss: 0.22754864767193794, Final Batch Loss: 0.0879465788602829\n",
      "Epoch 469, Loss: 0.21299574337899685, Final Batch Loss: 0.09077907353639603\n",
      "Epoch 470, Loss: 0.22719839960336685, Final Batch Loss: 0.043580491095781326\n",
      "Epoch 471, Loss: 0.3372914642095566, Final Batch Loss: 0.08779248595237732\n",
      "Epoch 472, Loss: 0.20624171197414398, Final Batch Loss: 0.05144888907670975\n",
      "Epoch 473, Loss: 0.2215077057480812, Final Batch Loss: 0.07866118848323822\n",
      "Epoch 474, Loss: 0.31724319607019424, Final Batch Loss: 0.1037561371922493\n",
      "Epoch 475, Loss: 0.2258450910449028, Final Batch Loss: 0.035289961844682693\n",
      "Epoch 476, Loss: 0.2765791080892086, Final Batch Loss: 0.08488006889820099\n",
      "Epoch 477, Loss: 0.2655029296875, Final Batch Loss: 0.08612833172082901\n",
      "Epoch 478, Loss: 0.19415027648210526, Final Batch Loss: 0.026526734232902527\n",
      "Epoch 479, Loss: 0.23632854595780373, Final Batch Loss: 0.09814077615737915\n",
      "Epoch 480, Loss: 0.20267776772379875, Final Batch Loss: 0.04483320564031601\n",
      "Epoch 481, Loss: 0.21972864493727684, Final Batch Loss: 0.08027106523513794\n",
      "Epoch 482, Loss: 0.2363339513540268, Final Batch Loss: 0.05811009556055069\n",
      "Epoch 483, Loss: 0.22268712893128395, Final Batch Loss: 0.033654678612947464\n",
      "Epoch 484, Loss: 0.3101245053112507, Final Batch Loss: 0.0673213005065918\n",
      "Epoch 485, Loss: 0.22584202513098717, Final Batch Loss: 0.07017851620912552\n",
      "Epoch 486, Loss: 0.2975505143404007, Final Batch Loss: 0.09070050716400146\n",
      "Epoch 487, Loss: 0.25054188445210457, Final Batch Loss: 0.041415080428123474\n",
      "Epoch 488, Loss: 0.21836388111114502, Final Batch Loss: 0.06891869753599167\n",
      "Epoch 489, Loss: 0.22645170614123344, Final Batch Loss: 0.04941132292151451\n",
      "Epoch 490, Loss: 0.17676126211881638, Final Batch Loss: 0.05928342416882515\n",
      "Epoch 491, Loss: 0.2568529173731804, Final Batch Loss: 0.052008237689733505\n",
      "Epoch 492, Loss: 0.271087110042572, Final Batch Loss: 0.10196118801832199\n",
      "Epoch 493, Loss: 0.24448616802692413, Final Batch Loss: 0.05482753738760948\n",
      "Epoch 494, Loss: 0.18511979095637798, Final Batch Loss: 0.0635855495929718\n",
      "Epoch 495, Loss: 0.15532194636762142, Final Batch Loss: 0.053200919181108475\n",
      "Epoch 496, Loss: 0.2121181394904852, Final Batch Loss: 0.07819747924804688\n",
      "Epoch 497, Loss: 0.20770879089832306, Final Batch Loss: 0.0324365608394146\n",
      "Epoch 498, Loss: 0.15147534012794495, Final Batch Loss: 0.018198631703853607\n",
      "Epoch 499, Loss: 0.26442015916109085, Final Batch Loss: 0.07360796630382538\n",
      "Epoch 500, Loss: 0.2122813705354929, Final Batch Loss: 0.09689489006996155\n",
      "Epoch 501, Loss: 0.21777386404573917, Final Batch Loss: 0.030136005952954292\n",
      "Epoch 502, Loss: 0.20863396674394608, Final Batch Loss: 0.025001469999551773\n",
      "Epoch 503, Loss: 0.1887215282768011, Final Batch Loss: 0.034231748431921005\n",
      "Epoch 504, Loss: 0.2768229693174362, Final Batch Loss: 0.060000717639923096\n",
      "Epoch 505, Loss: 0.22830989956855774, Final Batch Loss: 0.05106529965996742\n",
      "Epoch 506, Loss: 0.1892761094495654, Final Batch Loss: 0.07477080821990967\n",
      "Epoch 507, Loss: 0.16765847615897655, Final Batch Loss: 0.012221014127135277\n",
      "Epoch 508, Loss: 0.23532932996749878, Final Batch Loss: 0.06737866997718811\n",
      "Epoch 509, Loss: 0.2045607604086399, Final Batch Loss: 0.06474334746599197\n",
      "Epoch 510, Loss: 0.20230192132294178, Final Batch Loss: 0.07054994255304337\n",
      "Epoch 511, Loss: 0.2874288111925125, Final Batch Loss: 0.09939247369766235\n",
      "Epoch 512, Loss: 0.1839456930756569, Final Batch Loss: 0.02827564626932144\n",
      "Epoch 513, Loss: 0.2508301269263029, Final Batch Loss: 0.012210113927721977\n",
      "Epoch 514, Loss: 0.1930990368127823, Final Batch Loss: 0.06553860753774643\n",
      "Epoch 515, Loss: 0.21002552285790443, Final Batch Loss: 0.022055882960557938\n",
      "Epoch 516, Loss: 0.1597213950008154, Final Batch Loss: 0.009919965639710426\n",
      "Epoch 517, Loss: 0.17385615035891533, Final Batch Loss: 0.05083978921175003\n",
      "Epoch 518, Loss: 0.19809128530323505, Final Batch Loss: 0.02701389603316784\n",
      "Epoch 519, Loss: 0.1998927779495716, Final Batch Loss: 0.01648012176156044\n",
      "Epoch 520, Loss: 0.3585609793663025, Final Batch Loss: 0.11259936541318893\n",
      "Epoch 521, Loss: 0.18564358726143837, Final Batch Loss: 0.031950339674949646\n",
      "Epoch 522, Loss: 0.2573276776820421, Final Batch Loss: 0.13098719716072083\n",
      "Epoch 523, Loss: 0.20442366413772106, Final Batch Loss: 0.016633493825793266\n",
      "Epoch 524, Loss: 0.2008695136755705, Final Batch Loss: 0.02256239391863346\n",
      "Epoch 525, Loss: 0.2236758079379797, Final Batch Loss: 0.08255201578140259\n",
      "Epoch 526, Loss: 0.14479062147438526, Final Batch Loss: 0.025354035198688507\n",
      "Epoch 527, Loss: 0.1970805637538433, Final Batch Loss: 0.03419940173625946\n",
      "Epoch 528, Loss: 0.21054519526660442, Final Batch Loss: 0.04136371240019798\n",
      "Epoch 529, Loss: 0.25863645784556866, Final Batch Loss: 0.14629651606082916\n",
      "Epoch 530, Loss: 0.20162144303321838, Final Batch Loss: 0.1156468316912651\n",
      "Epoch 531, Loss: 0.1637795651331544, Final Batch Loss: 0.010760278441011906\n",
      "Epoch 532, Loss: 0.19585128873586655, Final Batch Loss: 0.04757429659366608\n",
      "Epoch 533, Loss: 0.2626848965883255, Final Batch Loss: 0.0798460990190506\n",
      "Epoch 534, Loss: 0.23273032531142235, Final Batch Loss: 0.07118228077888489\n",
      "Epoch 535, Loss: 0.1617679689079523, Final Batch Loss: 0.026864560320973396\n",
      "Epoch 536, Loss: 0.23428087681531906, Final Batch Loss: 0.08219297975301743\n",
      "Epoch 537, Loss: 0.2268790826201439, Final Batch Loss: 0.04146873950958252\n",
      "Epoch 538, Loss: 0.16465447843074799, Final Batch Loss: 0.01730632781982422\n",
      "Epoch 539, Loss: 0.23870595544576645, Final Batch Loss: 0.08827294409275055\n",
      "Epoch 540, Loss: 0.13874631561338902, Final Batch Loss: 0.03832686319947243\n",
      "Epoch 541, Loss: 0.26661960408091545, Final Batch Loss: 0.07245383411645889\n",
      "Epoch 542, Loss: 0.21629968099296093, Final Batch Loss: 0.04061520844697952\n",
      "Epoch 543, Loss: 0.20723308809101582, Final Batch Loss: 0.0703950896859169\n",
      "Epoch 544, Loss: 0.18454081937670708, Final Batch Loss: 0.041363075375556946\n",
      "Epoch 545, Loss: 0.15863124281167984, Final Batch Loss: 0.02380385994911194\n",
      "Epoch 546, Loss: 0.32119791582226753, Final Batch Loss: 0.18812894821166992\n",
      "Epoch 547, Loss: 0.20319353975355625, Final Batch Loss: 0.03716551885008812\n",
      "Epoch 548, Loss: 0.26261353492736816, Final Batch Loss: 0.05519527941942215\n",
      "Epoch 549, Loss: 0.14110014587640762, Final Batch Loss: 0.019822992384433746\n",
      "Epoch 550, Loss: 0.1864413283765316, Final Batch Loss: 0.027745505794882774\n",
      "Epoch 551, Loss: 0.29586782678961754, Final Batch Loss: 0.1273440420627594\n",
      "Epoch 552, Loss: 0.2241099700331688, Final Batch Loss: 0.06826747208833694\n",
      "Epoch 553, Loss: 0.22948740050196648, Final Batch Loss: 0.04658399149775505\n",
      "Epoch 554, Loss: 0.28714823722839355, Final Batch Loss: 0.13563738763332367\n",
      "Epoch 555, Loss: 0.2119572265073657, Final Batch Loss: 0.015132981352508068\n",
      "Epoch 556, Loss: 0.17112182453274727, Final Batch Loss: 0.06475958973169327\n",
      "Epoch 557, Loss: 0.16877328976988792, Final Batch Loss: 0.04254724085330963\n",
      "Epoch 558, Loss: 0.18213390931487083, Final Batch Loss: 0.034465719014406204\n",
      "Epoch 559, Loss: 0.17150343023240566, Final Batch Loss: 0.06166690215468407\n",
      "Epoch 560, Loss: 0.21225135400891304, Final Batch Loss: 0.09086621552705765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561, Loss: 0.17283732444047928, Final Batch Loss: 0.031352512538433075\n",
      "Epoch 562, Loss: 0.11344398185610771, Final Batch Loss: 0.01740901730954647\n",
      "Epoch 563, Loss: 0.18534615449607372, Final Batch Loss: 0.022518010810017586\n",
      "Epoch 564, Loss: 0.14158549811691046, Final Batch Loss: 0.00615816842764616\n",
      "Epoch 565, Loss: 0.21699070930480957, Final Batch Loss: 0.045406781136989594\n",
      "Epoch 566, Loss: 0.18241075985133648, Final Batch Loss: 0.036785583943128586\n",
      "Epoch 567, Loss: 0.1755651980638504, Final Batch Loss: 0.027723897248506546\n",
      "Epoch 568, Loss: 0.20443278551101685, Final Batch Loss: 0.05503624677658081\n",
      "Epoch 569, Loss: 0.2807345874607563, Final Batch Loss: 0.05918867513537407\n",
      "Epoch 570, Loss: 0.19821579940617085, Final Batch Loss: 0.04061344638466835\n",
      "Epoch 571, Loss: 0.2177087813615799, Final Batch Loss: 0.02780396305024624\n",
      "Epoch 572, Loss: 0.26768575608730316, Final Batch Loss: 0.10674728453159332\n",
      "Epoch 573, Loss: 0.1732482723891735, Final Batch Loss: 0.06599348783493042\n",
      "Epoch 574, Loss: 0.3447718508541584, Final Batch Loss: 0.08149144053459167\n",
      "Epoch 575, Loss: 0.1640618685632944, Final Batch Loss: 0.04916628077626228\n",
      "Epoch 576, Loss: 0.22223197296261787, Final Batch Loss: 0.02539076656103134\n",
      "Epoch 577, Loss: 0.3926154300570488, Final Batch Loss: 0.11575387418270111\n",
      "Epoch 578, Loss: 0.2491585649549961, Final Batch Loss: 0.046829819679260254\n",
      "Epoch 579, Loss: 0.2629638984799385, Final Batch Loss: 0.09245122969150543\n",
      "Epoch 580, Loss: 0.22962599620223045, Final Batch Loss: 0.03620675578713417\n",
      "Epoch 581, Loss: 0.2915147766470909, Final Batch Loss: 0.05977416783571243\n",
      "Epoch 582, Loss: 0.24189253151416779, Final Batch Loss: 0.027294840663671494\n",
      "Epoch 583, Loss: 0.4037918820977211, Final Batch Loss: 0.17787623405456543\n",
      "Epoch 584, Loss: 0.21513399481773376, Final Batch Loss: 0.06500038504600525\n",
      "Epoch 585, Loss: 0.25906312093138695, Final Batch Loss: 0.0788506492972374\n",
      "Epoch 586, Loss: 0.22175069153308868, Final Batch Loss: 0.04151690751314163\n",
      "Epoch 587, Loss: 0.3576380517333746, Final Batch Loss: 0.028879540041089058\n",
      "Epoch 588, Loss: 0.22251454554498196, Final Batch Loss: 0.0773187130689621\n",
      "Epoch 589, Loss: 0.2691639382392168, Final Batch Loss: 0.1345348209142685\n",
      "Epoch 590, Loss: 0.15186237916350365, Final Batch Loss: 0.02918744832277298\n",
      "Epoch 591, Loss: 0.21331148222088814, Final Batch Loss: 0.04839594289660454\n",
      "Epoch 592, Loss: 0.22685082908719778, Final Batch Loss: 0.013607892207801342\n",
      "Epoch 593, Loss: 0.1989164650440216, Final Batch Loss: 0.024305518716573715\n",
      "Epoch 594, Loss: 0.2044938262552023, Final Batch Loss: 0.028883052989840508\n",
      "Epoch 595, Loss: 0.2659219242632389, Final Batch Loss: 0.17570094764232635\n",
      "Epoch 596, Loss: 0.14382574148476124, Final Batch Loss: 0.021192120388150215\n",
      "Epoch 597, Loss: 0.22015242464840412, Final Batch Loss: 0.012777792289853096\n",
      "Epoch 598, Loss: 0.24735445156693459, Final Batch Loss: 0.06374596804380417\n",
      "Epoch 599, Loss: 0.23669564351439476, Final Batch Loss: 0.08581431955099106\n",
      "Epoch 600, Loss: 0.3485190272331238, Final Batch Loss: 0.14595386385917664\n",
      "Epoch 601, Loss: 0.18009698390960693, Final Batch Loss: 0.027062665671110153\n",
      "Epoch 602, Loss: 0.2412702850997448, Final Batch Loss: 0.06786522269248962\n",
      "Epoch 603, Loss: 0.20001890510320663, Final Batch Loss: 0.050615087151527405\n",
      "Epoch 604, Loss: 0.27717453241348267, Final Batch Loss: 0.10327762365341187\n",
      "Epoch 605, Loss: 0.24698514305055141, Final Batch Loss: 0.07708872109651566\n",
      "Epoch 606, Loss: 0.3528975248336792, Final Batch Loss: 0.13677950203418732\n",
      "Epoch 607, Loss: 0.15173116978257895, Final Batch Loss: 0.03986910358071327\n",
      "Epoch 608, Loss: 0.21850424632430077, Final Batch Loss: 0.0558164082467556\n",
      "Epoch 609, Loss: 0.2002938836812973, Final Batch Loss: 0.040804099291563034\n",
      "Epoch 610, Loss: 0.14677901193499565, Final Batch Loss: 0.03055310808122158\n",
      "Epoch 611, Loss: 0.13270459696650505, Final Batch Loss: 0.057840537279844284\n",
      "Epoch 612, Loss: 0.21448754705488682, Final Batch Loss: 0.051261089742183685\n",
      "Epoch 613, Loss: 0.28809628263115883, Final Batch Loss: 0.04598905146121979\n",
      "Epoch 614, Loss: 0.17509104683995247, Final Batch Loss: 0.02003486268222332\n",
      "Epoch 615, Loss: 0.36026448011398315, Final Batch Loss: 0.10854630172252655\n",
      "Epoch 616, Loss: 0.18393928743898869, Final Batch Loss: 0.027284802868962288\n",
      "Epoch 617, Loss: 0.16322601214051247, Final Batch Loss: 0.04594152048230171\n",
      "Epoch 618, Loss: 0.1808481402695179, Final Batch Loss: 0.03978417068719864\n",
      "Epoch 619, Loss: 0.27871287520974874, Final Batch Loss: 0.008067685179412365\n",
      "Epoch 620, Loss: 0.1250102836638689, Final Batch Loss: 0.040498774498701096\n",
      "Epoch 621, Loss: 0.33473682403564453, Final Batch Loss: 0.11885656416416168\n",
      "Epoch 622, Loss: 0.14697590842843056, Final Batch Loss: 0.016728345304727554\n",
      "Epoch 623, Loss: 0.14953084383159876, Final Batch Loss: 0.014373325742781162\n",
      "Epoch 624, Loss: 0.2485934142023325, Final Batch Loss: 0.08047372847795486\n",
      "Epoch 625, Loss: 0.20237328857183456, Final Batch Loss: 0.02682829648256302\n",
      "Epoch 626, Loss: 0.21328339353203773, Final Batch Loss: 0.10493412613868713\n",
      "Epoch 627, Loss: 0.13846238516271114, Final Batch Loss: 0.011195098981261253\n",
      "Epoch 628, Loss: 0.1637619026005268, Final Batch Loss: 0.015947453677654266\n",
      "Epoch 629, Loss: 0.17960222996771336, Final Batch Loss: 0.02423529140651226\n",
      "Epoch 630, Loss: 0.2202765829861164, Final Batch Loss: 0.04987265169620514\n",
      "Epoch 631, Loss: 0.21173487976193428, Final Batch Loss: 0.0655902847647667\n",
      "Epoch 632, Loss: 0.19923371076583862, Final Batch Loss: 0.07230184227228165\n",
      "Epoch 633, Loss: 0.11988257803022861, Final Batch Loss: 0.01921948976814747\n",
      "Epoch 634, Loss: 0.1809747088700533, Final Batch Loss: 0.026635877788066864\n",
      "Epoch 635, Loss: 0.13317073322832584, Final Batch Loss: 0.019888566806912422\n",
      "Epoch 636, Loss: 0.14088719990104437, Final Batch Loss: 0.012051570229232311\n",
      "Epoch 637, Loss: 0.21926273964345455, Final Batch Loss: 0.027471544221043587\n",
      "Epoch 638, Loss: 0.14310872182250023, Final Batch Loss: 0.023425597697496414\n",
      "Epoch 639, Loss: 0.12926907767541707, Final Batch Loss: 0.002938145073130727\n",
      "Epoch 640, Loss: 0.09790175035595894, Final Batch Loss: 0.01846219226717949\n",
      "Epoch 641, Loss: 0.14592123962938786, Final Batch Loss: 0.024896549060940742\n",
      "Epoch 642, Loss: 0.15967030450701714, Final Batch Loss: 0.07010392099618912\n",
      "Epoch 643, Loss: 0.14921674132347107, Final Batch Loss: 0.015658020973205566\n",
      "Epoch 644, Loss: 0.1633745301514864, Final Batch Loss: 0.026664437726140022\n",
      "Epoch 645, Loss: 0.23510447144508362, Final Batch Loss: 0.0540572889149189\n",
      "Epoch 646, Loss: 0.26003049314022064, Final Batch Loss: 0.10499735176563263\n",
      "Epoch 647, Loss: 0.17868915013968945, Final Batch Loss: 0.018751325085759163\n",
      "Epoch 648, Loss: 0.24175069853663445, Final Batch Loss: 0.0439152792096138\n",
      "Epoch 649, Loss: 0.25947991386055946, Final Batch Loss: 0.058823633939027786\n",
      "Epoch 650, Loss: 0.20659179612994194, Final Batch Loss: 0.07040132582187653\n",
      "Epoch 651, Loss: 0.252204280346632, Final Batch Loss: 0.07944837957620621\n",
      "Epoch 652, Loss: 0.11396877840161324, Final Batch Loss: 0.011807922273874283\n",
      "Epoch 653, Loss: 0.2084278855472803, Final Batch Loss: 0.029339345172047615\n",
      "Epoch 654, Loss: 0.18737576995044947, Final Batch Loss: 0.017997324466705322\n",
      "Epoch 655, Loss: 0.1316157840192318, Final Batch Loss: 0.005611518397927284\n",
      "Epoch 656, Loss: 0.21636542305350304, Final Batch Loss: 0.04200649634003639\n",
      "Epoch 657, Loss: 0.2158569172024727, Final Batch Loss: 0.02252882719039917\n",
      "Epoch 658, Loss: 0.15127618238329887, Final Batch Loss: 0.04160020127892494\n",
      "Epoch 659, Loss: 0.22110810317099094, Final Batch Loss: 0.015510478988289833\n",
      "Epoch 660, Loss: 0.1570223681628704, Final Batch Loss: 0.022349124774336815\n",
      "Epoch 661, Loss: 0.16422500647604465, Final Batch Loss: 0.04804355651140213\n",
      "Epoch 662, Loss: 0.18701017182320356, Final Batch Loss: 0.042614880949258804\n",
      "Epoch 663, Loss: 0.24858093820512295, Final Batch Loss: 0.017792919650673866\n",
      "Epoch 664, Loss: 0.22503004595637321, Final Batch Loss: 0.0736100822687149\n",
      "Epoch 665, Loss: 0.27347367629408836, Final Batch Loss: 0.05531919375061989\n",
      "Epoch 666, Loss: 0.17958975955843925, Final Batch Loss: 0.07292799651622772\n",
      "Epoch 667, Loss: 0.10453109443187714, Final Batch Loss: 0.01851094514131546\n",
      "Epoch 668, Loss: 0.2355373054742813, Final Batch Loss: 0.0817762166261673\n",
      "Epoch 669, Loss: 0.2330533880740404, Final Batch Loss: 0.018591919913887978\n",
      "Epoch 670, Loss: 0.18970518186688423, Final Batch Loss: 0.03834659606218338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671, Loss: 0.1856376677751541, Final Batch Loss: 0.0721936896443367\n",
      "Epoch 672, Loss: 0.29275393672287464, Final Batch Loss: 0.032009463757276535\n",
      "Epoch 673, Loss: 0.31672255881130695, Final Batch Loss: 0.13445106148719788\n",
      "Epoch 674, Loss: 0.23717277124524117, Final Batch Loss: 0.04958923161029816\n",
      "Epoch 675, Loss: 0.14730333350598812, Final Batch Loss: 0.018343573436141014\n",
      "Epoch 676, Loss: 0.19427377730607986, Final Batch Loss: 0.05528048053383827\n",
      "Epoch 677, Loss: 0.23562521301209927, Final Batch Loss: 0.11087989062070847\n",
      "Epoch 678, Loss: 0.16431851359084249, Final Batch Loss: 0.006994903553277254\n",
      "Epoch 679, Loss: 0.24221550673246384, Final Batch Loss: 0.09324454516172409\n",
      "Epoch 680, Loss: 0.1774876732379198, Final Batch Loss: 0.035209301859140396\n",
      "Epoch 681, Loss: 0.14355395175516605, Final Batch Loss: 0.027249040082097054\n",
      "Epoch 682, Loss: 0.17256544902920723, Final Batch Loss: 0.04602572321891785\n",
      "Epoch 683, Loss: 0.2155124880373478, Final Batch Loss: 0.0828058049082756\n",
      "Epoch 684, Loss: 0.13573753274977207, Final Batch Loss: 0.027295060455799103\n",
      "Epoch 685, Loss: 0.2274836879223585, Final Batch Loss: 0.026420636102557182\n",
      "Epoch 686, Loss: 0.1870767530053854, Final Batch Loss: 0.056117381900548935\n",
      "Epoch 687, Loss: 0.21481842547655106, Final Batch Loss: 0.09872656315565109\n",
      "Epoch 688, Loss: 0.1868621576577425, Final Batch Loss: 0.036431603133678436\n",
      "Epoch 689, Loss: 0.17567911371588707, Final Batch Loss: 0.05664731562137604\n",
      "Epoch 690, Loss: 0.2042225133627653, Final Batch Loss: 0.014210661873221397\n",
      "Epoch 691, Loss: 0.15016450453549623, Final Batch Loss: 0.03829945996403694\n",
      "Epoch 692, Loss: 0.1819934956729412, Final Batch Loss: 0.033237747848033905\n",
      "Epoch 693, Loss: 0.32224646024405956, Final Batch Loss: 0.1770041584968567\n",
      "Epoch 694, Loss: 0.1603381112217903, Final Batch Loss: 0.03657343611121178\n",
      "Epoch 695, Loss: 0.11221561208367348, Final Batch Loss: 0.026345564052462578\n",
      "Epoch 696, Loss: 0.24245085939764977, Final Batch Loss: 0.08861733227968216\n",
      "Epoch 697, Loss: 0.17901741154491901, Final Batch Loss: 0.040813054889440536\n",
      "Epoch 698, Loss: 0.15565570071339607, Final Batch Loss: 0.03555571287870407\n",
      "Epoch 699, Loss: 0.21050520241260529, Final Batch Loss: 0.04019371047616005\n",
      "Epoch 700, Loss: 0.169468455016613, Final Batch Loss: 0.06630202382802963\n",
      "Epoch 701, Loss: 0.15751789323985577, Final Batch Loss: 0.044202882796525955\n",
      "Epoch 702, Loss: 0.14012902416288853, Final Batch Loss: 0.03357061371207237\n",
      "Epoch 703, Loss: 0.2502492293715477, Final Batch Loss: 0.031349506229162216\n",
      "Epoch 704, Loss: 0.08353347238153219, Final Batch Loss: 0.015649136155843735\n",
      "Epoch 705, Loss: 0.1581560466438532, Final Batch Loss: 0.01885455660521984\n",
      "Epoch 706, Loss: 0.20829443261027336, Final Batch Loss: 0.017329491674900055\n",
      "Epoch 707, Loss: 0.10264744143933058, Final Batch Loss: 0.013648462481796741\n",
      "Epoch 708, Loss: 0.11547257006168365, Final Batch Loss: 0.02826792560517788\n",
      "Epoch 709, Loss: 0.13299859687685966, Final Batch Loss: 0.016352185979485512\n",
      "Epoch 710, Loss: 0.1220138343051076, Final Batch Loss: 0.008003638125956059\n",
      "Epoch 711, Loss: 0.10683984309434891, Final Batch Loss: 0.018282098695635796\n",
      "Epoch 712, Loss: 0.15023495350033045, Final Batch Loss: 0.01413359772413969\n",
      "Epoch 713, Loss: 0.10208025481551886, Final Batch Loss: 0.02319355122745037\n",
      "Epoch 714, Loss: 0.16472112759947777, Final Batch Loss: 0.0651419386267662\n",
      "Epoch 715, Loss: 0.1262957314029336, Final Batch Loss: 0.01250957790762186\n",
      "Epoch 716, Loss: 0.10523548116907477, Final Batch Loss: 0.004523168783634901\n",
      "Epoch 717, Loss: 0.15619794093072414, Final Batch Loss: 0.03510114923119545\n",
      "Epoch 718, Loss: 0.12316294712945819, Final Batch Loss: 0.007611505221575499\n",
      "Epoch 719, Loss: 0.16700264066457748, Final Batch Loss: 0.02498120255768299\n",
      "Epoch 720, Loss: 0.16905357129871845, Final Batch Loss: 0.07931265234947205\n",
      "Epoch 721, Loss: 0.0774396900087595, Final Batch Loss: 0.013266044668853283\n",
      "Epoch 722, Loss: 0.15011365339159966, Final Batch Loss: 0.018910232931375504\n",
      "Epoch 723, Loss: 0.143351836130023, Final Batch Loss: 0.049312833696603775\n",
      "Epoch 724, Loss: 0.15307446056976914, Final Batch Loss: 0.007634263951331377\n",
      "Epoch 725, Loss: 0.1653145458549261, Final Batch Loss: 0.023284057155251503\n",
      "Epoch 726, Loss: 0.14829587657004595, Final Batch Loss: 0.04382605478167534\n",
      "Epoch 727, Loss: 0.15076573938131332, Final Batch Loss: 0.048383671790361404\n",
      "Epoch 728, Loss: 0.1508062742650509, Final Batch Loss: 0.07307317107915878\n",
      "Epoch 729, Loss: 0.18323879316449165, Final Batch Loss: 0.019374333322048187\n",
      "Epoch 730, Loss: 0.1824227925390005, Final Batch Loss: 0.027540670707821846\n",
      "Epoch 731, Loss: 0.07594806142151356, Final Batch Loss: 0.020750747993588448\n",
      "Epoch 732, Loss: 0.1294399332255125, Final Batch Loss: 0.026385365054011345\n",
      "Epoch 733, Loss: 0.14750585705041885, Final Batch Loss: 0.018475469201803207\n",
      "Epoch 734, Loss: 0.12466785963624716, Final Batch Loss: 0.004570595920085907\n",
      "Epoch 735, Loss: 0.20482836849987507, Final Batch Loss: 0.09287352859973907\n",
      "Epoch 736, Loss: 0.23744498752057552, Final Batch Loss: 0.01573057658970356\n",
      "Epoch 737, Loss: 0.142797714099288, Final Batch Loss: 0.017043599858880043\n",
      "Epoch 738, Loss: 0.13238272070884705, Final Batch Loss: 0.01420457661151886\n",
      "Epoch 739, Loss: 0.15037397667765617, Final Batch Loss: 0.02796153724193573\n",
      "Epoch 740, Loss: 0.15546558052301407, Final Batch Loss: 0.04323618859052658\n",
      "Epoch 741, Loss: 0.23113348707556725, Final Batch Loss: 0.03941919654607773\n",
      "Epoch 742, Loss: 0.2551891375333071, Final Batch Loss: 0.060227733105421066\n",
      "Epoch 743, Loss: 0.1731839533895254, Final Batch Loss: 0.03145824000239372\n",
      "Epoch 744, Loss: 0.17026984319090843, Final Batch Loss: 0.02484017238020897\n",
      "Epoch 745, Loss: 0.25322646647691727, Final Batch Loss: 0.034005358815193176\n",
      "Epoch 746, Loss: 0.14780115708708763, Final Batch Loss: 0.04727122187614441\n",
      "Epoch 747, Loss: 0.23002976924180984, Final Batch Loss: 0.0406111404299736\n",
      "Epoch 748, Loss: 0.13450525887310505, Final Batch Loss: 0.06297246366739273\n",
      "Epoch 749, Loss: 0.18194343894720078, Final Batch Loss: 0.02394239790737629\n",
      "Epoch 750, Loss: 0.11382875964045525, Final Batch Loss: 0.06672908365726471\n",
      "Epoch 751, Loss: 0.10252959374338388, Final Batch Loss: 0.045459337532520294\n",
      "Epoch 752, Loss: 0.12703432142734528, Final Batch Loss: 0.020389534533023834\n",
      "Epoch 753, Loss: 0.0934826834127307, Final Batch Loss: 0.007943935692310333\n",
      "Epoch 754, Loss: 0.13732705265283585, Final Batch Loss: 0.03310036659240723\n",
      "Epoch 755, Loss: 0.1475286679342389, Final Batch Loss: 0.012282812036573887\n",
      "Epoch 756, Loss: 0.1532959258183837, Final Batch Loss: 0.013521087355911732\n",
      "Epoch 757, Loss: 0.11273927427828312, Final Batch Loss: 0.03677067533135414\n",
      "Epoch 758, Loss: 0.21513298898935318, Final Batch Loss: 0.031302910298109055\n",
      "Epoch 759, Loss: 0.12764621898531914, Final Batch Loss: 0.034338612109422684\n",
      "Epoch 760, Loss: 0.17289782408624887, Final Batch Loss: 0.10414952784776688\n",
      "Epoch 761, Loss: 0.1268078349530697, Final Batch Loss: 0.029465774074196815\n",
      "Epoch 762, Loss: 0.12469101510941982, Final Batch Loss: 0.019832035526633263\n",
      "Epoch 763, Loss: 0.10698703210800886, Final Batch Loss: 0.008037335239350796\n",
      "Epoch 764, Loss: 0.16624892503023148, Final Batch Loss: 0.03439079225063324\n",
      "Epoch 765, Loss: 0.17695345170795918, Final Batch Loss: 0.05865723267197609\n",
      "Epoch 766, Loss: 0.20224584825336933, Final Batch Loss: 0.074400395154953\n",
      "Epoch 767, Loss: 0.19059130549430847, Final Batch Loss: 0.06808622926473618\n",
      "Epoch 768, Loss: 0.15283735375851393, Final Batch Loss: 0.06587418168783188\n",
      "Epoch 769, Loss: 0.14109781756997108, Final Batch Loss: 0.00886555202305317\n",
      "Epoch 770, Loss: 0.2821326479315758, Final Batch Loss: 0.11278660595417023\n",
      "Epoch 771, Loss: 0.14953719079494476, Final Batch Loss: 0.031836144626140594\n",
      "Epoch 772, Loss: 0.18553226627409458, Final Batch Loss: 0.08692783117294312\n",
      "Epoch 773, Loss: 0.11021512188017368, Final Batch Loss: 0.016858670860528946\n",
      "Epoch 774, Loss: 0.19714096933603287, Final Batch Loss: 0.06977088004350662\n",
      "Epoch 775, Loss: 0.16944046411663294, Final Batch Loss: 0.011351988650858402\n",
      "Epoch 776, Loss: 0.25653746724128723, Final Batch Loss: 0.05788804218173027\n",
      "Epoch 777, Loss: 0.1759647848084569, Final Batch Loss: 0.06467519700527191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778, Loss: 0.18814273178577423, Final Batch Loss: 0.03474828228354454\n",
      "Epoch 779, Loss: 0.23155931755900383, Final Batch Loss: 0.051276177167892456\n",
      "Epoch 780, Loss: 0.23171600326895714, Final Batch Loss: 0.09487241506576538\n",
      "Epoch 781, Loss: 0.266030166298151, Final Batch Loss: 0.05120396986603737\n",
      "Epoch 782, Loss: 0.19296202715486288, Final Batch Loss: 0.013633708469569683\n",
      "Epoch 783, Loss: 0.1607215330004692, Final Batch Loss: 0.017627324908971786\n",
      "Epoch 784, Loss: 0.17673305422067642, Final Batch Loss: 0.051283761858940125\n",
      "Epoch 785, Loss: 0.1580137237906456, Final Batch Loss: 0.025183282792568207\n",
      "Epoch 786, Loss: 0.09668264351785183, Final Batch Loss: 0.02999761514365673\n",
      "Epoch 787, Loss: 0.2045285264030099, Final Batch Loss: 0.013960280455648899\n",
      "Epoch 788, Loss: 0.18994551012292504, Final Batch Loss: 0.006316325161606073\n",
      "Epoch 789, Loss: 0.1563846617937088, Final Batch Loss: 0.034565284848213196\n",
      "Epoch 790, Loss: 0.15948477759957314, Final Batch Loss: 0.049121301621198654\n",
      "Epoch 791, Loss: 0.21748871728777885, Final Batch Loss: 0.058977849781513214\n",
      "Epoch 792, Loss: 0.19267620518803596, Final Batch Loss: 0.05386936664581299\n",
      "Epoch 793, Loss: 0.11741920933127403, Final Batch Loss: 0.016261829063296318\n",
      "Epoch 794, Loss: 0.20809711888432503, Final Batch Loss: 0.0628250390291214\n",
      "Epoch 795, Loss: 0.1755801998078823, Final Batch Loss: 0.015849672257900238\n",
      "Epoch 796, Loss: 0.20849608816206455, Final Batch Loss: 0.08576910197734833\n",
      "Epoch 797, Loss: 0.16621939465403557, Final Batch Loss: 0.05120467767119408\n",
      "Epoch 798, Loss: 0.1381585793569684, Final Batch Loss: 0.0140356021001935\n",
      "Epoch 799, Loss: 0.2567826397716999, Final Batch Loss: 0.048877254128456116\n",
      "Epoch 800, Loss: 0.13622665405273438, Final Batch Loss: 0.04027688875794411\n",
      "Epoch 801, Loss: 0.22867444343864918, Final Batch Loss: 0.11024554818868637\n",
      "Epoch 802, Loss: 0.308434734120965, Final Batch Loss: 0.022875281050801277\n",
      "Epoch 803, Loss: 0.11231785733252764, Final Batch Loss: 0.012280081398785114\n",
      "Epoch 804, Loss: 0.2016722857952118, Final Batch Loss: 0.01756316050887108\n",
      "Epoch 805, Loss: 0.1314641311764717, Final Batch Loss: 0.020646383985877037\n",
      "Epoch 806, Loss: 0.12557872012257576, Final Batch Loss: 0.01843482069671154\n",
      "Epoch 807, Loss: 0.07645141752436757, Final Batch Loss: 0.0042176921851933\n",
      "Epoch 808, Loss: 0.08753082901239395, Final Batch Loss: 0.01765289157629013\n",
      "Epoch 809, Loss: 0.24152959510684013, Final Batch Loss: 0.07213953882455826\n",
      "Epoch 810, Loss: 0.07951792422682047, Final Batch Loss: 0.013372317887842655\n",
      "Epoch 811, Loss: 0.12043840903788805, Final Batch Loss: 0.03153504431247711\n",
      "Epoch 812, Loss: 0.19808994978666306, Final Batch Loss: 0.06073678284883499\n",
      "Epoch 813, Loss: 0.2378840409219265, Final Batch Loss: 0.14476321637630463\n",
      "Epoch 814, Loss: 0.2361229583621025, Final Batch Loss: 0.0870835930109024\n",
      "Epoch 815, Loss: 0.14102825429290533, Final Batch Loss: 0.05054379627108574\n",
      "Epoch 816, Loss: 0.3119019381701946, Final Batch Loss: 0.04010253772139549\n",
      "Epoch 817, Loss: 0.14843236096203327, Final Batch Loss: 0.02136576734483242\n",
      "Epoch 818, Loss: 0.12745736353099346, Final Batch Loss: 0.01799316145479679\n",
      "Epoch 819, Loss: 0.11427420377731323, Final Batch Loss: 0.020410550758242607\n",
      "Epoch 820, Loss: 0.16255393251776695, Final Batch Loss: 0.03633105754852295\n",
      "Epoch 821, Loss: 0.13747439347207546, Final Batch Loss: 0.07074905931949615\n",
      "Epoch 822, Loss: 0.1489058267325163, Final Batch Loss: 0.01620297320187092\n",
      "Epoch 823, Loss: 0.19298351556062698, Final Batch Loss: 0.0560532882809639\n",
      "Epoch 824, Loss: 0.1334343021735549, Final Batch Loss: 0.01052627619355917\n",
      "Epoch 825, Loss: 0.27843476831912994, Final Batch Loss: 0.06576579064130783\n",
      "Epoch 826, Loss: 0.37911684066057205, Final Batch Loss: 0.10495490580797195\n",
      "Epoch 827, Loss: 0.1415720209479332, Final Batch Loss: 0.03490341454744339\n",
      "Epoch 828, Loss: 0.28788376599550247, Final Batch Loss: 0.07306354492902756\n",
      "Epoch 829, Loss: 0.2913665473461151, Final Batch Loss: 0.113200344145298\n",
      "Epoch 830, Loss: 0.3181458869948983, Final Batch Loss: 0.044902361929416656\n",
      "Epoch 831, Loss: 0.3274340033531189, Final Batch Loss: 0.138976588845253\n",
      "Epoch 832, Loss: 0.2761462703347206, Final Batch Loss: 0.040471151471138\n",
      "Epoch 833, Loss: 0.21518672816455364, Final Batch Loss: 0.04218577966094017\n",
      "Epoch 834, Loss: 0.19194399006664753, Final Batch Loss: 0.06822340935468674\n",
      "Epoch 835, Loss: 0.25857457518577576, Final Batch Loss: 0.046093035489320755\n",
      "Epoch 836, Loss: 0.18732681684195995, Final Batch Loss: 0.02869860641658306\n",
      "Epoch 837, Loss: 0.1769654955714941, Final Batch Loss: 0.05876828730106354\n",
      "Epoch 838, Loss: 0.17402579076588154, Final Batch Loss: 0.027494365349411964\n",
      "Epoch 839, Loss: 0.2180018313229084, Final Batch Loss: 0.08108467608690262\n",
      "Epoch 840, Loss: 0.216343455016613, Final Batch Loss: 0.09577975422143936\n",
      "Epoch 841, Loss: 0.29753927513957024, Final Batch Loss: 0.1365700662136078\n",
      "Epoch 842, Loss: 0.23039273917675018, Final Batch Loss: 0.0818062424659729\n",
      "Epoch 843, Loss: 0.10318700410425663, Final Batch Loss: 0.019259942695498466\n",
      "Epoch 844, Loss: 0.12914378754794598, Final Batch Loss: 0.02446763776242733\n",
      "Epoch 845, Loss: 0.25021064281463623, Final Batch Loss: 0.04566578194499016\n",
      "Epoch 846, Loss: 0.1277278121560812, Final Batch Loss: 0.00913422740995884\n",
      "Epoch 847, Loss: 0.08703907020390034, Final Batch Loss: 0.010063622146844864\n",
      "Epoch 848, Loss: 0.08980399928987026, Final Batch Loss: 0.010018613189458847\n",
      "Epoch 849, Loss: 0.14608574472367764, Final Batch Loss: 0.019102316349744797\n",
      "Epoch 850, Loss: 0.07986186817288399, Final Batch Loss: 0.021304357796907425\n",
      "Epoch 851, Loss: 0.08007826143875718, Final Batch Loss: 0.007571070920675993\n",
      "Epoch 852, Loss: 0.20443061087280512, Final Batch Loss: 0.13313479721546173\n",
      "Epoch 853, Loss: 0.08196738921105862, Final Batch Loss: 0.013750365935266018\n",
      "Epoch 854, Loss: 0.08886381797492504, Final Batch Loss: 0.022279946133494377\n",
      "Epoch 855, Loss: 0.09933301387354732, Final Batch Loss: 0.007464741822332144\n",
      "Epoch 856, Loss: 0.1422829208895564, Final Batch Loss: 0.07005064189434052\n",
      "Epoch 857, Loss: 0.13415599428117275, Final Batch Loss: 0.04999605193734169\n",
      "Epoch 858, Loss: 0.16042965091764927, Final Batch Loss: 0.011760061606764793\n",
      "Epoch 859, Loss: 0.2287166453897953, Final Batch Loss: 0.06621509045362473\n",
      "Epoch 860, Loss: 0.18543662503361702, Final Batch Loss: 0.023416392505168915\n",
      "Epoch 861, Loss: 0.23256314173340797, Final Batch Loss: 0.01802162453532219\n",
      "Epoch 862, Loss: 0.12231161445379257, Final Batch Loss: 0.04568253085017204\n",
      "Epoch 863, Loss: 0.16985568217933178, Final Batch Loss: 0.0479167103767395\n",
      "Epoch 864, Loss: 0.32519821636378765, Final Batch Loss: 0.21414095163345337\n",
      "Epoch 865, Loss: 0.11975483782589436, Final Batch Loss: 0.030593492090702057\n",
      "Epoch 866, Loss: 0.18598823808133602, Final Batch Loss: 0.07326367497444153\n",
      "Epoch 867, Loss: 0.19865274243056774, Final Batch Loss: 0.09849810600280762\n",
      "Epoch 868, Loss: 0.21315563563257456, Final Batch Loss: 0.09947426617145538\n",
      "Epoch 869, Loss: 0.13064553774893284, Final Batch Loss: 0.04905524477362633\n",
      "Epoch 870, Loss: 0.10579985659569502, Final Batch Loss: 0.02563697099685669\n",
      "Epoch 871, Loss: 0.10213559120893478, Final Batch Loss: 0.017597297206521034\n",
      "Epoch 872, Loss: 0.16181095410138369, Final Batch Loss: 0.020313989371061325\n",
      "Epoch 873, Loss: 0.19932704139500856, Final Batch Loss: 0.1301661878824234\n",
      "Epoch 874, Loss: 0.10795894265174866, Final Batch Loss: 0.013662751764059067\n",
      "Epoch 875, Loss: 0.10255027376115322, Final Batch Loss: 0.016218295320868492\n",
      "Epoch 876, Loss: 0.12994933500885963, Final Batch Loss: 0.040467824786901474\n",
      "Epoch 877, Loss: 0.09980990644544363, Final Batch Loss: 0.01186384353786707\n",
      "Epoch 878, Loss: 0.07516325265169144, Final Batch Loss: 0.018581371754407883\n",
      "Epoch 879, Loss: 0.1882613655179739, Final Batch Loss: 0.10312525928020477\n",
      "Epoch 880, Loss: 0.12014783546328545, Final Batch Loss: 0.03168193995952606\n",
      "Epoch 881, Loss: 0.09554901719093323, Final Batch Loss: 0.020179342478513718\n",
      "Epoch 882, Loss: 0.07388274557888508, Final Batch Loss: 0.022543586790561676\n",
      "Epoch 883, Loss: 0.09141643531620502, Final Batch Loss: 0.01600644178688526\n",
      "Epoch 884, Loss: 0.10300526581704617, Final Batch Loss: 0.0407593660056591\n",
      "Epoch 885, Loss: 0.09583536069840193, Final Batch Loss: 0.026213090866804123\n",
      "Epoch 886, Loss: 0.0657842755317688, Final Batch Loss: 0.011115715838968754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887, Loss: 0.10645555518567562, Final Batch Loss: 0.026474379003047943\n",
      "Epoch 888, Loss: 0.07925787754356861, Final Batch Loss: 0.003107178956270218\n",
      "Epoch 889, Loss: 0.06765549071133137, Final Batch Loss: 0.013262222521007061\n",
      "Epoch 890, Loss: 0.12753856368362904, Final Batch Loss: 0.04932354763150215\n",
      "Epoch 891, Loss: 0.09150607418268919, Final Batch Loss: 0.02782290242612362\n",
      "Epoch 892, Loss: 0.1264951047487557, Final Batch Loss: 0.050947561860084534\n",
      "Epoch 893, Loss: 0.19315765239298344, Final Batch Loss: 0.0772152915596962\n",
      "Epoch 894, Loss: 0.12937054736539721, Final Batch Loss: 0.0064909025095403194\n",
      "Epoch 895, Loss: 0.07669321075081825, Final Batch Loss: 0.011705364100635052\n",
      "Epoch 896, Loss: 0.14389236457645893, Final Batch Loss: 0.04100529104471207\n",
      "Epoch 897, Loss: 0.10623422637581825, Final Batch Loss: 0.025749916210770607\n",
      "Epoch 898, Loss: 0.13557742722332478, Final Batch Loss: 0.02420593611896038\n",
      "Epoch 899, Loss: 0.10992431640625, Final Batch Loss: 0.01800054870545864\n",
      "Epoch 900, Loss: 0.09968635998666286, Final Batch Loss: 0.02106664516031742\n",
      "Epoch 901, Loss: 0.1168210506439209, Final Batch Loss: 0.01608317904174328\n",
      "Epoch 902, Loss: 0.10172751732170582, Final Batch Loss: 0.018302280455827713\n",
      "Epoch 903, Loss: 0.13425131049007177, Final Batch Loss: 0.057528767734766006\n",
      "Epoch 904, Loss: 0.1424432024359703, Final Batch Loss: 0.023274516686797142\n",
      "Epoch 905, Loss: 0.12057646550238132, Final Batch Loss: 0.018468275666236877\n",
      "Epoch 906, Loss: 0.11598539259284735, Final Batch Loss: 0.006652132607996464\n",
      "Epoch 907, Loss: 0.09408230194821954, Final Batch Loss: 0.004473470617085695\n",
      "Epoch 908, Loss: 0.11169841326773167, Final Batch Loss: 0.03301284462213516\n",
      "Epoch 909, Loss: 0.07485041860491037, Final Batch Loss: 0.01121221762150526\n",
      "Epoch 910, Loss: 0.10783984512090683, Final Batch Loss: 0.012726947665214539\n",
      "Epoch 911, Loss: 0.07434061542153358, Final Batch Loss: 0.021565385162830353\n",
      "Epoch 912, Loss: 0.10923663433641195, Final Batch Loss: 0.02776486985385418\n",
      "Epoch 913, Loss: 0.09295886568725109, Final Batch Loss: 0.009164023213088512\n",
      "Epoch 914, Loss: 0.06104564433917403, Final Batch Loss: 0.010399161837995052\n",
      "Epoch 915, Loss: 0.08719974686391652, Final Batch Loss: 0.002529584104195237\n",
      "Epoch 916, Loss: 0.07745230011641979, Final Batch Loss: 0.02497604303061962\n",
      "Epoch 917, Loss: 0.08493857830762863, Final Batch Loss: 0.04499097913503647\n",
      "Epoch 918, Loss: 0.1171758584678173, Final Batch Loss: 0.013277560472488403\n",
      "Epoch 919, Loss: 0.11376852728426456, Final Batch Loss: 0.04411919414997101\n",
      "Epoch 920, Loss: 0.07840206194669008, Final Batch Loss: 0.009995290078222752\n",
      "Epoch 921, Loss: 0.10320524126291275, Final Batch Loss: 0.013484357856214046\n",
      "Epoch 922, Loss: 0.10214684344828129, Final Batch Loss: 0.05394439771771431\n",
      "Epoch 923, Loss: 0.1113862432539463, Final Batch Loss: 0.006658600643277168\n",
      "Epoch 924, Loss: 0.06506084185093641, Final Batch Loss: 0.01730586774647236\n",
      "Epoch 925, Loss: 0.0948299989104271, Final Batch Loss: 0.0175043772906065\n",
      "Epoch 926, Loss: 0.09768631961196661, Final Batch Loss: 0.021137157455086708\n",
      "Epoch 927, Loss: 0.11100178095512092, Final Batch Loss: 0.002976038260385394\n",
      "Epoch 928, Loss: 0.1248328210785985, Final Batch Loss: 0.012836524285376072\n",
      "Epoch 929, Loss: 0.16933128982782364, Final Batch Loss: 0.04077913612127304\n",
      "Epoch 930, Loss: 0.1299869455397129, Final Batch Loss: 0.021220173686742783\n",
      "Epoch 931, Loss: 0.10490705817937851, Final Batch Loss: 0.00779759231954813\n",
      "Epoch 932, Loss: 0.10714850574731827, Final Batch Loss: 0.019755970686674118\n",
      "Epoch 933, Loss: 0.07414475176483393, Final Batch Loss: 0.01743188500404358\n",
      "Epoch 934, Loss: 0.080059610074386, Final Batch Loss: 0.0019642000552266836\n",
      "Epoch 935, Loss: 0.078951062168926, Final Batch Loss: 0.0071763391606509686\n",
      "Epoch 936, Loss: 0.14925110712647438, Final Batch Loss: 0.005578700453042984\n",
      "Epoch 937, Loss: 0.1429104320704937, Final Batch Loss: 0.007325185462832451\n",
      "Epoch 938, Loss: 0.0828594621270895, Final Batch Loss: 0.012874702922999859\n",
      "Epoch 939, Loss: 0.085027982480824, Final Batch Loss: 0.007884260267019272\n",
      "Epoch 940, Loss: 0.06107791140675545, Final Batch Loss: 0.013713350519537926\n",
      "Epoch 941, Loss: 0.10980599652975798, Final Batch Loss: 0.015238354913890362\n",
      "Epoch 942, Loss: 0.12585348123684525, Final Batch Loss: 0.07505753636360168\n",
      "Epoch 943, Loss: 0.10415017185732722, Final Batch Loss: 0.0032599843107163906\n",
      "Epoch 944, Loss: 0.14470970630645752, Final Batch Loss: 0.018764600157737732\n",
      "Epoch 945, Loss: 0.10180701687932014, Final Batch Loss: 0.013042118400335312\n",
      "Epoch 946, Loss: 0.11322231218218803, Final Batch Loss: 0.019550664350390434\n",
      "Epoch 947, Loss: 0.10923825949430466, Final Batch Loss: 0.005698559805750847\n",
      "Epoch 948, Loss: 0.13347182422876358, Final Batch Loss: 0.006161009892821312\n",
      "Epoch 949, Loss: 0.14570403844118118, Final Batch Loss: 0.00877341628074646\n",
      "Epoch 950, Loss: 0.1956544853746891, Final Batch Loss: 0.04571690410375595\n",
      "Epoch 951, Loss: 0.14193832781165838, Final Batch Loss: 0.008559084497392178\n",
      "Epoch 952, Loss: 0.10564149916172028, Final Batch Loss: 0.031226791441440582\n",
      "Epoch 953, Loss: 0.15254002530127764, Final Batch Loss: 0.013131345622241497\n",
      "Epoch 954, Loss: 0.170768516138196, Final Batch Loss: 0.07490649074316025\n",
      "Epoch 955, Loss: 0.14467963948845863, Final Batch Loss: 0.025135938078165054\n",
      "Epoch 956, Loss: 0.25341871753335, Final Batch Loss: 0.08526209741830826\n",
      "Epoch 957, Loss: 0.13609537295997143, Final Batch Loss: 0.06365810334682465\n",
      "Epoch 958, Loss: 0.14445247408002615, Final Batch Loss: 0.011074350215494633\n",
      "Epoch 959, Loss: 0.26937356777489185, Final Batch Loss: 0.022764572873711586\n",
      "Epoch 960, Loss: 0.1945010032504797, Final Batch Loss: 0.0452200248837471\n",
      "Epoch 961, Loss: 0.1407438525930047, Final Batch Loss: 0.031253255903720856\n",
      "Epoch 962, Loss: 0.227105975151062, Final Batch Loss: 0.09556206315755844\n",
      "Epoch 963, Loss: 0.14883411303162575, Final Batch Loss: 0.040361665189266205\n",
      "Epoch 964, Loss: 0.09940108377486467, Final Batch Loss: 0.013268495909869671\n",
      "Epoch 965, Loss: 0.0738765171263367, Final Batch Loss: 0.0038568947929888964\n",
      "Epoch 966, Loss: 0.09041283745318651, Final Batch Loss: 0.01068479660898447\n",
      "Epoch 967, Loss: 0.13041019439697266, Final Batch Loss: 0.007861930876970291\n",
      "Epoch 968, Loss: 0.13582549523562193, Final Batch Loss: 0.035583484917879105\n",
      "Epoch 969, Loss: 0.05932119907811284, Final Batch Loss: 0.0023432555608451366\n",
      "Epoch 970, Loss: 0.14411996491253376, Final Batch Loss: 0.03552040830254555\n",
      "Epoch 971, Loss: 0.1794736534357071, Final Batch Loss: 0.028681514784693718\n",
      "Epoch 972, Loss: 0.12924912758171558, Final Batch Loss: 0.015574593096971512\n",
      "Epoch 973, Loss: 0.08020068425685167, Final Batch Loss: 0.013232117518782616\n",
      "Epoch 974, Loss: 0.16555350832641125, Final Batch Loss: 0.020537463948130608\n",
      "Epoch 975, Loss: 0.14791684737429023, Final Batch Loss: 0.007189800497144461\n",
      "Epoch 976, Loss: 0.11250520776957273, Final Batch Loss: 0.007534679491072893\n",
      "Epoch 977, Loss: 0.19867143779993057, Final Batch Loss: 0.07637988030910492\n",
      "Epoch 978, Loss: 0.06882270332425833, Final Batch Loss: 0.019766980782151222\n",
      "Epoch 979, Loss: 0.2308668438345194, Final Batch Loss: 0.0664176344871521\n",
      "Epoch 980, Loss: 0.24773150123655796, Final Batch Loss: 0.025383921340107918\n",
      "Epoch 981, Loss: 0.29362671030685306, Final Batch Loss: 0.1780715137720108\n",
      "Epoch 982, Loss: 0.27034494280815125, Final Batch Loss: 0.07726427167654037\n",
      "Epoch 983, Loss: 0.14925170876085758, Final Batch Loss: 0.030638834461569786\n",
      "Epoch 984, Loss: 0.10733510553836823, Final Batch Loss: 0.019517023116350174\n",
      "Epoch 985, Loss: 0.1312998030334711, Final Batch Loss: 0.027185941115021706\n",
      "Epoch 986, Loss: 0.07894690427929163, Final Batch Loss: 0.037863198667764664\n",
      "Epoch 987, Loss: 0.1475021131336689, Final Batch Loss: 0.04872516915202141\n",
      "Epoch 988, Loss: 0.11778907291591167, Final Batch Loss: 0.026128383353352547\n",
      "Epoch 989, Loss: 0.09880683850497007, Final Batch Loss: 0.01290727686136961\n",
      "Epoch 990, Loss: 0.15786032937467098, Final Batch Loss: 0.02829645201563835\n",
      "Epoch 991, Loss: 0.15803861618041992, Final Batch Loss: 0.022126946598291397\n",
      "Epoch 992, Loss: 0.12363037932664156, Final Batch Loss: 0.0303440410643816\n",
      "Epoch 993, Loss: 0.147564516402781, Final Batch Loss: 0.0504860021173954\n",
      "Epoch 994, Loss: 0.21685143932700157, Final Batch Loss: 0.12018490582704544\n",
      "Epoch 995, Loss: 0.27127792686223984, Final Batch Loss: 0.062066543847322464\n",
      "Epoch 996, Loss: 0.25035904720425606, Final Batch Loss: 0.029368076473474503\n",
      "Epoch 997, Loss: 0.14065585657954216, Final Batch Loss: 0.054523613303899765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 998, Loss: 0.20137494802474976, Final Batch Loss: 0.07812511175870895\n",
      "Epoch 999, Loss: 0.26654141768813133, Final Batch Loss: 0.06867178529500961\n",
      "Epoch 1000, Loss: 0.1069447360932827, Final Batch Loss: 0.04029146209359169\n",
      "Epoch 1001, Loss: 0.2048564413562417, Final Batch Loss: 0.09561695903539658\n",
      "Epoch 1002, Loss: 0.11920733377337456, Final Batch Loss: 0.009062642231583595\n",
      "Epoch 1003, Loss: 0.17542981915175915, Final Batch Loss: 0.0197463221848011\n",
      "Epoch 1004, Loss: 0.12584171071648598, Final Batch Loss: 0.007359113544225693\n",
      "Epoch 1005, Loss: 0.10601470991969109, Final Batch Loss: 0.019045181572437286\n",
      "Epoch 1006, Loss: 0.26814647018909454, Final Batch Loss: 0.06381525099277496\n",
      "Epoch 1007, Loss: 0.11743125692009926, Final Batch Loss: 0.028306202962994576\n",
      "Epoch 1008, Loss: 0.19965986721217632, Final Batch Loss: 0.06156009063124657\n",
      "Epoch 1009, Loss: 0.33822769299149513, Final Batch Loss: 0.17785443365573883\n",
      "Epoch 1010, Loss: 0.11092662811279297, Final Batch Loss: 0.02938932180404663\n",
      "Epoch 1011, Loss: 0.19251490756869316, Final Batch Loss: 0.039894092828035355\n",
      "Epoch 1012, Loss: 0.11853164900094271, Final Batch Loss: 0.012681866995990276\n",
      "Epoch 1013, Loss: 0.2554379887878895, Final Batch Loss: 0.032296959310770035\n",
      "Epoch 1014, Loss: 0.1867560688406229, Final Batch Loss: 0.012786000967025757\n",
      "Epoch 1015, Loss: 0.20826683193445206, Final Batch Loss: 0.07493520528078079\n",
      "Epoch 1016, Loss: 0.13226857222616673, Final Batch Loss: 0.024118205532431602\n",
      "Epoch 1017, Loss: 0.08938133344054222, Final Batch Loss: 0.01903911866247654\n",
      "Epoch 1018, Loss: 0.0870058499276638, Final Batch Loss: 0.005595365539193153\n",
      "Epoch 1019, Loss: 0.14243878843262792, Final Batch Loss: 0.003422871697694063\n",
      "Epoch 1020, Loss: 0.12162499502301216, Final Batch Loss: 0.03816206753253937\n",
      "Epoch 1021, Loss: 0.0916085597127676, Final Batch Loss: 0.022786753252148628\n",
      "Epoch 1022, Loss: 0.0775544997304678, Final Batch Loss: 0.022035876289010048\n",
      "Epoch 1023, Loss: 0.2699226811528206, Final Batch Loss: 0.017721548676490784\n",
      "Epoch 1024, Loss: 0.15429296996444464, Final Batch Loss: 0.03862208500504494\n",
      "Epoch 1025, Loss: 0.10119750164449215, Final Batch Loss: 0.03106614202260971\n",
      "Epoch 1026, Loss: 0.08926912909373641, Final Batch Loss: 0.025331927463412285\n",
      "Epoch 1027, Loss: 0.11026980169117451, Final Batch Loss: 0.014041807502508163\n",
      "Epoch 1028, Loss: 0.16105212457478046, Final Batch Loss: 0.05925679951906204\n",
      "Epoch 1029, Loss: 0.120155343785882, Final Batch Loss: 0.017059627920389175\n",
      "Epoch 1030, Loss: 0.07401093142107129, Final Batch Loss: 0.006027268711477518\n",
      "Epoch 1031, Loss: 0.12136174482293427, Final Batch Loss: 0.00246666488237679\n",
      "Epoch 1032, Loss: 0.10064172651618719, Final Batch Loss: 0.022214949131011963\n",
      "Epoch 1033, Loss: 0.09588774666190147, Final Batch Loss: 0.02609088085591793\n",
      "Epoch 1034, Loss: 0.10567621700465679, Final Batch Loss: 0.04120726138353348\n",
      "Epoch 1035, Loss: 0.13202063459903002, Final Batch Loss: 0.043618567287921906\n",
      "Epoch 1036, Loss: 0.14551744144409895, Final Batch Loss: 0.005279364995658398\n",
      "Epoch 1037, Loss: 0.09241997264325619, Final Batch Loss: 0.03256445750594139\n",
      "Epoch 1038, Loss: 0.14293819479644299, Final Batch Loss: 0.05956879258155823\n",
      "Epoch 1039, Loss: 0.07120594731532037, Final Batch Loss: 0.00356708443723619\n",
      "Epoch 1040, Loss: 0.16981280408799648, Final Batch Loss: 0.008391084149479866\n",
      "Epoch 1041, Loss: 0.18022701144218445, Final Batch Loss: 0.05974198505282402\n",
      "Epoch 1042, Loss: 0.1908143348991871, Final Batch Loss: 0.05935627594590187\n",
      "Epoch 1043, Loss: 0.056310066021978855, Final Batch Loss: 0.015409711748361588\n",
      "Epoch 1044, Loss: 0.13283648248761892, Final Batch Loss: 0.05353064090013504\n",
      "Epoch 1045, Loss: 0.20291280932724476, Final Batch Loss: 0.07352203130722046\n",
      "Epoch 1046, Loss: 0.07927708933129907, Final Batch Loss: 0.004116013180464506\n",
      "Epoch 1047, Loss: 0.09623732045292854, Final Batch Loss: 0.006558751687407494\n",
      "Epoch 1048, Loss: 0.10596572048962116, Final Batch Loss: 0.03405432775616646\n",
      "Epoch 1049, Loss: 0.12603656947612762, Final Batch Loss: 0.04930566996335983\n",
      "Epoch 1050, Loss: 0.11423330241814256, Final Batch Loss: 0.007219277787953615\n",
      "Epoch 1051, Loss: 0.10666500497609377, Final Batch Loss: 0.008089878596365452\n",
      "Epoch 1052, Loss: 0.12693111319094896, Final Batch Loss: 0.015314175747334957\n",
      "Epoch 1053, Loss: 0.18682640232145786, Final Batch Loss: 0.08732070028781891\n",
      "Epoch 1054, Loss: 0.07917744480073452, Final Batch Loss: 0.03177652135491371\n",
      "Epoch 1055, Loss: 0.09543514810502529, Final Batch Loss: 0.004975087940692902\n",
      "Epoch 1056, Loss: 0.15249843569472432, Final Batch Loss: 0.07789116352796555\n",
      "Epoch 1057, Loss: 0.15457596257328987, Final Batch Loss: 0.04610080644488335\n",
      "Epoch 1058, Loss: 0.10068363323807716, Final Batch Loss: 0.008859988301992416\n",
      "Epoch 1059, Loss: 0.11210601218044758, Final Batch Loss: 0.012496108189225197\n",
      "Epoch 1060, Loss: 0.1520530004054308, Final Batch Loss: 0.04361490532755852\n",
      "Epoch 1061, Loss: 0.10718978010118008, Final Batch Loss: 0.039608146995306015\n",
      "Epoch 1062, Loss: 0.105402912478894, Final Batch Loss: 0.007415832486003637\n",
      "Epoch 1063, Loss: 0.19757117703557014, Final Batch Loss: 0.02437608316540718\n",
      "Epoch 1064, Loss: 0.2500681132078171, Final Batch Loss: 0.0753999575972557\n",
      "Epoch 1065, Loss: 0.10489706695079803, Final Batch Loss: 0.0027312496677041054\n",
      "Epoch 1066, Loss: 0.1531436275690794, Final Batch Loss: 0.02276694029569626\n",
      "Epoch 1067, Loss: 0.08934980724006891, Final Batch Loss: 0.008393361233174801\n",
      "Epoch 1068, Loss: 0.16144936345517635, Final Batch Loss: 0.05312895029783249\n",
      "Epoch 1069, Loss: 0.14492261223495007, Final Batch Loss: 0.030730685219168663\n",
      "Epoch 1070, Loss: 0.17723391205072403, Final Batch Loss: 0.012784251943230629\n",
      "Epoch 1071, Loss: 0.11307290382683277, Final Batch Loss: 0.03723802790045738\n",
      "Epoch 1072, Loss: 0.17451626434922218, Final Batch Loss: 0.045012813061475754\n",
      "Epoch 1073, Loss: 0.08848876785486937, Final Batch Loss: 0.012422937899827957\n",
      "Epoch 1074, Loss: 0.10120121482759714, Final Batch Loss: 0.028508545830845833\n",
      "Epoch 1075, Loss: 0.09648812189698219, Final Batch Loss: 0.015235718339681625\n",
      "Epoch 1076, Loss: 0.12056979164481163, Final Batch Loss: 0.08124113827943802\n",
      "Epoch 1077, Loss: 0.05312572792172432, Final Batch Loss: 0.008781741373240948\n",
      "Epoch 1078, Loss: 0.0640320279635489, Final Batch Loss: 0.005976885091513395\n",
      "Epoch 1079, Loss: 0.0990802701562643, Final Batch Loss: 0.051082149147987366\n",
      "Epoch 1080, Loss: 0.08883481100201607, Final Batch Loss: 0.016675934195518494\n",
      "Epoch 1081, Loss: 0.1017420869320631, Final Batch Loss: 0.01265384629368782\n",
      "Epoch 1082, Loss: 0.04901659581810236, Final Batch Loss: 0.011187289841473103\n",
      "Epoch 1083, Loss: 0.11852568853646517, Final Batch Loss: 0.008201728574931622\n",
      "Epoch 1084, Loss: 0.14756348729133606, Final Batch Loss: 0.022280195727944374\n",
      "Epoch 1085, Loss: 0.08020068751648068, Final Batch Loss: 0.0029050870798528194\n",
      "Epoch 1086, Loss: 0.10481269657611847, Final Batch Loss: 0.016530733555555344\n",
      "Epoch 1087, Loss: 0.11188368685543537, Final Batch Loss: 0.04982450604438782\n",
      "Epoch 1088, Loss: 0.10436444357037544, Final Batch Loss: 0.01153452880680561\n",
      "Epoch 1089, Loss: 0.08871969068422914, Final Batch Loss: 0.007024221587926149\n",
      "Epoch 1090, Loss: 0.10180984996259212, Final Batch Loss: 0.021133823320269585\n",
      "Epoch 1091, Loss: 0.09534321259707212, Final Batch Loss: 0.018702702596783638\n",
      "Epoch 1092, Loss: 0.1920788735151291, Final Batch Loss: 0.06426635384559631\n",
      "Epoch 1093, Loss: 0.11026497441343963, Final Batch Loss: 0.0034139405470341444\n",
      "Epoch 1094, Loss: 0.1217985674738884, Final Batch Loss: 0.0683894157409668\n",
      "Epoch 1095, Loss: 0.1467373501509428, Final Batch Loss: 0.10007461905479431\n",
      "Epoch 1096, Loss: 0.094205841422081, Final Batch Loss: 0.00826677680015564\n",
      "Epoch 1097, Loss: 0.0852492768317461, Final Batch Loss: 0.016667084768414497\n",
      "Epoch 1098, Loss: 0.0578503692522645, Final Batch Loss: 0.013616301119327545\n",
      "Epoch 1099, Loss: 0.08601379115134478, Final Batch Loss: 0.008562185801565647\n",
      "Epoch 1100, Loss: 0.09402722958475351, Final Batch Loss: 0.00784489419311285\n",
      "Epoch 1101, Loss: 0.11967256758362055, Final Batch Loss: 0.04388602450489998\n",
      "Epoch 1102, Loss: 0.09437752794474363, Final Batch Loss: 0.013163881376385689\n",
      "Epoch 1103, Loss: 0.09712314885109663, Final Batch Loss: 0.0170847587287426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1104, Loss: 0.1368098547682166, Final Batch Loss: 0.06051747500896454\n",
      "Epoch 1105, Loss: 0.05617936793714762, Final Batch Loss: 0.010669592767953873\n",
      "Epoch 1106, Loss: 0.10918852686882019, Final Batch Loss: 0.02403697557747364\n",
      "Epoch 1107, Loss: 0.14366190694272518, Final Batch Loss: 0.05059920996427536\n",
      "Epoch 1108, Loss: 0.0993877830915153, Final Batch Loss: 0.01997814141213894\n",
      "Epoch 1109, Loss: 0.08885083347558975, Final Batch Loss: 0.0022506294772028923\n",
      "Epoch 1110, Loss: 0.12002161704003811, Final Batch Loss: 0.012168182991445065\n",
      "Epoch 1111, Loss: 0.09209039434790611, Final Batch Loss: 0.015512540005147457\n",
      "Epoch 1112, Loss: 0.16881479136645794, Final Batch Loss: 0.05219925940036774\n",
      "Epoch 1113, Loss: 0.12768575176596642, Final Batch Loss: 0.05601150542497635\n",
      "Epoch 1114, Loss: 0.16189917735755444, Final Batch Loss: 0.027136946097016335\n",
      "Epoch 1115, Loss: 0.09306868445128202, Final Batch Loss: 0.03021300956606865\n",
      "Epoch 1116, Loss: 0.20964791253209114, Final Batch Loss: 0.03375016152858734\n",
      "Epoch 1117, Loss: 0.10083168372511864, Final Batch Loss: 0.008995833806693554\n",
      "Epoch 1118, Loss: 0.12746207974851131, Final Batch Loss: 0.019577037543058395\n",
      "Epoch 1119, Loss: 0.08124415343627334, Final Batch Loss: 0.006638723891228437\n",
      "Epoch 1120, Loss: 0.11377639137208462, Final Batch Loss: 0.03282599896192551\n",
      "Epoch 1121, Loss: 0.09722647070884705, Final Batch Loss: 0.0188919510692358\n",
      "Epoch 1122, Loss: 0.10813484061509371, Final Batch Loss: 0.011096312664449215\n",
      "Epoch 1123, Loss: 0.08181773498654366, Final Batch Loss: 0.010395161807537079\n",
      "Epoch 1124, Loss: 0.09190505649894476, Final Batch Loss: 0.0015478283166885376\n",
      "Epoch 1125, Loss: 0.0715619046241045, Final Batch Loss: 0.018471578136086464\n",
      "Epoch 1126, Loss: 0.134011241607368, Final Batch Loss: 0.07684367895126343\n",
      "Epoch 1127, Loss: 0.10559205757454038, Final Batch Loss: 0.04361607879400253\n",
      "Epoch 1128, Loss: 0.09840480401180685, Final Batch Loss: 0.0018900258000940084\n",
      "Epoch 1129, Loss: 0.18594746803864837, Final Batch Loss: 0.007806963752955198\n",
      "Epoch 1130, Loss: 0.07909963931888342, Final Batch Loss: 0.01912226714193821\n",
      "Epoch 1131, Loss: 0.15042981877923012, Final Batch Loss: 0.05897516384720802\n",
      "Epoch 1132, Loss: 0.17261188011616468, Final Batch Loss: 0.057359036058187485\n",
      "Epoch 1133, Loss: 0.1317803612910211, Final Batch Loss: 0.0073966351337730885\n",
      "Epoch 1134, Loss: 0.09643175639212132, Final Batch Loss: 0.018562590703368187\n",
      "Epoch 1135, Loss: 0.10396541375666857, Final Batch Loss: 0.030007485300302505\n",
      "Epoch 1136, Loss: 0.15814192593097687, Final Batch Loss: 0.06450773030519485\n",
      "Epoch 1137, Loss: 0.08290220331400633, Final Batch Loss: 0.03666042909026146\n",
      "Epoch 1138, Loss: 0.0602602856233716, Final Batch Loss: 0.02007865719497204\n",
      "Epoch 1139, Loss: 0.1756710633635521, Final Batch Loss: 0.07283481955528259\n",
      "Epoch 1140, Loss: 0.09590581711381674, Final Batch Loss: 0.024063576012849808\n",
      "Epoch 1141, Loss: 0.14737166743725538, Final Batch Loss: 0.06757837533950806\n",
      "Epoch 1142, Loss: 0.050618814304471016, Final Batch Loss: 0.005831415299326181\n",
      "Epoch 1143, Loss: 0.11204157210886478, Final Batch Loss: 0.031817540526390076\n",
      "Epoch 1144, Loss: 0.18035051226615906, Final Batch Loss: 0.06737302243709564\n",
      "Epoch 1145, Loss: 0.059378030709922314, Final Batch Loss: 0.008791330270469189\n",
      "Epoch 1146, Loss: 0.20061247423291206, Final Batch Loss: 0.027389205992221832\n",
      "Epoch 1147, Loss: 0.06585617340169847, Final Batch Loss: 0.0031471604015678167\n",
      "Epoch 1148, Loss: 0.15556303597986698, Final Batch Loss: 0.038171540945768356\n",
      "Epoch 1149, Loss: 0.053982752142474055, Final Batch Loss: 0.0010927270632237196\n",
      "Epoch 1150, Loss: 0.11884439177811146, Final Batch Loss: 0.028965214267373085\n",
      "Epoch 1151, Loss: 0.08757004421204329, Final Batch Loss: 0.02587675303220749\n",
      "Epoch 1152, Loss: 0.12782426364719868, Final Batch Loss: 0.07684389501810074\n",
      "Epoch 1153, Loss: 0.039236098527908325, Final Batch Loss: 0.002805817872285843\n",
      "Epoch 1154, Loss: 0.21093586832284927, Final Batch Loss: 0.08248409628868103\n",
      "Epoch 1155, Loss: 0.05657844338566065, Final Batch Loss: 0.004265887662768364\n",
      "Epoch 1156, Loss: 0.11914186179637909, Final Batch Loss: 0.05073364078998566\n",
      "Epoch 1157, Loss: 0.05945962434634566, Final Batch Loss: 0.03426770120859146\n",
      "Epoch 1158, Loss: 0.09783859364688396, Final Batch Loss: 0.03704152628779411\n",
      "Epoch 1159, Loss: 0.10065001994371414, Final Batch Loss: 0.027010435238480568\n",
      "Epoch 1160, Loss: 0.1605637650936842, Final Batch Loss: 0.09909527003765106\n",
      "Epoch 1161, Loss: 0.11743604950606823, Final Batch Loss: 0.01171850599348545\n",
      "Epoch 1162, Loss: 0.2817890867590904, Final Batch Loss: 0.08900078386068344\n",
      "Epoch 1163, Loss: 0.1298459731042385, Final Batch Loss: 0.019602347165346146\n",
      "Epoch 1164, Loss: 0.20500478148460388, Final Batch Loss: 0.08349618315696716\n",
      "Epoch 1165, Loss: 0.1603623852133751, Final Batch Loss: 0.012154679745435715\n",
      "Epoch 1166, Loss: 0.2615225864574313, Final Batch Loss: 0.014940905384719372\n",
      "Epoch 1167, Loss: 0.15151166543364525, Final Batch Loss: 0.009839026257395744\n",
      "Epoch 1168, Loss: 0.172963485121727, Final Batch Loss: 0.019715065136551857\n",
      "Epoch 1169, Loss: 0.09898493345826864, Final Batch Loss: 0.02807977981865406\n",
      "Epoch 1170, Loss: 0.27712571900337934, Final Batch Loss: 0.13151855766773224\n",
      "Epoch 1171, Loss: 0.12358351983129978, Final Batch Loss: 0.04528668150305748\n",
      "Epoch 1172, Loss: 0.13562847301363945, Final Batch Loss: 0.014306148514151573\n",
      "Epoch 1173, Loss: 0.14930274337530136, Final Batch Loss: 0.04689190536737442\n",
      "Epoch 1174, Loss: 0.07592696789652109, Final Batch Loss: 0.023772478103637695\n",
      "Epoch 1175, Loss: 0.12671916745603085, Final Batch Loss: 0.04747513309121132\n",
      "Epoch 1176, Loss: 0.12351354165002704, Final Batch Loss: 0.005658149253576994\n",
      "Epoch 1177, Loss: 0.0917656933888793, Final Batch Loss: 0.013195391744375229\n",
      "Epoch 1178, Loss: 0.13246571645140648, Final Batch Loss: 0.036290377378463745\n",
      "Epoch 1179, Loss: 0.12197028659284115, Final Batch Loss: 0.03356151655316353\n",
      "Epoch 1180, Loss: 0.08395101013593376, Final Batch Loss: 0.0021595365833491087\n",
      "Epoch 1181, Loss: 0.18352559953927994, Final Batch Loss: 0.01932116225361824\n",
      "Epoch 1182, Loss: 0.09902461431920528, Final Batch Loss: 0.03780364990234375\n",
      "Epoch 1183, Loss: 0.10129786934703588, Final Batch Loss: 0.009746049530804157\n",
      "Epoch 1184, Loss: 0.06852283701300621, Final Batch Loss: 0.002973472699522972\n",
      "Epoch 1185, Loss: 0.0908530568704009, Final Batch Loss: 0.017257917672395706\n",
      "Epoch 1186, Loss: 0.11088468972593546, Final Batch Loss: 0.05417656525969505\n",
      "Epoch 1187, Loss: 0.09031401854008436, Final Batch Loss: 0.006494396366178989\n",
      "Epoch 1188, Loss: 0.10737218987196684, Final Batch Loss: 0.010974005796015263\n",
      "Epoch 1189, Loss: 0.10451505519449711, Final Batch Loss: 0.024355167523026466\n",
      "Epoch 1190, Loss: 0.07296068873256445, Final Batch Loss: 0.02006668783724308\n",
      "Epoch 1191, Loss: 0.1438742633908987, Final Batch Loss: 0.024861503392457962\n",
      "Epoch 1192, Loss: 0.08804088179022074, Final Batch Loss: 0.00832050759345293\n",
      "Epoch 1193, Loss: 0.10210672952234745, Final Batch Loss: 0.02445814199745655\n",
      "Epoch 1194, Loss: 0.09840511623769999, Final Batch Loss: 0.0036892788484692574\n",
      "Epoch 1195, Loss: 0.19469988346099854, Final Batch Loss: 0.04749733582139015\n",
      "Epoch 1196, Loss: 0.17041135020554066, Final Batch Loss: 0.008117938414216042\n",
      "Epoch 1197, Loss: 0.0400719940662384, Final Batch Loss: 0.004469635896384716\n",
      "Epoch 1198, Loss: 0.08821217343211174, Final Batch Loss: 0.017140567302703857\n",
      "Epoch 1199, Loss: 0.10249961819499731, Final Batch Loss: 0.058562107384204865\n",
      "Epoch 1200, Loss: 0.08947190083563328, Final Batch Loss: 0.0024841204285621643\n",
      "Epoch 1201, Loss: 0.082507798448205, Final Batch Loss: 0.014761429280042648\n",
      "Epoch 1202, Loss: 0.1052976455539465, Final Batch Loss: 0.026539267972111702\n",
      "Epoch 1203, Loss: 0.16207815613597631, Final Batch Loss: 0.05054320767521858\n",
      "Epoch 1204, Loss: 0.20234402362257242, Final Batch Loss: 0.10755476355552673\n",
      "Epoch 1205, Loss: 0.1317159589380026, Final Batch Loss: 0.06145239993929863\n",
      "Epoch 1206, Loss: 0.11395744979381561, Final Batch Loss: 0.027879903092980385\n",
      "Epoch 1207, Loss: 0.14369897916913033, Final Batch Loss: 0.020583337172865868\n",
      "Epoch 1208, Loss: 0.19605179969221354, Final Batch Loss: 0.048962000757455826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1209, Loss: 0.13248598016798496, Final Batch Loss: 0.063814677298069\n",
      "Epoch 1210, Loss: 0.09372250270098448, Final Batch Loss: 0.011907421983778477\n",
      "Epoch 1211, Loss: 0.1696378942579031, Final Batch Loss: 0.05219249799847603\n",
      "Epoch 1212, Loss: 0.1418659258633852, Final Batch Loss: 0.02862556464970112\n",
      "Epoch 1213, Loss: 0.1712218075990677, Final Batch Loss: 0.053706441074609756\n",
      "Epoch 1214, Loss: 0.13379887863993645, Final Batch Loss: 0.03700578212738037\n",
      "Epoch 1215, Loss: 0.14027560595422983, Final Batch Loss: 0.006756016053259373\n",
      "Epoch 1216, Loss: 0.18033349886536598, Final Batch Loss: 0.021018370985984802\n",
      "Epoch 1217, Loss: 0.18791947234421968, Final Batch Loss: 0.09792149811983109\n",
      "Epoch 1218, Loss: 0.15604418329894543, Final Batch Loss: 0.05451015383005142\n",
      "Epoch 1219, Loss: 0.07366160629317164, Final Batch Loss: 0.006497835274785757\n",
      "Epoch 1220, Loss: 0.22673682868480682, Final Batch Loss: 0.07723886519670486\n",
      "Epoch 1221, Loss: 0.07350234594196081, Final Batch Loss: 0.014240197837352753\n",
      "Epoch 1222, Loss: 0.1752567607909441, Final Batch Loss: 0.05748818814754486\n",
      "Epoch 1223, Loss: 0.09004014544188976, Final Batch Loss: 0.00971711054444313\n",
      "Epoch 1224, Loss: 0.14215368404984474, Final Batch Loss: 0.04485872760415077\n",
      "Epoch 1225, Loss: 0.07415701681748033, Final Batch Loss: 0.007026548031717539\n",
      "Epoch 1226, Loss: 0.09723593667149544, Final Batch Loss: 0.03831831365823746\n",
      "Epoch 1227, Loss: 0.07464628759771585, Final Batch Loss: 0.01809495873749256\n",
      "Epoch 1228, Loss: 0.12391485925763845, Final Batch Loss: 0.007296889089047909\n",
      "Epoch 1229, Loss: 0.1142471069470048, Final Batch Loss: 0.02328256517648697\n",
      "Epoch 1230, Loss: 0.14008825877681375, Final Batch Loss: 0.040962088853120804\n",
      "Epoch 1231, Loss: 0.10842631198465824, Final Batch Loss: 0.020835034549236298\n",
      "Epoch 1232, Loss: 0.053219832479953766, Final Batch Loss: 0.010917662642896175\n",
      "Epoch 1233, Loss: 0.04952852288261056, Final Batch Loss: 0.010786619037389755\n",
      "Epoch 1234, Loss: 0.14199747703969479, Final Batch Loss: 0.05150981619954109\n",
      "Epoch 1235, Loss: 0.07260734494775534, Final Batch Loss: 0.006856108084321022\n",
      "Epoch 1236, Loss: 0.12568975798785686, Final Batch Loss: 0.016970302909612656\n",
      "Epoch 1237, Loss: 0.22011880949139595, Final Batch Loss: 0.09654856473207474\n",
      "Epoch 1238, Loss: 0.1088579623028636, Final Batch Loss: 0.03839631378650665\n",
      "Epoch 1239, Loss: 0.18119725212454796, Final Batch Loss: 0.08894763886928558\n",
      "Epoch 1240, Loss: 0.12999890185892582, Final Batch Loss: 0.07758130133152008\n",
      "Epoch 1241, Loss: 0.15773852914571762, Final Batch Loss: 0.03227997198700905\n",
      "Epoch 1242, Loss: 0.24212781712412834, Final Batch Loss: 0.03689561411738396\n",
      "Epoch 1243, Loss: 0.1593240275979042, Final Batch Loss: 0.08694586157798767\n",
      "Epoch 1244, Loss: 0.18627258390188217, Final Batch Loss: 0.023958425968885422\n",
      "Epoch 1245, Loss: 0.14213837683200836, Final Batch Loss: 0.01493939571082592\n",
      "Epoch 1246, Loss: 0.15078860614448786, Final Batch Loss: 0.00923039298504591\n",
      "Epoch 1247, Loss: 0.1281751049682498, Final Batch Loss: 0.016920873895287514\n",
      "Epoch 1248, Loss: 0.17102807201445103, Final Batch Loss: 0.06682821363210678\n",
      "Epoch 1249, Loss: 0.2690187059342861, Final Batch Loss: 0.07665497064590454\n",
      "Epoch 1250, Loss: 0.13006314542144537, Final Batch Loss: 0.014331002719700336\n",
      "Epoch 1251, Loss: 0.11965833697468042, Final Batch Loss: 0.011914188973605633\n",
      "Epoch 1252, Loss: 0.1849089302122593, Final Batch Loss: 0.06459499150514603\n",
      "Epoch 1253, Loss: 0.15324448235332966, Final Batch Loss: 0.07216258347034454\n",
      "Epoch 1254, Loss: 0.10837804758921266, Final Batch Loss: 0.0044025820679962635\n",
      "Epoch 1255, Loss: 0.16392262978479266, Final Batch Loss: 0.03700726106762886\n",
      "Epoch 1256, Loss: 0.12085673213005066, Final Batch Loss: 0.01284041814506054\n",
      "Epoch 1257, Loss: 0.23639949038624763, Final Batch Loss: 0.08278485387563705\n",
      "Epoch 1258, Loss: 0.09979341086000204, Final Batch Loss: 0.015418813563883305\n",
      "Epoch 1259, Loss: 0.09294218942523003, Final Batch Loss: 0.021548479795455933\n",
      "Epoch 1260, Loss: 0.07104816660284996, Final Batch Loss: 0.018412062898278236\n",
      "Epoch 1261, Loss: 0.09874557983130217, Final Batch Loss: 0.03900283947587013\n",
      "Epoch 1262, Loss: 0.06649927422404289, Final Batch Loss: 0.015500187873840332\n",
      "Epoch 1263, Loss: 0.0898013231344521, Final Batch Loss: 0.007478410843759775\n",
      "Epoch 1264, Loss: 0.12879166239872575, Final Batch Loss: 0.06919293850660324\n",
      "Epoch 1265, Loss: 0.0784677923657, Final Batch Loss: 0.00718300836160779\n",
      "Epoch 1266, Loss: 0.13289448199793696, Final Batch Loss: 0.0041148304007947445\n",
      "Epoch 1267, Loss: 0.06164216995239258, Final Batch Loss: 0.02647201530635357\n",
      "Epoch 1268, Loss: 0.10304822004400194, Final Batch Loss: 0.002495396649464965\n",
      "Epoch 1269, Loss: 0.07832366693764925, Final Batch Loss: 0.00804191268980503\n",
      "Epoch 1270, Loss: 0.11472661886364222, Final Batch Loss: 0.05284808576107025\n",
      "Epoch 1271, Loss: 0.12933529214933515, Final Batch Loss: 0.09259594231843948\n",
      "Epoch 1272, Loss: 0.07753417175263166, Final Batch Loss: 0.008342177607119083\n",
      "Epoch 1273, Loss: 0.04772676061838865, Final Batch Loss: 0.00678816344588995\n",
      "Epoch 1274, Loss: 0.0735483979806304, Final Batch Loss: 0.020753387361764908\n",
      "Epoch 1275, Loss: 0.07667285297065973, Final Batch Loss: 0.03126172348856926\n",
      "Epoch 1276, Loss: 0.16412116680294275, Final Batch Loss: 0.0869387686252594\n",
      "Epoch 1277, Loss: 0.10915971361100674, Final Batch Loss: 0.032719116657972336\n",
      "Epoch 1278, Loss: 0.08884827652946115, Final Batch Loss: 0.015713699162006378\n",
      "Epoch 1279, Loss: 0.10840752255171537, Final Batch Loss: 0.01667897216975689\n",
      "Epoch 1280, Loss: 0.12365320231765509, Final Batch Loss: 0.08178015798330307\n",
      "Epoch 1281, Loss: 0.0692597534507513, Final Batch Loss: 0.010999506339430809\n",
      "Epoch 1282, Loss: 0.12827914021909237, Final Batch Loss: 0.04071621969342232\n",
      "Epoch 1283, Loss: 0.13152753841131926, Final Batch Loss: 0.03948596119880676\n",
      "Epoch 1284, Loss: 0.27800810150802135, Final Batch Loss: 0.13571172952651978\n",
      "Epoch 1285, Loss: 0.06159172672778368, Final Batch Loss: 0.006433500908315182\n",
      "Epoch 1286, Loss: 0.15812399983406067, Final Batch Loss: 0.01970611698925495\n",
      "Epoch 1287, Loss: 0.2629621624946594, Final Batch Loss: 0.09774775803089142\n",
      "Epoch 1288, Loss: 0.10416478710249066, Final Batch Loss: 0.005913131404668093\n",
      "Epoch 1289, Loss: 0.19226335640996695, Final Batch Loss: 0.00913721602410078\n",
      "Epoch 1290, Loss: 0.050842876080423594, Final Batch Loss: 0.01047318335622549\n",
      "Epoch 1291, Loss: 0.10278484784066677, Final Batch Loss: 0.01172097958624363\n",
      "Epoch 1292, Loss: 0.056706588715314865, Final Batch Loss: 0.011906788684427738\n",
      "Epoch 1293, Loss: 0.14968920592218637, Final Batch Loss: 0.08546292036771774\n",
      "Epoch 1294, Loss: 0.11468832939863205, Final Batch Loss: 0.030981509014964104\n",
      "Epoch 1295, Loss: 0.0841988930478692, Final Batch Loss: 0.03623201325535774\n",
      "Epoch 1296, Loss: 0.059889792930334806, Final Batch Loss: 0.01854974962770939\n",
      "Epoch 1297, Loss: 0.0671365219168365, Final Batch Loss: 0.005835814867168665\n",
      "Epoch 1298, Loss: 0.11452515237033367, Final Batch Loss: 0.0549185611307621\n",
      "Epoch 1299, Loss: 0.20355820935219526, Final Batch Loss: 0.012420832179486752\n",
      "Epoch 1300, Loss: 0.10362865589559078, Final Batch Loss: 0.02083779126405716\n",
      "Epoch 1301, Loss: 0.06201756652444601, Final Batch Loss: 0.00784267671406269\n",
      "Epoch 1302, Loss: 0.13661914691329002, Final Batch Loss: 0.002906233072280884\n",
      "Epoch 1303, Loss: 0.19095036201179028, Final Batch Loss: 0.01427777111530304\n",
      "Epoch 1304, Loss: 0.07024595746770501, Final Batch Loss: 0.006313920486718416\n",
      "Epoch 1305, Loss: 0.09735515154898167, Final Batch Loss: 0.031115107238292694\n",
      "Epoch 1306, Loss: 0.07382513023912907, Final Batch Loss: 0.013387716375291348\n",
      "Epoch 1307, Loss: 0.08587394468486309, Final Batch Loss: 0.027807362377643585\n",
      "Epoch 1308, Loss: 0.11024183966219425, Final Batch Loss: 0.013489075005054474\n",
      "Epoch 1309, Loss: 0.14915724284946918, Final Batch Loss: 0.02843782678246498\n",
      "Epoch 1310, Loss: 0.1585491495206952, Final Batch Loss: 0.04789919778704643\n",
      "Epoch 1311, Loss: 0.07956461352296174, Final Batch Loss: 0.0026310172397643328\n",
      "Epoch 1312, Loss: 0.10307017620652914, Final Batch Loss: 0.0307308416813612\n",
      "Epoch 1313, Loss: 0.06713162129744887, Final Batch Loss: 0.00465635908767581\n",
      "Epoch 1314, Loss: 0.16341749392449856, Final Batch Loss: 0.05247199535369873\n",
      "Epoch 1315, Loss: 0.1196981268003583, Final Batch Loss: 0.02387499250471592\n",
      "Epoch 1316, Loss: 0.05265931831672788, Final Batch Loss: 0.00723982835188508\n",
      "Epoch 1317, Loss: 0.03573726490139961, Final Batch Loss: 0.011166692711412907\n",
      "Epoch 1318, Loss: 0.042712122201919556, Final Batch Loss: 0.009675674140453339\n",
      "Epoch 1319, Loss: 0.06713344156742096, Final Batch Loss: 0.029776712879538536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1320, Loss: 0.05017385073006153, Final Batch Loss: 0.007035274989902973\n",
      "Epoch 1321, Loss: 0.12123082159087062, Final Batch Loss: 0.004255426581948996\n",
      "Epoch 1322, Loss: 0.21057940274477005, Final Batch Loss: 0.13833922147750854\n",
      "Epoch 1323, Loss: 0.09350374154746532, Final Batch Loss: 0.02505112811923027\n",
      "Epoch 1324, Loss: 0.08621255401521921, Final Batch Loss: 0.03585481271147728\n",
      "Epoch 1325, Loss: 0.10497019300237298, Final Batch Loss: 0.035095132887363434\n",
      "Epoch 1326, Loss: 0.05858368705958128, Final Batch Loss: 0.008276375010609627\n",
      "Epoch 1327, Loss: 0.06587416213005781, Final Batch Loss: 0.007935410365462303\n",
      "Epoch 1328, Loss: 0.1377696618437767, Final Batch Loss: 0.0416744202375412\n",
      "Epoch 1329, Loss: 0.07634253986179829, Final Batch Loss: 0.027045154944062233\n",
      "Epoch 1330, Loss: 0.1327897310256958, Final Batch Loss: 0.037592820823192596\n",
      "Epoch 1331, Loss: 0.06437205569818616, Final Batch Loss: 0.006618708837777376\n",
      "Epoch 1332, Loss: 0.07717717718333006, Final Batch Loss: 0.013739556074142456\n",
      "Epoch 1333, Loss: 0.09706948883831501, Final Batch Loss: 0.057365722954273224\n",
      "Epoch 1334, Loss: 0.10800837259739637, Final Batch Loss: 0.03728608787059784\n",
      "Epoch 1335, Loss: 0.048447463661432266, Final Batch Loss: 0.008922567591071129\n",
      "Epoch 1336, Loss: 0.08511816477403045, Final Batch Loss: 0.003914964850991964\n",
      "Epoch 1337, Loss: 0.0573602644726634, Final Batch Loss: 0.012564334087073803\n",
      "Epoch 1338, Loss: 0.052127713337540627, Final Batch Loss: 0.017657984048128128\n",
      "Epoch 1339, Loss: 0.026884596329182386, Final Batch Loss: 0.004930836148560047\n",
      "Epoch 1340, Loss: 0.04242743505164981, Final Batch Loss: 0.007668112870305777\n",
      "Epoch 1341, Loss: 0.07975933514535427, Final Batch Loss: 0.014553890563547611\n",
      "Epoch 1342, Loss: 0.09062111377716064, Final Batch Loss: 0.060097306966781616\n",
      "Epoch 1343, Loss: 0.05399013450369239, Final Batch Loss: 0.00894075259566307\n",
      "Epoch 1344, Loss: 0.1082545667886734, Final Batch Loss: 0.028214268386363983\n",
      "Epoch 1345, Loss: 0.09359065792523324, Final Batch Loss: 0.002893587341532111\n",
      "Epoch 1346, Loss: 0.13012754544615746, Final Batch Loss: 0.02080029621720314\n",
      "Epoch 1347, Loss: 0.10259301261976361, Final Batch Loss: 0.007652819622308016\n",
      "Epoch 1348, Loss: 0.05676354840397835, Final Batch Loss: 0.010279071517288685\n",
      "Epoch 1349, Loss: 0.07709491718560457, Final Batch Loss: 0.03601740300655365\n",
      "Epoch 1350, Loss: 0.09243315551429987, Final Batch Loss: 0.027969397604465485\n",
      "Epoch 1351, Loss: 0.14618840254843235, Final Batch Loss: 0.05186871066689491\n",
      "Epoch 1352, Loss: 0.19722501002252102, Final Batch Loss: 0.06262767314910889\n",
      "Epoch 1353, Loss: 0.07124319486320019, Final Batch Loss: 0.0050863949581980705\n",
      "Epoch 1354, Loss: 0.1877603642642498, Final Batch Loss: 0.1059124693274498\n",
      "Epoch 1355, Loss: 0.21498177014291286, Final Batch Loss: 0.016128338873386383\n",
      "Epoch 1356, Loss: 0.14382178522646427, Final Batch Loss: 0.059020452201366425\n",
      "Epoch 1357, Loss: 0.16695049963891506, Final Batch Loss: 0.010593023151159286\n",
      "Epoch 1358, Loss: 0.10101479152217507, Final Batch Loss: 0.0038851764984428883\n",
      "Epoch 1359, Loss: 0.14774539158679545, Final Batch Loss: 0.002965459832921624\n",
      "Epoch 1360, Loss: 0.07024083100259304, Final Batch Loss: 0.022207561880350113\n",
      "Epoch 1361, Loss: 0.06470137927681208, Final Batch Loss: 0.01577715389430523\n",
      "Epoch 1362, Loss: 0.08804547367617488, Final Batch Loss: 0.009355233050882816\n",
      "Epoch 1363, Loss: 0.10691949725151062, Final Batch Loss: 0.01812134124338627\n",
      "Epoch 1364, Loss: 0.11101625743322074, Final Batch Loss: 0.0030737367924302816\n",
      "Epoch 1365, Loss: 0.03560666600242257, Final Batch Loss: 0.0041888076812028885\n",
      "Epoch 1366, Loss: 0.05611398397013545, Final Batch Loss: 0.006270875688642263\n",
      "Epoch 1367, Loss: 0.09673403110355139, Final Batch Loss: 0.015503580681979656\n",
      "Epoch 1368, Loss: 0.07995307724922895, Final Batch Loss: 0.03547802194952965\n",
      "Epoch 1369, Loss: 0.08357209200039506, Final Batch Loss: 0.006074317265301943\n",
      "Epoch 1370, Loss: 0.04197870334610343, Final Batch Loss: 0.009755122475326061\n",
      "Epoch 1371, Loss: 0.05783860106021166, Final Batch Loss: 0.009749033488333225\n",
      "Epoch 1372, Loss: 0.09377761790528893, Final Batch Loss: 0.04252723976969719\n",
      "Epoch 1373, Loss: 0.03640691703185439, Final Batch Loss: 0.006324063986539841\n",
      "Epoch 1374, Loss: 0.090086615877226, Final Batch Loss: 0.002148528816178441\n",
      "Epoch 1375, Loss: 0.08460207190364599, Final Batch Loss: 0.04464934766292572\n",
      "Epoch 1376, Loss: 0.10095305740833282, Final Batch Loss: 0.010558724403381348\n",
      "Epoch 1377, Loss: 0.10810854565352201, Final Batch Loss: 0.020427033305168152\n",
      "Epoch 1378, Loss: 0.10229106619954109, Final Batch Loss: 0.007086431607604027\n",
      "Epoch 1379, Loss: 0.0652825296856463, Final Batch Loss: 0.006821377668529749\n",
      "Epoch 1380, Loss: 0.11690137162804604, Final Batch Loss: 0.07893827557563782\n",
      "Epoch 1381, Loss: 0.11115549458190799, Final Batch Loss: 0.04378223046660423\n",
      "Epoch 1382, Loss: 0.09637863282114267, Final Batch Loss: 0.017007488757371902\n",
      "Epoch 1383, Loss: 0.056398524437099695, Final Batch Loss: 0.002288904506713152\n",
      "Epoch 1384, Loss: 0.08038639929145575, Final Batch Loss: 0.0023722173646092415\n",
      "Epoch 1385, Loss: 0.1583640119060874, Final Batch Loss: 0.0909678190946579\n",
      "Epoch 1386, Loss: 0.1104470007121563, Final Batch Loss: 0.03574923425912857\n",
      "Epoch 1387, Loss: 0.08036871254444122, Final Batch Loss: 0.023264627903699875\n",
      "Epoch 1388, Loss: 0.16556691844016314, Final Batch Loss: 0.09085153043270111\n",
      "Epoch 1389, Loss: 0.08698596991598606, Final Batch Loss: 0.018112841993570328\n",
      "Epoch 1390, Loss: 0.08266777358949184, Final Batch Loss: 0.005367221310734749\n",
      "Epoch 1391, Loss: 0.08166727796196938, Final Batch Loss: 0.0220966674387455\n",
      "Epoch 1392, Loss: 0.0548964012414217, Final Batch Loss: 0.024612383916974068\n",
      "Epoch 1393, Loss: 0.09088620450347662, Final Batch Loss: 0.020637784153223038\n",
      "Epoch 1394, Loss: 0.2359446156769991, Final Batch Loss: 0.018380092456936836\n",
      "Epoch 1395, Loss: 0.2029162384569645, Final Batch Loss: 0.05085349455475807\n",
      "Epoch 1396, Loss: 0.10619256738573313, Final Batch Loss: 0.02485479973256588\n",
      "Epoch 1397, Loss: 0.22431333363056183, Final Batch Loss: 0.08088362962007523\n",
      "Epoch 1398, Loss: 0.0828003752976656, Final Batch Loss: 0.009176820516586304\n",
      "Epoch 1399, Loss: 0.20144849456846714, Final Batch Loss: 0.14182303845882416\n",
      "Epoch 1400, Loss: 0.09521673433482647, Final Batch Loss: 0.011460809037089348\n",
      "Epoch 1401, Loss: 0.16064955666661263, Final Batch Loss: 0.039807505905628204\n",
      "Epoch 1402, Loss: 0.08784635737538338, Final Batch Loss: 0.006689670495688915\n",
      "Epoch 1403, Loss: 0.11800089082680643, Final Batch Loss: 0.003873994341120124\n",
      "Epoch 1404, Loss: 0.12532880529761314, Final Batch Loss: 0.0332232266664505\n",
      "Epoch 1405, Loss: 0.09529099240899086, Final Batch Loss: 0.024094071239233017\n",
      "Epoch 1406, Loss: 0.09221781208179891, Final Batch Loss: 0.0032343461643904448\n",
      "Epoch 1407, Loss: 0.07290027337148786, Final Batch Loss: 0.002653030678629875\n",
      "Epoch 1408, Loss: 0.12277374602854252, Final Batch Loss: 0.03159528598189354\n",
      "Epoch 1409, Loss: 0.0967296464368701, Final Batch Loss: 0.008830259554088116\n",
      "Epoch 1410, Loss: 0.040016525774262846, Final Batch Loss: 0.0016750249778851867\n",
      "Epoch 1411, Loss: 0.07638741750270128, Final Batch Loss: 0.007567121647298336\n",
      "Epoch 1412, Loss: 0.05178474402055144, Final Batch Loss: 0.005172306206077337\n",
      "Epoch 1413, Loss: 0.11100330110639334, Final Batch Loss: 0.008322452194988728\n",
      "Epoch 1414, Loss: 0.04622034030035138, Final Batch Loss: 0.020706774666905403\n",
      "Epoch 1415, Loss: 0.12764551769942045, Final Batch Loss: 0.0056690638884902\n",
      "Epoch 1416, Loss: 0.1851762067526579, Final Batch Loss: 0.05531994253396988\n",
      "Epoch 1417, Loss: 0.045372842345386744, Final Batch Loss: 0.009441648609936237\n",
      "Epoch 1418, Loss: 0.12449126690626144, Final Batch Loss: 0.0029103951528668404\n",
      "Epoch 1419, Loss: 0.0655613224953413, Final Batch Loss: 0.007835213094949722\n",
      "Epoch 1420, Loss: 0.03505855146795511, Final Batch Loss: 0.014556842856109142\n",
      "Epoch 1421, Loss: 0.05862428969703615, Final Batch Loss: 0.0026492716278880835\n",
      "Epoch 1422, Loss: 0.07696074363775551, Final Batch Loss: 0.0036494594532996416\n",
      "Epoch 1423, Loss: 0.03225514548830688, Final Batch Loss: 0.006811327300965786\n",
      "Epoch 1424, Loss: 0.03692437265999615, Final Batch Loss: 0.0019257294479757547\n",
      "Epoch 1425, Loss: 0.07139205932617188, Final Batch Loss: 0.008853456005454063\n",
      "Epoch 1426, Loss: 0.04404244525358081, Final Batch Loss: 0.003255095798522234\n",
      "Epoch 1427, Loss: 0.07867329777218401, Final Batch Loss: 0.0037812276277691126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1428, Loss: 0.13715728861279786, Final Batch Loss: 0.03765524923801422\n",
      "Epoch 1429, Loss: 0.0855695039499551, Final Batch Loss: 0.04368691146373749\n",
      "Epoch 1430, Loss: 0.035393154714256525, Final Batch Loss: 0.009498801082372665\n",
      "Epoch 1431, Loss: 0.051953672897070646, Final Batch Loss: 0.013522319495677948\n",
      "Epoch 1432, Loss: 0.07734681433066726, Final Batch Loss: 0.009966842830181122\n",
      "Epoch 1433, Loss: 0.06615296239033341, Final Batch Loss: 0.026128040626645088\n",
      "Epoch 1434, Loss: 0.08849495556205511, Final Batch Loss: 0.018847759813070297\n",
      "Epoch 1435, Loss: 0.07900610379874706, Final Batch Loss: 0.013339435681700706\n",
      "Epoch 1436, Loss: 0.0760034762788564, Final Batch Loss: 0.002924951957538724\n",
      "Epoch 1437, Loss: 0.10341503284871578, Final Batch Loss: 0.02021404355764389\n",
      "Epoch 1438, Loss: 0.03882137965410948, Final Batch Loss: 0.008737275376915932\n",
      "Epoch 1439, Loss: 0.1904323659837246, Final Batch Loss: 0.040135134011507034\n",
      "Epoch 1440, Loss: 0.07002188917249441, Final Batch Loss: 0.003887701779603958\n",
      "Epoch 1441, Loss: 0.12468645721673965, Final Batch Loss: 0.06231028214097023\n",
      "Epoch 1442, Loss: 0.057883205357939005, Final Batch Loss: 0.004912861157208681\n",
      "Epoch 1443, Loss: 0.1633448009379208, Final Batch Loss: 0.09230626374483109\n",
      "Epoch 1444, Loss: 0.08675248362123966, Final Batch Loss: 0.04478707164525986\n",
      "Epoch 1445, Loss: 0.22118750400841236, Final Batch Loss: 0.050975773483514786\n",
      "Epoch 1446, Loss: 0.09676357498392463, Final Batch Loss: 0.009604603052139282\n",
      "Epoch 1447, Loss: 0.06497987918555737, Final Batch Loss: 0.021733911707997322\n",
      "Epoch 1448, Loss: 0.04416084033437073, Final Batch Loss: 0.009637444280087948\n",
      "Epoch 1449, Loss: 0.07315115653909743, Final Batch Loss: 0.0020740728359669447\n",
      "Epoch 1450, Loss: 0.11892010737210512, Final Batch Loss: 0.04371674731373787\n",
      "Epoch 1451, Loss: 0.17364547215402126, Final Batch Loss: 0.04733354598283768\n",
      "Epoch 1452, Loss: 0.07126346882432699, Final Batch Loss: 0.02206895686686039\n",
      "Epoch 1453, Loss: 0.1331755295395851, Final Batch Loss: 0.02647915482521057\n",
      "Epoch 1454, Loss: 0.0639540571719408, Final Batch Loss: 0.011604824103415012\n",
      "Epoch 1455, Loss: 0.12517025880515575, Final Batch Loss: 0.014602091163396835\n",
      "Epoch 1456, Loss: 0.07275402965024114, Final Batch Loss: 0.005353874061256647\n",
      "Epoch 1457, Loss: 0.04573438270017505, Final Batch Loss: 0.007930677384138107\n",
      "Epoch 1458, Loss: 0.11720856372267008, Final Batch Loss: 0.08221016079187393\n",
      "Epoch 1459, Loss: 0.06215803464874625, Final Batch Loss: 0.007666034158319235\n",
      "Epoch 1460, Loss: 0.10614361637271941, Final Batch Loss: 0.0015839862171560526\n",
      "Epoch 1461, Loss: 0.12414086679928005, Final Batch Loss: 0.0540018305182457\n",
      "Epoch 1462, Loss: 0.1359277623705566, Final Batch Loss: 0.006467205006629229\n",
      "Epoch 1463, Loss: 0.10230741836130619, Final Batch Loss: 0.03048904612660408\n",
      "Epoch 1464, Loss: 0.08490344695746899, Final Batch Loss: 0.004359874874353409\n",
      "Epoch 1465, Loss: 0.14044607989490032, Final Batch Loss: 0.09665826708078384\n",
      "Epoch 1466, Loss: 0.27030955627560616, Final Batch Loss: 0.007934864610433578\n",
      "Epoch 1467, Loss: 0.1763576092198491, Final Batch Loss: 0.013428729958832264\n",
      "Epoch 1468, Loss: 0.1354980394244194, Final Batch Loss: 0.02554900012910366\n",
      "Epoch 1469, Loss: 0.061395315919071436, Final Batch Loss: 0.028522156178951263\n",
      "Epoch 1470, Loss: 0.09549810132011771, Final Batch Loss: 0.007605885621160269\n",
      "Epoch 1471, Loss: 0.1744733601808548, Final Batch Loss: 0.07579174637794495\n",
      "Epoch 1472, Loss: 0.13929264154285192, Final Batch Loss: 0.07900518923997879\n",
      "Epoch 1473, Loss: 0.06122144591063261, Final Batch Loss: 0.008461816236376762\n",
      "Epoch 1474, Loss: 0.09514379035681486, Final Batch Loss: 0.01157408393919468\n",
      "Epoch 1475, Loss: 0.15412788465619087, Final Batch Loss: 0.03153140842914581\n",
      "Epoch 1476, Loss: 0.0850142389535904, Final Batch Loss: 0.03748883679509163\n",
      "Epoch 1477, Loss: 0.103095393627882, Final Batch Loss: 0.029425429180264473\n",
      "Epoch 1478, Loss: 0.1685720826499164, Final Batch Loss: 0.06892264634370804\n",
      "Epoch 1479, Loss: 0.10810728557407856, Final Batch Loss: 0.008777999319136143\n",
      "Epoch 1480, Loss: 0.08008838398382068, Final Batch Loss: 0.007407513912767172\n",
      "Epoch 1481, Loss: 0.10599903762340546, Final Batch Loss: 0.017880374565720558\n",
      "Epoch 1482, Loss: 0.2279361174441874, Final Batch Loss: 0.17340174317359924\n",
      "Epoch 1483, Loss: 0.10522919613867998, Final Batch Loss: 0.005070026032626629\n",
      "Epoch 1484, Loss: 0.16784654837101698, Final Batch Loss: 0.01369794923812151\n",
      "Epoch 1485, Loss: 0.06893779570236802, Final Batch Loss: 0.009094562381505966\n",
      "Epoch 1486, Loss: 0.10791526455432177, Final Batch Loss: 0.02347533218562603\n",
      "Epoch 1487, Loss: 0.19938001036643982, Final Batch Loss: 0.05012504756450653\n",
      "Epoch 1488, Loss: 0.1577888955362141, Final Batch Loss: 0.03740241378545761\n",
      "Epoch 1489, Loss: 0.12883311975747347, Final Batch Loss: 0.010116408579051495\n",
      "Epoch 1490, Loss: 0.14550978038460016, Final Batch Loss: 0.014993785880506039\n",
      "Epoch 1491, Loss: 0.1488237725570798, Final Batch Loss: 0.011114655993878841\n",
      "Epoch 1492, Loss: 0.07191431801766157, Final Batch Loss: 0.03763915225863457\n",
      "Epoch 1493, Loss: 0.18169770948588848, Final Batch Loss: 0.012709133327007294\n",
      "Epoch 1494, Loss: 0.0880089858546853, Final Batch Loss: 0.005202675703912973\n",
      "Epoch 1495, Loss: 0.17439029831439257, Final Batch Loss: 0.009058686904609203\n",
      "Epoch 1496, Loss: 0.2891169097274542, Final Batch Loss: 0.09862235188484192\n",
      "Epoch 1497, Loss: 0.06489611743018031, Final Batch Loss: 0.015759611502289772\n",
      "Epoch 1498, Loss: 0.08960962388664484, Final Batch Loss: 0.0036271754652261734\n",
      "Epoch 1499, Loss: 0.13671670947223902, Final Batch Loss: 0.01413701381534338\n",
      "Epoch 1500, Loss: 0.07361191604286432, Final Batch Loss: 0.02055591344833374\n",
      "Epoch 1501, Loss: 0.1133267879486084, Final Batch Loss: 0.005450217053294182\n",
      "Epoch 1502, Loss: 0.0642541297711432, Final Batch Loss: 0.010002636350691319\n",
      "Epoch 1503, Loss: 0.061752615263685584, Final Batch Loss: 0.0012828025501221418\n",
      "Epoch 1504, Loss: 0.137743366882205, Final Batch Loss: 0.04215023294091225\n",
      "Epoch 1505, Loss: 0.07532893773168325, Final Batch Loss: 0.012140457518398762\n",
      "Epoch 1506, Loss: 0.07957233861088753, Final Batch Loss: 0.009772645309567451\n",
      "Epoch 1507, Loss: 0.0737918196246028, Final Batch Loss: 0.010266291908919811\n",
      "Epoch 1508, Loss: 0.06510149827226996, Final Batch Loss: 0.004599237348884344\n",
      "Epoch 1509, Loss: 0.08690598886460066, Final Batch Loss: 0.05198638141155243\n",
      "Epoch 1510, Loss: 0.12679734965786338, Final Batch Loss: 0.010599196888506413\n",
      "Epoch 1511, Loss: 0.07881863368675113, Final Batch Loss: 0.045468769967556\n",
      "Epoch 1512, Loss: 0.11137612629681826, Final Batch Loss: 0.05273464322090149\n",
      "Epoch 1513, Loss: 0.06049084383994341, Final Batch Loss: 0.008174852468073368\n",
      "Epoch 1514, Loss: 0.10680710291489959, Final Batch Loss: 0.005276601295918226\n",
      "Epoch 1515, Loss: 0.07234602142125368, Final Batch Loss: 0.02194477990269661\n",
      "Epoch 1516, Loss: 0.06155661179218441, Final Batch Loss: 0.0015279670478776097\n",
      "Epoch 1517, Loss: 0.049814166966825724, Final Batch Loss: 0.00999641977250576\n",
      "Epoch 1518, Loss: 0.06408256711438298, Final Batch Loss: 0.007623882964253426\n",
      "Epoch 1519, Loss: 0.11371758207678795, Final Batch Loss: 0.03487217426300049\n",
      "Epoch 1520, Loss: 0.12290736008435488, Final Batch Loss: 0.03697431460022926\n",
      "Epoch 1521, Loss: 0.06963157746940851, Final Batch Loss: 0.01726287044584751\n",
      "Epoch 1522, Loss: 0.1069393171928823, Final Batch Loss: 0.0121112409979105\n",
      "Epoch 1523, Loss: 0.1510971076786518, Final Batch Loss: 0.08874949812889099\n",
      "Epoch 1524, Loss: 0.12794255325570703, Final Batch Loss: 0.02843879908323288\n",
      "Epoch 1525, Loss: 0.1582050360739231, Final Batch Loss: 0.014687949791550636\n",
      "Epoch 1526, Loss: 0.11899408511817455, Final Batch Loss: 0.016822680830955505\n",
      "Epoch 1527, Loss: 0.11350531689822674, Final Batch Loss: 0.0277494415640831\n",
      "Epoch 1528, Loss: 0.1516151838004589, Final Batch Loss: 0.061310384422540665\n",
      "Epoch 1529, Loss: 0.1777314990758896, Final Batch Loss: 0.030153730884194374\n",
      "Epoch 1530, Loss: 0.14358955342322588, Final Batch Loss: 0.016019264236092567\n",
      "Epoch 1531, Loss: 0.10971895605325699, Final Batch Loss: 0.03161371499300003\n",
      "Epoch 1532, Loss: 0.14860079437494278, Final Batch Loss: 0.020980991423130035\n",
      "Epoch 1533, Loss: 0.1164699699729681, Final Batch Loss: 0.008778514340519905\n",
      "Epoch 1534, Loss: 0.11387316044420004, Final Batch Loss: 0.014206959865987301\n",
      "Epoch 1535, Loss: 0.13355134986341, Final Batch Loss: 0.05107706040143967\n",
      "Epoch 1536, Loss: 0.1628676876425743, Final Batch Loss: 0.04191324859857559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1537, Loss: 0.14327300805598497, Final Batch Loss: 0.020606599748134613\n",
      "Epoch 1538, Loss: 0.06549700116738677, Final Batch Loss: 0.007630019914358854\n",
      "Epoch 1539, Loss: 0.08199321664869785, Final Batch Loss: 0.006999680772423744\n",
      "Epoch 1540, Loss: 0.13094815239310265, Final Batch Loss: 0.025662261992692947\n",
      "Epoch 1541, Loss: 0.08975389041006565, Final Batch Loss: 0.012712916359305382\n",
      "Epoch 1542, Loss: 0.0715397484600544, Final Batch Loss: 0.020496929064393044\n",
      "Epoch 1543, Loss: 0.12636804394423962, Final Batch Loss: 0.023727500811219215\n",
      "Epoch 1544, Loss: 0.09112653462216258, Final Batch Loss: 0.05523274466395378\n",
      "Epoch 1545, Loss: 0.17269540950655937, Final Batch Loss: 0.07904137670993805\n",
      "Epoch 1546, Loss: 0.10745298024266958, Final Batch Loss: 0.015139231458306313\n",
      "Epoch 1547, Loss: 0.1528342547826469, Final Batch Loss: 0.02772967331111431\n",
      "Epoch 1548, Loss: 0.10986710898578167, Final Batch Loss: 0.02938494086265564\n",
      "Epoch 1549, Loss: 0.10738562233746052, Final Batch Loss: 0.00657820887863636\n",
      "Epoch 1550, Loss: 0.12050393875688314, Final Batch Loss: 0.05441879481077194\n",
      "Epoch 1551, Loss: 0.21533916145563126, Final Batch Loss: 0.037305157631635666\n",
      "Epoch 1552, Loss: 0.21411801129579544, Final Batch Loss: 0.058843113481998444\n",
      "Epoch 1553, Loss: 0.15677581913769245, Final Batch Loss: 0.04590233042836189\n",
      "Epoch 1554, Loss: 0.20116783492267132, Final Batch Loss: 0.0860266461968422\n",
      "Epoch 1555, Loss: 0.17043521255254745, Final Batch Loss: 0.03274274244904518\n",
      "Epoch 1556, Loss: 0.1389659997075796, Final Batch Loss: 0.037842489778995514\n",
      "Epoch 1557, Loss: 0.08175210002809763, Final Batch Loss: 0.019618170335888863\n",
      "Epoch 1558, Loss: 0.087572549469769, Final Batch Loss: 0.007094330154359341\n",
      "Epoch 1559, Loss: 0.10048009175807238, Final Batch Loss: 0.007167392410337925\n",
      "Epoch 1560, Loss: 0.08759979344904423, Final Batch Loss: 0.036073993891477585\n",
      "Epoch 1561, Loss: 0.10688084457069635, Final Batch Loss: 0.05710706487298012\n",
      "Epoch 1562, Loss: 0.1848880983889103, Final Batch Loss: 0.11347685754299164\n",
      "Epoch 1563, Loss: 0.07590759918093681, Final Batch Loss: 0.006248955614864826\n",
      "Epoch 1564, Loss: 0.13798428140580654, Final Batch Loss: 0.025217706337571144\n",
      "Epoch 1565, Loss: 0.09158096089959145, Final Batch Loss: 0.011425023898482323\n",
      "Epoch 1566, Loss: 0.07559428317472339, Final Batch Loss: 0.005827546585351229\n",
      "Epoch 1567, Loss: 0.053779908921569586, Final Batch Loss: 0.026161907240748405\n",
      "Epoch 1568, Loss: 0.09303141850978136, Final Batch Loss: 0.008788426406681538\n",
      "Epoch 1569, Loss: 0.09090288914740086, Final Batch Loss: 0.03059590607881546\n",
      "Epoch 1570, Loss: 0.10983351338654757, Final Batch Loss: 0.007258377969264984\n",
      "Epoch 1571, Loss: 0.0933860563673079, Final Batch Loss: 0.053645748645067215\n",
      "Epoch 1572, Loss: 0.09679820016026497, Final Batch Loss: 0.020305044949054718\n",
      "Epoch 1573, Loss: 0.0955915180966258, Final Batch Loss: 0.014539613388478756\n",
      "Epoch 1574, Loss: 0.15689919888973236, Final Batch Loss: 0.039042118936777115\n",
      "Epoch 1575, Loss: 0.06106849666684866, Final Batch Loss: 0.009136969223618507\n",
      "Epoch 1576, Loss: 0.08316945005208254, Final Batch Loss: 0.011245423927903175\n",
      "Epoch 1577, Loss: 0.14007896464318037, Final Batch Loss: 0.05443413183093071\n",
      "Epoch 1578, Loss: 0.12241887394338846, Final Batch Loss: 0.006031086668372154\n",
      "Epoch 1579, Loss: 0.13146186619997025, Final Batch Loss: 0.007037637755274773\n",
      "Epoch 1580, Loss: 0.10789562319405377, Final Batch Loss: 0.020855121314525604\n",
      "Epoch 1581, Loss: 0.10727853793650866, Final Batch Loss: 0.05207676813006401\n",
      "Epoch 1582, Loss: 0.07369183655828238, Final Batch Loss: 0.008040288463234901\n",
      "Epoch 1583, Loss: 0.07882958999834955, Final Batch Loss: 0.0036762363743036985\n",
      "Epoch 1584, Loss: 0.07572038937360048, Final Batch Loss: 0.008960934355854988\n",
      "Epoch 1585, Loss: 0.13103725528344512, Final Batch Loss: 0.06520386040210724\n",
      "Epoch 1586, Loss: 0.09956473065540195, Final Batch Loss: 0.06623929738998413\n",
      "Epoch 1587, Loss: 0.09941185405477881, Final Batch Loss: 0.05219374597072601\n",
      "Epoch 1588, Loss: 0.14474330004304647, Final Batch Loss: 0.05980505794286728\n",
      "Epoch 1589, Loss: 0.08217962412163615, Final Batch Loss: 0.007573473732918501\n",
      "Epoch 1590, Loss: 0.1084398184902966, Final Batch Loss: 0.042388200759887695\n",
      "Epoch 1591, Loss: 0.22981124930083752, Final Batch Loss: 0.1612815409898758\n",
      "Epoch 1592, Loss: 0.05860837223008275, Final Batch Loss: 0.006764799822121859\n",
      "Epoch 1593, Loss: 0.18612069846130908, Final Batch Loss: 0.0037143698427826166\n",
      "Epoch 1594, Loss: 0.21120049059391022, Final Batch Loss: 0.04243157058954239\n",
      "Epoch 1595, Loss: 0.08087483793497086, Final Batch Loss: 0.006230184808373451\n",
      "Epoch 1596, Loss: 0.08961820136755705, Final Batch Loss: 0.03822551667690277\n",
      "Epoch 1597, Loss: 0.14839264377951622, Final Batch Loss: 0.013005637563765049\n",
      "Epoch 1598, Loss: 0.12550101662054658, Final Batch Loss: 0.005209049675613642\n",
      "Epoch 1599, Loss: 0.11922129057347775, Final Batch Loss: 0.021382758393883705\n",
      "Epoch 1600, Loss: 0.08402251289226115, Final Batch Loss: 0.021783120930194855\n",
      "Epoch 1601, Loss: 0.13624229189008474, Final Batch Loss: 0.00856182910501957\n",
      "Epoch 1602, Loss: 0.09413155540823936, Final Batch Loss: 0.019183658063411713\n",
      "Epoch 1603, Loss: 0.14163839723914862, Final Batch Loss: 0.02295449562370777\n",
      "Epoch 1604, Loss: 0.05688551417551935, Final Batch Loss: 0.004983565770089626\n",
      "Epoch 1605, Loss: 0.09702584892511368, Final Batch Loss: 0.017999622970819473\n",
      "Epoch 1606, Loss: 0.10349124972708523, Final Batch Loss: 0.0030474329832941294\n",
      "Epoch 1607, Loss: 0.09391555469483137, Final Batch Loss: 0.015331442467868328\n",
      "Epoch 1608, Loss: 0.12312028091400862, Final Batch Loss: 0.07936429977416992\n",
      "Epoch 1609, Loss: 0.1289627831429243, Final Batch Loss: 0.03646452724933624\n",
      "Epoch 1610, Loss: 0.10271296743303537, Final Batch Loss: 0.03409093618392944\n",
      "Epoch 1611, Loss: 0.1515783267095685, Final Batch Loss: 0.025670329108834267\n",
      "Epoch 1612, Loss: 0.22530782036483288, Final Batch Loss: 0.1104547381401062\n",
      "Epoch 1613, Loss: 0.15964359883219004, Final Batch Loss: 0.005877449177205563\n",
      "Epoch 1614, Loss: 0.11902131047099829, Final Batch Loss: 0.06058385223150253\n",
      "Epoch 1615, Loss: 0.14925411250442266, Final Batch Loss: 0.056927796453237534\n",
      "Epoch 1616, Loss: 0.09912684001028538, Final Batch Loss: 0.009710904210805893\n",
      "Epoch 1617, Loss: 0.16206875257194042, Final Batch Loss: 0.016491562128067017\n",
      "Epoch 1618, Loss: 0.07956215459853411, Final Batch Loss: 0.009006534703075886\n",
      "Epoch 1619, Loss: 0.11662690481171012, Final Batch Loss: 0.005444602575153112\n",
      "Epoch 1620, Loss: 0.08688828442245722, Final Batch Loss: 0.006722495891153812\n",
      "Epoch 1621, Loss: 0.11240370385348797, Final Batch Loss: 0.04752868786454201\n",
      "Epoch 1622, Loss: 0.09171173674985766, Final Batch Loss: 0.0045986115001142025\n",
      "Epoch 1623, Loss: 0.11621850030496716, Final Batch Loss: 0.008883102796971798\n",
      "Epoch 1624, Loss: 0.05589969316497445, Final Batch Loss: 0.007717321161180735\n",
      "Epoch 1625, Loss: 0.055819411762058735, Final Batch Loss: 0.0061448682099580765\n",
      "Epoch 1626, Loss: 0.09868787927553058, Final Batch Loss: 0.02886274643242359\n",
      "Epoch 1627, Loss: 0.04964745347388089, Final Batch Loss: 0.0018738149665296078\n",
      "Epoch 1628, Loss: 0.09205835498869419, Final Batch Loss: 0.050414908677339554\n",
      "Epoch 1629, Loss: 0.08191400859504938, Final Batch Loss: 0.0213469211012125\n",
      "Epoch 1630, Loss: 0.11942598409950733, Final Batch Loss: 0.005474356934428215\n",
      "Epoch 1631, Loss: 0.12025788426399231, Final Batch Loss: 0.026425903663039207\n",
      "Epoch 1632, Loss: 0.22266784589737654, Final Batch Loss: 0.15539835393428802\n",
      "Epoch 1633, Loss: 0.2683814465999603, Final Batch Loss: 0.14722155034542084\n",
      "Epoch 1634, Loss: 0.08982496429234743, Final Batch Loss: 0.02479487471282482\n",
      "Epoch 1635, Loss: 0.1738818995654583, Final Batch Loss: 0.037961240857839584\n",
      "Epoch 1636, Loss: 0.26129478961229324, Final Batch Loss: 0.11224287003278732\n",
      "Epoch 1637, Loss: 0.238619701936841, Final Batch Loss: 0.13404910266399384\n",
      "Epoch 1638, Loss: 0.2593468017876148, Final Batch Loss: 0.026764091104269028\n",
      "Epoch 1639, Loss: 0.15802027098834515, Final Batch Loss: 0.010165145620703697\n",
      "Epoch 1640, Loss: 0.13959426060318947, Final Batch Loss: 0.056551069021224976\n",
      "Epoch 1641, Loss: 0.12914689909666777, Final Batch Loss: 0.012342558242380619\n",
      "Epoch 1642, Loss: 0.13596149906516075, Final Batch Loss: 0.04558590427041054\n",
      "Epoch 1643, Loss: 0.1200905847363174, Final Batch Loss: 0.005395970772951841\n",
      "Epoch 1644, Loss: 0.08379256725311279, Final Batch Loss: 0.007376460358500481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1645, Loss: 0.14498623833060265, Final Batch Loss: 0.025110961869359016\n",
      "Epoch 1646, Loss: 0.0821411656215787, Final Batch Loss: 0.01679299771785736\n",
      "Epoch 1647, Loss: 0.07365803886204958, Final Batch Loss: 0.03855197876691818\n",
      "Epoch 1648, Loss: 0.1173248728737235, Final Batch Loss: 0.054459020495414734\n",
      "Epoch 1649, Loss: 0.0962723670527339, Final Batch Loss: 0.031519487500190735\n",
      "Epoch 1650, Loss: 0.164787364192307, Final Batch Loss: 0.059818487614393234\n",
      "Epoch 1651, Loss: 0.11160705890506506, Final Batch Loss: 0.011323732323944569\n",
      "Epoch 1652, Loss: 0.07865306595340371, Final Batch Loss: 0.0053436183370649815\n",
      "Epoch 1653, Loss: 0.09149192180484533, Final Batch Loss: 0.005027242936193943\n",
      "Epoch 1654, Loss: 0.17228182591497898, Final Batch Loss: 0.07291210442781448\n",
      "Epoch 1655, Loss: 0.0786531837657094, Final Batch Loss: 0.006269823759794235\n",
      "Epoch 1656, Loss: 0.10640049306675792, Final Batch Loss: 0.006470841821283102\n",
      "Epoch 1657, Loss: 0.05979723948985338, Final Batch Loss: 0.01872674934566021\n",
      "Epoch 1658, Loss: 0.09005954675376415, Final Batch Loss: 0.016176199540495872\n",
      "Epoch 1659, Loss: 0.09132118988782167, Final Batch Loss: 0.04064583405852318\n",
      "Epoch 1660, Loss: 0.11392511002486572, Final Batch Loss: 0.0007468922412954271\n",
      "Epoch 1661, Loss: 0.06559704663231969, Final Batch Loss: 0.0041278572753071785\n",
      "Epoch 1662, Loss: 0.08645192580297589, Final Batch Loss: 0.009429301135241985\n",
      "Epoch 1663, Loss: 0.06955906958319247, Final Batch Loss: 0.0029253580141812563\n",
      "Epoch 1664, Loss: 0.11135540343821049, Final Batch Loss: 0.016309555619955063\n",
      "Epoch 1665, Loss: 0.17487491387873888, Final Batch Loss: 0.10261935740709305\n",
      "Epoch 1666, Loss: 0.12164197023957968, Final Batch Loss: 0.021821102127432823\n",
      "Epoch 1667, Loss: 0.1849839761853218, Final Batch Loss: 0.02765403687953949\n",
      "Epoch 1668, Loss: 0.08108701789751649, Final Batch Loss: 0.007269847672432661\n",
      "Epoch 1669, Loss: 0.13905120454728603, Final Batch Loss: 0.03412100672721863\n",
      "Epoch 1670, Loss: 0.11967853596433997, Final Batch Loss: 0.04095251113176346\n",
      "Epoch 1671, Loss: 0.1766831735149026, Final Batch Loss: 0.06666432321071625\n",
      "Epoch 1672, Loss: 0.1296948716044426, Final Batch Loss: 0.03148510679602623\n",
      "Epoch 1673, Loss: 0.09955275058746338, Final Batch Loss: 0.020305730402469635\n",
      "Epoch 1674, Loss: 0.1207807520404458, Final Batch Loss: 0.05324128270149231\n",
      "Epoch 1675, Loss: 0.05386822437867522, Final Batch Loss: 0.021933242678642273\n",
      "Epoch 1676, Loss: 0.15961745660752058, Final Batch Loss: 0.06431835144758224\n",
      "Epoch 1677, Loss: 0.09951739851385355, Final Batch Loss: 0.050955478101968765\n",
      "Epoch 1678, Loss: 0.09130369080230594, Final Batch Loss: 0.003115804400295019\n",
      "Epoch 1679, Loss: 0.15673497691750526, Final Batch Loss: 0.05483129993081093\n",
      "Epoch 1680, Loss: 0.25944483280181885, Final Batch Loss: 0.10337203741073608\n",
      "Epoch 1681, Loss: 0.1452237581834197, Final Batch Loss: 0.03755694627761841\n",
      "Epoch 1682, Loss: 0.14360291045159101, Final Batch Loss: 0.007185573689639568\n",
      "Epoch 1683, Loss: 0.1700995247811079, Final Batch Loss: 0.05698549002408981\n",
      "Epoch 1684, Loss: 0.0382388224825263, Final Batch Loss: 0.0048445165157318115\n",
      "Epoch 1685, Loss: 0.11594984587281942, Final Batch Loss: 0.00977019127458334\n",
      "Epoch 1686, Loss: 0.07634938484989107, Final Batch Loss: 0.0031041752081364393\n",
      "Epoch 1687, Loss: 0.1548425480723381, Final Batch Loss: 0.01640632003545761\n",
      "Epoch 1688, Loss: 0.08863029163330793, Final Batch Loss: 0.043808840215206146\n",
      "Epoch 1689, Loss: 0.08121951809152961, Final Batch Loss: 0.005776253994554281\n",
      "Epoch 1690, Loss: 0.07371637457981706, Final Batch Loss: 0.004935311619192362\n",
      "Epoch 1691, Loss: 0.05116464104503393, Final Batch Loss: 0.012156509794294834\n",
      "Epoch 1692, Loss: 0.08081364678218961, Final Batch Loss: 0.005261723417788744\n",
      "Epoch 1693, Loss: 0.06281432788819075, Final Batch Loss: 0.012442520819604397\n",
      "Epoch 1694, Loss: 0.09199699852615595, Final Batch Loss: 0.04374542459845543\n",
      "Epoch 1695, Loss: 0.05311874579638243, Final Batch Loss: 0.002582118846476078\n",
      "Epoch 1696, Loss: 0.06076511647552252, Final Batch Loss: 0.012258193455636501\n",
      "Epoch 1697, Loss: 0.06103913625702262, Final Batch Loss: 0.01176892314106226\n",
      "Epoch 1698, Loss: 0.0342148898052983, Final Batch Loss: 0.0009097104775719345\n",
      "Epoch 1699, Loss: 0.08771303808316588, Final Batch Loss: 0.0450420081615448\n",
      "Epoch 1700, Loss: 0.04439081018790603, Final Batch Loss: 0.016919370740652084\n",
      "Epoch 1701, Loss: 0.05968367378227413, Final Batch Loss: 0.0012748164590448141\n",
      "Epoch 1702, Loss: 0.04986173985525966, Final Batch Loss: 0.00593573646619916\n",
      "Epoch 1703, Loss: 0.08131959894672036, Final Batch Loss: 0.005400348920375109\n",
      "Epoch 1704, Loss: 0.07015690486878157, Final Batch Loss: 0.017500663176178932\n",
      "Epoch 1705, Loss: 0.06294713821262121, Final Batch Loss: 0.03137514367699623\n",
      "Epoch 1706, Loss: 0.06822391226887703, Final Batch Loss: 0.012885339558124542\n",
      "Epoch 1707, Loss: 0.12365318648517132, Final Batch Loss: 0.03912239149212837\n",
      "Epoch 1708, Loss: 0.08102755341678858, Final Batch Loss: 0.0063754357397556305\n",
      "Epoch 1709, Loss: 0.07429236406460404, Final Batch Loss: 0.030772816389799118\n",
      "Epoch 1710, Loss: 0.208129970356822, Final Batch Loss: 0.025442613288760185\n",
      "Epoch 1711, Loss: 0.09336524875834584, Final Batch Loss: 0.0051736426539719105\n",
      "Epoch 1712, Loss: 0.03578207502141595, Final Batch Loss: 0.004602191504091024\n",
      "Epoch 1713, Loss: 0.05083164758980274, Final Batch Loss: 0.01566132716834545\n",
      "Epoch 1714, Loss: 0.039473737590014935, Final Batch Loss: 0.004452915862202644\n",
      "Epoch 1715, Loss: 0.1379868253134191, Final Batch Loss: 0.0786769837141037\n",
      "Epoch 1716, Loss: 0.05543591594323516, Final Batch Loss: 0.013826689682900906\n",
      "Epoch 1717, Loss: 0.07813444919884205, Final Batch Loss: 0.021428516134619713\n",
      "Epoch 1718, Loss: 0.0657753236591816, Final Batch Loss: 0.01331657636910677\n",
      "Epoch 1719, Loss: 0.06369434902444482, Final Batch Loss: 0.00384352495893836\n",
      "Epoch 1720, Loss: 0.10754761006683111, Final Batch Loss: 0.009809986688196659\n",
      "Epoch 1721, Loss: 0.09741303976625204, Final Batch Loss: 0.006728615146130323\n",
      "Epoch 1722, Loss: 0.07534653693437576, Final Batch Loss: 0.0141979418694973\n",
      "Epoch 1723, Loss: 0.1255574468523264, Final Batch Loss: 0.0713428258895874\n",
      "Epoch 1724, Loss: 0.037099511828273535, Final Batch Loss: 0.019066734239459038\n",
      "Epoch 1725, Loss: 0.059409397770650685, Final Batch Loss: 0.0016276297392323613\n",
      "Epoch 1726, Loss: 0.04624302452430129, Final Batch Loss: 0.005029524210840464\n",
      "Epoch 1727, Loss: 0.1175569579936564, Final Batch Loss: 0.0859912633895874\n",
      "Epoch 1728, Loss: 0.04559841472655535, Final Batch Loss: 0.013640512712299824\n",
      "Epoch 1729, Loss: 0.13131312932819128, Final Batch Loss: 0.010634570382535458\n",
      "Epoch 1730, Loss: 0.05449723778292537, Final Batch Loss: 0.009778836742043495\n",
      "Epoch 1731, Loss: 0.055406002793461084, Final Batch Loss: 0.022135594859719276\n",
      "Epoch 1732, Loss: 0.07876106258481741, Final Batch Loss: 0.015373224392533302\n",
      "Epoch 1733, Loss: 0.12719057593494654, Final Batch Loss: 0.0833728164434433\n",
      "Epoch 1734, Loss: 0.1454662624746561, Final Batch Loss: 0.05259297788143158\n",
      "Epoch 1735, Loss: 0.09374711010605097, Final Batch Loss: 0.062496367841959\n",
      "Epoch 1736, Loss: 0.13235881738364697, Final Batch Loss: 0.03735905885696411\n",
      "Epoch 1737, Loss: 0.04092264152131975, Final Batch Loss: 0.0022688310127705336\n",
      "Epoch 1738, Loss: 0.03515307977795601, Final Batch Loss: 0.00538126565515995\n",
      "Epoch 1739, Loss: 0.03918411862105131, Final Batch Loss: 0.00441328389570117\n",
      "Epoch 1740, Loss: 0.0439202634152025, Final Batch Loss: 0.005308907013386488\n",
      "Epoch 1741, Loss: 0.036646457854658365, Final Batch Loss: 0.004462449345737696\n",
      "Epoch 1742, Loss: 0.04120984778273851, Final Batch Loss: 0.0017896025674417615\n",
      "Epoch 1743, Loss: 0.03370498272124678, Final Batch Loss: 0.0014663961483165622\n",
      "Epoch 1744, Loss: 0.05704106856137514, Final Batch Loss: 0.00905705988407135\n",
      "Epoch 1745, Loss: 0.03613587375730276, Final Batch Loss: 0.00523372320458293\n",
      "Epoch 1746, Loss: 0.07288275333121419, Final Batch Loss: 0.01919190213084221\n",
      "Epoch 1747, Loss: 0.07062422949820757, Final Batch Loss: 0.009053264744579792\n",
      "Epoch 1748, Loss: 0.07000572769902647, Final Batch Loss: 0.0031954662408679724\n",
      "Epoch 1749, Loss: 0.09693400096148252, Final Batch Loss: 0.05736193433403969\n",
      "Epoch 1750, Loss: 0.07022472564131021, Final Batch Loss: 0.03619571402668953\n",
      "Epoch 1751, Loss: 0.03634344204328954, Final Batch Loss: 0.0023897693026810884\n",
      "Epoch 1752, Loss: 0.07333112694323063, Final Batch Loss: 0.02498413622379303\n",
      "Epoch 1753, Loss: 0.046278465539216995, Final Batch Loss: 0.004204259254038334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1754, Loss: 0.12970346817746758, Final Batch Loss: 0.05004395917057991\n",
      "Epoch 1755, Loss: 0.08171181287616491, Final Batch Loss: 0.021969696506857872\n",
      "Epoch 1756, Loss: 0.08449243754148483, Final Batch Loss: 0.003201516345143318\n",
      "Epoch 1757, Loss: 0.09999469388276339, Final Batch Loss: 0.060548990964889526\n",
      "Epoch 1758, Loss: 0.04175038659013808, Final Batch Loss: 0.0035070476587861776\n",
      "Epoch 1759, Loss: 0.11688480246812105, Final Batch Loss: 0.012303616851568222\n",
      "Epoch 1760, Loss: 0.09121438674628735, Final Batch Loss: 0.004917812068015337\n",
      "Epoch 1761, Loss: 0.020249594934284687, Final Batch Loss: 0.0034728720784187317\n",
      "Epoch 1762, Loss: 0.0622704466804862, Final Batch Loss: 0.014260697178542614\n",
      "Epoch 1763, Loss: 0.07200082670897245, Final Batch Loss: 0.005786440335214138\n",
      "Epoch 1764, Loss: 0.06180330296047032, Final Batch Loss: 0.004475760273635387\n",
      "Epoch 1765, Loss: 0.04503426747396588, Final Batch Loss: 0.0024672900326550007\n",
      "Epoch 1766, Loss: 0.06689023226499557, Final Batch Loss: 0.006235260050743818\n",
      "Epoch 1767, Loss: 0.18049698881804943, Final Batch Loss: 0.12454133480787277\n",
      "Epoch 1768, Loss: 0.08070462103933096, Final Batch Loss: 0.00674800667911768\n",
      "Epoch 1769, Loss: 0.08189584780484438, Final Batch Loss: 0.001363258808851242\n",
      "Epoch 1770, Loss: 0.08182882610708475, Final Batch Loss: 0.016199296340346336\n",
      "Epoch 1771, Loss: 0.05323850945569575, Final Batch Loss: 0.012736178003251553\n",
      "Epoch 1772, Loss: 0.11997005250304937, Final Batch Loss: 0.0053804973140358925\n",
      "Epoch 1773, Loss: 0.06788658536970615, Final Batch Loss: 0.01674594357609749\n",
      "Epoch 1774, Loss: 0.08217940060421824, Final Batch Loss: 0.0038726232014596462\n",
      "Epoch 1775, Loss: 0.03038897318765521, Final Batch Loss: 0.004611664917320013\n",
      "Epoch 1776, Loss: 0.05191630683839321, Final Batch Loss: 0.006393527612090111\n",
      "Epoch 1777, Loss: 0.028373871347866952, Final Batch Loss: 0.0007528121350333095\n",
      "Epoch 1778, Loss: 0.05955435149371624, Final Batch Loss: 0.005930565297603607\n",
      "Epoch 1779, Loss: 0.12946024304255843, Final Batch Loss: 0.03298477828502655\n",
      "Epoch 1780, Loss: 0.03718507627490908, Final Batch Loss: 0.0010229890467599034\n",
      "Epoch 1781, Loss: 0.06428063497878611, Final Batch Loss: 0.0020412972662597895\n",
      "Epoch 1782, Loss: 0.12969263596460223, Final Batch Loss: 0.004378567915409803\n",
      "Epoch 1783, Loss: 0.13945004902780056, Final Batch Loss: 0.029978817328810692\n",
      "Epoch 1784, Loss: 0.08581525878980756, Final Batch Loss: 0.0016449452377855778\n",
      "Epoch 1785, Loss: 0.24835576117038727, Final Batch Loss: 0.0652904212474823\n",
      "Epoch 1786, Loss: 0.09295434504747391, Final Batch Loss: 0.03523818030953407\n",
      "Epoch 1787, Loss: 0.14001401886343956, Final Batch Loss: 0.054153747856616974\n",
      "Epoch 1788, Loss: 0.07104329112917185, Final Batch Loss: 0.01246882788836956\n",
      "Epoch 1789, Loss: 0.08157448749989271, Final Batch Loss: 0.01816820539534092\n",
      "Epoch 1790, Loss: 0.0658926866017282, Final Batch Loss: 0.005049871746450663\n",
      "Epoch 1791, Loss: 0.08194101974368095, Final Batch Loss: 0.0037930766120553017\n",
      "Epoch 1792, Loss: 0.08076515235006809, Final Batch Loss: 0.011207643896341324\n",
      "Epoch 1793, Loss: 0.09086931427009404, Final Batch Loss: 0.002445123391225934\n",
      "Epoch 1794, Loss: 0.13277609553188086, Final Batch Loss: 0.08658918738365173\n",
      "Epoch 1795, Loss: 0.11991693219169974, Final Batch Loss: 0.06856183707714081\n",
      "Epoch 1796, Loss: 0.08370705973356962, Final Batch Loss: 0.0160959605127573\n",
      "Epoch 1797, Loss: 0.11224664468318224, Final Batch Loss: 0.00903156865388155\n",
      "Epoch 1798, Loss: 0.10535695496946573, Final Batch Loss: 0.014544757083058357\n",
      "Epoch 1799, Loss: 0.13248829543590546, Final Batch Loss: 0.020977910608053207\n",
      "Epoch 1800, Loss: 0.08866247208788991, Final Batch Loss: 0.022181427106261253\n",
      "Epoch 1801, Loss: 0.11159602482803166, Final Batch Loss: 0.0028259933460503817\n",
      "Epoch 1802, Loss: 0.08289057854562998, Final Batch Loss: 0.00583104882389307\n",
      "Epoch 1803, Loss: 0.14002417214214802, Final Batch Loss: 0.02576889842748642\n",
      "Epoch 1804, Loss: 0.12698738276958466, Final Batch Loss: 0.02487531676888466\n",
      "Epoch 1805, Loss: 0.05170419090427458, Final Batch Loss: 0.0016887916717678308\n",
      "Epoch 1806, Loss: 0.035822564736008644, Final Batch Loss: 0.008362059481441975\n",
      "Epoch 1807, Loss: 0.07444633031263947, Final Batch Loss: 0.006016524974256754\n",
      "Epoch 1808, Loss: 0.09768942650407553, Final Batch Loss: 0.007491474039852619\n",
      "Epoch 1809, Loss: 0.07452019350603223, Final Batch Loss: 0.00442638760432601\n",
      "Epoch 1810, Loss: 0.1351884789764881, Final Batch Loss: 0.019801773130893707\n",
      "Epoch 1811, Loss: 0.0914453777950257, Final Batch Loss: 0.0031522053759545088\n",
      "Epoch 1812, Loss: 0.2567668966948986, Final Batch Loss: 0.04556558281183243\n",
      "Epoch 1813, Loss: 0.02360757626593113, Final Batch Loss: 0.004134124144911766\n",
      "Epoch 1814, Loss: 0.026156541192904115, Final Batch Loss: 0.005423687864094973\n",
      "Epoch 1815, Loss: 0.09270244557410479, Final Batch Loss: 0.007862894795835018\n",
      "Epoch 1816, Loss: 0.07895381283015013, Final Batch Loss: 0.0021034320816397667\n",
      "Epoch 1817, Loss: 0.12301413808017969, Final Batch Loss: 0.05885923281311989\n",
      "Epoch 1818, Loss: 0.22236389014869928, Final Batch Loss: 0.06986197829246521\n",
      "Epoch 1819, Loss: 0.08318024920299649, Final Batch Loss: 0.0015589450486004353\n",
      "Epoch 1820, Loss: 0.017780945170670748, Final Batch Loss: 0.0025666654109954834\n",
      "Epoch 1821, Loss: 0.038954950869083405, Final Batch Loss: 0.007281413301825523\n",
      "Epoch 1822, Loss: 0.07621696311980486, Final Batch Loss: 0.008570910431444645\n",
      "Epoch 1823, Loss: 0.10331030189990997, Final Batch Loss: 0.06503205001354218\n",
      "Epoch 1824, Loss: 0.05892563331872225, Final Batch Loss: 0.009285276755690575\n",
      "Epoch 1825, Loss: 0.1033412623219192, Final Batch Loss: 0.009637260809540749\n",
      "Epoch 1826, Loss: 0.068521877983585, Final Batch Loss: 0.002829186851158738\n",
      "Epoch 1827, Loss: 0.1547103552147746, Final Batch Loss: 0.1034553125500679\n",
      "Epoch 1828, Loss: 0.05268354434520006, Final Batch Loss: 0.0046466197818517685\n",
      "Epoch 1829, Loss: 0.08027339912950993, Final Batch Loss: 0.017348680645227432\n",
      "Epoch 1830, Loss: 0.09123685490339994, Final Batch Loss: 0.026462305337190628\n",
      "Epoch 1831, Loss: 0.1687699593603611, Final Batch Loss: 0.07777915894985199\n",
      "Epoch 1832, Loss: 0.10755355330184102, Final Batch Loss: 0.06392860412597656\n",
      "Epoch 1833, Loss: 0.06451187934726477, Final Batch Loss: 0.0025190217420458794\n",
      "Epoch 1834, Loss: 0.06186795420944691, Final Batch Loss: 0.033883336931467056\n",
      "Epoch 1835, Loss: 0.042770291212946177, Final Batch Loss: 0.009419514797627926\n",
      "Epoch 1836, Loss: 0.08066011406481266, Final Batch Loss: 0.03436390310525894\n",
      "Epoch 1837, Loss: 0.1688359323889017, Final Batch Loss: 0.01605539582669735\n",
      "Epoch 1838, Loss: 0.06654048012569547, Final Batch Loss: 0.022937437519431114\n",
      "Epoch 1839, Loss: 0.15162014588713646, Final Batch Loss: 0.0713782012462616\n",
      "Epoch 1840, Loss: 0.04904895508661866, Final Batch Loss: 0.007775477599352598\n",
      "Epoch 1841, Loss: 0.21066857129335403, Final Batch Loss: 0.04494815319776535\n",
      "Epoch 1842, Loss: 0.09705677710007876, Final Batch Loss: 0.0016783186001703143\n",
      "Epoch 1843, Loss: 0.17736863065510988, Final Batch Loss: 0.004004516638815403\n",
      "Epoch 1844, Loss: 0.1160901146940887, Final Batch Loss: 0.025299422442913055\n",
      "Epoch 1845, Loss: 0.13094375003129244, Final Batch Loss: 0.009767868556082249\n",
      "Epoch 1846, Loss: 0.16947328113019466, Final Batch Loss: 0.009735850617289543\n",
      "Epoch 1847, Loss: 0.17619702592492104, Final Batch Loss: 0.08525759726762772\n",
      "Epoch 1848, Loss: 0.1258587334305048, Final Batch Loss: 0.04645553603768349\n",
      "Epoch 1849, Loss: 0.08804098516702652, Final Batch Loss: 0.004590097814798355\n",
      "Epoch 1850, Loss: 0.07200961746275425, Final Batch Loss: 0.009245856665074825\n",
      "Epoch 1851, Loss: 0.16003340226598084, Final Batch Loss: 0.0031201664824038744\n",
      "Epoch 1852, Loss: 0.07075518416240811, Final Batch Loss: 0.04709658399224281\n",
      "Epoch 1853, Loss: 0.07046894356608391, Final Batch Loss: 0.008899874985218048\n",
      "Epoch 1854, Loss: 0.11642570700496435, Final Batch Loss: 0.043207619339227676\n",
      "Epoch 1855, Loss: 0.09567794390022755, Final Batch Loss: 0.006066536530852318\n",
      "Epoch 1856, Loss: 0.13228761963546276, Final Batch Loss: 0.003576028160750866\n",
      "Epoch 1857, Loss: 0.3400944657623768, Final Batch Loss: 0.16277775168418884\n",
      "Epoch 1858, Loss: 0.04369259579107165, Final Batch Loss: 0.010805943980813026\n",
      "Epoch 1859, Loss: 0.08283111406490207, Final Batch Loss: 0.004804431926459074\n",
      "Epoch 1860, Loss: 0.08378497790545225, Final Batch Loss: 0.004654667340219021\n",
      "Epoch 1861, Loss: 0.04487787140533328, Final Batch Loss: 0.0062906756065785885\n",
      "Epoch 1862, Loss: 0.07147255283780396, Final Batch Loss: 0.003318858565762639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1863, Loss: 0.057348924688994884, Final Batch Loss: 0.008160965517163277\n",
      "Epoch 1864, Loss: 0.12518065888434649, Final Batch Loss: 0.09320934116840363\n",
      "Epoch 1865, Loss: 0.061068106442689896, Final Batch Loss: 0.01927650161087513\n",
      "Epoch 1866, Loss: 0.08117455174215138, Final Batch Loss: 0.002676276257261634\n",
      "Epoch 1867, Loss: 0.12729049194604158, Final Batch Loss: 0.06912067532539368\n",
      "Epoch 1868, Loss: 0.06816546339541674, Final Batch Loss: 0.006866071373224258\n",
      "Epoch 1869, Loss: 0.19088790100067854, Final Batch Loss: 0.1303292214870453\n",
      "Epoch 1870, Loss: 0.23629334941506386, Final Batch Loss: 0.13826124370098114\n",
      "Epoch 1871, Loss: 0.16501742601394653, Final Batch Loss: 0.06991398334503174\n",
      "Epoch 1872, Loss: 0.07927915081381798, Final Batch Loss: 0.0028095347806811333\n",
      "Epoch 1873, Loss: 0.09515339392237365, Final Batch Loss: 0.010332188569009304\n",
      "Epoch 1874, Loss: 0.11031359015032649, Final Batch Loss: 0.06431959569454193\n",
      "Epoch 1875, Loss: 0.1224395390599966, Final Batch Loss: 0.059719134122133255\n",
      "Epoch 1876, Loss: 0.09458067640662193, Final Batch Loss: 0.029715916141867638\n",
      "Epoch 1877, Loss: 0.03375432966277003, Final Batch Loss: 0.005350038409233093\n",
      "Epoch 1878, Loss: 0.10304513294249773, Final Batch Loss: 0.02942633628845215\n",
      "Epoch 1879, Loss: 0.04974163929000497, Final Batch Loss: 0.007937095127999783\n",
      "Epoch 1880, Loss: 0.051259669940918684, Final Batch Loss: 0.00535177206620574\n",
      "Epoch 1881, Loss: 0.07637087116017938, Final Batch Loss: 0.003000427968800068\n",
      "Epoch 1882, Loss: 0.07284515351057053, Final Batch Loss: 0.015799764543771744\n",
      "Epoch 1883, Loss: 0.08649510098621249, Final Batch Loss: 0.010263379663228989\n",
      "Epoch 1884, Loss: 0.057701028883457184, Final Batch Loss: 0.0028168214485049248\n",
      "Epoch 1885, Loss: 0.041955210734158754, Final Batch Loss: 0.007491420488804579\n",
      "Epoch 1886, Loss: 0.03519194107502699, Final Batch Loss: 0.005928085185587406\n",
      "Epoch 1887, Loss: 0.027191645232960582, Final Batch Loss: 0.002227691002190113\n",
      "Epoch 1888, Loss: 0.042822418035939336, Final Batch Loss: 0.0018759167287498713\n",
      "Epoch 1889, Loss: 0.05079008173197508, Final Batch Loss: 0.016599057242274284\n",
      "Epoch 1890, Loss: 0.023087387904524803, Final Batch Loss: 0.003897571237757802\n",
      "Epoch 1891, Loss: 0.05477961106225848, Final Batch Loss: 0.0030710077844560146\n",
      "Epoch 1892, Loss: 0.04032060026656836, Final Batch Loss: 0.0015718984650447965\n",
      "Epoch 1893, Loss: 0.061738646822050214, Final Batch Loss: 0.016012007370591164\n",
      "Epoch 1894, Loss: 0.0684214779175818, Final Batch Loss: 0.032246675342321396\n",
      "Epoch 1895, Loss: 0.08426734711974859, Final Batch Loss: 0.03350300341844559\n",
      "Epoch 1896, Loss: 0.031773901311680675, Final Batch Loss: 0.0023669570218771696\n",
      "Epoch 1897, Loss: 0.038053200114518404, Final Batch Loss: 0.019336318597197533\n",
      "Epoch 1898, Loss: 0.06796325882896781, Final Batch Loss: 0.0068304468877613544\n",
      "Epoch 1899, Loss: 0.0814618831500411, Final Batch Loss: 0.008535959757864475\n",
      "Epoch 1900, Loss: 0.07680273521691561, Final Batch Loss: 0.006309074349701405\n",
      "Epoch 1901, Loss: 0.14142925012856722, Final Batch Loss: 0.08018628507852554\n",
      "Epoch 1902, Loss: 0.05440824362449348, Final Batch Loss: 0.02497244067490101\n",
      "Epoch 1903, Loss: 0.07954899966716766, Final Batch Loss: 0.030820174142718315\n",
      "Epoch 1904, Loss: 0.05515201389789581, Final Batch Loss: 0.006471253465861082\n",
      "Epoch 1905, Loss: 0.07400016905739903, Final Batch Loss: 0.024424796923995018\n",
      "Epoch 1906, Loss: 0.09229633072391152, Final Batch Loss: 0.04063167795538902\n",
      "Epoch 1907, Loss: 0.09711668582167476, Final Batch Loss: 0.0013706920435652137\n",
      "Epoch 1908, Loss: 0.0862080305814743, Final Batch Loss: 0.019967401400208473\n",
      "Epoch 1909, Loss: 0.06151260295882821, Final Batch Loss: 0.0044175912626087666\n",
      "Epoch 1910, Loss: 0.17696884647011757, Final Batch Loss: 0.08597517758607864\n",
      "Epoch 1911, Loss: 0.03956672258209437, Final Batch Loss: 0.0012688235146924853\n",
      "Epoch 1912, Loss: 0.08222217787988484, Final Batch Loss: 0.002272340701892972\n",
      "Epoch 1913, Loss: 0.0383069827221334, Final Batch Loss: 0.012779967859387398\n",
      "Epoch 1914, Loss: 0.04850802570581436, Final Batch Loss: 0.00467657670378685\n",
      "Epoch 1915, Loss: 0.06532849767245352, Final Batch Loss: 0.0013618578668683767\n",
      "Epoch 1916, Loss: 0.0882080988958478, Final Batch Loss: 0.031047126278281212\n",
      "Epoch 1917, Loss: 0.05056078778579831, Final Batch Loss: 0.0027227848768234253\n",
      "Epoch 1918, Loss: 0.10280716419219971, Final Batch Loss: 0.008954217657446861\n",
      "Epoch 1919, Loss: 0.04875674471259117, Final Batch Loss: 0.004603204317390919\n",
      "Epoch 1920, Loss: 0.02291786391288042, Final Batch Loss: 0.010380584746599197\n",
      "Epoch 1921, Loss: 0.058754279278218746, Final Batch Loss: 0.01101908553391695\n",
      "Epoch 1922, Loss: 0.10509936651214957, Final Batch Loss: 0.054759375751018524\n",
      "Epoch 1923, Loss: 0.0710451656486839, Final Batch Loss: 0.011610820889472961\n",
      "Epoch 1924, Loss: 0.05598675785586238, Final Batch Loss: 0.006739799864590168\n",
      "Epoch 1925, Loss: 0.043193165212869644, Final Batch Loss: 0.009607722982764244\n",
      "Epoch 1926, Loss: 0.06344319111667573, Final Batch Loss: 0.003433189122006297\n",
      "Epoch 1927, Loss: 0.06329431128688157, Final Batch Loss: 0.004773683380335569\n",
      "Epoch 1928, Loss: 0.08102385979145765, Final Batch Loss: 0.04040151461958885\n",
      "Epoch 1929, Loss: 0.07009878847748041, Final Batch Loss: 0.04355660453438759\n",
      "Epoch 1930, Loss: 0.07599298190325499, Final Batch Loss: 0.024214351549744606\n",
      "Epoch 1931, Loss: 0.06656903261318803, Final Batch Loss: 0.007650925777852535\n",
      "Epoch 1932, Loss: 0.15460640657693148, Final Batch Loss: 0.0531194806098938\n",
      "Epoch 1933, Loss: 0.05313019081950188, Final Batch Loss: 0.010481682606041431\n",
      "Epoch 1934, Loss: 0.05149876559153199, Final Batch Loss: 0.015520410612225533\n",
      "Epoch 1935, Loss: 0.047166897216811776, Final Batch Loss: 0.001681692199781537\n",
      "Epoch 1936, Loss: 0.02527670981362462, Final Batch Loss: 0.0018122647888958454\n",
      "Epoch 1937, Loss: 0.10063796630129218, Final Batch Loss: 0.04846828430891037\n",
      "Epoch 1938, Loss: 0.07800406776368618, Final Batch Loss: 0.002847295254468918\n",
      "Epoch 1939, Loss: 0.044100833125412464, Final Batch Loss: 0.008581295609474182\n",
      "Epoch 1940, Loss: 0.05875011906027794, Final Batch Loss: 0.017133919522166252\n",
      "Epoch 1941, Loss: 0.11272304225713015, Final Batch Loss: 0.04999783635139465\n",
      "Epoch 1942, Loss: 0.10345607018098235, Final Batch Loss: 0.053107425570487976\n",
      "Epoch 1943, Loss: 0.16985416412353516, Final Batch Loss: 0.07211138308048248\n",
      "Epoch 1944, Loss: 0.18837702739983797, Final Batch Loss: 0.14010277390480042\n",
      "Epoch 1945, Loss: 0.119144257158041, Final Batch Loss: 0.058786530047655106\n",
      "Epoch 1946, Loss: 0.1920879716053605, Final Batch Loss: 0.07973635941743851\n",
      "Epoch 1947, Loss: 0.12880231067538261, Final Batch Loss: 0.025451406836509705\n",
      "Epoch 1948, Loss: 0.07504721800796688, Final Batch Loss: 0.00232507917098701\n",
      "Epoch 1949, Loss: 0.22706089448183775, Final Batch Loss: 0.1551448106765747\n",
      "Epoch 1950, Loss: 0.11281009204685688, Final Batch Loss: 0.019598744809627533\n",
      "Epoch 1951, Loss: 0.15511722583323717, Final Batch Loss: 0.012486718595027924\n",
      "Epoch 1952, Loss: 0.12023974768817425, Final Batch Loss: 0.06313171982765198\n",
      "Epoch 1953, Loss: 0.09987430926412344, Final Batch Loss: 0.03048860840499401\n",
      "Epoch 1954, Loss: 0.03792080981656909, Final Batch Loss: 0.004332118202000856\n",
      "Epoch 1955, Loss: 0.06860170979052782, Final Batch Loss: 0.010003349743783474\n",
      "Epoch 1956, Loss: 0.2048225924372673, Final Batch Loss: 0.0478283166885376\n",
      "Epoch 1957, Loss: 0.050568406004458666, Final Batch Loss: 0.012925821356475353\n",
      "Epoch 1958, Loss: 0.14060425851494074, Final Batch Loss: 0.07922607660293579\n",
      "Epoch 1959, Loss: 0.0675224419683218, Final Batch Loss: 0.013829921372234821\n",
      "Epoch 1960, Loss: 0.07108525885269046, Final Batch Loss: 0.009424535557627678\n",
      "Epoch 1961, Loss: 0.11436085356399417, Final Batch Loss: 0.0768599882721901\n",
      "Epoch 1962, Loss: 0.09376489836722612, Final Batch Loss: 0.013431455008685589\n",
      "Epoch 1963, Loss: 0.06491207983344793, Final Batch Loss: 0.012956155464053154\n",
      "Epoch 1964, Loss: 0.11017428943887353, Final Batch Loss: 0.05025264248251915\n",
      "Epoch 1965, Loss: 0.04620594810694456, Final Batch Loss: 0.0041167400777339935\n",
      "Epoch 1966, Loss: 0.16846242593601346, Final Batch Loss: 0.006650541443377733\n",
      "Epoch 1967, Loss: 0.08636248297989368, Final Batch Loss: 0.026046618819236755\n",
      "Epoch 1968, Loss: 0.07719811983406544, Final Batch Loss: 0.0029838914051651955\n",
      "Epoch 1969, Loss: 0.11956884851679206, Final Batch Loss: 0.00646235654130578\n",
      "Epoch 1970, Loss: 0.05811834009364247, Final Batch Loss: 0.006574882194399834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1971, Loss: 0.10026167146861553, Final Batch Loss: 0.018444279208779335\n",
      "Epoch 1972, Loss: 0.054669626988470554, Final Batch Loss: 0.004278677981346846\n",
      "Epoch 1973, Loss: 0.08553368563298136, Final Batch Loss: 0.0009419746929779649\n",
      "Epoch 1974, Loss: 0.09457070380449295, Final Batch Loss: 0.009558003395795822\n",
      "Epoch 1975, Loss: 0.08267147094011307, Final Batch Loss: 0.032030802220106125\n",
      "Epoch 1976, Loss: 0.03815457923337817, Final Batch Loss: 0.0029961150139570236\n",
      "Epoch 1977, Loss: 0.058288525557145476, Final Batch Loss: 0.010355878621339798\n",
      "Epoch 1978, Loss: 0.15197061654180288, Final Batch Loss: 0.009384549222886562\n",
      "Epoch 1979, Loss: 0.06570862838998437, Final Batch Loss: 0.005684888456016779\n",
      "Epoch 1980, Loss: 0.08286022767424583, Final Batch Loss: 0.002410316839814186\n",
      "Epoch 1981, Loss: 0.18621329637244344, Final Batch Loss: 0.11236046999692917\n",
      "Epoch 1982, Loss: 0.09807586390525103, Final Batch Loss: 0.03886724263429642\n",
      "Epoch 1983, Loss: 0.15918941143900156, Final Batch Loss: 0.08417481929063797\n",
      "Epoch 1984, Loss: 0.0697584175504744, Final Batch Loss: 0.04095792397856712\n",
      "Epoch 1985, Loss: 0.08947711111977696, Final Batch Loss: 0.010425837710499763\n",
      "Epoch 1986, Loss: 0.10928041767328978, Final Batch Loss: 0.050827737897634506\n",
      "Epoch 1987, Loss: 0.04794130427762866, Final Batch Loss: 0.005187741946429014\n",
      "Epoch 1988, Loss: 0.06219695135951042, Final Batch Loss: 0.007022526115179062\n",
      "Epoch 1989, Loss: 0.11353774182498455, Final Batch Loss: 0.03350299596786499\n",
      "Epoch 1990, Loss: 0.05969930626451969, Final Batch Loss: 0.005173507146537304\n",
      "Epoch 1991, Loss: 0.05435588862746954, Final Batch Loss: 0.008638033643364906\n",
      "Epoch 1992, Loss: 0.05089359637349844, Final Batch Loss: 0.004191630985587835\n",
      "Epoch 1993, Loss: 0.15066985320299864, Final Batch Loss: 0.10286367684602737\n",
      "Epoch 1994, Loss: 0.0683599510230124, Final Batch Loss: 0.0023116115480661392\n",
      "Epoch 1995, Loss: 0.047573137329891324, Final Batch Loss: 0.001254691043868661\n",
      "Epoch 1996, Loss: 0.04433288052678108, Final Batch Loss: 0.0031599747017025948\n",
      "Epoch 1997, Loss: 0.05078104231506586, Final Batch Loss: 0.018402088433504105\n",
      "Epoch 1998, Loss: 0.07298495806753635, Final Batch Loss: 0.04481616988778114\n",
      "Epoch 1999, Loss: 0.032186541706323624, Final Batch Loss: 0.003357005538418889\n",
      "Epoch 2000, Loss: 0.04729156708344817, Final Batch Loss: 0.0125478720292449\n",
      "Epoch 2001, Loss: 0.04134687315672636, Final Batch Loss: 0.01771901734173298\n",
      "Epoch 2002, Loss: 0.029312814120203257, Final Batch Loss: 0.006982967257499695\n",
      "Epoch 2003, Loss: 0.09144736733287573, Final Batch Loss: 0.0019705016165971756\n",
      "Epoch 2004, Loss: 0.03629870910663158, Final Batch Loss: 0.0017410420114174485\n",
      "Epoch 2005, Loss: 0.08251666673459113, Final Batch Loss: 0.0334005281329155\n",
      "Epoch 2006, Loss: 0.033080745255574584, Final Batch Loss: 0.0018748084548860788\n",
      "Epoch 2007, Loss: 0.033697762759402394, Final Batch Loss: 0.0035184018779546022\n",
      "Epoch 2008, Loss: 0.044993725372478366, Final Batch Loss: 0.0023579096887260675\n",
      "Epoch 2009, Loss: 0.08166000689379871, Final Batch Loss: 0.01275328453630209\n",
      "Epoch 2010, Loss: 0.039373134495690465, Final Batch Loss: 0.0026992950588464737\n",
      "Epoch 2011, Loss: 0.05873437982518226, Final Batch Loss: 0.0018523616017773747\n",
      "Epoch 2012, Loss: 0.03248177655041218, Final Batch Loss: 0.0063216062262654305\n",
      "Epoch 2013, Loss: 0.034337945049628615, Final Batch Loss: 0.003598319599404931\n",
      "Epoch 2014, Loss: 0.03476419113576412, Final Batch Loss: 0.00829057302325964\n",
      "Epoch 2015, Loss: 0.04990900354459882, Final Batch Loss: 0.035441022366285324\n",
      "Epoch 2016, Loss: 0.09628831397276372, Final Batch Loss: 0.0011618741555139422\n",
      "Epoch 2017, Loss: 0.19233195716515183, Final Batch Loss: 0.16420955955982208\n",
      "Epoch 2018, Loss: 0.061971239279955626, Final Batch Loss: 0.000667596235871315\n",
      "Epoch 2019, Loss: 0.12037338316440582, Final Batch Loss: 0.033651940524578094\n",
      "Epoch 2020, Loss: 0.030496357940137386, Final Batch Loss: 0.01834578439593315\n",
      "Epoch 2021, Loss: 0.10213615372776985, Final Batch Loss: 0.028989186510443687\n",
      "Epoch 2022, Loss: 0.11511935433372855, Final Batch Loss: 0.004925131797790527\n",
      "Epoch 2023, Loss: 0.04014758882112801, Final Batch Loss: 0.0031090553384274244\n",
      "Epoch 2024, Loss: 0.06949903443455696, Final Batch Loss: 0.029647022485733032\n",
      "Epoch 2025, Loss: 0.05480093089863658, Final Batch Loss: 0.0052242400124669075\n",
      "Epoch 2026, Loss: 0.16489315032958984, Final Batch Loss: 0.08187562227249146\n",
      "Epoch 2027, Loss: 0.09029245772399008, Final Batch Loss: 0.0029985622968524694\n",
      "Epoch 2028, Loss: 0.09205721225589514, Final Batch Loss: 0.0061496468260884285\n",
      "Epoch 2029, Loss: 0.11285285651683807, Final Batch Loss: 0.019228411838412285\n",
      "Epoch 2030, Loss: 0.12147472985088825, Final Batch Loss: 0.01829010248184204\n",
      "Epoch 2031, Loss: 0.12383971083909273, Final Batch Loss: 0.08560138940811157\n",
      "Epoch 2032, Loss: 0.10079277958720922, Final Batch Loss: 0.03772658482193947\n",
      "Epoch 2033, Loss: 0.051415866473689675, Final Batch Loss: 0.001114437123760581\n",
      "Epoch 2034, Loss: 0.06545511959120631, Final Batch Loss: 0.002052444964647293\n",
      "Epoch 2035, Loss: 0.07299142354167998, Final Batch Loss: 0.002984248334541917\n",
      "Epoch 2036, Loss: 0.0522373802959919, Final Batch Loss: 0.00805729255080223\n",
      "Epoch 2037, Loss: 0.06301743490621448, Final Batch Loss: 0.03002573922276497\n",
      "Epoch 2038, Loss: 0.08409297233447433, Final Batch Loss: 0.00541646359488368\n",
      "Epoch 2039, Loss: 0.06355067761614919, Final Batch Loss: 0.0320875309407711\n",
      "Epoch 2040, Loss: 0.04216990014538169, Final Batch Loss: 0.0070007601752877235\n",
      "Epoch 2041, Loss: 0.06631988007575274, Final Batch Loss: 0.005664860364049673\n",
      "Epoch 2042, Loss: 0.05292777810245752, Final Batch Loss: 0.03153984248638153\n",
      "Epoch 2043, Loss: 0.11651468928903341, Final Batch Loss: 0.05412895977497101\n",
      "Epoch 2044, Loss: 0.09178559947758913, Final Batch Loss: 0.04343518242239952\n",
      "Epoch 2045, Loss: 0.07804563804529607, Final Batch Loss: 0.003421207657083869\n",
      "Epoch 2046, Loss: 0.11207882035523653, Final Batch Loss: 0.06893251836299896\n",
      "Epoch 2047, Loss: 0.0920405788347125, Final Batch Loss: 0.03879572078585625\n",
      "Epoch 2048, Loss: 0.1121286996640265, Final Batch Loss: 0.08217217773199081\n",
      "Epoch 2049, Loss: 0.03205238422378898, Final Batch Loss: 0.005190624855458736\n",
      "Epoch 2050, Loss: 0.04665381275117397, Final Batch Loss: 0.004480342380702496\n",
      "Epoch 2051, Loss: 0.09918088465929031, Final Batch Loss: 0.062213197350502014\n",
      "Epoch 2052, Loss: 0.026935290545225143, Final Batch Loss: 0.002425425685942173\n",
      "Epoch 2053, Loss: 0.017161056166514754, Final Batch Loss: 0.004392147529870272\n",
      "Epoch 2054, Loss: 0.06943273637443781, Final Batch Loss: 0.009054240770637989\n",
      "Epoch 2055, Loss: 0.02204853668808937, Final Batch Loss: 0.003496297402307391\n",
      "Epoch 2056, Loss: 0.039391325786709785, Final Batch Loss: 0.011681463569402695\n",
      "Epoch 2057, Loss: 0.07489747600629926, Final Batch Loss: 0.028876332566142082\n",
      "Epoch 2058, Loss: 0.018071513914037496, Final Batch Loss: 0.000523461087141186\n",
      "Epoch 2059, Loss: 0.0875913598574698, Final Batch Loss: 0.06072652339935303\n",
      "Epoch 2060, Loss: 0.05505476100370288, Final Batch Loss: 0.0021016658283770084\n",
      "Epoch 2061, Loss: 0.025789913488551974, Final Batch Loss: 0.003103619208559394\n",
      "Epoch 2062, Loss: 0.04319361550733447, Final Batch Loss: 0.01284460537135601\n",
      "Epoch 2063, Loss: 0.0733423032797873, Final Batch Loss: 0.03859741985797882\n",
      "Epoch 2064, Loss: 0.1265512655954808, Final Batch Loss: 0.05099177733063698\n",
      "Epoch 2065, Loss: 0.10510030435398221, Final Batch Loss: 0.0023954599164426327\n",
      "Epoch 2066, Loss: 0.07453033560886979, Final Batch Loss: 0.0017434712499380112\n",
      "Epoch 2067, Loss: 0.04544996237382293, Final Batch Loss: 0.00751458341255784\n",
      "Epoch 2068, Loss: 0.12373964581638575, Final Batch Loss: 0.004014794714748859\n",
      "Epoch 2069, Loss: 0.046298881992697716, Final Batch Loss: 0.007385361474007368\n",
      "Epoch 2070, Loss: 0.027415974531322718, Final Batch Loss: 0.0016091449651867151\n",
      "Epoch 2071, Loss: 0.03784470073878765, Final Batch Loss: 0.0027024983428418636\n",
      "Epoch 2072, Loss: 0.03400453273206949, Final Batch Loss: 0.013668746687471867\n",
      "Epoch 2073, Loss: 0.017730803170707077, Final Batch Loss: 0.0007058842456899583\n",
      "Epoch 2074, Loss: 0.08198693254962564, Final Batch Loss: 0.036587104201316833\n",
      "Epoch 2075, Loss: 0.019208905985578895, Final Batch Loss: 0.008599159307777882\n",
      "Epoch 2076, Loss: 0.06035722920205444, Final Batch Loss: 0.0017824684036895633\n",
      "Epoch 2077, Loss: 0.04848623462021351, Final Batch Loss: 0.0009587360545992851\n",
      "Epoch 2078, Loss: 0.051655842224135995, Final Batch Loss: 0.015544528141617775\n",
      "Epoch 2079, Loss: 0.08338963566347957, Final Batch Loss: 0.004003225360065699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2080, Loss: 0.030509280040860176, Final Batch Loss: 0.004226377699524164\n",
      "Epoch 2081, Loss: 0.08342174277640879, Final Batch Loss: 0.0033900472335517406\n",
      "Epoch 2082, Loss: 0.0379434903152287, Final Batch Loss: 0.003265615087002516\n",
      "Epoch 2083, Loss: 0.0739252744242549, Final Batch Loss: 0.06002325564622879\n",
      "Epoch 2084, Loss: 0.030528980190865695, Final Batch Loss: 0.0010291411308571696\n",
      "Epoch 2085, Loss: 0.07295553851872683, Final Batch Loss: 0.030779212713241577\n",
      "Epoch 2086, Loss: 0.07521053706295788, Final Batch Loss: 0.04323812201619148\n",
      "Epoch 2087, Loss: 0.04864609939977527, Final Batch Loss: 0.03469105064868927\n",
      "Epoch 2088, Loss: 0.043166490038856864, Final Batch Loss: 0.002683907048776746\n",
      "Epoch 2089, Loss: 0.1109904614277184, Final Batch Loss: 0.0698075070977211\n",
      "Epoch 2090, Loss: 0.14490940049290657, Final Batch Loss: 0.034857410937547684\n",
      "Epoch 2091, Loss: 0.09950823336839676, Final Batch Loss: 0.005401915870606899\n",
      "Epoch 2092, Loss: 0.15561634115874767, Final Batch Loss: 0.003975315019488335\n",
      "Epoch 2093, Loss: 0.0708880303427577, Final Batch Loss: 0.004452982917428017\n",
      "Epoch 2094, Loss: 0.16156863048672676, Final Batch Loss: 0.04229409247636795\n",
      "Epoch 2095, Loss: 0.07863823883235455, Final Batch Loss: 0.02132735587656498\n",
      "Epoch 2096, Loss: 0.12027118727564812, Final Batch Loss: 0.004315385594964027\n",
      "Epoch 2097, Loss: 0.18909991905093193, Final Batch Loss: 0.09122704714536667\n",
      "Epoch 2098, Loss: 0.0808276180177927, Final Batch Loss: 0.008363020606338978\n",
      "Epoch 2099, Loss: 0.14086608588695526, Final Batch Loss: 0.05706797167658806\n",
      "Epoch 2100, Loss: 0.08710197219625115, Final Batch Loss: 0.03235425055027008\n",
      "Epoch 2101, Loss: 0.04385498771443963, Final Batch Loss: 0.00634392723441124\n",
      "Epoch 2102, Loss: 0.07973472215235233, Final Batch Loss: 0.00864393450319767\n",
      "Epoch 2103, Loss: 0.09949261322617531, Final Batch Loss: 0.025038592517375946\n",
      "Epoch 2104, Loss: 0.09244557959027588, Final Batch Loss: 0.0023068434093147516\n",
      "Epoch 2105, Loss: 0.10837055742740631, Final Batch Loss: 0.030363796278834343\n",
      "Epoch 2106, Loss: 0.12688135169446468, Final Batch Loss: 0.022428570315241814\n",
      "Epoch 2107, Loss: 0.1610896736383438, Final Batch Loss: 0.08489523828029633\n",
      "Epoch 2108, Loss: 0.233356561511755, Final Batch Loss: 0.07592041045427322\n",
      "Epoch 2109, Loss: 0.07370013231411576, Final Batch Loss: 0.024634933099150658\n",
      "Epoch 2110, Loss: 0.06568203493952751, Final Batch Loss: 0.003026167396456003\n",
      "Epoch 2111, Loss: 0.03991229319944978, Final Batch Loss: 0.004544095601886511\n",
      "Epoch 2112, Loss: 0.11020985618233681, Final Batch Loss: 0.045345332473516464\n",
      "Epoch 2113, Loss: 0.09317367943003774, Final Batch Loss: 0.01520161610096693\n",
      "Epoch 2114, Loss: 0.11613785475492477, Final Batch Loss: 0.05882655084133148\n",
      "Epoch 2115, Loss: 0.11640132265165448, Final Batch Loss: 0.04501315951347351\n",
      "Epoch 2116, Loss: 0.06387471221387386, Final Batch Loss: 0.003278551623225212\n",
      "Epoch 2117, Loss: 0.05954355467110872, Final Batch Loss: 0.029759716242551804\n",
      "Epoch 2118, Loss: 0.07119268248789012, Final Batch Loss: 0.041574493050575256\n",
      "Epoch 2119, Loss: 0.0785206314176321, Final Batch Loss: 0.041855938732624054\n",
      "Epoch 2120, Loss: 0.06954233872238547, Final Batch Loss: 0.0019468233222141862\n",
      "Epoch 2121, Loss: 0.11886249762028456, Final Batch Loss: 0.014563798904418945\n",
      "Epoch 2122, Loss: 0.03662577085196972, Final Batch Loss: 0.003114987164735794\n",
      "Epoch 2123, Loss: 0.122978282161057, Final Batch Loss: 0.030256394296884537\n",
      "Epoch 2124, Loss: 0.05540089891292155, Final Batch Loss: 0.005220220889896154\n",
      "Epoch 2125, Loss: 0.042378681944683194, Final Batch Loss: 0.0032415923196822405\n",
      "Epoch 2126, Loss: 0.057347872760146856, Final Batch Loss: 0.01528500858694315\n",
      "Epoch 2127, Loss: 0.07517527230083942, Final Batch Loss: 0.004209821578115225\n",
      "Epoch 2128, Loss: 0.053342610131949186, Final Batch Loss: 0.004853517282754183\n",
      "Epoch 2129, Loss: 0.024648447521030903, Final Batch Loss: 0.009961378760635853\n",
      "Epoch 2130, Loss: 0.08550995728000998, Final Batch Loss: 0.04936138540506363\n",
      "Epoch 2131, Loss: 0.04531193571165204, Final Batch Loss: 0.005523658823221922\n",
      "Epoch 2132, Loss: 0.01847433135844767, Final Batch Loss: 0.004199295770376921\n",
      "Epoch 2133, Loss: 0.031979053281247616, Final Batch Loss: 0.004813858773559332\n",
      "Epoch 2134, Loss: 0.070109608117491, Final Batch Loss: 0.03277231752872467\n",
      "Epoch 2135, Loss: 0.08842673525214195, Final Batch Loss: 0.006990962661802769\n",
      "Epoch 2136, Loss: 0.1447436884045601, Final Batch Loss: 0.06885245442390442\n",
      "Epoch 2137, Loss: 0.023096368182450533, Final Batch Loss: 0.0030449735932052135\n",
      "Epoch 2138, Loss: 0.09887340711429715, Final Batch Loss: 0.0036181467585265636\n",
      "Epoch 2139, Loss: 0.08776714140549302, Final Batch Loss: 0.03279129043221474\n",
      "Epoch 2140, Loss: 0.023462217766791582, Final Batch Loss: 0.006121920421719551\n",
      "Epoch 2141, Loss: 0.020799610763788223, Final Batch Loss: 0.002017199993133545\n",
      "Epoch 2142, Loss: 0.04448318073991686, Final Batch Loss: 0.0005952893989160657\n",
      "Epoch 2143, Loss: 0.07289874460548162, Final Batch Loss: 0.04400508478283882\n",
      "Epoch 2144, Loss: 0.21067127585411072, Final Batch Loss: 0.06586112082004547\n",
      "Epoch 2145, Loss: 0.07810775935649872, Final Batch Loss: 0.02557201497256756\n",
      "Epoch 2146, Loss: 0.07325182692147791, Final Batch Loss: 0.0017583558801561594\n",
      "Epoch 2147, Loss: 0.11732627917081118, Final Batch Loss: 0.038190003484487534\n",
      "Epoch 2148, Loss: 0.0692244446836412, Final Batch Loss: 0.00837190542370081\n",
      "Epoch 2149, Loss: 0.0961475980002433, Final Batch Loss: 0.0024536263663321733\n",
      "Epoch 2150, Loss: 0.04916127119213343, Final Batch Loss: 0.028001947328448296\n",
      "Epoch 2151, Loss: 0.11881358176469803, Final Batch Loss: 0.033198535442352295\n",
      "Epoch 2152, Loss: 0.09074319992214441, Final Batch Loss: 0.020065441727638245\n",
      "Epoch 2153, Loss: 0.058965099044144154, Final Batch Loss: 0.011092310771346092\n",
      "Epoch 2154, Loss: 0.15246349526569247, Final Batch Loss: 0.06784778833389282\n",
      "Epoch 2155, Loss: 0.07133447797968984, Final Batch Loss: 0.009215597994625568\n",
      "Epoch 2156, Loss: 0.15798508375883102, Final Batch Loss: 0.05547430366277695\n",
      "Epoch 2157, Loss: 0.11178978532552719, Final Batch Loss: 0.08220957964658737\n",
      "Epoch 2158, Loss: 0.11782341171056032, Final Batch Loss: 0.009439618326723576\n",
      "Epoch 2159, Loss: 0.14390133321285248, Final Batch Loss: 0.023286936804652214\n",
      "Epoch 2160, Loss: 0.06516962079331279, Final Batch Loss: 0.017194228246808052\n",
      "Epoch 2161, Loss: 0.12219222111161798, Final Batch Loss: 0.0018765836721286178\n",
      "Epoch 2162, Loss: 0.12488575838506222, Final Batch Loss: 0.004010872915387154\n",
      "Epoch 2163, Loss: 0.19456339813768864, Final Batch Loss: 0.10847002267837524\n",
      "Epoch 2164, Loss: 0.18273775465786457, Final Batch Loss: 0.10860094428062439\n",
      "Epoch 2165, Loss: 0.11261852271854877, Final Batch Loss: 0.00391983799636364\n",
      "Epoch 2166, Loss: 0.09942884626798332, Final Batch Loss: 0.0038006387185305357\n",
      "Epoch 2167, Loss: 0.15545773971825838, Final Batch Loss: 0.10513156652450562\n",
      "Epoch 2168, Loss: 0.04215493495576084, Final Batch Loss: 0.002081558108329773\n",
      "Epoch 2169, Loss: 0.09289300255477428, Final Batch Loss: 0.014709822833538055\n",
      "Epoch 2170, Loss: 0.12635989114642143, Final Batch Loss: 0.03203769400715828\n",
      "Epoch 2171, Loss: 0.13749543949961662, Final Batch Loss: 0.048859093338251114\n",
      "Epoch 2172, Loss: 0.0754662505351007, Final Batch Loss: 0.006649747025221586\n",
      "Epoch 2173, Loss: 0.02852832735516131, Final Batch Loss: 0.000849918695166707\n",
      "Epoch 2174, Loss: 0.07452759612351656, Final Batch Loss: 0.005443284288048744\n",
      "Epoch 2175, Loss: 0.07115119672380388, Final Batch Loss: 0.0022181605454534292\n",
      "Epoch 2176, Loss: 0.06308151595294476, Final Batch Loss: 0.013934304006397724\n",
      "Epoch 2177, Loss: 0.04602724872529507, Final Batch Loss: 0.007907531224191189\n",
      "Epoch 2178, Loss: 0.08338907640427351, Final Batch Loss: 0.0423847958445549\n",
      "Epoch 2179, Loss: 0.11246130568906665, Final Batch Loss: 0.006695726420730352\n",
      "Epoch 2180, Loss: 0.13083977962378412, Final Batch Loss: 0.0014899816596880555\n",
      "Epoch 2181, Loss: 0.07075887592509389, Final Batch Loss: 0.007147051393985748\n",
      "Epoch 2182, Loss: 0.08306864299811423, Final Batch Loss: 0.0020612303633242846\n",
      "Epoch 2183, Loss: 0.07669773790985346, Final Batch Loss: 0.004797403700649738\n",
      "Epoch 2184, Loss: 0.0835904311388731, Final Batch Loss: 0.03297176584601402\n",
      "Epoch 2185, Loss: 0.06064626923762262, Final Batch Loss: 0.03787970170378685\n",
      "Epoch 2186, Loss: 0.0666305273771286, Final Batch Loss: 0.004594636149704456\n",
      "Epoch 2187, Loss: 0.045569999143481255, Final Batch Loss: 0.005813728552311659\n",
      "Epoch 2188, Loss: 0.10024988930672407, Final Batch Loss: 0.028067590668797493\n",
      "Epoch 2189, Loss: 0.07435303321108222, Final Batch Loss: 0.043411996215581894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2190, Loss: 0.12898967415094376, Final Batch Loss: 0.005489025264978409\n",
      "Epoch 2191, Loss: 0.04652104061096907, Final Batch Loss: 0.0076619358733296394\n",
      "Epoch 2192, Loss: 0.07022832613438368, Final Batch Loss: 0.009648616425693035\n",
      "Epoch 2193, Loss: 0.0932922400534153, Final Batch Loss: 0.0043882280588150024\n",
      "Epoch 2194, Loss: 0.06450795428827405, Final Batch Loss: 0.027346957474946976\n",
      "Epoch 2195, Loss: 0.08374541066586971, Final Batch Loss: 0.04116207733750343\n",
      "Epoch 2196, Loss: 0.1425430818926543, Final Batch Loss: 0.12622922658920288\n",
      "Epoch 2197, Loss: 0.030707523692399263, Final Batch Loss: 0.005279433447867632\n",
      "Epoch 2198, Loss: 0.03530946560204029, Final Batch Loss: 0.005979299545288086\n",
      "Epoch 2199, Loss: 0.10195173707325011, Final Batch Loss: 0.0018110295059159398\n",
      "Epoch 2200, Loss: 0.0825462113134563, Final Batch Loss: 0.05996501445770264\n",
      "Epoch 2201, Loss: 0.07227871753275394, Final Batch Loss: 0.029805680736899376\n",
      "Epoch 2202, Loss: 0.034745687851682305, Final Batch Loss: 0.0035874934401363134\n",
      "Epoch 2203, Loss: 0.07683410472236574, Final Batch Loss: 0.003033552784472704\n",
      "Epoch 2204, Loss: 0.056238047778606415, Final Batch Loss: 0.01436479389667511\n",
      "Epoch 2205, Loss: 0.0732150231488049, Final Batch Loss: 0.0029462147504091263\n",
      "Epoch 2206, Loss: 0.10380612034350634, Final Batch Loss: 0.04541819542646408\n",
      "Epoch 2207, Loss: 0.06065164878964424, Final Batch Loss: 0.016434453427791595\n",
      "Epoch 2208, Loss: 0.08848979789763689, Final Batch Loss: 0.03152115270495415\n",
      "Epoch 2209, Loss: 0.060855657793581486, Final Batch Loss: 0.01038753055036068\n",
      "Epoch 2210, Loss: 0.03398676263168454, Final Batch Loss: 0.011863435618579388\n",
      "Epoch 2211, Loss: 0.05847546411678195, Final Batch Loss: 0.006454943213611841\n",
      "Epoch 2212, Loss: 0.08655241504311562, Final Batch Loss: 0.05704037845134735\n",
      "Epoch 2213, Loss: 0.0778359854593873, Final Batch Loss: 0.012254099361598492\n",
      "Epoch 2214, Loss: 0.03973227273672819, Final Batch Loss: 0.010042540729045868\n",
      "Epoch 2215, Loss: 0.034822375513613224, Final Batch Loss: 0.010668184608221054\n",
      "Epoch 2216, Loss: 0.07103216368705034, Final Batch Loss: 0.001823541708290577\n",
      "Epoch 2217, Loss: 0.14103057235479355, Final Batch Loss: 0.0021300427615642548\n",
      "Epoch 2218, Loss: 0.11850940529257059, Final Batch Loss: 0.019461221992969513\n",
      "Epoch 2219, Loss: 0.05561068933457136, Final Batch Loss: 0.036803003400564194\n",
      "Epoch 2220, Loss: 0.15684169251471758, Final Batch Loss: 0.03510548174381256\n",
      "Epoch 2221, Loss: 0.1165704382583499, Final Batch Loss: 0.02072969451546669\n",
      "Epoch 2222, Loss: 0.08563446812331676, Final Batch Loss: 0.005535732954740524\n",
      "Epoch 2223, Loss: 0.04756776872090995, Final Batch Loss: 0.0020830591674894094\n",
      "Epoch 2224, Loss: 0.087919807061553, Final Batch Loss: 0.03751528263092041\n",
      "Epoch 2225, Loss: 0.022790602641180158, Final Batch Loss: 0.004313494078814983\n",
      "Epoch 2226, Loss: 0.05730763357132673, Final Batch Loss: 0.03130638599395752\n",
      "Epoch 2227, Loss: 0.13382405135780573, Final Batch Loss: 0.008630299009382725\n",
      "Epoch 2228, Loss: 0.04282854916527867, Final Batch Loss: 0.012536766938865185\n",
      "Epoch 2229, Loss: 0.13656566478312016, Final Batch Loss: 0.07730520516633987\n",
      "Epoch 2230, Loss: 0.052615078166127205, Final Batch Loss: 0.015737613663077354\n",
      "Epoch 2231, Loss: 0.07924309326335788, Final Batch Loss: 0.030859407037496567\n",
      "Epoch 2232, Loss: 0.08741624979302287, Final Batch Loss: 0.0628119632601738\n",
      "Epoch 2233, Loss: 0.07047264790162444, Final Batch Loss: 0.05176495015621185\n",
      "Epoch 2234, Loss: 0.14954283460974693, Final Batch Loss: 0.009940389543771744\n",
      "Epoch 2235, Loss: 0.12403699290007353, Final Batch Loss: 0.05889866501092911\n",
      "Epoch 2236, Loss: 0.1775802355259657, Final Batch Loss: 0.03842964395880699\n",
      "Epoch 2237, Loss: 0.1672483365982771, Final Batch Loss: 0.03487250953912735\n",
      "Epoch 2238, Loss: 0.15448916982859373, Final Batch Loss: 0.09515842795372009\n",
      "Epoch 2239, Loss: 0.16231075022369623, Final Batch Loss: 0.09972255676984787\n",
      "Epoch 2240, Loss: 0.10450586769729853, Final Batch Loss: 0.040313273668289185\n",
      "Epoch 2241, Loss: 0.08399490360170603, Final Batch Loss: 0.004773086868226528\n",
      "Epoch 2242, Loss: 0.12943024840205908, Final Batch Loss: 0.006986710242927074\n",
      "Epoch 2243, Loss: 0.1558927483856678, Final Batch Loss: 0.04671704024076462\n",
      "Epoch 2244, Loss: 0.09896487183868885, Final Batch Loss: 0.013638773933053017\n",
      "Epoch 2245, Loss: 0.07293532509356737, Final Batch Loss: 0.022153308615088463\n",
      "Epoch 2246, Loss: 0.06551759783178568, Final Batch Loss: 0.019155362620949745\n",
      "Epoch 2247, Loss: 0.07848277385346591, Final Batch Loss: 0.00209719012491405\n",
      "Epoch 2248, Loss: 0.09394178446382284, Final Batch Loss: 0.007440310902893543\n",
      "Epoch 2249, Loss: 0.061707207933068275, Final Batch Loss: 0.023174062371253967\n",
      "Epoch 2250, Loss: 0.039027982391417027, Final Batch Loss: 0.00831020250916481\n",
      "Epoch 2251, Loss: 0.09778048982843757, Final Batch Loss: 0.0060678510926663876\n",
      "Epoch 2252, Loss: 0.045074296183884144, Final Batch Loss: 0.009932099841535091\n",
      "Epoch 2253, Loss: 0.07263562432490289, Final Batch Loss: 0.0020097580272704363\n",
      "Epoch 2254, Loss: 0.06613780651241541, Final Batch Loss: 0.01187372487038374\n",
      "Epoch 2255, Loss: 0.049516227561980486, Final Batch Loss: 0.0031733401119709015\n",
      "Epoch 2256, Loss: 0.07683811918832362, Final Batch Loss: 0.019944284111261368\n",
      "Epoch 2257, Loss: 0.20160299446433783, Final Batch Loss: 0.0808112695813179\n",
      "Epoch 2258, Loss: 0.10769301932305098, Final Batch Loss: 0.050425272434949875\n",
      "Epoch 2259, Loss: 0.11934599466621876, Final Batch Loss: 0.03191482275724411\n",
      "Epoch 2260, Loss: 0.036356642842292786, Final Batch Loss: 0.0038569197058677673\n",
      "Epoch 2261, Loss: 0.07908029318787158, Final Batch Loss: 0.0029489428270608187\n",
      "Epoch 2262, Loss: 0.054670846089720726, Final Batch Loss: 0.005896225571632385\n",
      "Epoch 2263, Loss: 0.09414610685780644, Final Batch Loss: 0.011134650558233261\n",
      "Epoch 2264, Loss: 0.044878498651087284, Final Batch Loss: 0.02058214507997036\n",
      "Epoch 2265, Loss: 0.10308587457984686, Final Batch Loss: 0.06190445274114609\n",
      "Epoch 2266, Loss: 0.04566923715174198, Final Batch Loss: 0.013358956202864647\n",
      "Epoch 2267, Loss: 0.06455167150124907, Final Batch Loss: 0.0030598784796893597\n",
      "Epoch 2268, Loss: 0.1000232333317399, Final Batch Loss: 0.025944825261831284\n",
      "Epoch 2269, Loss: 0.082459413446486, Final Batch Loss: 0.0028724921867251396\n",
      "Epoch 2270, Loss: 0.11930062808096409, Final Batch Loss: 0.014402512460947037\n",
      "Epoch 2271, Loss: 0.09939775243401527, Final Batch Loss: 0.03426755219697952\n",
      "Epoch 2272, Loss: 0.08163151005282998, Final Batch Loss: 0.04501247778534889\n",
      "Epoch 2273, Loss: 0.08517133351415396, Final Batch Loss: 0.00635798554867506\n",
      "Epoch 2274, Loss: 0.07832297123968601, Final Batch Loss: 0.0056317709386348724\n",
      "Epoch 2275, Loss: 0.09952801838517189, Final Batch Loss: 0.03955401852726936\n",
      "Epoch 2276, Loss: 0.10887114237993956, Final Batch Loss: 0.023157494142651558\n",
      "Epoch 2277, Loss: 0.05785081838257611, Final Batch Loss: 0.0018143069464713335\n",
      "Epoch 2278, Loss: 0.08702855464071035, Final Batch Loss: 0.00809916015714407\n",
      "Epoch 2279, Loss: 0.10499372333288193, Final Batch Loss: 0.029642710462212563\n",
      "Epoch 2280, Loss: 0.10517441015690565, Final Batch Loss: 0.03168021887540817\n",
      "Epoch 2281, Loss: 0.07670037308707833, Final Batch Loss: 0.029253508895635605\n",
      "Epoch 2282, Loss: 0.07752852188423276, Final Batch Loss: 0.003774181939661503\n",
      "Epoch 2283, Loss: 0.1098622870631516, Final Batch Loss: 0.06733603030443192\n",
      "Epoch 2284, Loss: 0.11716169450664893, Final Batch Loss: 0.0003142185159958899\n",
      "Epoch 2285, Loss: 0.07687721028923988, Final Batch Loss: 0.012880058027803898\n",
      "Epoch 2286, Loss: 0.04305487917736173, Final Batch Loss: 0.006747065577656031\n",
      "Epoch 2287, Loss: 0.13628438487648964, Final Batch Loss: 0.016300562769174576\n",
      "Epoch 2288, Loss: 0.11422261130064726, Final Batch Loss: 0.0020809778943657875\n",
      "Epoch 2289, Loss: 0.0519273467361927, Final Batch Loss: 0.008601137436926365\n",
      "Epoch 2290, Loss: 0.11326864873990417, Final Batch Loss: 0.053057022392749786\n",
      "Epoch 2291, Loss: 0.15872998908162117, Final Batch Loss: 0.08771961182355881\n",
      "Epoch 2292, Loss: 0.03855242161080241, Final Batch Loss: 0.0067497133277356625\n",
      "Epoch 2293, Loss: 0.16989140398800373, Final Batch Loss: 0.11108695715665817\n",
      "Epoch 2294, Loss: 0.10391055420041084, Final Batch Loss: 0.010305887088179588\n",
      "Epoch 2295, Loss: 0.064179343637079, Final Batch Loss: 0.006815373431891203\n",
      "Epoch 2296, Loss: 0.07277608336880803, Final Batch Loss: 0.014500128105282784\n",
      "Epoch 2297, Loss: 0.05059273960068822, Final Batch Loss: 0.006351029966026545\n",
      "Epoch 2298, Loss: 0.0815235492773354, Final Batch Loss: 0.02232552133500576\n",
      "Epoch 2299, Loss: 0.1175378808984533, Final Batch Loss: 0.0015257062623277307\n",
      "Epoch 2300, Loss: 0.07034367974847555, Final Batch Loss: 0.014088263735175133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2301, Loss: 0.08961727377027273, Final Batch Loss: 0.051779601722955704\n",
      "Epoch 2302, Loss: 0.14976062439382076, Final Batch Loss: 0.0833355113863945\n",
      "Epoch 2303, Loss: 0.10167225915938616, Final Batch Loss: 0.07127568125724792\n",
      "Epoch 2304, Loss: 0.042810064274817705, Final Batch Loss: 0.01407411228865385\n",
      "Epoch 2305, Loss: 0.08781890198588371, Final Batch Loss: 0.014857569709420204\n",
      "Epoch 2306, Loss: 0.09049786441028118, Final Batch Loss: 0.036861225962638855\n",
      "Epoch 2307, Loss: 0.04883311316370964, Final Batch Loss: 0.004724364727735519\n",
      "Epoch 2308, Loss: 0.08764654537662864, Final Batch Loss: 0.0020997957326471806\n",
      "Epoch 2309, Loss: 0.09029410500079393, Final Batch Loss: 0.01178810652345419\n",
      "Epoch 2310, Loss: 0.07449846807867289, Final Batch Loss: 0.02660665102303028\n",
      "Epoch 2311, Loss: 0.1579484809190035, Final Batch Loss: 0.07008928805589676\n",
      "Epoch 2312, Loss: 0.10785194672644138, Final Batch Loss: 0.04779912531375885\n",
      "Epoch 2313, Loss: 0.03221537568606436, Final Batch Loss: 0.0012602463830262423\n",
      "Epoch 2314, Loss: 0.06794569687917829, Final Batch Loss: 0.02896808087825775\n",
      "Epoch 2315, Loss: 0.05790072027593851, Final Batch Loss: 0.004392607603222132\n",
      "Epoch 2316, Loss: 0.1677183322608471, Final Batch Loss: 0.047827355563640594\n",
      "Epoch 2317, Loss: 0.09316987311467528, Final Batch Loss: 0.04191536456346512\n",
      "Epoch 2318, Loss: 0.048434847965836525, Final Batch Loss: 0.004571136087179184\n",
      "Epoch 2319, Loss: 0.07132252119481564, Final Batch Loss: 0.013061796315014362\n",
      "Epoch 2320, Loss: 0.05048851715400815, Final Batch Loss: 0.0076604182831943035\n",
      "Epoch 2321, Loss: 0.04394055949524045, Final Batch Loss: 0.003023311961442232\n",
      "Epoch 2322, Loss: 0.04744752147234976, Final Batch Loss: 0.003106120740994811\n",
      "Epoch 2323, Loss: 0.03093021037057042, Final Batch Loss: 0.007807168178260326\n",
      "Epoch 2324, Loss: 0.07460281474050134, Final Batch Loss: 0.0026930079329758883\n",
      "Epoch 2325, Loss: 0.056939421221613884, Final Batch Loss: 0.003937435336410999\n",
      "Epoch 2326, Loss: 0.059027942130342126, Final Batch Loss: 0.004886866547167301\n",
      "Epoch 2327, Loss: 0.07758805644698441, Final Batch Loss: 0.004026975482702255\n",
      "Epoch 2328, Loss: 0.06292108772322536, Final Batch Loss: 0.012351916171610355\n",
      "Epoch 2329, Loss: 0.05707270000129938, Final Batch Loss: 0.0034999391064047813\n",
      "Epoch 2330, Loss: 0.10025097266770899, Final Batch Loss: 0.0010671813506633043\n",
      "Epoch 2331, Loss: 0.10976284462958574, Final Batch Loss: 0.01121471170336008\n",
      "Epoch 2332, Loss: 0.05461623892188072, Final Batch Loss: 0.0012141643092036247\n",
      "Epoch 2333, Loss: 0.11015204945579171, Final Batch Loss: 0.0012313579209148884\n",
      "Epoch 2334, Loss: 0.04486579913645983, Final Batch Loss: 0.02520802803337574\n",
      "Epoch 2335, Loss: 0.053335633827373385, Final Batch Loss: 0.027635779231786728\n",
      "Epoch 2336, Loss: 0.05584605864714831, Final Batch Loss: 0.0012547628721222281\n",
      "Epoch 2337, Loss: 0.03073231573216617, Final Batch Loss: 0.0030373551417142153\n",
      "Epoch 2338, Loss: 0.0881182486191392, Final Batch Loss: 0.029104536399245262\n",
      "Epoch 2339, Loss: 0.038251137477345765, Final Batch Loss: 0.0017305343644693494\n",
      "Epoch 2340, Loss: 0.09923843201249838, Final Batch Loss: 0.05751423165202141\n",
      "Epoch 2341, Loss: 0.11184570356272161, Final Batch Loss: 0.08120067417621613\n",
      "Epoch 2342, Loss: 0.10951143316924572, Final Batch Loss: 0.08374658226966858\n",
      "Epoch 2343, Loss: 0.0625804141163826, Final Batch Loss: 0.014871357940137386\n",
      "Epoch 2344, Loss: 0.03850636619608849, Final Batch Loss: 0.001017063739709556\n",
      "Epoch 2345, Loss: 0.11589007056318223, Final Batch Loss: 0.0019409351516515017\n",
      "Epoch 2346, Loss: 0.1644271370023489, Final Batch Loss: 0.06396707892417908\n",
      "Epoch 2347, Loss: 0.08911575376987457, Final Batch Loss: 0.013785981573164463\n",
      "Epoch 2348, Loss: 0.058205241337418556, Final Batch Loss: 0.002444102428853512\n",
      "Epoch 2349, Loss: 0.08936267998069525, Final Batch Loss: 0.01893467642366886\n",
      "Epoch 2350, Loss: 0.16820942144840956, Final Batch Loss: 0.07928955554962158\n",
      "Epoch 2351, Loss: 0.03678466333076358, Final Batch Loss: 0.003115674015134573\n",
      "Epoch 2352, Loss: 0.060577048221603036, Final Batch Loss: 0.0034515762235969305\n",
      "Epoch 2353, Loss: 0.12060261284932494, Final Batch Loss: 0.07217895239591599\n",
      "Epoch 2354, Loss: 0.09390781400725245, Final Batch Loss: 0.02953258529305458\n",
      "Epoch 2355, Loss: 0.08437499031424522, Final Batch Loss: 0.017131172120571136\n",
      "Epoch 2356, Loss: 0.07307653012685478, Final Batch Loss: 0.0031978206243366003\n",
      "Epoch 2357, Loss: 0.2263861270621419, Final Batch Loss: 0.06376049667596817\n",
      "Epoch 2358, Loss: 0.03068845020607114, Final Batch Loss: 0.006482393015176058\n",
      "Epoch 2359, Loss: 0.11135484371334314, Final Batch Loss: 0.014751286245882511\n",
      "Epoch 2360, Loss: 0.06306269019842148, Final Batch Loss: 0.03524695336818695\n",
      "Epoch 2361, Loss: 0.1205123895779252, Final Batch Loss: 0.06021541729569435\n",
      "Epoch 2362, Loss: 0.059064984787255526, Final Batch Loss: 0.00587428780272603\n",
      "Epoch 2363, Loss: 0.0707149391528219, Final Batch Loss: 0.0027245113160461187\n",
      "Epoch 2364, Loss: 0.03739959606900811, Final Batch Loss: 0.007824025116860867\n",
      "Epoch 2365, Loss: 0.06422838103026152, Final Batch Loss: 0.014600853435695171\n",
      "Epoch 2366, Loss: 0.09195305407047272, Final Batch Loss: 0.006563542410731316\n",
      "Epoch 2367, Loss: 0.09409270016476512, Final Batch Loss: 0.010641262866556644\n",
      "Epoch 2368, Loss: 0.038527547381818295, Final Batch Loss: 0.02177985943853855\n",
      "Epoch 2369, Loss: 0.051051765913143754, Final Batch Loss: 0.00216798041947186\n",
      "Epoch 2370, Loss: 0.105107675306499, Final Batch Loss: 0.036882247775793076\n",
      "Epoch 2371, Loss: 0.049198011634871364, Final Batch Loss: 0.02255542390048504\n",
      "Epoch 2372, Loss: 0.06973704695701599, Final Batch Loss: 0.004018389154225588\n",
      "Epoch 2373, Loss: 0.0768136684782803, Final Batch Loss: 0.03370986506342888\n",
      "Epoch 2374, Loss: 0.04142427758779377, Final Batch Loss: 0.0019455434521660209\n",
      "Epoch 2375, Loss: 0.07579976739361882, Final Batch Loss: 0.05120028927922249\n",
      "Epoch 2376, Loss: 0.09099631942808628, Final Batch Loss: 0.022006234154105186\n",
      "Epoch 2377, Loss: 0.05854392284527421, Final Batch Loss: 0.003997412510216236\n",
      "Epoch 2378, Loss: 0.16272882372140884, Final Batch Loss: 0.031296100467443466\n",
      "Epoch 2379, Loss: 0.07834902685135603, Final Batch Loss: 0.03659196197986603\n",
      "Epoch 2380, Loss: 0.09299029316753149, Final Batch Loss: 0.00419184286147356\n",
      "Epoch 2381, Loss: 0.10074389539659023, Final Batch Loss: 0.005188463255763054\n",
      "Epoch 2382, Loss: 0.10608347784727812, Final Batch Loss: 0.013787196017801762\n",
      "Epoch 2383, Loss: 0.07444365881383419, Final Batch Loss: 0.038968320935964584\n",
      "Epoch 2384, Loss: 0.062177454587072134, Final Batch Loss: 0.011319792829453945\n",
      "Epoch 2385, Loss: 0.2948421314358711, Final Batch Loss: 0.09976356476545334\n",
      "Epoch 2386, Loss: 0.18834947422146797, Final Batch Loss: 0.04435557499527931\n",
      "Epoch 2387, Loss: 0.10178468376398087, Final Batch Loss: 0.008130182512104511\n",
      "Epoch 2388, Loss: 0.16872956976294518, Final Batch Loss: 0.05955425649881363\n",
      "Epoch 2389, Loss: 0.09316642209887505, Final Batch Loss: 0.028665225952863693\n",
      "Epoch 2390, Loss: 0.21058909595012665, Final Batch Loss: 0.04394100233912468\n",
      "Epoch 2391, Loss: 0.1725191529840231, Final Batch Loss: 0.03904078155755997\n",
      "Epoch 2392, Loss: 0.11464130599051714, Final Batch Loss: 0.005248562432825565\n",
      "Epoch 2393, Loss: 0.09063983708620071, Final Batch Loss: 0.0276432354003191\n",
      "Epoch 2394, Loss: 0.15595195163041353, Final Batch Loss: 0.008790352381765842\n",
      "Epoch 2395, Loss: 0.17550735268741846, Final Batch Loss: 0.09476763010025024\n",
      "Epoch 2396, Loss: 0.13636107183992863, Final Batch Loss: 0.050862763077020645\n",
      "Epoch 2397, Loss: 0.08709272369742393, Final Batch Loss: 0.014218490570783615\n",
      "Epoch 2398, Loss: 0.20631958171725273, Final Batch Loss: 0.06102224439382553\n",
      "Epoch 2399, Loss: 0.0895270649343729, Final Batch Loss: 0.03021075949072838\n",
      "Epoch 2400, Loss: 0.15773005224764347, Final Batch Loss: 0.045805368572473526\n",
      "Epoch 2401, Loss: 0.1273144967854023, Final Batch Loss: 0.03412802517414093\n",
      "Epoch 2402, Loss: 0.09620129270479083, Final Batch Loss: 0.006758182309567928\n",
      "Epoch 2403, Loss: 0.110187117010355, Final Batch Loss: 0.0826340839266777\n",
      "Epoch 2404, Loss: 0.11689776368439198, Final Batch Loss: 0.03406626731157303\n",
      "Epoch 2405, Loss: 0.16200485359877348, Final Batch Loss: 0.036751944571733475\n",
      "Epoch 2406, Loss: 0.09385539218783379, Final Batch Loss: 0.016314955428242683\n",
      "Epoch 2407, Loss: 0.15960183646529913, Final Batch Loss: 0.056698452681303024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2408, Loss: 0.1627423381432891, Final Batch Loss: 0.09112141281366348\n",
      "Epoch 2409, Loss: 0.0878866370767355, Final Batch Loss: 0.01706467568874359\n",
      "Epoch 2410, Loss: 0.24156639724969864, Final Batch Loss: 0.07728224247694016\n",
      "Epoch 2411, Loss: 0.2542509790509939, Final Batch Loss: 0.13683439791202545\n",
      "Epoch 2412, Loss: 0.14335685037076473, Final Batch Loss: 0.030211886391043663\n",
      "Epoch 2413, Loss: 0.3391311839222908, Final Batch Loss: 0.07802249491214752\n",
      "Epoch 2414, Loss: 0.07635550294071436, Final Batch Loss: 0.012672350741922855\n",
      "Epoch 2415, Loss: 0.1142314225435257, Final Batch Loss: 0.03814402595162392\n",
      "Epoch 2416, Loss: 0.1598187480121851, Final Batch Loss: 0.10719441622495651\n",
      "Epoch 2417, Loss: 0.13622459303587675, Final Batch Loss: 0.08263453096151352\n",
      "Epoch 2418, Loss: 0.1159826465882361, Final Batch Loss: 0.007151948753744364\n",
      "Epoch 2419, Loss: 0.07889532903209329, Final Batch Loss: 0.006016153376549482\n",
      "Epoch 2420, Loss: 0.0965382931753993, Final Batch Loss: 0.0046760765835642815\n",
      "Epoch 2421, Loss: 0.0836555534042418, Final Batch Loss: 0.0030900374986231327\n",
      "Epoch 2422, Loss: 0.06853763107210398, Final Batch Loss: 0.020023159682750702\n",
      "Epoch 2423, Loss: 0.18720590602606535, Final Batch Loss: 0.13825905323028564\n",
      "Epoch 2424, Loss: 0.10399210825562477, Final Batch Loss: 0.012523367069661617\n",
      "Epoch 2425, Loss: 0.06122553255409002, Final Batch Loss: 0.004781516268849373\n",
      "Epoch 2426, Loss: 0.12595384567975998, Final Batch Loss: 0.023120982572436333\n",
      "Epoch 2427, Loss: 0.07200469728559256, Final Batch Loss: 0.034833356738090515\n",
      "Epoch 2428, Loss: 0.14796750945970416, Final Batch Loss: 0.10633290559053421\n",
      "Epoch 2429, Loss: 0.11936362041160464, Final Batch Loss: 0.004322109278291464\n",
      "Epoch 2430, Loss: 0.16933608707040548, Final Batch Loss: 0.013171444647014141\n",
      "Epoch 2431, Loss: 0.16269459016621113, Final Batch Loss: 0.09170844405889511\n",
      "Epoch 2432, Loss: 0.1398718529380858, Final Batch Loss: 0.014816413633525372\n",
      "Epoch 2433, Loss: 0.14813884254544973, Final Batch Loss: 0.036360401660203934\n",
      "Epoch 2434, Loss: 0.08394006453454494, Final Batch Loss: 0.005129672586917877\n",
      "Epoch 2435, Loss: 0.20118267089128494, Final Batch Loss: 0.09502483159303665\n",
      "Epoch 2436, Loss: 0.04785770666785538, Final Batch Loss: 0.0074778213165700436\n",
      "Epoch 2437, Loss: 0.06736483331769705, Final Batch Loss: 0.004929283633828163\n",
      "Epoch 2438, Loss: 0.11447980208322406, Final Batch Loss: 0.0036351638846099377\n",
      "Epoch 2439, Loss: 0.07354051433503628, Final Batch Loss: 0.013729427009820938\n",
      "Epoch 2440, Loss: 0.06434964761137962, Final Batch Loss: 0.012441249564290047\n",
      "Epoch 2441, Loss: 0.05016898736357689, Final Batch Loss: 0.004062289372086525\n",
      "Epoch 2442, Loss: 0.07683026161976159, Final Batch Loss: 0.0011359087657183409\n",
      "Epoch 2443, Loss: 0.15761274844408035, Final Batch Loss: 0.055265314877033234\n",
      "Epoch 2444, Loss: 0.04551402060315013, Final Batch Loss: 0.014070321805775166\n",
      "Epoch 2445, Loss: 0.06562186847440898, Final Batch Loss: 0.00295900902710855\n",
      "Epoch 2446, Loss: 0.0639359150081873, Final Batch Loss: 0.019310563802719116\n",
      "Epoch 2447, Loss: 0.03242681920528412, Final Batch Loss: 0.0025418857112526894\n",
      "Epoch 2448, Loss: 0.047386350110173225, Final Batch Loss: 0.009934925474226475\n",
      "Epoch 2449, Loss: 0.06107301986776292, Final Batch Loss: 0.01271363627165556\n",
      "Epoch 2450, Loss: 0.0684060133062303, Final Batch Loss: 0.020728573203086853\n",
      "Epoch 2451, Loss: 0.05646420503035188, Final Batch Loss: 0.013709468767046928\n",
      "Epoch 2452, Loss: 0.05267638363875449, Final Batch Loss: 0.0019740888383239508\n",
      "Epoch 2453, Loss: 0.06457877485081553, Final Batch Loss: 0.0022998335771262646\n",
      "Epoch 2454, Loss: 0.0395059771835804, Final Batch Loss: 0.011297017335891724\n",
      "Epoch 2455, Loss: 0.10079019423574209, Final Batch Loss: 0.04432345926761627\n",
      "Epoch 2456, Loss: 0.06546345539391041, Final Batch Loss: 0.00837219599634409\n",
      "Epoch 2457, Loss: 0.09443743666633964, Final Batch Loss: 0.0020576040260493755\n",
      "Epoch 2458, Loss: 0.1792294718325138, Final Batch Loss: 0.12249288707971573\n",
      "Epoch 2459, Loss: 0.06818056479096413, Final Batch Loss: 0.0068757967092096806\n",
      "Epoch 2460, Loss: 0.05463614221662283, Final Batch Loss: 0.005746176466345787\n",
      "Epoch 2461, Loss: 0.06218501180410385, Final Batch Loss: 0.0045902119018137455\n",
      "Epoch 2462, Loss: 0.06848742184229195, Final Batch Loss: 0.002712619723752141\n",
      "Epoch 2463, Loss: 0.040990729350596666, Final Batch Loss: 0.007530439179390669\n",
      "Epoch 2464, Loss: 0.06991339800879359, Final Batch Loss: 0.004229116719216108\n",
      "Epoch 2465, Loss: 0.09139405377209187, Final Batch Loss: 0.07200611382722855\n",
      "Epoch 2466, Loss: 0.056111662881448865, Final Batch Loss: 0.0024557162541896105\n",
      "Epoch 2467, Loss: 0.07956488523632288, Final Batch Loss: 0.013199348002672195\n",
      "Epoch 2468, Loss: 0.09712037956342101, Final Batch Loss: 0.004458780866116285\n",
      "Epoch 2469, Loss: 0.1285882769152522, Final Batch Loss: 0.0036990949884057045\n",
      "Epoch 2470, Loss: 0.05199041869491339, Final Batch Loss: 0.002188272774219513\n",
      "Epoch 2471, Loss: 0.07024636678397655, Final Batch Loss: 0.011231529526412487\n",
      "Epoch 2472, Loss: 0.08191603980958462, Final Batch Loss: 0.04037822410464287\n",
      "Epoch 2473, Loss: 0.06022588652558625, Final Batch Loss: 0.002924490487203002\n",
      "Epoch 2474, Loss: 0.05315784434787929, Final Batch Loss: 0.0037354787345975637\n",
      "Epoch 2475, Loss: 0.13332758797332644, Final Batch Loss: 0.003349966835230589\n",
      "Epoch 2476, Loss: 0.0779916737228632, Final Batch Loss: 0.008344952948391438\n",
      "Epoch 2477, Loss: 0.06729153217747808, Final Batch Loss: 0.01424457784742117\n",
      "Epoch 2478, Loss: 0.050616946537047625, Final Batch Loss: 0.001609573606401682\n",
      "Epoch 2479, Loss: 0.04434320190921426, Final Batch Loss: 0.005388351622968912\n",
      "Epoch 2480, Loss: 0.05407888349145651, Final Batch Loss: 0.025929290801286697\n",
      "Epoch 2481, Loss: 0.10579704120755196, Final Batch Loss: 0.07999220490455627\n",
      "Epoch 2482, Loss: 0.026215434540063143, Final Batch Loss: 0.009053231216967106\n",
      "Epoch 2483, Loss: 0.05385354004101828, Final Batch Loss: 0.0009722826653160155\n",
      "Epoch 2484, Loss: 0.021486270532477647, Final Batch Loss: 0.0008232019026763737\n",
      "Epoch 2485, Loss: 0.1027263943105936, Final Batch Loss: 0.03886891528964043\n",
      "Epoch 2486, Loss: 0.025103737600147724, Final Batch Loss: 0.004999931901693344\n",
      "Epoch 2487, Loss: 0.07159554935060441, Final Batch Loss: 0.003698924323543906\n",
      "Epoch 2488, Loss: 0.051173142390325665, Final Batch Loss: 0.001872877823188901\n",
      "Epoch 2489, Loss: 0.03384408447891474, Final Batch Loss: 0.0022390824742615223\n",
      "Epoch 2490, Loss: 0.05640891054645181, Final Batch Loss: 0.008071521297097206\n",
      "Epoch 2491, Loss: 0.05305517511442304, Final Batch Loss: 0.009347428567707539\n",
      "Epoch 2492, Loss: 0.020480119506828487, Final Batch Loss: 0.0017244367627426982\n",
      "Epoch 2493, Loss: 0.06469562789425254, Final Batch Loss: 0.010654963552951813\n",
      "Epoch 2494, Loss: 0.07189436350017786, Final Batch Loss: 0.01474425382912159\n",
      "Epoch 2495, Loss: 0.03575673000887036, Final Batch Loss: 0.006927677430212498\n",
      "Epoch 2496, Loss: 0.020091398851945996, Final Batch Loss: 0.002685670042410493\n",
      "Epoch 2497, Loss: 0.06820380897261202, Final Batch Loss: 0.03757067769765854\n",
      "Epoch 2498, Loss: 0.028775544837117195, Final Batch Loss: 0.012018929235637188\n",
      "Epoch 2499, Loss: 0.04136327235028148, Final Batch Loss: 0.0035193355288356543\n",
      "Epoch 2500, Loss: 0.060489302733913064, Final Batch Loss: 0.0028491674456745386\n",
      "Epoch 2501, Loss: 0.13924269657582045, Final Batch Loss: 0.07944638282060623\n",
      "Epoch 2502, Loss: 0.051125351106747985, Final Batch Loss: 0.004492130130529404\n",
      "Epoch 2503, Loss: 0.0654633091762662, Final Batch Loss: 0.008381546474993229\n",
      "Epoch 2504, Loss: 0.050688112154603004, Final Batch Loss: 0.004591069649904966\n",
      "Epoch 2505, Loss: 0.08127688616514206, Final Batch Loss: 0.02864226885139942\n",
      "Epoch 2506, Loss: 0.047331481240689754, Final Batch Loss: 0.011233596131205559\n",
      "Epoch 2507, Loss: 0.0568245523609221, Final Batch Loss: 0.01349450834095478\n",
      "Epoch 2508, Loss: 0.04662348423153162, Final Batch Loss: 0.0021604932844638824\n",
      "Epoch 2509, Loss: 0.0630159949650988, Final Batch Loss: 0.0010150031885132194\n",
      "Epoch 2510, Loss: 0.10182122979313135, Final Batch Loss: 0.0411151722073555\n",
      "Epoch 2511, Loss: 0.06483432836830616, Final Batch Loss: 0.003066243603825569\n",
      "Epoch 2512, Loss: 0.11088287876918912, Final Batch Loss: 0.032213643193244934\n",
      "Epoch 2513, Loss: 0.07394287874922156, Final Batch Loss: 0.020394612103700638\n",
      "Epoch 2514, Loss: 0.19938981719315052, Final Batch Loss: 0.107392817735672\n",
      "Epoch 2515, Loss: 0.05614826921373606, Final Batch Loss: 0.01286051981151104\n",
      "Epoch 2516, Loss: 0.0793139236047864, Final Batch Loss: 0.030056526884436607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2517, Loss: 0.09401950030587614, Final Batch Loss: 0.0189285259693861\n",
      "Epoch 2518, Loss: 0.1401511779986322, Final Batch Loss: 0.002204613294452429\n",
      "Epoch 2519, Loss: 0.051099035888910294, Final Batch Loss: 0.01585642248392105\n",
      "Epoch 2520, Loss: 0.1208498626947403, Final Batch Loss: 0.03750532120466232\n",
      "Epoch 2521, Loss: 0.05879616690799594, Final Batch Loss: 0.015620517544448376\n",
      "Epoch 2522, Loss: 0.13874088693410158, Final Batch Loss: 0.06709202378988266\n",
      "Epoch 2523, Loss: 0.16778455628082156, Final Batch Loss: 0.0010103951208293438\n",
      "Epoch 2524, Loss: 0.13095882255584002, Final Batch Loss: 0.04729796573519707\n",
      "Epoch 2525, Loss: 0.08569487638305873, Final Batch Loss: 0.0008371052099391818\n",
      "Epoch 2526, Loss: 0.10597451170906425, Final Batch Loss: 0.005610657390207052\n",
      "Epoch 2527, Loss: 0.08806125004775822, Final Batch Loss: 0.003018665825948119\n",
      "Epoch 2528, Loss: 0.06642492022365332, Final Batch Loss: 0.007264986634254456\n",
      "Epoch 2529, Loss: 0.11812181584537029, Final Batch Loss: 0.04436369240283966\n",
      "Epoch 2530, Loss: 0.1352092307060957, Final Batch Loss: 0.019993649795651436\n",
      "Epoch 2531, Loss: 0.27074607089161873, Final Batch Loss: 0.032186590135097504\n",
      "Epoch 2532, Loss: 0.18555898033082485, Final Batch Loss: 0.05068919062614441\n",
      "Epoch 2533, Loss: 0.06928718229755759, Final Batch Loss: 0.004926495719701052\n",
      "Epoch 2534, Loss: 0.11997598875313997, Final Batch Loss: 0.020591508597135544\n",
      "Epoch 2535, Loss: 0.1345793679356575, Final Batch Loss: 0.0613722950220108\n",
      "Epoch 2536, Loss: 0.05570916086435318, Final Batch Loss: 0.008415727876126766\n",
      "Epoch 2537, Loss: 0.07971170451492071, Final Batch Loss: 0.020938746631145477\n",
      "Epoch 2538, Loss: 0.05792258772999048, Final Batch Loss: 0.005384835414588451\n",
      "Epoch 2539, Loss: 0.094624615740031, Final Batch Loss: 0.003941222093999386\n",
      "Epoch 2540, Loss: 0.021379746729508042, Final Batch Loss: 0.003638878231868148\n",
      "Epoch 2541, Loss: 0.0399345513433218, Final Batch Loss: 0.002355641685426235\n",
      "Epoch 2542, Loss: 0.0336445327848196, Final Batch Loss: 0.007482202723622322\n",
      "Epoch 2543, Loss: 0.07906550262123346, Final Batch Loss: 0.024608217179775238\n",
      "Epoch 2544, Loss: 0.030433502979576588, Final Batch Loss: 0.0021326791029423475\n",
      "Epoch 2545, Loss: 0.05194009793922305, Final Batch Loss: 0.004141197074204683\n",
      "Epoch 2546, Loss: 0.1140134755987674, Final Batch Loss: 0.002268577925860882\n",
      "Epoch 2547, Loss: 0.06446834933012724, Final Batch Loss: 0.009508405812084675\n",
      "Epoch 2548, Loss: 0.04068848071619868, Final Batch Loss: 0.0072911689057946205\n",
      "Epoch 2549, Loss: 0.07695303158834577, Final Batch Loss: 0.040024884045124054\n",
      "Epoch 2550, Loss: 0.06547216139733791, Final Batch Loss: 0.007872847840189934\n",
      "Epoch 2551, Loss: 0.1087296986952424, Final Batch Loss: 0.07930696755647659\n",
      "Epoch 2552, Loss: 0.026473363395780325, Final Batch Loss: 0.003720139851793647\n",
      "Epoch 2553, Loss: 0.06753721740096807, Final Batch Loss: 0.010443697683513165\n",
      "Epoch 2554, Loss: 0.052368301432579756, Final Batch Loss: 0.0070064072497189045\n",
      "Epoch 2555, Loss: 0.03724313876591623, Final Batch Loss: 0.007931999862194061\n",
      "Epoch 2556, Loss: 0.05776892334688455, Final Batch Loss: 0.0016231468180194497\n",
      "Epoch 2557, Loss: 0.020962274633347988, Final Batch Loss: 0.002452332992106676\n",
      "Epoch 2558, Loss: 0.07876684190705419, Final Batch Loss: 0.0394560843706131\n",
      "Epoch 2559, Loss: 0.14083046186715364, Final Batch Loss: 0.004233135841786861\n",
      "Epoch 2560, Loss: 0.10875197825953364, Final Batch Loss: 0.033826038241386414\n",
      "Epoch 2561, Loss: 0.03504855837672949, Final Batch Loss: 0.007917103357613087\n",
      "Epoch 2562, Loss: 0.0680076852440834, Final Batch Loss: 0.002100680023431778\n",
      "Epoch 2563, Loss: 0.05230702832341194, Final Batch Loss: 0.022440502420067787\n",
      "Epoch 2564, Loss: 0.10104117076843977, Final Batch Loss: 0.01452492456883192\n",
      "Epoch 2565, Loss: 0.04485371941700578, Final Batch Loss: 0.006482887547463179\n",
      "Epoch 2566, Loss: 0.12462073843926191, Final Batch Loss: 0.009399576112627983\n",
      "Epoch 2567, Loss: 0.02161479671485722, Final Batch Loss: 0.00035656848922371864\n",
      "Epoch 2568, Loss: 0.08610079810023308, Final Batch Loss: 0.001611391082406044\n",
      "Epoch 2569, Loss: 0.03497590241022408, Final Batch Loss: 0.0033646507654339075\n",
      "Epoch 2570, Loss: 0.030515859369188547, Final Batch Loss: 0.005201674532145262\n",
      "Epoch 2571, Loss: 0.08663629670627415, Final Batch Loss: 0.003228378714993596\n",
      "Epoch 2572, Loss: 0.03593239560723305, Final Batch Loss: 0.007685515098273754\n",
      "Epoch 2573, Loss: 0.08133781002834439, Final Batch Loss: 0.00416307570412755\n",
      "Epoch 2574, Loss: 0.018852693377994, Final Batch Loss: 0.004367669578641653\n",
      "Epoch 2575, Loss: 0.03535242239013314, Final Batch Loss: 0.005356502253562212\n",
      "Epoch 2576, Loss: 0.07488433714024723, Final Batch Loss: 0.046433161944150925\n",
      "Epoch 2577, Loss: 0.028156703570857644, Final Batch Loss: 0.0031020392198115587\n",
      "Epoch 2578, Loss: 0.07191698253154755, Final Batch Loss: 0.014622665010392666\n",
      "Epoch 2579, Loss: 0.019330280600115657, Final Batch Loss: 0.002554139820858836\n",
      "Epoch 2580, Loss: 0.08812034223228693, Final Batch Loss: 0.030843768268823624\n",
      "Epoch 2581, Loss: 0.05289151007309556, Final Batch Loss: 0.021294815465807915\n",
      "Epoch 2582, Loss: 0.12722532218322158, Final Batch Loss: 0.026693249121308327\n",
      "Epoch 2583, Loss: 0.06402741849888116, Final Batch Loss: 0.001725369249470532\n",
      "Epoch 2584, Loss: 0.07809987291693687, Final Batch Loss: 0.018247470259666443\n",
      "Epoch 2585, Loss: 0.08579258807003498, Final Batch Loss: 0.01633516699075699\n",
      "Epoch 2586, Loss: 0.06111561506986618, Final Batch Loss: 0.003037556540220976\n",
      "Epoch 2587, Loss: 0.09502835478633642, Final Batch Loss: 0.003714919090270996\n",
      "Epoch 2588, Loss: 0.0718366983346641, Final Batch Loss: 0.004546274896711111\n",
      "Epoch 2589, Loss: 0.046279927948489785, Final Batch Loss: 0.002943824278190732\n",
      "Epoch 2590, Loss: 0.057568117044866085, Final Batch Loss: 0.0026289713568985462\n",
      "Epoch 2591, Loss: 0.02960948273539543, Final Batch Loss: 0.005845909006893635\n",
      "Epoch 2592, Loss: 0.06368894153274596, Final Batch Loss: 0.03065953217446804\n",
      "Epoch 2593, Loss: 0.07216518558561802, Final Batch Loss: 0.008287984877824783\n",
      "Epoch 2594, Loss: 0.06802092283032835, Final Batch Loss: 0.01506689190864563\n",
      "Epoch 2595, Loss: 0.14040676690638065, Final Batch Loss: 0.08190328627824783\n",
      "Epoch 2596, Loss: 0.057266140123829246, Final Batch Loss: 0.0028763485606759787\n",
      "Epoch 2597, Loss: 0.12643834855407476, Final Batch Loss: 0.008346165530383587\n",
      "Epoch 2598, Loss: 0.09883932815864682, Final Batch Loss: 0.004168468061834574\n",
      "Epoch 2599, Loss: 0.09676117217168212, Final Batch Loss: 0.04747772216796875\n",
      "Epoch 2600, Loss: 0.021191901993006468, Final Batch Loss: 0.008762499317526817\n",
      "Epoch 2601, Loss: 0.0503723977599293, Final Batch Loss: 0.0036796985659748316\n",
      "Epoch 2602, Loss: 0.032431129133328795, Final Batch Loss: 0.0048971278592944145\n",
      "Epoch 2603, Loss: 0.07006953982636333, Final Batch Loss: 0.009343119338154793\n",
      "Epoch 2604, Loss: 0.07470109825953841, Final Batch Loss: 0.013263926841318607\n",
      "Epoch 2605, Loss: 0.05424546403810382, Final Batch Loss: 0.006298076827079058\n",
      "Epoch 2606, Loss: 0.03671640902757645, Final Batch Loss: 0.010593426413834095\n",
      "Epoch 2607, Loss: 0.06499830773100257, Final Batch Loss: 0.032492946833372116\n",
      "Epoch 2608, Loss: 0.04068069311324507, Final Batch Loss: 0.0013542190426960588\n",
      "Epoch 2609, Loss: 0.04857574519701302, Final Batch Loss: 0.002277819672599435\n",
      "Epoch 2610, Loss: 0.10230320785194635, Final Batch Loss: 0.003198430873453617\n",
      "Epoch 2611, Loss: 0.07819993421435356, Final Batch Loss: 0.008879657834768295\n",
      "Epoch 2612, Loss: 0.07069410081021488, Final Batch Loss: 0.01828940212726593\n",
      "Epoch 2613, Loss: 0.04368424345739186, Final Batch Loss: 0.03293465077877045\n",
      "Epoch 2614, Loss: 0.10349853662773967, Final Batch Loss: 0.005179685540497303\n",
      "Epoch 2615, Loss: 0.1390288956463337, Final Batch Loss: 0.06444929540157318\n",
      "Epoch 2616, Loss: 0.05102048278786242, Final Batch Loss: 0.005793325137346983\n",
      "Epoch 2617, Loss: 0.093289700220339, Final Batch Loss: 0.0010521867079660296\n",
      "Epoch 2618, Loss: 0.10318468301557004, Final Batch Loss: 0.0025381927844136953\n",
      "Epoch 2619, Loss: 0.10587427718564868, Final Batch Loss: 0.02868199162185192\n",
      "Epoch 2620, Loss: 0.11383030749857426, Final Batch Loss: 0.008552051149308681\n",
      "Epoch 2621, Loss: 0.033002846175804734, Final Batch Loss: 0.0037767067551612854\n",
      "Epoch 2622, Loss: 0.13992009172216058, Final Batch Loss: 0.10712801665067673\n",
      "Epoch 2623, Loss: 0.08356771897524595, Final Batch Loss: 0.01103213056921959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2624, Loss: 0.042799470596946776, Final Batch Loss: 0.0017180709401145577\n",
      "Epoch 2625, Loss: 0.0768652455881238, Final Batch Loss: 0.0023079784587025642\n",
      "Epoch 2626, Loss: 0.0838424963876605, Final Batch Loss: 0.02778548188507557\n",
      "Epoch 2627, Loss: 0.07156503992155194, Final Batch Loss: 0.007902737706899643\n",
      "Epoch 2628, Loss: 0.030106400605291128, Final Batch Loss: 0.011038261465728283\n",
      "Epoch 2629, Loss: 0.11840797262266278, Final Batch Loss: 0.07024092972278595\n",
      "Epoch 2630, Loss: 0.037369220051914454, Final Batch Loss: 0.009394730441272259\n",
      "Epoch 2631, Loss: 0.07011900655925274, Final Batch Loss: 0.019199296832084656\n",
      "Epoch 2632, Loss: 0.049056144431233406, Final Batch Loss: 0.02338269166648388\n",
      "Epoch 2633, Loss: 0.09710180852562189, Final Batch Loss: 0.00974201038479805\n",
      "Epoch 2634, Loss: 0.11115658469498158, Final Batch Loss: 0.030533982440829277\n",
      "Epoch 2635, Loss: 0.036662549478933215, Final Batch Loss: 0.017149247229099274\n",
      "Epoch 2636, Loss: 0.08047086000442505, Final Batch Loss: 0.03995366767048836\n",
      "Epoch 2637, Loss: 0.09618317987769842, Final Batch Loss: 0.03238000348210335\n",
      "Epoch 2638, Loss: 0.1383963623084128, Final Batch Loss: 0.04340185970067978\n",
      "Epoch 2639, Loss: 0.14916899893432856, Final Batch Loss: 0.013632446527481079\n",
      "Epoch 2640, Loss: 0.1277846973389387, Final Batch Loss: 0.02534930221736431\n",
      "Epoch 2641, Loss: 0.13127426989376545, Final Batch Loss: 0.008163219317793846\n",
      "Epoch 2642, Loss: 0.09924169490113854, Final Batch Loss: 0.004061244893819094\n",
      "Epoch 2643, Loss: 0.06605068198405206, Final Batch Loss: 0.0020381801296025515\n",
      "Epoch 2644, Loss: 0.07642045989632607, Final Batch Loss: 0.014622263610363007\n",
      "Epoch 2645, Loss: 0.10003168322145939, Final Batch Loss: 0.025923650711774826\n",
      "Epoch 2646, Loss: 0.09308368992060423, Final Batch Loss: 0.023565996438264847\n",
      "Epoch 2647, Loss: 0.13576299138367176, Final Batch Loss: 0.010150961577892303\n",
      "Epoch 2648, Loss: 0.07462030928581953, Final Batch Loss: 0.01899356208741665\n",
      "Epoch 2649, Loss: 0.12067160103470087, Final Batch Loss: 0.06550181657075882\n",
      "Epoch 2650, Loss: 0.04175576567649841, Final Batch Loss: 0.008425014093518257\n",
      "Epoch 2651, Loss: 0.10828857310116291, Final Batch Loss: 0.06617197394371033\n",
      "Epoch 2652, Loss: 0.056217653676867485, Final Batch Loss: 0.022431308403611183\n",
      "Epoch 2653, Loss: 0.16062983870506287, Final Batch Loss: 0.019207198172807693\n",
      "Epoch 2654, Loss: 0.05870615318417549, Final Batch Loss: 0.01254079770296812\n",
      "Epoch 2655, Loss: 0.15848675929009914, Final Batch Loss: 0.06505902111530304\n",
      "Epoch 2656, Loss: 0.17201907094568014, Final Batch Loss: 0.13992543518543243\n",
      "Epoch 2657, Loss: 0.08537842612713575, Final Batch Loss: 0.013372612185776234\n",
      "Epoch 2658, Loss: 0.06159490346908569, Final Batch Loss: 0.007779535837471485\n",
      "Epoch 2659, Loss: 0.06154924817383289, Final Batch Loss: 0.004883389919996262\n",
      "Epoch 2660, Loss: 0.09798633866012096, Final Batch Loss: 0.004864882677793503\n",
      "Epoch 2661, Loss: 0.10594614408910275, Final Batch Loss: 0.05408871918916702\n",
      "Epoch 2662, Loss: 0.07569217588752508, Final Batch Loss: 0.025713277980685234\n",
      "Epoch 2663, Loss: 0.0779794231057167, Final Batch Loss: 0.0161629319190979\n",
      "Epoch 2664, Loss: 0.04820135748013854, Final Batch Loss: 0.0017209970392286777\n",
      "Epoch 2665, Loss: 0.10332315694540739, Final Batch Loss: 0.01095995306968689\n",
      "Epoch 2666, Loss: 0.02432084083557129, Final Batch Loss: 0.00998219009488821\n",
      "Epoch 2667, Loss: 0.03981143538840115, Final Batch Loss: 0.027284791693091393\n",
      "Epoch 2668, Loss: 0.03807074110955, Final Batch Loss: 0.0022865275386720896\n",
      "Epoch 2669, Loss: 0.02503352565690875, Final Batch Loss: 0.0027904438320547342\n",
      "Epoch 2670, Loss: 0.021307213930413127, Final Batch Loss: 0.007591394241899252\n",
      "Epoch 2671, Loss: 0.041360873030498624, Final Batch Loss: 0.003424846800044179\n",
      "Epoch 2672, Loss: 0.024157421779818833, Final Batch Loss: 0.00151562609244138\n",
      "Epoch 2673, Loss: 0.04364668077323586, Final Batch Loss: 0.00099868921097368\n",
      "Epoch 2674, Loss: 0.016999535961076617, Final Batch Loss: 0.003342369105666876\n",
      "Epoch 2675, Loss: 0.052331483690068126, Final Batch Loss: 0.0035421454813331366\n",
      "Epoch 2676, Loss: 0.036710654268972576, Final Batch Loss: 0.0017740995390340686\n",
      "Epoch 2677, Loss: 0.08097502775490284, Final Batch Loss: 0.0018330421298742294\n",
      "Epoch 2678, Loss: 0.1025072792544961, Final Batch Loss: 0.002087695524096489\n",
      "Epoch 2679, Loss: 0.11840161262080073, Final Batch Loss: 0.048831693828105927\n",
      "Epoch 2680, Loss: 0.0449925335124135, Final Batch Loss: 0.0036077694967389107\n",
      "Epoch 2681, Loss: 0.03198938025161624, Final Batch Loss: 0.005979093257337809\n",
      "Epoch 2682, Loss: 0.017048892797902226, Final Batch Loss: 0.006823784206062555\n",
      "Epoch 2683, Loss: 0.05939302785554901, Final Batch Loss: 0.0003196825855411589\n",
      "Epoch 2684, Loss: 0.07562915608286858, Final Batch Loss: 0.05039942264556885\n",
      "Epoch 2685, Loss: 0.01747333537787199, Final Batch Loss: 0.004868579097092152\n",
      "Epoch 2686, Loss: 0.053960253950208426, Final Batch Loss: 0.02786465547978878\n",
      "Epoch 2687, Loss: 0.07655973918735981, Final Batch Loss: 0.012670975178480148\n",
      "Epoch 2688, Loss: 0.051784918061457574, Final Batch Loss: 0.001879601157270372\n",
      "Epoch 2689, Loss: 0.11182404449209571, Final Batch Loss: 0.08476582914590836\n",
      "Epoch 2690, Loss: 0.07780428230762482, Final Batch Loss: 0.02103814296424389\n",
      "Epoch 2691, Loss: 0.05023937957594171, Final Batch Loss: 0.0007841811166144907\n",
      "Epoch 2692, Loss: 0.08186918566934764, Final Batch Loss: 0.007155476603657007\n",
      "Epoch 2693, Loss: 0.1628309739753604, Final Batch Loss: 0.08262338489294052\n",
      "Epoch 2694, Loss: 0.09365044627338648, Final Batch Loss: 0.010478292591869831\n",
      "Epoch 2695, Loss: 0.030220176791772246, Final Batch Loss: 0.0033072622027248144\n",
      "Epoch 2696, Loss: 0.07390485558426008, Final Batch Loss: 0.0006371936178766191\n",
      "Epoch 2697, Loss: 0.045556480530649424, Final Batch Loss: 0.006115433294326067\n",
      "Epoch 2698, Loss: 0.02637292305007577, Final Batch Loss: 0.003047155449166894\n",
      "Epoch 2699, Loss: 0.04507567035034299, Final Batch Loss: 0.00823455024510622\n",
      "Epoch 2700, Loss: 0.15320481732487679, Final Batch Loss: 0.07283888012170792\n",
      "Epoch 2701, Loss: 0.04968001530505717, Final Batch Loss: 0.0030531224329024553\n",
      "Epoch 2702, Loss: 0.07278797123581171, Final Batch Loss: 0.003233551047742367\n",
      "Epoch 2703, Loss: 0.029127008048817515, Final Batch Loss: 0.0022920919582247734\n",
      "Epoch 2704, Loss: 0.030671386513859034, Final Batch Loss: 0.008032385259866714\n",
      "Epoch 2705, Loss: 0.04560886835679412, Final Batch Loss: 0.010972916148602962\n",
      "Epoch 2706, Loss: 0.03782858978956938, Final Batch Loss: 0.018185822293162346\n",
      "Epoch 2707, Loss: 0.06241081410553306, Final Batch Loss: 0.0013384196208789945\n",
      "Epoch 2708, Loss: 0.03873208723962307, Final Batch Loss: 0.006918732076883316\n",
      "Epoch 2709, Loss: 0.0705476728035137, Final Batch Loss: 0.0015898559940978885\n",
      "Epoch 2710, Loss: 0.023710014880634844, Final Batch Loss: 0.0009189314441755414\n",
      "Epoch 2711, Loss: 0.04196016024798155, Final Batch Loss: 0.004541465546935797\n",
      "Epoch 2712, Loss: 0.04298007907345891, Final Batch Loss: 0.003610860090702772\n",
      "Epoch 2713, Loss: 0.02302986243739724, Final Batch Loss: 0.009634426794946194\n",
      "Epoch 2714, Loss: 0.04362825397402048, Final Batch Loss: 0.0029768403619527817\n",
      "Epoch 2715, Loss: 0.03968816203996539, Final Batch Loss: 0.008410211652517319\n",
      "Epoch 2716, Loss: 0.051346163963899016, Final Batch Loss: 0.0039970846846699715\n",
      "Epoch 2717, Loss: 0.04705792712047696, Final Batch Loss: 0.008217379450798035\n",
      "Epoch 2718, Loss: 0.03468745993450284, Final Batch Loss: 0.0027015679515898228\n",
      "Epoch 2719, Loss: 0.02898268122226, Final Batch Loss: 0.004267902113497257\n",
      "Epoch 2720, Loss: 0.028735559550113976, Final Batch Loss: 0.0014260269235819578\n",
      "Epoch 2721, Loss: 0.0546952614095062, Final Batch Loss: 0.0025430365931242704\n",
      "Epoch 2722, Loss: 0.0577686179894954, Final Batch Loss: 0.03873933106660843\n",
      "Epoch 2723, Loss: 0.0576599589549005, Final Batch Loss: 0.004224183037877083\n",
      "Epoch 2724, Loss: 0.05177108873613179, Final Batch Loss: 0.0030478572007268667\n",
      "Epoch 2725, Loss: 0.018898404436185956, Final Batch Loss: 0.0060002123937010765\n",
      "Epoch 2726, Loss: 0.014668243704363704, Final Batch Loss: 0.0038880775682628155\n",
      "Epoch 2727, Loss: 0.03942690882831812, Final Batch Loss: 0.0023775796871632338\n",
      "Epoch 2728, Loss: 0.04835021903272718, Final Batch Loss: 0.001748961745761335\n",
      "Epoch 2729, Loss: 0.03584812564076856, Final Batch Loss: 0.0006343976710923016\n",
      "Epoch 2730, Loss: 0.037864694371819496, Final Batch Loss: 0.01415396761149168\n",
      "Epoch 2731, Loss: 0.03414139221422374, Final Batch Loss: 0.0010415692813694477\n",
      "Epoch 2732, Loss: 0.07831275649368763, Final Batch Loss: 0.011151662096381187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2733, Loss: 0.08078571362420917, Final Batch Loss: 0.04926387965679169\n",
      "Epoch 2734, Loss: 0.1540734712034464, Final Batch Loss: 0.04642363265156746\n",
      "Epoch 2735, Loss: 0.029274171916767955, Final Batch Loss: 0.0020199220161885023\n",
      "Epoch 2736, Loss: 0.04876876878552139, Final Batch Loss: 0.022256696596741676\n",
      "Epoch 2737, Loss: 0.15737358573824167, Final Batch Loss: 0.014250469394028187\n",
      "Epoch 2738, Loss: 0.07583484891802073, Final Batch Loss: 0.009546083398163319\n",
      "Epoch 2739, Loss: 0.11131900455802679, Final Batch Loss: 0.007763354107737541\n",
      "Epoch 2740, Loss: 0.03389756195247173, Final Batch Loss: 0.007922722958028316\n",
      "Epoch 2741, Loss: 0.10212732199579477, Final Batch Loss: 0.026719288900494576\n",
      "Epoch 2742, Loss: 0.04037034744396806, Final Batch Loss: 0.0036505444440990686\n",
      "Epoch 2743, Loss: 0.050258571514859796, Final Batch Loss: 0.0019835655111819506\n",
      "Epoch 2744, Loss: 0.01944283046759665, Final Batch Loss: 0.0010780652519315481\n",
      "Epoch 2745, Loss: 0.11391770467162132, Final Batch Loss: 0.03129005804657936\n",
      "Epoch 2746, Loss: 0.07767228363081813, Final Batch Loss: 0.005143274087458849\n",
      "Epoch 2747, Loss: 0.06625071493908763, Final Batch Loss: 0.03143984079360962\n",
      "Epoch 2748, Loss: 0.18531857966445386, Final Batch Loss: 0.1183328628540039\n",
      "Epoch 2749, Loss: 0.1296381070278585, Final Batch Loss: 0.003521640319377184\n",
      "Epoch 2750, Loss: 0.16519505227915943, Final Batch Loss: 0.09384224563837051\n",
      "Epoch 2751, Loss: 0.18742173351347446, Final Batch Loss: 0.07136130332946777\n",
      "Epoch 2752, Loss: 0.10337784141302109, Final Batch Loss: 0.07049411535263062\n",
      "Epoch 2753, Loss: 0.10059184674173594, Final Batch Loss: 0.014646016992628574\n",
      "Epoch 2754, Loss: 0.1525290049612522, Final Batch Loss: 0.03534866124391556\n",
      "Epoch 2755, Loss: 0.14053689315915108, Final Batch Loss: 0.03642117232084274\n",
      "Epoch 2756, Loss: 0.1027004704810679, Final Batch Loss: 0.026837503537535667\n",
      "Epoch 2757, Loss: 0.040059957886114717, Final Batch Loss: 0.004461848642677069\n",
      "Epoch 2758, Loss: 0.05816217139363289, Final Batch Loss: 0.026974467560648918\n",
      "Epoch 2759, Loss: 0.05694061680696905, Final Batch Loss: 0.003484393237158656\n",
      "Epoch 2760, Loss: 0.037529742578044534, Final Batch Loss: 0.005642931442707777\n",
      "Epoch 2761, Loss: 0.03374727861955762, Final Batch Loss: 0.003254026174545288\n",
      "Epoch 2762, Loss: 0.11230152379721403, Final Batch Loss: 0.09432040899991989\n",
      "Epoch 2763, Loss: 0.07799240993335843, Final Batch Loss: 0.01995517872273922\n",
      "Epoch 2764, Loss: 0.04680169152561575, Final Batch Loss: 0.0015584096545353532\n",
      "Epoch 2765, Loss: 0.03265726426616311, Final Batch Loss: 0.003017424140125513\n",
      "Epoch 2766, Loss: 0.06897012190893292, Final Batch Loss: 0.004577541258186102\n",
      "Epoch 2767, Loss: 0.030172685394063592, Final Batch Loss: 0.0023457056377083063\n",
      "Epoch 2768, Loss: 0.09580712579190731, Final Batch Loss: 0.03387553244829178\n",
      "Epoch 2769, Loss: 0.06172400061041117, Final Batch Loss: 0.00941140204668045\n",
      "Epoch 2770, Loss: 0.05373691627755761, Final Batch Loss: 0.011554043740034103\n",
      "Epoch 2771, Loss: 0.01314410544000566, Final Batch Loss: 0.0015687593258917332\n",
      "Epoch 2772, Loss: 0.04316756781190634, Final Batch Loss: 0.010009968653321266\n",
      "Epoch 2773, Loss: 0.1162264421582222, Final Batch Loss: 0.027496254071593285\n",
      "Epoch 2774, Loss: 0.03926436882466078, Final Batch Loss: 0.006731935776770115\n",
      "Epoch 2775, Loss: 0.028665869846008718, Final Batch Loss: 0.0009335436625406146\n",
      "Epoch 2776, Loss: 0.04154612182173878, Final Batch Loss: 0.0013940796488896012\n",
      "Epoch 2777, Loss: 0.054806509986519814, Final Batch Loss: 0.003834628500044346\n",
      "Epoch 2778, Loss: 0.029952479526400566, Final Batch Loss: 0.003463943023234606\n",
      "Epoch 2779, Loss: 0.044394702883437276, Final Batch Loss: 0.01658373698592186\n",
      "Epoch 2780, Loss: 0.018916300032287836, Final Batch Loss: 0.0025614399928599596\n",
      "Epoch 2781, Loss: 0.09714852832257748, Final Batch Loss: 0.044845495373010635\n",
      "Epoch 2782, Loss: 0.027172810398042202, Final Batch Loss: 0.002702377736568451\n",
      "Epoch 2783, Loss: 0.07631107303313911, Final Batch Loss: 0.0021424356382340193\n",
      "Epoch 2784, Loss: 0.03929600678384304, Final Batch Loss: 0.01966637372970581\n",
      "Epoch 2785, Loss: 0.01647971081547439, Final Batch Loss: 0.0041259233839809895\n",
      "Epoch 2786, Loss: 0.12562320427969098, Final Batch Loss: 0.08469605445861816\n",
      "Epoch 2787, Loss: 0.046905393013730645, Final Batch Loss: 0.0038039556238800287\n",
      "Epoch 2788, Loss: 0.11397558450698853, Final Batch Loss: 0.09058164060115814\n",
      "Epoch 2789, Loss: 0.06771441036835313, Final Batch Loss: 0.019079484045505524\n",
      "Epoch 2790, Loss: 0.11976924142800272, Final Batch Loss: 0.08259936422109604\n",
      "Epoch 2791, Loss: 0.056024559773504734, Final Batch Loss: 0.007674058899283409\n",
      "Epoch 2792, Loss: 0.22826188430190086, Final Batch Loss: 0.05990687012672424\n",
      "Epoch 2793, Loss: 0.17632116749882698, Final Batch Loss: 0.015003426000475883\n",
      "Epoch 2794, Loss: 0.0634132674895227, Final Batch Loss: 0.01533393282443285\n",
      "Epoch 2795, Loss: 0.11588211543858051, Final Batch Loss: 0.020249079912900925\n",
      "Epoch 2796, Loss: 0.054077168460935354, Final Batch Loss: 0.0048156422562897205\n",
      "Epoch 2797, Loss: 0.12101745838299394, Final Batch Loss: 0.004773563239723444\n",
      "Epoch 2798, Loss: 0.06733014388009906, Final Batch Loss: 0.003942514304071665\n",
      "Epoch 2799, Loss: 0.0888228255789727, Final Batch Loss: 0.06954287737607956\n",
      "Epoch 2800, Loss: 0.067941227927804, Final Batch Loss: 0.030381593853235245\n",
      "Epoch 2801, Loss: 0.06097763078287244, Final Batch Loss: 0.021600527688860893\n",
      "Epoch 2802, Loss: 0.08857630752027035, Final Batch Loss: 0.013266434893012047\n",
      "Epoch 2803, Loss: 0.11261850665323436, Final Batch Loss: 0.0016065731178969145\n",
      "Epoch 2804, Loss: 0.07290447992272675, Final Batch Loss: 0.004691605921834707\n",
      "Epoch 2805, Loss: 0.09307525749318302, Final Batch Loss: 0.0038376401644200087\n",
      "Epoch 2806, Loss: 0.06461774744093418, Final Batch Loss: 0.015423687174916267\n",
      "Epoch 2807, Loss: 0.06162808137014508, Final Batch Loss: 0.008370981551706791\n",
      "Epoch 2808, Loss: 0.14979419531300664, Final Batch Loss: 0.04045281559228897\n",
      "Epoch 2809, Loss: 0.0836447193287313, Final Batch Loss: 0.005753604229539633\n",
      "Epoch 2810, Loss: 0.09808619040995836, Final Batch Loss: 0.01856270805001259\n",
      "Epoch 2811, Loss: 0.1418054522946477, Final Batch Loss: 0.022377587854862213\n",
      "Epoch 2812, Loss: 0.0889154109172523, Final Batch Loss: 0.005907490383833647\n",
      "Epoch 2813, Loss: 0.14184974785894156, Final Batch Loss: 0.05283243954181671\n",
      "Epoch 2814, Loss: 0.022323356941342354, Final Batch Loss: 0.005252404138445854\n",
      "Epoch 2815, Loss: 0.11302995774894953, Final Batch Loss: 0.06961455196142197\n",
      "Epoch 2816, Loss: 0.03633863991126418, Final Batch Loss: 0.015741562470793724\n",
      "Epoch 2817, Loss: 0.08079661522060633, Final Batch Loss: 0.013687442988157272\n",
      "Epoch 2818, Loss: 0.11274701496586204, Final Batch Loss: 0.055823247879743576\n",
      "Epoch 2819, Loss: 0.04014121717773378, Final Batch Loss: 0.0034134869929403067\n",
      "Epoch 2820, Loss: 0.039039260940626264, Final Batch Loss: 0.0035392215941101313\n",
      "Epoch 2821, Loss: 0.12193188187666237, Final Batch Loss: 0.0034269278403371572\n",
      "Epoch 2822, Loss: 0.08155972382519394, Final Batch Loss: 0.0016858155140653253\n",
      "Epoch 2823, Loss: 0.020727065857499838, Final Batch Loss: 0.004035645630210638\n",
      "Epoch 2824, Loss: 0.05692844744771719, Final Batch Loss: 0.017350129783153534\n",
      "Epoch 2825, Loss: 0.14388609351590276, Final Batch Loss: 0.09493137151002884\n",
      "Epoch 2826, Loss: 0.07155010453425348, Final Batch Loss: 0.0027543145697563887\n",
      "Epoch 2827, Loss: 0.12977073690854013, Final Batch Loss: 0.0011640999000519514\n",
      "Epoch 2828, Loss: 0.05743971117772162, Final Batch Loss: 0.003595447400584817\n",
      "Epoch 2829, Loss: 0.07259354321286082, Final Batch Loss: 0.00791686587035656\n",
      "Epoch 2830, Loss: 0.11102503072470427, Final Batch Loss: 0.07203470170497894\n",
      "Epoch 2831, Loss: 0.11451203562319279, Final Batch Loss: 0.03645794093608856\n",
      "Epoch 2832, Loss: 0.07708581630140543, Final Batch Loss: 0.03197922930121422\n",
      "Epoch 2833, Loss: 0.047936351504176855, Final Batch Loss: 0.025918368250131607\n",
      "Epoch 2834, Loss: 0.06949236243963242, Final Batch Loss: 0.021661914885044098\n",
      "Epoch 2835, Loss: 0.05751531710848212, Final Batch Loss: 0.00473859254270792\n",
      "Epoch 2836, Loss: 0.03303538868203759, Final Batch Loss: 0.006920150946825743\n",
      "Epoch 2837, Loss: 0.06527819251641631, Final Batch Loss: 0.0064428686164319515\n",
      "Epoch 2838, Loss: 0.04230016563087702, Final Batch Loss: 0.01629815436899662\n",
      "Epoch 2839, Loss: 0.019996400456875563, Final Batch Loss: 0.005460819229483604\n",
      "Epoch 2840, Loss: 0.030909164110198617, Final Batch Loss: 0.004635215271264315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2841, Loss: 0.053847416886128485, Final Batch Loss: 0.001419721287675202\n",
      "Epoch 2842, Loss: 0.07895790785551071, Final Batch Loss: 0.024624397978186607\n",
      "Epoch 2843, Loss: 0.08338932716287673, Final Batch Loss: 0.0026806259993463755\n",
      "Epoch 2844, Loss: 0.059398768935352564, Final Batch Loss: 0.028378143906593323\n",
      "Epoch 2845, Loss: 0.06494876532815397, Final Batch Loss: 0.0028289088513702154\n",
      "Epoch 2846, Loss: 0.08749156910926104, Final Batch Loss: 0.0072411587461829185\n",
      "Epoch 2847, Loss: 0.028924520360305905, Final Batch Loss: 0.002841015812009573\n",
      "Epoch 2848, Loss: 0.06800682097673416, Final Batch Loss: 0.005244814325124025\n",
      "Epoch 2849, Loss: 0.022093896521255374, Final Batch Loss: 0.002487039426341653\n",
      "Epoch 2850, Loss: 0.0481723906705156, Final Batch Loss: 0.0017102506244555116\n",
      "Epoch 2851, Loss: 0.07463516248390079, Final Batch Loss: 0.009033446200191975\n",
      "Epoch 2852, Loss: 0.02235642052255571, Final Batch Loss: 0.002780415117740631\n",
      "Epoch 2853, Loss: 0.040747216902673244, Final Batch Loss: 0.013073931448161602\n",
      "Epoch 2854, Loss: 0.0489558766130358, Final Batch Loss: 0.0032696120906621218\n",
      "Epoch 2855, Loss: 0.014266866026446223, Final Batch Loss: 0.001076665474101901\n",
      "Epoch 2856, Loss: 0.021107576205395162, Final Batch Loss: 0.0012397182872518897\n",
      "Epoch 2857, Loss: 0.026439009874593467, Final Batch Loss: 0.0008725958759896457\n",
      "Epoch 2858, Loss: 0.04245502920821309, Final Batch Loss: 0.0010732137598097324\n",
      "Epoch 2859, Loss: 0.011481239460408688, Final Batch Loss: 0.0008153778035193682\n",
      "Epoch 2860, Loss: 0.05121935490751639, Final Batch Loss: 0.000944769533816725\n",
      "Epoch 2861, Loss: 0.026195201324298978, Final Batch Loss: 0.0032118787057697773\n",
      "Epoch 2862, Loss: 0.013942214543931186, Final Batch Loss: 0.001698348089121282\n",
      "Epoch 2863, Loss: 0.049798805033788085, Final Batch Loss: 0.002308968221768737\n",
      "Epoch 2864, Loss: 0.10451576812192798, Final Batch Loss: 0.003946488257497549\n",
      "Epoch 2865, Loss: 0.025237743044272065, Final Batch Loss: 0.007177900522947311\n",
      "Epoch 2866, Loss: 0.0359328577760607, Final Batch Loss: 0.005952475592494011\n",
      "Epoch 2867, Loss: 0.011290900874882936, Final Batch Loss: 0.0011933003552258015\n",
      "Epoch 2868, Loss: 0.01283918390981853, Final Batch Loss: 0.0029753355775028467\n",
      "Epoch 2869, Loss: 0.041835125302895904, Final Batch Loss: 0.006955379154533148\n",
      "Epoch 2870, Loss: 0.12768558459356427, Final Batch Loss: 0.07373690605163574\n",
      "Epoch 2871, Loss: 0.03831379296025261, Final Batch Loss: 0.0008671276154927909\n",
      "Epoch 2872, Loss: 0.01983358385041356, Final Batch Loss: 0.003817178076133132\n",
      "Epoch 2873, Loss: 0.09174578869715333, Final Batch Loss: 0.018222741782665253\n",
      "Epoch 2874, Loss: 0.03774523007450625, Final Batch Loss: 0.0005705409566871822\n",
      "Epoch 2875, Loss: 0.016757623059675097, Final Batch Loss: 0.002511517610400915\n",
      "Epoch 2876, Loss: 0.18204710818827152, Final Batch Loss: 0.07719762623310089\n",
      "Epoch 2877, Loss: 0.03411713382229209, Final Batch Loss: 0.01041650865226984\n",
      "Epoch 2878, Loss: 0.19147774716839194, Final Batch Loss: 0.0016632112674415112\n",
      "Epoch 2879, Loss: 0.07159863749984652, Final Batch Loss: 0.03492793068289757\n",
      "Epoch 2880, Loss: 0.06139306863769889, Final Batch Loss: 0.03374626487493515\n",
      "Epoch 2881, Loss: 0.04275034257443622, Final Batch Loss: 0.0006806925521232188\n",
      "Epoch 2882, Loss: 0.08709840010851622, Final Batch Loss: 0.045513201504945755\n",
      "Epoch 2883, Loss: 0.029794215690344572, Final Batch Loss: 0.011528982780873775\n",
      "Epoch 2884, Loss: 0.11595762800425291, Final Batch Loss: 0.0760590061545372\n",
      "Epoch 2885, Loss: 0.12077383697032928, Final Batch Loss: 0.04914958029985428\n",
      "Epoch 2886, Loss: 0.0768613526597619, Final Batch Loss: 0.031297918409109116\n",
      "Epoch 2887, Loss: 0.11668494716286659, Final Batch Loss: 0.051936469972133636\n",
      "Epoch 2888, Loss: 0.07068277895450592, Final Batch Loss: 0.041577763855457306\n",
      "Epoch 2889, Loss: 0.0840130386641249, Final Batch Loss: 0.0019081662176176906\n",
      "Epoch 2890, Loss: 0.023014183214399964, Final Batch Loss: 0.0008880496607162058\n",
      "Epoch 2891, Loss: 0.05671145534142852, Final Batch Loss: 0.0019895867444574833\n",
      "Epoch 2892, Loss: 0.028490941622294486, Final Batch Loss: 0.004809876903891563\n",
      "Epoch 2893, Loss: 0.015450703678652644, Final Batch Loss: 0.0045148031786084175\n",
      "Epoch 2894, Loss: 0.10705206589773297, Final Batch Loss: 0.07507341355085373\n",
      "Epoch 2895, Loss: 0.019283180707134306, Final Batch Loss: 0.0008930127369239926\n",
      "Epoch 2896, Loss: 0.03538907854817808, Final Batch Loss: 0.0035081899259239435\n",
      "Epoch 2897, Loss: 0.04297705629142001, Final Batch Loss: 0.0005975382518954575\n",
      "Epoch 2898, Loss: 0.04328632028773427, Final Batch Loss: 0.0028716649394482374\n",
      "Epoch 2899, Loss: 0.0316508065443486, Final Batch Loss: 0.0024571719113737345\n",
      "Epoch 2900, Loss: 0.052961418870836496, Final Batch Loss: 0.003918809816241264\n",
      "Epoch 2901, Loss: 0.04317391861695796, Final Batch Loss: 0.0010193150956183672\n",
      "Epoch 2902, Loss: 0.02810048032552004, Final Batch Loss: 0.013428724370896816\n",
      "Epoch 2903, Loss: 0.027900977060198784, Final Batch Loss: 0.005903281271457672\n",
      "Epoch 2904, Loss: 0.020507598062977195, Final Batch Loss: 0.005232387222349644\n",
      "Epoch 2905, Loss: 0.030456212116405368, Final Batch Loss: 0.007945933379232883\n",
      "Epoch 2906, Loss: 0.0383504678029567, Final Batch Loss: 0.004842959810048342\n",
      "Epoch 2907, Loss: 0.02325539872981608, Final Batch Loss: 0.001042060786858201\n",
      "Epoch 2908, Loss: 0.02820193232037127, Final Batch Loss: 0.0033753321040421724\n",
      "Epoch 2909, Loss: 0.06887059914879501, Final Batch Loss: 0.011828094720840454\n",
      "Epoch 2910, Loss: 0.06467903964221478, Final Batch Loss: 0.02211856096982956\n",
      "Epoch 2911, Loss: 0.047556387609802186, Final Batch Loss: 0.03659376874566078\n",
      "Epoch 2912, Loss: 0.12253517750650644, Final Batch Loss: 0.03295975551009178\n",
      "Epoch 2913, Loss: 0.08667992008849978, Final Batch Loss: 0.04512212425470352\n",
      "Epoch 2914, Loss: 0.12877573166042566, Final Batch Loss: 0.05248016491532326\n",
      "Epoch 2915, Loss: 0.07180811231955886, Final Batch Loss: 0.004526257980614901\n",
      "Epoch 2916, Loss: 0.10250324895605445, Final Batch Loss: 0.005446035414934158\n",
      "Epoch 2917, Loss: 0.06175866746343672, Final Batch Loss: 0.0021449693012982607\n",
      "Epoch 2918, Loss: 0.06350855843629688, Final Batch Loss: 0.0016150841256603599\n",
      "Epoch 2919, Loss: 0.06945685856044292, Final Batch Loss: 0.010309336706995964\n",
      "Epoch 2920, Loss: 0.07599817216396332, Final Batch Loss: 0.04473137483000755\n",
      "Epoch 2921, Loss: 0.23814084264449775, Final Batch Loss: 0.16962119936943054\n",
      "Epoch 2922, Loss: 0.29373195953667164, Final Batch Loss: 0.09280945360660553\n",
      "Epoch 2923, Loss: 0.1713777557015419, Final Batch Loss: 0.05285532772541046\n",
      "Epoch 2924, Loss: 0.1813217978924513, Final Batch Loss: 0.029402391985058784\n",
      "Epoch 2925, Loss: 0.13907487411051989, Final Batch Loss: 0.004987395368516445\n",
      "Epoch 2926, Loss: 0.13093589432537556, Final Batch Loss: 0.05269297957420349\n",
      "Epoch 2927, Loss: 0.027948075672611594, Final Batch Loss: 0.0025703951250761747\n",
      "Epoch 2928, Loss: 0.11098108254373074, Final Batch Loss: 0.012867027893662453\n",
      "Epoch 2929, Loss: 0.07344207027927041, Final Batch Loss: 0.015255016274750233\n",
      "Epoch 2930, Loss: 0.04658782831393182, Final Batch Loss: 0.010280921123921871\n",
      "Epoch 2931, Loss: 0.04303364420775324, Final Batch Loss: 0.0014233427355065942\n",
      "Epoch 2932, Loss: 0.019847909454256296, Final Batch Loss: 0.003952611703425646\n",
      "Epoch 2933, Loss: 0.01616216474212706, Final Batch Loss: 0.0008539129048585892\n",
      "Epoch 2934, Loss: 0.06722033978439867, Final Batch Loss: 0.0032417878974229097\n",
      "Epoch 2935, Loss: 0.0535558108240366, Final Batch Loss: 0.006000331602990627\n",
      "Epoch 2936, Loss: 0.04756113514304161, Final Batch Loss: 0.014485358260571957\n",
      "Epoch 2937, Loss: 0.07359777949750423, Final Batch Loss: 0.03757277503609657\n",
      "Epoch 2938, Loss: 0.043644923251122236, Final Batch Loss: 0.005089335143566132\n",
      "Epoch 2939, Loss: 0.05347985867410898, Final Batch Loss: 0.007827355526387691\n",
      "Epoch 2940, Loss: 0.05916145024821162, Final Batch Loss: 0.009139028377830982\n",
      "Epoch 2941, Loss: 0.036981961922720075, Final Batch Loss: 0.0028144626412540674\n",
      "Epoch 2942, Loss: 0.04229984455741942, Final Batch Loss: 0.01914272829890251\n",
      "Epoch 2943, Loss: 0.044749208725988865, Final Batch Loss: 0.005971921607851982\n",
      "Epoch 2944, Loss: 0.013904646271839738, Final Batch Loss: 0.0011866872664541006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2945, Loss: 0.04038460156880319, Final Batch Loss: 0.0037479668390005827\n",
      "Epoch 2946, Loss: 0.08803519839420915, Final Batch Loss: 0.02597728930413723\n",
      "Epoch 2947, Loss: 0.09361198986880481, Final Batch Loss: 0.0563071109354496\n",
      "Epoch 2948, Loss: 0.03496296191588044, Final Batch Loss: 0.013022123835980892\n",
      "Epoch 2949, Loss: 0.021267945179715753, Final Batch Loss: 0.0033533554524183273\n",
      "Epoch 2950, Loss: 0.1185996737331152, Final Batch Loss: 0.07588528841733932\n",
      "Epoch 2951, Loss: 0.08250536723062396, Final Batch Loss: 0.028221743181347847\n",
      "Epoch 2952, Loss: 0.08621011022478342, Final Batch Loss: 0.007462754845619202\n",
      "Epoch 2953, Loss: 0.05054162861779332, Final Batch Loss: 0.015977824106812477\n",
      "Epoch 2954, Loss: 0.09365893481299281, Final Batch Loss: 0.06120096519589424\n",
      "Epoch 2955, Loss: 0.02584337256848812, Final Batch Loss: 0.0018824241124093533\n",
      "Epoch 2956, Loss: 0.023637684993445873, Final Batch Loss: 0.012408073991537094\n",
      "Epoch 2957, Loss: 0.07294787908904254, Final Batch Loss: 0.009485307149589062\n",
      "Epoch 2958, Loss: 0.030400047078728676, Final Batch Loss: 0.004237931687384844\n",
      "Epoch 2959, Loss: 0.04838307434692979, Final Batch Loss: 0.0037984121590852737\n",
      "Epoch 2960, Loss: 0.09291980182752013, Final Batch Loss: 0.04556935280561447\n",
      "Epoch 2961, Loss: 0.024236644618213177, Final Batch Loss: 0.005115910433232784\n",
      "Epoch 2962, Loss: 0.04109906009398401, Final Batch Loss: 0.0021665177773684263\n",
      "Epoch 2963, Loss: 0.014385614660568535, Final Batch Loss: 0.0014383221277967095\n",
      "Epoch 2964, Loss: 0.016383005306124687, Final Batch Loss: 0.0041665504686534405\n",
      "Epoch 2965, Loss: 0.023481521173380315, Final Batch Loss: 0.007690334226936102\n",
      "Epoch 2966, Loss: 0.03853861754760146, Final Batch Loss: 0.0023809303529560566\n",
      "Epoch 2967, Loss: 0.03390248934738338, Final Batch Loss: 0.005092294421046972\n",
      "Epoch 2968, Loss: 0.06458811834454536, Final Batch Loss: 0.018907980993390083\n",
      "Epoch 2969, Loss: 0.03247319161891937, Final Batch Loss: 0.004997429437935352\n",
      "Epoch 2970, Loss: 0.01937825419008732, Final Batch Loss: 0.011582370847463608\n",
      "Epoch 2971, Loss: 0.04257018200587481, Final Batch Loss: 0.03577509894967079\n",
      "Epoch 2972, Loss: 0.06126757711172104, Final Batch Loss: 0.011634765192866325\n",
      "Epoch 2973, Loss: 0.06786873773671687, Final Batch Loss: 0.014481187798082829\n",
      "Epoch 2974, Loss: 0.034246937837451696, Final Batch Loss: 0.01305938046425581\n",
      "Epoch 2975, Loss: 0.07965235505253077, Final Batch Loss: 0.007872591726481915\n",
      "Epoch 2976, Loss: 0.015685165533795953, Final Batch Loss: 0.00830966979265213\n",
      "Epoch 2977, Loss: 0.032527369214221835, Final Batch Loss: 0.019349155947566032\n",
      "Epoch 2978, Loss: 0.12068870477378368, Final Batch Loss: 0.03703532740473747\n",
      "Epoch 2979, Loss: 0.018213951727375388, Final Batch Loss: 0.003901591058820486\n",
      "Epoch 2980, Loss: 0.03668914595618844, Final Batch Loss: 0.01024473737925291\n",
      "Epoch 2981, Loss: 0.04911506688222289, Final Batch Loss: 0.006340485531836748\n",
      "Epoch 2982, Loss: 0.03948181448504329, Final Batch Loss: 0.00991256907582283\n",
      "Epoch 2983, Loss: 0.07704570982605219, Final Batch Loss: 0.01152866892516613\n",
      "Epoch 2984, Loss: 0.058027599938213825, Final Batch Loss: 0.011626706458628178\n",
      "Epoch 2985, Loss: 0.07718102354556322, Final Batch Loss: 0.027238065376877785\n",
      "Epoch 2986, Loss: 0.12809164449572563, Final Batch Loss: 0.012415677309036255\n",
      "Epoch 2987, Loss: 0.07882171729579568, Final Batch Loss: 0.0021567405201494694\n",
      "Epoch 2988, Loss: 0.04506942519219592, Final Batch Loss: 0.0008750733104534447\n",
      "Epoch 2989, Loss: 0.061424280516803265, Final Batch Loss: 0.03491656109690666\n",
      "Epoch 2990, Loss: 0.07652856048662215, Final Batch Loss: 0.0014843252720311284\n",
      "Epoch 2991, Loss: 0.02508147433400154, Final Batch Loss: 0.00991988368332386\n",
      "Epoch 2992, Loss: 0.031113251810893416, Final Batch Loss: 0.002349506365135312\n",
      "Epoch 2993, Loss: 0.029859473288524896, Final Batch Loss: 0.000512138765770942\n",
      "Epoch 2994, Loss: 0.07886438351124525, Final Batch Loss: 0.030364377424120903\n",
      "Epoch 2995, Loss: 0.04873177665285766, Final Batch Loss: 0.028536276891827583\n",
      "Epoch 2996, Loss: 0.10584172140806913, Final Batch Loss: 0.04032581299543381\n",
      "Epoch 2997, Loss: 0.11134139634668827, Final Batch Loss: 0.033093880861997604\n",
      "Epoch 2998, Loss: 0.09769884776324034, Final Batch Loss: 0.003173750825226307\n",
      "Epoch 2999, Loss: 0.13531936053186655, Final Batch Loss: 0.005150456912815571\n",
      "Epoch 3000, Loss: 0.04453703621402383, Final Batch Loss: 0.0070780678652226925\n",
      "Epoch 3001, Loss: 0.09629789553582668, Final Batch Loss: 0.035359740257263184\n",
      "Epoch 3002, Loss: 0.06514538731426, Final Batch Loss: 0.031223347410559654\n",
      "Epoch 3003, Loss: 0.14175670687109232, Final Batch Loss: 0.06326454132795334\n",
      "Epoch 3004, Loss: 0.18655477836728096, Final Batch Loss: 0.06389316916465759\n",
      "Epoch 3005, Loss: 0.11621342785656452, Final Batch Loss: 0.0033374372869729996\n",
      "Epoch 3006, Loss: 0.171041211578995, Final Batch Loss: 0.006158801261335611\n",
      "Epoch 3007, Loss: 0.055748746264725924, Final Batch Loss: 0.023053955286741257\n",
      "Epoch 3008, Loss: 0.03383869002573192, Final Batch Loss: 0.012613028287887573\n",
      "Epoch 3009, Loss: 0.12146463664248586, Final Batch Loss: 0.0019104094244539738\n",
      "Epoch 3010, Loss: 0.09630102175287902, Final Batch Loss: 0.003514922922477126\n",
      "Epoch 3011, Loss: 0.087378098978661, Final Batch Loss: 0.0015224007656797767\n",
      "Epoch 3012, Loss: 0.05080759385600686, Final Batch Loss: 0.021936116740107536\n",
      "Epoch 3013, Loss: 0.03136192890815437, Final Batch Loss: 0.005138743203133345\n",
      "Epoch 3014, Loss: 0.06715478672413155, Final Batch Loss: 0.0006578240427188575\n",
      "Epoch 3015, Loss: 0.02929868479259312, Final Batch Loss: 0.009616696275770664\n",
      "Epoch 3016, Loss: 0.12468563113361597, Final Batch Loss: 0.004514784552156925\n",
      "Epoch 3017, Loss: 0.028849363792687654, Final Batch Loss: 0.005071250256150961\n",
      "Epoch 3018, Loss: 0.06775663560256362, Final Batch Loss: 0.0356096513569355\n",
      "Epoch 3019, Loss: 0.04273399617522955, Final Batch Loss: 0.004744832869619131\n",
      "Epoch 3020, Loss: 0.029804447200149298, Final Batch Loss: 0.005904318764805794\n",
      "Epoch 3021, Loss: 0.04821263067424297, Final Batch Loss: 0.01716223917901516\n",
      "Epoch 3022, Loss: 0.11663374956697226, Final Batch Loss: 0.016419121995568275\n",
      "Epoch 3023, Loss: 0.09326452109962702, Final Batch Loss: 0.018272822722792625\n",
      "Epoch 3024, Loss: 0.06010457593947649, Final Batch Loss: 0.005806459113955498\n",
      "Epoch 3025, Loss: 0.058420638320967555, Final Batch Loss: 0.0024189406540244818\n",
      "Epoch 3026, Loss: 0.08204730856232345, Final Batch Loss: 0.0011302146594971418\n",
      "Epoch 3027, Loss: 0.08959840051829815, Final Batch Loss: 0.06257257610559464\n",
      "Epoch 3028, Loss: 0.05882361438125372, Final Batch Loss: 0.032133329659700394\n",
      "Epoch 3029, Loss: 0.06093463581055403, Final Batch Loss: 0.005779915489256382\n",
      "Epoch 3030, Loss: 0.05262977536767721, Final Batch Loss: 0.017066247761249542\n",
      "Epoch 3031, Loss: 0.08236919133923948, Final Batch Loss: 0.024038435891270638\n",
      "Epoch 3032, Loss: 0.0797940962947905, Final Batch Loss: 0.0017584958113729954\n",
      "Epoch 3033, Loss: 0.05442311055958271, Final Batch Loss: 0.005308338440954685\n",
      "Epoch 3034, Loss: 0.07441075332462788, Final Batch Loss: 0.0063033327460289\n",
      "Epoch 3035, Loss: 0.057235898450016975, Final Batch Loss: 0.020769191905856133\n",
      "Epoch 3036, Loss: 0.03364335559308529, Final Batch Loss: 0.002193795284256339\n",
      "Epoch 3037, Loss: 0.04080493072979152, Final Batch Loss: 0.005007455591112375\n",
      "Epoch 3038, Loss: 0.031141678453423083, Final Batch Loss: 0.0017538218526169658\n",
      "Epoch 3039, Loss: 0.014778327953536063, Final Batch Loss: 0.0005978213739581406\n",
      "Epoch 3040, Loss: 0.018904414493590593, Final Batch Loss: 0.0027946357149630785\n",
      "Epoch 3041, Loss: 0.03213082649745047, Final Batch Loss: 0.0033300358336418867\n",
      "Epoch 3042, Loss: 0.018904875963926315, Final Batch Loss: 0.002456632675603032\n",
      "Epoch 3043, Loss: 0.05320887407287955, Final Batch Loss: 0.004121106583625078\n",
      "Epoch 3044, Loss: 0.04096813593059778, Final Batch Loss: 0.010235829278826714\n",
      "Epoch 3045, Loss: 0.058131927624344826, Final Batch Loss: 0.043668776750564575\n",
      "Epoch 3046, Loss: 0.029404201544821262, Final Batch Loss: 0.005131067242473364\n",
      "Epoch 3047, Loss: 0.1063489057123661, Final Batch Loss: 0.02216084487736225\n",
      "Epoch 3048, Loss: 0.04182139248587191, Final Batch Loss: 0.004107637330889702\n",
      "Epoch 3049, Loss: 0.07164325006306171, Final Batch Loss: 0.034593746066093445\n",
      "Epoch 3050, Loss: 0.05842924024909735, Final Batch Loss: 0.006550674792379141\n",
      "Epoch 3051, Loss: 0.03455493599176407, Final Batch Loss: 0.006734848488122225\n",
      "Epoch 3052, Loss: 0.0298754523973912, Final Batch Loss: 0.011042366735637188\n",
      "Epoch 3053, Loss: 0.0768039277754724, Final Batch Loss: 0.005611277651041746\n",
      "Epoch 3054, Loss: 0.029796218499541283, Final Batch Loss: 0.01509833987802267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3055, Loss: 0.0587359182536602, Final Batch Loss: 0.011189382523298264\n",
      "Epoch 3056, Loss: 0.030343216378241777, Final Batch Loss: 0.0022260122932493687\n",
      "Epoch 3057, Loss: 0.02711797133088112, Final Batch Loss: 0.0026210404466837645\n",
      "Epoch 3058, Loss: 0.0471781597007066, Final Batch Loss: 0.019481193274259567\n",
      "Epoch 3059, Loss: 0.15528499009087682, Final Batch Loss: 0.06234091520309448\n",
      "Epoch 3060, Loss: 0.04689048195723444, Final Batch Loss: 0.0013306053588166833\n",
      "Epoch 3061, Loss: 0.12375348224304616, Final Batch Loss: 0.0023616391699761152\n",
      "Epoch 3062, Loss: 0.10155311226844788, Final Batch Loss: 0.008760679513216019\n",
      "Epoch 3063, Loss: 0.12212505307979882, Final Batch Loss: 0.0024116705171763897\n",
      "Epoch 3064, Loss: 0.16886780690401793, Final Batch Loss: 0.06018582358956337\n",
      "Epoch 3065, Loss: 0.15856969985179603, Final Batch Loss: 0.11642903834581375\n",
      "Epoch 3066, Loss: 0.11818452132865787, Final Batch Loss: 0.004299764055758715\n",
      "Epoch 3067, Loss: 0.20144430175423622, Final Batch Loss: 0.04928642138838768\n",
      "Epoch 3068, Loss: 0.11267423490062356, Final Batch Loss: 0.04316733404994011\n",
      "Epoch 3069, Loss: 0.13111561071127653, Final Batch Loss: 0.006930980831384659\n",
      "Epoch 3070, Loss: 0.05967530235648155, Final Batch Loss: 0.01026497408747673\n",
      "Epoch 3071, Loss: 0.044404045678675175, Final Batch Loss: 0.004645536653697491\n",
      "Epoch 3072, Loss: 0.02935509057715535, Final Batch Loss: 0.00809631310403347\n",
      "Epoch 3073, Loss: 0.05334427673369646, Final Batch Loss: 0.012057448737323284\n",
      "Epoch 3074, Loss: 0.056534640258178115, Final Batch Loss: 0.013497800566256046\n",
      "Epoch 3075, Loss: 0.03671821573516354, Final Batch Loss: 0.000534288992639631\n",
      "Epoch 3076, Loss: 0.10912370448932052, Final Batch Loss: 0.0059925043024122715\n",
      "Epoch 3077, Loss: 0.05268900375813246, Final Batch Loss: 0.01083026546984911\n",
      "Epoch 3078, Loss: 0.05709154158830643, Final Batch Loss: 0.02250661887228489\n",
      "Epoch 3079, Loss: 0.0709965112619102, Final Batch Loss: 0.04755527898669243\n",
      "Epoch 3080, Loss: 0.048225344507955015, Final Batch Loss: 0.00033025082666426897\n",
      "Epoch 3081, Loss: 0.029875978594645858, Final Batch Loss: 0.010716062039136887\n",
      "Epoch 3082, Loss: 0.059271430131047964, Final Batch Loss: 0.028176184743642807\n",
      "Epoch 3083, Loss: 0.02797652129083872, Final Batch Loss: 0.004200613126158714\n",
      "Epoch 3084, Loss: 0.04492851905524731, Final Batch Loss: 0.016158493235707283\n",
      "Epoch 3085, Loss: 0.032574288779869676, Final Batch Loss: 0.007290355395525694\n",
      "Epoch 3086, Loss: 0.026606835424900055, Final Batch Loss: 0.003574429079890251\n",
      "Epoch 3087, Loss: 0.08373431861400604, Final Batch Loss: 0.046812865883111954\n",
      "Epoch 3088, Loss: 0.017683201120235026, Final Batch Loss: 0.0016050777630880475\n",
      "Epoch 3089, Loss: 0.04102943488396704, Final Batch Loss: 0.0011516312370076776\n",
      "Epoch 3090, Loss: 0.05980882188305259, Final Batch Loss: 0.001918027875944972\n",
      "Epoch 3091, Loss: 0.02614094433374703, Final Batch Loss: 0.009413905441761017\n",
      "Epoch 3092, Loss: 0.023727904306724668, Final Batch Loss: 0.009371591731905937\n",
      "Epoch 3093, Loss: 0.030056368734221905, Final Batch Loss: 0.001428252668119967\n",
      "Epoch 3094, Loss: 0.042102405335754156, Final Batch Loss: 0.0100985337048769\n",
      "Epoch 3095, Loss: 0.02464023418724537, Final Batch Loss: 0.0036515698302537203\n",
      "Epoch 3096, Loss: 0.033055139472708106, Final Batch Loss: 0.01536861527711153\n",
      "Epoch 3097, Loss: 0.03901793679688126, Final Batch Loss: 0.0015789322787895799\n",
      "Epoch 3098, Loss: 0.030049258610233665, Final Batch Loss: 0.0012665477115660906\n",
      "Epoch 3099, Loss: 0.04569412278942764, Final Batch Loss: 0.003885566955432296\n",
      "Epoch 3100, Loss: 0.04071825719438493, Final Batch Loss: 0.0030605564825236797\n",
      "Epoch 3101, Loss: 0.05463096499443054, Final Batch Loss: 0.021072424948215485\n",
      "Epoch 3102, Loss: 0.02735154191032052, Final Batch Loss: 0.004291311837732792\n",
      "Epoch 3103, Loss: 0.03362624370492995, Final Batch Loss: 0.0032459956128150225\n",
      "Epoch 3104, Loss: 0.015154799446463585, Final Batch Loss: 0.0011064819991588593\n",
      "Epoch 3105, Loss: 0.023695390904322267, Final Batch Loss: 0.004551768768578768\n",
      "Epoch 3106, Loss: 0.049424983910284936, Final Batch Loss: 0.001246341853402555\n",
      "Epoch 3107, Loss: 0.03643203363753855, Final Batch Loss: 0.0018076454289257526\n",
      "Epoch 3108, Loss: 0.02266576699912548, Final Batch Loss: 0.005803072825074196\n",
      "Epoch 3109, Loss: 0.04865341307595372, Final Batch Loss: 0.0036843596026301384\n",
      "Epoch 3110, Loss: 0.011088389554060996, Final Batch Loss: 0.0011807068949565291\n",
      "Epoch 3111, Loss: 0.026221994310617447, Final Batch Loss: 0.002001696964725852\n",
      "Epoch 3112, Loss: 0.025614039157517254, Final Batch Loss: 0.0057008336298167706\n",
      "Epoch 3113, Loss: 0.010230488725937903, Final Batch Loss: 0.0033895811066031456\n",
      "Epoch 3114, Loss: 0.021679138502804562, Final Batch Loss: 0.0003462948079686612\n",
      "Epoch 3115, Loss: 0.02358046267181635, Final Batch Loss: 0.0030464669689536095\n",
      "Epoch 3116, Loss: 0.05520265200175345, Final Batch Loss: 0.0023438541684299707\n",
      "Epoch 3117, Loss: 0.02026683499570936, Final Batch Loss: 0.004525583703070879\n",
      "Epoch 3118, Loss: 0.017649222165346146, Final Batch Loss: 0.0008890836033970118\n",
      "Epoch 3119, Loss: 0.010790310334414244, Final Batch Loss: 0.0008036621147766709\n",
      "Epoch 3120, Loss: 0.03289171843789518, Final Batch Loss: 0.008875197730958462\n",
      "Epoch 3121, Loss: 0.025752648944035172, Final Batch Loss: 0.011314427480101585\n",
      "Epoch 3122, Loss: 0.016414978599641472, Final Batch Loss: 0.0008260273025371134\n",
      "Epoch 3123, Loss: 0.02361874742200598, Final Batch Loss: 0.0013502661604434252\n",
      "Epoch 3124, Loss: 0.07679350639227778, Final Batch Loss: 0.06887098401784897\n",
      "Epoch 3125, Loss: 0.014716569217853248, Final Batch Loss: 0.0015432544751092792\n",
      "Epoch 3126, Loss: 0.03217633726308122, Final Batch Loss: 0.00674611609429121\n",
      "Epoch 3127, Loss: 0.03060900780837983, Final Batch Loss: 0.0010703349253162742\n",
      "Epoch 3128, Loss: 0.015716380177764222, Final Batch Loss: 0.00039324929821304977\n",
      "Epoch 3129, Loss: 0.019317286903969944, Final Batch Loss: 0.004345424007624388\n",
      "Epoch 3130, Loss: 0.039412421465385705, Final Batch Loss: 0.03355235978960991\n",
      "Epoch 3131, Loss: 0.012444837368093431, Final Batch Loss: 0.0036378505174070597\n",
      "Epoch 3132, Loss: 0.017815820290707052, Final Batch Loss: 0.0015642744256183505\n",
      "Epoch 3133, Loss: 0.07164127775467932, Final Batch Loss: 0.011729415506124496\n",
      "Epoch 3134, Loss: 0.04164796869736165, Final Batch Loss: 0.001016556634567678\n",
      "Epoch 3135, Loss: 0.036210964259225875, Final Batch Loss: 0.0009459092398174107\n",
      "Epoch 3136, Loss: 0.13515966851264238, Final Batch Loss: 0.07441046088933945\n",
      "Epoch 3137, Loss: 0.046422168612480164, Final Batch Loss: 0.014070629142224789\n",
      "Epoch 3138, Loss: 0.09437781479209661, Final Batch Loss: 0.009099658578634262\n",
      "Epoch 3139, Loss: 0.0714890118688345, Final Batch Loss: 0.0025852015241980553\n",
      "Epoch 3140, Loss: 0.11840820033103228, Final Batch Loss: 0.004000379703938961\n",
      "Epoch 3141, Loss: 0.14781970484182239, Final Batch Loss: 0.05009026080369949\n",
      "Epoch 3142, Loss: 0.045863402308896184, Final Batch Loss: 0.02126261591911316\n",
      "Epoch 3143, Loss: 0.10210422053933144, Final Batch Loss: 0.009703150019049644\n",
      "Epoch 3144, Loss: 0.14457852859050035, Final Batch Loss: 0.01914222165942192\n",
      "Epoch 3145, Loss: 0.10239332355558872, Final Batch Loss: 0.010505430400371552\n",
      "Epoch 3146, Loss: 0.2010525707155466, Final Batch Loss: 0.16543515026569366\n",
      "Epoch 3147, Loss: 0.03672963986173272, Final Batch Loss: 0.004696854390203953\n",
      "Epoch 3148, Loss: 0.11007761768996716, Final Batch Loss: 0.06301254034042358\n",
      "Epoch 3149, Loss: 0.11778495088219643, Final Batch Loss: 0.01900923252105713\n",
      "Epoch 3150, Loss: 0.08165569510310888, Final Batch Loss: 0.00655148271471262\n",
      "Epoch 3151, Loss: 0.19189995620399714, Final Batch Loss: 0.002426563296467066\n",
      "Epoch 3152, Loss: 0.08889062097296119, Final Batch Loss: 0.004260713700205088\n",
      "Epoch 3153, Loss: 0.04894760879687965, Final Batch Loss: 0.0025369543582201004\n",
      "Epoch 3154, Loss: 0.06647815462201834, Final Batch Loss: 0.0027177585288882256\n",
      "Epoch 3155, Loss: 0.22097479365766048, Final Batch Loss: 0.12039075791835785\n",
      "Epoch 3156, Loss: 0.05090324650518596, Final Batch Loss: 0.0029515151400119066\n",
      "Epoch 3157, Loss: 0.06681599002331495, Final Batch Loss: 0.040780555456876755\n",
      "Epoch 3158, Loss: 0.10509197041392326, Final Batch Loss: 0.005678800866007805\n",
      "Epoch 3159, Loss: 0.1183646023273468, Final Batch Loss: 0.021904457360506058\n",
      "Epoch 3160, Loss: 0.06552742375060916, Final Batch Loss: 0.03893940895795822\n",
      "Epoch 3161, Loss: 0.05529699241742492, Final Batch Loss: 0.0022890139371156693\n",
      "Epoch 3162, Loss: 0.09856717474758625, Final Batch Loss: 0.011784235015511513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3163, Loss: 0.09987781662493944, Final Batch Loss: 0.042466796934604645\n",
      "Epoch 3164, Loss: 0.053973022382706404, Final Batch Loss: 0.01664254628121853\n",
      "Epoch 3165, Loss: 0.1638853568583727, Final Batch Loss: 0.009764404967427254\n",
      "Epoch 3166, Loss: 0.0919978991150856, Final Batch Loss: 0.0658772811293602\n",
      "Epoch 3167, Loss: 0.022815581876784563, Final Batch Loss: 0.0027733228635042906\n",
      "Epoch 3168, Loss: 0.047513483092188835, Final Batch Loss: 0.008575139567255974\n",
      "Epoch 3169, Loss: 0.04463486676104367, Final Batch Loss: 0.0025950546842068434\n",
      "Epoch 3170, Loss: 0.06745621655136347, Final Batch Loss: 0.010462568141520023\n",
      "Epoch 3171, Loss: 0.047466626623645425, Final Batch Loss: 0.020436132326722145\n",
      "Epoch 3172, Loss: 0.06681256601586938, Final Batch Loss: 0.014599253423511982\n",
      "Epoch 3173, Loss: 0.08973361179232597, Final Batch Loss: 0.011408902704715729\n",
      "Epoch 3174, Loss: 0.03463257383555174, Final Batch Loss: 0.00457446463406086\n",
      "Epoch 3175, Loss: 0.08606075728312135, Final Batch Loss: 0.021278871223330498\n",
      "Epoch 3176, Loss: 0.02851093339268118, Final Batch Loss: 0.001731287338770926\n",
      "Epoch 3177, Loss: 0.09728335402905941, Final Batch Loss: 0.07094626128673553\n",
      "Epoch 3178, Loss: 0.01771066361106932, Final Batch Loss: 0.004076060373336077\n",
      "Epoch 3179, Loss: 0.060519869439303875, Final Batch Loss: 0.005249345675110817\n",
      "Epoch 3180, Loss: 0.022602634970098734, Final Batch Loss: 0.0033045774325728416\n",
      "Epoch 3181, Loss: 0.02444496378302574, Final Batch Loss: 0.005162139888852835\n",
      "Epoch 3182, Loss: 0.1588319013826549, Final Batch Loss: 0.10417046397924423\n",
      "Epoch 3183, Loss: 0.07413900014944375, Final Batch Loss: 0.0030452825594693422\n",
      "Epoch 3184, Loss: 0.07159735867753625, Final Batch Loss: 0.0425882525742054\n",
      "Epoch 3185, Loss: 0.02123357681557536, Final Batch Loss: 0.004176262766122818\n",
      "Epoch 3186, Loss: 0.02776322327554226, Final Batch Loss: 0.0021323098335415125\n",
      "Epoch 3187, Loss: 0.04534126992803067, Final Batch Loss: 0.0013970417203381658\n",
      "Epoch 3188, Loss: 0.03218327625654638, Final Batch Loss: 0.006564549636095762\n",
      "Epoch 3189, Loss: 0.07380733615718782, Final Batch Loss: 0.03207865729928017\n",
      "Epoch 3190, Loss: 0.06445573316887021, Final Batch Loss: 0.02740619145333767\n",
      "Epoch 3191, Loss: 0.07509123883210123, Final Batch Loss: 0.03342162445187569\n",
      "Epoch 3192, Loss: 0.05129426205530763, Final Batch Loss: 0.006093598902225494\n",
      "Epoch 3193, Loss: 0.07761592837050557, Final Batch Loss: 0.024569712579250336\n",
      "Epoch 3194, Loss: 0.035998955368995667, Final Batch Loss: 0.001860730117186904\n",
      "Epoch 3195, Loss: 0.05228768056258559, Final Batch Loss: 0.004665664862841368\n",
      "Epoch 3196, Loss: 0.03267428232356906, Final Batch Loss: 0.004182907287031412\n",
      "Epoch 3197, Loss: 0.04088456369936466, Final Batch Loss: 0.007225112058222294\n",
      "Epoch 3198, Loss: 0.05302514648064971, Final Batch Loss: 0.0217375997453928\n",
      "Epoch 3199, Loss: 0.033054577419534326, Final Batch Loss: 0.006754447240382433\n",
      "Epoch 3200, Loss: 0.06975234858691692, Final Batch Loss: 0.022633692249655724\n",
      "Epoch 3201, Loss: 0.03857359918765724, Final Batch Loss: 0.0030832404736429453\n",
      "Epoch 3202, Loss: 0.053893989766947925, Final Batch Loss: 0.04105067625641823\n",
      "Epoch 3203, Loss: 0.014759952784515917, Final Batch Loss: 0.0011223190231248736\n",
      "Epoch 3204, Loss: 0.05439080763608217, Final Batch Loss: 0.0014529768377542496\n",
      "Epoch 3205, Loss: 0.08044042252004147, Final Batch Loss: 0.0021367864683270454\n",
      "Epoch 3206, Loss: 0.056274877628311515, Final Batch Loss: 0.01915428601205349\n",
      "Epoch 3207, Loss: 0.037915659428108484, Final Batch Loss: 0.0008818701026029885\n",
      "Epoch 3208, Loss: 0.012919461936689913, Final Batch Loss: 0.0005459025269374251\n",
      "Epoch 3209, Loss: 0.02309404220432043, Final Batch Loss: 0.0021275135222822428\n",
      "Epoch 3210, Loss: 0.037620563292875886, Final Batch Loss: 0.0025781153235584497\n",
      "Epoch 3211, Loss: 0.08689763164147735, Final Batch Loss: 0.0025597880594432354\n",
      "Epoch 3212, Loss: 0.040077298413962126, Final Batch Loss: 0.010196533054113388\n",
      "Epoch 3213, Loss: 0.020067741628736258, Final Batch Loss: 0.0014414614997804165\n",
      "Epoch 3214, Loss: 0.052127752685919404, Final Batch Loss: 0.027117537334561348\n",
      "Epoch 3215, Loss: 0.07169858820270747, Final Batch Loss: 0.000959991361014545\n",
      "Epoch 3216, Loss: 0.05530302529223263, Final Batch Loss: 0.01512835267931223\n",
      "Epoch 3217, Loss: 0.0740499955136329, Final Batch Loss: 0.006378249265253544\n",
      "Epoch 3218, Loss: 0.09533267095685005, Final Batch Loss: 0.03233150392770767\n",
      "Epoch 3219, Loss: 0.06538982596248388, Final Batch Loss: 0.02959165908396244\n",
      "Epoch 3220, Loss: 0.03768477635458112, Final Batch Loss: 0.0028477711603045464\n",
      "Epoch 3221, Loss: 0.06755804177373648, Final Batch Loss: 0.012474536895751953\n",
      "Epoch 3222, Loss: 0.03556134202517569, Final Batch Loss: 0.0008541059214621782\n",
      "Epoch 3223, Loss: 0.08606371469795704, Final Batch Loss: 0.008171026594936848\n",
      "Epoch 3224, Loss: 0.07414582511410117, Final Batch Loss: 0.022971663624048233\n",
      "Epoch 3225, Loss: 0.08492558647412807, Final Batch Loss: 0.001014062319882214\n",
      "Epoch 3226, Loss: 0.03493281872943044, Final Batch Loss: 0.008619897067546844\n",
      "Epoch 3227, Loss: 0.07160222227685153, Final Batch Loss: 0.027006130665540695\n",
      "Epoch 3228, Loss: 0.10421791672706604, Final Batch Loss: 0.04075000807642937\n",
      "Epoch 3229, Loss: 0.17609515599906445, Final Batch Loss: 0.0223048385232687\n",
      "Epoch 3230, Loss: 0.17414221540093422, Final Batch Loss: 0.08574546873569489\n",
      "Epoch 3231, Loss: 0.18351875618100166, Final Batch Loss: 0.04783044010400772\n",
      "Epoch 3232, Loss: 0.18280408158898354, Final Batch Loss: 0.10708056390285492\n",
      "Epoch 3233, Loss: 0.07640339434146881, Final Batch Loss: 0.020342715084552765\n",
      "Epoch 3234, Loss: 0.19679745100438595, Final Batch Loss: 0.07543971389532089\n",
      "Epoch 3235, Loss: 0.09577243868261576, Final Batch Loss: 0.04341566935181618\n",
      "Epoch 3236, Loss: 0.12167075031902641, Final Batch Loss: 0.0012305009877309203\n",
      "Epoch 3237, Loss: 0.10315379151143134, Final Batch Loss: 0.000981231452897191\n",
      "Epoch 3238, Loss: 0.0966305723413825, Final Batch Loss: 0.011173811741173267\n",
      "Epoch 3239, Loss: 0.04349706938955933, Final Batch Loss: 0.00664912723004818\n",
      "Epoch 3240, Loss: 0.15637900680303574, Final Batch Loss: 0.016743764281272888\n",
      "Epoch 3241, Loss: 0.05743345990777016, Final Batch Loss: 0.011833112686872482\n",
      "Epoch 3242, Loss: 0.10228077787905931, Final Batch Loss: 0.0038195503875613213\n",
      "Epoch 3243, Loss: 0.04801369505003095, Final Batch Loss: 0.004445949569344521\n",
      "Epoch 3244, Loss: 0.10429434129036963, Final Batch Loss: 0.0035812437999993563\n",
      "Epoch 3245, Loss: 0.04647023696452379, Final Batch Loss: 0.0071728830225765705\n",
      "Epoch 3246, Loss: 0.03041012748144567, Final Batch Loss: 0.0030082848388701677\n",
      "Epoch 3247, Loss: 0.030130968429148197, Final Batch Loss: 0.02398643083870411\n",
      "Epoch 3248, Loss: 0.033475871896371245, Final Batch Loss: 0.006570985075086355\n",
      "Epoch 3249, Loss: 0.030805618269369006, Final Batch Loss: 0.0024847376625984907\n",
      "Epoch 3250, Loss: 0.01635022077243775, Final Batch Loss: 0.0032827050890773535\n",
      "Epoch 3251, Loss: 0.02808809489943087, Final Batch Loss: 0.0016591630410403013\n",
      "Epoch 3252, Loss: 0.014625044132117182, Final Batch Loss: 0.0009136447333730757\n",
      "Epoch 3253, Loss: 0.07297486905008554, Final Batch Loss: 0.008057065308094025\n",
      "Epoch 3254, Loss: 0.03549140377435833, Final Batch Loss: 0.010564861819148064\n",
      "Epoch 3255, Loss: 0.036010148003697395, Final Batch Loss: 0.012535501271486282\n",
      "Epoch 3256, Loss: 0.03606010088697076, Final Batch Loss: 0.005675992928445339\n",
      "Epoch 3257, Loss: 0.04665454407222569, Final Batch Loss: 0.014259051531553268\n",
      "Epoch 3258, Loss: 0.020478329970501363, Final Batch Loss: 0.001931513543240726\n",
      "Epoch 3259, Loss: 0.01377620839048177, Final Batch Loss: 0.001897897687740624\n",
      "Epoch 3260, Loss: 0.0857222625054419, Final Batch Loss: 0.005703953560441732\n",
      "Epoch 3261, Loss: 0.05171833181520924, Final Batch Loss: 0.0009209669078700244\n",
      "Epoch 3262, Loss: 0.08862946182489395, Final Batch Loss: 0.033344607800245285\n",
      "Epoch 3263, Loss: 0.08707826817408204, Final Batch Loss: 0.0540926493704319\n",
      "Epoch 3264, Loss: 0.02760839438997209, Final Batch Loss: 0.004439240787178278\n",
      "Epoch 3265, Loss: 0.03519797115586698, Final Batch Loss: 0.004164703655987978\n",
      "Epoch 3266, Loss: 0.0601052213460207, Final Batch Loss: 0.006621107459068298\n",
      "Epoch 3267, Loss: 0.02101427863817662, Final Batch Loss: 0.002442649332806468\n",
      "Epoch 3268, Loss: 0.0803015218116343, Final Batch Loss: 0.019562114030122757\n",
      "Epoch 3269, Loss: 0.017864490626379848, Final Batch Loss: 0.0013201909605413675\n",
      "Epoch 3270, Loss: 0.05270202225074172, Final Batch Loss: 0.0024276981130242348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3271, Loss: 0.07189258886501193, Final Batch Loss: 0.009054609574377537\n",
      "Epoch 3272, Loss: 0.07093679253011942, Final Batch Loss: 0.022085705772042274\n",
      "Epoch 3273, Loss: 0.035921802278608084, Final Batch Loss: 0.01472656149417162\n",
      "Epoch 3274, Loss: 0.10922556137666106, Final Batch Loss: 0.06183977052569389\n",
      "Epoch 3275, Loss: 0.044418736128136516, Final Batch Loss: 0.019283777102828026\n",
      "Epoch 3276, Loss: 0.04336243751458824, Final Batch Loss: 0.0035061256494373083\n",
      "Epoch 3277, Loss: 0.023549303878098726, Final Batch Loss: 0.0026980962138623\n",
      "Epoch 3278, Loss: 0.031041215173900127, Final Batch Loss: 0.006804132368415594\n",
      "Epoch 3279, Loss: 0.04598076734691858, Final Batch Loss: 0.001784338615834713\n",
      "Epoch 3280, Loss: 0.06032750254962593, Final Batch Loss: 0.0019107457483187318\n",
      "Epoch 3281, Loss: 0.0703317845473066, Final Batch Loss: 0.0032828005496412516\n",
      "Epoch 3282, Loss: 0.07935989485122263, Final Batch Loss: 0.02656087465584278\n",
      "Epoch 3283, Loss: 0.024446025607176125, Final Batch Loss: 0.0015109857777133584\n",
      "Epoch 3284, Loss: 0.046083277091383934, Final Batch Loss: 0.005542509723454714\n",
      "Epoch 3285, Loss: 0.04282024432905018, Final Batch Loss: 0.0038255085237324238\n",
      "Epoch 3286, Loss: 0.04619723453652114, Final Batch Loss: 0.0005498033715412021\n",
      "Epoch 3287, Loss: 0.047239873791113496, Final Batch Loss: 0.0022921196650713682\n",
      "Epoch 3288, Loss: 0.02992217126302421, Final Batch Loss: 0.0012091186363250017\n",
      "Epoch 3289, Loss: 0.018356649205088615, Final Batch Loss: 0.0019322014413774014\n",
      "Epoch 3290, Loss: 0.02274782315362245, Final Batch Loss: 0.0006813131039962173\n",
      "Epoch 3291, Loss: 0.030202037072740495, Final Batch Loss: 0.0018267197301611304\n",
      "Epoch 3292, Loss: 0.03581975121051073, Final Batch Loss: 0.00958320964127779\n",
      "Epoch 3293, Loss: 0.050492601294536144, Final Batch Loss: 0.000805893272627145\n",
      "Epoch 3294, Loss: 0.02952210744842887, Final Batch Loss: 0.003934326581656933\n",
      "Epoch 3295, Loss: 0.046956207836046815, Final Batch Loss: 0.0028243691194802523\n",
      "Epoch 3296, Loss: 0.06569591455627233, Final Batch Loss: 0.01646648347377777\n",
      "Epoch 3297, Loss: 0.012307779281400144, Final Batch Loss: 0.0017003512475639582\n",
      "Epoch 3298, Loss: 0.02279524807818234, Final Batch Loss: 0.0021662297658622265\n",
      "Epoch 3299, Loss: 0.08365473547019064, Final Batch Loss: 0.004092838149517775\n",
      "Epoch 3300, Loss: 0.03461919818073511, Final Batch Loss: 0.003954208921641111\n",
      "Epoch 3301, Loss: 0.014308512443676591, Final Batch Loss: 0.0020612606313079596\n",
      "Epoch 3302, Loss: 0.03363892063498497, Final Batch Loss: 0.009670935571193695\n",
      "Epoch 3303, Loss: 0.006651027943007648, Final Batch Loss: 0.0008674664422869682\n",
      "Epoch 3304, Loss: 0.019798553781583905, Final Batch Loss: 0.001833614893257618\n",
      "Epoch 3305, Loss: 0.03570181177929044, Final Batch Loss: 0.002828224329277873\n",
      "Epoch 3306, Loss: 0.04754328913986683, Final Batch Loss: 0.009342526085674763\n",
      "Epoch 3307, Loss: 0.04084461322054267, Final Batch Loss: 0.008801759220659733\n",
      "Epoch 3308, Loss: 0.012863821408245713, Final Batch Loss: 0.00039893266512081027\n",
      "Epoch 3309, Loss: 0.06403964920900762, Final Batch Loss: 0.026785587891936302\n",
      "Epoch 3310, Loss: 0.09363982290960848, Final Batch Loss: 0.06717149913311005\n",
      "Epoch 3311, Loss: 0.05730108474381268, Final Batch Loss: 0.02066594548523426\n",
      "Epoch 3312, Loss: 0.036362106213346124, Final Batch Loss: 0.002168349688872695\n",
      "Epoch 3313, Loss: 0.0811128169298172, Final Batch Loss: 0.012628420256078243\n",
      "Epoch 3314, Loss: 0.01823465374764055, Final Batch Loss: 0.002711567562073469\n",
      "Epoch 3315, Loss: 0.030055748065933585, Final Batch Loss: 0.0018892742227762938\n",
      "Epoch 3316, Loss: 0.07483016513288021, Final Batch Loss: 0.010266441851854324\n",
      "Epoch 3317, Loss: 0.05202800082042813, Final Batch Loss: 0.011164046823978424\n",
      "Epoch 3318, Loss: 0.03267931123264134, Final Batch Loss: 0.0030507768969982862\n",
      "Epoch 3319, Loss: 0.019677891163155437, Final Batch Loss: 0.0021531933452934027\n",
      "Epoch 3320, Loss: 0.07733302179258317, Final Batch Loss: 0.06648322194814682\n",
      "Epoch 3321, Loss: 0.017287186812609434, Final Batch Loss: 0.010039171203970909\n",
      "Epoch 3322, Loss: 0.016623126401100308, Final Batch Loss: 0.00036594743141904473\n",
      "Epoch 3323, Loss: 0.0723288266453892, Final Batch Loss: 0.0013911055866628885\n",
      "Epoch 3324, Loss: 0.07058171462267637, Final Batch Loss: 0.01678093522787094\n",
      "Epoch 3325, Loss: 0.015495093539357185, Final Batch Loss: 0.0038608266040682793\n",
      "Epoch 3326, Loss: 0.022879635100252926, Final Batch Loss: 0.0014815704198554158\n",
      "Epoch 3327, Loss: 0.036569687828887254, Final Batch Loss: 0.032715313136577606\n",
      "Epoch 3328, Loss: 0.022366633405908942, Final Batch Loss: 0.003718262305483222\n",
      "Epoch 3329, Loss: 0.1654990913812071, Final Batch Loss: 0.0017529355827718973\n",
      "Epoch 3330, Loss: 0.07865385105833411, Final Batch Loss: 0.049102529883384705\n",
      "Epoch 3331, Loss: 0.05179642187431455, Final Batch Loss: 0.002220808994024992\n",
      "Epoch 3332, Loss: 0.08118386240676045, Final Batch Loss: 0.0013881153427064419\n",
      "Epoch 3333, Loss: 0.13914474938064814, Final Batch Loss: 0.0061135562136769295\n",
      "Epoch 3334, Loss: 0.1516701988875866, Final Batch Loss: 0.01758769527077675\n",
      "Epoch 3335, Loss: 0.06951001932611689, Final Batch Loss: 0.0008259685127995908\n",
      "Epoch 3336, Loss: 0.05665896530263126, Final Batch Loss: 0.0025922532659024\n",
      "Epoch 3337, Loss: 0.044850549194961786, Final Batch Loss: 0.0013692076317965984\n",
      "Epoch 3338, Loss: 0.024108089375658892, Final Batch Loss: 0.00021589767129626125\n",
      "Epoch 3339, Loss: 0.06451670825481415, Final Batch Loss: 0.008581606671214104\n",
      "Epoch 3340, Loss: 0.025466209510341287, Final Batch Loss: 0.00285142008215189\n",
      "Epoch 3341, Loss: 0.04622696386650205, Final Batch Loss: 0.0011413195170462132\n",
      "Epoch 3342, Loss: 0.053586260648444295, Final Batch Loss: 0.0013165224809199572\n",
      "Epoch 3343, Loss: 0.023944466141983867, Final Batch Loss: 0.009508749470114708\n",
      "Epoch 3344, Loss: 0.02559298354026396, Final Batch Loss: 0.00013767155178356916\n",
      "Epoch 3345, Loss: 0.10920307785272598, Final Batch Loss: 0.07427272945642471\n",
      "Epoch 3346, Loss: 0.027981551364064217, Final Batch Loss: 0.0018969853408634663\n",
      "Epoch 3347, Loss: 0.07208966510370374, Final Batch Loss: 0.05056015029549599\n",
      "Epoch 3348, Loss: 0.019936953554861248, Final Batch Loss: 0.006076416466385126\n",
      "Epoch 3349, Loss: 0.09143268968909979, Final Batch Loss: 0.030328964814543724\n",
      "Epoch 3350, Loss: 0.015551772899925709, Final Batch Loss: 0.0017436400521546602\n",
      "Epoch 3351, Loss: 0.029072397388517857, Final Batch Loss: 0.004928546492010355\n",
      "Epoch 3352, Loss: 0.058769102208316326, Final Batch Loss: 0.004159634932875633\n",
      "Epoch 3353, Loss: 0.04450659896247089, Final Batch Loss: 0.0025471297558397055\n",
      "Epoch 3354, Loss: 0.0450891877990216, Final Batch Loss: 0.002833366161212325\n",
      "Epoch 3355, Loss: 0.04370169481262565, Final Batch Loss: 0.009298975579440594\n",
      "Epoch 3356, Loss: 0.0294561383780092, Final Batch Loss: 0.002525222720578313\n",
      "Epoch 3357, Loss: 0.021773065207526088, Final Batch Loss: 0.0038757382426410913\n",
      "Epoch 3358, Loss: 0.0658754616160877, Final Batch Loss: 0.0006073916447348893\n",
      "Epoch 3359, Loss: 0.0324834946077317, Final Batch Loss: 0.009179084561765194\n",
      "Epoch 3360, Loss: 0.07617555488832295, Final Batch Loss: 0.017575232312083244\n",
      "Epoch 3361, Loss: 0.0315774031332694, Final Batch Loss: 0.0006478807772509754\n",
      "Epoch 3362, Loss: 0.025338471168652177, Final Batch Loss: 0.00525725819170475\n",
      "Epoch 3363, Loss: 0.013371997978538275, Final Batch Loss: 0.0031706644222140312\n",
      "Epoch 3364, Loss: 0.043073078559245914, Final Batch Loss: 0.00018769135931506753\n",
      "Epoch 3365, Loss: 0.008255134453065693, Final Batch Loss: 0.0025348037015646696\n",
      "Epoch 3366, Loss: 0.009770923643372953, Final Batch Loss: 0.0009880493162199855\n",
      "Epoch 3367, Loss: 0.024047026527114213, Final Batch Loss: 0.0010118552017956972\n",
      "Epoch 3368, Loss: 0.0930913652991876, Final Batch Loss: 0.08700686693191528\n",
      "Epoch 3369, Loss: 0.03136625955812633, Final Batch Loss: 0.004716061055660248\n",
      "Epoch 3370, Loss: 0.018013303284533322, Final Batch Loss: 0.003011281369253993\n",
      "Epoch 3371, Loss: 0.02467045048251748, Final Batch Loss: 0.014378268271684647\n",
      "Epoch 3372, Loss: 0.061373384203761816, Final Batch Loss: 0.0024212091229856014\n",
      "Epoch 3373, Loss: 0.02732959995046258, Final Batch Loss: 0.006151223089545965\n",
      "Epoch 3374, Loss: 0.031196388707030565, Final Batch Loss: 0.0005457895458675921\n",
      "Epoch 3375, Loss: 0.03632917965296656, Final Batch Loss: 0.0017940712859854102\n",
      "Epoch 3376, Loss: 0.026847573928534985, Final Batch Loss: 0.00463902996852994\n",
      "Epoch 3377, Loss: 0.023392683593556285, Final Batch Loss: 0.003205182496458292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3378, Loss: 0.00967899663373828, Final Batch Loss: 0.0014390924479812384\n",
      "Epoch 3379, Loss: 0.11143280903343111, Final Batch Loss: 0.09391649812459946\n",
      "Epoch 3380, Loss: 0.012189273140393198, Final Batch Loss: 0.0022718538530170918\n",
      "Epoch 3381, Loss: 0.021992904774378985, Final Batch Loss: 0.0005036342772655189\n",
      "Epoch 3382, Loss: 0.08125090971589088, Final Batch Loss: 0.013502111658453941\n",
      "Epoch 3383, Loss: 0.034581218380481005, Final Batch Loss: 0.002834944287315011\n",
      "Epoch 3384, Loss: 0.11280422145500779, Final Batch Loss: 0.054914940148591995\n",
      "Epoch 3385, Loss: 0.13287100195884705, Final Batch Loss: 0.09709387272596359\n",
      "Epoch 3386, Loss: 0.02008257166016847, Final Batch Loss: 0.0011693184496834874\n",
      "Epoch 3387, Loss: 0.08110542828217149, Final Batch Loss: 0.022810200229287148\n",
      "Epoch 3388, Loss: 0.09126403369009495, Final Batch Loss: 0.018041511997580528\n",
      "Epoch 3389, Loss: 0.041434620041400194, Final Batch Loss: 0.004847602918744087\n",
      "Epoch 3390, Loss: 0.017676900257356465, Final Batch Loss: 0.0014843078097328544\n",
      "Epoch 3391, Loss: 0.03412354318425059, Final Batch Loss: 0.012752617709338665\n",
      "Epoch 3392, Loss: 0.05697523464914411, Final Batch Loss: 0.0011189201613888144\n",
      "Epoch 3393, Loss: 0.11577546666376293, Final Batch Loss: 0.07586204260587692\n",
      "Epoch 3394, Loss: 0.16567020304501057, Final Batch Loss: 0.0754551962018013\n",
      "Epoch 3395, Loss: 0.07215943234041333, Final Batch Loss: 0.018689138814806938\n",
      "Epoch 3396, Loss: 0.16440478526055813, Final Batch Loss: 0.002803333103656769\n",
      "Epoch 3397, Loss: 0.20043745078146458, Final Batch Loss: 0.14248472452163696\n",
      "Epoch 3398, Loss: 0.03142319817561656, Final Batch Loss: 0.023772872984409332\n",
      "Epoch 3399, Loss: 0.037026338279247284, Final Batch Loss: 0.005256457719951868\n",
      "Epoch 3400, Loss: 0.10691768862307072, Final Batch Loss: 0.026492388918995857\n",
      "Epoch 3401, Loss: 0.08041888475418091, Final Batch Loss: 0.0052042873576283455\n",
      "Epoch 3402, Loss: 0.1270390897989273, Final Batch Loss: 0.02713317610323429\n",
      "Epoch 3403, Loss: 0.09743561688810587, Final Batch Loss: 0.014299949631094933\n",
      "Epoch 3404, Loss: 0.05140518839471042, Final Batch Loss: 0.0037141682114452124\n",
      "Epoch 3405, Loss: 0.036342353792861104, Final Batch Loss: 0.0029147628229111433\n",
      "Epoch 3406, Loss: 0.059192264918237925, Final Batch Loss: 0.02502582035958767\n",
      "Epoch 3407, Loss: 0.03280851058661938, Final Batch Loss: 0.004435802344232798\n",
      "Epoch 3408, Loss: 0.036996175069361925, Final Batch Loss: 0.005823989398777485\n",
      "Epoch 3409, Loss: 0.08045175299048424, Final Batch Loss: 0.027090195566415787\n",
      "Epoch 3410, Loss: 0.04205138306133449, Final Batch Loss: 0.024513978511095047\n",
      "Epoch 3411, Loss: 0.04572993377223611, Final Batch Loss: 0.004598241299390793\n",
      "Epoch 3412, Loss: 0.034645686973817647, Final Batch Loss: 0.0015868513146415353\n",
      "Epoch 3413, Loss: 0.02147081191651523, Final Batch Loss: 0.0023236586712300777\n",
      "Epoch 3414, Loss: 0.06437660870142281, Final Batch Loss: 0.0016872205305844545\n",
      "Epoch 3415, Loss: 0.04572169156745076, Final Batch Loss: 0.00597164873033762\n",
      "Epoch 3416, Loss: 0.0246240496635437, Final Batch Loss: 0.0007985921110957861\n",
      "Epoch 3417, Loss: 0.04783233368652873, Final Batch Loss: 0.0002401070378255099\n",
      "Epoch 3418, Loss: 0.09853059670422226, Final Batch Loss: 0.004812001250684261\n",
      "Epoch 3419, Loss: 0.07397040259093046, Final Batch Loss: 0.030113207176327705\n",
      "Epoch 3420, Loss: 0.04578556981869042, Final Batch Loss: 0.011525995098054409\n",
      "Epoch 3421, Loss: 0.06255728099495173, Final Batch Loss: 0.003253357484936714\n",
      "Epoch 3422, Loss: 0.020104738068766892, Final Batch Loss: 0.0036903226282447577\n",
      "Epoch 3423, Loss: 0.04232905886601657, Final Batch Loss: 0.0015764156123623252\n",
      "Epoch 3424, Loss: 0.06871377385687083, Final Batch Loss: 0.058330368250608444\n",
      "Epoch 3425, Loss: 0.07143442356027663, Final Batch Loss: 0.0023392506409436464\n",
      "Epoch 3426, Loss: 0.07879101624712348, Final Batch Loss: 0.009879376739263535\n",
      "Epoch 3427, Loss: 0.08103735279291868, Final Batch Loss: 0.020513880997896194\n",
      "Epoch 3428, Loss: 0.06416693422943354, Final Batch Loss: 0.008435479365289211\n",
      "Epoch 3429, Loss: 0.027621563407592475, Final Batch Loss: 0.0038213753141462803\n",
      "Epoch 3430, Loss: 0.05710901995189488, Final Batch Loss: 0.013930421322584152\n",
      "Epoch 3431, Loss: 0.12054206500761211, Final Batch Loss: 0.11262460052967072\n",
      "Epoch 3432, Loss: 0.06424830108880997, Final Batch Loss: 0.005971983075141907\n",
      "Epoch 3433, Loss: 0.025578745640814304, Final Batch Loss: 0.008493464440107346\n",
      "Epoch 3434, Loss: 0.0635652607306838, Final Batch Loss: 0.025208046659827232\n",
      "Epoch 3435, Loss: 0.036376007134094834, Final Batch Loss: 0.016536489129066467\n",
      "Epoch 3436, Loss: 0.05776685103774071, Final Batch Loss: 0.0034354643430560827\n",
      "Epoch 3437, Loss: 0.0791052405256778, Final Batch Loss: 0.014641736634075642\n",
      "Epoch 3438, Loss: 0.06619641883298755, Final Batch Loss: 0.0043144384399056435\n",
      "Epoch 3439, Loss: 0.03555245348252356, Final Batch Loss: 0.015944980084896088\n",
      "Epoch 3440, Loss: 0.02819868247024715, Final Batch Loss: 0.0032760652247816324\n",
      "Epoch 3441, Loss: 0.0406615911051631, Final Batch Loss: 0.004948520567268133\n",
      "Epoch 3442, Loss: 0.022473123855888844, Final Batch Loss: 0.0061457110568881035\n",
      "Epoch 3443, Loss: 0.01792552601546049, Final Batch Loss: 0.0016648902092128992\n",
      "Epoch 3444, Loss: 0.058643980883061886, Final Batch Loss: 0.0015609413385391235\n",
      "Epoch 3445, Loss: 0.017337049008347094, Final Batch Loss: 0.002626328030601144\n",
      "Epoch 3446, Loss: 0.02751840715063736, Final Batch Loss: 0.0008646861533634365\n",
      "Epoch 3447, Loss: 0.06804222660139203, Final Batch Loss: 0.004787313286215067\n",
      "Epoch 3448, Loss: 0.01721911085769534, Final Batch Loss: 0.0012446896871551871\n",
      "Epoch 3449, Loss: 0.08234818652272224, Final Batch Loss: 0.028050165623426437\n",
      "Epoch 3450, Loss: 0.019318901700899005, Final Batch Loss: 0.0076387254521250725\n",
      "Epoch 3451, Loss: 0.049367404310032725, Final Batch Loss: 0.0035314082633703947\n",
      "Epoch 3452, Loss: 0.024112872662954032, Final Batch Loss: 0.0015516459243372083\n",
      "Epoch 3453, Loss: 0.02063960046507418, Final Batch Loss: 0.003190103219822049\n",
      "Epoch 3454, Loss: 0.03606292721815407, Final Batch Loss: 0.0066491058096289635\n",
      "Epoch 3455, Loss: 0.11203991714864969, Final Batch Loss: 0.036956995725631714\n",
      "Epoch 3456, Loss: 0.040071504190564156, Final Batch Loss: 0.015532066114246845\n",
      "Epoch 3457, Loss: 0.034954577684402466, Final Batch Loss: 0.002507893368601799\n",
      "Epoch 3458, Loss: 0.03747022710740566, Final Batch Loss: 0.0019621243700385094\n",
      "Epoch 3459, Loss: 0.051760145695880055, Final Batch Loss: 0.008870481513440609\n",
      "Epoch 3460, Loss: 0.015489319572225213, Final Batch Loss: 0.0024768454022705555\n",
      "Epoch 3461, Loss: 0.033460876904428005, Final Batch Loss: 0.010607356205582619\n",
      "Epoch 3462, Loss: 0.012304328090976924, Final Batch Loss: 0.0005885940627194941\n",
      "Epoch 3463, Loss: 0.03934877342544496, Final Batch Loss: 0.0014223193284124136\n",
      "Epoch 3464, Loss: 0.012532344931969419, Final Batch Loss: 0.00046176897012628615\n",
      "Epoch 3465, Loss: 0.02002222600276582, Final Batch Loss: 0.00017972427303902805\n",
      "Epoch 3466, Loss: 0.017152624554000795, Final Batch Loss: 0.004190730396658182\n",
      "Epoch 3467, Loss: 0.05835488741286099, Final Batch Loss: 0.0029052721802145243\n",
      "Epoch 3468, Loss: 0.02512069052318111, Final Batch Loss: 0.01426083967089653\n",
      "Epoch 3469, Loss: 0.03816381259821355, Final Batch Loss: 0.003563748672604561\n",
      "Epoch 3470, Loss: 0.013303024577908218, Final Batch Loss: 0.005119175184518099\n",
      "Epoch 3471, Loss: 0.01200958073604852, Final Batch Loss: 0.0010274118976667523\n",
      "Epoch 3472, Loss: 0.014235364506021142, Final Batch Loss: 0.0009967549704015255\n",
      "Epoch 3473, Loss: 0.034528570831753314, Final Batch Loss: 0.003998565021902323\n",
      "Epoch 3474, Loss: 0.024466083734296262, Final Batch Loss: 0.010017724707722664\n",
      "Epoch 3475, Loss: 0.03169912099838257, Final Batch Loss: 0.004930481314659119\n",
      "Epoch 3476, Loss: 0.01369646587409079, Final Batch Loss: 0.0015607846435159445\n",
      "Epoch 3477, Loss: 0.006743315258063376, Final Batch Loss: 0.0014470131136476994\n",
      "Epoch 3478, Loss: 0.08810621267184615, Final Batch Loss: 0.0013091708533465862\n",
      "Epoch 3479, Loss: 0.03146994987037033, Final Batch Loss: 0.023022392764687538\n",
      "Epoch 3480, Loss: 0.027607008581981063, Final Batch Loss: 0.0031096411403268576\n",
      "Epoch 3481, Loss: 0.17893205117434263, Final Batch Loss: 0.16855865716934204\n",
      "Epoch 3482, Loss: 0.0662270737811923, Final Batch Loss: 0.03718225285410881\n",
      "Epoch 3483, Loss: 0.020094458712264895, Final Batch Loss: 0.0014716298319399357\n",
      "Epoch 3484, Loss: 0.08586512878537178, Final Batch Loss: 0.07813447713851929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3485, Loss: 0.0595327029004693, Final Batch Loss: 0.036476023495197296\n",
      "Epoch 3486, Loss: 0.06631896388716996, Final Batch Loss: 0.02307828515768051\n",
      "Epoch 3487, Loss: 0.10223265085369349, Final Batch Loss: 0.04906231537461281\n",
      "Epoch 3488, Loss: 0.09215197805315256, Final Batch Loss: 0.009485076181590557\n",
      "Epoch 3489, Loss: 0.06573055777698755, Final Batch Loss: 0.003878803923726082\n",
      "Epoch 3490, Loss: 0.2379364874213934, Final Batch Loss: 0.11214219778776169\n",
      "Epoch 3491, Loss: 0.15396412461996078, Final Batch Loss: 0.04235803335905075\n",
      "Epoch 3492, Loss: 0.09719389583915472, Final Batch Loss: 0.0498889721930027\n",
      "Epoch 3493, Loss: 0.06852442305535078, Final Batch Loss: 0.005635922309011221\n",
      "Epoch 3494, Loss: 0.06837960425764322, Final Batch Loss: 0.0056096818298101425\n",
      "Epoch 3495, Loss: 0.10561598371714354, Final Batch Loss: 0.011731047183275223\n",
      "Epoch 3496, Loss: 0.114325734321028, Final Batch Loss: 0.04037390649318695\n",
      "Epoch 3497, Loss: 0.12231219979003072, Final Batch Loss: 0.058027829974889755\n",
      "Epoch 3498, Loss: 0.21127240359783173, Final Batch Loss: 0.0715574249625206\n",
      "Epoch 3499, Loss: 0.1134911347180605, Final Batch Loss: 0.054932791739702225\n",
      "Epoch 3500, Loss: 0.14586193300783634, Final Batch Loss: 0.021837325766682625\n",
      "Epoch 3501, Loss: 0.11081170570105314, Final Batch Loss: 0.0154567277058959\n",
      "Epoch 3502, Loss: 0.08439088519662619, Final Batch Loss: 0.004496696405112743\n",
      "Epoch 3503, Loss: 0.08380235265940428, Final Batch Loss: 0.015170352533459663\n",
      "Epoch 3504, Loss: 0.11837992165237665, Final Batch Loss: 0.004928615875542164\n",
      "Epoch 3505, Loss: 0.038069864735007286, Final Batch Loss: 0.011550670489668846\n",
      "Epoch 3506, Loss: 0.0951297846622765, Final Batch Loss: 0.0042143757455050945\n",
      "Epoch 3507, Loss: 0.07718633394688368, Final Batch Loss: 0.059507668018341064\n",
      "Epoch 3508, Loss: 0.06811466114595532, Final Batch Loss: 0.004025420639663935\n",
      "Epoch 3509, Loss: 0.11985390074551105, Final Batch Loss: 0.05686775594949722\n",
      "Epoch 3510, Loss: 0.12478768173605204, Final Batch Loss: 0.02046905644237995\n",
      "Epoch 3511, Loss: 0.09346357500180602, Final Batch Loss: 0.005125236231833696\n",
      "Epoch 3512, Loss: 0.06158631097059697, Final Batch Loss: 0.002266678726300597\n",
      "Epoch 3513, Loss: 0.13537202216684818, Final Batch Loss: 0.08854158967733383\n",
      "Epoch 3514, Loss: 0.11309061967767775, Final Batch Loss: 0.002475241431966424\n",
      "Epoch 3515, Loss: 0.11427950812503695, Final Batch Loss: 0.06286435574293137\n",
      "Epoch 3516, Loss: 0.08009563968516886, Final Batch Loss: 0.002056210534647107\n",
      "Epoch 3517, Loss: 0.08090452663600445, Final Batch Loss: 0.006028458476066589\n",
      "Epoch 3518, Loss: 0.08888270147144794, Final Batch Loss: 0.011995073407888412\n",
      "Epoch 3519, Loss: 0.06452406942844391, Final Batch Loss: 0.02337336540222168\n",
      "Epoch 3520, Loss: 0.034282274544239044, Final Batch Loss: 0.01379215344786644\n",
      "Epoch 3521, Loss: 0.04129735380411148, Final Batch Loss: 0.0025915377773344517\n",
      "Epoch 3522, Loss: 0.06455480284057558, Final Batch Loss: 0.0388377420604229\n",
      "Epoch 3523, Loss: 0.06081387191079557, Final Batch Loss: 0.0026923820842057467\n",
      "Epoch 3524, Loss: 0.03980498854070902, Final Batch Loss: 0.003542594611644745\n",
      "Epoch 3525, Loss: 0.03835180518217385, Final Batch Loss: 0.0023090133909136057\n",
      "Epoch 3526, Loss: 0.13016108516603708, Final Batch Loss: 0.026795078068971634\n",
      "Epoch 3527, Loss: 0.050102554727345705, Final Batch Loss: 0.00957688968628645\n",
      "Epoch 3528, Loss: 0.019697460695169866, Final Batch Loss: 0.0013828411465510726\n",
      "Epoch 3529, Loss: 0.07609194703400135, Final Batch Loss: 0.03822720795869827\n",
      "Epoch 3530, Loss: 0.031137257115915418, Final Batch Loss: 0.004351747687906027\n",
      "Epoch 3531, Loss: 0.05531116353813559, Final Batch Loss: 0.0012916220584884286\n",
      "Epoch 3532, Loss: 0.15226649027317762, Final Batch Loss: 0.10945168137550354\n",
      "Epoch 3533, Loss: 0.06798641523346305, Final Batch Loss: 0.029429255053400993\n",
      "Epoch 3534, Loss: 0.03523042821325362, Final Batch Loss: 0.0017980767879635096\n",
      "Epoch 3535, Loss: 0.10914843017235398, Final Batch Loss: 0.06507985293865204\n",
      "Epoch 3536, Loss: 0.02924012066796422, Final Batch Loss: 0.007811740040779114\n",
      "Epoch 3537, Loss: 0.024026640690863132, Final Batch Loss: 0.0021126549690961838\n",
      "Epoch 3538, Loss: 0.06729375454597175, Final Batch Loss: 0.0027552281972020864\n",
      "Epoch 3539, Loss: 0.07428470568265766, Final Batch Loss: 0.0017650079680606723\n",
      "Epoch 3540, Loss: 0.06499073340091854, Final Batch Loss: 0.03411278501152992\n",
      "Epoch 3541, Loss: 0.029736624099314213, Final Batch Loss: 0.004913817625492811\n",
      "Epoch 3542, Loss: 0.03958034887909889, Final Batch Loss: 0.015388005413115025\n",
      "Epoch 3543, Loss: 0.023109626723453403, Final Batch Loss: 0.005702340509742498\n",
      "Epoch 3544, Loss: 0.07742245960980654, Final Batch Loss: 0.024209748953580856\n",
      "Epoch 3545, Loss: 0.038195434492081404, Final Batch Loss: 0.010300250723958015\n",
      "Epoch 3546, Loss: 0.02633169712498784, Final Batch Loss: 0.005950320512056351\n",
      "Epoch 3547, Loss: 0.03548755403608084, Final Batch Loss: 0.0054693035781383514\n",
      "Epoch 3548, Loss: 0.021228745114058256, Final Batch Loss: 0.0053577362559735775\n",
      "Epoch 3549, Loss: 0.026781179709360003, Final Batch Loss: 0.0027943600434809923\n",
      "Epoch 3550, Loss: 0.023392742383293808, Final Batch Loss: 0.0015691983280703425\n",
      "Epoch 3551, Loss: 0.0641815597191453, Final Batch Loss: 0.001388611737638712\n",
      "Epoch 3552, Loss: 0.026237553218379617, Final Batch Loss: 0.006276900880038738\n",
      "Epoch 3553, Loss: 0.0682663875631988, Final Batch Loss: 0.03318735957145691\n",
      "Epoch 3554, Loss: 0.027353650191798806, Final Batch Loss: 0.0053505185060203075\n",
      "Epoch 3555, Loss: 0.1986315925605595, Final Batch Loss: 0.006107531953603029\n",
      "Epoch 3556, Loss: 0.10086125135421753, Final Batch Loss: 0.010417016223073006\n",
      "Epoch 3557, Loss: 0.06838086294010282, Final Batch Loss: 0.003957567736506462\n",
      "Epoch 3558, Loss: 0.07562639587558806, Final Batch Loss: 0.061660394072532654\n",
      "Epoch 3559, Loss: 0.03872278332710266, Final Batch Loss: 0.004363717511296272\n",
      "Epoch 3560, Loss: 0.07997518638148904, Final Batch Loss: 0.03264803811907768\n",
      "Epoch 3561, Loss: 0.021444309852086008, Final Batch Loss: 0.001107859774492681\n",
      "Epoch 3562, Loss: 0.07588595838751644, Final Batch Loss: 0.0015815539518371224\n",
      "Epoch 3563, Loss: 0.07024310808628798, Final Batch Loss: 0.012332886457443237\n",
      "Epoch 3564, Loss: 0.05104980117175728, Final Batch Loss: 0.0012823023134842515\n",
      "Epoch 3565, Loss: 0.0804743580520153, Final Batch Loss: 0.04415425285696983\n",
      "Epoch 3566, Loss: 0.04302150919102132, Final Batch Loss: 0.001451106509193778\n",
      "Epoch 3567, Loss: 0.03209996584337205, Final Batch Loss: 0.0015661536017432809\n",
      "Epoch 3568, Loss: 0.03198658628389239, Final Batch Loss: 0.005541640799492598\n",
      "Epoch 3569, Loss: 0.09115232899785042, Final Batch Loss: 0.006575552746653557\n",
      "Epoch 3570, Loss: 0.016719193197786808, Final Batch Loss: 0.0034339148551225662\n",
      "Epoch 3571, Loss: 0.04576794768217951, Final Batch Loss: 0.01942995935678482\n",
      "Epoch 3572, Loss: 0.059789684833958745, Final Batch Loss: 0.0012506714556366205\n",
      "Epoch 3573, Loss: 0.009845797321759164, Final Batch Loss: 0.0011356669710949063\n",
      "Epoch 3574, Loss: 0.044114064425230026, Final Batch Loss: 0.0007613617926836014\n",
      "Epoch 3575, Loss: 0.025550578255206347, Final Batch Loss: 0.005189993884414434\n",
      "Epoch 3576, Loss: 0.04866773064713925, Final Batch Loss: 0.010593323968350887\n",
      "Epoch 3577, Loss: 0.0356570880394429, Final Batch Loss: 0.011405427008867264\n",
      "Epoch 3578, Loss: 0.027967426227405667, Final Batch Loss: 0.0018969847587868571\n",
      "Epoch 3579, Loss: 0.04489088128320873, Final Batch Loss: 0.0014909438323229551\n",
      "Epoch 3580, Loss: 0.04362277686595917, Final Batch Loss: 0.003924076911062002\n",
      "Epoch 3581, Loss: 0.04831535488483496, Final Batch Loss: 0.0004521746013779193\n",
      "Epoch 3582, Loss: 0.03958675282774493, Final Batch Loss: 0.0009654436144046485\n",
      "Epoch 3583, Loss: 0.04712550691328943, Final Batch Loss: 0.002642440376803279\n",
      "Epoch 3584, Loss: 0.057488839607685804, Final Batch Loss: 0.02745627798140049\n",
      "Epoch 3585, Loss: 0.09874392894562334, Final Batch Loss: 0.06826785206794739\n",
      "Epoch 3586, Loss: 0.02682405454106629, Final Batch Loss: 0.002883846638724208\n",
      "Epoch 3587, Loss: 0.05494179169181734, Final Batch Loss: 0.0008807649137452245\n",
      "Epoch 3588, Loss: 0.10071165137924254, Final Batch Loss: 0.003627686994150281\n",
      "Epoch 3589, Loss: 0.0558440110180527, Final Batch Loss: 0.019209114834666252\n",
      "Epoch 3590, Loss: 0.03595710941590369, Final Batch Loss: 0.0005729065742343664\n",
      "Epoch 3591, Loss: 0.0777887781150639, Final Batch Loss: 0.004728490952402353\n",
      "Epoch 3592, Loss: 0.10765852592885494, Final Batch Loss: 0.02938232757151127\n",
      "Epoch 3593, Loss: 0.0755865111714229, Final Batch Loss: 0.027411576360464096\n",
      "Epoch 3594, Loss: 0.02216315735131502, Final Batch Loss: 0.008569381199777126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3595, Loss: 0.07400670438073575, Final Batch Loss: 0.0026255014818161726\n",
      "Epoch 3596, Loss: 0.03819547640159726, Final Batch Loss: 0.008239244110882282\n",
      "Epoch 3597, Loss: 0.04917664220556617, Final Batch Loss: 0.0060653481632471085\n",
      "Epoch 3598, Loss: 0.019836176128592342, Final Batch Loss: 0.0009432911756448448\n",
      "Epoch 3599, Loss: 0.01630484953057021, Final Batch Loss: 0.0014648897340521216\n",
      "Epoch 3600, Loss: 0.019932607654482126, Final Batch Loss: 0.00127680494915694\n",
      "Epoch 3601, Loss: 0.05039961729198694, Final Batch Loss: 0.012092110700905323\n",
      "Epoch 3602, Loss: 0.0331996981985867, Final Batch Loss: 0.002886217087507248\n",
      "Epoch 3603, Loss: 0.024525373242795467, Final Batch Loss: 0.006279293447732925\n",
      "Epoch 3604, Loss: 0.025471751345321536, Final Batch Loss: 0.008255895227193832\n",
      "Epoch 3605, Loss: 0.033348690485581756, Final Batch Loss: 0.00616417545825243\n",
      "Epoch 3606, Loss: 0.02238063351251185, Final Batch Loss: 0.008153394795954227\n",
      "Epoch 3607, Loss: 0.09334786725230515, Final Batch Loss: 0.08143196254968643\n",
      "Epoch 3608, Loss: 0.030635567381978035, Final Batch Loss: 0.02084382064640522\n",
      "Epoch 3609, Loss: 0.04052137956023216, Final Batch Loss: 0.03613739833235741\n",
      "Epoch 3610, Loss: 0.18260198179632425, Final Batch Loss: 0.10293986648321152\n",
      "Epoch 3611, Loss: 0.014845914673060179, Final Batch Loss: 0.0036368488799780607\n",
      "Epoch 3612, Loss: 0.10540118208155036, Final Batch Loss: 0.009637082926928997\n",
      "Epoch 3613, Loss: 0.020020271418616176, Final Batch Loss: 0.0017006437992677093\n",
      "Epoch 3614, Loss: 0.03609417378902435, Final Batch Loss: 0.005362506490200758\n",
      "Epoch 3615, Loss: 0.05239376681856811, Final Batch Loss: 0.014294836670160294\n",
      "Epoch 3616, Loss: 0.03879291471093893, Final Batch Loss: 0.002578133950009942\n",
      "Epoch 3617, Loss: 0.03024129767436534, Final Batch Loss: 0.0014482395490631461\n",
      "Epoch 3618, Loss: 0.04426882159896195, Final Batch Loss: 0.013340648263692856\n",
      "Epoch 3619, Loss: 0.011078728595748544, Final Batch Loss: 0.004323159344494343\n",
      "Epoch 3620, Loss: 0.03662027639802545, Final Batch Loss: 0.0030159330926835537\n",
      "Epoch 3621, Loss: 0.012558186310343444, Final Batch Loss: 0.0010169566376134753\n",
      "Epoch 3622, Loss: 0.008776395116001368, Final Batch Loss: 0.0012831594794988632\n",
      "Epoch 3623, Loss: 0.021496121655218303, Final Batch Loss: 0.0136251924559474\n",
      "Epoch 3624, Loss: 0.009346759528853, Final Batch Loss: 0.0015853478107601404\n",
      "Epoch 3625, Loss: 0.011658823932521045, Final Batch Loss: 0.0008922723354771733\n",
      "Epoch 3626, Loss: 0.03782376507297158, Final Batch Loss: 0.01289965957403183\n",
      "Epoch 3627, Loss: 0.045311552472412586, Final Batch Loss: 0.0056250449270009995\n",
      "Epoch 3628, Loss: 0.03919708388275467, Final Batch Loss: 0.0003340757393743843\n",
      "Epoch 3629, Loss: 0.056142065208405256, Final Batch Loss: 0.03218776360154152\n",
      "Epoch 3630, Loss: 0.10862898267805576, Final Batch Loss: 0.07576656341552734\n",
      "Epoch 3631, Loss: 0.01926508266478777, Final Batch Loss: 0.006694579962641001\n",
      "Epoch 3632, Loss: 0.08088035183027387, Final Batch Loss: 0.005969941150397062\n",
      "Epoch 3633, Loss: 0.041926692705601454, Final Batch Loss: 0.008759614080190659\n",
      "Epoch 3634, Loss: 0.030186527408659458, Final Batch Loss: 0.0009090304374694824\n",
      "Epoch 3635, Loss: 0.10485059162601829, Final Batch Loss: 0.005173522513359785\n",
      "Epoch 3636, Loss: 0.03536873357370496, Final Batch Loss: 0.018289316445589066\n",
      "Epoch 3637, Loss: 0.08048157719895244, Final Batch Loss: 0.004162495490163565\n",
      "Epoch 3638, Loss: 0.02468797960318625, Final Batch Loss: 0.0025664414279162884\n",
      "Epoch 3639, Loss: 0.0703079211525619, Final Batch Loss: 0.007108459714800119\n",
      "Epoch 3640, Loss: 0.16716489754617214, Final Batch Loss: 0.06587497144937515\n",
      "Epoch 3641, Loss: 0.05034694471396506, Final Batch Loss: 0.003432605182752013\n",
      "Epoch 3642, Loss: 0.1726271826773882, Final Batch Loss: 0.025677384808659554\n",
      "Epoch 3643, Loss: 0.09889178024604917, Final Batch Loss: 0.01609671302139759\n",
      "Epoch 3644, Loss: 0.09716895723249763, Final Batch Loss: 0.0007354639237746596\n",
      "Epoch 3645, Loss: 0.016921028145588934, Final Batch Loss: 0.002379687735810876\n",
      "Epoch 3646, Loss: 0.055852804449386895, Final Batch Loss: 0.0011252734111621976\n",
      "Epoch 3647, Loss: 0.10612884094007313, Final Batch Loss: 0.016747262328863144\n",
      "Epoch 3648, Loss: 0.03700053144712001, Final Batch Loss: 0.0018251562723889947\n",
      "Epoch 3649, Loss: 0.033834513276815414, Final Batch Loss: 0.0008160923607647419\n",
      "Epoch 3650, Loss: 0.02903398487251252, Final Batch Loss: 0.0015885246684774756\n",
      "Epoch 3651, Loss: 0.01636927347863093, Final Batch Loss: 0.0022831540554761887\n",
      "Epoch 3652, Loss: 0.01705894386395812, Final Batch Loss: 0.007196894846856594\n",
      "Epoch 3653, Loss: 0.06428215675987303, Final Batch Loss: 0.006014599464833736\n",
      "Epoch 3654, Loss: 0.03940000233706087, Final Batch Loss: 0.0058258953504264355\n",
      "Epoch 3655, Loss: 0.07583668362349272, Final Batch Loss: 0.020636795088648796\n",
      "Epoch 3656, Loss: 0.046862605900969356, Final Batch Loss: 0.0007247789180837572\n",
      "Epoch 3657, Loss: 0.01369890570640564, Final Batch Loss: 0.0018232509028166533\n",
      "Epoch 3658, Loss: 0.05237099272198975, Final Batch Loss: 0.002965699415653944\n",
      "Epoch 3659, Loss: 0.0273249470628798, Final Batch Loss: 0.004764860961586237\n",
      "Epoch 3660, Loss: 0.043204276997130364, Final Batch Loss: 0.0007764615002088249\n",
      "Epoch 3661, Loss: 0.011613997456151992, Final Batch Loss: 0.0021057280246168375\n",
      "Epoch 3662, Loss: 0.030252809869125485, Final Batch Loss: 0.0007319794967770576\n",
      "Epoch 3663, Loss: 0.037054699612781405, Final Batch Loss: 0.023266218602657318\n",
      "Epoch 3664, Loss: 0.10230591287836432, Final Batch Loss: 0.061145201325416565\n",
      "Epoch 3665, Loss: 0.01057570450939238, Final Batch Loss: 0.0016146786510944366\n",
      "Epoch 3666, Loss: 0.16558541730046272, Final Batch Loss: 0.09156918525695801\n",
      "Epoch 3667, Loss: 0.14337219577282667, Final Batch Loss: 0.06451397389173508\n",
      "Epoch 3668, Loss: 0.19552546343766153, Final Batch Loss: 0.15912988781929016\n",
      "Epoch 3669, Loss: 0.1912902221083641, Final Batch Loss: 0.07069975137710571\n",
      "Epoch 3670, Loss: 0.08414029236882925, Final Batch Loss: 0.013977923430502415\n",
      "Epoch 3671, Loss: 0.235971056856215, Final Batch Loss: 0.13427060842514038\n",
      "Epoch 3672, Loss: 0.1683576311916113, Final Batch Loss: 0.06494021415710449\n",
      "Epoch 3673, Loss: 0.08993624709546566, Final Batch Loss: 0.005977010354399681\n",
      "Epoch 3674, Loss: 0.056974983774125576, Final Batch Loss: 0.0029523083940148354\n",
      "Epoch 3675, Loss: 0.03535405592992902, Final Batch Loss: 0.00604415126144886\n",
      "Epoch 3676, Loss: 0.10564218740910292, Final Batch Loss: 0.041824884712696075\n",
      "Epoch 3677, Loss: 0.07050554919987917, Final Batch Loss: 0.006907939445227385\n",
      "Epoch 3678, Loss: 0.09315227228216827, Final Batch Loss: 0.0014217242132872343\n",
      "Epoch 3679, Loss: 0.11513869510963559, Final Batch Loss: 0.007515740115195513\n",
      "Epoch 3680, Loss: 0.046855734661221504, Final Batch Loss: 0.0033331094309687614\n",
      "Epoch 3681, Loss: 0.039953547064214945, Final Batch Loss: 0.004359972197562456\n",
      "Epoch 3682, Loss: 0.057969344314187765, Final Batch Loss: 0.005676419474184513\n",
      "Epoch 3683, Loss: 0.036017290549352765, Final Batch Loss: 0.0034488625824451447\n",
      "Epoch 3684, Loss: 0.04942458961158991, Final Batch Loss: 0.01484005805104971\n",
      "Epoch 3685, Loss: 0.04215801926329732, Final Batch Loss: 0.0024824088905006647\n",
      "Epoch 3686, Loss: 0.0356046911329031, Final Batch Loss: 0.01322061289101839\n",
      "Epoch 3687, Loss: 0.03246734384447336, Final Batch Loss: 0.016671201214194298\n",
      "Epoch 3688, Loss: 0.04911105881910771, Final Batch Loss: 0.0017003751127049327\n",
      "Epoch 3689, Loss: 0.04171667620539665, Final Batch Loss: 0.008652185089886189\n",
      "Epoch 3690, Loss: 0.053636210155673325, Final Batch Loss: 0.0016016006702557206\n",
      "Epoch 3691, Loss: 0.015494135674089193, Final Batch Loss: 0.002487024525180459\n",
      "Epoch 3692, Loss: 0.03132133465260267, Final Batch Loss: 0.0019877534359693527\n",
      "Epoch 3693, Loss: 0.06507924338802695, Final Batch Loss: 0.006911163683980703\n",
      "Epoch 3694, Loss: 0.0379175121197477, Final Batch Loss: 0.003933845087885857\n",
      "Epoch 3695, Loss: 0.07385708286892623, Final Batch Loss: 0.0069494727067649364\n",
      "Epoch 3696, Loss: 0.03533738711848855, Final Batch Loss: 0.006488744169473648\n",
      "Epoch 3697, Loss: 0.033454788848757744, Final Batch Loss: 0.006453816778957844\n",
      "Epoch 3698, Loss: 0.0347800791496411, Final Batch Loss: 0.0011920166434720159\n",
      "Epoch 3699, Loss: 0.05058969557285309, Final Batch Loss: 0.002384377643465996\n",
      "Epoch 3700, Loss: 0.01155714550986886, Final Batch Loss: 0.002777128480374813\n",
      "Epoch 3701, Loss: 0.07206083182245493, Final Batch Loss: 0.06143883243203163\n",
      "Epoch 3702, Loss: 0.010587473050691187, Final Batch Loss: 0.0018370674224570394\n",
      "Epoch 3703, Loss: 0.046504369704052806, Final Batch Loss: 0.005212462041527033\n",
      "Epoch 3704, Loss: 0.018969114404171705, Final Batch Loss: 0.002380077028647065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3705, Loss: 0.03139417071361095, Final Batch Loss: 0.001241962076164782\n",
      "Epoch 3706, Loss: 0.07280151918530464, Final Batch Loss: 0.00761349406093359\n",
      "Epoch 3707, Loss: 0.056408578995615244, Final Batch Loss: 0.0050222622230648994\n",
      "Epoch 3708, Loss: 0.05948278773576021, Final Batch Loss: 0.026382364332675934\n",
      "Epoch 3709, Loss: 0.014836730668321252, Final Batch Loss: 0.004328754730522633\n",
      "Epoch 3710, Loss: 0.050460665952414274, Final Batch Loss: 0.02902061864733696\n",
      "Epoch 3711, Loss: 0.05552665493451059, Final Batch Loss: 0.00212940969504416\n",
      "Epoch 3712, Loss: 0.19105236046016216, Final Batch Loss: 0.15372301638126373\n",
      "Epoch 3713, Loss: 0.027939048828557134, Final Batch Loss: 0.012684638611972332\n",
      "Epoch 3714, Loss: 0.07855458650738001, Final Batch Loss: 0.042946118861436844\n",
      "Epoch 3715, Loss: 0.08106550201773643, Final Batch Loss: 0.02903568372130394\n",
      "Epoch 3716, Loss: 0.08269780641421676, Final Batch Loss: 0.0016069118864834309\n",
      "Epoch 3717, Loss: 0.06802522297948599, Final Batch Loss: 0.015281380154192448\n",
      "Epoch 3718, Loss: 0.053283567540347576, Final Batch Loss: 0.012183671817183495\n",
      "Epoch 3719, Loss: 0.04789340100251138, Final Batch Loss: 0.0030178192537277937\n",
      "Epoch 3720, Loss: 0.03913691628258675, Final Batch Loss: 0.0009659122442826629\n",
      "Epoch 3721, Loss: 0.02762521366821602, Final Batch Loss: 0.0008381454390473664\n",
      "Epoch 3722, Loss: 0.045544862980023026, Final Batch Loss: 0.0033722480293363333\n",
      "Epoch 3723, Loss: 0.06233580503612757, Final Batch Loss: 0.019944356754422188\n",
      "Epoch 3724, Loss: 0.09965221036691219, Final Batch Loss: 0.0010920075001195073\n",
      "Epoch 3725, Loss: 0.05710615450516343, Final Batch Loss: 0.030393412336707115\n",
      "Epoch 3726, Loss: 0.08929522801190615, Final Batch Loss: 0.02563682571053505\n",
      "Epoch 3727, Loss: 0.01966685231309384, Final Batch Loss: 0.008021024987101555\n",
      "Epoch 3728, Loss: 0.05137917457614094, Final Batch Loss: 0.001010038540698588\n",
      "Epoch 3729, Loss: 0.08488210709765553, Final Batch Loss: 0.06621970236301422\n",
      "Epoch 3730, Loss: 0.06357745139393955, Final Batch Loss: 0.03574686124920845\n",
      "Epoch 3731, Loss: 0.06170391058549285, Final Batch Loss: 0.002347887959331274\n",
      "Epoch 3732, Loss: 0.02944979816675186, Final Batch Loss: 0.01262140367180109\n",
      "Epoch 3733, Loss: 0.04920262360246852, Final Batch Loss: 0.0007403141935355961\n",
      "Epoch 3734, Loss: 0.05304003058699891, Final Batch Loss: 0.01563536562025547\n",
      "Epoch 3735, Loss: 0.04796853434527293, Final Batch Loss: 0.00014466146240010858\n",
      "Epoch 3736, Loss: 0.0587625905754976, Final Batch Loss: 0.0008284320938400924\n",
      "Epoch 3737, Loss: 0.044239404145628214, Final Batch Loss: 0.015254778787493706\n",
      "Epoch 3738, Loss: 0.0950745944865048, Final Batch Loss: 0.002210828009992838\n",
      "Epoch 3739, Loss: 0.04740037489682436, Final Batch Loss: 0.003911664709448814\n",
      "Epoch 3740, Loss: 0.07795336248818785, Final Batch Loss: 0.0015882692532613873\n",
      "Epoch 3741, Loss: 0.06539719458669424, Final Batch Loss: 0.015150773338973522\n",
      "Epoch 3742, Loss: 0.05755599495023489, Final Batch Loss: 0.0013134207110852003\n",
      "Epoch 3743, Loss: 0.05511648580431938, Final Batch Loss: 0.018427453935146332\n",
      "Epoch 3744, Loss: 0.0734236678108573, Final Batch Loss: 0.0019585425034165382\n",
      "Epoch 3745, Loss: 0.08133097691461444, Final Batch Loss: 0.0009906790219247341\n",
      "Epoch 3746, Loss: 0.1663072274532169, Final Batch Loss: 0.08389751613140106\n",
      "Epoch 3747, Loss: 0.07596502499654889, Final Batch Loss: 0.005027695093303919\n",
      "Epoch 3748, Loss: 0.06905113626271486, Final Batch Loss: 0.003973111510276794\n",
      "Epoch 3749, Loss: 0.06257188972085714, Final Batch Loss: 0.01378815621137619\n",
      "Epoch 3750, Loss: 0.11161672975867987, Final Batch Loss: 0.002995050512254238\n",
      "Epoch 3751, Loss: 0.12789002154022455, Final Batch Loss: 0.0022148629650473595\n",
      "Epoch 3752, Loss: 0.030860653147101402, Final Batch Loss: 0.012454940937459469\n",
      "Epoch 3753, Loss: 0.15150098456069827, Final Batch Loss: 0.06874558329582214\n",
      "Epoch 3754, Loss: 0.1443639937788248, Final Batch Loss: 0.05831655114889145\n",
      "Epoch 3755, Loss: 0.10653953813016415, Final Batch Loss: 0.02423262596130371\n",
      "Epoch 3756, Loss: 0.09742508199997246, Final Batch Loss: 0.003377543995156884\n",
      "Epoch 3757, Loss: 0.06087280483916402, Final Batch Loss: 0.01369813084602356\n",
      "Epoch 3758, Loss: 0.06594709353521466, Final Batch Loss: 0.005031765904277563\n",
      "Epoch 3759, Loss: 0.15783873107284307, Final Batch Loss: 0.010567273013293743\n",
      "Epoch 3760, Loss: 0.050336495507508516, Final Batch Loss: 0.006932658143341541\n",
      "Epoch 3761, Loss: 0.09316651057451963, Final Batch Loss: 0.05355231836438179\n",
      "Epoch 3762, Loss: 0.029749490204267204, Final Batch Loss: 0.0037646309938281775\n",
      "Epoch 3763, Loss: 0.050694165751338005, Final Batch Loss: 0.014230744913220406\n",
      "Epoch 3764, Loss: 0.046126426197588444, Final Batch Loss: 0.010128415189683437\n",
      "Epoch 3765, Loss: 0.06754301395267248, Final Batch Loss: 0.0036164852790534496\n",
      "Epoch 3766, Loss: 0.05570861976593733, Final Batch Loss: 0.017740724608302116\n",
      "Epoch 3767, Loss: 0.0316743707517162, Final Batch Loss: 0.0006966049550101161\n",
      "Epoch 3768, Loss: 0.04375104699283838, Final Batch Loss: 0.0027344971895217896\n",
      "Epoch 3769, Loss: 0.08306057145819068, Final Batch Loss: 0.0023947125300765038\n",
      "Epoch 3770, Loss: 0.029170271707698703, Final Batch Loss: 0.009238244965672493\n",
      "Epoch 3771, Loss: 0.06570662977173924, Final Batch Loss: 0.04271278902888298\n",
      "Epoch 3772, Loss: 0.02767762402072549, Final Batch Loss: 0.012863854877650738\n",
      "Epoch 3773, Loss: 0.11936523905023932, Final Batch Loss: 0.05082903802394867\n",
      "Epoch 3774, Loss: 0.01413354731630534, Final Batch Loss: 0.005210099741816521\n",
      "Epoch 3775, Loss: 0.029678309336304665, Final Batch Loss: 0.008705297484993935\n",
      "Epoch 3776, Loss: 0.027505724341608584, Final Batch Loss: 0.001256238087080419\n",
      "Epoch 3777, Loss: 0.03536587976850569, Final Batch Loss: 0.004998472519218922\n",
      "Epoch 3778, Loss: 0.013537082297261804, Final Batch Loss: 0.00039391167229041457\n",
      "Epoch 3779, Loss: 0.042262797709554434, Final Batch Loss: 0.0013674725778400898\n",
      "Epoch 3780, Loss: 0.040878828382119536, Final Batch Loss: 0.02281416393816471\n",
      "Epoch 3781, Loss: 0.04711505165323615, Final Batch Loss: 0.008196359500288963\n",
      "Epoch 3782, Loss: 0.10001987009309232, Final Batch Loss: 0.07493569701910019\n",
      "Epoch 3783, Loss: 0.053736764180939645, Final Batch Loss: 0.000570313713978976\n",
      "Epoch 3784, Loss: 0.0206706034950912, Final Batch Loss: 0.007577765267342329\n",
      "Epoch 3785, Loss: 0.038011074997484684, Final Batch Loss: 0.004450980573892593\n",
      "Epoch 3786, Loss: 0.043711958918720484, Final Batch Loss: 0.004578603431582451\n",
      "Epoch 3787, Loss: 0.025652880780398846, Final Batch Loss: 0.0030261888168752193\n",
      "Epoch 3788, Loss: 0.017115381197072566, Final Batch Loss: 0.0013056256575509906\n",
      "Epoch 3789, Loss: 0.019903136417269707, Final Batch Loss: 0.010995179414749146\n",
      "Epoch 3790, Loss: 0.0472316539962776, Final Batch Loss: 0.0008310780976898968\n",
      "Epoch 3791, Loss: 0.04071078076958656, Final Batch Loss: 0.010174933820962906\n",
      "Epoch 3792, Loss: 0.018660535046365112, Final Batch Loss: 0.0004609068273566663\n",
      "Epoch 3793, Loss: 0.08020313899032772, Final Batch Loss: 0.05444146320223808\n",
      "Epoch 3794, Loss: 0.012440919759683311, Final Batch Loss: 0.0012806638842448592\n",
      "Epoch 3795, Loss: 0.03911829646676779, Final Batch Loss: 0.004320924170315266\n",
      "Epoch 3796, Loss: 0.01966189220547676, Final Batch Loss: 0.004751567263156176\n",
      "Epoch 3797, Loss: 0.01775887538678944, Final Batch Loss: 0.0013849835377186537\n",
      "Epoch 3798, Loss: 0.03681188070913777, Final Batch Loss: 0.011138790287077427\n",
      "Epoch 3799, Loss: 0.046796723967418075, Final Batch Loss: 0.0006188515108078718\n",
      "Epoch 3800, Loss: 0.06936852028593421, Final Batch Loss: 0.0023495876230299473\n",
      "Epoch 3801, Loss: 0.052195422584190965, Final Batch Loss: 0.004117932170629501\n",
      "Epoch 3802, Loss: 0.02145670825848356, Final Batch Loss: 0.0008114721276797354\n",
      "Epoch 3803, Loss: 0.06137353228405118, Final Batch Loss: 0.009752821177244186\n",
      "Epoch 3804, Loss: 0.014789255801588297, Final Batch Loss: 0.0011102657299488783\n",
      "Epoch 3805, Loss: 0.018915890948846936, Final Batch Loss: 0.0032702621538192034\n",
      "Epoch 3806, Loss: 0.09465827187523246, Final Batch Loss: 0.07001208513975143\n",
      "Epoch 3807, Loss: 0.08184256160166115, Final Batch Loss: 0.05088932067155838\n",
      "Epoch 3808, Loss: 0.02920648269355297, Final Batch Loss: 0.0008472625631839037\n",
      "Epoch 3809, Loss: 0.012456239550374448, Final Batch Loss: 0.0013404523488134146\n",
      "Epoch 3810, Loss: 0.047560909762978554, Final Batch Loss: 0.003348288591951132\n",
      "Epoch 3811, Loss: 0.04432427720166743, Final Batch Loss: 0.001257553230971098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3812, Loss: 0.008469396911095828, Final Batch Loss: 0.0019926365930587053\n",
      "Epoch 3813, Loss: 0.035584143828600645, Final Batch Loss: 0.005858101882040501\n",
      "Epoch 3814, Loss: 0.04626732296310365, Final Batch Loss: 0.003917487803846598\n",
      "Epoch 3815, Loss: 0.010259208967909217, Final Batch Loss: 0.0010489681735634804\n",
      "Epoch 3816, Loss: 0.06128504150547087, Final Batch Loss: 0.003006062703207135\n",
      "Epoch 3817, Loss: 0.06246415339410305, Final Batch Loss: 0.007966678589582443\n",
      "Epoch 3818, Loss: 0.018339213449507952, Final Batch Loss: 0.001231716014444828\n",
      "Epoch 3819, Loss: 0.03807977866381407, Final Batch Loss: 0.0016998851206153631\n",
      "Epoch 3820, Loss: 0.06164632644504309, Final Batch Loss: 0.004994109272956848\n",
      "Epoch 3821, Loss: 0.1037197825498879, Final Batch Loss: 0.04016511142253876\n",
      "Epoch 3822, Loss: 0.06269293231889606, Final Batch Loss: 0.0068552554585039616\n",
      "Epoch 3823, Loss: 0.08828697865828872, Final Batch Loss: 0.005056540947407484\n",
      "Epoch 3824, Loss: 0.0594820121768862, Final Batch Loss: 0.00253969500772655\n",
      "Epoch 3825, Loss: 0.09976687375456095, Final Batch Loss: 0.00710362009704113\n",
      "Epoch 3826, Loss: 0.06476838560774922, Final Batch Loss: 0.006775880232453346\n",
      "Epoch 3827, Loss: 0.049748427933081985, Final Batch Loss: 0.003151753218844533\n",
      "Epoch 3828, Loss: 0.06283985986374319, Final Batch Loss: 0.0017905228305608034\n",
      "Epoch 3829, Loss: 0.0448564647231251, Final Batch Loss: 0.002338242018595338\n",
      "Epoch 3830, Loss: 0.056077634915709496, Final Batch Loss: 0.01136851403862238\n",
      "Epoch 3831, Loss: 0.0619558859616518, Final Batch Loss: 0.0041219196282327175\n",
      "Epoch 3832, Loss: 0.0563765550032258, Final Batch Loss: 0.034724391996860504\n",
      "Epoch 3833, Loss: 0.13747397856786847, Final Batch Loss: 0.04592929407954216\n",
      "Epoch 3834, Loss: 0.16752246767282486, Final Batch Loss: 0.08223140239715576\n",
      "Epoch 3835, Loss: 0.11834923783317208, Final Batch Loss: 0.019440945237874985\n",
      "Epoch 3836, Loss: 0.054147898219525814, Final Batch Loss: 0.008123026229441166\n",
      "Epoch 3837, Loss: 0.06945738382637501, Final Batch Loss: 0.03227538987994194\n",
      "Epoch 3838, Loss: 0.1234858266543597, Final Batch Loss: 0.041257645934820175\n",
      "Epoch 3839, Loss: 0.05745225225109607, Final Batch Loss: 0.025891678407788277\n",
      "Epoch 3840, Loss: 0.06399591267108917, Final Batch Loss: 0.005302462726831436\n",
      "Epoch 3841, Loss: 0.07013413356617093, Final Batch Loss: 0.007680424023419619\n",
      "Epoch 3842, Loss: 0.06253667897544801, Final Batch Loss: 0.002710911212489009\n",
      "Epoch 3843, Loss: 0.028403677977621555, Final Batch Loss: 0.0043949163518846035\n",
      "Epoch 3844, Loss: 0.09032716695219278, Final Batch Loss: 0.018100401386618614\n",
      "Epoch 3845, Loss: 0.06367057329043746, Final Batch Loss: 0.009003806859254837\n",
      "Epoch 3846, Loss: 0.04243229911662638, Final Batch Loss: 0.02184658870100975\n",
      "Epoch 3847, Loss: 0.018631164450198412, Final Batch Loss: 0.007862708531320095\n",
      "Epoch 3848, Loss: 0.05521567817777395, Final Batch Loss: 0.00712381349876523\n",
      "Epoch 3849, Loss: 0.019208695739507675, Final Batch Loss: 0.003354731248691678\n",
      "Epoch 3850, Loss: 0.028372254222631454, Final Batch Loss: 0.004265485797077417\n",
      "Epoch 3851, Loss: 0.03817121940664947, Final Batch Loss: 0.004499426111578941\n",
      "Epoch 3852, Loss: 0.01940385135821998, Final Batch Loss: 0.004807944409549236\n",
      "Epoch 3853, Loss: 0.02860886207781732, Final Batch Loss: 0.0015025150496512651\n",
      "Epoch 3854, Loss: 0.045545811764895916, Final Batch Loss: 0.0034598747733980417\n",
      "Epoch 3855, Loss: 0.0638851024559699, Final Batch Loss: 0.0007622851408086717\n",
      "Epoch 3856, Loss: 0.017496599350124598, Final Batch Loss: 0.004058768507093191\n",
      "Epoch 3857, Loss: 0.10369262751191854, Final Batch Loss: 0.028641095384955406\n",
      "Epoch 3858, Loss: 0.020741650369018316, Final Batch Loss: 0.00595058174803853\n",
      "Epoch 3859, Loss: 0.09600262437015772, Final Batch Loss: 0.06154540926218033\n",
      "Epoch 3860, Loss: 0.030255725781898946, Final Batch Loss: 0.0005743249203078449\n",
      "Epoch 3861, Loss: 0.021545178024098277, Final Batch Loss: 0.005271466448903084\n",
      "Epoch 3862, Loss: 0.08724602591246367, Final Batch Loss: 0.0474652498960495\n",
      "Epoch 3863, Loss: 0.014545055804774165, Final Batch Loss: 0.003327367128804326\n",
      "Epoch 3864, Loss: 0.06762150337453932, Final Batch Loss: 0.04189245030283928\n",
      "Epoch 3865, Loss: 0.050621357280761003, Final Batch Loss: 0.011983317323029041\n",
      "Epoch 3866, Loss: 0.029416581994155422, Final Batch Loss: 0.0003379419504199177\n",
      "Epoch 3867, Loss: 0.03292720369063318, Final Batch Loss: 0.002518012886866927\n",
      "Epoch 3868, Loss: 0.013541593914851546, Final Batch Loss: 0.004005027003586292\n",
      "Epoch 3869, Loss: 0.02031754655763507, Final Batch Loss: 0.002401558216661215\n",
      "Epoch 3870, Loss: 0.022634305991232395, Final Batch Loss: 0.004185972735285759\n",
      "Epoch 3871, Loss: 0.07746722409501672, Final Batch Loss: 0.018510842695832253\n",
      "Epoch 3872, Loss: 0.027743738057324663, Final Batch Loss: 0.00041969495941884816\n",
      "Epoch 3873, Loss: 0.01856095064431429, Final Batch Loss: 0.0011474750936031342\n",
      "Epoch 3874, Loss: 0.06625594710931182, Final Batch Loss: 0.004545377101749182\n",
      "Epoch 3875, Loss: 0.07336976379156113, Final Batch Loss: 0.020477913320064545\n",
      "Epoch 3876, Loss: 0.03056720463791862, Final Batch Loss: 0.0005091461935080588\n",
      "Epoch 3877, Loss: 0.03636259853374213, Final Batch Loss: 0.001605367287993431\n",
      "Epoch 3878, Loss: 0.07834267430007458, Final Batch Loss: 0.029289085417985916\n",
      "Epoch 3879, Loss: 0.09082864178344607, Final Batch Loss: 0.01737235113978386\n",
      "Epoch 3880, Loss: 0.04449820565059781, Final Batch Loss: 0.0007354202680289745\n",
      "Epoch 3881, Loss: 0.0788838854059577, Final Batch Loss: 0.013226545415818691\n",
      "Epoch 3882, Loss: 0.03364826901815832, Final Batch Loss: 0.0020906233694404364\n",
      "Epoch 3883, Loss: 0.03772955480962992, Final Batch Loss: 0.003235922195017338\n",
      "Epoch 3884, Loss: 0.06857607478741556, Final Batch Loss: 0.014826036058366299\n",
      "Epoch 3885, Loss: 0.017215107276570052, Final Batch Loss: 0.000778011919464916\n",
      "Epoch 3886, Loss: 0.04444201337173581, Final Batch Loss: 0.0011549764312803745\n",
      "Epoch 3887, Loss: 0.03236563201062381, Final Batch Loss: 0.0007308039348572493\n",
      "Epoch 3888, Loss: 0.020487814559601247, Final Batch Loss: 0.011906898580491543\n",
      "Epoch 3889, Loss: 0.07295173592865467, Final Batch Loss: 0.02792576141655445\n",
      "Epoch 3890, Loss: 0.0400356074096635, Final Batch Loss: 0.0030456879176199436\n",
      "Epoch 3891, Loss: 0.1162195410579443, Final Batch Loss: 0.024961605668067932\n",
      "Epoch 3892, Loss: 0.06858268729411066, Final Batch Loss: 0.002036719350144267\n",
      "Epoch 3893, Loss: 0.0376268511172384, Final Batch Loss: 0.00598898297175765\n",
      "Epoch 3894, Loss: 0.06385577586479485, Final Batch Loss: 0.0012840810231864452\n",
      "Epoch 3895, Loss: 0.0766772371425759, Final Batch Loss: 0.00040459955926053226\n",
      "Epoch 3896, Loss: 0.051182398572564125, Final Batch Loss: 0.015137070789933205\n",
      "Epoch 3897, Loss: 0.07032709685154259, Final Batch Loss: 0.025437040254473686\n",
      "Epoch 3898, Loss: 0.04529161797836423, Final Batch Loss: 0.01524124015122652\n",
      "Epoch 3899, Loss: 0.01462161517702043, Final Batch Loss: 0.0014534012880176306\n",
      "Epoch 3900, Loss: 0.0617453632876277, Final Batch Loss: 0.02725273184478283\n",
      "Epoch 3901, Loss: 0.031541222939267755, Final Batch Loss: 0.020520741119980812\n",
      "Epoch 3902, Loss: 0.05438828910700977, Final Batch Loss: 0.0035533399786800146\n",
      "Epoch 3903, Loss: 0.0491457199677825, Final Batch Loss: 0.0020360960625112057\n",
      "Epoch 3904, Loss: 0.057472200598567724, Final Batch Loss: 0.013624539598822594\n",
      "Epoch 3905, Loss: 0.02937942580319941, Final Batch Loss: 0.006257541943341494\n",
      "Epoch 3906, Loss: 0.014729752787388861, Final Batch Loss: 0.0015956285642459989\n",
      "Epoch 3907, Loss: 0.04038091632537544, Final Batch Loss: 0.028491143137216568\n",
      "Epoch 3908, Loss: 0.03054531675297767, Final Batch Loss: 0.0015905165346339345\n",
      "Epoch 3909, Loss: 0.05418344587087631, Final Batch Loss: 0.003134311642497778\n",
      "Epoch 3910, Loss: 0.026554349344223738, Final Batch Loss: 0.013255389407277107\n",
      "Epoch 3911, Loss: 0.03870797896524891, Final Batch Loss: 0.0008576440159231424\n",
      "Epoch 3912, Loss: 0.06753674912033603, Final Batch Loss: 0.000439861963968724\n",
      "Epoch 3913, Loss: 0.043337389128282666, Final Batch Loss: 0.0010807921644300222\n",
      "Epoch 3914, Loss: 0.018388563534244895, Final Batch Loss: 0.0014816656475886703\n",
      "Epoch 3915, Loss: 0.06770225276704878, Final Batch Loss: 0.05597574636340141\n",
      "Epoch 3916, Loss: 0.021355690201744437, Final Batch Loss: 0.0016036847373470664\n",
      "Epoch 3917, Loss: 0.06260251346975565, Final Batch Loss: 0.01216251403093338\n",
      "Epoch 3918, Loss: 0.0754654600750655, Final Batch Loss: 0.028510674834251404\n",
      "Epoch 3919, Loss: 0.042637171456590295, Final Batch Loss: 0.00207346654497087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3920, Loss: 0.09126392379403114, Final Batch Loss: 0.0271134190261364\n",
      "Epoch 3921, Loss: 0.0670631043612957, Final Batch Loss: 0.007666061166673899\n",
      "Epoch 3922, Loss: 0.05094012833433226, Final Batch Loss: 0.0009399664704687893\n",
      "Epoch 3923, Loss: 0.11350351758301258, Final Batch Loss: 0.04258131608366966\n",
      "Epoch 3924, Loss: 0.08717220928519964, Final Batch Loss: 0.016738345846533775\n",
      "Epoch 3925, Loss: 0.07535093510523438, Final Batch Loss: 0.03837242349982262\n",
      "Epoch 3926, Loss: 0.0646234080195427, Final Batch Loss: 0.006726878695189953\n",
      "Epoch 3927, Loss: 0.09041751362383366, Final Batch Loss: 0.01580234244465828\n",
      "Epoch 3928, Loss: 0.10769407637417316, Final Batch Loss: 0.024308891966938972\n",
      "Epoch 3929, Loss: 0.025944460183382034, Final Batch Loss: 0.004960167687386274\n",
      "Epoch 3930, Loss: 0.09907472971826792, Final Batch Loss: 0.05294932797551155\n",
      "Epoch 3931, Loss: 0.0559121782425791, Final Batch Loss: 0.003063714364543557\n",
      "Epoch 3932, Loss: 0.04378649825230241, Final Batch Loss: 0.003157589118927717\n",
      "Epoch 3933, Loss: 0.05036688409745693, Final Batch Loss: 0.005589130334556103\n",
      "Epoch 3934, Loss: 0.06301957531832159, Final Batch Loss: 0.012591181322932243\n",
      "Epoch 3935, Loss: 0.167607176117599, Final Batch Loss: 0.14350765943527222\n",
      "Epoch 3936, Loss: 0.09448450832860544, Final Batch Loss: 0.000828406133223325\n",
      "Epoch 3937, Loss: 0.0285514157731086, Final Batch Loss: 0.001958537148311734\n",
      "Epoch 3938, Loss: 0.09686314524151385, Final Batch Loss: 0.008638669736683369\n",
      "Epoch 3939, Loss: 0.055525981122627854, Final Batch Loss: 0.0032640397548675537\n",
      "Epoch 3940, Loss: 0.11515995766967535, Final Batch Loss: 0.012357109226286411\n",
      "Epoch 3941, Loss: 0.07868519425392151, Final Batch Loss: 0.003955557011067867\n",
      "Epoch 3942, Loss: 0.0692976750433445, Final Batch Loss: 0.007695297710597515\n",
      "Epoch 3943, Loss: 0.04310951801016927, Final Batch Loss: 0.0011092247441411018\n",
      "Epoch 3944, Loss: 0.07973013049922884, Final Batch Loss: 0.06658343225717545\n",
      "Epoch 3945, Loss: 0.044427220709621906, Final Batch Loss: 0.0028715836815536022\n",
      "Epoch 3946, Loss: 0.06271066586486995, Final Batch Loss: 0.002889092778787017\n",
      "Epoch 3947, Loss: 0.07938909507356584, Final Batch Loss: 0.0029164820443838835\n",
      "Epoch 3948, Loss: 0.05201471992768347, Final Batch Loss: 0.0010602048132568598\n",
      "Epoch 3949, Loss: 0.038397495402023196, Final Batch Loss: 0.022476885467767715\n",
      "Epoch 3950, Loss: 0.011039569799322635, Final Batch Loss: 0.0006593086873181164\n",
      "Epoch 3951, Loss: 0.08422543108463287, Final Batch Loss: 0.04421834647655487\n",
      "Epoch 3952, Loss: 0.015504887560382485, Final Batch Loss: 0.0028382206801325083\n",
      "Epoch 3953, Loss: 0.038355623837560415, Final Batch Loss: 0.0016525587998330593\n",
      "Epoch 3954, Loss: 0.026028835913166404, Final Batch Loss: 0.004900860134512186\n",
      "Epoch 3955, Loss: 0.0204287797678262, Final Batch Loss: 0.0028843297623097897\n",
      "Epoch 3956, Loss: 0.047948473365977407, Final Batch Loss: 0.026700632646679878\n",
      "Epoch 3957, Loss: 0.028473109239712358, Final Batch Loss: 0.0175063144415617\n",
      "Epoch 3958, Loss: 0.031717891222797334, Final Batch Loss: 0.012333843857049942\n",
      "Epoch 3959, Loss: 0.03646630747243762, Final Batch Loss: 0.006112717092037201\n",
      "Epoch 3960, Loss: 0.0118356600869447, Final Batch Loss: 0.0005676158471032977\n",
      "Epoch 3961, Loss: 0.07140642357990146, Final Batch Loss: 0.04836897924542427\n",
      "Epoch 3962, Loss: 0.07679080637171865, Final Batch Loss: 0.059882551431655884\n",
      "Epoch 3963, Loss: 0.062950877007097, Final Batch Loss: 0.006402581464499235\n",
      "Epoch 3964, Loss: 0.042592596262693405, Final Batch Loss: 0.0021721990779042244\n",
      "Epoch 3965, Loss: 0.025184047175571322, Final Batch Loss: 0.00841527059674263\n",
      "Epoch 3966, Loss: 0.04726419039070606, Final Batch Loss: 0.0027762704994529486\n",
      "Epoch 3967, Loss: 0.07142808753997087, Final Batch Loss: 0.013268710114061832\n",
      "Epoch 3968, Loss: 0.04700738191604614, Final Batch Loss: 0.017671706154942513\n",
      "Epoch 3969, Loss: 0.021582111017778516, Final Batch Loss: 0.00274664512835443\n",
      "Epoch 3970, Loss: 0.020610251231119037, Final Batch Loss: 0.0012012015795335174\n",
      "Epoch 3971, Loss: 0.07497417321428657, Final Batch Loss: 0.0029204776510596275\n",
      "Epoch 3972, Loss: 0.029221764067187905, Final Batch Loss: 0.01090839970856905\n",
      "Epoch 3973, Loss: 0.029514065943658352, Final Batch Loss: 0.01082548126578331\n",
      "Epoch 3974, Loss: 0.027259206166490912, Final Batch Loss: 0.0019440718460828066\n",
      "Epoch 3975, Loss: 0.03645201586186886, Final Batch Loss: 0.0020263073965907097\n",
      "Epoch 3976, Loss: 0.05159218213520944, Final Batch Loss: 0.0007756443228572607\n",
      "Epoch 3977, Loss: 0.07621238194406033, Final Batch Loss: 0.06082165986299515\n",
      "Epoch 3978, Loss: 0.09801396890543401, Final Batch Loss: 0.08292923122644424\n",
      "Epoch 3979, Loss: 0.008816601650323719, Final Batch Loss: 0.00038606388261541724\n",
      "Epoch 3980, Loss: 0.1287389153148979, Final Batch Loss: 0.009499628096818924\n",
      "Epoch 3981, Loss: 0.10852327384054661, Final Batch Loss: 0.01903686113655567\n",
      "Epoch 3982, Loss: 0.062438876018859446, Final Batch Loss: 0.04214804619550705\n",
      "Epoch 3983, Loss: 0.07261451659724116, Final Batch Loss: 0.03527652844786644\n",
      "Epoch 3984, Loss: 0.06481351586990058, Final Batch Loss: 0.0015690557193011045\n",
      "Epoch 3985, Loss: 0.09662080276757479, Final Batch Loss: 0.009031129069626331\n",
      "Epoch 3986, Loss: 0.10577880591154099, Final Batch Loss: 0.030233969911932945\n",
      "Epoch 3987, Loss: 0.08322898019105196, Final Batch Loss: 0.027046333998441696\n",
      "Epoch 3988, Loss: 0.1277073584496975, Final Batch Loss: 0.016713209450244904\n",
      "Epoch 3989, Loss: 0.09978642081841826, Final Batch Loss: 0.007261937018483877\n",
      "Epoch 3990, Loss: 0.09749624598771334, Final Batch Loss: 0.007494705729186535\n",
      "Epoch 3991, Loss: 0.1316756885498762, Final Batch Loss: 0.028053205460309982\n",
      "Epoch 3992, Loss: 0.07626196322962642, Final Batch Loss: 0.00232524867169559\n",
      "Epoch 3993, Loss: 0.08899633027613163, Final Batch Loss: 0.04670127481222153\n",
      "Epoch 3994, Loss: 0.09500393690541387, Final Batch Loss: 0.029711611568927765\n",
      "Epoch 3995, Loss: 0.037138260435312986, Final Batch Loss: 0.001845664344727993\n",
      "Epoch 3996, Loss: 0.05939444340765476, Final Batch Loss: 0.00571498554199934\n",
      "Epoch 3997, Loss: 0.03652368241455406, Final Batch Loss: 0.0018708802526816726\n",
      "Epoch 3998, Loss: 0.04457884794101119, Final Batch Loss: 0.011357158422470093\n",
      "Epoch 3999, Loss: 0.03031990514136851, Final Batch Loss: 0.0027409144677221775\n",
      "Epoch 4000, Loss: 0.046046274714171886, Final Batch Loss: 0.006437127478420734\n",
      "Epoch 4001, Loss: 0.02467450057156384, Final Batch Loss: 0.0032139653339982033\n",
      "Epoch 4002, Loss: 0.06457283231429756, Final Batch Loss: 0.033482592552900314\n",
      "Epoch 4003, Loss: 0.009483237634412944, Final Batch Loss: 0.003133959835395217\n",
      "Epoch 4004, Loss: 0.047506748931482434, Final Batch Loss: 0.0025567819830030203\n",
      "Epoch 4005, Loss: 0.028648272389546037, Final Batch Loss: 0.0030182544142007828\n",
      "Epoch 4006, Loss: 0.027691581286489964, Final Batch Loss: 0.008883069269359112\n",
      "Epoch 4007, Loss: 0.01021944626700133, Final Batch Loss: 0.002065818989649415\n",
      "Epoch 4008, Loss: 0.015216839383356273, Final Batch Loss: 0.0025367815978825092\n",
      "Epoch 4009, Loss: 0.02940772008150816, Final Batch Loss: 0.0028066670056432486\n",
      "Epoch 4010, Loss: 0.03529641916975379, Final Batch Loss: 0.023203155025839806\n",
      "Epoch 4011, Loss: 0.025432780268602073, Final Batch Loss: 0.002804278628900647\n",
      "Epoch 4012, Loss: 0.07711048214696348, Final Batch Loss: 0.04803599789738655\n",
      "Epoch 4013, Loss: 0.031831745989620686, Final Batch Loss: 0.005338507238775492\n",
      "Epoch 4014, Loss: 0.010074152727611363, Final Batch Loss: 0.00528054591268301\n",
      "Epoch 4015, Loss: 0.031809652951778844, Final Batch Loss: 0.00043466014903970063\n",
      "Epoch 4016, Loss: 0.013731679529882967, Final Batch Loss: 0.0020203059539198875\n",
      "Epoch 4017, Loss: 0.02626763324951753, Final Batch Loss: 0.0005257552838884294\n",
      "Epoch 4018, Loss: 0.03878998453728855, Final Batch Loss: 0.002627425594255328\n",
      "Epoch 4019, Loss: 0.027229712577536702, Final Batch Loss: 0.0011629157233983278\n",
      "Epoch 4020, Loss: 0.011433474428486079, Final Batch Loss: 0.003996109124273062\n",
      "Epoch 4021, Loss: 0.05512766324682161, Final Batch Loss: 0.0005636847927235067\n",
      "Epoch 4022, Loss: 0.030354141490533948, Final Batch Loss: 0.006859762128442526\n",
      "Epoch 4023, Loss: 0.056287274695932865, Final Batch Loss: 0.001213650219142437\n",
      "Epoch 4024, Loss: 0.07933221256826073, Final Batch Loss: 0.07112344354391098\n",
      "Epoch 4025, Loss: 0.08913618954829872, Final Batch Loss: 0.0672229528427124\n",
      "Epoch 4026, Loss: 0.053416898706927896, Final Batch Loss: 0.006883492227643728\n",
      "Epoch 4027, Loss: 0.09457943681627512, Final Batch Loss: 0.048891544342041016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4028, Loss: 0.06586441025137901, Final Batch Loss: 0.002367422915995121\n",
      "Epoch 4029, Loss: 0.08217474399134517, Final Batch Loss: 0.0015128501690924168\n",
      "Epoch 4030, Loss: 0.06050840963143855, Final Batch Loss: 0.014171749353408813\n",
      "Epoch 4031, Loss: 0.030459594214335084, Final Batch Loss: 0.002693990943953395\n",
      "Epoch 4032, Loss: 0.07972748670727015, Final Batch Loss: 0.0448787547647953\n",
      "Epoch 4033, Loss: 0.07467699330300093, Final Batch Loss: 0.04044661298394203\n",
      "Epoch 4034, Loss: 0.11664209701120853, Final Batch Loss: 0.004488779231905937\n",
      "Epoch 4035, Loss: 0.08025460876524448, Final Batch Loss: 0.018144123256206512\n",
      "Epoch 4036, Loss: 0.0218949259724468, Final Batch Loss: 0.0009822363499552011\n",
      "Epoch 4037, Loss: 0.08365081064403057, Final Batch Loss: 0.019823821261525154\n",
      "Epoch 4038, Loss: 0.05284641310572624, Final Batch Loss: 0.03347604721784592\n",
      "Epoch 4039, Loss: 0.05845755524933338, Final Batch Loss: 0.009503434412181377\n",
      "Epoch 4040, Loss: 0.0910207440610975, Final Batch Loss: 0.0036067769397050142\n",
      "Epoch 4041, Loss: 0.07977999374270439, Final Batch Loss: 0.03166307508945465\n",
      "Epoch 4042, Loss: 0.11050049308687449, Final Batch Loss: 0.06594617664813995\n",
      "Epoch 4043, Loss: 0.07178828259930015, Final Batch Loss: 0.03623766079545021\n",
      "Epoch 4044, Loss: 0.06958140712231398, Final Batch Loss: 0.04560030996799469\n",
      "Epoch 4045, Loss: 0.04817177541553974, Final Batch Loss: 0.014006182551383972\n",
      "Epoch 4046, Loss: 0.0613453674595803, Final Batch Loss: 0.022789904847741127\n",
      "Epoch 4047, Loss: 0.07629020279273391, Final Batch Loss: 0.006966763641685247\n",
      "Epoch 4048, Loss: 0.08963343780487776, Final Batch Loss: 0.017357047647237778\n",
      "Epoch 4049, Loss: 0.03231951384805143, Final Batch Loss: 0.0027756330091506243\n",
      "Epoch 4050, Loss: 0.05908043961971998, Final Batch Loss: 0.005577675066888332\n",
      "Epoch 4051, Loss: 0.037301148287951946, Final Batch Loss: 0.0028167464770376682\n",
      "Epoch 4052, Loss: 0.11196243576705456, Final Batch Loss: 0.026297638192772865\n",
      "Epoch 4053, Loss: 0.04657190898433328, Final Batch Loss: 0.004854940343648195\n",
      "Epoch 4054, Loss: 0.035686754155904055, Final Batch Loss: 0.013577131554484367\n",
      "Epoch 4055, Loss: 0.03279928443953395, Final Batch Loss: 0.0019630284514278173\n",
      "Epoch 4056, Loss: 0.05564926960505545, Final Batch Loss: 0.003093892941251397\n",
      "Epoch 4057, Loss: 0.014723091502673924, Final Batch Loss: 0.002981409663334489\n",
      "Epoch 4058, Loss: 0.024177625658921897, Final Batch Loss: 0.0013959723291918635\n",
      "Epoch 4059, Loss: 0.06970431748777628, Final Batch Loss: 0.016122136265039444\n",
      "Epoch 4060, Loss: 0.08276024181395769, Final Batch Loss: 0.005429782904684544\n",
      "Epoch 4061, Loss: 0.04639992117881775, Final Batch Loss: 0.01023180317133665\n",
      "Epoch 4062, Loss: 0.07118991622701287, Final Batch Loss: 0.03486800566315651\n",
      "Epoch 4063, Loss: 0.06290932663250715, Final Batch Loss: 0.0007849555695429444\n",
      "Epoch 4064, Loss: 0.10165422910358757, Final Batch Loss: 0.0013509573182091117\n",
      "Epoch 4065, Loss: 0.02531592035666108, Final Batch Loss: 0.004666901659220457\n",
      "Epoch 4066, Loss: 0.07964627153705806, Final Batch Loss: 0.0013458625180646777\n",
      "Epoch 4067, Loss: 0.06544895539991558, Final Batch Loss: 0.002553338650614023\n",
      "Epoch 4068, Loss: 0.01718822924885899, Final Batch Loss: 0.0011957964161410928\n",
      "Epoch 4069, Loss: 0.028393862769007683, Final Batch Loss: 0.012778794392943382\n",
      "Epoch 4070, Loss: 0.02414661506190896, Final Batch Loss: 0.0020483029074966908\n",
      "Epoch 4071, Loss: 0.053718544309958816, Final Batch Loss: 0.005639147013425827\n",
      "Epoch 4072, Loss: 0.04545208113268018, Final Batch Loss: 0.001904461532831192\n",
      "Epoch 4073, Loss: 0.021276166720781475, Final Batch Loss: 0.015624008141458035\n",
      "Epoch 4074, Loss: 0.03753466659691185, Final Batch Loss: 0.00175913714338094\n",
      "Epoch 4075, Loss: 0.040855554514564574, Final Batch Loss: 0.0011727852979674935\n",
      "Epoch 4076, Loss: 0.024468868039548397, Final Batch Loss: 0.002413979033008218\n",
      "Epoch 4077, Loss: 0.014639048255048692, Final Batch Loss: 0.002865722868591547\n",
      "Epoch 4078, Loss: 0.028181171277537942, Final Batch Loss: 0.0010506926337257028\n",
      "Epoch 4079, Loss: 0.029574897838756442, Final Batch Loss: 0.016449514776468277\n",
      "Epoch 4080, Loss: 0.07364364096429199, Final Batch Loss: 0.05379871651530266\n",
      "Epoch 4081, Loss: 0.031024226918816566, Final Batch Loss: 0.0026820525527000427\n",
      "Epoch 4082, Loss: 0.0952514735981822, Final Batch Loss: 0.04447953402996063\n",
      "Epoch 4083, Loss: 0.05018692906014621, Final Batch Loss: 0.012870769947767258\n",
      "Epoch 4084, Loss: 0.043321271310560405, Final Batch Loss: 0.0031278624664992094\n",
      "Epoch 4085, Loss: 0.05422798893414438, Final Batch Loss: 0.015500674955546856\n",
      "Epoch 4086, Loss: 0.05920707108452916, Final Batch Loss: 0.037251606583595276\n",
      "Epoch 4087, Loss: 0.060458531603217125, Final Batch Loss: 0.02075425535440445\n",
      "Epoch 4088, Loss: 0.07100719911977649, Final Batch Loss: 0.03545871004462242\n",
      "Epoch 4089, Loss: 0.045638815965503454, Final Batch Loss: 0.0015356000512838364\n",
      "Epoch 4090, Loss: 0.032897353172302246, Final Batch Loss: 0.013880733400583267\n",
      "Epoch 4091, Loss: 0.018412886071018875, Final Batch Loss: 0.0018702222732827067\n",
      "Epoch 4092, Loss: 0.04873546492308378, Final Batch Loss: 0.009268401190638542\n",
      "Epoch 4093, Loss: 0.041504429653286934, Final Batch Loss: 0.0053262668661773205\n",
      "Epoch 4094, Loss: 0.036640359088778496, Final Batch Loss: 0.001228279434144497\n",
      "Epoch 4095, Loss: 0.026629357307683676, Final Batch Loss: 0.00671078497543931\n",
      "Epoch 4096, Loss: 0.01498035475378856, Final Batch Loss: 0.0006250131991691887\n",
      "Epoch 4097, Loss: 0.05409489944577217, Final Batch Loss: 0.014146960340440273\n",
      "Epoch 4098, Loss: 0.013840709580108523, Final Batch Loss: 0.003280977252870798\n",
      "Epoch 4099, Loss: 0.10774458386003971, Final Batch Loss: 0.030997689813375473\n",
      "Epoch 4100, Loss: 0.18535400787368417, Final Batch Loss: 0.1563863754272461\n",
      "Epoch 4101, Loss: 0.010781209450215101, Final Batch Loss: 0.0013143745018169284\n",
      "Epoch 4102, Loss: 0.05679274816066027, Final Batch Loss: 0.020859921351075172\n",
      "Epoch 4103, Loss: 0.0411205132259056, Final Batch Loss: 0.0013502592919394374\n",
      "Epoch 4104, Loss: 0.1028088319581002, Final Batch Loss: 0.03250445798039436\n",
      "Epoch 4105, Loss: 0.07292931678239256, Final Batch Loss: 0.0048698908649384975\n",
      "Epoch 4106, Loss: 0.108755296561867, Final Batch Loss: 0.017936889082193375\n",
      "Epoch 4107, Loss: 0.07019694754853845, Final Batch Loss: 0.050798527896404266\n",
      "Epoch 4108, Loss: 0.04452646570280194, Final Batch Loss: 0.013147225603461266\n",
      "Epoch 4109, Loss: 0.03628179617226124, Final Batch Loss: 0.005805511958897114\n",
      "Epoch 4110, Loss: 0.04047241108492017, Final Batch Loss: 0.0028405634220689535\n",
      "Epoch 4111, Loss: 0.021076317178085446, Final Batch Loss: 0.009581410326063633\n",
      "Epoch 4112, Loss: 0.09061236056732014, Final Batch Loss: 0.07419116050004959\n",
      "Epoch 4113, Loss: 0.033911975333467126, Final Batch Loss: 0.00310879060998559\n",
      "Epoch 4114, Loss: 0.04298539622686803, Final Batch Loss: 0.008810363709926605\n",
      "Epoch 4115, Loss: 0.1238255575299263, Final Batch Loss: 0.06979039311408997\n",
      "Epoch 4116, Loss: 0.13546041632071137, Final Batch Loss: 0.060006026178598404\n",
      "Epoch 4117, Loss: 0.0874742204323411, Final Batch Loss: 0.0026436597108840942\n",
      "Epoch 4118, Loss: 0.1567656947299838, Final Batch Loss: 0.09224136918783188\n",
      "Epoch 4119, Loss: 0.30109157878905535, Final Batch Loss: 0.1997774839401245\n",
      "Epoch 4120, Loss: 0.14114149287343025, Final Batch Loss: 0.06457201391458511\n",
      "Epoch 4121, Loss: 0.1334412880241871, Final Batch Loss: 0.022415826097130775\n",
      "Epoch 4122, Loss: 0.14929155074059963, Final Batch Loss: 0.017713667824864388\n",
      "Epoch 4123, Loss: 0.20382900536060333, Final Batch Loss: 0.07973551750183105\n",
      "Epoch 4124, Loss: 0.14814712712541223, Final Batch Loss: 0.05137793719768524\n",
      "Epoch 4125, Loss: 0.08114753104746342, Final Batch Loss: 0.019551586359739304\n",
      "Epoch 4126, Loss: 0.09856547135859728, Final Batch Loss: 0.0035418150946497917\n",
      "Epoch 4127, Loss: 0.18217009492218494, Final Batch Loss: 0.08959340304136276\n",
      "Epoch 4128, Loss: 0.04279029346071184, Final Batch Loss: 0.01136100385338068\n",
      "Epoch 4129, Loss: 0.10844355169683695, Final Batch Loss: 0.055800143629312515\n",
      "Epoch 4130, Loss: 0.10346066812053323, Final Batch Loss: 0.005864523351192474\n",
      "Epoch 4131, Loss: 0.07757691876031458, Final Batch Loss: 0.0037784522864967585\n",
      "Epoch 4132, Loss: 0.0911792078986764, Final Batch Loss: 0.0005809706635773182\n",
      "Epoch 4133, Loss: 0.08604088984429836, Final Batch Loss: 0.030509090051054955\n",
      "Epoch 4134, Loss: 0.05506221204996109, Final Batch Loss: 0.008281662128865719\n",
      "Epoch 4135, Loss: 0.06784874945878983, Final Batch Loss: 0.0017544357106089592\n",
      "Epoch 4136, Loss: 0.06033087754622102, Final Batch Loss: 0.02488289773464203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4137, Loss: 0.0959074255079031, Final Batch Loss: 0.050487954169511795\n",
      "Epoch 4138, Loss: 0.0827851826325059, Final Batch Loss: 0.0074539766646921635\n",
      "Epoch 4139, Loss: 0.03685004566796124, Final Batch Loss: 0.0030489626806229353\n",
      "Epoch 4140, Loss: 0.07033920544199646, Final Batch Loss: 0.0056200032122433186\n",
      "Epoch 4141, Loss: 0.03771041892468929, Final Batch Loss: 0.0065988716669380665\n",
      "Epoch 4142, Loss: 0.08109816536307335, Final Batch Loss: 0.028820980340242386\n",
      "Epoch 4143, Loss: 0.03190802107565105, Final Batch Loss: 0.010138960555195808\n",
      "Epoch 4144, Loss: 0.07030120398849249, Final Batch Loss: 0.003195582889020443\n",
      "Epoch 4145, Loss: 0.019016704754903913, Final Batch Loss: 0.002460963325574994\n",
      "Epoch 4146, Loss: 0.018154795514419675, Final Batch Loss: 0.0007291433867067099\n",
      "Epoch 4147, Loss: 0.013481754343956709, Final Batch Loss: 0.0018075123662129045\n",
      "Epoch 4148, Loss: 0.007272035116329789, Final Batch Loss: 0.0005929090548306704\n",
      "Epoch 4149, Loss: 0.030449523823335767, Final Batch Loss: 0.004690776113420725\n",
      "Epoch 4150, Loss: 0.014310195023426786, Final Batch Loss: 0.00025158506468869746\n",
      "Epoch 4151, Loss: 0.030476822517812252, Final Batch Loss: 0.004926803521811962\n",
      "Epoch 4152, Loss: 0.010231086984276772, Final Batch Loss: 0.001433064928278327\n",
      "Epoch 4153, Loss: 0.01936265523545444, Final Batch Loss: 0.0028839230071753263\n",
      "Epoch 4154, Loss: 0.03442993073258549, Final Batch Loss: 0.0009407693287357688\n",
      "Epoch 4155, Loss: 0.12828345224261284, Final Batch Loss: 0.10740017145872116\n",
      "Epoch 4156, Loss: 0.019554183731088415, Final Batch Loss: 0.00047630039625801146\n",
      "Epoch 4157, Loss: 0.0885735834017396, Final Batch Loss: 0.027363557368516922\n",
      "Epoch 4158, Loss: 0.043010164052248, Final Batch Loss: 0.004277316853404045\n",
      "Epoch 4159, Loss: 0.039487870410084724, Final Batch Loss: 0.016103465110063553\n",
      "Epoch 4160, Loss: 0.018617880530655384, Final Batch Loss: 0.001293138600885868\n",
      "Epoch 4161, Loss: 0.034552439814433455, Final Batch Loss: 0.005430043209344149\n",
      "Epoch 4162, Loss: 0.07526834635064006, Final Batch Loss: 0.009675339795649052\n",
      "Epoch 4163, Loss: 0.07159648393280804, Final Batch Loss: 0.0033936903346329927\n",
      "Epoch 4164, Loss: 0.05219077499350533, Final Batch Loss: 0.0007030283450149\n",
      "Epoch 4165, Loss: 0.07298724702559412, Final Batch Loss: 0.00980176217854023\n",
      "Epoch 4166, Loss: 0.06230771658010781, Final Batch Loss: 0.045298539102077484\n",
      "Epoch 4167, Loss: 0.04630898730829358, Final Batch Loss: 0.013927614316344261\n",
      "Epoch 4168, Loss: 0.06294468266423792, Final Batch Loss: 0.0006006135372444987\n",
      "Epoch 4169, Loss: 0.041144717717543244, Final Batch Loss: 0.002256580861285329\n",
      "Epoch 4170, Loss: 0.033586777513846755, Final Batch Loss: 0.002936338307335973\n",
      "Epoch 4171, Loss: 0.04710729094222188, Final Batch Loss: 0.011496644467115402\n",
      "Epoch 4172, Loss: 0.016548260115087032, Final Batch Loss: 0.001995866419747472\n",
      "Epoch 4173, Loss: 0.04486377304419875, Final Batch Loss: 0.0028471280820667744\n",
      "Epoch 4174, Loss: 0.05409439210779965, Final Batch Loss: 0.004687743727117777\n",
      "Epoch 4175, Loss: 0.041359354625456035, Final Batch Loss: 0.014631025493144989\n",
      "Epoch 4176, Loss: 0.04122400959022343, Final Batch Loss: 0.001210070215165615\n",
      "Epoch 4177, Loss: 0.04021102795377374, Final Batch Loss: 0.0021478398703038692\n",
      "Epoch 4178, Loss: 0.03113334020599723, Final Batch Loss: 0.0028375836554914713\n",
      "Epoch 4179, Loss: 0.044963121647015214, Final Batch Loss: 0.004732032772153616\n",
      "Epoch 4180, Loss: 0.011097342474386096, Final Batch Loss: 0.0010607698932290077\n",
      "Epoch 4181, Loss: 0.02732192142866552, Final Batch Loss: 0.003216525772586465\n",
      "Epoch 4182, Loss: 0.027229441795498133, Final Batch Loss: 0.006542158778756857\n",
      "Epoch 4183, Loss: 0.018251377972774208, Final Batch Loss: 0.0012218933552503586\n",
      "Epoch 4184, Loss: 0.01938638067804277, Final Batch Loss: 0.002521140966564417\n",
      "Epoch 4185, Loss: 0.06778999092057347, Final Batch Loss: 0.04472963511943817\n",
      "Epoch 4186, Loss: 0.045585391810163856, Final Batch Loss: 0.01436239667236805\n",
      "Epoch 4187, Loss: 0.07024089922197163, Final Batch Loss: 0.0032795218285173178\n",
      "Epoch 4188, Loss: 0.02883491525426507, Final Batch Loss: 0.005869030486792326\n",
      "Epoch 4189, Loss: 0.024986625649034977, Final Batch Loss: 0.012201161123812199\n",
      "Epoch 4190, Loss: 0.025317372055724263, Final Batch Loss: 0.0037898276932537556\n",
      "Epoch 4191, Loss: 0.027655027573928237, Final Batch Loss: 0.012228633277118206\n",
      "Epoch 4192, Loss: 0.024215383222326636, Final Batch Loss: 0.0004906256217509508\n",
      "Epoch 4193, Loss: 0.011421143542975187, Final Batch Loss: 0.0012808580650016665\n",
      "Epoch 4194, Loss: 0.018598739756271243, Final Batch Loss: 0.0016644940478727221\n",
      "Epoch 4195, Loss: 0.029728805646300316, Final Batch Loss: 0.0047776177525520325\n",
      "Epoch 4196, Loss: 0.06590554886497557, Final Batch Loss: 0.003665413474664092\n",
      "Epoch 4197, Loss: 0.03692873101681471, Final Batch Loss: 0.002204444259405136\n",
      "Epoch 4198, Loss: 0.08471181913046166, Final Batch Loss: 0.07970709353685379\n",
      "Epoch 4199, Loss: 0.021515825064852834, Final Batch Loss: 0.0013302613515406847\n",
      "Epoch 4200, Loss: 0.03269897459540516, Final Batch Loss: 0.0030244868248701096\n",
      "Epoch 4201, Loss: 0.014402040978893638, Final Batch Loss: 0.0035564424470067024\n",
      "Epoch 4202, Loss: 0.040254641440697014, Final Batch Loss: 0.00247678579762578\n",
      "Epoch 4203, Loss: 0.02320344024337828, Final Batch Loss: 0.001424639718607068\n",
      "Epoch 4204, Loss: 0.010141826351173222, Final Batch Loss: 0.0008751486893743277\n",
      "Epoch 4205, Loss: 0.01868130615912378, Final Batch Loss: 0.0007103583193384111\n",
      "Epoch 4206, Loss: 0.026961829396896064, Final Batch Loss: 0.0026622842997312546\n",
      "Epoch 4207, Loss: 0.043665498960763216, Final Batch Loss: 0.0005034374771639705\n",
      "Epoch 4208, Loss: 0.007431695703417063, Final Batch Loss: 0.002118704142048955\n",
      "Epoch 4209, Loss: 0.03276174142956734, Final Batch Loss: 0.009843617677688599\n",
      "Epoch 4210, Loss: 0.02212499571032822, Final Batch Loss: 0.0024211856070905924\n",
      "Epoch 4211, Loss: 0.011876870936248451, Final Batch Loss: 0.0003841352299787104\n",
      "Epoch 4212, Loss: 0.02242717135231942, Final Batch Loss: 0.0010059339692816138\n",
      "Epoch 4213, Loss: 0.033136785961687565, Final Batch Loss: 0.0057474104687571526\n",
      "Epoch 4214, Loss: 0.021418572636321187, Final Batch Loss: 0.012027068063616753\n",
      "Epoch 4215, Loss: 0.013346413325052708, Final Batch Loss: 0.0009295241325162351\n",
      "Epoch 4216, Loss: 0.026935199624858797, Final Batch Loss: 0.0012175011215731502\n",
      "Epoch 4217, Loss: 0.06592971307691187, Final Batch Loss: 0.05722387507557869\n",
      "Epoch 4218, Loss: 0.02320510317804292, Final Batch Loss: 0.00879991427063942\n",
      "Epoch 4219, Loss: 0.006410804693587124, Final Batch Loss: 0.0019924065563827753\n",
      "Epoch 4220, Loss: 0.055272367666475475, Final Batch Loss: 0.001164910034276545\n",
      "Epoch 4221, Loss: 0.07872017688350752, Final Batch Loss: 0.07512589544057846\n",
      "Epoch 4222, Loss: 0.07363378629088402, Final Batch Loss: 0.012289662845432758\n",
      "Epoch 4223, Loss: 0.020829688059166074, Final Batch Loss: 0.004857358522713184\n",
      "Epoch 4224, Loss: 0.06801533978432417, Final Batch Loss: 0.0037526446394622326\n",
      "Epoch 4225, Loss: 0.009956987923942506, Final Batch Loss: 0.0033114831894636154\n",
      "Epoch 4226, Loss: 0.0542854112572968, Final Batch Loss: 0.01696503348648548\n",
      "Epoch 4227, Loss: 0.02326943801017478, Final Batch Loss: 0.00047887099208310246\n",
      "Epoch 4228, Loss: 0.012479209108278155, Final Batch Loss: 0.0011943147983402014\n",
      "Epoch 4229, Loss: 0.019367251195944846, Final Batch Loss: 0.0015778738306835294\n",
      "Epoch 4230, Loss: 0.02606893633492291, Final Batch Loss: 0.009994344785809517\n",
      "Epoch 4231, Loss: 0.04193374648457393, Final Batch Loss: 0.0005607101484201849\n",
      "Epoch 4232, Loss: 0.02305243327282369, Final Batch Loss: 0.0013876528246328235\n",
      "Epoch 4233, Loss: 0.023642255226150155, Final Batch Loss: 0.0026527380105108023\n",
      "Epoch 4234, Loss: 0.050682996632531285, Final Batch Loss: 0.0383736677467823\n",
      "Epoch 4235, Loss: 0.03585260713589378, Final Batch Loss: 0.006279891822487116\n",
      "Epoch 4236, Loss: 0.05049051472451538, Final Batch Loss: 0.0002796722110360861\n",
      "Epoch 4237, Loss: 0.03599071339704096, Final Batch Loss: 0.002029464580118656\n",
      "Epoch 4238, Loss: 0.0358173570712097, Final Batch Loss: 0.0008407398709096014\n",
      "Epoch 4239, Loss: 0.025682141829747707, Final Batch Loss: 0.0008785871905274689\n",
      "Epoch 4240, Loss: 0.0313897643936798, Final Batch Loss: 0.02471809647977352\n",
      "Epoch 4241, Loss: 0.021898353355936706, Final Batch Loss: 0.0041957818903028965\n",
      "Epoch 4242, Loss: 0.020698625245131552, Final Batch Loss: 0.00197118753567338\n",
      "Epoch 4243, Loss: 0.031733333831653, Final Batch Loss: 0.0008506579324603081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4244, Loss: 0.052673858124762774, Final Batch Loss: 0.036298323422670364\n",
      "Epoch 4245, Loss: 0.0203154890332371, Final Batch Loss: 0.0016882156487554312\n",
      "Epoch 4246, Loss: 0.0408067952375859, Final Batch Loss: 0.00288340519182384\n",
      "Epoch 4247, Loss: 0.03674634615890682, Final Batch Loss: 0.008459308184683323\n",
      "Epoch 4248, Loss: 0.015618015400832519, Final Batch Loss: 0.00019848471856676042\n",
      "Epoch 4249, Loss: 0.08427870459854603, Final Batch Loss: 0.018558857962489128\n",
      "Epoch 4250, Loss: 0.04654449224472046, Final Batch Loss: 0.002908189781010151\n",
      "Epoch 4251, Loss: 0.06565953604876995, Final Batch Loss: 0.0462409183382988\n",
      "Epoch 4252, Loss: 0.009957881746231578, Final Batch Loss: 0.0002317894686711952\n",
      "Epoch 4253, Loss: 0.02315451786853373, Final Batch Loss: 0.0010185803985223174\n",
      "Epoch 4254, Loss: 0.02591180638410151, Final Batch Loss: 0.00144280050881207\n",
      "Epoch 4255, Loss: 0.03792463801801205, Final Batch Loss: 0.01429068949073553\n",
      "Epoch 4256, Loss: 0.01902660506311804, Final Batch Loss: 0.001594104920513928\n",
      "Epoch 4257, Loss: 0.058714007725939155, Final Batch Loss: 0.03553638979792595\n",
      "Epoch 4258, Loss: 0.037341840914450586, Final Batch Loss: 0.0009358579991385341\n",
      "Epoch 4259, Loss: 0.0316196964122355, Final Batch Loss: 0.017061050981283188\n",
      "Epoch 4260, Loss: 0.01785251242108643, Final Batch Loss: 0.0038575157523155212\n",
      "Epoch 4261, Loss: 0.034098201605957, Final Batch Loss: 0.0008518735994584858\n",
      "Epoch 4262, Loss: 0.019115115981549025, Final Batch Loss: 0.005605448503047228\n",
      "Epoch 4263, Loss: 0.02422887133434415, Final Batch Loss: 0.006605845410376787\n",
      "Epoch 4264, Loss: 0.15784520749002695, Final Batch Loss: 0.09337136894464493\n",
      "Epoch 4265, Loss: 0.04776910837972537, Final Batch Loss: 0.0005524750449694693\n",
      "Epoch 4266, Loss: 0.07088700262829661, Final Batch Loss: 0.004316987004131079\n",
      "Epoch 4267, Loss: 0.027607122901827097, Final Batch Loss: 0.014338057488203049\n",
      "Epoch 4268, Loss: 0.054460795829072595, Final Batch Loss: 0.024365076795220375\n",
      "Epoch 4269, Loss: 0.03993216762319207, Final Batch Loss: 0.009718148037791252\n",
      "Epoch 4270, Loss: 0.03688175976276398, Final Batch Loss: 0.0012501399032771587\n",
      "Epoch 4271, Loss: 0.0438226736150682, Final Batch Loss: 0.00039418472442775965\n",
      "Epoch 4272, Loss: 0.019023423199541867, Final Batch Loss: 0.0018305311677977443\n",
      "Epoch 4273, Loss: 0.047669325256720185, Final Batch Loss: 0.0015820087864995003\n",
      "Epoch 4274, Loss: 0.06690156040713191, Final Batch Loss: 0.05303599685430527\n",
      "Epoch 4275, Loss: 0.07501444616355002, Final Batch Loss: 0.007847883738577366\n",
      "Epoch 4276, Loss: 0.0504118810640648, Final Batch Loss: 0.001257493975572288\n",
      "Epoch 4277, Loss: 0.031426708679646254, Final Batch Loss: 0.0056523471139371395\n",
      "Epoch 4278, Loss: 0.0737365186214447, Final Batch Loss: 0.04917468503117561\n",
      "Epoch 4279, Loss: 0.09380459506064653, Final Batch Loss: 0.002271861769258976\n",
      "Epoch 4280, Loss: 0.1336141669889912, Final Batch Loss: 0.054744504392147064\n",
      "Epoch 4281, Loss: 0.2606354500167072, Final Batch Loss: 0.14324846863746643\n",
      "Epoch 4282, Loss: 0.07180394232273102, Final Batch Loss: 0.005458422936499119\n",
      "Epoch 4283, Loss: 0.32138803601264954, Final Batch Loss: 0.060077980160713196\n",
      "Epoch 4284, Loss: 0.15058734454214573, Final Batch Loss: 0.024017268791794777\n",
      "Epoch 4285, Loss: 0.07901217881590128, Final Batch Loss: 0.004144255071878433\n",
      "Epoch 4286, Loss: 0.09594032168388367, Final Batch Loss: 0.05311780422925949\n",
      "Epoch 4287, Loss: 0.16085683181881905, Final Batch Loss: 0.09891783446073532\n",
      "Epoch 4288, Loss: 0.04523766878992319, Final Batch Loss: 0.01135116908699274\n",
      "Epoch 4289, Loss: 0.05304364045150578, Final Batch Loss: 0.023864634335041046\n",
      "Epoch 4290, Loss: 0.23911046609282494, Final Batch Loss: 0.08279112726449966\n",
      "Epoch 4291, Loss: 0.09149022120982409, Final Batch Loss: 0.022084351629018784\n",
      "Epoch 4292, Loss: 0.06967693800106645, Final Batch Loss: 0.01195231731981039\n",
      "Epoch 4293, Loss: 0.0947802234441042, Final Batch Loss: 0.02614397555589676\n",
      "Epoch 4294, Loss: 0.03466717293485999, Final Batch Loss: 0.015593470074236393\n",
      "Epoch 4295, Loss: 0.11758224107325077, Final Batch Loss: 0.037865690886974335\n",
      "Epoch 4296, Loss: 0.03579054237343371, Final Batch Loss: 0.006525082979351282\n",
      "Epoch 4297, Loss: 0.11217900086194277, Final Batch Loss: 0.009241725318133831\n",
      "Epoch 4298, Loss: 0.03689766000024974, Final Batch Loss: 0.0022156781051307917\n",
      "Epoch 4299, Loss: 0.03987060324288905, Final Batch Loss: 0.0009016322437673807\n",
      "Epoch 4300, Loss: 0.07250737445428967, Final Batch Loss: 0.002330516930669546\n",
      "Epoch 4301, Loss: 0.03738159965723753, Final Batch Loss: 0.006362719926983118\n",
      "Epoch 4302, Loss: 0.06960375048220158, Final Batch Loss: 0.01681206189095974\n",
      "Epoch 4303, Loss: 0.03604538692161441, Final Batch Loss: 0.014691337011754513\n",
      "Epoch 4304, Loss: 0.03912276087794453, Final Batch Loss: 0.0018249907298013568\n",
      "Epoch 4305, Loss: 0.023249233374372125, Final Batch Loss: 0.0035231674555689096\n",
      "Epoch 4306, Loss: 0.01395593152847141, Final Batch Loss: 0.0021975573617964983\n",
      "Epoch 4307, Loss: 0.032576681463979185, Final Batch Loss: 0.018220694735646248\n",
      "Epoch 4308, Loss: 0.07334536663256586, Final Batch Loss: 0.030244003981351852\n",
      "Epoch 4309, Loss: 0.016112299053929746, Final Batch Loss: 0.001894364831969142\n",
      "Epoch 4310, Loss: 0.03172755008563399, Final Batch Loss: 0.002642524428665638\n",
      "Epoch 4311, Loss: 0.08511125715449452, Final Batch Loss: 0.0045978776179254055\n",
      "Epoch 4312, Loss: 0.07235860032960773, Final Batch Loss: 0.0069020153023302555\n",
      "Epoch 4313, Loss: 0.032066238578408957, Final Batch Loss: 0.00628300104290247\n",
      "Epoch 4314, Loss: 0.061041504493914545, Final Batch Loss: 0.0017734825378283858\n",
      "Epoch 4315, Loss: 0.030557374702766538, Final Batch Loss: 0.0010025373194366693\n",
      "Epoch 4316, Loss: 0.07200888532679528, Final Batch Loss: 0.0008301379857584834\n",
      "Epoch 4317, Loss: 0.018339074100367725, Final Batch Loss: 0.008261253125965595\n",
      "Epoch 4318, Loss: 0.02679773257113993, Final Batch Loss: 0.0025315198581665754\n",
      "Epoch 4319, Loss: 0.03946245298720896, Final Batch Loss: 0.0030922836158424616\n",
      "Epoch 4320, Loss: 0.03366235992871225, Final Batch Loss: 0.004748828709125519\n",
      "Epoch 4321, Loss: 0.01110609876923263, Final Batch Loss: 0.003659983165562153\n",
      "Epoch 4322, Loss: 0.08490332681685686, Final Batch Loss: 0.059257622808218\n",
      "Epoch 4323, Loss: 0.04705770267173648, Final Batch Loss: 0.0013741464354097843\n",
      "Epoch 4324, Loss: 0.09778786497190595, Final Batch Loss: 0.005667493212968111\n",
      "Epoch 4325, Loss: 0.047092163702473044, Final Batch Loss: 0.0032269374933093786\n",
      "Epoch 4326, Loss: 0.02234793733805418, Final Batch Loss: 0.004179160576313734\n",
      "Epoch 4327, Loss: 0.08491894835606217, Final Batch Loss: 0.004383545834571123\n",
      "Epoch 4328, Loss: 0.0589750106446445, Final Batch Loss: 0.00483680097386241\n",
      "Epoch 4329, Loss: 0.030810058815404773, Final Batch Loss: 0.0016988161951303482\n",
      "Epoch 4330, Loss: 0.020050440449267626, Final Batch Loss: 0.004906872753053904\n",
      "Epoch 4331, Loss: 0.01843685540370643, Final Batch Loss: 0.0019303387962281704\n",
      "Epoch 4332, Loss: 0.045314177172258496, Final Batch Loss: 0.0023602417204529047\n",
      "Epoch 4333, Loss: 0.05444101837929338, Final Batch Loss: 0.0015134214190766215\n",
      "Epoch 4334, Loss: 0.04436799231916666, Final Batch Loss: 0.001755683682858944\n",
      "Epoch 4335, Loss: 0.05551112280227244, Final Batch Loss: 0.004768036771565676\n",
      "Epoch 4336, Loss: 0.024292234797030687, Final Batch Loss: 0.005762829910963774\n",
      "Epoch 4337, Loss: 0.016023491858504713, Final Batch Loss: 0.0006351628107950091\n",
      "Epoch 4338, Loss: 0.08796041109599173, Final Batch Loss: 0.04086931422352791\n",
      "Epoch 4339, Loss: 0.0669062779052183, Final Batch Loss: 0.001671744859777391\n",
      "Epoch 4340, Loss: 0.032707420410588384, Final Batch Loss: 0.0027460677083581686\n",
      "Epoch 4341, Loss: 0.03480506327468902, Final Batch Loss: 0.0025502066127955914\n",
      "Epoch 4342, Loss: 0.010592092527076602, Final Batch Loss: 0.0012277890928089619\n",
      "Epoch 4343, Loss: 0.015883242012932897, Final Batch Loss: 0.0012380490079522133\n",
      "Epoch 4344, Loss: 0.04101999802514911, Final Batch Loss: 0.0028783660382032394\n",
      "Epoch 4345, Loss: 0.00586473144358024, Final Batch Loss: 0.001931893639266491\n",
      "Epoch 4346, Loss: 0.016198800527490675, Final Batch Loss: 0.001029151608236134\n",
      "Epoch 4347, Loss: 0.016595860943198204, Final Batch Loss: 0.0013791641686111689\n",
      "Epoch 4348, Loss: 0.025839961017481983, Final Batch Loss: 0.01712212525308132\n",
      "Epoch 4349, Loss: 0.04478124959859997, Final Batch Loss: 0.018191441893577576\n",
      "Epoch 4350, Loss: 0.01366501027951017, Final Batch Loss: 0.0008691817638464272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4351, Loss: 0.03570125112310052, Final Batch Loss: 0.006759353447705507\n",
      "Epoch 4352, Loss: 0.031119196442887187, Final Batch Loss: 0.0017914960626512766\n",
      "Epoch 4353, Loss: 0.08696433168370277, Final Batch Loss: 0.04861811175942421\n",
      "Epoch 4354, Loss: 0.07301353884395212, Final Batch Loss: 0.04123350977897644\n",
      "Epoch 4355, Loss: 0.04457983304746449, Final Batch Loss: 0.017291299998760223\n",
      "Epoch 4356, Loss: 0.05370681546628475, Final Batch Loss: 0.004383633844554424\n",
      "Epoch 4357, Loss: 0.04573587910272181, Final Batch Loss: 0.0035595896188169718\n",
      "Epoch 4358, Loss: 0.06061449786648154, Final Batch Loss: 0.0390053354203701\n",
      "Epoch 4359, Loss: 0.020808218512684107, Final Batch Loss: 0.007054459303617477\n",
      "Epoch 4360, Loss: 0.03478300740243867, Final Batch Loss: 0.00048669223906472325\n",
      "Epoch 4361, Loss: 0.0398514976259321, Final Batch Loss: 0.0038209662307053804\n",
      "Epoch 4362, Loss: 0.020354882115498185, Final Batch Loss: 0.0034974217414855957\n",
      "Epoch 4363, Loss: 0.020928084384649992, Final Batch Loss: 0.0016586859710514545\n",
      "Epoch 4364, Loss: 0.04203491425141692, Final Batch Loss: 0.007137908600270748\n",
      "Epoch 4365, Loss: 0.05176040600053966, Final Batch Loss: 0.0011552965734153986\n",
      "Epoch 4366, Loss: 0.02715437486767769, Final Batch Loss: 0.004351411946117878\n",
      "Epoch 4367, Loss: 0.03858065442182124, Final Batch Loss: 0.0024650783743709326\n",
      "Epoch 4368, Loss: 0.06039242306724191, Final Batch Loss: 0.023238616064190865\n",
      "Epoch 4369, Loss: 0.10961394477635622, Final Batch Loss: 0.056095436215400696\n",
      "Epoch 4370, Loss: 0.05961011070758104, Final Batch Loss: 0.015814337879419327\n",
      "Epoch 4371, Loss: 0.08257909398525953, Final Batch Loss: 0.011463760398328304\n",
      "Epoch 4372, Loss: 0.06788996607065201, Final Batch Loss: 0.012550637125968933\n",
      "Epoch 4373, Loss: 0.05608388967812061, Final Batch Loss: 0.008294655941426754\n",
      "Epoch 4374, Loss: 0.05983682186342776, Final Batch Loss: 0.003386288182809949\n",
      "Epoch 4375, Loss: 0.02779052604455501, Final Batch Loss: 0.006604618858546019\n",
      "Epoch 4376, Loss: 0.07445796160027385, Final Batch Loss: 0.00420448137447238\n",
      "Epoch 4377, Loss: 0.012805579463019967, Final Batch Loss: 0.0005165208131074905\n",
      "Epoch 4378, Loss: 0.019236612366512418, Final Batch Loss: 0.007035782095044851\n",
      "Epoch 4379, Loss: 0.05088248080573976, Final Batch Loss: 0.001267061335965991\n",
      "Epoch 4380, Loss: 0.006536447966936976, Final Batch Loss: 0.0005065124132670462\n",
      "Epoch 4381, Loss: 0.018388177384622395, Final Batch Loss: 0.0018418015679344535\n",
      "Epoch 4382, Loss: 0.023236347129568458, Final Batch Loss: 0.0046531991101801395\n",
      "Epoch 4383, Loss: 0.03230357062420808, Final Batch Loss: 0.0003680389781948179\n",
      "Epoch 4384, Loss: 0.020600347546860576, Final Batch Loss: 0.001312414649873972\n",
      "Epoch 4385, Loss: 0.026676083682104945, Final Batch Loss: 0.001459347316995263\n",
      "Epoch 4386, Loss: 0.010706411907449365, Final Batch Loss: 0.0028256098739802837\n",
      "Epoch 4387, Loss: 0.007519073260482401, Final Batch Loss: 0.0006016322295181453\n",
      "Epoch 4388, Loss: 0.010940764448605478, Final Batch Loss: 0.0010195317445322871\n",
      "Epoch 4389, Loss: 0.012378260493278503, Final Batch Loss: 0.0010880357585847378\n",
      "Epoch 4390, Loss: 0.034561485750600696, Final Batch Loss: 0.0007101551163941622\n",
      "Epoch 4391, Loss: 0.03244967432692647, Final Batch Loss: 0.0028177856002002954\n",
      "Epoch 4392, Loss: 0.038874256424605846, Final Batch Loss: 0.0056905969977378845\n",
      "Epoch 4393, Loss: 0.03686955198645592, Final Batch Loss: 0.0013319444842636585\n",
      "Epoch 4394, Loss: 0.015330883441492915, Final Batch Loss: 0.0026787742972373962\n",
      "Epoch 4395, Loss: 0.06084668752737343, Final Batch Loss: 0.007333180867135525\n",
      "Epoch 4396, Loss: 0.014773549512028694, Final Batch Loss: 0.0010411316761747003\n",
      "Epoch 4397, Loss: 0.015422924072481692, Final Batch Loss: 0.0007753072422929108\n",
      "Epoch 4398, Loss: 0.016811125009553507, Final Batch Loss: 0.0003432701632846147\n",
      "Epoch 4399, Loss: 0.027916078630369157, Final Batch Loss: 0.0005532691138796508\n",
      "Epoch 4400, Loss: 0.04305964382365346, Final Batch Loss: 0.0007891817949712276\n",
      "Epoch 4401, Loss: 0.04105356737272814, Final Batch Loss: 0.026754703372716904\n",
      "Epoch 4402, Loss: 0.007104023301508278, Final Batch Loss: 0.0004994400660507381\n",
      "Epoch 4403, Loss: 0.01717264810577035, Final Batch Loss: 0.011133484542369843\n",
      "Epoch 4404, Loss: 0.0745121855288744, Final Batch Loss: 0.03207052871584892\n",
      "Epoch 4405, Loss: 0.038130055472720414, Final Batch Loss: 0.02717295102775097\n",
      "Epoch 4406, Loss: 0.026596095180138946, Final Batch Loss: 0.0023203957825899124\n",
      "Epoch 4407, Loss: 0.07743296411354095, Final Batch Loss: 0.04425997659564018\n",
      "Epoch 4408, Loss: 0.042165472521446645, Final Batch Loss: 0.001763802021741867\n",
      "Epoch 4409, Loss: 0.10346217732876539, Final Batch Loss: 0.003616134636104107\n",
      "Epoch 4410, Loss: 0.022362587158568203, Final Batch Loss: 0.0007327847415581346\n",
      "Epoch 4411, Loss: 0.10272060695569962, Final Batch Loss: 0.061249878257513046\n",
      "Epoch 4412, Loss: 0.09233173169195652, Final Batch Loss: 0.0022517330944538116\n",
      "Epoch 4413, Loss: 0.021685128682292998, Final Batch Loss: 0.0014302340568974614\n",
      "Epoch 4414, Loss: 0.14094399847090244, Final Batch Loss: 0.004493221640586853\n",
      "Epoch 4415, Loss: 0.12455646554008126, Final Batch Loss: 0.10224804282188416\n",
      "Epoch 4416, Loss: 0.03306662989780307, Final Batch Loss: 0.0065561761148273945\n",
      "Epoch 4417, Loss: 0.06678664521314204, Final Batch Loss: 0.0032154491636902094\n",
      "Epoch 4418, Loss: 0.06625205208547413, Final Batch Loss: 0.003706017741933465\n",
      "Epoch 4419, Loss: 0.11774100735783577, Final Batch Loss: 0.08280891925096512\n",
      "Epoch 4420, Loss: 0.038225914584472775, Final Batch Loss: 0.01378268375992775\n",
      "Epoch 4421, Loss: 0.016471206210553646, Final Batch Loss: 0.0021870150230824947\n",
      "Epoch 4422, Loss: 0.0701902483124286, Final Batch Loss: 0.03337489441037178\n",
      "Epoch 4423, Loss: 0.02036800142377615, Final Batch Loss: 0.004475140478461981\n",
      "Epoch 4424, Loss: 0.02268226898740977, Final Batch Loss: 0.0003959358436986804\n",
      "Epoch 4425, Loss: 0.04204047948587686, Final Batch Loss: 0.0008828934514895082\n",
      "Epoch 4426, Loss: 0.050045306561514735, Final Batch Loss: 0.0004294810350984335\n",
      "Epoch 4427, Loss: 0.02788556192535907, Final Batch Loss: 0.0010889190016314387\n",
      "Epoch 4428, Loss: 0.030949339481594507, Final Batch Loss: 0.00011917643860215321\n",
      "Epoch 4429, Loss: 0.0684142365353182, Final Batch Loss: 0.0005917927483096719\n",
      "Epoch 4430, Loss: 0.02479403279721737, Final Batch Loss: 0.005721329245716333\n",
      "Epoch 4431, Loss: 0.010132971801795065, Final Batch Loss: 0.0029250700026750565\n",
      "Epoch 4432, Loss: 0.033223281847313046, Final Batch Loss: 0.003298176219686866\n",
      "Epoch 4433, Loss: 0.03384258058213163, Final Batch Loss: 0.0001767043286236003\n",
      "Epoch 4434, Loss: 0.016445596935227513, Final Batch Loss: 0.0057231830433011055\n",
      "Epoch 4435, Loss: 0.03702595527283847, Final Batch Loss: 0.0027904098387807608\n",
      "Epoch 4436, Loss: 0.047021465143188834, Final Batch Loss: 0.00337612465955317\n",
      "Epoch 4437, Loss: 0.02616739517543465, Final Batch Loss: 0.005252418108284473\n",
      "Epoch 4438, Loss: 0.02317132019379642, Final Batch Loss: 0.00023726803192403167\n",
      "Epoch 4439, Loss: 0.05733573468751274, Final Batch Loss: 0.00019453404820524156\n",
      "Epoch 4440, Loss: 0.06405157619155943, Final Batch Loss: 0.014002175070345402\n",
      "Epoch 4441, Loss: 0.03437510598450899, Final Batch Loss: 0.0061376625671982765\n",
      "Epoch 4442, Loss: 0.039759856183081865, Final Batch Loss: 0.005784102249890566\n",
      "Epoch 4443, Loss: 0.01562521606683731, Final Batch Loss: 0.001453561126254499\n",
      "Epoch 4444, Loss: 0.022482462460175157, Final Batch Loss: 0.003974179271608591\n",
      "Epoch 4445, Loss: 0.036467684782110155, Final Batch Loss: 0.0015147925587370992\n",
      "Epoch 4446, Loss: 0.012755866046063602, Final Batch Loss: 0.0021464109886437654\n",
      "Epoch 4447, Loss: 0.03722574110724963, Final Batch Loss: 0.00035110782482661307\n",
      "Epoch 4448, Loss: 0.008686522953212261, Final Batch Loss: 0.0002717542229220271\n",
      "Epoch 4449, Loss: 0.04833089932799339, Final Batch Loss: 0.0012621274217963219\n",
      "Epoch 4450, Loss: 0.043883881880901754, Final Batch Loss: 0.005471023730933666\n",
      "Epoch 4451, Loss: 0.07720369379967451, Final Batch Loss: 0.02185910753905773\n",
      "Epoch 4452, Loss: 0.018219985649921, Final Batch Loss: 0.001891669468022883\n",
      "Epoch 4453, Loss: 0.022287853993475437, Final Batch Loss: 0.007884031161665916\n",
      "Epoch 4454, Loss: 0.058621727861464024, Final Batch Loss: 0.017474772408604622\n",
      "Epoch 4455, Loss: 0.046071835909970105, Final Batch Loss: 0.001833045040257275\n",
      "Epoch 4456, Loss: 0.013988594349939376, Final Batch Loss: 0.0006372102652676404\n",
      "Epoch 4457, Loss: 0.017218874883837998, Final Batch Loss: 0.0013804597547277808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4458, Loss: 0.011918619886273518, Final Batch Loss: 0.00024841949925757945\n",
      "Epoch 4459, Loss: 0.04301130259409547, Final Batch Loss: 0.004288866650313139\n",
      "Epoch 4460, Loss: 0.0488628787570633, Final Batch Loss: 0.035038769245147705\n",
      "Epoch 4461, Loss: 0.010998339945217595, Final Batch Loss: 0.00044510109000839293\n",
      "Epoch 4462, Loss: 0.018624707241542637, Final Batch Loss: 0.014314153231680393\n",
      "Epoch 4463, Loss: 0.01875193597516045, Final Batch Loss: 0.004745800979435444\n",
      "Epoch 4464, Loss: 0.044731611269526184, Final Batch Loss: 0.006655146833509207\n",
      "Epoch 4465, Loss: 0.01799811818636954, Final Batch Loss: 0.0010764205362647772\n",
      "Epoch 4466, Loss: 0.021519570233067498, Final Batch Loss: 0.003595762187615037\n",
      "Epoch 4467, Loss: 0.054825080325827, Final Batch Loss: 0.003020184813067317\n",
      "Epoch 4468, Loss: 0.01786003465531394, Final Batch Loss: 0.002114999806508422\n",
      "Epoch 4469, Loss: 0.007666032994166017, Final Batch Loss: 0.0013781460002064705\n",
      "Epoch 4470, Loss: 0.06230895163025707, Final Batch Loss: 0.032017167657613754\n",
      "Epoch 4471, Loss: 0.01069607341196388, Final Batch Loss: 0.001126444316469133\n",
      "Epoch 4472, Loss: 0.036676298128440976, Final Batch Loss: 0.008436732925474644\n",
      "Epoch 4473, Loss: 0.048305844189599156, Final Batch Loss: 0.009376710280776024\n",
      "Epoch 4474, Loss: 0.048953209072351456, Final Batch Loss: 0.021835029125213623\n",
      "Epoch 4475, Loss: 0.011508139432407916, Final Batch Loss: 0.0016800359589979053\n",
      "Epoch 4476, Loss: 0.019036539146327414, Final Batch Loss: 0.0007131067104637623\n",
      "Epoch 4477, Loss: 0.044916122453287244, Final Batch Loss: 0.01948287896811962\n",
      "Epoch 4478, Loss: 0.02783274557441473, Final Batch Loss: 0.014523492194712162\n",
      "Epoch 4479, Loss: 0.027126340428367257, Final Batch Loss: 0.005373054184019566\n",
      "Epoch 4480, Loss: 0.20639135362580419, Final Batch Loss: 0.16957630217075348\n",
      "Epoch 4481, Loss: 0.07951805926859379, Final Batch Loss: 0.004908889532089233\n",
      "Epoch 4482, Loss: 0.042113601230084896, Final Batch Loss: 0.004448500461876392\n",
      "Epoch 4483, Loss: 0.10087078530341387, Final Batch Loss: 0.023869561031460762\n",
      "Epoch 4484, Loss: 0.03217819845303893, Final Batch Loss: 0.023583149537444115\n",
      "Epoch 4485, Loss: 0.03079600166529417, Final Batch Loss: 0.002581288106739521\n",
      "Epoch 4486, Loss: 0.054057476576417685, Final Batch Loss: 0.0022606709972023964\n",
      "Epoch 4487, Loss: 0.02744978468399495, Final Batch Loss: 0.0016285061137750745\n",
      "Epoch 4488, Loss: 0.021867404459044337, Final Batch Loss: 0.0027652308344841003\n",
      "Epoch 4489, Loss: 0.011004089377820492, Final Batch Loss: 0.0002746226964518428\n",
      "Epoch 4490, Loss: 0.013512998819351196, Final Batch Loss: 0.001303975936025381\n",
      "Epoch 4491, Loss: 0.009687088633654639, Final Batch Loss: 0.00041008551488630474\n",
      "Epoch 4492, Loss: 0.029030585661530495, Final Batch Loss: 0.00777517119422555\n",
      "Epoch 4493, Loss: 0.03007216495461762, Final Batch Loss: 0.004726978950202465\n",
      "Epoch 4494, Loss: 0.029117124155163765, Final Batch Loss: 0.0017032739706337452\n",
      "Epoch 4495, Loss: 0.04989715735428035, Final Batch Loss: 0.033092401921749115\n",
      "Epoch 4496, Loss: 0.05221383273601532, Final Batch Loss: 0.012678681872785091\n",
      "Epoch 4497, Loss: 0.07752509694546461, Final Batch Loss: 0.0211349967867136\n",
      "Epoch 4498, Loss: 0.0820788306882605, Final Batch Loss: 0.0005735362647101283\n",
      "Epoch 4499, Loss: 0.03336852334905416, Final Batch Loss: 0.0014137056423351169\n",
      "Epoch 4500, Loss: 0.09438329585827887, Final Batch Loss: 0.0793800950050354\n",
      "Epoch 4501, Loss: 0.028895322000607848, Final Batch Loss: 0.011046876199543476\n",
      "Epoch 4502, Loss: 0.025524949887767434, Final Batch Loss: 0.001989868702366948\n",
      "Epoch 4503, Loss: 0.03051449079066515, Final Batch Loss: 0.0013841921463608742\n",
      "Epoch 4504, Loss: 0.03112343093380332, Final Batch Loss: 0.0017814780585467815\n",
      "Epoch 4505, Loss: 0.08940131589770317, Final Batch Loss: 0.04745710641145706\n",
      "Epoch 4506, Loss: 0.02522695786319673, Final Batch Loss: 0.0048314048908650875\n",
      "Epoch 4507, Loss: 0.045536614023149014, Final Batch Loss: 0.011844801716506481\n",
      "Epoch 4508, Loss: 0.06749459041748196, Final Batch Loss: 0.060546938329935074\n",
      "Epoch 4509, Loss: 0.02711977600120008, Final Batch Loss: 0.00403962517157197\n",
      "Epoch 4510, Loss: 0.042964501306414604, Final Batch Loss: 0.0052360049448907375\n",
      "Epoch 4511, Loss: 0.03362847096286714, Final Batch Loss: 0.0031255024950951338\n",
      "Epoch 4512, Loss: 0.0681428307434544, Final Batch Loss: 0.0028554601594805717\n",
      "Epoch 4513, Loss: 0.012186867883428931, Final Batch Loss: 0.004434787202626467\n",
      "Epoch 4514, Loss: 0.02299829141702503, Final Batch Loss: 0.0015974085545167327\n",
      "Epoch 4515, Loss: 0.02967820386402309, Final Batch Loss: 0.002864848356693983\n",
      "Epoch 4516, Loss: 0.0787660910282284, Final Batch Loss: 0.05658840760588646\n",
      "Epoch 4517, Loss: 0.07286318147089332, Final Batch Loss: 0.023839859291911125\n",
      "Epoch 4518, Loss: 0.06146041164174676, Final Batch Loss: 0.033216241747140884\n",
      "Epoch 4519, Loss: 0.0484246218111366, Final Batch Loss: 0.0035281123127788305\n",
      "Epoch 4520, Loss: 0.029013898223638535, Final Batch Loss: 0.008543554693460464\n",
      "Epoch 4521, Loss: 0.06289298087358475, Final Batch Loss: 0.008977594785392284\n",
      "Epoch 4522, Loss: 0.07492517348146066, Final Batch Loss: 0.0007965177646838129\n",
      "Epoch 4523, Loss: 0.08983134012669325, Final Batch Loss: 0.023595314472913742\n",
      "Epoch 4524, Loss: 0.06607513036578894, Final Batch Loss: 0.026892876252532005\n",
      "Epoch 4525, Loss: 0.05956766824238002, Final Batch Loss: 0.018001170828938484\n",
      "Epoch 4526, Loss: 0.1628132313489914, Final Batch Loss: 0.08946060389280319\n",
      "Epoch 4527, Loss: 0.060161363100633025, Final Batch Loss: 0.002109678229317069\n",
      "Epoch 4528, Loss: 0.06616528891026974, Final Batch Loss: 0.0189349427819252\n",
      "Epoch 4529, Loss: 0.034047580091282725, Final Batch Loss: 0.006266020704060793\n",
      "Epoch 4530, Loss: 0.02654436999000609, Final Batch Loss: 0.010145294480025768\n",
      "Epoch 4531, Loss: 0.03835643222555518, Final Batch Loss: 0.005395898129791021\n",
      "Epoch 4532, Loss: 0.03139630169607699, Final Batch Loss: 0.0008326547686010599\n",
      "Epoch 4533, Loss: 0.07385105290450156, Final Batch Loss: 0.03268097713589668\n",
      "Epoch 4534, Loss: 0.02838491415604949, Final Batch Loss: 0.010452929884195328\n",
      "Epoch 4535, Loss: 0.028124904725700617, Final Batch Loss: 0.0015442529693245888\n",
      "Epoch 4536, Loss: 0.03733909549191594, Final Batch Loss: 0.005871200934052467\n",
      "Epoch 4537, Loss: 0.08687021967489272, Final Batch Loss: 0.0020414029713720083\n",
      "Epoch 4538, Loss: 0.03674741444410756, Final Batch Loss: 0.0007986135897226632\n",
      "Epoch 4539, Loss: 0.06239252118393779, Final Batch Loss: 0.008397191762924194\n",
      "Epoch 4540, Loss: 0.04511689906939864, Final Batch Loss: 0.009305702522397041\n",
      "Epoch 4541, Loss: 0.018145779031328857, Final Batch Loss: 0.0017774013103917241\n",
      "Epoch 4542, Loss: 0.027381573105230927, Final Batch Loss: 0.006173137575387955\n",
      "Epoch 4543, Loss: 0.008927227114327252, Final Batch Loss: 0.0023390185087919235\n",
      "Epoch 4544, Loss: 0.03217685199342668, Final Batch Loss: 0.0012397754471749067\n",
      "Epoch 4545, Loss: 0.049738653120584786, Final Batch Loss: 0.012489368207752705\n",
      "Epoch 4546, Loss: 0.049537692102603614, Final Batch Loss: 0.0013889811234548688\n",
      "Epoch 4547, Loss: 0.014413240132853389, Final Batch Loss: 0.001961692236363888\n",
      "Epoch 4548, Loss: 0.03663251828402281, Final Batch Loss: 0.0070207007229328156\n",
      "Epoch 4549, Loss: 0.02062527963425964, Final Batch Loss: 0.009890235029160976\n",
      "Epoch 4550, Loss: 0.03963092074263841, Final Batch Loss: 0.0009888607310131192\n",
      "Epoch 4551, Loss: 0.008132370887324214, Final Batch Loss: 0.001137844636105001\n",
      "Epoch 4552, Loss: 0.039100793888792396, Final Batch Loss: 0.0020114106591790915\n",
      "Epoch 4553, Loss: 0.031633914448320866, Final Batch Loss: 0.008542896248400211\n",
      "Epoch 4554, Loss: 0.01684499776456505, Final Batch Loss: 0.001658740104176104\n",
      "Epoch 4555, Loss: 0.05213954532518983, Final Batch Loss: 0.009676453657448292\n",
      "Epoch 4556, Loss: 0.013628750573843718, Final Batch Loss: 0.0033486380707472563\n",
      "Epoch 4557, Loss: 0.025307591655291617, Final Batch Loss: 0.00039597286377102137\n",
      "Epoch 4558, Loss: 0.026181558496318758, Final Batch Loss: 0.0014536516973748803\n",
      "Epoch 4559, Loss: 0.004877278406638652, Final Batch Loss: 0.0009240311337634921\n",
      "Epoch 4560, Loss: 0.05011133351945318, Final Batch Loss: 0.0004259582201484591\n",
      "Epoch 4561, Loss: 0.02801758935675025, Final Batch Loss: 0.0028322881553322077\n",
      "Epoch 4562, Loss: 0.08018640987575054, Final Batch Loss: 0.0017883717082440853\n",
      "Epoch 4563, Loss: 0.0288701462559402, Final Batch Loss: 0.015145561657845974\n",
      "Epoch 4564, Loss: 0.04885907053539995, Final Batch Loss: 0.00017397211922798306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4565, Loss: 0.01588935893960297, Final Batch Loss: 0.0012782413978129625\n",
      "Epoch 4566, Loss: 0.013359308359213173, Final Batch Loss: 0.0007027528481557965\n",
      "Epoch 4567, Loss: 0.026551874936558306, Final Batch Loss: 0.0015611822018399835\n",
      "Epoch 4568, Loss: 0.0667482316493988, Final Batch Loss: 0.007773335091769695\n",
      "Epoch 4569, Loss: 0.08438498008763418, Final Batch Loss: 0.000868678733240813\n",
      "Epoch 4570, Loss: 0.050777592696249485, Final Batch Loss: 0.0028693396598100662\n",
      "Epoch 4571, Loss: 0.046408078633248806, Final Batch Loss: 0.011765412986278534\n",
      "Epoch 4572, Loss: 0.06735252728685737, Final Batch Loss: 0.0012339132372289896\n",
      "Epoch 4573, Loss: 0.040189054096117616, Final Batch Loss: 0.003231509355828166\n",
      "Epoch 4574, Loss: 0.13375790906138718, Final Batch Loss: 0.04977637529373169\n",
      "Epoch 4575, Loss: 0.05159231065772474, Final Batch Loss: 0.018809368833899498\n",
      "Epoch 4576, Loss: 0.09350977698341012, Final Batch Loss: 0.045185428112745285\n",
      "Epoch 4577, Loss: 0.05554138449952006, Final Batch Loss: 0.010144409723579884\n",
      "Epoch 4578, Loss: 0.07435896480455995, Final Batch Loss: 0.02256740629673004\n",
      "Epoch 4579, Loss: 0.05629429314285517, Final Batch Loss: 0.003440811298787594\n",
      "Epoch 4580, Loss: 0.13646569661796093, Final Batch Loss: 0.05337366834282875\n",
      "Epoch 4581, Loss: 0.1499837653245777, Final Batch Loss: 0.09700295329093933\n",
      "Epoch 4582, Loss: 0.03565315529704094, Final Batch Loss: 0.0030082748271524906\n",
      "Epoch 4583, Loss: 0.10148267261683941, Final Batch Loss: 0.0149063216522336\n",
      "Epoch 4584, Loss: 0.07482523657381535, Final Batch Loss: 0.0020876768976449966\n",
      "Epoch 4585, Loss: 0.02144786634016782, Final Batch Loss: 0.0012537973234429955\n",
      "Epoch 4586, Loss: 0.013988445163704455, Final Batch Loss: 0.001165384310297668\n",
      "Epoch 4587, Loss: 0.04383868188597262, Final Batch Loss: 0.003745617112144828\n",
      "Epoch 4588, Loss: 0.021371755632571876, Final Batch Loss: 0.008853473700582981\n",
      "Epoch 4589, Loss: 0.04951253207400441, Final Batch Loss: 0.005993538070470095\n",
      "Epoch 4590, Loss: 0.06541602686047554, Final Batch Loss: 0.006282070651650429\n",
      "Epoch 4591, Loss: 0.06595758907496929, Final Batch Loss: 0.016402335837483406\n",
      "Epoch 4592, Loss: 0.01636452623642981, Final Batch Loss: 0.0018118140287697315\n",
      "Epoch 4593, Loss: 0.07886941777542233, Final Batch Loss: 0.04082351177930832\n",
      "Epoch 4594, Loss: 0.03578810766339302, Final Batch Loss: 0.0017191818915307522\n",
      "Epoch 4595, Loss: 0.06749892141669989, Final Batch Loss: 0.009805127047002316\n",
      "Epoch 4596, Loss: 0.031052843783982098, Final Batch Loss: 0.0014641034649685025\n",
      "Epoch 4597, Loss: 0.035171968629583716, Final Batch Loss: 0.01142432913184166\n",
      "Epoch 4598, Loss: 0.03969839308410883, Final Batch Loss: 0.003080985974520445\n",
      "Epoch 4599, Loss: 0.03984210267663002, Final Batch Loss: 0.009308785200119019\n",
      "Epoch 4600, Loss: 0.06943757552653551, Final Batch Loss: 0.0075048464350402355\n",
      "Epoch 4601, Loss: 0.05552503373473883, Final Batch Loss: 0.017034756019711494\n",
      "Epoch 4602, Loss: 0.05950911599211395, Final Batch Loss: 0.03311733528971672\n",
      "Epoch 4603, Loss: 0.06430331151932478, Final Batch Loss: 0.0025587170384824276\n",
      "Epoch 4604, Loss: 0.06575020124728326, Final Batch Loss: 0.00021431503409985453\n",
      "Epoch 4605, Loss: 0.049419427290558815, Final Batch Loss: 0.00886631291359663\n",
      "Epoch 4606, Loss: 0.050911879632622004, Final Batch Loss: 0.01159130223095417\n",
      "Epoch 4607, Loss: 0.12688225787132978, Final Batch Loss: 0.07609674334526062\n",
      "Epoch 4608, Loss: 0.041993239196017385, Final Batch Loss: 0.0067778779193758965\n",
      "Epoch 4609, Loss: 0.10886764153838158, Final Batch Loss: 0.03524031490087509\n",
      "Epoch 4610, Loss: 0.07726610382087529, Final Batch Loss: 0.0007613350171595812\n",
      "Epoch 4611, Loss: 0.057572811376303434, Final Batch Loss: 0.016506191343069077\n",
      "Epoch 4612, Loss: 0.06238263426348567, Final Batch Loss: 0.007818103767931461\n",
      "Epoch 4613, Loss: 0.1010247494559735, Final Batch Loss: 0.00854070670902729\n",
      "Epoch 4614, Loss: 0.04159943573176861, Final Batch Loss: 0.026578128337860107\n",
      "Epoch 4615, Loss: 0.021609626768622547, Final Batch Loss: 0.0007169913151301444\n",
      "Epoch 4616, Loss: 0.06838298973161727, Final Batch Loss: 0.03272757679224014\n",
      "Epoch 4617, Loss: 0.10744719719514251, Final Batch Loss: 0.050356727093458176\n",
      "Epoch 4618, Loss: 0.03851813357323408, Final Batch Loss: 0.0091082863509655\n",
      "Epoch 4619, Loss: 0.08824831899255514, Final Batch Loss: 0.003271891735494137\n",
      "Epoch 4620, Loss: 0.023696130141615868, Final Batch Loss: 0.005584570113569498\n",
      "Epoch 4621, Loss: 0.045029571978375316, Final Batch Loss: 0.035790469497442245\n",
      "Epoch 4622, Loss: 0.07691011112183332, Final Batch Loss: 0.0038534747436642647\n",
      "Epoch 4623, Loss: 0.03405820322223008, Final Batch Loss: 0.0013874329160898924\n",
      "Epoch 4624, Loss: 0.12246568966656923, Final Batch Loss: 0.0330159030854702\n",
      "Epoch 4625, Loss: 0.058080500923097134, Final Batch Loss: 0.013294991105794907\n",
      "Epoch 4626, Loss: 0.02941543678753078, Final Batch Loss: 0.0038319441955536604\n",
      "Epoch 4627, Loss: 0.1538770697079599, Final Batch Loss: 0.005910517182201147\n",
      "Epoch 4628, Loss: 0.031004901858977973, Final Batch Loss: 0.0002704410580918193\n",
      "Epoch 4629, Loss: 0.02846882725134492, Final Batch Loss: 0.003989881835877895\n",
      "Epoch 4630, Loss: 0.083639707416296, Final Batch Loss: 0.055756233632564545\n",
      "Epoch 4631, Loss: 0.04041964118368924, Final Batch Loss: 0.008595405146479607\n",
      "Epoch 4632, Loss: 0.06714900187216699, Final Batch Loss: 0.0526009127497673\n",
      "Epoch 4633, Loss: 0.03793644066900015, Final Batch Loss: 0.013310890644788742\n",
      "Epoch 4634, Loss: 0.0901400875300169, Final Batch Loss: 0.038953546434640884\n",
      "Epoch 4635, Loss: 0.07377324625849724, Final Batch Loss: 0.018734373152256012\n",
      "Epoch 4636, Loss: 0.11154176667332649, Final Batch Loss: 0.03525591269135475\n",
      "Epoch 4637, Loss: 0.022583427256904542, Final Batch Loss: 0.0015332343755289912\n",
      "Epoch 4638, Loss: 0.06642143614590168, Final Batch Loss: 0.001072429120540619\n",
      "Epoch 4639, Loss: 0.01956177386455238, Final Batch Loss: 0.003998485393822193\n",
      "Epoch 4640, Loss: 0.07420025207102299, Final Batch Loss: 0.005979970097541809\n",
      "Epoch 4641, Loss: 0.02065516822040081, Final Batch Loss: 0.01331267599016428\n",
      "Epoch 4642, Loss: 0.031220388365909457, Final Batch Loss: 0.022249169647693634\n",
      "Epoch 4643, Loss: 0.10283867316320539, Final Batch Loss: 0.06010385602712631\n",
      "Epoch 4644, Loss: 0.04886333429021761, Final Batch Loss: 0.000906898349057883\n",
      "Epoch 4645, Loss: 0.046402536099776626, Final Batch Loss: 0.0038949339650571346\n",
      "Epoch 4646, Loss: 0.06659040180966258, Final Batch Loss: 0.0030431183986365795\n",
      "Epoch 4647, Loss: 0.05665107350796461, Final Batch Loss: 0.001985812559723854\n",
      "Epoch 4648, Loss: 0.03127085417509079, Final Batch Loss: 0.001058703288435936\n",
      "Epoch 4649, Loss: 0.021354121156036854, Final Batch Loss: 0.0013986809644848108\n",
      "Epoch 4650, Loss: 0.03842583601363003, Final Batch Loss: 0.0018215228337794542\n",
      "Epoch 4651, Loss: 0.012968493392691016, Final Batch Loss: 0.0019902747590094805\n",
      "Epoch 4652, Loss: 0.034928485518321395, Final Batch Loss: 0.00655909301713109\n",
      "Epoch 4653, Loss: 0.032495295628905296, Final Batch Loss: 0.016902975738048553\n",
      "Epoch 4654, Loss: 0.04718768777092919, Final Batch Loss: 0.003193097421899438\n",
      "Epoch 4655, Loss: 0.07259639073163271, Final Batch Loss: 0.01623520255088806\n",
      "Epoch 4656, Loss: 0.03797068493440747, Final Batch Loss: 0.009359005838632584\n",
      "Epoch 4657, Loss: 0.096273438539356, Final Batch Loss: 0.04496577009558678\n",
      "Epoch 4658, Loss: 0.038877180428244174, Final Batch Loss: 0.010132839903235435\n",
      "Epoch 4659, Loss: 0.11306302598677576, Final Batch Loss: 0.07653823494911194\n",
      "Epoch 4660, Loss: 0.0291868990752846, Final Batch Loss: 0.004499433562159538\n",
      "Epoch 4661, Loss: 0.13678798079490662, Final Batch Loss: 0.047267794609069824\n",
      "Epoch 4662, Loss: 0.051559427520260215, Final Batch Loss: 0.0023622813168913126\n",
      "Epoch 4663, Loss: 0.12127644941210747, Final Batch Loss: 0.0058787502348423\n",
      "Epoch 4664, Loss: 0.13858336862176657, Final Batch Loss: 0.08239562064409256\n",
      "Epoch 4665, Loss: 0.10922783426940441, Final Batch Loss: 0.06189185380935669\n",
      "Epoch 4666, Loss: 0.043877351796254516, Final Batch Loss: 0.005015973001718521\n",
      "Epoch 4667, Loss: 0.12034822651185095, Final Batch Loss: 0.001030987361446023\n",
      "Epoch 4668, Loss: 0.05078173615038395, Final Batch Loss: 0.002667889464646578\n",
      "Epoch 4669, Loss: 0.03364731790497899, Final Batch Loss: 0.002397592179477215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4670, Loss: 0.013273786171339452, Final Batch Loss: 0.0006823312724009156\n",
      "Epoch 4671, Loss: 0.03985720849595964, Final Batch Loss: 0.002716530580073595\n",
      "Epoch 4672, Loss: 0.04845222574658692, Final Batch Loss: 0.0014141818974167109\n",
      "Epoch 4673, Loss: 0.015737116103991866, Final Batch Loss: 0.001033617416396737\n",
      "Epoch 4674, Loss: 0.023578332853503525, Final Batch Loss: 0.014531997963786125\n",
      "Epoch 4675, Loss: 0.011668599909171462, Final Batch Loss: 0.001011658227071166\n",
      "Epoch 4676, Loss: 0.04171595326624811, Final Batch Loss: 0.012269525788724422\n",
      "Epoch 4677, Loss: 0.012767759501002729, Final Batch Loss: 0.0016286819009110332\n",
      "Epoch 4678, Loss: 0.03630438866093755, Final Batch Loss: 0.002657871227711439\n",
      "Epoch 4679, Loss: 0.06599075766280293, Final Batch Loss: 0.004713170696049929\n",
      "Epoch 4680, Loss: 0.049319662153720856, Final Batch Loss: 0.02127363346517086\n",
      "Epoch 4681, Loss: 0.08431098517030478, Final Batch Loss: 0.01496692281216383\n",
      "Epoch 4682, Loss: 0.022802502033300698, Final Batch Loss: 0.009721041657030582\n",
      "Epoch 4683, Loss: 0.07447234669234604, Final Batch Loss: 0.0005956360837444663\n",
      "Epoch 4684, Loss: 0.05338402860797942, Final Batch Loss: 0.005432087928056717\n",
      "Epoch 4685, Loss: 0.06651188340038061, Final Batch Loss: 0.005556800402700901\n",
      "Epoch 4686, Loss: 0.04665536608081311, Final Batch Loss: 0.001278641982935369\n",
      "Epoch 4687, Loss: 0.05548800260294229, Final Batch Loss: 0.0013245678273960948\n",
      "Epoch 4688, Loss: 0.05522551108151674, Final Batch Loss: 0.009268064051866531\n",
      "Epoch 4689, Loss: 0.06563413795083761, Final Batch Loss: 0.03169611096382141\n",
      "Epoch 4690, Loss: 0.026703740935772657, Final Batch Loss: 0.0041829803958535194\n",
      "Epoch 4691, Loss: 0.11341966409236193, Final Batch Loss: 0.01124205719679594\n",
      "Epoch 4692, Loss: 0.06068325508385897, Final Batch Loss: 0.026287734508514404\n",
      "Epoch 4693, Loss: 0.18453114107251167, Final Batch Loss: 0.13373585045337677\n",
      "Epoch 4694, Loss: 0.10120329610072076, Final Batch Loss: 0.017141954973340034\n",
      "Epoch 4695, Loss: 0.0634416148532182, Final Batch Loss: 0.005890828091651201\n",
      "Epoch 4696, Loss: 0.1316829426214099, Final Batch Loss: 0.04340255260467529\n",
      "Epoch 4697, Loss: 0.10554623790085316, Final Batch Loss: 0.00860472209751606\n",
      "Epoch 4698, Loss: 0.07801496563479304, Final Batch Loss: 0.0054151942022144794\n",
      "Epoch 4699, Loss: 0.07346720062196255, Final Batch Loss: 0.017661644145846367\n",
      "Epoch 4700, Loss: 0.11281136702746153, Final Batch Loss: 0.016212372109293938\n",
      "Epoch 4701, Loss: 0.11224774830043316, Final Batch Loss: 0.03922438248991966\n",
      "Epoch 4702, Loss: 0.05182009935379028, Final Batch Loss: 0.003241383470594883\n",
      "Epoch 4703, Loss: 0.0659121097996831, Final Batch Loss: 0.010233107954263687\n",
      "Epoch 4704, Loss: 0.13491613324731588, Final Batch Loss: 0.05764000862836838\n",
      "Epoch 4705, Loss: 0.07902263617143035, Final Batch Loss: 0.004223926458507776\n",
      "Epoch 4706, Loss: 0.04118839977309108, Final Batch Loss: 0.008154883049428463\n",
      "Epoch 4707, Loss: 0.04106613842304796, Final Batch Loss: 0.0012856688117608428\n",
      "Epoch 4708, Loss: 0.13165431981906295, Final Batch Loss: 0.08036796748638153\n",
      "Epoch 4709, Loss: 0.01752783771371469, Final Batch Loss: 0.0005757407634519041\n",
      "Epoch 4710, Loss: 0.10247879754751921, Final Batch Loss: 0.019070826470851898\n",
      "Epoch 4711, Loss: 0.054542399710044265, Final Batch Loss: 0.009396580047905445\n",
      "Epoch 4712, Loss: 0.13717258581891656, Final Batch Loss: 0.023840345442295074\n",
      "Epoch 4713, Loss: 0.012490159715525806, Final Batch Loss: 0.001837983843870461\n",
      "Epoch 4714, Loss: 0.06256952369585633, Final Batch Loss: 0.0026654419489204884\n",
      "Epoch 4715, Loss: 0.026303480146452785, Final Batch Loss: 0.0013166049029678106\n",
      "Epoch 4716, Loss: 0.04206844372674823, Final Batch Loss: 0.016519075259566307\n",
      "Epoch 4717, Loss: 0.044765603728592396, Final Batch Loss: 0.006307119969278574\n",
      "Epoch 4718, Loss: 0.044014500454068184, Final Batch Loss: 0.003786134533584118\n",
      "Epoch 4719, Loss: 0.0237172890920192, Final Batch Loss: 0.0027973789256066084\n",
      "Epoch 4720, Loss: 0.04580996325239539, Final Batch Loss: 0.0011093211360275745\n",
      "Epoch 4721, Loss: 0.08822441380470991, Final Batch Loss: 0.026430321857333183\n",
      "Epoch 4722, Loss: 0.023027253308100626, Final Batch Loss: 0.00037634672480635345\n",
      "Epoch 4723, Loss: 0.028668171260505915, Final Batch Loss: 0.0058711799792945385\n",
      "Epoch 4724, Loss: 0.0438760940451175, Final Batch Loss: 0.0013300725258886814\n",
      "Epoch 4725, Loss: 0.03767624218016863, Final Batch Loss: 0.010411250405013561\n",
      "Epoch 4726, Loss: 0.024220813997089863, Final Batch Loss: 0.0067517017014324665\n",
      "Epoch 4727, Loss: 0.08127356832846999, Final Batch Loss: 0.011736285872757435\n",
      "Epoch 4728, Loss: 0.0782146105193533, Final Batch Loss: 0.06631253659725189\n",
      "Epoch 4729, Loss: 0.09370851889252663, Final Batch Loss: 0.0017706602811813354\n",
      "Epoch 4730, Loss: 0.106898422120139, Final Batch Loss: 0.0038196982350200415\n",
      "Epoch 4731, Loss: 0.09210561134386808, Final Batch Loss: 0.04069077968597412\n",
      "Epoch 4732, Loss: 0.08656613156199455, Final Batch Loss: 0.01655118353664875\n",
      "Epoch 4733, Loss: 0.04883132118266076, Final Batch Loss: 0.0017668287036940455\n",
      "Epoch 4734, Loss: 0.09166455175727606, Final Batch Loss: 0.040097951889038086\n",
      "Epoch 4735, Loss: 0.04052730929106474, Final Batch Loss: 0.0012503627222031355\n",
      "Epoch 4736, Loss: 0.026843036990612745, Final Batch Loss: 0.005936094559729099\n",
      "Epoch 4737, Loss: 0.01598072052001953, Final Batch Loss: 0.001335042412392795\n",
      "Epoch 4738, Loss: 0.0872773549053818, Final Batch Loss: 0.0021481546573340893\n",
      "Epoch 4739, Loss: 0.05851412191987038, Final Batch Loss: 0.00824494007974863\n",
      "Epoch 4740, Loss: 0.07991074630990624, Final Batch Loss: 0.02156118117272854\n",
      "Epoch 4741, Loss: 0.022722583496943116, Final Batch Loss: 0.0019012547563761473\n",
      "Epoch 4742, Loss: 0.027988295420072973, Final Batch Loss: 0.0014022741233929992\n",
      "Epoch 4743, Loss: 0.03872774017509073, Final Batch Loss: 0.006350345443934202\n",
      "Epoch 4744, Loss: 0.05754427588544786, Final Batch Loss: 0.0204123817384243\n",
      "Epoch 4745, Loss: 0.030054782051593065, Final Batch Loss: 0.005347443278878927\n",
      "Epoch 4746, Loss: 0.012764125945977867, Final Batch Loss: 0.0010938997147604823\n",
      "Epoch 4747, Loss: 0.06097367638722062, Final Batch Loss: 0.03493639826774597\n",
      "Epoch 4748, Loss: 0.0418583037389908, Final Batch Loss: 0.0003049638180527836\n",
      "Epoch 4749, Loss: 0.07886652275919914, Final Batch Loss: 0.0024834172800183296\n",
      "Epoch 4750, Loss: 0.01813084770401474, Final Batch Loss: 0.0002248887758469209\n",
      "Epoch 4751, Loss: 0.024178643012419343, Final Batch Loss: 0.001797642558813095\n",
      "Epoch 4752, Loss: 0.037976965890266, Final Batch Loss: 0.000792198465205729\n",
      "Epoch 4753, Loss: 0.012655247352086008, Final Batch Loss: 0.005531261209398508\n",
      "Epoch 4754, Loss: 0.03724142676219344, Final Batch Loss: 0.0038450739812105894\n",
      "Epoch 4755, Loss: 0.021534544473979622, Final Batch Loss: 0.000687856983859092\n",
      "Epoch 4756, Loss: 0.07004054775461555, Final Batch Loss: 0.0024065938778221607\n",
      "Epoch 4757, Loss: 0.01600305293686688, Final Batch Loss: 0.0027330806478857994\n",
      "Epoch 4758, Loss: 0.024049172876402736, Final Batch Loss: 0.0015311832539737225\n",
      "Epoch 4759, Loss: 0.01879795314744115, Final Batch Loss: 0.00030626682564616203\n",
      "Epoch 4760, Loss: 0.10718301794258878, Final Batch Loss: 0.0002978869597427547\n",
      "Epoch 4761, Loss: 0.03382745897397399, Final Batch Loss: 0.011145440861582756\n",
      "Epoch 4762, Loss: 0.023307484108954668, Final Batch Loss: 0.003883883822709322\n",
      "Epoch 4763, Loss: 0.045317443524254486, Final Batch Loss: 0.00018329863087274134\n",
      "Epoch 4764, Loss: 0.059615980833768845, Final Batch Loss: 0.029691850766539574\n",
      "Epoch 4765, Loss: 0.01446542702615261, Final Batch Loss: 0.00598275288939476\n",
      "Epoch 4766, Loss: 0.008626070572063327, Final Batch Loss: 0.0013960901414975524\n",
      "Epoch 4767, Loss: 0.01700730435550213, Final Batch Loss: 0.002229168312624097\n",
      "Epoch 4768, Loss: 0.021523939620237797, Final Batch Loss: 0.006112728733569384\n",
      "Epoch 4769, Loss: 0.02329458948224783, Final Batch Loss: 0.0006602189969271421\n",
      "Epoch 4770, Loss: 0.03777940117288381, Final Batch Loss: 0.01925656758248806\n",
      "Epoch 4771, Loss: 0.015449122263817117, Final Batch Loss: 0.0003815416421275586\n",
      "Epoch 4772, Loss: 0.018737622653134167, Final Batch Loss: 0.0017888935981318355\n",
      "Epoch 4773, Loss: 0.045255518751218915, Final Batch Loss: 0.0016165771521627903\n",
      "Epoch 4774, Loss: 0.025455073919147253, Final Batch Loss: 0.002725776517763734\n",
      "Epoch 4775, Loss: 0.024555219861213118, Final Batch Loss: 0.0008959225961007178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4776, Loss: 0.00534692732617259, Final Batch Loss: 0.0006870743818581104\n",
      "Epoch 4777, Loss: 0.020268747117370367, Final Batch Loss: 0.0021871908102184534\n",
      "Epoch 4778, Loss: 0.026636996772140265, Final Batch Loss: 0.005823897197842598\n",
      "Epoch 4779, Loss: 0.020139095606282353, Final Batch Loss: 0.0010437509045004845\n",
      "Epoch 4780, Loss: 0.014866891782730818, Final Batch Loss: 0.0026409272104501724\n",
      "Epoch 4781, Loss: 0.1480114315636456, Final Batch Loss: 0.10737787187099457\n",
      "Epoch 4782, Loss: 0.03164096787804738, Final Batch Loss: 0.0006720349774695933\n",
      "Epoch 4783, Loss: 0.03465411765500903, Final Batch Loss: 0.006682953331619501\n",
      "Epoch 4784, Loss: 0.03511323011480272, Final Batch Loss: 0.003496040590107441\n",
      "Epoch 4785, Loss: 0.05093677155673504, Final Batch Loss: 0.031245239078998566\n",
      "Epoch 4786, Loss: 0.036731287371367216, Final Batch Loss: 0.01850176975131035\n",
      "Epoch 4787, Loss: 0.08339837053790689, Final Batch Loss: 0.0010506580583751202\n",
      "Epoch 4788, Loss: 0.04879096883814782, Final Batch Loss: 0.002030739327892661\n",
      "Epoch 4789, Loss: 0.06928601814433932, Final Batch Loss: 0.0024742628447711468\n",
      "Epoch 4790, Loss: 0.0474586714990437, Final Batch Loss: 0.0006866287440061569\n",
      "Epoch 4791, Loss: 0.0820000336971134, Final Batch Loss: 0.0038945942651480436\n",
      "Epoch 4792, Loss: 0.031201455043628812, Final Batch Loss: 0.0014527493622153997\n",
      "Epoch 4793, Loss: 0.03969102742848918, Final Batch Loss: 0.0006543078343383968\n",
      "Epoch 4794, Loss: 0.020444323075935245, Final Batch Loss: 0.00211104447953403\n",
      "Epoch 4795, Loss: 0.030516694416292012, Final Batch Loss: 0.010117915458977222\n",
      "Epoch 4796, Loss: 0.056172289536334574, Final Batch Loss: 0.001520840567536652\n",
      "Epoch 4797, Loss: 0.016474879579618573, Final Batch Loss: 0.0019701989367604256\n",
      "Epoch 4798, Loss: 0.010522800963371992, Final Batch Loss: 0.0019571890588849783\n",
      "Epoch 4799, Loss: 0.03349572280421853, Final Batch Loss: 0.0016224556602537632\n",
      "Epoch 4800, Loss: 0.05656079249456525, Final Batch Loss: 0.006888647098094225\n",
      "Epoch 4801, Loss: 0.028758254135027528, Final Batch Loss: 0.0013940382050350308\n",
      "Epoch 4802, Loss: 0.09203245071694255, Final Batch Loss: 0.04416300728917122\n",
      "Epoch 4803, Loss: 0.1569742764113471, Final Batch Loss: 0.13760532438755035\n",
      "Epoch 4804, Loss: 0.31965329870581627, Final Batch Loss: 0.15977071225643158\n",
      "Epoch 4805, Loss: 0.08445253781974316, Final Batch Loss: 0.004800228402018547\n",
      "Epoch 4806, Loss: 0.03591496031731367, Final Batch Loss: 0.017521722242236137\n",
      "Epoch 4807, Loss: 0.03934411227237433, Final Batch Loss: 0.0011103347642347217\n",
      "Epoch 4808, Loss: 0.024719941429793835, Final Batch Loss: 0.0011142806615680456\n",
      "Epoch 4809, Loss: 0.0344988756114617, Final Batch Loss: 0.001377393607981503\n",
      "Epoch 4810, Loss: 0.06094032060354948, Final Batch Loss: 0.033711764961481094\n",
      "Epoch 4811, Loss: 0.014672104734927416, Final Batch Loss: 0.002245945855975151\n",
      "Epoch 4812, Loss: 0.034754570573568344, Final Batch Loss: 0.014882332645356655\n",
      "Epoch 4813, Loss: 0.04855497530661523, Final Batch Loss: 0.015023327432572842\n",
      "Epoch 4814, Loss: 0.03547594993142411, Final Batch Loss: 0.0008122139261104167\n",
      "Epoch 4815, Loss: 0.03259280091151595, Final Batch Loss: 0.009428855031728745\n",
      "Epoch 4816, Loss: 0.028672635089606047, Final Batch Loss: 0.003191492985934019\n",
      "Epoch 4817, Loss: 0.029552454478107393, Final Batch Loss: 0.0029123772401362658\n",
      "Epoch 4818, Loss: 0.010608651442453265, Final Batch Loss: 0.0011680402094498277\n",
      "Epoch 4819, Loss: 0.14727085502818227, Final Batch Loss: 0.11027920991182327\n",
      "Epoch 4820, Loss: 0.03994900197722018, Final Batch Loss: 0.001882732380181551\n",
      "Epoch 4821, Loss: 0.025992097798734903, Final Batch Loss: 0.015985429286956787\n",
      "Epoch 4822, Loss: 0.009620747703593224, Final Batch Loss: 0.001517725526355207\n",
      "Epoch 4823, Loss: 0.07120272400788963, Final Batch Loss: 0.01076149195432663\n",
      "Epoch 4824, Loss: 0.0386712234467268, Final Batch Loss: 0.003967316821217537\n",
      "Epoch 4825, Loss: 0.03847164416220039, Final Batch Loss: 0.001785602536983788\n",
      "Epoch 4826, Loss: 0.08084142813459039, Final Batch Loss: 0.004496412817388773\n",
      "Epoch 4827, Loss: 0.04573900904506445, Final Batch Loss: 0.005284624639898539\n",
      "Epoch 4828, Loss: 0.03129571536555886, Final Batch Loss: 0.001273877453058958\n",
      "Epoch 4829, Loss: 0.01784174412023276, Final Batch Loss: 0.003150082193315029\n",
      "Epoch 4830, Loss: 0.04311946907546371, Final Batch Loss: 0.016177179291844368\n",
      "Epoch 4831, Loss: 0.014008923317305744, Final Batch Loss: 0.005722161382436752\n",
      "Epoch 4832, Loss: 0.07020492781884968, Final Batch Loss: 0.03681359067559242\n",
      "Epoch 4833, Loss: 0.0490703716641292, Final Batch Loss: 0.007889139465987682\n",
      "Epoch 4834, Loss: 0.14910264313220978, Final Batch Loss: 0.032630983740091324\n",
      "Epoch 4835, Loss: 0.07841420266777277, Final Batch Loss: 0.05982576683163643\n",
      "Epoch 4836, Loss: 0.07918905140832067, Final Batch Loss: 0.03898300603032112\n",
      "Epoch 4837, Loss: 0.052137646824121475, Final Batch Loss: 0.004189644008874893\n",
      "Epoch 4838, Loss: 0.19027378037571907, Final Batch Loss: 0.007904166355729103\n",
      "Epoch 4839, Loss: 0.14091382268816233, Final Batch Loss: 0.07414574921131134\n",
      "Epoch 4840, Loss: 0.10642855614423752, Final Batch Loss: 0.039385709911584854\n",
      "Epoch 4841, Loss: 0.07466629147529602, Final Batch Loss: 0.014651014469563961\n",
      "Epoch 4842, Loss: 0.04794488986954093, Final Batch Loss: 0.003985521383583546\n",
      "Epoch 4843, Loss: 0.12360006989911199, Final Batch Loss: 0.006421030033379793\n",
      "Epoch 4844, Loss: 0.095698656514287, Final Batch Loss: 0.005250089801847935\n",
      "Epoch 4845, Loss: 0.1206058794632554, Final Batch Loss: 0.05924024060368538\n",
      "Epoch 4846, Loss: 0.09958360623568296, Final Batch Loss: 0.008707704953849316\n",
      "Epoch 4847, Loss: 0.07362323836423457, Final Batch Loss: 0.0026377623435109854\n",
      "Epoch 4848, Loss: 0.1326815551146865, Final Batch Loss: 0.02655690349638462\n",
      "Epoch 4849, Loss: 0.16965303756296635, Final Batch Loss: 0.026655254885554314\n",
      "Epoch 4850, Loss: 0.08612121595069766, Final Batch Loss: 0.0204754788428545\n",
      "Epoch 4851, Loss: 0.0287148579955101, Final Batch Loss: 0.008398530073463917\n",
      "Epoch 4852, Loss: 0.07692854851484299, Final Batch Loss: 0.02301562763750553\n",
      "Epoch 4853, Loss: 0.05941554857417941, Final Batch Loss: 0.004920263309031725\n",
      "Epoch 4854, Loss: 0.12270515225827694, Final Batch Loss: 0.1082211285829544\n",
      "Epoch 4855, Loss: 0.09285182598978281, Final Batch Loss: 0.040931813418865204\n",
      "Epoch 4856, Loss: 0.1043303469195962, Final Batch Loss: 0.030477311462163925\n",
      "Epoch 4857, Loss: 0.09000776149332523, Final Batch Loss: 0.004978577606379986\n",
      "Epoch 4858, Loss: 0.06472519016824663, Final Batch Loss: 0.01502821035683155\n",
      "Epoch 4859, Loss: 0.06218641437590122, Final Batch Loss: 0.020102959126234055\n",
      "Epoch 4860, Loss: 0.15591722540557384, Final Batch Loss: 0.06878209114074707\n",
      "Epoch 4861, Loss: 0.031097952276468277, Final Batch Loss: 0.004967496730387211\n",
      "Epoch 4862, Loss: 0.10822416422888637, Final Batch Loss: 0.03276250511407852\n",
      "Epoch 4863, Loss: 0.06696018448565155, Final Batch Loss: 0.0009784117573872209\n",
      "Epoch 4864, Loss: 0.07861756952479482, Final Batch Loss: 0.007374410983175039\n",
      "Epoch 4865, Loss: 0.08061125036329031, Final Batch Loss: 0.02201273664832115\n",
      "Epoch 4866, Loss: 0.23843849869444966, Final Batch Loss: 0.16582699120044708\n",
      "Epoch 4867, Loss: 0.044105623383075, Final Batch Loss: 0.004533706232905388\n",
      "Epoch 4868, Loss: 0.07302827900275588, Final Batch Loss: 0.005359166767448187\n",
      "Epoch 4869, Loss: 0.10530632478184998, Final Batch Loss: 0.08228149265050888\n",
      "Epoch 4870, Loss: 0.07620814861729741, Final Batch Loss: 0.02113109640777111\n",
      "Epoch 4871, Loss: 0.0444112136028707, Final Batch Loss: 0.0027022897265851498\n",
      "Epoch 4872, Loss: 0.024392395513132215, Final Batch Loss: 0.00169136724434793\n",
      "Epoch 4873, Loss: 0.06878765171859413, Final Batch Loss: 0.001318535883910954\n",
      "Epoch 4874, Loss: 0.05006888974457979, Final Batch Loss: 0.024479925632476807\n",
      "Epoch 4875, Loss: 0.013505155686289072, Final Batch Loss: 0.002412476111203432\n",
      "Epoch 4876, Loss: 0.051561109721660614, Final Batch Loss: 0.010738752782344818\n",
      "Epoch 4877, Loss: 0.06607500743120909, Final Batch Loss: 0.0269961878657341\n",
      "Epoch 4878, Loss: 0.015351273352280259, Final Batch Loss: 0.003840995952486992\n",
      "Epoch 4879, Loss: 0.048101216671057045, Final Batch Loss: 0.001677407301031053\n",
      "Epoch 4880, Loss: 0.0252249768236652, Final Batch Loss: 0.001966870855540037\n",
      "Epoch 4881, Loss: 0.03210086515173316, Final Batch Loss: 0.003732806770130992\n",
      "Epoch 4882, Loss: 0.01438960526138544, Final Batch Loss: 0.004632424563169479\n",
      "Epoch 4883, Loss: 0.08710828982293606, Final Batch Loss: 0.06130189821124077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4884, Loss: 0.012238822411745787, Final Batch Loss: 0.0024487043265253305\n",
      "Epoch 4885, Loss: 0.027124167187139392, Final Batch Loss: 0.005361642688512802\n",
      "Epoch 4886, Loss: 0.03001379780471325, Final Batch Loss: 0.00479609239846468\n",
      "Epoch 4887, Loss: 0.0749621749855578, Final Batch Loss: 0.006589180789887905\n",
      "Epoch 4888, Loss: 0.041374200460268185, Final Batch Loss: 0.0002892659686040133\n",
      "Epoch 4889, Loss: 0.016388771357014775, Final Batch Loss: 0.0023451384622603655\n",
      "Epoch 4890, Loss: 0.03204533481039107, Final Batch Loss: 0.0081116808578372\n",
      "Epoch 4891, Loss: 0.012885102303698659, Final Batch Loss: 0.0020730337128043175\n",
      "Epoch 4892, Loss: 0.01869446935597807, Final Batch Loss: 0.0011666862992569804\n",
      "Epoch 4893, Loss: 0.014730311231687665, Final Batch Loss: 0.004527305252850056\n",
      "Epoch 4894, Loss: 0.0105917610344477, Final Batch Loss: 0.000851703283842653\n",
      "Epoch 4895, Loss: 0.03396634210366756, Final Batch Loss: 0.0019281505374237895\n",
      "Epoch 4896, Loss: 0.01653329440159723, Final Batch Loss: 0.0034655870404094458\n",
      "Epoch 4897, Loss: 0.015942243859171867, Final Batch Loss: 0.005513922311365604\n",
      "Epoch 4898, Loss: 0.016695400525350124, Final Batch Loss: 0.0009549449314363301\n",
      "Epoch 4899, Loss: 0.03725167619995773, Final Batch Loss: 0.0007246548775583506\n",
      "Epoch 4900, Loss: 0.19444813928566873, Final Batch Loss: 0.17632237076759338\n",
      "Epoch 4901, Loss: 0.03517611382994801, Final Batch Loss: 0.0033092370722442865\n",
      "Epoch 4902, Loss: 0.111159507650882, Final Batch Loss: 0.004227838013321161\n",
      "Epoch 4903, Loss: 0.06639282801188529, Final Batch Loss: 0.0035484947729855776\n",
      "Epoch 4904, Loss: 0.07313952886033803, Final Batch Loss: 0.0011773157166317105\n",
      "Epoch 4905, Loss: 0.042334756813943386, Final Batch Loss: 0.003893168643116951\n",
      "Epoch 4906, Loss: 0.06409736163914204, Final Batch Loss: 0.02233298309147358\n",
      "Epoch 4907, Loss: 0.031363952439278364, Final Batch Loss: 0.002295100362971425\n",
      "Epoch 4908, Loss: 0.02733490732498467, Final Batch Loss: 0.00718175433576107\n",
      "Epoch 4909, Loss: 0.033516999799758196, Final Batch Loss: 0.0019015682628378272\n",
      "Epoch 4910, Loss: 0.03355041379109025, Final Batch Loss: 0.006632631178945303\n",
      "Epoch 4911, Loss: 0.033666508679743856, Final Batch Loss: 0.0007582445978187025\n",
      "Epoch 4912, Loss: 0.06884121499024332, Final Batch Loss: 0.021120846271514893\n",
      "Epoch 4913, Loss: 0.017460632021538913, Final Batch Loss: 0.0006814437219873071\n",
      "Epoch 4914, Loss: 0.03587112738750875, Final Batch Loss: 0.013317994773387909\n",
      "Epoch 4915, Loss: 0.03998733009211719, Final Batch Loss: 0.0035193825606256723\n",
      "Epoch 4916, Loss: 0.028936385177075863, Final Batch Loss: 0.0054979631677269936\n",
      "Epoch 4917, Loss: 0.0741297664353624, Final Batch Loss: 0.05384879186749458\n",
      "Epoch 4918, Loss: 0.02410938951652497, Final Batch Loss: 0.001651386613957584\n",
      "Epoch 4919, Loss: 0.1283398810774088, Final Batch Loss: 0.059112101793289185\n",
      "Epoch 4920, Loss: 0.032191749196499586, Final Batch Loss: 0.017657987773418427\n",
      "Epoch 4921, Loss: 0.051497536012902856, Final Batch Loss: 0.0257625263184309\n",
      "Epoch 4922, Loss: 0.04108832706697285, Final Batch Loss: 0.0025511684361845255\n",
      "Epoch 4923, Loss: 0.09138487419113517, Final Batch Loss: 0.043785471469163895\n",
      "Epoch 4924, Loss: 0.026837897836230695, Final Batch Loss: 0.015286942012608051\n",
      "Epoch 4925, Loss: 0.020717780105769634, Final Batch Loss: 0.004787578247487545\n",
      "Epoch 4926, Loss: 0.033407527254894376, Final Batch Loss: 0.003069274127483368\n",
      "Epoch 4927, Loss: 0.011461641057394445, Final Batch Loss: 0.002664836822077632\n",
      "Epoch 4928, Loss: 0.05347998789511621, Final Batch Loss: 0.005918421782553196\n",
      "Epoch 4929, Loss: 0.01513437886023894, Final Batch Loss: 0.0006932138348929584\n",
      "Epoch 4930, Loss: 0.022345995879732072, Final Batch Loss: 0.0006450419314205647\n",
      "Epoch 4931, Loss: 0.01926922262646258, Final Batch Loss: 0.002548485528677702\n",
      "Epoch 4932, Loss: 0.01213484606705606, Final Batch Loss: 0.002873564139008522\n",
      "Epoch 4933, Loss: 0.036437376867979765, Final Batch Loss: 0.0022981027141213417\n",
      "Epoch 4934, Loss: 0.030087469203863293, Final Batch Loss: 0.0005730591365136206\n",
      "Epoch 4935, Loss: 0.05840848933439702, Final Batch Loss: 0.0013638240052387118\n",
      "Epoch 4936, Loss: 0.01904164662119001, Final Batch Loss: 0.00966606754809618\n",
      "Epoch 4937, Loss: 0.0271093383198604, Final Batch Loss: 0.018538951873779297\n",
      "Epoch 4938, Loss: 0.0097093217773363, Final Batch Loss: 0.0016864106291905046\n",
      "Epoch 4939, Loss: 0.019244569004513323, Final Batch Loss: 0.0012436705874279141\n",
      "Epoch 4940, Loss: 0.027005510608432814, Final Batch Loss: 0.00036998579162172973\n",
      "Epoch 4941, Loss: 0.02099137904588133, Final Batch Loss: 0.0017991858767345548\n",
      "Epoch 4942, Loss: 0.03924656129674986, Final Batch Loss: 0.0005041431286372244\n",
      "Epoch 4943, Loss: 0.03166767954826355, Final Batch Loss: 0.0023104052525013685\n",
      "Epoch 4944, Loss: 0.04623571672709659, Final Batch Loss: 0.0005167716299183667\n",
      "Epoch 4945, Loss: 0.057977113872766495, Final Batch Loss: 0.04471692815423012\n",
      "Epoch 4946, Loss: 0.0318848293973133, Final Batch Loss: 0.0040016742423176765\n",
      "Epoch 4947, Loss: 0.0450110380188562, Final Batch Loss: 0.0008567595505155623\n",
      "Epoch 4948, Loss: 0.04621301591396332, Final Batch Loss: 0.008004293777048588\n",
      "Epoch 4949, Loss: 0.05091352108865976, Final Batch Loss: 0.011797131039202213\n",
      "Epoch 4950, Loss: 0.08952716644853354, Final Batch Loss: 0.019658060744404793\n",
      "Epoch 4951, Loss: 0.016923765186220407, Final Batch Loss: 0.004427503328770399\n",
      "Epoch 4952, Loss: 0.02578022237867117, Final Batch Loss: 0.0013527553528547287\n",
      "Epoch 4953, Loss: 0.025603754329495132, Final Batch Loss: 0.0015569207025691867\n",
      "Epoch 4954, Loss: 0.04187894915230572, Final Batch Loss: 0.01821179874241352\n",
      "Epoch 4955, Loss: 0.06483497523004189, Final Batch Loss: 0.0009155539446510375\n",
      "Epoch 4956, Loss: 0.01777359109837562, Final Batch Loss: 0.0006887760246172547\n",
      "Epoch 4957, Loss: 0.043836359633132815, Final Batch Loss: 0.0012959653977304697\n",
      "Epoch 4958, Loss: 0.04174412600696087, Final Batch Loss: 0.0023973272182047367\n",
      "Epoch 4959, Loss: 0.01628146080474835, Final Batch Loss: 0.00015411734057124704\n",
      "Epoch 4960, Loss: 0.061121093458496034, Final Batch Loss: 0.04446239396929741\n",
      "Epoch 4961, Loss: 0.06384056829847395, Final Batch Loss: 0.05206409469246864\n",
      "Epoch 4962, Loss: 0.016407173709012568, Final Batch Loss: 0.003620527219027281\n",
      "Epoch 4963, Loss: 0.022033967659808695, Final Batch Loss: 0.0019048815593123436\n",
      "Epoch 4964, Loss: 0.10638484288938344, Final Batch Loss: 0.044424671679735184\n",
      "Epoch 4965, Loss: 0.05403023539111018, Final Batch Loss: 0.006269671954214573\n",
      "Epoch 4966, Loss: 0.021466607111506164, Final Batch Loss: 0.0009797575185075402\n",
      "Epoch 4967, Loss: 0.08957701397594064, Final Batch Loss: 0.0019429101375862956\n",
      "Epoch 4968, Loss: 0.06351749459281564, Final Batch Loss: 0.006629681680351496\n",
      "Epoch 4969, Loss: 0.04890642035752535, Final Batch Loss: 0.0018871077336370945\n",
      "Epoch 4970, Loss: 0.01747222151607275, Final Batch Loss: 0.002456208923831582\n",
      "Epoch 4971, Loss: 0.021910500014200807, Final Batch Loss: 0.0017126703169196844\n",
      "Epoch 4972, Loss: 0.0416685095988214, Final Batch Loss: 0.008063063956797123\n",
      "Epoch 4973, Loss: 0.07305849943077192, Final Batch Loss: 0.0007504256791435182\n",
      "Epoch 4974, Loss: 0.014702879823744297, Final Batch Loss: 0.0017716663423925638\n",
      "Epoch 4975, Loss: 0.025381835643202066, Final Batch Loss: 0.0013395436108112335\n",
      "Epoch 4976, Loss: 0.02279722865205258, Final Batch Loss: 0.0027029169723391533\n",
      "Epoch 4977, Loss: 0.029989376082085073, Final Batch Loss: 0.0012864425079897046\n",
      "Epoch 4978, Loss: 0.006736841052770615, Final Batch Loss: 0.00027850468177348375\n",
      "Epoch 4979, Loss: 0.06861912133172154, Final Batch Loss: 0.015966538339853287\n",
      "Epoch 4980, Loss: 0.03530182328540832, Final Batch Loss: 0.0018198156030848622\n",
      "Epoch 4981, Loss: 0.029691006988286972, Final Batch Loss: 0.0038930545561015606\n",
      "Epoch 4982, Loss: 0.02003597770817578, Final Batch Loss: 0.0012880119029432535\n",
      "Epoch 4983, Loss: 0.019547334406524897, Final Batch Loss: 0.006378855090588331\n",
      "Epoch 4984, Loss: 0.03343540383502841, Final Batch Loss: 0.0024979333393275738\n",
      "Epoch 4985, Loss: 0.04042958631180227, Final Batch Loss: 0.00483083026483655\n",
      "Epoch 4986, Loss: 0.015409142259159125, Final Batch Loss: 0.0001382231857860461\n",
      "Epoch 4987, Loss: 0.0033863247372210026, Final Batch Loss: 0.0008199660223908722\n",
      "Epoch 4988, Loss: 0.017323268577456474, Final Batch Loss: 0.011063898913562298\n",
      "Epoch 4989, Loss: 0.005000781267881393, Final Batch Loss: 0.0013162816176190972\n",
      "Epoch 4990, Loss: 0.013536309794289991, Final Batch Loss: 0.001432422548532486\n",
      "Epoch 4991, Loss: 0.010052926023490727, Final Batch Loss: 0.0015479852445423603\n",
      "Epoch 4992, Loss: 0.044015314313583076, Final Batch Loss: 0.003681080648675561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4993, Loss: 0.017013260629028082, Final Batch Loss: 0.0033168105874210596\n",
      "Epoch 4994, Loss: 0.013869815273210406, Final Batch Loss: 0.0032972211483865976\n",
      "Epoch 4995, Loss: 0.007659507216885686, Final Batch Loss: 0.0008949673501774669\n",
      "Epoch 4996, Loss: 0.006862071983050555, Final Batch Loss: 0.0009170525590889156\n",
      "Epoch 4997, Loss: 0.023491122061386704, Final Batch Loss: 0.0010062489891424775\n",
      "Epoch 4998, Loss: 0.006795394234359264, Final Batch Loss: 0.002530372468754649\n",
      "Epoch 4999, Loss: 0.039398421766236424, Final Batch Loss: 0.0022380922455340624\n",
      "Epoch 5000, Loss: 0.014535210619214922, Final Batch Loss: 0.0005553144146688282\n",
      "Epoch 5001, Loss: 0.013260040897876024, Final Batch Loss: 0.0007498848717659712\n",
      "Epoch 5002, Loss: 0.007132918864954263, Final Batch Loss: 0.0005102879367768764\n",
      "Epoch 5003, Loss: 0.013747557939495891, Final Batch Loss: 0.0009434650419279933\n",
      "Epoch 5004, Loss: 0.01019820146029815, Final Batch Loss: 0.002179604023694992\n",
      "Epoch 5005, Loss: 0.06295610929373652, Final Batch Loss: 0.054205406457185745\n",
      "Epoch 5006, Loss: 0.04173564648954198, Final Batch Loss: 0.035620756447315216\n",
      "Epoch 5007, Loss: 0.06975606584455818, Final Batch Loss: 0.03313680365681648\n",
      "Epoch 5008, Loss: 0.16530624497681856, Final Batch Loss: 0.008590367622673512\n",
      "Epoch 5009, Loss: 0.12917926348745823, Final Batch Loss: 0.03700760751962662\n",
      "Epoch 5010, Loss: 0.08503512805327773, Final Batch Loss: 0.05984753742814064\n",
      "Epoch 5011, Loss: 0.07319495570845902, Final Batch Loss: 0.0036637696903198957\n",
      "Epoch 5012, Loss: 0.04672382678836584, Final Batch Loss: 0.002219256479293108\n",
      "Epoch 5013, Loss: 0.024565132334828377, Final Batch Loss: 0.002921764273196459\n",
      "Epoch 5014, Loss: 0.05618730140849948, Final Batch Loss: 0.0065974765457212925\n",
      "Epoch 5015, Loss: 0.0752289304509759, Final Batch Loss: 0.0024552103132009506\n",
      "Epoch 5016, Loss: 0.06074681400787085, Final Batch Loss: 0.04364588111639023\n",
      "Epoch 5017, Loss: 0.04519700992386788, Final Batch Loss: 0.001030299230478704\n",
      "Epoch 5018, Loss: 0.05768807837739587, Final Batch Loss: 0.023375019431114197\n",
      "Epoch 5019, Loss: 0.07233527535572648, Final Batch Loss: 0.0027103666216135025\n",
      "Epoch 5020, Loss: 0.09161687875166535, Final Batch Loss: 0.04019901156425476\n",
      "Epoch 5021, Loss: 0.026914149755612016, Final Batch Loss: 0.0060242656618356705\n",
      "Epoch 5022, Loss: 0.10692469496279955, Final Batch Loss: 0.03558511659502983\n",
      "Epoch 5023, Loss: 0.04234521230682731, Final Batch Loss: 0.0032926895655691624\n",
      "Epoch 5024, Loss: 0.0985111827030778, Final Batch Loss: 0.05532693862915039\n",
      "Epoch 5025, Loss: 0.09509629802778363, Final Batch Loss: 0.06106150895357132\n",
      "Epoch 5026, Loss: 0.173161119222641, Final Batch Loss: 0.0367722362279892\n",
      "Epoch 5027, Loss: 0.1073369849473238, Final Batch Loss: 0.06983760744333267\n",
      "Epoch 5028, Loss: 0.05485774856060743, Final Batch Loss: 0.01598581299185753\n",
      "Epoch 5029, Loss: 0.07537156250327826, Final Batch Loss: 0.020213989540934563\n",
      "Epoch 5030, Loss: 0.10651145689189434, Final Batch Loss: 0.057854123413562775\n",
      "Epoch 5031, Loss: 0.06274380767717957, Final Batch Loss: 0.013811741955578327\n",
      "Epoch 5032, Loss: 0.14677786827087402, Final Batch Loss: 0.09306201338768005\n",
      "Epoch 5033, Loss: 0.04701301408931613, Final Batch Loss: 0.0032983380369842052\n",
      "Epoch 5034, Loss: 0.11030953470617533, Final Batch Loss: 0.012384920381009579\n",
      "Epoch 5035, Loss: 0.10723133245483041, Final Batch Loss: 0.0068807476200163364\n",
      "Epoch 5036, Loss: 0.06629378674551845, Final Batch Loss: 0.02252223901450634\n",
      "Epoch 5037, Loss: 0.09253110084682703, Final Batch Loss: 0.014035135507583618\n",
      "Epoch 5038, Loss: 0.039235208416357636, Final Batch Loss: 0.011883304454386234\n",
      "Epoch 5039, Loss: 0.025679527083411813, Final Batch Loss: 0.0016964210662990808\n",
      "Epoch 5040, Loss: 0.032014244236052036, Final Batch Loss: 0.004580868408083916\n",
      "Epoch 5041, Loss: 0.018422863679006696, Final Batch Loss: 0.005269978195428848\n",
      "Epoch 5042, Loss: 0.021964928600937128, Final Batch Loss: 0.007773669436573982\n",
      "Epoch 5043, Loss: 0.019616196514107287, Final Batch Loss: 0.00937639083713293\n",
      "Epoch 5044, Loss: 0.022999591659754515, Final Batch Loss: 0.007412563543766737\n",
      "Epoch 5045, Loss: 0.014798259129747748, Final Batch Loss: 0.007277986966073513\n",
      "Epoch 5046, Loss: 0.08214686717838049, Final Batch Loss: 0.004161872435361147\n",
      "Epoch 5047, Loss: 0.01931475434685126, Final Batch Loss: 0.0005715913721360266\n",
      "Epoch 5048, Loss: 0.019324978638906032, Final Batch Loss: 0.0006650016293860972\n",
      "Epoch 5049, Loss: 0.025573496997822076, Final Batch Loss: 0.0008576326654292643\n",
      "Epoch 5050, Loss: 0.03432150499429554, Final Batch Loss: 0.0018979109590873122\n",
      "Epoch 5051, Loss: 0.0128879175754264, Final Batch Loss: 0.0014470421010628343\n",
      "Epoch 5052, Loss: 0.00782927148975432, Final Batch Loss: 0.0026221841108053923\n",
      "Epoch 5053, Loss: 0.023153559595812112, Final Batch Loss: 0.0021472149528563023\n",
      "Epoch 5054, Loss: 0.02934808548889123, Final Batch Loss: 0.0002264025097247213\n",
      "Epoch 5055, Loss: 0.052443786058574915, Final Batch Loss: 0.0006141518242657185\n",
      "Epoch 5056, Loss: 0.051389946340350434, Final Batch Loss: 0.0035291332751512527\n",
      "Epoch 5057, Loss: 0.034464580938220024, Final Batch Loss: 0.0017294046701863408\n",
      "Epoch 5058, Loss: 0.022283822298049927, Final Batch Loss: 0.01147200632840395\n",
      "Epoch 5059, Loss: 0.021902354550547898, Final Batch Loss: 0.0013291180366650224\n",
      "Epoch 5060, Loss: 0.037307513412088156, Final Batch Loss: 0.007297622039914131\n",
      "Epoch 5061, Loss: 0.045245434157550335, Final Batch Loss: 0.015351994894444942\n",
      "Epoch 5062, Loss: 0.05798961955588311, Final Batch Loss: 0.018808305263519287\n",
      "Epoch 5063, Loss: 0.01341216400032863, Final Batch Loss: 0.00029402371728792787\n",
      "Epoch 5064, Loss: 0.05430193815845996, Final Batch Loss: 0.004537756554782391\n",
      "Epoch 5065, Loss: 0.016005978919565678, Final Batch Loss: 0.004266516771167517\n",
      "Epoch 5066, Loss: 0.019951163325458765, Final Batch Loss: 0.01325121521949768\n",
      "Epoch 5067, Loss: 0.027761015808209777, Final Batch Loss: 0.0016219422686845064\n",
      "Epoch 5068, Loss: 0.015257652383297682, Final Batch Loss: 0.007664775010198355\n",
      "Epoch 5069, Loss: 0.035432244767434895, Final Batch Loss: 0.005614477209746838\n",
      "Epoch 5070, Loss: 0.06556105171330273, Final Batch Loss: 0.05614452436566353\n",
      "Epoch 5071, Loss: 0.046244011260569096, Final Batch Loss: 0.004759015049785376\n",
      "Epoch 5072, Loss: 0.06691086117643863, Final Batch Loss: 0.05764894559979439\n",
      "Epoch 5073, Loss: 0.036202083225362, Final Batch Loss: 0.0016646747244521976\n",
      "Epoch 5074, Loss: 0.021153574052732438, Final Batch Loss: 0.0008557149558328092\n",
      "Epoch 5075, Loss: 0.014751651091501117, Final Batch Loss: 0.0016388953663408756\n",
      "Epoch 5076, Loss: 0.010192962130531669, Final Batch Loss: 0.0005907788872718811\n",
      "Epoch 5077, Loss: 0.009490425320109352, Final Batch Loss: 0.00032201266731135547\n",
      "Epoch 5078, Loss: 0.059060143830720335, Final Batch Loss: 0.015784548595547676\n",
      "Epoch 5079, Loss: 0.05674257315695286, Final Batch Loss: 0.015256529673933983\n",
      "Epoch 5080, Loss: 0.014655768987722695, Final Batch Loss: 0.003136708866804838\n",
      "Epoch 5081, Loss: 0.02867734944447875, Final Batch Loss: 0.005254154559224844\n",
      "Epoch 5082, Loss: 0.041101325768977404, Final Batch Loss: 0.001097261207178235\n",
      "Epoch 5083, Loss: 0.02123851201031357, Final Batch Loss: 0.0063492232002317905\n",
      "Epoch 5084, Loss: 0.027072973549365997, Final Batch Loss: 0.015207870863378048\n",
      "Epoch 5085, Loss: 0.021728561143390834, Final Batch Loss: 0.0009567666565999389\n",
      "Epoch 5086, Loss: 0.05029677553102374, Final Batch Loss: 0.004753017332404852\n",
      "Epoch 5087, Loss: 0.026877769618295133, Final Batch Loss: 0.013320709578692913\n",
      "Epoch 5088, Loss: 0.03110776311950758, Final Batch Loss: 0.0006152683054096997\n",
      "Epoch 5089, Loss: 0.012974415651115123, Final Batch Loss: 0.0001027826001518406\n",
      "Epoch 5090, Loss: 0.08292461931705475, Final Batch Loss: 0.04052954539656639\n",
      "Epoch 5091, Loss: 0.0355446299072355, Final Batch Loss: 0.00017706374637782574\n",
      "Epoch 5092, Loss: 0.0025414295960217714, Final Batch Loss: 0.0004000168410129845\n",
      "Epoch 5093, Loss: 0.014422558946534991, Final Batch Loss: 0.003342739073559642\n",
      "Epoch 5094, Loss: 0.028868229215731844, Final Batch Loss: 0.00034747595782391727\n",
      "Epoch 5095, Loss: 0.013158931047655642, Final Batch Loss: 0.0022668475285172462\n",
      "Epoch 5096, Loss: 0.019908499292796478, Final Batch Loss: 0.00046350513002835214\n",
      "Epoch 5097, Loss: 0.04708078224211931, Final Batch Loss: 0.007677125278860331\n",
      "Epoch 5098, Loss: 0.022394347295630723, Final Batch Loss: 0.00043948780512437224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5099, Loss: 0.014855906600132585, Final Batch Loss: 0.005874725989997387\n",
      "Epoch 5100, Loss: 0.036753599357325584, Final Batch Loss: 0.0014451966853812337\n",
      "Epoch 5101, Loss: 0.020136597799137235, Final Batch Loss: 0.0005859485827386379\n",
      "Epoch 5102, Loss: 0.010654588637407869, Final Batch Loss: 0.005834024865180254\n",
      "Epoch 5103, Loss: 0.0691502975532785, Final Batch Loss: 0.025568081066012383\n",
      "Epoch 5104, Loss: 0.01345574576407671, Final Batch Loss: 0.0012158898171037436\n",
      "Epoch 5105, Loss: 0.008572438382543623, Final Batch Loss: 0.0005561452126130462\n",
      "Epoch 5106, Loss: 0.022550951223820448, Final Batch Loss: 0.012627298012375832\n",
      "Epoch 5107, Loss: 0.04091618047095835, Final Batch Loss: 0.0018855833914130926\n",
      "Epoch 5108, Loss: 0.007643198601726908, Final Batch Loss: 7.567962893517688e-05\n",
      "Epoch 5109, Loss: 0.05737292135017924, Final Batch Loss: 0.0002993248344864696\n",
      "Epoch 5110, Loss: 0.01786179223563522, Final Batch Loss: 0.0011964794248342514\n",
      "Epoch 5111, Loss: 0.03885045577771962, Final Batch Loss: 0.02096947468817234\n",
      "Epoch 5112, Loss: 0.06093629589304328, Final Batch Loss: 0.003499803598970175\n",
      "Epoch 5113, Loss: 0.06056209374219179, Final Batch Loss: 0.00805265735834837\n",
      "Epoch 5114, Loss: 0.032656796276569366, Final Batch Loss: 0.0034349123015999794\n",
      "Epoch 5115, Loss: 0.03113003878388554, Final Batch Loss: 0.005112982355058193\n",
      "Epoch 5116, Loss: 0.0794616260100156, Final Batch Loss: 0.04650631546974182\n",
      "Epoch 5117, Loss: 0.023001683643087745, Final Batch Loss: 0.006526005920022726\n",
      "Epoch 5118, Loss: 0.067574018612504, Final Batch Loss: 0.0027932636439800262\n",
      "Epoch 5119, Loss: 0.03597843600437045, Final Batch Loss: 0.0035117166116833687\n",
      "Epoch 5120, Loss: 0.12973512895405293, Final Batch Loss: 0.024615023285150528\n",
      "Epoch 5121, Loss: 0.0600726876873523, Final Batch Loss: 0.0030611923430114985\n",
      "Epoch 5122, Loss: 0.1426562536507845, Final Batch Loss: 0.008518610149621964\n",
      "Epoch 5123, Loss: 0.0144214914762415, Final Batch Loss: 0.006996080745011568\n",
      "Epoch 5124, Loss: 0.10848500137217343, Final Batch Loss: 0.0052134268917143345\n",
      "Epoch 5125, Loss: 0.015141390962526202, Final Batch Loss: 0.005616315174847841\n",
      "Epoch 5126, Loss: 0.034788820426911116, Final Batch Loss: 0.0008357733022421598\n",
      "Epoch 5127, Loss: 0.01564506348222494, Final Batch Loss: 0.0037329073529690504\n",
      "Epoch 5128, Loss: 0.040424008620902896, Final Batch Loss: 0.003492854768410325\n",
      "Epoch 5129, Loss: 0.04667110834270716, Final Batch Loss: 0.0036004099529236555\n",
      "Epoch 5130, Loss: 0.043284999090246856, Final Batch Loss: 0.018635611981153488\n",
      "Epoch 5131, Loss: 0.039271730463951826, Final Batch Loss: 0.007236253470182419\n",
      "Epoch 5132, Loss: 0.03488588077016175, Final Batch Loss: 0.0025276464875787497\n",
      "Epoch 5133, Loss: 0.012927043135277927, Final Batch Loss: 0.0035453124437481165\n",
      "Epoch 5134, Loss: 0.027210883796215057, Final Batch Loss: 0.013179711066186428\n",
      "Epoch 5135, Loss: 0.0861926763318479, Final Batch Loss: 0.0223417729139328\n",
      "Epoch 5136, Loss: 0.10520539688877761, Final Batch Loss: 0.035823456943035126\n",
      "Epoch 5137, Loss: 0.06718737073242664, Final Batch Loss: 0.04911838099360466\n",
      "Epoch 5138, Loss: 0.017946894862689078, Final Batch Loss: 0.0005548525368794799\n",
      "Epoch 5139, Loss: 0.030373456422239542, Final Batch Loss: 0.002217215020209551\n",
      "Epoch 5140, Loss: 0.04181535984389484, Final Batch Loss: 0.005655968561768532\n",
      "Epoch 5141, Loss: 0.016821761382743716, Final Batch Loss: 0.002885865280404687\n",
      "Epoch 5142, Loss: 0.028672573273070157, Final Batch Loss: 0.003465494839474559\n",
      "Epoch 5143, Loss: 0.023267403797945008, Final Batch Loss: 0.0006631368887610734\n",
      "Epoch 5144, Loss: 0.01080890279263258, Final Batch Loss: 0.0034637434873729944\n",
      "Epoch 5145, Loss: 0.029901286587119102, Final Batch Loss: 0.0009700832888484001\n",
      "Epoch 5146, Loss: 0.02225782349705696, Final Batch Loss: 0.005864246748387814\n",
      "Epoch 5147, Loss: 0.08952023577876389, Final Batch Loss: 0.06725990027189255\n",
      "Epoch 5148, Loss: 0.06626092828810215, Final Batch Loss: 0.0035429750569164753\n",
      "Epoch 5149, Loss: 0.09051394811831415, Final Batch Loss: 0.013238118030130863\n",
      "Epoch 5150, Loss: 0.00829040160169825, Final Batch Loss: 0.0008478910312987864\n",
      "Epoch 5151, Loss: 0.04507943568751216, Final Batch Loss: 0.0074014742858707905\n",
      "Epoch 5152, Loss: 0.05196294898632914, Final Batch Loss: 0.0016584008699283004\n",
      "Epoch 5153, Loss: 0.01044235355220735, Final Batch Loss: 0.001846957951784134\n",
      "Epoch 5154, Loss: 0.03711507027037442, Final Batch Loss: 0.017764287069439888\n",
      "Epoch 5155, Loss: 0.06376160169020295, Final Batch Loss: 0.009876689873635769\n",
      "Epoch 5156, Loss: 0.13437599292956293, Final Batch Loss: 0.018591832369565964\n",
      "Epoch 5157, Loss: 0.020368547411635518, Final Batch Loss: 0.0061024390161037445\n",
      "Epoch 5158, Loss: 0.07182005583308637, Final Batch Loss: 0.03447036072611809\n",
      "Epoch 5159, Loss: 0.03286954830400646, Final Batch Loss: 0.006208013743162155\n",
      "Epoch 5160, Loss: 0.15910598821938038, Final Batch Loss: 0.0603950060904026\n",
      "Epoch 5161, Loss: 0.21545815281569958, Final Batch Loss: 0.17007707059383392\n",
      "Epoch 5162, Loss: 0.03596593136899173, Final Batch Loss: 0.0009506288915872574\n",
      "Epoch 5163, Loss: 0.035368306445889175, Final Batch Loss: 0.0019170715240761638\n",
      "Epoch 5164, Loss: 0.058079578331671655, Final Batch Loss: 0.0018243802478536963\n",
      "Epoch 5165, Loss: 0.07145373523235321, Final Batch Loss: 0.002041308907791972\n",
      "Epoch 5166, Loss: 0.028718803077936172, Final Batch Loss: 0.0019720380660146475\n",
      "Epoch 5167, Loss: 0.06279187719337642, Final Batch Loss: 0.0017279982566833496\n",
      "Epoch 5168, Loss: 0.08064378332346678, Final Batch Loss: 0.028893038630485535\n",
      "Epoch 5169, Loss: 0.04666457395069301, Final Batch Loss: 0.027216866612434387\n",
      "Epoch 5170, Loss: 0.1120844203978777, Final Batch Loss: 0.06283799558877945\n",
      "Epoch 5171, Loss: 0.05258541367948055, Final Batch Loss: 0.002078886143863201\n",
      "Epoch 5172, Loss: 0.14741183118894696, Final Batch Loss: 0.005829995963722467\n",
      "Epoch 5173, Loss: 0.10102613549679518, Final Batch Loss: 0.01413439679890871\n",
      "Epoch 5174, Loss: 0.08419823087751865, Final Batch Loss: 0.01749812439084053\n",
      "Epoch 5175, Loss: 0.08347775787115097, Final Batch Loss: 0.017663871869444847\n",
      "Epoch 5176, Loss: 0.11905580293387175, Final Batch Loss: 0.0321195088326931\n",
      "Epoch 5177, Loss: 0.1142160661984235, Final Batch Loss: 0.0033968177158385515\n",
      "Epoch 5178, Loss: 0.07611910300329328, Final Batch Loss: 0.005091849714517593\n",
      "Epoch 5179, Loss: 0.036042947467649356, Final Batch Loss: 0.0002770935243461281\n",
      "Epoch 5180, Loss: 0.07000486785545945, Final Batch Loss: 0.016116108745336533\n",
      "Epoch 5181, Loss: 0.02454968634992838, Final Batch Loss: 0.0021156943403184414\n",
      "Epoch 5182, Loss: 0.02064345678081736, Final Batch Loss: 0.0003424202441237867\n",
      "Epoch 5183, Loss: 0.0459724694956094, Final Batch Loss: 0.02885252609848976\n",
      "Epoch 5184, Loss: 0.02302116621285677, Final Batch Loss: 0.0011205635964870453\n",
      "Epoch 5185, Loss: 0.0642590846400708, Final Batch Loss: 0.0019415003480389714\n",
      "Epoch 5186, Loss: 0.07405023206956685, Final Batch Loss: 0.0026042063254863024\n",
      "Epoch 5187, Loss: 0.03041726374067366, Final Batch Loss: 0.015740012750029564\n",
      "Epoch 5188, Loss: 0.024677618173882365, Final Batch Loss: 0.009432287886738777\n",
      "Epoch 5189, Loss: 0.014654558442998677, Final Batch Loss: 0.0009567172382958233\n",
      "Epoch 5190, Loss: 0.028307095635682344, Final Batch Loss: 0.006135497707873583\n",
      "Epoch 5191, Loss: 0.03341467387508601, Final Batch Loss: 0.0010067573748528957\n",
      "Epoch 5192, Loss: 0.030219587264582515, Final Batch Loss: 0.0034772020298987627\n",
      "Epoch 5193, Loss: 0.021855988656170666, Final Batch Loss: 0.0010236072121188045\n",
      "Epoch 5194, Loss: 0.03677233285270631, Final Batch Loss: 0.006201571319252253\n",
      "Epoch 5195, Loss: 0.039864710066467524, Final Batch Loss: 0.005697971675544977\n",
      "Epoch 5196, Loss: 0.031159184873104095, Final Batch Loss: 0.013507837429642677\n",
      "Epoch 5197, Loss: 0.0447361720725894, Final Batch Loss: 0.0007633359637111425\n",
      "Epoch 5198, Loss: 0.014273645530920476, Final Batch Loss: 0.0005487818270921707\n",
      "Epoch 5199, Loss: 0.021806519012898207, Final Batch Loss: 0.002667212625965476\n",
      "Epoch 5200, Loss: 0.04892752110026777, Final Batch Loss: 0.03700663894414902\n",
      "Epoch 5201, Loss: 0.007990185869857669, Final Batch Loss: 0.0011562858708202839\n",
      "Epoch 5202, Loss: 0.008122535975417122, Final Batch Loss: 0.0004402446502353996\n",
      "Epoch 5203, Loss: 0.03605998121201992, Final Batch Loss: 0.0041597443632781506\n",
      "Epoch 5204, Loss: 0.022125713643617928, Final Batch Loss: 0.0018087163334712386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5205, Loss: 0.01103978417813778, Final Batch Loss: 0.0005681386683136225\n",
      "Epoch 5206, Loss: 0.04222950735129416, Final Batch Loss: 0.0018689519492909312\n",
      "Epoch 5207, Loss: 0.018785573018249124, Final Batch Loss: 0.004460235591977835\n",
      "Epoch 5208, Loss: 0.0484927948564291, Final Batch Loss: 0.01067370269447565\n",
      "Epoch 5209, Loss: 0.03160702908644453, Final Batch Loss: 0.02081739343702793\n",
      "Epoch 5210, Loss: 0.03423243900761008, Final Batch Loss: 0.0029228520579636097\n",
      "Epoch 5211, Loss: 0.09865803632419556, Final Batch Loss: 0.006794855464249849\n",
      "Epoch 5212, Loss: 0.06601623422466218, Final Batch Loss: 0.0027800453826785088\n",
      "Epoch 5213, Loss: 0.023480911273509264, Final Batch Loss: 0.004096848890185356\n",
      "Epoch 5214, Loss: 0.029385263565927744, Final Batch Loss: 0.008866863325238228\n",
      "Epoch 5215, Loss: 0.036620006314478815, Final Batch Loss: 0.011854501441121101\n",
      "Epoch 5216, Loss: 0.013037187047302723, Final Batch Loss: 0.0011678850278258324\n",
      "Epoch 5217, Loss: 0.0683875740505755, Final Batch Loss: 0.0013685119338333607\n",
      "Epoch 5218, Loss: 0.019522923277691007, Final Batch Loss: 0.004289277829229832\n",
      "Epoch 5219, Loss: 0.05793020885903388, Final Batch Loss: 0.010229240171611309\n",
      "Epoch 5220, Loss: 0.051501519745215774, Final Batch Loss: 0.0015512595418840647\n",
      "Epoch 5221, Loss: 0.009452831814996898, Final Batch Loss: 0.0016967194387689233\n",
      "Epoch 5222, Loss: 0.03152191184926778, Final Batch Loss: 0.0006724400445818901\n",
      "Epoch 5223, Loss: 0.023237730260007083, Final Batch Loss: 0.0010515049798414111\n",
      "Epoch 5224, Loss: 0.019938102108426392, Final Batch Loss: 0.001003358163870871\n",
      "Epoch 5225, Loss: 0.027963654370978475, Final Batch Loss: 0.003236649790778756\n",
      "Epoch 5226, Loss: 0.039501325227320194, Final Batch Loss: 0.01388093177229166\n",
      "Epoch 5227, Loss: 0.045001148828305304, Final Batch Loss: 0.005831470713019371\n",
      "Epoch 5228, Loss: 0.04758181795477867, Final Batch Loss: 0.0038185054436326027\n",
      "Epoch 5229, Loss: 0.015235964208841324, Final Batch Loss: 0.003774478565901518\n",
      "Epoch 5230, Loss: 0.08894514618441463, Final Batch Loss: 0.06691034138202667\n",
      "Epoch 5231, Loss: 0.02919849706813693, Final Batch Loss: 0.0023566654417663813\n",
      "Epoch 5232, Loss: 0.035897606052458286, Final Batch Loss: 0.0157062616199255\n",
      "Epoch 5233, Loss: 0.056143862660974264, Final Batch Loss: 0.004819681867957115\n",
      "Epoch 5234, Loss: 0.11011951323598623, Final Batch Loss: 0.04133913293480873\n",
      "Epoch 5235, Loss: 0.10635823872871697, Final Batch Loss: 0.002717643277719617\n",
      "Epoch 5236, Loss: 0.07103595603257418, Final Batch Loss: 0.014070659875869751\n",
      "Epoch 5237, Loss: 0.05637568747624755, Final Batch Loss: 0.026898976415395737\n",
      "Epoch 5238, Loss: 0.07435626816004515, Final Batch Loss: 0.017071859911084175\n",
      "Epoch 5239, Loss: 0.0409035881748423, Final Batch Loss: 0.00047429942060261965\n",
      "Epoch 5240, Loss: 0.0462778169894591, Final Batch Loss: 0.001216271542944014\n",
      "Epoch 5241, Loss: 0.08547306095715612, Final Batch Loss: 0.00302599323913455\n",
      "Epoch 5242, Loss: 0.02902577118948102, Final Batch Loss: 0.0008604491595178843\n",
      "Epoch 5243, Loss: 0.048284513875842094, Final Batch Loss: 0.0008150385692715645\n",
      "Epoch 5244, Loss: 0.03209632489597425, Final Batch Loss: 0.0005605900078080595\n",
      "Epoch 5245, Loss: 0.02011224441230297, Final Batch Loss: 0.003083572257310152\n",
      "Epoch 5246, Loss: 0.0402060782071203, Final Batch Loss: 0.02530759945511818\n",
      "Epoch 5247, Loss: 0.03847812965977937, Final Batch Loss: 0.0011520847911015153\n",
      "Epoch 5248, Loss: 0.11010548000922427, Final Batch Loss: 0.00042116170516237617\n",
      "Epoch 5249, Loss: 0.08161319070495665, Final Batch Loss: 0.0579659640789032\n",
      "Epoch 5250, Loss: 0.05222660512663424, Final Batch Loss: 0.0016905798111110926\n",
      "Epoch 5251, Loss: 0.02335517044411972, Final Batch Loss: 0.017581557855010033\n",
      "Epoch 5252, Loss: 0.011404575896449387, Final Batch Loss: 0.0010750603396445513\n",
      "Epoch 5253, Loss: 0.04864236479625106, Final Batch Loss: 0.001057436573319137\n",
      "Epoch 5254, Loss: 0.03333875676617026, Final Batch Loss: 0.000985286314971745\n",
      "Epoch 5255, Loss: 0.03407268691807985, Final Batch Loss: 0.0024119745939970016\n",
      "Epoch 5256, Loss: 0.03999353596009314, Final Batch Loss: 0.004785024095326662\n",
      "Epoch 5257, Loss: 0.01839048560941592, Final Batch Loss: 0.0005745543749071658\n",
      "Epoch 5258, Loss: 0.04988621023949236, Final Batch Loss: 0.0016432240372523665\n",
      "Epoch 5259, Loss: 0.1011033896356821, Final Batch Loss: 0.014141269028186798\n",
      "Epoch 5260, Loss: 0.013211158162448555, Final Batch Loss: 0.0007808658992871642\n",
      "Epoch 5261, Loss: 0.008051286800764501, Final Batch Loss: 0.0005877476651221514\n",
      "Epoch 5262, Loss: 0.05851298617199063, Final Batch Loss: 0.004613213706761599\n",
      "Epoch 5263, Loss: 0.06173903919989243, Final Batch Loss: 0.000513363687787205\n",
      "Epoch 5264, Loss: 0.08211478381417692, Final Batch Loss: 0.02506532520055771\n",
      "Epoch 5265, Loss: 0.018160494044423103, Final Batch Loss: 0.0015982873737812042\n",
      "Epoch 5266, Loss: 0.04054983300011372, Final Batch Loss: 6.861346628284082e-05\n",
      "Epoch 5267, Loss: 0.10677463700994849, Final Batch Loss: 0.08680792897939682\n",
      "Epoch 5268, Loss: 0.09036511252634227, Final Batch Loss: 0.0025826722849160433\n",
      "Epoch 5269, Loss: 0.022080598631873727, Final Batch Loss: 0.0025576730258762836\n",
      "Epoch 5270, Loss: 0.0320254135876894, Final Batch Loss: 0.004090143367648125\n",
      "Epoch 5271, Loss: 0.02670860826037824, Final Batch Loss: 0.0007004255894571543\n",
      "Epoch 5272, Loss: 0.03054587496444583, Final Batch Loss: 0.0026209603529423475\n",
      "Epoch 5273, Loss: 0.029494595248252153, Final Batch Loss: 0.0017738700844347477\n",
      "Epoch 5274, Loss: 0.020978782151360065, Final Batch Loss: 0.001437021535821259\n",
      "Epoch 5275, Loss: 0.029192801099270582, Final Batch Loss: 0.01002154778689146\n",
      "Epoch 5276, Loss: 0.007511313015129417, Final Batch Loss: 0.0009393784566782415\n",
      "Epoch 5277, Loss: 0.02209804265294224, Final Batch Loss: 0.0019220112590119243\n",
      "Epoch 5278, Loss: 0.03819856408517808, Final Batch Loss: 0.0003998236497864127\n",
      "Epoch 5279, Loss: 0.005317625298630446, Final Batch Loss: 0.0014621054287999868\n",
      "Epoch 5280, Loss: 0.05115201254375279, Final Batch Loss: 0.0012988618109375238\n",
      "Epoch 5281, Loss: 0.020019035669974983, Final Batch Loss: 0.012322252616286278\n",
      "Epoch 5282, Loss: 0.03484037343878299, Final Batch Loss: 0.001071836450137198\n",
      "Epoch 5283, Loss: 0.00917087818379514, Final Batch Loss: 0.0034038680605590343\n",
      "Epoch 5284, Loss: 0.009905961458571255, Final Batch Loss: 0.0017684751655906439\n",
      "Epoch 5285, Loss: 0.017866726499050856, Final Batch Loss: 0.011180631816387177\n",
      "Epoch 5286, Loss: 0.006733960821293294, Final Batch Loss: 0.0013463961658999324\n",
      "Epoch 5287, Loss: 0.04926890484057367, Final Batch Loss: 0.008919200859963894\n",
      "Epoch 5288, Loss: 0.058592927060090005, Final Batch Loss: 0.0003042089520022273\n",
      "Epoch 5289, Loss: 0.027296595973894, Final Batch Loss: 0.017873557284474373\n",
      "Epoch 5290, Loss: 0.010381467174738646, Final Batch Loss: 0.0020320832263678312\n",
      "Epoch 5291, Loss: 0.01147618016693741, Final Batch Loss: 0.0014599079731851816\n",
      "Epoch 5292, Loss: 0.058732346282340586, Final Batch Loss: 0.03533664718270302\n",
      "Epoch 5293, Loss: 0.011103114578872919, Final Batch Loss: 0.004279857035726309\n",
      "Epoch 5294, Loss: 0.04674757330212742, Final Batch Loss: 0.03569763898849487\n",
      "Epoch 5295, Loss: 0.011202134657651186, Final Batch Loss: 0.0015441854484379292\n",
      "Epoch 5296, Loss: 0.034934915747726336, Final Batch Loss: 0.0003685943374875933\n",
      "Epoch 5297, Loss: 0.030160894384607673, Final Batch Loss: 0.0013761979062110186\n",
      "Epoch 5298, Loss: 0.014083993504755199, Final Batch Loss: 0.0030026393942534924\n",
      "Epoch 5299, Loss: 0.028017270378768444, Final Batch Loss: 0.0011082938872277737\n",
      "Epoch 5300, Loss: 0.034501067540986696, Final Batch Loss: 5.5994783906498924e-05\n",
      "Epoch 5301, Loss: 0.019147894403431565, Final Batch Loss: 0.0007134156185202301\n",
      "Epoch 5302, Loss: 0.018670010729692876, Final Batch Loss: 0.007215666119009256\n",
      "Epoch 5303, Loss: 0.02667405756074004, Final Batch Loss: 0.00017383365775458515\n",
      "Epoch 5304, Loss: 0.006684966501779854, Final Batch Loss: 0.0009969129459932446\n",
      "Epoch 5305, Loss: 0.07714218366891146, Final Batch Loss: 0.054153960198163986\n",
      "Epoch 5306, Loss: 0.019812434329651296, Final Batch Loss: 0.0006640650099143386\n",
      "Epoch 5307, Loss: 0.02958363271318376, Final Batch Loss: 0.0038239851128309965\n",
      "Epoch 5308, Loss: 0.029609147284645587, Final Batch Loss: 0.0006118692108429968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5309, Loss: 0.040925614710431546, Final Batch Loss: 0.0006894992548041046\n",
      "Epoch 5310, Loss: 0.009240150975529104, Final Batch Loss: 0.005570238921791315\n",
      "Epoch 5311, Loss: 0.01841765665449202, Final Batch Loss: 0.004099847748875618\n",
      "Epoch 5312, Loss: 0.023361679632216692, Final Batch Loss: 0.00591216841712594\n",
      "Epoch 5313, Loss: 0.022809300920926034, Final Batch Loss: 0.0005177151178941131\n",
      "Epoch 5314, Loss: 0.02408338664099574, Final Batch Loss: 0.005717383697628975\n",
      "Epoch 5315, Loss: 0.02989619830623269, Final Batch Loss: 0.019719306379556656\n",
      "Epoch 5316, Loss: 0.01630514522548765, Final Batch Loss: 0.0007911826251074672\n",
      "Epoch 5317, Loss: 0.011825955618405715, Final Batch Loss: 0.0021503737661987543\n",
      "Epoch 5318, Loss: 0.04335981185431592, Final Batch Loss: 0.00021173254936002195\n",
      "Epoch 5319, Loss: 0.013202738715335727, Final Batch Loss: 0.001155797392129898\n",
      "Epoch 5320, Loss: 0.005422171554528177, Final Batch Loss: 0.0007044356898404658\n",
      "Epoch 5321, Loss: 0.011204852547962219, Final Batch Loss: 0.0073782531544566154\n",
      "Epoch 5322, Loss: 0.049210531113203615, Final Batch Loss: 0.0007175406790338457\n",
      "Epoch 5323, Loss: 0.01836466128588654, Final Batch Loss: 0.0003512852417770773\n",
      "Epoch 5324, Loss: 0.04394795384723693, Final Batch Loss: 0.0024546298664063215\n",
      "Epoch 5325, Loss: 0.017183199350256473, Final Batch Loss: 0.0027563178446143866\n",
      "Epoch 5326, Loss: 0.010363340727053583, Final Batch Loss: 0.0012057771673426032\n",
      "Epoch 5327, Loss: 0.004831951082451269, Final Batch Loss: 0.00020495490753091872\n",
      "Epoch 5328, Loss: 0.015017054683994502, Final Batch Loss: 0.0007062219665385783\n",
      "Epoch 5329, Loss: 0.007282443257281557, Final Batch Loss: 0.0020537807140499353\n",
      "Epoch 5330, Loss: 0.005615051166387275, Final Batch Loss: 0.0023637397680431604\n",
      "Epoch 5331, Loss: 0.010810011124704033, Final Batch Loss: 0.0010461913188919425\n",
      "Epoch 5332, Loss: 0.005619852046947926, Final Batch Loss: 0.0003389007179066539\n",
      "Epoch 5333, Loss: 0.035833496949635446, Final Batch Loss: 0.00036939303390681744\n",
      "Epoch 5334, Loss: 0.02293861302314326, Final Batch Loss: 0.0008114256779663265\n",
      "Epoch 5335, Loss: 0.030600349768064916, Final Batch Loss: 0.004035482183098793\n",
      "Epoch 5336, Loss: 0.01799488952383399, Final Batch Loss: 0.0021396565716713667\n",
      "Epoch 5337, Loss: 0.03476154140662402, Final Batch Loss: 0.01755077764391899\n",
      "Epoch 5338, Loss: 0.007670207764022052, Final Batch Loss: 0.0013623336562886834\n",
      "Epoch 5339, Loss: 0.01832563290372491, Final Batch Loss: 0.004061728250235319\n",
      "Epoch 5340, Loss: 0.01837624260224402, Final Batch Loss: 0.0010510336142033339\n",
      "Epoch 5341, Loss: 0.020202916231937706, Final Batch Loss: 0.004897737875580788\n",
      "Epoch 5342, Loss: 0.006117186858318746, Final Batch Loss: 0.00028574117459356785\n",
      "Epoch 5343, Loss: 0.05423327977769077, Final Batch Loss: 0.0010788517538458109\n",
      "Epoch 5344, Loss: 0.025571834528818727, Final Batch Loss: 0.0009204503148794174\n",
      "Epoch 5345, Loss: 0.009639283729484305, Final Batch Loss: 0.00045907890307717025\n",
      "Epoch 5346, Loss: 0.007707767013926059, Final Batch Loss: 0.0003674288163892925\n",
      "Epoch 5347, Loss: 0.017024535103701055, Final Batch Loss: 0.0011743920622393489\n",
      "Epoch 5348, Loss: 0.013007164758164436, Final Batch Loss: 0.0030839417595416307\n",
      "Epoch 5349, Loss: 0.010768681531772017, Final Batch Loss: 0.0006984808715060353\n",
      "Epoch 5350, Loss: 0.0599627933697775, Final Batch Loss: 0.031245343387126923\n",
      "Epoch 5351, Loss: 0.013510739372577518, Final Batch Loss: 0.0024127820506691933\n",
      "Epoch 5352, Loss: 0.015110149281099439, Final Batch Loss: 0.001285899430513382\n",
      "Epoch 5353, Loss: 0.023433343041688204, Final Batch Loss: 0.0019621909596025944\n",
      "Epoch 5354, Loss: 0.03841598134022206, Final Batch Loss: 0.0013731730869039893\n",
      "Epoch 5355, Loss: 0.011314081493765116, Final Batch Loss: 0.0004440707853063941\n",
      "Epoch 5356, Loss: 0.01903814065735787, Final Batch Loss: 0.0009707200806587934\n",
      "Epoch 5357, Loss: 0.025103237538132817, Final Batch Loss: 0.006582774221897125\n",
      "Epoch 5358, Loss: 0.034324882784858346, Final Batch Loss: 0.004569497425109148\n",
      "Epoch 5359, Loss: 0.04603964579291642, Final Batch Loss: 0.009120188653469086\n",
      "Epoch 5360, Loss: 0.015952262212522328, Final Batch Loss: 0.0015476346015930176\n",
      "Epoch 5361, Loss: 0.0046070850803516805, Final Batch Loss: 0.0004598854575306177\n",
      "Epoch 5362, Loss: 0.0967507092282176, Final Batch Loss: 0.033802177757024765\n",
      "Epoch 5363, Loss: 0.010085662666824646, Final Batch Loss: 0.00011192607053089887\n",
      "Epoch 5364, Loss: 0.010242907505016774, Final Batch Loss: 0.005952736828476191\n",
      "Epoch 5365, Loss: 0.005054122768342495, Final Batch Loss: 0.001297921990044415\n",
      "Epoch 5366, Loss: 0.012649623909965158, Final Batch Loss: 0.006160804070532322\n",
      "Epoch 5367, Loss: 0.009530631941743195, Final Batch Loss: 0.0014396471669897437\n",
      "Epoch 5368, Loss: 0.019991759763797745, Final Batch Loss: 0.0002803009410854429\n",
      "Epoch 5369, Loss: 0.007296863128431141, Final Batch Loss: 0.0018708452116698027\n",
      "Epoch 5370, Loss: 0.006836340340669267, Final Batch Loss: 0.0002012891200138256\n",
      "Epoch 5371, Loss: 0.009411124541657045, Final Batch Loss: 0.0012318962253630161\n",
      "Epoch 5372, Loss: 0.019297830178402364, Final Batch Loss: 0.000984452199190855\n",
      "Epoch 5373, Loss: 0.018930250662378967, Final Batch Loss: 0.0008694054558873177\n",
      "Epoch 5374, Loss: 0.0027121141902171075, Final Batch Loss: 0.00020896759815514088\n",
      "Epoch 5375, Loss: 0.060199447558261454, Final Batch Loss: 0.053576111793518066\n",
      "Epoch 5376, Loss: 0.013475262589054182, Final Batch Loss: 0.000354820309439674\n",
      "Epoch 5377, Loss: 0.03388313435425516, Final Batch Loss: 0.0001520234945928678\n",
      "Epoch 5378, Loss: 0.02342389791738242, Final Batch Loss: 0.0008904025889933109\n",
      "Epoch 5379, Loss: 0.02656313744955696, Final Batch Loss: 0.00020011761807836592\n",
      "Epoch 5380, Loss: 0.036252134828828275, Final Batch Loss: 0.0015630004927515984\n",
      "Epoch 5381, Loss: 0.01756347151240334, Final Batch Loss: 0.0009485228802077472\n",
      "Epoch 5382, Loss: 0.06806488060101401, Final Batch Loss: 0.00024018441035877913\n",
      "Epoch 5383, Loss: 0.04722231184132397, Final Batch Loss: 0.0016845292411744595\n",
      "Epoch 5384, Loss: 0.015094050846528262, Final Batch Loss: 0.0052965739741921425\n",
      "Epoch 5385, Loss: 0.014076728839427233, Final Batch Loss: 0.0014695762656629086\n",
      "Epoch 5386, Loss: 0.022013872861862183, Final Batch Loss: 0.0033540031872689724\n",
      "Epoch 5387, Loss: 0.066551907453686, Final Batch Loss: 0.002053620293736458\n",
      "Epoch 5388, Loss: 0.006828272715210915, Final Batch Loss: 0.0005426313728094101\n",
      "Epoch 5389, Loss: 0.005837504199007526, Final Batch Loss: 0.0038181026466190815\n",
      "Epoch 5390, Loss: 0.0354742631316185, Final Batch Loss: 0.012313373386859894\n",
      "Epoch 5391, Loss: 0.06876004091463983, Final Batch Loss: 0.004180592019110918\n",
      "Epoch 5392, Loss: 0.05039216950535774, Final Batch Loss: 0.005792532581835985\n",
      "Epoch 5393, Loss: 0.007218755315989256, Final Batch Loss: 0.0013498533517122269\n",
      "Epoch 5394, Loss: 0.043238555430434644, Final Batch Loss: 0.00042198679875582457\n",
      "Epoch 5395, Loss: 0.029255803674459457, Final Batch Loss: 0.002796619199216366\n",
      "Epoch 5396, Loss: 0.022252137772738934, Final Batch Loss: 0.005844934843480587\n",
      "Epoch 5397, Loss: 0.02131436887430027, Final Batch Loss: 0.0005696397856809199\n",
      "Epoch 5398, Loss: 0.023159558477345854, Final Batch Loss: 0.0007766796625219285\n",
      "Epoch 5399, Loss: 0.09499402693472803, Final Batch Loss: 0.0032091920729726553\n",
      "Epoch 5400, Loss: 0.03021560318302363, Final Batch Loss: 0.0003776562516577542\n",
      "Epoch 5401, Loss: 0.02950159431202337, Final Batch Loss: 0.0007768188952468336\n",
      "Epoch 5402, Loss: 0.015938346390612423, Final Batch Loss: 0.0005337841575965285\n",
      "Epoch 5403, Loss: 0.04341792190098204, Final Batch Loss: 0.03936558589339256\n",
      "Epoch 5404, Loss: 0.01726824336219579, Final Batch Loss: 0.004701139405369759\n",
      "Epoch 5405, Loss: 0.057760784344282, Final Batch Loss: 0.0030131677631288767\n",
      "Epoch 5406, Loss: 0.02722020889632404, Final Batch Loss: 0.0041835857555270195\n",
      "Epoch 5407, Loss: 0.03960352670401335, Final Batch Loss: 0.005931231193244457\n",
      "Epoch 5408, Loss: 0.010879623470827937, Final Batch Loss: 0.0012111571850255132\n",
      "Epoch 5409, Loss: 0.03966564079746604, Final Batch Loss: 0.022959740832448006\n",
      "Epoch 5410, Loss: 0.030101849901257083, Final Batch Loss: 0.0003801833081524819\n",
      "Epoch 5411, Loss: 0.02597727975808084, Final Batch Loss: 0.0068890731781721115\n",
      "Epoch 5412, Loss: 0.051419375580735505, Final Batch Loss: 0.0012107816291972995\n",
      "Epoch 5413, Loss: 0.015119897288968787, Final Batch Loss: 0.00015901410370133817\n",
      "Epoch 5414, Loss: 0.04512303788214922, Final Batch Loss: 0.015117677859961987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5415, Loss: 0.019481341645587236, Final Batch Loss: 0.0071601253002882\n",
      "Epoch 5416, Loss: 0.07017211336642504, Final Batch Loss: 0.021055687218904495\n",
      "Epoch 5417, Loss: 0.026786652044393122, Final Batch Loss: 0.0011364644160494208\n",
      "Epoch 5418, Loss: 0.07499713497236371, Final Batch Loss: 0.024147747084498405\n",
      "Epoch 5419, Loss: 0.030712535954080522, Final Batch Loss: 0.00907859206199646\n",
      "Epoch 5420, Loss: 0.04939056700095534, Final Batch Loss: 0.003043706528842449\n",
      "Epoch 5421, Loss: 0.06769233522936702, Final Batch Loss: 0.006475165486335754\n",
      "Epoch 5422, Loss: 0.10199729888699949, Final Batch Loss: 0.04383581876754761\n",
      "Epoch 5423, Loss: 0.05948053556494415, Final Batch Loss: 0.00237468839623034\n",
      "Epoch 5424, Loss: 0.15219838870689273, Final Batch Loss: 0.13021841645240784\n",
      "Epoch 5425, Loss: 0.078360375482589, Final Batch Loss: 0.004479790572077036\n",
      "Epoch 5426, Loss: 0.1686209503095597, Final Batch Loss: 0.06381780654191971\n",
      "Epoch 5427, Loss: 0.0799894155934453, Final Batch Loss: 0.01320764422416687\n",
      "Epoch 5428, Loss: 0.10321369767189026, Final Batch Loss: 0.020568611100316048\n",
      "Epoch 5429, Loss: 0.05066695809364319, Final Batch Loss: 0.010912926867604256\n",
      "Epoch 5430, Loss: 0.0423762621358037, Final Batch Loss: 0.008178497664630413\n",
      "Epoch 5431, Loss: 0.07828470063395798, Final Batch Loss: 0.003822531783953309\n",
      "Epoch 5432, Loss: 0.0596143901348114, Final Batch Loss: 0.0028253505006432533\n",
      "Epoch 5433, Loss: 0.07198678189888597, Final Batch Loss: 0.04630456492304802\n",
      "Epoch 5434, Loss: 0.03550986899062991, Final Batch Loss: 0.009152290411293507\n",
      "Epoch 5435, Loss: 0.06340519990772009, Final Batch Loss: 0.023993808776140213\n",
      "Epoch 5436, Loss: 0.028948334569577128, Final Batch Loss: 0.0009754510247148573\n",
      "Epoch 5437, Loss: 0.062126458855345845, Final Batch Loss: 0.043238431215286255\n",
      "Epoch 5438, Loss: 0.05504888517316431, Final Batch Loss: 0.008704561740159988\n",
      "Epoch 5439, Loss: 0.1331536779180169, Final Batch Loss: 0.04496872425079346\n",
      "Epoch 5440, Loss: 0.040850574121577665, Final Batch Loss: 0.0003860145516227931\n",
      "Epoch 5441, Loss: 0.194511529058218, Final Batch Loss: 0.03435765206813812\n",
      "Epoch 5442, Loss: 0.15942787239328027, Final Batch Loss: 0.0988273024559021\n",
      "Epoch 5443, Loss: 0.15892737358808517, Final Batch Loss: 0.01550912857055664\n",
      "Epoch 5444, Loss: 0.18022163771092892, Final Batch Loss: 0.09733208268880844\n",
      "Epoch 5445, Loss: 0.07076892163604498, Final Batch Loss: 0.013487516902387142\n",
      "Epoch 5446, Loss: 0.19045215751975775, Final Batch Loss: 0.025500396266579628\n",
      "Epoch 5447, Loss: 0.14604877936653793, Final Batch Loss: 0.0036210070829838514\n",
      "Epoch 5448, Loss: 0.09392030723392963, Final Batch Loss: 0.005108031444251537\n",
      "Epoch 5449, Loss: 0.06618974450975657, Final Batch Loss: 0.0031629083678126335\n",
      "Epoch 5450, Loss: 0.055077542550861835, Final Batch Loss: 0.004253885708749294\n",
      "Epoch 5451, Loss: 0.0642000250518322, Final Batch Loss: 0.01953152008354664\n",
      "Epoch 5452, Loss: 0.017543731024488807, Final Batch Loss: 0.0027075379621237516\n",
      "Epoch 5453, Loss: 0.035737925209105015, Final Batch Loss: 0.004123845137655735\n",
      "Epoch 5454, Loss: 0.03877366008237004, Final Batch Loss: 0.025874020531773567\n",
      "Epoch 5455, Loss: 0.020070810103788972, Final Batch Loss: 0.0033744412939995527\n",
      "Epoch 5456, Loss: 0.12194286286830902, Final Batch Loss: 0.04512525349855423\n",
      "Epoch 5457, Loss: 0.07501253532245755, Final Batch Loss: 0.05659598484635353\n",
      "Epoch 5458, Loss: 0.008615490514785051, Final Batch Loss: 0.004186939913779497\n",
      "Epoch 5459, Loss: 0.11197541025467217, Final Batch Loss: 0.0029124480206519365\n",
      "Epoch 5460, Loss: 0.029795054346323013, Final Batch Loss: 0.005014224909245968\n",
      "Epoch 5461, Loss: 0.013930243090726435, Final Batch Loss: 0.008848167955875397\n",
      "Epoch 5462, Loss: 0.010159841505810618, Final Batch Loss: 0.0035054737236350775\n",
      "Epoch 5463, Loss: 0.015413083485327661, Final Batch Loss: 0.0008680837927386165\n",
      "Epoch 5464, Loss: 0.01532636967021972, Final Batch Loss: 0.00025913503486663103\n",
      "Epoch 5465, Loss: 0.009915880276821554, Final Batch Loss: 0.0007545235566794872\n",
      "Epoch 5466, Loss: 0.013141523697413504, Final Batch Loss: 0.0003815038362517953\n",
      "Epoch 5467, Loss: 0.06012263474985957, Final Batch Loss: 0.004589915741235018\n",
      "Epoch 5468, Loss: 0.023504218785092235, Final Batch Loss: 0.006574774160981178\n",
      "Epoch 5469, Loss: 0.012211084947921336, Final Batch Loss: 0.0023016089107841253\n",
      "Epoch 5470, Loss: 0.014459474012255669, Final Batch Loss: 0.0011671781539916992\n",
      "Epoch 5471, Loss: 0.010976415709592402, Final Batch Loss: 0.002856428734958172\n",
      "Epoch 5472, Loss: 0.008683604653924704, Final Batch Loss: 0.0017675863346084952\n",
      "Epoch 5473, Loss: 0.07231676985975355, Final Batch Loss: 0.061663124710321426\n",
      "Epoch 5474, Loss: 0.049437231849879026, Final Batch Loss: 0.008166088722646236\n",
      "Epoch 5475, Loss: 0.018344273092225194, Final Batch Loss: 0.009227566421031952\n",
      "Epoch 5476, Loss: 0.02575354860164225, Final Batch Loss: 0.002597506856545806\n",
      "Epoch 5477, Loss: 0.04138712666463107, Final Batch Loss: 0.03292606770992279\n",
      "Epoch 5478, Loss: 0.01255095872329548, Final Batch Loss: 0.004286107141524553\n",
      "Epoch 5479, Loss: 0.005899480369407684, Final Batch Loss: 0.00040836207335814834\n",
      "Epoch 5480, Loss: 0.008312409045174718, Final Batch Loss: 0.0008120848797261715\n",
      "Epoch 5481, Loss: 0.007529170368798077, Final Batch Loss: 0.00020010361913591623\n",
      "Epoch 5482, Loss: 0.006155776442028582, Final Batch Loss: 0.0008526361198164523\n",
      "Epoch 5483, Loss: 0.02291052578948438, Final Batch Loss: 0.007138407323509455\n",
      "Epoch 5484, Loss: 0.033534014131873846, Final Batch Loss: 0.0020597148686647415\n",
      "Epoch 5485, Loss: 0.00801133003551513, Final Batch Loss: 0.0008635539561510086\n",
      "Epoch 5486, Loss: 0.00908986758440733, Final Batch Loss: 0.0029645508620887995\n",
      "Epoch 5487, Loss: 0.028378171904478222, Final Batch Loss: 0.0021410281769931316\n",
      "Epoch 5488, Loss: 0.04578131134621799, Final Batch Loss: 0.01645866222679615\n",
      "Epoch 5489, Loss: 0.010753144801128656, Final Batch Loss: 0.0030110999941825867\n",
      "Epoch 5490, Loss: 0.02610102016478777, Final Batch Loss: 0.003595287213101983\n",
      "Epoch 5491, Loss: 0.06904667086200789, Final Batch Loss: 0.00045366917038336396\n",
      "Epoch 5492, Loss: 0.02060913525929209, Final Batch Loss: 0.00022920638730283827\n",
      "Epoch 5493, Loss: 0.028873279632534832, Final Batch Loss: 0.020607473328709602\n",
      "Epoch 5494, Loss: 0.008280719339381903, Final Batch Loss: 0.0005831255693919957\n",
      "Epoch 5495, Loss: 0.08712816704064608, Final Batch Loss: 0.06037949025630951\n",
      "Epoch 5496, Loss: 0.05439590074820444, Final Batch Loss: 0.0006983524071983993\n",
      "Epoch 5497, Loss: 0.0294276419444941, Final Batch Loss: 0.0004237335524521768\n",
      "Epoch 5498, Loss: 0.026828651782125235, Final Batch Loss: 0.00610651820898056\n",
      "Epoch 5499, Loss: 0.04575201915577054, Final Batch Loss: 0.008467831648886204\n",
      "Epoch 5500, Loss: 0.013407427701167762, Final Batch Loss: 0.00394139951094985\n",
      "Epoch 5501, Loss: 0.02882618538569659, Final Batch Loss: 0.006703036837279797\n",
      "Epoch 5502, Loss: 0.016011541825719178, Final Batch Loss: 0.0005524568259716034\n",
      "Epoch 5503, Loss: 0.018625203403644264, Final Batch Loss: 0.007514153141528368\n",
      "Epoch 5504, Loss: 0.013605491491034627, Final Batch Loss: 0.0015974580310285091\n",
      "Epoch 5505, Loss: 0.007131479971576482, Final Batch Loss: 0.0025188149884343147\n",
      "Epoch 5506, Loss: 0.013803746871417388, Final Batch Loss: 0.0003001662844326347\n",
      "Epoch 5507, Loss: 0.02775706653483212, Final Batch Loss: 0.0034599078353494406\n",
      "Epoch 5508, Loss: 0.02532139199320227, Final Batch Loss: 0.0010553805623203516\n",
      "Epoch 5509, Loss: 0.009775659418664873, Final Batch Loss: 0.000357729266397655\n",
      "Epoch 5510, Loss: 0.021659924183040857, Final Batch Loss: 0.0007861593039706349\n",
      "Epoch 5511, Loss: 0.0809496867004782, Final Batch Loss: 0.06799069046974182\n",
      "Epoch 5512, Loss: 0.007193795434432104, Final Batch Loss: 0.0005279196775518358\n",
      "Epoch 5513, Loss: 0.034776582731865346, Final Batch Loss: 0.0077835144475102425\n",
      "Epoch 5514, Loss: 0.11092392541468143, Final Batch Loss: 0.02027885802090168\n",
      "Epoch 5515, Loss: 0.03037165611749515, Final Batch Loss: 0.00723982322961092\n",
      "Epoch 5516, Loss: 0.0356528942938894, Final Batch Loss: 0.0027731505688279867\n",
      "Epoch 5517, Loss: 0.016560607138671912, Final Batch Loss: 0.00022239309328142554\n",
      "Epoch 5518, Loss: 0.010586114251054823, Final Batch Loss: 0.0006975489086471498\n",
      "Epoch 5519, Loss: 0.014410152332857251, Final Batch Loss: 0.003945504315197468\n",
      "Epoch 5520, Loss: 0.0053984218393452466, Final Batch Loss: 0.0005853465409018099\n",
      "Epoch 5521, Loss: 0.011527926370035857, Final Batch Loss: 0.008266132324934006\n",
      "Epoch 5522, Loss: 0.01570998626993969, Final Batch Loss: 0.006891464814543724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5523, Loss: 0.023496484471252188, Final Batch Loss: 0.00036829631426371634\n",
      "Epoch 5524, Loss: 0.011425186530686915, Final Batch Loss: 0.0030630447436124086\n",
      "Epoch 5525, Loss: 0.027398923644796014, Final Batch Loss: 0.010520894080400467\n",
      "Epoch 5526, Loss: 0.03704547995585017, Final Batch Loss: 0.0003104831266682595\n",
      "Epoch 5527, Loss: 0.07359844446182251, Final Batch Loss: 0.006530771031975746\n",
      "Epoch 5528, Loss: 0.025075546727748588, Final Batch Loss: 0.0010614875936880708\n",
      "Epoch 5529, Loss: 0.04010142129845917, Final Batch Loss: 0.031006766483187675\n",
      "Epoch 5530, Loss: 0.052676419261842966, Final Batch Loss: 0.0038746243808418512\n",
      "Epoch 5531, Loss: 0.032569147762842476, Final Batch Loss: 0.022847136482596397\n",
      "Epoch 5532, Loss: 0.04716875310987234, Final Batch Loss: 0.022748913615942\n",
      "Epoch 5533, Loss: 0.009333456051535904, Final Batch Loss: 0.0011906884610652924\n",
      "Epoch 5534, Loss: 0.009890709203318693, Final Batch Loss: 0.00016773994138929993\n",
      "Epoch 5535, Loss: 0.012722872314043343, Final Batch Loss: 0.005084213800728321\n",
      "Epoch 5536, Loss: 0.009332073736004531, Final Batch Loss: 0.001724310452118516\n",
      "Epoch 5537, Loss: 0.016070997924543917, Final Batch Loss: 0.006499549839645624\n",
      "Epoch 5538, Loss: 0.0796881215646863, Final Batch Loss: 0.017958374693989754\n",
      "Epoch 5539, Loss: 0.01597370789386332, Final Batch Loss: 0.007341836113482714\n",
      "Epoch 5540, Loss: 0.05909563589375466, Final Batch Loss: 0.0015322574181482196\n",
      "Epoch 5541, Loss: 0.006579415028681979, Final Batch Loss: 0.0004797102592419833\n",
      "Epoch 5542, Loss: 0.06373212183825672, Final Batch Loss: 0.041339579969644547\n",
      "Epoch 5543, Loss: 0.02730456943390891, Final Batch Loss: 0.0005530552589334548\n",
      "Epoch 5544, Loss: 0.1326396471413318, Final Batch Loss: 0.0003410919161979109\n",
      "Epoch 5545, Loss: 0.1040830050187651, Final Batch Loss: 0.00026860242360271513\n",
      "Epoch 5546, Loss: 0.018480271042790264, Final Batch Loss: 0.0007322789751924574\n",
      "Epoch 5547, Loss: 0.04348601121455431, Final Batch Loss: 0.032805416733026505\n",
      "Epoch 5548, Loss: 0.007393845880869776, Final Batch Loss: 0.0005972679355181754\n",
      "Epoch 5549, Loss: 0.05538777122274041, Final Batch Loss: 0.02513030916452408\n",
      "Epoch 5550, Loss: 0.0774458625819534, Final Batch Loss: 0.0030688908882439137\n",
      "Epoch 5551, Loss: 0.11877037677913904, Final Batch Loss: 0.03347895294427872\n",
      "Epoch 5552, Loss: 0.04426577175036073, Final Batch Loss: 0.031791411340236664\n",
      "Epoch 5553, Loss: 0.19425594806671143, Final Batch Loss: 0.05030643939971924\n",
      "Epoch 5554, Loss: 0.0395838194526732, Final Batch Loss: 0.011199475266039371\n",
      "Epoch 5555, Loss: 0.07161295600235462, Final Batch Loss: 0.027682453393936157\n",
      "Epoch 5556, Loss: 0.06757877813652158, Final Batch Loss: 0.035073161125183105\n",
      "Epoch 5557, Loss: 0.04404182161670178, Final Batch Loss: 0.0010768045904114842\n",
      "Epoch 5558, Loss: 0.06270746001973748, Final Batch Loss: 0.0017996260430663824\n",
      "Epoch 5559, Loss: 0.016465477528981864, Final Batch Loss: 0.0005015489878132939\n",
      "Epoch 5560, Loss: 0.06673165829852223, Final Batch Loss: 0.01106109470129013\n",
      "Epoch 5561, Loss: 0.10505209770053625, Final Batch Loss: 0.033718306571245193\n",
      "Epoch 5562, Loss: 0.034502571215853095, Final Batch Loss: 0.0007205482106655836\n",
      "Epoch 5563, Loss: 0.06106131034903228, Final Batch Loss: 0.042233873158693314\n",
      "Epoch 5564, Loss: 0.05280672194203362, Final Batch Loss: 0.00318144541233778\n",
      "Epoch 5565, Loss: 0.07148310088086873, Final Batch Loss: 0.045786384493112564\n",
      "Epoch 5566, Loss: 0.08045967994257808, Final Batch Loss: 0.033342208713293076\n",
      "Epoch 5567, Loss: 0.09854208305478096, Final Batch Loss: 0.030691398307681084\n",
      "Epoch 5568, Loss: 0.12319951131939888, Final Batch Loss: 0.07241321355104446\n",
      "Epoch 5569, Loss: 0.1456818338483572, Final Batch Loss: 0.018291356042027473\n",
      "Epoch 5570, Loss: 0.08144330140203238, Final Batch Loss: 0.009152030572295189\n",
      "Epoch 5571, Loss: 0.08565536420792341, Final Batch Loss: 0.003535985015332699\n",
      "Epoch 5572, Loss: 0.08703433256596327, Final Batch Loss: 0.013050634413957596\n",
      "Epoch 5573, Loss: 0.05475152563303709, Final Batch Loss: 0.007925929501652718\n",
      "Epoch 5574, Loss: 0.06238200981169939, Final Batch Loss: 0.04602249339222908\n",
      "Epoch 5575, Loss: 0.07570018945261836, Final Batch Loss: 0.007118144538253546\n",
      "Epoch 5576, Loss: 0.07823364809155464, Final Batch Loss: 0.016688711941242218\n",
      "Epoch 5577, Loss: 0.09996238444000483, Final Batch Loss: 0.04629211500287056\n",
      "Epoch 5578, Loss: 0.012911024503409863, Final Batch Loss: 0.0015987937804311514\n",
      "Epoch 5579, Loss: 0.03533124068053439, Final Batch Loss: 0.0007145724375732243\n",
      "Epoch 5580, Loss: 0.01763294357806444, Final Batch Loss: 0.000581956934183836\n",
      "Epoch 5581, Loss: 0.013720729388296604, Final Batch Loss: 0.001582438126206398\n",
      "Epoch 5582, Loss: 0.01108694210415706, Final Batch Loss: 0.0037159565836191177\n",
      "Epoch 5583, Loss: 0.10301704611629248, Final Batch Loss: 0.06557141989469528\n",
      "Epoch 5584, Loss: 0.06395680087734945, Final Batch Loss: 0.0004829275712836534\n",
      "Epoch 5585, Loss: 0.02167473779991269, Final Batch Loss: 0.0034964752849191427\n",
      "Epoch 5586, Loss: 0.02562422794289887, Final Batch Loss: 0.009636498987674713\n",
      "Epoch 5587, Loss: 0.03570180130191147, Final Batch Loss: 0.002932313596829772\n",
      "Epoch 5588, Loss: 0.012237800459843129, Final Batch Loss: 0.0009867899352684617\n",
      "Epoch 5589, Loss: 0.037678158609196544, Final Batch Loss: 0.004927271511405706\n",
      "Epoch 5590, Loss: 0.013541819178499281, Final Batch Loss: 0.0029375385493040085\n",
      "Epoch 5591, Loss: 0.037403353257104754, Final Batch Loss: 0.005536702461540699\n",
      "Epoch 5592, Loss: 0.020282416138798, Final Batch Loss: 0.015462285839021206\n",
      "Epoch 5593, Loss: 0.03313071164302528, Final Batch Loss: 0.0017849180148914456\n",
      "Epoch 5594, Loss: 0.021256437088595703, Final Batch Loss: 0.00037806484033353627\n",
      "Epoch 5595, Loss: 0.020628277212381363, Final Batch Loss: 0.0035774721764028072\n",
      "Epoch 5596, Loss: 0.016513371840119362, Final Batch Loss: 0.0033383206464350224\n",
      "Epoch 5597, Loss: 0.022166122565977275, Final Batch Loss: 0.0024678679183125496\n",
      "Epoch 5598, Loss: 0.01912300440017134, Final Batch Loss: 0.0062936595641076565\n",
      "Epoch 5599, Loss: 0.007879609940573573, Final Batch Loss: 0.0017893044278025627\n",
      "Epoch 5600, Loss: 0.019685666891746223, Final Batch Loss: 0.0011084116995334625\n",
      "Epoch 5601, Loss: 0.015422521159052849, Final Batch Loss: 0.0019598479848355055\n",
      "Epoch 5602, Loss: 0.029953991528600454, Final Batch Loss: 0.01393161527812481\n",
      "Epoch 5603, Loss: 0.04039303696481511, Final Batch Loss: 0.0008874600171111524\n",
      "Epoch 5604, Loss: 0.006760583535651676, Final Batch Loss: 0.00015868355694692582\n",
      "Epoch 5605, Loss: 0.006958126439712942, Final Batch Loss: 0.0026504737325012684\n",
      "Epoch 5606, Loss: 0.0152017364744097, Final Batch Loss: 0.0015494718682020903\n",
      "Epoch 5607, Loss: 0.012899657478556037, Final Batch Loss: 0.00310469139367342\n",
      "Epoch 5608, Loss: 0.01999917544890195, Final Batch Loss: 0.002185468329116702\n",
      "Epoch 5609, Loss: 0.04251992952777073, Final Batch Loss: 0.033465802669525146\n",
      "Epoch 5610, Loss: 0.008948034606873989, Final Batch Loss: 0.0006925647030584514\n",
      "Epoch 5611, Loss: 0.016663223796058446, Final Batch Loss: 0.004173163324594498\n",
      "Epoch 5612, Loss: 0.009008076274767518, Final Batch Loss: 0.0018740843515843153\n",
      "Epoch 5613, Loss: 0.010971192154102027, Final Batch Loss: 0.005239374935626984\n",
      "Epoch 5614, Loss: 0.03632969583850354, Final Batch Loss: 0.0025179251097142696\n",
      "Epoch 5615, Loss: 0.005912105116294697, Final Batch Loss: 0.0004723990277852863\n",
      "Epoch 5616, Loss: 0.014831954438704997, Final Batch Loss: 0.002467954531311989\n",
      "Epoch 5617, Loss: 0.02858394873328507, Final Batch Loss: 0.002900531981140375\n",
      "Epoch 5618, Loss: 0.013541843625716865, Final Batch Loss: 0.000935835822019726\n",
      "Epoch 5619, Loss: 0.036816449486650527, Final Batch Loss: 0.0006317694205790758\n",
      "Epoch 5620, Loss: 0.008785095007624477, Final Batch Loss: 0.004587440751492977\n",
      "Epoch 5621, Loss: 0.021141451376024634, Final Batch Loss: 0.00043168553384020925\n",
      "Epoch 5622, Loss: 0.008156385651091114, Final Batch Loss: 0.00036300919600762427\n",
      "Epoch 5623, Loss: 0.02857353794388473, Final Batch Loss: 0.005061968229711056\n",
      "Epoch 5624, Loss: 0.012907690368592739, Final Batch Loss: 0.002485324628651142\n",
      "Epoch 5625, Loss: 0.03201099997386336, Final Batch Loss: 0.008788622915744781\n",
      "Epoch 5626, Loss: 0.02024868401349522, Final Batch Loss: 0.00017585654859431088\n",
      "Epoch 5627, Loss: 0.07105335779488087, Final Batch Loss: 0.018388213589787483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5628, Loss: 0.04925332812126726, Final Batch Loss: 0.00493272952735424\n",
      "Epoch 5629, Loss: 0.052080199122428894, Final Batch Loss: 0.0041147563606500626\n",
      "Epoch 5630, Loss: 0.011777762323617935, Final Batch Loss: 0.0030006784945726395\n",
      "Epoch 5631, Loss: 0.03484478872269392, Final Batch Loss: 0.001942017232067883\n",
      "Epoch 5632, Loss: 0.05741208652034402, Final Batch Loss: 0.022547278553247452\n",
      "Epoch 5633, Loss: 0.06807095604017377, Final Batch Loss: 0.04518939182162285\n",
      "Epoch 5634, Loss: 0.055542239831993356, Final Batch Loss: 0.0003626219986472279\n",
      "Epoch 5635, Loss: 0.026107666199095547, Final Batch Loss: 0.0011701193870976567\n",
      "Epoch 5636, Loss: 0.027629371033981442, Final Batch Loss: 0.0010112760355696082\n",
      "Epoch 5637, Loss: 0.04013872938230634, Final Batch Loss: 0.004167753271758556\n",
      "Epoch 5638, Loss: 0.04186954046599567, Final Batch Loss: 0.028344720602035522\n",
      "Epoch 5639, Loss: 0.009624297556001693, Final Batch Loss: 0.0005156342522241175\n",
      "Epoch 5640, Loss: 0.04146071337163448, Final Batch Loss: 0.0032488172873854637\n",
      "Epoch 5641, Loss: 0.0681134145706892, Final Batch Loss: 0.010947112925350666\n",
      "Epoch 5642, Loss: 0.022590367298107594, Final Batch Loss: 0.010086223483085632\n",
      "Epoch 5643, Loss: 0.039973273989744484, Final Batch Loss: 0.00489052152261138\n",
      "Epoch 5644, Loss: 0.014113367884419858, Final Batch Loss: 0.0008430858142673969\n",
      "Epoch 5645, Loss: 0.012316237087361515, Final Batch Loss: 0.00020270608365535736\n",
      "Epoch 5646, Loss: 0.0298903058283031, Final Batch Loss: 0.0029640509746968746\n",
      "Epoch 5647, Loss: 0.0797851225361228, Final Batch Loss: 0.025359196588397026\n",
      "Epoch 5648, Loss: 0.06332450779154897, Final Batch Loss: 0.015880949795246124\n",
      "Epoch 5649, Loss: 0.06126627663616091, Final Batch Loss: 0.00045690464321523905\n",
      "Epoch 5650, Loss: 0.055552736041136086, Final Batch Loss: 0.0015316280769184232\n",
      "Epoch 5651, Loss: 0.07612967025488615, Final Batch Loss: 0.029498791322112083\n",
      "Epoch 5652, Loss: 0.0348538220860064, Final Batch Loss: 0.010695981793105602\n",
      "Epoch 5653, Loss: 0.23195191146805882, Final Batch Loss: 0.18793024122714996\n",
      "Epoch 5654, Loss: 0.08307394059374928, Final Batch Loss: 0.06044493615627289\n",
      "Epoch 5655, Loss: 0.14136024471372366, Final Batch Loss: 0.054935891181230545\n",
      "Epoch 5656, Loss: 0.06190000404603779, Final Batch Loss: 0.004888066090643406\n",
      "Epoch 5657, Loss: 0.061184799298644066, Final Batch Loss: 0.01825564168393612\n",
      "Epoch 5658, Loss: 0.07090044487267733, Final Batch Loss: 0.010319688357412815\n",
      "Epoch 5659, Loss: 0.09851362463086843, Final Batch Loss: 0.044360384345054626\n",
      "Epoch 5660, Loss: 0.057310480158776045, Final Batch Loss: 0.03971370682120323\n",
      "Epoch 5661, Loss: 0.12335630506277084, Final Batch Loss: 0.02250128984451294\n",
      "Epoch 5662, Loss: 0.11808123905211687, Final Batch Loss: 0.058295559138059616\n",
      "Epoch 5663, Loss: 0.1306837722659111, Final Batch Loss: 0.01171606220304966\n",
      "Epoch 5664, Loss: 0.07971268892288208, Final Batch Loss: 0.013550071977078915\n",
      "Epoch 5665, Loss: 0.06788188079372048, Final Batch Loss: 0.007757001090794802\n",
      "Epoch 5666, Loss: 0.056004139594733715, Final Batch Loss: 0.0009769191965460777\n",
      "Epoch 5667, Loss: 0.05717412766534835, Final Batch Loss: 0.03313206136226654\n",
      "Epoch 5668, Loss: 0.02883278694935143, Final Batch Loss: 0.0022342081647366285\n",
      "Epoch 5669, Loss: 0.0245706292334944, Final Batch Loss: 0.0033651869744062424\n",
      "Epoch 5670, Loss: 0.02465799916535616, Final Batch Loss: 0.006996560841798782\n",
      "Epoch 5671, Loss: 0.03081167780328542, Final Batch Loss: 0.009011808782815933\n",
      "Epoch 5672, Loss: 0.03387565922457725, Final Batch Loss: 0.00045198656152933836\n",
      "Epoch 5673, Loss: 0.02966495242435485, Final Batch Loss: 0.003278123214840889\n",
      "Epoch 5674, Loss: 0.025060471263714135, Final Batch Loss: 0.0017508338205516338\n",
      "Epoch 5675, Loss: 0.015490418416447937, Final Batch Loss: 0.0007897830801084638\n",
      "Epoch 5676, Loss: 0.019807602278888226, Final Batch Loss: 0.002034232020378113\n",
      "Epoch 5677, Loss: 0.012146640394348651, Final Batch Loss: 0.0006762168486602604\n",
      "Epoch 5678, Loss: 0.028777119237929583, Final Batch Loss: 0.005309952422976494\n",
      "Epoch 5679, Loss: 0.009268186462577432, Final Batch Loss: 0.0006778602837584913\n",
      "Epoch 5680, Loss: 0.03782596412929706, Final Batch Loss: 0.0003874625253956765\n",
      "Epoch 5681, Loss: 0.012790281092748046, Final Batch Loss: 0.005689849611371756\n",
      "Epoch 5682, Loss: 0.015321152925025672, Final Batch Loss: 0.0009542561019770801\n",
      "Epoch 5683, Loss: 0.015605436987243593, Final Batch Loss: 0.004751691594719887\n",
      "Epoch 5684, Loss: 0.013611646194476634, Final Batch Loss: 0.0007267520413734019\n",
      "Epoch 5685, Loss: 0.023714394483249635, Final Batch Loss: 0.006062575150281191\n",
      "Epoch 5686, Loss: 0.02375662326812744, Final Batch Loss: 0.005943262483924627\n",
      "Epoch 5687, Loss: 0.08368042393703945, Final Batch Loss: 0.00047977411304600537\n",
      "Epoch 5688, Loss: 0.08621126809157431, Final Batch Loss: 0.002398600336164236\n",
      "Epoch 5689, Loss: 0.019422834389843047, Final Batch Loss: 0.001567428233101964\n",
      "Epoch 5690, Loss: 0.03436855901964009, Final Batch Loss: 0.015103472396731377\n",
      "Epoch 5691, Loss: 0.006315430975519121, Final Batch Loss: 0.0008914829231798649\n",
      "Epoch 5692, Loss: 0.018944355560961412, Final Batch Loss: 5.436050196294673e-05\n",
      "Epoch 5693, Loss: 0.02013083454221487, Final Batch Loss: 0.0030179996974766254\n",
      "Epoch 5694, Loss: 0.010938597260974348, Final Batch Loss: 0.0006910198135301471\n",
      "Epoch 5695, Loss: 0.05287304625380784, Final Batch Loss: 0.001870261156000197\n",
      "Epoch 5696, Loss: 0.01491864223498851, Final Batch Loss: 0.0025625203270465136\n",
      "Epoch 5697, Loss: 0.035812073620036244, Final Batch Loss: 0.0008955046068876982\n",
      "Epoch 5698, Loss: 0.020671690814197063, Final Batch Loss: 0.00126159330829978\n",
      "Epoch 5699, Loss: 0.005932565662078559, Final Batch Loss: 0.0006892255623824894\n",
      "Epoch 5700, Loss: 0.009402282885275781, Final Batch Loss: 0.0014496366493403912\n",
      "Epoch 5701, Loss: 0.06661468907259405, Final Batch Loss: 0.0003317368682473898\n",
      "Epoch 5702, Loss: 0.00860576273407787, Final Batch Loss: 0.0020737771410495043\n",
      "Epoch 5703, Loss: 0.03348917356925085, Final Batch Loss: 0.0007649523322470486\n",
      "Epoch 5704, Loss: 0.016848356812261045, Final Batch Loss: 0.012517199851572514\n",
      "Epoch 5705, Loss: 0.008241853676736355, Final Batch Loss: 0.001958548789843917\n",
      "Epoch 5706, Loss: 0.010476039751665667, Final Batch Loss: 0.0004410635738167912\n",
      "Epoch 5707, Loss: 0.016637938853818923, Final Batch Loss: 0.00016626837896183133\n",
      "Epoch 5708, Loss: 0.016508724889717996, Final Batch Loss: 0.0010312708327546716\n",
      "Epoch 5709, Loss: 0.02175592796993442, Final Batch Loss: 0.0011900888057425618\n",
      "Epoch 5710, Loss: 0.026440780493430793, Final Batch Loss: 0.003754578996449709\n",
      "Epoch 5711, Loss: 0.02837652969174087, Final Batch Loss: 0.009698589332401752\n",
      "Epoch 5712, Loss: 0.015498843626119196, Final Batch Loss: 0.0051908898167312145\n",
      "Epoch 5713, Loss: 0.004501399234868586, Final Batch Loss: 0.0015728442231193185\n",
      "Epoch 5714, Loss: 0.06766824453370646, Final Batch Loss: 0.06319064646959305\n",
      "Epoch 5715, Loss: 0.019636124023236334, Final Batch Loss: 0.004241976886987686\n",
      "Epoch 5716, Loss: 0.13981996476650238, Final Batch Loss: 0.011897312477231026\n",
      "Epoch 5717, Loss: 0.038472640328109264, Final Batch Loss: 0.0018031741492450237\n",
      "Epoch 5718, Loss: 0.044490467640571296, Final Batch Loss: 0.008061333559453487\n",
      "Epoch 5719, Loss: 0.04487914650235325, Final Batch Loss: 0.004173217341303825\n",
      "Epoch 5720, Loss: 0.059860982932150364, Final Batch Loss: 0.026358475908637047\n",
      "Epoch 5721, Loss: 0.031517701609118376, Final Batch Loss: 6.544395728269592e-05\n",
      "Epoch 5722, Loss: 0.015725414035841823, Final Batch Loss: 0.003671636339277029\n",
      "Epoch 5723, Loss: 0.07083106879144907, Final Batch Loss: 0.01646563597023487\n",
      "Epoch 5724, Loss: 0.016429775103460997, Final Batch Loss: 0.0007440357585437596\n",
      "Epoch 5725, Loss: 0.0427997934166342, Final Batch Loss: 0.02783355675637722\n",
      "Epoch 5726, Loss: 0.03426569444127381, Final Batch Loss: 0.001914055086672306\n",
      "Epoch 5727, Loss: 0.05343192350119352, Final Batch Loss: 0.031237229704856873\n",
      "Epoch 5728, Loss: 0.08931520581245422, Final Batch Loss: 0.006399115547537804\n",
      "Epoch 5729, Loss: 0.08416783437132835, Final Batch Loss: 0.015839310362935066\n",
      "Epoch 5730, Loss: 0.09614124801009893, Final Batch Loss: 0.008558322675526142\n",
      "Epoch 5731, Loss: 0.09782584547065198, Final Batch Loss: 0.0031533667352050543\n",
      "Epoch 5732, Loss: 0.11807600513566285, Final Batch Loss: 0.08610092103481293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5733, Loss: 0.08004020666703582, Final Batch Loss: 0.01765701361000538\n",
      "Epoch 5734, Loss: 0.14411594532430172, Final Batch Loss: 0.07023302465677261\n",
      "Epoch 5735, Loss: 0.0861966535449028, Final Batch Loss: 0.019199682399630547\n",
      "Epoch 5736, Loss: 0.03996652644127607, Final Batch Loss: 0.00820901244878769\n",
      "Epoch 5737, Loss: 0.08434232883155346, Final Batch Loss: 0.011826843023300171\n",
      "Epoch 5738, Loss: 0.08764713257551193, Final Batch Loss: 0.06683105230331421\n",
      "Epoch 5739, Loss: 0.27140974486246705, Final Batch Loss: 0.16014671325683594\n",
      "Epoch 5740, Loss: 0.13910650927573442, Final Batch Loss: 0.05692305788397789\n",
      "Epoch 5741, Loss: 0.1990228034555912, Final Batch Loss: 0.0016606003046035767\n",
      "Epoch 5742, Loss: 0.23919076845049858, Final Batch Loss: 0.08944310247898102\n",
      "Epoch 5743, Loss: 0.16784104169346392, Final Batch Loss: 0.09048519283533096\n",
      "Epoch 5744, Loss: 0.1271538883447647, Final Batch Loss: 0.02679034136235714\n",
      "Epoch 5745, Loss: 0.18267012387514114, Final Batch Loss: 0.036381885409355164\n",
      "Epoch 5746, Loss: 0.06907787080854177, Final Batch Loss: 0.026751575991511345\n",
      "Epoch 5747, Loss: 0.07053649751469493, Final Batch Loss: 0.016195017844438553\n",
      "Epoch 5748, Loss: 0.04807286523282528, Final Batch Loss: 0.004864101763814688\n",
      "Epoch 5749, Loss: 0.05410901125287637, Final Batch Loss: 0.0009383144206367433\n",
      "Epoch 5750, Loss: 0.038475921377539635, Final Batch Loss: 0.010378296487033367\n",
      "Epoch 5751, Loss: 0.05670017981901765, Final Batch Loss: 0.016008418053388596\n",
      "Epoch 5752, Loss: 0.04119799565523863, Final Batch Loss: 0.004877968225628138\n",
      "Epoch 5753, Loss: 0.049819262931123376, Final Batch Loss: 0.0031160847283899784\n",
      "Epoch 5754, Loss: 0.06674112193286419, Final Batch Loss: 0.007089251186698675\n",
      "Epoch 5755, Loss: 0.12796079204417765, Final Batch Loss: 0.11965502053499222\n",
      "Epoch 5756, Loss: 0.027977821184322238, Final Batch Loss: 0.0021558820735663176\n",
      "Epoch 5757, Loss: 0.04924942925572395, Final Batch Loss: 0.006284741684794426\n",
      "Epoch 5758, Loss: 0.047937230207026005, Final Batch Loss: 0.035392507910728455\n",
      "Epoch 5759, Loss: 0.01942775514908135, Final Batch Loss: 0.004636600613594055\n",
      "Epoch 5760, Loss: 0.11020218348130584, Final Batch Loss: 0.0792243555188179\n",
      "Epoch 5761, Loss: 0.034685720107518137, Final Batch Loss: 0.01055675558745861\n",
      "Epoch 5762, Loss: 0.026792845921590924, Final Batch Loss: 0.002152550732716918\n",
      "Epoch 5763, Loss: 0.05324627319350839, Final Batch Loss: 0.004481304902583361\n",
      "Epoch 5764, Loss: 0.07979302853345871, Final Batch Loss: 0.004595233127474785\n",
      "Epoch 5765, Loss: 0.018396816914901137, Final Batch Loss: 0.002081858227029443\n",
      "Epoch 5766, Loss: 0.06509797880426049, Final Batch Loss: 0.038344644010066986\n",
      "Epoch 5767, Loss: 0.018723073124419898, Final Batch Loss: 0.0005767074762843549\n",
      "Epoch 5768, Loss: 0.09512031124904752, Final Batch Loss: 0.0022455514408648014\n",
      "Epoch 5769, Loss: 0.035481123719364405, Final Batch Loss: 0.014871916733682156\n",
      "Epoch 5770, Loss: 0.07196411956101656, Final Batch Loss: 0.03531476482748985\n",
      "Epoch 5771, Loss: 0.05510473274625838, Final Batch Loss: 0.0005850887391716242\n",
      "Epoch 5772, Loss: 0.08034834917634726, Final Batch Loss: 0.014027943834662437\n",
      "Epoch 5773, Loss: 0.10318778890359681, Final Batch Loss: 0.00020451440650504082\n",
      "Epoch 5774, Loss: 0.030931484885513783, Final Batch Loss: 0.006642227526754141\n",
      "Epoch 5775, Loss: 0.03677080851048231, Final Batch Loss: 0.009126014076173306\n",
      "Epoch 5776, Loss: 0.031861796509474516, Final Batch Loss: 0.004803906660526991\n",
      "Epoch 5777, Loss: 0.03932139428798109, Final Batch Loss: 0.0014300717739388347\n",
      "Epoch 5778, Loss: 0.03639921173453331, Final Batch Loss: 0.008536002598702908\n",
      "Epoch 5779, Loss: 0.015306357061490417, Final Batch Loss: 0.0007626605220139027\n",
      "Epoch 5780, Loss: 0.03251131798606366, Final Batch Loss: 0.00434451550245285\n",
      "Epoch 5781, Loss: 0.09030785225331783, Final Batch Loss: 0.024711808189749718\n",
      "Epoch 5782, Loss: 0.05120337742846459, Final Batch Loss: 0.00153670075815171\n",
      "Epoch 5783, Loss: 0.05673783179372549, Final Batch Loss: 0.04021625965833664\n",
      "Epoch 5784, Loss: 0.09699422912672162, Final Batch Loss: 0.06976430863142014\n",
      "Epoch 5785, Loss: 0.03508234256878495, Final Batch Loss: 0.005734332371503115\n",
      "Epoch 5786, Loss: 0.03215886140242219, Final Batch Loss: 0.007068050559610128\n",
      "Epoch 5787, Loss: 0.04330253531225026, Final Batch Loss: 0.0021210575941950083\n",
      "Epoch 5788, Loss: 0.01704234816133976, Final Batch Loss: 0.006798570044338703\n",
      "Epoch 5789, Loss: 0.015881350613199174, Final Batch Loss: 0.002065818291157484\n",
      "Epoch 5790, Loss: 0.02018189657246694, Final Batch Loss: 0.0006893695681355894\n",
      "Epoch 5791, Loss: 0.01569228107109666, Final Batch Loss: 0.002971709007397294\n",
      "Epoch 5792, Loss: 0.009208823903463781, Final Batch Loss: 0.0039181518368422985\n",
      "Epoch 5793, Loss: 0.022463032510131598, Final Batch Loss: 0.00245542055927217\n",
      "Epoch 5794, Loss: 0.02582422981504351, Final Batch Loss: 0.0007815120043233037\n",
      "Epoch 5795, Loss: 0.07129432377405465, Final Batch Loss: 0.0470295175909996\n",
      "Epoch 5796, Loss: 0.046547572594136, Final Batch Loss: 0.00874557625502348\n",
      "Epoch 5797, Loss: 0.10923824878409505, Final Batch Loss: 0.03943894803524017\n",
      "Epoch 5798, Loss: 0.07803472084924579, Final Batch Loss: 0.05509297549724579\n",
      "Epoch 5799, Loss: 0.010528288315981627, Final Batch Loss: 0.002114316215738654\n",
      "Epoch 5800, Loss: 0.12226644158363342, Final Batch Loss: 0.033099811524152756\n",
      "Epoch 5801, Loss: 0.0850563207641244, Final Batch Loss: 0.021025653928518295\n",
      "Epoch 5802, Loss: 0.07504396187141538, Final Batch Loss: 0.011548100039362907\n",
      "Epoch 5803, Loss: 0.05136100482195616, Final Batch Loss: 0.006332457531243563\n",
      "Epoch 5804, Loss: 0.0364192184060812, Final Batch Loss: 0.017708003520965576\n",
      "Epoch 5805, Loss: 0.022598593961447477, Final Batch Loss: 0.004101693630218506\n",
      "Epoch 5806, Loss: 0.11156626231968403, Final Batch Loss: 0.006464039906859398\n",
      "Epoch 5807, Loss: 0.0186263183131814, Final Batch Loss: 0.0007119667716324329\n",
      "Epoch 5808, Loss: 0.054002907825633883, Final Batch Loss: 0.004589421208947897\n",
      "Epoch 5809, Loss: 0.0266143842600286, Final Batch Loss: 0.004720046650618315\n",
      "Epoch 5810, Loss: 0.03569863992743194, Final Batch Loss: 0.005773038603365421\n",
      "Epoch 5811, Loss: 0.021554135222686455, Final Batch Loss: 0.00048293053987435997\n",
      "Epoch 5812, Loss: 0.010984107153490186, Final Batch Loss: 0.002583694877102971\n",
      "Epoch 5813, Loss: 0.03374115325277671, Final Batch Loss: 0.02321704849600792\n",
      "Epoch 5814, Loss: 0.008815342735033482, Final Batch Loss: 0.0006991056725382805\n",
      "Epoch 5815, Loss: 0.038429524283856153, Final Batch Loss: 0.002336877165362239\n",
      "Epoch 5816, Loss: 0.03559058188693598, Final Batch Loss: 0.0006623693625442684\n",
      "Epoch 5817, Loss: 0.004830857273191214, Final Batch Loss: 0.0007331717060878873\n",
      "Epoch 5818, Loss: 0.005499388273165096, Final Batch Loss: 9.569485700922087e-05\n",
      "Epoch 5819, Loss: 0.03836320503614843, Final Batch Loss: 0.001297862851060927\n",
      "Epoch 5820, Loss: 0.05868596734944731, Final Batch Loss: 0.01616620644927025\n",
      "Epoch 5821, Loss: 0.023701481171883643, Final Batch Loss: 0.0014224249171093106\n",
      "Epoch 5822, Loss: 0.0158822265220806, Final Batch Loss: 0.004126136656850576\n",
      "Epoch 5823, Loss: 0.009204940870404243, Final Batch Loss: 0.00043404637835919857\n",
      "Epoch 5824, Loss: 0.019116027688141912, Final Batch Loss: 0.001600070158019662\n",
      "Epoch 5825, Loss: 0.018383711110800505, Final Batch Loss: 0.0017131507629528642\n",
      "Epoch 5826, Loss: 0.10343977576121688, Final Batch Loss: 0.068715400993824\n",
      "Epoch 5827, Loss: 0.02479706925805658, Final Batch Loss: 0.007720461115241051\n",
      "Epoch 5828, Loss: 0.041365920566022396, Final Batch Loss: 0.002831178717315197\n",
      "Epoch 5829, Loss: 0.08131931070238352, Final Batch Loss: 0.028737390413880348\n",
      "Epoch 5830, Loss: 0.041895814472809434, Final Batch Loss: 0.007905290462076664\n",
      "Epoch 5831, Loss: 0.042811967665329576, Final Batch Loss: 0.0034506870433688164\n",
      "Epoch 5832, Loss: 0.061964960768818855, Final Batch Loss: 0.004881930071860552\n",
      "Epoch 5833, Loss: 0.03968905040528625, Final Batch Loss: 0.0017206220654770732\n",
      "Epoch 5834, Loss: 0.016366789815947413, Final Batch Loss: 0.003197919111698866\n",
      "Epoch 5835, Loss: 0.035677278181537986, Final Batch Loss: 0.024122042581439018\n",
      "Epoch 5836, Loss: 0.01735360687598586, Final Batch Loss: 0.0030838530510663986\n",
      "Epoch 5837, Loss: 0.09902351070195436, Final Batch Loss: 0.06449060142040253\n",
      "Epoch 5838, Loss: 0.03409293107688427, Final Batch Loss: 0.007681519724428654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5839, Loss: 0.02457971265539527, Final Batch Loss: 0.0022021119948476553\n",
      "Epoch 5840, Loss: 0.07308638980612159, Final Batch Loss: 0.043475378304719925\n",
      "Epoch 5841, Loss: 0.024069361155852675, Final Batch Loss: 0.003509694477543235\n",
      "Epoch 5842, Loss: 0.12317089550197124, Final Batch Loss: 0.0114500243216753\n",
      "Epoch 5843, Loss: 0.034828987903892994, Final Batch Loss: 0.006107976660132408\n",
      "Epoch 5844, Loss: 0.17299164086580276, Final Batch Loss: 0.058124009519815445\n",
      "Epoch 5845, Loss: 0.053273188415914774, Final Batch Loss: 0.02719176560640335\n",
      "Epoch 5846, Loss: 0.09607559675350785, Final Batch Loss: 0.013198099099099636\n",
      "Epoch 5847, Loss: 0.040541364811360836, Final Batch Loss: 0.002133779227733612\n",
      "Epoch 5848, Loss: 0.07713526953011751, Final Batch Loss: 0.06247692182660103\n",
      "Epoch 5849, Loss: 0.027469894150272012, Final Batch Loss: 0.007619213778525591\n",
      "Epoch 5850, Loss: 0.08235671743750572, Final Batch Loss: 0.025976279750466347\n",
      "Epoch 5851, Loss: 0.03716406808234751, Final Batch Loss: 0.0023711363319307566\n",
      "Epoch 5852, Loss: 0.027216900838539004, Final Batch Loss: 0.0018885618774220347\n",
      "Epoch 5853, Loss: 0.02923093200661242, Final Batch Loss: 0.007530380040407181\n",
      "Epoch 5854, Loss: 0.023725902778096497, Final Batch Loss: 0.0012049408396705985\n",
      "Epoch 5855, Loss: 0.026105684228241444, Final Batch Loss: 0.006050814408808947\n",
      "Epoch 5856, Loss: 0.005829165922477841, Final Batch Loss: 0.0012171230046078563\n",
      "Epoch 5857, Loss: 0.016433856450021267, Final Batch Loss: 0.0034349425695836544\n",
      "Epoch 5858, Loss: 0.016947878699284047, Final Batch Loss: 0.00354115292429924\n",
      "Epoch 5859, Loss: 0.028179747983813286, Final Batch Loss: 0.002395930700004101\n",
      "Epoch 5860, Loss: 0.026270587666658685, Final Batch Loss: 0.0003094328276347369\n",
      "Epoch 5861, Loss: 0.0072437397902831435, Final Batch Loss: 0.002520695561543107\n",
      "Epoch 5862, Loss: 0.012852092302637175, Final Batch Loss: 0.0002474783395882696\n",
      "Epoch 5863, Loss: 0.016144686145707965, Final Batch Loss: 0.00419966597110033\n",
      "Epoch 5864, Loss: 0.03405672637745738, Final Batch Loss: 0.00095566944219172\n",
      "Epoch 5865, Loss: 0.008099292637780309, Final Batch Loss: 0.002849382348358631\n",
      "Epoch 5866, Loss: 0.07122186536435038, Final Batch Loss: 0.023396503180265427\n",
      "Epoch 5867, Loss: 0.0065876502194441855, Final Batch Loss: 0.001894400455057621\n",
      "Epoch 5868, Loss: 0.043603734113276005, Final Batch Loss: 0.0008058904204517603\n",
      "Epoch 5869, Loss: 0.058547696215100586, Final Batch Loss: 0.024117186665534973\n",
      "Epoch 5870, Loss: 0.006955065997317433, Final Batch Loss: 0.002371822018176317\n",
      "Epoch 5871, Loss: 0.01801760110538453, Final Batch Loss: 0.007276949472725391\n",
      "Epoch 5872, Loss: 0.011237809609156102, Final Batch Loss: 0.0028353221714496613\n",
      "Epoch 5873, Loss: 0.02322673739399761, Final Batch Loss: 0.001356234191916883\n",
      "Epoch 5874, Loss: 0.06905750010628253, Final Batch Loss: 0.0008441481040790677\n",
      "Epoch 5875, Loss: 0.04454251658171415, Final Batch Loss: 0.01623104140162468\n",
      "Epoch 5876, Loss: 0.023302550078369677, Final Batch Loss: 0.0029645119793713093\n",
      "Epoch 5877, Loss: 0.051305734436027706, Final Batch Loss: 0.02444598264992237\n",
      "Epoch 5878, Loss: 0.03040902758948505, Final Batch Loss: 0.0013827511575073004\n",
      "Epoch 5879, Loss: 0.011075299349613488, Final Batch Loss: 0.0016444199718534946\n",
      "Epoch 5880, Loss: 0.03537108888849616, Final Batch Loss: 0.01332863699644804\n",
      "Epoch 5881, Loss: 0.03390512359328568, Final Batch Loss: 0.008441081270575523\n",
      "Epoch 5882, Loss: 0.051971789682284, Final Batch Loss: 0.002429687650874257\n",
      "Epoch 5883, Loss: 0.05260299626388587, Final Batch Loss: 0.00038044751272536814\n",
      "Epoch 5884, Loss: 0.08435635600471869, Final Batch Loss: 0.06871750205755234\n",
      "Epoch 5885, Loss: 0.02698999980930239, Final Batch Loss: 0.001502903294749558\n",
      "Epoch 5886, Loss: 0.01761706208344549, Final Batch Loss: 0.006764748599380255\n",
      "Epoch 5887, Loss: 0.0181307791499421, Final Batch Loss: 0.0006746103754267097\n",
      "Epoch 5888, Loss: 0.04250310081988573, Final Batch Loss: 0.005283718463033438\n",
      "Epoch 5889, Loss: 0.022128898999653757, Final Batch Loss: 0.0010584706906229258\n",
      "Epoch 5890, Loss: 0.019335140474140644, Final Batch Loss: 0.007930717431008816\n",
      "Epoch 5891, Loss: 0.0552286701858975, Final Batch Loss: 0.012781430967152119\n",
      "Epoch 5892, Loss: 0.018527945037931204, Final Batch Loss: 0.0028387648053467274\n",
      "Epoch 5893, Loss: 0.02314596436917782, Final Batch Loss: 0.0028971564024686813\n",
      "Epoch 5894, Loss: 0.07445352687500417, Final Batch Loss: 0.041601572185754776\n",
      "Epoch 5895, Loss: 0.06712141330353916, Final Batch Loss: 0.024489590898156166\n",
      "Epoch 5896, Loss: 0.02038506034296006, Final Batch Loss: 0.009766321629285812\n",
      "Epoch 5897, Loss: 0.05111622659023851, Final Batch Loss: 0.007924068719148636\n",
      "Epoch 5898, Loss: 0.04246166301891208, Final Batch Loss: 0.011639050208032131\n",
      "Epoch 5899, Loss: 0.07316783629357815, Final Batch Loss: 0.021288486197590828\n",
      "Epoch 5900, Loss: 0.04197354335337877, Final Batch Loss: 0.010638052597641945\n",
      "Epoch 5901, Loss: 0.06278064893558621, Final Batch Loss: 0.0016992627643048763\n",
      "Epoch 5902, Loss: 0.022272289730608463, Final Batch Loss: 0.004206676501780748\n",
      "Epoch 5903, Loss: 0.010967733222059906, Final Batch Loss: 0.0024471827782690525\n",
      "Epoch 5904, Loss: 0.01334209821652621, Final Batch Loss: 0.0007361394818872213\n",
      "Epoch 5905, Loss: 0.03040202148258686, Final Batch Loss: 0.004945495165884495\n",
      "Epoch 5906, Loss: 0.02716248924843967, Final Batch Loss: 0.002327475231140852\n",
      "Epoch 5907, Loss: 0.016945171228144318, Final Batch Loss: 0.003961671143770218\n",
      "Epoch 5908, Loss: 0.016026743687689304, Final Batch Loss: 0.003891914850100875\n",
      "Epoch 5909, Loss: 0.0313680509570986, Final Batch Loss: 0.015701916068792343\n",
      "Epoch 5910, Loss: 0.01761330894078128, Final Batch Loss: 0.00012670780415646732\n",
      "Epoch 5911, Loss: 0.012812883942387998, Final Batch Loss: 0.000529893790371716\n",
      "Epoch 5912, Loss: 0.015063157537952065, Final Batch Loss: 0.006711589638143778\n",
      "Epoch 5913, Loss: 0.02350113235297613, Final Batch Loss: 0.00034115181188099086\n",
      "Epoch 5914, Loss: 0.004180125790298916, Final Batch Loss: 9.404816955793649e-05\n",
      "Epoch 5915, Loss: 0.004965691710822284, Final Batch Loss: 0.0011611864902079105\n",
      "Epoch 5916, Loss: 0.007294897281099111, Final Batch Loss: 0.0034512835554778576\n",
      "Epoch 5917, Loss: 0.03949525058851577, Final Batch Loss: 0.035568688064813614\n",
      "Epoch 5918, Loss: 0.007911480468465015, Final Batch Loss: 0.00034801880246959627\n",
      "Epoch 5919, Loss: 0.008436469710431993, Final Batch Loss: 0.0008833912434056401\n",
      "Epoch 5920, Loss: 0.05176283622859046, Final Batch Loss: 0.029818128794431686\n",
      "Epoch 5921, Loss: 0.07061664899811149, Final Batch Loss: 0.0340065136551857\n",
      "Epoch 5922, Loss: 0.007140465953852981, Final Batch Loss: 0.0029578208923339844\n",
      "Epoch 5923, Loss: 0.06069790874607861, Final Batch Loss: 0.03272293508052826\n",
      "Epoch 5924, Loss: 0.019135749200358987, Final Batch Loss: 0.0012375838123261929\n",
      "Epoch 5925, Loss: 0.0509228256996721, Final Batch Loss: 0.013973983936011791\n",
      "Epoch 5926, Loss: 0.04255800659302622, Final Batch Loss: 0.02228572592139244\n",
      "Epoch 5927, Loss: 0.013910439214669168, Final Batch Loss: 0.0012018367415294051\n",
      "Epoch 5928, Loss: 0.07827149983495474, Final Batch Loss: 0.015206347219645977\n",
      "Epoch 5929, Loss: 0.049048015964217484, Final Batch Loss: 0.02433113195002079\n",
      "Epoch 5930, Loss: 0.04997174387972336, Final Batch Loss: 0.0001544434780953452\n",
      "Epoch 5931, Loss: 0.021932504198048264, Final Batch Loss: 0.0006788485334254801\n",
      "Epoch 5932, Loss: 0.09039208805188537, Final Batch Loss: 0.022644121199846268\n",
      "Epoch 5933, Loss: 0.09001635247841477, Final Batch Loss: 0.004751128610223532\n",
      "Epoch 5934, Loss: 0.05447351676411927, Final Batch Loss: 0.036977220326662064\n",
      "Epoch 5935, Loss: 0.12241557927336544, Final Batch Loss: 0.0019235940417274833\n",
      "Epoch 5936, Loss: 0.24052558303810656, Final Batch Loss: 0.15805228054523468\n",
      "Epoch 5937, Loss: 0.06079697050154209, Final Batch Loss: 0.024209991097450256\n",
      "Epoch 5938, Loss: 0.09138915361836553, Final Batch Loss: 0.001220040488988161\n",
      "Epoch 5939, Loss: 0.05032216454856098, Final Batch Loss: 0.003225162858143449\n",
      "Epoch 5940, Loss: 0.04269233159720898, Final Batch Loss: 0.005652375984936953\n",
      "Epoch 5941, Loss: 0.03532909322530031, Final Batch Loss: 0.009907188825309277\n",
      "Epoch 5942, Loss: 0.02670094498898834, Final Batch Loss: 0.0017997875111177564\n",
      "Epoch 5943, Loss: 0.017178974114358425, Final Batch Loss: 0.0005070599727332592\n",
      "Epoch 5944, Loss: 0.016058403067290783, Final Batch Loss: 0.01007635984569788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5945, Loss: 0.03078758460469544, Final Batch Loss: 0.001065725227817893\n",
      "Epoch 5946, Loss: 0.04352236131671816, Final Batch Loss: 0.000403624027967453\n",
      "Epoch 5947, Loss: 0.02580495667643845, Final Batch Loss: 0.01925211399793625\n",
      "Epoch 5948, Loss: 0.023040530213620514, Final Batch Loss: 0.00020005862461403012\n",
      "Epoch 5949, Loss: 0.046599026303738356, Final Batch Loss: 0.012782572768628597\n",
      "Epoch 5950, Loss: 0.013689784682355821, Final Batch Loss: 0.0018754040356725454\n",
      "Epoch 5951, Loss: 0.040583078283816576, Final Batch Loss: 0.00043479003943502903\n",
      "Epoch 5952, Loss: 0.056097275111824274, Final Batch Loss: 0.009083622135221958\n",
      "Epoch 5953, Loss: 0.03203005250543356, Final Batch Loss: 0.0018651606515049934\n",
      "Epoch 5954, Loss: 0.022832654853118584, Final Batch Loss: 0.0003820978745352477\n",
      "Epoch 5955, Loss: 0.025303991744294763, Final Batch Loss: 0.001277766190469265\n",
      "Epoch 5956, Loss: 0.04345581214874983, Final Batch Loss: 0.03570012003183365\n",
      "Epoch 5957, Loss: 0.03940840158611536, Final Batch Loss: 0.0031782116275280714\n",
      "Epoch 5958, Loss: 0.0382388568832539, Final Batch Loss: 0.0018393397331237793\n",
      "Epoch 5959, Loss: 0.023467818973585963, Final Batch Loss: 0.0016868745442479849\n",
      "Epoch 5960, Loss: 0.010711658222135156, Final Batch Loss: 0.0068283951841294765\n",
      "Epoch 5961, Loss: 0.04330440185731277, Final Batch Loss: 0.005920571740716696\n",
      "Epoch 5962, Loss: 0.03922382328892127, Final Batch Loss: 0.022920267656445503\n",
      "Epoch 5963, Loss: 0.03862980887060985, Final Batch Loss: 0.001863089855760336\n",
      "Epoch 5964, Loss: 0.03658864297904074, Final Batch Loss: 0.0023453200701624155\n",
      "Epoch 5965, Loss: 0.027341366978362203, Final Batch Loss: 0.0006576756713911891\n",
      "Epoch 5966, Loss: 0.020768897840753198, Final Batch Loss: 0.008952449075877666\n",
      "Epoch 5967, Loss: 0.04815144999884069, Final Batch Loss: 0.002683772472664714\n",
      "Epoch 5968, Loss: 0.02827216312289238, Final Batch Loss: 0.002752200933173299\n",
      "Epoch 5969, Loss: 0.011445229407399893, Final Batch Loss: 0.0013211281038820744\n",
      "Epoch 5970, Loss: 0.006066138215828687, Final Batch Loss: 0.0002555703395046294\n",
      "Epoch 5971, Loss: 0.015260676940670237, Final Batch Loss: 0.0005609109648503363\n",
      "Epoch 5972, Loss: 0.041588591411709785, Final Batch Loss: 0.003667033975943923\n",
      "Epoch 5973, Loss: 0.028228751616552472, Final Batch Loss: 0.014742964878678322\n",
      "Epoch 5974, Loss: 0.07126086484640837, Final Batch Loss: 0.04903654381632805\n",
      "Epoch 5975, Loss: 0.1043993717757985, Final Batch Loss: 0.08960931748151779\n",
      "Epoch 5976, Loss: 0.004692753951530904, Final Batch Loss: 0.0004266354371793568\n",
      "Epoch 5977, Loss: 0.019739322422537953, Final Batch Loss: 0.0005488847964443266\n",
      "Epoch 5978, Loss: 0.018125702044926584, Final Batch Loss: 0.012428824789822102\n",
      "Epoch 5979, Loss: 0.02850699017290026, Final Batch Loss: 0.0013179854722693563\n",
      "Epoch 5980, Loss: 0.03580811637220904, Final Batch Loss: 0.0017550986958667636\n",
      "Epoch 5981, Loss: 0.017874499084427953, Final Batch Loss: 0.005029092542827129\n",
      "Epoch 5982, Loss: 0.005977387831080705, Final Batch Loss: 0.0017454882618039846\n",
      "Epoch 5983, Loss: 0.02596548749716021, Final Batch Loss: 0.00016296879039146006\n",
      "Epoch 5984, Loss: 0.01359524519648403, Final Batch Loss: 0.0006736036157235503\n",
      "Epoch 5985, Loss: 0.06040189042687416, Final Batch Loss: 0.04290178045630455\n",
      "Epoch 5986, Loss: 0.009821692248806357, Final Batch Loss: 0.004778545815497637\n",
      "Epoch 5987, Loss: 0.0639057767111808, Final Batch Loss: 0.012126677669584751\n",
      "Epoch 5988, Loss: 0.03346188453724608, Final Batch Loss: 0.0004823807976208627\n",
      "Epoch 5989, Loss: 0.013257911778055131, Final Batch Loss: 0.0014666366623714566\n",
      "Epoch 5990, Loss: 0.021082689054310322, Final Batch Loss: 0.0035954578779637814\n",
      "Epoch 5991, Loss: 0.01831639464944601, Final Batch Loss: 0.0028942092321813107\n",
      "Epoch 5992, Loss: 0.009522331762127578, Final Batch Loss: 0.0007938669878058136\n",
      "Epoch 5993, Loss: 0.006325996189843863, Final Batch Loss: 0.0008440730161964893\n",
      "Epoch 5994, Loss: 0.04482167249079794, Final Batch Loss: 0.0011671114480122924\n",
      "Epoch 5995, Loss: 0.0069463339750654995, Final Batch Loss: 0.00036900921259075403\n",
      "Epoch 5996, Loss: 0.030200515349861234, Final Batch Loss: 0.005182047840207815\n",
      "Epoch 5997, Loss: 0.03877116026706062, Final Batch Loss: 0.02935883030295372\n",
      "Epoch 5998, Loss: 0.009085182216949761, Final Batch Loss: 0.0013235820224508643\n",
      "Epoch 5999, Loss: 0.08152585732750595, Final Batch Loss: 0.005355095490813255\n",
      "Epoch 6000, Loss: 0.019256044062785804, Final Batch Loss: 0.010985413566231728\n",
      "Epoch 6001, Loss: 0.009875099698547274, Final Batch Loss: 0.002811721060425043\n",
      "Epoch 6002, Loss: 0.09863477479666471, Final Batch Loss: 0.035273414105176926\n",
      "Epoch 6003, Loss: 0.007624080404639244, Final Batch Loss: 0.0029554881621152163\n",
      "Epoch 6004, Loss: 0.018428347422741354, Final Batch Loss: 0.01307846698909998\n",
      "Epoch 6005, Loss: 0.03034972120076418, Final Batch Loss: 0.018495386466383934\n",
      "Epoch 6006, Loss: 0.07635623216629028, Final Batch Loss: 0.014077209867537022\n",
      "Epoch 6007, Loss: 0.00693758181296289, Final Batch Loss: 0.002038904232904315\n",
      "Epoch 6008, Loss: 0.03385879535926506, Final Batch Loss: 0.0008463297854177654\n",
      "Epoch 6009, Loss: 0.019951945985667408, Final Batch Loss: 0.0015410514315590262\n",
      "Epoch 6010, Loss: 0.027387448819354177, Final Batch Loss: 0.012488678097724915\n",
      "Epoch 6011, Loss: 0.006401542108505964, Final Batch Loss: 0.002353984396904707\n",
      "Epoch 6012, Loss: 0.0200553466565907, Final Batch Loss: 0.014980634674429893\n",
      "Epoch 6013, Loss: 0.022451379627455026, Final Batch Loss: 0.01667161099612713\n",
      "Epoch 6014, Loss: 0.008856604719767347, Final Batch Loss: 0.002325119450688362\n",
      "Epoch 6015, Loss: 0.03471871104557067, Final Batch Loss: 0.01493045873939991\n",
      "Epoch 6016, Loss: 0.033985917340032756, Final Batch Loss: 0.021515341475605965\n",
      "Epoch 6017, Loss: 0.028370303101837635, Final Batch Loss: 0.0012971155811101198\n",
      "Epoch 6018, Loss: 0.009399391594342887, Final Batch Loss: 0.0041869389824569225\n",
      "Epoch 6019, Loss: 0.053898250218480825, Final Batch Loss: 0.02383676916360855\n",
      "Epoch 6020, Loss: 0.008631115080788732, Final Batch Loss: 0.0013622080441564322\n",
      "Epoch 6021, Loss: 0.03541731275618076, Final Batch Loss: 0.005019031465053558\n",
      "Epoch 6022, Loss: 0.0261312706861645, Final Batch Loss: 0.006386014632880688\n",
      "Epoch 6023, Loss: 0.008570323407184333, Final Batch Loss: 0.0005442817346192896\n",
      "Epoch 6024, Loss: 0.003656997490907088, Final Batch Loss: 0.0002689831017050892\n",
      "Epoch 6025, Loss: 0.0487170594278723, Final Batch Loss: 0.0021664940286427736\n",
      "Epoch 6026, Loss: 0.02134039346128702, Final Batch Loss: 0.0009585125371813774\n",
      "Epoch 6027, Loss: 0.011091368272900581, Final Batch Loss: 0.0006079529412090778\n",
      "Epoch 6028, Loss: 0.04948729951865971, Final Batch Loss: 0.0021373373456299305\n",
      "Epoch 6029, Loss: 0.022264648869168013, Final Batch Loss: 0.01644037291407585\n",
      "Epoch 6030, Loss: 0.021927953115664423, Final Batch Loss: 0.0009410333586856723\n",
      "Epoch 6031, Loss: 0.022065743716666475, Final Batch Loss: 0.005514351651072502\n",
      "Epoch 6032, Loss: 0.006656379060586914, Final Batch Loss: 0.000287754024611786\n",
      "Epoch 6033, Loss: 0.01305324281565845, Final Batch Loss: 0.001248304732143879\n",
      "Epoch 6034, Loss: 0.06787871313281357, Final Batch Loss: 0.007945289835333824\n",
      "Epoch 6035, Loss: 0.0321742357336916, Final Batch Loss: 0.002119180979207158\n",
      "Epoch 6036, Loss: 0.020352310733869672, Final Batch Loss: 0.0028315309900790453\n",
      "Epoch 6037, Loss: 0.05814443633425981, Final Batch Loss: 0.00120924215298146\n",
      "Epoch 6038, Loss: 0.012997633952181786, Final Batch Loss: 0.0005333669832907617\n",
      "Epoch 6039, Loss: 0.016716213489416987, Final Batch Loss: 0.0007524891407229006\n",
      "Epoch 6040, Loss: 0.029990097973495722, Final Batch Loss: 0.001462798798456788\n",
      "Epoch 6041, Loss: 0.00637320225359872, Final Batch Loss: 0.0011079300893470645\n",
      "Epoch 6042, Loss: 0.0076219107722863555, Final Batch Loss: 0.0012491816887632012\n",
      "Epoch 6043, Loss: 0.059939540675259195, Final Batch Loss: 0.00016618891095276922\n",
      "Epoch 6044, Loss: 0.01503877918003127, Final Batch Loss: 0.0033167980145663023\n",
      "Epoch 6045, Loss: 0.02197009534575045, Final Batch Loss: 0.002263892674818635\n",
      "Epoch 6046, Loss: 0.043120775517309085, Final Batch Loss: 0.036324769258499146\n",
      "Epoch 6047, Loss: 0.021042783744633198, Final Batch Loss: 0.0010529626160860062\n",
      "Epoch 6048, Loss: 0.015208006836473942, Final Batch Loss: 0.0030294174794107676\n",
      "Epoch 6049, Loss: 0.025564606941770762, Final Batch Loss: 0.00032707868376746774\n",
      "Epoch 6050, Loss: 0.007977277622558177, Final Batch Loss: 0.0025705948937684298\n",
      "Epoch 6051, Loss: 0.19380849041044712, Final Batch Loss: 0.06710748374462128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6052, Loss: 0.0412069542799145, Final Batch Loss: 0.00320833339355886\n",
      "Epoch 6053, Loss: 0.01658839685842395, Final Batch Loss: 0.0026603322476148605\n",
      "Epoch 6054, Loss: 0.03673540591262281, Final Batch Loss: 0.004109400790184736\n",
      "Epoch 6055, Loss: 0.07033325638622046, Final Batch Loss: 0.007224179804325104\n",
      "Epoch 6056, Loss: 0.0507182537112385, Final Batch Loss: 0.026554102078080177\n",
      "Epoch 6057, Loss: 0.06354783824644983, Final Batch Loss: 0.027037693187594414\n",
      "Epoch 6058, Loss: 0.0745017696171999, Final Batch Loss: 0.051976148039102554\n",
      "Epoch 6059, Loss: 0.049964062753133476, Final Batch Loss: 0.0011309342226013541\n",
      "Epoch 6060, Loss: 0.06287849950604141, Final Batch Loss: 0.050459884107112885\n",
      "Epoch 6061, Loss: 0.01783921627793461, Final Batch Loss: 0.0011516480008140206\n",
      "Epoch 6062, Loss: 0.03931227803695947, Final Batch Loss: 0.0014056704239919782\n",
      "Epoch 6063, Loss: 0.04851061734370887, Final Batch Loss: 0.005301065742969513\n",
      "Epoch 6064, Loss: 0.015294604701921344, Final Batch Loss: 0.0007220432162284851\n",
      "Epoch 6065, Loss: 0.024283051025122404, Final Batch Loss: 0.005753280594944954\n",
      "Epoch 6066, Loss: 0.025779169285669923, Final Batch Loss: 0.006650567054748535\n",
      "Epoch 6067, Loss: 0.01694994792342186, Final Batch Loss: 0.004459204617887735\n",
      "Epoch 6068, Loss: 0.025219033006578684, Final Batch Loss: 0.002646051114425063\n",
      "Epoch 6069, Loss: 0.022479097358882427, Final Batch Loss: 0.0053506637923419476\n",
      "Epoch 6070, Loss: 0.031153407762758434, Final Batch Loss: 0.0006315261125564575\n",
      "Epoch 6071, Loss: 0.01863366283942014, Final Batch Loss: 0.001846074708737433\n",
      "Epoch 6072, Loss: 0.033160195176606067, Final Batch Loss: 0.00019549317948985845\n",
      "Epoch 6073, Loss: 0.03211302452837117, Final Batch Loss: 0.001604336779564619\n",
      "Epoch 6074, Loss: 0.046598311979323626, Final Batch Loss: 0.003987339325249195\n",
      "Epoch 6075, Loss: 0.05817174166440964, Final Batch Loss: 0.027693212032318115\n",
      "Epoch 6076, Loss: 0.03451473859604448, Final Batch Loss: 0.0004510545404627919\n",
      "Epoch 6077, Loss: 0.009933927256497554, Final Batch Loss: 0.00013409093662630767\n",
      "Epoch 6078, Loss: 0.042466173181310296, Final Batch Loss: 0.02110835537314415\n",
      "Epoch 6079, Loss: 0.005754005251219496, Final Batch Loss: 0.001925420481711626\n",
      "Epoch 6080, Loss: 0.016386711416998878, Final Batch Loss: 0.0004754495166707784\n",
      "Epoch 6081, Loss: 0.012058522406732664, Final Batch Loss: 0.0003104191564489156\n",
      "Epoch 6082, Loss: 0.01068466153810732, Final Batch Loss: 0.0002113035588990897\n",
      "Epoch 6083, Loss: 0.008302329515572637, Final Batch Loss: 0.000613239302765578\n",
      "Epoch 6084, Loss: 0.045787556446157396, Final Batch Loss: 0.0014722910709679127\n",
      "Epoch 6085, Loss: 0.012149130154284649, Final Batch Loss: 0.0001559860975248739\n",
      "Epoch 6086, Loss: 0.03775357635458931, Final Batch Loss: 0.0006698378711007535\n",
      "Epoch 6087, Loss: 0.014466042397543788, Final Batch Loss: 0.004053821321576834\n",
      "Epoch 6088, Loss: 0.04740007082000375, Final Batch Loss: 0.0344248041510582\n",
      "Epoch 6089, Loss: 0.021543172377278097, Final Batch Loss: 0.00011784159869421273\n",
      "Epoch 6090, Loss: 0.027015209547244012, Final Batch Loss: 0.0005352449370548129\n",
      "Epoch 6091, Loss: 0.02143414062447846, Final Batch Loss: 0.003443170106038451\n",
      "Epoch 6092, Loss: 0.03880126541480422, Final Batch Loss: 0.0032678304705768824\n",
      "Epoch 6093, Loss: 0.012472385889850557, Final Batch Loss: 0.0041471379809081554\n",
      "Epoch 6094, Loss: 0.009800421597901732, Final Batch Loss: 0.00032157922396436334\n",
      "Epoch 6095, Loss: 0.06185991084203124, Final Batch Loss: 0.016097214072942734\n",
      "Epoch 6096, Loss: 0.054606870748102665, Final Batch Loss: 0.005102498456835747\n",
      "Epoch 6097, Loss: 0.06976486771600321, Final Batch Loss: 0.03936305269598961\n",
      "Epoch 6098, Loss: 0.03618100180756301, Final Batch Loss: 0.0015873574884608388\n",
      "Epoch 6099, Loss: 0.03598768508527428, Final Batch Loss: 0.0013694671215489507\n",
      "Epoch 6100, Loss: 0.0378206935711205, Final Batch Loss: 0.007236036472022533\n",
      "Epoch 6101, Loss: 0.02487187134101987, Final Batch Loss: 0.007854497991502285\n",
      "Epoch 6102, Loss: 0.021962155675282702, Final Batch Loss: 0.00038021974614821374\n",
      "Epoch 6103, Loss: 0.057989386725239456, Final Batch Loss: 0.0017999052070081234\n",
      "Epoch 6104, Loss: 0.14554827730171382, Final Batch Loss: 0.10727371275424957\n",
      "Epoch 6105, Loss: 0.03542420803569257, Final Batch Loss: 0.003433954669162631\n",
      "Epoch 6106, Loss: 0.19993192702531815, Final Batch Loss: 0.040642429143190384\n",
      "Epoch 6107, Loss: 0.0432100000907667, Final Batch Loss: 0.025474758818745613\n",
      "Epoch 6108, Loss: 0.13966856570914388, Final Batch Loss: 0.004545286763459444\n",
      "Epoch 6109, Loss: 0.09033151145558804, Final Batch Loss: 0.06705258786678314\n",
      "Epoch 6110, Loss: 0.1059179687872529, Final Batch Loss: 0.018544478341937065\n",
      "Epoch 6111, Loss: 0.037849443731829524, Final Batch Loss: 0.0029118647798895836\n",
      "Epoch 6112, Loss: 0.07459064666181803, Final Batch Loss: 0.029094310477375984\n",
      "Epoch 6113, Loss: 0.13581436034291983, Final Batch Loss: 0.006656280718743801\n",
      "Epoch 6114, Loss: 0.037442128639668226, Final Batch Loss: 0.007626460865139961\n",
      "Epoch 6115, Loss: 0.06103675253689289, Final Batch Loss: 0.01121820043772459\n",
      "Epoch 6116, Loss: 0.05048853624612093, Final Batch Loss: 0.002913965377956629\n",
      "Epoch 6117, Loss: 0.04991057119332254, Final Batch Loss: 0.0025025957729667425\n",
      "Epoch 6118, Loss: 0.02935147937387228, Final Batch Loss: 0.0024560177698731422\n",
      "Epoch 6119, Loss: 0.06705263652838767, Final Batch Loss: 0.028190327808260918\n",
      "Epoch 6120, Loss: 0.027308521006489173, Final Batch Loss: 0.0004445814120117575\n",
      "Epoch 6121, Loss: 0.04148806247394532, Final Batch Loss: 0.0011635712580755353\n",
      "Epoch 6122, Loss: 0.021442845347337425, Final Batch Loss: 0.009050878696143627\n",
      "Epoch 6123, Loss: 0.025373760727234185, Final Batch Loss: 0.0006203463999554515\n",
      "Epoch 6124, Loss: 0.03384672850370407, Final Batch Loss: 0.0016283977311104536\n",
      "Epoch 6125, Loss: 0.021012699231505394, Final Batch Loss: 0.0146074453368783\n",
      "Epoch 6126, Loss: 0.010919814521912485, Final Batch Loss: 0.0005846343701705337\n",
      "Epoch 6127, Loss: 0.035927232122048736, Final Batch Loss: 0.01168772391974926\n",
      "Epoch 6128, Loss: 0.06603706255555153, Final Batch Loss: 0.031583093106746674\n",
      "Epoch 6129, Loss: 0.10520637966692448, Final Batch Loss: 0.08505070209503174\n",
      "Epoch 6130, Loss: 0.03848826000466943, Final Batch Loss: 0.005423801951110363\n",
      "Epoch 6131, Loss: 0.06602281145751476, Final Batch Loss: 0.011980139650404453\n",
      "Epoch 6132, Loss: 0.19159691594541073, Final Batch Loss: 0.0019899550825357437\n",
      "Epoch 6133, Loss: 0.04199634911492467, Final Batch Loss: 0.002743102377280593\n",
      "Epoch 6134, Loss: 0.06135218683630228, Final Batch Loss: 0.0013961996883153915\n",
      "Epoch 6135, Loss: 0.03987638955004513, Final Batch Loss: 0.0020161152351647615\n",
      "Epoch 6136, Loss: 0.06548292224761099, Final Batch Loss: 0.001251522800885141\n",
      "Epoch 6137, Loss: 0.06452550925314426, Final Batch Loss: 0.006474535446614027\n",
      "Epoch 6138, Loss: 0.02927379916945938, Final Batch Loss: 0.00018006192112807184\n",
      "Epoch 6139, Loss: 0.04546826228033751, Final Batch Loss: 0.0013751807855442166\n",
      "Epoch 6140, Loss: 0.08860609284602106, Final Batch Loss: 0.03560373932123184\n",
      "Epoch 6141, Loss: 0.06497261539334431, Final Batch Loss: 0.0007941392832435668\n",
      "Epoch 6142, Loss: 0.08429365698248148, Final Batch Loss: 0.03616049885749817\n",
      "Epoch 6143, Loss: 0.032653565518558025, Final Batch Loss: 0.0013970313593745232\n",
      "Epoch 6144, Loss: 0.02522080624476075, Final Batch Loss: 0.0023292982950806618\n",
      "Epoch 6145, Loss: 0.058284570928663015, Final Batch Loss: 0.01997949555516243\n",
      "Epoch 6146, Loss: 0.0246133035980165, Final Batch Loss: 0.002490473911166191\n",
      "Epoch 6147, Loss: 0.07066565030254424, Final Batch Loss: 0.011361747048795223\n",
      "Epoch 6148, Loss: 0.03534719749586657, Final Batch Loss: 0.0009127036319114268\n",
      "Epoch 6149, Loss: 0.04716636589728296, Final Batch Loss: 0.0238332636654377\n",
      "Epoch 6150, Loss: 0.03024546301458031, Final Batch Loss: 0.008628694340586662\n",
      "Epoch 6151, Loss: 0.015849463175982237, Final Batch Loss: 0.0033758184872567654\n",
      "Epoch 6152, Loss: 0.012911336991237476, Final Batch Loss: 0.00031193942413665354\n",
      "Epoch 6153, Loss: 0.03938795045542065, Final Batch Loss: 0.00019047434034291655\n",
      "Epoch 6154, Loss: 0.03156654816120863, Final Batch Loss: 0.002318300772458315\n",
      "Epoch 6155, Loss: 0.04134825197979808, Final Batch Loss: 0.010317198932170868\n",
      "Epoch 6156, Loss: 0.0637778292875737, Final Batch Loss: 0.02502441592514515\n",
      "Epoch 6157, Loss: 0.019113573827780783, Final Batch Loss: 0.004770996049046516\n",
      "Epoch 6158, Loss: 0.022492739255540073, Final Batch Loss: 0.007951293140649796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6159, Loss: 0.026506608235649765, Final Batch Loss: 0.001415763865225017\n",
      "Epoch 6160, Loss: 0.012747698347084224, Final Batch Loss: 0.0037962477654218674\n",
      "Epoch 6161, Loss: 0.03924102056771517, Final Batch Loss: 0.0020154465455561876\n",
      "Epoch 6162, Loss: 0.01204679673537612, Final Batch Loss: 0.007873762398958206\n",
      "Epoch 6163, Loss: 0.012968897412065417, Final Batch Loss: 0.0007701805443502963\n",
      "Epoch 6164, Loss: 0.04983743355842307, Final Batch Loss: 0.04370090365409851\n",
      "Epoch 6165, Loss: 0.028154352970886976, Final Batch Loss: 0.008103512227535248\n",
      "Epoch 6166, Loss: 0.025477490795310587, Final Batch Loss: 0.0006834307569079101\n",
      "Epoch 6167, Loss: 0.0606701853685081, Final Batch Loss: 0.035170044749975204\n",
      "Epoch 6168, Loss: 0.018991526449099183, Final Batch Loss: 0.009880634024739265\n",
      "Epoch 6169, Loss: 0.044222119729965925, Final Batch Loss: 0.012351945042610168\n",
      "Epoch 6170, Loss: 0.042125683510676026, Final Batch Loss: 0.001876521622762084\n",
      "Epoch 6171, Loss: 0.052595977671444416, Final Batch Loss: 0.00399466697126627\n",
      "Epoch 6172, Loss: 0.01756118843331933, Final Batch Loss: 0.0051504746079444885\n",
      "Epoch 6173, Loss: 0.04523535061161965, Final Batch Loss: 0.0006545941578224301\n",
      "Epoch 6174, Loss: 0.1358171822503209, Final Batch Loss: 0.1064448207616806\n",
      "Epoch 6175, Loss: 0.013025227061007172, Final Batch Loss: 0.0008230473031289876\n",
      "Epoch 6176, Loss: 0.06352818920277059, Final Batch Loss: 0.0038400364574044943\n",
      "Epoch 6177, Loss: 0.08264944143593311, Final Batch Loss: 0.04518307000398636\n",
      "Epoch 6178, Loss: 0.03972772927954793, Final Batch Loss: 0.0008239423623308539\n",
      "Epoch 6179, Loss: 0.033023697789758444, Final Batch Loss: 0.0055034286342561245\n",
      "Epoch 6180, Loss: 0.020297617418691516, Final Batch Loss: 0.007935699075460434\n",
      "Epoch 6181, Loss: 0.012201012461446226, Final Batch Loss: 0.001122761401347816\n",
      "Epoch 6182, Loss: 0.017742411873769015, Final Batch Loss: 0.0054991585202515125\n",
      "Epoch 6183, Loss: 0.009909077227348462, Final Batch Loss: 0.0004402104823384434\n",
      "Epoch 6184, Loss: 0.012595957610756159, Final Batch Loss: 0.0011165277101099491\n",
      "Epoch 6185, Loss: 0.06923653068952262, Final Batch Loss: 0.0017297426238656044\n",
      "Epoch 6186, Loss: 0.02971475850790739, Final Batch Loss: 0.0013819400919601321\n",
      "Epoch 6187, Loss: 0.024568064021877944, Final Batch Loss: 0.013924675062298775\n",
      "Epoch 6188, Loss: 0.010103909124154598, Final Batch Loss: 0.00022294215159490705\n",
      "Epoch 6189, Loss: 0.015286725480109453, Final Batch Loss: 0.0013569642324000597\n",
      "Epoch 6190, Loss: 0.014403310138732195, Final Batch Loss: 0.0055823796428740025\n",
      "Epoch 6191, Loss: 0.025304549373686314, Final Batch Loss: 0.00986373983323574\n",
      "Epoch 6192, Loss: 0.04422056028852239, Final Batch Loss: 0.004143096506595612\n",
      "Epoch 6193, Loss: 0.02104809373850003, Final Batch Loss: 0.0004216308589093387\n",
      "Epoch 6194, Loss: 0.012791133602149785, Final Batch Loss: 0.004443823359906673\n",
      "Epoch 6195, Loss: 0.005891088119824417, Final Batch Loss: 0.0004440684278961271\n",
      "Epoch 6196, Loss: 0.031960768392309546, Final Batch Loss: 0.0039821164682507515\n",
      "Epoch 6197, Loss: 0.01502954214811325, Final Batch Loss: 0.0049369861371815205\n",
      "Epoch 6198, Loss: 0.00890409480780363, Final Batch Loss: 0.001682768459431827\n",
      "Epoch 6199, Loss: 0.024419500317890197, Final Batch Loss: 0.0005636080750264227\n",
      "Epoch 6200, Loss: 0.014724069158546627, Final Batch Loss: 0.0015873702941462398\n",
      "Epoch 6201, Loss: 0.08613920421339571, Final Batch Loss: 0.012132657691836357\n",
      "Epoch 6202, Loss: 0.021188566461205482, Final Batch Loss: 0.0012981754262000322\n",
      "Epoch 6203, Loss: 0.03157635894604027, Final Batch Loss: 0.0003005592152476311\n",
      "Epoch 6204, Loss: 0.04990012291818857, Final Batch Loss: 0.0014262879267334938\n",
      "Epoch 6205, Loss: 0.01200152502860874, Final Batch Loss: 0.0015289208386093378\n",
      "Epoch 6206, Loss: 0.012684083660133183, Final Batch Loss: 0.00113470118958503\n",
      "Epoch 6207, Loss: 0.045875833835452795, Final Batch Loss: 0.004756916780024767\n",
      "Epoch 6208, Loss: 0.015303610533010215, Final Batch Loss: 0.0002723107463680208\n",
      "Epoch 6209, Loss: 0.09686803165823221, Final Batch Loss: 0.08385767787694931\n",
      "Epoch 6210, Loss: 0.03673450701171532, Final Batch Loss: 0.0008749052067287266\n",
      "Epoch 6211, Loss: 0.16984036937355995, Final Batch Loss: 0.04438305273652077\n",
      "Epoch 6212, Loss: 0.26657747430726886, Final Batch Loss: 0.021971210837364197\n",
      "Epoch 6213, Loss: 0.10694203339517117, Final Batch Loss: 0.03133397176861763\n",
      "Epoch 6214, Loss: 0.05075190216302872, Final Batch Loss: 0.002383247949182987\n",
      "Epoch 6215, Loss: 0.16970270313322544, Final Batch Loss: 0.05504128336906433\n",
      "Epoch 6216, Loss: 0.29528243467211723, Final Batch Loss: 0.1855470836162567\n",
      "Epoch 6217, Loss: 0.12133502308279276, Final Batch Loss: 0.03831877186894417\n",
      "Epoch 6218, Loss: 0.16107140015810728, Final Batch Loss: 0.04862036183476448\n",
      "Epoch 6219, Loss: 0.1926996372640133, Final Batch Loss: 0.03931097313761711\n",
      "Epoch 6220, Loss: 0.04701314936392009, Final Batch Loss: 0.015292801894247532\n",
      "Epoch 6221, Loss: 0.12516214698553085, Final Batch Loss: 0.02823096513748169\n",
      "Epoch 6222, Loss: 0.10335783194750547, Final Batch Loss: 0.03866063058376312\n",
      "Epoch 6223, Loss: 0.05794002674520016, Final Batch Loss: 0.008750460110604763\n",
      "Epoch 6224, Loss: 0.0952467666938901, Final Batch Loss: 0.008171048946678638\n",
      "Epoch 6225, Loss: 0.023291949182748795, Final Batch Loss: 0.0027543427422642708\n",
      "Epoch 6226, Loss: 0.05080658523365855, Final Batch Loss: 0.0024577053263783455\n",
      "Epoch 6227, Loss: 0.037376658292487264, Final Batch Loss: 0.0024091913364827633\n",
      "Epoch 6228, Loss: 0.014356959087308496, Final Batch Loss: 0.000949102861341089\n",
      "Epoch 6229, Loss: 0.04735339747276157, Final Batch Loss: 0.0033956188708543777\n",
      "Epoch 6230, Loss: 0.03102424368262291, Final Batch Loss: 0.00666798884049058\n",
      "Epoch 6231, Loss: 0.011972283711656928, Final Batch Loss: 0.0032882222440093756\n",
      "Epoch 6232, Loss: 0.01523487619124353, Final Batch Loss: 0.0021840627305209637\n",
      "Epoch 6233, Loss: 0.022423108341172338, Final Batch Loss: 0.001207913039252162\n",
      "Epoch 6234, Loss: 0.026306350715458393, Final Batch Loss: 0.007592007517814636\n",
      "Epoch 6235, Loss: 0.007864285696996376, Final Batch Loss: 0.001225982909090817\n",
      "Epoch 6236, Loss: 0.004895016900263727, Final Batch Loss: 0.00044584646821022034\n",
      "Epoch 6237, Loss: 0.01184021681547165, Final Batch Loss: 0.00031257967930287123\n",
      "Epoch 6238, Loss: 0.03406227665254846, Final Batch Loss: 0.00014650746015831828\n",
      "Epoch 6239, Loss: 0.013517466955818236, Final Batch Loss: 0.0007139359368011355\n",
      "Epoch 6240, Loss: 0.061193687724880874, Final Batch Loss: 0.025591470301151276\n",
      "Epoch 6241, Loss: 0.020707701449282467, Final Batch Loss: 0.0017860442167147994\n",
      "Epoch 6242, Loss: 0.013111166714224964, Final Batch Loss: 0.0006139872712083161\n",
      "Epoch 6243, Loss: 0.020718158455565572, Final Batch Loss: 0.0010132514871656895\n",
      "Epoch 6244, Loss: 0.027258521877229214, Final Batch Loss: 0.0022845712956041098\n",
      "Epoch 6245, Loss: 0.035973366582766175, Final Batch Loss: 0.017822882160544395\n",
      "Epoch 6246, Loss: 0.07527077291160822, Final Batch Loss: 0.044895317405462265\n",
      "Epoch 6247, Loss: 0.02471492369659245, Final Batch Loss: 0.003656935878098011\n",
      "Epoch 6248, Loss: 0.029713717056438327, Final Batch Loss: 0.004921707324683666\n",
      "Epoch 6249, Loss: 0.039223083993420005, Final Batch Loss: 0.00041577056981623173\n",
      "Epoch 6250, Loss: 0.0961057492531836, Final Batch Loss: 0.07597015798091888\n",
      "Epoch 6251, Loss: 0.026583266677334905, Final Batch Loss: 0.0024206407833844423\n",
      "Epoch 6252, Loss: 0.016014987719245255, Final Batch Loss: 0.0013197598746046424\n",
      "Epoch 6253, Loss: 0.10917946579866111, Final Batch Loss: 0.0016132432501763105\n",
      "Epoch 6254, Loss: 0.02473720209673047, Final Batch Loss: 0.0024846005253493786\n",
      "Epoch 6255, Loss: 0.04678524797782302, Final Batch Loss: 0.01212198007851839\n",
      "Epoch 6256, Loss: 0.03188825222605374, Final Batch Loss: 0.00022521369101013988\n",
      "Epoch 6257, Loss: 0.0643695822218433, Final Batch Loss: 0.001592605491168797\n",
      "Epoch 6258, Loss: 0.05730115994811058, Final Batch Loss: 0.005037484224885702\n",
      "Epoch 6259, Loss: 0.02696449146606028, Final Batch Loss: 0.012846089899539948\n",
      "Epoch 6260, Loss: 0.012822884833440185, Final Batch Loss: 0.003683827118948102\n",
      "Epoch 6261, Loss: 0.017337959026917815, Final Batch Loss: 0.0016073689330369234\n",
      "Epoch 6262, Loss: 0.013648636406287551, Final Batch Loss: 0.0025153367314487696\n",
      "Epoch 6263, Loss: 0.03585948213003576, Final Batch Loss: 0.001446678419597447\n",
      "Epoch 6264, Loss: 0.023845854680985212, Final Batch Loss: 0.004178356844931841\n",
      "Epoch 6265, Loss: 0.009519320155959576, Final Batch Loss: 0.0005815036711283028\n",
      "Epoch 6266, Loss: 0.03480763325933367, Final Batch Loss: 0.0015185774536803365\n",
      "Epoch 6267, Loss: 0.057586725102737546, Final Batch Loss: 0.015440947376191616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6268, Loss: 0.0745447325753048, Final Batch Loss: 0.000877111335285008\n",
      "Epoch 6269, Loss: 0.012859718117397279, Final Batch Loss: 0.0013955109752714634\n",
      "Epoch 6270, Loss: 0.06752731464803219, Final Batch Loss: 0.0020332313142716885\n",
      "Epoch 6271, Loss: 0.022815379430539906, Final Batch Loss: 0.0010436224984005094\n",
      "Epoch 6272, Loss: 0.019284518202766776, Final Batch Loss: 0.0025822282768785954\n",
      "Epoch 6273, Loss: 0.038577938452363014, Final Batch Loss: 0.020819412544369698\n",
      "Epoch 6274, Loss: 0.04923515813425183, Final Batch Loss: 0.003197910264134407\n",
      "Epoch 6275, Loss: 0.027588145254412666, Final Batch Loss: 0.0003297472430858761\n",
      "Epoch 6276, Loss: 0.029003703268244863, Final Batch Loss: 0.002813532017171383\n",
      "Epoch 6277, Loss: 0.0721713537350297, Final Batch Loss: 0.004970851354300976\n",
      "Epoch 6278, Loss: 0.018490109127014875, Final Batch Loss: 0.0031825616024434566\n",
      "Epoch 6279, Loss: 0.03099282638868317, Final Batch Loss: 0.000767623248975724\n",
      "Epoch 6280, Loss: 0.04575099959038198, Final Batch Loss: 0.0023264342453330755\n",
      "Epoch 6281, Loss: 0.0224902902264148, Final Batch Loss: 0.007150819059461355\n",
      "Epoch 6282, Loss: 0.01606749033089727, Final Batch Loss: 0.001518705510534346\n",
      "Epoch 6283, Loss: 0.06357709073927253, Final Batch Loss: 0.0005255605792626739\n",
      "Epoch 6284, Loss: 0.05384362302720547, Final Batch Loss: 0.009651404805481434\n",
      "Epoch 6285, Loss: 0.029864951386116445, Final Batch Loss: 0.003216585610061884\n",
      "Epoch 6286, Loss: 0.031369658187031746, Final Batch Loss: 0.0016827522777020931\n",
      "Epoch 6287, Loss: 0.0448520474601537, Final Batch Loss: 0.003087407210841775\n",
      "Epoch 6288, Loss: 0.05351422633975744, Final Batch Loss: 0.029961680993437767\n",
      "Epoch 6289, Loss: 0.029218231211416423, Final Batch Loss: 0.00842627976089716\n",
      "Epoch 6290, Loss: 0.05863579269498587, Final Batch Loss: 0.022623887285590172\n",
      "Epoch 6291, Loss: 0.05233023513574153, Final Batch Loss: 0.001351541024632752\n",
      "Epoch 6292, Loss: 0.04356837482191622, Final Batch Loss: 0.03734839707612991\n",
      "Epoch 6293, Loss: 0.05386277241632342, Final Batch Loss: 0.004598395433276892\n",
      "Epoch 6294, Loss: 0.022565380670130253, Final Batch Loss: 0.0012112832628190517\n",
      "Epoch 6295, Loss: 0.03273499116767198, Final Batch Loss: 0.005884923040866852\n",
      "Epoch 6296, Loss: 0.05483322450891137, Final Batch Loss: 0.014619988389313221\n",
      "Epoch 6297, Loss: 0.010437073593493551, Final Batch Loss: 0.00042231479892507195\n",
      "Epoch 6298, Loss: 0.01745335105806589, Final Batch Loss: 0.004861559718847275\n",
      "Epoch 6299, Loss: 0.08604509173892438, Final Batch Loss: 0.027106840163469315\n",
      "Epoch 6300, Loss: 0.10247202811297029, Final Batch Loss: 0.07871125638484955\n",
      "Epoch 6301, Loss: 0.07665810943581164, Final Batch Loss: 0.0028952474240213633\n",
      "Epoch 6302, Loss: 0.2370347362011671, Final Batch Loss: 0.13334712386131287\n",
      "Epoch 6303, Loss: 0.08093655854463577, Final Batch Loss: 0.000735769048333168\n",
      "Epoch 6304, Loss: 0.02041966770775616, Final Batch Loss: 0.004555404651910067\n",
      "Epoch 6305, Loss: 0.15197015646845102, Final Batch Loss: 0.02567305974662304\n",
      "Epoch 6306, Loss: 0.03277314733713865, Final Batch Loss: 0.006212687119841576\n",
      "Epoch 6307, Loss: 0.03398559591732919, Final Batch Loss: 0.00458677439019084\n",
      "Epoch 6308, Loss: 0.04488454130478203, Final Batch Loss: 0.009086019359529018\n",
      "Epoch 6309, Loss: 0.03158978535793722, Final Batch Loss: 0.002631898270919919\n",
      "Epoch 6310, Loss: 0.055996828712522984, Final Batch Loss: 0.033472076058387756\n",
      "Epoch 6311, Loss: 0.028629841515794396, Final Batch Loss: 0.006077361758798361\n",
      "Epoch 6312, Loss: 0.025983671192079782, Final Batch Loss: 0.0070290775038301945\n",
      "Epoch 6313, Loss: 0.03826925501925871, Final Batch Loss: 0.025351421907544136\n",
      "Epoch 6314, Loss: 0.013603630010038614, Final Batch Loss: 0.008461819030344486\n",
      "Epoch 6315, Loss: 0.027229647559579462, Final Batch Loss: 0.0014529948821291327\n",
      "Epoch 6316, Loss: 0.0694979156833142, Final Batch Loss: 0.001997498096898198\n",
      "Epoch 6317, Loss: 0.030422539450228214, Final Batch Loss: 0.0035939014051109552\n",
      "Epoch 6318, Loss: 0.06560950120911002, Final Batch Loss: 0.002122273202985525\n",
      "Epoch 6319, Loss: 0.014699532184749842, Final Batch Loss: 0.004379503894597292\n",
      "Epoch 6320, Loss: 0.056432662648148835, Final Batch Loss: 0.0005973081570118666\n",
      "Epoch 6321, Loss: 0.012618830893188715, Final Batch Loss: 0.004518446512520313\n",
      "Epoch 6322, Loss: 0.008362572698388249, Final Batch Loss: 0.004552636295557022\n",
      "Epoch 6323, Loss: 0.02596536581404507, Final Batch Loss: 0.0017427826533094049\n",
      "Epoch 6324, Loss: 0.018099940207321197, Final Batch Loss: 0.000355938624124974\n",
      "Epoch 6325, Loss: 0.04887038026936352, Final Batch Loss: 0.038494933396577835\n",
      "Epoch 6326, Loss: 0.04778728960081935, Final Batch Loss: 0.0076597449369728565\n",
      "Epoch 6327, Loss: 0.03962925018277019, Final Batch Loss: 0.0006477570859715343\n",
      "Epoch 6328, Loss: 0.018534161732532084, Final Batch Loss: 0.005342709831893444\n",
      "Epoch 6329, Loss: 0.02148846610361943, Final Batch Loss: 9.028500790009275e-05\n",
      "Epoch 6330, Loss: 0.02226035771309398, Final Batch Loss: 0.0004829418321605772\n",
      "Epoch 6331, Loss: 0.027637507882900536, Final Batch Loss: 0.0017766243545338511\n",
      "Epoch 6332, Loss: 0.012914916966110468, Final Batch Loss: 0.002137249568477273\n",
      "Epoch 6333, Loss: 0.03964709711726755, Final Batch Loss: 0.027202336117625237\n",
      "Epoch 6334, Loss: 0.004838204942643642, Final Batch Loss: 0.0011653192341327667\n",
      "Epoch 6335, Loss: 0.029557003872469068, Final Batch Loss: 0.005846885032951832\n",
      "Epoch 6336, Loss: 0.015198900364339352, Final Batch Loss: 0.0027457913383841515\n",
      "Epoch 6337, Loss: 0.0343807025346905, Final Batch Loss: 0.023006485775113106\n",
      "Epoch 6338, Loss: 0.040623092791065574, Final Batch Loss: 0.019316690042614937\n",
      "Epoch 6339, Loss: 0.006761564873158932, Final Batch Loss: 0.0015426804311573505\n",
      "Epoch 6340, Loss: 0.02217192656826228, Final Batch Loss: 0.0019987192936241627\n",
      "Epoch 6341, Loss: 0.028359311108943075, Final Batch Loss: 0.006248474586755037\n",
      "Epoch 6342, Loss: 0.0029521333635784686, Final Batch Loss: 0.0005603839526884258\n",
      "Epoch 6343, Loss: 0.02831338602118194, Final Batch Loss: 0.004792383871972561\n",
      "Epoch 6344, Loss: 0.010972370975650847, Final Batch Loss: 0.0016814066329970956\n",
      "Epoch 6345, Loss: 0.01351746782893315, Final Batch Loss: 0.0007339832955040038\n",
      "Epoch 6346, Loss: 0.01055750815430656, Final Batch Loss: 0.00543387234210968\n",
      "Epoch 6347, Loss: 0.016828992287628353, Final Batch Loss: 0.008849703706800938\n",
      "Epoch 6348, Loss: 0.020207005960401148, Final Batch Loss: 0.0008019089582376182\n",
      "Epoch 6349, Loss: 0.008708360372111201, Final Batch Loss: 0.001220601494424045\n",
      "Epoch 6350, Loss: 0.0283678756095469, Final Batch Loss: 0.01996157132089138\n",
      "Epoch 6351, Loss: 0.030136534944176674, Final Batch Loss: 0.005500716622918844\n",
      "Epoch 6352, Loss: 0.006279565743170679, Final Batch Loss: 0.000887745525687933\n",
      "Epoch 6353, Loss: 0.03327900008298457, Final Batch Loss: 0.0030150108505040407\n",
      "Epoch 6354, Loss: 0.006097294623032212, Final Batch Loss: 0.0005668691010214388\n",
      "Epoch 6355, Loss: 0.015934731578454375, Final Batch Loss: 0.0031045000068843365\n",
      "Epoch 6356, Loss: 0.024404890020377934, Final Batch Loss: 0.0004444615333341062\n",
      "Epoch 6357, Loss: 0.013002369552850723, Final Batch Loss: 0.002171688713133335\n",
      "Epoch 6358, Loss: 0.018405616632662714, Final Batch Loss: 0.0025309950578957796\n",
      "Epoch 6359, Loss: 0.026108237099833786, Final Batch Loss: 0.012555575929582119\n",
      "Epoch 6360, Loss: 0.018970880191773176, Final Batch Loss: 0.001970623154193163\n",
      "Epoch 6361, Loss: 0.04792701080441475, Final Batch Loss: 0.020859649404883385\n",
      "Epoch 6362, Loss: 0.04137969063594937, Final Batch Loss: 0.00045664538629353046\n",
      "Epoch 6363, Loss: 0.021005886839702725, Final Batch Loss: 0.0024527653586119413\n",
      "Epoch 6364, Loss: 0.05518477223813534, Final Batch Loss: 0.011301472783088684\n",
      "Epoch 6365, Loss: 0.04051675833761692, Final Batch Loss: 0.002820211462676525\n",
      "Epoch 6366, Loss: 0.02783804340288043, Final Batch Loss: 0.00298386556096375\n",
      "Epoch 6367, Loss: 0.022481948893982917, Final Batch Loss: 0.004254962783306837\n",
      "Epoch 6368, Loss: 0.03445868898415938, Final Batch Loss: 0.0005244389758445323\n",
      "Epoch 6369, Loss: 0.03485089261084795, Final Batch Loss: 0.0004995579365640879\n",
      "Epoch 6370, Loss: 0.012827119324356318, Final Batch Loss: 0.005546282511204481\n",
      "Epoch 6371, Loss: 0.013015665870625526, Final Batch Loss: 0.0005690795951522887\n",
      "Epoch 6372, Loss: 0.04018511367030442, Final Batch Loss: 0.0035580534022301435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6373, Loss: 0.0690112275769934, Final Batch Loss: 0.0501926951110363\n",
      "Epoch 6374, Loss: 0.06166425038827583, Final Batch Loss: 0.02116166427731514\n",
      "Epoch 6375, Loss: 0.06335489545017481, Final Batch Loss: 0.006076071411371231\n",
      "Epoch 6376, Loss: 0.1122178821824491, Final Batch Loss: 0.032366808503866196\n",
      "Epoch 6377, Loss: 0.011298153083771467, Final Batch Loss: 0.002841074950993061\n",
      "Epoch 6378, Loss: 0.04146132891764864, Final Batch Loss: 0.0005555636598728597\n",
      "Epoch 6379, Loss: 0.09129870042670518, Final Batch Loss: 0.0653991773724556\n",
      "Epoch 6380, Loss: 0.00997682474553585, Final Batch Loss: 0.0009480603621341288\n",
      "Epoch 6381, Loss: 0.0344851030386053, Final Batch Loss: 0.0007412717095576227\n",
      "Epoch 6382, Loss: 0.043282332830131054, Final Batch Loss: 0.0006061099702492356\n",
      "Epoch 6383, Loss: 0.01415575621649623, Final Batch Loss: 0.0025515740271657705\n",
      "Epoch 6384, Loss: 0.012554938264656812, Final Batch Loss: 0.0016047906829044223\n",
      "Epoch 6385, Loss: 0.019814964558463544, Final Batch Loss: 0.011545132845640182\n",
      "Epoch 6386, Loss: 0.01431066173245199, Final Batch Loss: 0.00046655096230097115\n",
      "Epoch 6387, Loss: 0.01729869795963168, Final Batch Loss: 0.003917573485523462\n",
      "Epoch 6388, Loss: 0.014415925019420683, Final Batch Loss: 0.0014988433104008436\n",
      "Epoch 6389, Loss: 0.008318760155816562, Final Batch Loss: 0.0002399852528469637\n",
      "Epoch 6390, Loss: 0.006719435201375745, Final Batch Loss: 0.002545346738770604\n",
      "Epoch 6391, Loss: 0.01569080544868484, Final Batch Loss: 0.0004555693012662232\n",
      "Epoch 6392, Loss: 0.0441285774577409, Final Batch Loss: 0.0009860683931037784\n",
      "Epoch 6393, Loss: 0.14371652237605304, Final Batch Loss: 0.07887189090251923\n",
      "Epoch 6394, Loss: 0.03329846577253193, Final Batch Loss: 0.0050150989554822445\n",
      "Epoch 6395, Loss: 0.018056712666293606, Final Batch Loss: 0.0003249670553486794\n",
      "Epoch 6396, Loss: 0.1061456180177629, Final Batch Loss: 0.03856972977519035\n",
      "Epoch 6397, Loss: 0.006317748935543932, Final Batch Loss: 0.00019731653446797282\n",
      "Epoch 6398, Loss: 0.10030035395175219, Final Batch Loss: 0.016304822638630867\n",
      "Epoch 6399, Loss: 0.01731343916617334, Final Batch Loss: 0.006699651945382357\n",
      "Epoch 6400, Loss: 0.06221731682308018, Final Batch Loss: 0.026779083535075188\n",
      "Epoch 6401, Loss: 0.023137721815146506, Final Batch Loss: 0.009821455925703049\n",
      "Epoch 6402, Loss: 0.025283765862695873, Final Batch Loss: 0.0022663597483187914\n",
      "Epoch 6403, Loss: 0.04288464866112918, Final Batch Loss: 0.004897069651633501\n",
      "Epoch 6404, Loss: 0.052585485740564764, Final Batch Loss: 0.0009182167705148458\n",
      "Epoch 6405, Loss: 0.024066444020718336, Final Batch Loss: 0.016180535778403282\n",
      "Epoch 6406, Loss: 0.022238324803765863, Final Batch Loss: 0.007731436286121607\n",
      "Epoch 6407, Loss: 0.04291757335886359, Final Batch Loss: 0.006141061428934336\n",
      "Epoch 6408, Loss: 0.030297582736238837, Final Batch Loss: 0.0020511483307927847\n",
      "Epoch 6409, Loss: 0.041387435514479876, Final Batch Loss: 0.00677665788680315\n",
      "Epoch 6410, Loss: 0.04187799710780382, Final Batch Loss: 0.0023021434899419546\n",
      "Epoch 6411, Loss: 0.019125095321214758, Final Batch Loss: 0.00014145088789518923\n",
      "Epoch 6412, Loss: 0.01750155063928105, Final Batch Loss: 0.000436605914728716\n",
      "Epoch 6413, Loss: 0.035372478363569826, Final Batch Loss: 0.0007610975299030542\n",
      "Epoch 6414, Loss: 0.04496598261175677, Final Batch Loss: 0.0022979113273322582\n",
      "Epoch 6415, Loss: 0.07419743307400495, Final Batch Loss: 0.01778453215956688\n",
      "Epoch 6416, Loss: 0.012861829018220305, Final Batch Loss: 0.002580889966338873\n",
      "Epoch 6417, Loss: 0.04591081972466782, Final Batch Loss: 0.018937483429908752\n",
      "Epoch 6418, Loss: 0.06863279500976205, Final Batch Loss: 0.027548160403966904\n",
      "Epoch 6419, Loss: 0.05620750633534044, Final Batch Loss: 0.004752493463456631\n",
      "Epoch 6420, Loss: 0.029056576546281576, Final Batch Loss: 0.006453317124396563\n",
      "Epoch 6421, Loss: 0.035218139411881566, Final Batch Loss: 0.0013963833916932344\n",
      "Epoch 6422, Loss: 0.027867838158272207, Final Batch Loss: 0.0014134491793811321\n",
      "Epoch 6423, Loss: 0.02159690682310611, Final Batch Loss: 0.0018179139588028193\n",
      "Epoch 6424, Loss: 0.015109865227714181, Final Batch Loss: 0.0020998867694288492\n",
      "Epoch 6425, Loss: 0.018897132657002658, Final Batch Loss: 0.001315031899139285\n",
      "Epoch 6426, Loss: 0.04263478849316016, Final Batch Loss: 0.0005703264032490551\n",
      "Epoch 6427, Loss: 0.042040275016915984, Final Batch Loss: 4.135894414503127e-05\n",
      "Epoch 6428, Loss: 0.03248584998073056, Final Batch Loss: 0.0009891194058582187\n",
      "Epoch 6429, Loss: 0.039422869915142655, Final Batch Loss: 0.0005795534234493971\n",
      "Epoch 6430, Loss: 0.02453619393054396, Final Batch Loss: 0.005919322837144136\n",
      "Epoch 6431, Loss: 0.05529600556474179, Final Batch Loss: 0.0009058410068973899\n",
      "Epoch 6432, Loss: 0.03745338233420625, Final Batch Loss: 0.0031265930738300085\n",
      "Epoch 6433, Loss: 0.016421761887613684, Final Batch Loss: 0.0019158339127898216\n",
      "Epoch 6434, Loss: 0.02300299477064982, Final Batch Loss: 0.000833512342069298\n",
      "Epoch 6435, Loss: 0.011099983472377062, Final Batch Loss: 0.0024586799554526806\n",
      "Epoch 6436, Loss: 0.02070332452422008, Final Batch Loss: 0.009863276034593582\n",
      "Epoch 6437, Loss: 0.05134011403424665, Final Batch Loss: 0.0006296878564171493\n",
      "Epoch 6438, Loss: 0.004182810385827906, Final Batch Loss: 0.0001444628433091566\n",
      "Epoch 6439, Loss: 0.041204704306437634, Final Batch Loss: 0.00015069135406520218\n",
      "Epoch 6440, Loss: 0.05832082766573876, Final Batch Loss: 0.019004633650183678\n",
      "Epoch 6441, Loss: 0.02191806520568207, Final Batch Loss: 0.011538208462297916\n",
      "Epoch 6442, Loss: 0.03748943388927728, Final Batch Loss: 0.00033136073034256697\n",
      "Epoch 6443, Loss: 0.040912496333476156, Final Batch Loss: 0.0006248219287954271\n",
      "Epoch 6444, Loss: 0.02044653129996732, Final Batch Loss: 0.000491743499878794\n",
      "Epoch 6445, Loss: 0.015862715197727084, Final Batch Loss: 0.0020935593638569117\n",
      "Epoch 6446, Loss: 0.13876125123351812, Final Batch Loss: 0.0013103391975164413\n",
      "Epoch 6447, Loss: 0.06074676517164335, Final Batch Loss: 0.039869844913482666\n",
      "Epoch 6448, Loss: 0.054508077388163656, Final Batch Loss: 0.0013432912528514862\n",
      "Epoch 6449, Loss: 0.02730004326440394, Final Batch Loss: 0.008120542392134666\n",
      "Epoch 6450, Loss: 0.014773529313970357, Final Batch Loss: 0.0008985796594060957\n",
      "Epoch 6451, Loss: 0.023257855558767915, Final Batch Loss: 0.0005148125346750021\n",
      "Epoch 6452, Loss: 0.008977678357041441, Final Batch Loss: 0.000185560536920093\n",
      "Epoch 6453, Loss: 0.016496773809194565, Final Batch Loss: 0.008858699351549149\n",
      "Epoch 6454, Loss: 0.006764657213352621, Final Batch Loss: 0.001201080740429461\n",
      "Epoch 6455, Loss: 0.029928366537205875, Final Batch Loss: 0.0032194957602769136\n",
      "Epoch 6456, Loss: 0.005042082688305527, Final Batch Loss: 0.0013352055102586746\n",
      "Epoch 6457, Loss: 0.012966179478098638, Final Batch Loss: 0.0031503760255873203\n",
      "Epoch 6458, Loss: 0.016052768100053072, Final Batch Loss: 0.0023970960173755884\n",
      "Epoch 6459, Loss: 0.022532661503646523, Final Batch Loss: 0.0011554599041119218\n",
      "Epoch 6460, Loss: 0.009958861046470702, Final Batch Loss: 0.0021458789706230164\n",
      "Epoch 6461, Loss: 0.00776168389711529, Final Batch Loss: 0.000315958634018898\n",
      "Epoch 6462, Loss: 0.011543207452632487, Final Batch Loss: 0.00557542173191905\n",
      "Epoch 6463, Loss: 0.03974005708005279, Final Batch Loss: 0.0004610697505995631\n",
      "Epoch 6464, Loss: 0.012149413814768195, Final Batch Loss: 0.0008539673872292042\n",
      "Epoch 6465, Loss: 0.009125151787884533, Final Batch Loss: 0.00015982681361492723\n",
      "Epoch 6466, Loss: 0.02875258171116002, Final Batch Loss: 0.00013173010665923357\n",
      "Epoch 6467, Loss: 0.026914037065580487, Final Batch Loss: 0.000897826801519841\n",
      "Epoch 6468, Loss: 0.03305252396967262, Final Batch Loss: 0.026296455413103104\n",
      "Epoch 6469, Loss: 0.004852608712099027, Final Batch Loss: 8.385936234844849e-05\n",
      "Epoch 6470, Loss: 0.01038195873843506, Final Batch Loss: 0.00541310990229249\n",
      "Epoch 6471, Loss: 0.029194856848334894, Final Batch Loss: 0.0003301453252788633\n",
      "Epoch 6472, Loss: 0.01168684964068234, Final Batch Loss: 0.0009318342199549079\n",
      "Epoch 6473, Loss: 0.03795852267649025, Final Batch Loss: 0.004702083766460419\n",
      "Epoch 6474, Loss: 0.012869122787378728, Final Batch Loss: 0.00013349397340789437\n",
      "Epoch 6475, Loss: 0.031891345395706594, Final Batch Loss: 0.0014188719214871526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6476, Loss: 0.019373897346667945, Final Batch Loss: 0.008176111616194248\n",
      "Epoch 6477, Loss: 0.006227909936569631, Final Batch Loss: 0.0023784716613590717\n",
      "Epoch 6478, Loss: 0.021307949296897277, Final Batch Loss: 0.0016203245613723993\n",
      "Epoch 6479, Loss: 0.012056209379807115, Final Batch Loss: 0.001136373495683074\n",
      "Epoch 6480, Loss: 0.01596392085775733, Final Batch Loss: 0.0024796915240585804\n",
      "Epoch 6481, Loss: 0.006122512684669346, Final Batch Loss: 0.0003116448351647705\n",
      "Epoch 6482, Loss: 0.005863811471499503, Final Batch Loss: 0.0008518552640452981\n",
      "Epoch 6483, Loss: 0.011235601908992976, Final Batch Loss: 0.0009099259623326361\n",
      "Epoch 6484, Loss: 0.004584188005537726, Final Batch Loss: 0.00011037483636755496\n",
      "Epoch 6485, Loss: 0.014276107307523489, Final Batch Loss: 0.006679377052932978\n",
      "Epoch 6486, Loss: 0.007271818467415869, Final Batch Loss: 0.0020894776098430157\n",
      "Epoch 6487, Loss: 0.008921551372623071, Final Batch Loss: 0.0016323488671332598\n",
      "Epoch 6488, Loss: 0.008437324548140168, Final Batch Loss: 0.005955011583864689\n",
      "Epoch 6489, Loss: 0.002288790372404037, Final Batch Loss: 4.4040509237674996e-05\n",
      "Epoch 6490, Loss: 0.004954910997184925, Final Batch Loss: 7.847997767385095e-05\n",
      "Epoch 6491, Loss: 0.008909543423214927, Final Batch Loss: 0.0005582264857366681\n",
      "Epoch 6492, Loss: 0.008126464614178985, Final Batch Loss: 0.0002823661779984832\n",
      "Epoch 6493, Loss: 0.0054565192986046895, Final Batch Loss: 0.00020165815658401698\n",
      "Epoch 6494, Loss: 0.018177861580625176, Final Batch Loss: 0.0011115868110209703\n",
      "Epoch 6495, Loss: 0.033599642716581, Final Batch Loss: 0.03164234757423401\n",
      "Epoch 6496, Loss: 0.012198152842756826, Final Batch Loss: 0.00010102270607603714\n",
      "Epoch 6497, Loss: 0.051418210205156356, Final Batch Loss: 0.01368661131709814\n",
      "Epoch 6498, Loss: 0.05053634266369045, Final Batch Loss: 0.004751912783831358\n",
      "Epoch 6499, Loss: 0.038665273459628224, Final Batch Loss: 0.007903491146862507\n",
      "Epoch 6500, Loss: 0.05127710627857596, Final Batch Loss: 0.006975342053920031\n",
      "Epoch 6501, Loss: 0.019858772633597255, Final Batch Loss: 0.0023254125844687223\n",
      "Epoch 6502, Loss: 0.014448771253228188, Final Batch Loss: 0.007372140884399414\n",
      "Epoch 6503, Loss: 0.04354384448379278, Final Batch Loss: 0.016302652657032013\n",
      "Epoch 6504, Loss: 0.03054057154804468, Final Batch Loss: 0.010931442491710186\n",
      "Epoch 6505, Loss: 0.06971672270447016, Final Batch Loss: 0.016789032146334648\n",
      "Epoch 6506, Loss: 0.05707964883185923, Final Batch Loss: 0.020632626488804817\n",
      "Epoch 6507, Loss: 0.011985740275122225, Final Batch Loss: 0.004389861598610878\n",
      "Epoch 6508, Loss: 0.1664815325057134, Final Batch Loss: 0.11693178117275238\n",
      "Epoch 6509, Loss: 0.041337230475619435, Final Batch Loss: 0.012406937777996063\n",
      "Epoch 6510, Loss: 0.007281982572749257, Final Batch Loss: 0.00038282282184809446\n",
      "Epoch 6511, Loss: 0.08249494270421565, Final Batch Loss: 0.0016112432349473238\n",
      "Epoch 6512, Loss: 0.04294564435258508, Final Batch Loss: 0.019851474091410637\n",
      "Epoch 6513, Loss: 0.024733738508075476, Final Batch Loss: 0.002867131493985653\n",
      "Epoch 6514, Loss: 0.022837699973024428, Final Batch Loss: 0.010293299332261086\n",
      "Epoch 6515, Loss: 0.0658175628632307, Final Batch Loss: 0.025178110226988792\n",
      "Epoch 6516, Loss: 0.06982598500326276, Final Batch Loss: 0.011594085954129696\n",
      "Epoch 6517, Loss: 0.05208005616441369, Final Batch Loss: 0.0021498880814760923\n",
      "Epoch 6518, Loss: 0.02474122168496251, Final Batch Loss: 0.00033567752689123154\n",
      "Epoch 6519, Loss: 0.03567651705816388, Final Batch Loss: 0.0081082908436656\n",
      "Epoch 6520, Loss: 0.03028783152694814, Final Batch Loss: 0.0004682669823523611\n",
      "Epoch 6521, Loss: 0.033459140569902956, Final Batch Loss: 0.006821912247687578\n",
      "Epoch 6522, Loss: 0.05763823806773871, Final Batch Loss: 0.001633531297557056\n",
      "Epoch 6523, Loss: 0.0994306611828506, Final Batch Loss: 0.06706536561250687\n",
      "Epoch 6524, Loss: 0.03820734145119786, Final Batch Loss: 0.03097672201693058\n",
      "Epoch 6525, Loss: 0.09891440905630589, Final Batch Loss: 0.005935846362262964\n",
      "Epoch 6526, Loss: 0.040085223503410816, Final Batch Loss: 0.006245581433176994\n",
      "Epoch 6527, Loss: 0.0251109863165766, Final Batch Loss: 0.0024570743553340435\n",
      "Epoch 6528, Loss: 0.05845220747869462, Final Batch Loss: 0.001241175807081163\n",
      "Epoch 6529, Loss: 0.11305167991667986, Final Batch Loss: 0.07731593400239944\n",
      "Epoch 6530, Loss: 0.01139494264498353, Final Batch Loss: 0.0020132167264819145\n",
      "Epoch 6531, Loss: 0.03449756000190973, Final Batch Loss: 0.0014107883907854557\n",
      "Epoch 6532, Loss: 0.019073092960752547, Final Batch Loss: 0.0005150208016857505\n",
      "Epoch 6533, Loss: 0.01746214894228615, Final Batch Loss: 0.00012154426076449454\n",
      "Epoch 6534, Loss: 0.012893358478322625, Final Batch Loss: 0.0016566028352826834\n",
      "Epoch 6535, Loss: 0.01575385103933513, Final Batch Loss: 0.0034896819852292538\n",
      "Epoch 6536, Loss: 0.01559161557815969, Final Batch Loss: 0.004454534035176039\n",
      "Epoch 6537, Loss: 0.012877036933787167, Final Batch Loss: 0.0006151277339085937\n",
      "Epoch 6538, Loss: 0.08576053151045926, Final Batch Loss: 0.00026130504556931555\n",
      "Epoch 6539, Loss: 0.003774445067392662, Final Batch Loss: 0.0003032383101526648\n",
      "Epoch 6540, Loss: 0.00609126991184894, Final Batch Loss: 0.00019856235303450376\n",
      "Epoch 6541, Loss: 0.05386521480977535, Final Batch Loss: 0.034786831587553024\n",
      "Epoch 6542, Loss: 0.013634909584652632, Final Batch Loss: 0.0006839646375738084\n",
      "Epoch 6543, Loss: 0.03863056539557874, Final Batch Loss: 0.01932039111852646\n",
      "Epoch 6544, Loss: 0.00446713155542966, Final Batch Loss: 0.00022048990649636835\n",
      "Epoch 6545, Loss: 0.049037450924515724, Final Batch Loss: 0.01956103928387165\n",
      "Epoch 6546, Loss: 0.008196376846171916, Final Batch Loss: 0.0006997602758929133\n",
      "Epoch 6547, Loss: 0.05012040305882692, Final Batch Loss: 0.018224108964204788\n",
      "Epoch 6548, Loss: 0.05153657701521297, Final Batch Loss: 3.390499114175327e-05\n",
      "Epoch 6549, Loss: 0.03613248701731209, Final Batch Loss: 0.00010148798173759133\n",
      "Epoch 6550, Loss: 0.048156563309021294, Final Batch Loss: 0.028996041044592857\n",
      "Epoch 6551, Loss: 0.045097536174580455, Final Batch Loss: 0.00316608021967113\n",
      "Epoch 6552, Loss: 0.024550354573875666, Final Batch Loss: 0.0011530006304383278\n",
      "Epoch 6553, Loss: 0.03276290890062228, Final Batch Loss: 0.00041387934470549226\n",
      "Epoch 6554, Loss: 0.07121760305017233, Final Batch Loss: 0.05495065078139305\n",
      "Epoch 6555, Loss: 0.04276404564734548, Final Batch Loss: 0.0011120009003207088\n",
      "Epoch 6556, Loss: 0.03253086289623752, Final Batch Loss: 0.0005747520481236279\n",
      "Epoch 6557, Loss: 0.07657088240375742, Final Batch Loss: 0.0004681804566644132\n",
      "Epoch 6558, Loss: 0.08701765816658735, Final Batch Loss: 0.040889207273721695\n",
      "Epoch 6559, Loss: 0.058779101571417414, Final Batch Loss: 0.00022665491269435734\n",
      "Epoch 6560, Loss: 0.0091612848918885, Final Batch Loss: 0.00023613160010427237\n",
      "Epoch 6561, Loss: 0.013758611923549324, Final Batch Loss: 0.004753267392516136\n",
      "Epoch 6562, Loss: 0.014911561040207744, Final Batch Loss: 0.0012782728299498558\n",
      "Epoch 6563, Loss: 0.026977111119776964, Final Batch Loss: 0.0059175072237849236\n",
      "Epoch 6564, Loss: 0.005022979981731623, Final Batch Loss: 0.00046049407683312893\n",
      "Epoch 6565, Loss: 0.02039397065527737, Final Batch Loss: 0.003967047668993473\n",
      "Epoch 6566, Loss: 0.018839859636500478, Final Batch Loss: 0.003938659559935331\n",
      "Epoch 6567, Loss: 0.021312293622031575, Final Batch Loss: 5.820151636726223e-05\n",
      "Epoch 6568, Loss: 0.0376682955538854, Final Batch Loss: 0.0017505979631096125\n",
      "Epoch 6569, Loss: 0.007527380497776903, Final Batch Loss: 0.004841852467507124\n",
      "Epoch 6570, Loss: 0.030298538506031036, Final Batch Loss: 0.002236592583358288\n",
      "Epoch 6571, Loss: 0.009573973249644041, Final Batch Loss: 0.0016683085123077035\n",
      "Epoch 6572, Loss: 0.05472647896385752, Final Batch Loss: 0.0003887345374096185\n",
      "Epoch 6573, Loss: 0.004911809344775975, Final Batch Loss: 0.001577254617586732\n",
      "Epoch 6574, Loss: 0.009919759235344827, Final Batch Loss: 0.0007658037357032299\n",
      "Epoch 6575, Loss: 0.00457070316770114, Final Batch Loss: 0.00024063492310233414\n",
      "Epoch 6576, Loss: 0.02921765437349677, Final Batch Loss: 0.002615605713799596\n",
      "Epoch 6577, Loss: 0.010905705916229635, Final Batch Loss: 0.002486135810613632\n",
      "Epoch 6578, Loss: 0.03571829746942967, Final Batch Loss: 0.0005802743253298104\n",
      "Epoch 6579, Loss: 0.02468979952391237, Final Batch Loss: 0.01712850295007229\n",
      "Epoch 6580, Loss: 0.007467742500011809, Final Batch Loss: 0.00017445308913011104\n",
      "Epoch 6581, Loss: 0.04362699433113448, Final Batch Loss: 0.00038526367279700935\n",
      "Epoch 6582, Loss: 0.055486074183136225, Final Batch Loss: 0.004615091253072023\n",
      "Epoch 6583, Loss: 0.005785555811598897, Final Batch Loss: 0.001707490999251604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6584, Loss: 0.040750585845671594, Final Batch Loss: 0.0009662207448855042\n",
      "Epoch 6585, Loss: 0.05616871314123273, Final Batch Loss: 0.018784206360578537\n",
      "Epoch 6586, Loss: 0.02431887260172516, Final Batch Loss: 0.0028733047656714916\n",
      "Epoch 6587, Loss: 0.036467442696448416, Final Batch Loss: 0.004088348243385553\n",
      "Epoch 6588, Loss: 0.009414587402716279, Final Batch Loss: 0.0016379071166738868\n",
      "Epoch 6589, Loss: 0.04580139642348513, Final Batch Loss: 0.00021577969891950488\n",
      "Epoch 6590, Loss: 0.0388862902764231, Final Batch Loss: 0.035061657428741455\n",
      "Epoch 6591, Loss: 0.06555939163081348, Final Batch Loss: 0.034763727337121964\n",
      "Epoch 6592, Loss: 0.06753251096233726, Final Batch Loss: 0.019695697352290154\n",
      "Epoch 6593, Loss: 0.05742063978686929, Final Batch Loss: 0.007237945217639208\n",
      "Epoch 6594, Loss: 0.06653308449313045, Final Batch Loss: 0.014659649692475796\n",
      "Epoch 6595, Loss: 0.044230850762687624, Final Batch Loss: 0.009527439251542091\n",
      "Epoch 6596, Loss: 0.035199584905058146, Final Batch Loss: 0.0006135287694633007\n",
      "Epoch 6597, Loss: 0.05753657256718725, Final Batch Loss: 0.026760831475257874\n",
      "Epoch 6598, Loss: 0.06840392370941117, Final Batch Loss: 0.004609062802046537\n",
      "Epoch 6599, Loss: 0.008828336838632822, Final Batch Loss: 0.0020856475457549095\n",
      "Epoch 6600, Loss: 0.04528528428636491, Final Batch Loss: 0.03605968505144119\n",
      "Epoch 6601, Loss: 0.03701892017852515, Final Batch Loss: 0.0066718473099172115\n",
      "Epoch 6602, Loss: 0.018063094408717006, Final Batch Loss: 0.0003948916564695537\n",
      "Epoch 6603, Loss: 0.014512312307488173, Final Batch Loss: 0.0007227067253552377\n",
      "Epoch 6604, Loss: 0.0385171995148994, Final Batch Loss: 0.0005912811611779034\n",
      "Epoch 6605, Loss: 0.02092494978569448, Final Batch Loss: 0.0035656357649713755\n",
      "Epoch 6606, Loss: 0.04809725843369961, Final Batch Loss: 0.0004959623329341412\n",
      "Epoch 6607, Loss: 0.01062492057099007, Final Batch Loss: 0.00028333751833997667\n",
      "Epoch 6608, Loss: 0.004242584924213588, Final Batch Loss: 0.0004012702265754342\n",
      "Epoch 6609, Loss: 0.01096522476291284, Final Batch Loss: 0.006727401167154312\n",
      "Epoch 6610, Loss: 0.007965052456711419, Final Batch Loss: 0.0013923734659329057\n",
      "Epoch 6611, Loss: 0.01323371974285692, Final Batch Loss: 0.0014757132157683372\n",
      "Epoch 6612, Loss: 0.040990216948557645, Final Batch Loss: 0.0005908795283176005\n",
      "Epoch 6613, Loss: 0.010180778917856514, Final Batch Loss: 0.0003122884372714907\n",
      "Epoch 6614, Loss: 0.01684800861403346, Final Batch Loss: 0.002427315106615424\n",
      "Epoch 6615, Loss: 0.03179179911967367, Final Batch Loss: 0.00183522654697299\n",
      "Epoch 6616, Loss: 0.004590639713569544, Final Batch Loss: 0.00011545173765625805\n",
      "Epoch 6617, Loss: 0.01839994522742927, Final Batch Loss: 0.0015227296389639378\n",
      "Epoch 6618, Loss: 0.03109832655172795, Final Batch Loss: 0.012033170089125633\n",
      "Epoch 6619, Loss: 0.005895543727092445, Final Batch Loss: 0.0033914961386471987\n",
      "Epoch 6620, Loss: 0.03726519108749926, Final Batch Loss: 0.0024739066138863564\n",
      "Epoch 6621, Loss: 0.006425411265809089, Final Batch Loss: 0.0008050159667618573\n",
      "Epoch 6622, Loss: 0.03539341734722257, Final Batch Loss: 0.000986616825684905\n",
      "Epoch 6623, Loss: 0.015020703198388219, Final Batch Loss: 0.0017995837843045592\n",
      "Epoch 6624, Loss: 0.023706264444626868, Final Batch Loss: 0.0052452608942985535\n",
      "Epoch 6625, Loss: 0.006133541726740077, Final Batch Loss: 4.1581952245905995e-05\n",
      "Epoch 6626, Loss: 0.022771583637222648, Final Batch Loss: 0.007694626227021217\n",
      "Epoch 6627, Loss: 0.025206397636793554, Final Batch Loss: 0.0015084123006090522\n",
      "Epoch 6628, Loss: 0.006277013861108571, Final Batch Loss: 0.00018280226504430175\n",
      "Epoch 6629, Loss: 0.016096410108730197, Final Batch Loss: 0.0070433104410767555\n",
      "Epoch 6630, Loss: 0.017791206541005522, Final Batch Loss: 0.010536642745137215\n",
      "Epoch 6631, Loss: 0.07764506014063954, Final Batch Loss: 0.00881202332675457\n",
      "Epoch 6632, Loss: 0.045767549076117575, Final Batch Loss: 0.020628344267606735\n",
      "Epoch 6633, Loss: 0.07739947969093919, Final Batch Loss: 0.0034272768534719944\n",
      "Epoch 6634, Loss: 0.0498110381886363, Final Batch Loss: 0.001290010754019022\n",
      "Epoch 6635, Loss: 0.03496364108286798, Final Batch Loss: 0.0062711662612855434\n",
      "Epoch 6636, Loss: 0.022619438590481877, Final Batch Loss: 0.011409846134483814\n",
      "Epoch 6637, Loss: 0.02836616977583617, Final Batch Loss: 0.007562249433249235\n",
      "Epoch 6638, Loss: 0.01600790792144835, Final Batch Loss: 0.0013191355392336845\n",
      "Epoch 6639, Loss: 0.023456360795535147, Final Batch Loss: 0.0023660084698349237\n",
      "Epoch 6640, Loss: 0.01977587677538395, Final Batch Loss: 0.005598433781415224\n",
      "Epoch 6641, Loss: 0.07517390424618497, Final Batch Loss: 0.0008905735448934138\n",
      "Epoch 6642, Loss: 0.05186077841790393, Final Batch Loss: 0.006152356509119272\n",
      "Epoch 6643, Loss: 0.0439121185336262, Final Batch Loss: 0.028084179386496544\n",
      "Epoch 6644, Loss: 0.013193532358855009, Final Batch Loss: 0.004812123719602823\n",
      "Epoch 6645, Loss: 0.023384123342111707, Final Batch Loss: 0.004811780992895365\n",
      "Epoch 6646, Loss: 0.050088394549675286, Final Batch Loss: 0.0204420555382967\n",
      "Epoch 6647, Loss: 0.06739487405866385, Final Batch Loss: 0.02474226802587509\n",
      "Epoch 6648, Loss: 0.032051187474280596, Final Batch Loss: 0.0012798956595361233\n",
      "Epoch 6649, Loss: 0.1559213511645794, Final Batch Loss: 0.08569926768541336\n",
      "Epoch 6650, Loss: 0.09277385147288442, Final Batch Loss: 0.005459542386233807\n",
      "Epoch 6651, Loss: 0.06276824348606169, Final Batch Loss: 0.002061546081677079\n",
      "Epoch 6652, Loss: 0.040086827939376235, Final Batch Loss: 0.0024501176085323095\n",
      "Epoch 6653, Loss: 0.05597307323478162, Final Batch Loss: 0.021372349932789803\n",
      "Epoch 6654, Loss: 0.027282098541036248, Final Batch Loss: 0.0028136775363236666\n",
      "Epoch 6655, Loss: 0.024924797005951405, Final Batch Loss: 0.002156165661290288\n",
      "Epoch 6656, Loss: 0.11864305753260851, Final Batch Loss: 0.08003352582454681\n",
      "Epoch 6657, Loss: 0.00390632392372936, Final Batch Loss: 0.0019562682136893272\n",
      "Epoch 6658, Loss: 0.032773202867247164, Final Batch Loss: 0.007083752192556858\n",
      "Epoch 6659, Loss: 0.05849087124806829, Final Batch Loss: 0.00040993993752636015\n",
      "Epoch 6660, Loss: 0.04973801213782281, Final Batch Loss: 0.04175414517521858\n",
      "Epoch 6661, Loss: 0.02878078632056713, Final Batch Loss: 0.0008926684968173504\n",
      "Epoch 6662, Loss: 0.0749196158722043, Final Batch Loss: 0.007815579883754253\n",
      "Epoch 6663, Loss: 0.02552584756631404, Final Batch Loss: 0.001779096433892846\n",
      "Epoch 6664, Loss: 0.026679220609366894, Final Batch Loss: 0.0033398745581507683\n",
      "Epoch 6665, Loss: 0.02235270180972293, Final Batch Loss: 0.004344114568084478\n",
      "Epoch 6666, Loss: 0.035465715220198035, Final Batch Loss: 0.01905800960958004\n",
      "Epoch 6667, Loss: 0.07744322856888175, Final Batch Loss: 0.0013186843134462833\n",
      "Epoch 6668, Loss: 0.015680956188589334, Final Batch Loss: 0.005106320604681969\n",
      "Epoch 6669, Loss: 0.01871258905157447, Final Batch Loss: 0.002103947103023529\n",
      "Epoch 6670, Loss: 0.01635690697003156, Final Batch Loss: 0.006092545110732317\n",
      "Epoch 6671, Loss: 0.01346946251578629, Final Batch Loss: 0.0016462524654343724\n",
      "Epoch 6672, Loss: 0.012567962519824505, Final Batch Loss: 0.007420304697006941\n",
      "Epoch 6673, Loss: 0.011239127605222166, Final Batch Loss: 0.0007983912946656346\n",
      "Epoch 6674, Loss: 0.0443622509483248, Final Batch Loss: 0.0012138222809880972\n",
      "Epoch 6675, Loss: 0.05767498933710158, Final Batch Loss: 0.029651589691638947\n",
      "Epoch 6676, Loss: 0.034354631206952035, Final Batch Loss: 0.025775354355573654\n",
      "Epoch 6677, Loss: 0.09085723094176501, Final Batch Loss: 0.0024749033618718386\n",
      "Epoch 6678, Loss: 0.05334030935773626, Final Batch Loss: 0.0001931526348926127\n",
      "Epoch 6679, Loss: 0.0566211809637025, Final Batch Loss: 0.0005310733104124665\n",
      "Epoch 6680, Loss: 0.05070075340336189, Final Batch Loss: 0.0070584723725914955\n",
      "Epoch 6681, Loss: 0.0066463437979109585, Final Batch Loss: 0.0005383343086577952\n",
      "Epoch 6682, Loss: 0.015888785186689347, Final Batch Loss: 0.009891591966152191\n",
      "Epoch 6683, Loss: 0.05224193539470434, Final Batch Loss: 0.00913568027317524\n",
      "Epoch 6684, Loss: 0.07623913558200002, Final Batch Loss: 0.06159721687436104\n",
      "Epoch 6685, Loss: 0.03298848029226065, Final Batch Loss: 0.015538292936980724\n",
      "Epoch 6686, Loss: 0.034706169506534934, Final Batch Loss: 0.01701287366449833\n",
      "Epoch 6687, Loss: 0.004991619091015309, Final Batch Loss: 0.0012339242966845632\n",
      "Epoch 6688, Loss: 0.11676195822656155, Final Batch Loss: 0.063181571662426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6689, Loss: 0.008642701373901218, Final Batch Loss: 0.0007600937387906015\n",
      "Epoch 6690, Loss: 0.11726482072845101, Final Batch Loss: 0.002504020929336548\n",
      "Epoch 6691, Loss: 0.012781253084540367, Final Batch Loss: 0.0031085649970918894\n",
      "Epoch 6692, Loss: 0.035346632823348045, Final Batch Loss: 0.0014828706625849009\n",
      "Epoch 6693, Loss: 0.011498002451844513, Final Batch Loss: 0.0005655580898746848\n",
      "Epoch 6694, Loss: 0.017639998462982476, Final Batch Loss: 0.006871732883155346\n",
      "Epoch 6695, Loss: 0.008919551968574524, Final Batch Loss: 0.002176248701289296\n",
      "Epoch 6696, Loss: 0.009187310934066772, Final Batch Loss: 0.0015761693939566612\n",
      "Epoch 6697, Loss: 0.009724088566144928, Final Batch Loss: 0.0001444709487259388\n",
      "Epoch 6698, Loss: 0.04753539987723343, Final Batch Loss: 0.0003895580011885613\n",
      "Epoch 6699, Loss: 0.05584029771853238, Final Batch Loss: 0.04893515259027481\n",
      "Epoch 6700, Loss: 0.009463266702368855, Final Batch Loss: 0.0025973087176680565\n",
      "Epoch 6701, Loss: 0.003193007520167157, Final Batch Loss: 0.00031753614894114435\n",
      "Epoch 6702, Loss: 0.016984810237772763, Final Batch Loss: 0.0011340887285768986\n",
      "Epoch 6703, Loss: 0.015302730142138898, Final Batch Loss: 0.0017346766544505954\n",
      "Epoch 6704, Loss: 0.009677240275777876, Final Batch Loss: 0.0006449628854170442\n",
      "Epoch 6705, Loss: 0.010038493783213198, Final Batch Loss: 0.00110999948810786\n",
      "Epoch 6706, Loss: 0.009682164702098817, Final Batch Loss: 0.0009904013713821769\n",
      "Epoch 6707, Loss: 0.015240069944411516, Final Batch Loss: 0.004146819934248924\n",
      "Epoch 6708, Loss: 0.023913883138448, Final Batch Loss: 0.00014431599993258715\n",
      "Epoch 6709, Loss: 0.010916401050053537, Final Batch Loss: 0.002944263396784663\n",
      "Epoch 6710, Loss: 0.01851521641947329, Final Batch Loss: 0.0011771832359954715\n",
      "Epoch 6711, Loss: 0.053383028716780245, Final Batch Loss: 0.007371445186436176\n",
      "Epoch 6712, Loss: 0.006537198962178081, Final Batch Loss: 0.0003749882453121245\n",
      "Epoch 6713, Loss: 0.002966793312225491, Final Batch Loss: 0.000400511606130749\n",
      "Epoch 6714, Loss: 0.006554543739184737, Final Batch Loss: 0.003983999602496624\n",
      "Epoch 6715, Loss: 0.02107334233005531, Final Batch Loss: 0.013427152298390865\n",
      "Epoch 6716, Loss: 0.004052477772347629, Final Batch Loss: 0.001163230394013226\n",
      "Epoch 6717, Loss: 0.027187368308659643, Final Batch Loss: 0.0008230920066125691\n",
      "Epoch 6718, Loss: 0.01018825895152986, Final Batch Loss: 0.0008639746229164302\n",
      "Epoch 6719, Loss: 0.009091659041587263, Final Batch Loss: 0.0004102447419427335\n",
      "Epoch 6720, Loss: 0.02739746286533773, Final Batch Loss: 0.007342459633946419\n",
      "Epoch 6721, Loss: 0.027375776029657573, Final Batch Loss: 0.0005499848048202693\n",
      "Epoch 6722, Loss: 0.02408203686354682, Final Batch Loss: 0.0015375952934846282\n",
      "Epoch 6723, Loss: 0.036524962866678834, Final Batch Loss: 0.01699298992753029\n",
      "Epoch 6724, Loss: 0.01030245260335505, Final Batch Loss: 0.0019795990083366632\n",
      "Epoch 6725, Loss: 0.0306136206490919, Final Batch Loss: 0.0012627359246835113\n",
      "Epoch 6726, Loss: 0.012276435852982104, Final Batch Loss: 0.0008296914165839553\n",
      "Epoch 6727, Loss: 0.007940993004012853, Final Batch Loss: 0.0005429459852166474\n",
      "Epoch 6728, Loss: 0.017659614386502653, Final Batch Loss: 0.0007387369987554848\n",
      "Epoch 6729, Loss: 0.0264519436750561, Final Batch Loss: 0.008877442218363285\n",
      "Epoch 6730, Loss: 0.01653720543254167, Final Batch Loss: 0.011967741884291172\n",
      "Epoch 6731, Loss: 0.03898954461328685, Final Batch Loss: 0.000607330584898591\n",
      "Epoch 6732, Loss: 0.04932909260969609, Final Batch Loss: 0.03714286908507347\n",
      "Epoch 6733, Loss: 0.028438647859729826, Final Batch Loss: 0.020855389535427094\n",
      "Epoch 6734, Loss: 0.013177089218515903, Final Batch Loss: 0.000832760997582227\n",
      "Epoch 6735, Loss: 0.050981582375243306, Final Batch Loss: 0.0014117939863353968\n",
      "Epoch 6736, Loss: 0.0843413604889065, Final Batch Loss: 0.016917971894145012\n",
      "Epoch 6737, Loss: 0.019404994149226695, Final Batch Loss: 0.0008214616100303829\n",
      "Epoch 6738, Loss: 0.008742423786316067, Final Batch Loss: 0.000389995111618191\n",
      "Epoch 6739, Loss: 0.05303762629046105, Final Batch Loss: 0.00025817411369644105\n",
      "Epoch 6740, Loss: 0.015015007113106549, Final Batch Loss: 0.0006430693319998682\n",
      "Epoch 6741, Loss: 0.0351613771636039, Final Batch Loss: 0.002051851013675332\n",
      "Epoch 6742, Loss: 0.03902761032804847, Final Batch Loss: 0.0036310225259512663\n",
      "Epoch 6743, Loss: 0.0053614709177054465, Final Batch Loss: 0.0005834489711560309\n",
      "Epoch 6744, Loss: 0.023487453174311668, Final Batch Loss: 0.00013352493988350034\n",
      "Epoch 6745, Loss: 0.029408525209873915, Final Batch Loss: 0.001966713694855571\n",
      "Epoch 6746, Loss: 0.011997726920526475, Final Batch Loss: 0.003165276488289237\n",
      "Epoch 6747, Loss: 0.004304564878111705, Final Batch Loss: 0.00032924709375947714\n",
      "Epoch 6748, Loss: 0.0402051709825173, Final Batch Loss: 0.00022586609702557325\n",
      "Epoch 6749, Loss: 0.005110366560984403, Final Batch Loss: 0.0010740102734416723\n",
      "Epoch 6750, Loss: 0.016391530632972717, Final Batch Loss: 0.004311145283281803\n",
      "Epoch 6751, Loss: 0.054560034011956304, Final Batch Loss: 0.005523783154785633\n",
      "Epoch 6752, Loss: 0.006871693447465077, Final Batch Loss: 0.004362302366644144\n",
      "Epoch 6753, Loss: 0.004739042080473155, Final Batch Loss: 0.000513862818479538\n",
      "Epoch 6754, Loss: 0.03418063651770353, Final Batch Loss: 0.008349929004907608\n",
      "Epoch 6755, Loss: 0.004605926893418655, Final Batch Loss: 0.0003274890186730772\n",
      "Epoch 6756, Loss: 0.022704222035827115, Final Batch Loss: 0.0004268373304512352\n",
      "Epoch 6757, Loss: 0.004437189141754061, Final Batch Loss: 0.0003481259918771684\n",
      "Epoch 6758, Loss: 0.03536024666391313, Final Batch Loss: 0.00032132863998413086\n",
      "Epoch 6759, Loss: 0.005203205917496234, Final Batch Loss: 0.002155373338609934\n",
      "Epoch 6760, Loss: 0.013603756931843236, Final Batch Loss: 0.00031799860880710185\n",
      "Epoch 6761, Loss: 0.005288063606712967, Final Batch Loss: 0.002056639874354005\n",
      "Epoch 6762, Loss: 0.026192944060312584, Final Batch Loss: 0.0012433059746399522\n",
      "Epoch 6763, Loss: 0.0033309990831185132, Final Batch Loss: 0.00041163116111420095\n",
      "Epoch 6764, Loss: 0.0190915513667278, Final Batch Loss: 0.01521523017436266\n",
      "Epoch 6765, Loss: 0.15804307110374793, Final Batch Loss: 0.13382433354854584\n",
      "Epoch 6766, Loss: 0.037109382916241884, Final Batch Loss: 0.006057125050574541\n",
      "Epoch 6767, Loss: 0.013981654134113342, Final Batch Loss: 0.0005161711596883833\n",
      "Epoch 6768, Loss: 0.03331466878444189, Final Batch Loss: 0.0001131107346736826\n",
      "Epoch 6769, Loss: 0.06230643065646291, Final Batch Loss: 0.0037148226983845234\n",
      "Epoch 6770, Loss: 0.08726962888613343, Final Batch Loss: 0.005170153919607401\n",
      "Epoch 6771, Loss: 0.02246833176468499, Final Batch Loss: 0.0004690436471719295\n",
      "Epoch 6772, Loss: 0.008704949636012316, Final Batch Loss: 0.0013855523429811\n",
      "Epoch 6773, Loss: 0.006132288137450814, Final Batch Loss: 0.0007551652379333973\n",
      "Epoch 6774, Loss: 0.009692012332379818, Final Batch Loss: 0.00027915206737816334\n",
      "Epoch 6775, Loss: 0.02195982472039759, Final Batch Loss: 0.002580119064077735\n",
      "Epoch 6776, Loss: 0.00382112804800272, Final Batch Loss: 0.00020239228615537286\n",
      "Epoch 6777, Loss: 0.03519942006096244, Final Batch Loss: 0.0013281396823003888\n",
      "Epoch 6778, Loss: 0.011227937997318804, Final Batch Loss: 0.003851943649351597\n",
      "Epoch 6779, Loss: 0.058796563651412725, Final Batch Loss: 0.005943394731730223\n",
      "Epoch 6780, Loss: 0.03425503592006862, Final Batch Loss: 0.018956270068883896\n",
      "Epoch 6781, Loss: 0.0032071008754428476, Final Batch Loss: 0.0003259242221247405\n",
      "Epoch 6782, Loss: 0.019366410560905933, Final Batch Loss: 0.00033811660250648856\n",
      "Epoch 6783, Loss: 0.03142308152746409, Final Batch Loss: 0.0005215957062318921\n",
      "Epoch 6784, Loss: 0.009733349550515413, Final Batch Loss: 0.0005989000201225281\n",
      "Epoch 6785, Loss: 0.007714673411101103, Final Batch Loss: 0.0011467683361843228\n",
      "Epoch 6786, Loss: 0.008929645089665428, Final Batch Loss: 0.00016315552056767046\n",
      "Epoch 6787, Loss: 0.05450229987036437, Final Batch Loss: 0.00643141008913517\n",
      "Epoch 6788, Loss: 0.00843857554718852, Final Batch Loss: 0.0016936580650508404\n",
      "Epoch 6789, Loss: 0.05374949937686324, Final Batch Loss: 0.004317453131079674\n",
      "Epoch 6790, Loss: 0.003736569662578404, Final Batch Loss: 0.0011585182510316372\n",
      "Epoch 6791, Loss: 0.012898879474960268, Final Batch Loss: 0.0004088528221473098\n",
      "Epoch 6792, Loss: 0.009960860887076706, Final Batch Loss: 0.004006624687463045\n",
      "Epoch 6793, Loss: 0.06386866519460455, Final Batch Loss: 0.000284271955024451\n",
      "Epoch 6794, Loss: 0.0056886011734604836, Final Batch Loss: 0.0004900603089481592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6795, Loss: 0.012435986020136625, Final Batch Loss: 0.0005793506861664355\n",
      "Epoch 6796, Loss: 0.0251276494236663, Final Batch Loss: 0.0008572110673412681\n",
      "Epoch 6797, Loss: 0.007523885113187134, Final Batch Loss: 0.0025976463221013546\n",
      "Epoch 6798, Loss: 0.019364683190360665, Final Batch Loss: 0.0011880847159773111\n",
      "Epoch 6799, Loss: 0.005407529009971768, Final Batch Loss: 0.00016076481551863253\n",
      "Epoch 6800, Loss: 0.010653303237631917, Final Batch Loss: 0.0007268159533850849\n",
      "Epoch 6801, Loss: 0.022568230953766033, Final Batch Loss: 0.0004931907169520855\n",
      "Epoch 6802, Loss: 0.022758712439099327, Final Batch Loss: 0.0002845064445864409\n",
      "Epoch 6803, Loss: 0.003728736948687583, Final Batch Loss: 0.001227469416335225\n",
      "Epoch 6804, Loss: 0.03298227224149741, Final Batch Loss: 0.0003934470296371728\n",
      "Epoch 6805, Loss: 0.06683104392141104, Final Batch Loss: 0.04381687939167023\n",
      "Epoch 6806, Loss: 0.01902295125182718, Final Batch Loss: 0.0017884414410218596\n",
      "Epoch 6807, Loss: 0.013402664437307976, Final Batch Loss: 7.422080670949072e-05\n",
      "Epoch 6808, Loss: 0.019141703029163182, Final Batch Loss: 0.0018822646234184504\n",
      "Epoch 6809, Loss: 0.014041514048585668, Final Batch Loss: 0.003895665518939495\n",
      "Epoch 6810, Loss: 0.005940725619439036, Final Batch Loss: 0.0009692705352790654\n",
      "Epoch 6811, Loss: 0.05956836498808116, Final Batch Loss: 0.001071576843969524\n",
      "Epoch 6812, Loss: 0.06743707033456303, Final Batch Loss: 0.05340750515460968\n",
      "Epoch 6813, Loss: 0.0044434684386942536, Final Batch Loss: 0.000279153318842873\n",
      "Epoch 6814, Loss: 0.10075196641264483, Final Batch Loss: 0.010088222101330757\n",
      "Epoch 6815, Loss: 0.015372909605503082, Final Batch Loss: 0.0010526069672778249\n",
      "Epoch 6816, Loss: 0.043391530838562176, Final Batch Loss: 0.002271686913445592\n",
      "Epoch 6817, Loss: 0.031451212242245674, Final Batch Loss: 0.007738450542092323\n",
      "Epoch 6818, Loss: 0.0325854605762288, Final Batch Loss: 0.00040615175385028124\n",
      "Epoch 6819, Loss: 0.012191591376904398, Final Batch Loss: 0.0008554410305805504\n",
      "Epoch 6820, Loss: 0.10951322969049215, Final Batch Loss: 0.06203144043684006\n",
      "Epoch 6821, Loss: 0.03127879020757973, Final Batch Loss: 0.0005169572541490197\n",
      "Epoch 6822, Loss: 0.05874798819422722, Final Batch Loss: 0.00473017618060112\n",
      "Epoch 6823, Loss: 0.07404944347217679, Final Batch Loss: 0.0071776811964809895\n",
      "Epoch 6824, Loss: 0.03392692806664854, Final Batch Loss: 0.0006066366331651807\n",
      "Epoch 6825, Loss: 0.0681951167061925, Final Batch Loss: 0.0038952487520873547\n",
      "Epoch 6826, Loss: 0.04691453312989324, Final Batch Loss: 0.000852463417686522\n",
      "Epoch 6827, Loss: 0.06485011384938844, Final Batch Loss: 0.00020716668223030865\n",
      "Epoch 6828, Loss: 0.033986974973231554, Final Batch Loss: 0.0020304247736930847\n",
      "Epoch 6829, Loss: 0.06638984545134008, Final Batch Loss: 0.038838595151901245\n",
      "Epoch 6830, Loss: 0.022015984286554158, Final Batch Loss: 0.0017304138746112585\n",
      "Epoch 6831, Loss: 0.09049730561673641, Final Batch Loss: 0.04640306159853935\n",
      "Epoch 6832, Loss: 0.04548245994374156, Final Batch Loss: 0.006299679167568684\n",
      "Epoch 6833, Loss: 0.10192419355735183, Final Batch Loss: 0.00539354095235467\n",
      "Epoch 6834, Loss: 0.0389840011484921, Final Batch Loss: 0.024843964725732803\n",
      "Epoch 6835, Loss: 0.02097340178443119, Final Batch Loss: 0.0003618457121774554\n",
      "Epoch 6836, Loss: 0.03523492289241403, Final Batch Loss: 0.00783887505531311\n",
      "Epoch 6837, Loss: 0.10856432700529695, Final Batch Loss: 0.09153197705745697\n",
      "Epoch 6838, Loss: 0.03980363951995969, Final Batch Loss: 0.012808925472199917\n",
      "Epoch 6839, Loss: 0.05495629832148552, Final Batch Loss: 0.010404915548861027\n",
      "Epoch 6840, Loss: 0.09691135259345174, Final Batch Loss: 0.034270644187927246\n",
      "Epoch 6841, Loss: 0.08567695878446102, Final Batch Loss: 0.02507024072110653\n",
      "Epoch 6842, Loss: 0.04406467475928366, Final Batch Loss: 0.013745366595685482\n",
      "Epoch 6843, Loss: 0.024931402876973152, Final Batch Loss: 0.0043868706561625\n",
      "Epoch 6844, Loss: 0.10999616945628077, Final Batch Loss: 0.10000627487897873\n",
      "Epoch 6845, Loss: 0.04702368832658976, Final Batch Loss: 0.0012727713910862803\n",
      "Epoch 6846, Loss: 0.07460112916305661, Final Batch Loss: 0.003070564940571785\n",
      "Epoch 6847, Loss: 0.02343386213760823, Final Batch Loss: 0.0012525682104751468\n",
      "Epoch 6848, Loss: 0.020758593920618296, Final Batch Loss: 0.0022666407749056816\n",
      "Epoch 6849, Loss: 0.043916042894124985, Final Batch Loss: 0.013389952480793\n",
      "Epoch 6850, Loss: 0.0451804167823866, Final Batch Loss: 0.01753636822104454\n",
      "Epoch 6851, Loss: 0.03591613098978996, Final Batch Loss: 0.006063427776098251\n",
      "Epoch 6852, Loss: 0.08246545866131783, Final Batch Loss: 0.02543005906045437\n",
      "Epoch 6853, Loss: 0.08085016254335642, Final Batch Loss: 0.003961025737226009\n",
      "Epoch 6854, Loss: 0.115540552418679, Final Batch Loss: 0.0027557085268199444\n",
      "Epoch 6855, Loss: 0.13933916296809912, Final Batch Loss: 0.04486888274550438\n",
      "Epoch 6856, Loss: 0.018860335345380008, Final Batch Loss: 0.00125415890943259\n",
      "Epoch 6857, Loss: 0.05589818628504872, Final Batch Loss: 0.0022792948875576258\n",
      "Epoch 6858, Loss: 0.03926357231102884, Final Batch Loss: 0.003482361324131489\n",
      "Epoch 6859, Loss: 0.06449898425489664, Final Batch Loss: 0.04686114937067032\n",
      "Epoch 6860, Loss: 0.03923150594346225, Final Batch Loss: 0.023983336985111237\n",
      "Epoch 6861, Loss: 0.014053544029593468, Final Batch Loss: 0.0029854075983166695\n",
      "Epoch 6862, Loss: 0.04904844705015421, Final Batch Loss: 0.0030926838517189026\n",
      "Epoch 6863, Loss: 0.06942938640713692, Final Batch Loss: 0.004804221913218498\n",
      "Epoch 6864, Loss: 0.0650330581702292, Final Batch Loss: 0.003353454638272524\n",
      "Epoch 6865, Loss: 0.013316197087988257, Final Batch Loss: 0.002010543830692768\n",
      "Epoch 6866, Loss: 0.04640652646776289, Final Batch Loss: 0.022274447605013847\n",
      "Epoch 6867, Loss: 0.03087065613362938, Final Batch Loss: 0.00048447411973029375\n",
      "Epoch 6868, Loss: 0.055717224488034844, Final Batch Loss: 0.005164307076483965\n",
      "Epoch 6869, Loss: 0.01487057947088033, Final Batch Loss: 0.006425156723707914\n",
      "Epoch 6870, Loss: 0.09864025318529457, Final Batch Loss: 0.04356028139591217\n",
      "Epoch 6871, Loss: 0.017035671626217663, Final Batch Loss: 0.0027566682547330856\n",
      "Epoch 6872, Loss: 0.020264027640223503, Final Batch Loss: 0.003282239194959402\n",
      "Epoch 6873, Loss: 0.01328856812324375, Final Batch Loss: 0.0005971546052023768\n",
      "Epoch 6874, Loss: 0.030137169640511274, Final Batch Loss: 0.002263001399114728\n",
      "Epoch 6875, Loss: 0.019988045562058687, Final Batch Loss: 0.004200759343802929\n",
      "Epoch 6876, Loss: 0.017233854508958757, Final Batch Loss: 0.003713783109560609\n",
      "Epoch 6877, Loss: 0.03196762129664421, Final Batch Loss: 0.0005828479188494384\n",
      "Epoch 6878, Loss: 0.0352461792062968, Final Batch Loss: 0.004600804299116135\n",
      "Epoch 6879, Loss: 0.009241607040166855, Final Batch Loss: 0.0005548384506255388\n",
      "Epoch 6880, Loss: 0.034433706663548946, Final Batch Loss: 0.01194036565721035\n",
      "Epoch 6881, Loss: 0.014981728396378458, Final Batch Loss: 0.00421295827254653\n",
      "Epoch 6882, Loss: 0.05068363092141226, Final Batch Loss: 0.001892492058686912\n",
      "Epoch 6883, Loss: 0.008571299375034869, Final Batch Loss: 0.0028588222339749336\n",
      "Epoch 6884, Loss: 0.018476166063919663, Final Batch Loss: 0.0059632002376019955\n",
      "Epoch 6885, Loss: 0.018316036032047123, Final Batch Loss: 0.0030173833947628736\n",
      "Epoch 6886, Loss: 0.007676966721192002, Final Batch Loss: 0.0021529654040932655\n",
      "Epoch 6887, Loss: 0.011523613473400474, Final Batch Loss: 0.0026339334435760975\n",
      "Epoch 6888, Loss: 0.02414374257205054, Final Batch Loss: 0.001006505684927106\n",
      "Epoch 6889, Loss: 0.004194241133518517, Final Batch Loss: 0.0003747345181182027\n",
      "Epoch 6890, Loss: 0.004667410161346197, Final Batch Loss: 0.0012214271118864417\n",
      "Epoch 6891, Loss: 0.023776411777362227, Final Batch Loss: 0.000553543446585536\n",
      "Epoch 6892, Loss: 0.0038711785746272653, Final Batch Loss: 0.00019825369236059487\n",
      "Epoch 6893, Loss: 0.02562373602995649, Final Batch Loss: 0.000342029903549701\n",
      "Epoch 6894, Loss: 0.01491781312506646, Final Batch Loss: 0.008299147710204124\n",
      "Epoch 6895, Loss: 0.0062288675107993186, Final Batch Loss: 0.0007188629824668169\n",
      "Epoch 6896, Loss: 0.020787114452105016, Final Batch Loss: 0.000967164698522538\n",
      "Epoch 6897, Loss: 0.03986949776299298, Final Batch Loss: 0.0013449466787278652\n",
      "Epoch 6898, Loss: 0.013361173187149689, Final Batch Loss: 0.00243345252238214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6899, Loss: 0.010782385492348112, Final Batch Loss: 0.00019510068523231894\n",
      "Epoch 6900, Loss: 0.006205120895174332, Final Batch Loss: 0.000409758766181767\n",
      "Epoch 6901, Loss: 0.012910078425193205, Final Batch Loss: 0.00024345135898329318\n",
      "Epoch 6902, Loss: 0.0549512377474457, Final Batch Loss: 0.04680044203996658\n",
      "Epoch 6903, Loss: 0.030318214325234294, Final Batch Loss: 0.011924983002245426\n",
      "Epoch 6904, Loss: 0.014089895237702876, Final Batch Loss: 0.000259379914496094\n",
      "Epoch 6905, Loss: 0.0172023443155922, Final Batch Loss: 0.0001360173337161541\n",
      "Epoch 6906, Loss: 0.019648746121674776, Final Batch Loss: 0.0005294927395880222\n",
      "Epoch 6907, Loss: 0.1754804405500181, Final Batch Loss: 0.17002800107002258\n",
      "Epoch 6908, Loss: 0.011530051124282181, Final Batch Loss: 0.002359821228310466\n",
      "Epoch 6909, Loss: 0.00477020867401734, Final Batch Loss: 0.0004979527438990772\n",
      "Epoch 6910, Loss: 0.013106144033372402, Final Batch Loss: 0.0017872194293886423\n",
      "Epoch 6911, Loss: 0.0542776194633916, Final Batch Loss: 0.0007746989140287042\n",
      "Epoch 6912, Loss: 0.013503317270078696, Final Batch Loss: 0.0002125850151060149\n",
      "Epoch 6913, Loss: 0.09381306931027211, Final Batch Loss: 0.0004207479942124337\n",
      "Epoch 6914, Loss: 0.040247137076221406, Final Batch Loss: 0.0012053231475874782\n",
      "Epoch 6915, Loss: 0.01718606846407056, Final Batch Loss: 0.005680374335497618\n",
      "Epoch 6916, Loss: 0.00639403285458684, Final Batch Loss: 0.0008835188345983624\n",
      "Epoch 6917, Loss: 0.017764476244337857, Final Batch Loss: 0.0017504016868770123\n",
      "Epoch 6918, Loss: 0.03150872967671603, Final Batch Loss: 0.020252682268619537\n",
      "Epoch 6919, Loss: 0.012216257397085428, Final Batch Loss: 0.004988788161426783\n",
      "Epoch 6920, Loss: 0.026140677509829402, Final Batch Loss: 0.00782070029526949\n",
      "Epoch 6921, Loss: 0.031132065574638546, Final Batch Loss: 0.002016599290072918\n",
      "Epoch 6922, Loss: 0.06498460011789575, Final Batch Loss: 0.000927394547034055\n",
      "Epoch 6923, Loss: 0.050862573785707355, Final Batch Loss: 0.0018726701382547617\n",
      "Epoch 6924, Loss: 0.041078406502492726, Final Batch Loss: 0.0013154518092051148\n",
      "Epoch 6925, Loss: 0.013099764299113303, Final Batch Loss: 0.006007710471749306\n",
      "Epoch 6926, Loss: 0.013344560458790511, Final Batch Loss: 0.0011627356288954616\n",
      "Epoch 6927, Loss: 0.007410868303850293, Final Batch Loss: 0.0023293031845241785\n",
      "Epoch 6928, Loss: 0.01407606154680252, Final Batch Loss: 0.001405711518600583\n",
      "Epoch 6929, Loss: 0.040312342724064365, Final Batch Loss: 0.00045236051664687693\n",
      "Epoch 6930, Loss: 0.006960602942854166, Final Batch Loss: 0.0024140523746609688\n",
      "Epoch 6931, Loss: 0.007797805184964091, Final Batch Loss: 0.0006849822821095586\n",
      "Epoch 6932, Loss: 0.018489006906747818, Final Batch Loss: 0.010526642203330994\n",
      "Epoch 6933, Loss: 0.011798742430983111, Final Batch Loss: 0.00011943947174586356\n",
      "Epoch 6934, Loss: 0.0091116750263609, Final Batch Loss: 0.00019064173102378845\n",
      "Epoch 6935, Loss: 0.10417545540258288, Final Batch Loss: 0.09264472126960754\n",
      "Epoch 6936, Loss: 0.06294688222988043, Final Batch Loss: 0.04088958725333214\n",
      "Epoch 6937, Loss: 0.016480350983329117, Final Batch Loss: 0.00027182925259694457\n",
      "Epoch 6938, Loss: 0.0167630969081074, Final Batch Loss: 0.00274101784452796\n",
      "Epoch 6939, Loss: 0.07797543262131512, Final Batch Loss: 0.05220312252640724\n",
      "Epoch 6940, Loss: 0.005821921629831195, Final Batch Loss: 0.0020984637085348368\n",
      "Epoch 6941, Loss: 0.08297898847376928, Final Batch Loss: 0.000798382272478193\n",
      "Epoch 6942, Loss: 0.06446059234440327, Final Batch Loss: 0.007605030667036772\n",
      "Epoch 6943, Loss: 0.020952652441337705, Final Batch Loss: 0.0045837354846298695\n",
      "Epoch 6944, Loss: 0.03358647250570357, Final Batch Loss: 0.0024183623027056456\n",
      "Epoch 6945, Loss: 0.03282339824363589, Final Batch Loss: 0.003227545414119959\n",
      "Epoch 6946, Loss: 0.040032224846072495, Final Batch Loss: 0.0017537089297547936\n",
      "Epoch 6947, Loss: 0.03137463494203985, Final Batch Loss: 0.002834051614627242\n",
      "Epoch 6948, Loss: 0.04297699447488412, Final Batch Loss: 0.0005177459097467363\n",
      "Epoch 6949, Loss: 0.005310087464749813, Final Batch Loss: 0.0006396662211045623\n",
      "Epoch 6950, Loss: 0.028767052572220564, Final Batch Loss: 0.007903911173343658\n",
      "Epoch 6951, Loss: 0.04719455004669726, Final Batch Loss: 0.031888119876384735\n",
      "Epoch 6952, Loss: 0.007205409652669914, Final Batch Loss: 0.0003798216057475656\n",
      "Epoch 6953, Loss: 0.12158459099009633, Final Batch Loss: 0.04285728558897972\n",
      "Epoch 6954, Loss: 0.03308609884697944, Final Batch Loss: 0.0013897117460146546\n",
      "Epoch 6955, Loss: 0.03487648535519838, Final Batch Loss: 0.0027165827341377735\n",
      "Epoch 6956, Loss: 0.06653921015094966, Final Batch Loss: 0.001753714750520885\n",
      "Epoch 6957, Loss: 0.07455565995769575, Final Batch Loss: 0.06142492592334747\n",
      "Epoch 6958, Loss: 0.009622335899621248, Final Batch Loss: 0.0006331722252070904\n",
      "Epoch 6959, Loss: 0.007632730295881629, Final Batch Loss: 0.0003707287833094597\n",
      "Epoch 6960, Loss: 0.066512864199467, Final Batch Loss: 0.04355394095182419\n",
      "Epoch 6961, Loss: 0.016181373444851488, Final Batch Loss: 0.002497855806723237\n",
      "Epoch 6962, Loss: 0.07000550534576178, Final Batch Loss: 0.038380980491638184\n",
      "Epoch 6963, Loss: 0.04446489579277113, Final Batch Loss: 0.0007981060189194977\n",
      "Epoch 6964, Loss: 0.020171144395135343, Final Batch Loss: 0.008949237875640392\n",
      "Epoch 6965, Loss: 0.059047101996839046, Final Batch Loss: 0.008622254244983196\n",
      "Epoch 6966, Loss: 0.18290347326546907, Final Batch Loss: 0.11656947433948517\n",
      "Epoch 6967, Loss: 0.013367002131417394, Final Batch Loss: 0.0005848389118909836\n",
      "Epoch 6968, Loss: 0.03269785095471889, Final Batch Loss: 0.021710842847824097\n",
      "Epoch 6969, Loss: 0.07776704709976912, Final Batch Loss: 0.04720441624522209\n",
      "Epoch 6970, Loss: 0.027067173505201936, Final Batch Loss: 0.003693151520565152\n",
      "Epoch 6971, Loss: 0.029629518277943134, Final Batch Loss: 0.009500919841229916\n",
      "Epoch 6972, Loss: 0.05991555470973253, Final Batch Loss: 0.017312051728367805\n",
      "Epoch 6973, Loss: 0.07378296088427305, Final Batch Loss: 0.016750534996390343\n",
      "Epoch 6974, Loss: 0.03457581903785467, Final Batch Loss: 0.007191200274974108\n",
      "Epoch 6975, Loss: 0.04355735032004304, Final Batch Loss: 0.00032092936453409493\n",
      "Epoch 6976, Loss: 0.06913317181169987, Final Batch Loss: 0.010031701065599918\n",
      "Epoch 6977, Loss: 0.0638327426277101, Final Batch Loss: 0.030439874157309532\n",
      "Epoch 6978, Loss: 0.04646943602710962, Final Batch Loss: 0.028497830033302307\n",
      "Epoch 6979, Loss: 0.07646185299381614, Final Batch Loss: 0.01521691121160984\n",
      "Epoch 6980, Loss: 0.023996176605578512, Final Batch Loss: 0.0009165801457129419\n",
      "Epoch 6981, Loss: 0.025782023323699832, Final Batch Loss: 0.0027134770061820745\n",
      "Epoch 6982, Loss: 0.046419376973062754, Final Batch Loss: 0.02994626946747303\n",
      "Epoch 6983, Loss: 0.04257697844877839, Final Batch Loss: 0.003959725610911846\n",
      "Epoch 6984, Loss: 0.028970512561500072, Final Batch Loss: 0.006438862066715956\n",
      "Epoch 6985, Loss: 0.026316483970731497, Final Batch Loss: 0.00025704805739223957\n",
      "Epoch 6986, Loss: 0.03217117709573358, Final Batch Loss: 0.006456958130002022\n",
      "Epoch 6987, Loss: 0.020818608405534178, Final Batch Loss: 0.0009764223941601813\n",
      "Epoch 6988, Loss: 0.007903664605692029, Final Batch Loss: 0.001238267868757248\n",
      "Epoch 6989, Loss: 0.0666209754999727, Final Batch Loss: 0.0012648697011172771\n",
      "Epoch 6990, Loss: 0.04966599238105118, Final Batch Loss: 0.03844752535223961\n",
      "Epoch 6991, Loss: 0.018497322336770594, Final Batch Loss: 0.011870374903082848\n",
      "Epoch 6992, Loss: 0.06061782967299223, Final Batch Loss: 0.01765897125005722\n",
      "Epoch 6993, Loss: 0.03217122727073729, Final Batch Loss: 0.002516851294785738\n",
      "Epoch 6994, Loss: 0.07650536415167153, Final Batch Loss: 0.0020221241284161806\n",
      "Epoch 6995, Loss: 0.056719327229075134, Final Batch Loss: 0.0014350953279063106\n",
      "Epoch 6996, Loss: 0.04460716526955366, Final Batch Loss: 0.027779502794146538\n",
      "Epoch 6997, Loss: 0.07606308476533741, Final Batch Loss: 0.05327143147587776\n",
      "Epoch 6998, Loss: 0.021542742964811623, Final Batch Loss: 0.000870035495609045\n",
      "Epoch 6999, Loss: 0.013415524270385504, Final Batch Loss: 0.0021428214386105537\n",
      "Epoch 7000, Loss: 0.043826361652463675, Final Batch Loss: 0.0009191795252263546\n",
      "Epoch 7001, Loss: 0.05027556873392314, Final Batch Loss: 0.025012565776705742\n",
      "Epoch 7002, Loss: 0.014746417931746691, Final Batch Loss: 0.0004129940061829984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7003, Loss: 0.010510231710213702, Final Batch Loss: 0.00010251125058857724\n",
      "Epoch 7004, Loss: 0.07877586958056781, Final Batch Loss: 0.06409350782632828\n",
      "Epoch 7005, Loss: 0.02718200022354722, Final Batch Loss: 0.002306395210325718\n",
      "Epoch 7006, Loss: 0.05688412603922188, Final Batch Loss: 0.001660009496845305\n",
      "Epoch 7007, Loss: 0.03127134987153113, Final Batch Loss: 0.00030949199572205544\n",
      "Epoch 7008, Loss: 0.04471098689828068, Final Batch Loss: 0.0014135745586827397\n",
      "Epoch 7009, Loss: 0.04503153171390295, Final Batch Loss: 0.006004041526466608\n",
      "Epoch 7010, Loss: 0.013074998161755502, Final Batch Loss: 0.000718634226359427\n",
      "Epoch 7011, Loss: 0.01642895967233926, Final Batch Loss: 0.001982607878744602\n",
      "Epoch 7012, Loss: 0.056302193901501596, Final Batch Loss: 0.001461148145608604\n",
      "Epoch 7013, Loss: 0.01871441787807271, Final Batch Loss: 0.0004423973732627928\n",
      "Epoch 7014, Loss: 0.023372764000669122, Final Batch Loss: 0.0009375470690429211\n",
      "Epoch 7015, Loss: 0.0037411234225146472, Final Batch Loss: 0.0015113407280296087\n",
      "Epoch 7016, Loss: 0.029746212909230962, Final Batch Loss: 0.01806756481528282\n",
      "Epoch 7017, Loss: 0.012594679486937821, Final Batch Loss: 0.0030953690875321627\n",
      "Epoch 7018, Loss: 0.03668105264659971, Final Batch Loss: 0.0006827809847891331\n",
      "Epoch 7019, Loss: 0.014082054141908884, Final Batch Loss: 0.0019250555196776986\n",
      "Epoch 7020, Loss: 0.006705757288727909, Final Batch Loss: 0.003032981650903821\n",
      "Epoch 7021, Loss: 0.009735061088576913, Final Batch Loss: 0.0037406643386930227\n",
      "Epoch 7022, Loss: 0.02252477966248989, Final Batch Loss: 0.0012137745507061481\n",
      "Epoch 7023, Loss: 0.00893879568320699, Final Batch Loss: 0.00034424863406457007\n",
      "Epoch 7024, Loss: 0.00491400808095932, Final Batch Loss: 0.0006961836479604244\n",
      "Epoch 7025, Loss: 0.012261431547813118, Final Batch Loss: 0.001112957950681448\n",
      "Epoch 7026, Loss: 0.008297950611449778, Final Batch Loss: 0.002500376431271434\n",
      "Epoch 7027, Loss: 0.012652579753194004, Final Batch Loss: 0.007980862632393837\n",
      "Epoch 7028, Loss: 0.03796968550886959, Final Batch Loss: 0.010927665047347546\n",
      "Epoch 7029, Loss: 0.03978895349428058, Final Batch Loss: 0.0011081424308940768\n",
      "Epoch 7030, Loss: 0.00692070071818307, Final Batch Loss: 0.0021631454583257437\n",
      "Epoch 7031, Loss: 0.021789219666970894, Final Batch Loss: 0.0003954623534809798\n",
      "Epoch 7032, Loss: 0.02722359972540289, Final Batch Loss: 0.0005278629250824451\n",
      "Epoch 7033, Loss: 0.004914014745736495, Final Batch Loss: 0.0003927618672605604\n",
      "Epoch 7034, Loss: 0.01684543985174969, Final Batch Loss: 0.0006038518622517586\n",
      "Epoch 7035, Loss: 0.009641362470574677, Final Batch Loss: 0.0010457116877660155\n",
      "Epoch 7036, Loss: 0.0028803960885852575, Final Batch Loss: 0.0010061758803203702\n",
      "Epoch 7037, Loss: 0.03253281064098701, Final Batch Loss: 0.03031313046813011\n",
      "Epoch 7038, Loss: 0.026530178729444742, Final Batch Loss: 0.0020812186412513256\n",
      "Epoch 7039, Loss: 0.007627946819411591, Final Batch Loss: 0.00034189820871688426\n",
      "Epoch 7040, Loss: 0.010616996209137142, Final Batch Loss: 0.0006444695172831416\n",
      "Epoch 7041, Loss: 0.03944292280357331, Final Batch Loss: 0.0009935753187164664\n",
      "Epoch 7042, Loss: 0.029968002185341902, Final Batch Loss: 0.00016953855811152607\n",
      "Epoch 7043, Loss: 0.030696663772687316, Final Batch Loss: 0.0038457075133919716\n",
      "Epoch 7044, Loss: 0.03163142182165757, Final Batch Loss: 0.0004400050383992493\n",
      "Epoch 7045, Loss: 0.01198758982354775, Final Batch Loss: 0.0007379375747404993\n",
      "Epoch 7046, Loss: 0.04490787602844648, Final Batch Loss: 0.0004205384466331452\n",
      "Epoch 7047, Loss: 0.05499788821907714, Final Batch Loss: 0.00031831912929192185\n",
      "Epoch 7048, Loss: 0.028787688119336963, Final Batch Loss: 0.006712983828037977\n",
      "Epoch 7049, Loss: 0.028941325494088233, Final Batch Loss: 0.00688893673941493\n",
      "Epoch 7050, Loss: 0.02846195304300636, Final Batch Loss: 0.0017660384764894843\n",
      "Epoch 7051, Loss: 0.04618326522177085, Final Batch Loss: 0.0018746255664154887\n",
      "Epoch 7052, Loss: 0.06635214947164059, Final Batch Loss: 0.01932830549776554\n",
      "Epoch 7053, Loss: 0.04136856464901939, Final Batch Loss: 0.0001364875352010131\n",
      "Epoch 7054, Loss: 0.10670606163330376, Final Batch Loss: 0.03150404989719391\n",
      "Epoch 7055, Loss: 0.025481772332568653, Final Batch Loss: 0.00013655931979883462\n",
      "Epoch 7056, Loss: 0.03676157956942916, Final Batch Loss: 0.003077580127865076\n",
      "Epoch 7057, Loss: 0.014905951218679547, Final Batch Loss: 0.0014643382746726274\n",
      "Epoch 7058, Loss: 0.042504012933932245, Final Batch Loss: 0.0045152464881539345\n",
      "Epoch 7059, Loss: 0.04185230683651753, Final Batch Loss: 0.0002899067767430097\n",
      "Epoch 7060, Loss: 0.012597202556207776, Final Batch Loss: 0.0008162218146026134\n",
      "Epoch 7061, Loss: 0.012210880988277495, Final Batch Loss: 0.0016149991424754262\n",
      "Epoch 7062, Loss: 0.038043808308430016, Final Batch Loss: 0.01439523696899414\n",
      "Epoch 7063, Loss: 0.009570248192176223, Final Batch Loss: 0.0018734997138381004\n",
      "Epoch 7064, Loss: 0.0548299178481102, Final Batch Loss: 0.0015203066868707538\n",
      "Epoch 7065, Loss: 0.01355120656080544, Final Batch Loss: 0.0004629127215594053\n",
      "Epoch 7066, Loss: 0.007304867031052709, Final Batch Loss: 0.004552582278847694\n",
      "Epoch 7067, Loss: 0.01851105981040746, Final Batch Loss: 0.014488711021840572\n",
      "Epoch 7068, Loss: 0.00812676252098754, Final Batch Loss: 0.003066262463107705\n",
      "Epoch 7069, Loss: 0.07877312717027962, Final Batch Loss: 0.0016061405185610056\n",
      "Epoch 7070, Loss: 0.02615510649047792, Final Batch Loss: 0.00220495299436152\n",
      "Epoch 7071, Loss: 0.030290480935946107, Final Batch Loss: 0.0002796964254230261\n",
      "Epoch 7072, Loss: 0.008428146131336689, Final Batch Loss: 0.0010225065052509308\n",
      "Epoch 7073, Loss: 0.043574164737947285, Final Batch Loss: 0.0021228629630059004\n",
      "Epoch 7074, Loss: 0.05609074863605201, Final Batch Loss: 0.0071646347641944885\n",
      "Epoch 7075, Loss: 0.012960092746652663, Final Batch Loss: 0.0005723732756450772\n",
      "Epoch 7076, Loss: 0.005184318273677491, Final Batch Loss: 0.00020137480169069022\n",
      "Epoch 7077, Loss: 0.006749840278644115, Final Batch Loss: 0.0010615368373692036\n",
      "Epoch 7078, Loss: 0.007080834766384214, Final Batch Loss: 0.00018919416470453143\n",
      "Epoch 7079, Loss: 0.003760028863325715, Final Batch Loss: 0.0011591225629672408\n",
      "Epoch 7080, Loss: 0.006126296291768085, Final Batch Loss: 6.116340955486521e-05\n",
      "Epoch 7081, Loss: 0.010757624579127878, Final Batch Loss: 0.0021624965593218803\n",
      "Epoch 7082, Loss: 0.01696641417220235, Final Batch Loss: 0.0014410389121621847\n",
      "Epoch 7083, Loss: 0.009299355908297002, Final Batch Loss: 0.00472567742690444\n",
      "Epoch 7084, Loss: 0.08092148753348738, Final Batch Loss: 0.0025495346635580063\n",
      "Epoch 7085, Loss: 0.02159232326084748, Final Batch Loss: 0.0006885419716127217\n",
      "Epoch 7086, Loss: 0.0322526030940935, Final Batch Loss: 0.005861514713615179\n",
      "Epoch 7087, Loss: 0.018933006358565763, Final Batch Loss: 0.000374212657334283\n",
      "Epoch 7088, Loss: 0.02066504955291748, Final Batch Loss: 0.002042361767962575\n",
      "Epoch 7089, Loss: 0.010186536906985566, Final Batch Loss: 0.003837286727502942\n",
      "Epoch 7090, Loss: 0.04370548442238942, Final Batch Loss: 0.02786199375987053\n",
      "Epoch 7091, Loss: 0.02387737261597067, Final Batch Loss: 0.003453461453318596\n",
      "Epoch 7092, Loss: 0.02844391667167656, Final Batch Loss: 0.0003584559017326683\n",
      "Epoch 7093, Loss: 0.017360662342980504, Final Batch Loss: 0.002384826308116317\n",
      "Epoch 7094, Loss: 0.019457432674244046, Final Batch Loss: 0.0011246937792748213\n",
      "Epoch 7095, Loss: 0.011857759847771376, Final Batch Loss: 0.0008944780565798283\n",
      "Epoch 7096, Loss: 0.014203611528500915, Final Batch Loss: 0.0008144248276948929\n",
      "Epoch 7097, Loss: 0.007697296387050301, Final Batch Loss: 0.0003850852372124791\n",
      "Epoch 7098, Loss: 0.012429448368493468, Final Batch Loss: 0.0026954789645969868\n",
      "Epoch 7099, Loss: 0.0041203337896149606, Final Batch Loss: 0.0004213069623801857\n",
      "Epoch 7100, Loss: 0.008975401928182691, Final Batch Loss: 0.0009920104639604688\n",
      "Epoch 7101, Loss: 0.04229599016252905, Final Batch Loss: 0.00041294610127806664\n",
      "Epoch 7102, Loss: 0.0063521953707095236, Final Batch Loss: 0.000347094057360664\n",
      "Epoch 7103, Loss: 0.00794548011617735, Final Batch Loss: 0.00043203201494179666\n",
      "Epoch 7104, Loss: 0.007880637655034661, Final Batch Loss: 0.0006403852021321654\n",
      "Epoch 7105, Loss: 0.018915305845439434, Final Batch Loss: 0.00345054198987782\n",
      "Epoch 7106, Loss: 0.015075401781359687, Final Batch Loss: 0.002277173101902008\n",
      "Epoch 7107, Loss: 0.008323228728841059, Final Batch Loss: 0.00018258790078107268\n",
      "Epoch 7108, Loss: 0.09855075521045364, Final Batch Loss: 0.09297072142362595\n",
      "Epoch 7109, Loss: 0.027042167261242867, Final Batch Loss: 0.003415639977902174\n",
      "Epoch 7110, Loss: 0.009040613134857267, Final Batch Loss: 0.0010509085841476917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7111, Loss: 0.008746230276301503, Final Batch Loss: 0.003863167017698288\n",
      "Epoch 7112, Loss: 0.003567432111594826, Final Batch Loss: 0.00037953798891976476\n",
      "Epoch 7113, Loss: 0.0061494278779719025, Final Batch Loss: 0.00019494243315421045\n",
      "Epoch 7114, Loss: 0.012770173110766336, Final Batch Loss: 0.00017062629922293127\n",
      "Epoch 7115, Loss: 0.022313141613267362, Final Batch Loss: 0.0012877110857516527\n",
      "Epoch 7116, Loss: 0.007183736102888361, Final Batch Loss: 0.00017351048882119358\n",
      "Epoch 7117, Loss: 0.07731267079361714, Final Batch Loss: 0.07343344390392303\n",
      "Epoch 7118, Loss: 0.03506146452855319, Final Batch Loss: 0.01099967397749424\n",
      "Epoch 7119, Loss: 0.05693499790504575, Final Batch Loss: 0.007976978085935116\n",
      "Epoch 7120, Loss: 0.021730637177824974, Final Batch Loss: 0.0012880915310233831\n",
      "Epoch 7121, Loss: 0.05114496452733874, Final Batch Loss: 0.012007398530840874\n",
      "Epoch 7122, Loss: 0.039378058863803744, Final Batch Loss: 0.00550812529399991\n",
      "Epoch 7123, Loss: 0.13990526413545012, Final Batch Loss: 0.08039568364620209\n",
      "Epoch 7124, Loss: 0.06806854082969949, Final Batch Loss: 0.0008676867000758648\n",
      "Epoch 7125, Loss: 0.029298757202923298, Final Batch Loss: 0.007230408955365419\n",
      "Epoch 7126, Loss: 0.04489374696277082, Final Batch Loss: 0.023599468171596527\n",
      "Epoch 7127, Loss: 0.02098411729093641, Final Batch Loss: 0.0006735835922881961\n",
      "Epoch 7128, Loss: 0.053114985465072095, Final Batch Loss: 0.0009013036033138633\n",
      "Epoch 7129, Loss: 0.03587599820457399, Final Batch Loss: 0.0014500231482088566\n",
      "Epoch 7130, Loss: 0.04532399290474132, Final Batch Loss: 0.035595640540122986\n",
      "Epoch 7131, Loss: 0.02673114649951458, Final Batch Loss: 0.0014362394576892257\n",
      "Epoch 7132, Loss: 0.03428053169045597, Final Batch Loss: 0.0009278407087549567\n",
      "Epoch 7133, Loss: 0.05452053854241967, Final Batch Loss: 0.0020941761322319508\n",
      "Epoch 7134, Loss: 0.07022464904002845, Final Batch Loss: 0.0411042682826519\n",
      "Epoch 7135, Loss: 0.10811058769468218, Final Batch Loss: 0.07555895298719406\n",
      "Epoch 7136, Loss: 0.0408165724365972, Final Batch Loss: 0.0008679362363182008\n",
      "Epoch 7137, Loss: 0.08522276114672422, Final Batch Loss: 0.013957197777926922\n",
      "Epoch 7138, Loss: 0.03508224757388234, Final Batch Loss: 0.009241239167749882\n",
      "Epoch 7139, Loss: 0.0686431904323399, Final Batch Loss: 0.005767519120126963\n",
      "Epoch 7140, Loss: 0.015420750190969557, Final Batch Loss: 0.0010419593891128898\n",
      "Epoch 7141, Loss: 0.060367107042111456, Final Batch Loss: 0.0015607815003022552\n",
      "Epoch 7142, Loss: 0.015957355499267578, Final Batch Loss: 0.002043630927801132\n",
      "Epoch 7143, Loss: 0.03104562422959134, Final Batch Loss: 0.0008804206736385822\n",
      "Epoch 7144, Loss: 0.037769453367218375, Final Batch Loss: 0.0014152433723211288\n",
      "Epoch 7145, Loss: 0.02770935371518135, Final Batch Loss: 0.0013341389130800962\n",
      "Epoch 7146, Loss: 0.01859506801702082, Final Batch Loss: 0.013087404891848564\n",
      "Epoch 7147, Loss: 0.00787214725278318, Final Batch Loss: 0.002423074096441269\n",
      "Epoch 7148, Loss: 0.0494332336820662, Final Batch Loss: 0.010807245038449764\n",
      "Epoch 7149, Loss: 0.030796460807323456, Final Batch Loss: 0.008541594259440899\n",
      "Epoch 7150, Loss: 0.007725645788013935, Final Batch Loss: 0.0036778023932129145\n",
      "Epoch 7151, Loss: 0.020574216614477336, Final Batch Loss: 0.011192839592695236\n",
      "Epoch 7152, Loss: 0.02418996673077345, Final Batch Loss: 0.009473998099565506\n",
      "Epoch 7153, Loss: 0.02066618378739804, Final Batch Loss: 0.0016545153921470046\n",
      "Epoch 7154, Loss: 0.016722274711355567, Final Batch Loss: 0.0031150472350418568\n",
      "Epoch 7155, Loss: 0.09684925759211183, Final Batch Loss: 0.08303903043270111\n",
      "Epoch 7156, Loss: 0.014296239765826613, Final Batch Loss: 0.000908117217477411\n",
      "Epoch 7157, Loss: 0.012835857924073935, Final Batch Loss: 0.0012307361466810107\n",
      "Epoch 7158, Loss: 0.0063070520118344575, Final Batch Loss: 0.00039246087544597685\n",
      "Epoch 7159, Loss: 0.01829611009452492, Final Batch Loss: 0.00105818931479007\n",
      "Epoch 7160, Loss: 0.021986281615681946, Final Batch Loss: 0.0035809576511383057\n",
      "Epoch 7161, Loss: 0.027263793745078146, Final Batch Loss: 0.004751383792608976\n",
      "Epoch 7162, Loss: 0.03541698062326759, Final Batch Loss: 0.020804764702916145\n",
      "Epoch 7163, Loss: 0.038486335484776646, Final Batch Loss: 0.0005310683627612889\n",
      "Epoch 7164, Loss: 0.012514624366303906, Final Batch Loss: 0.000133057328639552\n",
      "Epoch 7165, Loss: 0.03097663470543921, Final Batch Loss: 0.00200862274505198\n",
      "Epoch 7166, Loss: 0.015353231108747423, Final Batch Loss: 0.01098044216632843\n",
      "Epoch 7167, Loss: 0.026816270663402975, Final Batch Loss: 0.0016506961546838284\n",
      "Epoch 7168, Loss: 0.010680918931029737, Final Batch Loss: 0.001144837005995214\n",
      "Epoch 7169, Loss: 0.02027985648601316, Final Batch Loss: 0.0001631561608519405\n",
      "Epoch 7170, Loss: 0.033695348480250686, Final Batch Loss: 0.000576749152969569\n",
      "Epoch 7171, Loss: 0.019053806667216122, Final Batch Loss: 0.0031423489563167095\n",
      "Epoch 7172, Loss: 0.11152993561699986, Final Batch Loss: 0.0890265628695488\n",
      "Epoch 7173, Loss: 0.017876766389235854, Final Batch Loss: 0.001943475566804409\n",
      "Epoch 7174, Loss: 0.09988874313421547, Final Batch Loss: 0.07304152101278305\n",
      "Epoch 7175, Loss: 0.018201974919065833, Final Batch Loss: 0.0042871893383562565\n",
      "Epoch 7176, Loss: 0.04430816578678787, Final Batch Loss: 0.035783156752586365\n",
      "Epoch 7177, Loss: 0.06479702750220895, Final Batch Loss: 0.04766685515642166\n",
      "Epoch 7178, Loss: 0.026002402417361736, Final Batch Loss: 0.00672489870339632\n",
      "Epoch 7179, Loss: 0.06188988720532507, Final Batch Loss: 0.04252057895064354\n",
      "Epoch 7180, Loss: 0.02727115945890546, Final Batch Loss: 0.0029508296865969896\n",
      "Epoch 7181, Loss: 0.013856304984074086, Final Batch Loss: 0.0019012826960533857\n",
      "Epoch 7182, Loss: 0.08003874751739204, Final Batch Loss: 0.0036944986786693335\n",
      "Epoch 7183, Loss: 0.04832492885179818, Final Batch Loss: 0.0078890360891819\n",
      "Epoch 7184, Loss: 0.01625908352434635, Final Batch Loss: 0.008635085076093674\n",
      "Epoch 7185, Loss: 0.02076209575170651, Final Batch Loss: 0.0005542236031033099\n",
      "Epoch 7186, Loss: 0.02162545925239101, Final Batch Loss: 0.0023153529036790133\n",
      "Epoch 7187, Loss: 0.01165400492027402, Final Batch Loss: 0.0016626655124127865\n",
      "Epoch 7188, Loss: 0.015742394898552448, Final Batch Loss: 0.0005653361440636218\n",
      "Epoch 7189, Loss: 0.02277421671897173, Final Batch Loss: 0.0031805073376744986\n",
      "Epoch 7190, Loss: 0.002849707700079307, Final Batch Loss: 0.00040105663356371224\n",
      "Epoch 7191, Loss: 0.0039013155619613826, Final Batch Loss: 0.00020953943021595478\n",
      "Epoch 7192, Loss: 0.03391005302546546, Final Batch Loss: 0.030405361205339432\n",
      "Epoch 7193, Loss: 0.021195109700784087, Final Batch Loss: 0.010318126529455185\n",
      "Epoch 7194, Loss: 0.04462503199465573, Final Batch Loss: 0.0009619629709050059\n",
      "Epoch 7195, Loss: 0.005470917792990804, Final Batch Loss: 0.0036447877064347267\n",
      "Epoch 7196, Loss: 0.03372727910755202, Final Batch Loss: 0.0012752754846587777\n",
      "Epoch 7197, Loss: 0.005052528576925397, Final Batch Loss: 0.0007648349856026471\n",
      "Epoch 7198, Loss: 0.006005441857269034, Final Batch Loss: 0.00037113952566869557\n",
      "Epoch 7199, Loss: 0.011560503276996315, Final Batch Loss: 0.0002606717753224075\n",
      "Epoch 7200, Loss: 0.014218842901755124, Final Batch Loss: 0.0007617114461027086\n",
      "Epoch 7201, Loss: 0.03113829658832401, Final Batch Loss: 0.0007959487265907228\n",
      "Epoch 7202, Loss: 0.00741621432825923, Final Batch Loss: 0.004513912368565798\n",
      "Epoch 7203, Loss: 0.021204809192568064, Final Batch Loss: 0.01617882400751114\n",
      "Epoch 7204, Loss: 0.0058800679398700595, Final Batch Loss: 0.002046376233920455\n",
      "Epoch 7205, Loss: 0.011978603564784862, Final Batch Loss: 0.0002373288298258558\n",
      "Epoch 7206, Loss: 0.010371347598265857, Final Batch Loss: 0.00744760362431407\n",
      "Epoch 7207, Loss: 0.009011766764160711, Final Batch Loss: 5.546597094507888e-05\n",
      "Epoch 7208, Loss: 0.03907165926648304, Final Batch Loss: 0.022826800122857094\n",
      "Epoch 7209, Loss: 0.025445559062063694, Final Batch Loss: 0.0006861091824248433\n",
      "Epoch 7210, Loss: 0.05020419612992555, Final Batch Loss: 0.0009302442194893956\n",
      "Epoch 7211, Loss: 0.0672658322728239, Final Batch Loss: 0.0007772766402922571\n",
      "Epoch 7212, Loss: 0.036698915355373174, Final Batch Loss: 0.01856119930744171\n",
      "Epoch 7213, Loss: 0.06445530982455239, Final Batch Loss: 0.027028806507587433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7214, Loss: 0.04362716805189848, Final Batch Loss: 0.024148540571331978\n",
      "Epoch 7215, Loss: 0.0967938534449786, Final Batch Loss: 0.014962747693061829\n",
      "Epoch 7216, Loss: 0.04938303120434284, Final Batch Loss: 0.002852670382708311\n",
      "Epoch 7217, Loss: 0.1654839611146599, Final Batch Loss: 0.15399132668972015\n",
      "Epoch 7218, Loss: 0.06609636452049017, Final Batch Loss: 0.015038925223052502\n",
      "Epoch 7219, Loss: 0.03556616551941261, Final Batch Loss: 0.0005935602239333093\n",
      "Epoch 7220, Loss: 0.04559009399963543, Final Batch Loss: 0.0003551130066625774\n",
      "Epoch 7221, Loss: 0.0331288295565173, Final Batch Loss: 0.02140291966497898\n",
      "Epoch 7222, Loss: 0.02607395127415657, Final Batch Loss: 0.0019945059902966022\n",
      "Epoch 7223, Loss: 0.08197472407482564, Final Batch Loss: 0.0016079430934041739\n",
      "Epoch 7224, Loss: 0.03713173570577055, Final Batch Loss: 0.0006550857797265053\n",
      "Epoch 7225, Loss: 0.03216564212925732, Final Batch Loss: 0.0020683107431977987\n",
      "Epoch 7226, Loss: 0.024199246428906918, Final Batch Loss: 0.008307536132633686\n",
      "Epoch 7227, Loss: 0.015153181971982121, Final Batch Loss: 0.0009138700552284718\n",
      "Epoch 7228, Loss: 0.015617578173987567, Final Batch Loss: 0.0012495735427364707\n",
      "Epoch 7229, Loss: 0.025841701833996922, Final Batch Loss: 0.0009755334467627108\n",
      "Epoch 7230, Loss: 0.028291125898249447, Final Batch Loss: 0.0013534395257011056\n",
      "Epoch 7231, Loss: 0.018947756150737405, Final Batch Loss: 0.0010164343984797597\n",
      "Epoch 7232, Loss: 0.07748922402970493, Final Batch Loss: 0.003861717414110899\n",
      "Epoch 7233, Loss: 0.023441029217792675, Final Batch Loss: 0.0004403004131745547\n",
      "Epoch 7234, Loss: 0.028399894014000893, Final Batch Loss: 0.006395761854946613\n",
      "Epoch 7235, Loss: 0.008726994681637734, Final Batch Loss: 0.0010576595086604357\n",
      "Epoch 7236, Loss: 0.009347072365926579, Final Batch Loss: 0.0007259798003360629\n",
      "Epoch 7237, Loss: 0.025623494409956038, Final Batch Loss: 0.00967385433614254\n",
      "Epoch 7238, Loss: 0.010569295554887503, Final Batch Loss: 0.004029756877571344\n",
      "Epoch 7239, Loss: 0.029926155460998416, Final Batch Loss: 0.0016483922954648733\n",
      "Epoch 7240, Loss: 0.027020437992177904, Final Batch Loss: 0.0003469045041128993\n",
      "Epoch 7241, Loss: 0.020364137133583426, Final Batch Loss: 0.008008139207959175\n",
      "Epoch 7242, Loss: 0.040269944816827774, Final Batch Loss: 0.002029446419328451\n",
      "Epoch 7243, Loss: 0.013526561175240204, Final Batch Loss: 0.0004057350743096322\n",
      "Epoch 7244, Loss: 0.03796100663021207, Final Batch Loss: 0.02005142532289028\n",
      "Epoch 7245, Loss: 0.011887992732226849, Final Batch Loss: 0.00018865312449634075\n",
      "Epoch 7246, Loss: 0.03611415141494945, Final Batch Loss: 0.00630816537886858\n",
      "Epoch 7247, Loss: 0.0741945942863822, Final Batch Loss: 0.013560991734266281\n",
      "Epoch 7248, Loss: 0.010724707371991826, Final Batch Loss: 5.233367483015172e-05\n",
      "Epoch 7249, Loss: 0.012985303706955165, Final Batch Loss: 0.00028352014487609267\n",
      "Epoch 7250, Loss: 0.012473955168388784, Final Batch Loss: 0.0027834484353661537\n",
      "Epoch 7251, Loss: 0.017749726946931332, Final Batch Loss: 0.0006724958657287061\n",
      "Epoch 7252, Loss: 0.11679901124443859, Final Batch Loss: 0.0005565601168200374\n",
      "Epoch 7253, Loss: 0.014951267163269222, Final Batch Loss: 0.0018488779896870255\n",
      "Epoch 7254, Loss: 0.0703024931717664, Final Batch Loss: 0.003020105417817831\n",
      "Epoch 7255, Loss: 0.02214870520401746, Final Batch Loss: 0.005573345348238945\n",
      "Epoch 7256, Loss: 0.017044868087396026, Final Batch Loss: 0.0021282525267452\n",
      "Epoch 7257, Loss: 0.019631732284324244, Final Batch Loss: 0.0002555188548285514\n",
      "Epoch 7258, Loss: 0.02254467993043363, Final Batch Loss: 0.0011942125856876373\n",
      "Epoch 7259, Loss: 0.012063425150699914, Final Batch Loss: 0.00029427953995764256\n",
      "Epoch 7260, Loss: 0.008433915150817484, Final Batch Loss: 0.002507132710888982\n",
      "Epoch 7261, Loss: 0.007256383425556123, Final Batch Loss: 0.0009874094976112247\n",
      "Epoch 7262, Loss: 0.028361921082250774, Final Batch Loss: 0.004260452929884195\n",
      "Epoch 7263, Loss: 0.019258268090197816, Final Batch Loss: 0.00030268882983364165\n",
      "Epoch 7264, Loss: 0.03684981493279338, Final Batch Loss: 0.003434353042393923\n",
      "Epoch 7265, Loss: 0.015560184547211975, Final Batch Loss: 0.00011180524597875774\n",
      "Epoch 7266, Loss: 0.009650381747633219, Final Batch Loss: 0.0013914036098867655\n",
      "Epoch 7267, Loss: 0.005215713143115863, Final Batch Loss: 0.0010523052187636495\n",
      "Epoch 7268, Loss: 0.0028107625257689506, Final Batch Loss: 0.00045121589209884405\n",
      "Epoch 7269, Loss: 0.003759193990845233, Final Batch Loss: 0.0004923559608869255\n",
      "Epoch 7270, Loss: 0.0035731062234845012, Final Batch Loss: 0.00010037331958301365\n",
      "Epoch 7271, Loss: 0.04154585988726467, Final Batch Loss: 0.0017591299256309867\n",
      "Epoch 7272, Loss: 0.1858213908271864, Final Batch Loss: 0.17966993153095245\n",
      "Epoch 7273, Loss: 0.1838266032282263, Final Batch Loss: 0.13097453117370605\n",
      "Epoch 7274, Loss: 0.09408184699714184, Final Batch Loss: 0.06071711704134941\n",
      "Epoch 7275, Loss: 0.028876180615043268, Final Batch Loss: 0.0003802381397690624\n",
      "Epoch 7276, Loss: 0.03439186466857791, Final Batch Loss: 0.0037553906440734863\n",
      "Epoch 7277, Loss: 0.016643576585920528, Final Batch Loss: 0.00043934889254160225\n",
      "Epoch 7278, Loss: 0.05375466123223305, Final Batch Loss: 0.018249234184622765\n",
      "Epoch 7279, Loss: 0.006176256807520986, Final Batch Loss: 0.0011212705867365003\n",
      "Epoch 7280, Loss: 0.04116552299819887, Final Batch Loss: 0.030956747010350227\n",
      "Epoch 7281, Loss: 0.013074313086690381, Final Batch Loss: 0.0003922116302419454\n",
      "Epoch 7282, Loss: 0.029374395438935608, Final Batch Loss: 0.0007431734702549875\n",
      "Epoch 7283, Loss: 0.05172570823924616, Final Batch Loss: 0.0004933043965138495\n",
      "Epoch 7284, Loss: 0.015640411467757076, Final Batch Loss: 0.004059505648910999\n",
      "Epoch 7285, Loss: 0.0466518223984167, Final Batch Loss: 0.0013069974957033992\n",
      "Epoch 7286, Loss: 0.05186034122016281, Final Batch Loss: 0.0009769181488081813\n",
      "Epoch 7287, Loss: 0.03849131800234318, Final Batch Loss: 0.01742689311504364\n",
      "Epoch 7288, Loss: 0.05257115117274225, Final Batch Loss: 0.005557715892791748\n",
      "Epoch 7289, Loss: 0.04899158189073205, Final Batch Loss: 0.019760482013225555\n",
      "Epoch 7290, Loss: 0.02440996328368783, Final Batch Loss: 0.00509880855679512\n",
      "Epoch 7291, Loss: 0.04651594953611493, Final Batch Loss: 0.004964800085872412\n",
      "Epoch 7292, Loss: 0.05943049676716328, Final Batch Loss: 0.012636971659958363\n",
      "Epoch 7293, Loss: 0.021898601087741554, Final Batch Loss: 0.0009993937565013766\n",
      "Epoch 7294, Loss: 0.012376694532576948, Final Batch Loss: 0.0005978698027320206\n",
      "Epoch 7295, Loss: 0.05339450540486723, Final Batch Loss: 0.011329141445457935\n",
      "Epoch 7296, Loss: 0.0545640978962183, Final Batch Loss: 0.04289352893829346\n",
      "Epoch 7297, Loss: 0.00971270736772567, Final Batch Loss: 0.001489926129579544\n",
      "Epoch 7298, Loss: 0.027527224272489548, Final Batch Loss: 0.016929086297750473\n",
      "Epoch 7299, Loss: 0.02274622325785458, Final Batch Loss: 0.005633289460092783\n",
      "Epoch 7300, Loss: 0.007881384575739503, Final Batch Loss: 0.0015550414100289345\n",
      "Epoch 7301, Loss: 0.03289361082715914, Final Batch Loss: 0.0009559124591760337\n",
      "Epoch 7302, Loss: 0.012561637617181987, Final Batch Loss: 0.0008239441667683423\n",
      "Epoch 7303, Loss: 0.03848532447591424, Final Batch Loss: 0.03121885657310486\n",
      "Epoch 7304, Loss: 0.008353927929420024, Final Batch Loss: 0.004088269080966711\n",
      "Epoch 7305, Loss: 0.17877815011888742, Final Batch Loss: 0.11287882924079895\n",
      "Epoch 7306, Loss: 0.04374292548163794, Final Batch Loss: 0.01032679807394743\n",
      "Epoch 7307, Loss: 0.019602624175604433, Final Batch Loss: 0.0006544559146277606\n",
      "Epoch 7308, Loss: 0.05647379718720913, Final Batch Loss: 0.00301038334146142\n",
      "Epoch 7309, Loss: 0.06078908476047218, Final Batch Loss: 0.007121751084923744\n",
      "Epoch 7310, Loss: 0.01663576136343181, Final Batch Loss: 0.002782973926514387\n",
      "Epoch 7311, Loss: 0.013662958604982123, Final Batch Loss: 0.0002731348795350641\n",
      "Epoch 7312, Loss: 0.021431615110486746, Final Batch Loss: 0.009580619633197784\n",
      "Epoch 7313, Loss: 0.10120630171149969, Final Batch Loss: 0.07126329839229584\n",
      "Epoch 7314, Loss: 0.035034358967095613, Final Batch Loss: 0.0188848115503788\n",
      "Epoch 7315, Loss: 0.018103249953128397, Final Batch Loss: 0.011413361877202988\n",
      "Epoch 7316, Loss: 0.014669886557385325, Final Batch Loss: 0.0011621668236330152\n",
      "Epoch 7317, Loss: 0.008460153359919786, Final Batch Loss: 0.002154811518266797\n",
      "Epoch 7318, Loss: 0.010929784446489066, Final Batch Loss: 0.0021324430126696825\n",
      "Epoch 7319, Loss: 0.02805727702798322, Final Batch Loss: 0.001718701678328216\n",
      "Epoch 7320, Loss: 0.024938951479271054, Final Batch Loss: 0.006318049971014261\n",
      "Epoch 7321, Loss: 0.024373001884669065, Final Batch Loss: 0.004661689978092909\n",
      "Epoch 7322, Loss: 0.005456142593175173, Final Batch Loss: 0.0013519367203116417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7323, Loss: 0.01723749376833439, Final Batch Loss: 0.0008927621529437602\n",
      "Epoch 7324, Loss: 0.012458223674912006, Final Batch Loss: 0.0007849631947465241\n",
      "Epoch 7325, Loss: 0.028486215160228312, Final Batch Loss: 0.002985194558277726\n",
      "Epoch 7326, Loss: 0.013931645080447197, Final Batch Loss: 0.0025172263849526644\n",
      "Epoch 7327, Loss: 0.06795681803487241, Final Batch Loss: 0.03931313380599022\n",
      "Epoch 7328, Loss: 0.028742115304339677, Final Batch Loss: 0.0005894124624319375\n",
      "Epoch 7329, Loss: 0.0054891619947738945, Final Batch Loss: 0.0006412293296307325\n",
      "Epoch 7330, Loss: 0.030726270750164986, Final Batch Loss: 0.0009972755797207355\n",
      "Epoch 7331, Loss: 0.05598152906168252, Final Batch Loss: 0.00155926076695323\n",
      "Epoch 7332, Loss: 0.012353819445706904, Final Batch Loss: 0.0010524268727749586\n",
      "Epoch 7333, Loss: 0.024048748367931694, Final Batch Loss: 0.0005486821173690259\n",
      "Epoch 7334, Loss: 0.01743538776645437, Final Batch Loss: 0.011882172897458076\n",
      "Epoch 7335, Loss: 0.029541140655055642, Final Batch Loss: 0.005255661439150572\n",
      "Epoch 7336, Loss: 0.003390516241779551, Final Batch Loss: 0.00046801791177131236\n",
      "Epoch 7337, Loss: 0.03722060174914077, Final Batch Loss: 0.0006082791951484978\n",
      "Epoch 7338, Loss: 0.026210330936009996, Final Batch Loss: 0.00024090999795589596\n",
      "Epoch 7339, Loss: 0.03928857250139117, Final Batch Loss: 0.0035724129993468523\n",
      "Epoch 7340, Loss: 0.030495826504193246, Final Batch Loss: 0.023231009021401405\n",
      "Epoch 7341, Loss: 0.00939642684534192, Final Batch Loss: 0.0035338217858225107\n",
      "Epoch 7342, Loss: 0.045234862132929265, Final Batch Loss: 0.038701578974723816\n",
      "Epoch 7343, Loss: 0.00858411070657894, Final Batch Loss: 0.0029896367341279984\n",
      "Epoch 7344, Loss: 0.021353973541408777, Final Batch Loss: 0.004027734976261854\n",
      "Epoch 7345, Loss: 0.016149442963069305, Final Batch Loss: 0.00037622448871843517\n",
      "Epoch 7346, Loss: 0.006379986647516489, Final Batch Loss: 0.001240005949512124\n",
      "Epoch 7347, Loss: 0.008278521840111353, Final Batch Loss: 0.00015619858459103853\n",
      "Epoch 7348, Loss: 0.033930343168322, Final Batch Loss: 0.003137178486213088\n",
      "Epoch 7349, Loss: 0.012361585919279605, Final Batch Loss: 0.0004395227297209203\n",
      "Epoch 7350, Loss: 0.006348501658067107, Final Batch Loss: 0.00036422014818526804\n",
      "Epoch 7351, Loss: 0.05370767111890018, Final Batch Loss: 0.02950809895992279\n",
      "Epoch 7352, Loss: 0.002482997690094635, Final Batch Loss: 0.00029792438726872206\n",
      "Epoch 7353, Loss: 0.021636438614223152, Final Batch Loss: 0.0002555973478592932\n",
      "Epoch 7354, Loss: 0.009603056474588811, Final Batch Loss: 0.0028441958129405975\n",
      "Epoch 7355, Loss: 0.019922747276723385, Final Batch Loss: 0.013136660680174828\n",
      "Epoch 7356, Loss: 0.01949108816916123, Final Batch Loss: 0.009657262824475765\n",
      "Epoch 7357, Loss: 0.08113538473844528, Final Batch Loss: 0.04584749415516853\n",
      "Epoch 7358, Loss: 0.027631712378934026, Final Batch Loss: 0.01334955170750618\n",
      "Epoch 7359, Loss: 0.011408643564209342, Final Batch Loss: 0.008422033861279488\n",
      "Epoch 7360, Loss: 0.0674956567818299, Final Batch Loss: 0.0030863566789776087\n",
      "Epoch 7361, Loss: 0.015107854967936873, Final Batch Loss: 0.0003136890009045601\n",
      "Epoch 7362, Loss: 0.029564862954430282, Final Batch Loss: 0.002039328683167696\n",
      "Epoch 7363, Loss: 0.00957668450428173, Final Batch Loss: 0.0007232048665173352\n",
      "Epoch 7364, Loss: 0.013207849813625216, Final Batch Loss: 0.0048715537413954735\n",
      "Epoch 7365, Loss: 0.012992103889700957, Final Batch Loss: 0.00014977682440076023\n",
      "Epoch 7366, Loss: 0.004938203754136339, Final Batch Loss: 0.0019394606351852417\n",
      "Epoch 7367, Loss: 0.017096944386139512, Final Batch Loss: 0.006625375244766474\n",
      "Epoch 7368, Loss: 0.01034318447636906, Final Batch Loss: 0.0001572802575537935\n",
      "Epoch 7369, Loss: 0.019667816522996873, Final Batch Loss: 0.004301141481846571\n",
      "Epoch 7370, Loss: 0.04775523961870931, Final Batch Loss: 0.00040762874414213\n",
      "Epoch 7371, Loss: 0.008684433298185468, Final Batch Loss: 0.00040996811003424227\n",
      "Epoch 7372, Loss: 0.02304736798396334, Final Batch Loss: 0.0021556259598582983\n",
      "Epoch 7373, Loss: 0.00963652464270126, Final Batch Loss: 3.435490361880511e-05\n",
      "Epoch 7374, Loss: 0.04399339447263628, Final Batch Loss: 0.000584656372666359\n",
      "Epoch 7375, Loss: 0.010193119873292744, Final Batch Loss: 0.0020591774955391884\n",
      "Epoch 7376, Loss: 0.019723827834241092, Final Batch Loss: 0.012678324244916439\n",
      "Epoch 7377, Loss: 0.025057280116016045, Final Batch Loss: 0.0003042925673071295\n",
      "Epoch 7378, Loss: 0.004634811251889914, Final Batch Loss: 0.002099341480061412\n",
      "Epoch 7379, Loss: 0.017062657047063112, Final Batch Loss: 0.0037117062602192163\n",
      "Epoch 7380, Loss: 0.004748205450596288, Final Batch Loss: 0.002379985526204109\n",
      "Epoch 7381, Loss: 0.007135216175811365, Final Batch Loss: 0.0024714048486202955\n",
      "Epoch 7382, Loss: 0.053787343844305724, Final Batch Loss: 0.000511079269926995\n",
      "Epoch 7383, Loss: 0.012120907776989043, Final Batch Loss: 0.003636486828327179\n",
      "Epoch 7384, Loss: 0.08422082872129977, Final Batch Loss: 0.07174922525882721\n",
      "Epoch 7385, Loss: 0.015851340431254357, Final Batch Loss: 0.0009047822677530348\n",
      "Epoch 7386, Loss: 0.029374145553447306, Final Batch Loss: 0.00110232038423419\n",
      "Epoch 7387, Loss: 0.10471056797541678, Final Batch Loss: 0.048134323209524155\n",
      "Epoch 7388, Loss: 0.01792777539230883, Final Batch Loss: 0.013348901644349098\n",
      "Epoch 7389, Loss: 0.0525206236197846, Final Batch Loss: 0.0001292371453018859\n",
      "Epoch 7390, Loss: 0.025655609788373113, Final Batch Loss: 0.010681216605007648\n",
      "Epoch 7391, Loss: 0.0162781176622957, Final Batch Loss: 0.00330276763997972\n",
      "Epoch 7392, Loss: 0.036416532937437296, Final Batch Loss: 0.00041096273344010115\n",
      "Epoch 7393, Loss: 0.06697691255249083, Final Batch Loss: 0.03661157935857773\n",
      "Epoch 7394, Loss: 0.05895078566391021, Final Batch Loss: 0.0004201302072033286\n",
      "Epoch 7395, Loss: 0.05629637435777113, Final Batch Loss: 0.04433729872107506\n",
      "Epoch 7396, Loss: 0.016414391226135194, Final Batch Loss: 0.001196902128867805\n",
      "Epoch 7397, Loss: 0.0565705222543329, Final Batch Loss: 0.002414602553471923\n",
      "Epoch 7398, Loss: 0.04551714030094445, Final Batch Loss: 0.03034159727394581\n",
      "Epoch 7399, Loss: 0.05215982557274401, Final Batch Loss: 0.027078542858362198\n",
      "Epoch 7400, Loss: 0.06559024145826697, Final Batch Loss: 0.0034437100403010845\n",
      "Epoch 7401, Loss: 0.10048578516580164, Final Batch Loss: 0.008979473263025284\n",
      "Epoch 7402, Loss: 0.02607158594764769, Final Batch Loss: 0.00798244308680296\n",
      "Epoch 7403, Loss: 0.036068877670913935, Final Batch Loss: 0.028481334447860718\n",
      "Epoch 7404, Loss: 0.03543918649666011, Final Batch Loss: 0.017619242891669273\n",
      "Epoch 7405, Loss: 0.09187598433345556, Final Batch Loss: 0.030480707064270973\n",
      "Epoch 7406, Loss: 0.10790757182985544, Final Batch Loss: 0.03873085975646973\n",
      "Epoch 7407, Loss: 0.11586517631076276, Final Batch Loss: 0.049683716148138046\n",
      "Epoch 7408, Loss: 0.0633857015054673, Final Batch Loss: 0.03272514417767525\n",
      "Epoch 7409, Loss: 0.06309196207439527, Final Batch Loss: 0.0006042015156708658\n",
      "Epoch 7410, Loss: 0.04145290981978178, Final Batch Loss: 0.0022596241906285286\n",
      "Epoch 7411, Loss: 0.021320186438970268, Final Batch Loss: 0.0004484140081331134\n",
      "Epoch 7412, Loss: 0.09492518939077854, Final Batch Loss: 0.032174449414014816\n",
      "Epoch 7413, Loss: 0.0720178410410881, Final Batch Loss: 0.0248861126601696\n",
      "Epoch 7414, Loss: 0.05035013519227505, Final Batch Loss: 0.01017820555716753\n",
      "Epoch 7415, Loss: 0.08470935933291912, Final Batch Loss: 0.026977622881531715\n",
      "Epoch 7416, Loss: 0.02718594390898943, Final Batch Loss: 0.005347771570086479\n",
      "Epoch 7417, Loss: 0.08313218830153346, Final Batch Loss: 0.018328646197915077\n",
      "Epoch 7418, Loss: 0.025921463267877698, Final Batch Loss: 0.0033580113667994738\n",
      "Epoch 7419, Loss: 0.019210277823731303, Final Batch Loss: 0.0034176481422036886\n",
      "Epoch 7420, Loss: 0.053205394418910146, Final Batch Loss: 0.004109871108084917\n",
      "Epoch 7421, Loss: 0.011834336328320205, Final Batch Loss: 0.007854531519114971\n",
      "Epoch 7422, Loss: 0.006267805641982704, Final Batch Loss: 0.0019055323209613562\n",
      "Epoch 7423, Loss: 0.14189902693033218, Final Batch Loss: 0.05775243043899536\n",
      "Epoch 7424, Loss: 0.13930987019557506, Final Batch Loss: 0.12415086477994919\n",
      "Epoch 7425, Loss: 0.1277154586277902, Final Batch Loss: 0.0011875531636178493\n",
      "Epoch 7426, Loss: 0.028680881951004267, Final Batch Loss: 0.007062781136482954\n",
      "Epoch 7427, Loss: 0.0457282143906923, Final Batch Loss: 0.00019924559455830604\n",
      "Epoch 7428, Loss: 0.07909829029813409, Final Batch Loss: 0.04013712704181671\n",
      "Epoch 7429, Loss: 0.06608200364280492, Final Batch Loss: 0.0006324854912236333\n",
      "Epoch 7430, Loss: 0.0505275665782392, Final Batch Loss: 0.009656304493546486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7431, Loss: 0.029589725425466895, Final Batch Loss: 0.0014335655141621828\n",
      "Epoch 7432, Loss: 0.050351708894595504, Final Batch Loss: 0.003701104549691081\n",
      "Epoch 7433, Loss: 0.026980545837432146, Final Batch Loss: 0.002390854526311159\n",
      "Epoch 7434, Loss: 0.05036161397583783, Final Batch Loss: 0.0021388947498053312\n",
      "Epoch 7435, Loss: 0.0234700795263052, Final Batch Loss: 0.0072330511175096035\n",
      "Epoch 7436, Loss: 0.013730682083405554, Final Batch Loss: 0.0012590241385623813\n",
      "Epoch 7437, Loss: 0.06020993855781853, Final Batch Loss: 0.0011498986277729273\n",
      "Epoch 7438, Loss: 0.02487478288821876, Final Batch Loss: 0.012389308772981167\n",
      "Epoch 7439, Loss: 0.14256958477199078, Final Batch Loss: 0.12262256443500519\n",
      "Epoch 7440, Loss: 0.03230300405994058, Final Batch Loss: 0.01931837573647499\n",
      "Epoch 7441, Loss: 0.09445101208984852, Final Batch Loss: 0.04109780862927437\n",
      "Epoch 7442, Loss: 0.04586726659908891, Final Batch Loss: 0.014400028623640537\n",
      "Epoch 7443, Loss: 0.06020119180902839, Final Batch Loss: 0.04221007972955704\n",
      "Epoch 7444, Loss: 0.028888257453218102, Final Batch Loss: 0.008831876330077648\n",
      "Epoch 7445, Loss: 0.05503149188007228, Final Batch Loss: 0.03104914352297783\n",
      "Epoch 7446, Loss: 0.010888706776313484, Final Batch Loss: 0.0008498814422637224\n",
      "Epoch 7447, Loss: 0.21390955336391926, Final Batch Loss: 0.03068811260163784\n",
      "Epoch 7448, Loss: 0.02349362662062049, Final Batch Loss: 0.0032317074947059155\n",
      "Epoch 7449, Loss: 0.0908705968176946, Final Batch Loss: 0.05530974641442299\n",
      "Epoch 7450, Loss: 0.02896460727788508, Final Batch Loss: 0.005311985034495592\n",
      "Epoch 7451, Loss: 0.0624224878847599, Final Batch Loss: 0.02037396840751171\n",
      "Epoch 7452, Loss: 0.0347350116353482, Final Batch Loss: 0.0030665206722915173\n",
      "Epoch 7453, Loss: 0.013062554644420743, Final Batch Loss: 0.0010694721713662148\n",
      "Epoch 7454, Loss: 0.09712668188876705, Final Batch Loss: 9.379309631185606e-05\n",
      "Epoch 7455, Loss: 0.01587090315297246, Final Batch Loss: 0.0034145480021834373\n",
      "Epoch 7456, Loss: 0.12011399283073843, Final Batch Loss: 0.1094217300415039\n",
      "Epoch 7457, Loss: 0.035183158004656434, Final Batch Loss: 0.002196528483182192\n",
      "Epoch 7458, Loss: 0.055447743739932775, Final Batch Loss: 0.03312288969755173\n",
      "Epoch 7459, Loss: 0.02992314100265503, Final Batch Loss: 0.0036947354674339294\n",
      "Epoch 7460, Loss: 0.06916724797338247, Final Batch Loss: 0.019259173423051834\n",
      "Epoch 7461, Loss: 0.03287801658734679, Final Batch Loss: 0.013167103752493858\n",
      "Epoch 7462, Loss: 0.028068578452803195, Final Batch Loss: 0.0018985586939379573\n",
      "Epoch 7463, Loss: 0.025846096104942262, Final Batch Loss: 0.01705571822822094\n",
      "Epoch 7464, Loss: 0.021628439193591475, Final Batch Loss: 0.0019429970998317003\n",
      "Epoch 7465, Loss: 0.01594064326491207, Final Batch Loss: 0.009427757933735847\n",
      "Epoch 7466, Loss: 0.01621715712826699, Final Batch Loss: 0.010371441021561623\n",
      "Epoch 7467, Loss: 0.04255376779474318, Final Batch Loss: 0.0019594186451286077\n",
      "Epoch 7468, Loss: 0.0470061469823122, Final Batch Loss: 0.042410679161548615\n",
      "Epoch 7469, Loss: 0.010016815038397908, Final Batch Loss: 0.0006813985528424382\n",
      "Epoch 7470, Loss: 0.02925488678738475, Final Batch Loss: 0.00453533697873354\n",
      "Epoch 7471, Loss: 0.012572073203045875, Final Batch Loss: 0.00084636703832075\n",
      "Epoch 7472, Loss: 0.016593303997069597, Final Batch Loss: 0.0031872810795903206\n",
      "Epoch 7473, Loss: 0.02009393705520779, Final Batch Loss: 0.0033466871827840805\n",
      "Epoch 7474, Loss: 0.030672626744490117, Final Batch Loss: 0.00012622954091057181\n",
      "Epoch 7475, Loss: 0.00993849744554609, Final Batch Loss: 0.0016693010693416\n",
      "Epoch 7476, Loss: 0.010209330037469044, Final Batch Loss: 0.0004429382097441703\n",
      "Epoch 7477, Loss: 0.05238363437820226, Final Batch Loss: 0.004509943537414074\n",
      "Epoch 7478, Loss: 0.023592687575728633, Final Batch Loss: 0.000211286373087205\n",
      "Epoch 7479, Loss: 0.02203244506381452, Final Batch Loss: 0.006276789586991072\n",
      "Epoch 7480, Loss: 0.023911390220746398, Final Batch Loss: 0.003793313167989254\n",
      "Epoch 7481, Loss: 0.06837654579430819, Final Batch Loss: 0.0461183600127697\n",
      "Epoch 7482, Loss: 0.03756165818776935, Final Batch Loss: 0.007787761278450489\n",
      "Epoch 7483, Loss: 0.040348795242607594, Final Batch Loss: 0.003993445076048374\n",
      "Epoch 7484, Loss: 0.015311279566958547, Final Batch Loss: 0.006286624353379011\n",
      "Epoch 7485, Loss: 0.023228089907206595, Final Batch Loss: 0.0010945367394015193\n",
      "Epoch 7486, Loss: 0.017371568246744573, Final Batch Loss: 0.0031827951315790415\n",
      "Epoch 7487, Loss: 0.015876962745096534, Final Batch Loss: 0.0015435477253049612\n",
      "Epoch 7488, Loss: 0.04040779126808047, Final Batch Loss: 0.0048192827962338924\n",
      "Epoch 7489, Loss: 0.01699116063537076, Final Batch Loss: 0.0002855326165445149\n",
      "Epoch 7490, Loss: 0.016453687625471503, Final Batch Loss: 0.0008182902238331735\n",
      "Epoch 7491, Loss: 0.03764910652535036, Final Batch Loss: 0.02071297913789749\n",
      "Epoch 7492, Loss: 0.022730958298780024, Final Batch Loss: 0.001788197667337954\n",
      "Epoch 7493, Loss: 0.047053972724825144, Final Batch Loss: 0.02693905495107174\n",
      "Epoch 7494, Loss: 0.04980376991443336, Final Batch Loss: 0.0019320097053423524\n",
      "Epoch 7495, Loss: 0.0194007785175927, Final Batch Loss: 0.0003155735903419554\n",
      "Epoch 7496, Loss: 0.02946367545519024, Final Batch Loss: 0.003444792702794075\n",
      "Epoch 7497, Loss: 0.030910763307474554, Final Batch Loss: 0.02317626215517521\n",
      "Epoch 7498, Loss: 0.06444357382133603, Final Batch Loss: 0.034785155206918716\n",
      "Epoch 7499, Loss: 0.0424178761895746, Final Batch Loss: 0.009473645128309727\n",
      "Epoch 7500, Loss: 0.01690553466323763, Final Batch Loss: 0.005019811447709799\n",
      "Epoch 7501, Loss: 0.049689964624121785, Final Batch Loss: 0.0030419875402003527\n",
      "Epoch 7502, Loss: 0.03421630524098873, Final Batch Loss: 0.002560975030064583\n",
      "Epoch 7503, Loss: 0.03524957306217402, Final Batch Loss: 0.000920260208658874\n",
      "Epoch 7504, Loss: 0.07070996961556375, Final Batch Loss: 0.025746507570147514\n",
      "Epoch 7505, Loss: 0.023267575656063855, Final Batch Loss: 0.0010848578531295061\n",
      "Epoch 7506, Loss: 0.07323778606951237, Final Batch Loss: 0.06144816055893898\n",
      "Epoch 7507, Loss: 0.006128844048362225, Final Batch Loss: 0.0001575656933709979\n",
      "Epoch 7508, Loss: 0.06800239463336766, Final Batch Loss: 0.001111176097765565\n",
      "Epoch 7509, Loss: 0.04173042275942862, Final Batch Loss: 0.02021227404475212\n",
      "Epoch 7510, Loss: 0.04886305006220937, Final Batch Loss: 0.0026590412016958\n",
      "Epoch 7511, Loss: 0.104172044666484, Final Batch Loss: 0.05183352902531624\n",
      "Epoch 7512, Loss: 0.007733923615887761, Final Batch Loss: 0.0007679861155338585\n",
      "Epoch 7513, Loss: 0.009969854494556785, Final Batch Loss: 0.0006127546657808125\n",
      "Epoch 7514, Loss: 0.05848915921524167, Final Batch Loss: 0.006687254179269075\n",
      "Epoch 7515, Loss: 0.06143717863596976, Final Batch Loss: 0.0229443721473217\n",
      "Epoch 7516, Loss: 0.003329210157971829, Final Batch Loss: 0.000645160733256489\n",
      "Epoch 7517, Loss: 0.02193451592756901, Final Batch Loss: 0.00016412454715464264\n",
      "Epoch 7518, Loss: 0.014513942514895461, Final Batch Loss: 0.00012314766354393214\n",
      "Epoch 7519, Loss: 0.022961339447647333, Final Batch Loss: 0.0017613725503906608\n",
      "Epoch 7520, Loss: 0.004690467962063849, Final Batch Loss: 0.0008380934596061707\n",
      "Epoch 7521, Loss: 0.009765524242538959, Final Batch Loss: 0.0007319569704122841\n",
      "Epoch 7522, Loss: 0.01853932475205511, Final Batch Loss: 0.0020266303326934576\n",
      "Epoch 7523, Loss: 0.021495574852451682, Final Batch Loss: 0.002466459758579731\n",
      "Epoch 7524, Loss: 0.010121647093910724, Final Batch Loss: 0.003979191649705172\n",
      "Epoch 7525, Loss: 0.02892825665185228, Final Batch Loss: 0.000492700666654855\n",
      "Epoch 7526, Loss: 0.004291483841370791, Final Batch Loss: 0.0011243955232203007\n",
      "Epoch 7527, Loss: 0.029994129363331012, Final Batch Loss: 0.00021391471091192216\n",
      "Epoch 7528, Loss: 0.03932425822131336, Final Batch Loss: 0.000443173514213413\n",
      "Epoch 7529, Loss: 0.005979772889986634, Final Batch Loss: 0.0004609867464751005\n",
      "Epoch 7530, Loss: 0.01345366658642888, Final Batch Loss: 0.0015789101598784328\n",
      "Epoch 7531, Loss: 0.03245709137991071, Final Batch Loss: 0.006452476140111685\n",
      "Epoch 7532, Loss: 0.005635555760818534, Final Batch Loss: 0.0006076399586163461\n",
      "Epoch 7533, Loss: 0.061853065504692495, Final Batch Loss: 0.059055738151073456\n",
      "Epoch 7534, Loss: 0.02146084900596179, Final Batch Loss: 0.01866505667567253\n",
      "Epoch 7535, Loss: 0.02848413831088692, Final Batch Loss: 0.014646395109593868\n",
      "Epoch 7536, Loss: 0.03224174678325653, Final Batch Loss: 0.0018987064249813557\n",
      "Epoch 7537, Loss: 0.09732815623283386, Final Batch Loss: 0.02486944943666458\n",
      "Epoch 7538, Loss: 0.02667540474794805, Final Batch Loss: 0.0032098761294037104\n",
      "Epoch 7539, Loss: 0.022446335293352604, Final Batch Loss: 0.005962510593235493\n",
      "Epoch 7540, Loss: 0.03894915012642741, Final Batch Loss: 0.0025593936443328857\n",
      "Epoch 7541, Loss: 0.019043968408368528, Final Batch Loss: 0.0009762368863448501\n",
      "Epoch 7542, Loss: 0.022474998724646866, Final Batch Loss: 0.005934539716690779\n",
      "Epoch 7543, Loss: 0.047593660186976194, Final Batch Loss: 0.021435778588056564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7544, Loss: 0.034296267200261354, Final Batch Loss: 0.004059020429849625\n",
      "Epoch 7545, Loss: 0.007607918290887028, Final Batch Loss: 0.003887998638674617\n",
      "Epoch 7546, Loss: 0.030810142285190523, Final Batch Loss: 0.0008229577215388417\n",
      "Epoch 7547, Loss: 0.04457004775758833, Final Batch Loss: 0.0014198421267792583\n",
      "Epoch 7548, Loss: 0.029907036281656474, Final Batch Loss: 0.0005903791752643883\n",
      "Epoch 7549, Loss: 0.017416711532860063, Final Batch Loss: 0.00018864065350499004\n",
      "Epoch 7550, Loss: 0.04270684951916337, Final Batch Loss: 0.005172416567802429\n",
      "Epoch 7551, Loss: 0.01351014873944223, Final Batch Loss: 0.0014444759581238031\n",
      "Epoch 7552, Loss: 0.04679455514997244, Final Batch Loss: 0.0018147341907024384\n",
      "Epoch 7553, Loss: 0.011870155110955238, Final Batch Loss: 0.0008417458739131689\n",
      "Epoch 7554, Loss: 0.030123870354145765, Final Batch Loss: 0.008575673215091228\n",
      "Epoch 7555, Loss: 0.007674504508031532, Final Batch Loss: 0.002140295458957553\n",
      "Epoch 7556, Loss: 0.022801442304626107, Final Batch Loss: 0.009192741475999355\n",
      "Epoch 7557, Loss: 0.02511448468430899, Final Batch Loss: 0.0002687569649424404\n",
      "Epoch 7558, Loss: 0.005069664592156187, Final Batch Loss: 0.0014512799680233002\n",
      "Epoch 7559, Loss: 0.049723775176971685, Final Batch Loss: 0.00011605937470449135\n",
      "Epoch 7560, Loss: 0.027348835312295705, Final Batch Loss: 0.020032990723848343\n",
      "Epoch 7561, Loss: 0.007434133556671441, Final Batch Loss: 0.0013067425461485982\n",
      "Epoch 7562, Loss: 0.006312292214715853, Final Batch Loss: 0.0016821245662868023\n",
      "Epoch 7563, Loss: 0.07874282133707311, Final Batch Loss: 0.052940331399440765\n",
      "Epoch 7564, Loss: 0.0074735600501298904, Final Batch Loss: 0.00038283923640847206\n",
      "Epoch 7565, Loss: 0.021197295747697353, Final Batch Loss: 0.0003702434478327632\n",
      "Epoch 7566, Loss: 0.025063909823074937, Final Batch Loss: 0.0010755995754152536\n",
      "Epoch 7567, Loss: 0.014538645278662443, Final Batch Loss: 0.002305547473952174\n",
      "Epoch 7568, Loss: 0.008049499883782119, Final Batch Loss: 0.0033410685136914253\n",
      "Epoch 7569, Loss: 0.008044593036174774, Final Batch Loss: 0.0011704883072525263\n",
      "Epoch 7570, Loss: 0.01580562343588099, Final Batch Loss: 0.012395266443490982\n",
      "Epoch 7571, Loss: 0.0187983435971546, Final Batch Loss: 4.673492367146537e-05\n",
      "Epoch 7572, Loss: 0.01953266529017128, Final Batch Loss: 0.00155078514944762\n",
      "Epoch 7573, Loss: 0.029052823316305876, Final Batch Loss: 0.0012844183947890997\n",
      "Epoch 7574, Loss: 0.027980015496723354, Final Batch Loss: 0.024503765627741814\n",
      "Epoch 7575, Loss: 0.039187951129861176, Final Batch Loss: 0.0007124739931896329\n",
      "Epoch 7576, Loss: 0.01631784762139432, Final Batch Loss: 0.00821306649595499\n",
      "Epoch 7577, Loss: 0.035029644903261214, Final Batch Loss: 0.00854511559009552\n",
      "Epoch 7578, Loss: 0.0186943169683218, Final Batch Loss: 0.0027116909623146057\n",
      "Epoch 7579, Loss: 0.04326053929980844, Final Batch Loss: 0.0030214188154786825\n",
      "Epoch 7580, Loss: 0.012410632451064885, Final Batch Loss: 0.002010645344853401\n",
      "Epoch 7581, Loss: 0.007923087861854583, Final Batch Loss: 0.00019182477262802422\n",
      "Epoch 7582, Loss: 0.014458908350206912, Final Batch Loss: 0.0036289410199970007\n",
      "Epoch 7583, Loss: 0.042546578944893554, Final Batch Loss: 0.00015892021474428475\n",
      "Epoch 7584, Loss: 0.006855095212813467, Final Batch Loss: 0.0008613445679657161\n",
      "Epoch 7585, Loss: 0.009467957730521448, Final Batch Loss: 4.145941056776792e-05\n",
      "Epoch 7586, Loss: 0.003254738578107208, Final Batch Loss: 0.0017438901122659445\n",
      "Epoch 7587, Loss: 0.034599015838466585, Final Batch Loss: 0.02615540847182274\n",
      "Epoch 7588, Loss: 0.005501383449882269, Final Batch Loss: 0.00084087741561234\n",
      "Epoch 7589, Loss: 0.06265855056699365, Final Batch Loss: 6.285717245191336e-05\n",
      "Epoch 7590, Loss: 0.005619680654490367, Final Batch Loss: 0.0009319534292444587\n",
      "Epoch 7591, Loss: 0.03189351852051914, Final Batch Loss: 0.0007562753744423389\n",
      "Epoch 7592, Loss: 0.016492335591465235, Final Batch Loss: 0.0006821505958214402\n",
      "Epoch 7593, Loss: 0.025698211044073105, Final Batch Loss: 0.0009767699521034956\n",
      "Epoch 7594, Loss: 0.007449536817148328, Final Batch Loss: 0.0022179591469466686\n",
      "Epoch 7595, Loss: 0.021891429991228506, Final Batch Loss: 0.0009222619119100273\n",
      "Epoch 7596, Loss: 0.028456676698624506, Final Batch Loss: 2.3622362277819775e-05\n",
      "Epoch 7597, Loss: 0.006991477101109922, Final Batch Loss: 0.0009600194171071053\n",
      "Epoch 7598, Loss: 0.01441007420362439, Final Batch Loss: 0.00022819229343440384\n",
      "Epoch 7599, Loss: 0.014141113235382363, Final Batch Loss: 0.00040348435868509114\n",
      "Epoch 7600, Loss: 0.016592227155342698, Final Batch Loss: 0.004490660969167948\n",
      "Epoch 7601, Loss: 0.018982434878125787, Final Batch Loss: 0.0048652589321136475\n",
      "Epoch 7602, Loss: 0.009522645268589258, Final Batch Loss: 0.0029860693030059338\n",
      "Epoch 7603, Loss: 0.010131968942005187, Final Batch Loss: 0.0038957989308983088\n",
      "Epoch 7604, Loss: 0.03798976319376379, Final Batch Loss: 0.0006378418183885515\n",
      "Epoch 7605, Loss: 0.014003747521201149, Final Batch Loss: 0.000866327784024179\n",
      "Epoch 7606, Loss: 0.03533414016283132, Final Batch Loss: 4.068583166372264e-06\n",
      "Epoch 7607, Loss: 0.025081395579036325, Final Batch Loss: 0.012317731976509094\n",
      "Epoch 7608, Loss: 0.01654533518012613, Final Batch Loss: 0.006901174318045378\n",
      "Epoch 7609, Loss: 0.054964819632004946, Final Batch Loss: 0.032292671501636505\n",
      "Epoch 7610, Loss: 0.046487749088555574, Final Batch Loss: 0.014348171651363373\n",
      "Epoch 7611, Loss: 0.06253758305683732, Final Batch Loss: 0.004701340105384588\n",
      "Epoch 7612, Loss: 0.03279338497668505, Final Batch Loss: 0.004286153707653284\n",
      "Epoch 7613, Loss: 0.04841418005526066, Final Batch Loss: 0.010521034710109234\n",
      "Epoch 7614, Loss: 0.031667863484472036, Final Batch Loss: 0.016126414760947227\n",
      "Epoch 7615, Loss: 0.017369659733958542, Final Batch Loss: 0.004473340231925249\n",
      "Epoch 7616, Loss: 0.008258192567154765, Final Batch Loss: 0.0010185877326875925\n",
      "Epoch 7617, Loss: 0.0195423566037789, Final Batch Loss: 0.000611964613199234\n",
      "Epoch 7618, Loss: 0.11279724584892392, Final Batch Loss: 0.0863017812371254\n",
      "Epoch 7619, Loss: 0.012098585546482354, Final Batch Loss: 0.0004402646445669234\n",
      "Epoch 7620, Loss: 0.010808132821694016, Final Batch Loss: 0.0022287103347480297\n",
      "Epoch 7621, Loss: 0.023334087571129203, Final Batch Loss: 0.002276655985042453\n",
      "Epoch 7622, Loss: 0.016599530586972833, Final Batch Loss: 0.0010044209193438292\n",
      "Epoch 7623, Loss: 0.018469437840394676, Final Batch Loss: 0.005007672589272261\n",
      "Epoch 7624, Loss: 0.053474444430321455, Final Batch Loss: 0.045950423926115036\n",
      "Epoch 7625, Loss: 0.05827589286491275, Final Batch Loss: 0.005954583175480366\n",
      "Epoch 7626, Loss: 0.04219430114608258, Final Batch Loss: 0.001827893196605146\n",
      "Epoch 7627, Loss: 0.02322141986223869, Final Batch Loss: 0.00045751870493404567\n",
      "Epoch 7628, Loss: 0.02973155546351336, Final Batch Loss: 0.00017426590784452856\n",
      "Epoch 7629, Loss: 0.035567180486395955, Final Batch Loss: 0.0034641511738300323\n",
      "Epoch 7630, Loss: 0.021451795124448836, Final Batch Loss: 0.0001695352839305997\n",
      "Epoch 7631, Loss: 0.03144291718490422, Final Batch Loss: 0.0021395108196884394\n",
      "Epoch 7632, Loss: 0.027929827570915222, Final Batch Loss: 0.01773861236870289\n",
      "Epoch 7633, Loss: 0.024267679313197732, Final Batch Loss: 0.006277572829276323\n",
      "Epoch 7634, Loss: 0.040478219860233366, Final Batch Loss: 0.000692167435772717\n",
      "Epoch 7635, Loss: 0.015932134396280162, Final Batch Loss: 0.0001046609686454758\n",
      "Epoch 7636, Loss: 0.022182193119078875, Final Batch Loss: 0.00246572052128613\n",
      "Epoch 7637, Loss: 0.009491804987192154, Final Batch Loss: 0.001770201837643981\n",
      "Epoch 7638, Loss: 0.012797066941857338, Final Batch Loss: 0.0005614005494862795\n",
      "Epoch 7639, Loss: 0.014539463649271056, Final Batch Loss: 0.000280726351775229\n",
      "Epoch 7640, Loss: 0.009989176876842976, Final Batch Loss: 0.0007299083517864347\n",
      "Epoch 7641, Loss: 0.08152349462034181, Final Batch Loss: 0.06874922662973404\n",
      "Epoch 7642, Loss: 0.1465263068675995, Final Batch Loss: 0.08546436578035355\n",
      "Epoch 7643, Loss: 0.02509797364473343, Final Batch Loss: 0.0018666769610717893\n",
      "Epoch 7644, Loss: 0.04378380673006177, Final Batch Loss: 0.006480323150753975\n",
      "Epoch 7645, Loss: 0.025645730725955218, Final Batch Loss: 0.0009070517844520509\n",
      "Epoch 7646, Loss: 0.011511543649248779, Final Batch Loss: 0.0009622139041312039\n",
      "Epoch 7647, Loss: 0.01391703012632206, Final Batch Loss: 0.0017506734002381563\n",
      "Epoch 7648, Loss: 0.0073556299321353436, Final Batch Loss: 0.001410073833540082\n",
      "Epoch 7649, Loss: 0.06425744801526889, Final Batch Loss: 0.003209528746083379\n",
      "Epoch 7650, Loss: 0.010441923353937455, Final Batch Loss: 0.00019236731168348342\n",
      "Epoch 7651, Loss: 0.0072452042368240654, Final Batch Loss: 0.002999349031597376\n",
      "Epoch 7652, Loss: 0.02901483583264053, Final Batch Loss: 0.0008771952707320452\n",
      "Epoch 7653, Loss: 0.0039688317774562165, Final Batch Loss: 0.0002043379208771512\n",
      "Epoch 7654, Loss: 0.026483658875804394, Final Batch Loss: 0.0003211113507859409\n",
      "Epoch 7655, Loss: 0.03772843803744763, Final Batch Loss: 0.0002690879045985639\n",
      "Epoch 7656, Loss: 0.023059991479385644, Final Batch Loss: 0.0005231290706433356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7657, Loss: 0.011831080541014671, Final Batch Loss: 0.000656303483992815\n",
      "Epoch 7658, Loss: 0.056207263143733144, Final Batch Loss: 0.0008775230962783098\n",
      "Epoch 7659, Loss: 0.03201451076893136, Final Batch Loss: 0.024240482598543167\n",
      "Epoch 7660, Loss: 0.00641274347435683, Final Batch Loss: 0.00015562970656901598\n",
      "Epoch 7661, Loss: 0.02073013794142753, Final Batch Loss: 0.001875894027762115\n",
      "Epoch 7662, Loss: 0.049408528255298734, Final Batch Loss: 0.001189470523968339\n",
      "Epoch 7663, Loss: 0.010868848461541347, Final Batch Loss: 9.236081677954644e-05\n",
      "Epoch 7664, Loss: 0.017772119434084743, Final Batch Loss: 0.001496402663178742\n",
      "Epoch 7665, Loss: 0.01852164522279054, Final Batch Loss: 0.0053536719642579556\n",
      "Epoch 7666, Loss: 0.022779400751460344, Final Batch Loss: 0.0021801507100462914\n",
      "Epoch 7667, Loss: 0.011337918345816433, Final Batch Loss: 0.0009140789043158293\n",
      "Epoch 7668, Loss: 0.0068651457550004125, Final Batch Loss: 0.0010004279902204871\n",
      "Epoch 7669, Loss: 0.01605576254951302, Final Batch Loss: 9.718119690660387e-05\n",
      "Epoch 7670, Loss: 0.03175479336641729, Final Batch Loss: 0.0016458735335618258\n",
      "Epoch 7671, Loss: 0.013386772247031331, Final Batch Loss: 0.0006983094499446452\n",
      "Epoch 7672, Loss: 0.017343483545118943, Final Batch Loss: 0.0015532893594354391\n",
      "Epoch 7673, Loss: 0.018431565607897937, Final Batch Loss: 0.016590666025877\n",
      "Epoch 7674, Loss: 0.014879502792609856, Final Batch Loss: 0.0002066581801045686\n",
      "Epoch 7675, Loss: 0.009007973712868989, Final Batch Loss: 0.003712897188961506\n",
      "Epoch 7676, Loss: 0.005826343724038452, Final Batch Loss: 0.0004886319511570036\n",
      "Epoch 7677, Loss: 0.005121118141687475, Final Batch Loss: 0.00019464663637336344\n",
      "Epoch 7678, Loss: 0.008902856789063662, Final Batch Loss: 0.0014144278829917312\n",
      "Epoch 7679, Loss: 0.10677600928465836, Final Batch Loss: 0.10254687815904617\n",
      "Epoch 7680, Loss: 0.011188176460564137, Final Batch Loss: 0.0024714942555874586\n",
      "Epoch 7681, Loss: 0.048744662781246006, Final Batch Loss: 0.028758931905031204\n",
      "Epoch 7682, Loss: 0.04681464330178642, Final Batch Loss: 5.772792519564973e-06\n",
      "Epoch 7683, Loss: 0.031585328630171716, Final Batch Loss: 0.0012276888592168689\n",
      "Epoch 7684, Loss: 0.021621710155159235, Final Batch Loss: 0.0019038106547668576\n",
      "Epoch 7685, Loss: 0.08106571168173105, Final Batch Loss: 0.0011735270963981748\n",
      "Epoch 7686, Loss: 0.08405303419567645, Final Batch Loss: 0.018250413239002228\n",
      "Epoch 7687, Loss: 0.050703573040664196, Final Batch Loss: 0.003175155259668827\n",
      "Epoch 7688, Loss: 0.010872029233723879, Final Batch Loss: 0.0027698399499058723\n",
      "Epoch 7689, Loss: 0.02572148630861193, Final Batch Loss: 0.001776152872480452\n",
      "Epoch 7690, Loss: 0.053762505878694355, Final Batch Loss: 0.0034788441844284534\n",
      "Epoch 7691, Loss: 0.051509459677618, Final Batch Loss: 0.0005104481242597103\n",
      "Epoch 7692, Loss: 0.07356230041477829, Final Batch Loss: 0.04766838997602463\n",
      "Epoch 7693, Loss: 0.021848027128726244, Final Batch Loss: 0.0014727688394486904\n",
      "Epoch 7694, Loss: 0.07171213789843023, Final Batch Loss: 0.0033617110457271338\n",
      "Epoch 7695, Loss: 0.10821712901815772, Final Batch Loss: 0.07271282374858856\n",
      "Epoch 7696, Loss: 0.03334150303271599, Final Batch Loss: 0.00040566109237261117\n",
      "Epoch 7697, Loss: 0.048851336585357785, Final Batch Loss: 0.005067652091383934\n",
      "Epoch 7698, Loss: 0.05676791351288557, Final Batch Loss: 0.04133329540491104\n",
      "Epoch 7699, Loss: 0.10284056910313666, Final Batch Loss: 0.04464854300022125\n",
      "Epoch 7700, Loss: 0.08817567024379969, Final Batch Loss: 0.05525723099708557\n",
      "Epoch 7701, Loss: 0.06700588390231133, Final Batch Loss: 0.003927791491150856\n",
      "Epoch 7702, Loss: 0.01776016759686172, Final Batch Loss: 0.009661214426159859\n",
      "Epoch 7703, Loss: 0.09984509157948196, Final Batch Loss: 0.06807863712310791\n",
      "Epoch 7704, Loss: 0.053861909356783144, Final Batch Loss: 0.00016799270815681666\n",
      "Epoch 7705, Loss: 0.028386525227688253, Final Batch Loss: 0.014002317562699318\n",
      "Epoch 7706, Loss: 0.03474087780341506, Final Batch Loss: 0.015499655157327652\n",
      "Epoch 7707, Loss: 0.09220800618641078, Final Batch Loss: 0.04824942350387573\n",
      "Epoch 7708, Loss: 0.004365838540252298, Final Batch Loss: 0.0007763303583487868\n",
      "Epoch 7709, Loss: 0.03194019920192659, Final Batch Loss: 0.0072494326159358025\n",
      "Epoch 7710, Loss: 0.06624960387125611, Final Batch Loss: 0.037504516541957855\n",
      "Epoch 7711, Loss: 0.022428485564887524, Final Batch Loss: 0.001951818005181849\n",
      "Epoch 7712, Loss: 0.013227848568931222, Final Batch Loss: 0.0005936636589467525\n",
      "Epoch 7713, Loss: 0.024233926902525127, Final Batch Loss: 0.0060433209873735905\n",
      "Epoch 7714, Loss: 0.08879053185228258, Final Batch Loss: 0.0005917764501646161\n",
      "Epoch 7715, Loss: 0.008568528748583049, Final Batch Loss: 0.0005486988229677081\n",
      "Epoch 7716, Loss: 0.029874643310904503, Final Batch Loss: 0.0013725310564041138\n",
      "Epoch 7717, Loss: 0.015577724203467369, Final Batch Loss: 0.009678667411208153\n",
      "Epoch 7718, Loss: 0.01396448677405715, Final Batch Loss: 0.002458532340824604\n",
      "Epoch 7719, Loss: 0.029112596530467272, Final Batch Loss: 0.0031923572532832623\n",
      "Epoch 7720, Loss: 0.02149717352585867, Final Batch Loss: 0.0007994728512130678\n",
      "Epoch 7721, Loss: 0.03996546656708233, Final Batch Loss: 0.00032260906300507486\n",
      "Epoch 7722, Loss: 0.007293461705558002, Final Batch Loss: 0.0019982142839580774\n",
      "Epoch 7723, Loss: 0.027133974857861176, Final Batch Loss: 0.0002671041584108025\n",
      "Epoch 7724, Loss: 0.027531816202099435, Final Batch Loss: 0.021929392591118813\n",
      "Epoch 7725, Loss: 0.12309138104319572, Final Batch Loss: 0.07563111186027527\n",
      "Epoch 7726, Loss: 0.07374449755297974, Final Batch Loss: 0.001571673434227705\n",
      "Epoch 7727, Loss: 0.020414715516380966, Final Batch Loss: 0.003940301015973091\n",
      "Epoch 7728, Loss: 0.025034450576640666, Final Batch Loss: 0.0022466457448899746\n",
      "Epoch 7729, Loss: 0.06390102312434465, Final Batch Loss: 0.001359865185804665\n",
      "Epoch 7730, Loss: 0.03961903741583228, Final Batch Loss: 0.00203453260473907\n",
      "Epoch 7731, Loss: 0.038698015036061406, Final Batch Loss: 0.001232313341461122\n",
      "Epoch 7732, Loss: 0.03535854513756931, Final Batch Loss: 0.015210052020847797\n",
      "Epoch 7733, Loss: 0.01727182255126536, Final Batch Loss: 0.0018917149864137173\n",
      "Epoch 7734, Loss: 0.030425697099417448, Final Batch Loss: 0.002350867260247469\n",
      "Epoch 7735, Loss: 0.02318897470831871, Final Batch Loss: 0.0007851894479244947\n",
      "Epoch 7736, Loss: 0.05300650361459702, Final Batch Loss: 0.02313515730202198\n",
      "Epoch 7737, Loss: 0.008317619300214574, Final Batch Loss: 0.002700581680983305\n",
      "Epoch 7738, Loss: 0.0069182263687253, Final Batch Loss: 0.002098647179082036\n",
      "Epoch 7739, Loss: 0.0092979526380077, Final Batch Loss: 0.0012915096012875438\n",
      "Epoch 7740, Loss: 0.019850365410093218, Final Batch Loss: 0.003373510669916868\n",
      "Epoch 7741, Loss: 0.0028365702892187983, Final Batch Loss: 0.0005981979193165898\n",
      "Epoch 7742, Loss: 0.009184435126371682, Final Batch Loss: 0.0016380954766646028\n",
      "Epoch 7743, Loss: 0.007032729568891227, Final Batch Loss: 0.0026355120353400707\n",
      "Epoch 7744, Loss: 0.024596248753368855, Final Batch Loss: 0.0039269085973501205\n",
      "Epoch 7745, Loss: 0.038841161760501564, Final Batch Loss: 0.010299411602318287\n",
      "Epoch 7746, Loss: 0.028522073931526393, Final Batch Loss: 0.0006073274998925626\n",
      "Epoch 7747, Loss: 0.008211688342271373, Final Batch Loss: 0.000500624708365649\n",
      "Epoch 7748, Loss: 0.07889320582034998, Final Batch Loss: 0.0537579208612442\n",
      "Epoch 7749, Loss: 0.007121788046788424, Final Batch Loss: 0.00039702572394162416\n",
      "Epoch 7750, Loss: 0.0048427890869788826, Final Batch Loss: 0.0009626966202631593\n",
      "Epoch 7751, Loss: 0.028493052755948156, Final Batch Loss: 0.006799329072237015\n",
      "Epoch 7752, Loss: 0.00921091326745227, Final Batch Loss: 0.0006184214726090431\n",
      "Epoch 7753, Loss: 0.01747566959238611, Final Batch Loss: 0.000183179130544886\n",
      "Epoch 7754, Loss: 0.008234668843215331, Final Batch Loss: 0.00111759128049016\n",
      "Epoch 7755, Loss: 0.006738151831086725, Final Batch Loss: 0.0017300932668149471\n",
      "Epoch 7756, Loss: 0.003597836126573384, Final Batch Loss: 0.0012694685719907284\n",
      "Epoch 7757, Loss: 0.019437429764366243, Final Batch Loss: 0.00040152284782379866\n",
      "Epoch 7758, Loss: 0.003497796133160591, Final Batch Loss: 0.0007251276983879507\n",
      "Epoch 7759, Loss: 0.014933237805962563, Final Batch Loss: 0.0011871954193338752\n",
      "Epoch 7760, Loss: 0.02488295039802324, Final Batch Loss: 0.0002196853019995615\n",
      "Epoch 7761, Loss: 0.0046225281548686326, Final Batch Loss: 0.001609114115126431\n",
      "Epoch 7762, Loss: 0.01114576862892136, Final Batch Loss: 0.0006123650236986578\n",
      "Epoch 7763, Loss: 0.003385058807907626, Final Batch Loss: 0.0002045226574409753\n",
      "Epoch 7764, Loss: 0.05474965553730726, Final Batch Loss: 0.003872254630550742\n",
      "Epoch 7765, Loss: 0.017658238066360354, Final Batch Loss: 0.00355075323022902\n",
      "Epoch 7766, Loss: 0.038894642726518214, Final Batch Loss: 0.0002789848076645285\n",
      "Epoch 7767, Loss: 0.016701845364877954, Final Batch Loss: 0.00034685959690250456\n",
      "Epoch 7768, Loss: 0.037146326154470444, Final Batch Loss: 0.022779356688261032\n",
      "Epoch 7769, Loss: 0.045665377052500844, Final Batch Loss: 0.002912470605224371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7770, Loss: 0.005618724331725389, Final Batch Loss: 0.00023105397121980786\n",
      "Epoch 7771, Loss: 0.06408675588318147, Final Batch Loss: 0.00033009532489813864\n",
      "Epoch 7772, Loss: 0.0505021542776376, Final Batch Loss: 0.03993329033255577\n",
      "Epoch 7773, Loss: 0.006871481484267861, Final Batch Loss: 0.00012946873903274536\n",
      "Epoch 7774, Loss: 0.07415398396551609, Final Batch Loss: 0.00028890790417790413\n",
      "Epoch 7775, Loss: 0.10749932937324047, Final Batch Loss: 0.08986307680606842\n",
      "Epoch 7776, Loss: 0.03681460628286004, Final Batch Loss: 0.002735741436481476\n",
      "Epoch 7777, Loss: 0.01854374655522406, Final Batch Loss: 0.0024777697399258614\n",
      "Epoch 7778, Loss: 0.016591883992077783, Final Batch Loss: 0.0002210175443906337\n",
      "Epoch 7779, Loss: 0.008522655232809484, Final Batch Loss: 0.0007147220894694328\n",
      "Epoch 7780, Loss: 0.017032075091265142, Final Batch Loss: 0.0010423214407637715\n",
      "Epoch 7781, Loss: 0.023114017443731427, Final Batch Loss: 0.013714081607758999\n",
      "Epoch 7782, Loss: 0.029223241843283176, Final Batch Loss: 0.0031206870917230844\n",
      "Epoch 7783, Loss: 0.03306281042750925, Final Batch Loss: 0.0010462076170369983\n",
      "Epoch 7784, Loss: 0.030927957617677748, Final Batch Loss: 0.002906871261075139\n",
      "Epoch 7785, Loss: 0.01850266003748402, Final Batch Loss: 0.005275214556604624\n",
      "Epoch 7786, Loss: 0.005449830103316344, Final Batch Loss: 0.00018740784435067326\n",
      "Epoch 7787, Loss: 0.022489730559755117, Final Batch Loss: 0.0010011770064011216\n",
      "Epoch 7788, Loss: 0.019340736558660865, Final Batch Loss: 0.008083123713731766\n",
      "Epoch 7789, Loss: 0.010724250169005245, Final Batch Loss: 0.0004088150744792074\n",
      "Epoch 7790, Loss: 0.03561771637760103, Final Batch Loss: 0.0009559157770127058\n",
      "Epoch 7791, Loss: 0.008851805003359914, Final Batch Loss: 0.0019065572414547205\n",
      "Epoch 7792, Loss: 0.02021708677057177, Final Batch Loss: 0.006061918567866087\n",
      "Epoch 7793, Loss: 0.012420554645359516, Final Batch Loss: 0.0026569038163870573\n",
      "Epoch 7794, Loss: 0.00659989845007658, Final Batch Loss: 0.0012076637940481305\n",
      "Epoch 7795, Loss: 0.008218496979679912, Final Batch Loss: 0.0003994479775428772\n",
      "Epoch 7796, Loss: 0.015815374033991247, Final Batch Loss: 0.0009925405029207468\n",
      "Epoch 7797, Loss: 0.028678252827376127, Final Batch Loss: 0.017048582434654236\n",
      "Epoch 7798, Loss: 0.040677872792002745, Final Batch Loss: 0.00012907323252875358\n",
      "Epoch 7799, Loss: 0.03232889098580927, Final Batch Loss: 0.001050362247042358\n",
      "Epoch 7800, Loss: 0.02750266995280981, Final Batch Loss: 0.0028341799043118954\n",
      "Epoch 7801, Loss: 0.049444066593423486, Final Batch Loss: 0.005958592519164085\n",
      "Epoch 7802, Loss: 0.022934268694370985, Final Batch Loss: 0.0009424659656360745\n",
      "Epoch 7803, Loss: 0.0027755933406297117, Final Batch Loss: 0.00022307017934508622\n",
      "Epoch 7804, Loss: 0.011200676082808059, Final Batch Loss: 7.085612014634535e-05\n",
      "Epoch 7805, Loss: 0.003162290246109478, Final Batch Loss: 0.0001887031685328111\n",
      "Epoch 7806, Loss: 0.01283638400491327, Final Batch Loss: 0.001387359225191176\n",
      "Epoch 7807, Loss: 0.0131840193644166, Final Batch Loss: 0.0053153084591031075\n",
      "Epoch 7808, Loss: 0.07699979213066399, Final Batch Loss: 0.0051198373548686504\n",
      "Epoch 7809, Loss: 0.007399121474009007, Final Batch Loss: 0.0006098673329688609\n",
      "Epoch 7810, Loss: 0.012515435344539583, Final Batch Loss: 0.001699673943221569\n",
      "Epoch 7811, Loss: 0.006598785636015236, Final Batch Loss: 0.00156761787366122\n",
      "Epoch 7812, Loss: 0.006184545578435063, Final Batch Loss: 0.0005239146994426847\n",
      "Epoch 7813, Loss: 0.03597695869393647, Final Batch Loss: 0.018649887293577194\n",
      "Epoch 7814, Loss: 0.011182756279595196, Final Batch Loss: 0.0009270641021430492\n",
      "Epoch 7815, Loss: 0.010015231790021062, Final Batch Loss: 0.003931105136871338\n",
      "Epoch 7816, Loss: 0.011066904626204632, Final Batch Loss: 0.0004825289943255484\n",
      "Epoch 7817, Loss: 0.02238277083961293, Final Batch Loss: 0.0006418614066205919\n",
      "Epoch 7818, Loss: 0.01205597014632076, Final Batch Loss: 0.00018125682254321873\n",
      "Epoch 7819, Loss: 0.014732506242580712, Final Batch Loss: 0.005922507494688034\n",
      "Epoch 7820, Loss: 0.012181029131170362, Final Batch Loss: 0.0002586223999969661\n",
      "Epoch 7821, Loss: 0.0173055230116006, Final Batch Loss: 0.0007462648791261017\n",
      "Epoch 7822, Loss: 0.0037913232226856053, Final Batch Loss: 0.0011202136520296335\n",
      "Epoch 7823, Loss: 0.008392371120862663, Final Batch Loss: 0.006156159099191427\n",
      "Epoch 7824, Loss: 0.027416531112976372, Final Batch Loss: 0.0015950851375237107\n",
      "Epoch 7825, Loss: 0.027805681340396404, Final Batch Loss: 0.004049430601298809\n",
      "Epoch 7826, Loss: 0.004438895732164383, Final Batch Loss: 0.0007955514593049884\n",
      "Epoch 7827, Loss: 0.0396009261457948, Final Batch Loss: 0.00015608912508469075\n",
      "Epoch 7828, Loss: 0.01025059149833396, Final Batch Loss: 0.0003007589257322252\n",
      "Epoch 7829, Loss: 0.04967699234839529, Final Batch Loss: 0.0198043379932642\n",
      "Epoch 7830, Loss: 0.006767486745957285, Final Batch Loss: 0.002105581806972623\n",
      "Epoch 7831, Loss: 0.004393367096781731, Final Batch Loss: 0.0008622470195405185\n",
      "Epoch 7832, Loss: 0.016705555142834783, Final Batch Loss: 0.000377279007807374\n",
      "Epoch 7833, Loss: 0.01349531693267636, Final Batch Loss: 0.000485935335746035\n",
      "Epoch 7834, Loss: 0.011448075878433883, Final Batch Loss: 0.0015548649244010448\n",
      "Epoch 7835, Loss: 0.005382503615692258, Final Batch Loss: 0.0012637667823582888\n",
      "Epoch 7836, Loss: 0.0051588710193755105, Final Batch Loss: 0.000716931652277708\n",
      "Epoch 7837, Loss: 0.005253606359474361, Final Batch Loss: 0.00022576702758669853\n",
      "Epoch 7838, Loss: 0.00479571902542375, Final Batch Loss: 0.0017151284264400601\n",
      "Epoch 7839, Loss: 0.07386594571289606, Final Batch Loss: 0.013469228520989418\n",
      "Epoch 7840, Loss: 0.07267755037173629, Final Batch Loss: 0.0008860108209773898\n",
      "Epoch 7841, Loss: 0.04826655599754304, Final Batch Loss: 0.0018391479970887303\n",
      "Epoch 7842, Loss: 0.004699037002865225, Final Batch Loss: 0.0005809235153719783\n",
      "Epoch 7843, Loss: 0.018745777779258788, Final Batch Loss: 0.004572624806314707\n",
      "Epoch 7844, Loss: 0.02654842269839719, Final Batch Loss: 0.0007588797598145902\n",
      "Epoch 7845, Loss: 0.012700797291472554, Final Batch Loss: 0.003946894314140081\n",
      "Epoch 7846, Loss: 0.02591107157059014, Final Batch Loss: 0.002057918580248952\n",
      "Epoch 7847, Loss: 0.02163394948001951, Final Batch Loss: 0.0070623960345983505\n",
      "Epoch 7848, Loss: 0.00643676973413676, Final Batch Loss: 0.0013060912024229765\n",
      "Epoch 7849, Loss: 0.0240546518471092, Final Batch Loss: 0.015893561765551567\n",
      "Epoch 7850, Loss: 0.06151380902156234, Final Batch Loss: 0.00014689762610942125\n",
      "Epoch 7851, Loss: 0.04134955117478967, Final Batch Loss: 0.00812582392245531\n",
      "Epoch 7852, Loss: 0.05305267754010856, Final Batch Loss: 0.014692881144583225\n",
      "Epoch 7853, Loss: 0.025783614022657275, Final Batch Loss: 0.0003330542240291834\n",
      "Epoch 7854, Loss: 0.026560254802461714, Final Batch Loss: 0.010536746121942997\n",
      "Epoch 7855, Loss: 0.13259076938265935, Final Batch Loss: 0.00028198264772072434\n",
      "Epoch 7856, Loss: 0.08423601253889501, Final Batch Loss: 0.07540401816368103\n",
      "Epoch 7857, Loss: 0.02452324633486569, Final Batch Loss: 0.0053908806294202805\n",
      "Epoch 7858, Loss: 0.009362085140310228, Final Batch Loss: 0.0010027815587818623\n",
      "Epoch 7859, Loss: 0.03638745634816587, Final Batch Loss: 0.020110301673412323\n",
      "Epoch 7860, Loss: 0.07502170966472477, Final Batch Loss: 0.0010507538681849837\n",
      "Epoch 7861, Loss: 0.05818368500331417, Final Batch Loss: 0.0007663006545044482\n",
      "Epoch 7862, Loss: 0.04453681455925107, Final Batch Loss: 0.004126738756895065\n",
      "Epoch 7863, Loss: 0.08841970865614712, Final Batch Loss: 0.02917090617120266\n",
      "Epoch 7864, Loss: 0.013885041873436421, Final Batch Loss: 0.0005357912159524858\n",
      "Epoch 7865, Loss: 0.10086700122337788, Final Batch Loss: 0.09336438030004501\n",
      "Epoch 7866, Loss: 0.028108950005844235, Final Batch Loss: 0.0010244729928672314\n",
      "Epoch 7867, Loss: 0.13716335408389568, Final Batch Loss: 0.1119009479880333\n",
      "Epoch 7868, Loss: 0.02252913871780038, Final Batch Loss: 0.0011249276576563716\n",
      "Epoch 7869, Loss: 0.05367939861025661, Final Batch Loss: 0.0032098551746457815\n",
      "Epoch 7870, Loss: 0.06494118925184011, Final Batch Loss: 0.014106976799666882\n",
      "Epoch 7871, Loss: 0.059260012581944466, Final Batch Loss: 0.01159602589905262\n",
      "Epoch 7872, Loss: 0.021524923504330218, Final Batch Loss: 0.0014525501755997539\n",
      "Epoch 7873, Loss: 0.018906879166024737, Final Batch Loss: 0.0067497375421226025\n",
      "Epoch 7874, Loss: 0.029959163744933903, Final Batch Loss: 0.022731896489858627\n",
      "Epoch 7875, Loss: 0.027303399285301566, Final Batch Loss: 0.004385227337479591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7876, Loss: 0.03318820730783045, Final Batch Loss: 0.009762080386281013\n",
      "Epoch 7877, Loss: 0.029140882776118815, Final Batch Loss: 0.001563968718983233\n",
      "Epoch 7878, Loss: 0.030100182630121708, Final Batch Loss: 0.010825321078300476\n",
      "Epoch 7879, Loss: 0.008466886356472969, Final Batch Loss: 0.0007011129637248814\n",
      "Epoch 7880, Loss: 0.03174224798567593, Final Batch Loss: 0.018226109445095062\n",
      "Epoch 7881, Loss: 0.013568691443651915, Final Batch Loss: 0.001206202432513237\n",
      "Epoch 7882, Loss: 0.05244573927484453, Final Batch Loss: 0.0037812034133821726\n",
      "Epoch 7883, Loss: 0.020406237454153597, Final Batch Loss: 0.001683115609921515\n",
      "Epoch 7884, Loss: 0.05915552377700806, Final Batch Loss: 0.0040409197099506855\n",
      "Epoch 7885, Loss: 0.04167699406389147, Final Batch Loss: 0.03519660234451294\n",
      "Epoch 7886, Loss: 0.044255848857574165, Final Batch Loss: 0.016297686845064163\n",
      "Epoch 7887, Loss: 0.05843266798183322, Final Batch Loss: 0.05059458315372467\n",
      "Epoch 7888, Loss: 0.030479499837383628, Final Batch Loss: 0.0031303795985877514\n",
      "Epoch 7889, Loss: 0.0107510753441602, Final Batch Loss: 0.004645165055990219\n",
      "Epoch 7890, Loss: 0.028098644223064184, Final Batch Loss: 0.0007323433528654277\n",
      "Epoch 7891, Loss: 0.024418997185421176, Final Batch Loss: 0.0002351943840039894\n",
      "Epoch 7892, Loss: 0.020734743447974324, Final Batch Loss: 0.0010685021989047527\n",
      "Epoch 7893, Loss: 0.007871225097915158, Final Batch Loss: 0.00014787967666052282\n",
      "Epoch 7894, Loss: 0.01677716145059094, Final Batch Loss: 0.001731024938635528\n",
      "Epoch 7895, Loss: 0.04194037604611367, Final Batch Loss: 0.03169315308332443\n",
      "Epoch 7896, Loss: 0.08222458270029165, Final Batch Loss: 0.00013052430585958064\n",
      "Epoch 7897, Loss: 0.06151237420272082, Final Batch Loss: 0.053278304636478424\n",
      "Epoch 7898, Loss: 0.05302272143308073, Final Batch Loss: 0.0009819607948884368\n",
      "Epoch 7899, Loss: 0.06701935827732086, Final Batch Loss: 0.008463100530207157\n",
      "Epoch 7900, Loss: 0.050660490756854415, Final Batch Loss: 0.003466840600594878\n",
      "Epoch 7901, Loss: 0.046626034658402205, Final Batch Loss: 0.013129234313964844\n",
      "Epoch 7902, Loss: 0.05129639012739062, Final Batch Loss: 0.016015149652957916\n",
      "Epoch 7903, Loss: 0.028721237555146217, Final Batch Loss: 0.0053481608629226685\n",
      "Epoch 7904, Loss: 0.016425819951109588, Final Batch Loss: 0.01003571879118681\n",
      "Epoch 7905, Loss: 0.021505164506379515, Final Batch Loss: 0.014068754389882088\n",
      "Epoch 7906, Loss: 0.02346619637683034, Final Batch Loss: 0.0008072820492088795\n",
      "Epoch 7907, Loss: 0.009728468023240566, Final Batch Loss: 0.00453850906342268\n",
      "Epoch 7908, Loss: 0.03554920095484704, Final Batch Loss: 0.0022182322572916746\n",
      "Epoch 7909, Loss: 0.017478893685620278, Final Batch Loss: 0.0005794991157017648\n",
      "Epoch 7910, Loss: 0.014806602586759254, Final Batch Loss: 0.0003801192797254771\n",
      "Epoch 7911, Loss: 0.028537679463624954, Final Batch Loss: 0.0007292579975910485\n",
      "Epoch 7912, Loss: 0.01624545908998698, Final Batch Loss: 0.0013811317039653659\n",
      "Epoch 7913, Loss: 0.03079914243426174, Final Batch Loss: 0.0006141645135357976\n",
      "Epoch 7914, Loss: 0.02961125737056136, Final Batch Loss: 0.008849510923027992\n",
      "Epoch 7915, Loss: 0.08494176634121686, Final Batch Loss: 0.0014356047613546252\n",
      "Epoch 7916, Loss: 0.017377787589794025, Final Batch Loss: 0.0002504315634723753\n",
      "Epoch 7917, Loss: 0.008081705367658287, Final Batch Loss: 0.00021733279572799802\n",
      "Epoch 7918, Loss: 0.05902952450560406, Final Batch Loss: 0.0008426807471551001\n",
      "Epoch 7919, Loss: 0.028264195076189935, Final Batch Loss: 0.02393418364226818\n",
      "Epoch 7920, Loss: 0.037264045677147806, Final Batch Loss: 0.004919350612908602\n",
      "Epoch 7921, Loss: 0.019911729061277583, Final Batch Loss: 0.00046507202205248177\n",
      "Epoch 7922, Loss: 0.02379570750053972, Final Batch Loss: 0.002544882008805871\n",
      "Epoch 7923, Loss: 0.023771638341713697, Final Batch Loss: 0.011010436341166496\n",
      "Epoch 7924, Loss: 0.03161507425829768, Final Batch Loss: 0.0032384139485657215\n",
      "Epoch 7925, Loss: 0.04365638125455007, Final Batch Loss: 0.0017173746600747108\n",
      "Epoch 7926, Loss: 0.015653982642106712, Final Batch Loss: 0.001240474870428443\n",
      "Epoch 7927, Loss: 0.07952879229560494, Final Batch Loss: 0.0056002079509198666\n",
      "Epoch 7928, Loss: 0.06631404109066352, Final Batch Loss: 0.0006407573237083852\n",
      "Epoch 7929, Loss: 0.16015917796175927, Final Batch Loss: 0.1459871381521225\n",
      "Epoch 7930, Loss: 0.06264389434363693, Final Batch Loss: 0.0353856235742569\n",
      "Epoch 7931, Loss: 0.029764468199573457, Final Batch Loss: 0.01187759730964899\n",
      "Epoch 7932, Loss: 0.03188295994186774, Final Batch Loss: 0.0008337103645317256\n",
      "Epoch 7933, Loss: 0.031213939539156854, Final Batch Loss: 0.009391993284225464\n",
      "Epoch 7934, Loss: 0.015127258957363665, Final Batch Loss: 0.0006215703906491399\n",
      "Epoch 7935, Loss: 0.01689103478565812, Final Batch Loss: 0.0030824574641883373\n",
      "Epoch 7936, Loss: 0.014095821650698781, Final Batch Loss: 0.0027212388813495636\n",
      "Epoch 7937, Loss: 0.07162513141520321, Final Batch Loss: 0.061220865696668625\n",
      "Epoch 7938, Loss: 0.025714830146171153, Final Batch Loss: 0.003826269181445241\n",
      "Epoch 7939, Loss: 0.12432967268978246, Final Batch Loss: 0.0003242949314881116\n",
      "Epoch 7940, Loss: 0.02934906823793426, Final Batch Loss: 0.00822892040014267\n",
      "Epoch 7941, Loss: 0.06200199143495411, Final Batch Loss: 0.0486624538898468\n",
      "Epoch 7942, Loss: 0.04545339848846197, Final Batch Loss: 0.009746205992996693\n",
      "Epoch 7943, Loss: 0.11608349671587348, Final Batch Loss: 0.07525712996721268\n",
      "Epoch 7944, Loss: 0.10068123904056847, Final Batch Loss: 0.0019852800760418177\n",
      "Epoch 7945, Loss: 0.024375854176469147, Final Batch Loss: 0.01891302317380905\n",
      "Epoch 7946, Loss: 0.035770606133155525, Final Batch Loss: 0.0014478181255981326\n",
      "Epoch 7947, Loss: 0.030312181916087866, Final Batch Loss: 0.0038688217755407095\n",
      "Epoch 7948, Loss: 0.015703031443990767, Final Batch Loss: 0.0015853533986955881\n",
      "Epoch 7949, Loss: 0.016834899317473173, Final Batch Loss: 0.0019800213631242514\n",
      "Epoch 7950, Loss: 0.04105237335897982, Final Batch Loss: 0.001604537246748805\n",
      "Epoch 7951, Loss: 0.03283816238399595, Final Batch Loss: 0.01137168612331152\n",
      "Epoch 7952, Loss: 0.019550092751160264, Final Batch Loss: 0.00043988367542624474\n",
      "Epoch 7953, Loss: 0.018179187492933124, Final Batch Loss: 0.005920252297073603\n",
      "Epoch 7954, Loss: 0.016045335025410168, Final Batch Loss: 0.00018042138253804296\n",
      "Epoch 7955, Loss: 0.02662320516537875, Final Batch Loss: 0.0008673476986587048\n",
      "Epoch 7956, Loss: 0.011387439939426258, Final Batch Loss: 0.00047333099064417183\n",
      "Epoch 7957, Loss: 0.016212040558457375, Final Batch Loss: 0.006178285460919142\n",
      "Epoch 7958, Loss: 0.018465177214238793, Final Batch Loss: 0.00033330958103761077\n",
      "Epoch 7959, Loss: 0.003954867454012856, Final Batch Loss: 0.001092351507395506\n",
      "Epoch 7960, Loss: 0.00624859263189137, Final Batch Loss: 0.0010194836650043726\n",
      "Epoch 7961, Loss: 0.007566130050690845, Final Batch Loss: 0.0002560691791586578\n",
      "Epoch 7962, Loss: 0.018690735363634303, Final Batch Loss: 0.0005585268954746425\n",
      "Epoch 7963, Loss: 0.011678976254188456, Final Batch Loss: 0.00022594873735215515\n",
      "Epoch 7964, Loss: 0.005655391083564609, Final Batch Loss: 0.0002392713795416057\n",
      "Epoch 7965, Loss: 0.013038571749348193, Final Batch Loss: 0.00028309726621955633\n",
      "Epoch 7966, Loss: 0.041353265405632555, Final Batch Loss: 0.00047872751019895077\n",
      "Epoch 7967, Loss: 0.0019729737687157467, Final Batch Loss: 0.001149126561358571\n",
      "Epoch 7968, Loss: 0.009666159166954458, Final Batch Loss: 0.0005390605656430125\n",
      "Epoch 7969, Loss: 0.019254176237154752, Final Batch Loss: 0.0005285138031467795\n",
      "Epoch 7970, Loss: 0.05054353113519028, Final Batch Loss: 0.0004140126402489841\n",
      "Epoch 7971, Loss: 0.006017693842295557, Final Batch Loss: 0.00012431194772943854\n",
      "Epoch 7972, Loss: 0.005360514158383012, Final Batch Loss: 0.0010845325887203217\n",
      "Epoch 7973, Loss: 0.006936472898814827, Final Batch Loss: 0.0007695449166931212\n",
      "Epoch 7974, Loss: 0.011474218568764627, Final Batch Loss: 0.0017346494132652879\n",
      "Epoch 7975, Loss: 0.06022586766630411, Final Batch Loss: 0.05767593905329704\n",
      "Epoch 7976, Loss: 0.006101226812461391, Final Batch Loss: 0.0002596679551061243\n",
      "Epoch 7977, Loss: 0.005514678137842566, Final Batch Loss: 0.0004010409174952656\n",
      "Epoch 7978, Loss: 0.02161789417732507, Final Batch Loss: 0.002211980987340212\n",
      "Epoch 7979, Loss: 0.006677299999864772, Final Batch Loss: 0.0019791347440332174\n",
      "Epoch 7980, Loss: 0.015988493454642594, Final Batch Loss: 0.0027880242560058832\n",
      "Epoch 7981, Loss: 0.013028439600020647, Final Batch Loss: 0.006792237516492605\n",
      "Epoch 7982, Loss: 0.006785105273593217, Final Batch Loss: 0.0012643554946407676\n",
      "Epoch 7983, Loss: 0.003997197280114051, Final Batch Loss: 6.950963143026456e-05\n",
      "Epoch 7984, Loss: 0.025007871896377765, Final Batch Loss: 0.00021277945779729635\n",
      "Epoch 7985, Loss: 0.018699690932407975, Final Batch Loss: 0.0069294217973947525\n",
      "Epoch 7986, Loss: 0.05866749072447419, Final Batch Loss: 0.039609894156455994\n",
      "Epoch 7987, Loss: 0.006110912130679935, Final Batch Loss: 0.003577128518372774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7988, Loss: 0.021552900521783158, Final Batch Loss: 0.004328662995249033\n",
      "Epoch 7989, Loss: 0.007486970513127744, Final Batch Loss: 0.0007164637790992856\n",
      "Epoch 7990, Loss: 0.010852277278900146, Final Batch Loss: 0.001752790529280901\n",
      "Epoch 7991, Loss: 0.015120903786737472, Final Batch Loss: 0.0005094769294373691\n",
      "Epoch 7992, Loss: 0.0164917943184264, Final Batch Loss: 0.000890596944373101\n",
      "Epoch 7993, Loss: 0.004690633999416605, Final Batch Loss: 0.00032811317942105234\n",
      "Epoch 7994, Loss: 0.008004482660908252, Final Batch Loss: 0.000868002709466964\n",
      "Epoch 7995, Loss: 0.024273088318295777, Final Batch Loss: 0.0013901015045121312\n",
      "Epoch 7996, Loss: 0.03896011540200561, Final Batch Loss: 0.023673025891184807\n",
      "Epoch 7997, Loss: 0.010314900049706921, Final Batch Loss: 0.00038718615542165935\n",
      "Epoch 7998, Loss: 0.03778852545656264, Final Batch Loss: 0.013353817164897919\n",
      "Epoch 7999, Loss: 0.005472182179801166, Final Batch Loss: 0.0017534507205709815\n",
      "Epoch 8000, Loss: 0.005511142837349325, Final Batch Loss: 0.0008694670395925641\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  3  1]\n",
      " [ 4 41  2]\n",
      " [ 3  7 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.870     0.922     0.895        51\n",
      "           1      0.804     0.872     0.837        47\n",
      "           2      0.932     0.804     0.863        51\n",
      "\n",
      "    accuracy                          0.866       149\n",
      "   macro avg      0.869     0.866     0.865       149\n",
      "weighted avg      0.870     0.866     0.866       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../saved_models/UCI 3 User Classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
