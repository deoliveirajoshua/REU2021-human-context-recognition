{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 tBodyAcc-mean()-X</th>\n",
       "      <th>2 tBodyAcc-mean()-Y</th>\n",
       "      <th>3 tBodyAcc-mean()-Z</th>\n",
       "      <th>4 tBodyAcc-std()-X</th>\n",
       "      <th>5 tBodyAcc-std()-Y</th>\n",
       "      <th>6 tBodyAcc-std()-Z</th>\n",
       "      <th>7 tBodyAcc-mad()-X</th>\n",
       "      <th>8 tBodyAcc-mad()-Y</th>\n",
       "      <th>9 tBodyAcc-mad()-Z</th>\n",
       "      <th>10 tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>32 tBodyAcc-arCoeff()-Y,3</th>\n",
       "      <th>33 tBodyAcc-arCoeff()-Y,4</th>\n",
       "      <th>34 tBodyAcc-arCoeff()-Z,1</th>\n",
       "      <th>35 tBodyAcc-arCoeff()-Z,2</th>\n",
       "      <th>36 tBodyAcc-arCoeff()-Z,3</th>\n",
       "      <th>37 tBodyAcc-arCoeff()-Z,4</th>\n",
       "      <th>38 tBodyAcc-correlation()-X,Y</th>\n",
       "      <th>39 tBodyAcc-correlation()-X,Z</th>\n",
       "      <th>40 tBodyAcc-correlation()-Y,Z</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264106</td>\n",
       "      <td>-0.095246</td>\n",
       "      <td>0.278851</td>\n",
       "      <td>-0.465085</td>\n",
       "      <td>0.491936</td>\n",
       "      <td>-0.190884</td>\n",
       "      <td>0.376314</td>\n",
       "      <td>0.435129</td>\n",
       "      <td>0.660790</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294310</td>\n",
       "      <td>-0.281211</td>\n",
       "      <td>0.085988</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.016657</td>\n",
       "      <td>-0.220643</td>\n",
       "      <td>-0.013429</td>\n",
       "      <td>-0.072692</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342256</td>\n",
       "      <td>-0.332564</td>\n",
       "      <td>0.239281</td>\n",
       "      <td>-0.136204</td>\n",
       "      <td>0.173863</td>\n",
       "      <td>-0.299493</td>\n",
       "      <td>-0.124698</td>\n",
       "      <td>-0.181105</td>\n",
       "      <td>0.608900</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323154</td>\n",
       "      <td>-0.170813</td>\n",
       "      <td>0.294938</td>\n",
       "      <td>-0.306081</td>\n",
       "      <td>0.482148</td>\n",
       "      <td>-0.470129</td>\n",
       "      <td>-0.305693</td>\n",
       "      <td>-0.362654</td>\n",
       "      <td>0.507459</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434728</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>0.439744</td>\n",
       "      <td>-0.269069</td>\n",
       "      <td>0.179414</td>\n",
       "      <td>-0.088952</td>\n",
       "      <td>-0.155804</td>\n",
       "      <td>-0.189763</td>\n",
       "      <td>0.599213</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>0.299665</td>\n",
       "      <td>-0.057193</td>\n",
       "      <td>-0.181233</td>\n",
       "      <td>-0.195387</td>\n",
       "      <td>0.039905</td>\n",
       "      <td>0.077078</td>\n",
       "      <td>-0.282301</td>\n",
       "      <td>0.043616</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>0.210795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119821</td>\n",
       "      <td>0.293112</td>\n",
       "      <td>-0.425386</td>\n",
       "      <td>0.267986</td>\n",
       "      <td>-0.205315</td>\n",
       "      <td>0.142117</td>\n",
       "      <td>-0.211822</td>\n",
       "      <td>-0.251582</td>\n",
       "      <td>-0.283335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>0.273853</td>\n",
       "      <td>-0.007749</td>\n",
       "      <td>-0.147468</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-0.322552</td>\n",
       "      <td>-0.029456</td>\n",
       "      <td>0.080585</td>\n",
       "      <td>0.117440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034260</td>\n",
       "      <td>0.239835</td>\n",
       "      <td>-0.364480</td>\n",
       "      <td>0.121335</td>\n",
       "      <td>0.188717</td>\n",
       "      <td>-0.207505</td>\n",
       "      <td>-0.198555</td>\n",
       "      <td>-0.225866</td>\n",
       "      <td>-0.274504</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>0.273387</td>\n",
       "      <td>-0.017011</td>\n",
       "      <td>-0.045022</td>\n",
       "      <td>-0.218218</td>\n",
       "      <td>-0.103822</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>-0.304515</td>\n",
       "      <td>-0.098913</td>\n",
       "      <td>0.332584</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119962</td>\n",
       "      <td>0.080689</td>\n",
       "      <td>-0.420093</td>\n",
       "      <td>0.197763</td>\n",
       "      <td>-0.033780</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>-0.226826</td>\n",
       "      <td>-0.184700</td>\n",
       "      <td>-0.198452</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>0.289654</td>\n",
       "      <td>-0.018843</td>\n",
       "      <td>-0.158281</td>\n",
       "      <td>-0.219139</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>0.268893</td>\n",
       "      <td>-0.310487</td>\n",
       "      <td>-0.068200</td>\n",
       "      <td>0.319473</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101761</td>\n",
       "      <td>-0.108375</td>\n",
       "      <td>-0.438356</td>\n",
       "      <td>0.250837</td>\n",
       "      <td>-0.234309</td>\n",
       "      <td>0.232444</td>\n",
       "      <td>-0.257775</td>\n",
       "      <td>-0.231103</td>\n",
       "      <td>-0.189915</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>0.351503</td>\n",
       "      <td>-0.012423</td>\n",
       "      <td>-0.203867</td>\n",
       "      <td>-0.269270</td>\n",
       "      <td>-0.087212</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>-0.377404</td>\n",
       "      <td>-0.038678</td>\n",
       "      <td>0.229430</td>\n",
       "      <td>0.269013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156435</td>\n",
       "      <td>0.097870</td>\n",
       "      <td>-0.405691</td>\n",
       "      <td>0.183340</td>\n",
       "      <td>-0.056556</td>\n",
       "      <td>0.054368</td>\n",
       "      <td>-0.266442</td>\n",
       "      <td>-0.291113</td>\n",
       "      <td>-0.200293</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1 tBodyAcc-mean()-X  2 tBodyAcc-mean()-Y  3 tBodyAcc-mean()-Z  \\\n",
       "0                0.288585            -0.020294            -0.132905   \n",
       "1                0.278419            -0.016411            -0.123520   \n",
       "2                0.279653            -0.019467            -0.113462   \n",
       "3                0.279174            -0.026201            -0.123283   \n",
       "4                0.276629            -0.016570            -0.115362   \n",
       "...                   ...                  ...                  ...   \n",
       "7347             0.299665            -0.057193            -0.181233   \n",
       "7348             0.273853            -0.007749            -0.147468   \n",
       "7349             0.273387            -0.017011            -0.045022   \n",
       "7350             0.289654            -0.018843            -0.158281   \n",
       "7351             0.351503            -0.012423            -0.203867   \n",
       "\n",
       "      4 tBodyAcc-std()-X  5 tBodyAcc-std()-Y  6 tBodyAcc-std()-Z  \\\n",
       "0              -0.995279           -0.983111           -0.913526   \n",
       "1              -0.998245           -0.975300           -0.960322   \n",
       "2              -0.995380           -0.967187           -0.978944   \n",
       "3              -0.996091           -0.983403           -0.990675   \n",
       "4              -0.998139           -0.980817           -0.990482   \n",
       "...                  ...                 ...                 ...   \n",
       "7347           -0.195387            0.039905            0.077078   \n",
       "7348           -0.235309            0.004816            0.059280   \n",
       "7349           -0.218218           -0.103822            0.274533   \n",
       "7350           -0.219139           -0.111412            0.268893   \n",
       "7351           -0.269270           -0.087212            0.177404   \n",
       "\n",
       "      7 tBodyAcc-mad()-X  8 tBodyAcc-mad()-Y  9 tBodyAcc-mad()-Z  \\\n",
       "0              -0.995112           -0.983185           -0.923527   \n",
       "1              -0.998807           -0.974914           -0.957686   \n",
       "2              -0.996520           -0.963668           -0.977469   \n",
       "3              -0.997099           -0.982750           -0.989302   \n",
       "4              -0.998321           -0.979672           -0.990441   \n",
       "...                  ...                 ...                 ...   \n",
       "7347           -0.282301            0.043616            0.060410   \n",
       "7348           -0.322552           -0.029456            0.080585   \n",
       "7349           -0.304515           -0.098913            0.332584   \n",
       "7350           -0.310487           -0.068200            0.319473   \n",
       "7351           -0.377404           -0.038678            0.229430   \n",
       "\n",
       "      10 tBodyAcc-max()-X  ...  32 tBodyAcc-arCoeff()-Y,3  \\\n",
       "0               -0.934724  ...                   0.264106   \n",
       "1               -0.943068  ...                   0.294310   \n",
       "2               -0.938692  ...                   0.342256   \n",
       "3               -0.938692  ...                   0.323154   \n",
       "4               -0.942469  ...                   0.434728   \n",
       "...                   ...  ...                        ...   \n",
       "7347             0.210795  ...                  -0.119821   \n",
       "7348             0.117440  ...                   0.034260   \n",
       "7349             0.043999  ...                   0.119962   \n",
       "7350             0.101702  ...                   0.101761   \n",
       "7351             0.269013  ...                  -0.156435   \n",
       "\n",
       "      33 tBodyAcc-arCoeff()-Y,4  34 tBodyAcc-arCoeff()-Z,1  \\\n",
       "0                     -0.095246                   0.278851   \n",
       "1                     -0.281211                   0.085988   \n",
       "2                     -0.332564                   0.239281   \n",
       "3                     -0.170813                   0.294938   \n",
       "4                     -0.315375                   0.439744   \n",
       "...                         ...                        ...   \n",
       "7347                   0.293112                  -0.425386   \n",
       "7348                   0.239835                  -0.364480   \n",
       "7349                   0.080689                  -0.420093   \n",
       "7350                  -0.108375                  -0.438356   \n",
       "7351                   0.097870                  -0.405691   \n",
       "\n",
       "      35 tBodyAcc-arCoeff()-Z,2  36 tBodyAcc-arCoeff()-Z,3  \\\n",
       "0                     -0.465085                   0.491936   \n",
       "1                     -0.022153                  -0.016657   \n",
       "2                     -0.136204                   0.173863   \n",
       "3                     -0.306081                   0.482148   \n",
       "4                     -0.269069                   0.179414   \n",
       "...                         ...                        ...   \n",
       "7347                   0.267986                  -0.205315   \n",
       "7348                   0.121335                   0.188717   \n",
       "7349                   0.197763                  -0.033780   \n",
       "7350                   0.250837                  -0.234309   \n",
       "7351                   0.183340                  -0.056556   \n",
       "\n",
       "      37 tBodyAcc-arCoeff()-Z,4  38 tBodyAcc-correlation()-X,Y  \\\n",
       "0                     -0.190884                       0.376314   \n",
       "1                     -0.220643                      -0.013429   \n",
       "2                     -0.299493                      -0.124698   \n",
       "3                     -0.470129                      -0.305693   \n",
       "4                     -0.088952                      -0.155804   \n",
       "...                         ...                            ...   \n",
       "7347                   0.142117                      -0.211822   \n",
       "7348                  -0.207505                      -0.198555   \n",
       "7349                   0.016677                      -0.226826   \n",
       "7350                   0.232444                      -0.257775   \n",
       "7351                   0.054368                      -0.266442   \n",
       "\n",
       "      39 tBodyAcc-correlation()-X,Z  40 tBodyAcc-correlation()-Y,Z  Activity  \n",
       "0                          0.435129                       0.660790         5  \n",
       "1                         -0.072692                       0.579382         5  \n",
       "2                         -0.181105                       0.608900         5  \n",
       "3                         -0.362654                       0.507459         5  \n",
       "4                         -0.189763                       0.599213         5  \n",
       "...                             ...                            ...       ...  \n",
       "7347                      -0.251582                      -0.283335         2  \n",
       "7348                      -0.225866                      -0.274504         2  \n",
       "7349                      -0.184700                      -0.198452         2  \n",
       "7350                      -0.231103                      -0.189915         2  \n",
       "7351                      -0.291113                      -0.200293         2  \n",
       "\n",
       "[7352 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "X_train = train_data.iloc[:,:40]\n",
    "\n",
    "X_train = pd.concat([X_train, y_train], axis = 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[(X_train['Activity'] == 1) | (X_train['Activity'] == 3) | (X_train['Activity'] == 4)]\n",
    "X_train = X_train.iloc[:,:-1].values\n",
    "\n",
    "y_train = y_train[(y_train['Activity'] == 1) | (y_train['Activity'] == 3) | (y_train['Activity'] == 4)]\n",
    "y_train = y_train.values\n",
    "y_train = y_train.flatten()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_subjects = pd.read_csv('UCI/subject_train.txt', header = None)\n",
    "# train_subjects.columns = ['Subject']\n",
    "# train_subjects = train_subjects.values\n",
    "# train_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 tBodyAcc-mean()-X</th>\n",
       "      <th>2 tBodyAcc-mean()-Y</th>\n",
       "      <th>3 tBodyAcc-mean()-Z</th>\n",
       "      <th>4 tBodyAcc-std()-X</th>\n",
       "      <th>5 tBodyAcc-std()-Y</th>\n",
       "      <th>6 tBodyAcc-std()-Z</th>\n",
       "      <th>7 tBodyAcc-mad()-X</th>\n",
       "      <th>8 tBodyAcc-mad()-Y</th>\n",
       "      <th>9 tBodyAcc-mad()-Z</th>\n",
       "      <th>10 tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>32 tBodyAcc-arCoeff()-Y,3</th>\n",
       "      <th>33 tBodyAcc-arCoeff()-Y,4</th>\n",
       "      <th>34 tBodyAcc-arCoeff()-Z,1</th>\n",
       "      <th>35 tBodyAcc-arCoeff()-Z,2</th>\n",
       "      <th>36 tBodyAcc-arCoeff()-Z,3</th>\n",
       "      <th>37 tBodyAcc-arCoeff()-Z,4</th>\n",
       "      <th>38 tBodyAcc-correlation()-X,Y</th>\n",
       "      <th>39 tBodyAcc-correlation()-X,Z</th>\n",
       "      <th>40 tBodyAcc-correlation()-Y,Z</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130858</td>\n",
       "      <td>-0.014176</td>\n",
       "      <td>-0.105971</td>\n",
       "      <td>0.073544</td>\n",
       "      <td>-0.171516</td>\n",
       "      <td>0.040063</td>\n",
       "      <td>0.076989</td>\n",
       "      <td>-0.490546</td>\n",
       "      <td>-0.709003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411411</td>\n",
       "      <td>-0.340466</td>\n",
       "      <td>0.077555</td>\n",
       "      <td>-0.084024</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>-0.010083</td>\n",
       "      <td>-0.104983</td>\n",
       "      <td>-0.429134</td>\n",
       "      <td>0.399177</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470819</td>\n",
       "      <td>-0.507395</td>\n",
       "      <td>0.188536</td>\n",
       "      <td>-0.231575</td>\n",
       "      <td>0.632120</td>\n",
       "      <td>-0.550708</td>\n",
       "      <td>0.305653</td>\n",
       "      <td>-0.323848</td>\n",
       "      <td>0.279786</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270298</td>\n",
       "      <td>-0.032614</td>\n",
       "      <td>-0.117520</td>\n",
       "      <td>-0.994743</td>\n",
       "      <td>-0.973268</td>\n",
       "      <td>-0.967091</td>\n",
       "      <td>-0.995274</td>\n",
       "      <td>-0.974471</td>\n",
       "      <td>-0.968897</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446100</td>\n",
       "      <td>-0.419496</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>-0.225769</td>\n",
       "      <td>0.416376</td>\n",
       "      <td>-0.286445</td>\n",
       "      <td>-0.063792</td>\n",
       "      <td>-0.167111</td>\n",
       "      <td>0.544916</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274833</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>-0.129527</td>\n",
       "      <td>-0.993852</td>\n",
       "      <td>-0.967445</td>\n",
       "      <td>-0.978295</td>\n",
       "      <td>-0.994111</td>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-0.977346</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168419</td>\n",
       "      <td>-0.068156</td>\n",
       "      <td>0.074384</td>\n",
       "      <td>0.027138</td>\n",
       "      <td>-0.145931</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>0.235151</td>\n",
       "      <td>0.290487</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>0.310155</td>\n",
       "      <td>-0.053391</td>\n",
       "      <td>-0.099109</td>\n",
       "      <td>-0.287866</td>\n",
       "      <td>-0.140589</td>\n",
       "      <td>-0.215088</td>\n",
       "      <td>-0.356083</td>\n",
       "      <td>-0.148775</td>\n",
       "      <td>-0.232057</td>\n",
       "      <td>0.185361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>0.163305</td>\n",
       "      <td>-0.510918</td>\n",
       "      <td>0.525957</td>\n",
       "      <td>-0.467399</td>\n",
       "      <td>0.117754</td>\n",
       "      <td>-0.258908</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.022682</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>0.363385</td>\n",
       "      <td>-0.039214</td>\n",
       "      <td>-0.105915</td>\n",
       "      <td>-0.305388</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>-0.196373</td>\n",
       "      <td>-0.373540</td>\n",
       "      <td>-0.030036</td>\n",
       "      <td>-0.270237</td>\n",
       "      <td>0.185361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070093</td>\n",
       "      <td>0.085764</td>\n",
       "      <td>-0.416882</td>\n",
       "      <td>0.387530</td>\n",
       "      <td>-0.225698</td>\n",
       "      <td>-0.039828</td>\n",
       "      <td>-0.249325</td>\n",
       "      <td>-0.293864</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>0.349966</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>-0.115788</td>\n",
       "      <td>-0.329638</td>\n",
       "      <td>-0.042143</td>\n",
       "      <td>-0.250181</td>\n",
       "      <td>-0.388017</td>\n",
       "      <td>-0.133257</td>\n",
       "      <td>-0.347029</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170446</td>\n",
       "      <td>0.047362</td>\n",
       "      <td>-0.204792</td>\n",
       "      <td>0.077011</td>\n",
       "      <td>0.291691</td>\n",
       "      <td>-0.347075</td>\n",
       "      <td>-0.351080</td>\n",
       "      <td>-0.417738</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.237594</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>-0.096499</td>\n",
       "      <td>-0.323114</td>\n",
       "      <td>-0.229775</td>\n",
       "      <td>-0.207574</td>\n",
       "      <td>-0.392380</td>\n",
       "      <td>-0.279610</td>\n",
       "      <td>-0.289477</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233641</td>\n",
       "      <td>0.047228</td>\n",
       "      <td>-0.208363</td>\n",
       "      <td>0.195608</td>\n",
       "      <td>-0.054894</td>\n",
       "      <td>-0.038834</td>\n",
       "      <td>-0.190791</td>\n",
       "      <td>-0.507067</td>\n",
       "      <td>0.122642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>0.153627</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>-0.137018</td>\n",
       "      <td>-0.330046</td>\n",
       "      <td>-0.195253</td>\n",
       "      <td>-0.164339</td>\n",
       "      <td>-0.430974</td>\n",
       "      <td>-0.218295</td>\n",
       "      <td>-0.229933</td>\n",
       "      <td>-0.111527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338025</td>\n",
       "      <td>-0.123040</td>\n",
       "      <td>-0.331906</td>\n",
       "      <td>0.298205</td>\n",
       "      <td>-0.001256</td>\n",
       "      <td>-0.179224</td>\n",
       "      <td>-0.080295</td>\n",
       "      <td>-0.522901</td>\n",
       "      <td>0.056253</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2947 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1 tBodyAcc-mean()-X  2 tBodyAcc-mean()-Y  3 tBodyAcc-mean()-Z  \\\n",
       "0                0.257178            -0.023285            -0.014654   \n",
       "1                0.286027            -0.013163            -0.119083   \n",
       "2                0.275485            -0.026050            -0.118152   \n",
       "3                0.270298            -0.032614            -0.117520   \n",
       "4                0.274833            -0.027848            -0.129527   \n",
       "...                   ...                  ...                  ...   \n",
       "2942             0.310155            -0.053391            -0.099109   \n",
       "2943             0.363385            -0.039214            -0.105915   \n",
       "2944             0.349966             0.030077            -0.115788   \n",
       "2945             0.237594             0.018467            -0.096499   \n",
       "2946             0.153627            -0.018437            -0.137018   \n",
       "\n",
       "      4 tBodyAcc-std()-X  5 tBodyAcc-std()-Y  6 tBodyAcc-std()-Z  \\\n",
       "0              -0.938404           -0.920091           -0.667683   \n",
       "1              -0.975415           -0.967458           -0.944958   \n",
       "2              -0.993819           -0.969926           -0.962748   \n",
       "3              -0.994743           -0.973268           -0.967091   \n",
       "4              -0.993852           -0.967445           -0.978295   \n",
       "...                  ...                 ...                 ...   \n",
       "2942           -0.287866           -0.140589           -0.215088   \n",
       "2943           -0.305388            0.028148           -0.196373   \n",
       "2944           -0.329638           -0.042143           -0.250181   \n",
       "2945           -0.323114           -0.229775           -0.207574   \n",
       "2946           -0.330046           -0.195253           -0.164339   \n",
       "\n",
       "      7 tBodyAcc-mad()-X  8 tBodyAcc-mad()-Y  9 tBodyAcc-mad()-Z  \\\n",
       "0              -0.952501           -0.925249           -0.674302   \n",
       "1              -0.986799           -0.968401           -0.945823   \n",
       "2              -0.994403           -0.970735           -0.963483   \n",
       "3              -0.995274           -0.974471           -0.968897   \n",
       "4              -0.994111           -0.965953           -0.977346   \n",
       "...                  ...                 ...                 ...   \n",
       "2942           -0.356083           -0.148775           -0.232057   \n",
       "2943           -0.373540           -0.030036           -0.270237   \n",
       "2944           -0.388017           -0.133257           -0.347029   \n",
       "2945           -0.392380           -0.279610           -0.289477   \n",
       "2946           -0.430974           -0.218295           -0.229933   \n",
       "\n",
       "      10 tBodyAcc-max()-X  ...  32 tBodyAcc-arCoeff()-Y,3  \\\n",
       "0               -0.894088  ...                   0.130858   \n",
       "1               -0.894088  ...                   0.411411   \n",
       "2               -0.939260  ...                   0.470819   \n",
       "3               -0.938610  ...                   0.446100   \n",
       "4               -0.938610  ...                   0.168419   \n",
       "...                   ...  ...                        ...   \n",
       "2942             0.185361  ...                   0.013961   \n",
       "2943             0.185361  ...                   0.070093   \n",
       "2944             0.007471  ...                   0.170446   \n",
       "2945             0.007471  ...                   0.233641   \n",
       "2946            -0.111527  ...                   0.338025   \n",
       "\n",
       "      33 tBodyAcc-arCoeff()-Y,4  34 tBodyAcc-arCoeff()-Z,1  \\\n",
       "0                     -0.014176                  -0.105971   \n",
       "1                     -0.340466                   0.077555   \n",
       "2                     -0.507395                   0.188536   \n",
       "3                     -0.419496                   0.271493   \n",
       "4                     -0.068156                   0.074384   \n",
       "...                         ...                        ...   \n",
       "2942                   0.163305                  -0.510918   \n",
       "2943                   0.085764                  -0.416882   \n",
       "2944                   0.047362                  -0.204792   \n",
       "2945                   0.047228                  -0.208363   \n",
       "2946                  -0.123040                  -0.331906   \n",
       "\n",
       "      35 tBodyAcc-arCoeff()-Z,2  36 tBodyAcc-arCoeff()-Z,3  \\\n",
       "0                      0.073544                  -0.171516   \n",
       "1                     -0.084024                   0.035305   \n",
       "2                     -0.231575                   0.632120   \n",
       "3                     -0.225769                   0.416376   \n",
       "4                      0.027138                  -0.145931   \n",
       "...                         ...                        ...   \n",
       "2942                   0.525957                  -0.467399   \n",
       "2943                   0.387530                  -0.225698   \n",
       "2944                   0.077011                   0.291691   \n",
       "2945                   0.195608                  -0.054894   \n",
       "2946                   0.298205                  -0.001256   \n",
       "\n",
       "      37 tBodyAcc-arCoeff()-Z,4  38 tBodyAcc-correlation()-X,Y  \\\n",
       "0                      0.040063                       0.076989   \n",
       "1                     -0.010083                      -0.104983   \n",
       "2                     -0.550708                       0.305653   \n",
       "3                     -0.286445                      -0.063792   \n",
       "4                     -0.050197                       0.235151   \n",
       "...                         ...                            ...   \n",
       "2942                   0.117754                      -0.258908   \n",
       "2943                  -0.039828                      -0.249325   \n",
       "2944                  -0.347075                      -0.351080   \n",
       "2945                  -0.038834                      -0.190791   \n",
       "2946                  -0.179224                      -0.080295   \n",
       "\n",
       "      39 tBodyAcc-correlation()-X,Z  40 tBodyAcc-correlation()-Y,Z  Activity  \n",
       "0                         -0.490546                      -0.709003         5  \n",
       "1                         -0.429134                       0.399177         5  \n",
       "2                         -0.323848                       0.279786         5  \n",
       "3                         -0.167111                       0.544916         5  \n",
       "4                          0.290487                       0.457718         5  \n",
       "...                             ...                            ...       ...  \n",
       "2942                      -0.310537                      -0.022682         2  \n",
       "2943                      -0.293864                       0.031417         2  \n",
       "2944                      -0.417738                       0.118835         2  \n",
       "2945                      -0.507067                       0.122642         2  \n",
       "2946                      -0.522901                       0.056253         2  \n",
       "\n",
       "[2947 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "test_column_names = test_names.values.tolist()\n",
    "test_column_names = [k for row in test_column_names for k in row]\n",
    "\n",
    "test_data = pd.read_csv('../data/X_test.txt', delim_whitespace = True, header = None)\n",
    "test_data.columns = test_column_names\n",
    "\n",
    "y_test = pd.read_csv('../data/y_test.txt', header = None)\n",
    "y_test.columns = ['Activity']\n",
    "\n",
    "X_test = test_data.iloc[:,:40]\n",
    "\n",
    "X_test = pd.concat([X_test, y_test], axis = 1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[(X_test['Activity'] == 1) | (X_test['Activity'] == 3) | (X_test['Activity'] == 4)]\n",
    "X_test = X_test.iloc[:,:-1].values\n",
    "\n",
    "y_test = y_test[(y_test['Activity'] == 1) | (y_test['Activity'] == 3) | (y_test['Activity'] == 4)]\n",
    "y_test = y_test.values\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2\n",
    "        \n",
    "for k in range(len(y_test)):\n",
    "    if y_test[k] == 1:\n",
    "        y_test[k] = 0\n",
    "    elif y_test[k] == 3:\n",
    "        y_test[k] = 1\n",
    "    else:\n",
    "        y_test[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_subjects = pd.read_csv('UCI/subject_test.txt', header = None)\n",
    "# test_subjects.columns = ['Subject']\n",
    "# test_subjects = test_subjects.values\n",
    "# test_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = 40):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 15.241586685180664, Final Batch Loss: 1.0885568857192993\n",
      "Epoch 2, Loss: 15.01316499710083, Final Batch Loss: 1.0572901964187622\n",
      "Epoch 3, Loss: 14.4086195230484, Final Batch Loss: 1.0062532424926758\n",
      "Epoch 4, Loss: 12.898515105247498, Final Batch Loss: 0.8445584177970886\n",
      "Epoch 5, Loss: 10.042168617248535, Final Batch Loss: 0.6221087574958801\n",
      "Epoch 6, Loss: 6.96773573756218, Final Batch Loss: 0.42692217230796814\n",
      "Epoch 7, Loss: 4.945006847381592, Final Batch Loss: 0.32045426964759827\n",
      "Epoch 8, Loss: 4.002572491765022, Final Batch Loss: 0.2908990979194641\n",
      "Epoch 9, Loss: 3.357620432972908, Final Batch Loss: 0.24363577365875244\n",
      "Epoch 10, Loss: 2.7313525676727295, Final Batch Loss: 0.1869368851184845\n",
      "Epoch 11, Loss: 2.5092479437589645, Final Batch Loss: 0.2685406804084778\n",
      "Epoch 12, Loss: 1.9806807339191437, Final Batch Loss: 0.12742647528648376\n",
      "Epoch 13, Loss: 1.6515983492136002, Final Batch Loss: 0.12085820734500885\n",
      "Epoch 14, Loss: 1.5255390852689743, Final Batch Loss: 0.12020830810070038\n",
      "Epoch 15, Loss: 1.2986337132751942, Final Batch Loss: 0.09946218878030777\n",
      "Epoch 16, Loss: 1.163134392350912, Final Batch Loss: 0.11984627693891525\n",
      "Epoch 17, Loss: 1.086319476366043, Final Batch Loss: 0.045442648231983185\n",
      "Epoch 18, Loss: 1.0153829120099545, Final Batch Loss: 0.09287752211093903\n",
      "Epoch 19, Loss: 0.9270525611937046, Final Batch Loss: 0.11095812171697617\n",
      "Epoch 20, Loss: 0.8743663243949413, Final Batch Loss: 0.05012936145067215\n",
      "Epoch 21, Loss: 0.8242511264979839, Final Batch Loss: 0.05374891310930252\n",
      "Epoch 22, Loss: 0.7816076967865229, Final Batch Loss: 0.06437866389751434\n",
      "Epoch 23, Loss: 0.7669017780572176, Final Batch Loss: 0.07778631895780563\n",
      "Epoch 24, Loss: 0.7200883161276579, Final Batch Loss: 0.029258808121085167\n",
      "Epoch 25, Loss: 0.6877487152814865, Final Batch Loss: 0.052596040070056915\n",
      "Epoch 26, Loss: 0.5764063559472561, Final Batch Loss: 0.0407060869038105\n",
      "Epoch 27, Loss: 0.6650169715285301, Final Batch Loss: 0.034714557230472565\n",
      "Epoch 28, Loss: 0.5587802603840828, Final Batch Loss: 0.048125218600034714\n",
      "Epoch 29, Loss: 0.5815535224974155, Final Batch Loss: 0.052284494042396545\n",
      "Epoch 30, Loss: 0.5081836078315973, Final Batch Loss: 0.024517036974430084\n",
      "Epoch 31, Loss: 0.5603563562035561, Final Batch Loss: 0.042215801775455475\n",
      "Epoch 32, Loss: 0.46950519271194935, Final Batch Loss: 0.019912147894501686\n",
      "Epoch 33, Loss: 0.4789757477119565, Final Batch Loss: 0.04510272666811943\n",
      "Epoch 34, Loss: 0.5843794541433454, Final Batch Loss: 0.04715939983725548\n",
      "Epoch 35, Loss: 0.48881011083722115, Final Batch Loss: 0.030502870678901672\n",
      "Epoch 36, Loss: 0.4435000941157341, Final Batch Loss: 0.03946010768413544\n",
      "Epoch 37, Loss: 0.47249118611216545, Final Batch Loss: 0.05157315358519554\n",
      "Epoch 38, Loss: 0.4157352866604924, Final Batch Loss: 0.041228026151657104\n",
      "Epoch 39, Loss: 0.37933205999433994, Final Batch Loss: 0.028912845999002457\n",
      "Epoch 40, Loss: 0.421003102324903, Final Batch Loss: 0.051836781203746796\n",
      "Epoch 41, Loss: 0.3873060755431652, Final Batch Loss: 0.009440765716135502\n",
      "Epoch 42, Loss: 0.4382225638255477, Final Batch Loss: 0.032000597566366196\n",
      "Epoch 43, Loss: 0.428411265835166, Final Batch Loss: 0.02681109867990017\n",
      "Epoch 44, Loss: 0.32143806107342243, Final Batch Loss: 0.03377598151564598\n",
      "Epoch 45, Loss: 0.296645930968225, Final Batch Loss: 0.03043864294886589\n",
      "Epoch 46, Loss: 0.31955865351483226, Final Batch Loss: 0.05666038393974304\n",
      "Epoch 47, Loss: 0.31725021125748754, Final Batch Loss: 0.019606783986091614\n",
      "Epoch 48, Loss: 0.35162158217281103, Final Batch Loss: 0.01567349024116993\n",
      "Epoch 49, Loss: 0.28095207503065467, Final Batch Loss: 0.009261143393814564\n",
      "Epoch 50, Loss: 0.3339660121127963, Final Batch Loss: 0.010344134643673897\n",
      "Epoch 51, Loss: 0.3422501664608717, Final Batch Loss: 0.016081083565950394\n",
      "Epoch 52, Loss: 0.32339753210544586, Final Batch Loss: 0.013758288696408272\n",
      "Epoch 53, Loss: 0.27157588908448815, Final Batch Loss: 0.006537826731801033\n",
      "Epoch 54, Loss: 0.2663092636503279, Final Batch Loss: 0.010387929156422615\n",
      "Epoch 55, Loss: 0.29253643937408924, Final Batch Loss: 0.03251974657177925\n",
      "Epoch 56, Loss: 0.28640239546075463, Final Batch Loss: 0.012463567778468132\n",
      "Epoch 57, Loss: 0.28248506877571344, Final Batch Loss: 0.022846536710858345\n",
      "Epoch 58, Loss: 0.2724217139184475, Final Batch Loss: 0.0148002365604043\n",
      "Epoch 59, Loss: 0.2624020860530436, Final Batch Loss: 0.0133659141138196\n",
      "Epoch 60, Loss: 0.2816959242336452, Final Batch Loss: 0.0053432900458574295\n",
      "Epoch 61, Loss: 0.22600931162014604, Final Batch Loss: 0.020006267353892326\n",
      "Epoch 62, Loss: 0.269613787997514, Final Batch Loss: 0.02227618917822838\n",
      "Epoch 63, Loss: 0.2518653506413102, Final Batch Loss: 0.005975014064460993\n",
      "Epoch 64, Loss: 0.2506705462001264, Final Batch Loss: 0.02248295210301876\n",
      "Epoch 65, Loss: 0.17110797856003046, Final Batch Loss: 0.014845109544694424\n",
      "Epoch 66, Loss: 0.22578419465571642, Final Batch Loss: 0.00461226049810648\n",
      "Epoch 67, Loss: 0.19006200437434018, Final Batch Loss: 0.015746012330055237\n",
      "Epoch 68, Loss: 0.20145236002281308, Final Batch Loss: 0.008431140333414078\n",
      "Epoch 69, Loss: 0.25520799844525754, Final Batch Loss: 0.0321027971804142\n",
      "Epoch 70, Loss: 0.19513127789832652, Final Batch Loss: 0.019762756302952766\n",
      "Epoch 71, Loss: 0.1512257173890248, Final Batch Loss: 0.00708245113492012\n",
      "Epoch 72, Loss: 0.2146189019549638, Final Batch Loss: 0.008673569187521935\n",
      "Epoch 73, Loss: 0.21997167775407434, Final Batch Loss: 0.005924773868173361\n",
      "Epoch 74, Loss: 0.18616671371273696, Final Batch Loss: 0.005919983610510826\n",
      "Epoch 75, Loss: 0.20745620969682932, Final Batch Loss: 0.03027024120092392\n",
      "Epoch 76, Loss: 0.20804695785045624, Final Batch Loss: 0.026572884991765022\n",
      "Epoch 77, Loss: 0.1955587095580995, Final Batch Loss: 0.006136443931609392\n",
      "Epoch 78, Loss: 0.21375831100158393, Final Batch Loss: 0.006664396263659\n",
      "Epoch 79, Loss: 0.15427999896928668, Final Batch Loss: 0.005330439656972885\n",
      "Epoch 80, Loss: 0.19475794420577586, Final Batch Loss: 0.03213188797235489\n",
      "Epoch 81, Loss: 0.1546995509415865, Final Batch Loss: 0.012616281397640705\n",
      "Epoch 82, Loss: 0.15122281946241856, Final Batch Loss: 0.009327013045549393\n",
      "Epoch 83, Loss: 0.15957318164873868, Final Batch Loss: 0.012634778395295143\n",
      "Epoch 84, Loss: 0.17952703591436148, Final Batch Loss: 0.004820705391466618\n",
      "Epoch 85, Loss: 0.1177370676305145, Final Batch Loss: 0.005082578398287296\n",
      "Epoch 86, Loss: 0.16040273616090417, Final Batch Loss: 0.008951698429882526\n",
      "Epoch 87, Loss: 0.16017612244468182, Final Batch Loss: 0.021002216264605522\n",
      "Epoch 88, Loss: 0.16910677985288203, Final Batch Loss: 0.021447185426950455\n",
      "Epoch 89, Loss: 0.13489603134803474, Final Batch Loss: 0.0026714433915913105\n",
      "Epoch 90, Loss: 0.1275413534604013, Final Batch Loss: 0.011616278439760208\n",
      "Epoch 91, Loss: 0.1533345178468153, Final Batch Loss: 0.001983470981940627\n",
      "Epoch 92, Loss: 0.11706439417321235, Final Batch Loss: 0.005452429875731468\n",
      "Epoch 93, Loss: 0.18986531789414585, Final Batch Loss: 0.007090073544532061\n",
      "Epoch 94, Loss: 0.15760599658824503, Final Batch Loss: 0.005889474879950285\n",
      "Epoch 95, Loss: 0.1018304314929992, Final Batch Loss: 0.007121828384697437\n",
      "Epoch 96, Loss: 0.1387316812761128, Final Batch Loss: 0.0021217036992311478\n",
      "Epoch 97, Loss: 0.16323513118550181, Final Batch Loss: 0.011050515808165073\n",
      "Epoch 98, Loss: 0.12365022068843246, Final Batch Loss: 0.002607231494039297\n",
      "Epoch 99, Loss: 0.10879617067985237, Final Batch Loss: 0.0037693623453378677\n",
      "Epoch 100, Loss: 0.11080954759381711, Final Batch Loss: 0.021288039162755013\n",
      "Epoch 101, Loss: 0.15162296197377145, Final Batch Loss: 0.019194772467017174\n",
      "Epoch 102, Loss: 0.07753733405843377, Final Batch Loss: 0.003145073540508747\n",
      "Epoch 103, Loss: 0.13061580760404468, Final Batch Loss: 0.04399992525577545\n",
      "Epoch 104, Loss: 0.11515724519267678, Final Batch Loss: 0.0033747414126992226\n",
      "Epoch 105, Loss: 0.08391082845628262, Final Batch Loss: 0.005014252848923206\n",
      "Epoch 106, Loss: 0.13033255469053984, Final Batch Loss: 0.025218389928340912\n",
      "Epoch 107, Loss: 0.08560733770718798, Final Batch Loss: 0.0025618395302444696\n",
      "Epoch 108, Loss: 0.08936264825752005, Final Batch Loss: 0.023923352360725403\n",
      "Epoch 109, Loss: 0.09039550146553665, Final Batch Loss: 0.002576950704678893\n",
      "Epoch 110, Loss: 0.121996269619558, Final Batch Loss: 0.0008186166523955762\n",
      "Epoch 111, Loss: 0.11270846612751484, Final Batch Loss: 0.0029177453834563494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112, Loss: 0.08634157315827906, Final Batch Loss: 0.005801751744002104\n",
      "Epoch 113, Loss: 0.08193488779943436, Final Batch Loss: 0.007177344057708979\n",
      "Epoch 114, Loss: 0.09459406419773586, Final Batch Loss: 0.002206516917794943\n",
      "Epoch 115, Loss: 0.08133581758011132, Final Batch Loss: 0.0023064452689141035\n",
      "Epoch 116, Loss: 0.05188019125489518, Final Batch Loss: 0.0038154313806444407\n",
      "Epoch 117, Loss: 0.08495525736361742, Final Batch Loss: 0.010023830458521843\n",
      "Epoch 118, Loss: 0.05599799344781786, Final Batch Loss: 0.0037475249264389277\n",
      "Epoch 119, Loss: 0.11403863813029602, Final Batch Loss: 0.005134284496307373\n",
      "Epoch 120, Loss: 0.05481136939488351, Final Batch Loss: 0.0007477431208826602\n",
      "Epoch 121, Loss: 0.1071863709948957, Final Batch Loss: 0.0032539304811507463\n",
      "Epoch 122, Loss: 0.09256417077267542, Final Batch Loss: 0.003924989141523838\n",
      "Epoch 123, Loss: 0.07236905547324568, Final Batch Loss: 0.01141122542321682\n",
      "Epoch 124, Loss: 0.08305285428650677, Final Batch Loss: 0.0022090377751737833\n",
      "Epoch 125, Loss: 0.0717318921815604, Final Batch Loss: 0.004515103530138731\n",
      "Epoch 126, Loss: 0.10915180400479585, Final Batch Loss: 0.01042190846055746\n",
      "Epoch 127, Loss: 0.07874059514142573, Final Batch Loss: 0.0010385202476754785\n",
      "Epoch 128, Loss: 0.08700269635301083, Final Batch Loss: 0.003734653815627098\n",
      "Epoch 129, Loss: 0.08688149810768664, Final Batch Loss: 0.006806839257478714\n",
      "Epoch 130, Loss: 0.06000546121504158, Final Batch Loss: 0.001993434736505151\n",
      "Epoch 131, Loss: 0.05532845587003976, Final Batch Loss: 0.0010925480164587498\n",
      "Epoch 132, Loss: 0.09637585625750944, Final Batch Loss: 0.013554812408983707\n",
      "Epoch 133, Loss: 0.09262050793040544, Final Batch Loss: 0.003776781726628542\n",
      "Epoch 134, Loss: 0.09851501323282719, Final Batch Loss: 0.011358757503330708\n",
      "Epoch 135, Loss: 0.05539025942562148, Final Batch Loss: 0.002511646132916212\n",
      "Epoch 136, Loss: 0.06881246552802622, Final Batch Loss: 0.0012472005328163505\n",
      "Epoch 137, Loss: 0.07054313510889187, Final Batch Loss: 0.00373951462097466\n",
      "Epoch 138, Loss: 0.06020331254694611, Final Batch Loss: 0.007827913388609886\n",
      "Epoch 139, Loss: 0.07215710211312398, Final Batch Loss: 0.000921610975638032\n",
      "Epoch 140, Loss: 0.06223293801303953, Final Batch Loss: 0.005091298371553421\n",
      "Epoch 141, Loss: 0.06247013206302654, Final Batch Loss: 0.0010660269763320684\n",
      "Epoch 142, Loss: 0.060754089266993105, Final Batch Loss: 0.0005294457660056651\n",
      "Epoch 143, Loss: 0.0683769510651473, Final Batch Loss: 0.0082502206787467\n",
      "Epoch 144, Loss: 0.07956006756285205, Final Batch Loss: 0.00861439947038889\n",
      "Epoch 145, Loss: 0.054740690626204014, Final Batch Loss: 0.0161438025534153\n",
      "Epoch 146, Loss: 0.056584226636914536, Final Batch Loss: 0.001000168384052813\n",
      "Epoch 147, Loss: 0.05323448491981253, Final Batch Loss: 0.0014115608064457774\n",
      "Epoch 148, Loss: 0.07939254629309289, Final Batch Loss: 0.002424278762191534\n",
      "Epoch 149, Loss: 0.09634171234210953, Final Batch Loss: 0.0011322570499032736\n",
      "Epoch 150, Loss: 0.04870063814450987, Final Batch Loss: 0.0005945211742073298\n",
      "Epoch 151, Loss: 0.04500288757844828, Final Batch Loss: 0.0021558513399213552\n",
      "Epoch 152, Loss: 0.028890696878079325, Final Batch Loss: 0.0018457723781466484\n",
      "Epoch 153, Loss: 0.05012409493792802, Final Batch Loss: 0.0011223499896004796\n",
      "Epoch 154, Loss: 0.05244608368957415, Final Batch Loss: 0.014775192365050316\n",
      "Epoch 155, Loss: 0.04652604024158791, Final Batch Loss: 0.0012515945127233863\n",
      "Epoch 156, Loss: 0.038823659415356815, Final Batch Loss: 0.0006832011276856065\n",
      "Epoch 157, Loss: 0.035923197312513366, Final Batch Loss: 0.0009745723218657076\n",
      "Epoch 158, Loss: 0.05609521284350194, Final Batch Loss: 0.007246119901537895\n",
      "Epoch 159, Loss: 0.056108184333425015, Final Batch Loss: 0.0005425174022093415\n",
      "Epoch 160, Loss: 0.046904381131753325, Final Batch Loss: 0.0003445393522270024\n",
      "Epoch 161, Loss: 0.03333613876020536, Final Batch Loss: 0.0006741817924194038\n",
      "Epoch 162, Loss: 0.05407929857028648, Final Batch Loss: 0.007654502056539059\n",
      "Epoch 163, Loss: 0.051594807038782164, Final Batch Loss: 0.001463354448787868\n",
      "Epoch 164, Loss: 0.030131530395010486, Final Batch Loss: 0.0007306448533199728\n",
      "Epoch 165, Loss: 0.07430670852772892, Final Batch Loss: 0.0018965057097375393\n",
      "Epoch 166, Loss: 0.03803024445369374, Final Batch Loss: 0.0016826235223561525\n",
      "Epoch 167, Loss: 0.020380648464197293, Final Batch Loss: 0.0003280788369011134\n",
      "Epoch 168, Loss: 0.0345355493191164, Final Batch Loss: 0.001252368208952248\n",
      "Epoch 169, Loss: 0.02542066152091138, Final Batch Loss: 0.0008176956325769424\n",
      "Epoch 170, Loss: 0.0319631205056794, Final Batch Loss: 0.004886277485638857\n",
      "Epoch 171, Loss: 0.046228750550653785, Final Batch Loss: 0.00218026340007782\n",
      "Epoch 172, Loss: 0.05473148447345011, Final Batch Loss: 0.0013356104027479887\n",
      "Epoch 173, Loss: 0.03697454095527064, Final Batch Loss: 0.0002053365606116131\n",
      "Epoch 174, Loss: 0.026913041016086936, Final Batch Loss: 0.000985229155048728\n",
      "Epoch 175, Loss: 0.04979783250018954, Final Batch Loss: 0.0002656793803907931\n",
      "Epoch 176, Loss: 0.03792677323508542, Final Batch Loss: 0.001155023230239749\n",
      "Epoch 177, Loss: 0.040768987528281286, Final Batch Loss: 0.0016124066896736622\n",
      "Epoch 178, Loss: 0.021837563297594897, Final Batch Loss: 0.0018205457599833608\n",
      "Epoch 179, Loss: 0.048132904470548965, Final Batch Loss: 0.004951768554747105\n",
      "Epoch 180, Loss: 0.042249399062711746, Final Batch Loss: 0.0004788286460097879\n",
      "Epoch 181, Loss: 0.027714038005797192, Final Batch Loss: 0.0017027010908350348\n",
      "Epoch 182, Loss: 0.023752559936838225, Final Batch Loss: 0.0007214028155431151\n",
      "Epoch 183, Loss: 0.046467135252896696, Final Batch Loss: 0.02016475610435009\n",
      "Epoch 184, Loss: 0.022362029762007296, Final Batch Loss: 0.0009159958572126925\n",
      "Epoch 185, Loss: 0.02143396377505269, Final Batch Loss: 0.00015741704555694014\n",
      "Epoch 186, Loss: 0.045200988577562384, Final Batch Loss: 0.00017729029059410095\n",
      "Epoch 187, Loss: 0.029941820102976635, Final Batch Loss: 0.002213575877249241\n",
      "Epoch 188, Loss: 0.043923297576839104, Final Batch Loss: 0.0003995229781139642\n",
      "Epoch 189, Loss: 0.05675111060554627, Final Batch Loss: 0.0035810561385005713\n",
      "Epoch 190, Loss: 0.016560303469304927, Final Batch Loss: 0.00044651213102042675\n",
      "Epoch 191, Loss: 0.034606548681040294, Final Batch Loss: 0.00045601019519381225\n",
      "Epoch 192, Loss: 0.02302853690343909, Final Batch Loss: 0.0007114763138815761\n",
      "Epoch 193, Loss: 0.015338069861172698, Final Batch Loss: 0.0006140946643427014\n",
      "Epoch 194, Loss: 0.022035426984075457, Final Batch Loss: 0.0004486961697693914\n",
      "Epoch 195, Loss: 0.02626026533835102, Final Batch Loss: 0.00015600703773088753\n",
      "Epoch 196, Loss: 0.0614587505988311, Final Batch Loss: 0.0008800462237559259\n",
      "Epoch 197, Loss: 0.03324311293545179, Final Batch Loss: 0.00989479012787342\n",
      "Epoch 198, Loss: 0.020391261918121018, Final Batch Loss: 0.0006133426795713603\n",
      "Epoch 199, Loss: 0.02276216572499834, Final Batch Loss: 0.0011321258498355746\n",
      "Epoch 200, Loss: 0.028146652621217072, Final Batch Loss: 0.00101556780282408\n",
      "Epoch 201, Loss: 0.06189878407167271, Final Batch Loss: 0.0022293669171631336\n",
      "Epoch 202, Loss: 0.017894513046485372, Final Batch Loss: 0.002490877639502287\n",
      "Epoch 203, Loss: 0.042924749839585274, Final Batch Loss: 0.004113128874450922\n",
      "Epoch 204, Loss: 0.020719299485790543, Final Batch Loss: 0.012128102593123913\n",
      "Epoch 205, Loss: 0.04065157799050212, Final Batch Loss: 0.0011323218932375312\n",
      "Epoch 206, Loss: 0.02066851351992227, Final Batch Loss: 0.0002959523117169738\n",
      "Epoch 207, Loss: 0.022009396750945598, Final Batch Loss: 0.0005020176176913083\n",
      "Epoch 208, Loss: 0.018796920092427172, Final Batch Loss: 0.00018596350855659693\n",
      "Epoch 209, Loss: 0.025971631053835154, Final Batch Loss: 0.0012049347860738635\n",
      "Epoch 210, Loss: 0.00971691164886579, Final Batch Loss: 0.0011405631667003036\n",
      "Epoch 211, Loss: 0.026753443176858127, Final Batch Loss: 0.0010746351908892393\n",
      "Epoch 212, Loss: 0.02859743627050193, Final Batch Loss: 0.00666333781555295\n",
      "Epoch 213, Loss: 0.028167788157588802, Final Batch Loss: 0.0002587992057669908\n",
      "Epoch 214, Loss: 0.016343632611096837, Final Batch Loss: 0.0001725207403069362\n",
      "Epoch 215, Loss: 0.032946814037131844, Final Batch Loss: 0.0004482174408622086\n",
      "Epoch 216, Loss: 0.006359869061270729, Final Batch Loss: 0.00032409338746219873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217, Loss: 0.028978281843592413, Final Batch Loss: 0.0001334760308964178\n",
      "Epoch 218, Loss: 0.014887285302393138, Final Batch Loss: 0.0018702818779274821\n",
      "Epoch 219, Loss: 0.017541626337333582, Final Batch Loss: 0.00010187661973759532\n",
      "Epoch 220, Loss: 0.028177132749988232, Final Batch Loss: 0.00026794083532877266\n",
      "Epoch 221, Loss: 0.011415716900955886, Final Batch Loss: 0.000988880405202508\n",
      "Epoch 222, Loss: 0.009474600985413417, Final Batch Loss: 0.001124388538300991\n",
      "Epoch 223, Loss: 0.020283684047171846, Final Batch Loss: 0.0003629184211604297\n",
      "Epoch 224, Loss: 0.010153002083825413, Final Batch Loss: 0.00030816977960057557\n",
      "Epoch 225, Loss: 0.02875921181839658, Final Batch Loss: 0.0001191463743452914\n",
      "Epoch 226, Loss: 0.033331576792988926, Final Batch Loss: 0.0003574944275896996\n",
      "Epoch 227, Loss: 0.03886640210839687, Final Batch Loss: 0.0029229973442852497\n",
      "Epoch 228, Loss: 0.04515171701496001, Final Batch Loss: 0.0026348019018769264\n",
      "Epoch 229, Loss: 0.07846948754013283, Final Batch Loss: 8.116334356600419e-05\n",
      "Epoch 230, Loss: 0.036667492415290326, Final Batch Loss: 0.015799928456544876\n",
      "Epoch 231, Loss: 0.015331856360717211, Final Batch Loss: 0.00019088241970166564\n",
      "Epoch 232, Loss: 0.02047477540327236, Final Batch Loss: 0.0005317276809364557\n",
      "Epoch 233, Loss: 0.018578319635707885, Final Batch Loss: 0.002272946760058403\n",
      "Epoch 234, Loss: 0.01589468064776156, Final Batch Loss: 0.0002255874132970348\n",
      "Epoch 235, Loss: 0.017174478009110317, Final Batch Loss: 0.0006345024448819458\n",
      "Epoch 236, Loss: 0.03641050878650276, Final Batch Loss: 0.003880756674334407\n",
      "Epoch 237, Loss: 0.006650762792560272, Final Batch Loss: 0.00020712117839138955\n",
      "Epoch 238, Loss: 0.006694067858916242, Final Batch Loss: 0.0015245835529640317\n",
      "Epoch 239, Loss: 0.018786338478093967, Final Batch Loss: 0.001073789200745523\n",
      "Epoch 240, Loss: 0.0183536603290122, Final Batch Loss: 0.00042563528404571116\n",
      "Epoch 241, Loss: 0.026815867589903064, Final Batch Loss: 0.000343831954523921\n",
      "Epoch 242, Loss: 0.014220332479453646, Final Batch Loss: 0.002700016601011157\n",
      "Epoch 243, Loss: 0.026760200777061982, Final Batch Loss: 4.028970215586014e-05\n",
      "Epoch 244, Loss: 0.01985726342900307, Final Batch Loss: 0.00037233749753795564\n",
      "Epoch 245, Loss: 0.013787711337499786, Final Batch Loss: 0.0005013662739656866\n",
      "Epoch 246, Loss: 0.006562278817000333, Final Batch Loss: 7.894721056800336e-05\n",
      "Epoch 247, Loss: 0.00974106321518775, Final Batch Loss: 0.00028554603341035545\n",
      "Epoch 248, Loss: 0.023479512114136014, Final Batch Loss: 0.00043832336086779833\n",
      "Epoch 249, Loss: 0.013072168294456787, Final Batch Loss: 4.286483454052359e-05\n",
      "Epoch 250, Loss: 0.008365699497517198, Final Batch Loss: 0.0026027963031083345\n",
      "Epoch 251, Loss: 0.019317440604936564, Final Batch Loss: 0.00010975299665005878\n",
      "Epoch 252, Loss: 0.0544846492484794, Final Batch Loss: 0.0002016279031522572\n",
      "Epoch 253, Loss: 0.037739604769740254, Final Batch Loss: 0.00022665401047561318\n",
      "Epoch 254, Loss: 0.026892804922681535, Final Batch Loss: 0.0003475249104667455\n",
      "Epoch 255, Loss: 0.017665557861619163, Final Batch Loss: 0.0001720432483125478\n",
      "Epoch 256, Loss: 0.03087612582021393, Final Batch Loss: 0.00030631115077994764\n",
      "Epoch 257, Loss: 0.03127597612183308, Final Batch Loss: 0.0001505713298683986\n",
      "Epoch 258, Loss: 0.014048521188669838, Final Batch Loss: 0.0002048557944362983\n",
      "Epoch 259, Loss: 0.036162271462671924, Final Batch Loss: 0.00020336209854576737\n",
      "Epoch 260, Loss: 0.020572037698002532, Final Batch Loss: 0.00011625161278061569\n",
      "Epoch 261, Loss: 0.027293506278510904, Final Batch Loss: 0.000800949172116816\n",
      "Epoch 262, Loss: 0.006027081406500656, Final Batch Loss: 0.0005780781502835453\n",
      "Epoch 263, Loss: 0.011264068678428885, Final Batch Loss: 0.00012448497000150383\n",
      "Epoch 264, Loss: 0.01884815049561439, Final Batch Loss: 0.0013708560727536678\n",
      "Epoch 265, Loss: 0.03252527947552153, Final Batch Loss: 0.00016843207413330674\n",
      "Epoch 266, Loss: 0.01477559976046905, Final Batch Loss: 0.002603512490168214\n",
      "Epoch 267, Loss: 0.11846969820908271, Final Batch Loss: 0.0006060476298443973\n",
      "Epoch 268, Loss: 0.052884604781866074, Final Batch Loss: 0.0006712865433655679\n",
      "Epoch 269, Loss: 0.024444193782983348, Final Batch Loss: 0.0007820738828741014\n",
      "Epoch 270, Loss: 0.04067758321616566, Final Batch Loss: 0.003631673054769635\n",
      "Epoch 271, Loss: 0.01374239753204165, Final Batch Loss: 0.002410620218142867\n",
      "Epoch 272, Loss: 0.045649247455003206, Final Batch Loss: 0.00013202922127675265\n",
      "Epoch 273, Loss: 0.004116478998184903, Final Batch Loss: 0.0003718346997629851\n",
      "Epoch 274, Loss: 0.009065477337571792, Final Batch Loss: 0.00024259448400698602\n",
      "Epoch 275, Loss: 0.005110451915243175, Final Batch Loss: 0.000480182672617957\n",
      "Epoch 276, Loss: 0.009227609778463375, Final Batch Loss: 0.0001119973894674331\n",
      "Epoch 277, Loss: 0.011689356004353613, Final Batch Loss: 0.0001630709448363632\n",
      "Epoch 278, Loss: 0.006150234708911739, Final Batch Loss: 2.7598282031249255e-05\n",
      "Epoch 279, Loss: 0.012609940196853131, Final Batch Loss: 0.00020146503811702132\n",
      "Epoch 280, Loss: 0.028725696363835596, Final Batch Loss: 0.00017455004854127765\n",
      "Epoch 281, Loss: 0.004703822698502336, Final Batch Loss: 0.00019211994367651641\n",
      "Epoch 282, Loss: 0.016825322731165215, Final Batch Loss: 0.0005479941610246897\n",
      "Epoch 283, Loss: 0.02062249690789031, Final Batch Loss: 0.0002230125683126971\n",
      "Epoch 284, Loss: 0.010739175937487744, Final Batch Loss: 0.00034779912675730884\n",
      "Epoch 285, Loss: 0.0043117109598824754, Final Batch Loss: 7.52214909880422e-05\n",
      "Epoch 286, Loss: 0.010762353471363895, Final Batch Loss: 0.00013882701750844717\n",
      "Epoch 287, Loss: 0.003769884875509888, Final Batch Loss: 9.771087934495881e-05\n",
      "Epoch 288, Loss: 0.008754672075156122, Final Batch Loss: 0.00012553214037325233\n",
      "Epoch 289, Loss: 0.018415363498206716, Final Batch Loss: 3.634002496255562e-05\n",
      "Epoch 290, Loss: 0.017328297548374394, Final Batch Loss: 9.102885087486356e-05\n",
      "Epoch 291, Loss: 0.007681285420403583, Final Batch Loss: 0.00033885904122143984\n",
      "Epoch 292, Loss: 0.0114167777755938, Final Batch Loss: 3.208673660992645e-05\n",
      "Epoch 293, Loss: 0.05511573703188333, Final Batch Loss: 0.04041625186800957\n",
      "Epoch 294, Loss: 0.005233619034697767, Final Batch Loss: 0.00021998574084136635\n",
      "Epoch 295, Loss: 0.00831365052727051, Final Batch Loss: 0.00028133924934081733\n",
      "Epoch 296, Loss: 0.0304124695394421, Final Batch Loss: 0.0001445237430743873\n",
      "Epoch 297, Loss: 0.008322599089297, Final Batch Loss: 7.881804049247876e-05\n",
      "Epoch 298, Loss: 0.029198964955867268, Final Batch Loss: 0.0017820193897932768\n",
      "Epoch 299, Loss: 0.020828821940085618, Final Batch Loss: 0.008192743174731731\n",
      "Epoch 300, Loss: 0.027945166926656384, Final Batch Loss: 0.00011208242358407006\n",
      "Epoch 301, Loss: 0.00547719302267069, Final Batch Loss: 0.00015844046720303595\n",
      "Epoch 302, Loss: 0.008351832781045232, Final Batch Loss: 0.0001338026486337185\n",
      "Epoch 303, Loss: 0.024924180303059984, Final Batch Loss: 0.0003422527515795082\n",
      "Epoch 304, Loss: 0.004680018859289703, Final Batch Loss: 0.0001203818537760526\n",
      "Epoch 305, Loss: 0.005518199548532721, Final Batch Loss: 0.0011789546115323901\n",
      "Epoch 306, Loss: 0.007854403418605216, Final Batch Loss: 0.00023494225752074271\n",
      "Epoch 307, Loss: 0.011385497928131372, Final Batch Loss: 0.00016992409655358642\n",
      "Epoch 308, Loss: 0.015544419744401239, Final Batch Loss: 0.0003852112276945263\n",
      "Epoch 309, Loss: 0.01483649255533237, Final Batch Loss: 0.0001127313807955943\n",
      "Epoch 310, Loss: 0.005286407364110346, Final Batch Loss: 9.82495621428825e-05\n",
      "Epoch 311, Loss: 0.045953660846862476, Final Batch Loss: 0.011070803739130497\n",
      "Epoch 312, Loss: 0.0415539281348174, Final Batch Loss: 0.0054525770246982574\n",
      "Epoch 313, Loss: 0.04455168917775154, Final Batch Loss: 0.0010652011260390282\n",
      "Epoch 314, Loss: 0.01864631583157461, Final Batch Loss: 0.011922987177968025\n",
      "Epoch 315, Loss: 0.007587175889057107, Final Batch Loss: 0.00046114937867969275\n",
      "Epoch 316, Loss: 0.016014445885957684, Final Batch Loss: 0.00017259854939766228\n",
      "Epoch 317, Loss: 0.02810902394412551, Final Batch Loss: 0.002187201054766774\n",
      "Epoch 318, Loss: 0.03378514129144605, Final Batch Loss: 0.023784426972270012\n",
      "Epoch 319, Loss: 0.008765111642787815, Final Batch Loss: 0.0009186766692437232\n",
      "Epoch 320, Loss: 0.029333564772969112, Final Batch Loss: 0.0014263890916481614\n",
      "Epoch 321, Loss: 0.023550178248115117, Final Batch Loss: 0.00017006938287522644\n",
      "Epoch 322, Loss: 0.01096614539710572, Final Batch Loss: 0.00023245884221978486\n",
      "Epoch 323, Loss: 0.008522852858732222, Final Batch Loss: 0.0002566188923083246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324, Loss: 0.02210603934872779, Final Batch Loss: 0.00034766114549711347\n",
      "Epoch 325, Loss: 0.01167714744224213, Final Batch Loss: 0.0008401566883549094\n",
      "Epoch 326, Loss: 0.010536420770222321, Final Batch Loss: 0.0032286429777741432\n",
      "Epoch 327, Loss: 0.01024093556770822, Final Batch Loss: 8.013558544917032e-05\n",
      "Epoch 328, Loss: 0.02140706877980847, Final Batch Loss: 0.00028003103216178715\n",
      "Epoch 329, Loss: 0.01263274149823701, Final Batch Loss: 0.00042793405009433627\n",
      "Epoch 330, Loss: 0.003515785087074619, Final Batch Loss: 9.477422281634063e-05\n",
      "Epoch 331, Loss: 0.008101749772322364, Final Batch Loss: 7.623708370374516e-05\n",
      "Epoch 332, Loss: 0.007899538239144022, Final Batch Loss: 4.914637247566134e-05\n",
      "Epoch 333, Loss: 0.0061170445715106325, Final Batch Loss: 0.000108444168290589\n",
      "Epoch 334, Loss: 0.002652755089002312, Final Batch Loss: 1.830881774367299e-05\n",
      "Epoch 335, Loss: 0.02471543390856823, Final Batch Loss: 0.0006289386074058712\n",
      "Epoch 336, Loss: 0.011180084045918193, Final Batch Loss: 0.000290254014544189\n",
      "Epoch 337, Loss: 0.03542488311086345, Final Batch Loss: 2.6341342163505033e-05\n",
      "Epoch 338, Loss: 0.009398141715792008, Final Batch Loss: 8.806844562059268e-05\n",
      "Epoch 339, Loss: 0.016649949160637334, Final Batch Loss: 0.0004074394528288394\n",
      "Epoch 340, Loss: 0.0070954995117062936, Final Batch Loss: 0.0027934054378420115\n",
      "Epoch 341, Loss: 0.05585602671999368, Final Batch Loss: 5.307748870109208e-05\n",
      "Epoch 342, Loss: 0.013522012901376002, Final Batch Loss: 0.00020259508164599538\n",
      "Epoch 343, Loss: 0.004230537600960815, Final Batch Loss: 0.0017994490917772055\n",
      "Epoch 344, Loss: 0.01782712926797103, Final Batch Loss: 0.0004777371359523386\n",
      "Epoch 345, Loss: 0.014990603707701666, Final Batch Loss: 0.0003362635616213083\n",
      "Epoch 346, Loss: 0.004131090658120229, Final Batch Loss: 0.00013446330558508635\n",
      "Epoch 347, Loss: 0.0037372002625488676, Final Batch Loss: 0.0001555553317302838\n",
      "Epoch 348, Loss: 0.0052905132088199025, Final Batch Loss: 0.002274550497531891\n",
      "Epoch 349, Loss: 0.01746135980283725, Final Batch Loss: 0.00025217808433808386\n",
      "Epoch 350, Loss: 0.019717673894774634, Final Batch Loss: 0.00017631925584282726\n",
      "Epoch 351, Loss: 0.020228544526617043, Final Batch Loss: 4.1945302655221894e-05\n",
      "Epoch 352, Loss: 0.05309452990695718, Final Batch Loss: 1.2987275113118812e-05\n",
      "Epoch 353, Loss: 0.03334485193954606, Final Batch Loss: 0.0020690227393060923\n",
      "Epoch 354, Loss: 0.011297680992356618, Final Batch Loss: 0.0010727413464337587\n",
      "Epoch 355, Loss: 0.009235931600414915, Final Batch Loss: 0.0002474863431416452\n",
      "Epoch 356, Loss: 0.010091634958371287, Final Batch Loss: 0.00017415540060028434\n",
      "Epoch 357, Loss: 0.005213419550273102, Final Batch Loss: 0.00155319320037961\n",
      "Epoch 358, Loss: 0.020150235940491257, Final Batch Loss: 0.000144507983350195\n",
      "Epoch 359, Loss: 0.014358334981807275, Final Batch Loss: 0.0017525769071653485\n",
      "Epoch 360, Loss: 0.02236024410558457, Final Batch Loss: 0.014049534685909748\n",
      "Epoch 361, Loss: 0.005936074789133272, Final Batch Loss: 0.00019413554400671273\n",
      "Epoch 362, Loss: 0.040624030314575066, Final Batch Loss: 0.00023321759363170713\n",
      "Epoch 363, Loss: 0.0037447530094141257, Final Batch Loss: 9.362116543343291e-05\n",
      "Epoch 364, Loss: 0.004446652405022178, Final Batch Loss: 0.00022677435481455177\n",
      "Epoch 365, Loss: 0.0207270437713305, Final Batch Loss: 0.00024727077106945217\n",
      "Epoch 366, Loss: 0.0025110699898505118, Final Batch Loss: 9.426363976672292e-05\n",
      "Epoch 367, Loss: 0.004031776305055246, Final Batch Loss: 9.697199857328087e-05\n",
      "Epoch 368, Loss: 0.00621037557721138, Final Batch Loss: 0.0002925352018792182\n",
      "Epoch 369, Loss: 0.010694034383050166, Final Batch Loss: 0.00021661518258042634\n",
      "Epoch 370, Loss: 0.009460666054110334, Final Batch Loss: 0.00039125882904045284\n",
      "Epoch 371, Loss: 0.005590797656623181, Final Batch Loss: 5.7833192840917036e-05\n",
      "Epoch 372, Loss: 0.005623911172733642, Final Batch Loss: 0.00013612642942462116\n",
      "Epoch 373, Loss: 0.0077230301321833394, Final Batch Loss: 7.394751446554437e-05\n",
      "Epoch 374, Loss: 0.013649503427586751, Final Batch Loss: 7.334593101404607e-05\n",
      "Epoch 375, Loss: 0.0048843608838069486, Final Batch Loss: 0.0012983049964532256\n",
      "Epoch 376, Loss: 0.00816465643219999, Final Batch Loss: 0.002161016222089529\n",
      "Epoch 377, Loss: 0.004164031590335071, Final Batch Loss: 0.00016895856242626905\n",
      "Epoch 378, Loss: 0.01369216556486208, Final Batch Loss: 0.008431795053184032\n",
      "Epoch 379, Loss: 0.0024010991328395903, Final Batch Loss: 3.351572377141565e-05\n",
      "Epoch 380, Loss: 0.015435262235769187, Final Batch Loss: 4.781329334946349e-05\n",
      "Epoch 381, Loss: 0.005164122080714151, Final Batch Loss: 7.091756742738653e-06\n",
      "Epoch 382, Loss: 0.014482448756098165, Final Batch Loss: 0.00018091029778588563\n",
      "Epoch 383, Loss: 0.006439170669182204, Final Batch Loss: 0.00016974814934656024\n",
      "Epoch 384, Loss: 0.002883587840187829, Final Batch Loss: 3.193895463482477e-05\n",
      "Epoch 385, Loss: 0.005039899157964101, Final Batch Loss: 6.10765055171214e-05\n",
      "Epoch 386, Loss: 0.006034553376593976, Final Batch Loss: 0.00013735704123973846\n",
      "Epoch 387, Loss: 0.019131980872771237, Final Batch Loss: 0.00018775707576423883\n",
      "Epoch 388, Loss: 0.028232705502887256, Final Batch Loss: 1.5274623365257867e-05\n",
      "Epoch 389, Loss: 0.06559335263409594, Final Batch Loss: 0.00047448338591493666\n",
      "Epoch 390, Loss: 0.06957355046688463, Final Batch Loss: 5.717591193388216e-05\n",
      "Epoch 391, Loss: 0.006790920204366557, Final Batch Loss: 0.001789880683645606\n",
      "Epoch 392, Loss: 0.00966930282083922, Final Batch Loss: 9.451918595004827e-05\n",
      "Epoch 393, Loss: 0.010831465006049257, Final Batch Loss: 0.000249215227086097\n",
      "Epoch 394, Loss: 0.002923153453593841, Final Batch Loss: 0.00015521590830758214\n",
      "Epoch 395, Loss: 0.005862673504452687, Final Batch Loss: 0.0009211937431246042\n",
      "Epoch 396, Loss: 0.0035828156860588933, Final Batch Loss: 0.0014091760385781527\n",
      "Epoch 397, Loss: 0.006185334910696838, Final Batch Loss: 2.6942781914840452e-05\n",
      "Epoch 398, Loss: 0.0060993052647972945, Final Batch Loss: 3.0107566999504343e-05\n",
      "Epoch 399, Loss: 0.00847934743433143, Final Batch Loss: 0.00017253508849535137\n",
      "Epoch 400, Loss: 0.007103588696736551, Final Batch Loss: 0.00024862142163328826\n",
      "Epoch 401, Loss: 0.0033758688923626323, Final Batch Loss: 3.805756205110811e-05\n",
      "Epoch 402, Loss: 0.0038305591351672774, Final Batch Loss: 0.00030939068528823555\n",
      "Epoch 403, Loss: 0.00474976381747183, Final Batch Loss: 8.765300299273804e-05\n",
      "Epoch 404, Loss: 0.006416648471713415, Final Batch Loss: 0.00029137308592908084\n",
      "Epoch 405, Loss: 0.0024848361281328835, Final Batch Loss: 8.065050496952608e-05\n",
      "Epoch 406, Loss: 0.0032345224208256695, Final Batch Loss: 0.0008410715963691473\n",
      "Epoch 407, Loss: 0.0037440794608301076, Final Batch Loss: 7.602079222124303e-06\n",
      "Epoch 408, Loss: 0.008391278970520943, Final Batch Loss: 0.00019663067359942943\n",
      "Epoch 409, Loss: 0.0036170627654428245, Final Batch Loss: 2.6596932002576068e-05\n",
      "Epoch 410, Loss: 0.013631264333525905, Final Batch Loss: 4.448864274309017e-05\n",
      "Epoch 411, Loss: 0.016404474568844307, Final Batch Loss: 7.403281779261306e-05\n",
      "Epoch 412, Loss: 0.0012095734655304113, Final Batch Loss: 0.00011040354729630053\n",
      "Epoch 413, Loss: 0.011041650267543446, Final Batch Loss: 8.160100696841255e-05\n",
      "Epoch 414, Loss: 0.0012022430291835917, Final Batch Loss: 3.7737572711193934e-05\n",
      "Epoch 415, Loss: 0.011884597015523468, Final Batch Loss: 0.0001601153053343296\n",
      "Epoch 416, Loss: 0.003829502877124469, Final Batch Loss: 5.687791417585686e-05\n",
      "Epoch 417, Loss: 0.02702439891800168, Final Batch Loss: 0.00016424298519268632\n",
      "Epoch 418, Loss: 0.011774996672102134, Final Batch Loss: 4.465701204026118e-05\n",
      "Epoch 419, Loss: 0.002723846370827232, Final Batch Loss: 0.00030305198743008077\n",
      "Epoch 420, Loss: 0.019223870447603986, Final Batch Loss: 0.011817359365522861\n",
      "Epoch 421, Loss: 0.0036867665403406136, Final Batch Loss: 4.37382077507209e-05\n",
      "Epoch 422, Loss: 0.014095658993028337, Final Batch Loss: 0.006469287443906069\n",
      "Epoch 423, Loss: 0.0025530479579174425, Final Batch Loss: 8.254968270193785e-05\n",
      "Epoch 424, Loss: 0.014023140611243434, Final Batch Loss: 2.4890485292416997e-05\n",
      "Epoch 425, Loss: 0.03996284793493032, Final Batch Loss: 3.576204471755773e-05\n",
      "Epoch 426, Loss: 0.006044675918019493, Final Batch Loss: 3.616263347794302e-05\n",
      "Epoch 427, Loss: 0.06437852740964445, Final Batch Loss: 1.4828345229034312e-05\n",
      "Epoch 428, Loss: 0.06050539533043775, Final Batch Loss: 8.584275201428682e-05\n",
      "Epoch 429, Loss: 0.021066320605314104, Final Batch Loss: 7.933487358968705e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430, Loss: 0.004111970842131996, Final Batch Loss: 9.834458614932373e-05\n",
      "Epoch 431, Loss: 0.07316562936830451, Final Batch Loss: 3.462108361418359e-05\n",
      "Epoch 432, Loss: 0.004983006681868574, Final Batch Loss: 6.086334542487748e-05\n",
      "Epoch 433, Loss: 0.020011154487292515, Final Batch Loss: 2.1577779989456758e-05\n",
      "Epoch 434, Loss: 0.01712274690362392, Final Batch Loss: 0.00014597835252061486\n",
      "Epoch 435, Loss: 0.040843134080205346, Final Batch Loss: 0.0011628447100520134\n",
      "Epoch 436, Loss: 0.021764930332210497, Final Batch Loss: 0.00031583907548338175\n",
      "Epoch 437, Loss: 0.018619628026499413, Final Batch Loss: 9.774167847353965e-05\n",
      "Epoch 438, Loss: 0.007995945212314837, Final Batch Loss: 9.452590893488377e-05\n",
      "Epoch 439, Loss: 0.004320740448747529, Final Batch Loss: 4.926519250147976e-05\n",
      "Epoch 440, Loss: 0.006111536822572816, Final Batch Loss: 0.0010626360308378935\n",
      "Epoch 441, Loss: 0.01693783312657615, Final Batch Loss: 0.0010266026947647333\n",
      "Epoch 442, Loss: 0.007021899798473896, Final Batch Loss: 5.217228681431152e-05\n",
      "Epoch 443, Loss: 0.0032664954451320227, Final Batch Loss: 0.0002179232833441347\n",
      "Epoch 444, Loss: 0.013924530667281942, Final Batch Loss: 6.150437548058107e-05\n",
      "Epoch 445, Loss: 0.006735169321473222, Final Batch Loss: 0.00015077168063726276\n",
      "Epoch 446, Loss: 0.024228041885180573, Final Batch Loss: 8.680429891683161e-05\n",
      "Epoch 447, Loss: 0.006219341448741034, Final Batch Loss: 0.0001457872858736664\n",
      "Epoch 448, Loss: 0.006222624968359014, Final Batch Loss: 0.002670661313459277\n",
      "Epoch 449, Loss: 0.006692573570035165, Final Batch Loss: 0.00025039745378308\n",
      "Epoch 450, Loss: 0.0018596268419059925, Final Batch Loss: 0.00014788845146540552\n",
      "Epoch 451, Loss: 0.004551272239041282, Final Batch Loss: 0.001352556748315692\n",
      "Epoch 452, Loss: 0.014738773192220833, Final Batch Loss: 0.00014055772044230253\n",
      "Epoch 453, Loss: 0.007264492895046715, Final Batch Loss: 0.00011341249773977324\n",
      "Epoch 454, Loss: 0.0038566759667446604, Final Batch Loss: 1.060888189385878e-05\n",
      "Epoch 455, Loss: 0.005619493109406903, Final Batch Loss: 1.6934573068283498e-05\n",
      "Epoch 456, Loss: 0.002136382946446247, Final Batch Loss: 1.0266831850458402e-05\n",
      "Epoch 457, Loss: 0.001224978740538063, Final Batch Loss: 7.823273335816339e-05\n",
      "Epoch 458, Loss: 0.009008061493659625, Final Batch Loss: 3.162262510159053e-05\n",
      "Epoch 459, Loss: 0.001790229450307379, Final Batch Loss: 4.178689050604589e-05\n",
      "Epoch 460, Loss: 0.03481910506252461, Final Batch Loss: 0.001250068424269557\n",
      "Epoch 461, Loss: 0.025487014718237333, Final Batch Loss: 0.00015791998885106295\n",
      "Epoch 462, Loss: 0.004370499289507279, Final Batch Loss: 2.0877398128504865e-05\n",
      "Epoch 463, Loss: 0.0063842504455351445, Final Batch Loss: 0.000776752654928714\n",
      "Epoch 464, Loss: 0.009336547821021668, Final Batch Loss: 0.00010994217154802755\n",
      "Epoch 465, Loss: 0.00310218839058507, Final Batch Loss: 0.00011228924267925322\n",
      "Epoch 466, Loss: 0.007443331270224007, Final Batch Loss: 2.630537528602872e-05\n",
      "Epoch 467, Loss: 0.015539980804533116, Final Batch Loss: 7.94101069914177e-05\n",
      "Epoch 468, Loss: 0.026959460265061352, Final Batch Loss: 0.00014868991274852306\n",
      "Epoch 469, Loss: 0.058190719197227736, Final Batch Loss: 7.431769336108118e-05\n",
      "Epoch 470, Loss: 0.005859494634933071, Final Batch Loss: 0.00014791825378779322\n",
      "Epoch 471, Loss: 0.03406262311182218, Final Batch Loss: 0.02207128144800663\n",
      "Epoch 472, Loss: 0.0044908681920787785, Final Batch Loss: 0.0006221838993951678\n",
      "Epoch 473, Loss: 0.0028052566485712305, Final Batch Loss: 0.0010525505058467388\n",
      "Epoch 474, Loss: 0.0038830940966363414, Final Batch Loss: 0.001000342657789588\n",
      "Epoch 475, Loss: 0.00751334728920483, Final Batch Loss: 0.00048430802416987717\n",
      "Epoch 476, Loss: 0.0027664991284837015, Final Batch Loss: 0.00047996704233810306\n",
      "Epoch 477, Loss: 0.04424036174532375, Final Batch Loss: 0.0010417202720418572\n",
      "Epoch 478, Loss: 0.004900534322587191, Final Batch Loss: 0.0001772604591678828\n",
      "Epoch 479, Loss: 0.00621870725080953, Final Batch Loss: 0.0003569900873117149\n",
      "Epoch 480, Loss: 0.005363276866773958, Final Batch Loss: 0.002450463594868779\n",
      "Epoch 481, Loss: 0.041480680210952414, Final Batch Loss: 0.0002991751243826002\n",
      "Epoch 482, Loss: 0.011444784206105396, Final Batch Loss: 0.0003362691786605865\n",
      "Epoch 483, Loss: 0.004560513570140756, Final Batch Loss: 2.5312081561423838e-05\n",
      "Epoch 484, Loss: 0.0028107146918046055, Final Batch Loss: 9.077863796846941e-05\n",
      "Epoch 485, Loss: 0.0045101804371370235, Final Batch Loss: 2.4617538656457327e-05\n",
      "Epoch 486, Loss: 0.008658237609779462, Final Batch Loss: 1.8910610378952697e-05\n",
      "Epoch 487, Loss: 0.00775079687446123, Final Batch Loss: 0.0003858611744362861\n",
      "Epoch 488, Loss: 0.003583081139368005, Final Batch Loss: 0.0009914083639159799\n",
      "Epoch 489, Loss: 0.01605652893158549, Final Batch Loss: 0.00031074663274921477\n",
      "Epoch 490, Loss: 0.007127407672669506, Final Batch Loss: 0.00036044602165929973\n",
      "Epoch 491, Loss: 0.0072997921670321375, Final Batch Loss: 2.296972888871096e-05\n",
      "Epoch 492, Loss: 0.001308126149524469, Final Batch Loss: 0.00010255537927150726\n",
      "Epoch 493, Loss: 0.0012961025295226136, Final Batch Loss: 0.0001432028948329389\n",
      "Epoch 494, Loss: 0.009856606403900514, Final Batch Loss: 6.351109914248809e-05\n",
      "Epoch 495, Loss: 0.0033770009358704556, Final Batch Loss: 5.106029493617825e-05\n",
      "Epoch 496, Loss: 0.0012118744862164021, Final Batch Loss: 3.737486258614808e-05\n",
      "Epoch 497, Loss: 0.002324264488379413, Final Batch Loss: 0.0010275347158312798\n",
      "Epoch 498, Loss: 0.0020152249599050265, Final Batch Loss: 7.846599328331649e-05\n",
      "Epoch 499, Loss: 0.03453984495718032, Final Batch Loss: 5.71840355405584e-05\n",
      "Epoch 500, Loss: 0.003632801331605151, Final Batch Loss: 0.0005252973060123622\n",
      "Epoch 501, Loss: 0.028310334269008308, Final Batch Loss: 3.517882214509882e-05\n",
      "Epoch 502, Loss: 0.004127313797653187, Final Batch Loss: 1.622309173399117e-05\n",
      "Epoch 503, Loss: 0.0026012053649537847, Final Batch Loss: 2.260015571664553e-05\n",
      "Epoch 504, Loss: 0.01968485413453891, Final Batch Loss: 4.310497752157971e-05\n",
      "Epoch 505, Loss: 0.009495488992797618, Final Batch Loss: 0.00014244593330658972\n",
      "Epoch 506, Loss: 0.002115852738825197, Final Batch Loss: 3.2432788430014625e-05\n",
      "Epoch 507, Loss: 0.0014338955170387635, Final Batch Loss: 1.6128185961861163e-05\n",
      "Epoch 508, Loss: 0.0010119024227606133, Final Batch Loss: 7.167137664509937e-05\n",
      "Epoch 509, Loss: 0.0022825360561000707, Final Batch Loss: 1.2006053111690562e-05\n",
      "Epoch 510, Loss: 0.007104983053068281, Final Batch Loss: 5.467671871883795e-05\n",
      "Epoch 511, Loss: 0.010717298511735862, Final Batch Loss: 0.005429607350379229\n",
      "Epoch 512, Loss: 0.002260764644233859, Final Batch Loss: 2.1165984435356222e-05\n",
      "Epoch 513, Loss: 0.002855254257156048, Final Batch Loss: 0.00010077545448439196\n",
      "Epoch 514, Loss: 0.0010307446545994026, Final Batch Loss: 8.172632988134865e-06\n",
      "Epoch 515, Loss: 0.0012080183241778286, Final Batch Loss: 4.175270805717446e-05\n",
      "Epoch 516, Loss: 0.003084730105001654, Final Batch Loss: 1.6257177776424214e-05\n",
      "Epoch 517, Loss: 0.0011107523478131043, Final Batch Loss: 0.00016300480638165027\n",
      "Epoch 518, Loss: 0.005044767729486921, Final Batch Loss: 0.00125365168787539\n",
      "Epoch 519, Loss: 0.0010326764358978835, Final Batch Loss: 6.02318141318392e-05\n",
      "Epoch 520, Loss: 0.004582343183756166, Final Batch Loss: 1.2578778296301607e-05\n",
      "Epoch 521, Loss: 0.005122957878484158, Final Batch Loss: 4.9321064579999074e-05\n",
      "Epoch 522, Loss: 0.0006564123987118364, Final Batch Loss: 0.00012574730499181896\n",
      "Epoch 523, Loss: 0.002139345128853165, Final Batch Loss: 5.111852260597516e-06\n",
      "Epoch 524, Loss: 0.009554290216328809, Final Batch Loss: 9.702564966573846e-06\n",
      "Epoch 525, Loss: 0.028626468279298933, Final Batch Loss: 0.00023791026615072042\n",
      "Epoch 526, Loss: 0.002054551162473217, Final Batch Loss: 1.4094754078541882e-05\n",
      "Epoch 527, Loss: 0.0034385726185064414, Final Batch Loss: 1.5169187463470735e-05\n",
      "Epoch 528, Loss: 0.01600570193591011, Final Batch Loss: 0.013949599117040634\n",
      "Epoch 529, Loss: 0.0018809269886332913, Final Batch Loss: 0.0002678399032447487\n",
      "Epoch 530, Loss: 0.006114466345479741, Final Batch Loss: 0.0004226158489473164\n",
      "Epoch 531, Loss: 0.0022161354422678414, Final Batch Loss: 1.8278185962117277e-05\n",
      "Epoch 532, Loss: 0.0016250778327275839, Final Batch Loss: 1.1346836799930315e-05\n",
      "Epoch 533, Loss: 0.0037233996799841407, Final Batch Loss: 1.2577224879350979e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534, Loss: 0.002053871565294685, Final Batch Loss: 2.9673254175577313e-05\n",
      "Epoch 535, Loss: 0.0016002375850803219, Final Batch Loss: 1.455343772249762e-05\n",
      "Epoch 536, Loss: 0.0020557934449243476, Final Batch Loss: 1.4286422810982913e-05\n",
      "Epoch 537, Loss: 0.0022426837149396306, Final Batch Loss: 0.0005704755312763155\n",
      "Epoch 538, Loss: 0.006695889589536819, Final Batch Loss: 2.6308405722375028e-05\n",
      "Epoch 539, Loss: 0.0017546120400311338, Final Batch Loss: 0.0006666793487966061\n",
      "Epoch 540, Loss: 0.0029429137812257977, Final Batch Loss: 2.7534420951269567e-05\n",
      "Epoch 541, Loss: 0.007721273064817069, Final Batch Loss: 0.0002565902832429856\n",
      "Epoch 542, Loss: 0.0024301282887790876, Final Batch Loss: 1.8187979549111333e-06\n",
      "Epoch 543, Loss: 0.003751150629341282, Final Batch Loss: 2.770805986074265e-05\n",
      "Epoch 544, Loss: 0.0212691572728545, Final Batch Loss: 5.1508537580957636e-05\n",
      "Epoch 545, Loss: 0.0239349715593562, Final Batch Loss: 9.880879952106625e-05\n",
      "Epoch 546, Loss: 0.004087485664967971, Final Batch Loss: 0.0008407639688812196\n",
      "Epoch 547, Loss: 0.004479961148717848, Final Batch Loss: 0.000734300643671304\n",
      "Epoch 548, Loss: 0.006436705613623417, Final Batch Loss: 6.286479765549302e-05\n",
      "Epoch 549, Loss: 0.0012987714326300193, Final Batch Loss: 4.696138421422802e-05\n",
      "Epoch 550, Loss: 0.0009125705664700945, Final Batch Loss: 3.197979458491318e-05\n",
      "Epoch 551, Loss: 0.004657822540139023, Final Batch Loss: 0.00010374864359619096\n",
      "Epoch 552, Loss: 0.022613564799030428, Final Batch Loss: 1.800593781808857e-05\n",
      "Epoch 553, Loss: 0.011745605556825467, Final Batch Loss: 1.8363884009886533e-05\n",
      "Epoch 554, Loss: 0.012191156893095467, Final Batch Loss: 0.00011127621110063046\n",
      "Epoch 555, Loss: 0.04741812433621817, Final Batch Loss: 6.487123027909547e-05\n",
      "Epoch 556, Loss: 0.016605515426817874, Final Batch Loss: 0.0003352072089910507\n",
      "Epoch 557, Loss: 0.0156524004523817, Final Batch Loss: 0.0005871184985153377\n",
      "Epoch 558, Loss: 0.025004134238770348, Final Batch Loss: 0.0001151533069787547\n",
      "Epoch 559, Loss: 0.027857722475346236, Final Batch Loss: 0.0007495998870581388\n",
      "Epoch 560, Loss: 0.05330482514182222, Final Batch Loss: 0.028079450130462646\n",
      "Epoch 561, Loss: 0.00939160300004005, Final Batch Loss: 0.0008779021445661783\n",
      "Epoch 562, Loss: 0.003653307285730989, Final Batch Loss: 0.00034863478504121304\n",
      "Epoch 563, Loss: 0.011631940397819562, Final Batch Loss: 0.0009982890915125608\n",
      "Epoch 564, Loss: 0.006819652660851716, Final Batch Loss: 0.0002111617650371045\n",
      "Epoch 565, Loss: 0.003984630586273852, Final Batch Loss: 0.0002720919146668166\n",
      "Epoch 566, Loss: 0.0006827171391705633, Final Batch Loss: 2.2625310521107167e-05\n",
      "Epoch 567, Loss: 0.004397654256536043, Final Batch Loss: 0.0003324915887787938\n",
      "Epoch 568, Loss: 0.0023499775234085973, Final Batch Loss: 3.0091983717284165e-05\n",
      "Epoch 569, Loss: 0.02078021363922744, Final Batch Loss: 0.00019810127560049295\n",
      "Epoch 570, Loss: 0.019387534881389, Final Batch Loss: 0.002192846732214093\n",
      "Epoch 571, Loss: 0.003449929856287781, Final Batch Loss: 3.237269265810028e-05\n",
      "Epoch 572, Loss: 0.005680765085799067, Final Batch Loss: 0.000125439022667706\n",
      "Epoch 573, Loss: 0.004439916563114821, Final Batch Loss: 1.768693073245231e-05\n",
      "Epoch 574, Loss: 0.02659344995754509, Final Batch Loss: 7.525163528043777e-05\n",
      "Epoch 575, Loss: 0.006203360750077991, Final Batch Loss: 1.3693032087758183e-05\n",
      "Epoch 576, Loss: 0.0018702559245866723, Final Batch Loss: 1.1299360267003067e-05\n",
      "Epoch 577, Loss: 0.0012929247386637144, Final Batch Loss: 8.643031469546258e-05\n",
      "Epoch 578, Loss: 0.01808533704661386, Final Batch Loss: 4.002013156423345e-05\n",
      "Epoch 579, Loss: 0.031097851546292077, Final Batch Loss: 9.320683602709323e-05\n",
      "Epoch 580, Loss: 0.0015491306312469533, Final Batch Loss: 6.769359606551006e-05\n",
      "Epoch 581, Loss: 0.026541286049905466, Final Batch Loss: 0.00018258810450788587\n",
      "Epoch 582, Loss: 0.003511238925057114, Final Batch Loss: 0.00021216023014858365\n",
      "Epoch 583, Loss: 0.003831741780231823, Final Batch Loss: 7.70098777138628e-05\n",
      "Epoch 584, Loss: 0.005613632456515916, Final Batch Loss: 0.0019168430007994175\n",
      "Epoch 585, Loss: 0.0018326364015592844, Final Batch Loss: 4.531949161901139e-05\n",
      "Epoch 586, Loss: 0.001546680601677508, Final Batch Loss: 9.798467544896994e-06\n",
      "Epoch 587, Loss: 0.0010340149074181681, Final Batch Loss: 3.994328289991245e-05\n",
      "Epoch 588, Loss: 0.0031885042517387774, Final Batch Loss: 6.984807987464592e-05\n",
      "Epoch 589, Loss: 0.0018279964260727866, Final Batch Loss: 1.795152093109209e-05\n",
      "Epoch 590, Loss: 0.0015275333091722132, Final Batch Loss: 1.0531072803132702e-05\n",
      "Epoch 591, Loss: 0.0021106361818965524, Final Batch Loss: 0.00019399555458221585\n",
      "Epoch 592, Loss: 0.0013070453842374263, Final Batch Loss: 6.728339212713763e-05\n",
      "Epoch 593, Loss: 0.0012214029084134381, Final Batch Loss: 0.00036569504300132394\n",
      "Epoch 594, Loss: 0.002647031510036868, Final Batch Loss: 3.015440597664565e-05\n",
      "Epoch 595, Loss: 0.0019582010681915563, Final Batch Loss: 5.950328704784624e-05\n",
      "Epoch 596, Loss: 0.0017529743181512458, Final Batch Loss: 0.00019493736908771098\n",
      "Epoch 597, Loss: 0.003379586037908666, Final Batch Loss: 2.008047522394918e-05\n",
      "Epoch 598, Loss: 0.004339783928116958, Final Batch Loss: 9.391562343807891e-06\n",
      "Epoch 599, Loss: 0.0015585893875140755, Final Batch Loss: 0.00020133840735070407\n",
      "Epoch 600, Loss: 0.0014374565589605481, Final Batch Loss: 3.10965915559791e-05\n",
      "Epoch 601, Loss: 0.004537847835536013, Final Batch Loss: 6.585015944438055e-05\n",
      "Epoch 602, Loss: 0.0035821249866785365, Final Batch Loss: 7.799847480782773e-06\n",
      "Epoch 603, Loss: 0.0017738411561367684, Final Batch Loss: 1.3819940249959473e-05\n",
      "Epoch 604, Loss: 0.00044031209608874633, Final Batch Loss: 1.8568038285593502e-05\n",
      "Epoch 605, Loss: 0.0007024096744316921, Final Batch Loss: 4.376330252853222e-06\n",
      "Epoch 606, Loss: 0.028473210524680326, Final Batch Loss: 2.002916744459071e-06\n",
      "Epoch 607, Loss: 0.004554010018182453, Final Batch Loss: 6.276094791246578e-05\n",
      "Epoch 608, Loss: 0.005695961530477689, Final Batch Loss: 0.00014497163647320122\n",
      "Epoch 609, Loss: 0.0028222373962307756, Final Batch Loss: 0.00013367077917791903\n",
      "Epoch 610, Loss: 0.0016233120613833307, Final Batch Loss: 5.406420677900314e-05\n",
      "Epoch 611, Loss: 0.001372486228319758, Final Batch Loss: 1.760199484124314e-05\n",
      "Epoch 612, Loss: 0.00530476193944196, Final Batch Loss: 0.00011063483543694019\n",
      "Epoch 613, Loss: 0.003949272518639191, Final Batch Loss: 0.0006620108615607023\n",
      "Epoch 614, Loss: 0.004134521421065074, Final Batch Loss: 1.5273602912202477e-05\n",
      "Epoch 615, Loss: 0.0018323885733479983, Final Batch Loss: 0.0001210801929119043\n",
      "Epoch 616, Loss: 0.0018421091032223558, Final Batch Loss: 3.5935474897996755e-06\n",
      "Epoch 617, Loss: 0.0013922732296123286, Final Batch Loss: 7.424497744068503e-05\n",
      "Epoch 618, Loss: 0.04093379738856129, Final Batch Loss: 0.03866179287433624\n",
      "Epoch 619, Loss: 0.02827723493942358, Final Batch Loss: 0.0003541152400430292\n",
      "Epoch 620, Loss: 0.052906161518876615, Final Batch Loss: 8.119512494886294e-05\n",
      "Epoch 621, Loss: 0.0016106780822155997, Final Batch Loss: 1.110310222429689e-05\n",
      "Epoch 622, Loss: 0.00881253271290916, Final Batch Loss: 0.000152180582517758\n",
      "Epoch 623, Loss: 0.0035741486644838005, Final Batch Loss: 0.00032857010955922306\n",
      "Epoch 624, Loss: 0.026934369907394284, Final Batch Loss: 0.0007982582319527864\n",
      "Epoch 625, Loss: 0.003275081663559831, Final Batch Loss: 1.0279190064466093e-05\n",
      "Epoch 626, Loss: 0.0028659854742727475, Final Batch Loss: 1.99281275854446e-05\n",
      "Epoch 627, Loss: 0.010598877242955496, Final Batch Loss: 0.0009493482648395002\n",
      "Epoch 628, Loss: 0.0026101613802893553, Final Batch Loss: 0.0009698218782432377\n",
      "Epoch 629, Loss: 0.004665060603656457, Final Batch Loss: 0.0017864529509097338\n",
      "Epoch 630, Loss: 0.004507591888796014, Final Batch Loss: 9.019282151712105e-05\n",
      "Epoch 631, Loss: 0.005679846211023687, Final Batch Loss: 0.00010190906323259696\n",
      "Epoch 632, Loss: 0.008976888915640302, Final Batch Loss: 1.2413152944645844e-05\n",
      "Epoch 633, Loss: 0.0013414558522981679, Final Batch Loss: 4.228302714182064e-05\n",
      "Epoch 634, Loss: 0.005106244724629505, Final Batch Loss: 0.001053026644513011\n",
      "Epoch 635, Loss: 0.0024459771898364124, Final Batch Loss: 1.2999073987884913e-05\n",
      "Epoch 636, Loss: 0.003368654039604735, Final Batch Loss: 2.053659045486711e-05\n",
      "Epoch 637, Loss: 0.002065449060864921, Final Batch Loss: 7.521390216425061e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638, Loss: 0.0012940576089022215, Final Batch Loss: 1.2437192708603106e-05\n",
      "Epoch 639, Loss: 0.0012731170099868905, Final Batch Loss: 0.00011660544987535104\n",
      "Epoch 640, Loss: 0.0014233552683435846, Final Batch Loss: 3.291209213784896e-05\n",
      "Epoch 641, Loss: 0.0016947570161391923, Final Batch Loss: 5.992226306261728e-06\n",
      "Epoch 642, Loss: 0.0010633602687448729, Final Batch Loss: 2.6852447263081558e-05\n",
      "Epoch 643, Loss: 0.001501050655861036, Final Batch Loss: 0.00011730505502782762\n",
      "Epoch 644, Loss: 0.0332762751691007, Final Batch Loss: 0.028044652193784714\n",
      "Epoch 645, Loss: 0.018208739039437205, Final Batch Loss: 6.37470802757889e-05\n",
      "Epoch 646, Loss: 0.0018342863859288627, Final Batch Loss: 2.20112269744277e-05\n",
      "Epoch 647, Loss: 0.028227612456248607, Final Batch Loss: 1.706674083834514e-05\n",
      "Epoch 648, Loss: 0.01622894996944524, Final Batch Loss: 8.931701449910179e-05\n",
      "Epoch 649, Loss: 0.014459610047197202, Final Batch Loss: 0.0018158209277316928\n",
      "Epoch 650, Loss: 0.01341781324117619, Final Batch Loss: 7.167102739913389e-05\n",
      "Epoch 651, Loss: 0.004236576217408583, Final Batch Loss: 0.00021403557911980897\n",
      "Epoch 652, Loss: 0.001150582423179003, Final Batch Loss: 2.25253970711492e-05\n",
      "Epoch 653, Loss: 0.001257004808394413, Final Batch Loss: 0.0004024349618703127\n",
      "Epoch 654, Loss: 0.004544251556581003, Final Batch Loss: 0.0025662656407803297\n",
      "Epoch 655, Loss: 0.0013452788507493096, Final Batch Loss: 2.9417076802928932e-05\n",
      "Epoch 656, Loss: 0.004779322713147849, Final Batch Loss: 9.015340765472502e-05\n",
      "Epoch 657, Loss: 0.0028734623065247433, Final Batch Loss: 6.678554655081825e-06\n",
      "Epoch 658, Loss: 0.0022383991617971333, Final Batch Loss: 3.6589121009455994e-05\n",
      "Epoch 659, Loss: 0.03665135561641364, Final Batch Loss: 0.00031428580405190587\n",
      "Epoch 660, Loss: 0.005274459115753416, Final Batch Loss: 0.00012121420149924234\n",
      "Epoch 661, Loss: 0.0014473569444817258, Final Batch Loss: 0.00012118051381548867\n",
      "Epoch 662, Loss: 0.003729623455001274, Final Batch Loss: 2.197880166932009e-05\n",
      "Epoch 663, Loss: 0.0006935783703738707, Final Batch Loss: 6.47809574729763e-05\n",
      "Epoch 664, Loss: 0.0010427752354189579, Final Batch Loss: 0.00010601667599985376\n",
      "Epoch 665, Loss: 0.0005301677269926586, Final Batch Loss: 8.802316733635962e-05\n",
      "Epoch 666, Loss: 0.0062837016748744645, Final Batch Loss: 3.6911576899001375e-05\n",
      "Epoch 667, Loss: 0.007717867120845767, Final Batch Loss: 6.082288746256381e-05\n",
      "Epoch 668, Loss: 0.0016626650831312872, Final Batch Loss: 1.0109194590768311e-05\n",
      "Epoch 669, Loss: 0.01651205923553789, Final Batch Loss: 8.661020547151566e-05\n",
      "Epoch 670, Loss: 0.010281845708504989, Final Batch Loss: 4.152601377427345e-06\n",
      "Epoch 671, Loss: 0.0078801227364238, Final Batch Loss: 9.80363165581366e-06\n",
      "Epoch 672, Loss: 0.005368969013034075, Final Batch Loss: 3.064414704567753e-05\n",
      "Epoch 673, Loss: 0.039237655650595116, Final Batch Loss: 0.02274080365896225\n",
      "Epoch 674, Loss: 0.027452596861621714, Final Batch Loss: 2.2864307538839057e-05\n",
      "Epoch 675, Loss: 0.004889105794063653, Final Batch Loss: 1.0109278264280874e-05\n",
      "Epoch 676, Loss: 0.012747896693781513, Final Batch Loss: 0.01103467307984829\n",
      "Epoch 677, Loss: 0.00973749144031899, Final Batch Loss: 3.049406768695917e-05\n",
      "Epoch 678, Loss: 0.018373879729551845, Final Batch Loss: 0.0023712562397122383\n",
      "Epoch 679, Loss: 0.003822660730293137, Final Batch Loss: 1.3770095392828807e-05\n",
      "Epoch 680, Loss: 0.022248571993259247, Final Batch Loss: 7.039585034362972e-05\n",
      "Epoch 681, Loss: 0.006388518671883503, Final Batch Loss: 0.0005359097267501056\n",
      "Epoch 682, Loss: 0.0024137377167789964, Final Batch Loss: 8.284732030006126e-05\n",
      "Epoch 683, Loss: 0.006393302703145309, Final Batch Loss: 2.039272294496186e-05\n",
      "Epoch 684, Loss: 0.00250180477178219, Final Batch Loss: 4.4599175453186035e-05\n",
      "Epoch 685, Loss: 0.03771718654661527, Final Batch Loss: 0.0004834023129660636\n",
      "Epoch 686, Loss: 0.0016611565924904426, Final Batch Loss: 4.397297743707895e-05\n",
      "Epoch 687, Loss: 0.026155151444072544, Final Batch Loss: 0.00020090870384592563\n",
      "Epoch 688, Loss: 0.004005401657195762, Final Batch Loss: 0.00020045765268150717\n",
      "Epoch 689, Loss: 0.002943202587630367, Final Batch Loss: 0.00010065858077723533\n",
      "Epoch 690, Loss: 0.005729653385060374, Final Batch Loss: 4.005480514024384e-05\n",
      "Epoch 691, Loss: 0.0073997985491587315, Final Batch Loss: 0.001137532526627183\n",
      "Epoch 692, Loss: 0.00214964597580547, Final Batch Loss: 5.903648343519308e-05\n",
      "Epoch 693, Loss: 0.002130076642060885, Final Batch Loss: 1.993337536987383e-05\n",
      "Epoch 694, Loss: 0.0012528665233730862, Final Batch Loss: 0.00010786019265651703\n",
      "Epoch 695, Loss: 0.0011560623265722825, Final Batch Loss: 4.16122711612843e-05\n",
      "Epoch 696, Loss: 0.0018313037303414603, Final Batch Loss: 0.0003935420827474445\n",
      "Epoch 697, Loss: 0.0008553254374419339, Final Batch Loss: 0.0002752568107098341\n",
      "Epoch 698, Loss: 0.17416922723759853, Final Batch Loss: 4.576646097120829e-05\n",
      "Epoch 699, Loss: 0.005089347436296521, Final Batch Loss: 0.0007672239444218576\n",
      "Epoch 700, Loss: 0.003236842658225214, Final Batch Loss: 0.00010230163752567023\n",
      "Epoch 701, Loss: 0.004157855833909707, Final Batch Loss: 0.0001470061979489401\n",
      "Epoch 702, Loss: 0.0018253355683555128, Final Batch Loss: 5.550483547267504e-05\n",
      "Epoch 703, Loss: 0.0015869189792283578, Final Batch Loss: 1.9358358258614317e-05\n",
      "Epoch 704, Loss: 0.0014628043909397093, Final Batch Loss: 2.6064542907988653e-05\n",
      "Epoch 705, Loss: 0.0011802728213297087, Final Batch Loss: 1.1819352039310616e-05\n",
      "Epoch 706, Loss: 0.0015304624967029667, Final Batch Loss: 4.166727376286872e-05\n",
      "Epoch 707, Loss: 0.0020170204088572063, Final Batch Loss: 4.350087692728266e-05\n",
      "Epoch 708, Loss: 0.0038485519999085227, Final Batch Loss: 0.00010872070561163127\n",
      "Epoch 709, Loss: 0.0005797525591333397, Final Batch Loss: 2.2996135157882236e-05\n",
      "Epoch 710, Loss: 0.0027424730151324184, Final Batch Loss: 3.6577748687705025e-05\n",
      "Epoch 711, Loss: 0.0011467484928289196, Final Batch Loss: 0.00011807430564658716\n",
      "Epoch 712, Loss: 0.0015448660114998347, Final Batch Loss: 2.1880821805098094e-05\n",
      "Epoch 713, Loss: 0.011997948679436377, Final Batch Loss: 3.528021989041008e-05\n",
      "Epoch 714, Loss: 0.021075530652751695, Final Batch Loss: 3.76638649868255e-06\n",
      "Epoch 715, Loss: 0.005398572684498504, Final Batch Loss: 3.3985357731580734e-05\n",
      "Epoch 716, Loss: 0.004263987979356898, Final Batch Loss: 7.192391058197245e-05\n",
      "Epoch 717, Loss: 0.0069947633128322195, Final Batch Loss: 0.00036310034920461476\n",
      "Epoch 718, Loss: 0.05509954004719475, Final Batch Loss: 2.848476833605673e-05\n",
      "Epoch 719, Loss: 0.06764669573112769, Final Batch Loss: 0.03355921059846878\n",
      "Epoch 720, Loss: 0.005313235672474548, Final Batch Loss: 0.0005368225974962115\n",
      "Epoch 721, Loss: 0.0015842041248106398, Final Batch Loss: 8.353313023690134e-05\n",
      "Epoch 722, Loss: 0.016981771874270635, Final Batch Loss: 0.00011596363765420392\n",
      "Epoch 723, Loss: 0.020332132256953628, Final Batch Loss: 8.017696382012218e-05\n",
      "Epoch 724, Loss: 0.001480331151469727, Final Batch Loss: 5.2352759666973725e-05\n",
      "Epoch 725, Loss: 0.0021370132744777948, Final Batch Loss: 2.5738183467183262e-05\n",
      "Epoch 726, Loss: 0.0026880628247454297, Final Batch Loss: 5.5891581723699346e-05\n",
      "Epoch 727, Loss: 0.004047553341933963, Final Batch Loss: 0.0008952204370871186\n",
      "Epoch 728, Loss: 0.002035300856732647, Final Batch Loss: 2.527555261622183e-05\n",
      "Epoch 729, Loss: 0.0033637921551417094, Final Batch Loss: 9.279820369556546e-05\n",
      "Epoch 730, Loss: 0.002638486492287484, Final Batch Loss: 1.721904664009344e-05\n",
      "Epoch 731, Loss: 0.0033525110593473073, Final Batch Loss: 0.0027803280390799046\n",
      "Epoch 732, Loss: 0.0019505493582983036, Final Batch Loss: 3.9288512198254466e-05\n",
      "Epoch 733, Loss: 0.0009981036973840673, Final Batch Loss: 0.00016575987683609128\n",
      "Epoch 734, Loss: 0.0013994043820275692, Final Batch Loss: 2.2228749003261328e-05\n",
      "Epoch 735, Loss: 0.0007822564057278214, Final Batch Loss: 1.6414496712968685e-05\n",
      "Epoch 736, Loss: 0.0013433528865789413, Final Batch Loss: 0.0001491508592152968\n",
      "Epoch 737, Loss: 0.0008475294089294039, Final Batch Loss: 5.280029654386453e-05\n",
      "Epoch 738, Loss: 0.02633497060924128, Final Batch Loss: 0.00018033559899777174\n",
      "Epoch 739, Loss: 0.020847543388299528, Final Batch Loss: 2.0518453311524354e-05\n",
      "Epoch 740, Loss: 0.004479657369302004, Final Batch Loss: 0.0017528848256915808\n",
      "Epoch 741, Loss: 0.003334202352561988, Final Batch Loss: 0.00039305875543504953\n",
      "Epoch 742, Loss: 0.000683262946040486, Final Batch Loss: 9.556968871038407e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743, Loss: 0.0024083324515231652, Final Batch Loss: 2.119165401381906e-05\n",
      "Epoch 744, Loss: 0.0014307887486211257, Final Batch Loss: 0.00016374677943531424\n",
      "Epoch 745, Loss: 0.000964472515079251, Final Batch Loss: 5.024103302275762e-05\n",
      "Epoch 746, Loss: 0.0037452710485013085, Final Batch Loss: 4.737584822578356e-05\n",
      "Epoch 747, Loss: 0.00072878352511907, Final Batch Loss: 4.4858461478725076e-05\n",
      "Epoch 748, Loss: 0.0008893105023162207, Final Batch Loss: 1.3393923836702015e-05\n",
      "Epoch 749, Loss: 0.0006600683768738236, Final Batch Loss: 4.459941919776611e-05\n",
      "Epoch 750, Loss: 0.001261443433804743, Final Batch Loss: 0.0002460227406118065\n",
      "Epoch 751, Loss: 0.0004421216144692153, Final Batch Loss: 4.424447979545221e-05\n",
      "Epoch 752, Loss: 0.002462165131873917, Final Batch Loss: 8.65842230268754e-05\n",
      "Epoch 753, Loss: 0.011025443264770729, Final Batch Loss: 0.0005852942704223096\n",
      "Epoch 754, Loss: 0.01681089606063324, Final Batch Loss: 1.8550874301581644e-05\n",
      "Epoch 755, Loss: 0.0010156970038224244, Final Batch Loss: 6.696354103041813e-05\n",
      "Epoch 756, Loss: 0.001245801564436988, Final Batch Loss: 0.00010216179362032562\n",
      "Epoch 757, Loss: 0.01901977437273672, Final Batch Loss: 0.0013417351292446256\n",
      "Epoch 758, Loss: 0.0008725672164473508, Final Batch Loss: 7.257011748151854e-05\n",
      "Epoch 759, Loss: 0.0006912352282597567, Final Batch Loss: 4.364553024061024e-05\n",
      "Epoch 760, Loss: 0.0014369417363013781, Final Batch Loss: 5.044230056228116e-05\n",
      "Epoch 761, Loss: 0.006011084976876191, Final Batch Loss: 4.0412960515823215e-06\n",
      "Epoch 762, Loss: 0.0010072179179587692, Final Batch Loss: 5.107979177410016e-06\n",
      "Epoch 763, Loss: 0.0006507564794446807, Final Batch Loss: 1.1326900676067453e-05\n",
      "Epoch 764, Loss: 0.0008597017094871262, Final Batch Loss: 9.327568841399625e-05\n",
      "Epoch 765, Loss: 0.017505366837895053, Final Batch Loss: 1.2742477792926366e-06\n",
      "Epoch 766, Loss: 0.0011957451133639552, Final Batch Loss: 4.537746008281829e-06\n",
      "Epoch 767, Loss: 0.001008045747767028, Final Batch Loss: 8.496930604451336e-06\n",
      "Epoch 768, Loss: 0.000503922564575987, Final Batch Loss: 3.617434686020715e-06\n",
      "Epoch 769, Loss: 0.012547300773576353, Final Batch Loss: 1.4108087270869873e-05\n",
      "Epoch 770, Loss: 0.0016924596070566622, Final Batch Loss: 1.6080028217402287e-05\n",
      "Epoch 771, Loss: 0.07885915498172835, Final Batch Loss: 0.0004599104286171496\n",
      "Epoch 772, Loss: 0.004011954632915149, Final Batch Loss: 1.8211623682873324e-05\n",
      "Epoch 773, Loss: 0.004804669619716151, Final Batch Loss: 7.539943908341229e-05\n",
      "Epoch 774, Loss: 0.025218723440048052, Final Batch Loss: 3.6602752516046166e-05\n",
      "Epoch 775, Loss: 0.0012916716805193573, Final Batch Loss: 4.0852239180821925e-05\n",
      "Epoch 776, Loss: 0.002668373757842346, Final Batch Loss: 6.042548648110824e-06\n",
      "Epoch 777, Loss: 0.0020900809977320023, Final Batch Loss: 0.0006288442527875304\n",
      "Epoch 778, Loss: 0.008919117986806668, Final Batch Loss: 2.299972766195424e-05\n",
      "Epoch 779, Loss: 0.005651711110658653, Final Batch Loss: 6.115670112194493e-05\n",
      "Epoch 780, Loss: 0.0033399841295249644, Final Batch Loss: 5.7293993450002745e-05\n",
      "Epoch 781, Loss: 0.001203538172376284, Final Batch Loss: 0.00018426326278131455\n",
      "Epoch 782, Loss: 0.0015216111851259484, Final Batch Loss: 3.9410264434991404e-05\n",
      "Epoch 783, Loss: 0.0028819240101256582, Final Batch Loss: 3.092706174356863e-05\n",
      "Epoch 784, Loss: 0.001700662091934646, Final Batch Loss: 0.00016676644736435264\n",
      "Epoch 785, Loss: 0.0027834053616970778, Final Batch Loss: 0.001860164338722825\n",
      "Epoch 786, Loss: 0.0016264287430658442, Final Batch Loss: 0.00011169876961503178\n",
      "Epoch 787, Loss: 0.003349402320509398, Final Batch Loss: 6.807511908846209e-06\n",
      "Epoch 788, Loss: 0.005448151256132405, Final Batch Loss: 2.1990108507452533e-06\n",
      "Epoch 789, Loss: 0.002048936350092845, Final Batch Loss: 6.484633922809735e-05\n",
      "Epoch 790, Loss: 0.001770948502326064, Final Batch Loss: 0.00010511997970752418\n",
      "Epoch 791, Loss: 0.0011634306242740422, Final Batch Loss: 0.0001126960851252079\n",
      "Epoch 792, Loss: 0.0011564012402232038, Final Batch Loss: 8.196164344553836e-06\n",
      "Epoch 793, Loss: 0.002583027763193968, Final Batch Loss: 1.023751883622026e-05\n",
      "Epoch 794, Loss: 0.0028906822976750846, Final Batch Loss: 0.00016256648814305663\n",
      "Epoch 795, Loss: 0.0031213541510624054, Final Batch Loss: 6.000252142257523e-06\n",
      "Epoch 796, Loss: 0.0008905144579784974, Final Batch Loss: 4.252584039932117e-05\n",
      "Epoch 797, Loss: 0.000341150788244704, Final Batch Loss: 5.116005013405811e-06\n",
      "Epoch 798, Loss: 0.001140779553225002, Final Batch Loss: 1.0953527635138016e-05\n",
      "Epoch 799, Loss: 0.00031702105843578465, Final Batch Loss: 3.380412090336904e-05\n",
      "Epoch 800, Loss: 0.036911653368747466, Final Batch Loss: 1.0201878467341885e-05\n",
      "Epoch 801, Loss: 0.007065361837703676, Final Batch Loss: 3.4486056392779574e-05\n",
      "Epoch 802, Loss: 0.00072541441136309, Final Batch Loss: 2.2264606741373427e-05\n",
      "Epoch 803, Loss: 0.0026952841089951107, Final Batch Loss: 4.8751815484138206e-05\n",
      "Epoch 804, Loss: 0.0006907542799581279, Final Batch Loss: 3.578383621061221e-05\n",
      "Epoch 805, Loss: 0.0005847490497217223, Final Batch Loss: 2.315989877388347e-05\n",
      "Epoch 806, Loss: 0.036957736286240106, Final Batch Loss: 0.00013026039232499897\n",
      "Epoch 807, Loss: 0.03229496701851531, Final Batch Loss: 0.0025657345540821552\n",
      "Epoch 808, Loss: 0.008322716025759291, Final Batch Loss: 0.0006165818776935339\n",
      "Epoch 809, Loss: 0.12492457273037871, Final Batch Loss: 0.006295544095337391\n",
      "Epoch 810, Loss: 0.003995651301465841, Final Batch Loss: 9.604476508684456e-05\n",
      "Epoch 811, Loss: 0.016875842642548378, Final Batch Loss: 6.91434761392884e-05\n",
      "Epoch 812, Loss: 0.008341374988276584, Final Batch Loss: 0.00039425244904123247\n",
      "Epoch 813, Loss: 0.01282629383422318, Final Batch Loss: 0.00024210978881455958\n",
      "Epoch 814, Loss: 0.014846785904410353, Final Batch Loss: 1.5095807611942291e-05\n",
      "Epoch 815, Loss: 0.017808225888984452, Final Batch Loss: 1.0890554221987259e-05\n",
      "Epoch 816, Loss: 0.01591731439657451, Final Batch Loss: 1.9610606614151038e-05\n",
      "Epoch 817, Loss: 0.0022540347758877033, Final Batch Loss: 1.0080083484353963e-05\n",
      "Epoch 818, Loss: 0.005516057610293501, Final Batch Loss: 9.340365795651451e-05\n",
      "Epoch 819, Loss: 0.011835577583042323, Final Batch Loss: 1.3650110304297414e-05\n",
      "Epoch 820, Loss: 0.02626217260967678, Final Batch Loss: 8.77551210578531e-05\n",
      "Epoch 821, Loss: 0.01209899671812309, Final Batch Loss: 4.269132659828756e-06\n",
      "Epoch 822, Loss: 0.007903280898972298, Final Batch Loss: 3.0747498385608196e-05\n",
      "Epoch 823, Loss: 0.02948472679599945, Final Batch Loss: 3.044095319637563e-05\n",
      "Epoch 824, Loss: 0.0013913754119130317, Final Batch Loss: 9.011599104269408e-06\n",
      "Epoch 825, Loss: 0.008275094421151152, Final Batch Loss: 1.532699025119655e-05\n",
      "Epoch 826, Loss: 0.006384186011473503, Final Batch Loss: 8.4914434410166e-05\n",
      "Epoch 827, Loss: 0.0006846778906037798, Final Batch Loss: 9.570200927555561e-05\n",
      "Epoch 828, Loss: 0.04845898937867332, Final Batch Loss: 0.0446944423019886\n",
      "Epoch 829, Loss: 0.0027047182393289404, Final Batch Loss: 1.7593285519978963e-05\n",
      "Epoch 830, Loss: 0.0031316634467657423, Final Batch Loss: 3.8348924135789275e-05\n",
      "Epoch 831, Loss: 0.003335027737193741, Final Batch Loss: 4.360720777185634e-05\n",
      "Epoch 832, Loss: 0.007228817199575133, Final Batch Loss: 4.4605916627915576e-05\n",
      "Epoch 833, Loss: 0.004184625933703501, Final Batch Loss: 2.2774840545025654e-05\n",
      "Epoch 834, Loss: 0.0011720824777512462, Final Batch Loss: 3.0254872399382293e-05\n",
      "Epoch 835, Loss: 0.0016545391063118586, Final Batch Loss: 0.00013400045281741768\n",
      "Epoch 836, Loss: 0.005464056177970633, Final Batch Loss: 6.887347262818366e-05\n",
      "Epoch 837, Loss: 0.0036173692863030737, Final Batch Loss: 5.696319021808449e-06\n",
      "Epoch 838, Loss: 0.00763109760896441, Final Batch Loss: 0.00023326402879320085\n",
      "Epoch 839, Loss: 0.005142944266481209, Final Batch Loss: 0.00028572208248078823\n",
      "Epoch 840, Loss: 0.0025973376377805835, Final Batch Loss: 4.635263030650094e-05\n",
      "Epoch 841, Loss: 0.0045077702816342935, Final Batch Loss: 6.972177652642131e-05\n",
      "Epoch 842, Loss: 0.019946058058849303, Final Batch Loss: 4.391119728097692e-05\n",
      "Epoch 843, Loss: 0.011166529740876285, Final Batch Loss: 0.0003629954007919878\n",
      "Epoch 844, Loss: 0.005389324966927234, Final Batch Loss: 1.2261848496564198e-05\n",
      "Epoch 845, Loss: 0.0008856727545207832, Final Batch Loss: 7.249090413097292e-05\n",
      "Epoch 846, Loss: 0.015545529554401583, Final Batch Loss: 0.00010285768803441897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 847, Loss: 0.0685962070547248, Final Batch Loss: 0.00020729430252686143\n",
      "Epoch 848, Loss: 0.0028552636513268226, Final Batch Loss: 0.001114099402911961\n",
      "Epoch 849, Loss: 0.0015033545414553373, Final Batch Loss: 6.263131945161149e-05\n",
      "Epoch 850, Loss: 0.002244593141540463, Final Batch Loss: 2.9137420369806932e-06\n",
      "Epoch 851, Loss: 0.0019106903096144379, Final Batch Loss: 0.00010209424362983555\n",
      "Epoch 852, Loss: 0.11910993333822262, Final Batch Loss: 4.210484985378571e-05\n",
      "Epoch 853, Loss: 0.0029183430433477042, Final Batch Loss: 0.0003304250130895525\n",
      "Epoch 854, Loss: 0.012541442381916568, Final Batch Loss: 9.008061897475272e-05\n",
      "Epoch 855, Loss: 0.004535914013104048, Final Batch Loss: 8.061199332587421e-05\n",
      "Epoch 856, Loss: 0.0024890467093428015, Final Batch Loss: 1.0783423022076022e-05\n",
      "Epoch 857, Loss: 0.0026117367060578545, Final Batch Loss: 6.457471499743406e-06\n",
      "Epoch 858, Loss: 0.0030967129223427037, Final Batch Loss: 5.617950955638662e-05\n",
      "Epoch 859, Loss: 0.0011158721463289112, Final Batch Loss: 3.897655915352516e-05\n",
      "Epoch 860, Loss: 0.002647135510414955, Final Batch Loss: 2.6419536879984662e-05\n",
      "Epoch 861, Loss: 0.0014826066940258897, Final Batch Loss: 3.415526953176595e-05\n",
      "Epoch 862, Loss: 0.0010040623074019095, Final Batch Loss: 5.8183723012916744e-05\n",
      "Epoch 863, Loss: 0.0025054972029465716, Final Batch Loss: 0.00010176620708080009\n",
      "Epoch 864, Loss: 0.011018848868843634, Final Batch Loss: 7.3358664849365596e-06\n",
      "Epoch 865, Loss: 0.00422093825545744, Final Batch Loss: 0.0004104933177586645\n",
      "Epoch 866, Loss: 0.005872402549357503, Final Batch Loss: 0.0016065938398241997\n",
      "Epoch 867, Loss: 0.0015907528409115912, Final Batch Loss: 3.018323150172364e-05\n",
      "Epoch 868, Loss: 0.0008210861824409221, Final Batch Loss: 2.411240348010324e-05\n",
      "Epoch 869, Loss: 0.0014939546224468359, Final Batch Loss: 7.821434701327235e-05\n",
      "Epoch 870, Loss: 0.0007856456606987194, Final Batch Loss: 1.622734089323785e-05\n",
      "Epoch 871, Loss: 0.0005808486566820648, Final Batch Loss: 3.068348451051861e-05\n",
      "Epoch 872, Loss: 0.000727241261756717, Final Batch Loss: 6.35941569271381e-06\n",
      "Epoch 873, Loss: 0.0021818130476276565, Final Batch Loss: 5.585897724813549e-06\n",
      "Epoch 874, Loss: 0.0029756303010799456, Final Batch Loss: 9.44590829021763e-06\n",
      "Epoch 875, Loss: 0.004656645242448576, Final Batch Loss: 3.531081893015653e-05\n",
      "Epoch 876, Loss: 0.0008288085014100943, Final Batch Loss: 4.811363396584056e-06\n",
      "Epoch 877, Loss: 0.0056942406040434435, Final Batch Loss: 5.020475782657741e-06\n",
      "Epoch 878, Loss: 0.023224900968671136, Final Batch Loss: 6.449370266636834e-05\n",
      "Epoch 879, Loss: 0.022737043404049473, Final Batch Loss: 1.2472927664930467e-05\n",
      "Epoch 880, Loss: 0.0015772413325976231, Final Batch Loss: 6.226562982192263e-05\n",
      "Epoch 881, Loss: 0.01876629832713661, Final Batch Loss: 7.098687638062984e-05\n",
      "Epoch 882, Loss: 0.009043219120940194, Final Batch Loss: 0.00019407672516535968\n",
      "Epoch 883, Loss: 0.02152860963292369, Final Batch Loss: 0.017661331221461296\n",
      "Epoch 884, Loss: 0.0023574906799694872, Final Batch Loss: 0.0003109367680735886\n",
      "Epoch 885, Loss: 0.0011613664109972888, Final Batch Loss: 1.2405621419020463e-05\n",
      "Epoch 886, Loss: 0.022284416936599882, Final Batch Loss: 0.0001708185882307589\n",
      "Epoch 887, Loss: 0.0008654628172735102, Final Batch Loss: 3.249544170103036e-05\n",
      "Epoch 888, Loss: 0.0015721021786703204, Final Batch Loss: 7.659690163563937e-05\n",
      "Epoch 889, Loss: 0.00482769758127688, Final Batch Loss: 1.6567435523029417e-05\n",
      "Epoch 890, Loss: 0.0017121248606599693, Final Batch Loss: 4.214856744511053e-05\n",
      "Epoch 891, Loss: 0.0004881266645497817, Final Batch Loss: 1.289999363507377e-05\n",
      "Epoch 892, Loss: 0.01973414320673328, Final Batch Loss: 3.772797208512202e-05\n",
      "Epoch 893, Loss: 0.001165437832241878, Final Batch Loss: 5.610264270217158e-05\n",
      "Epoch 894, Loss: 0.0037213368850643747, Final Batch Loss: 0.0004303978639654815\n",
      "Epoch 895, Loss: 0.0025309687453045626, Final Batch Loss: 7.3556526331231e-05\n",
      "Epoch 896, Loss: 0.0035333879573045124, Final Batch Loss: 7.53181884647347e-05\n",
      "Epoch 897, Loss: 0.008241877575528633, Final Batch Loss: 0.000177080713910982\n",
      "Epoch 898, Loss: 0.002054518521163118, Final Batch Loss: 7.425771764246747e-05\n",
      "Epoch 899, Loss: 0.0006364879659486178, Final Batch Loss: 6.932115502422675e-05\n",
      "Epoch 900, Loss: 0.001532264925799609, Final Batch Loss: 4.380016616778448e-05\n",
      "Epoch 901, Loss: 0.0002970462051052891, Final Batch Loss: 4.746871582028689e-06\n",
      "Epoch 902, Loss: 0.0008859458271217591, Final Batch Loss: 1.1314973562548403e-05\n",
      "Epoch 903, Loss: 0.0008958940193224407, Final Batch Loss: 5.2081650210311636e-05\n",
      "Epoch 904, Loss: 0.009177383285987162, Final Batch Loss: 0.00035770575050264597\n",
      "Epoch 905, Loss: 0.03239209858838876, Final Batch Loss: 2.2757578335586004e-05\n",
      "Epoch 906, Loss: 0.020467030037252698, Final Batch Loss: 0.00030286534456536174\n",
      "Epoch 907, Loss: 0.0033071509469664306, Final Batch Loss: 1.3465525626088493e-05\n",
      "Epoch 908, Loss: 0.0021778580976388184, Final Batch Loss: 4.836485823034309e-05\n",
      "Epoch 909, Loss: 0.0031521617870566843, Final Batch Loss: 2.1735957488999702e-05\n",
      "Epoch 910, Loss: 0.009943644416125608, Final Batch Loss: 8.7448916019639e-06\n",
      "Epoch 911, Loss: 0.0008683609121362679, Final Batch Loss: 1.1515911864989903e-05\n",
      "Epoch 912, Loss: 0.00477842612144741, Final Batch Loss: 1.439512379874941e-05\n",
      "Epoch 913, Loss: 0.001678001282925834, Final Batch Loss: 0.0008334591402672231\n",
      "Epoch 914, Loss: 0.0011377940099919215, Final Batch Loss: 0.00016641071124468\n",
      "Epoch 915, Loss: 0.0019940445549764263, Final Batch Loss: 2.063068313873373e-05\n",
      "Epoch 916, Loss: 0.0008209799229916825, Final Batch Loss: 3.453925819485448e-05\n",
      "Epoch 917, Loss: 0.0006703785902573145, Final Batch Loss: 8.192982932087034e-05\n",
      "Epoch 918, Loss: 0.001288320278717947, Final Batch Loss: 0.00017196321277879179\n",
      "Epoch 919, Loss: 0.003469600530934258, Final Batch Loss: 2.8323414881015196e-05\n",
      "Epoch 920, Loss: 0.0013516335948224878, Final Batch Loss: 6.656234290858265e-06\n",
      "Epoch 921, Loss: 0.0017297027136464749, Final Batch Loss: 3.951819962821901e-06\n",
      "Epoch 922, Loss: 0.0006362831657042989, Final Batch Loss: 2.9083460049150744e-06\n",
      "Epoch 923, Loss: 0.0011724433861672878, Final Batch Loss: 3.7938392779324204e-05\n",
      "Epoch 924, Loss: 0.0007534683350058913, Final Batch Loss: 4.177744358457858e-06\n",
      "Epoch 925, Loss: 0.0006470209000326577, Final Batch Loss: 3.152071440126747e-05\n",
      "Epoch 926, Loss: 0.0011299553138996998, Final Batch Loss: 4.1099730879068375e-05\n",
      "Epoch 927, Loss: 0.027002614417142468, Final Batch Loss: 0.00014599354472011328\n",
      "Epoch 928, Loss: 0.006835861616309558, Final Batch Loss: 3.3045180316548795e-05\n",
      "Epoch 929, Loss: 0.0003778282543862588, Final Batch Loss: 1.5031209841254167e-05\n",
      "Epoch 930, Loss: 0.0021042624082383554, Final Batch Loss: 2.1988407752360217e-05\n",
      "Epoch 931, Loss: 0.003094111763402907, Final Batch Loss: 9.915526607073843e-05\n",
      "Epoch 932, Loss: 0.0013758958730250015, Final Batch Loss: 0.000481953116832301\n",
      "Epoch 933, Loss: 0.0009580013588674774, Final Batch Loss: 7.453472790075466e-06\n",
      "Epoch 934, Loss: 0.0028516881711766473, Final Batch Loss: 0.00021550239762291312\n",
      "Epoch 935, Loss: 0.0015117903362806828, Final Batch Loss: 1.571301072544884e-05\n",
      "Epoch 936, Loss: 0.0022871313612995436, Final Batch Loss: 2.131221117451787e-05\n",
      "Epoch 937, Loss: 0.0006593527473341965, Final Batch Loss: 7.141131936805323e-05\n",
      "Epoch 938, Loss: 0.0006996041063302982, Final Batch Loss: 1.5293377146008424e-05\n",
      "Epoch 939, Loss: 0.0009663343726060702, Final Batch Loss: 6.987633969401941e-05\n",
      "Epoch 940, Loss: 0.0010355130475545593, Final Batch Loss: 8.072832861216739e-05\n",
      "Epoch 941, Loss: 0.0007436087435053196, Final Batch Loss: 1.2818128197977785e-05\n",
      "Epoch 942, Loss: 0.006545407828070893, Final Batch Loss: 1.9850886019412428e-05\n",
      "Epoch 943, Loss: 0.004361502310985088, Final Batch Loss: 3.126167484879261e-06\n",
      "Epoch 944, Loss: 0.0011883598226631875, Final Batch Loss: 3.28364985762164e-05\n",
      "Epoch 945, Loss: 0.0013714291294490977, Final Batch Loss: 0.0007204394205473363\n",
      "Epoch 946, Loss: 0.023699289312389737, Final Batch Loss: 3.9712995203444734e-05\n",
      "Epoch 947, Loss: 0.0032573924036114477, Final Batch Loss: 7.572081813123077e-05\n",
      "Epoch 948, Loss: 0.015094432143996528, Final Batch Loss: 2.4138465960277244e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949, Loss: 0.0014050469010271627, Final Batch Loss: 1.4953860954847187e-05\n",
      "Epoch 950, Loss: 0.0010523851758534875, Final Batch Loss: 6.299716915236786e-06\n",
      "Epoch 951, Loss: 0.0008510691052379116, Final Batch Loss: 2.7026135285268538e-06\n",
      "Epoch 952, Loss: 0.033545962146945385, Final Batch Loss: 9.842538020166103e-06\n",
      "Epoch 953, Loss: 0.0005254143507045228, Final Batch Loss: 3.0855426302878186e-05\n",
      "Epoch 954, Loss: 0.0022107387876530993, Final Batch Loss: 8.781516953604296e-05\n",
      "Epoch 955, Loss: 0.003795892708694737, Final Batch Loss: 0.0011074719950556755\n",
      "Epoch 956, Loss: 0.0020276890845707385, Final Batch Loss: 1.081708433048334e-05\n",
      "Epoch 957, Loss: 0.0006971598932068446, Final Batch Loss: 2.6261554012307897e-05\n",
      "Epoch 958, Loss: 0.003007171661238317, Final Batch Loss: 2.1240257410681807e-05\n",
      "Epoch 959, Loss: 0.0004165002947047469, Final Batch Loss: 1.71539286384359e-05\n",
      "Epoch 960, Loss: 0.0007702526490902528, Final Batch Loss: 1.441211406927323e-05\n",
      "Epoch 961, Loss: 0.0006907225579197984, Final Batch Loss: 0.00013020203914493322\n",
      "Epoch 962, Loss: 0.0012892955385268579, Final Batch Loss: 2.409683474979829e-05\n",
      "Epoch 963, Loss: 0.00041201688441105944, Final Batch Loss: 5.661552222591126e-06\n",
      "Epoch 964, Loss: 0.0004046060512337135, Final Batch Loss: 0.00022173201432451606\n",
      "Epoch 965, Loss: 0.0005993310453504819, Final Batch Loss: 8.76861759024905e-06\n",
      "Epoch 966, Loss: 0.0007829368551028892, Final Batch Loss: 1.3516799299395643e-05\n",
      "Epoch 967, Loss: 0.0013924363803425877, Final Batch Loss: 1.4045725947653409e-05\n",
      "Epoch 968, Loss: 0.001546872432300006, Final Batch Loss: 0.0002593531971797347\n",
      "Epoch 969, Loss: 0.0011458213928108307, Final Batch Loss: 8.071111369645223e-05\n",
      "Epoch 970, Loss: 0.0008584448378314846, Final Batch Loss: 0.0001344050106126815\n",
      "Epoch 971, Loss: 0.0021301854631019523, Final Batch Loss: 3.082734110648744e-06\n",
      "Epoch 972, Loss: 0.038427891109449774, Final Batch Loss: 1.0074990314024035e-05\n",
      "Epoch 973, Loss: 0.0012524630374173285, Final Batch Loss: 8.091048584901728e-06\n",
      "Epoch 974, Loss: 0.0016748838488638285, Final Batch Loss: 3.425420436542481e-05\n",
      "Epoch 975, Loss: 0.003715988357498645, Final Batch Loss: 0.0012587843229994178\n",
      "Epoch 976, Loss: 0.0012737714673676237, Final Batch Loss: 0.00013076690083835274\n",
      "Epoch 977, Loss: 0.00041076454226640635, Final Batch Loss: 9.846487955655903e-05\n",
      "Epoch 978, Loss: 0.0009323051995124843, Final Batch Loss: 1.5002019608800765e-05\n",
      "Epoch 979, Loss: 0.005858579727828328, Final Batch Loss: 3.8618331018369645e-05\n",
      "Epoch 980, Loss: 0.000956714069843656, Final Batch Loss: 0.00019976570911239833\n",
      "Epoch 981, Loss: 0.0004004427869404026, Final Batch Loss: 4.982594691682607e-05\n",
      "Epoch 982, Loss: 0.02537429346148201, Final Batch Loss: 1.3403153388935607e-05\n",
      "Epoch 983, Loss: 0.007587545897649761, Final Batch Loss: 1.1816589903901331e-05\n",
      "Epoch 984, Loss: 0.005090023471666427, Final Batch Loss: 6.203752036526566e-06\n",
      "Epoch 985, Loss: 0.002484789762092987, Final Batch Loss: 9.536792276776396e-06\n",
      "Epoch 986, Loss: 0.0021922816786172916, Final Batch Loss: 2.3180211428552866e-05\n",
      "Epoch 987, Loss: 0.0008224359510222712, Final Batch Loss: 3.9323876990238205e-05\n",
      "Epoch 988, Loss: 0.001212787001804827, Final Batch Loss: 6.208748527569696e-05\n",
      "Epoch 989, Loss: 0.0008770166457452433, Final Batch Loss: 2.5613178422645433e-06\n",
      "Epoch 990, Loss: 0.0004812508195755072, Final Batch Loss: 3.2736843422753736e-06\n",
      "Epoch 991, Loss: 0.00030286412879831914, Final Batch Loss: 3.821987320407061e-06\n",
      "Epoch 992, Loss: 0.01842546373973164, Final Batch Loss: 0.00013719273556489497\n",
      "Epoch 993, Loss: 0.0011036604564651498, Final Batch Loss: 0.00015300656377803534\n",
      "Epoch 994, Loss: 0.022335743392659424, Final Batch Loss: 7.671800631214865e-06\n",
      "Epoch 995, Loss: 0.0038984654106570815, Final Batch Loss: 5.1534771046135575e-05\n",
      "Epoch 996, Loss: 0.04010251597287606, Final Batch Loss: 1.85488515853649e-05\n",
      "Epoch 997, Loss: 0.003927794369701587, Final Batch Loss: 5.242253337200964e-06\n",
      "Epoch 998, Loss: 0.002085321195409051, Final Batch Loss: 4.431705383467488e-05\n",
      "Epoch 999, Loss: 0.0014067671777411306, Final Batch Loss: 1.3484800547303166e-05\n",
      "Epoch 1000, Loss: 0.0013620973786601098, Final Batch Loss: 2.3421942387358285e-05\n",
      "Epoch 1001, Loss: 0.0009982940155168762, Final Batch Loss: 1.2329136552580167e-05\n",
      "Epoch 1002, Loss: 0.000964298375947692, Final Batch Loss: 8.18800472188741e-05\n",
      "Epoch 1003, Loss: 0.0006201795185916126, Final Batch Loss: 1.932682607730385e-05\n",
      "Epoch 1004, Loss: 0.0061322926076172735, Final Batch Loss: 5.63482717552688e-05\n",
      "Epoch 1005, Loss: 0.0029692980915569933, Final Batch Loss: 0.00018602587806526572\n",
      "Epoch 1006, Loss: 0.002076192621871087, Final Batch Loss: 2.2983342205407098e-05\n",
      "Epoch 1007, Loss: 0.00145499563325302, Final Batch Loss: 0.0001472503354307264\n",
      "Epoch 1008, Loss: 0.0003424791200359323, Final Batch Loss: 2.142722451026202e-06\n",
      "Epoch 1009, Loss: 0.0004301406138438324, Final Batch Loss: 1.1629222171904985e-05\n",
      "Epoch 1010, Loss: 0.000512104272615943, Final Batch Loss: 1.3867379493603949e-05\n",
      "Epoch 1011, Loss: 0.0003469213415883132, Final Batch Loss: 3.139266846119426e-05\n",
      "Epoch 1012, Loss: 0.0003950612954213284, Final Batch Loss: 1.641874769120477e-05\n",
      "Epoch 1013, Loss: 0.0006894755761095439, Final Batch Loss: 6.5405665736761875e-06\n",
      "Epoch 1014, Loss: 0.003109522096337969, Final Batch Loss: 0.0007720382418483496\n",
      "Epoch 1015, Loss: 0.0006873919844565535, Final Batch Loss: 1.3670357930095633e-06\n",
      "Epoch 1016, Loss: 0.01271393816705313, Final Batch Loss: 3.730569460458355e-06\n",
      "Epoch 1017, Loss: 0.009175122824672144, Final Batch Loss: 0.004209426697343588\n",
      "Epoch 1018, Loss: 0.0009859763296162782, Final Batch Loss: 2.8937518436578102e-05\n",
      "Epoch 1019, Loss: 0.0011625597907141128, Final Batch Loss: 1.897163997455209e-06\n",
      "Epoch 1020, Loss: 0.0068946479267424365, Final Batch Loss: 0.0036607186775654554\n",
      "Epoch 1021, Loss: 0.002115004246775243, Final Batch Loss: 9.598141332389787e-05\n",
      "Epoch 1022, Loss: 0.0005386798350173194, Final Batch Loss: 7.416707376250997e-06\n",
      "Epoch 1023, Loss: 0.006221724400347739, Final Batch Loss: 1.6192403563763946e-05\n",
      "Epoch 1024, Loss: 0.036527498291661686, Final Batch Loss: 9.084758403332671e-07\n",
      "Epoch 1025, Loss: 0.0005046827336627757, Final Batch Loss: 1.6502335711265914e-05\n",
      "Epoch 1026, Loss: 0.000847202778686551, Final Batch Loss: 5.326030986907426e-06\n",
      "Epoch 1027, Loss: 0.0014107665463143348, Final Batch Loss: 6.690408099530032e-06\n",
      "Epoch 1028, Loss: 0.0019967690849398423, Final Batch Loss: 1.0256759196636267e-05\n",
      "Epoch 1029, Loss: 0.00039377120924655173, Final Batch Loss: 0.000152245833305642\n",
      "Epoch 1030, Loss: 0.0003427758408633963, Final Batch Loss: 4.09487693104893e-05\n",
      "Epoch 1031, Loss: 0.0010335359922919451, Final Batch Loss: 0.00016223653801716864\n",
      "Epoch 1032, Loss: 0.0045033646479168965, Final Batch Loss: 0.0007743585156276822\n",
      "Epoch 1033, Loss: 0.004344119950701497, Final Batch Loss: 4.813789018953685e-06\n",
      "Epoch 1034, Loss: 0.0006091203235882858, Final Batch Loss: 8.162894664565101e-05\n",
      "Epoch 1035, Loss: 0.0006413066375898779, Final Batch Loss: 7.943774107843637e-06\n",
      "Epoch 1036, Loss: 0.0006578994602932653, Final Batch Loss: 7.999012450454757e-05\n",
      "Epoch 1037, Loss: 0.03286330844639451, Final Batch Loss: 0.001218624645844102\n",
      "Epoch 1038, Loss: 0.0028188407750349143, Final Batch Loss: 9.471579687669873e-06\n",
      "Epoch 1039, Loss: 0.0012073082480128505, Final Batch Loss: 0.0005137287080287933\n",
      "Epoch 1040, Loss: 0.0010869206703318923, Final Batch Loss: 0.0005267251399345696\n",
      "Epoch 1041, Loss: 0.0008648108077977668, Final Batch Loss: 8.758152944210451e-06\n",
      "Epoch 1042, Loss: 0.0005776719954155851, Final Batch Loss: 1.8426799215376377e-05\n",
      "Epoch 1043, Loss: 0.0004956308088139849, Final Batch Loss: 2.0618788767023943e-05\n",
      "Epoch 1044, Loss: 0.0005512274257171157, Final Batch Loss: 2.7837419111165218e-05\n",
      "Epoch 1045, Loss: 0.0012664500300161308, Final Batch Loss: 2.570252399891615e-05\n",
      "Epoch 1046, Loss: 0.0005063557298399246, Final Batch Loss: 3.508209192659706e-05\n",
      "Epoch 1047, Loss: 0.0008857479733705986, Final Batch Loss: 1.60576691996539e-05\n",
      "Epoch 1048, Loss: 0.0008050218823427713, Final Batch Loss: 1.6325686374329962e-05\n",
      "Epoch 1049, Loss: 0.0014665215987861302, Final Batch Loss: 0.0009995467262342572\n",
      "Epoch 1050, Loss: 0.11406396564848365, Final Batch Loss: 1.0926811228273436e-05\n",
      "Epoch 1051, Loss: 0.00040106490928337735, Final Batch Loss: 7.439831733790925e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1052, Loss: 0.0014208266446757989, Final Batch Loss: 2.5801020456128754e-05\n",
      "Epoch 1053, Loss: 0.0006869625232184262, Final Batch Loss: 1.7615985825614189e-06\n",
      "Epoch 1054, Loss: 0.00048340413343339605, Final Batch Loss: 1.4122325410426129e-05\n",
      "Epoch 1055, Loss: 0.0006486945103461039, Final Batch Loss: 0.0001533577305963263\n",
      "Epoch 1056, Loss: 0.002489902014076506, Final Batch Loss: 1.8239879864268005e-05\n",
      "Epoch 1057, Loss: 0.017513692007923964, Final Batch Loss: 0.00020560565462801605\n",
      "Epoch 1058, Loss: 0.0010738520259110373, Final Batch Loss: 7.272377388289897e-06\n",
      "Epoch 1059, Loss: 0.002864340109454133, Final Batch Loss: 3.144397624055273e-06\n",
      "Epoch 1060, Loss: 0.02211385437772151, Final Batch Loss: 8.757613250054419e-05\n",
      "Epoch 1061, Loss: 0.021828639261457283, Final Batch Loss: 6.224631215445697e-05\n",
      "Epoch 1062, Loss: 0.05540188068766838, Final Batch Loss: 7.516767072957009e-05\n",
      "Epoch 1063, Loss: 0.053591249514283845, Final Batch Loss: 1.4519568139803596e-05\n",
      "Epoch 1064, Loss: 0.0036157685372018022, Final Batch Loss: 2.5052788259927183e-05\n",
      "Epoch 1065, Loss: 0.003995628770098847, Final Batch Loss: 0.0011832714080810547\n",
      "Epoch 1066, Loss: 0.017066961767341127, Final Batch Loss: 8.37773404782638e-05\n",
      "Epoch 1067, Loss: 0.0043490925745572895, Final Batch Loss: 7.011185516603291e-05\n",
      "Epoch 1068, Loss: 0.0026909453963526175, Final Batch Loss: 1.081527898350032e-05\n",
      "Epoch 1069, Loss: 0.0017738120477588382, Final Batch Loss: 9.230369323631749e-05\n",
      "Epoch 1070, Loss: 0.0023532473969680723, Final Batch Loss: 1.7890004528453574e-05\n",
      "Epoch 1071, Loss: 0.003241362136122916, Final Batch Loss: 1.2416274330462329e-05\n",
      "Epoch 1072, Loss: 0.001214416502534732, Final Batch Loss: 7.054134039208293e-05\n",
      "Epoch 1073, Loss: 0.000753635936007413, Final Batch Loss: 8.57000850373879e-06\n",
      "Epoch 1074, Loss: 0.002072339880726304, Final Batch Loss: 9.693074389360845e-05\n",
      "Epoch 1075, Loss: 0.0006874711007185397, Final Batch Loss: 3.609949544625124e-06\n",
      "Epoch 1076, Loss: 0.0028768953266080644, Final Batch Loss: 1.9568025891203433e-05\n",
      "Epoch 1077, Loss: 0.0010476905356426869, Final Batch Loss: 3.2329051009583054e-06\n",
      "Epoch 1078, Loss: 0.0007007312701716728, Final Batch Loss: 8.149442874127999e-05\n",
      "Epoch 1079, Loss: 0.0017123549741882016, Final Batch Loss: 4.457199611351825e-05\n",
      "Epoch 1080, Loss: 0.0035251097410764487, Final Batch Loss: 2.1360392565838993e-05\n",
      "Epoch 1081, Loss: 0.0005306807065608155, Final Batch Loss: 5.6709272030275315e-05\n",
      "Epoch 1082, Loss: 0.0005051455912052916, Final Batch Loss: 2.0054550986969844e-05\n",
      "Epoch 1083, Loss: 0.03267380422039423, Final Batch Loss: 2.8059594114893116e-05\n",
      "Epoch 1084, Loss: 0.01324114941235166, Final Batch Loss: 0.0015912705566734076\n",
      "Epoch 1085, Loss: 0.002279551579249528, Final Batch Loss: 1.7839322026702575e-05\n",
      "Epoch 1086, Loss: 0.0016011488351068692, Final Batch Loss: 3.4392473025945947e-05\n",
      "Epoch 1087, Loss: 0.0029644165751960827, Final Batch Loss: 8.572323167754803e-06\n",
      "Epoch 1088, Loss: 0.010649776214904705, Final Batch Loss: 6.123006187408464e-06\n",
      "Epoch 1089, Loss: 0.0002820870508912776, Final Batch Loss: 2.745350320765283e-05\n",
      "Epoch 1090, Loss: 0.00040996689745043113, Final Batch Loss: 7.991220627445728e-06\n",
      "Epoch 1091, Loss: 0.0229441733351905, Final Batch Loss: 0.0001891411084216088\n",
      "Epoch 1092, Loss: 0.004589418924297206, Final Batch Loss: 1.7225740521098487e-05\n",
      "Epoch 1093, Loss: 0.000718446195605793, Final Batch Loss: 1.81532850547228e-05\n",
      "Epoch 1094, Loss: 0.006017631205395446, Final Batch Loss: 5.963405783404596e-06\n",
      "Epoch 1095, Loss: 0.0005196198642352101, Final Batch Loss: 7.871725392760709e-05\n",
      "Epoch 1096, Loss: 0.0004709777786047198, Final Batch Loss: 4.1124600102193654e-05\n",
      "Epoch 1097, Loss: 0.0003539234248819412, Final Batch Loss: 3.110436227871105e-05\n",
      "Epoch 1098, Loss: 0.01050367785137496, Final Batch Loss: 2.9704238841077313e-05\n",
      "Epoch 1099, Loss: 0.0008652716185224563, Final Batch Loss: 3.092847691732459e-05\n",
      "Epoch 1100, Loss: 0.0016302215392443031, Final Batch Loss: 4.004213769803755e-05\n",
      "Epoch 1101, Loss: 0.004545695196156885, Final Batch Loss: 3.349364851601422e-05\n",
      "Epoch 1102, Loss: 0.0001540458310955728, Final Batch Loss: 2.3063736080075614e-05\n",
      "Epoch 1103, Loss: 0.0009477051378325996, Final Batch Loss: 8.47819865157362e-06\n",
      "Epoch 1104, Loss: 0.0007510938375503429, Final Batch Loss: 5.214061457081698e-05\n",
      "Epoch 1105, Loss: 0.006357581436986948, Final Batch Loss: 0.00018389186880085617\n",
      "Epoch 1106, Loss: 0.0005947390549181364, Final Batch Loss: 5.607837374554947e-05\n",
      "Epoch 1107, Loss: 0.00516740611124078, Final Batch Loss: 1.5827185052330606e-05\n",
      "Epoch 1108, Loss: 0.00020006379020287568, Final Batch Loss: 1.9063720174017362e-05\n",
      "Epoch 1109, Loss: 0.01058172973012006, Final Batch Loss: 1.4350553101394325e-05\n",
      "Epoch 1110, Loss: 0.020575108746925252, Final Batch Loss: 2.9470114895957522e-05\n",
      "Epoch 1111, Loss: 0.005023707180953352, Final Batch Loss: 1.2781712030118797e-05\n",
      "Epoch 1112, Loss: 0.022931660103040485, Final Batch Loss: 1.8481532606529072e-05\n",
      "Epoch 1113, Loss: 0.0005439925143946311, Final Batch Loss: 8.559618436265737e-05\n",
      "Epoch 1114, Loss: 0.0011096481912318268, Final Batch Loss: 0.00017347424000035971\n",
      "Epoch 1115, Loss: 0.0008372429597329756, Final Batch Loss: 0.00011138808622490615\n",
      "Epoch 1116, Loss: 0.0033495903306857144, Final Batch Loss: 6.914416007930413e-05\n",
      "Epoch 1117, Loss: 0.009799280227525742, Final Batch Loss: 8.017140316951554e-06\n",
      "Epoch 1118, Loss: 0.001383705721309525, Final Batch Loss: 1.6237165255006403e-05\n",
      "Epoch 1119, Loss: 0.0017233798151323754, Final Batch Loss: 6.296028459473746e-06\n",
      "Epoch 1120, Loss: 0.0019338478293775552, Final Batch Loss: 5.897353730688337e-06\n",
      "Epoch 1121, Loss: 0.0018192386555710982, Final Batch Loss: 4.8915849220065866e-06\n",
      "Epoch 1122, Loss: 0.000485355461933068, Final Batch Loss: 6.49883077130653e-05\n",
      "Epoch 1123, Loss: 0.0018327045499972883, Final Batch Loss: 3.3461154089309275e-05\n",
      "Epoch 1124, Loss: 0.0007534298247264815, Final Batch Loss: 0.00012647824769373983\n",
      "Epoch 1125, Loss: 0.0009514289602066128, Final Batch Loss: 0.0001477199693908915\n",
      "Epoch 1126, Loss: 0.00045355913789535407, Final Batch Loss: 0.00016990024596452713\n",
      "Epoch 1127, Loss: 0.0005363311493056244, Final Batch Loss: 4.748597348225303e-06\n",
      "Epoch 1128, Loss: 0.00043163415602975874, Final Batch Loss: 3.182228101650253e-05\n",
      "Epoch 1129, Loss: 0.0034135525703504754, Final Batch Loss: 7.020606517471606e-06\n",
      "Epoch 1130, Loss: 0.001703916646874859, Final Batch Loss: 9.367156053485814e-06\n",
      "Epoch 1131, Loss: 0.00050122760734439, Final Batch Loss: 9.511000098427758e-05\n",
      "Epoch 1132, Loss: 0.0006175444835889721, Final Batch Loss: 9.182032954413444e-05\n",
      "Epoch 1133, Loss: 0.0005971475006845139, Final Batch Loss: 1.2112522199458908e-05\n",
      "Epoch 1134, Loss: 0.008598982696980784, Final Batch Loss: 0.0005678070010617375\n",
      "Epoch 1135, Loss: 0.0011172050508321263, Final Batch Loss: 2.396260606474243e-05\n",
      "Epoch 1136, Loss: 0.0013763810638920404, Final Batch Loss: 9.898962889565155e-05\n",
      "Epoch 1137, Loss: 0.0019161687964697194, Final Batch Loss: 0.0012691500596702099\n",
      "Epoch 1138, Loss: 0.00030802958599451813, Final Batch Loss: 4.340163741289871e-06\n",
      "Epoch 1139, Loss: 0.010817204476779807, Final Batch Loss: 5.33721595274983e-06\n",
      "Epoch 1140, Loss: 0.009515900602764304, Final Batch Loss: 2.758839400485158e-05\n",
      "Epoch 1141, Loss: 0.010492000399153767, Final Batch Loss: 3.05679022858385e-05\n",
      "Epoch 1142, Loss: 0.0005399587826815377, Final Batch Loss: 1.9495234937494388e-06\n",
      "Epoch 1143, Loss: 0.01705742211032657, Final Batch Loss: 0.00016968476120382547\n",
      "Epoch 1144, Loss: 0.03520526984956973, Final Batch Loss: 0.00011761493078665808\n",
      "Epoch 1145, Loss: 0.041367764898950554, Final Batch Loss: 0.00042403352563269436\n",
      "Epoch 1146, Loss: 0.015256496820825305, Final Batch Loss: 0.0130161102861166\n",
      "Epoch 1147, Loss: 0.0007475584470739705, Final Batch Loss: 5.772340955445543e-05\n",
      "Epoch 1148, Loss: 0.0010069438336586245, Final Batch Loss: 0.00013452136772684753\n",
      "Epoch 1149, Loss: 0.009439282371886293, Final Batch Loss: 1.4795741662965156e-05\n",
      "Epoch 1150, Loss: 0.0069211438230922795, Final Batch Loss: 3.7072368286317214e-05\n",
      "Epoch 1151, Loss: 0.0020604700475814752, Final Batch Loss: 8.44550504552899e-06\n",
      "Epoch 1152, Loss: 0.0018154059899870845, Final Batch Loss: 1.2817436982004438e-05\n",
      "Epoch 1153, Loss: 0.010135348376934417, Final Batch Loss: 3.994924554717727e-05\n",
      "Epoch 1154, Loss: 0.013310402248862374, Final Batch Loss: 0.00011887298023793846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1155, Loss: 0.002775771680944672, Final Batch Loss: 1.5807670934009366e-05\n",
      "Epoch 1156, Loss: 0.003711977889224727, Final Batch Loss: 1.535563205834478e-05\n",
      "Epoch 1157, Loss: 0.0006481961960389526, Final Batch Loss: 2.2740530766895972e-05\n",
      "Epoch 1158, Loss: 0.0007097406842149212, Final Batch Loss: 3.549355824361555e-05\n",
      "Epoch 1159, Loss: 0.004689146381224418, Final Batch Loss: 1.6658403183100745e-05\n",
      "Epoch 1160, Loss: 0.002478305356362398, Final Batch Loss: 5.824325489811599e-05\n",
      "Epoch 1161, Loss: 0.002844385346634226, Final Batch Loss: 4.845200237468816e-06\n",
      "Epoch 1162, Loss: 0.0007746541068627266, Final Batch Loss: 3.21935694955755e-05\n",
      "Epoch 1163, Loss: 0.006222550809070526, Final Batch Loss: 8.832850289763883e-05\n",
      "Epoch 1164, Loss: 0.003070926030886767, Final Batch Loss: 8.012153557501733e-05\n",
      "Epoch 1165, Loss: 0.003066261951062188, Final Batch Loss: 3.073709012824111e-05\n",
      "Epoch 1166, Loss: 0.000858233887129245, Final Batch Loss: 8.576869731768966e-05\n",
      "Epoch 1167, Loss: 0.0007153504857342341, Final Batch Loss: 9.189076990878675e-06\n",
      "Epoch 1168, Loss: 0.0003627938772297057, Final Batch Loss: 1.0145863598154392e-05\n",
      "Epoch 1169, Loss: 0.0005002814830277202, Final Batch Loss: 9.369250619783998e-06\n",
      "Epoch 1170, Loss: 0.00101185297489792, Final Batch Loss: 3.796586315729655e-05\n",
      "Epoch 1171, Loss: 0.0026937539032587665, Final Batch Loss: 1.1135358363389969e-05\n",
      "Epoch 1172, Loss: 0.0025425848708096055, Final Batch Loss: 0.002324081724509597\n",
      "Epoch 1173, Loss: 0.0009765017092604467, Final Batch Loss: 1.1530219126143493e-05\n",
      "Epoch 1174, Loss: 0.0018108435658632516, Final Batch Loss: 1.9227987650083378e-05\n",
      "Epoch 1175, Loss: 0.0006875979997857939, Final Batch Loss: 3.931748869945295e-05\n",
      "Epoch 1176, Loss: 0.00042686211736508994, Final Batch Loss: 2.288112045789603e-05\n",
      "Epoch 1177, Loss: 0.0003253452787248534, Final Batch Loss: 8.764835365582258e-05\n",
      "Epoch 1178, Loss: 0.002025418614721275, Final Batch Loss: 1.9142948076478206e-05\n",
      "Epoch 1179, Loss: 0.00352166814445809, Final Batch Loss: 5.538751793210395e-05\n",
      "Epoch 1180, Loss: 0.0007426543143083109, Final Batch Loss: 2.074403937513125e-06\n",
      "Epoch 1181, Loss: 0.0008347646298716427, Final Batch Loss: 5.369169002733543e-07\n",
      "Epoch 1182, Loss: 0.0003322964671497175, Final Batch Loss: 4.164988422417082e-05\n",
      "Epoch 1183, Loss: 0.0001519085371910478, Final Batch Loss: 1.3367134670261294e-06\n",
      "Epoch 1184, Loss: 0.005496164414012128, Final Batch Loss: 2.3728109226794913e-05\n",
      "Epoch 1185, Loss: 0.012646941505863651, Final Batch Loss: 8.123303132379078e-07\n",
      "Epoch 1186, Loss: 0.042769593644607085, Final Batch Loss: 0.00014816096518188715\n",
      "Epoch 1187, Loss: 0.0005885668998075744, Final Batch Loss: 6.586046220036224e-05\n",
      "Epoch 1188, Loss: 0.001676583559003575, Final Batch Loss: 0.0001059546775650233\n",
      "Epoch 1189, Loss: 0.0010693355028479345, Final Batch Loss: 4.94754385726992e-06\n",
      "Epoch 1190, Loss: 0.01481581499422191, Final Batch Loss: 4.800090209755581e-06\n",
      "Epoch 1191, Loss: 0.007087314385898935, Final Batch Loss: 3.237879354855977e-05\n",
      "Epoch 1192, Loss: 0.00030030111645373836, Final Batch Loss: 4.732150500785792e-06\n",
      "Epoch 1193, Loss: 0.004696814660292148, Final Batch Loss: 3.029384743058472e-06\n",
      "Epoch 1194, Loss: 0.0022523042067064125, Final Batch Loss: 6.239901995286345e-05\n",
      "Epoch 1195, Loss: 0.004195497238242751, Final Batch Loss: 4.830960460822098e-05\n",
      "Epoch 1196, Loss: 0.00909487667513531, Final Batch Loss: 0.00026289926609024405\n",
      "Epoch 1197, Loss: 0.003930195622615429, Final Batch Loss: 4.095206350029912e-06\n",
      "Epoch 1198, Loss: 0.0027012646274897634, Final Batch Loss: 1.1243042536079884e-05\n",
      "Epoch 1199, Loss: 0.0011089014947174292, Final Batch Loss: 1.0718492376327049e-05\n",
      "Epoch 1200, Loss: 0.004787339548101954, Final Batch Loss: 0.00014639088476542383\n",
      "Epoch 1201, Loss: 0.0012355399968555503, Final Batch Loss: 3.1485501494898926e-06\n",
      "Epoch 1202, Loss: 0.0002096546794234655, Final Batch Loss: 3.39025427820161e-05\n",
      "Epoch 1203, Loss: 0.0002892548534418893, Final Batch Loss: 1.634893851587549e-05\n",
      "Epoch 1204, Loss: 0.00026843065893444873, Final Batch Loss: 2.5248591555282474e-06\n",
      "Epoch 1205, Loss: 0.0018129284748056307, Final Batch Loss: 9.235473044100218e-06\n",
      "Epoch 1206, Loss: 0.001864301669456836, Final Batch Loss: 1.3057403521088418e-05\n",
      "Epoch 1207, Loss: 0.00027505708948183383, Final Batch Loss: 3.944902346120216e-05\n",
      "Epoch 1208, Loss: 0.0013907139964430826, Final Batch Loss: 0.00010245159501209855\n",
      "Epoch 1209, Loss: 0.0004427983618597864, Final Batch Loss: 1.0053497135231737e-05\n",
      "Epoch 1210, Loss: 0.003667975208941243, Final Batch Loss: 1.5327902929129777e-06\n",
      "Epoch 1211, Loss: 0.00244156184803046, Final Batch Loss: 5.256231361272512e-06\n",
      "Epoch 1212, Loss: 0.0002908324473196444, Final Batch Loss: 3.29513318320096e-06\n",
      "Epoch 1213, Loss: 0.010339720821491483, Final Batch Loss: 1.0493031368241645e-06\n",
      "Epoch 1214, Loss: 0.00023317135969591618, Final Batch Loss: 5.425207291409606e-06\n",
      "Epoch 1215, Loss: 0.0063785621197212095, Final Batch Loss: 3.8266429328359663e-05\n",
      "Epoch 1216, Loss: 0.0003151045017375509, Final Batch Loss: 5.530831003852654e-06\n",
      "Epoch 1217, Loss: 0.0012317482635353372, Final Batch Loss: 1.9961710222560214e-06\n",
      "Epoch 1218, Loss: 0.0008640090724156835, Final Batch Loss: 3.330053004901856e-05\n",
      "Epoch 1219, Loss: 0.0004314040900226246, Final Batch Loss: 1.5626271760993404e-06\n",
      "Epoch 1220, Loss: 0.000580105619292226, Final Batch Loss: 2.1535399355343543e-05\n",
      "Epoch 1221, Loss: 0.00024038540345827641, Final Batch Loss: 4.118719516554847e-06\n",
      "Epoch 1222, Loss: 0.0026050405641058205, Final Batch Loss: 7.803992957633454e-06\n",
      "Epoch 1223, Loss: 0.0004203728876746027, Final Batch Loss: 1.5129652638279367e-05\n",
      "Epoch 1224, Loss: 0.00044559434559232614, Final Batch Loss: 4.332527169026434e-06\n",
      "Epoch 1225, Loss: 0.0002873819964861468, Final Batch Loss: 2.5256829758291133e-05\n",
      "Epoch 1226, Loss: 0.0002984705538437993, Final Batch Loss: 6.622859473282006e-06\n",
      "Epoch 1227, Loss: 0.00023467582587954894, Final Batch Loss: 1.105202409235062e-05\n",
      "Epoch 1228, Loss: 0.013241284307468959, Final Batch Loss: 1.4251741049520206e-06\n",
      "Epoch 1229, Loss: 0.016223456375655587, Final Batch Loss: 1.2535931546153734e-06\n",
      "Epoch 1230, Loss: 0.00036520025855679705, Final Batch Loss: 8.500848707626574e-06\n",
      "Epoch 1231, Loss: 0.005158426823072659, Final Batch Loss: 5.372716714191483e-06\n",
      "Epoch 1232, Loss: 0.001438211731510819, Final Batch Loss: 2.6486564820515923e-05\n",
      "Epoch 1233, Loss: 0.0022050129828130594, Final Batch Loss: 7.222430213005282e-06\n",
      "Epoch 1234, Loss: 0.0033256354697641655, Final Batch Loss: 7.030713459243998e-05\n",
      "Epoch 1235, Loss: 0.0008414206699853821, Final Batch Loss: 2.4479213607264683e-05\n",
      "Epoch 1236, Loss: 0.0004257353107277595, Final Batch Loss: 2.6381781935924664e-05\n",
      "Epoch 1237, Loss: 0.0007963656942138186, Final Batch Loss: 0.00014735361037310213\n",
      "Epoch 1238, Loss: 0.0024010073379940877, Final Batch Loss: 2.8874699637526646e-05\n",
      "Epoch 1239, Loss: 0.0014378302324757897, Final Batch Loss: 5.735390459449263e-06\n",
      "Epoch 1240, Loss: 0.00025103773054979683, Final Batch Loss: 1.2290603081055451e-05\n",
      "Epoch 1241, Loss: 0.000612829117471847, Final Batch Loss: 5.170323493075557e-05\n",
      "Epoch 1242, Loss: 0.0015228789985712865, Final Batch Loss: 6.688153916911688e-06\n",
      "Epoch 1243, Loss: 0.0002623139625939075, Final Batch Loss: 5.8279965742258355e-06\n",
      "Epoch 1244, Loss: 0.00044659542271574537, Final Batch Loss: 7.017812890808273e-07\n",
      "Epoch 1245, Loss: 0.00038401661083753424, Final Batch Loss: 4.084563443029765e-06\n",
      "Epoch 1246, Loss: 0.00016536863870442176, Final Batch Loss: 3.2766499771241797e-06\n",
      "Epoch 1247, Loss: 0.00959212366740303, Final Batch Loss: 0.0018566315993666649\n",
      "Epoch 1248, Loss: 0.0002506536604869325, Final Batch Loss: 1.1338522654114058e-06\n",
      "Epoch 1249, Loss: 0.0008046201005527109, Final Batch Loss: 4.024524969281629e-05\n",
      "Epoch 1250, Loss: 0.00037678818813446924, Final Batch Loss: 3.5762431593866495e-07\n",
      "Epoch 1251, Loss: 0.0012889935589441848, Final Batch Loss: 1.6578285794821568e-05\n",
      "Epoch 1252, Loss: 0.0013377940064174254, Final Batch Loss: 1.819251338019967e-05\n",
      "Epoch 1253, Loss: 0.0005479964368078072, Final Batch Loss: 3.163206929457374e-05\n",
      "Epoch 1254, Loss: 0.0021451777213314926, Final Batch Loss: 3.04793084069388e-05\n",
      "Epoch 1255, Loss: 0.001498898788781844, Final Batch Loss: 1.6368783690268174e-05\n",
      "Epoch 1256, Loss: 0.005796807362571599, Final Batch Loss: 2.244469396828208e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1257, Loss: 0.002374370570805695, Final Batch Loss: 2.357208722969517e-05\n",
      "Epoch 1258, Loss: 0.0005212217737096125, Final Batch Loss: 3.735934342330438e-06\n",
      "Epoch 1259, Loss: 0.0016167744526001115, Final Batch Loss: 7.677149369555991e-06\n",
      "Epoch 1260, Loss: 0.0002151922603843559, Final Batch Loss: 2.8368269795464585e-06\n",
      "Epoch 1261, Loss: 0.0005118253074272161, Final Batch Loss: 0.00024072284577414393\n",
      "Epoch 1262, Loss: 0.0009235693490268204, Final Batch Loss: 7.839729505576543e-07\n",
      "Epoch 1263, Loss: 0.0005338960464200682, Final Batch Loss: 5.537215770345938e-07\n",
      "Epoch 1264, Loss: 0.0003767985855063216, Final Batch Loss: 1.0190155990130734e-06\n",
      "Epoch 1265, Loss: 8.622398794955188e-05, Final Batch Loss: 1.1266620276728645e-05\n",
      "Epoch 1266, Loss: 0.0002490258315219762, Final Batch Loss: 2.4282082449644804e-05\n",
      "Epoch 1267, Loss: 0.03608127933853211, Final Batch Loss: 0.01748703047633171\n",
      "Epoch 1268, Loss: 0.01686531672964975, Final Batch Loss: 0.016428831964731216\n",
      "Epoch 1269, Loss: 0.004780670911941343, Final Batch Loss: 0.004515948239713907\n",
      "Epoch 1270, Loss: 0.07226052299006369, Final Batch Loss: 5.1774964958895e-05\n",
      "Epoch 1271, Loss: 0.014608428055908007, Final Batch Loss: 2.1849677978025284e-06\n",
      "Epoch 1272, Loss: 0.0152337126897919, Final Batch Loss: 0.00012142737250542268\n",
      "Epoch 1273, Loss: 0.004457081930468121, Final Batch Loss: 0.0005671388353221118\n",
      "Epoch 1274, Loss: 0.011601198984408256, Final Batch Loss: 1.7255754301004345e-06\n",
      "Epoch 1275, Loss: 0.0009539279224100028, Final Batch Loss: 0.00011935522343264893\n",
      "Epoch 1276, Loss: 0.0017777337284314854, Final Batch Loss: 8.208357030525804e-05\n",
      "Epoch 1277, Loss: 0.0023267598553502467, Final Batch Loss: 8.318467735080048e-06\n",
      "Epoch 1278, Loss: 0.03804131397794208, Final Batch Loss: 1.4336414096760564e-05\n",
      "Epoch 1279, Loss: 0.00041306941216134874, Final Batch Loss: 3.200981154805049e-05\n",
      "Epoch 1280, Loss: 0.0028852205268776743, Final Batch Loss: 0.000367050408385694\n",
      "Epoch 1281, Loss: 0.002852865283784922, Final Batch Loss: 7.27849919712753e-06\n",
      "Epoch 1282, Loss: 0.0009059206336132775, Final Batch Loss: 5.080637492937967e-05\n",
      "Epoch 1283, Loss: 0.0010894650874888612, Final Batch Loss: 4.257663931639399e-06\n",
      "Epoch 1284, Loss: 0.00026875412231675, Final Batch Loss: 1.7324864529655315e-05\n",
      "Epoch 1285, Loss: 0.0007776928464409139, Final Batch Loss: 6.108011803007685e-06\n",
      "Epoch 1286, Loss: 0.0005260565844764642, Final Batch Loss: 0.00010434900468681008\n",
      "Epoch 1287, Loss: 0.0007617023138664081, Final Batch Loss: 0.00027491882792674005\n",
      "Epoch 1288, Loss: 0.005976124370590696, Final Batch Loss: 0.0052462113089859486\n",
      "Epoch 1289, Loss: 0.0014046052365301875, Final Batch Loss: 3.2694049878045917e-05\n",
      "Epoch 1290, Loss: 0.0017143574450528831, Final Batch Loss: 2.6912199245998636e-05\n",
      "Epoch 1291, Loss: 0.000554324549057128, Final Batch Loss: 0.00017930089961737394\n",
      "Epoch 1292, Loss: 0.000831019509178077, Final Batch Loss: 1.8744933640846284e-06\n",
      "Epoch 1293, Loss: 0.00022637062727426382, Final Batch Loss: 4.643132706405595e-05\n",
      "Epoch 1294, Loss: 0.023228910442412598, Final Batch Loss: 4.552293830784038e-06\n",
      "Epoch 1295, Loss: 0.010537709166328568, Final Batch Loss: 1.4390348951565102e-05\n",
      "Epoch 1296, Loss: 0.0012334793246679965, Final Batch Loss: 4.6441246013273485e-06\n",
      "Epoch 1297, Loss: 0.0004339594331668195, Final Batch Loss: 3.994485268776771e-06\n",
      "Epoch 1298, Loss: 0.01088171594767573, Final Batch Loss: 1.5117155953703332e-06\n",
      "Epoch 1299, Loss: 0.009588995742205952, Final Batch Loss: 1.8511533198761754e-05\n",
      "Epoch 1300, Loss: 0.0009292145796280238, Final Batch Loss: 4.711405381385703e-06\n",
      "Epoch 1301, Loss: 0.000357820885824367, Final Batch Loss: 2.0209767171763815e-05\n",
      "Epoch 1302, Loss: 0.0019372929732526245, Final Batch Loss: 0.0011132026556879282\n",
      "Epoch 1303, Loss: 0.00106919909512726, Final Batch Loss: 3.2853215088834986e-05\n",
      "Epoch 1304, Loss: 0.0014304661590358592, Final Batch Loss: 2.866897739295382e-05\n",
      "Epoch 1305, Loss: 0.001579770691705562, Final Batch Loss: 3.654905412986409e-06\n",
      "Epoch 1306, Loss: 0.00483804700473911, Final Batch Loss: 8.897170573618496e-07\n",
      "Epoch 1307, Loss: 0.0006048914931398031, Final Batch Loss: 5.11810276293545e-06\n",
      "Epoch 1308, Loss: 0.00033883716650962015, Final Batch Loss: 1.6774431514932076e-06\n",
      "Epoch 1309, Loss: 0.00022663591948912654, Final Batch Loss: 1.6272542779915966e-05\n",
      "Epoch 1310, Loss: 0.0012822319002907534, Final Batch Loss: 3.2182058930629864e-05\n",
      "Epoch 1311, Loss: 0.00030116773586996715, Final Batch Loss: 2.513352683308767e-06\n",
      "Epoch 1312, Loss: 0.00024480937133830594, Final Batch Loss: 5.021785000280943e-06\n",
      "Epoch 1313, Loss: 0.00033086533608184254, Final Batch Loss: 4.832778358832002e-06\n",
      "Epoch 1314, Loss: 0.0008099204187601572, Final Batch Loss: 1.3800302440358792e-05\n",
      "Epoch 1315, Loss: 0.0016667975560267223, Final Batch Loss: 0.0013910818379372358\n",
      "Epoch 1316, Loss: 0.008726357398245455, Final Batch Loss: 0.00015994867135304958\n",
      "Epoch 1317, Loss: 0.0009639108125156781, Final Batch Loss: 5.877751846128376e-06\n",
      "Epoch 1318, Loss: 0.0013217035334491811, Final Batch Loss: 0.0003847293264698237\n",
      "Epoch 1319, Loss: 0.004516878876529518, Final Batch Loss: 0.002172906417399645\n",
      "Epoch 1320, Loss: 0.004552689802949317, Final Batch Loss: 0.004118069540709257\n",
      "Epoch 1321, Loss: 0.0005087168752879734, Final Batch Loss: 9.439138921152335e-06\n",
      "Epoch 1322, Loss: 0.0003693923035825719, Final Batch Loss: 1.790723945305217e-05\n",
      "Epoch 1323, Loss: 0.009729131988478912, Final Batch Loss: 5.602256351266988e-06\n",
      "Epoch 1324, Loss: 0.001977830586838536, Final Batch Loss: 0.0013719801791012287\n",
      "Epoch 1325, Loss: 0.006871902990042145, Final Batch Loss: 4.597481620294275e-06\n",
      "Epoch 1326, Loss: 0.005179143698114785, Final Batch Loss: 0.00013587443390861154\n",
      "Epoch 1327, Loss: 0.0003656238379790011, Final Batch Loss: 1.4714801181980874e-05\n",
      "Epoch 1328, Loss: 0.0010599763079426339, Final Batch Loss: 8.723557584744412e-06\n",
      "Epoch 1329, Loss: 0.00029887459459132515, Final Batch Loss: 9.319528544438072e-06\n",
      "Epoch 1330, Loss: 0.0002988061177120471, Final Batch Loss: 1.5149834098338033e-06\n",
      "Epoch 1331, Loss: 0.0012837886715715285, Final Batch Loss: 2.1315877347660717e-06\n",
      "Epoch 1332, Loss: 0.0007939476579963411, Final Batch Loss: 1.801429425540846e-05\n",
      "Epoch 1333, Loss: 0.00010202741275122662, Final Batch Loss: 7.458429990947479e-06\n",
      "Epoch 1334, Loss: 0.001023488843998166, Final Batch Loss: 0.0005944870645180345\n",
      "Epoch 1335, Loss: 0.0031890537300114374, Final Batch Loss: 2.1508680219994858e-05\n",
      "Epoch 1336, Loss: 0.00032819231773828506, Final Batch Loss: 1.5215137864288408e-05\n",
      "Epoch 1337, Loss: 0.005837650900616609, Final Batch Loss: 5.437047548184637e-06\n",
      "Epoch 1338, Loss: 0.00047737428667460335, Final Batch Loss: 1.4238813491829205e-05\n",
      "Epoch 1339, Loss: 0.0003897489747259897, Final Batch Loss: 2.909757495217491e-05\n",
      "Epoch 1340, Loss: 0.000126159177966656, Final Batch Loss: 4.6256523091869894e-06\n",
      "Epoch 1341, Loss: 0.0025058821383936447, Final Batch Loss: 6.413642404368147e-05\n",
      "Epoch 1342, Loss: 0.003998304170465872, Final Batch Loss: 1.3590359230875038e-05\n",
      "Epoch 1343, Loss: 0.0004239350413399734, Final Batch Loss: 1.2461476217140444e-05\n",
      "Epoch 1344, Loss: 9.986318369215041e-05, Final Batch Loss: 9.735746061778627e-06\n",
      "Epoch 1345, Loss: 0.00012071007455460858, Final Batch Loss: 4.811541884919279e-07\n",
      "Epoch 1346, Loss: 0.0005084338979770564, Final Batch Loss: 6.4603163991705514e-06\n",
      "Epoch 1347, Loss: 0.0010284328516263486, Final Batch Loss: 3.1808644962438848e-06\n",
      "Epoch 1348, Loss: 0.0009424287321166958, Final Batch Loss: 0.000871925032697618\n",
      "Epoch 1349, Loss: 0.00013998866972997348, Final Batch Loss: 1.3116992704453878e-05\n",
      "Epoch 1350, Loss: 0.00030787425737344165, Final Batch Loss: 1.0079520507133566e-06\n",
      "Epoch 1351, Loss: 0.00014769214095622374, Final Batch Loss: 2.7449518711364362e-06\n",
      "Epoch 1352, Loss: 0.0013899826657279846, Final Batch Loss: 1.2868873454863206e-05\n",
      "Epoch 1353, Loss: 0.0005171349248485058, Final Batch Loss: 8.168108251993544e-06\n",
      "Epoch 1354, Loss: 0.05575596324547405, Final Batch Loss: 0.0016492449212819338\n",
      "Epoch 1355, Loss: 0.05529547128253398, Final Batch Loss: 3.170776108163409e-05\n",
      "Epoch 1356, Loss: 0.059061649206796574, Final Batch Loss: 7.346186976064928e-06\n",
      "Epoch 1357, Loss: 0.0020780522806944646, Final Batch Loss: 3.461887899902649e-05\n",
      "Epoch 1358, Loss: 0.003339903085361584, Final Batch Loss: 3.35902877850458e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1359, Loss: 0.00304714547291951, Final Batch Loss: 0.00017521760310046375\n",
      "Epoch 1360, Loss: 0.0007470208201993955, Final Batch Loss: 2.9094824640196748e-05\n",
      "Epoch 1361, Loss: 0.0014074620266910642, Final Batch Loss: 4.697821714216843e-05\n",
      "Epoch 1362, Loss: 0.0004683549768742523, Final Batch Loss: 2.3731265173410065e-05\n",
      "Epoch 1363, Loss: 0.0010117190731762093, Final Batch Loss: 0.00013038309407420456\n",
      "Epoch 1364, Loss: 0.0006572054189746268, Final Batch Loss: 1.766217428667005e-05\n",
      "Epoch 1365, Loss: 0.002471676190452854, Final Batch Loss: 5.9062326727143954e-06\n",
      "Epoch 1366, Loss: 0.0006313082931228564, Final Batch Loss: 1.2771733963745646e-05\n",
      "Epoch 1367, Loss: 0.0018479649620530836, Final Batch Loss: 3.856501734844642e-06\n",
      "Epoch 1368, Loss: 0.0037732252935711585, Final Batch Loss: 5.777392743766541e-06\n",
      "Epoch 1369, Loss: 0.0009657489331402758, Final Batch Loss: 1.1414515029173344e-05\n",
      "Epoch 1370, Loss: 0.0018052188211186149, Final Batch Loss: 6.809410933783511e-06\n",
      "Epoch 1371, Loss: 0.0005398509060796641, Final Batch Loss: 2.1032813037891174e-06\n",
      "Epoch 1372, Loss: 0.00256985350620198, Final Batch Loss: 7.049531996017322e-05\n",
      "Epoch 1373, Loss: 0.0019970615610986897, Final Batch Loss: 9.123171480496239e-07\n",
      "Epoch 1374, Loss: 0.0010737329971561849, Final Batch Loss: 6.206441321410239e-05\n",
      "Epoch 1375, Loss: 0.00048009494503276073, Final Batch Loss: 2.688528911676258e-05\n",
      "Epoch 1376, Loss: 0.0004486738805553614, Final Batch Loss: 3.9401861613441724e-06\n",
      "Epoch 1377, Loss: 0.0002589158965520255, Final Batch Loss: 4.492047446547076e-05\n",
      "Epoch 1378, Loss: 0.0002041077176500039, Final Batch Loss: 3.54562621396326e-06\n",
      "Epoch 1379, Loss: 0.0006788982907437457, Final Batch Loss: 1.2636195606319234e-05\n",
      "Epoch 1380, Loss: 0.0004459396566289797, Final Batch Loss: 1.1121594070573337e-05\n",
      "Epoch 1381, Loss: 0.00036354336612021143, Final Batch Loss: 3.250238296459429e-05\n",
      "Epoch 1382, Loss: 0.00041254455709349713, Final Batch Loss: 3.188543632859364e-05\n",
      "Epoch 1383, Loss: 0.01813926542899935, Final Batch Loss: 0.00010018050670623779\n",
      "Epoch 1384, Loss: 0.027514550422438333, Final Batch Loss: 2.235623287560884e-05\n",
      "Epoch 1385, Loss: 0.014641917367271162, Final Batch Loss: 2.155584525098675e-06\n",
      "Epoch 1386, Loss: 0.0024883049841264437, Final Batch Loss: 9.35192838369403e-06\n",
      "Epoch 1387, Loss: 0.0010851455313058977, Final Batch Loss: 1.0797270988405216e-05\n",
      "Epoch 1388, Loss: 0.00078707360307817, Final Batch Loss: 1.1946366612392012e-05\n",
      "Epoch 1389, Loss: 0.003054896031244425, Final Batch Loss: 4.665841333917342e-05\n",
      "Epoch 1390, Loss: 0.00045287303737495677, Final Batch Loss: 3.443303648964502e-05\n",
      "Epoch 1391, Loss: 0.0026597769638101454, Final Batch Loss: 1.8309170627617277e-05\n",
      "Epoch 1392, Loss: 0.0006047774631952052, Final Batch Loss: 4.041265128762461e-06\n",
      "Epoch 1393, Loss: 0.00047390401709890284, Final Batch Loss: 7.147641554183792e-07\n",
      "Epoch 1394, Loss: 0.0003032701965821616, Final Batch Loss: 2.595100113467197e-06\n",
      "Epoch 1395, Loss: 0.0010963920005906402, Final Batch Loss: 7.793235454300884e-06\n",
      "Epoch 1396, Loss: 0.002624568809324046, Final Batch Loss: 2.5003926111821784e-06\n",
      "Epoch 1397, Loss: 0.001233490965432793, Final Batch Loss: 0.0010811620159074664\n",
      "Epoch 1398, Loss: 0.0005192203730075562, Final Batch Loss: 9.910253720590845e-05\n",
      "Epoch 1399, Loss: 0.0003905472290171019, Final Batch Loss: 2.4873679649317637e-05\n",
      "Epoch 1400, Loss: 0.01688963929836973, Final Batch Loss: 0.00030430941842496395\n",
      "Epoch 1401, Loss: 0.031703526728051656, Final Batch Loss: 7.112052117008716e-05\n",
      "Epoch 1402, Loss: 0.0008033328015244479, Final Batch Loss: 1.103921931644436e-05\n",
      "Epoch 1403, Loss: 0.0003231666578358272, Final Batch Loss: 2.7688525733537972e-05\n",
      "Epoch 1404, Loss: 0.0004406613220453437, Final Batch Loss: 4.736996197607368e-05\n",
      "Epoch 1405, Loss: 0.0003718232965184143, Final Batch Loss: 3.884479610860581e-06\n",
      "Epoch 1406, Loss: 0.00047011689707687765, Final Batch Loss: 3.198802232873277e-06\n",
      "Epoch 1407, Loss: 0.0003423331259000406, Final Batch Loss: 1.1761062523873989e-05\n",
      "Epoch 1408, Loss: 0.00037960989811836043, Final Batch Loss: 5.399083602242172e-05\n",
      "Epoch 1409, Loss: 0.00024799796642582805, Final Batch Loss: 4.469103714654921e-06\n",
      "Epoch 1410, Loss: 0.0001644295938376672, Final Batch Loss: 1.0486928658792749e-05\n",
      "Epoch 1411, Loss: 0.0002947828983224099, Final Batch Loss: 2.1436835595523007e-06\n",
      "Epoch 1412, Loss: 0.00045634171317487926, Final Batch Loss: 1.215776865137741e-05\n",
      "Epoch 1413, Loss: 0.00023471773602068424, Final Batch Loss: 2.700801269384101e-05\n",
      "Epoch 1414, Loss: 0.002174555813326151, Final Batch Loss: 0.0005723967333324254\n",
      "Epoch 1415, Loss: 0.0036592162651913895, Final Batch Loss: 0.00010646510781953111\n",
      "Epoch 1416, Loss: 0.000397383036897736, Final Batch Loss: 4.858967258769553e-06\n",
      "Epoch 1417, Loss: 0.0017090570218556422, Final Batch Loss: 1.908231570268981e-05\n",
      "Epoch 1418, Loss: 0.00015876355585930924, Final Batch Loss: 1.0543451935518533e-05\n",
      "Epoch 1419, Loss: 0.0004275233481791929, Final Batch Loss: 1.5271241863956675e-05\n",
      "Epoch 1420, Loss: 0.0004247063168065779, Final Batch Loss: 2.1416535673779435e-05\n",
      "Epoch 1421, Loss: 0.006018802705511916, Final Batch Loss: 1.5145246834435966e-06\n",
      "Epoch 1422, Loss: 0.0008152488289852045, Final Batch Loss: 0.0002186876954510808\n",
      "Epoch 1423, Loss: 0.0021125635083762972, Final Batch Loss: 9.546072305965936e-07\n",
      "Epoch 1424, Loss: 0.008014727867021065, Final Batch Loss: 8.772997716732789e-06\n",
      "Epoch 1425, Loss: 0.010009353962914247, Final Batch Loss: 0.0001990321761695668\n",
      "Epoch 1426, Loss: 0.0015629488602826314, Final Batch Loss: 8.370632713194937e-05\n",
      "Epoch 1427, Loss: 0.001645621187776669, Final Batch Loss: 5.6480832427041605e-05\n",
      "Epoch 1428, Loss: 0.003581664839146015, Final Batch Loss: 3.0797709769103676e-05\n",
      "Epoch 1429, Loss: 0.0012310950155551836, Final Batch Loss: 1.3386290902417386e-06\n",
      "Epoch 1430, Loss: 0.0006730754382715531, Final Batch Loss: 3.0010849059181055e-06\n",
      "Epoch 1431, Loss: 0.000597442908940593, Final Batch Loss: 2.0581685475917766e-06\n",
      "Epoch 1432, Loss: 0.0010028408607922756, Final Batch Loss: 4.579897449730197e-06\n",
      "Epoch 1433, Loss: 0.00019836690626107156, Final Batch Loss: 3.984393515565898e-06\n",
      "Epoch 1434, Loss: 0.001167298879977352, Final Batch Loss: 5.420354227680946e-06\n",
      "Epoch 1435, Loss: 0.0009128999963650131, Final Batch Loss: 5.423949914984405e-05\n",
      "Epoch 1436, Loss: 8.03271672111805e-05, Final Batch Loss: 5.811364758301352e-07\n",
      "Epoch 1437, Loss: 0.00023258646868384858, Final Batch Loss: 7.44070639484562e-05\n",
      "Epoch 1438, Loss: 0.000547739071862452, Final Batch Loss: 1.9411129414947936e-06\n",
      "Epoch 1439, Loss: 0.00012564796693936842, Final Batch Loss: 6.514002507174155e-06\n",
      "Epoch 1440, Loss: 0.0005612464818653962, Final Batch Loss: 3.885927071678452e-05\n",
      "Epoch 1441, Loss: 0.00024060448129148426, Final Batch Loss: 2.5446431664022384e-06\n",
      "Epoch 1442, Loss: 0.00018138502667852663, Final Batch Loss: 4.0874419937608764e-05\n",
      "Epoch 1443, Loss: 0.0005675021744409037, Final Batch Loss: 1.129092538576515e-06\n",
      "Epoch 1444, Loss: 0.00034263931780742496, Final Batch Loss: 1.6173926269402727e-05\n",
      "Epoch 1445, Loss: 0.0006498613547805121, Final Batch Loss: 4.647259174817009e-06\n",
      "Epoch 1446, Loss: 0.003021733227342338, Final Batch Loss: 6.094660784583539e-05\n",
      "Epoch 1447, Loss: 0.012202909450479638, Final Batch Loss: 4.624917346518487e-05\n",
      "Epoch 1448, Loss: 0.0001725153271650015, Final Batch Loss: 1.2703883385256631e-06\n",
      "Epoch 1449, Loss: 0.0002161036362338109, Final Batch Loss: 3.154938167426735e-05\n",
      "Epoch 1450, Loss: 0.00016579605158995037, Final Batch Loss: 7.5160701271670405e-06\n",
      "Epoch 1451, Loss: 0.0007433941194676663, Final Batch Loss: 0.00040924944914877415\n",
      "Epoch 1452, Loss: 7.474091776771274e-05, Final Batch Loss: 2.8555296012200415e-06\n",
      "Epoch 1453, Loss: 0.0007922781043134819, Final Batch Loss: 1.3895996744395234e-06\n",
      "Epoch 1454, Loss: 0.00016776738846147055, Final Batch Loss: 3.9907208702061325e-06\n",
      "Epoch 1455, Loss: 0.00022357849456966505, Final Batch Loss: 7.47624144423753e-05\n",
      "Epoch 1456, Loss: 0.00020711803949780005, Final Batch Loss: 7.338480372709455e-06\n",
      "Epoch 1457, Loss: 0.0005852626815112671, Final Batch Loss: 2.5731545974849723e-05\n",
      "Epoch 1458, Loss: 0.00014417388490528538, Final Batch Loss: 1.3207927622715943e-05\n",
      "Epoch 1459, Loss: 0.005282623162827349, Final Batch Loss: 6.6121820054831915e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1460, Loss: 0.00018244014414392495, Final Batch Loss: 2.3174434318207204e-05\n",
      "Epoch 1461, Loss: 0.0003279234595510161, Final Batch Loss: 1.5993977285688743e-05\n",
      "Epoch 1462, Loss: 0.00010260576536325061, Final Batch Loss: 1.401103077114385e-06\n",
      "Epoch 1463, Loss: 0.00027302163050535455, Final Batch Loss: 6.137340096756816e-05\n",
      "Epoch 1464, Loss: 0.0005716888455538083, Final Batch Loss: 8.228970500567812e-07\n",
      "Epoch 1465, Loss: 0.00038018627174096764, Final Batch Loss: 4.89137619297253e-06\n",
      "Epoch 1466, Loss: 0.00045084641990911223, Final Batch Loss: 8.718356184544973e-06\n",
      "Epoch 1467, Loss: 0.0007989510230572705, Final Batch Loss: 2.4998910248541506e-06\n",
      "Epoch 1468, Loss: 0.00033713072448904313, Final Batch Loss: 4.267286840331508e-06\n",
      "Epoch 1469, Loss: 0.0013420490843998323, Final Batch Loss: 6.113520157668972e-06\n",
      "Epoch 1470, Loss: 0.00021908522927560625, Final Batch Loss: 1.8987384464708157e-05\n",
      "Epoch 1471, Loss: 0.0001269874968699014, Final Batch Loss: 3.922297651115514e-07\n",
      "Epoch 1472, Loss: 3.027423720425304e-05, Final Batch Loss: 4.619138508132892e-06\n",
      "Epoch 1473, Loss: 0.0004767785761146115, Final Batch Loss: 3.8374291762011126e-05\n",
      "Epoch 1474, Loss: 0.00036631231623118765, Final Batch Loss: 1.4630203395427088e-06\n",
      "Epoch 1475, Loss: 0.10028495004553406, Final Batch Loss: 7.967273631948046e-06\n",
      "Epoch 1476, Loss: 0.0023312628536587, Final Batch Loss: 7.316544269997394e-06\n",
      "Epoch 1477, Loss: 0.001203688701025385, Final Batch Loss: 2.064346699626185e-05\n",
      "Epoch 1478, Loss: 0.0014692431625462632, Final Batch Loss: 9.032358502736315e-05\n",
      "Epoch 1479, Loss: 0.0006238418326347528, Final Batch Loss: 1.5775327483424917e-05\n",
      "Epoch 1480, Loss: 0.0012962767521003116, Final Batch Loss: 3.031255118912668e-06\n",
      "Epoch 1481, Loss: 0.00031991021717203694, Final Batch Loss: 4.576941591949435e-06\n",
      "Epoch 1482, Loss: 0.00020024532352636015, Final Batch Loss: 3.4527573006926104e-05\n",
      "Epoch 1483, Loss: 0.00022114499068948135, Final Batch Loss: 1.375184410790098e-06\n",
      "Epoch 1484, Loss: 0.00031210734766773385, Final Batch Loss: 3.770178864215268e-06\n",
      "Epoch 1485, Loss: 0.009030385280993869, Final Batch Loss: 0.00048552409862168133\n",
      "Epoch 1486, Loss: 0.004095306188901304, Final Batch Loss: 0.0005622659809887409\n",
      "Epoch 1487, Loss: 0.00026304699116508345, Final Batch Loss: 2.3628651888429886e-06\n",
      "Epoch 1488, Loss: 0.00045040215195513156, Final Batch Loss: 0.00014897430082783103\n",
      "Epoch 1489, Loss: 0.0028306175714760684, Final Batch Loss: 4.833455022890121e-05\n",
      "Epoch 1490, Loss: 0.000264504780830066, Final Batch Loss: 7.338233990594745e-05\n",
      "Epoch 1491, Loss: 0.001353098726326607, Final Batch Loss: 1.0637271543600946e-06\n",
      "Epoch 1492, Loss: 0.0013153852648883912, Final Batch Loss: 6.180382479215041e-05\n",
      "Epoch 1493, Loss: 0.00019193629862002126, Final Batch Loss: 3.300442131148884e-06\n",
      "Epoch 1494, Loss: 0.0002663210675564187, Final Batch Loss: 4.752387758344412e-05\n",
      "Epoch 1495, Loss: 0.0002089846523176675, Final Batch Loss: 3.2284456210618373e-06\n",
      "Epoch 1496, Loss: 0.00015452864863618743, Final Batch Loss: 2.0632262021536008e-05\n",
      "Epoch 1497, Loss: 0.005428859125004237, Final Batch Loss: 2.147042778233299e-06\n",
      "Epoch 1498, Loss: 0.00893846280314392, Final Batch Loss: 5.77597666051588e-06\n",
      "Epoch 1499, Loss: 0.0005044243871452636, Final Batch Loss: 4.041450665681623e-05\n",
      "Epoch 1500, Loss: 0.03913278094967154, Final Batch Loss: 8.567193617636804e-06\n",
      "Epoch 1501, Loss: 0.000584021603117435, Final Batch Loss: 5.925770528847352e-05\n",
      "Epoch 1502, Loss: 0.0014563975189503253, Final Batch Loss: 1.4605632713937666e-05\n",
      "Epoch 1503, Loss: 0.0011937351432607102, Final Batch Loss: 1.3594688425655477e-05\n",
      "Epoch 1504, Loss: 0.0005167953668205882, Final Batch Loss: 2.0876193957519718e-05\n",
      "Epoch 1505, Loss: 0.0019348824603184767, Final Batch Loss: 5.965040145383682e-06\n",
      "Epoch 1506, Loss: 0.0008994230938697001, Final Batch Loss: 7.096527497196803e-06\n",
      "Epoch 1507, Loss: 0.0016289895708609947, Final Batch Loss: 4.423937571118586e-05\n",
      "Epoch 1508, Loss: 0.00020310597258799135, Final Batch Loss: 5.47402532902197e-06\n",
      "Epoch 1509, Loss: 0.00030845150240566, Final Batch Loss: 1.4863499927741941e-05\n",
      "Epoch 1510, Loss: 0.0010032150510141946, Final Batch Loss: 3.684024704853073e-05\n",
      "Epoch 1511, Loss: 0.0003450272694180967, Final Batch Loss: 4.752798849949613e-05\n",
      "Epoch 1512, Loss: 0.0003002730890102612, Final Batch Loss: 1.3203532034822274e-05\n",
      "Epoch 1513, Loss: 0.00015486740133496824, Final Batch Loss: 7.617989922437118e-06\n",
      "Epoch 1514, Loss: 0.000452519705333998, Final Batch Loss: 6.959989491406304e-07\n",
      "Epoch 1515, Loss: 0.00029862106208611294, Final Batch Loss: 1.1000054655596614e-05\n",
      "Epoch 1516, Loss: 0.0012743071976615283, Final Batch Loss: 2.914531432907097e-05\n",
      "Epoch 1517, Loss: 0.00010291715460652995, Final Batch Loss: 7.007723525020992e-06\n",
      "Epoch 1518, Loss: 0.0002809287650507031, Final Batch Loss: 2.453268052704516e-06\n",
      "Epoch 1519, Loss: 0.0002668408000090494, Final Batch Loss: 5.192850039748009e-06\n",
      "Epoch 1520, Loss: 0.00045342440239437565, Final Batch Loss: 0.00019981495279353112\n",
      "Epoch 1521, Loss: 0.00013346021020765875, Final Batch Loss: 5.134480488777626e-06\n",
      "Epoch 1522, Loss: 0.0006381096687846366, Final Batch Loss: 4.686515694629634e-06\n",
      "Epoch 1523, Loss: 0.0006900917178427335, Final Batch Loss: 1.547771717014257e-05\n",
      "Epoch 1524, Loss: 0.00034259934011515725, Final Batch Loss: 3.4811641853593756e-06\n",
      "Epoch 1525, Loss: 0.00036965989670534327, Final Batch Loss: 5.4431107855634764e-05\n",
      "Epoch 1526, Loss: 0.0001390750528571516, Final Batch Loss: 8.68048573465785e-06\n",
      "Epoch 1527, Loss: 0.0014724585166447923, Final Batch Loss: 0.001156073878519237\n",
      "Epoch 1528, Loss: 0.00016204131222252727, Final Batch Loss: 2.361727183597395e-06\n",
      "Epoch 1529, Loss: 0.00023012259543975233, Final Batch Loss: 8.090503797575366e-06\n",
      "Epoch 1530, Loss: 0.03721542250764287, Final Batch Loss: 6.485550693469122e-05\n",
      "Epoch 1531, Loss: 0.001956794778834592, Final Batch Loss: 1.0531702173466329e-05\n",
      "Epoch 1532, Loss: 0.000637825451349272, Final Batch Loss: 7.062021722958889e-06\n",
      "Epoch 1533, Loss: 0.0005669293069558989, Final Batch Loss: 1.4712546771988855e-06\n",
      "Epoch 1534, Loss: 0.00028460187638756906, Final Batch Loss: 4.812176484847441e-06\n",
      "Epoch 1535, Loss: 0.001296438243571174, Final Batch Loss: 5.756920018029632e-06\n",
      "Epoch 1536, Loss: 0.0005082076145299652, Final Batch Loss: 4.32117230957374e-05\n",
      "Epoch 1537, Loss: 0.03911051640000096, Final Batch Loss: 0.02716345526278019\n",
      "Epoch 1538, Loss: 0.0018410314893344548, Final Batch Loss: 7.926899343146943e-06\n",
      "Epoch 1539, Loss: 0.00157906345077663, Final Batch Loss: 0.00037444059853442013\n",
      "Epoch 1540, Loss: 0.0003635717409906647, Final Batch Loss: 7.722258487774525e-06\n",
      "Epoch 1541, Loss: 0.00032129231965427607, Final Batch Loss: 1.182749019790208e-05\n",
      "Epoch 1542, Loss: 0.0005693041150607314, Final Batch Loss: 2.0267585568944924e-05\n",
      "Epoch 1543, Loss: 0.0006742389355736123, Final Batch Loss: 7.825369152669737e-07\n",
      "Epoch 1544, Loss: 0.002558318799742665, Final Batch Loss: 3.403011305636028e-06\n",
      "Epoch 1545, Loss: 0.000302028579767466, Final Batch Loss: 1.2632256584765855e-05\n",
      "Epoch 1546, Loss: 0.00037403994892315495, Final Batch Loss: 1.6208042552534607e-06\n",
      "Epoch 1547, Loss: 0.0015706815712519528, Final Batch Loss: 8.20058849058114e-05\n",
      "Epoch 1548, Loss: 0.02747504005543533, Final Batch Loss: 9.273783689422999e-06\n",
      "Epoch 1549, Loss: 0.0024511712252888174, Final Batch Loss: 1.2718113566734246e-06\n",
      "Epoch 1550, Loss: 0.0007151392419473268, Final Batch Loss: 3.986549927503802e-05\n",
      "Epoch 1551, Loss: 0.001193101402350294, Final Batch Loss: 1.7958180251298472e-05\n",
      "Epoch 1552, Loss: 0.0010274573432980105, Final Batch Loss: 5.941029667155817e-05\n",
      "Epoch 1553, Loss: 0.019549263686201357, Final Batch Loss: 8.941667147155385e-06\n",
      "Epoch 1554, Loss: 0.0023122726290694118, Final Batch Loss: 0.0008120319689624012\n",
      "Epoch 1555, Loss: 0.0023883638314146083, Final Batch Loss: 0.0011999516282230616\n",
      "Epoch 1556, Loss: 0.0021757087524747476, Final Batch Loss: 2.1425461454782635e-05\n",
      "Epoch 1557, Loss: 0.00030021566749383055, Final Batch Loss: 1.0422452760394663e-05\n",
      "Epoch 1558, Loss: 0.0004787186110206676, Final Batch Loss: 9.096602298086509e-06\n",
      "Epoch 1559, Loss: 0.0010532334809738586, Final Batch Loss: 3.879054872868437e-07\n",
      "Epoch 1560, Loss: 0.0003282795642576275, Final Batch Loss: 1.1545643019417184e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1561, Loss: 0.00025202313145200606, Final Batch Loss: 4.207638994557783e-06\n",
      "Epoch 1562, Loss: 0.0008228138810864039, Final Batch Loss: 8.441787031188142e-06\n",
      "Epoch 1563, Loss: 0.000123336931551421, Final Batch Loss: 6.497793492599158e-06\n",
      "Epoch 1564, Loss: 0.0015336073688558827, Final Batch Loss: 2.827449316100683e-05\n",
      "Epoch 1565, Loss: 0.0011252723547841015, Final Batch Loss: 4.9964739446295425e-05\n",
      "Epoch 1566, Loss: 0.0010557300331583974, Final Batch Loss: 0.0006792819476686418\n",
      "Epoch 1567, Loss: 0.001125122130872569, Final Batch Loss: 1.4549148090736708e-06\n",
      "Epoch 1568, Loss: 0.0006230437830936353, Final Batch Loss: 2.88507199002197e-05\n",
      "Epoch 1569, Loss: 0.0002639936528794351, Final Batch Loss: 1.3742163673668983e-06\n",
      "Epoch 1570, Loss: 0.00021559233300649794, Final Batch Loss: 3.1663195841247216e-05\n",
      "Epoch 1571, Loss: 0.0007090507707516736, Final Batch Loss: 2.696374167499016e-06\n",
      "Epoch 1572, Loss: 0.0010171201274715713, Final Batch Loss: 1.7254511703868047e-06\n",
      "Epoch 1573, Loss: 0.0011299729189602203, Final Batch Loss: 6.787147867726162e-06\n",
      "Epoch 1574, Loss: 0.0005413177528907909, Final Batch Loss: 6.650279829045758e-05\n",
      "Epoch 1575, Loss: 0.0002193234652096976, Final Batch Loss: 5.3483036026591435e-05\n",
      "Epoch 1576, Loss: 0.0003028911920637256, Final Batch Loss: 1.3287996807775926e-05\n",
      "Epoch 1577, Loss: 0.00023132793860725087, Final Batch Loss: 7.245213964779396e-06\n",
      "Epoch 1578, Loss: 0.00018669890218347973, Final Batch Loss: 3.2832895158207975e-06\n",
      "Epoch 1579, Loss: 0.00017027929243340623, Final Batch Loss: 3.4100790799129754e-05\n",
      "Epoch 1580, Loss: 0.00011332270156572122, Final Batch Loss: 3.1488871172768995e-05\n",
      "Epoch 1581, Loss: 0.0002882306841343052, Final Batch Loss: 4.01230090574245e-06\n",
      "Epoch 1582, Loss: 8.278262455974073e-05, Final Batch Loss: 1.9014767076441785e-06\n",
      "Epoch 1583, Loss: 0.0001315750411947647, Final Batch Loss: 1.0633793863235041e-05\n",
      "Epoch 1584, Loss: 0.0008852789101130298, Final Batch Loss: 2.7242724627285497e-06\n",
      "Epoch 1585, Loss: 0.0009146136168283192, Final Batch Loss: 7.511471267207526e-06\n",
      "Epoch 1586, Loss: 0.0008672760439907279, Final Batch Loss: 1.2208948874103953e-06\n",
      "Epoch 1587, Loss: 0.00014869121534388796, Final Batch Loss: 3.3082131267292425e-05\n",
      "Epoch 1588, Loss: 0.003055656136140783, Final Batch Loss: 9.950106516498636e-08\n",
      "Epoch 1589, Loss: 0.0028446604925420615, Final Batch Loss: 0.00012719912047032267\n",
      "Epoch 1590, Loss: 0.009623451021283813, Final Batch Loss: 9.969325219572056e-06\n",
      "Epoch 1591, Loss: 0.0027641898817591937, Final Batch Loss: 2.3761915599607164e-06\n",
      "Epoch 1592, Loss: 0.08501630223082657, Final Batch Loss: 7.643377102795057e-06\n",
      "Epoch 1593, Loss: 0.0017664198566080813, Final Batch Loss: 0.00019720257841981947\n",
      "Epoch 1594, Loss: 0.0007187131079717801, Final Batch Loss: 1.2766294275934342e-05\n",
      "Epoch 1595, Loss: 0.009038944342478317, Final Batch Loss: 0.0001336652203463018\n",
      "Epoch 1596, Loss: 0.016975241496766103, Final Batch Loss: 3.293559348094277e-05\n",
      "Epoch 1597, Loss: 0.0061391894268467695, Final Batch Loss: 2.1345229015423683e-06\n",
      "Epoch 1598, Loss: 0.03250816659760858, Final Batch Loss: 8.797924965620041e-05\n",
      "Epoch 1599, Loss: 0.00818683758620864, Final Batch Loss: 0.007826622575521469\n",
      "Epoch 1600, Loss: 0.01186807720523575, Final Batch Loss: 0.0089379558339715\n",
      "Epoch 1601, Loss: 0.0011869557465615799, Final Batch Loss: 0.00013367965584620833\n",
      "Epoch 1602, Loss: 0.00023652608695101662, Final Batch Loss: 7.324264970520744e-06\n",
      "Epoch 1603, Loss: 0.011028878128627184, Final Batch Loss: 4.521654773270711e-05\n",
      "Epoch 1604, Loss: 0.0010029982879586896, Final Batch Loss: 5.673941632267088e-05\n",
      "Epoch 1605, Loss: 0.0032330878379980277, Final Batch Loss: 4.3853488023160025e-05\n",
      "Epoch 1606, Loss: 0.0004884803306595131, Final Batch Loss: 1.67532325576758e-05\n",
      "Epoch 1607, Loss: 0.00219707426720106, Final Batch Loss: 3.5787477372650756e-06\n",
      "Epoch 1608, Loss: 0.0032365732383823342, Final Batch Loss: 1.1370429092494305e-05\n",
      "Epoch 1609, Loss: 0.005368182428696855, Final Batch Loss: 1.2188017535663676e-05\n",
      "Epoch 1610, Loss: 0.00043083775267405144, Final Batch Loss: 1.069993322744267e-05\n",
      "Epoch 1611, Loss: 0.002516565170594731, Final Batch Loss: 0.0013773593818768859\n",
      "Epoch 1612, Loss: 0.0006258489009951518, Final Batch Loss: 4.013885700260289e-06\n",
      "Epoch 1613, Loss: 0.00016642879029404867, Final Batch Loss: 1.2405959068928496e-06\n",
      "Epoch 1614, Loss: 0.0003314122546953513, Final Batch Loss: 6.341694188449765e-06\n",
      "Epoch 1615, Loss: 0.0005486261326836939, Final Batch Loss: 4.7867101784504484e-06\n",
      "Epoch 1616, Loss: 0.0020188684303548143, Final Batch Loss: 1.3914833516537328e-06\n",
      "Epoch 1617, Loss: 0.00035506728090695105, Final Batch Loss: 5.0635273510124534e-05\n",
      "Epoch 1618, Loss: 0.0005302824826003416, Final Batch Loss: 1.2439362535587861e-06\n",
      "Epoch 1619, Loss: 0.0014439205455119009, Final Batch Loss: 0.0013277375837787986\n",
      "Epoch 1620, Loss: 0.0007508103626605589, Final Batch Loss: 3.7737885577371344e-05\n",
      "Epoch 1621, Loss: 0.0006952483855684477, Final Batch Loss: 1.7400009255652549e-06\n",
      "Epoch 1622, Loss: 0.00018833975980214746, Final Batch Loss: 2.444499159537372e-06\n",
      "Epoch 1623, Loss: 0.00032057690532383276, Final Batch Loss: 6.2795925259706564e-06\n",
      "Epoch 1624, Loss: 0.00027236090977567073, Final Batch Loss: 2.0749401301145554e-05\n",
      "Epoch 1625, Loss: 0.004273784332028185, Final Batch Loss: 6.394883257598849e-06\n",
      "Epoch 1626, Loss: 0.0016781230583546858, Final Batch Loss: 0.0013711295323446393\n",
      "Epoch 1627, Loss: 0.00022787135583257623, Final Batch Loss: 2.6646039259503596e-05\n",
      "Epoch 1628, Loss: 0.0006583147251149057, Final Batch Loss: 7.242369520099601e-06\n",
      "Epoch 1629, Loss: 0.00013030441778028035, Final Batch Loss: 1.607356171007268e-05\n",
      "Epoch 1630, Loss: 0.00026880939833517914, Final Batch Loss: 1.6630933714623097e-06\n",
      "Epoch 1631, Loss: 0.00026243962417993316, Final Batch Loss: 7.030620326986536e-05\n",
      "Epoch 1632, Loss: 0.0004913622337880952, Final Batch Loss: 4.704667844634969e-06\n",
      "Epoch 1633, Loss: 0.009924528942235611, Final Batch Loss: 3.299288437119685e-05\n",
      "Epoch 1634, Loss: 0.00044481374447968847, Final Batch Loss: 6.8399363044591155e-06\n",
      "Epoch 1635, Loss: 0.0003511604022605752, Final Batch Loss: 1.2014255844405852e-05\n",
      "Epoch 1636, Loss: 0.0005023291275847441, Final Batch Loss: 9.351821972813923e-06\n",
      "Epoch 1637, Loss: 0.0005708500175387599, Final Batch Loss: 2.095350282615982e-05\n",
      "Epoch 1638, Loss: 0.0009863385548669612, Final Batch Loss: 1.3833054254064336e-05\n",
      "Epoch 1639, Loss: 0.00018498969859592762, Final Batch Loss: 1.8346960359849618e-06\n",
      "Epoch 1640, Loss: 0.00024285313560312716, Final Batch Loss: 1.0449125511513557e-05\n",
      "Epoch 1641, Loss: 0.0013582123010564828, Final Batch Loss: 1.22325573101989e-05\n",
      "Epoch 1642, Loss: 0.00019272408121651097, Final Batch Loss: 9.980439244827721e-06\n",
      "Epoch 1643, Loss: 0.0002333220920718304, Final Batch Loss: 5.474917088577058e-07\n",
      "Epoch 1644, Loss: 0.0014272081712078943, Final Batch Loss: 1.772493305907119e-05\n",
      "Epoch 1645, Loss: 9.415157825287679e-05, Final Batch Loss: 2.4930636755016167e-06\n",
      "Epoch 1646, Loss: 0.0006792927504193358, Final Batch Loss: 1.7164400105684763e-06\n",
      "Epoch 1647, Loss: 0.000286295728415098, Final Batch Loss: 1.8105529306922108e-05\n",
      "Epoch 1648, Loss: 0.00010044296112710072, Final Batch Loss: 2.6080642783199437e-05\n",
      "Epoch 1649, Loss: 0.0008971738286476238, Final Batch Loss: 2.746204472714453e-06\n",
      "Epoch 1650, Loss: 0.0014363972439852546, Final Batch Loss: 9.613631135607648e-08\n",
      "Epoch 1651, Loss: 0.00014813092047916143, Final Batch Loss: 3.22552295983769e-05\n",
      "Epoch 1652, Loss: 0.00046019274134323496, Final Batch Loss: 2.578703515609959e-06\n",
      "Epoch 1653, Loss: 0.00017646222087819297, Final Batch Loss: 2.8709853722830303e-05\n",
      "Epoch 1654, Loss: 0.000251497690328506, Final Batch Loss: 5.0005937737296335e-06\n",
      "Epoch 1655, Loss: 0.00019501010382327877, Final Batch Loss: 0.0001418163737980649\n",
      "Epoch 1656, Loss: 0.001531852623912755, Final Batch Loss: 6.815927804382227e-07\n",
      "Epoch 1657, Loss: 0.007125160928950436, Final Batch Loss: 5.40973769602715e-06\n",
      "Epoch 1658, Loss: 0.012138775260552848, Final Batch Loss: 2.7548780053621158e-05\n",
      "Epoch 1659, Loss: 0.056927163167671324, Final Batch Loss: 0.05454438552260399\n",
      "Epoch 1660, Loss: 0.0002532371108827647, Final Batch Loss: 4.053618340549292e-06\n",
      "Epoch 1661, Loss: 0.02237875406422063, Final Batch Loss: 0.005284445825964212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1662, Loss: 0.007356466447163257, Final Batch Loss: 1.5641036952729337e-05\n",
      "Epoch 1663, Loss: 0.012431559571268735, Final Batch Loss: 0.011685149744153023\n",
      "Epoch 1664, Loss: 0.0049664244256746315, Final Batch Loss: 0.0006784344441257417\n",
      "Epoch 1665, Loss: 0.002586213799986581, Final Batch Loss: 1.665149102336727e-05\n",
      "Epoch 1666, Loss: 0.0028123281419993873, Final Batch Loss: 0.00011820469080703333\n",
      "Epoch 1667, Loss: 0.0018871991051128134, Final Batch Loss: 4.0882543544285e-05\n",
      "Epoch 1668, Loss: 0.012915254626022943, Final Batch Loss: 0.001343369483947754\n",
      "Epoch 1669, Loss: 0.008106678301373904, Final Batch Loss: 0.0001391754049109295\n",
      "Epoch 1670, Loss: 0.0009014395063786651, Final Batch Loss: 7.562540304206777e-06\n",
      "Epoch 1671, Loss: 0.0016811535842862213, Final Batch Loss: 8.05494564701803e-05\n",
      "Epoch 1672, Loss: 0.016072634180090972, Final Batch Loss: 3.441973603912629e-05\n",
      "Epoch 1673, Loss: 0.001483412363086245, Final Batch Loss: 7.513592572649941e-05\n",
      "Epoch 1674, Loss: 0.0056370943693764275, Final Batch Loss: 5.72618046135176e-05\n",
      "Epoch 1675, Loss: 0.0024446519996672578, Final Batch Loss: 6.210243736859411e-05\n",
      "Epoch 1676, Loss: 0.0005014736464090674, Final Batch Loss: 4.5295015297597274e-05\n",
      "Epoch 1677, Loss: 0.010000077170161603, Final Batch Loss: 4.2736621253425255e-05\n",
      "Epoch 1678, Loss: 0.0085016563643876, Final Batch Loss: 1.591697582625784e-05\n",
      "Epoch 1679, Loss: 0.001369445868931507, Final Batch Loss: 7.7814447649871e-06\n",
      "Epoch 1680, Loss: 0.0027899627140186567, Final Batch Loss: 2.52827703661751e-05\n",
      "Epoch 1681, Loss: 0.001001690489374596, Final Batch Loss: 4.8468424211023375e-05\n",
      "Epoch 1682, Loss: 0.0015430869686952065, Final Batch Loss: 0.0004161331453360617\n",
      "Epoch 1683, Loss: 0.0004574256846581193, Final Batch Loss: 6.303450936684385e-05\n",
      "Epoch 1684, Loss: 0.000593868231135275, Final Batch Loss: 3.742436456377618e-05\n",
      "Epoch 1685, Loss: 0.0003445110228312842, Final Batch Loss: 2.1438330804812722e-05\n",
      "Epoch 1686, Loss: 0.0009448575814303695, Final Batch Loss: 0.0006135260337032378\n",
      "Epoch 1687, Loss: 0.00017553563566252706, Final Batch Loss: 5.011066241422668e-05\n",
      "Epoch 1688, Loss: 0.001014323983781651, Final Batch Loss: 1.442142456653528e-05\n",
      "Epoch 1689, Loss: 0.0029293810559352096, Final Batch Loss: 2.9056952826067572e-06\n",
      "Epoch 1690, Loss: 0.0004952766032602085, Final Batch Loss: 5.264347237243783e-06\n",
      "Epoch 1691, Loss: 0.0005251165121080703, Final Batch Loss: 0.00011755800369428471\n",
      "Epoch 1692, Loss: 0.0005254115415027627, Final Batch Loss: 3.958984507335117e-06\n",
      "Epoch 1693, Loss: 0.0002255411524174633, Final Batch Loss: 2.954804131150013e-06\n",
      "Epoch 1694, Loss: 0.006212607213285537, Final Batch Loss: 8.810746976450901e-07\n",
      "Epoch 1695, Loss: 9.298133011270693e-05, Final Batch Loss: 3.2586156066827243e-06\n",
      "Epoch 1696, Loss: 0.000165715068078498, Final Batch Loss: 3.603835693866131e-06\n",
      "Epoch 1697, Loss: 0.0016565930678780205, Final Batch Loss: 1.333834120487154e-06\n",
      "Epoch 1698, Loss: 0.00032774668920865224, Final Batch Loss: 5.706410320271971e-06\n",
      "Epoch 1699, Loss: 0.00048117565165739506, Final Batch Loss: 0.0002703737118281424\n",
      "Epoch 1700, Loss: 0.00023095850582421917, Final Batch Loss: 3.4870727176894434e-06\n",
      "Epoch 1701, Loss: 0.0006205663195260058, Final Batch Loss: 4.761868240166223e-06\n",
      "Epoch 1702, Loss: 0.0003042688790628745, Final Batch Loss: 6.4699206632212736e-06\n",
      "Epoch 1703, Loss: 0.0008862209126618836, Final Batch Loss: 1.664027195147355e-06\n",
      "Epoch 1704, Loss: 0.020373086189579226, Final Batch Loss: 2.036787236647797e-06\n",
      "Epoch 1705, Loss: 0.0016257281825460268, Final Batch Loss: 7.445449341503263e-07\n",
      "Epoch 1706, Loss: 0.0015467923677903173, Final Batch Loss: 1.9692215573741123e-06\n",
      "Epoch 1707, Loss: 0.01593756930869006, Final Batch Loss: 5.536078333534533e-06\n",
      "Epoch 1708, Loss: 0.00014459421137758, Final Batch Loss: 2.7192025299882516e-05\n",
      "Epoch 1709, Loss: 0.004747647351450723, Final Batch Loss: 5.290410172165139e-06\n",
      "Epoch 1710, Loss: 0.0003126396177179913, Final Batch Loss: 1.1978215752606047e-06\n",
      "Epoch 1711, Loss: 0.0007467625633168495, Final Batch Loss: 1.8428214389132336e-05\n",
      "Epoch 1712, Loss: 0.00019108480879026501, Final Batch Loss: 8.273469575215131e-06\n",
      "Epoch 1713, Loss: 0.00308248305179859, Final Batch Loss: 5.239356823949493e-07\n",
      "Epoch 1714, Loss: 0.030750616348740323, Final Batch Loss: 0.030334480106830597\n",
      "Epoch 1715, Loss: 0.0007250319417835271, Final Batch Loss: 0.00026656725094653666\n",
      "Epoch 1716, Loss: 0.006470498940416292, Final Batch Loss: 1.216784949065186e-05\n",
      "Epoch 1717, Loss: 0.00399146390873284, Final Batch Loss: 1.0306575859431177e-05\n",
      "Epoch 1718, Loss: 0.0034065354534504877, Final Batch Loss: 0.00010572969767963514\n",
      "Epoch 1719, Loss: 0.0006703050412397715, Final Batch Loss: 9.169873919745442e-06\n",
      "Epoch 1720, Loss: 0.0007312928817100328, Final Batch Loss: 1.7208903955179267e-05\n",
      "Epoch 1721, Loss: 0.0006538940979226027, Final Batch Loss: 5.607738330581924e-06\n",
      "Epoch 1722, Loss: 0.0004320500929679838, Final Batch Loss: 1.1794178135460243e-05\n",
      "Epoch 1723, Loss: 0.0009622097968531307, Final Batch Loss: 7.03160185366869e-06\n",
      "Epoch 1724, Loss: 0.00017926515880617444, Final Batch Loss: 3.327918966533616e-05\n",
      "Epoch 1725, Loss: 0.0008091283234534785, Final Batch Loss: 0.0001327997597400099\n",
      "Epoch 1726, Loss: 0.00034948236066156824, Final Batch Loss: 2.3439641154254787e-05\n",
      "Epoch 1727, Loss: 0.0004069889559445983, Final Batch Loss: 2.2446522507379996e-06\n",
      "Epoch 1728, Loss: 0.0004399311984570886, Final Batch Loss: 6.629591098317178e-06\n",
      "Epoch 1729, Loss: 0.0063083026334425085, Final Batch Loss: 3.524004205246456e-05\n",
      "Epoch 1730, Loss: 0.000962819972755824, Final Batch Loss: 4.700096269516507e-06\n",
      "Epoch 1731, Loss: 0.0015208713145966613, Final Batch Loss: 1.7668613509158604e-05\n",
      "Epoch 1732, Loss: 0.002995607254206334, Final Batch Loss: 1.674927079875488e-05\n",
      "Epoch 1733, Loss: 0.00014002759598952252, Final Batch Loss: 5.165002676221775e-06\n",
      "Epoch 1734, Loss: 0.0005027872423397639, Final Batch Loss: 2.8849768568761647e-05\n",
      "Epoch 1735, Loss: 0.00038220304327296617, Final Batch Loss: 1.4166467735776678e-05\n",
      "Epoch 1736, Loss: 0.0001645183299388009, Final Batch Loss: 7.742774869257119e-06\n",
      "Epoch 1737, Loss: 0.0009249284474890374, Final Batch Loss: 7.137745114960126e-07\n",
      "Epoch 1738, Loss: 0.0007550922757673106, Final Batch Loss: 2.2768715552956564e-06\n",
      "Epoch 1739, Loss: 0.00038719926486763256, Final Batch Loss: 2.6339223495597253e-06\n",
      "Epoch 1740, Loss: 0.00026868718418882054, Final Batch Loss: 4.549337063508574e-06\n",
      "Epoch 1741, Loss: 0.0011568159029593517, Final Batch Loss: 2.4570392724854173e-06\n",
      "Epoch 1742, Loss: 0.0003254128996275085, Final Batch Loss: 1.4583240499632666e-06\n",
      "Epoch 1743, Loss: 0.002238627068493315, Final Batch Loss: 5.684993084287271e-05\n",
      "Epoch 1744, Loss: 0.00012007664292923437, Final Batch Loss: 1.4418994396692142e-05\n",
      "Epoch 1745, Loss: 0.00010881687251185213, Final Batch Loss: 9.162105016002897e-06\n",
      "Epoch 1746, Loss: 0.0001287549436028712, Final Batch Loss: 1.5023108062450774e-05\n",
      "Epoch 1747, Loss: 8.482598235559635e-05, Final Batch Loss: 1.3828363307766267e-06\n",
      "Epoch 1748, Loss: 0.000229835493257724, Final Batch Loss: 1.4497471966024023e-05\n",
      "Epoch 1749, Loss: 0.0005959859846029758, Final Batch Loss: 5.228222562436713e-06\n",
      "Epoch 1750, Loss: 0.000960038149059983, Final Batch Loss: 1.3601886166725308e-05\n",
      "Epoch 1751, Loss: 0.00010280387323291507, Final Batch Loss: 4.03901776735438e-06\n",
      "Epoch 1752, Loss: 0.0008734874944167359, Final Batch Loss: 7.542785169789568e-06\n",
      "Epoch 1753, Loss: 0.011647977091598705, Final Batch Loss: 3.8045136534492485e-06\n",
      "Epoch 1754, Loss: 0.0004813422259530853, Final Batch Loss: 1.1931866538361646e-05\n",
      "Epoch 1755, Loss: 0.0016715046883746254, Final Batch Loss: 7.2879511208157055e-06\n",
      "Epoch 1756, Loss: 0.0065426225407065886, Final Batch Loss: 3.268625903274369e-07\n",
      "Epoch 1757, Loss: 0.00012009336916207758, Final Batch Loss: 4.318695118854521e-06\n",
      "Epoch 1758, Loss: 0.000372524996635093, Final Batch Loss: 2.3313778001465835e-05\n",
      "Epoch 1759, Loss: 0.0010840562948999377, Final Batch Loss: 3.105294581473572e-06\n",
      "Epoch 1760, Loss: 0.0001960495018522579, Final Batch Loss: 1.7663021935732104e-05\n",
      "Epoch 1761, Loss: 0.0003213835591679981, Final Batch Loss: 2.589915311546065e-06\n",
      "Epoch 1762, Loss: 0.00015223835798394703, Final Batch Loss: 5.406876880442724e-06\n",
      "Epoch 1763, Loss: 4.667925242074489e-05, Final Batch Loss: 1.546192493151466e-06\n",
      "Epoch 1764, Loss: 0.0007219472608568367, Final Batch Loss: 1.9084091036347672e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1765, Loss: 6.691603667263735e-05, Final Batch Loss: 4.287648209810868e-07\n",
      "Epoch 1766, Loss: 0.0004753405974611269, Final Batch Loss: 2.2965072275837883e-05\n",
      "Epoch 1767, Loss: 0.0005190347087307146, Final Batch Loss: 2.393786076027027e-07\n",
      "Epoch 1768, Loss: 4.8052789679786656e-05, Final Batch Loss: 7.326849754463183e-06\n",
      "Epoch 1769, Loss: 0.00014858498585113011, Final Batch Loss: 1.1687811820593197e-05\n",
      "Epoch 1770, Loss: 0.00019982522334771602, Final Batch Loss: 4.8279402108164504e-05\n",
      "Epoch 1771, Loss: 0.0018675154450846776, Final Batch Loss: 4.7058387053766637e-07\n",
      "Epoch 1772, Loss: 6.96522195369198e-05, Final Batch Loss: 1.2833634173148312e-06\n",
      "Epoch 1773, Loss: 0.0002646225654814316, Final Batch Loss: 2.87118268715858e-06\n",
      "Epoch 1774, Loss: 0.00038911675315489447, Final Batch Loss: 4.100647856830619e-05\n",
      "Epoch 1775, Loss: 0.00013708547845681096, Final Batch Loss: 6.003524504194502e-07\n",
      "Epoch 1776, Loss: 3.08408973417329e-05, Final Batch Loss: 2.593291810626397e-06\n",
      "Epoch 1777, Loss: 0.026454882209897335, Final Batch Loss: 0.00746420631185174\n",
      "Epoch 1778, Loss: 0.0017451400048571486, Final Batch Loss: 1.4094004654907621e-05\n",
      "Epoch 1779, Loss: 0.006614883161148555, Final Batch Loss: 3.819647190539399e-06\n",
      "Epoch 1780, Loss: 0.0023911252467314625, Final Batch Loss: 0.0008271121187135577\n",
      "Epoch 1781, Loss: 0.004404273633213052, Final Batch Loss: 9.234239769284613e-06\n",
      "Epoch 1782, Loss: 0.00011956396673440395, Final Batch Loss: 3.775326376853627e-06\n",
      "Epoch 1783, Loss: 0.0005155586423484237, Final Batch Loss: 5.143293492437806e-06\n",
      "Epoch 1784, Loss: 0.0005864503958150635, Final Batch Loss: 2.3023321773507632e-05\n",
      "Epoch 1785, Loss: 0.0001129714174368246, Final Batch Loss: 3.350321549078217e-07\n",
      "Epoch 1786, Loss: 0.00026073568099604927, Final Batch Loss: 9.667604899732396e-06\n",
      "Epoch 1787, Loss: 0.0014853723313876799, Final Batch Loss: 7.017807774900575e-07\n",
      "Epoch 1788, Loss: 0.001093606105996514, Final Batch Loss: 5.91149319006945e-06\n",
      "Epoch 1789, Loss: 0.0054109964090685025, Final Batch Loss: 7.032219855318544e-07\n",
      "Epoch 1790, Loss: 0.00013499761044499792, Final Batch Loss: 4.4606673554881127e-07\n",
      "Epoch 1791, Loss: 0.00029858491618028893, Final Batch Loss: 9.84354414867994e-07\n",
      "Epoch 1792, Loss: 0.0015497930467631704, Final Batch Loss: 2.2216395336727146e-06\n",
      "Epoch 1793, Loss: 0.024490731909921237, Final Batch Loss: 0.0011859986698254943\n",
      "Epoch 1794, Loss: 0.013846432104855921, Final Batch Loss: 7.879966142354533e-05\n",
      "Epoch 1795, Loss: 0.00020383835803272632, Final Batch Loss: 1.907544537971262e-05\n",
      "Epoch 1796, Loss: 0.0207646098376415, Final Batch Loss: 0.00019371289818082005\n",
      "Epoch 1797, Loss: 0.0016246759978457703, Final Batch Loss: 4.170687134319451e-06\n",
      "Epoch 1798, Loss: 0.023638586688875307, Final Batch Loss: 1.9611755419646215e-07\n",
      "Epoch 1799, Loss: 0.07076128583582886, Final Batch Loss: 5.712389793188777e-06\n",
      "Epoch 1800, Loss: 0.041883073693696815, Final Batch Loss: 0.00018787218141369522\n",
      "Epoch 1801, Loss: 0.019771190824030782, Final Batch Loss: 0.006624952424317598\n",
      "Epoch 1802, Loss: 0.011919911416271134, Final Batch Loss: 0.00016304220480378717\n",
      "Epoch 1803, Loss: 0.00435668142290524, Final Batch Loss: 5.715786392102018e-05\n",
      "Epoch 1804, Loss: 0.006049662143595924, Final Batch Loss: 2.049512477242388e-05\n",
      "Epoch 1805, Loss: 0.005144093227045232, Final Batch Loss: 8.040351531235501e-05\n",
      "Epoch 1806, Loss: 0.007125365159026842, Final Batch Loss: 1.9010956748388708e-05\n",
      "Epoch 1807, Loss: 0.006350715167627641, Final Batch Loss: 2.302430038980674e-05\n",
      "Epoch 1808, Loss: 0.0012717288902877044, Final Batch Loss: 1.383182461722754e-05\n",
      "Epoch 1809, Loss: 0.0027439316231721023, Final Batch Loss: 1.6238136595347896e-05\n",
      "Epoch 1810, Loss: 0.023929491986564244, Final Batch Loss: 5.292295099934563e-06\n",
      "Epoch 1811, Loss: 0.0016031631630539778, Final Batch Loss: 0.0002550052886363119\n",
      "Epoch 1812, Loss: 0.00769837591178657, Final Batch Loss: 0.0007251581409946084\n",
      "Epoch 1813, Loss: 0.0032992894430208253, Final Batch Loss: 0.00019488534599076957\n",
      "Epoch 1814, Loss: 0.0005663338756676239, Final Batch Loss: 4.7754285333212465e-05\n",
      "Epoch 1815, Loss: 0.0007256574776874913, Final Batch Loss: 9.801922715269029e-05\n",
      "Epoch 1816, Loss: 0.0008647106960779638, Final Batch Loss: 3.376859694981249e-06\n",
      "Epoch 1817, Loss: 0.0012961394004378235, Final Batch Loss: 9.161148773273453e-05\n",
      "Epoch 1818, Loss: 0.0004766287645452394, Final Batch Loss: 1.3970077816338744e-05\n",
      "Epoch 1819, Loss: 0.02275725648541993, Final Batch Loss: 6.771303742425516e-05\n",
      "Epoch 1820, Loss: 0.0009396149343956495, Final Batch Loss: 0.00015440324204973876\n",
      "Epoch 1821, Loss: 0.0014146400408208137, Final Batch Loss: 3.4875734854722396e-05\n",
      "Epoch 1822, Loss: 0.0006033181762177264, Final Batch Loss: 4.183410419500433e-05\n",
      "Epoch 1823, Loss: 0.0005982181514809781, Final Batch Loss: 4.92533627038938e-06\n",
      "Epoch 1824, Loss: 0.0010873855976569757, Final Batch Loss: 1.048593367158901e-05\n",
      "Epoch 1825, Loss: 0.0034390481287118746, Final Batch Loss: 0.0028142340015619993\n",
      "Epoch 1826, Loss: 0.0010113056413274535, Final Batch Loss: 1.3809450138069224e-05\n",
      "Epoch 1827, Loss: 0.00029667162459645624, Final Batch Loss: 1.2746356333082076e-05\n",
      "Epoch 1828, Loss: 0.0006541388402183657, Final Batch Loss: 1.3699579540116247e-05\n",
      "Epoch 1829, Loss: 0.001993804929838916, Final Batch Loss: 2.0827059415751137e-05\n",
      "Epoch 1830, Loss: 0.00034813876368389174, Final Batch Loss: 3.7950844671286177e-06\n",
      "Epoch 1831, Loss: 0.0004268765997039736, Final Batch Loss: 1.0686027053452563e-05\n",
      "Epoch 1832, Loss: 0.000612752684901352, Final Batch Loss: 3.383020157343708e-06\n",
      "Epoch 1833, Loss: 0.001613959257042552, Final Batch Loss: 6.108228990342468e-05\n",
      "Epoch 1834, Loss: 0.00037899222570558777, Final Batch Loss: 6.010487777530216e-05\n",
      "Epoch 1835, Loss: 0.00013088790592519217, Final Batch Loss: 2.9103175620548427e-06\n",
      "Epoch 1836, Loss: 0.00024326566676791117, Final Batch Loss: 5.0386724979034625e-06\n",
      "Epoch 1837, Loss: 0.0018418568017182224, Final Batch Loss: 1.656867425481323e-05\n",
      "Epoch 1838, Loss: 0.0009641890455895918, Final Batch Loss: 0.00022192957112565637\n",
      "Epoch 1839, Loss: 0.025523467775656172, Final Batch Loss: 2.1719852156820707e-05\n",
      "Epoch 1840, Loss: 0.03332746209798643, Final Batch Loss: 0.0005260489415377378\n",
      "Epoch 1841, Loss: 0.005026629379244696, Final Batch Loss: 0.00016190223686862737\n",
      "Epoch 1842, Loss: 0.0005888471155230945, Final Batch Loss: 3.652628265626845e-06\n",
      "Epoch 1843, Loss: 0.0005732155736950517, Final Batch Loss: 6.430753273889422e-06\n",
      "Epoch 1844, Loss: 0.0009860380210966468, Final Batch Loss: 9.570114343659952e-06\n",
      "Epoch 1845, Loss: 0.0013481842531746224, Final Batch Loss: 4.973551767761819e-06\n",
      "Epoch 1846, Loss: 0.0005449405736044355, Final Batch Loss: 0.00011038494994863868\n",
      "Epoch 1847, Loss: 0.002500255433460552, Final Batch Loss: 0.00018677380285225809\n",
      "Epoch 1848, Loss: 0.09082098347425926, Final Batch Loss: 2.2503705622511916e-05\n",
      "Epoch 1849, Loss: 0.014791939549468225, Final Batch Loss: 3.377037137397565e-05\n",
      "Epoch 1850, Loss: 0.0007965536374285875, Final Batch Loss: 8.786581020103768e-06\n",
      "Epoch 1851, Loss: 0.000891134047833475, Final Batch Loss: 9.790898184292018e-05\n",
      "Epoch 1852, Loss: 0.001085869914277282, Final Batch Loss: 6.402131111826748e-05\n",
      "Epoch 1853, Loss: 0.0012540323650682694, Final Batch Loss: 0.00015242623339872807\n",
      "Epoch 1854, Loss: 0.0012125298731007206, Final Batch Loss: 2.675186078704428e-05\n",
      "Epoch 1855, Loss: 0.0016029115827222995, Final Batch Loss: 0.00016717608377803117\n",
      "Epoch 1856, Loss: 0.0007516840623793541, Final Batch Loss: 0.0001439874613424763\n",
      "Epoch 1857, Loss: 0.0009451695123061654, Final Batch Loss: 3.2747179830039386e-06\n",
      "Epoch 1858, Loss: 0.0004619924466169323, Final Batch Loss: 8.870115561876446e-05\n",
      "Epoch 1859, Loss: 0.00032653681410010904, Final Batch Loss: 7.741630724922288e-06\n",
      "Epoch 1860, Loss: 0.0004430927378962224, Final Batch Loss: 2.104284976667259e-05\n",
      "Epoch 1861, Loss: 0.008799209868357138, Final Batch Loss: 1.2331274774624035e-05\n",
      "Epoch 1862, Loss: 0.0012645460724343138, Final Batch Loss: 3.048506550840102e-05\n",
      "Epoch 1863, Loss: 0.0005356195815693354, Final Batch Loss: 6.105016655055806e-05\n",
      "Epoch 1864, Loss: 0.002649992217129693, Final Batch Loss: 1.0181775905948598e-05\n",
      "Epoch 1865, Loss: 0.00039444215076400724, Final Batch Loss: 2.7395651613915106e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1866, Loss: 0.0020048958690495056, Final Batch Loss: 3.684129524117452e-06\n",
      "Epoch 1867, Loss: 0.0014624918610479654, Final Batch Loss: 0.0006740836543031037\n",
      "Epoch 1868, Loss: 0.0007346179659180052, Final Batch Loss: 6.25149277766468e-06\n",
      "Epoch 1869, Loss: 0.0008948461791078444, Final Batch Loss: 0.00010046624083770439\n",
      "Epoch 1870, Loss: 0.00022911153064342216, Final Batch Loss: 4.181630356470123e-05\n",
      "Epoch 1871, Loss: 0.0002868199491672385, Final Batch Loss: 1.355224503640784e-05\n",
      "Epoch 1872, Loss: 0.0003342705008435587, Final Batch Loss: 2.1163739802432247e-05\n",
      "Epoch 1873, Loss: 0.0003488736542749393, Final Batch Loss: 6.694222065561917e-06\n",
      "Epoch 1874, Loss: 0.00029066755666917743, Final Batch Loss: 1.7289022480326821e-06\n",
      "Epoch 1875, Loss: 0.0002708420686303725, Final Batch Loss: 1.3667628991242964e-05\n",
      "Epoch 1876, Loss: 0.00015114116149561596, Final Batch Loss: 1.272308418265311e-05\n",
      "Epoch 1877, Loss: 0.0005427055716609175, Final Batch Loss: 2.143986421287991e-05\n",
      "Epoch 1878, Loss: 0.0004286220807898644, Final Batch Loss: 2.363931889703963e-05\n",
      "Epoch 1879, Loss: 0.00027651259517824656, Final Batch Loss: 2.392257101746509e-06\n",
      "Epoch 1880, Loss: 0.0009018797546787027, Final Batch Loss: 0.000715681875590235\n",
      "Epoch 1881, Loss: 0.000350574292156125, Final Batch Loss: 2.951165470221895e-06\n",
      "Epoch 1882, Loss: 0.001477189464935691, Final Batch Loss: 0.00012163454084657133\n",
      "Epoch 1883, Loss: 0.00045346907950261084, Final Batch Loss: 2.1353718693717383e-05\n",
      "Epoch 1884, Loss: 0.0005458007374272711, Final Batch Loss: 3.223131443519378e-06\n",
      "Epoch 1885, Loss: 0.0034562449516215565, Final Batch Loss: 8.287498530989978e-06\n",
      "Epoch 1886, Loss: 0.0024417722087264337, Final Batch Loss: 2.4224791559390724e-06\n",
      "Epoch 1887, Loss: 0.00018594637276692083, Final Batch Loss: 4.778285529027926e-06\n",
      "Epoch 1888, Loss: 0.00032734733918005077, Final Batch Loss: 6.462892088165972e-06\n",
      "Epoch 1889, Loss: 0.0005362798291486115, Final Batch Loss: 3.5069500881945714e-05\n",
      "Epoch 1890, Loss: 0.00036075530806556344, Final Batch Loss: 1.3864196262147743e-05\n",
      "Epoch 1891, Loss: 0.00036174079036754847, Final Batch Loss: 8.410933332925197e-06\n",
      "Epoch 1892, Loss: 0.0003077585664641447, Final Batch Loss: 1.175003399112029e-05\n",
      "Epoch 1893, Loss: 8.472535711234741e-05, Final Batch Loss: 1.7286109141423367e-05\n",
      "Epoch 1894, Loss: 0.0001315349402375432, Final Batch Loss: 2.118499423886533e-06\n",
      "Epoch 1895, Loss: 0.0001973298242035071, Final Batch Loss: 7.4522731665638275e-06\n",
      "Epoch 1896, Loss: 0.000552185850551723, Final Batch Loss: 2.5411297883692896e-06\n",
      "Epoch 1897, Loss: 0.002005193701279495, Final Batch Loss: 1.235828131029848e-05\n",
      "Epoch 1898, Loss: 0.002656793195114915, Final Batch Loss: 4.971064754499821e-06\n",
      "Epoch 1899, Loss: 0.00018404672323413251, Final Batch Loss: 5.2373084145074245e-06\n",
      "Epoch 1900, Loss: 0.00022804382365393394, Final Batch Loss: 8.03771945356857e-06\n",
      "Epoch 1901, Loss: 0.00024854399731566446, Final Batch Loss: 1.9197700567019638e-06\n",
      "Epoch 1902, Loss: 0.0006963078049579963, Final Batch Loss: 4.9023192332242616e-06\n",
      "Epoch 1903, Loss: 0.00018514596609975342, Final Batch Loss: 3.920149538316764e-06\n",
      "Epoch 1904, Loss: 0.00034935626086962657, Final Batch Loss: 4.143437308812281e-07\n",
      "Epoch 1905, Loss: 7.286009858376019e-05, Final Batch Loss: 2.553588046794175e-06\n",
      "Epoch 1906, Loss: 0.00011952436244655473, Final Batch Loss: 1.6933734059421113e-06\n",
      "Epoch 1907, Loss: 0.00010534048317367706, Final Batch Loss: 5.277228410704993e-06\n",
      "Epoch 1908, Loss: 0.00032162296258775314, Final Batch Loss: 5.664953278028406e-05\n",
      "Epoch 1909, Loss: 6.444043559383772e-05, Final Batch Loss: 1.8015184650721494e-06\n",
      "Epoch 1910, Loss: 0.0005541324247673174, Final Batch Loss: 1.917909600024359e-07\n",
      "Epoch 1911, Loss: 7.440310407247352e-05, Final Batch Loss: 2.0866962586296722e-05\n",
      "Epoch 1912, Loss: 0.001063667295326809, Final Batch Loss: 4.4645339585258625e-06\n",
      "Epoch 1913, Loss: 0.0009780189637353942, Final Batch Loss: 2.5471370008745e-06\n",
      "Epoch 1914, Loss: 0.0005701805129660897, Final Batch Loss: 3.0289970709418412e-06\n",
      "Epoch 1915, Loss: 0.00022637373305656183, Final Batch Loss: 6.862416285002837e-06\n",
      "Epoch 1916, Loss: 0.00018903218301602465, Final Batch Loss: 1.6383999536628835e-05\n",
      "Epoch 1917, Loss: 0.00035768335726515943, Final Batch Loss: 0.00020618854614440352\n",
      "Epoch 1918, Loss: 0.0002482713455975727, Final Batch Loss: 9.847296496445779e-06\n",
      "Epoch 1919, Loss: 0.0004124816530577391, Final Batch Loss: 7.773012839606963e-06\n",
      "Epoch 1920, Loss: 9.895760756606364e-05, Final Batch Loss: 2.090319867420476e-05\n",
      "Epoch 1921, Loss: 0.0002494395750716194, Final Batch Loss: 3.063564690819476e-06\n",
      "Epoch 1922, Loss: 0.00016608478625812495, Final Batch Loss: 7.798126898705959e-05\n",
      "Epoch 1923, Loss: 0.00012998140346098808, Final Batch Loss: 4.442427325557219e-06\n",
      "Epoch 1924, Loss: 5.3362416750246666e-05, Final Batch Loss: 1.6708378097973764e-05\n",
      "Epoch 1925, Loss: 0.00010644167872442267, Final Batch Loss: 9.733314527693437e-07\n",
      "Epoch 1926, Loss: 0.0004765549634839772, Final Batch Loss: 2.216840221080929e-05\n",
      "Epoch 1927, Loss: 0.0004119029543119268, Final Batch Loss: 7.301899131562095e-06\n",
      "Epoch 1928, Loss: 0.0003060101758194378, Final Batch Loss: 2.950679345303797e-06\n",
      "Epoch 1929, Loss: 0.0001774585696452391, Final Batch Loss: 8.094478403108951e-07\n",
      "Epoch 1930, Loss: 0.0002482013734379507, Final Batch Loss: 7.795920282660518e-06\n",
      "Epoch 1931, Loss: 0.0004973217725989798, Final Batch Loss: 1.5750534885228262e-06\n",
      "Epoch 1932, Loss: 0.0007092442374698749, Final Batch Loss: 2.9033155897195684e-06\n",
      "Epoch 1933, Loss: 0.0011575427738534927, Final Batch Loss: 3.709689735842403e-06\n",
      "Epoch 1934, Loss: 0.0008101435763592235, Final Batch Loss: 0.00027882930589839816\n",
      "Epoch 1935, Loss: 0.00013670628283080077, Final Batch Loss: 1.3621854577650083e-06\n",
      "Epoch 1936, Loss: 0.00010771697637323996, Final Batch Loss: 3.9030263110362284e-07\n",
      "Epoch 1937, Loss: 0.0009356273411640359, Final Batch Loss: 7.404983080050442e-06\n",
      "Epoch 1938, Loss: 0.00011311215489229198, Final Batch Loss: 5.6029939514701255e-06\n",
      "Epoch 1939, Loss: 0.0005436476144495828, Final Batch Loss: 6.864052579658164e-07\n",
      "Epoch 1940, Loss: 5.9417691858243415e-05, Final Batch Loss: 1.8846327520805062e-06\n",
      "Epoch 1941, Loss: 0.0008576697649687048, Final Batch Loss: 9.90634475783736e-07\n",
      "Epoch 1942, Loss: 0.00011725904327875014, Final Batch Loss: 1.3074465243789746e-07\n",
      "Epoch 1943, Loss: 0.00021390772646157075, Final Batch Loss: 2.1551511963480152e-05\n",
      "Epoch 1944, Loss: 6.89581504502712e-05, Final Batch Loss: 9.286521844842355e-07\n",
      "Epoch 1945, Loss: 0.0007769916681681366, Final Batch Loss: 4.606916718330467e-06\n",
      "Epoch 1946, Loss: 3.74433792273976e-05, Final Batch Loss: 1.2103010931241442e-06\n",
      "Epoch 1947, Loss: 0.0006239744110416723, Final Batch Loss: 1.6938142834987957e-06\n",
      "Epoch 1948, Loss: 0.00017858679998994376, Final Batch Loss: 6.35913893347606e-05\n",
      "Epoch 1949, Loss: 4.5024513127600585e-05, Final Batch Loss: 1.8731130921878503e-06\n",
      "Epoch 1950, Loss: 0.02734747197720111, Final Batch Loss: 2.965563680845662e-06\n",
      "Epoch 1951, Loss: 0.001019588111205394, Final Batch Loss: 4.989367994312488e-07\n",
      "Epoch 1952, Loss: 0.0001828487716153404, Final Batch Loss: 3.047494487873337e-07\n",
      "Epoch 1953, Loss: 0.00019302292074030447, Final Batch Loss: 5.060368494014256e-06\n",
      "Epoch 1954, Loss: 5.29435283311841e-05, Final Batch Loss: 6.456777100538602e-06\n",
      "Epoch 1955, Loss: 0.00045479656553482073, Final Batch Loss: 1.2746769243676681e-05\n",
      "Epoch 1956, Loss: 0.0001590055592544104, Final Batch Loss: 0.0001243140286533162\n",
      "Epoch 1957, Loss: 0.0002566826929069066, Final Batch Loss: 1.2512861758295912e-05\n",
      "Epoch 1958, Loss: 0.0015023727485470317, Final Batch Loss: 5.151543064130237e-06\n",
      "Epoch 1959, Loss: 0.004663201909949066, Final Batch Loss: 6.032425972080091e-07\n",
      "Epoch 1960, Loss: 0.019628480465712528, Final Batch Loss: 5.153379242983647e-05\n",
      "Epoch 1961, Loss: 0.03644003441070254, Final Batch Loss: 1.2002270750599564e-06\n",
      "Epoch 1962, Loss: 0.029112891443446642, Final Batch Loss: 0.024913709610700607\n",
      "Epoch 1963, Loss: 0.03677069440112746, Final Batch Loss: 9.959261433323263e-07\n",
      "Epoch 1964, Loss: 0.05165076212756503, Final Batch Loss: 0.0001224324805662036\n",
      "Epoch 1965, Loss: 0.006014428867160859, Final Batch Loss: 7.67745132179698e-06\n",
      "Epoch 1966, Loss: 0.0008835494918457698, Final Batch Loss: 5.940400660620071e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1967, Loss: 0.005057503431089572, Final Batch Loss: 1.6639123714412563e-05\n",
      "Epoch 1968, Loss: 0.0011296559563334085, Final Batch Loss: 1.72748275417689e-06\n",
      "Epoch 1969, Loss: 0.0016717007551960705, Final Batch Loss: 7.051665761537151e-06\n",
      "Epoch 1970, Loss: 0.0006087792016842286, Final Batch Loss: 9.808439244807232e-06\n",
      "Epoch 1971, Loss: 0.000415486602605597, Final Batch Loss: 2.8875960197183304e-05\n",
      "Epoch 1972, Loss: 0.006561919210525957, Final Batch Loss: 7.270935748238117e-05\n",
      "Epoch 1973, Loss: 0.0014270814107248952, Final Batch Loss: 2.6162172162003117e-06\n",
      "Epoch 1974, Loss: 0.0019806451589374774, Final Batch Loss: 9.434126695850864e-06\n",
      "Epoch 1975, Loss: 0.0008139778647091589, Final Batch Loss: 4.656762757804245e-05\n",
      "Epoch 1976, Loss: 0.009014762304445867, Final Batch Loss: 5.408980996435275e-06\n",
      "Epoch 1977, Loss: 0.01176603367343887, Final Batch Loss: 0.011169353500008583\n",
      "Epoch 1978, Loss: 0.003051581690783678, Final Batch Loss: 7.356090918619884e-06\n",
      "Epoch 1979, Loss: 0.004665897602080804, Final Batch Loss: 0.00011066826118621975\n",
      "Epoch 1980, Loss: 0.0012222497243783437, Final Batch Loss: 3.808310066233389e-05\n",
      "Epoch 1981, Loss: 0.0022863298913762264, Final Batch Loss: 1.5347243333962979e-06\n",
      "Epoch 1982, Loss: 0.0004277027562693547, Final Batch Loss: 3.932565959985368e-06\n",
      "Epoch 1983, Loss: 0.0016576290154262097, Final Batch Loss: 8.63184868649114e-06\n",
      "Epoch 1984, Loss: 0.00019989396065511755, Final Batch Loss: 1.073826388164889e-05\n",
      "Epoch 1985, Loss: 0.00077128771806656, Final Batch Loss: 2.1606512746075168e-05\n",
      "Epoch 1986, Loss: 0.02435650645156784, Final Batch Loss: 7.987915159901604e-05\n",
      "Epoch 1987, Loss: 0.012688605955190724, Final Batch Loss: 0.0007641793345101178\n",
      "Epoch 1988, Loss: 0.0002936311026360272, Final Batch Loss: 1.7624968677409925e-05\n",
      "Epoch 1989, Loss: 0.0013453414256900942, Final Batch Loss: 1.9600807718234137e-05\n",
      "Epoch 1990, Loss: 0.0006385835172295629, Final Batch Loss: 8.569988858653232e-05\n",
      "Epoch 1991, Loss: 0.0026498801844354603, Final Batch Loss: 3.32121089741122e-05\n",
      "Epoch 1992, Loss: 0.0005224638084655453, Final Batch Loss: 6.15818498772569e-06\n",
      "Epoch 1993, Loss: 0.005051512257523427, Final Batch Loss: 1.7782440409064293e-05\n",
      "Epoch 1994, Loss: 0.006387885798176285, Final Batch Loss: 6.914051937201293e-06\n",
      "Epoch 1995, Loss: 0.0021986404985909758, Final Batch Loss: 3.2500333873031195e-06\n",
      "Epoch 1996, Loss: 0.0003764443558793573, Final Batch Loss: 4.322646782384254e-05\n",
      "Epoch 1997, Loss: 0.0008126746101879689, Final Batch Loss: 9.920305274135899e-06\n",
      "Epoch 1998, Loss: 0.006196941834332392, Final Batch Loss: 2.91328633466037e-05\n",
      "Epoch 1999, Loss: 0.004340994730938519, Final Batch Loss: 6.418141310859937e-06\n",
      "Epoch 2000, Loss: 0.0008873341586195238, Final Batch Loss: 1.5548801002296386e-06\n",
      "Epoch 2001, Loss: 0.000787219196922706, Final Batch Loss: 1.0589020575935137e-06\n",
      "Epoch 2002, Loss: 0.005246382881978207, Final Batch Loss: 0.0014119253028184175\n",
      "Epoch 2003, Loss: 0.00026126823365757446, Final Batch Loss: 2.8037047741236165e-05\n",
      "Epoch 2004, Loss: 0.000402866936724422, Final Batch Loss: 2.4496010155417025e-05\n",
      "Epoch 2005, Loss: 0.0004190246147572907, Final Batch Loss: 7.940895557112526e-06\n",
      "Epoch 2006, Loss: 0.0006682537413098544, Final Batch Loss: 5.4185206863621715e-06\n",
      "Epoch 2007, Loss: 0.0006577371652838337, Final Batch Loss: 2.9280993203428807e-06\n",
      "Epoch 2008, Loss: 0.0020243383403339976, Final Batch Loss: 5.597031758952653e-06\n",
      "Epoch 2009, Loss: 0.0008755339627839476, Final Batch Loss: 0.0006509663071483374\n",
      "Epoch 2010, Loss: 0.00019351350539409395, Final Batch Loss: 6.233357271412387e-05\n",
      "Epoch 2011, Loss: 0.0011153198006468301, Final Batch Loss: 0.0006476528360508382\n",
      "Epoch 2012, Loss: 0.0012177165415323543, Final Batch Loss: 1.6443331105620018e-06\n",
      "Epoch 2013, Loss: 0.0006957463274375186, Final Batch Loss: 0.000101490382803604\n",
      "Epoch 2014, Loss: 0.0003484249527900829, Final Batch Loss: 1.019264709611889e-05\n",
      "Epoch 2015, Loss: 0.0013006946292080102, Final Batch Loss: 5.201934982324019e-06\n",
      "Epoch 2016, Loss: 0.0017113076849000208, Final Batch Loss: 0.001227234024554491\n",
      "Epoch 2017, Loss: 0.00020872584420317253, Final Batch Loss: 4.117496700928314e-06\n",
      "Epoch 2018, Loss: 0.00014693728991233002, Final Batch Loss: 4.259995421307394e-06\n",
      "Epoch 2019, Loss: 0.000342553126259304, Final Batch Loss: 2.3601424459229747e-07\n",
      "Epoch 2020, Loss: 0.00027038872768514466, Final Batch Loss: 4.5846649300074205e-05\n",
      "Epoch 2021, Loss: 0.00021495931133586055, Final Batch Loss: 2.300825826750952e-06\n",
      "Epoch 2022, Loss: 0.0008665371141205469, Final Batch Loss: 1.229518829859444e-06\n",
      "Epoch 2023, Loss: 0.00025619805423104935, Final Batch Loss: 2.0824220428039553e-06\n",
      "Epoch 2024, Loss: 0.001147844510910545, Final Batch Loss: 6.527150617330335e-06\n",
      "Epoch 2025, Loss: 0.0022619840247557477, Final Batch Loss: 8.634870027890429e-06\n",
      "Epoch 2026, Loss: 0.00015829225276320358, Final Batch Loss: 2.078356374113355e-05\n",
      "Epoch 2027, Loss: 0.00035505263849699986, Final Batch Loss: 1.08045469460194e-06\n",
      "Epoch 2028, Loss: 0.0002663521856902662, Final Batch Loss: 3.51657308783615e-06\n",
      "Epoch 2029, Loss: 0.0002881585184013602, Final Batch Loss: 6.813728759880178e-06\n",
      "Epoch 2030, Loss: 0.00017467824400796417, Final Batch Loss: 1.0199979442404583e-05\n",
      "Epoch 2031, Loss: 0.00018883382358581002, Final Batch Loss: 2.5591096346033737e-05\n",
      "Epoch 2032, Loss: 0.00010381743038578861, Final Batch Loss: 1.1440947673690971e-05\n",
      "Epoch 2033, Loss: 0.00045413589904796936, Final Batch Loss: 1.355909353151219e-05\n",
      "Epoch 2034, Loss: 0.0019702014091080855, Final Batch Loss: 4.910529241897166e-06\n",
      "Epoch 2035, Loss: 0.0005285752526447141, Final Batch Loss: 1.0464030992807238e-06\n",
      "Epoch 2036, Loss: 0.0013422726203202728, Final Batch Loss: 6.7562091317086015e-06\n",
      "Epoch 2037, Loss: 0.042350173273348446, Final Batch Loss: 5.518741545529338e-06\n",
      "Epoch 2038, Loss: 5.992843884428112e-05, Final Batch Loss: 7.253520834638039e-06\n",
      "Epoch 2039, Loss: 0.00015999795201082634, Final Batch Loss: 2.864802866042737e-07\n",
      "Epoch 2040, Loss: 0.030177710891990728, Final Batch Loss: 6.578795364475809e-06\n",
      "Epoch 2041, Loss: 0.0015727240308365253, Final Batch Loss: 3.3548358260304667e-06\n",
      "Epoch 2042, Loss: 0.000589795230666823, Final Batch Loss: 1.4741985978616867e-06\n",
      "Epoch 2043, Loss: 0.00027844042097058264, Final Batch Loss: 1.2074481674062554e-05\n",
      "Epoch 2044, Loss: 0.0004939651660151867, Final Batch Loss: 8.264633834187407e-06\n",
      "Epoch 2045, Loss: 0.0003598364252184183, Final Batch Loss: 6.661739007540746e-06\n",
      "Epoch 2046, Loss: 0.00034320351372230107, Final Batch Loss: 8.104750304482877e-05\n",
      "Epoch 2047, Loss: 0.000351992248880606, Final Batch Loss: 2.1636240489897318e-05\n",
      "Epoch 2048, Loss: 0.0003712613803372733, Final Batch Loss: 0.00019805080955848098\n",
      "Epoch 2049, Loss: 0.00022997692667559022, Final Batch Loss: 7.127604931156384e-06\n",
      "Epoch 2050, Loss: 0.00014783220009917386, Final Batch Loss: 1.005626381811453e-05\n",
      "Epoch 2051, Loss: 0.0001434669251239029, Final Batch Loss: 1.7838456187746488e-05\n",
      "Epoch 2052, Loss: 0.0008184622741964631, Final Batch Loss: 8.116857497952878e-05\n",
      "Epoch 2053, Loss: 7.710610105959859e-05, Final Batch Loss: 5.6063099691527896e-06\n",
      "Epoch 2054, Loss: 0.0016541449832061517, Final Batch Loss: 2.5983931664086413e-06\n",
      "Epoch 2055, Loss: 0.0006137249214077656, Final Batch Loss: 3.235892563679954e-06\n",
      "Epoch 2056, Loss: 0.00021429850056620126, Final Batch Loss: 1.5237555089697707e-05\n",
      "Epoch 2057, Loss: 0.0002288488717567816, Final Batch Loss: 3.238756562495837e-06\n",
      "Epoch 2058, Loss: 0.0008869890799587665, Final Batch Loss: 8.065648557931127e-07\n",
      "Epoch 2059, Loss: 0.00017133103673927508, Final Batch Loss: 1.3285571185406297e-06\n",
      "Epoch 2060, Loss: 0.00012490679178256414, Final Batch Loss: 5.488730676006526e-05\n",
      "Epoch 2061, Loss: 0.00024991689524256344, Final Batch Loss: 3.9655375871916476e-07\n",
      "Epoch 2062, Loss: 0.00022667143281296376, Final Batch Loss: 5.258370492811082e-06\n",
      "Epoch 2063, Loss: 0.00013832705877803164, Final Batch Loss: 2.8087767987017287e-06\n",
      "Epoch 2064, Loss: 5.650385574540451e-05, Final Batch Loss: 9.207243238051888e-06\n",
      "Epoch 2065, Loss: 0.0003504990615397219, Final Batch Loss: 5.176800073058985e-07\n",
      "Epoch 2066, Loss: 0.00014884390652980528, Final Batch Loss: 2.499548656942352e-08\n",
      "Epoch 2067, Loss: 0.0002528641877432847, Final Batch Loss: 6.599634616577532e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2068, Loss: 0.00010505520748438357, Final Batch Loss: 1.1548828297236469e-05\n",
      "Epoch 2069, Loss: 0.0002452184183994177, Final Batch Loss: 7.224450655485271e-07\n",
      "Epoch 2070, Loss: 0.0006806140497133129, Final Batch Loss: 3.403199002605106e-07\n",
      "Epoch 2071, Loss: 0.00015117713786594322, Final Batch Loss: 1.31218257592991e-06\n",
      "Epoch 2072, Loss: 0.0002147009188604443, Final Batch Loss: 9.070075179806736e-07\n",
      "Epoch 2073, Loss: 9.670677800954763e-05, Final Batch Loss: 8.312731551995967e-06\n",
      "Epoch 2074, Loss: 0.0002328149500687715, Final Batch Loss: 1.6254222146017128e-06\n",
      "Epoch 2075, Loss: 0.0307513565290094, Final Batch Loss: 0.030666518956422806\n",
      "Epoch 2076, Loss: 0.0004318318844411806, Final Batch Loss: 1.8691001969273202e-05\n",
      "Epoch 2077, Loss: 0.001608687984116841, Final Batch Loss: 1.9856664948747493e-05\n",
      "Epoch 2078, Loss: 0.0015548518528021305, Final Batch Loss: 7.606978215335403e-06\n",
      "Epoch 2079, Loss: 0.0003442360032295255, Final Batch Loss: 0.0001790998940123245\n",
      "Epoch 2080, Loss: 0.0003307694269096828, Final Batch Loss: 2.2973752038524253e-06\n",
      "Epoch 2081, Loss: 0.0006740465212828894, Final Batch Loss: 4.6169366214598995e-06\n",
      "Epoch 2082, Loss: 0.00012504187549211565, Final Batch Loss: 1.2737203178403433e-05\n",
      "Epoch 2083, Loss: 0.0007351606825523049, Final Batch Loss: 8.719371180632152e-06\n",
      "Epoch 2084, Loss: 7.62517136081442e-05, Final Batch Loss: 1.3069636224827264e-05\n",
      "Epoch 2085, Loss: 0.020701690671558026, Final Batch Loss: 2.3326106202148367e-06\n",
      "Epoch 2086, Loss: 0.0010287157651873713, Final Batch Loss: 1.4168016605253797e-05\n",
      "Epoch 2087, Loss: 0.001346140624718828, Final Batch Loss: 1.527044878457673e-05\n",
      "Epoch 2088, Loss: 0.0005161858482551906, Final Batch Loss: 1.1285953405604232e-05\n",
      "Epoch 2089, Loss: 0.00016192870242548452, Final Batch Loss: 6.914132882229751e-06\n",
      "Epoch 2090, Loss: 0.012584215291070677, Final Batch Loss: 3.2456304325023666e-05\n",
      "Epoch 2091, Loss: 0.006651563699563212, Final Batch Loss: 3.4832485198421637e-06\n",
      "Epoch 2092, Loss: 0.00021273326711934715, Final Batch Loss: 2.351106559217442e-06\n",
      "Epoch 2093, Loss: 0.00015288207279695598, Final Batch Loss: 9.02437386685051e-06\n",
      "Epoch 2094, Loss: 0.000327575673679803, Final Batch Loss: 5.859343445990817e-07\n",
      "Epoch 2095, Loss: 0.0001793452074139168, Final Batch Loss: 1.687824010332406e-06\n",
      "Epoch 2096, Loss: 0.0002012671427849, Final Batch Loss: 2.8192228000989417e-06\n",
      "Epoch 2097, Loss: 9.80606110942972e-05, Final Batch Loss: 2.518156179576181e-06\n",
      "Epoch 2098, Loss: 0.0004586960857864142, Final Batch Loss: 1.001549662760226e-05\n",
      "Epoch 2099, Loss: 0.0002565620328454088, Final Batch Loss: 8.401767672694405e-07\n",
      "Epoch 2100, Loss: 0.0002796170892338523, Final Batch Loss: 3.8472207961604e-06\n",
      "Epoch 2101, Loss: 0.0003377764707579445, Final Batch Loss: 1.742580388963688e-05\n",
      "Epoch 2102, Loss: 0.0013007607478954242, Final Batch Loss: 9.920946695274324e-07\n",
      "Epoch 2103, Loss: 0.0009568297951432214, Final Batch Loss: 8.801162039162591e-06\n",
      "Epoch 2104, Loss: 0.0007433214682919242, Final Batch Loss: 0.0005355831235647202\n",
      "Epoch 2105, Loss: 6.086011643446909e-05, Final Batch Loss: 5.235450316831702e-06\n",
      "Epoch 2106, Loss: 0.0008928400207679488, Final Batch Loss: 1.572107612446416e-05\n",
      "Epoch 2107, Loss: 0.0010611234185802232, Final Batch Loss: 7.546697844418304e-08\n",
      "Epoch 2108, Loss: 0.0008493504710216371, Final Batch Loss: 1.5977122529875487e-05\n",
      "Epoch 2109, Loss: 9.83542182169117e-05, Final Batch Loss: 7.65315598982852e-06\n",
      "Epoch 2110, Loss: 0.00011822477256728803, Final Batch Loss: 1.2069387594237924e-05\n",
      "Epoch 2111, Loss: 2.3224496700890995e-05, Final Batch Loss: 2.4305654733325355e-06\n",
      "Epoch 2112, Loss: 0.0002810550385277111, Final Batch Loss: 9.025011422636453e-06\n",
      "Epoch 2113, Loss: 0.015763367241262927, Final Batch Loss: 1.1204448355783825e-06\n",
      "Epoch 2114, Loss: 0.012751579155860782, Final Batch Loss: 0.00028320972342044115\n",
      "Epoch 2115, Loss: 0.0005885300794084003, Final Batch Loss: 1.5610909258612082e-06\n",
      "Epoch 2116, Loss: 0.000838371146528516, Final Batch Loss: 2.1959371224511415e-05\n",
      "Epoch 2117, Loss: 0.0005394834042675711, Final Batch Loss: 5.086916280561127e-05\n",
      "Epoch 2118, Loss: 0.013812895248378254, Final Batch Loss: 5.513811265700497e-05\n",
      "Epoch 2119, Loss: 0.05392007520322295, Final Batch Loss: 0.05267016962170601\n",
      "Epoch 2120, Loss: 0.009038778617664889, Final Batch Loss: 0.00028758906410075724\n",
      "Epoch 2121, Loss: 0.010090926357253949, Final Batch Loss: 1.4371654515343835e-06\n",
      "Epoch 2122, Loss: 0.009817689406531827, Final Batch Loss: 3.460547759459587e-06\n",
      "Epoch 2123, Loss: 0.0013639293753939796, Final Batch Loss: 0.00011350610293447971\n",
      "Epoch 2124, Loss: 0.010081696343036128, Final Batch Loss: 5.301026249071583e-06\n",
      "Epoch 2125, Loss: 0.0024324613198132283, Final Batch Loss: 5.8511791394266766e-06\n",
      "Epoch 2126, Loss: 0.002528744815549544, Final Batch Loss: 5.12052884005243e-06\n",
      "Epoch 2127, Loss: 0.0003737781137260754, Final Batch Loss: 1.6044106132540037e-06\n",
      "Epoch 2128, Loss: 0.0002664602327513421, Final Batch Loss: 1.7206435586558655e-05\n",
      "Epoch 2129, Loss: 0.00029987489482152796, Final Batch Loss: 5.996730124024907e-06\n",
      "Epoch 2130, Loss: 0.0011823861808863967, Final Batch Loss: 2.903299503032031e-07\n",
      "Epoch 2131, Loss: 0.0004368339491520601, Final Batch Loss: 4.646261004381813e-06\n",
      "Epoch 2132, Loss: 0.00041089916238945534, Final Batch Loss: 4.053404609294375e-06\n",
      "Epoch 2133, Loss: 0.0009312523768585379, Final Batch Loss: 1.020813397190068e-05\n",
      "Epoch 2134, Loss: 0.0009636205361687189, Final Batch Loss: 5.989638793835184e-06\n",
      "Epoch 2135, Loss: 0.0009034350586318851, Final Batch Loss: 1.138705738412682e-05\n",
      "Epoch 2136, Loss: 0.004834649515146339, Final Batch Loss: 1.3060419405519497e-05\n",
      "Epoch 2137, Loss: 0.000132342550557496, Final Batch Loss: 1.0702529834816232e-05\n",
      "Epoch 2138, Loss: 0.0019380002369153715, Final Batch Loss: 6.479486387434008e-07\n",
      "Epoch 2139, Loss: 0.0024757032849862526, Final Batch Loss: 3.871662556775846e-06\n",
      "Epoch 2140, Loss: 0.026245227852399466, Final Batch Loss: 4.2251269860571483e-07\n",
      "Epoch 2141, Loss: 0.00047680203518041253, Final Batch Loss: 3.6627673694056284e-07\n",
      "Epoch 2142, Loss: 0.0002526376808873465, Final Batch Loss: 3.982120688306168e-06\n",
      "Epoch 2143, Loss: 0.0005634690020883681, Final Batch Loss: 2.7110303335575736e-07\n",
      "Epoch 2144, Loss: 0.00027185841406662803, Final Batch Loss: 4.952355084242299e-06\n",
      "Epoch 2145, Loss: 0.0015749639122759618, Final Batch Loss: 4.0548939068685286e-06\n",
      "Epoch 2146, Loss: 0.00014490955754808965, Final Batch Loss: 1.1814800018328242e-06\n",
      "Epoch 2147, Loss: 0.0001700487804328077, Final Batch Loss: 8.037312909436878e-06\n",
      "Epoch 2148, Loss: 0.0004229714528491968, Final Batch Loss: 8.301539492094889e-05\n",
      "Epoch 2149, Loss: 0.00012246324052966884, Final Batch Loss: 3.126765705019352e-06\n",
      "Epoch 2150, Loss: 0.00016957494858615973, Final Batch Loss: 2.1559466404141858e-05\n",
      "Epoch 2151, Loss: 0.0025124094465667213, Final Batch Loss: 5.049629180575721e-06\n",
      "Epoch 2152, Loss: 0.0006055046500677008, Final Batch Loss: 2.811622607623576e-06\n",
      "Epoch 2153, Loss: 0.001974139838011979, Final Batch Loss: 4.9283313273917884e-05\n",
      "Epoch 2154, Loss: 0.00021157705668883864, Final Batch Loss: 3.587385799619369e-05\n",
      "Epoch 2155, Loss: 0.00025324145644844975, Final Batch Loss: 2.7602427508099936e-06\n",
      "Epoch 2156, Loss: 0.00021912834790782654, Final Batch Loss: 2.5459719381615287e-06\n",
      "Epoch 2157, Loss: 0.0004957994033247815, Final Batch Loss: 3.7484710446733516e-06\n",
      "Epoch 2158, Loss: 0.00033000626990542514, Final Batch Loss: 5.805379714729497e-06\n",
      "Epoch 2159, Loss: 0.006584743812652505, Final Batch Loss: 6.863976409476891e-07\n",
      "Epoch 2160, Loss: 8.815661351491144e-05, Final Batch Loss: 1.0122718094862648e-06\n",
      "Epoch 2161, Loss: 0.00016239838510045956, Final Batch Loss: 5.826659162266878e-06\n",
      "Epoch 2162, Loss: 0.0003779359955160544, Final Batch Loss: 3.470612227829406e-06\n",
      "Epoch 2163, Loss: 7.375719273738923e-05, Final Batch Loss: 4.462574452190893e-06\n",
      "Epoch 2164, Loss: 6.441057725226074e-05, Final Batch Loss: 3.373291292518843e-06\n",
      "Epoch 2165, Loss: 0.0005344467908088291, Final Batch Loss: 7.632759775333398e-07\n",
      "Epoch 2166, Loss: 0.006030248720975351, Final Batch Loss: 7.359307801380055e-06\n",
      "Epoch 2167, Loss: 0.0009866847360626707, Final Batch Loss: 3.780631595873274e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2168, Loss: 0.0007411093952214287, Final Batch Loss: 3.337742236908525e-05\n",
      "Epoch 2169, Loss: 0.00033824805154836213, Final Batch Loss: 3.3164353681058856e-06\n",
      "Epoch 2170, Loss: 0.000574048929138371, Final Batch Loss: 3.578303221729584e-05\n",
      "Epoch 2171, Loss: 0.0006174432421630627, Final Batch Loss: 1.969966797332745e-05\n",
      "Epoch 2172, Loss: 0.0019690538001668756, Final Batch Loss: 8.181098564818967e-06\n",
      "Epoch 2173, Loss: 0.00034209141676910804, Final Batch Loss: 2.879628664231859e-05\n",
      "Epoch 2174, Loss: 0.00037076582657391555, Final Batch Loss: 2.285216214659158e-05\n",
      "Epoch 2175, Loss: 0.00041419457977553975, Final Batch Loss: 6.6811817305278964e-06\n",
      "Epoch 2176, Loss: 0.00032453091114348354, Final Batch Loss: 7.387887421828054e-07\n",
      "Epoch 2177, Loss: 0.0008323189837255995, Final Batch Loss: 3.251571570217493e-06\n",
      "Epoch 2178, Loss: 0.00015197506547792727, Final Batch Loss: 2.058318023046013e-05\n",
      "Epoch 2179, Loss: 0.0026600633662496875, Final Batch Loss: 2.637969191709999e-05\n",
      "Epoch 2180, Loss: 0.000278468755141148, Final Batch Loss: 1.6876332438187092e-06\n",
      "Epoch 2181, Loss: 0.0003562954675544461, Final Batch Loss: 1.2785226317646448e-06\n",
      "Epoch 2182, Loss: 0.00019942886478929722, Final Batch Loss: 2.8416414352250285e-05\n",
      "Epoch 2183, Loss: 0.00016336183614384936, Final Batch Loss: 9.673169188317843e-06\n",
      "Epoch 2184, Loss: 0.003588648251906079, Final Batch Loss: 2.0513673462119186e-06\n",
      "Epoch 2185, Loss: 0.0002481262489339997, Final Batch Loss: 2.535942712711403e-06\n",
      "Epoch 2186, Loss: 0.17611081967932307, Final Batch Loss: 1.9419412922161428e-07\n",
      "Epoch 2187, Loss: 0.03100614150821457, Final Batch Loss: 0.0042847222648561\n",
      "Epoch 2188, Loss: 0.003895817151715164, Final Batch Loss: 1.188786973216338e-05\n",
      "Epoch 2189, Loss: 0.0005659214616571262, Final Batch Loss: 3.3397434890503064e-05\n",
      "Epoch 2190, Loss: 0.00244393123671216, Final Batch Loss: 7.970306614879519e-05\n",
      "Epoch 2191, Loss: 0.043517424279343686, Final Batch Loss: 3.51998969563283e-05\n",
      "Epoch 2192, Loss: 0.03836920833600743, Final Batch Loss: 7.738075510133058e-06\n",
      "Epoch 2193, Loss: 0.023800752574743456, Final Batch Loss: 2.1058875063317828e-05\n",
      "Epoch 2194, Loss: 0.013688733417438925, Final Batch Loss: 0.00019259464170318097\n",
      "Epoch 2195, Loss: 0.011435873606842506, Final Batch Loss: 0.009311728179454803\n",
      "Epoch 2196, Loss: 0.00022582568783491297, Final Batch Loss: 1.086846077669179e-05\n",
      "Epoch 2197, Loss: 0.023813759185941308, Final Batch Loss: 1.4430563169298694e-05\n",
      "Epoch 2198, Loss: 0.04153287482677115, Final Batch Loss: 8.193721441784874e-05\n",
      "Epoch 2199, Loss: 0.0032469647167090443, Final Batch Loss: 3.879695577779785e-05\n",
      "Epoch 2200, Loss: 0.002342068456528068, Final Batch Loss: 4.802897456102073e-05\n",
      "Epoch 2201, Loss: 0.0017596460079403187, Final Batch Loss: 2.2212772819329984e-05\n",
      "Epoch 2202, Loss: 0.0008208776712308463, Final Batch Loss: 2.4663284420967102e-05\n",
      "Epoch 2203, Loss: 0.0015493602509195625, Final Batch Loss: 0.0010588017757982016\n",
      "Epoch 2204, Loss: 0.003023106464297598, Final Batch Loss: 0.00122362794354558\n",
      "Epoch 2205, Loss: 0.0010758040486962273, Final Batch Loss: 0.0004745911865029484\n",
      "Epoch 2206, Loss: 0.0013556256062656757, Final Batch Loss: 0.00013710957136936486\n",
      "Epoch 2207, Loss: 0.0006206660933685271, Final Batch Loss: 3.7550013075815514e-05\n",
      "Epoch 2208, Loss: 0.0006815300184825901, Final Batch Loss: 4.805377557204338e-06\n",
      "Epoch 2209, Loss: 0.0007970407405082369, Final Batch Loss: 0.00011454229388618842\n",
      "Epoch 2210, Loss: 0.00034840627677112934, Final Batch Loss: 3.939839643862797e-06\n",
      "Epoch 2211, Loss: 0.002298976668726027, Final Batch Loss: 0.00020923199190292507\n",
      "Epoch 2212, Loss: 0.003037838207774257, Final Batch Loss: 2.0375733583932742e-05\n",
      "Epoch 2213, Loss: 0.0006943365112022093, Final Batch Loss: 5.761727607023204e-06\n",
      "Epoch 2214, Loss: 0.0010432504020627675, Final Batch Loss: 0.00018239632481709123\n",
      "Epoch 2215, Loss: 0.0004878259198903834, Final Batch Loss: 0.00019422681361902505\n",
      "Epoch 2216, Loss: 0.0029151295763085727, Final Batch Loss: 2.660814288901747e-06\n",
      "Epoch 2217, Loss: 0.0014571427200280596, Final Batch Loss: 6.809498154325411e-05\n",
      "Epoch 2218, Loss: 0.0005992515523303155, Final Batch Loss: 2.2694661311106756e-05\n",
      "Epoch 2219, Loss: 0.001244010255959438, Final Batch Loss: 3.981091867899522e-05\n",
      "Epoch 2220, Loss: 0.00023252606888490845, Final Batch Loss: 4.331870877649635e-05\n",
      "Epoch 2221, Loss: 0.00022414787184743545, Final Batch Loss: 9.856096767180134e-06\n",
      "Epoch 2222, Loss: 0.000396691451442166, Final Batch Loss: 2.1461360120156314e-06\n",
      "Epoch 2223, Loss: 0.011480861777613427, Final Batch Loss: 1.4828239727648906e-05\n",
      "Epoch 2224, Loss: 0.001059989507211867, Final Batch Loss: 1.1998353329545353e-05\n",
      "Epoch 2225, Loss: 0.006517597265315089, Final Batch Loss: 5.972671715426259e-06\n",
      "Epoch 2226, Loss: 0.0006280230089714678, Final Batch Loss: 1.6910493286559358e-05\n",
      "Epoch 2227, Loss: 0.0002845445924890555, Final Batch Loss: 2.8221040338394232e-05\n",
      "Epoch 2228, Loss: 0.002685240566876246, Final Batch Loss: 1.626535777177196e-05\n",
      "Epoch 2229, Loss: 0.0003441408478010999, Final Batch Loss: 1.1185196626684046e-06\n",
      "Epoch 2230, Loss: 0.0008565468413621602, Final Batch Loss: 5.701693226001225e-06\n",
      "Epoch 2231, Loss: 0.00028861379496447626, Final Batch Loss: 4.89634730911348e-05\n",
      "Epoch 2232, Loss: 0.00011255871208959434, Final Batch Loss: 2.4714713617868256e-06\n",
      "Epoch 2233, Loss: 0.00017093299629777903, Final Batch Loss: 3.1225440579873975e-06\n",
      "Epoch 2234, Loss: 0.00015207819802753875, Final Batch Loss: 8.533331310900394e-06\n",
      "Epoch 2235, Loss: 0.00016755068122620287, Final Batch Loss: 1.8889002149080625e-06\n",
      "Epoch 2236, Loss: 0.0049056838955721105, Final Batch Loss: 1.7239815861103125e-05\n",
      "Epoch 2237, Loss: 0.00018876177614401968, Final Batch Loss: 4.057895239384379e-06\n",
      "Epoch 2238, Loss: 0.0002719006319011896, Final Batch Loss: 1.4820431715634186e-05\n",
      "Epoch 2239, Loss: 0.00043825427496813063, Final Batch Loss: 1.0887737516895868e-05\n",
      "Epoch 2240, Loss: 0.00012893261526869537, Final Batch Loss: 2.0821886209887452e-05\n",
      "Epoch 2241, Loss: 0.002749270002254889, Final Batch Loss: 0.0002478382957633585\n",
      "Epoch 2242, Loss: 0.00026938926316688594, Final Batch Loss: 1.974859151232522e-05\n",
      "Epoch 2243, Loss: 0.00038765349074765254, Final Batch Loss: 1.7712458202367998e-06\n",
      "Epoch 2244, Loss: 0.0007792654637341911, Final Batch Loss: 0.0004045816313009709\n",
      "Epoch 2245, Loss: 0.000159953958927872, Final Batch Loss: 1.0173699592996854e-05\n",
      "Epoch 2246, Loss: 0.0003959232953434366, Final Batch Loss: 1.1859699952765368e-05\n",
      "Epoch 2247, Loss: 0.0002519190526300008, Final Batch Loss: 1.3160292837710585e-06\n",
      "Epoch 2248, Loss: 0.0005307508918122039, Final Batch Loss: 3.1433817184733925e-06\n",
      "Epoch 2249, Loss: 0.0013599458300177503, Final Batch Loss: 7.925885256554466e-06\n",
      "Epoch 2250, Loss: 0.0005879394272483296, Final Batch Loss: 4.793129392055562e-06\n",
      "Epoch 2251, Loss: 0.00015061831402363168, Final Batch Loss: 1.4656257008027751e-05\n",
      "Epoch 2252, Loss: 0.0003172666857835793, Final Batch Loss: 1.3670268117493833e-06\n",
      "Epoch 2253, Loss: 0.0005986878782948679, Final Batch Loss: 5.726906692871125e-06\n",
      "Epoch 2254, Loss: 9.659397619543597e-05, Final Batch Loss: 1.8480737935533398e-06\n",
      "Epoch 2255, Loss: 0.0006183831379757976, Final Batch Loss: 8.608884627392399e-07\n",
      "Epoch 2256, Loss: 0.00023522938511177927, Final Batch Loss: 4.807973709830549e-06\n",
      "Epoch 2257, Loss: 0.00035875653168204735, Final Batch Loss: 3.0456237709586276e-06\n",
      "Epoch 2258, Loss: 0.00020989472096744066, Final Batch Loss: 2.81335337604105e-06\n",
      "Epoch 2259, Loss: 0.00019816107710823871, Final Batch Loss: 7.801260153428302e-07\n",
      "Epoch 2260, Loss: 0.0036295154454819567, Final Batch Loss: 9.972644329536706e-05\n",
      "Epoch 2261, Loss: 0.0004909377131525616, Final Batch Loss: 1.3067709005554207e-05\n",
      "Epoch 2262, Loss: 0.00015581928465735473, Final Batch Loss: 2.5660242499725427e-06\n",
      "Epoch 2263, Loss: 0.0013673464184194017, Final Batch Loss: 8.876589163264725e-06\n",
      "Epoch 2264, Loss: 0.0007119324282029993, Final Batch Loss: 1.0366153219365515e-05\n",
      "Epoch 2265, Loss: 0.00032473487658535305, Final Batch Loss: 2.7444873921922408e-05\n",
      "Epoch 2266, Loss: 0.00010586972567239172, Final Batch Loss: 1.3938408301328309e-05\n",
      "Epoch 2267, Loss: 0.0004006764326618395, Final Batch Loss: 2.956286698463373e-05\n",
      "Epoch 2268, Loss: 0.00015568663685883166, Final Batch Loss: 4.929232090944424e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2269, Loss: 0.0004280113810466446, Final Batch Loss: 1.6068518107204e-06\n",
      "Epoch 2270, Loss: 0.0007563544448032644, Final Batch Loss: 1.6909331179704168e-06\n",
      "Epoch 2271, Loss: 0.00010023661771185743, Final Batch Loss: 1.0060089152830187e-06\n",
      "Epoch 2272, Loss: 0.00037213374977795866, Final Batch Loss: 1.4834194189461414e-05\n",
      "Epoch 2273, Loss: 8.461222520850242e-05, Final Batch Loss: 8.629185686004348e-06\n",
      "Epoch 2274, Loss: 8.253833729554572e-05, Final Batch Loss: 1.052187712957675e-06\n",
      "Epoch 2275, Loss: 0.00011602089585593944, Final Batch Loss: 4.028088824270526e-06\n",
      "Epoch 2276, Loss: 0.000336487738309188, Final Batch Loss: 3.436489714658819e-05\n",
      "Epoch 2277, Loss: 0.00025205152409313314, Final Batch Loss: 3.841774287138833e-06\n",
      "Epoch 2278, Loss: 0.00017268740964482276, Final Batch Loss: 3.537973498168867e-06\n",
      "Epoch 2279, Loss: 0.00036251093385430977, Final Batch Loss: 1.5524478840234224e-06\n",
      "Epoch 2280, Loss: 3.8331769161459306e-05, Final Batch Loss: 2.4181686058000196e-06\n",
      "Epoch 2281, Loss: 0.0004008583564143464, Final Batch Loss: 9.803712600842118e-06\n",
      "Epoch 2282, Loss: 0.00012900882029498462, Final Batch Loss: 4.42964937974466e-06\n",
      "Epoch 2283, Loss: 0.0002900150432196824, Final Batch Loss: 5.518528269021772e-06\n",
      "Epoch 2284, Loss: 0.000599616572060313, Final Batch Loss: 8.198273462767247e-06\n",
      "Epoch 2285, Loss: 0.011451943486861182, Final Batch Loss: 7.471580374840414e-06\n",
      "Epoch 2286, Loss: 0.018523539806665212, Final Batch Loss: 3.3964806789299473e-06\n",
      "Epoch 2287, Loss: 0.0001556829431024198, Final Batch Loss: 8.84606834006263e-06\n",
      "Epoch 2288, Loss: 0.0003036320648277524, Final Batch Loss: 5.609427375929954e-07\n",
      "Epoch 2289, Loss: 0.00021113483478529815, Final Batch Loss: 3.7782465369673446e-05\n",
      "Epoch 2290, Loss: 0.0013348088920679402, Final Batch Loss: 0.0004773117252625525\n",
      "Epoch 2291, Loss: 0.020113365384304416, Final Batch Loss: 1.357265682599973e-05\n",
      "Epoch 2292, Loss: 0.0018046907342750274, Final Batch Loss: 7.5545183790382e-05\n",
      "Epoch 2293, Loss: 0.0005685168171112309, Final Batch Loss: 7.687976903980598e-05\n",
      "Epoch 2294, Loss: 0.006891712465858291, Final Batch Loss: 0.00045801399392075837\n",
      "Epoch 2295, Loss: 0.005428438324770468, Final Batch Loss: 3.519165693433024e-05\n",
      "Epoch 2296, Loss: 0.004414466670567663, Final Batch Loss: 1.1348814950906672e-05\n",
      "Epoch 2297, Loss: 0.0002750341790260791, Final Batch Loss: 3.191685027559288e-05\n",
      "Epoch 2298, Loss: 0.001742439867939538, Final Batch Loss: 3.758566890610382e-05\n",
      "Epoch 2299, Loss: 0.00028320561068539973, Final Batch Loss: 1.4071344594412949e-05\n",
      "Epoch 2300, Loss: 0.0001523667846186072, Final Batch Loss: 2.395505362073891e-05\n",
      "Epoch 2301, Loss: 0.014968585633027942, Final Batch Loss: 1.566830860610935e-06\n",
      "Epoch 2302, Loss: 0.019942228046573973, Final Batch Loss: 0.019673185423016548\n",
      "Epoch 2303, Loss: 0.00014287579625715807, Final Batch Loss: 5.623758170258952e-07\n",
      "Epoch 2304, Loss: 0.0004374095730099725, Final Batch Loss: 1.277317187486915e-05\n",
      "Epoch 2305, Loss: 0.00012832733011691744, Final Batch Loss: 4.423432983458042e-06\n",
      "Epoch 2306, Loss: 0.00013540158547442616, Final Batch Loss: 1.8761949831969105e-05\n",
      "Epoch 2307, Loss: 0.00014606153413865286, Final Batch Loss: 1.7658761635175324e-06\n",
      "Epoch 2308, Loss: 0.0032867923854098535, Final Batch Loss: 2.812227421600255e-06\n",
      "Epoch 2309, Loss: 0.0005229036295304468, Final Batch Loss: 1.508778859715676e-05\n",
      "Epoch 2310, Loss: 0.0010444612655646779, Final Batch Loss: 0.0001567658910062164\n",
      "Epoch 2311, Loss: 0.0007739062932614615, Final Batch Loss: 8.875609637470916e-06\n",
      "Epoch 2312, Loss: 8.025627478502884e-05, Final Batch Loss: 1.788124706081362e-07\n",
      "Epoch 2313, Loss: 0.00037662702436591644, Final Batch Loss: 7.363940426330373e-07\n",
      "Epoch 2314, Loss: 0.00010496889041178292, Final Batch Loss: 2.9149086913093925e-06\n",
      "Epoch 2315, Loss: 0.0005255090477476188, Final Batch Loss: 2.0847737687290646e-05\n",
      "Epoch 2316, Loss: 0.0001669369450851832, Final Batch Loss: 1.0171846952289343e-05\n",
      "Epoch 2317, Loss: 0.00013116535762947024, Final Batch Loss: 9.809218681766652e-06\n",
      "Epoch 2318, Loss: 0.00011400071036860027, Final Batch Loss: 1.0439837751619052e-05\n",
      "Epoch 2319, Loss: 0.0019338093764389441, Final Batch Loss: 1.235349458283963e-07\n",
      "Epoch 2320, Loss: 0.0014611936626351962, Final Batch Loss: 5.257047632767353e-06\n",
      "Epoch 2321, Loss: 0.019288698882746758, Final Batch Loss: 0.019196374341845512\n",
      "Epoch 2322, Loss: 0.003269623400854016, Final Batch Loss: 0.003031296655535698\n",
      "Epoch 2323, Loss: 0.004410447007501261, Final Batch Loss: 5.434460945252795e-06\n",
      "Epoch 2324, Loss: 0.03181963264466958, Final Batch Loss: 2.4284658138640225e-05\n",
      "Epoch 2325, Loss: 0.003321312694652079, Final Batch Loss: 3.670627165774931e-06\n",
      "Epoch 2326, Loss: 0.0009890248988995154, Final Batch Loss: 1.3143911019142251e-05\n",
      "Epoch 2327, Loss: 0.0014948526791158656, Final Batch Loss: 4.369042471807916e-06\n",
      "Epoch 2328, Loss: 0.00022878209983900888, Final Batch Loss: 1.3848314665665384e-05\n",
      "Epoch 2329, Loss: 0.0005861145252765709, Final Batch Loss: 1.9360390069778077e-05\n",
      "Epoch 2330, Loss: 0.00256376881674214, Final Batch Loss: 5.031921318732202e-06\n",
      "Epoch 2331, Loss: 0.0010251456061496356, Final Batch Loss: 1.303260160057107e-05\n",
      "Epoch 2332, Loss: 0.0005287597708729663, Final Batch Loss: 4.846860247198492e-05\n",
      "Epoch 2333, Loss: 0.05917790773821707, Final Batch Loss: 8.588812306697946e-06\n",
      "Epoch 2334, Loss: 0.0015663444041820185, Final Batch Loss: 2.193078034906648e-05\n",
      "Epoch 2335, Loss: 0.005035408744788583, Final Batch Loss: 1.683942537056282e-05\n",
      "Epoch 2336, Loss: 0.0020498971593951865, Final Batch Loss: 9.767613846634049e-06\n",
      "Epoch 2337, Loss: 0.0008952619735964618, Final Batch Loss: 1.6812963394841063e-06\n",
      "Epoch 2338, Loss: 0.00018966707693834906, Final Batch Loss: 5.916177087783581e-06\n",
      "Epoch 2339, Loss: 0.0006236663807612786, Final Batch Loss: 0.00010585547715891153\n",
      "Epoch 2340, Loss: 0.000679790163871985, Final Batch Loss: 2.882514763768995e-06\n",
      "Epoch 2341, Loss: 0.0002988648259361071, Final Batch Loss: 2.7128597139380872e-05\n",
      "Epoch 2342, Loss: 0.00035220067820773693, Final Batch Loss: 1.520494060969213e-05\n",
      "Epoch 2343, Loss: 0.000395566978795614, Final Batch Loss: 0.00010558289068285376\n",
      "Epoch 2344, Loss: 0.031145170011541268, Final Batch Loss: 8.504774086759426e-06\n",
      "Epoch 2345, Loss: 0.0006683000078737678, Final Batch Loss: 9.000449063023552e-05\n",
      "Epoch 2346, Loss: 0.004186935959296534, Final Batch Loss: 0.00021427375031635165\n",
      "Epoch 2347, Loss: 0.0005577875460858195, Final Batch Loss: 6.3090915318753105e-06\n",
      "Epoch 2348, Loss: 0.00015348250872193603, Final Batch Loss: 1.265236278413795e-05\n",
      "Epoch 2349, Loss: 0.004533861638037706, Final Batch Loss: 3.4125881938962266e-05\n",
      "Epoch 2350, Loss: 0.0013079928767183446, Final Batch Loss: 3.334058419568464e-05\n",
      "Epoch 2351, Loss: 0.0014558687953467597, Final Batch Loss: 4.316705235396512e-05\n",
      "Epoch 2352, Loss: 0.000565453612807687, Final Batch Loss: 4.5698518079007044e-05\n",
      "Epoch 2353, Loss: 0.00021053253135505656, Final Batch Loss: 3.0512219382217154e-05\n",
      "Epoch 2354, Loss: 0.0003219039944042379, Final Batch Loss: 8.632047865830828e-06\n",
      "Epoch 2355, Loss: 0.00022804126274422742, Final Batch Loss: 2.7958411010331474e-05\n",
      "Epoch 2356, Loss: 0.00016934008380076193, Final Batch Loss: 6.806370947742835e-06\n",
      "Epoch 2357, Loss: 0.00029501891640393296, Final Batch Loss: 5.778572813142091e-05\n",
      "Epoch 2358, Loss: 0.0002502063324527626, Final Batch Loss: 1.6356776541215368e-05\n",
      "Epoch 2359, Loss: 0.0008632955580196722, Final Batch Loss: 9.007016342366114e-05\n",
      "Epoch 2360, Loss: 0.00041893217451161036, Final Batch Loss: 1.9493611034704372e-05\n",
      "Epoch 2361, Loss: 0.0001729349902461763, Final Batch Loss: 8.293828614114318e-06\n",
      "Epoch 2362, Loss: 0.00029248080818433664, Final Batch Loss: 2.163518547604326e-05\n",
      "Epoch 2363, Loss: 0.0003242120244522084, Final Batch Loss: 9.08025413082214e-06\n",
      "Epoch 2364, Loss: 0.0005029297921055331, Final Batch Loss: 3.5590663173934445e-05\n",
      "Epoch 2365, Loss: 0.0003616029757154138, Final Batch Loss: 5.6559842960268725e-06\n",
      "Epoch 2366, Loss: 0.00027342270755070786, Final Batch Loss: 2.8953207220183685e-05\n",
      "Epoch 2367, Loss: 0.0002850194694019592, Final Batch Loss: 7.941996955196373e-06\n",
      "Epoch 2368, Loss: 0.0028357256995263924, Final Batch Loss: 0.0026918083894997835\n",
      "Epoch 2369, Loss: 0.000510760156203105, Final Batch Loss: 3.996668601757847e-05\n",
      "Epoch 2370, Loss: 0.0007881837884724519, Final Batch Loss: 0.00016689670155756176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2371, Loss: 0.02122609302705314, Final Batch Loss: 1.3673923604073934e-05\n",
      "Epoch 2372, Loss: 0.01584386800550419, Final Batch Loss: 1.0384202141722199e-05\n",
      "Epoch 2373, Loss: 0.1879448664519714, Final Batch Loss: 5.629848601529375e-06\n",
      "Epoch 2374, Loss: 0.005491589640314487, Final Batch Loss: 0.00021666495013050735\n",
      "Epoch 2375, Loss: 0.0025336750823043985, Final Batch Loss: 0.0011107384925708175\n",
      "Epoch 2376, Loss: 0.0052062752556594205, Final Batch Loss: 0.00020759087055921555\n",
      "Epoch 2377, Loss: 0.010392530003969114, Final Batch Loss: 0.0003107445081695914\n",
      "Epoch 2378, Loss: 0.00028239126595508424, Final Batch Loss: 1.0133080650120974e-05\n",
      "Epoch 2379, Loss: 0.02468007327149735, Final Batch Loss: 1.343017447652528e-05\n",
      "Epoch 2380, Loss: 0.0032285410225085798, Final Batch Loss: 0.00026037284987978637\n",
      "Epoch 2381, Loss: 0.005148138473487052, Final Batch Loss: 0.000125911581562832\n",
      "Epoch 2382, Loss: 0.0005539381628523188, Final Batch Loss: 2.0497493096627295e-05\n",
      "Epoch 2383, Loss: 0.005497296151361297, Final Batch Loss: 1.774291740730405e-05\n",
      "Epoch 2384, Loss: 0.007980616679788, Final Batch Loss: 1.1910947250726167e-05\n",
      "Epoch 2385, Loss: 0.000330078797560418, Final Batch Loss: 3.5218155971961096e-05\n",
      "Epoch 2386, Loss: 0.0008713197636325276, Final Batch Loss: 1.0762157671706518e-06\n",
      "Epoch 2387, Loss: 0.0001778785044734832, Final Batch Loss: 1.5828465620870702e-05\n",
      "Epoch 2388, Loss: 0.00020280450752352408, Final Batch Loss: 1.1334075225022389e-06\n",
      "Epoch 2389, Loss: 0.002841388293404634, Final Batch Loss: 1.9583731045713648e-05\n",
      "Epoch 2390, Loss: 0.011187755779019426, Final Batch Loss: 9.716975182527676e-05\n",
      "Epoch 2391, Loss: 0.01300538556029096, Final Batch Loss: 1.600171162863262e-05\n",
      "Epoch 2392, Loss: 0.017720606288321505, Final Batch Loss: 2.2057572550693294e-06\n",
      "Epoch 2393, Loss: 0.010486382369776948, Final Batch Loss: 0.00018888253543991596\n",
      "Epoch 2394, Loss: 0.008938509178278764, Final Batch Loss: 1.578297269588802e-05\n",
      "Epoch 2395, Loss: 0.009002417214787783, Final Batch Loss: 3.6684861697722226e-05\n",
      "Epoch 2396, Loss: 0.0002505303764337441, Final Batch Loss: 3.931940227630548e-05\n",
      "Epoch 2397, Loss: 0.01829705715942964, Final Batch Loss: 0.00012070634693372995\n",
      "Epoch 2398, Loss: 0.0007685271571062913, Final Batch Loss: 1.1283472304057796e-05\n",
      "Epoch 2399, Loss: 0.0006247031451493967, Final Batch Loss: 0.00020830293942708522\n",
      "Epoch 2400, Loss: 0.0013678494651685469, Final Batch Loss: 3.3912574508576654e-06\n",
      "Epoch 2401, Loss: 0.002149503420696419, Final Batch Loss: 0.0001362510520266369\n",
      "Epoch 2402, Loss: 0.0003210566783309332, Final Batch Loss: 1.559267366246786e-05\n",
      "Epoch 2403, Loss: 0.00025897244734096603, Final Batch Loss: 5.264467290544417e-06\n",
      "Epoch 2404, Loss: 0.003823541121164453, Final Batch Loss: 1.6850593965500593e-05\n",
      "Epoch 2405, Loss: 0.007267432187290979, Final Batch Loss: 3.2915322663029656e-05\n",
      "Epoch 2406, Loss: 0.005504589469637722, Final Batch Loss: 5.150520155439153e-05\n",
      "Epoch 2407, Loss: 0.0009029540169649408, Final Batch Loss: 1.7908831068780273e-05\n",
      "Epoch 2408, Loss: 0.0010333543098113296, Final Batch Loss: 9.434698586119339e-05\n",
      "Epoch 2409, Loss: 0.0011129978163353371, Final Batch Loss: 3.607134885896812e-06\n",
      "Epoch 2410, Loss: 0.000502124933518644, Final Batch Loss: 6.018089607096044e-06\n",
      "Epoch 2411, Loss: 0.0003948052858504525, Final Batch Loss: 1.7257996660191566e-05\n",
      "Epoch 2412, Loss: 0.0005306846295525247, Final Batch Loss: 4.009005806437926e-06\n",
      "Epoch 2413, Loss: 0.000280048094225549, Final Batch Loss: 1.4817513147136196e-05\n",
      "Epoch 2414, Loss: 0.0002959588134672231, Final Batch Loss: 1.2002842595393304e-05\n",
      "Epoch 2415, Loss: 0.0027050426142523065, Final Batch Loss: 0.00012549146777018905\n",
      "Epoch 2416, Loss: 0.0008385114231259649, Final Batch Loss: 9.138394489127677e-06\n",
      "Epoch 2417, Loss: 0.000673090321924974, Final Batch Loss: 9.14740940061165e-06\n",
      "Epoch 2418, Loss: 0.004884004467612613, Final Batch Loss: 0.0046607498079538345\n",
      "Epoch 2419, Loss: 0.0005371357136709776, Final Batch Loss: 0.00026604492450132966\n",
      "Epoch 2420, Loss: 0.00022203647452556652, Final Batch Loss: 4.317929779062979e-06\n",
      "Epoch 2421, Loss: 0.0004289009993954096, Final Batch Loss: 0.00020303351629991084\n",
      "Epoch 2422, Loss: 0.00019115945929115696, Final Batch Loss: 1.2098378192604287e-06\n",
      "Epoch 2423, Loss: 0.00014135822232219653, Final Batch Loss: 1.7891647075884975e-05\n",
      "Epoch 2424, Loss: 0.001271562212821209, Final Batch Loss: 5.215329110797029e-07\n",
      "Epoch 2425, Loss: 0.006717203433709074, Final Batch Loss: 1.6050915291998535e-05\n",
      "Epoch 2426, Loss: 0.0005739841395779877, Final Batch Loss: 2.013900257225032e-06\n",
      "Epoch 2427, Loss: 0.00043301066443746095, Final Batch Loss: 2.1405263396445662e-05\n",
      "Epoch 2428, Loss: 0.0012335809468595471, Final Batch Loss: 5.869101187272463e-06\n",
      "Epoch 2429, Loss: 0.0012660935362873715, Final Batch Loss: 6.905680493218824e-05\n",
      "Epoch 2430, Loss: 0.002139785943768402, Final Batch Loss: 0.0018797260709106922\n",
      "Epoch 2431, Loss: 0.0007668376078981964, Final Batch Loss: 1.645870361244306e-05\n",
      "Epoch 2432, Loss: 0.0005744522104578209, Final Batch Loss: 4.871600140177179e-06\n",
      "Epoch 2433, Loss: 0.00019679827084928547, Final Batch Loss: 5.342700660548871e-06\n",
      "Epoch 2434, Loss: 0.00020615621025399378, Final Batch Loss: 7.940753334878536e-07\n",
      "Epoch 2435, Loss: 0.0003709149548285495, Final Batch Loss: 1.9553575839381665e-05\n",
      "Epoch 2436, Loss: 0.0005270349820420961, Final Batch Loss: 7.183275556599256e-06\n",
      "Epoch 2437, Loss: 0.029564259322341968, Final Batch Loss: 9.370593761559576e-05\n",
      "Epoch 2438, Loss: 0.007181969557677803, Final Batch Loss: 0.00035370810655876994\n",
      "Epoch 2439, Loss: 0.004267016520316247, Final Batch Loss: 2.6662004529498518e-05\n",
      "Epoch 2440, Loss: 0.0013159511017875047, Final Batch Loss: 6.206847956491401e-06\n",
      "Epoch 2441, Loss: 0.0008216025330511911, Final Batch Loss: 3.276140660091187e-06\n",
      "Epoch 2442, Loss: 0.0003306469818653568, Final Batch Loss: 8.478664676658809e-05\n",
      "Epoch 2443, Loss: 0.00034506794762023674, Final Batch Loss: 5.878171577933244e-06\n",
      "Epoch 2444, Loss: 0.00031021218433124886, Final Batch Loss: 9.365110599901527e-05\n",
      "Epoch 2445, Loss: 0.0014663367732055121, Final Batch Loss: 6.369992479449138e-05\n",
      "Epoch 2446, Loss: 0.00026646823789633345, Final Batch Loss: 2.6469062504475005e-05\n",
      "Epoch 2447, Loss: 0.00012934369306094595, Final Batch Loss: 3.8872758523211814e-06\n",
      "Epoch 2448, Loss: 0.0003150457744141022, Final Batch Loss: 2.556372464823653e-06\n",
      "Epoch 2449, Loss: 0.0002938829611593974, Final Batch Loss: 1.0052781362901442e-05\n",
      "Epoch 2450, Loss: 0.0002733857194812117, Final Batch Loss: 5.9341177802707534e-06\n",
      "Epoch 2451, Loss: 0.00114749221592092, Final Batch Loss: 1.40707043101429e-05\n",
      "Epoch 2452, Loss: 0.010188744592028343, Final Batch Loss: 8.737797543290071e-06\n",
      "Epoch 2453, Loss: 0.010293446651644445, Final Batch Loss: 2.4407420369243482e-06\n",
      "Epoch 2454, Loss: 0.0003582571039544291, Final Batch Loss: 2.829377626767382e-05\n",
      "Epoch 2455, Loss: 0.0004883939752744482, Final Batch Loss: 4.5229367970023304e-05\n",
      "Epoch 2456, Loss: 0.001854064972121705, Final Batch Loss: 8.665820132591762e-06\n",
      "Epoch 2457, Loss: 0.0004964086810446133, Final Batch Loss: 5.168840289115906e-06\n",
      "Epoch 2458, Loss: 0.0011905708939821125, Final Batch Loss: 3.533874769345857e-05\n",
      "Epoch 2459, Loss: 0.0026024343159178898, Final Batch Loss: 4.013520992884878e-06\n",
      "Epoch 2460, Loss: 0.0017048650491915396, Final Batch Loss: 5.1280512707307935e-06\n",
      "Epoch 2461, Loss: 0.00027445330505315724, Final Batch Loss: 7.206914688140387e-06\n",
      "Epoch 2462, Loss: 0.0008338595738450749, Final Batch Loss: 1.0742486665549222e-05\n",
      "Epoch 2463, Loss: 0.00020205697308028903, Final Batch Loss: 2.2220533537620213e-06\n",
      "Epoch 2464, Loss: 0.0004449359922489293, Final Batch Loss: 1.3860094441042747e-05\n",
      "Epoch 2465, Loss: 0.011885951298154396, Final Batch Loss: 1.1972672837146092e-05\n",
      "Epoch 2466, Loss: 0.0012634297182785303, Final Batch Loss: 0.00010290752106811851\n",
      "Epoch 2467, Loss: 0.0008150399334567737, Final Batch Loss: 4.467026428756071e-06\n",
      "Epoch 2468, Loss: 0.00038255723632119043, Final Batch Loss: 2.8053780624759383e-05\n",
      "Epoch 2469, Loss: 0.0007225389466043453, Final Batch Loss: 0.0005441047251224518\n",
      "Epoch 2470, Loss: 0.00043647398985058317, Final Batch Loss: 2.6610443455865607e-05\n",
      "Epoch 2471, Loss: 0.0012629636991050575, Final Batch Loss: 0.0005075135268270969\n",
      "Epoch 2472, Loss: 0.00018031199493862005, Final Batch Loss: 1.0684651670089806e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2473, Loss: 0.00041672992514918406, Final Batch Loss: 2.7824224162031896e-05\n",
      "Epoch 2474, Loss: 0.00018467915248265854, Final Batch Loss: 4.019051630166359e-06\n",
      "Epoch 2475, Loss: 0.006114463025483019, Final Batch Loss: 1.1438436558819376e-05\n",
      "Epoch 2476, Loss: 0.001605022058583927, Final Batch Loss: 9.833028161665425e-05\n",
      "Epoch 2477, Loss: 0.013140546284375887, Final Batch Loss: 8.59912006490049e-07\n",
      "Epoch 2478, Loss: 0.00012362364065410247, Final Batch Loss: 2.939103069365956e-05\n",
      "Epoch 2479, Loss: 0.0051975148056158105, Final Batch Loss: 4.7991024985094555e-06\n",
      "Epoch 2480, Loss: 0.0025938894473540586, Final Batch Loss: 1.7292330085183494e-05\n",
      "Epoch 2481, Loss: 0.00033934160038029404, Final Batch Loss: 4.4895179485138215e-07\n",
      "Epoch 2482, Loss: 0.00016393514223977945, Final Batch Loss: 2.4658977508806856e-06\n",
      "Epoch 2483, Loss: 0.0007686769651300551, Final Batch Loss: 2.4566183128627017e-05\n",
      "Epoch 2484, Loss: 0.00031711133948419956, Final Batch Loss: 3.222240820832667e-06\n",
      "Epoch 2485, Loss: 0.007752868629495424, Final Batch Loss: 2.9808037652401254e-05\n",
      "Epoch 2486, Loss: 0.00036932884154339263, Final Batch Loss: 6.020709406584501e-06\n",
      "Epoch 2487, Loss: 0.004035690716477802, Final Batch Loss: 0.000760229304432869\n",
      "Epoch 2488, Loss: 0.00035126698651311017, Final Batch Loss: 4.605662252288312e-05\n",
      "Epoch 2489, Loss: 0.0004125415928228904, Final Batch Loss: 1.1718325367837679e-05\n",
      "Epoch 2490, Loss: 0.0001827621263146284, Final Batch Loss: 3.975603249273263e-06\n",
      "Epoch 2491, Loss: 0.00025070021666806497, Final Batch Loss: 2.0070049231435405e-06\n",
      "Epoch 2492, Loss: 0.0035211874280207667, Final Batch Loss: 0.00025384456967003644\n",
      "Epoch 2493, Loss: 0.0009189498072146307, Final Batch Loss: 5.4623993491986766e-05\n",
      "Epoch 2494, Loss: 0.025175101161039493, Final Batch Loss: 0.024855569005012512\n",
      "Epoch 2495, Loss: 0.0042085704367593735, Final Batch Loss: 0.0039712293073534966\n",
      "Epoch 2496, Loss: 0.004696043838805508, Final Batch Loss: 0.004482538439333439\n",
      "Epoch 2497, Loss: 0.0008973429785328335, Final Batch Loss: 4.717254341812804e-06\n",
      "Epoch 2498, Loss: 0.00025870006663808454, Final Batch Loss: 6.245874101296067e-05\n",
      "Epoch 2499, Loss: 0.0028690538388218556, Final Batch Loss: 2.841304194589611e-06\n",
      "Epoch 2500, Loss: 0.0007139194221394973, Final Batch Loss: 9.274325748265255e-06\n",
      "Epoch 2501, Loss: 0.0006632762118670144, Final Batch Loss: 0.00030372056062333286\n",
      "Epoch 2502, Loss: 0.0009509257679383154, Final Batch Loss: 4.480200914258603e-06\n",
      "Epoch 2503, Loss: 0.0015496943057087265, Final Batch Loss: 9.794195648282766e-06\n",
      "Epoch 2504, Loss: 0.00017030917479132768, Final Batch Loss: 3.643562195065897e-06\n",
      "Epoch 2505, Loss: 0.0013606212598631373, Final Batch Loss: 1.3147935533197597e-05\n",
      "Epoch 2506, Loss: 0.0001325251445791764, Final Batch Loss: 2.653519914019853e-05\n",
      "Epoch 2507, Loss: 0.0002523717707845208, Final Batch Loss: 3.932030449504964e-05\n",
      "Epoch 2508, Loss: 7.935999434494079e-05, Final Batch Loss: 4.719599019153975e-06\n",
      "Epoch 2509, Loss: 0.0008282502579675111, Final Batch Loss: 1.434590285498416e-05\n",
      "Epoch 2510, Loss: 0.0017999405392288281, Final Batch Loss: 0.0002594834368210286\n",
      "Epoch 2511, Loss: 0.0004205356103170743, Final Batch Loss: 6.306447630777257e-07\n",
      "Epoch 2512, Loss: 0.0001728187120875191, Final Batch Loss: 1.8005293895839714e-06\n",
      "Epoch 2513, Loss: 0.00017155120668377322, Final Batch Loss: 4.614516342371644e-07\n",
      "Epoch 2514, Loss: 0.0002132036870250431, Final Batch Loss: 3.446427001563279e-07\n",
      "Epoch 2515, Loss: 0.00039907963067875585, Final Batch Loss: 2.0087154553039e-05\n",
      "Epoch 2516, Loss: 0.00042889552889846527, Final Batch Loss: 8.012043508642819e-06\n",
      "Epoch 2517, Loss: 6.931993118541868e-05, Final Batch Loss: 5.876930117665324e-06\n",
      "Epoch 2518, Loss: 0.00042090677331430015, Final Batch Loss: 3.7422437344503123e-06\n",
      "Epoch 2519, Loss: 0.000249191808705973, Final Batch Loss: 7.851944246795028e-06\n",
      "Epoch 2520, Loss: 0.010880727142421165, Final Batch Loss: 1.9414990674704313e-05\n",
      "Epoch 2521, Loss: 0.013138793241409985, Final Batch Loss: 1.0294160347257275e-05\n",
      "Epoch 2522, Loss: 0.0247390526677691, Final Batch Loss: 2.007566990869236e-06\n",
      "Epoch 2523, Loss: 0.05017800428845476, Final Batch Loss: 4.992766844225116e-05\n",
      "Epoch 2524, Loss: 0.01119154357206753, Final Batch Loss: 5.43845999345649e-06\n",
      "Epoch 2525, Loss: 0.027492226522781493, Final Batch Loss: 4.64847034891136e-05\n",
      "Epoch 2526, Loss: 0.008409388033214782, Final Batch Loss: 2.2883272322360426e-05\n",
      "Epoch 2527, Loss: 0.00122173316685803, Final Batch Loss: 0.0003497290308587253\n",
      "Epoch 2528, Loss: 0.0048015625834523235, Final Batch Loss: 1.1644708138192073e-05\n",
      "Epoch 2529, Loss: 0.0013219428055890603, Final Batch Loss: 1.1586233995330986e-05\n",
      "Epoch 2530, Loss: 0.00041174071020577685, Final Batch Loss: 5.663517185894307e-06\n",
      "Epoch 2531, Loss: 0.0006000758194204536, Final Batch Loss: 1.4035465028428007e-05\n",
      "Epoch 2532, Loss: 0.00210819898347836, Final Batch Loss: 5.881733522983268e-05\n",
      "Epoch 2533, Loss: 0.0003459969717596323, Final Batch Loss: 1.7360916899633594e-05\n",
      "Epoch 2534, Loss: 0.00020870625803581788, Final Batch Loss: 5.8364958022139035e-06\n",
      "Epoch 2535, Loss: 0.004139725235290825, Final Batch Loss: 5.534636784432223e-06\n",
      "Epoch 2536, Loss: 0.010696434628243878, Final Batch Loss: 0.004474707413464785\n",
      "Epoch 2537, Loss: 0.00091780003549502, Final Batch Loss: 0.0001064051830326207\n",
      "Epoch 2538, Loss: 0.0002935914160957509, Final Batch Loss: 2.2278329197433777e-05\n",
      "Epoch 2539, Loss: 0.0002830471692050196, Final Batch Loss: 2.932285497081466e-05\n",
      "Epoch 2540, Loss: 0.00023100750513549428, Final Batch Loss: 7.678152542212047e-06\n",
      "Epoch 2541, Loss: 0.0014268367510794633, Final Batch Loss: 3.809527925113798e-06\n",
      "Epoch 2542, Loss: 0.00013668573114955507, Final Batch Loss: 3.4690797292569187e-06\n",
      "Epoch 2543, Loss: 9.270963053609194e-05, Final Batch Loss: 6.51402569928905e-06\n",
      "Epoch 2544, Loss: 0.0005921146805007993, Final Batch Loss: 2.3951270122779533e-05\n",
      "Epoch 2545, Loss: 0.0016434500188040602, Final Batch Loss: 9.723223229229916e-06\n",
      "Epoch 2546, Loss: 0.00041255520829963643, Final Batch Loss: 3.91122157452628e-05\n",
      "Epoch 2547, Loss: 0.0008570969334300571, Final Batch Loss: 1.1824100511148572e-05\n",
      "Epoch 2548, Loss: 0.0032928753799410515, Final Batch Loss: 0.0029070163145661354\n",
      "Epoch 2549, Loss: 0.0003937769620279141, Final Batch Loss: 6.083284824853763e-05\n",
      "Epoch 2550, Loss: 0.0010296394386841712, Final Batch Loss: 1.5725709090474993e-05\n",
      "Epoch 2551, Loss: 0.0012409508566406657, Final Batch Loss: 1.0726573236752301e-05\n",
      "Epoch 2552, Loss: 0.001132592850723313, Final Batch Loss: 0.0006740409298799932\n",
      "Epoch 2553, Loss: 0.0003397195214347448, Final Batch Loss: 5.612425866274862e-06\n",
      "Epoch 2554, Loss: 0.0006839243364993308, Final Batch Loss: 4.346538389654597e-06\n",
      "Epoch 2555, Loss: 0.0019675664755141042, Final Batch Loss: 3.8486200537590776e-06\n",
      "Epoch 2556, Loss: 0.00013333722904462775, Final Batch Loss: 1.4864805052638985e-05\n",
      "Epoch 2557, Loss: 0.0003753179426269071, Final Batch Loss: 4.618336788553279e-06\n",
      "Epoch 2558, Loss: 0.00031713312165493335, Final Batch Loss: 7.955619366839528e-05\n",
      "Epoch 2559, Loss: 0.00046404133794908375, Final Batch Loss: 1.187845555250533e-05\n",
      "Epoch 2560, Loss: 8.68662751258853e-05, Final Batch Loss: 3.83091162348137e-07\n",
      "Epoch 2561, Loss: 0.00011373505338951873, Final Batch Loss: 7.850215297366958e-06\n",
      "Epoch 2562, Loss: 0.00011980253754018122, Final Batch Loss: 1.4069227063373546e-06\n",
      "Epoch 2563, Loss: 0.0011067061112157717, Final Batch Loss: 2.4000672055990435e-05\n",
      "Epoch 2564, Loss: 0.0004435095917472154, Final Batch Loss: 4.273232718787767e-07\n",
      "Epoch 2565, Loss: 7.059550358690103e-05, Final Batch Loss: 5.710983259632485e-06\n",
      "Epoch 2566, Loss: 0.00018691254354052944, Final Batch Loss: 1.9499973404890625e-06\n",
      "Epoch 2567, Loss: 0.00018013669964034307, Final Batch Loss: 2.9761033601971576e-06\n",
      "Epoch 2568, Loss: 0.00010708694118477524, Final Batch Loss: 3.320344603707781e-06\n",
      "Epoch 2569, Loss: 0.0002883775439386227, Final Batch Loss: 1.888494466584234e-06\n",
      "Epoch 2570, Loss: 5.2442990181589266e-05, Final Batch Loss: 2.0326276626292383e-06\n",
      "Epoch 2571, Loss: 0.0001292091690174857, Final Batch Loss: 2.1367375211411854e-06\n",
      "Epoch 2572, Loss: 4.438343239243636e-05, Final Batch Loss: 1.9595979665609775e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2573, Loss: 9.962755584069782e-05, Final Batch Loss: 2.9790617190883495e-06\n",
      "Epoch 2574, Loss: 0.0007548196993809597, Final Batch Loss: 2.0528293589450186e-06\n",
      "Epoch 2575, Loss: 7.08029498923679e-05, Final Batch Loss: 9.62765284384659e-07\n",
      "Epoch 2576, Loss: 0.00025987423413198485, Final Batch Loss: 1.6072831385827158e-06\n",
      "Epoch 2577, Loss: 0.00011802232606328289, Final Batch Loss: 1.9379642708372558e-06\n",
      "Epoch 2578, Loss: 0.00017636321092595608, Final Batch Loss: 3.317234950372949e-05\n",
      "Epoch 2579, Loss: 5.652261394573088e-05, Final Batch Loss: 1.6077627833510633e-06\n",
      "Epoch 2580, Loss: 0.002604592938467931, Final Batch Loss: 3.6752176129084546e-06\n",
      "Epoch 2581, Loss: 0.00012164870554443041, Final Batch Loss: 1.139378764491994e-05\n",
      "Epoch 2582, Loss: 0.00010527145337846378, Final Batch Loss: 1.4006543551658979e-06\n",
      "Epoch 2583, Loss: 0.00011035691451866114, Final Batch Loss: 2.7927413270845136e-07\n",
      "Epoch 2584, Loss: 5.35909760657205e-05, Final Batch Loss: 5.597762537945528e-06\n",
      "Epoch 2585, Loss: 2.6223117309598365e-05, Final Batch Loss: 1.8485125110601075e-06\n",
      "Epoch 2586, Loss: 0.00014586975786556877, Final Batch Loss: 8.171247714017227e-07\n",
      "Epoch 2587, Loss: 0.00012394056153652855, Final Batch Loss: 1.296349182666745e-06\n",
      "Epoch 2588, Loss: 0.00012634595594818165, Final Batch Loss: 6.970550657570129e-06\n",
      "Epoch 2589, Loss: 8.084691495469087e-05, Final Batch Loss: 1.1127325478810235e-06\n",
      "Epoch 2590, Loss: 4.6256550952250564e-05, Final Batch Loss: 9.046009836310986e-06\n",
      "Epoch 2591, Loss: 0.000167087201589311, Final Batch Loss: 1.1328819482514518e-06\n",
      "Epoch 2592, Loss: 4.431874823751514e-05, Final Batch Loss: 5.883397875550145e-07\n",
      "Epoch 2593, Loss: 5.246411912196436e-05, Final Batch Loss: 7.13865802026703e-06\n",
      "Epoch 2594, Loss: 3.5162153494638915e-05, Final Batch Loss: 2.288096084157587e-06\n",
      "Epoch 2595, Loss: 0.0003414923433595618, Final Batch Loss: 4.35550191468792e-06\n",
      "Epoch 2596, Loss: 0.0001237467531893799, Final Batch Loss: 9.556480108585674e-06\n",
      "Epoch 2597, Loss: 0.0005080792220439889, Final Batch Loss: 4.8667279770597816e-06\n",
      "Epoch 2598, Loss: 0.0005771319247749318, Final Batch Loss: 0.000496154185384512\n",
      "Epoch 2599, Loss: 3.5272267304264915e-05, Final Batch Loss: 1.439056063645694e-06\n",
      "Epoch 2600, Loss: 7.589740965840974e-05, Final Batch Loss: 2.9463781174854375e-05\n",
      "Epoch 2601, Loss: 0.00021793960944194168, Final Batch Loss: 1.5096770766831469e-05\n",
      "Epoch 2602, Loss: 9.315247115182501e-05, Final Batch Loss: 2.57640067502507e-07\n",
      "Epoch 2603, Loss: 0.07688788776694011, Final Batch Loss: 1.451652167361317e-07\n",
      "Epoch 2604, Loss: 0.014234031925695945, Final Batch Loss: 0.0014230364467948675\n",
      "Epoch 2605, Loss: 0.0019287488189689839, Final Batch Loss: 8.411876706304611e-08\n",
      "Epoch 2606, Loss: 0.0005236107712818239, Final Batch Loss: 2.9071411518089008e-06\n",
      "Epoch 2607, Loss: 0.00020372819127789654, Final Batch Loss: 1.8986663974374096e-07\n",
      "Epoch 2608, Loss: 0.0001279616961014085, Final Batch Loss: 5.912036158406409e-07\n",
      "Epoch 2609, Loss: 0.0015369980444095432, Final Batch Loss: 1.0959463025983496e-07\n",
      "Epoch 2610, Loss: 0.0015615414237117875, Final Batch Loss: 0.0014540894189849496\n",
      "Epoch 2611, Loss: 0.0009026722310130353, Final Batch Loss: 1.2738007626467152e-07\n",
      "Epoch 2612, Loss: 6.920885715189229e-05, Final Batch Loss: 2.884091543364775e-08\n",
      "Epoch 2613, Loss: 0.00017790140197604387, Final Batch Loss: 1.1776604225133269e-07\n",
      "Epoch 2614, Loss: 0.006121284149465112, Final Batch Loss: 2.5235419798264047e-07\n",
      "Epoch 2615, Loss: 0.008246283310526792, Final Batch Loss: 5.335459150046518e-07\n",
      "Epoch 2616, Loss: 0.0017181523315858982, Final Batch Loss: 3.906454730895348e-05\n",
      "Epoch 2617, Loss: 2.1563560652637648e-05, Final Batch Loss: 2.7222772587265354e-06\n",
      "Epoch 2618, Loss: 6.352847871937684e-05, Final Batch Loss: 7.546701397131983e-08\n",
      "Epoch 2619, Loss: 6.694601012213752e-05, Final Batch Loss: 3.1848251182964304e-06\n",
      "Epoch 2620, Loss: 3.003524538058855e-05, Final Batch Loss: 6.440993161049846e-07\n",
      "Epoch 2621, Loss: 0.00016017755846453596, Final Batch Loss: 1.35061202399811e-06\n",
      "Epoch 2622, Loss: 0.0001004864811253725, Final Batch Loss: 5.962212981103221e-06\n",
      "Epoch 2623, Loss: 0.22263245402828602, Final Batch Loss: 3.7546633393503726e-06\n",
      "Epoch 2624, Loss: 0.003546095903971036, Final Batch Loss: 0.0006564826471731067\n",
      "Epoch 2625, Loss: 0.007327576249963386, Final Batch Loss: 3.2827872473717434e-06\n",
      "Epoch 2626, Loss: 0.002146081160731228, Final Batch Loss: 1.5258130588335916e-05\n",
      "Epoch 2627, Loss: 0.0010149824006475683, Final Batch Loss: 2.2626695681537967e-06\n",
      "Epoch 2628, Loss: 0.0007350287107641407, Final Batch Loss: 4.816391765416483e-07\n",
      "Epoch 2629, Loss: 0.002021381511610798, Final Batch Loss: 1.2986125511815771e-05\n",
      "Epoch 2630, Loss: 0.00032498488148746674, Final Batch Loss: 1.5771149264764972e-05\n",
      "Epoch 2631, Loss: 0.0004694877773516737, Final Batch Loss: 0.00012809773033950478\n",
      "Epoch 2632, Loss: 0.0010459762753782798, Final Batch Loss: 7.699457455601078e-06\n",
      "Epoch 2633, Loss: 0.0019109907909680146, Final Batch Loss: 9.622220204619225e-06\n",
      "Epoch 2634, Loss: 0.00046724816786536394, Final Batch Loss: 4.43706194346305e-05\n",
      "Epoch 2635, Loss: 0.0011018881459108343, Final Batch Loss: 0.0008450117893517017\n",
      "Epoch 2636, Loss: 0.007220465939553833, Final Batch Loss: 4.493148935580393e-06\n",
      "Epoch 2637, Loss: 0.005604463145715499, Final Batch Loss: 4.109264773433097e-05\n",
      "Epoch 2638, Loss: 0.0006075183416953678, Final Batch Loss: 1.4971345763115096e-06\n",
      "Epoch 2639, Loss: 0.00031584834384545957, Final Batch Loss: 1.414542111888295e-06\n",
      "Epoch 2640, Loss: 0.00010743305057303587, Final Batch Loss: 5.119026695865614e-07\n",
      "Epoch 2641, Loss: 3.8603804277670406e-05, Final Batch Loss: 1.4693833918499877e-06\n",
      "Epoch 2642, Loss: 0.00023126859365873997, Final Batch Loss: 8.387488037442381e-07\n",
      "Epoch 2643, Loss: 0.00010778247415998976, Final Batch Loss: 3.3530673135828692e-06\n",
      "Epoch 2644, Loss: 0.00019678199154782305, Final Batch Loss: 3.662902372525423e-06\n",
      "Epoch 2645, Loss: 0.00013234405186324238, Final Batch Loss: 1.6985582988127135e-05\n",
      "Epoch 2646, Loss: 0.0006458467780134924, Final Batch Loss: 0.000572439341340214\n",
      "Epoch 2647, Loss: 0.002689073656526375, Final Batch Loss: 0.002459079958498478\n",
      "Epoch 2648, Loss: 0.012642326666354897, Final Batch Loss: 0.012599139474332333\n",
      "Epoch 2649, Loss: 8.266001592005523e-05, Final Batch Loss: 3.679827932501212e-05\n",
      "Epoch 2650, Loss: 0.0005478953956981059, Final Batch Loss: 5.869047754458734e-07\n",
      "Epoch 2651, Loss: 0.001278516729371404, Final Batch Loss: 1.1084718607889954e-05\n",
      "Epoch 2652, Loss: 0.00018631702225491154, Final Batch Loss: 3.4014137781923637e-06\n",
      "Epoch 2653, Loss: 0.00018479508014479507, Final Batch Loss: 5.372644409362692e-06\n",
      "Epoch 2654, Loss: 9.540108268879521e-05, Final Batch Loss: 2.4833802854118403e-06\n",
      "Epoch 2655, Loss: 0.00031032034493705396, Final Batch Loss: 8.312591489811894e-06\n",
      "Epoch 2656, Loss: 0.00011697326192461333, Final Batch Loss: 1.1310002264508512e-05\n",
      "Epoch 2657, Loss: 0.00011720488384980854, Final Batch Loss: 9.789807336346712e-06\n",
      "Epoch 2658, Loss: 0.0006343905489103463, Final Batch Loss: 5.3733216191176325e-05\n",
      "Epoch 2659, Loss: 0.0006546795624728929, Final Batch Loss: 1.0996124728990253e-05\n",
      "Epoch 2660, Loss: 9.119909195476339e-05, Final Batch Loss: 1.9163001070410246e-06\n",
      "Epoch 2661, Loss: 6.916894324149325e-05, Final Batch Loss: 6.459241831180407e-06\n",
      "Epoch 2662, Loss: 6.34323142918447e-05, Final Batch Loss: 2.364949551747486e-07\n",
      "Epoch 2663, Loss: 0.00021750220736294068, Final Batch Loss: 2.909970362452441e-06\n",
      "Epoch 2664, Loss: 0.002668206549117258, Final Batch Loss: 4.849991341870918e-07\n",
      "Epoch 2665, Loss: 0.0003089320527323025, Final Batch Loss: 9.046071909324382e-07\n",
      "Epoch 2666, Loss: 0.00019854066714231067, Final Batch Loss: 0.00010631139593897387\n",
      "Epoch 2667, Loss: 0.0004558212778391635, Final Batch Loss: 0.0003793350188061595\n",
      "Epoch 2668, Loss: 4.33929056953275e-05, Final Batch Loss: 2.9626630748680327e-06\n",
      "Epoch 2669, Loss: 0.0003345899834386046, Final Batch Loss: 1.3163885341782589e-06\n",
      "Epoch 2670, Loss: 0.00049197190512551, Final Batch Loss: 2.4034120471583265e-08\n",
      "Epoch 2671, Loss: 0.00023423713180648065, Final Batch Loss: 1.9755945857014012e-07\n",
      "Epoch 2672, Loss: 0.00010388881980816222, Final Batch Loss: 2.635586270116619e-06\n",
      "Epoch 2673, Loss: 8.468188987365011e-05, Final Batch Loss: 1.115180268129734e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2674, Loss: 8.025808382683408e-05, Final Batch Loss: 4.595135862928146e-07\n",
      "Epoch 2675, Loss: 0.0005638167196195809, Final Batch Loss: 2.1459867639350705e-05\n",
      "Epoch 2676, Loss: 2.377372344142259e-05, Final Batch Loss: 3.7560878354270244e-06\n",
      "Epoch 2677, Loss: 8.502056873993524e-05, Final Batch Loss: 5.854599294252694e-07\n",
      "Epoch 2678, Loss: 0.00014308566968423975, Final Batch Loss: 1.5429847621817316e-07\n",
      "Epoch 2679, Loss: 0.010127544036834024, Final Batch Loss: 1.206411252496764e-05\n",
      "Epoch 2680, Loss: 5.4611226232736954e-05, Final Batch Loss: 1.6116086953843478e-06\n",
      "Epoch 2681, Loss: 0.0010812969231324132, Final Batch Loss: 2.605932877486339e-06\n",
      "Epoch 2682, Loss: 7.398766139488089e-05, Final Batch Loss: 1.2300337175474851e-06\n",
      "Epoch 2683, Loss: 0.006063913617026628, Final Batch Loss: 1.7921767039297265e-06\n",
      "Epoch 2684, Loss: 0.015640606783804856, Final Batch Loss: 4.461227035790216e-06\n",
      "Epoch 2685, Loss: 0.0005523693079680925, Final Batch Loss: 3.180370185873471e-05\n",
      "Epoch 2686, Loss: 0.00014977646634406483, Final Batch Loss: 2.081223101413343e-05\n",
      "Epoch 2687, Loss: 0.0007680832317760178, Final Batch Loss: 2.9693092074012384e-05\n",
      "Epoch 2688, Loss: 0.0007179647317343552, Final Batch Loss: 8.855668056639843e-06\n",
      "Epoch 2689, Loss: 0.00013242777606592426, Final Batch Loss: 1.2677064660238102e-05\n",
      "Epoch 2690, Loss: 0.0012412224748459266, Final Batch Loss: 0.0005272077978588641\n",
      "Epoch 2691, Loss: 0.00011564288223553376, Final Batch Loss: 1.9210570826544426e-05\n",
      "Epoch 2692, Loss: 0.018163295312433547, Final Batch Loss: 6.720031524309888e-05\n",
      "Epoch 2693, Loss: 0.000538900628043848, Final Batch Loss: 3.316652055218583e-06\n",
      "Epoch 2694, Loss: 0.0003509809876049985, Final Batch Loss: 5.51522862224374e-06\n",
      "Epoch 2695, Loss: 0.0005609140494016174, Final Batch Loss: 8.509910549037158e-05\n",
      "Epoch 2696, Loss: 0.00027914106658499804, Final Batch Loss: 1.3883552128390875e-05\n",
      "Epoch 2697, Loss: 0.0018978424421902673, Final Batch Loss: 5.349263574316865e-06\n",
      "Epoch 2698, Loss: 0.0010392986134775128, Final Batch Loss: 0.0008549788035452366\n",
      "Epoch 2699, Loss: 0.00015804166048383195, Final Batch Loss: 1.1194778153367224e-06\n",
      "Epoch 2700, Loss: 0.0005521121144056451, Final Batch Loss: 6.000806479278253e-06\n",
      "Epoch 2701, Loss: 0.00011448637951616547, Final Batch Loss: 6.099697316130914e-07\n",
      "Epoch 2702, Loss: 9.165526846288685e-05, Final Batch Loss: 4.2924514787046064e-07\n",
      "Epoch 2703, Loss: 0.02401167099597501, Final Batch Loss: 1.7932034097611904e-05\n",
      "Epoch 2704, Loss: 0.000251045144523232, Final Batch Loss: 1.0904772352660075e-05\n",
      "Epoch 2705, Loss: 0.0005197169514303823, Final Batch Loss: 0.00024877669056877494\n",
      "Epoch 2706, Loss: 0.004976886358463162, Final Batch Loss: 9.14545489649754e-06\n",
      "Epoch 2707, Loss: 0.0010076627468151855, Final Batch Loss: 1.0641019798640627e-05\n",
      "Epoch 2708, Loss: 0.006476669726907858, Final Batch Loss: 5.566290201386437e-05\n",
      "Epoch 2709, Loss: 0.00018229238872891074, Final Batch Loss: 4.13234056395595e-06\n",
      "Epoch 2710, Loss: 0.004268053854389109, Final Batch Loss: 3.871365606755717e-06\n",
      "Epoch 2711, Loss: 0.004038517443831324, Final Batch Loss: 4.322766471887007e-06\n",
      "Epoch 2712, Loss: 0.00032408551078333403, Final Batch Loss: 1.2463724488043226e-06\n",
      "Epoch 2713, Loss: 0.00010449490957853413, Final Batch Loss: 2.778315888463112e-07\n",
      "Epoch 2714, Loss: 0.018299930624039007, Final Batch Loss: 7.401321636280045e-05\n",
      "Epoch 2715, Loss: 0.0008885472996098542, Final Batch Loss: 1.7192753603012534e-06\n",
      "Epoch 2716, Loss: 0.004473372739767001, Final Batch Loss: 3.140079797958606e-06\n",
      "Epoch 2717, Loss: 0.0018945564580690188, Final Batch Loss: 5.650761886499822e-05\n",
      "Epoch 2718, Loss: 0.002032792594889088, Final Batch Loss: 1.9186622921552043e-06\n",
      "Epoch 2719, Loss: 0.0002911062861414848, Final Batch Loss: 3.738864324986935e-05\n",
      "Epoch 2720, Loss: 0.0009649884509883577, Final Batch Loss: 2.5485505830147304e-05\n",
      "Epoch 2721, Loss: 0.0002737007029054439, Final Batch Loss: 5.600741133093834e-06\n",
      "Epoch 2722, Loss: 0.0004987562099358911, Final Batch Loss: 3.1727279292681487e-06\n",
      "Epoch 2723, Loss: 0.0003829637956869192, Final Batch Loss: 5.657913334289333e-06\n",
      "Epoch 2724, Loss: 0.00046851969437966545, Final Batch Loss: 2.777276313281618e-05\n",
      "Epoch 2725, Loss: 0.03359621893261533, Final Batch Loss: 0.0001985260023502633\n",
      "Epoch 2726, Loss: 0.012163264664536655, Final Batch Loss: 1.1526356047397712e-06\n",
      "Epoch 2727, Loss: 0.0005460846464302449, Final Batch Loss: 5.612263976217946e-06\n",
      "Epoch 2728, Loss: 0.0011783981922235398, Final Batch Loss: 8.76579633768415e-06\n",
      "Epoch 2729, Loss: 0.0004165048386539638, Final Batch Loss: 7.490569987567142e-05\n",
      "Epoch 2730, Loss: 0.0003717511350487257, Final Batch Loss: 5.667985533364117e-06\n",
      "Epoch 2731, Loss: 0.0009022947882613153, Final Batch Loss: 5.77824393985793e-05\n",
      "Epoch 2732, Loss: 0.004652569742574997, Final Batch Loss: 0.00021661078790202737\n",
      "Epoch 2733, Loss: 0.0001740759468447095, Final Batch Loss: 3.984766010489693e-07\n",
      "Epoch 2734, Loss: 0.00022107984091235267, Final Batch Loss: 8.075830919551663e-06\n",
      "Epoch 2735, Loss: 0.00022829952945357945, Final Batch Loss: 3.024315992661286e-05\n",
      "Epoch 2736, Loss: 0.00034404096243179083, Final Batch Loss: 3.775461300392635e-05\n",
      "Epoch 2737, Loss: 0.0005413819613977466, Final Batch Loss: 2.8837716854468454e-06\n",
      "Epoch 2738, Loss: 0.02934986793650296, Final Batch Loss: 9.505708294454962e-05\n",
      "Epoch 2739, Loss: 0.0005109794963118475, Final Batch Loss: 7.276926044141874e-05\n",
      "Epoch 2740, Loss: 0.000616184963860178, Final Batch Loss: 3.106227450189181e-05\n",
      "Epoch 2741, Loss: 0.0005542136374856454, Final Batch Loss: 1.4476328033197206e-05\n",
      "Epoch 2742, Loss: 0.005561504945035267, Final Batch Loss: 5.7112312788376585e-05\n",
      "Epoch 2743, Loss: 0.0005971189600586513, Final Batch Loss: 0.0002522819850128144\n",
      "Epoch 2744, Loss: 0.008588712335495075, Final Batch Loss: 1.5922523743938655e-05\n",
      "Epoch 2745, Loss: 0.0013821732765109118, Final Batch Loss: 4.35015135735739e-05\n",
      "Epoch 2746, Loss: 0.0005024189999858208, Final Batch Loss: 1.9201608665753156e-05\n",
      "Epoch 2747, Loss: 0.0011198190372851968, Final Batch Loss: 2.2355241526383907e-05\n",
      "Epoch 2748, Loss: 0.0002240369199171255, Final Batch Loss: 1.342007067250961e-06\n",
      "Epoch 2749, Loss: 0.0032458797370509274, Final Batch Loss: 1.2906491065223236e-05\n",
      "Epoch 2750, Loss: 0.00015618294264641008, Final Batch Loss: 3.9323149394476786e-05\n",
      "Epoch 2751, Loss: 0.0001376136190174293, Final Batch Loss: 5.416387921286514e-06\n",
      "Epoch 2752, Loss: 0.00016883836178749334, Final Batch Loss: 9.513975783193018e-06\n",
      "Epoch 2753, Loss: 0.00036335904826501064, Final Batch Loss: 7.954999091452919e-06\n",
      "Epoch 2754, Loss: 0.0004251117205740229, Final Batch Loss: 1.364352192467777e-05\n",
      "Epoch 2755, Loss: 0.00010838051417749739, Final Batch Loss: 1.2515993148554116e-06\n",
      "Epoch 2756, Loss: 8.748027767069289e-05, Final Batch Loss: 2.8882143396913307e-06\n",
      "Epoch 2757, Loss: 0.0003018177500848651, Final Batch Loss: 6.428923370549455e-05\n",
      "Epoch 2758, Loss: 0.0008590452445957908, Final Batch Loss: 2.2336682377499528e-05\n",
      "Epoch 2759, Loss: 0.0001488263945361723, Final Batch Loss: 2.3501766918343492e-05\n",
      "Epoch 2760, Loss: 0.00011219027641118373, Final Batch Loss: 2.753273474809248e-05\n",
      "Epoch 2761, Loss: 0.00013782572983700447, Final Batch Loss: 7.704636118432973e-06\n",
      "Epoch 2762, Loss: 0.0002704318889072965, Final Batch Loss: 4.352977157395799e-06\n",
      "Epoch 2763, Loss: 0.00010519302406919451, Final Batch Loss: 3.051177145607653e-06\n",
      "Epoch 2764, Loss: 0.00011854980524361736, Final Batch Loss: 5.589359352597967e-05\n",
      "Epoch 2765, Loss: 0.00010392599776309908, Final Batch Loss: 1.4669369647890562e-06\n",
      "Epoch 2766, Loss: 8.845033104165623e-05, Final Batch Loss: 7.8831753569375e-08\n",
      "Epoch 2767, Loss: 0.000522830398530516, Final Batch Loss: 0.00016737419355195016\n",
      "Epoch 2768, Loss: 0.00023100602521708424, Final Batch Loss: 1.6996182239381596e-05\n",
      "Epoch 2769, Loss: 0.0001871277127918347, Final Batch Loss: 3.029248773600557e-06\n",
      "Epoch 2770, Loss: 0.00021327132540704952, Final Batch Loss: 2.903299503032031e-07\n",
      "Epoch 2771, Loss: 0.00019684677481279778, Final Batch Loss: 2.175210966015584e-06\n",
      "Epoch 2772, Loss: 0.01137697787814318, Final Batch Loss: 1.1580282262002584e-05\n",
      "Epoch 2773, Loss: 0.0131610091324319, Final Batch Loss: 1.3922089237894397e-05\n",
      "Epoch 2774, Loss: 0.002955322280826067, Final Batch Loss: 1.0793925866892096e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2775, Loss: 0.0002608524829490477, Final Batch Loss: 6.734109319950221e-06\n",
      "Epoch 2776, Loss: 0.0001294039473975772, Final Batch Loss: 3.6297574297350366e-06\n",
      "Epoch 2777, Loss: 6.385845517087319e-05, Final Batch Loss: 1.9034830245345802e-07\n",
      "Epoch 2778, Loss: 0.00020356838780344333, Final Batch Loss: 5.662786406901432e-06\n",
      "Epoch 2779, Loss: 0.0002826780559530562, Final Batch Loss: 1.8602241880216752e-07\n",
      "Epoch 2780, Loss: 6.844064161981578e-05, Final Batch Loss: 1.7152002328657545e-05\n",
      "Epoch 2781, Loss: 0.0004373876595167303, Final Batch Loss: 3.576143399186549e-07\n",
      "Epoch 2782, Loss: 0.0003241286300124102, Final Batch Loss: 1.4678806792289834e-06\n",
      "Epoch 2783, Loss: 0.010960443377626916, Final Batch Loss: 0.0004850490659009665\n",
      "Epoch 2784, Loss: 0.003920670321804209, Final Batch Loss: 4.604098648997024e-06\n",
      "Epoch 2785, Loss: 6.394524745445551e-05, Final Batch Loss: 2.1230018774076598e-06\n",
      "Epoch 2786, Loss: 0.00047955790818576816, Final Batch Loss: 4.705836147422815e-07\n",
      "Epoch 2787, Loss: 0.00017824338227967473, Final Batch Loss: 7.911473289823334e-07\n",
      "Epoch 2788, Loss: 8.727638893901712e-05, Final Batch Loss: 1.4783973711018916e-05\n",
      "Epoch 2789, Loss: 4.765212162993748e-05, Final Batch Loss: 1.316023372055497e-06\n",
      "Epoch 2790, Loss: 9.373923637667758e-05, Final Batch Loss: 1.1953538887610193e-06\n",
      "Epoch 2791, Loss: 9.716799857528713e-05, Final Batch Loss: 6.67656649966375e-07\n",
      "Epoch 2792, Loss: 0.02126648130246167, Final Batch Loss: 0.0002801963419187814\n",
      "Epoch 2793, Loss: 0.0001629252074053511, Final Batch Loss: 1.7375718016410246e-05\n",
      "Epoch 2794, Loss: 0.0002807019666306587, Final Batch Loss: 9.488310297456337e-07\n",
      "Epoch 2795, Loss: 0.0005889673332148959, Final Batch Loss: 5.369222890294623e-06\n",
      "Epoch 2796, Loss: 0.0009327809742671889, Final Batch Loss: 6.60089062876068e-05\n",
      "Epoch 2797, Loss: 0.0001563036872767043, Final Batch Loss: 5.5736068134137895e-06\n",
      "Epoch 2798, Loss: 9.270731651156439e-05, Final Batch Loss: 1.8077661252391408e-06\n",
      "Epoch 2799, Loss: 0.00039780078782314376, Final Batch Loss: 8.275359505205415e-06\n",
      "Epoch 2800, Loss: 0.01829252927404923, Final Batch Loss: 0.0009238370694220066\n",
      "Epoch 2801, Loss: 0.031399922313312345, Final Batch Loss: 4.1405878619116265e-06\n",
      "Epoch 2802, Loss: 0.00013234564252684322, Final Batch Loss: 9.445643081562594e-05\n",
      "Epoch 2803, Loss: 0.036273466762807516, Final Batch Loss: 4.577894742396893e-06\n",
      "Epoch 2804, Loss: 0.0015080612524798198, Final Batch Loss: 0.000138098796014674\n",
      "Epoch 2805, Loss: 0.0012210514400976535, Final Batch Loss: 6.705947271257173e-06\n",
      "Epoch 2806, Loss: 0.0024098319681797875, Final Batch Loss: 1.5593226635246538e-05\n",
      "Epoch 2807, Loss: 0.0008789190599145513, Final Batch Loss: 4.461823209567228e-06\n",
      "Epoch 2808, Loss: 0.0004164500530805526, Final Batch Loss: 1.0964176908601075e-06\n",
      "Epoch 2809, Loss: 0.0016397368390244083, Final Batch Loss: 0.0005057248054072261\n",
      "Epoch 2810, Loss: 0.000263028056224357, Final Batch Loss: 8.617517596576363e-05\n",
      "Epoch 2811, Loss: 0.00031578330231241125, Final Batch Loss: 3.097253284067847e-05\n",
      "Epoch 2812, Loss: 0.00045039259089207917, Final Batch Loss: 3.25735391015769e-06\n",
      "Epoch 2813, Loss: 0.0006405358772099135, Final Batch Loss: 5.201203384785913e-05\n",
      "Epoch 2814, Loss: 0.0009464539727161991, Final Batch Loss: 7.1466156441601925e-06\n",
      "Epoch 2815, Loss: 0.00018922313972780103, Final Batch Loss: 1.0983056881741504e-06\n",
      "Epoch 2816, Loss: 0.00023457420076056223, Final Batch Loss: 2.956113803520566e-06\n",
      "Epoch 2817, Loss: 0.0012507328287938435, Final Batch Loss: 1.12699317469378e-05\n",
      "Epoch 2818, Loss: 0.0002855822019682819, Final Batch Loss: 2.3407264961861074e-05\n",
      "Epoch 2819, Loss: 0.008955804632137188, Final Batch Loss: 7.519207883888157e-06\n",
      "Epoch 2820, Loss: 0.0005424104144111652, Final Batch Loss: 7.293197086255532e-06\n",
      "Epoch 2821, Loss: 0.09931283307923877, Final Batch Loss: 3.825331077678129e-05\n",
      "Epoch 2822, Loss: 0.0024593516898221424, Final Batch Loss: 1.6111428067233646e-06\n",
      "Epoch 2823, Loss: 0.0010494605534177026, Final Batch Loss: 0.0003141559427604079\n",
      "Epoch 2824, Loss: 0.001059890339888625, Final Batch Loss: 1.074339343176689e-05\n",
      "Epoch 2825, Loss: 0.0001838296307141718, Final Batch Loss: 1.1344953236402944e-05\n",
      "Epoch 2826, Loss: 0.0009291253360856899, Final Batch Loss: 0.00012039706780342385\n",
      "Epoch 2827, Loss: 0.0003257009829837898, Final Batch Loss: 2.2605545382248238e-05\n",
      "Epoch 2828, Loss: 0.0018780647161520392, Final Batch Loss: 6.150766239443328e-06\n",
      "Epoch 2829, Loss: 0.00015065121488078148, Final Batch Loss: 7.150366855057655e-06\n",
      "Epoch 2830, Loss: 0.0006873226042216629, Final Batch Loss: 2.311488515260862e-06\n",
      "Epoch 2831, Loss: 0.0017739030197390093, Final Batch Loss: 4.996090410713805e-06\n",
      "Epoch 2832, Loss: 0.00041490895188189825, Final Batch Loss: 6.520259375975002e-06\n",
      "Epoch 2833, Loss: 0.0002904187507510869, Final Batch Loss: 3.000248943862971e-05\n",
      "Epoch 2834, Loss: 0.00034514703224886034, Final Batch Loss: 0.0002418253425275907\n",
      "Epoch 2835, Loss: 0.00142024064399493, Final Batch Loss: 9.284504812967498e-06\n",
      "Epoch 2836, Loss: 0.0003795168310318786, Final Batch Loss: 3.416685103729833e-06\n",
      "Epoch 2837, Loss: 0.000135643998788737, Final Batch Loss: 2.64188133769494e-06\n",
      "Epoch 2838, Loss: 0.0006533969941528994, Final Batch Loss: 3.5912278235628037e-06\n",
      "Epoch 2839, Loss: 0.0004556343037052102, Final Batch Loss: 1.1337494470353704e-05\n",
      "Epoch 2840, Loss: 0.00018035813326378047, Final Batch Loss: 5.247979515843326e-06\n",
      "Epoch 2841, Loss: 0.0002459698685868261, Final Batch Loss: 4.39143650510232e-06\n",
      "Epoch 2842, Loss: 0.00013433111303129408, Final Batch Loss: 4.026467195217265e-06\n",
      "Epoch 2843, Loss: 0.00014244210672131885, Final Batch Loss: 1.815402356442064e-06\n",
      "Epoch 2844, Loss: 0.00013895804772801057, Final Batch Loss: 9.041919838637114e-06\n",
      "Epoch 2845, Loss: 0.00010739886363353435, Final Batch Loss: 7.676204631934525e-07\n",
      "Epoch 2846, Loss: 0.0003075843310966775, Final Batch Loss: 3.88817807106534e-06\n",
      "Epoch 2847, Loss: 9.169456129143327e-05, Final Batch Loss: 4.5087327293913404e-07\n",
      "Epoch 2848, Loss: 0.001380744988495053, Final Batch Loss: 2.7602284262684407e-06\n",
      "Epoch 2849, Loss: 0.00010309790915030703, Final Batch Loss: 4.037730505501713e-08\n",
      "Epoch 2850, Loss: 0.0005760403602721453, Final Batch Loss: 2.094662340823561e-05\n",
      "Epoch 2851, Loss: 0.00942609707205122, Final Batch Loss: 0.009258775971829891\n",
      "Epoch 2852, Loss: 0.0006685287269618811, Final Batch Loss: 0.00045077252434566617\n",
      "Epoch 2853, Loss: 0.0010469615582451297, Final Batch Loss: 5.410277026385302e-06\n",
      "Epoch 2854, Loss: 0.00013470583181174334, Final Batch Loss: 2.6033185349660926e-05\n",
      "Epoch 2855, Loss: 9.014417483399484e-05, Final Batch Loss: 1.0685153029044159e-06\n",
      "Epoch 2856, Loss: 0.0001970077153004013, Final Batch Loss: 2.7958694772678427e-06\n",
      "Epoch 2857, Loss: 0.0005785991734654772, Final Batch Loss: 6.344997416363185e-08\n",
      "Epoch 2858, Loss: 5.688928592917364e-05, Final Batch Loss: 2.6971890747518046e-06\n",
      "Epoch 2859, Loss: 0.0005591957986581519, Final Batch Loss: 1.1939562227780698e-06\n",
      "Epoch 2860, Loss: 3.888137601393282e-05, Final Batch Loss: 3.258984122567199e-07\n",
      "Epoch 2861, Loss: 0.0012481898144756087, Final Batch Loss: 1.6173845551747945e-06\n",
      "Epoch 2862, Loss: 0.026759614904449336, Final Batch Loss: 0.00011077082308474928\n",
      "Epoch 2863, Loss: 0.0576080258522893, Final Batch Loss: 8.253101100308413e-07\n",
      "Epoch 2864, Loss: 0.001081657156817073, Final Batch Loss: 6.880409637233242e-05\n",
      "Epoch 2865, Loss: 0.005032883438502722, Final Batch Loss: 7.072833977872506e-05\n",
      "Epoch 2866, Loss: 0.00027449608103324863, Final Batch Loss: 4.222581992507912e-06\n",
      "Epoch 2867, Loss: 0.003708656977778446, Final Batch Loss: 4.8371453885920346e-05\n",
      "Epoch 2868, Loss: 0.0004978601591574261, Final Batch Loss: 2.730021151364781e-05\n",
      "Epoch 2869, Loss: 0.0006325692684185924, Final Batch Loss: 4.223765245114919e-06\n",
      "Epoch 2870, Loss: 0.00018379181915406662, Final Batch Loss: 4.931361672788626e-06\n",
      "Epoch 2871, Loss: 0.0008935612455616138, Final Batch Loss: 2.419633347017225e-05\n",
      "Epoch 2872, Loss: 0.0002661096494875892, Final Batch Loss: 7.322464080061764e-05\n",
      "Epoch 2873, Loss: 0.011528464165905916, Final Batch Loss: 8.27316671347944e-06\n",
      "Epoch 2874, Loss: 0.0031766029260325013, Final Batch Loss: 4.544873263512272e-06\n",
      "Epoch 2875, Loss: 0.023736356984016993, Final Batch Loss: 3.859143180307001e-05\n",
      "Epoch 2876, Loss: 0.0016272423474674724, Final Batch Loss: 0.0010445137741044164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2877, Loss: 0.0009905742434739295, Final Batch Loss: 0.00013069235137663782\n",
      "Epoch 2878, Loss: 0.006327401257181009, Final Batch Loss: 1.25453789223684e-05\n",
      "Epoch 2879, Loss: 0.0008561021099922073, Final Batch Loss: 6.853235845483141e-06\n",
      "Epoch 2880, Loss: 0.00047235349302354734, Final Batch Loss: 1.2883433555543888e-05\n",
      "Epoch 2881, Loss: 0.00022746446688870492, Final Batch Loss: 1.0348158866690937e-05\n",
      "Epoch 2882, Loss: 0.0002451637581089017, Final Batch Loss: 4.0354325392399915e-06\n",
      "Epoch 2883, Loss: 0.000275783311565192, Final Batch Loss: 8.676156539877411e-06\n",
      "Epoch 2884, Loss: 0.00021219205154920928, Final Batch Loss: 2.0232087990734726e-05\n",
      "Epoch 2885, Loss: 0.0003591974970049705, Final Batch Loss: 4.31511398346629e-06\n",
      "Epoch 2886, Loss: 0.00044800223372476466, Final Batch Loss: 2.3905122361611575e-05\n",
      "Epoch 2887, Loss: 0.00030030145364889904, Final Batch Loss: 4.770404484588653e-05\n",
      "Epoch 2888, Loss: 0.00026718202718711836, Final Batch Loss: 5.7979409575636964e-06\n",
      "Epoch 2889, Loss: 0.0002490258519003419, Final Batch Loss: 3.1351605684903916e-06\n",
      "Epoch 2890, Loss: 0.0005938099379818595, Final Batch Loss: 1.4799605196458288e-05\n",
      "Epoch 2891, Loss: 0.00027282731389277615, Final Batch Loss: 9.20770107768476e-05\n",
      "Epoch 2892, Loss: 0.00029260481164783414, Final Batch Loss: 5.900117685087025e-06\n",
      "Epoch 2893, Loss: 0.0003733678189519196, Final Batch Loss: 1.4894158994138706e-05\n",
      "Epoch 2894, Loss: 0.0005961744723492757, Final Batch Loss: 2.129087079083547e-05\n",
      "Epoch 2895, Loss: 0.00011168048541776443, Final Batch Loss: 4.989212811778998e-06\n",
      "Epoch 2896, Loss: 0.005619254088855996, Final Batch Loss: 1.9125307062495267e-06\n",
      "Epoch 2897, Loss: 0.00015395026423448144, Final Batch Loss: 4.017639184894506e-06\n",
      "Epoch 2898, Loss: 0.00022167753968460602, Final Batch Loss: 4.5739623601548374e-05\n",
      "Epoch 2899, Loss: 0.0006067540723506681, Final Batch Loss: 2.192202828155132e-06\n",
      "Epoch 2900, Loss: 0.0005586857037087611, Final Batch Loss: 0.00010990183363901451\n",
      "Epoch 2901, Loss: 0.00029113157506799325, Final Batch Loss: 1.1346483915986028e-05\n",
      "Epoch 2902, Loss: 0.0019429849288599144, Final Batch Loss: 3.9499042031820863e-05\n",
      "Epoch 2903, Loss: 0.0026699053400989214, Final Batch Loss: 5.006948413210921e-05\n",
      "Epoch 2904, Loss: 0.0003814235138861477, Final Batch Loss: 1.251151115866378e-05\n",
      "Epoch 2905, Loss: 0.0001437185733266233, Final Batch Loss: 1.0171704161621165e-05\n",
      "Epoch 2906, Loss: 0.0005257800160052284, Final Batch Loss: 3.2278408070851583e-06\n",
      "Epoch 2907, Loss: 0.000346649239332919, Final Batch Loss: 5.467980372486636e-05\n",
      "Epoch 2908, Loss: 0.0002693393412300793, Final Batch Loss: 1.591927912159008e-06\n",
      "Epoch 2909, Loss: 0.0001235780222827998, Final Batch Loss: 3.85044768336229e-06\n",
      "Epoch 2910, Loss: 0.0001627606842617979, Final Batch Loss: 5.719999762732186e-07\n",
      "Epoch 2911, Loss: 0.00024391748142704728, Final Batch Loss: 3.579033773348783e-06\n",
      "Epoch 2912, Loss: 0.01142795560363652, Final Batch Loss: 3.566595694337593e-07\n",
      "Epoch 2913, Loss: 0.0007427763372618301, Final Batch Loss: 6.53727170174534e-08\n",
      "Epoch 2914, Loss: 0.004567171767515532, Final Batch Loss: 1.673577230576484e-06\n",
      "Epoch 2915, Loss: 0.001626001410244271, Final Batch Loss: 8.553619409212843e-06\n",
      "Epoch 2916, Loss: 0.0006507331204375078, Final Batch Loss: 4.055309545947239e-06\n",
      "Epoch 2917, Loss: 0.0036059850089031897, Final Batch Loss: 1.3010057955398224e-05\n",
      "Epoch 2918, Loss: 0.018589991595007405, Final Batch Loss: 3.7354625419538934e-06\n",
      "Epoch 2919, Loss: 0.0009123619796582716, Final Batch Loss: 4.94870801048819e-06\n",
      "Epoch 2920, Loss: 0.025433405362150552, Final Batch Loss: 0.02499510906636715\n",
      "Epoch 2921, Loss: 0.009150179008884152, Final Batch Loss: 0.001972820144146681\n",
      "Epoch 2922, Loss: 0.0028490083575434255, Final Batch Loss: 3.0305038762890035e-06\n",
      "Epoch 2923, Loss: 0.0007628263786045864, Final Batch Loss: 2.2599393560085446e-05\n",
      "Epoch 2924, Loss: 0.002665765235633444, Final Batch Loss: 1.7132606444647536e-05\n",
      "Epoch 2925, Loss: 0.0009632424795427141, Final Batch Loss: 4.214464934193529e-05\n",
      "Epoch 2926, Loss: 0.0014089907413392666, Final Batch Loss: 4.254009411397419e-07\n",
      "Epoch 2927, Loss: 0.0004378028089604413, Final Batch Loss: 5.554154995479621e-05\n",
      "Epoch 2928, Loss: 0.0006701367594814656, Final Batch Loss: 3.948430276068393e-06\n",
      "Epoch 2929, Loss: 0.0005985339522567301, Final Batch Loss: 2.9544505650846986e-06\n",
      "Epoch 2930, Loss: 0.00018679507616070623, Final Batch Loss: 3.4118551411665976e-05\n",
      "Epoch 2931, Loss: 0.0005838839276748331, Final Batch Loss: 1.1221150089113507e-05\n",
      "Epoch 2932, Loss: 0.00015923374462545326, Final Batch Loss: 9.61920159170404e-06\n",
      "Epoch 2933, Loss: 0.0007470845641535107, Final Batch Loss: 7.733798383924295e-07\n",
      "Epoch 2934, Loss: 0.0005596986586340336, Final Batch Loss: 9.88230340226437e-07\n",
      "Epoch 2935, Loss: 0.0008867743050586796, Final Batch Loss: 1.550540400785394e-05\n",
      "Epoch 2936, Loss: 0.00015495761761030735, Final Batch Loss: 8.74105444381712e-06\n",
      "Epoch 2937, Loss: 8.9970177413079e-05, Final Batch Loss: 3.728770934685599e-06\n",
      "Epoch 2938, Loss: 0.00032273685690142884, Final Batch Loss: 5.700948531739414e-05\n",
      "Epoch 2939, Loss: 0.00019380634978460876, Final Batch Loss: 2.85212772723753e-05\n",
      "Epoch 2940, Loss: 0.005784848242228691, Final Batch Loss: 6.7654332269739825e-06\n",
      "Epoch 2941, Loss: 0.007178147632885157, Final Batch Loss: 1.8793591152643785e-05\n",
      "Epoch 2942, Loss: 0.0002856872001757438, Final Batch Loss: 2.4196473532356322e-05\n",
      "Epoch 2943, Loss: 0.0001737103066261625, Final Batch Loss: 1.1622247484410764e-06\n",
      "Epoch 2944, Loss: 0.0014635980562616169, Final Batch Loss: 1.692352952886722e-06\n",
      "Epoch 2945, Loss: 0.003706278096387905, Final Batch Loss: 1.5770353911648272e-06\n",
      "Epoch 2946, Loss: 0.0009323431727779052, Final Batch Loss: 2.79914092971012e-05\n",
      "Epoch 2947, Loss: 6.014151139766e-05, Final Batch Loss: 6.859241921119974e-07\n",
      "Epoch 2948, Loss: 0.0003095267055215345, Final Batch Loss: 8.293318387586623e-06\n",
      "Epoch 2949, Loss: 0.0002751747275624439, Final Batch Loss: 2.3727536699880147e-06\n",
      "Epoch 2950, Loss: 0.00010127051041308732, Final Batch Loss: 2.4058861527009867e-05\n",
      "Epoch 2951, Loss: 0.00044780156991919284, Final Batch Loss: 1.5900112657618592e-06\n",
      "Epoch 2952, Loss: 7.608609655562759e-05, Final Batch Loss: 8.563183655496687e-06\n",
      "Epoch 2953, Loss: 0.0002733441791633595, Final Batch Loss: 4.466761674848385e-05\n",
      "Epoch 2954, Loss: 0.00012673486102698917, Final Batch Loss: 1.238957884197589e-05\n",
      "Epoch 2955, Loss: 0.0013150858301287371, Final Batch Loss: 1.4914985513314605e-06\n",
      "Epoch 2956, Loss: 0.00014952724552586005, Final Batch Loss: 5.581638561125146e-06\n",
      "Epoch 2957, Loss: 0.0003339658819214719, Final Batch Loss: 5.877609055460198e-06\n",
      "Epoch 2958, Loss: 0.0004531813516877037, Final Batch Loss: 1.2401555693486443e-07\n",
      "Epoch 2959, Loss: 0.00020271336470045753, Final Batch Loss: 1.4851740388621693e-06\n",
      "Epoch 2960, Loss: 0.0009904831141227532, Final Batch Loss: 0.00039884651778265834\n",
      "Epoch 2961, Loss: 9.427238910575397e-05, Final Batch Loss: 3.660795528048766e-06\n",
      "Epoch 2962, Loss: 0.00010349102440088132, Final Batch Loss: 2.2766710117139155e-06\n",
      "Epoch 2963, Loss: 0.00020258350230051292, Final Batch Loss: 9.727757969812956e-06\n",
      "Epoch 2964, Loss: 7.757788932849508e-05, Final Batch Loss: 3.3293124488409376e-06\n",
      "Epoch 2965, Loss: 0.004712153257955265, Final Batch Loss: 0.00208344217389822\n",
      "Epoch 2966, Loss: 0.0003739218763030294, Final Batch Loss: 5.186218459130032e-06\n",
      "Epoch 2967, Loss: 0.00017796573800410442, Final Batch Loss: 8.538676047464833e-05\n",
      "Epoch 2968, Loss: 0.00039599997444383916, Final Batch Loss: 3.8213161133171525e-06\n",
      "Epoch 2969, Loss: 0.0002026835703645702, Final Batch Loss: 7.765902410028502e-06\n",
      "Epoch 2970, Loss: 0.002885171393472774, Final Batch Loss: 0.0002813667815644294\n",
      "Epoch 2971, Loss: 0.00029385999016540154, Final Batch Loss: 4.264098606654443e-06\n",
      "Epoch 2972, Loss: 0.0004696417120158003, Final Batch Loss: 3.994993676315062e-06\n",
      "Epoch 2973, Loss: 0.00019155517173885528, Final Batch Loss: 1.53387645696057e-05\n",
      "Epoch 2974, Loss: 7.736005409242352e-05, Final Batch Loss: 2.8799629490094958e-06\n",
      "Epoch 2975, Loss: 0.0007371056193505865, Final Batch Loss: 3.1772303827892756e-06\n",
      "Epoch 2976, Loss: 8.721561663094235e-05, Final Batch Loss: 1.1060984434152488e-05\n",
      "Epoch 2977, Loss: 0.00015921464537882457, Final Batch Loss: 2.299198240507394e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2978, Loss: 0.000124918984283795, Final Batch Loss: 5.114390546623326e-07\n",
      "Epoch 2979, Loss: 0.00017902666382951793, Final Batch Loss: 1.3636381481774151e-06\n",
      "Epoch 2980, Loss: 0.00017180271035499572, Final Batch Loss: 1.0149138688575476e-05\n",
      "Epoch 2981, Loss: 0.0003281927094462844, Final Batch Loss: 5.803842668683501e-06\n",
      "Epoch 2982, Loss: 0.0002450746551261318, Final Batch Loss: 1.1141610229969956e-06\n",
      "Epoch 2983, Loss: 4.071790738180425e-05, Final Batch Loss: 5.133638865117973e-07\n",
      "Epoch 2984, Loss: 0.0001726110912443346, Final Batch Loss: 3.1099679631552135e-07\n",
      "Epoch 2985, Loss: 0.00019802505232746626, Final Batch Loss: 3.410146518945112e-06\n",
      "Epoch 2986, Loss: 0.00014173054461252832, Final Batch Loss: 5.128812290422502e-07\n",
      "Epoch 2987, Loss: 0.0019277950580374181, Final Batch Loss: 3.4858985600294545e-06\n",
      "Epoch 2988, Loss: 0.00023474146939861384, Final Batch Loss: 5.290837179927621e-06\n",
      "Epoch 2989, Loss: 0.00012877223144869276, Final Batch Loss: 7.695559247622441e-07\n",
      "Epoch 2990, Loss: 3.693495997936225e-05, Final Batch Loss: 1.2065095233992906e-07\n",
      "Epoch 2991, Loss: 0.00014363448894982866, Final Batch Loss: 3.287911749794148e-05\n",
      "Epoch 2992, Loss: 0.0002568258107942256, Final Batch Loss: 4.581881148624234e-05\n",
      "Epoch 2993, Loss: 0.00014795776593246046, Final Batch Loss: 4.0837392589310184e-05\n",
      "Epoch 2994, Loss: 4.372647377692829e-05, Final Batch Loss: 4.080924043137202e-07\n",
      "Epoch 2995, Loss: 4.882571845143957e-05, Final Batch Loss: 7.517743370044627e-07\n",
      "Epoch 2996, Loss: 0.00013384085029599646, Final Batch Loss: 6.585334233477624e-08\n",
      "Epoch 2997, Loss: 0.001386376554336266, Final Batch Loss: 1.900267852761317e-05\n",
      "Epoch 2998, Loss: 0.00014601721417761837, Final Batch Loss: 1.158439602022554e-07\n",
      "Epoch 2999, Loss: 0.0001239481709447432, Final Batch Loss: 1.4372349710356502e-07\n",
      "Epoch 3000, Loss: 2.8745864753432215e-05, Final Batch Loss: 8.853878057379916e-07\n",
      "Epoch 3001, Loss: 3.674554189103674e-05, Final Batch Loss: 2.513937999992777e-07\n",
      "Epoch 3002, Loss: 0.000248335100121011, Final Batch Loss: 5.061307888354349e-07\n",
      "Epoch 3003, Loss: 0.00014950855835849097, Final Batch Loss: 1.4010951190357446e-06\n",
      "Epoch 3004, Loss: 0.00011615927601837939, Final Batch Loss: 3.186889614426036e-07\n",
      "Epoch 3005, Loss: 8.966671516219549e-05, Final Batch Loss: 2.2495822804557974e-07\n",
      "Epoch 3006, Loss: 8.562260363476071e-05, Final Batch Loss: 9.507264735475474e-07\n",
      "Epoch 3007, Loss: 0.00014917556210747307, Final Batch Loss: 3.271739115007222e-05\n",
      "Epoch 3008, Loss: 0.00014917019002780307, Final Batch Loss: 6.657265885223751e-07\n",
      "Epoch 3009, Loss: 0.0016452114777365523, Final Batch Loss: 5.931364626121649e-07\n",
      "Epoch 3010, Loss: 6.213604709159881e-05, Final Batch Loss: 2.9735722364421235e-06\n",
      "Epoch 3011, Loss: 0.00012803677011419268, Final Batch Loss: 1.8668050643100287e-06\n",
      "Epoch 3012, Loss: 0.001602180870087011, Final Batch Loss: 2.120867975463625e-06\n",
      "Epoch 3013, Loss: 9.737092236861145e-05, Final Batch Loss: 3.979926361807884e-07\n",
      "Epoch 3014, Loss: 0.00032253562056538954, Final Batch Loss: 5.868761263627675e-07\n",
      "Epoch 3015, Loss: 0.00012763039807595078, Final Batch Loss: 3.9623766497243196e-05\n",
      "Epoch 3016, Loss: 9.612171396611302e-05, Final Batch Loss: 1.63363506544556e-06\n",
      "Epoch 3017, Loss: 0.0008307217759266905, Final Batch Loss: 2.8073218345525675e-06\n",
      "Epoch 3018, Loss: 6.904507540639315e-05, Final Batch Loss: 2.499505740161112e-07\n",
      "Epoch 3019, Loss: 0.00047889358526731485, Final Batch Loss: 1.9853259800584055e-06\n",
      "Epoch 3020, Loss: 0.003208043471943256, Final Batch Loss: 6.053825200069696e-05\n",
      "Epoch 3021, Loss: 0.0005883303938780671, Final Batch Loss: 6.90718366058718e-07\n",
      "Epoch 3022, Loss: 0.00036192473718976714, Final Batch Loss: 4.63357110902507e-07\n",
      "Epoch 3023, Loss: 5.8146176769469093e-05, Final Batch Loss: 3.128590833512135e-06\n",
      "Epoch 3024, Loss: 1.6823177382718768e-05, Final Batch Loss: 1.6679575765010668e-07\n",
      "Epoch 3025, Loss: 0.0004379368728741895, Final Batch Loss: 3.981189820478903e-06\n",
      "Epoch 3026, Loss: 0.00042011513288642277, Final Batch Loss: 6.777607808317043e-08\n",
      "Epoch 3027, Loss: 0.00018315283254288772, Final Batch Loss: 3.8260708379311836e-07\n",
      "Epoch 3028, Loss: 0.0008036037751395497, Final Batch Loss: 1.7940254792847554e-06\n",
      "Epoch 3029, Loss: 0.01786632042745495, Final Batch Loss: 0.01776966080069542\n",
      "Epoch 3030, Loss: 0.0004196161954297395, Final Batch Loss: 0.00034504407085478306\n",
      "Epoch 3031, Loss: 0.03902593037783042, Final Batch Loss: 3.1916798093334364e-07\n",
      "Epoch 3032, Loss: 0.048673327427522395, Final Batch Loss: 0.007517734542489052\n",
      "Epoch 3033, Loss: 0.000809570190881459, Final Batch Loss: 3.863717211061157e-06\n",
      "Epoch 3034, Loss: 0.001298999063692463, Final Batch Loss: 7.435790030285716e-05\n",
      "Epoch 3035, Loss: 0.00632616349298587, Final Batch Loss: 5.252638857200509e-06\n",
      "Epoch 3036, Loss: 0.0005115844598435615, Final Batch Loss: 2.328052914890577e-06\n",
      "Epoch 3037, Loss: 8.343631833440668e-05, Final Batch Loss: 6.897568596286874e-07\n",
      "Epoch 3038, Loss: 0.00038207090932473875, Final Batch Loss: 6.157392817840446e-07\n",
      "Epoch 3039, Loss: 0.0002442793901877849, Final Batch Loss: 3.4951719953824067e-06\n",
      "Epoch 3040, Loss: 0.00038186627953962216, Final Batch Loss: 4.916792477160925e-06\n",
      "Epoch 3041, Loss: 0.0003769785434997175, Final Batch Loss: 8.417715434916317e-05\n",
      "Epoch 3042, Loss: 0.0025553712896329017, Final Batch Loss: 1.4630005580329453e-06\n",
      "Epoch 3043, Loss: 0.001157574370211023, Final Batch Loss: 2.281903334733215e-06\n",
      "Epoch 3044, Loss: 0.0005843512599810197, Final Batch Loss: 1.0190444044155811e-07\n",
      "Epoch 3045, Loss: 6.274955993035292e-05, Final Batch Loss: 2.4636528905830346e-06\n",
      "Epoch 3046, Loss: 0.00022766379002092663, Final Batch Loss: 2.86343401967315e-06\n",
      "Epoch 3047, Loss: 0.03148035206145394, Final Batch Loss: 0.0009845838649198413\n",
      "Epoch 3048, Loss: 0.00232139696709055, Final Batch Loss: 0.0010452443966642022\n",
      "Epoch 3049, Loss: 0.00949150407950583, Final Batch Loss: 5.588608928519534e-06\n",
      "Epoch 3050, Loss: 0.0006327495912046288, Final Batch Loss: 4.459775027498836e-06\n",
      "Epoch 3051, Loss: 0.005996935379812385, Final Batch Loss: 1.1055816685257014e-05\n",
      "Epoch 3052, Loss: 0.0004143181247400207, Final Batch Loss: 2.6479503503651358e-05\n",
      "Epoch 3053, Loss: 0.00023866892058777012, Final Batch Loss: 1.311065807385603e-05\n",
      "Epoch 3054, Loss: 0.00043908036019502106, Final Batch Loss: 9.42319275054615e-06\n",
      "Epoch 3055, Loss: 0.0006602886464861513, Final Batch Loss: 3.8141056393214967e-06\n",
      "Epoch 3056, Loss: 0.011391458461503134, Final Batch Loss: 3.3797307423810707e-06\n",
      "Epoch 3057, Loss: 0.00018710426317625206, Final Batch Loss: 7.798099431965966e-06\n",
      "Epoch 3058, Loss: 0.0008080889251402823, Final Batch Loss: 1.297691142099211e-05\n",
      "Epoch 3059, Loss: 0.0005332050608615191, Final Batch Loss: 2.518760027214739e-07\n",
      "Epoch 3060, Loss: 0.00015562670773761056, Final Batch Loss: 6.812633273511892e-06\n",
      "Epoch 3061, Loss: 0.0010610722612227619, Final Batch Loss: 6.428859705920331e-06\n",
      "Epoch 3062, Loss: 0.00040677528292576426, Final Batch Loss: 0.00020240175945218652\n",
      "Epoch 3063, Loss: 0.010336754955574179, Final Batch Loss: 2.3778911781846546e-05\n",
      "Epoch 3064, Loss: 0.014939500930836402, Final Batch Loss: 1.37516883569333e-06\n",
      "Epoch 3065, Loss: 0.0004312161814823412, Final Batch Loss: 2.1969190129311755e-06\n",
      "Epoch 3066, Loss: 0.0003130122040886363, Final Batch Loss: 6.944119832041906e-06\n",
      "Epoch 3067, Loss: 0.023222576389969163, Final Batch Loss: 1.581569631525781e-05\n",
      "Epoch 3068, Loss: 0.015155418906289242, Final Batch Loss: 6.567736818396952e-06\n",
      "Epoch 3069, Loss: 0.001734157938244607, Final Batch Loss: 0.0008921174448914826\n",
      "Epoch 3070, Loss: 0.0024908726750254573, Final Batch Loss: 1.2278725080250297e-05\n",
      "Epoch 3071, Loss: 0.00015100438815807138, Final Batch Loss: 1.4698391169076785e-05\n",
      "Epoch 3072, Loss: 0.0002451767363709223, Final Batch Loss: 1.4982419997977559e-06\n",
      "Epoch 3073, Loss: 0.0015717978825477985, Final Batch Loss: 0.00018506850756239146\n",
      "Epoch 3074, Loss: 0.0022266719198569263, Final Batch Loss: 3.6359080695547163e-05\n",
      "Epoch 3075, Loss: 0.015315659126827086, Final Batch Loss: 6.966117325646337e-06\n",
      "Epoch 3076, Loss: 0.00018706073396401734, Final Batch Loss: 4.460606817247026e-07\n",
      "Epoch 3077, Loss: 0.0010551596451477963, Final Batch Loss: 5.3763651521876454e-06\n",
      "Epoch 3078, Loss: 0.007335818852453713, Final Batch Loss: 3.013862226453057e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3079, Loss: 0.0005098039691802114, Final Batch Loss: 7.767287570459303e-06\n",
      "Epoch 3080, Loss: 0.0003385925796237643, Final Batch Loss: 0.0001421341294189915\n",
      "Epoch 3081, Loss: 0.0006939797891618582, Final Batch Loss: 1.9639285255834693e-06\n",
      "Epoch 3082, Loss: 0.0007351776058612813, Final Batch Loss: 4.738812640425749e-05\n",
      "Epoch 3083, Loss: 0.0008063596449119359, Final Batch Loss: 2.6143586637772387e-06\n",
      "Epoch 3084, Loss: 0.00022215866502506287, Final Batch Loss: 1.99880969375954e-06\n",
      "Epoch 3085, Loss: 0.006909988526103916, Final Batch Loss: 5.133070771989878e-06\n",
      "Epoch 3086, Loss: 0.000489928503043302, Final Batch Loss: 0.0004230080812703818\n",
      "Epoch 3087, Loss: 0.0008844114067869668, Final Batch Loss: 2.020019201154355e-05\n",
      "Epoch 3088, Loss: 0.0003728500691977388, Final Batch Loss: 1.8136570361093618e-05\n",
      "Epoch 3089, Loss: 0.00011908534764870637, Final Batch Loss: 1.1327604624966625e-05\n",
      "Epoch 3090, Loss: 0.00029923587783287076, Final Batch Loss: 8.934613106248435e-06\n",
      "Epoch 3091, Loss: 0.0002751464306811613, Final Batch Loss: 5.545447947952198e-06\n",
      "Epoch 3092, Loss: 0.0002724353200846963, Final Batch Loss: 2.0259610664652428e-06\n",
      "Epoch 3093, Loss: 0.0001913563281163988, Final Batch Loss: 1.0104601642524358e-05\n",
      "Epoch 3094, Loss: 0.00011165090705844705, Final Batch Loss: 1.4064164588489803e-06\n",
      "Epoch 3095, Loss: 0.00017292910865762678, Final Batch Loss: 1.372765200358117e-05\n",
      "Epoch 3096, Loss: 0.0003410877288274605, Final Batch Loss: 7.433949576807208e-06\n",
      "Epoch 3097, Loss: 0.0005516769745668171, Final Batch Loss: 8.193234862119425e-06\n",
      "Epoch 3098, Loss: 7.100441857232909e-05, Final Batch Loss: 1.559194060973823e-06\n",
      "Epoch 3099, Loss: 0.0023289727308792862, Final Batch Loss: 2.1134173948667012e-06\n",
      "Epoch 3100, Loss: 0.13234880861338638, Final Batch Loss: 0.00037936068838462234\n",
      "Epoch 3101, Loss: 0.028071189694728105, Final Batch Loss: 0.005039912182837725\n",
      "Epoch 3102, Loss: 0.0023342288366734465, Final Batch Loss: 1.3140731880412204e-06\n",
      "Epoch 3103, Loss: 0.0037077818788020522, Final Batch Loss: 6.2504655033990275e-06\n",
      "Epoch 3104, Loss: 0.000786279771318732, Final Batch Loss: 4.2074966586369555e-06\n",
      "Epoch 3105, Loss: 0.0008802531649507728, Final Batch Loss: 4.499466285778908e-06\n",
      "Epoch 3106, Loss: 0.0004154749935878499, Final Batch Loss: 0.00024444624432362616\n",
      "Epoch 3107, Loss: 0.0012118759228769704, Final Batch Loss: 0.00024725034018047154\n",
      "Epoch 3108, Loss: 0.00025498142676383395, Final Batch Loss: 3.281085355411051e-06\n",
      "Epoch 3109, Loss: 0.0008341013073049908, Final Batch Loss: 1.7295131328864954e-05\n",
      "Epoch 3110, Loss: 0.0014314128246155633, Final Batch Loss: 3.230684524169192e-05\n",
      "Epoch 3111, Loss: 0.0002150620297243222, Final Batch Loss: 3.910263785655843e-06\n",
      "Epoch 3112, Loss: 0.00022658705313460814, Final Batch Loss: 4.525401891442016e-05\n",
      "Epoch 3113, Loss: 0.000716984035477708, Final Batch Loss: 0.00010769363871077076\n",
      "Epoch 3114, Loss: 0.00014516096820216262, Final Batch Loss: 3.3135522699012654e-06\n",
      "Epoch 3115, Loss: 0.0010968880077868448, Final Batch Loss: 1.2800443982996512e-05\n",
      "Epoch 3116, Loss: 0.0005729771512363868, Final Batch Loss: 0.00014588011254090816\n",
      "Epoch 3117, Loss: 0.00011053833108576328, Final Batch Loss: 1.480123773944797e-05\n",
      "Epoch 3118, Loss: 0.0006638281036472904, Final Batch Loss: 1.1748506040021311e-05\n",
      "Epoch 3119, Loss: 0.0006246347874707681, Final Batch Loss: 6.200656912369595e-07\n",
      "Epoch 3120, Loss: 0.00033922411165576705, Final Batch Loss: 2.2956126485951245e-05\n",
      "Epoch 3121, Loss: 0.0035476765479245387, Final Batch Loss: 1.1329123026371235e-06\n",
      "Epoch 3122, Loss: 0.0028911787958350033, Final Batch Loss: 9.7718725555751e-07\n",
      "Epoch 3123, Loss: 0.00011102671379603635, Final Batch Loss: 3.9209444366861135e-06\n",
      "Epoch 3124, Loss: 0.007425956753550622, Final Batch Loss: 0.0034536938183009624\n",
      "Epoch 3125, Loss: 0.00029523446960411093, Final Batch Loss: 2.275916131111444e-06\n",
      "Epoch 3126, Loss: 0.0004070521850252362, Final Batch Loss: 7.226557954709278e-06\n",
      "Epoch 3127, Loss: 0.00017240988182720685, Final Batch Loss: 5.74290925214882e-06\n",
      "Epoch 3128, Loss: 0.00012542095274170606, Final Batch Loss: 1.0742919585027266e-05\n",
      "Epoch 3129, Loss: 0.00025313166952400934, Final Batch Loss: 1.1458857898105634e-06\n",
      "Epoch 3130, Loss: 8.452662725844107e-05, Final Batch Loss: 2.807157386541803e-07\n",
      "Epoch 3131, Loss: 0.000797189081303884, Final Batch Loss: 7.455144555024162e-07\n",
      "Epoch 3132, Loss: 0.22359357211348652, Final Batch Loss: 0.000469413585960865\n",
      "Epoch 3133, Loss: 0.051429063636419414, Final Batch Loss: 2.6172016077907756e-05\n",
      "Epoch 3134, Loss: 0.00021788451385873486, Final Batch Loss: 6.695778665744001e-06\n",
      "Epoch 3135, Loss: 0.0010888749627611105, Final Batch Loss: 0.00010261810530209914\n",
      "Epoch 3136, Loss: 0.0002581617932264635, Final Batch Loss: 7.196319529612083e-06\n",
      "Epoch 3137, Loss: 0.00022218281537789153, Final Batch Loss: 8.252490260929335e-06\n",
      "Epoch 3138, Loss: 0.0006971675611566752, Final Batch Loss: 9.16218323254725e-06\n",
      "Epoch 3139, Loss: 0.0010206419305518466, Final Batch Loss: 2.0988311007386073e-05\n",
      "Epoch 3140, Loss: 0.00025437023123231484, Final Batch Loss: 2.7432744900579564e-05\n",
      "Epoch 3141, Loss: 0.0006187857486565917, Final Batch Loss: 1.0169041161134373e-05\n",
      "Epoch 3142, Loss: 0.0005210564768276527, Final Batch Loss: 4.9190816753252875e-06\n",
      "Epoch 3143, Loss: 0.0005773534430772997, Final Batch Loss: 3.176927975800936e-06\n",
      "Epoch 3144, Loss: 0.001988006998772107, Final Batch Loss: 8.346613867615815e-06\n",
      "Epoch 3145, Loss: 0.0009572779915743013, Final Batch Loss: 1.5912946764728986e-05\n",
      "Epoch 3146, Loss: 0.0011317226899336674, Final Batch Loss: 8.752969733905047e-05\n",
      "Epoch 3147, Loss: 0.00026897680595538986, Final Batch Loss: 5.900105861655902e-06\n",
      "Epoch 3148, Loss: 0.00034562856706088496, Final Batch Loss: 4.602239187079249e-06\n",
      "Epoch 3149, Loss: 0.0002427846782211418, Final Batch Loss: 1.2177350981801283e-05\n",
      "Epoch 3150, Loss: 0.00018623078926793823, Final Batch Loss: 8.67964445205871e-06\n",
      "Epoch 3151, Loss: 0.00032005441153160064, Final Batch Loss: 6.509691593237221e-05\n",
      "Epoch 3152, Loss: 0.000309489462779311, Final Batch Loss: 5.8108134908252396e-06\n",
      "Epoch 3153, Loss: 0.00022597144425162696, Final Batch Loss: 1.8091639503836632e-05\n",
      "Epoch 3154, Loss: 0.0014489158343167219, Final Batch Loss: 7.988771358213853e-06\n",
      "Epoch 3155, Loss: 0.0004291235918572056, Final Batch Loss: 9.778702951734886e-05\n",
      "Epoch 3156, Loss: 0.00018752965513613162, Final Batch Loss: 9.305385901825503e-06\n",
      "Epoch 3157, Loss: 0.000361204237151469, Final Batch Loss: 3.7908271224296186e-06\n",
      "Epoch 3158, Loss: 0.0002501745681229295, Final Batch Loss: 3.35197501044604e-06\n",
      "Epoch 3159, Loss: 0.00030876856919803686, Final Batch Loss: 3.230984657420777e-05\n",
      "Epoch 3160, Loss: 0.0020619081240056403, Final Batch Loss: 1.3347349522518925e-05\n",
      "Epoch 3161, Loss: 0.00028632343116896664, Final Batch Loss: 0.00015489004726987332\n",
      "Epoch 3162, Loss: 0.00016158246410213906, Final Batch Loss: 4.1394346226297785e-06\n",
      "Epoch 3163, Loss: 0.0004917303152751629, Final Batch Loss: 2.05086780624697e-05\n",
      "Epoch 3164, Loss: 0.0002969101453800249, Final Batch Loss: 3.661303935587057e-06\n",
      "Epoch 3165, Loss: 0.00016640453520722076, Final Batch Loss: 4.733833520731423e-06\n",
      "Epoch 3166, Loss: 0.0016912658814476345, Final Batch Loss: 4.4497387534647714e-06\n",
      "Epoch 3167, Loss: 0.0002739204418844565, Final Batch Loss: 4.2702107748482376e-05\n",
      "Epoch 3168, Loss: 0.00044235383791146887, Final Batch Loss: 1.7674094578978838e-06\n",
      "Epoch 3169, Loss: 0.10901006303276972, Final Batch Loss: 2.6534500648267567e-05\n",
      "Epoch 3170, Loss: 0.01692738230303803, Final Batch Loss: 1.5105440070328768e-05\n",
      "Epoch 3171, Loss: 0.0027812117114081047, Final Batch Loss: 1.2366588634904474e-05\n",
      "Epoch 3172, Loss: 0.0008900791476662562, Final Batch Loss: 4.1009971027961e-06\n",
      "Epoch 3173, Loss: 0.000384241334586477, Final Batch Loss: 1.0654280231392477e-05\n",
      "Epoch 3174, Loss: 0.00021133139125595335, Final Batch Loss: 9.964401215256657e-07\n",
      "Epoch 3175, Loss: 0.01070519345375942, Final Batch Loss: 2.3902794055175036e-05\n",
      "Epoch 3176, Loss: 0.005988071003002915, Final Batch Loss: 2.995399654537323e-06\n",
      "Epoch 3177, Loss: 0.00030951472490414744, Final Batch Loss: 6.546850272570737e-06\n",
      "Epoch 3178, Loss: 0.00028111312235523656, Final Batch Loss: 5.273509486869443e-06\n",
      "Epoch 3179, Loss: 0.000250560059498639, Final Batch Loss: 8.357366823474877e-06\n",
      "Epoch 3180, Loss: 0.0006316358479807604, Final Batch Loss: 3.1959847547113895e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3181, Loss: 0.00016408789201705076, Final Batch Loss: 1.283384335692972e-06\n",
      "Epoch 3182, Loss: 0.00022462700394498825, Final Batch Loss: 4.5191602112026885e-05\n",
      "Epoch 3183, Loss: 0.000390996309761249, Final Batch Loss: 2.62443450083083e-06\n",
      "Epoch 3184, Loss: 0.0013703517595899939, Final Batch Loss: 2.887518348870799e-05\n",
      "Epoch 3185, Loss: 0.0008218265205641728, Final Batch Loss: 6.109363312134519e-06\n",
      "Epoch 3186, Loss: 0.00028771085055723233, Final Batch Loss: 5.300583779899171e-06\n",
      "Epoch 3187, Loss: 0.00020545579457120766, Final Batch Loss: 8.575133847443794e-07\n",
      "Epoch 3188, Loss: 0.00014648512581061368, Final Batch Loss: 7.99244298832491e-06\n",
      "Epoch 3189, Loss: 0.0002117530523264577, Final Batch Loss: 2.9869349873479223e-06\n",
      "Epoch 3190, Loss: 0.0003811019388706427, Final Batch Loss: 4.96245638714754e-06\n",
      "Epoch 3191, Loss: 0.00022798115537625563, Final Batch Loss: 9.635666174290236e-06\n",
      "Epoch 3192, Loss: 0.0024065586031838393, Final Batch Loss: 1.072842906069127e-06\n",
      "Epoch 3193, Loss: 0.03755889675915114, Final Batch Loss: 5.294014499668265e-06\n",
      "Epoch 3194, Loss: 0.0006626009509318465, Final Batch Loss: 1.9723140212590806e-05\n",
      "Epoch 3195, Loss: 0.00612140262990124, Final Batch Loss: 6.167124865896767e-06\n",
      "Epoch 3196, Loss: 0.0003559487815891771, Final Batch Loss: 9.513235454505775e-06\n",
      "Epoch 3197, Loss: 0.00029819036353728734, Final Batch Loss: 1.3118208698870149e-05\n",
      "Epoch 3198, Loss: 0.0003425516410970886, Final Batch Loss: 3.890290372510208e-06\n",
      "Epoch 3199, Loss: 0.002026880567882472, Final Batch Loss: 7.314140475500608e-06\n",
      "Epoch 3200, Loss: 0.0003918742302175815, Final Batch Loss: 2.013974153669551e-05\n",
      "Epoch 3201, Loss: 0.00024807288832562335, Final Batch Loss: 1.9980059278168483e-06\n",
      "Epoch 3202, Loss: 0.00022648612457487616, Final Batch Loss: 6.226024197530933e-06\n",
      "Epoch 3203, Loss: 0.003206476603054398, Final Batch Loss: 7.275305961229606e-06\n",
      "Epoch 3204, Loss: 0.00024710120078452746, Final Batch Loss: 9.541952749714255e-06\n",
      "Epoch 3205, Loss: 0.00033384112612111494, Final Batch Loss: 3.1853146538196597e-06\n",
      "Epoch 3206, Loss: 0.005039614082761545, Final Batch Loss: 1.0140789527213201e-05\n",
      "Epoch 3207, Loss: 0.0006841596197091349, Final Batch Loss: 2.1567253497778438e-05\n",
      "Epoch 3208, Loss: 0.000271839329229806, Final Batch Loss: 3.2138962069439003e-06\n",
      "Epoch 3209, Loss: 0.028105123329510207, Final Batch Loss: 0.00010063694935524836\n",
      "Epoch 3210, Loss: 0.005628448786410445, Final Batch Loss: 6.032445526216179e-05\n",
      "Epoch 3211, Loss: 0.006587355434021447, Final Batch Loss: 1.907562000269536e-05\n",
      "Epoch 3212, Loss: 0.0007701714948780136, Final Batch Loss: 5.6570338529127184e-06\n",
      "Epoch 3213, Loss: 0.0006472186257724388, Final Batch Loss: 1.4289348655438516e-05\n",
      "Epoch 3214, Loss: 0.00016507152031408623, Final Batch Loss: 2.44646544160787e-05\n",
      "Epoch 3215, Loss: 0.0008072738597775242, Final Batch Loss: 8.619324034953024e-06\n",
      "Epoch 3216, Loss: 9.136240947782426e-05, Final Batch Loss: 4.15082377003273e-06\n",
      "Epoch 3217, Loss: 8.577197149861604e-05, Final Batch Loss: 3.0038454497116618e-06\n",
      "Epoch 3218, Loss: 0.00022557973363745987, Final Batch Loss: 1.3235389815235976e-05\n",
      "Epoch 3219, Loss: 0.004970515021796018, Final Batch Loss: 1.2336890904407483e-05\n",
      "Epoch 3220, Loss: 0.01387550933577586, Final Batch Loss: 1.0608727279759478e-05\n",
      "Epoch 3221, Loss: 0.006514064448310819, Final Batch Loss: 3.383658986422233e-05\n",
      "Epoch 3222, Loss: 0.0030770571152061166, Final Batch Loss: 5.0148128138971515e-06\n",
      "Epoch 3223, Loss: 0.00014654418509962852, Final Batch Loss: 2.031691792581114e-06\n",
      "Epoch 3224, Loss: 0.0016553261671106156, Final Batch Loss: 3.761747939279303e-05\n",
      "Epoch 3225, Loss: 0.0002532056852828646, Final Batch Loss: 9.051009897120821e-07\n",
      "Epoch 3226, Loss: 0.004823248987690931, Final Batch Loss: 1.818777604967181e-06\n",
      "Epoch 3227, Loss: 0.006579280957225819, Final Batch Loss: 3.347801975905895e-05\n",
      "Epoch 3228, Loss: 0.0004628926010354917, Final Batch Loss: 1.9736693502636626e-05\n",
      "Epoch 3229, Loss: 0.0008072499256286392, Final Batch Loss: 2.0999973457946908e-06\n",
      "Epoch 3230, Loss: 0.0009677176371951646, Final Batch Loss: 2.3174718080554157e-05\n",
      "Epoch 3231, Loss: 0.00018300455027997486, Final Batch Loss: 1.8643737348611467e-05\n",
      "Epoch 3232, Loss: 0.00018242916826238798, Final Batch Loss: 1.5198569371932535e-06\n",
      "Epoch 3233, Loss: 0.009295660235693504, Final Batch Loss: 1.7694803318590857e-05\n",
      "Epoch 3234, Loss: 0.0026566182187366394, Final Batch Loss: 4.998306394554675e-06\n",
      "Epoch 3235, Loss: 0.002704768353169129, Final Batch Loss: 2.779184569590143e-06\n",
      "Epoch 3236, Loss: 0.0012076786168790932, Final Batch Loss: 3.131436415060307e-06\n",
      "Epoch 3237, Loss: 0.0023287705457732955, Final Batch Loss: 2.1129014839971205e-06\n",
      "Epoch 3238, Loss: 0.00039510798808350955, Final Batch Loss: 9.094359120354056e-05\n",
      "Epoch 3239, Loss: 6.373913890911354e-05, Final Batch Loss: 1.0853526646315004e-06\n",
      "Epoch 3240, Loss: 0.0024809029782772996, Final Batch Loss: 1.7165059034596197e-05\n",
      "Epoch 3241, Loss: 0.0005628333492495585, Final Batch Loss: 0.00016441837942693383\n",
      "Epoch 3242, Loss: 0.00017173862897834624, Final Batch Loss: 2.5430679215787677e-06\n",
      "Epoch 3243, Loss: 0.0006952393930959033, Final Batch Loss: 4.554622501018457e-05\n",
      "Epoch 3244, Loss: 9.583076956687364e-05, Final Batch Loss: 1.9188075839338126e-06\n",
      "Epoch 3245, Loss: 0.0009621845653100536, Final Batch Loss: 7.429706784023438e-06\n",
      "Epoch 3246, Loss: 0.015022938848460399, Final Batch Loss: 2.6416907985549187e-06\n",
      "Epoch 3247, Loss: 0.0007175739151534799, Final Batch Loss: 2.254697847092757e-06\n",
      "Epoch 3248, Loss: 0.0009397361410492522, Final Batch Loss: 4.298192379792454e-06\n",
      "Epoch 3249, Loss: 0.0006376276185164897, Final Batch Loss: 1.3708436199522112e-05\n",
      "Epoch 3250, Loss: 0.038968758530756986, Final Batch Loss: 0.00014892456238158047\n",
      "Epoch 3251, Loss: 0.0011310309305372357, Final Batch Loss: 0.00018395639199297875\n",
      "Epoch 3252, Loss: 0.000329120482547296, Final Batch Loss: 1.4241739336284809e-05\n",
      "Epoch 3253, Loss: 0.0005542849144148931, Final Batch Loss: 5.261273690848611e-05\n",
      "Epoch 3254, Loss: 0.00028582197012383403, Final Batch Loss: 6.587993084394839e-06\n",
      "Epoch 3255, Loss: 0.0006834421057817508, Final Batch Loss: 4.14551941503305e-05\n",
      "Epoch 3256, Loss: 0.0008897146487925056, Final Batch Loss: 2.1259284039842896e-05\n",
      "Epoch 3257, Loss: 0.00022440555409275476, Final Batch Loss: 9.99286839942215e-07\n",
      "Epoch 3258, Loss: 0.0021587201157444724, Final Batch Loss: 3.349808594066417e-06\n",
      "Epoch 3259, Loss: 0.0005502034814526269, Final Batch Loss: 7.07725803295034e-06\n",
      "Epoch 3260, Loss: 0.00019840565352069461, Final Batch Loss: 2.215598669863539e-06\n",
      "Epoch 3261, Loss: 0.00016425481430815125, Final Batch Loss: 5.653062089550076e-06\n",
      "Epoch 3262, Loss: 0.0011727022472314275, Final Batch Loss: 1.0313989150745329e-05\n",
      "Epoch 3263, Loss: 0.00033076428630351984, Final Batch Loss: 3.7961206544423476e-05\n",
      "Epoch 3264, Loss: 0.000354575657524947, Final Batch Loss: 5.213160875428002e-06\n",
      "Epoch 3265, Loss: 0.00015397418030715926, Final Batch Loss: 3.625758381531341e-06\n",
      "Epoch 3266, Loss: 0.00020368588349128913, Final Batch Loss: 1.9599553979787743e-06\n",
      "Epoch 3267, Loss: 0.00016957528328021, Final Batch Loss: 1.4871900020807516e-05\n",
      "Epoch 3268, Loss: 0.00013973108164577752, Final Batch Loss: 3.1273892091121525e-05\n",
      "Epoch 3269, Loss: 0.00014180662140006461, Final Batch Loss: 3.147354436805472e-05\n",
      "Epoch 3270, Loss: 0.00021037579543303764, Final Batch Loss: 4.904003162664594e-06\n",
      "Epoch 3271, Loss: 0.0007328370910499871, Final Batch Loss: 2.6462619189260295e-06\n",
      "Epoch 3272, Loss: 0.0003953354898271755, Final Batch Loss: 0.00010708290938055143\n",
      "Epoch 3273, Loss: 0.019556047011832334, Final Batch Loss: 4.8938441068457905e-06\n",
      "Epoch 3274, Loss: 0.0038056933965435746, Final Batch Loss: 2.043795348072308e-06\n",
      "Epoch 3275, Loss: 0.0015906543912933557, Final Batch Loss: 1.0940382708213292e-05\n",
      "Epoch 3276, Loss: 0.00024944370716184494, Final Batch Loss: 5.863970727659762e-06\n",
      "Epoch 3277, Loss: 0.0033547596851803974, Final Batch Loss: 0.0001398383465129882\n",
      "Epoch 3278, Loss: 0.0029845631001990114, Final Batch Loss: 4.514464762905845e-06\n",
      "Epoch 3279, Loss: 0.0005550672358367592, Final Batch Loss: 6.263128307182342e-05\n",
      "Epoch 3280, Loss: 0.0034166459665812, Final Batch Loss: 3.4590741506690392e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3281, Loss: 0.00015003768987753574, Final Batch Loss: 1.136455284722615e-05\n",
      "Epoch 3282, Loss: 0.000958590476415111, Final Batch Loss: 7.180862553468614e-07\n",
      "Epoch 3283, Loss: 0.00011895405125983416, Final Batch Loss: 1.282417656511825e-06\n",
      "Epoch 3284, Loss: 0.0006123874675267871, Final Batch Loss: 2.0705663700937293e-05\n",
      "Epoch 3285, Loss: 0.0001554200040914111, Final Batch Loss: 2.429395135550294e-05\n",
      "Epoch 3286, Loss: 5.4184803786938573e-05, Final Batch Loss: 4.276481377019081e-06\n",
      "Epoch 3287, Loss: 0.00020538017213311832, Final Batch Loss: 6.254043455555802e-06\n",
      "Epoch 3288, Loss: 0.0002527727822325687, Final Batch Loss: 2.9121961233613547e-06\n",
      "Epoch 3289, Loss: 0.0018989806904130546, Final Batch Loss: 7.987397111719474e-05\n",
      "Epoch 3290, Loss: 0.00019872878294791008, Final Batch Loss: 8.175263246812392e-06\n",
      "Epoch 3291, Loss: 0.0001545410420931148, Final Batch Loss: 2.115828829118982e-05\n",
      "Epoch 3292, Loss: 0.000523036999766191, Final Batch Loss: 0.0003680306253954768\n",
      "Epoch 3293, Loss: 0.0001822565336055959, Final Batch Loss: 1.992146962948027e-06\n",
      "Epoch 3294, Loss: 0.0013738164055325797, Final Batch Loss: 1.2369845535431523e-05\n",
      "Epoch 3295, Loss: 0.00045552117046554486, Final Batch Loss: 0.00023956195218488574\n",
      "Epoch 3296, Loss: 0.00023729555550744408, Final Batch Loss: 6.6340630837657955e-06\n",
      "Epoch 3297, Loss: 0.0005839748680216417, Final Batch Loss: 1.1271578159721685e-06\n",
      "Epoch 3298, Loss: 0.0002450006811614003, Final Batch Loss: 1.6337144188582897e-06\n",
      "Epoch 3299, Loss: 0.017449449117521, Final Batch Loss: 3.53608470504696e-06\n",
      "Epoch 3300, Loss: 0.02325443807649208, Final Batch Loss: 2.6540824364928994e-06\n",
      "Epoch 3301, Loss: 0.00022648715741979686, Final Batch Loss: 6.0032170949853025e-06\n",
      "Epoch 3302, Loss: 0.000841004507492471, Final Batch Loss: 2.8050410492141964e-06\n",
      "Epoch 3303, Loss: 0.01483908657212396, Final Batch Loss: 1.9949624402215704e-05\n",
      "Epoch 3304, Loss: 0.006123923228187778, Final Batch Loss: 3.041764284716919e-05\n",
      "Epoch 3305, Loss: 0.0019192672292547286, Final Batch Loss: 1.9845205315505154e-05\n",
      "Epoch 3306, Loss: 0.00025274533561514545, Final Batch Loss: 6.79188678986975e-06\n",
      "Epoch 3307, Loss: 0.0004448471058822179, Final Batch Loss: 4.731405169877689e-06\n",
      "Epoch 3308, Loss: 0.0007966244978376835, Final Batch Loss: 2.5550461941747926e-06\n",
      "Epoch 3309, Loss: 0.00026875818420535325, Final Batch Loss: 3.2995871151797473e-05\n",
      "Epoch 3310, Loss: 0.0013284107750877183, Final Batch Loss: 0.0002187863428844139\n",
      "Epoch 3311, Loss: 0.0002179190609581383, Final Batch Loss: 8.901449473341927e-05\n",
      "Epoch 3312, Loss: 0.0001821033621922652, Final Batch Loss: 2.3281722860701848e-06\n",
      "Epoch 3313, Loss: 0.00022969799596239682, Final Batch Loss: 2.272950587212108e-05\n",
      "Epoch 3314, Loss: 7.987149706423224e-05, Final Batch Loss: 3.4461970699339872e-06\n",
      "Epoch 3315, Loss: 0.00018981658507755128, Final Batch Loss: 2.5282577553298324e-05\n",
      "Epoch 3316, Loss: 0.00016545168503512286, Final Batch Loss: 2.974615927087143e-05\n",
      "Epoch 3317, Loss: 0.0007041076808604885, Final Batch Loss: 9.431530088477302e-06\n",
      "Epoch 3318, Loss: 9.627010388157942e-05, Final Batch Loss: 5.6552148635091726e-06\n",
      "Epoch 3319, Loss: 3.805468477935392e-05, Final Batch Loss: 6.796711318202142e-07\n",
      "Epoch 3320, Loss: 4.03651860096943e-05, Final Batch Loss: 1.90245214071183e-06\n",
      "Epoch 3321, Loss: 0.0002190402578321482, Final Batch Loss: 2.8293639843468554e-05\n",
      "Epoch 3322, Loss: 8.968262162056817e-05, Final Batch Loss: 1.1831325537059456e-05\n",
      "Epoch 3323, Loss: 5.6326344122226146e-05, Final Batch Loss: 7.858732260501711e-07\n",
      "Epoch 3324, Loss: 0.00473091436177242, Final Batch Loss: 1.7004563233058434e-06\n",
      "Epoch 3325, Loss: 0.0015549800295389105, Final Batch Loss: 2.5334144083899446e-05\n",
      "Epoch 3326, Loss: 8.011919410932933e-05, Final Batch Loss: 1.384784582114662e-06\n",
      "Epoch 3327, Loss: 0.00011358339108369364, Final Batch Loss: 3.3922635793715017e-06\n",
      "Epoch 3328, Loss: 5.133139001145537e-05, Final Batch Loss: 3.887829734594561e-06\n",
      "Epoch 3329, Loss: 0.0003065141726565912, Final Batch Loss: 3.16286701718127e-07\n",
      "Epoch 3330, Loss: 0.00019936706576118013, Final Batch Loss: 1.688037627900485e-06\n",
      "Epoch 3331, Loss: 9.079476647855245e-05, Final Batch Loss: 7.243738195938931e-07\n",
      "Epoch 3332, Loss: 0.0005261907128613075, Final Batch Loss: 2.160903250114643e-06\n",
      "Epoch 3333, Loss: 0.0002169974137018471, Final Batch Loss: 8.24247908894904e-05\n",
      "Epoch 3334, Loss: 6.591134456357395e-05, Final Batch Loss: 3.067892976105213e-06\n",
      "Epoch 3335, Loss: 8.818410965716339e-05, Final Batch Loss: 8.776875688454311e-07\n",
      "Epoch 3336, Loss: 0.0001250413135380768, Final Batch Loss: 1.9820477973553352e-05\n",
      "Epoch 3337, Loss: 0.00014556312566327279, Final Batch Loss: 9.229074038330509e-08\n",
      "Epoch 3338, Loss: 0.00016874089752150212, Final Batch Loss: 7.892602980064112e-07\n",
      "Epoch 3339, Loss: 0.00011422904236724207, Final Batch Loss: 2.835298118952778e-06\n",
      "Epoch 3340, Loss: 0.00012983084053530547, Final Batch Loss: 1.4515954944727127e-06\n",
      "Epoch 3341, Loss: 0.00014524070621746432, Final Batch Loss: 5.876174327568151e-06\n",
      "Epoch 3342, Loss: 0.00048808282625856236, Final Batch Loss: 3.499330034628656e-07\n",
      "Epoch 3343, Loss: 0.00010896858680098376, Final Batch Loss: 2.0118899556109682e-05\n",
      "Epoch 3344, Loss: 0.00027310074284514485, Final Batch Loss: 2.502952156646643e-06\n",
      "Epoch 3345, Loss: 0.00014534812430611055, Final Batch Loss: 6.76738636684604e-06\n",
      "Epoch 3346, Loss: 0.0002004923908884848, Final Batch Loss: 1.4121583262749482e-06\n",
      "Epoch 3347, Loss: 0.00011187961695213744, Final Batch Loss: 1.095421453101153e-06\n",
      "Epoch 3348, Loss: 0.0001042544348237584, Final Batch Loss: 4.589528998621972e-06\n",
      "Epoch 3349, Loss: 8.426477209155792e-05, Final Batch Loss: 9.829774171521422e-06\n",
      "Epoch 3350, Loss: 0.0001359877652760133, Final Batch Loss: 1.534457624075003e-05\n",
      "Epoch 3351, Loss: 5.990760143959051e-05, Final Batch Loss: 1.081962068383291e-06\n",
      "Epoch 3352, Loss: 4.93423010539118e-05, Final Batch Loss: 7.359123515016108e-07\n",
      "Epoch 3353, Loss: 8.780041454770071e-05, Final Batch Loss: 6.500504241557792e-06\n",
      "Epoch 3354, Loss: 0.0009030888842289642, Final Batch Loss: 1.763518753250537e-06\n",
      "Epoch 3355, Loss: 0.00010326435020147073, Final Batch Loss: 3.1436357517122815e-07\n",
      "Epoch 3356, Loss: 0.00012031226338038437, Final Batch Loss: 1.5305169654311612e-05\n",
      "Epoch 3357, Loss: 6.41502666667293e-05, Final Batch Loss: 6.9565671765303705e-06\n",
      "Epoch 3358, Loss: 8.971388198730779e-05, Final Batch Loss: 2.0075947304576403e-06\n",
      "Epoch 3359, Loss: 7.519686678847393e-05, Final Batch Loss: 1.564518584018515e-06\n",
      "Epoch 3360, Loss: 0.00010827181647243833, Final Batch Loss: 5.6166759350162465e-06\n",
      "Epoch 3361, Loss: 7.963618534745365e-05, Final Batch Loss: 1.5562409316771664e-05\n",
      "Epoch 3362, Loss: 6.296384628967644e-05, Final Batch Loss: 1.2304813026275951e-06\n",
      "Epoch 3363, Loss: 0.0006101740835049441, Final Batch Loss: 2.686990399070055e-07\n",
      "Epoch 3364, Loss: 0.00905985295287337, Final Batch Loss: 0.008301500231027603\n",
      "Epoch 3365, Loss: 0.0002717172707065174, Final Batch Loss: 3.3430005714762956e-05\n",
      "Epoch 3366, Loss: 0.0008420761124057208, Final Batch Loss: 1.6442500054836273e-05\n",
      "Epoch 3367, Loss: 0.0002960430900884603, Final Batch Loss: 1.9471250197966583e-05\n",
      "Epoch 3368, Loss: 0.00011941013588057103, Final Batch Loss: 6.215061603143113e-07\n",
      "Epoch 3369, Loss: 0.00030908431295983974, Final Batch Loss: 7.914400157460477e-06\n",
      "Epoch 3370, Loss: 4.699551074338615e-05, Final Batch Loss: 1.14402027406868e-07\n",
      "Epoch 3371, Loss: 0.00016223421584982134, Final Batch Loss: 1.148379215010209e-05\n",
      "Epoch 3372, Loss: 4.836780718164846e-05, Final Batch Loss: 7.650995939911809e-06\n",
      "Epoch 3373, Loss: 0.00014498573793275682, Final Batch Loss: 1.3367204019232304e-06\n",
      "Epoch 3374, Loss: 8.014090070673774e-05, Final Batch Loss: 7.14243583388452e-07\n",
      "Epoch 3375, Loss: 8.388763379230113e-05, Final Batch Loss: 1.0671107020243653e-07\n",
      "Epoch 3376, Loss: 9.498313818312454e-05, Final Batch Loss: 4.7106163947319146e-07\n",
      "Epoch 3377, Loss: 7.806559153777926e-05, Final Batch Loss: 9.019766366691329e-06\n",
      "Epoch 3378, Loss: 0.0001440472217666411, Final Batch Loss: 2.6963491109199822e-05\n",
      "Epoch 3379, Loss: 0.000869316540104137, Final Batch Loss: 1.4755578376934864e-06\n",
      "Epoch 3380, Loss: 2.4089049688313935e-05, Final Batch Loss: 1.4420432137285388e-07\n",
      "Epoch 3381, Loss: 3.659378069897912e-05, Final Batch Loss: 3.9655890304857166e-07\n",
      "Epoch 3382, Loss: 3.3354952222452994e-05, Final Batch Loss: 4.05200722752852e-07\n",
      "Epoch 3383, Loss: 0.0026505645294676583, Final Batch Loss: 4.449863808986265e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3384, Loss: 8.278144434825663e-05, Final Batch Loss: 3.134824282824411e-06\n",
      "Epoch 3385, Loss: 0.0003087839524766878, Final Batch Loss: 9.102567673835438e-06\n",
      "Epoch 3386, Loss: 0.0019671667091074596, Final Batch Loss: 2.979512373713078e-06\n",
      "Epoch 3387, Loss: 0.00042736686225453013, Final Batch Loss: 6.33223244221881e-05\n",
      "Epoch 3388, Loss: 0.0001875764256169532, Final Batch Loss: 4.03860713049653e-06\n",
      "Epoch 3389, Loss: 0.00016595907464989068, Final Batch Loss: 1.3304794492796645e-06\n",
      "Epoch 3390, Loss: 7.398874078035078e-05, Final Batch Loss: 4.114404873689637e-06\n",
      "Epoch 3391, Loss: 0.00022581987053627017, Final Batch Loss: 2.9790466214763e-05\n",
      "Epoch 3392, Loss: 0.00015559864283432034, Final Batch Loss: 1.0648175702954177e-05\n",
      "Epoch 3393, Loss: 0.0007824222104062528, Final Batch Loss: 6.908828800078481e-05\n",
      "Epoch 3394, Loss: 0.00010972776284745578, Final Batch Loss: 7.481146440113662e-06\n",
      "Epoch 3395, Loss: 0.00030248556240053404, Final Batch Loss: 5.50676450075116e-05\n",
      "Epoch 3396, Loss: 0.00016804968180395008, Final Batch Loss: 5.732444606110221e-06\n",
      "Epoch 3397, Loss: 0.00017030156138275743, Final Batch Loss: 3.917198409908451e-05\n",
      "Epoch 3398, Loss: 4.064732887343325e-05, Final Batch Loss: 1.1341760000505019e-05\n",
      "Epoch 3399, Loss: 0.00011324556237468641, Final Batch Loss: 2.5804863525991095e-06\n",
      "Epoch 3400, Loss: 0.00015495643143026427, Final Batch Loss: 1.288655312237097e-06\n",
      "Epoch 3401, Loss: 0.00022711960245658247, Final Batch Loss: 2.023646885618291e-07\n",
      "Epoch 3402, Loss: 0.00018114207947306227, Final Batch Loss: 1.879809019555978e-06\n",
      "Epoch 3403, Loss: 0.0005661678475235021, Final Batch Loss: 1.9745500594581245e-06\n",
      "Epoch 3404, Loss: 0.0005117695612000261, Final Batch Loss: 2.3767358925397275e-06\n",
      "Epoch 3405, Loss: 0.0001422895855185402, Final Batch Loss: 5.491442152560921e-06\n",
      "Epoch 3406, Loss: 0.001999786517387747, Final Batch Loss: 1.7693048448563786e-06\n",
      "Epoch 3407, Loss: 5.2268105477537574e-05, Final Batch Loss: 3.0745625281269895e-06\n",
      "Epoch 3408, Loss: 0.0015782001399884393, Final Batch Loss: 1.65580775046692e-06\n",
      "Epoch 3409, Loss: 0.00048552517606026413, Final Batch Loss: 6.870649667689577e-05\n",
      "Epoch 3410, Loss: 0.00010495812767885582, Final Batch Loss: 1.5044745396153303e-06\n",
      "Epoch 3411, Loss: 3.985432670106093e-05, Final Batch Loss: 4.1721611410139303e-07\n",
      "Epoch 3412, Loss: 6.730234284901826e-05, Final Batch Loss: 1.5808518583071418e-06\n",
      "Epoch 3413, Loss: 3.996191452415587e-05, Final Batch Loss: 1.3429399814413046e-06\n",
      "Epoch 3414, Loss: 0.00020417584104848174, Final Batch Loss: 1.1232687029405497e-06\n",
      "Epoch 3415, Loss: 0.00022612373109609507, Final Batch Loss: 1.2017017070320435e-07\n",
      "Epoch 3416, Loss: 0.00020208583717362671, Final Batch Loss: 1.32186727341832e-07\n",
      "Epoch 3417, Loss: 0.0005599200923711578, Final Batch Loss: 5.741723725805059e-06\n",
      "Epoch 3418, Loss: 4.495404003534986e-05, Final Batch Loss: 4.4895244855069905e-07\n",
      "Epoch 3419, Loss: 2.6291556224578017e-05, Final Batch Loss: 7.46009902741207e-07\n",
      "Epoch 3420, Loss: 3.3656222505840105e-05, Final Batch Loss: 1.7667481415628572e-06\n",
      "Epoch 3421, Loss: 6.52101989686571e-05, Final Batch Loss: 1.2919690561830066e-06\n",
      "Epoch 3422, Loss: 7.949236911031221e-05, Final Batch Loss: 4.162635036664142e-07\n",
      "Epoch 3423, Loss: 0.00027578745020662154, Final Batch Loss: 2.6326106308260933e-06\n",
      "Epoch 3424, Loss: 8.113854722324731e-05, Final Batch Loss: 1.133222394855693e-05\n",
      "Epoch 3425, Loss: 4.644346490589868e-05, Final Batch Loss: 1.1550284853001358e-06\n",
      "Epoch 3426, Loss: 9.314082384292988e-05, Final Batch Loss: 1.6960326547632576e-06\n",
      "Epoch 3427, Loss: 3.244202565610976e-05, Final Batch Loss: 1.3059576531304629e-06\n",
      "Epoch 3428, Loss: 6.792780104802887e-05, Final Batch Loss: 2.648551173933811e-07\n",
      "Epoch 3429, Loss: 6.671761911292151e-05, Final Batch Loss: 6.239170033950359e-07\n",
      "Epoch 3430, Loss: 1.3932151581741437e-05, Final Batch Loss: 8.353567295671382e-07\n",
      "Epoch 3431, Loss: 0.0011937007771507524, Final Batch Loss: 3.0523045779773383e-07\n",
      "Epoch 3432, Loss: 4.039489260154738e-05, Final Batch Loss: 3.028260096016311e-07\n",
      "Epoch 3433, Loss: 3.9758862779848414e-05, Final Batch Loss: 2.962565304187592e-06\n",
      "Epoch 3434, Loss: 0.0007207581346477809, Final Batch Loss: 2.7727144242817303e-06\n",
      "Epoch 3435, Loss: 9.155079110456654e-05, Final Batch Loss: 1.0766746072476963e-06\n",
      "Epoch 3436, Loss: 0.00010491267738643728, Final Batch Loss: 8.512447493558284e-07\n",
      "Epoch 3437, Loss: 0.00023454608441397795, Final Batch Loss: 7.10205586074153e-06\n",
      "Epoch 3438, Loss: 2.5586217788031718e-05, Final Batch Loss: 8.464327265755855e-07\n",
      "Epoch 3439, Loss: 0.0003197032224022678, Final Batch Loss: 5.098472684039734e-06\n",
      "Epoch 3440, Loss: 0.00027461007341145205, Final Batch Loss: 8.421118309343001e-07\n",
      "Epoch 3441, Loss: 0.0055719080058977966, Final Batch Loss: 0.005565249361097813\n",
      "Epoch 3442, Loss: 0.027437688696322127, Final Batch Loss: 8.017291293072049e-07\n",
      "Epoch 3443, Loss: 0.012876637758495235, Final Batch Loss: 6.944971391931176e-05\n",
      "Epoch 3444, Loss: 0.0005050148484713191, Final Batch Loss: 7.383163165286533e-07\n",
      "Epoch 3445, Loss: 9.831758976019955e-05, Final Batch Loss: 1.289968622586457e-05\n",
      "Epoch 3446, Loss: 0.00016801173298475192, Final Batch Loss: 1.3650436585521675e-06\n",
      "Epoch 3447, Loss: 0.002263073562872364, Final Batch Loss: 0.0018157410668209195\n",
      "Epoch 3448, Loss: 0.0004794881339194035, Final Batch Loss: 1.2914604667457752e-05\n",
      "Epoch 3449, Loss: 0.0006353538781240786, Final Batch Loss: 3.067718353122473e-05\n",
      "Epoch 3450, Loss: 0.0018752218401232312, Final Batch Loss: 1.8793988374454784e-06\n",
      "Epoch 3451, Loss: 7.643080675734382e-05, Final Batch Loss: 2.788126039376948e-06\n",
      "Epoch 3452, Loss: 0.00043621943859761814, Final Batch Loss: 5.455618747873814e-07\n",
      "Epoch 3453, Loss: 0.0004264552815271827, Final Batch Loss: 2.852583747880999e-06\n",
      "Epoch 3454, Loss: 0.00019843268270847148, Final Batch Loss: 8.104033213385264e-07\n",
      "Epoch 3455, Loss: 4.59498756413268e-05, Final Batch Loss: 4.258522494637873e-06\n",
      "Epoch 3456, Loss: 0.0016895092268214285, Final Batch Loss: 0.001439591753296554\n",
      "Epoch 3457, Loss: 0.00023252035183674025, Final Batch Loss: 7.897206728557649e-07\n",
      "Epoch 3458, Loss: 7.421175286026482e-05, Final Batch Loss: 8.08771528681973e-06\n",
      "Epoch 3459, Loss: 6.921043945595784e-05, Final Batch Loss: 1.6584403056185693e-05\n",
      "Epoch 3460, Loss: 5.1930629922480875e-05, Final Batch Loss: 1.4202830698195612e-06\n",
      "Epoch 3461, Loss: 0.0024736897141437453, Final Batch Loss: 1.5574018163988512e-07\n",
      "Epoch 3462, Loss: 0.000100184312913143, Final Batch Loss: 5.346483249013545e-06\n",
      "Epoch 3463, Loss: 6.337644273912701e-05, Final Batch Loss: 2.1616915546474047e-06\n",
      "Epoch 3464, Loss: 2.525582878121213e-05, Final Batch Loss: 3.997236490249634e-06\n",
      "Epoch 3465, Loss: 0.000718586788437392, Final Batch Loss: 3.4832326036848826e-06\n",
      "Epoch 3466, Loss: 0.00010617304628013358, Final Batch Loss: 1.0881651633098954e-06\n",
      "Epoch 3467, Loss: 0.0003018609399312311, Final Batch Loss: 3.2666275728843175e-06\n",
      "Epoch 3468, Loss: 0.002441042589907738, Final Batch Loss: 5.484511120812385e-07\n",
      "Epoch 3469, Loss: 0.0005492203353583136, Final Batch Loss: 1.216115776969673e-07\n",
      "Epoch 3470, Loss: 0.00039537226396646474, Final Batch Loss: 1.0680334980861517e-06\n",
      "Epoch 3471, Loss: 0.00015758227121409618, Final Batch Loss: 3.119608322776912e-07\n",
      "Epoch 3472, Loss: 0.000292159392273561, Final Batch Loss: 1.1055655591007962e-07\n",
      "Epoch 3473, Loss: 1.5918233430056716e-05, Final Batch Loss: 1.19389733299613e-06\n",
      "Epoch 3474, Loss: 3.350826619907821e-05, Final Batch Loss: 2.8549068247230025e-06\n",
      "Epoch 3475, Loss: 0.010975210535434599, Final Batch Loss: 0.0004893771256320179\n",
      "Epoch 3476, Loss: 0.009085132763033243, Final Batch Loss: 4.119335983432393e-07\n",
      "Epoch 3477, Loss: 0.0008236008156865537, Final Batch Loss: 2.886879656216479e-06\n",
      "Epoch 3478, Loss: 0.014463307535553582, Final Batch Loss: 8.119786798488349e-06\n",
      "Epoch 3479, Loss: 0.0032669056439544875, Final Batch Loss: 1.6927026081248187e-05\n",
      "Epoch 3480, Loss: 0.006484037305028778, Final Batch Loss: 1.174483713839436e-05\n",
      "Epoch 3481, Loss: 0.013346005506356562, Final Batch Loss: 1.0377333410360734e-06\n",
      "Epoch 3482, Loss: 0.002352198920846149, Final Batch Loss: 3.874230287692626e-07\n",
      "Epoch 3483, Loss: 0.0009460225762722985, Final Batch Loss: 1.4533294233842753e-05\n",
      "Epoch 3484, Loss: 0.0007523243129554658, Final Batch Loss: 1.2323755527177127e-06\n",
      "Epoch 3485, Loss: 0.00031911661447736606, Final Batch Loss: 1.932320543573951e-07\n",
      "Epoch 3486, Loss: 7.014254352100124e-05, Final Batch Loss: 1.1763319889723789e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3487, Loss: 0.002523001831690408, Final Batch Loss: 1.6289575341943419e-06\n",
      "Epoch 3488, Loss: 0.028435077649128004, Final Batch Loss: 1.0833909072971437e-05\n",
      "Epoch 3489, Loss: 0.0004171103159364975, Final Batch Loss: 6.303122790995985e-05\n",
      "Epoch 3490, Loss: 0.005108319660394045, Final Batch Loss: 9.413401130586863e-06\n",
      "Epoch 3491, Loss: 0.0002834842494792156, Final Batch Loss: 1.4991478565207217e-06\n",
      "Epoch 3492, Loss: 0.06016392058995734, Final Batch Loss: 2.6726547730504535e-05\n",
      "Epoch 3493, Loss: 0.025697612721160112, Final Batch Loss: 9.844507439993322e-05\n",
      "Epoch 3494, Loss: 0.0002845106156392774, Final Batch Loss: 0.00013787268835585564\n",
      "Epoch 3495, Loss: 0.013573854617611403, Final Batch Loss: 0.00033891317434608936\n",
      "Epoch 3496, Loss: 0.0055188967456842875, Final Batch Loss: 0.003805294167250395\n",
      "Epoch 3497, Loss: 0.0006719500175620396, Final Batch Loss: 1.871078711701557e-05\n",
      "Epoch 3498, Loss: 0.0003674670336977215, Final Batch Loss: 1.6548694929952035e-06\n",
      "Epoch 3499, Loss: 0.0006491481968851076, Final Batch Loss: 5.911810603720369e-06\n",
      "Epoch 3500, Loss: 0.0001126985160908589, Final Batch Loss: 2.9740276659140363e-05\n",
      "Epoch 3501, Loss: 0.0006958518149389192, Final Batch Loss: 2.1552245925704483e-06\n",
      "Epoch 3502, Loss: 0.00030493589525804055, Final Batch Loss: 1.2358059393591247e-05\n",
      "Epoch 3503, Loss: 0.0007268960135888847, Final Batch Loss: 5.374493412091397e-06\n",
      "Epoch 3504, Loss: 0.0014280548957685824, Final Batch Loss: 2.7511280222825008e-06\n",
      "Epoch 3505, Loss: 0.0004396482286210812, Final Batch Loss: 3.6328194710222306e-06\n",
      "Epoch 3506, Loss: 0.0006508498827635378, Final Batch Loss: 9.060251500159211e-07\n",
      "Epoch 3507, Loss: 6.347240250192954e-05, Final Batch Loss: 5.239328970674251e-07\n",
      "Epoch 3508, Loss: 0.00022271648181515502, Final Batch Loss: 5.854850769537734e-06\n",
      "Epoch 3509, Loss: 0.00011499968132966387, Final Batch Loss: 2.2615799025516026e-05\n",
      "Epoch 3510, Loss: 2.8436583683344452e-05, Final Batch Loss: 1.0050864602817455e-06\n",
      "Epoch 3511, Loss: 5.2318270718387794e-05, Final Batch Loss: 6.162215413496597e-07\n",
      "Epoch 3512, Loss: 0.00012765163103267696, Final Batch Loss: 9.685157237981912e-06\n",
      "Epoch 3513, Loss: 0.01959450019472797, Final Batch Loss: 5.131495072419057e-06\n",
      "Epoch 3514, Loss: 0.004367312540352941, Final Batch Loss: 3.5187499634048436e-06\n",
      "Epoch 3515, Loss: 0.0002945393319748746, Final Batch Loss: 4.603950856107986e-06\n",
      "Epoch 3516, Loss: 0.0003749527095280314, Final Batch Loss: 1.9005306057806592e-06\n",
      "Epoch 3517, Loss: 0.00040720473666056023, Final Batch Loss: 5.649325885315193e-06\n",
      "Epoch 3518, Loss: 0.0024282087205165226, Final Batch Loss: 7.286690788532724e-07\n",
      "Epoch 3519, Loss: 0.0001943476590042792, Final Batch Loss: 2.374553673689661e-07\n",
      "Epoch 3520, Loss: 0.00011645266420146072, Final Batch Loss: 3.164110921716201e-06\n",
      "Epoch 3521, Loss: 0.001176053897154361, Final Batch Loss: 2.504429176042322e-06\n",
      "Epoch 3522, Loss: 0.0037876407004659995, Final Batch Loss: 5.248963930171158e-07\n",
      "Epoch 3523, Loss: 0.00028970807335326754, Final Batch Loss: 7.66382163419621e-06\n",
      "Epoch 3524, Loss: 0.002559639626497301, Final Batch Loss: 3.064514885409153e-06\n",
      "Epoch 3525, Loss: 0.00019129679873230998, Final Batch Loss: 6.426494564948371e-06\n",
      "Epoch 3526, Loss: 0.00018588015450404782, Final Batch Loss: 4.659667411033297e-06\n",
      "Epoch 3527, Loss: 0.0002737324045938294, Final Batch Loss: 1.746632960930583e-06\n",
      "Epoch 3528, Loss: 0.0003982807658076126, Final Batch Loss: 0.0001456959143979475\n",
      "Epoch 3529, Loss: 7.875780323729487e-05, Final Batch Loss: 1.4112123380982666e-06\n",
      "Epoch 3530, Loss: 0.0001634991654100304, Final Batch Loss: 5.120779860590119e-06\n",
      "Epoch 3531, Loss: 5.5675103226349165e-05, Final Batch Loss: 7.910141903266776e-06\n",
      "Epoch 3532, Loss: 0.0001380947013558398, Final Batch Loss: 2.1945161279290915e-05\n",
      "Epoch 3533, Loss: 0.0001037761754218991, Final Batch Loss: 1.4064453353057615e-05\n",
      "Epoch 3534, Loss: 0.0002943506181054545, Final Batch Loss: 3.595552470869734e-06\n",
      "Epoch 3535, Loss: 0.001238750905741881, Final Batch Loss: 3.0182316095306305e-06\n",
      "Epoch 3536, Loss: 5.907181611064516e-05, Final Batch Loss: 1.14398983441788e-06\n",
      "Epoch 3537, Loss: 0.0001007293230088635, Final Batch Loss: 4.265044935891638e-06\n",
      "Epoch 3538, Loss: 0.00016757765339292519, Final Batch Loss: 1.2515912430899334e-06\n",
      "Epoch 3539, Loss: 5.1744748390092354e-05, Final Batch Loss: 8.176043593266513e-06\n",
      "Epoch 3540, Loss: 0.0006403513069983546, Final Batch Loss: 6.147579938442504e-07\n",
      "Epoch 3541, Loss: 5.8363336421507483e-05, Final Batch Loss: 3.370820195414126e-05\n",
      "Epoch 3542, Loss: 0.00012051539822266477, Final Batch Loss: 1.0646174359862925e-06\n",
      "Epoch 3543, Loss: 0.00011987321835249531, Final Batch Loss: 4.6483895857818425e-05\n",
      "Epoch 3544, Loss: 0.00012005349601196258, Final Batch Loss: 6.576733994734241e-06\n",
      "Epoch 3545, Loss: 8.575736264049283e-05, Final Batch Loss: 4.8795773182064295e-06\n",
      "Epoch 3546, Loss: 6.456380973673959e-05, Final Batch Loss: 2.1797347926622024e-06\n",
      "Epoch 3547, Loss: 0.0021595722543992224, Final Batch Loss: 2.367783508816501e-06\n",
      "Epoch 3548, Loss: 0.008355436165004448, Final Batch Loss: 1.2660685797527549e-06\n",
      "Epoch 3549, Loss: 9.129640064742262e-05, Final Batch Loss: 2.6435798645252362e-05\n",
      "Epoch 3550, Loss: 0.008684276782140898, Final Batch Loss: 5.7893494158633985e-06\n",
      "Epoch 3551, Loss: 0.004205813710257189, Final Batch Loss: 1.1815981451945845e-05\n",
      "Epoch 3552, Loss: 0.036242833739635216, Final Batch Loss: 4.436530218754342e-07\n",
      "Epoch 3553, Loss: 0.00015585734684009367, Final Batch Loss: 2.561364453868009e-06\n",
      "Epoch 3554, Loss: 0.0003304422523697781, Final Batch Loss: 7.774527148285415e-06\n",
      "Epoch 3555, Loss: 0.0005963325996276581, Final Batch Loss: 4.0424868075206177e-07\n",
      "Epoch 3556, Loss: 0.04138409849326763, Final Batch Loss: 1.2237957207617e-06\n",
      "Epoch 3557, Loss: 0.003916328670072744, Final Batch Loss: 6.777346698072506e-06\n",
      "Epoch 3558, Loss: 0.01021799287855174, Final Batch Loss: 0.0009660770301707089\n",
      "Epoch 3559, Loss: 0.005470016136314371, Final Batch Loss: 5.6282310652022716e-06\n",
      "Epoch 3560, Loss: 0.0001160026417892368, Final Batch Loss: 3.876326809404418e-05\n",
      "Epoch 3561, Loss: 0.00030641729460967326, Final Batch Loss: 6.185093297972344e-06\n",
      "Epoch 3562, Loss: 0.0004555034498707755, Final Batch Loss: 9.687960118753836e-05\n",
      "Epoch 3563, Loss: 0.009384683514383596, Final Batch Loss: 3.4849342682718998e-06\n",
      "Epoch 3564, Loss: 0.00033583919275770313, Final Batch Loss: 1.4513084352074657e-05\n",
      "Epoch 3565, Loss: 0.00552598706963181, Final Batch Loss: 1.0893587386817671e-05\n",
      "Epoch 3566, Loss: 0.00024059334327830584, Final Batch Loss: 8.037995030463208e-06\n",
      "Epoch 3567, Loss: 0.0008922577139856003, Final Batch Loss: 6.178165494929999e-05\n",
      "Epoch 3568, Loss: 0.0012807790942588326, Final Batch Loss: 0.0011687834048643708\n",
      "Epoch 3569, Loss: 0.0002152844039073898, Final Batch Loss: 1.8359836531089968e-06\n",
      "Epoch 3570, Loss: 0.00016009487308110693, Final Batch Loss: 6.482182925537927e-06\n",
      "Epoch 3571, Loss: 0.0017039960347347005, Final Batch Loss: 1.1649413863779046e-05\n",
      "Epoch 3572, Loss: 0.00011846485045907684, Final Batch Loss: 5.503792635863647e-06\n",
      "Epoch 3573, Loss: 0.0001709983874889076, Final Batch Loss: 5.0106350499845576e-06\n",
      "Epoch 3574, Loss: 0.0002127672097458344, Final Batch Loss: 1.475078988733003e-05\n",
      "Epoch 3575, Loss: 0.0004320466080116603, Final Batch Loss: 2.7471244266052963e-06\n",
      "Epoch 3576, Loss: 0.000305013885167682, Final Batch Loss: 1.7061609014490386e-06\n",
      "Epoch 3577, Loss: 0.00013189897163101705, Final Batch Loss: 2.087379925796995e-06\n",
      "Epoch 3578, Loss: 0.00031874269188847393, Final Batch Loss: 0.00019930797861889005\n",
      "Epoch 3579, Loss: 0.0005904130367753169, Final Batch Loss: 2.7437279186415253e-06\n",
      "Epoch 3580, Loss: 0.00024594083481588314, Final Batch Loss: 1.788936060620472e-05\n",
      "Epoch 3581, Loss: 8.486596837542493e-05, Final Batch Loss: 1.416244231222663e-05\n",
      "Epoch 3582, Loss: 0.0032497438905352283, Final Batch Loss: 3.0265116492955713e-06\n",
      "Epoch 3583, Loss: 0.00011257902123418262, Final Batch Loss: 2.095559011650039e-06\n",
      "Epoch 3584, Loss: 0.022623288056337287, Final Batch Loss: 1.214173494190618e-06\n",
      "Epoch 3585, Loss: 0.0011739505584955623, Final Batch Loss: 4.507920493779238e-06\n",
      "Epoch 3586, Loss: 0.0001743153421784882, Final Batch Loss: 6.129933899501339e-05\n",
      "Epoch 3587, Loss: 0.003334044730820551, Final Batch Loss: 3.0625960789620876e-05\n",
      "Epoch 3588, Loss: 0.0005261332183295053, Final Batch Loss: 4.313409135647817e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3589, Loss: 0.0002585696532264592, Final Batch Loss: 1.287702161789639e-06\n",
      "Epoch 3590, Loss: 0.0002814582198595872, Final Batch Loss: 2.0225106709403917e-06\n",
      "Epoch 3591, Loss: 0.0005478692240785676, Final Batch Loss: 0.0002932120696641505\n",
      "Epoch 3592, Loss: 0.00017009998083494793, Final Batch Loss: 1.2191476344014518e-05\n",
      "Epoch 3593, Loss: 0.004531510394201632, Final Batch Loss: 0.00011541259300429374\n",
      "Epoch 3594, Loss: 0.0014999126254906514, Final Batch Loss: 0.0010628923773765564\n",
      "Epoch 3595, Loss: 0.004658267574086494, Final Batch Loss: 0.00015518600412178785\n",
      "Epoch 3596, Loss: 0.0011551040529980128, Final Batch Loss: 1.719237661745865e-05\n",
      "Epoch 3597, Loss: 0.00011490634483379836, Final Batch Loss: 1.9869034076691605e-05\n",
      "Epoch 3598, Loss: 0.00020891582119020313, Final Batch Loss: 1.281760251004016e-05\n",
      "Epoch 3599, Loss: 0.00018795555020290067, Final Batch Loss: 1.2098525985493325e-05\n",
      "Epoch 3600, Loss: 0.000780297250997819, Final Batch Loss: 9.719069566926919e-07\n",
      "Epoch 3601, Loss: 0.0004875830317701002, Final Batch Loss: 5.896633865631884e-06\n",
      "Epoch 3602, Loss: 0.0006611108512686314, Final Batch Loss: 6.162123327158042e-07\n",
      "Epoch 3603, Loss: 7.536089913173782e-05, Final Batch Loss: 6.123829052739893e-07\n",
      "Epoch 3604, Loss: 0.00028625931511783165, Final Batch Loss: 9.688058526080567e-06\n",
      "Epoch 3605, Loss: 0.00012428138941089628, Final Batch Loss: 9.747770945978118e-07\n",
      "Epoch 3606, Loss: 0.0001057998527755899, Final Batch Loss: 1.0683350410545245e-05\n",
      "Epoch 3607, Loss: 0.00019429573393736632, Final Batch Loss: 1.4181630831444636e-05\n",
      "Epoch 3608, Loss: 0.0004546183491598299, Final Batch Loss: 5.2541770855896175e-05\n",
      "Epoch 3609, Loss: 0.00010262983028042072, Final Batch Loss: 3.0929372769605834e-06\n",
      "Epoch 3610, Loss: 0.00014011050772921863, Final Batch Loss: 8.844170906741056e-07\n",
      "Epoch 3611, Loss: 0.0010475354999357478, Final Batch Loss: 1.6880549082998186e-06\n",
      "Epoch 3612, Loss: 0.0002942643910941456, Final Batch Loss: 4.181748408882413e-06\n",
      "Epoch 3613, Loss: 4.525770114582883e-05, Final Batch Loss: 7.541718787251739e-07\n",
      "Epoch 3614, Loss: 3.8569762828899457e-05, Final Batch Loss: 2.769803131741355e-06\n",
      "Epoch 3615, Loss: 0.0012618660676508853, Final Batch Loss: 1.6508759017597185e-06\n",
      "Epoch 3616, Loss: 0.00015782572661748873, Final Batch Loss: 1.4713355085405055e-05\n",
      "Epoch 3617, Loss: 0.00022870791599416407, Final Batch Loss: 9.166417953565542e-07\n",
      "Epoch 3618, Loss: 0.0006963320242334703, Final Batch Loss: 5.146557214175118e-06\n",
      "Epoch 3619, Loss: 5.700883485815211e-05, Final Batch Loss: 4.555678060569335e-06\n",
      "Epoch 3620, Loss: 3.769191442160036e-05, Final Batch Loss: 7.594760376150589e-08\n",
      "Epoch 3621, Loss: 7.859138753474326e-05, Final Batch Loss: 1.2884618627140298e-05\n",
      "Epoch 3622, Loss: 0.0020564180119180264, Final Batch Loss: 0.0018793853232637048\n",
      "Epoch 3623, Loss: 0.0003863388587888039, Final Batch Loss: 4.259123215888394e-06\n",
      "Epoch 3624, Loss: 0.019552984279584962, Final Batch Loss: 1.0161320460611023e-06\n",
      "Epoch 3625, Loss: 0.00014878250161487472, Final Batch Loss: 6.330406563392899e-07\n",
      "Epoch 3626, Loss: 0.0003877529359144205, Final Batch Loss: 3.009052704783244e-07\n",
      "Epoch 3627, Loss: 0.0016633256955458364, Final Batch Loss: 9.122936717176344e-07\n",
      "Epoch 3628, Loss: 7.105811757668334e-05, Final Batch Loss: 1.0992470151904854e-06\n",
      "Epoch 3629, Loss: 9.893097995927747e-05, Final Batch Loss: 8.931723641580902e-06\n",
      "Epoch 3630, Loss: 0.005463980553770398, Final Batch Loss: 1.3607392475023516e-06\n",
      "Epoch 3631, Loss: 0.0007984615398299866, Final Batch Loss: 1.0348454452469014e-05\n",
      "Epoch 3632, Loss: 0.0009475816184192354, Final Batch Loss: 3.992441179434536e-06\n",
      "Epoch 3633, Loss: 0.000150848349889543, Final Batch Loss: 3.221248334739357e-05\n",
      "Epoch 3634, Loss: 0.0004988608056919475, Final Batch Loss: 1.961952420970192e-06\n",
      "Epoch 3635, Loss: 0.0002409077854821362, Final Batch Loss: 2.4069470327958697e-06\n",
      "Epoch 3636, Loss: 0.00046142350275601984, Final Batch Loss: 8.978791470326541e-07\n",
      "Epoch 3637, Loss: 6.130761919109773e-05, Final Batch Loss: 4.477765742194606e-06\n",
      "Epoch 3638, Loss: 7.625841681146994e-05, Final Batch Loss: 9.076305104827043e-06\n",
      "Epoch 3639, Loss: 0.0002738469273140254, Final Batch Loss: 7.241833372972906e-05\n",
      "Epoch 3640, Loss: 0.003116529383703437, Final Batch Loss: 0.0030842553824186325\n",
      "Epoch 3641, Loss: 0.0001713935344866968, Final Batch Loss: 3.6502283364825416e-06\n",
      "Epoch 3642, Loss: 0.00010587208174683838, Final Batch Loss: 2.6748266463982873e-06\n",
      "Epoch 3643, Loss: 0.02082183036236529, Final Batch Loss: 0.0009873475646600127\n",
      "Epoch 3644, Loss: 0.0021128504275793603, Final Batch Loss: 0.0002482160343788564\n",
      "Epoch 3645, Loss: 0.0013415381102674928, Final Batch Loss: 6.574345661647385e-06\n",
      "Epoch 3646, Loss: 7.639432075734476e-05, Final Batch Loss: 9.171142778541252e-07\n",
      "Epoch 3647, Loss: 5.858059208208033e-05, Final Batch Loss: 5.085537395643769e-07\n",
      "Epoch 3648, Loss: 0.0001278921438654379, Final Batch Loss: 2.486348785168957e-05\n",
      "Epoch 3649, Loss: 4.863531702881119e-05, Final Batch Loss: 2.927329774138343e-07\n",
      "Epoch 3650, Loss: 4.989952458345215e-05, Final Batch Loss: 2.1947957975498866e-06\n",
      "Epoch 3651, Loss: 0.00025880758012419847, Final Batch Loss: 2.698748858165345e-06\n",
      "Epoch 3652, Loss: 0.006029549573725035, Final Batch Loss: 5.009268988942495e-06\n",
      "Epoch 3653, Loss: 0.0003738744770203084, Final Batch Loss: 7.502821972593665e-05\n",
      "Epoch 3654, Loss: 6.198142170887877e-05, Final Batch Loss: 5.799564405606361e-06\n",
      "Epoch 3655, Loss: 0.00012146977780957968, Final Batch Loss: 2.8308973924140446e-05\n",
      "Epoch 3656, Loss: 5.384355965531995e-05, Final Batch Loss: 6.263021532504354e-07\n",
      "Epoch 3657, Loss: 0.0005397547856986762, Final Batch Loss: 3.3857547805382637e-06\n",
      "Epoch 3658, Loss: 0.018262663647746535, Final Batch Loss: 4.883493602392264e-06\n",
      "Epoch 3659, Loss: 0.006653354517453636, Final Batch Loss: 4.914455075777369e-06\n",
      "Epoch 3660, Loss: 0.0010186696563323494, Final Batch Loss: 1.3122948985255789e-05\n",
      "Epoch 3661, Loss: 0.0007918869642367099, Final Batch Loss: 5.846339990966953e-05\n",
      "Epoch 3662, Loss: 0.0003068166111006576, Final Batch Loss: 5.40325345355086e-06\n",
      "Epoch 3663, Loss: 0.0001356846397584377, Final Batch Loss: 2.590205667729606e-06\n",
      "Epoch 3664, Loss: 0.0002644397243329877, Final Batch Loss: 1.576081103848992e-06\n",
      "Epoch 3665, Loss: 0.0010464572873871703, Final Batch Loss: 9.546509318170138e-06\n",
      "Epoch 3666, Loss: 0.002200598531203468, Final Batch Loss: 0.0014962919522076845\n",
      "Epoch 3667, Loss: 7.927619543579567e-05, Final Batch Loss: 1.881601860986848e-06\n",
      "Epoch 3668, Loss: 0.00015580661492720083, Final Batch Loss: 1.782764570634754e-06\n",
      "Epoch 3669, Loss: 0.00013585279467065448, Final Batch Loss: 2.5036490569618763e-06\n",
      "Epoch 3670, Loss: 0.00027470418369546223, Final Batch Loss: 1.1392158683065645e-07\n",
      "Epoch 3671, Loss: 0.00014694738287346354, Final Batch Loss: 2.0314042558311485e-05\n",
      "Epoch 3672, Loss: 4.50459872993747e-05, Final Batch Loss: 4.070324848726159e-06\n",
      "Epoch 3673, Loss: 0.0001911378260786023, Final Batch Loss: 0.00011280395847279578\n",
      "Epoch 3674, Loss: 4.131739925128386e-05, Final Batch Loss: 3.1265740290109534e-06\n",
      "Epoch 3675, Loss: 0.0001921566537248509, Final Batch Loss: 7.136861677281559e-05\n",
      "Epoch 3676, Loss: 0.0011470180672858987, Final Batch Loss: 0.0001428589748684317\n",
      "Epoch 3677, Loss: 0.011002466597972216, Final Batch Loss: 3.263805012920784e-07\n",
      "Epoch 3678, Loss: 0.00010963705727817796, Final Batch Loss: 2.4579735509178136e-06\n",
      "Epoch 3679, Loss: 7.117337833051351e-05, Final Batch Loss: 8.253106216216111e-07\n",
      "Epoch 3680, Loss: 6.286817290401814e-05, Final Batch Loss: 2.8833660508098546e-06\n",
      "Epoch 3681, Loss: 8.72238558429217e-05, Final Batch Loss: 1.5193169247140759e-06\n",
      "Epoch 3682, Loss: 5.4323204622619414e-05, Final Batch Loss: 6.888027996865276e-07\n",
      "Epoch 3683, Loss: 0.0002680341798537711, Final Batch Loss: 5.782374046248151e-07\n",
      "Epoch 3684, Loss: 0.00040693522879564625, Final Batch Loss: 2.941723948879371e-07\n",
      "Epoch 3685, Loss: 0.00030718571157706265, Final Batch Loss: 1.0761651765278657e-06\n",
      "Epoch 3686, Loss: 0.00020585205449208388, Final Batch Loss: 1.1713590311046573e-06\n",
      "Epoch 3687, Loss: 7.14059884217022e-05, Final Batch Loss: 2.0468587536015548e-06\n",
      "Epoch 3688, Loss: 0.00037678344435221334, Final Batch Loss: 1.0334117632737616e-06\n",
      "Epoch 3689, Loss: 0.0003327769192900121, Final Batch Loss: 7.199172614491545e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3690, Loss: 0.000143781723593861, Final Batch Loss: 1.9659830741147744e-07\n",
      "Epoch 3691, Loss: 2.9208223622845253e-05, Final Batch Loss: 3.864589643853833e-07\n",
      "Epoch 3692, Loss: 0.00015820398662214075, Final Batch Loss: 5.066197559244756e-07\n",
      "Epoch 3693, Loss: 0.00014011408015335292, Final Batch Loss: 8.683734449732583e-06\n",
      "Epoch 3694, Loss: 3.758310170276502e-05, Final Batch Loss: 1.139214447221093e-07\n",
      "Epoch 3695, Loss: 3.9879112136986805e-05, Final Batch Loss: 4.167414999756147e-07\n",
      "Epoch 3696, Loss: 0.0003522363129917494, Final Batch Loss: 1.369346932733606e-06\n",
      "Epoch 3697, Loss: 0.0011357350083258666, Final Batch Loss: 5.710427330996026e-07\n",
      "Epoch 3698, Loss: 5.8791719709461177e-05, Final Batch Loss: 4.811523695025244e-07\n",
      "Epoch 3699, Loss: 0.0005174765369559964, Final Batch Loss: 3.463781695245416e-06\n",
      "Epoch 3700, Loss: 2.397002637621881e-05, Final Batch Loss: 2.88888401200893e-07\n",
      "Epoch 3701, Loss: 0.0001196732634127784, Final Batch Loss: 1.2629932825802825e-05\n",
      "Epoch 3702, Loss: 4.350816695364301e-05, Final Batch Loss: 1.4136127219899208e-06\n",
      "Epoch 3703, Loss: 9.248391325655803e-05, Final Batch Loss: 5.618890668301901e-07\n",
      "Epoch 3704, Loss: 9.400743076781737e-05, Final Batch Loss: 2.6581008683024265e-07\n",
      "Epoch 3705, Loss: 6.561260726911655e-05, Final Batch Loss: 2.550703356973827e-06\n",
      "Epoch 3706, Loss: 0.00022850420219100442, Final Batch Loss: 0.00017923525592777878\n",
      "Epoch 3707, Loss: 0.00036248644651948325, Final Batch Loss: 0.000112181092845276\n",
      "Epoch 3708, Loss: 4.592859433216745e-05, Final Batch Loss: 5.230764145380817e-06\n",
      "Epoch 3709, Loss: 4.2201764500759964e-05, Final Batch Loss: 2.097172364301514e-05\n",
      "Epoch 3710, Loss: 0.054357392076482824, Final Batch Loss: 0.05430102348327637\n",
      "Epoch 3711, Loss: 0.000110351103415951, Final Batch Loss: 5.222587060416117e-05\n",
      "Epoch 3712, Loss: 0.0002108304020111973, Final Batch Loss: 9.46548334468389e-06\n",
      "Epoch 3713, Loss: 0.0003437146809801561, Final Batch Loss: 1.559225552227872e-06\n",
      "Epoch 3714, Loss: 0.00013956142441884367, Final Batch Loss: 3.237739656469785e-05\n",
      "Epoch 3715, Loss: 0.00035680368426938003, Final Batch Loss: 1.4463140587395173e-06\n",
      "Epoch 3716, Loss: 0.013995140007843077, Final Batch Loss: 2.2271208308666246e-06\n",
      "Epoch 3717, Loss: 0.0003513253410858397, Final Batch Loss: 2.9176996463320393e-07\n",
      "Epoch 3718, Loss: 0.0028800278572287397, Final Batch Loss: 3.047506709208392e-07\n",
      "Epoch 3719, Loss: 0.0021201294055117614, Final Batch Loss: 5.700750307369162e-07\n",
      "Epoch 3720, Loss: 0.001136691409328705, Final Batch Loss: 2.634363954712171e-05\n",
      "Epoch 3721, Loss: 0.000865555767177284, Final Batch Loss: 2.710986564125051e-07\n",
      "Epoch 3722, Loss: 0.0007100720194159749, Final Batch Loss: 1.1805212807303178e-06\n",
      "Epoch 3723, Loss: 8.871962268131028e-05, Final Batch Loss: 1.4484888197330292e-05\n",
      "Epoch 3724, Loss: 0.0002180642155735768, Final Batch Loss: 1.458332462789258e-06\n",
      "Epoch 3725, Loss: 0.00014222774962036056, Final Batch Loss: 3.23235349242168e-06\n",
      "Epoch 3726, Loss: 0.0001622527749418623, Final Batch Loss: 3.6574135720002232e-06\n",
      "Epoch 3727, Loss: 0.00021432221706163546, Final Batch Loss: 1.1333884231135016e-06\n",
      "Epoch 3728, Loss: 6.957204465152245e-05, Final Batch Loss: 3.5906626294490707e-07\n",
      "Epoch 3729, Loss: 0.0004793674568759343, Final Batch Loss: 9.420572837370855e-07\n",
      "Epoch 3730, Loss: 4.0090161860462104e-05, Final Batch Loss: 1.6014041648304556e-06\n",
      "Epoch 3731, Loss: 0.0003075038545858888, Final Batch Loss: 4.5392673200694844e-05\n",
      "Epoch 3732, Loss: 0.005727979507426539, Final Batch Loss: 2.6473469461052446e-06\n",
      "Epoch 3733, Loss: 0.0012776235334968078, Final Batch Loss: 0.00031389802461490035\n",
      "Epoch 3734, Loss: 0.00037256282683983954, Final Batch Loss: 1.8359263776801527e-05\n",
      "Epoch 3735, Loss: 0.00014871314465381147, Final Batch Loss: 1.9449033061391674e-05\n",
      "Epoch 3736, Loss: 0.00012669611328419705, Final Batch Loss: 1.053566847986076e-05\n",
      "Epoch 3737, Loss: 0.00010704505054093261, Final Batch Loss: 6.368924800881359e-07\n",
      "Epoch 3738, Loss: 0.0006223960822353547, Final Batch Loss: 6.242990366445156e-06\n",
      "Epoch 3739, Loss: 9.460214522505339e-05, Final Batch Loss: 4.5952879190735985e-07\n",
      "Epoch 3740, Loss: 9.927368904527611e-05, Final Batch Loss: 1.0041027280749404e-06\n",
      "Epoch 3741, Loss: 7.40289113707604e-05, Final Batch Loss: 4.262756647221977e-06\n",
      "Epoch 3742, Loss: 0.011000376090009922, Final Batch Loss: 0.00019313859229441732\n",
      "Epoch 3743, Loss: 0.0005497079800989013, Final Batch Loss: 0.00011682795593515038\n",
      "Epoch 3744, Loss: 0.0004042024588670756, Final Batch Loss: 1.5131022337300237e-05\n",
      "Epoch 3745, Loss: 0.02630136670746097, Final Batch Loss: 7.908916813903488e-06\n",
      "Epoch 3746, Loss: 0.022838367677422866, Final Batch Loss: 1.3000956187170232e-06\n",
      "Epoch 3747, Loss: 0.0007867980771152361, Final Batch Loss: 0.00015288882423192263\n",
      "Epoch 3748, Loss: 0.0016727069146327267, Final Batch Loss: 0.0011582686565816402\n",
      "Epoch 3749, Loss: 0.0014639744047144632, Final Batch Loss: 1.7024893168127164e-05\n",
      "Epoch 3750, Loss: 0.0014349068037944335, Final Batch Loss: 1.3881167433282826e-06\n",
      "Epoch 3751, Loss: 0.0003569794418467609, Final Batch Loss: 7.253351554936671e-07\n",
      "Epoch 3752, Loss: 0.00019193932689631765, Final Batch Loss: 0.00010093753371620551\n",
      "Epoch 3753, Loss: 0.0017200757543491818, Final Batch Loss: 7.145382824091939e-06\n",
      "Epoch 3754, Loss: 0.00019659862084608903, Final Batch Loss: 2.75456204690272e-06\n",
      "Epoch 3755, Loss: 0.0013327778381722055, Final Batch Loss: 3.682472424770822e-06\n",
      "Epoch 3756, Loss: 0.0003846314642288462, Final Batch Loss: 2.989828828958707e-07\n",
      "Epoch 3757, Loss: 6.087720444725164e-05, Final Batch Loss: 7.545808330178261e-06\n",
      "Epoch 3758, Loss: 0.00014485098932937035, Final Batch Loss: 2.642456365720136e-06\n",
      "Epoch 3759, Loss: 0.00026316282912652866, Final Batch Loss: 6.123668754298706e-07\n",
      "Epoch 3760, Loss: 8.153909578823004e-05, Final Batch Loss: 1.5773611039548996e-06\n",
      "Epoch 3761, Loss: 0.0004317756983880372, Final Batch Loss: 3.5608120469987625e-06\n",
      "Epoch 3762, Loss: 9.959090280631244e-05, Final Batch Loss: 3.976470907218754e-06\n",
      "Epoch 3763, Loss: 0.0006581980069313431, Final Batch Loss: 3.281988392700441e-05\n",
      "Epoch 3764, Loss: 0.00015940567749339607, Final Batch Loss: 2.600474715563905e-07\n",
      "Epoch 3765, Loss: 0.0015451987880510387, Final Batch Loss: 2.6461080778972246e-05\n",
      "Epoch 3766, Loss: 0.008428953223756253, Final Batch Loss: 0.00031787302577868104\n",
      "Epoch 3767, Loss: 0.004522313732650218, Final Batch Loss: 2.159486257369281e-06\n",
      "Epoch 3768, Loss: 7.887803816686301e-05, Final Batch Loss: 1.3784519069304224e-05\n",
      "Epoch 3769, Loss: 0.000727345830938475, Final Batch Loss: 6.794141427235445e-06\n",
      "Epoch 3770, Loss: 0.011013004814103056, Final Batch Loss: 2.117649955835077e-06\n",
      "Epoch 3771, Loss: 0.009863334986249583, Final Batch Loss: 1.5379950127680786e-05\n",
      "Epoch 3772, Loss: 0.0003667358576535662, Final Batch Loss: 6.65257402943098e-06\n",
      "Epoch 3773, Loss: 0.00112833534501533, Final Batch Loss: 2.0018595023429953e-05\n",
      "Epoch 3774, Loss: 0.00039943869197500703, Final Batch Loss: 2.8653332719841274e-06\n",
      "Epoch 3775, Loss: 9.965373311615622e-05, Final Batch Loss: 3.7850113585591316e-06\n",
      "Epoch 3776, Loss: 8.597275501642798e-05, Final Batch Loss: 1.5543500921921805e-05\n",
      "Epoch 3777, Loss: 0.0034518982300824064, Final Batch Loss: 6.289451266638935e-05\n",
      "Epoch 3778, Loss: 0.018557815255917376, Final Batch Loss: 6.032454393789521e-07\n",
      "Epoch 3779, Loss: 7.229504427286315e-05, Final Batch Loss: 1.365132646924394e-07\n",
      "Epoch 3780, Loss: 0.012561454872496824, Final Batch Loss: 2.766075112958788e-06\n",
      "Epoch 3781, Loss: 0.001383988226848487, Final Batch Loss: 4.655661541619338e-06\n",
      "Epoch 3782, Loss: 0.0029504548000431896, Final Batch Loss: 3.203201686119428e-06\n",
      "Epoch 3783, Loss: 0.00020232362356864542, Final Batch Loss: 3.6000208183395443e-06\n",
      "Epoch 3784, Loss: 0.00029843304801602244, Final Batch Loss: 3.6368372093420476e-05\n",
      "Epoch 3785, Loss: 0.00020754614314455466, Final Batch Loss: 9.146230695478152e-06\n",
      "Epoch 3786, Loss: 0.0001619544631239478, Final Batch Loss: 2.1984640170558123e-06\n",
      "Epoch 3787, Loss: 0.00022742199472247648, Final Batch Loss: 1.9804024020686484e-07\n",
      "Epoch 3788, Loss: 0.001112471034190321, Final Batch Loss: 5.787337045148888e-07\n",
      "Epoch 3789, Loss: 0.00016620147457047096, Final Batch Loss: 2.640994807734387e-06\n",
      "Epoch 3790, Loss: 0.00014886360600030457, Final Batch Loss: 8.924108442442957e-06\n",
      "Epoch 3791, Loss: 8.009666191810538e-05, Final Batch Loss: 3.0324351882882183e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3792, Loss: 0.0006489706147476682, Final Batch Loss: 6.265222509682644e-06\n",
      "Epoch 3793, Loss: 9.299536384332896e-05, Final Batch Loss: 3.6866781556454953e-06\n",
      "Epoch 3794, Loss: 9.527503902972967e-05, Final Batch Loss: 5.177866569283651e-06\n",
      "Epoch 3795, Loss: 0.000200514854782341, Final Batch Loss: 7.572279173473362e-06\n",
      "Epoch 3796, Loss: 0.00022395308107547862, Final Batch Loss: 1.4019294667377835e-06\n",
      "Epoch 3797, Loss: 0.0001137386460925427, Final Batch Loss: 2.804059022309957e-06\n",
      "Epoch 3798, Loss: 0.00010698063076119979, Final Batch Loss: 2.5200283744197804e-06\n",
      "Epoch 3799, Loss: 0.0015539368068218096, Final Batch Loss: 1.486592054789071e-06\n",
      "Epoch 3800, Loss: 0.00016091963550479704, Final Batch Loss: 7.348493909375975e-06\n",
      "Epoch 3801, Loss: 0.00011970814728101686, Final Batch Loss: 1.2799830983567517e-05\n",
      "Epoch 3802, Loss: 0.0071313484463360055, Final Batch Loss: 2.638928435771959e-07\n",
      "Epoch 3803, Loss: 0.00022157984747650517, Final Batch Loss: 1.7024372027663048e-06\n",
      "Epoch 3804, Loss: 8.659952288780914e-05, Final Batch Loss: 2.4090850274660625e-06\n",
      "Epoch 3805, Loss: 9.751613481512322e-05, Final Batch Loss: 8.706270818947814e-06\n",
      "Epoch 3806, Loss: 0.00021376686981966486, Final Batch Loss: 1.5260196960298344e-05\n",
      "Epoch 3807, Loss: 0.00017217098906030515, Final Batch Loss: 1.2808346582460217e-05\n",
      "Epoch 3808, Loss: 0.0007640396929673443, Final Batch Loss: 0.0005416605272330344\n",
      "Epoch 3809, Loss: 9.54721236325895e-05, Final Batch Loss: 7.787007234583143e-06\n",
      "Epoch 3810, Loss: 9.284788308150382e-05, Final Batch Loss: 6.690110240015201e-06\n",
      "Epoch 3811, Loss: 0.000649635967832296, Final Batch Loss: 4.411021564010298e-06\n",
      "Epoch 3812, Loss: 0.002280928480900002, Final Batch Loss: 1.8372122212895192e-05\n",
      "Epoch 3813, Loss: 0.0001742186823037173, Final Batch Loss: 2.09705490306078e-06\n",
      "Epoch 3814, Loss: 0.00021235020687981887, Final Batch Loss: 4.824279676540755e-05\n",
      "Epoch 3815, Loss: 0.00044933454514506366, Final Batch Loss: 1.593321258042124e-06\n",
      "Epoch 3816, Loss: 0.00015420586606751385, Final Batch Loss: 9.512357905805402e-07\n",
      "Epoch 3817, Loss: 9.769997086550575e-05, Final Batch Loss: 6.311173592621344e-07\n",
      "Epoch 3818, Loss: 7.372709680453227e-05, Final Batch Loss: 1.7664459619481931e-06\n",
      "Epoch 3819, Loss: 0.00018444010447637993, Final Batch Loss: 2.3517156932939542e-06\n",
      "Epoch 3820, Loss: 0.00013399807153646748, Final Batch Loss: 1.0627486517478246e-06\n",
      "Epoch 3821, Loss: 0.0011785663169519012, Final Batch Loss: 4.063298547407612e-06\n",
      "Epoch 3822, Loss: 0.00020862815151190262, Final Batch Loss: 1.1977161875620368e-06\n",
      "Epoch 3823, Loss: 0.00011455036757013204, Final Batch Loss: 8.668583177495748e-06\n",
      "Epoch 3824, Loss: 0.000291146660913455, Final Batch Loss: 1.1468586080809473e-06\n",
      "Epoch 3825, Loss: 7.074817378338594e-05, Final Batch Loss: 2.675178984645754e-05\n",
      "Epoch 3826, Loss: 6.92483700674984e-05, Final Batch Loss: 1.0545062650635373e-05\n",
      "Epoch 3827, Loss: 0.0004178536207035677, Final Batch Loss: 3.639670694610686e-06\n",
      "Epoch 3828, Loss: 0.00012481138612940867, Final Batch Loss: 4.161765446042409e-06\n",
      "Epoch 3829, Loss: 0.0003808009195651607, Final Batch Loss: 1.0536649824643973e-05\n",
      "Epoch 3830, Loss: 0.00040266992110815636, Final Batch Loss: 0.00030931030050851405\n",
      "Epoch 3831, Loss: 0.000418654841581656, Final Batch Loss: 4.952636118105147e-06\n",
      "Epoch 3832, Loss: 0.0004389442447774172, Final Batch Loss: 4.869214080827078e-07\n",
      "Epoch 3833, Loss: 4.832952802757973e-05, Final Batch Loss: 7.776955612825986e-07\n",
      "Epoch 3834, Loss: 1.1582897293749284e-05, Final Batch Loss: 1.9371280757241038e-07\n",
      "Epoch 3835, Loss: 0.016251879476953945, Final Batch Loss: 1.68957412824966e-05\n",
      "Epoch 3836, Loss: 0.00982253809524991, Final Batch Loss: 3.205991015420295e-05\n",
      "Epoch 3837, Loss: 0.01045035577908493, Final Batch Loss: 9.13940675673075e-05\n",
      "Epoch 3838, Loss: 0.0023953498475748347, Final Batch Loss: 2.364968713663984e-05\n",
      "Epoch 3839, Loss: 0.017303988587400454, Final Batch Loss: 1.0886906238738447e-06\n",
      "Epoch 3840, Loss: 0.0003152157698878, Final Batch Loss: 7.691619248362258e-05\n",
      "Epoch 3841, Loss: 0.005451013804808724, Final Batch Loss: 0.0023517475929111242\n",
      "Epoch 3842, Loss: 0.00019075757171549412, Final Batch Loss: 4.69122824142687e-05\n",
      "Epoch 3843, Loss: 0.0011576653534461911, Final Batch Loss: 3.633354708654224e-06\n",
      "Epoch 3844, Loss: 0.0012401356767668403, Final Batch Loss: 7.181239925557747e-05\n",
      "Epoch 3845, Loss: 0.00023159526227800598, Final Batch Loss: 2.6410757527628448e-06\n",
      "Epoch 3846, Loss: 0.0008879171001012764, Final Batch Loss: 4.13217640016228e-06\n",
      "Epoch 3847, Loss: 0.02529097091633048, Final Batch Loss: 1.8437059452480753e-06\n",
      "Epoch 3848, Loss: 0.00016165049973437817, Final Batch Loss: 1.7518463209853508e-05\n",
      "Epoch 3849, Loss: 0.0008377291012493515, Final Batch Loss: 1.4371187262440799e-06\n",
      "Epoch 3850, Loss: 0.0003305169832970023, Final Batch Loss: 1.983023321372457e-05\n",
      "Epoch 3851, Loss: 0.005303086821754732, Final Batch Loss: 2.6500050807953812e-05\n",
      "Epoch 3852, Loss: 0.000501606897671536, Final Batch Loss: 1.0287313671142329e-05\n",
      "Epoch 3853, Loss: 0.0003549664010336073, Final Batch Loss: 1.5808533362360322e-06\n",
      "Epoch 3854, Loss: 0.021803178898238684, Final Batch Loss: 1.118507771025179e-05\n",
      "Epoch 3855, Loss: 0.0016006669413997088, Final Batch Loss: 4.659518253902206e-06\n",
      "Epoch 3856, Loss: 0.0008841045606118314, Final Batch Loss: 1.713979509077035e-05\n",
      "Epoch 3857, Loss: 0.00044990291177748887, Final Batch Loss: 5.018211481910839e-07\n",
      "Epoch 3858, Loss: 0.00023705563322717893, Final Batch Loss: 1.249774239653334e-08\n",
      "Epoch 3859, Loss: 0.002014352604476244, Final Batch Loss: 0.0017131760250777006\n",
      "Epoch 3860, Loss: 0.0006194619116399736, Final Batch Loss: 6.479500029854535e-07\n",
      "Epoch 3861, Loss: 0.007071175888597736, Final Batch Loss: 1.0492650289961603e-05\n",
      "Epoch 3862, Loss: 0.00358768654814412, Final Batch Loss: 4.125048235437134e-06\n",
      "Epoch 3863, Loss: 0.0024854054479419574, Final Batch Loss: 2.233984787380905e-06\n",
      "Epoch 3864, Loss: 0.0003436098087377104, Final Batch Loss: 1.6715670199118904e-06\n",
      "Epoch 3865, Loss: 0.00042898065805729857, Final Batch Loss: 2.3169366158981575e-06\n",
      "Epoch 3866, Loss: 0.00011595798662256129, Final Batch Loss: 1.8602253248900524e-07\n",
      "Epoch 3867, Loss: 8.93376279975655e-05, Final Batch Loss: 6.1778573581250384e-06\n",
      "Epoch 3868, Loss: 4.7977852037917046e-05, Final Batch Loss: 9.483107987762196e-07\n",
      "Epoch 3869, Loss: 0.00082198495783814, Final Batch Loss: 2.114977064593404e-07\n",
      "Epoch 3870, Loss: 0.00039523164434740465, Final Batch Loss: 6.469840059253329e-07\n",
      "Epoch 3871, Loss: 7.518780280690862e-05, Final Batch Loss: 5.1156399422325194e-05\n",
      "Epoch 3872, Loss: 0.00027880288439519063, Final Batch Loss: 1.1800124184446759e-06\n",
      "Epoch 3873, Loss: 0.005097855653559691, Final Batch Loss: 9.185308726955554e-07\n",
      "Epoch 3874, Loss: 0.03225241108054888, Final Batch Loss: 0.009028526023030281\n",
      "Epoch 3875, Loss: 0.006109238760927838, Final Batch Loss: 8.150701432896312e-06\n",
      "Epoch 3876, Loss: 0.00041356809299486486, Final Batch Loss: 3.5873670185537776e-06\n",
      "Epoch 3877, Loss: 0.00046958889498682765, Final Batch Loss: 7.440854119522555e-07\n",
      "Epoch 3878, Loss: 0.0007288999951811093, Final Batch Loss: 2.4575758743594633e-06\n",
      "Epoch 3879, Loss: 0.0005331576438720731, Final Batch Loss: 1.6049541500251507e-06\n",
      "Epoch 3880, Loss: 0.0001856329027987158, Final Batch Loss: 1.4073115153223625e-06\n",
      "Epoch 3881, Loss: 7.649498766681972e-05, Final Batch Loss: 3.6146954585092317e-07\n",
      "Epoch 3882, Loss: 0.010152497805165694, Final Batch Loss: 8.094446570794389e-07\n",
      "Epoch 3883, Loss: 0.0009630843452441695, Final Batch Loss: 7.701585855102167e-05\n",
      "Epoch 3884, Loss: 0.00020823084651055979, Final Batch Loss: 2.5838942292466527e-06\n",
      "Epoch 3885, Loss: 0.0003789081370086933, Final Batch Loss: 2.8456166546675377e-05\n",
      "Epoch 3886, Loss: 0.00034547971995380067, Final Batch Loss: 3.8137874071253464e-05\n",
      "Epoch 3887, Loss: 0.0004996989462142665, Final Batch Loss: 0.00033696473110467196\n",
      "Epoch 3888, Loss: 0.00011934259470081088, Final Batch Loss: 1.1615054972935468e-05\n",
      "Epoch 3889, Loss: 0.0004257138491539081, Final Batch Loss: 5.902516477362951e-06\n",
      "Epoch 3890, Loss: 0.0010435236330295083, Final Batch Loss: 8.392295058001764e-06\n",
      "Epoch 3891, Loss: 0.00020657449260852445, Final Batch Loss: 1.1714173524524085e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3892, Loss: 0.00016567233444675367, Final Batch Loss: 3.1017145374789834e-05\n",
      "Epoch 3893, Loss: 0.0005346538750359286, Final Batch Loss: 5.589625743596116e-06\n",
      "Epoch 3894, Loss: 0.0015636257948017374, Final Batch Loss: 3.0070341381360777e-05\n",
      "Epoch 3895, Loss: 0.00034115486300834164, Final Batch Loss: 5.084475105832098e-06\n",
      "Epoch 3896, Loss: 0.00023132315732254938, Final Batch Loss: 4.69158730993513e-05\n",
      "Epoch 3897, Loss: 0.0002610641577689421, Final Batch Loss: 5.624215191346593e-06\n",
      "Epoch 3898, Loss: 0.0022404651901979378, Final Batch Loss: 2.371505161136156e-06\n",
      "Epoch 3899, Loss: 3.647849732146824e-05, Final Batch Loss: 1.924302523548249e-06\n",
      "Epoch 3900, Loss: 0.0001084567606994824, Final Batch Loss: 1.3477576885634335e-06\n",
      "Epoch 3901, Loss: 0.00023248591290325749, Final Batch Loss: 0.0001521655503893271\n",
      "Epoch 3902, Loss: 0.00021264347401483974, Final Batch Loss: 2.316715381311951e-06\n",
      "Epoch 3903, Loss: 8.200603355135172e-05, Final Batch Loss: 8.288430763059296e-06\n",
      "Epoch 3904, Loss: 7.763681020378499e-05, Final Batch Loss: 1.4033465049578808e-05\n",
      "Epoch 3905, Loss: 0.00025589315015395186, Final Batch Loss: 1.635210196582193e-06\n",
      "Epoch 3906, Loss: 0.00011057170371486791, Final Batch Loss: 4.544855619315058e-05\n",
      "Epoch 3907, Loss: 0.00043315692425949237, Final Batch Loss: 1.46225274875178e-05\n",
      "Epoch 3908, Loss: 0.0004281299491353252, Final Batch Loss: 3.0325902571348706e-06\n",
      "Epoch 3909, Loss: 0.00023614425172979736, Final Batch Loss: 1.5241334040183574e-05\n",
      "Epoch 3910, Loss: 0.00015124365326357747, Final Batch Loss: 1.4701986401632894e-06\n",
      "Epoch 3911, Loss: 7.540319739973711e-05, Final Batch Loss: 1.4962872683099704e-06\n",
      "Epoch 3912, Loss: 0.00017451919458721932, Final Batch Loss: 1.8883316670326167e-06\n",
      "Epoch 3913, Loss: 8.19316854787644e-05, Final Batch Loss: 7.623136752954451e-07\n",
      "Epoch 3914, Loss: 4.021155480415928e-05, Final Batch Loss: 1.6279461760859704e-06\n",
      "Epoch 3915, Loss: 5.4655084483101746e-05, Final Batch Loss: 1.850613244869237e-07\n",
      "Epoch 3916, Loss: 0.00011040618397828439, Final Batch Loss: 6.023126843501814e-06\n",
      "Epoch 3917, Loss: 7.75958325789361e-05, Final Batch Loss: 4.3625705075100996e-06\n",
      "Epoch 3918, Loss: 0.0005427328695191136, Final Batch Loss: 6.926536002538342e-07\n",
      "Epoch 3919, Loss: 4.959392101966387e-05, Final Batch Loss: 4.797119572685915e-07\n",
      "Epoch 3920, Loss: 0.0002856292250896786, Final Batch Loss: 1.7796789961721515e-06\n",
      "Epoch 3921, Loss: 0.00016636228752986426, Final Batch Loss: 2.19671221657336e-07\n",
      "Epoch 3922, Loss: 7.622226490866524e-05, Final Batch Loss: 1.5674178257540916e-06\n",
      "Epoch 3923, Loss: 4.1835452876171075e-05, Final Batch Loss: 6.195096830197144e-06\n",
      "Epoch 3924, Loss: 5.530795130681554e-05, Final Batch Loss: 6.796496450078848e-07\n",
      "Epoch 3925, Loss: 0.00014124951331950797, Final Batch Loss: 1.8556254417489981e-06\n",
      "Epoch 3926, Loss: 0.0004020563720246173, Final Batch Loss: 2.5476015252934303e-07\n",
      "Epoch 3927, Loss: 0.00018295991095840236, Final Batch Loss: 5.292110358823265e-07\n",
      "Epoch 3928, Loss: 0.0007619330874746311, Final Batch Loss: 4.269527562428266e-05\n",
      "Epoch 3929, Loss: 5.8231480728920815e-05, Final Batch Loss: 2.6225961846648715e-05\n",
      "Epoch 3930, Loss: 8.153938795629756e-05, Final Batch Loss: 8.918193998397328e-06\n",
      "Epoch 3931, Loss: 0.00016856924017361052, Final Batch Loss: 2.250638090117718e-06\n",
      "Epoch 3932, Loss: 4.435179062767247e-05, Final Batch Loss: 1.2064493830621359e-06\n",
      "Epoch 3933, Loss: 5.762732050129671e-05, Final Batch Loss: 4.764669029100332e-06\n",
      "Epoch 3934, Loss: 4.2055661722884e-05, Final Batch Loss: 5.694212632079143e-06\n",
      "Epoch 3935, Loss: 0.00014982866734847278, Final Batch Loss: 2.8407984586920065e-07\n",
      "Epoch 3936, Loss: 8.509285834179536e-05, Final Batch Loss: 2.005464693866088e-06\n",
      "Epoch 3937, Loss: 0.000746509763466463, Final Batch Loss: 3.0378356541405083e-07\n",
      "Epoch 3938, Loss: 0.001595507715890676, Final Batch Loss: 2.629301718570787e-07\n",
      "Epoch 3939, Loss: 0.00013298517606941118, Final Batch Loss: 2.749466716522875e-07\n",
      "Epoch 3940, Loss: 3.647544169638195e-05, Final Batch Loss: 5.748651119574788e-07\n",
      "Epoch 3941, Loss: 2.5453492071392247e-05, Final Batch Loss: 4.4269421550779953e-07\n",
      "Epoch 3942, Loss: 0.0006957155924851577, Final Batch Loss: 8.556123987091269e-08\n",
      "Epoch 3943, Loss: 8.528059888135431e-05, Final Batch Loss: 4.88362900341599e-07\n",
      "Epoch 3944, Loss: 5.341614956932972e-05, Final Batch Loss: 1.5189490909506276e-07\n",
      "Epoch 3945, Loss: 0.009149110526337267, Final Batch Loss: 3.984816316915385e-07\n",
      "Epoch 3946, Loss: 3.719767399701368e-05, Final Batch Loss: 2.8030731300532352e-06\n",
      "Epoch 3947, Loss: 0.0004345098258369262, Final Batch Loss: 4.656330474972492e-06\n",
      "Epoch 3948, Loss: 6.245343115551805e-05, Final Batch Loss: 1.2607553117049974e-06\n",
      "Epoch 3949, Loss: 0.00024648410328609316, Final Batch Loss: 4.991764399164822e-06\n",
      "Epoch 3950, Loss: 0.02249261399718705, Final Batch Loss: 1.0838837170012994e-06\n",
      "Epoch 3951, Loss: 0.00042606112656073947, Final Batch Loss: 3.726669774550828e-06\n",
      "Epoch 3952, Loss: 0.0004713462182621697, Final Batch Loss: 1.1272387382632587e-05\n",
      "Epoch 3953, Loss: 0.0005809072908959934, Final Batch Loss: 8.397511919611134e-06\n",
      "Epoch 3954, Loss: 0.000336129942070329, Final Batch Loss: 5.463915385917062e-06\n",
      "Epoch 3955, Loss: 0.0004818786749183346, Final Batch Loss: 0.00032241150620393455\n",
      "Epoch 3956, Loss: 0.00018441481580566688, Final Batch Loss: 4.904051365883788e-06\n",
      "Epoch 3957, Loss: 0.0007436291632529901, Final Batch Loss: 1.3298060366651043e-05\n",
      "Epoch 3958, Loss: 0.00018266888130824555, Final Batch Loss: 3.9751782310304407e-07\n",
      "Epoch 3959, Loss: 0.00016085462823411945, Final Batch Loss: 2.9303384962986456e-06\n",
      "Epoch 3960, Loss: 0.002671061295927757, Final Batch Loss: 6.752377430530032e-06\n",
      "Epoch 3961, Loss: 0.00014235209859236875, Final Batch Loss: 7.450829343724763e-06\n",
      "Epoch 3962, Loss: 0.00012061271299046439, Final Batch Loss: 1.4206632386049023e-06\n",
      "Epoch 3963, Loss: 0.00012166172655980745, Final Batch Loss: 2.0964807845302857e-05\n",
      "Epoch 3964, Loss: 4.604212109526884e-05, Final Batch Loss: 2.03518584385165e-06\n",
      "Epoch 3965, Loss: 5.607815876373934e-05, Final Batch Loss: 1.5163945136009715e-05\n",
      "Epoch 3966, Loss: 2.9201502094622356e-05, Final Batch Loss: 2.631992856549914e-06\n",
      "Epoch 3967, Loss: 0.00013542106496089445, Final Batch Loss: 4.713465750683099e-05\n",
      "Epoch 3968, Loss: 0.002450101239546143, Final Batch Loss: 9.66625748333172e-07\n",
      "Epoch 3969, Loss: 1.4357749572369016e-05, Final Batch Loss: 2.3208847323985538e-06\n",
      "Epoch 3970, Loss: 0.00012774101486456857, Final Batch Loss: 6.681215154458187e-07\n",
      "Epoch 3971, Loss: 0.0003329921580483841, Final Batch Loss: 7.1889116952661425e-06\n",
      "Epoch 3972, Loss: 2.954406520672137e-05, Final Batch Loss: 3.4230843084515072e-06\n",
      "Epoch 3973, Loss: 0.000269976570820063, Final Batch Loss: 1.7195939108205494e-06\n",
      "Epoch 3974, Loss: 0.002964438850916906, Final Batch Loss: 1.6027759102144046e-06\n",
      "Epoch 3975, Loss: 4.1696278273661846e-05, Final Batch Loss: 6.585337075648567e-08\n",
      "Epoch 3976, Loss: 3.614353103387202e-05, Final Batch Loss: 1.1247911402278987e-07\n",
      "Epoch 3977, Loss: 0.00018571134945588597, Final Batch Loss: 8.219623026661793e-08\n",
      "Epoch 3978, Loss: 1.66322382444406e-05, Final Batch Loss: 1.562199827276345e-07\n",
      "Epoch 3979, Loss: 0.04218144598888074, Final Batch Loss: 1.1786512004618999e-05\n",
      "Epoch 3980, Loss: 0.010160841249302166, Final Batch Loss: 1.8264906884724041e-06\n",
      "Epoch 3981, Loss: 0.0005831357169654439, Final Batch Loss: 9.84247526503168e-05\n",
      "Epoch 3982, Loss: 0.0003674759881562295, Final Batch Loss: 3.265463419666048e-06\n",
      "Epoch 3983, Loss: 0.006126586417849467, Final Batch Loss: 1.044011582962412e-06\n",
      "Epoch 3984, Loss: 0.00010798259916100506, Final Batch Loss: 5.444280759547837e-06\n",
      "Epoch 3985, Loss: 5.121449497380581e-05, Final Batch Loss: 5.07330832988373e-06\n",
      "Epoch 3986, Loss: 0.0005799145706646414, Final Batch Loss: 8.975411219580565e-06\n",
      "Epoch 3987, Loss: 0.00018283230085103241, Final Batch Loss: 3.105158157268306e-07\n",
      "Epoch 3988, Loss: 0.00010671432342235221, Final Batch Loss: 2.2880381322920584e-07\n",
      "Epoch 3989, Loss: 0.00010716533012100626, Final Batch Loss: 2.230145582871046e-06\n",
      "Epoch 3990, Loss: 0.019664216185447003, Final Batch Loss: 4.428517513588304e-06\n",
      "Epoch 3991, Loss: 0.0002613112412177543, Final Batch Loss: 4.912242275167955e-06\n",
      "Epoch 3992, Loss: 0.0019797893760369334, Final Batch Loss: 0.0005315471207723022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3993, Loss: 0.0003476089016203332, Final Batch Loss: 5.1992588851135224e-05\n",
      "Epoch 3994, Loss: 0.0006366743210719505, Final Batch Loss: 3.8922585190448444e-06\n",
      "Epoch 3995, Loss: 0.0008019873092734997, Final Batch Loss: 9.560541229802766e-07\n",
      "Epoch 3996, Loss: 0.00023392850118852948, Final Batch Loss: 5.6519547797506675e-06\n",
      "Epoch 3997, Loss: 0.0001488610196247464, Final Batch Loss: 1.2389761650410946e-05\n",
      "Epoch 3998, Loss: 0.00017726095639147843, Final Batch Loss: 3.1965228117769584e-06\n",
      "Epoch 3999, Loss: 9.899032571070165e-05, Final Batch Loss: 3.585858223686955e-07\n",
      "Epoch 4000, Loss: 9.441036041835105e-05, Final Batch Loss: 2.6588968466967344e-06\n",
      "Epoch 4001, Loss: 0.00018345520788898284, Final Batch Loss: 2.5267265755246626e-06\n",
      "Epoch 4002, Loss: 0.013546019594571135, Final Batch Loss: 5.92928881815169e-05\n",
      "Epoch 4003, Loss: 0.0012752980512686918, Final Batch Loss: 1.690438875812106e-05\n",
      "Epoch 4004, Loss: 0.0006049548879332178, Final Batch Loss: 5.035738467995543e-06\n",
      "Epoch 4005, Loss: 0.001066941090812179, Final Batch Loss: 6.465088517870754e-07\n",
      "Epoch 4006, Loss: 0.0006255073391230326, Final Batch Loss: 4.4928263378096744e-05\n",
      "Epoch 4007, Loss: 0.00015005203556484048, Final Batch Loss: 1.2257089565537171e-06\n",
      "Epoch 4008, Loss: 0.0002775662665044365, Final Batch Loss: 5.715235147363273e-07\n",
      "Epoch 4009, Loss: 0.00020814579232109054, Final Batch Loss: 0.00010508839477552101\n",
      "Epoch 4010, Loss: 0.00011855251608494655, Final Batch Loss: 1.4572464124285034e-06\n",
      "Epoch 4011, Loss: 0.0018654858723436973, Final Batch Loss: 1.135823481490661e-06\n",
      "Epoch 4012, Loss: 0.0005753024996977274, Final Batch Loss: 0.00044441179488785565\n",
      "Epoch 4013, Loss: 0.00013803246918087098, Final Batch Loss: 1.3428718830255093e-06\n",
      "Epoch 4014, Loss: 0.00010602878974452778, Final Batch Loss: 2.253181037303875e-06\n",
      "Epoch 4015, Loss: 0.00035959409621000304, Final Batch Loss: 3.061915663238324e-07\n",
      "Epoch 4016, Loss: 0.0003787084701798449, Final Batch Loss: 5.964428964944091e-06\n",
      "Epoch 4017, Loss: 8.507960921733115e-05, Final Batch Loss: 7.61380590574845e-07\n",
      "Epoch 4018, Loss: 0.0001548041618946172, Final Batch Loss: 5.852497451996896e-06\n",
      "Epoch 4019, Loss: 0.0004274088746427651, Final Batch Loss: 8.246249308285769e-06\n",
      "Epoch 4020, Loss: 7.468200973903549e-05, Final Batch Loss: 6.344835696836526e-07\n",
      "Epoch 4021, Loss: 0.0001888457288146128, Final Batch Loss: 1.127777522924589e-05\n",
      "Epoch 4022, Loss: 0.0008631195538271186, Final Batch Loss: 9.546130286253174e-07\n",
      "Epoch 4023, Loss: 5.78211313495558e-05, Final Batch Loss: 6.883053629280766e-07\n",
      "Epoch 4024, Loss: 7.025525025028401e-05, Final Batch Loss: 4.218118192511611e-06\n",
      "Epoch 4025, Loss: 3.919221812509477e-05, Final Batch Loss: 1.9755937330501183e-07\n",
      "Epoch 4026, Loss: 2.8116062736671665e-05, Final Batch Loss: 3.424116812311695e-06\n",
      "Epoch 4027, Loss: 9.397781298048358e-05, Final Batch Loss: 7.022497356956592e-07\n",
      "Epoch 4028, Loss: 0.0008990555179977378, Final Batch Loss: 7.578986696898937e-06\n",
      "Epoch 4029, Loss: 4.978403799782427e-05, Final Batch Loss: 2.787320045172237e-05\n",
      "Epoch 4030, Loss: 0.00015145969812380145, Final Batch Loss: 3.5141911212122068e-06\n",
      "Epoch 4031, Loss: 2.9005796463366096e-05, Final Batch Loss: 1.181682000606088e-05\n",
      "Epoch 4032, Loss: 3.9003104255641574e-05, Final Batch Loss: 5.221568699198542e-06\n",
      "Epoch 4033, Loss: 9.907814944654092e-05, Final Batch Loss: 4.595563495968236e-06\n",
      "Epoch 4034, Loss: 0.00013826264127736465, Final Batch Loss: 5.561431066780642e-07\n",
      "Epoch 4035, Loss: 2.284400829921651e-05, Final Batch Loss: 3.94634469103039e-07\n",
      "Epoch 4036, Loss: 9.771720191409372e-05, Final Batch Loss: 1.7201713262693374e-06\n",
      "Epoch 4037, Loss: 7.08874726740305e-05, Final Batch Loss: 3.782797648455016e-05\n",
      "Epoch 4038, Loss: 0.00034073929769817823, Final Batch Loss: 8.060867003223393e-06\n",
      "Epoch 4039, Loss: 4.296373430179301e-05, Final Batch Loss: 9.958645250662812e-07\n",
      "Epoch 4040, Loss: 3.0030030636396532e-05, Final Batch Loss: 9.171138231067744e-07\n",
      "Epoch 4041, Loss: 0.00015986223618824624, Final Batch Loss: 3.465672762104077e-07\n",
      "Epoch 4042, Loss: 6.430097825216308e-05, Final Batch Loss: 1.978250111278612e-05\n",
      "Epoch 4043, Loss: 0.00356632891072195, Final Batch Loss: 1.904300006572157e-05\n",
      "Epoch 4044, Loss: 0.00024175997727127196, Final Batch Loss: 1.8302301896255813e-06\n",
      "Epoch 4045, Loss: 8.572129992501232e-05, Final Batch Loss: 2.0954798856109846e-06\n",
      "Epoch 4046, Loss: 0.0001880210028843976, Final Batch Loss: 7.936961083032656e-06\n",
      "Epoch 4047, Loss: 6.217861073309905e-05, Final Batch Loss: 1.1497133982629748e-06\n",
      "Epoch 4048, Loss: 2.9167191613055365e-05, Final Batch Loss: 4.5135331561141356e-07\n",
      "Epoch 4049, Loss: 4.4401413461514494e-05, Final Batch Loss: 2.113089067279361e-06\n",
      "Epoch 4050, Loss: 0.0001474172168158816, Final Batch Loss: 1.2482053080020705e-06\n",
      "Epoch 4051, Loss: 0.0003668228645210547, Final Batch Loss: 8.109964983304963e-05\n",
      "Epoch 4052, Loss: 0.0003092737047794003, Final Batch Loss: 2.326647290828987e-06\n",
      "Epoch 4053, Loss: 1.8016311258861606e-05, Final Batch Loss: 4.417347838625574e-07\n",
      "Epoch 4054, Loss: 0.00012856224350343837, Final Batch Loss: 2.2386082036973676e-06\n",
      "Epoch 4055, Loss: 3.980683625570691e-05, Final Batch Loss: 5.657490191879333e-07\n",
      "Epoch 4056, Loss: 0.00022668243921941666, Final Batch Loss: 5.397935751716432e-07\n",
      "Epoch 4057, Loss: 1.885068043350202e-05, Final Batch Loss: 8.79647217288948e-08\n",
      "Epoch 4058, Loss: 4.618744527817853e-05, Final Batch Loss: 5.075868330095545e-07\n",
      "Epoch 4059, Loss: 7.324672198194548e-05, Final Batch Loss: 5.590574801317416e-06\n",
      "Epoch 4060, Loss: 7.856279396278865e-05, Final Batch Loss: 1.8073502872084646e-07\n",
      "Epoch 4061, Loss: 5.880739880481656e-05, Final Batch Loss: 7.498618970203097e-08\n",
      "Epoch 4062, Loss: 9.367136434690337e-05, Final Batch Loss: 1.5624688103343942e-06\n",
      "Epoch 4063, Loss: 4.126002093585157e-05, Final Batch Loss: 1.5036209333629813e-05\n",
      "Epoch 4064, Loss: 1.6626620499948785e-05, Final Batch Loss: 5.974587793389219e-07\n",
      "Epoch 4065, Loss: 4.2508771002758294e-05, Final Batch Loss: 3.6743576856679283e-06\n",
      "Epoch 4066, Loss: 0.00012301719081619922, Final Batch Loss: 8.868119948601816e-06\n",
      "Epoch 4067, Loss: 6.300858587593439e-05, Final Batch Loss: 1.0478416925252532e-06\n",
      "Epoch 4068, Loss: 7.959424823056338e-05, Final Batch Loss: 4.473042281460948e-05\n",
      "Epoch 4069, Loss: 6.91012208928754e-05, Final Batch Loss: 1.547791868006243e-07\n",
      "Epoch 4070, Loss: 4.565395923350479e-05, Final Batch Loss: 2.0246845906513045e-06\n",
      "Epoch 4071, Loss: 0.00030418938092680037, Final Batch Loss: 0.00012167963723186404\n",
      "Epoch 4072, Loss: 0.0010679703459146594, Final Batch Loss: 3.604910943977302e-06\n",
      "Epoch 4073, Loss: 0.00012654285859881043, Final Batch Loss: 2.1816097159899073e-06\n",
      "Epoch 4074, Loss: 0.00227982642050506, Final Batch Loss: 0.0018030393403023481\n",
      "Epoch 4075, Loss: 5.022582292646405e-05, Final Batch Loss: 8.238343980337959e-07\n",
      "Epoch 4076, Loss: 0.00017455086804574194, Final Batch Loss: 2.1101840275150607e-07\n",
      "Epoch 4077, Loss: 0.0001660860155681121, Final Batch Loss: 1.5347131920862012e-06\n",
      "Epoch 4078, Loss: 3.792775123656611e-05, Final Batch Loss: 3.35032439124916e-07\n",
      "Epoch 4079, Loss: 2.353670796040319e-05, Final Batch Loss: 2.547615807202419e-08\n",
      "Epoch 4080, Loss: 3.0345677977550167e-05, Final Batch Loss: 1.196888774757099e-07\n",
      "Epoch 4081, Loss: 0.0024318774380560626, Final Batch Loss: 8.151608312800818e-07\n",
      "Epoch 4082, Loss: 8.227353191614384e-05, Final Batch Loss: 8.671263458381873e-07\n",
      "Epoch 4083, Loss: 1.2106013286938833e-05, Final Batch Loss: 3.7139764117455343e-06\n",
      "Epoch 4084, Loss: 8.203719347665839e-05, Final Batch Loss: 5.042271368438378e-05\n",
      "Epoch 4085, Loss: 0.0016070832930777934, Final Batch Loss: 8.988735800130598e-08\n",
      "Epoch 4086, Loss: 5.661888268093662e-05, Final Batch Loss: 8.017186701181345e-06\n",
      "Epoch 4087, Loss: 0.005647247120901255, Final Batch Loss: 0.0001165752619272098\n",
      "Epoch 4088, Loss: 0.0016147797009180564, Final Batch Loss: 1.8796316680891323e-06\n",
      "Epoch 4089, Loss: 8.810242617585118e-05, Final Batch Loss: 9.30493297346402e-06\n",
      "Epoch 4090, Loss: 0.001862136024811889, Final Batch Loss: 6.996630418143468e-06\n",
      "Epoch 4091, Loss: 6.057487754951296e-05, Final Batch Loss: 8.991100003186148e-06\n",
      "Epoch 4092, Loss: 4.0912573573415045e-05, Final Batch Loss: 1.0896624189626891e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4093, Loss: 9.671381324150019e-05, Final Batch Loss: 7.100502989487723e-05\n",
      "Epoch 4094, Loss: 1.576622327803534e-05, Final Batch Loss: 4.4413664568310196e-07\n",
      "Epoch 4095, Loss: 4.8253540329668e-05, Final Batch Loss: 5.611606866295915e-06\n",
      "Epoch 4096, Loss: 7.043701765052646e-05, Final Batch Loss: 2.2399648003101902e-07\n",
      "Epoch 4097, Loss: 3.8053030543494515e-05, Final Batch Loss: 7.055264177324716e-06\n",
      "Epoch 4098, Loss: 9.402722417917175e-05, Final Batch Loss: 4.181850101758755e-07\n",
      "Epoch 4099, Loss: 0.00861551003792016, Final Batch Loss: 8.290129699162208e-06\n",
      "Epoch 4100, Loss: 0.004555770180694196, Final Batch Loss: 6.2239541875896975e-06\n",
      "Epoch 4101, Loss: 0.0008185053361771111, Final Batch Loss: 0.0005137897678650916\n",
      "Epoch 4102, Loss: 2.860248004932231e-05, Final Batch Loss: 7.402494617281263e-08\n",
      "Epoch 4103, Loss: 2.613206841228788e-05, Final Batch Loss: 9.634872185415588e-06\n",
      "Epoch 4104, Loss: 9.874767613382573e-05, Final Batch Loss: 8.050188625929877e-06\n",
      "Epoch 4105, Loss: 2.955962180184457e-05, Final Batch Loss: 2.374530225779381e-07\n",
      "Epoch 4106, Loss: 0.01120564848708483, Final Batch Loss: 1.9911487470380962e-05\n",
      "Epoch 4107, Loss: 0.02404023880637851, Final Batch Loss: 2.4540106551285135e-06\n",
      "Epoch 4108, Loss: 0.031999005391369906, Final Batch Loss: 2.375280701016891e-06\n",
      "Epoch 4109, Loss: 0.0005952951516405847, Final Batch Loss: 2.0133120415266603e-05\n",
      "Epoch 4110, Loss: 0.007887500651406754, Final Batch Loss: 2.8803999612136977e-06\n",
      "Epoch 4111, Loss: 0.00010046358363524632, Final Batch Loss: 1.1382131788195693e-06\n",
      "Epoch 4112, Loss: 0.0010117290916582533, Final Batch Loss: 5.42748193765874e-06\n",
      "Epoch 4113, Loss: 5.980933755722617e-05, Final Batch Loss: 6.224688604561379e-07\n",
      "Epoch 4114, Loss: 0.00111971600024674, Final Batch Loss: 1.4372240286775195e-07\n",
      "Epoch 4115, Loss: 0.0006213504480570009, Final Batch Loss: 1.5628746041329578e-05\n",
      "Epoch 4116, Loss: 0.00016775444407812756, Final Batch Loss: 6.172403664095327e-05\n",
      "Epoch 4117, Loss: 0.00015317875664777603, Final Batch Loss: 1.4024867596162949e-06\n",
      "Epoch 4118, Loss: 0.0003428952602533286, Final Batch Loss: 7.118504754544119e-07\n",
      "Epoch 4119, Loss: 9.533478413459306e-05, Final Batch Loss: 3.113552565991995e-06\n",
      "Epoch 4120, Loss: 4.6026288117673175e-05, Final Batch Loss: 1.331386670244683e-06\n",
      "Epoch 4121, Loss: 0.0001947084994924353, Final Batch Loss: 7.339658168348251e-06\n",
      "Epoch 4122, Loss: 0.0004202028011075498, Final Batch Loss: 1.831390079587436e-07\n",
      "Epoch 4123, Loss: 4.99952031773887e-05, Final Batch Loss: 4.3164217800040205e-07\n",
      "Epoch 4124, Loss: 1.438686618371321e-05, Final Batch Loss: 1.1987568768745405e-06\n",
      "Epoch 4125, Loss: 0.00021270443666310257, Final Batch Loss: 1.839442120399326e-05\n",
      "Epoch 4126, Loss: 8.13662121146308e-05, Final Batch Loss: 1.23522636386042e-06\n",
      "Epoch 4127, Loss: 0.0002555155464563086, Final Batch Loss: 4.115632236789679e-06\n",
      "Epoch 4128, Loss: 0.00013266140789269798, Final Batch Loss: 1.2540170928332373e-06\n",
      "Epoch 4129, Loss: 0.0003388294165169725, Final Batch Loss: 2.2570479814021382e-06\n",
      "Epoch 4130, Loss: 0.00012606748099130982, Final Batch Loss: 1.2933944617543602e-06\n",
      "Epoch 4131, Loss: 3.410412450932654e-05, Final Batch Loss: 5.128756583872018e-07\n",
      "Epoch 4132, Loss: 4.504692638107599e-05, Final Batch Loss: 2.5331414121865237e-07\n",
      "Epoch 4133, Loss: 0.0008577140405279238, Final Batch Loss: 1.1872806737756036e-07\n",
      "Epoch 4134, Loss: 0.00010236844326527716, Final Batch Loss: 1.5099660231499001e-05\n",
      "Epoch 4135, Loss: 0.00011024581172591752, Final Batch Loss: 1.5518576219619717e-06\n",
      "Epoch 4136, Loss: 0.0001823705600259018, Final Batch Loss: 7.99805206952442e-07\n",
      "Epoch 4137, Loss: 0.0010139616744595514, Final Batch Loss: 4.953076859237626e-05\n",
      "Epoch 4138, Loss: 0.0008129285486351279, Final Batch Loss: 4.26361623340199e-07\n",
      "Epoch 4139, Loss: 0.002105552107195763, Final Batch Loss: 1.0838008165592328e-05\n",
      "Epoch 4140, Loss: 9.401909426287602e-05, Final Batch Loss: 1.4943186670279829e-06\n",
      "Epoch 4141, Loss: 0.0002753787235789673, Final Batch Loss: 2.341388062632177e-05\n",
      "Epoch 4142, Loss: 0.0002002579588804565, Final Batch Loss: 1.518684712209506e-06\n",
      "Epoch 4143, Loss: 5.237542536207229e-05, Final Batch Loss: 1.4196039046510123e-05\n",
      "Epoch 4144, Loss: 4.714936952154858e-05, Final Batch Loss: 1.7282857243117178e-06\n",
      "Epoch 4145, Loss: 0.00012660778050133104, Final Batch Loss: 3.114761000233557e-07\n",
      "Epoch 4146, Loss: 2.1909600846470312e-05, Final Batch Loss: 1.1252303693254362e-06\n",
      "Epoch 4147, Loss: 1.4306093476079695e-05, Final Batch Loss: 2.1822457085818314e-07\n",
      "Epoch 4148, Loss: 3.147435447736768e-05, Final Batch Loss: 1.2226822718730546e-06\n",
      "Epoch 4149, Loss: 8.001326450468582e-05, Final Batch Loss: 9.805884815250465e-08\n",
      "Epoch 4150, Loss: 0.00027123557477182203, Final Batch Loss: 1.4774735745959333e-06\n",
      "Epoch 4151, Loss: 1.2781121105476245e-05, Final Batch Loss: 4.7503417590633035e-06\n",
      "Epoch 4152, Loss: 2.6862873289346112e-05, Final Batch Loss: 1.0575016418101768e-08\n",
      "Epoch 4153, Loss: 3.580525929081091e-05, Final Batch Loss: 4.133863029665008e-08\n",
      "Epoch 4154, Loss: 5.516207151501362e-05, Final Batch Loss: 1.211310092230633e-07\n",
      "Epoch 4155, Loss: 0.0004776875939285219, Final Batch Loss: 1.4552555285263225e-06\n",
      "Epoch 4156, Loss: 0.0002130481152047281, Final Batch Loss: 1.6221707710428745e-06\n",
      "Epoch 4157, Loss: 0.008571311901505396, Final Batch Loss: 3.851854853564873e-05\n",
      "Epoch 4158, Loss: 0.041179489728918384, Final Batch Loss: 1.591049851867865e-07\n",
      "Epoch 4159, Loss: 0.020682444131963962, Final Batch Loss: 5.508380240826227e-07\n",
      "Epoch 4160, Loss: 9.506151742755264e-05, Final Batch Loss: 2.2460497348220088e-05\n",
      "Epoch 4161, Loss: 0.004185834249881282, Final Batch Loss: 4.715195700555341e-06\n",
      "Epoch 4162, Loss: 0.0004775008478210552, Final Batch Loss: 3.220567634798499e-08\n",
      "Epoch 4163, Loss: 0.0003122766587448922, Final Batch Loss: 5.83039593493595e-07\n",
      "Epoch 4164, Loss: 0.005546968327049484, Final Batch Loss: 3.681937812416436e-07\n",
      "Epoch 4165, Loss: 0.0002213427088690878, Final Batch Loss: 4.607657956512412e-06\n",
      "Epoch 4166, Loss: 0.00027647675605635413, Final Batch Loss: 4.595322479872266e-06\n",
      "Epoch 4167, Loss: 0.0002961564324550636, Final Batch Loss: 7.34482382540591e-05\n",
      "Epoch 4168, Loss: 0.0005320019743493276, Final Batch Loss: 1.0588667009869823e-06\n",
      "Epoch 4169, Loss: 0.0011091470571500395, Final Batch Loss: 8.382596661249408e-07\n",
      "Epoch 4170, Loss: 6.612484608581326e-05, Final Batch Loss: 1.6695301383151673e-05\n",
      "Epoch 4171, Loss: 0.00010273312787489886, Final Batch Loss: 5.538321602216456e-06\n",
      "Epoch 4172, Loss: 0.00032852989110665476, Final Batch Loss: 3.6483004805631936e-05\n",
      "Epoch 4173, Loss: 0.0001133281244705131, Final Batch Loss: 5.136659638083074e-06\n",
      "Epoch 4174, Loss: 0.004616377680342509, Final Batch Loss: 8.53231358632911e-06\n",
      "Epoch 4175, Loss: 0.00014729228960419505, Final Batch Loss: 1.7114163028963958e-06\n",
      "Epoch 4176, Loss: 0.00013201283630426275, Final Batch Loss: 4.143999467487447e-05\n",
      "Epoch 4177, Loss: 3.7022082741700046e-05, Final Batch Loss: 7.354380926472004e-08\n",
      "Epoch 4178, Loss: 0.00031065877696612176, Final Batch Loss: 2.330745019207825e-06\n",
      "Epoch 4179, Loss: 0.051921945096898625, Final Batch Loss: 3.1676407274972007e-07\n",
      "Epoch 4180, Loss: 0.0009239663656899211, Final Batch Loss: 6.656432378804311e-05\n",
      "Epoch 4181, Loss: 0.03138506377877093, Final Batch Loss: 0.029614947736263275\n",
      "Epoch 4182, Loss: 9.955878036294052e-05, Final Batch Loss: 1.3074540561319736e-07\n",
      "Epoch 4183, Loss: 0.017991253367199533, Final Batch Loss: 2.8660426778515102e-06\n",
      "Epoch 4184, Loss: 0.00017481206884895073, Final Batch Loss: 1.2408135262376163e-05\n",
      "Epoch 4185, Loss: 0.0006536719727137097, Final Batch Loss: 0.00010775205009849742\n",
      "Epoch 4186, Loss: 0.0010475423262619188, Final Batch Loss: 0.000637873716186732\n",
      "Epoch 4187, Loss: 0.009621094520298357, Final Batch Loss: 2.7034284357796423e-05\n",
      "Epoch 4188, Loss: 0.0006427744401662494, Final Batch Loss: 2.7598816814133897e-06\n",
      "Epoch 4189, Loss: 0.0007364769653577241, Final Batch Loss: 8.166006409737747e-06\n",
      "Epoch 4190, Loss: 0.0007215108928591007, Final Batch Loss: 1.530901386104233e-06\n",
      "Epoch 4191, Loss: 9.600956030908492e-05, Final Batch Loss: 8.229139893956017e-06\n",
      "Epoch 4192, Loss: 0.0036504909209043035, Final Batch Loss: 1.1536239071574528e-05\n",
      "Epoch 4193, Loss: 0.0016390843758244955, Final Batch Loss: 0.00044899029307998717\n",
      "Epoch 4194, Loss: 0.00030466381417681987, Final Batch Loss: 5.068504833616316e-06\n",
      "Epoch 4195, Loss: 0.00027349936004839037, Final Batch Loss: 1.2953248187841382e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4196, Loss: 0.0021605254461292134, Final Batch Loss: 1.1917646588699427e-05\n",
      "Epoch 4197, Loss: 0.0001490550703522331, Final Batch Loss: 2.863142071873881e-06\n",
      "Epoch 4198, Loss: 5.0691202204689034e-05, Final Batch Loss: 6.854183993709739e-07\n",
      "Epoch 4199, Loss: 8.525082444066356e-05, Final Batch Loss: 1.1477815178295714e-06\n",
      "Epoch 4200, Loss: 0.00059658346741287, Final Batch Loss: 4.550430821836926e-05\n",
      "Epoch 4201, Loss: 0.00017673716683930252, Final Batch Loss: 8.849053756421199e-07\n",
      "Epoch 4202, Loss: 7.49615405197801e-05, Final Batch Loss: 3.6355597785586724e-06\n",
      "Epoch 4203, Loss: 0.00035149402754086623, Final Batch Loss: 8.093035830825102e-06\n",
      "Epoch 4204, Loss: 0.0002305352353886292, Final Batch Loss: 5.142996997165028e-06\n",
      "Epoch 4205, Loss: 0.00011696015852180608, Final Batch Loss: 2.1048255803179927e-05\n",
      "Epoch 4206, Loss: 0.0003922708374375361, Final Batch Loss: 1.1682789590850007e-05\n",
      "Epoch 4207, Loss: 6.880985688439978e-05, Final Batch Loss: 2.156683422072092e-06\n",
      "Epoch 4208, Loss: 4.369435138329436e-05, Final Batch Loss: 7.197652394097531e-06\n",
      "Epoch 4209, Loss: 9.147962157385336e-05, Final Batch Loss: 2.422616205421946e-07\n",
      "Epoch 4210, Loss: 5.7481930006986204e-05, Final Batch Loss: 8.1929138104897e-06\n",
      "Epoch 4211, Loss: 0.00012181091106810982, Final Batch Loss: 1.9465696823317558e-05\n",
      "Epoch 4212, Loss: 0.00016125845306191877, Final Batch Loss: 1.7339370970148593e-05\n",
      "Epoch 4213, Loss: 0.0004232255462000012, Final Batch Loss: 0.00021800491958856583\n",
      "Epoch 4214, Loss: 0.0002572193704821757, Final Batch Loss: 1.3512742953025736e-05\n",
      "Epoch 4215, Loss: 5.3451977329643796e-05, Final Batch Loss: 4.486099442146951e-06\n",
      "Epoch 4216, Loss: 0.0001930283168292135, Final Batch Loss: 9.768214113137219e-06\n",
      "Epoch 4217, Loss: 5.373156344035124e-05, Final Batch Loss: 3.6655021631304407e-06\n",
      "Epoch 4218, Loss: 2.854949414654584e-05, Final Batch Loss: 4.0232734477285703e-07\n",
      "Epoch 4219, Loss: 4.033461652852566e-05, Final Batch Loss: 1.9368796984053915e-06\n",
      "Epoch 4220, Loss: 0.00011897598591303904, Final Batch Loss: 4.579315373121062e-06\n",
      "Epoch 4221, Loss: 0.0008389499620591323, Final Batch Loss: 0.0008136961841955781\n",
      "Epoch 4222, Loss: 0.00010834395156678056, Final Batch Loss: 1.1145926919198246e-06\n",
      "Epoch 4223, Loss: 0.0001114697940280962, Final Batch Loss: 1.2953947589267045e-05\n",
      "Epoch 4224, Loss: 3.182267904122682e-05, Final Batch Loss: 2.56682426424959e-07\n",
      "Epoch 4225, Loss: 0.0008173206974930736, Final Batch Loss: 1.4420429295114445e-07\n",
      "Epoch 4226, Loss: 7.790203211754942e-05, Final Batch Loss: 6.368831236613914e-06\n",
      "Epoch 4227, Loss: 5.334182088034822e-05, Final Batch Loss: 8.291350468425662e-07\n",
      "Epoch 4228, Loss: 0.00028582336820193177, Final Batch Loss: 4.993257789465133e-06\n",
      "Epoch 4229, Loss: 5.6707001618860886e-05, Final Batch Loss: 5.034631612943485e-06\n",
      "Epoch 4230, Loss: 6.583387681757813e-05, Final Batch Loss: 4.979686991646304e-07\n",
      "Epoch 4231, Loss: 0.0009389605994662986, Final Batch Loss: 0.0008425200940109789\n",
      "Epoch 4232, Loss: 3.679453700300428e-05, Final Batch Loss: 6.094748528084892e-07\n",
      "Epoch 4233, Loss: 1.907628687547458e-05, Final Batch Loss: 6.950356805646152e-07\n",
      "Epoch 4234, Loss: 0.0001343767291501763, Final Batch Loss: 1.927526795952872e-07\n",
      "Epoch 4235, Loss: 2.9545376357020814e-05, Final Batch Loss: 2.5812059334384685e-07\n",
      "Epoch 4236, Loss: 0.0008165508200477234, Final Batch Loss: 3.2584900964138797e-06\n",
      "Epoch 4237, Loss: 0.00021309978826167253, Final Batch Loss: 2.444338406348834e-06\n",
      "Epoch 4238, Loss: 0.001282013831271911, Final Batch Loss: 4.893259983873577e-07\n",
      "Epoch 4239, Loss: 8.12629013893229e-05, Final Batch Loss: 8.094353916021646e-07\n",
      "Epoch 4240, Loss: 5.508716731128516e-05, Final Batch Loss: 1.2702998901659157e-05\n",
      "Epoch 4241, Loss: 0.0001236638503598897, Final Batch Loss: 4.864419906880357e-07\n",
      "Epoch 4242, Loss: 0.0018799693348228175, Final Batch Loss: 2.223310548288282e-05\n",
      "Epoch 4243, Loss: 5.521742973257915e-05, Final Batch Loss: 3.4817460345948348e-06\n",
      "Epoch 4244, Loss: 0.00016470793394418592, Final Batch Loss: 0.00013948061678092927\n",
      "Epoch 4245, Loss: 4.310204781532434e-05, Final Batch Loss: 4.9990930506282893e-08\n",
      "Epoch 4246, Loss: 4.417508893084232e-05, Final Batch Loss: 1.0279345588060096e-05\n",
      "Epoch 4247, Loss: 5.1314779980771164e-05, Final Batch Loss: 2.5283617333116126e-07\n",
      "Epoch 4248, Loss: 3.413065275914562e-05, Final Batch Loss: 5.8162473948186744e-08\n",
      "Epoch 4249, Loss: 0.00014264697067289944, Final Batch Loss: 6.474671181422309e-07\n",
      "Epoch 4250, Loss: 0.000478216608515325, Final Batch Loss: 2.824328248607344e-06\n",
      "Epoch 4251, Loss: 1.585464131537151e-05, Final Batch Loss: 5.412287578110409e-07\n",
      "Epoch 4252, Loss: 6.0898348872129304e-05, Final Batch Loss: 9.950075252618262e-08\n",
      "Epoch 4253, Loss: 4.055269919156501e-05, Final Batch Loss: 2.3072743715601973e-08\n",
      "Epoch 4254, Loss: 2.3402272279149372e-05, Final Batch Loss: 6.152723841523766e-08\n",
      "Epoch 4255, Loss: 0.0028120338221810925, Final Batch Loss: 6.762737712051603e-07\n",
      "Epoch 4256, Loss: 0.0002868689280859371, Final Batch Loss: 6.508188903353584e-07\n",
      "Epoch 4257, Loss: 0.00021172618260578702, Final Batch Loss: 5.812985818920424e-06\n",
      "Epoch 4258, Loss: 9.800268907156351e-05, Final Batch Loss: 4.6000181441741006e-07\n",
      "Epoch 4259, Loss: 7.73464061580853e-05, Final Batch Loss: 2.981088300657575e-06\n",
      "Epoch 4260, Loss: 2.0297312721240246e-05, Final Batch Loss: 9.968804306481616e-07\n",
      "Epoch 4261, Loss: 4.031432785467359e-05, Final Batch Loss: 1.1584393888597333e-07\n",
      "Epoch 4262, Loss: 4.8762872680185865e-05, Final Batch Loss: 4.003922811079974e-07\n",
      "Epoch 4263, Loss: 2.2072001615747183e-05, Final Batch Loss: 1.6172208461284754e-06\n",
      "Epoch 4264, Loss: 0.0015492469003568488, Final Batch Loss: 2.2255409248828073e-07\n",
      "Epoch 4265, Loss: 0.00012607645302864512, Final Batch Loss: 6.681445796630214e-08\n",
      "Epoch 4266, Loss: 1.0317466550446852e-05, Final Batch Loss: 3.3647719277496435e-08\n",
      "Epoch 4267, Loss: 3.431788134999891e-05, Final Batch Loss: 4.357538728072541e-06\n",
      "Epoch 4268, Loss: 0.000313823730927254, Final Batch Loss: 5.253771746538405e-07\n",
      "Epoch 4269, Loss: 1.819529554403232e-05, Final Batch Loss: 5.162207799003227e-07\n",
      "Epoch 4270, Loss: 6.332997772062754e-05, Final Batch Loss: 6.614034191443352e-07\n",
      "Epoch 4271, Loss: 1.8782883877577206e-05, Final Batch Loss: 6.868535251669527e-07\n",
      "Epoch 4272, Loss: 4.926139382632755e-05, Final Batch Loss: 1.625938693905482e-06\n",
      "Epoch 4273, Loss: 1.435385050996274e-05, Final Batch Loss: 1.5189337432275352e-07\n",
      "Epoch 4274, Loss: 4.8371608265540544e-05, Final Batch Loss: 7.056175377329055e-07\n",
      "Epoch 4275, Loss: 1.5915042174796667e-05, Final Batch Loss: 3.2569219001743477e-06\n",
      "Epoch 4276, Loss: 5.621248345377694e-05, Final Batch Loss: 1.0465473678777926e-05\n",
      "Epoch 4277, Loss: 0.00014816526699945598, Final Batch Loss: 0.00013600838428828865\n",
      "Epoch 4278, Loss: 0.0005829578467988483, Final Batch Loss: 2.035436182268313e-06\n",
      "Epoch 4279, Loss: 3.577180166303151e-05, Final Batch Loss: 2.427388494652405e-07\n",
      "Epoch 4280, Loss: 6.728765745833698e-05, Final Batch Loss: 2.0232155293342657e-06\n",
      "Epoch 4281, Loss: 3.435848258526164e-05, Final Batch Loss: 7.483809554287291e-07\n",
      "Epoch 4282, Loss: 2.0726803156456697e-05, Final Batch Loss: 4.671102033171337e-06\n",
      "Epoch 4283, Loss: 0.0008814772650644898, Final Batch Loss: 0.0001094183317036368\n",
      "Epoch 4284, Loss: 1.5331336131074735e-05, Final Batch Loss: 1.3410948440650827e-07\n",
      "Epoch 4285, Loss: 7.130594389503919e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4286, Loss: 0.0025181749449920687, Final Batch Loss: 4.83140775031643e-06\n",
      "Epoch 4287, Loss: 0.03692125092096887, Final Batch Loss: 1.2017001438380248e-07\n",
      "Epoch 4288, Loss: 2.7305702502644635e-05, Final Batch Loss: 1.8695575363381067e-06\n",
      "Epoch 4289, Loss: 0.0008887410263920259, Final Batch Loss: 4.3579525481618475e-06\n",
      "Epoch 4290, Loss: 9.312465172772733e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 4291, Loss: 0.00048740892689735915, Final Batch Loss: 2.0188618776728617e-08\n",
      "Epoch 4292, Loss: 0.0003449538253521567, Final Batch Loss: 3.9896594472565994e-08\n",
      "Epoch 4293, Loss: 0.00011167411526358251, Final Batch Loss: 1.439873244635237e-06\n",
      "Epoch 4294, Loss: 0.00017523850265721563, Final Batch Loss: 2.5668038006188e-07\n",
      "Epoch 4295, Loss: 3.3319751313598545e-05, Final Batch Loss: 5.794052412966266e-06\n",
      "Epoch 4296, Loss: 0.00016175791774131199, Final Batch Loss: 2.615439598230296e-06\n",
      "Epoch 4297, Loss: 1.811618314873087e-05, Final Batch Loss: 6.248591830626538e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4298, Loss: 0.0004923040727229377, Final Batch Loss: 0.0004769207153003663\n",
      "Epoch 4299, Loss: 1.3047702735136113e-05, Final Batch Loss: 2.59567816129902e-08\n",
      "Epoch 4300, Loss: 1.897289694774429e-05, Final Batch Loss: 5.277732384456613e-07\n",
      "Epoch 4301, Loss: 0.0004285488874939958, Final Batch Loss: 1.1968955959673622e-07\n",
      "Epoch 4302, Loss: 2.302108453999807e-05, Final Batch Loss: 9.421341218285306e-08\n",
      "Epoch 4303, Loss: 0.00012532401009357486, Final Batch Loss: 6.729521118131743e-08\n",
      "Epoch 4304, Loss: 1.6549957353007017e-05, Final Batch Loss: 1.6875111441549961e-06\n",
      "Epoch 4305, Loss: 1.419897840015949e-05, Final Batch Loss: 2.2111358077836485e-08\n",
      "Epoch 4306, Loss: 0.0019350368573824994, Final Batch Loss: 8.31575519555372e-08\n",
      "Epoch 4307, Loss: 0.00018798202120251517, Final Batch Loss: 2.136390548912459e-06\n",
      "Epoch 4308, Loss: 5.103977941800508e-05, Final Batch Loss: 4.3155564526387025e-06\n",
      "Epoch 4309, Loss: 3.126659640173557e-05, Final Batch Loss: 3.4608390819812485e-07\n",
      "Epoch 4310, Loss: 0.00027708135008985835, Final Batch Loss: 1.3459105829838336e-08\n",
      "Epoch 4311, Loss: 4.091347361256936e-05, Final Batch Loss: 2.7302468197376584e-07\n",
      "Epoch 4312, Loss: 0.00015926680848110664, Final Batch Loss: 3.880392978317104e-05\n",
      "Epoch 4313, Loss: 0.00023936847073713352, Final Batch Loss: 2.1726637555730122e-07\n",
      "Epoch 4314, Loss: 3.5382239235381974e-05, Final Batch Loss: 1.7448608957693068e-07\n",
      "Epoch 4315, Loss: 0.00010879419604314933, Final Batch Loss: 4.970162876816175e-07\n",
      "Epoch 4316, Loss: 5.614078096272124e-05, Final Batch Loss: 1.8124140979125514e-06\n",
      "Epoch 4317, Loss: 5.677265339443238e-05, Final Batch Loss: 1.6729497929190984e-06\n",
      "Epoch 4318, Loss: 1.730750321904395e-05, Final Batch Loss: 5.2874835176908164e-08\n",
      "Epoch 4319, Loss: 9.766980397785119e-06, Final Batch Loss: 4.7057460506039206e-07\n",
      "Epoch 4320, Loss: 8.82780353061996e-05, Final Batch Loss: 8.387147545363405e-07\n",
      "Epoch 4321, Loss: 5.732441518624398e-05, Final Batch Loss: 1.2322116162977181e-05\n",
      "Epoch 4322, Loss: 0.00011113801511442034, Final Batch Loss: 1.2804079233319499e-05\n",
      "Epoch 4323, Loss: 6.760881764300564e-05, Final Batch Loss: 1.1193773161721765e-06\n",
      "Epoch 4324, Loss: 2.175218058830808e-05, Final Batch Loss: 7.642818644626459e-08\n",
      "Epoch 4325, Loss: 0.00010019790915283266, Final Batch Loss: 2.0524990418380185e-07\n",
      "Epoch 4326, Loss: 1.4196831564561307e-05, Final Batch Loss: 9.325204786136965e-08\n",
      "Epoch 4327, Loss: 0.00023801377220422637, Final Batch Loss: 1.0723000514190062e-06\n",
      "Epoch 4328, Loss: 6.71681597204099e-05, Final Batch Loss: 2.403391476946126e-07\n",
      "Epoch 4329, Loss: 0.00020403973095350914, Final Batch Loss: 1.8718832279773778e-06\n",
      "Epoch 4330, Loss: 5.440045608295918e-05, Final Batch Loss: 3.26371690562155e-07\n",
      "Epoch 4331, Loss: 1.7427057741770113e-05, Final Batch Loss: 1.9803844963917072e-07\n",
      "Epoch 4332, Loss: 4.8517023559568884e-05, Final Batch Loss: 4.6145466114921874e-08\n",
      "Epoch 4333, Loss: 0.00014323480431244207, Final Batch Loss: 1.3507087714970112e-07\n",
      "Epoch 4334, Loss: 9.17072438078037e-06, Final Batch Loss: 1.1501693961690762e-06\n",
      "Epoch 4335, Loss: 0.0001646414509774985, Final Batch Loss: 5.479751763459717e-08\n",
      "Epoch 4336, Loss: 5.304909481029796e-05, Final Batch Loss: 8.65227889335074e-09\n",
      "Epoch 4337, Loss: 4.786707902049159e-06, Final Batch Loss: 2.605258089261042e-07\n",
      "Epoch 4338, Loss: 8.111273942290609e-05, Final Batch Loss: 6.152726683694709e-08\n",
      "Epoch 4339, Loss: 4.048635055120542e-05, Final Batch Loss: 3.465615634468122e-07\n",
      "Epoch 4340, Loss: 0.0001632466754539763, Final Batch Loss: 5.47467948308622e-07\n",
      "Epoch 4341, Loss: 1.133861353963539e-05, Final Batch Loss: 2.3553413441845805e-08\n",
      "Epoch 4342, Loss: 0.000131206195779221, Final Batch Loss: 1.509327489657153e-07\n",
      "Epoch 4343, Loss: 1.4198541188337188e-05, Final Batch Loss: 3.028298323215495e-08\n",
      "Epoch 4344, Loss: 0.0002268641034852692, Final Batch Loss: 1.3314765112681926e-07\n",
      "Epoch 4345, Loss: 6.78769057227413e-05, Final Batch Loss: 1.3531705917557701e-05\n",
      "Epoch 4346, Loss: 5.607212193670108e-06, Final Batch Loss: 7.210201147245243e-08\n",
      "Epoch 4347, Loss: 9.099475602702967e-05, Final Batch Loss: 1.163235552326114e-07\n",
      "Epoch 4348, Loss: 5.6512804547992346e-05, Final Batch Loss: 9.084865837394318e-08\n",
      "Epoch 4349, Loss: 0.000733773276294869, Final Batch Loss: 1.1055554693939484e-07\n",
      "Epoch 4350, Loss: 0.001911630312456225, Final Batch Loss: 7.210194041817886e-08\n",
      "Epoch 4351, Loss: 4.653187385628144e-06, Final Batch Loss: 1.0861982673304738e-06\n",
      "Epoch 4352, Loss: 6.97564605149914e-05, Final Batch Loss: 8.123487305056187e-08\n",
      "Epoch 4353, Loss: 1.7063515149295938e-05, Final Batch Loss: 6.248826167620791e-08\n",
      "Epoch 4354, Loss: 1.6696250043524152e-05, Final Batch Loss: 3.220568700612603e-08\n",
      "Epoch 4355, Loss: 2.003992144472555e-05, Final Batch Loss: 5.2394273808431535e-08\n",
      "Epoch 4356, Loss: 0.00029660992499591643, Final Batch Loss: 1.2497737067462822e-08\n",
      "Epoch 4357, Loss: 0.00011438745212333234, Final Batch Loss: 3.0330002687151136e-07\n",
      "Epoch 4358, Loss: 2.11346384459965e-06, Final Batch Loss: 6.262810074986191e-07\n",
      "Epoch 4359, Loss: 5.164216522590692e-05, Final Batch Loss: 1.1481972705951193e-06\n",
      "Epoch 4360, Loss: 9.401758612148647e-05, Final Batch Loss: 1.1536219091112798e-07\n",
      "Epoch 4361, Loss: 1.5093369059804296e-05, Final Batch Loss: 2.3841226948206895e-07\n",
      "Epoch 4362, Loss: 8.36115558011663e-07, Final Batch Loss: 2.932153719825692e-08\n",
      "Epoch 4363, Loss: 1.3689194153232442e-05, Final Batch Loss: 3.2060609100881265e-07\n",
      "Epoch 4364, Loss: 0.00013493281054355322, Final Batch Loss: 0.00013289634080138057\n",
      "Epoch 4365, Loss: 0.0006456913970467326, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 4366, Loss: 5.357442794950984e-06, Final Batch Loss: 4.9029516446807975e-08\n",
      "Epoch 4367, Loss: 7.253144778118781e-06, Final Batch Loss: 5.815867325509316e-07\n",
      "Epoch 4368, Loss: 0.000993941708300916, Final Batch Loss: 1.1920847953206248e-07\n",
      "Epoch 4369, Loss: 0.0007256056163762459, Final Batch Loss: 6.001238944008946e-06\n",
      "Epoch 4370, Loss: 0.00013733491096012962, Final Batch Loss: 1.4845829355181195e-05\n",
      "Epoch 4371, Loss: 0.0001662730339313523, Final Batch Loss: 4.5871103793615475e-05\n",
      "Epoch 4372, Loss: 5.8578204203740825e-05, Final Batch Loss: 5.171859243091603e-07\n",
      "Epoch 4373, Loss: 0.0008451923640979686, Final Batch Loss: 5.220702860242454e-06\n",
      "Epoch 4374, Loss: 2.1623532304726467e-06, Final Batch Loss: 9.132961942270867e-09\n",
      "Epoch 4375, Loss: 0.007007615113134635, Final Batch Loss: 1.5958515575675847e-07\n",
      "Epoch 4376, Loss: 0.00040102875682102024, Final Batch Loss: 2.3734999558655545e-05\n",
      "Epoch 4377, Loss: 0.0012226011634481893, Final Batch Loss: 1.6500431456734077e-06\n",
      "Epoch 4378, Loss: 6.737126608413746e-05, Final Batch Loss: 1.8325328028367949e-06\n",
      "Epoch 4379, Loss: 0.00018074483245733575, Final Batch Loss: 8.171180070348782e-07\n",
      "Epoch 4380, Loss: 0.0004127455452351825, Final Batch Loss: 2.2447673586611927e-07\n",
      "Epoch 4381, Loss: 2.004438042035872e-05, Final Batch Loss: 8.853240274220298e-07\n",
      "Epoch 4382, Loss: 1.2399432824050649e-05, Final Batch Loss: 2.5042828610821743e-07\n",
      "Epoch 4383, Loss: 0.00028619995346756966, Final Batch Loss: 1.2443481409718515e-06\n",
      "Epoch 4384, Loss: 8.768537383185837e-05, Final Batch Loss: 1.903480892906373e-07\n",
      "Epoch 4385, Loss: 2.978574324519201e-05, Final Batch Loss: 3.893516620223636e-08\n",
      "Epoch 4386, Loss: 0.0003641503858951012, Final Batch Loss: 1.1632418761564622e-07\n",
      "Epoch 4387, Loss: 1.3274502623339401e-05, Final Batch Loss: 3.316706553846416e-08\n",
      "Epoch 4388, Loss: 6.753583629404147e-05, Final Batch Loss: 1.81830762358004e-06\n",
      "Epoch 4389, Loss: 1.2652486223396764e-05, Final Batch Loss: 1.51894198552327e-07\n",
      "Epoch 4390, Loss: 0.00011977895542081285, Final Batch Loss: 5.191343532828796e-08\n",
      "Epoch 4391, Loss: 0.0002607609236946473, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4392, Loss: 0.00011334783265226633, Final Batch Loss: 2.7879520914098066e-08\n",
      "Epoch 4393, Loss: 9.398413679306827e-06, Final Batch Loss: 2.7398884938634183e-08\n",
      "Epoch 4394, Loss: 4.067516564965068e-05, Final Batch Loss: 9.795900268727564e-07\n",
      "Epoch 4395, Loss: 2.959130792845599e-06, Final Batch Loss: 6.7295542471867975e-09\n",
      "Epoch 4396, Loss: 3.0275587252770464e-05, Final Batch Loss: 4.989206559002923e-07\n",
      "Epoch 4397, Loss: 7.977651282642384e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4398, Loss: 8.462451583035602e-06, Final Batch Loss: 1.0046199605540096e-07\n",
      "Epoch 4399, Loss: 0.00019154130343213005, Final Batch Loss: 2.884095406940901e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4400, Loss: 8.007052871406017e-06, Final Batch Loss: 3.4855179364967626e-06\n",
      "Epoch 4401, Loss: 5.383221136878724e-05, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 4402, Loss: 0.0010124408981035948, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 4403, Loss: 6.885429109093621e-07, Final Batch Loss: 0.0\n",
      "Epoch 4404, Loss: 3.7311697160813395e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4405, Loss: 9.18305135944042e-06, Final Batch Loss: 1.3928365660831332e-06\n",
      "Epoch 4406, Loss: 5.5807932624718504e-05, Final Batch Loss: 2.0188647198438048e-08\n",
      "Epoch 4407, Loss: 0.00014474233797967528, Final Batch Loss: 1.970796681405318e-08\n",
      "Epoch 4408, Loss: 0.00014954265902289432, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4409, Loss: 8.488005701634549e-07, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4410, Loss: 4.975633361892218e-05, Final Batch Loss: 6.094646778365131e-07\n",
      "Epoch 4411, Loss: 2.026449206105063e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4412, Loss: 1.165289922688828e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4413, Loss: 4.683904268110162e-06, Final Batch Loss: 6.681435138489178e-08\n",
      "Epoch 4414, Loss: 2.9414516054870887e-05, Final Batch Loss: 1.9515300664352253e-07\n",
      "Epoch 4415, Loss: 3.5393300212849255e-06, Final Batch Loss: 7.354417874694263e-08\n",
      "Epoch 4416, Loss: 0.0010480951719392673, Final Batch Loss: 1.2222521945659537e-05\n",
      "Epoch 4417, Loss: 0.009178422767377237, Final Batch Loss: 1.3795479958389478e-07\n",
      "Epoch 4418, Loss: 0.0038979396118230536, Final Batch Loss: 1.0046198184454624e-07\n",
      "Epoch 4419, Loss: 0.0009065153186860186, Final Batch Loss: 2.148606483842741e-07\n",
      "Epoch 4420, Loss: 0.0002609021808623879, Final Batch Loss: 0.00011413724132580683\n",
      "Epoch 4421, Loss: 9.179280532212175e-05, Final Batch Loss: 1.7743437865647138e-06\n",
      "Epoch 4422, Loss: 1.1132396502411268e-05, Final Batch Loss: 9.613642326655736e-09\n",
      "Epoch 4423, Loss: 0.0004984342509439799, Final Batch Loss: 5.7681795340158715e-08\n",
      "Epoch 4424, Loss: 3.509480554952926e-05, Final Batch Loss: 8.60862712670496e-07\n",
      "Epoch 4425, Loss: 0.05556234776854285, Final Batch Loss: 2.9802283307844846e-08\n",
      "Epoch 4426, Loss: 0.014666315483228054, Final Batch Loss: 9.950084489673827e-08\n",
      "Epoch 4427, Loss: 0.04687212849540856, Final Batch Loss: 2.5664514851087006e-06\n",
      "Epoch 4428, Loss: 0.00010975877025742875, Final Batch Loss: 1.1700019058480393e-05\n",
      "Epoch 4429, Loss: 4.465107996054485e-05, Final Batch Loss: 3.908568487531738e-06\n",
      "Epoch 4430, Loss: 0.0014794781151934444, Final Batch Loss: 1.6947903986874735e-06\n",
      "Epoch 4431, Loss: 0.0013984717685673331, Final Batch Loss: 3.6539715893013636e-06\n",
      "Epoch 4432, Loss: 0.00010635323630392435, Final Batch Loss: 7.65221386700432e-07\n",
      "Epoch 4433, Loss: 5.9055715240674544e-05, Final Batch Loss: 1.2620257621165365e-05\n",
      "Epoch 4434, Loss: 0.0010057926786544158, Final Batch Loss: 3.7238812637951924e-06\n",
      "Epoch 4435, Loss: 0.00013261982267920303, Final Batch Loss: 5.526877430384047e-06\n",
      "Epoch 4436, Loss: 0.00027837299205657473, Final Batch Loss: 9.296196026298276e-07\n",
      "Epoch 4437, Loss: 0.00010249073847035106, Final Batch Loss: 6.783361459383741e-05\n",
      "Epoch 4438, Loss: 0.00029083338682767135, Final Batch Loss: 1.2066716408298817e-05\n",
      "Epoch 4439, Loss: 0.00026045963784326887, Final Batch Loss: 7.845935215300415e-06\n",
      "Epoch 4440, Loss: 0.0006578396395298114, Final Batch Loss: 9.618083822715562e-07\n",
      "Epoch 4441, Loss: 0.0004847551702198416, Final Batch Loss: 0.00010153901530429721\n",
      "Epoch 4442, Loss: 8.378662549546334e-05, Final Batch Loss: 7.877972620917717e-07\n",
      "Epoch 4443, Loss: 8.70295999817472e-05, Final Batch Loss: 3.3330643418594263e-06\n",
      "Epoch 4444, Loss: 0.0002541860772709015, Final Batch Loss: 3.6055647797184065e-05\n",
      "Epoch 4445, Loss: 7.297786089566216e-05, Final Batch Loss: 5.425496055977419e-06\n",
      "Epoch 4446, Loss: 0.00021570947967575194, Final Batch Loss: 1.0526515552555793e-06\n",
      "Epoch 4447, Loss: 0.00013426346474432194, Final Batch Loss: 1.4228105271740787e-07\n",
      "Epoch 4448, Loss: 5.638204746105657e-05, Final Batch Loss: 1.0493530680832919e-05\n",
      "Epoch 4449, Loss: 0.0029946564624765415, Final Batch Loss: 0.0028849036898463964\n",
      "Epoch 4450, Loss: 0.00031809736956134316, Final Batch Loss: 6.609127467527287e-07\n",
      "Epoch 4451, Loss: 0.00015780369939477623, Final Batch Loss: 7.73915417084936e-06\n",
      "Epoch 4452, Loss: 0.00046064046326677044, Final Batch Loss: 8.776491426942812e-07\n",
      "Epoch 4453, Loss: 3.239082685979611e-05, Final Batch Loss: 6.912068215569889e-07\n",
      "Epoch 4454, Loss: 6.250767688698033e-05, Final Batch Loss: 9.6194880825351e-06\n",
      "Epoch 4455, Loss: 0.010317197470214978, Final Batch Loss: 2.2430533590522828e-06\n",
      "Epoch 4456, Loss: 0.0006761576868470343, Final Batch Loss: 0.0003270054003223777\n",
      "Epoch 4457, Loss: 0.0018556883451523731, Final Batch Loss: 1.6955356841208413e-05\n",
      "Epoch 4458, Loss: 0.01083636678639266, Final Batch Loss: 3.0692085601913277e-06\n",
      "Epoch 4459, Loss: 0.00038913266681106506, Final Batch Loss: 6.971508264541626e-05\n",
      "Epoch 4460, Loss: 0.0014844073870108332, Final Batch Loss: 6.299757387751015e-06\n",
      "Epoch 4461, Loss: 0.00011426014771132031, Final Batch Loss: 1.6102781330573634e-07\n",
      "Epoch 4462, Loss: 0.0007762529202182122, Final Batch Loss: 0.0005087106837891042\n",
      "Epoch 4463, Loss: 0.0007232602882680794, Final Batch Loss: 6.314846359600779e-06\n",
      "Epoch 4464, Loss: 5.132616176695137e-05, Final Batch Loss: 5.425506515166489e-06\n",
      "Epoch 4465, Loss: 0.07581678833631145, Final Batch Loss: 0.0013763634487986565\n",
      "Epoch 4466, Loss: 0.002800710843075649, Final Batch Loss: 0.00013629646855406463\n",
      "Epoch 4467, Loss: 0.0055602572606403555, Final Batch Loss: 2.03236431843834e-05\n",
      "Epoch 4468, Loss: 0.0010495262531549088, Final Batch Loss: 1.5310635717469268e-05\n",
      "Epoch 4469, Loss: 0.0005771647029177984, Final Batch Loss: 2.4097129426081665e-05\n",
      "Epoch 4470, Loss: 0.0025762649895568757, Final Batch Loss: 0.0007292394293472171\n",
      "Epoch 4471, Loss: 0.00036950874664398725, Final Batch Loss: 4.354893462732434e-06\n",
      "Epoch 4472, Loss: 0.0005865375883331581, Final Batch Loss: 0.0001878147159004584\n",
      "Epoch 4473, Loss: 0.00036989290515521134, Final Batch Loss: 3.168768307659775e-05\n",
      "Epoch 4474, Loss: 0.0007149639075691994, Final Batch Loss: 2.9994331271154806e-05\n",
      "Epoch 4475, Loss: 0.00026006596760907996, Final Batch Loss: 6.07602441959898e-06\n",
      "Epoch 4476, Loss: 0.0001342924259688516, Final Batch Loss: 3.6204862681188388e-06\n",
      "Epoch 4477, Loss: 0.001441460854849197, Final Batch Loss: 6.069166829547612e-06\n",
      "Epoch 4478, Loss: 0.0008358368332892496, Final Batch Loss: 0.000720989250112325\n",
      "Epoch 4479, Loss: 0.0003119430045188665, Final Batch Loss: 8.60522959555965e-06\n",
      "Epoch 4480, Loss: 0.0001953775275467251, Final Batch Loss: 3.5318892059876816e-06\n",
      "Epoch 4481, Loss: 0.00032085407585213943, Final Batch Loss: 3.441618048327655e-07\n",
      "Epoch 4482, Loss: 0.00017113810848456978, Final Batch Loss: 7.1019894676283e-06\n",
      "Epoch 4483, Loss: 0.00015501871268952527, Final Batch Loss: 1.4664881291537313e-06\n",
      "Epoch 4484, Loss: 0.0001272133684722121, Final Batch Loss: 3.1997776659409283e-06\n",
      "Epoch 4485, Loss: 7.59401725929365e-05, Final Batch Loss: 1.6144800838446827e-06\n",
      "Epoch 4486, Loss: 6.673065109907839e-05, Final Batch Loss: 1.0968478818540461e-06\n",
      "Epoch 4487, Loss: 5.131160281734992e-05, Final Batch Loss: 5.297084726407775e-07\n",
      "Epoch 4488, Loss: 0.0002608204003990977, Final Batch Loss: 1.2011755643470678e-06\n",
      "Epoch 4489, Loss: 0.00016210744516342857, Final Batch Loss: 1.1280834542048979e-06\n",
      "Epoch 4490, Loss: 0.00011185125633517146, Final Batch Loss: 1.260736667063611e-06\n",
      "Epoch 4491, Loss: 0.00047042802768260117, Final Batch Loss: 1.0247932777929236e-06\n",
      "Epoch 4492, Loss: 0.00014018441055441144, Final Batch Loss: 7.083883247105405e-05\n",
      "Epoch 4493, Loss: 0.00017116566914410214, Final Batch Loss: 2.6965688448399305e-05\n",
      "Epoch 4494, Loss: 0.001553419536662659, Final Batch Loss: 3.508947372665716e-07\n",
      "Epoch 4495, Loss: 0.00023981856838872773, Final Batch Loss: 7.418491441057995e-05\n",
      "Epoch 4496, Loss: 0.00020150426360032725, Final Batch Loss: 5.739031621487811e-06\n",
      "Epoch 4497, Loss: 0.000458578635914364, Final Batch Loss: 8.238664008786145e-07\n",
      "Epoch 4498, Loss: 0.0008256055646427285, Final Batch Loss: 3.0872015486238524e-06\n",
      "Epoch 4499, Loss: 0.00010174435071519383, Final Batch Loss: 2.763568227237556e-05\n",
      "Epoch 4500, Loss: 0.028615416964726137, Final Batch Loss: 0.02845311537384987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4501, Loss: 6.983211169142578e-05, Final Batch Loss: 1.304458805861941e-06\n",
      "Epoch 4502, Loss: 0.0010409481615454297, Final Batch Loss: 0.0005159533466212451\n",
      "Epoch 4503, Loss: 0.0004016019147172756, Final Batch Loss: 0.0002691716072149575\n",
      "Epoch 4504, Loss: 0.00010014575366312783, Final Batch Loss: 1.55309298861539e-05\n",
      "Epoch 4505, Loss: 0.00017072486705416168, Final Batch Loss: 4.7320572775788605e-05\n",
      "Epoch 4506, Loss: 0.0004886012150677743, Final Batch Loss: 4.114568810109631e-07\n",
      "Epoch 4507, Loss: 7.826429391855072e-05, Final Batch Loss: 1.6798313708932255e-06\n",
      "Epoch 4508, Loss: 7.483612671421724e-05, Final Batch Loss: 6.155981736810645e-06\n",
      "Epoch 4509, Loss: 0.0055210666141078946, Final Batch Loss: 8.099259503069334e-06\n",
      "Epoch 4510, Loss: 0.0001774165500592062, Final Batch Loss: 6.317773659247905e-05\n",
      "Epoch 4511, Loss: 0.0010597652439514604, Final Batch Loss: 0.0008300976478494704\n",
      "Epoch 4512, Loss: 0.0005107521159288808, Final Batch Loss: 9.549956303089857e-06\n",
      "Epoch 4513, Loss: 0.013185797832534263, Final Batch Loss: 1.8307790696781012e-06\n",
      "Epoch 4514, Loss: 0.004368005513299522, Final Batch Loss: 3.3393034755135886e-06\n",
      "Epoch 4515, Loss: 6.397980156691574e-05, Final Batch Loss: 3.3473388612037525e-06\n",
      "Epoch 4516, Loss: 0.0003630946872590357, Final Batch Loss: 0.0001412199198966846\n",
      "Epoch 4517, Loss: 0.00019171773169546213, Final Batch Loss: 9.203467925544828e-05\n",
      "Epoch 4518, Loss: 0.0006457294953179371, Final Batch Loss: 1.954283561644843e-06\n",
      "Epoch 4519, Loss: 0.00013241701020660912, Final Batch Loss: 3.831438334600534e-06\n",
      "Epoch 4520, Loss: 0.00032482613057993603, Final Batch Loss: 5.474499630508944e-06\n",
      "Epoch 4521, Loss: 9.534510581943323e-05, Final Batch Loss: 9.432217666471843e-06\n",
      "Epoch 4522, Loss: 0.00012268457408737277, Final Batch Loss: 1.2006478300463641e-06\n",
      "Epoch 4523, Loss: 0.00024877580574411695, Final Batch Loss: 4.263559958417318e-07\n",
      "Epoch 4524, Loss: 0.001813079043728294, Final Batch Loss: 1.946629254234722e-06\n",
      "Epoch 4525, Loss: 0.0005467168928703359, Final Batch Loss: 6.042929271643516e-06\n",
      "Epoch 4526, Loss: 0.0008015744129465929, Final Batch Loss: 3.501657829474425e-06\n",
      "Epoch 4527, Loss: 0.00021975827314690832, Final Batch Loss: 2.3247201170306653e-05\n",
      "Epoch 4528, Loss: 0.00017254209942052512, Final Batch Loss: 4.828983492188854e-06\n",
      "Epoch 4529, Loss: 0.00011392981411972869, Final Batch Loss: 2.8662905151577434e-06\n",
      "Epoch 4530, Loss: 7.550460556160488e-05, Final Batch Loss: 9.289619811170269e-06\n",
      "Epoch 4531, Loss: 0.00013445482771601291, Final Batch Loss: 2.7861851776833646e-06\n",
      "Epoch 4532, Loss: 6.0327881826083285e-05, Final Batch Loss: 4.72024794362369e-06\n",
      "Epoch 4533, Loss: 0.0018470855930559082, Final Batch Loss: 2.421006229269551e-06\n",
      "Epoch 4534, Loss: 0.00043995584178446734, Final Batch Loss: 1.4404562534764409e-05\n",
      "Epoch 4535, Loss: 0.0002902588379072313, Final Batch Loss: 1.0273541192873381e-05\n",
      "Epoch 4536, Loss: 0.00024321570987240193, Final Batch Loss: 1.238568984263111e-06\n",
      "Epoch 4537, Loss: 7.147427959353081e-05, Final Batch Loss: 2.655639036674984e-06\n",
      "Epoch 4538, Loss: 0.001109035821798443, Final Batch Loss: 1.0430004522277159e-06\n",
      "Epoch 4539, Loss: 6.277992571313007e-05, Final Batch Loss: 8.670890565554146e-07\n",
      "Epoch 4540, Loss: 5.596243748584584e-05, Final Batch Loss: 2.152483102690894e-05\n",
      "Epoch 4541, Loss: 3.015135136763547e-05, Final Batch Loss: 2.1576199742412427e-06\n",
      "Epoch 4542, Loss: 0.00011588949257657077, Final Batch Loss: 6.277409170252213e-07\n",
      "Epoch 4543, Loss: 3.8230462521937625e-05, Final Batch Loss: 2.0717145332582731e-07\n",
      "Epoch 4544, Loss: 8.135805444453581e-05, Final Batch Loss: 3.749296126898116e-07\n",
      "Epoch 4545, Loss: 7.305096238496844e-05, Final Batch Loss: 6.839869115538022e-07\n",
      "Epoch 4546, Loss: 0.00010109056664475702, Final Batch Loss: 4.6048526769482123e-07\n",
      "Epoch 4547, Loss: 9.561437656202543e-05, Final Batch Loss: 3.0390851861739065e-06\n",
      "Epoch 4548, Loss: 1.5788509827530106e-05, Final Batch Loss: 1.8932373677671421e-06\n",
      "Epoch 4549, Loss: 1.745270468234139e-05, Final Batch Loss: 1.990292503251112e-06\n",
      "Epoch 4550, Loss: 0.00018824182426868674, Final Batch Loss: 2.3264885840035276e-07\n",
      "Epoch 4551, Loss: 0.0004692753737174371, Final Batch Loss: 7.402459800687211e-08\n",
      "Epoch 4552, Loss: 2.5179170208389223e-05, Final Batch Loss: 1.0806472346303053e-05\n",
      "Epoch 4553, Loss: 2.499690862123316e-05, Final Batch Loss: 1.7881141900488728e-07\n",
      "Epoch 4554, Loss: 8.550244628224846e-05, Final Batch Loss: 3.8125735954963602e-06\n",
      "Epoch 4555, Loss: 0.0001756505770771355, Final Batch Loss: 6.657351150352042e-07\n",
      "Epoch 4556, Loss: 5.799409623818974e-05, Final Batch Loss: 3.1532397315459093e-07\n",
      "Epoch 4557, Loss: 0.00015075192444413688, Final Batch Loss: 1.6696684497219394e-06\n",
      "Epoch 4558, Loss: 1.454423368585367e-05, Final Batch Loss: 3.1859276532486547e-06\n",
      "Epoch 4559, Loss: 3.408513116198719e-05, Final Batch Loss: 2.5716380491758173e-07\n",
      "Epoch 4560, Loss: 0.0001504044926576853, Final Batch Loss: 4.90770730721124e-07\n",
      "Epoch 4561, Loss: 1.919292808594264e-05, Final Batch Loss: 4.965315838489914e-07\n",
      "Epoch 4562, Loss: 5.1015796039166617e-05, Final Batch Loss: 7.560926746918994e-07\n",
      "Epoch 4563, Loss: 1.832076327445975e-05, Final Batch Loss: 1.0665445415725117e-06\n",
      "Epoch 4564, Loss: 0.00010893679498025222, Final Batch Loss: 5.116813554195687e-06\n",
      "Epoch 4565, Loss: 5.13884521495811e-05, Final Batch Loss: 3.00423124599547e-07\n",
      "Epoch 4566, Loss: 1.6428077458385815e-05, Final Batch Loss: 5.623978438507038e-08\n",
      "Epoch 4567, Loss: 0.00010966949872948106, Final Batch Loss: 6.027387939866458e-07\n",
      "Epoch 4568, Loss: 2.2814722242969765e-05, Final Batch Loss: 4.951009202613932e-08\n",
      "Epoch 4569, Loss: 7.559781379029573e-05, Final Batch Loss: 1.1492624025777332e-06\n",
      "Epoch 4570, Loss: 1.709368723368243e-05, Final Batch Loss: 6.128531708782248e-07\n",
      "Epoch 4571, Loss: 5.189540291539174e-05, Final Batch Loss: 2.831285883075907e-06\n",
      "Epoch 4572, Loss: 2.2830189621458885e-05, Final Batch Loss: 1.0767258373789446e-07\n",
      "Epoch 4573, Loss: 9.104767580936368e-05, Final Batch Loss: 9.47408170759445e-06\n",
      "Epoch 4574, Loss: 0.0002140841038169583, Final Batch Loss: 9.590770787326619e-06\n",
      "Epoch 4575, Loss: 0.00027658552185272356, Final Batch Loss: 2.666687350938446e-06\n",
      "Epoch 4576, Loss: 2.4469734196230775e-05, Final Batch Loss: 3.3884248296089936e-06\n",
      "Epoch 4577, Loss: 2.1415410543568214e-05, Final Batch Loss: 2.4769058200035943e-06\n",
      "Epoch 4578, Loss: 1.2397443605038916e-05, Final Batch Loss: 5.2874948863745885e-08\n",
      "Epoch 4579, Loss: 2.929677625118643e-05, Final Batch Loss: 1.1260991641393048e-06\n",
      "Epoch 4580, Loss: 2.722862223691891e-05, Final Batch Loss: 9.184978466691973e-07\n",
      "Epoch 4581, Loss: 2.8091663629936647e-05, Final Batch Loss: 4.1376920307811815e-06\n",
      "Epoch 4582, Loss: 1.8051779171912585e-05, Final Batch Loss: 2.0911829778924584e-06\n",
      "Epoch 4583, Loss: 2.5315737904207936e-05, Final Batch Loss: 2.860018639694317e-07\n",
      "Epoch 4584, Loss: 2.6598661600374385e-05, Final Batch Loss: 1.7785245276513706e-08\n",
      "Epoch 4585, Loss: 0.00018718127250849648, Final Batch Loss: 1.3663823210663395e-06\n",
      "Epoch 4586, Loss: 2.8123213013486748e-05, Final Batch Loss: 1.2294082125663408e-06\n",
      "Epoch 4587, Loss: 0.00013378974202993277, Final Batch Loss: 1.4053205177333439e-06\n",
      "Epoch 4588, Loss: 2.2416234136013458e-05, Final Batch Loss: 5.374964530346915e-06\n",
      "Epoch 4589, Loss: 1.664631169973063e-05, Final Batch Loss: 2.3601266718742409e-07\n",
      "Epoch 4590, Loss: 1.0723827028158439e-05, Final Batch Loss: 6.565876446984475e-07\n",
      "Epoch 4591, Loss: 4.106628885836017e-06, Final Batch Loss: 6.820417866038042e-07\n",
      "Epoch 4592, Loss: 3.111206871153627e-05, Final Batch Loss: 1.225735957177676e-07\n",
      "Epoch 4593, Loss: 5.355444406163201e-05, Final Batch Loss: 8.147045491568861e-07\n",
      "Epoch 4594, Loss: 0.00012327006494849968, Final Batch Loss: 0.00010970722360070795\n",
      "Epoch 4595, Loss: 3.439170076546816e-05, Final Batch Loss: 9.805850709199149e-08\n",
      "Epoch 4596, Loss: 7.181405964473697e-05, Final Batch Loss: 4.9029544868517405e-08\n",
      "Epoch 4597, Loss: 0.0002841228149463859, Final Batch Loss: 7.071236268529901e-06\n",
      "Epoch 4598, Loss: 4.1160098728454386e-05, Final Batch Loss: 4.49786148237763e-06\n",
      "Epoch 4599, Loss: 0.00011989098644704654, Final Batch Loss: 7.647469146832009e-07\n",
      "Epoch 4600, Loss: 4.3016010856433695e-05, Final Batch Loss: 2.8888209158139944e-07\n",
      "Epoch 4601, Loss: 1.6038054369005295e-05, Final Batch Loss: 2.720326165217557e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4602, Loss: 7.859378818864116e-05, Final Batch Loss: 2.7566313747229287e-06\n",
      "Epoch 4603, Loss: 1.1011309011266235e-05, Final Batch Loss: 6.39305142158264e-08\n",
      "Epoch 4604, Loss: 0.00013421423048498582, Final Batch Loss: 5.654751021211268e-06\n",
      "Epoch 4605, Loss: 0.0001265000020964635, Final Batch Loss: 4.668839210353326e-06\n",
      "Epoch 4606, Loss: 8.728770375476813e-05, Final Batch Loss: 8.81062476310035e-07\n",
      "Epoch 4607, Loss: 0.00014880218024515557, Final Batch Loss: 1.0623013935173731e-07\n",
      "Epoch 4608, Loss: 3.0686643839317185e-05, Final Batch Loss: 1.7977339439312345e-07\n",
      "Epoch 4609, Loss: 0.00021175233682235728, Final Batch Loss: 2.571589163835597e-07\n",
      "Epoch 4610, Loss: 2.1250649420601064e-05, Final Batch Loss: 4.62919206256629e-06\n",
      "Epoch 4611, Loss: 6.471857165735173e-06, Final Batch Loss: 3.6051130081204974e-08\n",
      "Epoch 4612, Loss: 9.75552080983988e-06, Final Batch Loss: 4.2971683456016763e-07\n",
      "Epoch 4613, Loss: 2.1870379242505678e-05, Final Batch Loss: 1.2386215075821383e-06\n",
      "Epoch 4614, Loss: 2.055374636800167e-05, Final Batch Loss: 6.64263382077479e-07\n",
      "Epoch 4615, Loss: 0.00012146643260280143, Final Batch Loss: 1.2016977279927232e-07\n",
      "Epoch 4616, Loss: 0.0007368000006753306, Final Batch Loss: 2.172660771293522e-07\n",
      "Epoch 4617, Loss: 1.87200524042197e-05, Final Batch Loss: 2.2592056225789747e-08\n",
      "Epoch 4618, Loss: 0.0002904949035755777, Final Batch Loss: 2.5572069262125297e-07\n",
      "Epoch 4619, Loss: 1.6413099367618145e-05, Final Batch Loss: 4.4172935531605617e-07\n",
      "Epoch 4620, Loss: 0.00012953221415834548, Final Batch Loss: 0.0001237708784174174\n",
      "Epoch 4621, Loss: 7.349730385897146e-05, Final Batch Loss: 1.2049735005348339e-06\n",
      "Epoch 4622, Loss: 0.00027904242972809357, Final Batch Loss: 8.142370120367559e-07\n",
      "Epoch 4623, Loss: 2.2166343409679712e-05, Final Batch Loss: 2.09673953577294e-06\n",
      "Epoch 4624, Loss: 3.644807528146998e-05, Final Batch Loss: 2.7819169190479442e-06\n",
      "Epoch 4625, Loss: 0.00012261671592384005, Final Batch Loss: 1.0338983884139452e-05\n",
      "Epoch 4626, Loss: 1.7365581175710076e-05, Final Batch Loss: 1.4783290680497885e-06\n",
      "Epoch 4627, Loss: 0.000193295277439276, Final Batch Loss: 4.3404304506111657e-07\n",
      "Epoch 4628, Loss: 2.3628809875830825e-05, Final Batch Loss: 4.234359494148521e-06\n",
      "Epoch 4629, Loss: 8.404085726887445e-05, Final Batch Loss: 6.171572749735788e-05\n",
      "Epoch 4630, Loss: 3.50019672197277e-05, Final Batch Loss: 1.5477912995720544e-07\n",
      "Epoch 4631, Loss: 9.197099789304275e-06, Final Batch Loss: 1.75445961758669e-07\n",
      "Epoch 4632, Loss: 0.00014104989083563169, Final Batch Loss: 9.540945029584691e-05\n",
      "Epoch 4633, Loss: 4.2936829768081e-05, Final Batch Loss: 6.489202064585697e-08\n",
      "Epoch 4634, Loss: 7.415185580494921e-05, Final Batch Loss: 2.1053595844477968e-07\n",
      "Epoch 4635, Loss: 1.3926362762539668e-05, Final Batch Loss: 2.7975340799457626e-07\n",
      "Epoch 4636, Loss: 1.0336447195946619e-05, Final Batch Loss: 4.326135893961691e-08\n",
      "Epoch 4637, Loss: 2.023200958589655e-05, Final Batch Loss: 5.089855221740436e-06\n",
      "Epoch 4638, Loss: 0.00010981157510592254, Final Batch Loss: 5.179326035431586e-05\n",
      "Epoch 4639, Loss: 0.000132379153157558, Final Batch Loss: 4.239451811827166e-07\n",
      "Epoch 4640, Loss: 9.94777080869369e-05, Final Batch Loss: 1.2930281911849306e-07\n",
      "Epoch 4641, Loss: 9.155280420003464e-06, Final Batch Loss: 3.989654118186081e-08\n",
      "Epoch 4642, Loss: 7.358056647976952e-06, Final Batch Loss: 1.7592837764368596e-07\n",
      "Epoch 4643, Loss: 6.9396631655394e-05, Final Batch Loss: 4.854876323179269e-08\n",
      "Epoch 4644, Loss: 6.586277338627156e-06, Final Batch Loss: 6.53726672794619e-08\n",
      "Epoch 4645, Loss: 1.707280857132787e-05, Final Batch Loss: 1.4658237432740862e-06\n",
      "Epoch 4646, Loss: 4.0665500335990146e-05, Final Batch Loss: 9.175531658911495e-07\n",
      "Epoch 4647, Loss: 2.9516372116233924e-05, Final Batch Loss: 9.766436050995253e-07\n",
      "Epoch 4648, Loss: 6.221019882790557e-06, Final Batch Loss: 1.7320628558081808e-06\n",
      "Epoch 4649, Loss: 4.136045505731545e-05, Final Batch Loss: 5.7201027914288716e-08\n",
      "Epoch 4650, Loss: 0.0006083371245040325, Final Batch Loss: 0.0001368124212604016\n",
      "Epoch 4651, Loss: 5.0808734167517855e-05, Final Batch Loss: 5.287499149631003e-08\n",
      "Epoch 4652, Loss: 1.5535138516042934e-05, Final Batch Loss: 4.566471289990659e-08\n",
      "Epoch 4653, Loss: 2.098090967095345e-05, Final Batch Loss: 4.321262849771301e-07\n",
      "Epoch 4654, Loss: 3.272606949433765e-05, Final Batch Loss: 7.305729923245963e-07\n",
      "Epoch 4655, Loss: 9.895538939375115e-06, Final Batch Loss: 1.1103648489552143e-07\n",
      "Epoch 4656, Loss: 8.16910569548801e-05, Final Batch Loss: 5.714941835321952e-07\n",
      "Epoch 4657, Loss: 7.864167110582798e-05, Final Batch Loss: 1.7304226673786616e-07\n",
      "Epoch 4658, Loss: 5.534674910379067e-06, Final Batch Loss: 3.8935240809223615e-08\n",
      "Epoch 4659, Loss: 1.8815266760618954e-05, Final Batch Loss: 6.806113788115908e-07\n",
      "Epoch 4660, Loss: 1.3167433109861904e-05, Final Batch Loss: 1.0583459015833796e-06\n",
      "Epoch 4661, Loss: 0.0002688096514482652, Final Batch Loss: 6.032037617842434e-06\n",
      "Epoch 4662, Loss: 5.14996094924669e-06, Final Batch Loss: 2.3456861697468412e-07\n",
      "Epoch 4663, Loss: 1.3007821014987542e-05, Final Batch Loss: 5.830507348036917e-07\n",
      "Epoch 4664, Loss: 0.00021627009253633034, Final Batch Loss: 8.944537626121019e-07\n",
      "Epoch 4665, Loss: 7.367485016729347e-06, Final Batch Loss: 3.1376844162878115e-06\n",
      "Epoch 4666, Loss: 1.1538909918229479e-05, Final Batch Loss: 4.479817050651036e-07\n",
      "Epoch 4667, Loss: 4.233441928569448e-06, Final Batch Loss: 4.662597419269332e-08\n",
      "Epoch 4668, Loss: 2.9903755661919718e-05, Final Batch Loss: 6.729555135365217e-09\n",
      "Epoch 4669, Loss: 1.5637984373206848e-05, Final Batch Loss: 1.538182914373465e-08\n",
      "Epoch 4670, Loss: 5.040701554603899e-05, Final Batch Loss: 1.0574964903753425e-07\n",
      "Epoch 4671, Loss: 1.4246678643914379e-05, Final Batch Loss: 1.8265929213612253e-08\n",
      "Epoch 4672, Loss: 0.009833417130802213, Final Batch Loss: 1.379549132707325e-07\n",
      "Epoch 4673, Loss: 0.0003211186445630787, Final Batch Loss: 1.1506850796649815e-06\n",
      "Epoch 4674, Loss: 0.0027804698206104206, Final Batch Loss: 4.6233300963649526e-05\n",
      "Epoch 4675, Loss: 0.005046923367899581, Final Batch Loss: 4.237029133946635e-05\n",
      "Epoch 4676, Loss: 0.007564459379285182, Final Batch Loss: 1.0603154123600689e-06\n",
      "Epoch 4677, Loss: 0.0023373415069585235, Final Batch Loss: 2.4523300453438424e-05\n",
      "Epoch 4678, Loss: 0.0027101961010203013, Final Batch Loss: 4.534692925517447e-05\n",
      "Epoch 4679, Loss: 0.0015438230477182735, Final Batch Loss: 6.820403655183327e-07\n",
      "Epoch 4680, Loss: 0.06539892477358933, Final Batch Loss: 6.568016942765098e-06\n",
      "Epoch 4681, Loss: 0.024286018903580953, Final Batch Loss: 0.02259473130106926\n",
      "Epoch 4682, Loss: 0.00441124486477662, Final Batch Loss: 2.7998399673379026e-05\n",
      "Epoch 4683, Loss: 0.03293604389568827, Final Batch Loss: 0.031795185059309006\n",
      "Epoch 4684, Loss: 0.0006172211421215934, Final Batch Loss: 8.264663847512566e-06\n",
      "Epoch 4685, Loss: 0.0015938526239267503, Final Batch Loss: 7.489687504858011e-06\n",
      "Epoch 4686, Loss: 0.0002760980307030536, Final Batch Loss: 4.914262899546884e-05\n",
      "Epoch 4687, Loss: 0.0005956695459232719, Final Batch Loss: 5.027863494433404e-07\n",
      "Epoch 4688, Loss: 0.0009629060331803885, Final Batch Loss: 1.3569542716140859e-05\n",
      "Epoch 4689, Loss: 0.0009544136955739191, Final Batch Loss: 8.497980843458208e-07\n",
      "Epoch 4690, Loss: 0.00022892863506740468, Final Batch Loss: 1.8144204432246624e-06\n",
      "Epoch 4691, Loss: 0.00013673014738913025, Final Batch Loss: 2.0205779946991242e-06\n",
      "Epoch 4692, Loss: 0.00018428635430112195, Final Batch Loss: 1.6803900280137896e-06\n",
      "Epoch 4693, Loss: 0.0001725260835314657, Final Batch Loss: 0.0001029018749250099\n",
      "Epoch 4694, Loss: 0.0001293706978060527, Final Batch Loss: 1.860813245002646e-05\n",
      "Epoch 4695, Loss: 6.0709773066491834e-05, Final Batch Loss: 4.782697828886739e-07\n",
      "Epoch 4696, Loss: 9.57039435434126e-05, Final Batch Loss: 5.911223524890374e-06\n",
      "Epoch 4697, Loss: 0.00040162286862255314, Final Batch Loss: 1.0372783663115115e-06\n",
      "Epoch 4698, Loss: 6.584927837138821e-05, Final Batch Loss: 7.036948090899386e-07\n",
      "Epoch 4699, Loss: 0.02872841501118728, Final Batch Loss: 0.0015553993871435523\n",
      "Epoch 4700, Loss: 6.546071330859604e-05, Final Batch Loss: 4.787492571267649e-07\n",
      "Epoch 4701, Loss: 0.00018587925552537854, Final Batch Loss: 2.1731696051574545e-06\n",
      "Epoch 4702, Loss: 0.00010728156931349986, Final Batch Loss: 2.3114784198696725e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4703, Loss: 0.006555826183425317, Final Batch Loss: 2.0259506072761724e-06\n",
      "Epoch 4704, Loss: 5.505658849358497e-05, Final Batch Loss: 5.344997475731361e-07\n",
      "Epoch 4705, Loss: 5.3937010164872845e-05, Final Batch Loss: 3.7359679936344037e-06\n",
      "Epoch 4706, Loss: 4.8832304571533314e-05, Final Batch Loss: 9.223017514159437e-06\n",
      "Epoch 4707, Loss: 6.0929076369120594e-05, Final Batch Loss: 1.5307560943256249e-06\n",
      "Epoch 4708, Loss: 0.0001410150479728145, Final Batch Loss: 1.4756429891349399e-06\n",
      "Epoch 4709, Loss: 9.94470365185407e-05, Final Batch Loss: 4.579557753459085e-06\n",
      "Epoch 4710, Loss: 3.699820547353738e-05, Final Batch Loss: 4.960509727425233e-07\n",
      "Epoch 4711, Loss: 0.00014169911824524206, Final Batch Loss: 5.003817591386905e-07\n",
      "Epoch 4712, Loss: 0.0001673768535539466, Final Batch Loss: 3.4945276183862006e-07\n",
      "Epoch 4713, Loss: 5.9488309517519156e-05, Final Batch Loss: 4.554581209958997e-06\n",
      "Epoch 4714, Loss: 7.570121528033269e-05, Final Batch Loss: 5.043368673796067e-06\n",
      "Epoch 4715, Loss: 4.6275413467355975e-05, Final Batch Loss: 7.027287551863992e-07\n",
      "Epoch 4716, Loss: 0.00014629130399157475, Final Batch Loss: 9.92812929325737e-05\n",
      "Epoch 4717, Loss: 0.0001922624419847807, Final Batch Loss: 0.00014348281547427177\n",
      "Epoch 4718, Loss: 0.04831255276102553, Final Batch Loss: 5.9600079111987725e-06\n",
      "Epoch 4719, Loss: 0.0027099284388896194, Final Batch Loss: 0.0014556816313415766\n",
      "Epoch 4720, Loss: 0.0004838576372776515, Final Batch Loss: 3.255934643675573e-05\n",
      "Epoch 4721, Loss: 0.000649844856297932, Final Batch Loss: 5.223017979005817e-06\n",
      "Epoch 4722, Loss: 0.00039180749740808096, Final Batch Loss: 9.562600462231785e-05\n",
      "Epoch 4723, Loss: 0.00026430135835653346, Final Batch Loss: 6.767265404050704e-06\n",
      "Epoch 4724, Loss: 0.00013643918117622889, Final Batch Loss: 6.210322567312687e-07\n",
      "Epoch 4725, Loss: 0.00020972213746972557, Final Batch Loss: 2.9851535146008246e-06\n",
      "Epoch 4726, Loss: 0.0002831928936757322, Final Batch Loss: 3.574072025003261e-06\n",
      "Epoch 4727, Loss: 0.00029478904036750464, Final Batch Loss: 2.5849021767498925e-06\n",
      "Epoch 4728, Loss: 0.00010623525548680846, Final Batch Loss: 1.3919934644945897e-06\n",
      "Epoch 4729, Loss: 9.50912559005701e-05, Final Batch Loss: 1.3193746326578548e-06\n",
      "Epoch 4730, Loss: 0.00011220442638659733, Final Batch Loss: 9.426877113583032e-06\n",
      "Epoch 4731, Loss: 0.0031596701894613943, Final Batch Loss: 9.550670938551775e-07\n",
      "Epoch 4732, Loss: 0.0005078285057038556, Final Batch Loss: 3.159706830047071e-05\n",
      "Epoch 4733, Loss: 8.312848291325281e-05, Final Batch Loss: 2.3195450467028422e-06\n",
      "Epoch 4734, Loss: 0.00017647881134053023, Final Batch Loss: 1.0353357993153622e-06\n",
      "Epoch 4735, Loss: 0.00016651449627147485, Final Batch Loss: 3.9642341107537504e-06\n",
      "Epoch 4736, Loss: 5.921557908550312e-05, Final Batch Loss: 2.4160990506061353e-06\n",
      "Epoch 4737, Loss: 5.5706868110405594e-05, Final Batch Loss: 1.4746652595931664e-05\n",
      "Epoch 4738, Loss: 0.002570380759721047, Final Batch Loss: 1.051226831805252e-06\n",
      "Epoch 4739, Loss: 0.00013371636200076864, Final Batch Loss: 1.2367497674858896e-06\n",
      "Epoch 4740, Loss: 4.717099966455862e-05, Final Batch Loss: 4.4847132585346117e-07\n",
      "Epoch 4741, Loss: 4.349074198728431e-05, Final Batch Loss: 5.146741386852227e-06\n",
      "Epoch 4742, Loss: 4.036218068392827e-05, Final Batch Loss: 1.6058661458373535e-06\n",
      "Epoch 4743, Loss: 0.026123358140139885, Final Batch Loss: 3.7877398995078693e-07\n",
      "Epoch 4744, Loss: 0.00017526668821687963, Final Batch Loss: 6.604394911846612e-06\n",
      "Epoch 4745, Loss: 0.00023979907882676343, Final Batch Loss: 1.7270353055209853e-05\n",
      "Epoch 4746, Loss: 0.0003040103460421051, Final Batch Loss: 7.011468369455542e-06\n",
      "Epoch 4747, Loss: 0.0002154544458790042, Final Batch Loss: 1.0755948096630163e-05\n",
      "Epoch 4748, Loss: 0.00020251435438467524, Final Batch Loss: 2.353248419240117e-06\n",
      "Epoch 4749, Loss: 0.0003539865164157163, Final Batch Loss: 6.200252391863614e-05\n",
      "Epoch 4750, Loss: 0.00019658669663158435, Final Batch Loss: 6.752074114046991e-05\n",
      "Epoch 4751, Loss: 0.00016562217030013926, Final Batch Loss: 7.007411477388814e-05\n",
      "Epoch 4752, Loss: 0.00016238772940369017, Final Batch Loss: 4.257439741195412e-06\n",
      "Epoch 4753, Loss: 0.00021770077307792235, Final Batch Loss: 2.4184892026823945e-06\n",
      "Epoch 4754, Loss: 0.000581310178631611, Final Batch Loss: 2.7866728942171903e-06\n",
      "Epoch 4755, Loss: 0.00022671615664648925, Final Batch Loss: 1.2213406535011018e-06\n",
      "Epoch 4756, Loss: 0.00015019746939515244, Final Batch Loss: 5.00862654462253e-07\n",
      "Epoch 4757, Loss: 9.237623652325055e-05, Final Batch Loss: 1.8855114831239916e-05\n",
      "Epoch 4758, Loss: 0.000523720112596493, Final Batch Loss: 7.73205920268083e-06\n",
      "Epoch 4759, Loss: 0.00013662557257987373, Final Batch Loss: 1.3266082987684058e-06\n",
      "Epoch 4760, Loss: 4.533100792514233e-05, Final Batch Loss: 4.5038234475214267e-07\n",
      "Epoch 4761, Loss: 9.159621356502612e-05, Final Batch Loss: 3.364773647263064e-06\n",
      "Epoch 4762, Loss: 6.529186570247703e-05, Final Batch Loss: 9.334756214229856e-06\n",
      "Epoch 4763, Loss: 9.186120334447878e-05, Final Batch Loss: 5.4038896450947504e-06\n",
      "Epoch 4764, Loss: 4.574429102888189e-05, Final Batch Loss: 1.6439260264178301e-07\n",
      "Epoch 4765, Loss: 8.137683390430084e-05, Final Batch Loss: 1.8522129039411084e-06\n",
      "Epoch 4766, Loss: 0.0001272675165537862, Final Batch Loss: 2.9195123261160916e-06\n",
      "Epoch 4767, Loss: 2.643984240791042e-05, Final Batch Loss: 5.912324354540033e-07\n",
      "Epoch 4768, Loss: 0.00019329646983123894, Final Batch Loss: 2.60486649494851e-06\n",
      "Epoch 4769, Loss: 3.5670847267965655e-05, Final Batch Loss: 6.027663062013744e-07\n",
      "Epoch 4770, Loss: 6.834199973582145e-05, Final Batch Loss: 3.820333404291887e-06\n",
      "Epoch 4771, Loss: 8.036349213824678e-05, Final Batch Loss: 2.1822785356562235e-07\n",
      "Epoch 4772, Loss: 4.945636099051853e-05, Final Batch Loss: 1.3699380474463396e-07\n",
      "Epoch 4773, Loss: 5.54182046812457e-05, Final Batch Loss: 3.635796019807458e-06\n",
      "Epoch 4774, Loss: 6.260464517993114e-05, Final Batch Loss: 1.2761659036186757e-06\n",
      "Epoch 4775, Loss: 0.00012339678590933545, Final Batch Loss: 2.718891300901305e-05\n",
      "Epoch 4776, Loss: 0.0001285724053445847, Final Batch Loss: 1.0848488045667182e-06\n",
      "Epoch 4777, Loss: 3.1844711209316756e-05, Final Batch Loss: 5.090286663289589e-07\n",
      "Epoch 4778, Loss: 0.00013201998078216093, Final Batch Loss: 1.3697767826670315e-06\n",
      "Epoch 4779, Loss: 3.004502623582539e-05, Final Batch Loss: 1.7494024859843194e-06\n",
      "Epoch 4780, Loss: 5.821565869013057e-05, Final Batch Loss: 6.964635872463987e-07\n",
      "Epoch 4781, Loss: 0.0011026514534933085, Final Batch Loss: 0.0010563351679593325\n",
      "Epoch 4782, Loss: 0.0010607321115969626, Final Batch Loss: 1.8698432313613012e-07\n",
      "Epoch 4783, Loss: 6.912522744073613e-05, Final Batch Loss: 2.1906167603447102e-05\n",
      "Epoch 4784, Loss: 4.499739751651077e-05, Final Batch Loss: 1.0190419885702795e-07\n",
      "Epoch 4785, Loss: 2.623432560966421e-05, Final Batch Loss: 3.776588300752337e-06\n",
      "Epoch 4786, Loss: 2.668341407030539e-05, Final Batch Loss: 1.4823631317995023e-06\n",
      "Epoch 4787, Loss: 1.7064681767209322e-05, Final Batch Loss: 2.543552227507462e-06\n",
      "Epoch 4788, Loss: 2.3069916323947837e-05, Final Batch Loss: 1.6610291595497984e-06\n",
      "Epoch 4789, Loss: 2.125585076129255e-05, Final Batch Loss: 6.181376193126198e-07\n",
      "Epoch 4790, Loss: 0.00013296074784108214, Final Batch Loss: 1.2542558579298202e-05\n",
      "Epoch 4791, Loss: 3.065576212435417e-05, Final Batch Loss: 1.1045107157769962e-06\n",
      "Epoch 4792, Loss: 0.00017510154806998912, Final Batch Loss: 1.1747166581699275e-06\n",
      "Epoch 4793, Loss: 3.122669361488306e-05, Final Batch Loss: 1.2434461496013682e-06\n",
      "Epoch 4794, Loss: 2.389500363264574e-05, Final Batch Loss: 2.3255779524333775e-06\n",
      "Epoch 4795, Loss: 2.4029459112284712e-05, Final Batch Loss: 6.465007231781783e-07\n",
      "Epoch 4796, Loss: 2.797677554511324e-05, Final Batch Loss: 2.605278268674738e-07\n",
      "Epoch 4797, Loss: 0.0005365159647183759, Final Batch Loss: 2.3471666281693615e-06\n",
      "Epoch 4798, Loss: 2.3742382150970798e-05, Final Batch Loss: 7.931211598588561e-08\n",
      "Epoch 4799, Loss: 8.504788009844333e-05, Final Batch Loss: 1.317060451810903e-07\n",
      "Epoch 4800, Loss: 3.180113001555185e-05, Final Batch Loss: 9.334534638583136e-07\n",
      "Epoch 4801, Loss: 1.9971860742984404e-05, Final Batch Loss: 1.9659795214010956e-07\n",
      "Epoch 4802, Loss: 2.0277227065435e-05, Final Batch Loss: 1.446206397304195e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4803, Loss: 2.0914303107133492e-05, Final Batch Loss: 6.868681907690188e-07\n",
      "Epoch 4804, Loss: 9.548587681784682e-05, Final Batch Loss: 6.529917754960479e-06\n",
      "Epoch 4805, Loss: 1.8093536094165863e-05, Final Batch Loss: 8.425902819908515e-07\n",
      "Epoch 4806, Loss: 7.50426033349072e-05, Final Batch Loss: 3.004217035140755e-07\n",
      "Epoch 4807, Loss: 2.7569280106831684e-05, Final Batch Loss: 1.5189517910130235e-07\n",
      "Epoch 4808, Loss: 2.2546144279544933e-05, Final Batch Loss: 8.252912380157795e-07\n",
      "Epoch 4809, Loss: 6.884133500761891e-05, Final Batch Loss: 1.0815325168778145e-07\n",
      "Epoch 4810, Loss: 2.0505076491872387e-05, Final Batch Loss: 1.0266278422932373e-06\n",
      "Epoch 4811, Loss: 3.5177767850669284e-05, Final Batch Loss: 6.810959689573792e-07\n",
      "Epoch 4812, Loss: 0.00010788798380545472, Final Batch Loss: 1.7581475049155415e-06\n",
      "Epoch 4813, Loss: 1.0271517240312278e-05, Final Batch Loss: 2.093144530590507e-06\n",
      "Epoch 4814, Loss: 6.559258229188458e-05, Final Batch Loss: 2.5139496528936434e-07\n",
      "Epoch 4815, Loss: 6.029645202687561e-05, Final Batch Loss: 6.241709343157709e-06\n",
      "Epoch 4816, Loss: 2.7153389412504225e-05, Final Batch Loss: 2.836024215469024e-08\n",
      "Epoch 4817, Loss: 0.032671622916403464, Final Batch Loss: 2.7371193027647678e-06\n",
      "Epoch 4818, Loss: 5.669365915395019e-06, Final Batch Loss: 1.158439602022554e-07\n",
      "Epoch 4819, Loss: 0.00014283553887572964, Final Batch Loss: 1.9611564994193031e-07\n",
      "Epoch 4820, Loss: 1.8831255360396426e-05, Final Batch Loss: 7.69087336038865e-08\n",
      "Epoch 4821, Loss: 0.0001805984325997656, Final Batch Loss: 7.835101456521443e-08\n",
      "Epoch 4822, Loss: 0.0016844455815494541, Final Batch Loss: 2.482104264345253e-06\n",
      "Epoch 4823, Loss: 0.00011878103640583504, Final Batch Loss: 2.7488998966873623e-05\n",
      "Epoch 4824, Loss: 0.00017423557630991127, Final Batch Loss: 2.347890131204622e-06\n",
      "Epoch 4825, Loss: 0.0002082529232154684, Final Batch Loss: 5.893018624192337e-07\n",
      "Epoch 4826, Loss: 0.0001522981318089478, Final Batch Loss: 3.1351457892014878e-06\n",
      "Epoch 4827, Loss: 0.00016246860051438716, Final Batch Loss: 7.743588525954692e-07\n",
      "Epoch 4828, Loss: 5.3523987681103335e-05, Final Batch Loss: 1.619887513015783e-07\n",
      "Epoch 4829, Loss: 5.152787852580332e-05, Final Batch Loss: 2.6581437850836664e-07\n",
      "Epoch 4830, Loss: 0.00030041249101486756, Final Batch Loss: 1.0800313248182647e-06\n",
      "Epoch 4831, Loss: 0.00019295418865183933, Final Batch Loss: 1.1344077677222231e-07\n",
      "Epoch 4832, Loss: 0.0001970665507133873, Final Batch Loss: 3.2481923426530557e-06\n",
      "Epoch 4833, Loss: 6.392987172887388e-05, Final Batch Loss: 3.5800676414510235e-05\n",
      "Epoch 4834, Loss: 3.94879895608824e-05, Final Batch Loss: 1.8844332316803047e-06\n",
      "Epoch 4835, Loss: 7.187883559822694e-05, Final Batch Loss: 1.9507017441355856e-06\n",
      "Epoch 4836, Loss: 6.651880559616075e-05, Final Batch Loss: 2.3410425455949735e-06\n",
      "Epoch 4837, Loss: 0.00024391819365376932, Final Batch Loss: 1.3861724255548324e-05\n",
      "Epoch 4838, Loss: 5.117034201163051e-05, Final Batch Loss: 2.6590583729557693e-05\n",
      "Epoch 4839, Loss: 2.9217678559234628e-05, Final Batch Loss: 5.892958938602533e-07\n",
      "Epoch 4840, Loss: 0.00010732326180118434, Final Batch Loss: 2.014129495364614e-05\n",
      "Epoch 4841, Loss: 5.3514279592548064e-05, Final Batch Loss: 1.2930235016028746e-07\n",
      "Epoch 4842, Loss: 2.590890376197308e-05, Final Batch Loss: 5.672022140856825e-08\n",
      "Epoch 4843, Loss: 1.9319943312723353e-05, Final Batch Loss: 5.470064479595749e-06\n",
      "Epoch 4844, Loss: 0.0002224137528656911, Final Batch Loss: 0.0002078634570352733\n",
      "Epoch 4845, Loss: 0.020620374649507056, Final Batch Loss: 0.002949450397863984\n",
      "Epoch 4846, Loss: 0.00015336475007643458, Final Batch Loss: 1.0396836387371877e-06\n",
      "Epoch 4847, Loss: 3.4825231821855596e-05, Final Batch Loss: 3.6224200812284835e-06\n",
      "Epoch 4848, Loss: 0.011444928798042042, Final Batch Loss: 7.623024430358782e-05\n",
      "Epoch 4849, Loss: 0.0007672497647490673, Final Batch Loss: 5.471621989272535e-05\n",
      "Epoch 4850, Loss: 0.0009392361936022553, Final Batch Loss: 1.4040147107152734e-06\n",
      "Epoch 4851, Loss: 0.0007142085777331886, Final Batch Loss: 0.0005689052050001919\n",
      "Epoch 4852, Loss: 0.002921594269977845, Final Batch Loss: 1.0578182809695136e-05\n",
      "Epoch 4853, Loss: 0.00031646381185623795, Final Batch Loss: 7.712214937782846e-06\n",
      "Epoch 4854, Loss: 0.000259319008009129, Final Batch Loss: 5.811368282593321e-06\n",
      "Epoch 4855, Loss: 0.0005624790626370668, Final Batch Loss: 3.4287165817659115e-06\n",
      "Epoch 4856, Loss: 0.0001405583818723244, Final Batch Loss: 1.864934915829508e-06\n",
      "Epoch 4857, Loss: 8.56265018569502e-05, Final Batch Loss: 4.0376590959567693e-07\n",
      "Epoch 4858, Loss: 0.00010144847954052238, Final Batch Loss: 5.106121079734294e-06\n",
      "Epoch 4859, Loss: 0.00016010951355838188, Final Batch Loss: 2.494995669621858e-06\n",
      "Epoch 4860, Loss: 0.0001074646594929618, Final Batch Loss: 1.5121099750103895e-06\n",
      "Epoch 4861, Loss: 5.1201569590375584e-05, Final Batch Loss: 2.1088792436785297e-06\n",
      "Epoch 4862, Loss: 0.0001135348118168622, Final Batch Loss: 2.528759296183125e-06\n",
      "Epoch 4863, Loss: 4.0286962182278785e-05, Final Batch Loss: 2.773510061615525e-07\n",
      "Epoch 4864, Loss: 5.389943876821235e-05, Final Batch Loss: 3.3020999126165407e-06\n",
      "Epoch 4865, Loss: 0.00023820496181770068, Final Batch Loss: 2.3618474642717047e-06\n",
      "Epoch 4866, Loss: 6.527865534744492e-05, Final Batch Loss: 4.2731508642646077e-07\n",
      "Epoch 4867, Loss: 4.939287167360362e-05, Final Batch Loss: 8.137427016663423e-07\n",
      "Epoch 4868, Loss: 4.841933199273285e-05, Final Batch Loss: 2.2701694888382917e-06\n",
      "Epoch 4869, Loss: 2.550724737204746e-05, Final Batch Loss: 1.8123511154044536e-06\n",
      "Epoch 4870, Loss: 5.264774122437643e-05, Final Batch Loss: 3.748672952497145e-06\n",
      "Epoch 4871, Loss: 4.8874857014880035e-05, Final Batch Loss: 1.7489041965745855e-06\n",
      "Epoch 4872, Loss: 2.3780353117786035e-05, Final Batch Loss: 3.7540814901149133e-07\n",
      "Epoch 4873, Loss: 2.282474466852591e-05, Final Batch Loss: 7.527295338149997e-07\n",
      "Epoch 4874, Loss: 2.9072801197571607e-05, Final Batch Loss: 4.657875251723453e-06\n",
      "Epoch 4875, Loss: 7.283923224576938e-05, Final Batch Loss: 1.283417168451706e-05\n",
      "Epoch 4876, Loss: 2.4363777797020703e-05, Final Batch Loss: 5.470037649502046e-06\n",
      "Epoch 4877, Loss: 0.381989263423975, Final Batch Loss: 1.9659543681882496e-07\n",
      "Epoch 4878, Loss: 0.04124669299136485, Final Batch Loss: 9.363224648950563e-07\n",
      "Epoch 4879, Loss: 0.002249522732071796, Final Batch Loss: 0.00019332302326802164\n",
      "Epoch 4880, Loss: 0.004846640768562338, Final Batch Loss: 8.147285370796453e-07\n",
      "Epoch 4881, Loss: 0.001109655775792362, Final Batch Loss: 3.0932724257581867e-06\n",
      "Epoch 4882, Loss: 0.00024536061219038174, Final Batch Loss: 5.60464684440376e-07\n",
      "Epoch 4883, Loss: 0.0005625802907349708, Final Batch Loss: 4.089097274118103e-05\n",
      "Epoch 4884, Loss: 5.2854099145349664e-05, Final Batch Loss: 3.004244035764714e-07\n",
      "Epoch 4885, Loss: 4.060129116112421e-05, Final Batch Loss: 2.2241340502660023e-06\n",
      "Epoch 4886, Loss: 0.0005647736251219726, Final Batch Loss: 3.7299055293260608e-06\n",
      "Epoch 4887, Loss: 7.36213717686951e-05, Final Batch Loss: 4.758746996458285e-08\n",
      "Epoch 4888, Loss: 0.0003336049541928787, Final Batch Loss: 4.0658902435097843e-05\n",
      "Epoch 4889, Loss: 0.002140513679670164, Final Batch Loss: 1.2554515933516086e-06\n",
      "Epoch 4890, Loss: 0.03236070340327046, Final Batch Loss: 7.888694199209567e-06\n",
      "Epoch 4891, Loss: 9.004403767676195e-05, Final Batch Loss: 1.6448321957795997e-06\n",
      "Epoch 4892, Loss: 0.0006782312107702637, Final Batch Loss: 2.86458566733927e-06\n",
      "Epoch 4893, Loss: 0.00014725871275800273, Final Batch Loss: 4.994332812202629e-06\n",
      "Epoch 4894, Loss: 0.0005720804294071513, Final Batch Loss: 2.4610793047941115e-07\n",
      "Epoch 4895, Loss: 0.00024818567152351534, Final Batch Loss: 5.251698166830465e-05\n",
      "Epoch 4896, Loss: 0.0012507051053347595, Final Batch Loss: 2.7587375370785594e-06\n",
      "Epoch 4897, Loss: 4.074503324602574e-05, Final Batch Loss: 3.1101908462005667e-06\n",
      "Epoch 4898, Loss: 0.00042617873597805556, Final Batch Loss: 2.91290092491181e-07\n",
      "Epoch 4899, Loss: 0.0674334137611936, Final Batch Loss: 2.4634226065245457e-05\n",
      "Epoch 4900, Loss: 0.005284401073964773, Final Batch Loss: 0.0004013920552097261\n",
      "Epoch 4901, Loss: 0.004209399645105805, Final Batch Loss: 6.833089628344169e-06\n",
      "Epoch 4902, Loss: 0.005773634820116058, Final Batch Loss: 2.14362171391258e-06\n",
      "Epoch 4903, Loss: 0.0001697044461934638, Final Batch Loss: 2.1662087874574354e-06\n",
      "Epoch 4904, Loss: 0.0002854158599063794, Final Batch Loss: 0.0001066387485479936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4905, Loss: 0.0013155457917264357, Final Batch Loss: 1.8041971998172812e-05\n",
      "Epoch 4906, Loss: 6.485061429373218e-05, Final Batch Loss: 1.9739659364859108e-06\n",
      "Epoch 4907, Loss: 0.0017385590190883704, Final Batch Loss: 7.815640969965898e-07\n",
      "Epoch 4908, Loss: 0.00031734993649479293, Final Batch Loss: 0.00010216773807769641\n",
      "Epoch 4909, Loss: 0.00016740024597083902, Final Batch Loss: 2.0129880340391537e-06\n",
      "Epoch 4910, Loss: 0.0006087403256742618, Final Batch Loss: 1.9984092432423495e-05\n",
      "Epoch 4911, Loss: 0.0004514757924312107, Final Batch Loss: 8.671045748087636e-07\n",
      "Epoch 4912, Loss: 0.015043691799860426, Final Batch Loss: 0.00010685068991733715\n",
      "Epoch 4913, Loss: 0.001415128714597813, Final Batch Loss: 1.2117688129364979e-05\n",
      "Epoch 4914, Loss: 0.00037611976836160466, Final Batch Loss: 0.00018522546452004462\n",
      "Epoch 4915, Loss: 0.00043705359212253825, Final Batch Loss: 1.1420424925745465e-06\n",
      "Epoch 4916, Loss: 0.00012694394155232658, Final Batch Loss: 4.575045295496238e-06\n",
      "Epoch 4917, Loss: 0.00014822386782498143, Final Batch Loss: 9.642213854021975e-07\n",
      "Epoch 4918, Loss: 0.00031181341620367675, Final Batch Loss: 3.092700580964447e-06\n",
      "Epoch 4919, Loss: 0.0002956482236413649, Final Batch Loss: 7.028716026979964e-06\n",
      "Epoch 4920, Loss: 0.0015364968385256361, Final Batch Loss: 2.7347373361408245e-06\n",
      "Epoch 4921, Loss: 0.0001331298307150064, Final Batch Loss: 1.3019849802731187e-06\n",
      "Epoch 4922, Loss: 0.0006355086617588768, Final Batch Loss: 3.508936003981944e-07\n",
      "Epoch 4923, Loss: 0.00012994823981671288, Final Batch Loss: 2.1648415895469952e-06\n",
      "Epoch 4924, Loss: 0.00018596458488673306, Final Batch Loss: 4.7538620151499345e-07\n",
      "Epoch 4925, Loss: 0.00017017561581411655, Final Batch Loss: 2.026160700552282e-06\n",
      "Epoch 4926, Loss: 4.810002623401033e-05, Final Batch Loss: 1.4538316008838592e-06\n",
      "Epoch 4927, Loss: 7.0271908327868e-05, Final Batch Loss: 1.2093369150534272e-06\n",
      "Epoch 4928, Loss: 0.0011527611140991212, Final Batch Loss: 1.1223687579331454e-06\n",
      "Epoch 4929, Loss: 7.921734253102386e-05, Final Batch Loss: 9.603706985217286e-07\n",
      "Epoch 4930, Loss: 0.00021697971489942347, Final Batch Loss: 5.6844301070668735e-06\n",
      "Epoch 4931, Loss: 0.00014360587553596815, Final Batch Loss: 5.493969865710824e-07\n",
      "Epoch 4932, Loss: 9.571345140102494e-05, Final Batch Loss: 6.307690455287229e-06\n",
      "Epoch 4933, Loss: 8.716652142481962e-05, Final Batch Loss: 1.8269201973453164e-06\n",
      "Epoch 4934, Loss: 3.0359033829086002e-05, Final Batch Loss: 1.922708889878777e-07\n",
      "Epoch 4935, Loss: 4.44561482062511e-05, Final Batch Loss: 7.470739092241274e-06\n",
      "Epoch 4936, Loss: 0.00010966415200641677, Final Batch Loss: 4.693775281339185e-06\n",
      "Epoch 4937, Loss: 8.299397202904402e-05, Final Batch Loss: 6.496965215774253e-05\n",
      "Epoch 4938, Loss: 4.490621101638226e-05, Final Batch Loss: 4.063545020471793e-06\n",
      "Epoch 4939, Loss: 0.0016419806552505634, Final Batch Loss: 3.085885111886455e-07\n",
      "Epoch 4940, Loss: 0.00011499184174112997, Final Batch Loss: 3.1539584597339854e-05\n",
      "Epoch 4941, Loss: 0.00017631274078588888, Final Batch Loss: 4.9067555664805695e-05\n",
      "Epoch 4942, Loss: 0.00013578654349544195, Final Batch Loss: 1.1872764105191891e-07\n",
      "Epoch 4943, Loss: 0.0001780675999860648, Final Batch Loss: 1.2414308002917096e-05\n",
      "Epoch 4944, Loss: 2.5044581317246184e-05, Final Batch Loss: 1.4741754057467915e-06\n",
      "Epoch 4945, Loss: 0.00013722100777613377, Final Batch Loss: 8.253045962192118e-07\n",
      "Epoch 4946, Loss: 8.910439581910623e-05, Final Batch Loss: 8.781495921539317e-07\n",
      "Epoch 4947, Loss: 0.00012357473362101246, Final Batch Loss: 9.904407306748908e-06\n",
      "Epoch 4948, Loss: 0.00186468370444004, Final Batch Loss: 8.16834744910011e-06\n",
      "Epoch 4949, Loss: 0.0017793486032360306, Final Batch Loss: 4.542987880995497e-06\n",
      "Epoch 4950, Loss: 7.101216442606528e-05, Final Batch Loss: 3.951435246563051e-06\n",
      "Epoch 4951, Loss: 0.00011841368677778519, Final Batch Loss: 4.4004147639498115e-05\n",
      "Epoch 4952, Loss: 0.00018943533862625372, Final Batch Loss: 7.257912102431874e-07\n",
      "Epoch 4953, Loss: 0.00036796452937437607, Final Batch Loss: 2.595669741367601e-07\n",
      "Epoch 4954, Loss: 0.00014552827327918294, Final Batch Loss: 2.262299403810175e-06\n",
      "Epoch 4955, Loss: 0.02214227170963312, Final Batch Loss: 7.019354143267265e-06\n",
      "Epoch 4956, Loss: 0.00016406598669505001, Final Batch Loss: 3.3126166272268165e-06\n",
      "Epoch 4957, Loss: 0.0008288791132429196, Final Batch Loss: 5.109477001496998e-07\n",
      "Epoch 4958, Loss: 4.152345897168175e-05, Final Batch Loss: 5.018176807425334e-07\n",
      "Epoch 4959, Loss: 0.00011734537028473824, Final Batch Loss: 1.2298901310714427e-06\n",
      "Epoch 4960, Loss: 0.024356373915495055, Final Batch Loss: 1.3237297480372945e-06\n",
      "Epoch 4961, Loss: 0.0011689355957855696, Final Batch Loss: 6.28634006716311e-05\n",
      "Epoch 4962, Loss: 0.0009774097388515202, Final Batch Loss: 4.167125098319957e-06\n",
      "Epoch 4963, Loss: 0.0004023242150879014, Final Batch Loss: 5.503110969584668e-06\n",
      "Epoch 4964, Loss: 0.00065328458924796, Final Batch Loss: 7.049317446217174e-06\n",
      "Epoch 4965, Loss: 0.0029216704319878772, Final Batch Loss: 0.00013520677748601884\n",
      "Epoch 4966, Loss: 0.00031776949293771395, Final Batch Loss: 5.554979907174129e-06\n",
      "Epoch 4967, Loss: 0.01673461397226106, Final Batch Loss: 1.567473736940883e-05\n",
      "Epoch 4968, Loss: 0.0001171357601492673, Final Batch Loss: 7.026274033705704e-06\n",
      "Epoch 4969, Loss: 0.00040951582900561334, Final Batch Loss: 0.0001682489091763273\n",
      "Epoch 4970, Loss: 0.0013169274531037445, Final Batch Loss: 1.728295842440275e-06\n",
      "Epoch 4971, Loss: 0.0001894161530344718, Final Batch Loss: 2.7190548280486837e-05\n",
      "Epoch 4972, Loss: 0.00024166715004980688, Final Batch Loss: 2.3049603896652116e-06\n",
      "Epoch 4973, Loss: 0.002461168886497944, Final Batch Loss: 1.6395312059103162e-06\n",
      "Epoch 4974, Loss: 0.0379199817598419, Final Batch Loss: 1.0128092981176451e-05\n",
      "Epoch 4975, Loss: 0.005248111779820874, Final Batch Loss: 9.699651855044067e-07\n",
      "Epoch 4976, Loss: 5.8568308716644424e-05, Final Batch Loss: 8.209501629607985e-07\n",
      "Epoch 4977, Loss: 0.00029659662430958633, Final Batch Loss: 3.057623689528555e-05\n",
      "Epoch 4978, Loss: 8.695836434924331e-05, Final Batch Loss: 5.511616109288298e-06\n",
      "Epoch 4979, Loss: 0.0002309706199845607, Final Batch Loss: 1.4836283526165062e-06\n",
      "Epoch 4980, Loss: 0.00013401533996670878, Final Batch Loss: 6.22468405708787e-06\n",
      "Epoch 4981, Loss: 0.0030312483173950966, Final Batch Loss: 7.835091508923142e-08\n",
      "Epoch 4982, Loss: 0.00015815785894801593, Final Batch Loss: 4.2155528490184224e-07\n",
      "Epoch 4983, Loss: 7.647684134326482e-05, Final Batch Loss: 6.62368506709754e-07\n",
      "Epoch 4984, Loss: 7.456506693870324e-05, Final Batch Loss: 5.715668976336019e-06\n",
      "Epoch 4985, Loss: 0.0004563044469136912, Final Batch Loss: 2.1641860712406924e-06\n",
      "Epoch 4986, Loss: 0.00010614677105991177, Final Batch Loss: 7.026384537311969e-06\n",
      "Epoch 4987, Loss: 0.00014867188630773853, Final Batch Loss: 3.0219985092116985e-06\n",
      "Epoch 4988, Loss: 0.00043807138627016684, Final Batch Loss: 8.76560079632327e-06\n",
      "Epoch 4989, Loss: 2.2233326539833342e-05, Final Batch Loss: 1.3410377732725465e-06\n",
      "Epoch 4990, Loss: 0.00045948745474788666, Final Batch Loss: 9.267239420296391e-07\n",
      "Epoch 4991, Loss: 0.0001300916443369715, Final Batch Loss: 3.0559087917936267e-06\n",
      "Epoch 4992, Loss: 0.0003622150643423083, Final Batch Loss: 2.415650487819221e-05\n",
      "Epoch 4993, Loss: 0.00014000604856789778, Final Batch Loss: 3.548984386725351e-05\n",
      "Epoch 4994, Loss: 0.002413228176862958, Final Batch Loss: 6.462647888838546e-06\n",
      "Epoch 4995, Loss: 0.0010750432517738773, Final Batch Loss: 1.6343126674200903e-07\n",
      "Epoch 4996, Loss: 0.00017089842052087079, Final Batch Loss: 7.171218385337852e-06\n",
      "Epoch 4997, Loss: 0.0006324504448826929, Final Batch Loss: 2.497412879165495e-06\n",
      "Epoch 4998, Loss: 5.471485604857662e-05, Final Batch Loss: 3.077962446695892e-06\n",
      "Epoch 4999, Loss: 2.897096877063632e-05, Final Batch Loss: 1.700928123682388e-06\n",
      "Epoch 5000, Loss: 2.9535378544665036e-05, Final Batch Loss: 4.5279736582415353e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[473  23   0]\n",
      " [ 18 402   0]\n",
      " [  0   0 491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.963     0.954     0.958       496\n",
      "           1      0.946     0.957     0.951       420\n",
      "           2      1.000     1.000     1.000       491\n",
      "\n",
      "    accuracy                          0.971      1407\n",
      "   macro avg      0.970     0.970     0.970      1407\n",
      "weighted avg      0.971     0.971     0.971      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../saved_models/UCI 3 Label Classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
