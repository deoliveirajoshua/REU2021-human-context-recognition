{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "from pylab import *\n",
    "from scipy.stats import wasserstein_distance\n",
    "import random\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaryClare's\n",
    "#os.chdir('/Users/maryclaremartin/Documents/jup/ExtraSensory')\n",
    "\n",
    "# Josh's\n",
    "#os.chdir(\"D:/Research_Projects/REU2021-human-context-recognition/ExtraSensory_data\")\n",
    "\n",
    "# Harrison's\n",
    "os.chdir(\"/Users/hkimr/Desktop/WPI Github/REU2021-human-context-recognition/UCI_data\")\n",
    "\n",
    "#os.chdir('../')\n",
    "softmax = nn.Softmax(dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/features.txt', delimiter = \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load and scale data\n",
    "#returns scaled data (X) and labels (Y)\n",
    "#file_name: string, file with data to be used\n",
    "#label: array, list of activities to use\n",
    "#users: array, list of users whose data is to be used\n",
    "\n",
    "def start_data(file_name, label, users):\n",
    "    #read csv into dataframe\n",
    "    data = pd.read_csv(file_name)\n",
    "    data = data[data['UUID'].isin(users)]\n",
    "\n",
    "    #seperate only acceleration data\n",
    "    X = data.loc[:,'raw_acc:magnitude_stats:mean':'raw_acc:3d:ro_yz']    \n",
    "    y = data[label]\n",
    "\n",
    "    #seperate only \"on\" labels\n",
    "    X = X[(y!=0).any(axis=1)]\n",
    "    y = y[(y!=0).any(axis=1)]\n",
    "    \n",
    "    #interpolate averages per column\n",
    "    X = interpolation(X).values\n",
    "    y = interpolation(y).values\n",
    "    \n",
    "    #scale the data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim).to(device)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = 26, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, int(hidden_dim/2)),\n",
    "            generator_block(int(hidden_dim/2), int(hidden_dim/4)),\n",
    "            generator_block(int(hidden_dim/4), 30),\n",
    "            generator_block(30, 28),\n",
    "            nn.Linear(28, feature_dim)\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "##calculates generator loss\n",
    "#gen: generator\n",
    "#disc: discriminator\n",
    "#criterion1: loss function1\n",
    "#criterion2: loss function2\n",
    "#batch_size: batch size\n",
    "#z_dim: number of dimensions in the latent space\n",
    "def get_gen_loss(gen, disc, act, usr, criterion1, criterion2, batch_size, z_dim, activities, users):\n",
    "    latent_vectors = get_noise(batch_size, z_dim)\n",
    "    act_vectors = get_act_matrix(batch_size, activities)\n",
    "    usr_vectors = get_usr_matrix(batch_size, users)\n",
    "    \n",
    "    to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "    fake_features = gen(to_gen)\n",
    "    disc.eval()\n",
    "    pred_disc = disc(fake_features)\n",
    "    disc.train()\n",
    "    pred_act = act(fake_features) ### CrossEntropyLoss Criterion automatically applies softmax and torch.max\n",
    "    pred_usr = usr(fake_features)\n",
    "    \n",
    "    d_loss = criterion1(pred_disc, torch.ones_like(pred_disc))\n",
    "    act_loss = criterion2(pred_act, act_vectors[0])\n",
    "    usr_loss = criterion2(pred_usr, usr_vectors[0])\n",
    "    \n",
    "    gen_loss = d_loss + act_loss + usr_loss\n",
    "    return gen_loss\n",
    "    \n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long().to(device), torch.Tensor(one_hot).to(device)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long().to(device), torch.Tensor(one_hot).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Fake Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fake_samples(gen, batch_size, z_dim):\n",
    "    \"\"\"\n",
    "    Generates fake acceleration features given a batch size, latent vector dimension, and trained generator.\n",
    "    \n",
    "    \"\"\"\n",
    "    latent_vectors = get_noise(batch_size, z_dim) ### Retrieves a 2D tensor of noise\n",
    "    gen.eval()\n",
    "    fake_features = gen(latent_vectors)\n",
    "    gen.train()\n",
    "    return fake_features ### Returns a 2D tensor of fake features of size batch_size x z_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "#defines discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feature_dim = 26, hidden_dim = 16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            discriminator_block(feature_dim, hidden_dim),\n",
    "            discriminator_block(hidden_dim, int(hidden_dim/2)),\n",
    "            discriminator_block(int(hidden_dim/2), int(hidden_dim/4)),\n",
    "            nn.Linear(int(hidden_dim/4), 1),\n",
    "            nn.Sigmoid()                    \n",
    "        )\n",
    "    def forward(self, feature_vector):\n",
    "        return self.disc(feature_vector)\n",
    "    \n",
    "def get_disc_loss(gen, disc, criterion, real_features, batch_size, z_dim, a_dim, u_dim):\n",
    "    latent_vectors = get_noise(batch_size, z_dim)\n",
    "    act_vectors = get_act_matrix(batch_size, a_dim)\n",
    "    usr_vectors = get_usr_matrix(batch_size, u_dim)\n",
    "    \n",
    "    to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "    gen.eval()\n",
    "    fake_features = gen(to_gen)\n",
    "    gen.train()\n",
    "    pred_fake = disc(fake_features.detach())\n",
    "    \n",
    "    ground_truth = torch.zeros_like(pred_fake)\n",
    "    loss_fake = criterion(pred_fake, ground_truth)\n",
    "    \n",
    "    pred_real = disc(real_features)\n",
    "    ground_truth = torch.ones_like(pred_real)\n",
    "    loss_real = criterion(pred_real, ground_truth)\n",
    "    \n",
    "    disc_loss = (loss_fake + loss_real) / 2\n",
    "    return disc_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class User_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = 26):\n",
    "        super(User_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3) \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = 26):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            classifier_block(10, 5),\n",
    "            nn.Linear(5, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #softmax = nn.Softmax(dim = 1)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolating acceleration columns with average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replaces Nan values with average values\n",
    "#df: data frame of data to use\n",
    "def interpolation(df):\n",
    "    col_to_avg = list(df.columns) #Start with keeping all the columns as columns to use an average interpolation on\n",
    "    for k in range(len(list(df.columns))):\n",
    "        if list(df.columns)[k].startswith(('discrete', 'label')): #Remove label and discrete columns from col_to_avg\n",
    "            col_to_avg.remove(list(df.columns)[k])\n",
    "    \n",
    "    df_with_avg = df[col_to_avg].fillna(df[col_to_avg].mean()) #Interpolate nan columns for all continuous-valued columns with average\n",
    "    \n",
    "    col_to_zero = list(df.columns)\n",
    "    for k in range(len(list(df.columns))):\n",
    "        if not list(df.columns)[k].startswith(('discrete', 'label')): #Remove all columns except label and discrete\n",
    "            col_to_zero.remove(list(df.columns)[k])\n",
    "    \n",
    "    df_with_zero = df[col_to_zero].fillna(0) #Interpolate nan values for label and discrete columns with 0\n",
    "    \n",
    "    return pd.concat([df_with_avg, df_with_zero], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##prints a plot of a generator batch\n",
    "#gen: generator\n",
    "#b_size: batch size\n",
    "#epochs: current epoch (-1)\n",
    "def visualize_gen_batch(gen, b_size, epochs = -1):\n",
    "    #print(str(b_size))\n",
    "    latent_vectors = get_noise(b_size, z_dim)\n",
    "    #print(latent_vectors.shape)\n",
    "    fake_features = gen(latent_vectors)\n",
    "    #print(fake_features.shape)\n",
    "    \n",
    "    w_img = fake_features\n",
    "    wmin = torch.min(w_img)\n",
    "    wmax = torch.max(w_img)\n",
    "    w_img = w_img.cpu()\n",
    "    w_img = w_img.detach().numpy()\n",
    "    c = plt.imshow(w_img, cmap ='Reds', vmin = wmin , vmax = wmax,\n",
    "                        interpolation ='nearest', origin ='upper')\n",
    "    plt.colorbar(c)\n",
    "    plt.title('Generated Batch at Epoch ' + str(epochs), fontweight =\"bold\")\n",
    "    plt.show()\n",
    "\n",
    "##prints a plot of a batch of real data\n",
    "#features: real data\n",
    "def visualize_real_batch(features):\n",
    "    w_img = features\n",
    "    wmin = torch.min(w_img)\n",
    "    wmax = torch.max(w_img)\n",
    "    w_img = w_img.cpu()\n",
    "    w_img = w_img.detach().numpy()\n",
    "    c = plt.imshow(w_img, cmap ='Reds', vmin = wmin , vmax = wmax,\n",
    "                        interpolation ='nearest', origin ='upper')\n",
    "    plt.colorbar(c)\n",
    "    plt.title('Real Batch of Data', fontweight =\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculates performance statistics for each epoch of training\n",
    "#gen: generator\n",
    "#disc: discriminator\n",
    "#b_size: batch size\n",
    "#z_dim: number of dimensions of the latent space\n",
    "##returns accuracy, precision, recall, fpR, and f1 score\n",
    "def performance_stats(gen, disc, b_size, z_dim, a_dim, u_dim, batch = None):\n",
    "    tp = 0 #true positive\n",
    "    fp = 0 #false positive\n",
    "    tn = 0 #true negative\n",
    "    fn = 0 #false negative\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_hat_fake = torch.Tensor([0])\n",
    "        y_hat_real = torch.Tensor([0])\n",
    "        \n",
    "        if batch is None:\n",
    "            latent_vectors = get_noise(b_size, z_dim)\n",
    "            act_vectors = get_act_matrix(b_size, a_dim)\n",
    "            usr_vectors = get_usr_matrix(b_size, u_dim)\n",
    "            to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "            gen.eval()\n",
    "            fake_features = gen(to_gen)\n",
    "            gen.train()\n",
    "            disc.eval()\n",
    "            y_hat_fake = torch.round(disc(fake_features))\n",
    "            disc.train()\n",
    "        else:\n",
    "            latent_vectors = get_noise(b_size, z_dim)\n",
    "            act_vectors = get_act_matrix(b_size, a_dim)\n",
    "            usr_vectors = get_usr_matrix(b_size, u_dim)\n",
    "            to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "            gen.eval()\n",
    "            fake_features = gen(to_gen)\n",
    "            gen.train()\n",
    "            disc.eval()\n",
    "            y_hat_fake = torch.round(disc(fake_features))\n",
    "            y_hat_real = torch.round(disc(batch))\n",
    "            disc.train()\n",
    "         \n",
    "        fpR = torch.mean(y_hat_fake)\n",
    "        recall = torch.mean(y_hat_real)\n",
    "        class_acc = ((len(y_hat_fake) - torch.sum(y_hat_fake)) + torch.sum(y_hat_real)) / (2*b_size)\n",
    "        #print(f'Classification Accuracy: {class_acc:.2f}'\n",
    "        #print(f'Recall: {recall:.2f}') #What percent of the true positives were identified\n",
    "        return class_acc, recall, fpR\n",
    "      \n",
    "\n",
    "def performance_stats_class(gen, a_class, u_class, batch_size, z_dim, a_dim, u_dim):\n",
    "    tp = 0 #true positive\n",
    "    fp = 0 #false positive\n",
    "    tn = 0 #true negative\n",
    "    fn = 0 #false negative\n",
    "\n",
    "    with torch.no_grad():\n",
    "        latent_vectors = get_noise(batch_size, z_dim)\n",
    "        act_vectors = get_act_matrix(batch_size, a_dim)\n",
    "        usr_vectors = get_usr_matrix(batch_size, u_dim)\n",
    "    \n",
    "        to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "        gen.eval()\n",
    "        fake_features = gen(to_gen)\n",
    "        gen.train()\n",
    "    \n",
    "        _, pred_a_class = torch.max(softmax(a_class(fake_features)), dim = 1)\n",
    "        _, pred_u_class = torch.max(softmax(u_class(fake_features)), dim = 1)\n",
    "        \n",
    "        return torch.eq(act_vectors[0], pred_a_class).sum()/batch_size, torch.eq(usr_vectors[0], pred_u_class).sum()/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Density Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and plot density curves for mean, x, y, z acceleration\n",
    "#reals: real data\n",
    "#fakes: generated data\n",
    "def density_curves(reals, fakes):\n",
    "    plt.figure(figsize = (15, 15))\n",
    "    subplot(2, 2, 1)\n",
    "    sns.kdeplot(fakes.cpu().numpy()[:,0], color = 'r', shade = True, label = 'Fake Distribution')\n",
    "    sns.kdeplot(reals[:,0], color = 'b', shade = True, label = 'Real Distribution')\n",
    "    plt.xlabel('Mean Acceleration')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    subplot(2, 2, 2)\n",
    "    sns.kdeplot(fakes.cpu().numpy()[:,18], color = 'r', shade = True, label = 'Fake Distribution')\n",
    "    sns.kdeplot(reals[:,18], color = 'b', shade = True, label = 'Real Distribution')\n",
    "    plt.xlabel('Mean X-Acceleration')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    subplot(2, 2, 3)\n",
    "    sns.kdeplot(fakes.cpu().numpy()[:,19], color = 'r', shade = True, label = 'Fake Distribution')\n",
    "    sns.kdeplot(reals[:,19], color = 'b', shade = True, label = 'Real Distribution')\n",
    "    plt.xlabel('Mean Y-Acceleration')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    subplot(2, 2, 4)\n",
    "    sns.kdeplot(fakes.cpu().numpy()[:,20], color = 'r', shade = True, label = 'Fake Distribution')\n",
    "    sns.kdeplot(reals[:,20], color = 'b', shade = True, label = 'Real Distribution')\n",
    "    plt.xlabel('Mean Z-Acceleration')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Wassertein distance for each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculate Waaserstein distances for each dimension\n",
    "#gen: generator\n",
    "#z_dim: number of dimensions of the latent space\n",
    "#feature_dim: number ofd dimensions in the feature space\n",
    "#sample: sample of data\n",
    "def all_Wasserstein_dists(gen, z_dim, feature_dim, sample):\n",
    "    wasser_dim = []\n",
    "    latent_vectors = get_noise(len(sample), z_dim)\n",
    "    gen.eval()\n",
    "    fake_features = gen(latent_vectors)\n",
    "    gen.train()\n",
    "    for k in range(feature_dim):\n",
    "        wasser_dim.append(wasserstein_distance(fake_features[:, k].cpu().detach().numpy(), sample[:, k].cpu().detach().numpy()))\n",
    "    return torch.tensor(wasser_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Generation Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates and prints a plot of the generated vs real data\n",
    "#data: data used\n",
    "#gen: generator\n",
    "#z_dim: number of dimensions of the latent space\n",
    "def visualize_gen(data, gen, z_dim, a_dim, u_dim):\n",
    "    #Number of datum to visualize\n",
    "    sample_size = len(data)\n",
    "    reals = data[0:sample_size, :]\n",
    "    fakes = get_fake_samples(gen, sample_size, z_dim).detach()\n",
    "    density_curves(reals, fakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###initalize parameters that depend on training loop parameters\n",
    "#X: acceleration data\n",
    "#y: labels associated with X data (fake or real)\n",
    "#z_dim: number of dimensions to the latent space\n",
    "#disc_lr: discriminator learning rate\n",
    "#gen_lr: generator learning rate\n",
    "#DISCRIMINATOR: 1 to indicate if discriminator is training\n",
    "#batch_size: batch size\n",
    "#disc: initialized discrimiantor\n",
    "\n",
    "def initialize_params(X, y, z_dim, a_dim, u_dim, disc_lr, gen_lr, DISCRIMINATOR, batch_size, disc):\n",
    "    #initialize generator\n",
    "    gen = Generator(z_dim + a_dim + u_dim).to(device)\n",
    "    #indicate that discriminator is training\n",
    "    to_train = DISCRIMINATOR\n",
    "    #create training features\n",
    "    train_features = torch.tensor(X)\n",
    "    #create training labels\n",
    "    train_labels = torch.tensor(y)\n",
    "    #concatenate to create training data\n",
    "    train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    #create data loader for training data\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "    #initialize generator and discriminator optimizers\n",
    "    opt_disc = optim.Adam(disc.parameters(), lr = disc_lr)\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr = gen_lr)\n",
    "    \n",
    "    return gen, to_train, train_features, train_labels, train_data, train_loader, opt_disc, opt_gen   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save / Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change path and name of the Generator and Discriminator accordingly\n",
    "def save_model(gen, disc, model_name):\n",
    "    torch.save(gen.state_dict(), f\"saved_models/{model_name}_gen.param\")\n",
    "    torch.save(disc.state_dict(), f\"saved_models/{model_name}_disc.param\")\n",
    "    \n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Training loop to train GAN\n",
    "\n",
    "#Parameters to specifiy: \n",
    "    #X: starting accelerometer data\n",
    "    #y: starting labels for X data (fake or real)\n",
    "    \n",
    "#Set parameters (do not change)\n",
    "    #criterion: loss function (BCE)\n",
    "    #dig: number of significant digits for printing (5)\n",
    "    #feature_dim: Number of dimensions of output from generator (26)\n",
    "    #GENERATOR: set generator to zero for training\n",
    "    #DISCRIMINATOR: set discriminator to one for training\n",
    "    #train_string: starting machine to train (DISC)\n",
    "    #disc: initalize discriminator\n",
    "    #rel_epochs: Epochs passed since last switch (constant training) (0)\n",
    "    #rows: initialization of array to save data of each epoch to CSV file ([])\n",
    "    #heading: array of column headings for table ([\"Epoch\", \"Machine Training\", \"Discriminator Loss\", \n",
    "                    #\"Generator Loss\", \"FPR\", \"Recall\", \"Median Wasserstein\", \"Mean Wasserstein\"])\n",
    "    #table: intialize a table as a pretty table to save epoch data\n",
    "    #switch_count: number of switches in dynamic training (0)\n",
    "    \n",
    "#Set parameters (can change):\n",
    "    #z_dim: number of dimensions of latent vector (100)\n",
    "    #gen_lr: generator learning rate (.001)\n",
    "    #disc_lr: discriminator learning rate (.001) (shoud be equal to gen_lr)\n",
    "    #batch_size: batch size (75)\n",
    "    #print_batches: Show model performance per batch (False)\n",
    "    #n_epochs: number of epochs to train (100)\n",
    "    #constant_train_flag: (False)\n",
    "        #Set to true to train based on constant # of epochs per machine \n",
    "        #Set to false to train dynamically based on machine performance\n",
    "        \n",
    "    #Constant training approach:\n",
    "        #disc_epochs: Number of consecutive epochs to train discriminator before epoch threshold (5)\n",
    "        #gen_epochs: Number of consecutive epochs to train generator before epoch threshold (2)\n",
    "        #epoch_threshold: Epoch number to change training epoch ratio (50)\n",
    "        #disc_epochs_change: New number of consecutive epochs to train discriminator after epoch threshold is exceeded (1)\n",
    "        #gen_epochs_change: New number of consecutive epochs to train generator after epoch threshold is exceeded (50)\n",
    "    \n",
    "    #Dynamic training approach:                        \n",
    "        #static_threshold: Epoch number to change from static ratio to dynamic (18)\n",
    "        #static_disc_epochs: Number of consecutive epochs to train discriminator before epoch threshold (4)\n",
    "        #static_gen_epochs: Number of consecutive epochs to train generator before epoch threshold (2)\n",
    "        #pull_threshold: Accuracy threshold for switching machine training when the generator is no longer competitive (0.4)\n",
    "        #push_threshold: Accuracy threshold for switching machine training when the discriminator is no longer competitive (0.6)\n",
    "        #recall_threshold: threshold for recall to switch machine training when discriminator is training well\n",
    "        #switch_flag: indicates if we should switch our training machine (False)\n",
    "        \n",
    "def training_loop(X, y, act, usr, criterion1 = nn.BCELoss(), criterion2 = nn.CrossEntropyLoss(), gan_id = \"Mod Test Gan\", dig = 5, feature_dim = 26, \n",
    "                  GENERATOR = 0, DISCRIMINATOR = 1, train_string = \"DISC\", disc = Discriminator(), z_dim = 100, a_dim = 3, u_dim = 3, \n",
    "                  gen_lr =  0.001, disc_lr = 0.001, batch_size = 100, constant_train_flag = False, disc_epochs = 5,\n",
    "                  gen_epochs = 2, epoch_threshold = 50, disc_epochs_change = 5, gen_epochs_change = 2, rel_epochs = 0,\n",
    "                 static_threshold = 28, static_disc_epochs = 5, static_gen_epochs = 2, pull_threshold = 0.3,\n",
    "                 push_threshold = 0.7, recall_threshold = 0.75, n_epochs = 1000, rows = [],\n",
    "                 heading = [\"Epoch\", \"Training\", \"Discriminator Loss\", \"Generator Loss\", \"D_Accuracy\", \"D_fpR\", \"D_Recall\", \"A_fpR\", \"U_fpR\"],\n",
    "                 table = PrettyTable(), switch_flag = False, switch_count = 0, last_real_features = []):\n",
    "    \n",
    "    disc.to(device)\n",
    "    #returns generator, sets discriminator training, creates training tensor, loads data, and initializes optimizers\n",
    "    gen, to_train, train_features, train_labels, train_data, train_loader, opt_disc, opt_gen = initialize_params(X, y, z_dim, a_dim, u_dim, disc_lr, gen_lr, DISCRIMINATOR, batch_size, disc)\n",
    "\n",
    "    #set pretty table field names\n",
    "    table.field_names = heading\n",
    "    \n",
    "    #visualize_gen(X, gen, z_dim, a_dim, u_dim)\n",
    "    gen_epochs = 0\n",
    "    \n",
    "    last_D_loss = -1.0\n",
    "    last_G_loss = -1.0\n",
    "    \n",
    "    mean_mean = []\n",
    "    mean_median = []\n",
    "    \n",
    "    for epoch in range(n_epochs):  \n",
    "        if constant_train_flag:\n",
    "            if to_train == DISCRIMINATOR and rel_epochs >= disc_epochs:\n",
    "                rel_epochs = 0\n",
    "                to_train = GENERATOR\n",
    "                train_string = \"GEN\"\n",
    "\n",
    "            elif to_train == GENERATOR and rel_epochs >= gen_epochs:\n",
    "                rel_epochs = 0\n",
    "                to_train = DISCRIMINATOR\n",
    "                train_string = \"DISC\"\n",
    "\n",
    "            # Change epoch ratio after intial 'leveling out'\n",
    "            if epoch == epoch_threshold:\n",
    "                rel_epochs = 0\n",
    "                to_train = GENERATOR\n",
    "                train_string = \"GEN\"\n",
    "\n",
    "                old_ratio = gen_epochs / disc_epochs\n",
    "                gen_epochs = gen_epochs_change\n",
    "                disc_epochs = disc_epochs_change\n",
    "                new_ratio = gen_epochs / disc_epochs\n",
    "                print(f'\\n\\nTraining ratio of G/D switched from {old_ratio:.{dig}f} to {new_ratio:.{dig}f}\\n\\n')\n",
    "        else:\n",
    "            if epoch < static_threshold:\n",
    "                if to_train == DISCRIMINATOR and rel_epochs >= static_disc_epochs:\n",
    "                    rel_epochs = 0\n",
    "                    to_train = GENERATOR\n",
    "                    train_string = \"GEN\"\n",
    "\n",
    "                elif to_train == GENERATOR and rel_epochs >= static_gen_epochs:\n",
    "                    rel_epochs = 0\n",
    "                    to_train = DISCRIMINATOR\n",
    "                    train_string = \"DISC\"\n",
    "\n",
    "            else:\n",
    "                if not switch_flag:\n",
    "                    print(\"\\nSwitching to Dynamic Training\\n\")\n",
    "                    switch_flag = True\n",
    "                    to_train = DISCRIMINATOR\n",
    "                    train_string = \"DISC\"\n",
    "                if to_train == DISCRIMINATOR and fpR <= pull_threshold and R >= recall_threshold:\n",
    "                    to_train = GENERATOR\n",
    "                    train_string = \"GEN\"\n",
    "                    print(\"\\nPull Generator\\n\")\n",
    "                    switch_count += 1\n",
    "                if to_train == GENERATOR and fpR >= push_threshold:\n",
    "                    to_train = DISCRIMINATOR\n",
    "                    train_string = \"DISC\"\n",
    "                    print(\"\\nPush Generator\\n\")\n",
    "                    switch_count += 1\n",
    "                    \n",
    "        print(f'Epoch[{epoch + 1}/{n_epochs}] Train: {train_string} ', end ='')\n",
    "        \n",
    "        for batch_idx, (real_features, _) in enumerate(train_loader):\n",
    "            #Size of this current batch\n",
    "            batch_size = len(real_features)\n",
    "            #Send batch to GPU\n",
    "            real_features = real_features.float().to(device)\n",
    "            \n",
    "            if to_train == DISCRIMINATOR:\n",
    "                ### Training Discriminator\n",
    "                #visualize_real_batch(real_features.float())\n",
    "                opt_disc.zero_grad()\n",
    "                disc_loss = get_disc_loss(gen, disc, criterion1, real_features, batch_size, z_dim, a_dim, u_dim)\n",
    "                disc_loss.backward(retain_graph = True)\n",
    "                opt_disc.step()\n",
    "                last_D_loss = disc_loss.item()\n",
    "                # If generator has yet to ever train, run intial evaluation\n",
    "                if last_G_loss == -1.0:\n",
    "                    last_G_loss = get_gen_loss(gen, disc, act, usr, criterion1, criterion2, batch_size, z_dim, a_dim, u_dim)\n",
    "                \n",
    "            else:\n",
    "                ### Training Generator\n",
    "                opt_gen.zero_grad()\n",
    "                gen_loss = get_gen_loss(gen, disc, act, usr, criterion1, criterion2, batch_size, z_dim, a_dim, u_dim)\n",
    "                gen_loss.backward()\n",
    "                opt_gen.step()\n",
    "                last_G_loss = gen_loss.item()\n",
    "                # If discriminator has yet to ever train, run intial evaluation\n",
    "                if last_D_loss == -1.0:\n",
    "                    last_D_loss = get_disc_loss(gen, disc, criterion1, real_features, batch_size, z_dim, a_dim, u_dim)\n",
    "                \n",
    "            if batch_idx == (len(train_loader) - 1):\n",
    "                acc, R, fpR = performance_stats(gen, disc, batch_size, z_dim, a_dim, u_dim, batch = real_features)\n",
    "                A_fpR, U_fpR = performance_stats_class(gen, act, usr, batch_size, z_dim, a_dim, u_dim)\n",
    "                #w_dist = all_Wasserstein_dists(gen, z_dim, feature_dim, real_features.float())\n",
    "                #median_w_dist = torch.median(w_dist)\n",
    "                #mean_w_dist = torch.mean(w_dist)\n",
    "                \n",
    "                #mean_mean.append(mean_w_dist)\n",
    "                #mean_median.append(median_w_dist)\n",
    "                \n",
    "        mean_mean_w = torch.mean(torch.Tensor(mean_mean)) \n",
    "        mean_median_w = torch.mean(torch.Tensor(mean_median))\n",
    "            \n",
    "        ### Currently doesn't print Median/Mean Wasserstein --> Change if needed\n",
    "        print(f'| LossD: {last_D_loss:.{dig}f}, LossG: {last_G_loss:.{dig}f} | Acc: {acc:.{dig}f} | fpR: {fpR:.{dig}f} | R: {R:.{dig}f} | A_fpR: {A_fpR:.{dig}f} | U_fpR: {U_fpR:.{dig}f}')\n",
    "        row_to_add = [f\"{epoch + 1}\", train_string, f\"{last_D_loss:.{dig}f}\", f\"{last_G_loss:.{dig}f}\", f\"{acc:.{dig}f}\", f\"{fpR:.{dig}f}\", f\"{R:.{dig}f}\", f\"{A_fpR:.{dig}f}\", f\"{U_fpR:.{dig}f}\"]\n",
    "        table.add_row(row_to_add)\n",
    "        rows.append(row_to_add)\n",
    "                \n",
    "        if to_train == GENERATOR:\n",
    "            gen_epochs += 1\n",
    "            \n",
    "        mean_mean.clear()\n",
    "        mean_median.clear()\n",
    "        rel_epochs += 1\n",
    "        \n",
    "        \n",
    "    print(\"\\n\\nTraining Session Finished\")\n",
    "    print(f\"Encountered {switch_count} non-trivial training swaps\")\n",
    "    percent = gen_epochs / n_epochs\n",
    "    print(f\"Trained Generator {gen_epochs} out of {n_epochs} ({percent:.3f})\")\n",
    "    f = open(\"model_outputs/\" + gan_id + \".txt\", \"w\")\n",
    "    f.write(table.get_string())\n",
    "    f.close()\n",
    "    print(\"Model Results Sucessfully Saved to \\\"model_outputs/\" + gan_id + \".txt\\\"\")\n",
    "\n",
    "    with open(\"model_outputs/\" + gan_id + \".csv\", \"w\") as csvfile: \n",
    "        # creating a csv writer object \n",
    "        csvwriter = csv.writer(csvfile) \n",
    "        # writing the fields \n",
    "        csvwriter.writerow(heading)\n",
    "        # writing the data rows \n",
    "        csvwriter.writerows(rows)\n",
    "    print(\"Model Results Sucessfully Saved to \\\"model_outputs/\" + gan_id + \".csv\\\"\")\n",
    "    save_model(gen, disc, gan_id)\n",
    "    print(\"Generator's Trained Parameters Sucessfully Saved to \\\"saved_models/\" + gan_id + \"_gen.param\\\"\")\n",
    "    print(\"Discriminators's Trained Parameters Sucessfully Saved to \\\"saved_models/\" + gan_id + \"_disc.param\\\"\")\n",
    "    model_output = pd.read_csv(\"model_outputs/\" + gan_id + \".csv\")\n",
    "    #visualize_gen(X, gen, z_dim)\n",
    "    # Change path and name of the Generator and Discriminator accordingly\n",
    "    save_model(gen, disc, gan_id)\n",
    "    \n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot metrics based on data (csv)\n",
    "def plot_metrics(data, vanilla = True):\n",
    "    if vanilla:\n",
    "        sns.set(style = 'whitegrid', context = 'talk', palette = 'rainbow')\n",
    "    \n",
    "        plt.figure(figsize = (15, 15))\n",
    "        subplot(2, 2, 1)\n",
    "        sns.scatterplot(x = 'Epoch', y = 'D_fpR', data = data).set(xlim = (0, None))\n",
    "        sns.despine()\n",
    "        \n",
    "        subplot(2, 2, 2)\n",
    "        sns.scatterplot(x = 'Epoch', y = 'D_Recall', data = data).set(xlim = (0, None))\n",
    "        sns.despine()\n",
    "        \n",
    "        subplot(2, 2, 3)\n",
    "        sns.regplot(x = 'Epoch', y = 'Median Wasserstein', data = data, line_kws = {'color': 'orange'}).set(xlim = (0, None))\n",
    "        sns.despine()\n",
    "        \n",
    "        subplot(2, 2, 4)\n",
    "        sns.regplot(x = 'Epoch', y = 'Mean Wasserstein', data = data, line_kws = {'color': 'orange'}).set(xlim = (0, None))\n",
    "        sns.despine()\n",
    "        plt.show()\n",
    "    else:\n",
    "        sns.set(style = 'whitegrid', context = 'talk', palette = 'rainbow')\n",
    "        plt.figure(figsize = (15, 8))\n",
    "        \n",
    "        subplot(1, 2, 1)\n",
    "        sns.regplot(x = 'Epoch', y = 'Median Wasserstein', data = data, line_kws = {'color': 'orange'}).set(xlim = (0, None))\n",
    "        sns.despine()\n",
    "        \n",
    "        subplot(1, 2, 2)\n",
    "        sns.regplot(x = 'Epoch', y = 'Mean Wasserstein', data = data, line_kws = {'color': 'orange'}).set(xlim = (0, None))\n",
    "        sns.despine()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/50] Train: DISC | LossD: 0.72431, LossG: 10.03079 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32827 | U_fpR: 0.32954\n",
      "Epoch[2/50] Train: DISC | LossD: 0.72388, LossG: 10.03079 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.34104 | U_fpR: 0.33345\n",
      "Epoch[3/50] Train: DISC | LossD: 0.72353, LossG: 10.03079 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33494 | U_fpR: 0.33126\n",
      "Epoch[4/50] Train: DISC | LossD: 0.72315, LossG: 10.03079 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.34668 | U_fpR: 0.33632\n",
      "Epoch[5/50] Train: DISC | LossD: 0.72277, LossG: 10.03079 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33644 | U_fpR: 0.33000\n",
      "Epoch[6/50] Train: GEN | LossD: 0.72277, LossG: 10.35830 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32885 | U_fpR: 0.33817\n",
      "Epoch[7/50] Train: GEN | LossD: 0.72277, LossG: 9.26776 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32620 | U_fpR: 0.32666\n",
      "Epoch[8/50] Train: DISC | LossD: 0.72226, LossG: 9.26776 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33805 | U_fpR: 0.32562\n",
      "Epoch[9/50] Train: DISC | LossD: 0.72194, LossG: 9.26776 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33506 | U_fpR: 0.33759\n",
      "Epoch[10/50] Train: DISC | LossD: 0.72161, LossG: 9.26776 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33448 | U_fpR: 0.34139\n",
      "Epoch[11/50] Train: DISC | LossD: 0.72116, LossG: 9.26776 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33598 | U_fpR: 0.32908\n",
      "Epoch[12/50] Train: DISC | LossD: 0.72079, LossG: 9.26776 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32378 | U_fpR: 0.34024\n",
      "Epoch[13/50] Train: GEN | LossD: 0.72079, LossG: 8.72189 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33563 | U_fpR: 0.32528\n",
      "Epoch[14/50] Train: GEN | LossD: 0.72079, LossG: 8.21581 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32539 | U_fpR: 0.33851\n",
      "Epoch[15/50] Train: DISC | LossD: 0.72037, LossG: 8.21581 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32735 | U_fpR: 0.33552\n",
      "Epoch[16/50] Train: DISC | LossD: 0.72006, LossG: 8.21581 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32712 | U_fpR: 0.33667\n",
      "Epoch[17/50] Train: DISC | LossD: 0.71954, LossG: 8.21581 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32781 | U_fpR: 0.33034\n",
      "Epoch[18/50] Train: DISC | LossD: 0.71905, LossG: 8.21581 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32700 | U_fpR: 0.33241\n",
      "Epoch[19/50] Train: DISC | LossD: 0.71867, LossG: 8.21581 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33138 | U_fpR: 0.33632\n",
      "Epoch[20/50] Train: GEN | LossD: 0.71867, LossG: 7.83054 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33322 | U_fpR: 0.33264\n",
      "Epoch[21/50] Train: GEN | LossD: 0.71867, LossG: 7.63679 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33506 | U_fpR: 0.33368\n",
      "Epoch[22/50] Train: DISC | LossD: 0.71831, LossG: 7.63679 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33955 | U_fpR: 0.33046\n",
      "Epoch[23/50] Train: DISC | LossD: 0.71780, LossG: 7.63679 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32677 | U_fpR: 0.33609\n",
      "Epoch[24/50] Train: DISC | LossD: 0.71737, LossG: 7.63679 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32977 | U_fpR: 0.33368\n",
      "Epoch[25/50] Train: DISC | LossD: 0.71679, LossG: 7.63679 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32931 | U_fpR: 0.33840\n",
      "Epoch[26/50] Train: DISC | LossD: 0.71633, LossG: 7.63679 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33471 | U_fpR: 0.33725\n",
      "Epoch[27/50] Train: GEN | LossD: 0.71633, LossG: 7.26097 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32516 | U_fpR: 0.33276\n",
      "Epoch[28/50] Train: GEN | LossD: 0.71633, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32217 | U_fpR: 0.32793\n",
      "\n",
      "Switching to Dynamic Training\n",
      "\n",
      "Epoch[29/50] Train: DISC | LossD: 0.71578, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33333 | U_fpR: 0.33161\n",
      "Epoch[30/50] Train: DISC | LossD: 0.71522, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32332 | U_fpR: 0.33886\n",
      "Epoch[31/50] Train: DISC | LossD: 0.71485, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32885 | U_fpR: 0.34070\n",
      "Epoch[32/50] Train: DISC | LossD: 0.71431, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32183 | U_fpR: 0.33299\n",
      "Epoch[33/50] Train: DISC | LossD: 0.71368, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32954 | U_fpR: 0.33609\n",
      "Epoch[34/50] Train: DISC | LossD: 0.71285, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32505 | U_fpR: 0.33817\n",
      "Epoch[35/50] Train: DISC | LossD: 0.71233, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32424 | U_fpR: 0.34634\n",
      "Epoch[36/50] Train: DISC | LossD: 0.71166, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32954 | U_fpR: 0.32793\n",
      "Epoch[37/50] Train: DISC | LossD: 0.71099, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32931 | U_fpR: 0.32977\n",
      "Epoch[38/50] Train: DISC | LossD: 0.71020, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33172 | U_fpR: 0.34012\n",
      "Epoch[39/50] Train: DISC | LossD: 0.70950, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32747 | U_fpR: 0.32885\n",
      "Epoch[40/50] Train: DISC | LossD: 0.70859, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32355 | U_fpR: 0.33195\n",
      "Epoch[41/50] Train: DISC | LossD: 0.70774, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32827 | U_fpR: 0.33368\n",
      "Epoch[42/50] Train: DISC | LossD: 0.70687, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32724 | U_fpR: 0.33817\n",
      "Epoch[43/50] Train: DISC | LossD: 0.70579, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33080 | U_fpR: 0.33414\n",
      "Epoch[44/50] Train: DISC | LossD: 0.70508, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33000 | U_fpR: 0.33322\n",
      "Epoch[45/50] Train: DISC | LossD: 0.70375, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32988 | U_fpR: 0.33552\n",
      "Epoch[46/50] Train: DISC | LossD: 0.70290, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32620 | U_fpR: 0.32988\n",
      "Epoch[47/50] Train: DISC | LossD: 0.70164, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33184 | U_fpR: 0.32850\n",
      "Epoch[48/50] Train: DISC | LossD: 0.70067, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.32493 | U_fpR: 0.33759\n",
      "Epoch[49/50] Train: DISC | LossD: 0.69924, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33299 | U_fpR: 0.33609\n",
      "Epoch[50/50] Train: DISC | LossD: 0.69813, LossG: 6.83204 | Acc: 0.50000 | fpR: 1.00000 | R: 1.00000 | A_fpR: 0.33195 | U_fpR: 0.33448\n",
      "\n",
      "\n",
      "Training Session Finished\n",
      "Encountered 0 non-trivial training swaps\n",
      "Trained Generator 8 out of 50 (0.160)\n",
      "Model Results Sucessfully Saved to \"model_outputs/cGAN_trained.txt\"\n",
      "Model Results Sucessfully Saved to \"model_outputs/cGAN_trained.csv\"\n",
      "         4241571 function calls (4222780 primitive calls) in 7.899 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        9    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(concatenate)\n",
      "      302    0.001    0.000    0.010    0.000 <__array_function__ internals>:2(prod)\n",
      "       17    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "        1    0.000    0.000    0.004    0.004 <ipython-input-16-f1e6e7611ed9>:11(initialize_params)\n",
      "        2    0.000    0.000    0.012    0.006 <ipython-input-17-473ec4637da1>:2(save_model)\n",
      "       50    0.005    0.000    0.620    0.012 <ipython-input-26-e80cee953625>:49(performance_stats_class)\n",
      "       50    0.005    0.000    0.614    0.012 <ipython-input-26-e80cee953625>:7(performance_stats)\n",
      "        1    0.029    0.029    7.899    7.899 <ipython-input-37-cd2bb1e3035f>:49(training_loop)\n",
      "      151    0.054    0.000    1.296    0.009 <ipython-input-5-0f12b0bee3b9>:12(get_noise)\n",
      "        1    0.000    0.000    0.002    0.002 <ipython-input-5-0f12b0bee3b9>:18(__init__)\n",
      "      151    0.001    0.000    0.144    0.001 <ipython-input-5-0f12b0bee3b9>:27(forward)\n",
      "        4    0.000    0.000    0.001    0.000 <ipython-input-5-0f12b0bee3b9>:3(generator_block)\n",
      "        9    0.001    0.000    0.121    0.013 <ipython-input-5-0f12b0bee3b9>:37(get_gen_loss)\n",
      "      151    0.032    0.000    0.096    0.001 <ipython-input-5-0f12b0bee3b9>:57(get_act_matrix)\n",
      "      151    0.027    0.000    0.079    0.001 <ipython-input-5-0f12b0bee3b9>:66(get_usr_matrix)\n",
      "      193    0.001    0.000    0.102    0.001 <ipython-input-7-7834af6c95ab>:19(forward)\n",
      "       42    0.004    0.000    0.546    0.013 <ipython-input-7-7834af6c95ab>:22(get_disc_loss)\n",
      "       59    0.000    0.000    0.024    0.000 <ipython-input-8-8f7159e71621>:17(forward)\n",
      "       59    0.000    0.000    0.032    0.001 <ipython-input-9-605984e1a986>:18(forward)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:2(__init__)\n",
      "     1596    0.001    0.000    0.002    0.000 _VF.py:25(__getattr__)\n",
      "       26    0.000    0.000    0.000    0.000 __future__.py:18(get_overwrite_module_params_on_conversion)\n",
      "       76    0.000    0.000    0.000    0.000 __init__.py:107(is_initialized)\n",
      "       76    0.000    0.000    0.000    0.000 __init__.py:144(_lazy_init)\n",
      "       76    0.000    0.000    0.000    0.000 __init__.py:216(__init__)\n",
      "       76    0.000    0.000    0.000    0.000 __init__.py:220(__enter__)\n",
      "       76    0.000    0.000    0.000    0.000 __init__.py:228(__exit__)\n",
      "     1808    0.000    0.000    0.000    0.000 __init__.py:271(is_storage)\n",
      "       50    0.000    0.000    0.002    0.000 __init__.py:28(_make_grads)\n",
      "      604    0.000    0.000    0.001    0.000 __init__.py:31(__get__)\n",
      "       76    0.000    0.000    0.005    0.000 __init__.py:491(type)\n",
      "       50    0.000    0.000    0.000    0.000 __init__.py:60(_tensor_or_tensors_to_tuple)\n",
      "       50    0.000    0.000    0.085    0.002 __init__.py:68(backward)\n",
      "       22    0.000    0.000    0.000    0.000 _asarray.py:14(asarray)\n",
      "        3    0.000    0.000    0.000    0.000 _asarray.py:221(require)\n",
      "        3    0.000    0.000    0.000    0.000 _asarray.py:298(<setcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 _bootlocale.py:11(getpreferredencoding)\n",
      "       50    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
      "       16    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
      "       16    0.000    0.000    0.000    0.000 _dtype.py:307(_name_includes_bit_suffix)\n",
      "       16    0.000    0.000    0.000    0.000 _dtype.py:321(_name_get)\n",
      "       50    0.012    0.000    0.046    0.001 _functional.py:53(adam)\n",
      "      194    0.000    0.000    0.000    0.000 _jit_internal.py:833(is_scripting)\n",
      "      302    0.000    0.000    0.005    0.000 _methods.py:37(_amax)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:53(_any)\n",
      "       76    0.000    0.000    0.000    0.000 _namedtensor_internals.py:10(check_serializing_named_tensor)\n",
      "      111    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)\n",
      "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:132(geterr)\n",
      "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:32(seterr)\n",
      "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:429(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:433(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:438(__exit__)\n",
      "       76    0.000    0.000    0.004    0.000 _utils.py:11(_type)\n",
      "       76    0.000    0.000    0.000    0.000 _utils.py:462(_get_device_index)\n",
      "       76    0.000    0.000    0.000    0.000 _utils.py:8(_get_device_index)\n",
      "       76    0.000    0.000    0.000    0.000 _utils.py:83(_get_async_or_non_blocking)\n",
      "       51    0.000    0.000    0.000    0.000 abc.py:100(__subclasscheck__)\n",
      "      120    0.000    0.000    0.001    0.000 abc.py:96(__instancecheck__)\n",
      "      604    0.001    0.000    0.012    0.000 activation.py:101(forward)\n",
      "      100    0.000    0.000    0.002    0.000 activation.py:1199(forward)\n",
      "      193    0.000    0.000    0.004    0.000 activation.py:298(forward)\n",
      "      992    0.001    0.000    0.022    0.000 activation.py:713(forward)\n",
      "        4    0.000    0.000    0.000    0.000 activation.py:97(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 adam.py:34(__init__)\n",
      "       50    0.002    0.000    0.052    0.001 adam.py:55(step)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1232(name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1239(name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:2134(_is_all_dates)\n",
      "      7/3    0.000    0.000    0.001    0.000 base.py:250(__new__)\n",
      "      131    0.000    0.000    0.000    0.000 base.py:254(is_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:381(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:397(ndim)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:4070(_values)\n",
      "       95    0.000    0.000    0.000    0.000 base.py:411(find)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:425(_simple_new)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:4279(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:4393(equals)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4472(identical)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:4485(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:532(is_)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:563(_reset_identity)\n",
      "        9    0.000    0.000    0.001    0.000 base.py:5836(ensure_index)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:5953(maybe_extract_name)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:5969(_maybe_cast_with_dtype)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:600(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:6023(_maybe_cast_data_without_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:623(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:796(__iter__)\n",
      "      604    0.000    0.000    0.001    0.000 batchnorm.py:210(_check_input_dim)\n",
      "        4    0.000    0.000    0.001    0.000 batchnorm.py:25(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 batchnorm.py:55(reset_running_stats)\n",
      "        4    0.000    0.000    0.000    0.000 batchnorm.py:63(reset_parameters)\n",
      "        4    0.000    0.000    0.001    0.000 batchnorm.py:94(__init__)\n",
      "      604    0.007    0.000    0.046    0.000 batchnorm.py:99(forward)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:127(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:147(_maybe_coerce_values)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:161(_check_ndim)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:233(internal_values)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:2505(_maybe_coerce_values)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:265(mgr_locs)\n",
      "       14    0.000    0.000    0.000    0.000 blocks.py:2662(get_block_type)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:269(mgr_locs)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:2711(make_block)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:343(shape)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:347(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 cProfile.py:133(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 cast.py:1257(maybe_castable)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1273(maybe_infer_to_datetimelike)\n",
      "        4    0.000    0.000    0.000    0.000 cast.py:1379(maybe_cast_to_datetime)\n",
      "        3    0.000    0.000    0.000    0.000 cast.py:1617(construct_1d_object_array_from_listlike)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1642(construct_1d_ndarray_preserving_na)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:186(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 codecs.py:319(decode)\n",
      "        3    0.000    0.000    0.000    0.000 codecs.py:331(getstate)\n",
      "   150/50    0.231    0.002    1.455    0.029 collate.py:42(default_collate)\n",
      "   434550    0.126    0.000    0.158    0.000 collate.py:80(<genexpr>)\n",
      "       50    0.021    0.000    1.019    0.020 collate.py:83(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:108(is_url)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1187(needs_i8_conversion)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:126(_expand_user)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1276(is_string_like_dtype)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:129(cast_scalar_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1304(<lambda>)\n",
      "       19    0.000    0.000    0.000    0.000 common.py:1307(is_float_dtype)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:1341(is_bool_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:145(validate_header_arg)\n",
      "       94    0.000    0.000    0.000    0.000 common.py:1470(is_extension_array_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:154(stringify_path)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:1551(_is_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:157(ensure_python_int)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:1575(get_dtype)\n",
      "       95    0.000    0.000    0.000    0.000 common.py:1610(_is_dtype_type)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:170(all_none)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:174(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:1743(validate_all_hashable)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:1762(<genexpr>)\n",
      "       13    0.000    0.000    0.000    0.000 common.py:1769(pandas_dtype)\n",
      "       57    0.000    0.000    0.000    0.000 common.py:185(classes)\n",
      "       57    0.000    0.000    0.000    0.000 common.py:187(<lambda>)\n",
      "       38    0.000    0.000    0.000    0.000 common.py:190(classes_and_not_datetimelike)\n",
      "       38    0.000    0.000    0.000    0.000 common.py:195(<lambda>)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:198(asarray_tuplesafe)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:198(is_fsspec_url)\n",
      "       32    0.000    0.000    0.000    0.000 common.py:201(is_object_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:210(_get_filepath_or_buffer)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:231(is_sparse)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:254(maybe_iterable_to_list)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:355(is_datetime64_dtype)\n",
      "       16    0.000    0.000    0.000    0.000 common.py:388(is_datetime64tz_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:403(get_compression_method)\n",
      "       16    0.000    0.000    0.000    0.000 common.py:429(is_timedelta64_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:438(infer_compression)\n",
      "       31    0.000    0.000    0.000    0.000 common.py:463(is_period_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:491(get_handle)\n",
      "       31    0.000    0.000    0.000    0.000 common.py:499(is_interval_dtype)\n",
      "       68    0.000    0.000    0.000    0.000 common.py:537(is_categorical_dtype)\n",
      "       13    0.000    0.000    0.000    0.000 common.py:573(is_string_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:602(condition)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:605(is_excluded_dtype)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:610(<genexpr>)\n",
      "       26    0.000    0.000    0.000    0.000 common.py:703(is_integer_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:757(is_signed_integer_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:793(_maybe_memory_map)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:81(close)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:813(is_unsigned_integer_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:846(_is_binary_mode)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:912(is_datetime64_any_dtype)\n",
      "        1    0.000    0.000    0.002    0.002 construction.py:241(init_dict)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:333(_homogenize)\n",
      "       12    0.000    0.000    0.000    0.000 construction.py:354(extract_array)\n",
      "       11    0.000    0.000    0.000    0.000 construction.py:423(sanitize_array)\n",
      "       11    0.000    0.000    0.000    0.000 construction.py:554(_try_cast)\n",
      "        4    0.000    0.000    0.000    0.000 construction.py:612(is_empty_data)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:62(arrays_to_mgr)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:632(create_series_with_explicit_dtype)\n",
      "     2058    0.002    0.000    0.003    0.000 container.py:109(__iter__)\n",
      " 2058/462    0.017    0.000    0.296    0.001 container.py:117(forward)\n",
      "        5    0.000    0.000    0.000    0.000 container.py:62(__init__)\n",
      "    501/1    0.000    0.000    0.001    0.001 copy.py:128(deepcopy)\n",
      "      450    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)\n",
      "     51/1    0.000    0.000    0.001    0.001 copy.py:200(_deepcopy_list)\n",
      "       51    0.000    0.000    0.000    0.000 copy.py:242(_keep_alive)\n",
      "       52    0.000    0.000    0.000    0.000 cp1252.py:18(encode)\n",
      "       16    0.000    0.000    0.000    0.000 cycler.py:227(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:158(__init__)\n",
      "       50    0.000    0.000    0.011    0.000 dataloader.py:296(_get_iterator)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:307(multiprocessing_context)\n",
      "    19/18    0.000    0.000    0.000    0.000 dataloader.py:332(__setattr__)\n",
      "       50    0.000    0.000    0.011    0.000 dataloader.py:342(__iter__)\n",
      "      151    0.000    0.000    0.000    0.000 dataloader.py:357(_auto_collation)\n",
      "      100    0.000    0.000    0.000    0.000 dataloader.py:361(_index_sampler)\n",
      "       50    0.000    0.000    0.001    0.000 dataloader.py:373(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:402(check_worker_number_rationality)\n",
      "       50    0.000    0.000    0.000    0.000 dataloader.py:46(create_fetcher)\n",
      "       50    0.001    0.000    0.010    0.000 dataloader.py:481(__init__)\n",
      "      100    0.000    0.000    0.392    0.004 dataloader.py:507(_next_index)\n",
      "      100    0.001    0.000    5.636    0.056 dataloader.py:513(__next__)\n",
      "       50    0.000    0.000    0.010    0.000 dataloader.py:547(__init__)\n",
      "      100    0.271    0.003    5.629    0.056 dataloader.py:555(_next_data)\n",
      "        1    0.000    0.000    0.000    0.000 dataset.py:166(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 dataset.py:167(<genexpr>)\n",
      "   434550    0.509    0.000    3.307    0.000 dataset.py:170(__getitem__)\n",
      "  1303650    2.799    0.000    2.799    0.000 dataset.py:171(<genexpr>)\n",
      "      102    0.000    0.000    0.000    0.000 dataset.py:173(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 dropout.py:12(__init__)\n",
      "     1596    0.002    0.000    0.025    0.000 dropout.py:57(forward)\n",
      "       26    0.000    0.000    0.000    0.000 dtypes.py:1132(is_dtype)\n",
      "       26    0.000    0.000    0.000    0.000 dtypes.py:923(is_dtype)\n",
      "       50    0.000    0.000    0.000    0.000 fetch.py:39(__init__)\n",
      "       50    0.018    0.000    4.966    0.099 fetch.py:42(fetch)\n",
      "       50    0.185    0.004    3.493    0.070 fetch.py:44(<listcomp>)\n",
      "       50    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 flags.py:47(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 flags.py:51(allows_duplicate_labels)\n",
      "        1    0.000    0.000    0.000    0.000 flags.py:83(allows_duplicate_labels)\n",
      "        1    0.000    0.000    0.002    0.002 frame.py:502(__init__)\n",
      "      302    0.000    0.000    0.000    0.000 fromnumeric.py:2876(_prod_dispatcher)\n",
      "      302    0.001    0.000    0.009    0.000 fromnumeric.py:2881(prod)\n",
      "      302    0.002    0.000    0.008    0.000 fromnumeric.py:70(_wrapreduction)\n",
      "      302    0.000    0.000    0.000    0.000 fromnumeric.py:71(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 function.py:45(__call__)\n",
      "     1596    0.007    0.000    0.023    0.000 functional.py:1059(dropout)\n",
      "      604    0.001    0.000    0.011    0.000 functional.py:1195(relu)\n",
      "      992    0.001    0.000    0.021    0.000 functional.py:1364(leaky_relu)\n",
      "      100    0.000    0.000    0.002    0.000 functional.py:1553(softmax)\n",
      "       18    0.000    0.000    0.001    0.000 functional.py:1651(log_softmax)\n",
      "     2058    0.003    0.000    0.101    0.000 functional.py:1737(linear)\n",
      "       36    0.000    0.000    0.000    0.000 functional.py:2100(_verify_batch_size)\n",
      "      604    0.002    0.000    0.033    0.000 functional.py:2117(batch_norm)\n",
      "       18    0.000    0.000    0.001    0.000 functional.py:2315(nll_loss)\n",
      "       18    0.000    0.000    0.001    0.000 functional.py:2630(cross_entropy)\n",
      "       93    0.000    0.000    0.008    0.000 functional.py:2696(binary_cross_entropy)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:10560(_logical_func)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:10588(any)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:10853(any)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:187(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:226(attrs)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:247(flags)\n",
      "      515    0.000    0.000    0.000    0.000 generic.py:30(_check)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:339(_validate_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:423(_construct_axes_from_arguments)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:452(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:455(_get_axis_number)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:4561(reindex)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:469(_get_axis)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:4794(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5408(__finalize__)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:5446(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:5464(__setattr__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5519(_protect_consolidate)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5531(_consolidate_inplace)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5535(f)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:7411(isna)\n",
      "      194    0.001    0.000    0.001    0.000 grad_mode.py:114(__init__)\n",
      "      194    0.000    0.000    0.001    0.000 grad_mode.py:119(__enter__)\n",
      "      194    0.001    0.000    0.001    0.000 grad_mode.py:123(__exit__)\n",
      "      388    0.001    0.000    0.001    0.000 grad_mode.py:200(__init__)\n",
      "       50    0.000    0.000    0.053    0.001 grad_mode.py:24(decorate_context)\n",
      "       76    0.000    0.000    0.000    0.000 hooks.py:55(warn_if_has_hooks)\n",
      "        3    0.000    0.000    0.000    0.000 inference.py:263(is_dict_like)\n",
      "        9    0.000    0.000    0.000    0.000 inference.py:289(<genexpr>)\n",
      "       17    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\n",
      "        2    0.000    0.000    0.000    0.000 inference.py:96(is_file_like)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:112(uniform_)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:12(_no_grad_uniform_)\n",
      "        4    0.000    0.000    0.000    0.000 init.py:179(ones_)\n",
      "        4    0.000    0.000    0.000    0.000 init.py:192(zeros_)\n",
      "       10    0.000    0.000    0.000    0.000 init.py:268(_calculate_fan_in_and_fan_out)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:337(_calculate_correct_fan)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:347(kaiming_uniform_)\n",
      "        4    0.000    0.000    0.000    0.000 init.py:57(_no_grad_fill_)\n",
      "        4    0.000    0.000    0.000    0.000 init.py:62(_no_grad_zero_)\n",
      "        5    0.000    0.000    0.000    0.000 init.py:67(calculate_gain)\n",
      "      243    0.001    0.000    0.006    0.000 iostream.py:197(schedule)\n",
      "      212    0.000    0.000    0.000    0.000 iostream.py:310(_is_master_process)\n",
      "      212    0.000    0.000    0.001    0.000 iostream.py:323(_schedule_flush)\n",
      "      212    0.001    0.000    0.007    0.000 iostream.py:386(write)\n",
      "      243    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        5    0.000    0.000    0.001    0.000 linear.py:75(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 linear.py:86(reset_parameters)\n",
      "     2058    0.006    0.000    0.110    0.000 linear.py:93(forward)\n",
      "       18    0.000    0.000    0.001    0.000 loss.py:1045(forward)\n",
      "       93    0.000    0.000    0.008    0.000 loss.py:611(forward)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:126(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:132(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1545(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1577(from_array)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:1588(_block)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:1626(internal_values)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1634(is_consolidated)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1    0.000    0.000    0.001    0.001 managers.py:1690(create_block_manager_from_arrays)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1695(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1699(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 managers.py:1733(_form_blocks)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1829(_simple_blockify)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1844(_multi_blockify)\n",
      "        8    0.000    0.000    0.000    0.000 managers.py:1847(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1860(_stack_arrays)\n",
      "        9    0.000    0.000    0.000    0.000 managers.py:1863(_asarray_compat)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1869(_shape_compat)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:206(shape)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:208(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:210(ndim)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:253(items)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:318(_verify_integrity)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:320(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:681(is_consolidated)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:689(_consolidate_check)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:690(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:975(consolidate)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:991(_consolidate_inplace)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:133(_isna)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:202(_isna_ndarraylike)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:244(_isna_string_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:367(array_equivalent)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:465(_array_equivalent_object)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:50(isna)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:64(clean_fill_method)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:721(clean_reindex_fill_method)\n",
      "       78    0.000    0.000    0.000    0.000 module.py:1019(_save_to_state_dict)\n",
      "     78/4    0.000    0.000    0.001    0.000 module.py:1053(state_dict)\n",
      "       28    0.000    0.000    0.000    0.000 module.py:1227(_named_members)\n",
      "       28    0.000    0.000    0.000    0.000 module.py:1240(parameters)\n",
      "       28    0.000    0.000    0.000    0.000 module.py:1264(named_parameters)\n",
      "       39    0.000    0.000    0.000    0.000 module.py:1285(<lambda>)\n",
      "    16514    0.009    0.000    0.025    0.000 module.py:1338(children)\n",
      "    16514    0.013    0.000    0.015    0.000 module.py:1347(named_children)\n",
      "   175/41    0.000    0.000    0.000    0.000 module.py:1394(named_modules)\n",
      " 8420/402    0.016    0.000    0.067    0.000 module.py:1432(train)\n",
      "      201    0.000    0.000    0.036    0.000 module.py:1452(eval)\n",
      "       23    0.000    0.000    0.001    0.000 module.py:250(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 module.py:270(register_buffer)\n",
      "       18    0.000    0.000    0.000    0.000 module.py:322(register_parameter)\n",
      "       21    0.000    0.000    0.000    0.000 module.py:361(add_module)\n",
      "     39/2    0.000    0.000    0.002    0.001 module.py:385(_apply)\n",
      "       26    0.000    0.000    0.000    0.000 module.py:389(compute_should_use_set_data)\n",
      "        2    0.000    0.000    0.002    0.001 module.py:573(to)\n",
      "       38    0.000    0.000    0.002    0.000 module.py:667(convert)\n",
      " 8778/673    0.050    0.000    0.321    0.000 module.py:866(_call_impl)\n",
      "    10363    0.008    0.000    0.008    0.000 module.py:934(__getattr__)\n",
      "     8770    0.021    0.000    0.028    0.000 module.py:950(__setattr__)\n",
      "       19    0.000    0.000    0.000    0.000 module.py:951(remove_from)\n",
      "        9    0.000    0.000    0.000    0.000 multiarray.py:143(concatenate)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:172(_get_fill_value)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:197(_maybe_get_mask)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:241(_get_values)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:328(_na_ok_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:440(nanany)\n",
      "        3    0.000    0.000    0.000    0.000 ntpath.py:289(expanduser)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:78(_validate_dtype)\n",
      "       16    0.000    0.000    0.000    0.000 numerictypes.py:286(issubclass_)\n",
      "        8    0.000    0.000    0.000    0.000 numerictypes.py:360(issubdtype)\n",
      "       50    0.002    0.000    0.011    0.000 optimizer.py:189(zero_grad)\n",
      "        2    0.000    0.000    0.000    0.000 optimizer.py:232(add_param_group)\n",
      "        2    0.000    0.000    0.000    0.000 optimizer.py:34(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 optimizer.py:79(_hook_for_profile)\n",
      "       50    0.001    0.000    0.056    0.001 optimizer.py:84(wrapper)\n",
      "       18    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 parse.py:110(_coerce_args)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:366(urlparse)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:417(urlsplit)\n",
      "        2    0.000    0.000    0.000    0.000 parse.py:99(_noop)\n",
      "        1    0.000    0.000    0.001    0.001 parsers.py:1039(_make_engine)\n",
      "        1    0.000    0.000    0.003    0.003 parsers.py:1055(read)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1086(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1089(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 parsers.py:1093(_is_index_col)\n",
      "        3    0.000    0.000    0.000    0.000 parsers.py:1097(_is_potential_multi_index)\n",
      "        6    0.000    0.000    0.000    0.000 parsers.py:1121(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1199(_validate_usecols_arg)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1249(_validate_parse_dates_arg)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1272(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1358(_open_handles)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1371(_validate_parse_dates_presence)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1407(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1419(close)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1423(_has_complex_date_col)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1509(_maybe_dedup_names)\n",
      "        2    0.000    0.000    0.000    0.000 parsers.py:1539(_maybe_make_multi_index_columns)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1545(_make_index)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1835(_do_date_conversions)\n",
      "        1    0.000    0.000    0.001    0.001 parsers.py:1853(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1987(close)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1996(_set_noconvert_columns)\n",
      "        1    0.000    0.000    0.001    0.001 parsers.py:2059(read)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:2134(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:2136(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3299(_make_date_converter)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3344(_process_date_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3432(_clean_na_values)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3786(_refine_defaults_read)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3875(_extract_dialect)\n",
      "        2    0.000    0.000    0.000    0.000 parsers.py:394(validate_integer)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3971(_validate_skipfooter)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:423(_validate_names)\n",
      "        1    0.000    0.000    0.004    0.004 parsers.py:447(_read)\n",
      "        1    0.000    0.000    0.004    0.004 parsers.py:533(read_csv)\n",
      "        1    0.000    0.000    0.001    0.001 parsers.py:780(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:821(close)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:824(_get_options_with_defaults)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:865(_check_file_or_buffer)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:876(_clean_options)\n",
      "       50    0.000    0.000    0.000    0.000 prettytable.py:1024(add_row)\n",
      "      450    0.000    0.000    0.000    0.000 prettytable.py:1133(_format_value)\n",
      "        1    0.001    0.001    0.003    0.003 prettytable.py:1150(_compute_widths)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:1152(<listcomp>)\n",
      "       52    0.000    0.000    0.000    0.000 prettytable.py:1198(_get_padding_widths)\n",
      "        1    0.000    0.000    0.001    0.001 prettytable.py:1210(_get_rows)\n",
      "       50    0.000    0.000    0.000    0.000 prettytable.py:1239(_format_row)\n",
      "       50    0.000    0.000    0.000    0.000 prettytable.py:1240(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:1245(_format_rows)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:1246(<listcomp>)\n",
      "        1    0.000    0.000    0.016    0.016 prettytable.py:1252(get_string)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:1329(_stringify_hrule)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:1377(_stringify_header)\n",
      "       50    0.003    0.000    0.012    0.000 prettytable.py:1428(_stringify_row)\n",
      "     2061    0.001    0.000    0.007    0.000 prettytable.py:1768(_str_block_width)\n",
      "      459    0.001    0.000    0.003    0.000 prettytable.py:202(_justify)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:223(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:269(_validate_option)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:315(_validate_field_names)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:347(_validate_align)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:353(_validate_valign)\n",
      "      450    0.000    0.000    0.000    0.000 prettytable.py:448(field_names)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:457(field_names)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:459(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:490(align)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:510(valign)\n",
      "      450    0.000    0.000    0.000    0.000 prettytable.py:522(max_width)\n",
      "      450    0.000    0.000    0.000    0.000 prettytable.py:539(min_width)\n",
      "      909    0.001    0.000    0.005    0.000 prettytable.py:64(_get_size)\n",
      "     1818    0.000    0.000    0.003    0.000 prettytable.py:67(<genexpr>)\n",
      "      500    0.000    0.000    0.000    0.000 prettytable.py:816(vertical_char)\n",
      "        1    0.000    0.000    0.000    0.000 prettytable.py:919(_get_options)\n",
      "      200    0.001    0.000    0.003    0.000 profiler.py:607(__init__)\n",
      "      200    0.001    0.000    0.004    0.000 profiler.py:615(__enter__)\n",
      "      200    0.001    0.000    0.003    0.000 profiler.py:619(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:133(_simple_new)\n",
      "       10    0.000    0.000    0.000    0.000 range.py:747(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:85(__new__)\n",
      "       52    0.000    0.000    0.000    0.000 sampler.py:106(num_samples)\n",
      "   434600    0.049    0.000    0.069    0.000 sampler.py:113(__iter__)\n",
      "       50    0.000    0.000    0.001    0.000 sampler.py:127(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:210(__init__)\n",
      "      100    0.246    0.002    0.392    0.004 sampler.py:225(__iter__)\n",
      "       50    0.000    0.000    0.001    0.000 sampler.py:235(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:87(__init__)\n",
      "       76    0.000    0.000    0.000    0.000 serialization.py:116(_cpu_tag)\n",
      "       76    0.000    0.000    0.000    0.000 serialization.py:121(_cuda_tag)\n",
      "       76    0.000    0.000    0.000    0.000 serialization.py:164(location_tag)\n",
      "       76    0.000    0.000    0.000    0.000 serialization.py:183(normalize_storage_type)\n",
      "        8    0.000    0.000    0.000    0.000 serialization.py:193(_is_path)\n",
      "        8    0.000    0.000    0.000    0.000 serialization.py:199(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 serialization.py:202(__enter__)\n",
      "        4    0.000    0.000    0.001    0.000 serialization.py:210(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:213(__exit__)\n",
      "        4    0.000    0.000    0.001    0.000 serialization.py:228(_open_file_like)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:254(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:258(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:263(_open_zipfile_writer)\n",
      "        4    0.000    0.000    0.000    0.000 serialization.py:314(_check_dill_version)\n",
      "        4    0.000    0.000    0.011    0.003 serialization.py:333(save)\n",
      "        4    0.001    0.000    0.010    0.002 serialization.py:450(_save)\n",
      "     1808    0.001    0.000    0.001    0.000 serialization.py:453(persistent_id)\n",
      "      3/2    0.000    0.000    0.001    0.000 series.py:236(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:370(_init_dict)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:4146(_reduce)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:420(_constructor)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:4334(reindex)\n",
      "        3    0.000    0.000    0.000    0.000 series.py:437(_set_axis)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:4775(isna)\n",
      "        5    0.000    0.000    0.000    0.000 series.py:486(name)\n",
      "        4    0.000    0.000    0.000    0.000 series.py:536(name)\n",
      "        5    0.000    0.000    0.000    0.000 series.py:583(_values)\n",
      "      243    0.004    0.000    0.004    0.000 socket.py:432(send)\n",
      "       76    0.000    0.000    0.000    0.000 storage.py:13(__init__)\n",
      "       76    0.000    0.000    0.005    0.000 storage.py:70(cpu)\n",
      "       76    0.000    0.000    0.001    0.000 tensor.py:103(_reduce_ex_internal)\n",
      "       50    0.000    0.000    0.086    0.002 tensor.py:195(backward)\n",
      "       50    0.000    0.000    0.001    0.000 tensor.py:525(__rsub__)\n",
      "      510    0.001    0.000    0.047    0.000 tensor.py:540(__format__)\n",
      "      100    0.000    0.000    0.001    0.000 tensor.py:568(__len__)\n",
      "      610    0.000    0.000    0.000    0.000 tensor.py:593(__hash__)\n",
      "     3308    0.004    0.000    0.004    0.000 tensor.py:906(grad)\n",
      "       76    0.000    0.000    0.001    0.000 tensor.py:93(__reduce_ex__)\n",
      "      243    0.000    0.000    0.000    0.000 threading.py:1017(_wait_for_tstate_lock)\n",
      "      243    0.000    0.000    0.001    0.000 threading.py:1071(is_alive)\n",
      "      243    0.000    0.000    0.000    0.000 threading.py:513(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1149(cast)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1822(new_type)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:768(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:771(__subclasscheck__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:868(__new__)\n",
      "     2061    0.005    0.000    0.005    0.000 wcwidth.py:222(wcswidth)\n",
      "      100    0.000    0.000    0.000    0.000 worker.py:83(get_worker_info)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x00007FF8B49EB810}\n",
      "      120    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       51    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "       52    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_encode}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _csv.writer}\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method _has_compatible_shallow_copy_type}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _locale._getdefaultlocale}\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
      "      604    0.030    0.000    0.030    0.000 {built-in method batch_norm}\n",
      "    66/65    0.047    0.001    0.205    0.003 {built-in method builtins.all}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "     2864    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
      "     3520    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "     1214    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "22260/22259    0.003    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "      327    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "     2159    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
      "909173/909004    0.077    0.000    0.078    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
      "     1359    0.001    0.000    0.004    0.000 {built-in method builtins.max}\n",
      "      151    0.000    0.000    0.392    0.003 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "      106    0.000    0.000    0.007    0.000 {built-in method builtins.print}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "      151    0.007    0.000    0.007    0.000 {built-in method cat}\n",
      "     1596    0.014    0.000    0.014    0.000 {built-in method dropout}\n",
      "      100    0.005    0.000    0.005    0.000 {built-in method empty}\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method eq}\n",
      "        7    0.002    0.000    0.002    0.000 {built-in method io.open}\n",
      "      505    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "      100    0.003    0.000    0.003    0.000 {built-in method max}\n",
      "      200    0.004    0.000    0.004    0.000 {built-in method mean}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method nt.fspath}\n",
      "      212    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "      303    0.003    0.000    0.003    0.000 {built-in method numpy.arange}\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "      311    0.001    0.000    0.010    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
      "      302    0.004    0.000    0.004    0.000 {built-in method numpy.zeros}\n",
      "      101    0.003    0.000    0.003    0.000 {built-in method ones_like}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method ones}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
      "      151    1.093    0.007    1.093    0.007 {built-in method randn}\n",
      "       50    0.007    0.000    0.007    0.000 {built-in method randperm}\n",
      "      604    0.010    0.000    0.010    0.000 {built-in method relu_}\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method round}\n",
      "       50    0.001    0.000    0.001    0.000 {built-in method rsub}\n",
      "      193    0.004    0.000    0.004    0.000 {built-in method sigmoid}\n",
      "      100    0.997    0.010    0.997    0.010 {built-in method stack}\n",
      "      100    0.002    0.000    0.002    0.000 {built-in method sum}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method tensor}\n",
      "       76    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}\n",
      "       76    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}\n",
      "      604    0.000    0.000    0.000    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "     8778    0.008    0.000    0.008    0.000 {built-in method torch._C._get_tracing_state}\n",
      "     8568    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "     2237    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._nn._parse_to}\n",
      "       93    0.007    0.000    0.007    0.000 {built-in method torch._C._nn.binary_cross_entropy}\n",
      "      992    0.020    0.000    0.020    0.000 {built-in method torch._C._nn.leaky_relu}\n",
      "     2058    0.098    0.000    0.098    0.000 {built-in method torch._C._nn.linear}\n",
      "       18    0.001    0.000    0.001    0.000 {built-in method torch._C._nn.nll_loss}\n",
      "      388    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "      582    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}\n",
      "      200    0.004    0.000    0.004    0.000 {built-in method torch._ops.profiler._record_function_enter}\n",
      "      200    0.002    0.000    0.002    0.000 {built-in method torch._ops.profiler._record_function_exit}\n",
      "       94    0.002    0.000    0.002    0.000 {built-in method zeros_like}\n",
      "      204    0.003    0.000    0.003    0.000 {built-in method zeros}\n",
      "      510    0.001    0.000    0.001    0.000 {method '__format__' of 'float' objects}\n",
      "      243    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "     8120    0.001    0.000    0.001    0.000 {method 'add' of 'set' objects}\n",
      "      960    0.009    0.000    0.009    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "      480    0.005    0.000    0.005    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
      "      480    0.005    0.000    0.005    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "      243    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "   439216    0.040    0.000    0.040    0.000 {method 'append' of 'list' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'clear' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       68    0.004    0.000    0.004    0.000 {method 'copy_' of 'torch._C.FloatStorageBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'copy_' of 'torch._C.LongStorageBase' objects}\n",
      "       68    0.000    0.000    0.000    0.000 {method 'data_ptr' of 'torch._C.FloatStorageBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'data_ptr' of 'torch._C.LongStorageBase' objects}\n",
      "      118    0.000    0.000    0.000    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
      "     1252    0.001    0.000    0.001    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        4    0.001    0.000    0.003    0.001 {method 'dump' of '_pickle.Pickler' objects}\n",
      "       68    0.000    0.000    0.000    0.000 {method 'element_size' of 'torch._C.FloatStorageBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'element_size' of 'torch._C.LongStorageBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
      "       50    0.013    0.000    0.013    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BufferedWriter' objects}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      161    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "    27338    0.005    0.000    0.005    0.000 {method 'get' of 'dict' objects}\n",
      "      136    0.000    0.000    0.000    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'get_device' of 'torch._C.CudaLongStorageBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "       76    0.000    0.000    0.000    0.000 {method 'has_names' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'is_complex' of 'torch._C._TensorBase' objects}\n",
      "       38    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "      660    0.085    0.000    0.085    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "     8849    0.001    0.000    0.001    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "      309    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      554    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
      "      302    0.004    0.000    0.004    0.000 {method 'long' of 'torch._C._TensorBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "      302    0.000    0.000    0.005    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "      960    0.010    0.000    0.010    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "       23    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "      302    0.034    0.000    0.044    0.000 {method 'randint' of 'numpy.random.mtrand.RandomState' objects}\n",
      "      100    0.005    0.000    0.005    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.001    0.001 {method 'read' of 'pandas._libs.parsers.TextReader' objects}\n",
      "      605    0.009    0.000    0.009    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "      454    0.000    0.000    0.000    0.000 {method 'requires_grad_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "       50    0.083    0.002    0.083    0.002 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "      136    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.CudaLongStorageBase' objects}\n",
      "       68    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.LongStorageBase' objects}\n",
      "      460    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "      100    0.002    0.000    0.002    0.000 {method 'softmax' of 'torch._C._TensorBase' objects}\n",
      "     1809    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "      480    0.005    0.000    0.005    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       76    0.000    0.000    0.000    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
      "       76    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
      "       76    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
      "     2061    0.001    0.000    0.001    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "      100    0.004    0.000    0.004    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "      843    0.226    0.000    0.226    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "       50    0.010    0.000    0.010    0.000 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "    37248    0.005    0.000    0.005    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'writerow' of '_csv.writer' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'writerows' of '_csv.writer' objects}\n",
      "      466    0.004    0.000    0.004    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "        2    0.000    0.000    0.000    0.000 {pandas._libs.lib.array_equivalent_object}\n",
      "        2    0.000    0.000    0.000    0.000 {pandas._libs.lib.clean_index_list}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
      "        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "        9    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "        5    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "       12    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "       15    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#X, y = start_data(\"aggregated_data/aggregated_data.csv\", \"label:SITTING\")\n",
    "#X, y = start_data(\"raw_data/0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv\", \"label:SITTING\" ) \n",
    "X, y = start_data(\"aggregated_data/aggregated_data.csv\", [\"label:SITTING\", \"label:FIX_walking\", \"label:SLEEPING\"], [\"0BFC35E2-4817-4865-BFA7-764742302A2D\", \"0A986513-7828-4D53-AA1F-E02D6DF9561B\", \"00EABED2-271D-49D8-B599-1D4A09240601\"])\n",
    "\n",
    "#Initialize Classifier Architectures\n",
    "activity_classifier = Activity_Classifier()\n",
    "user_classifier = User_Classifier()\n",
    "\n",
    "#Freeze Them\n",
    "activity_classifier.eval()\n",
    "user_classifier.eval()\n",
    "#Send to GPU\n",
    "activity_classifier.to(device)\n",
    "user_classifier.to(device)\n",
    "\n",
    "#Load with pre-trained parameters\n",
    "activity_classifier.load_state_dict(torch.load('saved_models/2000Epochs_0.01LR_UserClassifier'), strict = False)\n",
    "user_classifier.load_state_dict(torch.load(\"saved_models/5000Epochs_0.01LR_MutualExclusiveLabelClassifier\"), strict = False)\n",
    "\n",
    "#Train\n",
    "model_output = training_loop(X,y, activity_classifier, user_classifier, gan_id=\"cGAN_trained\", batch_size = len(X), gen_lr=.001, disc_lr =.001, n_epochs=50, dig=5, constant_train_flag=False)\n",
    "plot_metrics(model_output, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Median Wasserstein'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Median Wasserstein'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ac208c07852e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-477e4b535980>\u001b[0m in \u001b[0;36mplot_metrics\u001b[1;34m(data, vanilla)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Median Wasserstein'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_kws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'color'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'orange'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxlim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdespine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36mregplot\u001b[1;34m(x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, label, color, marker, scatter_kws, line_kws, ax)\u001b[0m\n\u001b[0;32m    824\u001b[0m ):\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m     plotter = _RegressionPlotter(x, y, data, x_estimator, x_bins, x_ci,\n\u001b[0m\u001b[0;32m    827\u001b[0m                                  \u001b[0mscatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m                                  \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrobust\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, color, label)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# Extract the data vals from the arguments or passed dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         self.establish_variables(data, x=x, y=y, units=units,\n\u001b[0m\u001b[0;32m    110\u001b[0m                                  x_partial=x_partial, y_partial=y_partial)\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[1;34m(self, data, **kws)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Median Wasserstein'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(model_output, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
