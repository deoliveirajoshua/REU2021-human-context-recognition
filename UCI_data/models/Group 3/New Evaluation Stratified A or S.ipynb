{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 9)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [14, 15, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.078963279724121, Final Batch Loss: 2.034856081008911\n",
      "Epoch 2, Loss: 4.058208465576172, Final Batch Loss: 2.025503396987915\n",
      "Epoch 3, Loss: 4.041425466537476, Final Batch Loss: 2.0212910175323486\n",
      "Epoch 4, Loss: 4.024147272109985, Final Batch Loss: 2.012317180633545\n",
      "Epoch 5, Loss: 4.001115322113037, Final Batch Loss: 1.9981250762939453\n",
      "Epoch 6, Loss: 3.9739232063293457, Final Batch Loss: 1.9851902723312378\n",
      "Epoch 7, Loss: 3.959748864173889, Final Batch Loss: 1.9802050590515137\n",
      "Epoch 8, Loss: 3.929610252380371, Final Batch Loss: 1.957871675491333\n",
      "Epoch 9, Loss: 3.9117616415023804, Final Batch Loss: 1.9478113651275635\n",
      "Epoch 10, Loss: 3.883876323699951, Final Batch Loss: 1.9407999515533447\n",
      "Epoch 11, Loss: 3.8524307012557983, Final Batch Loss: 1.9215139150619507\n",
      "Epoch 12, Loss: 3.8124618530273438, Final Batch Loss: 1.9053488969802856\n",
      "Epoch 13, Loss: 3.77833092212677, Final Batch Loss: 1.8823391199111938\n",
      "Epoch 14, Loss: 3.729729175567627, Final Batch Loss: 1.8594715595245361\n",
      "Epoch 15, Loss: 3.6940749883651733, Final Batch Loss: 1.8394609689712524\n",
      "Epoch 16, Loss: 3.6465166807174683, Final Batch Loss: 1.8195652961730957\n",
      "Epoch 17, Loss: 3.6008639335632324, Final Batch Loss: 1.796264886856079\n",
      "Epoch 18, Loss: 3.5436272621154785, Final Batch Loss: 1.762316346168518\n",
      "Epoch 19, Loss: 3.4655089378356934, Final Batch Loss: 1.7140562534332275\n",
      "Epoch 20, Loss: 3.395851969718933, Final Batch Loss: 1.692665457725525\n",
      "Epoch 21, Loss: 3.3042666912078857, Final Batch Loss: 1.6459119319915771\n",
      "Epoch 22, Loss: 3.199055790901184, Final Batch Loss: 1.5844272375106812\n",
      "Epoch 23, Loss: 3.1097795963287354, Final Batch Loss: 1.5339744091033936\n",
      "Epoch 24, Loss: 2.9899455308914185, Final Batch Loss: 1.4716404676437378\n",
      "Epoch 25, Loss: 2.9036033153533936, Final Batch Loss: 1.4545636177062988\n",
      "Epoch 26, Loss: 2.7673683166503906, Final Batch Loss: 1.35185968875885\n",
      "Epoch 27, Loss: 2.6550631523132324, Final Batch Loss: 1.3162907361984253\n",
      "Epoch 28, Loss: 2.50831139087677, Final Batch Loss: 1.2485913038253784\n",
      "Epoch 29, Loss: 2.4913012981414795, Final Batch Loss: 1.2335180044174194\n",
      "Epoch 30, Loss: 2.3470170497894287, Final Batch Loss: 1.1586028337478638\n",
      "Epoch 31, Loss: 2.242305874824524, Final Batch Loss: 1.1047163009643555\n",
      "Epoch 32, Loss: 2.19625723361969, Final Batch Loss: 1.0695515871047974\n",
      "Epoch 33, Loss: 2.120719313621521, Final Batch Loss: 1.0583101511001587\n",
      "Epoch 34, Loss: 2.0100096464157104, Final Batch Loss: 0.9602780342102051\n",
      "Epoch 35, Loss: 1.8846394419670105, Final Batch Loss: 0.9388590455055237\n",
      "Epoch 36, Loss: 1.8229627013206482, Final Batch Loss: 0.8738654255867004\n",
      "Epoch 37, Loss: 1.7634621858596802, Final Batch Loss: 0.9148560166358948\n",
      "Epoch 38, Loss: 1.64584082365036, Final Batch Loss: 0.8006101250648499\n",
      "Epoch 39, Loss: 1.5677143335342407, Final Batch Loss: 0.7948344945907593\n",
      "Epoch 40, Loss: 1.4420658946037292, Final Batch Loss: 0.6670486927032471\n",
      "Epoch 41, Loss: 1.4715956449508667, Final Batch Loss: 0.7034399509429932\n",
      "Epoch 42, Loss: 1.4072784781455994, Final Batch Loss: 0.6535612940788269\n",
      "Epoch 43, Loss: 1.3042263984680176, Final Batch Loss: 0.638793408870697\n",
      "Epoch 44, Loss: 1.2152916193008423, Final Batch Loss: 0.6103431582450867\n",
      "Epoch 45, Loss: 1.2265847325325012, Final Batch Loss: 0.587043821811676\n",
      "Epoch 46, Loss: 1.1385286450386047, Final Batch Loss: 0.5546754598617554\n",
      "Epoch 47, Loss: 1.1071963906288147, Final Batch Loss: 0.5550719499588013\n",
      "Epoch 48, Loss: 1.010673314332962, Final Batch Loss: 0.4854629337787628\n",
      "Epoch 49, Loss: 1.0349618196487427, Final Batch Loss: 0.5100588202476501\n",
      "Epoch 50, Loss: 1.0044252276420593, Final Batch Loss: 0.48901623487472534\n",
      "Epoch 51, Loss: 0.9773194789886475, Final Batch Loss: 0.5273292064666748\n",
      "Epoch 52, Loss: 0.918407529592514, Final Batch Loss: 0.47581276297569275\n",
      "Epoch 53, Loss: 0.8893172442913055, Final Batch Loss: 0.44087111949920654\n",
      "Epoch 54, Loss: 0.8072661459445953, Final Batch Loss: 0.40402740240097046\n",
      "Epoch 55, Loss: 0.7983204126358032, Final Batch Loss: 0.4007701575756073\n",
      "Epoch 56, Loss: 0.8598325848579407, Final Batch Loss: 0.42590394616127014\n",
      "Epoch 57, Loss: 0.7409128546714783, Final Batch Loss: 0.3836911618709564\n",
      "Epoch 58, Loss: 0.704086184501648, Final Batch Loss: 0.36928513646125793\n",
      "Epoch 59, Loss: 0.7926692366600037, Final Batch Loss: 0.42530542612075806\n",
      "Epoch 60, Loss: 0.6957349479198456, Final Batch Loss: 0.35669219493865967\n",
      "Epoch 61, Loss: 0.5798365473747253, Final Batch Loss: 0.25318408012390137\n",
      "Epoch 62, Loss: 0.5881883800029755, Final Batch Loss: 0.2970149517059326\n",
      "Epoch 63, Loss: 0.5787946879863739, Final Batch Loss: 0.3078332543373108\n",
      "Epoch 64, Loss: 0.5696934759616852, Final Batch Loss: 0.28406956791877747\n",
      "Epoch 65, Loss: 0.5570724010467529, Final Batch Loss: 0.27641454339027405\n",
      "Epoch 66, Loss: 0.48105689883232117, Final Batch Loss: 0.23611901700496674\n",
      "Epoch 67, Loss: 0.5139737725257874, Final Batch Loss: 0.27232086658477783\n",
      "Epoch 68, Loss: 0.4516621083021164, Final Batch Loss: 0.24484717845916748\n",
      "Epoch 69, Loss: 0.5046572536230087, Final Batch Loss: 0.2606416344642639\n",
      "Epoch 70, Loss: 0.4365270584821701, Final Batch Loss: 0.20907041430473328\n",
      "Epoch 71, Loss: 0.41676439344882965, Final Batch Loss: 0.19516761600971222\n",
      "Epoch 72, Loss: 0.478203609585762, Final Batch Loss: 0.22793029248714447\n",
      "Epoch 73, Loss: 0.38718415796756744, Final Batch Loss: 0.19567427039146423\n",
      "Epoch 74, Loss: 0.39781366288661957, Final Batch Loss: 0.1970258355140686\n",
      "Epoch 75, Loss: 0.37711410224437714, Final Batch Loss: 0.1892000138759613\n",
      "Epoch 76, Loss: 0.3771809935569763, Final Batch Loss: 0.18697886168956757\n",
      "Epoch 77, Loss: 0.3683602213859558, Final Batch Loss: 0.18547159433364868\n",
      "Epoch 78, Loss: 0.30474674701690674, Final Batch Loss: 0.1391734629869461\n",
      "Epoch 79, Loss: 0.3243735358119011, Final Batch Loss: 0.10858578234910965\n",
      "Epoch 80, Loss: 0.2849000543355942, Final Batch Loss: 0.12765945494174957\n",
      "Epoch 81, Loss: 0.27736279368400574, Final Batch Loss: 0.13446538150310516\n",
      "Epoch 82, Loss: 0.3649187982082367, Final Batch Loss: 0.17555363476276398\n",
      "Epoch 83, Loss: 0.34008292853832245, Final Batch Loss: 0.19181795418262482\n",
      "Epoch 84, Loss: 0.33408597111701965, Final Batch Loss: 0.16797183454036713\n",
      "Epoch 85, Loss: 0.3417442589998245, Final Batch Loss: 0.18051305413246155\n",
      "Epoch 86, Loss: 0.24156355112791061, Final Batch Loss: 0.08991891890764236\n",
      "Epoch 87, Loss: 0.20971733331680298, Final Batch Loss: 0.11282435059547424\n",
      "Epoch 88, Loss: 0.2388295903801918, Final Batch Loss: 0.11021057516336441\n",
      "Epoch 89, Loss: 0.3158929795026779, Final Batch Loss: 0.1997290700674057\n",
      "Epoch 90, Loss: 0.2720758020877838, Final Batch Loss: 0.14467740058898926\n",
      "Epoch 91, Loss: 0.29176168143749237, Final Batch Loss: 0.1549730747938156\n",
      "Epoch 92, Loss: 0.34534572064876556, Final Batch Loss: 0.2168518304824829\n",
      "Epoch 93, Loss: 0.19715584814548492, Final Batch Loss: 0.11496952176094055\n",
      "Epoch 94, Loss: 0.23600470274686813, Final Batch Loss: 0.100376196205616\n",
      "Epoch 95, Loss: 0.23694781213998795, Final Batch Loss: 0.09580007940530777\n",
      "Epoch 96, Loss: 0.2793213278055191, Final Batch Loss: 0.13412579894065857\n",
      "Epoch 97, Loss: 0.27406178414821625, Final Batch Loss: 0.1032884269952774\n",
      "Epoch 98, Loss: 0.18791460618376732, Final Batch Loss: 0.0543358139693737\n",
      "Epoch 99, Loss: 0.22226183861494064, Final Batch Loss: 0.12269614636898041\n",
      "Epoch 100, Loss: 0.222322978079319, Final Batch Loss: 0.10331124067306519\n",
      "Epoch 101, Loss: 0.2185284122824669, Final Batch Loss: 0.10204986482858658\n",
      "Epoch 102, Loss: 0.18534297496080399, Final Batch Loss: 0.0843467190861702\n",
      "Epoch 103, Loss: 0.2236214056611061, Final Batch Loss: 0.10700144618749619\n",
      "Epoch 104, Loss: 0.258639819920063, Final Batch Loss: 0.15849469602108002\n",
      "Epoch 105, Loss: 0.16847484558820724, Final Batch Loss: 0.06922905892133713\n",
      "Epoch 106, Loss: 0.16557344794273376, Final Batch Loss: 0.09262910485267639\n",
      "Epoch 107, Loss: 0.2044578567147255, Final Batch Loss: 0.08745705336332321\n",
      "Epoch 108, Loss: 0.23693454265594482, Final Batch Loss: 0.14972653985023499\n",
      "Epoch 109, Loss: 0.16393664479255676, Final Batch Loss: 0.07371404021978378\n",
      "Epoch 110, Loss: 0.2095126435160637, Final Batch Loss: 0.07623385637998581\n",
      "Epoch 111, Loss: 0.18134494870901108, Final Batch Loss: 0.09993636608123779\n",
      "Epoch 112, Loss: 0.18115205317735672, Final Batch Loss: 0.05014873296022415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113, Loss: 0.18484464287757874, Final Batch Loss: 0.09799067676067352\n",
      "Epoch 114, Loss: 0.19096579402685165, Final Batch Loss: 0.11104916036128998\n",
      "Epoch 115, Loss: 0.16206420958042145, Final Batch Loss: 0.0718717947602272\n",
      "Epoch 116, Loss: 0.12363890931010246, Final Batch Loss: 0.06573349237442017\n",
      "Epoch 117, Loss: 0.1216634102165699, Final Batch Loss: 0.047695714980363846\n",
      "Epoch 118, Loss: 0.15961245447397232, Final Batch Loss: 0.10527409613132477\n",
      "Epoch 119, Loss: 0.12272849306464195, Final Batch Loss: 0.07771702110767365\n",
      "Epoch 120, Loss: 0.1786285862326622, Final Batch Loss: 0.09474918246269226\n",
      "Epoch 121, Loss: 0.13250815868377686, Final Batch Loss: 0.06909279525279999\n",
      "Epoch 122, Loss: 0.11212491244077682, Final Batch Loss: 0.06555783748626709\n",
      "Epoch 123, Loss: 0.17154225707054138, Final Batch Loss: 0.07543251663446426\n",
      "Epoch 124, Loss: 0.11735688149929047, Final Batch Loss: 0.038710758090019226\n",
      "Epoch 125, Loss: 0.13672852143645287, Final Batch Loss: 0.07814313471317291\n",
      "Epoch 126, Loss: 0.11648387089371681, Final Batch Loss: 0.034259337931871414\n",
      "Epoch 127, Loss: 0.10306401178240776, Final Batch Loss: 0.04643649607896805\n",
      "Epoch 128, Loss: 0.12220460921525955, Final Batch Loss: 0.06662212312221527\n",
      "Epoch 129, Loss: 0.1683945320546627, Final Batch Loss: 0.11022943258285522\n",
      "Epoch 130, Loss: 0.12884777411818504, Final Batch Loss: 0.08817844092845917\n",
      "Epoch 131, Loss: 0.11846942082047462, Final Batch Loss: 0.07245580852031708\n",
      "Epoch 132, Loss: 0.0780169777572155, Final Batch Loss: 0.036945853382349014\n",
      "Epoch 133, Loss: 0.09166599810123444, Final Batch Loss: 0.038177818059921265\n",
      "Epoch 134, Loss: 0.2068527527153492, Final Batch Loss: 0.15359728038311005\n",
      "Epoch 135, Loss: 0.13548782095313072, Final Batch Loss: 0.03776641562581062\n",
      "Epoch 136, Loss: 0.1823761984705925, Final Batch Loss: 0.1000417172908783\n",
      "Epoch 137, Loss: 0.1714640036225319, Final Batch Loss: 0.0882909968495369\n",
      "Epoch 138, Loss: 0.12287315726280212, Final Batch Loss: 0.06254876405000687\n",
      "Epoch 139, Loss: 0.1443890854716301, Final Batch Loss: 0.05906600505113602\n",
      "Epoch 140, Loss: 0.11487101390957832, Final Batch Loss: 0.03548014536499977\n",
      "Epoch 141, Loss: 0.08306445367634296, Final Batch Loss: 0.052864864468574524\n",
      "Epoch 142, Loss: 0.10377030447125435, Final Batch Loss: 0.064470075070858\n",
      "Epoch 143, Loss: 0.10917532444000244, Final Batch Loss: 0.03519930690526962\n",
      "Epoch 144, Loss: 0.12163595110177994, Final Batch Loss: 0.06051872298121452\n",
      "Epoch 145, Loss: 0.10380641371011734, Final Batch Loss: 0.03130948543548584\n",
      "Epoch 146, Loss: 0.09594735875725746, Final Batch Loss: 0.044380586594343185\n",
      "Epoch 147, Loss: 0.10269900411367416, Final Batch Loss: 0.0700094997882843\n",
      "Epoch 148, Loss: 0.09323320537805557, Final Batch Loss: 0.045019425451755524\n",
      "Epoch 149, Loss: 0.10485835000872612, Final Batch Loss: 0.04988609254360199\n",
      "Epoch 150, Loss: 0.12715685740113258, Final Batch Loss: 0.07595399767160416\n",
      "Epoch 151, Loss: 0.11703735962510109, Final Batch Loss: 0.07070892304182053\n",
      "Epoch 152, Loss: 0.07635849714279175, Final Batch Loss: 0.03508913516998291\n",
      "Epoch 153, Loss: 0.07754471525549889, Final Batch Loss: 0.017512015998363495\n",
      "Epoch 154, Loss: 0.1363285928964615, Final Batch Loss: 0.0735948234796524\n",
      "Epoch 155, Loss: 0.09216584078967571, Final Batch Loss: 0.06354580074548721\n",
      "Epoch 156, Loss: 0.060863886028528214, Final Batch Loss: 0.025334622710943222\n",
      "Epoch 157, Loss: 0.08085797354578972, Final Batch Loss: 0.0469515435397625\n",
      "Epoch 158, Loss: 0.10540533438324928, Final Batch Loss: 0.04020367190241814\n",
      "Epoch 159, Loss: 0.08551751635968685, Final Batch Loss: 0.06405545771121979\n",
      "Epoch 160, Loss: 0.0867309421300888, Final Batch Loss: 0.052342794835567474\n",
      "Epoch 161, Loss: 0.07959843054413795, Final Batch Loss: 0.035721614956855774\n",
      "Epoch 162, Loss: 0.045165011659264565, Final Batch Loss: 0.026023030281066895\n",
      "Epoch 163, Loss: 0.14069603756070137, Final Batch Loss: 0.09471585601568222\n",
      "Epoch 164, Loss: 0.08048811554908752, Final Batch Loss: 0.04166139289736748\n",
      "Epoch 165, Loss: 0.07209219969809055, Final Batch Loss: 0.048675764352083206\n",
      "Epoch 166, Loss: 0.1121881790459156, Final Batch Loss: 0.07222889363765717\n",
      "Epoch 167, Loss: 0.07081018574535847, Final Batch Loss: 0.025631917640566826\n",
      "Epoch 168, Loss: 0.058876462280750275, Final Batch Loss: 0.031205326318740845\n",
      "Epoch 169, Loss: 0.07369714044034481, Final Batch Loss: 0.04438009858131409\n",
      "Epoch 170, Loss: 0.12814221903681755, Final Batch Loss: 0.08276974409818649\n",
      "Epoch 171, Loss: 0.13584104925394058, Final Batch Loss: 0.07218734920024872\n",
      "Epoch 172, Loss: 0.06325668841600418, Final Batch Loss: 0.026313483715057373\n",
      "Epoch 173, Loss: 0.10926040261983871, Final Batch Loss: 0.07783814519643784\n",
      "Epoch 174, Loss: 0.1019042432308197, Final Batch Loss: 0.06485366821289062\n",
      "Epoch 175, Loss: 0.06465697847306728, Final Batch Loss: 0.024779995903372765\n",
      "Epoch 176, Loss: 0.06516019627451897, Final Batch Loss: 0.03470863401889801\n",
      "Epoch 177, Loss: 0.07599327154457569, Final Batch Loss: 0.029569057747721672\n",
      "Epoch 178, Loss: 0.05949326045811176, Final Batch Loss: 0.03366796299815178\n",
      "Epoch 179, Loss: 0.08144241198897362, Final Batch Loss: 0.04755965247750282\n",
      "Epoch 180, Loss: 0.08716889098286629, Final Batch Loss: 0.042549245059490204\n",
      "Epoch 181, Loss: 0.07150921411812305, Final Batch Loss: 0.029539940878748894\n",
      "Epoch 182, Loss: 0.07816516980528831, Final Batch Loss: 0.04547082632780075\n",
      "Epoch 183, Loss: 0.05207890272140503, Final Batch Loss: 0.02361590974032879\n",
      "Epoch 184, Loss: 0.12488456070423126, Final Batch Loss: 0.0776657685637474\n",
      "Epoch 185, Loss: 0.09527917578816414, Final Batch Loss: 0.05581076815724373\n",
      "Epoch 186, Loss: 0.04074316658079624, Final Batch Loss: 0.02303113415837288\n",
      "Epoch 187, Loss: 0.03701423667371273, Final Batch Loss: 0.01590515859425068\n",
      "Epoch 188, Loss: 0.07655123248696327, Final Batch Loss: 0.04536328464746475\n",
      "Epoch 189, Loss: 0.07059888727962971, Final Batch Loss: 0.022935086861252785\n",
      "Epoch 190, Loss: 0.06138528697192669, Final Batch Loss: 0.023170849308371544\n",
      "Epoch 191, Loss: 0.0961877852678299, Final Batch Loss: 0.07747854292392731\n",
      "Epoch 192, Loss: 0.09495850652456284, Final Batch Loss: 0.04787714034318924\n",
      "Epoch 193, Loss: 0.05662448704242706, Final Batch Loss: 0.02411666139960289\n",
      "Epoch 194, Loss: 0.046070646494627, Final Batch Loss: 0.02063238061964512\n",
      "Epoch 195, Loss: 0.043786514550447464, Final Batch Loss: 0.021206699311733246\n",
      "Epoch 196, Loss: 0.04657019209116697, Final Batch Loss: 0.008929464034736156\n",
      "Epoch 197, Loss: 0.05213000811636448, Final Batch Loss: 0.02872943878173828\n",
      "Epoch 198, Loss: 0.05295100063085556, Final Batch Loss: 0.016639500856399536\n",
      "Epoch 199, Loss: 0.03518204763531685, Final Batch Loss: 0.019909512251615524\n",
      "Epoch 200, Loss: 0.0669139176607132, Final Batch Loss: 0.038570255041122437\n",
      "Epoch 201, Loss: 0.0619107773527503, Final Batch Loss: 0.01446648221462965\n",
      "Epoch 202, Loss: 0.03326359856873751, Final Batch Loss: 0.015291674993932247\n",
      "Epoch 203, Loss: 0.08855737745761871, Final Batch Loss: 0.04338077828288078\n",
      "Epoch 204, Loss: 0.05517791770398617, Final Batch Loss: 0.029332613572478294\n",
      "Epoch 205, Loss: 0.027360139414668083, Final Batch Loss: 0.007420672103762627\n",
      "Epoch 206, Loss: 0.04316072631627321, Final Batch Loss: 0.013630564324557781\n",
      "Epoch 207, Loss: 0.027854532934725285, Final Batch Loss: 0.005604804493486881\n",
      "Epoch 208, Loss: 0.044260671362280846, Final Batch Loss: 0.017260035499930382\n",
      "Epoch 209, Loss: 0.06904450803995132, Final Batch Loss: 0.031929027289152145\n",
      "Epoch 210, Loss: 0.06070537958294153, Final Batch Loss: 0.01135860476642847\n",
      "Epoch 211, Loss: 0.040438626892864704, Final Batch Loss: 0.013187617994844913\n",
      "Epoch 212, Loss: 0.02816598117351532, Final Batch Loss: 0.017546962946653366\n",
      "Epoch 213, Loss: 0.08208470046520233, Final Batch Loss: 0.029492110013961792\n",
      "Epoch 214, Loss: 0.02733450196683407, Final Batch Loss: 0.01362504344433546\n",
      "Epoch 215, Loss: 0.043974826112389565, Final Batch Loss: 0.01606261171400547\n",
      "Epoch 216, Loss: 0.05743728578090668, Final Batch Loss: 0.011922948062419891\n",
      "Epoch 217, Loss: 0.05896938405930996, Final Batch Loss: 0.03326335549354553\n",
      "Epoch 218, Loss: 0.11064115166664124, Final Batch Loss: 0.06037168577313423\n",
      "Epoch 219, Loss: 0.10167314857244492, Final Batch Loss: 0.06972595304250717\n",
      "Epoch 220, Loss: 0.046453630551695824, Final Batch Loss: 0.030502552166581154\n",
      "Epoch 221, Loss: 0.05723469331860542, Final Batch Loss: 0.02391943708062172\n",
      "Epoch 222, Loss: 0.08557452633976936, Final Batch Loss: 0.06745949387550354\n",
      "Epoch 223, Loss: 0.09468607604503632, Final Batch Loss: 0.052950382232666016\n",
      "Epoch 224, Loss: 0.05193965509533882, Final Batch Loss: 0.033592432737350464\n",
      "Epoch 225, Loss: 0.027547371573746204, Final Batch Loss: 0.006672157905995846\n",
      "Epoch 226, Loss: 0.04014637600630522, Final Batch Loss: 0.030185410752892494\n",
      "Epoch 227, Loss: 0.01706089125946164, Final Batch Loss: 0.005728787276893854\n",
      "Epoch 228, Loss: 0.050045641139149666, Final Batch Loss: 0.026608649641275406\n",
      "Epoch 229, Loss: 0.03706956095993519, Final Batch Loss: 0.01994743011891842\n",
      "Epoch 230, Loss: 0.043745413422584534, Final Batch Loss: 0.031239360570907593\n",
      "Epoch 231, Loss: 0.061594804748892784, Final Batch Loss: 0.04084261134266853\n",
      "Epoch 232, Loss: 0.05375754274427891, Final Batch Loss: 0.025792228057980537\n",
      "Epoch 233, Loss: 0.03599758259952068, Final Batch Loss: 0.018925318494439125\n",
      "Epoch 234, Loss: 0.04811990261077881, Final Batch Loss: 0.03085685335099697\n",
      "Epoch 235, Loss: 0.05864686705172062, Final Batch Loss: 0.037904318422079086\n",
      "Epoch 236, Loss: 0.05781913176178932, Final Batch Loss: 0.023216962814331055\n",
      "Epoch 237, Loss: 0.018176614306867123, Final Batch Loss: 0.0048778485506772995\n",
      "Epoch 238, Loss: 0.025650346651673317, Final Batch Loss: 0.006559373810887337\n",
      "Epoch 239, Loss: 0.03856043331325054, Final Batch Loss: 0.006553458049893379\n",
      "Epoch 240, Loss: 0.044776489958167076, Final Batch Loss: 0.02731144428253174\n",
      "Epoch 241, Loss: 0.059668345376849174, Final Batch Loss: 0.0366634875535965\n",
      "Epoch 242, Loss: 0.044325802475214005, Final Batch Loss: 0.013426501303911209\n",
      "Epoch 243, Loss: 0.049875074066221714, Final Batch Loss: 0.012640726752579212\n",
      "Epoch 244, Loss: 0.0278234900906682, Final Batch Loss: 0.011521154083311558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245, Loss: 0.029714398086071014, Final Batch Loss: 0.012694869190454483\n",
      "Epoch 246, Loss: 0.06191334128379822, Final Batch Loss: 0.035954784601926804\n",
      "Epoch 247, Loss: 0.028933795168995857, Final Batch Loss: 0.015721814706921577\n",
      "Epoch 248, Loss: 0.016712781973183155, Final Batch Loss: 0.008124716579914093\n",
      "Epoch 249, Loss: 0.060019451193511486, Final Batch Loss: 0.047722239047288895\n",
      "Epoch 250, Loss: 0.017103967256844044, Final Batch Loss: 0.008770931512117386\n",
      "Epoch 251, Loss: 0.0617985874414444, Final Batch Loss: 0.03789651393890381\n",
      "Epoch 252, Loss: 0.012831022497266531, Final Batch Loss: 0.007028212770819664\n",
      "Epoch 253, Loss: 0.031006078235805035, Final Batch Loss: 0.012936300598084927\n",
      "Epoch 254, Loss: 0.02613584604114294, Final Batch Loss: 0.010007248260080814\n",
      "Epoch 255, Loss: 0.030788345262408257, Final Batch Loss: 0.013643166050314903\n",
      "Epoch 256, Loss: 0.05008656159043312, Final Batch Loss: 0.04005475714802742\n",
      "Epoch 257, Loss: 0.017091648653149605, Final Batch Loss: 0.00653732568025589\n",
      "Epoch 258, Loss: 0.052876660600304604, Final Batch Loss: 0.017704403027892113\n",
      "Epoch 259, Loss: 0.03474847227334976, Final Batch Loss: 0.023982474580407143\n",
      "Epoch 260, Loss: 0.019774128682911396, Final Batch Loss: 0.008300668559968472\n",
      "Epoch 261, Loss: 0.029571757651865482, Final Batch Loss: 0.010135325603187084\n",
      "Epoch 262, Loss: 0.017861075699329376, Final Batch Loss: 0.008280743844807148\n",
      "Epoch 263, Loss: 0.029899226501584053, Final Batch Loss: 0.015202922746539116\n",
      "Epoch 264, Loss: 0.03600296005606651, Final Batch Loss: 0.016793182119727135\n",
      "Epoch 265, Loss: 0.02329954132437706, Final Batch Loss: 0.006964815780520439\n",
      "Epoch 266, Loss: 0.03528527868911624, Final Batch Loss: 0.03060918301343918\n",
      "Epoch 267, Loss: 0.032939910888671875, Final Batch Loss: 0.016371693462133408\n",
      "Epoch 268, Loss: 0.022023245692253113, Final Batch Loss: 0.003998257219791412\n",
      "Epoch 269, Loss: 0.04160040616989136, Final Batch Loss: 0.010862570255994797\n",
      "Epoch 270, Loss: 0.03786463104188442, Final Batch Loss: 0.01811828278005123\n",
      "Epoch 271, Loss: 0.04165159538388252, Final Batch Loss: 0.022293174639344215\n",
      "Epoch 272, Loss: 0.04153605457395315, Final Batch Loss: 0.008190001361072063\n",
      "Epoch 273, Loss: 0.05359623022377491, Final Batch Loss: 0.02459275722503662\n",
      "Epoch 274, Loss: 0.04024775046855211, Final Batch Loss: 0.012563853524625301\n",
      "Epoch 275, Loss: 0.025480258278548717, Final Batch Loss: 0.015860410407185555\n",
      "Epoch 276, Loss: 0.026008205488324165, Final Batch Loss: 0.007349861785769463\n",
      "Epoch 277, Loss: 0.02062551025301218, Final Batch Loss: 0.008017043583095074\n",
      "Epoch 278, Loss: 0.039112236350774765, Final Batch Loss: 0.024497879669070244\n",
      "Epoch 279, Loss: 0.019465855322778225, Final Batch Loss: 0.009403596632182598\n",
      "Epoch 280, Loss: 0.06506146676838398, Final Batch Loss: 0.04032568261027336\n",
      "Epoch 281, Loss: 0.04169056471437216, Final Batch Loss: 0.029276371002197266\n",
      "Epoch 282, Loss: 0.02654878981411457, Final Batch Loss: 0.012467438355088234\n",
      "Epoch 283, Loss: 0.023011084645986557, Final Batch Loss: 0.007861168123781681\n",
      "Epoch 284, Loss: 0.03812919370830059, Final Batch Loss: 0.021014438942074776\n",
      "Epoch 285, Loss: 0.041539447382092476, Final Batch Loss: 0.02732081152498722\n",
      "Epoch 286, Loss: 0.037288349121809006, Final Batch Loss: 0.027179326862096786\n",
      "Epoch 287, Loss: 0.023033183999359608, Final Batch Loss: 0.015450391918420792\n",
      "Epoch 288, Loss: 0.02052195556461811, Final Batch Loss: 0.004353085532784462\n",
      "Epoch 289, Loss: 0.027734014205634594, Final Batch Loss: 0.014373614452779293\n",
      "Epoch 290, Loss: 0.0577788520604372, Final Batch Loss: 0.026943637058138847\n",
      "Epoch 291, Loss: 0.03603852540254593, Final Batch Loss: 0.017023727297782898\n",
      "Epoch 292, Loss: 0.028852390125393867, Final Batch Loss: 0.014045887626707554\n",
      "Epoch 293, Loss: 0.04912841599434614, Final Batch Loss: 0.013495060615241528\n",
      "Epoch 294, Loss: 0.04841272346675396, Final Batch Loss: 0.017026221379637718\n",
      "Epoch 295, Loss: 0.02315918728709221, Final Batch Loss: 0.013774316757917404\n",
      "Epoch 296, Loss: 0.01443898444995284, Final Batch Loss: 0.005290980916470289\n",
      "Epoch 297, Loss: 0.03106256015598774, Final Batch Loss: 0.016176659613847733\n",
      "Epoch 298, Loss: 0.02681785821914673, Final Batch Loss: 0.02191191539168358\n",
      "Epoch 299, Loss: 0.04918492026627064, Final Batch Loss: 0.01176208071410656\n",
      "Epoch 300, Loss: 0.023604491725564003, Final Batch Loss: 0.01176619902253151\n",
      "Epoch 301, Loss: 0.03762123920023441, Final Batch Loss: 0.028511811047792435\n",
      "Epoch 302, Loss: 0.021949841640889645, Final Batch Loss: 0.01136490423232317\n",
      "Epoch 303, Loss: 0.023310163524001837, Final Batch Loss: 0.004809047561138868\n",
      "Epoch 304, Loss: 0.05145600810647011, Final Batch Loss: 0.03461321443319321\n",
      "Epoch 305, Loss: 0.039800822734832764, Final Batch Loss: 0.018708767369389534\n",
      "Epoch 306, Loss: 0.023769511841237545, Final Batch Loss: 0.012787717394530773\n",
      "Epoch 307, Loss: 0.024873966351151466, Final Batch Loss: 0.008209625259041786\n",
      "Epoch 308, Loss: 0.026676132809370756, Final Batch Loss: 0.018895694985985756\n",
      "Epoch 309, Loss: 0.016997830010950565, Final Batch Loss: 0.005864138714969158\n",
      "Epoch 310, Loss: 0.03655072767287493, Final Batch Loss: 0.02839518152177334\n",
      "Epoch 311, Loss: 0.012794482288882136, Final Batch Loss: 0.0034629374276846647\n",
      "Epoch 312, Loss: 0.03415061254054308, Final Batch Loss: 0.022336764261126518\n",
      "Epoch 313, Loss: 0.043819610029459, Final Batch Loss: 0.023033181205391884\n",
      "Epoch 314, Loss: 0.026035670191049576, Final Batch Loss: 0.01820443570613861\n",
      "Epoch 315, Loss: 0.026426426135003567, Final Batch Loss: 0.01493518054485321\n",
      "Epoch 316, Loss: 0.03682857099920511, Final Batch Loss: 0.007729836739599705\n",
      "Epoch 317, Loss: 0.03032094892114401, Final Batch Loss: 0.018650345504283905\n",
      "Epoch 318, Loss: 0.018612130545079708, Final Batch Loss: 0.010676203295588493\n",
      "Epoch 319, Loss: 0.022842234931886196, Final Batch Loss: 0.013611648231744766\n",
      "Epoch 320, Loss: 0.024949824903160334, Final Batch Loss: 0.00766799645498395\n",
      "Epoch 321, Loss: 0.02329417411237955, Final Batch Loss: 0.006388227455317974\n",
      "Epoch 322, Loss: 0.02572630438953638, Final Batch Loss: 0.003741801716387272\n",
      "Epoch 323, Loss: 0.02464229427278042, Final Batch Loss: 0.012090584263205528\n",
      "Epoch 324, Loss: 0.0197947695851326, Final Batch Loss: 0.009966671466827393\n",
      "Epoch 325, Loss: 0.017620381899178028, Final Batch Loss: 0.005392499268054962\n",
      "Epoch 326, Loss: 0.027287395671010017, Final Batch Loss: 0.013361884281039238\n",
      "Epoch 327, Loss: 0.03249465115368366, Final Batch Loss: 0.015160560607910156\n",
      "Epoch 328, Loss: 0.02435720432549715, Final Batch Loss: 0.013321571983397007\n",
      "Epoch 329, Loss: 0.0071074883453547955, Final Batch Loss: 0.0026970310136675835\n",
      "Epoch 330, Loss: 0.012723036343231797, Final Batch Loss: 0.002326100366190076\n",
      "Epoch 331, Loss: 0.015139658469706774, Final Batch Loss: 0.0037796548567712307\n",
      "Epoch 332, Loss: 0.03379729576408863, Final Batch Loss: 0.016533374786376953\n",
      "Epoch 333, Loss: 0.02096553146839142, Final Batch Loss: 0.01783778890967369\n",
      "Epoch 334, Loss: 0.03451372915878892, Final Batch Loss: 0.007531580049544573\n",
      "Epoch 335, Loss: 0.06233406625688076, Final Batch Loss: 0.009923124685883522\n",
      "Epoch 336, Loss: 0.05347285233438015, Final Batch Loss: 0.035614967346191406\n",
      "Epoch 337, Loss: 0.01984127936884761, Final Batch Loss: 0.006944169756025076\n",
      "Epoch 338, Loss: 0.011555809061974287, Final Batch Loss: 0.003047203179448843\n",
      "Epoch 339, Loss: 0.010309430537745357, Final Batch Loss: 0.006799535360187292\n",
      "Epoch 340, Loss: 0.07824906380847096, Final Batch Loss: 0.07352577894926071\n",
      "Epoch 341, Loss: 0.03051451314240694, Final Batch Loss: 0.012310911901295185\n",
      "Epoch 342, Loss: 0.014703100547194481, Final Batch Loss: 0.008891448378562927\n",
      "Epoch 343, Loss: 0.05297258868813515, Final Batch Loss: 0.016397379338741302\n",
      "Epoch 344, Loss: 0.02403709851205349, Final Batch Loss: 0.017454000189900398\n",
      "Epoch 345, Loss: 0.019654156640172005, Final Batch Loss: 0.01035037450492382\n",
      "Epoch 346, Loss: 0.034385548904538155, Final Batch Loss: 0.024809906259179115\n",
      "Epoch 347, Loss: 0.012569667771458626, Final Batch Loss: 0.003610922023653984\n",
      "Epoch 348, Loss: 0.03825374599546194, Final Batch Loss: 0.008893917314708233\n",
      "Epoch 349, Loss: 0.009812359465286136, Final Batch Loss: 0.006433872040361166\n",
      "Epoch 350, Loss: 0.017795520834624767, Final Batch Loss: 0.011940925382077694\n",
      "Epoch 351, Loss: 0.015123514458537102, Final Batch Loss: 0.003070548176765442\n",
      "Epoch 352, Loss: 0.02078329399228096, Final Batch Loss: 0.01188482716679573\n",
      "Epoch 353, Loss: 0.037186807952821255, Final Batch Loss: 0.009650318883359432\n",
      "Epoch 354, Loss: 0.02355903247371316, Final Batch Loss: 0.0071956017054617405\n",
      "Epoch 355, Loss: 0.035492933820933104, Final Batch Loss: 0.006268808152526617\n",
      "Epoch 356, Loss: 0.010070273536257446, Final Batch Loss: 0.0016207712469622493\n",
      "Epoch 357, Loss: 0.015891403891146183, Final Batch Loss: 0.006309272721409798\n",
      "Epoch 358, Loss: 0.019425631500780582, Final Batch Loss: 0.009289395064115524\n",
      "Epoch 359, Loss: 0.0166692310012877, Final Batch Loss: 0.009677165187895298\n",
      "Epoch 360, Loss: 0.017174480948597193, Final Batch Loss: 0.012796763330698013\n",
      "Epoch 361, Loss: 0.007172478130087256, Final Batch Loss: 0.0034382997546344995\n",
      "Epoch 362, Loss: 0.015009159920737147, Final Batch Loss: 0.003242384409531951\n",
      "Epoch 363, Loss: 0.01749896793626249, Final Batch Loss: 0.0018855396192520857\n",
      "Epoch 364, Loss: 0.01821675756946206, Final Batch Loss: 0.006984296720474958\n",
      "Epoch 365, Loss: 0.018471790477633476, Final Batch Loss: 0.005451965145766735\n",
      "Epoch 366, Loss: 0.030401600990444422, Final Batch Loss: 0.007460440043359995\n",
      "Epoch 367, Loss: 0.03558005625382066, Final Batch Loss: 0.03311680629849434\n",
      "Epoch 368, Loss: 0.029191238805651665, Final Batch Loss: 0.010951869189739227\n",
      "Epoch 369, Loss: 0.006764955818653107, Final Batch Loss: 0.002744495403021574\n",
      "Epoch 370, Loss: 0.03022860363125801, Final Batch Loss: 0.021780993789434433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371, Loss: 0.019866991322487593, Final Batch Loss: 0.014954989776015282\n",
      "Epoch 372, Loss: 0.02011938439682126, Final Batch Loss: 0.01565307006239891\n",
      "Epoch 373, Loss: 0.018858415074646473, Final Batch Loss: 0.007356660440564156\n",
      "Epoch 374, Loss: 0.029019074514508247, Final Batch Loss: 0.008674843236804008\n",
      "Epoch 375, Loss: 0.011430058162659407, Final Batch Loss: 0.004163600504398346\n",
      "Epoch 376, Loss: 0.05316422414034605, Final Batch Loss: 0.041384488344192505\n",
      "Epoch 377, Loss: 0.014655235689133406, Final Batch Loss: 0.005229210015386343\n",
      "Epoch 378, Loss: 0.013123358832672238, Final Batch Loss: 0.003223507897928357\n",
      "Epoch 379, Loss: 0.018873596098273993, Final Batch Loss: 0.0048141260631382465\n",
      "Epoch 380, Loss: 0.028731065802276134, Final Batch Loss: 0.006064972840249538\n",
      "Epoch 381, Loss: 0.02498052967712283, Final Batch Loss: 0.003790860529989004\n",
      "Epoch 382, Loss: 0.010132243391126394, Final Batch Loss: 0.0055182212963700294\n",
      "Epoch 383, Loss: 0.01872100541368127, Final Batch Loss: 0.005792488809674978\n",
      "Epoch 384, Loss: 0.015038539422675967, Final Batch Loss: 0.013222446665167809\n",
      "Epoch 385, Loss: 0.01778909785207361, Final Batch Loss: 0.0013980999356135726\n",
      "Epoch 386, Loss: 0.010274511761963367, Final Batch Loss: 0.007671145722270012\n",
      "Epoch 387, Loss: 0.050332925748080015, Final Batch Loss: 0.04470806568861008\n",
      "Epoch 388, Loss: 0.0126976523315534, Final Batch Loss: 0.011158512905240059\n",
      "Epoch 389, Loss: 0.01616722671315074, Final Batch Loss: 0.007279863115400076\n",
      "Epoch 390, Loss: 0.010849668644368649, Final Batch Loss: 0.004787818994373083\n",
      "Epoch 391, Loss: 0.020692019490525126, Final Batch Loss: 0.01869695633649826\n",
      "Epoch 392, Loss: 0.011598839424550533, Final Batch Loss: 0.002548553980886936\n",
      "Epoch 393, Loss: 0.009217718383297324, Final Batch Loss: 0.006630820222198963\n",
      "Epoch 394, Loss: 0.03832204919308424, Final Batch Loss: 0.029207052662968636\n",
      "Epoch 395, Loss: 0.019705607322975993, Final Batch Loss: 0.017153166234493256\n",
      "Epoch 396, Loss: 0.014306750148534775, Final Batch Loss: 0.004442205652594566\n",
      "Epoch 397, Loss: 0.05296351946890354, Final Batch Loss: 0.03229890018701553\n",
      "Epoch 398, Loss: 0.026707465760409832, Final Batch Loss: 0.018086735159158707\n",
      "Epoch 399, Loss: 0.010952549055218697, Final Batch Loss: 0.004498887807130814\n",
      "Epoch 400, Loss: 0.00965943222399801, Final Batch Loss: 0.001555460854433477\n",
      "Epoch 401, Loss: 0.024021247401833534, Final Batch Loss: 0.016072286292910576\n",
      "Epoch 402, Loss: 0.00795889541041106, Final Batch Loss: 0.006097069010138512\n",
      "Epoch 403, Loss: 0.00467878591734916, Final Batch Loss: 0.001865743543021381\n",
      "Epoch 404, Loss: 0.03046888206154108, Final Batch Loss: 0.008974309079349041\n",
      "Epoch 405, Loss: 0.007318746764212847, Final Batch Loss: 0.0018623601645231247\n",
      "Epoch 406, Loss: 0.02045633678790182, Final Batch Loss: 0.01905805803835392\n",
      "Epoch 407, Loss: 0.024526909226551652, Final Batch Loss: 0.02342361956834793\n",
      "Epoch 408, Loss: 0.011439267895184457, Final Batch Loss: 0.0013148182770237327\n",
      "Epoch 409, Loss: 0.05682067945599556, Final Batch Loss: 0.03692243993282318\n",
      "Epoch 410, Loss: 0.012392521603032947, Final Batch Loss: 0.0007110477890819311\n",
      "Epoch 411, Loss: 0.013939538039267063, Final Batch Loss: 0.0066905757412314415\n",
      "Epoch 412, Loss: 0.010838992893695831, Final Batch Loss: 0.007329312618821859\n",
      "Epoch 413, Loss: 0.017248653806746006, Final Batch Loss: 0.006224209442734718\n",
      "Epoch 414, Loss: 0.009302281308919191, Final Batch Loss: 0.005184359382838011\n",
      "Epoch 415, Loss: 0.006625212845392525, Final Batch Loss: 0.001893579144962132\n",
      "Epoch 416, Loss: 0.005772927775979042, Final Batch Loss: 0.002393315779045224\n",
      "Epoch 417, Loss: 0.00972118810750544, Final Batch Loss: 0.00680913683027029\n",
      "Epoch 418, Loss: 0.003382474649697542, Final Batch Loss: 0.0008773927111178637\n",
      "Epoch 419, Loss: 0.019439184688962996, Final Batch Loss: 0.01834707334637642\n",
      "Epoch 420, Loss: 0.014740242157131433, Final Batch Loss: 0.010341442190110683\n",
      "Epoch 421, Loss: 0.016919024754315615, Final Batch Loss: 0.011058112606406212\n",
      "Epoch 422, Loss: 0.012087853159755468, Final Batch Loss: 0.009175569750368595\n",
      "Epoch 423, Loss: 0.007758523104712367, Final Batch Loss: 0.002878756495192647\n",
      "Epoch 424, Loss: 0.02124233916401863, Final Batch Loss: 0.017669228836894035\n",
      "Epoch 425, Loss: 0.011219823732972145, Final Batch Loss: 0.005476842168718576\n",
      "Epoch 426, Loss: 0.020969940349459648, Final Batch Loss: 0.009891213849186897\n",
      "Epoch 427, Loss: 0.013758165296167135, Final Batch Loss: 0.007671560626477003\n",
      "Epoch 428, Loss: 0.01734971534460783, Final Batch Loss: 0.015409182757139206\n",
      "Epoch 429, Loss: 0.048890190897509456, Final Batch Loss: 0.04634055867791176\n",
      "Epoch 430, Loss: 0.015209146542474627, Final Batch Loss: 0.012233184650540352\n",
      "Epoch 431, Loss: 0.021896717604249716, Final Batch Loss: 0.0014580241404473782\n",
      "Epoch 432, Loss: 0.01619280595332384, Final Batch Loss: 0.006277468986809254\n",
      "Epoch 433, Loss: 0.05604429077357054, Final Batch Loss: 0.04060797393321991\n",
      "Epoch 434, Loss: 0.020180921535938978, Final Batch Loss: 0.006996580865234137\n",
      "Epoch 435, Loss: 0.023764366284012794, Final Batch Loss: 0.015592396259307861\n",
      "Epoch 436, Loss: 0.016401377972215414, Final Batch Loss: 0.010900449007749557\n",
      "Epoch 437, Loss: 0.009960519266314805, Final Batch Loss: 0.0017812988953664899\n",
      "Epoch 438, Loss: 0.010019030189141631, Final Batch Loss: 0.00275534694083035\n",
      "Epoch 439, Loss: 0.005732034798711538, Final Batch Loss: 0.001269001979380846\n",
      "Epoch 440, Loss: 0.020285606384277344, Final Batch Loss: 0.006215565837919712\n",
      "Epoch 441, Loss: 0.01588511373847723, Final Batch Loss: 0.005086795426905155\n",
      "Epoch 442, Loss: 0.014492745511233807, Final Batch Loss: 0.00664667971432209\n",
      "Epoch 443, Loss: 0.007313477399293333, Final Batch Loss: 0.0008988804765976965\n",
      "Epoch 444, Loss: 0.02880257135257125, Final Batch Loss: 0.00606033718213439\n",
      "Epoch 445, Loss: 0.03277379693463445, Final Batch Loss: 0.027954723685979843\n",
      "Epoch 446, Loss: 0.011719466652721167, Final Batch Loss: 0.004522240255028009\n",
      "Epoch 447, Loss: 0.021305007860064507, Final Batch Loss: 0.012230963446199894\n",
      "Epoch 448, Loss: 0.012236740905791521, Final Batch Loss: 0.004322678316384554\n",
      "Epoch 449, Loss: 0.009860310703516006, Final Batch Loss: 0.004716011695563793\n",
      "Epoch 450, Loss: 0.012934542261064053, Final Batch Loss: 0.008605564013123512\n",
      "Epoch 451, Loss: 0.0071100350469350815, Final Batch Loss: 0.006336547899991274\n",
      "Epoch 452, Loss: 0.007396290544420481, Final Batch Loss: 0.0032841782085597515\n",
      "Epoch 453, Loss: 0.03556502005085349, Final Batch Loss: 0.004519700538367033\n",
      "Epoch 454, Loss: 0.007666578167118132, Final Batch Loss: 0.006073276977986097\n",
      "Epoch 455, Loss: 0.005374735686928034, Final Batch Loss: 0.0023600407876074314\n",
      "Epoch 456, Loss: 0.00626685720635578, Final Batch Loss: 0.0009233743767254055\n",
      "Epoch 457, Loss: 0.030510496580973268, Final Batch Loss: 0.0038052352610975504\n",
      "Epoch 458, Loss: 0.013791401870548725, Final Batch Loss: 0.008995347656309605\n",
      "Epoch 459, Loss: 0.0053198838722892106, Final Batch Loss: 0.0007748243515379727\n",
      "Epoch 460, Loss: 0.020686210598796606, Final Batch Loss: 0.01838972233235836\n",
      "Epoch 461, Loss: 0.007312621688470244, Final Batch Loss: 0.005299413111060858\n",
      "Epoch 462, Loss: 0.0045297283213585615, Final Batch Loss: 0.0011549193877726793\n",
      "Epoch 463, Loss: 0.012088878778740764, Final Batch Loss: 0.009633254259824753\n",
      "Epoch 464, Loss: 0.0401834393851459, Final Batch Loss: 0.007718450855463743\n",
      "Epoch 465, Loss: 0.011966594960540533, Final Batch Loss: 0.005381244700402021\n",
      "Epoch 466, Loss: 0.04967678524553776, Final Batch Loss: 0.03937070071697235\n",
      "Epoch 467, Loss: 0.005421797221060842, Final Batch Loss: 0.004763840697705746\n",
      "Epoch 468, Loss: 0.01241519395262003, Final Batch Loss: 0.010489779524505138\n",
      "Epoch 469, Loss: 0.01587391598150134, Final Batch Loss: 0.003743086475878954\n",
      "Epoch 470, Loss: 0.003659860114566982, Final Batch Loss: 0.0011738530592992902\n",
      "Epoch 471, Loss: 0.039401812478899956, Final Batch Loss: 0.030480585992336273\n",
      "Epoch 472, Loss: 0.012737920973449945, Final Batch Loss: 0.0039341929368674755\n",
      "Epoch 473, Loss: 0.013826035661622882, Final Batch Loss: 0.011140219867229462\n",
      "Epoch 474, Loss: 0.003824179177172482, Final Batch Loss: 0.0005974798696115613\n",
      "Epoch 475, Loss: 0.004397504846565425, Final Batch Loss: 0.0016863237833604217\n",
      "Epoch 476, Loss: 0.015196957625448704, Final Batch Loss: 0.01335070002824068\n",
      "Epoch 477, Loss: 0.02030490431934595, Final Batch Loss: 0.006786387413740158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478, Loss: 0.006162018631584942, Final Batch Loss: 0.0008930709445849061\n",
      "Epoch 479, Loss: 0.010198021307587624, Final Batch Loss: 0.0010079499334096909\n",
      "Epoch 480, Loss: 0.009804020170122385, Final Batch Loss: 0.004294665530323982\n",
      "Epoch 481, Loss: 0.015328339766710997, Final Batch Loss: 0.010236617177724838\n",
      "Epoch 482, Loss: 0.036054931581020355, Final Batch Loss: 0.027095763012766838\n",
      "Epoch 483, Loss: 0.011273069307208061, Final Batch Loss: 0.001063324511051178\n",
      "Epoch 484, Loss: 0.019649074412882328, Final Batch Loss: 0.009957073256373405\n",
      "Epoch 485, Loss: 0.008751828223466873, Final Batch Loss: 0.002448217011988163\n",
      "Epoch 486, Loss: 0.004066147259436548, Final Batch Loss: 0.0026690508238971233\n",
      "Epoch 487, Loss: 0.031048834789544344, Final Batch Loss: 0.025006135925650597\n",
      "Epoch 488, Loss: 0.009156413841992617, Final Batch Loss: 0.003920154646039009\n",
      "Epoch 489, Loss: 0.01411270466633141, Final Batch Loss: 0.002618562662974\n",
      "Epoch 490, Loss: 0.013701556948944926, Final Batch Loss: 0.0034432511311024427\n",
      "Epoch 491, Loss: 0.016284494660794735, Final Batch Loss: 0.006233891472220421\n",
      "Epoch 492, Loss: 0.029114898992702365, Final Batch Loss: 0.0020890336018055677\n",
      "Epoch 493, Loss: 0.008644250920042396, Final Batch Loss: 0.002709785243496299\n",
      "Epoch 494, Loss: 0.024850771063938737, Final Batch Loss: 0.021414676681160927\n",
      "Epoch 495, Loss: 0.014498951844871044, Final Batch Loss: 0.005718862637877464\n",
      "Epoch 496, Loss: 0.004304118687286973, Final Batch Loss: 0.001384506467729807\n",
      "Epoch 497, Loss: 0.014038624474778771, Final Batch Loss: 0.011958535760641098\n",
      "Epoch 498, Loss: 0.006459022290073335, Final Batch Loss: 0.0010786730563268065\n",
      "Epoch 499, Loss: 0.005382734816521406, Final Batch Loss: 0.00140326377004385\n",
      "Epoch 500, Loss: 0.033460203325375915, Final Batch Loss: 0.0037217491772025824\n",
      "Epoch 501, Loss: 0.012397036014590412, Final Batch Loss: 0.0006527109653688967\n",
      "Epoch 502, Loss: 0.007454582257196307, Final Batch Loss: 0.003422518027946353\n",
      "Epoch 503, Loss: 0.014472556998953223, Final Batch Loss: 0.01160193420946598\n",
      "Epoch 504, Loss: 0.01659032329916954, Final Batch Loss: 0.010621670633554459\n",
      "Epoch 505, Loss: 0.01157891028560698, Final Batch Loss: 0.00288706854917109\n",
      "Epoch 506, Loss: 0.004714723094366491, Final Batch Loss: 0.0037318968679755926\n",
      "Epoch 507, Loss: 0.024207783862948418, Final Batch Loss: 0.011465654708445072\n",
      "Epoch 508, Loss: 0.007971263490617275, Final Batch Loss: 0.007194428704679012\n",
      "Epoch 509, Loss: 0.024150448851287365, Final Batch Loss: 0.007521391846239567\n",
      "Epoch 510, Loss: 0.0036913490621373057, Final Batch Loss: 0.0015990891261026263\n",
      "Epoch 511, Loss: 0.01503973756916821, Final Batch Loss: 0.0026104648131877184\n",
      "Epoch 512, Loss: 0.007729356293566525, Final Batch Loss: 0.005926995072513819\n",
      "Epoch 513, Loss: 0.0038638309633824974, Final Batch Loss: 0.00045445203431881964\n",
      "Epoch 514, Loss: 0.019366704858839512, Final Batch Loss: 0.004793668165802956\n",
      "Epoch 515, Loss: 0.0014276454166974872, Final Batch Loss: 0.0009874020470306277\n",
      "Epoch 516, Loss: 0.011645835591480136, Final Batch Loss: 0.008337562903761864\n",
      "Epoch 517, Loss: 0.016437972662970424, Final Batch Loss: 0.002032897202298045\n",
      "Epoch 518, Loss: 0.04909064923413098, Final Batch Loss: 0.0456797331571579\n",
      "Epoch 519, Loss: 0.011965082958340645, Final Batch Loss: 0.0036923736333847046\n",
      "Epoch 520, Loss: 0.02749720960855484, Final Batch Loss: 0.011903151869773865\n",
      "Epoch 521, Loss: 0.012388489907607436, Final Batch Loss: 0.0034583944361656904\n",
      "Epoch 522, Loss: 0.007573055219836533, Final Batch Loss: 0.0012671431759372354\n",
      "Epoch 523, Loss: 0.010460545658133924, Final Batch Loss: 0.0015626990934833884\n",
      "Epoch 524, Loss: 0.018237689044326544, Final Batch Loss: 0.007294912356883287\n",
      "Epoch 525, Loss: 0.009085627738386393, Final Batch Loss: 0.004772860556840897\n",
      "Epoch 526, Loss: 0.002755463356152177, Final Batch Loss: 0.0007667131721973419\n",
      "Epoch 527, Loss: 0.012568134698085487, Final Batch Loss: 0.0010803499026224017\n",
      "Epoch 528, Loss: 0.0061103838961571455, Final Batch Loss: 0.002598807215690613\n",
      "Epoch 529, Loss: 0.004141312558203936, Final Batch Loss: 0.003096909960731864\n",
      "Epoch 530, Loss: 0.01115351915359497, Final Batch Loss: 0.003508336842060089\n",
      "Epoch 531, Loss: 0.021539871580898762, Final Batch Loss: 0.0020107412710785866\n",
      "Epoch 532, Loss: 0.006653437623754144, Final Batch Loss: 0.005068709142506123\n",
      "Epoch 533, Loss: 0.00647366582415998, Final Batch Loss: 0.0038928419817239046\n",
      "Epoch 534, Loss: 0.009104962460696697, Final Batch Loss: 0.0020007314160466194\n",
      "Epoch 535, Loss: 0.00461898825597018, Final Batch Loss: 0.0029022148810327053\n",
      "Epoch 536, Loss: 0.008110216585919261, Final Batch Loss: 0.005533806513994932\n",
      "Epoch 537, Loss: 0.004194081120658666, Final Batch Loss: 0.0008924946305342019\n",
      "Epoch 538, Loss: 0.007835872936993837, Final Batch Loss: 0.0053261383436620235\n",
      "Epoch 539, Loss: 0.018820672761648893, Final Batch Loss: 0.002340990584343672\n",
      "Epoch 540, Loss: 0.006103905383497477, Final Batch Loss: 0.003732636570930481\n",
      "Epoch 541, Loss: 0.004259768989868462, Final Batch Loss: 0.002388235880061984\n",
      "Epoch 542, Loss: 0.007056372473016381, Final Batch Loss: 0.0032573076896369457\n",
      "Epoch 543, Loss: 0.017763634212315083, Final Batch Loss: 0.013615398667752743\n",
      "Epoch 544, Loss: 0.006610489916056395, Final Batch Loss: 0.004176983144134283\n",
      "Epoch 545, Loss: 0.00886292103677988, Final Batch Loss: 0.002890388946980238\n",
      "Epoch 546, Loss: 0.006494142347946763, Final Batch Loss: 0.002333306474611163\n",
      "Epoch 547, Loss: 0.013450347585603595, Final Batch Loss: 0.011227836832404137\n",
      "Epoch 548, Loss: 0.016723765525966883, Final Batch Loss: 0.006656949874013662\n",
      "Epoch 549, Loss: 0.04336724244058132, Final Batch Loss: 0.020569967105984688\n",
      "Epoch 550, Loss: 0.02511177328415215, Final Batch Loss: 0.022968368604779243\n",
      "Epoch 551, Loss: 0.0014723636559210718, Final Batch Loss: 0.0003311611362732947\n",
      "Epoch 552, Loss: 0.03543077548965812, Final Batch Loss: 0.005863170605152845\n",
      "Epoch 553, Loss: 0.015996900852769613, Final Batch Loss: 0.013863635249435902\n",
      "Epoch 554, Loss: 0.0051770193967968225, Final Batch Loss: 0.0021594646386802197\n",
      "Epoch 555, Loss: 0.004878220148384571, Final Batch Loss: 0.001071614446118474\n",
      "Epoch 556, Loss: 0.0014941593108233064, Final Batch Loss: 0.00040514589636586607\n",
      "Epoch 557, Loss: 0.002326026326045394, Final Batch Loss: 0.0016750117065384984\n",
      "Epoch 558, Loss: 0.006331789772957563, Final Batch Loss: 0.002316621597856283\n",
      "Epoch 559, Loss: 0.008146677864715457, Final Batch Loss: 0.0015049006324261427\n",
      "Epoch 560, Loss: 0.004020854132249951, Final Batch Loss: 0.002022137399762869\n",
      "Epoch 561, Loss: 0.0035472150484565645, Final Batch Loss: 0.0004353100957814604\n",
      "Epoch 562, Loss: 0.011138095054775476, Final Batch Loss: 0.0037739016115665436\n",
      "Epoch 563, Loss: 0.0041603397112339735, Final Batch Loss: 0.0012586358934640884\n",
      "Epoch 564, Loss: 0.004978021956048906, Final Batch Loss: 0.003216795390471816\n",
      "Epoch 565, Loss: 0.014251105720177293, Final Batch Loss: 0.011340112425386906\n",
      "Epoch 566, Loss: 0.015699726180173457, Final Batch Loss: 0.001780740567483008\n",
      "Epoch 567, Loss: 0.034357551485300064, Final Batch Loss: 0.007231827825307846\n",
      "Epoch 568, Loss: 0.007327834144234657, Final Batch Loss: 0.002124370075762272\n",
      "Epoch 569, Loss: 0.0011415818007662892, Final Batch Loss: 0.0005291664856486022\n",
      "Epoch 570, Loss: 0.003586409264244139, Final Batch Loss: 0.001714223762974143\n",
      "Epoch 571, Loss: 0.00577352661639452, Final Batch Loss: 0.0039822557009756565\n",
      "Epoch 572, Loss: 0.008455256931483746, Final Batch Loss: 0.004003145731985569\n",
      "Epoch 573, Loss: 0.00488953641615808, Final Batch Loss: 0.001526691485196352\n",
      "Epoch 574, Loss: 0.005964934825897217, Final Batch Loss: 0.003023277735337615\n",
      "Epoch 575, Loss: 0.0044657724210992455, Final Batch Loss: 0.0011676190188154578\n",
      "Epoch 576, Loss: 0.006430465262383223, Final Batch Loss: 0.0040181842632591724\n",
      "Epoch 577, Loss: 0.012568387668579817, Final Batch Loss: 0.011593891307711601\n",
      "Epoch 578, Loss: 0.0018997557344846427, Final Batch Loss: 0.0012136615114286542\n",
      "Epoch 579, Loss: 0.03535951138474047, Final Batch Loss: 0.03207860141992569\n",
      "Epoch 580, Loss: 0.005871088709682226, Final Batch Loss: 0.0025180892553180456\n",
      "Epoch 581, Loss: 0.005413529928773642, Final Batch Loss: 0.0023628685157746077\n",
      "Epoch 582, Loss: 0.006715182855259627, Final Batch Loss: 0.0008261787588708103\n",
      "Epoch 583, Loss: 0.006100110826082528, Final Batch Loss: 0.00436594570055604\n",
      "Epoch 584, Loss: 0.0209726900793612, Final Batch Loss: 0.016415908932685852\n",
      "Epoch 585, Loss: 0.007505553192459047, Final Batch Loss: 0.0003816223470494151\n",
      "Epoch 586, Loss: 0.018371084704995155, Final Batch Loss: 0.0064234258607029915\n",
      "Epoch 587, Loss: 0.005190126597881317, Final Batch Loss: 0.0040340120904147625\n",
      "Epoch 588, Loss: 0.007807301357388496, Final Batch Loss: 0.002257895190268755\n",
      "Epoch 589, Loss: 0.0048914795042946935, Final Batch Loss: 0.004205445293337107\n",
      "Epoch 590, Loss: 0.008779619471170008, Final Batch Loss: 0.0018368387827649713\n",
      "Epoch 591, Loss: 0.0012669773423112929, Final Batch Loss: 0.0006180781056173146\n",
      "Epoch 592, Loss: 0.004526853561401367, Final Batch Loss: 0.0024585137143731117\n",
      "Epoch 593, Loss: 0.016859948867931962, Final Batch Loss: 0.0021748992148786783\n",
      "Epoch 594, Loss: 0.011576038668863475, Final Batch Loss: 0.01064919400960207\n",
      "Epoch 595, Loss: 0.015190193895250559, Final Batch Loss: 0.0062582348473370075\n",
      "Epoch 596, Loss: 0.0025377243291586637, Final Batch Loss: 0.0005537176039069891\n",
      "Epoch 597, Loss: 0.014036978245712817, Final Batch Loss: 0.012869616039097309\n",
      "Epoch 598, Loss: 0.03372101439163089, Final Batch Loss: 0.00439889682456851\n",
      "Epoch 599, Loss: 0.02245453931391239, Final Batch Loss: 0.013391531072556973\n",
      "Epoch 600, Loss: 0.005855328286997974, Final Batch Loss: 0.001053030020557344\n",
      "Epoch 601, Loss: 0.0040956183802336454, Final Batch Loss: 0.002056114375591278\n",
      "Epoch 602, Loss: 0.005258417688310146, Final Batch Loss: 0.002146058715879917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 603, Loss: 0.006268930155783892, Final Batch Loss: 0.004285276401787996\n",
      "Epoch 604, Loss: 0.002764058648608625, Final Batch Loss: 0.0006019476568326354\n",
      "Epoch 605, Loss: 0.009510764386504889, Final Batch Loss: 0.005037369672209024\n",
      "Epoch 606, Loss: 0.0230602971278131, Final Batch Loss: 0.0014217342250049114\n",
      "Epoch 607, Loss: 0.0036253936123102903, Final Batch Loss: 0.0026472746394574642\n",
      "Epoch 608, Loss: 0.01106552901910618, Final Batch Loss: 0.0005948453326709569\n",
      "Epoch 609, Loss: 0.02396638278150931, Final Batch Loss: 0.0009288150467909873\n",
      "Epoch 610, Loss: 0.01104342145845294, Final Batch Loss: 0.00940250325948\n",
      "Epoch 611, Loss: 0.011902391095645726, Final Batch Loss: 0.011396097019314766\n",
      "Epoch 612, Loss: 0.003669774276204407, Final Batch Loss: 0.003062766045331955\n",
      "Epoch 613, Loss: 0.009129891055636108, Final Batch Loss: 0.007251934614032507\n",
      "Epoch 614, Loss: 0.01508683804422617, Final Batch Loss: 0.005069988779723644\n",
      "Epoch 615, Loss: 0.0280440216884017, Final Batch Loss: 0.020777497440576553\n",
      "Epoch 616, Loss: 0.01595286908559501, Final Batch Loss: 0.0132451755926013\n",
      "Epoch 617, Loss: 0.006576575920917094, Final Batch Loss: 0.005309583619236946\n",
      "Epoch 618, Loss: 0.00665240315720439, Final Batch Loss: 0.002628730610013008\n",
      "Epoch 619, Loss: 0.005777308950200677, Final Batch Loss: 0.0046641211956739426\n",
      "Epoch 620, Loss: 0.003610241343267262, Final Batch Loss: 0.0013691639760509133\n",
      "Epoch 621, Loss: 0.0009417975670658052, Final Batch Loss: 0.00021305849077180028\n",
      "Epoch 622, Loss: 0.004449300467967987, Final Batch Loss: 0.0020310948602855206\n",
      "Epoch 623, Loss: 0.007632542634382844, Final Batch Loss: 0.0021342288237065077\n",
      "Epoch 624, Loss: 0.00275122351013124, Final Batch Loss: 0.0013408125378191471\n",
      "Epoch 625, Loss: 0.011720519047230482, Final Batch Loss: 0.009866525419056416\n",
      "Epoch 626, Loss: 0.006131382775492966, Final Batch Loss: 0.004566565155982971\n",
      "Epoch 627, Loss: 0.0038841930218040943, Final Batch Loss: 0.0022523272782564163\n",
      "Epoch 628, Loss: 0.01400562422350049, Final Batch Loss: 0.011922864243388176\n",
      "Epoch 629, Loss: 0.018772419774904847, Final Batch Loss: 0.016625234857201576\n",
      "Epoch 630, Loss: 0.008031364064663649, Final Batch Loss: 0.006971009075641632\n",
      "Epoch 631, Loss: 0.011433133156970143, Final Batch Loss: 0.003810951253399253\n",
      "Epoch 632, Loss: 0.0027679799241013825, Final Batch Loss: 0.0022636614739894867\n",
      "Epoch 633, Loss: 0.0020780228078365326, Final Batch Loss: 0.00029326113872230053\n",
      "Epoch 634, Loss: 0.004149289918132126, Final Batch Loss: 0.0024552796967327595\n",
      "Epoch 635, Loss: 0.010059282183647156, Final Batch Loss: 0.007745312061160803\n",
      "Epoch 636, Loss: 0.006940694758668542, Final Batch Loss: 0.0038061703089624643\n",
      "Epoch 637, Loss: 0.004222529329126701, Final Batch Loss: 0.00033026872551999986\n",
      "Epoch 638, Loss: 0.01089323591440916, Final Batch Loss: 0.00201374851167202\n",
      "Epoch 639, Loss: 0.03370744804851711, Final Batch Loss: 0.003876532195135951\n",
      "Epoch 640, Loss: 0.010578956105746329, Final Batch Loss: 0.008838535286486149\n",
      "Epoch 641, Loss: 0.015056533738970757, Final Batch Loss: 0.004502212628722191\n",
      "Epoch 642, Loss: 0.013356541283428669, Final Batch Loss: 0.0013721752911806107\n",
      "Epoch 643, Loss: 0.0019393600523471832, Final Batch Loss: 0.0005305993836373091\n",
      "Epoch 644, Loss: 0.01326338283251971, Final Batch Loss: 0.0009235654724761844\n",
      "Epoch 645, Loss: 0.004080962506122887, Final Batch Loss: 0.002780394395813346\n",
      "Epoch 646, Loss: 0.0033719530911184847, Final Batch Loss: 0.0005226415232755244\n",
      "Epoch 647, Loss: 0.00346243882086128, Final Batch Loss: 0.0005414836341515183\n",
      "Epoch 648, Loss: 0.0049616333562880754, Final Batch Loss: 0.004118838347494602\n",
      "Epoch 649, Loss: 0.00407298794016242, Final Batch Loss: 0.00202320609241724\n",
      "Epoch 650, Loss: 0.005765926674939692, Final Batch Loss: 0.00463492888957262\n",
      "Epoch 651, Loss: 0.012853942112997174, Final Batch Loss: 0.0028155019972473383\n",
      "Epoch 652, Loss: 0.005227861809544265, Final Batch Loss: 0.003382614580914378\n",
      "Epoch 653, Loss: 0.005301001365296543, Final Batch Loss: 0.0012774764327332377\n",
      "Epoch 654, Loss: 0.01277110178489238, Final Batch Loss: 0.011715812608599663\n",
      "Epoch 655, Loss: 0.013697871938347816, Final Batch Loss: 0.0064954436384141445\n",
      "Epoch 656, Loss: 0.02298241388052702, Final Batch Loss: 0.01556448731571436\n",
      "Epoch 657, Loss: 0.012523801764473319, Final Batch Loss: 0.003145570633932948\n",
      "Epoch 658, Loss: 0.0031442029867321253, Final Batch Loss: 0.0009504687041044235\n",
      "Epoch 659, Loss: 0.010649038013070822, Final Batch Loss: 0.008743396028876305\n",
      "Epoch 660, Loss: 0.010823477408848703, Final Batch Loss: 0.0017899846425279975\n",
      "Epoch 661, Loss: 0.003547208762029186, Final Batch Loss: 0.0002618887519929558\n",
      "Epoch 662, Loss: 0.004702859267126769, Final Batch Loss: 0.003775867633521557\n",
      "Epoch 663, Loss: 0.012100908439606428, Final Batch Loss: 0.007418779656291008\n",
      "Epoch 664, Loss: 0.011655292939394712, Final Batch Loss: 0.007506683003157377\n",
      "Epoch 665, Loss: 0.004003137117251754, Final Batch Loss: 0.0028842648025602102\n",
      "Epoch 666, Loss: 0.012134413700550795, Final Batch Loss: 0.009135338477790356\n",
      "Epoch 667, Loss: 0.010570722399279475, Final Batch Loss: 0.002225402509793639\n",
      "Epoch 668, Loss: 0.03177738469094038, Final Batch Loss: 0.002214972861111164\n",
      "Epoch 669, Loss: 0.002922664803918451, Final Batch Loss: 0.0020076569635421038\n",
      "Epoch 670, Loss: 0.00393235613591969, Final Batch Loss: 0.0008469175081700087\n",
      "Epoch 671, Loss: 0.0026684871991164982, Final Batch Loss: 0.0007199248648248613\n",
      "Epoch 672, Loss: 0.022906626341864467, Final Batch Loss: 0.020550010725855827\n",
      "Epoch 673, Loss: 0.03983925189822912, Final Batch Loss: 0.03374361991882324\n",
      "Epoch 674, Loss: 0.0019060784834437072, Final Batch Loss: 0.00044502440141513944\n",
      "Epoch 675, Loss: 0.008502027718350291, Final Batch Loss: 0.0010707646142691374\n",
      "Epoch 676, Loss: 0.007595312898047268, Final Batch Loss: 0.0011626804480329156\n",
      "Epoch 677, Loss: 0.01063660520594567, Final Batch Loss: 0.0013480129418894649\n",
      "Epoch 678, Loss: 0.022491255309432745, Final Batch Loss: 0.002842725720256567\n",
      "Epoch 679, Loss: 0.009687269572168589, Final Batch Loss: 0.0017695906572043896\n",
      "Epoch 680, Loss: 0.013267961738165468, Final Batch Loss: 0.01282547041773796\n",
      "Epoch 681, Loss: 0.004924859036691487, Final Batch Loss: 0.003332948312163353\n",
      "Epoch 682, Loss: 0.003364630276337266, Final Batch Loss: 0.0013580473605543375\n",
      "Epoch 683, Loss: 0.0017401417717337608, Final Batch Loss: 0.0012050027726218104\n",
      "Epoch 684, Loss: 0.002185716468375176, Final Batch Loss: 0.0008520533447153866\n",
      "Epoch 685, Loss: 0.026403547963127494, Final Batch Loss: 0.0024229807313531637\n",
      "Epoch 686, Loss: 0.002416674164123833, Final Batch Loss: 0.0005885873688384891\n",
      "Epoch 687, Loss: 0.001698726846370846, Final Batch Loss: 0.0003728233859874308\n",
      "Epoch 688, Loss: 0.02667387342080474, Final Batch Loss: 0.021467123180627823\n",
      "Epoch 689, Loss: 0.010596388019621372, Final Batch Loss: 0.006864745169878006\n",
      "Epoch 690, Loss: 0.011296332348138094, Final Batch Loss: 0.0033420477993786335\n",
      "Epoch 691, Loss: 0.0037930505350232124, Final Batch Loss: 0.002990004373714328\n",
      "Epoch 692, Loss: 0.01848950982093811, Final Batch Loss: 0.004488118924200535\n",
      "Epoch 693, Loss: 0.004148154170252383, Final Batch Loss: 0.002888381714001298\n",
      "Epoch 694, Loss: 0.007676678244024515, Final Batch Loss: 0.0031486735679209232\n",
      "Epoch 695, Loss: 0.0015718216309323907, Final Batch Loss: 0.0004934836179018021\n",
      "Epoch 696, Loss: 0.001776252523995936, Final Batch Loss: 0.0012496518902480602\n",
      "Epoch 697, Loss: 0.03730579512193799, Final Batch Loss: 0.030561063438653946\n",
      "Epoch 698, Loss: 0.005364643409848213, Final Batch Loss: 0.0046906545758247375\n",
      "Epoch 699, Loss: 0.003637296729721129, Final Batch Loss: 0.0011695929570123553\n",
      "Epoch 700, Loss: 0.010004785377532244, Final Batch Loss: 0.0064898645505309105\n",
      "Epoch 701, Loss: 0.0017507639713585377, Final Batch Loss: 0.0005124539602547884\n",
      "Epoch 702, Loss: 0.007292399925063364, Final Batch Loss: 0.00012807761959265918\n",
      "Epoch 703, Loss: 0.002648634254001081, Final Batch Loss: 0.0011214988771826029\n",
      "Epoch 704, Loss: 0.001062524737790227, Final Batch Loss: 0.000512984930537641\n",
      "Epoch 705, Loss: 0.01092056673951447, Final Batch Loss: 0.002368226880207658\n",
      "Epoch 706, Loss: 0.004117981065064669, Final Batch Loss: 0.002421664074063301\n",
      "Epoch 707, Loss: 0.0036599580198526382, Final Batch Loss: 0.0026322246994823217\n",
      "Epoch 708, Loss: 0.0015181907219812274, Final Batch Loss: 0.0005667125806212425\n",
      "Epoch 709, Loss: 0.0016075783059932292, Final Batch Loss: 0.0008552261278964579\n",
      "Epoch 710, Loss: 0.0010355380945838988, Final Batch Loss: 0.0002707029925659299\n",
      "Epoch 711, Loss: 0.006158953416161239, Final Batch Loss: 0.0017176721012219787\n",
      "Epoch 712, Loss: 0.012486929073929787, Final Batch Loss: 0.00881674699485302\n",
      "Epoch 713, Loss: 0.004584510461427271, Final Batch Loss: 0.0005811286391690373\n",
      "Epoch 714, Loss: 0.005609869956970215, Final Batch Loss: 0.0022591687738895416\n",
      "Epoch 715, Loss: 0.002657692413777113, Final Batch Loss: 0.0013401554897427559\n",
      "Epoch 716, Loss: 0.005430410732515156, Final Batch Loss: 0.004284826572984457\n",
      "Epoch 717, Loss: 0.0012463351304177195, Final Batch Loss: 0.0009838800178840756\n",
      "Epoch 718, Loss: 0.00818723370321095, Final Batch Loss: 0.0025466515216976404\n",
      "Epoch 719, Loss: 0.004101564001757652, Final Batch Loss: 0.003797006793320179\n",
      "Epoch 720, Loss: 0.010664363042451441, Final Batch Loss: 0.008821465075016022\n",
      "Epoch 721, Loss: 0.0076109649380669, Final Batch Loss: 0.006743141915649176\n",
      "Epoch 722, Loss: 0.020041861571371555, Final Batch Loss: 0.011689317412674427\n",
      "Epoch 723, Loss: 0.0015582120249746367, Final Batch Loss: 0.000150147287058644\n",
      "Epoch 724, Loss: 0.008325891103595495, Final Batch Loss: 0.003933585248887539\n",
      "Epoch 725, Loss: 0.006819757865741849, Final Batch Loss: 0.0037730636540800333\n",
      "Epoch 726, Loss: 0.003965582000091672, Final Batch Loss: 0.0024284047540277243\n",
      "Epoch 727, Loss: 0.0020585915190167725, Final Batch Loss: 0.0007469946867786348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728, Loss: 0.007679329835809767, Final Batch Loss: 0.0013566372217610478\n",
      "Epoch 729, Loss: 0.001777208934072405, Final Batch Loss: 0.0009211247670464218\n",
      "Epoch 730, Loss: 0.0237598295789212, Final Batch Loss: 0.002624981803819537\n",
      "Epoch 731, Loss: 0.010263988515362144, Final Batch Loss: 0.008619819767773151\n",
      "Epoch 732, Loss: 0.009676480520283803, Final Batch Loss: 0.00018601291230879724\n",
      "Epoch 733, Loss: 0.013086348422802985, Final Batch Loss: 0.0010293197119608521\n",
      "Epoch 734, Loss: 0.002129868691554293, Final Batch Loss: 0.00019764513126574457\n",
      "Epoch 735, Loss: 0.0040038288570940495, Final Batch Loss: 0.001995095517486334\n",
      "Epoch 736, Loss: 0.019206040538847446, Final Batch Loss: 0.01760980114340782\n",
      "Epoch 737, Loss: 0.012531064567156136, Final Batch Loss: 0.010991567745804787\n",
      "Epoch 738, Loss: 0.020473812241107225, Final Batch Loss: 0.002444144804030657\n",
      "Epoch 739, Loss: 0.00634394190274179, Final Batch Loss: 0.0027980839367955923\n",
      "Epoch 740, Loss: 0.023221993120387197, Final Batch Loss: 0.0034503352362662554\n",
      "Epoch 741, Loss: 0.001647084136493504, Final Batch Loss: 0.0004481922369450331\n",
      "Epoch 742, Loss: 0.002055813805782236, Final Batch Loss: 0.00013482595386449248\n",
      "Epoch 743, Loss: 0.006335722020594403, Final Batch Loss: 0.005851252470165491\n",
      "Epoch 744, Loss: 0.01584436558187008, Final Batch Loss: 0.0031627127900719643\n",
      "Epoch 745, Loss: 0.002304229070432484, Final Batch Loss: 0.0011054397327825427\n",
      "Epoch 746, Loss: 0.000887687288923189, Final Batch Loss: 0.00039057046524249017\n",
      "Epoch 747, Loss: 0.0038874620804563165, Final Batch Loss: 0.0025988523848354816\n",
      "Epoch 748, Loss: 0.005232760915532708, Final Batch Loss: 0.0020707431249320507\n",
      "Epoch 749, Loss: 0.02062682033283636, Final Batch Loss: 0.019885100424289703\n",
      "Epoch 750, Loss: 0.001103143789805472, Final Batch Loss: 0.0005480733816511929\n",
      "Epoch 751, Loss: 0.0193333177594468, Final Batch Loss: 0.018020041286945343\n",
      "Epoch 752, Loss: 0.006620784057304263, Final Batch Loss: 0.0012561066541820765\n",
      "Epoch 753, Loss: 0.005158377578482032, Final Batch Loss: 0.0031459438614547253\n",
      "Epoch 754, Loss: 0.001108855227357708, Final Batch Loss: 0.00013040842895861715\n",
      "Epoch 755, Loss: 0.0015726429992355406, Final Batch Loss: 0.0009793034987524152\n",
      "Epoch 756, Loss: 0.00306979869492352, Final Batch Loss: 0.0009151974227279425\n",
      "Epoch 757, Loss: 0.0009432868100702763, Final Batch Loss: 0.000582686741836369\n",
      "Epoch 758, Loss: 0.010314170736819506, Final Batch Loss: 0.008341838605701923\n",
      "Epoch 759, Loss: 0.0011350650747772306, Final Batch Loss: 0.0006743709091097116\n",
      "Epoch 760, Loss: 0.0006283629918470979, Final Batch Loss: 0.0002753020671661943\n",
      "Epoch 761, Loss: 0.0031707913149148226, Final Batch Loss: 0.002299531130120158\n",
      "Epoch 762, Loss: 0.0021507704514078796, Final Batch Loss: 0.0008000207017175853\n",
      "Epoch 763, Loss: 0.03520331287290901, Final Batch Loss: 0.03419895097613335\n",
      "Epoch 764, Loss: 0.0016382051398977637, Final Batch Loss: 0.001244442188180983\n",
      "Epoch 765, Loss: 0.0036545988405123353, Final Batch Loss: 0.00247091893106699\n",
      "Epoch 766, Loss: 0.004551159567199647, Final Batch Loss: 0.001035835244692862\n",
      "Epoch 767, Loss: 0.01226138393394649, Final Batch Loss: 0.0019712417852133512\n",
      "Epoch 768, Loss: 0.01094474841374904, Final Batch Loss: 0.009855445474386215\n",
      "Epoch 769, Loss: 0.005553344148211181, Final Batch Loss: 0.0012523893965408206\n",
      "Epoch 770, Loss: 0.004152039415203035, Final Batch Loss: 0.0031537285540252924\n",
      "Epoch 771, Loss: 0.007950621016789228, Final Batch Loss: 0.0006511456449516118\n",
      "Epoch 772, Loss: 0.0020120402332395315, Final Batch Loss: 0.0005097731482237577\n",
      "Epoch 773, Loss: 0.002548887801822275, Final Batch Loss: 0.0018466400215402246\n",
      "Epoch 774, Loss: 0.009671728126704693, Final Batch Loss: 0.008469918742775917\n",
      "Epoch 775, Loss: 0.005840142141096294, Final Batch Loss: 0.0019282748689875007\n",
      "Epoch 776, Loss: 0.010166863998165354, Final Batch Loss: 0.009879776276648045\n",
      "Epoch 777, Loss: 0.008116851793602109, Final Batch Loss: 0.00247781234793365\n",
      "Epoch 778, Loss: 0.002759145980235189, Final Batch Loss: 0.00045469769975170493\n",
      "Epoch 779, Loss: 0.01194203831255436, Final Batch Loss: 0.009377800859510899\n",
      "Epoch 780, Loss: 0.0011162139126099646, Final Batch Loss: 0.0008787632687017322\n",
      "Epoch 781, Loss: 0.006244598771445453, Final Batch Loss: 0.0007122227689251304\n",
      "Epoch 782, Loss: 0.003995580365881324, Final Batch Loss: 0.002947869012132287\n",
      "Epoch 783, Loss: 0.00223188049858436, Final Batch Loss: 0.001293908804655075\n",
      "Epoch 784, Loss: 0.002247147378511727, Final Batch Loss: 0.000791676458902657\n",
      "Epoch 785, Loss: 0.0020788328838534653, Final Batch Loss: 0.0012091113021597266\n",
      "Epoch 786, Loss: 0.004185196710750461, Final Batch Loss: 0.0007642586715519428\n",
      "Epoch 787, Loss: 0.006160050863400102, Final Batch Loss: 0.003891985397785902\n",
      "Epoch 788, Loss: 0.002420957782305777, Final Batch Loss: 0.0008870498277246952\n",
      "Epoch 789, Loss: 0.011672856868244708, Final Batch Loss: 0.0013162397081032395\n",
      "Epoch 790, Loss: 0.003461219370365143, Final Batch Loss: 0.0011441269889473915\n",
      "Epoch 791, Loss: 0.016462248051539063, Final Batch Loss: 0.015893058851361275\n",
      "Epoch 792, Loss: 0.0036644521169364452, Final Batch Loss: 0.0016726397443562746\n",
      "Epoch 793, Loss: 0.000658170145470649, Final Batch Loss: 0.0003509262460283935\n",
      "Epoch 794, Loss: 0.00454116752371192, Final Batch Loss: 0.0019640715327113867\n",
      "Epoch 795, Loss: 0.002721041557379067, Final Batch Loss: 0.0014549125917255878\n",
      "Epoch 796, Loss: 0.0005740619671996683, Final Batch Loss: 0.0002861132670659572\n",
      "Epoch 797, Loss: 0.004873278667218983, Final Batch Loss: 0.003743220353499055\n",
      "Epoch 798, Loss: 0.0007505251269321889, Final Batch Loss: 0.0002470345643814653\n",
      "Epoch 799, Loss: 0.002416014700429514, Final Batch Loss: 0.002153136068955064\n",
      "Epoch 800, Loss: 0.0014685204369015992, Final Batch Loss: 0.0008596605621278286\n",
      "Epoch 801, Loss: 0.00683953361294698, Final Batch Loss: 0.00014120321429800242\n",
      "Epoch 802, Loss: 0.0017206139746122062, Final Batch Loss: 0.0008954563527368009\n",
      "Epoch 803, Loss: 0.006357904872857034, Final Batch Loss: 0.0012913382379338145\n",
      "Epoch 804, Loss: 0.01236403500661254, Final Batch Loss: 0.011571574956178665\n",
      "Epoch 805, Loss: 0.002728187129832804, Final Batch Loss: 0.0022368580102920532\n",
      "Epoch 806, Loss: 0.002803371986374259, Final Batch Loss: 0.000597251346334815\n",
      "Epoch 807, Loss: 0.01594701487920247, Final Batch Loss: 0.015538648702204227\n",
      "Epoch 808, Loss: 0.008042317349463701, Final Batch Loss: 0.0005501061677932739\n",
      "Epoch 809, Loss: 0.015278158709406853, Final Batch Loss: 0.01380273699760437\n",
      "Epoch 810, Loss: 0.007241761544719338, Final Batch Loss: 0.003135327948257327\n",
      "Epoch 811, Loss: 0.01118059508735314, Final Batch Loss: 0.0008579488494433463\n",
      "Epoch 812, Loss: 0.006277360953390598, Final Batch Loss: 0.0014683529734611511\n",
      "Epoch 813, Loss: 0.0068343782622832805, Final Batch Loss: 0.0003632686857599765\n",
      "Epoch 814, Loss: 0.004059084691107273, Final Batch Loss: 0.0025473416317254305\n",
      "Epoch 815, Loss: 0.0020315057481639087, Final Batch Loss: 0.0005323192453943193\n",
      "Epoch 816, Loss: 0.0025174482143484056, Final Batch Loss: 0.0019061780767515302\n",
      "Epoch 817, Loss: 0.0015701344818808138, Final Batch Loss: 0.0006389297777786851\n",
      "Epoch 818, Loss: 0.003159047744702548, Final Batch Loss: 0.0009513189434073865\n",
      "Epoch 819, Loss: 0.013356400886550546, Final Batch Loss: 0.012548702768981457\n",
      "Epoch 820, Loss: 0.0012038643326377496, Final Batch Loss: 0.001011983142234385\n",
      "Epoch 821, Loss: 0.01858724607154727, Final Batch Loss: 0.01113171223551035\n",
      "Epoch 822, Loss: 0.0057176910049747676, Final Batch Loss: 0.0004857508174609393\n",
      "Epoch 823, Loss: 0.014547680038958788, Final Batch Loss: 0.012102227658033371\n",
      "Epoch 824, Loss: 0.0013583959662355483, Final Batch Loss: 0.0005181885208003223\n",
      "Epoch 825, Loss: 0.0007500518695451319, Final Batch Loss: 0.00039737706538289785\n",
      "Epoch 826, Loss: 0.0035618863767012954, Final Batch Loss: 0.0010522218653932214\n",
      "Epoch 827, Loss: 0.003947148681618273, Final Batch Loss: 0.0010226467857137322\n",
      "Epoch 828, Loss: 0.009724839590489864, Final Batch Loss: 0.0082121966406703\n",
      "Epoch 829, Loss: 0.0015447309124283493, Final Batch Loss: 0.0006662974483333528\n",
      "Epoch 830, Loss: 0.004439094569534063, Final Batch Loss: 0.001012203050777316\n",
      "Epoch 831, Loss: 0.0056279238779097795, Final Batch Loss: 0.002976086223497987\n",
      "Epoch 832, Loss: 0.006157101597636938, Final Batch Loss: 0.00015492038801312447\n",
      "Epoch 833, Loss: 0.05408448207890615, Final Batch Loss: 0.05361805856227875\n",
      "Epoch 834, Loss: 0.0025850716629065573, Final Batch Loss: 0.0004392581176944077\n",
      "Epoch 835, Loss: 0.003099258174188435, Final Batch Loss: 0.001929091289639473\n",
      "Epoch 836, Loss: 0.0018861948628909886, Final Batch Loss: 0.0012308441800996661\n",
      "Epoch 837, Loss: 0.004130716202780604, Final Batch Loss: 0.0007843784987926483\n",
      "Epoch 838, Loss: 0.008701706770807505, Final Batch Loss: 0.003510685171931982\n",
      "Epoch 839, Loss: 0.0016895071603357792, Final Batch Loss: 0.0011052152840420604\n",
      "Epoch 840, Loss: 0.0065973830642178655, Final Batch Loss: 0.005350954364985228\n",
      "Epoch 841, Loss: 0.0020939431560691446, Final Batch Loss: 0.000400774268200621\n",
      "Epoch 842, Loss: 0.0005200267187319696, Final Batch Loss: 0.00032365418155677617\n",
      "Epoch 843, Loss: 0.019791628466919065, Final Batch Loss: 0.003458411665633321\n",
      "Epoch 844, Loss: 0.01104068337008357, Final Batch Loss: 0.005635675508528948\n",
      "Epoch 845, Loss: 0.003737877297680825, Final Batch Loss: 0.0005201030871830881\n",
      "Epoch 846, Loss: 0.028937358409166336, Final Batch Loss: 0.012061355635523796\n",
      "Epoch 847, Loss: 0.00483331416035071, Final Batch Loss: 0.004451558459550142\n",
      "Epoch 848, Loss: 0.0011920166434720159, Final Batch Loss: 0.0007253531366586685\n",
      "Epoch 849, Loss: 0.003042501106392592, Final Batch Loss: 0.002234191168099642\n",
      "Epoch 850, Loss: 0.007174485377618112, Final Batch Loss: 0.00702713942155242\n",
      "Epoch 851, Loss: 0.005296938004903495, Final Batch Loss: 0.00024454749654978514\n",
      "Epoch 852, Loss: 0.003894711844623089, Final Batch Loss: 0.0011690324172377586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853, Loss: 0.0030781800160184503, Final Batch Loss: 0.0010637767845764756\n",
      "Epoch 854, Loss: 0.032521229528356344, Final Batch Loss: 0.0001428428222425282\n",
      "Epoch 855, Loss: 0.016988360788673162, Final Batch Loss: 0.010741356760263443\n",
      "Epoch 856, Loss: 0.0023526091827079654, Final Batch Loss: 0.00012214493472129107\n",
      "Epoch 857, Loss: 0.0016121807348099537, Final Batch Loss: 0.00010135386401088908\n",
      "Epoch 858, Loss: 0.0030557732097804546, Final Batch Loss: 0.001058340072631836\n",
      "Epoch 859, Loss: 0.004415416158735752, Final Batch Loss: 0.002128330757841468\n",
      "Epoch 860, Loss: 0.02001892201951705, Final Batch Loss: 0.00042478166869841516\n",
      "Epoch 861, Loss: 0.0009778113017091528, Final Batch Loss: 0.0001882179785752669\n",
      "Epoch 862, Loss: 0.002189322200138122, Final Batch Loss: 0.00016536010662093759\n",
      "Epoch 863, Loss: 0.005272022724966519, Final Batch Loss: 0.00017307027883362025\n",
      "Epoch 864, Loss: 0.003325937082991004, Final Batch Loss: 0.002572719007730484\n",
      "Epoch 865, Loss: 0.012164882384240627, Final Batch Loss: 0.009256522171199322\n",
      "Epoch 866, Loss: 0.004784756165463477, Final Batch Loss: 0.0003421584260649979\n",
      "Epoch 867, Loss: 0.011574480682611465, Final Batch Loss: 0.00955459475517273\n",
      "Epoch 868, Loss: 0.002404771570581943, Final Batch Loss: 0.0005166540504433215\n",
      "Epoch 869, Loss: 0.014419407933019102, Final Batch Loss: 0.0009882947197183967\n",
      "Epoch 870, Loss: 0.0074517878238111734, Final Batch Loss: 0.0004261487629264593\n",
      "Epoch 871, Loss: 0.012272757769096643, Final Batch Loss: 0.01154793705791235\n",
      "Epoch 872, Loss: 0.011753057362511754, Final Batch Loss: 0.010353105142712593\n",
      "Epoch 873, Loss: 0.04129724844824523, Final Batch Loss: 0.0009096217108890414\n",
      "Epoch 874, Loss: 0.012588038574904203, Final Batch Loss: 0.006183501798659563\n",
      "Epoch 875, Loss: 0.0041522253304719925, Final Batch Loss: 0.00111681898124516\n",
      "Epoch 876, Loss: 0.0007027146202744916, Final Batch Loss: 0.000578800798393786\n",
      "Epoch 877, Loss: 0.00215779070276767, Final Batch Loss: 0.0006866059266030788\n",
      "Epoch 878, Loss: 0.005582489771768451, Final Batch Loss: 0.0014599401038140059\n",
      "Epoch 879, Loss: 0.007266024069394916, Final Batch Loss: 0.0009028864442370832\n",
      "Epoch 880, Loss: 0.04762971343006939, Final Batch Loss: 0.04640023410320282\n",
      "Epoch 881, Loss: 0.007292519585462287, Final Batch Loss: 0.00012803057325072587\n",
      "Epoch 882, Loss: 0.003586704027839005, Final Batch Loss: 0.002057026606053114\n",
      "Epoch 883, Loss: 0.0027443666476756334, Final Batch Loss: 0.0017818619962781668\n",
      "Epoch 884, Loss: 0.012725230306386948, Final Batch Loss: 0.005083461292088032\n",
      "Epoch 885, Loss: 0.0013988231803523377, Final Batch Loss: 0.00011810434807557613\n",
      "Epoch 886, Loss: 0.006375196855515242, Final Batch Loss: 0.001124636735767126\n",
      "Epoch 887, Loss: 0.0005311308850650676, Final Batch Loss: 0.00041491849697194993\n",
      "Epoch 888, Loss: 0.0011835126933874562, Final Batch Loss: 0.0010564037365838885\n",
      "Epoch 889, Loss: 0.006027963245287538, Final Batch Loss: 0.0011001366656273603\n",
      "Epoch 890, Loss: 0.005909048253670335, Final Batch Loss: 0.00467030331492424\n",
      "Epoch 891, Loss: 0.011527640112035442, Final Batch Loss: 0.011436223052442074\n",
      "Epoch 892, Loss: 0.00224807218182832, Final Batch Loss: 0.0010620156535878778\n",
      "Epoch 893, Loss: 0.017119726166129112, Final Batch Loss: 0.014398762956261635\n",
      "Epoch 894, Loss: 0.003026694350410253, Final Batch Loss: 0.0001281791483052075\n",
      "Epoch 895, Loss: 0.0013817206781823188, Final Batch Loss: 0.0011184423929080367\n",
      "Epoch 896, Loss: 0.00275029509793967, Final Batch Loss: 0.0010852180421352386\n",
      "Epoch 897, Loss: 0.0009403183066751808, Final Batch Loss: 0.00028432716499082744\n",
      "Epoch 898, Loss: 0.006283630908001214, Final Batch Loss: 0.005666512530297041\n",
      "Epoch 899, Loss: 0.004572024801746011, Final Batch Loss: 0.0005857415962964296\n",
      "Epoch 900, Loss: 0.00787014770321548, Final Batch Loss: 0.004745250567793846\n",
      "Epoch 901, Loss: 0.0015439332491951063, Final Batch Loss: 0.00012548461381811649\n",
      "Epoch 902, Loss: 0.0027414971846155822, Final Batch Loss: 0.002179477596655488\n",
      "Epoch 903, Loss: 0.0015248963245539926, Final Batch Loss: 0.00011743694631149992\n",
      "Epoch 904, Loss: 0.00040156207978725433, Final Batch Loss: 0.00019782205345109105\n",
      "Epoch 905, Loss: 0.0009532763360766694, Final Batch Loss: 0.00012254311877768487\n",
      "Epoch 906, Loss: 0.0016801738529466093, Final Batch Loss: 0.00046757777454331517\n",
      "Epoch 907, Loss: 0.00047042075311765075, Final Batch Loss: 0.00020843089441768825\n",
      "Epoch 908, Loss: 0.002695844857953489, Final Batch Loss: 0.0011321620550006628\n",
      "Epoch 909, Loss: 0.0009063467150554061, Final Batch Loss: 0.0005146582843735814\n",
      "Epoch 910, Loss: 0.03259964272729121, Final Batch Loss: 0.03212287276983261\n",
      "Epoch 911, Loss: 0.0015714524779468775, Final Batch Loss: 0.0012723959516733885\n",
      "Epoch 912, Loss: 0.0012185460072942078, Final Batch Loss: 0.00041044026147574186\n",
      "Epoch 913, Loss: 0.0024247324327006936, Final Batch Loss: 0.0018789327004924417\n",
      "Epoch 914, Loss: 0.002151379594579339, Final Batch Loss: 0.0014242042088881135\n",
      "Epoch 915, Loss: 0.01250966964289546, Final Batch Loss: 0.007731611840426922\n",
      "Epoch 916, Loss: 0.0004880056803813204, Final Batch Loss: 0.00016250192129518837\n",
      "Epoch 917, Loss: 0.002209529106039554, Final Batch Loss: 0.001718010869808495\n",
      "Epoch 918, Loss: 0.006811071711126715, Final Batch Loss: 0.005865687504410744\n",
      "Epoch 919, Loss: 0.000681260775309056, Final Batch Loss: 0.0003702843969222158\n",
      "Epoch 920, Loss: 0.006914232508279383, Final Batch Loss: 0.0019218280212953687\n",
      "Epoch 921, Loss: 0.00792993779759854, Final Batch Loss: 0.0009145158110186458\n",
      "Epoch 922, Loss: 0.0023028681753203273, Final Batch Loss: 0.0012236362090334296\n",
      "Epoch 923, Loss: 0.0019063215149799362, Final Batch Loss: 0.00018099126464221627\n",
      "Epoch 924, Loss: 0.011914579663425684, Final Batch Loss: 0.010723959654569626\n",
      "Epoch 925, Loss: 0.011583420273382217, Final Batch Loss: 0.0008431475725956261\n",
      "Epoch 926, Loss: 0.008008287521079183, Final Batch Loss: 0.005921564064919949\n",
      "Epoch 927, Loss: 0.008951085415901616, Final Batch Loss: 0.008514606393873692\n",
      "Epoch 928, Loss: 0.0012357846135273576, Final Batch Loss: 0.0007035201415419579\n",
      "Epoch 929, Loss: 0.0010263569711241871, Final Batch Loss: 0.00027426399174146354\n",
      "Epoch 930, Loss: 0.002087225904688239, Final Batch Loss: 0.0007880531484261155\n",
      "Epoch 931, Loss: 0.007722087320871651, Final Batch Loss: 0.0018519303994253278\n",
      "Epoch 932, Loss: 0.012519061099737883, Final Batch Loss: 0.007376689929515123\n",
      "Epoch 933, Loss: 0.014177764765918255, Final Batch Loss: 0.012251514941453934\n",
      "Epoch 934, Loss: 0.0010953191085718572, Final Batch Loss: 0.000279761734418571\n",
      "Epoch 935, Loss: 0.0033211555564776063, Final Batch Loss: 0.001983306370675564\n",
      "Epoch 936, Loss: 0.006996181444264948, Final Batch Loss: 0.0006118664750829339\n",
      "Epoch 937, Loss: 0.005386764416471124, Final Batch Loss: 0.004249621648341417\n",
      "Epoch 938, Loss: 0.001352252293145284, Final Batch Loss: 0.00048626321949996054\n",
      "Epoch 939, Loss: 0.0009791701595531777, Final Batch Loss: 0.00015526644710917026\n",
      "Epoch 940, Loss: 0.001060098540619947, Final Batch Loss: 0.00018310071027372032\n",
      "Epoch 941, Loss: 0.007666349527426064, Final Batch Loss: 0.00033618288580328226\n",
      "Epoch 942, Loss: 0.0121276353020221, Final Batch Loss: 0.0002555402461439371\n",
      "Epoch 943, Loss: 0.006352845462970436, Final Batch Loss: 0.0003849201602861285\n",
      "Epoch 944, Loss: 0.0023244011972565204, Final Batch Loss: 0.0004238664696458727\n",
      "Epoch 945, Loss: 0.0014654778642579913, Final Batch Loss: 0.0007012685528025031\n",
      "Epoch 946, Loss: 0.005820752616273239, Final Batch Loss: 0.0003865738690365106\n",
      "Epoch 947, Loss: 0.00265345856314525, Final Batch Loss: 0.0008963868604041636\n",
      "Epoch 948, Loss: 0.03581879351986572, Final Batch Loss: 0.03517018258571625\n",
      "Epoch 949, Loss: 0.010153858980629593, Final Batch Loss: 0.00040682783583179116\n",
      "Epoch 950, Loss: 0.0015647423570044339, Final Batch Loss: 0.0003451423835940659\n",
      "Epoch 951, Loss: 0.00028265611035749316, Final Batch Loss: 0.0001411616540281102\n",
      "Epoch 952, Loss: 0.0008273597049992532, Final Batch Loss: 0.0004995311610400677\n",
      "Epoch 953, Loss: 0.0013840435130987316, Final Batch Loss: 0.0004213765205349773\n",
      "Epoch 954, Loss: 0.0031108252005651593, Final Batch Loss: 0.00044448848348110914\n",
      "Epoch 955, Loss: 0.005643865835736506, Final Batch Loss: 0.00020337225578259677\n",
      "Epoch 956, Loss: 0.0009377553651574999, Final Batch Loss: 8.32937948871404e-05\n",
      "Epoch 957, Loss: 0.011844214983284473, Final Batch Loss: 0.0064816102385520935\n",
      "Epoch 958, Loss: 0.001674430852290243, Final Batch Loss: 0.0008259917376562953\n",
      "Epoch 959, Loss: 0.0010876978049054742, Final Batch Loss: 0.0004198793903924525\n",
      "Epoch 960, Loss: 0.0024759800726315007, Final Batch Loss: 0.0001388116361340508\n",
      "Epoch 961, Loss: 0.016310374718159437, Final Batch Loss: 0.010372024960815907\n",
      "Epoch 962, Loss: 0.000711780390702188, Final Batch Loss: 0.0005503154243342578\n",
      "Epoch 963, Loss: 0.0072632646188139915, Final Batch Loss: 0.002228993922472\n",
      "Epoch 964, Loss: 0.008607240684796125, Final Batch Loss: 0.007880818098783493\n",
      "Epoch 965, Loss: 0.000806108902906999, Final Batch Loss: 0.00022996930056251585\n",
      "Epoch 966, Loss: 0.0018593381682876498, Final Batch Loss: 0.0014125487068668008\n",
      "Epoch 967, Loss: 0.016662947804434225, Final Batch Loss: 0.00036648285458795726\n",
      "Epoch 968, Loss: 0.0025424290797673166, Final Batch Loss: 0.000950074230786413\n",
      "Epoch 969, Loss: 0.001549028791487217, Final Batch Loss: 0.0005768512492068112\n",
      "Epoch 970, Loss: 0.006980933714658022, Final Batch Loss: 0.002379429992288351\n",
      "Epoch 971, Loss: 0.0010298840643372387, Final Batch Loss: 0.0004475229943636805\n",
      "Epoch 972, Loss: 0.007650380808627233, Final Batch Loss: 0.00719287758693099\n",
      "Epoch 973, Loss: 0.0033027678728103638, Final Batch Loss: 0.002436251612380147\n",
      "Epoch 974, Loss: 0.0009718235960463062, Final Batch Loss: 0.00011641120363492519\n",
      "Epoch 975, Loss: 0.0021630757255479693, Final Batch Loss: 0.0014229502994567156\n",
      "Epoch 976, Loss: 0.01035706081893295, Final Batch Loss: 0.009761541150510311\n",
      "Epoch 977, Loss: 0.0016980227082967758, Final Batch Loss: 0.00023654941469430923\n",
      "Epoch 978, Loss: 0.010959208244457841, Final Batch Loss: 0.00015749153681099415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 979, Loss: 0.0018814559443853796, Final Batch Loss: 0.00045568012865260243\n",
      "Epoch 980, Loss: 0.003897717921063304, Final Batch Loss: 0.002313867211341858\n",
      "Epoch 981, Loss: 0.0015710957814007998, Final Batch Loss: 0.00031505594961345196\n",
      "Epoch 982, Loss: 0.0010726418113335967, Final Batch Loss: 0.0007236604578793049\n",
      "Epoch 983, Loss: 0.0006615086167585105, Final Batch Loss: 0.0003533003618940711\n",
      "Epoch 984, Loss: 0.0022912903514225036, Final Batch Loss: 0.001967457588762045\n",
      "Epoch 985, Loss: 0.024824727966915816, Final Batch Loss: 0.000839410990010947\n",
      "Epoch 986, Loss: 0.001338113346719183, Final Batch Loss: 0.001151733915321529\n",
      "Epoch 987, Loss: 0.0014650746015831828, Final Batch Loss: 0.0006228419952094555\n",
      "Epoch 988, Loss: 0.0012179971381556243, Final Batch Loss: 0.0004606762377079576\n",
      "Epoch 989, Loss: 0.00624251170665957, Final Batch Loss: 0.005949047859758139\n",
      "Epoch 990, Loss: 0.0026101473413291387, Final Batch Loss: 0.00010505515820113942\n",
      "Epoch 991, Loss: 0.023045541951432824, Final Batch Loss: 0.022166458889842033\n",
      "Epoch 992, Loss: 0.008195483416784555, Final Batch Loss: 0.0076095107942819595\n",
      "Epoch 993, Loss: 0.008831947081489488, Final Batch Loss: 0.008458041585981846\n",
      "Epoch 994, Loss: 0.001326820463873446, Final Batch Loss: 0.0003974597784690559\n",
      "Epoch 995, Loss: 0.01925791089888662, Final Batch Loss: 0.0005865547573193908\n",
      "Epoch 996, Loss: 0.0008317185856867582, Final Batch Loss: 0.0003524505300447345\n",
      "Epoch 997, Loss: 0.0007995264313649386, Final Batch Loss: 0.00018960892339237034\n",
      "Epoch 998, Loss: 0.002934473450295627, Final Batch Loss: 0.0009831999195739627\n",
      "Epoch 999, Loss: 0.0059604759444482625, Final Batch Loss: 0.0006059653242118657\n",
      "Epoch 1000, Loss: 0.00781229417771101, Final Batch Loss: 0.002254489343613386\n",
      "Epoch 1001, Loss: 0.0012873066298197955, Final Batch Loss: 0.0003860678698401898\n",
      "Epoch 1002, Loss: 0.003234514268115163, Final Batch Loss: 0.0027326359413564205\n",
      "Epoch 1003, Loss: 0.00639680921449326, Final Batch Loss: 0.00017514973296783864\n",
      "Epoch 1004, Loss: 0.0020898755465168506, Final Batch Loss: 0.00040344431181438267\n",
      "Epoch 1005, Loss: 0.003446181188337505, Final Batch Loss: 0.0010922102956101298\n",
      "Epoch 1006, Loss: 0.010615551320370287, Final Batch Loss: 0.009859295561909676\n",
      "Epoch 1007, Loss: 0.001462303742300719, Final Batch Loss: 0.0009915344417095184\n",
      "Epoch 1008, Loss: 0.0018468940979801118, Final Batch Loss: 0.0009860877180472016\n",
      "Epoch 1009, Loss: 0.0009001300495583564, Final Batch Loss: 0.00033711831201799214\n",
      "Epoch 1010, Loss: 0.00784732194733806, Final Batch Loss: 0.00019577218336053193\n",
      "Epoch 1011, Loss: 0.001321315547102131, Final Batch Loss: 0.00012013713421765715\n",
      "Epoch 1012, Loss: 0.0033808416919782758, Final Batch Loss: 0.0004977696808055043\n",
      "Epoch 1013, Loss: 0.0003444170215516351, Final Batch Loss: 5.1965842430945486e-05\n",
      "Epoch 1014, Loss: 0.003239444806240499, Final Batch Loss: 0.0006334075005725026\n",
      "Epoch 1015, Loss: 0.0008062127453740686, Final Batch Loss: 0.00023004130343906581\n",
      "Epoch 1016, Loss: 0.002078536927001551, Final Batch Loss: 0.0004511968290898949\n",
      "Epoch 1017, Loss: 0.003266232437454164, Final Batch Loss: 0.0014600838767364621\n",
      "Epoch 1018, Loss: 0.009659827221184969, Final Batch Loss: 0.002181051764637232\n",
      "Epoch 1019, Loss: 0.003783428925089538, Final Batch Loss: 0.0024662779178470373\n",
      "Epoch 1020, Loss: 0.0009153752180282027, Final Batch Loss: 0.00014868340804241598\n",
      "Epoch 1021, Loss: 0.002303744142409414, Final Batch Loss: 0.001694327569566667\n",
      "Epoch 1022, Loss: 0.002614353725221008, Final Batch Loss: 0.0022523861844092607\n",
      "Epoch 1023, Loss: 0.005521971266716719, Final Batch Loss: 0.0014157560653984547\n",
      "Epoch 1024, Loss: 0.0021186285885050893, Final Batch Loss: 0.0014912212500348687\n",
      "Epoch 1025, Loss: 0.0018471545627107844, Final Batch Loss: 0.00015952553076203912\n",
      "Epoch 1026, Loss: 0.0004826324147870764, Final Batch Loss: 0.0002784708049148321\n",
      "Epoch 1027, Loss: 0.002196176501456648, Final Batch Loss: 0.0008692448609508574\n",
      "Epoch 1028, Loss: 0.004545693198451772, Final Batch Loss: 0.00037282929406501353\n",
      "Epoch 1029, Loss: 0.005410281621152535, Final Batch Loss: 0.005124413874000311\n",
      "Epoch 1030, Loss: 0.0025858156150206923, Final Batch Loss: 0.0018750777235254645\n",
      "Epoch 1031, Loss: 0.0016234490904025733, Final Batch Loss: 0.0008601914742030203\n",
      "Epoch 1032, Loss: 0.0034213101607747376, Final Batch Loss: 0.00285160169005394\n",
      "Epoch 1033, Loss: 0.00028367173217702657, Final Batch Loss: 0.00014400678628589958\n",
      "Epoch 1034, Loss: 0.0032597603130852804, Final Batch Loss: 0.00022603546676691622\n",
      "Epoch 1035, Loss: 0.0011275810829829425, Final Batch Loss: 0.0007632551714777946\n",
      "Epoch 1036, Loss: 0.007460871187504381, Final Batch Loss: 0.0003669517464004457\n",
      "Epoch 1037, Loss: 0.014754251722479239, Final Batch Loss: 0.00016553341993130744\n",
      "Epoch 1038, Loss: 0.0007480993517674506, Final Batch Loss: 0.00020805076928809285\n",
      "Epoch 1039, Loss: 0.0005292203895805869, Final Batch Loss: 3.0638595490017906e-05\n",
      "Epoch 1040, Loss: 0.006096080760471523, Final Batch Loss: 0.0013101109070703387\n",
      "Epoch 1041, Loss: 0.009514086996205151, Final Batch Loss: 0.009094180539250374\n",
      "Epoch 1042, Loss: 0.006269935285672545, Final Batch Loss: 0.001587744103744626\n",
      "Epoch 1043, Loss: 0.001520034100394696, Final Batch Loss: 0.00033662159694358706\n",
      "Epoch 1044, Loss: 0.000566078131669201, Final Batch Loss: 8.627188799437135e-05\n",
      "Epoch 1045, Loss: 0.009953928645700216, Final Batch Loss: 0.0070678540505468845\n",
      "Epoch 1046, Loss: 0.0003918908623745665, Final Batch Loss: 0.00026432835147716105\n",
      "Epoch 1047, Loss: 0.008304144022986293, Final Batch Loss: 0.007633158005774021\n",
      "Epoch 1048, Loss: 0.002017814025748521, Final Batch Loss: 0.00039359700167551637\n",
      "Epoch 1049, Loss: 0.000485686534375418, Final Batch Loss: 0.00011360034841345623\n",
      "Epoch 1050, Loss: 0.0006542008341057226, Final Batch Loss: 0.0001232707145391032\n",
      "Epoch 1051, Loss: 0.0017513197963126004, Final Batch Loss: 2.8789450880140066e-05\n",
      "Epoch 1052, Loss: 0.0015599164180457592, Final Batch Loss: 8.921511471271515e-05\n",
      "Epoch 1053, Loss: 0.0008107919857138768, Final Batch Loss: 0.0001536799973109737\n",
      "Epoch 1054, Loss: 0.0009100520401261747, Final Batch Loss: 0.00034966052044183016\n",
      "Epoch 1055, Loss: 0.0020146261958871037, Final Batch Loss: 0.0004064539971295744\n",
      "Epoch 1056, Loss: 0.0028341421857476234, Final Batch Loss: 0.0013791443780064583\n",
      "Epoch 1057, Loss: 0.0002699277247302234, Final Batch Loss: 0.00015927935601212084\n",
      "Epoch 1058, Loss: 0.0008105786982923746, Final Batch Loss: 0.00047091738088056445\n",
      "Epoch 1059, Loss: 0.007333833840675652, Final Batch Loss: 0.006311249919235706\n",
      "Epoch 1060, Loss: 0.0020638674031943083, Final Batch Loss: 0.001209551701322198\n",
      "Epoch 1061, Loss: 0.0022013497437001206, Final Batch Loss: 8.265747601399198e-05\n",
      "Epoch 1062, Loss: 0.00044852208520751446, Final Batch Loss: 0.0002041830593952909\n",
      "Epoch 1063, Loss: 0.05695630703121424, Final Batch Loss: 0.05156823620200157\n",
      "Epoch 1064, Loss: 0.0014078799649723805, Final Batch Loss: 0.0013242003042250872\n",
      "Epoch 1065, Loss: 0.0013765394978690892, Final Batch Loss: 0.0004088111745659262\n",
      "Epoch 1066, Loss: 0.0011262683547101915, Final Batch Loss: 0.0007004206418059766\n",
      "Epoch 1067, Loss: 0.0063112141797319055, Final Batch Loss: 0.00133191526401788\n",
      "Epoch 1068, Loss: 0.003827541950158775, Final Batch Loss: 0.0010222502751275897\n",
      "Epoch 1069, Loss: 0.0011447707074694335, Final Batch Loss: 0.000546217430382967\n",
      "Epoch 1070, Loss: 0.007750869175652042, Final Batch Loss: 0.007358169183135033\n",
      "Epoch 1071, Loss: 0.0016816210700199008, Final Batch Loss: 0.0011780427303165197\n",
      "Epoch 1072, Loss: 0.001769642265571747, Final Batch Loss: 0.00011714563152054325\n",
      "Epoch 1073, Loss: 0.0018405464652460068, Final Batch Loss: 0.0015767813893035054\n",
      "Epoch 1074, Loss: 0.003794602700509131, Final Batch Loss: 0.0021436684764921665\n",
      "Epoch 1075, Loss: 0.0007685238379053771, Final Batch Loss: 0.00026829802663996816\n",
      "Epoch 1076, Loss: 0.0010547892597969621, Final Batch Loss: 0.0005996939726173878\n",
      "Epoch 1077, Loss: 0.00089456228306517, Final Batch Loss: 0.00031616404885426164\n",
      "Epoch 1078, Loss: 0.0012657443876378238, Final Batch Loss: 0.0009551435359753668\n",
      "Epoch 1079, Loss: 0.0016625142598059028, Final Batch Loss: 0.0011768542462959886\n",
      "Epoch 1080, Loss: 0.0010525441612116992, Final Batch Loss: 0.0005378503119572997\n",
      "Epoch 1081, Loss: 0.002249012228276115, Final Batch Loss: 0.002136471215635538\n",
      "Epoch 1082, Loss: 0.0020570727647282183, Final Batch Loss: 0.0012713384348899126\n",
      "Epoch 1083, Loss: 0.0008254748427134473, Final Batch Loss: 4.177085429546423e-05\n",
      "Epoch 1084, Loss: 0.0007136217755032703, Final Batch Loss: 0.00015925725165288895\n",
      "Epoch 1085, Loss: 0.004099237426999025, Final Batch Loss: 0.00015069979417603463\n",
      "Epoch 1086, Loss: 0.0007586460706079379, Final Batch Loss: 8.372981392312795e-05\n",
      "Epoch 1087, Loss: 0.00022150679069454782, Final Batch Loss: 4.717138290288858e-05\n",
      "Epoch 1088, Loss: 0.0008296681335195899, Final Batch Loss: 0.00032090931199491024\n",
      "Epoch 1089, Loss: 0.0022539073834195733, Final Batch Loss: 0.0016590692102909088\n",
      "Epoch 1090, Loss: 0.0028594581817742437, Final Batch Loss: 0.00018405154696665704\n",
      "Epoch 1091, Loss: 0.0011118000984424725, Final Batch Loss: 0.0009225436369888484\n",
      "Epoch 1092, Loss: 0.0003725516580743715, Final Batch Loss: 0.00012798326497431844\n",
      "Epoch 1093, Loss: 0.0007570111192762852, Final Batch Loss: 0.00024382199626415968\n",
      "Epoch 1094, Loss: 0.0002352280935156159, Final Batch Loss: 4.63188553112559e-05\n",
      "Epoch 1095, Loss: 0.0012973055127076805, Final Batch Loss: 0.0005297104362398386\n",
      "Epoch 1096, Loss: 0.001930625323439017, Final Batch Loss: 0.0017988280160352588\n",
      "Epoch 1097, Loss: 0.030617179931141436, Final Batch Loss: 0.029399018734693527\n",
      "Epoch 1098, Loss: 0.014987857459345832, Final Batch Loss: 0.00010472667054273188\n",
      "Epoch 1099, Loss: 0.0007275093666976318, Final Batch Loss: 0.00017840111104305834\n",
      "Epoch 1100, Loss: 0.0012581702903844416, Final Batch Loss: 0.00044317933497950435\n",
      "Epoch 1101, Loss: 0.0230216943891719, Final Batch Loss: 0.02257789671421051\n",
      "Epoch 1102, Loss: 0.017684228900179733, Final Batch Loss: 6.387028406606987e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1103, Loss: 0.0019196918874513358, Final Batch Loss: 0.0003549221146386117\n",
      "Epoch 1104, Loss: 0.0005492515920195729, Final Batch Loss: 0.00020248882356099784\n",
      "Epoch 1105, Loss: 0.0017601492581889033, Final Batch Loss: 0.00033563736360520124\n",
      "Epoch 1106, Loss: 0.0015001168649177998, Final Batch Loss: 0.00030316339689306915\n",
      "Epoch 1107, Loss: 0.0033690661657601595, Final Batch Loss: 0.002563853980973363\n",
      "Epoch 1108, Loss: 0.0009672827291069552, Final Batch Loss: 0.00011240957246627659\n",
      "Epoch 1109, Loss: 0.0010377666039858013, Final Batch Loss: 0.00048000665265135467\n",
      "Epoch 1110, Loss: 0.003058705653529614, Final Batch Loss: 0.0022407849319279194\n",
      "Epoch 1111, Loss: 0.00361273463931866, Final Batch Loss: 0.00015288221766240895\n",
      "Epoch 1112, Loss: 0.0009710883896332234, Final Batch Loss: 0.00047336900024674833\n",
      "Epoch 1113, Loss: 0.003350756800500676, Final Batch Loss: 0.002976119751110673\n",
      "Epoch 1114, Loss: 0.0008354692836292088, Final Batch Loss: 0.0003134470316581428\n",
      "Epoch 1115, Loss: 0.007881163823185489, Final Batch Loss: 0.007506422698497772\n",
      "Epoch 1116, Loss: 0.00018938645007438026, Final Batch Loss: 3.221058796043508e-05\n",
      "Epoch 1117, Loss: 0.0010250577179249376, Final Batch Loss: 0.0001428884279448539\n",
      "Epoch 1118, Loss: 0.001219289202708751, Final Batch Loss: 0.0009262673556804657\n",
      "Epoch 1119, Loss: 0.0006831621285527945, Final Batch Loss: 0.000244696595473215\n",
      "Epoch 1120, Loss: 0.011072875466197729, Final Batch Loss: 0.0038439296185970306\n",
      "Epoch 1121, Loss: 0.0014411936281248927, Final Batch Loss: 0.0009031991939991713\n",
      "Epoch 1122, Loss: 0.009014235343784094, Final Batch Loss: 0.0012450404465198517\n",
      "Epoch 1123, Loss: 0.004685529100243002, Final Batch Loss: 0.0004153196350671351\n",
      "Epoch 1124, Loss: 0.0012092961987946182, Final Batch Loss: 0.0009540814207866788\n",
      "Epoch 1125, Loss: 0.0012168123939773068, Final Batch Loss: 0.0001622168201720342\n",
      "Epoch 1126, Loss: 0.0011515164951561019, Final Batch Loss: 0.0002328419213881716\n",
      "Epoch 1127, Loss: 0.0013598026125691831, Final Batch Loss: 0.0011729426914826035\n",
      "Epoch 1128, Loss: 0.007440578410751186, Final Batch Loss: 0.007420138921588659\n",
      "Epoch 1129, Loss: 0.00212335487594828, Final Batch Loss: 0.00021672010188922286\n",
      "Epoch 1130, Loss: 0.00021324014232959598, Final Batch Loss: 2.7215020963922143e-05\n",
      "Epoch 1131, Loss: 0.008013843966182321, Final Batch Loss: 0.0007155490457080305\n",
      "Epoch 1132, Loss: 0.0019086466672888491, Final Batch Loss: 5.0455917516956106e-05\n",
      "Epoch 1133, Loss: 0.002290095391799696, Final Batch Loss: 0.00017647370987106115\n",
      "Epoch 1134, Loss: 0.0001972864192794077, Final Batch Loss: 3.2699092116672546e-05\n",
      "Epoch 1135, Loss: 0.0004143762052990496, Final Batch Loss: 0.0002666273503564298\n",
      "Epoch 1136, Loss: 0.000875271245604381, Final Batch Loss: 0.0005466949078254402\n",
      "Epoch 1137, Loss: 0.0041302494937554, Final Batch Loss: 0.00014343729708343744\n",
      "Epoch 1138, Loss: 0.00046002058661542833, Final Batch Loss: 0.00020440801745280623\n",
      "Epoch 1139, Loss: 0.003052057189051993, Final Batch Loss: 0.0001854716829257086\n",
      "Epoch 1140, Loss: 0.006637295708060265, Final Batch Loss: 0.0020903670229017735\n",
      "Epoch 1141, Loss: 0.0006002352747600526, Final Batch Loss: 0.0002934723161160946\n",
      "Epoch 1142, Loss: 0.01395904365926981, Final Batch Loss: 0.001847938634455204\n",
      "Epoch 1143, Loss: 0.007852306312997825, Final Batch Loss: 0.00760918203741312\n",
      "Epoch 1144, Loss: 0.001649234676733613, Final Batch Loss: 0.0014852070016786456\n",
      "Epoch 1145, Loss: 0.0008669175731483847, Final Batch Loss: 0.0004937941557727754\n",
      "Epoch 1146, Loss: 0.0009232127122231759, Final Batch Loss: 1.9434468413237482e-05\n",
      "Epoch 1147, Loss: 0.00646246672840789, Final Batch Loss: 0.005793438293039799\n",
      "Epoch 1148, Loss: 0.01120974076911807, Final Batch Loss: 0.00901707261800766\n",
      "Epoch 1149, Loss: 0.0008963633154053241, Final Batch Loss: 0.00028733935323543847\n",
      "Epoch 1150, Loss: 0.0063827526464592665, Final Batch Loss: 0.005995516665279865\n",
      "Epoch 1151, Loss: 0.00043768053728854284, Final Batch Loss: 0.0004148827283643186\n",
      "Epoch 1152, Loss: 0.005373465159209445, Final Batch Loss: 0.00013169486192055047\n",
      "Epoch 1153, Loss: 0.0013222414563642815, Final Batch Loss: 7.362193719018251e-05\n",
      "Epoch 1154, Loss: 0.000726717000361532, Final Batch Loss: 0.0003896215930581093\n",
      "Epoch 1155, Loss: 0.019708871841430664, Final Batch Loss: 0.009306570515036583\n",
      "Epoch 1156, Loss: 0.0010503074736334383, Final Batch Loss: 0.0002479501417838037\n",
      "Epoch 1157, Loss: 0.0002621487947180867, Final Batch Loss: 0.00013821768516208977\n",
      "Epoch 1158, Loss: 0.012897889653686434, Final Batch Loss: 0.012148846872150898\n",
      "Epoch 1159, Loss: 0.021421171724796295, Final Batch Loss: 0.010298366658389568\n",
      "Epoch 1160, Loss: 0.0005175342812435701, Final Batch Loss: 0.0001395375729771331\n",
      "Epoch 1161, Loss: 0.00033187935332534835, Final Batch Loss: 8.481079566990957e-05\n",
      "Epoch 1162, Loss: 0.010315512539818883, Final Batch Loss: 0.0012903113383799791\n",
      "Epoch 1163, Loss: 0.004112850612727925, Final Batch Loss: 6.446029874496162e-05\n",
      "Epoch 1164, Loss: 0.0025759401032701135, Final Batch Loss: 0.00054307805839926\n",
      "Epoch 1165, Loss: 0.00242831654031761, Final Batch Loss: 0.00028525901143439114\n",
      "Epoch 1166, Loss: 0.0017496257787570357, Final Batch Loss: 0.0009850269416347146\n",
      "Epoch 1167, Loss: 0.005279219476506114, Final Batch Loss: 0.0014329918194562197\n",
      "Epoch 1168, Loss: 0.0005970681231701747, Final Batch Loss: 0.0004500811919569969\n",
      "Epoch 1169, Loss: 0.0002695043076528236, Final Batch Loss: 0.00015961566532496363\n",
      "Epoch 1170, Loss: 0.0020172292715869844, Final Batch Loss: 0.0013146406272426248\n",
      "Epoch 1171, Loss: 0.0011787253024522215, Final Batch Loss: 0.0009538152953609824\n",
      "Epoch 1172, Loss: 0.00048239727038890123, Final Batch Loss: 0.00022062045172788203\n",
      "Epoch 1173, Loss: 0.004049679424497299, Final Batch Loss: 7.438535976689309e-05\n",
      "Epoch 1174, Loss: 0.000783152470830828, Final Batch Loss: 0.0004632369673345238\n",
      "Epoch 1175, Loss: 0.006308173542493023, Final Batch Loss: 6.705826672259718e-05\n",
      "Epoch 1176, Loss: 0.0033915727690327913, Final Batch Loss: 3.6661309422925115e-05\n",
      "Epoch 1177, Loss: 0.0023730333195999265, Final Batch Loss: 0.0005208679940551519\n",
      "Epoch 1178, Loss: 0.0040214819309767336, Final Batch Loss: 0.000426798447733745\n",
      "Epoch 1179, Loss: 0.015598897938616574, Final Batch Loss: 0.01396264135837555\n",
      "Epoch 1180, Loss: 0.004601059219567105, Final Batch Loss: 0.00020201478037051857\n",
      "Epoch 1181, Loss: 0.011515664111357182, Final Batch Loss: 0.01073534693568945\n",
      "Epoch 1182, Loss: 0.0003226807093597017, Final Batch Loss: 0.00024174823192879558\n",
      "Epoch 1183, Loss: 0.0129080644401256, Final Batch Loss: 0.01244503166526556\n",
      "Epoch 1184, Loss: 0.0023973078350536525, Final Batch Loss: 0.0006158598116599023\n",
      "Epoch 1185, Loss: 0.005920551833696663, Final Batch Loss: 0.0014969456242397428\n",
      "Epoch 1186, Loss: 0.0021105515770614147, Final Batch Loss: 0.0014427333371713758\n",
      "Epoch 1187, Loss: 0.0011061785626225173, Final Batch Loss: 0.0004352194373495877\n",
      "Epoch 1188, Loss: 0.0005102333379909396, Final Batch Loss: 0.0002241549373138696\n",
      "Epoch 1189, Loss: 0.001247006410267204, Final Batch Loss: 0.00020217656856402755\n",
      "Epoch 1190, Loss: 0.005427750220405869, Final Batch Loss: 0.0001508760469732806\n",
      "Epoch 1191, Loss: 0.0006502658652607352, Final Batch Loss: 8.386714034713805e-05\n",
      "Epoch 1192, Loss: 0.001294632107601501, Final Batch Loss: 0.00016564784164074808\n",
      "Epoch 1193, Loss: 0.00031227886211127043, Final Batch Loss: 0.00018395432562101632\n",
      "Epoch 1194, Loss: 0.0005919467657804489, Final Batch Loss: 0.000346658838680014\n",
      "Epoch 1195, Loss: 0.0008901558467186987, Final Batch Loss: 0.0006391165079548955\n",
      "Epoch 1196, Loss: 0.006093427655287087, Final Batch Loss: 0.0005448973970487714\n",
      "Epoch 1197, Loss: 0.0003579513286240399, Final Batch Loss: 0.0002443506964482367\n",
      "Epoch 1198, Loss: 0.005463217707074364, Final Batch Loss: 0.005436436738818884\n",
      "Epoch 1199, Loss: 0.002338749181944877, Final Batch Loss: 0.0007218232494778931\n",
      "Epoch 1200, Loss: 0.0006010558863636106, Final Batch Loss: 0.000260903820162639\n",
      "Epoch 1201, Loss: 0.0015974809357430786, Final Batch Loss: 0.0013245019363239408\n",
      "Epoch 1202, Loss: 0.00022508313122671098, Final Batch Loss: 5.6373304687440395e-05\n",
      "Epoch 1203, Loss: 0.000297987055091653, Final Batch Loss: 3.128374373773113e-05\n",
      "Epoch 1204, Loss: 0.001144327048677951, Final Batch Loss: 0.0003223500680178404\n",
      "Epoch 1205, Loss: 0.0009099626622628421, Final Batch Loss: 0.0005040358519181609\n",
      "Epoch 1206, Loss: 0.005423892929684371, Final Batch Loss: 0.0006740798125974834\n",
      "Epoch 1207, Loss: 0.010361884313169867, Final Batch Loss: 0.009528891183435917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1208, Loss: 0.007131877835490741, Final Batch Loss: 0.006908863317221403\n",
      "Epoch 1209, Loss: 0.01347645788337104, Final Batch Loss: 0.01307619083672762\n",
      "Epoch 1210, Loss: 0.0009895435359794647, Final Batch Loss: 0.0003924744378309697\n",
      "Epoch 1211, Loss: 0.0003285597267677076, Final Batch Loss: 3.5292185202706605e-05\n",
      "Epoch 1212, Loss: 0.0010479541961103678, Final Batch Loss: 0.0007531499722972512\n",
      "Epoch 1213, Loss: 0.00035178116377210245, Final Batch Loss: 8.420753147220239e-05\n",
      "Epoch 1214, Loss: 0.0011917176452698186, Final Batch Loss: 0.0009798618266358972\n",
      "Epoch 1215, Loss: 0.006423534592613578, Final Batch Loss: 0.0015748220030218363\n",
      "Epoch 1216, Loss: 0.0002973194787045941, Final Batch Loss: 0.00010804692283272743\n",
      "Epoch 1217, Loss: 0.0017562765278853476, Final Batch Loss: 0.0006651267758570611\n",
      "Epoch 1218, Loss: 0.0020983082067687064, Final Batch Loss: 0.0017279303865507245\n",
      "Epoch 1219, Loss: 0.00876661587972194, Final Batch Loss: 0.008155867457389832\n",
      "Epoch 1220, Loss: 0.0019217533408664167, Final Batch Loss: 0.0009729305165819824\n",
      "Epoch 1221, Loss: 0.005641811942041386, Final Batch Loss: 0.00011224760237382725\n",
      "Epoch 1222, Loss: 0.00723049294174416, Final Batch Loss: 0.007120136637240648\n",
      "Epoch 1223, Loss: 0.0005384242631407687, Final Batch Loss: 2.6581366910249926e-05\n",
      "Epoch 1224, Loss: 0.001086547039449215, Final Batch Loss: 0.00025693996576592326\n",
      "Epoch 1225, Loss: 0.0051392094101174735, Final Batch Loss: 6.184362428029999e-05\n",
      "Epoch 1226, Loss: 0.005218078440520912, Final Batch Loss: 0.0002964991726912558\n",
      "Epoch 1227, Loss: 0.009164390619844198, Final Batch Loss: 0.008664545603096485\n",
      "Epoch 1228, Loss: 0.004440496755705681, Final Batch Loss: 0.004405929706990719\n",
      "Epoch 1229, Loss: 0.0021647946487064473, Final Batch Loss: 6.58936842228286e-05\n",
      "Epoch 1230, Loss: 0.004773718494107015, Final Batch Loss: 8.674310811329633e-05\n",
      "Epoch 1231, Loss: 0.000154580244270619, Final Batch Loss: 2.573275560280308e-05\n",
      "Epoch 1232, Loss: 0.0012871892540715635, Final Batch Loss: 0.0005587177001871169\n",
      "Epoch 1233, Loss: 0.0014158990161377005, Final Batch Loss: 0.0013266070745885372\n",
      "Epoch 1234, Loss: 0.00023425056133419275, Final Batch Loss: 0.00013702652358915657\n",
      "Epoch 1235, Loss: 0.0032598020043224096, Final Batch Loss: 0.0019393074326217175\n",
      "Epoch 1236, Loss: 0.0006368620233843103, Final Batch Loss: 0.0004216862143948674\n",
      "Epoch 1237, Loss: 0.0010094220488099381, Final Batch Loss: 0.0002409026346867904\n",
      "Epoch 1238, Loss: 0.0010008846875280142, Final Batch Loss: 0.0008631204254925251\n",
      "Epoch 1239, Loss: 0.00012940060150867794, Final Batch Loss: 2.0338246031315066e-05\n",
      "Epoch 1240, Loss: 6.21296730969334e-05, Final Batch Loss: 1.184628672490362e-05\n",
      "Epoch 1241, Loss: 0.008878726890543476, Final Batch Loss: 0.008440890349447727\n",
      "Epoch 1242, Loss: 0.0005025702666898724, Final Batch Loss: 5.542975486605428e-05\n",
      "Epoch 1243, Loss: 0.000749595565139316, Final Batch Loss: 0.00015334085037466139\n",
      "Epoch 1244, Loss: 0.0008730182744329795, Final Batch Loss: 0.00011658253788482398\n",
      "Epoch 1245, Loss: 0.0032197213731706142, Final Batch Loss: 0.0012705883709713817\n",
      "Epoch 1246, Loss: 0.0003020540389115922, Final Batch Loss: 0.00018801195255946368\n",
      "Epoch 1247, Loss: 0.000665854720864445, Final Batch Loss: 0.0005056395311839879\n",
      "Epoch 1248, Loss: 0.0010474944137968123, Final Batch Loss: 0.0007610393804498017\n",
      "Epoch 1249, Loss: 0.00039840432509663515, Final Batch Loss: 1.3733351806877181e-05\n",
      "Epoch 1250, Loss: 0.005683485767804086, Final Batch Loss: 0.00012567394878715277\n",
      "Epoch 1251, Loss: 0.0005726031813537702, Final Batch Loss: 0.00043406564509496093\n",
      "Epoch 1252, Loss: 0.001366079755825922, Final Batch Loss: 0.0010266528697684407\n",
      "Epoch 1253, Loss: 0.0005386386110330932, Final Batch Loss: 8.053131023189053e-05\n",
      "Epoch 1254, Loss: 0.0018486803746782243, Final Batch Loss: 0.0001622209674678743\n",
      "Epoch 1255, Loss: 0.00340812861759332, Final Batch Loss: 5.496641460922547e-05\n",
      "Epoch 1256, Loss: 0.0005095997839816846, Final Batch Loss: 7.104723044903949e-05\n",
      "Epoch 1257, Loss: 0.003715711172844749, Final Batch Loss: 4.118633660255e-05\n",
      "Epoch 1258, Loss: 0.001056766981491819, Final Batch Loss: 0.0003907197096850723\n",
      "Epoch 1259, Loss: 0.0017067836015485227, Final Batch Loss: 0.0009198659681715071\n",
      "Epoch 1260, Loss: 0.0006030546428519301, Final Batch Loss: 4.69693259219639e-05\n",
      "Epoch 1261, Loss: 0.0011909435561392456, Final Batch Loss: 0.00028341860161162913\n",
      "Epoch 1262, Loss: 0.0008371610892936587, Final Batch Loss: 0.0004037695180159062\n",
      "Epoch 1263, Loss: 0.002556056613684632, Final Batch Loss: 0.0023239445872604847\n",
      "Epoch 1264, Loss: 0.003094509716902394, Final Batch Loss: 0.0029858918860554695\n",
      "Epoch 1265, Loss: 0.0004000886110588908, Final Batch Loss: 0.00015281143714673817\n",
      "Epoch 1266, Loss: 0.00042422387923579663, Final Batch Loss: 0.00022067541431169957\n",
      "Epoch 1267, Loss: 0.0005977668770356104, Final Batch Loss: 0.00016937586769927293\n",
      "Epoch 1268, Loss: 0.0010481864446774125, Final Batch Loss: 0.0005583147285506129\n",
      "Epoch 1269, Loss: 0.0007529849535785615, Final Batch Loss: 0.0005268738605082035\n",
      "Epoch 1270, Loss: 0.004253042512573302, Final Batch Loss: 0.002518458291888237\n",
      "Epoch 1271, Loss: 0.0003108314995188266, Final Batch Loss: 0.00013918847253080457\n",
      "Epoch 1272, Loss: 0.00048764112580101937, Final Batch Loss: 0.0003639076021499932\n",
      "Epoch 1273, Loss: 0.0008506629383191466, Final Batch Loss: 0.0003125258954241872\n",
      "Epoch 1274, Loss: 0.006767599959857762, Final Batch Loss: 0.0006155200535431504\n",
      "Epoch 1275, Loss: 0.0042592062236508355, Final Batch Loss: 0.0001489993737777695\n",
      "Epoch 1276, Loss: 0.00031966942697181366, Final Batch Loss: 0.00026245505432598293\n",
      "Epoch 1277, Loss: 0.0009798034116101917, Final Batch Loss: 4.956274278811179e-05\n",
      "Epoch 1278, Loss: 0.0017473490734118968, Final Batch Loss: 0.001589959836564958\n",
      "Epoch 1279, Loss: 0.0014903804985806346, Final Batch Loss: 5.845446139574051e-05\n",
      "Epoch 1280, Loss: 0.005447154500870965, Final Batch Loss: 0.00017897422367241234\n",
      "Epoch 1281, Loss: 0.0006964285566937178, Final Batch Loss: 0.0003957184962928295\n",
      "Epoch 1282, Loss: 0.0015569727984257042, Final Batch Loss: 0.0002479574759490788\n",
      "Epoch 1283, Loss: 0.0025371418087161146, Final Batch Loss: 0.0024553516414016485\n",
      "Epoch 1284, Loss: 0.0003874277954309946, Final Batch Loss: 1.574370799062308e-05\n",
      "Epoch 1285, Loss: 0.00022151351004140452, Final Batch Loss: 0.0001105578921851702\n",
      "Epoch 1286, Loss: 0.003483297099592164, Final Batch Loss: 7.547184941358864e-05\n",
      "Epoch 1287, Loss: 0.008735349401831627, Final Batch Loss: 0.007600206416100264\n",
      "Epoch 1288, Loss: 0.006692926166579127, Final Batch Loss: 0.0005170411895960569\n",
      "Epoch 1289, Loss: 0.02034568804083392, Final Batch Loss: 0.0200961884111166\n",
      "Epoch 1290, Loss: 0.00039844382263254374, Final Batch Loss: 0.00012106263602618128\n",
      "Epoch 1291, Loss: 0.0008910731921787374, Final Batch Loss: 0.00010981526429532096\n",
      "Epoch 1292, Loss: 0.001544213097076863, Final Batch Loss: 0.0007056210306473076\n",
      "Epoch 1293, Loss: 0.005625691846944392, Final Batch Loss: 0.0007374646374955773\n",
      "Epoch 1294, Loss: 0.00023339638482866576, Final Batch Loss: 1.5058590179251041e-05\n",
      "Epoch 1295, Loss: 0.00043449513032101095, Final Batch Loss: 0.0003408965712878853\n",
      "Epoch 1296, Loss: 0.005554530740482733, Final Batch Loss: 0.0004135612107347697\n",
      "Epoch 1297, Loss: 0.06068697338923812, Final Batch Loss: 0.05579841881990433\n",
      "Epoch 1298, Loss: 0.0033531416120240465, Final Batch Loss: 0.00016850967949721962\n",
      "Epoch 1299, Loss: 0.0006935566125321202, Final Batch Loss: 0.00060486258007586\n",
      "Epoch 1300, Loss: 0.0007933961460366845, Final Batch Loss: 0.0004421378253027797\n",
      "Epoch 1301, Loss: 0.002808820514474064, Final Batch Loss: 0.0022631047759205103\n",
      "Epoch 1302, Loss: 0.020270018838346004, Final Batch Loss: 0.0032115140929818153\n",
      "Epoch 1303, Loss: 0.000740561808925122, Final Batch Loss: 0.00027123524341732264\n",
      "Epoch 1304, Loss: 0.008500541393004823, Final Batch Loss: 0.008445383980870247\n",
      "Epoch 1305, Loss: 0.0027139902813360095, Final Batch Loss: 0.00017004890833050013\n",
      "Epoch 1306, Loss: 0.003354554486577399, Final Batch Loss: 0.0033069057390093803\n",
      "Epoch 1307, Loss: 0.0009737829386722296, Final Batch Loss: 0.0003563207865227014\n",
      "Epoch 1308, Loss: 0.0007886720995884389, Final Batch Loss: 0.0004996586940251291\n",
      "Epoch 1309, Loss: 0.0006242334638955072, Final Batch Loss: 7.399068272206932e-05\n",
      "Epoch 1310, Loss: 0.00036207483208272606, Final Batch Loss: 0.00012440122372936457\n",
      "Epoch 1311, Loss: 0.0017136566602857783, Final Batch Loss: 7.619820826221257e-05\n",
      "Epoch 1312, Loss: 0.0013496935716830194, Final Batch Loss: 0.0009694063337519765\n",
      "Epoch 1313, Loss: 0.009380585001053987, Final Batch Loss: 5.538430923479609e-05\n",
      "Epoch 1314, Loss: 0.0019177062786184251, Final Batch Loss: 0.0015610083937644958\n",
      "Epoch 1315, Loss: 0.0006816407403675839, Final Batch Loss: 0.0005334272282198071\n",
      "Epoch 1316, Loss: 0.030528439616318792, Final Batch Loss: 0.0006379377446137369\n",
      "Epoch 1317, Loss: 0.0029418474878184497, Final Batch Loss: 0.00016415322897955775\n",
      "Epoch 1318, Loss: 0.0010849912359844893, Final Batch Loss: 0.0006765660946257412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1319, Loss: 0.0004009996191598475, Final Batch Loss: 0.00012799585238099098\n",
      "Epoch 1320, Loss: 0.0007266213942784816, Final Batch Loss: 0.00027355935890227556\n",
      "Epoch 1321, Loss: 0.00234801014084951, Final Batch Loss: 2.3524688003817573e-05\n",
      "Epoch 1322, Loss: 0.0008728145767236128, Final Batch Loss: 7.179025851655751e-05\n",
      "Epoch 1323, Loss: 0.004653035168303177, Final Batch Loss: 0.00048567072371952236\n",
      "Epoch 1324, Loss: 0.002992639085277915, Final Batch Loss: 0.0012373167555779219\n",
      "Epoch 1325, Loss: 0.005651675746776164, Final Batch Loss: 0.0009709048317745328\n",
      "Epoch 1326, Loss: 0.0059583092806860805, Final Batch Loss: 0.0003279688535258174\n",
      "Epoch 1327, Loss: 0.0022079544723965228, Final Batch Loss: 0.0005808491841889918\n",
      "Epoch 1328, Loss: 0.0012835357774747536, Final Batch Loss: 0.001074447063729167\n",
      "Epoch 1329, Loss: 0.0009644755045883358, Final Batch Loss: 0.0004973423783667386\n",
      "Epoch 1330, Loss: 0.00039429593743989244, Final Batch Loss: 0.00031478534219786525\n",
      "Epoch 1331, Loss: 0.0011811859731096774, Final Batch Loss: 0.0010320013388991356\n",
      "Epoch 1332, Loss: 0.0006511758001579437, Final Batch Loss: 0.0006160729681141675\n",
      "Epoch 1333, Loss: 0.0005840557569172233, Final Batch Loss: 0.00028002471663057804\n",
      "Epoch 1334, Loss: 0.00025041246408363804, Final Batch Loss: 0.00015502132009714842\n",
      "Epoch 1335, Loss: 0.0003746722068171948, Final Batch Loss: 0.00022265504230745137\n",
      "Epoch 1336, Loss: 0.0005777812330052257, Final Batch Loss: 0.0004169584426563233\n",
      "Epoch 1337, Loss: 0.0018545390339568257, Final Batch Loss: 0.001339172595180571\n",
      "Epoch 1338, Loss: 0.009548614034429193, Final Batch Loss: 0.007168772164732218\n",
      "Epoch 1339, Loss: 0.012158254161477089, Final Batch Loss: 0.0070532551035285\n",
      "Epoch 1340, Loss: 0.0007782620668876916, Final Batch Loss: 0.0003539668978191912\n",
      "Epoch 1341, Loss: 0.0005066630692454055, Final Batch Loss: 0.0002659583406057209\n",
      "Epoch 1342, Loss: 7.841148180887103e-05, Final Batch Loss: 3.0573275580536574e-05\n",
      "Epoch 1343, Loss: 0.00018694590107770637, Final Batch Loss: 7.907525287009776e-05\n",
      "Epoch 1344, Loss: 0.005789503687992692, Final Batch Loss: 0.0022643457632511854\n",
      "Epoch 1345, Loss: 0.0008067119924817234, Final Batch Loss: 0.0006955667631700635\n",
      "Epoch 1346, Loss: 0.0001557536597829312, Final Batch Loss: 1.3156823115423322e-05\n",
      "Epoch 1347, Loss: 0.006992192007601261, Final Batch Loss: 0.00043812813237309456\n",
      "Epoch 1348, Loss: 0.0004126904204895254, Final Batch Loss: 0.0003547531960066408\n",
      "Epoch 1349, Loss: 0.0003134963772026822, Final Batch Loss: 0.00028132926672697067\n",
      "Epoch 1350, Loss: 0.0008937460370361805, Final Batch Loss: 0.0006130127585493028\n",
      "Epoch 1351, Loss: 0.00046145015221554786, Final Batch Loss: 0.00031516101444140077\n",
      "Epoch 1352, Loss: 0.0017015085395541973, Final Batch Loss: 4.907814582111314e-05\n",
      "Epoch 1353, Loss: 0.007199818035587668, Final Batch Loss: 0.005918639246374369\n",
      "Epoch 1354, Loss: 0.003324060089653358, Final Batch Loss: 0.002994466107338667\n",
      "Epoch 1355, Loss: 0.0029803124198224396, Final Batch Loss: 0.0027540007140487432\n",
      "Epoch 1356, Loss: 0.0004760021647598478, Final Batch Loss: 1.1699618880811613e-05\n",
      "Epoch 1357, Loss: 0.0035136754158884287, Final Batch Loss: 0.0003147008828818798\n",
      "Epoch 1358, Loss: 0.00399135841144016, Final Batch Loss: 6.723819387843832e-05\n",
      "Epoch 1359, Loss: 0.0002499271504348144, Final Batch Loss: 0.00012495892588049173\n",
      "Epoch 1360, Loss: 0.0003451204902376048, Final Batch Loss: 7.518461643485352e-05\n",
      "Epoch 1361, Loss: 0.005151155579369515, Final Batch Loss: 0.004443754907697439\n",
      "Epoch 1362, Loss: 0.00017585978275747038, Final Batch Loss: 0.0001394116407027468\n",
      "Epoch 1363, Loss: 0.004630534076568438, Final Batch Loss: 1.6145972040249035e-05\n",
      "Epoch 1364, Loss: 0.0005452445620903745, Final Batch Loss: 0.00041281632729806006\n",
      "Epoch 1365, Loss: 0.000544098686077632, Final Batch Loss: 0.00013685076555702835\n",
      "Epoch 1366, Loss: 0.002569960372056812, Final Batch Loss: 0.0018641232745721936\n",
      "Epoch 1367, Loss: 0.0011858920333907008, Final Batch Loss: 0.0006809313199482858\n",
      "Epoch 1368, Loss: 0.005829938920214772, Final Batch Loss: 0.004695537965744734\n",
      "Epoch 1369, Loss: 0.0038284151914922404, Final Batch Loss: 1.2694169527094346e-05\n",
      "Epoch 1370, Loss: 0.002144082813174464, Final Batch Loss: 0.0019007049268111587\n",
      "Epoch 1371, Loss: 8.771648390393239e-05, Final Batch Loss: 6.06163521297276e-05\n",
      "Epoch 1372, Loss: 0.0004386517575767357, Final Batch Loss: 3.500171078485437e-05\n",
      "Epoch 1373, Loss: 0.0005136529580340721, Final Batch Loss: 8.149015047820285e-05\n",
      "Epoch 1374, Loss: 0.0006026899827702437, Final Batch Loss: 3.632466905401088e-05\n",
      "Epoch 1375, Loss: 0.006031919343513437, Final Batch Loss: 5.610806692857295e-05\n",
      "Epoch 1376, Loss: 0.0011127149336971343, Final Batch Loss: 0.0005240371101535857\n",
      "Epoch 1377, Loss: 0.007457980827894062, Final Batch Loss: 0.006623477675020695\n",
      "Epoch 1378, Loss: 0.0003662553626782028, Final Batch Loss: 2.0035380657645874e-05\n",
      "Epoch 1379, Loss: 0.015265441499650478, Final Batch Loss: 0.008616650477051735\n",
      "Epoch 1380, Loss: 0.0003111187688773498, Final Batch Loss: 0.000127843304653652\n",
      "Epoch 1381, Loss: 0.0031895678330329247, Final Batch Loss: 0.0031166989356279373\n",
      "Epoch 1382, Loss: 0.00928776222281158, Final Batch Loss: 0.008864032104611397\n",
      "Epoch 1383, Loss: 0.0009330407192464918, Final Batch Loss: 0.00048224497004412115\n",
      "Epoch 1384, Loss: 0.00025966516113840044, Final Batch Loss: 7.895808084867895e-05\n",
      "Epoch 1385, Loss: 0.004050953051773831, Final Batch Loss: 0.0002449124294798821\n",
      "Epoch 1386, Loss: 0.002729778250795789, Final Batch Loss: 0.00021899382409173995\n",
      "Epoch 1387, Loss: 0.0026366274105384946, Final Batch Loss: 0.002464071149006486\n",
      "Epoch 1388, Loss: 0.0017402716621290892, Final Batch Loss: 0.0001403336354997009\n",
      "Epoch 1389, Loss: 0.00034861503809224814, Final Batch Loss: 9.874939860310405e-05\n",
      "Epoch 1390, Loss: 0.0003669674333650619, Final Batch Loss: 0.00013574393233284354\n",
      "Epoch 1391, Loss: 0.0013164847987354733, Final Batch Loss: 0.0011981193674728274\n",
      "Epoch 1392, Loss: 0.0003041562522412278, Final Batch Loss: 0.00018214101146440953\n",
      "Epoch 1393, Loss: 0.00016990619405987673, Final Batch Loss: 2.4498422135366127e-05\n",
      "Epoch 1394, Loss: 0.0005811381488456391, Final Batch Loss: 9.34141207835637e-05\n",
      "Epoch 1395, Loss: 0.0008993404626380652, Final Batch Loss: 0.0005349725252017379\n",
      "Epoch 1396, Loss: 0.0009911370871122926, Final Batch Loss: 0.0002394880575593561\n",
      "Epoch 1397, Loss: 0.004237525397911668, Final Batch Loss: 0.002126903971657157\n",
      "Epoch 1398, Loss: 0.0005447539042506833, Final Batch Loss: 1.5336485375883058e-05\n",
      "Epoch 1399, Loss: 0.006217248155735433, Final Batch Loss: 0.001816188800148666\n",
      "Epoch 1400, Loss: 0.0027978119323961437, Final Batch Loss: 0.0003848508349619806\n",
      "Epoch 1401, Loss: 0.0018394774524495006, Final Batch Loss: 0.0011363248340785503\n",
      "Epoch 1402, Loss: 0.00012710375449387357, Final Batch Loss: 4.974302282789722e-05\n",
      "Epoch 1403, Loss: 0.0020178890554234385, Final Batch Loss: 0.001072978018783033\n",
      "Epoch 1404, Loss: 0.0003701048481161706, Final Batch Loss: 0.00025862830807454884\n",
      "Epoch 1405, Loss: 0.0008178590578609146, Final Batch Loss: 6.725281855324283e-05\n",
      "Epoch 1406, Loss: 0.0005575154355028644, Final Batch Loss: 9.593575668986887e-05\n",
      "Epoch 1407, Loss: 0.00043178324995096773, Final Batch Loss: 0.00015839510888326913\n",
      "Epoch 1408, Loss: 0.0006320030952338129, Final Batch Loss: 0.0002479345421306789\n",
      "Epoch 1409, Loss: 0.005150370801857207, Final Batch Loss: 0.005090304650366306\n",
      "Epoch 1410, Loss: 0.00031309719634009525, Final Batch Loss: 0.0001956461346708238\n",
      "Epoch 1411, Loss: 0.0001995312559301965, Final Batch Loss: 0.0001295498077524826\n",
      "Epoch 1412, Loss: 0.02448164587985957, Final Batch Loss: 0.02439899928867817\n",
      "Epoch 1413, Loss: 0.0007078726348481723, Final Batch Loss: 1.3013094758207444e-05\n",
      "Epoch 1414, Loss: 0.01778575492789969, Final Batch Loss: 0.0007866462110541761\n",
      "Epoch 1415, Loss: 0.0011335177696309984, Final Batch Loss: 0.00030872697243466973\n",
      "Epoch 1416, Loss: 0.005734093123464845, Final Batch Loss: 0.00010909103730227798\n",
      "Epoch 1417, Loss: 0.0037328336475184187, Final Batch Loss: 6.806441524531692e-05\n",
      "Epoch 1418, Loss: 0.0009689340658951551, Final Batch Loss: 0.0005123947048559785\n",
      "Epoch 1419, Loss: 0.004624138804501854, Final Batch Loss: 4.4487169361673295e-05\n",
      "Epoch 1420, Loss: 0.001660581532632932, Final Batch Loss: 0.0015995255671441555\n",
      "Epoch 1421, Loss: 0.000409162665164331, Final Batch Loss: 3.9269976696232334e-05\n",
      "Epoch 1422, Loss: 0.0008867116357578197, Final Batch Loss: 0.0008690226823091507\n",
      "Epoch 1423, Loss: 0.012372461173072224, Final Batch Loss: 3.2932523026829585e-05\n",
      "Epoch 1424, Loss: 0.0011641192832030356, Final Batch Loss: 0.0007971490267664194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1425, Loss: 0.0037945241274428554, Final Batch Loss: 3.721309622051194e-05\n",
      "Epoch 1426, Loss: 0.0006148288084659725, Final Batch Loss: 0.00047460192581638694\n",
      "Epoch 1427, Loss: 0.0004131531313760206, Final Batch Loss: 0.00011063624697271734\n",
      "Epoch 1428, Loss: 0.001868455728981644, Final Batch Loss: 0.0011118603870272636\n",
      "Epoch 1429, Loss: 0.0006938437072676606, Final Batch Loss: 0.000576647580601275\n",
      "Epoch 1430, Loss: 0.0019758398411795497, Final Batch Loss: 0.001474676071666181\n",
      "Epoch 1431, Loss: 0.00020903945915051736, Final Batch Loss: 3.4958782634930685e-05\n",
      "Epoch 1432, Loss: 0.0008161859295796603, Final Batch Loss: 0.00040590864955447614\n",
      "Epoch 1433, Loss: 0.001520850082670222, Final Batch Loss: 1.7903015759657137e-05\n",
      "Epoch 1434, Loss: 0.0009691720770206302, Final Batch Loss: 6.939630839042366e-05\n",
      "Epoch 1435, Loss: 0.0005411506426753476, Final Batch Loss: 0.00035786424996331334\n",
      "Epoch 1436, Loss: 0.0006310906173894182, Final Batch Loss: 0.0004174814384896308\n",
      "Epoch 1437, Loss: 0.0003856460825772956, Final Batch Loss: 2.4920693249441683e-05\n",
      "Epoch 1438, Loss: 0.0002792820414470043, Final Batch Loss: 0.00022685772273689508\n",
      "Epoch 1439, Loss: 0.0029820374911651015, Final Batch Loss: 0.0004919738275930285\n",
      "Epoch 1440, Loss: 0.003744128829566762, Final Batch Loss: 0.0001240176788996905\n",
      "Epoch 1441, Loss: 0.0012087587019777857, Final Batch Loss: 9.094460256164894e-05\n",
      "Epoch 1442, Loss: 0.0005644965385727119, Final Batch Loss: 2.957436299766414e-05\n",
      "Epoch 1443, Loss: 0.00040893361438065767, Final Batch Loss: 0.0002817919885274023\n",
      "Epoch 1444, Loss: 0.00010746177213150077, Final Batch Loss: 4.697477197623812e-05\n",
      "Epoch 1445, Loss: 0.00017561521599418484, Final Batch Loss: 0.0001222627906827256\n",
      "Epoch 1446, Loss: 0.007557732067652978, Final Batch Loss: 0.007388539612293243\n",
      "Epoch 1447, Loss: 0.00039930858474690467, Final Batch Loss: 9.393446089234203e-05\n",
      "Epoch 1448, Loss: 0.0005707917516701855, Final Batch Loss: 0.00012161982158431783\n",
      "Epoch 1449, Loss: 0.015246872548232204, Final Batch Loss: 1.6445052096969448e-05\n",
      "Epoch 1450, Loss: 0.0005385911135817878, Final Batch Loss: 0.00012004258314846084\n",
      "Epoch 1451, Loss: 0.000457885253126733, Final Batch Loss: 0.00010107176785822958\n",
      "Epoch 1452, Loss: 0.006552797791300691, Final Batch Loss: 1.1136804459965788e-05\n",
      "Epoch 1453, Loss: 0.0007692613726248965, Final Batch Loss: 0.000689626089297235\n",
      "Epoch 1454, Loss: 0.0007243418658617884, Final Batch Loss: 0.00040264788549393415\n",
      "Epoch 1455, Loss: 0.0011628688334894832, Final Batch Loss: 5.2323590352898464e-05\n",
      "Epoch 1456, Loss: 0.005089589685667306, Final Batch Loss: 0.0044801789335906506\n",
      "Epoch 1457, Loss: 0.0011471288016764447, Final Batch Loss: 0.0010217459639534354\n",
      "Epoch 1458, Loss: 0.000945554937061388, Final Batch Loss: 0.0008528499747626483\n",
      "Epoch 1459, Loss: 0.0016451116825919598, Final Batch Loss: 0.0013008118839934468\n",
      "Epoch 1460, Loss: 0.0010243519500363618, Final Batch Loss: 0.00022229747264645994\n",
      "Epoch 1461, Loss: 0.004794526888872497, Final Batch Loss: 7.291189103852957e-05\n",
      "Epoch 1462, Loss: 0.0006866091571282595, Final Batch Loss: 0.00035634697997011244\n",
      "Epoch 1463, Loss: 0.0037757325917482376, Final Batch Loss: 0.0018540601013228297\n",
      "Epoch 1464, Loss: 0.0010197862629865995, Final Batch Loss: 2.169519393646624e-05\n",
      "Epoch 1465, Loss: 0.005691546597518027, Final Batch Loss: 0.0053711580112576485\n",
      "Epoch 1466, Loss: 0.002014481695368886, Final Batch Loss: 0.000986370607279241\n",
      "Epoch 1467, Loss: 0.002689751680009067, Final Batch Loss: 0.001597049878910184\n",
      "Epoch 1468, Loss: 0.004204983706586063, Final Batch Loss: 8.710508700460196e-05\n",
      "Epoch 1469, Loss: 0.00019211134349461645, Final Batch Loss: 0.00014818887575529516\n",
      "Epoch 1470, Loss: 8.508427526976448e-05, Final Batch Loss: 8.75883961271029e-06\n",
      "Epoch 1471, Loss: 0.0014938538952264935, Final Batch Loss: 6.763465353287756e-05\n",
      "Epoch 1472, Loss: 0.004382521954539698, Final Batch Loss: 3.9133352402132004e-05\n",
      "Epoch 1473, Loss: 0.0002815413099597208, Final Batch Loss: 4.265814641257748e-05\n",
      "Epoch 1474, Loss: 0.0004089497315362678, Final Batch Loss: 2.7295545805827715e-06\n",
      "Epoch 1475, Loss: 0.0003780788538279012, Final Batch Loss: 0.00025329430354759097\n",
      "Epoch 1476, Loss: 0.00015613905634381808, Final Batch Loss: 2.7794860216090456e-05\n",
      "Epoch 1477, Loss: 0.004216746718157083, Final Batch Loss: 0.0009038583957590163\n",
      "Epoch 1478, Loss: 0.00024301121447933838, Final Batch Loss: 7.178560917964205e-05\n",
      "Epoch 1479, Loss: 0.0012538528826553375, Final Batch Loss: 0.0010624402202665806\n",
      "Epoch 1480, Loss: 0.008620712498668581, Final Batch Loss: 0.007871859706938267\n",
      "Epoch 1481, Loss: 0.003729381924131303, Final Batch Loss: 2.1105026462464593e-05\n",
      "Epoch 1482, Loss: 7.356554124271497e-05, Final Batch Loss: 4.009871190646663e-05\n",
      "Epoch 1483, Loss: 0.0004843184578930959, Final Batch Loss: 0.00015394460933748633\n",
      "Epoch 1484, Loss: 0.0009537855730741285, Final Batch Loss: 0.0008378399652428925\n",
      "Epoch 1485, Loss: 0.0008464935090159997, Final Batch Loss: 0.00019074078591074795\n",
      "Epoch 1486, Loss: 0.0047395868168678135, Final Batch Loss: 0.00028376010595820844\n",
      "Epoch 1487, Loss: 0.006300991168245673, Final Batch Loss: 0.002748279832303524\n",
      "Epoch 1488, Loss: 0.000450176652520895, Final Batch Loss: 6.462077726610005e-05\n",
      "Epoch 1489, Loss: 0.0016154997656485648, Final Batch Loss: 5.503455213329289e-06\n",
      "Epoch 1490, Loss: 0.0009036290284711868, Final Batch Loss: 0.0007675758097320795\n",
      "Epoch 1491, Loss: 0.000594701079535298, Final Batch Loss: 0.0001852482819231227\n",
      "Epoch 1492, Loss: 0.0064785492431838065, Final Batch Loss: 0.00033171827089972794\n",
      "Epoch 1493, Loss: 0.0013315190881257877, Final Batch Loss: 0.00021619627659674734\n",
      "Epoch 1494, Loss: 0.0008780391508480534, Final Batch Loss: 0.0001375185529468581\n",
      "Epoch 1495, Loss: 0.0007267094479175285, Final Batch Loss: 0.00017644792387727648\n",
      "Epoch 1496, Loss: 0.0004689740017056465, Final Batch Loss: 0.00032940940582193434\n",
      "Epoch 1497, Loss: 0.0008949457842390984, Final Batch Loss: 0.00026837686891667545\n",
      "Epoch 1498, Loss: 0.001557300565764308, Final Batch Loss: 0.000913575931917876\n",
      "Epoch 1499, Loss: 0.0007529401045758277, Final Batch Loss: 6.484441109932959e-05\n",
      "Epoch 1500, Loss: 0.0072698969233897515, Final Batch Loss: 0.007176869083195925\n",
      "Epoch 1501, Loss: 0.000679084419971332, Final Batch Loss: 0.00030934764072299004\n",
      "Epoch 1502, Loss: 0.003855465998640284, Final Batch Loss: 0.0002703199570532888\n",
      "Epoch 1503, Loss: 0.0002537484106142074, Final Batch Loss: 0.00010722549632191658\n",
      "Epoch 1504, Loss: 0.00015946317762427498, Final Batch Loss: 2.713488538574893e-05\n",
      "Epoch 1505, Loss: 0.00017235009181604255, Final Batch Loss: 0.00014241840108297765\n",
      "Epoch 1506, Loss: 0.0008207241771742702, Final Batch Loss: 0.0005445724818855524\n",
      "Epoch 1507, Loss: 0.0012663660454563797, Final Batch Loss: 0.000686227751430124\n",
      "Epoch 1508, Loss: 0.002406871411949396, Final Batch Loss: 0.0010766817722469568\n",
      "Epoch 1509, Loss: 0.0018669552518986166, Final Batch Loss: 0.001532148802652955\n",
      "Epoch 1510, Loss: 0.0010471780260559171, Final Batch Loss: 0.0009603629587218165\n",
      "Epoch 1511, Loss: 0.00038104694976937026, Final Batch Loss: 2.948076871689409e-05\n",
      "Epoch 1512, Loss: 0.0004422361234901473, Final Batch Loss: 0.00018791052571032196\n",
      "Epoch 1513, Loss: 0.0006312291952781379, Final Batch Loss: 7.409881800413132e-05\n",
      "Epoch 1514, Loss: 0.02966004639165476, Final Batch Loss: 0.0006563405622728169\n",
      "Epoch 1515, Loss: 0.006913073390023783, Final Batch Loss: 0.006755696143954992\n",
      "Epoch 1516, Loss: 0.008197018130886136, Final Batch Loss: 8.507817256031558e-06\n",
      "Epoch 1517, Loss: 0.0003537786105880514, Final Batch Loss: 0.00027960119768977165\n",
      "Epoch 1518, Loss: 0.00031445825879927725, Final Batch Loss: 6.141768244560808e-05\n",
      "Epoch 1519, Loss: 0.0001770246371961548, Final Batch Loss: 9.121088623942342e-06\n",
      "Epoch 1520, Loss: 0.00029574192740255967, Final Batch Loss: 5.643693293677643e-05\n",
      "Epoch 1521, Loss: 0.006947170135390479, Final Batch Loss: 0.006844041869044304\n",
      "Epoch 1522, Loss: 0.0012293719337321818, Final Batch Loss: 0.00012115453137084842\n",
      "Epoch 1523, Loss: 0.0019132390443701297, Final Batch Loss: 0.00016066900570876896\n",
      "Epoch 1524, Loss: 0.0002427256404189393, Final Batch Loss: 0.00015741288370918483\n",
      "Epoch 1525, Loss: 0.006557947244800744, Final Batch Loss: 1.5382875062641688e-05\n",
      "Epoch 1526, Loss: 0.004265031311661005, Final Batch Loss: 0.003911740146577358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1527, Loss: 0.006808825361076742, Final Batch Loss: 0.006641795393079519\n",
      "Epoch 1528, Loss: 0.0002469327737344429, Final Batch Loss: 0.0001679168635746464\n",
      "Epoch 1529, Loss: 0.00016783315004431643, Final Batch Loss: 0.00011399680079193786\n",
      "Epoch 1530, Loss: 0.0012799479300156236, Final Batch Loss: 0.0006361358100548387\n",
      "Epoch 1531, Loss: 0.0006888963398523629, Final Batch Loss: 0.00040000546141527593\n",
      "Epoch 1532, Loss: 0.00015544092275376897, Final Batch Loss: 0.00013756034604739398\n",
      "Epoch 1533, Loss: 0.002026401663897559, Final Batch Loss: 0.001836618990637362\n",
      "Epoch 1534, Loss: 0.0008757893374422565, Final Batch Loss: 3.489306254778057e-05\n",
      "Epoch 1535, Loss: 0.0016770663787610829, Final Batch Loss: 0.001142782624810934\n",
      "Epoch 1536, Loss: 0.0007211418997030705, Final Batch Loss: 0.0002889208553824574\n",
      "Epoch 1537, Loss: 6.620395470235962e-05, Final Batch Loss: 2.734995177888777e-05\n",
      "Epoch 1538, Loss: 0.0008538811671314761, Final Batch Loss: 0.0008189345826394856\n",
      "Epoch 1539, Loss: 0.00034682245313888416, Final Batch Loss: 0.0002968891931232065\n",
      "Epoch 1540, Loss: 0.00013815769716529758, Final Batch Loss: 6.002645477565238e-06\n",
      "Epoch 1541, Loss: 0.00045027091982774436, Final Batch Loss: 0.00028504448710009456\n",
      "Epoch 1542, Loss: 0.01201870758086443, Final Batch Loss: 0.011158096604049206\n",
      "Epoch 1543, Loss: 0.00038042190863052383, Final Batch Loss: 0.00031297391979023814\n",
      "Epoch 1544, Loss: 0.006000814355502371, Final Batch Loss: 7.301322330022231e-05\n",
      "Epoch 1545, Loss: 0.0004992005924577825, Final Batch Loss: 0.00048062356654554605\n",
      "Epoch 1546, Loss: 8.704641004442237e-05, Final Batch Loss: 3.1193158065434545e-05\n",
      "Epoch 1547, Loss: 0.0007499981275032042, Final Batch Loss: 9.723806215333752e-06\n",
      "Epoch 1548, Loss: 0.00027523056633071974, Final Batch Loss: 0.00017233473772648722\n",
      "Epoch 1549, Loss: 0.003814412399151479, Final Batch Loss: 2.6792871722136624e-05\n",
      "Epoch 1550, Loss: 0.0007306817860808223, Final Batch Loss: 0.0002301375789102167\n",
      "Epoch 1551, Loss: 0.00025003543123602867, Final Batch Loss: 8.838438952807337e-05\n",
      "Epoch 1552, Loss: 0.00020430788572411984, Final Batch Loss: 0.00014530037879012525\n",
      "Epoch 1553, Loss: 0.0004682395010604523, Final Batch Loss: 8.376259211217985e-05\n",
      "Epoch 1554, Loss: 0.004027055227197707, Final Batch Loss: 0.00041166937444359064\n",
      "Epoch 1555, Loss: 0.004306447895942256, Final Batch Loss: 0.0003786978486459702\n",
      "Epoch 1556, Loss: 0.0010182098194491118, Final Batch Loss: 0.0005780882784165442\n",
      "Epoch 1557, Loss: 0.0006110009562689811, Final Batch Loss: 0.00017660841695033014\n",
      "Epoch 1558, Loss: 0.0004510068101808429, Final Batch Loss: 0.00018133342382498085\n",
      "Epoch 1559, Loss: 0.004314323450671509, Final Batch Loss: 0.00038186044548638165\n",
      "Epoch 1560, Loss: 0.0003402198399271583, Final Batch Loss: 0.00031460614991374314\n",
      "Epoch 1561, Loss: 0.0047342946054413915, Final Batch Loss: 0.00020076532382518053\n",
      "Epoch 1562, Loss: 0.0002502820498193614, Final Batch Loss: 6.311905599432066e-05\n",
      "Epoch 1563, Loss: 0.009447338918107562, Final Batch Loss: 0.009387479163706303\n",
      "Epoch 1564, Loss: 0.0007405908618238755, Final Batch Loss: 8.078473183559254e-05\n",
      "Epoch 1565, Loss: 0.0003711934159582597, Final Batch Loss: 1.435865578969242e-05\n",
      "Epoch 1566, Loss: 0.00037491798866540194, Final Batch Loss: 0.00021270610159263015\n",
      "Epoch 1567, Loss: 0.00030340409284690395, Final Batch Loss: 0.00020360197231639177\n",
      "Epoch 1568, Loss: 0.0009212405420839787, Final Batch Loss: 0.00032115832436829805\n",
      "Epoch 1569, Loss: 0.0008438262884737924, Final Batch Loss: 0.00012268977297935635\n",
      "Epoch 1570, Loss: 0.00015384742437163368, Final Batch Loss: 8.59624778968282e-05\n",
      "Epoch 1571, Loss: 0.001000612144707702, Final Batch Loss: 1.4554578228853643e-05\n",
      "Epoch 1572, Loss: 0.006231425068108365, Final Batch Loss: 0.006063290871679783\n",
      "Epoch 1573, Loss: 0.0007823490304872394, Final Batch Loss: 0.00041075359331443906\n",
      "Epoch 1574, Loss: 0.00393068086123094, Final Batch Loss: 0.0003471625386737287\n",
      "Epoch 1575, Loss: 0.004873261146713048, Final Batch Loss: 0.0006065464694984257\n",
      "Epoch 1576, Loss: 9.372164822707418e-05, Final Batch Loss: 7.785739580867812e-05\n",
      "Epoch 1577, Loss: 0.002381696569500491, Final Batch Loss: 0.0023146888706833124\n",
      "Epoch 1578, Loss: 0.00020490966926445253, Final Batch Loss: 3.903461401932873e-05\n",
      "Epoch 1579, Loss: 0.00035290380037622526, Final Batch Loss: 0.0003454875259194523\n",
      "Epoch 1580, Loss: 0.004434551010490395, Final Batch Loss: 3.0523064197041094e-05\n",
      "Epoch 1581, Loss: 0.024445871596981306, Final Batch Loss: 7.940154318930581e-05\n",
      "Epoch 1582, Loss: 0.0002815863444993738, Final Batch Loss: 0.00023636491096112877\n",
      "Epoch 1583, Loss: 0.0011425326083553955, Final Batch Loss: 0.0010102654341608286\n",
      "Epoch 1584, Loss: 0.005426035542768659, Final Batch Loss: 0.005401952192187309\n",
      "Epoch 1585, Loss: 0.0010561490835243603, Final Batch Loss: 0.001037335372529924\n",
      "Epoch 1586, Loss: 0.0006037691928213462, Final Batch Loss: 0.00041778740705922246\n",
      "Epoch 1587, Loss: 0.0001505021209595725, Final Batch Loss: 6.362592102959752e-06\n",
      "Epoch 1588, Loss: 0.0003381224669283256, Final Batch Loss: 0.00020089989993721247\n",
      "Epoch 1589, Loss: 0.0008465608989354223, Final Batch Loss: 0.00035321395262144506\n",
      "Epoch 1590, Loss: 0.0007429693068843335, Final Batch Loss: 0.00035530063905753195\n",
      "Epoch 1591, Loss: 6.29546129857772e-05, Final Batch Loss: 9.810636584006716e-06\n",
      "Epoch 1592, Loss: 0.01028215508813446, Final Batch Loss: 2.535894418542739e-05\n",
      "Epoch 1593, Loss: 0.001263734302483499, Final Batch Loss: 0.0005402228562161326\n",
      "Epoch 1594, Loss: 0.00025315105449408293, Final Batch Loss: 0.00014469191955868155\n",
      "Epoch 1595, Loss: 0.0006226834520930424, Final Batch Loss: 0.00010239555558655411\n",
      "Epoch 1596, Loss: 0.00908678153064102, Final Batch Loss: 0.0012569486862048507\n",
      "Epoch 1597, Loss: 0.0006514296401292086, Final Batch Loss: 0.00045703601790592074\n",
      "Epoch 1598, Loss: 0.001794192532543093, Final Batch Loss: 0.0007616297225467861\n",
      "Epoch 1599, Loss: 0.0005690253310604021, Final Batch Loss: 0.0004647852620109916\n",
      "Epoch 1600, Loss: 0.01023420609999448, Final Batch Loss: 0.009314815513789654\n",
      "Epoch 1601, Loss: 0.0011786895047407597, Final Batch Loss: 0.0007853715214878321\n",
      "Epoch 1602, Loss: 0.0007567473367089406, Final Batch Loss: 0.00021104795450810343\n",
      "Epoch 1603, Loss: 0.001197769794089254, Final Batch Loss: 7.989376172190532e-05\n",
      "Epoch 1604, Loss: 0.00018355599240749143, Final Batch Loss: 1.8851755157811567e-05\n",
      "Epoch 1605, Loss: 0.0009815357116167434, Final Batch Loss: 0.00010956574260490015\n",
      "Epoch 1606, Loss: 0.0007350606028921902, Final Batch Loss: 0.00023742136545479298\n",
      "Epoch 1607, Loss: 0.0027631110278889537, Final Batch Loss: 0.00040962721686810255\n",
      "Epoch 1608, Loss: 0.0005428814474726096, Final Batch Loss: 0.00021757154900114983\n",
      "Epoch 1609, Loss: 0.0003180495696142316, Final Batch Loss: 0.00013749276695307344\n",
      "Epoch 1610, Loss: 0.0009009144123410806, Final Batch Loss: 0.00024028772895690054\n",
      "Epoch 1611, Loss: 0.0002109684319293592, Final Batch Loss: 0.00017949614266399294\n",
      "Epoch 1612, Loss: 0.0010148201690753922, Final Batch Loss: 0.00013732931984122843\n",
      "Epoch 1613, Loss: 0.004872559820796596, Final Batch Loss: 2.430777021800168e-05\n",
      "Epoch 1614, Loss: 0.004458010589587502, Final Batch Loss: 0.00014347016985993832\n",
      "Epoch 1615, Loss: 0.00042761649092426524, Final Batch Loss: 0.00010341472079744563\n",
      "Epoch 1616, Loss: 0.003037312053493224, Final Batch Loss: 0.0029285489581525326\n",
      "Epoch 1617, Loss: 0.00042736929026432335, Final Batch Loss: 0.00030059434357099235\n",
      "Epoch 1618, Loss: 0.024885014501705882, Final Batch Loss: 3.720504537341185e-06\n",
      "Epoch 1619, Loss: 0.004204952419968322, Final Batch Loss: 0.00017938276869244874\n",
      "Epoch 1620, Loss: 0.0016022593881643843, Final Batch Loss: 0.0015518419677391648\n",
      "Epoch 1621, Loss: 0.00022764545428799465, Final Batch Loss: 8.607768540969118e-05\n",
      "Epoch 1622, Loss: 0.010982426814734936, Final Batch Loss: 0.008601751178503036\n",
      "Epoch 1623, Loss: 0.0022276366071309894, Final Batch Loss: 0.0018928046338260174\n",
      "Epoch 1624, Loss: 0.0004680795500462409, Final Batch Loss: 3.4903492633020505e-05\n",
      "Epoch 1625, Loss: 0.00031921999470796436, Final Batch Loss: 0.0002970606437884271\n",
      "Epoch 1626, Loss: 0.009363769087940454, Final Batch Loss: 8.544651791453362e-05\n",
      "Epoch 1627, Loss: 0.0002015765994656249, Final Batch Loss: 9.328875421488192e-06\n",
      "Epoch 1628, Loss: 0.0006334653735393658, Final Batch Loss: 0.00042362342355772853\n",
      "Epoch 1629, Loss: 0.0011111203348264098, Final Batch Loss: 0.00018253229791298509\n",
      "Epoch 1630, Loss: 6.887378549436107e-05, Final Batch Loss: 1.5686164260841906e-05\n",
      "Epoch 1631, Loss: 0.0003409312048461288, Final Batch Loss: 0.0002135210670530796\n",
      "Epoch 1632, Loss: 0.006539252353832126, Final Batch Loss: 0.00020154076628386974\n",
      "Epoch 1633, Loss: 0.0005814969190396369, Final Batch Loss: 0.00016927480464801192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1634, Loss: 0.0004342668689787388, Final Batch Loss: 0.0001452288415748626\n",
      "Epoch 1635, Loss: 0.0061352248303592205, Final Batch Loss: 0.006082977633923292\n",
      "Epoch 1636, Loss: 0.0017104039143305272, Final Batch Loss: 0.00011739853653125465\n",
      "Epoch 1637, Loss: 7.19983709132066e-05, Final Batch Loss: 1.5193641957012005e-05\n",
      "Epoch 1638, Loss: 0.0036029784023412503, Final Batch Loss: 4.5155502448324114e-05\n",
      "Epoch 1639, Loss: 0.0001694431557552889, Final Batch Loss: 6.216511246748269e-05\n",
      "Epoch 1640, Loss: 0.0003632611915236339, Final Batch Loss: 0.00011541658022906631\n",
      "Epoch 1641, Loss: 0.0001769069003785262, Final Batch Loss: 2.6950519895763136e-05\n",
      "Epoch 1642, Loss: 0.00026302428159397095, Final Batch Loss: 4.715254181064665e-05\n",
      "Epoch 1643, Loss: 0.004624625842552632, Final Batch Loss: 0.0004490606370382011\n",
      "Epoch 1644, Loss: 0.0002751148022070993, Final Batch Loss: 4.280740176909603e-05\n",
      "Epoch 1645, Loss: 0.01890727137288195, Final Batch Loss: 2.8733211365761235e-05\n",
      "Epoch 1646, Loss: 0.0001261033939954359, Final Batch Loss: 5.208339644013904e-05\n",
      "Epoch 1647, Loss: 0.0006582611822523177, Final Batch Loss: 0.0005767580005340278\n",
      "Epoch 1648, Loss: 0.012965944519237382, Final Batch Loss: 4.701681245933287e-05\n",
      "Epoch 1649, Loss: 0.005545912261823105, Final Batch Loss: 5.622345724987099e-06\n",
      "Epoch 1650, Loss: 0.0003996826126240194, Final Batch Loss: 0.00013567839050665498\n",
      "Epoch 1651, Loss: 0.003104345654719509, Final Batch Loss: 0.00296883680857718\n",
      "Epoch 1652, Loss: 0.004459624338778667, Final Batch Loss: 0.00015375127259176224\n",
      "Epoch 1653, Loss: 0.0014852231834083796, Final Batch Loss: 0.00026202050503343344\n",
      "Epoch 1654, Loss: 0.006320313812466338, Final Batch Loss: 0.00017687937361188233\n",
      "Epoch 1655, Loss: 0.008119094971334562, Final Batch Loss: 0.0002565168251749128\n",
      "Epoch 1656, Loss: 9.869458881439641e-05, Final Batch Loss: 5.0933111197082326e-05\n",
      "Epoch 1657, Loss: 0.00010931441283901222, Final Batch Loss: 6.177993054734543e-05\n",
      "Epoch 1658, Loss: 0.002768958282103995, Final Batch Loss: 5.345704630599357e-05\n",
      "Epoch 1659, Loss: 0.006727229105308652, Final Batch Loss: 0.006492040120065212\n",
      "Epoch 1660, Loss: 0.00043463856854941696, Final Batch Loss: 0.00020072578627150506\n",
      "Epoch 1661, Loss: 0.000619564569205977, Final Batch Loss: 8.356479520443827e-05\n",
      "Epoch 1662, Loss: 0.000694327252858784, Final Batch Loss: 6.538713205372915e-05\n",
      "Epoch 1663, Loss: 0.00030465942836599424, Final Batch Loss: 0.00010163256229134277\n",
      "Epoch 1664, Loss: 0.0009893513924907893, Final Batch Loss: 0.0006406107568182051\n",
      "Epoch 1665, Loss: 0.011712018353136955, Final Batch Loss: 4.567853102344088e-05\n",
      "Epoch 1666, Loss: 0.000769550275435904, Final Batch Loss: 0.0007617634255439043\n",
      "Epoch 1667, Loss: 0.0001156282341980841, Final Batch Loss: 2.2007003281032667e-05\n",
      "Epoch 1668, Loss: 0.00012130361392337363, Final Batch Loss: 2.8029475288349204e-05\n",
      "Epoch 1669, Loss: 0.002201067458372563, Final Batch Loss: 0.0005001124809496105\n",
      "Epoch 1670, Loss: 0.00025598235151846893, Final Batch Loss: 3.299741729279049e-05\n",
      "Epoch 1671, Loss: 0.00028547011606860906, Final Batch Loss: 0.000106523119029589\n",
      "Epoch 1672, Loss: 0.0007967750643729232, Final Batch Loss: 7.43415075703524e-05\n",
      "Epoch 1673, Loss: 0.000497319117130246, Final Batch Loss: 5.6275246606674045e-05\n",
      "Epoch 1674, Loss: 0.000838432926684618, Final Batch Loss: 0.00023839285131543875\n",
      "Epoch 1675, Loss: 0.0002800620968628209, Final Batch Loss: 0.00021938509598840028\n",
      "Epoch 1676, Loss: 0.002383136099524563, Final Batch Loss: 0.002327308524399996\n",
      "Epoch 1677, Loss: 0.0002264443101012148, Final Batch Loss: 8.217847062041983e-05\n",
      "Epoch 1678, Loss: 0.009978145768400282, Final Batch Loss: 0.0008810213184915483\n",
      "Epoch 1679, Loss: 0.0001390878851452726, Final Batch Loss: 0.00012418713595252484\n",
      "Epoch 1680, Loss: 0.005055350218754029, Final Batch Loss: 1.8504881154512987e-05\n",
      "Epoch 1681, Loss: 0.0003626935231295647, Final Batch Loss: 2.1360743630793877e-05\n",
      "Epoch 1682, Loss: 0.00034124225203413516, Final Batch Loss: 0.0001676542597124353\n",
      "Epoch 1683, Loss: 0.029491312703157746, Final Batch Loss: 7.083540822350187e-06\n",
      "Epoch 1684, Loss: 0.009016656113089994, Final Batch Loss: 0.00020475292694754899\n",
      "Epoch 1685, Loss: 0.00028257172380108386, Final Batch Loss: 0.00026244521723128855\n",
      "Epoch 1686, Loss: 0.00023873498139437288, Final Batch Loss: 0.00017481244867667556\n",
      "Epoch 1687, Loss: 0.00034736047746264376, Final Batch Loss: 0.00029540288960561156\n",
      "Epoch 1688, Loss: 0.0005031554319430143, Final Batch Loss: 0.00035563320852816105\n",
      "Epoch 1689, Loss: 0.00023821926879463717, Final Batch Loss: 0.0001923598174471408\n",
      "Epoch 1690, Loss: 0.002389470872003585, Final Batch Loss: 0.0002666887012310326\n",
      "Epoch 1691, Loss: 0.007033010188024491, Final Batch Loss: 0.006888095289468765\n",
      "Epoch 1692, Loss: 0.0002662376136868261, Final Batch Loss: 6.870349898235872e-05\n",
      "Epoch 1693, Loss: 0.00032519314845558256, Final Batch Loss: 0.00014501331315841526\n",
      "Epoch 1694, Loss: 0.0003743579909496475, Final Batch Loss: 4.99196357850451e-05\n",
      "Epoch 1695, Loss: 0.0005066980666015297, Final Batch Loss: 0.00034591290750540793\n",
      "Epoch 1696, Loss: 0.005523956395336427, Final Batch Loss: 0.005372514016926289\n",
      "Epoch 1697, Loss: 0.00034575455811136635, Final Batch Loss: 1.3293935808178503e-05\n",
      "Epoch 1698, Loss: 0.007870949164498597, Final Batch Loss: 0.007380382157862186\n",
      "Epoch 1699, Loss: 0.000584017820074223, Final Batch Loss: 0.0004206207231618464\n",
      "Epoch 1700, Loss: 0.0004086785811523441, Final Batch Loss: 4.018427353003062e-05\n",
      "Epoch 1701, Loss: 0.0003292869296274148, Final Batch Loss: 6.350329931592569e-05\n",
      "Epoch 1702, Loss: 0.00048371293814852834, Final Batch Loss: 5.436284118331969e-05\n",
      "Epoch 1703, Loss: 0.00011070231630583294, Final Batch Loss: 3.078487134189345e-05\n",
      "Epoch 1704, Loss: 0.0015567816008115187, Final Batch Loss: 0.001332573127001524\n",
      "Epoch 1705, Loss: 0.0031493001224589534, Final Batch Loss: 3.417209518374875e-05\n",
      "Epoch 1706, Loss: 0.0007830843096598983, Final Batch Loss: 0.00018299015937373042\n",
      "Epoch 1707, Loss: 0.0005075743101770058, Final Batch Loss: 0.00031931392732076347\n",
      "Epoch 1708, Loss: 0.0001531522320874501, Final Batch Loss: 0.00012814815272577107\n",
      "Epoch 1709, Loss: 0.011531618714798242, Final Batch Loss: 0.00024751509772613645\n",
      "Epoch 1710, Loss: 0.0003415124556340743, Final Batch Loss: 0.0003176222671754658\n",
      "Epoch 1711, Loss: 0.00017050691531039774, Final Batch Loss: 2.2610678570345044e-05\n",
      "Epoch 1712, Loss: 0.0019331894945935346, Final Batch Loss: 0.001852945308201015\n",
      "Epoch 1713, Loss: 0.003718616673722863, Final Batch Loss: 0.0002960790880024433\n",
      "Epoch 1714, Loss: 0.01572593995661009, Final Batch Loss: 0.015514223836362362\n",
      "Epoch 1715, Loss: 0.0005003438491257839, Final Batch Loss: 0.0004058217164129019\n",
      "Epoch 1716, Loss: 0.0025753290319698863, Final Batch Loss: 4.184757563052699e-05\n",
      "Epoch 1717, Loss: 8.815620822133496e-05, Final Batch Loss: 2.8115402528783306e-05\n",
      "Epoch 1718, Loss: 0.0004119132318010088, Final Batch Loss: 3.5730739909922704e-05\n",
      "Epoch 1719, Loss: 0.0004927446716465056, Final Batch Loss: 0.0003043964970856905\n",
      "Epoch 1720, Loss: 0.0010505504324100912, Final Batch Loss: 0.0006406343309208751\n",
      "Epoch 1721, Loss: 0.005066827689006459, Final Batch Loss: 3.81379431928508e-05\n",
      "Epoch 1722, Loss: 0.0012061661400366575, Final Batch Loss: 0.00020764328655786812\n",
      "Epoch 1723, Loss: 0.001011678046779707, Final Batch Loss: 0.0006764899590052664\n",
      "Epoch 1724, Loss: 0.0002848768053809181, Final Batch Loss: 9.530609531793743e-05\n",
      "Epoch 1725, Loss: 0.001975918043171987, Final Batch Loss: 0.0002590494405012578\n",
      "Epoch 1726, Loss: 0.00011931903372897068, Final Batch Loss: 1.0792618013510946e-05\n",
      "Epoch 1727, Loss: 0.00029017824272159487, Final Batch Loss: 0.00023478821094613522\n",
      "Epoch 1728, Loss: 0.003220633933779027, Final Batch Loss: 1.4940839719201904e-05\n",
      "Epoch 1729, Loss: 0.0011696824367390946, Final Batch Loss: 0.0001918649795698002\n",
      "Epoch 1730, Loss: 0.00024156001018127427, Final Batch Loss: 0.00013565845438279212\n",
      "Epoch 1731, Loss: 0.0005849169338034699, Final Batch Loss: 1.0381010724813677e-05\n",
      "Epoch 1732, Loss: 0.00023849918125051772, Final Batch Loss: 0.000227643278776668\n",
      "Epoch 1733, Loss: 0.0003476254205452278, Final Batch Loss: 0.0002882278640754521\n",
      "Epoch 1734, Loss: 0.0005463327106554061, Final Batch Loss: 0.00025573201128281653\n",
      "Epoch 1735, Loss: 0.0007128884026315063, Final Batch Loss: 0.00037906167563050985\n",
      "Epoch 1736, Loss: 0.00018409868062008172, Final Batch Loss: 0.000168196129379794\n",
      "Epoch 1737, Loss: 0.0023093015188351274, Final Batch Loss: 0.0017729593673720956\n",
      "Epoch 1738, Loss: 0.007073736494930927, Final Batch Loss: 3.578115865821019e-05\n",
      "Epoch 1739, Loss: 0.00020539616525638849, Final Batch Loss: 0.00014429692237172276\n",
      "Epoch 1740, Loss: 0.005338517661584774, Final Batch Loss: 0.005284283775836229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1741, Loss: 0.0011567046203708742, Final Batch Loss: 4.370103488327004e-05\n",
      "Epoch 1742, Loss: 0.0001297347916988656, Final Batch Loss: 6.158498581498861e-05\n",
      "Epoch 1743, Loss: 0.0001416241120750783, Final Batch Loss: 0.00011787948460550979\n",
      "Epoch 1744, Loss: 0.00047156683649518527, Final Batch Loss: 5.884835627512075e-05\n",
      "Epoch 1745, Loss: 0.00016610736565780826, Final Batch Loss: 0.00011968037870246917\n",
      "Epoch 1746, Loss: 0.0005391890881583095, Final Batch Loss: 0.00027028672047890723\n",
      "Epoch 1747, Loss: 0.004967679356923327, Final Batch Loss: 0.00038433269946835935\n",
      "Epoch 1748, Loss: 0.0002647753844939871, Final Batch Loss: 0.00023538216191809624\n",
      "Epoch 1749, Loss: 0.002602779699373059, Final Batch Loss: 0.0024730167351663113\n",
      "Epoch 1750, Loss: 0.003220040933229029, Final Batch Loss: 9.765417780727148e-05\n",
      "Epoch 1751, Loss: 0.0011742807109840214, Final Batch Loss: 0.000994830159470439\n",
      "Epoch 1752, Loss: 0.00012049736324115656, Final Batch Loss: 8.454995258944109e-05\n",
      "Epoch 1753, Loss: 0.0047882455110084265, Final Batch Loss: 0.0003287428698968142\n",
      "Epoch 1754, Loss: 0.0004893314035143703, Final Batch Loss: 0.00029045416158623993\n",
      "Epoch 1755, Loss: 0.0066805099486373365, Final Batch Loss: 0.0063079060055315495\n",
      "Epoch 1756, Loss: 0.00023808685364201665, Final Batch Loss: 0.00020385136303957552\n",
      "Epoch 1757, Loss: 6.317454608506523e-05, Final Batch Loss: 1.7323996871709824e-05\n",
      "Epoch 1758, Loss: 0.000907820271095261, Final Batch Loss: 0.0008237260626628995\n",
      "Epoch 1759, Loss: 0.0030208516764105298, Final Batch Loss: 5.1407878345344216e-05\n",
      "Epoch 1760, Loss: 0.0004844837967539206, Final Batch Loss: 0.00017567614850122482\n",
      "Epoch 1761, Loss: 0.0008319883490912616, Final Batch Loss: 0.0003389365738257766\n",
      "Epoch 1762, Loss: 0.00036497895780485123, Final Batch Loss: 0.00033742020605131984\n",
      "Epoch 1763, Loss: 0.004775191657245159, Final Batch Loss: 0.0010436903685331345\n",
      "Epoch 1764, Loss: 0.0007249298796523362, Final Batch Loss: 0.0002985241881106049\n",
      "Epoch 1765, Loss: 8.523017095285468e-05, Final Batch Loss: 5.216592762735672e-05\n",
      "Epoch 1766, Loss: 0.0007689575249969494, Final Batch Loss: 4.026274473289959e-05\n",
      "Epoch 1767, Loss: 0.0023070180614013225, Final Batch Loss: 0.0020055510103702545\n",
      "Epoch 1768, Loss: 0.0005136452527949587, Final Batch Loss: 0.0002253544080303982\n",
      "Epoch 1769, Loss: 0.0002373010247538332, Final Batch Loss: 4.498855923884548e-05\n",
      "Epoch 1770, Loss: 0.00030507412157021463, Final Batch Loss: 0.00014220444427337497\n",
      "Epoch 1771, Loss: 0.0018661763169802725, Final Batch Loss: 0.0014774433802813292\n",
      "Epoch 1772, Loss: 0.0019006466027349234, Final Batch Loss: 0.0008862949907779694\n",
      "Epoch 1773, Loss: 0.0005029986787121743, Final Batch Loss: 0.00038222078001126647\n",
      "Epoch 1774, Loss: 0.0026346194790676236, Final Batch Loss: 0.0004693578230217099\n",
      "Epoch 1775, Loss: 0.0023570035518787336, Final Batch Loss: 0.002324454253539443\n",
      "Epoch 1776, Loss: 0.00045134146785130724, Final Batch Loss: 5.7334684242960066e-05\n",
      "Epoch 1777, Loss: 0.0009210446924043936, Final Batch Loss: 1.2994064491067547e-05\n",
      "Epoch 1778, Loss: 0.0015532308025285602, Final Batch Loss: 0.0007900362252257764\n",
      "Epoch 1779, Loss: 0.00010494307935005054, Final Batch Loss: 8.074112702161074e-05\n",
      "Epoch 1780, Loss: 1.3268328984850086e-05, Final Batch Loss: 5.729445092583774e-06\n",
      "Epoch 1781, Loss: 0.0002422468678560108, Final Batch Loss: 5.360048089642078e-05\n",
      "Epoch 1782, Loss: 0.00030728959245607257, Final Batch Loss: 0.00015737365174572915\n",
      "Epoch 1783, Loss: 0.008042966859648004, Final Batch Loss: 0.007942141965031624\n",
      "Epoch 1784, Loss: 0.00025227086734957993, Final Batch Loss: 0.0001238795230165124\n",
      "Epoch 1785, Loss: 0.00019037276069866493, Final Batch Loss: 2.128633059328422e-05\n",
      "Epoch 1786, Loss: 0.00011599005119933281, Final Batch Loss: 1.8360618923907168e-05\n",
      "Epoch 1787, Loss: 0.0003675023399409838, Final Batch Loss: 0.0002917028614319861\n",
      "Epoch 1788, Loss: 0.001006440619676141, Final Batch Loss: 0.0009684900869615376\n",
      "Epoch 1789, Loss: 0.004289713002435747, Final Batch Loss: 2.4989492885651998e-05\n",
      "Epoch 1790, Loss: 0.00028088217368349433, Final Batch Loss: 0.00020599912386387587\n",
      "Epoch 1791, Loss: 0.00139764926279895, Final Batch Loss: 0.0011806328548118472\n",
      "Epoch 1792, Loss: 0.00012674762547248974, Final Batch Loss: 5.397582572186366e-05\n",
      "Epoch 1793, Loss: 0.00014979191473685205, Final Batch Loss: 7.953336898935959e-05\n",
      "Epoch 1794, Loss: 0.00015915633957774844, Final Batch Loss: 1.8937489585368894e-05\n",
      "Epoch 1795, Loss: 0.0003398796761757694, Final Batch Loss: 0.00027024696464650333\n",
      "Epoch 1796, Loss: 0.0007374874694505706, Final Batch Loss: 0.0006274708430282772\n",
      "Epoch 1797, Loss: 0.00012054558828822337, Final Batch Loss: 8.47370465635322e-05\n",
      "Epoch 1798, Loss: 0.004176567090325989, Final Batch Loss: 3.221376391593367e-05\n",
      "Epoch 1799, Loss: 0.009935645342920907, Final Batch Loss: 0.009836588054895401\n",
      "Epoch 1800, Loss: 0.00020492469047894701, Final Batch Loss: 8.863425318850204e-05\n",
      "Epoch 1801, Loss: 0.001208653060530196, Final Batch Loss: 2.1469748389790766e-05\n",
      "Epoch 1802, Loss: 0.00031070706791069824, Final Batch Loss: 2.0765308363479562e-05\n",
      "Epoch 1803, Loss: 0.00028123749143560417, Final Batch Loss: 5.101757778902538e-05\n",
      "Epoch 1804, Loss: 0.00024355639106943272, Final Batch Loss: 5.4521482525160536e-05\n",
      "Epoch 1805, Loss: 0.010995407406880986, Final Batch Loss: 0.010916856117546558\n",
      "Epoch 1806, Loss: 0.0030454195803031325, Final Batch Loss: 0.0016326919430866838\n",
      "Epoch 1807, Loss: 0.0007788946095388383, Final Batch Loss: 0.0007020373595878482\n",
      "Epoch 1808, Loss: 0.00020801983191631734, Final Batch Loss: 4.363399057183415e-05\n",
      "Epoch 1809, Loss: 0.00017147411381301936, Final Batch Loss: 2.47962507273769e-05\n",
      "Epoch 1810, Loss: 0.0007158087391871959, Final Batch Loss: 0.0003598828916437924\n",
      "Epoch 1811, Loss: 0.0001260423396161059, Final Batch Loss: 2.7024487280868925e-05\n",
      "Epoch 1812, Loss: 0.00017671333534963196, Final Batch Loss: 5.936394700256642e-06\n",
      "Epoch 1813, Loss: 0.0005803380772704259, Final Batch Loss: 0.00012883277668152004\n",
      "Epoch 1814, Loss: 0.0005066829035058618, Final Batch Loss: 0.0002537030086386949\n",
      "Epoch 1815, Loss: 0.0024539725254726363, Final Batch Loss: 2.5127721528406255e-05\n",
      "Epoch 1816, Loss: 0.0001684770977590233, Final Batch Loss: 0.00010090555588249117\n",
      "Epoch 1817, Loss: 0.0005286191590130329, Final Batch Loss: 0.0003738389350473881\n",
      "Epoch 1818, Loss: 0.0002251017704111291, Final Batch Loss: 1.0850691978703253e-05\n",
      "Epoch 1819, Loss: 0.0006765371072106063, Final Batch Loss: 0.0005606726044788957\n",
      "Epoch 1820, Loss: 0.00011053740763600217, Final Batch Loss: 7.652231033716816e-06\n",
      "Epoch 1821, Loss: 0.00010709127127483953, Final Batch Loss: 2.4977738576126285e-05\n",
      "Epoch 1822, Loss: 0.0019284449581391527, Final Batch Loss: 1.2633047845156398e-05\n",
      "Epoch 1823, Loss: 0.0033191366237588227, Final Batch Loss: 0.0001903367810882628\n",
      "Epoch 1824, Loss: 0.00023359955957857892, Final Batch Loss: 6.952496914891526e-05\n",
      "Epoch 1825, Loss: 0.0004171437285549473, Final Batch Loss: 5.3988023864803836e-05\n",
      "Epoch 1826, Loss: 0.004120271993087954, Final Batch Loss: 2.4865255909389816e-05\n",
      "Epoch 1827, Loss: 0.00022934298613108695, Final Batch Loss: 3.560868208296597e-05\n",
      "Epoch 1828, Loss: 0.00023086369401426055, Final Batch Loss: 5.2564111683750525e-05\n",
      "Epoch 1829, Loss: 0.0007037262548692524, Final Batch Loss: 0.00042790634324774146\n",
      "Epoch 1830, Loss: 0.00040154592716135085, Final Batch Loss: 0.00023660909209866077\n",
      "Epoch 1831, Loss: 0.00033006793091772124, Final Batch Loss: 3.1298921385314316e-05\n",
      "Epoch 1832, Loss: 0.000355691256118007, Final Batch Loss: 0.00025224615819752216\n",
      "Epoch 1833, Loss: 8.245845128840301e-05, Final Batch Loss: 2.394951479800511e-05\n",
      "Epoch 1834, Loss: 0.00046369679330382496, Final Batch Loss: 0.0003290807653684169\n",
      "Epoch 1835, Loss: 0.0003167570976074785, Final Batch Loss: 6.986749940551817e-05\n",
      "Epoch 1836, Loss: 0.0035864198180206586, Final Batch Loss: 2.37321546592284e-05\n",
      "Epoch 1837, Loss: 0.0005055478250142187, Final Batch Loss: 9.771829354576766e-05\n",
      "Epoch 1838, Loss: 0.0019204641284886748, Final Batch Loss: 0.00023756505106575787\n",
      "Epoch 1839, Loss: 0.0009490023148828186, Final Batch Loss: 8.68197312229313e-05\n",
      "Epoch 1840, Loss: 0.0002363847816013731, Final Batch Loss: 0.0001329670485574752\n",
      "Epoch 1841, Loss: 0.0016286131794913672, Final Batch Loss: 0.001536519848741591\n",
      "Epoch 1842, Loss: 0.0030999020382296294, Final Batch Loss: 0.00020908910664729774\n",
      "Epoch 1843, Loss: 0.004754533874802291, Final Batch Loss: 0.0031533576548099518\n",
      "Epoch 1844, Loss: 0.012565238634124398, Final Batch Loss: 0.012392749078571796\n",
      "Epoch 1845, Loss: 0.013061046367511153, Final Batch Loss: 0.009814148768782616\n",
      "Epoch 1846, Loss: 0.001377288528601639, Final Batch Loss: 0.0012503060279414058\n",
      "Epoch 1847, Loss: 0.0002637767029227689, Final Batch Loss: 6.447674240916967e-05\n",
      "Epoch 1848, Loss: 0.0004596537837642245, Final Batch Loss: 0.00035504921106621623\n",
      "Epoch 1849, Loss: 0.0001256318519153865, Final Batch Loss: 2.0440662410692312e-05\n",
      "Epoch 1850, Loss: 0.00020309923274908215, Final Batch Loss: 7.486596587114036e-05\n",
      "Epoch 1851, Loss: 0.00043822400402859785, Final Batch Loss: 3.1763254810357466e-05\n",
      "Epoch 1852, Loss: 0.00033952896774280816, Final Batch Loss: 0.00020996751845814288\n",
      "Epoch 1853, Loss: 0.00010565959382802248, Final Batch Loss: 4.5300144847715273e-05\n",
      "Epoch 1854, Loss: 0.007529871980295866, Final Batch Loss: 0.0075025917030870914\n",
      "Epoch 1855, Loss: 0.0006966942019062117, Final Batch Loss: 7.105573604349047e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1856, Loss: 0.0011939414289372507, Final Batch Loss: 4.3146053940290585e-05\n",
      "Epoch 1857, Loss: 0.00021093396389915142, Final Batch Loss: 0.00018884730525314808\n",
      "Epoch 1858, Loss: 0.0047498634667135775, Final Batch Loss: 0.0002680817269720137\n",
      "Epoch 1859, Loss: 0.001175919813249493, Final Batch Loss: 1.3653454516315833e-05\n",
      "Epoch 1860, Loss: 0.00020089893223484978, Final Batch Loss: 9.880105062620714e-05\n",
      "Epoch 1861, Loss: 0.0047306933120125905, Final Batch Loss: 0.00012354717182461172\n",
      "Epoch 1862, Loss: 0.0004623670829460025, Final Batch Loss: 0.00029589186306111515\n",
      "Epoch 1863, Loss: 0.0006049095100024715, Final Batch Loss: 0.00046286056749522686\n",
      "Epoch 1864, Loss: 0.0003666820211947197, Final Batch Loss: 2.501731250958983e-05\n",
      "Epoch 1865, Loss: 0.00821435684338212, Final Batch Loss: 0.00043202750384807587\n",
      "Epoch 1866, Loss: 0.0001415838905813871, Final Batch Loss: 1.166209221992176e-05\n",
      "Epoch 1867, Loss: 0.0002007188886636868, Final Batch Loss: 0.00014641320740338415\n",
      "Epoch 1868, Loss: 0.004878177511272952, Final Batch Loss: 0.004696554504334927\n",
      "Epoch 1869, Loss: 0.0005200019077165052, Final Batch Loss: 0.0003102346381638199\n",
      "Epoch 1870, Loss: 0.00018380383789917687, Final Batch Loss: 1.5258433450071607e-05\n",
      "Epoch 1871, Loss: 0.00013343615501071326, Final Batch Loss: 5.882361074327491e-05\n",
      "Epoch 1872, Loss: 0.00019564890817491687, Final Batch Loss: 4.248483946867054e-06\n",
      "Epoch 1873, Loss: 0.0004209219096082961, Final Batch Loss: 2.8498083338490687e-05\n",
      "Epoch 1874, Loss: 0.001152462573372759, Final Batch Loss: 0.0009669661521911621\n",
      "Epoch 1875, Loss: 0.00023122664424590766, Final Batch Loss: 0.0001270326174562797\n",
      "Epoch 1876, Loss: 0.00043329058280505706, Final Batch Loss: 2.682942613319028e-05\n",
      "Epoch 1877, Loss: 0.004291475808713585, Final Batch Loss: 0.00012481171870604157\n",
      "Epoch 1878, Loss: 0.0003601960352170863, Final Batch Loss: 1.3114143257553224e-05\n",
      "Epoch 1879, Loss: 0.0012412858741299715, Final Batch Loss: 1.908366903080605e-05\n",
      "Epoch 1880, Loss: 0.0009773721976671368, Final Batch Loss: 0.0008552196668460965\n",
      "Epoch 1881, Loss: 0.0016286450263578445, Final Batch Loss: 0.00042369464063085616\n",
      "Epoch 1882, Loss: 0.0003164388908771798, Final Batch Loss: 5.256517033558339e-05\n",
      "Epoch 1883, Loss: 0.0006075377605156973, Final Batch Loss: 0.0004329203220549971\n",
      "Epoch 1884, Loss: 0.00019248111675551627, Final Batch Loss: 1.9885419533238746e-05\n",
      "Epoch 1885, Loss: 0.0037496579352591652, Final Batch Loss: 8.321181667270139e-06\n",
      "Epoch 1886, Loss: 0.0003409431028558174, Final Batch Loss: 1.7820619177655317e-05\n",
      "Epoch 1887, Loss: 0.0002468148340994958, Final Batch Loss: 4.9538419261807576e-05\n",
      "Epoch 1888, Loss: 0.0040492546977475286, Final Batch Loss: 0.00039664527866989374\n",
      "Epoch 1889, Loss: 5.371974111767486e-05, Final Batch Loss: 8.554270607419312e-06\n",
      "Epoch 1890, Loss: 0.003829556038908777, Final Batch Loss: 1.7268337614950724e-05\n",
      "Epoch 1891, Loss: 0.005929310020292178, Final Batch Loss: 7.701167487539351e-05\n",
      "Epoch 1892, Loss: 0.0011155088884606812, Final Batch Loss: 1.5966813862178242e-06\n",
      "Epoch 1893, Loss: 0.0006887053968966939, Final Batch Loss: 8.56756596476771e-05\n",
      "Epoch 1894, Loss: 0.00022260086188907735, Final Batch Loss: 0.000166913858265616\n",
      "Epoch 1895, Loss: 0.002062027568172198, Final Batch Loss: 0.0019911015406250954\n",
      "Epoch 1896, Loss: 0.00010134996045962907, Final Batch Loss: 3.3783773687900975e-05\n",
      "Epoch 1897, Loss: 0.00021554962495429209, Final Batch Loss: 1.3575517186836805e-05\n",
      "Epoch 1898, Loss: 6.946925714146346e-05, Final Batch Loss: 8.914292266126722e-06\n",
      "Epoch 1899, Loss: 0.0005352193693397567, Final Batch Loss: 3.8438287447206676e-05\n",
      "Epoch 1900, Loss: 0.001542373214761028, Final Batch Loss: 4.9814469093689695e-05\n",
      "Epoch 1901, Loss: 0.0029078605948598124, Final Batch Loss: 8.556646207580343e-05\n",
      "Epoch 1902, Loss: 8.60372674651444e-05, Final Batch Loss: 2.3498112568631768e-05\n",
      "Epoch 1903, Loss: 0.0035142577689839527, Final Batch Loss: 8.479230746161193e-05\n",
      "Epoch 1904, Loss: 0.0002900404142565094, Final Batch Loss: 0.0001944077666848898\n",
      "Epoch 1905, Loss: 6.245805434446083e-05, Final Batch Loss: 1.3596022654382978e-05\n",
      "Epoch 1906, Loss: 0.0007318439747905359, Final Batch Loss: 0.0006272902246564627\n",
      "Epoch 1907, Loss: 0.0005327821272658184, Final Batch Loss: 0.0001454312150599435\n",
      "Epoch 1908, Loss: 0.00033861446354421787, Final Batch Loss: 2.788538040476851e-05\n",
      "Epoch 1909, Loss: 7.3606595833553e-05, Final Batch Loss: 3.869983265758492e-05\n",
      "Epoch 1910, Loss: 0.00023541913287772331, Final Batch Loss: 0.00021604789071716368\n",
      "Epoch 1911, Loss: 0.0009437122498638928, Final Batch Loss: 0.00020667072385549545\n",
      "Epoch 1912, Loss: 0.0003502752479107585, Final Batch Loss: 1.397073719999753e-05\n",
      "Epoch 1913, Loss: 5.157363966645789e-05, Final Batch Loss: 3.3576839086890686e-06\n",
      "Epoch 1914, Loss: 0.0001825705203373218, Final Batch Loss: 2.5503783035674132e-05\n",
      "Epoch 1915, Loss: 0.0013705146411666647, Final Batch Loss: 0.0012214340968057513\n",
      "Epoch 1916, Loss: 0.010741227946709841, Final Batch Loss: 0.0006966923247091472\n",
      "Epoch 1917, Loss: 3.185994137311354e-05, Final Batch Loss: 7.358123184530996e-06\n",
      "Epoch 1918, Loss: 7.482266846636776e-05, Final Batch Loss: 6.502210453618318e-05\n",
      "Epoch 1919, Loss: 7.797651051077992e-05, Final Batch Loss: 5.210487870499492e-06\n",
      "Epoch 1920, Loss: 0.0018328054866287857, Final Batch Loss: 7.726499461568892e-05\n",
      "Epoch 1921, Loss: 0.0004443329744390212, Final Batch Loss: 0.0003346443991176784\n",
      "Epoch 1922, Loss: 0.00025200565141858533, Final Batch Loss: 0.00020544877042993903\n",
      "Epoch 1923, Loss: 0.0005240080499788746, Final Batch Loss: 0.00014203980390448123\n",
      "Epoch 1924, Loss: 0.00034899567253887653, Final Batch Loss: 2.0445208065211773e-05\n",
      "Epoch 1925, Loss: 0.00671472807880491, Final Batch Loss: 0.0064859152771532536\n",
      "Epoch 1926, Loss: 0.0003318587696412578, Final Batch Loss: 9.908305946737528e-05\n",
      "Epoch 1927, Loss: 0.00032478491630172357, Final Batch Loss: 6.213751476025209e-05\n",
      "Epoch 1928, Loss: 0.0010703559455578215, Final Batch Loss: 0.0009609332773834467\n",
      "Epoch 1929, Loss: 0.00020020398005726747, Final Batch Loss: 0.0001521960220998153\n",
      "Epoch 1930, Loss: 8.759444244788028e-05, Final Batch Loss: 4.887286922894418e-05\n",
      "Epoch 1931, Loss: 0.00017163559095934033, Final Batch Loss: 8.711105328984559e-05\n",
      "Epoch 1932, Loss: 0.0006766760488972068, Final Batch Loss: 0.0004186356090940535\n",
      "Epoch 1933, Loss: 0.007874773204093799, Final Batch Loss: 0.000372888840502128\n",
      "Epoch 1934, Loss: 0.0003265976265538484, Final Batch Loss: 8.59167193993926e-05\n",
      "Epoch 1935, Loss: 5.427295263871201e-05, Final Batch Loss: 4.1982043512689415e-06\n",
      "Epoch 1936, Loss: 5.9652003983501345e-05, Final Batch Loss: 3.0488254196825437e-05\n",
      "Epoch 1937, Loss: 0.0019603414057201007, Final Batch Loss: 1.7095875591621734e-05\n",
      "Epoch 1938, Loss: 0.00022465160873252898, Final Batch Loss: 0.00010710528295021504\n",
      "Epoch 1939, Loss: 0.0018250793364131823, Final Batch Loss: 3.832428774330765e-05\n",
      "Epoch 1940, Loss: 0.008888241005479358, Final Batch Loss: 0.00015720176452305168\n",
      "Epoch 1941, Loss: 0.005375113629270345, Final Batch Loss: 0.0006983166676945984\n",
      "Epoch 1942, Loss: 7.309890497708693e-05, Final Batch Loss: 2.2291322238743305e-05\n",
      "Epoch 1943, Loss: 0.0003988894241047092, Final Batch Loss: 9.189415868604556e-05\n",
      "Epoch 1944, Loss: 0.0005290346089168452, Final Batch Loss: 0.0004383186751510948\n",
      "Epoch 1945, Loss: 0.00025878768792608753, Final Batch Loss: 2.1955340343993157e-05\n",
      "Epoch 1946, Loss: 0.00010364609624957666, Final Batch Loss: 2.8385809855535626e-05\n",
      "Epoch 1947, Loss: 0.004395056814246345, Final Batch Loss: 8.110778435366228e-05\n",
      "Epoch 1948, Loss: 0.00014424142500502057, Final Batch Loss: 5.276178490021266e-05\n",
      "Epoch 1949, Loss: 0.0002519087192922598, Final Batch Loss: 0.00022592009918298572\n",
      "Epoch 1950, Loss: 0.00027580019195738714, Final Batch Loss: 0.0002505726588424295\n",
      "Epoch 1951, Loss: 0.006771097177079355, Final Batch Loss: 0.006762821692973375\n",
      "Epoch 1952, Loss: 0.02164041087962687, Final Batch Loss: 0.018875159323215485\n",
      "Epoch 1953, Loss: 0.00026650752442947123, Final Batch Loss: 1.589694329595659e-05\n",
      "Epoch 1954, Loss: 0.000238768698181957, Final Batch Loss: 0.000201289018150419\n",
      "Epoch 1955, Loss: 0.0002444719066261314, Final Batch Loss: 0.0001280519354622811\n",
      "Epoch 1956, Loss: 0.00036054632801096886, Final Batch Loss: 8.036756480578333e-05\n",
      "Epoch 1957, Loss: 0.0012196645220683422, Final Batch Loss: 0.0012152920244261622\n",
      "Epoch 1958, Loss: 0.0005353902452043258, Final Batch Loss: 0.000494795327540487\n",
      "Epoch 1959, Loss: 0.0005391897866502404, Final Batch Loss: 0.00027756026247516274\n",
      "Epoch 1960, Loss: 0.0007368479855358601, Final Batch Loss: 0.0001461475039832294\n",
      "Epoch 1961, Loss: 0.00035256844421382993, Final Batch Loss: 4.836161679122597e-05\n",
      "Epoch 1962, Loss: 0.0003612171858549118, Final Batch Loss: 0.00019885163055732846\n",
      "Epoch 1963, Loss: 0.0007681848364882171, Final Batch Loss: 0.0003171757562085986\n",
      "Epoch 1964, Loss: 0.0023535869768238626, Final Batch Loss: 4.190860636299476e-05\n",
      "Epoch 1965, Loss: 0.0014182903178152628, Final Batch Loss: 4.5820379455108196e-05\n",
      "Epoch 1966, Loss: 0.00042294120066799223, Final Batch Loss: 0.00013039345503784716\n",
      "Epoch 1967, Loss: 0.006875442108139396, Final Batch Loss: 0.002395963529124856\n",
      "Epoch 1968, Loss: 0.0003818234963546274, Final Batch Loss: 1.7748227037373e-05\n",
      "Epoch 1969, Loss: 0.0002058919235423673, Final Batch Loss: 0.00017079159442801028\n",
      "Epoch 1970, Loss: 0.0001462217805965338, Final Batch Loss: 3.1593259336659685e-05\n",
      "Epoch 1971, Loss: 0.0002702157580642961, Final Batch Loss: 5.6894779845606536e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1972, Loss: 0.00010582848881313112, Final Batch Loss: 8.134901145240292e-05\n",
      "Epoch 1973, Loss: 0.00028496430604718626, Final Batch Loss: 9.392085485160351e-05\n",
      "Epoch 1974, Loss: 0.0006806126184528694, Final Batch Loss: 0.00014891817409079522\n",
      "Epoch 1975, Loss: 7.122125316527672e-05, Final Batch Loss: 5.15284737048205e-05\n",
      "Epoch 1976, Loss: 0.00023913046607049182, Final Batch Loss: 0.00022353415261022747\n",
      "Epoch 1977, Loss: 0.0001236026691913139, Final Batch Loss: 5.828871871926822e-05\n",
      "Epoch 1978, Loss: 0.000995537731796503, Final Batch Loss: 0.0008242311305366457\n",
      "Epoch 1979, Loss: 0.00016423415945610031, Final Batch Loss: 6.352365744533017e-05\n",
      "Epoch 1980, Loss: 9.088196384254843e-05, Final Batch Loss: 5.467467417474836e-05\n",
      "Epoch 1981, Loss: 0.006990864727413282, Final Batch Loss: 8.466592407785356e-05\n",
      "Epoch 1982, Loss: 0.0007779192092129961, Final Batch Loss: 0.00017305360233876854\n",
      "Epoch 1983, Loss: 0.00012184301886009052, Final Batch Loss: 2.4168926756829023e-05\n",
      "Epoch 1984, Loss: 5.7447941799182445e-05, Final Batch Loss: 1.9028113456442952e-05\n",
      "Epoch 1985, Loss: 0.0002450451720505953, Final Batch Loss: 0.00014226543135009706\n",
      "Epoch 1986, Loss: 0.0027399202808737755, Final Batch Loss: 0.0002767492551356554\n",
      "Epoch 1987, Loss: 0.006073356664273888, Final Batch Loss: 0.005552990362048149\n",
      "Epoch 1988, Loss: 0.005299806362017989, Final Batch Loss: 0.002517649671062827\n",
      "Epoch 1989, Loss: 0.002458910079440102, Final Batch Loss: 0.000266951130470261\n",
      "Epoch 1990, Loss: 0.0002498671419743914, Final Batch Loss: 0.00019627445726655424\n",
      "Epoch 1991, Loss: 0.0003889683139277622, Final Batch Loss: 0.0002467054291628301\n",
      "Epoch 1992, Loss: 0.00020891134408884682, Final Batch Loss: 0.00015464791795238853\n",
      "Epoch 1993, Loss: 0.00020970697005395778, Final Batch Loss: 0.00017402104276698083\n",
      "Epoch 1994, Loss: 0.006297941963794074, Final Batch Loss: 2.161312522730441e-06\n",
      "Epoch 1995, Loss: 5.980369132885244e-05, Final Batch Loss: 3.602890865295194e-05\n",
      "Epoch 1996, Loss: 9.768367453943938e-05, Final Batch Loss: 1.6790007066447288e-05\n",
      "Epoch 1997, Loss: 9.534167111269198e-05, Final Batch Loss: 8.727894601179287e-05\n",
      "Epoch 1998, Loss: 0.0010823047196026891, Final Batch Loss: 0.00035384573857299984\n",
      "Epoch 1999, Loss: 0.0003882480305037461, Final Batch Loss: 0.0002984549500979483\n",
      "Epoch 2000, Loss: 0.00022032426568330266, Final Batch Loss: 0.00018961229943670332\n",
      "Epoch 2001, Loss: 6.620493422815343e-05, Final Batch Loss: 5.389925354393199e-05\n",
      "Epoch 2002, Loss: 0.00015868451214373636, Final Batch Loss: 3.725605211002403e-06\n",
      "Epoch 2003, Loss: 0.00046316630687215365, Final Batch Loss: 4.608449671650305e-06\n",
      "Epoch 2004, Loss: 0.0002491380728315562, Final Batch Loss: 7.867382373660803e-05\n",
      "Epoch 2005, Loss: 0.00043379437647672603, Final Batch Loss: 5.441405846795533e-06\n",
      "Epoch 2006, Loss: 0.001319904054980725, Final Batch Loss: 0.0009260360384359956\n",
      "Epoch 2007, Loss: 0.00031028779631014913, Final Batch Loss: 0.0001539549557492137\n",
      "Epoch 2008, Loss: 0.004707662796135992, Final Batch Loss: 0.000910708389710635\n",
      "Epoch 2009, Loss: 0.00033500612335046753, Final Batch Loss: 6.583367212442681e-05\n",
      "Epoch 2010, Loss: 0.003389547848200891, Final Batch Loss: 0.003331464482471347\n",
      "Epoch 2011, Loss: 0.002765893266769126, Final Batch Loss: 0.00026174032245762646\n",
      "Epoch 2012, Loss: 6.201218639034778e-05, Final Batch Loss: 3.5581782867666334e-05\n",
      "Epoch 2013, Loss: 0.0001244918266820605, Final Batch Loss: 0.0001103010872611776\n",
      "Epoch 2014, Loss: 0.00023005741240922362, Final Batch Loss: 0.00010252496576867998\n",
      "Epoch 2015, Loss: 0.00024882384605007246, Final Batch Loss: 8.267914381576702e-05\n",
      "Epoch 2016, Loss: 0.00024069483333732933, Final Batch Loss: 6.784223660361022e-05\n",
      "Epoch 2017, Loss: 4.8563945938440156e-05, Final Batch Loss: 3.7361926388257416e-06\n",
      "Epoch 2018, Loss: 0.0003704886112245731, Final Batch Loss: 0.0002887306036427617\n",
      "Epoch 2019, Loss: 0.00028685031429631636, Final Batch Loss: 0.00022187535068951547\n",
      "Epoch 2020, Loss: 0.00041863188380375504, Final Batch Loss: 0.00033073799568228424\n",
      "Epoch 2021, Loss: 0.0005582925368798897, Final Batch Loss: 0.00033443639404140413\n",
      "Epoch 2022, Loss: 6.00147686782293e-05, Final Batch Loss: 2.8902195481350645e-05\n",
      "Epoch 2023, Loss: 0.00044356874423101544, Final Batch Loss: 0.0001521719095762819\n",
      "Epoch 2024, Loss: 0.0010674500663299114, Final Batch Loss: 3.9992184611037374e-05\n",
      "Epoch 2025, Loss: 0.0020857734657511173, Final Batch Loss: 5.3841672524868045e-06\n",
      "Epoch 2026, Loss: 0.0007657374371774495, Final Batch Loss: 0.0006010186043567955\n",
      "Epoch 2027, Loss: 0.004550514473521616, Final Batch Loss: 0.00010301285510649905\n",
      "Epoch 2028, Loss: 0.00018625296070240438, Final Batch Loss: 3.919271694030613e-05\n",
      "Epoch 2029, Loss: 0.00015309668287954992, Final Batch Loss: 1.4416552403417882e-05\n",
      "Epoch 2030, Loss: 0.0010568558645900339, Final Batch Loss: 0.0008618011488579214\n",
      "Epoch 2031, Loss: 0.0003318582457723096, Final Batch Loss: 0.00018132747209165245\n",
      "Epoch 2032, Loss: 0.00023147595311456826, Final Batch Loss: 2.65868930000579e-05\n",
      "Epoch 2033, Loss: 0.0013708077021874487, Final Batch Loss: 0.0004565923591144383\n",
      "Epoch 2034, Loss: 0.007793956960085779, Final Batch Loss: 0.006937110330909491\n",
      "Epoch 2035, Loss: 8.67983962962171e-05, Final Batch Loss: 6.0673013649648055e-05\n",
      "Epoch 2036, Loss: 7.95300438767299e-05, Final Batch Loss: 8.311290002893656e-06\n",
      "Epoch 2037, Loss: 0.0004159551172051579, Final Batch Loss: 2.6025983970612288e-05\n",
      "Epoch 2038, Loss: 0.016698377122793318, Final Batch Loss: 0.016694173216819763\n",
      "Epoch 2039, Loss: 0.0001265900700673228, Final Batch Loss: 0.00011480981629574671\n",
      "Epoch 2040, Loss: 0.003659662943391595, Final Batch Loss: 7.394669955829158e-05\n",
      "Epoch 2041, Loss: 0.0006623155993565888, Final Batch Loss: 0.0006585756782442331\n",
      "Epoch 2042, Loss: 0.006710371235385537, Final Batch Loss: 0.006348868366330862\n",
      "Epoch 2043, Loss: 0.0008703405619598925, Final Batch Loss: 0.0007470340351574123\n",
      "Epoch 2044, Loss: 8.716742104297737e-05, Final Batch Loss: 9.370815860165749e-06\n",
      "Epoch 2045, Loss: 0.003013997305970406, Final Batch Loss: 5.059802424511872e-05\n",
      "Epoch 2046, Loss: 0.00011747572716558352, Final Batch Loss: 1.8103506590705365e-05\n",
      "Epoch 2047, Loss: 3.7315998270059936e-05, Final Batch Loss: 1.5104964404599741e-05\n",
      "Epoch 2048, Loss: 0.0008248204940173309, Final Batch Loss: 5.33555394213181e-05\n",
      "Epoch 2049, Loss: 0.022583759295230266, Final Batch Loss: 9.57575612119399e-05\n",
      "Epoch 2050, Loss: 0.00024975157430162653, Final Batch Loss: 0.0001811942202039063\n",
      "Epoch 2051, Loss: 0.0002770861392491497, Final Batch Loss: 6.05697205173783e-05\n",
      "Epoch 2052, Loss: 3.723413283296395e-05, Final Batch Loss: 1.7406528058927506e-05\n",
      "Epoch 2053, Loss: 8.161782034221687e-05, Final Batch Loss: 3.0156575121509377e-06\n",
      "Epoch 2054, Loss: 0.00022828403598396108, Final Batch Loss: 0.00010113341704709455\n",
      "Epoch 2055, Loss: 6.806310375395697e-05, Final Batch Loss: 2.9250479201436974e-05\n",
      "Epoch 2056, Loss: 0.00018752417599898763, Final Batch Loss: 3.3261083444813266e-05\n",
      "Epoch 2057, Loss: 3.243846549594309e-05, Final Batch Loss: 1.6965665054158308e-05\n",
      "Epoch 2058, Loss: 0.0004407288579386659, Final Batch Loss: 0.0003799845289904624\n",
      "Epoch 2059, Loss: 0.0006702851096633822, Final Batch Loss: 0.00025844102492555976\n",
      "Epoch 2060, Loss: 5.2183811931172386e-05, Final Batch Loss: 2.9197964977356605e-05\n",
      "Epoch 2061, Loss: 3.24056400131667e-05, Final Batch Loss: 1.9110448192805052e-05\n",
      "Epoch 2062, Loss: 0.0004173819543211721, Final Batch Loss: 9.962062904378399e-05\n",
      "Epoch 2063, Loss: 0.00022339788120007142, Final Batch Loss: 8.372309821425006e-05\n",
      "Epoch 2064, Loss: 8.83165866980562e-05, Final Batch Loss: 9.80279037321452e-06\n",
      "Epoch 2065, Loss: 7.488847950298805e-05, Final Batch Loss: 4.5031112676952034e-05\n",
      "Epoch 2066, Loss: 5.923311982769519e-05, Final Batch Loss: 2.964240593428258e-05\n",
      "Epoch 2067, Loss: 0.0003869446227326989, Final Batch Loss: 5.5580021580681205e-05\n",
      "Epoch 2068, Loss: 0.0007067258629831485, Final Batch Loss: 2.807308192132041e-05\n",
      "Epoch 2069, Loss: 0.0006220285722520202, Final Batch Loss: 0.00012615005834959447\n",
      "Epoch 2070, Loss: 6.537745412060758e-05, Final Batch Loss: 5.46064147783909e-05\n",
      "Epoch 2071, Loss: 0.000565882190130651, Final Batch Loss: 0.0004932210431434214\n",
      "Epoch 2072, Loss: 6.523867705254816e-05, Final Batch Loss: 3.83107180823572e-06\n",
      "Epoch 2073, Loss: 0.00023645661622140324, Final Batch Loss: 9.268026587960776e-06\n",
      "Epoch 2074, Loss: 0.0006523437768919393, Final Batch Loss: 0.00015713069296907634\n",
      "Epoch 2075, Loss: 0.00011307111526548397, Final Batch Loss: 1.1153095329063945e-05\n",
      "Epoch 2076, Loss: 0.0005047218437539414, Final Batch Loss: 0.00040736401570029557\n",
      "Epoch 2077, Loss: 7.19106724318408e-05, Final Batch Loss: 7.068760169204324e-05\n",
      "Epoch 2078, Loss: 0.00019026667268917663, Final Batch Loss: 8.475765753246378e-06\n",
      "Epoch 2079, Loss: 0.0002692609868972795, Final Batch Loss: 0.00026025809347629547\n",
      "Epoch 2080, Loss: 0.00014976163220126182, Final Batch Loss: 7.347189966822043e-05\n",
      "Epoch 2081, Loss: 0.0006491349777206779, Final Batch Loss: 0.00029465853003785014\n",
      "Epoch 2082, Loss: 9.040731856657658e-05, Final Batch Loss: 8.091904601315036e-05\n",
      "Epoch 2083, Loss: 0.00117399020382436, Final Batch Loss: 4.2085426684934646e-05\n",
      "Epoch 2084, Loss: 0.005168175033759326, Final Batch Loss: 0.0008425015839748085\n",
      "Epoch 2085, Loss: 0.00042748994019348174, Final Batch Loss: 0.00035128105082549155\n",
      "Epoch 2086, Loss: 0.01064743901224574, Final Batch Loss: 0.010576625354588032\n",
      "Epoch 2087, Loss: 0.000426293678174261, Final Batch Loss: 0.00012177325697848573\n",
      "Epoch 2088, Loss: 1.4759211808268446e-05, Final Batch Loss: 6.4943051256705076e-06\n",
      "Epoch 2089, Loss: 0.00017330041009699926, Final Batch Loss: 0.00013832887634634972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2090, Loss: 0.0006827890829299577, Final Batch Loss: 0.0005825639236718416\n",
      "Epoch 2091, Loss: 3.1698069506092e-05, Final Batch Loss: 8.772231012699194e-06\n",
      "Epoch 2092, Loss: 0.0010844740900211036, Final Batch Loss: 0.00014138204278424382\n",
      "Epoch 2093, Loss: 1.2875957509095315e-05, Final Batch Loss: 7.656212801521178e-06\n",
      "Epoch 2094, Loss: 2.819684186761151e-05, Final Batch Loss: 2.1537538486882113e-05\n",
      "Epoch 2095, Loss: 0.00039103918243199587, Final Batch Loss: 0.0003179371415171772\n",
      "Epoch 2096, Loss: 0.0008934609377320157, Final Batch Loss: 0.0008852191385813057\n",
      "Epoch 2097, Loss: 0.005729641925427131, Final Batch Loss: 0.0056829690001904964\n",
      "Epoch 2098, Loss: 0.00017283312263316475, Final Batch Loss: 0.00013621203834190965\n",
      "Epoch 2099, Loss: 0.0006040165480953874, Final Batch Loss: 0.0005861980025656521\n",
      "Epoch 2100, Loss: 0.0004651228628063109, Final Batch Loss: 4.556975545710884e-05\n",
      "Epoch 2101, Loss: 1.0371338703407673e-05, Final Batch Loss: 1.4870151971990708e-06\n",
      "Epoch 2102, Loss: 6.501515326817753e-05, Final Batch Loss: 1.4434991499001626e-05\n",
      "Epoch 2103, Loss: 5.36611028110201e-05, Final Batch Loss: 4.892523429589346e-05\n",
      "Epoch 2104, Loss: 0.007031191431451589, Final Batch Loss: 0.006523200776427984\n",
      "Epoch 2105, Loss: 0.0022166198468767107, Final Batch Loss: 0.0019003348425030708\n",
      "Epoch 2106, Loss: 0.0005105856544105336, Final Batch Loss: 0.00043798191472887993\n",
      "Epoch 2107, Loss: 0.0009801158303162083, Final Batch Loss: 0.0007671367493458092\n",
      "Epoch 2108, Loss: 0.027606409043073654, Final Batch Loss: 0.018277181312441826\n",
      "Epoch 2109, Loss: 0.003618530769017525, Final Batch Loss: 3.6914905649609864e-05\n",
      "Epoch 2110, Loss: 0.0005498120735865086, Final Batch Loss: 0.00016735351528041065\n",
      "Epoch 2111, Loss: 0.0002159757714252919, Final Batch Loss: 1.539618824608624e-05\n",
      "Epoch 2112, Loss: 0.03026180900633335, Final Batch Loss: 0.020623352378606796\n",
      "Epoch 2113, Loss: 0.0003500566540424188, Final Batch Loss: 0.00034569494891911745\n",
      "Epoch 2114, Loss: 0.00017321461928077042, Final Batch Loss: 0.00012455125397536904\n",
      "Epoch 2115, Loss: 0.0005679176101693884, Final Batch Loss: 4.491729487199336e-05\n",
      "Epoch 2116, Loss: 0.007270718284416944, Final Batch Loss: 0.007017403841018677\n",
      "Epoch 2117, Loss: 6.719542761857156e-05, Final Batch Loss: 4.6573648432968184e-05\n",
      "Epoch 2118, Loss: 0.0004963942265021615, Final Batch Loss: 0.0004226071760058403\n",
      "Epoch 2119, Loss: 0.000394639719161205, Final Batch Loss: 0.0002508061588741839\n",
      "Epoch 2120, Loss: 0.0056458652743458515, Final Batch Loss: 0.00562176713719964\n",
      "Epoch 2121, Loss: 0.00818350218469277, Final Batch Loss: 0.007985898293554783\n",
      "Epoch 2122, Loss: 0.00033030015765689313, Final Batch Loss: 0.00026144605362787843\n",
      "Epoch 2123, Loss: 0.0021878722982364707, Final Batch Loss: 0.0021164193749427795\n",
      "Epoch 2124, Loss: 0.00022451314362115227, Final Batch Loss: 2.4592514819232747e-05\n",
      "Epoch 2125, Loss: 0.005436977353383554, Final Batch Loss: 3.426101102377288e-05\n",
      "Epoch 2126, Loss: 0.00014362470392370597, Final Batch Loss: 8.118851110339165e-05\n",
      "Epoch 2127, Loss: 0.0007322009259951301, Final Batch Loss: 0.0006498111179098487\n",
      "Epoch 2128, Loss: 0.0011280891194473952, Final Batch Loss: 0.0008461797842755914\n",
      "Epoch 2129, Loss: 0.00042186515929643065, Final Batch Loss: 9.213124576490372e-05\n",
      "Epoch 2130, Loss: 0.0002870691314456053, Final Batch Loss: 0.000217980079469271\n",
      "Epoch 2131, Loss: 8.676793891027046e-05, Final Batch Loss: 1.9490669274091488e-06\n",
      "Epoch 2132, Loss: 0.00016728923037589993, Final Batch Loss: 0.0001425334921805188\n",
      "Epoch 2133, Loss: 0.0001351089358649915, Final Batch Loss: 1.8577293303678744e-05\n",
      "Epoch 2134, Loss: 0.0003607624676078558, Final Batch Loss: 6.432546069845557e-05\n",
      "Epoch 2135, Loss: 0.00022073667059885338, Final Batch Loss: 9.217300248565152e-05\n",
      "Epoch 2136, Loss: 0.0001927908742800355, Final Batch Loss: 7.071996515151113e-05\n",
      "Epoch 2137, Loss: 4.6481772187689785e-05, Final Batch Loss: 3.556716546881944e-05\n",
      "Epoch 2138, Loss: 0.0025255932177969953, Final Batch Loss: 2.783077616186347e-05\n",
      "Epoch 2139, Loss: 0.0001459677987440955, Final Batch Loss: 1.7343725630780682e-05\n",
      "Epoch 2140, Loss: 0.0004448854015208781, Final Batch Loss: 0.0003567160456441343\n",
      "Epoch 2141, Loss: 0.0003343138787386124, Final Batch Loss: 0.00032736058346927166\n",
      "Epoch 2142, Loss: 0.0002921600535046309, Final Batch Loss: 2.5028479285538197e-05\n",
      "Epoch 2143, Loss: 0.00037275826616678387, Final Batch Loss: 0.0001278924901271239\n",
      "Epoch 2144, Loss: 0.00048482511192560196, Final Batch Loss: 0.00016245857113972306\n",
      "Epoch 2145, Loss: 0.004511777631705627, Final Batch Loss: 0.00017731482512317598\n",
      "Epoch 2146, Loss: 0.005426941177574918, Final Batch Loss: 0.00513962609693408\n",
      "Epoch 2147, Loss: 0.0012604215153260157, Final Batch Loss: 0.0001465016248403117\n",
      "Epoch 2148, Loss: 0.003322974076581886, Final Batch Loss: 3.451574229984544e-05\n",
      "Epoch 2149, Loss: 0.0003066279095946811, Final Batch Loss: 1.087423152057454e-05\n",
      "Epoch 2150, Loss: 0.00015099723896128125, Final Batch Loss: 0.00011161057773279026\n",
      "Epoch 2151, Loss: 0.00023067923757480457, Final Batch Loss: 0.00014065294817555696\n",
      "Epoch 2152, Loss: 0.0018308368744328618, Final Batch Loss: 4.6726781874895096e-05\n",
      "Epoch 2153, Loss: 0.0003544405954016838, Final Batch Loss: 1.1638334399322048e-05\n",
      "Epoch 2154, Loss: 0.0001620377297513187, Final Batch Loss: 0.00012100043386453763\n",
      "Epoch 2155, Loss: 0.01355123745452147, Final Batch Loss: 0.013330810703337193\n",
      "Epoch 2156, Loss: 0.010908920946349099, Final Batch Loss: 1.0825390745594632e-05\n",
      "Epoch 2157, Loss: 0.00023664198124606628, Final Batch Loss: 2.7018382752430625e-05\n",
      "Epoch 2158, Loss: 0.006947110428882297, Final Batch Loss: 0.0068355463445186615\n",
      "Epoch 2159, Loss: 0.004106546299226466, Final Batch Loss: 0.004091223236173391\n",
      "Epoch 2160, Loss: 0.00035004648088943213, Final Batch Loss: 0.00021519779693335295\n",
      "Epoch 2161, Loss: 0.00034763937583193183, Final Batch Loss: 6.232826854102314e-05\n",
      "Epoch 2162, Loss: 0.00012796167720807716, Final Batch Loss: 6.376820238074288e-05\n",
      "Epoch 2163, Loss: 0.005307470361003652, Final Batch Loss: 0.0051285563968122005\n",
      "Epoch 2164, Loss: 0.0037505316868191585, Final Batch Loss: 0.00016015533765312284\n",
      "Epoch 2165, Loss: 0.004050811869092286, Final Batch Loss: 0.0006846525939181447\n",
      "Epoch 2166, Loss: 0.0008545443415641785, Final Batch Loss: 0.000273260404355824\n",
      "Epoch 2167, Loss: 0.0001697858879197156, Final Batch Loss: 2.521976966818329e-05\n",
      "Epoch 2168, Loss: 4.7410422666871455e-05, Final Batch Loss: 4.980381163477432e-06\n",
      "Epoch 2169, Loss: 0.001345892498648027, Final Batch Loss: 6.001541987643577e-05\n",
      "Epoch 2170, Loss: 0.0010957796548609622, Final Batch Loss: 0.0010573859326541424\n",
      "Epoch 2171, Loss: 0.000964184022450354, Final Batch Loss: 0.00010287792974850163\n",
      "Epoch 2172, Loss: 0.001085131982108578, Final Batch Loss: 0.0004329481453169137\n",
      "Epoch 2173, Loss: 0.0002636948993313126, Final Batch Loss: 1.0657902748789638e-05\n",
      "Epoch 2174, Loss: 0.0002684693372430047, Final Batch Loss: 9.475688784732483e-06\n",
      "Epoch 2175, Loss: 0.0005801858424092643, Final Batch Loss: 0.0004905970999971032\n",
      "Epoch 2176, Loss: 0.00016799460172478575, Final Batch Loss: 2.4838360332068987e-05\n",
      "Epoch 2177, Loss: 2.3363570107903797e-05, Final Batch Loss: 3.999005457444582e-06\n",
      "Epoch 2178, Loss: 0.00017508470045868307, Final Batch Loss: 0.0001470625284127891\n",
      "Epoch 2179, Loss: 0.00014862779062241316, Final Batch Loss: 6.703271355945617e-05\n",
      "Epoch 2180, Loss: 0.00013636954099638388, Final Batch Loss: 9.23197585507296e-05\n",
      "Epoch 2181, Loss: 0.006062786502297968, Final Batch Loss: 0.000662413367535919\n",
      "Epoch 2182, Loss: 0.00010841346738743596, Final Batch Loss: 7.84905714681372e-05\n",
      "Epoch 2183, Loss: 0.0005558812381423195, Final Batch Loss: 0.0005406640120781958\n",
      "Epoch 2184, Loss: 0.0005211268780840328, Final Batch Loss: 0.0004943051608279347\n",
      "Epoch 2185, Loss: 0.003519809994031675, Final Batch Loss: 0.0002249404351459816\n",
      "Epoch 2186, Loss: 0.0007121689268387854, Final Batch Loss: 0.0003745593421626836\n",
      "Epoch 2187, Loss: 0.0035934436546085635, Final Batch Loss: 2.7369935196475126e-05\n",
      "Epoch 2188, Loss: 0.0005432252983155195, Final Batch Loss: 4.6926990762585774e-05\n",
      "Epoch 2189, Loss: 0.0005067218444310129, Final Batch Loss: 0.00010442108032293618\n",
      "Epoch 2190, Loss: 0.0005993343220325187, Final Batch Loss: 0.00044700829312205315\n",
      "Epoch 2191, Loss: 0.00014890986130922101, Final Batch Loss: 2.0805160602321848e-05\n",
      "Epoch 2192, Loss: 0.00017804654635256156, Final Batch Loss: 0.00011920050746994093\n",
      "Epoch 2193, Loss: 0.000163906869602215, Final Batch Loss: 9.86998657026561e-06\n",
      "Epoch 2194, Loss: 0.00136039671360777, Final Batch Loss: 1.0201915756624658e-05\n",
      "Epoch 2195, Loss: 0.008078349288553, Final Batch Loss: 0.005452317651361227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2196, Loss: 0.00023745248472550884, Final Batch Loss: 0.0001615085784578696\n",
      "Epoch 2197, Loss: 0.0005663058545906097, Final Batch Loss: 0.000269740994554013\n",
      "Epoch 2198, Loss: 0.0003681186335597886, Final Batch Loss: 9.28187910176348e-06\n",
      "Epoch 2199, Loss: 0.00021297568673617207, Final Batch Loss: 3.6703564546769485e-05\n",
      "Epoch 2200, Loss: 0.00018251745586894685, Final Batch Loss: 0.0001719663996482268\n",
      "Epoch 2201, Loss: 0.00035962679248768836, Final Batch Loss: 0.00026901252567768097\n",
      "Epoch 2202, Loss: 0.00042738390766317025, Final Batch Loss: 7.400371396215633e-05\n",
      "Epoch 2203, Loss: 7.731746700301301e-05, Final Batch Loss: 1.658351357036736e-05\n",
      "Epoch 2204, Loss: 7.049742634990253e-05, Final Batch Loss: 5.4683714552083984e-05\n",
      "Epoch 2205, Loss: 0.00028493176796473563, Final Batch Loss: 0.00021839351393282413\n",
      "Epoch 2206, Loss: 0.0010039780172519386, Final Batch Loss: 0.0004927951958961785\n",
      "Epoch 2207, Loss: 6.29851856501773e-05, Final Batch Loss: 3.0485396564472467e-05\n",
      "Epoch 2208, Loss: 0.00023542467988590943, Final Batch Loss: 0.00022854098642710596\n",
      "Epoch 2209, Loss: 0.0036634604093706002, Final Batch Loss: 2.939711521321442e-05\n",
      "Epoch 2210, Loss: 0.004412978218169883, Final Batch Loss: 0.004239845555275679\n",
      "Epoch 2211, Loss: 0.00032731081046222243, Final Batch Loss: 0.00030763354152441025\n",
      "Epoch 2212, Loss: 0.00010206774459220469, Final Batch Loss: 6.954210402909666e-05\n",
      "Epoch 2213, Loss: 0.0003007265790984093, Final Batch Loss: 6.60777959637926e-06\n",
      "Epoch 2214, Loss: 0.00021203989672358148, Final Batch Loss: 0.00016519341443199664\n",
      "Epoch 2215, Loss: 0.0024085252371151, Final Batch Loss: 1.560084638185799e-05\n",
      "Epoch 2216, Loss: 0.0002497937675798312, Final Batch Loss: 0.00017496004875283688\n",
      "Epoch 2217, Loss: 0.0001337878275080584, Final Batch Loss: 2.5007990188896656e-05\n",
      "Epoch 2218, Loss: 9.782017150428146e-05, Final Batch Loss: 4.006523158750497e-05\n",
      "Epoch 2219, Loss: 0.0006368598551489413, Final Batch Loss: 0.0004290442157071084\n",
      "Epoch 2220, Loss: 0.0018984728958457708, Final Batch Loss: 0.0017660199664533138\n",
      "Epoch 2221, Loss: 7.223115426313598e-05, Final Batch Loss: 5.443508052849211e-05\n",
      "Epoch 2222, Loss: 0.00010576791373750893, Final Batch Loss: 1.3576357559941243e-05\n",
      "Epoch 2223, Loss: 0.00025993951567215845, Final Batch Loss: 8.817988418741152e-05\n",
      "Epoch 2224, Loss: 0.00023450206208508462, Final Batch Loss: 3.9577396819368005e-05\n",
      "Epoch 2225, Loss: 0.0015111027169041336, Final Batch Loss: 0.00034786906326189637\n",
      "Epoch 2226, Loss: 5.651714491250459e-05, Final Batch Loss: 1.5750496459077112e-05\n",
      "Epoch 2227, Loss: 0.00040850474306353135, Final Batch Loss: 0.0004019925545435399\n",
      "Epoch 2228, Loss: 0.006388627397427626, Final Batch Loss: 0.0063805426470935345\n",
      "Epoch 2229, Loss: 0.00011942336800530029, Final Batch Loss: 1.2277503174118465e-06\n",
      "Epoch 2230, Loss: 7.152959778977674e-05, Final Batch Loss: 6.330236374196829e-06\n",
      "Epoch 2231, Loss: 0.01366606104420498, Final Batch Loss: 0.0005420719389803708\n",
      "Epoch 2232, Loss: 0.00472981339044054, Final Batch Loss: 0.004698149859905243\n",
      "Epoch 2233, Loss: 0.0017887387803057209, Final Batch Loss: 8.247200457844883e-05\n",
      "Epoch 2234, Loss: 3.769961494981544e-05, Final Batch Loss: 2.2634902052232064e-05\n",
      "Epoch 2235, Loss: 0.008798375143669546, Final Batch Loss: 0.008736904710531235\n",
      "Epoch 2236, Loss: 0.0004290046781534329, Final Batch Loss: 0.000120472555863671\n",
      "Epoch 2237, Loss: 0.00025775367612368427, Final Batch Loss: 4.8395548219559714e-05\n",
      "Epoch 2238, Loss: 0.00023188530758488923, Final Batch Loss: 5.4883668781258166e-05\n",
      "Epoch 2239, Loss: 0.0003911156245521852, Final Batch Loss: 0.0003817676333710551\n",
      "Epoch 2240, Loss: 0.00018800769612425938, Final Batch Loss: 7.15097994543612e-05\n",
      "Epoch 2241, Loss: 0.0007150007259042468, Final Batch Loss: 0.000655180134344846\n",
      "Epoch 2242, Loss: 0.002443027413391974, Final Batch Loss: 4.661824641516432e-05\n",
      "Epoch 2243, Loss: 0.0009546939108986408, Final Batch Loss: 0.00042726771789602935\n",
      "Epoch 2244, Loss: 9.347590821562335e-05, Final Batch Loss: 4.3339117837604135e-05\n",
      "Epoch 2245, Loss: 2.2873412490298506e-05, Final Batch Loss: 8.446791071037296e-06\n",
      "Epoch 2246, Loss: 0.010372067903517745, Final Batch Loss: 0.00010833713167812675\n",
      "Epoch 2247, Loss: 0.0002939585829153657, Final Batch Loss: 6.220486829988658e-05\n",
      "Epoch 2248, Loss: 0.0006943417247384787, Final Batch Loss: 0.0002915924706030637\n",
      "Epoch 2249, Loss: 0.00039075723725545686, Final Batch Loss: 2.032240263361018e-05\n",
      "Epoch 2250, Loss: 0.0003196922625647858, Final Batch Loss: 0.00029077401268295944\n",
      "Epoch 2251, Loss: 0.00010518972703721374, Final Batch Loss: 6.151289562694728e-05\n",
      "Epoch 2252, Loss: 0.0004400256148073822, Final Batch Loss: 0.00022326211910694838\n",
      "Epoch 2253, Loss: 0.00010754757022368722, Final Batch Loss: 3.174938683514483e-05\n",
      "Epoch 2254, Loss: 0.00027690490969689563, Final Batch Loss: 0.0001766192726790905\n",
      "Epoch 2255, Loss: 0.004395561329147313, Final Batch Loss: 7.804579945513979e-05\n",
      "Epoch 2256, Loss: 7.690079110034276e-05, Final Batch Loss: 5.147418414708227e-05\n",
      "Epoch 2257, Loss: 0.00011828765991594992, Final Batch Loss: 4.813214673049515e-06\n",
      "Epoch 2258, Loss: 0.000347818189766258, Final Batch Loss: 0.00017982133431360126\n",
      "Epoch 2259, Loss: 0.000548592972336337, Final Batch Loss: 0.00027365671121515334\n",
      "Epoch 2260, Loss: 0.000869777737534605, Final Batch Loss: 4.69226943096146e-05\n",
      "Epoch 2261, Loss: 0.00011396531044738367, Final Batch Loss: 3.3568918297532946e-05\n",
      "Epoch 2262, Loss: 0.0019821384485112503, Final Batch Loss: 0.00010470284905750304\n",
      "Epoch 2263, Loss: 0.004301083943573758, Final Batch Loss: 0.00032795194420032203\n",
      "Epoch 2264, Loss: 0.0010079896492243279, Final Batch Loss: 0.000970329565461725\n",
      "Epoch 2265, Loss: 6.584389211639063e-05, Final Batch Loss: 1.0352851859352086e-05\n",
      "Epoch 2266, Loss: 0.0007152925390983, Final Batch Loss: 0.0005487198941409588\n",
      "Epoch 2267, Loss: 7.987469325598795e-05, Final Batch Loss: 2.3599955966346897e-05\n",
      "Epoch 2268, Loss: 2.4619175292173168e-05, Final Batch Loss: 1.82738367584534e-05\n",
      "Epoch 2269, Loss: 2.5093603653658647e-05, Final Batch Loss: 1.3110778127156664e-05\n",
      "Epoch 2270, Loss: 0.001459570357837947, Final Batch Loss: 0.0014221371384337544\n",
      "Epoch 2271, Loss: 3.7814797906321473e-05, Final Batch Loss: 3.15045726893004e-05\n",
      "Epoch 2272, Loss: 0.0012504650621849578, Final Batch Loss: 0.0011996258981525898\n",
      "Epoch 2273, Loss: 0.004906438218313269, Final Batch Loss: 0.004836510866880417\n",
      "Epoch 2274, Loss: 0.00022355890359904151, Final Batch Loss: 1.1579393685678951e-05\n",
      "Epoch 2275, Loss: 0.00025711909620440565, Final Batch Loss: 0.00024183845380321145\n",
      "Epoch 2276, Loss: 0.00022046671801945195, Final Batch Loss: 9.778954699868336e-05\n",
      "Epoch 2277, Loss: 0.00010311139521945734, Final Batch Loss: 7.703853771090508e-05\n",
      "Epoch 2278, Loss: 0.0004369125090306625, Final Batch Loss: 0.00030533139943145216\n",
      "Epoch 2279, Loss: 0.00011028124390577432, Final Batch Loss: 2.184950244554784e-05\n",
      "Epoch 2280, Loss: 8.393424104724545e-05, Final Batch Loss: 1.670536039455328e-05\n",
      "Epoch 2281, Loss: 0.00010855085201910697, Final Batch Loss: 7.125734555302188e-05\n",
      "Epoch 2282, Loss: 9.164139919448644e-05, Final Batch Loss: 3.624213422881439e-05\n",
      "Epoch 2283, Loss: 0.008393350100959651, Final Batch Loss: 0.008286463096737862\n",
      "Epoch 2284, Loss: 0.002601401531137526, Final Batch Loss: 0.00025888101663440466\n",
      "Epoch 2285, Loss: 0.00018752417236100882, Final Batch Loss: 8.26405084808357e-05\n",
      "Epoch 2286, Loss: 0.00020866651539108716, Final Batch Loss: 0.00019863358465954661\n",
      "Epoch 2287, Loss: 0.00013703999866265804, Final Batch Loss: 9.657043119659647e-05\n",
      "Epoch 2288, Loss: 0.00043992532846459653, Final Batch Loss: 0.000423159304773435\n",
      "Epoch 2289, Loss: 7.261992868734524e-05, Final Batch Loss: 3.70989328075666e-05\n",
      "Epoch 2290, Loss: 5.664398076987709e-05, Final Batch Loss: 1.95514394363272e-06\n",
      "Epoch 2291, Loss: 0.00016741112449381035, Final Batch Loss: 0.00015196151798591018\n",
      "Epoch 2292, Loss: 0.00014779231673855975, Final Batch Loss: 2.517913117117132e-06\n",
      "Epoch 2293, Loss: 0.000571965943890973, Final Batch Loss: 2.472266169206705e-05\n",
      "Epoch 2294, Loss: 0.0007715620376984589, Final Batch Loss: 9.260104707209393e-05\n",
      "Epoch 2295, Loss: 0.0001166768846587729, Final Batch Loss: 1.6671395997036598e-06\n",
      "Epoch 2296, Loss: 0.0005045601137680933, Final Batch Loss: 3.539778117556125e-05\n",
      "Epoch 2297, Loss: 0.00014602824739995413, Final Batch Loss: 3.3508087653899565e-05\n",
      "Epoch 2298, Loss: 0.0017125097294865554, Final Batch Loss: 2.5241827188438037e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2299, Loss: 7.993850204002229e-05, Final Batch Loss: 4.751171672978671e-06\n",
      "Epoch 2300, Loss: 0.00016489219706272706, Final Batch Loss: 1.6417143342550844e-05\n",
      "Epoch 2301, Loss: 0.0005504987348103896, Final Batch Loss: 0.00040965250809676945\n",
      "Epoch 2302, Loss: 0.0002261963381897658, Final Batch Loss: 1.75503664650023e-05\n",
      "Epoch 2303, Loss: 0.0003000738433911465, Final Batch Loss: 0.0002351161529077217\n",
      "Epoch 2304, Loss: 3.434044901950983e-05, Final Batch Loss: 7.788178663759027e-06\n",
      "Epoch 2305, Loss: 0.0063895960920490324, Final Batch Loss: 0.00028113514417782426\n",
      "Epoch 2306, Loss: 0.00046010484220460057, Final Batch Loss: 0.00039229949470609426\n",
      "Epoch 2307, Loss: 0.0001741754358590697, Final Batch Loss: 8.717234777577687e-06\n",
      "Epoch 2308, Loss: 0.00011124366938020103, Final Batch Loss: 5.873854024684988e-05\n",
      "Epoch 2309, Loss: 0.00012924341717734933, Final Batch Loss: 6.479017611127347e-05\n",
      "Epoch 2310, Loss: 0.00015900969447102398, Final Batch Loss: 4.101500962860882e-06\n",
      "Epoch 2311, Loss: 0.0017461232637288049, Final Batch Loss: 0.0016019230242818594\n",
      "Epoch 2312, Loss: 0.0005982212969684042, Final Batch Loss: 9.65773724601604e-05\n",
      "Epoch 2313, Loss: 0.0001415961532984511, Final Batch Loss: 0.0001338142465101555\n",
      "Epoch 2314, Loss: 0.009735596584505402, Final Batch Loss: 0.00013370088709052652\n",
      "Epoch 2315, Loss: 3.644311402695166e-05, Final Batch Loss: 5.055441079093725e-07\n",
      "Epoch 2316, Loss: 8.439263910986483e-05, Final Batch Loss: 2.8758418920915574e-05\n",
      "Epoch 2317, Loss: 3.178120459779166e-05, Final Batch Loss: 1.554917253088206e-05\n",
      "Epoch 2318, Loss: 0.005505903536686674, Final Batch Loss: 0.00529195973649621\n",
      "Epoch 2319, Loss: 0.00024353323533432558, Final Batch Loss: 0.00021826291049364954\n",
      "Epoch 2320, Loss: 0.0017093118658522144, Final Batch Loss: 2.2545704268850386e-05\n",
      "Epoch 2321, Loss: 0.0003624824648795766, Final Batch Loss: 1.279979642276885e-05\n",
      "Epoch 2322, Loss: 5.223036896495614e-05, Final Batch Loss: 2.1846291929250583e-05\n",
      "Epoch 2323, Loss: 0.00027230889827478677, Final Batch Loss: 0.00012982955377083272\n",
      "Epoch 2324, Loss: 0.0004408822860568762, Final Batch Loss: 0.00015235450700856745\n",
      "Epoch 2325, Loss: 0.00012076591883669607, Final Batch Loss: 3.91980393033009e-05\n",
      "Epoch 2326, Loss: 0.00012587773926497903, Final Batch Loss: 0.00011737419117707759\n",
      "Epoch 2327, Loss: 0.00026338444877183065, Final Batch Loss: 0.0001467893016524613\n",
      "Epoch 2328, Loss: 0.00013710656025978096, Final Batch Loss: 1.4461559203482466e-06\n",
      "Epoch 2329, Loss: 2.8956168534932658e-05, Final Batch Loss: 2.1242180082481354e-05\n",
      "Epoch 2330, Loss: 0.011524236353579909, Final Batch Loss: 0.011036657728254795\n",
      "Epoch 2331, Loss: 0.008749904140131548, Final Batch Loss: 0.008502901531755924\n",
      "Epoch 2332, Loss: 3.205053781130118e-05, Final Batch Loss: 1.2352616067801137e-05\n",
      "Epoch 2333, Loss: 0.00031115393539948855, Final Batch Loss: 2.1536945496336557e-05\n",
      "Epoch 2334, Loss: 0.004686997679527849, Final Batch Loss: 0.00061181461205706\n",
      "Epoch 2335, Loss: 4.173616525804391e-05, Final Batch Loss: 3.0494542443193495e-05\n",
      "Epoch 2336, Loss: 0.002993164242070634, Final Batch Loss: 7.267262117238715e-05\n",
      "Epoch 2337, Loss: 0.00018831986744771712, Final Batch Loss: 5.840968151460402e-05\n",
      "Epoch 2338, Loss: 0.004219344739794906, Final Batch Loss: 0.004206810146570206\n",
      "Epoch 2339, Loss: 0.00039977622509468347, Final Batch Loss: 0.00011239766899961978\n",
      "Epoch 2340, Loss: 0.004717685136711225, Final Batch Loss: 0.0046453517861664295\n",
      "Epoch 2341, Loss: 0.0002816388732753694, Final Batch Loss: 4.262344737071544e-05\n",
      "Epoch 2342, Loss: 0.00035796325391856954, Final Batch Loss: 0.000247007526922971\n",
      "Epoch 2343, Loss: 0.0015133005490497453, Final Batch Loss: 0.0014958836836740375\n",
      "Epoch 2344, Loss: 0.000790851358033251, Final Batch Loss: 8.249904931290075e-05\n",
      "Epoch 2345, Loss: 0.003551783674993203, Final Batch Loss: 4.679366611526348e-06\n",
      "Epoch 2346, Loss: 9.280553058488294e-05, Final Batch Loss: 6.225036486284807e-05\n",
      "Epoch 2347, Loss: 0.00020597566435753834, Final Batch Loss: 0.00017867058340925723\n",
      "Epoch 2348, Loss: 0.0003176172294843127, Final Batch Loss: 6.644547283940483e-06\n",
      "Epoch 2349, Loss: 4.8595809857943095e-05, Final Batch Loss: 2.8475935323513113e-05\n",
      "Epoch 2350, Loss: 0.00031816070622880943, Final Batch Loss: 0.00025869254022836685\n",
      "Epoch 2351, Loss: 6.055722224118654e-05, Final Batch Loss: 2.468687125656288e-05\n",
      "Epoch 2352, Loss: 0.002392334191881673, Final Batch Loss: 5.586332463280996e-06\n",
      "Epoch 2353, Loss: 0.023679311110754497, Final Batch Loss: 0.00012338599481154233\n",
      "Epoch 2354, Loss: 8.561495269532315e-05, Final Batch Loss: 3.461504093138501e-05\n",
      "Epoch 2355, Loss: 0.00015531214739894494, Final Batch Loss: 0.000118294294225052\n",
      "Epoch 2356, Loss: 0.00013660709373652935, Final Batch Loss: 5.312587018124759e-05\n",
      "Epoch 2357, Loss: 0.02604397015284121, Final Batch Loss: 4.444286332727643e-06\n",
      "Epoch 2358, Loss: 6.919258885318413e-05, Final Batch Loss: 5.916268128203228e-05\n",
      "Epoch 2359, Loss: 5.9648113392540836e-05, Final Batch Loss: 2.221355543952086e-06\n",
      "Epoch 2360, Loss: 6.771463995391969e-05, Final Batch Loss: 5.2396142564248294e-05\n",
      "Epoch 2361, Loss: 0.00011563549560378306, Final Batch Loss: 7.569551962660626e-05\n",
      "Epoch 2362, Loss: 9.793291519599734e-05, Final Batch Loss: 8.716585580259562e-05\n",
      "Epoch 2363, Loss: 0.0061221187497721985, Final Batch Loss: 0.00024067745835054666\n",
      "Epoch 2364, Loss: 0.0002589596842881292, Final Batch Loss: 0.00013686029706150293\n",
      "Epoch 2365, Loss: 0.00045352814504440175, Final Batch Loss: 1.1611596164584626e-05\n",
      "Epoch 2366, Loss: 0.0018898578782682307, Final Batch Loss: 2.1618739992845803e-05\n",
      "Epoch 2367, Loss: 0.0033474565570941195, Final Batch Loss: 0.003121795365586877\n",
      "Epoch 2368, Loss: 0.004068346121130162, Final Batch Loss: 2.6438743589096703e-05\n",
      "Epoch 2369, Loss: 2.1747204300481826e-05, Final Batch Loss: 1.5849462215555832e-05\n",
      "Epoch 2370, Loss: 0.003971864280174486, Final Batch Loss: 0.00010700365237426013\n",
      "Epoch 2371, Loss: 0.0004264575691195205, Final Batch Loss: 0.0003567460225895047\n",
      "Epoch 2372, Loss: 0.00352006470257038, Final Batch Loss: 1.0468479558767285e-05\n",
      "Epoch 2373, Loss: 0.0006463353347498924, Final Batch Loss: 0.0005450620665214956\n",
      "Epoch 2374, Loss: 0.00014497685060632648, Final Batch Loss: 4.686623469751794e-06\n",
      "Epoch 2375, Loss: 9.822237007028889e-05, Final Batch Loss: 1.725969741528388e-05\n",
      "Epoch 2376, Loss: 0.000681587313010823, Final Batch Loss: 8.7877779151313e-06\n",
      "Epoch 2377, Loss: 0.005503473919816315, Final Batch Loss: 0.005083099938929081\n",
      "Epoch 2378, Loss: 2.9210302272986155e-05, Final Batch Loss: 1.0032225873146672e-05\n",
      "Epoch 2379, Loss: 0.003799553116550669, Final Batch Loss: 0.00019298269762657583\n",
      "Epoch 2380, Loss: 0.0006937803177606838, Final Batch Loss: 4.1371154111402575e-06\n",
      "Epoch 2381, Loss: 0.0008903410052880645, Final Batch Loss: 0.0008324593072757125\n",
      "Epoch 2382, Loss: 0.00033511908259242773, Final Batch Loss: 3.1120056519284844e-05\n",
      "Epoch 2383, Loss: 0.0005474284080264624, Final Batch Loss: 2.3764292564010248e-05\n",
      "Epoch 2384, Loss: 0.00016037496425269637, Final Batch Loss: 0.00013626751024276018\n",
      "Epoch 2385, Loss: 0.0009305902331107063, Final Batch Loss: 0.0009014272363856435\n",
      "Epoch 2386, Loss: 5.6515608775953297e-05, Final Batch Loss: 1.233453531312989e-05\n",
      "Epoch 2387, Loss: 3.207989630027441e-05, Final Batch Loss: 7.805248060321901e-06\n",
      "Epoch 2388, Loss: 0.00020774596487171948, Final Batch Loss: 0.0001463681983295828\n",
      "Epoch 2389, Loss: 0.0003914326043741312, Final Batch Loss: 0.00036185828503221273\n",
      "Epoch 2390, Loss: 0.00046062022011028603, Final Batch Loss: 6.250121077755466e-05\n",
      "Epoch 2391, Loss: 0.0010932912700809538, Final Batch Loss: 0.0001841457560658455\n",
      "Epoch 2392, Loss: 0.0003027198704330658, Final Batch Loss: 4.97912833452574e-06\n",
      "Epoch 2393, Loss: 0.0002121945708495332, Final Batch Loss: 1.9259516193415038e-05\n",
      "Epoch 2394, Loss: 0.00012033293751301244, Final Batch Loss: 7.73480860516429e-05\n",
      "Epoch 2395, Loss: 2.8934018018844654e-05, Final Batch Loss: 2.80167773780704e-06\n",
      "Epoch 2396, Loss: 0.004289435145437892, Final Batch Loss: 1.1471022844489198e-05\n",
      "Epoch 2397, Loss: 0.002203066454967484, Final Batch Loss: 0.0002646919747348875\n",
      "Epoch 2398, Loss: 0.00038876991311553866, Final Batch Loss: 0.00016276004316750914\n",
      "Epoch 2399, Loss: 7.217689926619641e-05, Final Batch Loss: 3.831090725725517e-05\n",
      "Epoch 2400, Loss: 0.00025574315441190265, Final Batch Loss: 1.1975058441748843e-05\n",
      "Epoch 2401, Loss: 7.371326114480325e-05, Final Batch Loss: 3.139113459837972e-06\n",
      "Epoch 2402, Loss: 0.0001418015526724048, Final Batch Loss: 0.0001121833993238397\n",
      "Epoch 2403, Loss: 0.00020719074109365465, Final Batch Loss: 9.057885108632036e-07\n",
      "Epoch 2404, Loss: 0.00036937488584953826, Final Batch Loss: 1.76354205905227e-05\n",
      "Epoch 2405, Loss: 7.24719111531158e-05, Final Batch Loss: 5.7339300838066265e-05\n",
      "Epoch 2406, Loss: 0.002707841902065411, Final Batch Loss: 1.762856754794484e-06\n",
      "Epoch 2407, Loss: 0.00014081166773394216, Final Batch Loss: 1.8722597815212794e-05\n",
      "Epoch 2408, Loss: 0.00014918648957973346, Final Batch Loss: 5.50936529180035e-05\n",
      "Epoch 2409, Loss: 0.0006558068271260709, Final Batch Loss: 0.0006392494542524219\n",
      "Epoch 2410, Loss: 0.00017378318443661556, Final Batch Loss: 0.00011245023779338226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2411, Loss: 9.454883002035785e-05, Final Batch Loss: 8.65470246935729e-06\n",
      "Epoch 2412, Loss: 0.0005700264737242833, Final Batch Loss: 0.00041818537283688784\n",
      "Epoch 2413, Loss: 0.00011483227353892289, Final Batch Loss: 7.23262710380368e-05\n",
      "Epoch 2414, Loss: 0.005968451761873439, Final Batch Loss: 0.0004342187021393329\n",
      "Epoch 2415, Loss: 0.00019151713058818132, Final Batch Loss: 8.482135308440775e-05\n",
      "Epoch 2416, Loss: 5.719020373362582e-05, Final Batch Loss: 2.1570123863057233e-05\n",
      "Epoch 2417, Loss: 0.00010663163266144693, Final Batch Loss: 6.970307731535286e-05\n",
      "Epoch 2418, Loss: 0.00023273276747204363, Final Batch Loss: 0.0001950259174918756\n",
      "Epoch 2419, Loss: 7.148718395910691e-05, Final Batch Loss: 1.251648245670367e-05\n",
      "Epoch 2420, Loss: 0.00015769259334774688, Final Batch Loss: 1.9991603039670736e-05\n",
      "Epoch 2421, Loss: 0.00013145340562914498, Final Batch Loss: 4.951982191414572e-05\n",
      "Epoch 2422, Loss: 0.014634792621109227, Final Batch Loss: 0.014631804078817368\n",
      "Epoch 2423, Loss: 1.0789276984723983e-05, Final Batch Loss: 9.622021025279537e-06\n",
      "Epoch 2424, Loss: 0.00013613266310130712, Final Batch Loss: 1.2057504136464559e-05\n",
      "Epoch 2425, Loss: 0.0006479095318354666, Final Batch Loss: 0.0006175269954837859\n",
      "Epoch 2426, Loss: 0.0010460531902936054, Final Batch Loss: 1.520413024991285e-05\n",
      "Epoch 2427, Loss: 0.0008824502729112282, Final Batch Loss: 0.0001342672185273841\n",
      "Epoch 2428, Loss: 0.0002457512491673697, Final Batch Loss: 5.7222892792196944e-05\n",
      "Epoch 2429, Loss: 0.0051285540394019336, Final Batch Loss: 0.004761131014674902\n",
      "Epoch 2430, Loss: 0.0004401255864650011, Final Batch Loss: 0.00026180213899351656\n",
      "Epoch 2431, Loss: 0.0005126824798935559, Final Batch Loss: 5.570624125539325e-05\n",
      "Epoch 2432, Loss: 0.00035718084836844355, Final Batch Loss: 0.00021774842753075063\n",
      "Epoch 2433, Loss: 0.0005235231656115502, Final Batch Loss: 0.00010522501543164253\n",
      "Epoch 2434, Loss: 0.000245517905568704, Final Batch Loss: 5.9948215493932366e-05\n",
      "Epoch 2435, Loss: 0.0007481368957087398, Final Batch Loss: 0.0005529416957870126\n",
      "Epoch 2436, Loss: 0.0008883997797966003, Final Batch Loss: 0.0002579661086201668\n",
      "Epoch 2437, Loss: 0.0006231263832887635, Final Batch Loss: 0.0004827502416446805\n",
      "Epoch 2438, Loss: 0.00018257789633935317, Final Batch Loss: 7.294875831576064e-05\n",
      "Epoch 2439, Loss: 0.003210546390619129, Final Batch Loss: 0.0001386412768624723\n",
      "Epoch 2440, Loss: 0.0005088949610581039, Final Batch Loss: 1.0438488061481621e-05\n",
      "Epoch 2441, Loss: 0.022005587350577116, Final Batch Loss: 0.017876792699098587\n",
      "Epoch 2442, Loss: 6.59141060168622e-05, Final Batch Loss: 1.1791520591941662e-05\n",
      "Epoch 2443, Loss: 0.001349769278021995, Final Batch Loss: 2.2971165890339762e-05\n",
      "Epoch 2444, Loss: 0.0006205321406014264, Final Batch Loss: 0.00016189782763831317\n",
      "Epoch 2445, Loss: 0.0007296762814803515, Final Batch Loss: 0.0006832923390902579\n",
      "Epoch 2446, Loss: 0.00545321439858526, Final Batch Loss: 2.8459238819777966e-05\n",
      "Epoch 2447, Loss: 0.000622166640823707, Final Batch Loss: 0.0003520103346090764\n",
      "Epoch 2448, Loss: 0.00025449734675930813, Final Batch Loss: 0.00016142807726282626\n",
      "Epoch 2449, Loss: 0.00017090655092033558, Final Batch Loss: 2.0277449948480353e-05\n",
      "Epoch 2450, Loss: 0.0003394032082724152, Final Batch Loss: 1.3279188351589255e-05\n",
      "Epoch 2451, Loss: 0.0017752802523318678, Final Batch Loss: 0.0014362585498020053\n",
      "Epoch 2452, Loss: 0.00016792154929134995, Final Batch Loss: 2.5690111215226352e-05\n",
      "Epoch 2453, Loss: 0.0001538018259452656, Final Batch Loss: 6.054199184291065e-05\n",
      "Epoch 2454, Loss: 0.00017258525986107998, Final Batch Loss: 5.614413748844527e-05\n",
      "Epoch 2455, Loss: 0.00016559139658056665, Final Batch Loss: 0.0001379346358589828\n",
      "Epoch 2456, Loss: 0.0017808867996791378, Final Batch Loss: 0.00019307051843497902\n",
      "Epoch 2457, Loss: 5.051025709690293e-05, Final Batch Loss: 5.668170160788577e-06\n",
      "Epoch 2458, Loss: 0.00036241545603843406, Final Batch Loss: 0.0002469765313435346\n",
      "Epoch 2459, Loss: 0.0005723899994336534, Final Batch Loss: 0.0005159902502782643\n",
      "Epoch 2460, Loss: 0.006711460169753991, Final Batch Loss: 3.8745798519812524e-05\n",
      "Epoch 2461, Loss: 0.00041914789835573174, Final Batch Loss: 0.00040113707655109465\n",
      "Epoch 2462, Loss: 0.000413718240451999, Final Batch Loss: 0.0003175235469825566\n",
      "Epoch 2463, Loss: 4.02229036353674e-05, Final Batch Loss: 3.9113798266043887e-05\n",
      "Epoch 2464, Loss: 0.001125952711845457, Final Batch Loss: 0.0011149061610922217\n",
      "Epoch 2465, Loss: 0.005950002290774137, Final Batch Loss: 0.005354567896574736\n",
      "Epoch 2466, Loss: 6.535700777021702e-05, Final Batch Loss: 1.82353123818757e-05\n",
      "Epoch 2467, Loss: 0.00023609682784808683, Final Batch Loss: 3.994565759057878e-06\n",
      "Epoch 2468, Loss: 5.379838967201067e-05, Final Batch Loss: 3.3506503314129077e-06\n",
      "Epoch 2469, Loss: 0.0014404578832909465, Final Batch Loss: 0.0006166927050799131\n",
      "Epoch 2470, Loss: 0.0010623964190017432, Final Batch Loss: 0.0006880967412143946\n",
      "Epoch 2471, Loss: 0.00016622486873529851, Final Batch Loss: 2.6221227017231286e-05\n",
      "Epoch 2472, Loss: 0.0002732564607867971, Final Batch Loss: 6.634346209466457e-05\n",
      "Epoch 2473, Loss: 0.006630599615164101, Final Batch Loss: 0.006024837493896484\n",
      "Epoch 2474, Loss: 0.0010821960750035942, Final Batch Loss: 0.0005462613771669567\n",
      "Epoch 2475, Loss: 0.0011554263401194476, Final Batch Loss: 0.0010659974068403244\n",
      "Epoch 2476, Loss: 0.0008779990112088853, Final Batch Loss: 1.0163706974708475e-05\n",
      "Epoch 2477, Loss: 0.0008940010302467272, Final Batch Loss: 0.0006748184096068144\n",
      "Epoch 2478, Loss: 0.0002448301784170326, Final Batch Loss: 0.0002064930449705571\n",
      "Epoch 2479, Loss: 8.315769855471444e-05, Final Batch Loss: 1.3043177204963285e-06\n",
      "Epoch 2480, Loss: 0.0031431550851266365, Final Batch Loss: 0.003110109828412533\n",
      "Epoch 2481, Loss: 0.0006781718548154458, Final Batch Loss: 9.825830056797713e-05\n",
      "Epoch 2482, Loss: 0.0005512855677807238, Final Batch Loss: 0.0005280809127725661\n",
      "Epoch 2483, Loss: 0.0004476567410165444, Final Batch Loss: 0.00032014044700190425\n",
      "Epoch 2484, Loss: 2.1583081888820743e-05, Final Batch Loss: 2.9479556360456627e-06\n",
      "Epoch 2485, Loss: 0.0004869753429375123, Final Batch Loss: 2.8584250685526058e-05\n",
      "Epoch 2486, Loss: 0.000878149348864099, Final Batch Loss: 0.0008217979338951409\n",
      "Epoch 2487, Loss: 0.00011334401278872974, Final Batch Loss: 3.423843372729607e-05\n",
      "Epoch 2488, Loss: 0.00047613613423891366, Final Batch Loss: 5.668986705131829e-05\n",
      "Epoch 2489, Loss: 0.0005621721647912636, Final Batch Loss: 0.00035458808997645974\n",
      "Epoch 2490, Loss: 0.0002231923126601032, Final Batch Loss: 6.94043319526827e-06\n",
      "Epoch 2491, Loss: 0.00044732983224093914, Final Batch Loss: 0.00021359624224714935\n",
      "Epoch 2492, Loss: 0.0002592460805317387, Final Batch Loss: 0.00021810074395034462\n",
      "Epoch 2493, Loss: 0.00021110276793478988, Final Batch Loss: 4.830133912037127e-05\n",
      "Epoch 2494, Loss: 0.0008713435236131772, Final Batch Loss: 0.0008307182579301298\n",
      "Epoch 2495, Loss: 0.0001286032929783687, Final Batch Loss: 8.806924597593024e-05\n",
      "Epoch 2496, Loss: 0.00012342254854047496, Final Batch Loss: 2.3057648377289297e-06\n",
      "Epoch 2497, Loss: 0.0001709224197838921, Final Batch Loss: 0.0001393911661580205\n",
      "Epoch 2498, Loss: 4.18855433963472e-05, Final Batch Loss: 1.0355137419537641e-05\n",
      "Epoch 2499, Loss: 0.00012506512030086014, Final Batch Loss: 0.0001114566475735046\n",
      "Epoch 2500, Loss: 0.00021456483409565408, Final Batch Loss: 1.7802785805542953e-05\n",
      "Epoch 2501, Loss: 0.00013332184244063683, Final Batch Loss: 8.832813909975812e-05\n",
      "Epoch 2502, Loss: 3.492798532533925e-05, Final Batch Loss: 1.583307675900869e-05\n",
      "Epoch 2503, Loss: 0.004096420714631677, Final Batch Loss: 0.0003136582672595978\n",
      "Epoch 2504, Loss: 0.00011125379023724236, Final Batch Loss: 5.431062891148031e-05\n",
      "Epoch 2505, Loss: 0.0002543125028751092, Final Batch Loss: 2.4450144337606616e-05\n",
      "Epoch 2506, Loss: 0.00013158575529814698, Final Batch Loss: 3.972954073105939e-05\n",
      "Epoch 2507, Loss: 0.009816320740355877, Final Batch Loss: 1.1596024705795571e-05\n",
      "Epoch 2508, Loss: 7.019694567134138e-05, Final Batch Loss: 4.7926823754096404e-05\n",
      "Epoch 2509, Loss: 0.004341805491321793, Final Batch Loss: 3.4218167002109112e-06\n",
      "Epoch 2510, Loss: 0.00016977032919385238, Final Batch Loss: 1.6314616004819982e-06\n",
      "Epoch 2511, Loss: 6.429296990972944e-05, Final Batch Loss: 1.908643389469944e-05\n",
      "Epoch 2512, Loss: 5.449856325867586e-05, Final Batch Loss: 1.7087746527977288e-05\n",
      "Epoch 2513, Loss: 0.009427812416106462, Final Batch Loss: 0.004076656885445118\n",
      "Epoch 2514, Loss: 0.0001110055745812133, Final Batch Loss: 4.150173481320962e-05\n",
      "Epoch 2515, Loss: 0.0005392758685047738, Final Batch Loss: 0.00046659630606882274\n",
      "Epoch 2516, Loss: 0.00021924509201198816, Final Batch Loss: 8.23774462332949e-05\n",
      "Epoch 2517, Loss: 0.0038818531247670762, Final Batch Loss: 7.165624265326187e-05\n",
      "Epoch 2518, Loss: 3.875793481711298e-05, Final Batch Loss: 2.1063968233647756e-05\n",
      "Epoch 2519, Loss: 3.1536513233731966e-05, Final Batch Loss: 2.6894264010479674e-05\n",
      "Epoch 2520, Loss: 0.00017297226440859959, Final Batch Loss: 5.501797568285838e-05\n",
      "Epoch 2521, Loss: 0.0002132793415512424, Final Batch Loss: 2.128898267983459e-05\n",
      "Epoch 2522, Loss: 0.00033067946060327813, Final Batch Loss: 4.285660543246195e-05\n",
      "Epoch 2523, Loss: 0.004630507290130481, Final Batch Loss: 0.004270891193300486\n",
      "Epoch 2524, Loss: 0.009133842075243592, Final Batch Loss: 0.008018952794373035\n",
      "Epoch 2525, Loss: 0.0001741845087508409, Final Batch Loss: 1.2433636129571823e-06\n",
      "Epoch 2526, Loss: 0.0007647783058928326, Final Batch Loss: 0.0005854893825016916\n",
      "Epoch 2527, Loss: 0.00044489780702861026, Final Batch Loss: 1.36928356369026e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2528, Loss: 0.000245761784753995, Final Batch Loss: 3.154637306579389e-05\n",
      "Epoch 2529, Loss: 2.1114472474437207e-05, Final Batch Loss: 1.0202387784374878e-05\n",
      "Epoch 2530, Loss: 0.00013917491014581174, Final Batch Loss: 0.00011622731835814193\n",
      "Epoch 2531, Loss: 0.00011368580453563482, Final Batch Loss: 5.820354272145778e-05\n",
      "Epoch 2532, Loss: 0.00025267408273066394, Final Batch Loss: 0.00020086640142835677\n",
      "Epoch 2533, Loss: 0.00016890229926502798, Final Batch Loss: 1.552198409626726e-05\n",
      "Epoch 2534, Loss: 6.724397098878399e-05, Final Batch Loss: 3.5931832826463506e-05\n",
      "Epoch 2535, Loss: 3.400540845177602e-05, Final Batch Loss: 1.9607485228334554e-05\n",
      "Epoch 2536, Loss: 0.00021029654089943506, Final Batch Loss: 4.539135625236668e-05\n",
      "Epoch 2537, Loss: 0.0012653112644329667, Final Batch Loss: 0.0006769837345927954\n",
      "Epoch 2538, Loss: 0.00028105055753258057, Final Batch Loss: 3.773626303882338e-05\n",
      "Epoch 2539, Loss: 0.00013587989269581158, Final Batch Loss: 0.00012050758232362568\n",
      "Epoch 2540, Loss: 0.00014983673463575542, Final Batch Loss: 7.45458819437772e-05\n",
      "Epoch 2541, Loss: 0.0001539081231385353, Final Batch Loss: 8.88682097865967e-06\n",
      "Epoch 2542, Loss: 0.00013161657807359006, Final Batch Loss: 0.00011832545715151355\n",
      "Epoch 2543, Loss: 3.885200749209616e-05, Final Batch Loss: 9.396928362548351e-06\n",
      "Epoch 2544, Loss: 0.00037549735861830413, Final Batch Loss: 0.00020777055760845542\n",
      "Epoch 2545, Loss: 9.713216422824189e-05, Final Batch Loss: 1.2951095413882285e-05\n",
      "Epoch 2546, Loss: 0.00010113867756444961, Final Batch Loss: 8.696052100276574e-05\n",
      "Epoch 2547, Loss: 0.00026269190857419744, Final Batch Loss: 0.00014571938663721085\n",
      "Epoch 2548, Loss: 0.00022908238588570384, Final Batch Loss: 0.0002171834494220093\n",
      "Epoch 2549, Loss: 0.0002688447884793277, Final Batch Loss: 1.0665174158930313e-05\n",
      "Epoch 2550, Loss: 0.0002839599037542939, Final Batch Loss: 7.20185344107449e-05\n",
      "Epoch 2551, Loss: 0.0045720922644250095, Final Batch Loss: 0.004513719119131565\n",
      "Epoch 2552, Loss: 0.0006956917573006649, Final Batch Loss: 7.5738867053587455e-06\n",
      "Epoch 2553, Loss: 0.0022762912631151266, Final Batch Loss: 0.0001068153724190779\n",
      "Epoch 2554, Loss: 0.0001695358478173148, Final Batch Loss: 5.849486842635088e-05\n",
      "Epoch 2555, Loss: 0.00017829132229962852, Final Batch Loss: 0.00014778591867070645\n",
      "Epoch 2556, Loss: 0.0002927252044173656, Final Batch Loss: 0.00026287854416295886\n",
      "Epoch 2557, Loss: 0.00019772971540987783, Final Batch Loss: 2.10651455745392e-06\n",
      "Epoch 2558, Loss: 0.00011196360583198839, Final Batch Loss: 4.749467279907549e-06\n",
      "Epoch 2559, Loss: 3.8779083524786984e-05, Final Batch Loss: 3.287908157290076e-06\n",
      "Epoch 2560, Loss: 0.0045684074739256175, Final Batch Loss: 2.6583833459881134e-05\n",
      "Epoch 2561, Loss: 4.08934693041374e-06, Final Batch Loss: 1.9899443941540085e-06\n",
      "Epoch 2562, Loss: 0.00013163079984224169, Final Batch Loss: 0.00011727212404366583\n",
      "Epoch 2563, Loss: 0.00013018503886996768, Final Batch Loss: 0.00010514039604458958\n",
      "Epoch 2564, Loss: 0.00017776987897377694, Final Batch Loss: 0.00016585193225182593\n",
      "Epoch 2565, Loss: 0.00046470656525343657, Final Batch Loss: 0.00011819932842627168\n",
      "Epoch 2566, Loss: 5.734371370635927e-05, Final Batch Loss: 6.595793820451945e-06\n",
      "Epoch 2567, Loss: 5.614638575934805e-05, Final Batch Loss: 2.183715332648717e-05\n",
      "Epoch 2568, Loss: 9.62376179813873e-05, Final Batch Loss: 7.24953570170328e-05\n",
      "Epoch 2569, Loss: 0.00013449187463265844, Final Batch Loss: 3.9734160964144394e-05\n",
      "Epoch 2570, Loss: 1.2250316103745718e-05, Final Batch Loss: 4.2981391743524e-06\n",
      "Epoch 2571, Loss: 0.0004363609623396769, Final Batch Loss: 3.254933108109981e-05\n",
      "Epoch 2572, Loss: 9.459043030801695e-05, Final Batch Loss: 1.8642413124325685e-05\n",
      "Epoch 2573, Loss: 0.0016707507311366498, Final Batch Loss: 0.001507776090875268\n",
      "Epoch 2574, Loss: 0.01118860648239206, Final Batch Loss: 0.011166571639478207\n",
      "Epoch 2575, Loss: 8.53460928738059e-05, Final Batch Loss: 5.575236627919367e-06\n",
      "Epoch 2576, Loss: 1.3869799204258015e-05, Final Batch Loss: 9.72935049503576e-06\n",
      "Epoch 2577, Loss: 0.0003475102785159834, Final Batch Loss: 3.5602257412392646e-05\n",
      "Epoch 2578, Loss: 0.0008556537286494859, Final Batch Loss: 0.0007889191037975252\n",
      "Epoch 2579, Loss: 0.0001405432885803748, Final Batch Loss: 8.080555562628433e-05\n",
      "Epoch 2580, Loss: 8.78532009664923e-05, Final Batch Loss: 7.468937837984413e-05\n",
      "Epoch 2581, Loss: 0.00010375084093539044, Final Batch Loss: 4.364038250059821e-05\n",
      "Epoch 2582, Loss: 0.00011560196253412869, Final Batch Loss: 9.167486132355407e-05\n",
      "Epoch 2583, Loss: 0.0004802456242032349, Final Batch Loss: 0.00015582330524921417\n",
      "Epoch 2584, Loss: 0.005786138353869319, Final Batch Loss: 0.004179445095360279\n",
      "Epoch 2585, Loss: 0.003915979131306813, Final Batch Loss: 0.0039043747819960117\n",
      "Epoch 2586, Loss: 3.7538630749622826e-05, Final Batch Loss: 2.6296687792637385e-05\n",
      "Epoch 2587, Loss: 2.339162620046409e-05, Final Batch Loss: 7.5990365075995214e-06\n",
      "Epoch 2588, Loss: 0.0007023221405688673, Final Batch Loss: 0.0001823822094593197\n",
      "Epoch 2589, Loss: 2.6679248037453362e-05, Final Batch Loss: 5.882115488020645e-07\n",
      "Epoch 2590, Loss: 0.0018242285959786386, Final Batch Loss: 8.992888069769833e-06\n",
      "Epoch 2591, Loss: 0.0008384462853427976, Final Batch Loss: 0.0004252271610312164\n",
      "Epoch 2592, Loss: 5.730942029913422e-05, Final Batch Loss: 3.4163749660365283e-05\n",
      "Epoch 2593, Loss: 6.412457423721207e-05, Final Batch Loss: 7.719695531704929e-06\n",
      "Epoch 2594, Loss: 4.558729506243253e-05, Final Batch Loss: 7.870880835980643e-06\n",
      "Epoch 2595, Loss: 8.404505933867767e-05, Final Batch Loss: 1.4651312085334212e-05\n",
      "Epoch 2596, Loss: 3.927295040284662e-06, Final Batch Loss: 5.011957568967773e-07\n",
      "Epoch 2597, Loss: 0.003474869590718299, Final Batch Loss: 0.0034255587961524725\n",
      "Epoch 2598, Loss: 9.051053348230198e-05, Final Batch Loss: 6.277226930251345e-05\n",
      "Epoch 2599, Loss: 7.031662335066358e-05, Final Batch Loss: 1.2169622095825616e-05\n",
      "Epoch 2600, Loss: 0.003655029518995434, Final Batch Loss: 0.0034497841261327267\n",
      "Epoch 2601, Loss: 0.0012921398083562963, Final Batch Loss: 0.0012374711222946644\n",
      "Epoch 2602, Loss: 0.0021553135393332923, Final Batch Loss: 5.6203371059382334e-06\n",
      "Epoch 2603, Loss: 0.005706712334358599, Final Batch Loss: 0.005689908284693956\n",
      "Epoch 2604, Loss: 4.3864851249963976e-05, Final Batch Loss: 2.448483974148985e-05\n",
      "Epoch 2605, Loss: 0.00034036267697956646, Final Batch Loss: 1.2319259440118913e-05\n",
      "Epoch 2606, Loss: 7.760111111565493e-05, Final Batch Loss: 6.698256765957922e-05\n",
      "Epoch 2607, Loss: 2.3225821223604726e-05, Final Batch Loss: 1.9368695575394668e-05\n",
      "Epoch 2608, Loss: 1.549266357869783e-05, Final Batch Loss: 1.251642606803216e-05\n",
      "Epoch 2609, Loss: 0.00481705568927282, Final Batch Loss: 0.004791673738509417\n",
      "Epoch 2610, Loss: 0.0007566207787021995, Final Batch Loss: 0.00021939579164609313\n",
      "Epoch 2611, Loss: 0.000913020693587896, Final Batch Loss: 0.0008992166258394718\n",
      "Epoch 2612, Loss: 0.00026486012575333007, Final Batch Loss: 0.00020704485359601676\n",
      "Epoch 2613, Loss: 1.5279628087228048e-05, Final Batch Loss: 1.1555791388673242e-05\n",
      "Epoch 2614, Loss: 1.5684019217587775e-05, Final Batch Loss: 1.1615879884629976e-06\n",
      "Epoch 2615, Loss: 5.091922525934933e-05, Final Batch Loss: 2.2073948002798716e-06\n",
      "Epoch 2616, Loss: 1.372399447063799e-05, Final Batch Loss: 9.218357263307553e-06\n",
      "Epoch 2617, Loss: 0.00015626955428160727, Final Batch Loss: 7.009925320744514e-05\n",
      "Epoch 2618, Loss: 0.00011834144515887601, Final Batch Loss: 0.00011153119703521952\n",
      "Epoch 2619, Loss: 2.3488557417294942e-05, Final Batch Loss: 5.278065145830624e-06\n",
      "Epoch 2620, Loss: 0.003889183353749104, Final Batch Loss: 0.0038220626302063465\n",
      "Epoch 2621, Loss: 0.00012026102047002496, Final Batch Loss: 7.456968660335406e-07\n",
      "Epoch 2622, Loss: 0.00010758371354313567, Final Batch Loss: 6.28233392490074e-05\n",
      "Epoch 2623, Loss: 0.002048363016001531, Final Batch Loss: 2.336692159587983e-05\n",
      "Epoch 2624, Loss: 0.00018505787011235952, Final Batch Loss: 2.564593160059303e-05\n",
      "Epoch 2625, Loss: 0.0006891357625136152, Final Batch Loss: 8.72499804245308e-05\n",
      "Epoch 2626, Loss: 0.0041372252999281045, Final Batch Loss: 0.004077475517988205\n",
      "Epoch 2627, Loss: 0.0005579873651413436, Final Batch Loss: 1.1894118188138236e-06\n",
      "Epoch 2628, Loss: 0.0001027659818646498, Final Batch Loss: 6.368572940118611e-05\n",
      "Epoch 2629, Loss: 0.00010627582287270343, Final Batch Loss: 9.173825674224645e-05\n",
      "Epoch 2630, Loss: 0.0001695655519142747, Final Batch Loss: 3.838549309875816e-05\n",
      "Epoch 2631, Loss: 0.004710564971901476, Final Batch Loss: 0.004275334533303976\n",
      "Epoch 2632, Loss: 0.00015893288400548045, Final Batch Loss: 2.3236987544805743e-05\n",
      "Epoch 2633, Loss: 0.044122215134848375, Final Batch Loss: 0.044004637748003006\n",
      "Epoch 2634, Loss: 0.0008835996050038375, Final Batch Loss: 0.0007955721230246127\n",
      "Epoch 2635, Loss: 0.0009327964507974684, Final Batch Loss: 0.0003142746863886714\n",
      "Epoch 2636, Loss: 0.0012443341256584972, Final Batch Loss: 0.00015069133951328695\n",
      "Epoch 2637, Loss: 7.521139923483133e-05, Final Batch Loss: 1.848470128607005e-05\n",
      "Epoch 2638, Loss: 0.00029924970294814557, Final Batch Loss: 0.00016891147242859006\n",
      "Epoch 2639, Loss: 0.0003426095317990985, Final Batch Loss: 0.00029084578272886574\n",
      "Epoch 2640, Loss: 0.000826777702968684, Final Batch Loss: 0.0008067896123975515\n",
      "Epoch 2641, Loss: 0.029114454655427835, Final Batch Loss: 2.9008506317040883e-05\n",
      "Epoch 2642, Loss: 0.00838079466484487, Final Batch Loss: 0.0035227469634264708\n",
      "Epoch 2643, Loss: 0.00011512321043483098, Final Batch Loss: 0.00011254129640292376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2644, Loss: 0.00023710144250799203, Final Batch Loss: 0.0002270852419314906\n",
      "Epoch 2645, Loss: 0.0003690126468427479, Final Batch Loss: 0.00010350820957683027\n",
      "Epoch 2646, Loss: 1.9805352167168166e-05, Final Batch Loss: 1.3565262634074315e-05\n",
      "Epoch 2647, Loss: 0.0007766585404169746, Final Batch Loss: 5.98482511122711e-05\n",
      "Epoch 2648, Loss: 0.00012926417775815935, Final Batch Loss: 6.716562438668916e-06\n",
      "Epoch 2649, Loss: 8.24049911898328e-05, Final Batch Loss: 6.005177419865504e-05\n",
      "Epoch 2650, Loss: 0.0009280351259803865, Final Batch Loss: 0.0008988613844849169\n",
      "Epoch 2651, Loss: 0.00035629620833788067, Final Batch Loss: 0.00023912964388728142\n",
      "Epoch 2652, Loss: 0.0012879450659966096, Final Batch Loss: 0.0010780955199152231\n",
      "Epoch 2653, Loss: 0.0001237295218743384, Final Batch Loss: 5.288263491820544e-05\n",
      "Epoch 2654, Loss: 0.001968691671208944, Final Batch Loss: 4.352904943516478e-05\n",
      "Epoch 2655, Loss: 0.00016034808504628018, Final Batch Loss: 5.2947711083106697e-05\n",
      "Epoch 2656, Loss: 0.0005445695405796869, Final Batch Loss: 0.0005145542090758681\n",
      "Epoch 2657, Loss: 0.00022914462715561967, Final Batch Loss: 2.560776010795962e-05\n",
      "Epoch 2658, Loss: 0.003287702798843384, Final Batch Loss: 0.0006438533309847116\n",
      "Epoch 2659, Loss: 0.003746509610209614, Final Batch Loss: 4.27219201810658e-05\n",
      "Epoch 2660, Loss: 0.0003665476069727447, Final Batch Loss: 9.685954864835367e-06\n",
      "Epoch 2661, Loss: 0.002198091555328574, Final Batch Loss: 8.13662409200333e-05\n",
      "Epoch 2662, Loss: 0.00021871895296499133, Final Batch Loss: 0.0001365132484352216\n",
      "Epoch 2663, Loss: 0.000632220325542221, Final Batch Loss: 0.0006300184759311378\n",
      "Epoch 2664, Loss: 0.0005515344123523391, Final Batch Loss: 4.2944479901052546e-06\n",
      "Epoch 2665, Loss: 0.0021532384907914093, Final Batch Loss: 1.257562507817056e-05\n",
      "Epoch 2666, Loss: 6.682216371700633e-05, Final Batch Loss: 4.9422673328081146e-05\n",
      "Epoch 2667, Loss: 3.7055711800348945e-05, Final Batch Loss: 2.102376129187178e-05\n",
      "Epoch 2668, Loss: 0.0011321511592541356, Final Batch Loss: 0.00108182686381042\n",
      "Epoch 2669, Loss: 0.00010841243420145474, Final Batch Loss: 5.2536779548972845e-05\n",
      "Epoch 2670, Loss: 5.563604372582631e-05, Final Batch Loss: 4.158365118200891e-05\n",
      "Epoch 2671, Loss: 0.0005678260099557519, Final Batch Loss: 0.0005627149366773665\n",
      "Epoch 2672, Loss: 0.00011924522050321684, Final Batch Loss: 0.00011425338743720204\n",
      "Epoch 2673, Loss: 0.0035943896073149517, Final Batch Loss: 0.00017217938147950917\n",
      "Epoch 2674, Loss: 0.004185308760497719, Final Batch Loss: 0.000905380176845938\n",
      "Epoch 2675, Loss: 0.0003785404551308602, Final Batch Loss: 2.16829648707062e-05\n",
      "Epoch 2676, Loss: 0.0006643103938586137, Final Batch Loss: 2.8338204174360726e-06\n",
      "Epoch 2677, Loss: 0.00045169461282057455, Final Batch Loss: 0.0004422240308485925\n",
      "Epoch 2678, Loss: 0.002369232170167379, Final Batch Loss: 7.8038006904535e-05\n",
      "Epoch 2679, Loss: 0.001219810277234501, Final Batch Loss: 6.935034889465896e-06\n",
      "Epoch 2680, Loss: 0.004543532384559512, Final Batch Loss: 0.004456569906324148\n",
      "Epoch 2681, Loss: 0.0001392060876241885, Final Batch Loss: 3.2435840694233775e-05\n",
      "Epoch 2682, Loss: 7.173954077188682e-05, Final Batch Loss: 1.8254825135954889e-06\n",
      "Epoch 2683, Loss: 4.995899143978022e-05, Final Batch Loss: 3.846544132102281e-06\n",
      "Epoch 2684, Loss: 7.778612052788958e-05, Final Batch Loss: 3.998179090558551e-05\n",
      "Epoch 2685, Loss: 5.2849817166134017e-05, Final Batch Loss: 7.082879619701998e-06\n",
      "Epoch 2686, Loss: 0.0001483014020777773, Final Batch Loss: 9.046361083164811e-05\n",
      "Epoch 2687, Loss: 4.760802391956531e-05, Final Batch Loss: 1.7306300605923752e-06\n",
      "Epoch 2688, Loss: 0.006733969421475194, Final Batch Loss: 0.00010349751391913742\n",
      "Epoch 2689, Loss: 6.70464269205695e-05, Final Batch Loss: 5.629776569548994e-05\n",
      "Epoch 2690, Loss: 0.00032122373522724956, Final Batch Loss: 0.0002835156919900328\n",
      "Epoch 2691, Loss: 9.951755055226386e-05, Final Batch Loss: 7.88292454672046e-05\n",
      "Epoch 2692, Loss: 8.163878328559804e-05, Final Batch Loss: 5.862071247975109e-06\n",
      "Epoch 2693, Loss: 0.003967078650020994, Final Batch Loss: 0.003733796300366521\n",
      "Epoch 2694, Loss: 0.006331736003630795, Final Batch Loss: 0.006287026219069958\n",
      "Epoch 2695, Loss: 0.0004056249536006362, Final Batch Loss: 1.4733298485225532e-05\n",
      "Epoch 2696, Loss: 5.252152641332941e-05, Final Batch Loss: 1.1223576620977838e-05\n",
      "Epoch 2697, Loss: 0.00015967410672601545, Final Batch Loss: 1.231981241289759e-05\n",
      "Epoch 2698, Loss: 0.001314404362346977, Final Batch Loss: 0.0005349945276975632\n",
      "Epoch 2699, Loss: 0.0018227639084216207, Final Batch Loss: 0.00011727874516509473\n",
      "Epoch 2700, Loss: 0.0006153610302135348, Final Batch Loss: 0.00036808958975598216\n",
      "Epoch 2701, Loss: 0.0020621065559680574, Final Batch Loss: 8.117878314806148e-05\n",
      "Epoch 2702, Loss: 0.0015669101412640885, Final Batch Loss: 7.238549005705863e-05\n",
      "Epoch 2703, Loss: 0.002490376980858855, Final Batch Loss: 0.00022412293765228242\n",
      "Epoch 2704, Loss: 0.00010604738145048032, Final Batch Loss: 9.931837121257558e-05\n",
      "Epoch 2705, Loss: 0.0027198458374186885, Final Batch Loss: 0.002666671061888337\n",
      "Epoch 2706, Loss: 8.474905371258501e-05, Final Batch Loss: 2.1457637558341958e-05\n",
      "Epoch 2707, Loss: 0.00018199988426204072, Final Batch Loss: 0.00017276890866924077\n",
      "Epoch 2708, Loss: 5.294105903885793e-05, Final Batch Loss: 2.106539068336133e-05\n",
      "Epoch 2709, Loss: 0.0014887085126247257, Final Batch Loss: 0.00025466058286838233\n",
      "Epoch 2710, Loss: 0.0022098460831330158, Final Batch Loss: 9.200271597364917e-05\n",
      "Epoch 2711, Loss: 0.0031243583471223246, Final Batch Loss: 1.5817797248018906e-05\n",
      "Epoch 2712, Loss: 0.00040074340358842164, Final Batch Loss: 0.0001472871663281694\n",
      "Epoch 2713, Loss: 0.0004952088565914892, Final Batch Loss: 3.618676419137046e-05\n",
      "Epoch 2714, Loss: 1.351270134364313e-05, Final Batch Loss: 2.897417516578571e-06\n",
      "Epoch 2715, Loss: 0.00010721757303144841, Final Batch Loss: 2.6083437205670634e-06\n",
      "Epoch 2716, Loss: 0.0003809538520727074, Final Batch Loss: 2.001970096898731e-05\n",
      "Epoch 2717, Loss: 9.49295936152339e-05, Final Batch Loss: 6.982270133448765e-05\n",
      "Epoch 2718, Loss: 0.0004844577797484817, Final Batch Loss: 8.774792149779387e-06\n",
      "Epoch 2719, Loss: 1.5698029528721236e-05, Final Batch Loss: 1.1398167771403678e-05\n",
      "Epoch 2720, Loss: 0.00019481484196148813, Final Batch Loss: 0.00010803092300193384\n",
      "Epoch 2721, Loss: 0.0003600744530558586, Final Batch Loss: 0.00011437339708209038\n",
      "Epoch 2722, Loss: 0.0029923457750555826, Final Batch Loss: 4.889732736046426e-06\n",
      "Epoch 2723, Loss: 3.443948264703067e-05, Final Batch Loss: 8.805687912172289e-07\n",
      "Epoch 2724, Loss: 0.0024786173507891363, Final Batch Loss: 2.3458493160433136e-05\n",
      "Epoch 2725, Loss: 0.00017907258370541967, Final Batch Loss: 0.0001563157420605421\n",
      "Epoch 2726, Loss: 0.0005546364045585506, Final Batch Loss: 4.6224959078244865e-06\n",
      "Epoch 2727, Loss: 2.466159639880061e-05, Final Batch Loss: 2.0224761101417243e-05\n",
      "Epoch 2728, Loss: 0.0021950587292849377, Final Batch Loss: 0.00219177664257586\n",
      "Epoch 2729, Loss: 7.622305565746501e-05, Final Batch Loss: 5.787694681202993e-05\n",
      "Epoch 2730, Loss: 0.00033204823557753116, Final Batch Loss: 0.0002244080969830975\n",
      "Epoch 2731, Loss: 0.0007423582865158096, Final Batch Loss: 0.0006153611466288567\n",
      "Epoch 2732, Loss: 0.00026810033909896447, Final Batch Loss: 0.0002657230943441391\n",
      "Epoch 2733, Loss: 0.00019703938960446976, Final Batch Loss: 0.00014769092376809567\n",
      "Epoch 2734, Loss: 0.00019235274521633983, Final Batch Loss: 0.00018559319141786546\n",
      "Epoch 2735, Loss: 0.0027192797870156937, Final Batch Loss: 3.9678425309830345e-06\n",
      "Epoch 2736, Loss: 0.00016617812570984825, Final Batch Loss: 0.00015967049694154412\n",
      "Epoch 2737, Loss: 0.00022006942162988707, Final Batch Loss: 7.343194010900334e-05\n",
      "Epoch 2738, Loss: 2.8779124477296136e-05, Final Batch Loss: 1.8847717001335695e-05\n",
      "Epoch 2739, Loss: 0.0009518607977270221, Final Batch Loss: 1.2277151881789905e-06\n",
      "Epoch 2740, Loss: 0.00027713309100363404, Final Batch Loss: 0.00015858914412092417\n",
      "Epoch 2741, Loss: 7.296936382772401e-05, Final Batch Loss: 5.193955803406425e-05\n",
      "Epoch 2742, Loss: 3.8105607018223964e-05, Final Batch Loss: 2.2963056835578755e-05\n",
      "Epoch 2743, Loss: 3.2476591968588764e-05, Final Batch Loss: 2.7619575121207163e-05\n",
      "Epoch 2744, Loss: 0.0034498782179070986, Final Batch Loss: 5.725100891140755e-06\n",
      "Epoch 2745, Loss: 2.955957461381331e-05, Final Batch Loss: 2.000109634536784e-05\n",
      "Epoch 2746, Loss: 0.000388712278663661, Final Batch Loss: 2.518098199288943e-06\n",
      "Epoch 2747, Loss: 0.00011056951734644827, Final Batch Loss: 8.51078366395086e-05\n",
      "Epoch 2748, Loss: 0.002880646410631016, Final Batch Loss: 0.00012974280980415642\n",
      "Epoch 2749, Loss: 0.00029249772342154756, Final Batch Loss: 7.424140494549647e-05\n",
      "Epoch 2750, Loss: 2.349589351524628e-06, Final Batch Loss: 6.908821319484559e-07\n",
      "Epoch 2751, Loss: 0.000256681192695396, Final Batch Loss: 3.054303306271322e-05\n",
      "Epoch 2752, Loss: 5.212494943407364e-05, Final Batch Loss: 8.156483090715483e-06\n",
      "Epoch 2753, Loss: 1.3109815995449026e-05, Final Batch Loss: 1.5757897244839114e-06\n",
      "Epoch 2754, Loss: 6.788111932110041e-05, Final Batch Loss: 2.4397199013037607e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2755, Loss: 0.004655199596982129, Final Batch Loss: 4.7059788812475745e-06\n",
      "Epoch 2756, Loss: 0.00018933335923065897, Final Batch Loss: 1.2479771612561308e-05\n",
      "Epoch 2757, Loss: 7.024099795671646e-05, Final Batch Loss: 8.072218406596221e-06\n",
      "Epoch 2758, Loss: 5.734969818149693e-05, Final Batch Loss: 2.7233581931795925e-05\n",
      "Epoch 2759, Loss: 2.3249960577231832e-05, Final Batch Loss: 7.540320439147763e-06\n",
      "Epoch 2760, Loss: 4.227801400702447e-05, Final Batch Loss: 8.554157830076292e-06\n",
      "Epoch 2761, Loss: 0.0005660312017425895, Final Batch Loss: 0.00029163897852413356\n",
      "Epoch 2762, Loss: 0.0011680638272082433, Final Batch Loss: 0.0009273372124880552\n",
      "Epoch 2763, Loss: 0.00037355211134126876, Final Batch Loss: 0.00035345801734365523\n",
      "Epoch 2764, Loss: 0.00016038764078984968, Final Batch Loss: 0.00013017533638048917\n",
      "Epoch 2765, Loss: 0.000107449118331715, Final Batch Loss: 8.822705240163486e-06\n",
      "Epoch 2766, Loss: 0.00013936742470832542, Final Batch Loss: 4.71866806037724e-05\n",
      "Epoch 2767, Loss: 0.00027053679400523833, Final Batch Loss: 0.0002670477260835469\n",
      "Epoch 2768, Loss: 0.00026988414902007207, Final Batch Loss: 0.00011268539674347267\n",
      "Epoch 2769, Loss: 0.002606679165182868, Final Batch Loss: 0.0025865682400763035\n",
      "Epoch 2770, Loss: 2.2564127334590012e-05, Final Batch Loss: 2.111515095748473e-05\n",
      "Epoch 2771, Loss: 6.0453367041191086e-05, Final Batch Loss: 4.0068101952783763e-05\n",
      "Epoch 2772, Loss: 3.645476817837334e-05, Final Batch Loss: 3.0744486139155924e-05\n",
      "Epoch 2773, Loss: 3.5032402593060397e-05, Final Batch Loss: 2.486595076334197e-05\n",
      "Epoch 2774, Loss: 0.00023888021632956224, Final Batch Loss: 4.02591058445978e-06\n",
      "Epoch 2775, Loss: 0.00016083405512290483, Final Batch Loss: 0.00015882286243140697\n",
      "Epoch 2776, Loss: 0.00022553022427018732, Final Batch Loss: 0.00016160568338818848\n",
      "Epoch 2777, Loss: 5.885384990733655e-05, Final Batch Loss: 5.807423804071732e-05\n",
      "Epoch 2778, Loss: 0.002927575431385776, Final Batch Loss: 0.002922294894233346\n",
      "Epoch 2779, Loss: 1.5755935351080552e-05, Final Batch Loss: 1.132894908550952e-06\n",
      "Epoch 2780, Loss: 9.106908464673324e-06, Final Batch Loss: 2.2655606244370574e-06\n",
      "Epoch 2781, Loss: 4.957299643137958e-05, Final Batch Loss: 3.054226181120612e-05\n",
      "Epoch 2782, Loss: 0.00021478217695403146, Final Batch Loss: 0.00020342176139820367\n",
      "Epoch 2783, Loss: 0.001502231927588582, Final Batch Loss: 0.0005272968555800617\n",
      "Epoch 2784, Loss: 0.00012933457310282392, Final Batch Loss: 0.00011694922432070598\n",
      "Epoch 2785, Loss: 1.8459974171491922e-06, Final Batch Loss: 9.414688975084573e-07\n",
      "Epoch 2786, Loss: 0.00014347054820973426, Final Batch Loss: 7.18776645953767e-05\n",
      "Epoch 2787, Loss: 2.432775272609433e-05, Final Batch Loss: 1.920907561725471e-05\n",
      "Epoch 2788, Loss: 3.174333687638864e-05, Final Batch Loss: 1.543305734230671e-05\n",
      "Epoch 2789, Loss: 1.3960456499262364e-05, Final Batch Loss: 1.3660749118571403e-06\n",
      "Epoch 2790, Loss: 1.9057520148635376e-05, Final Batch Loss: 7.956309673318174e-06\n",
      "Epoch 2791, Loss: 0.00019288100884296, Final Batch Loss: 0.0001454745652154088\n",
      "Epoch 2792, Loss: 2.7924046662519686e-05, Final Batch Loss: 8.153694579959847e-06\n",
      "Epoch 2793, Loss: 3.8352381125150714e-05, Final Batch Loss: 2.6370849809609354e-05\n",
      "Epoch 2794, Loss: 8.488787716487423e-05, Final Batch Loss: 5.52169258298818e-05\n",
      "Epoch 2795, Loss: 0.0011549765040399507, Final Batch Loss: 0.0010254665976390243\n",
      "Epoch 2796, Loss: 2.7722628260562487e-05, Final Batch Loss: 1.8628380757945706e-06\n",
      "Epoch 2797, Loss: 0.00013199126897234237, Final Batch Loss: 1.1392722626624163e-05\n",
      "Epoch 2798, Loss: 0.00026727095973910764, Final Batch Loss: 2.909001341322437e-05\n",
      "Epoch 2799, Loss: 0.0022924998938833596, Final Batch Loss: 0.0022848648950457573\n",
      "Epoch 2800, Loss: 0.0020319320783528383, Final Batch Loss: 1.3111816770106088e-05\n",
      "Epoch 2801, Loss: 0.0012282210191187914, Final Batch Loss: 3.240027217543684e-05\n",
      "Epoch 2802, Loss: 0.005094852313050069, Final Batch Loss: 0.005001303274184465\n",
      "Epoch 2803, Loss: 9.601810234016739e-05, Final Batch Loss: 7.674688094994053e-05\n",
      "Epoch 2804, Loss: 0.00017160167590191122, Final Batch Loss: 1.4416384146898054e-05\n",
      "Epoch 2805, Loss: 5.065453933639219e-05, Final Batch Loss: 3.495962118904572e-06\n",
      "Epoch 2806, Loss: 0.00018390753677977045, Final Batch Loss: 0.00018277174967806786\n",
      "Epoch 2807, Loss: 3.358371668582549e-05, Final Batch Loss: 2.8719843612634577e-05\n",
      "Epoch 2808, Loss: 2.7784091344074113e-05, Final Batch Loss: 2.1569379896391183e-05\n",
      "Epoch 2809, Loss: 0.0016674787912052125, Final Batch Loss: 0.0015914536779746413\n",
      "Epoch 2810, Loss: 7.577095993838157e-05, Final Batch Loss: 1.739277195156319e-06\n",
      "Epoch 2811, Loss: 0.00010091744115925394, Final Batch Loss: 3.0442704883171245e-05\n",
      "Epoch 2812, Loss: 5.028700161346933e-05, Final Batch Loss: 4.1620216506998986e-05\n",
      "Epoch 2813, Loss: 0.024460389584419318, Final Batch Loss: 0.024446796625852585\n",
      "Epoch 2814, Loss: 7.432300594700791e-05, Final Batch Loss: 7.087003177730367e-05\n",
      "Epoch 2815, Loss: 2.5031939287600835e-05, Final Batch Loss: 7.213278081508179e-07\n",
      "Epoch 2816, Loss: 0.0001227991160703823, Final Batch Loss: 8.150903886416927e-05\n",
      "Epoch 2817, Loss: 0.002539565375627717, Final Batch Loss: 5.791970397694968e-05\n",
      "Epoch 2818, Loss: 0.002277821142342873, Final Batch Loss: 3.1723015126772225e-05\n",
      "Epoch 2819, Loss: 0.00019802967653959058, Final Batch Loss: 2.093673901981674e-05\n",
      "Epoch 2820, Loss: 0.00016836699796840549, Final Batch Loss: 3.4532436984591186e-05\n",
      "Epoch 2821, Loss: 0.00023051872631185688, Final Batch Loss: 6.63346509099938e-06\n",
      "Epoch 2822, Loss: 0.006399105778143621, Final Batch Loss: 4.898851670986915e-07\n",
      "Epoch 2823, Loss: 0.00018805726040227455, Final Batch Loss: 0.00018303451361134648\n",
      "Epoch 2824, Loss: 0.0007348628219006059, Final Batch Loss: 2.2647523110208567e-06\n",
      "Epoch 2825, Loss: 1.0064328307635151e-05, Final Batch Loss: 4.472085038287332e-06\n",
      "Epoch 2826, Loss: 6.082000436435919e-05, Final Batch Loss: 3.330769686726853e-05\n",
      "Epoch 2827, Loss: 0.00027269280326436274, Final Batch Loss: 5.485192741616629e-05\n",
      "Epoch 2828, Loss: 0.0043487372604431584, Final Batch Loss: 0.004218224436044693\n",
      "Epoch 2829, Loss: 0.00014891728278598748, Final Batch Loss: 4.7254001401597634e-05\n",
      "Epoch 2830, Loss: 6.405550448107533e-05, Final Batch Loss: 2.6201727450825274e-05\n",
      "Epoch 2831, Loss: 0.0012324594899837393, Final Batch Loss: 5.944997610640712e-05\n",
      "Epoch 2832, Loss: 2.5716620029925252e-05, Final Batch Loss: 2.3018053980194964e-05\n",
      "Epoch 2833, Loss: 1.1813686342065921e-05, Final Batch Loss: 1.0763119462353643e-06\n",
      "Epoch 2834, Loss: 2.559502308940864e-05, Final Batch Loss: 3.823442511929898e-06\n",
      "Epoch 2835, Loss: 0.00020705816649524422, Final Batch Loss: 7.561299639746721e-07\n",
      "Epoch 2836, Loss: 0.00019723131117643788, Final Batch Loss: 0.00011367977276677266\n",
      "Epoch 2837, Loss: 0.0012311255122767761, Final Batch Loss: 0.0011152708902955055\n",
      "Epoch 2838, Loss: 0.0015946637322485913, Final Batch Loss: 5.244558633421548e-05\n",
      "Epoch 2839, Loss: 0.00010177664444199763, Final Batch Loss: 5.789887654827908e-05\n",
      "Epoch 2840, Loss: 3.41421549592269e-05, Final Batch Loss: 1.2781896430169581e-06\n",
      "Epoch 2841, Loss: 0.003234658292512904, Final Batch Loss: 5.010417680750834e-06\n",
      "Epoch 2842, Loss: 0.0026898957876255736, Final Batch Loss: 4.865728260483593e-05\n",
      "Epoch 2843, Loss: 0.00019605627312557772, Final Batch Loss: 0.0001651892380323261\n",
      "Epoch 2844, Loss: 0.0002952949216705747, Final Batch Loss: 0.0002115132665494457\n",
      "Epoch 2845, Loss: 3.4234665690746624e-05, Final Batch Loss: 9.051223059941549e-06\n",
      "Epoch 2846, Loss: 0.00020149592819507234, Final Batch Loss: 5.404672629083507e-05\n",
      "Epoch 2847, Loss: 2.3181754386314424e-05, Final Batch Loss: 9.057916940946598e-07\n",
      "Epoch 2848, Loss: 1.390551551594399e-05, Final Batch Loss: 7.175279733928619e-06\n",
      "Epoch 2849, Loss: 0.00033194849493156653, Final Batch Loss: 2.443908124405425e-05\n",
      "Epoch 2850, Loss: 0.002949036381323822, Final Batch Loss: 0.00012045232870150357\n",
      "Epoch 2851, Loss: 0.0001653370782150887, Final Batch Loss: 9.037710697157308e-05\n",
      "Epoch 2852, Loss: 2.0622565386929637e-05, Final Batch Loss: 2.6452147494637757e-07\n",
      "Epoch 2853, Loss: 7.361271673289593e-05, Final Batch Loss: 5.1537761464715004e-05\n",
      "Epoch 2854, Loss: 0.00538153225897986, Final Batch Loss: 2.662431143107824e-06\n",
      "Epoch 2855, Loss: 1.7580178564458038e-05, Final Batch Loss: 1.5643394362996332e-05\n",
      "Epoch 2856, Loss: 0.0015749211015645415, Final Batch Loss: 0.0002740943164099008\n",
      "Epoch 2857, Loss: 0.00018240992994833505, Final Batch Loss: 1.5099575648491737e-05\n",
      "Epoch 2858, Loss: 0.000262754263530951, Final Batch Loss: 0.00021858738909941167\n",
      "Epoch 2859, Loss: 0.00023692568720434792, Final Batch Loss: 0.0001922747032949701\n",
      "Epoch 2860, Loss: 2.9915160212112824e-05, Final Batch Loss: 2.337502155569382e-05\n",
      "Epoch 2861, Loss: 8.310504881592351e-06, Final Batch Loss: 3.5715745525521925e-06\n",
      "Epoch 2862, Loss: 9.611201608095143e-05, Final Batch Loss: 1.954125082193059e-06\n",
      "Epoch 2863, Loss: 0.00014157394980429672, Final Batch Loss: 0.00012741748651023954\n",
      "Epoch 2864, Loss: 0.0011398790056773578, Final Batch Loss: 1.3608264453068841e-05\n",
      "Epoch 2865, Loss: 0.006716783624142408, Final Batch Loss: 0.0030773929320275784\n",
      "Epoch 2866, Loss: 0.004541407513897866, Final Batch Loss: 0.004114935640245676\n",
      "Epoch 2867, Loss: 0.0004028829016533564, Final Batch Loss: 8.411126145801973e-06\n",
      "Epoch 2868, Loss: 0.00016237607633229345, Final Batch Loss: 9.836051322054118e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2869, Loss: 0.0004709985660156235, Final Batch Loss: 0.00022076618915889412\n",
      "Epoch 2870, Loss: 4.692020047514234e-05, Final Batch Loss: 2.581436092441436e-05\n",
      "Epoch 2871, Loss: 0.0002162047854312732, Final Batch Loss: 2.392876581325254e-07\n",
      "Epoch 2872, Loss: 0.00031513940939476015, Final Batch Loss: 3.997837666247506e-06\n",
      "Epoch 2873, Loss: 5.7537638895155396e-05, Final Batch Loss: 4.403155980980955e-05\n",
      "Epoch 2874, Loss: 0.0034914566701900185, Final Batch Loss: 2.4615353595436318e-06\n",
      "Epoch 2875, Loss: 0.0018940693407785147, Final Batch Loss: 0.0017578158294782043\n",
      "Epoch 2876, Loss: 0.00022543758313986473, Final Batch Loss: 0.00017890660092234612\n",
      "Epoch 2877, Loss: 0.008877712290995987, Final Batch Loss: 0.008839629590511322\n",
      "Epoch 2878, Loss: 0.0005472158700285945, Final Batch Loss: 0.0005207274807617068\n",
      "Epoch 2879, Loss: 7.607980114698876e-05, Final Batch Loss: 4.6390265197260305e-05\n",
      "Epoch 2880, Loss: 0.00039626617945032194, Final Batch Loss: 0.0003208441485185176\n",
      "Epoch 2881, Loss: 0.001467638328904286, Final Batch Loss: 5.3263065638020635e-05\n",
      "Epoch 2882, Loss: 0.004038849667267641, Final Batch Loss: 1.2477215932449326e-05\n",
      "Epoch 2883, Loss: 9.839471385930665e-05, Final Batch Loss: 4.193885615677573e-05\n",
      "Epoch 2884, Loss: 0.00010497798757569399, Final Batch Loss: 9.23626430449076e-05\n",
      "Epoch 2885, Loss: 5.8126844123762567e-05, Final Batch Loss: 4.3472649849718437e-05\n",
      "Epoch 2886, Loss: 5.6393539807686466e-05, Final Batch Loss: 2.9928057756478665e-06\n",
      "Epoch 2887, Loss: 6.294107515714131e-05, Final Batch Loss: 3.342860873090103e-05\n",
      "Epoch 2888, Loss: 0.043960578041151166, Final Batch Loss: 0.0419788621366024\n",
      "Epoch 2889, Loss: 0.0014457709112321027, Final Batch Loss: 6.758113886462525e-05\n",
      "Epoch 2890, Loss: 8.431992682744749e-05, Final Batch Loss: 7.915823516668752e-05\n",
      "Epoch 2891, Loss: 1.2526232694654027e-05, Final Batch Loss: 8.379787686862983e-06\n",
      "Epoch 2892, Loss: 4.577445542963687e-05, Final Batch Loss: 2.6866382540902123e-06\n",
      "Epoch 2893, Loss: 2.0989615222788416e-05, Final Batch Loss: 3.2236621336778626e-06\n",
      "Epoch 2894, Loss: 0.00039052548845575075, Final Batch Loss: 5.103316198074026e-06\n",
      "Epoch 2895, Loss: 0.0002188190071592544, Final Batch Loss: 2.3979471279744757e-06\n",
      "Epoch 2896, Loss: 0.0001591613909113221, Final Batch Loss: 2.6787143724504858e-05\n",
      "Epoch 2897, Loss: 0.00018274477770319209, Final Batch Loss: 4.309806536184624e-05\n",
      "Epoch 2898, Loss: 4.3768199930127594e-05, Final Batch Loss: 2.981760871989536e-06\n",
      "Epoch 2899, Loss: 4.025770022053621e-05, Final Batch Loss: 5.06640344610787e-06\n",
      "Epoch 2900, Loss: 0.003055476292502135, Final Batch Loss: 0.0002727831597439945\n",
      "Epoch 2901, Loss: 1.7325938188150758e-05, Final Batch Loss: 2.2072240426496137e-06\n",
      "Epoch 2902, Loss: 2.4136998725055037e-05, Final Batch Loss: 1.1833868285293647e-07\n",
      "Epoch 2903, Loss: 0.0006541403818118852, Final Batch Loss: 0.0006402587168850005\n",
      "Epoch 2904, Loss: 8.745296202050667e-05, Final Batch Loss: 1.3312643432072946e-06\n",
      "Epoch 2905, Loss: 5.89180453971494e-05, Final Batch Loss: 2.4150060198735446e-05\n",
      "Epoch 2906, Loss: 0.00442905594536569, Final Batch Loss: 0.004223177675157785\n",
      "Epoch 2907, Loss: 0.0018341470931773074, Final Batch Loss: 0.0017612791853025556\n",
      "Epoch 2908, Loss: 0.002841079949575942, Final Batch Loss: 3.218591882614419e-05\n",
      "Epoch 2909, Loss: 9.592518484424772e-06, Final Batch Loss: 3.6545873882687374e-08\n",
      "Epoch 2910, Loss: 0.0026041877827083226, Final Batch Loss: 3.641270086518489e-05\n",
      "Epoch 2911, Loss: 4.027805334771983e-05, Final Batch Loss: 2.0202980522299185e-05\n",
      "Epoch 2912, Loss: 0.0003971747646573931, Final Batch Loss: 0.000210674581467174\n",
      "Epoch 2913, Loss: 0.0038431082358556523, Final Batch Loss: 1.233813350154378e-06\n",
      "Epoch 2914, Loss: 8.235361929109786e-05, Final Batch Loss: 2.035247780440841e-05\n",
      "Epoch 2915, Loss: 0.005634663886667113, Final Batch Loss: 0.005607832223176956\n",
      "Epoch 2916, Loss: 0.002753472783297184, Final Batch Loss: 0.0027348711155354977\n",
      "Epoch 2917, Loss: 0.0007051439170027152, Final Batch Loss: 0.0005350994761101902\n",
      "Epoch 2918, Loss: 1.212158804264618e-05, Final Batch Loss: 2.186387973779347e-06\n",
      "Epoch 2919, Loss: 4.059773459630378e-05, Final Batch Loss: 3.7998157495167106e-05\n",
      "Epoch 2920, Loss: 7.445013034157455e-05, Final Batch Loss: 2.8891641704831272e-05\n",
      "Epoch 2921, Loss: 0.00019237500964663923, Final Batch Loss: 0.0001062842711689882\n",
      "Epoch 2922, Loss: 1.7077143297683506e-05, Final Batch Loss: 3.689380037030787e-07\n",
      "Epoch 2923, Loss: 4.398429427965311e-05, Final Batch Loss: 1.467276979383314e-05\n",
      "Epoch 2924, Loss: 0.000319375547405798, Final Batch Loss: 7.922207441879436e-05\n",
      "Epoch 2925, Loss: 0.0035773873823927715, Final Batch Loss: 0.0001787910732673481\n",
      "Epoch 2926, Loss: 7.70311921769462e-05, Final Batch Loss: 7.456171715602977e-06\n",
      "Epoch 2927, Loss: 0.0027006857399101136, Final Batch Loss: 5.308056643116288e-06\n",
      "Epoch 2928, Loss: 0.0024013899819692597, Final Batch Loss: 0.0022453514393419027\n",
      "Epoch 2929, Loss: 6.294749204016625e-05, Final Batch Loss: 7.308876206479908e-07\n",
      "Epoch 2930, Loss: 6.479120384028647e-05, Final Batch Loss: 2.432798282825388e-06\n",
      "Epoch 2931, Loss: 0.00024303933741975925, Final Batch Loss: 4.196206191409146e-06\n",
      "Epoch 2932, Loss: 0.0009027114429045469, Final Batch Loss: 2.9128656024113297e-05\n",
      "Epoch 2933, Loss: 0.0002735983252932783, Final Batch Loss: 2.1139883756404743e-05\n",
      "Epoch 2934, Loss: 0.00028389327417244203, Final Batch Loss: 0.00027228822000324726\n",
      "Epoch 2935, Loss: 0.001942980776220793, Final Batch Loss: 9.553950803820044e-07\n",
      "Epoch 2936, Loss: 0.00022976283071329817, Final Batch Loss: 0.00010119660146301612\n",
      "Epoch 2937, Loss: 0.001832508365623653, Final Batch Loss: 0.0006637509213760495\n",
      "Epoch 2938, Loss: 0.000162195104849161, Final Batch Loss: 3.2469504276377847e-06\n",
      "Epoch 2939, Loss: 0.0027507045306265354, Final Batch Loss: 0.0020798398181796074\n",
      "Epoch 2940, Loss: 0.0008310277626151219, Final Batch Loss: 2.946962194982916e-05\n",
      "Epoch 2941, Loss: 0.00013594856955023715, Final Batch Loss: 1.5348277884186246e-06\n",
      "Epoch 2942, Loss: 5.011918437958229e-05, Final Batch Loss: 2.578069870651234e-05\n",
      "Epoch 2943, Loss: 0.0003351589894009521, Final Batch Loss: 0.00031302310526371\n",
      "Epoch 2944, Loss: 9.020116976898862e-05, Final Batch Loss: 8.05493546067737e-05\n",
      "Epoch 2945, Loss: 5.752653942181496e-05, Final Batch Loss: 8.341437023773324e-06\n",
      "Epoch 2946, Loss: 0.0013356959825614467, Final Batch Loss: 0.00010817231668625027\n",
      "Epoch 2947, Loss: 0.0008994283343781717, Final Batch Loss: 3.3034659281838685e-05\n",
      "Epoch 2948, Loss: 4.380010432214476e-05, Final Batch Loss: 2.4796714569674805e-05\n",
      "Epoch 2949, Loss: 0.0002176878185764508, Final Batch Loss: 3.284279728177353e-06\n",
      "Epoch 2950, Loss: 1.975030704670644e-05, Final Batch Loss: 2.6694126518123085e-06\n",
      "Epoch 2951, Loss: 5.496302492247196e-05, Final Batch Loss: 7.771720447635744e-06\n",
      "Epoch 2952, Loss: 5.583732036029687e-05, Final Batch Loss: 1.0938055311271455e-05\n",
      "Epoch 2953, Loss: 0.00012712963416561252, Final Batch Loss: 0.00011535159137565643\n",
      "Epoch 2954, Loss: 0.0005532582581508905, Final Batch Loss: 0.00014002545503899455\n",
      "Epoch 2955, Loss: 4.8965865971695166e-05, Final Batch Loss: 1.0736296644608956e-05\n",
      "Epoch 2956, Loss: 0.002554123642767081, Final Batch Loss: 5.9180314565310255e-05\n",
      "Epoch 2957, Loss: 0.00011383607125026174, Final Batch Loss: 4.65320517832879e-05\n",
      "Epoch 2958, Loss: 0.00010714606182204989, Final Batch Loss: 0.00010668305912986398\n",
      "Epoch 2959, Loss: 0.0057142136502079666, Final Batch Loss: 0.005659713409841061\n",
      "Epoch 2960, Loss: 4.709401196123508e-06, Final Batch Loss: 3.7038003029010724e-06\n",
      "Epoch 2961, Loss: 0.0005178407227504067, Final Batch Loss: 0.0005017875228077173\n",
      "Epoch 2962, Loss: 1.4890096053932211e-05, Final Batch Loss: 2.138609261237434e-06\n",
      "Epoch 2963, Loss: 2.1828342667618017e-05, Final Batch Loss: 1.2355901901628386e-07\n",
      "Epoch 2964, Loss: 3.656359183423774e-06, Final Batch Loss: 5.325093184183061e-07\n",
      "Epoch 2965, Loss: 0.002328754777636277, Final Batch Loss: 2.844866912710131e-06\n",
      "Epoch 2966, Loss: 0.0001303954759350745, Final Batch Loss: 1.9236844309489243e-05\n",
      "Epoch 2967, Loss: 6.052339209361435e-06, Final Batch Loss: 8.701393738874685e-08\n",
      "Epoch 2968, Loss: 0.00016235198881986435, Final Batch Loss: 2.6867305678024422e-06\n",
      "Epoch 2969, Loss: 0.00011024926061509177, Final Batch Loss: 7.051276043057442e-06\n",
      "Epoch 2970, Loss: 2.8866932098026155e-05, Final Batch Loss: 7.458971140295034e-06\n",
      "Epoch 2971, Loss: 0.0002585708280093968, Final Batch Loss: 4.3106250814162195e-05\n",
      "Epoch 2972, Loss: 1.9448766579444055e-06, Final Batch Loss: 2.688703943931614e-07\n",
      "Epoch 2973, Loss: 0.0008027813280477858, Final Batch Loss: 0.0008000797242857516\n",
      "Epoch 2974, Loss: 0.0008358814357620759, Final Batch Loss: 7.674516950828547e-07\n",
      "Epoch 2975, Loss: 0.00013771864541922696, Final Batch Loss: 4.373119372758083e-05\n",
      "Epoch 2976, Loss: 0.00016673945356160402, Final Batch Loss: 5.6975324696395546e-05\n",
      "Epoch 2977, Loss: 0.0013032290430601279, Final Batch Loss: 3.9069259401003364e-06\n",
      "Epoch 2978, Loss: 0.0006645123510224948, Final Batch Loss: 0.0006634619203396142\n",
      "Epoch 2979, Loss: 0.00021812338127347175, Final Batch Loss: 2.5367606212967075e-05\n",
      "Epoch 2980, Loss: 0.004891634191153571, Final Batch Loss: 0.004824494011700153\n",
      "Epoch 2981, Loss: 8.953513406595448e-05, Final Batch Loss: 8.261408220278099e-05\n",
      "Epoch 2982, Loss: 6.065221100470808e-05, Final Batch Loss: 1.0284813924954506e-06\n",
      "Epoch 2983, Loss: 0.0008445724233752117, Final Batch Loss: 0.0008436058997176588\n",
      "Epoch 2984, Loss: 3.112980220976169e-05, Final Batch Loss: 2.4524568289052695e-05\n",
      "Epoch 2985, Loss: 0.0002919873149949126, Final Batch Loss: 0.00011948965402552858\n",
      "Epoch 2986, Loss: 0.004255826679582242, Final Batch Loss: 0.0042109498754143715\n",
      "Epoch 2987, Loss: 0.000145714416703413, Final Batch Loss: 6.773443146812497e-06\n",
      "Epoch 2988, Loss: 0.0005877605285604659, Final Batch Loss: 0.0005854252958670259\n",
      "Epoch 2989, Loss: 3.1497763046672844e-06, Final Batch Loss: 1.5836501177091122e-07\n",
      "Epoch 2990, Loss: 9.9391966159601e-06, Final Batch Loss: 3.156208776999847e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2991, Loss: 0.0003558846947271377, Final Batch Loss: 0.00013798878353554755\n",
      "Epoch 2992, Loss: 0.004000251858087722, Final Batch Loss: 0.003938538953661919\n",
      "Epoch 2993, Loss: 2.7986045097350143e-05, Final Batch Loss: 5.516631063073874e-07\n",
      "Epoch 2994, Loss: 2.161924112442648e-05, Final Batch Loss: 7.747766176180448e-06\n",
      "Epoch 2995, Loss: 0.00038056565972510725, Final Batch Loss: 0.00015604935470037162\n",
      "Epoch 2996, Loss: 5.082397240130376e-05, Final Batch Loss: 5.034475543652661e-05\n",
      "Epoch 2997, Loss: 6.273675376178289e-05, Final Batch Loss: 6.072908945498057e-05\n",
      "Epoch 2998, Loss: 0.0009705402626423165, Final Batch Loss: 1.6778227291069925e-05\n",
      "Epoch 2999, Loss: 0.0002893183191190474, Final Batch Loss: 0.0002787047124002129\n",
      "Epoch 3000, Loss: 2.7277976187178865e-05, Final Batch Loss: 5.156161932973191e-06\n",
      "Epoch 3001, Loss: 1.768552863268269e-05, Final Batch Loss: 6.847734539405792e-07\n",
      "Epoch 3002, Loss: 2.1788869617012097e-05, Final Batch Loss: 1.6484544175909832e-05\n",
      "Epoch 3003, Loss: 4.494260120679883e-05, Final Batch Loss: 1.6358590926301986e-07\n",
      "Epoch 3004, Loss: 0.0014528619722113945, Final Batch Loss: 3.170493437210098e-05\n",
      "Epoch 3005, Loss: 4.7241552238119766e-05, Final Batch Loss: 2.8998703783145174e-05\n",
      "Epoch 3006, Loss: 0.0005478089296957478, Final Batch Loss: 0.00037003520992584527\n",
      "Epoch 3007, Loss: 0.0005099924883325002, Final Batch Loss: 1.4123695109446999e-05\n",
      "Epoch 3008, Loss: 0.00020132069766987115, Final Batch Loss: 3.759087121579796e-05\n",
      "Epoch 3009, Loss: 0.015635292039405613, Final Batch Loss: 0.015620635822415352\n",
      "Epoch 3010, Loss: 0.0013193809793961009, Final Batch Loss: 8.353165981134225e-07\n",
      "Epoch 3011, Loss: 0.0001856304515968077, Final Batch Loss: 0.00013488219701685011\n",
      "Epoch 3012, Loss: 1.3243298326415243e-05, Final Batch Loss: 3.172884589730529e-06\n",
      "Epoch 3013, Loss: 2.8898676191602135e-05, Final Batch Loss: 2.2826545318821445e-05\n",
      "Epoch 3014, Loss: 0.00023689758018008433, Final Batch Loss: 1.627718665986322e-05\n",
      "Epoch 3015, Loss: 0.0014715471463659924, Final Batch Loss: 3.370425702087232e-06\n",
      "Epoch 3016, Loss: 2.0357148969196714e-05, Final Batch Loss: 1.2633368896786124e-05\n",
      "Epoch 3017, Loss: 0.003697824497066904, Final Batch Loss: 0.0035942629911005497\n",
      "Epoch 3018, Loss: 3.831103276752401e-05, Final Batch Loss: 7.872509740991518e-06\n",
      "Epoch 3019, Loss: 0.00020177428086753935, Final Batch Loss: 7.528565765824169e-05\n",
      "Epoch 3020, Loss: 0.00012733504263451323, Final Batch Loss: 5.206748755881563e-05\n",
      "Epoch 3021, Loss: 0.00011950932093895972, Final Batch Loss: 1.1711192200891674e-05\n",
      "Epoch 3022, Loss: 1.7930967601387238e-05, Final Batch Loss: 1.8516105910748593e-06\n",
      "Epoch 3023, Loss: 8.065968722803518e-05, Final Batch Loss: 6.188757834024727e-05\n",
      "Epoch 3024, Loss: 0.00036490970887825824, Final Batch Loss: 4.930259092361666e-05\n",
      "Epoch 3025, Loss: 3.7326739402487874e-05, Final Batch Loss: 1.8113367332261987e-05\n",
      "Epoch 3026, Loss: 0.000370729154383298, Final Batch Loss: 6.45052277832292e-05\n",
      "Epoch 3027, Loss: 0.00031231631146511063, Final Batch Loss: 9.717322973301634e-05\n",
      "Epoch 3028, Loss: 0.0001314410233135277, Final Batch Loss: 5.5813047765695956e-06\n",
      "Epoch 3029, Loss: 0.007282659411430359, Final Batch Loss: 0.004503224045038223\n",
      "Epoch 3030, Loss: 8.159913926419904e-05, Final Batch Loss: 7.805014661244059e-07\n",
      "Epoch 3031, Loss: 0.051297972226166166, Final Batch Loss: 0.051288820803165436\n",
      "Epoch 3032, Loss: 0.000122959636428277, Final Batch Loss: 0.00010549177386565134\n",
      "Epoch 3033, Loss: 0.005164775182493031, Final Batch Loss: 0.0002078452380374074\n",
      "Epoch 3034, Loss: 2.665909141796874e-05, Final Batch Loss: 4.365255335869733e-06\n",
      "Epoch 3035, Loss: 3.7326129131542984e-05, Final Batch Loss: 3.125381226709578e-06\n",
      "Epoch 3036, Loss: 1.3813175428367686e-05, Final Batch Loss: 6.2556082411902025e-06\n",
      "Epoch 3037, Loss: 0.01140851023956202, Final Batch Loss: 0.00018722712411545217\n",
      "Epoch 3038, Loss: 0.0003706595745143204, Final Batch Loss: 1.1398516335248132e-06\n",
      "Epoch 3039, Loss: 0.0002891597415555225, Final Batch Loss: 8.161606501744245e-07\n",
      "Epoch 3040, Loss: 0.001628721656743437, Final Batch Loss: 0.0007668929174542427\n",
      "Epoch 3041, Loss: 4.95614121973631e-05, Final Batch Loss: 1.4531077795254532e-05\n",
      "Epoch 3042, Loss: 0.0007380079550785013, Final Batch Loss: 2.5446359359193593e-05\n",
      "Epoch 3043, Loss: 0.0013075466267764568, Final Batch Loss: 5.1702954806387424e-05\n",
      "Epoch 3044, Loss: 0.0017859013751149178, Final Batch Loss: 0.0006734814960509539\n",
      "Epoch 3045, Loss: 0.0012273674583411776, Final Batch Loss: 0.0011933317873626947\n",
      "Epoch 3046, Loss: 0.00827403413131833, Final Batch Loss: 0.0014022989198565483\n",
      "Epoch 3047, Loss: 0.0004136438947170973, Final Batch Loss: 7.690192433074117e-06\n",
      "Epoch 3048, Loss: 0.0005346736979845446, Final Batch Loss: 0.0005079440306872129\n",
      "Epoch 3049, Loss: 3.836834457615623e-05, Final Batch Loss: 3.383410148671828e-05\n",
      "Epoch 3050, Loss: 0.0003186590062114192, Final Batch Loss: 1.4739367770744138e-06\n",
      "Epoch 3051, Loss: 7.951650002269162e-05, Final Batch Loss: 6.195299420141964e-07\n",
      "Epoch 3052, Loss: 0.00018217839874523634, Final Batch Loss: 6.438965556299081e-07\n",
      "Epoch 3053, Loss: 0.0007129616424208507, Final Batch Loss: 1.9023878849111497e-05\n",
      "Epoch 3054, Loss: 0.001155990820734587, Final Batch Loss: 0.0011432761093601584\n",
      "Epoch 3055, Loss: 0.0023595420279889368, Final Batch Loss: 0.002343442989513278\n",
      "Epoch 3056, Loss: 0.0002884245586756151, Final Batch Loss: 1.570976382936351e-05\n",
      "Epoch 3057, Loss: 0.0008377310098275359, Final Batch Loss: 3.1325047444852316e-08\n",
      "Epoch 3058, Loss: 0.04216854122933, Final Batch Loss: 0.0005351811414584517\n",
      "Epoch 3059, Loss: 1.7998490079662588e-05, Final Batch Loss: 5.525317874344182e-07\n",
      "Epoch 3060, Loss: 0.0002949398481177923, Final Batch Loss: 0.0002931723720394075\n",
      "Epoch 3061, Loss: 0.0001735337316404184, Final Batch Loss: 0.00017095731163863093\n",
      "Epoch 3062, Loss: 3.244548679504078e-05, Final Batch Loss: 2.14419615076622e-05\n",
      "Epoch 3063, Loss: 0.00012242975776644016, Final Batch Loss: 2.4536259388696635e-06\n",
      "Epoch 3064, Loss: 0.0017391790224792203, Final Batch Loss: 1.9520410205586813e-05\n",
      "Epoch 3065, Loss: 6.542745177284814e-05, Final Batch Loss: 1.9583676476031542e-05\n",
      "Epoch 3066, Loss: 3.740751753866789e-05, Final Batch Loss: 3.227066190447658e-05\n",
      "Epoch 3067, Loss: 0.00025501993150101043, Final Batch Loss: 0.00020882641547359526\n",
      "Epoch 3068, Loss: 0.0001041138602886349, Final Batch Loss: 7.485559763154015e-05\n",
      "Epoch 3069, Loss: 0.0002959395860671066, Final Batch Loss: 0.0002448335289955139\n",
      "Epoch 3070, Loss: 0.0018161984262405895, Final Batch Loss: 0.001774874865077436\n",
      "Epoch 3071, Loss: 0.004855874093550483, Final Batch Loss: 7.996394515430438e-07\n",
      "Epoch 3072, Loss: 0.00011039707260351861, Final Batch Loss: 1.1337594514770899e-05\n",
      "Epoch 3073, Loss: 0.00019530454665073194, Final Batch Loss: 0.00016019474423956126\n",
      "Epoch 3074, Loss: 7.264393161676708e-05, Final Batch Loss: 2.7573037186812144e-06\n",
      "Epoch 3075, Loss: 0.00014120112246018834, Final Batch Loss: 0.00011414480104576796\n",
      "Epoch 3076, Loss: 8.784766805547406e-06, Final Batch Loss: 9.675807177700335e-07\n",
      "Epoch 3077, Loss: 0.00013157344073988497, Final Batch Loss: 8.522931602783501e-05\n",
      "Epoch 3078, Loss: 0.000643204467905889, Final Batch Loss: 6.257184850255726e-06\n",
      "Epoch 3079, Loss: 0.00022363995776686352, Final Batch Loss: 2.428538391541224e-05\n",
      "Epoch 3080, Loss: 0.0005348870786292537, Final Batch Loss: 0.0005277548334561288\n",
      "Epoch 3081, Loss: 9.458964268560521e-05, Final Batch Loss: 4.481380892684683e-05\n",
      "Epoch 3082, Loss: 7.752282499495777e-06, Final Batch Loss: 1.0554374512139475e-06\n",
      "Epoch 3083, Loss: 0.0014185825202730484, Final Batch Loss: 5.5014163081068546e-05\n",
      "Epoch 3084, Loss: 3.564992493920727e-05, Final Batch Loss: 2.5040066248038784e-05\n",
      "Epoch 3085, Loss: 0.0013549364248319762, Final Batch Loss: 2.8100012059439905e-05\n",
      "Epoch 3086, Loss: 0.00013343006133936797, Final Batch Loss: 5.943001610830834e-07\n",
      "Epoch 3087, Loss: 0.0021548410959439934, Final Batch Loss: 0.0021452484652400017\n",
      "Epoch 3088, Loss: 0.004547775140963495, Final Batch Loss: 0.002841021167114377\n",
      "Epoch 3089, Loss: 0.0004981006459274795, Final Batch Loss: 2.7395170036470518e-05\n",
      "Epoch 3090, Loss: 0.0002071897888527019, Final Batch Loss: 2.635417149576824e-05\n",
      "Epoch 3091, Loss: 2.487171195753035e-05, Final Batch Loss: 1.786544089554809e-05\n",
      "Epoch 3092, Loss: 0.00018195540724263992, Final Batch Loss: 2.5903855203068815e-05\n",
      "Epoch 3093, Loss: 0.00019880608851963188, Final Batch Loss: 1.2422407962731086e-05\n",
      "Epoch 3094, Loss: 7.310263799809036e-05, Final Batch Loss: 7.503346296289237e-06\n",
      "Epoch 3095, Loss: 9.65097588050412e-05, Final Batch Loss: 6.713816401315853e-05\n",
      "Epoch 3096, Loss: 1.041696214088006e-05, Final Batch Loss: 5.4025113058742136e-06\n",
      "Epoch 3097, Loss: 0.00016542868252145126, Final Batch Loss: 2.2900196199771017e-05\n",
      "Epoch 3098, Loss: 0.0011295232689008117, Final Batch Loss: 0.0008324552909471095\n",
      "Epoch 3099, Loss: 0.0002359265781706199, Final Batch Loss: 5.584151949733496e-05\n",
      "Epoch 3100, Loss: 0.016568301078223158, Final Batch Loss: 0.00010653940989868715\n",
      "Epoch 3101, Loss: 0.0017430895240977407, Final Batch Loss: 5.848892033100128e-05\n",
      "Epoch 3102, Loss: 0.00021358295271056704, Final Batch Loss: 3.52565803041216e-05\n",
      "Epoch 3103, Loss: 0.0003818476398009807, Final Batch Loss: 0.00011978199472650886\n",
      "Epoch 3104, Loss: 2.5120878490270115e-05, Final Batch Loss: 1.0289274541719351e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3105, Loss: 0.001978740685444791, Final Batch Loss: 6.452285015257075e-05\n",
      "Epoch 3106, Loss: 5.553520895773545e-05, Final Batch Loss: 1.4641038433182985e-05\n",
      "Epoch 3107, Loss: 0.0019286258830106817, Final Batch Loss: 8.205908670788631e-05\n",
      "Epoch 3108, Loss: 0.0005008180050936062, Final Batch Loss: 0.00044543645344674587\n",
      "Epoch 3109, Loss: 0.00019263991316620377, Final Batch Loss: 5.441194389277371e-06\n",
      "Epoch 3110, Loss: 0.0005781471973023145, Final Batch Loss: 0.0005535371601581573\n",
      "Epoch 3111, Loss: 0.00010284215375122585, Final Batch Loss: 1.580126877342991e-06\n",
      "Epoch 3112, Loss: 0.00012310333295317832, Final Batch Loss: 9.320962999481708e-05\n",
      "Epoch 3113, Loss: 0.0008245941439781745, Final Batch Loss: 0.000817102671135217\n",
      "Epoch 3114, Loss: 0.00018743071996141225, Final Batch Loss: 0.00015677596093155444\n",
      "Epoch 3115, Loss: 0.002478160531609319, Final Batch Loss: 0.00010829638631548733\n",
      "Epoch 3116, Loss: 0.00047103854012675583, Final Batch Loss: 5.413789767771959e-05\n",
      "Epoch 3117, Loss: 0.0035978133673779666, Final Batch Loss: 0.0007182557019405067\n",
      "Epoch 3118, Loss: 4.110817326363758e-05, Final Batch Loss: 4.780604740517447e-06\n",
      "Epoch 3119, Loss: 0.00014014405496709514, Final Batch Loss: 2.7039111955673434e-05\n",
      "Epoch 3120, Loss: 0.0005543729036503464, Final Batch Loss: 9.501797535449441e-07\n",
      "Epoch 3121, Loss: 9.153780047199689e-05, Final Batch Loss: 2.91085998469498e-05\n",
      "Epoch 3122, Loss: 0.004093270981684327, Final Batch Loss: 0.0004064671229571104\n",
      "Epoch 3123, Loss: 0.00042032189230667427, Final Batch Loss: 0.00038655364187434316\n",
      "Epoch 3124, Loss: 3.5538749216357246e-05, Final Batch Loss: 2.6540716135059483e-05\n",
      "Epoch 3125, Loss: 0.00010021263915405143, Final Batch Loss: 2.623742511786986e-05\n",
      "Epoch 3126, Loss: 0.006863263042760082, Final Batch Loss: 0.00023691922251600772\n",
      "Epoch 3127, Loss: 0.0002564565911598038, Final Batch Loss: 4.5529344788519666e-05\n",
      "Epoch 3128, Loss: 0.0026232760574202985, Final Batch Loss: 0.0023365593515336514\n",
      "Epoch 3129, Loss: 0.004192202721242211, Final Batch Loss: 0.004164905287325382\n",
      "Epoch 3130, Loss: 0.00026198911200481234, Final Batch Loss: 8.034762686293107e-06\n",
      "Epoch 3131, Loss: 0.011095594061771408, Final Batch Loss: 0.00014340635971166193\n",
      "Epoch 3132, Loss: 0.00024277884949697182, Final Batch Loss: 0.0001185080545837991\n",
      "Epoch 3133, Loss: 0.00015069016080815345, Final Batch Loss: 0.00013409127132035792\n",
      "Epoch 3134, Loss: 0.00023366327513940632, Final Batch Loss: 0.0001707329647615552\n",
      "Epoch 3135, Loss: 0.0001037397378240712, Final Batch Loss: 3.3131014788523316e-05\n",
      "Epoch 3136, Loss: 0.00014856918551231502, Final Batch Loss: 5.843360668222886e-06\n",
      "Epoch 3137, Loss: 0.0010230033229845503, Final Batch Loss: 1.773311737451877e-06\n",
      "Epoch 3138, Loss: 0.0040985679006553255, Final Batch Loss: 8.122974395519122e-05\n",
      "Epoch 3139, Loss: 0.0009326893923571333, Final Batch Loss: 0.0008435452473349869\n",
      "Epoch 3140, Loss: 0.00012102672644687118, Final Batch Loss: 1.0793734873004723e-05\n",
      "Epoch 3141, Loss: 0.040058421102003194, Final Batch Loss: 0.03997454419732094\n",
      "Epoch 3142, Loss: 0.009591573209036142, Final Batch Loss: 5.101255374029279e-05\n",
      "Epoch 3143, Loss: 0.00025298002583440393, Final Batch Loss: 0.0001849064719863236\n",
      "Epoch 3144, Loss: 0.0011630750523181632, Final Batch Loss: 0.0010281263384968042\n",
      "Epoch 3145, Loss: 8.49467542138882e-05, Final Batch Loss: 4.8146866902243346e-05\n",
      "Epoch 3146, Loss: 3.460347943473607e-05, Final Batch Loss: 1.4236706192605197e-05\n",
      "Epoch 3147, Loss: 4.405289109854493e-05, Final Batch Loss: 2.6870415240409784e-05\n",
      "Epoch 3148, Loss: 0.0001320609565027553, Final Batch Loss: 2.7103353659185814e-06\n",
      "Epoch 3149, Loss: 1.713149549686932e-05, Final Batch Loss: 4.266624728188617e-06\n",
      "Epoch 3150, Loss: 0.0001120984506997047, Final Batch Loss: 9.057508577825502e-05\n",
      "Epoch 3151, Loss: 0.00025459641619818285, Final Batch Loss: 0.00021667638793587685\n",
      "Epoch 3152, Loss: 9.714048519526841e-05, Final Batch Loss: 8.910518954508007e-05\n",
      "Epoch 3153, Loss: 0.00022331316131385393, Final Batch Loss: 4.367838755570119e-06\n",
      "Epoch 3154, Loss: 3.7326477468013763e-05, Final Batch Loss: 7.2941074904520065e-06\n",
      "Epoch 3155, Loss: 4.341263593232725e-05, Final Batch Loss: 1.9733515728148632e-05\n",
      "Epoch 3156, Loss: 3.522246151987929e-05, Final Batch Loss: 1.7248981748707592e-05\n",
      "Epoch 3157, Loss: 7.163503687479533e-05, Final Batch Loss: 5.3822845075046644e-05\n",
      "Epoch 3158, Loss: 0.00015340610343628214, Final Batch Loss: 6.029209998814622e-06\n",
      "Epoch 3159, Loss: 8.639786665298743e-05, Final Batch Loss: 1.626215635042172e-06\n",
      "Epoch 3160, Loss: 1.4880435628583655e-05, Final Batch Loss: 1.0405698958493304e-05\n",
      "Epoch 3161, Loss: 0.00010254356311634183, Final Batch Loss: 3.494112752377987e-05\n",
      "Epoch 3162, Loss: 0.00015809215483386652, Final Batch Loss: 2.977396889036754e-06\n",
      "Epoch 3163, Loss: 0.00013766789197688922, Final Batch Loss: 7.57581292418763e-05\n",
      "Epoch 3164, Loss: 0.007176025421358645, Final Batch Loss: 0.006452293135225773\n",
      "Epoch 3165, Loss: 0.00010854869651666377, Final Batch Loss: 5.760355634265579e-06\n",
      "Epoch 3166, Loss: 4.728488602268044e-05, Final Batch Loss: 2.6509063900448382e-05\n",
      "Epoch 3167, Loss: 0.04428632798953913, Final Batch Loss: 0.00013902279897592962\n",
      "Epoch 3168, Loss: 0.0007698239205637947, Final Batch Loss: 2.8970491257496178e-05\n",
      "Epoch 3169, Loss: 0.000228729062655475, Final Batch Loss: 1.8271894077770412e-06\n",
      "Epoch 3170, Loss: 7.852304247535358e-05, Final Batch Loss: 7.759515574434772e-05\n",
      "Epoch 3171, Loss: 0.0015678869185649091, Final Batch Loss: 6.18038211541716e-06\n",
      "Epoch 3172, Loss: 0.00014008894504513592, Final Batch Loss: 2.340844366699457e-05\n",
      "Epoch 3173, Loss: 0.00015970744061633013, Final Batch Loss: 0.0001359833695460111\n",
      "Epoch 3174, Loss: 0.0002947814828075934, Final Batch Loss: 3.0347862775670364e-05\n",
      "Epoch 3175, Loss: 0.0015980385251168627, Final Batch Loss: 3.806646054727025e-05\n",
      "Epoch 3176, Loss: 0.0001357274886686355, Final Batch Loss: 8.807780250208452e-05\n",
      "Epoch 3177, Loss: 0.00024366553043364547, Final Batch Loss: 0.00020115546067245305\n",
      "Epoch 3178, Loss: 2.6038467694888823e-05, Final Batch Loss: 1.269726999453269e-05\n",
      "Epoch 3179, Loss: 4.237932557771273e-06, Final Batch Loss: 1.8715917349254596e-06\n",
      "Epoch 3180, Loss: 7.029443668216118e-05, Final Batch Loss: 6.815067172283307e-05\n",
      "Epoch 3181, Loss: 0.00838518317323178, Final Batch Loss: 0.008179745636880398\n",
      "Epoch 3182, Loss: 4.5413660700432956e-05, Final Batch Loss: 2.5845230993581936e-05\n",
      "Epoch 3183, Loss: 0.015652676112949848, Final Batch Loss: 0.007353213615715504\n",
      "Epoch 3184, Loss: 0.005020504235289991, Final Batch Loss: 0.004570603836327791\n",
      "Epoch 3185, Loss: 0.00032718759030103683, Final Batch Loss: 0.0002139489952242002\n",
      "Epoch 3186, Loss: 5.555538609769428e-05, Final Batch Loss: 6.277206011873204e-06\n",
      "Epoch 3187, Loss: 0.0002402139361947775, Final Batch Loss: 9.10865783225745e-05\n",
      "Epoch 3188, Loss: 8.401888817388681e-05, Final Batch Loss: 1.5818154679436702e-06\n",
      "Epoch 3189, Loss: 0.000174167421164384, Final Batch Loss: 3.072273784709978e-06\n",
      "Epoch 3190, Loss: 0.0012263547851034673, Final Batch Loss: 1.1878715667990036e-05\n",
      "Epoch 3191, Loss: 4.4562776281509286e-05, Final Batch Loss: 5.542630674426618e-07\n",
      "Epoch 3192, Loss: 0.0057843766061296265, Final Batch Loss: 5.882119467059965e-07\n",
      "Epoch 3193, Loss: 0.00012314200876062387, Final Batch Loss: 6.508633759949589e-06\n",
      "Epoch 3194, Loss: 0.0043360940355228195, Final Batch Loss: 0.004335237666964531\n",
      "Epoch 3195, Loss: 0.00016336715998477302, Final Batch Loss: 0.00014346257376018912\n",
      "Epoch 3196, Loss: 9.522496839053929e-05, Final Batch Loss: 4.593266567098908e-05\n",
      "Epoch 3197, Loss: 0.00055993856585701, Final Batch Loss: 1.5608518879162148e-05\n",
      "Epoch 3198, Loss: 0.00039275271410588175, Final Batch Loss: 4.538991197478026e-05\n",
      "Epoch 3199, Loss: 0.00010863671923289075, Final Batch Loss: 3.83817678084597e-05\n",
      "Epoch 3200, Loss: 0.00014006009587319568, Final Batch Loss: 7.477599137928337e-05\n",
      "Epoch 3201, Loss: 0.00044607674499275163, Final Batch Loss: 0.00032669701613485813\n",
      "Epoch 3202, Loss: 0.00012286393939575646, Final Batch Loss: 1.7989930711337365e-05\n",
      "Epoch 3203, Loss: 0.00023338658502325416, Final Batch Loss: 0.00015695983893238008\n",
      "Epoch 3204, Loss: 0.00016418072846136056, Final Batch Loss: 0.0001383209746563807\n",
      "Epoch 3205, Loss: 4.9287926231045276e-05, Final Batch Loss: 3.816905518760905e-06\n",
      "Epoch 3206, Loss: 1.1148680187034188e-05, Final Batch Loss: 5.2404243433556985e-06\n",
      "Epoch 3207, Loss: 0.0013689037141375593, Final Batch Loss: 1.3581636267190333e-05\n",
      "Epoch 3208, Loss: 0.0065194143517146586, Final Batch Loss: 0.00650129234418273\n",
      "Epoch 3209, Loss: 6.321511500573251e-05, Final Batch Loss: 2.7806339858216234e-05\n",
      "Epoch 3210, Loss: 0.010055843857116997, Final Batch Loss: 0.00998105201870203\n",
      "Epoch 3211, Loss: 0.004223699361318722, Final Batch Loss: 4.0460057789459825e-05\n",
      "Epoch 3212, Loss: 9.064657933777198e-05, Final Batch Loss: 8.10980491223745e-05\n",
      "Epoch 3213, Loss: 2.8330908207863104e-05, Final Batch Loss: 2.7946016416535713e-06\n",
      "Epoch 3214, Loss: 1.1843410447909264e-05, Final Batch Loss: 4.800482201972045e-06\n",
      "Epoch 3215, Loss: 0.004627879927284084, Final Batch Loss: 0.00010277585533913225\n",
      "Epoch 3216, Loss: 4.357030695700814e-05, Final Batch Loss: 5.429566272141528e-07\n",
      "Epoch 3217, Loss: 0.00021241078502498567, Final Batch Loss: 0.0001830238470574841\n",
      "Epoch 3218, Loss: 0.0002253544662380591, Final Batch Loss: 4.012147837784141e-05\n",
      "Epoch 3219, Loss: 0.00025972207004087977, Final Batch Loss: 0.0002445413847453892\n",
      "Epoch 3220, Loss: 1.3973216027807212e-05, Final Batch Loss: 1.0979274520650506e-05\n",
      "Epoch 3221, Loss: 3.087575441895751e-05, Final Batch Loss: 8.342102773895022e-06\n",
      "Epoch 3222, Loss: 0.00019420435273787007, Final Batch Loss: 0.00016065931413322687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3223, Loss: 0.00010895393188548042, Final Batch Loss: 1.4075873878027778e-05\n",
      "Epoch 3224, Loss: 6.072475571272662e-06, Final Batch Loss: 2.8912957077409374e-06\n",
      "Epoch 3225, Loss: 0.0003498497462715022, Final Batch Loss: 1.7020814993884414e-05\n",
      "Epoch 3226, Loss: 0.00010518450289964676, Final Batch Loss: 6.63675891701132e-05\n",
      "Epoch 3227, Loss: 7.384842774627032e-05, Final Batch Loss: 1.4879963600833435e-05\n",
      "Epoch 3228, Loss: 4.173658453510143e-05, Final Batch Loss: 3.068653677473776e-05\n",
      "Epoch 3229, Loss: 0.000102948915809975, Final Batch Loss: 2.9896002160967328e-05\n",
      "Epoch 3230, Loss: 6.752105764462613e-05, Final Batch Loss: 2.4051878426689655e-05\n",
      "Epoch 3231, Loss: 0.0011600381203606958, Final Batch Loss: 0.001131818164139986\n",
      "Epoch 3232, Loss: 0.00019629304370027967, Final Batch Loss: 0.00015921339218039066\n",
      "Epoch 3233, Loss: 5.4990528951748274e-05, Final Batch Loss: 4.707726839114912e-05\n",
      "Epoch 3234, Loss: 2.5146213829430053e-05, Final Batch Loss: 1.9424553101998754e-05\n",
      "Epoch 3235, Loss: 0.00022714928854838945, Final Batch Loss: 0.00018314499175176024\n",
      "Epoch 3236, Loss: 0.00022523275401908904, Final Batch Loss: 0.0001441416097804904\n",
      "Epoch 3237, Loss: 3.096165801252937e-05, Final Batch Loss: 1.4955806364014279e-05\n",
      "Epoch 3238, Loss: 6.118932651588693e-05, Final Batch Loss: 3.084147465415299e-06\n",
      "Epoch 3239, Loss: 0.0009595665687811561, Final Batch Loss: 0.0009112448315136135\n",
      "Epoch 3240, Loss: 0.00011700101094902493, Final Batch Loss: 0.00010249528713757172\n",
      "Epoch 3241, Loss: 1.9946547581639607e-05, Final Batch Loss: 1.1529913535923697e-05\n",
      "Epoch 3242, Loss: 0.0001006783641059883, Final Batch Loss: 2.760862116701901e-05\n",
      "Epoch 3243, Loss: 0.002258767917737714, Final Batch Loss: 2.547361327742692e-05\n",
      "Epoch 3244, Loss: 0.0005233796709944727, Final Batch Loss: 0.0005129928467795253\n",
      "Epoch 3245, Loss: 0.0001380657085974235, Final Batch Loss: 7.974771870067343e-05\n",
      "Epoch 3246, Loss: 0.007675778018892743, Final Batch Loss: 0.00011195278784725815\n",
      "Epoch 3247, Loss: 0.00011333143788760935, Final Batch Loss: 2.560542043283931e-06\n",
      "Epoch 3248, Loss: 0.0001390914544572297, Final Batch Loss: 4.1049929677683394e-06\n",
      "Epoch 3249, Loss: 5.777081219093816e-05, Final Batch Loss: 1.9646975033538183e-06\n",
      "Epoch 3250, Loss: 5.696146445188788e-05, Final Batch Loss: 3.878475126839476e-06\n",
      "Epoch 3251, Loss: 0.0011775664606830105, Final Batch Loss: 0.00011689179518725723\n",
      "Epoch 3252, Loss: 1.752123534970451e-05, Final Batch Loss: 5.635191882902291e-06\n",
      "Epoch 3253, Loss: 7.564550196548225e-05, Final Batch Loss: 1.7715619833325036e-06\n",
      "Epoch 3254, Loss: 0.0003522409342622268, Final Batch Loss: 1.1617909876804333e-05\n",
      "Epoch 3255, Loss: 0.00015090217857505195, Final Batch Loss: 9.572943235980347e-05\n",
      "Epoch 3256, Loss: 0.0004944226675434038, Final Batch Loss: 0.00035042318631894886\n",
      "Epoch 3257, Loss: 6.479295552708209e-05, Final Batch Loss: 2.52203899435699e-05\n",
      "Epoch 3258, Loss: 0.000270925673248712, Final Batch Loss: 6.946218491066247e-06\n",
      "Epoch 3259, Loss: 0.00011535737121448619, Final Batch Loss: 1.1804443602159154e-05\n",
      "Epoch 3260, Loss: 2.611313414035976e-05, Final Batch Loss: 2.4997360014822334e-05\n",
      "Epoch 3261, Loss: 5.788461203337647e-05, Final Batch Loss: 1.3385157217271626e-05\n",
      "Epoch 3262, Loss: 0.001123171765357256, Final Batch Loss: 0.00022949225967749953\n",
      "Epoch 3263, Loss: 0.0004435712990016327, Final Batch Loss: 0.00043540768092498183\n",
      "Epoch 3264, Loss: 0.00012528796287369914, Final Batch Loss: 0.00010633711644914001\n",
      "Epoch 3265, Loss: 1.4865190905766212e-05, Final Batch Loss: 2.1482921965798596e-06\n",
      "Epoch 3266, Loss: 1.2864372763488063e-05, Final Batch Loss: 7.970351703079359e-07\n",
      "Epoch 3267, Loss: 2.3289353521249723e-05, Final Batch Loss: 1.4780302080907859e-05\n",
      "Epoch 3268, Loss: 0.001943974661116954, Final Batch Loss: 5.541848804568872e-05\n",
      "Epoch 3269, Loss: 9.604481601854786e-05, Final Batch Loss: 6.0711565311066806e-05\n",
      "Epoch 3270, Loss: 1.7712693988869432e-05, Final Batch Loss: 8.165269719029311e-06\n",
      "Epoch 3271, Loss: 6.118948522271239e-05, Final Batch Loss: 2.028240942308912e-06\n",
      "Epoch 3272, Loss: 0.004628671136742923, Final Batch Loss: 8.6647727584932e-05\n",
      "Epoch 3273, Loss: 2.8932957775396062e-05, Final Batch Loss: 2.5350778741994873e-05\n",
      "Epoch 3274, Loss: 3.061174311369541e-05, Final Batch Loss: 2.304517329321243e-05\n",
      "Epoch 3275, Loss: 0.001302542892517522, Final Batch Loss: 0.0010990685550495982\n",
      "Epoch 3276, Loss: 4.649088532460155e-05, Final Batch Loss: 4.2044637666549534e-05\n",
      "Epoch 3277, Loss: 0.002037494954038266, Final Batch Loss: 3.989132437709486e-06\n",
      "Epoch 3278, Loss: 0.00018169185204897076, Final Batch Loss: 1.75390305230394e-05\n",
      "Epoch 3279, Loss: 6.393118428604794e-05, Final Batch Loss: 5.9941823565168306e-05\n",
      "Epoch 3280, Loss: 0.00011583796367631294, Final Batch Loss: 6.700953235849738e-05\n",
      "Epoch 3281, Loss: 0.002282005632878281, Final Batch Loss: 6.924512854311615e-05\n",
      "Epoch 3282, Loss: 6.625537480431376e-05, Final Batch Loss: 5.739974221796729e-05\n",
      "Epoch 3283, Loss: 5.912176311539952e-05, Final Batch Loss: 4.351977986516431e-05\n",
      "Epoch 3284, Loss: 0.004277613013982773, Final Batch Loss: 0.0006178636103868484\n",
      "Epoch 3285, Loss: 0.0002339984057471156, Final Batch Loss: 0.00011384711251594126\n",
      "Epoch 3286, Loss: 2.6712659746408463e-05, Final Batch Loss: 1.7376078176312149e-06\n",
      "Epoch 3287, Loss: 0.0026547582248213075, Final Batch Loss: 1.1494277032397804e-06\n",
      "Epoch 3288, Loss: 0.006149267079308629, Final Batch Loss: 0.0019559802021831274\n",
      "Epoch 3289, Loss: 9.869958375929855e-06, Final Batch Loss: 4.5772599150950555e-06\n",
      "Epoch 3290, Loss: 0.0006807454337831587, Final Batch Loss: 0.00039663835195824504\n",
      "Epoch 3291, Loss: 0.00011903652284672717, Final Batch Loss: 0.00011127495235996321\n",
      "Epoch 3292, Loss: 0.0011064908994740108, Final Batch Loss: 1.305230580328498e-05\n",
      "Epoch 3293, Loss: 8.878802043454925e-05, Final Batch Loss: 1.1502969528009999e-06\n",
      "Epoch 3294, Loss: 0.0010467815718584461, Final Batch Loss: 8.02569957158994e-06\n",
      "Epoch 3295, Loss: 0.00017658314027357846, Final Batch Loss: 9.587045497028157e-05\n",
      "Epoch 3296, Loss: 0.004214559216052294, Final Batch Loss: 0.0009703848045319319\n",
      "Epoch 3297, Loss: 3.227477031941817e-05, Final Batch Loss: 3.1108935218071565e-05\n",
      "Epoch 3298, Loss: 0.001255806226254208, Final Batch Loss: 3.310285319457762e-05\n",
      "Epoch 3299, Loss: 1.5118584997253492e-05, Final Batch Loss: 7.737221494608093e-06\n",
      "Epoch 3300, Loss: 0.00037484853783098515, Final Batch Loss: 1.3455535736284219e-05\n",
      "Epoch 3301, Loss: 0.0022434230420458334, Final Batch Loss: 1.9743099528568564e-06\n",
      "Epoch 3302, Loss: 0.008300717749307296, Final Batch Loss: 1.589596877238364e-06\n",
      "Epoch 3303, Loss: 0.0009366017475258559, Final Batch Loss: 0.0001015547604765743\n",
      "Epoch 3304, Loss: 0.0001502327013440663, Final Batch Loss: 1.8453642042004503e-05\n",
      "Epoch 3305, Loss: 3.048595817745081e-05, Final Batch Loss: 4.931978310196428e-06\n",
      "Epoch 3306, Loss: 1.1182446996826911e-05, Final Batch Loss: 3.228798505006125e-06\n",
      "Epoch 3307, Loss: 0.0003967481170548126, Final Batch Loss: 0.0002920616534538567\n",
      "Epoch 3308, Loss: 0.0013790812663501129, Final Batch Loss: 0.001334041589871049\n",
      "Epoch 3309, Loss: 3.973462116846349e-05, Final Batch Loss: 1.775256714608986e-05\n",
      "Epoch 3310, Loss: 3.945982143704896e-05, Final Batch Loss: 3.754397766897455e-05\n",
      "Epoch 3311, Loss: 0.001042709614011983, Final Batch Loss: 1.0469158041814808e-05\n",
      "Epoch 3312, Loss: 9.120930485551071e-06, Final Batch Loss: 1.681022808952548e-06\n",
      "Epoch 3313, Loss: 0.0002528539503146021, Final Batch Loss: 7.187993560364703e-06\n",
      "Epoch 3314, Loss: 0.00017314360047748778, Final Batch Loss: 6.840718924649991e-06\n",
      "Epoch 3315, Loss: 0.00012622921531146858, Final Batch Loss: 0.00010374920384492725\n",
      "Epoch 3316, Loss: 0.00042673598591136397, Final Batch Loss: 0.0004223467840347439\n",
      "Epoch 3317, Loss: 0.0002895061334129423, Final Batch Loss: 4.8774221795611084e-05\n",
      "Epoch 3318, Loss: 0.00022529175475938246, Final Batch Loss: 0.0001180959734483622\n",
      "Epoch 3319, Loss: 0.0004133383699809201, Final Batch Loss: 0.00037054080166853964\n",
      "Epoch 3320, Loss: 0.012882189017545898, Final Batch Loss: 0.012781677767634392\n",
      "Epoch 3321, Loss: 0.00013741556904278696, Final Batch Loss: 6.703552207909524e-05\n",
      "Epoch 3322, Loss: 3.3707548936945386e-05, Final Batch Loss: 2.4103363102767617e-05\n",
      "Epoch 3323, Loss: 0.0003022202104148164, Final Batch Loss: 6.543511972267879e-06\n",
      "Epoch 3324, Loss: 0.0006505684868898243, Final Batch Loss: 6.210486753843725e-05\n",
      "Epoch 3325, Loss: 0.00517707469407469, Final Batch Loss: 0.0038105465937405825\n",
      "Epoch 3326, Loss: 2.419584188828594e-05, Final Batch Loss: 5.950454124103999e-06\n",
      "Epoch 3327, Loss: 2.1775296318082837e-05, Final Batch Loss: 3.961465608881554e-06\n",
      "Epoch 3328, Loss: 4.471071588341147e-05, Final Batch Loss: 1.2037507985951379e-05\n",
      "Epoch 3329, Loss: 0.0001384557854180457, Final Batch Loss: 0.00012464463361538947\n",
      "Epoch 3330, Loss: 0.0001267344250663882, Final Batch Loss: 2.768998638202902e-05\n",
      "Epoch 3331, Loss: 0.0003654528300103266, Final Batch Loss: 4.2048824980156496e-05\n",
      "Epoch 3332, Loss: 0.00022498902580991853, Final Batch Loss: 0.00020878943905699998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3333, Loss: 0.0011163988610860542, Final Batch Loss: 5.34814262209693e-06\n",
      "Epoch 3334, Loss: 5.490238618222065e-05, Final Batch Loss: 2.1961222955724224e-05\n",
      "Epoch 3335, Loss: 9.588933244231157e-05, Final Batch Loss: 7.380863826256245e-05\n",
      "Epoch 3336, Loss: 0.019644218429675675, Final Batch Loss: 1.5671297660446726e-05\n",
      "Epoch 3337, Loss: 0.00020251625392120332, Final Batch Loss: 0.00011018948134733364\n",
      "Epoch 3338, Loss: 0.0019210227401345037, Final Batch Loss: 0.00011514659126987681\n",
      "Epoch 3339, Loss: 0.00010772557652671821, Final Batch Loss: 5.767936454503797e-05\n",
      "Epoch 3340, Loss: 0.0011528068862389773, Final Batch Loss: 0.0007145582349039614\n",
      "Epoch 3341, Loss: 0.00012912928650621325, Final Batch Loss: 7.957473280839622e-05\n",
      "Epoch 3342, Loss: 4.174211608187761e-05, Final Batch Loss: 1.8359171008341946e-05\n",
      "Epoch 3343, Loss: 0.00011666266436805017, Final Batch Loss: 3.5949324228568e-05\n",
      "Epoch 3344, Loss: 0.00017851823940873146, Final Batch Loss: 0.00013351035886444151\n",
      "Epoch 3345, Loss: 0.0001226407111971639, Final Batch Loss: 7.772826211294159e-05\n",
      "Epoch 3346, Loss: 0.00037758722828584723, Final Batch Loss: 1.312959284405224e-05\n",
      "Epoch 3347, Loss: 0.0003672943348647095, Final Batch Loss: 0.0003462425956968218\n",
      "Epoch 3348, Loss: 3.430029028095305e-05, Final Batch Loss: 1.2600025002029724e-05\n",
      "Epoch 3349, Loss: 0.0016305601748172194, Final Batch Loss: 0.00024978877627290785\n",
      "Epoch 3350, Loss: 0.00011885259300470352, Final Batch Loss: 2.94232158921659e-05\n",
      "Epoch 3351, Loss: 0.00015690199006712646, Final Batch Loss: 0.00014939381799194962\n",
      "Epoch 3352, Loss: 1.4288124106087707e-05, Final Batch Loss: 4.3071813138340076e-07\n",
      "Epoch 3353, Loss: 1.4733095667907037e-05, Final Batch Loss: 5.9397170844022185e-06\n",
      "Epoch 3354, Loss: 5.937099012953695e-05, Final Batch Loss: 4.717080810223706e-05\n",
      "Epoch 3355, Loss: 0.00024885615857783705, Final Batch Loss: 0.00012024055467918515\n",
      "Epoch 3356, Loss: 8.980072379927151e-05, Final Batch Loss: 2.792905070236884e-05\n",
      "Epoch 3357, Loss: 0.0028282906860113144, Final Batch Loss: 0.0014858902432024479\n",
      "Epoch 3358, Loss: 0.0006374469685397344, Final Batch Loss: 0.0006178294424898922\n",
      "Epoch 3359, Loss: 7.061916039674543e-05, Final Batch Loss: 2.7573438273975626e-05\n",
      "Epoch 3360, Loss: 0.001664682786213234, Final Batch Loss: 0.00016465681255795062\n",
      "Epoch 3361, Loss: 0.0008921428052417468, Final Batch Loss: 0.0008738512988202274\n",
      "Epoch 3362, Loss: 0.00013279540553412517, Final Batch Loss: 6.645376288361149e-06\n",
      "Epoch 3363, Loss: 4.312888768254197e-05, Final Batch Loss: 7.136424301279476e-06\n",
      "Epoch 3364, Loss: 0.00039112206650315784, Final Batch Loss: 0.00035078590735793114\n",
      "Epoch 3365, Loss: 0.001810313726309687, Final Batch Loss: 0.0002554385573603213\n",
      "Epoch 3366, Loss: 0.0019189163576811552, Final Batch Loss: 0.0005163674941286445\n",
      "Epoch 3367, Loss: 0.0004649481434171321, Final Batch Loss: 0.0004511227598413825\n",
      "Epoch 3368, Loss: 0.0007919209019746631, Final Batch Loss: 0.0006375529919750988\n",
      "Epoch 3369, Loss: 0.0023441166849806905, Final Batch Loss: 0.0023081686813384295\n",
      "Epoch 3370, Loss: 0.0002810903170029633, Final Batch Loss: 0.00024393582134507596\n",
      "Epoch 3371, Loss: 3.5862204640579876e-05, Final Batch Loss: 5.232500370766502e-06\n",
      "Epoch 3372, Loss: 0.0003073281368415337, Final Batch Loss: 1.8674658349482343e-05\n",
      "Epoch 3373, Loss: 0.0001363147202937398, Final Batch Loss: 8.735633309697732e-05\n",
      "Epoch 3374, Loss: 0.0029873959902033675, Final Batch Loss: 0.002967515029013157\n",
      "Epoch 3375, Loss: 0.0001971307210624218, Final Batch Loss: 0.00012311201135162264\n",
      "Epoch 3376, Loss: 9.347561217509792e-06, Final Batch Loss: 6.343273071252042e-07\n",
      "Epoch 3377, Loss: 9.620850505598355e-05, Final Batch Loss: 8.573780360165983e-05\n",
      "Epoch 3378, Loss: 7.979416113812476e-05, Final Batch Loss: 5.253590643405914e-05\n",
      "Epoch 3379, Loss: 0.0002208203441114165, Final Batch Loss: 6.205797399161384e-05\n",
      "Epoch 3380, Loss: 0.00010848668898688629, Final Batch Loss: 7.861949416110292e-05\n",
      "Epoch 3381, Loss: 9.345138550997945e-06, Final Batch Loss: 6.810930699430173e-06\n",
      "Epoch 3382, Loss: 0.00016667304589645937, Final Batch Loss: 2.2619809897150844e-05\n",
      "Epoch 3383, Loss: 0.0021562580368481576, Final Batch Loss: 0.000663171464111656\n",
      "Epoch 3384, Loss: 0.00011367804108886048, Final Batch Loss: 8.165232429746538e-05\n",
      "Epoch 3385, Loss: 0.00021192370695644058, Final Batch Loss: 5.2973005949752405e-05\n",
      "Epoch 3386, Loss: 0.00040728639578446746, Final Batch Loss: 0.00032143760472536087\n",
      "Epoch 3387, Loss: 0.00017149720770248678, Final Batch Loss: 6.430089342757128e-06\n",
      "Epoch 3388, Loss: 7.340067440964049e-05, Final Batch Loss: 6.314452912192792e-05\n",
      "Epoch 3389, Loss: 2.87401448986202e-05, Final Batch Loss: 7.347381597355707e-06\n",
      "Epoch 3390, Loss: 8.723306700630928e-05, Final Batch Loss: 8.118528057821095e-05\n",
      "Epoch 3391, Loss: 3.7599767892970704e-05, Final Batch Loss: 3.320271571283229e-05\n",
      "Epoch 3392, Loss: 4.706200888904277e-05, Final Batch Loss: 1.827209780458361e-05\n",
      "Epoch 3393, Loss: 5.527670691662934e-05, Final Batch Loss: 1.3120106814312749e-05\n",
      "Epoch 3394, Loss: 7.146097959775943e-05, Final Batch Loss: 2.7984862754237838e-05\n",
      "Epoch 3395, Loss: 7.606877079524565e-05, Final Batch Loss: 2.393645809206646e-05\n",
      "Epoch 3396, Loss: 0.00012303507355682086, Final Batch Loss: 1.6774907635408454e-05\n",
      "Epoch 3397, Loss: 5.595714537776075e-05, Final Batch Loss: 9.642328222980723e-06\n",
      "Epoch 3398, Loss: 3.043991728191031e-05, Final Batch Loss: 1.4910926438460592e-05\n",
      "Epoch 3399, Loss: 2.1897185433772393e-05, Final Batch Loss: 1.6474885342177004e-05\n",
      "Epoch 3400, Loss: 0.00038585614629482734, Final Batch Loss: 5.793851869384525e-06\n",
      "Epoch 3401, Loss: 0.00011629708330929134, Final Batch Loss: 1.356518055217748e-06\n",
      "Epoch 3402, Loss: 0.00013795292852591956, Final Batch Loss: 1.4962512977945153e-05\n",
      "Epoch 3403, Loss: 0.0015070116446622706, Final Batch Loss: 2.6451257326698396e-06\n",
      "Epoch 3404, Loss: 7.973800165927969e-06, Final Batch Loss: 2.6187922230747063e-06\n",
      "Epoch 3405, Loss: 8.457487092528027e-05, Final Batch Loss: 1.9913988580810837e-05\n",
      "Epoch 3406, Loss: 9.058152863872238e-05, Final Batch Loss: 2.5071927666431293e-05\n",
      "Epoch 3407, Loss: 0.00016051280181272887, Final Batch Loss: 0.00015217276813928038\n",
      "Epoch 3408, Loss: 1.974778660951415e-05, Final Batch Loss: 1.0400789506093133e-05\n",
      "Epoch 3409, Loss: 0.0010135416596313007, Final Batch Loss: 0.0009648803970776498\n",
      "Epoch 3410, Loss: 3.7475896533578634e-05, Final Batch Loss: 2.4090639271889813e-05\n",
      "Epoch 3411, Loss: 9.038934877025895e-05, Final Batch Loss: 3.13947384711355e-05\n",
      "Epoch 3412, Loss: 0.0006771771659259684, Final Batch Loss: 3.243640094297007e-05\n",
      "Epoch 3413, Loss: 6.155308074085042e-05, Final Batch Loss: 3.568598549463786e-05\n",
      "Epoch 3414, Loss: 0.002336475241207836, Final Batch Loss: 4.2462463056835986e-07\n",
      "Epoch 3415, Loss: 0.0077174901744001545, Final Batch Loss: 0.00761061254888773\n",
      "Epoch 3416, Loss: 2.1705780454794876e-05, Final Batch Loss: 1.3611750546260737e-05\n",
      "Epoch 3417, Loss: 0.00016495542877237312, Final Batch Loss: 0.0001529485161881894\n",
      "Epoch 3418, Loss: 1.1636049748631194e-05, Final Batch Loss: 3.442887646087911e-06\n",
      "Epoch 3419, Loss: 0.00025860323512461036, Final Batch Loss: 0.00016253252397291362\n",
      "Epoch 3420, Loss: 9.418069657840533e-05, Final Batch Loss: 8.767680265009403e-05\n",
      "Epoch 3421, Loss: 0.004452549240340886, Final Batch Loss: 0.004442177712917328\n",
      "Epoch 3422, Loss: 0.0011889025299751665, Final Batch Loss: 1.6318746929755434e-05\n",
      "Epoch 3423, Loss: 1.4717993508384097e-05, Final Batch Loss: 5.7465522331767716e-06\n",
      "Epoch 3424, Loss: 0.00018598227325128391, Final Batch Loss: 7.315022230613977e-06\n",
      "Epoch 3425, Loss: 0.00016139503350132145, Final Batch Loss: 3.2494357583345845e-05\n",
      "Epoch 3426, Loss: 0.0017579945479155867, Final Batch Loss: 6.311361175903585e-06\n",
      "Epoch 3427, Loss: 0.0017963357372536848, Final Batch Loss: 4.803702267963672e-06\n",
      "Epoch 3428, Loss: 0.00019547009651432745, Final Batch Loss: 0.00017888729053083807\n",
      "Epoch 3429, Loss: 2.6052503017126583e-05, Final Batch Loss: 1.5246180737449322e-05\n",
      "Epoch 3430, Loss: 0.0001437198066014389, Final Batch Loss: 3.0226206035877112e-06\n",
      "Epoch 3431, Loss: 7.30706196918618e-05, Final Batch Loss: 5.170369695406407e-05\n",
      "Epoch 3432, Loss: 0.0003402891306905076, Final Batch Loss: 7.294250826817006e-05\n",
      "Epoch 3433, Loss: 2.3163763671618653e-05, Final Batch Loss: 5.688201326847775e-06\n",
      "Epoch 3434, Loss: 0.0030320149762701476, Final Batch Loss: 0.0030202451162040234\n",
      "Epoch 3435, Loss: 2.6198953491984867e-05, Final Batch Loss: 5.035948561271653e-06\n",
      "Epoch 3436, Loss: 5.6164737543440424e-05, Final Batch Loss: 3.652658415376209e-05\n",
      "Epoch 3437, Loss: 0.00204825846140011, Final Batch Loss: 0.0020387957338243723\n",
      "Epoch 3438, Loss: 0.00016414246420026757, Final Batch Loss: 0.00014541497512254864\n",
      "Epoch 3439, Loss: 4.7513554363831645e-05, Final Batch Loss: 6.642837888648501e-06\n",
      "Epoch 3440, Loss: 7.246699351526331e-05, Final Batch Loss: 5.249998503131792e-05\n",
      "Epoch 3441, Loss: 0.00041441895882599056, Final Batch Loss: 0.00034934881841763854\n",
      "Epoch 3442, Loss: 0.00010444235158502124, Final Batch Loss: 3.990619370597415e-05\n",
      "Epoch 3443, Loss: 5.224121741775889e-05, Final Batch Loss: 2.1610152543871664e-05\n",
      "Epoch 3444, Loss: 0.0005391142694861628, Final Batch Loss: 5.141957808518782e-05\n",
      "Epoch 3445, Loss: 0.0017902440740726888, Final Batch Loss: 0.0005161921144463122\n",
      "Epoch 3446, Loss: 4.3268217268632725e-05, Final Batch Loss: 1.8064924006466754e-05\n",
      "Epoch 3447, Loss: 0.00023845739633543417, Final Batch Loss: 6.264892726903781e-05\n",
      "Epoch 3448, Loss: 3.0324055842356756e-05, Final Batch Loss: 1.2808059182134457e-05\n",
      "Epoch 3449, Loss: 5.0534493425402616e-05, Final Batch Loss: 1.2016236041745287e-06\n",
      "Epoch 3450, Loss: 0.00200479019258637, Final Batch Loss: 0.0018458303529769182\n",
      "Epoch 3451, Loss: 8.63130544530577e-05, Final Batch Loss: 7.51727056922391e-05\n",
      "Epoch 3452, Loss: 5.852660979144275e-05, Final Batch Loss: 1.6306010365951806e-05\n",
      "Epoch 3453, Loss: 0.00019325171388118179, Final Batch Loss: 0.0001860602351371199\n",
      "Epoch 3454, Loss: 0.00033635241379670333, Final Batch Loss: 2.9436485419864766e-05\n",
      "Epoch 3455, Loss: 8.523149699612986e-05, Final Batch Loss: 6.510846287710592e-05\n",
      "Epoch 3456, Loss: 0.00011113005530205555, Final Batch Loss: 0.00010001521877711639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3457, Loss: 0.0006677783312625252, Final Batch Loss: 7.768128853058442e-05\n",
      "Epoch 3458, Loss: 2.8996317269047722e-05, Final Batch Loss: 8.8515935203759e-06\n",
      "Epoch 3459, Loss: 0.0012844163982208556, Final Batch Loss: 0.0012807244202122092\n",
      "Epoch 3460, Loss: 0.0003120862147625303, Final Batch Loss: 0.00028473648126237094\n",
      "Epoch 3461, Loss: 0.002655823787790723, Final Batch Loss: 0.0025374661199748516\n",
      "Epoch 3462, Loss: 4.7786455070308875e-05, Final Batch Loss: 7.929836101538967e-06\n",
      "Epoch 3463, Loss: 0.000751124978705775, Final Batch Loss: 8.457764488412067e-05\n",
      "Epoch 3464, Loss: 4.673845614888705e-05, Final Batch Loss: 2.5239362003048882e-05\n",
      "Epoch 3465, Loss: 7.854410523577826e-05, Final Batch Loss: 1.0802298675116617e-05\n",
      "Epoch 3466, Loss: 0.0007390464779746253, Final Batch Loss: 2.042534833890386e-05\n",
      "Epoch 3467, Loss: 0.0002681122387002688, Final Batch Loss: 3.322904740343802e-05\n",
      "Epoch 3468, Loss: 5.829066356000112e-05, Final Batch Loss: 5.447021749205305e-07\n",
      "Epoch 3469, Loss: 0.0003092665265285177, Final Batch Loss: 0.000279605999821797\n",
      "Epoch 3470, Loss: 6.158004612188961e-05, Final Batch Loss: 2.432804421914625e-06\n",
      "Epoch 3471, Loss: 0.00020633399253711104, Final Batch Loss: 0.00019088656699750572\n",
      "Epoch 3472, Loss: 0.0007679009831917938, Final Batch Loss: 0.0007346762577071786\n",
      "Epoch 3473, Loss: 2.6133948267670348e-05, Final Batch Loss: 1.623104981263168e-05\n",
      "Epoch 3474, Loss: 1.580365642439574e-05, Final Batch Loss: 2.9887014534324408e-06\n",
      "Epoch 3475, Loss: 0.004260881433765462, Final Batch Loss: 1.121694458561251e-05\n",
      "Epoch 3476, Loss: 0.00010243906524465274, Final Batch Loss: 0.00010091801232192665\n",
      "Epoch 3477, Loss: 6.602642224606825e-05, Final Batch Loss: 1.0301772817911115e-05\n",
      "Epoch 3478, Loss: 0.0002667939734237734, Final Batch Loss: 3.0927378247724846e-05\n",
      "Epoch 3479, Loss: 0.00021765070778201334, Final Batch Loss: 0.0001870093256002292\n",
      "Epoch 3480, Loss: 0.0001200086544486112, Final Batch Loss: 7.286914296855684e-06\n",
      "Epoch 3481, Loss: 0.0005321843877936772, Final Batch Loss: 4.59532975582988e-06\n",
      "Epoch 3482, Loss: 0.00010309747995052021, Final Batch Loss: 1.894376146083232e-05\n",
      "Epoch 3483, Loss: 0.00013069673877907917, Final Batch Loss: 4.048973642056808e-05\n",
      "Epoch 3484, Loss: 8.075299774645828e-05, Final Batch Loss: 3.185759487678297e-05\n",
      "Epoch 3485, Loss: 3.2311542781826574e-05, Final Batch Loss: 2.180881710955873e-05\n",
      "Epoch 3486, Loss: 0.001968091364688007, Final Batch Loss: 0.0019447675440460443\n",
      "Epoch 3487, Loss: 2.6620762923812435e-05, Final Batch Loss: 1.261624106518866e-06\n",
      "Epoch 3488, Loss: 0.00015253168567141984, Final Batch Loss: 2.638226760609541e-05\n",
      "Epoch 3489, Loss: 2.0117254621254688e-05, Final Batch Loss: 1.3530237765735365e-06\n",
      "Epoch 3490, Loss: 0.0019327885825077828, Final Batch Loss: 6.207905698829563e-06\n",
      "Epoch 3491, Loss: 0.0002290443480887916, Final Batch Loss: 0.00018550803360994905\n",
      "Epoch 3492, Loss: 4.7555659875797573e-05, Final Batch Loss: 4.818918569071684e-06\n",
      "Epoch 3493, Loss: 3.841320540232118e-05, Final Batch Loss: 7.421915142913349e-06\n",
      "Epoch 3494, Loss: 1.6981397607196413e-05, Final Batch Loss: 1.3469490340867196e-06\n",
      "Epoch 3495, Loss: 3.2980775358737446e-05, Final Batch Loss: 1.583476478117518e-05\n",
      "Epoch 3496, Loss: 6.0879927332280204e-05, Final Batch Loss: 1.1476739018689841e-05\n",
      "Epoch 3497, Loss: 2.1674092749890406e-05, Final Batch Loss: 1.4383815141627565e-05\n",
      "Epoch 3498, Loss: 1.8754156144495937e-05, Final Batch Loss: 2.3065392724674894e-06\n",
      "Epoch 3499, Loss: 4.494457061809953e-05, Final Batch Loss: 2.7758995202020742e-05\n",
      "Epoch 3500, Loss: 3.550867950252723e-05, Final Batch Loss: 3.291793109383434e-05\n",
      "Epoch 3501, Loss: 1.639858146518236e-05, Final Batch Loss: 1.023014647216769e-05\n",
      "Epoch 3502, Loss: 0.00023665869230171666, Final Batch Loss: 6.942929030628875e-05\n",
      "Epoch 3503, Loss: 3.7971338315401226e-05, Final Batch Loss: 2.9387703762040474e-05\n",
      "Epoch 3504, Loss: 0.002345388915273361, Final Batch Loss: 0.002262812340632081\n",
      "Epoch 3505, Loss: 4.219835682306439e-05, Final Batch Loss: 1.863760371634271e-05\n",
      "Epoch 3506, Loss: 2.4064978561000316e-05, Final Batch Loss: 2.230603240604978e-05\n",
      "Epoch 3507, Loss: 0.0001711412876943541, Final Batch Loss: 8.092136454251886e-07\n",
      "Epoch 3508, Loss: 7.51878601477074e-05, Final Batch Loss: 6.875711551401764e-05\n",
      "Epoch 3509, Loss: 3.505154791128007e-05, Final Batch Loss: 2.7564306947169825e-05\n",
      "Epoch 3510, Loss: 1.2764273321863584e-05, Final Batch Loss: 1.2481510566431098e-05\n",
      "Epoch 3511, Loss: 2.93276461889036e-05, Final Batch Loss: 1.913717460411135e-05\n",
      "Epoch 3512, Loss: 4.158589035796467e-05, Final Batch Loss: 3.5041466617258266e-06\n",
      "Epoch 3513, Loss: 4.2137551190535305e-05, Final Batch Loss: 7.2695106609899085e-06\n",
      "Epoch 3514, Loss: 1.9417991097725462e-05, Final Batch Loss: 1.2282883290026803e-05\n",
      "Epoch 3515, Loss: 6.805320481362287e-06, Final Batch Loss: 4.636332505469909e-06\n",
      "Epoch 3516, Loss: 5.218740932377841e-05, Final Batch Loss: 1.1537844102349482e-06\n",
      "Epoch 3517, Loss: 1.661971600697143e-05, Final Batch Loss: 6.267522621783428e-06\n",
      "Epoch 3518, Loss: 3.0097907256276812e-05, Final Batch Loss: 1.8621165509102866e-05\n",
      "Epoch 3519, Loss: 0.00011490723773022182, Final Batch Loss: 3.940301758120768e-05\n",
      "Epoch 3520, Loss: 0.00018618814283399843, Final Batch Loss: 4.70115446660202e-05\n",
      "Epoch 3521, Loss: 6.315328391792718e-05, Final Batch Loss: 4.35863112215884e-05\n",
      "Epoch 3522, Loss: 0.0002256750813103281, Final Batch Loss: 7.88583347457461e-05\n",
      "Epoch 3523, Loss: 0.0002062788298644591, Final Batch Loss: 2.6809986593434587e-05\n",
      "Epoch 3524, Loss: 6.445362669182941e-05, Final Batch Loss: 1.9613333279266953e-05\n",
      "Epoch 3525, Loss: 4.0200855551120185e-06, Final Batch Loss: 3.276742518210085e-06\n",
      "Epoch 3526, Loss: 0.00010039352537205559, Final Batch Loss: 9.863172454060987e-05\n",
      "Epoch 3527, Loss: 1.4118398098617035e-05, Final Batch Loss: 1.3504130720320973e-06\n",
      "Epoch 3528, Loss: 0.0023851838986956864, Final Batch Loss: 0.0023772302083671093\n",
      "Epoch 3529, Loss: 1.4238819858292118e-05, Final Batch Loss: 7.240933427965501e-06\n",
      "Epoch 3530, Loss: 2.833177063621406e-05, Final Batch Loss: 3.2054151688498678e-06\n",
      "Epoch 3531, Loss: 0.00010061670036520809, Final Batch Loss: 1.7669466615188867e-05\n",
      "Epoch 3532, Loss: 0.00016171263405340142, Final Batch Loss: 0.00015491490194108337\n",
      "Epoch 3533, Loss: 0.00014160996215650812, Final Batch Loss: 9.190809942083433e-05\n",
      "Epoch 3534, Loss: 2.1440844534481585e-05, Final Batch Loss: 1.5183485402303631e-06\n",
      "Epoch 3535, Loss: 4.713765429187333e-05, Final Batch Loss: 3.460364314378239e-05\n",
      "Epoch 3536, Loss: 0.00020180007084036333, Final Batch Loss: 8.840473810778349e-07\n",
      "Epoch 3537, Loss: 0.00019106838954030536, Final Batch Loss: 0.00017415705951862037\n",
      "Epoch 3538, Loss: 0.0003930330494767986, Final Batch Loss: 0.00030711147701367736\n",
      "Epoch 3539, Loss: 3.013253916606118e-05, Final Batch Loss: 7.865903057791002e-07\n",
      "Epoch 3540, Loss: 0.004734005109639838, Final Batch Loss: 0.004492558538913727\n",
      "Epoch 3541, Loss: 5.121688991494011e-05, Final Batch Loss: 7.84702024247963e-06\n",
      "Epoch 3542, Loss: 0.0001529031214886345, Final Batch Loss: 7.630987965967506e-06\n",
      "Epoch 3543, Loss: 3.212963065379881e-05, Final Batch Loss: 2.635479722812306e-05\n",
      "Epoch 3544, Loss: 4.727162604467594e-05, Final Batch Loss: 4.116078343940899e-05\n",
      "Epoch 3545, Loss: 0.0009797173697734252, Final Batch Loss: 0.0009336303919553757\n",
      "Epoch 3546, Loss: 3.403986795547098e-06, Final Batch Loss: 2.6458294541953364e-06\n",
      "Epoch 3547, Loss: 9.006071877593058e-06, Final Batch Loss: 1.7697573184705107e-06\n",
      "Epoch 3548, Loss: 0.0008700964453254301, Final Batch Loss: 1.8533948775711906e-07\n",
      "Epoch 3549, Loss: 0.0001274337412269233, Final Batch Loss: 1.3460669379128376e-06\n",
      "Epoch 3550, Loss: 4.141305271332385e-05, Final Batch Loss: 1.320264800597215e-05\n",
      "Epoch 3551, Loss: 9.525468885840382e-05, Final Batch Loss: 1.460812745790463e-05\n",
      "Epoch 3552, Loss: 0.0010219644545941264, Final Batch Loss: 1.380939738737652e-05\n",
      "Epoch 3553, Loss: 0.00034924915803458134, Final Batch Loss: 2.9998393529240275e-06\n",
      "Epoch 3554, Loss: 3.8756058074795874e-05, Final Batch Loss: 6.817885605414631e-06\n",
      "Epoch 3555, Loss: 0.0006618037077714689, Final Batch Loss: 2.361398219363764e-05\n",
      "Epoch 3556, Loss: 0.0031884270024420402, Final Batch Loss: 4.0607296796224546e-06\n",
      "Epoch 3557, Loss: 4.1751122466848756e-05, Final Batch Loss: 8.701250635567703e-07\n",
      "Epoch 3558, Loss: 1.0578661672866474e-05, Final Batch Loss: 1.2268948523797008e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3559, Loss: 0.00017044067863025703, Final Batch Loss: 5.1577775593614206e-05\n",
      "Epoch 3560, Loss: 0.0003925684036403254, Final Batch Loss: 5.300059001456248e-06\n",
      "Epoch 3561, Loss: 5.05831376358401e-05, Final Batch Loss: 1.5520756278419867e-05\n",
      "Epoch 3562, Loss: 0.0008980642080587131, Final Batch Loss: 2.9408613499981584e-06\n",
      "Epoch 3563, Loss: 0.00016516135292476974, Final Batch Loss: 0.00012813105422537774\n",
      "Epoch 3564, Loss: 3.2081446079246234e-05, Final Batch Loss: 7.2646644184715115e-06\n",
      "Epoch 3565, Loss: 9.740122186485678e-05, Final Batch Loss: 5.696514926967211e-05\n",
      "Epoch 3566, Loss: 0.0020147223258391023, Final Batch Loss: 0.0007211660267785192\n",
      "Epoch 3567, Loss: 0.002292123783263378, Final Batch Loss: 0.00015847540635149926\n",
      "Epoch 3568, Loss: 0.0005663453033548649, Final Batch Loss: 7.065376621540054e-07\n",
      "Epoch 3569, Loss: 5.207230060477741e-05, Final Batch Loss: 2.7451202186057344e-05\n",
      "Epoch 3570, Loss: 9.17069678507687e-06, Final Batch Loss: 5.003255409974372e-07\n",
      "Epoch 3571, Loss: 1.4609565596401808e-05, Final Batch Loss: 3.35995468958572e-06\n",
      "Epoch 3572, Loss: 0.0029526430043915752, Final Batch Loss: 0.002930308924987912\n",
      "Epoch 3573, Loss: 1.125887138186954e-05, Final Batch Loss: 8.138620614772663e-06\n",
      "Epoch 3574, Loss: 2.7992103241558652e-05, Final Batch Loss: 2.0634883185266517e-05\n",
      "Epoch 3575, Loss: 4.220164601065335e-05, Final Batch Loss: 3.5681601730175316e-05\n",
      "Epoch 3576, Loss: 0.0016224321225308813, Final Batch Loss: 2.153669629478827e-05\n",
      "Epoch 3577, Loss: 6.317480165307643e-05, Final Batch Loss: 1.3555135410570074e-05\n",
      "Epoch 3578, Loss: 0.00012333817721810192, Final Batch Loss: 6.220214709173888e-05\n",
      "Epoch 3579, Loss: 0.00024848700923030265, Final Batch Loss: 1.6815876733744517e-05\n",
      "Epoch 3580, Loss: 2.1882013470531092e-05, Final Batch Loss: 3.6956082567485282e-06\n",
      "Epoch 3581, Loss: 0.003048100224987138, Final Batch Loss: 0.0030379777308553457\n",
      "Epoch 3582, Loss: 1.775099190126639e-05, Final Batch Loss: 8.577297194278799e-06\n",
      "Epoch 3583, Loss: 4.767007430928061e-05, Final Batch Loss: 3.473171454970725e-05\n",
      "Epoch 3584, Loss: 2.420628214849785e-05, Final Batch Loss: 5.011904136154044e-07\n",
      "Epoch 3585, Loss: 9.016467674882733e-05, Final Batch Loss: 8.528670878149569e-05\n",
      "Epoch 3586, Loss: 0.001222683731612051, Final Batch Loss: 0.0012086894130334258\n",
      "Epoch 3587, Loss: 2.1799668502353597e-05, Final Batch Loss: 2.5943636501324363e-06\n",
      "Epoch 3588, Loss: 0.0002692168072826462, Final Batch Loss: 0.00025824891054071486\n",
      "Epoch 3589, Loss: 9.54444858507486e-05, Final Batch Loss: 8.715443254914135e-05\n",
      "Epoch 3590, Loss: 0.000784835108788684, Final Batch Loss: 0.0001226829190272838\n",
      "Epoch 3591, Loss: 9.688174759503454e-05, Final Batch Loss: 6.247279816307127e-05\n",
      "Epoch 3592, Loss: 0.0004066707188030705, Final Batch Loss: 7.950424333103001e-06\n",
      "Epoch 3593, Loss: 5.302197223500116e-05, Final Batch Loss: 4.556287603918463e-05\n",
      "Epoch 3594, Loss: 0.002386393009146559, Final Batch Loss: 2.160061376343947e-05\n",
      "Epoch 3595, Loss: 0.0012597436143551022, Final Batch Loss: 0.0002697636664379388\n",
      "Epoch 3596, Loss: 0.0005348705403775966, Final Batch Loss: 2.2570552573597524e-06\n",
      "Epoch 3597, Loss: 1.897998549793556e-05, Final Batch Loss: 8.509875897289021e-07\n",
      "Epoch 3598, Loss: 2.374436962782056e-05, Final Batch Loss: 3.9171832213469315e-06\n",
      "Epoch 3599, Loss: 5.836214404553175e-05, Final Batch Loss: 4.963434912497178e-05\n",
      "Epoch 3600, Loss: 1.585009999871545e-05, Final Batch Loss: 1.4238949916034471e-05\n",
      "Epoch 3601, Loss: 6.399591933359261e-05, Final Batch Loss: 5.455671612253354e-07\n",
      "Epoch 3602, Loss: 1.0663209195627132e-05, Final Batch Loss: 5.124527888256125e-06\n",
      "Epoch 3603, Loss: 0.001025293435304775, Final Batch Loss: 1.4043816918274388e-06\n",
      "Epoch 3604, Loss: 1.4966915387049085e-05, Final Batch Loss: 4.155324404564453e-06\n",
      "Epoch 3605, Loss: 0.0001811291795092984, Final Batch Loss: 3.367712452018168e-06\n",
      "Epoch 3606, Loss: 6.196306730998913e-05, Final Batch Loss: 5.230800525168888e-05\n",
      "Epoch 3607, Loss: 0.00010553829633863643, Final Batch Loss: 4.6725130232516676e-05\n",
      "Epoch 3608, Loss: 1.790753185559879e-05, Final Batch Loss: 4.488701506488724e-06\n",
      "Epoch 3609, Loss: 2.379519173700828e-05, Final Batch Loss: 7.869834007578902e-06\n",
      "Epoch 3610, Loss: 9.656559791437758e-05, Final Batch Loss: 9.231932835973566e-07\n",
      "Epoch 3611, Loss: 0.001035899986163713, Final Batch Loss: 0.00011572307266760617\n",
      "Epoch 3612, Loss: 5.319380898072268e-05, Final Batch Loss: 3.889952040481148e-06\n",
      "Epoch 3613, Loss: 0.0003571862180251628, Final Batch Loss: 0.000135404261527583\n",
      "Epoch 3614, Loss: 0.00020888411199848633, Final Batch Loss: 1.336681998509448e-05\n",
      "Epoch 3615, Loss: 0.00015969871310517192, Final Batch Loss: 7.246773748192936e-05\n",
      "Epoch 3616, Loss: 1.7144159755844157e-05, Final Batch Loss: 5.679399691871367e-06\n",
      "Epoch 3617, Loss: 1.7044565538526513e-05, Final Batch Loss: 2.2552194423042238e-06\n",
      "Epoch 3618, Loss: 0.0002416721179514525, Final Batch Loss: 2.0622228191768954e-07\n",
      "Epoch 3619, Loss: 7.358022372727646e-06, Final Batch Loss: 2.906255360812793e-07\n",
      "Epoch 3620, Loss: 2.0414430764503777e-05, Final Batch Loss: 7.918343726487365e-06\n",
      "Epoch 3621, Loss: 4.994399250790593e-05, Final Batch Loss: 4.580600943882018e-05\n",
      "Epoch 3622, Loss: 3.863499659928493e-05, Final Batch Loss: 1.4713912605657242e-05\n",
      "Epoch 3623, Loss: 4.606849870469887e-05, Final Batch Loss: 3.323130658827722e-05\n",
      "Epoch 3624, Loss: 9.40196514420677e-06, Final Batch Loss: 5.031291948398575e-06\n",
      "Epoch 3625, Loss: 2.7240314238952124e-05, Final Batch Loss: 1.921049488373683e-06\n",
      "Epoch 3626, Loss: 1.6548299754504114e-05, Final Batch Loss: 4.410619112604763e-06\n",
      "Epoch 3627, Loss: 2.9554376396845328e-05, Final Batch Loss: 2.3762890123180114e-05\n",
      "Epoch 3628, Loss: 0.00042346901318524033, Final Batch Loss: 4.486010584514588e-05\n",
      "Epoch 3629, Loss: 1.8014624401985202e-05, Final Batch Loss: 1.055077609635191e-05\n",
      "Epoch 3630, Loss: 0.0015773017294122837, Final Batch Loss: 7.984657713677734e-06\n",
      "Epoch 3631, Loss: 0.0008121711439343926, Final Batch Loss: 6.909191597515019e-06\n",
      "Epoch 3632, Loss: 3.5980658140033484e-05, Final Batch Loss: 3.171554271830246e-05\n",
      "Epoch 3633, Loss: 0.0004961262893630192, Final Batch Loss: 2.0492952899076045e-05\n",
      "Epoch 3634, Loss: 4.173266802354192e-06, Final Batch Loss: 2.0535105704766465e-07\n",
      "Epoch 3635, Loss: 3.1074984690349083e-05, Final Batch Loss: 5.055876499682199e-06\n",
      "Epoch 3636, Loss: 2.3542391886621772e-05, Final Batch Loss: 1.461775923417008e-06\n",
      "Epoch 3637, Loss: 6.467112143582199e-05, Final Batch Loss: 4.225723387207836e-05\n",
      "Epoch 3638, Loss: 0.00011378021372365765, Final Batch Loss: 1.567520303069614e-05\n",
      "Epoch 3639, Loss: 4.5381908648778335e-06, Final Batch Loss: 3.086288188569597e-06\n",
      "Epoch 3640, Loss: 3.798525722231716e-05, Final Batch Loss: 1.7380230929120444e-05\n",
      "Epoch 3641, Loss: 9.011953261506278e-05, Final Batch Loss: 7.306576662813313e-06\n",
      "Epoch 3642, Loss: 3.46643096236221e-05, Final Batch Loss: 5.152887297299458e-06\n",
      "Epoch 3643, Loss: 1.672352732384752e-05, Final Batch Loss: 2.757223001026432e-06\n",
      "Epoch 3644, Loss: 0.00019216958708057064, Final Batch Loss: 4.563501988741336e-06\n",
      "Epoch 3645, Loss: 0.0006462793826358393, Final Batch Loss: 1.8479840946383774e-05\n",
      "Epoch 3646, Loss: 0.00015881058880040655, Final Batch Loss: 1.0652694072632585e-05\n",
      "Epoch 3647, Loss: 8.911484110285528e-05, Final Batch Loss: 7.471473509212956e-05\n",
      "Epoch 3648, Loss: 8.654670637042727e-05, Final Batch Loss: 1.8391996491118334e-05\n",
      "Epoch 3649, Loss: 2.7375407626095694e-05, Final Batch Loss: 1.6334743122570217e-05\n",
      "Epoch 3650, Loss: 1.284188192585134e-05, Final Batch Loss: 6.5174722294614185e-06\n",
      "Epoch 3651, Loss: 9.493096803225853e-05, Final Batch Loss: 8.240014608418278e-07\n",
      "Epoch 3652, Loss: 9.34005988710851e-05, Final Batch Loss: 1.064149273588555e-06\n",
      "Epoch 3653, Loss: 0.0005258132755443512, Final Batch Loss: 0.0005229621310718358\n",
      "Epoch 3654, Loss: 5.440210770757403e-05, Final Batch Loss: 1.5787993106641807e-05\n",
      "Epoch 3655, Loss: 0.0002345794637221843, Final Batch Loss: 7.53318308852613e-05\n",
      "Epoch 3656, Loss: 0.0005748556059188559, Final Batch Loss: 0.0005657890578731894\n",
      "Epoch 3657, Loss: 0.0010442881678045524, Final Batch Loss: 1.3451856375468196e-06\n",
      "Epoch 3658, Loss: 0.00010012136885961809, Final Batch Loss: 9.658942144596949e-05\n",
      "Epoch 3659, Loss: 6.917229700320604e-05, Final Batch Loss: 1.0023585446106154e-06\n",
      "Epoch 3660, Loss: 0.0020437158964341506, Final Batch Loss: 0.0019872919656336308\n",
      "Epoch 3661, Loss: 2.5915306878232514e-06, Final Batch Loss: 1.5696916761953617e-06\n",
      "Epoch 3662, Loss: 3.8229202800721396e-05, Final Batch Loss: 7.926243597466964e-06\n",
      "Epoch 3663, Loss: 3.085188200202538e-05, Final Batch Loss: 2.101617428706959e-05\n",
      "Epoch 3664, Loss: 0.001884761935343704, Final Batch Loss: 0.0018809152534231544\n",
      "Epoch 3665, Loss: 0.000112749688923941, Final Batch Loss: 2.6661613446776755e-05\n",
      "Epoch 3666, Loss: 0.002195094804847031, Final Batch Loss: 2.269502692797687e-05\n",
      "Epoch 3667, Loss: 0.000115503783490567, Final Batch Loss: 8.826283192320261e-06\n",
      "Epoch 3668, Loss: 2.175758436351316e-05, Final Batch Loss: 1.8253069356433116e-05\n",
      "Epoch 3669, Loss: 0.0026017928512374056, Final Batch Loss: 0.002589763840660453\n",
      "Epoch 3670, Loss: 0.0010370698082624585, Final Batch Loss: 0.0010222489945590496\n",
      "Epoch 3671, Loss: 9.756373856362188e-06, Final Batch Loss: 2.7015285013476387e-06\n",
      "Epoch 3672, Loss: 0.00045262153435032815, Final Batch Loss: 0.00038056870107539\n",
      "Epoch 3673, Loss: 1.3618121556646656e-05, Final Batch Loss: 1.9786029952229e-06\n",
      "Epoch 3674, Loss: 4.3716612765365426e-06, Final Batch Loss: 3.732888274043944e-07\n",
      "Epoch 3675, Loss: 4.81211427540984e-05, Final Batch Loss: 1.3346503692446277e-05\n",
      "Epoch 3676, Loss: 0.0006591264547068931, Final Batch Loss: 0.0006580264889635146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3677, Loss: 4.638748578145169e-05, Final Batch Loss: 2.073225005005952e-05\n",
      "Epoch 3678, Loss: 6.725178877786675e-06, Final Batch Loss: 1.1955415857300977e-06\n",
      "Epoch 3679, Loss: 1.602104958919881e-06, Final Batch Loss: 4.0722252947489324e-07\n",
      "Epoch 3680, Loss: 3.096394743806741e-05, Final Batch Loss: 3.0379853797057876e-06\n",
      "Epoch 3681, Loss: 2.860560539375001e-05, Final Batch Loss: 3.3103640362242004e-06\n",
      "Epoch 3682, Loss: 3.6866420636272323e-05, Final Batch Loss: 1.0789714366410408e-07\n",
      "Epoch 3683, Loss: 0.0002574840709712589, Final Batch Loss: 0.00023697278811596334\n",
      "Epoch 3684, Loss: 0.0008672943199599104, Final Batch Loss: 4.4747116589860525e-06\n",
      "Epoch 3685, Loss: 6.656255027337465e-05, Final Batch Loss: 2.7525200493982993e-05\n",
      "Epoch 3686, Loss: 3.736146663868567e-05, Final Batch Loss: 2.7869613404618576e-05\n",
      "Epoch 3687, Loss: 0.0001621907576918602, Final Batch Loss: 0.0001252846559509635\n",
      "Epoch 3688, Loss: 1.4789280385230086e-05, Final Batch Loss: 1.1113655091321561e-05\n",
      "Epoch 3689, Loss: 0.010397047580227081, Final Batch Loss: 0.010386668145656586\n",
      "Epoch 3690, Loss: 6.704075349261984e-05, Final Batch Loss: 6.275231862673536e-05\n",
      "Epoch 3691, Loss: 0.0014717521071361261, Final Batch Loss: 0.0014603136805817485\n",
      "Epoch 3692, Loss: 0.0026343166432525322, Final Batch Loss: 0.0026318496093153954\n",
      "Epoch 3693, Loss: 0.0005439185006252956, Final Batch Loss: 0.0004878113104496151\n",
      "Epoch 3694, Loss: 0.00012354878708720207, Final Batch Loss: 4.342721513239667e-05\n",
      "Epoch 3695, Loss: 0.00048192599570029415, Final Batch Loss: 2.150864020222798e-06\n",
      "Epoch 3696, Loss: 0.0001211595481436234, Final Batch Loss: 0.0001050546343321912\n",
      "Epoch 3697, Loss: 0.0002442477889417205, Final Batch Loss: 1.747484566294588e-05\n",
      "Epoch 3698, Loss: 1.1518714018166065e-05, Final Batch Loss: 1.5200839698081836e-06\n",
      "Epoch 3699, Loss: 0.00014062277750781504, Final Batch Loss: 0.00012962579785380512\n",
      "Epoch 3700, Loss: 4.160851585766068e-05, Final Batch Loss: 3.373940853634849e-05\n",
      "Epoch 3701, Loss: 5.293480171530973e-05, Final Batch Loss: 3.5684319300344214e-05\n",
      "Epoch 3702, Loss: 4.76466784675722e-05, Final Batch Loss: 2.2307876861304976e-06\n",
      "Epoch 3703, Loss: 3.835901043203194e-05, Final Batch Loss: 2.5978888515965082e-05\n",
      "Epoch 3704, Loss: 4.4128737499704584e-05, Final Batch Loss: 1.642864845052827e-05\n",
      "Epoch 3705, Loss: 7.988034781192255e-06, Final Batch Loss: 6.177789373396081e-07\n",
      "Epoch 3706, Loss: 5.478406217207521e-05, Final Batch Loss: 1.0493434956515557e-06\n",
      "Epoch 3707, Loss: 6.156628660392016e-05, Final Batch Loss: 1.601719850441441e-05\n",
      "Epoch 3708, Loss: 1.662764634602354e-05, Final Batch Loss: 1.3814778867526911e-05\n",
      "Epoch 3709, Loss: 0.0006156849040053203, Final Batch Loss: 1.0492810361029115e-05\n",
      "Epoch 3710, Loss: 6.306610612227814e-05, Final Batch Loss: 4.8589503421681e-05\n",
      "Epoch 3711, Loss: 9.442710143048316e-05, Final Batch Loss: 5.5923068430274725e-05\n",
      "Epoch 3712, Loss: 2.419640281914326e-05, Final Batch Loss: 2.294457090101787e-06\n",
      "Epoch 3713, Loss: 0.0004529855453085929, Final Batch Loss: 1.4618333921134763e-07\n",
      "Epoch 3714, Loss: 2.593317003629636e-05, Final Batch Loss: 1.4029385965841357e-05\n",
      "Epoch 3715, Loss: 1.738128139550099e-05, Final Batch Loss: 1.687957592366729e-06\n",
      "Epoch 3716, Loss: 7.905935308372136e-05, Final Batch Loss: 2.468119237164501e-05\n",
      "Epoch 3717, Loss: 1.5477020724574686e-05, Final Batch Loss: 1.1925337275897618e-05\n",
      "Epoch 3718, Loss: 0.0026332469947192294, Final Batch Loss: 4.630704552255338e-06\n",
      "Epoch 3719, Loss: 0.0005065766162033469, Final Batch Loss: 1.7062410506696324e-06\n",
      "Epoch 3720, Loss: 5.910596655667177e-06, Final Batch Loss: 3.7868333038204582e-06\n",
      "Epoch 3721, Loss: 1.9208563116990263e-05, Final Batch Loss: 7.517887297581183e-06\n",
      "Epoch 3722, Loss: 3.797066710831132e-05, Final Batch Loss: 1.5689096471760422e-05\n",
      "Epoch 3723, Loss: 1.1908778333236114e-05, Final Batch Loss: 3.563778818715946e-06\n",
      "Epoch 3724, Loss: 8.068875467870384e-05, Final Batch Loss: 2.0293155102990568e-05\n",
      "Epoch 3725, Loss: 0.00031015535751066636, Final Batch Loss: 1.1228547009523027e-05\n",
      "Epoch 3726, Loss: 0.00014023527455719886, Final Batch Loss: 1.391600653732894e-05\n",
      "Epoch 3727, Loss: 0.0062951769853043515, Final Batch Loss: 2.172606627937057e-06\n",
      "Epoch 3728, Loss: 3.825043859251309e-05, Final Batch Loss: 2.9277909561642446e-05\n",
      "Epoch 3729, Loss: 1.784009964467259e-05, Final Batch Loss: 1.2096385944460053e-05\n",
      "Epoch 3730, Loss: 5.683515701093711e-05, Final Batch Loss: 2.3072960175340995e-05\n",
      "Epoch 3731, Loss: 8.094878103293013e-05, Final Batch Loss: 7.51350526115857e-05\n",
      "Epoch 3732, Loss: 6.4879291130637284e-06, Final Batch Loss: 2.2422036636271514e-06\n",
      "Epoch 3733, Loss: 0.0011289688263786957, Final Batch Loss: 7.242737046908587e-05\n",
      "Epoch 3734, Loss: 0.00030325353509397246, Final Batch Loss: 5.249615423963405e-05\n",
      "Epoch 3735, Loss: 0.00019239088669564808, Final Batch Loss: 0.00018165922665502876\n",
      "Epoch 3736, Loss: 3.407906928032389e-05, Final Batch Loss: 5.855990252712218e-07\n",
      "Epoch 3737, Loss: 1.5019591302234403e-05, Final Batch Loss: 8.266331974482455e-08\n",
      "Epoch 3738, Loss: 1.4992810065450612e-05, Final Batch Loss: 7.771797754685394e-06\n",
      "Epoch 3739, Loss: 1.6680561884641065e-05, Final Batch Loss: 2.1161129097890807e-06\n",
      "Epoch 3740, Loss: 1.3130932075000601e-05, Final Batch Loss: 2.238780780317029e-06\n",
      "Epoch 3741, Loss: 9.734606919664657e-06, Final Batch Loss: 5.539366611628793e-06\n",
      "Epoch 3742, Loss: 4.240950511302799e-05, Final Batch Loss: 1.639506808714941e-05\n",
      "Epoch 3743, Loss: 1.9422875084273983e-05, Final Batch Loss: 1.3833700904797297e-05\n",
      "Epoch 3744, Loss: 0.001264980949144956, Final Batch Loss: 7.549139354523504e-06\n",
      "Epoch 3745, Loss: 5.3894653319730423e-05, Final Batch Loss: 1.7873759134090506e-05\n",
      "Epoch 3746, Loss: 5.385346776165534e-05, Final Batch Loss: 3.299215677543543e-05\n",
      "Epoch 3747, Loss: 0.0004419706809812851, Final Batch Loss: 3.828598664767924e-07\n",
      "Epoch 3748, Loss: 0.003547472195350565, Final Batch Loss: 0.00011736505257431418\n",
      "Epoch 3749, Loss: 1.622829358893796e-05, Final Batch Loss: 4.1680846152303275e-06\n",
      "Epoch 3750, Loss: 0.00021796225155412685, Final Batch Loss: 6.365675289998762e-06\n",
      "Epoch 3751, Loss: 0.00011861144594149664, Final Batch Loss: 4.602033004630357e-05\n",
      "Epoch 3752, Loss: 2.893301279982552e-05, Final Batch Loss: 4.826008080272004e-06\n",
      "Epoch 3753, Loss: 0.00010785945823954535, Final Batch Loss: 6.680595561192604e-06\n",
      "Epoch 3754, Loss: 0.0004241551373524999, Final Batch Loss: 6.6200605033372995e-06\n",
      "Epoch 3755, Loss: 2.0695421653726953e-05, Final Batch Loss: 1.943428287631832e-05\n",
      "Epoch 3756, Loss: 2.2284287751972442e-05, Final Batch Loss: 5.046221758675529e-06\n",
      "Epoch 3757, Loss: 0.0001600171726749977, Final Batch Loss: 0.00015621920465491712\n",
      "Epoch 3758, Loss: 4.443924126462662e-06, Final Batch Loss: 2.020295141846873e-06\n",
      "Epoch 3759, Loss: 2.0022258922836045e-05, Final Batch Loss: 4.679201538237976e-06\n",
      "Epoch 3760, Loss: 1.1742994075802926e-05, Final Batch Loss: 2.8279421826482576e-07\n",
      "Epoch 3761, Loss: 3.389463290659478e-05, Final Batch Loss: 9.397176654601935e-06\n",
      "Epoch 3762, Loss: 0.0011926414008485153, Final Batch Loss: 0.0011346112005412579\n",
      "Epoch 3763, Loss: 7.883843636591337e-06, Final Batch Loss: 1.5148195871006465e-06\n",
      "Epoch 3764, Loss: 2.0415447124833008e-05, Final Batch Loss: 3.842983915092191e-06\n",
      "Epoch 3765, Loss: 0.0018034520599030657, Final Batch Loss: 2.3345839508692734e-05\n",
      "Epoch 3766, Loss: 2.7568470613914542e-05, Final Batch Loss: 9.382261850987561e-06\n",
      "Epoch 3767, Loss: 3.7321558920666575e-05, Final Batch Loss: 2.1144567654118873e-05\n",
      "Epoch 3768, Loss: 0.003379845788003877, Final Batch Loss: 0.0032278085127472878\n",
      "Epoch 3769, Loss: 1.6149760313055594e-05, Final Batch Loss: 1.3079392374493182e-05\n",
      "Epoch 3770, Loss: 0.00032948508487606887, Final Batch Loss: 1.1057718438678421e-05\n",
      "Epoch 3771, Loss: 4.211333560988351e-06, Final Batch Loss: 3.926186764147133e-06\n",
      "Epoch 3772, Loss: 0.0026094679578818614, Final Batch Loss: 0.002593049081042409\n",
      "Epoch 3773, Loss: 0.0002169312174373772, Final Batch Loss: 0.00017070566536858678\n",
      "Epoch 3774, Loss: 1.3597802649201185e-05, Final Batch Loss: 1.232522936334135e-05\n",
      "Epoch 3775, Loss: 3.528732986524119e-05, Final Batch Loss: 3.429269781918265e-05\n",
      "Epoch 3776, Loss: 2.312632886969368e-06, Final Batch Loss: 7.883376156314625e-07\n",
      "Epoch 3777, Loss: 8.912262728699716e-06, Final Batch Loss: 4.738174538942985e-06\n",
      "Epoch 3778, Loss: 6.066368587198667e-05, Final Batch Loss: 5.6562566896900535e-05\n",
      "Epoch 3779, Loss: 0.00015172246276051737, Final Batch Loss: 1.5942863683449104e-05\n",
      "Epoch 3780, Loss: 0.0022774003675749555, Final Batch Loss: 0.0022736871615052223\n",
      "Epoch 3781, Loss: 5.345706995285582e-05, Final Batch Loss: 1.178456841444131e-05\n",
      "Epoch 3782, Loss: 2.3363286345556844e-05, Final Batch Loss: 9.822330866882112e-06\n",
      "Epoch 3783, Loss: 9.970176336082659e-06, Final Batch Loss: 8.300983722620003e-07\n",
      "Epoch 3784, Loss: 5.613208145405224e-06, Final Batch Loss: 4.900831299892161e-06\n",
      "Epoch 3785, Loss: 1.5137249079089088e-05, Final Batch Loss: 5.21209017279034e-07\n",
      "Epoch 3786, Loss: 0.0013276678073452786, Final Batch Loss: 4.052645817864686e-05\n",
      "Epoch 3787, Loss: 2.889671691264084e-05, Final Batch Loss: 2.5542329240124673e-05\n",
      "Epoch 3788, Loss: 6.225324159458978e-05, Final Batch Loss: 4.914444070891477e-05\n",
      "Epoch 3789, Loss: 2.085354708469822e-05, Final Batch Loss: 2.2291783352557104e-06\n",
      "Epoch 3790, Loss: 2.3945713792272727e-05, Final Batch Loss: 2.101235804730095e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3791, Loss: 1.0010693813455873e-05, Final Batch Loss: 2.5334286419820273e-06\n",
      "Epoch 3792, Loss: 3.738648501894204e-05, Final Batch Loss: 2.8746570023940876e-05\n",
      "Epoch 3793, Loss: 7.207211183413165e-06, Final Batch Loss: 4.9261470849160105e-06\n",
      "Epoch 3794, Loss: 0.0006922222623870766, Final Batch Loss: 4.64950653622509e-06\n",
      "Epoch 3795, Loss: 2.9625458410009742e-05, Final Batch Loss: 1.9029981558560394e-05\n",
      "Epoch 3796, Loss: 0.0001418478232153575, Final Batch Loss: 0.0001390856778016314\n",
      "Epoch 3797, Loss: 3.400036462153366e-05, Final Batch Loss: 1.8872417513193795e-06\n",
      "Epoch 3798, Loss: 0.0012454145617084578, Final Batch Loss: 0.0012351645855233073\n",
      "Epoch 3799, Loss: 0.0016147816531884018, Final Batch Loss: 3.1857260182732716e-05\n",
      "Epoch 3800, Loss: 8.667752226187986e-05, Final Batch Loss: 2.0622209717657825e-07\n",
      "Epoch 3801, Loss: 0.00031809232314117253, Final Batch Loss: 0.00017464003758504987\n",
      "Epoch 3802, Loss: 0.0016106069178931648, Final Batch Loss: 0.0015953308902680874\n",
      "Epoch 3803, Loss: 0.0001289635147259105, Final Batch Loss: 0.00011257822916377336\n",
      "Epoch 3804, Loss: 0.0002675598291261849, Final Batch Loss: 0.0002659797319211066\n",
      "Epoch 3805, Loss: 4.867713187195477e-06, Final Batch Loss: 3.3095848266384564e-06\n",
      "Epoch 3806, Loss: 8.283600209324504e-06, Final Batch Loss: 4.693804385169642e-06\n",
      "Epoch 3807, Loss: 0.00011584026788113988, Final Batch Loss: 0.0001132356992457062\n",
      "Epoch 3808, Loss: 0.04564903792925179, Final Batch Loss: 0.044919487088918686\n",
      "Epoch 3809, Loss: 0.00022227307817956898, Final Batch Loss: 0.00021871428180020303\n",
      "Epoch 3810, Loss: 5.5480035371147096e-05, Final Batch Loss: 3.96997420466505e-05\n",
      "Epoch 3811, Loss: 4.537129370874027e-05, Final Batch Loss: 1.4367998119269032e-05\n",
      "Epoch 3812, Loss: 0.002809849684126675, Final Batch Loss: 0.00042341824155300856\n",
      "Epoch 3813, Loss: 0.0002091528058372205, Final Batch Loss: 0.00018449565686751157\n",
      "Epoch 3814, Loss: 0.0005646204772347119, Final Batch Loss: 0.0005092521314509213\n",
      "Epoch 3815, Loss: 4.140679811825976e-05, Final Batch Loss: 9.47389708016999e-06\n",
      "Epoch 3816, Loss: 0.00028048107833456015, Final Batch Loss: 0.0002666678046807647\n",
      "Epoch 3817, Loss: 0.00016971215609373758, Final Batch Loss: 1.4512895177176688e-05\n",
      "Epoch 3818, Loss: 0.00017672431931714527, Final Batch Loss: 0.00015642169455531985\n",
      "Epoch 3819, Loss: 2.7283362669550115e-05, Final Batch Loss: 2.3295366190723144e-05\n",
      "Epoch 3820, Loss: 4.589603304339107e-05, Final Batch Loss: 1.984477239602711e-05\n",
      "Epoch 3821, Loss: 0.0007094343382050283, Final Batch Loss: 0.0001163659107987769\n",
      "Epoch 3822, Loss: 1.5766222759339144e-05, Final Batch Loss: 3.82858388547902e-07\n",
      "Epoch 3823, Loss: 0.0004450515334610827, Final Batch Loss: 8.146934123942629e-05\n",
      "Epoch 3824, Loss: 0.000270381904556416, Final Batch Loss: 0.00014450319577008486\n",
      "Epoch 3825, Loss: 0.00011200218068552203, Final Batch Loss: 7.273377559613436e-05\n",
      "Epoch 3826, Loss: 2.5798338356253225e-05, Final Batch Loss: 1.3130781553627457e-05\n",
      "Epoch 3827, Loss: 0.0006225228498806246, Final Batch Loss: 3.3099793654400855e-05\n",
      "Epoch 3828, Loss: 2.321371221114532e-05, Final Batch Loss: 1.867794526333455e-05\n",
      "Epoch 3829, Loss: 7.84387084422633e-05, Final Batch Loss: 4.362933759693988e-05\n",
      "Epoch 3830, Loss: 0.0018781299295369536, Final Batch Loss: 0.0015313776675611734\n",
      "Epoch 3831, Loss: 9.391803359903861e-05, Final Batch Loss: 6.657477933913469e-05\n",
      "Epoch 3832, Loss: 6.118918531683448e-05, Final Batch Loss: 5.744919690187089e-05\n",
      "Epoch 3833, Loss: 0.000359424484486226, Final Batch Loss: 0.0002571752993389964\n",
      "Epoch 3834, Loss: 0.00014493697017314844, Final Batch Loss: 4.902329601463862e-05\n",
      "Epoch 3835, Loss: 4.831124260817887e-05, Final Batch Loss: 7.858595381549094e-06\n",
      "Epoch 3836, Loss: 0.0004019085426989477, Final Batch Loss: 0.00035250504151917994\n",
      "Epoch 3837, Loss: 0.00013478187975124456, Final Batch Loss: 9.297153883380815e-05\n",
      "Epoch 3838, Loss: 0.001845057588070631, Final Batch Loss: 3.725942224264145e-05\n",
      "Epoch 3839, Loss: 3.49307802025578e-05, Final Batch Loss: 8.125351996568497e-06\n",
      "Epoch 3840, Loss: 2.117934377565689e-05, Final Batch Loss: 2.6729692308435915e-06\n",
      "Epoch 3841, Loss: 0.00011767508931370685, Final Batch Loss: 0.00010743198072304949\n",
      "Epoch 3842, Loss: 5.103429975861218e-05, Final Batch Loss: 1.9706980310729705e-05\n",
      "Epoch 3843, Loss: 0.0011568813843041426, Final Batch Loss: 0.001143589848652482\n",
      "Epoch 3844, Loss: 0.00012529941159300506, Final Batch Loss: 6.12748772255145e-05\n",
      "Epoch 3845, Loss: 0.00016676800760251353, Final Batch Loss: 5.713317932531936e-06\n",
      "Epoch 3846, Loss: 2.7480477911012713e-05, Final Batch Loss: 1.1050557986891363e-05\n",
      "Epoch 3847, Loss: 2.3700592919340124e-05, Final Batch Loss: 5.619754574581748e-06\n",
      "Epoch 3848, Loss: 0.0025066102534765378, Final Batch Loss: 0.0023609381169080734\n",
      "Epoch 3849, Loss: 1.5138673120418389e-05, Final Batch Loss: 1.8802812746798736e-06\n",
      "Epoch 3850, Loss: 5.183395023777848e-05, Final Batch Loss: 1.1376453585398849e-05\n",
      "Epoch 3851, Loss: 7.203447785286698e-05, Final Batch Loss: 5.6497105106245726e-05\n",
      "Epoch 3852, Loss: 0.00014153655820337008, Final Batch Loss: 2.680684247025056e-06\n",
      "Epoch 3853, Loss: 0.0009703146215542802, Final Batch Loss: 1.2279212569410447e-05\n",
      "Epoch 3854, Loss: 0.00016745121456551715, Final Batch Loss: 4.41066868006601e-06\n",
      "Epoch 3855, Loss: 0.0025783469282032456, Final Batch Loss: 0.0025348749477416277\n",
      "Epoch 3856, Loss: 0.00013882283133170858, Final Batch Loss: 3.5059103993262397e-06\n",
      "Epoch 3857, Loss: 0.0014866263263684232, Final Batch Loss: 1.5261688531609252e-05\n",
      "Epoch 3858, Loss: 9.085074634640478e-05, Final Batch Loss: 5.050099207437597e-05\n",
      "Epoch 3859, Loss: 0.00035916718661610503, Final Batch Loss: 0.00033994539990089834\n",
      "Epoch 3860, Loss: 1.3868986570741981e-05, Final Batch Loss: 5.366116965888068e-06\n",
      "Epoch 3861, Loss: 0.0010038834298029542, Final Batch Loss: 9.420560672879219e-05\n",
      "Epoch 3862, Loss: 0.0032306365683325566, Final Batch Loss: 0.003162718378007412\n",
      "Epoch 3863, Loss: 0.0010016785563493613, Final Batch Loss: 2.227657023468055e-05\n",
      "Epoch 3864, Loss: 0.0015167598767220625, Final Batch Loss: 0.0015118180308490992\n",
      "Epoch 3865, Loss: 2.6199477133559412e-05, Final Batch Loss: 2.1126377305336064e-06\n",
      "Epoch 3866, Loss: 3.118971176263585e-05, Final Batch Loss: 2.9852730222046375e-05\n",
      "Epoch 3867, Loss: 9.763658545125509e-05, Final Batch Loss: 5.365488505049143e-06\n",
      "Epoch 3868, Loss: 0.0003241117256038706, Final Batch Loss: 0.00031221547396853566\n",
      "Epoch 3869, Loss: 0.0031809853498998564, Final Batch Loss: 0.0031597802881151438\n",
      "Epoch 3870, Loss: 1.4678492334496696e-05, Final Batch Loss: 9.93954836303601e-06\n",
      "Epoch 3871, Loss: 0.002028617034739, Final Batch Loss: 1.1839396393042989e-05\n",
      "Epoch 3872, Loss: 4.561373316391837e-05, Final Batch Loss: 3.674647814477794e-05\n",
      "Epoch 3873, Loss: 5.980384980830422e-05, Final Batch Loss: 2.3317991235671798e-06\n",
      "Epoch 3874, Loss: 0.00014379640879269573, Final Batch Loss: 3.976092102675466e-06\n",
      "Epoch 3875, Loss: 7.769853681338645e-06, Final Batch Loss: 7.3373689701838885e-06\n",
      "Epoch 3876, Loss: 0.002468456979840994, Final Batch Loss: 0.0018645364325493574\n",
      "Epoch 3877, Loss: 0.0008838195899443235, Final Batch Loss: 0.0008567675831727684\n",
      "Epoch 3878, Loss: 0.0013421092030512227, Final Batch Loss: 7.616853054059902e-06\n",
      "Epoch 3879, Loss: 0.00022745691967429593, Final Batch Loss: 0.00011290539259789512\n",
      "Epoch 3880, Loss: 1.8496931488698465e-05, Final Batch Loss: 1.5257646737154573e-05\n",
      "Epoch 3881, Loss: 4.8303867515642196e-05, Final Batch Loss: 1.049024285748601e-05\n",
      "Epoch 3882, Loss: 6.14645832683891e-05, Final Batch Loss: 1.491982038714923e-05\n",
      "Epoch 3883, Loss: 0.000561823854695831, Final Batch Loss: 1.5618470570188947e-06\n",
      "Epoch 3884, Loss: 2.807827968354104e-05, Final Batch Loss: 2.464581666572485e-05\n",
      "Epoch 3885, Loss: 5.468408562592231e-05, Final Batch Loss: 3.895525151165202e-05\n",
      "Epoch 3886, Loss: 2.983595823025098e-05, Final Batch Loss: 2.0318469978519715e-05\n",
      "Epoch 3887, Loss: 0.0005291821726132184, Final Batch Loss: 0.00019445540965534747\n",
      "Epoch 3888, Loss: 0.0017388189808116294, Final Batch Loss: 3.609425766626373e-05\n",
      "Epoch 3889, Loss: 7.265399472089484e-05, Final Batch Loss: 5.277588206809014e-05\n",
      "Epoch 3890, Loss: 1.3324753126653377e-05, Final Batch Loss: 1.0670618394215126e-05\n",
      "Epoch 3891, Loss: 7.982603790424037e-06, Final Batch Loss: 7.670754712307826e-06\n",
      "Epoch 3892, Loss: 8.818965943646617e-05, Final Batch Loss: 8.337114559253678e-05\n",
      "Epoch 3893, Loss: 4.946124681737274e-05, Final Batch Loss: 1.3242217391962186e-05\n",
      "Epoch 3894, Loss: 0.0002503416849322093, Final Batch Loss: 0.0002434334164718166\n",
      "Epoch 3895, Loss: 0.00013819270884596335, Final Batch Loss: 2.8329907308943802e-06\n",
      "Epoch 3896, Loss: 0.00500359258694516, Final Batch Loss: 0.004980109632015228\n",
      "Epoch 3897, Loss: 1.983238371394691e-05, Final Batch Loss: 4.562411504593911e-06\n",
      "Epoch 3898, Loss: 3.612879390857415e-05, Final Batch Loss: 1.2749539564538281e-05\n",
      "Epoch 3899, Loss: 1.4756267432858294e-05, Final Batch Loss: 1.3753538951277733e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3900, Loss: 2.8850523449364118e-05, Final Batch Loss: 3.3949618227779865e-06\n",
      "Epoch 3901, Loss: 3.0088222956692334e-05, Final Batch Loss: 2.077344834106043e-05\n",
      "Epoch 3902, Loss: 0.0001858010236901464, Final Batch Loss: 0.00016724913439247757\n",
      "Epoch 3903, Loss: 0.0001374228268105071, Final Batch Loss: 5.412802784121595e-05\n",
      "Epoch 3904, Loss: 0.00010947730334009975, Final Batch Loss: 3.031888627447188e-05\n",
      "Epoch 3905, Loss: 0.004582143216794066, Final Batch Loss: 9.462065463594627e-06\n",
      "Epoch 3906, Loss: 9.255028999177739e-05, Final Batch Loss: 2.8410853701643646e-05\n",
      "Epoch 3907, Loss: 6.903082976350561e-05, Final Batch Loss: 4.589174932334572e-05\n",
      "Epoch 3908, Loss: 4.161563720117556e-05, Final Batch Loss: 9.84105372481281e-06\n",
      "Epoch 3909, Loss: 0.0004205425539112184, Final Batch Loss: 9.523009794065729e-06\n",
      "Epoch 3910, Loss: 1.97328715785261e-05, Final Batch Loss: 3.0025109936104855e-06\n",
      "Epoch 3911, Loss: 0.00022115436877356842, Final Batch Loss: 0.00015683520177844912\n",
      "Epoch 3912, Loss: 0.0007364294433500618, Final Batch Loss: 0.00042184253106825054\n",
      "Epoch 3913, Loss: 4.579716986086169e-06, Final Batch Loss: 1.2268908733403805e-07\n",
      "Epoch 3914, Loss: 0.0008862760639658518, Final Batch Loss: 3.0209682790882653e-06\n",
      "Epoch 3915, Loss: 0.00012916497325932141, Final Batch Loss: 1.6447744201286696e-05\n",
      "Epoch 3916, Loss: 5.997016705805436e-05, Final Batch Loss: 5.662886906065978e-05\n",
      "Epoch 3917, Loss: 8.284916839329526e-05, Final Batch Loss: 6.683323590550572e-06\n",
      "Epoch 3918, Loss: 0.0001439760171706439, Final Batch Loss: 1.2186800631752703e-05\n",
      "Epoch 3919, Loss: 1.0806156979015213e-05, Final Batch Loss: 1.050224682330736e-06\n",
      "Epoch 3920, Loss: 0.0010434761982196505, Final Batch Loss: 9.693078482087003e-07\n",
      "Epoch 3921, Loss: 0.00013523231382350787, Final Batch Loss: 4.693921709986171e-06\n",
      "Epoch 3922, Loss: 3.603284312703181e-05, Final Batch Loss: 1.9624572814791463e-05\n",
      "Epoch 3923, Loss: 6.112334858698887e-05, Final Batch Loss: 1.0371663847763557e-06\n",
      "Epoch 3924, Loss: 4.328250270191347e-05, Final Batch Loss: 3.6770437873201445e-05\n",
      "Epoch 3925, Loss: 6.116418990131933e-05, Final Batch Loss: 3.354344153194688e-05\n",
      "Epoch 3926, Loss: 0.0012385513364279177, Final Batch Loss: 9.587613021722063e-06\n",
      "Epoch 3927, Loss: 5.6530428992118686e-05, Final Batch Loss: 7.998445653356612e-06\n",
      "Epoch 3928, Loss: 4.268012389729847e-05, Final Batch Loss: 5.585429335042136e-06\n",
      "Epoch 3929, Loss: 5.790368322777795e-05, Final Batch Loss: 1.4232381545298267e-05\n",
      "Epoch 3930, Loss: 0.007648415195717462, Final Batch Loss: 3.014023377545527e-06\n",
      "Epoch 3931, Loss: 1.1910130979231326e-05, Final Batch Loss: 4.231984803482192e-06\n",
      "Epoch 3932, Loss: 2.8089064471714664e-05, Final Batch Loss: 2.0682073227362707e-05\n",
      "Epoch 3933, Loss: 6.632103122683475e-06, Final Batch Loss: 5.4257302508631255e-06\n",
      "Epoch 3934, Loss: 8.680610335431993e-06, Final Batch Loss: 2.074319127132185e-06\n",
      "Epoch 3935, Loss: 8.124147279886529e-05, Final Batch Loss: 5.0338934670435265e-05\n",
      "Epoch 3936, Loss: 4.7059178541530855e-05, Final Batch Loss: 2.271100674988702e-05\n",
      "Epoch 3937, Loss: 0.00019732270357053494, Final Batch Loss: 1.3619544006360229e-05\n",
      "Epoch 3938, Loss: 0.00011618946882663295, Final Batch Loss: 3.40180704370141e-05\n",
      "Epoch 3939, Loss: 6.0982536979281576e-05, Final Batch Loss: 5.8319860727351625e-06\n",
      "Epoch 3940, Loss: 0.006246863340493292, Final Batch Loss: 0.005927022080868483\n",
      "Epoch 3941, Loss: 0.00010276427929056808, Final Batch Loss: 7.013630238361657e-06\n",
      "Epoch 3942, Loss: 3.5326795000401034e-05, Final Batch Loss: 1.2181352531115408e-06\n",
      "Epoch 3943, Loss: 0.0002093049561153748, Final Batch Loss: 1.1198587344551925e-05\n",
      "Epoch 3944, Loss: 4.0847924537956715e-05, Final Batch Loss: 9.535411663819104e-06\n",
      "Epoch 3945, Loss: 0.0001317945636856166, Final Batch Loss: 1.0476280749571742e-06\n",
      "Epoch 3946, Loss: 5.509262052783015e-06, Final Batch Loss: 8.222561405091255e-07\n",
      "Epoch 3947, Loss: 0.0005686842305294704, Final Batch Loss: 0.0005453290068544447\n",
      "Epoch 3948, Loss: 0.0016172800839058254, Final Batch Loss: 7.248178235386149e-07\n",
      "Epoch 3949, Loss: 9.572604176355526e-05, Final Batch Loss: 3.734771962626837e-05\n",
      "Epoch 3950, Loss: 1.6169260362630666e-05, Final Batch Loss: 3.2455844234391407e-07\n",
      "Epoch 3951, Loss: 0.020484120217588497, Final Batch Loss: 3.1736311939312145e-05\n",
      "Epoch 3952, Loss: 0.004115421790629625, Final Batch Loss: 0.002597865415737033\n",
      "Epoch 3953, Loss: 1.8378459571977146e-05, Final Batch Loss: 2.597023922135122e-06\n",
      "Epoch 3954, Loss: 9.332774823178625e-06, Final Batch Loss: 6.16911563611211e-07\n",
      "Epoch 3955, Loss: 0.00034709698240931175, Final Batch Loss: 1.300810367865779e-06\n",
      "Epoch 3956, Loss: 6.602290977753e-05, Final Batch Loss: 5.6327171478187665e-05\n",
      "Epoch 3957, Loss: 1.892606360343052e-05, Final Batch Loss: 7.685768650844693e-06\n",
      "Epoch 3958, Loss: 0.020590255968272686, Final Batch Loss: 0.0020751478150486946\n",
      "Epoch 3959, Loss: 0.0010335778699825937, Final Batch Loss: 4.089657323902429e-08\n",
      "Epoch 3960, Loss: 0.0005966929165879264, Final Batch Loss: 0.00022397648717742413\n",
      "Epoch 3961, Loss: 8.029923009189588e-06, Final Batch Loss: 3.228185221360036e-07\n",
      "Epoch 3962, Loss: 9.337395454167563e-06, Final Batch Loss: 7.82037568569649e-06\n",
      "Epoch 3963, Loss: 0.0001921176344694686, Final Batch Loss: 0.0001825391809688881\n",
      "Epoch 3964, Loss: 7.548133822865566e-06, Final Batch Loss: 7.093239219102543e-06\n",
      "Epoch 3965, Loss: 0.001699158521660138, Final Batch Loss: 5.160058208275586e-06\n",
      "Epoch 3966, Loss: 0.0002202646810474107, Final Batch Loss: 2.0377428882056847e-06\n",
      "Epoch 3967, Loss: 0.0001881531934486702, Final Batch Loss: 0.00013867474626749754\n",
      "Epoch 3968, Loss: 8.403159426961793e-06, Final Batch Loss: 2.453686192893656e-06\n",
      "Epoch 3969, Loss: 3.768251553992741e-05, Final Batch Loss: 1.558626172482036e-05\n",
      "Epoch 3970, Loss: 0.00030600756690546405, Final Batch Loss: 9.369859981234185e-06\n",
      "Epoch 3971, Loss: 2.452366334182443e-05, Final Batch Loss: 5.093336767458823e-06\n",
      "Epoch 3972, Loss: 1.3510283679352142e-05, Final Batch Loss: 8.756038369028829e-06\n",
      "Epoch 3973, Loss: 0.00042718041368061677, Final Batch Loss: 0.00031442404724657536\n",
      "Epoch 3974, Loss: 2.709334330575075e-05, Final Batch Loss: 1.2947435607202351e-05\n",
      "Epoch 3975, Loss: 1.1162231658090604e-05, Final Batch Loss: 6.2199533203965984e-06\n",
      "Epoch 3976, Loss: 9.110639439313672e-05, Final Batch Loss: 1.5747584257042035e-05\n",
      "Epoch 3977, Loss: 0.00026693034305935726, Final Batch Loss: 0.0002374182950006798\n",
      "Epoch 3978, Loss: 5.874064481758978e-05, Final Batch Loss: 9.264245818485506e-06\n",
      "Epoch 3979, Loss: 0.00016068673812696943, Final Batch Loss: 1.2436613360478077e-05\n",
      "Epoch 3980, Loss: 4.3530350922083016e-05, Final Batch Loss: 1.139409050665563e-05\n",
      "Epoch 3981, Loss: 6.252583602872619e-05, Final Batch Loss: 6.0207141359569505e-05\n",
      "Epoch 3982, Loss: 0.0035399490952841006, Final Batch Loss: 0.0035188202746212482\n",
      "Epoch 3983, Loss: 7.490502912332886e-05, Final Batch Loss: 6.746397411916405e-05\n",
      "Epoch 3984, Loss: 0.001141818385804072, Final Batch Loss: 4.044038360007107e-05\n",
      "Epoch 3985, Loss: 2.5431954099985887e-05, Final Batch Loss: 2.068204821625841e-06\n",
      "Epoch 3986, Loss: 0.00012725036140182056, Final Batch Loss: 1.8833630747394636e-05\n",
      "Epoch 3987, Loss: 9.33600531425327e-05, Final Batch Loss: 3.741069303941913e-05\n",
      "Epoch 3988, Loss: 3.2964378817723627e-06, Final Batch Loss: 3.654575095879409e-07\n",
      "Epoch 3989, Loss: 2.019184057644452e-05, Final Batch Loss: 1.3867689631297253e-05\n",
      "Epoch 3990, Loss: 5.551405820369837e-06, Final Batch Loss: 3.6524627375911223e-06\n",
      "Epoch 3991, Loss: 1.6235264411079697e-05, Final Batch Loss: 1.2044483810313977e-05\n",
      "Epoch 3992, Loss: 1.1961972631979734e-05, Final Batch Loss: 7.869503861002158e-06\n",
      "Epoch 3993, Loss: 2.9388679195108125e-05, Final Batch Loss: 2.2986316253081895e-05\n",
      "Epoch 3994, Loss: 0.00011373782399459742, Final Batch Loss: 3.060217932215892e-05\n",
      "Epoch 3995, Loss: 0.0005874533017049544, Final Batch Loss: 0.0005009368760511279\n",
      "Epoch 3996, Loss: 9.6746249255375e-05, Final Batch Loss: 1.9742468793992884e-05\n",
      "Epoch 3997, Loss: 4.7679044655524194e-05, Final Batch Loss: 2.4679773559910245e-05\n",
      "Epoch 3998, Loss: 0.000487948527734261, Final Batch Loss: 0.00048465971485711634\n",
      "Epoch 3999, Loss: 7.441220441251062e-05, Final Batch Loss: 6.28955167485401e-05\n",
      "Epoch 4000, Loss: 0.00018886700127040967, Final Batch Loss: 0.00014738245226908475\n",
      "Epoch 4001, Loss: 6.929628307261737e-05, Final Batch Loss: 9.863911145657767e-06\n",
      "Epoch 4002, Loss: 0.005019165199314557, Final Batch Loss: 7.335059990509762e-07\n",
      "Epoch 4003, Loss: 0.0025413997407213174, Final Batch Loss: 6.926181868038839e-07\n",
      "Epoch 4004, Loss: 1.6848697669047397e-05, Final Batch Loss: 6.726140782120638e-07\n",
      "Epoch 4005, Loss: 2.8565495540533448e-05, Final Batch Loss: 4.1493462958897e-06\n",
      "Epoch 4006, Loss: 0.00010038072018403454, Final Batch Loss: 1.9752137347950338e-07\n",
      "Epoch 4007, Loss: 0.000509919183969032, Final Batch Loss: 0.0003992221609223634\n",
      "Epoch 4008, Loss: 2.109932484017918e-05, Final Batch Loss: 1.4849224498902913e-05\n",
      "Epoch 4009, Loss: 0.0002011134135955217, Final Batch Loss: 0.00019899220205843449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4010, Loss: 4.233104607465066e-05, Final Batch Loss: 1.2564390772240586e-06\n",
      "Epoch 4011, Loss: 3.0481190151476767e-05, Final Batch Loss: 6.28224643151043e-06\n",
      "Epoch 4012, Loss: 0.0009696592605905607, Final Batch Loss: 0.0009514887351542711\n",
      "Epoch 4013, Loss: 2.7684794076776598e-05, Final Batch Loss: 1.210494610859314e-05\n",
      "Epoch 4014, Loss: 6.449295142374467e-05, Final Batch Loss: 4.0245940908789635e-05\n",
      "Epoch 4015, Loss: 0.004825811513001099, Final Batch Loss: 0.00028492059209384024\n",
      "Epoch 4016, Loss: 0.00036763078105650493, Final Batch Loss: 0.00036460880073718727\n",
      "Epoch 4017, Loss: 7.145144991227426e-05, Final Batch Loss: 6.672916788375005e-05\n",
      "Epoch 4018, Loss: 4.8886089643929154e-05, Final Batch Loss: 2.433288136671763e-05\n",
      "Epoch 4019, Loss: 0.0001297107373829931, Final Batch Loss: 5.282781785354018e-06\n",
      "Epoch 4020, Loss: 1.3699574843428763e-05, Final Batch Loss: 1.1833875390721005e-07\n",
      "Epoch 4021, Loss: 1.1713537162449938e-06, Final Batch Loss: 4.5420856054079195e-07\n",
      "Epoch 4022, Loss: 1.8454139990353724e-05, Final Batch Loss: 1.2173188224551268e-05\n",
      "Epoch 4023, Loss: 8.956266719906125e-05, Final Batch Loss: 2.056958692264743e-06\n",
      "Epoch 4024, Loss: 0.0010030512657976942, Final Batch Loss: 0.0009920307202264667\n",
      "Epoch 4025, Loss: 3.7952895581838675e-05, Final Batch Loss: 1.6729438357288018e-05\n",
      "Epoch 4026, Loss: 0.0002852739280569949, Final Batch Loss: 0.0002773985906969756\n",
      "Epoch 4027, Loss: 0.0008604715549154207, Final Batch Loss: 0.00010295082756783813\n",
      "Epoch 4028, Loss: 7.947794927076757e-06, Final Batch Loss: 6.142981305856665e-07\n",
      "Epoch 4029, Loss: 5.326191933363589e-05, Final Batch Loss: 5.1768100092886016e-05\n",
      "Epoch 4030, Loss: 0.0006426240634027636, Final Batch Loss: 5.28545024280902e-06\n",
      "Epoch 4031, Loss: 0.00030420439725276083, Final Batch Loss: 0.0002091224887408316\n",
      "Epoch 4032, Loss: 0.0005981680733384565, Final Batch Loss: 0.0005319796619005501\n",
      "Epoch 4033, Loss: 9.274185003960156e-06, Final Batch Loss: 1.0214955636911327e-06\n",
      "Epoch 4034, Loss: 8.292737538795336e-05, Final Batch Loss: 7.770878437440842e-05\n",
      "Epoch 4035, Loss: 5.2140618208795786e-05, Final Batch Loss: 3.6834248021477833e-05\n",
      "Epoch 4036, Loss: 9.064858090823691e-06, Final Batch Loss: 5.333885155778262e-07\n",
      "Epoch 4037, Loss: 0.000133395180455409, Final Batch Loss: 4.03173326049e-05\n",
      "Epoch 4038, Loss: 5.7628831058309515e-06, Final Batch Loss: 5.631753538182238e-06\n",
      "Epoch 4039, Loss: 5.0637926506169606e-05, Final Batch Loss: 4.1169405449181795e-05\n",
      "Epoch 4040, Loss: 4.730108571493474e-06, Final Batch Loss: 5.447035391625832e-07\n",
      "Epoch 4041, Loss: 5.939086008766026e-06, Final Batch Loss: 1.566146806908364e-06\n",
      "Epoch 4042, Loss: 0.0006322807748802006, Final Batch Loss: 1.7683953046798706e-05\n",
      "Epoch 4043, Loss: 1.955466842673559e-06, Final Batch Loss: 3.47180758808463e-07\n",
      "Epoch 4044, Loss: 0.00019160493229719577, Final Batch Loss: 1.5168780919339042e-05\n",
      "Epoch 4045, Loss: 5.726378549297806e-05, Final Batch Loss: 2.911503725044895e-05\n",
      "Epoch 4046, Loss: 5.9382963399912114e-06, Final Batch Loss: 1.0562888519416447e-06\n",
      "Epoch 4047, Loss: 1.4921408364898525e-05, Final Batch Loss: 5.466063157655299e-06\n",
      "Epoch 4048, Loss: 4.5855831558583304e-06, Final Batch Loss: 2.7590058380155824e-06\n",
      "Epoch 4049, Loss: 3.146042490698164e-05, Final Batch Loss: 1.4721196748723742e-05\n",
      "Epoch 4050, Loss: 3.1423215887116385e-06, Final Batch Loss: 9.962908507077373e-07\n",
      "Epoch 4051, Loss: 3.4161572557422915e-06, Final Batch Loss: 5.229484258961747e-07\n",
      "Epoch 4052, Loss: 0.0001158867835329147, Final Batch Loss: 0.00011279567843303084\n",
      "Epoch 4053, Loss: 3.663341522042174e-05, Final Batch Loss: 3.4348206099821255e-05\n",
      "Epoch 4054, Loss: 0.0004961852523877042, Final Batch Loss: 0.0004958853241987526\n",
      "Epoch 4055, Loss: 0.01462960300591476, Final Batch Loss: 2.518869905543397e-06\n",
      "Epoch 4056, Loss: 5.322509605321102e-05, Final Batch Loss: 2.9287833967828192e-05\n",
      "Epoch 4057, Loss: 5.611904202851292e-05, Final Batch Loss: 5.324796075001359e-05\n",
      "Epoch 4058, Loss: 1.888774340841337e-05, Final Batch Loss: 1.4869912774884142e-05\n",
      "Epoch 4059, Loss: 0.00034232745974804857, Final Batch Loss: 0.0003359525289852172\n",
      "Epoch 4060, Loss: 3.6614209193430725e-06, Final Batch Loss: 1.9673004771902924e-06\n",
      "Epoch 4061, Loss: 0.00032870650011318503, Final Batch Loss: 0.0003248038701713085\n",
      "Epoch 4062, Loss: 0.0019453774651765343, Final Batch Loss: 2.149239435311756e-07\n",
      "Epoch 4063, Loss: 0.00013702292380912695, Final Batch Loss: 2.2386348064173944e-05\n",
      "Epoch 4064, Loss: 2.678800183275598e-05, Final Batch Loss: 2.0445486370590515e-05\n",
      "Epoch 4065, Loss: 0.00031514230272478017, Final Batch Loss: 1.7549630229041213e-06\n",
      "Epoch 4066, Loss: 0.0017675229219094035, Final Batch Loss: 0.0017586273606866598\n",
      "Epoch 4067, Loss: 0.0005708412967280196, Final Batch Loss: 3.74160364913223e-08\n",
      "Epoch 4068, Loss: 0.002099797492974176, Final Batch Loss: 2.1594019017356914e-06\n",
      "Epoch 4069, Loss: 0.00036912674113409594, Final Batch Loss: 7.326569902943447e-05\n",
      "Epoch 4070, Loss: 5.263618197659525e-05, Final Batch Loss: 5.091695493320003e-05\n",
      "Epoch 4071, Loss: 0.0002219989983132109, Final Batch Loss: 0.00015011087816674262\n",
      "Epoch 4072, Loss: 0.00011151384205732029, Final Batch Loss: 8.401900413446128e-05\n",
      "Epoch 4073, Loss: 0.0007701517024543136, Final Batch Loss: 0.0003384906449355185\n",
      "Epoch 4074, Loss: 7.150748388085049e-06, Final Batch Loss: 5.390985279518645e-06\n",
      "Epoch 4075, Loss: 0.00012016562277494813, Final Batch Loss: 0.00011530044139362872\n",
      "Epoch 4076, Loss: 0.0006902963086758973, Final Batch Loss: 1.2791149856639095e-05\n",
      "Epoch 4077, Loss: 0.00019315165081934538, Final Batch Loss: 2.033431883319281e-06\n",
      "Epoch 4078, Loss: 0.0003973161510657519, Final Batch Loss: 0.00021488629863597453\n",
      "Epoch 4079, Loss: 0.001035634777508676, Final Batch Loss: 0.0005197608843445778\n",
      "Epoch 4080, Loss: 0.0006285045092226937, Final Batch Loss: 0.00017114476941060275\n",
      "Epoch 4081, Loss: 3.3745511416327645e-06, Final Batch Loss: 2.1405296024568088e-07\n",
      "Epoch 4082, Loss: 5.447394249813442e-05, Final Batch Loss: 5.185913209970749e-07\n",
      "Epoch 4083, Loss: 2.1227520051070314e-05, Final Batch Loss: 1.6035929775171098e-06\n",
      "Epoch 4084, Loss: 9.286246381634555e-06, Final Batch Loss: 1.1189612223461154e-06\n",
      "Epoch 4085, Loss: 1.1699730379177709e-05, Final Batch Loss: 1.1392652595532127e-05\n",
      "Epoch 4086, Loss: 7.036869556031888e-05, Final Batch Loss: 4.614302270056214e-06\n",
      "Epoch 4087, Loss: 0.0012804534735550988, Final Batch Loss: 0.0012677322374656796\n",
      "Epoch 4088, Loss: 0.00016643234721414046, Final Batch Loss: 0.00016207725275307894\n",
      "Epoch 4089, Loss: 0.0006917621334423529, Final Batch Loss: 1.0232300837742514e-06\n",
      "Epoch 4090, Loss: 8.966248969954904e-06, Final Batch Loss: 5.4618303693132475e-06\n",
      "Epoch 4091, Loss: 3.380465440727676e-05, Final Batch Loss: 3.3502823498565704e-05\n",
      "Epoch 4092, Loss: 0.0003544683786458336, Final Batch Loss: 1.6509256965946406e-05\n",
      "Epoch 4093, Loss: 0.00012965137341325317, Final Batch Loss: 1.5757183291498222e-06\n",
      "Epoch 4094, Loss: 4.184072395219118e-06, Final Batch Loss: 1.974119868464186e-06\n",
      "Epoch 4095, Loss: 0.00019687618987518363, Final Batch Loss: 4.64274016849231e-05\n",
      "Epoch 4096, Loss: 1.8656766769709066e-05, Final Batch Loss: 1.3879238395020366e-05\n",
      "Epoch 4097, Loss: 0.00023951076809680671, Final Batch Loss: 7.2579955485707615e-06\n",
      "Epoch 4098, Loss: 0.00035107412259094417, Final Batch Loss: 0.00014029159501660615\n",
      "Epoch 4099, Loss: 2.752559578311775e-05, Final Batch Loss: 1.2581500641317689e-06\n",
      "Epoch 4100, Loss: 2.261337272102537e-06, Final Batch Loss: 1.392097487951105e-06\n",
      "Epoch 4101, Loss: 1.506776101223295e-06, Final Batch Loss: 1.310319930780679e-06\n",
      "Epoch 4102, Loss: 0.0027706548096375627, Final Batch Loss: 3.225821046726196e-06\n",
      "Epoch 4103, Loss: 1.455345864087576e-05, Final Batch Loss: 1.1686851394188125e-05\n",
      "Epoch 4104, Loss: 2.0233614577591652e-05, Final Batch Loss: 1.4920390640327241e-05\n",
      "Epoch 4105, Loss: 1.211505190212847e-05, Final Batch Loss: 5.098849555906781e-07\n",
      "Epoch 4106, Loss: 1.8641468528812766e-06, Final Batch Loss: 1.8098866405580338e-07\n",
      "Epoch 4107, Loss: 1.5887422364357917e-05, Final Batch Loss: 1.4903334886184894e-05\n",
      "Epoch 4108, Loss: 6.117488555901218e-05, Final Batch Loss: 4.362839536042884e-05\n",
      "Epoch 4109, Loss: 3.0919743494450813e-06, Final Batch Loss: 1.098959273804212e-06\n",
      "Epoch 4110, Loss: 0.0009318251750300988, Final Batch Loss: 4.043081389681902e-06\n",
      "Epoch 4111, Loss: 3.4001096537394915e-05, Final Batch Loss: 1.9630671886261553e-05\n",
      "Epoch 4112, Loss: 1.1980907288489107e-05, Final Batch Loss: 8.422856581091764e-07\n",
      "Epoch 4113, Loss: 0.0001939436733664479, Final Batch Loss: 0.00014447460125666112\n",
      "Epoch 4114, Loss: 0.00044735123810824007, Final Batch Loss: 0.00022196776990313083\n",
      "Epoch 4115, Loss: 7.609505246364279e-06, Final Batch Loss: 5.197468453843612e-06\n",
      "Epoch 4116, Loss: 9.835796299739741e-05, Final Batch Loss: 8.461743709631264e-05\n",
      "Epoch 4117, Loss: 9.358844545204192e-05, Final Batch Loss: 5.7334033044753596e-05\n",
      "Epoch 4118, Loss: 0.00012527258513728157, Final Batch Loss: 1.0486655810382217e-05\n",
      "Epoch 4119, Loss: 0.0005476598425957491, Final Batch Loss: 1.5151538718782831e-05\n",
      "Epoch 4120, Loss: 8.492748384014703e-05, Final Batch Loss: 3.670914884423837e-05\n",
      "Epoch 4121, Loss: 0.001722573137612926, Final Batch Loss: 6.795579338358948e-06\n",
      "Epoch 4122, Loss: 0.0004955634212819859, Final Batch Loss: 0.00015181167691480368\n",
      "Epoch 4123, Loss: 1.65063042913971e-05, Final Batch Loss: 4.31974649472977e-06\n",
      "Epoch 4124, Loss: 0.0006819284685946059, Final Batch Loss: 3.245591244649404e-07\n",
      "Epoch 4125, Loss: 9.741249414219055e-06, Final Batch Loss: 5.033132765674964e-06\n",
      "Epoch 4126, Loss: 0.002256261148431804, Final Batch Loss: 1.7758655303623527e-05\n",
      "Epoch 4127, Loss: 1.035427874285233e-05, Final Batch Loss: 8.602915841038339e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4128, Loss: 8.105968663585372e-05, Final Batch Loss: 4.605056528816931e-05\n",
      "Epoch 4129, Loss: 0.0008430032585238223, Final Batch Loss: 0.0008314871811307967\n",
      "Epoch 4130, Loss: 0.00011213756079087034, Final Batch Loss: 1.3826589565724134e-05\n",
      "Epoch 4131, Loss: 8.628116120235063e-06, Final Batch Loss: 7.530944458267186e-06\n",
      "Epoch 4132, Loss: 0.00011920430097234203, Final Batch Loss: 1.4437561731028836e-05\n",
      "Epoch 4133, Loss: 0.0004942349075918173, Final Batch Loss: 3.1938577649270883e-06\n",
      "Epoch 4134, Loss: 9.00387425417648e-06, Final Batch Loss: 7.378616260211857e-07\n",
      "Epoch 4135, Loss: 2.266122601213283e-05, Final Batch Loss: 1.9883931599906646e-05\n",
      "Epoch 4136, Loss: 6.02263753535226e-06, Final Batch Loss: 2.945031155832112e-06\n",
      "Epoch 4137, Loss: 5.846175281476462e-05, Final Batch Loss: 9.801792657526676e-06\n",
      "Epoch 4138, Loss: 8.277384040411562e-06, Final Batch Loss: 3.439070951571921e-06\n",
      "Epoch 4139, Loss: 4.033079187593103e-05, Final Batch Loss: 3.925888449884951e-05\n",
      "Epoch 4140, Loss: 7.360536983469501e-05, Final Batch Loss: 1.6771300579421222e-05\n",
      "Epoch 4141, Loss: 3.27870197907032e-05, Final Batch Loss: 4.8262622840411495e-06\n",
      "Epoch 4142, Loss: 0.0001545161212561652, Final Batch Loss: 4.6570370614062995e-05\n",
      "Epoch 4143, Loss: 4.310955227992963e-05, Final Batch Loss: 3.19370228680782e-05\n",
      "Epoch 4144, Loss: 2.7999294047731382e-05, Final Batch Loss: 1.3408401855485863e-06\n",
      "Epoch 4145, Loss: 0.0010308438071433557, Final Batch Loss: 7.848578889024793e-07\n",
      "Epoch 4146, Loss: 0.00014589314378099516, Final Batch Loss: 0.0001267804327653721\n",
      "Epoch 4147, Loss: 0.0032761854363343446, Final Batch Loss: 0.0032661238219588995\n",
      "Epoch 4148, Loss: 5.3238570671965135e-05, Final Batch Loss: 5.780722403869731e-06\n",
      "Epoch 4149, Loss: 8.404392065131105e-05, Final Batch Loss: 5.72031713090837e-05\n",
      "Epoch 4150, Loss: 0.0004566383618112013, Final Batch Loss: 0.0004517220368143171\n",
      "Epoch 4151, Loss: 9.858190151135204e-05, Final Batch Loss: 9.07943322090432e-05\n",
      "Epoch 4152, Loss: 0.0006825270575063769, Final Batch Loss: 4.474589150049724e-05\n",
      "Epoch 4153, Loss: 0.002501323161595792, Final Batch Loss: 1.4804111742705572e-05\n",
      "Epoch 4154, Loss: 1.8045487081508327e-05, Final Batch Loss: 1.0058655561806518e-06\n",
      "Epoch 4155, Loss: 0.0005391584454628173, Final Batch Loss: 1.0166291758650914e-05\n",
      "Epoch 4156, Loss: 2.8505824047897477e-06, Final Batch Loss: 1.239895368598809e-06\n",
      "Epoch 4157, Loss: 0.00022215285571292043, Final Batch Loss: 0.00018769269809126854\n",
      "Epoch 4158, Loss: 0.00012195430917927297, Final Batch Loss: 9.712702194519807e-06\n",
      "Epoch 4159, Loss: 4.794498977389594e-05, Final Batch Loss: 4.603395427693613e-05\n",
      "Epoch 4160, Loss: 0.0007870557432738678, Final Batch Loss: 5.812448193864839e-07\n",
      "Epoch 4161, Loss: 0.0003455539487617898, Final Batch Loss: 6.987035590100277e-07\n",
      "Epoch 4162, Loss: 0.00015022677121123706, Final Batch Loss: 0.00014862131502013654\n",
      "Epoch 4163, Loss: 4.577688923745882e-05, Final Batch Loss: 2.0864461475866847e-05\n",
      "Epoch 4164, Loss: 3.963752760682837e-06, Final Batch Loss: 1.855912159953732e-06\n",
      "Epoch 4165, Loss: 2.1012376237194985e-05, Final Batch Loss: 3.904297045664862e-06\n",
      "Epoch 4166, Loss: 0.00012749088546115672, Final Batch Loss: 0.0001162386397481896\n",
      "Epoch 4167, Loss: 0.00012841105533212271, Final Batch Loss: 5.307854067382323e-08\n",
      "Epoch 4168, Loss: 1.0218141142104287e-05, Final Batch Loss: 3.0052638066990767e-06\n",
      "Epoch 4169, Loss: 2.3409644200000912e-05, Final Batch Loss: 1.1020901183655951e-05\n",
      "Epoch 4170, Loss: 0.005148393796844175, Final Batch Loss: 0.005116721149533987\n",
      "Epoch 4171, Loss: 6.522365765704308e-06, Final Batch Loss: 4.247534889145754e-06\n",
      "Epoch 4172, Loss: 0.00010072041868625092, Final Batch Loss: 9.967237565433607e-05\n",
      "Epoch 4173, Loss: 0.0002361407023272477, Final Batch Loss: 0.0002324303495697677\n",
      "Epoch 4174, Loss: 5.586018119174696e-06, Final Batch Loss: 9.849790103544365e-07\n",
      "Epoch 4175, Loss: 0.00025893403721966024, Final Batch Loss: 0.00025547639233991504\n",
      "Epoch 4176, Loss: 0.0001001402379188221, Final Batch Loss: 8.765646634856239e-05\n",
      "Epoch 4177, Loss: 0.0002668550502562539, Final Batch Loss: 7.230761980281386e-07\n",
      "Epoch 4178, Loss: 0.0025366450181536493, Final Batch Loss: 0.002527656964957714\n",
      "Epoch 4179, Loss: 1.2141422303102445e-05, Final Batch Loss: 2.1822279450134374e-06\n",
      "Epoch 4180, Loss: 8.809768951323349e-05, Final Batch Loss: 6.86896382831037e-05\n",
      "Epoch 4181, Loss: 3.3003378234752745e-06, Final Batch Loss: 3.4805344739652355e-07\n",
      "Epoch 4182, Loss: 5.511759098908442e-06, Final Batch Loss: 4.272344256150973e-07\n",
      "Epoch 4183, Loss: 5.733451598644024e-05, Final Batch Loss: 5.254357529338449e-05\n",
      "Epoch 4184, Loss: 5.41065323886869e-05, Final Batch Loss: 3.3025912671291735e-06\n",
      "Epoch 4185, Loss: 0.00030378468363778666, Final Batch Loss: 0.00027423721621744335\n",
      "Epoch 4186, Loss: 5.400317348858152e-06, Final Batch Loss: 4.1331051647830463e-07\n",
      "Epoch 4187, Loss: 2.3873999566603743e-05, Final Batch Loss: 8.492353344990988e-07\n",
      "Epoch 4188, Loss: 3.008241310453741e-05, Final Batch Loss: 1.899885137390811e-05\n",
      "Epoch 4189, Loss: 7.139924264265574e-06, Final Batch Loss: 1.2781899840774713e-06\n",
      "Epoch 4190, Loss: 0.0019647354592962074, Final Batch Loss: 0.0019550819415599108\n",
      "Epoch 4191, Loss: 5.642866381094791e-05, Final Batch Loss: 9.055991540662944e-06\n",
      "Epoch 4192, Loss: 1.068941173798521e-05, Final Batch Loss: 7.359496066783322e-06\n",
      "Epoch 4193, Loss: 0.0028935486329828564, Final Batch Loss: 4.852131951338379e-06\n",
      "Epoch 4194, Loss: 0.0007675328815821558, Final Batch Loss: 0.0004760168376378715\n",
      "Epoch 4195, Loss: 0.0023345183726632968, Final Batch Loss: 0.002295187907293439\n",
      "Epoch 4196, Loss: 6.931942698429339e-05, Final Batch Loss: 4.530646401690319e-05\n",
      "Epoch 4197, Loss: 6.053602646716172e-06, Final Batch Loss: 2.5526535409881035e-06\n",
      "Epoch 4198, Loss: 1.638857088437362e-05, Final Batch Loss: 1.2716191122308373e-05\n",
      "Epoch 4199, Loss: 3.143582580378279e-05, Final Batch Loss: 1.0041561836260371e-05\n",
      "Epoch 4200, Loss: 0.00015773296604493225, Final Batch Loss: 2.7822372885566438e-06\n",
      "Epoch 4201, Loss: 0.0001937213437486207, Final Batch Loss: 0.000185319222509861\n",
      "Epoch 4202, Loss: 4.655420889321249e-05, Final Batch Loss: 5.480005711433478e-06\n",
      "Epoch 4203, Loss: 8.846976362519854e-05, Final Batch Loss: 3.558796493052796e-07\n",
      "Epoch 4204, Loss: 0.003584514871818101, Final Batch Loss: 7.4527101787680294e-06\n",
      "Epoch 4205, Loss: 2.6054775389638962e-05, Final Batch Loss: 1.8584587451186962e-05\n",
      "Epoch 4206, Loss: 6.660852250206517e-06, Final Batch Loss: 4.936383447784465e-06\n",
      "Epoch 4207, Loss: 4.002354074827963e-07, Final Batch Loss: 2.8627187020902056e-07\n",
      "Epoch 4208, Loss: 1.0172771453653695e-05, Final Batch Loss: 3.9986234696698375e-06\n",
      "Epoch 4209, Loss: 1.213089308294002e-05, Final Batch Loss: 9.779830179468263e-06\n",
      "Epoch 4210, Loss: 0.008587433924731158, Final Batch Loss: 0.008576225489377975\n",
      "Epoch 4211, Loss: 1.69235794942324e-05, Final Batch Loss: 1.68530077644391e-05\n",
      "Epoch 4212, Loss: 2.882687817873375e-05, Final Batch Loss: 5.481686002895003e-07\n",
      "Epoch 4213, Loss: 3.940613510167168e-06, Final Batch Loss: 2.036752448475454e-06\n",
      "Epoch 4214, Loss: 7.28871273167897e-05, Final Batch Loss: 3.164152803947218e-05\n",
      "Epoch 4215, Loss: 0.0006310548183137143, Final Batch Loss: 7.455890681740129e-06\n",
      "Epoch 4216, Loss: 3.7661248839526706e-05, Final Batch Loss: 1.9752134505779395e-07\n",
      "Epoch 4217, Loss: 0.00016666252122377045, Final Batch Loss: 0.00011034664930775762\n",
      "Epoch 4218, Loss: 2.5960057428164873e-05, Final Batch Loss: 1.3010156180826016e-05\n",
      "Epoch 4219, Loss: 0.00016865970974322408, Final Batch Loss: 5.448178853839636e-05\n",
      "Epoch 4220, Loss: 0.007712965417340456, Final Batch Loss: 8.211522981582675e-06\n",
      "Epoch 4221, Loss: 1.4234782923949751e-05, Final Batch Loss: 2.192740282680461e-07\n",
      "Epoch 4222, Loss: 0.00015486022539334954, Final Batch Loss: 3.6006626942253206e-06\n",
      "Epoch 4223, Loss: 1.5213912405442898e-05, Final Batch Loss: 2.1405375605354493e-07\n",
      "Epoch 4224, Loss: 0.0006277119204582959, Final Batch Loss: 4.1331389866172685e-07\n",
      "Epoch 4225, Loss: 0.005613165459436686, Final Batch Loss: 4.6986977508822747e-07\n",
      "Epoch 4226, Loss: 0.00015935882152007252, Final Batch Loss: 1.083300276150112e-06\n",
      "Epoch 4227, Loss: 5.573440193984425e-05, Final Batch Loss: 4.279738641344011e-05\n",
      "Epoch 4228, Loss: 0.0004569700176944025, Final Batch Loss: 0.0003880722215399146\n",
      "Epoch 4229, Loss: 3.0971219757702784e-06, Final Batch Loss: 2.0524244064290542e-06\n",
      "Epoch 4230, Loss: 1.2785026228812058e-05, Final Batch Loss: 7.602090590808075e-06\n",
      "Epoch 4231, Loss: 0.0005195244302740321, Final Batch Loss: 0.00031173258321359754\n",
      "Epoch 4232, Loss: 0.0028595904877875, Final Batch Loss: 0.002572722267359495\n",
      "Epoch 4233, Loss: 7.122804345272016e-05, Final Batch Loss: 2.3377864636131562e-05\n",
      "Epoch 4234, Loss: 3.58111867626576e-06, Final Batch Loss: 1.411319203725725e-06\n",
      "Epoch 4235, Loss: 0.00012022941882605664, Final Batch Loss: 7.286592153832316e-05\n",
      "Epoch 4236, Loss: 1.4200478176462639e-05, Final Batch Loss: 1.698420305729087e-06\n",
      "Epoch 4237, Loss: 4.4093292444813414e-05, Final Batch Loss: 4.27453123847954e-05\n",
      "Epoch 4238, Loss: 0.00495627720374614, Final Batch Loss: 0.004889356438070536\n",
      "Epoch 4239, Loss: 2.64089885604335e-05, Final Batch Loss: 5.684407369699329e-06\n",
      "Epoch 4240, Loss: 0.00022446187676905538, Final Batch Loss: 0.00022010860266163945\n",
      "Epoch 4241, Loss: 0.00011149196325277444, Final Batch Loss: 8.646724745631218e-05\n",
      "Epoch 4242, Loss: 5.9114328905707225e-05, Final Batch Loss: 2.477052839822136e-05\n",
      "Epoch 4243, Loss: 9.275578486267477e-05, Final Batch Loss: 1.0770090739242733e-05\n",
      "Epoch 4244, Loss: 1.5354260312960832e-05, Final Batch Loss: 2.934759095296613e-06\n",
      "Epoch 4245, Loss: 9.161463594864472e-06, Final Batch Loss: 7.218087375804316e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4246, Loss: 2.0905267774651293e-05, Final Batch Loss: 2.4300798031617887e-06\n",
      "Epoch 4247, Loss: 1.5570853520330274e-05, Final Batch Loss: 5.3151475185586605e-06\n",
      "Epoch 4248, Loss: 0.00017376164396409877, Final Batch Loss: 1.237653850694187e-05\n",
      "Epoch 4249, Loss: 0.00044415632510208525, Final Batch Loss: 2.2608499421039596e-05\n",
      "Epoch 4250, Loss: 0.0010516311108403897, Final Batch Loss: 3.0561882340407465e-06\n",
      "Epoch 4251, Loss: 0.00015234692182275467, Final Batch Loss: 0.00013624178245663643\n",
      "Epoch 4252, Loss: 4.819069431505341e-06, Final Batch Loss: 1.5809831666047103e-06\n",
      "Epoch 4253, Loss: 2.7661866624839604e-05, Final Batch Loss: 1.7061884136637673e-05\n",
      "Epoch 4254, Loss: 0.00011127620018669404, Final Batch Loss: 0.000102226622402668\n",
      "Epoch 4255, Loss: 0.00015162312683969503, Final Batch Loss: 0.0001435010926797986\n",
      "Epoch 4256, Loss: 1.4166150890559948e-05, Final Batch Loss: 1.8254719407195807e-06\n",
      "Epoch 4257, Loss: 0.00012481574867706513, Final Batch Loss: 0.00011638039723038673\n",
      "Epoch 4258, Loss: 1.2208724911033642e-05, Final Batch Loss: 2.0290353859309107e-06\n",
      "Epoch 4259, Loss: 0.0007012603596194822, Final Batch Loss: 3.9280416785913985e-06\n",
      "Epoch 4260, Loss: 1.4060815146876848e-05, Final Batch Loss: 1.1661120879580267e-05\n",
      "Epoch 4261, Loss: 0.0001743019483910757, Final Batch Loss: 0.00017018367361743003\n",
      "Epoch 4262, Loss: 1.627534493309213e-05, Final Batch Loss: 1.1522042768774554e-05\n",
      "Epoch 4263, Loss: 5.211994539422449e-05, Final Batch Loss: 4.426890882314183e-05\n",
      "Epoch 4264, Loss: 8.028712500163238e-06, Final Batch Loss: 2.5441497655265266e-06\n",
      "Epoch 4265, Loss: 3.463949087745277e-05, Final Batch Loss: 2.1046103938715532e-05\n",
      "Epoch 4266, Loss: 0.0002957892430615061, Final Batch Loss: 1.1050735082562824e-07\n",
      "Epoch 4267, Loss: 0.00031276866502594203, Final Batch Loss: 0.000182872885488905\n",
      "Epoch 4268, Loss: 0.0013993545435369015, Final Batch Loss: 0.00040036742575466633\n",
      "Epoch 4269, Loss: 0.00010324780578230275, Final Batch Loss: 1.2900108231406193e-05\n",
      "Epoch 4270, Loss: 0.0001216344790009316, Final Batch Loss: 4.052275471622124e-06\n",
      "Epoch 4271, Loss: 0.00010394562923465855, Final Batch Loss: 8.185790647985414e-06\n",
      "Epoch 4272, Loss: 0.0013813886907882988, Final Batch Loss: 0.0003536842414177954\n",
      "Epoch 4273, Loss: 2.9586156472305447e-05, Final Batch Loss: 6.125656568656268e-07\n",
      "Epoch 4274, Loss: 1.2366952432785183e-05, Final Batch Loss: 5.738370418839622e-06\n",
      "Epoch 4275, Loss: 1.899023550322454e-05, Final Batch Loss: 1.685567076492589e-05\n",
      "Epoch 4276, Loss: 6.318164469121257e-05, Final Batch Loss: 2.318750375707168e-06\n",
      "Epoch 4277, Loss: 0.0007133406652428675, Final Batch Loss: 0.0007071482832543552\n",
      "Epoch 4278, Loss: 1.3687336945622519e-05, Final Batch Loss: 1.2767079169861972e-05\n",
      "Epoch 4279, Loss: 4.7643426910326525e-05, Final Batch Loss: 4.71027015009895e-05\n",
      "Epoch 4280, Loss: 0.000147192673466634, Final Batch Loss: 0.00010826988000189885\n",
      "Epoch 4281, Loss: 0.02303345425752923, Final Batch Loss: 0.022190162912011147\n",
      "Epoch 4282, Loss: 7.31954980892624e-06, Final Batch Loss: 6.499795972558786e-07\n",
      "Epoch 4283, Loss: 0.00015000622443039902, Final Batch Loss: 5.8207213442074135e-05\n",
      "Epoch 4284, Loss: 3.60983597147424e-06, Final Batch Loss: 8.265952828878653e-07\n",
      "Epoch 4285, Loss: 3.419830318307504e-05, Final Batch Loss: 1.259085547644645e-05\n",
      "Epoch 4286, Loss: 0.00013806289049134168, Final Batch Loss: 1.740281363460383e-09\n",
      "Epoch 4287, Loss: 3.759562650884618e-05, Final Batch Loss: 6.622682576562511e-06\n",
      "Epoch 4288, Loss: 6.533225314342417e-05, Final Batch Loss: 7.824150088708848e-06\n",
      "Epoch 4289, Loss: 0.00012305439292958908, Final Batch Loss: 0.00012157965102232993\n",
      "Epoch 4290, Loss: 8.389313643419882e-05, Final Batch Loss: 6.990899237280246e-06\n",
      "Epoch 4291, Loss: 0.02474318287568167, Final Batch Loss: 0.024445945397019386\n",
      "Epoch 4292, Loss: 0.005189230274481815, Final Batch Loss: 0.005172593053430319\n",
      "Epoch 4293, Loss: 0.0002994835000436069, Final Batch Loss: 0.00029833728331141174\n",
      "Epoch 4294, Loss: 0.00541083830432143, Final Batch Loss: 8.092285241900754e-08\n",
      "Epoch 4295, Loss: 0.00090029055809282, Final Batch Loss: 1.6322019291692413e-06\n",
      "Epoch 4296, Loss: 2.158401866836357e-05, Final Batch Loss: 1.410359709552722e-05\n",
      "Epoch 4297, Loss: 8.384284410567489e-05, Final Batch Loss: 3.822808139375411e-06\n",
      "Epoch 4298, Loss: 0.00043254292442895803, Final Batch Loss: 2.314545071158136e-07\n",
      "Epoch 4299, Loss: 6.907960687385639e-05, Final Batch Loss: 4.972097485733684e-06\n",
      "Epoch 4300, Loss: 8.483896390187873e-06, Final Batch Loss: 8.701407372413428e-10\n",
      "Epoch 4301, Loss: 0.052451193713356936, Final Batch Loss: 7.831265413926758e-09\n",
      "Epoch 4302, Loss: 1.8007322566404582e-07, Final Batch Loss: 1.557545630248569e-07\n",
      "Epoch 4303, Loss: 0.0001256747159459337, Final Batch Loss: 0.00012149328540544957\n",
      "Epoch 4304, Loss: 2.1259263576212106e-05, Final Batch Loss: 3.982558610005071e-06\n",
      "Epoch 4305, Loss: 0.0038933884625294013, Final Batch Loss: 0.003877681214362383\n",
      "Epoch 4306, Loss: 0.0002139110356438323, Final Batch Loss: 0.00021157432638574392\n",
      "Epoch 4307, Loss: 2.469657999881747e-06, Final Batch Loss: 2.1759294668299844e-06\n",
      "Epoch 4308, Loss: 3.0722604833499645e-05, Final Batch Loss: 1.5575392353639472e-07\n",
      "Epoch 4309, Loss: 0.0011020191477655317, Final Batch Loss: 1.3586529348685872e-05\n",
      "Epoch 4310, Loss: 8.875980256561888e-06, Final Batch Loss: 4.121734491491225e-06\n",
      "Epoch 4311, Loss: 2.3638504700329577e-06, Final Batch Loss: 2.1273422134981956e-06\n",
      "Epoch 4312, Loss: 0.0005548544932025834, Final Batch Loss: 4.952110430167522e-06\n",
      "Epoch 4313, Loss: 2.347906388422416e-05, Final Batch Loss: 1.9532942587829893e-06\n",
      "Epoch 4314, Loss: 0.0015159300946550047, Final Batch Loss: 3.2716886266825895e-07\n",
      "Epoch 4315, Loss: 0.0006170439446577802, Final Batch Loss: 4.4818807509727776e-05\n",
      "Epoch 4316, Loss: 3.1975288948160596e-05, Final Batch Loss: 1.1748328688554466e-05\n",
      "Epoch 4317, Loss: 1.0316552561562276e-05, Final Batch Loss: 5.7263296184828505e-06\n",
      "Epoch 4318, Loss: 1.2410476927016134e-05, Final Batch Loss: 3.4718203778538737e-07\n",
      "Epoch 4319, Loss: 0.000209556983463699, Final Batch Loss: 3.9581649616593495e-05\n",
      "Epoch 4320, Loss: 1.2703029597105342e-05, Final Batch Loss: 3.081834393015015e-06\n",
      "Epoch 4321, Loss: 8.859498834112856e-06, Final Batch Loss: 6.090975546158006e-08\n",
      "Epoch 4322, Loss: 7.534507403761381e-05, Final Batch Loss: 6.332036718958989e-05\n",
      "Epoch 4323, Loss: 7.387848836515332e-05, Final Batch Loss: 6.536262662848458e-05\n",
      "Epoch 4324, Loss: 0.0017983515572268516, Final Batch Loss: 6.45991531200707e-06\n",
      "Epoch 4325, Loss: 4.149880851400667e-05, Final Batch Loss: 5.3779790505359415e-06\n",
      "Epoch 4326, Loss: 0.0014442873653024435, Final Batch Loss: 0.0001728252973407507\n",
      "Epoch 4327, Loss: 2.49825948230864e-05, Final Batch Loss: 1.2616451385838445e-06\n",
      "Epoch 4328, Loss: 0.0019613722352005425, Final Batch Loss: 0.0019507292890921235\n",
      "Epoch 4329, Loss: 0.002527859661313414, Final Batch Loss: 9.365047844767105e-06\n",
      "Epoch 4330, Loss: 6.789868257328635e-05, Final Batch Loss: 6.503885379061103e-05\n",
      "Epoch 4331, Loss: 8.82178994743299e-06, Final Batch Loss: 1.450456807106093e-06\n",
      "Epoch 4332, Loss: 0.00018607000129122753, Final Batch Loss: 0.00017491324979346246\n",
      "Epoch 4333, Loss: 2.1670063006240525e-05, Final Batch Loss: 1.6618562312942231e-06\n",
      "Epoch 4334, Loss: 0.0005496300676810506, Final Batch Loss: 1.4183241603404895e-07\n",
      "Epoch 4335, Loss: 0.00014227768383534567, Final Batch Loss: 1.3294627478899201e-06\n",
      "Epoch 4336, Loss: 8.343341505678836e-05, Final Batch Loss: 2.188419057347346e-05\n",
      "Epoch 4337, Loss: 5.666399692927371e-05, Final Batch Loss: 2.080330432363553e-06\n",
      "Epoch 4338, Loss: 0.0001479354341427097, Final Batch Loss: 0.00013469578698277473\n",
      "Epoch 4339, Loss: 0.0024834113414726744, Final Batch Loss: 0.0024791222531348467\n",
      "Epoch 4340, Loss: 7.166494697230519e-06, Final Batch Loss: 4.539856035989942e-06\n",
      "Epoch 4341, Loss: 4.368930831333273e-06, Final Batch Loss: 3.356631395945442e-06\n",
      "Epoch 4342, Loss: 8.291129233839456e-06, Final Batch Loss: 1.4347497199196368e-06\n",
      "Epoch 4343, Loss: 0.00013249323637865018, Final Batch Loss: 1.1829330105683766e-05\n",
      "Epoch 4344, Loss: 0.0003678017656056909, Final Batch Loss: 1.5837822502362542e-05\n",
      "Epoch 4345, Loss: 3.288090738351457e-06, Final Batch Loss: 1.6688832147337962e-06\n",
      "Epoch 4346, Loss: 0.0003168316952724126, Final Batch Loss: 0.00030469009652733803\n",
      "Epoch 4347, Loss: 0.0029076998253003694, Final Batch Loss: 0.00010974417818943039\n",
      "Epoch 4348, Loss: 6.42341387901979e-06, Final Batch Loss: 2.9426480523397913e-06\n",
      "Epoch 4349, Loss: 4.751146843773313e-05, Final Batch Loss: 4.792753315996379e-06\n",
      "Epoch 4350, Loss: 0.0007326669040139677, Final Batch Loss: 3.290395625299425e-06\n",
      "Epoch 4351, Loss: 1.2624776445591124e-05, Final Batch Loss: 3.039151579287136e-06\n",
      "Epoch 4352, Loss: 0.001732162752887234, Final Batch Loss: 0.0016639954410493374\n",
      "Epoch 4353, Loss: 3.890340121870395e-05, Final Batch Loss: 1.0133257092093118e-05\n",
      "Epoch 4354, Loss: 0.0002133534171662177, Final Batch Loss: 8.751553650654387e-06\n",
      "Epoch 4355, Loss: 0.00026185476963291876, Final Batch Loss: 0.00022162208915688097\n",
      "Epoch 4356, Loss: 7.99038552941056e-05, Final Batch Loss: 2.410920751572121e-05\n",
      "Epoch 4357, Loss: 1.1993928865194903e-05, Final Batch Loss: 9.52090704231523e-06\n",
      "Epoch 4358, Loss: 0.0001529746878077276, Final Batch Loss: 2.516473614377901e-05\n",
      "Epoch 4359, Loss: 0.0003597802047181631, Final Batch Loss: 4.098315287137666e-07\n",
      "Epoch 4360, Loss: 2.771575111637503e-06, Final Batch Loss: 4.959677539773111e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4361, Loss: 0.0002947941820821143, Final Batch Loss: 1.7114498405135237e-06\n",
      "Epoch 4362, Loss: 0.0028779846707038814, Final Batch Loss: 0.0028626432176679373\n",
      "Epoch 4363, Loss: 4.671617148233054e-06, Final Batch Loss: 9.588633247403777e-07\n",
      "Epoch 4364, Loss: 0.0007101548553691828, Final Batch Loss: 4.161528522672597e-06\n",
      "Epoch 4365, Loss: 3.0966894115636023e-06, Final Batch Loss: 1.6619607379197987e-07\n",
      "Epoch 4366, Loss: 1.2366074997771648e-05, Final Batch Loss: 1.7767354165698634e-06\n",
      "Epoch 4367, Loss: 1.3174576793062442e-05, Final Batch Loss: 6.08208551966527e-07\n",
      "Epoch 4368, Loss: 0.00012394839080798192, Final Batch Loss: 0.00012330229219514877\n",
      "Epoch 4369, Loss: 0.00032293902938818064, Final Batch Loss: 1.5104759540918167e-06\n",
      "Epoch 4370, Loss: 3.077015844610287e-05, Final Batch Loss: 4.922944754071068e-06\n",
      "Epoch 4371, Loss: 1.2307116321608191e-05, Final Batch Loss: 5.602654709946364e-06\n",
      "Epoch 4372, Loss: 3.2010823815653566e-05, Final Batch Loss: 7.415731488435995e-06\n",
      "Epoch 4373, Loss: 3.900769979736651e-05, Final Batch Loss: 1.1032784641429316e-06\n",
      "Epoch 4374, Loss: 3.1822570093709146e-05, Final Batch Loss: 3.106341353031894e-07\n",
      "Epoch 4375, Loss: 3.352865223860135e-05, Final Batch Loss: 2.7388516173232347e-05\n",
      "Epoch 4376, Loss: 0.0008215932280108973, Final Batch Loss: 5.262274044071091e-06\n",
      "Epoch 4377, Loss: 0.0002560235388955334, Final Batch Loss: 0.00024309732543770224\n",
      "Epoch 4378, Loss: 1.335319234385679e-05, Final Batch Loss: 3.5158693663106533e-06\n",
      "Epoch 4379, Loss: 9.003944069263525e-05, Final Batch Loss: 6.960945029277354e-07\n",
      "Epoch 4380, Loss: 4.659572005039081e-05, Final Batch Loss: 3.7731104384874925e-05\n",
      "Epoch 4381, Loss: 0.0001334322714683367, Final Batch Loss: 2.669161585799884e-05\n",
      "Epoch 4382, Loss: 7.021732176326623e-05, Final Batch Loss: 3.1988909086066997e-06\n",
      "Epoch 4383, Loss: 0.00018492977642381447, Final Batch Loss: 0.00017835994367487729\n",
      "Epoch 4384, Loss: 0.002473961536452407, Final Batch Loss: 0.002413718029856682\n",
      "Epoch 4385, Loss: 0.001538880947705934, Final Batch Loss: 0.001538748387247324\n",
      "Epoch 4386, Loss: 3.4766253520501778e-06, Final Batch Loss: 2.1481966996361734e-06\n",
      "Epoch 4387, Loss: 7.951977124776022e-06, Final Batch Loss: 7.605321115988772e-06\n",
      "Epoch 4388, Loss: 0.0023220106945700536, Final Batch Loss: 0.002319576684385538\n",
      "Epoch 4389, Loss: 5.383078269005637e-05, Final Batch Loss: 7.141813966882182e-06\n",
      "Epoch 4390, Loss: 2.892106465424149e-05, Final Batch Loss: 1.5052672779347631e-06\n",
      "Epoch 4391, Loss: 6.024669971793628e-05, Final Batch Loss: 4.768324970427784e-07\n",
      "Epoch 4392, Loss: 4.399979661684483e-05, Final Batch Loss: 7.0229834818746895e-06\n",
      "Epoch 4393, Loss: 1.8152400116377976e-05, Final Batch Loss: 1.703615635051392e-05\n",
      "Epoch 4394, Loss: 1.9623596166695734e-05, Final Batch Loss: 7.657232714564088e-08\n",
      "Epoch 4395, Loss: 1.1825550018329523e-05, Final Batch Loss: 1.1185656148882117e-05\n",
      "Epoch 4396, Loss: 6.266955324463197e-06, Final Batch Loss: 2.9233458462840645e-06\n",
      "Epoch 4397, Loss: 0.018287398820575618, Final Batch Loss: 1.7871761883725412e-06\n",
      "Epoch 4398, Loss: 1.4758974884898635e-05, Final Batch Loss: 1.2843172953580506e-05\n",
      "Epoch 4399, Loss: 0.0006750467127858428, Final Batch Loss: 8.534361768397503e-06\n",
      "Epoch 4400, Loss: 0.0007290660141734406, Final Batch Loss: 0.0005423662369139493\n",
      "Epoch 4401, Loss: 6.765145826648222e-06, Final Batch Loss: 3.8029372717574006e-06\n",
      "Epoch 4402, Loss: 0.00010088157236509687, Final Batch Loss: 3.9068785895324254e-07\n",
      "Epoch 4403, Loss: 0.0001828801059673424, Final Batch Loss: 9.059603144123685e-06\n",
      "Epoch 4404, Loss: 2.2775881006964482e-05, Final Batch Loss: 2.24035102291964e-06\n",
      "Epoch 4405, Loss: 7.035329326754436e-05, Final Batch Loss: 2.5260622351197526e-05\n",
      "Epoch 4406, Loss: 2.217217252109549e-05, Final Batch Loss: 7.3427358984190505e-06\n",
      "Epoch 4407, Loss: 9.604888168723846e-05, Final Batch Loss: 9.264409163733944e-05\n",
      "Epoch 4408, Loss: 0.00040095206512091863, Final Batch Loss: 3.480543284695159e-07\n",
      "Epoch 4409, Loss: 2.5060151983780088e-05, Final Batch Loss: 4.85421014673193e-06\n",
      "Epoch 4410, Loss: 2.859247433661949e-05, Final Batch Loss: 2.182081516366452e-06\n",
      "Epoch 4411, Loss: 9.28625763663149e-06, Final Batch Loss: 6.745448899891926e-06\n",
      "Epoch 4412, Loss: 1.1263950909778941e-05, Final Batch Loss: 4.367987457953859e-06\n",
      "Epoch 4413, Loss: 4.749412687488075e-05, Final Batch Loss: 4.5812899770680815e-05\n",
      "Epoch 4414, Loss: 1.829234133765567e-05, Final Batch Loss: 2.1333435142878443e-06\n",
      "Epoch 4415, Loss: 0.004202286106192332, Final Batch Loss: 7.936124347907025e-06\n",
      "Epoch 4416, Loss: 1.2196231637062738e-05, Final Batch Loss: 9.999570465879515e-06\n",
      "Epoch 4417, Loss: 6.064387434889795e-05, Final Batch Loss: 5.2622977818828076e-05\n",
      "Epoch 4418, Loss: 8.044858805078547e-05, Final Batch Loss: 7.100612856447697e-05\n",
      "Epoch 4419, Loss: 2.3268205495696748e-05, Final Batch Loss: 4.752419499709504e-06\n",
      "Epoch 4420, Loss: 1.0026244808614138e-05, Final Batch Loss: 3.6551743960444583e-06\n",
      "Epoch 4421, Loss: 0.00021476779693330172, Final Batch Loss: 1.3900376870878972e-05\n",
      "Epoch 4422, Loss: 8.416673563260701e-05, Final Batch Loss: 8.196256385417655e-05\n",
      "Epoch 4423, Loss: 0.00011970929881499615, Final Batch Loss: 1.2806622180505656e-05\n",
      "Epoch 4424, Loss: 0.00044076827907701954, Final Batch Loss: 7.855629519326612e-05\n",
      "Epoch 4425, Loss: 1.0888326642088941e-05, Final Batch Loss: 1.119836952057085e-06\n",
      "Epoch 4426, Loss: 9.89696195574652e-06, Final Batch Loss: 7.093345175235299e-06\n",
      "Epoch 4427, Loss: 1.717330451356247e-05, Final Batch Loss: 6.3145544118015096e-06\n",
      "Epoch 4428, Loss: 0.00037791746296989004, Final Batch Loss: 0.00037648796569556\n",
      "Epoch 4429, Loss: 2.6496201371628558e-05, Final Batch Loss: 2.1936062694294378e-05\n",
      "Epoch 4430, Loss: 7.400906815746566e-05, Final Batch Loss: 8.970738235802855e-06\n",
      "Epoch 4431, Loss: 3.598435478124884e-05, Final Batch Loss: 3.525960346451029e-05\n",
      "Epoch 4432, Loss: 1.6241635421465617e-05, Final Batch Loss: 4.848953722103033e-06\n",
      "Epoch 4433, Loss: 4.128483578824671e-05, Final Batch Loss: 1.5143598830036353e-05\n",
      "Epoch 4434, Loss: 0.0004535841371762217, Final Batch Loss: 0.00044451860594563186\n",
      "Epoch 4435, Loss: 1.9982188860012684e-05, Final Batch Loss: 1.8597520465846173e-05\n",
      "Epoch 4436, Loss: 2.6007627639046405e-05, Final Batch Loss: 3.7209183574304916e-06\n",
      "Epoch 4437, Loss: 1.1406210433051456e-05, Final Batch Loss: 7.039075626380509e-06\n",
      "Epoch 4438, Loss: 4.358336354925996e-05, Final Batch Loss: 1.2574134416354354e-05\n",
      "Epoch 4439, Loss: 0.0013075150782242417, Final Batch Loss: 0.00022944773081690073\n",
      "Epoch 4440, Loss: 6.683662877549068e-05, Final Batch Loss: 6.21160288574174e-05\n",
      "Epoch 4441, Loss: 1.144907213301849e-05, Final Batch Loss: 4.019966013402154e-07\n",
      "Epoch 4442, Loss: 0.00011602659469645005, Final Batch Loss: 2.2660684408037923e-05\n",
      "Epoch 4443, Loss: 1.533370650008692e-05, Final Batch Loss: 3.654585611911898e-08\n",
      "Epoch 4444, Loss: 1.806131513149012e-05, Final Batch Loss: 8.53126675792737e-06\n",
      "Epoch 4445, Loss: 6.566452384504373e-06, Final Batch Loss: 2.2933684249437647e-06\n",
      "Epoch 4446, Loss: 1.0502407803869573e-05, Final Batch Loss: 2.314305220352253e-06\n",
      "Epoch 4447, Loss: 3.4449362829036545e-05, Final Batch Loss: 1.0613922313496005e-05\n",
      "Epoch 4448, Loss: 0.0004178587332717143, Final Batch Loss: 0.0003838947741314769\n",
      "Epoch 4449, Loss: 2.2497831650980515e-06, Final Batch Loss: 4.994544724468142e-07\n",
      "Epoch 4450, Loss: 6.731060864240135e-06, Final Batch Loss: 9.136344374383043e-07\n",
      "Epoch 4451, Loss: 0.00010945937901851721, Final Batch Loss: 3.497665238683112e-05\n",
      "Epoch 4452, Loss: 0.0002894053091040405, Final Batch Loss: 3.309475232526893e-06\n",
      "Epoch 4453, Loss: 6.245397571547073e-06, Final Batch Loss: 4.3621143959171604e-06\n",
      "Epoch 4454, Loss: 0.000182377130840905, Final Batch Loss: 7.926285616122186e-05\n",
      "Epoch 4455, Loss: 6.334508270811057e-05, Final Batch Loss: 1.4060175999475177e-05\n",
      "Epoch 4456, Loss: 1.3402654190031171e-05, Final Batch Loss: 1.0667610013115336e-06\n",
      "Epoch 4457, Loss: 6.262313036131673e-05, Final Batch Loss: 1.5718880604254082e-05\n",
      "Epoch 4458, Loss: 0.0001624410506337881, Final Batch Loss: 6.027272320352495e-06\n",
      "Epoch 4459, Loss: 0.0006568674434674904, Final Batch Loss: 3.169207775499672e-05\n",
      "Epoch 4460, Loss: 5.64961942473019e-06, Final Batch Loss: 2.9757954962406075e-06\n",
      "Epoch 4461, Loss: 3.211947023373796e-05, Final Batch Loss: 6.349321665766183e-06\n",
      "Epoch 4462, Loss: 5.2886077810399e-06, Final Batch Loss: 1.3643154943565605e-06\n",
      "Epoch 4463, Loss: 0.000155095968580099, Final Batch Loss: 1.2172939705124008e-06\n",
      "Epoch 4464, Loss: 0.00014702060343552148, Final Batch Loss: 9.124835742113646e-06\n",
      "Epoch 4465, Loss: 1.345441546618531e-05, Final Batch Loss: 1.2717238860204816e-05\n",
      "Epoch 4466, Loss: 6.750227055363212e-05, Final Batch Loss: 6.624733214266598e-05\n",
      "Epoch 4467, Loss: 2.5502785319986288e-05, Final Batch Loss: 1.1074619578721467e-05\n",
      "Epoch 4468, Loss: 3.0398690341826295e-05, Final Batch Loss: 2.6849947971641086e-05\n",
      "Epoch 4469, Loss: 6.858546748844674e-05, Final Batch Loss: 1.1125414857815485e-05\n",
      "Epoch 4470, Loss: 1.096903179131914e-05, Final Batch Loss: 9.540035534882918e-06\n",
      "Epoch 4471, Loss: 0.0014435896882787347, Final Batch Loss: 0.001172209857031703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4472, Loss: 0.000653079041512683, Final Batch Loss: 0.00016356594278477132\n",
      "Epoch 4473, Loss: 0.00010810681669681799, Final Batch Loss: 8.382921078009531e-05\n",
      "Epoch 4474, Loss: 0.0003701043953583394, Final Batch Loss: 4.994564619664743e-07\n",
      "Epoch 4475, Loss: 4.28727778398752e-05, Final Batch Loss: 2.8163428851257777e-06\n",
      "Epoch 4476, Loss: 1.3457532531901961e-05, Final Batch Loss: 7.952044143166859e-06\n",
      "Epoch 4477, Loss: 0.0003176086629537167, Final Batch Loss: 1.3345839761313982e-05\n",
      "Epoch 4478, Loss: 3.698356613313081e-05, Final Batch Loss: 3.023071985808201e-05\n",
      "Epoch 4479, Loss: 0.0014006809656166297, Final Batch Loss: 0.001393970218487084\n",
      "Epoch 4480, Loss: 5.063143862571451e-05, Final Batch Loss: 4.272882051736815e-06\n",
      "Epoch 4481, Loss: 0.000788130786986585, Final Batch Loss: 1.5426089703396428e-06\n",
      "Epoch 4482, Loss: 0.0015039337795315078, Final Batch Loss: 0.0014743591891601682\n",
      "Epoch 4483, Loss: 1.4223209518604563e-05, Final Batch Loss: 2.922571411545505e-06\n",
      "Epoch 4484, Loss: 3.0287601418876875e-05, Final Batch Loss: 2.968298394989688e-05\n",
      "Epoch 4485, Loss: 2.401254459982738e-05, Final Batch Loss: 1.3408930499281269e-05\n",
      "Epoch 4486, Loss: 0.00015911441983007535, Final Batch Loss: 0.00015602506755385548\n",
      "Epoch 4487, Loss: 0.0008062611886998639, Final Batch Loss: 0.000780974340159446\n",
      "Epoch 4488, Loss: 0.0008724323033248993, Final Batch Loss: 1.557545630248569e-07\n",
      "Epoch 4489, Loss: 0.0009258462850993965, Final Batch Loss: 1.3796965504297987e-05\n",
      "Epoch 4490, Loss: 0.0014288579389187817, Final Batch Loss: 0.0014283896889537573\n",
      "Epoch 4491, Loss: 0.00024090921215247363, Final Batch Loss: 0.00023300143948290497\n",
      "Epoch 4492, Loss: 1.5484187770198332e-05, Final Batch Loss: 4.920234914607136e-06\n",
      "Epoch 4493, Loss: 1.5374643652421582e-05, Final Batch Loss: 4.759626506256609e-07\n",
      "Epoch 4494, Loss: 7.730780680503813e-06, Final Batch Loss: 4.527641067397781e-06\n",
      "Epoch 4495, Loss: 3.928435398847796e-05, Final Batch Loss: 1.5331061149481684e-06\n",
      "Epoch 4496, Loss: 2.960501524285064e-05, Final Batch Loss: 2.7545922421268187e-05\n",
      "Epoch 4497, Loss: 0.00019761603198276134, Final Batch Loss: 0.00018654008454177529\n",
      "Epoch 4498, Loss: 3.054809781133372e-06, Final Batch Loss: 9.39728920457128e-07\n",
      "Epoch 4499, Loss: 9.677794059825828e-05, Final Batch Loss: 9.04953558347188e-05\n",
      "Epoch 4500, Loss: 5.507033347385004e-05, Final Batch Loss: 3.4763390431180596e-05\n",
      "Epoch 4501, Loss: 0.0005096319191579823, Final Batch Loss: 5.135470019013155e-06\n",
      "Epoch 4502, Loss: 0.0002668445049494039, Final Batch Loss: 1.8804636056302115e-05\n",
      "Epoch 4503, Loss: 7.348864619416418e-05, Final Batch Loss: 9.898610187519807e-06\n",
      "Epoch 4504, Loss: 0.0007713425657129847, Final Batch Loss: 9.208395931636915e-05\n",
      "Epoch 4505, Loss: 2.602247104732669e-05, Final Batch Loss: 3.8422635952883866e-06\n",
      "Epoch 4506, Loss: 6.127735787231359e-06, Final Batch Loss: 3.819504854618572e-06\n",
      "Epoch 4507, Loss: 4.353052827354986e-05, Final Batch Loss: 2.386657797615044e-06\n",
      "Epoch 4508, Loss: 0.00012858123426440216, Final Batch Loss: 4.951018013343855e-07\n",
      "Epoch 4509, Loss: 2.491806935722707e-05, Final Batch Loss: 2.091693204420153e-06\n",
      "Epoch 4510, Loss: 0.000517064101586584, Final Batch Loss: 5.7095676311291754e-06\n",
      "Epoch 4511, Loss: 0.00029325194986995484, Final Batch Loss: 1.4043259852769552e-06\n",
      "Epoch 4512, Loss: 0.00021680863756046165, Final Batch Loss: 0.00021277036285027862\n",
      "Epoch 4513, Loss: 4.6826398829580285e-06, Final Batch Loss: 2.3620521005796036e-06\n",
      "Epoch 4514, Loss: 0.00023622655828603456, Final Batch Loss: 1.6270129208351136e-06\n",
      "Epoch 4515, Loss: 0.0001596883496404189, Final Batch Loss: 1.958597977136378e-06\n",
      "Epoch 4516, Loss: 1.7691955406462512e-05, Final Batch Loss: 7.013210847617302e-07\n",
      "Epoch 4517, Loss: 1.3270017461763928e-05, Final Batch Loss: 1.6539574971830007e-06\n",
      "Epoch 4518, Loss: 4.2553872845019214e-05, Final Batch Loss: 2.4748442228883505e-05\n",
      "Epoch 4519, Loss: 0.00010176059367950074, Final Batch Loss: 9.25867716432549e-05\n",
      "Epoch 4520, Loss: 0.00014867080881231232, Final Batch Loss: 0.00013670418411493301\n",
      "Epoch 4521, Loss: 9.752683865826839e-06, Final Batch Loss: 5.838531365043309e-07\n",
      "Epoch 4522, Loss: 0.0007802222498867195, Final Batch Loss: 1.0462255886523053e-05\n",
      "Epoch 4523, Loss: 0.006506294076643826, Final Batch Loss: 1.3164890333428048e-06\n",
      "Epoch 4524, Loss: 9.69552615970315e-06, Final Batch Loss: 2.1534663119382458e-06\n",
      "Epoch 4525, Loss: 3.577188499548356e-05, Final Batch Loss: 3.055161505471915e-05\n",
      "Epoch 4526, Loss: 3.819217727141222e-05, Final Batch Loss: 2.6915231501334347e-05\n",
      "Epoch 4527, Loss: 0.0012678888655841547, Final Batch Loss: 6.29972817023372e-07\n",
      "Epoch 4528, Loss: 6.428355231946625e-05, Final Batch Loss: 6.111548282206059e-05\n",
      "Epoch 4529, Loss: 1.3425006955003482e-05, Final Batch Loss: 2.8877504973934265e-06\n",
      "Epoch 4530, Loss: 6.836342299720854e-05, Final Batch Loss: 3.7761442399641965e-06\n",
      "Epoch 4531, Loss: 6.908450956188972e-06, Final Batch Loss: 2.854045817457518e-07\n",
      "Epoch 4532, Loss: 5.398752819019137e-06, Final Batch Loss: 3.4348099688941147e-06\n",
      "Epoch 4533, Loss: 1.2024026545986999e-05, Final Batch Loss: 5.288939064485021e-06\n",
      "Epoch 4534, Loss: 0.00027574510750127956, Final Batch Loss: 4.4845852244179696e-05\n",
      "Epoch 4535, Loss: 5.765862533735344e-05, Final Batch Loss: 4.8981768486555666e-05\n",
      "Epoch 4536, Loss: 0.0002709243508434156, Final Batch Loss: 6.538082743645646e-06\n",
      "Epoch 4537, Loss: 0.0004619004228061385, Final Batch Loss: 0.0004589301533997059\n",
      "Epoch 4538, Loss: 9.245405408364604e-06, Final Batch Loss: 6.935908459126949e-06\n",
      "Epoch 4539, Loss: 8.34973415742013e-06, Final Batch Loss: 2.9584766636503446e-08\n",
      "Epoch 4540, Loss: 6.404515602298488e-07, Final Batch Loss: 2.923640067820088e-07\n",
      "Epoch 4541, Loss: 0.0003708907062787148, Final Batch Loss: 0.000369963760022074\n",
      "Epoch 4542, Loss: 1.2929012427775888e-05, Final Batch Loss: 6.262691840674961e-06\n",
      "Epoch 4543, Loss: 0.004134951232117601, Final Batch Loss: 0.003969590645283461\n",
      "Epoch 4544, Loss: 1.5251666241056228e-06, Final Batch Loss: 1.261700504073815e-07\n",
      "Epoch 4545, Loss: 1.8445334249328482e-05, Final Batch Loss: 1.13118270306245e-08\n",
      "Epoch 4546, Loss: 4.653761334338924e-05, Final Batch Loss: 9.683600183052476e-06\n",
      "Epoch 4547, Loss: 0.0003783329900670651, Final Batch Loss: 3.0052776764932787e-06\n",
      "Epoch 4548, Loss: 2.9003228974033846e-06, Final Batch Loss: 7.935518624435645e-07\n",
      "Epoch 4549, Loss: 1.1725290278263856e-05, Final Batch Loss: 1.0407871741335839e-05\n",
      "Epoch 4550, Loss: 1.8228570525025134e-05, Final Batch Loss: 1.8384919258096488e-06\n",
      "Epoch 4551, Loss: 5.307519927555404e-05, Final Batch Loss: 1.373044824504177e-06\n",
      "Epoch 4552, Loss: 1.0894506203840137e-06, Final Batch Loss: 4.829227009395254e-07\n",
      "Epoch 4553, Loss: 3.19540772579785e-05, Final Batch Loss: 2.6552311283012386e-06\n",
      "Epoch 4554, Loss: 6.312640834948979e-06, Final Batch Loss: 4.2228730308124796e-06\n",
      "Epoch 4555, Loss: 0.00010015551197284367, Final Batch Loss: 8.368607086595148e-05\n",
      "Epoch 4556, Loss: 6.277917111674469e-05, Final Batch Loss: 6.091294198995456e-05\n",
      "Epoch 4557, Loss: 2.72763008979382e-06, Final Batch Loss: 1.0606707974147866e-06\n",
      "Epoch 4558, Loss: 0.0032896717661969888, Final Batch Loss: 0.003286834340542555\n",
      "Epoch 4559, Loss: 0.0006585918154087267, Final Batch Loss: 9.806316484173294e-06\n",
      "Epoch 4560, Loss: 5.5712168432364706e-05, Final Batch Loss: 1.4262151125876699e-05\n",
      "Epoch 4561, Loss: 1.848635838541668e-05, Final Batch Loss: 1.3669305189978331e-06\n",
      "Epoch 4562, Loss: 1.1065890930694877e-05, Final Batch Loss: 2.6397090095997555e-06\n",
      "Epoch 4563, Loss: 0.000522061354786274, Final Batch Loss: 1.8217879187432118e-05\n",
      "Epoch 4564, Loss: 6.511949550258578e-05, Final Batch Loss: 5.373358817450935e-06\n",
      "Epoch 4565, Loss: 7.138775117709883e-05, Final Batch Loss: 6.412225775420666e-05\n",
      "Epoch 4566, Loss: 2.9773943651889567e-05, Final Batch Loss: 2.651588511071168e-05\n",
      "Epoch 4567, Loss: 2.7691082777892007e-05, Final Batch Loss: 5.1334823183424305e-06\n",
      "Epoch 4568, Loss: 3.238801775751199e-05, Final Batch Loss: 9.153719702226226e-07\n",
      "Epoch 4569, Loss: 7.808847294654697e-05, Final Batch Loss: 7.849375833757222e-06\n",
      "Epoch 4570, Loss: 0.001641184000618523, Final Batch Loss: 1.1906169675057754e-05\n",
      "Epoch 4571, Loss: 4.5352525717134995e-06, Final Batch Loss: 3.595926045818487e-06\n",
      "Epoch 4572, Loss: 0.0014201509607119078, Final Batch Loss: 0.0014180177822709084\n",
      "Epoch 4573, Loss: 5.468456947710365e-05, Final Batch Loss: 2.8576385375345126e-05\n",
      "Epoch 4574, Loss: 8.18306637029309e-06, Final Batch Loss: 6.540923550346633e-06\n",
      "Epoch 4575, Loss: 0.00035311383862790535, Final Batch Loss: 0.0003529211971908808\n",
      "Epoch 4576, Loss: 6.667486013611779e-05, Final Batch Loss: 3.374111111043021e-05\n",
      "Epoch 4577, Loss: 0.0008385390210605692, Final Batch Loss: 0.0008104675798676908\n",
      "Epoch 4578, Loss: 1.4592600564355962e-05, Final Batch Loss: 1.2363818314042874e-05\n",
      "Epoch 4579, Loss: 7.372941039029968e-06, Final Batch Loss: 1.4792388647322241e-08\n",
      "Epoch 4580, Loss: 2.1761632524430752e-05, Final Batch Loss: 4.647657988243736e-06\n",
      "Epoch 4581, Loss: 1.5823684901050683e-05, Final Batch Loss: 4.959796839898445e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4582, Loss: 8.911903569241986e-05, Final Batch Loss: 2.676098665688187e-05\n",
      "Epoch 4583, Loss: 1.6756398281358997e-05, Final Batch Loss: 1.1328509117447538e-06\n",
      "Epoch 4584, Loss: 0.0008969204823188193, Final Batch Loss: 0.0008955320226959884\n",
      "Epoch 4585, Loss: 4.783058864177292e-05, Final Batch Loss: 4.6608009142801166e-05\n",
      "Epoch 4586, Loss: 4.931017798526227e-07, Final Batch Loss: 1.583651823011678e-07\n",
      "Epoch 4587, Loss: 1.0211478638666449e-05, Final Batch Loss: 6.834349278506124e-06\n",
      "Epoch 4588, Loss: 0.00025002974985000037, Final Batch Loss: 0.00024752612807787955\n",
      "Epoch 4589, Loss: 3.062097670181174e-05, Final Batch Loss: 2.1057343246866367e-07\n",
      "Epoch 4590, Loss: 5.476728379960605e-05, Final Batch Loss: 1.6010504566565942e-07\n",
      "Epoch 4591, Loss: 6.778050453704054e-05, Final Batch Loss: 1.654870061429392e-06\n",
      "Epoch 4592, Loss: 0.000610807497650967, Final Batch Loss: 0.0005972756189294159\n",
      "Epoch 4593, Loss: 5.055287715549639e-06, Final Batch Loss: 3.77168566956243e-06\n",
      "Epoch 4594, Loss: 5.511908852895431e-06, Final Batch Loss: 4.503423951973673e-06\n",
      "Epoch 4595, Loss: 3.009612953519536e-06, Final Batch Loss: 7.944208277876896e-07\n",
      "Epoch 4596, Loss: 0.0034962865875058924, Final Batch Loss: 1.2103363587812055e-05\n",
      "Epoch 4597, Loss: 2.2239059035200626e-05, Final Batch Loss: 1.3635790310217999e-05\n",
      "Epoch 4598, Loss: 9.090906985420588e-06, Final Batch Loss: 5.273004148875771e-07\n",
      "Epoch 4599, Loss: 0.0009530324314255267, Final Batch Loss: 0.00031559597118757665\n",
      "Epoch 4600, Loss: 3.7333628824853804e-05, Final Batch Loss: 2.0569341359077953e-06\n",
      "Epoch 4601, Loss: 5.767791094513086e-06, Final Batch Loss: 1.2042409025525558e-06\n",
      "Epoch 4602, Loss: 2.2595361883759324e-06, Final Batch Loss: 8.605474590694939e-07\n",
      "Epoch 4603, Loss: 2.7400401449995115e-05, Final Batch Loss: 3.864292011712678e-06\n",
      "Epoch 4604, Loss: 2.16977257423423e-05, Final Batch Loss: 3.4114707432308933e-06\n",
      "Epoch 4605, Loss: 6.489649490504235e-05, Final Batch Loss: 3.061674533455516e-06\n",
      "Epoch 4606, Loss: 0.0002438240044284612, Final Batch Loss: 0.00020824529929086566\n",
      "Epoch 4607, Loss: 9.952677373803454e-06, Final Batch Loss: 6.837487489974592e-06\n",
      "Epoch 4608, Loss: 0.0001527718995930627, Final Batch Loss: 2.6827066903933883e-05\n",
      "Epoch 4609, Loss: 8.66684757738767e-06, Final Batch Loss: 7.039349725346256e-07\n",
      "Epoch 4610, Loss: 0.0002905411352003284, Final Batch Loss: 4.0426498344459105e-06\n",
      "Epoch 4611, Loss: 7.158961352615734e-06, Final Batch Loss: 2.8311467303865356e-06\n",
      "Epoch 4612, Loss: 0.021354951575631276, Final Batch Loss: 3.6342680687084794e-05\n",
      "Epoch 4613, Loss: 1.8651589925866574e-05, Final Batch Loss: 2.13698876905255e-06\n",
      "Epoch 4614, Loss: 1.5016520137578482e-05, Final Batch Loss: 9.882078302325681e-06\n",
      "Epoch 4615, Loss: 7.352522482051427e-05, Final Batch Loss: 1.010208166007942e-06\n",
      "Epoch 4616, Loss: 0.0005277496675262228, Final Batch Loss: 5.955736560281366e-05\n",
      "Epoch 4617, Loss: 7.256501660890535e-06, Final Batch Loss: 1.0615663370572292e-07\n",
      "Epoch 4618, Loss: 0.0006135691085091821, Final Batch Loss: 0.0006101853214204311\n",
      "Epoch 4619, Loss: 1.1137663022964261e-05, Final Batch Loss: 6.268988727242686e-06\n",
      "Epoch 4620, Loss: 1.714983955025673e-05, Final Batch Loss: 5.0557591748656705e-06\n",
      "Epoch 4621, Loss: 0.00012945883963766391, Final Batch Loss: 0.00012328202137723565\n",
      "Epoch 4622, Loss: 0.008365700021386147, Final Batch Loss: 0.008314734324812889\n",
      "Epoch 4623, Loss: 1.772259838617174e-05, Final Batch Loss: 4.10355187341338e-06\n",
      "Epoch 4624, Loss: 1.691921488600201e-05, Final Batch Loss: 6.814213065808872e-06\n",
      "Epoch 4625, Loss: 4.24662647446894e-06, Final Batch Loss: 3.631528443293064e-06\n",
      "Epoch 4626, Loss: 4.0560003981227055e-05, Final Batch Loss: 3.2376159651903436e-05\n",
      "Epoch 4627, Loss: 1.1039123819500674e-05, Final Batch Loss: 7.639195246156305e-06\n",
      "Epoch 4628, Loss: 9.665721859164478e-05, Final Batch Loss: 9.575173316989094e-05\n",
      "Epoch 4629, Loss: 3.0036278985789977e-05, Final Batch Loss: 4.097058990737423e-06\n",
      "Epoch 4630, Loss: 0.0032322833676516893, Final Batch Loss: 0.0032184699084609747\n",
      "Epoch 4631, Loss: 2.4678704903635662e-05, Final Batch Loss: 1.3100472642690875e-05\n",
      "Epoch 4632, Loss: 0.0003202709149263683, Final Batch Loss: 8.333207915711682e-06\n",
      "Epoch 4633, Loss: 5.912728306611825e-05, Final Batch Loss: 2.3579189019073965e-06\n",
      "Epoch 4634, Loss: 0.00025851790280739806, Final Batch Loss: 0.0002576510305516422\n",
      "Epoch 4635, Loss: 6.608497869819985e-06, Final Batch Loss: 1.3521446362574352e-06\n",
      "Epoch 4636, Loss: 1.5840235846553696e-05, Final Batch Loss: 5.394309027906274e-06\n",
      "Epoch 4637, Loss: 0.0003330310687488236, Final Batch Loss: 7.262086455739336e-06\n",
      "Epoch 4638, Loss: 6.8882184223184595e-06, Final Batch Loss: 2.747490952970111e-06\n",
      "Epoch 4639, Loss: 3.913472392014228e-05, Final Batch Loss: 1.8131624528905377e-05\n",
      "Epoch 4640, Loss: 9.647512291621752e-05, Final Batch Loss: 9.022909921441169e-07\n",
      "Epoch 4641, Loss: 1.643720497668255e-05, Final Batch Loss: 3.923839358321857e-06\n",
      "Epoch 4642, Loss: 6.864109036541777e-05, Final Batch Loss: 4.936538061883766e-06\n",
      "Epoch 4643, Loss: 3.856806301882898e-06, Final Batch Loss: 2.6824488941201707e-06\n",
      "Epoch 4644, Loss: 3.4722427699307445e-05, Final Batch Loss: 4.908505616185721e-06\n",
      "Epoch 4645, Loss: 0.00020055613003933104, Final Batch Loss: 7.608386113133747e-06\n",
      "Epoch 4646, Loss: 7.778930250879057e-05, Final Batch Loss: 1.7149019413409405e-06\n",
      "Epoch 4647, Loss: 0.00010239028893010982, Final Batch Loss: 9.994914580602199e-05\n",
      "Epoch 4648, Loss: 2.1718210518884007e-05, Final Batch Loss: 4.931406692776363e-06\n",
      "Epoch 4649, Loss: 4.084257057002105e-06, Final Batch Loss: 1.344319684903894e-06\n",
      "Epoch 4650, Loss: 8.514337059750687e-05, Final Batch Loss: 5.638882066705264e-05\n",
      "Epoch 4651, Loss: 7.96302515482239e-06, Final Batch Loss: 2.3813706775399623e-06\n",
      "Epoch 4652, Loss: 0.0001390664419886889, Final Batch Loss: 0.00012024520401610062\n",
      "Epoch 4653, Loss: 0.001213147334055975, Final Batch Loss: 0.0010763606987893581\n",
      "Epoch 4654, Loss: 0.0015180242460246518, Final Batch Loss: 6.569296147063142e-07\n",
      "Epoch 4655, Loss: 3.5094658557000002e-06, Final Batch Loss: 8.266330553396983e-08\n",
      "Epoch 4656, Loss: 0.0006838487443019403, Final Batch Loss: 0.0006660133367404342\n",
      "Epoch 4657, Loss: 6.195986844659274e-05, Final Batch Loss: 7.482993282792449e-07\n",
      "Epoch 4658, Loss: 0.00042948295322275953, Final Batch Loss: 7.2242664828081615e-06\n",
      "Epoch 4659, Loss: 6.72129408485489e-05, Final Batch Loss: 2.5971805371227674e-05\n",
      "Epoch 4660, Loss: 6.427846983569907e-06, Final Batch Loss: 2.4831956579873804e-06\n",
      "Epoch 4661, Loss: 1.466525418436504e-05, Final Batch Loss: 2.957066044473322e-06\n",
      "Epoch 4662, Loss: 9.517833495920058e-05, Final Batch Loss: 8.896486542653292e-05\n",
      "Epoch 4663, Loss: 1.432583388805142e-05, Final Batch Loss: 6.439034905270091e-08\n",
      "Epoch 4664, Loss: 4.934434855385916e-05, Final Batch Loss: 4.5383152610156685e-05\n",
      "Epoch 4665, Loss: 7.79325928306207e-05, Final Batch Loss: 6.43628227408044e-05\n",
      "Epoch 4666, Loss: 5.974197847535834e-05, Final Batch Loss: 2.098648838000372e-05\n",
      "Epoch 4667, Loss: 4.117941512049583e-05, Final Batch Loss: 3.924998964066617e-05\n",
      "Epoch 4668, Loss: 1.0334586022509029e-05, Final Batch Loss: 4.088268269697437e-06\n",
      "Epoch 4669, Loss: 0.0001238113463841728, Final Batch Loss: 4.608757990354206e-06\n",
      "Epoch 4670, Loss: 0.003826233951258473, Final Batch Loss: 3.4993718145415187e-06\n",
      "Epoch 4671, Loss: 0.00011667736794152006, Final Batch Loss: 0.00011330314009683207\n",
      "Epoch 4672, Loss: 1.5584972743454273e-05, Final Batch Loss: 1.7593008578842273e-06\n",
      "Epoch 4673, Loss: 0.00014556699352397118, Final Batch Loss: 0.00012103623157599941\n",
      "Epoch 4674, Loss: 8.229159448092105e-06, Final Batch Loss: 4.197181624476798e-06\n",
      "Epoch 4675, Loss: 1.3524337873604964e-05, Final Batch Loss: 2.660414565980318e-06\n",
      "Epoch 4676, Loss: 3.4232763027830515e-05, Final Batch Loss: 9.194748599838931e-06\n",
      "Epoch 4677, Loss: 0.00018070915328394221, Final Batch Loss: 2.9932496659057506e-07\n",
      "Epoch 4678, Loss: 1.5562356168175029e-06, Final Batch Loss: 2.5407999260096403e-07\n",
      "Epoch 4679, Loss: 5.182235099709942e-06, Final Batch Loss: 1.6853907709446503e-06\n",
      "Epoch 4680, Loss: 4.515263640314515e-06, Final Batch Loss: 2.6649506708054105e-06\n",
      "Epoch 4681, Loss: 1.556751362841169e-05, Final Batch Loss: 2.3108680125005776e-06\n",
      "Epoch 4682, Loss: 8.051956902122015e-06, Final Batch Loss: 2.1753512768896144e-08\n",
      "Epoch 4683, Loss: 3.169457704643719e-05, Final Batch Loss: 2.130457323801238e-05\n",
      "Epoch 4684, Loss: 0.0006426007416848734, Final Batch Loss: 3.753327746380819e-06\n",
      "Epoch 4685, Loss: 3.688643391797086e-05, Final Batch Loss: 1.120507931773318e-05\n",
      "Epoch 4686, Loss: 3.715101229317952e-06, Final Batch Loss: 1.7054239833669271e-06\n",
      "Epoch 4687, Loss: 4.510531490797831e-05, Final Batch Loss: 1.2181968322977355e-08\n",
      "Epoch 4688, Loss: 0.000632158132702898, Final Batch Loss: 3.2044495128502604e-06\n",
      "Epoch 4689, Loss: 7.489544657346414e-06, Final Batch Loss: 5.029286853641679e-07\n",
      "Epoch 4690, Loss: 1.862975327071581e-05, Final Batch Loss: 1.200790791244799e-07\n",
      "Epoch 4691, Loss: 1.7435556628697668e-05, Final Batch Loss: 1.0180633580603171e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4692, Loss: 8.653160648464109e-06, Final Batch Loss: 8.387685284105828e-07\n",
      "Epoch 4693, Loss: 1.276222121759929e-06, Final Batch Loss: 5.586160796156037e-07\n",
      "Epoch 4694, Loss: 7.074097266013268e-05, Final Batch Loss: 1.746583620843012e-05\n",
      "Epoch 4695, Loss: 2.5372762593178777e-06, Final Batch Loss: 6.229997779882979e-07\n",
      "Epoch 4696, Loss: 1.7610920394872664e-05, Final Batch Loss: 2.7135381515108747e-06\n",
      "Epoch 4697, Loss: 3.008610008237156e-05, Final Batch Loss: 1.7105784309023875e-06\n",
      "Epoch 4698, Loss: 9.972872794605792e-05, Final Batch Loss: 8.197288843803108e-05\n",
      "Epoch 4699, Loss: 0.0005887204206374008, Final Batch Loss: 3.552680209395476e-05\n",
      "Epoch 4700, Loss: 0.000326004814269254, Final Batch Loss: 0.000294949219096452\n",
      "Epoch 4701, Loss: 0.048806556113504485, Final Batch Loss: 0.04879896715283394\n",
      "Epoch 4702, Loss: 3.2127223903444246e-06, Final Batch Loss: 2.2047261154511943e-06\n",
      "Epoch 4703, Loss: 5.1121234719175845e-05, Final Batch Loss: 7.5831630965694785e-06\n",
      "Epoch 4704, Loss: 2.673861288826629e-06, Final Batch Loss: 3.828616002010676e-08\n",
      "Epoch 4705, Loss: 1.2808903420591378e-05, Final Batch Loss: 1.5991447526175762e-06\n",
      "Epoch 4706, Loss: 0.00023121657432056963, Final Batch Loss: 1.6347388736903667e-05\n",
      "Epoch 4707, Loss: 0.00015741285074000189, Final Batch Loss: 3.079690714002936e-06\n",
      "Epoch 4708, Loss: 0.0019474018197342957, Final Batch Loss: 1.7419522464479087e-06\n",
      "Epoch 4709, Loss: 8.836819105795257e-06, Final Batch Loss: 2.1840274655460234e-07\n",
      "Epoch 4710, Loss: 2.4395180275860184e-06, Final Batch Loss: 1.7619627215026412e-06\n",
      "Epoch 4711, Loss: 1.9198504560336005e-05, Final Batch Loss: 7.72610837884713e-06\n",
      "Epoch 4712, Loss: 0.004098160556395669, Final Batch Loss: 0.0040964120998978615\n",
      "Epoch 4713, Loss: 1.9186634290235816e-06, Final Batch Loss: 4.472410637390567e-07\n",
      "Epoch 4714, Loss: 3.553966386959928e-06, Final Batch Loss: 5.7429240030160145e-08\n",
      "Epoch 4715, Loss: 1.6363772317617986e-05, Final Batch Loss: 2.610394744806399e-07\n",
      "Epoch 4716, Loss: 0.006218776805326343, Final Batch Loss: 0.0025747050531208515\n",
      "Epoch 4717, Loss: 3.829607703664806e-05, Final Batch Loss: 6.672378731309436e-06\n",
      "Epoch 4718, Loss: 0.0007838581013857038, Final Batch Loss: 1.0179101991525386e-05\n",
      "Epoch 4719, Loss: 0.05788854953152622, Final Batch Loss: 8.628482646599878e-06\n",
      "Epoch 4720, Loss: 0.0008900855027604848, Final Batch Loss: 0.00030234051519073546\n",
      "Epoch 4721, Loss: 0.013262286083772779, Final Batch Loss: 0.010005335323512554\n",
      "Epoch 4722, Loss: 0.00039642798947170377, Final Batch Loss: 0.00034225269337184727\n",
      "Epoch 4723, Loss: 0.00025377701240358874, Final Batch Loss: 0.00016888542450033128\n",
      "Epoch 4724, Loss: 0.00022243076006134288, Final Batch Loss: 6.769469678147289e-07\n",
      "Epoch 4725, Loss: 8.875689309206791e-05, Final Batch Loss: 5.703498391085304e-05\n",
      "Epoch 4726, Loss: 4.3442377318569925e-05, Final Batch Loss: 4.194531720713712e-05\n",
      "Epoch 4727, Loss: 8.556081002097926e-05, Final Batch Loss: 8.107146277325228e-05\n",
      "Epoch 4728, Loss: 8.883948794391472e-07, Final Batch Loss: 3.071545506827533e-07\n",
      "Epoch 4729, Loss: 4.0841591953721945e-05, Final Batch Loss: 2.7717517241399037e-06\n",
      "Epoch 4730, Loss: 2.9152816459543374e-05, Final Batch Loss: 2.903837594203651e-05\n",
      "Epoch 4731, Loss: 3.048747088030268e-05, Final Batch Loss: 1.9752108926240908e-07\n",
      "Epoch 4732, Loss: 4.3249046473015085e-05, Final Batch Loss: 1.1311828806981339e-08\n",
      "Epoch 4733, Loss: 0.0015204835437998554, Final Batch Loss: 2.7388089165469864e-06\n",
      "Epoch 4734, Loss: 0.0002476920017215889, Final Batch Loss: 0.00020545456209219992\n",
      "Epoch 4735, Loss: 1.6063031438307007e-06, Final Batch Loss: 5.481875575696904e-08\n",
      "Epoch 4736, Loss: 0.00022211262324844938, Final Batch Loss: 5.307701371748408e-07\n",
      "Epoch 4737, Loss: 4.978172114533663e-06, Final Batch Loss: 1.5913209381324123e-06\n",
      "Epoch 4738, Loss: 8.356712896784302e-06, Final Batch Loss: 1.9776048247877043e-06\n",
      "Epoch 4739, Loss: 3.0334542316268198e-05, Final Batch Loss: 2.5783685487112962e-05\n",
      "Epoch 4740, Loss: 5.540368107403992e-06, Final Batch Loss: 3.088977393872483e-07\n",
      "Epoch 4741, Loss: 0.00022647045993906545, Final Batch Loss: 1.9143090668194418e-08\n",
      "Epoch 4742, Loss: 0.009811244516725992, Final Batch Loss: 1.6445582673441095e-07\n",
      "Epoch 4743, Loss: 2.6788477498485008e-05, Final Batch Loss: 4.8649676500645e-06\n",
      "Epoch 4744, Loss: 1.2220688915931532e-05, Final Batch Loss: 1.5662459418308572e-07\n",
      "Epoch 4745, Loss: 1.3340962709662563e-05, Final Batch Loss: 1.1842399771921919e-06\n",
      "Epoch 4746, Loss: 0.00019782406707236078, Final Batch Loss: 1.3526927432394587e-05\n",
      "Epoch 4747, Loss: 0.0006913992547197267, Final Batch Loss: 0.0006843344308435917\n",
      "Epoch 4748, Loss: 0.00011817323593277251, Final Batch Loss: 8.724949111638125e-06\n",
      "Epoch 4749, Loss: 5.436264746094821e-05, Final Batch Loss: 4.507927951635793e-05\n",
      "Epoch 4750, Loss: 5.581835239354405e-06, Final Batch Loss: 1.6287701782857766e-06\n",
      "Epoch 4751, Loss: 2.2942093153233145e-05, Final Batch Loss: 2.2364663891494274e-05\n",
      "Epoch 4752, Loss: 0.00045180798497312935, Final Batch Loss: 4.194157554593403e-06\n",
      "Epoch 4753, Loss: 0.0007205455194707611, Final Batch Loss: 1.4936537809262518e-05\n",
      "Epoch 4754, Loss: 1.412012386481365e-05, Final Batch Loss: 1.9001612372449017e-06\n",
      "Epoch 4755, Loss: 5.7670518799568526e-05, Final Batch Loss: 1.2328839147812687e-05\n",
      "Epoch 4756, Loss: 0.0007570846428279765, Final Batch Loss: 1.652126229600981e-05\n",
      "Epoch 4757, Loss: 8.820922857921687e-06, Final Batch Loss: 6.022724392096279e-06\n",
      "Epoch 4758, Loss: 9.477345926711678e-06, Final Batch Loss: 1.8359791909006162e-07\n",
      "Epoch 4759, Loss: 6.712144454468216e-06, Final Batch Loss: 7.126362788767437e-07\n",
      "Epoch 4760, Loss: 0.002083990412302228, Final Batch Loss: 0.002081702696159482\n",
      "Epoch 4761, Loss: 8.437737415079027e-05, Final Batch Loss: 1.558044459670782e-05\n",
      "Epoch 4762, Loss: 2.9729139441769803e-05, Final Batch Loss: 3.5076395761279855e-06\n",
      "Epoch 4763, Loss: 3.6380642995936796e-05, Final Batch Loss: 2.803166353260167e-05\n",
      "Epoch 4764, Loss: 3.2464835385326296e-05, Final Batch Loss: 1.3441434930427931e-05\n",
      "Epoch 4765, Loss: 1.2097395483579021e-05, Final Batch Loss: 8.027303010749165e-06\n",
      "Epoch 4766, Loss: 2.3122512402551365e-06, Final Batch Loss: 1.6871266552698216e-06\n",
      "Epoch 4767, Loss: 1.2450163922039792e-05, Final Batch Loss: 3.3625992728048004e-06\n",
      "Epoch 4768, Loss: 2.5317014660686255e-05, Final Batch Loss: 1.008164599625161e-05\n",
      "Epoch 4769, Loss: 3.575606933736708e-05, Final Batch Loss: 1.9959770725108683e-05\n",
      "Epoch 4770, Loss: 6.531032522616442e-05, Final Batch Loss: 3.7492271076189354e-05\n",
      "Epoch 4771, Loss: 6.563833835571131e-06, Final Batch Loss: 7.352529109994066e-07\n",
      "Epoch 4772, Loss: 1.580014503588245e-05, Final Batch Loss: 6.97840903285396e-07\n",
      "Epoch 4773, Loss: 0.0009312883485108614, Final Batch Loss: 0.0009044471080414951\n",
      "Epoch 4774, Loss: 0.000227245909627527, Final Batch Loss: 0.00012878589041065425\n",
      "Epoch 4775, Loss: 4.706424806499854e-05, Final Batch Loss: 4.468738552532159e-05\n",
      "Epoch 4776, Loss: 0.0030618322404620812, Final Batch Loss: 9.353595373795542e-07\n",
      "Epoch 4777, Loss: 0.00033835000067483634, Final Batch Loss: 2.0732390112243593e-05\n",
      "Epoch 4778, Loss: 8.22207757664728e-05, Final Batch Loss: 7.869707587815356e-06\n",
      "Epoch 4779, Loss: 4.297663599572843e-05, Final Batch Loss: 1.3707979633181822e-05\n",
      "Epoch 4780, Loss: 3.6664259823737666e-06, Final Batch Loss: 1.0101944099005777e-06\n",
      "Epoch 4781, Loss: 3.512131934257923e-05, Final Batch Loss: 1.0580603884591255e-05\n",
      "Epoch 4782, Loss: 1.303881890635239e-05, Final Batch Loss: 9.954667802958284e-06\n",
      "Epoch 4783, Loss: 0.00042754698370117694, Final Batch Loss: 0.00023914982739370316\n",
      "Epoch 4784, Loss: 0.0006765317825738748, Final Batch Loss: 4.852803158428287e-06\n",
      "Epoch 4785, Loss: 0.0002607482762186919, Final Batch Loss: 7.317736390177743e-07\n",
      "Epoch 4786, Loss: 2.8334749629266298e-05, Final Batch Loss: 2.804864925565198e-05\n",
      "Epoch 4787, Loss: 1.7319935977866407e-05, Final Batch Loss: 8.780321877566166e-06\n",
      "Epoch 4788, Loss: 2.237222906842362e-05, Final Batch Loss: 1.0754481081676204e-05\n",
      "Epoch 4789, Loss: 4.591408105625305e-05, Final Batch Loss: 3.376435051904991e-05\n",
      "Epoch 4790, Loss: 5.932838030275889e-05, Final Batch Loss: 3.933966945623979e-05\n",
      "Epoch 4791, Loss: 1.468143909733044e-05, Final Batch Loss: 1.0917831787082832e-05\n",
      "Epoch 4792, Loss: 2.7611824961581988e-05, Final Batch Loss: 1.8794945333411306e-07\n",
      "Epoch 4793, Loss: 2.9116836230969056e-05, Final Batch Loss: 2.7589609089773148e-05\n",
      "Epoch 4794, Loss: 1.2121166491851909e-05, Final Batch Loss: 7.007940894254716e-06\n",
      "Epoch 4795, Loss: 1.4667117511635297e-05, Final Batch Loss: 1.96818677977717e-06\n",
      "Epoch 4796, Loss: 2.2271509124038857e-05, Final Batch Loss: 1.9721355783985928e-05\n",
      "Epoch 4797, Loss: 3.2539718120006e-05, Final Batch Loss: 3.1941297493176535e-05\n",
      "Epoch 4798, Loss: 1.8395904589851853e-05, Final Batch Loss: 5.427017640613485e-06\n",
      "Epoch 4799, Loss: 0.00010003140081948914, Final Batch Loss: 2.314558003035927e-07\n",
      "Epoch 4800, Loss: 0.08808365906224935, Final Batch Loss: 0.08807532489299774\n",
      "Epoch 4801, Loss: 6.158386804600013e-05, Final Batch Loss: 2.6319494281779043e-06\n",
      "Epoch 4802, Loss: 3.4386762308713514e-06, Final Batch Loss: 1.685398615336453e-06\n",
      "Epoch 4803, Loss: 0.00027508573703016737, Final Batch Loss: 5.552747552428627e-06\n",
      "Epoch 4804, Loss: 4.056261332152644e-05, Final Batch Loss: 1.391335990774678e-05\n",
      "Epoch 4805, Loss: 0.0004122871541767381, Final Batch Loss: 0.00037429973599500954\n",
      "Epoch 4806, Loss: 6.384109065038501e-05, Final Batch Loss: 5.7505483709974214e-05\n",
      "Epoch 4807, Loss: 0.000579542902414687, Final Batch Loss: 0.000519791676197201\n",
      "Epoch 4808, Loss: 1.9577721104724333e-05, Final Batch Loss: 1.4059812201594468e-05\n",
      "Epoch 4809, Loss: 1.46045981637144e-05, Final Batch Loss: 1.1015731615771074e-06\n",
      "Epoch 4810, Loss: 6.412509173969738e-05, Final Batch Loss: 3.336186273372732e-05\n",
      "Epoch 4811, Loss: 0.00012764469283865765, Final Batch Loss: 4.721462755696848e-05\n",
      "Epoch 4812, Loss: 0.0012408237816998735, Final Batch Loss: 0.001108106691390276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4813, Loss: 0.0011406005924072815, Final Batch Loss: 2.517882785468828e-05\n",
      "Epoch 4814, Loss: 0.00013313742238096893, Final Batch Loss: 5.147887713974342e-05\n",
      "Epoch 4815, Loss: 0.0002195140750700375, Final Batch Loss: 0.00021148010273464024\n",
      "Epoch 4816, Loss: 6.497899539681384e-05, Final Batch Loss: 6.339801075228024e-06\n",
      "Epoch 4817, Loss: 0.0001307498496316839, Final Batch Loss: 4.4086042180424556e-05\n",
      "Epoch 4818, Loss: 0.00010362918328610249, Final Batch Loss: 1.8018061382463202e-05\n",
      "Epoch 4819, Loss: 0.00016446437439299189, Final Batch Loss: 0.00013259629486128688\n",
      "Epoch 4820, Loss: 0.0005192354146856815, Final Batch Loss: 0.0004937630146741867\n",
      "Epoch 4821, Loss: 0.00022234179050428793, Final Batch Loss: 4.857984458794817e-05\n",
      "Epoch 4822, Loss: 2.414889786450658e-05, Final Batch Loss: 1.3260505511425436e-06\n",
      "Epoch 4823, Loss: 0.0010803394543472677, Final Batch Loss: 0.0009688524878583848\n",
      "Epoch 4824, Loss: 0.0007390278660750482, Final Batch Loss: 0.0007127961725927889\n",
      "Epoch 4825, Loss: 0.00019379728473722935, Final Batch Loss: 0.00017508561722934246\n",
      "Epoch 4826, Loss: 0.0001224880406880402, Final Batch Loss: 9.739124834595714e-06\n",
      "Epoch 4827, Loss: 5.426467214419972e-05, Final Batch Loss: 4.3586682295426726e-05\n",
      "Epoch 4828, Loss: 0.00019088836415903643, Final Batch Loss: 0.00016269975458271801\n",
      "Epoch 4829, Loss: 5.3777133871335536e-05, Final Batch Loss: 2.929631773440633e-05\n",
      "Epoch 4830, Loss: 3.1569231396133546e-05, Final Batch Loss: 1.8040707800537348e-05\n",
      "Epoch 4831, Loss: 0.0001853809972089948, Final Batch Loss: 1.5771673133713193e-05\n",
      "Epoch 4832, Loss: 0.0003192172443959862, Final Batch Loss: 0.00010381732136011124\n",
      "Epoch 4833, Loss: 0.0007550291049938096, Final Batch Loss: 2.625936986078159e-06\n",
      "Epoch 4834, Loss: 2.4320854663528735e-05, Final Batch Loss: 9.101336218009237e-07\n",
      "Epoch 4835, Loss: 0.0004529375219135545, Final Batch Loss: 3.409725468372926e-05\n",
      "Epoch 4836, Loss: 0.0023360159029834904, Final Batch Loss: 0.0022984526585787535\n",
      "Epoch 4837, Loss: 0.00048364460963057354, Final Batch Loss: 3.6991208617109805e-05\n",
      "Epoch 4838, Loss: 0.0004319596610002918, Final Batch Loss: 0.00041577484807930887\n",
      "Epoch 4839, Loss: 0.0002981306752189994, Final Batch Loss: 9.585186489857733e-05\n",
      "Epoch 4840, Loss: 2.7673944259731798e-05, Final Batch Loss: 7.3808382694551256e-06\n",
      "Epoch 4841, Loss: 6.604581358260475e-06, Final Batch Loss: 1.1494307727843989e-06\n",
      "Epoch 4842, Loss: 1.7117646393671748e-05, Final Batch Loss: 1.343830990663264e-05\n",
      "Epoch 4843, Loss: 0.00011196079867659137, Final Batch Loss: 6.834996747784317e-05\n",
      "Epoch 4844, Loss: 0.0004145542634432786, Final Batch Loss: 1.289908050239319e-05\n",
      "Epoch 4845, Loss: 1.3644276350532891e-05, Final Batch Loss: 5.681421043846058e-06\n",
      "Epoch 4846, Loss: 0.00017456511704949662, Final Batch Loss: 7.865327643230557e-05\n",
      "Epoch 4847, Loss: 4.3394859858381096e-05, Final Batch Loss: 1.4102429304330144e-05\n",
      "Epoch 4848, Loss: 3.2129210921993945e-05, Final Batch Loss: 2.155442416551523e-05\n",
      "Epoch 4849, Loss: 4.951013943355065e-05, Final Batch Loss: 3.154868318233639e-05\n",
      "Epoch 4850, Loss: 2.4799085622362327e-05, Final Batch Loss: 6.882894922455307e-06\n",
      "Epoch 4851, Loss: 0.0002534538580221124, Final Batch Loss: 0.00022473424905911088\n",
      "Epoch 4852, Loss: 0.002406666943215896, Final Batch Loss: 3.7629654343618313e-06\n",
      "Epoch 4853, Loss: 1.379038280902023e-05, Final Batch Loss: 2.5946776531782234e-06\n",
      "Epoch 4854, Loss: 0.0001271964702027617, Final Batch Loss: 4.724393875221722e-06\n",
      "Epoch 4855, Loss: 0.00019831656527458108, Final Batch Loss: 2.6947031983581837e-06\n",
      "Epoch 4856, Loss: 7.854859131839476e-05, Final Batch Loss: 7.121008820831776e-05\n",
      "Epoch 4857, Loss: 1.6434212000149273e-05, Final Batch Loss: 1.5696552509325556e-05\n",
      "Epoch 4858, Loss: 0.0003911352214345243, Final Batch Loss: 0.0003489468072075397\n",
      "Epoch 4859, Loss: 3.5390489756537136e-05, Final Batch Loss: 1.2827730643039104e-05\n",
      "Epoch 4860, Loss: 3.04435474163256e-06, Final Batch Loss: 8.509886697538604e-07\n",
      "Epoch 4861, Loss: 6.951097020646557e-06, Final Batch Loss: 3.2002010357246036e-06\n",
      "Epoch 4862, Loss: 8.403377796639688e-05, Final Batch Loss: 8.169639477273449e-05\n",
      "Epoch 4863, Loss: 0.00035684000977198593, Final Batch Loss: 0.0003406766918487847\n",
      "Epoch 4864, Loss: 2.2546428226632997e-05, Final Batch Loss: 4.102876118849963e-06\n",
      "Epoch 4865, Loss: 0.0001213413052028045, Final Batch Loss: 7.863927748985589e-05\n",
      "Epoch 4866, Loss: 1.7773015997590846e-05, Final Batch Loss: 1.4047946933715139e-05\n",
      "Epoch 4867, Loss: 0.00020368973673612345, Final Batch Loss: 1.7191445294884034e-05\n",
      "Epoch 4868, Loss: 3.514131230986095e-05, Final Batch Loss: 4.248352979629999e-06\n",
      "Epoch 4869, Loss: 6.32277417480509e-05, Final Batch Loss: 2.7931423574045766e-07\n",
      "Epoch 4870, Loss: 1.447098520657164e-05, Final Batch Loss: 5.518339548871154e-06\n",
      "Epoch 4871, Loss: 4.014996920886915e-05, Final Batch Loss: 2.1729305444750935e-05\n",
      "Epoch 4872, Loss: 0.0005804466763947858, Final Batch Loss: 0.0005603283643722534\n",
      "Epoch 4873, Loss: 0.00010424745278214687, Final Batch Loss: 9.847152250586078e-05\n",
      "Epoch 4874, Loss: 8.523684664396569e-05, Final Batch Loss: 4.546042328001931e-05\n",
      "Epoch 4875, Loss: 3.818306686298456e-05, Final Batch Loss: 1.3697033864445984e-05\n",
      "Epoch 4876, Loss: 0.0015123423290788196, Final Batch Loss: 9.178264008369297e-06\n",
      "Epoch 4877, Loss: 0.0018058652954096033, Final Batch Loss: 0.0018002173164859414\n",
      "Epoch 4878, Loss: 0.0005255260548437946, Final Batch Loss: 0.00043398240813985467\n",
      "Epoch 4879, Loss: 0.00018495123367756605, Final Batch Loss: 0.00011692946281982586\n",
      "Epoch 4880, Loss: 0.00025141696096397936, Final Batch Loss: 0.00015908956993371248\n",
      "Epoch 4881, Loss: 0.00019327350673847832, Final Batch Loss: 0.00018534442642703652\n",
      "Epoch 4882, Loss: 5.4121409789331665e-06, Final Batch Loss: 8.562059861105809e-07\n",
      "Epoch 4883, Loss: 2.8717580789816566e-05, Final Batch Loss: 1.499133668403374e-05\n",
      "Epoch 4884, Loss: 0.00016817582218209282, Final Batch Loss: 3.490596282063052e-05\n",
      "Epoch 4885, Loss: 6.296450192166958e-05, Final Batch Loss: 3.4747979952953756e-05\n",
      "Epoch 4886, Loss: 2.28670098749717e-05, Final Batch Loss: 2.941756292784703e-06\n",
      "Epoch 4887, Loss: 6.68827954086737e-05, Final Batch Loss: 3.298558340247837e-06\n",
      "Epoch 4888, Loss: 6.018118801875971e-05, Final Batch Loss: 1.1322656064294279e-05\n",
      "Epoch 4889, Loss: 6.089140606491128e-05, Final Batch Loss: 5.0938655476784334e-05\n",
      "Epoch 4890, Loss: 1.6546006918360945e-05, Final Batch Loss: 1.1230640666326508e-05\n",
      "Epoch 4891, Loss: 0.00041636903915787116, Final Batch Loss: 0.00033996629645116627\n",
      "Epoch 4892, Loss: 5.0730473958537914e-05, Final Batch Loss: 1.8962417016155086e-05\n",
      "Epoch 4893, Loss: 7.494098235838464e-05, Final Batch Loss: 7.15161077096127e-05\n",
      "Epoch 4894, Loss: 0.0006134029972599819, Final Batch Loss: 7.559791265521199e-05\n",
      "Epoch 4895, Loss: 0.00019261391969394026, Final Batch Loss: 2.349373744436889e-07\n",
      "Epoch 4896, Loss: 2.8034170099999756e-05, Final Batch Loss: 1.976509520318359e-05\n",
      "Epoch 4897, Loss: 3.951309190597385e-05, Final Batch Loss: 2.0013660105178133e-05\n",
      "Epoch 4898, Loss: 7.360755034824251e-06, Final Batch Loss: 1.4165054835757473e-06\n",
      "Epoch 4899, Loss: 8.10197161627002e-06, Final Batch Loss: 4.578987955028424e-06\n",
      "Epoch 4900, Loss: 0.00021138289230293594, Final Batch Loss: 3.0879145924700424e-05\n",
      "Epoch 4901, Loss: 0.00026344267644162755, Final Batch Loss: 0.00024766684509813786\n",
      "Epoch 4902, Loss: 3.72470090042043e-05, Final Batch Loss: 3.263293911004439e-05\n",
      "Epoch 4903, Loss: 9.00441767726079e-05, Final Batch Loss: 8.849889127304778e-05\n",
      "Epoch 4904, Loss: 2.3217679881781805e-05, Final Batch Loss: 1.6468469766550697e-05\n",
      "Epoch 4905, Loss: 6.468893388955621e-05, Final Batch Loss: 5.3274510719347745e-05\n",
      "Epoch 4906, Loss: 2.0058271957168472e-05, Final Batch Loss: 3.2599175483483123e-06\n",
      "Epoch 4907, Loss: 0.00015028904942937515, Final Batch Loss: 1.0102206715600914e-06\n",
      "Epoch 4908, Loss: 8.042290937737562e-05, Final Batch Loss: 3.6381781683303416e-05\n",
      "Epoch 4909, Loss: 3.176040098651356e-05, Final Batch Loss: 3.1186777050606906e-05\n",
      "Epoch 4910, Loss: 3.3910810088855214e-05, Final Batch Loss: 1.8154078134102747e-05\n",
      "Epoch 4911, Loss: 2.9392840588116087e-05, Final Batch Loss: 1.765267370501533e-05\n",
      "Epoch 4912, Loss: 6.31840332516731e-05, Final Batch Loss: 2.0970333025616128e-07\n",
      "Epoch 4913, Loss: 8.326731585839298e-05, Final Batch Loss: 2.620297709654551e-05\n",
      "Epoch 4914, Loss: 9.845149179454893e-06, Final Batch Loss: 4.88262458020472e-06\n",
      "Epoch 4915, Loss: 0.00019732041164388647, Final Batch Loss: 6.8845756686641835e-06\n",
      "Epoch 4916, Loss: 3.0291414987004828e-05, Final Batch Loss: 2.3097691155271605e-05\n",
      "Epoch 4917, Loss: 0.0015245583599607926, Final Batch Loss: 3.8831021811347455e-06\n",
      "Epoch 4918, Loss: 0.001225019716002862, Final Batch Loss: 1.6664414943079464e-05\n",
      "Epoch 4919, Loss: 3.4092095461346617e-05, Final Batch Loss: 1.4069549933992676e-06\n",
      "Epoch 4920, Loss: 0.00021185318064453895, Final Batch Loss: 6.78203241477604e-06\n",
      "Epoch 4921, Loss: 8.192588029487524e-05, Final Batch Loss: 5.5558368330821395e-05\n",
      "Epoch 4922, Loss: 0.00013828555893269368, Final Batch Loss: 0.00011994400119874626\n",
      "Epoch 4923, Loss: 1.5945005884532293e-05, Final Batch Loss: 1.4330811382023967e-06\n",
      "Epoch 4924, Loss: 9.731069803819992e-05, Final Batch Loss: 3.3731597795849666e-05\n",
      "Epoch 4925, Loss: 3.157272112730425e-05, Final Batch Loss: 1.6222480553551577e-05\n",
      "Epoch 4926, Loss: 0.00010372241013101302, Final Batch Loss: 2.4513708922313526e-05\n",
      "Epoch 4927, Loss: 6.175990031920264e-05, Final Batch Loss: 4.759645264584833e-07\n",
      "Epoch 4928, Loss: 0.0004789415042978362, Final Batch Loss: 0.00047648779582232237\n",
      "Epoch 4929, Loss: 3.458464743744116e-05, Final Batch Loss: 9.893292371998541e-06\n",
      "Epoch 4930, Loss: 0.00010533224053688173, Final Batch Loss: 9.449497611058177e-07\n",
      "Epoch 4931, Loss: 1.8346006299907458e-05, Final Batch Loss: 2.12029340218578e-06\n",
      "Epoch 4932, Loss: 7.322032251977362e-05, Final Batch Loss: 3.7694651837227866e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4933, Loss: 2.5781349449971458e-05, Final Batch Loss: 2.10179241548758e-05\n",
      "Epoch 4934, Loss: 7.520129486238147e-06, Final Batch Loss: 6.756724815204507e-06\n",
      "Epoch 4935, Loss: 1.1839125136248185e-05, Final Batch Loss: 9.47322496358538e-06\n",
      "Epoch 4936, Loss: 3.7012475786468713e-06, Final Batch Loss: 1.4365346032718662e-06\n",
      "Epoch 4937, Loss: 1.9602007341745775e-05, Final Batch Loss: 9.367006896354724e-06\n",
      "Epoch 4938, Loss: 4.208368318359135e-05, Final Batch Loss: 2.7108289941679686e-05\n",
      "Epoch 4939, Loss: 6.153542153697344e-05, Final Batch Loss: 5.928836981183849e-05\n",
      "Epoch 4940, Loss: 5.756341306550894e-05, Final Batch Loss: 1.6456075172754936e-05\n",
      "Epoch 4941, Loss: 4.72591136713163e-06, Final Batch Loss: 1.8306798210687703e-06\n",
      "Epoch 4942, Loss: 0.00012671362856053747, Final Batch Loss: 5.3597392252413556e-05\n",
      "Epoch 4943, Loss: 0.0019339832797413692, Final Batch Loss: 0.0018774131312966347\n",
      "Epoch 4944, Loss: 0.0024398429295615642, Final Batch Loss: 4.596447070071008e-06\n",
      "Epoch 4945, Loss: 2.6637569135345984e-05, Final Batch Loss: 7.917770744825248e-06\n",
      "Epoch 4946, Loss: 0.0001319784641964361, Final Batch Loss: 0.00012732262257486582\n",
      "Epoch 4947, Loss: 5.3268444162313244e-06, Final Batch Loss: 1.3156171689843177e-06\n",
      "Epoch 4948, Loss: 1.1500851087475894e-05, Final Batch Loss: 4.560939942166442e-06\n",
      "Epoch 4949, Loss: 0.00019871946460625622, Final Batch Loss: 1.9325621906318702e-05\n",
      "Epoch 4950, Loss: 5.624611185339745e-05, Final Batch Loss: 5.2789237088290974e-05\n",
      "Epoch 4951, Loss: 5.201477870286908e-05, Final Batch Loss: 4.919399361824617e-05\n",
      "Epoch 4952, Loss: 2.0545116285575205e-05, Final Batch Loss: 3.2984355584630975e-06\n",
      "Epoch 4953, Loss: 2.4545927772123832e-05, Final Batch Loss: 1.290680120291654e-05\n",
      "Epoch 4954, Loss: 0.00017181898510898463, Final Batch Loss: 2.193757609347813e-05\n",
      "Epoch 4955, Loss: 2.3993370632524602e-05, Final Batch Loss: 1.7991864297073334e-05\n",
      "Epoch 4956, Loss: 9.408258165422012e-06, Final Batch Loss: 7.990212907316163e-06\n",
      "Epoch 4957, Loss: 1.8125933365809033e-05, Final Batch Loss: 2.390801910223672e-06\n",
      "Epoch 4958, Loss: 2.0001098619104596e-05, Final Batch Loss: 1.4010997801960912e-05\n",
      "Epoch 4959, Loss: 0.0008358775503438665, Final Batch Loss: 1.8888675185735337e-05\n",
      "Epoch 4960, Loss: 0.0018899309807238751, Final Batch Loss: 0.0018857382237911224\n",
      "Epoch 4961, Loss: 0.002680575620615855, Final Batch Loss: 0.0022391125094145536\n",
      "Epoch 4962, Loss: 3.336419786137412e-05, Final Batch Loss: 2.7145752028445713e-05\n",
      "Epoch 4963, Loss: 0.0005921004194533452, Final Batch Loss: 0.0005021213437430561\n",
      "Epoch 4964, Loss: 3.0006855695319246e-05, Final Batch Loss: 2.668489059942658e-06\n",
      "Epoch 4965, Loss: 7.254061074490892e-05, Final Batch Loss: 1.070982852979796e-05\n",
      "Epoch 4966, Loss: 6.270307403610786e-05, Final Batch Loss: 5.0399215979268774e-05\n",
      "Epoch 4967, Loss: 3.119911252724705e-05, Final Batch Loss: 1.873138353403192e-05\n",
      "Epoch 4968, Loss: 9.202380579154124e-05, Final Batch Loss: 8.67643830133602e-05\n",
      "Epoch 4969, Loss: 7.819824077159865e-06, Final Batch Loss: 2.5710642148624174e-06\n",
      "Epoch 4970, Loss: 0.00023687826160312397, Final Batch Loss: 5.034950845583808e-06\n",
      "Epoch 4971, Loss: 2.234650673926808e-05, Final Batch Loss: 3.309285602881573e-06\n",
      "Epoch 4972, Loss: 1.0708112426982552e-05, Final Batch Loss: 1.0199335520155728e-05\n",
      "Epoch 4973, Loss: 2.3591730951011414e-06, Final Batch Loss: 1.1685606295941398e-06\n",
      "Epoch 4974, Loss: 1.1162463124492206e-05, Final Batch Loss: 6.7686178226722404e-06\n",
      "Epoch 4975, Loss: 7.34213813302631e-06, Final Batch Loss: 2.2517940578836715e-06\n",
      "Epoch 4976, Loss: 0.0025180369593726937, Final Batch Loss: 0.0025160410441458225\n",
      "Epoch 4977, Loss: 0.00012517120649135904, Final Batch Loss: 9.002154001791496e-06\n",
      "Epoch 4978, Loss: 2.034109343185264e-06, Final Batch Loss: 9.83233348961221e-07\n",
      "Epoch 4979, Loss: 0.003020204885615385, Final Batch Loss: 0.002993025118485093\n",
      "Epoch 4980, Loss: 4.4191410893290595e-05, Final Batch Loss: 4.2308936826884747e-05\n",
      "Epoch 4981, Loss: 2.7068199415225536e-05, Final Batch Loss: 1.0098630809807219e-05\n",
      "Epoch 4982, Loss: 9.72197340161074e-05, Final Batch Loss: 3.245332118240185e-05\n",
      "Epoch 4983, Loss: 0.00027696867618942633, Final Batch Loss: 0.00024180019681807607\n",
      "Epoch 4984, Loss: 0.0004053375159855932, Final Batch Loss: 0.00026004586834460497\n",
      "Epoch 4985, Loss: 1.482329963664597e-05, Final Batch Loss: 5.742870712310832e-07\n",
      "Epoch 4986, Loss: 2.025890057666402e-05, Final Batch Loss: 2.5267715955124004e-06\n",
      "Epoch 4987, Loss: 3.748784126855753e-05, Final Batch Loss: 9.5971097380243e-07\n",
      "Epoch 4988, Loss: 1.960635563591495e-05, Final Batch Loss: 4.5477809180738404e-06\n",
      "Epoch 4989, Loss: 6.571704534508171e-05, Final Batch Loss: 6.352514901664108e-05\n",
      "Epoch 4990, Loss: 0.0011255497083766386, Final Batch Loss: 0.0009210961288772523\n",
      "Epoch 4991, Loss: 6.745012797182426e-06, Final Batch Loss: 3.891831511282362e-06\n",
      "Epoch 4992, Loss: 0.0016577845008214354, Final Batch Loss: 9.28906138142338e-06\n",
      "Epoch 4993, Loss: 0.000759288806875702, Final Batch Loss: 0.0006949721719138324\n",
      "Epoch 4994, Loss: 0.0008128944682539441, Final Batch Loss: 0.0006966526852920651\n",
      "Epoch 4995, Loss: 0.0003832981897176069, Final Batch Loss: 0.00037769851041957736\n",
      "Epoch 4996, Loss: 1.5287386759155197e-05, Final Batch Loss: 1.36081916934927e-06\n",
      "Epoch 4997, Loss: 3.662059134512674e-05, Final Batch Loss: 2.0949053578078747e-05\n",
      "Epoch 4998, Loss: 0.0001719648607831914, Final Batch Loss: 0.00014265760546550155\n",
      "Epoch 4999, Loss: 1.335405360691766e-05, Final Batch Loss: 2.0361241581667855e-07\n",
      "Epoch 5000, Loss: 0.00013570451528721605, Final Batch Loss: 0.00012890326615888625\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0]\n",
      " [ 0 27  0]\n",
      " [ 0  0 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        25\n",
      "           1    1.00000   1.00000   1.00000        27\n",
      "           2    1.00000   1.00000   1.00000        45\n",
      "\n",
      "    accuracy                        1.00000        97\n",
      "   macro avg    1.00000   1.00000   1.00000        97\n",
      "weighted avg    1.00000   1.00000   1.00000        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Group 3_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 3) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 0 30  0]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    1.00000   1.00000   1.00000        30\n",
      "         1.0    1.00000   1.00000   1.00000        30\n",
      "         2.0    1.00000   1.00000   1.00000        30\n",
      "\n",
      "    accuracy                        1.00000        90\n",
      "   macro avg    1.00000   1.00000   1.00000        90\n",
      "weighted avg    1.00000   1.00000   1.00000        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [14, 15, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 14:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 15:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.212775945663452, Final Batch Loss: 2.1009202003479004\n",
      "Epoch 2, Loss: 4.208991289138794, Final Batch Loss: 2.1168651580810547\n",
      "Epoch 3, Loss: 4.18974232673645, Final Batch Loss: 2.098130702972412\n",
      "Epoch 4, Loss: 4.178011417388916, Final Batch Loss: 2.0885064601898193\n",
      "Epoch 5, Loss: 4.1669018268585205, Final Batch Loss: 2.0820682048797607\n",
      "Epoch 6, Loss: 4.149097681045532, Final Batch Loss: 2.071721315383911\n",
      "Epoch 7, Loss: 4.126430511474609, Final Batch Loss: 2.0566389560699463\n",
      "Epoch 8, Loss: 4.110490560531616, Final Batch Loss: 2.0427193641662598\n",
      "Epoch 9, Loss: 4.105367183685303, Final Batch Loss: 2.0580835342407227\n",
      "Epoch 10, Loss: 4.087891101837158, Final Batch Loss: 2.033804416656494\n",
      "Epoch 11, Loss: 4.063032150268555, Final Batch Loss: 2.0144364833831787\n",
      "Epoch 12, Loss: 4.0352044105529785, Final Batch Loss: 2.004441022872925\n",
      "Epoch 13, Loss: 4.027859449386597, Final Batch Loss: 2.0145206451416016\n",
      "Epoch 14, Loss: 4.0024871826171875, Final Batch Loss: 2.0002188682556152\n",
      "Epoch 15, Loss: 3.975223660469055, Final Batch Loss: 1.9920438528060913\n",
      "Epoch 16, Loss: 3.935894012451172, Final Batch Loss: 1.949837565422058\n",
      "Epoch 17, Loss: 3.8894617557525635, Final Batch Loss: 1.9250236749649048\n",
      "Epoch 18, Loss: 3.880114197731018, Final Batch Loss: 1.945448637008667\n",
      "Epoch 19, Loss: 3.823909878730774, Final Batch Loss: 1.9005762338638306\n",
      "Epoch 20, Loss: 3.779892325401306, Final Batch Loss: 1.888200283050537\n",
      "Epoch 21, Loss: 3.7168251276016235, Final Batch Loss: 1.8471705913543701\n",
      "Epoch 22, Loss: 3.648253083229065, Final Batch Loss: 1.8003172874450684\n",
      "Epoch 23, Loss: 3.6087048053741455, Final Batch Loss: 1.8089361190795898\n",
      "Epoch 24, Loss: 3.5511069297790527, Final Batch Loss: 1.782931923866272\n",
      "Epoch 25, Loss: 3.4400999546051025, Final Batch Loss: 1.6710251569747925\n",
      "Epoch 26, Loss: 3.3682583570480347, Final Batch Loss: 1.6696224212646484\n",
      "Epoch 27, Loss: 3.290421962738037, Final Batch Loss: 1.6372405290603638\n",
      "Epoch 28, Loss: 3.1508424282073975, Final Batch Loss: 1.540930986404419\n",
      "Epoch 29, Loss: 3.0400551557540894, Final Batch Loss: 1.50533127784729\n",
      "Epoch 30, Loss: 2.88809072971344, Final Batch Loss: 1.4075291156768799\n",
      "Epoch 31, Loss: 2.81441867351532, Final Batch Loss: 1.3968514204025269\n",
      "Epoch 32, Loss: 2.815768599510193, Final Batch Loss: 1.4157757759094238\n",
      "Epoch 33, Loss: 2.7414722442626953, Final Batch Loss: 1.328359603881836\n",
      "Epoch 34, Loss: 2.603946089744568, Final Batch Loss: 1.3096791505813599\n",
      "Epoch 35, Loss: 2.5744718313217163, Final Batch Loss: 1.2556520700454712\n",
      "Epoch 36, Loss: 2.426781415939331, Final Batch Loss: 1.1994351148605347\n",
      "Epoch 37, Loss: 2.35884952545166, Final Batch Loss: 1.1242483854293823\n",
      "Epoch 38, Loss: 2.2863258123397827, Final Batch Loss: 1.1396898031234741\n",
      "Epoch 39, Loss: 2.2556618452072144, Final Batch Loss: 1.134861946105957\n",
      "Epoch 40, Loss: 2.2845574617385864, Final Batch Loss: 1.0869019031524658\n",
      "Epoch 41, Loss: 2.159625291824341, Final Batch Loss: 1.03216552734375\n",
      "Epoch 42, Loss: 2.2810752391815186, Final Batch Loss: 1.1664764881134033\n",
      "Epoch 43, Loss: 2.183117985725403, Final Batch Loss: 1.0878275632858276\n",
      "Epoch 44, Loss: 2.138377070426941, Final Batch Loss: 1.043378472328186\n",
      "Epoch 45, Loss: 2.14189612865448, Final Batch Loss: 1.1590408086776733\n",
      "Epoch 46, Loss: 2.101643443107605, Final Batch Loss: 1.0216281414031982\n",
      "Epoch 47, Loss: 2.0381369590759277, Final Batch Loss: 1.0635682344436646\n",
      "Epoch 48, Loss: 2.1061360836029053, Final Batch Loss: 1.0720994472503662\n",
      "Epoch 49, Loss: 1.9698322415351868, Final Batch Loss: 0.9870941638946533\n",
      "Epoch 50, Loss: 1.9810616374015808, Final Batch Loss: 0.9328300356864929\n",
      "Epoch 51, Loss: 1.9785256385803223, Final Batch Loss: 0.9869228005409241\n",
      "Epoch 52, Loss: 1.953909695148468, Final Batch Loss: 0.9334420561790466\n",
      "Epoch 53, Loss: 2.0160269141197205, Final Batch Loss: 1.0496406555175781\n",
      "Epoch 54, Loss: 1.9183809161186218, Final Batch Loss: 0.8915460705757141\n",
      "Epoch 55, Loss: 1.9323342442512512, Final Batch Loss: 0.9617186188697815\n",
      "Epoch 56, Loss: 1.8789471983909607, Final Batch Loss: 0.9180577993392944\n",
      "Epoch 57, Loss: 1.8127548098564148, Final Batch Loss: 0.9279395341873169\n",
      "Epoch 58, Loss: 1.847527027130127, Final Batch Loss: 0.9166429042816162\n",
      "Epoch 59, Loss: 1.9634894132614136, Final Batch Loss: 1.019247055053711\n",
      "Epoch 60, Loss: 1.8162689805030823, Final Batch Loss: 0.9644626379013062\n",
      "Epoch 61, Loss: 1.8860461115837097, Final Batch Loss: 0.9083594083786011\n",
      "Epoch 62, Loss: 1.7966836094856262, Final Batch Loss: 0.8958004713058472\n",
      "Epoch 63, Loss: 1.8474061489105225, Final Batch Loss: 0.9301280975341797\n",
      "Epoch 64, Loss: 1.7772217392921448, Final Batch Loss: 0.8791199922561646\n",
      "Epoch 65, Loss: 1.8301132917404175, Final Batch Loss: 0.9337570667266846\n",
      "Epoch 66, Loss: 1.6849608421325684, Final Batch Loss: 0.7983731627464294\n",
      "Epoch 67, Loss: 1.7885818481445312, Final Batch Loss: 0.8845103979110718\n",
      "Epoch 68, Loss: 1.7581928968429565, Final Batch Loss: 0.9036930203437805\n",
      "Epoch 69, Loss: 1.7391653656959534, Final Batch Loss: 0.877558708190918\n",
      "Epoch 70, Loss: 1.7797013521194458, Final Batch Loss: 0.9214600920677185\n",
      "Epoch 71, Loss: 1.697025179862976, Final Batch Loss: 0.8212869763374329\n",
      "Epoch 72, Loss: 1.7242588996887207, Final Batch Loss: 0.8650305867195129\n",
      "Epoch 73, Loss: 1.7082311511039734, Final Batch Loss: 0.850863516330719\n",
      "Epoch 74, Loss: 1.731326162815094, Final Batch Loss: 0.8800713419914246\n",
      "Epoch 75, Loss: 1.7038445472717285, Final Batch Loss: 0.8268479108810425\n",
      "Epoch 76, Loss: 1.6994346976280212, Final Batch Loss: 0.8342878818511963\n",
      "Epoch 77, Loss: 1.786363422870636, Final Batch Loss: 0.9785439372062683\n",
      "Epoch 78, Loss: 1.6601977944374084, Final Batch Loss: 0.7641130685806274\n",
      "Epoch 79, Loss: 1.6785399913787842, Final Batch Loss: 0.8030048608779907\n",
      "Epoch 80, Loss: 1.6501163244247437, Final Batch Loss: 0.7732064127922058\n",
      "Epoch 81, Loss: 1.7517331838607788, Final Batch Loss: 0.9165206551551819\n",
      "Epoch 82, Loss: 1.6038249135017395, Final Batch Loss: 0.7988435626029968\n",
      "Epoch 83, Loss: 1.6479635834693909, Final Batch Loss: 0.8175613880157471\n",
      "Epoch 84, Loss: 1.5985623002052307, Final Batch Loss: 0.7974656224250793\n",
      "Epoch 85, Loss: 1.6424949169158936, Final Batch Loss: 0.8269689679145813\n",
      "Epoch 86, Loss: 1.5678462386131287, Final Batch Loss: 0.781002402305603\n",
      "Epoch 87, Loss: 1.6668033599853516, Final Batch Loss: 0.8080117702484131\n",
      "Epoch 88, Loss: 1.666863203048706, Final Batch Loss: 0.8736216425895691\n",
      "Epoch 89, Loss: 1.623984694480896, Final Batch Loss: 0.8297998905181885\n",
      "Epoch 90, Loss: 1.6711305975914001, Final Batch Loss: 0.8754096031188965\n",
      "Epoch 91, Loss: 1.6004254817962646, Final Batch Loss: 0.7794156074523926\n",
      "Epoch 92, Loss: 1.5707321166992188, Final Batch Loss: 0.7540055513381958\n",
      "Epoch 93, Loss: 1.5988891124725342, Final Batch Loss: 0.8000242710113525\n",
      "Epoch 94, Loss: 1.5750203728675842, Final Batch Loss: 0.8119936585426331\n",
      "Epoch 95, Loss: 1.639883279800415, Final Batch Loss: 0.8536653518676758\n",
      "Epoch 96, Loss: 1.59504896402359, Final Batch Loss: 0.7550120949745178\n",
      "Epoch 97, Loss: 1.5651788115501404, Final Batch Loss: 0.7797034382820129\n",
      "Epoch 98, Loss: 1.5998207926750183, Final Batch Loss: 0.814353346824646\n",
      "Epoch 99, Loss: 1.606344997882843, Final Batch Loss: 0.8027012348175049\n",
      "Epoch 100, Loss: 1.5722201466560364, Final Batch Loss: 0.831466555595398\n",
      "Epoch 101, Loss: 1.5922794342041016, Final Batch Loss: 0.7700839638710022\n",
      "Epoch 102, Loss: 1.5898661017417908, Final Batch Loss: 0.7961505651473999\n",
      "Epoch 103, Loss: 1.5500943660736084, Final Batch Loss: 0.7536929249763489\n",
      "Epoch 104, Loss: 1.5234816670417786, Final Batch Loss: 0.6972242593765259\n",
      "Epoch 105, Loss: 1.5615578889846802, Final Batch Loss: 0.7778155207633972\n",
      "Epoch 106, Loss: 1.5697710514068604, Final Batch Loss: 0.7551659345626831\n",
      "Epoch 107, Loss: 1.5715102553367615, Final Batch Loss: 0.7844944000244141\n",
      "Epoch 108, Loss: 1.6396048665046692, Final Batch Loss: 0.8946377635002136\n",
      "Epoch 109, Loss: 1.595991849899292, Final Batch Loss: 0.868399977684021\n",
      "Epoch 110, Loss: 1.564676284790039, Final Batch Loss: 0.7882779240608215\n",
      "Epoch 111, Loss: 1.5750601887702942, Final Batch Loss: 0.7719854116439819\n",
      "Epoch 112, Loss: 1.516678273677826, Final Batch Loss: 0.7126277089118958\n",
      "Epoch 113, Loss: 1.497912347316742, Final Batch Loss: 0.7113538384437561\n",
      "Epoch 114, Loss: 1.5492156147956848, Final Batch Loss: 0.8424580693244934\n",
      "Epoch 115, Loss: 1.5271610617637634, Final Batch Loss: 0.7158520221710205\n",
      "Epoch 116, Loss: 1.5266872644424438, Final Batch Loss: 0.7126846313476562\n",
      "Epoch 117, Loss: 1.5331350564956665, Final Batch Loss: 0.7794799208641052\n",
      "Epoch 118, Loss: 1.4972248077392578, Final Batch Loss: 0.7433628439903259\n",
      "Epoch 119, Loss: 1.5548577904701233, Final Batch Loss: 0.7368481755256653\n",
      "Epoch 120, Loss: 1.5248728394508362, Final Batch Loss: 0.790228009223938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121, Loss: 1.5377275347709656, Final Batch Loss: 0.782069206237793\n",
      "Epoch 122, Loss: 1.5177512764930725, Final Batch Loss: 0.7822418808937073\n",
      "Epoch 123, Loss: 1.5593517422676086, Final Batch Loss: 0.8305290341377258\n",
      "Epoch 124, Loss: 1.4834073185920715, Final Batch Loss: 0.7316708564758301\n",
      "Epoch 125, Loss: 1.5139175653457642, Final Batch Loss: 0.7761777639389038\n",
      "Epoch 126, Loss: 1.4916625022888184, Final Batch Loss: 0.7640619874000549\n",
      "Epoch 127, Loss: 1.5680912137031555, Final Batch Loss: 0.8093515038490295\n",
      "Epoch 128, Loss: 1.4780933260917664, Final Batch Loss: 0.7141973972320557\n",
      "Epoch 129, Loss: 1.5635334849357605, Final Batch Loss: 0.7980458736419678\n",
      "Epoch 130, Loss: 1.565445899963379, Final Batch Loss: 0.8232944011688232\n",
      "Epoch 131, Loss: 1.4670230150222778, Final Batch Loss: 0.7315845489501953\n",
      "Epoch 132, Loss: 1.4910864233970642, Final Batch Loss: 0.7470732927322388\n",
      "Epoch 133, Loss: 1.4618062376976013, Final Batch Loss: 0.7206176519393921\n",
      "Epoch 134, Loss: 1.5094990134239197, Final Batch Loss: 0.7848568558692932\n",
      "Epoch 135, Loss: 1.4737694263458252, Final Batch Loss: 0.7385932207107544\n",
      "Epoch 136, Loss: 1.4672030806541443, Final Batch Loss: 0.743533194065094\n",
      "Epoch 137, Loss: 1.46821928024292, Final Batch Loss: 0.6968309879302979\n",
      "Epoch 138, Loss: 1.5159252285957336, Final Batch Loss: 0.787168562412262\n",
      "Epoch 139, Loss: 1.4947529435157776, Final Batch Loss: 0.7777662873268127\n",
      "Epoch 140, Loss: 1.5223103165626526, Final Batch Loss: 0.8213339447975159\n",
      "Epoch 141, Loss: 1.534133791923523, Final Batch Loss: 0.7809466123580933\n",
      "Epoch 142, Loss: 1.5037572979927063, Final Batch Loss: 0.7661433219909668\n",
      "Epoch 143, Loss: 1.47636079788208, Final Batch Loss: 0.7639798521995544\n",
      "Epoch 144, Loss: 1.4621314406394958, Final Batch Loss: 0.7278429865837097\n",
      "Epoch 145, Loss: 1.4658819437026978, Final Batch Loss: 0.7185773849487305\n",
      "Epoch 146, Loss: 1.5036574006080627, Final Batch Loss: 0.7674833536148071\n",
      "Epoch 147, Loss: 1.4585618376731873, Final Batch Loss: 0.6730784773826599\n",
      "Epoch 148, Loss: 1.4571677446365356, Final Batch Loss: 0.7370185256004333\n",
      "Epoch 149, Loss: 1.4204501509666443, Final Batch Loss: 0.6594711542129517\n",
      "Epoch 150, Loss: 1.4770865440368652, Final Batch Loss: 0.7230859398841858\n",
      "Epoch 151, Loss: 1.4128952026367188, Final Batch Loss: 0.6776730418205261\n",
      "Epoch 152, Loss: 1.4767363667488098, Final Batch Loss: 0.7572530508041382\n",
      "Epoch 153, Loss: 1.462262749671936, Final Batch Loss: 0.7774456739425659\n",
      "Epoch 154, Loss: 1.431641936302185, Final Batch Loss: 0.7032831311225891\n",
      "Epoch 155, Loss: 1.428167700767517, Final Batch Loss: 0.6991220116615295\n",
      "Epoch 156, Loss: 1.4707626104354858, Final Batch Loss: 0.7711879014968872\n",
      "Epoch 157, Loss: 1.4361488819122314, Final Batch Loss: 0.7509216070175171\n",
      "Epoch 158, Loss: 1.4507445096969604, Final Batch Loss: 0.7259314060211182\n",
      "Epoch 159, Loss: 1.4098567962646484, Final Batch Loss: 0.7024008631706238\n",
      "Epoch 160, Loss: 1.4227885603904724, Final Batch Loss: 0.6895247101783752\n",
      "Epoch 161, Loss: 1.4222831726074219, Final Batch Loss: 0.6683002710342407\n",
      "Epoch 162, Loss: 1.4149208664894104, Final Batch Loss: 0.6725854277610779\n",
      "Epoch 163, Loss: 1.383690357208252, Final Batch Loss: 0.7088885307312012\n",
      "Epoch 164, Loss: 1.4242042899131775, Final Batch Loss: 0.7180514335632324\n",
      "Epoch 165, Loss: 1.4213133454322815, Final Batch Loss: 0.7132347226142883\n",
      "Epoch 166, Loss: 1.4600546956062317, Final Batch Loss: 0.775221049785614\n",
      "Epoch 167, Loss: 1.4144222736358643, Final Batch Loss: 0.7381786108016968\n",
      "Epoch 168, Loss: 1.4379488825798035, Final Batch Loss: 0.7851566672325134\n",
      "Epoch 169, Loss: 1.4254528880119324, Final Batch Loss: 0.6756790280342102\n",
      "Epoch 170, Loss: 1.4115983247756958, Final Batch Loss: 0.6799042224884033\n",
      "Epoch 171, Loss: 1.369079053401947, Final Batch Loss: 0.6359221339225769\n",
      "Epoch 172, Loss: 1.4068074226379395, Final Batch Loss: 0.7086985111236572\n",
      "Epoch 173, Loss: 1.4076387286186218, Final Batch Loss: 0.6752439141273499\n",
      "Epoch 174, Loss: 1.4169701933860779, Final Batch Loss: 0.7284987568855286\n",
      "Epoch 175, Loss: 1.3631916642189026, Final Batch Loss: 0.6979726552963257\n",
      "Epoch 176, Loss: 1.3914061188697815, Final Batch Loss: 0.7202572822570801\n",
      "Epoch 177, Loss: 1.3792262077331543, Final Batch Loss: 0.6854600310325623\n",
      "Epoch 178, Loss: 1.359815537929535, Final Batch Loss: 0.681519627571106\n",
      "Epoch 179, Loss: 1.3852024674415588, Final Batch Loss: 0.7048084735870361\n",
      "Epoch 180, Loss: 1.3505902290344238, Final Batch Loss: 0.6700027585029602\n",
      "Epoch 181, Loss: 1.3723745346069336, Final Batch Loss: 0.7116908431053162\n",
      "Epoch 182, Loss: 1.3986909985542297, Final Batch Loss: 0.6828329563140869\n",
      "Epoch 183, Loss: 1.3637124300003052, Final Batch Loss: 0.7164055109024048\n",
      "Epoch 184, Loss: 1.352634847164154, Final Batch Loss: 0.7013981342315674\n",
      "Epoch 185, Loss: 1.360650897026062, Final Batch Loss: 0.6961968541145325\n",
      "Epoch 186, Loss: 1.3342734575271606, Final Batch Loss: 0.6427637338638306\n",
      "Epoch 187, Loss: 1.3437666296958923, Final Batch Loss: 0.6764393448829651\n",
      "Epoch 188, Loss: 1.3741317987442017, Final Batch Loss: 0.6622060537338257\n",
      "Epoch 189, Loss: 1.3561237454414368, Final Batch Loss: 0.6607562303543091\n",
      "Epoch 190, Loss: 1.3391743302345276, Final Batch Loss: 0.6710019707679749\n",
      "Epoch 191, Loss: 1.351677656173706, Final Batch Loss: 0.6901072859764099\n",
      "Epoch 192, Loss: 1.3244418501853943, Final Batch Loss: 0.6494831442832947\n",
      "Epoch 193, Loss: 1.37709379196167, Final Batch Loss: 0.7367283701896667\n",
      "Epoch 194, Loss: 1.3542864918708801, Final Batch Loss: 0.7195619940757751\n",
      "Epoch 195, Loss: 1.2926225066184998, Final Batch Loss: 0.6219735741615295\n",
      "Epoch 196, Loss: 1.277102530002594, Final Batch Loss: 0.5815805196762085\n",
      "Epoch 197, Loss: 1.3400920629501343, Final Batch Loss: 0.6776150465011597\n",
      "Epoch 198, Loss: 1.3097078800201416, Final Batch Loss: 0.642708957195282\n",
      "Epoch 199, Loss: 1.3584589958190918, Final Batch Loss: 0.6758759021759033\n",
      "Epoch 200, Loss: 1.3369710445404053, Final Batch Loss: 0.6867519617080688\n",
      "Epoch 201, Loss: 1.285153090953827, Final Batch Loss: 0.6289665102958679\n",
      "Epoch 202, Loss: 1.319162368774414, Final Batch Loss: 0.6144154071807861\n",
      "Epoch 203, Loss: 1.3386775255203247, Final Batch Loss: 0.6689947843551636\n",
      "Epoch 204, Loss: 1.3066098093986511, Final Batch Loss: 0.6901037693023682\n",
      "Epoch 205, Loss: 1.2910452485084534, Final Batch Loss: 0.6593952775001526\n",
      "Epoch 206, Loss: 1.3038274049758911, Final Batch Loss: 0.6403870582580566\n",
      "Epoch 207, Loss: 1.3188046216964722, Final Batch Loss: 0.6880056262016296\n",
      "Epoch 208, Loss: 1.310975730419159, Final Batch Loss: 0.6660389304161072\n",
      "Epoch 209, Loss: 1.2325958013534546, Final Batch Loss: 0.5728484988212585\n",
      "Epoch 210, Loss: 1.2728040218353271, Final Batch Loss: 0.625392735004425\n",
      "Epoch 211, Loss: 1.265832543373108, Final Batch Loss: 0.604529082775116\n",
      "Epoch 212, Loss: 1.2889931797981262, Final Batch Loss: 0.6803426146507263\n",
      "Epoch 213, Loss: 1.2952615022659302, Final Batch Loss: 0.6986036896705627\n",
      "Epoch 214, Loss: 1.2277578115463257, Final Batch Loss: 0.6203405857086182\n",
      "Epoch 215, Loss: 1.2440280318260193, Final Batch Loss: 0.5533685088157654\n",
      "Epoch 216, Loss: 1.176903486251831, Final Batch Loss: 0.5326313376426697\n",
      "Epoch 217, Loss: 1.2520155906677246, Final Batch Loss: 0.636488676071167\n",
      "Epoch 218, Loss: 1.2523483037948608, Final Batch Loss: 0.6779765486717224\n",
      "Epoch 219, Loss: 1.2319123148918152, Final Batch Loss: 0.6097205281257629\n",
      "Epoch 220, Loss: 1.2021812796592712, Final Batch Loss: 0.5910799503326416\n",
      "Epoch 221, Loss: 1.1838461756706238, Final Batch Loss: 0.5882520079612732\n",
      "Epoch 222, Loss: 1.2326304912567139, Final Batch Loss: 0.6685001254081726\n",
      "Epoch 223, Loss: 1.1852643489837646, Final Batch Loss: 0.5733112096786499\n",
      "Epoch 224, Loss: 1.178688645362854, Final Batch Loss: 0.5777069330215454\n",
      "Epoch 225, Loss: 1.2605477571487427, Final Batch Loss: 0.6209678649902344\n",
      "Epoch 226, Loss: 1.1673479676246643, Final Batch Loss: 0.598371148109436\n",
      "Epoch 227, Loss: 1.2099702954292297, Final Batch Loss: 0.5989912748336792\n",
      "Epoch 228, Loss: 1.178756594657898, Final Batch Loss: 0.5779313445091248\n",
      "Epoch 229, Loss: 1.1372347474098206, Final Batch Loss: 0.5666616559028625\n",
      "Epoch 230, Loss: 1.1300910711288452, Final Batch Loss: 0.5247788429260254\n",
      "Epoch 231, Loss: 1.1318159103393555, Final Batch Loss: 0.5309742093086243\n",
      "Epoch 232, Loss: 1.1166998147964478, Final Batch Loss: 0.5671143531799316\n",
      "Epoch 233, Loss: 1.1405880451202393, Final Batch Loss: 0.5877435207366943\n",
      "Epoch 234, Loss: 1.0852802395820618, Final Batch Loss: 0.5580193996429443\n",
      "Epoch 235, Loss: 1.058655023574829, Final Batch Loss: 0.4770295023918152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236, Loss: 1.0951869487762451, Final Batch Loss: 0.548299252986908\n",
      "Epoch 237, Loss: 1.1333884596824646, Final Batch Loss: 0.6008874177932739\n",
      "Epoch 238, Loss: 1.1065813302993774, Final Batch Loss: 0.5880618691444397\n",
      "Epoch 239, Loss: 1.0402279496192932, Final Batch Loss: 0.5231348872184753\n",
      "Epoch 240, Loss: 1.0630711913108826, Final Batch Loss: 0.5306309461593628\n",
      "Epoch 241, Loss: 0.9903439283370972, Final Batch Loss: 0.45720911026000977\n",
      "Epoch 242, Loss: 1.0253254175186157, Final Batch Loss: 0.5192955136299133\n",
      "Epoch 243, Loss: 1.0185168981552124, Final Batch Loss: 0.5013346672058105\n",
      "Epoch 244, Loss: 0.9427862763404846, Final Batch Loss: 0.44443559646606445\n",
      "Epoch 245, Loss: 1.0170587301254272, Final Batch Loss: 0.5162209272384644\n",
      "Epoch 246, Loss: 1.0024062991142273, Final Batch Loss: 0.4869190454483032\n",
      "Epoch 247, Loss: 0.9887283742427826, Final Batch Loss: 0.49556809663772583\n",
      "Epoch 248, Loss: 0.958329975605011, Final Batch Loss: 0.4616200625896454\n",
      "Epoch 249, Loss: 0.9287835955619812, Final Batch Loss: 0.49065932631492615\n",
      "Epoch 250, Loss: 0.9440594017505646, Final Batch Loss: 0.43486276268959045\n",
      "Epoch 251, Loss: 0.9021943807601929, Final Batch Loss: 0.45382246375083923\n",
      "Epoch 252, Loss: 0.9219290912151337, Final Batch Loss: 0.45472070574760437\n",
      "Epoch 253, Loss: 0.9372812807559967, Final Batch Loss: 0.4505278468132019\n",
      "Epoch 254, Loss: 0.8962429463863373, Final Batch Loss: 0.43859031796455383\n",
      "Epoch 255, Loss: 0.8400371968746185, Final Batch Loss: 0.40461838245391846\n",
      "Epoch 256, Loss: 0.9038911461830139, Final Batch Loss: 0.5079011917114258\n",
      "Epoch 257, Loss: 0.9105790853500366, Final Batch Loss: 0.42874839901924133\n",
      "Epoch 258, Loss: 0.9380201995372772, Final Batch Loss: 0.5046443939208984\n",
      "Epoch 259, Loss: 0.8749374747276306, Final Batch Loss: 0.4911474585533142\n",
      "Epoch 260, Loss: 0.8953568935394287, Final Batch Loss: 0.4478740990161896\n",
      "Epoch 261, Loss: 0.8942587673664093, Final Batch Loss: 0.46233272552490234\n",
      "Epoch 262, Loss: 0.8483994901180267, Final Batch Loss: 0.39148861169815063\n",
      "Epoch 263, Loss: 0.9311313033103943, Final Batch Loss: 0.49397343397140503\n",
      "Epoch 264, Loss: 0.8897779583930969, Final Batch Loss: 0.433335542678833\n",
      "Epoch 265, Loss: 0.9522864520549774, Final Batch Loss: 0.5180633068084717\n",
      "Epoch 266, Loss: 0.8413426280021667, Final Batch Loss: 0.36723995208740234\n",
      "Epoch 267, Loss: 0.8254095911979675, Final Batch Loss: 0.4510551989078522\n",
      "Epoch 268, Loss: 0.7993353307247162, Final Batch Loss: 0.3286574184894562\n",
      "Epoch 269, Loss: 0.794113427400589, Final Batch Loss: 0.3851129412651062\n",
      "Epoch 270, Loss: 0.8061752319335938, Final Batch Loss: 0.43167218565940857\n",
      "Epoch 271, Loss: 0.7998807430267334, Final Batch Loss: 0.37538716197013855\n",
      "Epoch 272, Loss: 0.8414953947067261, Final Batch Loss: 0.4809020161628723\n",
      "Epoch 273, Loss: 0.8115079700946808, Final Batch Loss: 0.3667980432510376\n",
      "Epoch 274, Loss: 0.7565113008022308, Final Batch Loss: 0.3689046800136566\n",
      "Epoch 275, Loss: 0.7846897840499878, Final Batch Loss: 0.3383862376213074\n",
      "Epoch 276, Loss: 0.7751993238925934, Final Batch Loss: 0.40100011229515076\n",
      "Epoch 277, Loss: 0.8463654816150665, Final Batch Loss: 0.4454699456691742\n",
      "Epoch 278, Loss: 0.8440786004066467, Final Batch Loss: 0.47720059752464294\n",
      "Epoch 279, Loss: 0.7536957859992981, Final Batch Loss: 0.36175715923309326\n",
      "Epoch 280, Loss: 0.7750116884708405, Final Batch Loss: 0.3746638000011444\n",
      "Epoch 281, Loss: 0.7636748850345612, Final Batch Loss: 0.34998852014541626\n",
      "Epoch 282, Loss: 0.712563693523407, Final Batch Loss: 0.33605554699897766\n",
      "Epoch 283, Loss: 0.7503179609775543, Final Batch Loss: 0.36427873373031616\n",
      "Epoch 284, Loss: 0.7802053987979889, Final Batch Loss: 0.35623684525489807\n",
      "Epoch 285, Loss: 0.7520651817321777, Final Batch Loss: 0.4058995842933655\n",
      "Epoch 286, Loss: 0.7121597230434418, Final Batch Loss: 0.34584560990333557\n",
      "Epoch 287, Loss: 0.7240790128707886, Final Batch Loss: 0.28993919491767883\n",
      "Epoch 288, Loss: 0.8092135488986969, Final Batch Loss: 0.3911699652671814\n",
      "Epoch 289, Loss: 0.7206295728683472, Final Batch Loss: 0.3321458399295807\n",
      "Epoch 290, Loss: 0.6926042139530182, Final Batch Loss: 0.293195903301239\n",
      "Epoch 291, Loss: 0.691344290971756, Final Batch Loss: 0.35358214378356934\n",
      "Epoch 292, Loss: 0.7423857748508453, Final Batch Loss: 0.34669873118400574\n",
      "Epoch 293, Loss: 0.7513538897037506, Final Batch Loss: 0.3441683351993561\n",
      "Epoch 294, Loss: 0.7145368158817291, Final Batch Loss: 0.3725418150424957\n",
      "Epoch 295, Loss: 0.7446253895759583, Final Batch Loss: 0.41950300335884094\n",
      "Epoch 296, Loss: 0.6467911005020142, Final Batch Loss: 0.29596462845802307\n",
      "Epoch 297, Loss: 0.7010893821716309, Final Batch Loss: 0.38781625032424927\n",
      "Epoch 298, Loss: 0.7532570660114288, Final Batch Loss: 0.3362744450569153\n",
      "Epoch 299, Loss: 0.7068070471286774, Final Batch Loss: 0.3797350823879242\n",
      "Epoch 300, Loss: 0.7446274161338806, Final Batch Loss: 0.38533756136894226\n",
      "Epoch 301, Loss: 0.7308253049850464, Final Batch Loss: 0.3861040771007538\n",
      "Epoch 302, Loss: 0.6976317763328552, Final Batch Loss: 0.29800593852996826\n",
      "Epoch 303, Loss: 0.6640938818454742, Final Batch Loss: 0.31833696365356445\n",
      "Epoch 304, Loss: 0.7524042129516602, Final Batch Loss: 0.4385194182395935\n",
      "Epoch 305, Loss: 0.7674492001533508, Final Batch Loss: 0.39409661293029785\n",
      "Epoch 306, Loss: 0.677186518907547, Final Batch Loss: 0.2941736578941345\n",
      "Epoch 307, Loss: 0.7376164197921753, Final Batch Loss: 0.3978656530380249\n",
      "Epoch 308, Loss: 0.7170446813106537, Final Batch Loss: 0.3026440441608429\n",
      "Epoch 309, Loss: 0.7281451523303986, Final Batch Loss: 0.36523088812828064\n",
      "Epoch 310, Loss: 0.6797647476196289, Final Batch Loss: 0.31057238578796387\n",
      "Epoch 311, Loss: 0.6744524538516998, Final Batch Loss: 0.2857118844985962\n",
      "Epoch 312, Loss: 0.7092775106430054, Final Batch Loss: 0.3487470746040344\n",
      "Epoch 313, Loss: 0.6924943029880524, Final Batch Loss: 0.349550724029541\n",
      "Epoch 314, Loss: 0.8004263937473297, Final Batch Loss: 0.443813681602478\n",
      "Epoch 315, Loss: 0.6951434016227722, Final Batch Loss: 0.3478247821331024\n",
      "Epoch 316, Loss: 0.6213715374469757, Final Batch Loss: 0.2958766222000122\n",
      "Epoch 317, Loss: 0.7644543349742889, Final Batch Loss: 0.39995983242988586\n",
      "Epoch 318, Loss: 0.6847319602966309, Final Batch Loss: 0.3256732225418091\n",
      "Epoch 319, Loss: 0.658968985080719, Final Batch Loss: 0.31143155694007874\n",
      "Epoch 320, Loss: 0.7207561731338501, Final Batch Loss: 0.3930354118347168\n",
      "Epoch 321, Loss: 0.66407909989357, Final Batch Loss: 0.34136101603507996\n",
      "Epoch 322, Loss: 0.779533326625824, Final Batch Loss: 0.427246630191803\n",
      "Epoch 323, Loss: 0.6652199327945709, Final Batch Loss: 0.2840222716331482\n",
      "Epoch 324, Loss: 0.6682143807411194, Final Batch Loss: 0.3316012918949127\n",
      "Epoch 325, Loss: 0.7204454243183136, Final Batch Loss: 0.40642568469047546\n",
      "Epoch 326, Loss: 0.6291522681713104, Final Batch Loss: 0.2628917694091797\n",
      "Epoch 327, Loss: 0.6299583911895752, Final Batch Loss: 0.3106440007686615\n",
      "Epoch 328, Loss: 0.7086528539657593, Final Batch Loss: 0.33362528681755066\n",
      "Epoch 329, Loss: 0.7806560397148132, Final Batch Loss: 0.4113118052482605\n",
      "Epoch 330, Loss: 0.6511084139347076, Final Batch Loss: 0.3053644001483917\n",
      "Epoch 331, Loss: 0.652502715587616, Final Batch Loss: 0.3157859146595001\n",
      "Epoch 332, Loss: 0.6122496277093887, Final Batch Loss: 0.23850615322589874\n",
      "Epoch 333, Loss: 0.6535061001777649, Final Batch Loss: 0.3318227231502533\n",
      "Epoch 334, Loss: 0.6952605247497559, Final Batch Loss: 0.3854219913482666\n",
      "Epoch 335, Loss: 0.6096237301826477, Final Batch Loss: 0.2657841444015503\n",
      "Epoch 336, Loss: 0.7487248480319977, Final Batch Loss: 0.43299397826194763\n",
      "Epoch 337, Loss: 0.6465485394001007, Final Batch Loss: 0.37876808643341064\n",
      "Epoch 338, Loss: 0.6566787958145142, Final Batch Loss: 0.33281973004341125\n",
      "Epoch 339, Loss: 0.6352624595165253, Final Batch Loss: 0.30325376987457275\n",
      "Epoch 340, Loss: 0.6717455089092255, Final Batch Loss: 0.3722529113292694\n",
      "Epoch 341, Loss: 0.6538720726966858, Final Batch Loss: 0.38029593229293823\n",
      "Epoch 342, Loss: 0.6282062232494354, Final Batch Loss: 0.32293933629989624\n",
      "Epoch 343, Loss: 0.6573206186294556, Final Batch Loss: 0.3178707957267761\n",
      "Epoch 344, Loss: 0.5371278524398804, Final Batch Loss: 0.2566629946231842\n",
      "Epoch 345, Loss: 0.6104100048542023, Final Batch Loss: 0.31940528750419617\n",
      "Epoch 346, Loss: 0.6764124631881714, Final Batch Loss: 0.3588879406452179\n",
      "Epoch 347, Loss: 0.6596847176551819, Final Batch Loss: 0.30118370056152344\n",
      "Epoch 348, Loss: 0.733187735080719, Final Batch Loss: 0.3846338987350464\n",
      "Epoch 349, Loss: 0.5471441298723221, Final Batch Loss: 0.23052971065044403\n",
      "Epoch 350, Loss: 0.7124446928501129, Final Batch Loss: 0.3930474817752838\n",
      "Epoch 351, Loss: 0.723605751991272, Final Batch Loss: 0.3740796446800232\n",
      "Epoch 352, Loss: 0.6369441449642181, Final Batch Loss: 0.32612544298171997\n",
      "Epoch 353, Loss: 0.6463754177093506, Final Batch Loss: 0.32330241799354553\n",
      "Epoch 354, Loss: 0.5938576459884644, Final Batch Loss: 0.2758651673793793\n",
      "Epoch 355, Loss: 0.6852833032608032, Final Batch Loss: 0.4003039002418518\n",
      "Epoch 356, Loss: 0.6728531420230865, Final Batch Loss: 0.35256698727607727\n",
      "Epoch 357, Loss: 0.6374579966068268, Final Batch Loss: 0.3115246891975403\n",
      "Epoch 358, Loss: 0.5795895606279373, Final Batch Loss: 0.22941090166568756\n",
      "Epoch 359, Loss: 0.6186365485191345, Final Batch Loss: 0.33118730783462524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360, Loss: 0.6216825544834137, Final Batch Loss: 0.29556167125701904\n",
      "Epoch 361, Loss: 0.6519550681114197, Final Batch Loss: 0.35062500834465027\n",
      "Epoch 362, Loss: 0.6352902948856354, Final Batch Loss: 0.26095759868621826\n",
      "Epoch 363, Loss: 0.5763691663742065, Final Batch Loss: 0.2627629041671753\n",
      "Epoch 364, Loss: 0.611301988363266, Final Batch Loss: 0.2773798108100891\n",
      "Epoch 365, Loss: 0.601038247346878, Final Batch Loss: 0.2820705771446228\n",
      "Epoch 366, Loss: 0.5867957770824432, Final Batch Loss: 0.27291637659072876\n",
      "Epoch 367, Loss: 0.6321539580821991, Final Batch Loss: 0.34069326519966125\n",
      "Epoch 368, Loss: 0.5366683751344681, Final Batch Loss: 0.22047816216945648\n",
      "Epoch 369, Loss: 0.5943033993244171, Final Batch Loss: 0.28367337584495544\n",
      "Epoch 370, Loss: 0.66403529047966, Final Batch Loss: 0.32969969511032104\n",
      "Epoch 371, Loss: 0.6488195657730103, Final Batch Loss: 0.314433753490448\n",
      "Epoch 372, Loss: 0.6690360307693481, Final Batch Loss: 0.3579172194004059\n",
      "Epoch 373, Loss: 0.5720158517360687, Final Batch Loss: 0.2702048122882843\n",
      "Epoch 374, Loss: 0.672809362411499, Final Batch Loss: 0.34296438097953796\n",
      "Epoch 375, Loss: 0.6101392209529877, Final Batch Loss: 0.2980305850505829\n",
      "Epoch 376, Loss: 0.6731874048709869, Final Batch Loss: 0.35499948263168335\n",
      "Epoch 377, Loss: 0.6923411190509796, Final Batch Loss: 0.40037786960601807\n",
      "Epoch 378, Loss: 0.5742943733930588, Final Batch Loss: 0.24914182722568512\n",
      "Epoch 379, Loss: 0.6228888928890228, Final Batch Loss: 0.2926405370235443\n",
      "Epoch 380, Loss: 0.5991314053535461, Final Batch Loss: 0.34145382046699524\n",
      "Epoch 381, Loss: 0.6247826218605042, Final Batch Loss: 0.2960520088672638\n",
      "Epoch 382, Loss: 0.5729316771030426, Final Batch Loss: 0.3100488781929016\n",
      "Epoch 383, Loss: 0.5381923615932465, Final Batch Loss: 0.2917376160621643\n",
      "Epoch 384, Loss: 0.5963141024112701, Final Batch Loss: 0.27847275137901306\n",
      "Epoch 385, Loss: 0.5692794024944305, Final Batch Loss: 0.2501088082790375\n",
      "Epoch 386, Loss: 0.5525052547454834, Final Batch Loss: 0.25566089153289795\n",
      "Epoch 387, Loss: 0.5818884968757629, Final Batch Loss: 0.30703631043434143\n",
      "Epoch 388, Loss: 0.676811546087265, Final Batch Loss: 0.3634255826473236\n",
      "Epoch 389, Loss: 0.627865731716156, Final Batch Loss: 0.3051803708076477\n",
      "Epoch 390, Loss: 0.5709596425294876, Final Batch Loss: 0.24269627034664154\n",
      "Epoch 391, Loss: 0.6143004596233368, Final Batch Loss: 0.28215429186820984\n",
      "Epoch 392, Loss: 0.6238991022109985, Final Batch Loss: 0.3258398175239563\n",
      "Epoch 393, Loss: 0.638919860124588, Final Batch Loss: 0.33301180601119995\n",
      "Epoch 394, Loss: 0.7062177360057831, Final Batch Loss: 0.3761041462421417\n",
      "Epoch 395, Loss: 0.6150818467140198, Final Batch Loss: 0.30042389035224915\n",
      "Epoch 396, Loss: 0.6093275845050812, Final Batch Loss: 0.3025415241718292\n",
      "Epoch 397, Loss: 0.5726586580276489, Final Batch Loss: 0.2909362316131592\n",
      "Epoch 398, Loss: 0.6172875463962555, Final Batch Loss: 0.310747891664505\n",
      "Epoch 399, Loss: 0.5882578492164612, Final Batch Loss: 0.28825539350509644\n",
      "Epoch 400, Loss: 0.6925598978996277, Final Batch Loss: 0.37163686752319336\n",
      "Epoch 401, Loss: 0.5770700871944427, Final Batch Loss: 0.27946415543556213\n",
      "Epoch 402, Loss: 0.6066171526908875, Final Batch Loss: 0.33023297786712646\n",
      "Epoch 403, Loss: 0.5799100399017334, Final Batch Loss: 0.2967657744884491\n",
      "Epoch 404, Loss: 0.547114297747612, Final Batch Loss: 0.22150982916355133\n",
      "Epoch 405, Loss: 0.5598139464855194, Final Batch Loss: 0.2635476589202881\n",
      "Epoch 406, Loss: 0.6823699474334717, Final Batch Loss: 0.37355268001556396\n",
      "Epoch 407, Loss: 0.56324303150177, Final Batch Loss: 0.2505415380001068\n",
      "Epoch 408, Loss: 0.5948246121406555, Final Batch Loss: 0.2837180197238922\n",
      "Epoch 409, Loss: 0.5910897552967072, Final Batch Loss: 0.331983357667923\n",
      "Epoch 410, Loss: 0.5536593943834305, Final Batch Loss: 0.2273184210062027\n",
      "Epoch 411, Loss: 0.6030001044273376, Final Batch Loss: 0.33456581830978394\n",
      "Epoch 412, Loss: 0.598991870880127, Final Batch Loss: 0.26349711418151855\n",
      "Epoch 413, Loss: 0.5828681886196136, Final Batch Loss: 0.3259640634059906\n",
      "Epoch 414, Loss: 0.6038215756416321, Final Batch Loss: 0.32573816180229187\n",
      "Epoch 415, Loss: 0.5416075736284256, Final Batch Loss: 0.23099182546138763\n",
      "Epoch 416, Loss: 0.5691710412502289, Final Batch Loss: 0.34279772639274597\n",
      "Epoch 417, Loss: 0.5798806250095367, Final Batch Loss: 0.2985835373401642\n",
      "Epoch 418, Loss: 0.5605437457561493, Final Batch Loss: 0.29224079847335815\n",
      "Epoch 419, Loss: 0.5535636246204376, Final Batch Loss: 0.2939804196357727\n",
      "Epoch 420, Loss: 0.6030959784984589, Final Batch Loss: 0.28770068287849426\n",
      "Epoch 421, Loss: 0.5484901666641235, Final Batch Loss: 0.2735622823238373\n",
      "Epoch 422, Loss: 0.6062401235103607, Final Batch Loss: 0.321479856967926\n",
      "Epoch 423, Loss: 0.545159712433815, Final Batch Loss: 0.3063868284225464\n",
      "Epoch 424, Loss: 0.5349750220775604, Final Batch Loss: 0.2653822898864746\n",
      "Epoch 425, Loss: 0.513823851943016, Final Batch Loss: 0.22492699325084686\n",
      "Epoch 426, Loss: 0.61472487449646, Final Batch Loss: 0.34217897057533264\n",
      "Epoch 427, Loss: 0.5381505787372589, Final Batch Loss: 0.26555830240249634\n",
      "Epoch 428, Loss: 0.560710608959198, Final Batch Loss: 0.29790645837783813\n",
      "Epoch 429, Loss: 0.5164152383804321, Final Batch Loss: 0.21757614612579346\n",
      "Epoch 430, Loss: 0.5187831223011017, Final Batch Loss: 0.23862722516059875\n",
      "Epoch 431, Loss: 0.5478046834468842, Final Batch Loss: 0.27355027198791504\n",
      "Epoch 432, Loss: 0.5205638408660889, Final Batch Loss: 0.26642146706581116\n",
      "Epoch 433, Loss: 0.5542748868465424, Final Batch Loss: 0.29537132382392883\n",
      "Epoch 434, Loss: 0.5245819687843323, Final Batch Loss: 0.2551800310611725\n",
      "Epoch 435, Loss: 0.5691551268100739, Final Batch Loss: 0.24911201000213623\n",
      "Epoch 436, Loss: 0.585846871137619, Final Batch Loss: 0.3317224383354187\n",
      "Epoch 437, Loss: 0.5991343855857849, Final Batch Loss: 0.3071501851081848\n",
      "Epoch 438, Loss: 0.528770312666893, Final Batch Loss: 0.23580314218997955\n",
      "Epoch 439, Loss: 0.5061827301979065, Final Batch Loss: 0.2516889274120331\n",
      "Epoch 440, Loss: 0.544438511133194, Final Batch Loss: 0.2529207766056061\n",
      "Epoch 441, Loss: 0.5117916166782379, Final Batch Loss: 0.27980899810791016\n",
      "Epoch 442, Loss: 0.5800707638263702, Final Batch Loss: 0.32395705580711365\n",
      "Epoch 443, Loss: 0.5697343051433563, Final Batch Loss: 0.306888610124588\n",
      "Epoch 444, Loss: 0.5902398228645325, Final Batch Loss: 0.3119576871395111\n",
      "Epoch 445, Loss: 0.5200661718845367, Final Batch Loss: 0.26512134075164795\n",
      "Epoch 446, Loss: 0.539996862411499, Final Batch Loss: 0.2511540949344635\n",
      "Epoch 447, Loss: 0.5378695428371429, Final Batch Loss: 0.2830321490764618\n",
      "Epoch 448, Loss: 0.5617998093366623, Final Batch Loss: 0.2444324642419815\n",
      "Epoch 449, Loss: 0.5351270735263824, Final Batch Loss: 0.2613958418369293\n",
      "Epoch 450, Loss: 0.5964491963386536, Final Batch Loss: 0.30417123436927795\n",
      "Epoch 451, Loss: 0.5842172652482986, Final Batch Loss: 0.35518717765808105\n",
      "Epoch 452, Loss: 0.5546189695596695, Final Batch Loss: 0.3151940405368805\n",
      "Epoch 453, Loss: 0.5423791706562042, Final Batch Loss: 0.24803921580314636\n",
      "Epoch 454, Loss: 0.5872528553009033, Final Batch Loss: 0.3000810146331787\n",
      "Epoch 455, Loss: 0.5713834464550018, Final Batch Loss: 0.32544422149658203\n",
      "Epoch 456, Loss: 0.5845916569232941, Final Batch Loss: 0.2762930989265442\n",
      "Epoch 457, Loss: 0.5776180922985077, Final Batch Loss: 0.282069593667984\n",
      "Epoch 458, Loss: 0.49200770258903503, Final Batch Loss: 0.23837026953697205\n",
      "Epoch 459, Loss: 0.5532943606376648, Final Batch Loss: 0.2641497850418091\n",
      "Epoch 460, Loss: 0.4948820471763611, Final Batch Loss: 0.22444286942481995\n",
      "Epoch 461, Loss: 0.4958144873380661, Final Batch Loss: 0.20329271256923676\n",
      "Epoch 462, Loss: 0.5339290797710419, Final Batch Loss: 0.2545733153820038\n",
      "Epoch 463, Loss: 0.5655329823493958, Final Batch Loss: 0.3041270971298218\n",
      "Epoch 464, Loss: 0.5358009338378906, Final Batch Loss: 0.2886413633823395\n",
      "Epoch 465, Loss: 0.5181477665901184, Final Batch Loss: 0.21706101298332214\n",
      "Epoch 466, Loss: 0.5242213010787964, Final Batch Loss: 0.2469075322151184\n",
      "Epoch 467, Loss: 0.5719005167484283, Final Batch Loss: 0.28669190406799316\n",
      "Epoch 468, Loss: 0.51298388838768, Final Batch Loss: 0.22935158014297485\n",
      "Epoch 469, Loss: 0.5521241426467896, Final Batch Loss: 0.294289231300354\n",
      "Epoch 470, Loss: 0.5480660200119019, Final Batch Loss: 0.26438045501708984\n",
      "Epoch 471, Loss: 0.531127393245697, Final Batch Loss: 0.27162984013557434\n",
      "Epoch 472, Loss: 0.556140810251236, Final Batch Loss: 0.29301920533180237\n",
      "Epoch 473, Loss: 0.5310014635324478, Final Batch Loss: 0.24508436024188995\n",
      "Epoch 474, Loss: 0.5621004700660706, Final Batch Loss: 0.3063943088054657\n",
      "Epoch 475, Loss: 0.49681568145751953, Final Batch Loss: 0.2156762182712555\n",
      "Epoch 476, Loss: 0.5164379775524139, Final Batch Loss: 0.2640445828437805\n",
      "Epoch 477, Loss: 0.506192073225975, Final Batch Loss: 0.2322029322385788\n",
      "Epoch 478, Loss: 0.5122459828853607, Final Batch Loss: 0.26100611686706543\n",
      "Epoch 479, Loss: 0.5636849403381348, Final Batch Loss: 0.24370625615119934\n",
      "Epoch 480, Loss: 0.5289708524942398, Final Batch Loss: 0.23043017089366913\n",
      "Epoch 481, Loss: 0.49143774807453156, Final Batch Loss: 0.237517312169075\n",
      "Epoch 482, Loss: 0.5405406355857849, Final Batch Loss: 0.29008108377456665\n",
      "Epoch 483, Loss: 0.5533871650695801, Final Batch Loss: 0.3247939944267273\n",
      "Epoch 484, Loss: 0.6990146040916443, Final Batch Loss: 0.3592948913574219\n",
      "Epoch 485, Loss: 0.5138205885887146, Final Batch Loss: 0.28830257058143616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486, Loss: 0.5208021402359009, Final Batch Loss: 0.28566116094589233\n",
      "Epoch 487, Loss: 0.5437843501567841, Final Batch Loss: 0.24345055222511292\n",
      "Epoch 488, Loss: 0.5624257922172546, Final Batch Loss: 0.33774974942207336\n",
      "Epoch 489, Loss: 0.5221356302499771, Final Batch Loss: 0.29093897342681885\n",
      "Epoch 490, Loss: 0.5012147575616837, Final Batch Loss: 0.20549754798412323\n",
      "Epoch 491, Loss: 0.5228656232357025, Final Batch Loss: 0.27310910820961\n",
      "Epoch 492, Loss: 0.5065844506025314, Final Batch Loss: 0.2687583565711975\n",
      "Epoch 493, Loss: 0.6159967482089996, Final Batch Loss: 0.3778725862503052\n",
      "Epoch 494, Loss: 0.45843377709388733, Final Batch Loss: 0.23520977795124054\n",
      "Epoch 495, Loss: 0.541085347533226, Final Batch Loss: 0.1942162662744522\n",
      "Epoch 496, Loss: 0.46951794624328613, Final Batch Loss: 0.20273825526237488\n",
      "Epoch 497, Loss: 0.5078954100608826, Final Batch Loss: 0.24704325199127197\n",
      "Epoch 498, Loss: 0.5250839591026306, Final Batch Loss: 0.257376492023468\n",
      "Epoch 499, Loss: 0.526932030916214, Final Batch Loss: 0.26452088356018066\n",
      "Epoch 500, Loss: 0.5346793234348297, Final Batch Loss: 0.2637696862220764\n",
      "Epoch 501, Loss: 0.502624586224556, Final Batch Loss: 0.2395407110452652\n",
      "Epoch 502, Loss: 0.5312947779893875, Final Batch Loss: 0.28770720958709717\n",
      "Epoch 503, Loss: 0.49974313378334045, Final Batch Loss: 0.24946516752243042\n",
      "Epoch 504, Loss: 0.5194649547338486, Final Batch Loss: 0.27055174112319946\n",
      "Epoch 505, Loss: 0.5057395994663239, Final Batch Loss: 0.25371989607810974\n",
      "Epoch 506, Loss: 0.49664174020290375, Final Batch Loss: 0.22929994761943817\n",
      "Epoch 507, Loss: 0.5143033713102341, Final Batch Loss: 0.2916877865791321\n",
      "Epoch 508, Loss: 0.44826628267765045, Final Batch Loss: 0.19624947011470795\n",
      "Epoch 509, Loss: 0.472793310880661, Final Batch Loss: 0.20952904224395752\n",
      "Epoch 510, Loss: 0.5627245455980301, Final Batch Loss: 0.3327207863330841\n",
      "Epoch 511, Loss: 0.46626368165016174, Final Batch Loss: 0.22530657052993774\n",
      "Epoch 512, Loss: 0.46488161385059357, Final Batch Loss: 0.2197844684123993\n",
      "Epoch 513, Loss: 0.5590796172618866, Final Batch Loss: 0.30494046211242676\n",
      "Epoch 514, Loss: 0.4240475445985794, Final Batch Loss: 0.1825128197669983\n",
      "Epoch 515, Loss: 0.5105510801076889, Final Batch Loss: 0.2652328610420227\n",
      "Epoch 516, Loss: 0.5336881726980209, Final Batch Loss: 0.29419898986816406\n",
      "Epoch 517, Loss: 0.5232409685850143, Final Batch Loss: 0.21694542467594147\n",
      "Epoch 518, Loss: 0.45323625206947327, Final Batch Loss: 0.24132846295833588\n",
      "Epoch 519, Loss: 0.5001690685749054, Final Batch Loss: 0.24301862716674805\n",
      "Epoch 520, Loss: 0.5946029722690582, Final Batch Loss: 0.3263685405254364\n",
      "Epoch 521, Loss: 0.5682361721992493, Final Batch Loss: 0.3053133487701416\n",
      "Epoch 522, Loss: 0.5751143097877502, Final Batch Loss: 0.3065027892589569\n",
      "Epoch 523, Loss: 0.5448535978794098, Final Batch Loss: 0.3157070279121399\n",
      "Epoch 524, Loss: 0.5344041436910629, Final Batch Loss: 0.3248226046562195\n",
      "Epoch 525, Loss: 0.5018222779035568, Final Batch Loss: 0.2223690301179886\n",
      "Epoch 526, Loss: 0.4727017879486084, Final Batch Loss: 0.23424658179283142\n",
      "Epoch 527, Loss: 0.509796679019928, Final Batch Loss: 0.2762598991394043\n",
      "Epoch 528, Loss: 0.5397784113883972, Final Batch Loss: 0.2855446934700012\n",
      "Epoch 529, Loss: 0.501261830329895, Final Batch Loss: 0.22219958901405334\n",
      "Epoch 530, Loss: 0.49952246248722076, Final Batch Loss: 0.24616603553295135\n",
      "Epoch 531, Loss: 0.5278348624706268, Final Batch Loss: 0.28580909967422485\n",
      "Epoch 532, Loss: 0.5332958698272705, Final Batch Loss: 0.3008241653442383\n",
      "Epoch 533, Loss: 0.5592541396617889, Final Batch Loss: 0.31592434644699097\n",
      "Epoch 534, Loss: 0.4831739217042923, Final Batch Loss: 0.22223271429538727\n",
      "Epoch 535, Loss: 0.5162152647972107, Final Batch Loss: 0.256210058927536\n",
      "Epoch 536, Loss: 0.5053671151399612, Final Batch Loss: 0.2498277872800827\n",
      "Epoch 537, Loss: 0.4979296624660492, Final Batch Loss: 0.24053367972373962\n",
      "Epoch 538, Loss: 0.5247022062540054, Final Batch Loss: 0.2803508937358856\n",
      "Epoch 539, Loss: 0.46698909997940063, Final Batch Loss: 0.2039441466331482\n",
      "Epoch 540, Loss: 0.4608762413263321, Final Batch Loss: 0.2165859341621399\n",
      "Epoch 541, Loss: 0.43781712651252747, Final Batch Loss: 0.22064240276813507\n",
      "Epoch 542, Loss: 0.46700286865234375, Final Batch Loss: 0.2444305419921875\n",
      "Epoch 543, Loss: 0.48081016540527344, Final Batch Loss: 0.2425784021615982\n",
      "Epoch 544, Loss: 0.49915623664855957, Final Batch Loss: 0.22453084588050842\n",
      "Epoch 545, Loss: 0.47029270231723785, Final Batch Loss: 0.21708758175373077\n",
      "Epoch 546, Loss: 0.5628274381160736, Final Batch Loss: 0.27305424213409424\n",
      "Epoch 547, Loss: 0.4996910095214844, Final Batch Loss: 0.2528185248374939\n",
      "Epoch 548, Loss: 0.5474664568901062, Final Batch Loss: 0.26545506715774536\n",
      "Epoch 549, Loss: 0.5147385001182556, Final Batch Loss: 0.2555551528930664\n",
      "Epoch 550, Loss: 0.45618852972984314, Final Batch Loss: 0.2239583134651184\n",
      "Epoch 551, Loss: 0.49189431965351105, Final Batch Loss: 0.2092447429895401\n",
      "Epoch 552, Loss: 0.5198796391487122, Final Batch Loss: 0.2797693610191345\n",
      "Epoch 553, Loss: 0.4459063410758972, Final Batch Loss: 0.19172143936157227\n",
      "Epoch 554, Loss: 0.5193704217672348, Final Batch Loss: 0.2793288230895996\n",
      "Epoch 555, Loss: 0.49395333230495453, Final Batch Loss: 0.23314084112644196\n",
      "Epoch 556, Loss: 0.45121435821056366, Final Batch Loss: 0.20268213748931885\n",
      "Epoch 557, Loss: 0.5075476765632629, Final Batch Loss: 0.24575883150100708\n",
      "Epoch 558, Loss: 0.45548850297927856, Final Batch Loss: 0.24754320085048676\n",
      "Epoch 559, Loss: 0.5275743305683136, Final Batch Loss: 0.2469499707221985\n",
      "Epoch 560, Loss: 0.5110901892185211, Final Batch Loss: 0.2763844430446625\n",
      "Epoch 561, Loss: 0.5018034726381302, Final Batch Loss: 0.2613346576690674\n",
      "Epoch 562, Loss: 0.48553961515426636, Final Batch Loss: 0.23556560277938843\n",
      "Epoch 563, Loss: 0.4814710021018982, Final Batch Loss: 0.21999776363372803\n",
      "Epoch 564, Loss: 0.5224339365959167, Final Batch Loss: 0.26753678917884827\n",
      "Epoch 565, Loss: 0.4517015963792801, Final Batch Loss: 0.1797485500574112\n",
      "Epoch 566, Loss: 0.48789267241954803, Final Batch Loss: 0.22592361271381378\n",
      "Epoch 567, Loss: 0.43461574614048004, Final Batch Loss: 0.18749406933784485\n",
      "Epoch 568, Loss: 0.4947739988565445, Final Batch Loss: 0.2132311910390854\n",
      "Epoch 569, Loss: 0.5190808326005936, Final Batch Loss: 0.27059170603752136\n",
      "Epoch 570, Loss: 0.49109965562820435, Final Batch Loss: 0.2256951928138733\n",
      "Epoch 571, Loss: 0.4604250639677048, Final Batch Loss: 0.23996765911579132\n",
      "Epoch 572, Loss: 0.47126252949237823, Final Batch Loss: 0.22853323817253113\n",
      "Epoch 573, Loss: 0.46835173666477203, Final Batch Loss: 0.2666355073451996\n",
      "Epoch 574, Loss: 0.5058971047401428, Final Batch Loss: 0.22303330898284912\n",
      "Epoch 575, Loss: 0.466510072350502, Final Batch Loss: 0.22024817764759064\n",
      "Epoch 576, Loss: 0.559540182352066, Final Batch Loss: 0.2726723849773407\n",
      "Epoch 577, Loss: 0.44993050396442413, Final Batch Loss: 0.23183771967887878\n",
      "Epoch 578, Loss: 0.5458719283342361, Final Batch Loss: 0.29633626341819763\n",
      "Epoch 579, Loss: 0.46546725928783417, Final Batch Loss: 0.20947767794132233\n",
      "Epoch 580, Loss: 0.5011105388402939, Final Batch Loss: 0.28690287470817566\n",
      "Epoch 581, Loss: 0.5265171825885773, Final Batch Loss: 0.24309292435646057\n",
      "Epoch 582, Loss: 0.5074128061532974, Final Batch Loss: 0.20860455930233002\n",
      "Epoch 583, Loss: 0.5210447311401367, Final Batch Loss: 0.26746293902397156\n",
      "Epoch 584, Loss: 0.49394817650318146, Final Batch Loss: 0.19741655886173248\n",
      "Epoch 585, Loss: 0.5280043333768845, Final Batch Loss: 0.2267768532037735\n",
      "Epoch 586, Loss: 0.4698103666305542, Final Batch Loss: 0.2428686022758484\n",
      "Epoch 587, Loss: 0.4877663850784302, Final Batch Loss: 0.24262523651123047\n",
      "Epoch 588, Loss: 0.4565579891204834, Final Batch Loss: 0.2138749063014984\n",
      "Epoch 589, Loss: 0.4777135103940964, Final Batch Loss: 0.2632397413253784\n",
      "Epoch 590, Loss: 0.4828169643878937, Final Batch Loss: 0.22777214646339417\n",
      "Epoch 591, Loss: 0.4933595657348633, Final Batch Loss: 0.24868954718112946\n",
      "Epoch 592, Loss: 0.46844688057899475, Final Batch Loss: 0.24360647797584534\n",
      "Epoch 593, Loss: 0.5365357398986816, Final Batch Loss: 0.2839057445526123\n",
      "Epoch 594, Loss: 0.5403222143650055, Final Batch Loss: 0.27458253502845764\n",
      "Epoch 595, Loss: 0.4940759688615799, Final Batch Loss: 0.21015121042728424\n",
      "Epoch 596, Loss: 0.5242220759391785, Final Batch Loss: 0.2693357765674591\n",
      "Epoch 597, Loss: 0.4527788609266281, Final Batch Loss: 0.19349811971187592\n",
      "Epoch 598, Loss: 0.47255952656269073, Final Batch Loss: 0.22724215686321259\n",
      "Epoch 599, Loss: 0.4539961665868759, Final Batch Loss: 0.23610088229179382\n",
      "Epoch 600, Loss: 0.45560912787914276, Final Batch Loss: 0.24034234881401062\n",
      "Epoch 601, Loss: 0.40910547971725464, Final Batch Loss: 0.1600756049156189\n",
      "Epoch 602, Loss: 0.4436529874801636, Final Batch Loss: 0.22647695243358612\n",
      "Epoch 603, Loss: 0.47545553743839264, Final Batch Loss: 0.2235363870859146\n",
      "Epoch 604, Loss: 0.4985715299844742, Final Batch Loss: 0.2548867166042328\n",
      "Epoch 605, Loss: 0.4537583440542221, Final Batch Loss: 0.2182905524969101\n",
      "Epoch 606, Loss: 0.4683161675930023, Final Batch Loss: 0.20092672109603882\n",
      "Epoch 607, Loss: 0.503271222114563, Final Batch Loss: 0.22899708151817322\n",
      "Epoch 608, Loss: 0.410026490688324, Final Batch Loss: 0.19128718972206116\n",
      "Epoch 609, Loss: 0.47004151344299316, Final Batch Loss: 0.22776614129543304\n",
      "Epoch 610, Loss: 0.5357505679130554, Final Batch Loss: 0.264832079410553\n",
      "Epoch 611, Loss: 0.49765031039714813, Final Batch Loss: 0.2721828818321228\n",
      "Epoch 612, Loss: 0.4837856590747833, Final Batch Loss: 0.2808310091495514\n",
      "Epoch 613, Loss: 0.6036884188652039, Final Batch Loss: 0.31712576746940613\n",
      "Epoch 614, Loss: 0.45412378013134, Final Batch Loss: 0.21127773821353912\n",
      "Epoch 615, Loss: 0.588215172290802, Final Batch Loss: 0.31454455852508545\n",
      "Epoch 616, Loss: 0.5128737986087799, Final Batch Loss: 0.26085397601127625\n",
      "Epoch 617, Loss: 0.4874066114425659, Final Batch Loss: 0.21786925196647644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 618, Loss: 0.5000149607658386, Final Batch Loss: 0.3059496581554413\n",
      "Epoch 619, Loss: 0.5705296099185944, Final Batch Loss: 0.30050423741340637\n",
      "Epoch 620, Loss: 0.5194015949964523, Final Batch Loss: 0.2854999005794525\n",
      "Epoch 621, Loss: 0.44502751529216766, Final Batch Loss: 0.21436341106891632\n",
      "Epoch 622, Loss: 0.5097673833370209, Final Batch Loss: 0.2896393835544586\n",
      "Epoch 623, Loss: 0.45953014492988586, Final Batch Loss: 0.20925676822662354\n",
      "Epoch 624, Loss: 0.5098540782928467, Final Batch Loss: 0.27051034569740295\n",
      "Epoch 625, Loss: 0.5255498886108398, Final Batch Loss: 0.24816933274269104\n",
      "Epoch 626, Loss: 0.4778811186552048, Final Batch Loss: 0.2815052568912506\n",
      "Epoch 627, Loss: 0.4678945392370224, Final Batch Loss: 0.24195683002471924\n",
      "Epoch 628, Loss: 0.47441886365413666, Final Batch Loss: 0.2329682856798172\n",
      "Epoch 629, Loss: 0.5083536803722382, Final Batch Loss: 0.25877705216407776\n",
      "Epoch 630, Loss: 0.4825414568185806, Final Batch Loss: 0.21964921057224274\n",
      "Epoch 631, Loss: 0.4481663107872009, Final Batch Loss: 0.2208949625492096\n",
      "Epoch 632, Loss: 0.5077966004610062, Final Batch Loss: 0.2776350677013397\n",
      "Epoch 633, Loss: 0.43340781331062317, Final Batch Loss: 0.20978793501853943\n",
      "Epoch 634, Loss: 0.5036958456039429, Final Batch Loss: 0.25909513235092163\n",
      "Epoch 635, Loss: 0.4764772802591324, Final Batch Loss: 0.24866056442260742\n",
      "Epoch 636, Loss: 0.4803948253393173, Final Batch Loss: 0.27187401056289673\n",
      "Epoch 637, Loss: 0.4861893653869629, Final Batch Loss: 0.2959910035133362\n",
      "Epoch 638, Loss: 0.5044487714767456, Final Batch Loss: 0.25005972385406494\n",
      "Epoch 639, Loss: 0.5012023895978928, Final Batch Loss: 0.29259660840034485\n",
      "Epoch 640, Loss: 0.45319582521915436, Final Batch Loss: 0.2478923350572586\n",
      "Epoch 641, Loss: 0.4586543142795563, Final Batch Loss: 0.2455371618270874\n",
      "Epoch 642, Loss: 0.4520988315343857, Final Batch Loss: 0.2483285516500473\n",
      "Epoch 643, Loss: 0.4414426237344742, Final Batch Loss: 0.2140250951051712\n",
      "Epoch 644, Loss: 0.43032145500183105, Final Batch Loss: 0.19224293529987335\n",
      "Epoch 645, Loss: 0.4334208816289902, Final Batch Loss: 0.21703623235225677\n",
      "Epoch 646, Loss: 0.4377061724662781, Final Batch Loss: 0.19687677919864655\n",
      "Epoch 647, Loss: 0.4506765604019165, Final Batch Loss: 0.21257229149341583\n",
      "Epoch 648, Loss: 0.5282342582941055, Final Batch Loss: 0.29186007380485535\n",
      "Epoch 649, Loss: 0.48415407538414, Final Batch Loss: 0.2617756724357605\n",
      "Epoch 650, Loss: 0.4382752329111099, Final Batch Loss: 0.24886082112789154\n",
      "Epoch 651, Loss: 0.46347418427467346, Final Batch Loss: 0.2505994737148285\n",
      "Epoch 652, Loss: 0.4272589683532715, Final Batch Loss: 0.20165210962295532\n",
      "Epoch 653, Loss: 0.4643376022577286, Final Batch Loss: 0.2592931389808655\n",
      "Epoch 654, Loss: 0.45689961314201355, Final Batch Loss: 0.21509219706058502\n",
      "Epoch 655, Loss: 0.5083915293216705, Final Batch Loss: 0.2843945026397705\n",
      "Epoch 656, Loss: 0.46935316920280457, Final Batch Loss: 0.216842383146286\n",
      "Epoch 657, Loss: 0.49513909220695496, Final Batch Loss: 0.26989319920539856\n",
      "Epoch 658, Loss: 0.5107322633266449, Final Batch Loss: 0.2609914243221283\n",
      "Epoch 659, Loss: 0.42332184314727783, Final Batch Loss: 0.18086041510105133\n",
      "Epoch 660, Loss: 0.44497814774513245, Final Batch Loss: 0.22519606351852417\n",
      "Epoch 661, Loss: 0.46320322155952454, Final Batch Loss: 0.23854048550128937\n",
      "Epoch 662, Loss: 0.4530896097421646, Final Batch Loss: 0.2332683503627777\n",
      "Epoch 663, Loss: 0.42475426197052, Final Batch Loss: 0.1790863573551178\n",
      "Epoch 664, Loss: 0.5370655059814453, Final Batch Loss: 0.3295852541923523\n",
      "Epoch 665, Loss: 0.5567465871572495, Final Batch Loss: 0.334006667137146\n",
      "Epoch 666, Loss: 0.4450906217098236, Final Batch Loss: 0.2081741988658905\n",
      "Epoch 667, Loss: 0.4073393791913986, Final Batch Loss: 0.19914700090885162\n",
      "Epoch 668, Loss: 0.46635086834430695, Final Batch Loss: 0.16403518617153168\n",
      "Epoch 669, Loss: 0.4721504896879196, Final Batch Loss: 0.23147925734519958\n",
      "Epoch 670, Loss: 0.42800454795360565, Final Batch Loss: 0.21714206039905548\n",
      "Epoch 671, Loss: 0.4038872867822647, Final Batch Loss: 0.19580726325511932\n",
      "Epoch 672, Loss: 0.45719414949417114, Final Batch Loss: 0.2707716226577759\n",
      "Epoch 673, Loss: 0.42892469465732574, Final Batch Loss: 0.20862945914268494\n",
      "Epoch 674, Loss: 0.4625464230775833, Final Batch Loss: 0.21309682726860046\n",
      "Epoch 675, Loss: 0.40434442460536957, Final Batch Loss: 0.20181068778038025\n",
      "Epoch 676, Loss: 0.4515244960784912, Final Batch Loss: 0.22005490958690643\n",
      "Epoch 677, Loss: 0.4854429215192795, Final Batch Loss: 0.20981235802173615\n",
      "Epoch 678, Loss: 0.42520108819007874, Final Batch Loss: 0.2089020311832428\n",
      "Epoch 679, Loss: 0.4555314779281616, Final Batch Loss: 0.2176688015460968\n",
      "Epoch 680, Loss: 0.4670272767543793, Final Batch Loss: 0.25860995054244995\n",
      "Epoch 681, Loss: 0.48280467092990875, Final Batch Loss: 0.24847197532653809\n",
      "Epoch 682, Loss: 0.4755769819021225, Final Batch Loss: 0.2369355857372284\n",
      "Epoch 683, Loss: 0.46168795228004456, Final Batch Loss: 0.20739763975143433\n",
      "Epoch 684, Loss: 0.4439181834459305, Final Batch Loss: 0.20655161142349243\n",
      "Epoch 685, Loss: 0.42538100481033325, Final Batch Loss: 0.1774352341890335\n",
      "Epoch 686, Loss: 0.40865014493465424, Final Batch Loss: 0.194274440407753\n",
      "Epoch 687, Loss: 0.4862529933452606, Final Batch Loss: 0.2436903566122055\n",
      "Epoch 688, Loss: 0.43743273615837097, Final Batch Loss: 0.2633269727230072\n",
      "Epoch 689, Loss: 0.4116276353597641, Final Batch Loss: 0.1989060491323471\n",
      "Epoch 690, Loss: 0.4267825186252594, Final Batch Loss: 0.2062915414571762\n",
      "Epoch 691, Loss: 0.4357497990131378, Final Batch Loss: 0.21359805762767792\n",
      "Epoch 692, Loss: 0.4748639166355133, Final Batch Loss: 0.23503939807415009\n",
      "Epoch 693, Loss: 0.4186215102672577, Final Batch Loss: 0.1892189383506775\n",
      "Epoch 694, Loss: 0.4365914314985275, Final Batch Loss: 0.25009462237358093\n",
      "Epoch 695, Loss: 0.44830894470214844, Final Batch Loss: 0.18325871229171753\n",
      "Epoch 696, Loss: 0.4483783394098282, Final Batch Loss: 0.20902346074581146\n",
      "Epoch 697, Loss: 0.41405634582042694, Final Batch Loss: 0.2114408016204834\n",
      "Epoch 698, Loss: 0.4327806383371353, Final Batch Loss: 0.17557992041110992\n",
      "Epoch 699, Loss: 0.4129909574985504, Final Batch Loss: 0.18535923957824707\n",
      "Epoch 700, Loss: 0.45582643151283264, Final Batch Loss: 0.2605147659778595\n",
      "Epoch 701, Loss: 0.45659081637859344, Final Batch Loss: 0.24158422648906708\n",
      "Epoch 702, Loss: 0.46275366842746735, Final Batch Loss: 0.23300005495548248\n",
      "Epoch 703, Loss: 0.5009366571903229, Final Batch Loss: 0.32249993085861206\n",
      "Epoch 704, Loss: 0.44919440150260925, Final Batch Loss: 0.17968347668647766\n",
      "Epoch 705, Loss: 0.4598131626844406, Final Batch Loss: 0.2512882947921753\n",
      "Epoch 706, Loss: 0.4395880848169327, Final Batch Loss: 0.19030335545539856\n",
      "Epoch 707, Loss: 0.4631074219942093, Final Batch Loss: 0.24221108853816986\n",
      "Epoch 708, Loss: 0.4278814196586609, Final Batch Loss: 0.20091784000396729\n",
      "Epoch 709, Loss: 0.42019379138946533, Final Batch Loss: 0.2319622039794922\n",
      "Epoch 710, Loss: 0.4116222411394119, Final Batch Loss: 0.20014125108718872\n",
      "Epoch 711, Loss: 0.47683438658714294, Final Batch Loss: 0.2652888894081116\n",
      "Epoch 712, Loss: 0.47114719450473785, Final Batch Loss: 0.26291030645370483\n",
      "Epoch 713, Loss: 0.419879674911499, Final Batch Loss: 0.20448487997055054\n",
      "Epoch 714, Loss: 0.46621616184711456, Final Batch Loss: 0.2892681956291199\n",
      "Epoch 715, Loss: 0.4572027623653412, Final Batch Loss: 0.2619624137878418\n",
      "Epoch 716, Loss: 0.4264431446790695, Final Batch Loss: 0.22278815507888794\n",
      "Epoch 717, Loss: 0.4876551032066345, Final Batch Loss: 0.2695569694042206\n",
      "Epoch 718, Loss: 0.4402325451374054, Final Batch Loss: 0.22345659136772156\n",
      "Epoch 719, Loss: 0.4559168070554733, Final Batch Loss: 0.22768515348434448\n",
      "Epoch 720, Loss: 0.4394673556089401, Final Batch Loss: 0.25135117769241333\n",
      "Epoch 721, Loss: 0.41423487663269043, Final Batch Loss: 0.21660102903842926\n",
      "Epoch 722, Loss: 0.4915362298488617, Final Batch Loss: 0.23683372139930725\n",
      "Epoch 723, Loss: 0.40088528394699097, Final Batch Loss: 0.20321975648403168\n",
      "Epoch 724, Loss: 0.4778547137975693, Final Batch Loss: 0.24725498259067535\n",
      "Epoch 725, Loss: 0.4011412709951401, Final Batch Loss: 0.18610849976539612\n",
      "Epoch 726, Loss: 0.458165779709816, Final Batch Loss: 0.2583005726337433\n",
      "Epoch 727, Loss: 0.555150181055069, Final Batch Loss: 0.3779488205909729\n",
      "Epoch 728, Loss: 0.4034880995750427, Final Batch Loss: 0.2003961205482483\n",
      "Epoch 729, Loss: 0.4550931453704834, Final Batch Loss: 0.24445076286792755\n",
      "Epoch 730, Loss: 0.3923543393611908, Final Batch Loss: 0.18783028423786163\n",
      "Epoch 731, Loss: 0.3987082690000534, Final Batch Loss: 0.21187500655651093\n",
      "Epoch 732, Loss: 0.39383403956890106, Final Batch Loss: 0.18782180547714233\n",
      "Epoch 733, Loss: 0.4516051560640335, Final Batch Loss: 0.2697731852531433\n",
      "Epoch 734, Loss: 0.40121664106845856, Final Batch Loss: 0.1895115226507187\n",
      "Epoch 735, Loss: 0.40525150299072266, Final Batch Loss: 0.21729861199855804\n",
      "Epoch 736, Loss: 0.43614785373210907, Final Batch Loss: 0.20572839677333832\n",
      "Epoch 737, Loss: 0.39372146129608154, Final Batch Loss: 0.16537265479564667\n",
      "Epoch 738, Loss: 0.44900232553482056, Final Batch Loss: 0.22994785010814667\n",
      "Epoch 739, Loss: 0.44644924998283386, Final Batch Loss: 0.2346080094575882\n",
      "Epoch 740, Loss: 0.5007609724998474, Final Batch Loss: 0.3017033338546753\n",
      "Epoch 741, Loss: 0.4515179395675659, Final Batch Loss: 0.25593236088752747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742, Loss: 0.4310602396726608, Final Batch Loss: 0.19428151845932007\n",
      "Epoch 743, Loss: 0.44961075484752655, Final Batch Loss: 0.21975111961364746\n",
      "Epoch 744, Loss: 0.40738098323345184, Final Batch Loss: 0.21299631893634796\n",
      "Epoch 745, Loss: 0.4415315240621567, Final Batch Loss: 0.23719272017478943\n",
      "Epoch 746, Loss: 0.4424491226673126, Final Batch Loss: 0.2105753868818283\n",
      "Epoch 747, Loss: 0.45741865038871765, Final Batch Loss: 0.22912798821926117\n",
      "Epoch 748, Loss: 0.4044467806816101, Final Batch Loss: 0.16122762858867645\n",
      "Epoch 749, Loss: 0.42292067408561707, Final Batch Loss: 0.22609688341617584\n",
      "Epoch 750, Loss: 0.45915400981903076, Final Batch Loss: 0.2456670105457306\n",
      "Epoch 751, Loss: 0.3911829739809036, Final Batch Loss: 0.1630478799343109\n",
      "Epoch 752, Loss: 0.41639238595962524, Final Batch Loss: 0.2018224149942398\n",
      "Epoch 753, Loss: 0.48132410645484924, Final Batch Loss: 0.2839645743370056\n",
      "Epoch 754, Loss: 0.43169501423835754, Final Batch Loss: 0.22149311006069183\n",
      "Epoch 755, Loss: 0.43919335305690765, Final Batch Loss: 0.2506869435310364\n",
      "Epoch 756, Loss: 0.43540383875370026, Final Batch Loss: 0.21572187542915344\n",
      "Epoch 757, Loss: 0.46603627502918243, Final Batch Loss: 0.28286269307136536\n",
      "Epoch 758, Loss: 0.39450640976428986, Final Batch Loss: 0.16738629341125488\n",
      "Epoch 759, Loss: 0.4137927293777466, Final Batch Loss: 0.1814902424812317\n",
      "Epoch 760, Loss: 0.519657090306282, Final Batch Loss: 0.31646135449409485\n",
      "Epoch 761, Loss: 0.552202433347702, Final Batch Loss: 0.3245639204978943\n",
      "Epoch 762, Loss: 0.38760344684123993, Final Batch Loss: 0.18264225125312805\n",
      "Epoch 763, Loss: 0.3925365060567856, Final Batch Loss: 0.15398649871349335\n",
      "Epoch 764, Loss: 0.4261082410812378, Final Batch Loss: 0.2470022588968277\n",
      "Epoch 765, Loss: 0.4571843594312668, Final Batch Loss: 0.19061611592769623\n",
      "Epoch 766, Loss: 0.3990425020456314, Final Batch Loss: 0.21303129196166992\n",
      "Epoch 767, Loss: 0.41843949258327484, Final Batch Loss: 0.18382489681243896\n",
      "Epoch 768, Loss: 0.40253743529319763, Final Batch Loss: 0.17462018132209778\n",
      "Epoch 769, Loss: 0.445590540766716, Final Batch Loss: 0.24414856731891632\n",
      "Epoch 770, Loss: 0.4087490290403366, Final Batch Loss: 0.19430139660835266\n",
      "Epoch 771, Loss: 0.40753673017024994, Final Batch Loss: 0.1662965565919876\n",
      "Epoch 772, Loss: 0.4010535478591919, Final Batch Loss: 0.19168159365653992\n",
      "Epoch 773, Loss: 0.46737274527549744, Final Batch Loss: 0.2356647551059723\n",
      "Epoch 774, Loss: 0.3641176074743271, Final Batch Loss: 0.15085512399673462\n",
      "Epoch 775, Loss: 0.44413551688194275, Final Batch Loss: 0.21728958189487457\n",
      "Epoch 776, Loss: 0.4055172950029373, Final Batch Loss: 0.1391323357820511\n",
      "Epoch 777, Loss: 0.4025423228740692, Final Batch Loss: 0.16695822775363922\n",
      "Epoch 778, Loss: 0.41446933150291443, Final Batch Loss: 0.19130490720272064\n",
      "Epoch 779, Loss: 0.47207389771938324, Final Batch Loss: 0.2293635904788971\n",
      "Epoch 780, Loss: 0.4266084134578705, Final Batch Loss: 0.23654469847679138\n",
      "Epoch 781, Loss: 0.4146890640258789, Final Batch Loss: 0.2228655070066452\n",
      "Epoch 782, Loss: 0.4328136742115021, Final Batch Loss: 0.1860056072473526\n",
      "Epoch 783, Loss: 0.41685380041599274, Final Batch Loss: 0.2528172731399536\n",
      "Epoch 784, Loss: 0.46873344480991364, Final Batch Loss: 0.25852450728416443\n",
      "Epoch 785, Loss: 0.42677149176597595, Final Batch Loss: 0.23385630548000336\n",
      "Epoch 786, Loss: 0.42647384107112885, Final Batch Loss: 0.24126774072647095\n",
      "Epoch 787, Loss: 0.40630367398262024, Final Batch Loss: 0.19051241874694824\n",
      "Epoch 788, Loss: 0.46706049144268036, Final Batch Loss: 0.25737902522087097\n",
      "Epoch 789, Loss: 0.41855645179748535, Final Batch Loss: 0.21041660010814667\n",
      "Epoch 790, Loss: 0.4352140575647354, Final Batch Loss: 0.230187326669693\n",
      "Epoch 791, Loss: 0.4177350401878357, Final Batch Loss: 0.22021913528442383\n",
      "Epoch 792, Loss: 0.49604466557502747, Final Batch Loss: 0.27643218636512756\n",
      "Epoch 793, Loss: 0.39871472120285034, Final Batch Loss: 0.1958015263080597\n",
      "Epoch 794, Loss: 0.42089100182056427, Final Batch Loss: 0.21564044058322906\n",
      "Epoch 795, Loss: 0.4381124675273895, Final Batch Loss: 0.23830243945121765\n",
      "Epoch 796, Loss: 0.37850338220596313, Final Batch Loss: 0.1836378425359726\n",
      "Epoch 797, Loss: 0.3994361609220505, Final Batch Loss: 0.17952921986579895\n",
      "Epoch 798, Loss: 0.42945125699043274, Final Batch Loss: 0.2052643746137619\n",
      "Epoch 799, Loss: 0.4267251491546631, Final Batch Loss: 0.2273140251636505\n",
      "Epoch 800, Loss: 0.4439988136291504, Final Batch Loss: 0.24462002515792847\n",
      "Epoch 801, Loss: 0.4953131079673767, Final Batch Loss: 0.22057095170021057\n",
      "Epoch 802, Loss: 0.3948910981416702, Final Batch Loss: 0.1970655471086502\n",
      "Epoch 803, Loss: 0.44981566071510315, Final Batch Loss: 0.20048709213733673\n",
      "Epoch 804, Loss: 0.4071868360042572, Final Batch Loss: 0.20592407882213593\n",
      "Epoch 805, Loss: 0.36862674355506897, Final Batch Loss: 0.14592710137367249\n",
      "Epoch 806, Loss: 0.395719975233078, Final Batch Loss: 0.22358807921409607\n",
      "Epoch 807, Loss: 0.4373813271522522, Final Batch Loss: 0.18619775772094727\n",
      "Epoch 808, Loss: 0.3651719391345978, Final Batch Loss: 0.16696076095104218\n",
      "Epoch 809, Loss: 0.42443105578422546, Final Batch Loss: 0.22607022523880005\n",
      "Epoch 810, Loss: 0.4011383056640625, Final Batch Loss: 0.17141683399677277\n",
      "Epoch 811, Loss: 0.36326949298381805, Final Batch Loss: 0.18246491253376007\n",
      "Epoch 812, Loss: 0.4212133586406708, Final Batch Loss: 0.22254501283168793\n",
      "Epoch 813, Loss: 0.39102059602737427, Final Batch Loss: 0.166254460811615\n",
      "Epoch 814, Loss: 0.40741267800331116, Final Batch Loss: 0.2172888219356537\n",
      "Epoch 815, Loss: 0.37521959841251373, Final Batch Loss: 0.16459210216999054\n",
      "Epoch 816, Loss: 0.4415957182645798, Final Batch Loss: 0.24334262311458588\n",
      "Epoch 817, Loss: 0.3939536362886429, Final Batch Loss: 0.17587213218212128\n",
      "Epoch 818, Loss: 0.40306033194065094, Final Batch Loss: 0.18692176043987274\n",
      "Epoch 819, Loss: 0.4302791655063629, Final Batch Loss: 0.22634030878543854\n",
      "Epoch 820, Loss: 0.37390168011188507, Final Batch Loss: 0.15131816267967224\n",
      "Epoch 821, Loss: 0.4197102040052414, Final Batch Loss: 0.21428267657756805\n",
      "Epoch 822, Loss: 0.4580010324716568, Final Batch Loss: 0.2837463319301605\n",
      "Epoch 823, Loss: 0.4767450541257858, Final Batch Loss: 0.24720978736877441\n",
      "Epoch 824, Loss: 0.40005724132061005, Final Batch Loss: 0.19798269867897034\n",
      "Epoch 825, Loss: 0.39704465866088867, Final Batch Loss: 0.2161451280117035\n",
      "Epoch 826, Loss: 0.40499305725097656, Final Batch Loss: 0.20605693757534027\n",
      "Epoch 827, Loss: 0.44770582020282745, Final Batch Loss: 0.20884566009044647\n",
      "Epoch 828, Loss: 0.394225150346756, Final Batch Loss: 0.1925443857908249\n",
      "Epoch 829, Loss: 0.39972980320453644, Final Batch Loss: 0.2129281908273697\n",
      "Epoch 830, Loss: 0.41521796584129333, Final Batch Loss: 0.18710601329803467\n",
      "Epoch 831, Loss: 0.3759600520133972, Final Batch Loss: 0.16415119171142578\n",
      "Epoch 832, Loss: 0.4029049128293991, Final Batch Loss: 0.19951985776424408\n",
      "Epoch 833, Loss: 0.42505547404289246, Final Batch Loss: 0.2181880921125412\n",
      "Epoch 834, Loss: 0.36224569380283356, Final Batch Loss: 0.1949009746313095\n",
      "Epoch 835, Loss: 0.3775431960821152, Final Batch Loss: 0.16222696006298065\n",
      "Epoch 836, Loss: 0.3756176233291626, Final Batch Loss: 0.18958722054958344\n",
      "Epoch 837, Loss: 0.3932012468576431, Final Batch Loss: 0.19176346063613892\n",
      "Epoch 838, Loss: 0.4052998274564743, Final Batch Loss: 0.20568931102752686\n",
      "Epoch 839, Loss: 0.4080301970243454, Final Batch Loss: 0.16855816543102264\n",
      "Epoch 840, Loss: 0.4015367478132248, Final Batch Loss: 0.21031101047992706\n",
      "Epoch 841, Loss: 0.42044705152511597, Final Batch Loss: 0.2286488562822342\n",
      "Epoch 842, Loss: 0.44058820605278015, Final Batch Loss: 0.20630696415901184\n",
      "Epoch 843, Loss: 0.3906678855419159, Final Batch Loss: 0.15068098902702332\n",
      "Epoch 844, Loss: 0.3956882804632187, Final Batch Loss: 0.20061348378658295\n",
      "Epoch 845, Loss: 0.3941129148006439, Final Batch Loss: 0.18834489583969116\n",
      "Epoch 846, Loss: 0.39524713158607483, Final Batch Loss: 0.18575559556484222\n",
      "Epoch 847, Loss: 0.4321316182613373, Final Batch Loss: 0.26407742500305176\n",
      "Epoch 848, Loss: 0.3583335280418396, Final Batch Loss: 0.13950476050376892\n",
      "Epoch 849, Loss: 0.38642212748527527, Final Batch Loss: 0.17910924553871155\n",
      "Epoch 850, Loss: 0.41374409198760986, Final Batch Loss: 0.20815688371658325\n",
      "Epoch 851, Loss: 0.38026420772075653, Final Batch Loss: 0.16432853043079376\n",
      "Epoch 852, Loss: 0.4233618527650833, Final Batch Loss: 0.2376803159713745\n",
      "Epoch 853, Loss: 0.39753809571266174, Final Batch Loss: 0.1983714997768402\n",
      "Epoch 854, Loss: 0.40992471575737, Final Batch Loss: 0.16009072959423065\n",
      "Epoch 855, Loss: 0.43980787694454193, Final Batch Loss: 0.2709478735923767\n",
      "Epoch 856, Loss: 0.4263212978839874, Final Batch Loss: 0.21474340558052063\n",
      "Epoch 857, Loss: 0.41110649704933167, Final Batch Loss: 0.23659570515155792\n",
      "Epoch 858, Loss: 0.3683825582265854, Final Batch Loss: 0.17372751235961914\n",
      "Epoch 859, Loss: 0.41462601721286774, Final Batch Loss: 0.22047869861125946\n",
      "Epoch 860, Loss: 0.4258788228034973, Final Batch Loss: 0.2581078112125397\n",
      "Epoch 861, Loss: 0.38779041171073914, Final Batch Loss: 0.1854853332042694\n",
      "Epoch 862, Loss: 0.4143253415822983, Final Batch Loss: 0.21806135773658752\n",
      "Epoch 863, Loss: 0.39490076899528503, Final Batch Loss: 0.21328598260879517\n",
      "Epoch 864, Loss: 0.37694528698921204, Final Batch Loss: 0.17448730766773224\n",
      "Epoch 865, Loss: 0.3584713488817215, Final Batch Loss: 0.1667417734861374\n",
      "Epoch 866, Loss: 0.37743425369262695, Final Batch Loss: 0.1617138683795929\n",
      "Epoch 867, Loss: 0.3651188313961029, Final Batch Loss: 0.2017870396375656\n",
      "Epoch 868, Loss: 0.36451834440231323, Final Batch Loss: 0.15102238953113556\n",
      "Epoch 869, Loss: 0.462880402803421, Final Batch Loss: 0.2798728942871094\n",
      "Epoch 870, Loss: 0.36085186898708344, Final Batch Loss: 0.1762695014476776\n",
      "Epoch 871, Loss: 0.3998800069093704, Final Batch Loss: 0.2026481032371521\n",
      "Epoch 872, Loss: 0.44419416785240173, Final Batch Loss: 0.23525187373161316\n",
      "Epoch 873, Loss: 0.36874987185001373, Final Batch Loss: 0.1497241109609604\n",
      "Epoch 874, Loss: 0.4082724153995514, Final Batch Loss: 0.25011464953422546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875, Loss: 0.354455903172493, Final Batch Loss: 0.16117480397224426\n",
      "Epoch 876, Loss: 0.40109236538410187, Final Batch Loss: 0.18890179693698883\n",
      "Epoch 877, Loss: 0.4067274481058121, Final Batch Loss: 0.17694677412509918\n",
      "Epoch 878, Loss: 0.44562341272830963, Final Batch Loss: 0.24784819781780243\n",
      "Epoch 879, Loss: 0.3768051713705063, Final Batch Loss: 0.21331724524497986\n",
      "Epoch 880, Loss: 0.38871365785598755, Final Batch Loss: 0.2051679790019989\n",
      "Epoch 881, Loss: 0.38675346970558167, Final Batch Loss: 0.14807818830013275\n",
      "Epoch 882, Loss: 0.41382643580436707, Final Batch Loss: 0.21354533731937408\n",
      "Epoch 883, Loss: 0.328789621591568, Final Batch Loss: 0.13095438480377197\n",
      "Epoch 884, Loss: 0.43727028369903564, Final Batch Loss: 0.24260865151882172\n",
      "Epoch 885, Loss: 0.44214506447315216, Final Batch Loss: 0.2621195316314697\n",
      "Epoch 886, Loss: 0.39281532168388367, Final Batch Loss: 0.21265822649002075\n",
      "Epoch 887, Loss: 0.40584833920001984, Final Batch Loss: 0.20494094491004944\n",
      "Epoch 888, Loss: 0.4208013117313385, Final Batch Loss: 0.22794020175933838\n",
      "Epoch 889, Loss: 0.34204286336898804, Final Batch Loss: 0.14832817018032074\n",
      "Epoch 890, Loss: 0.34476691484451294, Final Batch Loss: 0.152931347489357\n",
      "Epoch 891, Loss: 0.3481252193450928, Final Batch Loss: 0.1510411947965622\n",
      "Epoch 892, Loss: 0.3397394120693207, Final Batch Loss: 0.16985005140304565\n",
      "Epoch 893, Loss: 0.37139052152633667, Final Batch Loss: 0.2032831460237503\n",
      "Epoch 894, Loss: 0.45850910246372223, Final Batch Loss: 0.2921917140483856\n",
      "Epoch 895, Loss: 0.4179152101278305, Final Batch Loss: 0.2244240939617157\n",
      "Epoch 896, Loss: 0.35856427252292633, Final Batch Loss: 0.161861389875412\n",
      "Epoch 897, Loss: 0.35531771183013916, Final Batch Loss: 0.1504933089017868\n",
      "Epoch 898, Loss: 0.3626808822154999, Final Batch Loss: 0.15290839970111847\n",
      "Epoch 899, Loss: 0.3979814797639847, Final Batch Loss: 0.22403237223625183\n",
      "Epoch 900, Loss: 0.3616236299276352, Final Batch Loss: 0.14138922095298767\n",
      "Epoch 901, Loss: 0.4243686944246292, Final Batch Loss: 0.26212480664253235\n",
      "Epoch 902, Loss: 0.4315081089735031, Final Batch Loss: 0.2758086919784546\n",
      "Epoch 903, Loss: 0.36761726438999176, Final Batch Loss: 0.21893911063671112\n",
      "Epoch 904, Loss: 0.37031495571136475, Final Batch Loss: 0.18227365612983704\n",
      "Epoch 905, Loss: 0.36325937509536743, Final Batch Loss: 0.15273018181324005\n",
      "Epoch 906, Loss: 0.3940639942884445, Final Batch Loss: 0.20870409905910492\n",
      "Epoch 907, Loss: 0.37962180376052856, Final Batch Loss: 0.16243307292461395\n",
      "Epoch 908, Loss: 0.43988098204135895, Final Batch Loss: 0.18909429013729095\n",
      "Epoch 909, Loss: 0.34602633118629456, Final Batch Loss: 0.14921517670154572\n",
      "Epoch 910, Loss: 0.5145022422075272, Final Batch Loss: 0.31231245398521423\n",
      "Epoch 911, Loss: 0.35469022393226624, Final Batch Loss: 0.1592874974012375\n",
      "Epoch 912, Loss: 0.3968129903078079, Final Batch Loss: 0.20406495034694672\n",
      "Epoch 913, Loss: 0.3026968166232109, Final Batch Loss: 0.0933893695473671\n",
      "Epoch 914, Loss: 0.3484077602624893, Final Batch Loss: 0.15202116966247559\n",
      "Epoch 915, Loss: 0.37956681847572327, Final Batch Loss: 0.2409677505493164\n",
      "Epoch 916, Loss: 0.36627712845802307, Final Batch Loss: 0.16577158868312836\n",
      "Epoch 917, Loss: 0.42830102145671844, Final Batch Loss: 0.23833119869232178\n",
      "Epoch 918, Loss: 0.3949185162782669, Final Batch Loss: 0.2346699833869934\n",
      "Epoch 919, Loss: 0.34853149950504303, Final Batch Loss: 0.1662430465221405\n",
      "Epoch 920, Loss: 0.361182302236557, Final Batch Loss: 0.1539941281080246\n",
      "Epoch 921, Loss: 0.337374284863472, Final Batch Loss: 0.15078699588775635\n",
      "Epoch 922, Loss: 0.4055476039648056, Final Batch Loss: 0.23618941009044647\n",
      "Epoch 923, Loss: 0.37505169212818146, Final Batch Loss: 0.19768670201301575\n",
      "Epoch 924, Loss: 0.3354920595884323, Final Batch Loss: 0.1859360635280609\n",
      "Epoch 925, Loss: 0.3479396551847458, Final Batch Loss: 0.18039856851100922\n",
      "Epoch 926, Loss: 0.3254082053899765, Final Batch Loss: 0.19386716187000275\n",
      "Epoch 927, Loss: 0.37835484743118286, Final Batch Loss: 0.19587457180023193\n",
      "Epoch 928, Loss: 0.3996645659208298, Final Batch Loss: 0.19482915103435516\n",
      "Epoch 929, Loss: 0.40559619665145874, Final Batch Loss: 0.22905272245407104\n",
      "Epoch 930, Loss: 0.417788103222847, Final Batch Loss: 0.22845976054668427\n",
      "Epoch 931, Loss: 0.3568283021450043, Final Batch Loss: 0.1990809440612793\n",
      "Epoch 932, Loss: 0.3419019877910614, Final Batch Loss: 0.16633771359920502\n",
      "Epoch 933, Loss: 0.31273433566093445, Final Batch Loss: 0.13892240822315216\n",
      "Epoch 934, Loss: 0.3375861197710037, Final Batch Loss: 0.14977052807807922\n",
      "Epoch 935, Loss: 0.36531707644462585, Final Batch Loss: 0.16866914927959442\n",
      "Epoch 936, Loss: 0.3542667478322983, Final Batch Loss: 0.16110925376415253\n",
      "Epoch 937, Loss: 0.36108070611953735, Final Batch Loss: 0.18567755818367004\n",
      "Epoch 938, Loss: 0.3657629042863846, Final Batch Loss: 0.178170844912529\n",
      "Epoch 939, Loss: 0.3339890241622925, Final Batch Loss: 0.18578626215457916\n",
      "Epoch 940, Loss: 0.31577299535274506, Final Batch Loss: 0.15826091170310974\n",
      "Epoch 941, Loss: 0.3768293708562851, Final Batch Loss: 0.2088644951581955\n",
      "Epoch 942, Loss: 0.36399102210998535, Final Batch Loss: 0.2059244066476822\n",
      "Epoch 943, Loss: 0.32111847400665283, Final Batch Loss: 0.14041130244731903\n",
      "Epoch 944, Loss: 0.37385475635528564, Final Batch Loss: 0.19357939064502716\n",
      "Epoch 945, Loss: 0.37720488011837006, Final Batch Loss: 0.20801641047000885\n",
      "Epoch 946, Loss: 0.37760333716869354, Final Batch Loss: 0.1328008621931076\n",
      "Epoch 947, Loss: 0.3596627414226532, Final Batch Loss: 0.16505993902683258\n",
      "Epoch 948, Loss: 0.39432603120803833, Final Batch Loss: 0.19740605354309082\n",
      "Epoch 949, Loss: 0.3833213597536087, Final Batch Loss: 0.2126184105873108\n",
      "Epoch 950, Loss: 0.33102187514305115, Final Batch Loss: 0.1728912889957428\n",
      "Epoch 951, Loss: 0.3713698238134384, Final Batch Loss: 0.19106757640838623\n",
      "Epoch 952, Loss: 0.3891441524028778, Final Batch Loss: 0.22787423431873322\n",
      "Epoch 953, Loss: 0.30449341237545013, Final Batch Loss: 0.1364273726940155\n",
      "Epoch 954, Loss: 0.33934928476810455, Final Batch Loss: 0.16170915961265564\n",
      "Epoch 955, Loss: 0.3363477289676666, Final Batch Loss: 0.1553930640220642\n",
      "Epoch 956, Loss: 0.3453335613012314, Final Batch Loss: 0.1676579713821411\n",
      "Epoch 957, Loss: 0.28005896508693695, Final Batch Loss: 0.08809898793697357\n",
      "Epoch 958, Loss: 0.32837584614753723, Final Batch Loss: 0.14866702258586884\n",
      "Epoch 959, Loss: 0.3496897518634796, Final Batch Loss: 0.1365053802728653\n",
      "Epoch 960, Loss: 0.34480932354927063, Final Batch Loss: 0.14589406549930573\n",
      "Epoch 961, Loss: 0.3417855203151703, Final Batch Loss: 0.21044056117534637\n",
      "Epoch 962, Loss: 0.3548031747341156, Final Batch Loss: 0.18115028738975525\n",
      "Epoch 963, Loss: 0.3133552372455597, Final Batch Loss: 0.13767804205417633\n",
      "Epoch 964, Loss: 0.33293895423412323, Final Batch Loss: 0.18085968494415283\n",
      "Epoch 965, Loss: 0.332492932677269, Final Batch Loss: 0.1642407327890396\n",
      "Epoch 966, Loss: 0.3127945512533188, Final Batch Loss: 0.15311631560325623\n",
      "Epoch 967, Loss: 0.3488568067550659, Final Batch Loss: 0.2257566750049591\n",
      "Epoch 968, Loss: 0.45628125965595245, Final Batch Loss: 0.2912108302116394\n",
      "Epoch 969, Loss: 0.31581200659275055, Final Batch Loss: 0.15425680577754974\n",
      "Epoch 970, Loss: 0.3174325227737427, Final Batch Loss: 0.1438748836517334\n",
      "Epoch 971, Loss: 0.34873583912849426, Final Batch Loss: 0.18650107085704803\n",
      "Epoch 972, Loss: 0.3029150143265724, Final Batch Loss: 0.12359883636236191\n",
      "Epoch 973, Loss: 0.3674781173467636, Final Batch Loss: 0.1479567438364029\n",
      "Epoch 974, Loss: 0.28846611082553864, Final Batch Loss: 0.1241673082113266\n",
      "Epoch 975, Loss: 0.3446293771266937, Final Batch Loss: 0.13565301895141602\n",
      "Epoch 976, Loss: 0.32219459116458893, Final Batch Loss: 0.1558298021554947\n",
      "Epoch 977, Loss: 0.39484703540802, Final Batch Loss: 0.22971297800540924\n",
      "Epoch 978, Loss: 0.313041515648365, Final Batch Loss: 0.11797494441270828\n",
      "Epoch 979, Loss: 0.314879909157753, Final Batch Loss: 0.14390015602111816\n",
      "Epoch 980, Loss: 0.31322768330574036, Final Batch Loss: 0.16325631737709045\n",
      "Epoch 981, Loss: 0.3288283944129944, Final Batch Loss: 0.17510107159614563\n",
      "Epoch 982, Loss: 0.2673110216856003, Final Batch Loss: 0.10072822868824005\n",
      "Epoch 983, Loss: 0.3760078400373459, Final Batch Loss: 0.20305055379867554\n",
      "Epoch 984, Loss: 0.37075386941432953, Final Batch Loss: 0.169467493891716\n",
      "Epoch 985, Loss: 0.32778915762901306, Final Batch Loss: 0.13051503896713257\n",
      "Epoch 986, Loss: 0.3425982594490051, Final Batch Loss: 0.18367163836956024\n",
      "Epoch 987, Loss: 0.33597399294376373, Final Batch Loss: 0.17954915761947632\n",
      "Epoch 988, Loss: 0.29347556829452515, Final Batch Loss: 0.16199445724487305\n",
      "Epoch 989, Loss: 0.30166082084178925, Final Batch Loss: 0.15306593477725983\n",
      "Epoch 990, Loss: 0.3693217635154724, Final Batch Loss: 0.2079225778579712\n",
      "Epoch 991, Loss: 0.26580917090177536, Final Batch Loss: 0.11882217973470688\n",
      "Epoch 992, Loss: 0.2991729825735092, Final Batch Loss: 0.13741256296634674\n",
      "Epoch 993, Loss: 0.29641616344451904, Final Batch Loss: 0.14157937467098236\n",
      "Epoch 994, Loss: 0.2893495410680771, Final Batch Loss: 0.13589303195476532\n",
      "Epoch 995, Loss: 0.2937068045139313, Final Batch Loss: 0.14757217466831207\n",
      "Epoch 996, Loss: 0.27815045416355133, Final Batch Loss: 0.11713029444217682\n",
      "Epoch 997, Loss: 0.29919350147247314, Final Batch Loss: 0.1382889747619629\n",
      "Epoch 998, Loss: 0.3218482881784439, Final Batch Loss: 0.1624898910522461\n",
      "Epoch 999, Loss: 0.3566955178976059, Final Batch Loss: 0.2237548977136612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss: 0.28407754749059677, Final Batch Loss: 0.11266390234231949\n",
      "Epoch 1001, Loss: 0.29883380234241486, Final Batch Loss: 0.1412220150232315\n",
      "Epoch 1002, Loss: 0.3516165465116501, Final Batch Loss: 0.1615280956029892\n",
      "Epoch 1003, Loss: 0.3302474319934845, Final Batch Loss: 0.16216278076171875\n",
      "Epoch 1004, Loss: 0.3211614042520523, Final Batch Loss: 0.15444086492061615\n",
      "Epoch 1005, Loss: 0.30265195667743683, Final Batch Loss: 0.1606980562210083\n",
      "Epoch 1006, Loss: 0.2950955778360367, Final Batch Loss: 0.12850219011306763\n",
      "Epoch 1007, Loss: 0.27190598100423813, Final Batch Loss: 0.15510094165802002\n",
      "Epoch 1008, Loss: 0.29592304676771164, Final Batch Loss: 0.11639123409986496\n",
      "Epoch 1009, Loss: 0.24913519620895386, Final Batch Loss: 0.09800979495048523\n",
      "Epoch 1010, Loss: 0.31497420370578766, Final Batch Loss: 0.1173774003982544\n",
      "Epoch 1011, Loss: 0.29075950384140015, Final Batch Loss: 0.129225954413414\n",
      "Epoch 1012, Loss: 0.3179514706134796, Final Batch Loss: 0.14164932072162628\n",
      "Epoch 1013, Loss: 0.3829401433467865, Final Batch Loss: 0.2298526018857956\n",
      "Epoch 1014, Loss: 0.294334813952446, Final Batch Loss: 0.16500313580036163\n",
      "Epoch 1015, Loss: 0.2946584075689316, Final Batch Loss: 0.14703288674354553\n",
      "Epoch 1016, Loss: 0.35031186044216156, Final Batch Loss: 0.18333834409713745\n",
      "Epoch 1017, Loss: 0.32210686802864075, Final Batch Loss: 0.1558895707130432\n",
      "Epoch 1018, Loss: 0.28644874691963196, Final Batch Loss: 0.1673533320426941\n",
      "Epoch 1019, Loss: 0.3286530375480652, Final Batch Loss: 0.14831951260566711\n",
      "Epoch 1020, Loss: 0.2881285548210144, Final Batch Loss: 0.13565558195114136\n",
      "Epoch 1021, Loss: 0.3377024382352829, Final Batch Loss: 0.18616649508476257\n",
      "Epoch 1022, Loss: 0.27043166011571884, Final Batch Loss: 0.11121610552072525\n",
      "Epoch 1023, Loss: 0.29892656207084656, Final Batch Loss: 0.1289912611246109\n",
      "Epoch 1024, Loss: 0.2333962544798851, Final Batch Loss: 0.1072520986199379\n",
      "Epoch 1025, Loss: 0.2541666850447655, Final Batch Loss: 0.14033371210098267\n",
      "Epoch 1026, Loss: 0.3519159406423569, Final Batch Loss: 0.17485132813453674\n",
      "Epoch 1027, Loss: 0.24562982469797134, Final Batch Loss: 0.09717079252004623\n",
      "Epoch 1028, Loss: 0.24461888521909714, Final Batch Loss: 0.12290216982364655\n",
      "Epoch 1029, Loss: 0.29188184440135956, Final Batch Loss: 0.15397819876670837\n",
      "Epoch 1030, Loss: 0.2779749929904938, Final Batch Loss: 0.16177082061767578\n",
      "Epoch 1031, Loss: 0.3268890380859375, Final Batch Loss: 0.19134926795959473\n",
      "Epoch 1032, Loss: 0.268328920006752, Final Batch Loss: 0.15140950679779053\n",
      "Epoch 1033, Loss: 0.278095580637455, Final Batch Loss: 0.17532619833946228\n",
      "Epoch 1034, Loss: 0.31147968769073486, Final Batch Loss: 0.13892193138599396\n",
      "Epoch 1035, Loss: 0.2780006676912308, Final Batch Loss: 0.1169230192899704\n",
      "Epoch 1036, Loss: 0.2877172380685806, Final Batch Loss: 0.13314874470233917\n",
      "Epoch 1037, Loss: 0.2916947156190872, Final Batch Loss: 0.15338118374347687\n",
      "Epoch 1038, Loss: 0.27220746874809265, Final Batch Loss: 0.12838420271873474\n",
      "Epoch 1039, Loss: 0.24080896377563477, Final Batch Loss: 0.14543086290359497\n",
      "Epoch 1040, Loss: 0.2503689303994179, Final Batch Loss: 0.13928566873073578\n",
      "Epoch 1041, Loss: 0.31721046566963196, Final Batch Loss: 0.1594236195087433\n",
      "Epoch 1042, Loss: 0.32355478405952454, Final Batch Loss: 0.16430824995040894\n",
      "Epoch 1043, Loss: 0.2686929553747177, Final Batch Loss: 0.13133041560649872\n",
      "Epoch 1044, Loss: 0.2980734705924988, Final Batch Loss: 0.15969330072402954\n",
      "Epoch 1045, Loss: 0.2741764336824417, Final Batch Loss: 0.126261904835701\n",
      "Epoch 1046, Loss: 0.2546732425689697, Final Batch Loss: 0.09860648214817047\n",
      "Epoch 1047, Loss: 0.3049997091293335, Final Batch Loss: 0.1430388242006302\n",
      "Epoch 1048, Loss: 0.29232199490070343, Final Batch Loss: 0.15084022283554077\n",
      "Epoch 1049, Loss: 0.3516809493303299, Final Batch Loss: 0.17527922987937927\n",
      "Epoch 1050, Loss: 0.29541756212711334, Final Batch Loss: 0.14631099998950958\n",
      "Epoch 1051, Loss: 0.3695438653230667, Final Batch Loss: 0.23095691204071045\n",
      "Epoch 1052, Loss: 0.29372939467430115, Final Batch Loss: 0.16575054824352264\n",
      "Epoch 1053, Loss: 0.3027517944574356, Final Batch Loss: 0.16286131739616394\n",
      "Epoch 1054, Loss: 0.3496275395154953, Final Batch Loss: 0.1585966795682907\n",
      "Epoch 1055, Loss: 0.2696158289909363, Final Batch Loss: 0.1411653310060501\n",
      "Epoch 1056, Loss: 0.25810327380895615, Final Batch Loss: 0.09842351824045181\n",
      "Epoch 1057, Loss: 0.35457640141248703, Final Batch Loss: 0.11919241398572922\n",
      "Epoch 1058, Loss: 0.23193374276161194, Final Batch Loss: 0.08707426488399506\n",
      "Epoch 1059, Loss: 0.22089935839176178, Final Batch Loss: 0.08447568118572235\n",
      "Epoch 1060, Loss: 0.36692696809768677, Final Batch Loss: 0.1945529729127884\n",
      "Epoch 1061, Loss: 0.3377060443162918, Final Batch Loss: 0.1985599398612976\n",
      "Epoch 1062, Loss: 0.28064756095409393, Final Batch Loss: 0.1393125355243683\n",
      "Epoch 1063, Loss: 0.3024550676345825, Final Batch Loss: 0.18436488509178162\n",
      "Epoch 1064, Loss: 0.3308446705341339, Final Batch Loss: 0.20450086891651154\n",
      "Epoch 1065, Loss: 0.23925049602985382, Final Batch Loss: 0.12796393036842346\n",
      "Epoch 1066, Loss: 0.25849463045597076, Final Batch Loss: 0.15049031376838684\n",
      "Epoch 1067, Loss: 0.279087632894516, Final Batch Loss: 0.14607872068881989\n",
      "Epoch 1068, Loss: 0.27952123433351517, Final Batch Loss: 0.15947701036930084\n",
      "Epoch 1069, Loss: 0.293626993894577, Final Batch Loss: 0.1548885852098465\n",
      "Epoch 1070, Loss: 0.2761377990245819, Final Batch Loss: 0.14234469830989838\n",
      "Epoch 1071, Loss: 0.2783926874399185, Final Batch Loss: 0.1250324547290802\n",
      "Epoch 1072, Loss: 0.2910600006580353, Final Batch Loss: 0.1511247456073761\n",
      "Epoch 1073, Loss: 0.21184048801660538, Final Batch Loss: 0.08665119856595993\n",
      "Epoch 1074, Loss: 0.3101152181625366, Final Batch Loss: 0.14757129549980164\n",
      "Epoch 1075, Loss: 0.23511167615652084, Final Batch Loss: 0.13366585969924927\n",
      "Epoch 1076, Loss: 0.2146177515387535, Final Batch Loss: 0.08727750927209854\n",
      "Epoch 1077, Loss: 0.27577370405197144, Final Batch Loss: 0.12626305222511292\n",
      "Epoch 1078, Loss: 0.2801717668771744, Final Batch Loss: 0.15609559416770935\n",
      "Epoch 1079, Loss: 0.36115263402462006, Final Batch Loss: 0.20378825068473816\n",
      "Epoch 1080, Loss: 0.3223094046115875, Final Batch Loss: 0.17974381148815155\n",
      "Epoch 1081, Loss: 0.2440599948167801, Final Batch Loss: 0.08316594362258911\n",
      "Epoch 1082, Loss: 0.22146401554346085, Final Batch Loss: 0.08596578985452652\n",
      "Epoch 1083, Loss: 0.2748428285121918, Final Batch Loss: 0.13417662680149078\n",
      "Epoch 1084, Loss: 0.2514876201748848, Final Batch Loss: 0.08228128403425217\n",
      "Epoch 1085, Loss: 0.2397281527519226, Final Batch Loss: 0.11630599200725555\n",
      "Epoch 1086, Loss: 0.2969513237476349, Final Batch Loss: 0.13348226249217987\n",
      "Epoch 1087, Loss: 0.24208106845617294, Final Batch Loss: 0.08578810840845108\n",
      "Epoch 1088, Loss: 0.26479990780353546, Final Batch Loss: 0.14083682000637054\n",
      "Epoch 1089, Loss: 0.2874084413051605, Final Batch Loss: 0.14047978818416595\n",
      "Epoch 1090, Loss: 0.22318260371685028, Final Batch Loss: 0.11651570349931717\n",
      "Epoch 1091, Loss: 0.2835412919521332, Final Batch Loss: 0.14611971378326416\n",
      "Epoch 1092, Loss: 0.25297239422798157, Final Batch Loss: 0.1285390406847\n",
      "Epoch 1093, Loss: 0.192013218998909, Final Batch Loss: 0.08632111549377441\n",
      "Epoch 1094, Loss: 0.24332159012556076, Final Batch Loss: 0.12099990248680115\n",
      "Epoch 1095, Loss: 0.24742130935192108, Final Batch Loss: 0.13274696469306946\n",
      "Epoch 1096, Loss: 0.2789446860551834, Final Batch Loss: 0.13748371601104736\n",
      "Epoch 1097, Loss: 0.35209496319293976, Final Batch Loss: 0.21528063714504242\n",
      "Epoch 1098, Loss: 0.2568163499236107, Final Batch Loss: 0.13300366699695587\n",
      "Epoch 1099, Loss: 0.251079685986042, Final Batch Loss: 0.10325784236192703\n",
      "Epoch 1100, Loss: 0.2982751131057739, Final Batch Loss: 0.18835684657096863\n",
      "Epoch 1101, Loss: 0.25824740529060364, Final Batch Loss: 0.1350170373916626\n",
      "Epoch 1102, Loss: 0.2908334732055664, Final Batch Loss: 0.13986730575561523\n",
      "Epoch 1103, Loss: 0.25226400047540665, Final Batch Loss: 0.12957040965557098\n",
      "Epoch 1104, Loss: 0.26886070519685745, Final Batch Loss: 0.1458168923854828\n",
      "Epoch 1105, Loss: 0.24418319761753082, Final Batch Loss: 0.12234657257795334\n",
      "Epoch 1106, Loss: 0.25848643481731415, Final Batch Loss: 0.11817441880702972\n",
      "Epoch 1107, Loss: 0.2567990869283676, Final Batch Loss: 0.12789377570152283\n",
      "Epoch 1108, Loss: 0.23940514773130417, Final Batch Loss: 0.12334500253200531\n",
      "Epoch 1109, Loss: 0.2777803838253021, Final Batch Loss: 0.1254332959651947\n",
      "Epoch 1110, Loss: 0.23882976174354553, Final Batch Loss: 0.12193378806114197\n",
      "Epoch 1111, Loss: 0.2365947738289833, Final Batch Loss: 0.12906381487846375\n",
      "Epoch 1112, Loss: 0.2784850299358368, Final Batch Loss: 0.1288105845451355\n",
      "Epoch 1113, Loss: 0.21730008721351624, Final Batch Loss: 0.1068369522690773\n",
      "Epoch 1114, Loss: 0.2538163289427757, Final Batch Loss: 0.12402164191007614\n",
      "Epoch 1115, Loss: 0.3128536641597748, Final Batch Loss: 0.1668100357055664\n",
      "Epoch 1116, Loss: 0.2817215099930763, Final Batch Loss: 0.17019811272621155\n",
      "Epoch 1117, Loss: 0.2247338965535164, Final Batch Loss: 0.10467527061700821\n",
      "Epoch 1118, Loss: 0.28624027222394943, Final Batch Loss: 0.11694034188985825\n",
      "Epoch 1119, Loss: 0.2298678234219551, Final Batch Loss: 0.1032554879784584\n",
      "Epoch 1120, Loss: 0.24013283103704453, Final Batch Loss: 0.12821133434772491\n",
      "Epoch 1121, Loss: 0.2523857429623604, Final Batch Loss: 0.10633375495672226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1122, Loss: 0.24675920605659485, Final Batch Loss: 0.12046003341674805\n",
      "Epoch 1123, Loss: 0.20745563507080078, Final Batch Loss: 0.08549613505601883\n",
      "Epoch 1124, Loss: 0.1908687949180603, Final Batch Loss: 0.06699016690254211\n",
      "Epoch 1125, Loss: 0.20935676246881485, Final Batch Loss: 0.07173841446638107\n",
      "Epoch 1126, Loss: 0.3672664016485214, Final Batch Loss: 0.179857075214386\n",
      "Epoch 1127, Loss: 0.2099398896098137, Final Batch Loss: 0.09476939588785172\n",
      "Epoch 1128, Loss: 0.2475854679942131, Final Batch Loss: 0.11043677479028702\n",
      "Epoch 1129, Loss: 0.3363832086324692, Final Batch Loss: 0.12779049575328827\n",
      "Epoch 1130, Loss: 0.24890170991420746, Final Batch Loss: 0.12538225948810577\n",
      "Epoch 1131, Loss: 0.25910305976867676, Final Batch Loss: 0.1300707459449768\n",
      "Epoch 1132, Loss: 0.3444209098815918, Final Batch Loss: 0.24202734231948853\n",
      "Epoch 1133, Loss: 0.2967832684516907, Final Batch Loss: 0.16866104304790497\n",
      "Epoch 1134, Loss: 0.2246308997273445, Final Batch Loss: 0.12580008804798126\n",
      "Epoch 1135, Loss: 0.2340564802289009, Final Batch Loss: 0.13218927383422852\n",
      "Epoch 1136, Loss: 0.1988271325826645, Final Batch Loss: 0.0809130072593689\n",
      "Epoch 1137, Loss: 0.28926095366477966, Final Batch Loss: 0.17815753817558289\n",
      "Epoch 1138, Loss: 0.2046280801296234, Final Batch Loss: 0.1094048023223877\n",
      "Epoch 1139, Loss: 0.2965475916862488, Final Batch Loss: 0.12225790321826935\n",
      "Epoch 1140, Loss: 0.23876121640205383, Final Batch Loss: 0.10616861283779144\n",
      "Epoch 1141, Loss: 0.2788695991039276, Final Batch Loss: 0.16278956830501556\n",
      "Epoch 1142, Loss: 0.22291196882724762, Final Batch Loss: 0.08489878475666046\n",
      "Epoch 1143, Loss: 0.24078920483589172, Final Batch Loss: 0.13946221768856049\n",
      "Epoch 1144, Loss: 0.2881438136100769, Final Batch Loss: 0.15812934935092926\n",
      "Epoch 1145, Loss: 0.2161155641078949, Final Batch Loss: 0.09324279427528381\n",
      "Epoch 1146, Loss: 0.28277160227298737, Final Batch Loss: 0.16959041357040405\n",
      "Epoch 1147, Loss: 0.2432016059756279, Final Batch Loss: 0.09968607872724533\n",
      "Epoch 1148, Loss: 0.24172543734312057, Final Batch Loss: 0.10697241872549057\n",
      "Epoch 1149, Loss: 0.23535749316215515, Final Batch Loss: 0.11297207325696945\n",
      "Epoch 1150, Loss: 0.23803558945655823, Final Batch Loss: 0.12144040316343307\n",
      "Epoch 1151, Loss: 0.2863265872001648, Final Batch Loss: 0.11707940697669983\n",
      "Epoch 1152, Loss: 0.20645742863416672, Final Batch Loss: 0.09419107437133789\n",
      "Epoch 1153, Loss: 0.21904730796813965, Final Batch Loss: 0.07199950516223907\n",
      "Epoch 1154, Loss: 0.19854164868593216, Final Batch Loss: 0.08758501708507538\n",
      "Epoch 1155, Loss: 0.21400513499975204, Final Batch Loss: 0.09775605797767639\n",
      "Epoch 1156, Loss: 0.2108040377497673, Final Batch Loss: 0.10738898813724518\n",
      "Epoch 1157, Loss: 0.2411181926727295, Final Batch Loss: 0.09568814933300018\n",
      "Epoch 1158, Loss: 0.24285782128572464, Final Batch Loss: 0.12725724279880524\n",
      "Epoch 1159, Loss: 0.20301634073257446, Final Batch Loss: 0.10799595713615417\n",
      "Epoch 1160, Loss: 0.28444404900074005, Final Batch Loss: 0.17107099294662476\n",
      "Epoch 1161, Loss: 0.21199103444814682, Final Batch Loss: 0.1251228004693985\n",
      "Epoch 1162, Loss: 0.261883482336998, Final Batch Loss: 0.1339670866727829\n",
      "Epoch 1163, Loss: 0.23710889369249344, Final Batch Loss: 0.11144941300153732\n",
      "Epoch 1164, Loss: 0.16863130778074265, Final Batch Loss: 0.06957392394542694\n",
      "Epoch 1165, Loss: 0.2058034911751747, Final Batch Loss: 0.09638367593288422\n",
      "Epoch 1166, Loss: 0.2592397555708885, Final Batch Loss: 0.15057983994483948\n",
      "Epoch 1167, Loss: 0.22620337456464767, Final Batch Loss: 0.11936616897583008\n",
      "Epoch 1168, Loss: 0.2356598898768425, Final Batch Loss: 0.13617506623268127\n",
      "Epoch 1169, Loss: 0.20259995758533478, Final Batch Loss: 0.08723118156194687\n",
      "Epoch 1170, Loss: 0.2384888082742691, Final Batch Loss: 0.14573299884796143\n",
      "Epoch 1171, Loss: 0.24082671850919724, Final Batch Loss: 0.11605643481016159\n",
      "Epoch 1172, Loss: 0.2864690497517586, Final Batch Loss: 0.18363752961158752\n",
      "Epoch 1173, Loss: 0.22362730652093887, Final Batch Loss: 0.09327834099531174\n",
      "Epoch 1174, Loss: 0.20945905894041061, Final Batch Loss: 0.08345969766378403\n",
      "Epoch 1175, Loss: 0.29429854452610016, Final Batch Loss: 0.16601763665676117\n",
      "Epoch 1176, Loss: 0.25344356149435043, Final Batch Loss: 0.1371493935585022\n",
      "Epoch 1177, Loss: 0.23201876878738403, Final Batch Loss: 0.13344396650791168\n",
      "Epoch 1178, Loss: 0.2035321146249771, Final Batch Loss: 0.0914406105875969\n",
      "Epoch 1179, Loss: 0.20355238020420074, Final Batch Loss: 0.10909481346607208\n",
      "Epoch 1180, Loss: 0.2787574455142021, Final Batch Loss: 0.11875604838132858\n",
      "Epoch 1181, Loss: 0.22859983146190643, Final Batch Loss: 0.1577528417110443\n",
      "Epoch 1182, Loss: 0.2417561188340187, Final Batch Loss: 0.16142530739307404\n",
      "Epoch 1183, Loss: 0.23454860597848892, Final Batch Loss: 0.11871492117643356\n",
      "Epoch 1184, Loss: 0.2416207566857338, Final Batch Loss: 0.14902712404727936\n",
      "Epoch 1185, Loss: 0.23093226552009583, Final Batch Loss: 0.10384291410446167\n",
      "Epoch 1186, Loss: 0.2805807590484619, Final Batch Loss: 0.15543273091316223\n",
      "Epoch 1187, Loss: 0.24288809299468994, Final Batch Loss: 0.14532853662967682\n",
      "Epoch 1188, Loss: 0.27618709951639175, Final Batch Loss: 0.09570256620645523\n",
      "Epoch 1189, Loss: 0.1803874596953392, Final Batch Loss: 0.06957078725099564\n",
      "Epoch 1190, Loss: 0.21654406189918518, Final Batch Loss: 0.09948596358299255\n",
      "Epoch 1191, Loss: 0.26368894428014755, Final Batch Loss: 0.16585105657577515\n",
      "Epoch 1192, Loss: 0.17575568705797195, Final Batch Loss: 0.06285790354013443\n",
      "Epoch 1193, Loss: 0.20486456900835037, Final Batch Loss: 0.05570479482412338\n",
      "Epoch 1194, Loss: 0.20774005353450775, Final Batch Loss: 0.1043623611330986\n",
      "Epoch 1195, Loss: 0.20179986953735352, Final Batch Loss: 0.09448251128196716\n",
      "Epoch 1196, Loss: 0.23873088508844376, Final Batch Loss: 0.12869049608707428\n",
      "Epoch 1197, Loss: 0.17907050997018814, Final Batch Loss: 0.07058912515640259\n",
      "Epoch 1198, Loss: 0.2693149521946907, Final Batch Loss: 0.15784987807273865\n",
      "Epoch 1199, Loss: 0.19138253480196, Final Batch Loss: 0.09237080067396164\n",
      "Epoch 1200, Loss: 0.20643990486860275, Final Batch Loss: 0.10622456669807434\n",
      "Epoch 1201, Loss: 0.21467754244804382, Final Batch Loss: 0.14168646931648254\n",
      "Epoch 1202, Loss: 0.21813759207725525, Final Batch Loss: 0.08753885328769684\n",
      "Epoch 1203, Loss: 0.1982128918170929, Final Batch Loss: 0.08369901031255722\n",
      "Epoch 1204, Loss: 0.23837148398160934, Final Batch Loss: 0.1123567745089531\n",
      "Epoch 1205, Loss: 0.17439939826726913, Final Batch Loss: 0.08286846429109573\n",
      "Epoch 1206, Loss: 0.20557443797588348, Final Batch Loss: 0.11882498115301132\n",
      "Epoch 1207, Loss: 0.21520604938268661, Final Batch Loss: 0.1321643888950348\n",
      "Epoch 1208, Loss: 0.1853645220398903, Final Batch Loss: 0.11111025512218475\n",
      "Epoch 1209, Loss: 0.1777673289179802, Final Batch Loss: 0.08862708508968353\n",
      "Epoch 1210, Loss: 0.3248203843832016, Final Batch Loss: 0.19647599756717682\n",
      "Epoch 1211, Loss: 0.2184176966547966, Final Batch Loss: 0.11528531461954117\n",
      "Epoch 1212, Loss: 0.35160230100154877, Final Batch Loss: 0.2544640600681305\n",
      "Epoch 1213, Loss: 0.23513668030500412, Final Batch Loss: 0.1442958265542984\n",
      "Epoch 1214, Loss: 0.26307202130556107, Final Batch Loss: 0.1428011655807495\n",
      "Epoch 1215, Loss: 0.1777494177222252, Final Batch Loss: 0.0847008004784584\n",
      "Epoch 1216, Loss: 0.18338454514741898, Final Batch Loss: 0.09670519828796387\n",
      "Epoch 1217, Loss: 0.19892817735671997, Final Batch Loss: 0.10097211599349976\n",
      "Epoch 1218, Loss: 0.19259488582611084, Final Batch Loss: 0.06795750558376312\n",
      "Epoch 1219, Loss: 0.24914050847291946, Final Batch Loss: 0.16485907137393951\n",
      "Epoch 1220, Loss: 0.2139124944806099, Final Batch Loss: 0.09672338515520096\n",
      "Epoch 1221, Loss: 0.24055012315511703, Final Batch Loss: 0.08944221585988998\n",
      "Epoch 1222, Loss: 0.22162920981645584, Final Batch Loss: 0.08474873751401901\n",
      "Epoch 1223, Loss: 0.1815037503838539, Final Batch Loss: 0.10427363961935043\n",
      "Epoch 1224, Loss: 0.19679491966962814, Final Batch Loss: 0.11353344470262527\n",
      "Epoch 1225, Loss: 0.17788778990507126, Final Batch Loss: 0.07391553372144699\n",
      "Epoch 1226, Loss: 0.2220565378665924, Final Batch Loss: 0.06966327130794525\n",
      "Epoch 1227, Loss: 0.26741093397140503, Final Batch Loss: 0.15244746208190918\n",
      "Epoch 1228, Loss: 0.21525757759809494, Final Batch Loss: 0.10354005545377731\n",
      "Epoch 1229, Loss: 0.19856727868318558, Final Batch Loss: 0.1060434952378273\n",
      "Epoch 1230, Loss: 0.1521953046321869, Final Batch Loss: 0.058100685477256775\n",
      "Epoch 1231, Loss: 0.19111553579568863, Final Batch Loss: 0.0820438489317894\n",
      "Epoch 1232, Loss: 0.1723053976893425, Final Batch Loss: 0.08653988689184189\n",
      "Epoch 1233, Loss: 0.2973521277308464, Final Batch Loss: 0.11863375455141068\n",
      "Epoch 1234, Loss: 0.2588130608201027, Final Batch Loss: 0.09548167139291763\n",
      "Epoch 1235, Loss: 0.19662214815616608, Final Batch Loss: 0.10607019066810608\n",
      "Epoch 1236, Loss: 0.22076406329870224, Final Batch Loss: 0.12420311570167542\n",
      "Epoch 1237, Loss: 0.21023600548505783, Final Batch Loss: 0.09008628129959106\n",
      "Epoch 1238, Loss: 0.18764728307724, Final Batch Loss: 0.08987719565629959\n",
      "Epoch 1239, Loss: 0.2242269217967987, Final Batch Loss: 0.1021675318479538\n",
      "Epoch 1240, Loss: 0.21315129101276398, Final Batch Loss: 0.10848670452833176\n",
      "Epoch 1241, Loss: 0.20883239060640335, Final Batch Loss: 0.08222881704568863\n",
      "Epoch 1242, Loss: 0.1963989958167076, Final Batch Loss: 0.09857174009084702\n",
      "Epoch 1243, Loss: 0.1715407930314541, Final Batch Loss: 0.04996364936232567\n",
      "Epoch 1244, Loss: 0.1832270845770836, Final Batch Loss: 0.11171164363622665\n",
      "Epoch 1245, Loss: 0.2785779982805252, Final Batch Loss: 0.19207999110221863\n",
      "Epoch 1246, Loss: 0.22558436542749405, Final Batch Loss: 0.13750627636909485\n",
      "Epoch 1247, Loss: 0.18123426288366318, Final Batch Loss: 0.08344002813100815\n",
      "Epoch 1248, Loss: 0.2493990734219551, Final Batch Loss: 0.12160228937864304\n",
      "Epoch 1249, Loss: 0.2131112962961197, Final Batch Loss: 0.11933474242687225\n",
      "Epoch 1250, Loss: 0.17276087403297424, Final Batch Loss: 0.06951344013214111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1251, Loss: 0.19550004601478577, Final Batch Loss: 0.10191783308982849\n",
      "Epoch 1252, Loss: 0.2422742024064064, Final Batch Loss: 0.10777140408754349\n",
      "Epoch 1253, Loss: 0.17719653993844986, Final Batch Loss: 0.0800405964255333\n",
      "Epoch 1254, Loss: 0.16126851737499237, Final Batch Loss: 0.08377357572317123\n",
      "Epoch 1255, Loss: 0.20111322402954102, Final Batch Loss: 0.10351218283176422\n",
      "Epoch 1256, Loss: 0.1637682020664215, Final Batch Loss: 0.08549883961677551\n",
      "Epoch 1257, Loss: 0.19473256915807724, Final Batch Loss: 0.08531367033720016\n",
      "Epoch 1258, Loss: 0.2325032651424408, Final Batch Loss: 0.14102506637573242\n",
      "Epoch 1259, Loss: 0.22964328527450562, Final Batch Loss: 0.11061079800128937\n",
      "Epoch 1260, Loss: 0.2043231725692749, Final Batch Loss: 0.09331735968589783\n",
      "Epoch 1261, Loss: 0.16898784786462784, Final Batch Loss: 0.09035664051771164\n",
      "Epoch 1262, Loss: 0.2017708569765091, Final Batch Loss: 0.12744663655757904\n",
      "Epoch 1263, Loss: 0.22029449045658112, Final Batch Loss: 0.1135399118065834\n",
      "Epoch 1264, Loss: 0.20760775357484818, Final Batch Loss: 0.1184844821691513\n",
      "Epoch 1265, Loss: 0.1739598885178566, Final Batch Loss: 0.08165735751390457\n",
      "Epoch 1266, Loss: 0.24087346345186234, Final Batch Loss: 0.15686911344528198\n",
      "Epoch 1267, Loss: 0.21272563934326172, Final Batch Loss: 0.08253557980060577\n",
      "Epoch 1268, Loss: 0.18353815376758575, Final Batch Loss: 0.10139625519514084\n",
      "Epoch 1269, Loss: 0.2577577158808708, Final Batch Loss: 0.1504385620355606\n",
      "Epoch 1270, Loss: 0.23480769991874695, Final Batch Loss: 0.13220545649528503\n",
      "Epoch 1271, Loss: 0.17298168689012527, Final Batch Loss: 0.08593174070119858\n",
      "Epoch 1272, Loss: 0.18189695477485657, Final Batch Loss: 0.08696166425943375\n",
      "Epoch 1273, Loss: 0.24540134519338608, Final Batch Loss: 0.12526169419288635\n",
      "Epoch 1274, Loss: 0.18425043672323227, Final Batch Loss: 0.07624197006225586\n",
      "Epoch 1275, Loss: 0.17754682153463364, Final Batch Loss: 0.10080090910196304\n",
      "Epoch 1276, Loss: 0.20635325461626053, Final Batch Loss: 0.11358796060085297\n",
      "Epoch 1277, Loss: 0.18795277923345566, Final Batch Loss: 0.09906775504350662\n",
      "Epoch 1278, Loss: 0.1805027350783348, Final Batch Loss: 0.07509800046682358\n",
      "Epoch 1279, Loss: 0.1818336769938469, Final Batch Loss: 0.08872658014297485\n",
      "Epoch 1280, Loss: 0.1747800037264824, Final Batch Loss: 0.08238469064235687\n",
      "Epoch 1281, Loss: 0.17965855449438095, Final Batch Loss: 0.09039612859487534\n",
      "Epoch 1282, Loss: 0.2387128323316574, Final Batch Loss: 0.12233559042215347\n",
      "Epoch 1283, Loss: 0.29031913727521896, Final Batch Loss: 0.17478658258914948\n",
      "Epoch 1284, Loss: 0.2021123543381691, Final Batch Loss: 0.11089035123586655\n",
      "Epoch 1285, Loss: 0.16287274658679962, Final Batch Loss: 0.06368979066610336\n",
      "Epoch 1286, Loss: 0.20748146623373032, Final Batch Loss: 0.11317408084869385\n",
      "Epoch 1287, Loss: 0.16407525539398193, Final Batch Loss: 0.08933664858341217\n",
      "Epoch 1288, Loss: 0.2378152683377266, Final Batch Loss: 0.11292076855897903\n",
      "Epoch 1289, Loss: 0.19566000252962112, Final Batch Loss: 0.07868005335330963\n",
      "Epoch 1290, Loss: 0.16185037791728973, Final Batch Loss: 0.07326012849807739\n",
      "Epoch 1291, Loss: 0.16189203411340714, Final Batch Loss: 0.06451786309480667\n",
      "Epoch 1292, Loss: 0.24379462748765945, Final Batch Loss: 0.0806860700249672\n",
      "Epoch 1293, Loss: 0.16675623878836632, Final Batch Loss: 0.05142161622643471\n",
      "Epoch 1294, Loss: 0.20910771191120148, Final Batch Loss: 0.08057837188243866\n",
      "Epoch 1295, Loss: 0.22292691469192505, Final Batch Loss: 0.12047603726387024\n",
      "Epoch 1296, Loss: 0.19189117848873138, Final Batch Loss: 0.11945923417806625\n",
      "Epoch 1297, Loss: 0.22868216782808304, Final Batch Loss: 0.1295389086008072\n",
      "Epoch 1298, Loss: 0.20977670699357986, Final Batch Loss: 0.11490562558174133\n",
      "Epoch 1299, Loss: 0.1935461312532425, Final Batch Loss: 0.11252114176750183\n",
      "Epoch 1300, Loss: 0.17288832366466522, Final Batch Loss: 0.08654343336820602\n",
      "Epoch 1301, Loss: 0.17636065930128098, Final Batch Loss: 0.0975976511836052\n",
      "Epoch 1302, Loss: 0.22601012885570526, Final Batch Loss: 0.09130677580833435\n",
      "Epoch 1303, Loss: 0.25110577791929245, Final Batch Loss: 0.061293475329875946\n",
      "Epoch 1304, Loss: 0.19516170769929886, Final Batch Loss: 0.08308275043964386\n",
      "Epoch 1305, Loss: 0.20067432522773743, Final Batch Loss: 0.11778821796178818\n",
      "Epoch 1306, Loss: 0.1990092173218727, Final Batch Loss: 0.08351267129182816\n",
      "Epoch 1307, Loss: 0.1661851480603218, Final Batch Loss: 0.08933064341545105\n",
      "Epoch 1308, Loss: 0.15809153020381927, Final Batch Loss: 0.08584998548030853\n",
      "Epoch 1309, Loss: 0.17187613248825073, Final Batch Loss: 0.07871831953525543\n",
      "Epoch 1310, Loss: 0.25592703372240067, Final Batch Loss: 0.1405787616968155\n",
      "Epoch 1311, Loss: 0.19037975370883942, Final Batch Loss: 0.11662492156028748\n",
      "Epoch 1312, Loss: 0.1447603404521942, Final Batch Loss: 0.06541768461465836\n",
      "Epoch 1313, Loss: 0.21039462089538574, Final Batch Loss: 0.10538774728775024\n",
      "Epoch 1314, Loss: 0.2136300802230835, Final Batch Loss: 0.11635361611843109\n",
      "Epoch 1315, Loss: 0.2495754361152649, Final Batch Loss: 0.16559065878391266\n",
      "Epoch 1316, Loss: 0.1785595379769802, Final Batch Loss: 0.061504002660512924\n",
      "Epoch 1317, Loss: 0.19701869040727615, Final Batch Loss: 0.07742767035961151\n",
      "Epoch 1318, Loss: 0.17778725922107697, Final Batch Loss: 0.0841650441288948\n",
      "Epoch 1319, Loss: 0.1869855746626854, Final Batch Loss: 0.08907176554203033\n",
      "Epoch 1320, Loss: 0.2511064037680626, Final Batch Loss: 0.09008552879095078\n",
      "Epoch 1321, Loss: 0.15433840081095695, Final Batch Loss: 0.05816909298300743\n",
      "Epoch 1322, Loss: 0.22035567462444305, Final Batch Loss: 0.10528980940580368\n",
      "Epoch 1323, Loss: 0.16992449015378952, Final Batch Loss: 0.06964748352766037\n",
      "Epoch 1324, Loss: 0.22623410820960999, Final Batch Loss: 0.1044381782412529\n",
      "Epoch 1325, Loss: 0.16199471056461334, Final Batch Loss: 0.06863081455230713\n",
      "Epoch 1326, Loss: 0.19927985966205597, Final Batch Loss: 0.09556902199983597\n",
      "Epoch 1327, Loss: 0.283319354057312, Final Batch Loss: 0.19164933264255524\n",
      "Epoch 1328, Loss: 0.18754101544618607, Final Batch Loss: 0.10305874794721603\n",
      "Epoch 1329, Loss: 0.21466638147830963, Final Batch Loss: 0.09204065054655075\n",
      "Epoch 1330, Loss: 0.24775047600269318, Final Batch Loss: 0.1517132967710495\n",
      "Epoch 1331, Loss: 0.22574367374181747, Final Batch Loss: 0.098399318754673\n",
      "Epoch 1332, Loss: 0.19559545814990997, Final Batch Loss: 0.10806164145469666\n",
      "Epoch 1333, Loss: 0.18052361905574799, Final Batch Loss: 0.09433767199516296\n",
      "Epoch 1334, Loss: 0.22992298007011414, Final Batch Loss: 0.09527480602264404\n",
      "Epoch 1335, Loss: 0.18359070271253586, Final Batch Loss: 0.07238491624593735\n",
      "Epoch 1336, Loss: 0.20696353167295456, Final Batch Loss: 0.13263119757175446\n",
      "Epoch 1337, Loss: 0.20740962773561478, Final Batch Loss: 0.10235361754894257\n",
      "Epoch 1338, Loss: 0.15346702188253403, Final Batch Loss: 0.059750013053417206\n",
      "Epoch 1339, Loss: 0.16135545819997787, Final Batch Loss: 0.05378420650959015\n",
      "Epoch 1340, Loss: 0.17282884567975998, Final Batch Loss: 0.10229116678237915\n",
      "Epoch 1341, Loss: 0.18974968791007996, Final Batch Loss: 0.07420546561479568\n",
      "Epoch 1342, Loss: 0.16403408348560333, Final Batch Loss: 0.0873328372836113\n",
      "Epoch 1343, Loss: 0.16929228603839874, Final Batch Loss: 0.07913696020841599\n",
      "Epoch 1344, Loss: 0.22429640591144562, Final Batch Loss: 0.1321157068014145\n",
      "Epoch 1345, Loss: 0.17907828092575073, Final Batch Loss: 0.06470844149589539\n",
      "Epoch 1346, Loss: 0.20355764031410217, Final Batch Loss: 0.10284873843193054\n",
      "Epoch 1347, Loss: 0.230837881565094, Final Batch Loss: 0.13674744963645935\n",
      "Epoch 1348, Loss: 0.207097627222538, Final Batch Loss: 0.12261581420898438\n",
      "Epoch 1349, Loss: 0.22201485186815262, Final Batch Loss: 0.1320723444223404\n",
      "Epoch 1350, Loss: 0.24321643263101578, Final Batch Loss: 0.1518126130104065\n",
      "Epoch 1351, Loss: 0.21374443918466568, Final Batch Loss: 0.12346167117357254\n",
      "Epoch 1352, Loss: 0.17610745877027512, Final Batch Loss: 0.06936287134885788\n",
      "Epoch 1353, Loss: 0.16126036643981934, Final Batch Loss: 0.07518234848976135\n",
      "Epoch 1354, Loss: 0.16291360557079315, Final Batch Loss: 0.0630803033709526\n",
      "Epoch 1355, Loss: 0.20169147849082947, Final Batch Loss: 0.10687790811061859\n",
      "Epoch 1356, Loss: 0.15939538180828094, Final Batch Loss: 0.06688502430915833\n",
      "Epoch 1357, Loss: 0.21759619563817978, Final Batch Loss: 0.10228153318166733\n",
      "Epoch 1358, Loss: 0.20467837154865265, Final Batch Loss: 0.10538524389266968\n",
      "Epoch 1359, Loss: 0.1557564213871956, Final Batch Loss: 0.09070906788110733\n",
      "Epoch 1360, Loss: 0.14150253683328629, Final Batch Loss: 0.06504256278276443\n",
      "Epoch 1361, Loss: 0.12623701617121696, Final Batch Loss: 0.05024642124772072\n",
      "Epoch 1362, Loss: 0.16372011974453926, Final Batch Loss: 0.05897379294037819\n",
      "Epoch 1363, Loss: 0.2159651294350624, Final Batch Loss: 0.14551478624343872\n",
      "Epoch 1364, Loss: 0.15256962180137634, Final Batch Loss: 0.05484528839588165\n",
      "Epoch 1365, Loss: 0.18308646976947784, Final Batch Loss: 0.08500808477401733\n",
      "Epoch 1366, Loss: 0.21212545782327652, Final Batch Loss: 0.08199463039636612\n",
      "Epoch 1367, Loss: 0.15985116362571716, Final Batch Loss: 0.09272962063550949\n",
      "Epoch 1368, Loss: 0.17350086569786072, Final Batch Loss: 0.0843021348118782\n",
      "Epoch 1369, Loss: 0.17603041976690292, Final Batch Loss: 0.10628878325223923\n",
      "Epoch 1370, Loss: 0.18012190610170364, Final Batch Loss: 0.10015164315700531\n",
      "Epoch 1371, Loss: 0.17546308785676956, Final Batch Loss: 0.08961974084377289\n",
      "Epoch 1372, Loss: 0.19076932221651077, Final Batch Loss: 0.10558860749006271\n",
      "Epoch 1373, Loss: 0.18078651279211044, Final Batch Loss: 0.10007284581661224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1374, Loss: 0.16694753617048264, Final Batch Loss: 0.08292043954133987\n",
      "Epoch 1375, Loss: 0.24731704592704773, Final Batch Loss: 0.10688643157482147\n",
      "Epoch 1376, Loss: 0.19895098358392715, Final Batch Loss: 0.08063583821058273\n",
      "Epoch 1377, Loss: 0.1850191131234169, Final Batch Loss: 0.06409762054681778\n",
      "Epoch 1378, Loss: 0.16322658956050873, Final Batch Loss: 0.0814744234085083\n",
      "Epoch 1379, Loss: 0.1795056238770485, Final Batch Loss: 0.10791250318288803\n",
      "Epoch 1380, Loss: 0.1678495928645134, Final Batch Loss: 0.09594521671533585\n",
      "Epoch 1381, Loss: 0.17001580819487572, Final Batch Loss: 0.05913938954472542\n",
      "Epoch 1382, Loss: 0.2084103524684906, Final Batch Loss: 0.12190243601799011\n",
      "Epoch 1383, Loss: 0.21385393291711807, Final Batch Loss: 0.11037316173315048\n",
      "Epoch 1384, Loss: 0.16411113739013672, Final Batch Loss: 0.09684392064809799\n",
      "Epoch 1385, Loss: 0.1564980074763298, Final Batch Loss: 0.09644751995801926\n",
      "Epoch 1386, Loss: 0.17213410884141922, Final Batch Loss: 0.10913664847612381\n",
      "Epoch 1387, Loss: 0.16263124346733093, Final Batch Loss: 0.09500091522932053\n",
      "Epoch 1388, Loss: 0.15132638812065125, Final Batch Loss: 0.06778068840503693\n",
      "Epoch 1389, Loss: 0.1831599324941635, Final Batch Loss: 0.09155073761940002\n",
      "Epoch 1390, Loss: 0.14826145768165588, Final Batch Loss: 0.053010448813438416\n",
      "Epoch 1391, Loss: 0.12958666682243347, Final Batch Loss: 0.05807262659072876\n",
      "Epoch 1392, Loss: 0.14951913058757782, Final Batch Loss: 0.06656448543071747\n",
      "Epoch 1393, Loss: 0.18494116514921188, Final Batch Loss: 0.05911370366811752\n",
      "Epoch 1394, Loss: 0.17321158945560455, Final Batch Loss: 0.09362232685089111\n",
      "Epoch 1395, Loss: 0.21779900044202805, Final Batch Loss: 0.11795568466186523\n",
      "Epoch 1396, Loss: 0.16433967649936676, Final Batch Loss: 0.09009397774934769\n",
      "Epoch 1397, Loss: 0.15573586896061897, Final Batch Loss: 0.058247070759534836\n",
      "Epoch 1398, Loss: 0.19174595177173615, Final Batch Loss: 0.08684307336807251\n",
      "Epoch 1399, Loss: 0.15542326867580414, Final Batch Loss: 0.07201499491930008\n",
      "Epoch 1400, Loss: 0.16507065296173096, Final Batch Loss: 0.09482867270708084\n",
      "Epoch 1401, Loss: 0.19253717362880707, Final Batch Loss: 0.0709887146949768\n",
      "Epoch 1402, Loss: 0.1887890100479126, Final Batch Loss: 0.10181853920221329\n",
      "Epoch 1403, Loss: 0.1552954539656639, Final Batch Loss: 0.07564275711774826\n",
      "Epoch 1404, Loss: 0.17617366462945938, Final Batch Loss: 0.09612482786178589\n",
      "Epoch 1405, Loss: 0.2057567462325096, Final Batch Loss: 0.10271453112363815\n",
      "Epoch 1406, Loss: 0.1223205029964447, Final Batch Loss: 0.055891312658786774\n",
      "Epoch 1407, Loss: 0.13264409825205803, Final Batch Loss: 0.07084805518388748\n",
      "Epoch 1408, Loss: 0.14304477721452713, Final Batch Loss: 0.04841269552707672\n",
      "Epoch 1409, Loss: 0.2502289265394211, Final Batch Loss: 0.1658712476491928\n",
      "Epoch 1410, Loss: 0.17439599335193634, Final Batch Loss: 0.10714071244001389\n",
      "Epoch 1411, Loss: 0.14651285484433174, Final Batch Loss: 0.08513947576284409\n",
      "Epoch 1412, Loss: 0.21728218346834183, Final Batch Loss: 0.10750158131122589\n",
      "Epoch 1413, Loss: 0.20528937876224518, Final Batch Loss: 0.12306557595729828\n",
      "Epoch 1414, Loss: 0.16889209300279617, Final Batch Loss: 0.08403970301151276\n",
      "Epoch 1415, Loss: 0.1989952102303505, Final Batch Loss: 0.0917404517531395\n",
      "Epoch 1416, Loss: 0.25699345022439957, Final Batch Loss: 0.14963291585445404\n",
      "Epoch 1417, Loss: 0.13261177390813828, Final Batch Loss: 0.05053243041038513\n",
      "Epoch 1418, Loss: 0.14862744137644768, Final Batch Loss: 0.08952650427818298\n",
      "Epoch 1419, Loss: 0.1730121597647667, Final Batch Loss: 0.10153621435165405\n",
      "Epoch 1420, Loss: 0.18534095957875252, Final Batch Loss: 0.1332074999809265\n",
      "Epoch 1421, Loss: 0.14287517592310905, Final Batch Loss: 0.049808625131845474\n",
      "Epoch 1422, Loss: 0.1580759659409523, Final Batch Loss: 0.07527673244476318\n",
      "Epoch 1423, Loss: 0.20250154286623, Final Batch Loss: 0.11433660238981247\n",
      "Epoch 1424, Loss: 0.1745855063199997, Final Batch Loss: 0.07678020745515823\n",
      "Epoch 1425, Loss: 0.17360835522413254, Final Batch Loss: 0.06766089051961899\n",
      "Epoch 1426, Loss: 0.15137066692113876, Final Batch Loss: 0.06921123713254929\n",
      "Epoch 1427, Loss: 0.1591412052512169, Final Batch Loss: 0.07982809096574783\n",
      "Epoch 1428, Loss: 0.19297780841588974, Final Batch Loss: 0.12397870421409607\n",
      "Epoch 1429, Loss: 0.17636124417185783, Final Batch Loss: 0.05768116936087608\n",
      "Epoch 1430, Loss: 0.221417635679245, Final Batch Loss: 0.1013534888625145\n",
      "Epoch 1431, Loss: 0.1345175914466381, Final Batch Loss: 0.049406278878450394\n",
      "Epoch 1432, Loss: 0.14382146298885345, Final Batch Loss: 0.08770818263292313\n",
      "Epoch 1433, Loss: 0.20511936396360397, Final Batch Loss: 0.11914285272359848\n",
      "Epoch 1434, Loss: 0.20537668466567993, Final Batch Loss: 0.12451615929603577\n",
      "Epoch 1435, Loss: 0.19304119050502777, Final Batch Loss: 0.11068535596132278\n",
      "Epoch 1436, Loss: 0.12449400871992111, Final Batch Loss: 0.06682178378105164\n",
      "Epoch 1437, Loss: 0.17870566993951797, Final Batch Loss: 0.09095021337270737\n",
      "Epoch 1438, Loss: 0.16177546232938766, Final Batch Loss: 0.0775732547044754\n",
      "Epoch 1439, Loss: 0.16982372850179672, Final Batch Loss: 0.07002801448106766\n",
      "Epoch 1440, Loss: 0.16233881562948227, Final Batch Loss: 0.06406226009130478\n",
      "Epoch 1441, Loss: 0.16810040920972824, Final Batch Loss: 0.08776026219129562\n",
      "Epoch 1442, Loss: 0.23255882412195206, Final Batch Loss: 0.12989442050457\n",
      "Epoch 1443, Loss: 0.16628985852003098, Final Batch Loss: 0.0706687867641449\n",
      "Epoch 1444, Loss: 0.1323547326028347, Final Batch Loss: 0.07292096316814423\n",
      "Epoch 1445, Loss: 0.18498513847589493, Final Batch Loss: 0.10066748410463333\n",
      "Epoch 1446, Loss: 0.17512919753789902, Final Batch Loss: 0.10471964627504349\n",
      "Epoch 1447, Loss: 0.13843343034386635, Final Batch Loss: 0.08261016011238098\n",
      "Epoch 1448, Loss: 0.2018335461616516, Final Batch Loss: 0.10924293100833893\n",
      "Epoch 1449, Loss: 0.1808653622865677, Final Batch Loss: 0.10419899970293045\n",
      "Epoch 1450, Loss: 0.18294885009527206, Final Batch Loss: 0.08456838876008987\n",
      "Epoch 1451, Loss: 0.1193242184817791, Final Batch Loss: 0.04049399867653847\n",
      "Epoch 1452, Loss: 0.18552729487419128, Final Batch Loss: 0.11443217843770981\n",
      "Epoch 1453, Loss: 0.18003633618354797, Final Batch Loss: 0.09296225756406784\n",
      "Epoch 1454, Loss: 0.13199199736118317, Final Batch Loss: 0.05090443044900894\n",
      "Epoch 1455, Loss: 0.19139458239078522, Final Batch Loss: 0.09752105921506882\n",
      "Epoch 1456, Loss: 0.1598835326731205, Final Batch Loss: 0.10555165261030197\n",
      "Epoch 1457, Loss: 0.16544561833143234, Final Batch Loss: 0.06850819289684296\n",
      "Epoch 1458, Loss: 0.17033561319112778, Final Batch Loss: 0.0876481831073761\n",
      "Epoch 1459, Loss: 0.2309497520327568, Final Batch Loss: 0.17113730311393738\n",
      "Epoch 1460, Loss: 0.17075131833553314, Final Batch Loss: 0.09151755273342133\n",
      "Epoch 1461, Loss: 0.1872955560684204, Final Batch Loss: 0.07325103133916855\n",
      "Epoch 1462, Loss: 0.18688350915908813, Final Batch Loss: 0.11604293435811996\n",
      "Epoch 1463, Loss: 0.1975058764219284, Final Batch Loss: 0.10113988071680069\n",
      "Epoch 1464, Loss: 0.1918332651257515, Final Batch Loss: 0.08451665937900543\n",
      "Epoch 1465, Loss: 0.2124496027827263, Final Batch Loss: 0.11939582228660583\n",
      "Epoch 1466, Loss: 0.16110818088054657, Final Batch Loss: 0.0733976736664772\n",
      "Epoch 1467, Loss: 0.1448841281235218, Final Batch Loss: 0.08968126773834229\n",
      "Epoch 1468, Loss: 0.18683408945798874, Final Batch Loss: 0.08300291001796722\n",
      "Epoch 1469, Loss: 0.20678891986608505, Final Batch Loss: 0.12382344156503677\n",
      "Epoch 1470, Loss: 0.17078384011983871, Final Batch Loss: 0.06065135449171066\n",
      "Epoch 1471, Loss: 0.1336047761142254, Final Batch Loss: 0.07607553899288177\n",
      "Epoch 1472, Loss: 0.15435411781072617, Final Batch Loss: 0.04991507530212402\n",
      "Epoch 1473, Loss: 0.17797261476516724, Final Batch Loss: 0.11194051057100296\n",
      "Epoch 1474, Loss: 0.18248721212148666, Final Batch Loss: 0.07869575917720795\n",
      "Epoch 1475, Loss: 0.1828330159187317, Final Batch Loss: 0.07290727645158768\n",
      "Epoch 1476, Loss: 0.1493823118507862, Final Batch Loss: 0.05379888787865639\n",
      "Epoch 1477, Loss: 0.1460738480091095, Final Batch Loss: 0.0783160924911499\n",
      "Epoch 1478, Loss: 0.16091735661029816, Final Batch Loss: 0.06707104295492172\n",
      "Epoch 1479, Loss: 0.23031198978424072, Final Batch Loss: 0.14358940720558167\n",
      "Epoch 1480, Loss: 0.16408580541610718, Final Batch Loss: 0.06378579139709473\n",
      "Epoch 1481, Loss: 0.1491730883717537, Final Batch Loss: 0.06232346594333649\n",
      "Epoch 1482, Loss: 0.15363288670778275, Final Batch Loss: 0.08292584866285324\n",
      "Epoch 1483, Loss: 0.1738695725798607, Final Batch Loss: 0.09849569946527481\n",
      "Epoch 1484, Loss: 0.14171591773629189, Final Batch Loss: 0.07945376634597778\n",
      "Epoch 1485, Loss: 0.15132904052734375, Final Batch Loss: 0.06841481477022171\n",
      "Epoch 1486, Loss: 0.12911119684576988, Final Batch Loss: 0.06960076838731766\n",
      "Epoch 1487, Loss: 0.17997592687606812, Final Batch Loss: 0.08727560937404633\n",
      "Epoch 1488, Loss: 0.18139372766017914, Final Batch Loss: 0.1047416403889656\n",
      "Epoch 1489, Loss: 0.20558760315179825, Final Batch Loss: 0.13892264664173126\n",
      "Epoch 1490, Loss: 0.1608804538846016, Final Batch Loss: 0.08703073114156723\n",
      "Epoch 1491, Loss: 0.18374419212341309, Final Batch Loss: 0.10160046815872192\n",
      "Epoch 1492, Loss: 0.1462750807404518, Final Batch Loss: 0.050285667181015015\n",
      "Epoch 1493, Loss: 0.15667560696601868, Final Batch Loss: 0.09774096310138702\n",
      "Epoch 1494, Loss: 0.12494676187634468, Final Batch Loss: 0.08096365630626678\n",
      "Epoch 1495, Loss: 0.1591300368309021, Final Batch Loss: 0.09756693243980408\n",
      "Epoch 1496, Loss: 0.1252712570130825, Final Batch Loss: 0.0496537871658802\n",
      "Epoch 1497, Loss: 0.14686746150255203, Final Batch Loss: 0.08252666145563126\n",
      "Epoch 1498, Loss: 0.16461120545864105, Final Batch Loss: 0.09748370945453644\n",
      "Epoch 1499, Loss: 0.2345350980758667, Final Batch Loss: 0.07718726992607117\n",
      "Epoch 1500, Loss: 0.15924681723117828, Final Batch Loss: 0.08379634469747543\n",
      "Epoch 1501, Loss: 0.12583167478442192, Final Batch Loss: 0.0586492158472538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1502, Loss: 0.15930650383234024, Final Batch Loss: 0.09005115926265717\n",
      "Epoch 1503, Loss: 0.1488395482301712, Final Batch Loss: 0.05564829707145691\n",
      "Epoch 1504, Loss: 0.2032143622636795, Final Batch Loss: 0.11009000986814499\n",
      "Epoch 1505, Loss: 0.11646720767021179, Final Batch Loss: 0.05081486701965332\n",
      "Epoch 1506, Loss: 0.13875014334917068, Final Batch Loss: 0.06339683383703232\n",
      "Epoch 1507, Loss: 0.2265913262963295, Final Batch Loss: 0.09763891249895096\n",
      "Epoch 1508, Loss: 0.2398483157157898, Final Batch Loss: 0.1392364352941513\n",
      "Epoch 1509, Loss: 0.1275700367987156, Final Batch Loss: 0.04904010519385338\n",
      "Epoch 1510, Loss: 0.13316669315099716, Final Batch Loss: 0.06799585372209549\n",
      "Epoch 1511, Loss: 0.2676576003432274, Final Batch Loss: 0.19696520268917084\n",
      "Epoch 1512, Loss: 0.1910068243741989, Final Batch Loss: 0.08735626935958862\n",
      "Epoch 1513, Loss: 0.15355797111988068, Final Batch Loss: 0.09775866568088531\n",
      "Epoch 1514, Loss: 0.16649814695119858, Final Batch Loss: 0.08837713301181793\n",
      "Epoch 1515, Loss: 0.1356675885617733, Final Batch Loss: 0.07601232826709747\n",
      "Epoch 1516, Loss: 0.14558548852801323, Final Batch Loss: 0.05448577180504799\n",
      "Epoch 1517, Loss: 0.14601103216409683, Final Batch Loss: 0.07180038094520569\n",
      "Epoch 1518, Loss: 0.1760919988155365, Final Batch Loss: 0.08680587261915207\n",
      "Epoch 1519, Loss: 0.11399484425783157, Final Batch Loss: 0.06505586951971054\n",
      "Epoch 1520, Loss: 0.16581988334655762, Final Batch Loss: 0.07619422674179077\n",
      "Epoch 1521, Loss: 0.1430348940193653, Final Batch Loss: 0.05530126020312309\n",
      "Epoch 1522, Loss: 0.1465097740292549, Final Batch Loss: 0.05851033329963684\n",
      "Epoch 1523, Loss: 0.1313077136874199, Final Batch Loss: 0.06876122951507568\n",
      "Epoch 1524, Loss: 0.17239337414503098, Final Batch Loss: 0.1102883517742157\n",
      "Epoch 1525, Loss: 0.11351756379008293, Final Batch Loss: 0.06713966280221939\n",
      "Epoch 1526, Loss: 0.17004980891942978, Final Batch Loss: 0.08519760519266129\n",
      "Epoch 1527, Loss: 0.10598401166498661, Final Batch Loss: 0.029676200821995735\n",
      "Epoch 1528, Loss: 0.1592041477560997, Final Batch Loss: 0.0537695437669754\n",
      "Epoch 1529, Loss: 0.14057134091854095, Final Batch Loss: 0.04267764836549759\n",
      "Epoch 1530, Loss: 0.13412438333034515, Final Batch Loss: 0.07105118781328201\n",
      "Epoch 1531, Loss: 0.16231068968772888, Final Batch Loss: 0.062836192548275\n",
      "Epoch 1532, Loss: 0.16787715628743172, Final Batch Loss: 0.13117355108261108\n",
      "Epoch 1533, Loss: 0.13179673627018929, Final Batch Loss: 0.05286828801035881\n",
      "Epoch 1534, Loss: 0.09178540483117104, Final Batch Loss: 0.03610069677233696\n",
      "Epoch 1535, Loss: 0.12260333448648453, Final Batch Loss: 0.0611315593123436\n",
      "Epoch 1536, Loss: 0.15210575237870216, Final Batch Loss: 0.10972727835178375\n",
      "Epoch 1537, Loss: 0.2292894497513771, Final Batch Loss: 0.15255890786647797\n",
      "Epoch 1538, Loss: 0.15863067284226418, Final Batch Loss: 0.0417800210416317\n",
      "Epoch 1539, Loss: 0.16907357797026634, Final Batch Loss: 0.06223081424832344\n",
      "Epoch 1540, Loss: 0.1639229878783226, Final Batch Loss: 0.08801469206809998\n",
      "Epoch 1541, Loss: 0.11446363851428032, Final Batch Loss: 0.06412903219461441\n",
      "Epoch 1542, Loss: 0.143733661621809, Final Batch Loss: 0.09190056473016739\n",
      "Epoch 1543, Loss: 0.17008299380540848, Final Batch Loss: 0.09543049335479736\n",
      "Epoch 1544, Loss: 0.1387990564107895, Final Batch Loss: 0.06661072373390198\n",
      "Epoch 1545, Loss: 0.12194468453526497, Final Batch Loss: 0.04933072254061699\n",
      "Epoch 1546, Loss: 0.14216310158371925, Final Batch Loss: 0.053216855973005295\n",
      "Epoch 1547, Loss: 0.12982571125030518, Final Batch Loss: 0.04570753127336502\n",
      "Epoch 1548, Loss: 0.17115283757448196, Final Batch Loss: 0.09193579107522964\n",
      "Epoch 1549, Loss: 0.209061898291111, Final Batch Loss: 0.09229344874620438\n",
      "Epoch 1550, Loss: 0.15023907274007797, Final Batch Loss: 0.07237567752599716\n",
      "Epoch 1551, Loss: 0.12369976192712784, Final Batch Loss: 0.0590302050113678\n",
      "Epoch 1552, Loss: 0.14156091213226318, Final Batch Loss: 0.0677027553319931\n",
      "Epoch 1553, Loss: 0.16224206611514091, Final Batch Loss: 0.10072523355484009\n",
      "Epoch 1554, Loss: 0.15158835425972939, Final Batch Loss: 0.04577938839793205\n",
      "Epoch 1555, Loss: 0.18434003740549088, Final Batch Loss: 0.1070941835641861\n",
      "Epoch 1556, Loss: 0.16963239014148712, Final Batch Loss: 0.0999697893857956\n",
      "Epoch 1557, Loss: 0.1082044169306755, Final Batch Loss: 0.04870230704545975\n",
      "Epoch 1558, Loss: 0.12040288001298904, Final Batch Loss: 0.047392018139362335\n",
      "Epoch 1559, Loss: 0.21777625381946564, Final Batch Loss: 0.07501287758350372\n",
      "Epoch 1560, Loss: 0.16034629940986633, Final Batch Loss: 0.08984312415122986\n",
      "Epoch 1561, Loss: 0.150961484760046, Final Batch Loss: 0.0407414473593235\n",
      "Epoch 1562, Loss: 0.1262957751750946, Final Batch Loss: 0.04440291225910187\n",
      "Epoch 1563, Loss: 0.1390056535601616, Final Batch Loss: 0.05659694969654083\n",
      "Epoch 1564, Loss: 0.1440962813794613, Final Batch Loss: 0.08800312131643295\n",
      "Epoch 1565, Loss: 0.16571110114455223, Final Batch Loss: 0.11052051931619644\n",
      "Epoch 1566, Loss: 0.17666346207261086, Final Batch Loss: 0.11724542826414108\n",
      "Epoch 1567, Loss: 0.1406659334897995, Final Batch Loss: 0.07597377151250839\n",
      "Epoch 1568, Loss: 0.0897446759045124, Final Batch Loss: 0.03287487477064133\n",
      "Epoch 1569, Loss: 0.13383744657039642, Final Batch Loss: 0.06661362946033478\n",
      "Epoch 1570, Loss: 0.1336582899093628, Final Batch Loss: 0.06983194500207901\n",
      "Epoch 1571, Loss: 0.1316075325012207, Final Batch Loss: 0.07082904875278473\n",
      "Epoch 1572, Loss: 0.17644824087619781, Final Batch Loss: 0.10663925856351852\n",
      "Epoch 1573, Loss: 0.1508365422487259, Final Batch Loss: 0.08723709732294083\n",
      "Epoch 1574, Loss: 0.1983313336968422, Final Batch Loss: 0.11657124757766724\n",
      "Epoch 1575, Loss: 0.13468016684055328, Final Batch Loss: 0.06968263536691666\n",
      "Epoch 1576, Loss: 0.21161436289548874, Final Batch Loss: 0.1496933549642563\n",
      "Epoch 1577, Loss: 0.1090075708925724, Final Batch Loss: 0.042847175151109695\n",
      "Epoch 1578, Loss: 0.14057641103863716, Final Batch Loss: 0.08639010787010193\n",
      "Epoch 1579, Loss: 0.11390084400773048, Final Batch Loss: 0.0513479970395565\n",
      "Epoch 1580, Loss: 0.14632007479667664, Final Batch Loss: 0.06448904424905777\n",
      "Epoch 1581, Loss: 0.17215949296951294, Final Batch Loss: 0.08711805194616318\n",
      "Epoch 1582, Loss: 0.21580536663532257, Final Batch Loss: 0.12577152252197266\n",
      "Epoch 1583, Loss: 0.15810072422027588, Final Batch Loss: 0.09494320303201675\n",
      "Epoch 1584, Loss: 0.1708231195807457, Final Batch Loss: 0.1035926416516304\n",
      "Epoch 1585, Loss: 0.14981772378087044, Final Batch Loss: 0.058744918555021286\n",
      "Epoch 1586, Loss: 0.1506178304553032, Final Batch Loss: 0.05647187680006027\n",
      "Epoch 1587, Loss: 0.2418394684791565, Final Batch Loss: 0.1616578847169876\n",
      "Epoch 1588, Loss: 0.16108085215091705, Final Batch Loss: 0.08675146102905273\n",
      "Epoch 1589, Loss: 0.1333281546831131, Final Batch Loss: 0.0642930269241333\n",
      "Epoch 1590, Loss: 0.12630098313093185, Final Batch Loss: 0.05822429805994034\n",
      "Epoch 1591, Loss: 0.18495961278676987, Final Batch Loss: 0.08819893002510071\n",
      "Epoch 1592, Loss: 0.15412434935569763, Final Batch Loss: 0.06681957840919495\n",
      "Epoch 1593, Loss: 0.17318806797266006, Final Batch Loss: 0.05016085505485535\n",
      "Epoch 1594, Loss: 0.17087219655513763, Final Batch Loss: 0.07506780326366425\n",
      "Epoch 1595, Loss: 0.1385401301085949, Final Batch Loss: 0.07806871086359024\n",
      "Epoch 1596, Loss: 0.07939627766609192, Final Batch Loss: 0.024968519806861877\n",
      "Epoch 1597, Loss: 0.15565689653158188, Final Batch Loss: 0.07364023476839066\n",
      "Epoch 1598, Loss: 0.0986948274075985, Final Batch Loss: 0.0586099699139595\n",
      "Epoch 1599, Loss: 0.1644023060798645, Final Batch Loss: 0.09239106625318527\n",
      "Epoch 1600, Loss: 0.10544466599822044, Final Batch Loss: 0.03886083886027336\n",
      "Epoch 1601, Loss: 0.22356904298067093, Final Batch Loss: 0.12748074531555176\n",
      "Epoch 1602, Loss: 0.13455981388688087, Final Batch Loss: 0.08275888115167618\n",
      "Epoch 1603, Loss: 0.12737617641687393, Final Batch Loss: 0.036576300859451294\n",
      "Epoch 1604, Loss: 0.14014700800180435, Final Batch Loss: 0.08879289776086807\n",
      "Epoch 1605, Loss: 0.09341320022940636, Final Batch Loss: 0.0500919371843338\n",
      "Epoch 1606, Loss: 0.111066784709692, Final Batch Loss: 0.0608641617000103\n",
      "Epoch 1607, Loss: 0.1421404965221882, Final Batch Loss: 0.09087776392698288\n",
      "Epoch 1608, Loss: 0.19154106825590134, Final Batch Loss: 0.0815260112285614\n",
      "Epoch 1609, Loss: 0.14434454590082169, Final Batch Loss: 0.06663481891155243\n",
      "Epoch 1610, Loss: 0.15458060801029205, Final Batch Loss: 0.08144006878137589\n",
      "Epoch 1611, Loss: 0.1497025117278099, Final Batch Loss: 0.07610032707452774\n",
      "Epoch 1612, Loss: 0.13525119796395302, Final Batch Loss: 0.07698991149663925\n",
      "Epoch 1613, Loss: 0.2860967293381691, Final Batch Loss: 0.21897760033607483\n",
      "Epoch 1614, Loss: 0.1444399133324623, Final Batch Loss: 0.03890477120876312\n",
      "Epoch 1615, Loss: 0.08708548173308372, Final Batch Loss: 0.03852781280875206\n",
      "Epoch 1616, Loss: 0.12079733237624168, Final Batch Loss: 0.053765568882226944\n",
      "Epoch 1617, Loss: 0.10772302746772766, Final Batch Loss: 0.059233296662569046\n",
      "Epoch 1618, Loss: 0.1447002813220024, Final Batch Loss: 0.07462570071220398\n",
      "Epoch 1619, Loss: 0.17288505285978317, Final Batch Loss: 0.12991812825202942\n",
      "Epoch 1620, Loss: 0.11707987636327744, Final Batch Loss: 0.0658494383096695\n",
      "Epoch 1621, Loss: 0.10123823583126068, Final Batch Loss: 0.03863036632537842\n",
      "Epoch 1622, Loss: 0.14388926327228546, Final Batch Loss: 0.05621039867401123\n",
      "Epoch 1623, Loss: 0.1814706102013588, Final Batch Loss: 0.1157558411359787\n",
      "Epoch 1624, Loss: 0.14973430335521698, Final Batch Loss: 0.07355615496635437\n",
      "Epoch 1625, Loss: 0.10463245958089828, Final Batch Loss: 0.05669933557510376\n",
      "Epoch 1626, Loss: 0.1082686148583889, Final Batch Loss: 0.046363428235054016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1627, Loss: 0.16941359266638756, Final Batch Loss: 0.10946068912744522\n",
      "Epoch 1628, Loss: 0.09980091080069542, Final Batch Loss: 0.03631198778748512\n",
      "Epoch 1629, Loss: 0.1493566632270813, Final Batch Loss: 0.07275700569152832\n",
      "Epoch 1630, Loss: 0.1462443694472313, Final Batch Loss: 0.06228077411651611\n",
      "Epoch 1631, Loss: 0.2204132080078125, Final Batch Loss: 0.10392957925796509\n",
      "Epoch 1632, Loss: 0.14490748941898346, Final Batch Loss: 0.07363785803318024\n",
      "Epoch 1633, Loss: 0.11070286482572556, Final Batch Loss: 0.06188943237066269\n",
      "Epoch 1634, Loss: 0.2252674400806427, Final Batch Loss: 0.11798853427171707\n",
      "Epoch 1635, Loss: 0.15833738446235657, Final Batch Loss: 0.05104288458824158\n",
      "Epoch 1636, Loss: 0.17404503375291824, Final Batch Loss: 0.09171631187200546\n",
      "Epoch 1637, Loss: 0.14567577093839645, Final Batch Loss: 0.06781389564275742\n",
      "Epoch 1638, Loss: 0.12815815210342407, Final Batch Loss: 0.04633224755525589\n",
      "Epoch 1639, Loss: 0.13833504170179367, Final Batch Loss: 0.08763187378644943\n",
      "Epoch 1640, Loss: 0.1260264851152897, Final Batch Loss: 0.05511203035712242\n",
      "Epoch 1641, Loss: 0.07554860971868038, Final Batch Loss: 0.04943154379725456\n",
      "Epoch 1642, Loss: 0.16417349129915237, Final Batch Loss: 0.06441767513751984\n",
      "Epoch 1643, Loss: 0.1006237342953682, Final Batch Loss: 0.04911935329437256\n",
      "Epoch 1644, Loss: 0.1678071692585945, Final Batch Loss: 0.08813484758138657\n",
      "Epoch 1645, Loss: 0.10784315690398216, Final Batch Loss: 0.04079880937933922\n",
      "Epoch 1646, Loss: 0.18940672278404236, Final Batch Loss: 0.10858556628227234\n",
      "Epoch 1647, Loss: 0.2095387876033783, Final Batch Loss: 0.12627725303173065\n",
      "Epoch 1648, Loss: 0.15887818485498428, Final Batch Loss: 0.06275556236505508\n",
      "Epoch 1649, Loss: 0.10829204320907593, Final Batch Loss: 0.06931741535663605\n",
      "Epoch 1650, Loss: 0.13858693838119507, Final Batch Loss: 0.06353447586297989\n",
      "Epoch 1651, Loss: 0.16605108976364136, Final Batch Loss: 0.08048193156719208\n",
      "Epoch 1652, Loss: 0.1974935531616211, Final Batch Loss: 0.086841881275177\n",
      "Epoch 1653, Loss: 0.165987990796566, Final Batch Loss: 0.08515484631061554\n",
      "Epoch 1654, Loss: 0.10928047448396683, Final Batch Loss: 0.0330202579498291\n",
      "Epoch 1655, Loss: 0.1420583315193653, Final Batch Loss: 0.08141335099935532\n",
      "Epoch 1656, Loss: 0.18609954416751862, Final Batch Loss: 0.13697971403598785\n",
      "Epoch 1657, Loss: 0.12210772559046745, Final Batch Loss: 0.059716928750276566\n",
      "Epoch 1658, Loss: 0.1114133968949318, Final Batch Loss: 0.04228939116001129\n",
      "Epoch 1659, Loss: 0.19877931475639343, Final Batch Loss: 0.10268280655145645\n",
      "Epoch 1660, Loss: 0.2272409349679947, Final Batch Loss: 0.09891696274280548\n",
      "Epoch 1661, Loss: 0.11479436233639717, Final Batch Loss: 0.04147876426577568\n",
      "Epoch 1662, Loss: 0.18481816723942757, Final Batch Loss: 0.042928773909807205\n",
      "Epoch 1663, Loss: 0.11035097017884254, Final Batch Loss: 0.03548846021294594\n",
      "Epoch 1664, Loss: 0.1405816525220871, Final Batch Loss: 0.07528600096702576\n",
      "Epoch 1665, Loss: 0.13217683136463165, Final Batch Loss: 0.08036954700946808\n",
      "Epoch 1666, Loss: 0.11690330132842064, Final Batch Loss: 0.07846717536449432\n",
      "Epoch 1667, Loss: 0.11961109191179276, Final Batch Loss: 0.06371531635522842\n",
      "Epoch 1668, Loss: 0.14477016031742096, Final Batch Loss: 0.07382030785083771\n",
      "Epoch 1669, Loss: 0.103278748691082, Final Batch Loss: 0.05850846320390701\n",
      "Epoch 1670, Loss: 0.11458509042859077, Final Batch Loss: 0.08414585888385773\n",
      "Epoch 1671, Loss: 0.11645960807800293, Final Batch Loss: 0.045962847769260406\n",
      "Epoch 1672, Loss: 0.1381557434797287, Final Batch Loss: 0.06649133563041687\n",
      "Epoch 1673, Loss: 0.14334003254771233, Final Batch Loss: 0.09257940948009491\n",
      "Epoch 1674, Loss: 0.10384009778499603, Final Batch Loss: 0.054260700941085815\n",
      "Epoch 1675, Loss: 0.10266465321183205, Final Batch Loss: 0.05968694016337395\n",
      "Epoch 1676, Loss: 0.10266292467713356, Final Batch Loss: 0.04198049008846283\n",
      "Epoch 1677, Loss: 0.14845991879701614, Final Batch Loss: 0.08673752099275589\n",
      "Epoch 1678, Loss: 0.12760666757822037, Final Batch Loss: 0.05809790641069412\n",
      "Epoch 1679, Loss: 0.16108833253383636, Final Batch Loss: 0.08711900562047958\n",
      "Epoch 1680, Loss: 0.13128145039081573, Final Batch Loss: 0.05370517075061798\n",
      "Epoch 1681, Loss: 0.10215502232313156, Final Batch Loss: 0.038435354828834534\n",
      "Epoch 1682, Loss: 0.07785330712795258, Final Batch Loss: 0.045907702296972275\n",
      "Epoch 1683, Loss: 0.1165606863796711, Final Batch Loss: 0.05432700738310814\n",
      "Epoch 1684, Loss: 0.12140571139752865, Final Batch Loss: 0.030905229970812798\n",
      "Epoch 1685, Loss: 0.12180542200803757, Final Batch Loss: 0.047888003289699554\n",
      "Epoch 1686, Loss: 0.13070616498589516, Final Batch Loss: 0.06041974946856499\n",
      "Epoch 1687, Loss: 0.10856504365801811, Final Batch Loss: 0.040011268109083176\n",
      "Epoch 1688, Loss: 0.1690131388604641, Final Batch Loss: 0.12150222808122635\n",
      "Epoch 1689, Loss: 0.15747970342636108, Final Batch Loss: 0.10595273971557617\n",
      "Epoch 1690, Loss: 0.10868595913052559, Final Batch Loss: 0.04626132920384407\n",
      "Epoch 1691, Loss: 0.1947275847196579, Final Batch Loss: 0.128534734249115\n",
      "Epoch 1692, Loss: 0.13122976385056973, Final Batch Loss: 0.02889249287545681\n",
      "Epoch 1693, Loss: 0.11481704749166965, Final Batch Loss: 0.025668324902653694\n",
      "Epoch 1694, Loss: 0.12681814283132553, Final Batch Loss: 0.06911671906709671\n",
      "Epoch 1695, Loss: 0.14974375069141388, Final Batch Loss: 0.07667603343725204\n",
      "Epoch 1696, Loss: 0.1873823180794716, Final Batch Loss: 0.09813027828931808\n",
      "Epoch 1697, Loss: 0.11679976433515549, Final Batch Loss: 0.03779252618551254\n",
      "Epoch 1698, Loss: 0.1254577822983265, Final Batch Loss: 0.06659640371799469\n",
      "Epoch 1699, Loss: 0.10275896266102791, Final Batch Loss: 0.04320809245109558\n",
      "Epoch 1700, Loss: 0.12192894890904427, Final Batch Loss: 0.05343710258603096\n",
      "Epoch 1701, Loss: 0.10421242192387581, Final Batch Loss: 0.061331357806921005\n",
      "Epoch 1702, Loss: 0.1310845948755741, Final Batch Loss: 0.04295049235224724\n",
      "Epoch 1703, Loss: 0.18907936662435532, Final Batch Loss: 0.11252894997596741\n",
      "Epoch 1704, Loss: 0.09968239441514015, Final Batch Loss: 0.0531107522547245\n",
      "Epoch 1705, Loss: 0.15741168707609177, Final Batch Loss: 0.11282068490982056\n",
      "Epoch 1706, Loss: 0.12613122910261154, Final Batch Loss: 0.06896289438009262\n",
      "Epoch 1707, Loss: 0.1590409353375435, Final Batch Loss: 0.11043991148471832\n",
      "Epoch 1708, Loss: 0.13245463743805885, Final Batch Loss: 0.05173094943165779\n",
      "Epoch 1709, Loss: 0.15820765867829323, Final Batch Loss: 0.11569658666849136\n",
      "Epoch 1710, Loss: 0.13155393116176128, Final Batch Loss: 0.028523055836558342\n",
      "Epoch 1711, Loss: 0.1401275396347046, Final Batch Loss: 0.1019296944141388\n",
      "Epoch 1712, Loss: 0.1073618121445179, Final Batch Loss: 0.057333968579769135\n",
      "Epoch 1713, Loss: 0.09650661796331406, Final Batch Loss: 0.037948861718177795\n",
      "Epoch 1714, Loss: 0.1431800127029419, Final Batch Loss: 0.07831034064292908\n",
      "Epoch 1715, Loss: 0.08491536229848862, Final Batch Loss: 0.03871913254261017\n",
      "Epoch 1716, Loss: 0.08061133325099945, Final Batch Loss: 0.0271347276866436\n",
      "Epoch 1717, Loss: 0.10082307457923889, Final Batch Loss: 0.056858837604522705\n",
      "Epoch 1718, Loss: 0.11890747025609016, Final Batch Loss: 0.05725683644413948\n",
      "Epoch 1719, Loss: 0.09765180945396423, Final Batch Loss: 0.03696281835436821\n",
      "Epoch 1720, Loss: 0.1442338339984417, Final Batch Loss: 0.05894901230931282\n",
      "Epoch 1721, Loss: 0.2038797289133072, Final Batch Loss: 0.11656172573566437\n",
      "Epoch 1722, Loss: 0.15623324364423752, Final Batch Loss: 0.07318475097417831\n",
      "Epoch 1723, Loss: 0.16868037730455399, Final Batch Loss: 0.10328254848718643\n",
      "Epoch 1724, Loss: 0.14623630791902542, Final Batch Loss: 0.06717991083860397\n",
      "Epoch 1725, Loss: 0.13050419837236404, Final Batch Loss: 0.07397903501987457\n",
      "Epoch 1726, Loss: 0.10900870710611343, Final Batch Loss: 0.04829399287700653\n",
      "Epoch 1727, Loss: 0.1523115672171116, Final Batch Loss: 0.062022674828767776\n",
      "Epoch 1728, Loss: 0.12921975180506706, Final Batch Loss: 0.0614338181912899\n",
      "Epoch 1729, Loss: 0.2154584378004074, Final Batch Loss: 0.15098339319229126\n",
      "Epoch 1730, Loss: 0.17346367985010147, Final Batch Loss: 0.09104049950838089\n",
      "Epoch 1731, Loss: 0.11523367837071419, Final Batch Loss: 0.05883076414465904\n",
      "Epoch 1732, Loss: 0.19996533542871475, Final Batch Loss: 0.10119432210922241\n",
      "Epoch 1733, Loss: 0.14241298288106918, Final Batch Loss: 0.052144162356853485\n",
      "Epoch 1734, Loss: 0.15063050761818886, Final Batch Loss: 0.09814661741256714\n",
      "Epoch 1735, Loss: 0.15177442133426666, Final Batch Loss: 0.10198219120502472\n",
      "Epoch 1736, Loss: 0.18371541798114777, Final Batch Loss: 0.08023407310247421\n",
      "Epoch 1737, Loss: 0.10576532408595085, Final Batch Loss: 0.059853337705135345\n",
      "Epoch 1738, Loss: 0.10920879989862442, Final Batch Loss: 0.04758596420288086\n",
      "Epoch 1739, Loss: 0.16487785801291466, Final Batch Loss: 0.04216698929667473\n",
      "Epoch 1740, Loss: 0.133398761972785, Final Batch Loss: 0.026131516322493553\n",
      "Epoch 1741, Loss: 0.11765437200665474, Final Batch Loss: 0.06801126152276993\n",
      "Epoch 1742, Loss: 0.12791763246059418, Final Batch Loss: 0.06749890744686127\n",
      "Epoch 1743, Loss: 0.09431624412536621, Final Batch Loss: 0.025889642536640167\n",
      "Epoch 1744, Loss: 0.2086673304438591, Final Batch Loss: 0.11161946505308151\n",
      "Epoch 1745, Loss: 0.225305937230587, Final Batch Loss: 0.1264292448759079\n",
      "Epoch 1746, Loss: 0.11164681240916252, Final Batch Loss: 0.03996602073311806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1747, Loss: 0.14700854569673538, Final Batch Loss: 0.07083254307508469\n",
      "Epoch 1748, Loss: 0.08065814711153507, Final Batch Loss: 0.029676401987671852\n",
      "Epoch 1749, Loss: 0.10399416461586952, Final Batch Loss: 0.05923793092370033\n",
      "Epoch 1750, Loss: 0.11696823686361313, Final Batch Loss: 0.07117117196321487\n",
      "Epoch 1751, Loss: 0.12722966820001602, Final Batch Loss: 0.07455142587423325\n",
      "Epoch 1752, Loss: 0.159219391644001, Final Batch Loss: 0.0442049503326416\n",
      "Epoch 1753, Loss: 0.13917387649416924, Final Batch Loss: 0.052242692559957504\n",
      "Epoch 1754, Loss: 0.1142234243452549, Final Batch Loss: 0.07273925095796585\n",
      "Epoch 1755, Loss: 0.09291370213031769, Final Batch Loss: 0.04580865800380707\n",
      "Epoch 1756, Loss: 0.18950701504945755, Final Batch Loss: 0.12307912111282349\n",
      "Epoch 1757, Loss: 0.12291662022471428, Final Batch Loss: 0.07698025554418564\n",
      "Epoch 1758, Loss: 0.10577446967363358, Final Batch Loss: 0.030616559088230133\n",
      "Epoch 1759, Loss: 0.12141944840550423, Final Batch Loss: 0.05075925216078758\n",
      "Epoch 1760, Loss: 0.1607852578163147, Final Batch Loss: 0.09696202725172043\n",
      "Epoch 1761, Loss: 0.17144908383488655, Final Batch Loss: 0.1100187823176384\n",
      "Epoch 1762, Loss: 0.13036642223596573, Final Batch Loss: 0.042338356375694275\n",
      "Epoch 1763, Loss: 0.15530773252248764, Final Batch Loss: 0.08017028868198395\n",
      "Epoch 1764, Loss: 0.0847592893987894, Final Batch Loss: 0.030874235555529594\n",
      "Epoch 1765, Loss: 0.1238105297088623, Final Batch Loss: 0.06582862883806229\n",
      "Epoch 1766, Loss: 0.07768433541059494, Final Batch Loss: 0.016694627702236176\n",
      "Epoch 1767, Loss: 0.16575412452220917, Final Batch Loss: 0.09450402855873108\n",
      "Epoch 1768, Loss: 0.13470244407653809, Final Batch Loss: 0.10552188754081726\n",
      "Epoch 1769, Loss: 0.15941358357667923, Final Batch Loss: 0.0713261216878891\n",
      "Epoch 1770, Loss: 0.20154476165771484, Final Batch Loss: 0.09377627819776535\n",
      "Epoch 1771, Loss: 0.14307230710983276, Final Batch Loss: 0.05543394386768341\n",
      "Epoch 1772, Loss: 0.13598060235381126, Final Batch Loss: 0.08191879838705063\n",
      "Epoch 1773, Loss: 0.11841529235243797, Final Batch Loss: 0.043498698621988297\n",
      "Epoch 1774, Loss: 0.11307622864842415, Final Batch Loss: 0.051960792392492294\n",
      "Epoch 1775, Loss: 0.12839043140411377, Final Batch Loss: 0.08207441866397858\n",
      "Epoch 1776, Loss: 0.1699903905391693, Final Batch Loss: 0.10156693309545517\n",
      "Epoch 1777, Loss: 0.0970899723470211, Final Batch Loss: 0.03286546841263771\n",
      "Epoch 1778, Loss: 0.08611339330673218, Final Batch Loss: 0.04723715782165527\n",
      "Epoch 1779, Loss: 0.11684834957122803, Final Batch Loss: 0.06087656691670418\n",
      "Epoch 1780, Loss: 0.13229455426335335, Final Batch Loss: 0.07243011891841888\n",
      "Epoch 1781, Loss: 0.08920606598258018, Final Batch Loss: 0.032386086881160736\n",
      "Epoch 1782, Loss: 0.15199033915996552, Final Batch Loss: 0.0711594820022583\n",
      "Epoch 1783, Loss: 0.187250517308712, Final Batch Loss: 0.04425849765539169\n",
      "Epoch 1784, Loss: 0.11916978657245636, Final Batch Loss: 0.06377416104078293\n",
      "Epoch 1785, Loss: 0.25502292066812515, Final Batch Loss: 0.189517080783844\n",
      "Epoch 1786, Loss: 0.11191683262586594, Final Batch Loss: 0.0717148557305336\n",
      "Epoch 1787, Loss: 0.14244631677865982, Final Batch Loss: 0.0934055894613266\n",
      "Epoch 1788, Loss: 0.07182089611887932, Final Batch Loss: 0.032386619597673416\n",
      "Epoch 1789, Loss: 0.0971534512937069, Final Batch Loss: 0.03150239959359169\n",
      "Epoch 1790, Loss: 0.09256965294480324, Final Batch Loss: 0.04913156479597092\n",
      "Epoch 1791, Loss: 0.10652396082878113, Final Batch Loss: 0.07182122021913528\n",
      "Epoch 1792, Loss: 0.18925899267196655, Final Batch Loss: 0.0871797725558281\n",
      "Epoch 1793, Loss: 0.16488415747880936, Final Batch Loss: 0.08101928234100342\n",
      "Epoch 1794, Loss: 0.1563861146569252, Final Batch Loss: 0.07144998013973236\n",
      "Epoch 1795, Loss: 0.1309274099767208, Final Batch Loss: 0.04555046185851097\n",
      "Epoch 1796, Loss: 0.17370450496673584, Final Batch Loss: 0.09004302322864532\n",
      "Epoch 1797, Loss: 0.14300595968961716, Final Batch Loss: 0.08927474170923233\n",
      "Epoch 1798, Loss: 0.08523473143577576, Final Batch Loss: 0.028562210500240326\n",
      "Epoch 1799, Loss: 0.06011432223021984, Final Batch Loss: 0.023887569084763527\n",
      "Epoch 1800, Loss: 0.17013505846261978, Final Batch Loss: 0.09796200692653656\n",
      "Epoch 1801, Loss: 0.162586510181427, Final Batch Loss: 0.0747642070055008\n",
      "Epoch 1802, Loss: 0.1553320214152336, Final Batch Loss: 0.09406241774559021\n",
      "Epoch 1803, Loss: 0.11269121989607811, Final Batch Loss: 0.03389627858996391\n",
      "Epoch 1804, Loss: 0.18617656081914902, Final Batch Loss: 0.10250891745090485\n",
      "Epoch 1805, Loss: 0.08156717196106911, Final Batch Loss: 0.04388588294386864\n",
      "Epoch 1806, Loss: 0.12867006659507751, Final Batch Loss: 0.04548608511686325\n",
      "Epoch 1807, Loss: 0.08790580928325653, Final Batch Loss: 0.03348911553621292\n",
      "Epoch 1808, Loss: 0.12403403222560883, Final Batch Loss: 0.07406270503997803\n",
      "Epoch 1809, Loss: 0.14917420968413353, Final Batch Loss: 0.05766675993800163\n",
      "Epoch 1810, Loss: 0.09651720896363258, Final Batch Loss: 0.0446152463555336\n",
      "Epoch 1811, Loss: 0.11265083029866219, Final Batch Loss: 0.04872012510895729\n",
      "Epoch 1812, Loss: 0.1279960721731186, Final Batch Loss: 0.07191931456327438\n",
      "Epoch 1813, Loss: 0.11692287214100361, Final Batch Loss: 0.029417650774121284\n",
      "Epoch 1814, Loss: 0.12335730716586113, Final Batch Loss: 0.06100769340991974\n",
      "Epoch 1815, Loss: 0.13148637488484383, Final Batch Loss: 0.08977297693490982\n",
      "Epoch 1816, Loss: 0.09652359783649445, Final Batch Loss: 0.049580689519643784\n",
      "Epoch 1817, Loss: 0.17311568930745125, Final Batch Loss: 0.04710954800248146\n",
      "Epoch 1818, Loss: 0.19491181522607803, Final Batch Loss: 0.11822196841239929\n",
      "Epoch 1819, Loss: 0.15514803305268288, Final Batch Loss: 0.10503356903791428\n",
      "Epoch 1820, Loss: 0.1053851991891861, Final Batch Loss: 0.0749589279294014\n",
      "Epoch 1821, Loss: 0.15269746631383896, Final Batch Loss: 0.07485189288854599\n",
      "Epoch 1822, Loss: 0.11932885646820068, Final Batch Loss: 0.06974905729293823\n",
      "Epoch 1823, Loss: 0.12102566659450531, Final Batch Loss: 0.046545401215553284\n",
      "Epoch 1824, Loss: 0.13439147919416428, Final Batch Loss: 0.05878181755542755\n",
      "Epoch 1825, Loss: 0.060250189155340195, Final Batch Loss: 0.027460984885692596\n",
      "Epoch 1826, Loss: 0.22265758365392685, Final Batch Loss: 0.16748863458633423\n",
      "Epoch 1827, Loss: 0.11287171766161919, Final Batch Loss: 0.04952048882842064\n",
      "Epoch 1828, Loss: 0.1691587269306183, Final Batch Loss: 0.08313160389661789\n",
      "Epoch 1829, Loss: 0.11681253835558891, Final Batch Loss: 0.076531782746315\n",
      "Epoch 1830, Loss: 0.10246496833860874, Final Batch Loss: 0.07704082131385803\n",
      "Epoch 1831, Loss: 0.13766444101929665, Final Batch Loss: 0.04520455375313759\n",
      "Epoch 1832, Loss: 0.23705943673849106, Final Batch Loss: 0.1536136269569397\n",
      "Epoch 1833, Loss: 0.12930912896990776, Final Batch Loss: 0.07062799483537674\n",
      "Epoch 1834, Loss: 0.17934413254261017, Final Batch Loss: 0.07604530453681946\n",
      "Epoch 1835, Loss: 0.10874321311712265, Final Batch Loss: 0.0398978516459465\n",
      "Epoch 1836, Loss: 0.11496728658676147, Final Batch Loss: 0.05955442786216736\n",
      "Epoch 1837, Loss: 0.14748400822281837, Final Batch Loss: 0.09700433164834976\n",
      "Epoch 1838, Loss: 0.12787946686148643, Final Batch Loss: 0.058867197483778\n",
      "Epoch 1839, Loss: 0.11863824725151062, Final Batch Loss: 0.06267567723989487\n",
      "Epoch 1840, Loss: 0.11454377695918083, Final Batch Loss: 0.04758286848664284\n",
      "Epoch 1841, Loss: 0.11220240592956543, Final Batch Loss: 0.07119868695735931\n",
      "Epoch 1842, Loss: 0.11508401110768318, Final Batch Loss: 0.05517185106873512\n",
      "Epoch 1843, Loss: 0.09010417759418488, Final Batch Loss: 0.04994090646505356\n",
      "Epoch 1844, Loss: 0.14587626233696938, Final Batch Loss: 0.05418778583407402\n",
      "Epoch 1845, Loss: 0.15627046301960945, Final Batch Loss: 0.03597595915198326\n",
      "Epoch 1846, Loss: 0.09544070065021515, Final Batch Loss: 0.042693980038166046\n",
      "Epoch 1847, Loss: 0.13777224719524384, Final Batch Loss: 0.08170907199382782\n",
      "Epoch 1848, Loss: 0.10891654342412949, Final Batch Loss: 0.06032535806298256\n",
      "Epoch 1849, Loss: 0.1417529433965683, Final Batch Loss: 0.05626150220632553\n",
      "Epoch 1850, Loss: 0.12611248344182968, Final Batch Loss: 0.058947257697582245\n",
      "Epoch 1851, Loss: 0.13235892355442047, Final Batch Loss: 0.04674414545297623\n",
      "Epoch 1852, Loss: 0.0908331610262394, Final Batch Loss: 0.030594080686569214\n",
      "Epoch 1853, Loss: 0.14963790774345398, Final Batch Loss: 0.08306324481964111\n",
      "Epoch 1854, Loss: 0.07810206525027752, Final Batch Loss: 0.05030370503664017\n",
      "Epoch 1855, Loss: 0.10747454315423965, Final Batch Loss: 0.04481421411037445\n",
      "Epoch 1856, Loss: 0.06886439956724644, Final Batch Loss: 0.022960925474762917\n",
      "Epoch 1857, Loss: 0.0972620528191328, Final Batch Loss: 0.028854360803961754\n",
      "Epoch 1858, Loss: 0.15387874841690063, Final Batch Loss: 0.052426062524318695\n",
      "Epoch 1859, Loss: 0.1082344725728035, Final Batch Loss: 0.04994317889213562\n",
      "Epoch 1860, Loss: 0.12735573202371597, Final Batch Loss: 0.08313757181167603\n",
      "Epoch 1861, Loss: 0.19424599409103394, Final Batch Loss: 0.10775946080684662\n",
      "Epoch 1862, Loss: 0.11771772801876068, Final Batch Loss: 0.05795171484351158\n",
      "Epoch 1863, Loss: 0.09804597496986389, Final Batch Loss: 0.05125126615166664\n",
      "Epoch 1864, Loss: 0.10488924756646156, Final Batch Loss: 0.03475954756140709\n",
      "Epoch 1865, Loss: 0.1607300490140915, Final Batch Loss: 0.06416134536266327\n",
      "Epoch 1866, Loss: 0.16283303499221802, Final Batch Loss: 0.07245010137557983\n",
      "Epoch 1867, Loss: 0.06931827776134014, Final Batch Loss: 0.020744821056723595\n",
      "Epoch 1868, Loss: 0.09774094074964523, Final Batch Loss: 0.036414921283721924\n",
      "Epoch 1869, Loss: 0.11799714341759682, Final Batch Loss: 0.0724542960524559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1870, Loss: 0.1220594011247158, Final Batch Loss: 0.08688397705554962\n",
      "Epoch 1871, Loss: 0.14064764976501465, Final Batch Loss: 0.08520480990409851\n",
      "Epoch 1872, Loss: 0.08778446167707443, Final Batch Loss: 0.04816890135407448\n",
      "Epoch 1873, Loss: 0.1365450583398342, Final Batch Loss: 0.08053315430879593\n",
      "Epoch 1874, Loss: 0.15211271494627, Final Batch Loss: 0.0526324063539505\n",
      "Epoch 1875, Loss: 0.07754610292613506, Final Batch Loss: 0.04726538062095642\n",
      "Epoch 1876, Loss: 0.082549549639225, Final Batch Loss: 0.031505052000284195\n",
      "Epoch 1877, Loss: 0.11898299306631088, Final Batch Loss: 0.07017602771520615\n",
      "Epoch 1878, Loss: 0.05798950605094433, Final Batch Loss: 0.02428458072245121\n",
      "Epoch 1879, Loss: 0.11034679226577282, Final Batch Loss: 0.030542513355612755\n",
      "Epoch 1880, Loss: 0.10193291306495667, Final Batch Loss: 0.03397296369075775\n",
      "Epoch 1881, Loss: 0.11850348114967346, Final Batch Loss: 0.053443603217601776\n",
      "Epoch 1882, Loss: 0.09658753499388695, Final Batch Loss: 0.033188384026288986\n",
      "Epoch 1883, Loss: 0.12313566356897354, Final Batch Loss: 0.0834718868136406\n",
      "Epoch 1884, Loss: 0.08514801226556301, Final Batch Loss: 0.025556379929184914\n",
      "Epoch 1885, Loss: 0.12896090745925903, Final Batch Loss: 0.0790928453207016\n",
      "Epoch 1886, Loss: 0.11633770540356636, Final Batch Loss: 0.06012539938092232\n",
      "Epoch 1887, Loss: 0.146254550665617, Final Batch Loss: 0.11097592860460281\n",
      "Epoch 1888, Loss: 0.07476740702986717, Final Batch Loss: 0.026117656379938126\n",
      "Epoch 1889, Loss: 0.08495050854980946, Final Batch Loss: 0.025690196081995964\n",
      "Epoch 1890, Loss: 0.07440906018018723, Final Batch Loss: 0.03173360228538513\n",
      "Epoch 1891, Loss: 0.10580318421125412, Final Batch Loss: 0.0485987588763237\n",
      "Epoch 1892, Loss: 0.09050555899739265, Final Batch Loss: 0.024190571159124374\n",
      "Epoch 1893, Loss: 0.12430233508348465, Final Batch Loss: 0.05278012901544571\n",
      "Epoch 1894, Loss: 0.11587513983249664, Final Batch Loss: 0.06588141620159149\n",
      "Epoch 1895, Loss: 0.11250025779008865, Final Batch Loss: 0.06826724112033844\n",
      "Epoch 1896, Loss: 0.12015634402632713, Final Batch Loss: 0.0829261764883995\n",
      "Epoch 1897, Loss: 0.1669517457485199, Final Batch Loss: 0.09995543211698532\n",
      "Epoch 1898, Loss: 0.13635662198066711, Final Batch Loss: 0.09250331670045853\n",
      "Epoch 1899, Loss: 0.1365865096449852, Final Batch Loss: 0.08421184122562408\n",
      "Epoch 1900, Loss: 0.18155468255281448, Final Batch Loss: 0.07022848725318909\n",
      "Epoch 1901, Loss: 0.12281100824475288, Final Batch Loss: 0.04032350704073906\n",
      "Epoch 1902, Loss: 0.09190817177295685, Final Batch Loss: 0.052824266254901886\n",
      "Epoch 1903, Loss: 0.09640294685959816, Final Batch Loss: 0.06078846752643585\n",
      "Epoch 1904, Loss: 0.15421736240386963, Final Batch Loss: 0.05783877521753311\n",
      "Epoch 1905, Loss: 0.10783547908067703, Final Batch Loss: 0.041315220296382904\n",
      "Epoch 1906, Loss: 0.10614431276917458, Final Batch Loss: 0.07044882327318192\n",
      "Epoch 1907, Loss: 0.1727335900068283, Final Batch Loss: 0.06600192189216614\n",
      "Epoch 1908, Loss: 0.1457405537366867, Final Batch Loss: 0.05357027053833008\n",
      "Epoch 1909, Loss: 0.15527408570051193, Final Batch Loss: 0.07185473293066025\n",
      "Epoch 1910, Loss: 0.16760370135307312, Final Batch Loss: 0.046755678951740265\n",
      "Epoch 1911, Loss: 0.07645840384066105, Final Batch Loss: 0.019938288256525993\n",
      "Epoch 1912, Loss: 0.0754614882171154, Final Batch Loss: 0.039978355169296265\n",
      "Epoch 1913, Loss: 0.12105312570929527, Final Batch Loss: 0.04008595272898674\n",
      "Epoch 1914, Loss: 0.13047030195593834, Final Batch Loss: 0.0909004658460617\n",
      "Epoch 1915, Loss: 0.04819321259856224, Final Batch Loss: 0.020588163286447525\n",
      "Epoch 1916, Loss: 0.4483975023031235, Final Batch Loss: 0.35274016857147217\n",
      "Epoch 1917, Loss: 0.1002630740404129, Final Batch Loss: 0.05322250723838806\n",
      "Epoch 1918, Loss: 0.09682472422719002, Final Batch Loss: 0.039474040269851685\n",
      "Epoch 1919, Loss: 0.06391166895627975, Final Batch Loss: 0.04105405882000923\n",
      "Epoch 1920, Loss: 0.14450158923864365, Final Batch Loss: 0.09577815234661102\n",
      "Epoch 1921, Loss: 0.09159159287810326, Final Batch Loss: 0.046562664210796356\n",
      "Epoch 1922, Loss: 0.1044015996158123, Final Batch Loss: 0.060830485075712204\n",
      "Epoch 1923, Loss: 0.13443130999803543, Final Batch Loss: 0.08041148632764816\n",
      "Epoch 1924, Loss: 0.1255650483071804, Final Batch Loss: 0.06946028023958206\n",
      "Epoch 1925, Loss: 0.09496204182505608, Final Batch Loss: 0.054919302463531494\n",
      "Epoch 1926, Loss: 0.15823552012443542, Final Batch Loss: 0.06143473833799362\n",
      "Epoch 1927, Loss: 0.12099561095237732, Final Batch Loss: 0.05929623916745186\n",
      "Epoch 1928, Loss: 0.10035965591669083, Final Batch Loss: 0.05939613655209541\n",
      "Epoch 1929, Loss: 0.1090773493051529, Final Batch Loss: 0.02157709002494812\n",
      "Epoch 1930, Loss: 0.09033210389316082, Final Batch Loss: 0.028659095987677574\n",
      "Epoch 1931, Loss: 0.10915189236402512, Final Batch Loss: 0.06433992087841034\n",
      "Epoch 1932, Loss: 0.1296892613172531, Final Batch Loss: 0.05035454034805298\n",
      "Epoch 1933, Loss: 0.0723315142095089, Final Batch Loss: 0.019772857427597046\n",
      "Epoch 1934, Loss: 0.07987666130065918, Final Batch Loss: 0.026835016906261444\n",
      "Epoch 1935, Loss: 0.1382020339369774, Final Batch Loss: 0.09048417210578918\n",
      "Epoch 1936, Loss: 0.06287240982055664, Final Batch Loss: 0.020596403628587723\n",
      "Epoch 1937, Loss: 0.17241737246513367, Final Batch Loss: 0.08902837336063385\n",
      "Epoch 1938, Loss: 0.1770593598484993, Final Batch Loss: 0.12149177491664886\n",
      "Epoch 1939, Loss: 0.0949251689016819, Final Batch Loss: 0.04502185061573982\n",
      "Epoch 1940, Loss: 0.10357613489031792, Final Batch Loss: 0.05435479059815407\n",
      "Epoch 1941, Loss: 0.07253553159534931, Final Batch Loss: 0.026399655267596245\n",
      "Epoch 1942, Loss: 0.09091444127261639, Final Batch Loss: 0.028424805030226707\n",
      "Epoch 1943, Loss: 0.13637416064739227, Final Batch Loss: 0.07000567764043808\n",
      "Epoch 1944, Loss: 0.10446448251605034, Final Batch Loss: 0.031297411769628525\n",
      "Epoch 1945, Loss: 0.09194663166999817, Final Batch Loss: 0.04997365549206734\n",
      "Epoch 1946, Loss: 0.1079848688095808, Final Batch Loss: 0.030114514753222466\n",
      "Epoch 1947, Loss: 0.18213367462158203, Final Batch Loss: 0.11096613109111786\n",
      "Epoch 1948, Loss: 0.11483491584658623, Final Batch Loss: 0.08279731124639511\n",
      "Epoch 1949, Loss: 0.08447960391640663, Final Batch Loss: 0.03796917200088501\n",
      "Epoch 1950, Loss: 0.0970483347773552, Final Batch Loss: 0.039207614958286285\n",
      "Epoch 1951, Loss: 0.1967177800834179, Final Batch Loss: 0.02991829439997673\n",
      "Epoch 1952, Loss: 0.12695855647325516, Final Batch Loss: 0.060409776866436005\n",
      "Epoch 1953, Loss: 0.1292286217212677, Final Batch Loss: 0.06013447791337967\n",
      "Epoch 1954, Loss: 0.10165680944919586, Final Batch Loss: 0.0534193217754364\n",
      "Epoch 1955, Loss: 0.12214292213320732, Final Batch Loss: 0.04748273268342018\n",
      "Epoch 1956, Loss: 0.13954635709524155, Final Batch Loss: 0.07308868318796158\n",
      "Epoch 1957, Loss: 0.09054530411958694, Final Batch Loss: 0.03612946718931198\n",
      "Epoch 1958, Loss: 0.09437631443142891, Final Batch Loss: 0.04459823668003082\n",
      "Epoch 1959, Loss: 0.07758278027176857, Final Batch Loss: 0.04099946841597557\n",
      "Epoch 1960, Loss: 0.10009492561221123, Final Batch Loss: 0.06259876489639282\n",
      "Epoch 1961, Loss: 0.1394815891981125, Final Batch Loss: 0.06914611160755157\n",
      "Epoch 1962, Loss: 0.11126625165343285, Final Batch Loss: 0.03550070896744728\n",
      "Epoch 1963, Loss: 0.11355889402329922, Final Batch Loss: 0.0257092397660017\n",
      "Epoch 1964, Loss: 0.12524499371647835, Final Batch Loss: 0.07488507032394409\n",
      "Epoch 1965, Loss: 0.15860836952924728, Final Batch Loss: 0.1246357411146164\n",
      "Epoch 1966, Loss: 0.08495954424142838, Final Batch Loss: 0.021192990243434906\n",
      "Epoch 1967, Loss: 0.116212647408247, Final Batch Loss: 0.03463294729590416\n",
      "Epoch 1968, Loss: 0.11381824314594269, Final Batch Loss: 0.0691654160618782\n",
      "Epoch 1969, Loss: 0.1075919084250927, Final Batch Loss: 0.05084235221147537\n",
      "Epoch 1970, Loss: 0.12519817426800728, Final Batch Loss: 0.07532543689012527\n",
      "Epoch 1971, Loss: 0.10593381524085999, Final Batch Loss: 0.07230010628700256\n",
      "Epoch 1972, Loss: 0.10384920611977577, Final Batch Loss: 0.030222270637750626\n",
      "Epoch 1973, Loss: 0.23543249815702438, Final Batch Loss: 0.10830012708902359\n",
      "Epoch 1974, Loss: 0.11116259545087814, Final Batch Loss: 0.04084137827157974\n",
      "Epoch 1975, Loss: 0.10346359014511108, Final Batch Loss: 0.06426562368869781\n",
      "Epoch 1976, Loss: 0.08643363043665886, Final Batch Loss: 0.045188289135694504\n",
      "Epoch 1977, Loss: 0.1521933600306511, Final Batch Loss: 0.09692411869764328\n",
      "Epoch 1978, Loss: 0.13007912784814835, Final Batch Loss: 0.03306344896554947\n",
      "Epoch 1979, Loss: 0.09789616614580154, Final Batch Loss: 0.05732647329568863\n",
      "Epoch 1980, Loss: 0.100722786039114, Final Batch Loss: 0.05039751157164574\n",
      "Epoch 1981, Loss: 0.09662501141428947, Final Batch Loss: 0.045503389090299606\n",
      "Epoch 1982, Loss: 0.11237694323062897, Final Batch Loss: 0.04683452099561691\n",
      "Epoch 1983, Loss: 0.10192207247018814, Final Batch Loss: 0.054118722677230835\n",
      "Epoch 1984, Loss: 0.08928287774324417, Final Batch Loss: 0.04014443978667259\n",
      "Epoch 1985, Loss: 0.09781204164028168, Final Batch Loss: 0.028834380209445953\n",
      "Epoch 1986, Loss: 0.0847817026078701, Final Batch Loss: 0.044293034821748734\n",
      "Epoch 1987, Loss: 0.08770436234772205, Final Batch Loss: 0.02677297778427601\n",
      "Epoch 1988, Loss: 0.09145659953355789, Final Batch Loss: 0.029755525290966034\n",
      "Epoch 1989, Loss: 0.14606942981481552, Final Batch Loss: 0.06568394601345062\n",
      "Epoch 1990, Loss: 0.10451088473200798, Final Batch Loss: 0.03513709083199501\n",
      "Epoch 1991, Loss: 0.13801399245858192, Final Batch Loss: 0.05631240829825401\n",
      "Epoch 1992, Loss: 0.0925857461988926, Final Batch Loss: 0.051429636776447296\n",
      "Epoch 1993, Loss: 0.17631133273243904, Final Batch Loss: 0.05627508834004402\n",
      "Epoch 1994, Loss: 0.09451388940215111, Final Batch Loss: 0.04214689880609512\n",
      "Epoch 1995, Loss: 0.08717280253767967, Final Batch Loss: 0.04580484703183174\n",
      "Epoch 1996, Loss: 0.07658050954341888, Final Batch Loss: 0.03670760616660118\n",
      "Epoch 1997, Loss: 0.09890878945589066, Final Batch Loss: 0.05606001615524292\n",
      "Epoch 1998, Loss: 0.11700551956892014, Final Batch Loss: 0.05126025527715683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1999, Loss: 0.06772179529070854, Final Batch Loss: 0.03935807943344116\n",
      "Epoch 2000, Loss: 0.10666794516146183, Final Batch Loss: 0.0754321739077568\n",
      "Epoch 2001, Loss: 0.14913222938776016, Final Batch Loss: 0.08103762567043304\n",
      "Epoch 2002, Loss: 0.10589943453669548, Final Batch Loss: 0.051444247364997864\n",
      "Epoch 2003, Loss: 0.14614712446928024, Final Batch Loss: 0.05583807826042175\n",
      "Epoch 2004, Loss: 0.1261388137936592, Final Batch Loss: 0.048667535185813904\n",
      "Epoch 2005, Loss: 0.09891682118177414, Final Batch Loss: 0.06165414676070213\n",
      "Epoch 2006, Loss: 0.14557839184999466, Final Batch Loss: 0.06604830920696259\n",
      "Epoch 2007, Loss: 0.07371792942285538, Final Batch Loss: 0.02709076926112175\n",
      "Epoch 2008, Loss: 0.07466177456080914, Final Batch Loss: 0.03037354163825512\n",
      "Epoch 2009, Loss: 0.1524159014225006, Final Batch Loss: 0.1164575144648552\n",
      "Epoch 2010, Loss: 0.1490609422326088, Final Batch Loss: 0.09269881248474121\n",
      "Epoch 2011, Loss: 0.08485162444412708, Final Batch Loss: 0.05369757115840912\n",
      "Epoch 2012, Loss: 0.11723046377301216, Final Batch Loss: 0.06284324079751968\n",
      "Epoch 2013, Loss: 0.09855594485998154, Final Batch Loss: 0.05433715134859085\n",
      "Epoch 2014, Loss: 0.07277728989720345, Final Batch Loss: 0.031215786933898926\n",
      "Epoch 2015, Loss: 0.13835910707712173, Final Batch Loss: 0.0673663318157196\n",
      "Epoch 2016, Loss: 0.09669413603842258, Final Batch Loss: 0.02844184823334217\n",
      "Epoch 2017, Loss: 0.068656075745821, Final Batch Loss: 0.026491273194551468\n",
      "Epoch 2018, Loss: 0.08484556898474693, Final Batch Loss: 0.037675075232982635\n",
      "Epoch 2019, Loss: 0.06472059898078442, Final Batch Loss: 0.026824278756976128\n",
      "Epoch 2020, Loss: 0.15470176190137863, Final Batch Loss: 0.040240578353405\n",
      "Epoch 2021, Loss: 0.0789395235478878, Final Batch Loss: 0.040468621999025345\n",
      "Epoch 2022, Loss: 0.09795001894235611, Final Batch Loss: 0.054220959544181824\n",
      "Epoch 2023, Loss: 0.07785151526331902, Final Batch Loss: 0.05726531893014908\n",
      "Epoch 2024, Loss: 0.10385462827980518, Final Batch Loss: 0.00862916000187397\n",
      "Epoch 2025, Loss: 0.0982787162065506, Final Batch Loss: 0.03258204460144043\n",
      "Epoch 2026, Loss: 0.1262834258377552, Final Batch Loss: 0.06863321363925934\n",
      "Epoch 2027, Loss: 0.08224763348698616, Final Batch Loss: 0.04921914264559746\n",
      "Epoch 2028, Loss: 0.07075164094567299, Final Batch Loss: 0.03919321671128273\n",
      "Epoch 2029, Loss: 0.13028346002101898, Final Batch Loss: 0.034062206745147705\n",
      "Epoch 2030, Loss: 0.1871596872806549, Final Batch Loss: 0.11966019123792648\n",
      "Epoch 2031, Loss: 0.13610028848052025, Final Batch Loss: 0.10177486389875412\n",
      "Epoch 2032, Loss: 0.06499933265149593, Final Batch Loss: 0.042159322649240494\n",
      "Epoch 2033, Loss: 0.0826792698353529, Final Batch Loss: 0.05526798591017723\n",
      "Epoch 2034, Loss: 0.11640176177024841, Final Batch Loss: 0.07017713040113449\n",
      "Epoch 2035, Loss: 0.07021467573940754, Final Batch Loss: 0.02345065213739872\n",
      "Epoch 2036, Loss: 0.10039643384516239, Final Batch Loss: 0.07897374033927917\n",
      "Epoch 2037, Loss: 0.11136431992053986, Final Batch Loss: 0.06821801513433456\n",
      "Epoch 2038, Loss: 0.1239565797150135, Final Batch Loss: 0.06064512953162193\n",
      "Epoch 2039, Loss: 0.11433260515332222, Final Batch Loss: 0.06504901498556137\n",
      "Epoch 2040, Loss: 0.1252407245337963, Final Batch Loss: 0.05899190530180931\n",
      "Epoch 2041, Loss: 0.08541414886713028, Final Batch Loss: 0.03784632310271263\n",
      "Epoch 2042, Loss: 0.0885453149676323, Final Batch Loss: 0.03434009104967117\n",
      "Epoch 2043, Loss: 0.07248208671808243, Final Batch Loss: 0.016389276832342148\n",
      "Epoch 2044, Loss: 0.13143426179885864, Final Batch Loss: 0.04792416840791702\n",
      "Epoch 2045, Loss: 0.10268932208418846, Final Batch Loss: 0.05729018524289131\n",
      "Epoch 2046, Loss: 0.09244274348020554, Final Batch Loss: 0.042270999401807785\n",
      "Epoch 2047, Loss: 0.12246282771229744, Final Batch Loss: 0.04146841540932655\n",
      "Epoch 2048, Loss: 0.0916333720088005, Final Batch Loss: 0.038675326853990555\n",
      "Epoch 2049, Loss: 0.10499168559908867, Final Batch Loss: 0.03780728206038475\n",
      "Epoch 2050, Loss: 0.14067992568016052, Final Batch Loss: 0.10655096918344498\n",
      "Epoch 2051, Loss: 0.13561252877116203, Final Batch Loss: 0.07782551646232605\n",
      "Epoch 2052, Loss: 0.12037665024399757, Final Batch Loss: 0.08396801352500916\n",
      "Epoch 2053, Loss: 0.13072581216692924, Final Batch Loss: 0.047043610364198685\n",
      "Epoch 2054, Loss: 0.10087078809738159, Final Batch Loss: 0.06046420335769653\n",
      "Epoch 2055, Loss: 0.10364509746432304, Final Batch Loss: 0.04693451151251793\n",
      "Epoch 2056, Loss: 0.08404070883989334, Final Batch Loss: 0.03709305450320244\n",
      "Epoch 2057, Loss: 0.10016047582030296, Final Batch Loss: 0.05105333402752876\n",
      "Epoch 2058, Loss: 0.050126057118177414, Final Batch Loss: 0.032235369086265564\n",
      "Epoch 2059, Loss: 0.11342388018965721, Final Batch Loss: 0.043209854513406754\n",
      "Epoch 2060, Loss: 0.05702443979680538, Final Batch Loss: 0.02750878594815731\n",
      "Epoch 2061, Loss: 0.12550777196884155, Final Batch Loss: 0.02607308328151703\n",
      "Epoch 2062, Loss: 0.09696900472044945, Final Batch Loss: 0.03899119794368744\n",
      "Epoch 2063, Loss: 0.18544087186455727, Final Batch Loss: 0.12748786807060242\n",
      "Epoch 2064, Loss: 0.08227892406284809, Final Batch Loss: 0.051905807107686996\n",
      "Epoch 2065, Loss: 0.07745487987995148, Final Batch Loss: 0.03968457877635956\n",
      "Epoch 2066, Loss: 0.0902290865778923, Final Batch Loss: 0.056629449129104614\n",
      "Epoch 2067, Loss: 0.09379425458610058, Final Batch Loss: 0.02950507216155529\n",
      "Epoch 2068, Loss: 0.07780581898987293, Final Batch Loss: 0.04988161474466324\n",
      "Epoch 2069, Loss: 0.11732233315706253, Final Batch Loss: 0.06792134046554565\n",
      "Epoch 2070, Loss: 0.09364955499768257, Final Batch Loss: 0.0207391194999218\n",
      "Epoch 2071, Loss: 0.11708063818514347, Final Batch Loss: 0.08784513175487518\n",
      "Epoch 2072, Loss: 0.138494111597538, Final Batch Loss: 0.06752389669418335\n",
      "Epoch 2073, Loss: 0.05437467060983181, Final Batch Loss: 0.029047871008515358\n",
      "Epoch 2074, Loss: 0.14232704788446426, Final Batch Loss: 0.07006846368312836\n",
      "Epoch 2075, Loss: 0.061833227053284645, Final Batch Loss: 0.035313282161951065\n",
      "Epoch 2076, Loss: 0.140081275254488, Final Batch Loss: 0.061145421117544174\n",
      "Epoch 2077, Loss: 0.11863228306174278, Final Batch Loss: 0.06819754093885422\n",
      "Epoch 2078, Loss: 0.16735419631004333, Final Batch Loss: 0.10188646614551544\n",
      "Epoch 2079, Loss: 0.09540366008877754, Final Batch Loss: 0.01939331367611885\n",
      "Epoch 2080, Loss: 0.06979479640722275, Final Batch Loss: 0.02556665614247322\n",
      "Epoch 2081, Loss: 0.1378558799624443, Final Batch Loss: 0.07254685461521149\n",
      "Epoch 2082, Loss: 0.1370714269578457, Final Batch Loss: 0.1149616464972496\n",
      "Epoch 2083, Loss: 0.11610261350870132, Final Batch Loss: 0.03311812877655029\n",
      "Epoch 2084, Loss: 0.09533504396677017, Final Batch Loss: 0.0625525489449501\n",
      "Epoch 2085, Loss: 0.09734172374010086, Final Batch Loss: 0.05310168117284775\n",
      "Epoch 2086, Loss: 0.08949259668588638, Final Batch Loss: 0.0321788415312767\n",
      "Epoch 2087, Loss: 0.08748475834727287, Final Batch Loss: 0.0357176773250103\n",
      "Epoch 2088, Loss: 0.131303234025836, Final Batch Loss: 0.026834649965167046\n",
      "Epoch 2089, Loss: 0.0823657400906086, Final Batch Loss: 0.06202244758605957\n",
      "Epoch 2090, Loss: 0.1038222424685955, Final Batch Loss: 0.04467059299349785\n",
      "Epoch 2091, Loss: 0.07440491765737534, Final Batch Loss: 0.033900536596775055\n",
      "Epoch 2092, Loss: 0.07123074121773243, Final Batch Loss: 0.029397470876574516\n",
      "Epoch 2093, Loss: 0.11873574554920197, Final Batch Loss: 0.07434903085231781\n",
      "Epoch 2094, Loss: 0.11521908268332481, Final Batch Loss: 0.028683897107839584\n",
      "Epoch 2095, Loss: 0.09154985286295414, Final Batch Loss: 0.021405892446637154\n",
      "Epoch 2096, Loss: 0.12422031536698341, Final Batch Loss: 0.06363614648580551\n",
      "Epoch 2097, Loss: 0.0813232995569706, Final Batch Loss: 0.04853028804063797\n",
      "Epoch 2098, Loss: 0.13146085292100906, Final Batch Loss: 0.05564042925834656\n",
      "Epoch 2099, Loss: 0.057249950245022774, Final Batch Loss: 0.035523392260074615\n",
      "Epoch 2100, Loss: 0.11416802555322647, Final Batch Loss: 0.040169961750507355\n",
      "Epoch 2101, Loss: 0.13081618770956993, Final Batch Loss: 0.05499282106757164\n",
      "Epoch 2102, Loss: 0.06510202772915363, Final Batch Loss: 0.03776286914944649\n",
      "Epoch 2103, Loss: 0.1129627600312233, Final Batch Loss: 0.0813431441783905\n",
      "Epoch 2104, Loss: 0.09108605980873108, Final Batch Loss: 0.03703610971570015\n",
      "Epoch 2105, Loss: 0.09128198027610779, Final Batch Loss: 0.042163651436567307\n",
      "Epoch 2106, Loss: 0.10549848899245262, Final Batch Loss: 0.041772011667490005\n",
      "Epoch 2107, Loss: 0.09232652559876442, Final Batch Loss: 0.041045624762773514\n",
      "Epoch 2108, Loss: 0.08796455897390842, Final Batch Loss: 0.05841727927327156\n",
      "Epoch 2109, Loss: 0.045059192925691605, Final Batch Loss: 0.017948230728507042\n",
      "Epoch 2110, Loss: 0.04774470254778862, Final Batch Loss: 0.025500744581222534\n",
      "Epoch 2111, Loss: 0.11850125342607498, Final Batch Loss: 0.02698425203561783\n",
      "Epoch 2112, Loss: 0.11020390316843987, Final Batch Loss: 0.030828166753053665\n",
      "Epoch 2113, Loss: 0.14899469539523125, Final Batch Loss: 0.11029426753520966\n",
      "Epoch 2114, Loss: 0.14878062903881073, Final Batch Loss: 0.10711608082056046\n",
      "Epoch 2115, Loss: 0.07097781077027321, Final Batch Loss: 0.03162362426519394\n",
      "Epoch 2116, Loss: 0.05524522811174393, Final Batch Loss: 0.029743587598204613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2117, Loss: 0.0855216383934021, Final Batch Loss: 0.04999526962637901\n",
      "Epoch 2118, Loss: 0.14168418943881989, Final Batch Loss: 0.11354386061429977\n",
      "Epoch 2119, Loss: 0.10673944652080536, Final Batch Loss: 0.054778389632701874\n",
      "Epoch 2120, Loss: 0.09495796635746956, Final Batch Loss: 0.057273980230093\n",
      "Epoch 2121, Loss: 0.10736796259880066, Final Batch Loss: 0.04471353441476822\n",
      "Epoch 2122, Loss: 0.14907021075487137, Final Batch Loss: 0.07624027132987976\n",
      "Epoch 2123, Loss: 0.11334916949272156, Final Batch Loss: 0.07813224196434021\n",
      "Epoch 2124, Loss: 0.07104934379458427, Final Batch Loss: 0.03495572879910469\n",
      "Epoch 2125, Loss: 0.07528170756995678, Final Batch Loss: 0.028973734006285667\n",
      "Epoch 2126, Loss: 0.08172429725527763, Final Batch Loss: 0.037485890090465546\n",
      "Epoch 2127, Loss: 0.1303272470831871, Final Batch Loss: 0.08220966905355453\n",
      "Epoch 2128, Loss: 0.08242839202284813, Final Batch Loss: 0.030364200472831726\n",
      "Epoch 2129, Loss: 0.16243234649300575, Final Batch Loss: 0.10322634130716324\n",
      "Epoch 2130, Loss: 0.18222947418689728, Final Batch Loss: 0.13085687160491943\n",
      "Epoch 2131, Loss: 0.07857806794345379, Final Batch Loss: 0.030039073899388313\n",
      "Epoch 2132, Loss: 0.10625491291284561, Final Batch Loss: 0.051816314458847046\n",
      "Epoch 2133, Loss: 0.09537475556135178, Final Batch Loss: 0.03263173997402191\n",
      "Epoch 2134, Loss: 0.08588313683867455, Final Batch Loss: 0.04447896406054497\n",
      "Epoch 2135, Loss: 0.10168784484267235, Final Batch Loss: 0.06826528906822205\n",
      "Epoch 2136, Loss: 0.09009665437042713, Final Batch Loss: 0.05890877544879913\n",
      "Epoch 2137, Loss: 0.0501821581274271, Final Batch Loss: 0.027787134051322937\n",
      "Epoch 2138, Loss: 0.11878575757145882, Final Batch Loss: 0.056406524032354355\n",
      "Epoch 2139, Loss: 0.07057136297225952, Final Batch Loss: 0.029133133590221405\n",
      "Epoch 2140, Loss: 0.09493563324213028, Final Batch Loss: 0.04447608441114426\n",
      "Epoch 2141, Loss: 0.1345348134636879, Final Batch Loss: 0.08062911033630371\n",
      "Epoch 2142, Loss: 0.13310568407177925, Final Batch Loss: 0.11514552682638168\n",
      "Epoch 2143, Loss: 0.043088655918836594, Final Batch Loss: 0.012936636805534363\n",
      "Epoch 2144, Loss: 0.08948031067848206, Final Batch Loss: 0.038077227771282196\n",
      "Epoch 2145, Loss: 0.09265222772955894, Final Batch Loss: 0.05084645003080368\n",
      "Epoch 2146, Loss: 0.0913189435377717, Final Batch Loss: 0.008470744825899601\n",
      "Epoch 2147, Loss: 0.0829198881983757, Final Batch Loss: 0.04893827810883522\n",
      "Epoch 2148, Loss: 0.07857357896864414, Final Batch Loss: 0.030174219980835915\n",
      "Epoch 2149, Loss: 0.05568988621234894, Final Batch Loss: 0.022371739149093628\n",
      "Epoch 2150, Loss: 0.11452559195458889, Final Batch Loss: 0.0279193427413702\n",
      "Epoch 2151, Loss: 0.12387664243578911, Final Batch Loss: 0.06591542065143585\n",
      "Epoch 2152, Loss: 0.2130618318915367, Final Batch Loss: 0.1238182783126831\n",
      "Epoch 2153, Loss: 0.05254174396395683, Final Batch Loss: 0.03213882073760033\n",
      "Epoch 2154, Loss: 0.12969383969902992, Final Batch Loss: 0.05594073608517647\n",
      "Epoch 2155, Loss: 0.0809254739433527, Final Batch Loss: 0.054545097053050995\n",
      "Epoch 2156, Loss: 0.11400486342608929, Final Batch Loss: 0.08423967659473419\n",
      "Epoch 2157, Loss: 0.11870639026165009, Final Batch Loss: 0.05952060967683792\n",
      "Epoch 2158, Loss: 0.12268232181668282, Final Batch Loss: 0.05283303186297417\n",
      "Epoch 2159, Loss: 0.1507297158241272, Final Batch Loss: 0.07902367413043976\n",
      "Epoch 2160, Loss: 0.12216420471668243, Final Batch Loss: 0.04532000422477722\n",
      "Epoch 2161, Loss: 0.11938345059752464, Final Batch Loss: 0.06345710903406143\n",
      "Epoch 2162, Loss: 0.04762479104101658, Final Batch Loss: 0.01792028546333313\n",
      "Epoch 2163, Loss: 0.08891603350639343, Final Batch Loss: 0.043652936816215515\n",
      "Epoch 2164, Loss: 0.11057460308074951, Final Batch Loss: 0.04618498682975769\n",
      "Epoch 2165, Loss: 0.09079286269843578, Final Batch Loss: 0.025408221408724785\n",
      "Epoch 2166, Loss: 0.07014517299830914, Final Batch Loss: 0.028704697266221046\n",
      "Epoch 2167, Loss: 0.10410619899630547, Final Batch Loss: 0.04712449014186859\n",
      "Epoch 2168, Loss: 0.09729862585663795, Final Batch Loss: 0.04875531420111656\n",
      "Epoch 2169, Loss: 0.1395355984568596, Final Batch Loss: 0.0777258574962616\n",
      "Epoch 2170, Loss: 0.05092537961900234, Final Batch Loss: 0.015895115211606026\n",
      "Epoch 2171, Loss: 0.09122304990887642, Final Batch Loss: 0.0546812079846859\n",
      "Epoch 2172, Loss: 0.07929963432252407, Final Batch Loss: 0.03110300935804844\n",
      "Epoch 2173, Loss: 0.062262484803795815, Final Batch Loss: 0.02887263335287571\n",
      "Epoch 2174, Loss: 0.05249678622931242, Final Batch Loss: 0.011292035691440105\n",
      "Epoch 2175, Loss: 0.08125151693820953, Final Batch Loss: 0.045295435935258865\n",
      "Epoch 2176, Loss: 0.05826660990715027, Final Batch Loss: 0.015845857560634613\n",
      "Epoch 2177, Loss: 0.057440534234046936, Final Batch Loss: 0.023114752024412155\n",
      "Epoch 2178, Loss: 0.09719638526439667, Final Batch Loss: 0.06139068305492401\n",
      "Epoch 2179, Loss: 0.08251063153147697, Final Batch Loss: 0.031275078654289246\n",
      "Epoch 2180, Loss: 0.10480495914816856, Final Batch Loss: 0.04062468931078911\n",
      "Epoch 2181, Loss: 0.03568148426711559, Final Batch Loss: 0.019908515736460686\n",
      "Epoch 2182, Loss: 0.05994242615997791, Final Batch Loss: 0.025372644886374474\n",
      "Epoch 2183, Loss: 0.04916616715490818, Final Batch Loss: 0.011800093576312065\n",
      "Epoch 2184, Loss: 0.15415090322494507, Final Batch Loss: 0.10045936703681946\n",
      "Epoch 2185, Loss: 0.11273849755525589, Final Batch Loss: 0.05356178060173988\n",
      "Epoch 2186, Loss: 0.07953618094325066, Final Batch Loss: 0.05729847401380539\n",
      "Epoch 2187, Loss: 0.11194496974349022, Final Batch Loss: 0.050350092351436615\n",
      "Epoch 2188, Loss: 0.09695932269096375, Final Batch Loss: 0.06747567653656006\n",
      "Epoch 2189, Loss: 0.08986571617424488, Final Batch Loss: 0.014219725504517555\n",
      "Epoch 2190, Loss: 0.11144919693470001, Final Batch Loss: 0.06579870730638504\n",
      "Epoch 2191, Loss: 0.08056335337460041, Final Batch Loss: 0.05908483639359474\n",
      "Epoch 2192, Loss: 0.09366145357489586, Final Batch Loss: 0.05777136608958244\n",
      "Epoch 2193, Loss: 0.13076931983232498, Final Batch Loss: 0.09201487898826599\n",
      "Epoch 2194, Loss: 0.06784824468195438, Final Batch Loss: 0.03845271095633507\n",
      "Epoch 2195, Loss: 0.13423502072691917, Final Batch Loss: 0.03353660926222801\n",
      "Epoch 2196, Loss: 0.08674078620970249, Final Batch Loss: 0.06299471855163574\n",
      "Epoch 2197, Loss: 0.045423898845911026, Final Batch Loss: 0.017736995592713356\n",
      "Epoch 2198, Loss: 0.0765480175614357, Final Batch Loss: 0.04278566688299179\n",
      "Epoch 2199, Loss: 0.16757557541131973, Final Batch Loss: 0.10459032654762268\n",
      "Epoch 2200, Loss: 0.06447496078908443, Final Batch Loss: 0.02278311736881733\n",
      "Epoch 2201, Loss: 0.07281026989221573, Final Batch Loss: 0.02799193561077118\n",
      "Epoch 2202, Loss: 0.12999258935451508, Final Batch Loss: 0.02962373197078705\n",
      "Epoch 2203, Loss: 0.09671733155846596, Final Batch Loss: 0.04805488884449005\n",
      "Epoch 2204, Loss: 0.06220116280019283, Final Batch Loss: 0.03289176523685455\n",
      "Epoch 2205, Loss: 0.1618521623313427, Final Batch Loss: 0.10708823800086975\n",
      "Epoch 2206, Loss: 0.058924488723278046, Final Batch Loss: 0.028771795332431793\n",
      "Epoch 2207, Loss: 0.06663136929273605, Final Batch Loss: 0.0289059579372406\n",
      "Epoch 2208, Loss: 0.13772131502628326, Final Batch Loss: 0.06724296510219574\n",
      "Epoch 2209, Loss: 0.059617819264531136, Final Batch Loss: 0.03050212748348713\n",
      "Epoch 2210, Loss: 0.13332418352365494, Final Batch Loss: 0.06907141953706741\n",
      "Epoch 2211, Loss: 0.07319045998156071, Final Batch Loss: 0.021826332435011864\n",
      "Epoch 2212, Loss: 0.05677076429128647, Final Batch Loss: 0.032564662396907806\n",
      "Epoch 2213, Loss: 0.08203962445259094, Final Batch Loss: 0.043741412460803986\n",
      "Epoch 2214, Loss: 0.06288104504346848, Final Batch Loss: 0.03142857551574707\n",
      "Epoch 2215, Loss: 0.13656965643167496, Final Batch Loss: 0.06441134214401245\n",
      "Epoch 2216, Loss: 0.06718004308640957, Final Batch Loss: 0.03949252516031265\n",
      "Epoch 2217, Loss: 0.05958232656121254, Final Batch Loss: 0.01717311516404152\n",
      "Epoch 2218, Loss: 0.06874558888375759, Final Batch Loss: 0.02316277287900448\n",
      "Epoch 2219, Loss: 0.15810062736272812, Final Batch Loss: 0.1115506961941719\n",
      "Epoch 2220, Loss: 0.1610303893685341, Final Batch Loss: 0.10006290674209595\n",
      "Epoch 2221, Loss: 0.06563314609229565, Final Batch Loss: 0.030885973945260048\n",
      "Epoch 2222, Loss: 0.09661635011434555, Final Batch Loss: 0.06618041545152664\n",
      "Epoch 2223, Loss: 0.1470605954527855, Final Batch Loss: 0.07521836459636688\n",
      "Epoch 2224, Loss: 0.09729117155075073, Final Batch Loss: 0.0465480238199234\n",
      "Epoch 2225, Loss: 0.08253392577171326, Final Batch Loss: 0.03308112546801567\n",
      "Epoch 2226, Loss: 0.07939474284648895, Final Batch Loss: 0.045310527086257935\n",
      "Epoch 2227, Loss: 0.10966300591826439, Final Batch Loss: 0.05451970919966698\n",
      "Epoch 2228, Loss: 0.09421413391828537, Final Batch Loss: 0.03448669984936714\n",
      "Epoch 2229, Loss: 0.047299230471253395, Final Batch Loss: 0.016405440866947174\n",
      "Epoch 2230, Loss: 0.08422019146382809, Final Batch Loss: 0.023816270753741264\n",
      "Epoch 2231, Loss: 0.07287974283099174, Final Batch Loss: 0.02622836083173752\n",
      "Epoch 2232, Loss: 0.092110775411129, Final Batch Loss: 0.0455799363553524\n",
      "Epoch 2233, Loss: 0.09231926128268242, Final Batch Loss: 0.05490387976169586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2234, Loss: 0.05477866530418396, Final Batch Loss: 0.026683233678340912\n",
      "Epoch 2235, Loss: 0.12918228656053543, Final Batch Loss: 0.08944907039403915\n",
      "Epoch 2236, Loss: 0.06475008651614189, Final Batch Loss: 0.030740421265363693\n",
      "Epoch 2237, Loss: 0.10681276768445969, Final Batch Loss: 0.07290151715278625\n",
      "Epoch 2238, Loss: 0.10441025719046593, Final Batch Loss: 0.06549336761236191\n",
      "Epoch 2239, Loss: 0.09667705930769444, Final Batch Loss: 0.02301199920475483\n",
      "Epoch 2240, Loss: 0.08386864513158798, Final Batch Loss: 0.04222077876329422\n",
      "Epoch 2241, Loss: 0.12908752262592316, Final Batch Loss: 0.10132432729005814\n",
      "Epoch 2242, Loss: 0.05752035975456238, Final Batch Loss: 0.027813225984573364\n",
      "Epoch 2243, Loss: 0.16790295764803886, Final Batch Loss: 0.12253627926111221\n",
      "Epoch 2244, Loss: 0.0528484508395195, Final Batch Loss: 0.03325364366173744\n",
      "Epoch 2245, Loss: 0.1434410624206066, Final Batch Loss: 0.09564884752035141\n",
      "Epoch 2246, Loss: 0.09768691658973694, Final Batch Loss: 0.03170614689588547\n",
      "Epoch 2247, Loss: 0.10780398175120354, Final Batch Loss: 0.08429670333862305\n",
      "Epoch 2248, Loss: 0.08605827018618584, Final Batch Loss: 0.038136474788188934\n",
      "Epoch 2249, Loss: 0.11979475617408752, Final Batch Loss: 0.06640800088644028\n",
      "Epoch 2250, Loss: 0.09025302529335022, Final Batch Loss: 0.06426522880792618\n",
      "Epoch 2251, Loss: 0.0946415476500988, Final Batch Loss: 0.034657783806324005\n",
      "Epoch 2252, Loss: 0.07497713714838028, Final Batch Loss: 0.032174207270145416\n",
      "Epoch 2253, Loss: 0.0552557073533535, Final Batch Loss: 0.025199780240654945\n",
      "Epoch 2254, Loss: 0.08057264238595963, Final Batch Loss: 0.03772788122296333\n",
      "Epoch 2255, Loss: 0.10036858171224594, Final Batch Loss: 0.05258411914110184\n",
      "Epoch 2256, Loss: 0.053229548037052155, Final Batch Loss: 0.0186898373067379\n",
      "Epoch 2257, Loss: 0.07395592331886292, Final Batch Loss: 0.03859870508313179\n",
      "Epoch 2258, Loss: 0.09500044956803322, Final Batch Loss: 0.05342572182416916\n",
      "Epoch 2259, Loss: 0.05990565940737724, Final Batch Loss: 0.036136772483587265\n",
      "Epoch 2260, Loss: 0.07970351725816727, Final Batch Loss: 0.025448106229305267\n",
      "Epoch 2261, Loss: 0.0787208080291748, Final Batch Loss: 0.01774495095014572\n",
      "Epoch 2262, Loss: 0.13357773050665855, Final Batch Loss: 0.09763174504041672\n",
      "Epoch 2263, Loss: 0.10432406887412071, Final Batch Loss: 0.020214620977640152\n",
      "Epoch 2264, Loss: 0.09945089928805828, Final Batch Loss: 0.030648095533251762\n",
      "Epoch 2265, Loss: 0.13121257722377777, Final Batch Loss: 0.0783572793006897\n",
      "Epoch 2266, Loss: 0.10075443610548973, Final Batch Loss: 0.054332416504621506\n",
      "Epoch 2267, Loss: 0.0671805702149868, Final Batch Loss: 0.03144872188568115\n",
      "Epoch 2268, Loss: 0.0354996295645833, Final Batch Loss: 0.024457518011331558\n",
      "Epoch 2269, Loss: 0.08406370878219604, Final Batch Loss: 0.04590722918510437\n",
      "Epoch 2270, Loss: 0.08392928540706635, Final Batch Loss: 0.0494668148458004\n",
      "Epoch 2271, Loss: 0.09809717908501625, Final Batch Loss: 0.05254649370908737\n",
      "Epoch 2272, Loss: 0.09932462871074677, Final Batch Loss: 0.04787739738821983\n",
      "Epoch 2273, Loss: 0.06536432355642319, Final Batch Loss: 0.03521173447370529\n",
      "Epoch 2274, Loss: 0.08063130639493465, Final Batch Loss: 0.06012978404760361\n",
      "Epoch 2275, Loss: 0.13477562740445137, Final Batch Loss: 0.08069717884063721\n",
      "Epoch 2276, Loss: 0.10202156752347946, Final Batch Loss: 0.040254708379507065\n",
      "Epoch 2277, Loss: 0.09575261920690536, Final Batch Loss: 0.05018218979239464\n",
      "Epoch 2278, Loss: 0.1100008562207222, Final Batch Loss: 0.06353077292442322\n",
      "Epoch 2279, Loss: 0.09732183627784252, Final Batch Loss: 0.0727027878165245\n",
      "Epoch 2280, Loss: 0.09443004801869392, Final Batch Loss: 0.04836553707718849\n",
      "Epoch 2281, Loss: 0.1507362350821495, Final Batch Loss: 0.08509907126426697\n",
      "Epoch 2282, Loss: 0.08681007660925388, Final Batch Loss: 0.029391752555966377\n",
      "Epoch 2283, Loss: 0.11160361766815186, Final Batch Loss: 0.05373375862836838\n",
      "Epoch 2284, Loss: 0.10548366233706474, Final Batch Loss: 0.03996824100613594\n",
      "Epoch 2285, Loss: 0.10995867475867271, Final Batch Loss: 0.031780559569597244\n",
      "Epoch 2286, Loss: 0.1399690881371498, Final Batch Loss: 0.03927052766084671\n",
      "Epoch 2287, Loss: 0.08544202148914337, Final Batch Loss: 0.03900511935353279\n",
      "Epoch 2288, Loss: 0.18436813354492188, Final Batch Loss: 0.12141429632902145\n",
      "Epoch 2289, Loss: 0.07676009275019169, Final Batch Loss: 0.04614797234535217\n",
      "Epoch 2290, Loss: 0.08104589581489563, Final Batch Loss: 0.04473661258816719\n",
      "Epoch 2291, Loss: 0.053107975050807, Final Batch Loss: 0.026843439787626266\n",
      "Epoch 2292, Loss: 0.10402121394872665, Final Batch Loss: 0.04730544611811638\n",
      "Epoch 2293, Loss: 0.05900454334914684, Final Batch Loss: 0.025922996923327446\n",
      "Epoch 2294, Loss: 0.11595744267106056, Final Batch Loss: 0.06406857073307037\n",
      "Epoch 2295, Loss: 0.16528475284576416, Final Batch Loss: 0.07039101421833038\n",
      "Epoch 2296, Loss: 0.07977288030087948, Final Batch Loss: 0.06120873987674713\n",
      "Epoch 2297, Loss: 0.12314120680093765, Final Batch Loss: 0.07376930862665176\n",
      "Epoch 2298, Loss: 0.09184842556715012, Final Batch Loss: 0.06711272895336151\n",
      "Epoch 2299, Loss: 0.1126854196190834, Final Batch Loss: 0.07101306319236755\n",
      "Epoch 2300, Loss: 0.23091640323400497, Final Batch Loss: 0.15764059126377106\n",
      "Epoch 2301, Loss: 0.04948531650006771, Final Batch Loss: 0.02523508295416832\n",
      "Epoch 2302, Loss: 0.08324355259537697, Final Batch Loss: 0.05413616821169853\n",
      "Epoch 2303, Loss: 0.11227263882756233, Final Batch Loss: 0.04594312235713005\n",
      "Epoch 2304, Loss: 0.05915827304124832, Final Batch Loss: 0.028431355953216553\n",
      "Epoch 2305, Loss: 0.11075134202837944, Final Batch Loss: 0.06101928651332855\n",
      "Epoch 2306, Loss: 0.08989141322672367, Final Batch Loss: 0.0664706602692604\n",
      "Epoch 2307, Loss: 0.08292533457279205, Final Batch Loss: 0.03217224031686783\n",
      "Epoch 2308, Loss: 0.07347427681088448, Final Batch Loss: 0.02588433399796486\n",
      "Epoch 2309, Loss: 0.09294652193784714, Final Batch Loss: 0.053141262382268906\n",
      "Epoch 2310, Loss: 0.04591212421655655, Final Batch Loss: 0.014898408204317093\n",
      "Epoch 2311, Loss: 0.1606079563498497, Final Batch Loss: 0.09291283041238785\n",
      "Epoch 2312, Loss: 0.06663442403078079, Final Batch Loss: 0.03497821465134621\n",
      "Epoch 2313, Loss: 0.16966664791107178, Final Batch Loss: 0.06851354241371155\n",
      "Epoch 2314, Loss: 0.10241067782044411, Final Batch Loss: 0.06973224878311157\n",
      "Epoch 2315, Loss: 0.10634449496865273, Final Batch Loss: 0.0535673126578331\n",
      "Epoch 2316, Loss: 0.10306106880307198, Final Batch Loss: 0.03170068934559822\n",
      "Epoch 2317, Loss: 0.09134535491466522, Final Batch Loss: 0.054490670561790466\n",
      "Epoch 2318, Loss: 0.12491338327527046, Final Batch Loss: 0.038304854184389114\n",
      "Epoch 2319, Loss: 0.17404649779200554, Final Batch Loss: 0.1238023117184639\n",
      "Epoch 2320, Loss: 0.07082260772585869, Final Batch Loss: 0.03204512596130371\n",
      "Epoch 2321, Loss: 0.08769087493419647, Final Batch Loss: 0.05779159441590309\n",
      "Epoch 2322, Loss: 0.10102122649550438, Final Batch Loss: 0.06076592206954956\n",
      "Epoch 2323, Loss: 0.12068967148661613, Final Batch Loss: 0.06884126365184784\n",
      "Epoch 2324, Loss: 0.12102359905838966, Final Batch Loss: 0.0659894198179245\n",
      "Epoch 2325, Loss: 0.12442325614392757, Final Batch Loss: 0.09666810184717178\n",
      "Epoch 2326, Loss: 0.09467776864767075, Final Batch Loss: 0.029858529567718506\n",
      "Epoch 2327, Loss: 0.06956716813147068, Final Batch Loss: 0.029927173629403114\n",
      "Epoch 2328, Loss: 0.14175506681203842, Final Batch Loss: 0.06820376217365265\n",
      "Epoch 2329, Loss: 0.09548749774694443, Final Batch Loss: 0.038106970489025116\n",
      "Epoch 2330, Loss: 0.11111291125416756, Final Batch Loss: 0.030923467129468918\n",
      "Epoch 2331, Loss: 0.08579630590975285, Final Batch Loss: 0.026811016723513603\n",
      "Epoch 2332, Loss: 0.07534218207001686, Final Batch Loss: 0.03263381868600845\n",
      "Epoch 2333, Loss: 0.07383061572909355, Final Batch Loss: 0.02471628040075302\n",
      "Epoch 2334, Loss: 0.10862813144922256, Final Batch Loss: 0.023123107850551605\n",
      "Epoch 2335, Loss: 0.07199928537011147, Final Batch Loss: 0.020368915051221848\n",
      "Epoch 2336, Loss: 0.08385808020830154, Final Batch Loss: 0.0362323634326458\n",
      "Epoch 2337, Loss: 0.11662660911679268, Final Batch Loss: 0.050534602254629135\n",
      "Epoch 2338, Loss: 0.08983028680086136, Final Batch Loss: 0.052746694535017014\n",
      "Epoch 2339, Loss: 0.0826139785349369, Final Batch Loss: 0.03746883198618889\n",
      "Epoch 2340, Loss: 0.12197703495621681, Final Batch Loss: 0.06670937687158585\n",
      "Epoch 2341, Loss: 0.12013488635420799, Final Batch Loss: 0.07870025932788849\n",
      "Epoch 2342, Loss: 0.06281273998320103, Final Batch Loss: 0.02366832084953785\n",
      "Epoch 2343, Loss: 0.09917205572128296, Final Batch Loss: 0.06050094589591026\n",
      "Epoch 2344, Loss: 0.07442166283726692, Final Batch Loss: 0.039797741919755936\n",
      "Epoch 2345, Loss: 0.04288651421666145, Final Batch Loss: 0.008405342698097229\n",
      "Epoch 2346, Loss: 0.11380144208669662, Final Batch Loss: 0.055141203105449677\n",
      "Epoch 2347, Loss: 0.09268676862120628, Final Batch Loss: 0.05454395338892937\n",
      "Epoch 2348, Loss: 0.08151589147746563, Final Batch Loss: 0.02996732108294964\n",
      "Epoch 2349, Loss: 0.1610666923224926, Final Batch Loss: 0.10089316219091415\n",
      "Epoch 2350, Loss: 0.12173062562942505, Final Batch Loss: 0.07968474179506302\n",
      "Epoch 2351, Loss: 0.10391242057085037, Final Batch Loss: 0.05290509760379791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2352, Loss: 0.11347243562340736, Final Batch Loss: 0.034962836652994156\n",
      "Epoch 2353, Loss: 0.03400368057191372, Final Batch Loss: 0.01422291062772274\n",
      "Epoch 2354, Loss: 0.07260183990001678, Final Batch Loss: 0.04007961228489876\n",
      "Epoch 2355, Loss: 0.07624813541769981, Final Batch Loss: 0.0439041368663311\n",
      "Epoch 2356, Loss: 0.07244245149195194, Final Batch Loss: 0.02657087706029415\n",
      "Epoch 2357, Loss: 0.08451110124588013, Final Batch Loss: 0.03798696771264076\n",
      "Epoch 2358, Loss: 0.10519524477422237, Final Batch Loss: 0.08324288576841354\n",
      "Epoch 2359, Loss: 0.1395405288785696, Final Batch Loss: 0.1083630695939064\n",
      "Epoch 2360, Loss: 0.07354646921157837, Final Batch Loss: 0.028095558285713196\n",
      "Epoch 2361, Loss: 0.11241855844855309, Final Batch Loss: 0.057545896619558334\n",
      "Epoch 2362, Loss: 0.08763676322996616, Final Batch Loss: 0.06112423911690712\n",
      "Epoch 2363, Loss: 0.0899578370153904, Final Batch Loss: 0.0441695861518383\n",
      "Epoch 2364, Loss: 0.05792112462222576, Final Batch Loss: 0.019521476700901985\n",
      "Epoch 2365, Loss: 0.09486318752169609, Final Batch Loss: 0.05174269899725914\n",
      "Epoch 2366, Loss: 0.06487521901726723, Final Batch Loss: 0.01687227189540863\n",
      "Epoch 2367, Loss: 0.04419480450451374, Final Batch Loss: 0.023774713277816772\n",
      "Epoch 2368, Loss: 0.0532626211643219, Final Batch Loss: 0.016182396560907364\n",
      "Epoch 2369, Loss: 0.1151951439678669, Final Batch Loss: 0.07041343301534653\n",
      "Epoch 2370, Loss: 0.12420548126101494, Final Batch Loss: 0.06304218620061874\n",
      "Epoch 2371, Loss: 0.1263316534459591, Final Batch Loss: 0.06697272509336472\n",
      "Epoch 2372, Loss: 0.08655859157443047, Final Batch Loss: 0.039767879992723465\n",
      "Epoch 2373, Loss: 0.0668271891772747, Final Batch Loss: 0.017066340893507004\n",
      "Epoch 2374, Loss: 0.10015427693724632, Final Batch Loss: 0.06471596658229828\n",
      "Epoch 2375, Loss: 0.09285424277186394, Final Batch Loss: 0.05126752331852913\n",
      "Epoch 2376, Loss: 0.06600761786103249, Final Batch Loss: 0.03412964940071106\n",
      "Epoch 2377, Loss: 0.12764281034469604, Final Batch Loss: 0.08114299923181534\n",
      "Epoch 2378, Loss: 0.09619571268558502, Final Batch Loss: 0.05966359004378319\n",
      "Epoch 2379, Loss: 0.09737297147512436, Final Batch Loss: 0.041869793087244034\n",
      "Epoch 2380, Loss: 0.06652519293129444, Final Batch Loss: 0.027300206944346428\n",
      "Epoch 2381, Loss: 0.056710490956902504, Final Batch Loss: 0.023270314559340477\n",
      "Epoch 2382, Loss: 0.1053430326282978, Final Batch Loss: 0.04395139217376709\n",
      "Epoch 2383, Loss: 0.046944646164774895, Final Batch Loss: 0.024549229070544243\n",
      "Epoch 2384, Loss: 0.13303604908287525, Final Batch Loss: 0.103396937251091\n",
      "Epoch 2385, Loss: 0.05417437478899956, Final Batch Loss: 0.02210944890975952\n",
      "Epoch 2386, Loss: 0.06591961532831192, Final Batch Loss: 0.014614187180995941\n",
      "Epoch 2387, Loss: 0.039494569413363934, Final Batch Loss: 0.009719752706587315\n",
      "Epoch 2388, Loss: 0.08454335853457451, Final Batch Loss: 0.048286739736795425\n",
      "Epoch 2389, Loss: 0.10731716081500053, Final Batch Loss: 0.05115550011396408\n",
      "Epoch 2390, Loss: 0.08333570882678032, Final Batch Loss: 0.04225964844226837\n",
      "Epoch 2391, Loss: 0.11340398713946342, Final Batch Loss: 0.051226772367954254\n",
      "Epoch 2392, Loss: 0.0708333607763052, Final Batch Loss: 0.026718126609921455\n",
      "Epoch 2393, Loss: 0.07619595527648926, Final Batch Loss: 0.04665767401456833\n",
      "Epoch 2394, Loss: 0.05752960406243801, Final Batch Loss: 0.03684608265757561\n",
      "Epoch 2395, Loss: 0.07442031614482403, Final Batch Loss: 0.027965513989329338\n",
      "Epoch 2396, Loss: 0.11552581191062927, Final Batch Loss: 0.03719520568847656\n",
      "Epoch 2397, Loss: 0.09395739436149597, Final Batch Loss: 0.04120431840419769\n",
      "Epoch 2398, Loss: 0.05610209237784147, Final Batch Loss: 0.010985649190843105\n",
      "Epoch 2399, Loss: 0.08440751023590565, Final Batch Loss: 0.025285569950938225\n",
      "Epoch 2400, Loss: 0.1113332100212574, Final Batch Loss: 0.0499543696641922\n",
      "Epoch 2401, Loss: 0.153329499065876, Final Batch Loss: 0.10301757603883743\n",
      "Epoch 2402, Loss: 0.04376737400889397, Final Batch Loss: 0.020536713302135468\n",
      "Epoch 2403, Loss: 0.03877277020365, Final Batch Loss: 0.010614135302603245\n",
      "Epoch 2404, Loss: 0.08047601021826267, Final Batch Loss: 0.024781057611107826\n",
      "Epoch 2405, Loss: 0.09995551407337189, Final Batch Loss: 0.060247547924518585\n",
      "Epoch 2406, Loss: 0.07830366306006908, Final Batch Loss: 0.014042092487215996\n",
      "Epoch 2407, Loss: 0.13144643604755402, Final Batch Loss: 0.06625683605670929\n",
      "Epoch 2408, Loss: 0.07140602171421051, Final Batch Loss: 0.027654722332954407\n",
      "Epoch 2409, Loss: 0.1131664477288723, Final Batch Loss: 0.04675457254052162\n",
      "Epoch 2410, Loss: 0.08428597450256348, Final Batch Loss: 0.04358544945716858\n",
      "Epoch 2411, Loss: 0.06704387441277504, Final Batch Loss: 0.017174769192934036\n",
      "Epoch 2412, Loss: 0.11373546905815601, Final Batch Loss: 0.09290248155593872\n",
      "Epoch 2413, Loss: 0.07191820070147514, Final Batch Loss: 0.018700100481510162\n",
      "Epoch 2414, Loss: 0.07313617784529924, Final Batch Loss: 0.06135164946317673\n",
      "Epoch 2415, Loss: 0.08986292965710163, Final Batch Loss: 0.06594672054052353\n",
      "Epoch 2416, Loss: 0.05323899257928133, Final Batch Loss: 0.009389759041368961\n",
      "Epoch 2417, Loss: 0.06075225118547678, Final Batch Loss: 0.013014198280870914\n",
      "Epoch 2418, Loss: 0.0835091844201088, Final Batch Loss: 0.04162430763244629\n",
      "Epoch 2419, Loss: 0.07719505578279495, Final Batch Loss: 0.03339599072933197\n",
      "Epoch 2420, Loss: 0.09121215902268887, Final Batch Loss: 0.0652509406208992\n",
      "Epoch 2421, Loss: 0.06530330330133438, Final Batch Loss: 0.03204891085624695\n",
      "Epoch 2422, Loss: 0.06621294468641281, Final Batch Loss: 0.023748647421598434\n",
      "Epoch 2423, Loss: 0.03566086292266846, Final Batch Loss: 0.014507116749882698\n",
      "Epoch 2424, Loss: 0.04839582182466984, Final Batch Loss: 0.016020549461245537\n",
      "Epoch 2425, Loss: 0.07903643697500229, Final Batch Loss: 0.03408816084265709\n",
      "Epoch 2426, Loss: 0.05420771986246109, Final Batch Loss: 0.0362979955971241\n",
      "Epoch 2427, Loss: 0.03984149731695652, Final Batch Loss: 0.020682351663708687\n",
      "Epoch 2428, Loss: 0.12258556857705116, Final Batch Loss: 0.06362487375736237\n",
      "Epoch 2429, Loss: 0.16319739073514938, Final Batch Loss: 0.1389998495578766\n",
      "Epoch 2430, Loss: 0.059803109616041183, Final Batch Loss: 0.01835617795586586\n",
      "Epoch 2431, Loss: 0.024891655892133713, Final Batch Loss: 0.011656126007437706\n",
      "Epoch 2432, Loss: 0.06065783929079771, Final Batch Loss: 0.013625687919557095\n",
      "Epoch 2433, Loss: 0.05196013301610947, Final Batch Loss: 0.01789131760597229\n",
      "Epoch 2434, Loss: 0.04617469199001789, Final Batch Loss: 0.0302758626639843\n",
      "Epoch 2435, Loss: 0.07521800138056278, Final Batch Loss: 0.025805054232478142\n",
      "Epoch 2436, Loss: 0.049799880012869835, Final Batch Loss: 0.015366999432444572\n",
      "Epoch 2437, Loss: 0.08829442411661148, Final Batch Loss: 0.029780540615320206\n",
      "Epoch 2438, Loss: 0.07734221406280994, Final Batch Loss: 0.029884377494454384\n",
      "Epoch 2439, Loss: 0.06675609014928341, Final Batch Loss: 0.018211329355835915\n",
      "Epoch 2440, Loss: 0.07332771085202694, Final Batch Loss: 0.04713219776749611\n",
      "Epoch 2441, Loss: 0.05636751838028431, Final Batch Loss: 0.015254968777298927\n",
      "Epoch 2442, Loss: 0.1058198381215334, Final Batch Loss: 0.08118409663438797\n",
      "Epoch 2443, Loss: 0.07740580663084984, Final Batch Loss: 0.035058096051216125\n",
      "Epoch 2444, Loss: 0.08403821103274822, Final Batch Loss: 0.02431209571659565\n",
      "Epoch 2445, Loss: 0.06061803363263607, Final Batch Loss: 0.038229092955589294\n",
      "Epoch 2446, Loss: 0.1324746571481228, Final Batch Loss: 0.06076597794890404\n",
      "Epoch 2447, Loss: 0.0888858251273632, Final Batch Loss: 0.051570259034633636\n",
      "Epoch 2448, Loss: 0.06042974069714546, Final Batch Loss: 0.0425344780087471\n",
      "Epoch 2449, Loss: 0.08508606627583504, Final Batch Loss: 0.0478750616312027\n",
      "Epoch 2450, Loss: 0.042410632595419884, Final Batch Loss: 0.015690138563513756\n",
      "Epoch 2451, Loss: 0.05951987951993942, Final Batch Loss: 0.03464393690228462\n",
      "Epoch 2452, Loss: 0.06912444531917572, Final Batch Loss: 0.03200342878699303\n",
      "Epoch 2453, Loss: 0.13271377980709076, Final Batch Loss: 0.06111323833465576\n",
      "Epoch 2454, Loss: 0.04192037880420685, Final Batch Loss: 0.01314297504723072\n",
      "Epoch 2455, Loss: 0.042473060078918934, Final Batch Loss: 0.009196796454489231\n",
      "Epoch 2456, Loss: 0.12353815138339996, Final Batch Loss: 0.08510617166757584\n",
      "Epoch 2457, Loss: 0.0520185362547636, Final Batch Loss: 0.022139256820082664\n",
      "Epoch 2458, Loss: 0.10414131730794907, Final Batch Loss: 0.0719720795750618\n",
      "Epoch 2459, Loss: 0.09741105511784554, Final Batch Loss: 0.0618956983089447\n",
      "Epoch 2460, Loss: 0.07662332430481911, Final Batch Loss: 0.01435919851064682\n",
      "Epoch 2461, Loss: 0.07193999364972115, Final Batch Loss: 0.04048873484134674\n",
      "Epoch 2462, Loss: 0.09806501865386963, Final Batch Loss: 0.07294119894504547\n",
      "Epoch 2463, Loss: 0.09833306074142456, Final Batch Loss: 0.03781075030565262\n",
      "Epoch 2464, Loss: 0.10102000832557678, Final Batch Loss: 0.0147009938955307\n",
      "Epoch 2465, Loss: 0.09347780421376228, Final Batch Loss: 0.025168802589178085\n",
      "Epoch 2466, Loss: 0.11605395749211311, Final Batch Loss: 0.07846954464912415\n",
      "Epoch 2467, Loss: 0.03576111048460007, Final Batch Loss: 0.012495120987296104\n",
      "Epoch 2468, Loss: 0.0605030357837677, Final Batch Loss: 0.03714675083756447\n",
      "Epoch 2469, Loss: 0.069634348154068, Final Batch Loss: 0.03520601615309715\n",
      "Epoch 2470, Loss: 0.16638275608420372, Final Batch Loss: 0.10844031721353531\n",
      "Epoch 2471, Loss: 0.05254717357456684, Final Batch Loss: 0.010118922218680382\n",
      "Epoch 2472, Loss: 0.06643842719495296, Final Batch Loss: 0.025472698733210564\n",
      "Epoch 2473, Loss: 0.09818005934357643, Final Batch Loss: 0.05925504490733147\n",
      "Epoch 2474, Loss: 0.11118537932634354, Final Batch Loss: 0.05183793976902962\n",
      "Epoch 2475, Loss: 0.03876019828021526, Final Batch Loss: 0.017839856445789337\n",
      "Epoch 2476, Loss: 0.07219620421528816, Final Batch Loss: 0.042382966727018356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2477, Loss: 0.07728723250329494, Final Batch Loss: 0.013533448800444603\n",
      "Epoch 2478, Loss: 0.06809468567371368, Final Batch Loss: 0.027215413749217987\n",
      "Epoch 2479, Loss: 0.07289306074380875, Final Batch Loss: 0.03973507508635521\n",
      "Epoch 2480, Loss: 0.07008060812950134, Final Batch Loss: 0.031486570835113525\n",
      "Epoch 2481, Loss: 0.12081535905599594, Final Batch Loss: 0.024688303470611572\n",
      "Epoch 2482, Loss: 0.05406000092625618, Final Batch Loss: 0.016326408833265305\n",
      "Epoch 2483, Loss: 0.03569015674293041, Final Batch Loss: 0.0130109041929245\n",
      "Epoch 2484, Loss: 0.04645789600908756, Final Batch Loss: 0.026529328897595406\n",
      "Epoch 2485, Loss: 0.09172451123595238, Final Batch Loss: 0.010134097188711166\n",
      "Epoch 2486, Loss: 0.10094038769602776, Final Batch Loss: 0.03235640004277229\n",
      "Epoch 2487, Loss: 0.057350512593984604, Final Batch Loss: 0.018452275544404984\n",
      "Epoch 2488, Loss: 0.08661385998129845, Final Batch Loss: 0.0360347181558609\n",
      "Epoch 2489, Loss: 0.06304826959967613, Final Batch Loss: 0.03166232630610466\n",
      "Epoch 2490, Loss: 0.07463110983371735, Final Batch Loss: 0.020325805991888046\n",
      "Epoch 2491, Loss: 0.03853481076657772, Final Batch Loss: 0.01818551868200302\n",
      "Epoch 2492, Loss: 0.04666811227798462, Final Batch Loss: 0.029449859634041786\n",
      "Epoch 2493, Loss: 0.037522561848163605, Final Batch Loss: 0.022972848266363144\n",
      "Epoch 2494, Loss: 0.0394075782969594, Final Batch Loss: 0.013227651827037334\n",
      "Epoch 2495, Loss: 0.05741700530052185, Final Batch Loss: 0.04434753581881523\n",
      "Epoch 2496, Loss: 0.09683814644813538, Final Batch Loss: 0.04101218283176422\n",
      "Epoch 2497, Loss: 0.05260448157787323, Final Batch Loss: 0.020247366279363632\n",
      "Epoch 2498, Loss: 0.04788746125996113, Final Batch Loss: 0.020773209631443024\n",
      "Epoch 2499, Loss: 0.08856723085045815, Final Batch Loss: 0.03685687109827995\n",
      "Epoch 2500, Loss: 0.1177498921751976, Final Batch Loss: 0.06096217408776283\n",
      "Epoch 2501, Loss: 0.0816666167229414, Final Batch Loss: 0.020480366423726082\n",
      "Epoch 2502, Loss: 0.1681872308254242, Final Batch Loss: 0.05012708157300949\n",
      "Epoch 2503, Loss: 0.16492117568850517, Final Batch Loss: 0.14328424632549286\n",
      "Epoch 2504, Loss: 0.0381172988563776, Final Batch Loss: 0.00974423997104168\n",
      "Epoch 2505, Loss: 0.07222776859998703, Final Batch Loss: 0.02582715079188347\n",
      "Epoch 2506, Loss: 0.0384642006829381, Final Batch Loss: 0.01240867841988802\n",
      "Epoch 2507, Loss: 0.07701129280030727, Final Batch Loss: 0.01208340935409069\n",
      "Epoch 2508, Loss: 0.08463729918003082, Final Batch Loss: 0.0527433343231678\n",
      "Epoch 2509, Loss: 0.09533009305596352, Final Batch Loss: 0.03096030279994011\n",
      "Epoch 2510, Loss: 0.051074390299618244, Final Batch Loss: 0.010075368918478489\n",
      "Epoch 2511, Loss: 0.08221907541155815, Final Batch Loss: 0.040258582681417465\n",
      "Epoch 2512, Loss: 0.11067948490381241, Final Batch Loss: 0.04946427419781685\n",
      "Epoch 2513, Loss: 0.04798918589949608, Final Batch Loss: 0.029042694717645645\n",
      "Epoch 2514, Loss: 0.09978712350130081, Final Batch Loss: 0.054613277316093445\n",
      "Epoch 2515, Loss: 0.07772603258490562, Final Batch Loss: 0.059966329485177994\n",
      "Epoch 2516, Loss: 0.11610699817538261, Final Batch Loss: 0.0895465761423111\n",
      "Epoch 2517, Loss: 0.057309532538056374, Final Batch Loss: 0.02411034144461155\n",
      "Epoch 2518, Loss: 0.05298933945596218, Final Batch Loss: 0.03589125722646713\n",
      "Epoch 2519, Loss: 0.07403852045536041, Final Batch Loss: 0.03273333981633186\n",
      "Epoch 2520, Loss: 0.049366749823093414, Final Batch Loss: 0.01869639754295349\n",
      "Epoch 2521, Loss: 0.06630035303533077, Final Batch Loss: 0.02706279046833515\n",
      "Epoch 2522, Loss: 0.06316999532282352, Final Batch Loss: 0.022541509941220284\n",
      "Epoch 2523, Loss: 0.0717855766415596, Final Batch Loss: 0.017447181046009064\n",
      "Epoch 2524, Loss: 0.03110120352357626, Final Batch Loss: 0.013321959413588047\n",
      "Epoch 2525, Loss: 0.0959533043205738, Final Batch Loss: 0.03651869669556618\n",
      "Epoch 2526, Loss: 0.031424811109900475, Final Batch Loss: 0.010765865445137024\n",
      "Epoch 2527, Loss: 0.05290074273943901, Final Batch Loss: 0.0220009908080101\n",
      "Epoch 2528, Loss: 0.04929772578179836, Final Batch Loss: 0.009880909696221352\n",
      "Epoch 2529, Loss: 0.07344761863350868, Final Batch Loss: 0.037365153431892395\n",
      "Epoch 2530, Loss: 0.09820783883333206, Final Batch Loss: 0.03032853454351425\n",
      "Epoch 2531, Loss: 0.060190342366695404, Final Batch Loss: 0.019917692989110947\n",
      "Epoch 2532, Loss: 0.0504448302090168, Final Batch Loss: 0.028089892119169235\n",
      "Epoch 2533, Loss: 0.12975583225488663, Final Batch Loss: 0.07355396449565887\n",
      "Epoch 2534, Loss: 0.09732271358370781, Final Batch Loss: 0.07195413112640381\n",
      "Epoch 2535, Loss: 0.07793192937970161, Final Batch Loss: 0.04379948601126671\n",
      "Epoch 2536, Loss: 0.11797735467553139, Final Batch Loss: 0.09418389201164246\n",
      "Epoch 2537, Loss: 0.04535871930420399, Final Batch Loss: 0.02550755999982357\n",
      "Epoch 2538, Loss: 0.07959919422864914, Final Batch Loss: 0.03261686488986015\n",
      "Epoch 2539, Loss: 0.07832265086472034, Final Batch Loss: 0.05651324614882469\n",
      "Epoch 2540, Loss: 0.06769140437245369, Final Batch Loss: 0.045135725289583206\n",
      "Epoch 2541, Loss: 0.1615481898188591, Final Batch Loss: 0.08817698061466217\n",
      "Epoch 2542, Loss: 0.0599925871938467, Final Batch Loss: 0.032476067543029785\n",
      "Epoch 2543, Loss: 0.045691268518567085, Final Batch Loss: 0.010992048308253288\n",
      "Epoch 2544, Loss: 0.046559966169297695, Final Batch Loss: 0.013675651513040066\n",
      "Epoch 2545, Loss: 0.0694761723279953, Final Batch Loss: 0.020333804190158844\n",
      "Epoch 2546, Loss: 0.06616294011473656, Final Batch Loss: 0.025514621287584305\n",
      "Epoch 2547, Loss: 0.03374519571661949, Final Batch Loss: 0.02042088471353054\n",
      "Epoch 2548, Loss: 0.08735727146267891, Final Batch Loss: 0.06351268291473389\n",
      "Epoch 2549, Loss: 0.07599258609116077, Final Batch Loss: 0.05766163021326065\n",
      "Epoch 2550, Loss: 0.06246402859687805, Final Batch Loss: 0.04744734987616539\n",
      "Epoch 2551, Loss: 0.04402430169284344, Final Batch Loss: 0.009199762716889381\n",
      "Epoch 2552, Loss: 0.044052230194211006, Final Batch Loss: 0.0232277549803257\n",
      "Epoch 2553, Loss: 0.06024622172117233, Final Batch Loss: 0.030330905690789223\n",
      "Epoch 2554, Loss: 0.12182079628109932, Final Batch Loss: 0.0814826488494873\n",
      "Epoch 2555, Loss: 0.09555050730705261, Final Batch Loss: 0.07254566252231598\n",
      "Epoch 2556, Loss: 0.039569128304719925, Final Batch Loss: 0.02017483487725258\n",
      "Epoch 2557, Loss: 0.12058464623987675, Final Batch Loss: 0.0940689668059349\n",
      "Epoch 2558, Loss: 0.06544248573482037, Final Batch Loss: 0.056008581072092056\n",
      "Epoch 2559, Loss: 0.17792239785194397, Final Batch Loss: 0.09256177395582199\n",
      "Epoch 2560, Loss: 0.06312514282763004, Final Batch Loss: 0.03189004957675934\n",
      "Epoch 2561, Loss: 0.051143230870366096, Final Batch Loss: 0.02963503636419773\n",
      "Epoch 2562, Loss: 0.07488656789064407, Final Batch Loss: 0.021077938377857208\n",
      "Epoch 2563, Loss: 0.05433906614780426, Final Batch Loss: 0.03023190051317215\n",
      "Epoch 2564, Loss: 0.07917044684290886, Final Batch Loss: 0.01570746675133705\n",
      "Epoch 2565, Loss: 0.05957583524286747, Final Batch Loss: 0.021712666377425194\n",
      "Epoch 2566, Loss: 0.0763828195631504, Final Batch Loss: 0.05015678331255913\n",
      "Epoch 2567, Loss: 0.08737435191869736, Final Batch Loss: 0.050599418580532074\n",
      "Epoch 2568, Loss: 0.09272373840212822, Final Batch Loss: 0.05463686212897301\n",
      "Epoch 2569, Loss: 0.07175786048173904, Final Batch Loss: 0.05224544554948807\n",
      "Epoch 2570, Loss: 0.05979880131781101, Final Batch Loss: 0.02676149643957615\n",
      "Epoch 2571, Loss: 0.14516399800777435, Final Batch Loss: 0.0450216606259346\n",
      "Epoch 2572, Loss: 0.11685500293970108, Final Batch Loss: 0.09143581986427307\n",
      "Epoch 2573, Loss: 0.1293810959905386, Final Batch Loss: 0.10648033022880554\n",
      "Epoch 2574, Loss: 0.11378937028348446, Final Batch Loss: 0.08365382254123688\n",
      "Epoch 2575, Loss: 0.060446249321103096, Final Batch Loss: 0.023181667551398277\n",
      "Epoch 2576, Loss: 0.040135251358151436, Final Batch Loss: 0.013845225796103477\n",
      "Epoch 2577, Loss: 0.10922987759113312, Final Batch Loss: 0.07519019395112991\n",
      "Epoch 2578, Loss: 0.09720112010836601, Final Batch Loss: 0.07878422737121582\n",
      "Epoch 2579, Loss: 0.08536083623766899, Final Batch Loss: 0.027808308601379395\n",
      "Epoch 2580, Loss: 0.054430706426501274, Final Batch Loss: 0.025948746129870415\n",
      "Epoch 2581, Loss: 0.06572218239307404, Final Batch Loss: 0.021028801798820496\n",
      "Epoch 2582, Loss: 0.048672059550881386, Final Batch Loss: 0.02713574469089508\n",
      "Epoch 2583, Loss: 0.11761434748768806, Final Batch Loss: 0.08160223811864853\n",
      "Epoch 2584, Loss: 0.03688118979334831, Final Batch Loss: 0.011595513671636581\n",
      "Epoch 2585, Loss: 0.03565404377877712, Final Batch Loss: 0.011546224355697632\n",
      "Epoch 2586, Loss: 0.06207931973040104, Final Batch Loss: 0.02510976977646351\n",
      "Epoch 2587, Loss: 0.041508535854518414, Final Batch Loss: 0.025970960035920143\n",
      "Epoch 2588, Loss: 0.0740112978965044, Final Batch Loss: 0.047633782029151917\n",
      "Epoch 2589, Loss: 0.07819107547402382, Final Batch Loss: 0.03259127959609032\n",
      "Epoch 2590, Loss: 0.0451482217758894, Final Batch Loss: 0.014684680849313736\n",
      "Epoch 2591, Loss: 0.09370234981179237, Final Batch Loss: 0.06075068190693855\n",
      "Epoch 2592, Loss: 0.039095599204301834, Final Batch Loss: 0.019376294687390327\n",
      "Epoch 2593, Loss: 0.048258399590849876, Final Batch Loss: 0.03136134892702103\n",
      "Epoch 2594, Loss: 0.055172440595924854, Final Batch Loss: 0.010386568494141102\n",
      "Epoch 2595, Loss: 0.05650479719042778, Final Batch Loss: 0.028907690197229385\n",
      "Epoch 2596, Loss: 0.14994646236300468, Final Batch Loss: 0.09597135335206985\n",
      "Epoch 2597, Loss: 0.08219056576490402, Final Batch Loss: 0.03872920200228691\n",
      "Epoch 2598, Loss: 0.05513906851410866, Final Batch Loss: 0.024962900206446648\n",
      "Epoch 2599, Loss: 0.05105612799525261, Final Batch Loss: 0.030800631269812584\n",
      "Epoch 2600, Loss: 0.032124783378094435, Final Batch Loss: 0.0062804254703223705\n",
      "Epoch 2601, Loss: 0.09656466729938984, Final Batch Loss: 0.07498875260353088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2602, Loss: 0.0426939632743597, Final Batch Loss: 0.024575060233473778\n",
      "Epoch 2603, Loss: 0.027995385229587555, Final Batch Loss: 0.006257565692067146\n",
      "Epoch 2604, Loss: 0.0521352868527174, Final Batch Loss: 0.02696795016527176\n",
      "Epoch 2605, Loss: 0.08356005512177944, Final Batch Loss: 0.02488820068538189\n",
      "Epoch 2606, Loss: 0.1095629334449768, Final Batch Loss: 0.020510926842689514\n",
      "Epoch 2607, Loss: 0.13272437453269958, Final Batch Loss: 0.09838628768920898\n",
      "Epoch 2608, Loss: 0.08632368221879005, Final Batch Loss: 0.03802510350942612\n",
      "Epoch 2609, Loss: 0.0754794105887413, Final Batch Loss: 0.03919929265975952\n",
      "Epoch 2610, Loss: 0.032014247961342335, Final Batch Loss: 0.025237170979380608\n",
      "Epoch 2611, Loss: 0.05508217215538025, Final Batch Loss: 0.027735276147723198\n",
      "Epoch 2612, Loss: 0.06918630190193653, Final Batch Loss: 0.03900055214762688\n",
      "Epoch 2613, Loss: 0.08465002570301294, Final Batch Loss: 0.0700371116399765\n",
      "Epoch 2614, Loss: 0.053615487180650234, Final Batch Loss: 0.0073816804215312\n",
      "Epoch 2615, Loss: 0.03675925359129906, Final Batch Loss: 0.015153354033827782\n",
      "Epoch 2616, Loss: 0.07659827545285225, Final Batch Loss: 0.036737583577632904\n",
      "Epoch 2617, Loss: 0.029410756193101406, Final Batch Loss: 0.012647380121052265\n",
      "Epoch 2618, Loss: 0.09265715628862381, Final Batch Loss: 0.05257706344127655\n",
      "Epoch 2619, Loss: 0.10290081426501274, Final Batch Loss: 0.039923686534166336\n",
      "Epoch 2620, Loss: 0.07588541880249977, Final Batch Loss: 0.033471979200839996\n",
      "Epoch 2621, Loss: 0.04391341470181942, Final Batch Loss: 0.02663727104663849\n",
      "Epoch 2622, Loss: 0.05316175892949104, Final Batch Loss: 0.021134663373231888\n",
      "Epoch 2623, Loss: 0.045897296629846096, Final Batch Loss: 0.015024094842374325\n",
      "Epoch 2624, Loss: 0.06574454717338085, Final Batch Loss: 0.02261357568204403\n",
      "Epoch 2625, Loss: 0.059566741809248924, Final Batch Loss: 0.027754822745919228\n",
      "Epoch 2626, Loss: 0.14719251543283463, Final Batch Loss: 0.07664505392313004\n",
      "Epoch 2627, Loss: 0.04088987596333027, Final Batch Loss: 0.012297559529542923\n",
      "Epoch 2628, Loss: 0.04665837623178959, Final Batch Loss: 0.021433871239423752\n",
      "Epoch 2629, Loss: 0.03543321695178747, Final Batch Loss: 0.021066226065158844\n",
      "Epoch 2630, Loss: 0.060016194358468056, Final Batch Loss: 0.025924591347575188\n",
      "Epoch 2631, Loss: 0.09441209211945534, Final Batch Loss: 0.05402746796607971\n",
      "Epoch 2632, Loss: 0.08713521249592304, Final Batch Loss: 0.02602308802306652\n",
      "Epoch 2633, Loss: 0.06270946562290192, Final Batch Loss: 0.039840731769800186\n",
      "Epoch 2634, Loss: 0.10420694202184677, Final Batch Loss: 0.05522659420967102\n",
      "Epoch 2635, Loss: 0.05729842372238636, Final Batch Loss: 0.04027951881289482\n",
      "Epoch 2636, Loss: 0.05451374314725399, Final Batch Loss: 0.028653567656874657\n",
      "Epoch 2637, Loss: 0.05581796169281006, Final Batch Loss: 0.028999673202633858\n",
      "Epoch 2638, Loss: 0.03813921846449375, Final Batch Loss: 0.013258516788482666\n",
      "Epoch 2639, Loss: 0.046677347272634506, Final Batch Loss: 0.02682635746896267\n",
      "Epoch 2640, Loss: 0.0986156240105629, Final Batch Loss: 0.05606468766927719\n",
      "Epoch 2641, Loss: 0.09746575728058815, Final Batch Loss: 0.05403824895620346\n",
      "Epoch 2642, Loss: 0.04771646950393915, Final Batch Loss: 0.014947076328098774\n",
      "Epoch 2643, Loss: 0.2333778403699398, Final Batch Loss: 0.20102278888225555\n",
      "Epoch 2644, Loss: 0.09118569269776344, Final Batch Loss: 0.046203888952732086\n",
      "Epoch 2645, Loss: 0.04827992059290409, Final Batch Loss: 0.020145267248153687\n",
      "Epoch 2646, Loss: 0.142627926543355, Final Batch Loss: 0.11389652639627457\n",
      "Epoch 2647, Loss: 0.03904745262116194, Final Batch Loss: 0.011848817579448223\n",
      "Epoch 2648, Loss: 0.05974805913865566, Final Batch Loss: 0.010767621919512749\n",
      "Epoch 2649, Loss: 0.13749157264828682, Final Batch Loss: 0.057966675609350204\n",
      "Epoch 2650, Loss: 0.1026487946510315, Final Batch Loss: 0.05784372240304947\n",
      "Epoch 2651, Loss: 0.05559947155416012, Final Batch Loss: 0.009753236547112465\n",
      "Epoch 2652, Loss: 0.08237018436193466, Final Batch Loss: 0.05044998973608017\n",
      "Epoch 2653, Loss: 0.0608416385948658, Final Batch Loss: 0.023408666253089905\n",
      "Epoch 2654, Loss: 0.04603500850498676, Final Batch Loss: 0.024556845426559448\n",
      "Epoch 2655, Loss: 0.0908118449151516, Final Batch Loss: 0.03798628970980644\n",
      "Epoch 2656, Loss: 0.0731469877064228, Final Batch Loss: 0.03416861966252327\n",
      "Epoch 2657, Loss: 0.04604187607765198, Final Batch Loss: 0.01925348863005638\n",
      "Epoch 2658, Loss: 0.06664870865643024, Final Batch Loss: 0.04267384484410286\n",
      "Epoch 2659, Loss: 0.07134430669248104, Final Batch Loss: 0.041792646050453186\n",
      "Epoch 2660, Loss: 0.07523285783827305, Final Batch Loss: 0.025942230597138405\n",
      "Epoch 2661, Loss: 0.08284109830856323, Final Batch Loss: 0.05065576359629631\n",
      "Epoch 2662, Loss: 0.0933400671929121, Final Batch Loss: 0.02113923244178295\n",
      "Epoch 2663, Loss: 0.11953825131058693, Final Batch Loss: 0.07358832657337189\n",
      "Epoch 2664, Loss: 0.14571456611156464, Final Batch Loss: 0.03681010752916336\n",
      "Epoch 2665, Loss: 0.0522361621260643, Final Batch Loss: 0.02304731123149395\n",
      "Epoch 2666, Loss: 0.10733906179666519, Final Batch Loss: 0.04300674796104431\n",
      "Epoch 2667, Loss: 0.036741044372320175, Final Batch Loss: 0.0161073449999094\n",
      "Epoch 2668, Loss: 0.080298887565732, Final Batch Loss: 0.013922551646828651\n",
      "Epoch 2669, Loss: 0.11833510920405388, Final Batch Loss: 0.1016407385468483\n",
      "Epoch 2670, Loss: 0.050176115706562996, Final Batch Loss: 0.01855013333261013\n",
      "Epoch 2671, Loss: 0.05644702911376953, Final Batch Loss: 0.0206013061106205\n",
      "Epoch 2672, Loss: 0.0268259821459651, Final Batch Loss: 0.013029652647674084\n",
      "Epoch 2673, Loss: 0.06550519540905952, Final Batch Loss: 0.040067825466394424\n",
      "Epoch 2674, Loss: 0.06615494750440121, Final Batch Loss: 0.027972115203738213\n",
      "Epoch 2675, Loss: 0.07328255474567413, Final Batch Loss: 0.039263706654310226\n",
      "Epoch 2676, Loss: 0.05308725871145725, Final Batch Loss: 0.030064834281802177\n",
      "Epoch 2677, Loss: 0.13126308470964432, Final Batch Loss: 0.03557324409484863\n",
      "Epoch 2678, Loss: 0.03659912012517452, Final Batch Loss: 0.006475025787949562\n",
      "Epoch 2679, Loss: 0.06832014862447977, Final Batch Loss: 0.05493362993001938\n",
      "Epoch 2680, Loss: 0.05848773568868637, Final Batch Loss: 0.013383977115154266\n",
      "Epoch 2681, Loss: 0.07210378535091877, Final Batch Loss: 0.046416640281677246\n",
      "Epoch 2682, Loss: 0.09241591766476631, Final Batch Loss: 0.04526591673493385\n",
      "Epoch 2683, Loss: 0.049788232892751694, Final Batch Loss: 0.022623371332883835\n",
      "Epoch 2684, Loss: 0.09368089213967323, Final Batch Loss: 0.04950748756527901\n",
      "Epoch 2685, Loss: 0.039969571866095066, Final Batch Loss: 0.030341824516654015\n",
      "Epoch 2686, Loss: 0.08714701980352402, Final Batch Loss: 0.052185166627168655\n",
      "Epoch 2687, Loss: 0.03875676169991493, Final Batch Loss: 0.01646331697702408\n",
      "Epoch 2688, Loss: 0.08680274151265621, Final Batch Loss: 0.06766415387392044\n",
      "Epoch 2689, Loss: 0.08089714497327805, Final Batch Loss: 0.04282540827989578\n",
      "Epoch 2690, Loss: 0.07027389481663704, Final Batch Loss: 0.01608533039689064\n",
      "Epoch 2691, Loss: 0.13246089965105057, Final Batch Loss: 0.03830737620592117\n",
      "Epoch 2692, Loss: 0.08455641660839319, Final Batch Loss: 0.012355470098555088\n",
      "Epoch 2693, Loss: 0.05849752202630043, Final Batch Loss: 0.026787780225276947\n",
      "Epoch 2694, Loss: 0.04751206189393997, Final Batch Loss: 0.024244040250778198\n",
      "Epoch 2695, Loss: 0.0806187316775322, Final Batch Loss: 0.05842866748571396\n",
      "Epoch 2696, Loss: 0.04078100807964802, Final Batch Loss: 0.018148571252822876\n",
      "Epoch 2697, Loss: 0.04826280660927296, Final Batch Loss: 0.03237660974264145\n",
      "Epoch 2698, Loss: 0.11408738233149052, Final Batch Loss: 0.09514176100492477\n",
      "Epoch 2699, Loss: 0.06847165152430534, Final Batch Loss: 0.03955084830522537\n",
      "Epoch 2700, Loss: 0.07485981937497854, Final Batch Loss: 0.010570011101663113\n",
      "Epoch 2701, Loss: 0.09753512963652611, Final Batch Loss: 0.04909931868314743\n",
      "Epoch 2702, Loss: 0.044317107647657394, Final Batch Loss: 0.02660316601395607\n",
      "Epoch 2703, Loss: 0.057605328038334846, Final Batch Loss: 0.017597047612071037\n",
      "Epoch 2704, Loss: 0.13345365785062313, Final Batch Loss: 0.10695268213748932\n",
      "Epoch 2705, Loss: 0.06888954900205135, Final Batch Loss: 0.04510651156306267\n",
      "Epoch 2706, Loss: 0.05293053388595581, Final Batch Loss: 0.03181185945868492\n",
      "Epoch 2707, Loss: 0.08707304485142231, Final Batch Loss: 0.0208576712757349\n",
      "Epoch 2708, Loss: 0.11316799744963646, Final Batch Loss: 0.04147722199559212\n",
      "Epoch 2709, Loss: 0.06127823330461979, Final Batch Loss: 0.043273940682411194\n",
      "Epoch 2710, Loss: 0.11152320355176926, Final Batch Loss: 0.0554133839905262\n",
      "Epoch 2711, Loss: 0.07019543088972569, Final Batch Loss: 0.05080088600516319\n",
      "Epoch 2712, Loss: 0.07210608571767807, Final Batch Loss: 0.025731515139341354\n",
      "Epoch 2713, Loss: 0.08764977008104324, Final Batch Loss: 0.037977252155542374\n",
      "Epoch 2714, Loss: 0.04094564542174339, Final Batch Loss: 0.020598001778125763\n",
      "Epoch 2715, Loss: 0.07226387597620487, Final Batch Loss: 0.017362257465720177\n",
      "Epoch 2716, Loss: 0.1621418297290802, Final Batch Loss: 0.12492407858371735\n",
      "Epoch 2717, Loss: 0.04728412441909313, Final Batch Loss: 0.023191915825009346\n",
      "Epoch 2718, Loss: 0.08611443173140287, Final Batch Loss: 0.07163744419813156\n",
      "Epoch 2719, Loss: 0.04634164460003376, Final Batch Loss: 0.01633807085454464\n",
      "Epoch 2720, Loss: 0.10485811159014702, Final Batch Loss: 0.0570407435297966\n",
      "Epoch 2721, Loss: 0.061367060989141464, Final Batch Loss: 0.03481843322515488\n",
      "Epoch 2722, Loss: 0.12570233643054962, Final Batch Loss: 0.09483595192432404\n",
      "Epoch 2723, Loss: 0.0493205264210701, Final Batch Loss: 0.02991344965994358\n",
      "Epoch 2724, Loss: 0.11072731204330921, Final Batch Loss: 0.09315498918294907\n",
      "Epoch 2725, Loss: 0.09796366281807423, Final Batch Loss: 0.07049339264631271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2726, Loss: 0.0728955902159214, Final Batch Loss: 0.02478373423218727\n",
      "Epoch 2727, Loss: 0.08054875023663044, Final Batch Loss: 0.028536604717373848\n",
      "Epoch 2728, Loss: 0.12207341566681862, Final Batch Loss: 0.10142236202955246\n",
      "Epoch 2729, Loss: 0.05498548597097397, Final Batch Loss: 0.02931157685816288\n",
      "Epoch 2730, Loss: 0.08899056352674961, Final Batch Loss: 0.07237305492162704\n",
      "Epoch 2731, Loss: 0.0365810738876462, Final Batch Loss: 0.024778537452220917\n",
      "Epoch 2732, Loss: 0.10784376598894596, Final Batch Loss: 0.0780923068523407\n",
      "Epoch 2733, Loss: 0.039476461708545685, Final Batch Loss: 0.00935039110481739\n",
      "Epoch 2734, Loss: 0.048263952136039734, Final Batch Loss: 0.025038808584213257\n",
      "Epoch 2735, Loss: 0.1453421264886856, Final Batch Loss: 0.11075544357299805\n",
      "Epoch 2736, Loss: 0.08628390915691853, Final Batch Loss: 0.0616101436316967\n",
      "Epoch 2737, Loss: 0.044129339046776295, Final Batch Loss: 0.01154122594743967\n",
      "Epoch 2738, Loss: 0.043029408901929855, Final Batch Loss: 0.0238984115421772\n",
      "Epoch 2739, Loss: 0.0893316064029932, Final Batch Loss: 0.016724208369851112\n",
      "Epoch 2740, Loss: 0.029135641641914845, Final Batch Loss: 0.010224987752735615\n",
      "Epoch 2741, Loss: 0.0901586301624775, Final Batch Loss: 0.018021877855062485\n",
      "Epoch 2742, Loss: 0.08434387855231762, Final Batch Loss: 0.07212075591087341\n",
      "Epoch 2743, Loss: 0.08270364627242088, Final Batch Loss: 0.03387182950973511\n",
      "Epoch 2744, Loss: 0.06347424536943436, Final Batch Loss: 0.022079143673181534\n",
      "Epoch 2745, Loss: 0.1357304584234953, Final Batch Loss: 0.107769675552845\n",
      "Epoch 2746, Loss: 0.07022724859416485, Final Batch Loss: 0.040232546627521515\n",
      "Epoch 2747, Loss: 0.08230494149029255, Final Batch Loss: 0.029821792617440224\n",
      "Epoch 2748, Loss: 0.04826003685593605, Final Batch Loss: 0.031672731041908264\n",
      "Epoch 2749, Loss: 0.05203438922762871, Final Batch Loss: 0.019008710980415344\n",
      "Epoch 2750, Loss: 0.057845909148454666, Final Batch Loss: 0.02358078584074974\n",
      "Epoch 2751, Loss: 0.05367801710963249, Final Batch Loss: 0.026469239965081215\n",
      "Epoch 2752, Loss: 0.08217721991240978, Final Batch Loss: 0.05503539368510246\n",
      "Epoch 2753, Loss: 0.029887832701206207, Final Batch Loss: 0.017466871067881584\n",
      "Epoch 2754, Loss: 0.06965042091906071, Final Batch Loss: 0.04957957565784454\n",
      "Epoch 2755, Loss: 0.1151597648859024, Final Batch Loss: 0.08387816697359085\n",
      "Epoch 2756, Loss: 0.05162138119339943, Final Batch Loss: 0.023555999621748924\n",
      "Epoch 2757, Loss: 0.10395688936114311, Final Batch Loss: 0.08367230743169785\n",
      "Epoch 2758, Loss: 0.07461847364902496, Final Batch Loss: 0.029404111206531525\n",
      "Epoch 2759, Loss: 0.023439261596649885, Final Batch Loss: 0.005485014524310827\n",
      "Epoch 2760, Loss: 0.1283334270119667, Final Batch Loss: 0.08930540084838867\n",
      "Epoch 2761, Loss: 0.06988253630697727, Final Batch Loss: 0.013176912441849709\n",
      "Epoch 2762, Loss: 0.04114275425672531, Final Batch Loss: 0.013335984200239182\n",
      "Epoch 2763, Loss: 0.05030811857432127, Final Batch Loss: 0.013752809725701809\n",
      "Epoch 2764, Loss: 0.04853866435587406, Final Batch Loss: 0.027390344068408012\n",
      "Epoch 2765, Loss: 0.08176903426647186, Final Batch Loss: 0.06703416258096695\n",
      "Epoch 2766, Loss: 0.11213459074497223, Final Batch Loss: 0.05682806298136711\n",
      "Epoch 2767, Loss: 0.11399944126605988, Final Batch Loss: 0.02426895499229431\n",
      "Epoch 2768, Loss: 0.1471044160425663, Final Batch Loss: 0.09993698447942734\n",
      "Epoch 2769, Loss: 0.06824464723467827, Final Batch Loss: 0.04137353226542473\n",
      "Epoch 2770, Loss: 0.08502240851521492, Final Batch Loss: 0.0314786322414875\n",
      "Epoch 2771, Loss: 0.04682605527341366, Final Batch Loss: 0.011526821181178093\n",
      "Epoch 2772, Loss: 0.0766060184687376, Final Batch Loss: 0.030088039115071297\n",
      "Epoch 2773, Loss: 0.05415862984955311, Final Batch Loss: 0.01471761055290699\n",
      "Epoch 2774, Loss: 0.06562956981360912, Final Batch Loss: 0.01954217441380024\n",
      "Epoch 2775, Loss: 0.10713819414377213, Final Batch Loss: 0.04901282116770744\n",
      "Epoch 2776, Loss: 0.12929508090019226, Final Batch Loss: 0.10336749255657196\n",
      "Epoch 2777, Loss: 0.03948471788316965, Final Batch Loss: 0.007917397655546665\n",
      "Epoch 2778, Loss: 0.11026908829808235, Final Batch Loss: 0.0706365630030632\n",
      "Epoch 2779, Loss: 0.05799447186291218, Final Batch Loss: 0.019952556118369102\n",
      "Epoch 2780, Loss: 0.056505920365452766, Final Batch Loss: 0.011752331629395485\n",
      "Epoch 2781, Loss: 0.08855817466974258, Final Batch Loss: 0.033195387572050095\n",
      "Epoch 2782, Loss: 0.03966676443815231, Final Batch Loss: 0.01732051372528076\n",
      "Epoch 2783, Loss: 0.08204853162169456, Final Batch Loss: 0.05752652883529663\n",
      "Epoch 2784, Loss: 0.10452695563435555, Final Batch Loss: 0.04414999857544899\n",
      "Epoch 2785, Loss: 0.08726086653769016, Final Batch Loss: 0.02456633932888508\n",
      "Epoch 2786, Loss: 0.05393552780151367, Final Batch Loss: 0.03401738032698631\n",
      "Epoch 2787, Loss: 0.07448361814022064, Final Batch Loss: 0.03253718465566635\n",
      "Epoch 2788, Loss: 0.07591392286121845, Final Batch Loss: 0.02921108342707157\n",
      "Epoch 2789, Loss: 0.24770472012460232, Final Batch Loss: 0.23036323487758636\n",
      "Epoch 2790, Loss: 0.04510417673736811, Final Batch Loss: 0.011299089528620243\n",
      "Epoch 2791, Loss: 0.12927634082734585, Final Batch Loss: 0.10971669107675552\n",
      "Epoch 2792, Loss: 0.05491423234343529, Final Batch Loss: 0.02132708579301834\n",
      "Epoch 2793, Loss: 0.17615605890750885, Final Batch Loss: 0.1266389638185501\n",
      "Epoch 2794, Loss: 0.05778023786842823, Final Batch Loss: 0.01813771016895771\n",
      "Epoch 2795, Loss: 0.05388922244310379, Final Batch Loss: 0.02945411019027233\n",
      "Epoch 2796, Loss: 0.05909496918320656, Final Batch Loss: 0.03215198963880539\n",
      "Epoch 2797, Loss: 0.04039986710995436, Final Batch Loss: 0.028244484215974808\n",
      "Epoch 2798, Loss: 0.09333543479442596, Final Batch Loss: 0.07089094817638397\n",
      "Epoch 2799, Loss: 0.06290050782263279, Final Batch Loss: 0.034590039402246475\n",
      "Epoch 2800, Loss: 0.04646811634302139, Final Batch Loss: 0.027899574488401413\n",
      "Epoch 2801, Loss: 0.0649636909365654, Final Batch Loss: 0.045244522392749786\n",
      "Epoch 2802, Loss: 0.06875807791948318, Final Batch Loss: 0.04504679515957832\n",
      "Epoch 2803, Loss: 0.06423443928360939, Final Batch Loss: 0.04427693784236908\n",
      "Epoch 2804, Loss: 0.09902753494679928, Final Batch Loss: 0.06780604273080826\n",
      "Epoch 2805, Loss: 0.06026050075888634, Final Batch Loss: 0.025119926780462265\n",
      "Epoch 2806, Loss: 0.0628356896340847, Final Batch Loss: 0.026112020015716553\n",
      "Epoch 2807, Loss: 0.11282213404774666, Final Batch Loss: 0.07567304372787476\n",
      "Epoch 2808, Loss: 0.04681941960006952, Final Batch Loss: 0.03679249435663223\n",
      "Epoch 2809, Loss: 0.0764270219951868, Final Batch Loss: 0.027551865205168724\n",
      "Epoch 2810, Loss: 0.035036162473261356, Final Batch Loss: 0.013150147162377834\n",
      "Epoch 2811, Loss: 0.04974093288183212, Final Batch Loss: 0.0309318657964468\n",
      "Epoch 2812, Loss: 0.04314992018043995, Final Batch Loss: 0.02506413124501705\n",
      "Epoch 2813, Loss: 0.030279471073299646, Final Batch Loss: 0.007412270177155733\n",
      "Epoch 2814, Loss: 0.07972064428031445, Final Batch Loss: 0.056494228541851044\n",
      "Epoch 2815, Loss: 0.08910688385367393, Final Batch Loss: 0.0390169657766819\n",
      "Epoch 2816, Loss: 0.08502147346735, Final Batch Loss: 0.03380676731467247\n",
      "Epoch 2817, Loss: 0.0292655685916543, Final Batch Loss: 0.010810759849846363\n",
      "Epoch 2818, Loss: 0.03922767052426934, Final Batch Loss: 0.0316397063434124\n",
      "Epoch 2819, Loss: 0.09443139657378197, Final Batch Loss: 0.0741204097867012\n",
      "Epoch 2820, Loss: 0.0334506849758327, Final Batch Loss: 0.00772078288719058\n",
      "Epoch 2821, Loss: 0.06606028974056244, Final Batch Loss: 0.03267702832818031\n",
      "Epoch 2822, Loss: 0.047980012372136116, Final Batch Loss: 0.030204681679606438\n",
      "Epoch 2823, Loss: 0.07245156913995743, Final Batch Loss: 0.03294086828827858\n",
      "Epoch 2824, Loss: 0.10664109513163567, Final Batch Loss: 0.052979785948991776\n",
      "Epoch 2825, Loss: 0.04789973981678486, Final Batch Loss: 0.018375156447291374\n",
      "Epoch 2826, Loss: 0.06295248866081238, Final Batch Loss: 0.034524548798799515\n",
      "Epoch 2827, Loss: 0.0842049652710557, Final Batch Loss: 0.07170295715332031\n",
      "Epoch 2828, Loss: 0.030083712190389633, Final Batch Loss: 0.015330204740166664\n",
      "Epoch 2829, Loss: 0.06025233678519726, Final Batch Loss: 0.025951514020562172\n",
      "Epoch 2830, Loss: 0.09819339402019978, Final Batch Loss: 0.06717564165592194\n",
      "Epoch 2831, Loss: 0.06788270175457001, Final Batch Loss: 0.010490331798791885\n",
      "Epoch 2832, Loss: 0.07125068455934525, Final Batch Loss: 0.026959940791130066\n",
      "Epoch 2833, Loss: 0.06946917437016964, Final Batch Loss: 0.05253563076257706\n",
      "Epoch 2834, Loss: 0.08471998199820518, Final Batch Loss: 0.04067540168762207\n",
      "Epoch 2835, Loss: 0.06043666787445545, Final Batch Loss: 0.041183099150657654\n",
      "Epoch 2836, Loss: 0.07183403708040714, Final Batch Loss: 0.05485168471932411\n",
      "Epoch 2837, Loss: 0.09536314569413662, Final Batch Loss: 0.018786637112498283\n",
      "Epoch 2838, Loss: 0.05517485737800598, Final Batch Loss: 0.02816431224346161\n",
      "Epoch 2839, Loss: 0.030752883292734623, Final Batch Loss: 0.0069108931347727776\n",
      "Epoch 2840, Loss: 0.07049793750047684, Final Batch Loss: 0.0353374145925045\n",
      "Epoch 2841, Loss: 0.10841378569602966, Final Batch Loss: 0.03925862908363342\n",
      "Epoch 2842, Loss: 0.027772679924964905, Final Batch Loss: 0.013907059095799923\n",
      "Epoch 2843, Loss: 0.02910144440829754, Final Batch Loss: 0.019163085147738457\n",
      "Epoch 2844, Loss: 0.06544994190335274, Final Batch Loss: 0.03106483444571495\n",
      "Epoch 2845, Loss: 0.07289022393524647, Final Batch Loss: 0.04523801431059837\n",
      "Epoch 2846, Loss: 0.09607941657304764, Final Batch Loss: 0.019884169101715088\n",
      "Epoch 2847, Loss: 0.031474847346544266, Final Batch Loss: 0.008353639394044876\n",
      "Epoch 2848, Loss: 0.09380616992712021, Final Batch Loss: 0.050664715468883514\n",
      "Epoch 2849, Loss: 0.03652668697759509, Final Batch Loss: 0.006974851246923208\n",
      "Epoch 2850, Loss: 0.021773170679807663, Final Batch Loss: 0.01046780776232481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2851, Loss: 0.10446812212467194, Final Batch Loss: 0.06705065071582794\n",
      "Epoch 2852, Loss: 0.08081484958529472, Final Batch Loss: 0.042989227920770645\n",
      "Epoch 2853, Loss: 0.027027799282222986, Final Batch Loss: 0.005620001349598169\n",
      "Epoch 2854, Loss: 0.10896889865398407, Final Batch Loss: 0.06797171384096146\n",
      "Epoch 2855, Loss: 0.04478169605135918, Final Batch Loss: 0.027646828442811966\n",
      "Epoch 2856, Loss: 0.07277082093060017, Final Batch Loss: 0.019573649391531944\n",
      "Epoch 2857, Loss: 0.0633121095597744, Final Batch Loss: 0.033373478800058365\n",
      "Epoch 2858, Loss: 0.04764640890061855, Final Batch Loss: 0.03105812706053257\n",
      "Epoch 2859, Loss: 0.08318668603897095, Final Batch Loss: 0.06361962109804153\n",
      "Epoch 2860, Loss: 0.09040175378322601, Final Batch Loss: 0.03503113612532616\n",
      "Epoch 2861, Loss: 0.05557095631957054, Final Batch Loss: 0.024985220283269882\n",
      "Epoch 2862, Loss: 0.06868353113532066, Final Batch Loss: 0.04693816974759102\n",
      "Epoch 2863, Loss: 0.08634964004158974, Final Batch Loss: 0.05973852053284645\n",
      "Epoch 2864, Loss: 0.05629653297364712, Final Batch Loss: 0.01866159401834011\n",
      "Epoch 2865, Loss: 0.12160393968224525, Final Batch Loss: 0.07832561433315277\n",
      "Epoch 2866, Loss: 0.0921972244977951, Final Batch Loss: 0.04064805433154106\n",
      "Epoch 2867, Loss: 0.04172751773148775, Final Batch Loss: 0.01409215573221445\n",
      "Epoch 2868, Loss: 0.05696883238852024, Final Batch Loss: 0.028874654322862625\n",
      "Epoch 2869, Loss: 0.06274791434407234, Final Batch Loss: 0.030918531119823456\n",
      "Epoch 2870, Loss: 0.08562356978654861, Final Batch Loss: 0.040862470865249634\n",
      "Epoch 2871, Loss: 0.1080857366323471, Final Batch Loss: 0.07769589871168137\n",
      "Epoch 2872, Loss: 0.06228177063167095, Final Batch Loss: 0.04585794359445572\n",
      "Epoch 2873, Loss: 0.08091244474053383, Final Batch Loss: 0.03367072716355324\n",
      "Epoch 2874, Loss: 0.04939756914973259, Final Batch Loss: 0.013313129544258118\n",
      "Epoch 2875, Loss: 0.0731662679463625, Final Batch Loss: 0.024189868941903114\n",
      "Epoch 2876, Loss: 0.06568644009530544, Final Batch Loss: 0.02997947670519352\n",
      "Epoch 2877, Loss: 0.031899494118988514, Final Batch Loss: 0.01441162172704935\n",
      "Epoch 2878, Loss: 0.058240512385964394, Final Batch Loss: 0.028061512857675552\n",
      "Epoch 2879, Loss: 0.04107538424432278, Final Batch Loss: 0.02716655656695366\n",
      "Epoch 2880, Loss: 0.07742328569293022, Final Batch Loss: 0.06178829446434975\n",
      "Epoch 2881, Loss: 0.042160430923104286, Final Batch Loss: 0.022455411031842232\n",
      "Epoch 2882, Loss: 0.05270873382687569, Final Batch Loss: 0.029893165454268456\n",
      "Epoch 2883, Loss: 0.04552593640983105, Final Batch Loss: 0.015737013891339302\n",
      "Epoch 2884, Loss: 0.06813334114849567, Final Batch Loss: 0.0224533062428236\n",
      "Epoch 2885, Loss: 0.028196881525218487, Final Batch Loss: 0.011767354793846607\n",
      "Epoch 2886, Loss: 0.09694432467222214, Final Batch Loss: 0.04201759770512581\n",
      "Epoch 2887, Loss: 0.07211393490433693, Final Batch Loss: 0.01592300832271576\n",
      "Epoch 2888, Loss: 0.07958676852285862, Final Batch Loss: 0.022218165919184685\n",
      "Epoch 2889, Loss: 0.051950374618172646, Final Batch Loss: 0.02592000924050808\n",
      "Epoch 2890, Loss: 0.024830687791109085, Final Batch Loss: 0.009642801247537136\n",
      "Epoch 2891, Loss: 0.06911405175924301, Final Batch Loss: 0.030897732824087143\n",
      "Epoch 2892, Loss: 0.046310458332300186, Final Batch Loss: 0.0174441896378994\n",
      "Epoch 2893, Loss: 0.11634786799550056, Final Batch Loss: 0.0610293447971344\n",
      "Epoch 2894, Loss: 0.030597052536904812, Final Batch Loss: 0.013155191205441952\n",
      "Epoch 2895, Loss: 0.04855057969689369, Final Batch Loss: 0.030297795310616493\n",
      "Epoch 2896, Loss: 0.03210579138249159, Final Batch Loss: 0.01441433746367693\n",
      "Epoch 2897, Loss: 0.030762036330997944, Final Batch Loss: 0.011210440658032894\n",
      "Epoch 2898, Loss: 0.0448937751352787, Final Batch Loss: 0.031911496073007584\n",
      "Epoch 2899, Loss: 0.030154348351061344, Final Batch Loss: 0.016702745109796524\n",
      "Epoch 2900, Loss: 0.07073993049561977, Final Batch Loss: 0.02696874924004078\n",
      "Epoch 2901, Loss: 0.05560754053294659, Final Batch Loss: 0.03662949427962303\n",
      "Epoch 2902, Loss: 0.04367896728217602, Final Batch Loss: 0.017711425200104713\n",
      "Epoch 2903, Loss: 0.03277745842933655, Final Batch Loss: 0.009323492646217346\n",
      "Epoch 2904, Loss: 0.027491441927850246, Final Batch Loss: 0.012924768030643463\n",
      "Epoch 2905, Loss: 0.05199481174349785, Final Batch Loss: 0.023438751697540283\n",
      "Epoch 2906, Loss: 0.04831128194928169, Final Batch Loss: 0.01900830678641796\n",
      "Epoch 2907, Loss: 0.04839855246245861, Final Batch Loss: 0.02132369764149189\n",
      "Epoch 2908, Loss: 0.055621543899178505, Final Batch Loss: 0.022352231666445732\n",
      "Epoch 2909, Loss: 0.06385894864797592, Final Batch Loss: 0.037598613649606705\n",
      "Epoch 2910, Loss: 0.06533263716846704, Final Batch Loss: 0.05451880395412445\n",
      "Epoch 2911, Loss: 0.04659022390842438, Final Batch Loss: 0.018143117427825928\n",
      "Epoch 2912, Loss: 0.09381428360939026, Final Batch Loss: 0.03032185137271881\n",
      "Epoch 2913, Loss: 0.05196315422654152, Final Batch Loss: 0.017701461911201477\n",
      "Epoch 2914, Loss: 0.04005634970963001, Final Batch Loss: 0.01115058921277523\n",
      "Epoch 2915, Loss: 0.042887408286333084, Final Batch Loss: 0.023923786357045174\n",
      "Epoch 2916, Loss: 0.08115670830011368, Final Batch Loss: 0.011549890041351318\n",
      "Epoch 2917, Loss: 0.0739976167678833, Final Batch Loss: 0.044230733066797256\n",
      "Epoch 2918, Loss: 0.06571329943835735, Final Batch Loss: 0.03563544154167175\n",
      "Epoch 2919, Loss: 0.027576296590268612, Final Batch Loss: 0.011322316713631153\n",
      "Epoch 2920, Loss: 0.06373946741223335, Final Batch Loss: 0.04333241283893585\n",
      "Epoch 2921, Loss: 0.11127904430031776, Final Batch Loss: 0.05483103543519974\n",
      "Epoch 2922, Loss: 0.04876463860273361, Final Batch Loss: 0.02347947470843792\n",
      "Epoch 2923, Loss: 0.038558817468583584, Final Batch Loss: 0.010674762539565563\n",
      "Epoch 2924, Loss: 0.044681554194539785, Final Batch Loss: 0.006681015249341726\n",
      "Epoch 2925, Loss: 0.04217306710779667, Final Batch Loss: 0.02292972430586815\n",
      "Epoch 2926, Loss: 0.08558281697332859, Final Batch Loss: 0.06332411617040634\n",
      "Epoch 2927, Loss: 0.037574402987957, Final Batch Loss: 0.019373159855604172\n",
      "Epoch 2928, Loss: 0.04908224940299988, Final Batch Loss: 0.012205671519041061\n",
      "Epoch 2929, Loss: 0.119334040209651, Final Batch Loss: 0.02105819247663021\n",
      "Epoch 2930, Loss: 0.08896378753706813, Final Batch Loss: 0.08210502564907074\n",
      "Epoch 2931, Loss: 0.03455496672540903, Final Batch Loss: 0.014302165247499943\n",
      "Epoch 2932, Loss: 0.08635861426591873, Final Batch Loss: 0.05581503361463547\n",
      "Epoch 2933, Loss: 0.03971858322620392, Final Batch Loss: 0.03074759803712368\n",
      "Epoch 2934, Loss: 0.04796610213816166, Final Batch Loss: 0.012630986049771309\n",
      "Epoch 2935, Loss: 0.059025706723332405, Final Batch Loss: 0.026943368837237358\n",
      "Epoch 2936, Loss: 0.0712176039814949, Final Batch Loss: 0.0511569082736969\n",
      "Epoch 2937, Loss: 0.10683083906769753, Final Batch Loss: 0.035354066640138626\n",
      "Epoch 2938, Loss: 0.04639539308845997, Final Batch Loss: 0.019617624580860138\n",
      "Epoch 2939, Loss: 0.030012759380042553, Final Batch Loss: 0.01578347384929657\n",
      "Epoch 2940, Loss: 0.06457403488457203, Final Batch Loss: 0.020566092804074287\n",
      "Epoch 2941, Loss: 0.037829564884305, Final Batch Loss: 0.029234690591692924\n",
      "Epoch 2942, Loss: 0.08838551491498947, Final Batch Loss: 0.018366143107414246\n",
      "Epoch 2943, Loss: 0.0642574317753315, Final Batch Loss: 0.03164929896593094\n",
      "Epoch 2944, Loss: 0.07971292175352573, Final Batch Loss: 0.017746465280652046\n",
      "Epoch 2945, Loss: 0.03985871747136116, Final Batch Loss: 0.018338743597269058\n",
      "Epoch 2946, Loss: 0.046059162355959415, Final Batch Loss: 0.010191881097853184\n",
      "Epoch 2947, Loss: 0.03047801461070776, Final Batch Loss: 0.019069505855441093\n",
      "Epoch 2948, Loss: 0.05933655984699726, Final Batch Loss: 0.04624277725815773\n",
      "Epoch 2949, Loss: 0.03470343444496393, Final Batch Loss: 0.013542036525905132\n",
      "Epoch 2950, Loss: 0.050555046647787094, Final Batch Loss: 0.031132234260439873\n",
      "Epoch 2951, Loss: 0.032338179647922516, Final Batch Loss: 0.004968972876667976\n",
      "Epoch 2952, Loss: 0.043401606380939484, Final Batch Loss: 0.008370298892259598\n",
      "Epoch 2953, Loss: 0.0701514445245266, Final Batch Loss: 0.05629881098866463\n",
      "Epoch 2954, Loss: 0.040553159080445766, Final Batch Loss: 0.035108912736177444\n",
      "Epoch 2955, Loss: 0.025720766745507717, Final Batch Loss: 0.014237218536436558\n",
      "Epoch 2956, Loss: 0.07140414044260979, Final Batch Loss: 0.034462183713912964\n",
      "Epoch 2957, Loss: 0.07002162374556065, Final Batch Loss: 0.024249156937003136\n",
      "Epoch 2958, Loss: 0.08883316814899445, Final Batch Loss: 0.06406548619270325\n",
      "Epoch 2959, Loss: 0.05536484159529209, Final Batch Loss: 0.0388038195669651\n",
      "Epoch 2960, Loss: 0.06621824018657207, Final Batch Loss: 0.018452582880854607\n",
      "Epoch 2961, Loss: 0.021439680829644203, Final Batch Loss: 0.007509829476475716\n",
      "Epoch 2962, Loss: 0.06209181062877178, Final Batch Loss: 0.03074408881366253\n",
      "Epoch 2963, Loss: 0.05761818401515484, Final Batch Loss: 0.051354460418224335\n",
      "Epoch 2964, Loss: 0.05345756188035011, Final Batch Loss: 0.03325284272432327\n",
      "Epoch 2965, Loss: 0.03664787579327822, Final Batch Loss: 0.025145569816231728\n",
      "Epoch 2966, Loss: 0.05084325931966305, Final Batch Loss: 0.021405402570962906\n",
      "Epoch 2967, Loss: 0.1466127634048462, Final Batch Loss: 0.10465554893016815\n",
      "Epoch 2968, Loss: 0.07297101616859436, Final Batch Loss: 0.042847491800785065\n",
      "Epoch 2969, Loss: 0.08300582598894835, Final Batch Loss: 0.0068939803168177605\n",
      "Epoch 2970, Loss: 0.019556377548724413, Final Batch Loss: 0.005637672264128923\n",
      "Epoch 2971, Loss: 0.02840934321284294, Final Batch Loss: 0.012849814258515835\n",
      "Epoch 2972, Loss: 0.06867341138422489, Final Batch Loss: 0.024583442136645317\n",
      "Epoch 2973, Loss: 0.062208330258727074, Final Batch Loss: 0.04720107093453407\n",
      "Epoch 2974, Loss: 0.028686683624982834, Final Batch Loss: 0.012614812701940536\n",
      "Epoch 2975, Loss: 0.06178241968154907, Final Batch Loss: 0.044980764389038086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2976, Loss: 0.16288312757387757, Final Batch Loss: 0.00747653329744935\n",
      "Epoch 2977, Loss: 0.06441815011203289, Final Batch Loss: 0.026252998039126396\n",
      "Epoch 2978, Loss: 0.0320559018291533, Final Batch Loss: 0.004477460402995348\n",
      "Epoch 2979, Loss: 0.04739284887909889, Final Batch Loss: 0.01631436124444008\n",
      "Epoch 2980, Loss: 0.037807355634868145, Final Batch Loss: 0.009134494699537754\n",
      "Epoch 2981, Loss: 0.058474207296967506, Final Batch Loss: 0.050545163452625275\n",
      "Epoch 2982, Loss: 0.14729548059403896, Final Batch Loss: 0.11782349646091461\n",
      "Epoch 2983, Loss: 0.1031028963625431, Final Batch Loss: 0.04749881476163864\n",
      "Epoch 2984, Loss: 0.110615074634552, Final Batch Loss: 0.061638329178094864\n",
      "Epoch 2985, Loss: 0.05016050115227699, Final Batch Loss: 0.023938748985528946\n",
      "Epoch 2986, Loss: 0.0936201959848404, Final Batch Loss: 0.07713376730680466\n",
      "Epoch 2987, Loss: 0.07327628694474697, Final Batch Loss: 0.049217771738767624\n",
      "Epoch 2988, Loss: 0.029731707647442818, Final Batch Loss: 0.009942669421434402\n",
      "Epoch 2989, Loss: 0.04319138452410698, Final Batch Loss: 0.018718445673584938\n",
      "Epoch 2990, Loss: 0.056363824754953384, Final Batch Loss: 0.028777945786714554\n",
      "Epoch 2991, Loss: 0.07976148743182421, Final Batch Loss: 0.06726639717817307\n",
      "Epoch 2992, Loss: 0.10685152560472488, Final Batch Loss: 0.023268967866897583\n",
      "Epoch 2993, Loss: 0.02973797358572483, Final Batch Loss: 0.019938157871365547\n",
      "Epoch 2994, Loss: 0.06080893985927105, Final Batch Loss: 0.02734869159758091\n",
      "Epoch 2995, Loss: 0.09274004399776459, Final Batch Loss: 0.0659739300608635\n",
      "Epoch 2996, Loss: 0.040488929487764835, Final Batch Loss: 0.007270247675478458\n",
      "Epoch 2997, Loss: 0.13243409618735313, Final Batch Loss: 0.08846697956323624\n",
      "Epoch 2998, Loss: 0.14936247281730175, Final Batch Loss: 0.12785248458385468\n",
      "Epoch 2999, Loss: 0.09444631449878216, Final Batch Loss: 0.07777491211891174\n",
      "Epoch 3000, Loss: 0.0959607157856226, Final Batch Loss: 0.017921553924679756\n",
      "Epoch 3001, Loss: 0.027753609232604504, Final Batch Loss: 0.014131770469248295\n",
      "Epoch 3002, Loss: 0.0371395368129015, Final Batch Loss: 0.01916588842868805\n",
      "Epoch 3003, Loss: 0.039268686436116695, Final Batch Loss: 0.030954698100686073\n",
      "Epoch 3004, Loss: 0.19157681055366993, Final Batch Loss: 0.16397470235824585\n",
      "Epoch 3005, Loss: 0.03963113948702812, Final Batch Loss: 0.013352785259485245\n",
      "Epoch 3006, Loss: 0.07656510546803474, Final Batch Loss: 0.06379055976867676\n",
      "Epoch 3007, Loss: 0.03302782028913498, Final Batch Loss: 0.022398170083761215\n",
      "Epoch 3008, Loss: 0.06426351796835661, Final Batch Loss: 0.050376757979393005\n",
      "Epoch 3009, Loss: 0.14267129451036453, Final Batch Loss: 0.08930609375238419\n",
      "Epoch 3010, Loss: 0.14269845187664032, Final Batch Loss: 0.06354771554470062\n",
      "Epoch 3011, Loss: 0.12061511166393757, Final Batch Loss: 0.09845330566167831\n",
      "Epoch 3012, Loss: 0.09842875972390175, Final Batch Loss: 0.04968119040131569\n",
      "Epoch 3013, Loss: 0.07636729814112186, Final Batch Loss: 0.029426665976643562\n",
      "Epoch 3014, Loss: 0.09027747809886932, Final Batch Loss: 0.04423515498638153\n",
      "Epoch 3015, Loss: 0.07833540439605713, Final Batch Loss: 0.026284553110599518\n",
      "Epoch 3016, Loss: 0.14158743992447853, Final Batch Loss: 0.11273901164531708\n",
      "Epoch 3017, Loss: 0.08752720430493355, Final Batch Loss: 0.031989071518182755\n",
      "Epoch 3018, Loss: 0.0291145583614707, Final Batch Loss: 0.013298875652253628\n",
      "Epoch 3019, Loss: 0.0568853672593832, Final Batch Loss: 0.01750919781625271\n",
      "Epoch 3020, Loss: 0.05345374718308449, Final Batch Loss: 0.025373976677656174\n",
      "Epoch 3021, Loss: 0.10494831204414368, Final Batch Loss: 0.05536022037267685\n",
      "Epoch 3022, Loss: 0.055686311796307564, Final Batch Loss: 0.02756919525563717\n",
      "Epoch 3023, Loss: 0.042365094646811485, Final Batch Loss: 0.021140912547707558\n",
      "Epoch 3024, Loss: 0.07962747104465961, Final Batch Loss: 0.05594552308320999\n",
      "Epoch 3025, Loss: 0.13082750141620636, Final Batch Loss: 0.10616377741098404\n",
      "Epoch 3026, Loss: 0.0366280572488904, Final Batch Loss: 0.021580826491117477\n",
      "Epoch 3027, Loss: 0.03774480149149895, Final Batch Loss: 0.02551853470504284\n",
      "Epoch 3028, Loss: 0.03920224588364363, Final Batch Loss: 0.010427174158394337\n",
      "Epoch 3029, Loss: 0.10247933864593506, Final Batch Loss: 0.0644649788737297\n",
      "Epoch 3030, Loss: 0.05879554897546768, Final Batch Loss: 0.03848671168088913\n",
      "Epoch 3031, Loss: 0.02486727014183998, Final Batch Loss: 0.012888881377875805\n",
      "Epoch 3032, Loss: 0.047243284061551094, Final Batch Loss: 0.028238695114850998\n",
      "Epoch 3033, Loss: 0.10223735123872757, Final Batch Loss: 0.04974965751171112\n",
      "Epoch 3034, Loss: 0.05601584445685148, Final Batch Loss: 0.014074965380132198\n",
      "Epoch 3035, Loss: 0.08757065422832966, Final Batch Loss: 0.020252006128430367\n",
      "Epoch 3036, Loss: 0.05261961184442043, Final Batch Loss: 0.020937656983733177\n",
      "Epoch 3037, Loss: 0.031438909471035004, Final Batch Loss: 0.009291235357522964\n",
      "Epoch 3038, Loss: 0.07770302332937717, Final Batch Loss: 0.04840276762843132\n",
      "Epoch 3039, Loss: 0.06275836937129498, Final Batch Loss: 0.03661416471004486\n",
      "Epoch 3040, Loss: 0.09033465012907982, Final Batch Loss: 0.04038262739777565\n",
      "Epoch 3041, Loss: 0.04520486015826464, Final Batch Loss: 0.015291920863091946\n",
      "Epoch 3042, Loss: 0.02711543533951044, Final Batch Loss: 0.01790645159780979\n",
      "Epoch 3043, Loss: 0.08692221902310848, Final Batch Loss: 0.06964023411273956\n",
      "Epoch 3044, Loss: 0.10504536144435406, Final Batch Loss: 0.08627587556838989\n",
      "Epoch 3045, Loss: 0.0834166668355465, Final Batch Loss: 0.03869287297129631\n",
      "Epoch 3046, Loss: 0.06474637240171432, Final Batch Loss: 0.02443009614944458\n",
      "Epoch 3047, Loss: 0.06688623130321503, Final Batch Loss: 0.017906561493873596\n",
      "Epoch 3048, Loss: 0.05628778040409088, Final Batch Loss: 0.03888789936900139\n",
      "Epoch 3049, Loss: 0.03673778288066387, Final Batch Loss: 0.018559101969003677\n",
      "Epoch 3050, Loss: 0.06431571580469608, Final Batch Loss: 0.021433772519230843\n",
      "Epoch 3051, Loss: 0.14073674753308296, Final Batch Loss: 0.02310611680150032\n",
      "Epoch 3052, Loss: 0.02612612396478653, Final Batch Loss: 0.007022377103567123\n",
      "Epoch 3053, Loss: 0.13988598622381687, Final Batch Loss: 0.10985762625932693\n",
      "Epoch 3054, Loss: 0.057468106970191, Final Batch Loss: 0.022103508934378624\n",
      "Epoch 3055, Loss: 0.03744623810052872, Final Batch Loss: 0.011670304462313652\n",
      "Epoch 3056, Loss: 0.05039573460817337, Final Batch Loss: 0.015553954988718033\n",
      "Epoch 3057, Loss: 0.03800092078745365, Final Batch Loss: 0.017969731241464615\n",
      "Epoch 3058, Loss: 0.057910764357075095, Final Batch Loss: 0.0025803723838180304\n",
      "Epoch 3059, Loss: 0.10621478408575058, Final Batch Loss: 0.07519099861383438\n",
      "Epoch 3060, Loss: 0.03345454577356577, Final Batch Loss: 0.010510100983083248\n",
      "Epoch 3061, Loss: 0.06333875097334385, Final Batch Loss: 0.046176742762327194\n",
      "Epoch 3062, Loss: 0.041685761883854866, Final Batch Loss: 0.0221704188734293\n",
      "Epoch 3063, Loss: 0.04956699162721634, Final Batch Loss: 0.014509409666061401\n",
      "Epoch 3064, Loss: 0.07286273501813412, Final Batch Loss: 0.0420147143304348\n",
      "Epoch 3065, Loss: 0.038763416931033134, Final Batch Loss: 0.020282991230487823\n",
      "Epoch 3066, Loss: 0.14092036336660385, Final Batch Loss: 0.03096511960029602\n",
      "Epoch 3067, Loss: 0.19853242486715317, Final Batch Loss: 0.08826039731502533\n",
      "Epoch 3068, Loss: 0.029536987654864788, Final Batch Loss: 0.009876432828605175\n",
      "Epoch 3069, Loss: 0.07869493961334229, Final Batch Loss: 0.025865178555250168\n",
      "Epoch 3070, Loss: 0.1914324164390564, Final Batch Loss: 0.1477975994348526\n",
      "Epoch 3071, Loss: 0.11436201632022858, Final Batch Loss: 0.03860211372375488\n",
      "Epoch 3072, Loss: 0.08013997972011566, Final Batch Loss: 0.04570506885647774\n",
      "Epoch 3073, Loss: 0.027644680812954903, Final Batch Loss: 0.009754380211234093\n",
      "Epoch 3074, Loss: 0.079125065356493, Final Batch Loss: 0.033369455486536026\n",
      "Epoch 3075, Loss: 0.12067031674087048, Final Batch Loss: 0.09516162425279617\n",
      "Epoch 3076, Loss: 0.07475083973258734, Final Batch Loss: 0.014214570634067059\n",
      "Epoch 3077, Loss: 0.12641092762351036, Final Batch Loss: 0.08368269354104996\n",
      "Epoch 3078, Loss: 0.056638214737176895, Final Batch Loss: 0.032507553696632385\n",
      "Epoch 3079, Loss: 0.03972543030977249, Final Batch Loss: 0.016438337042927742\n",
      "Epoch 3080, Loss: 0.04840720631182194, Final Batch Loss: 0.013986056670546532\n",
      "Epoch 3081, Loss: 0.03985965996980667, Final Batch Loss: 0.013985363766551018\n",
      "Epoch 3082, Loss: 0.04156353138387203, Final Batch Loss: 0.0156995952129364\n",
      "Epoch 3083, Loss: 0.05708872899413109, Final Batch Loss: 0.021231845021247864\n",
      "Epoch 3084, Loss: 0.05121273174881935, Final Batch Loss: 0.03515411168336868\n",
      "Epoch 3085, Loss: 0.07454098388552666, Final Batch Loss: 0.023907892405986786\n",
      "Epoch 3086, Loss: 0.07343960925936699, Final Batch Loss: 0.019711051136255264\n",
      "Epoch 3087, Loss: 0.06429401971399784, Final Batch Loss: 0.03501420468091965\n",
      "Epoch 3088, Loss: 0.047678230330348015, Final Batch Loss: 0.02938813902437687\n",
      "Epoch 3089, Loss: 0.04580271057784557, Final Batch Loss: 0.013359731063246727\n",
      "Epoch 3090, Loss: 0.04766823258250952, Final Batch Loss: 0.013934738002717495\n",
      "Epoch 3091, Loss: 0.06400374509394169, Final Batch Loss: 0.043429527431726456\n",
      "Epoch 3092, Loss: 0.18694963306188583, Final Batch Loss: 0.14406739175319672\n",
      "Epoch 3093, Loss: 0.03860046621412039, Final Batch Loss: 0.029634026810526848\n",
      "Epoch 3094, Loss: 0.026193823665380478, Final Batch Loss: 0.008047424256801605\n",
      "Epoch 3095, Loss: 0.05154464207589626, Final Batch Loss: 0.01828491874039173\n",
      "Epoch 3096, Loss: 0.031036117114126682, Final Batch Loss: 0.012357213534414768\n",
      "Epoch 3097, Loss: 0.03145486582070589, Final Batch Loss: 0.008180060423910618\n",
      "Epoch 3098, Loss: 0.06415350455790758, Final Batch Loss: 0.011685502715408802\n",
      "Epoch 3099, Loss: 0.05079171434044838, Final Batch Loss: 0.01681452989578247\n",
      "Epoch 3100, Loss: 0.03017788752913475, Final Batch Loss: 0.015205423347651958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3101, Loss: 0.16182558424770832, Final Batch Loss: 0.1324305683374405\n",
      "Epoch 3102, Loss: 0.04696098482236266, Final Batch Loss: 0.04214325547218323\n",
      "Epoch 3103, Loss: 0.11017036810517311, Final Batch Loss: 0.03213992342352867\n",
      "Epoch 3104, Loss: 0.08083752170205116, Final Batch Loss: 0.029809091240167618\n",
      "Epoch 3105, Loss: 0.054038370959460735, Final Batch Loss: 0.013829461298882961\n",
      "Epoch 3106, Loss: 0.07168897800147533, Final Batch Loss: 0.014875857159495354\n",
      "Epoch 3107, Loss: 0.12723993510007858, Final Batch Loss: 0.0647197812795639\n",
      "Epoch 3108, Loss: 0.08657833933830261, Final Batch Loss: 0.04705583304166794\n",
      "Epoch 3109, Loss: 0.031333948485553265, Final Batch Loss: 0.015218828804790974\n",
      "Epoch 3110, Loss: 0.051783230155706406, Final Batch Loss: 0.03123287484049797\n",
      "Epoch 3111, Loss: 0.03786139748990536, Final Batch Loss: 0.020220264792442322\n",
      "Epoch 3112, Loss: 0.03408517595380545, Final Batch Loss: 0.013885383494198322\n",
      "Epoch 3113, Loss: 0.11055758967995644, Final Batch Loss: 0.07306994497776031\n",
      "Epoch 3114, Loss: 0.07752667367458344, Final Batch Loss: 0.03922048956155777\n",
      "Epoch 3115, Loss: 0.08683932386338711, Final Batch Loss: 0.05975473299622536\n",
      "Epoch 3116, Loss: 0.06500651314854622, Final Batch Loss: 0.03526194393634796\n",
      "Epoch 3117, Loss: 0.048536164686083794, Final Batch Loss: 0.029989760369062424\n",
      "Epoch 3118, Loss: 0.03786862641572952, Final Batch Loss: 0.024493282660841942\n",
      "Epoch 3119, Loss: 0.037666259333491325, Final Batch Loss: 0.008429927751421928\n",
      "Epoch 3120, Loss: 0.0341286463662982, Final Batch Loss: 0.015221421606838703\n",
      "Epoch 3121, Loss: 0.03172760829329491, Final Batch Loss: 0.010557249188423157\n",
      "Epoch 3122, Loss: 0.06812871620059013, Final Batch Loss: 0.030161593109369278\n",
      "Epoch 3123, Loss: 0.049342937767505646, Final Batch Loss: 0.026576116681098938\n",
      "Epoch 3124, Loss: 0.04287170898169279, Final Batch Loss: 0.031068408861756325\n",
      "Epoch 3125, Loss: 0.040303376503288746, Final Batch Loss: 0.026966020464897156\n",
      "Epoch 3126, Loss: 0.11252012476325035, Final Batch Loss: 0.06914875656366348\n",
      "Epoch 3127, Loss: 0.07666382193565369, Final Batch Loss: 0.028215456753969193\n",
      "Epoch 3128, Loss: 0.027805128134787083, Final Batch Loss: 0.009071831591427326\n",
      "Epoch 3129, Loss: 0.04270434193313122, Final Batch Loss: 0.027961507439613342\n",
      "Epoch 3130, Loss: 0.043585048988461494, Final Batch Loss: 0.024072935804724693\n",
      "Epoch 3131, Loss: 0.05730474670417607, Final Batch Loss: 0.003027200000360608\n",
      "Epoch 3132, Loss: 0.0961326863616705, Final Batch Loss: 0.018174877390265465\n",
      "Epoch 3133, Loss: 0.04167370963841677, Final Batch Loss: 0.030264273285865784\n",
      "Epoch 3134, Loss: 0.06546705029904842, Final Batch Loss: 0.04673752561211586\n",
      "Epoch 3135, Loss: 0.02169046923518181, Final Batch Loss: 0.009575076401233673\n",
      "Epoch 3136, Loss: 0.0378085533156991, Final Batch Loss: 0.022636989131569862\n",
      "Epoch 3137, Loss: 0.07819004217162728, Final Batch Loss: 0.004331214819103479\n",
      "Epoch 3138, Loss: 0.08230989426374435, Final Batch Loss: 0.048312049359083176\n",
      "Epoch 3139, Loss: 0.04863736219704151, Final Batch Loss: 0.020743973553180695\n",
      "Epoch 3140, Loss: 0.05491491220891476, Final Batch Loss: 0.016129883006215096\n",
      "Epoch 3141, Loss: 0.08548075705766678, Final Batch Loss: 0.048723794519901276\n",
      "Epoch 3142, Loss: 0.05397368222475052, Final Batch Loss: 0.0335046648979187\n",
      "Epoch 3143, Loss: 0.045882537961006165, Final Batch Loss: 0.013860385864973068\n",
      "Epoch 3144, Loss: 0.01877339417114854, Final Batch Loss: 0.0042118835262954235\n",
      "Epoch 3145, Loss: 0.07523542083799839, Final Batch Loss: 0.026744240894913673\n",
      "Epoch 3146, Loss: 0.05788431316614151, Final Batch Loss: 0.02242588996887207\n",
      "Epoch 3147, Loss: 0.0350309107452631, Final Batch Loss: 0.025626057758927345\n",
      "Epoch 3148, Loss: 0.09575280547142029, Final Batch Loss: 0.05768149718642235\n",
      "Epoch 3149, Loss: 0.07028431631624699, Final Batch Loss: 0.04268200695514679\n",
      "Epoch 3150, Loss: 0.09326511435210705, Final Batch Loss: 0.02194809727370739\n",
      "Epoch 3151, Loss: 0.0685092881321907, Final Batch Loss: 0.027149125933647156\n",
      "Epoch 3152, Loss: 0.07964127138257027, Final Batch Loss: 0.03905849903821945\n",
      "Epoch 3153, Loss: 0.035533783957362175, Final Batch Loss: 0.022765887901186943\n",
      "Epoch 3154, Loss: 0.01724452106282115, Final Batch Loss: 0.01093003898859024\n",
      "Epoch 3155, Loss: 0.04922414757311344, Final Batch Loss: 0.02849402464926243\n",
      "Epoch 3156, Loss: 0.058297473937273026, Final Batch Loss: 0.04101984202861786\n",
      "Epoch 3157, Loss: 0.04272454511374235, Final Batch Loss: 0.03517322614789009\n",
      "Epoch 3158, Loss: 0.048882666043937206, Final Batch Loss: 0.014509308151900768\n",
      "Epoch 3159, Loss: 0.06447005271911621, Final Batch Loss: 0.015636563301086426\n",
      "Epoch 3160, Loss: 0.0443015992641449, Final Batch Loss: 0.028262613341212273\n",
      "Epoch 3161, Loss: 0.03775001596659422, Final Batch Loss: 0.009417912922799587\n",
      "Epoch 3162, Loss: 0.03062136098742485, Final Batch Loss: 0.013780083507299423\n",
      "Epoch 3163, Loss: 0.03509608283638954, Final Batch Loss: 0.00792219303548336\n",
      "Epoch 3164, Loss: 0.06773824617266655, Final Batch Loss: 0.04282796382904053\n",
      "Epoch 3165, Loss: 0.030122810043394566, Final Batch Loss: 0.008139454759657383\n",
      "Epoch 3166, Loss: 0.019411140121519566, Final Batch Loss: 0.01112594734877348\n",
      "Epoch 3167, Loss: 0.03931769961491227, Final Batch Loss: 0.00679918983951211\n",
      "Epoch 3168, Loss: 0.06192336603999138, Final Batch Loss: 0.027197565883398056\n",
      "Epoch 3169, Loss: 0.037956059910357, Final Batch Loss: 0.00966575462371111\n",
      "Epoch 3170, Loss: 0.0954172033816576, Final Batch Loss: 0.022346550598740578\n",
      "Epoch 3171, Loss: 0.09962751530110836, Final Batch Loss: 0.06845740228891373\n",
      "Epoch 3172, Loss: 0.05070339981466532, Final Batch Loss: 0.042764030396938324\n",
      "Epoch 3173, Loss: 0.047482844442129135, Final Batch Loss: 0.010299641638994217\n",
      "Epoch 3174, Loss: 0.04040175583213568, Final Batch Loss: 0.015623928047716618\n",
      "Epoch 3175, Loss: 0.08719974383711815, Final Batch Loss: 0.06821273267269135\n",
      "Epoch 3176, Loss: 0.10205471888184547, Final Batch Loss: 0.04787054285407066\n",
      "Epoch 3177, Loss: 0.06937770545482635, Final Batch Loss: 0.03978072106838226\n",
      "Epoch 3178, Loss: 0.03689584881067276, Final Batch Loss: 0.01273425668478012\n",
      "Epoch 3179, Loss: 0.06959133595228195, Final Batch Loss: 0.022021465003490448\n",
      "Epoch 3180, Loss: 0.0924038402736187, Final Batch Loss: 0.04501500725746155\n",
      "Epoch 3181, Loss: 0.055610036477446556, Final Batch Loss: 0.028710171580314636\n",
      "Epoch 3182, Loss: 0.03551521897315979, Final Batch Loss: 0.018719781190156937\n",
      "Epoch 3183, Loss: 0.026927814818918705, Final Batch Loss: 0.005449502728879452\n",
      "Epoch 3184, Loss: 0.09817687794566154, Final Batch Loss: 0.035093288868665695\n",
      "Epoch 3185, Loss: 0.050881572999060154, Final Batch Loss: 0.008691982366144657\n",
      "Epoch 3186, Loss: 0.06072734668850899, Final Batch Loss: 0.04452897608280182\n",
      "Epoch 3187, Loss: 0.03997157048434019, Final Batch Loss: 0.007369502447545528\n",
      "Epoch 3188, Loss: 0.031945135444402695, Final Batch Loss: 0.01959514245390892\n",
      "Epoch 3189, Loss: 0.031488336622714996, Final Batch Loss: 0.011320173740386963\n",
      "Epoch 3190, Loss: 0.07191282045096159, Final Batch Loss: 0.00991061981767416\n",
      "Epoch 3191, Loss: 0.08364295214414597, Final Batch Loss: 0.04617221653461456\n",
      "Epoch 3192, Loss: 0.07292183395475149, Final Batch Loss: 0.008331305347383022\n",
      "Epoch 3193, Loss: 0.04486838495358825, Final Batch Loss: 0.00547083979472518\n",
      "Epoch 3194, Loss: 0.044531866908073425, Final Batch Loss: 0.022169815376400948\n",
      "Epoch 3195, Loss: 0.05130811734125018, Final Batch Loss: 0.0025523449294269085\n",
      "Epoch 3196, Loss: 0.07965218275785446, Final Batch Loss: 0.03599574789404869\n",
      "Epoch 3197, Loss: 0.08107288181781769, Final Batch Loss: 0.05334316939115524\n",
      "Epoch 3198, Loss: 0.028274464420974255, Final Batch Loss: 0.010671847499907017\n",
      "Epoch 3199, Loss: 0.03111778013408184, Final Batch Loss: 0.0071191973984241486\n",
      "Epoch 3200, Loss: 0.04250325635075569, Final Batch Loss: 0.022608621045947075\n",
      "Epoch 3201, Loss: 0.03280111122876406, Final Batch Loss: 0.015104970894753933\n",
      "Epoch 3202, Loss: 0.08229911606758833, Final Batch Loss: 0.006714443676173687\n",
      "Epoch 3203, Loss: 0.07264142297208309, Final Batch Loss: 0.05116966739296913\n",
      "Epoch 3204, Loss: 0.05772064067423344, Final Batch Loss: 0.014306841418147087\n",
      "Epoch 3205, Loss: 0.06181280501186848, Final Batch Loss: 0.029888665303587914\n",
      "Epoch 3206, Loss: 0.047590394504368305, Final Batch Loss: 0.03769214078783989\n",
      "Epoch 3207, Loss: 0.08708055317401886, Final Batch Loss: 0.011082552373409271\n",
      "Epoch 3208, Loss: 0.06912544369697571, Final Batch Loss: 0.0456630103290081\n",
      "Epoch 3209, Loss: 0.04095239192247391, Final Batch Loss: 0.02242111973464489\n",
      "Epoch 3210, Loss: 0.03835267573595047, Final Batch Loss: 0.018598360940814018\n",
      "Epoch 3211, Loss: 0.03699978953227401, Final Batch Loss: 0.02986878715455532\n",
      "Epoch 3212, Loss: 0.06569754704833031, Final Batch Loss: 0.032143332064151764\n",
      "Epoch 3213, Loss: 0.13347118720412254, Final Batch Loss: 0.0399724580347538\n",
      "Epoch 3214, Loss: 0.08882087375968695, Final Batch Loss: 0.014232366345822811\n",
      "Epoch 3215, Loss: 0.06353027559816837, Final Batch Loss: 0.03658858314156532\n",
      "Epoch 3216, Loss: 0.04653764143586159, Final Batch Loss: 0.019152896478772163\n",
      "Epoch 3217, Loss: 0.03589381463825703, Final Batch Loss: 0.011970635503530502\n",
      "Epoch 3218, Loss: 0.06402888149023056, Final Batch Loss: 0.046032294631004333\n",
      "Epoch 3219, Loss: 0.05434064567089081, Final Batch Loss: 0.022268090397119522\n",
      "Epoch 3220, Loss: 0.14490769570693374, Final Batch Loss: 0.13934586942195892\n",
      "Epoch 3221, Loss: 0.16150236502289772, Final Batch Loss: 0.12455189973115921\n",
      "Epoch 3222, Loss: 0.039891138672828674, Final Batch Loss: 0.016279876232147217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3223, Loss: 0.026000075973570347, Final Batch Loss: 0.012995094060897827\n",
      "Epoch 3224, Loss: 0.05130712315440178, Final Batch Loss: 0.04396815970540047\n",
      "Epoch 3225, Loss: 0.10536132007837296, Final Batch Loss: 0.0564442053437233\n",
      "Epoch 3226, Loss: 0.0445393081754446, Final Batch Loss: 0.018362296745181084\n",
      "Epoch 3227, Loss: 0.18310624361038208, Final Batch Loss: 0.10030391812324524\n",
      "Epoch 3228, Loss: 0.0789276696741581, Final Batch Loss: 0.03908161073923111\n",
      "Epoch 3229, Loss: 0.01933794841170311, Final Batch Loss: 0.009447243995964527\n",
      "Epoch 3230, Loss: 0.04027329757809639, Final Batch Loss: 0.026696423068642616\n",
      "Epoch 3231, Loss: 0.0713309608399868, Final Batch Loss: 0.02549850568175316\n",
      "Epoch 3232, Loss: 0.14114049077033997, Final Batch Loss: 0.03308163583278656\n",
      "Epoch 3233, Loss: 0.06329567357897758, Final Batch Loss: 0.031121674925088882\n",
      "Epoch 3234, Loss: 0.05250287614762783, Final Batch Loss: 0.025096356868743896\n",
      "Epoch 3235, Loss: 0.05122990719974041, Final Batch Loss: 0.03190359100699425\n",
      "Epoch 3236, Loss: 0.029747946187853813, Final Batch Loss: 0.012548625469207764\n",
      "Epoch 3237, Loss: 0.04768484830856323, Final Batch Loss: 0.023369284346699715\n",
      "Epoch 3238, Loss: 0.07762317731976509, Final Batch Loss: 0.0448213629424572\n",
      "Epoch 3239, Loss: 0.08224719017744064, Final Batch Loss: 0.028786901384592056\n",
      "Epoch 3240, Loss: 0.03435268346220255, Final Batch Loss: 0.009904355742037296\n",
      "Epoch 3241, Loss: 0.10277752950787544, Final Batch Loss: 0.058641884475946426\n",
      "Epoch 3242, Loss: 0.057664260268211365, Final Batch Loss: 0.03358741104602814\n",
      "Epoch 3243, Loss: 0.08041553571820259, Final Batch Loss: 0.033435456454753876\n",
      "Epoch 3244, Loss: 0.045188164338469505, Final Batch Loss: 0.025363029912114143\n",
      "Epoch 3245, Loss: 0.057007014751434326, Final Batch Loss: 0.022869806736707687\n",
      "Epoch 3246, Loss: 0.03797709755599499, Final Batch Loss: 0.015607170760631561\n",
      "Epoch 3247, Loss: 0.06972261890769005, Final Batch Loss: 0.03498094528913498\n",
      "Epoch 3248, Loss: 0.1855974867939949, Final Batch Loss: 0.12230920791625977\n",
      "Epoch 3249, Loss: 0.027499954216182232, Final Batch Loss: 0.009380330331623554\n",
      "Epoch 3250, Loss: 0.0294985082000494, Final Batch Loss: 0.007336193695664406\n",
      "Epoch 3251, Loss: 0.05535055510699749, Final Batch Loss: 0.01913514919579029\n",
      "Epoch 3252, Loss: 0.04469217732548714, Final Batch Loss: 0.032190609723329544\n",
      "Epoch 3253, Loss: 0.035057203844189644, Final Batch Loss: 0.018110031262040138\n",
      "Epoch 3254, Loss: 0.028413030318915844, Final Batch Loss: 0.008358738385140896\n",
      "Epoch 3255, Loss: 0.049040403217077255, Final Batch Loss: 0.024058133363723755\n",
      "Epoch 3256, Loss: 0.05587107501924038, Final Batch Loss: 0.006643457338213921\n",
      "Epoch 3257, Loss: 0.03296625893563032, Final Batch Loss: 0.011139136739075184\n",
      "Epoch 3258, Loss: 0.025461949408054352, Final Batch Loss: 0.013301534578204155\n",
      "Epoch 3259, Loss: 0.11001317575573921, Final Batch Loss: 0.07947716861963272\n",
      "Epoch 3260, Loss: 0.06193790026009083, Final Batch Loss: 0.04455983266234398\n",
      "Epoch 3261, Loss: 0.03631937224417925, Final Batch Loss: 0.02485179901123047\n",
      "Epoch 3262, Loss: 0.09316523373126984, Final Batch Loss: 0.059451863169670105\n",
      "Epoch 3263, Loss: 0.04203253984451294, Final Batch Loss: 0.0226080771535635\n",
      "Epoch 3264, Loss: 0.019384323619306087, Final Batch Loss: 0.012501154094934464\n",
      "Epoch 3265, Loss: 0.043553369119763374, Final Batch Loss: 0.021781088784337044\n",
      "Epoch 3266, Loss: 0.057794274762272835, Final Batch Loss: 0.019980641081929207\n",
      "Epoch 3267, Loss: 0.03370572812855244, Final Batch Loss: 0.015271611511707306\n",
      "Epoch 3268, Loss: 0.08050575852394104, Final Batch Loss: 0.017905429005622864\n",
      "Epoch 3269, Loss: 0.046924540773034096, Final Batch Loss: 0.029209304600954056\n",
      "Epoch 3270, Loss: 0.049409426748752594, Final Batch Loss: 0.025169460102915764\n",
      "Epoch 3271, Loss: 0.07387341931462288, Final Batch Loss: 0.04988209158182144\n",
      "Epoch 3272, Loss: 0.049305934458971024, Final Batch Loss: 0.018439915031194687\n",
      "Epoch 3273, Loss: 0.06669647060334682, Final Batch Loss: 0.030058352276682854\n",
      "Epoch 3274, Loss: 0.11570550128817558, Final Batch Loss: 0.08915986865758896\n",
      "Epoch 3275, Loss: 0.018465024419128895, Final Batch Loss: 0.010677352547645569\n",
      "Epoch 3276, Loss: 0.040328108123503625, Final Batch Loss: 0.0017322603380307555\n",
      "Epoch 3277, Loss: 0.06067092623561621, Final Batch Loss: 0.013349424116313457\n",
      "Epoch 3278, Loss: 0.08188313897699118, Final Batch Loss: 0.012378267012536526\n",
      "Epoch 3279, Loss: 0.04486638307571411, Final Batch Loss: 0.010646466165781021\n",
      "Epoch 3280, Loss: 0.025762698613107204, Final Batch Loss: 0.007307658903300762\n",
      "Epoch 3281, Loss: 0.08376960083842278, Final Batch Loss: 0.03392209857702255\n",
      "Epoch 3282, Loss: 0.06063699536025524, Final Batch Loss: 0.027324942871928215\n",
      "Epoch 3283, Loss: 0.11807914823293686, Final Batch Loss: 0.05610378086566925\n",
      "Epoch 3284, Loss: 0.03831233363598585, Final Batch Loss: 0.012411938048899174\n",
      "Epoch 3285, Loss: 0.08048111572861671, Final Batch Loss: 0.03913431614637375\n",
      "Epoch 3286, Loss: 0.05500855948776007, Final Batch Loss: 0.003506946377456188\n",
      "Epoch 3287, Loss: 0.06527810543775558, Final Batch Loss: 0.046545132994651794\n",
      "Epoch 3288, Loss: 0.028803604654967785, Final Batch Loss: 0.014917826279997826\n",
      "Epoch 3289, Loss: 0.10622797906398773, Final Batch Loss: 0.08092135936021805\n",
      "Epoch 3290, Loss: 0.05056911613792181, Final Batch Loss: 0.01525591965764761\n",
      "Epoch 3291, Loss: 0.055007465183734894, Final Batch Loss: 0.026359260082244873\n",
      "Epoch 3292, Loss: 0.06559412181377411, Final Batch Loss: 0.016592252999544144\n",
      "Epoch 3293, Loss: 0.05903108790516853, Final Batch Loss: 0.018127519637346268\n",
      "Epoch 3294, Loss: 0.03617681376636028, Final Batch Loss: 0.016658706590533257\n",
      "Epoch 3295, Loss: 0.052528759464621544, Final Batch Loss: 0.025518294423818588\n",
      "Epoch 3296, Loss: 0.08587094256654382, Final Batch Loss: 0.07991475611925125\n",
      "Epoch 3297, Loss: 0.04292653314769268, Final Batch Loss: 0.016364233568310738\n",
      "Epoch 3298, Loss: 0.01993504771962762, Final Batch Loss: 0.007465027738362551\n",
      "Epoch 3299, Loss: 0.06429509446024895, Final Batch Loss: 0.0248471237719059\n",
      "Epoch 3300, Loss: 0.02722742408514023, Final Batch Loss: 0.014605804346501827\n",
      "Epoch 3301, Loss: 0.04816341586410999, Final Batch Loss: 0.02438012696802616\n",
      "Epoch 3302, Loss: 0.03315132483839989, Final Batch Loss: 0.018609696999192238\n",
      "Epoch 3303, Loss: 0.06045699678361416, Final Batch Loss: 0.012276841327548027\n",
      "Epoch 3304, Loss: 0.08704809471964836, Final Batch Loss: 0.04440959915518761\n",
      "Epoch 3305, Loss: 0.046363385394215584, Final Batch Loss: 0.010255550965666771\n",
      "Epoch 3306, Loss: 0.0843023955821991, Final Batch Loss: 0.044342927634716034\n",
      "Epoch 3307, Loss: 0.08291260525584221, Final Batch Loss: 0.06474751979112625\n",
      "Epoch 3308, Loss: 0.030437656678259373, Final Batch Loss: 0.016812659800052643\n",
      "Epoch 3309, Loss: 0.015246741473674774, Final Batch Loss: 0.004493607208132744\n",
      "Epoch 3310, Loss: 0.0815762784332037, Final Batch Loss: 0.05266397446393967\n",
      "Epoch 3311, Loss: 0.0620759092271328, Final Batch Loss: 0.010632634162902832\n",
      "Epoch 3312, Loss: 0.042917609214782715, Final Batch Loss: 0.025419577956199646\n",
      "Epoch 3313, Loss: 0.02274823933839798, Final Batch Loss: 0.012341982685029507\n",
      "Epoch 3314, Loss: 0.08520961739122868, Final Batch Loss: 0.07234493643045425\n",
      "Epoch 3315, Loss: 0.059052618220448494, Final Batch Loss: 0.04499800503253937\n",
      "Epoch 3316, Loss: 0.03613002132624388, Final Batch Loss: 0.0122422119602561\n",
      "Epoch 3317, Loss: 0.08722715452313423, Final Batch Loss: 0.07135380804538727\n",
      "Epoch 3318, Loss: 0.044386906549334526, Final Batch Loss: 0.020819175988435745\n",
      "Epoch 3319, Loss: 0.05369611643254757, Final Batch Loss: 0.0205573420971632\n",
      "Epoch 3320, Loss: 0.02116451133042574, Final Batch Loss: 0.008625118993222713\n",
      "Epoch 3321, Loss: 0.04642800986766815, Final Batch Loss: 0.02967074327170849\n",
      "Epoch 3322, Loss: 0.05845933686941862, Final Batch Loss: 0.015274777077138424\n",
      "Epoch 3323, Loss: 0.057380485348403454, Final Batch Loss: 0.04721713066101074\n",
      "Epoch 3324, Loss: 0.02030645404011011, Final Batch Loss: 0.005023992620408535\n",
      "Epoch 3325, Loss: 0.036374508403241634, Final Batch Loss: 0.02152571640908718\n",
      "Epoch 3326, Loss: 0.07444749400019646, Final Batch Loss: 0.04170683026313782\n",
      "Epoch 3327, Loss: 0.03740594629198313, Final Batch Loss: 0.02522500976920128\n",
      "Epoch 3328, Loss: 0.05841068737208843, Final Batch Loss: 0.04679019749164581\n",
      "Epoch 3329, Loss: 0.07742834463715553, Final Batch Loss: 0.03543400391936302\n",
      "Epoch 3330, Loss: 0.02956376690417528, Final Batch Loss: 0.011640381999313831\n",
      "Epoch 3331, Loss: 0.16915953531861305, Final Batch Loss: 0.14879220724105835\n",
      "Epoch 3332, Loss: 0.07670762203633785, Final Batch Loss: 0.012238679453730583\n",
      "Epoch 3333, Loss: 0.07736996375024319, Final Batch Loss: 0.0597180612385273\n",
      "Epoch 3334, Loss: 0.07475695013999939, Final Batch Loss: 0.05056357383728027\n",
      "Epoch 3335, Loss: 0.18442777171730995, Final Batch Loss: 0.04497678950428963\n",
      "Epoch 3336, Loss: 0.16441845893859863, Final Batch Loss: 0.047796882688999176\n",
      "Epoch 3337, Loss: 0.11892110854387283, Final Batch Loss: 0.06601635366678238\n",
      "Epoch 3338, Loss: 0.07236944325268269, Final Batch Loss: 0.022829139605164528\n",
      "Epoch 3339, Loss: 0.060589817352592945, Final Batch Loss: 0.009863783605396748\n",
      "Epoch 3340, Loss: 0.0811576209962368, Final Batch Loss: 0.046393491327762604\n",
      "Epoch 3341, Loss: 0.05945746973156929, Final Batch Loss: 0.032586321234703064\n",
      "Epoch 3342, Loss: 0.04996431991457939, Final Batch Loss: 0.023567821830511093\n",
      "Epoch 3343, Loss: 0.06074432283639908, Final Batch Loss: 0.023022327572107315\n",
      "Epoch 3344, Loss: 0.02576468326151371, Final Batch Loss: 0.008650461211800575\n",
      "Epoch 3345, Loss: 0.12229820713400841, Final Batch Loss: 0.03278782591223717\n",
      "Epoch 3346, Loss: 0.042009759694337845, Final Batch Loss: 0.01939576491713524\n",
      "Epoch 3347, Loss: 0.10313839837908745, Final Batch Loss: 0.07128824293613434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3348, Loss: 0.1011905837804079, Final Batch Loss: 0.08939739316701889\n",
      "Epoch 3349, Loss: 0.1278274729847908, Final Batch Loss: 0.09401898831129074\n",
      "Epoch 3350, Loss: 0.035385383758693933, Final Batch Loss: 0.005444678012281656\n",
      "Epoch 3351, Loss: 0.04798380471765995, Final Batch Loss: 0.012412911280989647\n",
      "Epoch 3352, Loss: 0.09741156920790672, Final Batch Loss: 0.04969209432601929\n",
      "Epoch 3353, Loss: 0.049609193578362465, Final Batch Loss: 0.023569194599986076\n",
      "Epoch 3354, Loss: 0.04229460470378399, Final Batch Loss: 0.022004378959536552\n",
      "Epoch 3355, Loss: 0.04631953500211239, Final Batch Loss: 0.019858447834849358\n",
      "Epoch 3356, Loss: 0.053171681240200996, Final Batch Loss: 0.038302160799503326\n",
      "Epoch 3357, Loss: 0.044762756675481796, Final Batch Loss: 0.016541942954063416\n",
      "Epoch 3358, Loss: 0.08322405070066452, Final Batch Loss: 0.05104391649365425\n",
      "Epoch 3359, Loss: 0.039507159031927586, Final Batch Loss: 0.02524615451693535\n",
      "Epoch 3360, Loss: 0.023592146579176188, Final Batch Loss: 0.0064372108317911625\n",
      "Epoch 3361, Loss: 0.06058257445693016, Final Batch Loss: 0.040053971111774445\n",
      "Epoch 3362, Loss: 0.026106002740561962, Final Batch Loss: 0.009498397819697857\n",
      "Epoch 3363, Loss: 0.024701028130948544, Final Batch Loss: 0.011822015978395939\n",
      "Epoch 3364, Loss: 0.047989532351493835, Final Batch Loss: 0.026321593672037125\n",
      "Epoch 3365, Loss: 0.057599594816565514, Final Batch Loss: 0.04074870049953461\n",
      "Epoch 3366, Loss: 0.030167202930897474, Final Batch Loss: 0.007555767428129911\n",
      "Epoch 3367, Loss: 0.19602461904287338, Final Batch Loss: 0.0694432184100151\n",
      "Epoch 3368, Loss: 0.03897770307958126, Final Batch Loss: 0.011450959369540215\n",
      "Epoch 3369, Loss: 0.07063002698123455, Final Batch Loss: 0.02831179089844227\n",
      "Epoch 3370, Loss: 0.036897605285048485, Final Batch Loss: 0.02119683101773262\n",
      "Epoch 3371, Loss: 0.05466981418430805, Final Batch Loss: 0.01921285130083561\n",
      "Epoch 3372, Loss: 0.09128859639167786, Final Batch Loss: 0.06002859026193619\n",
      "Epoch 3373, Loss: 0.102198775857687, Final Batch Loss: 0.08361554145812988\n",
      "Epoch 3374, Loss: 0.03822118975222111, Final Batch Loss: 0.01798981986939907\n",
      "Epoch 3375, Loss: 0.0575312077999115, Final Batch Loss: 0.044621068984270096\n",
      "Epoch 3376, Loss: 0.035553363151848316, Final Batch Loss: 0.0240417942404747\n",
      "Epoch 3377, Loss: 0.03758917097002268, Final Batch Loss: 0.011148224584758282\n",
      "Epoch 3378, Loss: 0.05061765946447849, Final Batch Loss: 0.027241278439760208\n",
      "Epoch 3379, Loss: 0.05953744612634182, Final Batch Loss: 0.05117309093475342\n",
      "Epoch 3380, Loss: 0.03143143467605114, Final Batch Loss: 0.014971673488616943\n",
      "Epoch 3381, Loss: 0.0376366525888443, Final Batch Loss: 0.006934143602848053\n",
      "Epoch 3382, Loss: 0.06453714892268181, Final Batch Loss: 0.0417935810983181\n",
      "Epoch 3383, Loss: 0.027826576493680477, Final Batch Loss: 0.019795404747128487\n",
      "Epoch 3384, Loss: 0.04002257902175188, Final Batch Loss: 0.014281623996794224\n",
      "Epoch 3385, Loss: 0.04869632422924042, Final Batch Loss: 0.03164278715848923\n",
      "Epoch 3386, Loss: 0.03004126762971282, Final Batch Loss: 0.007283513899892569\n",
      "Epoch 3387, Loss: 0.02989637292921543, Final Batch Loss: 0.009304434061050415\n",
      "Epoch 3388, Loss: 0.03390991734340787, Final Batch Loss: 0.0033012148924171925\n",
      "Epoch 3389, Loss: 0.040354350581765175, Final Batch Loss: 0.01669139787554741\n",
      "Epoch 3390, Loss: 0.07032330334186554, Final Batch Loss: 0.05713194981217384\n",
      "Epoch 3391, Loss: 0.13587388396263123, Final Batch Loss: 0.11639478802680969\n",
      "Epoch 3392, Loss: 0.027729381807148457, Final Batch Loss: 0.014247996732592583\n",
      "Epoch 3393, Loss: 0.018655764870345592, Final Batch Loss: 0.008614066056907177\n",
      "Epoch 3394, Loss: 0.03457303065806627, Final Batch Loss: 0.012337475083768368\n",
      "Epoch 3395, Loss: 0.044044552370905876, Final Batch Loss: 0.016426987946033478\n",
      "Epoch 3396, Loss: 0.11559473909437656, Final Batch Loss: 0.02244858630001545\n",
      "Epoch 3397, Loss: 0.06295622512698174, Final Batch Loss: 0.029468953609466553\n",
      "Epoch 3398, Loss: 0.04166145995259285, Final Batch Loss: 0.025605781003832817\n",
      "Epoch 3399, Loss: 0.04982575587928295, Final Batch Loss: 0.03574754297733307\n",
      "Epoch 3400, Loss: 0.034706758335232735, Final Batch Loss: 0.016541454941034317\n",
      "Epoch 3401, Loss: 0.07413896732032299, Final Batch Loss: 0.043034713715314865\n",
      "Epoch 3402, Loss: 0.07061142474412918, Final Batch Loss: 0.03402422368526459\n",
      "Epoch 3403, Loss: 0.051662747748196125, Final Batch Loss: 0.010924560017883778\n",
      "Epoch 3404, Loss: 0.02697403822094202, Final Batch Loss: 0.008966234512627125\n",
      "Epoch 3405, Loss: 0.05301613733172417, Final Batch Loss: 0.03366069495677948\n",
      "Epoch 3406, Loss: 0.08715307712554932, Final Batch Loss: 0.05455348640680313\n",
      "Epoch 3407, Loss: 0.06242339499294758, Final Batch Loss: 0.05570995807647705\n",
      "Epoch 3408, Loss: 0.023328982293605804, Final Batch Loss: 0.012837831862270832\n",
      "Epoch 3409, Loss: 0.03235116694122553, Final Batch Loss: 0.014649965800344944\n",
      "Epoch 3410, Loss: 0.04500718228518963, Final Batch Loss: 0.02537342719733715\n",
      "Epoch 3411, Loss: 0.025617051869630814, Final Batch Loss: 0.011230560019612312\n",
      "Epoch 3412, Loss: 0.0331052066758275, Final Batch Loss: 0.011379431001842022\n",
      "Epoch 3413, Loss: 0.08671598695218563, Final Batch Loss: 0.07141370326280594\n",
      "Epoch 3414, Loss: 0.035517992451786995, Final Batch Loss: 0.017171595245599747\n",
      "Epoch 3415, Loss: 0.048712937626987696, Final Batch Loss: 0.004396459553390741\n",
      "Epoch 3416, Loss: 0.05795522499829531, Final Batch Loss: 0.009868902154266834\n",
      "Epoch 3417, Loss: 0.03579329513013363, Final Batch Loss: 0.01052708737552166\n",
      "Epoch 3418, Loss: 0.03544873185455799, Final Batch Loss: 0.01629234477877617\n",
      "Epoch 3419, Loss: 0.04604183882474899, Final Batch Loss: 0.021636763587594032\n",
      "Epoch 3420, Loss: 0.056135169230401516, Final Batch Loss: 0.04855746775865555\n",
      "Epoch 3421, Loss: 0.03198013687506318, Final Batch Loss: 0.025148378685116768\n",
      "Epoch 3422, Loss: 0.054261982440948486, Final Batch Loss: 0.018863573670387268\n",
      "Epoch 3423, Loss: 0.0788003895431757, Final Batch Loss: 0.019799524918198586\n",
      "Epoch 3424, Loss: 0.04099836479872465, Final Batch Loss: 0.029497690498828888\n",
      "Epoch 3425, Loss: 0.0453416146337986, Final Batch Loss: 0.014937711879611015\n",
      "Epoch 3426, Loss: 0.034177515655756, Final Batch Loss: 0.015855243429541588\n",
      "Epoch 3427, Loss: 0.07556857168674469, Final Batch Loss: 0.05285164713859558\n",
      "Epoch 3428, Loss: 0.07707482948899269, Final Batch Loss: 0.013674486428499222\n",
      "Epoch 3429, Loss: 0.017830318305641413, Final Batch Loss: 0.007074770983308554\n",
      "Epoch 3430, Loss: 0.04460872616618872, Final Batch Loss: 0.013189206831157207\n",
      "Epoch 3431, Loss: 0.09955590963363647, Final Batch Loss: 0.007106512784957886\n",
      "Epoch 3432, Loss: 0.055038224905729294, Final Batch Loss: 0.04439365491271019\n",
      "Epoch 3433, Loss: 0.03351402096450329, Final Batch Loss: 0.016358600929379463\n",
      "Epoch 3434, Loss: 0.04709234647452831, Final Batch Loss: 0.00881795771420002\n",
      "Epoch 3435, Loss: 0.045695481821894646, Final Batch Loss: 0.012434976175427437\n",
      "Epoch 3436, Loss: 0.051127269864082336, Final Batch Loss: 0.028604932129383087\n",
      "Epoch 3437, Loss: 0.07470039092004299, Final Batch Loss: 0.04853195697069168\n",
      "Epoch 3438, Loss: 0.031886366195976734, Final Batch Loss: 0.025547320023179054\n",
      "Epoch 3439, Loss: 0.021185625810176134, Final Batch Loss: 0.006917010527104139\n",
      "Epoch 3440, Loss: 0.01991179073229432, Final Batch Loss: 0.00779247609898448\n",
      "Epoch 3441, Loss: 0.045941793359816074, Final Batch Loss: 0.012044181115925312\n",
      "Epoch 3442, Loss: 0.049732303246855736, Final Batch Loss: 0.03323374688625336\n",
      "Epoch 3443, Loss: 0.0848584696650505, Final Batch Loss: 0.04316207021474838\n",
      "Epoch 3444, Loss: 0.024001635145395994, Final Batch Loss: 0.005505112465471029\n",
      "Epoch 3445, Loss: 0.029502738267183304, Final Batch Loss: 0.010240286588668823\n",
      "Epoch 3446, Loss: 0.038141281343996525, Final Batch Loss: 0.01041483972221613\n",
      "Epoch 3447, Loss: 0.08563903160393238, Final Batch Loss: 0.013066994026303291\n",
      "Epoch 3448, Loss: 0.03822637442499399, Final Batch Loss: 0.011912907473742962\n",
      "Epoch 3449, Loss: 0.06275710463523865, Final Batch Loss: 0.03139447793364525\n",
      "Epoch 3450, Loss: 0.03496784809976816, Final Batch Loss: 0.020290909335017204\n",
      "Epoch 3451, Loss: 0.07970386929810047, Final Batch Loss: 0.0529472790658474\n",
      "Epoch 3452, Loss: 0.03343075793236494, Final Batch Loss: 0.009172418154776096\n",
      "Epoch 3453, Loss: 0.04384031519293785, Final Batch Loss: 0.017967956140637398\n",
      "Epoch 3454, Loss: 0.025967857101932168, Final Batch Loss: 0.00303144589997828\n",
      "Epoch 3455, Loss: 0.04233104549348354, Final Batch Loss: 0.021044142544269562\n",
      "Epoch 3456, Loss: 0.06291620247066021, Final Batch Loss: 0.05493316054344177\n",
      "Epoch 3457, Loss: 0.024166387505829334, Final Batch Loss: 0.012829025276005268\n",
      "Epoch 3458, Loss: 0.020589064341038465, Final Batch Loss: 0.005945377517491579\n",
      "Epoch 3459, Loss: 0.03425630833953619, Final Batch Loss: 0.0188384260982275\n",
      "Epoch 3460, Loss: 0.04483194928616285, Final Batch Loss: 0.012092101387679577\n",
      "Epoch 3461, Loss: 0.08115938678383827, Final Batch Loss: 0.05458693206310272\n",
      "Epoch 3462, Loss: 0.04612707532942295, Final Batch Loss: 0.029412969946861267\n",
      "Epoch 3463, Loss: 0.03172974567860365, Final Batch Loss: 0.02084343694150448\n",
      "Epoch 3464, Loss: 0.021034413017332554, Final Batch Loss: 0.010209147818386555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3465, Loss: 0.10980983451008797, Final Batch Loss: 0.07016774266958237\n",
      "Epoch 3466, Loss: 0.041827861219644547, Final Batch Loss: 0.008427806198596954\n",
      "Epoch 3467, Loss: 0.036536460276693106, Final Batch Loss: 0.006359355058521032\n",
      "Epoch 3468, Loss: 0.017568040173500776, Final Batch Loss: 0.01164553314447403\n",
      "Epoch 3469, Loss: 0.010276780929416418, Final Batch Loss: 0.005594080314040184\n",
      "Epoch 3470, Loss: 0.06295754760503769, Final Batch Loss: 0.02772871032357216\n",
      "Epoch 3471, Loss: 0.029169591143727303, Final Batch Loss: 0.019681615754961967\n",
      "Epoch 3472, Loss: 0.0448129465803504, Final Batch Loss: 0.009061544202268124\n",
      "Epoch 3473, Loss: 0.03920713812112808, Final Batch Loss: 0.01677071675658226\n",
      "Epoch 3474, Loss: 0.042448182590305805, Final Batch Loss: 0.009428502060472965\n",
      "Epoch 3475, Loss: 0.02986682439222932, Final Batch Loss: 0.00480067590251565\n",
      "Epoch 3476, Loss: 0.02727593993768096, Final Batch Loss: 0.00557655980810523\n",
      "Epoch 3477, Loss: 0.0329932626336813, Final Batch Loss: 0.018339814618229866\n",
      "Epoch 3478, Loss: 0.12652722746133804, Final Batch Loss: 0.0920499637722969\n",
      "Epoch 3479, Loss: 0.05927206948399544, Final Batch Loss: 0.02083592116832733\n",
      "Epoch 3480, Loss: 0.08666709531098604, Final Batch Loss: 0.013734986074268818\n",
      "Epoch 3481, Loss: 0.03840675810351968, Final Batch Loss: 0.005856173578649759\n",
      "Epoch 3482, Loss: 0.05175685556605458, Final Batch Loss: 0.005444452632218599\n",
      "Epoch 3483, Loss: 0.030423463322222233, Final Batch Loss: 0.006668728776276112\n",
      "Epoch 3484, Loss: 0.12213019747287035, Final Batch Loss: 0.0034898268058896065\n",
      "Epoch 3485, Loss: 0.02657028939574957, Final Batch Loss: 0.014533923007547855\n",
      "Epoch 3486, Loss: 0.04633192531764507, Final Batch Loss: 0.016552969813346863\n",
      "Epoch 3487, Loss: 0.06329126749187708, Final Batch Loss: 0.012989175505936146\n",
      "Epoch 3488, Loss: 0.08367062732577324, Final Batch Loss: 0.048310328274965286\n",
      "Epoch 3489, Loss: 0.04471767321228981, Final Batch Loss: 0.018038015812635422\n",
      "Epoch 3490, Loss: 0.029870133846998215, Final Batch Loss: 0.015766918659210205\n",
      "Epoch 3491, Loss: 0.021889815106987953, Final Batch Loss: 0.013324971310794353\n",
      "Epoch 3492, Loss: 0.11606910824775696, Final Batch Loss: 0.09995143115520477\n",
      "Epoch 3493, Loss: 0.09598538093268871, Final Batch Loss: 0.026857493445277214\n",
      "Epoch 3494, Loss: 0.02843894623219967, Final Batch Loss: 0.012484012171626091\n",
      "Epoch 3495, Loss: 0.09510086290538311, Final Batch Loss: 0.08120657503604889\n",
      "Epoch 3496, Loss: 0.022513017058372498, Final Batch Loss: 0.014241410419344902\n",
      "Epoch 3497, Loss: 0.11233988404273987, Final Batch Loss: 0.06119213625788689\n",
      "Epoch 3498, Loss: 0.05995476804673672, Final Batch Loss: 0.027327416464686394\n",
      "Epoch 3499, Loss: 0.1817374899983406, Final Batch Loss: 0.14529362320899963\n",
      "Epoch 3500, Loss: 0.05192774161696434, Final Batch Loss: 0.02125411480665207\n",
      "Epoch 3501, Loss: 0.02306815329939127, Final Batch Loss: 0.007615052163600922\n",
      "Epoch 3502, Loss: 0.03251935448497534, Final Batch Loss: 0.008532487787306309\n",
      "Epoch 3503, Loss: 0.042453487403690815, Final Batch Loss: 0.03163912892341614\n",
      "Epoch 3504, Loss: 0.029154286719858646, Final Batch Loss: 0.010736617259681225\n",
      "Epoch 3505, Loss: 0.021714868023991585, Final Batch Loss: 0.006103867664933205\n",
      "Epoch 3506, Loss: 0.022834381088614464, Final Batch Loss: 0.010717560537159443\n",
      "Epoch 3507, Loss: 0.05206940323114395, Final Batch Loss: 0.015637602657079697\n",
      "Epoch 3508, Loss: 0.06615481711924076, Final Batch Loss: 0.05765331909060478\n",
      "Epoch 3509, Loss: 0.046161115169525146, Final Batch Loss: 0.03212291747331619\n",
      "Epoch 3510, Loss: 0.02731842640787363, Final Batch Loss: 0.011228944174945354\n",
      "Epoch 3511, Loss: 0.017179624643176794, Final Batch Loss: 0.004815904889255762\n",
      "Epoch 3512, Loss: 0.07594731263816357, Final Batch Loss: 0.0580764003098011\n",
      "Epoch 3513, Loss: 0.062222426757216454, Final Batch Loss: 0.03017730824649334\n",
      "Epoch 3514, Loss: 0.03669995069503784, Final Batch Loss: 0.020920153707265854\n",
      "Epoch 3515, Loss: 0.04733159765601158, Final Batch Loss: 0.038669634610414505\n",
      "Epoch 3516, Loss: 0.0853137681260705, Final Batch Loss: 0.008184016682207584\n",
      "Epoch 3517, Loss: 0.019441524520516396, Final Batch Loss: 0.009633690118789673\n",
      "Epoch 3518, Loss: 0.05445853807032108, Final Batch Loss: 0.02942008711397648\n",
      "Epoch 3519, Loss: 0.02324376069009304, Final Batch Loss: 0.008761543780565262\n",
      "Epoch 3520, Loss: 0.03688901010900736, Final Batch Loss: 0.013156118802726269\n",
      "Epoch 3521, Loss: 0.07060846500098705, Final Batch Loss: 0.060695696622133255\n",
      "Epoch 3522, Loss: 0.06386619061231613, Final Batch Loss: 0.024243447929620743\n",
      "Epoch 3523, Loss: 0.04266803711652756, Final Batch Loss: 0.028328794986009598\n",
      "Epoch 3524, Loss: 0.0718513447791338, Final Batch Loss: 0.0531948059797287\n",
      "Epoch 3525, Loss: 0.05198287311941385, Final Batch Loss: 0.04648227244615555\n",
      "Epoch 3526, Loss: 0.06739691132679582, Final Batch Loss: 0.007749045733362436\n",
      "Epoch 3527, Loss: 0.06667812168598175, Final Batch Loss: 0.04071136936545372\n",
      "Epoch 3528, Loss: 0.09549268521368504, Final Batch Loss: 0.0701737254858017\n",
      "Epoch 3529, Loss: 0.10530149191617966, Final Batch Loss: 0.04735283926129341\n",
      "Epoch 3530, Loss: 0.08598849177360535, Final Batch Loss: 0.01826465129852295\n",
      "Epoch 3531, Loss: 0.10535543039441109, Final Batch Loss: 0.06786813586950302\n",
      "Epoch 3532, Loss: 0.03192817233502865, Final Batch Loss: 0.008679818361997604\n",
      "Epoch 3533, Loss: 0.12803801521658897, Final Batch Loss: 0.09059038758277893\n",
      "Epoch 3534, Loss: 0.07961954548954964, Final Batch Loss: 0.04116244241595268\n",
      "Epoch 3535, Loss: 0.02404676377773285, Final Batch Loss: 0.007887585088610649\n",
      "Epoch 3536, Loss: 0.03632412292063236, Final Batch Loss: 0.01576051115989685\n",
      "Epoch 3537, Loss: 0.07832789048552513, Final Batch Loss: 0.042964041233062744\n",
      "Epoch 3538, Loss: 0.15150415524840355, Final Batch Loss: 0.09165577590465546\n",
      "Epoch 3539, Loss: 0.05183237884193659, Final Batch Loss: 0.011104878969490528\n",
      "Epoch 3540, Loss: 0.09358308464288712, Final Batch Loss: 0.052332017570734024\n",
      "Epoch 3541, Loss: 0.05045695975422859, Final Batch Loss: 0.012623634189367294\n",
      "Epoch 3542, Loss: 0.06926743499934673, Final Batch Loss: 0.05333905294537544\n",
      "Epoch 3543, Loss: 0.04214707016944885, Final Batch Loss: 0.019769499078392982\n",
      "Epoch 3544, Loss: 0.04146911855787039, Final Batch Loss: 0.012114168144762516\n",
      "Epoch 3545, Loss: 0.05898535996675491, Final Batch Loss: 0.04688060283660889\n",
      "Epoch 3546, Loss: 0.11636257544159889, Final Batch Loss: 0.05195479467511177\n",
      "Epoch 3547, Loss: 0.053276749327778816, Final Batch Loss: 0.026054346933960915\n",
      "Epoch 3548, Loss: 0.04822000302374363, Final Batch Loss: 0.014408348128199577\n",
      "Epoch 3549, Loss: 0.0234183045104146, Final Batch Loss: 0.007508725859224796\n",
      "Epoch 3550, Loss: 0.07246909104287624, Final Batch Loss: 0.02104681171476841\n",
      "Epoch 3551, Loss: 0.03570215217769146, Final Batch Loss: 0.011188849806785583\n",
      "Epoch 3552, Loss: 0.05381129868328571, Final Batch Loss: 0.025135237723588943\n",
      "Epoch 3553, Loss: 0.12673503160476685, Final Batch Loss: 0.06930459290742874\n",
      "Epoch 3554, Loss: 0.11324548721313477, Final Batch Loss: 0.08109959214925766\n",
      "Epoch 3555, Loss: 0.06621607206761837, Final Batch Loss: 0.0439765602350235\n",
      "Epoch 3556, Loss: 0.03362212935462594, Final Batch Loss: 0.007313281763345003\n",
      "Epoch 3557, Loss: 0.0417014230042696, Final Batch Loss: 0.008436037227511406\n",
      "Epoch 3558, Loss: 0.05631328746676445, Final Batch Loss: 0.027720283716917038\n",
      "Epoch 3559, Loss: 0.02316188719123602, Final Batch Loss: 0.010755679570138454\n",
      "Epoch 3560, Loss: 0.014216895215213299, Final Batch Loss: 0.006211170926690102\n",
      "Epoch 3561, Loss: 0.02021384285762906, Final Batch Loss: 0.005041967611759901\n",
      "Epoch 3562, Loss: 0.019343691412359476, Final Batch Loss: 0.007641122210770845\n",
      "Epoch 3563, Loss: 0.07892310991883278, Final Batch Loss: 0.035135749727487564\n",
      "Epoch 3564, Loss: 0.026647396385669708, Final Batch Loss: 0.014336109161376953\n",
      "Epoch 3565, Loss: 0.02129843458533287, Final Batch Loss: 0.012481977231800556\n",
      "Epoch 3566, Loss: 0.04720432683825493, Final Batch Loss: 0.007903013378381729\n",
      "Epoch 3567, Loss: 0.06936878710985184, Final Batch Loss: 0.04902670532464981\n",
      "Epoch 3568, Loss: 0.07074180524796247, Final Batch Loss: 0.06483480334281921\n",
      "Epoch 3569, Loss: 0.04942959267646074, Final Batch Loss: 0.03494909778237343\n",
      "Epoch 3570, Loss: 0.0790582001209259, Final Batch Loss: 0.04577474668622017\n",
      "Epoch 3571, Loss: 0.14752135798335075, Final Batch Loss: 0.12339253723621368\n",
      "Epoch 3572, Loss: 0.043121105059981346, Final Batch Loss: 0.0242020171135664\n",
      "Epoch 3573, Loss: 0.05282954080030322, Final Batch Loss: 0.04679159075021744\n",
      "Epoch 3574, Loss: 0.050565192475914955, Final Batch Loss: 0.01227177120745182\n",
      "Epoch 3575, Loss: 0.04046769626438618, Final Batch Loss: 0.009876439347863197\n",
      "Epoch 3576, Loss: 0.061841838993132114, Final Batch Loss: 0.04905140399932861\n",
      "Epoch 3577, Loss: 0.04166009183973074, Final Batch Loss: 0.010501588694751263\n",
      "Epoch 3578, Loss: 0.052416847087442875, Final Batch Loss: 0.042056478559970856\n",
      "Epoch 3579, Loss: 0.02278862427920103, Final Batch Loss: 0.014278508722782135\n",
      "Epoch 3580, Loss: 0.06749558076262474, Final Batch Loss: 0.025478970259428024\n",
      "Epoch 3581, Loss: 0.025478522293269634, Final Batch Loss: 0.01265045627951622\n",
      "Epoch 3582, Loss: 0.08381052315235138, Final Batch Loss: 0.010583758354187012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3583, Loss: 0.06173348426818848, Final Batch Loss: 0.04445865750312805\n",
      "Epoch 3584, Loss: 0.059420397505164146, Final Batch Loss: 0.024359403178095818\n",
      "Epoch 3585, Loss: 0.059296565130352974, Final Batch Loss: 0.042979683727025986\n",
      "Epoch 3586, Loss: 0.037478809244930744, Final Batch Loss: 0.01042188797146082\n",
      "Epoch 3587, Loss: 0.041262026876211166, Final Batch Loss: 0.01671268418431282\n",
      "Epoch 3588, Loss: 0.035350444726645947, Final Batch Loss: 0.012595160864293575\n",
      "Epoch 3589, Loss: 0.04361342079937458, Final Batch Loss: 0.013065336272120476\n",
      "Epoch 3590, Loss: 0.07011329475790262, Final Batch Loss: 0.05901021510362625\n",
      "Epoch 3591, Loss: 0.1192917712032795, Final Batch Loss: 0.09416728466749191\n",
      "Epoch 3592, Loss: 0.050709063187241554, Final Batch Loss: 0.01182444579899311\n",
      "Epoch 3593, Loss: 0.10056440532207489, Final Batch Loss: 0.06354890018701553\n",
      "Epoch 3594, Loss: 0.046499489806592464, Final Batch Loss: 0.010663214139640331\n",
      "Epoch 3595, Loss: 0.051343608647584915, Final Batch Loss: 0.009533990174531937\n",
      "Epoch 3596, Loss: 0.03138813469558954, Final Batch Loss: 0.007934686727821827\n",
      "Epoch 3597, Loss: 0.03629500977694988, Final Batch Loss: 0.01088414341211319\n",
      "Epoch 3598, Loss: 0.030598648823797703, Final Batch Loss: 0.0043015023693442345\n",
      "Epoch 3599, Loss: 0.10587955638766289, Final Batch Loss: 0.0745583102107048\n",
      "Epoch 3600, Loss: 0.05394904874265194, Final Batch Loss: 0.03627413883805275\n",
      "Epoch 3601, Loss: 0.026963907293975353, Final Batch Loss: 0.01311539113521576\n",
      "Epoch 3602, Loss: 0.03966919519007206, Final Batch Loss: 0.02204435132443905\n",
      "Epoch 3603, Loss: 0.0621872004121542, Final Batch Loss: 0.045492250472307205\n",
      "Epoch 3604, Loss: 0.014292176812887192, Final Batch Loss: 0.006764907855540514\n",
      "Epoch 3605, Loss: 0.026689586928114295, Final Batch Loss: 0.0029478834476321936\n",
      "Epoch 3606, Loss: 0.05821188259869814, Final Batch Loss: 0.049455128610134125\n",
      "Epoch 3607, Loss: 0.1361227510496974, Final Batch Loss: 0.12255355715751648\n",
      "Epoch 3608, Loss: 0.028936984948813915, Final Batch Loss: 0.020080773159861565\n",
      "Epoch 3609, Loss: 0.04078512638807297, Final Batch Loss: 0.026920313015580177\n",
      "Epoch 3610, Loss: 0.03759588301181793, Final Batch Loss: 0.012407319620251656\n",
      "Epoch 3611, Loss: 0.08242918737232685, Final Batch Loss: 0.022013531997799873\n",
      "Epoch 3612, Loss: 0.020099716261029243, Final Batch Loss: 0.011244820430874825\n",
      "Epoch 3613, Loss: 0.04839253704994917, Final Batch Loss: 0.03852355480194092\n",
      "Epoch 3614, Loss: 0.040027724113315344, Final Batch Loss: 0.032584574073553085\n",
      "Epoch 3615, Loss: 0.06974203232675791, Final Batch Loss: 0.06020287051796913\n",
      "Epoch 3616, Loss: 0.042381906881928444, Final Batch Loss: 0.007867580279707909\n",
      "Epoch 3617, Loss: 0.012737924233078957, Final Batch Loss: 0.004828483797609806\n",
      "Epoch 3618, Loss: 0.0626638950780034, Final Batch Loss: 0.0046531157568097115\n",
      "Epoch 3619, Loss: 0.042003543581813574, Final Batch Loss: 0.03692414611577988\n",
      "Epoch 3620, Loss: 0.06756291352212429, Final Batch Loss: 0.027412859722971916\n",
      "Epoch 3621, Loss: 0.04004886653274298, Final Batch Loss: 0.02562129497528076\n",
      "Epoch 3622, Loss: 0.05328116938471794, Final Batch Loss: 0.03241662681102753\n",
      "Epoch 3623, Loss: 0.08322284929454327, Final Batch Loss: 0.030421284958720207\n",
      "Epoch 3624, Loss: 0.0424320250749588, Final Batch Loss: 0.017897097393870354\n",
      "Epoch 3625, Loss: 0.05609926115721464, Final Batch Loss: 0.01301086600869894\n",
      "Epoch 3626, Loss: 0.033203763887286186, Final Batch Loss: 0.021729562431573868\n",
      "Epoch 3627, Loss: 0.0412908848375082, Final Batch Loss: 0.03328889608383179\n",
      "Epoch 3628, Loss: 0.021258074790239334, Final Batch Loss: 0.010342583991587162\n",
      "Epoch 3629, Loss: 0.04191530868411064, Final Batch Loss: 0.02263786271214485\n",
      "Epoch 3630, Loss: 0.052365124225616455, Final Batch Loss: 0.02213991805911064\n",
      "Epoch 3631, Loss: 0.07753817364573479, Final Batch Loss: 0.04221126809716225\n",
      "Epoch 3632, Loss: 0.035180686973035336, Final Batch Loss: 0.020671825855970383\n",
      "Epoch 3633, Loss: 0.07155651319772005, Final Batch Loss: 0.057693324983119965\n",
      "Epoch 3634, Loss: 0.010753026930615306, Final Batch Loss: 0.0028090213891118765\n",
      "Epoch 3635, Loss: 0.0879598930478096, Final Batch Loss: 0.062489259988069534\n",
      "Epoch 3636, Loss: 0.04343029484152794, Final Batch Loss: 0.026462852954864502\n",
      "Epoch 3637, Loss: 0.02489136904478073, Final Batch Loss: 0.013462812639772892\n",
      "Epoch 3638, Loss: 0.09034476056694984, Final Batch Loss: 0.044877439737319946\n",
      "Epoch 3639, Loss: 0.02317026723176241, Final Batch Loss: 0.012802820652723312\n",
      "Epoch 3640, Loss: 0.02715263795107603, Final Batch Loss: 0.006235337816178799\n",
      "Epoch 3641, Loss: 0.04178338870406151, Final Batch Loss: 0.01761295646429062\n",
      "Epoch 3642, Loss: 0.04465101286768913, Final Batch Loss: 0.0260508731007576\n",
      "Epoch 3643, Loss: 0.02555401436984539, Final Batch Loss: 0.017071131616830826\n",
      "Epoch 3644, Loss: 0.08355440199375153, Final Batch Loss: 0.050568487495183945\n",
      "Epoch 3645, Loss: 0.07038464117795229, Final Batch Loss: 0.06178392842411995\n",
      "Epoch 3646, Loss: 0.023301578126847744, Final Batch Loss: 0.013468775898218155\n",
      "Epoch 3647, Loss: 0.05711245629936457, Final Batch Loss: 0.01078315544873476\n",
      "Epoch 3648, Loss: 0.08568012807518244, Final Batch Loss: 0.006088816560804844\n",
      "Epoch 3649, Loss: 0.06406758725643158, Final Batch Loss: 0.031479611992836\n",
      "Epoch 3650, Loss: 0.04249753896147013, Final Batch Loss: 0.03148789703845978\n",
      "Epoch 3651, Loss: 0.01849741442129016, Final Batch Loss: 0.006322783883661032\n",
      "Epoch 3652, Loss: 0.02375683467835188, Final Batch Loss: 0.014405723661184311\n",
      "Epoch 3653, Loss: 0.049873052164912224, Final Batch Loss: 0.04165082052350044\n",
      "Epoch 3654, Loss: 0.14512383565306664, Final Batch Loss: 0.1270744502544403\n",
      "Epoch 3655, Loss: 0.032845498993992805, Final Batch Loss: 0.017972571775317192\n",
      "Epoch 3656, Loss: 0.04819794837385416, Final Batch Loss: 0.013470587320625782\n",
      "Epoch 3657, Loss: 0.03551311045885086, Final Batch Loss: 0.010783189907670021\n",
      "Epoch 3658, Loss: 0.03365245275199413, Final Batch Loss: 0.010513950139284134\n",
      "Epoch 3659, Loss: 0.06727842427790165, Final Batch Loss: 0.0552578940987587\n",
      "Epoch 3660, Loss: 0.053308652713894844, Final Batch Loss: 0.03265467658638954\n",
      "Epoch 3661, Loss: 0.03308551199734211, Final Batch Loss: 0.017797674983739853\n",
      "Epoch 3662, Loss: 0.0394835751503706, Final Batch Loss: 0.016541574150323868\n",
      "Epoch 3663, Loss: 0.0801162701100111, Final Batch Loss: 0.05845646187663078\n",
      "Epoch 3664, Loss: 0.060945089906454086, Final Batch Loss: 0.04069442301988602\n",
      "Epoch 3665, Loss: 0.0539780193939805, Final Batch Loss: 0.045495882630348206\n",
      "Epoch 3666, Loss: 0.10797763615846634, Final Batch Loss: 0.042210400104522705\n",
      "Epoch 3667, Loss: 0.042524050921201706, Final Batch Loss: 0.02311677299439907\n",
      "Epoch 3668, Loss: 0.02389720780774951, Final Batch Loss: 0.007284968625754118\n",
      "Epoch 3669, Loss: 0.03766932711005211, Final Batch Loss: 0.019504500553011894\n",
      "Epoch 3670, Loss: 0.03300975076854229, Final Batch Loss: 0.01567150466144085\n",
      "Epoch 3671, Loss: 0.04774954169988632, Final Batch Loss: 0.015916798263788223\n",
      "Epoch 3672, Loss: 0.022423474583774805, Final Batch Loss: 0.004458519164472818\n",
      "Epoch 3673, Loss: 0.025284694507718086, Final Batch Loss: 0.014453073032200336\n",
      "Epoch 3674, Loss: 0.05312666669487953, Final Batch Loss: 0.031195608898997307\n",
      "Epoch 3675, Loss: 0.03999239020049572, Final Batch Loss: 0.005134278908371925\n",
      "Epoch 3676, Loss: 0.0377876702696085, Final Batch Loss: 0.02945222333073616\n",
      "Epoch 3677, Loss: 0.037864421494305134, Final Batch Loss: 0.024200748652219772\n",
      "Epoch 3678, Loss: 0.008525768760591745, Final Batch Loss: 0.003486625850200653\n",
      "Epoch 3679, Loss: 0.05285780690610409, Final Batch Loss: 0.011016888543963432\n",
      "Epoch 3680, Loss: 0.017081611789762974, Final Batch Loss: 0.004605915397405624\n",
      "Epoch 3681, Loss: 0.05832207202911377, Final Batch Loss: 0.042041897773742676\n",
      "Epoch 3682, Loss: 0.07464072853326797, Final Batch Loss: 0.0271528959274292\n",
      "Epoch 3683, Loss: 0.03419274464249611, Final Batch Loss: 0.03082512505352497\n",
      "Epoch 3684, Loss: 0.14084997028112411, Final Batch Loss: 0.07781563699245453\n",
      "Epoch 3685, Loss: 0.05662946216762066, Final Batch Loss: 0.024737300351262093\n",
      "Epoch 3686, Loss: 0.0970592126250267, Final Batch Loss: 0.02194037288427353\n",
      "Epoch 3687, Loss: 0.12285604700446129, Final Batch Loss: 0.08576736599206924\n",
      "Epoch 3688, Loss: 0.05438490491360426, Final Batch Loss: 0.04149084538221359\n",
      "Epoch 3689, Loss: 0.028401754796504974, Final Batch Loss: 0.01200651004910469\n",
      "Epoch 3690, Loss: 0.04401147458702326, Final Batch Loss: 0.010713317431509495\n",
      "Epoch 3691, Loss: 0.06756816990673542, Final Batch Loss: 0.025159647688269615\n",
      "Epoch 3692, Loss: 0.0272566806524992, Final Batch Loss: 0.003916345536708832\n",
      "Epoch 3693, Loss: 0.06077335961163044, Final Batch Loss: 0.012101275846362114\n",
      "Epoch 3694, Loss: 0.05319163762032986, Final Batch Loss: 0.044766176491975784\n",
      "Epoch 3695, Loss: 0.07092309929430485, Final Batch Loss: 0.00868316926062107\n",
      "Epoch 3696, Loss: 0.012536431895568967, Final Batch Loss: 0.0038006932009011507\n",
      "Epoch 3697, Loss: 0.03458339907228947, Final Batch Loss: 0.0041374824941158295\n",
      "Epoch 3698, Loss: 0.06537198554724455, Final Batch Loss: 0.0548546202480793\n",
      "Epoch 3699, Loss: 0.11153975501656532, Final Batch Loss: 0.04520637169480324\n",
      "Epoch 3700, Loss: 0.03807096555829048, Final Batch Loss: 0.013236131519079208\n",
      "Epoch 3701, Loss: 0.10763829573988914, Final Batch Loss: 0.0706239566206932\n",
      "Epoch 3702, Loss: 0.02946949377655983, Final Batch Loss: 0.01676415465772152\n",
      "Epoch 3703, Loss: 0.07401396706700325, Final Batch Loss: 0.06001662462949753\n",
      "Epoch 3704, Loss: 0.105143703520298, Final Batch Loss: 0.07852565497159958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3705, Loss: 0.15277544409036636, Final Batch Loss: 0.11220377683639526\n",
      "Epoch 3706, Loss: 0.06415324844419956, Final Batch Loss: 0.04353305697441101\n",
      "Epoch 3707, Loss: 0.08247093856334686, Final Batch Loss: 0.026232846081256866\n",
      "Epoch 3708, Loss: 0.04883161559700966, Final Batch Loss: 0.008908428251743317\n",
      "Epoch 3709, Loss: 0.029161409940570593, Final Batch Loss: 0.006301175337284803\n",
      "Epoch 3710, Loss: 0.041434429585933685, Final Batch Loss: 0.015271617099642754\n",
      "Epoch 3711, Loss: 0.027921438217163086, Final Batch Loss: 0.011621423065662384\n",
      "Epoch 3712, Loss: 0.049613882787525654, Final Batch Loss: 0.009316463954746723\n",
      "Epoch 3713, Loss: 0.08085170388221741, Final Batch Loss: 0.05373470112681389\n",
      "Epoch 3714, Loss: 0.031070801429450512, Final Batch Loss: 0.012262622825801373\n",
      "Epoch 3715, Loss: 0.049157554283738136, Final Batch Loss: 0.01563381962478161\n",
      "Epoch 3716, Loss: 0.07337291724979877, Final Batch Loss: 0.06568152457475662\n",
      "Epoch 3717, Loss: 0.04150936845690012, Final Batch Loss: 0.030425164848566055\n",
      "Epoch 3718, Loss: 0.031691182404756546, Final Batch Loss: 0.015307961031794548\n",
      "Epoch 3719, Loss: 0.09571311436593533, Final Batch Loss: 0.07018277794122696\n",
      "Epoch 3720, Loss: 0.015279663261026144, Final Batch Loss: 0.007058918010443449\n",
      "Epoch 3721, Loss: 0.06620592996478081, Final Batch Loss: 0.018967516720294952\n",
      "Epoch 3722, Loss: 0.06778598204255104, Final Batch Loss: 0.03903687745332718\n",
      "Epoch 3723, Loss: 0.017536811996251345, Final Batch Loss: 0.0072611612267792225\n",
      "Epoch 3724, Loss: 0.0700929332524538, Final Batch Loss: 0.01623690314590931\n",
      "Epoch 3725, Loss: 0.06342018395662308, Final Batch Loss: 0.017028510570526123\n",
      "Epoch 3726, Loss: 0.03558098152279854, Final Batch Loss: 0.01989300735294819\n",
      "Epoch 3727, Loss: 0.01834512408822775, Final Batch Loss: 0.010548783466219902\n",
      "Epoch 3728, Loss: 0.07445903494954109, Final Batch Loss: 0.041314758360385895\n",
      "Epoch 3729, Loss: 0.054187942296266556, Final Batch Loss: 0.0063772052526474\n",
      "Epoch 3730, Loss: 0.040581983514130116, Final Batch Loss: 0.012736679054796696\n",
      "Epoch 3731, Loss: 0.033964415080845356, Final Batch Loss: 0.022538885474205017\n",
      "Epoch 3732, Loss: 0.09486490860581398, Final Batch Loss: 0.016014184802770615\n",
      "Epoch 3733, Loss: 0.062484825029969215, Final Batch Loss: 0.03223450854420662\n",
      "Epoch 3734, Loss: 0.04088419210165739, Final Batch Loss: 0.011232429184019566\n",
      "Epoch 3735, Loss: 0.02361613721586764, Final Batch Loss: 0.0038552714977413416\n",
      "Epoch 3736, Loss: 0.0544628594070673, Final Batch Loss: 0.04853503778576851\n",
      "Epoch 3737, Loss: 0.047735098749399185, Final Batch Loss: 0.028277596458792686\n",
      "Epoch 3738, Loss: 0.049854228273034096, Final Batch Loss: 0.017990263178944588\n",
      "Epoch 3739, Loss: 0.06465024314820766, Final Batch Loss: 0.05677466839551926\n",
      "Epoch 3740, Loss: 0.05169605929404497, Final Batch Loss: 0.04564213007688522\n",
      "Epoch 3741, Loss: 0.02371716871857643, Final Batch Loss: 0.013757898472249508\n",
      "Epoch 3742, Loss: 0.034105136059224606, Final Batch Loss: 0.02676250971853733\n",
      "Epoch 3743, Loss: 0.07669481448829174, Final Batch Loss: 0.06617879867553711\n",
      "Epoch 3744, Loss: 0.06007286719977856, Final Batch Loss: 0.03569234535098076\n",
      "Epoch 3745, Loss: 0.021318646147847176, Final Batch Loss: 0.007843181490898132\n",
      "Epoch 3746, Loss: 0.06674821302294731, Final Batch Loss: 0.025494687259197235\n",
      "Epoch 3747, Loss: 0.016943474765866995, Final Batch Loss: 0.010326878167688847\n",
      "Epoch 3748, Loss: 0.14086055755615234, Final Batch Loss: 0.07784052938222885\n",
      "Epoch 3749, Loss: 0.027921634260565042, Final Batch Loss: 0.005983822513371706\n",
      "Epoch 3750, Loss: 0.011475985869765282, Final Batch Loss: 0.0073749227449297905\n",
      "Epoch 3751, Loss: 0.029159358702600002, Final Batch Loss: 0.015624681487679482\n",
      "Epoch 3752, Loss: 0.018205204978585243, Final Batch Loss: 0.006903176195919514\n",
      "Epoch 3753, Loss: 0.020254029892385006, Final Batch Loss: 0.010870651341974735\n",
      "Epoch 3754, Loss: 0.016036710469052196, Final Batch Loss: 0.0037924933712929487\n",
      "Epoch 3755, Loss: 0.0909982267767191, Final Batch Loss: 0.01257290132343769\n",
      "Epoch 3756, Loss: 0.07323667407035828, Final Batch Loss: 0.044848598539829254\n",
      "Epoch 3757, Loss: 0.042542160488665104, Final Batch Loss: 0.03466564416885376\n",
      "Epoch 3758, Loss: 0.017929475754499435, Final Batch Loss: 0.009187251329421997\n",
      "Epoch 3759, Loss: 0.03984383214265108, Final Batch Loss: 0.015291673131287098\n",
      "Epoch 3760, Loss: 0.02071523480117321, Final Batch Loss: 0.008683493360877037\n",
      "Epoch 3761, Loss: 0.0402890108525753, Final Batch Loss: 0.02997242473065853\n",
      "Epoch 3762, Loss: 0.02309140097349882, Final Batch Loss: 0.0137910395860672\n",
      "Epoch 3763, Loss: 0.05770627874881029, Final Batch Loss: 0.05096166208386421\n",
      "Epoch 3764, Loss: 0.024760919623076916, Final Batch Loss: 0.014330152422189713\n",
      "Epoch 3765, Loss: 0.04196244850754738, Final Batch Loss: 0.011572929099202156\n",
      "Epoch 3766, Loss: 0.03277208376675844, Final Batch Loss: 0.013678490184247494\n",
      "Epoch 3767, Loss: 0.07649649679660797, Final Batch Loss: 0.0413975827395916\n",
      "Epoch 3768, Loss: 0.04319864884018898, Final Batch Loss: 0.023351535201072693\n",
      "Epoch 3769, Loss: 0.016730101313441992, Final Batch Loss: 0.004561154637485743\n",
      "Epoch 3770, Loss: 0.02933918498456478, Final Batch Loss: 0.009547937661409378\n",
      "Epoch 3771, Loss: 0.052252464927732944, Final Batch Loss: 0.00832382682710886\n",
      "Epoch 3772, Loss: 0.12973086163401604, Final Batch Loss: 0.09744928032159805\n",
      "Epoch 3773, Loss: 0.013708637095987797, Final Batch Loss: 0.004779385402798653\n",
      "Epoch 3774, Loss: 0.05655192816630006, Final Batch Loss: 0.004323887173086405\n",
      "Epoch 3775, Loss: 0.042781311087310314, Final Batch Loss: 0.004555790685117245\n",
      "Epoch 3776, Loss: 0.06989935133606195, Final Batch Loss: 0.058798182755708694\n",
      "Epoch 3777, Loss: 0.041889723390340805, Final Batch Loss: 0.01576325297355652\n",
      "Epoch 3778, Loss: 0.031160129234194756, Final Batch Loss: 0.020824765786528587\n",
      "Epoch 3779, Loss: 0.02943006344139576, Final Batch Loss: 0.0061186254024505615\n",
      "Epoch 3780, Loss: 0.07339533790946007, Final Batch Loss: 0.054766733199357986\n",
      "Epoch 3781, Loss: 0.024691956117749214, Final Batch Loss: 0.0091980816796422\n",
      "Epoch 3782, Loss: 0.03583708917722106, Final Batch Loss: 0.007411855738610029\n",
      "Epoch 3783, Loss: 0.04103521257638931, Final Batch Loss: 0.0193795058876276\n",
      "Epoch 3784, Loss: 0.07439124956727028, Final Batch Loss: 0.04510170593857765\n",
      "Epoch 3785, Loss: 0.049150481820106506, Final Batch Loss: 0.01571260765194893\n",
      "Epoch 3786, Loss: 0.020369472913444042, Final Batch Loss: 0.006557338871061802\n",
      "Epoch 3787, Loss: 0.04363678954541683, Final Batch Loss: 0.011140374466776848\n",
      "Epoch 3788, Loss: 0.07016521226614714, Final Batch Loss: 0.008732064627110958\n",
      "Epoch 3789, Loss: 0.019625856541097164, Final Batch Loss: 0.00397090706974268\n",
      "Epoch 3790, Loss: 0.03444450069218874, Final Batch Loss: 0.022763583809137344\n",
      "Epoch 3791, Loss: 0.05063606984913349, Final Batch Loss: 0.030482914298772812\n",
      "Epoch 3792, Loss: 0.045948587357997894, Final Batch Loss: 0.019325925037264824\n",
      "Epoch 3793, Loss: 0.03626669477671385, Final Batch Loss: 0.011656693182885647\n",
      "Epoch 3794, Loss: 0.03317835880443454, Final Batch Loss: 0.02580343745648861\n",
      "Epoch 3795, Loss: 0.03769579529762268, Final Batch Loss: 0.020512038841843605\n",
      "Epoch 3796, Loss: 0.09179692342877388, Final Batch Loss: 0.050523847341537476\n",
      "Epoch 3797, Loss: 0.034205639734864235, Final Batch Loss: 0.013404101133346558\n",
      "Epoch 3798, Loss: 0.01596557442098856, Final Batch Loss: 0.004160746932029724\n",
      "Epoch 3799, Loss: 0.0549294613301754, Final Batch Loss: 0.036834716796875\n",
      "Epoch 3800, Loss: 0.013960456475615501, Final Batch Loss: 0.006647981237620115\n",
      "Epoch 3801, Loss: 0.08449504990130663, Final Batch Loss: 0.07476174086332321\n",
      "Epoch 3802, Loss: 0.023141699377447367, Final Batch Loss: 0.006017519626766443\n",
      "Epoch 3803, Loss: 0.04381414595991373, Final Batch Loss: 0.009322171099483967\n",
      "Epoch 3804, Loss: 0.035749963484704494, Final Batch Loss: 0.009140175767242908\n",
      "Epoch 3805, Loss: 0.02224139589816332, Final Batch Loss: 0.008199700154364109\n",
      "Epoch 3806, Loss: 0.050461187958717346, Final Batch Loss: 0.015828900039196014\n",
      "Epoch 3807, Loss: 0.06978528015315533, Final Batch Loss: 0.04864738881587982\n",
      "Epoch 3808, Loss: 0.029679552651941776, Final Batch Loss: 0.009624271653592587\n",
      "Epoch 3809, Loss: 0.02291337540373206, Final Batch Loss: 0.01863708905875683\n",
      "Epoch 3810, Loss: 0.013108714949339628, Final Batch Loss: 0.0060285464860498905\n",
      "Epoch 3811, Loss: 0.043846883811056614, Final Batch Loss: 0.014941169880330563\n",
      "Epoch 3812, Loss: 0.018978598527610302, Final Batch Loss: 0.009881376288831234\n",
      "Epoch 3813, Loss: 0.05174210062250495, Final Batch Loss: 0.007588209118694067\n",
      "Epoch 3814, Loss: 0.0516764335334301, Final Batch Loss: 0.029194887727499008\n",
      "Epoch 3815, Loss: 0.07803382910788059, Final Batch Loss: 0.01701418124139309\n",
      "Epoch 3816, Loss: 0.035912164486944675, Final Batch Loss: 0.01478153932839632\n",
      "Epoch 3817, Loss: 0.03212132444605231, Final Batch Loss: 0.006968410219997168\n",
      "Epoch 3818, Loss: 0.02850216254591942, Final Batch Loss: 0.018178705126047134\n",
      "Epoch 3819, Loss: 0.07549909874796867, Final Batch Loss: 0.036930520087480545\n",
      "Epoch 3820, Loss: 0.02153878239914775, Final Batch Loss: 0.006707416381686926\n",
      "Epoch 3821, Loss: 0.042886946350336075, Final Batch Loss: 0.01672101393342018\n",
      "Epoch 3822, Loss: 0.05741862999275327, Final Batch Loss: 0.05152080953121185\n",
      "Epoch 3823, Loss: 0.0451897494494915, Final Batch Loss: 0.021527649834752083\n",
      "Epoch 3824, Loss: 0.06410651840269566, Final Batch Loss: 0.02119576372206211\n",
      "Epoch 3825, Loss: 0.03953630290925503, Final Batch Loss: 0.01300809346139431\n",
      "Epoch 3826, Loss: 0.027446352876722813, Final Batch Loss: 0.014079511165618896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3827, Loss: 0.014633838087320328, Final Batch Loss: 0.008510460145771503\n",
      "Epoch 3828, Loss: 0.0441840598359704, Final Batch Loss: 0.014368354342877865\n",
      "Epoch 3829, Loss: 0.04781043529510498, Final Batch Loss: 0.02291313000023365\n",
      "Epoch 3830, Loss: 0.11856542527675629, Final Batch Loss: 0.10158348828554153\n",
      "Epoch 3831, Loss: 0.050251470878720284, Final Batch Loss: 0.011388024315237999\n",
      "Epoch 3832, Loss: 0.0434532081708312, Final Batch Loss: 0.03516767546534538\n",
      "Epoch 3833, Loss: 0.02937236148864031, Final Batch Loss: 0.02167251519858837\n",
      "Epoch 3834, Loss: 0.0465488713234663, Final Batch Loss: 0.03078589402139187\n",
      "Epoch 3835, Loss: 0.05243639461696148, Final Batch Loss: 0.038418255746364594\n",
      "Epoch 3836, Loss: 0.0328596793115139, Final Batch Loss: 0.015337446704506874\n",
      "Epoch 3837, Loss: 0.06626563332974911, Final Batch Loss: 0.02001274935901165\n",
      "Epoch 3838, Loss: 0.08143153786659241, Final Batch Loss: 0.030353069305419922\n",
      "Epoch 3839, Loss: 0.03260973282158375, Final Batch Loss: 0.017048601061105728\n",
      "Epoch 3840, Loss: 0.024753795936703682, Final Batch Loss: 0.006124291568994522\n",
      "Epoch 3841, Loss: 0.05789383873343468, Final Batch Loss: 0.021160580217838287\n",
      "Epoch 3842, Loss: 0.01364160468801856, Final Batch Loss: 0.004759724717587233\n",
      "Epoch 3843, Loss: 0.028199412394315004, Final Batch Loss: 0.020925305783748627\n",
      "Epoch 3844, Loss: 0.016608302481472492, Final Batch Loss: 0.006041848100721836\n",
      "Epoch 3845, Loss: 0.05650562606751919, Final Batch Loss: 0.009352380409836769\n",
      "Epoch 3846, Loss: 0.040919216349720955, Final Batch Loss: 0.01799706742167473\n",
      "Epoch 3847, Loss: 0.05617169290781021, Final Batch Loss: 0.020693909376859665\n",
      "Epoch 3848, Loss: 0.024529305286705494, Final Batch Loss: 0.012795843183994293\n",
      "Epoch 3849, Loss: 0.047223612666130066, Final Batch Loss: 0.02085818164050579\n",
      "Epoch 3850, Loss: 0.04192385450005531, Final Batch Loss: 0.025446824729442596\n",
      "Epoch 3851, Loss: 0.025421288795769215, Final Batch Loss: 0.005794051103293896\n",
      "Epoch 3852, Loss: 0.07281709276139736, Final Batch Loss: 0.055475521832704544\n",
      "Epoch 3853, Loss: 0.09942885488271713, Final Batch Loss: 0.049949124455451965\n",
      "Epoch 3854, Loss: 0.03429659456014633, Final Batch Loss: 0.016247989609837532\n",
      "Epoch 3855, Loss: 0.04578492697328329, Final Batch Loss: 0.03490833938121796\n",
      "Epoch 3856, Loss: 0.036808932200074196, Final Batch Loss: 0.025296740233898163\n",
      "Epoch 3857, Loss: 0.030412957072257996, Final Batch Loss: 0.0160779170691967\n",
      "Epoch 3858, Loss: 0.033969237934798, Final Batch Loss: 0.02796001173555851\n",
      "Epoch 3859, Loss: 0.01025781873613596, Final Batch Loss: 0.007757255807518959\n",
      "Epoch 3860, Loss: 0.06118752248585224, Final Batch Loss: 0.02002759464085102\n",
      "Epoch 3861, Loss: 0.05649057775735855, Final Batch Loss: 0.04478437080979347\n",
      "Epoch 3862, Loss: 0.04156557470560074, Final Batch Loss: 0.02099480666220188\n",
      "Epoch 3863, Loss: 0.029321508016437292, Final Batch Loss: 0.004753887187689543\n",
      "Epoch 3864, Loss: 0.022352322936058044, Final Batch Loss: 0.014055904932320118\n",
      "Epoch 3865, Loss: 0.05489989370107651, Final Batch Loss: 0.017191104590892792\n",
      "Epoch 3866, Loss: 0.04865429550409317, Final Batch Loss: 0.032322365790605545\n",
      "Epoch 3867, Loss: 0.08463533036410809, Final Batch Loss: 0.07500667124986649\n",
      "Epoch 3868, Loss: 0.06086267903447151, Final Batch Loss: 0.04135439917445183\n",
      "Epoch 3869, Loss: 0.05701317545026541, Final Batch Loss: 0.04405124858021736\n",
      "Epoch 3870, Loss: 0.049655078910291195, Final Batch Loss: 0.012906382791697979\n",
      "Epoch 3871, Loss: 0.03865448758006096, Final Batch Loss: 0.02121276780962944\n",
      "Epoch 3872, Loss: 0.07501999102532864, Final Batch Loss: 0.05275497958064079\n",
      "Epoch 3873, Loss: 0.037336841225624084, Final Batch Loss: 0.01362050324678421\n",
      "Epoch 3874, Loss: 0.026413624174892902, Final Batch Loss: 0.017882809042930603\n",
      "Epoch 3875, Loss: 0.025964205153286457, Final Batch Loss: 0.011695749126374722\n",
      "Epoch 3876, Loss: 0.10124186519533396, Final Batch Loss: 0.09282916784286499\n",
      "Epoch 3877, Loss: 0.02878059260547161, Final Batch Loss: 0.008852306753396988\n",
      "Epoch 3878, Loss: 0.16831136494874954, Final Batch Loss: 0.1358080953359604\n",
      "Epoch 3879, Loss: 0.019794032908976078, Final Batch Loss: 0.0063052913174033165\n",
      "Epoch 3880, Loss: 0.029483080841600895, Final Batch Loss: 0.021515678614377975\n",
      "Epoch 3881, Loss: 0.06513219326734543, Final Batch Loss: 0.03217947110533714\n",
      "Epoch 3882, Loss: 0.042446453124284744, Final Batch Loss: 0.029710466042160988\n",
      "Epoch 3883, Loss: 0.02183403354138136, Final Batch Loss: 0.009376379661262035\n",
      "Epoch 3884, Loss: 0.1305132694542408, Final Batch Loss: 0.09862640500068665\n",
      "Epoch 3885, Loss: 0.04104417376220226, Final Batch Loss: 0.012384919449687004\n",
      "Epoch 3886, Loss: 0.07189898565411568, Final Batch Loss: 0.04725053533911705\n",
      "Epoch 3887, Loss: 0.11179215088486671, Final Batch Loss: 0.08016464114189148\n",
      "Epoch 3888, Loss: 0.015387370251119137, Final Batch Loss: 0.007942927069962025\n",
      "Epoch 3889, Loss: 0.04348286986351013, Final Batch Loss: 0.016806749626994133\n",
      "Epoch 3890, Loss: 0.06235833279788494, Final Batch Loss: 0.03241639584302902\n",
      "Epoch 3891, Loss: 0.007428476121276617, Final Batch Loss: 0.00416593300178647\n",
      "Epoch 3892, Loss: 0.08759657479822636, Final Batch Loss: 0.06636752188205719\n",
      "Epoch 3893, Loss: 0.0558623131364584, Final Batch Loss: 0.03161470219492912\n",
      "Epoch 3894, Loss: 0.06527461670339108, Final Batch Loss: 0.018505195155739784\n",
      "Epoch 3895, Loss: 0.07078716345131397, Final Batch Loss: 0.01099337823688984\n",
      "Epoch 3896, Loss: 0.07787214778363705, Final Batch Loss: 0.0736708715558052\n",
      "Epoch 3897, Loss: 0.056785245425999165, Final Batch Loss: 0.045810386538505554\n",
      "Epoch 3898, Loss: 0.028509220108389854, Final Batch Loss: 0.017707092687487602\n",
      "Epoch 3899, Loss: 0.018745743669569492, Final Batch Loss: 0.014192144386470318\n",
      "Epoch 3900, Loss: 0.05115910619497299, Final Batch Loss: 0.004226654767990112\n",
      "Epoch 3901, Loss: 0.03973313793540001, Final Batch Loss: 0.018673162907361984\n",
      "Epoch 3902, Loss: 0.041990446858108044, Final Batch Loss: 0.012713455595076084\n",
      "Epoch 3903, Loss: 0.08170571830123663, Final Batch Loss: 0.07073774933815002\n",
      "Epoch 3904, Loss: 0.020546863321214914, Final Batch Loss: 0.0036926274187862873\n",
      "Epoch 3905, Loss: 0.040072147734463215, Final Batch Loss: 0.008829821832478046\n",
      "Epoch 3906, Loss: 0.05221262760460377, Final Batch Loss: 0.03114967606961727\n",
      "Epoch 3907, Loss: 0.009689734783023596, Final Batch Loss: 0.0033836141228675842\n",
      "Epoch 3908, Loss: 0.024889987893402576, Final Batch Loss: 0.010111010633409023\n",
      "Epoch 3909, Loss: 0.05283062346279621, Final Batch Loss: 0.008405784144997597\n",
      "Epoch 3910, Loss: 0.04554542899131775, Final Batch Loss: 0.011790875345468521\n",
      "Epoch 3911, Loss: 0.023352027870714664, Final Batch Loss: 0.011265518143773079\n",
      "Epoch 3912, Loss: 0.018500240053981543, Final Batch Loss: 0.004408903885632753\n",
      "Epoch 3913, Loss: 0.07643178850412369, Final Batch Loss: 0.05983290821313858\n",
      "Epoch 3914, Loss: 0.021868949756026268, Final Batch Loss: 0.0076994383707642555\n",
      "Epoch 3915, Loss: 0.020842759869992733, Final Batch Loss: 0.014050796627998352\n",
      "Epoch 3916, Loss: 0.03205391298979521, Final Batch Loss: 0.014911930076777935\n",
      "Epoch 3917, Loss: 0.04688332602381706, Final Batch Loss: 0.030817491933703423\n",
      "Epoch 3918, Loss: 0.03225476434454322, Final Batch Loss: 0.025485027581453323\n",
      "Epoch 3919, Loss: 0.03322688024491072, Final Batch Loss: 0.011774563230574131\n",
      "Epoch 3920, Loss: 0.053307805210351944, Final Batch Loss: 0.027441658079624176\n",
      "Epoch 3921, Loss: 0.03494483744725585, Final Batch Loss: 0.003975374158471823\n",
      "Epoch 3922, Loss: 0.020686145406216383, Final Batch Loss: 0.005998362321406603\n",
      "Epoch 3923, Loss: 0.05133538134396076, Final Batch Loss: 0.040536731481552124\n",
      "Epoch 3924, Loss: 0.04603518918156624, Final Batch Loss: 0.021993370726704597\n",
      "Epoch 3925, Loss: 0.02047864906489849, Final Batch Loss: 0.005766577087342739\n",
      "Epoch 3926, Loss: 0.029877539724111557, Final Batch Loss: 0.01761355996131897\n",
      "Epoch 3927, Loss: 0.019231639220379293, Final Batch Loss: 0.0019308974733576179\n",
      "Epoch 3928, Loss: 0.0448028240352869, Final Batch Loss: 0.01731930486857891\n",
      "Epoch 3929, Loss: 0.014820349402725697, Final Batch Loss: 0.00581641960889101\n",
      "Epoch 3930, Loss: 0.021233337000012398, Final Batch Loss: 0.010195310227572918\n",
      "Epoch 3931, Loss: 0.046115209348499775, Final Batch Loss: 0.00837783608585596\n",
      "Epoch 3932, Loss: 0.02134280325844884, Final Batch Loss: 0.002562990877777338\n",
      "Epoch 3933, Loss: 0.07914742873981595, Final Batch Loss: 0.0027337674982845783\n",
      "Epoch 3934, Loss: 0.05783869652077556, Final Batch Loss: 0.002399373333901167\n",
      "Epoch 3935, Loss: 0.010500703938305378, Final Batch Loss: 0.004104397725313902\n",
      "Epoch 3936, Loss: 0.03629430569708347, Final Batch Loss: 0.012861404567956924\n",
      "Epoch 3937, Loss: 0.013345833634957671, Final Batch Loss: 0.0021498471032828093\n",
      "Epoch 3938, Loss: 0.017037034034729004, Final Batch Loss: 0.01000222284346819\n",
      "Epoch 3939, Loss: 0.10639332374557853, Final Batch Loss: 0.006217868532985449\n",
      "Epoch 3940, Loss: 0.03220731904730201, Final Batch Loss: 0.004678343888372183\n",
      "Epoch 3941, Loss: 0.02695256471633911, Final Batch Loss: 0.011300142854452133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3942, Loss: 0.06919648870825768, Final Batch Loss: 0.04743311554193497\n",
      "Epoch 3943, Loss: 0.02810753509402275, Final Batch Loss: 0.01280286256223917\n",
      "Epoch 3944, Loss: 0.03855283744633198, Final Batch Loss: 0.024815307930111885\n",
      "Epoch 3945, Loss: 0.08852456510066986, Final Batch Loss: 0.04611749202013016\n",
      "Epoch 3946, Loss: 0.08607198856770992, Final Batch Loss: 0.06409071385860443\n",
      "Epoch 3947, Loss: 0.09978401474654675, Final Batch Loss: 0.073602095246315\n",
      "Epoch 3948, Loss: 0.04413552023470402, Final Batch Loss: 0.028940092772245407\n",
      "Epoch 3949, Loss: 0.03497085813432932, Final Batch Loss: 0.010053918696939945\n",
      "Epoch 3950, Loss: 0.06720372475683689, Final Batch Loss: 0.012462010607123375\n",
      "Epoch 3951, Loss: 0.07221228955313563, Final Batch Loss: 0.0072831097058951855\n",
      "Epoch 3952, Loss: 0.023901340551674366, Final Batch Loss: 0.010424645617604256\n",
      "Epoch 3953, Loss: 0.029754512943327427, Final Batch Loss: 0.009808504022657871\n",
      "Epoch 3954, Loss: 0.01834066491574049, Final Batch Loss: 0.007203701883554459\n",
      "Epoch 3955, Loss: 0.03684740234166384, Final Batch Loss: 0.007829573936760426\n",
      "Epoch 3956, Loss: 0.00948552112095058, Final Batch Loss: 0.00321635021828115\n",
      "Epoch 3957, Loss: 0.02913021482527256, Final Batch Loss: 0.007947802543640137\n",
      "Epoch 3958, Loss: 0.04085006471723318, Final Batch Loss: 0.006930622272193432\n",
      "Epoch 3959, Loss: 0.020322215743362904, Final Batch Loss: 0.011097212322056293\n",
      "Epoch 3960, Loss: 0.01944982772693038, Final Batch Loss: 0.014299173839390278\n",
      "Epoch 3961, Loss: 0.055549368262290955, Final Batch Loss: 0.023862827569246292\n",
      "Epoch 3962, Loss: 0.06773934327065945, Final Batch Loss: 0.02678809128701687\n",
      "Epoch 3963, Loss: 0.039545437321066856, Final Batch Loss: 0.01726284809410572\n",
      "Epoch 3964, Loss: 0.07675242330878973, Final Batch Loss: 0.06546296924352646\n",
      "Epoch 3965, Loss: 0.05572706647217274, Final Batch Loss: 0.03518384322524071\n",
      "Epoch 3966, Loss: 0.04010860063135624, Final Batch Loss: 0.00874815322458744\n",
      "Epoch 3967, Loss: 0.036860669031739235, Final Batch Loss: 0.018271174281835556\n",
      "Epoch 3968, Loss: 0.05762066692113876, Final Batch Loss: 0.010580882430076599\n",
      "Epoch 3969, Loss: 0.01648105029016733, Final Batch Loss: 0.005013729445636272\n",
      "Epoch 3970, Loss: 0.11850652657449245, Final Batch Loss: 0.09879162907600403\n",
      "Epoch 3971, Loss: 0.0170300486497581, Final Batch Loss: 0.005745592061430216\n",
      "Epoch 3972, Loss: 0.10696237161755562, Final Batch Loss: 0.06324171274900436\n",
      "Epoch 3973, Loss: 0.06756561156362295, Final Batch Loss: 0.05748840421438217\n",
      "Epoch 3974, Loss: 0.04284807667136192, Final Batch Loss: 0.01580256223678589\n",
      "Epoch 3975, Loss: 0.12429777905344963, Final Batch Loss: 0.08945410698652267\n",
      "Epoch 3976, Loss: 0.06271132826805115, Final Batch Loss: 0.034641362726688385\n",
      "Epoch 3977, Loss: 0.06655791774392128, Final Batch Loss: 0.03289152681827545\n",
      "Epoch 3978, Loss: 0.12472875416278839, Final Batch Loss: 0.06769261509180069\n",
      "Epoch 3979, Loss: 0.08297573775053024, Final Batch Loss: 0.034126460552215576\n",
      "Epoch 3980, Loss: 0.040809390135109425, Final Batch Loss: 0.02690725401043892\n",
      "Epoch 3981, Loss: 0.11916857771575451, Final Batch Loss: 0.0900549590587616\n",
      "Epoch 3982, Loss: 0.018249748274683952, Final Batch Loss: 0.008457032032310963\n",
      "Epoch 3983, Loss: 0.025674592703580856, Final Batch Loss: 0.012293335050344467\n",
      "Epoch 3984, Loss: 0.08496300503611565, Final Batch Loss: 0.06915225833654404\n",
      "Epoch 3985, Loss: 0.04433591617271304, Final Batch Loss: 0.03758654370903969\n",
      "Epoch 3986, Loss: 0.039900604635477066, Final Batch Loss: 0.025504959747195244\n",
      "Epoch 3987, Loss: 0.10617007315158844, Final Batch Loss: 0.07102449238300323\n",
      "Epoch 3988, Loss: 0.057877982035279274, Final Batch Loss: 0.031610701233148575\n",
      "Epoch 3989, Loss: 0.024838498327881098, Final Batch Loss: 0.004816931206732988\n",
      "Epoch 3990, Loss: 0.030680617317557335, Final Batch Loss: 0.016750214621424675\n",
      "Epoch 3991, Loss: 0.03756825253367424, Final Batch Loss: 0.025828892365098\n",
      "Epoch 3992, Loss: 0.07014554599300027, Final Batch Loss: 0.0059973509050905704\n",
      "Epoch 3993, Loss: 0.03690151125192642, Final Batch Loss: 0.027592990547418594\n",
      "Epoch 3994, Loss: 0.023000404238700867, Final Batch Loss: 0.013645119965076447\n",
      "Epoch 3995, Loss: 0.05759245902299881, Final Batch Loss: 0.012385636568069458\n",
      "Epoch 3996, Loss: 0.039160373620688915, Final Batch Loss: 0.014626643620431423\n",
      "Epoch 3997, Loss: 0.02031803037971258, Final Batch Loss: 0.010716031305491924\n",
      "Epoch 3998, Loss: 0.07213411666452885, Final Batch Loss: 0.05049295723438263\n",
      "Epoch 3999, Loss: 0.15257443115115166, Final Batch Loss: 0.09242229163646698\n",
      "Epoch 4000, Loss: 0.031552571803331375, Final Batch Loss: 0.015736036002635956\n",
      "Epoch 4001, Loss: 0.030242188833653927, Final Batch Loss: 0.019576378166675568\n",
      "Epoch 4002, Loss: 0.11091886647045612, Final Batch Loss: 0.02175881899893284\n",
      "Epoch 4003, Loss: 0.026012548245489597, Final Batch Loss: 0.008323014713823795\n",
      "Epoch 4004, Loss: 0.08657307177782059, Final Batch Loss: 0.06840075552463531\n",
      "Epoch 4005, Loss: 0.06639941222965717, Final Batch Loss: 0.023713307455182076\n",
      "Epoch 4006, Loss: 0.04989047348499298, Final Batch Loss: 0.019360361620783806\n",
      "Epoch 4007, Loss: 0.04318399913609028, Final Batch Loss: 0.017903583124279976\n",
      "Epoch 4008, Loss: 0.10133184865117073, Final Batch Loss: 0.06032631918787956\n",
      "Epoch 4009, Loss: 0.06923983804881573, Final Batch Loss: 0.03048364259302616\n",
      "Epoch 4010, Loss: 0.05631689727306366, Final Batch Loss: 0.029094798490405083\n",
      "Epoch 4011, Loss: 0.06494614528492093, Final Batch Loss: 0.007577091921120882\n",
      "Epoch 4012, Loss: 0.0374902063049376, Final Batch Loss: 0.005268795881420374\n",
      "Epoch 4013, Loss: 0.11735902354121208, Final Batch Loss: 0.07057303935289383\n",
      "Epoch 4014, Loss: 0.0320830000564456, Final Batch Loss: 0.011527462862432003\n",
      "Epoch 4015, Loss: 0.040811687707901, Final Batch Loss: 0.009834753349423409\n",
      "Epoch 4016, Loss: 0.05500704050064087, Final Batch Loss: 0.04264972731471062\n",
      "Epoch 4017, Loss: 0.06507881172001362, Final Batch Loss: 0.01869468204677105\n",
      "Epoch 4018, Loss: 0.07683738507330418, Final Batch Loss: 0.056220926344394684\n",
      "Epoch 4019, Loss: 0.13026438653469086, Final Batch Loss: 0.038334183394908905\n",
      "Epoch 4020, Loss: 0.024740582332015038, Final Batch Loss: 0.008100856095552444\n",
      "Epoch 4021, Loss: 0.03837983217090368, Final Batch Loss: 0.010845654644072056\n",
      "Epoch 4022, Loss: 0.08001492917537689, Final Batch Loss: 0.039615027606487274\n",
      "Epoch 4023, Loss: 0.03346307948231697, Final Batch Loss: 0.008653556928038597\n",
      "Epoch 4024, Loss: 0.09552095457911491, Final Batch Loss: 0.04723352566361427\n",
      "Epoch 4025, Loss: 0.08868922293186188, Final Batch Loss: 0.05285436660051346\n",
      "Epoch 4026, Loss: 0.07012755051255226, Final Batch Loss: 0.038561441004276276\n",
      "Epoch 4027, Loss: 0.04943177476525307, Final Batch Loss: 0.011477358639240265\n",
      "Epoch 4028, Loss: 0.044100732542574406, Final Batch Loss: 0.012470290996134281\n",
      "Epoch 4029, Loss: 0.0623213704675436, Final Batch Loss: 0.033171407878398895\n",
      "Epoch 4030, Loss: 0.041383939795196056, Final Batch Loss: 0.015525002963840961\n",
      "Epoch 4031, Loss: 0.038653336465358734, Final Batch Loss: 0.0224920604377985\n",
      "Epoch 4032, Loss: 0.0672573558986187, Final Batch Loss: 0.02886122465133667\n",
      "Epoch 4033, Loss: 0.023880360182374716, Final Batch Loss: 0.01704804226756096\n",
      "Epoch 4034, Loss: 0.025665283203125, Final Batch Loss: 0.009575413540005684\n",
      "Epoch 4035, Loss: 0.09326371364295483, Final Batch Loss: 0.06901656091213226\n",
      "Epoch 4036, Loss: 0.06193998362869024, Final Batch Loss: 0.014563693664968014\n",
      "Epoch 4037, Loss: 0.04466896364465356, Final Batch Loss: 0.0057291374541819096\n",
      "Epoch 4038, Loss: 0.01768683549016714, Final Batch Loss: 0.0054176682606339455\n",
      "Epoch 4039, Loss: 0.016463868785649538, Final Batch Loss: 0.009601252153515816\n",
      "Epoch 4040, Loss: 0.06704913824796677, Final Batch Loss: 0.03651125356554985\n",
      "Epoch 4041, Loss: 0.01992153190076351, Final Batch Loss: 0.010834853164851665\n",
      "Epoch 4042, Loss: 0.07861494086682796, Final Batch Loss: 0.070712611079216\n",
      "Epoch 4043, Loss: 0.04462108388543129, Final Batch Loss: 0.01476513221859932\n",
      "Epoch 4044, Loss: 0.015981282107532024, Final Batch Loss: 0.005417647771537304\n",
      "Epoch 4045, Loss: 0.04861668311059475, Final Batch Loss: 0.017756955698132515\n",
      "Epoch 4046, Loss: 0.023651978699490428, Final Batch Loss: 0.0024476766120642424\n",
      "Epoch 4047, Loss: 0.059508608654141426, Final Batch Loss: 0.028881728649139404\n",
      "Epoch 4048, Loss: 0.01261413306929171, Final Batch Loss: 0.003177858190611005\n",
      "Epoch 4049, Loss: 0.026411792263388634, Final Batch Loss: 0.017014030367136\n",
      "Epoch 4050, Loss: 0.0829579196870327, Final Batch Loss: 0.050394173711538315\n",
      "Epoch 4051, Loss: 0.02053552703000605, Final Batch Loss: 0.003109490731731057\n",
      "Epoch 4052, Loss: 0.11147605907171965, Final Batch Loss: 0.01518192421644926\n",
      "Epoch 4053, Loss: 0.0777057446539402, Final Batch Loss: 0.0577632337808609\n",
      "Epoch 4054, Loss: 0.07539331912994385, Final Batch Loss: 0.043194275349378586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4055, Loss: 0.03744946978986263, Final Batch Loss: 0.008956512436270714\n",
      "Epoch 4056, Loss: 0.034482880495488644, Final Batch Loss: 0.0100055867806077\n",
      "Epoch 4057, Loss: 0.01804943522438407, Final Batch Loss: 0.005796667654067278\n",
      "Epoch 4058, Loss: 0.04090003902092576, Final Batch Loss: 0.007553598377853632\n",
      "Epoch 4059, Loss: 0.05744762159883976, Final Batch Loss: 0.03819318115711212\n",
      "Epoch 4060, Loss: 0.022495513781905174, Final Batch Loss: 0.00791175477206707\n",
      "Epoch 4061, Loss: 0.0819418029859662, Final Batch Loss: 0.06823884695768356\n",
      "Epoch 4062, Loss: 0.08625960163772106, Final Batch Loss: 0.06971900165081024\n",
      "Epoch 4063, Loss: 0.05258621461689472, Final Batch Loss: 0.03708045557141304\n",
      "Epoch 4064, Loss: 0.02276240848004818, Final Batch Loss: 0.010334976017475128\n",
      "Epoch 4065, Loss: 0.01990767940878868, Final Batch Loss: 0.01075698621571064\n",
      "Epoch 4066, Loss: 0.10031679645180702, Final Batch Loss: 0.061605535447597504\n",
      "Epoch 4067, Loss: 0.020980537869036198, Final Batch Loss: 0.009328309446573257\n",
      "Epoch 4068, Loss: 0.030015972442924976, Final Batch Loss: 0.021061982959508896\n",
      "Epoch 4069, Loss: 0.012812038883566856, Final Batch Loss: 0.006939847953617573\n",
      "Epoch 4070, Loss: 0.051403021439909935, Final Batch Loss: 0.015109119936823845\n",
      "Epoch 4071, Loss: 0.04197724536061287, Final Batch Loss: 0.01852772943675518\n",
      "Epoch 4072, Loss: 0.08355993777513504, Final Batch Loss: 0.05620467662811279\n",
      "Epoch 4073, Loss: 0.020888619124889374, Final Batch Loss: 0.010259522125124931\n",
      "Epoch 4074, Loss: 0.03419334255158901, Final Batch Loss: 0.017361709848046303\n",
      "Epoch 4075, Loss: 0.03888374986127019, Final Batch Loss: 0.0066082593984901905\n",
      "Epoch 4076, Loss: 0.030633714981377125, Final Batch Loss: 0.015532213263213634\n",
      "Epoch 4077, Loss: 0.041961691342294216, Final Batch Loss: 0.008489842526614666\n",
      "Epoch 4078, Loss: 0.03903128858655691, Final Batch Loss: 0.008851361460983753\n",
      "Epoch 4079, Loss: 0.03244445659220219, Final Batch Loss: 0.014388907700777054\n",
      "Epoch 4080, Loss: 0.011089797830209136, Final Batch Loss: 0.003099462715908885\n",
      "Epoch 4081, Loss: 0.02190045779570937, Final Batch Loss: 0.006667726207524538\n",
      "Epoch 4082, Loss: 0.03707049507647753, Final Batch Loss: 0.030773619189858437\n",
      "Epoch 4083, Loss: 0.06718226429075003, Final Batch Loss: 0.013823761604726315\n",
      "Epoch 4084, Loss: 0.03330686083063483, Final Batch Loss: 0.005311119835823774\n",
      "Epoch 4085, Loss: 0.03615985903888941, Final Batch Loss: 0.009092009626328945\n",
      "Epoch 4086, Loss: 0.04491574130952358, Final Batch Loss: 0.009780706837773323\n",
      "Epoch 4087, Loss: 0.013681185664609075, Final Batch Loss: 0.0030337937641888857\n",
      "Epoch 4088, Loss: 0.04728674050420523, Final Batch Loss: 0.03421177342534065\n",
      "Epoch 4089, Loss: 0.025336558232083917, Final Batch Loss: 0.0034236779902130365\n",
      "Epoch 4090, Loss: 0.012602262198925018, Final Batch Loss: 0.004892128519713879\n",
      "Epoch 4091, Loss: 0.026989703997969627, Final Batch Loss: 0.013766368851065636\n",
      "Epoch 4092, Loss: 0.01631183596327901, Final Batch Loss: 0.006740973796695471\n",
      "Epoch 4093, Loss: 0.024205454625189304, Final Batch Loss: 0.010654634796082973\n",
      "Epoch 4094, Loss: 0.01291916100308299, Final Batch Loss: 0.006713420618325472\n",
      "Epoch 4095, Loss: 0.03411955572664738, Final Batch Loss: 0.008735671639442444\n",
      "Epoch 4096, Loss: 0.017097505973652005, Final Batch Loss: 0.0025906891096383333\n",
      "Epoch 4097, Loss: 0.029715852811932564, Final Batch Loss: 0.013805098831653595\n",
      "Epoch 4098, Loss: 0.022269622888416052, Final Batch Loss: 0.004367514979094267\n",
      "Epoch 4099, Loss: 0.07363558746874332, Final Batch Loss: 0.05345214903354645\n",
      "Epoch 4100, Loss: 0.02510559093207121, Final Batch Loss: 0.012242457829415798\n",
      "Epoch 4101, Loss: 0.03663057740777731, Final Batch Loss: 0.011262268759310246\n",
      "Epoch 4102, Loss: 0.019307922571897507, Final Batch Loss: 0.007968633435666561\n",
      "Epoch 4103, Loss: 0.014299395959824324, Final Batch Loss: 0.005125539842993021\n",
      "Epoch 4104, Loss: 0.05628104321658611, Final Batch Loss: 0.041544631123542786\n",
      "Epoch 4105, Loss: 0.05618210602551699, Final Batch Loss: 0.04492437094449997\n",
      "Epoch 4106, Loss: 0.08543353155255318, Final Batch Loss: 0.05020785704255104\n",
      "Epoch 4107, Loss: 0.06747879041358829, Final Batch Loss: 0.004439368378371\n",
      "Epoch 4108, Loss: 0.028508968651294708, Final Batch Loss: 0.020787836983799934\n",
      "Epoch 4109, Loss: 0.0684988871216774, Final Batch Loss: 0.04071119800209999\n",
      "Epoch 4110, Loss: 0.02759463246911764, Final Batch Loss: 0.008423532359302044\n",
      "Epoch 4111, Loss: 0.03161989338696003, Final Batch Loss: 0.008119704201817513\n",
      "Epoch 4112, Loss: 0.10459387395530939, Final Batch Loss: 0.0937809944152832\n",
      "Epoch 4113, Loss: 0.024161039851605892, Final Batch Loss: 0.015132126398384571\n",
      "Epoch 4114, Loss: 0.028587158769369125, Final Batch Loss: 0.012043299153447151\n",
      "Epoch 4115, Loss: 0.047305090352892876, Final Batch Loss: 0.025695761665701866\n",
      "Epoch 4116, Loss: 0.05507627176120877, Final Batch Loss: 0.05104876309633255\n",
      "Epoch 4117, Loss: 0.09050578996539116, Final Batch Loss: 0.04997417703270912\n",
      "Epoch 4118, Loss: 0.02622254192829132, Final Batch Loss: 0.010352762416005135\n",
      "Epoch 4119, Loss: 0.07571708038449287, Final Batch Loss: 0.0396481454372406\n",
      "Epoch 4120, Loss: 0.0411953441798687, Final Batch Loss: 0.01835692673921585\n",
      "Epoch 4121, Loss: 0.025448462925851345, Final Batch Loss: 0.006224437616765499\n",
      "Epoch 4122, Loss: 0.022046956233680248, Final Batch Loss: 0.00998507346957922\n",
      "Epoch 4123, Loss: 0.04497840814292431, Final Batch Loss: 0.03578157350420952\n",
      "Epoch 4124, Loss: 0.06787938624620438, Final Batch Loss: 0.024408698081970215\n",
      "Epoch 4125, Loss: 0.02696721162647009, Final Batch Loss: 0.01907697692513466\n",
      "Epoch 4126, Loss: 0.02173516061156988, Final Batch Loss: 0.008030365221202374\n",
      "Epoch 4127, Loss: 0.06130049750208855, Final Batch Loss: 0.03571801260113716\n",
      "Epoch 4128, Loss: 0.009211497846990824, Final Batch Loss: 0.003180726896971464\n",
      "Epoch 4129, Loss: 0.04147668834775686, Final Batch Loss: 0.007851063273847103\n",
      "Epoch 4130, Loss: 0.03720965422689915, Final Batch Loss: 0.020870693027973175\n",
      "Epoch 4131, Loss: 0.018628055229783058, Final Batch Loss: 0.005515489727258682\n",
      "Epoch 4132, Loss: 0.06256679259240627, Final Batch Loss: 0.005446793511509895\n",
      "Epoch 4133, Loss: 0.03950263373553753, Final Batch Loss: 0.018802190199494362\n",
      "Epoch 4134, Loss: 0.0579218789935112, Final Batch Loss: 0.03300773724913597\n",
      "Epoch 4135, Loss: 0.056737249717116356, Final Batch Loss: 0.017601868137717247\n",
      "Epoch 4136, Loss: 0.01443461049348116, Final Batch Loss: 0.007975252345204353\n",
      "Epoch 4137, Loss: 0.011843969114124775, Final Batch Loss: 0.007684152573347092\n",
      "Epoch 4138, Loss: 0.031570687890052795, Final Batch Loss: 0.022135743871331215\n",
      "Epoch 4139, Loss: 0.015641930513083935, Final Batch Loss: 0.009636687114834785\n",
      "Epoch 4140, Loss: 0.015347839333117008, Final Batch Loss: 0.0050708698108792305\n",
      "Epoch 4141, Loss: 0.01255741436034441, Final Batch Loss: 0.006329615134745836\n",
      "Epoch 4142, Loss: 0.04579437617212534, Final Batch Loss: 0.03198356553912163\n",
      "Epoch 4143, Loss: 0.09148742631077766, Final Batch Loss: 0.06289095431566238\n",
      "Epoch 4144, Loss: 0.13213886320590973, Final Batch Loss: 0.09619541466236115\n",
      "Epoch 4145, Loss: 0.03249340504407883, Final Batch Loss: 0.01966441608965397\n",
      "Epoch 4146, Loss: 0.029809636529535055, Final Batch Loss: 0.006901427637785673\n",
      "Epoch 4147, Loss: 0.07124720886349678, Final Batch Loss: 0.029197275638580322\n",
      "Epoch 4148, Loss: 0.01186975697055459, Final Batch Loss: 0.00458761490881443\n",
      "Epoch 4149, Loss: 0.01950035709887743, Final Batch Loss: 0.009280558675527573\n",
      "Epoch 4150, Loss: 0.048427924513816833, Final Batch Loss: 0.011643555015325546\n",
      "Epoch 4151, Loss: 0.05050046369433403, Final Batch Loss: 0.03777030482888222\n",
      "Epoch 4152, Loss: 0.02831000741571188, Final Batch Loss: 0.01404145359992981\n",
      "Epoch 4153, Loss: 0.016974343452602625, Final Batch Loss: 0.007230940740555525\n",
      "Epoch 4154, Loss: 0.03071286715567112, Final Batch Loss: 0.024632543325424194\n",
      "Epoch 4155, Loss: 0.018145849462598562, Final Batch Loss: 0.00744597939774394\n",
      "Epoch 4156, Loss: 0.10678344033658504, Final Batch Loss: 0.07761374861001968\n",
      "Epoch 4157, Loss: 0.04221719782799482, Final Batch Loss: 0.03197471797466278\n",
      "Epoch 4158, Loss: 0.12850358337163925, Final Batch Loss: 0.07210763543844223\n",
      "Epoch 4159, Loss: 0.018723072484135628, Final Batch Loss: 0.010050930082798004\n",
      "Epoch 4160, Loss: 0.05615147389471531, Final Batch Loss: 0.023110507056117058\n",
      "Epoch 4161, Loss: 0.05740965437144041, Final Batch Loss: 0.015159889124333858\n",
      "Epoch 4162, Loss: 0.027327965013682842, Final Batch Loss: 0.014716693200170994\n",
      "Epoch 4163, Loss: 0.10621272400021553, Final Batch Loss: 0.04410809651017189\n",
      "Epoch 4164, Loss: 0.03862995654344559, Final Batch Loss: 0.025004329159855843\n",
      "Epoch 4165, Loss: 0.0450199143961072, Final Batch Loss: 0.03185409680008888\n",
      "Epoch 4166, Loss: 0.02034568740054965, Final Batch Loss: 0.013025893829762936\n",
      "Epoch 4167, Loss: 0.026621422730386257, Final Batch Loss: 0.009111977182328701\n",
      "Epoch 4168, Loss: 0.05443643406033516, Final Batch Loss: 0.026510458439588547\n",
      "Epoch 4169, Loss: 0.054470366798341274, Final Batch Loss: 0.04733757674694061\n",
      "Epoch 4170, Loss: 0.041822025435976684, Final Batch Loss: 0.0017512681661173701\n",
      "Epoch 4171, Loss: 0.02270106878131628, Final Batch Loss: 0.014593347907066345\n",
      "Epoch 4172, Loss: 0.020934537053108215, Final Batch Loss: 0.004829609766602516\n",
      "Epoch 4173, Loss: 0.08939368277788162, Final Batch Loss: 0.028564326465129852\n",
      "Epoch 4174, Loss: 0.05004703067243099, Final Batch Loss: 0.03166137635707855\n",
      "Epoch 4175, Loss: 0.05633944272994995, Final Batch Loss: 0.014680221676826477\n",
      "Epoch 4176, Loss: 0.11089112982153893, Final Batch Loss: 0.06343750655651093\n",
      "Epoch 4177, Loss: 0.01743457932025194, Final Batch Loss: 0.01234865840524435\n",
      "Epoch 4178, Loss: 0.07842404022812843, Final Batch Loss: 0.0334424190223217\n",
      "Epoch 4179, Loss: 0.06234999652951956, Final Batch Loss: 0.013697548769414425\n",
      "Epoch 4180, Loss: 0.014769277535378933, Final Batch Loss: 0.009669934399425983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4181, Loss: 0.05182209238409996, Final Batch Loss: 0.009447555989027023\n",
      "Epoch 4182, Loss: 0.023896920960396528, Final Batch Loss: 0.003319119568914175\n",
      "Epoch 4183, Loss: 0.04702698811888695, Final Batch Loss: 0.018325168639421463\n",
      "Epoch 4184, Loss: 0.04205274023115635, Final Batch Loss: 0.030556369572877884\n",
      "Epoch 4185, Loss: 0.03033268451690674, Final Batch Loss: 0.020940912887454033\n",
      "Epoch 4186, Loss: 0.035716161131858826, Final Batch Loss: 0.02480827271938324\n",
      "Epoch 4187, Loss: 0.04363386705517769, Final Batch Loss: 0.018851717934012413\n",
      "Epoch 4188, Loss: 0.0459337318316102, Final Batch Loss: 0.03683151304721832\n",
      "Epoch 4189, Loss: 0.04080453282222152, Final Batch Loss: 0.03385201096534729\n",
      "Epoch 4190, Loss: 0.07301472220569849, Final Batch Loss: 0.011975971050560474\n",
      "Epoch 4191, Loss: 0.13722523674368858, Final Batch Loss: 0.08961132168769836\n",
      "Epoch 4192, Loss: 0.08283401886001229, Final Batch Loss: 0.006085342261940241\n",
      "Epoch 4193, Loss: 0.05722927674651146, Final Batch Loss: 0.022530462592840195\n",
      "Epoch 4194, Loss: 0.027096016332507133, Final Batch Loss: 0.021634802222251892\n",
      "Epoch 4195, Loss: 0.022414528764784336, Final Batch Loss: 0.006760039366781712\n",
      "Epoch 4196, Loss: 0.02281917817890644, Final Batch Loss: 0.009289455600082874\n",
      "Epoch 4197, Loss: 0.022301977965980768, Final Batch Loss: 0.007369934115558863\n",
      "Epoch 4198, Loss: 0.020607561338692904, Final Batch Loss: 0.006813790183514357\n",
      "Epoch 4199, Loss: 0.038266371935606, Final Batch Loss: 0.021246563643217087\n",
      "Epoch 4200, Loss: 0.03622819064185023, Final Batch Loss: 0.005642326083034277\n",
      "Epoch 4201, Loss: 0.05411983281373978, Final Batch Loss: 0.03445088118314743\n",
      "Epoch 4202, Loss: 0.03947514109313488, Final Batch Loss: 0.02844557724893093\n",
      "Epoch 4203, Loss: 0.020362702198326588, Final Batch Loss: 0.009453395381569862\n",
      "Epoch 4204, Loss: 0.043401895090937614, Final Batch Loss: 0.03517758846282959\n",
      "Epoch 4205, Loss: 0.06667344644665718, Final Batch Loss: 0.029332943260669708\n",
      "Epoch 4206, Loss: 0.04324541613459587, Final Batch Loss: 0.01587282493710518\n",
      "Epoch 4207, Loss: 0.040775964967906475, Final Batch Loss: 0.015379448421299458\n",
      "Epoch 4208, Loss: 0.02254959661513567, Final Batch Loss: 0.007247284986078739\n",
      "Epoch 4209, Loss: 0.04773406684398651, Final Batch Loss: 0.020589428022503853\n",
      "Epoch 4210, Loss: 0.016993626952171326, Final Batch Loss: 0.007485603913664818\n",
      "Epoch 4211, Loss: 0.024517112411558628, Final Batch Loss: 0.012581110931932926\n",
      "Epoch 4212, Loss: 0.05515722930431366, Final Batch Loss: 0.02785617485642433\n",
      "Epoch 4213, Loss: 0.03269382566213608, Final Batch Loss: 0.009197989478707314\n",
      "Epoch 4214, Loss: 0.05851213354617357, Final Batch Loss: 0.04558232054114342\n",
      "Epoch 4215, Loss: 0.015257070306688547, Final Batch Loss: 0.0063533359207212925\n",
      "Epoch 4216, Loss: 0.031129632145166397, Final Batch Loss: 0.02197415381669998\n",
      "Epoch 4217, Loss: 0.021467885933816433, Final Batch Loss: 0.01692971959710121\n",
      "Epoch 4218, Loss: 0.04079734068363905, Final Batch Loss: 0.013433906249701977\n",
      "Epoch 4219, Loss: 0.014907944481819868, Final Batch Loss: 0.009883715771138668\n",
      "Epoch 4220, Loss: 0.029316937550902367, Final Batch Loss: 0.021021971479058266\n",
      "Epoch 4221, Loss: 0.04099954850971699, Final Batch Loss: 0.031085554510354996\n",
      "Epoch 4222, Loss: 0.03533823974430561, Final Batch Loss: 0.01732858270406723\n",
      "Epoch 4223, Loss: 0.02865382982417941, Final Batch Loss: 0.006968011613935232\n",
      "Epoch 4224, Loss: 0.04297796590253711, Final Batch Loss: 0.037527669221162796\n",
      "Epoch 4225, Loss: 0.0218095313757658, Final Batch Loss: 0.007579854689538479\n",
      "Epoch 4226, Loss: 0.018662136048078537, Final Batch Loss: 0.009224976412951946\n",
      "Epoch 4227, Loss: 0.03881210368126631, Final Batch Loss: 0.03557053208351135\n",
      "Epoch 4228, Loss: 0.008630200289189816, Final Batch Loss: 0.004313729703426361\n",
      "Epoch 4229, Loss: 0.04520353628322482, Final Batch Loss: 0.041059479117393494\n",
      "Epoch 4230, Loss: 0.07408758252859116, Final Batch Loss: 0.051257334649562836\n",
      "Epoch 4231, Loss: 0.01979987882077694, Final Batch Loss: 0.007581355050206184\n",
      "Epoch 4232, Loss: 0.043461652006953955, Final Batch Loss: 0.03577226400375366\n",
      "Epoch 4233, Loss: 0.029132465831935406, Final Batch Loss: 0.010362627916038036\n",
      "Epoch 4234, Loss: 0.024795391596853733, Final Batch Loss: 0.007811295799911022\n",
      "Epoch 4235, Loss: 0.03962571732699871, Final Batch Loss: 0.01654837094247341\n",
      "Epoch 4236, Loss: 0.017211359925568104, Final Batch Loss: 0.00799272209405899\n",
      "Epoch 4237, Loss: 0.13951455801725388, Final Batch Loss: 0.05869017541408539\n",
      "Epoch 4238, Loss: 0.05581522919237614, Final Batch Loss: 0.02191879414021969\n",
      "Epoch 4239, Loss: 0.013141121715307236, Final Batch Loss: 0.006211114581674337\n",
      "Epoch 4240, Loss: 0.029844422824680805, Final Batch Loss: 0.010947625152766705\n",
      "Epoch 4241, Loss: 0.036509512923657894, Final Batch Loss: 0.0106050418689847\n",
      "Epoch 4242, Loss: 0.0578371649608016, Final Batch Loss: 0.01285365130752325\n",
      "Epoch 4243, Loss: 0.015292691066861153, Final Batch Loss: 0.004734393209218979\n",
      "Epoch 4244, Loss: 0.016499264631420374, Final Batch Loss: 0.004069179762154818\n",
      "Epoch 4245, Loss: 0.02880443725734949, Final Batch Loss: 0.012313184328377247\n",
      "Epoch 4246, Loss: 0.09618186205625534, Final Batch Loss: 0.04540158063173294\n",
      "Epoch 4247, Loss: 0.03832166828215122, Final Batch Loss: 0.012921852990984917\n",
      "Epoch 4248, Loss: 0.015563668683171272, Final Batch Loss: 0.00432472862303257\n",
      "Epoch 4249, Loss: 0.04463565116748214, Final Batch Loss: 0.00653766980394721\n",
      "Epoch 4250, Loss: 0.062006800435483456, Final Batch Loss: 0.0471639446914196\n",
      "Epoch 4251, Loss: 0.057261256501078606, Final Batch Loss: 0.019830087199807167\n",
      "Epoch 4252, Loss: 0.02457627607509494, Final Batch Loss: 0.004381093662232161\n",
      "Epoch 4253, Loss: 0.04997543338686228, Final Batch Loss: 0.009060018695890903\n",
      "Epoch 4254, Loss: 0.20466600731015205, Final Batch Loss: 0.1621880978345871\n",
      "Epoch 4255, Loss: 0.03514059167355299, Final Batch Loss: 0.01958124153316021\n",
      "Epoch 4256, Loss: 0.02500234544277191, Final Batch Loss: 0.014829621650278568\n",
      "Epoch 4257, Loss: 0.12769949063658714, Final Batch Loss: 0.06658391654491425\n",
      "Epoch 4258, Loss: 0.06107722409069538, Final Batch Loss: 0.022924968972802162\n",
      "Epoch 4259, Loss: 0.06585615500807762, Final Batch Loss: 0.011170703917741776\n",
      "Epoch 4260, Loss: 0.04927387461066246, Final Batch Loss: 0.026459794491529465\n",
      "Epoch 4261, Loss: 0.06537897419184446, Final Batch Loss: 0.04984743893146515\n",
      "Epoch 4262, Loss: 0.02932857722043991, Final Batch Loss: 0.011437740176916122\n",
      "Epoch 4263, Loss: 0.040689622052013874, Final Batch Loss: 0.01547189336270094\n",
      "Epoch 4264, Loss: 0.03634444251656532, Final Batch Loss: 0.03229297697544098\n",
      "Epoch 4265, Loss: 0.08163592591881752, Final Batch Loss: 0.05229739844799042\n",
      "Epoch 4266, Loss: 0.09988207370042801, Final Batch Loss: 0.0355442613363266\n",
      "Epoch 4267, Loss: 0.03642407152801752, Final Batch Loss: 0.020881691947579384\n",
      "Epoch 4268, Loss: 0.09686161205172539, Final Batch Loss: 0.06312430649995804\n",
      "Epoch 4269, Loss: 0.030690476298332214, Final Batch Loss: 0.010304974392056465\n",
      "Epoch 4270, Loss: 0.09906179085373878, Final Batch Loss: 0.041291892528533936\n",
      "Epoch 4271, Loss: 0.02532429527491331, Final Batch Loss: 0.005135859362781048\n",
      "Epoch 4272, Loss: 0.06699960306286812, Final Batch Loss: 0.05035493150353432\n",
      "Epoch 4273, Loss: 0.12647493183612823, Final Batch Loss: 0.042876772582530975\n",
      "Epoch 4274, Loss: 0.08970259688794613, Final Batch Loss: 0.01757904700934887\n",
      "Epoch 4275, Loss: 0.030922868521884084, Final Batch Loss: 0.003848939435556531\n",
      "Epoch 4276, Loss: 0.10851120948791504, Final Batch Loss: 0.07363186776638031\n",
      "Epoch 4277, Loss: 0.02013680711388588, Final Batch Loss: 0.007170476019382477\n",
      "Epoch 4278, Loss: 0.03934992477297783, Final Batch Loss: 0.01700589805841446\n",
      "Epoch 4279, Loss: 0.052186911925673485, Final Batch Loss: 0.020751966163516045\n",
      "Epoch 4280, Loss: 0.02604316547513008, Final Batch Loss: 0.008337363600730896\n",
      "Epoch 4281, Loss: 0.09366869134828448, Final Batch Loss: 0.00673995865508914\n",
      "Epoch 4282, Loss: 0.07908948138356209, Final Batch Loss: 0.033114243298769\n",
      "Epoch 4283, Loss: 0.08156195189803839, Final Batch Loss: 0.07063693553209305\n",
      "Epoch 4284, Loss: 0.03673280170187354, Final Batch Loss: 0.0038950382731854916\n",
      "Epoch 4285, Loss: 0.02830450516194105, Final Batch Loss: 0.0045462967827916145\n",
      "Epoch 4286, Loss: 0.05024080350995064, Final Batch Loss: 0.03807634860277176\n",
      "Epoch 4287, Loss: 0.06607788242399693, Final Batch Loss: 0.01613522134721279\n",
      "Epoch 4288, Loss: 0.044623998925089836, Final Batch Loss: 0.02500174194574356\n",
      "Epoch 4289, Loss: 0.05127362161874771, Final Batch Loss: 0.020130492746829987\n",
      "Epoch 4290, Loss: 0.043338985182344913, Final Batch Loss: 0.008531608618795872\n",
      "Epoch 4291, Loss: 0.05098804412409663, Final Batch Loss: 0.04506335034966469\n",
      "Epoch 4292, Loss: 0.07429148443043232, Final Batch Loss: 0.04426608979701996\n",
      "Epoch 4293, Loss: 0.054846073500812054, Final Batch Loss: 0.013096789829432964\n",
      "Epoch 4294, Loss: 0.12813979387283325, Final Batch Loss: 0.08149417489767075\n",
      "Epoch 4295, Loss: 0.03811294212937355, Final Batch Loss: 0.006309308111667633\n",
      "Epoch 4296, Loss: 0.04611183051019907, Final Batch Loss: 0.03714384138584137\n",
      "Epoch 4297, Loss: 0.08247457817196846, Final Batch Loss: 0.04514718055725098\n",
      "Epoch 4298, Loss: 0.06881071254611015, Final Batch Loss: 0.007004160434007645\n",
      "Epoch 4299, Loss: 0.08090964704751968, Final Batch Loss: 0.00599786639213562\n",
      "Epoch 4300, Loss: 0.02386545669287443, Final Batch Loss: 0.01453098002821207\n",
      "Epoch 4301, Loss: 0.015304801519960165, Final Batch Loss: 0.007784705143421888\n",
      "Epoch 4302, Loss: 0.054458996281027794, Final Batch Loss: 0.017585953697562218\n",
      "Epoch 4303, Loss: 0.02470707707107067, Final Batch Loss: 0.014759518206119537\n",
      "Epoch 4304, Loss: 0.054296160116791725, Final Batch Loss: 0.024624116718769073\n",
      "Epoch 4305, Loss: 0.04620242677628994, Final Batch Loss: 0.022142210975289345\n",
      "Epoch 4306, Loss: 0.0486164940521121, Final Batch Loss: 0.0063781579956412315\n",
      "Epoch 4307, Loss: 0.03221434075385332, Final Batch Loss: 0.0057091424241662025\n",
      "Epoch 4308, Loss: 0.0211652759462595, Final Batch Loss: 0.008511564694344997\n",
      "Epoch 4309, Loss: 0.05394967179745436, Final Batch Loss: 0.009797426871955395\n",
      "Epoch 4310, Loss: 0.022453928599134088, Final Batch Loss: 0.002839848631992936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4311, Loss: 0.07311221398413181, Final Batch Loss: 0.05294203758239746\n",
      "Epoch 4312, Loss: 0.04259229218587279, Final Batch Loss: 0.03788182511925697\n",
      "Epoch 4313, Loss: 0.08395769260823727, Final Batch Loss: 0.07217954099178314\n",
      "Epoch 4314, Loss: 0.012781715486198664, Final Batch Loss: 0.008449050597846508\n",
      "Epoch 4315, Loss: 0.012434535659849644, Final Batch Loss: 0.004385987296700478\n",
      "Epoch 4316, Loss: 0.05740860616788268, Final Batch Loss: 0.05214793607592583\n",
      "Epoch 4317, Loss: 0.017559389816597104, Final Batch Loss: 0.01373865082859993\n",
      "Epoch 4318, Loss: 0.025823507457971573, Final Batch Loss: 0.015637440606951714\n",
      "Epoch 4319, Loss: 0.0513004157692194, Final Batch Loss: 0.04151609539985657\n",
      "Epoch 4320, Loss: 0.009452992584556341, Final Batch Loss: 0.005206315778195858\n",
      "Epoch 4321, Loss: 0.03647089283913374, Final Batch Loss: 0.028634486719965935\n",
      "Epoch 4322, Loss: 0.04132608836516738, Final Batch Loss: 0.0064586675725877285\n",
      "Epoch 4323, Loss: 0.03318890230730176, Final Batch Loss: 0.005448610056191683\n",
      "Epoch 4324, Loss: 0.04606970399618149, Final Batch Loss: 0.017233312129974365\n",
      "Epoch 4325, Loss: 0.04891003854572773, Final Batch Loss: 0.03156884387135506\n",
      "Epoch 4326, Loss: 0.025446342304348946, Final Batch Loss: 0.007910987362265587\n",
      "Epoch 4327, Loss: 0.05199817009270191, Final Batch Loss: 0.027119355276226997\n",
      "Epoch 4328, Loss: 0.03273767326027155, Final Batch Loss: 0.013261371292173862\n",
      "Epoch 4329, Loss: 0.058529049158096313, Final Batch Loss: 0.01625160500407219\n",
      "Epoch 4330, Loss: 0.06336815096437931, Final Batch Loss: 0.04221487045288086\n",
      "Epoch 4331, Loss: 0.1144491694867611, Final Batch Loss: 0.04867621883749962\n",
      "Epoch 4332, Loss: 0.02550652716308832, Final Batch Loss: 0.014428830705583096\n",
      "Epoch 4333, Loss: 0.03282662760466337, Final Batch Loss: 0.01901763305068016\n",
      "Epoch 4334, Loss: 0.04344766493886709, Final Batch Loss: 0.011964126490056515\n",
      "Epoch 4335, Loss: 0.04583611944690347, Final Batch Loss: 0.0049565196968615055\n",
      "Epoch 4336, Loss: 0.020629588747397065, Final Batch Loss: 0.0036659615579992533\n",
      "Epoch 4337, Loss: 0.02012510458007455, Final Batch Loss: 0.004493192303925753\n",
      "Epoch 4338, Loss: 0.011874610558152199, Final Batch Loss: 0.005642877425998449\n",
      "Epoch 4339, Loss: 0.06747189490124583, Final Batch Loss: 0.06032721698284149\n",
      "Epoch 4340, Loss: 0.043548365123569965, Final Batch Loss: 0.009706397540867329\n",
      "Epoch 4341, Loss: 0.06198312807828188, Final Batch Loss: 0.05653931573033333\n",
      "Epoch 4342, Loss: 0.033178625628352165, Final Batch Loss: 0.0213111974298954\n",
      "Epoch 4343, Loss: 0.03812113730236888, Final Batch Loss: 0.002607576083391905\n",
      "Epoch 4344, Loss: 0.040526761673390865, Final Batch Loss: 0.009057859890162945\n",
      "Epoch 4345, Loss: 0.0503730196505785, Final Batch Loss: 0.03854129835963249\n",
      "Epoch 4346, Loss: 0.06349634751677513, Final Batch Loss: 0.05365306884050369\n",
      "Epoch 4347, Loss: 0.06593049690127373, Final Batch Loss: 0.034134406596422195\n",
      "Epoch 4348, Loss: 0.03913868963718414, Final Batch Loss: 0.003751218318939209\n",
      "Epoch 4349, Loss: 0.08899431303143501, Final Batch Loss: 0.0666395053267479\n",
      "Epoch 4350, Loss: 0.022032476728782058, Final Batch Loss: 0.0026586127933114767\n",
      "Epoch 4351, Loss: 0.043695793487131596, Final Batch Loss: 0.012354494072496891\n",
      "Epoch 4352, Loss: 0.0511299092322588, Final Batch Loss: 0.025974445044994354\n",
      "Epoch 4353, Loss: 0.04275668133050203, Final Batch Loss: 0.014583359472453594\n",
      "Epoch 4354, Loss: 0.012705895351246, Final Batch Loss: 0.002712114015594125\n",
      "Epoch 4355, Loss: 0.015245905611664057, Final Batch Loss: 0.003943196963518858\n",
      "Epoch 4356, Loss: 0.025355006102472544, Final Batch Loss: 0.019038083031773567\n",
      "Epoch 4357, Loss: 0.014092544093728065, Final Batch Loss: 0.006345633417367935\n",
      "Epoch 4358, Loss: 0.05607912875711918, Final Batch Loss: 0.019346164539456367\n",
      "Epoch 4359, Loss: 0.033970155753195286, Final Batch Loss: 0.013547287322580814\n",
      "Epoch 4360, Loss: 0.05763295944780111, Final Batch Loss: 0.04912249371409416\n",
      "Epoch 4361, Loss: 0.03138947859406471, Final Batch Loss: 0.015012525022029877\n",
      "Epoch 4362, Loss: 0.0710196066647768, Final Batch Loss: 0.06291413307189941\n",
      "Epoch 4363, Loss: 0.07443715445697308, Final Batch Loss: 0.06552734971046448\n",
      "Epoch 4364, Loss: 0.01710338704288006, Final Batch Loss: 0.00805682223290205\n",
      "Epoch 4365, Loss: 0.05296054249629378, Final Batch Loss: 0.04703211784362793\n",
      "Epoch 4366, Loss: 0.12739339843392372, Final Batch Loss: 0.11487595736980438\n",
      "Epoch 4367, Loss: 0.013790652621537447, Final Batch Loss: 0.010054252110421658\n",
      "Epoch 4368, Loss: 0.032133473083376884, Final Batch Loss: 0.02059081941843033\n",
      "Epoch 4369, Loss: 0.19845498725771904, Final Batch Loss: 0.15782389044761658\n",
      "Epoch 4370, Loss: 0.0814570295624435, Final Batch Loss: 0.007470469456166029\n",
      "Epoch 4371, Loss: 0.023689339868724346, Final Batch Loss: 0.006270603276789188\n",
      "Epoch 4372, Loss: 0.01878876332193613, Final Batch Loss: 0.00579645112156868\n",
      "Epoch 4373, Loss: 0.03289244323968887, Final Batch Loss: 0.024006489664316177\n",
      "Epoch 4374, Loss: 0.061179500073194504, Final Batch Loss: 0.0024181902408599854\n",
      "Epoch 4375, Loss: 0.04769764235243201, Final Batch Loss: 0.005877835210412741\n",
      "Epoch 4376, Loss: 0.07211134117096663, Final Batch Loss: 0.0652802586555481\n",
      "Epoch 4377, Loss: 0.05692874453961849, Final Batch Loss: 0.024721750989556313\n",
      "Epoch 4378, Loss: 0.0818595252931118, Final Batch Loss: 0.058948028832674026\n",
      "Epoch 4379, Loss: 0.09722033143043518, Final Batch Loss: 0.03955889493227005\n",
      "Epoch 4380, Loss: 0.025186683516949415, Final Batch Loss: 0.01960417814552784\n",
      "Epoch 4381, Loss: 0.045093921944499016, Final Batch Loss: 0.01902756839990616\n",
      "Epoch 4382, Loss: 0.07824888080358505, Final Batch Loss: 0.02255309745669365\n",
      "Epoch 4383, Loss: 0.04279180243611336, Final Batch Loss: 0.008039113134145737\n",
      "Epoch 4384, Loss: 0.07006106711924076, Final Batch Loss: 0.04195534810423851\n",
      "Epoch 4385, Loss: 0.1534099578857422, Final Batch Loss: 0.08114682137966156\n",
      "Epoch 4386, Loss: 0.04839239816647023, Final Batch Loss: 0.001906065153889358\n",
      "Epoch 4387, Loss: 0.019567042589187622, Final Batch Loss: 0.0077031319960951805\n",
      "Epoch 4388, Loss: 0.12461709417402744, Final Batch Loss: 0.09836050868034363\n",
      "Epoch 4389, Loss: 0.07139646913856268, Final Batch Loss: 0.008338621817529202\n",
      "Epoch 4390, Loss: 0.023203415796160698, Final Batch Loss: 0.012830018065869808\n",
      "Epoch 4391, Loss: 0.02702927775681019, Final Batch Loss: 0.009548181667923927\n",
      "Epoch 4392, Loss: 0.043580327183008194, Final Batch Loss: 0.0143221914768219\n",
      "Epoch 4393, Loss: 0.06317970156669617, Final Batch Loss: 0.03435329347848892\n",
      "Epoch 4394, Loss: 0.05817128345370293, Final Batch Loss: 0.028735971078276634\n",
      "Epoch 4395, Loss: 0.053767167031764984, Final Batch Loss: 0.02682911604642868\n",
      "Epoch 4396, Loss: 0.012015493586659431, Final Batch Loss: 0.003706091083586216\n",
      "Epoch 4397, Loss: 0.02375276479870081, Final Batch Loss: 0.013409445993602276\n",
      "Epoch 4398, Loss: 0.04787563346326351, Final Batch Loss: 0.013387201353907585\n",
      "Epoch 4399, Loss: 0.04095291905105114, Final Batch Loss: 0.02446097508072853\n",
      "Epoch 4400, Loss: 0.06450718268752098, Final Batch Loss: 0.045975323766469955\n",
      "Epoch 4401, Loss: 0.07107376493513584, Final Batch Loss: 0.009801825508475304\n",
      "Epoch 4402, Loss: 0.060406506061553955, Final Batch Loss: 0.02588779851794243\n",
      "Epoch 4403, Loss: 0.06055917404592037, Final Batch Loss: 0.02063305862247944\n",
      "Epoch 4404, Loss: 0.02115856297314167, Final Batch Loss: 0.004730928689241409\n",
      "Epoch 4405, Loss: 0.1065815519541502, Final Batch Loss: 0.030805712565779686\n",
      "Epoch 4406, Loss: 0.03827807866036892, Final Batch Loss: 0.030700022354722023\n",
      "Epoch 4407, Loss: 0.06137496791779995, Final Batch Loss: 0.020134659484028816\n",
      "Epoch 4408, Loss: 0.029275435023009777, Final Batch Loss: 0.003772747702896595\n",
      "Epoch 4409, Loss: 0.033820740878582, Final Batch Loss: 0.016143973916769028\n",
      "Epoch 4410, Loss: 0.03319513564929366, Final Batch Loss: 0.027479374781250954\n",
      "Epoch 4411, Loss: 0.047628953121602535, Final Batch Loss: 0.0073002977296710014\n",
      "Epoch 4412, Loss: 0.032690598629415035, Final Batch Loss: 0.017607461661100388\n",
      "Epoch 4413, Loss: 0.024809996597468853, Final Batch Loss: 0.017729278653860092\n",
      "Epoch 4414, Loss: 0.04264020174741745, Final Batch Loss: 0.023857899010181427\n",
      "Epoch 4415, Loss: 0.06136542931199074, Final Batch Loss: 0.03628246858716011\n",
      "Epoch 4416, Loss: 0.022911285050213337, Final Batch Loss: 0.009138066321611404\n",
      "Epoch 4417, Loss: 0.04157421924173832, Final Batch Loss: 0.02599884383380413\n",
      "Epoch 4418, Loss: 0.015228625386953354, Final Batch Loss: 0.004455584101378918\n",
      "Epoch 4419, Loss: 0.020658796653151512, Final Batch Loss: 0.002456512302160263\n",
      "Epoch 4420, Loss: 0.0196317033842206, Final Batch Loss: 0.010584871284663677\n",
      "Epoch 4421, Loss: 0.03147314628586173, Final Batch Loss: 0.006935232784599066\n",
      "Epoch 4422, Loss: 0.00996858044527471, Final Batch Loss: 0.0020518179517239332\n",
      "Epoch 4423, Loss: 0.013428446371108294, Final Batch Loss: 0.00659931730479002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4424, Loss: 0.01714492030441761, Final Batch Loss: 0.011080662719905376\n",
      "Epoch 4425, Loss: 0.018720888532698154, Final Batch Loss: 0.011023454368114471\n",
      "Epoch 4426, Loss: 0.08826787443831563, Final Batch Loss: 0.08107277005910873\n",
      "Epoch 4427, Loss: 0.0969167910516262, Final Batch Loss: 0.024514567106962204\n",
      "Epoch 4428, Loss: 0.03688941616564989, Final Batch Loss: 0.022253679111599922\n",
      "Epoch 4429, Loss: 0.01889229565858841, Final Batch Loss: 0.009999857284128666\n",
      "Epoch 4430, Loss: 0.0150603661313653, Final Batch Loss: 0.009270657785236835\n",
      "Epoch 4431, Loss: 0.012554254615679383, Final Batch Loss: 0.0017798955086618662\n",
      "Epoch 4432, Loss: 0.0339425140991807, Final Batch Loss: 0.006076029501855373\n",
      "Epoch 4433, Loss: 0.03046681359410286, Final Batch Loss: 0.024784468114376068\n",
      "Epoch 4434, Loss: 0.03392417263239622, Final Batch Loss: 0.011535721831023693\n",
      "Epoch 4435, Loss: 0.052069809287786484, Final Batch Loss: 0.036513835191726685\n",
      "Epoch 4436, Loss: 0.02156996075063944, Final Batch Loss: 0.004421425051987171\n",
      "Epoch 4437, Loss: 0.06721785850822926, Final Batch Loss: 0.04316685348749161\n",
      "Epoch 4438, Loss: 0.010484768077731133, Final Batch Loss: 0.0023390566930174828\n",
      "Epoch 4439, Loss: 0.02378497738391161, Final Batch Loss: 0.008431024849414825\n",
      "Epoch 4440, Loss: 0.04848713055253029, Final Batch Loss: 0.010475218296051025\n",
      "Epoch 4441, Loss: 0.030508832074701786, Final Batch Loss: 0.021114002913236618\n",
      "Epoch 4442, Loss: 0.02317616529762745, Final Batch Loss: 0.008401215076446533\n",
      "Epoch 4443, Loss: 0.07326275552622974, Final Batch Loss: 0.0699758529663086\n",
      "Epoch 4444, Loss: 0.008424671599641442, Final Batch Loss: 0.005515416152775288\n",
      "Epoch 4445, Loss: 0.05806493014097214, Final Batch Loss: 0.05170528590679169\n",
      "Epoch 4446, Loss: 0.019627773202955723, Final Batch Loss: 0.006816956214606762\n",
      "Epoch 4447, Loss: 0.04142502881586552, Final Batch Loss: 0.008985685184597969\n",
      "Epoch 4448, Loss: 0.02980908192694187, Final Batch Loss: 0.02094791829586029\n",
      "Epoch 4449, Loss: 0.009082016069442034, Final Batch Loss: 0.005082588642835617\n",
      "Epoch 4450, Loss: 0.02938612876459956, Final Batch Loss: 0.005212354939430952\n",
      "Epoch 4451, Loss: 0.01844650460407138, Final Batch Loss: 0.004100909922271967\n",
      "Epoch 4452, Loss: 0.016410015523433685, Final Batch Loss: 0.004540991969406605\n",
      "Epoch 4453, Loss: 0.04140056064352393, Final Batch Loss: 0.036030448973178864\n",
      "Epoch 4454, Loss: 0.03289914829656482, Final Batch Loss: 0.007257027085870504\n",
      "Epoch 4455, Loss: 0.05849599791690707, Final Batch Loss: 0.05358438566327095\n",
      "Epoch 4456, Loss: 0.02916005440056324, Final Batch Loss: 0.023358488455414772\n",
      "Epoch 4457, Loss: 0.04746739845722914, Final Batch Loss: 0.037566713988780975\n",
      "Epoch 4458, Loss: 0.04313665488734841, Final Batch Loss: 0.00582330534234643\n",
      "Epoch 4459, Loss: 0.021680407924577594, Final Batch Loss: 0.0026158306282013655\n",
      "Epoch 4460, Loss: 0.009593483759090304, Final Batch Loss: 0.003192646661773324\n",
      "Epoch 4461, Loss: 0.03721544658765197, Final Batch Loss: 0.03001927211880684\n",
      "Epoch 4462, Loss: 0.05215700576081872, Final Batch Loss: 0.04680810868740082\n",
      "Epoch 4463, Loss: 0.038123030215501785, Final Batch Loss: 0.012029940262436867\n",
      "Epoch 4464, Loss: 0.026164203882217407, Final Batch Loss: 0.0026477891951799393\n",
      "Epoch 4465, Loss: 0.012065584771335125, Final Batch Loss: 0.004414771683514118\n",
      "Epoch 4466, Loss: 0.01655825413763523, Final Batch Loss: 0.002885728143155575\n",
      "Epoch 4467, Loss: 0.03855287982150912, Final Batch Loss: 0.0030664014630019665\n",
      "Epoch 4468, Loss: 0.03762040985748172, Final Batch Loss: 0.005365386139601469\n",
      "Epoch 4469, Loss: 0.05177475791424513, Final Batch Loss: 0.042590051889419556\n",
      "Epoch 4470, Loss: 0.009184666909277439, Final Batch Loss: 0.004576520062983036\n",
      "Epoch 4471, Loss: 0.02441618125885725, Final Batch Loss: 0.012854764237999916\n",
      "Epoch 4472, Loss: 0.01855568401515484, Final Batch Loss: 0.01371338963508606\n",
      "Epoch 4473, Loss: 0.011305535212159157, Final Batch Loss: 0.005482273176312447\n",
      "Epoch 4474, Loss: 0.00758003257215023, Final Batch Loss: 0.002950016874819994\n",
      "Epoch 4475, Loss: 0.029108879156410694, Final Batch Loss: 0.018033523112535477\n",
      "Epoch 4476, Loss: 0.00988145754672587, Final Batch Loss: 0.00630837632343173\n",
      "Epoch 4477, Loss: 0.0662469700910151, Final Batch Loss: 0.06129829213023186\n",
      "Epoch 4478, Loss: 0.010281603783369064, Final Batch Loss: 0.003152737393975258\n",
      "Epoch 4479, Loss: 0.08302142098546028, Final Batch Loss: 0.03555580601096153\n",
      "Epoch 4480, Loss: 0.012127910275012255, Final Batch Loss: 0.004749681334942579\n",
      "Epoch 4481, Loss: 0.01682148256804794, Final Batch Loss: 0.001617011963389814\n",
      "Epoch 4482, Loss: 0.05685218423604965, Final Batch Loss: 0.03936654329299927\n",
      "Epoch 4483, Loss: 0.02284831367433071, Final Batch Loss: 0.005936143919825554\n",
      "Epoch 4484, Loss: 0.04915269464254379, Final Batch Loss: 0.008594270795583725\n",
      "Epoch 4485, Loss: 0.009645950049161911, Final Batch Loss: 0.003916845191270113\n",
      "Epoch 4486, Loss: 0.020574874244630337, Final Batch Loss: 0.005990327335894108\n",
      "Epoch 4487, Loss: 0.10257432423532009, Final Batch Loss: 0.009385516867041588\n",
      "Epoch 4488, Loss: 0.01846433151513338, Final Batch Loss: 0.009170318953692913\n",
      "Epoch 4489, Loss: 0.013794573955237865, Final Batch Loss: 0.006941244006156921\n",
      "Epoch 4490, Loss: 0.010462533216923475, Final Batch Loss: 0.005277925170958042\n",
      "Epoch 4491, Loss: 0.03495587967336178, Final Batch Loss: 0.027596844360232353\n",
      "Epoch 4492, Loss: 0.009798199404031038, Final Batch Loss: 0.0017378074117004871\n",
      "Epoch 4493, Loss: 0.024443387985229492, Final Batch Loss: 0.013561751693487167\n",
      "Epoch 4494, Loss: 0.031598687171936035, Final Batch Loss: 0.011042667552828789\n",
      "Epoch 4495, Loss: 0.0461641950532794, Final Batch Loss: 0.012569195590913296\n",
      "Epoch 4496, Loss: 0.03986218571662903, Final Batch Loss: 0.003957793116569519\n",
      "Epoch 4497, Loss: 0.017126298043876886, Final Batch Loss: 0.01028947252780199\n",
      "Epoch 4498, Loss: 0.03810080233961344, Final Batch Loss: 0.028076577931642532\n",
      "Epoch 4499, Loss: 0.03024429315701127, Final Batch Loss: 0.004569169599562883\n",
      "Epoch 4500, Loss: 0.023325487971305847, Final Batch Loss: 0.018979746848344803\n",
      "Epoch 4501, Loss: 0.07873941538855433, Final Batch Loss: 0.004176940303295851\n",
      "Epoch 4502, Loss: 0.014923673588782549, Final Batch Loss: 0.007828069850802422\n",
      "Epoch 4503, Loss: 0.04605380864813924, Final Batch Loss: 0.005615402478724718\n",
      "Epoch 4504, Loss: 0.06090947473421693, Final Batch Loss: 0.05756707116961479\n",
      "Epoch 4505, Loss: 0.04529535910114646, Final Batch Loss: 0.007285320665687323\n",
      "Epoch 4506, Loss: 0.011884194798767567, Final Batch Loss: 0.00614866241812706\n",
      "Epoch 4507, Loss: 0.017210558522492647, Final Batch Loss: 0.004152382258325815\n",
      "Epoch 4508, Loss: 0.023299474269151688, Final Batch Loss: 0.004341088235378265\n",
      "Epoch 4509, Loss: 0.058942098170518875, Final Batch Loss: 0.04497324302792549\n",
      "Epoch 4510, Loss: 0.0310148848220706, Final Batch Loss: 0.02719966322183609\n",
      "Epoch 4511, Loss: 0.05457814037799835, Final Batch Loss: 0.008663997054100037\n",
      "Epoch 4512, Loss: 0.023172405548393726, Final Batch Loss: 0.013620601035654545\n",
      "Epoch 4513, Loss: 0.019363507628440857, Final Batch Loss: 0.005505647510290146\n",
      "Epoch 4514, Loss: 0.059862684458494186, Final Batch Loss: 0.03487519174814224\n",
      "Epoch 4515, Loss: 0.03537018224596977, Final Batch Loss: 0.02834809571504593\n",
      "Epoch 4516, Loss: 0.049198233522474766, Final Batch Loss: 0.014265806414186954\n",
      "Epoch 4517, Loss: 0.023371262475848198, Final Batch Loss: 0.015001893974840641\n",
      "Epoch 4518, Loss: 0.015607026871293783, Final Batch Loss: 0.0049963281489908695\n",
      "Epoch 4519, Loss: 0.10809274949133396, Final Batch Loss: 0.08322682976722717\n",
      "Epoch 4520, Loss: 0.012764882296323776, Final Batch Loss: 0.003784795291721821\n",
      "Epoch 4521, Loss: 0.048036521300673485, Final Batch Loss: 0.01774769090116024\n",
      "Epoch 4522, Loss: 0.16433776915073395, Final Batch Loss: 0.04784227907657623\n",
      "Epoch 4523, Loss: 0.09996163658797741, Final Batch Loss: 0.07549930363893509\n",
      "Epoch 4524, Loss: 0.01434543076902628, Final Batch Loss: 0.005377913825213909\n",
      "Epoch 4525, Loss: 0.026911249849945307, Final Batch Loss: 0.002184134442359209\n",
      "Epoch 4526, Loss: 0.032229525968432426, Final Batch Loss: 0.008352568373084068\n",
      "Epoch 4527, Loss: 0.016889089485630393, Final Batch Loss: 0.003208475885912776\n",
      "Epoch 4528, Loss: 0.1068057082593441, Final Batch Loss: 0.05453145131468773\n",
      "Epoch 4529, Loss: 0.05729048326611519, Final Batch Loss: 0.03443257883191109\n",
      "Epoch 4530, Loss: 0.1393455653451383, Final Batch Loss: 0.13429276645183563\n",
      "Epoch 4531, Loss: 0.013170918449759483, Final Batch Loss: 0.004966474138200283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4532, Loss: 0.05289357528090477, Final Batch Loss: 0.047624099999666214\n",
      "Epoch 4533, Loss: 0.015822704881429672, Final Batch Loss: 0.008719358593225479\n",
      "Epoch 4534, Loss: 0.05821964889764786, Final Batch Loss: 0.01573287695646286\n",
      "Epoch 4535, Loss: 0.017804550705477595, Final Batch Loss: 0.0035056553315371275\n",
      "Epoch 4536, Loss: 0.00941725680604577, Final Batch Loss: 0.0019697826355695724\n",
      "Epoch 4537, Loss: 0.017646665568463504, Final Batch Loss: 0.0017968666506931186\n",
      "Epoch 4538, Loss: 0.04209689702838659, Final Batch Loss: 0.013085554353892803\n",
      "Epoch 4539, Loss: 0.06241531856358051, Final Batch Loss: 0.035661689937114716\n",
      "Epoch 4540, Loss: 0.03146099764853716, Final Batch Loss: 0.024527469649910927\n",
      "Epoch 4541, Loss: 0.05493887048214674, Final Batch Loss: 0.049650222063064575\n",
      "Epoch 4542, Loss: 0.01723745046183467, Final Batch Loss: 0.007036540191620588\n",
      "Epoch 4543, Loss: 0.05664627440273762, Final Batch Loss: 0.015140006318688393\n",
      "Epoch 4544, Loss: 0.034146467223763466, Final Batch Loss: 0.02721511758863926\n",
      "Epoch 4545, Loss: 0.015051407273858786, Final Batch Loss: 0.010668912902474403\n",
      "Epoch 4546, Loss: 0.037921713665127754, Final Batch Loss: 0.027670081704854965\n",
      "Epoch 4547, Loss: 0.08558908477425575, Final Batch Loss: 0.036054596304893494\n",
      "Epoch 4548, Loss: 0.018882835283875465, Final Batch Loss: 0.008119489066302776\n",
      "Epoch 4549, Loss: 0.05145983770489693, Final Batch Loss: 0.006593149155378342\n",
      "Epoch 4550, Loss: 0.05483864154666662, Final Batch Loss: 0.04599431902170181\n",
      "Epoch 4551, Loss: 0.11475851759314537, Final Batch Loss: 0.06518270075321198\n",
      "Epoch 4552, Loss: 0.08635541051626205, Final Batch Loss: 0.07464238256216049\n",
      "Epoch 4553, Loss: 0.02701550954952836, Final Batch Loss: 0.005805192980915308\n",
      "Epoch 4554, Loss: 0.054239846765995026, Final Batch Loss: 0.03676049783825874\n",
      "Epoch 4555, Loss: 0.026620805263519287, Final Batch Loss: 0.007870685309171677\n",
      "Epoch 4556, Loss: 0.0220613949932158, Final Batch Loss: 0.005085342098027468\n",
      "Epoch 4557, Loss: 0.01161551522091031, Final Batch Loss: 0.005607886239886284\n",
      "Epoch 4558, Loss: 0.026206951588392258, Final Batch Loss: 0.011850492097437382\n",
      "Epoch 4559, Loss: 0.032328980043530464, Final Batch Loss: 0.009961219504475594\n",
      "Epoch 4560, Loss: 0.06295200251042843, Final Batch Loss: 0.00546899251639843\n",
      "Epoch 4561, Loss: 0.04011060995981097, Final Batch Loss: 0.0067935059778392315\n",
      "Epoch 4562, Loss: 0.013494581449776888, Final Batch Loss: 0.0014933128841221333\n",
      "Epoch 4563, Loss: 0.07121970597654581, Final Batch Loss: 0.01495590154081583\n",
      "Epoch 4564, Loss: 0.023356124758720398, Final Batch Loss: 0.009047859348356724\n",
      "Epoch 4565, Loss: 0.010995544027537107, Final Batch Loss: 0.003930330276489258\n",
      "Epoch 4566, Loss: 0.07182447426021099, Final Batch Loss: 0.04652661457657814\n",
      "Epoch 4567, Loss: 0.051200104877352715, Final Batch Loss: 0.0352267250418663\n",
      "Epoch 4568, Loss: 0.02925895480439067, Final Batch Loss: 0.0044770087115466595\n",
      "Epoch 4569, Loss: 0.01473827997688204, Final Batch Loss: 0.0018737927312031388\n",
      "Epoch 4570, Loss: 0.02893718471750617, Final Batch Loss: 0.022060805931687355\n",
      "Epoch 4571, Loss: 0.006320315646007657, Final Batch Loss: 0.002904127584770322\n",
      "Epoch 4572, Loss: 0.027954095043241978, Final Batch Loss: 0.020304659381508827\n",
      "Epoch 4573, Loss: 0.05655929492786527, Final Batch Loss: 0.0053509739227592945\n",
      "Epoch 4574, Loss: 0.022107804659754038, Final Batch Loss: 0.004564071539789438\n",
      "Epoch 4575, Loss: 0.039960313588380814, Final Batch Loss: 0.026900088414549828\n",
      "Epoch 4576, Loss: 0.010018317960202694, Final Batch Loss: 0.0023060166276991367\n",
      "Epoch 4577, Loss: 0.058677319437265396, Final Batch Loss: 0.054103001952171326\n",
      "Epoch 4578, Loss: 0.009088142542168498, Final Batch Loss: 0.0031787881162017584\n",
      "Epoch 4579, Loss: 0.010974159464240074, Final Batch Loss: 0.004899346269667149\n",
      "Epoch 4580, Loss: 0.07980912178754807, Final Batch Loss: 0.06361328810453415\n",
      "Epoch 4581, Loss: 0.050231266766786575, Final Batch Loss: 0.009643536061048508\n",
      "Epoch 4582, Loss: 0.01935573434457183, Final Batch Loss: 0.006722427438944578\n",
      "Epoch 4583, Loss: 0.019770026672631502, Final Batch Loss: 0.005860085133463144\n",
      "Epoch 4584, Loss: 0.042717439820989966, Final Batch Loss: 0.002919038524851203\n",
      "Epoch 4585, Loss: 0.027555765118449926, Final Batch Loss: 0.006185957696288824\n",
      "Epoch 4586, Loss: 0.053958674892783165, Final Batch Loss: 0.0399138480424881\n",
      "Epoch 4587, Loss: 0.04324546176940203, Final Batch Loss: 0.030331650748848915\n",
      "Epoch 4588, Loss: 0.040966265834867954, Final Batch Loss: 0.032851990312337875\n",
      "Epoch 4589, Loss: 0.02915906999260187, Final Batch Loss: 0.004777883179485798\n",
      "Epoch 4590, Loss: 0.03331637801602483, Final Batch Loss: 0.004642853979021311\n",
      "Epoch 4591, Loss: 0.010912211611866951, Final Batch Loss: 0.00511258514598012\n",
      "Epoch 4592, Loss: 0.04505633795633912, Final Batch Loss: 0.04026283696293831\n",
      "Epoch 4593, Loss: 0.06199507974088192, Final Batch Loss: 0.048680391162633896\n",
      "Epoch 4594, Loss: 0.05875229090452194, Final Batch Loss: 0.02405049279332161\n",
      "Epoch 4595, Loss: 0.08982023224234581, Final Batch Loss: 0.0627611055970192\n",
      "Epoch 4596, Loss: 0.02366727404296398, Final Batch Loss: 0.009074692614376545\n",
      "Epoch 4597, Loss: 0.04107129480689764, Final Batch Loss: 0.00915337260812521\n",
      "Epoch 4598, Loss: 0.022909957449883223, Final Batch Loss: 0.01652047410607338\n",
      "Epoch 4599, Loss: 0.030638491734862328, Final Batch Loss: 0.009607251733541489\n",
      "Epoch 4600, Loss: 0.02002392616122961, Final Batch Loss: 0.01384108979254961\n",
      "Epoch 4601, Loss: 0.039973008912056684, Final Batch Loss: 0.007534712087363005\n",
      "Epoch 4602, Loss: 0.06482429802417755, Final Batch Loss: 0.04524196311831474\n",
      "Epoch 4603, Loss: 0.03946374589577317, Final Batch Loss: 0.03444278985261917\n",
      "Epoch 4604, Loss: 0.020067580742761493, Final Batch Loss: 0.016548728570342064\n",
      "Epoch 4605, Loss: 0.012916095089167356, Final Batch Loss: 0.005905321333557367\n",
      "Epoch 4606, Loss: 0.03910082043148577, Final Batch Loss: 0.0011898784432560205\n",
      "Epoch 4607, Loss: 0.047797898296266794, Final Batch Loss: 0.04277339205145836\n",
      "Epoch 4608, Loss: 0.04703860799781978, Final Batch Loss: 0.0026888444554060698\n",
      "Epoch 4609, Loss: 0.07185197062790394, Final Batch Loss: 0.04656483232975006\n",
      "Epoch 4610, Loss: 0.0505100479349494, Final Batch Loss: 0.012722584418952465\n",
      "Epoch 4611, Loss: 0.07484286278486252, Final Batch Loss: 0.036547739058732986\n",
      "Epoch 4612, Loss: 0.03786537563428283, Final Batch Loss: 0.006980483885854483\n",
      "Epoch 4613, Loss: 0.07323105074465275, Final Batch Loss: 0.024139387533068657\n",
      "Epoch 4614, Loss: 0.04680081503465772, Final Batch Loss: 0.007422980386763811\n",
      "Epoch 4615, Loss: 0.02124686981551349, Final Batch Loss: 0.0034124336671084166\n",
      "Epoch 4616, Loss: 0.013036343734711409, Final Batch Loss: 0.005757532082498074\n",
      "Epoch 4617, Loss: 0.032802545465528965, Final Batch Loss: 0.028809241950511932\n",
      "Epoch 4618, Loss: 0.09273543953895569, Final Batch Loss: 0.0524694062769413\n",
      "Epoch 4619, Loss: 0.013536896090954542, Final Batch Loss: 0.005302074830979109\n",
      "Epoch 4620, Loss: 0.03961147926747799, Final Batch Loss: 0.004933493211865425\n",
      "Epoch 4621, Loss: 0.04417368769645691, Final Batch Loss: 0.012585170567035675\n",
      "Epoch 4622, Loss: 0.01062250416725874, Final Batch Loss: 0.00677794124931097\n",
      "Epoch 4623, Loss: 0.03839336009696126, Final Batch Loss: 0.032386284321546555\n",
      "Epoch 4624, Loss: 0.042738566640764475, Final Batch Loss: 0.036883387714624405\n",
      "Epoch 4625, Loss: 0.025890523567795753, Final Batch Loss: 0.014801987446844578\n",
      "Epoch 4626, Loss: 0.04808381199836731, Final Batch Loss: 0.03835713863372803\n",
      "Epoch 4627, Loss: 0.03504438977688551, Final Batch Loss: 0.02358352579176426\n",
      "Epoch 4628, Loss: 0.057805342599749565, Final Batch Loss: 0.02301393263041973\n",
      "Epoch 4629, Loss: 0.02736341394484043, Final Batch Loss: 0.011194203048944473\n",
      "Epoch 4630, Loss: 0.02551425341516733, Final Batch Loss: 0.004865352995693684\n",
      "Epoch 4631, Loss: 0.035821414552628994, Final Batch Loss: 0.004073555581271648\n",
      "Epoch 4632, Loss: 0.026618770323693752, Final Batch Loss: 0.018627021461725235\n",
      "Epoch 4633, Loss: 0.04110521706752479, Final Batch Loss: 0.002047064481303096\n",
      "Epoch 4634, Loss: 0.03271597484126687, Final Batch Loss: 0.006375682074576616\n",
      "Epoch 4635, Loss: 0.019434775225818157, Final Batch Loss: 0.010546903125941753\n",
      "Epoch 4636, Loss: 0.006961405742913485, Final Batch Loss: 0.004551982972770929\n",
      "Epoch 4637, Loss: 0.05428318865597248, Final Batch Loss: 0.01924833096563816\n",
      "Epoch 4638, Loss: 0.034576572477817535, Final Batch Loss: 0.023408101871609688\n",
      "Epoch 4639, Loss: 0.0641076946631074, Final Batch Loss: 0.013125081546604633\n",
      "Epoch 4640, Loss: 0.09777987003326416, Final Batch Loss: 0.04203285649418831\n",
      "Epoch 4641, Loss: 0.13129603117704391, Final Batch Loss: 0.03190343827009201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4642, Loss: 0.039322853088378906, Final Batch Loss: 0.015670454129576683\n",
      "Epoch 4643, Loss: 0.06799942627549171, Final Batch Loss: 0.03137368708848953\n",
      "Epoch 4644, Loss: 0.08481663465499878, Final Batch Loss: 0.05948471277952194\n",
      "Epoch 4645, Loss: 0.18606941401958466, Final Batch Loss: 0.1413642317056656\n",
      "Epoch 4646, Loss: 0.08562006987631321, Final Batch Loss: 0.026797166094183922\n",
      "Epoch 4647, Loss: 0.07601959817111492, Final Batch Loss: 0.026083694770932198\n",
      "Epoch 4648, Loss: 0.09000075608491898, Final Batch Loss: 0.05759857967495918\n",
      "Epoch 4649, Loss: 0.02062493795529008, Final Batch Loss: 0.004882868845015764\n",
      "Epoch 4650, Loss: 0.11732861027121544, Final Batch Loss: 0.07852551341056824\n",
      "Epoch 4651, Loss: 0.014557241927832365, Final Batch Loss: 0.005219979677349329\n",
      "Epoch 4652, Loss: 0.03810556326061487, Final Batch Loss: 0.030074981972575188\n",
      "Epoch 4653, Loss: 0.027849999256432056, Final Batch Loss: 0.006794902496039867\n",
      "Epoch 4654, Loss: 0.05948106665164232, Final Batch Loss: 0.01274969894438982\n",
      "Epoch 4655, Loss: 0.03222618065774441, Final Batch Loss: 0.00785532221198082\n",
      "Epoch 4656, Loss: 0.052941497415304184, Final Batch Loss: 0.03418196365237236\n",
      "Epoch 4657, Loss: 0.061510875821113586, Final Batch Loss: 0.011105511337518692\n",
      "Epoch 4658, Loss: 0.08405948616564274, Final Batch Loss: 0.07640218734741211\n",
      "Epoch 4659, Loss: 0.013652438763529062, Final Batch Loss: 0.0065412744879722595\n",
      "Epoch 4660, Loss: 0.0324912965297699, Final Batch Loss: 0.006840892136096954\n",
      "Epoch 4661, Loss: 0.03968270309269428, Final Batch Loss: 0.008635155856609344\n",
      "Epoch 4662, Loss: 0.10609174147248268, Final Batch Loss: 0.08676853030920029\n",
      "Epoch 4663, Loss: 0.03265004511922598, Final Batch Loss: 0.021808039397001266\n",
      "Epoch 4664, Loss: 0.025996921584010124, Final Batch Loss: 0.005849288776516914\n",
      "Epoch 4665, Loss: 0.037902576848864555, Final Batch Loss: 0.01704217679798603\n",
      "Epoch 4666, Loss: 0.03580943029373884, Final Batch Loss: 0.02522262930870056\n",
      "Epoch 4667, Loss: 0.04828125797212124, Final Batch Loss: 0.03305811434984207\n",
      "Epoch 4668, Loss: 0.07312328368425369, Final Batch Loss: 0.04938241094350815\n",
      "Epoch 4669, Loss: 0.02764605823904276, Final Batch Loss: 0.020600201562047005\n",
      "Epoch 4670, Loss: 0.043789083138108253, Final Batch Loss: 0.021283823996782303\n",
      "Epoch 4671, Loss: 0.026830660179257393, Final Batch Loss: 0.010769641026854515\n",
      "Epoch 4672, Loss: 0.037773724645376205, Final Batch Loss: 0.008281391113996506\n",
      "Epoch 4673, Loss: 0.04408605443313718, Final Batch Loss: 0.004168633837252855\n",
      "Epoch 4674, Loss: 0.02903854101896286, Final Batch Loss: 0.008693771436810493\n",
      "Epoch 4675, Loss: 0.03125354927033186, Final Batch Loss: 0.004499136470258236\n",
      "Epoch 4676, Loss: 0.04281759541481733, Final Batch Loss: 0.010302565060555935\n",
      "Epoch 4677, Loss: 0.038736989721655846, Final Batch Loss: 0.003832319751381874\n",
      "Epoch 4678, Loss: 0.06644789688289165, Final Batch Loss: 0.05262787267565727\n",
      "Epoch 4679, Loss: 0.0558379702270031, Final Batch Loss: 0.027087155729532242\n",
      "Epoch 4680, Loss: 0.028421110473573208, Final Batch Loss: 0.008157829754054546\n",
      "Epoch 4681, Loss: 0.028773496858775616, Final Batch Loss: 0.016988437622785568\n",
      "Epoch 4682, Loss: 0.013594071613624692, Final Batch Loss: 0.0039010329637676477\n",
      "Epoch 4683, Loss: 0.028201185632497072, Final Batch Loss: 0.02323613502085209\n",
      "Epoch 4684, Loss: 0.11445846920832992, Final Batch Loss: 0.10875005275011063\n",
      "Epoch 4685, Loss: 0.016668324125930667, Final Batch Loss: 0.0033035713713616133\n",
      "Epoch 4686, Loss: 0.11448454856872559, Final Batch Loss: 0.07328334450721741\n",
      "Epoch 4687, Loss: 0.02131204679608345, Final Batch Loss: 0.014466418884694576\n",
      "Epoch 4688, Loss: 0.07418859750032425, Final Batch Loss: 0.03453008830547333\n",
      "Epoch 4689, Loss: 0.1128925085067749, Final Batch Loss: 0.01572129875421524\n",
      "Epoch 4690, Loss: 0.06714252568781376, Final Batch Loss: 0.04576515778899193\n",
      "Epoch 4691, Loss: 0.041181111708283424, Final Batch Loss: 0.011931413784623146\n",
      "Epoch 4692, Loss: 0.01929134875535965, Final Batch Loss: 0.007838774472475052\n",
      "Epoch 4693, Loss: 0.01296286704018712, Final Batch Loss: 0.005161772016435862\n",
      "Epoch 4694, Loss: 0.022328108549118042, Final Batch Loss: 0.011900149285793304\n",
      "Epoch 4695, Loss: 0.044645692221820354, Final Batch Loss: 0.008871822617948055\n",
      "Epoch 4696, Loss: 0.07778451032936573, Final Batch Loss: 0.054279811680316925\n",
      "Epoch 4697, Loss: 0.038916582241654396, Final Batch Loss: 0.011615736410021782\n",
      "Epoch 4698, Loss: 0.030556824058294296, Final Batch Loss: 0.02245868369936943\n",
      "Epoch 4699, Loss: 0.05305572599172592, Final Batch Loss: 0.005601353943347931\n",
      "Epoch 4700, Loss: 0.04151087114587426, Final Batch Loss: 0.03687172383069992\n",
      "Epoch 4701, Loss: 0.030527747236192226, Final Batch Loss: 0.010473602451384068\n",
      "Epoch 4702, Loss: 0.04343658126890659, Final Batch Loss: 0.024620404466986656\n",
      "Epoch 4703, Loss: 0.028009841218590736, Final Batch Loss: 0.01916600950062275\n",
      "Epoch 4704, Loss: 0.018365239491686225, Final Batch Loss: 0.0038777419831603765\n",
      "Epoch 4705, Loss: 0.027086968533694744, Final Batch Loss: 0.005120999179780483\n",
      "Epoch 4706, Loss: 0.014604334253817797, Final Batch Loss: 0.008552885614335537\n",
      "Epoch 4707, Loss: 0.015305492328479886, Final Batch Loss: 0.0026990475598722696\n",
      "Epoch 4708, Loss: 0.04485425632447004, Final Batch Loss: 0.008058088831603527\n",
      "Epoch 4709, Loss: 0.05391784757375717, Final Batch Loss: 0.03483806177973747\n",
      "Epoch 4710, Loss: 0.12332115788012743, Final Batch Loss: 0.10848233103752136\n",
      "Epoch 4711, Loss: 0.07842967659235, Final Batch Loss: 0.028479192405939102\n",
      "Epoch 4712, Loss: 0.04224244877696037, Final Batch Loss: 0.01877453923225403\n",
      "Epoch 4713, Loss: 0.015039031859487295, Final Batch Loss: 0.0040201605297625065\n",
      "Epoch 4714, Loss: 0.04886504355818033, Final Batch Loss: 0.01298165787011385\n",
      "Epoch 4715, Loss: 0.022607283666729927, Final Batch Loss: 0.008202743716537952\n",
      "Epoch 4716, Loss: 0.039354472421109676, Final Batch Loss: 0.011392862536013126\n",
      "Epoch 4717, Loss: 0.028674860950559378, Final Batch Loss: 0.007402291055768728\n",
      "Epoch 4718, Loss: 0.11018677335232496, Final Batch Loss: 0.0975281298160553\n",
      "Epoch 4719, Loss: 0.022181982174515724, Final Batch Loss: 0.005610296502709389\n",
      "Epoch 4720, Loss: 0.03610818134620786, Final Batch Loss: 0.007466720882803202\n",
      "Epoch 4721, Loss: 0.07641485054045916, Final Batch Loss: 0.011410032398998737\n",
      "Epoch 4722, Loss: 0.033163273707032204, Final Batch Loss: 0.011894773691892624\n",
      "Epoch 4723, Loss: 0.020138666965067387, Final Batch Loss: 0.012669543735682964\n",
      "Epoch 4724, Loss: 0.05758887995034456, Final Batch Loss: 0.05334310978651047\n",
      "Epoch 4725, Loss: 0.024066276382654905, Final Batch Loss: 0.020917614921927452\n",
      "Epoch 4726, Loss: 0.045908572152256966, Final Batch Loss: 0.01350688748061657\n",
      "Epoch 4727, Loss: 0.08913397695869207, Final Batch Loss: 0.008759594522416592\n",
      "Epoch 4728, Loss: 0.05617108196020126, Final Batch Loss: 0.015982914716005325\n",
      "Epoch 4729, Loss: 0.014273600652813911, Final Batch Loss: 0.008305009454488754\n",
      "Epoch 4730, Loss: 0.030111873522400856, Final Batch Loss: 0.014632505364716053\n",
      "Epoch 4731, Loss: 0.012541277334094048, Final Batch Loss: 0.007800837513059378\n",
      "Epoch 4732, Loss: 0.01132030738517642, Final Batch Loss: 0.006183594465255737\n",
      "Epoch 4733, Loss: 0.03175349906086922, Final Batch Loss: 0.010646270588040352\n",
      "Epoch 4734, Loss: 0.07314383424818516, Final Batch Loss: 0.025460800155997276\n",
      "Epoch 4735, Loss: 0.015379070304334164, Final Batch Loss: 0.005201426334679127\n",
      "Epoch 4736, Loss: 0.01109245722182095, Final Batch Loss: 0.007962505333125591\n",
      "Epoch 4737, Loss: 0.030055503360927105, Final Batch Loss: 0.019462332129478455\n",
      "Epoch 4738, Loss: 0.07317915931344032, Final Batch Loss: 0.057595394551754\n",
      "Epoch 4739, Loss: 0.058403005823493004, Final Batch Loss: 0.03841284662485123\n",
      "Epoch 4740, Loss: 0.061257253400981426, Final Batch Loss: 0.053346503525972366\n",
      "Epoch 4741, Loss: 0.019825744442641735, Final Batch Loss: 0.008386610075831413\n",
      "Epoch 4742, Loss: 0.01986308628693223, Final Batch Loss: 0.014073280617594719\n",
      "Epoch 4743, Loss: 0.01317135151475668, Final Batch Loss: 0.008140061050653458\n",
      "Epoch 4744, Loss: 0.06946973036974669, Final Batch Loss: 0.061629768460989\n",
      "Epoch 4745, Loss: 0.04646819457411766, Final Batch Loss: 0.029068807139992714\n",
      "Epoch 4746, Loss: 0.037773916963487864, Final Batch Loss: 0.006322967354208231\n",
      "Epoch 4747, Loss: 0.016506261192262173, Final Batch Loss: 0.009774445556104183\n",
      "Epoch 4748, Loss: 0.019091114401817322, Final Batch Loss: 0.010237237438559532\n",
      "Epoch 4749, Loss: 0.050327898003160954, Final Batch Loss: 0.009599470533430576\n",
      "Epoch 4750, Loss: 0.017273861914873123, Final Batch Loss: 0.005826873704791069\n",
      "Epoch 4751, Loss: 0.043068673461675644, Final Batch Loss: 0.009892698377370834\n",
      "Epoch 4752, Loss: 0.04610900208353996, Final Batch Loss: 0.007983706891536713\n",
      "Epoch 4753, Loss: 0.023691993206739426, Final Batch Loss: 0.014859937131404877\n",
      "Epoch 4754, Loss: 0.05316160945221782, Final Batch Loss: 0.007669005077332258\n",
      "Epoch 4755, Loss: 0.024543575011193752, Final Batch Loss: 0.011832361109554768\n",
      "Epoch 4756, Loss: 0.020727918948978186, Final Batch Loss: 0.007299841847270727\n",
      "Epoch 4757, Loss: 0.032101658172905445, Final Batch Loss: 0.021483156830072403\n",
      "Epoch 4758, Loss: 0.07695614732801914, Final Batch Loss: 0.022968465462327003\n",
      "Epoch 4759, Loss: 0.03798808949068189, Final Batch Loss: 0.03529217094182968\n",
      "Epoch 4760, Loss: 0.04931618180125952, Final Batch Loss: 0.03647352382540703\n",
      "Epoch 4761, Loss: 0.026167682372033596, Final Batch Loss: 0.012551017105579376\n",
      "Epoch 4762, Loss: 0.04989122552797198, Final Batch Loss: 0.005039616953581572\n",
      "Epoch 4763, Loss: 0.07996287941932678, Final Batch Loss: 0.05025392398238182\n",
      "Epoch 4764, Loss: 0.017074125353246927, Final Batch Loss: 0.006885384675115347\n",
      "Epoch 4765, Loss: 0.03705898392945528, Final Batch Loss: 0.025728905573487282\n",
      "Epoch 4766, Loss: 0.03981760982424021, Final Batch Loss: 0.029728902503848076\n",
      "Epoch 4767, Loss: 0.017033760901540518, Final Batch Loss: 0.00924692116677761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4768, Loss: 0.03077455423772335, Final Batch Loss: 0.022547075524926186\n",
      "Epoch 4769, Loss: 0.030847984366118908, Final Batch Loss: 0.014541669748723507\n",
      "Epoch 4770, Loss: 0.04379897937178612, Final Batch Loss: 0.025616761296987534\n",
      "Epoch 4771, Loss: 0.021705929189920425, Final Batch Loss: 0.016993040218949318\n",
      "Epoch 4772, Loss: 0.014528241474181414, Final Batch Loss: 0.005486680660396814\n",
      "Epoch 4773, Loss: 0.09479454159736633, Final Batch Loss: 0.027986422181129456\n",
      "Epoch 4774, Loss: 0.023196297697722912, Final Batch Loss: 0.015719609335064888\n",
      "Epoch 4775, Loss: 0.020603445824235678, Final Batch Loss: 0.015402374789118767\n",
      "Epoch 4776, Loss: 0.013200992718338966, Final Batch Loss: 0.00805641245096922\n",
      "Epoch 4777, Loss: 0.04248631373047829, Final Batch Loss: 0.0304876696318388\n",
      "Epoch 4778, Loss: 0.010518923169001937, Final Batch Loss: 0.00688367011025548\n",
      "Epoch 4779, Loss: 0.051643332466483116, Final Batch Loss: 0.008291585370898247\n",
      "Epoch 4780, Loss: 0.01144018943887204, Final Batch Loss: 0.0018192407442256808\n",
      "Epoch 4781, Loss: 0.023023871704936028, Final Batch Loss: 0.014925431460142136\n",
      "Epoch 4782, Loss: 0.031349406111985445, Final Batch Loss: 0.005346686113625765\n",
      "Epoch 4783, Loss: 0.019081543432548642, Final Batch Loss: 0.003528693923726678\n",
      "Epoch 4784, Loss: 0.03329419158399105, Final Batch Loss: 0.007672006264328957\n",
      "Epoch 4785, Loss: 0.023894664831459522, Final Batch Loss: 0.007259831763803959\n",
      "Epoch 4786, Loss: 0.018302918411791325, Final Batch Loss: 0.013062283396720886\n",
      "Epoch 4787, Loss: 0.017484482610598207, Final Batch Loss: 0.013791748322546482\n",
      "Epoch 4788, Loss: 0.02621043100953102, Final Batch Loss: 0.01602996699512005\n",
      "Epoch 4789, Loss: 0.016178262885659933, Final Batch Loss: 0.008508195169270039\n",
      "Epoch 4790, Loss: 0.010196943301707506, Final Batch Loss: 0.006200350821018219\n",
      "Epoch 4791, Loss: 0.02845149952918291, Final Batch Loss: 0.016650129109621048\n",
      "Epoch 4792, Loss: 0.022105294279754162, Final Batch Loss: 0.011881320737302303\n",
      "Epoch 4793, Loss: 0.03274089749902487, Final Batch Loss: 0.021367089822888374\n",
      "Epoch 4794, Loss: 0.023363446351140738, Final Batch Loss: 0.006649637129157782\n",
      "Epoch 4795, Loss: 0.023281574249267578, Final Batch Loss: 0.004943067207932472\n",
      "Epoch 4796, Loss: 0.037879081442952156, Final Batch Loss: 0.021468140184879303\n",
      "Epoch 4797, Loss: 0.04732394916936755, Final Batch Loss: 0.006167005281895399\n",
      "Epoch 4798, Loss: 0.057388486340641975, Final Batch Loss: 0.0382549874484539\n",
      "Epoch 4799, Loss: 0.02069329097867012, Final Batch Loss: 0.006484323181211948\n",
      "Epoch 4800, Loss: 0.08089119847863913, Final Batch Loss: 0.072335384786129\n",
      "Epoch 4801, Loss: 0.02756877988576889, Final Batch Loss: 0.014101486653089523\n",
      "Epoch 4802, Loss: 0.0378010228741914, Final Batch Loss: 0.03428136184811592\n",
      "Epoch 4803, Loss: 0.010746166575700045, Final Batch Loss: 0.005353015847504139\n",
      "Epoch 4804, Loss: 0.01339450990781188, Final Batch Loss: 0.005482095759361982\n",
      "Epoch 4805, Loss: 0.012750215362757444, Final Batch Loss: 0.005072542000561953\n",
      "Epoch 4806, Loss: 0.007248393725603819, Final Batch Loss: 0.002360701560974121\n",
      "Epoch 4807, Loss: 0.007789935567416251, Final Batch Loss: 0.001883329008705914\n",
      "Epoch 4808, Loss: 0.012482861522585154, Final Batch Loss: 0.004811965394765139\n",
      "Epoch 4809, Loss: 0.02351915556937456, Final Batch Loss: 0.008544078096747398\n",
      "Epoch 4810, Loss: 0.006563802482560277, Final Batch Loss: 0.00368703156709671\n",
      "Epoch 4811, Loss: 0.0415581613779068, Final Batch Loss: 0.026082172989845276\n",
      "Epoch 4812, Loss: 0.006617499748244882, Final Batch Loss: 0.0032361929770559072\n",
      "Epoch 4813, Loss: 0.0467926524579525, Final Batch Loss: 0.017812136560678482\n",
      "Epoch 4814, Loss: 0.015136159490793943, Final Batch Loss: 0.005368594545871019\n",
      "Epoch 4815, Loss: 0.07662679441273212, Final Batch Loss: 0.052180562168359756\n",
      "Epoch 4816, Loss: 0.07457365770824254, Final Batch Loss: 0.003476253943517804\n",
      "Epoch 4817, Loss: 0.012806192971765995, Final Batch Loss: 0.00745844142511487\n",
      "Epoch 4818, Loss: 0.020699908025562763, Final Batch Loss: 0.01356164738535881\n",
      "Epoch 4819, Loss: 0.03165726503357291, Final Batch Loss: 0.02423267439007759\n",
      "Epoch 4820, Loss: 0.024040330201387405, Final Batch Loss: 0.011567358858883381\n",
      "Epoch 4821, Loss: 0.11188230849802494, Final Batch Loss: 0.09387039393186569\n",
      "Epoch 4822, Loss: 0.051518787164241076, Final Batch Loss: 0.005354170221835375\n",
      "Epoch 4823, Loss: 0.06642027385532856, Final Batch Loss: 0.028679491952061653\n",
      "Epoch 4824, Loss: 0.10362542048096657, Final Batch Loss: 0.03633320704102516\n",
      "Epoch 4825, Loss: 0.03994846995919943, Final Batch Loss: 0.0288727805018425\n",
      "Epoch 4826, Loss: 0.1351337656378746, Final Batch Loss: 0.10080579668283463\n",
      "Epoch 4827, Loss: 0.10980438254773617, Final Batch Loss: 0.0877147689461708\n",
      "Epoch 4828, Loss: 0.046405376866459846, Final Batch Loss: 0.03420419245958328\n",
      "Epoch 4829, Loss: 0.02214818587526679, Final Batch Loss: 0.004661086481064558\n",
      "Epoch 4830, Loss: 0.030077140778303146, Final Batch Loss: 0.017889181151986122\n",
      "Epoch 4831, Loss: 0.10194352641701698, Final Batch Loss: 0.0644703283905983\n",
      "Epoch 4832, Loss: 0.0648180115967989, Final Batch Loss: 0.040412381291389465\n",
      "Epoch 4833, Loss: 0.04229958262294531, Final Batch Loss: 0.008449035696685314\n",
      "Epoch 4834, Loss: 0.0780473779886961, Final Batch Loss: 0.02646043710410595\n",
      "Epoch 4835, Loss: 0.034947652369737625, Final Batch Loss: 0.018690669909119606\n",
      "Epoch 4836, Loss: 0.11932307481765747, Final Batch Loss: 0.07572317868471146\n",
      "Epoch 4837, Loss: 0.0417089257389307, Final Batch Loss: 0.02793959341943264\n",
      "Epoch 4838, Loss: 0.03603144362568855, Final Batch Loss: 0.025418924167752266\n",
      "Epoch 4839, Loss: 0.04927768558263779, Final Batch Loss: 0.009930260479450226\n",
      "Epoch 4840, Loss: 0.09146666154265404, Final Batch Loss: 0.06026974692940712\n",
      "Epoch 4841, Loss: 0.05761037394404411, Final Batch Loss: 0.04151253402233124\n",
      "Epoch 4842, Loss: 0.0550652239471674, Final Batch Loss: 0.022008856758475304\n",
      "Epoch 4843, Loss: 0.021506049670279026, Final Batch Loss: 0.014413034543395042\n",
      "Epoch 4844, Loss: 0.06210132781416178, Final Batch Loss: 0.005847030319273472\n",
      "Epoch 4845, Loss: 0.013774416409432888, Final Batch Loss: 0.004951522685587406\n",
      "Epoch 4846, Loss: 0.056527888402342796, Final Batch Loss: 0.020403722301125526\n",
      "Epoch 4847, Loss: 0.027482195757329464, Final Batch Loss: 0.01392209529876709\n",
      "Epoch 4848, Loss: 0.03171255998313427, Final Batch Loss: 0.011113835498690605\n",
      "Epoch 4849, Loss: 0.01964012859389186, Final Batch Loss: 0.00749218137934804\n",
      "Epoch 4850, Loss: 0.036588650196790695, Final Batch Loss: 0.012802865356206894\n",
      "Epoch 4851, Loss: 0.07463378459215164, Final Batch Loss: 0.027531445026397705\n",
      "Epoch 4852, Loss: 0.030373638030141592, Final Batch Loss: 0.02514846995472908\n",
      "Epoch 4853, Loss: 0.04151232959702611, Final Batch Loss: 0.034271240234375\n",
      "Epoch 4854, Loss: 0.06259609665721655, Final Batch Loss: 0.009065966121852398\n",
      "Epoch 4855, Loss: 0.06476221885532141, Final Batch Loss: 0.056794777512550354\n",
      "Epoch 4856, Loss: 0.046962615102529526, Final Batch Loss: 0.011396471410989761\n",
      "Epoch 4857, Loss: 0.05435654893517494, Final Batch Loss: 0.01684011146426201\n",
      "Epoch 4858, Loss: 0.0067403195425868034, Final Batch Loss: 0.0036839826498180628\n",
      "Epoch 4859, Loss: 0.08575649186968803, Final Batch Loss: 0.05488331988453865\n",
      "Epoch 4860, Loss: 0.03091991413384676, Final Batch Loss: 0.01268020924180746\n",
      "Epoch 4861, Loss: 0.10394231230020523, Final Batch Loss: 0.07122492045164108\n",
      "Epoch 4862, Loss: 0.03454653965309262, Final Batch Loss: 0.029206600040197372\n",
      "Epoch 4863, Loss: 0.038599721156060696, Final Batch Loss: 0.023557119071483612\n",
      "Epoch 4864, Loss: 0.03875403292477131, Final Batch Loss: 0.004054835066199303\n",
      "Epoch 4865, Loss: 0.06914248131215572, Final Batch Loss: 0.013651309534907341\n",
      "Epoch 4866, Loss: 0.028829551534727216, Final Batch Loss: 0.0028818112332373857\n",
      "Epoch 4867, Loss: 0.02724907547235489, Final Batch Loss: 0.00513743981719017\n",
      "Epoch 4868, Loss: 0.027021212503314018, Final Batch Loss: 0.003761397674679756\n",
      "Epoch 4869, Loss: 0.025324170477688313, Final Batch Loss: 0.010933644138276577\n",
      "Epoch 4870, Loss: 0.04061475954949856, Final Batch Loss: 0.005375640466809273\n",
      "Epoch 4871, Loss: 0.11162818968296051, Final Batch Loss: 0.035156555473804474\n",
      "Epoch 4872, Loss: 0.024515213444828987, Final Batch Loss: 0.01462589018046856\n",
      "Epoch 4873, Loss: 0.024329947773367167, Final Batch Loss: 0.01923084445297718\n",
      "Epoch 4874, Loss: 0.035788063891232014, Final Batch Loss: 0.011833795346319675\n",
      "Epoch 4875, Loss: 0.04841898940503597, Final Batch Loss: 0.04102311655879021\n",
      "Epoch 4876, Loss: 0.009825436864048243, Final Batch Loss: 0.006526667159050703\n",
      "Epoch 4877, Loss: 0.03678849712014198, Final Batch Loss: 0.020966289564967155\n",
      "Epoch 4878, Loss: 0.023011300712823868, Final Batch Loss: 0.01859930530190468\n",
      "Epoch 4879, Loss: 0.0152551238425076, Final Batch Loss: 0.00824106577783823\n",
      "Epoch 4880, Loss: 0.05858304724097252, Final Batch Loss: 0.008539479225873947\n",
      "Epoch 4881, Loss: 0.03404810652136803, Final Batch Loss: 0.008316369727253914\n",
      "Epoch 4882, Loss: 0.03605083283036947, Final Batch Loss: 0.011696751229465008\n",
      "Epoch 4883, Loss: 0.014814695809036493, Final Batch Loss: 0.005477879662066698\n",
      "Epoch 4884, Loss: 0.05753354914486408, Final Batch Loss: 0.04125316068530083\n",
      "Epoch 4885, Loss: 0.032129296101629734, Final Batch Loss: 0.006229556165635586\n",
      "Epoch 4886, Loss: 0.026664840057492256, Final Batch Loss: 0.011962596327066422\n",
      "Epoch 4887, Loss: 0.010608146898448467, Final Batch Loss: 0.002539423294365406\n",
      "Epoch 4888, Loss: 0.017055490985512733, Final Batch Loss: 0.003365124575793743\n",
      "Epoch 4889, Loss: 0.023463459219783545, Final Batch Loss: 0.0032709850929677486\n",
      "Epoch 4890, Loss: 0.048995028249919415, Final Batch Loss: 0.007356314919888973\n",
      "Epoch 4891, Loss: 0.009533207630738616, Final Batch Loss: 0.0026701970491558313\n",
      "Epoch 4892, Loss: 0.03712634276598692, Final Batch Loss: 0.032338861376047134\n",
      "Epoch 4893, Loss: 0.04964051581919193, Final Batch Loss: 0.022661177441477776\n",
      "Epoch 4894, Loss: 0.07943490892648697, Final Batch Loss: 0.06852903962135315\n",
      "Epoch 4895, Loss: 0.013127350946888328, Final Batch Loss: 0.0026191126089543104\n",
      "Epoch 4896, Loss: 0.030033935327082872, Final Batch Loss: 0.004995363298803568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4897, Loss: 0.05837918957695365, Final Batch Loss: 0.0019720769487321377\n",
      "Epoch 4898, Loss: 0.012577638030052185, Final Batch Loss: 0.005253720562905073\n",
      "Epoch 4899, Loss: 0.12098958063870668, Final Batch Loss: 0.11321906745433807\n",
      "Epoch 4900, Loss: 0.04174316441640258, Final Batch Loss: 0.03504155948758125\n",
      "Epoch 4901, Loss: 0.05952721042558551, Final Batch Loss: 0.006385821383446455\n",
      "Epoch 4902, Loss: 0.1499871639534831, Final Batch Loss: 0.011945920996367931\n",
      "Epoch 4903, Loss: 0.031716194935142994, Final Batch Loss: 0.005990779958665371\n",
      "Epoch 4904, Loss: 0.027270644903182983, Final Batch Loss: 0.006180375814437866\n",
      "Epoch 4905, Loss: 0.07112362515181303, Final Batch Loss: 0.06095818802714348\n",
      "Epoch 4906, Loss: 0.010146853281185031, Final Batch Loss: 0.0019894593860954046\n",
      "Epoch 4907, Loss: 0.12338182143867016, Final Batch Loss: 0.11562670022249222\n",
      "Epoch 4908, Loss: 0.05043829791247845, Final Batch Loss: 0.011980211362242699\n",
      "Epoch 4909, Loss: 0.04227781854569912, Final Batch Loss: 0.01807846501469612\n",
      "Epoch 4910, Loss: 0.12216424569487572, Final Batch Loss: 0.04737091436982155\n",
      "Epoch 4911, Loss: 0.08269223850220442, Final Batch Loss: 0.07363900542259216\n",
      "Epoch 4912, Loss: 0.04700654372572899, Final Batch Loss: 0.026202332228422165\n",
      "Epoch 4913, Loss: 0.1807541847229004, Final Batch Loss: 0.13657508790493011\n",
      "Epoch 4914, Loss: 0.07290391065180302, Final Batch Loss: 0.05707196518778801\n",
      "Epoch 4915, Loss: 0.12355038896203041, Final Batch Loss: 0.06252066045999527\n",
      "Epoch 4916, Loss: 0.14296040311455727, Final Batch Loss: 0.04949374124407768\n",
      "Epoch 4917, Loss: 0.08672761917114258, Final Batch Loss: 0.05468803644180298\n",
      "Epoch 4918, Loss: 0.0753763597458601, Final Batch Loss: 0.027993453666567802\n",
      "Epoch 4919, Loss: 0.04407442966476083, Final Batch Loss: 0.03790067881345749\n",
      "Epoch 4920, Loss: 0.08212333917617798, Final Batch Loss: 0.03648388758301735\n",
      "Epoch 4921, Loss: 0.033866976387798786, Final Batch Loss: 0.022553009912371635\n",
      "Epoch 4922, Loss: 0.07697494328022003, Final Batch Loss: 0.04365188255906105\n",
      "Epoch 4923, Loss: 0.05013254377990961, Final Batch Loss: 0.011109107173979282\n",
      "Epoch 4924, Loss: 0.09934365376830101, Final Batch Loss: 0.03831733018159866\n",
      "Epoch 4925, Loss: 0.05346611142158508, Final Batch Loss: 0.014608774334192276\n",
      "Epoch 4926, Loss: 0.023287620395421982, Final Batch Loss: 0.009915930218994617\n",
      "Epoch 4927, Loss: 0.059102913830429316, Final Batch Loss: 0.05143912881612778\n",
      "Epoch 4928, Loss: 0.06994809955358505, Final Batch Loss: 0.03460850939154625\n",
      "Epoch 4929, Loss: 0.022628160193562508, Final Batch Loss: 0.011291345581412315\n",
      "Epoch 4930, Loss: 0.03385963477194309, Final Batch Loss: 0.010177494958043098\n",
      "Epoch 4931, Loss: 0.06351918214932084, Final Batch Loss: 0.056099746376276016\n",
      "Epoch 4932, Loss: 0.0655690710991621, Final Batch Loss: 0.04114864766597748\n",
      "Epoch 4933, Loss: 0.015240808948874474, Final Batch Loss: 0.005192208103835583\n",
      "Epoch 4934, Loss: 0.014264106750488281, Final Batch Loss: 0.008904827758669853\n",
      "Epoch 4935, Loss: 0.020715435035526752, Final Batch Loss: 0.0068835606798529625\n",
      "Epoch 4936, Loss: 0.03084993502125144, Final Batch Loss: 0.004049943294376135\n",
      "Epoch 4937, Loss: 0.0355616114102304, Final Batch Loss: 0.0043722945265471935\n",
      "Epoch 4938, Loss: 0.02443597186356783, Final Batch Loss: 0.017376570031046867\n",
      "Epoch 4939, Loss: 0.02668141620233655, Final Batch Loss: 0.005915297660976648\n",
      "Epoch 4940, Loss: 0.02299178810790181, Final Batch Loss: 0.004733801353722811\n",
      "Epoch 4941, Loss: 0.021479858085513115, Final Batch Loss: 0.011371429078280926\n",
      "Epoch 4942, Loss: 0.05226650461554527, Final Batch Loss: 0.028707409277558327\n",
      "Epoch 4943, Loss: 0.02292946120724082, Final Batch Loss: 0.004840973298996687\n",
      "Epoch 4944, Loss: 0.012814847752451897, Final Batch Loss: 0.006270896643400192\n",
      "Epoch 4945, Loss: 0.06413293536752462, Final Batch Loss: 0.056984927505254745\n",
      "Epoch 4946, Loss: 0.03954065078869462, Final Batch Loss: 0.002886506263166666\n",
      "Epoch 4947, Loss: 0.023074904922395945, Final Batch Loss: 0.017971757799386978\n",
      "Epoch 4948, Loss: 0.08887068554759026, Final Batch Loss: 0.07631625980138779\n",
      "Epoch 4949, Loss: 0.054802704602479935, Final Batch Loss: 0.044980376958847046\n",
      "Epoch 4950, Loss: 0.03806252218782902, Final Batch Loss: 0.01159093901515007\n",
      "Epoch 4951, Loss: 0.01989875454455614, Final Batch Loss: 0.005901661701500416\n",
      "Epoch 4952, Loss: 0.010910079116001725, Final Batch Loss: 0.0034185091499239206\n",
      "Epoch 4953, Loss: 0.008589253993704915, Final Batch Loss: 0.0038436746690422297\n",
      "Epoch 4954, Loss: 0.034419281990267336, Final Batch Loss: 0.00144350400660187\n",
      "Epoch 4955, Loss: 0.059389409609138966, Final Batch Loss: 0.006948427297174931\n",
      "Epoch 4956, Loss: 0.03322651609778404, Final Batch Loss: 0.010196762159466743\n",
      "Epoch 4957, Loss: 0.026107579935342073, Final Batch Loss: 0.007018823642283678\n",
      "Epoch 4958, Loss: 0.03378396201878786, Final Batch Loss: 0.023426586762070656\n",
      "Epoch 4959, Loss: 0.024115402717143297, Final Batch Loss: 0.004238298628479242\n",
      "Epoch 4960, Loss: 0.0266881100833416, Final Batch Loss: 0.019123470410704613\n",
      "Epoch 4961, Loss: 0.07561603002250195, Final Batch Loss: 0.05667797476053238\n",
      "Epoch 4962, Loss: 0.01730891317129135, Final Batch Loss: 0.008616628125309944\n",
      "Epoch 4963, Loss: 0.041504350723698735, Final Batch Loss: 0.003715505125001073\n",
      "Epoch 4964, Loss: 0.01823088340461254, Final Batch Loss: 0.007974674925208092\n",
      "Epoch 4965, Loss: 0.04636585898697376, Final Batch Loss: 0.031079964712262154\n",
      "Epoch 4966, Loss: 0.06267941184341908, Final Batch Loss: 0.04051487147808075\n",
      "Epoch 4967, Loss: 0.030391475185751915, Final Batch Loss: 0.02596113085746765\n",
      "Epoch 4968, Loss: 0.03189406916499138, Final Batch Loss: 0.010121488943696022\n",
      "Epoch 4969, Loss: 0.02929716184735298, Final Batch Loss: 0.013052461668848991\n",
      "Epoch 4970, Loss: 0.02809968451038003, Final Batch Loss: 0.020459260791540146\n",
      "Epoch 4971, Loss: 0.007684761192649603, Final Batch Loss: 0.00398597028106451\n",
      "Epoch 4972, Loss: 0.060198962688446045, Final Batch Loss: 0.0162322036921978\n",
      "Epoch 4973, Loss: 0.029259451664984226, Final Batch Loss: 0.002465606667101383\n",
      "Epoch 4974, Loss: 0.03609991678968072, Final Batch Loss: 0.006341301370412111\n",
      "Epoch 4975, Loss: 0.04377812519669533, Final Batch Loss: 0.02752561680972576\n",
      "Epoch 4976, Loss: 0.01995706744492054, Final Batch Loss: 0.0054628681391477585\n",
      "Epoch 4977, Loss: 0.07809958071447909, Final Batch Loss: 0.07470076531171799\n",
      "Epoch 4978, Loss: 0.05993781052529812, Final Batch Loss: 0.03827871009707451\n",
      "Epoch 4979, Loss: 0.014602246694266796, Final Batch Loss: 0.005493737757205963\n",
      "Epoch 4980, Loss: 0.06063498929142952, Final Batch Loss: 0.019268713891506195\n",
      "Epoch 4981, Loss: 0.026053864508867264, Final Batch Loss: 0.016513561829924583\n",
      "Epoch 4982, Loss: 0.04301991779357195, Final Batch Loss: 0.004067444242537022\n",
      "Epoch 4983, Loss: 0.013359268545173109, Final Batch Loss: 0.001437834813259542\n",
      "Epoch 4984, Loss: 0.023325441405177116, Final Batch Loss: 0.013731114566326141\n",
      "Epoch 4985, Loss: 0.013325507286936045, Final Batch Loss: 0.005986938718706369\n",
      "Epoch 4986, Loss: 0.010071832221001387, Final Batch Loss: 0.003156314603984356\n",
      "Epoch 4987, Loss: 0.10092572495341301, Final Batch Loss: 0.08069365471601486\n",
      "Epoch 4988, Loss: 0.061306451447308064, Final Batch Loss: 0.05734643340110779\n",
      "Epoch 4989, Loss: 0.027809614082798362, Final Batch Loss: 0.0015553624834865332\n",
      "Epoch 4990, Loss: 0.03636823873966932, Final Batch Loss: 0.025775132700800896\n",
      "Epoch 4991, Loss: 0.08411143533885479, Final Batch Loss: 0.05497077852487564\n",
      "Epoch 4992, Loss: 0.03824698831886053, Final Batch Loss: 0.012880499474704266\n",
      "Epoch 4993, Loss: 0.045078739523887634, Final Batch Loss: 0.022850356996059418\n",
      "Epoch 4994, Loss: 0.025275010615587234, Final Batch Loss: 0.00493730790913105\n",
      "Epoch 4995, Loss: 0.04063153825700283, Final Batch Loss: 0.010614773258566856\n",
      "Epoch 4996, Loss: 0.024187026545405388, Final Batch Loss: 0.01698239892721176\n",
      "Epoch 4997, Loss: 0.029468143125995994, Final Batch Loss: 0.0038147286977618933\n",
      "Epoch 4998, Loss: 0.018090611789375544, Final Batch Loss: 0.00647363206371665\n",
      "Epoch 4999, Loss: 0.03466813173145056, Final Batch Loss: 0.004737379960715771\n",
      "Epoch 5000, Loss: 0.006727170664817095, Final Batch Loss: 0.004030688665807247\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0  0]\n",
      " [ 0 31  0]\n",
      " [ 0  0 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        35\n",
      "           1    1.00000   1.00000   1.00000        31\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "\n",
      "    accuracy                        1.00000        97\n",
      "   macro avg    1.00000   1.00000   1.00000        97\n",
      "weighted avg    1.00000   1.00000   1.00000        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  5]\n",
      " [ 4 21  5]\n",
      " [ 2  1 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80645   0.83333   0.81967        30\n",
      "           1    0.95455   0.70000   0.80769        30\n",
      "           2    0.72973   0.90000   0.80597        30\n",
      "\n",
      "    accuracy                        0.81111        90\n",
      "   macro avg    0.83024   0.81111   0.81111        90\n",
      "weighted avg    0.83024   0.81111   0.81111        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
