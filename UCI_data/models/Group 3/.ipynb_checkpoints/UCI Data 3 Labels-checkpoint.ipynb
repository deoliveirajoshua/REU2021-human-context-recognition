{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>125 tBodyGyro-std()-Y</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>506 fBodyAccMag-max()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.976623</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.974321</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.989046</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.978226</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.993552</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.993062</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.992407</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.990230</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.992378</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.990506</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.065142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.401674</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.410577</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.362904</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.190360</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.397687</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.620014</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  59 tGravityAcc-energy()-Z  \\\n",
       "0                   0.056483             -0.375426                  -0.975510   \n",
       "1                   0.102764             -0.383430                  -0.978500   \n",
       "2                   0.102764             -0.401602                  -0.981672   \n",
       "3                   0.095753             -0.400278                  -0.982420   \n",
       "4                   0.094059             -0.400477                  -0.984363   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.995193   \n",
       "7348               -0.068919             -0.358934                  -0.995151   \n",
       "7349               -0.068919             -0.377025                  -0.995450   \n",
       "7350               -0.040009             -0.440050                  -0.998824   \n",
       "7351               -0.047491             -0.432003                  -0.998144   \n",
       "\n",
       "      125 tBodyGyro-std()-Y  128 tBodyGyro-mad()-Y  ...  \\\n",
       "0                 -0.976623              -0.976353  ...   \n",
       "1                 -0.989046              -0.989038  ...   \n",
       "2                 -0.993552              -0.994122  ...   \n",
       "3                 -0.992407              -0.993142  ...   \n",
       "4                 -0.992378              -0.992542  ...   \n",
       "...                     ...                    ...  ...   \n",
       "7347               0.084878               0.065142  ...   \n",
       "7348               0.098249               0.091791  ...   \n",
       "7349               0.185902               0.170686  ...   \n",
       "7350               0.190360               0.178939  ...   \n",
       "7351               0.022216              -0.073681  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      504 fBodyAccMag-std()  505 fBodyAccMag-mad()  506 fBodyAccMag-max()  \\\n",
       "0                 -0.956134              -0.948870              -0.974321   \n",
       "1                 -0.975866              -0.975777              -0.978226   \n",
       "2                 -0.989015              -0.985594              -0.993062   \n",
       "3                 -0.986742              -0.983524              -0.990230   \n",
       "4                 -0.990063              -0.992324              -0.990506   \n",
       "...                     ...                    ...                    ...   \n",
       "7347              -0.232600              -0.007392              -0.401674   \n",
       "7348              -0.275373              -0.172448              -0.410577   \n",
       "7349              -0.220288              -0.216074              -0.362904   \n",
       "7350              -0.234539              -0.220443              -0.397687   \n",
       "7351              -0.342670              -0.146649              -0.620014   \n",
       "\n",
       "      509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                    -0.998285         5        1  \n",
       "1                    -0.999472         5        1  \n",
       "2                    -0.999807         5        1  \n",
       "3                    -0.999770         5        1  \n",
       "4                    -0.999873         5        1  \n",
       "...                        ...       ...      ...  \n",
       "7347                 -0.584282         2       30  \n",
       "7348                 -0.632536         2       30  \n",
       "7349                 -0.641170         2       30  \n",
       "7350                 -0.663579         2       30  \n",
       "7351                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([14, 15, 17])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([14, 15, 17])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1884469985961914, Final Batch Loss: 1.0937533378601074\n",
      "Epoch 2, Loss: 2.1778552532196045, Final Batch Loss: 1.0887830257415771\n",
      "Epoch 3, Loss: 2.1718538999557495, Final Batch Loss: 1.0823500156402588\n",
      "Epoch 4, Loss: 2.1624797582626343, Final Batch Loss: 1.0751487016677856\n",
      "Epoch 5, Loss: 2.159520983695984, Final Batch Loss: 1.0749386548995972\n",
      "Epoch 6, Loss: 2.1509028673171997, Final Batch Loss: 1.0757124423980713\n",
      "Epoch 7, Loss: 2.1351670026779175, Final Batch Loss: 1.0639897584915161\n",
      "Epoch 8, Loss: 2.1194241046905518, Final Batch Loss: 1.0504930019378662\n",
      "Epoch 9, Loss: 2.1049293279647827, Final Batch Loss: 1.0508451461791992\n",
      "Epoch 10, Loss: 2.095505714416504, Final Batch Loss: 1.0451767444610596\n",
      "Epoch 11, Loss: 2.0758254528045654, Final Batch Loss: 1.0291024446487427\n",
      "Epoch 12, Loss: 2.059468150138855, Final Batch Loss: 1.0302376747131348\n",
      "Epoch 13, Loss: 2.035524010658264, Final Batch Loss: 1.0240482091903687\n",
      "Epoch 14, Loss: 2.0206947326660156, Final Batch Loss: 1.0024808645248413\n",
      "Epoch 15, Loss: 1.9889898896217346, Final Batch Loss: 0.9824054837226868\n",
      "Epoch 16, Loss: 1.9602379202842712, Final Batch Loss: 0.974653422832489\n",
      "Epoch 17, Loss: 1.936776041984558, Final Batch Loss: 0.9724896550178528\n",
      "Epoch 18, Loss: 1.909703552722931, Final Batch Loss: 0.9639391303062439\n",
      "Epoch 19, Loss: 1.8862510919570923, Final Batch Loss: 0.9370545744895935\n",
      "Epoch 20, Loss: 1.842380940914154, Final Batch Loss: 0.9196010828018188\n",
      "Epoch 21, Loss: 1.8154655694961548, Final Batch Loss: 0.9067789316177368\n",
      "Epoch 22, Loss: 1.7728826999664307, Final Batch Loss: 0.8904380202293396\n",
      "Epoch 23, Loss: 1.7374314069747925, Final Batch Loss: 0.8699656128883362\n",
      "Epoch 24, Loss: 1.6828205585479736, Final Batch Loss: 0.8189348578453064\n",
      "Epoch 25, Loss: 1.6737180948257446, Final Batch Loss: 0.838809072971344\n",
      "Epoch 26, Loss: 1.6283667087554932, Final Batch Loss: 0.802619993686676\n",
      "Epoch 27, Loss: 1.5877066254615784, Final Batch Loss: 0.7777355313301086\n",
      "Epoch 28, Loss: 1.5351201295852661, Final Batch Loss: 0.7405984401702881\n",
      "Epoch 29, Loss: 1.5089527368545532, Final Batch Loss: 0.7538536787033081\n",
      "Epoch 30, Loss: 1.4425498247146606, Final Batch Loss: 0.7166416049003601\n",
      "Epoch 31, Loss: 1.4043445587158203, Final Batch Loss: 0.6975467801094055\n",
      "Epoch 32, Loss: 1.3505799770355225, Final Batch Loss: 0.6793861389160156\n",
      "Epoch 33, Loss: 1.3165153861045837, Final Batch Loss: 0.6799975633621216\n",
      "Epoch 34, Loss: 1.2429016828536987, Final Batch Loss: 0.615073561668396\n",
      "Epoch 35, Loss: 1.2254464626312256, Final Batch Loss: 0.6258079409599304\n",
      "Epoch 36, Loss: 1.1705095171928406, Final Batch Loss: 0.5890017151832581\n",
      "Epoch 37, Loss: 1.140011191368103, Final Batch Loss: 0.5509093403816223\n",
      "Epoch 38, Loss: 1.080177903175354, Final Batch Loss: 0.5278679132461548\n",
      "Epoch 39, Loss: 1.0507925748825073, Final Batch Loss: 0.5126284956932068\n",
      "Epoch 40, Loss: 0.975310355424881, Final Batch Loss: 0.4836697280406952\n",
      "Epoch 41, Loss: 0.9472849667072296, Final Batch Loss: 0.44688889384269714\n",
      "Epoch 42, Loss: 0.9712859690189362, Final Batch Loss: 0.5055703520774841\n",
      "Epoch 43, Loss: 0.9099359810352325, Final Batch Loss: 0.4441072344779968\n",
      "Epoch 44, Loss: 0.8486370742321014, Final Batch Loss: 0.4174611270427704\n",
      "Epoch 45, Loss: 0.8105012476444244, Final Batch Loss: 0.3997010886669159\n",
      "Epoch 46, Loss: 0.8422968685626984, Final Batch Loss: 0.42890116572380066\n",
      "Epoch 47, Loss: 0.7480227947235107, Final Batch Loss: 0.3676837384700775\n",
      "Epoch 48, Loss: 0.7153096199035645, Final Batch Loss: 0.335231214761734\n",
      "Epoch 49, Loss: 0.6645658016204834, Final Batch Loss: 0.3296973705291748\n",
      "Epoch 50, Loss: 0.6427665054798126, Final Batch Loss: 0.3325141966342926\n",
      "Epoch 51, Loss: 0.622850775718689, Final Batch Loss: 0.31888481974601746\n",
      "Epoch 52, Loss: 0.5750902891159058, Final Batch Loss: 0.26809558272361755\n",
      "Epoch 53, Loss: 0.5281222313642502, Final Batch Loss: 0.28381937742233276\n",
      "Epoch 54, Loss: 0.5344806015491486, Final Batch Loss: 0.2639993131160736\n",
      "Epoch 55, Loss: 0.5325561463832855, Final Batch Loss: 0.2659764289855957\n",
      "Epoch 56, Loss: 0.4784773737192154, Final Batch Loss: 0.21348612010478973\n",
      "Epoch 57, Loss: 0.42348872125148773, Final Batch Loss: 0.17360708117485046\n",
      "Epoch 58, Loss: 0.39020466804504395, Final Batch Loss: 0.17606519162654877\n",
      "Epoch 59, Loss: 0.4451711028814316, Final Batch Loss: 0.21506820619106293\n",
      "Epoch 60, Loss: 0.3864971697330475, Final Batch Loss: 0.19115322828292847\n",
      "Epoch 61, Loss: 0.38941556215286255, Final Batch Loss: 0.20738054811954498\n",
      "Epoch 62, Loss: 0.36002105474472046, Final Batch Loss: 0.16437163949012756\n",
      "Epoch 63, Loss: 0.3639134615659714, Final Batch Loss: 0.1637360006570816\n",
      "Epoch 64, Loss: 0.3031160309910774, Final Batch Loss: 0.11294575780630112\n",
      "Epoch 65, Loss: 0.28786296397447586, Final Batch Loss: 0.12136977165937424\n",
      "Epoch 66, Loss: 0.29098473489284515, Final Batch Loss: 0.14274409413337708\n",
      "Epoch 67, Loss: 0.2708393633365631, Final Batch Loss: 0.13587388396263123\n",
      "Epoch 68, Loss: 0.2737816274166107, Final Batch Loss: 0.13759811222553253\n",
      "Epoch 69, Loss: 0.2295476719737053, Final Batch Loss: 0.10965204238891602\n",
      "Epoch 70, Loss: 0.22243231534957886, Final Batch Loss: 0.1257796734571457\n",
      "Epoch 71, Loss: 0.253487192094326, Final Batch Loss: 0.11974673718214035\n",
      "Epoch 72, Loss: 0.16953065991401672, Final Batch Loss: 0.06752018630504608\n",
      "Epoch 73, Loss: 0.23564355075359344, Final Batch Loss: 0.14182910323143005\n",
      "Epoch 74, Loss: 0.17589711397886276, Final Batch Loss: 0.11133641749620438\n",
      "Epoch 75, Loss: 0.19391659647226334, Final Batch Loss: 0.09562374651432037\n",
      "Epoch 76, Loss: 0.2054547592997551, Final Batch Loss: 0.11182442307472229\n",
      "Epoch 77, Loss: 0.1985810101032257, Final Batch Loss: 0.10887505859136581\n",
      "Epoch 78, Loss: 0.16512249410152435, Final Batch Loss: 0.08655821532011032\n",
      "Epoch 79, Loss: 0.1237318255007267, Final Batch Loss: 0.055016759783029556\n",
      "Epoch 80, Loss: 0.1608908325433731, Final Batch Loss: 0.08323976397514343\n",
      "Epoch 81, Loss: 0.19129732251167297, Final Batch Loss: 0.11324430257081985\n",
      "Epoch 82, Loss: 0.16153977438807487, Final Batch Loss: 0.05263395980000496\n",
      "Epoch 83, Loss: 0.16626080125570297, Final Batch Loss: 0.08796598017215729\n",
      "Epoch 84, Loss: 0.13383585214614868, Final Batch Loss: 0.08551184833049774\n",
      "Epoch 85, Loss: 0.12641875445842743, Final Batch Loss: 0.04773065447807312\n",
      "Epoch 86, Loss: 0.16952884942293167, Final Batch Loss: 0.08838150650262833\n",
      "Epoch 87, Loss: 0.14361580461263657, Final Batch Loss: 0.0544135719537735\n",
      "Epoch 88, Loss: 0.14149900898337364, Final Batch Loss: 0.060948844999074936\n",
      "Epoch 89, Loss: 0.12697908282279968, Final Batch Loss: 0.08124824613332748\n",
      "Epoch 90, Loss: 0.17732539027929306, Final Batch Loss: 0.10431613028049469\n",
      "Epoch 91, Loss: 0.16139881312847137, Final Batch Loss: 0.09393512457609177\n",
      "Epoch 92, Loss: 0.15265889465808868, Final Batch Loss: 0.061874642968177795\n",
      "Epoch 93, Loss: 0.154291283339262, Final Batch Loss: 0.060103971511125565\n",
      "Epoch 94, Loss: 0.11527548730373383, Final Batch Loss: 0.04340174049139023\n",
      "Epoch 95, Loss: 0.14183015748858452, Final Batch Loss: 0.0834425538778305\n",
      "Epoch 96, Loss: 0.14915910363197327, Final Batch Loss: 0.07621908187866211\n",
      "Epoch 97, Loss: 0.12317978590726852, Final Batch Loss: 0.07345157861709595\n",
      "Epoch 98, Loss: 0.14872241765260696, Final Batch Loss: 0.05296189337968826\n",
      "Epoch 99, Loss: 0.08852644637227058, Final Batch Loss: 0.046628858894109726\n",
      "Epoch 100, Loss: 0.09974970668554306, Final Batch Loss: 0.05179345980286598\n",
      "Epoch 101, Loss: 0.14993344992399216, Final Batch Loss: 0.07997985184192657\n",
      "Epoch 102, Loss: 0.11023371294140816, Final Batch Loss: 0.04194452241063118\n",
      "Epoch 103, Loss: 0.15119821578264236, Final Batch Loss: 0.09481712430715561\n",
      "Epoch 104, Loss: 0.08266852423548698, Final Batch Loss: 0.035779476165771484\n",
      "Epoch 105, Loss: 0.08590048179030418, Final Batch Loss: 0.032332513481378555\n",
      "Epoch 106, Loss: 0.08428052812814713, Final Batch Loss: 0.053153157234191895\n",
      "Epoch 107, Loss: 0.08650703355669975, Final Batch Loss: 0.04697998985648155\n",
      "Epoch 108, Loss: 0.08446380868554115, Final Batch Loss: 0.04346678406000137\n",
      "Epoch 109, Loss: 0.12116362154483795, Final Batch Loss: 0.06658481806516647\n",
      "Epoch 110, Loss: 0.1051797978579998, Final Batch Loss: 0.04239765182137489\n",
      "Epoch 111, Loss: 0.09868771210312843, Final Batch Loss: 0.05588283762335777\n",
      "Epoch 112, Loss: 0.09638580307364464, Final Batch Loss: 0.04701327905058861\n",
      "Epoch 113, Loss: 0.10830258205533028, Final Batch Loss: 0.056100234389305115\n",
      "Epoch 114, Loss: 0.05917727015912533, Final Batch Loss: 0.03086433932185173\n",
      "Epoch 115, Loss: 0.07199385017156601, Final Batch Loss: 0.022667579352855682\n",
      "Epoch 116, Loss: 0.07980305887758732, Final Batch Loss: 0.05427892506122589\n",
      "Epoch 117, Loss: 0.08325530588626862, Final Batch Loss: 0.029344700276851654\n",
      "Epoch 118, Loss: 0.09669133275747299, Final Batch Loss: 0.0480620451271534\n",
      "Epoch 119, Loss: 0.07591729238629341, Final Batch Loss: 0.041943296790122986\n",
      "Epoch 120, Loss: 0.11294350028038025, Final Batch Loss: 0.05067474767565727\n",
      "Epoch 121, Loss: 0.06927592121064663, Final Batch Loss: 0.02730930782854557\n",
      "Epoch 122, Loss: 0.12832535430788994, Final Batch Loss: 0.03929314389824867\n",
      "Epoch 123, Loss: 0.06237977370619774, Final Batch Loss: 0.03467085584998131\n",
      "Epoch 124, Loss: 0.08394588902592659, Final Batch Loss: 0.032732125371694565\n",
      "Epoch 125, Loss: 0.0571439266204834, Final Batch Loss: 0.03973182663321495\n",
      "Epoch 126, Loss: 0.060527002438902855, Final Batch Loss: 0.022861773148179054\n",
      "Epoch 127, Loss: 0.03875364363193512, Final Batch Loss: 0.016462141647934914\n",
      "Epoch 128, Loss: 0.056212395429611206, Final Batch Loss: 0.026731034740805626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129, Loss: 0.10454792343080044, Final Batch Loss: 0.028744397684931755\n",
      "Epoch 130, Loss: 0.08757053688168526, Final Batch Loss: 0.05131585896015167\n",
      "Epoch 131, Loss: 0.08756707794964314, Final Batch Loss: 0.056343529373407364\n",
      "Epoch 132, Loss: 0.058255042880773544, Final Batch Loss: 0.04751259461045265\n",
      "Epoch 133, Loss: 0.0393071286380291, Final Batch Loss: 0.02040559984743595\n",
      "Epoch 134, Loss: 0.03123533073812723, Final Batch Loss: 0.012027976103127003\n",
      "Epoch 135, Loss: 0.03472348861396313, Final Batch Loss: 0.016538303345441818\n",
      "Epoch 136, Loss: 0.04962976649403572, Final Batch Loss: 0.02979869768023491\n",
      "Epoch 137, Loss: 0.05606369487941265, Final Batch Loss: 0.03242567181587219\n",
      "Epoch 138, Loss: 0.06794284284114838, Final Batch Loss: 0.022314690053462982\n",
      "Epoch 139, Loss: 0.034858633764088154, Final Batch Loss: 0.013314458541572094\n",
      "Epoch 140, Loss: 0.04138231463730335, Final Batch Loss: 0.02145771123468876\n",
      "Epoch 141, Loss: 0.07590083032846451, Final Batch Loss: 0.03935372829437256\n",
      "Epoch 142, Loss: 0.06994879059493542, Final Batch Loss: 0.04614945128560066\n",
      "Epoch 143, Loss: 0.08381406217813492, Final Batch Loss: 0.03759435936808586\n",
      "Epoch 144, Loss: 0.0562219712883234, Final Batch Loss: 0.021553894504904747\n",
      "Epoch 145, Loss: 0.03808819968253374, Final Batch Loss: 0.010107777081429958\n",
      "Epoch 146, Loss: 0.10441958159208298, Final Batch Loss: 0.04548730328679085\n",
      "Epoch 147, Loss: 0.07862300239503384, Final Batch Loss: 0.02783101610839367\n",
      "Epoch 148, Loss: 0.0460485965013504, Final Batch Loss: 0.020640242844820023\n",
      "Epoch 149, Loss: 0.0394115149974823, Final Batch Loss: 0.01315540075302124\n",
      "Epoch 150, Loss: 0.04609995521605015, Final Batch Loss: 0.016537152230739594\n",
      "Epoch 151, Loss: 0.09895944222807884, Final Batch Loss: 0.05470717325806618\n",
      "Epoch 152, Loss: 0.04055805131793022, Final Batch Loss: 0.00875597819685936\n",
      "Epoch 153, Loss: 0.04009941779077053, Final Batch Loss: 0.021997621282935143\n",
      "Epoch 154, Loss: 0.053093357011675835, Final Batch Loss: 0.031019125133752823\n",
      "Epoch 155, Loss: 0.05089037586003542, Final Batch Loss: 0.037049926817417145\n",
      "Epoch 156, Loss: 0.05394822917878628, Final Batch Loss: 0.04366656392812729\n",
      "Epoch 157, Loss: 0.03590761311352253, Final Batch Loss: 0.02373756282031536\n",
      "Epoch 158, Loss: 0.03064294531941414, Final Batch Loss: 0.014610392972826958\n",
      "Epoch 159, Loss: 0.035848019644618034, Final Batch Loss: 0.015048844739794731\n",
      "Epoch 160, Loss: 0.036397081799805164, Final Batch Loss: 0.009408907033503056\n",
      "Epoch 161, Loss: 0.09726443700492382, Final Batch Loss: 0.07475129514932632\n",
      "Epoch 162, Loss: 0.05038746539503336, Final Batch Loss: 0.035223182290792465\n",
      "Epoch 163, Loss: 0.03640532307326794, Final Batch Loss: 0.02036217413842678\n",
      "Epoch 164, Loss: 0.06398100219666958, Final Batch Loss: 0.04727305471897125\n",
      "Epoch 165, Loss: 0.024489850737154484, Final Batch Loss: 0.014530796557664871\n",
      "Epoch 166, Loss: 0.05660507455468178, Final Batch Loss: 0.032907888293266296\n",
      "Epoch 167, Loss: 0.07076767645776272, Final Batch Loss: 0.030404990538954735\n",
      "Epoch 168, Loss: 0.061017836444079876, Final Batch Loss: 0.009884207509458065\n",
      "Epoch 169, Loss: 0.027317211031913757, Final Batch Loss: 0.011353792622685432\n",
      "Epoch 170, Loss: 0.03702410217374563, Final Batch Loss: 0.023116864264011383\n",
      "Epoch 171, Loss: 0.0464944951236248, Final Batch Loss: 0.023028409108519554\n",
      "Epoch 172, Loss: 0.04432421736419201, Final Batch Loss: 0.021463224664330482\n",
      "Epoch 173, Loss: 0.047485229559242725, Final Batch Loss: 0.009445683099329472\n",
      "Epoch 174, Loss: 0.04757402837276459, Final Batch Loss: 0.016394373029470444\n",
      "Epoch 175, Loss: 0.039487612433731556, Final Batch Loss: 0.012030738405883312\n",
      "Epoch 176, Loss: 0.030876992270350456, Final Batch Loss: 0.016282077878713608\n",
      "Epoch 177, Loss: 0.03861749358475208, Final Batch Loss: 0.01930086687207222\n",
      "Epoch 178, Loss: 0.02198681328445673, Final Batch Loss: 0.012053653597831726\n",
      "Epoch 179, Loss: 0.030541430227458477, Final Batch Loss: 0.012975835241377354\n",
      "Epoch 180, Loss: 0.02735978364944458, Final Batch Loss: 0.013858341611921787\n",
      "Epoch 181, Loss: 0.035144273191690445, Final Batch Loss: 0.01861640065908432\n",
      "Epoch 182, Loss: 0.03921562805771828, Final Batch Loss: 0.031122975051403046\n",
      "Epoch 183, Loss: 0.02434451412409544, Final Batch Loss: 0.004614685662090778\n",
      "Epoch 184, Loss: 0.042727554216980934, Final Batch Loss: 0.025983242318034172\n",
      "Epoch 185, Loss: 0.062275322154164314, Final Batch Loss: 0.02970891259610653\n",
      "Epoch 186, Loss: 0.02558378456160426, Final Batch Loss: 0.01959691010415554\n",
      "Epoch 187, Loss: 0.01898625958710909, Final Batch Loss: 0.005406196229159832\n",
      "Epoch 188, Loss: 0.03251591697335243, Final Batch Loss: 0.01471642404794693\n",
      "Epoch 189, Loss: 0.034585362300276756, Final Batch Loss: 0.015102146193385124\n",
      "Epoch 190, Loss: 0.04119785409420729, Final Batch Loss: 0.029238760471343994\n",
      "Epoch 191, Loss: 0.034514772705733776, Final Batch Loss: 0.015281318686902523\n",
      "Epoch 192, Loss: 0.020691807381808758, Final Batch Loss: 0.00891796499490738\n",
      "Epoch 193, Loss: 0.023375293239951134, Final Batch Loss: 0.01232472900301218\n",
      "Epoch 194, Loss: 0.03947462094947696, Final Batch Loss: 0.03509470447897911\n",
      "Epoch 195, Loss: 0.015012791845947504, Final Batch Loss: 0.00629998417571187\n",
      "Epoch 196, Loss: 0.035981941036880016, Final Batch Loss: 0.012373960576951504\n",
      "Epoch 197, Loss: 0.021685535088181496, Final Batch Loss: 0.014493588358163834\n",
      "Epoch 198, Loss: 0.02247518952935934, Final Batch Loss: 0.009293580427765846\n",
      "Epoch 199, Loss: 0.03320685774087906, Final Batch Loss: 0.01967337541282177\n",
      "Epoch 200, Loss: 0.07861992344260216, Final Batch Loss: 0.06300058215856552\n",
      "Epoch 201, Loss: 0.0806567370891571, Final Batch Loss: 0.044575292617082596\n",
      "Epoch 202, Loss: 0.0174402198754251, Final Batch Loss: 0.012317315675318241\n",
      "Epoch 203, Loss: 0.02035290887579322, Final Batch Loss: 0.00507100997492671\n",
      "Epoch 204, Loss: 0.03713682573288679, Final Batch Loss: 0.009543913416564465\n",
      "Epoch 205, Loss: 0.035856432281434536, Final Batch Loss: 0.02306625247001648\n",
      "Epoch 206, Loss: 0.024631797336041927, Final Batch Loss: 0.015949316322803497\n",
      "Epoch 207, Loss: 0.017607154790312052, Final Batch Loss: 0.00647715525701642\n",
      "Epoch 208, Loss: 0.035996414721012115, Final Batch Loss: 0.017992665991187096\n",
      "Epoch 209, Loss: 0.027090890798717737, Final Batch Loss: 0.020155198872089386\n",
      "Epoch 210, Loss: 0.038424049504101276, Final Batch Loss: 0.02769530564546585\n",
      "Epoch 211, Loss: 0.014624298550188541, Final Batch Loss: 0.005001618526875973\n",
      "Epoch 212, Loss: 0.021332159638404846, Final Batch Loss: 0.00794319435954094\n",
      "Epoch 213, Loss: 0.036781168077141047, Final Batch Loss: 0.004236558917909861\n",
      "Epoch 214, Loss: 0.014059241861104965, Final Batch Loss: 0.005691377446055412\n",
      "Epoch 215, Loss: 0.02395603619515896, Final Batch Loss: 0.00508028082549572\n",
      "Epoch 216, Loss: 0.044636046048253775, Final Batch Loss: 0.005232115741819143\n",
      "Epoch 217, Loss: 0.03054005093872547, Final Batch Loss: 0.016792112961411476\n",
      "Epoch 218, Loss: 0.04929448291659355, Final Batch Loss: 0.011033851653337479\n",
      "Epoch 219, Loss: 0.02336139138787985, Final Batch Loss: 0.005689551122486591\n",
      "Epoch 220, Loss: 0.0379212386906147, Final Batch Loss: 0.019338786602020264\n",
      "Epoch 221, Loss: 0.015050229616463184, Final Batch Loss: 0.005734608508646488\n",
      "Epoch 222, Loss: 0.011317356722429395, Final Batch Loss: 0.0035848405677825212\n",
      "Epoch 223, Loss: 0.02110734162852168, Final Batch Loss: 0.0059008547104895115\n",
      "Epoch 224, Loss: 0.018928500823676586, Final Batch Loss: 0.012778478674590588\n",
      "Epoch 225, Loss: 0.014696490950882435, Final Batch Loss: 0.007837051525712013\n",
      "Epoch 226, Loss: 0.02026026463136077, Final Batch Loss: 0.004555934574455023\n",
      "Epoch 227, Loss: 0.008071879390627146, Final Batch Loss: 0.0027825175784528255\n",
      "Epoch 228, Loss: 0.02097886335104704, Final Batch Loss: 0.008479723706841469\n",
      "Epoch 229, Loss: 0.017949892207980156, Final Batch Loss: 0.00441205408424139\n",
      "Epoch 230, Loss: 0.023335174657404423, Final Batch Loss: 0.012658434920012951\n",
      "Epoch 231, Loss: 0.032561265863478184, Final Batch Loss: 0.019288131967186928\n",
      "Epoch 232, Loss: 0.015476700384169817, Final Batch Loss: 0.004235432017594576\n",
      "Epoch 233, Loss: 0.013315632473677397, Final Batch Loss: 0.006573614664375782\n",
      "Epoch 234, Loss: 0.019462340511381626, Final Batch Loss: 0.009530715644359589\n",
      "Epoch 235, Loss: 0.016135032288730145, Final Batch Loss: 0.004962741397321224\n",
      "Epoch 236, Loss: 0.014167554210871458, Final Batch Loss: 0.0079600615426898\n",
      "Epoch 237, Loss: 0.021003789734095335, Final Batch Loss: 0.004765923600643873\n",
      "Epoch 238, Loss: 0.016134253470227122, Final Batch Loss: 0.0128244049847126\n",
      "Epoch 239, Loss: 0.01967033836990595, Final Batch Loss: 0.012471728958189487\n",
      "Epoch 240, Loss: 0.027978689409792423, Final Batch Loss: 0.005331822670996189\n",
      "Epoch 241, Loss: 0.011923874262720346, Final Batch Loss: 0.005203987006098032\n",
      "Epoch 242, Loss: 0.031091670505702496, Final Batch Loss: 0.020458342507481575\n",
      "Epoch 243, Loss: 0.014763468876481056, Final Batch Loss: 0.006951231975108385\n",
      "Epoch 244, Loss: 0.004763703560456634, Final Batch Loss: 0.0018317014910280704\n",
      "Epoch 245, Loss: 0.013836517464369535, Final Batch Loss: 0.003307084087282419\n",
      "Epoch 246, Loss: 0.016631510923616588, Final Batch Loss: 0.014784784987568855\n",
      "Epoch 247, Loss: 0.017494899220764637, Final Batch Loss: 0.00733723770827055\n",
      "Epoch 248, Loss: 0.046005850192159414, Final Batch Loss: 0.03915639966726303\n",
      "Epoch 249, Loss: 0.015005652559921145, Final Batch Loss: 0.011131350882351398\n",
      "Epoch 250, Loss: 0.007203853805549443, Final Batch Loss: 0.001019940827973187\n",
      "Epoch 251, Loss: 0.02495098114013672, Final Batch Loss: 0.009428697638213634\n",
      "Epoch 252, Loss: 0.024229458533227444, Final Batch Loss: 0.008041185326874256\n",
      "Epoch 253, Loss: 0.019665635656565428, Final Batch Loss: 0.014374827966094017\n",
      "Epoch 254, Loss: 0.03375385608524084, Final Batch Loss: 0.01362753938883543\n",
      "Epoch 255, Loss: 0.013383616227656603, Final Batch Loss: 0.007767224684357643\n",
      "Epoch 256, Loss: 0.03115092497318983, Final Batch Loss: 0.011371173895895481\n",
      "Epoch 257, Loss: 0.014341544825583696, Final Batch Loss: 0.010144275613129139\n",
      "Epoch 258, Loss: 0.026466619223356247, Final Batch Loss: 0.022397048771381378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259, Loss: 0.014677047729492188, Final Batch Loss: 0.007158257067203522\n",
      "Epoch 260, Loss: 0.01717496383935213, Final Batch Loss: 0.009404836222529411\n",
      "Epoch 261, Loss: 0.011736045591533184, Final Batch Loss: 0.009313784539699554\n",
      "Epoch 262, Loss: 0.02040109783411026, Final Batch Loss: 0.009641148149967194\n",
      "Epoch 263, Loss: 0.01304356288164854, Final Batch Loss: 0.0037561580538749695\n",
      "Epoch 264, Loss: 0.014985163696110249, Final Batch Loss: 0.004811571910977364\n",
      "Epoch 265, Loss: 0.030631807167083025, Final Batch Loss: 0.023498786613345146\n",
      "Epoch 266, Loss: 0.03098719986155629, Final Batch Loss: 0.02558656968176365\n",
      "Epoch 267, Loss: 0.026937801390886307, Final Batch Loss: 0.005470776930451393\n",
      "Epoch 268, Loss: 0.011510975193232298, Final Batch Loss: 0.006041918881237507\n",
      "Epoch 269, Loss: 0.02304428583011031, Final Batch Loss: 0.01858355663716793\n",
      "Epoch 270, Loss: 0.0074524544179439545, Final Batch Loss: 0.004860451444983482\n",
      "Epoch 271, Loss: 0.03855480533093214, Final Batch Loss: 0.012045417912304401\n",
      "Epoch 272, Loss: 0.010406856890767813, Final Batch Loss: 0.003468868788331747\n",
      "Epoch 273, Loss: 0.023581434972584248, Final Batch Loss: 0.015010637231171131\n",
      "Epoch 274, Loss: 0.007438864791765809, Final Batch Loss: 0.0020266433712095022\n",
      "Epoch 275, Loss: 0.01516268018167466, Final Batch Loss: 0.001918754423968494\n",
      "Epoch 276, Loss: 0.012800410389900208, Final Batch Loss: 0.00545177748426795\n",
      "Epoch 277, Loss: 0.016733304597437382, Final Batch Loss: 0.0059257978573441505\n",
      "Epoch 278, Loss: 0.012721312465146184, Final Batch Loss: 0.00989201758056879\n",
      "Epoch 279, Loss: 0.008870643097907305, Final Batch Loss: 0.0034857322461903095\n",
      "Epoch 280, Loss: 0.025394871830940247, Final Batch Loss: 0.006468741223216057\n",
      "Epoch 281, Loss: 0.010382614564150572, Final Batch Loss: 0.0060804616659879684\n",
      "Epoch 282, Loss: 0.012872583698481321, Final Batch Loss: 0.0032482673414051533\n",
      "Epoch 283, Loss: 0.014484538929536939, Final Batch Loss: 0.003562454367056489\n",
      "Epoch 284, Loss: 0.019999753683805466, Final Batch Loss: 0.008484398014843464\n",
      "Epoch 285, Loss: 0.018195672892034054, Final Batch Loss: 0.00390890147536993\n",
      "Epoch 286, Loss: 0.008883267873898149, Final Batch Loss: 0.00365808024071157\n",
      "Epoch 287, Loss: 0.02592939231544733, Final Batch Loss: 0.022078316658735275\n",
      "Epoch 288, Loss: 0.020304583478718996, Final Batch Loss: 0.01687629707157612\n",
      "Epoch 289, Loss: 0.013461099471896887, Final Batch Loss: 0.006199819501489401\n",
      "Epoch 290, Loss: 0.05202756589278579, Final Batch Loss: 0.0029925047419965267\n",
      "Epoch 291, Loss: 0.02478916710242629, Final Batch Loss: 0.003996368031948805\n",
      "Epoch 292, Loss: 0.009404795477166772, Final Batch Loss: 0.003293995512649417\n",
      "Epoch 293, Loss: 0.020589444786310196, Final Batch Loss: 0.0024853870272636414\n",
      "Epoch 294, Loss: 0.010863595409318805, Final Batch Loss: 0.007817281410098076\n",
      "Epoch 295, Loss: 0.00883739534765482, Final Batch Loss: 0.006739519536495209\n",
      "Epoch 296, Loss: 0.01255152525845915, Final Batch Loss: 0.0014912585029378533\n",
      "Epoch 297, Loss: 0.012603447772562504, Final Batch Loss: 0.0020728539675474167\n",
      "Epoch 298, Loss: 0.01901165011804551, Final Batch Loss: 0.0012065431801602244\n",
      "Epoch 299, Loss: 0.01635915320366621, Final Batch Loss: 0.0122062461450696\n",
      "Epoch 300, Loss: 0.0072575160302221775, Final Batch Loss: 0.0029784562066197395\n",
      "Epoch 301, Loss: 0.018629084806889296, Final Batch Loss: 0.004050531890243292\n",
      "Epoch 302, Loss: 0.011517057195305824, Final Batch Loss: 0.00574170146137476\n",
      "Epoch 303, Loss: 0.008175161550752819, Final Batch Loss: 0.0015724188415333629\n",
      "Epoch 304, Loss: 0.012066854164004326, Final Batch Loss: 0.0030618421733379364\n",
      "Epoch 305, Loss: 0.009768017916940153, Final Batch Loss: 0.0012560359900817275\n",
      "Epoch 306, Loss: 0.015539260813966393, Final Batch Loss: 0.012856615707278252\n",
      "Epoch 307, Loss: 0.01710396632552147, Final Batch Loss: 0.011229395866394043\n",
      "Epoch 308, Loss: 0.0068160779774188995, Final Batch Loss: 0.004787780344486237\n",
      "Epoch 309, Loss: 0.00944164558313787, Final Batch Loss: 0.0024979275185614824\n",
      "Epoch 310, Loss: 0.007933361921459436, Final Batch Loss: 0.0022095986641943455\n",
      "Epoch 311, Loss: 0.017094637267291546, Final Batch Loss: 0.004050169140100479\n",
      "Epoch 312, Loss: 0.014492586953565478, Final Batch Loss: 0.0019570577424019575\n",
      "Epoch 313, Loss: 0.016350085847079754, Final Batch Loss: 0.00843794271349907\n",
      "Epoch 314, Loss: 0.015538086649030447, Final Batch Loss: 0.010948965325951576\n",
      "Epoch 315, Loss: 0.02305416576564312, Final Batch Loss: 0.0059761181473731995\n",
      "Epoch 316, Loss: 0.009794904384762049, Final Batch Loss: 0.004405308980494738\n",
      "Epoch 317, Loss: 0.015387864783406258, Final Batch Loss: 0.00678971316665411\n",
      "Epoch 318, Loss: 0.022210690192878246, Final Batch Loss: 0.010658529587090015\n",
      "Epoch 319, Loss: 0.008799436502158642, Final Batch Loss: 0.006146261468529701\n",
      "Epoch 320, Loss: 0.010874290484935045, Final Batch Loss: 0.0073304916732013226\n",
      "Epoch 321, Loss: 0.006191853433847427, Final Batch Loss: 0.0020980695262551308\n",
      "Epoch 322, Loss: 0.016521615907549858, Final Batch Loss: 0.011044829152524471\n",
      "Epoch 323, Loss: 0.010574388783425093, Final Batch Loss: 0.006016023922711611\n",
      "Epoch 324, Loss: 0.007575130555778742, Final Batch Loss: 0.002572673372924328\n",
      "Epoch 325, Loss: 0.014440869446843863, Final Batch Loss: 0.0012472043745219707\n",
      "Epoch 326, Loss: 0.022841117344796658, Final Batch Loss: 0.011456256732344627\n",
      "Epoch 327, Loss: 0.00520644651260227, Final Batch Loss: 0.003870082087814808\n",
      "Epoch 328, Loss: 0.010048002004623413, Final Batch Loss: 0.0075261821039021015\n",
      "Epoch 329, Loss: 0.005986365838907659, Final Batch Loss: 0.0045661721378564835\n",
      "Epoch 330, Loss: 0.013273653341457248, Final Batch Loss: 0.012528778053820133\n",
      "Epoch 331, Loss: 0.010859388276003301, Final Batch Loss: 0.0008315214654430747\n",
      "Epoch 332, Loss: 0.00968252751044929, Final Batch Loss: 0.0038442600052803755\n",
      "Epoch 333, Loss: 0.005678232759237289, Final Batch Loss: 0.002928360365331173\n",
      "Epoch 334, Loss: 0.00655037141405046, Final Batch Loss: 0.0023044703993946314\n",
      "Epoch 335, Loss: 0.013610434252768755, Final Batch Loss: 0.004568730015307665\n",
      "Epoch 336, Loss: 0.0046048853546381, Final Batch Loss: 0.001405627466738224\n",
      "Epoch 337, Loss: 0.009568116627633572, Final Batch Loss: 0.0021360665559768677\n",
      "Epoch 338, Loss: 0.016117091290652752, Final Batch Loss: 0.007308377884328365\n",
      "Epoch 339, Loss: 0.031960329273715615, Final Batch Loss: 0.02896094135940075\n",
      "Epoch 340, Loss: 0.00632890232373029, Final Batch Loss: 0.0018175133736804128\n",
      "Epoch 341, Loss: 0.005575215443968773, Final Batch Loss: 0.001639829482883215\n",
      "Epoch 342, Loss: 0.009149949066340923, Final Batch Loss: 0.002749927341938019\n",
      "Epoch 343, Loss: 0.0025841108872555196, Final Batch Loss: 0.0016602397663518786\n",
      "Epoch 344, Loss: 0.023256560787558556, Final Batch Loss: 0.018188051879405975\n",
      "Epoch 345, Loss: 0.005871421715710312, Final Batch Loss: 0.0005864417762495577\n",
      "Epoch 346, Loss: 0.007254338124766946, Final Batch Loss: 0.0011688258964568377\n",
      "Epoch 347, Loss: 0.012804433237761259, Final Batch Loss: 0.006817220244556665\n",
      "Epoch 348, Loss: 0.013536402024328709, Final Batch Loss: 0.008440283127129078\n",
      "Epoch 349, Loss: 0.015018657315522432, Final Batch Loss: 0.0043402849696576595\n",
      "Epoch 350, Loss: 0.01763003645464778, Final Batch Loss: 0.01566500961780548\n",
      "Epoch 351, Loss: 0.01654124539345503, Final Batch Loss: 0.0038410983979701996\n",
      "Epoch 352, Loss: 0.010093791177496314, Final Batch Loss: 0.003103635972365737\n",
      "Epoch 353, Loss: 0.019040649523958564, Final Batch Loss: 0.01709473319351673\n",
      "Epoch 354, Loss: 0.0034293164499104023, Final Batch Loss: 0.0011149111669510603\n",
      "Epoch 355, Loss: 0.01091337064281106, Final Batch Loss: 0.005920167081058025\n",
      "Epoch 356, Loss: 0.010701565071940422, Final Batch Loss: 0.001716787926852703\n",
      "Epoch 357, Loss: 0.007716967375017703, Final Batch Loss: 0.0014411710435524583\n",
      "Epoch 358, Loss: 0.003405327908694744, Final Batch Loss: 0.002008412266150117\n",
      "Epoch 359, Loss: 0.005074157728813589, Final Batch Loss: 0.0017774462467059493\n",
      "Epoch 360, Loss: 0.008104917593300343, Final Batch Loss: 0.005025970283895731\n",
      "Epoch 361, Loss: 0.018234727904200554, Final Batch Loss: 0.016671326011419296\n",
      "Epoch 362, Loss: 0.0032510050805285573, Final Batch Loss: 0.0011420139344409108\n",
      "Epoch 363, Loss: 0.004670988768339157, Final Batch Loss: 0.0020072839688509703\n",
      "Epoch 364, Loss: 0.002698878903174773, Final Batch Loss: 0.000326547451550141\n",
      "Epoch 365, Loss: 0.003272934234701097, Final Batch Loss: 0.0019703384023159742\n",
      "Epoch 366, Loss: 0.017807128955610096, Final Batch Loss: 0.000975947012193501\n",
      "Epoch 367, Loss: 0.0051205073250457644, Final Batch Loss: 0.0012001878349110484\n",
      "Epoch 368, Loss: 0.002560154825914651, Final Batch Loss: 0.0017048167064785957\n",
      "Epoch 369, Loss: 0.007150773657485843, Final Batch Loss: 0.00453812163323164\n",
      "Epoch 370, Loss: 0.008459481643512845, Final Batch Loss: 0.0019990454893559217\n",
      "Epoch 371, Loss: 0.002503181924112141, Final Batch Loss: 0.0013205907307565212\n",
      "Epoch 372, Loss: 0.009693290863651782, Final Batch Loss: 0.00063768943073228\n",
      "Epoch 373, Loss: 0.008416548953391612, Final Batch Loss: 0.000903097097761929\n",
      "Epoch 374, Loss: 0.00785585050471127, Final Batch Loss: 0.003780262777581811\n",
      "Epoch 375, Loss: 0.0089472018298693, Final Batch Loss: 0.000933065835852176\n",
      "Epoch 376, Loss: 0.04539676336571574, Final Batch Loss: 0.04281825199723244\n",
      "Epoch 377, Loss: 0.005590117070823908, Final Batch Loss: 0.0018043266609311104\n",
      "Epoch 378, Loss: 0.031959221232682467, Final Batch Loss: 0.004258033353835344\n",
      "Epoch 379, Loss: 0.011964865261688828, Final Batch Loss: 0.0023850242141634226\n",
      "Epoch 380, Loss: 0.015367504209280014, Final Batch Loss: 0.0039200084283947945\n",
      "Epoch 381, Loss: 0.00780935725197196, Final Batch Loss: 0.0027007106691598892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382, Loss: 0.016797243617475033, Final Batch Loss: 0.0019993362948298454\n",
      "Epoch 383, Loss: 0.004482852295041084, Final Batch Loss: 0.0018471693620085716\n",
      "Epoch 384, Loss: 0.002494009560905397, Final Batch Loss: 0.0011480996618047357\n",
      "Epoch 385, Loss: 0.0094826091080904, Final Batch Loss: 0.003746909089386463\n",
      "Epoch 386, Loss: 0.015777724562212825, Final Batch Loss: 0.003552791429683566\n",
      "Epoch 387, Loss: 0.00723417237168178, Final Batch Loss: 0.0003526736400090158\n",
      "Epoch 388, Loss: 0.008873660117387772, Final Batch Loss: 0.00403362512588501\n",
      "Epoch 389, Loss: 0.012467337073758245, Final Batch Loss: 0.0007164704147726297\n",
      "Epoch 390, Loss: 0.04170520417392254, Final Batch Loss: 0.00030888430774211884\n",
      "Epoch 391, Loss: 0.004533236031420529, Final Batch Loss: 0.0014959905529394746\n",
      "Epoch 392, Loss: 0.04739043163135648, Final Batch Loss: 0.043836623430252075\n",
      "Epoch 393, Loss: 0.010060975211672485, Final Batch Loss: 0.00893180351704359\n",
      "Epoch 394, Loss: 0.0036856572842225432, Final Batch Loss: 0.0020131838973611593\n",
      "Epoch 395, Loss: 0.0029592365026474, Final Batch Loss: 0.002150905318558216\n",
      "Epoch 396, Loss: 0.02165436325594783, Final Batch Loss: 0.016625849530100822\n",
      "Epoch 397, Loss: 0.003425501403398812, Final Batch Loss: 0.0013546367408707738\n",
      "Epoch 398, Loss: 0.008664276916533709, Final Batch Loss: 0.005169819109141827\n",
      "Epoch 399, Loss: 0.001384578354191035, Final Batch Loss: 0.0006130945985205472\n",
      "Epoch 400, Loss: 0.008667538641020656, Final Batch Loss: 0.006694014649838209\n",
      "Epoch 401, Loss: 0.009357617236673832, Final Batch Loss: 0.007838214747607708\n",
      "Epoch 402, Loss: 0.0329055399633944, Final Batch Loss: 0.026658914983272552\n",
      "Epoch 403, Loss: 0.0028895528230350465, Final Batch Loss: 0.00031936189043335617\n",
      "Epoch 404, Loss: 0.0025066029629670084, Final Batch Loss: 0.0015380466356873512\n",
      "Epoch 405, Loss: 0.008865277050063014, Final Batch Loss: 0.0067649418488144875\n",
      "Epoch 406, Loss: 0.005747679620981216, Final Batch Loss: 0.004461916629225016\n",
      "Epoch 407, Loss: 0.00793896452523768, Final Batch Loss: 0.002556483494117856\n",
      "Epoch 408, Loss: 0.015251050223014317, Final Batch Loss: 0.00024406843294855207\n",
      "Epoch 409, Loss: 0.004024402936920524, Final Batch Loss: 0.0024681417271494865\n",
      "Epoch 410, Loss: 0.01532415219116956, Final Batch Loss: 0.0010620859684422612\n",
      "Epoch 411, Loss: 0.01739517878741026, Final Batch Loss: 0.013624058105051517\n",
      "Epoch 412, Loss: 0.0067156716249883175, Final Batch Loss: 0.004840889945626259\n",
      "Epoch 413, Loss: 0.0017695725546218455, Final Batch Loss: 0.0008702253107912838\n",
      "Epoch 414, Loss: 0.004272814723663032, Final Batch Loss: 0.0007082243682816625\n",
      "Epoch 415, Loss: 0.003049899940378964, Final Batch Loss: 0.0012278426438570023\n",
      "Epoch 416, Loss: 0.011764341732487082, Final Batch Loss: 0.001280234893783927\n",
      "Epoch 417, Loss: 0.0024319730582647026, Final Batch Loss: 0.0006074938573874533\n",
      "Epoch 418, Loss: 0.0019949363195337355, Final Batch Loss: 0.0012523415498435497\n",
      "Epoch 419, Loss: 0.0020970090408809483, Final Batch Loss: 0.001395693514496088\n",
      "Epoch 420, Loss: 0.00979986391030252, Final Batch Loss: 0.00862337090075016\n",
      "Epoch 421, Loss: 0.00211490347282961, Final Batch Loss: 0.0011913233902305365\n",
      "Epoch 422, Loss: 0.020883814024273306, Final Batch Loss: 0.0006414619856514037\n",
      "Epoch 423, Loss: 0.005044000572524965, Final Batch Loss: 0.0019036392914131284\n",
      "Epoch 424, Loss: 0.023555380757898092, Final Batch Loss: 0.01644073612987995\n",
      "Epoch 425, Loss: 0.004351875395514071, Final Batch Loss: 0.0025858404114842415\n",
      "Epoch 426, Loss: 0.019118463387712836, Final Batch Loss: 0.0009994988795369864\n",
      "Epoch 427, Loss: 0.005532879149541259, Final Batch Loss: 0.0028632287867367268\n",
      "Epoch 428, Loss: 0.015219161286950111, Final Batch Loss: 0.007628680672496557\n",
      "Epoch 429, Loss: 0.004924791865050793, Final Batch Loss: 0.0026433460880070925\n",
      "Epoch 430, Loss: 0.0021779494709335268, Final Batch Loss: 0.001411409699358046\n",
      "Epoch 431, Loss: 0.0040244628908112645, Final Batch Loss: 0.002760600997135043\n",
      "Epoch 432, Loss: 0.0027725357795134187, Final Batch Loss: 0.0012112545082345605\n",
      "Epoch 433, Loss: 0.0036824418348260224, Final Batch Loss: 0.0029665264301002026\n",
      "Epoch 434, Loss: 0.007075452362187207, Final Batch Loss: 0.0012732424074783921\n",
      "Epoch 435, Loss: 0.017843128880485892, Final Batch Loss: 0.0030127863865345716\n",
      "Epoch 436, Loss: 0.006313112564384937, Final Batch Loss: 0.004302521701902151\n",
      "Epoch 437, Loss: 0.005017002811655402, Final Batch Loss: 0.0013859337195754051\n",
      "Epoch 438, Loss: 0.0014797380426898599, Final Batch Loss: 0.0009408696787431836\n",
      "Epoch 439, Loss: 0.004084358166437596, Final Batch Loss: 0.0007952323067001998\n",
      "Epoch 440, Loss: 0.0021643383661285043, Final Batch Loss: 0.0011234963312745094\n",
      "Epoch 441, Loss: 0.013262396911159158, Final Batch Loss: 0.0022109488490968943\n",
      "Epoch 442, Loss: 0.012736886274069548, Final Batch Loss: 0.009591416455805302\n",
      "Epoch 443, Loss: 0.01077999291010201, Final Batch Loss: 0.00960865244269371\n",
      "Epoch 444, Loss: 0.004750940948724747, Final Batch Loss: 0.00404348922893405\n",
      "Epoch 445, Loss: 0.00983703089877963, Final Batch Loss: 0.003919665701687336\n",
      "Epoch 446, Loss: 0.007978941313922405, Final Batch Loss: 0.007385245990008116\n",
      "Epoch 447, Loss: 0.004640068509615958, Final Batch Loss: 0.001701056375168264\n",
      "Epoch 448, Loss: 0.006858645007014275, Final Batch Loss: 0.0010006367228925228\n",
      "Epoch 449, Loss: 0.007595369126647711, Final Batch Loss: 0.0030263541266322136\n",
      "Epoch 450, Loss: 0.0033629892859607935, Final Batch Loss: 0.0011346908286213875\n",
      "Epoch 451, Loss: 0.015637291595339775, Final Batch Loss: 0.014021600596606731\n",
      "Epoch 452, Loss: 0.014664882561191916, Final Batch Loss: 0.011620597913861275\n",
      "Epoch 453, Loss: 0.004833914572373033, Final Batch Loss: 0.002067528199404478\n",
      "Epoch 454, Loss: 0.005177991755772382, Final Batch Loss: 0.0006040165317244828\n",
      "Epoch 455, Loss: 0.00993670045863837, Final Batch Loss: 0.008702742867171764\n",
      "Epoch 456, Loss: 0.009975258144550025, Final Batch Loss: 0.008954606018960476\n",
      "Epoch 457, Loss: 0.019713585497811437, Final Batch Loss: 0.0012269832659512758\n",
      "Epoch 458, Loss: 0.009261623170459643, Final Batch Loss: 0.00038700379082001746\n",
      "Epoch 459, Loss: 0.007333406247198582, Final Batch Loss: 0.001363994088023901\n",
      "Epoch 460, Loss: 0.0019830117817036808, Final Batch Loss: 0.0012145808432251215\n",
      "Epoch 461, Loss: 0.017178669571876526, Final Batch Loss: 0.011102398857474327\n",
      "Epoch 462, Loss: 0.00444654852617532, Final Batch Loss: 0.0031751086935400963\n",
      "Epoch 463, Loss: 0.01539702108129859, Final Batch Loss: 0.0014704172499477863\n",
      "Epoch 464, Loss: 0.0033104170579463243, Final Batch Loss: 0.001971508376300335\n",
      "Epoch 465, Loss: 0.005309227737598121, Final Batch Loss: 0.0013148336438462138\n",
      "Epoch 466, Loss: 0.0020363369840197265, Final Batch Loss: 0.0009379519033245742\n",
      "Epoch 467, Loss: 0.00916572823189199, Final Batch Loss: 0.00857266690582037\n",
      "Epoch 468, Loss: 0.0058007785701192915, Final Batch Loss: 0.0053659467957913876\n",
      "Epoch 469, Loss: 0.014615682419389486, Final Batch Loss: 0.012773075141012669\n",
      "Epoch 470, Loss: 0.004628058290109038, Final Batch Loss: 0.0009836787357926369\n",
      "Epoch 471, Loss: 0.004602674744091928, Final Batch Loss: 0.0019017319427803159\n",
      "Epoch 472, Loss: 0.001781780447345227, Final Batch Loss: 0.0009271640446968377\n",
      "Epoch 473, Loss: 0.013846462592482567, Final Batch Loss: 0.011429443955421448\n",
      "Epoch 474, Loss: 0.00306411599740386, Final Batch Loss: 0.001129965647123754\n",
      "Epoch 475, Loss: 0.002910897310357541, Final Batch Loss: 0.0021785087883472443\n",
      "Epoch 476, Loss: 0.010094782803207636, Final Batch Loss: 0.0080002062022686\n",
      "Epoch 477, Loss: 0.005213221826124936, Final Batch Loss: 0.0003949918900616467\n",
      "Epoch 478, Loss: 0.004772664397023618, Final Batch Loss: 0.0018979791784659028\n",
      "Epoch 479, Loss: 0.0011565911117941141, Final Batch Loss: 0.00042675097938627005\n",
      "Epoch 480, Loss: 0.0023636914556846023, Final Batch Loss: 0.0010513177840039134\n",
      "Epoch 481, Loss: 0.0008881256799213588, Final Batch Loss: 0.0006090730894356966\n",
      "Epoch 482, Loss: 0.03153888322412968, Final Batch Loss: 0.021925656124949455\n",
      "Epoch 483, Loss: 0.006128103006631136, Final Batch Loss: 0.0016207327134907246\n",
      "Epoch 484, Loss: 0.0016900254704523832, Final Batch Loss: 0.0012698108330368996\n",
      "Epoch 485, Loss: 0.005496238591149449, Final Batch Loss: 0.003349741455167532\n",
      "Epoch 486, Loss: 0.003938512876629829, Final Batch Loss: 0.0029192848596721888\n",
      "Epoch 487, Loss: 0.0034099435433745384, Final Batch Loss: 0.0019435550784692168\n",
      "Epoch 488, Loss: 0.003286272694822401, Final Batch Loss: 0.0006873297388665378\n",
      "Epoch 489, Loss: 0.00441541476175189, Final Batch Loss: 0.00230433139950037\n",
      "Epoch 490, Loss: 0.007023958722129464, Final Batch Loss: 0.0036624406930059195\n",
      "Epoch 491, Loss: 0.002553700702264905, Final Batch Loss: 0.0007623641286045313\n",
      "Epoch 492, Loss: 0.004691229201853275, Final Batch Loss: 0.002260100794956088\n",
      "Epoch 493, Loss: 0.005061215488240123, Final Batch Loss: 0.0016955062747001648\n",
      "Epoch 494, Loss: 0.005108741752337664, Final Batch Loss: 0.004439280368387699\n",
      "Epoch 495, Loss: 0.020513237948762253, Final Batch Loss: 0.0003545354411471635\n",
      "Epoch 496, Loss: 0.017306096153333783, Final Batch Loss: 0.014441749081015587\n",
      "Epoch 497, Loss: 0.0011275793076492846, Final Batch Loss: 0.00018740835366770625\n",
      "Epoch 498, Loss: 0.0017633921233937144, Final Batch Loss: 0.000886464724317193\n",
      "Epoch 499, Loss: 0.009475584549363703, Final Batch Loss: 0.008945970796048641\n",
      "Epoch 500, Loss: 0.027346741408109665, Final Batch Loss: 0.014624733477830887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501, Loss: 0.004599508480168879, Final Batch Loss: 0.003912783227860928\n",
      "Epoch 502, Loss: 0.0015927078493405133, Final Batch Loss: 0.00028368926723487675\n",
      "Epoch 503, Loss: 0.003055859822779894, Final Batch Loss: 0.0012562162009999156\n",
      "Epoch 504, Loss: 0.0033937107073143125, Final Batch Loss: 0.0008527663303539157\n",
      "Epoch 505, Loss: 0.0032450740691274405, Final Batch Loss: 0.0021353887859731913\n",
      "Epoch 506, Loss: 0.0036329017020761967, Final Batch Loss: 0.0013846887741237879\n",
      "Epoch 507, Loss: 0.0054044234566390514, Final Batch Loss: 0.0038354608695954084\n",
      "Epoch 508, Loss: 0.0033801216050051153, Final Batch Loss: 0.002476802561432123\n",
      "Epoch 509, Loss: 0.00437333295121789, Final Batch Loss: 0.0027669104747474194\n",
      "Epoch 510, Loss: 0.002261372050270438, Final Batch Loss: 0.001076213549822569\n",
      "Epoch 511, Loss: 0.00438295176718384, Final Batch Loss: 0.0010448131943121552\n",
      "Epoch 512, Loss: 0.008334976620972157, Final Batch Loss: 0.007301073055714369\n",
      "Epoch 513, Loss: 0.0028714979998767376, Final Batch Loss: 0.0011454782215878367\n",
      "Epoch 514, Loss: 0.0011227251670788974, Final Batch Loss: 0.0008724405779503286\n",
      "Epoch 515, Loss: 0.006345397152472287, Final Batch Loss: 0.0009374430519528687\n",
      "Epoch 516, Loss: 0.0059206075966358185, Final Batch Loss: 0.004343986511230469\n",
      "Epoch 517, Loss: 0.0026617292314767838, Final Batch Loss: 0.0021825784351676702\n",
      "Epoch 518, Loss: 0.0015945272170938551, Final Batch Loss: 0.0006762477569282055\n",
      "Epoch 519, Loss: 0.003660052490886301, Final Batch Loss: 0.0007506810943596065\n",
      "Epoch 520, Loss: 0.006286780466325581, Final Batch Loss: 0.0010414492571726441\n",
      "Epoch 521, Loss: 0.007343236648011953, Final Batch Loss: 0.0004998099175281823\n",
      "Epoch 522, Loss: 0.021535195875912905, Final Batch Loss: 0.002910078037530184\n",
      "Epoch 523, Loss: 0.002256360341561958, Final Batch Loss: 0.00030750184669159353\n",
      "Epoch 524, Loss: 0.009829684044234455, Final Batch Loss: 0.001335025648586452\n",
      "Epoch 525, Loss: 0.008517942216712981, Final Batch Loss: 0.008135375566780567\n",
      "Epoch 526, Loss: 0.01178548764437437, Final Batch Loss: 0.0052421377040445805\n",
      "Epoch 527, Loss: 0.003742831526324153, Final Batch Loss: 0.0012698089703917503\n",
      "Epoch 528, Loss: 0.005856924457475543, Final Batch Loss: 0.0035139129031449556\n",
      "Epoch 529, Loss: 0.005434018326923251, Final Batch Loss: 0.00397899653762579\n",
      "Epoch 530, Loss: 0.01713646948337555, Final Batch Loss: 0.011237984523177147\n",
      "Epoch 531, Loss: 0.011668442457448691, Final Batch Loss: 0.0006270657177083194\n",
      "Epoch 532, Loss: 0.007371296174824238, Final Batch Loss: 0.004145344253629446\n",
      "Epoch 533, Loss: 0.012298204703256488, Final Batch Loss: 0.003742858534678817\n",
      "Epoch 534, Loss: 0.016087209805846214, Final Batch Loss: 0.00902112852782011\n",
      "Epoch 535, Loss: 0.014011547609698027, Final Batch Loss: 0.01336589828133583\n",
      "Epoch 536, Loss: 0.0022571443114429712, Final Batch Loss: 0.0012243196833878756\n",
      "Epoch 537, Loss: 0.006228333571925759, Final Batch Loss: 0.0010705830063670874\n",
      "Epoch 538, Loss: 0.0005094646621728316, Final Batch Loss: 0.0002316736354259774\n",
      "Epoch 539, Loss: 0.0032294009579345584, Final Batch Loss: 0.0020733503624796867\n",
      "Epoch 540, Loss: 0.0028801207372453064, Final Batch Loss: 0.00036215162253938615\n",
      "Epoch 541, Loss: 0.005174889229238033, Final Batch Loss: 0.0014491169713437557\n",
      "Epoch 542, Loss: 0.012151561095379293, Final Batch Loss: 0.0007657309761270881\n",
      "Epoch 543, Loss: 0.015430331346578896, Final Batch Loss: 0.0016514445887878537\n",
      "Epoch 544, Loss: 0.04854380036704242, Final Batch Loss: 0.04794864356517792\n",
      "Epoch 545, Loss: 0.001334448781562969, Final Batch Loss: 0.00038833674625493586\n",
      "Epoch 546, Loss: 0.002281956374645233, Final Batch Loss: 0.0009831124916672707\n",
      "Epoch 547, Loss: 0.0016912537394091487, Final Batch Loss: 0.0009772032499313354\n",
      "Epoch 548, Loss: 0.00405668345047161, Final Batch Loss: 0.00043692433973774314\n",
      "Epoch 549, Loss: 0.004541296075331047, Final Batch Loss: 0.004084158688783646\n",
      "Epoch 550, Loss: 0.00498467346187681, Final Batch Loss: 0.003924110904335976\n",
      "Epoch 551, Loss: 0.01627893967088312, Final Batch Loss: 0.014506562612950802\n",
      "Epoch 552, Loss: 0.00611954735359177, Final Batch Loss: 0.0005093537620268762\n",
      "Epoch 553, Loss: 0.004185413476079702, Final Batch Loss: 0.0019633756019175053\n",
      "Epoch 554, Loss: 0.0033974340185523033, Final Batch Loss: 0.0007401008624583483\n",
      "Epoch 555, Loss: 0.026099805923877284, Final Batch Loss: 0.02568351849913597\n",
      "Epoch 556, Loss: 0.004615836543962359, Final Batch Loss: 0.002064664615318179\n",
      "Epoch 557, Loss: 0.005524343636352569, Final Batch Loss: 0.00037119194166734815\n",
      "Epoch 558, Loss: 0.0027115753619000316, Final Batch Loss: 0.0013220852706581354\n",
      "Epoch 559, Loss: 0.003312474233098328, Final Batch Loss: 0.0010654880898073316\n",
      "Epoch 560, Loss: 0.004532576305791736, Final Batch Loss: 0.003204299369826913\n",
      "Epoch 561, Loss: 0.0015388705069199204, Final Batch Loss: 0.0007862955681048334\n",
      "Epoch 562, Loss: 0.003019890224095434, Final Batch Loss: 0.0005541655118577182\n",
      "Epoch 563, Loss: 0.013440549839287996, Final Batch Loss: 0.0018873079679906368\n",
      "Epoch 564, Loss: 0.008220587595133111, Final Batch Loss: 0.0004339187580626458\n",
      "Epoch 565, Loss: 0.001021936652250588, Final Batch Loss: 0.0003973750863224268\n",
      "Epoch 566, Loss: 0.001355563581455499, Final Batch Loss: 0.0008234920096583664\n",
      "Epoch 567, Loss: 0.0022519599297083914, Final Batch Loss: 0.0007012809510342777\n",
      "Epoch 568, Loss: 0.020548323169350624, Final Batch Loss: 0.0017544403672218323\n",
      "Epoch 569, Loss: 0.0018319690134376287, Final Batch Loss: 0.0010497506009414792\n",
      "Epoch 570, Loss: 0.00781793030910194, Final Batch Loss: 0.0040126983076334\n",
      "Epoch 571, Loss: 0.009979892522096634, Final Batch Loss: 0.009316655807197094\n",
      "Epoch 572, Loss: 0.0012451141665223986, Final Batch Loss: 0.0004094786418136209\n",
      "Epoch 573, Loss: 0.0023116659285733476, Final Batch Loss: 0.00019499323389027268\n",
      "Epoch 574, Loss: 0.00428723159711808, Final Batch Loss: 0.0012386642629280686\n",
      "Epoch 575, Loss: 0.0007167652365751565, Final Batch Loss: 0.0002677400771062821\n",
      "Epoch 576, Loss: 0.001333311724010855, Final Batch Loss: 0.0005804473767057061\n",
      "Epoch 577, Loss: 0.006805361743317917, Final Batch Loss: 0.006408081389963627\n",
      "Epoch 578, Loss: 0.0017444530385546386, Final Batch Loss: 0.0003129628603346646\n",
      "Epoch 579, Loss: 0.004435051348991692, Final Batch Loss: 0.0002590311923995614\n",
      "Epoch 580, Loss: 0.002027147449553013, Final Batch Loss: 0.001098441076464951\n",
      "Epoch 581, Loss: 0.00797998218331486, Final Batch Loss: 0.006070571020245552\n",
      "Epoch 582, Loss: 0.011517215287312865, Final Batch Loss: 0.0023578244727104902\n",
      "Epoch 583, Loss: 0.01890079368604347, Final Batch Loss: 0.0008816483314149082\n",
      "Epoch 584, Loss: 0.0012827895698137581, Final Batch Loss: 0.0007713126833550632\n",
      "Epoch 585, Loss: 0.02956234646262601, Final Batch Loss: 0.0005304122460074723\n",
      "Epoch 586, Loss: 0.0014672644902020693, Final Batch Loss: 0.0010223883436992764\n",
      "Epoch 587, Loss: 0.0007957703637657687, Final Batch Loss: 0.0001474870805395767\n",
      "Epoch 588, Loss: 0.001415350823663175, Final Batch Loss: 0.000803173054009676\n",
      "Epoch 589, Loss: 0.0028862099861726165, Final Batch Loss: 0.001169366529211402\n",
      "Epoch 590, Loss: 0.002597234910354018, Final Batch Loss: 0.000159720191732049\n",
      "Epoch 591, Loss: 0.00247493403730914, Final Batch Loss: 0.0016414382262155414\n",
      "Epoch 592, Loss: 0.0021965770283713937, Final Batch Loss: 0.00040836608968675137\n",
      "Epoch 593, Loss: 0.0015753403422422707, Final Batch Loss: 0.0010464716469869018\n",
      "Epoch 594, Loss: 0.0012693773314822465, Final Batch Loss: 0.00036784922122024\n",
      "Epoch 595, Loss: 0.00169495987938717, Final Batch Loss: 0.0012034252285957336\n",
      "Epoch 596, Loss: 0.003708407748490572, Final Batch Loss: 0.001839286764152348\n",
      "Epoch 597, Loss: 0.02341094013536349, Final Batch Loss: 0.022806819528341293\n",
      "Epoch 598, Loss: 0.00875865831039846, Final Batch Loss: 0.005667883902788162\n",
      "Epoch 599, Loss: 0.001988893549423665, Final Batch Loss: 0.0012369947507977486\n",
      "Epoch 600, Loss: 0.04021057818317786, Final Batch Loss: 0.03946544975042343\n",
      "Epoch 601, Loss: 0.006630989664699882, Final Batch Loss: 0.0008135190582834184\n",
      "Epoch 602, Loss: 0.0028274545329622924, Final Batch Loss: 0.002334549091756344\n",
      "Epoch 603, Loss: 0.0059757394483312964, Final Batch Loss: 0.0048151640221476555\n",
      "Epoch 604, Loss: 0.003331029787659645, Final Batch Loss: 0.0012113945558667183\n",
      "Epoch 605, Loss: 0.0013297920813784003, Final Batch Loss: 0.0007234076620079577\n",
      "Epoch 606, Loss: 0.005158290616236627, Final Batch Loss: 0.001758687780238688\n",
      "Epoch 607, Loss: 0.00237161573022604, Final Batch Loss: 0.0008689762325957417\n",
      "Epoch 608, Loss: 0.00865647115278989, Final Batch Loss: 0.008277288638055325\n",
      "Epoch 609, Loss: 0.001469354348955676, Final Batch Loss: 0.00043195681064389646\n",
      "Epoch 610, Loss: 0.001454221724998206, Final Batch Loss: 0.0007712318329140544\n",
      "Epoch 611, Loss: 0.0010428096284158528, Final Batch Loss: 0.0005809530848637223\n",
      "Epoch 612, Loss: 0.0037794113159179688, Final Batch Loss: 0.0028692837804555893\n",
      "Epoch 613, Loss: 0.006216913461685181, Final Batch Loss: 0.0033205533400177956\n",
      "Epoch 614, Loss: 0.004654301446862519, Final Batch Loss: 0.0003023511962965131\n",
      "Epoch 615, Loss: 0.0027334728511050344, Final Batch Loss: 0.0015615647425875068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616, Loss: 0.0016283830918837339, Final Batch Loss: 0.0002512454811949283\n",
      "Epoch 617, Loss: 0.007581606390886009, Final Batch Loss: 0.0008507099701091647\n",
      "Epoch 618, Loss: 0.003508192952722311, Final Batch Loss: 0.0021602099295705557\n",
      "Epoch 619, Loss: 0.00634969245584216, Final Batch Loss: 0.006183558143675327\n",
      "Epoch 620, Loss: 0.0015451966610271484, Final Batch Loss: 0.0012839757837355137\n",
      "Epoch 621, Loss: 0.0032386305974796414, Final Batch Loss: 0.0024566419888287783\n",
      "Epoch 622, Loss: 0.001107429212424904, Final Batch Loss: 0.0003298663650639355\n",
      "Epoch 623, Loss: 0.0016603275144007057, Final Batch Loss: 0.00045269131078384817\n",
      "Epoch 624, Loss: 0.005013468326069415, Final Batch Loss: 0.0010664543369784951\n",
      "Epoch 625, Loss: 0.011304586776532233, Final Batch Loss: 0.0006045658374205232\n",
      "Epoch 626, Loss: 0.0021625101508107036, Final Batch Loss: 0.0018441439606249332\n",
      "Epoch 627, Loss: 0.0012354839855106547, Final Batch Loss: 0.00018666342657525092\n",
      "Epoch 628, Loss: 0.0011642128229141235, Final Batch Loss: 0.0005674342974089086\n",
      "Epoch 629, Loss: 0.0019023764180019498, Final Batch Loss: 0.0013777962885797024\n",
      "Epoch 630, Loss: 0.002188154438044876, Final Batch Loss: 0.0005971772479824722\n",
      "Epoch 631, Loss: 0.01102089462801814, Final Batch Loss: 0.0022451807744801044\n",
      "Epoch 632, Loss: 0.0014721947227371857, Final Batch Loss: 0.00022499384067486972\n",
      "Epoch 633, Loss: 0.005447720759548247, Final Batch Loss: 0.004818530287593603\n",
      "Epoch 634, Loss: 0.000905192457139492, Final Batch Loss: 0.00046648294664919376\n",
      "Epoch 635, Loss: 0.05872420684318058, Final Batch Loss: 0.0003804312727879733\n",
      "Epoch 636, Loss: 0.00642707699444145, Final Batch Loss: 0.0015987091464921832\n",
      "Epoch 637, Loss: 0.005611676722764969, Final Batch Loss: 0.0012652468867599964\n",
      "Epoch 638, Loss: 0.004461818374693394, Final Batch Loss: 0.0007974458858370781\n",
      "Epoch 639, Loss: 0.0014075707586016506, Final Batch Loss: 0.0003552148991730064\n",
      "Epoch 640, Loss: 0.005824896041303873, Final Batch Loss: 0.002625909633934498\n",
      "Epoch 641, Loss: 0.003418525870074518, Final Batch Loss: 0.00018318388902116567\n",
      "Epoch 642, Loss: 0.0016032205894589424, Final Batch Loss: 0.0009654032764956355\n",
      "Epoch 643, Loss: 0.002792972489260137, Final Batch Loss: 0.00185861112549901\n",
      "Epoch 644, Loss: 0.0018395932711428031, Final Batch Loss: 0.00017949506582226604\n",
      "Epoch 645, Loss: 0.00269840145483613, Final Batch Loss: 0.002241807524114847\n",
      "Epoch 646, Loss: 0.0071327126352116466, Final Batch Loss: 0.006131893955171108\n",
      "Epoch 647, Loss: 0.0009653919260017574, Final Batch Loss: 0.0005184030742384493\n",
      "Epoch 648, Loss: 0.0018786106957122684, Final Batch Loss: 0.0009867065818980336\n",
      "Epoch 649, Loss: 0.0019764055032283068, Final Batch Loss: 0.0004322476452216506\n",
      "Epoch 650, Loss: 0.00569150282535702, Final Batch Loss: 0.0007532659219577909\n",
      "Epoch 651, Loss: 0.0010103918320965022, Final Batch Loss: 0.0008099872502498329\n",
      "Epoch 652, Loss: 0.008552747269277461, Final Batch Loss: 0.00022772183001507074\n",
      "Epoch 653, Loss: 0.006629606010392308, Final Batch Loss: 0.0018821044359356165\n",
      "Epoch 654, Loss: 0.0013424488133750856, Final Batch Loss: 0.0007382516050711274\n",
      "Epoch 655, Loss: 0.00250872626202181, Final Batch Loss: 0.00039073574589565396\n",
      "Epoch 656, Loss: 0.00046027058851905167, Final Batch Loss: 0.0003537257434800267\n",
      "Epoch 657, Loss: 0.0023904979461804032, Final Batch Loss: 0.001056135632097721\n",
      "Epoch 658, Loss: 0.003787154913879931, Final Batch Loss: 0.002157759852707386\n",
      "Epoch 659, Loss: 0.004045705660246313, Final Batch Loss: 0.002337187994271517\n",
      "Epoch 660, Loss: 0.0016172876057680696, Final Batch Loss: 0.0004712389491032809\n",
      "Epoch 661, Loss: 0.007031402928987518, Final Batch Loss: 0.0065961359068751335\n",
      "Epoch 662, Loss: 0.005759473307989538, Final Batch Loss: 0.0011560883140191436\n",
      "Epoch 663, Loss: 0.0021961827587801963, Final Batch Loss: 0.00040098748286254704\n",
      "Epoch 664, Loss: 0.0004966130800312385, Final Batch Loss: 0.00013529493298847228\n",
      "Epoch 665, Loss: 0.000769879603467416, Final Batch Loss: 0.00010542297241045162\n",
      "Epoch 666, Loss: 0.0012126959773013368, Final Batch Loss: 0.00019576553313527256\n",
      "Epoch 667, Loss: 0.0005508460017153993, Final Batch Loss: 0.00023938326921779662\n",
      "Epoch 668, Loss: 0.024903495330363512, Final Batch Loss: 0.002046498004347086\n",
      "Epoch 669, Loss: 0.004995352035621181, Final Batch Loss: 0.0002782977244351059\n",
      "Epoch 670, Loss: 0.002265423652715981, Final Batch Loss: 0.0014083362184464931\n",
      "Epoch 671, Loss: 0.0010806057980516925, Final Batch Loss: 0.0009298177319578826\n",
      "Epoch 672, Loss: 0.020055922330357134, Final Batch Loss: 0.0190262533724308\n",
      "Epoch 673, Loss: 0.0017530045006424189, Final Batch Loss: 0.0012361378176137805\n",
      "Epoch 674, Loss: 0.017189896199852228, Final Batch Loss: 0.0005657286383211613\n",
      "Epoch 675, Loss: 0.014996750047430396, Final Batch Loss: 0.00216337270103395\n",
      "Epoch 676, Loss: 0.006460369797423482, Final Batch Loss: 0.0003655024338513613\n",
      "Epoch 677, Loss: 0.00255952071165666, Final Batch Loss: 0.0002562256413511932\n",
      "Epoch 678, Loss: 0.0038327363436110318, Final Batch Loss: 0.003199243452399969\n",
      "Epoch 679, Loss: 0.0023946937872096896, Final Batch Loss: 0.0012882417067885399\n",
      "Epoch 680, Loss: 0.014152569870930165, Final Batch Loss: 0.0007399331661872566\n",
      "Epoch 681, Loss: 0.034972836379893124, Final Batch Loss: 0.0010296489344909787\n",
      "Epoch 682, Loss: 0.006001184927299619, Final Batch Loss: 0.0038121347315609455\n",
      "Epoch 683, Loss: 0.006301233544945717, Final Batch Loss: 0.0009823916479945183\n",
      "Epoch 684, Loss: 0.004403748083859682, Final Batch Loss: 0.0015127765946090221\n",
      "Epoch 685, Loss: 0.0009965167846530676, Final Batch Loss: 0.0004249856574460864\n",
      "Epoch 686, Loss: 0.001922433148138225, Final Batch Loss: 0.000680492608807981\n",
      "Epoch 687, Loss: 0.00721012894064188, Final Batch Loss: 0.001982046291232109\n",
      "Epoch 688, Loss: 0.008667408663313836, Final Batch Loss: 0.0004119017976336181\n",
      "Epoch 689, Loss: 0.012641035835258663, Final Batch Loss: 0.011583675630390644\n",
      "Epoch 690, Loss: 0.0017068400629796088, Final Batch Loss: 0.000571599171962589\n",
      "Epoch 691, Loss: 0.0026502968976274133, Final Batch Loss: 0.0012619985500350595\n",
      "Epoch 692, Loss: 0.002453740991768427, Final Batch Loss: 0.00014200860459823161\n",
      "Epoch 693, Loss: 0.001337132474873215, Final Batch Loss: 0.00023004255490377545\n",
      "Epoch 694, Loss: 0.0021724090911448, Final Batch Loss: 0.000721471500582993\n",
      "Epoch 695, Loss: 0.0033205290674231946, Final Batch Loss: 0.002689097309485078\n",
      "Epoch 696, Loss: 0.002651029033586383, Final Batch Loss: 0.0022170168813318014\n",
      "Epoch 697, Loss: 0.0005508890462806448, Final Batch Loss: 0.00019435725698713213\n",
      "Epoch 698, Loss: 0.00047237923718057573, Final Batch Loss: 0.00020439460058696568\n",
      "Epoch 699, Loss: 0.008959555416367948, Final Batch Loss: 0.0006270952289924026\n",
      "Epoch 700, Loss: 0.00841018557548523, Final Batch Loss: 0.007727902848273516\n",
      "Epoch 701, Loss: 0.010208486171904951, Final Batch Loss: 0.00033160351449623704\n",
      "Epoch 702, Loss: 0.0013902871287427843, Final Batch Loss: 0.0008833976462483406\n",
      "Epoch 703, Loss: 0.0009883814927889034, Final Batch Loss: 0.00017195874534081668\n",
      "Epoch 704, Loss: 0.001491386181442067, Final Batch Loss: 0.00023532492923550308\n",
      "Epoch 705, Loss: 0.00284296995960176, Final Batch Loss: 0.0018398177344352007\n",
      "Epoch 706, Loss: 0.0018083256436511874, Final Batch Loss: 0.0012658725026994944\n",
      "Epoch 707, Loss: 0.021333460172172636, Final Batch Loss: 0.021040217950940132\n",
      "Epoch 708, Loss: 0.0032687943894416094, Final Batch Loss: 0.002087933011353016\n",
      "Epoch 709, Loss: 0.0026020227232947946, Final Batch Loss: 0.0015800556866452098\n",
      "Epoch 710, Loss: 0.0021900648716837168, Final Batch Loss: 0.0011090727057307959\n",
      "Epoch 711, Loss: 0.002720430842600763, Final Batch Loss: 0.0009046074701473117\n",
      "Epoch 712, Loss: 0.0035046688572037965, Final Batch Loss: 0.0030985416378825903\n",
      "Epoch 713, Loss: 0.0016930525307543576, Final Batch Loss: 0.0007515361066907644\n",
      "Epoch 714, Loss: 0.002342312887776643, Final Batch Loss: 0.0008697291486896574\n",
      "Epoch 715, Loss: 0.0063727369997650385, Final Batch Loss: 0.0011022945400327444\n",
      "Epoch 716, Loss: 0.001929211983224377, Final Batch Loss: 0.0004399225290399045\n",
      "Epoch 717, Loss: 0.0012810385669581592, Final Batch Loss: 0.0006718900986015797\n",
      "Epoch 718, Loss: 0.010838605696335435, Final Batch Loss: 0.0021987969521433115\n",
      "Epoch 719, Loss: 0.005717841442674398, Final Batch Loss: 0.0030796865466982126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720, Loss: 0.001368766708765179, Final Batch Loss: 0.0005084623699076474\n",
      "Epoch 721, Loss: 0.0014862305542919785, Final Batch Loss: 0.0004205020668450743\n",
      "Epoch 722, Loss: 0.0031027157383505255, Final Batch Loss: 0.0004847274685744196\n",
      "Epoch 723, Loss: 0.0022605833364650607, Final Batch Loss: 0.0008976198732852936\n",
      "Epoch 724, Loss: 0.019780001020990312, Final Batch Loss: 0.001137074432335794\n",
      "Epoch 725, Loss: 0.005386099335737526, Final Batch Loss: 0.004134766291826963\n",
      "Epoch 726, Loss: 0.00097735965391621, Final Batch Loss: 0.000608411617577076\n",
      "Epoch 727, Loss: 0.01236792031704681, Final Batch Loss: 0.012262086383998394\n",
      "Epoch 728, Loss: 0.0013612976181320846, Final Batch Loss: 0.0003053114633075893\n",
      "Epoch 729, Loss: 0.004613642813637853, Final Batch Loss: 0.0007031124550849199\n",
      "Epoch 730, Loss: 0.003641619172412902, Final Batch Loss: 0.0032477108761668205\n",
      "Epoch 731, Loss: 0.0022848466178402305, Final Batch Loss: 0.0015323536936193705\n",
      "Epoch 732, Loss: 0.013625859224703163, Final Batch Loss: 0.0008850814192555845\n",
      "Epoch 733, Loss: 0.0011288452369626611, Final Batch Loss: 0.0003068996302317828\n",
      "Epoch 734, Loss: 0.005347410653484985, Final Batch Loss: 0.00043355950037948787\n",
      "Epoch 735, Loss: 0.014739496167749166, Final Batch Loss: 0.00030689267441630363\n",
      "Epoch 736, Loss: 0.0012000148417428136, Final Batch Loss: 0.0007177239749580622\n",
      "Epoch 737, Loss: 0.003421599045395851, Final Batch Loss: 0.0002498375251889229\n",
      "Epoch 738, Loss: 0.0007728450582362711, Final Batch Loss: 0.00036613745032809675\n",
      "Epoch 739, Loss: 0.0008838694484438747, Final Batch Loss: 0.0005636629648506641\n",
      "Epoch 740, Loss: 0.011596454918617383, Final Batch Loss: 0.011405556462705135\n",
      "Epoch 741, Loss: 0.007513237476814538, Final Batch Loss: 0.0065650842152535915\n",
      "Epoch 742, Loss: 0.005979093140922487, Final Batch Loss: 0.0016447444213554263\n",
      "Epoch 743, Loss: 0.0019073394360020757, Final Batch Loss: 0.0005789059214293957\n",
      "Epoch 744, Loss: 0.0006459751457441598, Final Batch Loss: 0.00035022699739784\n",
      "Epoch 745, Loss: 0.001162711385404691, Final Batch Loss: 0.0004034349985886365\n",
      "Epoch 746, Loss: 0.0006456442060880363, Final Batch Loss: 0.00030024006264284253\n",
      "Epoch 747, Loss: 0.0013776467530988157, Final Batch Loss: 0.0007269726484082639\n",
      "Epoch 748, Loss: 0.0028740192647092044, Final Batch Loss: 0.002477593719959259\n",
      "Epoch 749, Loss: 0.0010041186033049598, Final Batch Loss: 0.00019497612083796412\n",
      "Epoch 750, Loss: 0.0007855435251258314, Final Batch Loss: 0.0005361375515349209\n",
      "Epoch 751, Loss: 0.00728077907115221, Final Batch Loss: 0.0022208397276699543\n",
      "Epoch 752, Loss: 0.0006573804130312055, Final Batch Loss: 0.0005180187290534377\n",
      "Epoch 753, Loss: 0.009440035675652325, Final Batch Loss: 0.00787385180592537\n",
      "Epoch 754, Loss: 0.0017431395535822958, Final Batch Loss: 0.0003542367776390165\n",
      "Epoch 755, Loss: 0.005597703158855438, Final Batch Loss: 0.0032935156486928463\n",
      "Epoch 756, Loss: 0.012250383850187063, Final Batch Loss: 0.007142283953726292\n",
      "Epoch 757, Loss: 0.0017698586452752352, Final Batch Loss: 0.0008740958874113858\n",
      "Epoch 758, Loss: 0.002593768513179384, Final Batch Loss: 9.166773816104978e-05\n",
      "Epoch 759, Loss: 0.004133807960897684, Final Batch Loss: 0.0021960418671369553\n",
      "Epoch 760, Loss: 0.0006377204263117164, Final Batch Loss: 0.0002601138548925519\n",
      "Epoch 761, Loss: 0.006257589906454086, Final Batch Loss: 0.0006290157325565815\n",
      "Epoch 762, Loss: 0.0017343270010314882, Final Batch Loss: 0.0010148646542802453\n",
      "Epoch 763, Loss: 0.003963378898333758, Final Batch Loss: 0.0007604671991430223\n",
      "Epoch 764, Loss: 0.006986992782913148, Final Batch Loss: 0.006304850336164236\n",
      "Epoch 765, Loss: 0.0005006069695809856, Final Batch Loss: 0.00019086153770331293\n",
      "Epoch 766, Loss: 0.0052150453557260334, Final Batch Loss: 0.004844650160521269\n",
      "Epoch 767, Loss: 0.00904902711044997, Final Batch Loss: 0.0005337706534191966\n",
      "Epoch 768, Loss: 0.005087297642603517, Final Batch Loss: 0.0030355583876371384\n",
      "Epoch 769, Loss: 0.0005024527199566364, Final Batch Loss: 0.00026984658325091004\n",
      "Epoch 770, Loss: 0.0009149547986453399, Final Batch Loss: 0.00023851472360547632\n",
      "Epoch 771, Loss: 0.04266313789412379, Final Batch Loss: 0.0006884741596877575\n",
      "Epoch 772, Loss: 0.005314014881150797, Final Batch Loss: 0.00030396043439395726\n",
      "Epoch 773, Loss: 0.0055103611666709185, Final Batch Loss: 0.0006251309532672167\n",
      "Epoch 774, Loss: 0.002108735323417932, Final Batch Loss: 0.0008971860515885055\n",
      "Epoch 775, Loss: 0.001414839643985033, Final Batch Loss: 0.0007999511435627937\n",
      "Epoch 776, Loss: 0.020882320357486606, Final Batch Loss: 0.001418462721630931\n",
      "Epoch 777, Loss: 0.0028569369460456073, Final Batch Loss: 0.0021278089843690395\n",
      "Epoch 778, Loss: 0.015043981416965835, Final Batch Loss: 0.000132956585730426\n",
      "Epoch 779, Loss: 0.010336834791814908, Final Batch Loss: 0.000439345691120252\n",
      "Epoch 780, Loss: 0.0010752682283055037, Final Batch Loss: 0.00036057326360605657\n",
      "Epoch 781, Loss: 0.005033667664974928, Final Batch Loss: 0.002619606675580144\n",
      "Epoch 782, Loss: 0.0007778509898344055, Final Batch Loss: 0.00022488624381367117\n",
      "Epoch 783, Loss: 0.0012750840978696942, Final Batch Loss: 0.00035163620486855507\n",
      "Epoch 784, Loss: 0.001888966013211757, Final Batch Loss: 0.0013069630367681384\n",
      "Epoch 785, Loss: 0.017218060325831175, Final Batch Loss: 0.0020520626567304134\n",
      "Epoch 786, Loss: 0.0006645012181252241, Final Batch Loss: 0.0001790731039363891\n",
      "Epoch 787, Loss: 0.01041985079064034, Final Batch Loss: 0.010235371999442577\n",
      "Epoch 788, Loss: 0.0008697016673977487, Final Batch Loss: 0.0007641779957339168\n",
      "Epoch 789, Loss: 0.000890579802216962, Final Batch Loss: 0.00038848284748382866\n",
      "Epoch 790, Loss: 0.0048039318062365055, Final Batch Loss: 0.0008674990385770798\n",
      "Epoch 791, Loss: 0.006540117901749909, Final Batch Loss: 0.0010043258080258965\n",
      "Epoch 792, Loss: 0.0011254028358962387, Final Batch Loss: 0.0007992151658982038\n",
      "Epoch 793, Loss: 0.006658360594883561, Final Batch Loss: 0.0030619262252002954\n",
      "Epoch 794, Loss: 0.00063599061104469, Final Batch Loss: 0.00038946469430811703\n",
      "Epoch 795, Loss: 0.008040533401072025, Final Batch Loss: 0.004357803147286177\n",
      "Epoch 796, Loss: 0.004751375061459839, Final Batch Loss: 0.0035727834329009056\n",
      "Epoch 797, Loss: 0.0002463652126607485, Final Batch Loss: 8.984689338831231e-05\n",
      "Epoch 798, Loss: 0.0009072402899619192, Final Batch Loss: 0.000668432388920337\n",
      "Epoch 799, Loss: 0.0009437750704819337, Final Batch Loss: 0.0001947521377587691\n",
      "Epoch 800, Loss: 0.0007930541905807331, Final Batch Loss: 0.00012741745740640908\n",
      "Epoch 801, Loss: 0.0010935338214039803, Final Batch Loss: 0.0005959196132607758\n",
      "Epoch 802, Loss: 0.007614496047608554, Final Batch Loss: 0.0003095505526289344\n",
      "Epoch 803, Loss: 0.0010487567051313818, Final Batch Loss: 0.0004837537417188287\n",
      "Epoch 804, Loss: 0.0035095685452688485, Final Batch Loss: 0.0001682229631114751\n",
      "Epoch 805, Loss: 0.002595569152617827, Final Batch Loss: 0.00047716559492982924\n",
      "Epoch 806, Loss: 0.0025400655576959252, Final Batch Loss: 0.002033409895375371\n",
      "Epoch 807, Loss: 0.0013093231100356206, Final Batch Loss: 0.0001258941920241341\n",
      "Epoch 808, Loss: 0.0015198016189970076, Final Batch Loss: 0.0007092038285918534\n",
      "Epoch 809, Loss: 0.0007448403484886512, Final Batch Loss: 0.0005764858215115964\n",
      "Epoch 810, Loss: 0.006408971268683672, Final Batch Loss: 0.00543271703645587\n",
      "Epoch 811, Loss: 0.0013615889474749565, Final Batch Loss: 0.0007857360178604722\n",
      "Epoch 812, Loss: 0.0007382024923572317, Final Batch Loss: 0.0001825032668421045\n",
      "Epoch 813, Loss: 0.0015513923426624388, Final Batch Loss: 0.0002740957716014236\n",
      "Epoch 814, Loss: 0.0006226512341527268, Final Batch Loss: 0.0005500292172655463\n",
      "Epoch 815, Loss: 0.0002203019212174695, Final Batch Loss: 0.00016505290113855153\n",
      "Epoch 816, Loss: 0.0006110655522206798, Final Batch Loss: 0.00015042487939354032\n",
      "Epoch 817, Loss: 0.0008520910632796586, Final Batch Loss: 0.0007769074873067439\n",
      "Epoch 818, Loss: 0.0023995517985895276, Final Batch Loss: 0.0004619475221261382\n",
      "Epoch 819, Loss: 0.017786364071071148, Final Batch Loss: 0.014885890297591686\n",
      "Epoch 820, Loss: 0.0023237793357111514, Final Batch Loss: 0.0005200934247113764\n",
      "Epoch 821, Loss: 0.002252474892884493, Final Batch Loss: 0.0006219500210136175\n",
      "Epoch 822, Loss: 0.0006446316401707008, Final Batch Loss: 0.00019061237981077284\n",
      "Epoch 823, Loss: 0.0019436919828876853, Final Batch Loss: 0.0014358266489580274\n",
      "Epoch 824, Loss: 0.0014000206138007343, Final Batch Loss: 0.0006433824892155826\n",
      "Epoch 825, Loss: 0.0026090400060638785, Final Batch Loss: 0.0014620813308283687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826, Loss: 0.02447216131258756, Final Batch Loss: 0.023712769150733948\n",
      "Epoch 827, Loss: 0.0013822417822666466, Final Batch Loss: 0.001120475004427135\n",
      "Epoch 828, Loss: 0.0007609403037349693, Final Batch Loss: 7.491528958780691e-05\n",
      "Epoch 829, Loss: 0.0013874434225726873, Final Batch Loss: 0.000443457713117823\n",
      "Epoch 830, Loss: 0.0006993857678025961, Final Batch Loss: 0.00046416401164606214\n",
      "Epoch 831, Loss: 0.00038871821016073227, Final Batch Loss: 0.00016710378986317664\n",
      "Epoch 832, Loss: 0.001399645727360621, Final Batch Loss: 0.00027453622897155583\n",
      "Epoch 833, Loss: 0.001361850772809703, Final Batch Loss: 8.65187103045173e-05\n",
      "Epoch 834, Loss: 0.0008365014800801873, Final Batch Loss: 0.0002555742394179106\n",
      "Epoch 835, Loss: 0.0015526792558375746, Final Batch Loss: 0.0002533330407459289\n",
      "Epoch 836, Loss: 0.0009501510648988187, Final Batch Loss: 0.0003438253188505769\n",
      "Epoch 837, Loss: 0.0012565858487505466, Final Batch Loss: 0.0011016408680006862\n",
      "Epoch 838, Loss: 0.012599809211678803, Final Batch Loss: 0.011853043921291828\n",
      "Epoch 839, Loss: 0.008101182989776134, Final Batch Loss: 0.0004994128830730915\n",
      "Epoch 840, Loss: 0.006650349736446515, Final Batch Loss: 0.006281276699155569\n",
      "Epoch 841, Loss: 0.0020453042816370726, Final Batch Loss: 0.0008752860594540834\n",
      "Epoch 842, Loss: 0.008655088429804891, Final Batch Loss: 0.00808197446167469\n",
      "Epoch 843, Loss: 0.0014347074320539832, Final Batch Loss: 0.0004525979747995734\n",
      "Epoch 844, Loss: 0.005746540613472462, Final Batch Loss: 0.004964887630194426\n",
      "Epoch 845, Loss: 0.00712513888720423, Final Batch Loss: 0.0005263240309432149\n",
      "Epoch 846, Loss: 0.006554487510584295, Final Batch Loss: 0.0007826605578884482\n",
      "Epoch 847, Loss: 0.0052330156322568655, Final Batch Loss: 0.0027042352594435215\n",
      "Epoch 848, Loss: 0.0006604888039873913, Final Batch Loss: 0.0004597236402332783\n",
      "Epoch 849, Loss: 0.0017627037595957518, Final Batch Loss: 0.0008387301932089031\n",
      "Epoch 850, Loss: 0.005154486192623153, Final Batch Loss: 0.0003609307168517262\n",
      "Epoch 851, Loss: 0.012879236019216478, Final Batch Loss: 0.012102359905838966\n",
      "Epoch 852, Loss: 0.0016775153344497085, Final Batch Loss: 0.0007915592868812382\n",
      "Epoch 853, Loss: 0.0013517406769096851, Final Batch Loss: 0.0005916625377722085\n",
      "Epoch 854, Loss: 0.0013391803804552183, Final Batch Loss: 0.00014126427413430065\n",
      "Epoch 855, Loss: 0.0006385569431586191, Final Batch Loss: 0.000567031092941761\n",
      "Epoch 856, Loss: 0.002113368347636424, Final Batch Loss: 0.0002303622750332579\n",
      "Epoch 857, Loss: 0.0010307195479981601, Final Batch Loss: 0.00041841919301077724\n",
      "Epoch 858, Loss: 0.00821352022467181, Final Batch Loss: 0.0005320954951457679\n",
      "Epoch 859, Loss: 0.002615688747027889, Final Batch Loss: 0.0002730012929532677\n",
      "Epoch 860, Loss: 0.01681427366565913, Final Batch Loss: 0.001172752003185451\n",
      "Epoch 861, Loss: 0.0019252736237831414, Final Batch Loss: 0.000470476399641484\n",
      "Epoch 862, Loss: 0.0019689642067532986, Final Batch Loss: 0.0002716092567425221\n",
      "Epoch 863, Loss: 0.006500452975160442, Final Batch Loss: 0.006371283903717995\n",
      "Epoch 864, Loss: 0.001041647352394648, Final Batch Loss: 0.0008276199223473668\n",
      "Epoch 865, Loss: 0.0008685417997185141, Final Batch Loss: 0.00025748167536221445\n",
      "Epoch 866, Loss: 0.000501566450111568, Final Batch Loss: 0.00028929722611792386\n",
      "Epoch 867, Loss: 0.000943836581427604, Final Batch Loss: 0.0005668813828378916\n",
      "Epoch 868, Loss: 0.0010186709696426988, Final Batch Loss: 0.00027089379727840424\n",
      "Epoch 869, Loss: 0.0010000522015616298, Final Batch Loss: 0.0006782373529858887\n",
      "Epoch 870, Loss: 0.00046554273285437375, Final Batch Loss: 0.00018574342539068311\n",
      "Epoch 871, Loss: 0.005819579935632646, Final Batch Loss: 0.0010776490671560168\n",
      "Epoch 872, Loss: 0.014509185770293698, Final Batch Loss: 0.00047764796181581914\n",
      "Epoch 873, Loss: 0.0010678695398382843, Final Batch Loss: 0.0005234376876614988\n",
      "Epoch 874, Loss: 0.0004875495214946568, Final Batch Loss: 0.00028186856070533395\n",
      "Epoch 875, Loss: 0.010886596282944083, Final Batch Loss: 0.0019755528774112463\n",
      "Epoch 876, Loss: 0.0018496538395993412, Final Batch Loss: 0.0008474167552776635\n",
      "Epoch 877, Loss: 0.0005421271780505776, Final Batch Loss: 0.0002473402419127524\n",
      "Epoch 878, Loss: 0.0022824525804026052, Final Batch Loss: 0.002125382889062166\n",
      "Epoch 879, Loss: 0.001783192201401107, Final Batch Loss: 0.0015842346474528313\n",
      "Epoch 880, Loss: 0.0011840914376080036, Final Batch Loss: 0.0005001039244234562\n",
      "Epoch 881, Loss: 0.01623842414119281, Final Batch Loss: 0.000310105417156592\n",
      "Epoch 882, Loss: 0.007493707817047834, Final Batch Loss: 0.0020428895950317383\n",
      "Epoch 883, Loss: 0.0004728841668111272, Final Batch Loss: 5.251635593594983e-05\n",
      "Epoch 884, Loss: 0.0006827172910561785, Final Batch Loss: 0.0002006710710702464\n",
      "Epoch 885, Loss: 0.0006199718191055581, Final Batch Loss: 0.00011318594624754041\n",
      "Epoch 886, Loss: 0.0011532888456713408, Final Batch Loss: 0.0002695177390705794\n",
      "Epoch 887, Loss: 0.005647504549415316, Final Batch Loss: 8.562937000533566e-05\n",
      "Epoch 888, Loss: 0.0014891321407048963, Final Batch Loss: 0.0013694139197468758\n",
      "Epoch 889, Loss: 0.0008018471562536433, Final Batch Loss: 8.176070696208626e-05\n",
      "Epoch 890, Loss: 0.002716852104640566, Final Batch Loss: 0.0026262635365128517\n",
      "Epoch 891, Loss: 0.002225174510385841, Final Batch Loss: 0.0012966579524800181\n",
      "Epoch 892, Loss: 0.004232281091390178, Final Batch Loss: 0.00027360368403606117\n",
      "Epoch 893, Loss: 0.0012902508096885867, Final Batch Loss: 0.0001146448848885484\n",
      "Epoch 894, Loss: 0.001341012364719063, Final Batch Loss: 0.0011036258656531572\n",
      "Epoch 895, Loss: 0.00040745198202785105, Final Batch Loss: 0.00014439433289226145\n",
      "Epoch 896, Loss: 0.0024118471737892833, Final Batch Loss: 5.856289863004349e-05\n",
      "Epoch 897, Loss: 0.0016708850744180381, Final Batch Loss: 0.0001531022717244923\n",
      "Epoch 898, Loss: 0.003894043678883463, Final Batch Loss: 0.00017244491027668118\n",
      "Epoch 899, Loss: 0.0007686998069402762, Final Batch Loss: 0.0007146285497583449\n",
      "Epoch 900, Loss: 0.011390391708118841, Final Batch Loss: 0.01127755269408226\n",
      "Epoch 901, Loss: 0.0019084534578723833, Final Batch Loss: 0.00021219327754806727\n",
      "Epoch 902, Loss: 0.007602181518450379, Final Batch Loss: 0.00072709028609097\n",
      "Epoch 903, Loss: 0.005135833693202585, Final Batch Loss: 0.0047708735801279545\n",
      "Epoch 904, Loss: 0.002661238453583792, Final Batch Loss: 0.0022438792511820793\n",
      "Epoch 905, Loss: 0.0012181915881228633, Final Batch Loss: 0.0011134069645777345\n",
      "Epoch 906, Loss: 0.0021262223890516907, Final Batch Loss: 0.00192764971870929\n",
      "Epoch 907, Loss: 0.0021148225641809404, Final Batch Loss: 0.0009236571495421231\n",
      "Epoch 908, Loss: 0.0010441351914778352, Final Batch Loss: 0.0002781765069812536\n",
      "Epoch 909, Loss: 0.0002852287288988009, Final Batch Loss: 7.266331522259861e-05\n",
      "Epoch 910, Loss: 0.012127502355724573, Final Batch Loss: 0.007482717279344797\n",
      "Epoch 911, Loss: 0.0014280668110586703, Final Batch Loss: 0.0008756816387176514\n",
      "Epoch 912, Loss: 0.0004858162865275517, Final Batch Loss: 0.00023295408755075186\n",
      "Epoch 913, Loss: 0.0018604602664709091, Final Batch Loss: 0.0014896044740453362\n",
      "Epoch 914, Loss: 0.00045399907685350627, Final Batch Loss: 0.00027953158132731915\n",
      "Epoch 915, Loss: 0.005494218377862126, Final Batch Loss: 0.005049701780080795\n",
      "Epoch 916, Loss: 0.0007222921121865511, Final Batch Loss: 0.00028099160408601165\n",
      "Epoch 917, Loss: 0.0062897015595808625, Final Batch Loss: 0.00032546522561460733\n",
      "Epoch 918, Loss: 0.005958013003692031, Final Batch Loss: 0.002501123119145632\n",
      "Epoch 919, Loss: 0.0003589633197407238, Final Batch Loss: 4.921608342556283e-05\n",
      "Epoch 920, Loss: 0.0016967527917586267, Final Batch Loss: 0.0009486471535637975\n",
      "Epoch 921, Loss: 0.0005019293748773634, Final Batch Loss: 0.00013170225429348648\n",
      "Epoch 922, Loss: 0.0010752770249382593, Final Batch Loss: 0.000959591066930443\n",
      "Epoch 923, Loss: 0.0017195442069350975, Final Batch Loss: 2.342826519452501e-05\n",
      "Epoch 924, Loss: 0.00035157853562850505, Final Batch Loss: 0.0001027784455800429\n",
      "Epoch 925, Loss: 0.0005663901538355276, Final Batch Loss: 0.0003558903408702463\n",
      "Epoch 926, Loss: 0.007038340627332218, Final Batch Loss: 0.00687243090942502\n",
      "Epoch 927, Loss: 0.0011668845254462212, Final Batch Loss: 0.0008777957409620285\n",
      "Epoch 928, Loss: 0.00022142466332297772, Final Batch Loss: 7.6903379522264e-05\n",
      "Epoch 929, Loss: 0.0009425160533282906, Final Batch Loss: 0.000690341810695827\n",
      "Epoch 930, Loss: 0.0011607713822741061, Final Batch Loss: 0.00017828380805440247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 931, Loss: 0.0015878962585702538, Final Batch Loss: 0.0011473404010757804\n",
      "Epoch 932, Loss: 0.00031822330493014306, Final Batch Loss: 0.00016841791511978954\n",
      "Epoch 933, Loss: 0.0007307350169867277, Final Batch Loss: 0.000566779519431293\n",
      "Epoch 934, Loss: 0.0005318342737155035, Final Batch Loss: 0.0002930713235400617\n",
      "Epoch 935, Loss: 0.0009487494244240224, Final Batch Loss: 0.00025278289103880525\n",
      "Epoch 936, Loss: 0.0006134767972980626, Final Batch Loss: 6.651413423242047e-05\n",
      "Epoch 937, Loss: 0.00039542574086226523, Final Batch Loss: 0.0002104809827869758\n",
      "Epoch 938, Loss: 0.02110741287469864, Final Batch Loss: 0.010006381198763847\n",
      "Epoch 939, Loss: 0.00048877766039368, Final Batch Loss: 1.16585733849206e-05\n",
      "Epoch 940, Loss: 0.007293269911315292, Final Batch Loss: 0.0007377620204351842\n",
      "Epoch 941, Loss: 0.0009274081676267087, Final Batch Loss: 0.0006120583857409656\n",
      "Epoch 942, Loss: 0.000191362552868668, Final Batch Loss: 0.00011884317063959315\n",
      "Epoch 943, Loss: 0.03330416385142598, Final Batch Loss: 0.03307183086872101\n",
      "Epoch 944, Loss: 0.001417795050656423, Final Batch Loss: 0.00043501760228537023\n",
      "Epoch 945, Loss: 0.0052678678766824305, Final Batch Loss: 0.0005400879890657961\n",
      "Epoch 946, Loss: 0.006496580666862428, Final Batch Loss: 0.001024615834467113\n",
      "Epoch 947, Loss: 0.0014830994768999517, Final Batch Loss: 0.0003412317601032555\n",
      "Epoch 948, Loss: 0.0008631160017102957, Final Batch Loss: 0.00031358504202216864\n",
      "Epoch 949, Loss: 0.0024087362398859113, Final Batch Loss: 0.00192630582023412\n",
      "Epoch 950, Loss: 0.01908133304095827, Final Batch Loss: 0.00046611702418886125\n",
      "Epoch 951, Loss: 0.0011214530386496335, Final Batch Loss: 0.0003470231604296714\n",
      "Epoch 952, Loss: 0.0017495834617875516, Final Batch Loss: 0.0002536530955694616\n",
      "Epoch 953, Loss: 0.001130551056121476, Final Batch Loss: 5.121024150867015e-05\n",
      "Epoch 954, Loss: 0.0008745344821363688, Final Batch Loss: 4.318816354498267e-05\n",
      "Epoch 955, Loss: 0.008723608450964093, Final Batch Loss: 0.004824907053261995\n",
      "Epoch 956, Loss: 0.0057981276186183095, Final Batch Loss: 0.0008335519814863801\n",
      "Epoch 957, Loss: 0.0027639681939035654, Final Batch Loss: 0.0011036605574190617\n",
      "Epoch 958, Loss: 0.0016848547820700333, Final Batch Loss: 0.0014630347723141313\n",
      "Epoch 959, Loss: 0.0013671359374711756, Final Batch Loss: 5.0385981012368575e-05\n",
      "Epoch 960, Loss: 0.004619898478267714, Final Batch Loss: 9.102441254071891e-05\n",
      "Epoch 961, Loss: 0.00032923089747782797, Final Batch Loss: 0.0002022769913310185\n",
      "Epoch 962, Loss: 0.0013407647638814524, Final Batch Loss: 0.001133715733885765\n",
      "Epoch 963, Loss: 0.0009036276023834944, Final Batch Loss: 0.00061482546152547\n",
      "Epoch 964, Loss: 0.002071531751425937, Final Batch Loss: 0.0016008232487365603\n",
      "Epoch 965, Loss: 0.009198107989504933, Final Batch Loss: 0.00855356827378273\n",
      "Epoch 966, Loss: 0.0009252827148884535, Final Batch Loss: 0.0008532596402801573\n",
      "Epoch 967, Loss: 0.0006499737210106105, Final Batch Loss: 0.00039097582339309156\n",
      "Epoch 968, Loss: 0.002576992570539005, Final Batch Loss: 0.0023351709824055433\n",
      "Epoch 969, Loss: 0.001415410268236883, Final Batch Loss: 5.068846803624183e-05\n",
      "Epoch 970, Loss: 0.0054075214138720185, Final Batch Loss: 0.0002054864598903805\n",
      "Epoch 971, Loss: 0.0005771051510237157, Final Batch Loss: 0.00023167073959484696\n",
      "Epoch 972, Loss: 0.0005919327231822535, Final Batch Loss: 0.00019402614270802587\n",
      "Epoch 973, Loss: 0.008474006783217192, Final Batch Loss: 0.0036570713855326176\n",
      "Epoch 974, Loss: 0.0006024181784596294, Final Batch Loss: 0.0003295070491731167\n",
      "Epoch 975, Loss: 0.006686820008326322, Final Batch Loss: 0.00027379003586247563\n",
      "Epoch 976, Loss: 0.000651191410725005, Final Batch Loss: 0.00010650565673131496\n",
      "Epoch 977, Loss: 0.00046412632218562067, Final Batch Loss: 0.0001249838387593627\n",
      "Epoch 978, Loss: 0.002008354989811778, Final Batch Loss: 0.0009395524393767118\n",
      "Epoch 979, Loss: 0.0039020025869831443, Final Batch Loss: 0.0006149039836600423\n",
      "Epoch 980, Loss: 0.006939826882444322, Final Batch Loss: 0.0005744345253333449\n",
      "Epoch 981, Loss: 0.0002865170536097139, Final Batch Loss: 3.816673415713012e-05\n",
      "Epoch 982, Loss: 0.00471369072329253, Final Batch Loss: 0.003215810051187873\n",
      "Epoch 983, Loss: 0.0015425180608872324, Final Batch Loss: 0.0011575304670259356\n",
      "Epoch 984, Loss: 0.0005074826331110671, Final Batch Loss: 0.0001908962003653869\n",
      "Epoch 985, Loss: 0.0008481248514726758, Final Batch Loss: 0.00019709632033482194\n",
      "Epoch 986, Loss: 0.0010015905427280813, Final Batch Loss: 0.00027289040735922754\n",
      "Epoch 987, Loss: 0.0006981382321100682, Final Batch Loss: 0.0003736008075065911\n",
      "Epoch 988, Loss: 0.0008724717772565782, Final Batch Loss: 0.0001844812068156898\n",
      "Epoch 989, Loss: 0.00032225257746176794, Final Batch Loss: 0.00021311490854714066\n",
      "Epoch 990, Loss: 0.00356076518073678, Final Batch Loss: 0.002858285093680024\n",
      "Epoch 991, Loss: 0.0014394092722795904, Final Batch Loss: 0.000949301989749074\n",
      "Epoch 992, Loss: 0.0009604637743905187, Final Batch Loss: 0.0007569833542220294\n",
      "Epoch 993, Loss: 0.00176507823925931, Final Batch Loss: 0.0002275625738548115\n",
      "Epoch 994, Loss: 0.0004639535763999447, Final Batch Loss: 0.00026903970865532756\n",
      "Epoch 995, Loss: 0.00029828449623892084, Final Batch Loss: 0.00018989005184266716\n",
      "Epoch 996, Loss: 0.00023989519831957296, Final Batch Loss: 0.00011208227806491777\n",
      "Epoch 997, Loss: 0.0003406574105611071, Final Batch Loss: 0.00017252753605134785\n",
      "Epoch 998, Loss: 0.005033500725403428, Final Batch Loss: 0.002783056115731597\n",
      "Epoch 999, Loss: 0.0001351177015749272, Final Batch Loss: 1.9165909179719165e-05\n",
      "Epoch 1000, Loss: 0.0008097068930510432, Final Batch Loss: 0.0002310250129085034\n",
      "Epoch 1001, Loss: 0.00048156412958633155, Final Batch Loss: 0.00028361938893795013\n",
      "Epoch 1002, Loss: 0.0002905585279222578, Final Batch Loss: 0.00010040294728241861\n",
      "Epoch 1003, Loss: 0.000322509808029281, Final Batch Loss: 0.00029252079548314214\n",
      "Epoch 1004, Loss: 0.0018552040855865926, Final Batch Loss: 0.0015070106601342559\n",
      "Epoch 1005, Loss: 0.000279426560155116, Final Batch Loss: 0.00016967198462225497\n",
      "Epoch 1006, Loss: 0.0023569708173454273, Final Batch Loss: 5.1381899538682774e-05\n",
      "Epoch 1007, Loss: 0.0004455114540178329, Final Batch Loss: 0.00018542958423495293\n",
      "Epoch 1008, Loss: 0.00706982403062284, Final Batch Loss: 0.002604477806016803\n",
      "Epoch 1009, Loss: 0.0008053736964939162, Final Batch Loss: 0.0006827549077570438\n",
      "Epoch 1010, Loss: 0.000998973657260649, Final Batch Loss: 0.0002039879182120785\n",
      "Epoch 1011, Loss: 0.010238037444651127, Final Batch Loss: 0.0057528517208993435\n",
      "Epoch 1012, Loss: 0.0011271538460277952, Final Batch Loss: 0.00010421672050142661\n",
      "Epoch 1013, Loss: 0.0006271498277783394, Final Batch Loss: 0.0005461072432808578\n",
      "Epoch 1014, Loss: 0.002964611347124446, Final Batch Loss: 8.569629426347092e-05\n",
      "Epoch 1015, Loss: 0.0011389772989787161, Final Batch Loss: 0.0007792867836542428\n",
      "Epoch 1016, Loss: 0.00043687103607226163, Final Batch Loss: 0.00025990864378400147\n",
      "Epoch 1017, Loss: 0.000834523918456398, Final Batch Loss: 8.956003875937313e-05\n",
      "Epoch 1018, Loss: 0.0003829302731901407, Final Batch Loss: 0.00033647005329839885\n",
      "Epoch 1019, Loss: 0.0018963715501740808, Final Batch Loss: 1.8077504137181677e-05\n",
      "Epoch 1020, Loss: 0.0005449871387099847, Final Batch Loss: 0.00019436491129454225\n",
      "Epoch 1021, Loss: 0.000317714067932684, Final Batch Loss: 0.0002082515275105834\n",
      "Epoch 1022, Loss: 0.0034540157284936868, Final Batch Loss: 7.405076030408964e-05\n",
      "Epoch 1023, Loss: 0.009888101951219141, Final Batch Loss: 0.0013527382398024201\n",
      "Epoch 1024, Loss: 0.0016033765859901905, Final Batch Loss: 0.0010959644569084048\n",
      "Epoch 1025, Loss: 0.00026317134324926883, Final Batch Loss: 5.7101002312265337e-05\n",
      "Epoch 1026, Loss: 0.0018167858361266553, Final Batch Loss: 0.0012497963616624475\n",
      "Epoch 1027, Loss: 0.005479916275362484, Final Batch Loss: 0.0001339519367320463\n",
      "Epoch 1028, Loss: 0.0017211995145771652, Final Batch Loss: 0.0003291776229161769\n",
      "Epoch 1029, Loss: 0.0002524840965634212, Final Batch Loss: 0.00013662458513863385\n",
      "Epoch 1030, Loss: 0.0002500597020116402, Final Batch Loss: 1.6166331988642924e-05\n",
      "Epoch 1031, Loss: 0.0007729929639026523, Final Batch Loss: 0.0006067020585760474\n",
      "Epoch 1032, Loss: 0.0007126061391318217, Final Batch Loss: 0.00059479009360075\n",
      "Epoch 1033, Loss: 0.0103791817673482, Final Batch Loss: 0.0006238003843463957\n",
      "Epoch 1034, Loss: 0.007509812188800424, Final Batch Loss: 0.0005931173800490797\n",
      "Epoch 1035, Loss: 0.0007965668919496238, Final Batch Loss: 0.0003110063844360411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1036, Loss: 8.0551046266919e-05, Final Batch Loss: 4.3562617065617815e-05\n",
      "Epoch 1037, Loss: 0.0003917969297617674, Final Batch Loss: 0.00026967833400703967\n",
      "Epoch 1038, Loss: 0.0006559853136423044, Final Batch Loss: 7.632699998794124e-05\n",
      "Epoch 1039, Loss: 0.0024440028937533498, Final Batch Loss: 0.0016040528425946832\n",
      "Epoch 1040, Loss: 0.001627627367270179, Final Batch Loss: 0.0014132163487374783\n",
      "Epoch 1041, Loss: 0.007551457441877574, Final Batch Loss: 0.0005268051172606647\n",
      "Epoch 1042, Loss: 0.0022203130065463483, Final Batch Loss: 0.0009669411811046302\n",
      "Epoch 1043, Loss: 0.00037969325785525143, Final Batch Loss: 0.00013619777746498585\n",
      "Epoch 1044, Loss: 0.0008758048643358052, Final Batch Loss: 0.0006124413921497762\n",
      "Epoch 1045, Loss: 0.0005896987859159708, Final Batch Loss: 2.3294880520552397e-05\n",
      "Epoch 1046, Loss: 0.00779244618024677, Final Batch Loss: 0.00021024455782026052\n",
      "Epoch 1047, Loss: 0.00032813067082315683, Final Batch Loss: 0.00021302739332895726\n",
      "Epoch 1048, Loss: 0.0003075632921536453, Final Batch Loss: 9.858739940682426e-05\n",
      "Epoch 1049, Loss: 0.00027455599774839357, Final Batch Loss: 0.0001638649991946295\n",
      "Epoch 1050, Loss: 0.0039008702151477337, Final Batch Loss: 0.0009050560183823109\n",
      "Epoch 1051, Loss: 0.0004760873707709834, Final Batch Loss: 0.00023956317454576492\n",
      "Epoch 1052, Loss: 0.0009662714728619903, Final Batch Loss: 0.0005858708755113184\n",
      "Epoch 1053, Loss: 0.03646654658950865, Final Batch Loss: 0.03623077645897865\n",
      "Epoch 1054, Loss: 0.000259805288806092, Final Batch Loss: 0.00017984528676606715\n",
      "Epoch 1055, Loss: 0.00020749762188643217, Final Batch Loss: 8.50307842483744e-05\n",
      "Epoch 1056, Loss: 0.0004384174171718769, Final Batch Loss: 7.279754936462268e-05\n",
      "Epoch 1057, Loss: 0.0018859457632061094, Final Batch Loss: 0.001421833992935717\n",
      "Epoch 1058, Loss: 0.0006353422941174358, Final Batch Loss: 0.0003542810445651412\n",
      "Epoch 1059, Loss: 0.0006019764841767028, Final Batch Loss: 0.0003746209549717605\n",
      "Epoch 1060, Loss: 0.004149192580371164, Final Batch Loss: 0.004017707426100969\n",
      "Epoch 1061, Loss: 0.007731535326456651, Final Batch Loss: 0.00018376749358139932\n",
      "Epoch 1062, Loss: 0.0028131907456554472, Final Batch Loss: 0.00010884233051910996\n",
      "Epoch 1063, Loss: 0.00856514906627126, Final Batch Loss: 0.008310790173709393\n",
      "Epoch 1064, Loss: 0.0007490681309718639, Final Batch Loss: 0.00028410929371602833\n",
      "Epoch 1065, Loss: 0.001376752508804202, Final Batch Loss: 0.0005138522828929126\n",
      "Epoch 1066, Loss: 0.0002712286077439785, Final Batch Loss: 8.338116458617151e-05\n",
      "Epoch 1067, Loss: 0.022695454536005855, Final Batch Loss: 6.0519902035593987e-05\n",
      "Epoch 1068, Loss: 0.00032952523906715214, Final Batch Loss: 0.00010016562009695917\n",
      "Epoch 1069, Loss: 0.0005403155519161373, Final Batch Loss: 0.00012704732944257557\n",
      "Epoch 1070, Loss: 0.00023402632359648123, Final Batch Loss: 0.00019277696264907718\n",
      "Epoch 1071, Loss: 0.0009328284359071404, Final Batch Loss: 0.0004759039729833603\n",
      "Epoch 1072, Loss: 0.0008593995735282078, Final Batch Loss: 8.161117148119956e-05\n",
      "Epoch 1073, Loss: 0.000869063034770079, Final Batch Loss: 8.591353252995759e-05\n",
      "Epoch 1074, Loss: 0.0009445630275877193, Final Batch Loss: 0.0001276349212275818\n",
      "Epoch 1075, Loss: 0.0006122989725554362, Final Batch Loss: 0.0004175836220383644\n",
      "Epoch 1076, Loss: 0.0016541117220185697, Final Batch Loss: 0.0005707875243388116\n",
      "Epoch 1077, Loss: 0.003741316839295905, Final Batch Loss: 0.003639982780441642\n",
      "Epoch 1078, Loss: 0.004260254994733259, Final Batch Loss: 0.00010259213740937412\n",
      "Epoch 1079, Loss: 0.0012933905381942168, Final Batch Loss: 0.0011350426357239485\n",
      "Epoch 1080, Loss: 0.0002532337275624741, Final Batch Loss: 0.00019724895537365228\n",
      "Epoch 1081, Loss: 0.0004729902357212268, Final Batch Loss: 0.0003911439562216401\n",
      "Epoch 1082, Loss: 0.0003899980802088976, Final Batch Loss: 0.00024060932628344744\n",
      "Epoch 1083, Loss: 0.002402081125183031, Final Batch Loss: 0.002208521356806159\n",
      "Epoch 1084, Loss: 0.008467296720482409, Final Batch Loss: 0.0004670411581173539\n",
      "Epoch 1085, Loss: 0.0009129693862632848, Final Batch Loss: 0.00010670183837646618\n",
      "Epoch 1086, Loss: 0.010120473802089691, Final Batch Loss: 0.009531949646770954\n",
      "Epoch 1087, Loss: 0.0010366761234763544, Final Batch Loss: 4.9397593102185056e-05\n",
      "Epoch 1088, Loss: 0.0012707309506367892, Final Batch Loss: 8.52668599691242e-05\n",
      "Epoch 1089, Loss: 0.0019042275962419808, Final Batch Loss: 0.00028733379440382123\n",
      "Epoch 1090, Loss: 0.018301059724763036, Final Batch Loss: 0.0005450688768178225\n",
      "Epoch 1091, Loss: 0.00762561772717163, Final Batch Loss: 0.00015627517132088542\n",
      "Epoch 1092, Loss: 0.000300136256555561, Final Batch Loss: 6.210400169948116e-05\n",
      "Epoch 1093, Loss: 0.003343719057738781, Final Batch Loss: 0.0029660649597644806\n",
      "Epoch 1094, Loss: 0.004387440480059013, Final Batch Loss: 0.00011144843301735818\n",
      "Epoch 1095, Loss: 0.00037269966560415924, Final Batch Loss: 0.00021396212105173618\n",
      "Epoch 1096, Loss: 0.003977338390541263, Final Batch Loss: 0.003855189075693488\n",
      "Epoch 1097, Loss: 0.000833045894978568, Final Batch Loss: 0.00023552009952254593\n",
      "Epoch 1098, Loss: 0.010841745272045955, Final Batch Loss: 0.00024131065583787858\n",
      "Epoch 1099, Loss: 0.001012406028166879, Final Batch Loss: 8.313934813486412e-05\n",
      "Epoch 1100, Loss: 0.0008134529634844512, Final Batch Loss: 0.0004156663781031966\n",
      "Epoch 1101, Loss: 0.0007906473911134526, Final Batch Loss: 0.0005520327831618488\n",
      "Epoch 1102, Loss: 0.001524981518741697, Final Batch Loss: 0.0005668944795615971\n",
      "Epoch 1103, Loss: 0.0004544254916254431, Final Batch Loss: 0.00023818686895538121\n",
      "Epoch 1104, Loss: 0.0006229886348592117, Final Batch Loss: 0.00042966657201759517\n",
      "Epoch 1105, Loss: 0.0007110687147360295, Final Batch Loss: 0.0005629898514598608\n",
      "Epoch 1106, Loss: 0.0001507429697085172, Final Batch Loss: 0.00010105585533892736\n",
      "Epoch 1107, Loss: 0.005730725883040577, Final Batch Loss: 0.0009257225901819766\n",
      "Epoch 1108, Loss: 0.0005901281256228685, Final Batch Loss: 0.0002837899373844266\n",
      "Epoch 1109, Loss: 0.00801341524493182, Final Batch Loss: 0.0079133166000247\n",
      "Epoch 1110, Loss: 0.005922495853155851, Final Batch Loss: 0.0013191262260079384\n",
      "Epoch 1111, Loss: 0.0008298857283079997, Final Batch Loss: 0.0006820630514994264\n",
      "Epoch 1112, Loss: 0.0018132947443518788, Final Batch Loss: 0.0003985937510151416\n",
      "Epoch 1113, Loss: 0.0012855282111559063, Final Batch Loss: 0.0004428551474120468\n",
      "Epoch 1114, Loss: 0.008503000251948833, Final Batch Loss: 0.0005428697913885117\n",
      "Epoch 1115, Loss: 0.0017327791720163077, Final Batch Loss: 0.0015297289937734604\n",
      "Epoch 1116, Loss: 0.000837184543343028, Final Batch Loss: 4.8115496610989794e-05\n",
      "Epoch 1117, Loss: 0.0005369854188757017, Final Batch Loss: 0.00018490532238502055\n",
      "Epoch 1118, Loss: 0.003223797175451182, Final Batch Loss: 0.0030272456351667643\n",
      "Epoch 1119, Loss: 0.0006145244551589713, Final Batch Loss: 0.0002365789987379685\n",
      "Epoch 1120, Loss: 0.0006022895395290107, Final Batch Loss: 0.0005182725144550204\n",
      "Epoch 1121, Loss: 0.0005511866183951497, Final Batch Loss: 0.00038051960291340947\n",
      "Epoch 1122, Loss: 0.001172023912658915, Final Batch Loss: 0.0010341124143451452\n",
      "Epoch 1123, Loss: 0.0007526333502028137, Final Batch Loss: 0.0004470072453841567\n",
      "Epoch 1124, Loss: 0.0002816118794726208, Final Batch Loss: 0.00018092461687047035\n",
      "Epoch 1125, Loss: 0.003053568070754409, Final Batch Loss: 0.0027584386989474297\n",
      "Epoch 1126, Loss: 0.0017924209823831916, Final Batch Loss: 0.000502879498526454\n",
      "Epoch 1127, Loss: 0.008341925509739667, Final Batch Loss: 0.007840335369110107\n",
      "Epoch 1128, Loss: 0.000357458702637814, Final Batch Loss: 0.00018239910423289984\n",
      "Epoch 1129, Loss: 0.0010368258517701179, Final Batch Loss: 0.0001535873452667147\n",
      "Epoch 1130, Loss: 0.0004432085406733677, Final Batch Loss: 0.00018058183195535094\n",
      "Epoch 1131, Loss: 0.004320432315580547, Final Batch Loss: 0.00029389176052063704\n",
      "Epoch 1132, Loss: 0.0002601143278297968, Final Batch Loss: 0.00011872413597302511\n",
      "Epoch 1133, Loss: 0.0017174597160192207, Final Batch Loss: 0.001558138756081462\n",
      "Epoch 1134, Loss: 0.0011926686056540348, Final Batch Loss: 7.57651068852283e-05\n",
      "Epoch 1135, Loss: 0.0006338498060358688, Final Batch Loss: 0.0004418109019752592\n",
      "Epoch 1136, Loss: 0.00039724497764836997, Final Batch Loss: 0.00012776338553521782\n",
      "Epoch 1137, Loss: 0.0018064886680804193, Final Batch Loss: 0.0014815818285569549\n",
      "Epoch 1138, Loss: 0.00031177783966995776, Final Batch Loss: 0.00013710516213905066\n",
      "Epoch 1139, Loss: 0.0007838491219445132, Final Batch Loss: 6.397093966370448e-05\n",
      "Epoch 1140, Loss: 0.0003515964126563631, Final Batch Loss: 0.00010416722943773493\n",
      "Epoch 1141, Loss: 0.000427217673859559, Final Batch Loss: 0.0001087123091565445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142, Loss: 0.001625022734515369, Final Batch Loss: 6.133387796580791e-05\n",
      "Epoch 1143, Loss: 0.000476567744044587, Final Batch Loss: 0.0001338402507826686\n",
      "Epoch 1144, Loss: 0.006816980894654989, Final Batch Loss: 0.006191062740981579\n",
      "Epoch 1145, Loss: 0.0009220520732924342, Final Batch Loss: 0.00025864847702905536\n",
      "Epoch 1146, Loss: 0.0005412978061940521, Final Batch Loss: 0.00029704198823310435\n",
      "Epoch 1147, Loss: 0.0010614172497298568, Final Batch Loss: 0.0002538361877668649\n",
      "Epoch 1148, Loss: 0.0011825394176412374, Final Batch Loss: 0.00028964204830117524\n",
      "Epoch 1149, Loss: 0.0032267013448290527, Final Batch Loss: 0.0004395027062855661\n",
      "Epoch 1150, Loss: 0.0016070217134256382, Final Batch Loss: 0.0015728507423773408\n",
      "Epoch 1151, Loss: 0.00626197864767164, Final Batch Loss: 0.0050318920984864235\n",
      "Epoch 1152, Loss: 0.006055379053577781, Final Batch Loss: 0.005479828454554081\n",
      "Epoch 1153, Loss: 0.01177069847472012, Final Batch Loss: 0.0014992777723819017\n",
      "Epoch 1154, Loss: 0.0003950227110181004, Final Batch Loss: 0.00013398239389061928\n",
      "Epoch 1155, Loss: 0.0002555022656451911, Final Batch Loss: 8.572368824388832e-05\n",
      "Epoch 1156, Loss: 0.0004519487629295327, Final Batch Loss: 9.203080117003992e-05\n",
      "Epoch 1157, Loss: 0.0008520789560861886, Final Batch Loss: 0.0005333541776053607\n",
      "Epoch 1158, Loss: 0.00027753595350077376, Final Batch Loss: 0.00010213937639491633\n",
      "Epoch 1159, Loss: 0.0004255374660715461, Final Batch Loss: 0.00027403986314311624\n",
      "Epoch 1160, Loss: 0.0061738268414046615, Final Batch Loss: 0.00015425271703861654\n",
      "Epoch 1161, Loss: 0.0001957091772055719, Final Batch Loss: 5.9161426179343835e-05\n",
      "Epoch 1162, Loss: 0.00040048091614153236, Final Batch Loss: 0.00018284900579601526\n",
      "Epoch 1163, Loss: 0.004472184256883338, Final Batch Loss: 0.00010741016012616456\n",
      "Epoch 1164, Loss: 0.0018691925797611475, Final Batch Loss: 5.52422134205699e-05\n",
      "Epoch 1165, Loss: 0.0010098988277604803, Final Batch Loss: 0.00013243737339507788\n",
      "Epoch 1166, Loss: 0.0007377666188403964, Final Batch Loss: 0.0005001742974855006\n",
      "Epoch 1167, Loss: 0.001096609736123355, Final Batch Loss: 5.8819528931053355e-05\n",
      "Epoch 1168, Loss: 0.0011151794460602105, Final Batch Loss: 0.0009290461312048137\n",
      "Epoch 1169, Loss: 0.00031977472826838493, Final Batch Loss: 0.00022224649728741497\n",
      "Epoch 1170, Loss: 0.004559412962407805, Final Batch Loss: 6.328652671072632e-05\n",
      "Epoch 1171, Loss: 0.00143835847848095, Final Batch Loss: 0.000253797770710662\n",
      "Epoch 1172, Loss: 0.0015766415090183727, Final Batch Loss: 3.471975651336834e-05\n",
      "Epoch 1173, Loss: 0.00012681498628808185, Final Batch Loss: 6.189426494529471e-05\n",
      "Epoch 1174, Loss: 0.00028325019957264885, Final Batch Loss: 0.0001015949746943079\n",
      "Epoch 1175, Loss: 0.0004335867997724563, Final Batch Loss: 0.00019327776681166142\n",
      "Epoch 1176, Loss: 0.0004752350359922275, Final Batch Loss: 0.0002542477159295231\n",
      "Epoch 1177, Loss: 0.00018217448450741358, Final Batch Loss: 4.289704156690277e-05\n",
      "Epoch 1178, Loss: 0.0007758964202366769, Final Batch Loss: 0.0006817106041125953\n",
      "Epoch 1179, Loss: 0.011435170890763402, Final Batch Loss: 0.011038729920983315\n",
      "Epoch 1180, Loss: 0.0016096290346467867, Final Batch Loss: 0.0014173263916745782\n",
      "Epoch 1181, Loss: 0.003830225265119225, Final Batch Loss: 0.00032733409898355603\n",
      "Epoch 1182, Loss: 0.0005916294667258626, Final Batch Loss: 3.028706669283565e-05\n",
      "Epoch 1183, Loss: 0.000524541872437112, Final Batch Loss: 0.0004374257114250213\n",
      "Epoch 1184, Loss: 0.00022268920292844996, Final Batch Loss: 7.923428347567096e-05\n",
      "Epoch 1185, Loss: 0.00230423198081553, Final Batch Loss: 0.002235566498711705\n",
      "Epoch 1186, Loss: 0.0001853684152592905, Final Batch Loss: 0.00010962625674437732\n",
      "Epoch 1187, Loss: 0.0008967781413957709, Final Batch Loss: 2.360606777074281e-05\n",
      "Epoch 1188, Loss: 0.0005272764683468267, Final Batch Loss: 4.288689524400979e-05\n",
      "Epoch 1189, Loss: 0.07509658774506534, Final Batch Loss: 0.07504961639642715\n",
      "Epoch 1190, Loss: 0.0005414572078734636, Final Batch Loss: 0.00031473912531509995\n",
      "Epoch 1191, Loss: 0.0005759724881500006, Final Batch Loss: 0.00032188621116802096\n",
      "Epoch 1192, Loss: 0.0005269362009130418, Final Batch Loss: 0.000202062918106094\n",
      "Epoch 1193, Loss: 0.0003099812165601179, Final Batch Loss: 0.00020456705533433706\n",
      "Epoch 1194, Loss: 0.0011905935825780034, Final Batch Loss: 0.0004262506845407188\n",
      "Epoch 1195, Loss: 0.0012712629977613688, Final Batch Loss: 0.0005661339382641017\n",
      "Epoch 1196, Loss: 0.0009336843504570425, Final Batch Loss: 4.557997453957796e-05\n",
      "Epoch 1197, Loss: 0.00409760772890877, Final Batch Loss: 0.0002027487353188917\n",
      "Epoch 1198, Loss: 0.000345642096363008, Final Batch Loss: 3.839100827462971e-05\n",
      "Epoch 1199, Loss: 0.0018431587959639728, Final Batch Loss: 0.000979638658463955\n",
      "Epoch 1200, Loss: 0.0004065692992298864, Final Batch Loss: 6.364646105794236e-05\n",
      "Epoch 1201, Loss: 0.0017810661811381578, Final Batch Loss: 0.0013609029119834304\n",
      "Epoch 1202, Loss: 0.00031604745890945196, Final Batch Loss: 0.00012664106907323003\n",
      "Epoch 1203, Loss: 0.00029704085682169534, Final Batch Loss: 5.338166738511063e-05\n",
      "Epoch 1204, Loss: 0.005420168134151027, Final Batch Loss: 0.00026221174630336463\n",
      "Epoch 1205, Loss: 0.005543955041503068, Final Batch Loss: 0.005501625128090382\n",
      "Epoch 1206, Loss: 0.00042487652171985246, Final Batch Loss: 4.552927930490114e-05\n",
      "Epoch 1207, Loss: 0.0014586958568543196, Final Batch Loss: 0.0007480242638848722\n",
      "Epoch 1208, Loss: 0.0008436314237769693, Final Batch Loss: 0.00015346772852353752\n",
      "Epoch 1209, Loss: 0.0019249540055170655, Final Batch Loss: 0.0004938793135806918\n",
      "Epoch 1210, Loss: 0.0010215441034233663, Final Batch Loss: 0.000973712420091033\n",
      "Epoch 1211, Loss: 0.0019686456653289497, Final Batch Loss: 0.001485929125919938\n",
      "Epoch 1212, Loss: 0.00038540566310985014, Final Batch Loss: 0.00027808157028630376\n",
      "Epoch 1213, Loss: 0.0026469871518202126, Final Batch Loss: 0.0023159408010542393\n",
      "Epoch 1214, Loss: 0.005697937100194395, Final Batch Loss: 0.0050898329354822636\n",
      "Epoch 1215, Loss: 0.0014797910989727825, Final Batch Loss: 0.0001822685298975557\n",
      "Epoch 1216, Loss: 0.0009527126530883834, Final Batch Loss: 0.0008394471951760352\n",
      "Epoch 1217, Loss: 0.0007785152702126652, Final Batch Loss: 0.0005685201031155884\n",
      "Epoch 1218, Loss: 0.0037518374156206846, Final Batch Loss: 0.00029755174182355404\n",
      "Epoch 1219, Loss: 0.0004409270331962034, Final Batch Loss: 0.0001653503131819889\n",
      "Epoch 1220, Loss: 0.0007336173002840951, Final Batch Loss: 0.000587318791076541\n",
      "Epoch 1221, Loss: 0.0005161617300473154, Final Batch Loss: 0.0002794934553094208\n",
      "Epoch 1222, Loss: 0.0005350315914256498, Final Batch Loss: 7.382997137028724e-05\n",
      "Epoch 1223, Loss: 0.010593899758532643, Final Batch Loss: 0.009899487718939781\n",
      "Epoch 1224, Loss: 0.00026243229513056576, Final Batch Loss: 0.00016649934696033597\n",
      "Epoch 1225, Loss: 0.007459235639544204, Final Batch Loss: 0.00031275421497412026\n",
      "Epoch 1226, Loss: 0.0011681144387694076, Final Batch Loss: 0.00022900641488377005\n",
      "Epoch 1227, Loss: 0.00023478684306610376, Final Batch Loss: 0.00011346495011821389\n",
      "Epoch 1228, Loss: 0.00047539715887978673, Final Batch Loss: 0.000293383258394897\n",
      "Epoch 1229, Loss: 0.0002912756863224786, Final Batch Loss: 0.0002454885106999427\n",
      "Epoch 1230, Loss: 0.00039277205360122025, Final Batch Loss: 0.00018309231381863356\n",
      "Epoch 1231, Loss: 0.00032814482983667403, Final Batch Loss: 0.00019908868125639856\n",
      "Epoch 1232, Loss: 0.0007900664932094514, Final Batch Loss: 3.270094748586416e-05\n",
      "Epoch 1233, Loss: 0.00040089951107802335, Final Batch Loss: 2.0992252757423557e-05\n",
      "Epoch 1234, Loss: 0.0010985466396959964, Final Batch Loss: 2.0874173060292378e-05\n",
      "Epoch 1235, Loss: 0.0008864158298820257, Final Batch Loss: 0.0005115472595207393\n",
      "Epoch 1236, Loss: 0.0003589557745726779, Final Batch Loss: 0.00012367204180918634\n",
      "Epoch 1237, Loss: 0.0019642158586066216, Final Batch Loss: 0.00018553013796918094\n",
      "Epoch 1238, Loss: 0.0006042949098628014, Final Batch Loss: 0.0001962044625543058\n",
      "Epoch 1239, Loss: 0.0005489913019118831, Final Batch Loss: 0.00015361620171461254\n",
      "Epoch 1240, Loss: 0.009973731124773622, Final Batch Loss: 0.006310109049081802\n",
      "Epoch 1241, Loss: 0.0007229790062410757, Final Batch Loss: 0.0005590412765741348\n",
      "Epoch 1242, Loss: 0.0011562204745132476, Final Batch Loss: 0.0008481147815473378\n",
      "Epoch 1243, Loss: 0.006769108935259283, Final Batch Loss: 0.006577212829142809\n",
      "Epoch 1244, Loss: 0.0034303979482501745, Final Batch Loss: 0.002438669092953205\n",
      "Epoch 1245, Loss: 0.0004638550308300182, Final Batch Loss: 0.00021586856746580452\n",
      "Epoch 1246, Loss: 0.000991256587440148, Final Batch Loss: 0.0004535329935606569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1247, Loss: 0.0004033672739751637, Final Batch Loss: 0.00034348739427514374\n",
      "Epoch 1248, Loss: 0.01807616651058197, Final Batch Loss: 0.00655503012239933\n",
      "Epoch 1249, Loss: 0.005686115997377783, Final Batch Loss: 0.005522077437490225\n",
      "Epoch 1250, Loss: 0.0006169872212922201, Final Batch Loss: 0.00021183765784371644\n",
      "Epoch 1251, Loss: 0.0007131101010600105, Final Batch Loss: 0.000520785222761333\n",
      "Epoch 1252, Loss: 0.004595442791469395, Final Batch Loss: 0.0027304815594106913\n",
      "Epoch 1253, Loss: 0.00019922477076761425, Final Batch Loss: 0.00015035178512334824\n",
      "Epoch 1254, Loss: 0.013393664732575417, Final Batch Loss: 0.00973628368228674\n",
      "Epoch 1255, Loss: 0.001527332467958331, Final Batch Loss: 0.0006279777735471725\n",
      "Epoch 1256, Loss: 0.004875150334555656, Final Batch Loss: 0.0009178913314826787\n",
      "Epoch 1257, Loss: 0.03024528082460165, Final Batch Loss: 0.008282014168798923\n",
      "Epoch 1258, Loss: 0.0030747931741643697, Final Batch Loss: 0.0029340190812945366\n",
      "Epoch 1259, Loss: 0.0003039392104255967, Final Batch Loss: 0.00010443464998388663\n",
      "Epoch 1260, Loss: 0.000657007381960284, Final Batch Loss: 6.149842374725267e-05\n",
      "Epoch 1261, Loss: 0.0005582274388871156, Final Batch Loss: 0.00048429242451675236\n",
      "Epoch 1262, Loss: 0.0024096317356452346, Final Batch Loss: 0.0014237945433706045\n",
      "Epoch 1263, Loss: 0.0008476619696011767, Final Batch Loss: 0.0006253932951949537\n",
      "Epoch 1264, Loss: 0.00010291647049598396, Final Batch Loss: 2.970227797050029e-05\n",
      "Epoch 1265, Loss: 0.006383130559697747, Final Batch Loss: 0.0029387352988123894\n",
      "Epoch 1266, Loss: 0.0003485134948277846, Final Batch Loss: 0.0002053588250419125\n",
      "Epoch 1267, Loss: 0.001740423667797586, Final Batch Loss: 4.689738489105366e-05\n",
      "Epoch 1268, Loss: 0.00034296579178771935, Final Batch Loss: 0.0002900037507060915\n",
      "Epoch 1269, Loss: 0.0006712384347338229, Final Batch Loss: 0.0003811802016571164\n",
      "Epoch 1270, Loss: 0.0002466798341629328, Final Batch Loss: 1.8830733097274788e-05\n",
      "Epoch 1271, Loss: 0.03058415136183612, Final Batch Loss: 0.00017190954531542957\n",
      "Epoch 1272, Loss: 0.00020859043797827326, Final Batch Loss: 5.080215851194225e-05\n",
      "Epoch 1273, Loss: 0.0006452873931266367, Final Batch Loss: 0.00040268056909553707\n",
      "Epoch 1274, Loss: 0.0004652170609915629, Final Batch Loss: 0.00029723558691330254\n",
      "Epoch 1275, Loss: 0.0008640247979201376, Final Batch Loss: 0.0005173764075152576\n",
      "Epoch 1276, Loss: 0.00991777032322716, Final Batch Loss: 0.00020654946274589747\n",
      "Epoch 1277, Loss: 0.00022953617735765874, Final Batch Loss: 0.00011745579831767827\n",
      "Epoch 1278, Loss: 0.004412773036165163, Final Batch Loss: 0.00023095772485248744\n",
      "Epoch 1279, Loss: 0.002300698368344456, Final Batch Loss: 0.0003038677969016135\n",
      "Epoch 1280, Loss: 0.004873494151979685, Final Batch Loss: 0.0005717831663787365\n",
      "Epoch 1281, Loss: 0.0014891191967763007, Final Batch Loss: 0.0006054146215319633\n",
      "Epoch 1282, Loss: 0.0007064407400321215, Final Batch Loss: 0.00041221914580091834\n",
      "Epoch 1283, Loss: 0.001104675990063697, Final Batch Loss: 0.00016689486801624298\n",
      "Epoch 1284, Loss: 0.0013257482933113351, Final Batch Loss: 0.0011251743417233229\n",
      "Epoch 1285, Loss: 0.0013109119900036603, Final Batch Loss: 0.00012002282892353833\n",
      "Epoch 1286, Loss: 0.004896618294878863, Final Batch Loss: 7.188865856733173e-05\n",
      "Epoch 1287, Loss: 0.0002015663922065869, Final Batch Loss: 0.00010929180280072615\n",
      "Epoch 1288, Loss: 0.0024605655344203115, Final Batch Loss: 0.0001305231126025319\n",
      "Epoch 1289, Loss: 0.0005603821919066831, Final Batch Loss: 0.0003591374261304736\n",
      "Epoch 1290, Loss: 0.00018881933647207916, Final Batch Loss: 7.894346344983205e-05\n",
      "Epoch 1291, Loss: 0.0001334236021648394, Final Batch Loss: 1.7891101379063912e-05\n",
      "Epoch 1292, Loss: 0.006325444170215633, Final Batch Loss: 9.42707629292272e-05\n",
      "Epoch 1293, Loss: 0.0005263993443804793, Final Batch Loss: 7.353550608968362e-05\n",
      "Epoch 1294, Loss: 0.0031698403763584793, Final Batch Loss: 0.0005484583671204746\n",
      "Epoch 1295, Loss: 0.010820327090186765, Final Batch Loss: 5.1752427680185065e-05\n",
      "Epoch 1296, Loss: 0.00017791306891012937, Final Batch Loss: 0.00010561299859546125\n",
      "Epoch 1297, Loss: 0.0003734147467184812, Final Batch Loss: 0.00018757101497612894\n",
      "Epoch 1298, Loss: 0.0006158917676657438, Final Batch Loss: 9.237753693014383e-05\n",
      "Epoch 1299, Loss: 0.0006997435848461464, Final Batch Loss: 9.073050750885159e-05\n",
      "Epoch 1300, Loss: 0.005036878690589219, Final Batch Loss: 0.0003158462350256741\n",
      "Epoch 1301, Loss: 0.0004910943243885413, Final Batch Loss: 0.0002477739180903882\n",
      "Epoch 1302, Loss: 0.00046633408055640757, Final Batch Loss: 0.000358235789462924\n",
      "Epoch 1303, Loss: 0.0002642949402797967, Final Batch Loss: 0.0001696853432804346\n",
      "Epoch 1304, Loss: 0.0001862136305135209, Final Batch Loss: 3.4442975447745994e-05\n",
      "Epoch 1305, Loss: 0.0004139988304814324, Final Batch Loss: 9.52633999986574e-05\n",
      "Epoch 1306, Loss: 0.0001445841735403519, Final Batch Loss: 8.625648479210213e-05\n",
      "Epoch 1307, Loss: 0.007268552802997874, Final Batch Loss: 5.390648220782168e-05\n",
      "Epoch 1308, Loss: 0.0004656906967284158, Final Batch Loss: 0.0001456635509384796\n",
      "Epoch 1309, Loss: 0.0007174943893915042, Final Batch Loss: 0.0005055538495071232\n",
      "Epoch 1310, Loss: 0.001433897705283016, Final Batch Loss: 0.00078060373198241\n",
      "Epoch 1311, Loss: 0.00014826791084487922, Final Batch Loss: 9.969674283638597e-05\n",
      "Epoch 1312, Loss: 0.00012860670540248975, Final Batch Loss: 4.185373109066859e-05\n",
      "Epoch 1313, Loss: 0.00017590377683518454, Final Batch Loss: 6.953939009690657e-05\n",
      "Epoch 1314, Loss: 0.000406316186854383, Final Batch Loss: 0.00035128340823575854\n",
      "Epoch 1315, Loss: 0.0010022723581641912, Final Batch Loss: 9.802787099033594e-05\n",
      "Epoch 1316, Loss: 0.00048781008808873594, Final Batch Loss: 0.0001745856716297567\n",
      "Epoch 1317, Loss: 0.001312398148002103, Final Batch Loss: 0.0009007618646137416\n",
      "Epoch 1318, Loss: 0.00039739229032420553, Final Batch Loss: 0.0003632641164585948\n",
      "Epoch 1319, Loss: 0.001778105361154303, Final Batch Loss: 6.23877567704767e-05\n",
      "Epoch 1320, Loss: 0.0006441278965212405, Final Batch Loss: 0.0002639442100189626\n",
      "Epoch 1321, Loss: 0.0034097010975528974, Final Batch Loss: 2.310324998688884e-05\n",
      "Epoch 1322, Loss: 0.0013316077020135708, Final Batch Loss: 0.0012611343991011381\n",
      "Epoch 1323, Loss: 0.0005314072768669575, Final Batch Loss: 0.00021891758660785854\n",
      "Epoch 1324, Loss: 0.003898159076925367, Final Batch Loss: 0.0035873032175004482\n",
      "Epoch 1325, Loss: 0.004522631992585957, Final Batch Loss: 0.0001434945734217763\n",
      "Epoch 1326, Loss: 0.0002456809270370286, Final Batch Loss: 4.9091348046204075e-05\n",
      "Epoch 1327, Loss: 0.00041703924944158643, Final Batch Loss: 0.00012901767331641167\n",
      "Epoch 1328, Loss: 0.00047035585157573223, Final Batch Loss: 0.0002639255835674703\n",
      "Epoch 1329, Loss: 0.000613601652730722, Final Batch Loss: 0.000595577119383961\n",
      "Epoch 1330, Loss: 0.002153115376131609, Final Batch Loss: 0.0020147538743913174\n",
      "Epoch 1331, Loss: 0.0005008272710256279, Final Batch Loss: 0.0002450304164085537\n",
      "Epoch 1332, Loss: 0.0037871262247790582, Final Batch Loss: 0.00011563424050109461\n",
      "Epoch 1333, Loss: 0.007760413471260108, Final Batch Loss: 0.0077309259213507175\n",
      "Epoch 1334, Loss: 0.0007711288053542376, Final Batch Loss: 0.0005140922148711979\n",
      "Epoch 1335, Loss: 0.002386436884989962, Final Batch Loss: 0.0021775183267891407\n",
      "Epoch 1336, Loss: 0.007604873011587188, Final Batch Loss: 0.007441762834787369\n",
      "Epoch 1337, Loss: 0.0004939478094456717, Final Batch Loss: 0.00031064561335369945\n",
      "Epoch 1338, Loss: 0.0005702855705749243, Final Batch Loss: 6.677673081867397e-05\n",
      "Epoch 1339, Loss: 0.0030495828832499683, Final Batch Loss: 0.0029782301280647516\n",
      "Epoch 1340, Loss: 0.00074258316817577, Final Batch Loss: 2.1740484953625128e-05\n",
      "Epoch 1341, Loss: 0.0004250935890013352, Final Batch Loss: 0.00027485997998155653\n",
      "Epoch 1342, Loss: 0.0058385797747178, Final Batch Loss: 0.005685020238161087\n",
      "Epoch 1343, Loss: 0.00041848126420518383, Final Batch Loss: 0.00037340912967920303\n",
      "Epoch 1344, Loss: 0.000353962772351224, Final Batch Loss: 0.0002782045630738139\n",
      "Epoch 1345, Loss: 0.0008010865858523175, Final Batch Loss: 0.0006593713187612593\n",
      "Epoch 1346, Loss: 0.002091816466418095, Final Batch Loss: 0.00020240126468706876\n",
      "Epoch 1347, Loss: 0.0002770017526927404, Final Batch Loss: 0.0002054821961792186\n",
      "Epoch 1348, Loss: 0.00021936907432973385, Final Batch Loss: 5.9891739510931075e-05\n",
      "Epoch 1349, Loss: 0.0005196386482566595, Final Batch Loss: 0.00025103476946242154\n",
      "Epoch 1350, Loss: 0.00020639733338612132, Final Batch Loss: 0.0001520592049928382\n",
      "Epoch 1351, Loss: 0.0004262403745087795, Final Batch Loss: 6.210806168382987e-05\n",
      "Epoch 1352, Loss: 0.0017858244937087875, Final Batch Loss: 0.0017706112703308463\n",
      "Epoch 1353, Loss: 0.00014133747754385695, Final Batch Loss: 6.818379188189283e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1354, Loss: 0.0030443723226198927, Final Batch Loss: 0.0028895533178001642\n",
      "Epoch 1355, Loss: 0.0010801274111145176, Final Batch Loss: 0.0010117109632119536\n",
      "Epoch 1356, Loss: 0.001095645668101497, Final Batch Loss: 0.0009799092076718807\n",
      "Epoch 1357, Loss: 0.0008924792346078902, Final Batch Loss: 0.0003086855576839298\n",
      "Epoch 1358, Loss: 0.003601664793677628, Final Batch Loss: 0.002751318272203207\n",
      "Epoch 1359, Loss: 0.00018648974946700037, Final Batch Loss: 0.00015301789971999824\n",
      "Epoch 1360, Loss: 0.001147237411714741, Final Batch Loss: 7.369710147031583e-06\n",
      "Epoch 1361, Loss: 0.001124048896599561, Final Batch Loss: 0.0005862808902747929\n",
      "Epoch 1362, Loss: 0.0005008785228710622, Final Batch Loss: 0.0003301604592707008\n",
      "Epoch 1363, Loss: 0.0008245310455095023, Final Batch Loss: 0.0006505029741674662\n",
      "Epoch 1364, Loss: 0.001255352864973247, Final Batch Loss: 0.0006329615716822445\n",
      "Epoch 1365, Loss: 0.00031540739291813225, Final Batch Loss: 0.00025334241217933595\n",
      "Epoch 1366, Loss: 0.0074018476298078895, Final Batch Loss: 0.006521332543343306\n",
      "Epoch 1367, Loss: 7.894208829384297e-05, Final Batch Loss: 3.7619349313899875e-05\n",
      "Epoch 1368, Loss: 0.007276718271896243, Final Batch Loss: 0.0010362665634602308\n",
      "Epoch 1369, Loss: 0.00037926979712210596, Final Batch Loss: 0.0001489270362071693\n",
      "Epoch 1370, Loss: 0.00403861182712717, Final Batch Loss: 0.003965915646404028\n",
      "Epoch 1371, Loss: 0.0011696841975208372, Final Batch Loss: 0.00047626093146391213\n",
      "Epoch 1372, Loss: 0.00016988207789836451, Final Batch Loss: 7.24627825547941e-05\n",
      "Epoch 1373, Loss: 0.00016909609985304996, Final Batch Loss: 7.44998105801642e-05\n",
      "Epoch 1374, Loss: 0.0033451307972427458, Final Batch Loss: 0.00013768378994427621\n",
      "Epoch 1375, Loss: 0.0027444431398180313, Final Batch Loss: 0.0001005391895887442\n",
      "Epoch 1376, Loss: 0.00031952158315107226, Final Batch Loss: 7.453089347109199e-05\n",
      "Epoch 1377, Loss: 0.00029609582270495594, Final Batch Loss: 8.073003846220672e-05\n",
      "Epoch 1378, Loss: 0.00024632542863400886, Final Batch Loss: 1.309051822317997e-05\n",
      "Epoch 1379, Loss: 0.0003669239958981052, Final Batch Loss: 0.0002241635083919391\n",
      "Epoch 1380, Loss: 0.0005384691758081317, Final Batch Loss: 0.00021693864255212247\n",
      "Epoch 1381, Loss: 0.005099148023873568, Final Batch Loss: 0.0007312977686524391\n",
      "Epoch 1382, Loss: 0.00043264508713036776, Final Batch Loss: 0.0001231627247761935\n",
      "Epoch 1383, Loss: 0.0004501534494920634, Final Batch Loss: 0.00011158893903484568\n",
      "Epoch 1384, Loss: 0.00018373447164776735, Final Batch Loss: 0.00014047394506633282\n",
      "Epoch 1385, Loss: 0.0008880266104824841, Final Batch Loss: 0.0005470341420732439\n",
      "Epoch 1386, Loss: 0.0006751741166226566, Final Batch Loss: 0.00015515898121520877\n",
      "Epoch 1387, Loss: 0.00028708054742310196, Final Batch Loss: 0.00019303616136312485\n",
      "Epoch 1388, Loss: 0.002297938335686922, Final Batch Loss: 0.0012724869884550571\n",
      "Epoch 1389, Loss: 0.00015040508878882974, Final Batch Loss: 2.0935345673933625e-05\n",
      "Epoch 1390, Loss: 0.00013329503417480737, Final Batch Loss: 2.896752266678959e-05\n",
      "Epoch 1391, Loss: 0.0019918368197977543, Final Batch Loss: 0.000977745046839118\n",
      "Epoch 1392, Loss: 4.9621554353507236e-05, Final Batch Loss: 2.215774657088332e-05\n",
      "Epoch 1393, Loss: 0.00022295173403108492, Final Batch Loss: 0.00010599066445138305\n",
      "Epoch 1394, Loss: 0.0003120400506304577, Final Batch Loss: 0.00016944471281021833\n",
      "Epoch 1395, Loss: 0.000453867090982385, Final Batch Loss: 0.0002424346748739481\n",
      "Epoch 1396, Loss: 0.00018125570932170376, Final Batch Loss: 5.9104560932610184e-05\n",
      "Epoch 1397, Loss: 0.0002027285227086395, Final Batch Loss: 6.208014383446425e-05\n",
      "Epoch 1398, Loss: 7.883897342253476e-05, Final Batch Loss: 2.417785071884282e-05\n",
      "Epoch 1399, Loss: 0.00019162968965247273, Final Batch Loss: 2.70687451120466e-05\n",
      "Epoch 1400, Loss: 0.010730501264333725, Final Batch Loss: 0.005142709705978632\n",
      "Epoch 1401, Loss: 0.00021394948271336034, Final Batch Loss: 0.00013340673467610031\n",
      "Epoch 1402, Loss: 0.0009556609147693962, Final Batch Loss: 0.00047913799062371254\n",
      "Epoch 1403, Loss: 0.0003129762699245475, Final Batch Loss: 0.00022852225811220706\n",
      "Epoch 1404, Loss: 0.0003738667583093047, Final Batch Loss: 0.00031264242716133595\n",
      "Epoch 1405, Loss: 0.00025046767041203566, Final Batch Loss: 4.2639763705665246e-05\n",
      "Epoch 1406, Loss: 9.824877997743897e-05, Final Batch Loss: 3.6676221498055384e-05\n",
      "Epoch 1407, Loss: 0.0003095187057624571, Final Batch Loss: 8.606032497482374e-05\n",
      "Epoch 1408, Loss: 0.004113469389267266, Final Batch Loss: 0.00018593447748571634\n",
      "Epoch 1409, Loss: 0.007908853003755212, Final Batch Loss: 0.00015661749057471752\n",
      "Epoch 1410, Loss: 0.00027471979774418287, Final Batch Loss: 0.00022564244864042848\n",
      "Epoch 1411, Loss: 0.0009177110914606601, Final Batch Loss: 0.0006024347967468202\n",
      "Epoch 1412, Loss: 0.00046542639029212296, Final Batch Loss: 5.462602712213993e-05\n",
      "Epoch 1413, Loss: 0.006134629773441702, Final Batch Loss: 0.005368672776967287\n",
      "Epoch 1414, Loss: 0.0004957560777256731, Final Batch Loss: 5.143467933521606e-05\n",
      "Epoch 1415, Loss: 0.0005171839138711221, Final Batch Loss: 8.442380021733698e-06\n",
      "Epoch 1416, Loss: 0.0006802382413297892, Final Batch Loss: 0.00010913197183981538\n",
      "Epoch 1417, Loss: 0.0003491779607429635, Final Batch Loss: 1.5028414054540917e-05\n",
      "Epoch 1418, Loss: 0.00037370522477431223, Final Batch Loss: 0.0002551254292484373\n",
      "Epoch 1419, Loss: 0.00013374631816986948, Final Batch Loss: 9.184782538795844e-05\n",
      "Epoch 1420, Loss: 0.0005427105206763372, Final Batch Loss: 0.0002082816936308518\n",
      "Epoch 1421, Loss: 0.0015288447903003544, Final Batch Loss: 0.00014761005877517164\n",
      "Epoch 1422, Loss: 0.00046062095498200506, Final Batch Loss: 0.0003892940003424883\n",
      "Epoch 1423, Loss: 0.0005842999671585858, Final Batch Loss: 0.00027907229377888143\n",
      "Epoch 1424, Loss: 0.00028466410003602505, Final Batch Loss: 4.712634836323559e-05\n",
      "Epoch 1425, Loss: 0.00058370380429551, Final Batch Loss: 0.000284692388959229\n",
      "Epoch 1426, Loss: 0.0003570820699678734, Final Batch Loss: 0.0002268748066853732\n",
      "Epoch 1427, Loss: 0.004971264017513022, Final Batch Loss: 0.004541516304016113\n",
      "Epoch 1428, Loss: 0.001793902789358981, Final Batch Loss: 0.00014251093671191484\n",
      "Epoch 1429, Loss: 0.0027429431975178886, Final Batch Loss: 5.629456791211851e-05\n",
      "Epoch 1430, Loss: 0.0001076494409062434, Final Batch Loss: 2.07253651751671e-05\n",
      "Epoch 1431, Loss: 0.00032758340967120603, Final Batch Loss: 0.0002642610343173146\n",
      "Epoch 1432, Loss: 0.001469207607442513, Final Batch Loss: 0.0012220701901242137\n",
      "Epoch 1433, Loss: 0.0002822357382683549, Final Batch Loss: 5.8413050282979384e-05\n",
      "Epoch 1434, Loss: 0.006135954019555356, Final Batch Loss: 0.006055786274373531\n",
      "Epoch 1435, Loss: 0.00023799672726454446, Final Batch Loss: 0.00022353051463142037\n",
      "Epoch 1436, Loss: 0.0031964613735908642, Final Batch Loss: 0.003145793918520212\n",
      "Epoch 1437, Loss: 0.0005239901365712285, Final Batch Loss: 0.0002730616251938045\n",
      "Epoch 1438, Loss: 0.004250877304002643, Final Batch Loss: 0.00038587418384850025\n",
      "Epoch 1439, Loss: 0.00021267618467391003, Final Batch Loss: 2.6480442102183588e-05\n",
      "Epoch 1440, Loss: 0.0020138788095209748, Final Batch Loss: 0.0004066492256242782\n",
      "Epoch 1441, Loss: 4.832191552850418e-05, Final Batch Loss: 2.067317473120056e-05\n",
      "Epoch 1442, Loss: 0.0030482472357107326, Final Batch Loss: 6.410297646652907e-05\n",
      "Epoch 1443, Loss: 0.0012105181522201747, Final Batch Loss: 0.00017708734958432615\n",
      "Epoch 1444, Loss: 0.0003207401132385712, Final Batch Loss: 5.19979621458333e-05\n",
      "Epoch 1445, Loss: 0.0012897203077955055, Final Batch Loss: 1.0504746569495182e-05\n",
      "Epoch 1446, Loss: 0.003537775424774736, Final Batch Loss: 0.00032450276194140315\n",
      "Epoch 1447, Loss: 0.00014134131379250903, Final Batch Loss: 1.5404382793349214e-05\n",
      "Epoch 1448, Loss: 0.00030081339355092496, Final Batch Loss: 7.028180698398501e-05\n",
      "Epoch 1449, Loss: 7.917078619357198e-05, Final Batch Loss: 9.561437764205039e-06\n",
      "Epoch 1450, Loss: 0.003290196758825914, Final Batch Loss: 2.7464115191833116e-05\n",
      "Epoch 1451, Loss: 0.0006040387015673332, Final Batch Loss: 0.0005191947566345334\n",
      "Epoch 1452, Loss: 0.000637189339613542, Final Batch Loss: 0.00038883942761458457\n",
      "Epoch 1453, Loss: 0.0008399440266657621, Final Batch Loss: 0.0002173783432226628\n",
      "Epoch 1454, Loss: 0.0006998756725806743, Final Batch Loss: 0.00042118807323276997\n",
      "Epoch 1455, Loss: 0.0025528641454002354, Final Batch Loss: 5.8948298828909174e-05\n",
      "Epoch 1456, Loss: 0.0005491116899065673, Final Batch Loss: 0.00023911960306577384\n",
      "Epoch 1457, Loss: 0.00044602628622669727, Final Batch Loss: 0.00031879733433015645\n",
      "Epoch 1458, Loss: 0.00025427476793993264, Final Batch Loss: 5.659737507812679e-05\n",
      "Epoch 1459, Loss: 0.019507857505232096, Final Batch Loss: 0.018726756796240807\n",
      "Epoch 1460, Loss: 0.0001734411926008761, Final Batch Loss: 8.781235374044627e-05\n",
      "Epoch 1461, Loss: 0.0004412898124428466, Final Batch Loss: 5.096611857879907e-05\n",
      "Epoch 1462, Loss: 0.00452589074120624, Final Batch Loss: 0.00010815512359840795\n",
      "Epoch 1463, Loss: 0.003109983925241977, Final Batch Loss: 0.0002220736932940781\n",
      "Epoch 1464, Loss: 0.0004995805065846071, Final Batch Loss: 8.39636632008478e-05\n",
      "Epoch 1465, Loss: 0.04301211272832006, Final Batch Loss: 0.042418789118528366\n",
      "Epoch 1466, Loss: 0.00045166096242610365, Final Batch Loss: 8.775705646257848e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1467, Loss: 0.00026041320961667225, Final Batch Loss: 0.0001756108831614256\n",
      "Epoch 1468, Loss: 0.00036096949042985216, Final Batch Loss: 0.00023993159993551672\n",
      "Epoch 1469, Loss: 0.0004311352386139333, Final Batch Loss: 0.0001821241166908294\n",
      "Epoch 1470, Loss: 0.00023845420582802035, Final Batch Loss: 5.768136543338187e-05\n",
      "Epoch 1471, Loss: 0.0004887442191829905, Final Batch Loss: 0.00020844234677497298\n",
      "Epoch 1472, Loss: 0.006232026731595397, Final Batch Loss: 0.005925196222960949\n",
      "Epoch 1473, Loss: 0.0070956105919322, Final Batch Loss: 0.006969637703150511\n",
      "Epoch 1474, Loss: 0.0006466382401413284, Final Batch Loss: 7.506165275117382e-05\n",
      "Epoch 1475, Loss: 0.0003249948058510199, Final Batch Loss: 0.00010401320469100028\n",
      "Epoch 1476, Loss: 0.009495237318333238, Final Batch Loss: 0.00878820475190878\n",
      "Epoch 1477, Loss: 0.0052338032983243465, Final Batch Loss: 0.0024671463761478662\n",
      "Epoch 1478, Loss: 0.0005441485409392044, Final Batch Loss: 0.00036143246688880026\n",
      "Epoch 1479, Loss: 0.01917212341504637, Final Batch Loss: 0.00015922707098070532\n",
      "Epoch 1480, Loss: 0.0001812012997106649, Final Batch Loss: 0.00010604454291751608\n",
      "Epoch 1481, Loss: 0.0010866763623198494, Final Batch Loss: 0.0009493838879279792\n",
      "Epoch 1482, Loss: 0.0001393706425005803, Final Batch Loss: 0.00011032533075194806\n",
      "Epoch 1483, Loss: 0.00015344801067840308, Final Batch Loss: 4.622665437636897e-05\n",
      "Epoch 1484, Loss: 0.0002445792370053823, Final Batch Loss: 1.4707055925100576e-05\n",
      "Epoch 1485, Loss: 0.00044235814129933715, Final Batch Loss: 0.00017162589938379824\n",
      "Epoch 1486, Loss: 0.00048216315917670727, Final Batch Loss: 0.00020140735432505608\n",
      "Epoch 1487, Loss: 0.0016111253062263131, Final Batch Loss: 0.0006429204950109124\n",
      "Epoch 1488, Loss: 0.0017932325499714352, Final Batch Loss: 4.074062599102035e-05\n",
      "Epoch 1489, Loss: 0.000177624067873694, Final Batch Loss: 7.33579508960247e-05\n",
      "Epoch 1490, Loss: 0.00012484824037528597, Final Batch Loss: 0.00010364620538894087\n",
      "Epoch 1491, Loss: 0.003222700484911911, Final Batch Loss: 0.00021008173644077033\n",
      "Epoch 1492, Loss: 0.00044033773883711547, Final Batch Loss: 2.473923086654395e-05\n",
      "Epoch 1493, Loss: 0.0012787209125235677, Final Batch Loss: 0.000758648500777781\n",
      "Epoch 1494, Loss: 0.0003803567815339193, Final Batch Loss: 0.0003026772756129503\n",
      "Epoch 1495, Loss: 0.004079603575519286, Final Batch Loss: 0.0002251628175145015\n",
      "Epoch 1496, Loss: 0.0009599757031537592, Final Batch Loss: 0.0007056585163809359\n",
      "Epoch 1497, Loss: 0.00023623707238584757, Final Batch Loss: 0.000217555119888857\n",
      "Epoch 1498, Loss: 0.00028455672145355493, Final Batch Loss: 7.887752144597471e-05\n",
      "Epoch 1499, Loss: 0.0005818268982693553, Final Batch Loss: 0.0003537312150001526\n",
      "Epoch 1500, Loss: 0.00047690833162050694, Final Batch Loss: 0.00020644573669414967\n",
      "Epoch 1501, Loss: 0.0002282778477820102, Final Batch Loss: 3.9792012103134766e-05\n",
      "Epoch 1502, Loss: 0.005908356164582074, Final Batch Loss: 0.0007643104763701558\n",
      "Epoch 1503, Loss: 0.00037242178586893715, Final Batch Loss: 4.57333262602333e-05\n",
      "Epoch 1504, Loss: 0.004484560340642929, Final Batch Loss: 0.003778682090342045\n",
      "Epoch 1505, Loss: 9.152403072221205e-05, Final Batch Loss: 2.842872345354408e-05\n",
      "Epoch 1506, Loss: 0.00017510373800178058, Final Batch Loss: 0.00011503384303068742\n",
      "Epoch 1507, Loss: 0.004703066602814943, Final Batch Loss: 0.003908831160515547\n",
      "Epoch 1508, Loss: 0.0030102823220659047, Final Batch Loss: 0.0027288536075502634\n",
      "Epoch 1509, Loss: 9.890219371300191e-05, Final Batch Loss: 2.1880565327592194e-05\n",
      "Epoch 1510, Loss: 0.0001939356698130723, Final Batch Loss: 5.295626397128217e-05\n",
      "Epoch 1511, Loss: 0.004265674113412388, Final Batch Loss: 0.0040505449287593365\n",
      "Epoch 1512, Loss: 0.0002480254988768138, Final Batch Loss: 0.00020584228332154453\n",
      "Epoch 1513, Loss: 0.0007662305433768779, Final Batch Loss: 0.0004402029444463551\n",
      "Epoch 1514, Loss: 0.0005962064024060965, Final Batch Loss: 0.00031202114769257605\n",
      "Epoch 1515, Loss: 0.0005911740881856531, Final Batch Loss: 0.0005216331337578595\n",
      "Epoch 1516, Loss: 0.0006612468569073826, Final Batch Loss: 0.00042695365846157074\n",
      "Epoch 1517, Loss: 0.00021463499069795944, Final Batch Loss: 0.00017923125415109098\n",
      "Epoch 1518, Loss: 0.0005051442094554659, Final Batch Loss: 0.0004445047816261649\n",
      "Epoch 1519, Loss: 0.00035462456798995845, Final Batch Loss: 5.991560101392679e-05\n",
      "Epoch 1520, Loss: 0.0013376720889937133, Final Batch Loss: 0.0012858463451266289\n",
      "Epoch 1521, Loss: 0.0003123198293906171, Final Batch Loss: 4.340966188465245e-05\n",
      "Epoch 1522, Loss: 0.0002086901913571637, Final Batch Loss: 4.0496695874026045e-05\n",
      "Epoch 1523, Loss: 0.00027841475457535125, Final Batch Loss: 3.8734000554541126e-05\n",
      "Epoch 1524, Loss: 0.003375733887878596, Final Batch Loss: 2.906672852986958e-05\n",
      "Epoch 1525, Loss: 0.012381936001474969, Final Batch Loss: 7.486394315492362e-05\n",
      "Epoch 1526, Loss: 0.0006953617812541779, Final Batch Loss: 5.66622729820665e-05\n",
      "Epoch 1527, Loss: 0.00039971600199351087, Final Batch Loss: 0.00011349929991411045\n",
      "Epoch 1528, Loss: 9.216987018589862e-05, Final Batch Loss: 6.1474071117118e-05\n",
      "Epoch 1529, Loss: 0.00046687798749189824, Final Batch Loss: 7.635624206159264e-05\n",
      "Epoch 1530, Loss: 0.00019646815781015903, Final Batch Loss: 0.00011390380677767098\n",
      "Epoch 1531, Loss: 0.001875676607596688, Final Batch Loss: 0.00014760011981707066\n",
      "Epoch 1532, Loss: 0.0005208686925470829, Final Batch Loss: 0.0002811619488056749\n",
      "Epoch 1533, Loss: 0.00039505356835434213, Final Batch Loss: 0.0002914617070928216\n",
      "Epoch 1534, Loss: 0.00024640462652314454, Final Batch Loss: 0.00014965231821406633\n",
      "Epoch 1535, Loss: 0.0025488634855719283, Final Batch Loss: 0.0002287585084559396\n",
      "Epoch 1536, Loss: 0.0011524506262503564, Final Batch Loss: 0.00028342887526378036\n",
      "Epoch 1537, Loss: 0.00026947052356263157, Final Batch Loss: 2.7998778023174964e-05\n",
      "Epoch 1538, Loss: 5.5738904848112725e-05, Final Batch Loss: 2.7029940611100756e-05\n",
      "Epoch 1539, Loss: 0.00043268237641314045, Final Batch Loss: 0.00036808312870562077\n",
      "Epoch 1540, Loss: 0.0010461045894771814, Final Batch Loss: 0.0005582926678471267\n",
      "Epoch 1541, Loss: 0.00040556972817284986, Final Batch Loss: 0.00029713925323449075\n",
      "Epoch 1542, Loss: 0.0013505645329132676, Final Batch Loss: 0.000753306201659143\n",
      "Epoch 1543, Loss: 0.01752103352919221, Final Batch Loss: 0.015317228622734547\n",
      "Epoch 1544, Loss: 0.00017947225387615617, Final Batch Loss: 2.88133214780828e-05\n",
      "Epoch 1545, Loss: 0.00021474540335475467, Final Batch Loss: 4.589973468682729e-05\n",
      "Epoch 1546, Loss: 0.0026534505595918745, Final Batch Loss: 7.262764847837389e-05\n",
      "Epoch 1547, Loss: 0.0005466446164064109, Final Batch Loss: 7.944845128804445e-05\n",
      "Epoch 1548, Loss: 0.00033966828777920455, Final Batch Loss: 9.480251173954457e-05\n",
      "Epoch 1549, Loss: 0.0008079465769696981, Final Batch Loss: 0.00046369200572371483\n",
      "Epoch 1550, Loss: 0.006172861700179055, Final Batch Loss: 0.00013964090612716973\n",
      "Epoch 1551, Loss: 0.00013736787150264718, Final Batch Loss: 4.118183642276563e-05\n",
      "Epoch 1552, Loss: 0.0034479903988540173, Final Batch Loss: 0.00092170643620193\n",
      "Epoch 1553, Loss: 0.00026242126477882266, Final Batch Loss: 0.00010791340901050717\n",
      "Epoch 1554, Loss: 0.0011253378324909136, Final Batch Loss: 0.0009679890354163945\n",
      "Epoch 1555, Loss: 0.00031555671739624813, Final Batch Loss: 4.940530197927728e-05\n",
      "Epoch 1556, Loss: 0.0005837366334162652, Final Batch Loss: 0.00026302289916202426\n",
      "Epoch 1557, Loss: 0.0003566729574231431, Final Batch Loss: 0.00012803732533939183\n",
      "Epoch 1558, Loss: 0.0001930102807818912, Final Batch Loss: 0.00010737854609033093\n",
      "Epoch 1559, Loss: 0.002067531240754761, Final Batch Loss: 0.0018386805895715952\n",
      "Epoch 1560, Loss: 0.0016210832400247455, Final Batch Loss: 0.0006921389140188694\n",
      "Epoch 1561, Loss: 0.0002657057557371445, Final Batch Loss: 4.8759982746560127e-05\n",
      "Epoch 1562, Loss: 0.0004749455547425896, Final Batch Loss: 0.0001845381921157241\n",
      "Epoch 1563, Loss: 0.00043232210737187415, Final Batch Loss: 6.175284215714782e-05\n",
      "Epoch 1564, Loss: 0.0005966179451206699, Final Batch Loss: 0.0005167697672732174\n",
      "Epoch 1565, Loss: 0.0001823609090934042, Final Batch Loss: 3.1438121368410066e-05\n",
      "Epoch 1566, Loss: 0.0007034214504528791, Final Batch Loss: 0.0003086972574237734\n",
      "Epoch 1567, Loss: 0.000515759049449116, Final Batch Loss: 0.00033167036599479616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1568, Loss: 0.00014122070570010692, Final Batch Loss: 9.838897676672786e-05\n",
      "Epoch 1569, Loss: 0.007619649870321155, Final Batch Loss: 0.003699314082041383\n",
      "Epoch 1570, Loss: 0.0006441143050324172, Final Batch Loss: 0.0002792265440803021\n",
      "Epoch 1571, Loss: 0.01524165875161998, Final Batch Loss: 0.0002008764713536948\n",
      "Epoch 1572, Loss: 0.00022637753863818944, Final Batch Loss: 0.00012246266123838723\n",
      "Epoch 1573, Loss: 0.00034946706728078425, Final Batch Loss: 0.00011943755089305341\n",
      "Epoch 1574, Loss: 0.0004931528455927037, Final Batch Loss: 0.00042558705899864435\n",
      "Epoch 1575, Loss: 0.0037479424063349143, Final Batch Loss: 4.8929607146419585e-05\n",
      "Epoch 1576, Loss: 0.00027374470300856046, Final Batch Loss: 0.0002149506181012839\n",
      "Epoch 1577, Loss: 0.0006380126142175868, Final Batch Loss: 0.0004912556614726782\n",
      "Epoch 1578, Loss: 0.0005187468232179526, Final Batch Loss: 4.2878560634562746e-05\n",
      "Epoch 1579, Loss: 0.023483838187530637, Final Batch Loss: 0.022162528708577156\n",
      "Epoch 1580, Loss: 0.0013668303727172315, Final Batch Loss: 9.357422823086381e-05\n",
      "Epoch 1581, Loss: 0.005975723193841986, Final Batch Loss: 9.782325651030988e-05\n",
      "Epoch 1582, Loss: 0.0002576118422439322, Final Batch Loss: 9.821174899116158e-05\n",
      "Epoch 1583, Loss: 0.0001672852158662863, Final Batch Loss: 8.827044803183526e-05\n",
      "Epoch 1584, Loss: 0.006573481710802298, Final Batch Loss: 0.00648429524153471\n",
      "Epoch 1585, Loss: 0.00024464528542011976, Final Batch Loss: 9.45352076087147e-05\n",
      "Epoch 1586, Loss: 0.0036046399764018133, Final Batch Loss: 0.0035022692754864693\n",
      "Epoch 1587, Loss: 0.0004733920650323853, Final Batch Loss: 0.00026801222702488303\n",
      "Epoch 1588, Loss: 0.0002433957633911632, Final Batch Loss: 0.00010743259190348908\n",
      "Epoch 1589, Loss: 0.0008247962250607088, Final Batch Loss: 0.0007886664243414998\n",
      "Epoch 1590, Loss: 0.003831603389699012, Final Batch Loss: 0.003177560633048415\n",
      "Epoch 1591, Loss: 0.0008269190439023077, Final Batch Loss: 0.0005002706893719733\n",
      "Epoch 1592, Loss: 0.00026870052533922717, Final Batch Loss: 5.879540549358353e-05\n",
      "Epoch 1593, Loss: 0.00016856699949130416, Final Batch Loss: 7.173784979386255e-05\n",
      "Epoch 1594, Loss: 0.0004871330893365666, Final Batch Loss: 0.0003102714545093477\n",
      "Epoch 1595, Loss: 0.0006055680714780465, Final Batch Loss: 0.0004260789428371936\n",
      "Epoch 1596, Loss: 0.00022901211923453957, Final Batch Loss: 7.74293439462781e-05\n",
      "Epoch 1597, Loss: 0.007591083412989974, Final Batch Loss: 0.0035023766104131937\n",
      "Epoch 1598, Loss: 0.0006793003412894905, Final Batch Loss: 0.000256121507845819\n",
      "Epoch 1599, Loss: 0.006939300306839868, Final Batch Loss: 0.0001358645677100867\n",
      "Epoch 1600, Loss: 0.00028013100381940603, Final Batch Loss: 0.00016039337788242847\n",
      "Epoch 1601, Loss: 0.00018410527263768017, Final Batch Loss: 4.7028122935444117e-05\n",
      "Epoch 1602, Loss: 0.00013561410742113367, Final Batch Loss: 0.00010532562737353146\n",
      "Epoch 1603, Loss: 0.0007260742568178102, Final Batch Loss: 0.00018443782755639404\n",
      "Epoch 1604, Loss: 0.0008209547959268093, Final Batch Loss: 0.000675092451274395\n",
      "Epoch 1605, Loss: 0.0002473286976965028, Final Batch Loss: 1.1431485290813725e-05\n",
      "Epoch 1606, Loss: 0.000412190129281953, Final Batch Loss: 0.0002229765959782526\n",
      "Epoch 1607, Loss: 0.0008414670301135629, Final Batch Loss: 9.140864131040871e-05\n",
      "Epoch 1608, Loss: 0.0004961871018167585, Final Batch Loss: 0.0001741854357533157\n",
      "Epoch 1609, Loss: 0.000294400415441487, Final Batch Loss: 7.279671990545467e-05\n",
      "Epoch 1610, Loss: 0.00036977526542614214, Final Batch Loss: 0.000328764203004539\n",
      "Epoch 1611, Loss: 0.00015973387053236365, Final Batch Loss: 8.139566489262506e-05\n",
      "Epoch 1612, Loss: 0.0004935349134029821, Final Batch Loss: 0.0003114631399512291\n",
      "Epoch 1613, Loss: 0.0002503935138520319, Final Batch Loss: 0.0002014013152802363\n",
      "Epoch 1614, Loss: 0.00018988710871781223, Final Batch Loss: 0.00015763152623549104\n",
      "Epoch 1615, Loss: 0.007879832468461245, Final Batch Loss: 0.007723966613411903\n",
      "Epoch 1616, Loss: 0.00021052006195532158, Final Batch Loss: 0.00011951701890211552\n",
      "Epoch 1617, Loss: 0.001084242707293015, Final Batch Loss: 0.00011997034744126722\n",
      "Epoch 1618, Loss: 0.008098544567474164, Final Batch Loss: 7.889048720244318e-05\n",
      "Epoch 1619, Loss: 0.007507404374337057, Final Batch Loss: 3.806647509918548e-05\n",
      "Epoch 1620, Loss: 0.003335505723953247, Final Batch Loss: 0.0031345293391495943\n",
      "Epoch 1621, Loss: 0.0001492931041866541, Final Batch Loss: 4.391297261463478e-05\n",
      "Epoch 1622, Loss: 0.002683246071683243, Final Batch Loss: 0.00023933433112688363\n",
      "Epoch 1623, Loss: 0.00020136941748205572, Final Batch Loss: 0.00012047628115396947\n",
      "Epoch 1624, Loss: 0.0009888545610010624, Final Batch Loss: 0.0007967045530676842\n",
      "Epoch 1625, Loss: 0.0002594521065475419, Final Batch Loss: 3.2519790693186224e-05\n",
      "Epoch 1626, Loss: 0.014872291270876303, Final Batch Loss: 0.0002365178952459246\n",
      "Epoch 1627, Loss: 0.0005406531563494354, Final Batch Loss: 0.0003627271798904985\n",
      "Epoch 1628, Loss: 0.0003391555292182602, Final Batch Loss: 0.00011442168761277571\n",
      "Epoch 1629, Loss: 0.0030910710484022275, Final Batch Loss: 0.00018950087542179972\n",
      "Epoch 1630, Loss: 0.0034510568402765784, Final Batch Loss: 0.0034258817322552204\n",
      "Epoch 1631, Loss: 0.0005643241165671498, Final Batch Loss: 0.0002999769931193441\n",
      "Epoch 1632, Loss: 0.0006783287390135229, Final Batch Loss: 0.00043247052235528827\n",
      "Epoch 1633, Loss: 0.0011463781411293894, Final Batch Loss: 0.00045197541476227343\n",
      "Epoch 1634, Loss: 0.00028453205595724285, Final Batch Loss: 0.00016041375056374818\n",
      "Epoch 1635, Loss: 0.0032609888585284352, Final Batch Loss: 0.0018113370751962066\n",
      "Epoch 1636, Loss: 0.0008992666407721117, Final Batch Loss: 0.0001347889337921515\n",
      "Epoch 1637, Loss: 0.0007601095421705395, Final Batch Loss: 0.00029897308559156954\n",
      "Epoch 1638, Loss: 0.00023042744578560814, Final Batch Loss: 9.589004184817895e-05\n",
      "Epoch 1639, Loss: 0.0008061631378950551, Final Batch Loss: 2.8256341465748847e-05\n",
      "Epoch 1640, Loss: 0.0007899343909230083, Final Batch Loss: 0.0005192881799302995\n",
      "Epoch 1641, Loss: 0.0006309411401161924, Final Batch Loss: 0.00013746928016189486\n",
      "Epoch 1642, Loss: 0.0004733137975563295, Final Batch Loss: 0.0003564158396329731\n",
      "Epoch 1643, Loss: 0.004577495725243352, Final Batch Loss: 0.004447105806320906\n",
      "Epoch 1644, Loss: 0.0002878029044950381, Final Batch Loss: 8.05762829259038e-05\n",
      "Epoch 1645, Loss: 0.005080340226413682, Final Batch Loss: 0.004933818243443966\n",
      "Epoch 1646, Loss: 0.003973957573180087, Final Batch Loss: 0.0038407782558351755\n",
      "Epoch 1647, Loss: 0.0005765063688158989, Final Batch Loss: 0.00029929468291811645\n",
      "Epoch 1648, Loss: 0.00013560623119701631, Final Batch Loss: 5.323216100805439e-05\n",
      "Epoch 1649, Loss: 0.0010888583201449364, Final Batch Loss: 0.0007930417195893824\n",
      "Epoch 1650, Loss: 0.007268442977874656, Final Batch Loss: 2.3169648557086475e-05\n",
      "Epoch 1651, Loss: 0.00029880144575145096, Final Batch Loss: 0.0001702701993053779\n",
      "Epoch 1652, Loss: 0.0003244487270421814, Final Batch Loss: 3.7587549741147086e-05\n",
      "Epoch 1653, Loss: 0.003870890097459778, Final Batch Loss: 0.0002679737226571888\n",
      "Epoch 1654, Loss: 0.00016378735017497092, Final Batch Loss: 6.290918827289715e-05\n",
      "Epoch 1655, Loss: 0.00015050070578581654, Final Batch Loss: 5.4040512623032555e-05\n",
      "Epoch 1656, Loss: 0.00048281332419719547, Final Batch Loss: 0.0002677445882000029\n",
      "Epoch 1657, Loss: 0.0003171445496263914, Final Batch Loss: 0.0002439822710584849\n",
      "Epoch 1658, Loss: 0.0035157965703547234, Final Batch Loss: 2.9199125492596067e-05\n",
      "Epoch 1659, Loss: 0.0005812319141114131, Final Batch Loss: 0.00013646438310388476\n",
      "Epoch 1660, Loss: 0.010352898621931672, Final Batch Loss: 0.0011196436826139688\n",
      "Epoch 1661, Loss: 0.0025740866258274764, Final Batch Loss: 0.00013032203423790634\n",
      "Epoch 1662, Loss: 0.0002589033938420471, Final Batch Loss: 4.716553303296678e-05\n",
      "Epoch 1663, Loss: 0.00030461295682471246, Final Batch Loss: 7.981150702107698e-05\n",
      "Epoch 1664, Loss: 0.0015110164167708717, Final Batch Loss: 0.0001083236638805829\n",
      "Epoch 1665, Loss: 0.0005593442911049351, Final Batch Loss: 0.0005315879243426025\n",
      "Epoch 1666, Loss: 0.00039674100116826594, Final Batch Loss: 0.00017502318951301277\n",
      "Epoch 1667, Loss: 0.0006725155690219253, Final Batch Loss: 0.0003292883047834039\n",
      "Epoch 1668, Loss: 0.0044173280912218615, Final Batch Loss: 0.004223775118589401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1669, Loss: 0.00023954559219419025, Final Batch Loss: 0.00019205454736948013\n",
      "Epoch 1670, Loss: 0.00011945189908146858, Final Batch Loss: 2.8607944841496646e-05\n",
      "Epoch 1671, Loss: 0.0003336518566356972, Final Batch Loss: 8.191690722014755e-05\n",
      "Epoch 1672, Loss: 0.00030700842035003006, Final Batch Loss: 0.0001279451826121658\n",
      "Epoch 1673, Loss: 0.00021051560179330409, Final Batch Loss: 0.00012203490769024938\n",
      "Epoch 1674, Loss: 0.0004178907547611743, Final Batch Loss: 9.589677210897207e-05\n",
      "Epoch 1675, Loss: 4.196159261482535e-05, Final Batch Loss: 1.2348825293884147e-05\n",
      "Epoch 1676, Loss: 0.00039491214920417406, Final Batch Loss: 3.9821785321692005e-05\n",
      "Epoch 1677, Loss: 0.0003062747127842158, Final Batch Loss: 0.00017266377108171582\n",
      "Epoch 1678, Loss: 0.0001386365147482138, Final Batch Loss: 4.3962416384601966e-05\n",
      "Epoch 1679, Loss: 0.00026825508393812925, Final Batch Loss: 0.00011734569852706045\n",
      "Epoch 1680, Loss: 0.00025414709307369776, Final Batch Loss: 4.672218710766174e-05\n",
      "Epoch 1681, Loss: 0.00043413459206931293, Final Batch Loss: 0.00014271953841671348\n",
      "Epoch 1682, Loss: 0.0018980388558702543, Final Batch Loss: 0.0017587150214239955\n",
      "Epoch 1683, Loss: 0.01340723579050973, Final Batch Loss: 0.013066234067082405\n",
      "Epoch 1684, Loss: 0.0009236310143023729, Final Batch Loss: 0.0008623489993624389\n",
      "Epoch 1685, Loss: 0.0002789399859466357, Final Batch Loss: 0.0002618441649246961\n",
      "Epoch 1686, Loss: 0.010987964909872971, Final Batch Loss: 0.0001818979944800958\n",
      "Epoch 1687, Loss: 0.00043931728578172624, Final Batch Loss: 0.0003415538230910897\n",
      "Epoch 1688, Loss: 0.005687003373168409, Final Batch Loss: 0.0055513205006718636\n",
      "Epoch 1689, Loss: 0.0006411025096895173, Final Batch Loss: 0.00040618801722303033\n",
      "Epoch 1690, Loss: 0.006704379833536223, Final Batch Loss: 0.000334834709065035\n",
      "Epoch 1691, Loss: 0.0006398064433597028, Final Batch Loss: 0.0003191263531334698\n",
      "Epoch 1692, Loss: 0.00027365840651327744, Final Batch Loss: 0.00010551085142651573\n",
      "Epoch 1693, Loss: 0.0005162367888260633, Final Batch Loss: 0.00015199891640804708\n",
      "Epoch 1694, Loss: 0.00031451196991838515, Final Batch Loss: 7.018967880867422e-05\n",
      "Epoch 1695, Loss: 8.197542410925962e-05, Final Batch Loss: 3.702928006532602e-05\n",
      "Epoch 1696, Loss: 0.003057339708902873, Final Batch Loss: 0.00022856333816889673\n",
      "Epoch 1697, Loss: 0.0006358499558700714, Final Batch Loss: 5.735195372835733e-05\n",
      "Epoch 1698, Loss: 0.005494236291269772, Final Batch Loss: 0.005349691025912762\n",
      "Epoch 1699, Loss: 0.0004996081333956681, Final Batch Loss: 4.819226887775585e-05\n",
      "Epoch 1700, Loss: 0.004434562113601714, Final Batch Loss: 0.0004660755512304604\n",
      "Epoch 1701, Loss: 0.0007252860887092538, Final Batch Loss: 0.0006353970384225249\n",
      "Epoch 1702, Loss: 0.0001582243166922126, Final Batch Loss: 3.976927473559044e-05\n",
      "Epoch 1703, Loss: 0.00018271221779286861, Final Batch Loss: 9.210134885506704e-05\n",
      "Epoch 1704, Loss: 0.0015293745091184974, Final Batch Loss: 0.0012452688533812761\n",
      "Epoch 1705, Loss: 0.003354434680659324, Final Batch Loss: 0.000903651409316808\n",
      "Epoch 1706, Loss: 0.0009076605711015873, Final Batch Loss: 0.0008140191785059869\n",
      "Epoch 1707, Loss: 0.011323100954541587, Final Batch Loss: 2.1286376068019308e-05\n",
      "Epoch 1708, Loss: 0.0005310333654051647, Final Batch Loss: 6.189766281750053e-05\n",
      "Epoch 1709, Loss: 0.0007004338112892583, Final Batch Loss: 0.00019834413251373917\n",
      "Epoch 1710, Loss: 0.0005873395493836142, Final Batch Loss: 4.280222492525354e-05\n",
      "Epoch 1711, Loss: 0.031185118481516838, Final Batch Loss: 0.009443173184990883\n",
      "Epoch 1712, Loss: 0.003618702059611678, Final Batch Loss: 0.0005784656386822462\n",
      "Epoch 1713, Loss: 0.000555725913727656, Final Batch Loss: 0.00027793325716629624\n",
      "Epoch 1714, Loss: 0.0002240190005977638, Final Batch Loss: 4.382523911772296e-05\n",
      "Epoch 1715, Loss: 0.00018802322847477626, Final Batch Loss: 2.9576285669463687e-05\n",
      "Epoch 1716, Loss: 0.00046327715972438455, Final Batch Loss: 0.00020055926870554686\n",
      "Epoch 1717, Loss: 0.00018059897411148995, Final Batch Loss: 8.246117795351893e-05\n",
      "Epoch 1718, Loss: 0.005265283049084246, Final Batch Loss: 0.0036986973136663437\n",
      "Epoch 1719, Loss: 0.005893750756513327, Final Batch Loss: 0.00036472425563260913\n",
      "Epoch 1720, Loss: 0.0006917377904755995, Final Batch Loss: 0.00012808280007448047\n",
      "Epoch 1721, Loss: 0.0010824029450304806, Final Batch Loss: 0.0008829791331663728\n",
      "Epoch 1722, Loss: 0.0005654876003973186, Final Batch Loss: 0.00036534297396428883\n",
      "Epoch 1723, Loss: 0.004027924849651754, Final Batch Loss: 0.00011546153109520674\n",
      "Epoch 1724, Loss: 0.00023257781685970258, Final Batch Loss: 2.810775004036259e-05\n",
      "Epoch 1725, Loss: 0.0005235237404122017, Final Batch Loss: 4.819590685656294e-05\n",
      "Epoch 1726, Loss: 0.000509115430759266, Final Batch Loss: 0.00021168490638956428\n",
      "Epoch 1727, Loss: 0.0063848728823359124, Final Batch Loss: 5.2632349252235144e-05\n",
      "Epoch 1728, Loss: 0.006663655178272165, Final Batch Loss: 0.0064735691994428635\n",
      "Epoch 1729, Loss: 0.00010795235721161589, Final Batch Loss: 2.4236134777311236e-05\n",
      "Epoch 1730, Loss: 0.0004903518274659291, Final Batch Loss: 0.00014837206981610507\n",
      "Epoch 1731, Loss: 0.0015385864899144508, Final Batch Loss: 7.260373240569606e-05\n",
      "Epoch 1732, Loss: 0.00025499029288766906, Final Batch Loss: 0.00018469565839041024\n",
      "Epoch 1733, Loss: 0.002440568554447964, Final Batch Loss: 0.00020537039381451905\n",
      "Epoch 1734, Loss: 0.00023610261268913746, Final Batch Loss: 0.00017002628010232002\n",
      "Epoch 1735, Loss: 0.00021023552835686132, Final Batch Loss: 0.00010245256271446124\n",
      "Epoch 1736, Loss: 0.002501500479411334, Final Batch Loss: 0.0016635969514027238\n",
      "Epoch 1737, Loss: 0.00018617419118527323, Final Batch Loss: 3.496707358863205e-05\n",
      "Epoch 1738, Loss: 0.00704115821281448, Final Batch Loss: 0.006859018001705408\n",
      "Epoch 1739, Loss: 0.0002787632547551766, Final Batch Loss: 0.0001528152934042737\n",
      "Epoch 1740, Loss: 0.00036732775333803147, Final Batch Loss: 9.355517977382988e-05\n",
      "Epoch 1741, Loss: 0.00024459971609758213, Final Batch Loss: 6.509556988021359e-05\n",
      "Epoch 1742, Loss: 0.0226957189879613, Final Batch Loss: 0.022468017414212227\n",
      "Epoch 1743, Loss: 0.0004658405086956918, Final Batch Loss: 0.00028107408434152603\n",
      "Epoch 1744, Loss: 0.00013416075307759456, Final Batch Loss: 8.792141306912526e-05\n",
      "Epoch 1745, Loss: 0.00515103738871403, Final Batch Loss: 0.00507038040086627\n",
      "Epoch 1746, Loss: 0.0001876888345577754, Final Batch Loss: 9.906107152346522e-05\n",
      "Epoch 1747, Loss: 0.009101863484829664, Final Batch Loss: 0.005886668339371681\n",
      "Epoch 1748, Loss: 0.0006479599396698177, Final Batch Loss: 0.0002592169912531972\n",
      "Epoch 1749, Loss: 0.007290417415788397, Final Batch Loss: 0.0003777841047849506\n",
      "Epoch 1750, Loss: 0.0003302765944681596, Final Batch Loss: 3.9013026253087446e-05\n",
      "Epoch 1751, Loss: 0.0014660771121270955, Final Batch Loss: 0.001064546057023108\n",
      "Epoch 1752, Loss: 0.02359285793500021, Final Batch Loss: 0.02331988327205181\n",
      "Epoch 1753, Loss: 0.0005423825059551746, Final Batch Loss: 0.0002802293165586889\n",
      "Epoch 1754, Loss: 0.001003973768092692, Final Batch Loss: 0.00028567644767463207\n",
      "Epoch 1755, Loss: 0.000981559365754947, Final Batch Loss: 0.0005635821144096553\n",
      "Epoch 1756, Loss: 0.0002670140893314965, Final Batch Loss: 0.00010288623889209703\n",
      "Epoch 1757, Loss: 0.0009795886871870607, Final Batch Loss: 0.0002462622069288045\n",
      "Epoch 1758, Loss: 0.002235199266579002, Final Batch Loss: 0.0019874190911650658\n",
      "Epoch 1759, Loss: 0.0006844911258667707, Final Batch Loss: 0.00042638214654289186\n",
      "Epoch 1760, Loss: 0.011597103672102094, Final Batch Loss: 0.010933700948953629\n",
      "Epoch 1761, Loss: 0.0004066254186909646, Final Batch Loss: 0.00016575846530031413\n",
      "Epoch 1762, Loss: 0.005403508024755865, Final Batch Loss: 0.000727890117559582\n",
      "Epoch 1763, Loss: 0.000553094781935215, Final Batch Loss: 0.0004147636063862592\n",
      "Epoch 1764, Loss: 0.0007979505753610283, Final Batch Loss: 0.0003326394653413445\n",
      "Epoch 1765, Loss: 0.0001997981744352728, Final Batch Loss: 0.0001277240226045251\n",
      "Epoch 1766, Loss: 0.0005529591871891171, Final Batch Loss: 0.00033999502193182707\n",
      "Epoch 1767, Loss: 0.00033203801285708323, Final Batch Loss: 0.00025746988831087947\n",
      "Epoch 1768, Loss: 0.0016826589890115429, Final Batch Loss: 5.5849279306130484e-05\n",
      "Epoch 1769, Loss: 0.00927362388028996, Final Batch Loss: 0.00922453310340643\n",
      "Epoch 1770, Loss: 0.00020512968330876902, Final Batch Loss: 0.00013109741848893464\n",
      "Epoch 1771, Loss: 0.0012169593246653676, Final Batch Loss: 0.0008749118424020708\n",
      "Epoch 1772, Loss: 7.3027938924497e-05, Final Batch Loss: 4.251406426192261e-05\n",
      "Epoch 1773, Loss: 0.0004380037426017225, Final Batch Loss: 3.714262857101858e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1774, Loss: 0.0008244843629654497, Final Batch Loss: 0.00016980056534521282\n",
      "Epoch 1775, Loss: 0.00717591680586338, Final Batch Loss: 0.0015035797841846943\n",
      "Epoch 1776, Loss: 0.00020188065900583751, Final Batch Loss: 4.924333552480675e-05\n",
      "Epoch 1777, Loss: 0.000632044582744129, Final Batch Loss: 8.610561781097203e-05\n",
      "Epoch 1778, Loss: 0.0003907185819116421, Final Batch Loss: 0.0003152833378408104\n",
      "Epoch 1779, Loss: 0.0007346591737587005, Final Batch Loss: 0.000441718875663355\n",
      "Epoch 1780, Loss: 0.0005710120603907853, Final Batch Loss: 0.00023008519201539457\n",
      "Epoch 1781, Loss: 0.0008471277687931433, Final Batch Loss: 0.000722491939086467\n",
      "Epoch 1782, Loss: 0.003431920394177723, Final Batch Loss: 1.234627688972978e-05\n",
      "Epoch 1783, Loss: 0.0012172776914667338, Final Batch Loss: 0.0010611197212710977\n",
      "Epoch 1784, Loss: 9.42924634728115e-05, Final Batch Loss: 2.7265155949862674e-05\n",
      "Epoch 1785, Loss: 0.000408358100685291, Final Batch Loss: 0.0001602052798261866\n",
      "Epoch 1786, Loss: 0.0006426387772080489, Final Batch Loss: 3.399392153369263e-05\n",
      "Epoch 1787, Loss: 0.00045955542009323835, Final Batch Loss: 0.0001729231735225767\n",
      "Epoch 1788, Loss: 0.0011512758792378008, Final Batch Loss: 0.0005031351465731859\n",
      "Epoch 1789, Loss: 0.0015821040178707335, Final Batch Loss: 6.044248948455788e-05\n",
      "Epoch 1790, Loss: 0.0002659688107087277, Final Batch Loss: 4.914690362056717e-05\n",
      "Epoch 1791, Loss: 0.0008294831641251221, Final Batch Loss: 0.00023455255723092705\n",
      "Epoch 1792, Loss: 0.0005497591919265687, Final Batch Loss: 6.65367697365582e-05\n",
      "Epoch 1793, Loss: 0.00029230179643491283, Final Batch Loss: 8.27905532787554e-05\n",
      "Epoch 1794, Loss: 0.0005448651645565405, Final Batch Loss: 0.0003769861359614879\n",
      "Epoch 1795, Loss: 0.0002418978874629829, Final Batch Loss: 0.00020902391406707466\n",
      "Epoch 1796, Loss: 0.00574019574560225, Final Batch Loss: 0.0006876250263303518\n",
      "Epoch 1797, Loss: 0.001563974132295698, Final Batch Loss: 0.0010290851350873709\n",
      "Epoch 1798, Loss: 7.163500595197547e-05, Final Batch Loss: 1.7333573850919493e-05\n",
      "Epoch 1799, Loss: 0.0005775822137366049, Final Batch Loss: 0.000491588085424155\n",
      "Epoch 1800, Loss: 0.0031163367530098185, Final Batch Loss: 2.5460831238888204e-05\n",
      "Epoch 1801, Loss: 0.0003018325696757529, Final Batch Loss: 3.4599248465383425e-05\n",
      "Epoch 1802, Loss: 0.0002513220861146692, Final Batch Loss: 5.143380622030236e-05\n",
      "Epoch 1803, Loss: 0.0002340518549317494, Final Batch Loss: 0.0001500391954323277\n",
      "Epoch 1804, Loss: 0.00048367222188971937, Final Batch Loss: 0.00029393337899819016\n",
      "Epoch 1805, Loss: 0.00010804128032759763, Final Batch Loss: 7.511145668104291e-05\n",
      "Epoch 1806, Loss: 8.197626448236406e-05, Final Batch Loss: 1.7609701899345964e-05\n",
      "Epoch 1807, Loss: 0.0006203062948770821, Final Batch Loss: 0.00047306035412475467\n",
      "Epoch 1808, Loss: 0.002116154704708606, Final Batch Loss: 0.0016243727877736092\n",
      "Epoch 1809, Loss: 0.0002915443619713187, Final Batch Loss: 4.779640585184097e-05\n",
      "Epoch 1810, Loss: 0.00083288974565221, Final Batch Loss: 9.72277412074618e-05\n",
      "Epoch 1811, Loss: 0.002289157571794931, Final Batch Loss: 0.00011517990060383454\n",
      "Epoch 1812, Loss: 0.004193385364487767, Final Batch Loss: 0.003895500907674432\n",
      "Epoch 1813, Loss: 0.0002764485980151221, Final Batch Loss: 0.00023633966338820755\n",
      "Epoch 1814, Loss: 0.0001960693480214104, Final Batch Loss: 0.0001224343868670985\n",
      "Epoch 1815, Loss: 0.00015075935516506433, Final Batch Loss: 4.206703306408599e-05\n",
      "Epoch 1816, Loss: 0.00013724487871513702, Final Batch Loss: 1.3047745596850291e-05\n",
      "Epoch 1817, Loss: 0.00028910126275150105, Final Batch Loss: 0.0001204434156534262\n",
      "Epoch 1818, Loss: 0.0007160247187130153, Final Batch Loss: 0.00024210411356762052\n",
      "Epoch 1819, Loss: 0.0053048721310915425, Final Batch Loss: 0.005170060787349939\n",
      "Epoch 1820, Loss: 0.00041042518023459706, Final Batch Loss: 0.0003902476164512336\n",
      "Epoch 1821, Loss: 0.0004879963234998286, Final Batch Loss: 0.00023417017655447125\n",
      "Epoch 1822, Loss: 0.0003703251568367705, Final Batch Loss: 0.0001399343746015802\n",
      "Epoch 1823, Loss: 0.0002113424488925375, Final Batch Loss: 0.00013504580419976264\n",
      "Epoch 1824, Loss: 0.002376181277213618, Final Batch Loss: 0.0002591455995570868\n",
      "Epoch 1825, Loss: 4.95881395181641e-05, Final Batch Loss: 3.98224510718137e-05\n",
      "Epoch 1826, Loss: 0.0019068196415901184, Final Batch Loss: 0.0011818928178399801\n",
      "Epoch 1827, Loss: 0.00043928487866651267, Final Batch Loss: 0.000285443413304165\n",
      "Epoch 1828, Loss: 0.0003200395294697955, Final Batch Loss: 0.00012682074157055467\n",
      "Epoch 1829, Loss: 0.00035198389741708525, Final Batch Loss: 5.979572961223312e-05\n",
      "Epoch 1830, Loss: 0.003815464282524772, Final Batch Loss: 7.19833915354684e-05\n",
      "Epoch 1831, Loss: 0.000528412449057214, Final Batch Loss: 0.00012821551354136318\n",
      "Epoch 1832, Loss: 0.003552997804945335, Final Batch Loss: 0.00023514041095040739\n",
      "Epoch 1833, Loss: 0.0004234605876263231, Final Batch Loss: 0.0001585960853844881\n",
      "Epoch 1834, Loss: 0.00018528139480622485, Final Batch Loss: 7.963932876009494e-05\n",
      "Epoch 1835, Loss: 0.004850364312005695, Final Batch Loss: 0.004749878775328398\n",
      "Epoch 1836, Loss: 0.0003029111976502463, Final Batch Loss: 2.1493659005500376e-05\n",
      "Epoch 1837, Loss: 0.000783497147494927, Final Batch Loss: 0.0005237698787823319\n",
      "Epoch 1838, Loss: 0.0004380434547783807, Final Batch Loss: 0.0002420008968329057\n",
      "Epoch 1839, Loss: 0.0014730391412740573, Final Batch Loss: 0.0012384316651150584\n",
      "Epoch 1840, Loss: 0.0002790825819829479, Final Batch Loss: 0.0002513280196581036\n",
      "Epoch 1841, Loss: 0.0001368209341308102, Final Batch Loss: 4.957263445248827e-05\n",
      "Epoch 1842, Loss: 0.0004906460089841858, Final Batch Loss: 8.374707249458879e-05\n",
      "Epoch 1843, Loss: 0.00032230481156148016, Final Batch Loss: 0.0001329427323071286\n",
      "Epoch 1844, Loss: 0.003047253645490855, Final Batch Loss: 7.532391464337707e-05\n",
      "Epoch 1845, Loss: 0.00042772175947902724, Final Batch Loss: 0.00011812877346528694\n",
      "Epoch 1846, Loss: 0.0002052637646556832, Final Batch Loss: 0.00011730368714779615\n",
      "Epoch 1847, Loss: 0.0058885995094897225, Final Batch Loss: 0.005723503418266773\n",
      "Epoch 1848, Loss: 0.000344401276379358, Final Batch Loss: 7.36121364752762e-05\n",
      "Epoch 1849, Loss: 0.00011080567674071062, Final Batch Loss: 2.9536875445046462e-05\n",
      "Epoch 1850, Loss: 0.00040203316893894225, Final Batch Loss: 0.0003193249285686761\n",
      "Epoch 1851, Loss: 0.0004105800180695951, Final Batch Loss: 0.0002403337712166831\n",
      "Epoch 1852, Loss: 0.0001858137948147487, Final Batch Loss: 0.0001358141453238204\n",
      "Epoch 1853, Loss: 0.0036487506004050374, Final Batch Loss: 0.0006663604872301221\n",
      "Epoch 1854, Loss: 0.00013031966955168173, Final Batch Loss: 8.376094774575904e-05\n",
      "Epoch 1855, Loss: 0.00014173754607327282, Final Batch Loss: 3.0359820812009275e-05\n",
      "Epoch 1856, Loss: 0.00020772693096660078, Final Batch Loss: 0.0001393406419083476\n",
      "Epoch 1857, Loss: 0.000587328991969116, Final Batch Loss: 0.0001571089815115556\n",
      "Epoch 1858, Loss: 8.447753771179123e-05, Final Batch Loss: 7.28522427380085e-05\n",
      "Epoch 1859, Loss: 0.00017020399172906764, Final Batch Loss: 4.4804637582274154e-05\n",
      "Epoch 1860, Loss: 7.469683623639867e-05, Final Batch Loss: 5.046476508141495e-05\n",
      "Epoch 1861, Loss: 0.006175545277073979, Final Batch Loss: 0.001134013058617711\n",
      "Epoch 1862, Loss: 0.0003267801148467697, Final Batch Loss: 0.0002627717622090131\n",
      "Epoch 1863, Loss: 8.081773194135167e-05, Final Batch Loss: 2.1668220142601058e-05\n",
      "Epoch 1864, Loss: 3.312806529720547e-05, Final Batch Loss: 1.9535840692697093e-05\n",
      "Epoch 1865, Loss: 0.00478914646373596, Final Batch Loss: 7.669800834264606e-05\n",
      "Epoch 1866, Loss: 0.004134217946557328, Final Batch Loss: 9.442653390578926e-05\n",
      "Epoch 1867, Loss: 0.0002725962813201477, Final Batch Loss: 1.4973772522353102e-05\n",
      "Epoch 1868, Loss: 0.011195522188245377, Final Batch Loss: 0.011181006208062172\n",
      "Epoch 1869, Loss: 0.00032011981602408923, Final Batch Loss: 0.0002792658342514187\n",
      "Epoch 1870, Loss: 0.005375637476390693, Final Batch Loss: 8.012427861103788e-05\n",
      "Epoch 1871, Loss: 0.00019283641449874267, Final Batch Loss: 4.617301601683721e-05\n",
      "Epoch 1872, Loss: 0.0006127436208771542, Final Batch Loss: 0.0004324149340391159\n",
      "Epoch 1873, Loss: 9.788219540496357e-05, Final Batch Loss: 4.0079019527183846e-05\n",
      "Epoch 1874, Loss: 0.0001373960003547836, Final Batch Loss: 5.7740438933251426e-05\n",
      "Epoch 1875, Loss: 0.00045342461817199364, Final Batch Loss: 0.0003719329251907766\n",
      "Epoch 1876, Loss: 0.002950197202153504, Final Batch Loss: 0.0017360493075102568\n",
      "Epoch 1877, Loss: 0.0065095152240246534, Final Batch Loss: 0.004163338802754879\n",
      "Epoch 1878, Loss: 0.0008823450189083815, Final Batch Loss: 8.48383060656488e-05\n",
      "Epoch 1879, Loss: 0.0004670966154662892, Final Batch Loss: 0.0004250186902936548\n",
      "Epoch 1880, Loss: 0.0001229478875757195, Final Batch Loss: 3.6017183447256684e-05\n",
      "Epoch 1881, Loss: 0.0002007839357247576, Final Batch Loss: 0.0001280053984373808\n",
      "Epoch 1882, Loss: 0.00021170663967495784, Final Batch Loss: 0.00011107567115686834\n",
      "Epoch 1883, Loss: 0.004836993972276105, Final Batch Loss: 3.814439332927577e-05\n",
      "Epoch 1884, Loss: 9.247474190487992e-05, Final Batch Loss: 2.575983489805367e-05\n",
      "Epoch 1885, Loss: 0.0002836016283254139, Final Batch Loss: 4.4317021092865616e-05\n",
      "Epoch 1886, Loss: 0.014024799049366266, Final Batch Loss: 0.0005332662840373814\n",
      "Epoch 1887, Loss: 0.0006047853676136583, Final Batch Loss: 0.0004401129554025829\n",
      "Epoch 1888, Loss: 0.0012480813420552295, Final Batch Loss: 0.0012043570168316364\n",
      "Epoch 1889, Loss: 0.0005839045206812443, Final Batch Loss: 0.0005598526331596076\n",
      "Epoch 1890, Loss: 7.591693793074228e-05, Final Batch Loss: 6.472682434832677e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1891, Loss: 0.0003294086272944696, Final Batch Loss: 0.0002340463106520474\n",
      "Epoch 1892, Loss: 0.0007937246555229649, Final Batch Loss: 0.000222393122385256\n",
      "Epoch 1893, Loss: 0.0006635782192461193, Final Batch Loss: 0.0005796666373498738\n",
      "Epoch 1894, Loss: 0.0013148215366527438, Final Batch Loss: 0.00018250674474984407\n",
      "Epoch 1895, Loss: 0.0002701801586226793, Final Batch Loss: 0.00025863994960673153\n",
      "Epoch 1896, Loss: 0.00020078503439435735, Final Batch Loss: 6.913503602845594e-05\n",
      "Epoch 1897, Loss: 0.0001663652728893794, Final Batch Loss: 2.0540646801237017e-05\n",
      "Epoch 1898, Loss: 0.0004193498461972922, Final Batch Loss: 0.0001803371706046164\n",
      "Epoch 1899, Loss: 0.0005694776482414454, Final Batch Loss: 0.0001615491637494415\n",
      "Epoch 1900, Loss: 5.8643203374231234e-05, Final Batch Loss: 2.2568856365978718e-05\n",
      "Epoch 1901, Loss: 0.0004275782994227484, Final Batch Loss: 8.978151890914887e-05\n",
      "Epoch 1902, Loss: 0.00019955657626269385, Final Batch Loss: 7.182457920862362e-05\n",
      "Epoch 1903, Loss: 0.00035033652966376394, Final Batch Loss: 4.192021151538938e-05\n",
      "Epoch 1904, Loss: 0.00010511322761885822, Final Batch Loss: 3.6302226362749934e-05\n",
      "Epoch 1905, Loss: 0.000315158256853465, Final Batch Loss: 0.00011152470688102767\n",
      "Epoch 1906, Loss: 0.00037047416662971955, Final Batch Loss: 1.69464747159509e-05\n",
      "Epoch 1907, Loss: 0.0005448082629300188, Final Batch Loss: 4.7762452595634386e-05\n",
      "Epoch 1908, Loss: 9.797837628866546e-05, Final Batch Loss: 6.236752960830927e-05\n",
      "Epoch 1909, Loss: 0.0011319457571516978, Final Batch Loss: 2.748763836279977e-05\n",
      "Epoch 1910, Loss: 0.002718592713790713, Final Batch Loss: 5.191955642658286e-05\n",
      "Epoch 1911, Loss: 0.0003082748953602277, Final Batch Loss: 8.454459748463705e-05\n",
      "Epoch 1912, Loss: 0.0002934959265985526, Final Batch Loss: 0.00020748365204781294\n",
      "Epoch 1913, Loss: 0.0013236108343335218, Final Batch Loss: 9.209207746607717e-06\n",
      "Epoch 1914, Loss: 0.00048493663780391216, Final Batch Loss: 0.00013254646910354495\n",
      "Epoch 1915, Loss: 4.549329241854139e-05, Final Batch Loss: 3.108138116658665e-05\n",
      "Epoch 1916, Loss: 0.00024393267813138664, Final Batch Loss: 3.2077834475785494e-05\n",
      "Epoch 1917, Loss: 0.00029974447534186766, Final Batch Loss: 0.00020054665219504386\n",
      "Epoch 1918, Loss: 0.00047691557847429067, Final Batch Loss: 0.00032884348183870316\n",
      "Epoch 1919, Loss: 0.008776423754170537, Final Batch Loss: 0.0035619379486888647\n",
      "Epoch 1920, Loss: 0.0004588957854139153, Final Batch Loss: 0.00041938258800655603\n",
      "Epoch 1921, Loss: 0.00017281486361753196, Final Batch Loss: 3.1788586056791246e-05\n",
      "Epoch 1922, Loss: 0.00010527977792662568, Final Batch Loss: 6.646230031037703e-05\n",
      "Epoch 1923, Loss: 0.00012900140245619696, Final Batch Loss: 6.264801413635723e-06\n",
      "Epoch 1924, Loss: 0.002773450527456589, Final Batch Loss: 0.00012690208677668124\n",
      "Epoch 1925, Loss: 9.612623762222938e-05, Final Batch Loss: 3.330909748910926e-05\n",
      "Epoch 1926, Loss: 0.0024540923950553406, Final Batch Loss: 0.00240792753174901\n",
      "Epoch 1927, Loss: 9.529055387247354e-05, Final Batch Loss: 6.452127126976848e-05\n",
      "Epoch 1928, Loss: 0.005623009754344821, Final Batch Loss: 0.002589933341369033\n",
      "Epoch 1929, Loss: 0.00014837643539067358, Final Batch Loss: 6.228026904864237e-05\n",
      "Epoch 1930, Loss: 0.006002525318763219, Final Batch Loss: 0.00586842792108655\n",
      "Epoch 1931, Loss: 7.914113666629419e-05, Final Batch Loss: 1.920598151627928e-05\n",
      "Epoch 1932, Loss: 0.006763718032743782, Final Batch Loss: 0.006701319012790918\n",
      "Epoch 1933, Loss: 0.0005091944767627865, Final Batch Loss: 0.00018309251754544675\n",
      "Epoch 1934, Loss: 7.947950143716298e-05, Final Batch Loss: 3.204694075975567e-05\n",
      "Epoch 1935, Loss: 0.00013269452028907835, Final Batch Loss: 8.499324758304283e-05\n",
      "Epoch 1936, Loss: 0.00017283284978475422, Final Batch Loss: 7.570173329440877e-05\n",
      "Epoch 1937, Loss: 0.00047748487850185484, Final Batch Loss: 0.00037421402521431446\n",
      "Epoch 1938, Loss: 0.00045236264122650027, Final Batch Loss: 0.00013721047434955835\n",
      "Epoch 1939, Loss: 8.430753223365173e-05, Final Batch Loss: 1.7147576727438718e-05\n",
      "Epoch 1940, Loss: 0.003545493818819523, Final Batch Loss: 8.543417789041996e-05\n",
      "Epoch 1941, Loss: 0.00032894711330300197, Final Batch Loss: 0.00020834917086176574\n",
      "Epoch 1942, Loss: 0.0001834837457863614, Final Batch Loss: 9.238401253242046e-05\n",
      "Epoch 1943, Loss: 9.662356751505286e-05, Final Batch Loss: 4.3287920561851934e-05\n",
      "Epoch 1944, Loss: 0.0006415535171981901, Final Batch Loss: 8.21505964267999e-05\n",
      "Epoch 1945, Loss: 0.005267606728011742, Final Batch Loss: 0.00029199119308032095\n",
      "Epoch 1946, Loss: 0.0003998798783868551, Final Batch Loss: 0.00023615015379618853\n",
      "Epoch 1947, Loss: 0.00027121154562337324, Final Batch Loss: 0.00019123511447105557\n",
      "Epoch 1948, Loss: 0.0002531781319703441, Final Batch Loss: 0.00022187440481502563\n",
      "Epoch 1949, Loss: 0.00031518860487267375, Final Batch Loss: 0.00021611741976812482\n",
      "Epoch 1950, Loss: 0.0006511388783110306, Final Batch Loss: 0.0001910930295707658\n",
      "Epoch 1951, Loss: 0.00011937283488805406, Final Batch Loss: 1.9824768969556317e-05\n",
      "Epoch 1952, Loss: 0.0003731226606760174, Final Batch Loss: 0.0002939692058134824\n",
      "Epoch 1953, Loss: 0.0003246992564527318, Final Batch Loss: 0.0001302359305555001\n",
      "Epoch 1954, Loss: 0.012761900085024536, Final Batch Loss: 0.012136801145970821\n",
      "Epoch 1955, Loss: 0.01179718398998375, Final Batch Loss: 0.011761284433305264\n",
      "Epoch 1956, Loss: 0.0004356274876045063, Final Batch Loss: 0.00015749970043543726\n",
      "Epoch 1957, Loss: 0.000528814533026889, Final Batch Loss: 0.00012225541286170483\n",
      "Epoch 1958, Loss: 0.0017053929768735543, Final Batch Loss: 0.0015267845010384917\n",
      "Epoch 1959, Loss: 0.0004944465326843783, Final Batch Loss: 0.0003943319316022098\n",
      "Epoch 1960, Loss: 0.0001666253047005739, Final Batch Loss: 4.540926238405518e-05\n",
      "Epoch 1961, Loss: 0.00012079460066161118, Final Batch Loss: 7.764014299027622e-05\n",
      "Epoch 1962, Loss: 0.00022727337636752054, Final Batch Loss: 0.00019014699500985444\n",
      "Epoch 1963, Loss: 0.0001503430503362324, Final Batch Loss: 5.390425576479174e-05\n",
      "Epoch 1964, Loss: 0.00011500545679155039, Final Batch Loss: 1.468415302952053e-05\n",
      "Epoch 1965, Loss: 0.0002412068788544275, Final Batch Loss: 0.0002058067184407264\n",
      "Epoch 1966, Loss: 0.0002772292500594631, Final Batch Loss: 0.00013390560343395919\n",
      "Epoch 1967, Loss: 0.0007764956098981202, Final Batch Loss: 0.0006003137095831335\n",
      "Epoch 1968, Loss: 0.0004730506188934669, Final Batch Loss: 0.00042975498945452273\n",
      "Epoch 1969, Loss: 0.00029498495496227406, Final Batch Loss: 0.0002344584499951452\n",
      "Epoch 1970, Loss: 0.00017177149129565805, Final Batch Loss: 3.38555546477437e-05\n",
      "Epoch 1971, Loss: 9.988527381210588e-05, Final Batch Loss: 2.1734722395194694e-05\n",
      "Epoch 1972, Loss: 0.00037542421887337696, Final Batch Loss: 1.122290086641442e-05\n",
      "Epoch 1973, Loss: 0.0001282963130506687, Final Batch Loss: 7.006558735156432e-05\n",
      "Epoch 1974, Loss: 7.737048326816875e-05, Final Batch Loss: 2.6126241209567524e-05\n",
      "Epoch 1975, Loss: 0.00022590676417166833, Final Batch Loss: 2.3713111659162678e-05\n",
      "Epoch 1976, Loss: 0.00045189833326730877, Final Batch Loss: 0.00020728942763525993\n",
      "Epoch 1977, Loss: 5.4705697039025836e-05, Final Batch Loss: 3.628110789577477e-05\n",
      "Epoch 1978, Loss: 0.003748172779523884, Final Batch Loss: 1.3608370863948949e-05\n",
      "Epoch 1979, Loss: 0.004556572524961666, Final Batch Loss: 1.1795194950536825e-05\n",
      "Epoch 1980, Loss: 0.0003946009528590366, Final Batch Loss: 7.256427488755435e-05\n",
      "Epoch 1981, Loss: 0.00011472021287772804, Final Batch Loss: 6.49734865874052e-05\n",
      "Epoch 1982, Loss: 6.013451456965413e-05, Final Batch Loss: 3.9584199839737266e-05\n",
      "Epoch 1983, Loss: 4.461796743271407e-05, Final Batch Loss: 1.0539844879531302e-05\n",
      "Epoch 1984, Loss: 0.0033931141879293136, Final Batch Loss: 3.646418190328404e-05\n",
      "Epoch 1985, Loss: 0.00021646282766596414, Final Batch Loss: 0.0001786857028491795\n",
      "Epoch 1986, Loss: 0.0004032936012663413, Final Batch Loss: 4.322566746850498e-05\n",
      "Epoch 1987, Loss: 8.047062146943063e-05, Final Batch Loss: 3.658279820228927e-05\n",
      "Epoch 1988, Loss: 2.964024724860792e-05, Final Batch Loss: 6.405529802577803e-06\n",
      "Epoch 1989, Loss: 0.00013165165000827983, Final Batch Loss: 1.0593881597742438e-05\n",
      "Epoch 1990, Loss: 0.0003538305245456286, Final Batch Loss: 1.6270299965981394e-05\n",
      "Epoch 1991, Loss: 0.0002047369271167554, Final Batch Loss: 0.00012378755491226912\n",
      "Epoch 1992, Loss: 0.0003198084596078843, Final Batch Loss: 0.0001972858008230105\n",
      "Epoch 1993, Loss: 0.0009349703323096037, Final Batch Loss: 0.0003916322602890432\n",
      "Epoch 1994, Loss: 7.615288268425502e-05, Final Batch Loss: 1.990080636460334e-05\n",
      "Epoch 1995, Loss: 0.0006045290938345715, Final Batch Loss: 0.00017437843780498952\n",
      "Epoch 1996, Loss: 0.00017945171566680074, Final Batch Loss: 0.00010523790115257725\n",
      "Epoch 1997, Loss: 0.001678725366218714, Final Batch Loss: 2.8833757824031636e-05\n",
      "Epoch 1998, Loss: 3.644934440671932e-05, Final Batch Loss: 9.8080636234954e-06\n",
      "Epoch 1999, Loss: 0.0001566477003507316, Final Batch Loss: 7.949680730234832e-05\n",
      "Epoch 2000, Loss: 0.007643574383109808, Final Batch Loss: 0.0071536581963300705\n",
      "Epoch 2001, Loss: 5.534500314752222e-05, Final Batch Loss: 7.4988552114518825e-06\n",
      "Epoch 2002, Loss: 0.0003407363110454753, Final Batch Loss: 0.00024724091053940356\n",
      "Epoch 2003, Loss: 0.00014783665392315015, Final Batch Loss: 1.460802013752982e-05\n",
      "Epoch 2004, Loss: 0.00020414115715539083, Final Batch Loss: 6.69084329274483e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2005, Loss: 0.0001588775085110683, Final Batch Loss: 4.4668649934465066e-05\n",
      "Epoch 2006, Loss: 0.0002374913456151262, Final Batch Loss: 0.0001484341046307236\n",
      "Epoch 2007, Loss: 0.000933754097786732, Final Batch Loss: 0.00010987640416715294\n",
      "Epoch 2008, Loss: 0.0007404571224469692, Final Batch Loss: 0.00026840390637516975\n",
      "Epoch 2009, Loss: 0.00033360618726874236, Final Batch Loss: 0.00030329471337608993\n",
      "Epoch 2010, Loss: 3.874817048199475e-05, Final Batch Loss: 1.9391318346606568e-05\n",
      "Epoch 2011, Loss: 0.00017708902851154562, Final Batch Loss: 0.00016851820691954345\n",
      "Epoch 2012, Loss: 0.00015122675722523127, Final Batch Loss: 2.7214462534175254e-05\n",
      "Epoch 2013, Loss: 0.0002577334744273685, Final Batch Loss: 3.176987956976518e-05\n",
      "Epoch 2014, Loss: 0.00019553889433154836, Final Batch Loss: 9.286101703764871e-05\n",
      "Epoch 2015, Loss: 8.573256855015643e-05, Final Batch Loss: 1.9360890291864052e-05\n",
      "Epoch 2016, Loss: 0.0007198350367616513, Final Batch Loss: 9.56973326537991e-06\n",
      "Epoch 2017, Loss: 9.833808871917427e-05, Final Batch Loss: 3.8061669329181314e-05\n",
      "Epoch 2018, Loss: 0.0001260851786355488, Final Batch Loss: 5.132867954671383e-05\n",
      "Epoch 2019, Loss: 6.628533083130606e-05, Final Batch Loss: 2.3566506570205092e-05\n",
      "Epoch 2020, Loss: 5.0978591843886534e-05, Final Batch Loss: 4.637692109099589e-05\n",
      "Epoch 2021, Loss: 0.0003464551118668169, Final Batch Loss: 0.0001811469264794141\n",
      "Epoch 2022, Loss: 0.003847513740765862, Final Batch Loss: 8.379963401239365e-05\n",
      "Epoch 2023, Loss: 6.83712733007269e-05, Final Batch Loss: 1.8837416064343415e-05\n",
      "Epoch 2024, Loss: 4.77039284305647e-05, Final Batch Loss: 9.525036148261279e-06\n",
      "Epoch 2025, Loss: 0.0005701641657651635, Final Batch Loss: 0.0005544849555008113\n",
      "Epoch 2026, Loss: 0.0026775265650940128, Final Batch Loss: 2.6805100787896663e-05\n",
      "Epoch 2027, Loss: 7.00374175721663e-05, Final Batch Loss: 1.3533949640986975e-05\n",
      "Epoch 2028, Loss: 0.00030869445618009195, Final Batch Loss: 0.0002213882835349068\n",
      "Epoch 2029, Loss: 0.00010423952971905237, Final Batch Loss: 9.191266144625843e-05\n",
      "Epoch 2030, Loss: 0.0003107066913798917, Final Batch Loss: 0.0002680070174392313\n",
      "Epoch 2031, Loss: 0.000422088400227949, Final Batch Loss: 0.00034918743767775595\n",
      "Epoch 2032, Loss: 0.00017218394714291207, Final Batch Loss: 4.2887357267318293e-05\n",
      "Epoch 2033, Loss: 0.00055406877072528, Final Batch Loss: 0.000257170177064836\n",
      "Epoch 2034, Loss: 0.0011793232524723862, Final Batch Loss: 4.142942088947166e-06\n",
      "Epoch 2035, Loss: 0.003965471783885732, Final Batch Loss: 0.0038901157677173615\n",
      "Epoch 2036, Loss: 0.0003496366844046861, Final Batch Loss: 3.2332434784621e-05\n",
      "Epoch 2037, Loss: 0.0001494282878411468, Final Batch Loss: 9.19069061637856e-05\n",
      "Epoch 2038, Loss: 5.87845643167384e-05, Final Batch Loss: 3.4538141335360706e-05\n",
      "Epoch 2039, Loss: 0.0024757984556345036, Final Batch Loss: 9.982939445762895e-06\n",
      "Epoch 2040, Loss: 7.693158386246068e-05, Final Batch Loss: 6.484604818979278e-05\n",
      "Epoch 2041, Loss: 0.0003552058115019463, Final Batch Loss: 5.540661368286237e-05\n",
      "Epoch 2042, Loss: 0.00015899783829809166, Final Batch Loss: 4.540832378552295e-05\n",
      "Epoch 2043, Loss: 0.00013589646550826728, Final Batch Loss: 6.663842941634357e-05\n",
      "Epoch 2044, Loss: 6.297960135270841e-05, Final Batch Loss: 5.0309427024330944e-05\n",
      "Epoch 2045, Loss: 0.00012407824760884978, Final Batch Loss: 5.213955228100531e-05\n",
      "Epoch 2046, Loss: 0.0004556835483526811, Final Batch Loss: 6.143828795757145e-05\n",
      "Epoch 2047, Loss: 0.0002570719152572565, Final Batch Loss: 0.0001580318930791691\n",
      "Epoch 2048, Loss: 0.008322301553562284, Final Batch Loss: 0.0059445626102387905\n",
      "Epoch 2049, Loss: 0.0003037118494830793, Final Batch Loss: 8.692722985870205e-06\n",
      "Epoch 2050, Loss: 8.457792864646763e-05, Final Batch Loss: 3.2352116249967366e-05\n",
      "Epoch 2051, Loss: 0.0003089188139711041, Final Batch Loss: 0.00024913516244851053\n",
      "Epoch 2052, Loss: 0.006675593424006365, Final Batch Loss: 0.0066072060726583\n",
      "Epoch 2053, Loss: 7.374465167231392e-05, Final Batch Loss: 4.573842670652084e-05\n",
      "Epoch 2054, Loss: 0.00026892520327237435, Final Batch Loss: 1.6205001884372905e-05\n",
      "Epoch 2055, Loss: 0.0009353776258649305, Final Batch Loss: 0.00021383231796789914\n",
      "Epoch 2056, Loss: 0.0040833215098246, Final Batch Loss: 0.003993162419646978\n",
      "Epoch 2057, Loss: 6.580741137440782e-05, Final Batch Loss: 4.8078545660246164e-05\n",
      "Epoch 2058, Loss: 0.0029591598286060616, Final Batch Loss: 0.00015481111768167466\n",
      "Epoch 2059, Loss: 4.911664473183919e-05, Final Batch Loss: 1.8418142644804902e-05\n",
      "Epoch 2060, Loss: 4.671980241255369e-05, Final Batch Loss: 1.8003343939199112e-05\n",
      "Epoch 2061, Loss: 0.0001142671198977041, Final Batch Loss: 0.00010426444350741804\n",
      "Epoch 2062, Loss: 0.0015939353324938565, Final Batch Loss: 0.00026405302924104035\n",
      "Epoch 2063, Loss: 6.645579014730174e-05, Final Batch Loss: 1.3212234989623539e-05\n",
      "Epoch 2064, Loss: 0.00010832888801814988, Final Batch Loss: 1.749826333252713e-05\n",
      "Epoch 2065, Loss: 0.00010119998114532791, Final Batch Loss: 1.057441477314569e-05\n",
      "Epoch 2066, Loss: 0.0005129663040861487, Final Batch Loss: 0.00018159716273657978\n",
      "Epoch 2067, Loss: 0.0028246119363757316, Final Batch Loss: 2.4717974156374112e-05\n",
      "Epoch 2068, Loss: 0.004827222786843777, Final Batch Loss: 0.0022776147816330194\n",
      "Epoch 2069, Loss: 8.986620014184155e-05, Final Batch Loss: 5.305987724568695e-05\n",
      "Epoch 2070, Loss: 0.0007824354179319926, Final Batch Loss: 8.526084275217727e-05\n",
      "Epoch 2071, Loss: 0.00034967369447258534, Final Batch Loss: 8.896856343199033e-06\n",
      "Epoch 2072, Loss: 0.0009831372626649681, Final Batch Loss: 1.3970395229989663e-05\n",
      "Epoch 2073, Loss: 0.0025248100500903092, Final Batch Loss: 0.00251424009911716\n",
      "Epoch 2074, Loss: 2.6398885893286206e-05, Final Batch Loss: 9.842406143434346e-06\n",
      "Epoch 2075, Loss: 0.0011624205126281595, Final Batch Loss: 0.0011350397253409028\n",
      "Epoch 2076, Loss: 0.0025351136737299385, Final Batch Loss: 2.100884921674151e-05\n",
      "Epoch 2077, Loss: 4.610253017744981e-05, Final Batch Loss: 1.873925793915987e-05\n",
      "Epoch 2078, Loss: 0.010991912815370597, Final Batch Loss: 0.010920562781393528\n",
      "Epoch 2079, Loss: 3.92341025872156e-05, Final Batch Loss: 7.1755857788957655e-06\n",
      "Epoch 2080, Loss: 0.0001702419322100468, Final Batch Loss: 0.00013338740973267704\n",
      "Epoch 2081, Loss: 0.00041414460883970605, Final Batch Loss: 9.458756721869577e-06\n",
      "Epoch 2082, Loss: 6.480491174443159e-05, Final Batch Loss: 1.062762203218881e-05\n",
      "Epoch 2083, Loss: 0.0001633412393857725, Final Batch Loss: 7.246559107443318e-05\n",
      "Epoch 2084, Loss: 2.4946773010015022e-05, Final Batch Loss: 1.3580077393271495e-05\n",
      "Epoch 2085, Loss: 0.0023791358325979672, Final Batch Loss: 3.803954314207658e-05\n",
      "Epoch 2086, Loss: 0.00011460709720267914, Final Batch Loss: 3.14923636324238e-05\n",
      "Epoch 2087, Loss: 9.623256482882425e-05, Final Batch Loss: 6.646791007369757e-05\n",
      "Epoch 2088, Loss: 0.0002801809541779221, Final Batch Loss: 3.0074234018684365e-06\n",
      "Epoch 2089, Loss: 0.00034171019615314435, Final Batch Loss: 1.5464347598026507e-05\n",
      "Epoch 2090, Loss: 0.00015974033158272505, Final Batch Loss: 8.157649426721036e-05\n",
      "Epoch 2091, Loss: 0.0002317660182598047, Final Batch Loss: 5.129399505676702e-05\n",
      "Epoch 2092, Loss: 0.00014069721055420814, Final Batch Loss: 5.51114044355927e-06\n",
      "Epoch 2093, Loss: 4.6957088670751546e-05, Final Batch Loss: 3.5757093428401276e-05\n",
      "Epoch 2094, Loss: 3.051834255529684e-05, Final Batch Loss: 5.3419630603457335e-06\n",
      "Epoch 2095, Loss: 0.0001081193950085435, Final Batch Loss: 6.671445589745417e-05\n",
      "Epoch 2096, Loss: 0.0007194515637820587, Final Batch Loss: 5.6729288189671934e-05\n",
      "Epoch 2097, Loss: 0.00013607106302515604, Final Batch Loss: 3.512783223413862e-05\n",
      "Epoch 2098, Loss: 5.415528517005441e-05, Final Batch Loss: 1.4208469565346604e-06\n",
      "Epoch 2099, Loss: 1.582328081894957e-05, Final Batch Loss: 1.3422103620541748e-05\n",
      "Epoch 2100, Loss: 0.0005689854369848035, Final Batch Loss: 0.0004951240262016654\n",
      "Epoch 2101, Loss: 0.00026897383577306755, Final Batch Loss: 2.067936657113023e-05\n",
      "Epoch 2102, Loss: 0.0008629576695966534, Final Batch Loss: 0.0008454258786514401\n",
      "Epoch 2103, Loss: 0.0004334341356297955, Final Batch Loss: 0.0002873370540328324\n",
      "Epoch 2104, Loss: 0.000955568699282594, Final Batch Loss: 0.0008506355807185173\n",
      "Epoch 2105, Loss: 0.00024155955179594457, Final Batch Loss: 7.750684744678438e-05\n",
      "Epoch 2106, Loss: 0.0001015506559269852, Final Batch Loss: 1.5250027900037821e-05\n",
      "Epoch 2107, Loss: 7.855127478251234e-05, Final Batch Loss: 3.690048833959736e-05\n",
      "Epoch 2108, Loss: 0.0002757138972810935, Final Batch Loss: 0.000237103013205342\n",
      "Epoch 2109, Loss: 0.00035499083605827764, Final Batch Loss: 0.00026656020781956613\n",
      "Epoch 2110, Loss: 0.0001827184642024804, Final Batch Loss: 3.140466651530005e-05\n",
      "Epoch 2111, Loss: 0.0009849896814557724, Final Batch Loss: 8.244916534749791e-05\n",
      "Epoch 2112, Loss: 0.0003116166826657718, Final Batch Loss: 1.759305268933531e-05\n",
      "Epoch 2113, Loss: 7.1458498496213e-05, Final Batch Loss: 5.456985309137963e-05\n",
      "Epoch 2114, Loss: 0.00010835579814738594, Final Batch Loss: 7.946274126879871e-05\n",
      "Epoch 2115, Loss: 1.2836993846576661e-05, Final Batch Loss: 8.997340046335012e-06\n",
      "Epoch 2116, Loss: 0.00020179521015961654, Final Batch Loss: 0.00015265260299202055\n",
      "Epoch 2117, Loss: 0.0012556759102153592, Final Batch Loss: 0.0011869431473314762\n",
      "Epoch 2118, Loss: 0.004920381426927634, Final Batch Loss: 0.00010720577847678214\n",
      "Epoch 2119, Loss: 0.0028434097912395373, Final Batch Loss: 0.00012640167551580817\n",
      "Epoch 2120, Loss: 0.00026228486240142956, Final Batch Loss: 6.175888847792521e-05\n",
      "Epoch 2121, Loss: 7.636855298187584e-05, Final Batch Loss: 2.14086685446091e-05\n",
      "Epoch 2122, Loss: 0.0003552368871169165, Final Batch Loss: 0.00014702050248160958\n",
      "Epoch 2123, Loss: 0.0003136512059427332, Final Batch Loss: 0.0002627951034810394\n",
      "Epoch 2124, Loss: 0.0038514222269441234, Final Batch Loss: 2.6366325982962735e-05\n",
      "Epoch 2125, Loss: 0.0017699253003229387, Final Batch Loss: 3.7828060158062726e-05\n",
      "Epoch 2126, Loss: 0.0009192342695314437, Final Batch Loss: 0.0007010061526671052\n",
      "Epoch 2127, Loss: 0.00012535849691630574, Final Batch Loss: 1.304389752476709e-05\n",
      "Epoch 2128, Loss: 0.00166679324775032, Final Batch Loss: 1.2872970728494693e-05\n",
      "Epoch 2129, Loss: 0.005925446283072233, Final Batch Loss: 0.002966103842481971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2130, Loss: 0.002141593722626567, Final Batch Loss: 0.00010568788275122643\n",
      "Epoch 2131, Loss: 0.00016666292867739685, Final Batch Loss: 0.00012548423546832055\n",
      "Epoch 2132, Loss: 2.110748255290673e-05, Final Batch Loss: 4.935960987495491e-06\n",
      "Epoch 2133, Loss: 5.726810559281148e-05, Final Batch Loss: 2.175025292672217e-05\n",
      "Epoch 2134, Loss: 0.0013792372337775305, Final Batch Loss: 3.810990892816335e-05\n",
      "Epoch 2135, Loss: 0.00017249690426979214, Final Batch Loss: 3.977336746174842e-05\n",
      "Epoch 2136, Loss: 9.160457557300106e-05, Final Batch Loss: 4.0391296352026984e-05\n",
      "Epoch 2137, Loss: 0.0037729446194134653, Final Batch Loss: 0.003692377358675003\n",
      "Epoch 2138, Loss: 4.241044007358141e-05, Final Batch Loss: 2.706111263250932e-05\n",
      "Epoch 2139, Loss: 0.0011878345685545355, Final Batch Loss: 0.00013761947047896683\n",
      "Epoch 2140, Loss: 0.00030757951753912494, Final Batch Loss: 0.0002665037754923105\n",
      "Epoch 2141, Loss: 0.0003177438957209233, Final Batch Loss: 0.00029567713500000536\n",
      "Epoch 2142, Loss: 0.00012395973863021936, Final Batch Loss: 0.00011251794785493985\n",
      "Epoch 2143, Loss: 6.597814171982463e-05, Final Batch Loss: 5.313441579346545e-05\n",
      "Epoch 2144, Loss: 0.0022149697783788724, Final Batch Loss: 4.071453531651059e-06\n",
      "Epoch 2145, Loss: 7.870240369811654e-05, Final Batch Loss: 5.515762677532621e-05\n",
      "Epoch 2146, Loss: 5.378512923925882e-05, Final Batch Loss: 5.856311872776132e-06\n",
      "Epoch 2147, Loss: 0.0007024201295280363, Final Batch Loss: 0.0006704077241010964\n",
      "Epoch 2148, Loss: 0.00046400129212997854, Final Batch Loss: 0.00039013271452859044\n",
      "Epoch 2149, Loss: 0.0037732633427367546, Final Batch Loss: 0.0037279902026057243\n",
      "Epoch 2150, Loss: 0.00014412866221391596, Final Batch Loss: 3.3830994652817026e-05\n",
      "Epoch 2151, Loss: 2.3884709662524983e-05, Final Batch Loss: 1.391228761349339e-05\n",
      "Epoch 2152, Loss: 0.004348567519627977, Final Batch Loss: 0.004313312470912933\n",
      "Epoch 2153, Loss: 0.004737731709610671, Final Batch Loss: 0.00453909020870924\n",
      "Epoch 2154, Loss: 0.0025699373509269208, Final Batch Loss: 0.002399030141532421\n",
      "Epoch 2155, Loss: 0.0001405922812409699, Final Batch Loss: 6.655511970166117e-05\n",
      "Epoch 2156, Loss: 0.008469746011542156, Final Batch Loss: 0.008337363600730896\n",
      "Epoch 2157, Loss: 0.0004544226248981431, Final Batch Loss: 0.00016611099999863654\n",
      "Epoch 2158, Loss: 0.0032701347954571247, Final Batch Loss: 0.00047185784205794334\n",
      "Epoch 2159, Loss: 0.00020091367696295492, Final Batch Loss: 0.0001931211882038042\n",
      "Epoch 2160, Loss: 9.017406682687579e-05, Final Batch Loss: 7.902651123004034e-05\n",
      "Epoch 2161, Loss: 2.2123929284134647e-05, Final Batch Loss: 6.779313025617739e-06\n",
      "Epoch 2162, Loss: 0.00014060402781979064, Final Batch Loss: 4.159013315074844e-06\n",
      "Epoch 2163, Loss: 0.0002497838668205077, Final Batch Loss: 0.0002265020302729681\n",
      "Epoch 2164, Loss: 0.0001312902895733714, Final Batch Loss: 5.294814764056355e-05\n",
      "Epoch 2165, Loss: 0.00016527453772141598, Final Batch Loss: 4.617970625986345e-05\n",
      "Epoch 2166, Loss: 0.013138491325662471, Final Batch Loss: 0.00019835181592497975\n",
      "Epoch 2167, Loss: 0.003579269781766925, Final Batch Loss: 3.157920582452789e-05\n",
      "Epoch 2168, Loss: 9.816710007726215e-05, Final Batch Loss: 2.5602068490115926e-05\n",
      "Epoch 2169, Loss: 0.00017239337103092112, Final Batch Loss: 5.207305002841167e-05\n",
      "Epoch 2170, Loss: 0.00013172452327125939, Final Batch Loss: 1.1437169632699806e-05\n",
      "Epoch 2171, Loss: 0.0002161671218345873, Final Batch Loss: 0.00015110993990674615\n",
      "Epoch 2172, Loss: 0.00013983840835862793, Final Batch Loss: 4.787493162439205e-05\n",
      "Epoch 2173, Loss: 0.0002411821551504545, Final Batch Loss: 0.00017645461775828153\n",
      "Epoch 2174, Loss: 3.5488085813994985e-05, Final Batch Loss: 6.5308258854201995e-06\n",
      "Epoch 2175, Loss: 0.0006144540529930964, Final Batch Loss: 0.00012488513311836869\n",
      "Epoch 2176, Loss: 0.004567011317703873, Final Batch Loss: 0.0045386687852442265\n",
      "Epoch 2177, Loss: 0.00035598480098997243, Final Batch Loss: 0.0003006551705766469\n",
      "Epoch 2178, Loss: 8.960027480497956e-05, Final Batch Loss: 1.7330596165265888e-05\n",
      "Epoch 2179, Loss: 3.4912593037006445e-05, Final Batch Loss: 1.93819469131995e-05\n",
      "Epoch 2180, Loss: 7.267898763529956e-05, Final Batch Loss: 3.335144720040262e-05\n",
      "Epoch 2181, Loss: 0.0012874084541181219, Final Batch Loss: 1.138616516982438e-05\n",
      "Epoch 2182, Loss: 0.000344320765179873, Final Batch Loss: 1.3070920431346167e-05\n",
      "Epoch 2183, Loss: 7.591134635731578e-05, Final Batch Loss: 3.65351079381071e-05\n",
      "Epoch 2184, Loss: 0.001236099732977891, Final Batch Loss: 4.361133960628649e-06\n",
      "Epoch 2185, Loss: 0.0015924069994071033, Final Batch Loss: 0.001570672495290637\n",
      "Epoch 2186, Loss: 0.00017661907986621372, Final Batch Loss: 8.454178896499798e-06\n",
      "Epoch 2187, Loss: 0.002396123541984707, Final Batch Loss: 0.0017703031189739704\n",
      "Epoch 2188, Loss: 0.0012518390431068838, Final Batch Loss: 0.001015972695313394\n",
      "Epoch 2189, Loss: 0.001055714796166285, Final Batch Loss: 1.6932846847339533e-05\n",
      "Epoch 2190, Loss: 9.912963651004247e-05, Final Batch Loss: 6.46832850179635e-05\n",
      "Epoch 2191, Loss: 3.3056533538911026e-05, Final Batch Loss: 3.329910214233678e-06\n",
      "Epoch 2192, Loss: 5.9191149375692476e-05, Final Batch Loss: 1.1432847713876981e-05\n",
      "Epoch 2193, Loss: 0.0007479164632968605, Final Batch Loss: 0.00019228836754336953\n",
      "Epoch 2194, Loss: 0.0008403890824411064, Final Batch Loss: 0.0006144046783447266\n",
      "Epoch 2195, Loss: 0.0002468146792580228, Final Batch Loss: 3.350238102939329e-06\n",
      "Epoch 2196, Loss: 0.0013348645443329588, Final Batch Loss: 0.00119905942119658\n",
      "Epoch 2197, Loss: 1.372040878777625e-05, Final Batch Loss: 8.82865788298659e-06\n",
      "Epoch 2198, Loss: 1.2847235211665975e-05, Final Batch Loss: 4.6424142965406645e-06\n",
      "Epoch 2199, Loss: 0.00020041448897245573, Final Batch Loss: 0.00018630432896316051\n",
      "Epoch 2200, Loss: 4.725985309050884e-05, Final Batch Loss: 3.194809687556699e-05\n",
      "Epoch 2201, Loss: 0.00019915530356229283, Final Batch Loss: 0.00017333425057586282\n",
      "Epoch 2202, Loss: 5.378630339691881e-05, Final Batch Loss: 1.630033330002334e-05\n",
      "Epoch 2203, Loss: 0.00044217455433681607, Final Batch Loss: 0.00012235058238729835\n",
      "Epoch 2204, Loss: 0.00016495361342094839, Final Batch Loss: 8.285599324153736e-05\n",
      "Epoch 2205, Loss: 9.768811150934198e-05, Final Batch Loss: 3.30357443090179e-06\n",
      "Epoch 2206, Loss: 0.0002068487092401483, Final Batch Loss: 0.00019514121231622994\n",
      "Epoch 2207, Loss: 0.00020264352679078002, Final Batch Loss: 9.336990842712112e-06\n",
      "Epoch 2208, Loss: 0.00027136549215356354, Final Batch Loss: 0.00024785110144875944\n",
      "Epoch 2209, Loss: 0.01444560958771035, Final Batch Loss: 0.013937177136540413\n",
      "Epoch 2210, Loss: 0.00011687199730658904, Final Batch Loss: 4.380036989459768e-05\n",
      "Epoch 2211, Loss: 5.423938455351163e-05, Final Batch Loss: 1.9702629288076423e-05\n",
      "Epoch 2212, Loss: 0.00010185984683630522, Final Batch Loss: 3.453749741311185e-06\n",
      "Epoch 2213, Loss: 0.0019653982948284465, Final Batch Loss: 1.8776394199448987e-06\n",
      "Epoch 2214, Loss: 0.0007450932207575534, Final Batch Loss: 0.0007163535337895155\n",
      "Epoch 2215, Loss: 7.885554259701166e-05, Final Batch Loss: 5.1862269174307585e-05\n",
      "Epoch 2216, Loss: 2.7289288709653192e-05, Final Batch Loss: 2.2322967652144143e-06\n",
      "Epoch 2217, Loss: 0.0027973207215836737, Final Batch Loss: 5.5781103583285585e-05\n",
      "Epoch 2218, Loss: 5.5253087793971645e-06, Final Batch Loss: 2.3936045181471854e-06\n",
      "Epoch 2219, Loss: 9.45914798649028e-05, Final Batch Loss: 8.828668796923012e-06\n",
      "Epoch 2220, Loss: 3.4059207791869994e-05, Final Batch Loss: 1.524830895505147e-05\n",
      "Epoch 2221, Loss: 0.00014345062663778663, Final Batch Loss: 0.00012945481284987181\n",
      "Epoch 2222, Loss: 7.17338243703125e-05, Final Batch Loss: 4.877126411884092e-05\n",
      "Epoch 2223, Loss: 0.0027214054571231827, Final Batch Loss: 0.0001255903480341658\n",
      "Epoch 2224, Loss: 0.004860653500600165, Final Batch Loss: 0.00485322717577219\n",
      "Epoch 2225, Loss: 7.782107240927871e-05, Final Batch Loss: 1.97783865587553e-05\n",
      "Epoch 2226, Loss: 0.00011673570952552836, Final Batch Loss: 0.00010663258581189439\n",
      "Epoch 2227, Loss: 0.00018152474376620376, Final Batch Loss: 4.898224233329529e-06\n",
      "Epoch 2228, Loss: 0.000514636114530731, Final Batch Loss: 0.0004385189095046371\n",
      "Epoch 2229, Loss: 9.492661320109619e-05, Final Batch Loss: 8.923281711759046e-05\n",
      "Epoch 2230, Loss: 3.30251259583747e-05, Final Batch Loss: 3.290240783826448e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2231, Loss: 2.1501003175217193e-05, Final Batch Loss: 1.140394033427583e-05\n",
      "Epoch 2232, Loss: 0.0003071837272727862, Final Batch Loss: 0.00023601416614837945\n",
      "Epoch 2233, Loss: 0.002840880830262904, Final Batch Loss: 2.9847784389858134e-05\n",
      "Epoch 2234, Loss: 0.028192159727041144, Final Batch Loss: 0.028090177103877068\n",
      "Epoch 2235, Loss: 0.00025188433755829465, Final Batch Loss: 3.031582855328452e-05\n",
      "Epoch 2236, Loss: 0.00011787940456997603, Final Batch Loss: 3.0954237445257604e-05\n",
      "Epoch 2237, Loss: 0.004327464836023864, Final Batch Loss: 0.004299470689147711\n",
      "Epoch 2238, Loss: 6.871405821584631e-05, Final Batch Loss: 1.5803490896360017e-05\n",
      "Epoch 2239, Loss: 3.707481846504379e-05, Final Batch Loss: 1.5893410818534903e-05\n",
      "Epoch 2240, Loss: 6.27842491667252e-05, Final Batch Loss: 3.2120326068252325e-05\n",
      "Epoch 2241, Loss: 0.00029553948570537614, Final Batch Loss: 0.00028080365154892206\n",
      "Epoch 2242, Loss: 0.002731754975684453, Final Batch Loss: 0.00012161333143012598\n",
      "Epoch 2243, Loss: 0.0004957854907843284, Final Batch Loss: 2.191450766986236e-05\n",
      "Epoch 2244, Loss: 0.0051662461537489435, Final Batch Loss: 0.0051521360874176025\n",
      "Epoch 2245, Loss: 0.005401865142630413, Final Batch Loss: 0.005135204643011093\n",
      "Epoch 2246, Loss: 0.00027641152519208845, Final Batch Loss: 1.8646931494004093e-05\n",
      "Epoch 2247, Loss: 0.00032573495263932273, Final Batch Loss: 0.00010017772001447156\n",
      "Epoch 2248, Loss: 0.0009430983946003835, Final Batch Loss: 1.200585666083498e-05\n",
      "Epoch 2249, Loss: 0.00011323703802190721, Final Batch Loss: 2.321448118891567e-05\n",
      "Epoch 2250, Loss: 0.00017692667461233214, Final Batch Loss: 3.4142758522648364e-05\n",
      "Epoch 2251, Loss: 8.383406020584516e-05, Final Batch Loss: 2.4341810785699636e-05\n",
      "Epoch 2252, Loss: 0.0002714234942686744, Final Batch Loss: 0.0002031240874202922\n",
      "Epoch 2253, Loss: 0.0003200018691131845, Final Batch Loss: 0.00023165368475019932\n",
      "Epoch 2254, Loss: 8.501601405441761e-05, Final Batch Loss: 2.1136336727067828e-05\n",
      "Epoch 2255, Loss: 0.0002022895496338606, Final Batch Loss: 9.46500149439089e-05\n",
      "Epoch 2256, Loss: 0.00041976914508268237, Final Batch Loss: 0.00026968703605234623\n",
      "Epoch 2257, Loss: 0.00018539497250458226, Final Batch Loss: 3.848135384032503e-05\n",
      "Epoch 2258, Loss: 0.0007748600510240067, Final Batch Loss: 0.0007211032207123935\n",
      "Epoch 2259, Loss: 0.000265354523435235, Final Batch Loss: 9.44542553042993e-05\n",
      "Epoch 2260, Loss: 0.00012714279364445247, Final Batch Loss: 9.618697367841378e-05\n",
      "Epoch 2261, Loss: 0.00016112499724840745, Final Batch Loss: 0.00010225731239188462\n",
      "Epoch 2262, Loss: 0.00026143702780245803, Final Batch Loss: 3.9373375329887494e-05\n",
      "Epoch 2263, Loss: 0.0023692461036262102, Final Batch Loss: 7.587823347421363e-05\n",
      "Epoch 2264, Loss: 0.00018712406381382607, Final Batch Loss: 1.2556683941511437e-05\n",
      "Epoch 2265, Loss: 0.0003600890195230022, Final Batch Loss: 0.0003294657217338681\n",
      "Epoch 2266, Loss: 3.136244868073845e-05, Final Batch Loss: 1.649391015234869e-05\n",
      "Epoch 2267, Loss: 0.00013957284409116255, Final Batch Loss: 0.00013320872676558793\n",
      "Epoch 2268, Loss: 0.0007639469567948254, Final Batch Loss: 2.560606117185671e-05\n",
      "Epoch 2269, Loss: 0.0025706101405376103, Final Batch Loss: 2.0772564312210307e-05\n",
      "Epoch 2270, Loss: 0.006614985395572148, Final Batch Loss: 0.0065778642892837524\n",
      "Epoch 2271, Loss: 0.0014343496004585177, Final Batch Loss: 0.0013256872771307826\n",
      "Epoch 2272, Loss: 0.0002493445481377421, Final Batch Loss: 2.0254125047358684e-05\n",
      "Epoch 2273, Loss: 0.0002829346194630489, Final Batch Loss: 0.00014009323786012828\n",
      "Epoch 2274, Loss: 0.0005604259640676901, Final Batch Loss: 0.0003911590902134776\n",
      "Epoch 2275, Loss: 0.00014262867625802755, Final Batch Loss: 4.182033444521949e-05\n",
      "Epoch 2276, Loss: 4.563256698020268e-05, Final Batch Loss: 1.917297595355194e-05\n",
      "Epoch 2277, Loss: 0.00012896578118670732, Final Batch Loss: 4.998284566681832e-05\n",
      "Epoch 2278, Loss: 7.800473667884944e-05, Final Batch Loss: 6.369283801177517e-05\n",
      "Epoch 2279, Loss: 0.00030691534630022943, Final Batch Loss: 3.922387259081006e-05\n",
      "Epoch 2280, Loss: 0.001508651941549033, Final Batch Loss: 0.00015048490604385734\n",
      "Epoch 2281, Loss: 6.852802562207216e-05, Final Batch Loss: 1.0168908374907915e-05\n",
      "Epoch 2282, Loss: 0.00017438361828681082, Final Batch Loss: 8.555428212275729e-05\n",
      "Epoch 2283, Loss: 0.00019109071581624448, Final Batch Loss: 0.00012407205940689892\n",
      "Epoch 2284, Loss: 0.00035545140599424485, Final Batch Loss: 0.00034466403303667903\n",
      "Epoch 2285, Loss: 0.00015857767812121892, Final Batch Loss: 1.4029342310095672e-05\n",
      "Epoch 2286, Loss: 0.0008604929680586793, Final Batch Loss: 3.104002826148644e-05\n",
      "Epoch 2287, Loss: 2.199060963903321e-05, Final Batch Loss: 4.438416908669751e-06\n",
      "Epoch 2288, Loss: 0.00020138019317528233, Final Batch Loss: 1.8245707906316966e-05\n",
      "Epoch 2289, Loss: 8.012263606360648e-05, Final Batch Loss: 2.3604125090059824e-05\n",
      "Epoch 2290, Loss: 9.444101669942029e-05, Final Batch Loss: 3.3960277505684644e-06\n",
      "Epoch 2291, Loss: 0.001976063234906178, Final Batch Loss: 3.9327416743617505e-05\n",
      "Epoch 2292, Loss: 0.00044589628669200465, Final Batch Loss: 7.048388215480372e-05\n",
      "Epoch 2293, Loss: 0.0002074961994367186, Final Batch Loss: 1.5116125723579898e-05\n",
      "Epoch 2294, Loss: 9.248179412679747e-05, Final Batch Loss: 6.769588799215853e-05\n",
      "Epoch 2295, Loss: 0.0031214179398375563, Final Batch Loss: 0.0030535487458109856\n",
      "Epoch 2296, Loss: 6.122029935795581e-05, Final Batch Loss: 7.721198016952258e-06\n",
      "Epoch 2297, Loss: 0.0033488758199382573, Final Batch Loss: 0.00022810141672380269\n",
      "Epoch 2298, Loss: 0.000595379518927075, Final Batch Loss: 0.0004484458186198026\n",
      "Epoch 2299, Loss: 0.00011524601359269582, Final Batch Loss: 5.8810372138395905e-05\n",
      "Epoch 2300, Loss: 9.500810392637504e-05, Final Batch Loss: 8.929556497605518e-05\n",
      "Epoch 2301, Loss: 0.00018634851949173026, Final Batch Loss: 3.276551069575362e-05\n",
      "Epoch 2302, Loss: 8.416810032940703e-06, Final Batch Loss: 4.346101377450395e-06\n",
      "Epoch 2303, Loss: 0.004189217906969134, Final Batch Loss: 0.004118128214031458\n",
      "Epoch 2304, Loss: 0.00017866162306745537, Final Batch Loss: 5.6124164984794334e-05\n",
      "Epoch 2305, Loss: 0.0002315097262908239, Final Batch Loss: 0.00019676735973916948\n",
      "Epoch 2306, Loss: 7.583073238492943e-05, Final Batch Loss: 3.858346099150367e-05\n",
      "Epoch 2307, Loss: 0.00040088350579026155, Final Batch Loss: 5.953835716354661e-05\n",
      "Epoch 2308, Loss: 0.0007958983769640326, Final Batch Loss: 0.0004205866134725511\n",
      "Epoch 2309, Loss: 0.006375881304848008, Final Batch Loss: 0.006277749314904213\n",
      "Epoch 2310, Loss: 3.6386844840308186e-05, Final Batch Loss: 1.0474522241565865e-05\n",
      "Epoch 2311, Loss: 0.00018153652490582317, Final Batch Loss: 4.887637624051422e-05\n",
      "Epoch 2312, Loss: 2.681605656107422e-05, Final Batch Loss: 2.2528256522491574e-05\n",
      "Epoch 2313, Loss: 0.00023922375203255797, Final Batch Loss: 0.00023182888980954885\n",
      "Epoch 2314, Loss: 0.0005343564407667145, Final Batch Loss: 0.00011687319783959538\n",
      "Epoch 2315, Loss: 0.002451669926813338, Final Batch Loss: 4.000918852398172e-05\n",
      "Epoch 2316, Loss: 0.0008030848380258249, Final Batch Loss: 4.681436166720232e-06\n",
      "Epoch 2317, Loss: 0.003818343218881637, Final Batch Loss: 0.0009526622598059475\n",
      "Epoch 2318, Loss: 4.8139946557057556e-05, Final Batch Loss: 4.0424754843115807e-05\n",
      "Epoch 2319, Loss: 2.8681542971753515e-05, Final Batch Loss: 1.5827270544832572e-05\n",
      "Epoch 2320, Loss: 8.307282769237645e-05, Final Batch Loss: 2.8746722819050774e-05\n",
      "Epoch 2321, Loss: 0.0010100315757881617, Final Batch Loss: 1.6589669030508958e-05\n",
      "Epoch 2322, Loss: 0.00015468442143173888, Final Batch Loss: 4.677847755374387e-05\n",
      "Epoch 2323, Loss: 8.125885187837412e-05, Final Batch Loss: 4.7851976887614e-06\n",
      "Epoch 2324, Loss: 0.00019740213610930368, Final Batch Loss: 2.6475470804143697e-05\n",
      "Epoch 2325, Loss: 7.031516361166723e-05, Final Batch Loss: 6.088907684898004e-05\n",
      "Epoch 2326, Loss: 0.003194490709574893, Final Batch Loss: 0.003138509579002857\n",
      "Epoch 2327, Loss: 0.00044847884419141337, Final Batch Loss: 0.0003464876499492675\n",
      "Epoch 2328, Loss: 0.00017026099340000656, Final Batch Loss: 0.00014264843775890768\n",
      "Epoch 2329, Loss: 0.00012982002954231575, Final Batch Loss: 0.00010534367902437225\n",
      "Epoch 2330, Loss: 9.632772162149195e-05, Final Batch Loss: 7.876975723775104e-05\n",
      "Epoch 2331, Loss: 0.0007793091936036944, Final Batch Loss: 3.2186449971050024e-05\n",
      "Epoch 2332, Loss: 0.0001297992275794968, Final Batch Loss: 7.859497418394312e-05\n",
      "Epoch 2333, Loss: 0.00010450211630086415, Final Batch Loss: 5.418732689577155e-05\n",
      "Epoch 2334, Loss: 0.0002588288134575123, Final Batch Loss: 1.9263849026174285e-05\n",
      "Epoch 2335, Loss: 5.056162171968026e-05, Final Batch Loss: 3.5324294003658e-05\n",
      "Epoch 2336, Loss: 0.0004747903731185943, Final Batch Loss: 0.0002980722638312727\n",
      "Epoch 2337, Loss: 7.5327781814849e-05, Final Batch Loss: 6.703865801682696e-05\n",
      "Epoch 2338, Loss: 0.0001592163898749277, Final Batch Loss: 7.350918895099312e-05\n",
      "Epoch 2339, Loss: 0.0017446783094783314, Final Batch Loss: 4.263729351805523e-05\n",
      "Epoch 2340, Loss: 4.1306465391244274e-05, Final Batch Loss: 8.050576980167534e-06\n",
      "Epoch 2341, Loss: 3.127458148810547e-05, Final Batch Loss: 1.3626548025058582e-05\n",
      "Epoch 2342, Loss: 6.008960917824879e-05, Final Batch Loss: 2.9731130780419335e-05\n",
      "Epoch 2343, Loss: 0.00016696780221536756, Final Batch Loss: 7.50930339563638e-05\n",
      "Epoch 2344, Loss: 0.0006813525924371788, Final Batch Loss: 0.00065564428223297\n",
      "Epoch 2345, Loss: 0.0003376337390363915, Final Batch Loss: 0.0003107191005256027\n",
      "Epoch 2346, Loss: 3.267927831984707e-05, Final Batch Loss: 4.148253083258169e-06\n",
      "Epoch 2347, Loss: 6.534148008086049e-05, Final Batch Loss: 1.0276972943756846e-06\n",
      "Epoch 2348, Loss: 1.2955604688613676e-05, Final Batch Loss: 5.647659236274194e-06\n",
      "Epoch 2349, Loss: 0.000117621966637671, Final Batch Loss: 7.482329965569079e-05\n",
      "Epoch 2350, Loss: 0.00016052096179919317, Final Batch Loss: 7.3679540946614e-05\n",
      "Epoch 2351, Loss: 0.00017417591334378812, Final Batch Loss: 0.00015967595390975475\n",
      "Epoch 2352, Loss: 0.004226856850436889, Final Batch Loss: 0.0041632573120296\n",
      "Epoch 2353, Loss: 0.0016530576831428334, Final Batch Loss: 0.0001249658380402252\n",
      "Epoch 2354, Loss: 3.468213935775566e-05, Final Batch Loss: 1.8791574802889954e-06\n",
      "Epoch 2355, Loss: 0.003214397234842181, Final Batch Loss: 0.0030580167658627033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2356, Loss: 0.0006998217468208168, Final Batch Loss: 2.9026883566984907e-05\n",
      "Epoch 2357, Loss: 0.0036376420248416252, Final Batch Loss: 8.227315993281081e-05\n",
      "Epoch 2358, Loss: 0.00011359558902768185, Final Batch Loss: 1.1957969945797231e-05\n",
      "Epoch 2359, Loss: 0.005041505801727908, Final Batch Loss: 4.2488195504120085e-06\n",
      "Epoch 2360, Loss: 0.00013943828889750876, Final Batch Loss: 9.381490235682577e-05\n",
      "Epoch 2361, Loss: 5.2726129069924355e-05, Final Batch Loss: 8.4047787822783e-06\n",
      "Epoch 2362, Loss: 0.000325894114212133, Final Batch Loss: 0.0002733784494921565\n",
      "Epoch 2363, Loss: 0.0002217144356109202, Final Batch Loss: 8.274086576420814e-05\n",
      "Epoch 2364, Loss: 0.0023472972188756103, Final Batch Loss: 1.5775623978697695e-05\n",
      "Epoch 2365, Loss: 3.6628924135584384e-05, Final Batch Loss: 2.6770059776026756e-05\n",
      "Epoch 2366, Loss: 0.000429377454565838, Final Batch Loss: 0.0001275939284823835\n",
      "Epoch 2367, Loss: 7.00377768225735e-05, Final Batch Loss: 5.9484071243787184e-05\n",
      "Epoch 2368, Loss: 0.00015304247062886134, Final Batch Loss: 1.2892116501461715e-05\n",
      "Epoch 2369, Loss: 0.0003429003154451493, Final Batch Loss: 0.00032446844852529466\n",
      "Epoch 2370, Loss: 5.162043635209557e-05, Final Batch Loss: 2.3793341824784875e-05\n",
      "Epoch 2371, Loss: 1.684907920207479e-05, Final Batch Loss: 3.5138605198881123e-06\n",
      "Epoch 2372, Loss: 0.0022522792278323323, Final Batch Loss: 0.00045749827404506505\n",
      "Epoch 2373, Loss: 0.0001380603207508102, Final Batch Loss: 6.645888061029837e-05\n",
      "Epoch 2374, Loss: 0.00027031157151213847, Final Batch Loss: 0.00023135225637815893\n",
      "Epoch 2375, Loss: 0.00030151157989166677, Final Batch Loss: 0.00014877341163810343\n",
      "Epoch 2376, Loss: 0.0001319518814852927, Final Batch Loss: 4.780522795044817e-05\n",
      "Epoch 2377, Loss: 0.010020684224400611, Final Batch Loss: 2.402585778327193e-06\n",
      "Epoch 2378, Loss: 7.886283492553048e-05, Final Batch Loss: 8.071179763646796e-06\n",
      "Epoch 2379, Loss: 0.0037536347608693177, Final Batch Loss: 2.2954433006816544e-05\n",
      "Epoch 2380, Loss: 5.056604459241498e-05, Final Batch Loss: 2.168467835872434e-05\n",
      "Epoch 2381, Loss: 0.004224932929446368, Final Batch Loss: 0.004219546914100647\n",
      "Epoch 2382, Loss: 0.00021136103168828413, Final Batch Loss: 0.00017468593432568014\n",
      "Epoch 2383, Loss: 0.012514358022599481, Final Batch Loss: 0.012382728978991508\n",
      "Epoch 2384, Loss: 0.0002432877226965502, Final Batch Loss: 0.0001802737097023055\n",
      "Epoch 2385, Loss: 6.60024415992666e-05, Final Batch Loss: 1.8685554096009582e-05\n",
      "Epoch 2386, Loss: 9.408078403794207e-05, Final Batch Loss: 6.008008131175302e-05\n",
      "Epoch 2387, Loss: 0.0045826404966646805, Final Batch Loss: 0.004540722817182541\n",
      "Epoch 2388, Loss: 0.0002156524933525361, Final Batch Loss: 9.959260205505416e-05\n",
      "Epoch 2389, Loss: 0.00033863558201119304, Final Batch Loss: 0.00030543492175638676\n",
      "Epoch 2390, Loss: 0.0022253701754380018, Final Batch Loss: 0.0018856473034247756\n",
      "Epoch 2391, Loss: 0.0010386475951236207, Final Batch Loss: 0.0009871396468952298\n",
      "Epoch 2392, Loss: 0.00016264749319816474, Final Batch Loss: 2.5389288566657342e-05\n",
      "Epoch 2393, Loss: 0.0064597055497870315, Final Batch Loss: 4.4478587369667366e-05\n",
      "Epoch 2394, Loss: 0.00016707159375073388, Final Batch Loss: 3.569994441932067e-05\n",
      "Epoch 2395, Loss: 8.75082400852989e-05, Final Batch Loss: 8.188628271454945e-05\n",
      "Epoch 2396, Loss: 0.000800723322754493, Final Batch Loss: 0.0007851357804611325\n",
      "Epoch 2397, Loss: 1.983969832508592e-05, Final Batch Loss: 1.3264347217045724e-05\n",
      "Epoch 2398, Loss: 0.00048321570648113266, Final Batch Loss: 7.452921272488311e-05\n",
      "Epoch 2399, Loss: 0.00010044547411780513, Final Batch Loss: 3.437706936892937e-06\n",
      "Epoch 2400, Loss: 0.00015529348092968576, Final Batch Loss: 5.540352503885515e-05\n",
      "Epoch 2401, Loss: 2.7629651413008105e-05, Final Batch Loss: 9.648884770285804e-06\n",
      "Epoch 2402, Loss: 0.0001612273126738728, Final Batch Loss: 1.482509196648607e-05\n",
      "Epoch 2403, Loss: 0.001937163160619093, Final Batch Loss: 2.4900986318243667e-05\n",
      "Epoch 2404, Loss: 4.909732524538413e-05, Final Batch Loss: 2.1562342226388864e-05\n",
      "Epoch 2405, Loss: 0.0023291599354706705, Final Batch Loss: 0.0005788079579360783\n",
      "Epoch 2406, Loss: 0.0045980511931702495, Final Batch Loss: 0.004090294241905212\n",
      "Epoch 2407, Loss: 0.0005705623807443772, Final Batch Loss: 0.0005299191107042134\n",
      "Epoch 2408, Loss: 0.00010132733223144896, Final Batch Loss: 4.076725963386707e-05\n",
      "Epoch 2409, Loss: 0.0008842040770105086, Final Batch Loss: 7.396478758892044e-05\n",
      "Epoch 2410, Loss: 0.005741655295423698, Final Batch Loss: 0.005623736418783665\n",
      "Epoch 2411, Loss: 0.0004968912980984896, Final Batch Loss: 0.0004281886504031718\n",
      "Epoch 2412, Loss: 0.0002627602789289085, Final Batch Loss: 2.520278030715417e-05\n",
      "Epoch 2413, Loss: 0.00031247712331605726, Final Batch Loss: 7.545814241893822e-06\n",
      "Epoch 2414, Loss: 5.6940359172585886e-05, Final Batch Loss: 4.670059934142046e-05\n",
      "Epoch 2415, Loss: 5.644365728585399e-05, Final Batch Loss: 5.099149711895734e-05\n",
      "Epoch 2416, Loss: 4.878395156993065e-05, Final Batch Loss: 1.4494265997200273e-05\n",
      "Epoch 2417, Loss: 0.0014517039162456058, Final Batch Loss: 2.8320901037659496e-05\n",
      "Epoch 2418, Loss: 8.095637895166874e-05, Final Batch Loss: 1.1612952221184969e-05\n",
      "Epoch 2419, Loss: 7.126858690753579e-05, Final Batch Loss: 5.255693395156413e-05\n",
      "Epoch 2420, Loss: 5.1785726100206375e-05, Final Batch Loss: 2.4408980607404374e-05\n",
      "Epoch 2421, Loss: 0.00018403567469249538, Final Batch Loss: 0.00018073948740493506\n",
      "Epoch 2422, Loss: 0.0009173434955300763, Final Batch Loss: 0.0008822070667520165\n",
      "Epoch 2423, Loss: 8.615843398729339e-05, Final Batch Loss: 4.975961201125756e-05\n",
      "Epoch 2424, Loss: 3.6049301343155093e-05, Final Batch Loss: 2.497250898159109e-05\n",
      "Epoch 2425, Loss: 7.617429764650296e-05, Final Batch Loss: 4.937201083521359e-06\n",
      "Epoch 2426, Loss: 0.007942393960547633, Final Batch Loss: 0.007704786490648985\n",
      "Epoch 2427, Loss: 8.620128056691101e-05, Final Batch Loss: 7.633773861925874e-07\n",
      "Epoch 2428, Loss: 0.0006533322848554235, Final Batch Loss: 0.0006121084443293512\n",
      "Epoch 2429, Loss: 5.311280801834073e-05, Final Batch Loss: 1.469281232857611e-05\n",
      "Epoch 2430, Loss: 7.661789277335629e-05, Final Batch Loss: 5.188738214201294e-05\n",
      "Epoch 2431, Loss: 0.000765693313041993, Final Batch Loss: 0.0007550359005108476\n",
      "Epoch 2432, Loss: 6.604383270314429e-05, Final Batch Loss: 4.037383769173175e-05\n",
      "Epoch 2433, Loss: 0.0002419668307993561, Final Batch Loss: 0.00010715627286117524\n",
      "Epoch 2434, Loss: 5.5323270316876005e-05, Final Batch Loss: 5.571301699092146e-06\n",
      "Epoch 2435, Loss: 8.446073479717597e-05, Final Batch Loss: 4.709148561232723e-05\n",
      "Epoch 2436, Loss: 0.0001058016496244818, Final Batch Loss: 1.4036835636943579e-05\n",
      "Epoch 2437, Loss: 0.01563501506097964, Final Batch Loss: 1.3822307664668187e-05\n",
      "Epoch 2438, Loss: 0.0001309435592702357, Final Batch Loss: 2.1961181118967943e-05\n",
      "Epoch 2439, Loss: 5.258309829514474e-05, Final Batch Loss: 3.918464426533319e-05\n",
      "Epoch 2440, Loss: 0.0002748882179730572, Final Batch Loss: 0.0002465713187120855\n",
      "Epoch 2441, Loss: 5.487983253260609e-05, Final Batch Loss: 7.728298442088999e-06\n",
      "Epoch 2442, Loss: 9.153819701168686e-05, Final Batch Loss: 3.8091176975285634e-05\n",
      "Epoch 2443, Loss: 0.0005349101411411539, Final Batch Loss: 0.00034157713525928557\n",
      "Epoch 2444, Loss: 0.00034095723822247237, Final Batch Loss: 0.00014823961828369647\n",
      "Epoch 2445, Loss: 0.0034368949418421835, Final Batch Loss: 0.0004601414257194847\n",
      "Epoch 2446, Loss: 0.0002129538552253507, Final Batch Loss: 4.618046659743413e-05\n",
      "Epoch 2447, Loss: 9.677252455730923e-05, Final Batch Loss: 5.915647489018738e-05\n",
      "Epoch 2448, Loss: 0.00016743339801905677, Final Batch Loss: 0.00010513439337955788\n",
      "Epoch 2449, Loss: 0.001134388687205501, Final Batch Loss: 0.0010649178875610232\n",
      "Epoch 2450, Loss: 9.865731590252835e-05, Final Batch Loss: 2.659188066900242e-05\n",
      "Epoch 2451, Loss: 0.00023717147269053385, Final Batch Loss: 4.2747655243147165e-05\n",
      "Epoch 2452, Loss: 0.0010702474537538365, Final Batch Loss: 0.0009926465572789311\n",
      "Epoch 2453, Loss: 0.000631113478448242, Final Batch Loss: 0.0002537835680413991\n",
      "Epoch 2454, Loss: 0.0018039465212495998, Final Batch Loss: 0.0016919246409088373\n",
      "Epoch 2455, Loss: 0.0007569744338979945, Final Batch Loss: 0.00014652857498731464\n",
      "Epoch 2456, Loss: 0.00012263739972695475, Final Batch Loss: 1.2757888725900557e-05\n",
      "Epoch 2457, Loss: 0.0009513510449323803, Final Batch Loss: 0.000500028021633625\n",
      "Epoch 2458, Loss: 0.00016888993195607327, Final Batch Loss: 5.872120163985528e-05\n",
      "Epoch 2459, Loss: 0.0005242185252427589, Final Batch Loss: 0.0005013923509977758\n",
      "Epoch 2460, Loss: 4.159838590567233e-05, Final Batch Loss: 2.8863265470135957e-05\n",
      "Epoch 2461, Loss: 0.003860235257889144, Final Batch Loss: 0.0038420939818024635\n",
      "Epoch 2462, Loss: 0.00018532896501710638, Final Batch Loss: 7.691273640375584e-05\n",
      "Epoch 2463, Loss: 0.00012894231986138038, Final Batch Loss: 9.484964539296925e-05\n",
      "Epoch 2464, Loss: 0.00017527849558973685, Final Batch Loss: 4.625569999916479e-05\n",
      "Epoch 2465, Loss: 0.00017502650007372722, Final Batch Loss: 0.00013849599054083228\n",
      "Epoch 2466, Loss: 0.0003263238104409538, Final Batch Loss: 1.7039004887919873e-05\n",
      "Epoch 2467, Loss: 0.00015366632942459546, Final Batch Loss: 4.286250259610824e-05\n",
      "Epoch 2468, Loss: 0.000652069371426478, Final Batch Loss: 0.00027983635663986206\n",
      "Epoch 2469, Loss: 0.002201766474172473, Final Batch Loss: 0.0004440764896571636\n",
      "Epoch 2470, Loss: 0.0001195078766613733, Final Batch Loss: 8.40257853269577e-05\n",
      "Epoch 2471, Loss: 7.976407687237952e-05, Final Batch Loss: 2.065143962681759e-05\n",
      "Epoch 2472, Loss: 0.00022018478193785995, Final Batch Loss: 6.55691692372784e-05\n",
      "Epoch 2473, Loss: 0.00014035495405551046, Final Batch Loss: 5.2690076699946076e-05\n",
      "Epoch 2474, Loss: 0.00021408881002571434, Final Batch Loss: 0.00011559222912183031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2475, Loss: 0.0004077118937857449, Final Batch Loss: 0.00013719242997467518\n",
      "Epoch 2476, Loss: 8.55893249536166e-05, Final Batch Loss: 2.4210808987845667e-05\n",
      "Epoch 2477, Loss: 0.000494630843604682, Final Batch Loss: 1.364211129839532e-05\n",
      "Epoch 2478, Loss: 0.00012690058611042332, Final Batch Loss: 2.8664891942753457e-05\n",
      "Epoch 2479, Loss: 0.00021664887754013762, Final Batch Loss: 8.67367853061296e-05\n",
      "Epoch 2480, Loss: 0.10234571079490706, Final Batch Loss: 0.10203959792852402\n",
      "Epoch 2481, Loss: 0.0035556795046431944, Final Batch Loss: 6.931489042472094e-05\n",
      "Epoch 2482, Loss: 4.242605587023718e-05, Final Batch Loss: 3.567127123460523e-06\n",
      "Epoch 2483, Loss: 0.00048096618411364034, Final Batch Loss: 0.00041868892731145024\n",
      "Epoch 2484, Loss: 7.679583177377935e-05, Final Batch Loss: 1.575362512085121e-05\n",
      "Epoch 2485, Loss: 0.00052251061424613, Final Batch Loss: 0.00035198693512938917\n",
      "Epoch 2486, Loss: 4.025134148832876e-05, Final Batch Loss: 6.81805431668181e-06\n",
      "Epoch 2487, Loss: 9.681223309598863e-05, Final Batch Loss: 6.42404702375643e-05\n",
      "Epoch 2488, Loss: 0.01354117329174187, Final Batch Loss: 0.00013038991892244667\n",
      "Epoch 2489, Loss: 6.678299541817978e-05, Final Batch Loss: 5.661392060574144e-05\n",
      "Epoch 2490, Loss: 0.021768802696897183, Final Batch Loss: 3.200202627340332e-05\n",
      "Epoch 2491, Loss: 0.008326438430231065, Final Batch Loss: 0.0006110940012149513\n",
      "Epoch 2492, Loss: 0.0018918042514997069, Final Batch Loss: 3.376472523086704e-05\n",
      "Epoch 2493, Loss: 0.05420305111329071, Final Batch Loss: 0.0537177138030529\n",
      "Epoch 2494, Loss: 0.007773842367896577, Final Batch Loss: 2.442736513330601e-05\n",
      "Epoch 2495, Loss: 0.04742841752431559, Final Batch Loss: 0.04741520434617996\n",
      "Epoch 2496, Loss: 0.00022029247338650748, Final Batch Loss: 5.584306927630678e-05\n",
      "Epoch 2497, Loss: 3.1430121225639596e-05, Final Batch Loss: 2.6017148684331914e-06\n",
      "Epoch 2498, Loss: 0.00010056434257421643, Final Batch Loss: 5.582046287599951e-05\n",
      "Epoch 2499, Loss: 0.0024553800976718776, Final Batch Loss: 8.914648060454056e-05\n",
      "Epoch 2500, Loss: 0.00011818038819910726, Final Batch Loss: 8.90441060619196e-06\n",
      "Epoch 2501, Loss: 0.00014969475523685105, Final Batch Loss: 9.40900863497518e-05\n",
      "Epoch 2502, Loss: 5.1590221119113266e-05, Final Batch Loss: 3.003378697030712e-05\n",
      "Epoch 2503, Loss: 0.0004427798558026552, Final Batch Loss: 0.00025557243498042226\n",
      "Epoch 2504, Loss: 0.0010931621836789418, Final Batch Loss: 4.312543387641199e-05\n",
      "Epoch 2505, Loss: 0.0006553799175890163, Final Batch Loss: 0.0005604391335509717\n",
      "Epoch 2506, Loss: 0.000614884978858754, Final Batch Loss: 0.00042798888171091676\n",
      "Epoch 2507, Loss: 0.00042963100713677704, Final Batch Loss: 0.00017381174257025123\n",
      "Epoch 2508, Loss: 0.00038368946115951985, Final Batch Loss: 0.0003611849097069353\n",
      "Epoch 2509, Loss: 0.00010670157280401327, Final Batch Loss: 6.0808288253610954e-05\n",
      "Epoch 2510, Loss: 0.0002454702553222887, Final Batch Loss: 0.00013953473535366356\n",
      "Epoch 2511, Loss: 0.00021156519505893812, Final Batch Loss: 9.42553233471699e-05\n",
      "Epoch 2512, Loss: 0.0002402786249149358, Final Batch Loss: 2.669782224984374e-05\n",
      "Epoch 2513, Loss: 0.0004961453232681379, Final Batch Loss: 0.0001598096132511273\n",
      "Epoch 2514, Loss: 0.0004640354309231043, Final Batch Loss: 9.957101428881288e-05\n",
      "Epoch 2515, Loss: 0.0006222173178684898, Final Batch Loss: 0.0005317511968314648\n",
      "Epoch 2516, Loss: 0.000287182760075666, Final Batch Loss: 8.042810077313334e-05\n",
      "Epoch 2517, Loss: 0.00045179916560300626, Final Batch Loss: 0.00041216000681743026\n",
      "Epoch 2518, Loss: 0.00035414683225099, Final Batch Loss: 0.0001730837393552065\n",
      "Epoch 2519, Loss: 0.0007136730928323232, Final Batch Loss: 0.0006080088787712157\n",
      "Epoch 2520, Loss: 0.00022473016360891052, Final Batch Loss: 3.2043772080214694e-05\n",
      "Epoch 2521, Loss: 0.0024865380182745866, Final Batch Loss: 8.920614345697686e-05\n",
      "Epoch 2522, Loss: 8.96914025361184e-05, Final Batch Loss: 3.469353396212682e-05\n",
      "Epoch 2523, Loss: 0.000519942506798543, Final Batch Loss: 0.0004843073256779462\n",
      "Epoch 2524, Loss: 0.007044066675007343, Final Batch Loss: 0.0024591065011918545\n",
      "Epoch 2525, Loss: 0.00034050980502797756, Final Batch Loss: 0.00031990130082704127\n",
      "Epoch 2526, Loss: 0.0003157571773044765, Final Batch Loss: 0.00015111247193999588\n",
      "Epoch 2527, Loss: 0.00033793222974054515, Final Batch Loss: 0.00023796060122549534\n",
      "Epoch 2528, Loss: 0.00041397433960810304, Final Batch Loss: 0.00021785928402096033\n",
      "Epoch 2529, Loss: 0.0006978103774599731, Final Batch Loss: 0.0005053466884419322\n",
      "Epoch 2530, Loss: 0.00014134313460090198, Final Batch Loss: 5.012478868593462e-05\n",
      "Epoch 2531, Loss: 4.207613346807193e-05, Final Batch Loss: 2.3452874302165583e-05\n",
      "Epoch 2532, Loss: 0.00026905135018751025, Final Batch Loss: 0.00010977557394653559\n",
      "Epoch 2533, Loss: 0.0003812997820205055, Final Batch Loss: 0.0003314531350042671\n",
      "Epoch 2534, Loss: 0.004639779275748879, Final Batch Loss: 0.00028649071464315057\n",
      "Epoch 2535, Loss: 0.00030272331059677526, Final Batch Loss: 0.00010484526137588546\n",
      "Epoch 2536, Loss: 0.0006128783934400417, Final Batch Loss: 0.0005891125765629113\n",
      "Epoch 2537, Loss: 0.0019288047078589443, Final Batch Loss: 0.0018872418440878391\n",
      "Epoch 2538, Loss: 6.708271575917024e-05, Final Batch Loss: 2.9058990548946895e-05\n",
      "Epoch 2539, Loss: 0.00016085523020592518, Final Batch Loss: 5.9033922298112884e-05\n",
      "Epoch 2540, Loss: 0.000698846037266776, Final Batch Loss: 0.0005240285536274314\n",
      "Epoch 2541, Loss: 0.00019520723435562104, Final Batch Loss: 7.231526251416653e-05\n",
      "Epoch 2542, Loss: 0.005535405973205343, Final Batch Loss: 0.0003673093451652676\n",
      "Epoch 2543, Loss: 0.00047830470430199057, Final Batch Loss: 0.00031555088935419917\n",
      "Epoch 2544, Loss: 0.000219645236938959, Final Batch Loss: 5.520695049199276e-05\n",
      "Epoch 2545, Loss: 0.0002864187699742615, Final Batch Loss: 6.303517147898674e-05\n",
      "Epoch 2546, Loss: 8.354481542482972e-05, Final Batch Loss: 5.292894275044091e-05\n",
      "Epoch 2547, Loss: 0.0003775459190364927, Final Batch Loss: 0.00013705287710763514\n",
      "Epoch 2548, Loss: 6.27974804956466e-05, Final Batch Loss: 4.0432023524772376e-05\n",
      "Epoch 2549, Loss: 0.0001485316315665841, Final Batch Loss: 0.00011543696746230125\n",
      "Epoch 2550, Loss: 0.009040944278240204, Final Batch Loss: 0.0034995530731976032\n",
      "Epoch 2551, Loss: 0.00020188749476801604, Final Batch Loss: 7.723229646217078e-05\n",
      "Epoch 2552, Loss: 0.002675766751053743, Final Batch Loss: 0.00013440677139442414\n",
      "Epoch 2553, Loss: 0.0001362392576993443, Final Batch Loss: 6.560721521964297e-05\n",
      "Epoch 2554, Loss: 0.0001566417486174032, Final Batch Loss: 3.477336576906964e-05\n",
      "Epoch 2555, Loss: 0.0011180576984770596, Final Batch Loss: 0.0005560147692449391\n",
      "Epoch 2556, Loss: 0.0026219219507765956, Final Batch Loss: 6.424031016649678e-05\n",
      "Epoch 2557, Loss: 7.081925286911428e-05, Final Batch Loss: 4.998028089175932e-05\n",
      "Epoch 2558, Loss: 0.0004942304403812159, Final Batch Loss: 0.0004734908288810402\n",
      "Epoch 2559, Loss: 9.545507782604545e-05, Final Batch Loss: 4.927325790049508e-05\n",
      "Epoch 2560, Loss: 0.00018367897428106517, Final Batch Loss: 6.095899152569473e-05\n",
      "Epoch 2561, Loss: 0.001546828425489366, Final Batch Loss: 6.555241998285055e-05\n",
      "Epoch 2562, Loss: 9.072444663615897e-05, Final Batch Loss: 3.5946155549027026e-05\n",
      "Epoch 2563, Loss: 0.00031847183345234953, Final Batch Loss: 9.258506906917319e-06\n",
      "Epoch 2564, Loss: 0.0004316404811106622, Final Batch Loss: 0.0001386426156386733\n",
      "Epoch 2565, Loss: 2.7943428449361818e-05, Final Batch Loss: 7.067243586789118e-06\n",
      "Epoch 2566, Loss: 0.0003987551826867275, Final Batch Loss: 0.0001104741168092005\n",
      "Epoch 2567, Loss: 0.00010506454236747231, Final Batch Loss: 2.6908031941275112e-05\n",
      "Epoch 2568, Loss: 7.601239667565096e-05, Final Batch Loss: 2.9779099349980243e-05\n",
      "Epoch 2569, Loss: 0.0007374760753009468, Final Batch Loss: 0.00013726207544095814\n",
      "Epoch 2570, Loss: 0.0009447434858884662, Final Batch Loss: 6.391669739969075e-05\n",
      "Epoch 2571, Loss: 6.94932332407916e-05, Final Batch Loss: 5.4199426813283935e-05\n",
      "Epoch 2572, Loss: 0.00012086444257874973, Final Batch Loss: 2.2355441615218297e-05\n",
      "Epoch 2573, Loss: 0.00017798021872295067, Final Batch Loss: 4.699650889961049e-05\n",
      "Epoch 2574, Loss: 0.00020077740191482008, Final Batch Loss: 0.00010562700481386855\n",
      "Epoch 2575, Loss: 0.002656140182807576, Final Batch Loss: 3.653211024357006e-05\n",
      "Epoch 2576, Loss: 0.00016848245832079556, Final Batch Loss: 8.200169759220444e-06\n",
      "Epoch 2577, Loss: 0.00020326186859165318, Final Batch Loss: 0.0001739084254950285\n",
      "Epoch 2578, Loss: 0.00015566636648145504, Final Batch Loss: 0.00013456375745590776\n",
      "Epoch 2579, Loss: 0.010337134954170324, Final Batch Loss: 0.010193401016294956\n",
      "Epoch 2580, Loss: 0.004578437437885441, Final Batch Loss: 0.004396299831569195\n",
      "Epoch 2581, Loss: 0.018721453903708607, Final Batch Loss: 0.00026262743631377816\n",
      "Epoch 2582, Loss: 7.60151324357139e-05, Final Batch Loss: 6.046674388926476e-05\n",
      "Epoch 2583, Loss: 0.00020477852376643568, Final Batch Loss: 3.394280793145299e-05\n",
      "Epoch 2584, Loss: 0.000570297401282005, Final Batch Loss: 0.00021445339370984584\n",
      "Epoch 2585, Loss: 0.0028326061874395236, Final Batch Loss: 0.00019926343520637602\n",
      "Epoch 2586, Loss: 0.0001350083402940072, Final Batch Loss: 7.547991845058277e-05\n",
      "Epoch 2587, Loss: 0.00012589083416969515, Final Batch Loss: 4.0088114474201575e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2588, Loss: 8.368963244720362e-05, Final Batch Loss: 4.056494071846828e-05\n",
      "Epoch 2589, Loss: 0.00019782201707130298, Final Batch Loss: 8.756433089729398e-05\n",
      "Epoch 2590, Loss: 0.0004036372702103108, Final Batch Loss: 0.0002764424425549805\n",
      "Epoch 2591, Loss: 4.4891656216350384e-05, Final Batch Loss: 2.1055004253867082e-05\n",
      "Epoch 2592, Loss: 0.0004475557361729443, Final Batch Loss: 0.0003713385376613587\n",
      "Epoch 2593, Loss: 0.003819253408437362, Final Batch Loss: 0.0037691215984523296\n",
      "Epoch 2594, Loss: 0.00017348416622553486, Final Batch Loss: 1.8046530385618098e-05\n",
      "Epoch 2595, Loss: 0.00043804362940136343, Final Batch Loss: 0.0002671342226676643\n",
      "Epoch 2596, Loss: 0.00016123025852721184, Final Batch Loss: 8.973261719802395e-05\n",
      "Epoch 2597, Loss: 0.0003952856932301074, Final Batch Loss: 0.0003336128720548004\n",
      "Epoch 2598, Loss: 0.00014241992175811902, Final Batch Loss: 7.915528112789616e-05\n",
      "Epoch 2599, Loss: 0.00014598744382965378, Final Batch Loss: 3.7208879803074524e-05\n",
      "Epoch 2600, Loss: 0.0004242539289407432, Final Batch Loss: 0.00026817378238774836\n",
      "Epoch 2601, Loss: 0.00020333192696853075, Final Batch Loss: 2.85738587990636e-05\n",
      "Epoch 2602, Loss: 0.00026153034559683874, Final Batch Loss: 3.20529579767026e-05\n",
      "Epoch 2603, Loss: 3.4410175430821255e-05, Final Batch Loss: 1.786398388503585e-05\n",
      "Epoch 2604, Loss: 5.316557508194819e-05, Final Batch Loss: 1.3305361790116876e-05\n",
      "Epoch 2605, Loss: 0.007606759503687499, Final Batch Loss: 4.323322718846612e-05\n",
      "Epoch 2606, Loss: 0.00021312235276127467, Final Batch Loss: 8.15926705399761e-06\n",
      "Epoch 2607, Loss: 0.00021654733427567407, Final Batch Loss: 0.00019605331181082875\n",
      "Epoch 2608, Loss: 0.0007420784968417138, Final Batch Loss: 0.00012695658369921148\n",
      "Epoch 2609, Loss: 0.0023086400324245915, Final Batch Loss: 0.0002001848624786362\n",
      "Epoch 2610, Loss: 6.600815504498314e-05, Final Batch Loss: 1.961465932254214e-05\n",
      "Epoch 2611, Loss: 0.0006138746539363638, Final Batch Loss: 0.0002086101012537256\n",
      "Epoch 2612, Loss: 0.00160015701840166, Final Batch Loss: 0.001402177382260561\n",
      "Epoch 2613, Loss: 0.0005587901687249541, Final Batch Loss: 0.0004314637335482985\n",
      "Epoch 2614, Loss: 0.0007953558306326158, Final Batch Loss: 0.000685262493789196\n",
      "Epoch 2615, Loss: 0.0015061506710480899, Final Batch Loss: 0.0004731553781311959\n",
      "Epoch 2616, Loss: 0.0038539298257092014, Final Batch Loss: 0.00013150869926903397\n",
      "Epoch 2617, Loss: 0.0027990063244942576, Final Batch Loss: 0.000487595476442948\n",
      "Epoch 2618, Loss: 0.00034100437915185466, Final Batch Loss: 9.793831122806296e-05\n",
      "Epoch 2619, Loss: 0.00044742043246515095, Final Batch Loss: 7.52689375076443e-05\n",
      "Epoch 2620, Loss: 0.0005772796575911343, Final Batch Loss: 0.00029143859865143895\n",
      "Epoch 2621, Loss: 0.0002673569179023616, Final Batch Loss: 0.00016088421398308128\n",
      "Epoch 2622, Loss: 0.0007385635399259627, Final Batch Loss: 0.00028421165188774467\n",
      "Epoch 2623, Loss: 0.0005577149422606453, Final Batch Loss: 0.00014891063619870692\n",
      "Epoch 2624, Loss: 0.004737349430797622, Final Batch Loss: 0.0001434788282494992\n",
      "Epoch 2625, Loss: 0.0010183986232732423, Final Batch Loss: 6.144319922896102e-05\n",
      "Epoch 2626, Loss: 0.0001631772865948733, Final Batch Loss: 3.887347338604741e-05\n",
      "Epoch 2627, Loss: 0.0002812195525621064, Final Batch Loss: 0.00010731949441833422\n",
      "Epoch 2628, Loss: 0.0007232261486933567, Final Batch Loss: 0.0006035762489773333\n",
      "Epoch 2629, Loss: 0.0010926683025900275, Final Batch Loss: 0.00017947485321201384\n",
      "Epoch 2630, Loss: 0.0002535356288717594, Final Batch Loss: 5.318357943906449e-05\n",
      "Epoch 2631, Loss: 0.00024118589499266818, Final Batch Loss: 9.720086382003501e-05\n",
      "Epoch 2632, Loss: 0.00040861581510398537, Final Batch Loss: 0.00018834826187230647\n",
      "Epoch 2633, Loss: 0.00022232174524106085, Final Batch Loss: 0.000144542456837371\n",
      "Epoch 2634, Loss: 0.0002148188314095023, Final Batch Loss: 8.605357834312599e-06\n",
      "Epoch 2635, Loss: 0.00024334412228199653, Final Batch Loss: 0.0001924799580592662\n",
      "Epoch 2636, Loss: 0.0001326568344666157, Final Batch Loss: 1.6746151231927797e-05\n",
      "Epoch 2637, Loss: 0.002440596610540524, Final Batch Loss: 9.57687443587929e-05\n",
      "Epoch 2638, Loss: 0.00048778613563627005, Final Batch Loss: 0.0003298165975138545\n",
      "Epoch 2639, Loss: 9.242124542652164e-05, Final Batch Loss: 6.559801113326102e-05\n",
      "Epoch 2640, Loss: 0.00045891531408415176, Final Batch Loss: 4.936624100082554e-05\n",
      "Epoch 2641, Loss: 0.00019693712965818122, Final Batch Loss: 6.09743656241335e-05\n",
      "Epoch 2642, Loss: 0.0001979239023057744, Final Batch Loss: 8.78030841704458e-05\n",
      "Epoch 2643, Loss: 0.00020566209059325047, Final Batch Loss: 0.00014465078129433095\n",
      "Epoch 2644, Loss: 0.00010428390305605717, Final Batch Loss: 3.159968400723301e-05\n",
      "Epoch 2645, Loss: 0.00031863286858424544, Final Batch Loss: 9.300177043769509e-05\n",
      "Epoch 2646, Loss: 0.00013935247079643887, Final Batch Loss: 2.9414868549793027e-05\n",
      "Epoch 2647, Loss: 0.00026773659919854254, Final Batch Loss: 0.0001500221696915105\n",
      "Epoch 2648, Loss: 0.0002223314077127725, Final Batch Loss: 0.00016898257308639586\n",
      "Epoch 2649, Loss: 8.57298846312915e-05, Final Batch Loss: 7.202666165539995e-05\n",
      "Epoch 2650, Loss: 0.0004503272721194662, Final Batch Loss: 0.000388546526664868\n",
      "Epoch 2651, Loss: 0.0002270340410177596, Final Batch Loss: 0.00016912021965254098\n",
      "Epoch 2652, Loss: 0.0006839588459115475, Final Batch Loss: 0.0005898440140299499\n",
      "Epoch 2653, Loss: 0.00011658517905743793, Final Batch Loss: 4.0377446566708386e-05\n",
      "Epoch 2654, Loss: 6.430701796489302e-05, Final Batch Loss: 3.4718923416221514e-05\n",
      "Epoch 2655, Loss: 6.563331226061564e-05, Final Batch Loss: 3.743062188732438e-05\n",
      "Epoch 2656, Loss: 0.0001691776324150851, Final Batch Loss: 0.0001485849206801504\n",
      "Epoch 2657, Loss: 0.000175044136994984, Final Batch Loss: 8.527726458851248e-05\n",
      "Epoch 2658, Loss: 0.00024929543724283576, Final Batch Loss: 0.0002039357350440696\n",
      "Epoch 2659, Loss: 0.0003461413816694403, Final Batch Loss: 2.5848255972960033e-05\n",
      "Epoch 2660, Loss: 0.00015497776985284872, Final Batch Loss: 5.370737562770955e-05\n",
      "Epoch 2661, Loss: 0.00014212646783562377, Final Batch Loss: 6.535377906402573e-05\n",
      "Epoch 2662, Loss: 0.00012419155973475426, Final Batch Loss: 7.509323040721938e-05\n",
      "Epoch 2663, Loss: 0.001175810077256756, Final Batch Loss: 4.889905176241882e-05\n",
      "Epoch 2664, Loss: 0.00011380503747204784, Final Batch Loss: 2.5654504497651942e-05\n",
      "Epoch 2665, Loss: 8.74752313393401e-05, Final Batch Loss: 6.191302963998169e-05\n",
      "Epoch 2666, Loss: 0.00019265394439571537, Final Batch Loss: 0.00013779573782812804\n",
      "Epoch 2667, Loss: 0.00022819559671916068, Final Batch Loss: 0.00015667655679862946\n",
      "Epoch 2668, Loss: 0.00010844116695807315, Final Batch Loss: 7.440269837388769e-05\n",
      "Epoch 2669, Loss: 8.307111784233712e-05, Final Batch Loss: 4.957892815582454e-05\n",
      "Epoch 2670, Loss: 9.676740955910645e-05, Final Batch Loss: 4.8553385568084195e-05\n",
      "Epoch 2671, Loss: 0.00010506215039640665, Final Batch Loss: 5.7165674661519006e-05\n",
      "Epoch 2672, Loss: 0.00018908562924480066, Final Batch Loss: 0.0001442395441699773\n",
      "Epoch 2673, Loss: 0.001293797031394206, Final Batch Loss: 8.398199861403555e-05\n",
      "Epoch 2674, Loss: 0.00010295472020516172, Final Batch Loss: 4.3800486309919506e-05\n",
      "Epoch 2675, Loss: 0.0004247818360454403, Final Batch Loss: 0.0003730647440534085\n",
      "Epoch 2676, Loss: 0.00013394493907981087, Final Batch Loss: 1.6175285054487176e-05\n",
      "Epoch 2677, Loss: 0.00014053746781428345, Final Batch Loss: 9.648715058574453e-05\n",
      "Epoch 2678, Loss: 0.0003177662001689896, Final Batch Loss: 0.00028861023019999266\n",
      "Epoch 2679, Loss: 0.00030862027779221535, Final Batch Loss: 8.321052882820368e-05\n",
      "Epoch 2680, Loss: 0.00021586360526271164, Final Batch Loss: 3.9201477193273604e-05\n",
      "Epoch 2681, Loss: 0.00041924502147594467, Final Batch Loss: 0.0003465561312623322\n",
      "Epoch 2682, Loss: 0.0001268471169169061, Final Batch Loss: 4.0556384192314e-05\n",
      "Epoch 2683, Loss: 0.00017690119057078846, Final Batch Loss: 3.770110561163165e-05\n",
      "Epoch 2684, Loss: 0.00048481423800694756, Final Batch Loss: 5.144237002241425e-05\n",
      "Epoch 2685, Loss: 0.00013016361117479391, Final Batch Loss: 4.48896644229535e-05\n",
      "Epoch 2686, Loss: 0.0002718671239563264, Final Batch Loss: 4.896552854916081e-05\n",
      "Epoch 2687, Loss: 6.725549064867664e-05, Final Batch Loss: 3.048254620807711e-05\n",
      "Epoch 2688, Loss: 0.00043884389560844284, Final Batch Loss: 0.0004190831386949867\n",
      "Epoch 2689, Loss: 0.0003363045834703371, Final Batch Loss: 0.00027179712196812034\n",
      "Epoch 2690, Loss: 0.0003614144225139171, Final Batch Loss: 0.00024101267626974732\n",
      "Epoch 2691, Loss: 0.0001247789987246506, Final Batch Loss: 4.8435002099722624e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2692, Loss: 0.000280576040950109, Final Batch Loss: 6.529309303004993e-06\n",
      "Epoch 2693, Loss: 0.0033584180746402126, Final Batch Loss: 2.4076736735878512e-05\n",
      "Epoch 2694, Loss: 0.00010413075051474152, Final Batch Loss: 8.89394577825442e-05\n",
      "Epoch 2695, Loss: 0.0003231028968002647, Final Batch Loss: 9.42698388826102e-05\n",
      "Epoch 2696, Loss: 0.0036327032139524817, Final Batch Loss: 0.0021743334364145994\n",
      "Epoch 2697, Loss: 0.0006269423247431405, Final Batch Loss: 8.369069109903648e-05\n",
      "Epoch 2698, Loss: 4.533004448603606e-05, Final Batch Loss: 7.660447408852633e-06\n",
      "Epoch 2699, Loss: 0.00039088747871574014, Final Batch Loss: 0.00018716964405030012\n",
      "Epoch 2700, Loss: 0.00016914545994950458, Final Batch Loss: 9.402680007042363e-05\n",
      "Epoch 2701, Loss: 0.00017927278531715274, Final Batch Loss: 1.263157173525542e-05\n",
      "Epoch 2702, Loss: 0.00015977953080437146, Final Batch Loss: 5.749636693508364e-05\n",
      "Epoch 2703, Loss: 0.0023372603236566647, Final Batch Loss: 8.44445366965374e-06\n",
      "Epoch 2704, Loss: 0.00010526225014473312, Final Batch Loss: 3.8032758311601356e-05\n",
      "Epoch 2705, Loss: 9.007540938910097e-05, Final Batch Loss: 6.256718916120008e-05\n",
      "Epoch 2706, Loss: 5.870169206900755e-05, Final Batch Loss: 1.1309087312838528e-05\n",
      "Epoch 2707, Loss: 0.0021153452689759433, Final Batch Loss: 9.176030289381742e-06\n",
      "Epoch 2708, Loss: 6.417154327209573e-05, Final Batch Loss: 4.74943190056365e-05\n",
      "Epoch 2709, Loss: 0.0033652002148301108, Final Batch Loss: 2.3930768293212168e-05\n",
      "Epoch 2710, Loss: 0.00037758733014925383, Final Batch Loss: 4.620945765054785e-05\n",
      "Epoch 2711, Loss: 0.0001009063380479347, Final Batch Loss: 4.270604767953046e-05\n",
      "Epoch 2712, Loss: 0.0006180949785630219, Final Batch Loss: 1.7605947505217046e-05\n",
      "Epoch 2713, Loss: 5.965547279629391e-05, Final Batch Loss: 1.0476023817318492e-05\n",
      "Epoch 2714, Loss: 0.00029232885572128, Final Batch Loss: 0.00020772949210368097\n",
      "Epoch 2715, Loss: 4.6772396672167815e-05, Final Batch Loss: 2.3149063054006547e-05\n",
      "Epoch 2716, Loss: 2.363446674280567e-05, Final Batch Loss: 6.8387189458007924e-06\n",
      "Epoch 2717, Loss: 0.0006005393370287493, Final Batch Loss: 0.00017876566562335938\n",
      "Epoch 2718, Loss: 0.00026589995104586706, Final Batch Loss: 0.00016217985830735415\n",
      "Epoch 2719, Loss: 0.007084035994921578, Final Batch Loss: 3.231710797990672e-05\n",
      "Epoch 2720, Loss: 0.00012253782915649936, Final Batch Loss: 5.957244138699025e-05\n",
      "Epoch 2721, Loss: 0.00013035411029704846, Final Batch Loss: 7.462717621820047e-05\n",
      "Epoch 2722, Loss: 0.0013042927857895847, Final Batch Loss: 4.0543465729570016e-05\n",
      "Epoch 2723, Loss: 4.285511295165634e-05, Final Batch Loss: 2.989190943480935e-05\n",
      "Epoch 2724, Loss: 0.0004048729460919276, Final Batch Loss: 0.0003279997908975929\n",
      "Epoch 2725, Loss: 0.0002938114485004917, Final Batch Loss: 0.0002612538810353726\n",
      "Epoch 2726, Loss: 0.0003906846686732024, Final Batch Loss: 4.8223650082945824e-05\n",
      "Epoch 2727, Loss: 9.126134045800427e-05, Final Batch Loss: 8.020875975489616e-05\n",
      "Epoch 2728, Loss: 0.0001504083484178409, Final Batch Loss: 7.176843791967258e-05\n",
      "Epoch 2729, Loss: 9.56484464040841e-05, Final Batch Loss: 8.851686288835481e-05\n",
      "Epoch 2730, Loss: 0.0009300784713559551, Final Batch Loss: 1.5913245078991167e-05\n",
      "Epoch 2731, Loss: 0.005433120299130678, Final Batch Loss: 0.0023677668068557978\n",
      "Epoch 2732, Loss: 0.0045098989830876235, Final Batch Loss: 4.223842188366689e-05\n",
      "Epoch 2733, Loss: 4.751303458760958e-05, Final Batch Loss: 2.2214551790966652e-05\n",
      "Epoch 2734, Loss: 4.998895929020364e-05, Final Batch Loss: 2.156953269150108e-05\n",
      "Epoch 2735, Loss: 0.005502793937921524, Final Batch Loss: 0.0032906890846788883\n",
      "Epoch 2736, Loss: 9.138486916526745e-05, Final Batch Loss: 2.947452458101907e-06\n",
      "Epoch 2737, Loss: 0.00011396784975659102, Final Batch Loss: 8.151904330588877e-05\n",
      "Epoch 2738, Loss: 0.0020084203279111534, Final Batch Loss: 7.3887931648641825e-06\n",
      "Epoch 2739, Loss: 0.00015269521827576682, Final Batch Loss: 8.417528442805633e-05\n",
      "Epoch 2740, Loss: 0.00020799973572138697, Final Batch Loss: 0.00010848470265045762\n",
      "Epoch 2741, Loss: 0.011465363670140505, Final Batch Loss: 0.009986216202378273\n",
      "Epoch 2742, Loss: 0.00040219959191745147, Final Batch Loss: 9.819928527576849e-05\n",
      "Epoch 2743, Loss: 0.00010964915054501034, Final Batch Loss: 3.3749147405615076e-05\n",
      "Epoch 2744, Loss: 6.99669799359981e-05, Final Batch Loss: 3.8434223824879155e-05\n",
      "Epoch 2745, Loss: 0.004571592317006434, Final Batch Loss: 2.4458740881527774e-05\n",
      "Epoch 2746, Loss: 0.017540622064188938, Final Batch Loss: 0.01752016320824623\n",
      "Epoch 2747, Loss: 0.000573364071897231, Final Batch Loss: 0.00010420325270388275\n",
      "Epoch 2748, Loss: 6.412866059690714e-05, Final Batch Loss: 4.0472503314958885e-05\n",
      "Epoch 2749, Loss: 0.0018075818152283318, Final Batch Loss: 0.001696697436273098\n",
      "Epoch 2750, Loss: 0.00035239516364526935, Final Batch Loss: 0.00031822637538425624\n",
      "Epoch 2751, Loss: 6.189913983689621e-05, Final Batch Loss: 3.239577199565247e-05\n",
      "Epoch 2752, Loss: 0.00011534237546584336, Final Batch Loss: 1.27147168313968e-05\n",
      "Epoch 2753, Loss: 9.789750765776262e-05, Final Batch Loss: 3.929756712750532e-05\n",
      "Epoch 2754, Loss: 0.057660096063045785, Final Batch Loss: 1.7028971342369914e-05\n",
      "Epoch 2755, Loss: 0.0006459175492636859, Final Batch Loss: 0.0003171661519445479\n",
      "Epoch 2756, Loss: 0.043662574142217636, Final Batch Loss: 0.032356008887290955\n",
      "Epoch 2757, Loss: 0.0007905137172201648, Final Batch Loss: 0.0006515667191706598\n",
      "Epoch 2758, Loss: 0.022692773505696096, Final Batch Loss: 0.00012151339615229517\n",
      "Epoch 2759, Loss: 0.00030227449315134436, Final Batch Loss: 0.00015402970893774182\n",
      "Epoch 2760, Loss: 0.0008227737562265247, Final Batch Loss: 0.0007290260400623083\n",
      "Epoch 2761, Loss: 0.0004965501866536215, Final Batch Loss: 0.00030145596247166395\n",
      "Epoch 2762, Loss: 0.04385746829211712, Final Batch Loss: 0.01746267080307007\n",
      "Epoch 2763, Loss: 0.0010714925301726907, Final Batch Loss: 0.0006381321582011878\n",
      "Epoch 2764, Loss: 0.0022296113602351397, Final Batch Loss: 0.0019823911134153605\n",
      "Epoch 2765, Loss: 0.00037261323450366035, Final Batch Loss: 0.0001089031356968917\n",
      "Epoch 2766, Loss: 0.00029797501338180155, Final Batch Loss: 0.00015488119970541447\n",
      "Epoch 2767, Loss: 0.0006855802785139531, Final Batch Loss: 0.00042895463411696255\n",
      "Epoch 2768, Loss: 0.0009038404677994549, Final Batch Loss: 0.0006957646110095084\n",
      "Epoch 2769, Loss: 0.000248100081080338, Final Batch Loss: 0.00019747803162317723\n",
      "Epoch 2770, Loss: 0.0016768267087172717, Final Batch Loss: 0.001397028798237443\n",
      "Epoch 2771, Loss: 0.008674920900375582, Final Batch Loss: 0.00848807580769062\n",
      "Epoch 2772, Loss: 0.0005908343882765621, Final Batch Loss: 0.00034302278072573245\n",
      "Epoch 2773, Loss: 0.004648418034776114, Final Batch Loss: 0.004458007402718067\n",
      "Epoch 2774, Loss: 0.0003042493699467741, Final Batch Loss: 0.00011184956383658573\n",
      "Epoch 2775, Loss: 0.0005355916218832135, Final Batch Loss: 0.00024809985188767314\n",
      "Epoch 2776, Loss: 0.004081291175680235, Final Batch Loss: 0.003685987088829279\n",
      "Epoch 2777, Loss: 0.0009252060190192424, Final Batch Loss: 0.0008494473295286298\n",
      "Epoch 2778, Loss: 0.004720858880318701, Final Batch Loss: 0.004379947204142809\n",
      "Epoch 2779, Loss: 0.0003952579863835126, Final Batch Loss: 0.00016056015738286078\n",
      "Epoch 2780, Loss: 0.00024626617960166186, Final Batch Loss: 0.00017462791583966464\n",
      "Epoch 2781, Loss: 0.0006467860366683453, Final Batch Loss: 0.0004866201779805124\n",
      "Epoch 2782, Loss: 0.0026187649273197167, Final Batch Loss: 0.002539748093113303\n",
      "Epoch 2783, Loss: 0.00024136163119692355, Final Batch Loss: 0.00017583493900019675\n",
      "Epoch 2784, Loss: 0.006509391590952873, Final Batch Loss: 0.004019920714199543\n",
      "Epoch 2785, Loss: 0.0017998908733716235, Final Batch Loss: 0.00013946100079920143\n",
      "Epoch 2786, Loss: 0.001648582547204569, Final Batch Loss: 0.0012720493832603097\n",
      "Epoch 2787, Loss: 0.0002666855289135128, Final Batch Loss: 0.0001376767613692209\n",
      "Epoch 2788, Loss: 0.00041056302143260837, Final Batch Loss: 0.00024437878164462745\n",
      "Epoch 2789, Loss: 0.005511671042768285, Final Batch Loss: 0.00031212737667374313\n",
      "Epoch 2790, Loss: 0.00027009098266717046, Final Batch Loss: 0.00011571447248570621\n",
      "Epoch 2791, Loss: 0.0019124578684568405, Final Batch Loss: 0.0003025003243237734\n",
      "Epoch 2792, Loss: 0.00037896727735642344, Final Batch Loss: 0.0003490006783977151\n",
      "Epoch 2793, Loss: 0.0004346024361439049, Final Batch Loss: 0.0002534171799197793\n",
      "Epoch 2794, Loss: 0.0002217469664174132, Final Batch Loss: 6.829543417552486e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2795, Loss: 0.0005923018034081906, Final Batch Loss: 0.00014685819041915238\n",
      "Epoch 2796, Loss: 0.0002906597401306499, Final Batch Loss: 0.0002304374793311581\n",
      "Epoch 2797, Loss: 0.0018780105383484624, Final Batch Loss: 6.710734305670485e-05\n",
      "Epoch 2798, Loss: 0.00025081321655306965, Final Batch Loss: 8.328034891746938e-05\n",
      "Epoch 2799, Loss: 0.00039317623304668814, Final Batch Loss: 0.00031010471866466105\n",
      "Epoch 2800, Loss: 0.000677893083775416, Final Batch Loss: 0.00036964655737392604\n",
      "Epoch 2801, Loss: 0.00034021570536424406, Final Batch Loss: 0.0003103534399997443\n",
      "Epoch 2802, Loss: 0.000691325738443993, Final Batch Loss: 0.00045129944919608533\n",
      "Epoch 2803, Loss: 0.0003185607274645008, Final Batch Loss: 7.328950596274808e-05\n",
      "Epoch 2804, Loss: 0.0002997726041940041, Final Batch Loss: 7.56510635255836e-05\n",
      "Epoch 2805, Loss: 0.012608857359737158, Final Batch Loss: 0.010765780694782734\n",
      "Epoch 2806, Loss: 0.00012707968198810704, Final Batch Loss: 7.760009611956775e-05\n",
      "Epoch 2807, Loss: 0.0007526514236815274, Final Batch Loss: 0.0004377150034997612\n",
      "Epoch 2808, Loss: 3.1978423066902906e-05, Final Batch Loss: 1.2979913663002662e-05\n",
      "Epoch 2809, Loss: 0.0002068465473712422, Final Batch Loss: 0.00016516854520887136\n",
      "Epoch 2810, Loss: 4.881303266301984e-05, Final Batch Loss: 1.5207781871140469e-05\n",
      "Epoch 2811, Loss: 3.893750999850454e-05, Final Batch Loss: 1.0942726476059761e-05\n",
      "Epoch 2812, Loss: 6.190671774675138e-05, Final Batch Loss: 2.6305191568098962e-05\n",
      "Epoch 2813, Loss: 0.000973672496911604, Final Batch Loss: 0.000892429263330996\n",
      "Epoch 2814, Loss: 0.00031837011192692444, Final Batch Loss: 0.00011113165965070948\n",
      "Epoch 2815, Loss: 0.014042419694305863, Final Batch Loss: 5.490177863975987e-05\n",
      "Epoch 2816, Loss: 0.001932212726387661, Final Batch Loss: 3.0731076549272984e-05\n",
      "Epoch 2817, Loss: 0.0004172872759227175, Final Batch Loss: 4.481659925659187e-05\n",
      "Epoch 2818, Loss: 0.00025768313025764655, Final Batch Loss: 0.00023875392798800021\n",
      "Epoch 2819, Loss: 0.00013240718908491544, Final Batch Loss: 9.27962246350944e-05\n",
      "Epoch 2820, Loss: 0.005372071638703346, Final Batch Loss: 0.002695613307878375\n",
      "Epoch 2821, Loss: 0.00016010907347663306, Final Batch Loss: 3.598862895159982e-05\n",
      "Epoch 2822, Loss: 7.663684482395183e-05, Final Batch Loss: 2.0659006622736342e-05\n",
      "Epoch 2823, Loss: 0.00014612531595048495, Final Batch Loss: 2.8519596526166424e-05\n",
      "Epoch 2824, Loss: 0.0001227340144396294, Final Batch Loss: 6.0656177083728835e-05\n",
      "Epoch 2825, Loss: 0.0001291647149628261, Final Batch Loss: 2.3628383132745512e-05\n",
      "Epoch 2826, Loss: 0.0005886921208002605, Final Batch Loss: 9.119362948695198e-05\n",
      "Epoch 2827, Loss: 9.319537093688268e-05, Final Batch Loss: 2.9181925128796138e-05\n",
      "Epoch 2828, Loss: 9.243232125299983e-05, Final Batch Loss: 6.135174044175074e-05\n",
      "Epoch 2829, Loss: 0.0002486996745574288, Final Batch Loss: 0.0001793700794223696\n",
      "Epoch 2830, Loss: 0.0006355518271448091, Final Batch Loss: 0.0005715441657230258\n",
      "Epoch 2831, Loss: 0.002071542010526173, Final Batch Loss: 0.00014376376930158585\n",
      "Epoch 2832, Loss: 0.00012543857155833393, Final Batch Loss: 6.471327651524916e-05\n",
      "Epoch 2833, Loss: 0.00014705269131809473, Final Batch Loss: 7.959987124195322e-05\n",
      "Epoch 2834, Loss: 0.00022782751329941675, Final Batch Loss: 6.464549369411543e-05\n",
      "Epoch 2835, Loss: 0.00015905135114735458, Final Batch Loss: 8.723620339878835e-06\n",
      "Epoch 2836, Loss: 5.8227193676430034e-05, Final Batch Loss: 6.744227448507445e-06\n",
      "Epoch 2837, Loss: 0.0004649450711440295, Final Batch Loss: 0.0003670834412332624\n",
      "Epoch 2838, Loss: 0.001973914600966964, Final Batch Loss: 2.0175859390292317e-05\n",
      "Epoch 2839, Loss: 0.00011954703586525284, Final Batch Loss: 9.368669998366386e-05\n",
      "Epoch 2840, Loss: 0.00011604984501900617, Final Batch Loss: 1.2331760444794782e-05\n",
      "Epoch 2841, Loss: 0.00011736753731383942, Final Batch Loss: 4.797125075128861e-05\n",
      "Epoch 2842, Loss: 0.0001429351068509277, Final Batch Loss: 8.74735924298875e-05\n",
      "Epoch 2843, Loss: 0.008593445774749853, Final Batch Loss: 0.008447016589343548\n",
      "Epoch 2844, Loss: 0.0002916598241426982, Final Batch Loss: 0.0002446934813633561\n",
      "Epoch 2845, Loss: 0.0001516483462182805, Final Batch Loss: 0.0001342215109616518\n",
      "Epoch 2846, Loss: 0.00015251414151862264, Final Batch Loss: 1.41176424222067e-05\n",
      "Epoch 2847, Loss: 0.00011155856373079587, Final Batch Loss: 4.994699338567443e-06\n",
      "Epoch 2848, Loss: 0.0008983838779386133, Final Batch Loss: 0.0006476082489825785\n",
      "Epoch 2849, Loss: 0.00045310589030123083, Final Batch Loss: 1.1546358109626453e-05\n",
      "Epoch 2850, Loss: 0.0003955519350711256, Final Batch Loss: 6.367676542140543e-05\n",
      "Epoch 2851, Loss: 0.00039850856410339475, Final Batch Loss: 0.0002305543312104419\n",
      "Epoch 2852, Loss: 0.01863441925161169, Final Batch Loss: 0.018608929589390755\n",
      "Epoch 2853, Loss: 7.187590017565526e-05, Final Batch Loss: 4.101881495444104e-05\n",
      "Epoch 2854, Loss: 0.0001239798693859484, Final Batch Loss: 3.106965232291259e-05\n",
      "Epoch 2855, Loss: 0.0016818901858641766, Final Batch Loss: 0.00010070946154883131\n",
      "Epoch 2856, Loss: 0.00012995617726119235, Final Batch Loss: 4.4533415348269045e-05\n",
      "Epoch 2857, Loss: 0.00024932045562309213, Final Batch Loss: 4.1078066715272143e-05\n",
      "Epoch 2858, Loss: 0.00013747459524893202, Final Batch Loss: 8.440461533609778e-05\n",
      "Epoch 2859, Loss: 0.00016233313363045454, Final Batch Loss: 2.286849485244602e-05\n",
      "Epoch 2860, Loss: 0.0005329759005689994, Final Batch Loss: 0.00023555713414680213\n",
      "Epoch 2861, Loss: 0.0002892028132919222, Final Batch Loss: 6.425988976843655e-05\n",
      "Epoch 2862, Loss: 0.009182061941828579, Final Batch Loss: 0.008222728967666626\n",
      "Epoch 2863, Loss: 0.0005372060695663095, Final Batch Loss: 0.0003433401871006936\n",
      "Epoch 2864, Loss: 0.00030209391843527555, Final Batch Loss: 0.000234623730648309\n",
      "Epoch 2865, Loss: 0.00032949912019830663, Final Batch Loss: 2.6678391805035062e-05\n",
      "Epoch 2866, Loss: 0.0003190752468071878, Final Batch Loss: 0.00015637617616448551\n",
      "Epoch 2867, Loss: 0.001127309849835001, Final Batch Loss: 0.0001560093805892393\n",
      "Epoch 2868, Loss: 0.0005635498964693397, Final Batch Loss: 0.00022246968001127243\n",
      "Epoch 2869, Loss: 0.0003921436582459137, Final Batch Loss: 0.00025651822215877473\n",
      "Epoch 2870, Loss: 0.0002769531783997081, Final Batch Loss: 0.00015995188732631505\n",
      "Epoch 2871, Loss: 0.0002646999491844326, Final Batch Loss: 0.00020093251077923924\n",
      "Epoch 2872, Loss: 0.0002587397539173253, Final Batch Loss: 0.00010388498048996553\n",
      "Epoch 2873, Loss: 0.00022107917902758345, Final Batch Loss: 7.19908784958534e-05\n",
      "Epoch 2874, Loss: 0.00045487246097764, Final Batch Loss: 7.34305867808871e-05\n",
      "Epoch 2875, Loss: 0.0006859790591988713, Final Batch Loss: 0.0003818685363512486\n",
      "Epoch 2876, Loss: 0.00016934726590989158, Final Batch Loss: 6.135479634394869e-05\n",
      "Epoch 2877, Loss: 0.00407292737509124, Final Batch Loss: 4.720219294540584e-05\n",
      "Epoch 2878, Loss: 0.00023405403044307604, Final Batch Loss: 0.00010846246004803106\n",
      "Epoch 2879, Loss: 0.00011937570161535405, Final Batch Loss: 6.54217365081422e-05\n",
      "Epoch 2880, Loss: 0.00029524143610615283, Final Batch Loss: 7.063407974783331e-05\n",
      "Epoch 2881, Loss: 0.00027149928791914135, Final Batch Loss: 7.51323823351413e-05\n",
      "Epoch 2882, Loss: 8.1322890764568e-05, Final Batch Loss: 1.8106249626725912e-05\n",
      "Epoch 2883, Loss: 0.00013657199815497734, Final Batch Loss: 3.5181732528144494e-05\n",
      "Epoch 2884, Loss: 0.0003475981138763018, Final Batch Loss: 0.0002295544691151008\n",
      "Epoch 2885, Loss: 0.0003278035583207384, Final Batch Loss: 0.00010856078006327152\n",
      "Epoch 2886, Loss: 0.0029187560649006628, Final Batch Loss: 4.7379602619912475e-05\n",
      "Epoch 2887, Loss: 0.0002437525945424568, Final Batch Loss: 5.972016879240982e-05\n",
      "Epoch 2888, Loss: 0.0003113627972197719, Final Batch Loss: 7.202108827186748e-05\n",
      "Epoch 2889, Loss: 0.00018027790792984888, Final Batch Loss: 0.00011513915524119511\n",
      "Epoch 2890, Loss: 0.004186752354144119, Final Batch Loss: 0.00411860179156065\n",
      "Epoch 2891, Loss: 0.0026335617403674405, Final Batch Loss: 5.865761704626493e-05\n",
      "Epoch 2892, Loss: 0.00011193165482836775, Final Batch Loss: 4.0962881030282006e-05\n",
      "Epoch 2893, Loss: 0.0032346413863706402, Final Batch Loss: 0.003158018458634615\n",
      "Epoch 2894, Loss: 0.00026241166960971896, Final Batch Loss: 0.00023698470613453537\n",
      "Epoch 2895, Loss: 0.0021850690100109205, Final Batch Loss: 6.051290256436914e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2896, Loss: 0.00023472172324545681, Final Batch Loss: 0.00017617782577872276\n",
      "Epoch 2897, Loss: 0.005979057168588042, Final Batch Loss: 0.0025680772960186005\n",
      "Epoch 2898, Loss: 0.00040274622006108984, Final Batch Loss: 9.067265636986122e-05\n",
      "Epoch 2899, Loss: 0.00023596216487931088, Final Batch Loss: 0.00017642199236433953\n",
      "Epoch 2900, Loss: 0.006399594272807008, Final Batch Loss: 5.651128230965696e-05\n",
      "Epoch 2901, Loss: 0.0002202526302426122, Final Batch Loss: 0.00016348440840374678\n",
      "Epoch 2902, Loss: 0.0001286374554183567, Final Batch Loss: 1.8108179574483074e-05\n",
      "Epoch 2903, Loss: 0.0001723170335026225, Final Batch Loss: 2.206862518505659e-05\n",
      "Epoch 2904, Loss: 0.0001684544658928644, Final Batch Loss: 0.0001429585536243394\n",
      "Epoch 2905, Loss: 0.00018748715228866786, Final Batch Loss: 0.00015603362408000976\n",
      "Epoch 2906, Loss: 0.00011915674622287042, Final Batch Loss: 5.46530973224435e-05\n",
      "Epoch 2907, Loss: 0.0003884962643496692, Final Batch Loss: 0.0001649542828090489\n",
      "Epoch 2908, Loss: 0.0016010898252716288, Final Batch Loss: 3.1220013624988496e-05\n",
      "Epoch 2909, Loss: 0.00010651567572494969, Final Batch Loss: 3.848201595246792e-05\n",
      "Epoch 2910, Loss: 0.0001456018835597206, Final Batch Loss: 0.00011280343460384756\n",
      "Epoch 2911, Loss: 9.324292295787018e-05, Final Batch Loss: 2.9198452466516756e-05\n",
      "Epoch 2912, Loss: 0.0003671971680887509, Final Batch Loss: 0.00034273226629011333\n",
      "Epoch 2913, Loss: 0.004959710349794477, Final Batch Loss: 0.004921169951558113\n",
      "Epoch 2914, Loss: 7.788445873302408e-05, Final Batch Loss: 1.9244831491960213e-05\n",
      "Epoch 2915, Loss: 0.0005249181849649176, Final Batch Loss: 2.592393138911575e-05\n",
      "Epoch 2916, Loss: 0.0002701447592698969, Final Batch Loss: 0.00017682451289147139\n",
      "Epoch 2917, Loss: 0.00031876846333034337, Final Batch Loss: 0.00011161775910295546\n",
      "Epoch 2918, Loss: 0.00010401076360722072, Final Batch Loss: 6.312869663815945e-05\n",
      "Epoch 2919, Loss: 7.433443715854082e-05, Final Batch Loss: 3.0365556085598655e-05\n",
      "Epoch 2920, Loss: 0.00013472570572048426, Final Batch Loss: 7.514056051149964e-05\n",
      "Epoch 2921, Loss: 5.447174135042587e-05, Final Batch Loss: 1.0409105925646145e-05\n",
      "Epoch 2922, Loss: 0.0003529931746015791, Final Batch Loss: 5.4061940318206325e-05\n",
      "Epoch 2923, Loss: 6.046138696547132e-05, Final Batch Loss: 1.4719376849825494e-05\n",
      "Epoch 2924, Loss: 0.00010517097143747378, Final Batch Loss: 8.055608486756682e-05\n",
      "Epoch 2925, Loss: 0.0004018949330202304, Final Batch Loss: 9.33537885430269e-05\n",
      "Epoch 2926, Loss: 0.0002859152118617203, Final Batch Loss: 3.3858141250675544e-05\n",
      "Epoch 2927, Loss: 0.0001830934088502545, Final Batch Loss: 2.08289893635083e-05\n",
      "Epoch 2928, Loss: 0.00015059519864735194, Final Batch Loss: 4.7916026232996956e-05\n",
      "Epoch 2929, Loss: 0.00026947430887958035, Final Batch Loss: 9.887379565043375e-05\n",
      "Epoch 2930, Loss: 0.00011321165402478073, Final Batch Loss: 2.7695505195879377e-05\n",
      "Epoch 2931, Loss: 0.0040865104529075325, Final Batch Loss: 0.0038280042354017496\n",
      "Epoch 2932, Loss: 0.00036691318382509053, Final Batch Loss: 0.0003256789641454816\n",
      "Epoch 2933, Loss: 0.0006200583156896755, Final Batch Loss: 0.0005967319593764842\n",
      "Epoch 2934, Loss: 4.4903856178279966e-05, Final Batch Loss: 2.4190074327634647e-05\n",
      "Epoch 2935, Loss: 0.003226466775231529, Final Batch Loss: 9.938010043697432e-05\n",
      "Epoch 2936, Loss: 0.00018688742420636117, Final Batch Loss: 0.0001218987163156271\n",
      "Epoch 2937, Loss: 6.066616879252251e-05, Final Batch Loss: 2.5509709303150885e-05\n",
      "Epoch 2938, Loss: 0.0026918792573269457, Final Batch Loss: 7.348446524702013e-05\n",
      "Epoch 2939, Loss: 0.0015326074208132923, Final Batch Loss: 0.0003748275921680033\n",
      "Epoch 2940, Loss: 9.278589823225047e-05, Final Batch Loss: 2.0100973415537737e-05\n",
      "Epoch 2941, Loss: 4.898507540929131e-05, Final Batch Loss: 1.793591582099907e-05\n",
      "Epoch 2942, Loss: 9.896086703520268e-05, Final Batch Loss: 2.804915129672736e-05\n",
      "Epoch 2943, Loss: 0.0020323642529547215, Final Batch Loss: 0.00018226541578769684\n",
      "Epoch 2944, Loss: 0.0010848443125723861, Final Batch Loss: 0.0010364089393988252\n",
      "Epoch 2945, Loss: 8.017660275072558e-05, Final Batch Loss: 1.325909670413239e-05\n",
      "Epoch 2946, Loss: 9.186049646814354e-05, Final Batch Loss: 3.617960828705691e-05\n",
      "Epoch 2947, Loss: 0.00012004121890640818, Final Batch Loss: 6.181569187901914e-05\n",
      "Epoch 2948, Loss: 0.00012087892537238076, Final Batch Loss: 3.671117883641273e-05\n",
      "Epoch 2949, Loss: 0.001819456520024687, Final Batch Loss: 0.0001277046394534409\n",
      "Epoch 2950, Loss: 5.162467459740583e-05, Final Batch Loss: 2.6165316739934497e-05\n",
      "Epoch 2951, Loss: 0.0021496646013474674, Final Batch Loss: 0.002136656315997243\n",
      "Epoch 2952, Loss: 0.0002105547509927419, Final Batch Loss: 1.4561262105416972e-05\n",
      "Epoch 2953, Loss: 0.0005295792434480973, Final Batch Loss: 8.630511729279533e-05\n",
      "Epoch 2954, Loss: 0.00027807288461190183, Final Batch Loss: 0.0002574058889877051\n",
      "Epoch 2955, Loss: 0.0005081583076389506, Final Batch Loss: 0.00033881282433867455\n",
      "Epoch 2956, Loss: 0.00028717684108414687, Final Batch Loss: 0.0002616820565890521\n",
      "Epoch 2957, Loss: 0.00010311422192899045, Final Batch Loss: 3.0374400012078695e-05\n",
      "Epoch 2958, Loss: 0.0002701991470530629, Final Batch Loss: 6.91581517457962e-05\n",
      "Epoch 2959, Loss: 0.00010794150512083434, Final Batch Loss: 4.397483644424938e-05\n",
      "Epoch 2960, Loss: 3.386833395779831e-05, Final Batch Loss: 1.5192646060313564e-05\n",
      "Epoch 2961, Loss: 0.0022845527364552254, Final Batch Loss: 0.002255253726616502\n",
      "Epoch 2962, Loss: 0.003560498616025143, Final Batch Loss: 0.003551401663571596\n",
      "Epoch 2963, Loss: 0.0042759074858622625, Final Batch Loss: 0.004066046327352524\n",
      "Epoch 2964, Loss: 0.013174604639061727, Final Batch Loss: 0.013086595572531223\n",
      "Epoch 2965, Loss: 7.237512727442663e-05, Final Batch Loss: 3.0451601560343988e-05\n",
      "Epoch 2966, Loss: 9.922720983013278e-05, Final Batch Loss: 4.98946519655874e-06\n",
      "Epoch 2967, Loss: 0.0005292379501042888, Final Batch Loss: 2.5330213247798383e-05\n",
      "Epoch 2968, Loss: 0.0063677949365228415, Final Batch Loss: 0.006268136203289032\n",
      "Epoch 2969, Loss: 0.0007007422100286931, Final Batch Loss: 0.0006579213077202439\n",
      "Epoch 2970, Loss: 0.0005811801092932001, Final Batch Loss: 0.0004518506466411054\n",
      "Epoch 2971, Loss: 0.002424020382022718, Final Batch Loss: 0.002390430774539709\n",
      "Epoch 2972, Loss: 0.0002068419853458181, Final Batch Loss: 0.00013025078806094825\n",
      "Epoch 2973, Loss: 0.0008730076078791171, Final Batch Loss: 0.0004212360072415322\n",
      "Epoch 2974, Loss: 0.00011027534674212802, Final Batch Loss: 2.3051516109262593e-05\n",
      "Epoch 2975, Loss: 0.0001899071539810393, Final Batch Loss: 3.7755922676296905e-05\n",
      "Epoch 2976, Loss: 0.0023015105252852663, Final Batch Loss: 0.002138560637831688\n",
      "Epoch 2977, Loss: 6.120807665865868e-05, Final Batch Loss: 1.940308720804751e-05\n",
      "Epoch 2978, Loss: 5.89550854783738e-05, Final Batch Loss: 3.307533552288078e-05\n",
      "Epoch 2979, Loss: 0.00032782564812805504, Final Batch Loss: 0.00014442586689256132\n",
      "Epoch 2980, Loss: 0.00024017427858780138, Final Batch Loss: 2.1074007236165926e-05\n",
      "Epoch 2981, Loss: 9.419553316547535e-05, Final Batch Loss: 3.983559145126492e-05\n",
      "Epoch 2982, Loss: 0.00012380050975480117, Final Batch Loss: 5.323880031937733e-06\n",
      "Epoch 2983, Loss: 0.002612790369312279, Final Batch Loss: 0.0025236557703465223\n",
      "Epoch 2984, Loss: 0.0001541154197184369, Final Batch Loss: 8.976303070085123e-05\n",
      "Epoch 2985, Loss: 3.881932207150385e-05, Final Batch Loss: 4.359320882940665e-06\n",
      "Epoch 2986, Loss: 0.0024516795019735582, Final Batch Loss: 0.0023582482244819403\n",
      "Epoch 2987, Loss: 7.239131082314998e-05, Final Batch Loss: 1.8031438230536878e-05\n",
      "Epoch 2988, Loss: 0.00010876342275878415, Final Batch Loss: 6.768840103177354e-05\n",
      "Epoch 2989, Loss: 0.0028430939419195056, Final Batch Loss: 0.0006890945369377732\n",
      "Epoch 2990, Loss: 0.00278280844213441, Final Batch Loss: 0.0026514751370996237\n",
      "Epoch 2991, Loss: 8.636446000309661e-05, Final Batch Loss: 2.262366615468636e-05\n",
      "Epoch 2992, Loss: 0.00010260875933454372, Final Batch Loss: 6.290276360232383e-05\n",
      "Epoch 2993, Loss: 4.190573235973716e-05, Final Batch Loss: 3.402560469112359e-05\n",
      "Epoch 2994, Loss: 0.00024952777312137187, Final Batch Loss: 0.00010481096978764981\n",
      "Epoch 2995, Loss: 0.0003587657702155411, Final Batch Loss: 0.00011283819912932813\n",
      "Epoch 2996, Loss: 0.0006807097670389339, Final Batch Loss: 0.000529166660271585\n",
      "Epoch 2997, Loss: 3.8476504414575174e-05, Final Batch Loss: 1.83048214239534e-05\n",
      "Epoch 2998, Loss: 0.00018382564121566247, Final Batch Loss: 0.00015633265138603747\n",
      "Epoch 2999, Loss: 6.67356034682598e-05, Final Batch Loss: 1.166942820418626e-05\n",
      "Epoch 3000, Loss: 0.0014943245259928517, Final Batch Loss: 6.215913890628144e-05\n",
      "Epoch 3001, Loss: 5.78780091018416e-05, Final Batch Loss: 8.142334991134703e-06\n",
      "Epoch 3002, Loss: 0.0019835902930935845, Final Batch Loss: 1.8009086488746107e-05\n",
      "Epoch 3003, Loss: 0.0013169527337595355, Final Batch Loss: 4.01797988160979e-05\n",
      "Epoch 3004, Loss: 8.751980203669518e-05, Final Batch Loss: 2.4089720682241023e-05\n",
      "Epoch 3005, Loss: 4.518484820437152e-05, Final Batch Loss: 2.086973654513713e-05\n",
      "Epoch 3006, Loss: 8.768014595261775e-05, Final Batch Loss: 6.964070780668408e-05\n",
      "Epoch 3007, Loss: 0.00013058080003247596, Final Batch Loss: 0.00010226410086033866\n",
      "Epoch 3008, Loss: 0.00013126716567057883, Final Batch Loss: 0.00012706953566521406\n",
      "Epoch 3009, Loss: 0.00011422729039622936, Final Batch Loss: 1.5575040379189886e-05\n",
      "Epoch 3010, Loss: 0.0008405037224292755, Final Batch Loss: 0.0001586712314747274\n",
      "Epoch 3011, Loss: 0.0001112702775571961, Final Batch Loss: 3.4400105505483225e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3012, Loss: 0.00017847801427706145, Final Batch Loss: 0.00015134905697777867\n",
      "Epoch 3013, Loss: 0.002241468522697687, Final Batch Loss: 0.0012455836404114962\n",
      "Epoch 3014, Loss: 2.558141295594396e-05, Final Batch Loss: 1.3871385817765258e-05\n",
      "Epoch 3015, Loss: 0.00018782258121063933, Final Batch Loss: 5.296705785440281e-05\n",
      "Epoch 3016, Loss: 0.00020839831222474459, Final Batch Loss: 0.0002008123992709443\n",
      "Epoch 3017, Loss: 0.0014487181888398482, Final Batch Loss: 2.5993967938120477e-05\n",
      "Epoch 3018, Loss: 0.00014807659499638248, Final Batch Loss: 0.00013011100236326456\n",
      "Epoch 3019, Loss: 0.00029044815892120823, Final Batch Loss: 0.00017425071564503014\n",
      "Epoch 3020, Loss: 0.00035595188091974705, Final Batch Loss: 0.00028147469856776297\n",
      "Epoch 3021, Loss: 0.002075633290587575, Final Batch Loss: 2.1505426047951914e-05\n",
      "Epoch 3022, Loss: 0.00014805110731686, Final Batch Loss: 0.00012331611651461571\n",
      "Epoch 3023, Loss: 0.0012621845889952965, Final Batch Loss: 0.0012483540922403336\n",
      "Epoch 3024, Loss: 0.00025938024555216543, Final Batch Loss: 1.908813646878116e-05\n",
      "Epoch 3025, Loss: 0.00011893246482941322, Final Batch Loss: 6.303710688371211e-05\n",
      "Epoch 3026, Loss: 0.0002517391330911778, Final Batch Loss: 0.00010238950926577672\n",
      "Epoch 3027, Loss: 3.1672480872657616e-05, Final Batch Loss: 8.011559657461476e-06\n",
      "Epoch 3028, Loss: 0.0016104860842460766, Final Batch Loss: 0.001489150570705533\n",
      "Epoch 3029, Loss: 5.875954866496613e-05, Final Batch Loss: 1.3330462934391107e-05\n",
      "Epoch 3030, Loss: 0.00013031731577939354, Final Batch Loss: 4.064182212459855e-05\n",
      "Epoch 3031, Loss: 0.002794414380332455, Final Batch Loss: 0.00277038780041039\n",
      "Epoch 3032, Loss: 0.000489045340600569, Final Batch Loss: 0.00048424836131744087\n",
      "Epoch 3033, Loss: 0.00015508603246416897, Final Batch Loss: 5.945286829955876e-05\n",
      "Epoch 3034, Loss: 7.76008891989477e-05, Final Batch Loss: 4.246536627761088e-05\n",
      "Epoch 3035, Loss: 4.605844151228666e-05, Final Batch Loss: 1.0827690857695416e-05\n",
      "Epoch 3036, Loss: 0.0037278014642652124, Final Batch Loss: 2.3885018890723586e-05\n",
      "Epoch 3037, Loss: 0.00019035047080251388, Final Batch Loss: 4.77012617920991e-05\n",
      "Epoch 3038, Loss: 0.001810140754969325, Final Batch Loss: 1.774759584804997e-05\n",
      "Epoch 3039, Loss: 6.307720650511328e-05, Final Batch Loss: 1.8326087229070254e-05\n",
      "Epoch 3040, Loss: 0.00011244334018556401, Final Batch Loss: 1.122600951930508e-05\n",
      "Epoch 3041, Loss: 3.9702474168734625e-05, Final Batch Loss: 2.079503974528052e-05\n",
      "Epoch 3042, Loss: 3.786527304328047e-05, Final Batch Loss: 1.0803134500747547e-05\n",
      "Epoch 3043, Loss: 0.0007027991678114631, Final Batch Loss: 1.0789125553856138e-05\n",
      "Epoch 3044, Loss: 7.775062840664759e-05, Final Batch Loss: 4.541088856058195e-05\n",
      "Epoch 3045, Loss: 0.00018389461183687672, Final Batch Loss: 0.00010829220991581678\n",
      "Epoch 3046, Loss: 9.213189150614198e-05, Final Batch Loss: 7.618937524966896e-05\n",
      "Epoch 3047, Loss: 6.51003724669863e-05, Final Batch Loss: 6.886712526465999e-06\n",
      "Epoch 3048, Loss: 5.308858999342192e-05, Final Batch Loss: 3.724107227753848e-05\n",
      "Epoch 3049, Loss: 0.0013366585881158244, Final Batch Loss: 3.184166780556552e-05\n",
      "Epoch 3050, Loss: 7.684954471187666e-05, Final Batch Loss: 4.4489370338851586e-05\n",
      "Epoch 3051, Loss: 0.00041635928118921584, Final Batch Loss: 0.00040518687455914915\n",
      "Epoch 3052, Loss: 2.466208343321341e-05, Final Batch Loss: 2.046083682216704e-05\n",
      "Epoch 3053, Loss: 2.6135655389225576e-05, Final Batch Loss: 1.46917809615843e-05\n",
      "Epoch 3054, Loss: 0.0010427732122479938, Final Batch Loss: 0.0010077268816530704\n",
      "Epoch 3055, Loss: 4.397846623760415e-05, Final Batch Loss: 8.95411994861206e-06\n",
      "Epoch 3056, Loss: 3.66712538379943e-05, Final Batch Loss: 2.3553739083581604e-05\n",
      "Epoch 3057, Loss: 0.00010073016528622247, Final Batch Loss: 5.853315451531671e-05\n",
      "Epoch 3058, Loss: 0.00011011279275408015, Final Batch Loss: 1.0822310287039727e-05\n",
      "Epoch 3059, Loss: 0.0001705021786619909, Final Batch Loss: 2.1235297026578337e-05\n",
      "Epoch 3060, Loss: 6.415896314138081e-05, Final Batch Loss: 2.595250953163486e-05\n",
      "Epoch 3061, Loss: 5.7621296946308576e-05, Final Batch Loss: 2.1701200239476748e-05\n",
      "Epoch 3062, Loss: 3.9799871046852786e-05, Final Batch Loss: 3.055166598642245e-05\n",
      "Epoch 3063, Loss: 0.00017001967353280634, Final Batch Loss: 7.606421422678977e-05\n",
      "Epoch 3064, Loss: 0.00012994728967896663, Final Batch Loss: 8.818296191748232e-05\n",
      "Epoch 3065, Loss: 0.0004423575137479929, Final Batch Loss: 8.50426840770524e-06\n",
      "Epoch 3066, Loss: 8.021185203688219e-05, Final Batch Loss: 1.215611700899899e-05\n",
      "Epoch 3067, Loss: 3.472019488981459e-05, Final Batch Loss: 1.4740748156327754e-05\n",
      "Epoch 3068, Loss: 0.00019002525368705392, Final Batch Loss: 0.00011520154657773674\n",
      "Epoch 3069, Loss: 7.828929301467724e-05, Final Batch Loss: 6.0717356973327696e-05\n",
      "Epoch 3070, Loss: 0.00028777406259905547, Final Batch Loss: 0.00023425107065122575\n",
      "Epoch 3071, Loss: 9.379329094372224e-05, Final Batch Loss: 1.1673406334011815e-05\n",
      "Epoch 3072, Loss: 0.00010123647371074185, Final Batch Loss: 1.8536265997681767e-05\n",
      "Epoch 3073, Loss: 0.0049174407904502004, Final Batch Loss: 0.004669237416237593\n",
      "Epoch 3074, Loss: 3.741715181604377e-05, Final Batch Loss: 6.9871998675807845e-06\n",
      "Epoch 3075, Loss: 9.07879693841096e-05, Final Batch Loss: 4.407776941661723e-05\n",
      "Epoch 3076, Loss: 0.000662369198835222, Final Batch Loss: 3.651943916338496e-05\n",
      "Epoch 3077, Loss: 7.979305883054622e-05, Final Batch Loss: 5.3775995183968917e-05\n",
      "Epoch 3078, Loss: 4.2632433178368956e-05, Final Batch Loss: 1.4846553312963806e-05\n",
      "Epoch 3079, Loss: 0.0032300294915330596, Final Batch Loss: 0.003223092993721366\n",
      "Epoch 3080, Loss: 4.215087574266363e-05, Final Batch Loss: 2.6069361410918646e-05\n",
      "Epoch 3081, Loss: 9.739908273331821e-05, Final Batch Loss: 6.978288729442284e-05\n",
      "Epoch 3082, Loss: 0.0016231926433647459, Final Batch Loss: 1.5844866538827773e-06\n",
      "Epoch 3083, Loss: 4.1392298953724094e-05, Final Batch Loss: 1.9351338778506033e-05\n",
      "Epoch 3084, Loss: 2.3071184841683134e-05, Final Batch Loss: 1.7368765838909894e-05\n",
      "Epoch 3085, Loss: 3.3796264688135125e-05, Final Batch Loss: 6.046493581379764e-06\n",
      "Epoch 3086, Loss: 7.603720405313652e-05, Final Batch Loss: 1.484322092437651e-05\n",
      "Epoch 3087, Loss: 6.909059675308526e-05, Final Batch Loss: 6.416996711777756e-06\n",
      "Epoch 3088, Loss: 0.0001623541938897688, Final Batch Loss: 6.336402293527499e-06\n",
      "Epoch 3089, Loss: 4.686277907239855e-05, Final Batch Loss: 5.796208370156819e-06\n",
      "Epoch 3090, Loss: 8.113307558232918e-05, Final Batch Loss: 3.219461359549314e-05\n",
      "Epoch 3091, Loss: 2.354463140363805e-05, Final Batch Loss: 2.2930380509933457e-06\n",
      "Epoch 3092, Loss: 0.0026877540512941778, Final Batch Loss: 0.002399114426225424\n",
      "Epoch 3093, Loss: 0.00010852450941456482, Final Batch Loss: 5.939146285527386e-05\n",
      "Epoch 3094, Loss: 8.088367758318782e-05, Final Batch Loss: 7.078359340084717e-05\n",
      "Epoch 3095, Loss: 0.00013442258205031976, Final Batch Loss: 6.0089558246545494e-05\n",
      "Epoch 3096, Loss: 0.00033970008371397853, Final Batch Loss: 0.0002495452936273068\n",
      "Epoch 3097, Loss: 3.279033580838586e-05, Final Batch Loss: 4.601500677381409e-06\n",
      "Epoch 3098, Loss: 0.00020774000222445466, Final Batch Loss: 1.7271322576561943e-05\n",
      "Epoch 3099, Loss: 0.00036342670864542015, Final Batch Loss: 0.0003451415686868131\n",
      "Epoch 3100, Loss: 4.259890692992485e-05, Final Batch Loss: 5.0606736294867005e-06\n",
      "Epoch 3101, Loss: 0.00010978356840496417, Final Batch Loss: 1.8678530977922492e-05\n",
      "Epoch 3102, Loss: 8.092372900136979e-05, Final Batch Loss: 1.4605863725591917e-05\n",
      "Epoch 3103, Loss: 0.00013937060793978162, Final Batch Loss: 4.1423376387683675e-05\n",
      "Epoch 3104, Loss: 0.0002969958513858728, Final Batch Loss: 0.00020306256192270666\n",
      "Epoch 3105, Loss: 0.001780906972271623, Final Batch Loss: 0.0017397450283169746\n",
      "Epoch 3106, Loss: 0.004823085297630314, Final Batch Loss: 0.004818328190594912\n",
      "Epoch 3107, Loss: 0.00010162536182178883, Final Batch Loss: 5.620243427983951e-06\n",
      "Epoch 3108, Loss: 0.001373699820760521, Final Batch Loss: 6.675092663499527e-06\n",
      "Epoch 3109, Loss: 4.6752877096878365e-05, Final Batch Loss: 1.6691778000677004e-05\n",
      "Epoch 3110, Loss: 0.003335071902256459, Final Batch Loss: 0.0026667045895010233\n",
      "Epoch 3111, Loss: 4.083031763002509e-05, Final Batch Loss: 5.54049347556429e-06\n",
      "Epoch 3112, Loss: 0.0009041430166689679, Final Batch Loss: 0.0001219610421685502\n",
      "Epoch 3113, Loss: 0.00026870805209000537, Final Batch Loss: 7.463493147952249e-07\n",
      "Epoch 3114, Loss: 7.272060474861064e-05, Final Batch Loss: 6.5960171923507e-05\n",
      "Epoch 3115, Loss: 9.87713542599522e-05, Final Batch Loss: 5.398117082222598e-06\n",
      "Epoch 3116, Loss: 5.058229589849361e-05, Final Batch Loss: 4.486527177505195e-05\n",
      "Epoch 3117, Loss: 0.0001436019103948638, Final Batch Loss: 2.3085324301064247e-06\n",
      "Epoch 3118, Loss: 3.409593682590639e-05, Final Batch Loss: 2.8690566978184506e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3119, Loss: 0.00043147438555024564, Final Batch Loss: 0.0002080543345073238\n",
      "Epoch 3120, Loss: 3.192777785443468e-05, Final Batch Loss: 1.5010094102763105e-05\n",
      "Epoch 3121, Loss: 3.765920246223686e-05, Final Batch Loss: 9.190313903673086e-06\n",
      "Epoch 3122, Loss: 4.487541264097672e-05, Final Batch Loss: 3.4860313462559134e-05\n",
      "Epoch 3123, Loss: 0.0006697136020648031, Final Batch Loss: 0.0006686660344712436\n",
      "Epoch 3124, Loss: 7.445425990226795e-05, Final Batch Loss: 6.604761892958777e-06\n",
      "Epoch 3125, Loss: 6.652626689174213e-05, Final Batch Loss: 2.6425164833199233e-05\n",
      "Epoch 3126, Loss: 0.0018422889970679535, Final Batch Loss: 1.6293137377942912e-05\n",
      "Epoch 3127, Loss: 0.00033653483114903793, Final Batch Loss: 0.0002757898473646492\n",
      "Epoch 3128, Loss: 0.00010053672303911299, Final Batch Loss: 5.7462377299088985e-05\n",
      "Epoch 3129, Loss: 0.0021137497387826443, Final Batch Loss: 4.274887032806873e-05\n",
      "Epoch 3130, Loss: 0.0007149913835746702, Final Batch Loss: 1.5578549209749326e-05\n",
      "Epoch 3131, Loss: 8.549401854907046e-05, Final Batch Loss: 4.365635959402425e-06\n",
      "Epoch 3132, Loss: 5.7663890856929356e-05, Final Batch Loss: 5.696858806913951e-06\n",
      "Epoch 3133, Loss: 0.0002851917852240149, Final Batch Loss: 1.01500227174256e-05\n",
      "Epoch 3134, Loss: 3.917612775694579e-05, Final Batch Loss: 3.32653580699116e-05\n",
      "Epoch 3135, Loss: 0.00024377071895287372, Final Batch Loss: 3.209674105164595e-05\n",
      "Epoch 3136, Loss: 5.769033305114135e-05, Final Batch Loss: 4.591096512740478e-06\n",
      "Epoch 3137, Loss: 2.5168463253066875e-05, Final Batch Loss: 6.301015673670918e-07\n",
      "Epoch 3138, Loss: 5.014891939936206e-05, Final Batch Loss: 9.523024345980957e-06\n",
      "Epoch 3139, Loss: 0.00010644261419656686, Final Batch Loss: 9.455038525629789e-05\n",
      "Epoch 3140, Loss: 0.0008732525202503894, Final Batch Loss: 0.0008627446368336678\n",
      "Epoch 3141, Loss: 0.0012816129710699897, Final Batch Loss: 5.7140434364555404e-05\n",
      "Epoch 3142, Loss: 9.024472819874063e-05, Final Batch Loss: 3.3387612347723916e-05\n",
      "Epoch 3143, Loss: 0.004440940625499934, Final Batch Loss: 0.0005886626313440502\n",
      "Epoch 3144, Loss: 4.904942943539936e-05, Final Batch Loss: 5.372587111196481e-06\n",
      "Epoch 3145, Loss: 7.39058964427386e-05, Final Batch Loss: 2.247740212624194e-06\n",
      "Epoch 3146, Loss: 0.0002480755138094537, Final Batch Loss: 3.9474536606576294e-05\n",
      "Epoch 3147, Loss: 1.772804330357758e-05, Final Batch Loss: 3.6493427160166902e-06\n",
      "Epoch 3148, Loss: 3.376036238478264e-05, Final Batch Loss: 1.3979414688947145e-05\n",
      "Epoch 3149, Loss: 0.0004992692297491885, Final Batch Loss: 4.056495072291e-06\n",
      "Epoch 3150, Loss: 0.00035696452687261626, Final Batch Loss: 0.00029032546444796026\n",
      "Epoch 3151, Loss: 8.176101073331665e-05, Final Batch Loss: 5.6716366088949144e-05\n",
      "Epoch 3152, Loss: 3.690552352964005e-05, Final Batch Loss: 1.8502689727029065e-06\n",
      "Epoch 3153, Loss: 0.015209528763080016, Final Batch Loss: 0.0001656032691244036\n",
      "Epoch 3154, Loss: 0.03761121940829071, Final Batch Loss: 2.56982661994698e-06\n",
      "Epoch 3155, Loss: 4.6036886942601996e-06, Final Batch Loss: 2.6668744794733357e-06\n",
      "Epoch 3156, Loss: 0.00010150493108085357, Final Batch Loss: 8.045900176512077e-05\n",
      "Epoch 3157, Loss: 0.00033059215638786554, Final Batch Loss: 0.00016509299166500568\n",
      "Epoch 3158, Loss: 5.743411566072609e-05, Final Batch Loss: 3.0578165024053305e-05\n",
      "Epoch 3159, Loss: 0.0012289407968637533, Final Batch Loss: 3.402774018468335e-05\n",
      "Epoch 3160, Loss: 0.00021544383344007656, Final Batch Loss: 0.00017047609435394406\n",
      "Epoch 3161, Loss: 0.0002414186528767459, Final Batch Loss: 1.7619073332753032e-05\n",
      "Epoch 3162, Loss: 3.16951741297089e-05, Final Batch Loss: 2.6921212338493206e-05\n",
      "Epoch 3163, Loss: 0.00012120125711589935, Final Batch Loss: 7.2471370913262945e-06\n",
      "Epoch 3164, Loss: 5.1555854952312075e-05, Final Batch Loss: 9.616489478503354e-06\n",
      "Epoch 3165, Loss: 0.0005140176363056526, Final Batch Loss: 0.00016363085887860507\n",
      "Epoch 3166, Loss: 0.00013231084085418843, Final Batch Loss: 3.547350570443086e-05\n",
      "Epoch 3167, Loss: 4.0822895698511275e-05, Final Batch Loss: 3.510838723741472e-05\n",
      "Epoch 3168, Loss: 4.554451970761875e-05, Final Batch Loss: 4.011650526081212e-05\n",
      "Epoch 3169, Loss: 0.00033962725956371287, Final Batch Loss: 0.0003245305269956589\n",
      "Epoch 3170, Loss: 7.531683968409197e-05, Final Batch Loss: 1.0771666893560905e-05\n",
      "Epoch 3171, Loss: 0.00029157381868571974, Final Batch Loss: 1.9106581021333113e-05\n",
      "Epoch 3172, Loss: 3.935446875402704e-05, Final Batch Loss: 2.3676559067098424e-05\n",
      "Epoch 3173, Loss: 0.0006737239696121833, Final Batch Loss: 2.445575319143245e-06\n",
      "Epoch 3174, Loss: 0.0009112090774578974, Final Batch Loss: 6.21927174506709e-05\n",
      "Epoch 3175, Loss: 9.459115972276777e-05, Final Batch Loss: 7.362214819295332e-05\n",
      "Epoch 3176, Loss: 7.944075514387805e-05, Final Batch Loss: 2.8022130209137686e-05\n",
      "Epoch 3177, Loss: 0.0036453096799959894, Final Batch Loss: 1.6592643078183755e-05\n",
      "Epoch 3178, Loss: 0.0019302575674373657, Final Batch Loss: 0.00010467987158335745\n",
      "Epoch 3179, Loss: 0.00019029326358577237, Final Batch Loss: 5.4187454225029796e-05\n",
      "Epoch 3180, Loss: 0.0003144619786326075, Final Batch Loss: 1.5759791494929232e-05\n",
      "Epoch 3181, Loss: 3.000880496983882e-05, Final Batch Loss: 1.770928611222189e-05\n",
      "Epoch 3182, Loss: 4.55975887234672e-05, Final Batch Loss: 1.4762593309569638e-05\n",
      "Epoch 3183, Loss: 0.00012927266652695835, Final Batch Loss: 4.229937621857971e-05\n",
      "Epoch 3184, Loss: 0.00025178821488225367, Final Batch Loss: 0.00022361120500136167\n",
      "Epoch 3185, Loss: 8.36773069750052e-05, Final Batch Loss: 7.995642954483628e-05\n",
      "Epoch 3186, Loss: 0.00036893580818286864, Final Batch Loss: 7.2877110142144375e-06\n",
      "Epoch 3187, Loss: 6.326142192847328e-05, Final Batch Loss: 1.3954763744550291e-05\n",
      "Epoch 3188, Loss: 0.0014983187456891756, Final Batch Loss: 0.0014905569842085242\n",
      "Epoch 3189, Loss: 4.172670469415607e-05, Final Batch Loss: 2.906445115513634e-05\n",
      "Epoch 3190, Loss: 7.491180076613091e-05, Final Batch Loss: 2.0445779227884486e-05\n",
      "Epoch 3191, Loss: 0.0007133818107831758, Final Batch Loss: 3.5676010156748816e-05\n",
      "Epoch 3192, Loss: 0.0018641025271790568, Final Batch Loss: 0.0018461637664586306\n",
      "Epoch 3193, Loss: 0.001839886317611672, Final Batch Loss: 0.00013659884280059487\n",
      "Epoch 3194, Loss: 0.00033424840148654766, Final Batch Loss: 3.5986671719001606e-05\n",
      "Epoch 3195, Loss: 2.74672365776496e-05, Final Batch Loss: 1.770685048541054e-05\n",
      "Epoch 3196, Loss: 3.07250829791883e-05, Final Batch Loss: 1.7666212443145923e-05\n",
      "Epoch 3197, Loss: 1.3175540516385809e-05, Final Batch Loss: 7.183999059634516e-06\n",
      "Epoch 3198, Loss: 2.216333359683631e-05, Final Batch Loss: 1.6351594240404665e-05\n",
      "Epoch 3199, Loss: 0.0020056720677530393, Final Batch Loss: 0.001930953236296773\n",
      "Epoch 3200, Loss: 0.0009386299470861559, Final Batch Loss: 1.3307185326993931e-05\n",
      "Epoch 3201, Loss: 0.00011087049369962187, Final Batch Loss: 1.1089065992564429e-05\n",
      "Epoch 3202, Loss: 0.00030406657606363297, Final Batch Loss: 0.00028055167058482766\n",
      "Epoch 3203, Loss: 3.59212617695448e-05, Final Batch Loss: 1.2078761756129097e-05\n",
      "Epoch 3204, Loss: 2.0763277916557854e-05, Final Batch Loss: 1.451216303394176e-05\n",
      "Epoch 3205, Loss: 6.297506479313597e-05, Final Batch Loss: 3.905331323039718e-05\n",
      "Epoch 3206, Loss: 0.0001583605680934852, Final Batch Loss: 0.0001499620993854478\n",
      "Epoch 3207, Loss: 3.272073263360653e-05, Final Batch Loss: 1.1411933883209713e-05\n",
      "Epoch 3208, Loss: 0.0016206111608880747, Final Batch Loss: 5.057881480752258e-06\n",
      "Epoch 3209, Loss: 0.00013147358549758792, Final Batch Loss: 4.725898907054216e-05\n",
      "Epoch 3210, Loss: 0.0015286678935808595, Final Batch Loss: 0.0015205033123493195\n",
      "Epoch 3211, Loss: 0.0030857276724418625, Final Batch Loss: 0.002940972102805972\n",
      "Epoch 3212, Loss: 0.0005543351362575777, Final Batch Loss: 0.0005070863990113139\n",
      "Epoch 3213, Loss: 3.244901108701015e-05, Final Batch Loss: 2.412632602499798e-05\n",
      "Epoch 3214, Loss: 0.00012037455962854438, Final Batch Loss: 6.719505472574383e-05\n",
      "Epoch 3215, Loss: 3.232761628169101e-05, Final Batch Loss: 1.417205567122437e-05\n",
      "Epoch 3216, Loss: 5.860714827576885e-05, Final Batch Loss: 1.0391243449703325e-05\n",
      "Epoch 3217, Loss: 7.685805940127466e-05, Final Batch Loss: 4.6508725063176826e-05\n",
      "Epoch 3218, Loss: 0.006199291887241998, Final Batch Loss: 0.006196246948093176\n",
      "Epoch 3219, Loss: 0.00026047651408589445, Final Batch Loss: 0.00021566149371210486\n",
      "Epoch 3220, Loss: 7.154841659939848e-05, Final Batch Loss: 1.633294959901832e-05\n",
      "Epoch 3221, Loss: 0.0001245546154677868, Final Batch Loss: 2.1645304514095187e-05\n",
      "Epoch 3222, Loss: 0.0014404334433493204, Final Batch Loss: 0.001365199452266097\n",
      "Epoch 3223, Loss: 0.00034065353247569874, Final Batch Loss: 0.00010647092858562246\n",
      "Epoch 3224, Loss: 1.4292188552644802e-05, Final Batch Loss: 6.257554105104646e-06\n",
      "Epoch 3225, Loss: 9.277303161070449e-05, Final Batch Loss: 8.265082578873262e-05\n",
      "Epoch 3226, Loss: 5.164193680684548e-05, Final Batch Loss: 1.6499159755767323e-05\n",
      "Epoch 3227, Loss: 0.0001791577597032301, Final Batch Loss: 0.00012160547339590266\n",
      "Epoch 3228, Loss: 7.759944219287718e-05, Final Batch Loss: 6.502743781311437e-05\n",
      "Epoch 3229, Loss: 0.00012139705904701259, Final Batch Loss: 1.7887910871650092e-05\n",
      "Epoch 3230, Loss: 5.863587466592435e-05, Final Batch Loss: 4.450219785212539e-05\n",
      "Epoch 3231, Loss: 0.0002974115268443711, Final Batch Loss: 4.000310582341626e-05\n",
      "Epoch 3232, Loss: 1.0540284165472258e-05, Final Batch Loss: 4.3200384425290395e-06\n",
      "Epoch 3233, Loss: 4.153374447923852e-05, Final Batch Loss: 1.4508995263895486e-05\n",
      "Epoch 3234, Loss: 0.0003277257555964752, Final Batch Loss: 8.62568322190782e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3235, Loss: 4.342554439062951e-05, Final Batch Loss: 6.111683433118742e-06\n",
      "Epoch 3236, Loss: 1.8460112642060267e-05, Final Batch Loss: 1.3780399967799895e-05\n",
      "Epoch 3237, Loss: 3.008145995408995e-05, Final Batch Loss: 7.1248787207878195e-06\n",
      "Epoch 3238, Loss: 3.3107231956819305e-05, Final Batch Loss: 2.665244392119348e-05\n",
      "Epoch 3239, Loss: 3.21098486892879e-05, Final Batch Loss: 1.6005806173780002e-05\n",
      "Epoch 3240, Loss: 5.197568270887132e-06, Final Batch Loss: 2.192346983065363e-06\n",
      "Epoch 3241, Loss: 0.00028315745294094086, Final Batch Loss: 6.7986169597134e-05\n",
      "Epoch 3242, Loss: 0.0027627400122582912, Final Batch Loss: 0.0021017875988036394\n",
      "Epoch 3243, Loss: 0.00012057851927238517, Final Batch Loss: 7.054679736029357e-05\n",
      "Epoch 3244, Loss: 1.4845943496766267e-05, Final Batch Loss: 4.559158242045669e-06\n",
      "Epoch 3245, Loss: 4.221597828291124e-05, Final Batch Loss: 3.6804751289309934e-05\n",
      "Epoch 3246, Loss: 4.364392407296691e-05, Final Batch Loss: 7.091761290212162e-06\n",
      "Epoch 3247, Loss: 0.0013906619358294847, Final Batch Loss: 2.4840780952217756e-06\n",
      "Epoch 3248, Loss: 9.098050941247493e-05, Final Batch Loss: 1.7920850950758904e-05\n",
      "Epoch 3249, Loss: 0.00012212541287226486, Final Batch Loss: 2.224914624093799e-06\n",
      "Epoch 3250, Loss: 1.687516987658455e-05, Final Batch Loss: 1.1842291314678732e-05\n",
      "Epoch 3251, Loss: 1.723257537378231e-05, Final Batch Loss: 1.150748721556738e-05\n",
      "Epoch 3252, Loss: 0.0014449396394411451, Final Batch Loss: 0.0014375736936926842\n",
      "Epoch 3253, Loss: 4.687881028075935e-05, Final Batch Loss: 4.8266747398884036e-06\n",
      "Epoch 3254, Loss: 0.0007512977354053874, Final Batch Loss: 4.738965799333528e-06\n",
      "Epoch 3255, Loss: 4.91980636070366e-05, Final Batch Loss: 3.93495756725315e-05\n",
      "Epoch 3256, Loss: 8.130272453854559e-05, Final Batch Loss: 7.04852063790895e-05\n",
      "Epoch 3257, Loss: 0.00021150226530153304, Final Batch Loss: 0.0001420458866050467\n",
      "Epoch 3258, Loss: 1.242606776941102e-05, Final Batch Loss: 8.600006367487367e-06\n",
      "Epoch 3259, Loss: 7.420418751280522e-05, Final Batch Loss: 6.217073678271845e-05\n",
      "Epoch 3260, Loss: 6.819779991928954e-05, Final Batch Loss: 5.560857607633807e-05\n",
      "Epoch 3261, Loss: 0.004709440749138594, Final Batch Loss: 0.0033233817666769028\n",
      "Epoch 3262, Loss: 0.00021088703852001345, Final Batch Loss: 0.00019910179253201932\n",
      "Epoch 3263, Loss: 0.0007512756237701979, Final Batch Loss: 0.0007151687168516219\n",
      "Epoch 3264, Loss: 2.5071087748074206e-05, Final Batch Loss: 6.815620963607216e-06\n",
      "Epoch 3265, Loss: 0.0009917253069033904, Final Batch Loss: 2.3707420950813685e-06\n",
      "Epoch 3266, Loss: 4.063388360009412e-05, Final Batch Loss: 3.577441748348065e-05\n",
      "Epoch 3267, Loss: 0.0001319922130278428, Final Batch Loss: 4.065453140356112e-06\n",
      "Epoch 3268, Loss: 0.00023022160530672409, Final Batch Loss: 1.4581124560208991e-05\n",
      "Epoch 3269, Loss: 6.511276433229796e-05, Final Batch Loss: 6.14709415458492e-06\n",
      "Epoch 3270, Loss: 9.011519432533532e-05, Final Batch Loss: 3.132604615529999e-05\n",
      "Epoch 3271, Loss: 1.9213762243452948e-05, Final Batch Loss: 1.1659452866297215e-05\n",
      "Epoch 3272, Loss: 1.4947735962778097e-05, Final Batch Loss: 1.0983562788169365e-05\n",
      "Epoch 3273, Loss: 0.0003598076002617745, Final Batch Loss: 2.6617783532856265e-06\n",
      "Epoch 3274, Loss: 0.005656755447716932, Final Batch Loss: 2.4995881631184602e-06\n",
      "Epoch 3275, Loss: 6.344237772282213e-05, Final Batch Loss: 4.888308103545569e-05\n",
      "Epoch 3276, Loss: 3.570404714992037e-05, Final Batch Loss: 6.197324182721786e-07\n",
      "Epoch 3277, Loss: 0.0002676844669622369, Final Batch Loss: 0.00010131461749551818\n",
      "Epoch 3278, Loss: 3.3978245255639195e-05, Final Batch Loss: 2.0782824776688358e-06\n",
      "Epoch 3279, Loss: 0.014902870054356754, Final Batch Loss: 0.013267497532069683\n",
      "Epoch 3280, Loss: 4.841400004806928e-05, Final Batch Loss: 2.644194864842575e-05\n",
      "Epoch 3281, Loss: 0.0006778038659831509, Final Batch Loss: 1.8240869394503534e-05\n",
      "Epoch 3282, Loss: 0.002690735971555114, Final Batch Loss: 0.002414135495200753\n",
      "Epoch 3283, Loss: 5.552696529775858e-05, Final Batch Loss: 1.1510284821270034e-05\n",
      "Epoch 3284, Loss: 2.2799762973590987e-05, Final Batch Loss: 5.345166300685378e-06\n",
      "Epoch 3285, Loss: 0.0009607989195501432, Final Batch Loss: 9.805189620237797e-05\n",
      "Epoch 3286, Loss: 7.134535462682834e-05, Final Batch Loss: 1.3271305761008989e-05\n",
      "Epoch 3287, Loss: 0.00012977252481505275, Final Batch Loss: 6.237318302737549e-05\n",
      "Epoch 3288, Loss: 0.00012693093776761089, Final Batch Loss: 0.00011587358312681317\n",
      "Epoch 3289, Loss: 4.162636287219357e-05, Final Batch Loss: 1.0764351827674545e-05\n",
      "Epoch 3290, Loss: 0.0002108793742081616, Final Batch Loss: 3.871096487273462e-05\n",
      "Epoch 3291, Loss: 3.340064904477913e-05, Final Batch Loss: 1.5831139535293914e-05\n",
      "Epoch 3292, Loss: 4.522510425886139e-05, Final Batch Loss: 2.3712089387117885e-05\n",
      "Epoch 3293, Loss: 1.390870647810516e-05, Final Batch Loss: 6.48823242954677e-06\n",
      "Epoch 3294, Loss: 9.67411142482888e-06, Final Batch Loss: 3.4169624996138737e-06\n",
      "Epoch 3295, Loss: 3.6139825169811957e-05, Final Batch Loss: 9.398709153174423e-06\n",
      "Epoch 3296, Loss: 6.792699696234195e-05, Final Batch Loss: 1.2886403965239879e-05\n",
      "Epoch 3297, Loss: 0.00029334809551073704, Final Batch Loss: 0.0002879359817598015\n",
      "Epoch 3298, Loss: 1.552489970890747e-05, Final Batch Loss: 3.001543291247799e-06\n",
      "Epoch 3299, Loss: 0.00010913279584201518, Final Batch Loss: 1.620406146685127e-05\n",
      "Epoch 3300, Loss: 0.0017079612553061452, Final Batch Loss: 1.8675633327802643e-05\n",
      "Epoch 3301, Loss: 3.749505049199797e-05, Final Batch Loss: 1.4800352801103145e-05\n",
      "Epoch 3302, Loss: 7.180642842286034e-05, Final Batch Loss: 1.462524141970789e-05\n",
      "Epoch 3303, Loss: 0.002059070444374811, Final Batch Loss: 0.0019818702712655067\n",
      "Epoch 3304, Loss: 8.395629811275285e-05, Final Batch Loss: 5.44219437870197e-05\n",
      "Epoch 3305, Loss: 0.00024168926756829023, Final Batch Loss: 2.9176502721384168e-05\n",
      "Epoch 3306, Loss: 3.3303214877378196e-05, Final Batch Loss: 1.6443527783849277e-05\n",
      "Epoch 3307, Loss: 6.914978166605579e-05, Final Batch Loss: 4.919010279991198e-06\n",
      "Epoch 3308, Loss: 0.002001275545808312, Final Batch Loss: 0.0019873492419719696\n",
      "Epoch 3309, Loss: 0.002010047819567262, Final Batch Loss: 2.997779483848717e-05\n",
      "Epoch 3310, Loss: 1.9107756543235155e-05, Final Batch Loss: 5.738278105127392e-06\n",
      "Epoch 3311, Loss: 0.0017454383487347513, Final Batch Loss: 0.0016091895522549748\n",
      "Epoch 3312, Loss: 0.00035890568324248306, Final Batch Loss: 1.9680428522406146e-05\n",
      "Epoch 3313, Loss: 2.9374088626354933e-05, Final Batch Loss: 2.0403011149028316e-05\n",
      "Epoch 3314, Loss: 3.796703276748303e-05, Final Batch Loss: 1.0102157830260694e-05\n",
      "Epoch 3315, Loss: 1.9128465737594524e-05, Final Batch Loss: 7.567647571704583e-06\n",
      "Epoch 3316, Loss: 0.0005391627405515464, Final Batch Loss: 7.174871370807523e-06\n",
      "Epoch 3317, Loss: 4.7624935632484267e-05, Final Batch Loss: 4.649717538995901e-06\n",
      "Epoch 3318, Loss: 1.1988344340352342e-05, Final Batch Loss: 8.882149813871365e-06\n",
      "Epoch 3319, Loss: 3.8745789424865507e-05, Final Batch Loss: 2.550363205955364e-06\n",
      "Epoch 3320, Loss: 2.4854354705894366e-05, Final Batch Loss: 7.610697139170952e-06\n",
      "Epoch 3321, Loss: 3.240797377657145e-05, Final Batch Loss: 1.3952791050542146e-05\n",
      "Epoch 3322, Loss: 6.624726211157395e-05, Final Batch Loss: 5.9401234466349706e-05\n",
      "Epoch 3323, Loss: 0.00011596776039368706, Final Batch Loss: 3.2087382351164706e-06\n",
      "Epoch 3324, Loss: 1.4163687183099682e-05, Final Batch Loss: 1.637047489566612e-06\n",
      "Epoch 3325, Loss: 0.005391544196754694, Final Batch Loss: 0.002110955538228154\n",
      "Epoch 3326, Loss: 8.58874773257412e-06, Final Batch Loss: 3.0052001420699526e-06\n",
      "Epoch 3327, Loss: 0.001911038923481101, Final Batch Loss: 7.287174867087742e-06\n",
      "Epoch 3328, Loss: 0.00020019764633616433, Final Batch Loss: 2.087867324007675e-05\n",
      "Epoch 3329, Loss: 6.354197694236063e-06, Final Batch Loss: 1.4719096270709997e-06\n",
      "Epoch 3330, Loss: 2.9551065381383523e-05, Final Batch Loss: 8.250895916717127e-06\n",
      "Epoch 3331, Loss: 9.02457904885523e-05, Final Batch Loss: 4.602493208949454e-05\n",
      "Epoch 3332, Loss: 0.005299734242726117, Final Batch Loss: 0.004867514129728079\n",
      "Epoch 3333, Loss: 1.1163983344886219e-05, Final Batch Loss: 5.691934347851202e-06\n",
      "Epoch 3334, Loss: 0.0046444457620964386, Final Batch Loss: 3.638599446276203e-05\n",
      "Epoch 3335, Loss: 3.1929821489029564e-05, Final Batch Loss: 8.913664714782499e-06\n",
      "Epoch 3336, Loss: 6.863265025458531e-05, Final Batch Loss: 1.483644973632181e-05\n",
      "Epoch 3337, Loss: 0.0020283488579480036, Final Batch Loss: 0.002026444533839822\n",
      "Epoch 3338, Loss: 0.00044998276280239224, Final Batch Loss: 1.4371471479535103e-05\n",
      "Epoch 3339, Loss: 7.119738074834459e-05, Final Batch Loss: 3.187844413332641e-05\n",
      "Epoch 3340, Loss: 4.480202824197477e-05, Final Batch Loss: 6.106215550971683e-06\n",
      "Epoch 3341, Loss: 1.2721066127596714e-05, Final Batch Loss: 1.0945406756945886e-05\n",
      "Epoch 3342, Loss: 4.7495732360403053e-05, Final Batch Loss: 4.0219496440840885e-05\n",
      "Epoch 3343, Loss: 0.0025682299165055156, Final Batch Loss: 0.0012856344692409039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3344, Loss: 1.495171864007716e-05, Final Batch Loss: 9.1728279585368e-06\n",
      "Epoch 3345, Loss: 9.719932359075756e-05, Final Batch Loss: 4.921765594190219e-06\n",
      "Epoch 3346, Loss: 2.3878802494436968e-05, Final Batch Loss: 8.495912879880052e-06\n",
      "Epoch 3347, Loss: 0.0007572324630018556, Final Batch Loss: 1.8615895896800794e-05\n",
      "Epoch 3348, Loss: 2.7499942461872706e-05, Final Batch Loss: 3.971116257162066e-06\n",
      "Epoch 3349, Loss: 0.00021394236682681367, Final Batch Loss: 0.00017602059233468026\n",
      "Epoch 3350, Loss: 7.288129472726723e-05, Final Batch Loss: 6.884022150188684e-05\n",
      "Epoch 3351, Loss: 3.3623512251779175e-05, Final Batch Loss: 7.863115456530068e-07\n",
      "Epoch 3352, Loss: 1.2026747299387353e-05, Final Batch Loss: 5.287946805765387e-06\n",
      "Epoch 3353, Loss: 0.0016041512299125316, Final Batch Loss: 1.3045633750152774e-05\n",
      "Epoch 3354, Loss: 0.0002710851258598268, Final Batch Loss: 2.7576519642025232e-05\n",
      "Epoch 3355, Loss: 5.831620183016639e-05, Final Batch Loss: 1.704819624137599e-05\n",
      "Epoch 3356, Loss: 1.3056897046226368e-05, Final Batch Loss: 1.1742310562112834e-05\n",
      "Epoch 3357, Loss: 6.652343699897756e-06, Final Batch Loss: 3.956534783355892e-06\n",
      "Epoch 3358, Loss: 5.657371548295487e-05, Final Batch Loss: 3.263463077018969e-05\n",
      "Epoch 3359, Loss: 7.750997610855848e-05, Final Batch Loss: 7.571914466097951e-06\n",
      "Epoch 3360, Loss: 4.978036122338381e-05, Final Batch Loss: 1.1218982763239183e-05\n",
      "Epoch 3361, Loss: 0.00012548494123620912, Final Batch Loss: 0.00011941633420065045\n",
      "Epoch 3362, Loss: 0.000797782103290956, Final Batch Loss: 1.3669962754647713e-05\n",
      "Epoch 3363, Loss: 2.062072042008367e-05, Final Batch Loss: 1.955407060449943e-05\n",
      "Epoch 3364, Loss: 0.00012204288941575214, Final Batch Loss: 4.82702671433799e-05\n",
      "Epoch 3365, Loss: 2.473986205586698e-05, Final Batch Loss: 7.842807463021018e-06\n",
      "Epoch 3366, Loss: 5.222447839514643e-06, Final Batch Loss: 3.3938974866032368e-06\n",
      "Epoch 3367, Loss: 0.00031168162922767806, Final Batch Loss: 0.00030774131300859153\n",
      "Epoch 3368, Loss: 0.001201098504679976, Final Batch Loss: 4.069688657182269e-05\n",
      "Epoch 3369, Loss: 0.0005101408041809918, Final Batch Loss: 5.516822056961246e-06\n",
      "Epoch 3370, Loss: 0.006888475967571139, Final Batch Loss: 0.0030717230401933193\n",
      "Epoch 3371, Loss: 1.9256374798715115e-05, Final Batch Loss: 1.280545438930858e-05\n",
      "Epoch 3372, Loss: 2.1561068933806382e-05, Final Batch Loss: 1.421735214535147e-05\n",
      "Epoch 3373, Loss: 4.800368787982734e-05, Final Batch Loss: 4.0707534935791045e-05\n",
      "Epoch 3374, Loss: 5.766111394223117e-05, Final Batch Loss: 5.417521242634393e-05\n",
      "Epoch 3375, Loss: 0.0014015485685376916, Final Batch Loss: 0.001368192839436233\n",
      "Epoch 3376, Loss: 0.01439117849804461, Final Batch Loss: 0.0001008997205644846\n",
      "Epoch 3377, Loss: 3.2838244806043804e-05, Final Batch Loss: 2.1706451661884785e-05\n",
      "Epoch 3378, Loss: 0.0009231152653228492, Final Batch Loss: 0.00010445239604450762\n",
      "Epoch 3379, Loss: 0.00011674002780637238, Final Batch Loss: 9.134505671681836e-05\n",
      "Epoch 3380, Loss: 0.00018736278252617922, Final Batch Loss: 1.695070204732474e-05\n",
      "Epoch 3381, Loss: 4.931845796818379e-05, Final Batch Loss: 3.9582599129062146e-05\n",
      "Epoch 3382, Loss: 0.011751000285585178, Final Batch Loss: 0.011737437918782234\n",
      "Epoch 3383, Loss: 0.00012543837510747835, Final Batch Loss: 8.660364983370528e-05\n",
      "Epoch 3384, Loss: 2.9312001970538404e-05, Final Batch Loss: 1.311240248469403e-05\n",
      "Epoch 3385, Loss: 0.0010138035631825915, Final Batch Loss: 0.0009954461129382253\n",
      "Epoch 3386, Loss: 0.00028745758027071133, Final Batch Loss: 0.00023612077347934246\n",
      "Epoch 3387, Loss: 0.0023660403603571467, Final Batch Loss: 0.0023173706140369177\n",
      "Epoch 3388, Loss: 6.626653794228332e-05, Final Batch Loss: 1.1335405361023732e-06\n",
      "Epoch 3389, Loss: 0.00012984992008568952, Final Batch Loss: 0.0001188469395856373\n",
      "Epoch 3390, Loss: 4.3704859308490995e-05, Final Batch Loss: 3.115000436082482e-05\n",
      "Epoch 3391, Loss: 8.394010819756659e-05, Final Batch Loss: 7.901232311269268e-05\n",
      "Epoch 3392, Loss: 6.650663453910965e-05, Final Batch Loss: 1.9169556253473274e-05\n",
      "Epoch 3393, Loss: 0.0043528930436878, Final Batch Loss: 0.00432077469304204\n",
      "Epoch 3394, Loss: 4.677283050114056e-05, Final Batch Loss: 3.3341581001877785e-05\n",
      "Epoch 3395, Loss: 4.3971424020128325e-05, Final Batch Loss: 1.6369978766306303e-05\n",
      "Epoch 3396, Loss: 6.146257419459289e-06, Final Batch Loss: 4.0239651752926875e-06\n",
      "Epoch 3397, Loss: 0.0025518132365505153, Final Batch Loss: 5.951243565505138e-06\n",
      "Epoch 3398, Loss: 0.0001210675727634225, Final Batch Loss: 6.890253280289471e-05\n",
      "Epoch 3399, Loss: 0.0016887162200873718, Final Batch Loss: 0.0015407896135002375\n",
      "Epoch 3400, Loss: 8.17123259366781e-06, Final Batch Loss: 4.4865591917186975e-06\n",
      "Epoch 3401, Loss: 4.8105806854437105e-05, Final Batch Loss: 2.8454232960939407e-05\n",
      "Epoch 3402, Loss: 3.553249734977726e-05, Final Batch Loss: 2.2457925297203474e-05\n",
      "Epoch 3403, Loss: 7.84283429311472e-06, Final Batch Loss: 6.3327229327114765e-06\n",
      "Epoch 3404, Loss: 4.097608143638354e-05, Final Batch Loss: 1.0593681508908048e-05\n",
      "Epoch 3405, Loss: 0.00026720474124886096, Final Batch Loss: 0.0001923999807331711\n",
      "Epoch 3406, Loss: 0.0001308656355831772, Final Batch Loss: 8.75253026606515e-05\n",
      "Epoch 3407, Loss: 0.00023374055672320537, Final Batch Loss: 0.0002314433950232342\n",
      "Epoch 3408, Loss: 0.001269634929485619, Final Batch Loss: 5.132053047418594e-06\n",
      "Epoch 3409, Loss: 1.3212443263910245e-05, Final Batch Loss: 6.629628387599951e-06\n",
      "Epoch 3410, Loss: 0.0005658187401422765, Final Batch Loss: 0.000540940323844552\n",
      "Epoch 3411, Loss: 7.723620001343079e-06, Final Batch Loss: 3.900147930835374e-06\n",
      "Epoch 3412, Loss: 8.030236290323955e-05, Final Batch Loss: 3.3959420306928223e-06\n",
      "Epoch 3413, Loss: 3.059015034523327e-05, Final Batch Loss: 1.1811031072284095e-05\n",
      "Epoch 3414, Loss: 8.463745280096191e-05, Final Batch Loss: 5.774585133622168e-06\n",
      "Epoch 3415, Loss: 1.2438155863492284e-05, Final Batch Loss: 3.890540938300546e-06\n",
      "Epoch 3416, Loss: 9.769590405994677e-05, Final Batch Loss: 7.375942459475482e-06\n",
      "Epoch 3417, Loss: 1.0957690847135382e-05, Final Batch Loss: 5.754482572228881e-06\n",
      "Epoch 3418, Loss: 6.725205139446189e-06, Final Batch Loss: 3.093774694207241e-06\n",
      "Epoch 3419, Loss: 0.0002569699138348369, Final Batch Loss: 1.4363906757353107e-06\n",
      "Epoch 3420, Loss: 1.7804242816055194e-05, Final Batch Loss: 1.2040659385093022e-05\n",
      "Epoch 3421, Loss: 8.138053931361355e-05, Final Batch Loss: 1.9035953755519586e-06\n",
      "Epoch 3422, Loss: 6.756559469067724e-05, Final Batch Loss: 5.66483722650446e-05\n",
      "Epoch 3423, Loss: 0.002311481162905693, Final Batch Loss: 0.0021491486113518476\n",
      "Epoch 3424, Loss: 0.00039391656400766806, Final Batch Loss: 0.0003918814763892442\n",
      "Epoch 3425, Loss: 9.220626816386357e-05, Final Batch Loss: 3.3876091038109735e-05\n",
      "Epoch 3426, Loss: 3.976446987508098e-05, Final Batch Loss: 3.260477569710929e-06\n",
      "Epoch 3427, Loss: 0.00020647224300773814, Final Batch Loss: 7.653015927644446e-05\n",
      "Epoch 3428, Loss: 3.2446459499624325e-05, Final Batch Loss: 4.502745923673501e-06\n",
      "Epoch 3429, Loss: 5.956160703135538e-05, Final Batch Loss: 4.823548351851059e-06\n",
      "Epoch 3430, Loss: 4.135542258154601e-05, Final Batch Loss: 8.71636439114809e-06\n",
      "Epoch 3431, Loss: 0.00021213659965724219, Final Batch Loss: 0.0001883077493403107\n",
      "Epoch 3432, Loss: 0.0003388684071978787, Final Batch Loss: 0.00033080109278671443\n",
      "Epoch 3433, Loss: 0.000238761835078094, Final Batch Loss: 9.047561775332724e-07\n",
      "Epoch 3434, Loss: 9.286224894822226e-06, Final Batch Loss: 2.9399832328635966e-06\n",
      "Epoch 3435, Loss: 0.0023596156388521194, Final Batch Loss: 0.0013023982755839825\n",
      "Epoch 3436, Loss: 2.4880235741875367e-05, Final Batch Loss: 1.5866994544921909e-06\n",
      "Epoch 3437, Loss: 7.397222725558095e-05, Final Batch Loss: 4.715426257462241e-05\n",
      "Epoch 3438, Loss: 1.2746280162900803e-05, Final Batch Loss: 1.087050713977078e-05\n",
      "Epoch 3439, Loss: 0.001828604559705127, Final Batch Loss: 0.001804322237148881\n",
      "Epoch 3440, Loss: 6.228820711839944e-05, Final Batch Loss: 2.2290420019999146e-05\n",
      "Epoch 3441, Loss: 7.654171940885135e-05, Final Batch Loss: 7.1669987846689764e-06\n",
      "Epoch 3442, Loss: 1.0690814633562695e-05, Final Batch Loss: 4.6339710024767555e-06\n",
      "Epoch 3443, Loss: 3.653341400422505e-05, Final Batch Loss: 3.073429979849607e-05\n",
      "Epoch 3444, Loss: 0.0033295824250672013, Final Batch Loss: 0.003066310193389654\n",
      "Epoch 3445, Loss: 2.3035861886455677e-05, Final Batch Loss: 2.3544253053842112e-06\n",
      "Epoch 3446, Loss: 0.0015539063065261871, Final Batch Loss: 4.88775958729093e-06\n",
      "Epoch 3447, Loss: 2.3686080112383934e-05, Final Batch Loss: 1.6305748431477696e-05\n",
      "Epoch 3448, Loss: 0.00016719110885787813, Final Batch Loss: 2.2404640276363352e-06\n",
      "Epoch 3449, Loss: 1.2010178579657804e-05, Final Batch Loss: 5.335059540811926e-06\n",
      "Epoch 3450, Loss: 0.0009154674353339942, Final Batch Loss: 2.7328833311912604e-05\n",
      "Epoch 3451, Loss: 0.0008839213467126683, Final Batch Loss: 9.788261650101049e-07\n",
      "Epoch 3452, Loss: 3.163686142215738e-05, Final Batch Loss: 2.4475255486322567e-05\n",
      "Epoch 3453, Loss: 0.0003189682320225984, Final Batch Loss: 6.159502663649619e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3454, Loss: 0.00042110845606657676, Final Batch Loss: 5.4927524615777656e-05\n",
      "Epoch 3455, Loss: 0.0014087821214161522, Final Batch Loss: 1.2808336578018498e-06\n",
      "Epoch 3456, Loss: 1.0409480637463275e-05, Final Batch Loss: 2.9407142392301466e-06\n",
      "Epoch 3457, Loss: 0.0013640437646245118, Final Batch Loss: 5.399211295298301e-05\n",
      "Epoch 3458, Loss: 0.0007352509201155044, Final Batch Loss: 0.00010913532605627552\n",
      "Epoch 3459, Loss: 0.00015588377209496684, Final Batch Loss: 0.00010710278002079576\n",
      "Epoch 3460, Loss: 0.00024173936208171654, Final Batch Loss: 0.00023496401263400912\n",
      "Epoch 3461, Loss: 6.0238499827391934e-05, Final Batch Loss: 5.0297028792556375e-05\n",
      "Epoch 3462, Loss: 0.00025124806597887073, Final Batch Loss: 0.00023286804207600653\n",
      "Epoch 3463, Loss: 0.0013773629116258235, Final Batch Loss: 9.301272257289384e-06\n",
      "Epoch 3464, Loss: 0.0001644044605200179, Final Batch Loss: 2.902983396779746e-06\n",
      "Epoch 3465, Loss: 0.0002474666544003412, Final Batch Loss: 9.512847464065999e-05\n",
      "Epoch 3466, Loss: 0.00016750424811107223, Final Batch Loss: 3.869794909405755e-06\n",
      "Epoch 3467, Loss: 0.0001297668791266915, Final Batch Loss: 6.525384833366843e-06\n",
      "Epoch 3468, Loss: 6.534320050377573e-05, Final Batch Loss: 2.800909669531393e-06\n",
      "Epoch 3469, Loss: 0.0008373199962079525, Final Batch Loss: 0.00050616409862414\n",
      "Epoch 3470, Loss: 2.187286872867844e-05, Final Batch Loss: 1.9144639736623503e-05\n",
      "Epoch 3471, Loss: 0.0013824501002090983, Final Batch Loss: 7.429857942042872e-05\n",
      "Epoch 3472, Loss: 0.0001080566507880576, Final Batch Loss: 1.658718247199431e-05\n",
      "Epoch 3473, Loss: 8.44564582394014e-05, Final Batch Loss: 8.272800187114626e-05\n",
      "Epoch 3474, Loss: 0.00016968779164017178, Final Batch Loss: 4.171209366177209e-05\n",
      "Epoch 3475, Loss: 9.738442895468324e-05, Final Batch Loss: 1.3608194421976805e-05\n",
      "Epoch 3476, Loss: 5.15811589139048e-05, Final Batch Loss: 3.315603680675849e-05\n",
      "Epoch 3477, Loss: 6.062527245376259e-05, Final Batch Loss: 2.901757397921756e-05\n",
      "Epoch 3478, Loss: 0.00014443347140513652, Final Batch Loss: 0.00014247906801756471\n",
      "Epoch 3479, Loss: 1.831521558415261e-05, Final Batch Loss: 3.90467039323994e-06\n",
      "Epoch 3480, Loss: 0.0001572630244481843, Final Batch Loss: 5.1599523430923e-05\n",
      "Epoch 3481, Loss: 2.5576681935035595e-05, Final Batch Loss: 2.1472368416652898e-07\n",
      "Epoch 3482, Loss: 9.230817522620782e-05, Final Batch Loss: 1.6646823496557772e-05\n",
      "Epoch 3483, Loss: 0.0001606391670065932, Final Batch Loss: 7.200467371148989e-05\n",
      "Epoch 3484, Loss: 1.2497878287831554e-05, Final Batch Loss: 1.1217130122531671e-06\n",
      "Epoch 3485, Loss: 1.996150376726291e-05, Final Batch Loss: 4.447201263246825e-06\n",
      "Epoch 3486, Loss: 1.1251670002820902e-05, Final Batch Loss: 4.578759217110928e-06\n",
      "Epoch 3487, Loss: 9.124383814196335e-05, Final Batch Loss: 8.095819066511467e-05\n",
      "Epoch 3488, Loss: 1.5481111859116936e-05, Final Batch Loss: 4.306693426769925e-06\n",
      "Epoch 3489, Loss: 3.593041492422344e-05, Final Batch Loss: 2.2266794985625893e-05\n",
      "Epoch 3490, Loss: 0.0014631673966505332, Final Batch Loss: 0.0014388865092769265\n",
      "Epoch 3491, Loss: 2.89012227767671e-05, Final Batch Loss: 2.2719090338796377e-05\n",
      "Epoch 3492, Loss: 2.0224732452334138e-05, Final Batch Loss: 6.886500614200486e-06\n",
      "Epoch 3493, Loss: 1.2164763575128745e-05, Final Batch Loss: 5.034476998844184e-06\n",
      "Epoch 3494, Loss: 0.00012486239029385615, Final Batch Loss: 2.4802300686133094e-05\n",
      "Epoch 3495, Loss: 6.243227630875481e-06, Final Batch Loss: 4.536681444733404e-06\n",
      "Epoch 3496, Loss: 7.113177116480074e-05, Final Batch Loss: 5.826981123391306e-06\n",
      "Epoch 3497, Loss: 0.0001653060971875675, Final Batch Loss: 0.0001244737213710323\n",
      "Epoch 3498, Loss: 9.92843956737488e-06, Final Batch Loss: 7.488247319997754e-06\n",
      "Epoch 3499, Loss: 0.00011718099267454818, Final Batch Loss: 3.322777047287673e-05\n",
      "Epoch 3500, Loss: 0.00018165872279496398, Final Batch Loss: 0.00016343007155228406\n",
      "Epoch 3501, Loss: 0.04357172027607703, Final Batch Loss: 0.04356960207223892\n",
      "Epoch 3502, Loss: 2.8715841835946776e-05, Final Batch Loss: 2.072914139716886e-05\n",
      "Epoch 3503, Loss: 8.014984200599429e-05, Final Batch Loss: 2.0449472231121035e-06\n",
      "Epoch 3504, Loss: 3.6619305319618434e-05, Final Batch Loss: 1.6803536709630862e-05\n",
      "Epoch 3505, Loss: 7.983767636687844e-05, Final Batch Loss: 7.385663047898561e-05\n",
      "Epoch 3506, Loss: 0.0001288990788452793, Final Batch Loss: 8.027596777537838e-05\n",
      "Epoch 3507, Loss: 0.001536809515528148, Final Batch Loss: 2.45623778027948e-05\n",
      "Epoch 3508, Loss: 3.2907513741520233e-05, Final Batch Loss: 1.3283313819556497e-05\n",
      "Epoch 3509, Loss: 0.00016465010048705153, Final Batch Loss: 3.636290421127342e-05\n",
      "Epoch 3510, Loss: 2.9900217668910045e-05, Final Batch Loss: 1.615434666746296e-05\n",
      "Epoch 3511, Loss: 0.00010879829824261833, Final Batch Loss: 2.0908659280394204e-05\n",
      "Epoch 3512, Loss: 2.8929302061442286e-05, Final Batch Loss: 1.2094884368707426e-05\n",
      "Epoch 3513, Loss: 0.0001203919655381469, Final Batch Loss: 9.494214464211836e-05\n",
      "Epoch 3514, Loss: 0.00018675696992431767, Final Batch Loss: 2.7085963665740564e-05\n",
      "Epoch 3515, Loss: 0.0002583005843916908, Final Batch Loss: 0.00017926713917404413\n",
      "Epoch 3516, Loss: 0.0010187203843088355, Final Batch Loss: 1.0806888894876465e-05\n",
      "Epoch 3517, Loss: 9.682061227067607e-05, Final Batch Loss: 8.555234671803191e-05\n",
      "Epoch 3518, Loss: 0.0007177435763878748, Final Batch Loss: 0.0006970589747652411\n",
      "Epoch 3519, Loss: 0.00017698126976029016, Final Batch Loss: 5.2581588533939794e-05\n",
      "Epoch 3520, Loss: 8.171857916750014e-05, Final Batch Loss: 3.3109474316006526e-05\n",
      "Epoch 3521, Loss: 3.635305074567441e-05, Final Batch Loss: 1.5204001101665199e-05\n",
      "Epoch 3522, Loss: 3.76577863789862e-05, Final Batch Loss: 2.586812297522556e-05\n",
      "Epoch 3523, Loss: 0.00015590613838867284, Final Batch Loss: 9.60594043135643e-05\n",
      "Epoch 3524, Loss: 0.002161205091397278, Final Batch Loss: 9.627272083889693e-05\n",
      "Epoch 3525, Loss: 0.0021074251126265153, Final Batch Loss: 0.001953902654349804\n",
      "Epoch 3526, Loss: 5.513256837730296e-05, Final Batch Loss: 3.960112371714786e-05\n",
      "Epoch 3527, Loss: 0.00047116526548052207, Final Batch Loss: 0.00036828318843618035\n",
      "Epoch 3528, Loss: 0.0001590068859513849, Final Batch Loss: 0.0001425063528586179\n",
      "Epoch 3529, Loss: 0.0005666761335305637, Final Batch Loss: 0.000551251694560051\n",
      "Epoch 3530, Loss: 0.0012542339391075075, Final Batch Loss: 6.610102718695998e-05\n",
      "Epoch 3531, Loss: 8.328794137923978e-05, Final Batch Loss: 4.0220922528533265e-05\n",
      "Epoch 3532, Loss: 5.405878346209647e-05, Final Batch Loss: 4.776689820573665e-05\n",
      "Epoch 3533, Loss: 7.394503700197674e-05, Final Batch Loss: 3.165119778714143e-05\n",
      "Epoch 3534, Loss: 0.0002220359247075976, Final Batch Loss: 1.1026198080799077e-05\n",
      "Epoch 3535, Loss: 0.001048891066602664, Final Batch Loss: 1.2219959899084643e-05\n",
      "Epoch 3536, Loss: 2.9733198971371166e-05, Final Batch Loss: 2.1772759282612242e-05\n",
      "Epoch 3537, Loss: 6.094709715398494e-05, Final Batch Loss: 1.2467220585676841e-05\n",
      "Epoch 3538, Loss: 9.023227721627336e-05, Final Batch Loss: 1.5085852282936685e-05\n",
      "Epoch 3539, Loss: 5.927492384216748e-05, Final Batch Loss: 5.795907782157883e-06\n",
      "Epoch 3540, Loss: 0.0004926272958982736, Final Batch Loss: 0.00027067429618909955\n",
      "Epoch 3541, Loss: 0.0037763113832625095, Final Batch Loss: 0.0037525296211242676\n",
      "Epoch 3542, Loss: 2.5861963422357803e-05, Final Batch Loss: 7.187172286649002e-06\n",
      "Epoch 3543, Loss: 0.0001418162792106159, Final Batch Loss: 9.672440501162782e-05\n",
      "Epoch 3544, Loss: 0.0008733141567063285, Final Batch Loss: 1.6959615095402114e-05\n",
      "Epoch 3545, Loss: 2.5408389774383977e-05, Final Batch Loss: 3.3789037843234837e-06\n",
      "Epoch 3546, Loss: 0.0012601308230841823, Final Batch Loss: 3.530917183525162e-06\n",
      "Epoch 3547, Loss: 4.093266943527851e-05, Final Batch Loss: 2.192480860685464e-05\n",
      "Epoch 3548, Loss: 9.917464467434911e-05, Final Batch Loss: 1.2248138773429673e-05\n",
      "Epoch 3549, Loss: 0.00018158975899496, Final Batch Loss: 7.576516054541571e-06\n",
      "Epoch 3550, Loss: 0.006859726831862645, Final Batch Loss: 0.0068497974425554276\n",
      "Epoch 3551, Loss: 7.056472895783372e-05, Final Batch Loss: 1.011407221085392e-05\n",
      "Epoch 3552, Loss: 8.149928180500865e-05, Final Batch Loss: 5.5600685300305486e-05\n",
      "Epoch 3553, Loss: 0.0025331723172712373, Final Batch Loss: 7.908385668997653e-06\n",
      "Epoch 3554, Loss: 0.00012903145398013294, Final Batch Loss: 1.603372220415622e-05\n",
      "Epoch 3555, Loss: 0.0005710757941415068, Final Batch Loss: 3.5609376936918125e-05\n",
      "Epoch 3556, Loss: 0.015002550864664954, Final Batch Loss: 1.1783400623244233e-05\n",
      "Epoch 3557, Loss: 1.3361005130718695e-05, Final Batch Loss: 7.842721970519051e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3558, Loss: 2.3829554265830666e-05, Final Batch Loss: 9.42525002756156e-06\n",
      "Epoch 3559, Loss: 4.795415952685289e-05, Final Batch Loss: 2.2708525648340583e-05\n",
      "Epoch 3560, Loss: 5.8218001868226565e-05, Final Batch Loss: 4.3868811189895496e-05\n",
      "Epoch 3561, Loss: 0.00023661817249376327, Final Batch Loss: 3.0310373404063284e-05\n",
      "Epoch 3562, Loss: 5.48439552403579e-05, Final Batch Loss: 4.8325207899324596e-05\n",
      "Epoch 3563, Loss: 2.425619459245354e-05, Final Batch Loss: 1.3977980415802449e-05\n",
      "Epoch 3564, Loss: 3.884479974658461e-05, Final Batch Loss: 1.2102326763852034e-05\n",
      "Epoch 3565, Loss: 0.00014166456821840256, Final Batch Loss: 8.804869139567018e-06\n",
      "Epoch 3566, Loss: 0.00016008817965484923, Final Batch Loss: 0.0001503540697740391\n",
      "Epoch 3567, Loss: 0.00012284124250072637, Final Batch Loss: 3.721898337971652e-06\n",
      "Epoch 3568, Loss: 0.00269647449022159, Final Batch Loss: 0.0020892415195703506\n",
      "Epoch 3569, Loss: 7.076661859173328e-05, Final Batch Loss: 4.59985931229312e-05\n",
      "Epoch 3570, Loss: 0.00044838753092335537, Final Batch Loss: 0.0004213028878439218\n",
      "Epoch 3571, Loss: 8.08596614660928e-05, Final Batch Loss: 2.0478537408052944e-05\n",
      "Epoch 3572, Loss: 0.0003911124913429376, Final Batch Loss: 1.354713094769977e-05\n",
      "Epoch 3573, Loss: 4.244790670782095e-05, Final Batch Loss: 1.3677944480150472e-05\n",
      "Epoch 3574, Loss: 7.548071243945742e-05, Final Batch Loss: 9.687327292340342e-06\n",
      "Epoch 3575, Loss: 0.00011047969746869057, Final Batch Loss: 7.645177538506687e-05\n",
      "Epoch 3576, Loss: 0.00025345618087158073, Final Batch Loss: 1.542570134915877e-05\n",
      "Epoch 3577, Loss: 7.493238445022143e-05, Final Batch Loss: 2.8827154892496765e-05\n",
      "Epoch 3578, Loss: 1.967858315765625e-05, Final Batch Loss: 1.3046110325376503e-06\n",
      "Epoch 3579, Loss: 7.363838130913791e-05, Final Batch Loss: 6.932692940608831e-06\n",
      "Epoch 3580, Loss: 0.00010485107486601919, Final Batch Loss: 7.180761167546734e-05\n",
      "Epoch 3581, Loss: 0.00011880625652338495, Final Batch Loss: 3.822683083853917e-06\n",
      "Epoch 3582, Loss: 0.0006562762455359916, Final Batch Loss: 4.8690153562347405e-06\n",
      "Epoch 3583, Loss: 2.9934577469248325e-05, Final Batch Loss: 4.0180730138672516e-06\n",
      "Epoch 3584, Loss: 8.323069232574198e-05, Final Batch Loss: 1.9450331819825806e-05\n",
      "Epoch 3585, Loss: 6.045812460797606e-05, Final Batch Loss: 9.213558769260999e-06\n",
      "Epoch 3586, Loss: 0.004162474320764886, Final Batch Loss: 0.004153617192059755\n",
      "Epoch 3587, Loss: 8.104317203105893e-05, Final Batch Loss: 6.993913848418742e-05\n",
      "Epoch 3588, Loss: 3.602072501962539e-05, Final Batch Loss: 1.0080275387736037e-05\n",
      "Epoch 3589, Loss: 5.780232459073886e-05, Final Batch Loss: 3.112071499344893e-05\n",
      "Epoch 3590, Loss: 0.00024337560989806661, Final Batch Loss: 4.714188435173128e-06\n",
      "Epoch 3591, Loss: 5.0778270633600187e-05, Final Batch Loss: 1.1442715731391218e-05\n",
      "Epoch 3592, Loss: 2.2992393496679142e-05, Final Batch Loss: 1.0368518815084826e-05\n",
      "Epoch 3593, Loss: 0.00023556969608762302, Final Batch Loss: 2.4104087060550228e-05\n",
      "Epoch 3594, Loss: 0.001144665224273922, Final Batch Loss: 2.3394404706778005e-05\n",
      "Epoch 3595, Loss: 7.375862878689077e-05, Final Batch Loss: 6.143676728243008e-05\n",
      "Epoch 3596, Loss: 4.121478195884265e-05, Final Batch Loss: 2.998417585331481e-05\n",
      "Epoch 3597, Loss: 7.854857653910585e-05, Final Batch Loss: 7.621835538884625e-05\n",
      "Epoch 3598, Loss: 6.016973748046439e-05, Final Batch Loss: 4.31894077337347e-05\n",
      "Epoch 3599, Loss: 2.1337692487577442e-05, Final Batch Loss: 8.878419976099394e-06\n",
      "Epoch 3600, Loss: 1.8078953871736303e-05, Final Batch Loss: 1.3173359548090957e-05\n",
      "Epoch 3601, Loss: 3.764381199289346e-05, Final Batch Loss: 1.066763525159331e-05\n",
      "Epoch 3602, Loss: 0.0011342312791384757, Final Batch Loss: 3.6528625059872866e-05\n",
      "Epoch 3603, Loss: 1.9936825538025005e-05, Final Batch Loss: 4.203320258966414e-06\n",
      "Epoch 3604, Loss: 9.375411536893807e-05, Final Batch Loss: 6.679820216959342e-05\n",
      "Epoch 3605, Loss: 9.508883522357792e-05, Final Batch Loss: 4.9439022404840216e-05\n",
      "Epoch 3606, Loss: 3.684362400235841e-05, Final Batch Loss: 2.7066593247582205e-05\n",
      "Epoch 3607, Loss: 0.0003358250833116472, Final Batch Loss: 0.00020060990937054157\n",
      "Epoch 3608, Loss: 4.065443681611214e-05, Final Batch Loss: 1.3726863471674733e-05\n",
      "Epoch 3609, Loss: 1.680559307715157e-05, Final Batch Loss: 7.3880719355656765e-06\n",
      "Epoch 3610, Loss: 3.8048732676543295e-05, Final Batch Loss: 9.163810318568721e-06\n",
      "Epoch 3611, Loss: 0.00011580768477870151, Final Batch Loss: 5.834830517414957e-06\n",
      "Epoch 3612, Loss: 0.006217143585672602, Final Batch Loss: 0.006069641560316086\n",
      "Epoch 3613, Loss: 0.0002627733374538366, Final Batch Loss: 0.0002054261858575046\n",
      "Epoch 3614, Loss: 8.943332431954332e-05, Final Batch Loss: 7.838792953407392e-05\n",
      "Epoch 3615, Loss: 0.000655292786177597, Final Batch Loss: 1.35138016048586e-05\n",
      "Epoch 3616, Loss: 4.675545642385259e-05, Final Batch Loss: 2.311360185558442e-05\n",
      "Epoch 3617, Loss: 8.780899952398613e-05, Final Batch Loss: 1.3348668289836496e-05\n",
      "Epoch 3618, Loss: 0.0001432154131180141, Final Batch Loss: 4.270337740308605e-05\n",
      "Epoch 3619, Loss: 0.0033675413401397236, Final Batch Loss: 4.122481641388731e-06\n",
      "Epoch 3620, Loss: 3.5595592635218054e-05, Final Batch Loss: 2.1265717805363238e-05\n",
      "Epoch 3621, Loss: 5.6743096820355277e-05, Final Batch Loss: 5.381645678426139e-05\n",
      "Epoch 3622, Loss: 2.1491447000698827e-05, Final Batch Loss: 1.3090483435007627e-06\n",
      "Epoch 3623, Loss: 0.004071597591973841, Final Batch Loss: 0.0011804717360064387\n",
      "Epoch 3624, Loss: 0.001384648054227, Final Batch Loss: 2.9335871658986434e-05\n",
      "Epoch 3625, Loss: 0.0010401217787148198, Final Batch Loss: 1.1036527212127112e-05\n",
      "Epoch 3626, Loss: 0.0001280549513467122, Final Batch Loss: 1.3725180906476453e-05\n",
      "Epoch 3627, Loss: 0.0005160973214515252, Final Batch Loss: 2.8176551495562308e-05\n",
      "Epoch 3628, Loss: 2.5858448907456477e-05, Final Batch Loss: 3.7936890748824226e-06\n",
      "Epoch 3629, Loss: 1.9831078134302516e-05, Final Batch Loss: 8.673669981362764e-06\n",
      "Epoch 3630, Loss: 1.8319679838896263e-05, Final Batch Loss: 6.269265213632025e-06\n",
      "Epoch 3631, Loss: 7.278821249201428e-05, Final Batch Loss: 4.7169691242743284e-05\n",
      "Epoch 3632, Loss: 0.0001028567276080139, Final Batch Loss: 4.730226646643132e-05\n",
      "Epoch 3633, Loss: 4.762340267916443e-05, Final Batch Loss: 6.517469046229962e-06\n",
      "Epoch 3634, Loss: 9.201749344356358e-05, Final Batch Loss: 5.920821422478184e-05\n",
      "Epoch 3635, Loss: 2.759285689535318e-05, Final Batch Loss: 1.2604578842001501e-05\n",
      "Epoch 3636, Loss: 5.1306624300195836e-05, Final Batch Loss: 2.4311293600476347e-05\n",
      "Epoch 3637, Loss: 0.0028693436506728176, Final Batch Loss: 1.755755874910392e-05\n",
      "Epoch 3638, Loss: 0.0012497470670496114, Final Batch Loss: 0.0011517314705997705\n",
      "Epoch 3639, Loss: 8.331598655786365e-05, Final Batch Loss: 6.623314402531832e-05\n",
      "Epoch 3640, Loss: 3.418226333451457e-05, Final Batch Loss: 1.007282298814971e-05\n",
      "Epoch 3641, Loss: 5.176672675588634e-05, Final Batch Loss: 3.35279582941439e-05\n",
      "Epoch 3642, Loss: 3.115588697255589e-05, Final Batch Loss: 3.891420419677161e-06\n",
      "Epoch 3643, Loss: 1.0275415206706384e-05, Final Batch Loss: 4.331758191256085e-06\n",
      "Epoch 3644, Loss: 8.248400718002813e-05, Final Batch Loss: 7.062703662086278e-05\n",
      "Epoch 3645, Loss: 2.5385027583979536e-05, Final Batch Loss: 7.784535227983724e-06\n",
      "Epoch 3646, Loss: 6.207184560480528e-05, Final Batch Loss: 4.9139733164338395e-05\n",
      "Epoch 3647, Loss: 3.512624607537873e-05, Final Batch Loss: 2.228559969807975e-05\n",
      "Epoch 3648, Loss: 1.5285662811947986e-05, Final Batch Loss: 2.7364685593056493e-06\n",
      "Epoch 3649, Loss: 2.0364621832413832e-05, Final Batch Loss: 4.877391347690718e-06\n",
      "Epoch 3650, Loss: 0.0002797477427520789, Final Batch Loss: 0.0001066750191967003\n",
      "Epoch 3651, Loss: 5.5133710702648386e-05, Final Batch Loss: 3.4113698347937316e-05\n",
      "Epoch 3652, Loss: 4.4855747546534985e-05, Final Batch Loss: 3.0586397770093754e-05\n",
      "Epoch 3653, Loss: 3.07243135466706e-05, Final Batch Loss: 1.3210874385549687e-05\n",
      "Epoch 3654, Loss: 3.490143353701569e-05, Final Batch Loss: 6.051070158719085e-06\n",
      "Epoch 3655, Loss: 0.0016616198008705396, Final Batch Loss: 3.093287887168117e-05\n",
      "Epoch 3656, Loss: 0.04052422348468099, Final Batch Loss: 0.00010612759797368199\n",
      "Epoch 3657, Loss: 1.836802812249516e-05, Final Batch Loss: 1.3104927347740158e-05\n",
      "Epoch 3658, Loss: 0.0006209031053003855, Final Batch Loss: 0.000579457264393568\n",
      "Epoch 3659, Loss: 0.0018809755092661362, Final Batch Loss: 0.0018450344214215875\n",
      "Epoch 3660, Loss: 0.0031281044794013724, Final Batch Loss: 0.003068450838327408\n",
      "Epoch 3661, Loss: 0.0005174561301828362, Final Batch Loss: 0.00047890981659293175\n",
      "Epoch 3662, Loss: 0.0001016899805108551, Final Batch Loss: 5.6121898523997515e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3663, Loss: 0.0028100488452764694, Final Batch Loss: 0.0027896983083337545\n",
      "Epoch 3664, Loss: 9.306641004513949e-05, Final Batch Loss: 2.024372952291742e-05\n",
      "Epoch 3665, Loss: 0.00028295421361690387, Final Batch Loss: 8.692239498486742e-05\n",
      "Epoch 3666, Loss: 0.00021408569955383427, Final Batch Loss: 2.150235013687052e-05\n",
      "Epoch 3667, Loss: 0.0001424079637217801, Final Batch Loss: 4.288773561711423e-05\n",
      "Epoch 3668, Loss: 8.722368875169195e-05, Final Batch Loss: 6.684418622171506e-06\n",
      "Epoch 3669, Loss: 6.057708014850505e-05, Final Batch Loss: 3.307124643470161e-05\n",
      "Epoch 3670, Loss: 0.0004992605781808379, Final Batch Loss: 9.945036254066508e-06\n",
      "Epoch 3671, Loss: 0.00010474014743522275, Final Batch Loss: 2.6482894099899568e-05\n",
      "Epoch 3672, Loss: 0.0009912247405736707, Final Batch Loss: 7.418050518026575e-05\n",
      "Epoch 3673, Loss: 0.0019408794978517108, Final Batch Loss: 0.00010347062925575301\n",
      "Epoch 3674, Loss: 3.211376861145254e-05, Final Batch Loss: 1.3267206668388098e-05\n",
      "Epoch 3675, Loss: 0.00023250932827068027, Final Batch Loss: 2.0540557670756243e-05\n",
      "Epoch 3676, Loss: 0.00015325694403145462, Final Batch Loss: 5.3990639571566135e-05\n",
      "Epoch 3677, Loss: 0.0023804892825864954, Final Batch Loss: 0.0023636966943740845\n",
      "Epoch 3678, Loss: 6.3088555180002e-05, Final Batch Loss: 8.072132914094254e-06\n",
      "Epoch 3679, Loss: 8.745577542867977e-05, Final Batch Loss: 7.088057463988662e-05\n",
      "Epoch 3680, Loss: 0.0033155438213725574, Final Batch Loss: 0.00326280458830297\n",
      "Epoch 3681, Loss: 8.090964183793403e-05, Final Batch Loss: 3.484018088784069e-05\n",
      "Epoch 3682, Loss: 9.525721361569595e-05, Final Batch Loss: 1.2497204807004891e-05\n",
      "Epoch 3683, Loss: 4.622391497832723e-05, Final Batch Loss: 2.16968146560248e-05\n",
      "Epoch 3684, Loss: 0.0003775977711484302, Final Batch Loss: 4.561087189358659e-05\n",
      "Epoch 3685, Loss: 9.821374624152668e-05, Final Batch Loss: 5.154731479706243e-05\n",
      "Epoch 3686, Loss: 0.00032709793231333606, Final Batch Loss: 2.5307479518232867e-05\n",
      "Epoch 3687, Loss: 0.00015920456121421012, Final Batch Loss: 3.6752046526089543e-06\n",
      "Epoch 3688, Loss: 0.00011823768363683484, Final Batch Loss: 7.983051182236522e-05\n",
      "Epoch 3689, Loss: 0.0021783770607726183, Final Batch Loss: 1.1970343621214852e-05\n",
      "Epoch 3690, Loss: 0.002851754423318198, Final Batch Loss: 0.002807788783684373\n",
      "Epoch 3691, Loss: 0.00025437675503781065, Final Batch Loss: 7.262675353558734e-05\n",
      "Epoch 3692, Loss: 5.659831003868021e-05, Final Batch Loss: 1.7236645362572744e-05\n",
      "Epoch 3693, Loss: 0.0012464607425499707, Final Batch Loss: 6.68728316668421e-05\n",
      "Epoch 3694, Loss: 0.0017804958738452115, Final Batch Loss: 0.0017764868680387735\n",
      "Epoch 3695, Loss: 6.54290938655322e-05, Final Batch Loss: 7.357205959124258e-06\n",
      "Epoch 3696, Loss: 6.322121953417081e-05, Final Batch Loss: 2.403329017397482e-05\n",
      "Epoch 3697, Loss: 0.0002817987788148457, Final Batch Loss: 2.0769579350599088e-05\n",
      "Epoch 3698, Loss: 0.00014613464372814633, Final Batch Loss: 0.00011764332884922624\n",
      "Epoch 3699, Loss: 0.00016052951377787394, Final Batch Loss: 1.0493039553693961e-05\n",
      "Epoch 3700, Loss: 0.00011542199354153126, Final Batch Loss: 3.485155320959166e-05\n",
      "Epoch 3701, Loss: 0.001182409028388065, Final Batch Loss: 3.1703634704172146e-06\n",
      "Epoch 3702, Loss: 0.0009020073011924978, Final Batch Loss: 4.095749682164751e-05\n",
      "Epoch 3703, Loss: 0.00014203775390342344, Final Batch Loss: 2.378997487539891e-05\n",
      "Epoch 3704, Loss: 0.0015656835821573623, Final Batch Loss: 0.001477398443967104\n",
      "Epoch 3705, Loss: 4.59603270428488e-05, Final Batch Loss: 2.236286672996357e-05\n",
      "Epoch 3706, Loss: 0.0013900424401072087, Final Batch Loss: 2.2743903173250146e-05\n",
      "Epoch 3707, Loss: 0.0008028225038287928, Final Batch Loss: 1.5989504390745424e-05\n",
      "Epoch 3708, Loss: 3.34153296535078e-05, Final Batch Loss: 3.835984443867346e-06\n",
      "Epoch 3709, Loss: 0.0005732435674872249, Final Batch Loss: 0.00044808490201830864\n",
      "Epoch 3710, Loss: 3.628650529208244e-05, Final Batch Loss: 4.276333584130043e-06\n",
      "Epoch 3711, Loss: 0.005270189329166897, Final Batch Loss: 0.0002104306622641161\n",
      "Epoch 3712, Loss: 0.0032450634280394297, Final Batch Loss: 3.6099529097555205e-05\n",
      "Epoch 3713, Loss: 9.146327647613361e-05, Final Batch Loss: 8.124554733512923e-05\n",
      "Epoch 3714, Loss: 0.002055868215393275, Final Batch Loss: 0.001371261547319591\n",
      "Epoch 3715, Loss: 0.00013041387501289137, Final Batch Loss: 4.793017069459893e-05\n",
      "Epoch 3716, Loss: 0.00017852406745078042, Final Batch Loss: 0.00012952576798852533\n",
      "Epoch 3717, Loss: 0.00014125653706287267, Final Batch Loss: 1.2981680811208207e-05\n",
      "Epoch 3718, Loss: 4.430332387528324e-05, Final Batch Loss: 2.931133849415346e-06\n",
      "Epoch 3719, Loss: 0.0004382157167128753, Final Batch Loss: 2.2523116058437154e-05\n",
      "Epoch 3720, Loss: 0.001385183470119955, Final Batch Loss: 7.66937228036113e-06\n",
      "Epoch 3721, Loss: 6.53201873319631e-05, Final Batch Loss: 7.233241831272608e-06\n",
      "Epoch 3722, Loss: 9.803331886359956e-05, Final Batch Loss: 1.7361626305500977e-05\n",
      "Epoch 3723, Loss: 7.99038043624023e-05, Final Batch Loss: 3.016148002643604e-05\n",
      "Epoch 3724, Loss: 1.4016382010595407e-05, Final Batch Loss: 9.679441063781269e-06\n",
      "Epoch 3725, Loss: 0.0003012965553352842, Final Batch Loss: 9.72928864939604e-06\n",
      "Epoch 3726, Loss: 2.574985319370171e-05, Final Batch Loss: 1.490045997343259e-05\n",
      "Epoch 3727, Loss: 6.844222480140161e-05, Final Batch Loss: 5.148151467437856e-05\n",
      "Epoch 3728, Loss: 0.00010042410758615006, Final Batch Loss: 2.8489275791798718e-05\n",
      "Epoch 3729, Loss: 0.002550667144532781, Final Batch Loss: 0.0024751934688538313\n",
      "Epoch 3730, Loss: 0.00010378359365859069, Final Batch Loss: 4.812148472410627e-05\n",
      "Epoch 3731, Loss: 0.0013602667895611376, Final Batch Loss: 0.0011299619218334556\n",
      "Epoch 3732, Loss: 0.004764466976666881, Final Batch Loss: 8.24542894406477e-06\n",
      "Epoch 3733, Loss: 8.997595250548329e-05, Final Batch Loss: 7.033769361441955e-05\n",
      "Epoch 3734, Loss: 4.489111415750813e-05, Final Batch Loss: 2.5698247554828413e-05\n",
      "Epoch 3735, Loss: 9.772784324013628e-05, Final Batch Loss: 3.887353523168713e-05\n",
      "Epoch 3736, Loss: 0.00016276767564704642, Final Batch Loss: 0.0001120050874305889\n",
      "Epoch 3737, Loss: 8.008795157365967e-05, Final Batch Loss: 5.2278017392382026e-05\n",
      "Epoch 3738, Loss: 0.0031019856432976667, Final Batch Loss: 1.9338887796038762e-05\n",
      "Epoch 3739, Loss: 0.00014132233263808303, Final Batch Loss: 3.451655720709823e-05\n",
      "Epoch 3740, Loss: 0.0007626024562341627, Final Batch Loss: 0.0007018012111075222\n",
      "Epoch 3741, Loss: 8.738231917959638e-05, Final Batch Loss: 4.387947774375789e-05\n",
      "Epoch 3742, Loss: 6.150627086753957e-05, Final Batch Loss: 2.4678469344507903e-05\n",
      "Epoch 3743, Loss: 0.00017056695651262999, Final Batch Loss: 0.0001284000463783741\n",
      "Epoch 3744, Loss: 7.370599087153096e-05, Final Batch Loss: 1.2830738342017867e-05\n",
      "Epoch 3745, Loss: 9.347094237455167e-05, Final Batch Loss: 5.6189346651080996e-05\n",
      "Epoch 3746, Loss: 9.665312609286048e-05, Final Batch Loss: 2.7626640076050535e-05\n",
      "Epoch 3747, Loss: 0.0004213626671116799, Final Batch Loss: 0.00030798718216829\n",
      "Epoch 3748, Loss: 0.00020392271926539252, Final Batch Loss: 9.300108104071114e-06\n",
      "Epoch 3749, Loss: 5.590020737145096e-05, Final Batch Loss: 1.8261624063597992e-05\n",
      "Epoch 3750, Loss: 0.0014890225138515234, Final Batch Loss: 1.0666903108358383e-05\n",
      "Epoch 3751, Loss: 2.578617841209052e-05, Final Batch Loss: 8.96318397280993e-06\n",
      "Epoch 3752, Loss: 9.912165205605561e-05, Final Batch Loss: 1.2308010809647385e-05\n",
      "Epoch 3753, Loss: 4.3686462504410883e-05, Final Batch Loss: 4.032839115097886e-06\n",
      "Epoch 3754, Loss: 0.00034521382440289017, Final Batch Loss: 1.1996706234640442e-05\n",
      "Epoch 3755, Loss: 4.310852455091663e-05, Final Batch Loss: 3.0412342312047258e-05\n",
      "Epoch 3756, Loss: 1.706819693936268e-05, Final Batch Loss: 1.1626420928223524e-05\n",
      "Epoch 3757, Loss: 3.381525857548695e-05, Final Batch Loss: 5.508998583536595e-06\n",
      "Epoch 3758, Loss: 1.111799929276458e-05, Final Batch Loss: 6.407234650396276e-06\n",
      "Epoch 3759, Loss: 0.00012411809802870266, Final Batch Loss: 6.435140676330775e-05\n",
      "Epoch 3760, Loss: 8.306089330289979e-05, Final Batch Loss: 6.476981070591137e-05\n",
      "Epoch 3761, Loss: 9.708141806186177e-05, Final Batch Loss: 6.612369179492816e-05\n",
      "Epoch 3762, Loss: 0.0019320869650982786, Final Batch Loss: 0.0019175787456333637\n",
      "Epoch 3763, Loss: 8.893278572941199e-05, Final Batch Loss: 4.126591738895513e-05\n",
      "Epoch 3764, Loss: 0.0009242280375474365, Final Batch Loss: 0.0009195492602884769\n",
      "Epoch 3765, Loss: 9.415870408702176e-05, Final Batch Loss: 1.4690469470224343e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3766, Loss: 0.0012230463235027855, Final Batch Loss: 0.0011990113416686654\n",
      "Epoch 3767, Loss: 0.00010947155897156335, Final Batch Loss: 3.501211540424265e-05\n",
      "Epoch 3768, Loss: 9.518355773252551e-05, Final Batch Loss: 6.55956364425947e-06\n",
      "Epoch 3769, Loss: 3.2537463994231075e-05, Final Batch Loss: 1.1618503776844591e-05\n",
      "Epoch 3770, Loss: 3.982046291639563e-05, Final Batch Loss: 3.6081615689909086e-05\n",
      "Epoch 3771, Loss: 4.456880014913622e-05, Final Batch Loss: 2.8017206204822287e-05\n",
      "Epoch 3772, Loss: 0.00014140612984192558, Final Batch Loss: 1.880168929346837e-05\n",
      "Epoch 3773, Loss: 1.3294857126311399e-05, Final Batch Loss: 5.1145370889571495e-06\n",
      "Epoch 3774, Loss: 6.786937592551112e-05, Final Batch Loss: 3.231276059523225e-05\n",
      "Epoch 3775, Loss: 0.001147732697063475, Final Batch Loss: 9.920540833263658e-06\n",
      "Epoch 3776, Loss: 0.001045146780597861, Final Batch Loss: 0.0010336919222027063\n",
      "Epoch 3777, Loss: 3.9557555282954127e-05, Final Batch Loss: 1.674397753959056e-05\n",
      "Epoch 3778, Loss: 0.00014094605330683407, Final Batch Loss: 4.874470050708624e-06\n",
      "Epoch 3779, Loss: 0.0002299225379829295, Final Batch Loss: 0.00012609998520929366\n",
      "Epoch 3780, Loss: 5.8711651945486665e-05, Final Batch Loss: 9.756466170074418e-06\n",
      "Epoch 3781, Loss: 1.4898300150889554e-05, Final Batch Loss: 3.4020379189314554e-06\n",
      "Epoch 3782, Loss: 6.680491969746072e-05, Final Batch Loss: 5.725338633055799e-05\n",
      "Epoch 3783, Loss: 0.0009572758981448715, Final Batch Loss: 0.0009452738449908793\n",
      "Epoch 3784, Loss: 0.00016755570413806709, Final Batch Loss: 1.0876728993025608e-06\n",
      "Epoch 3785, Loss: 0.00013853353084414266, Final Batch Loss: 9.727357974043116e-05\n",
      "Epoch 3786, Loss: 0.0017705304985611292, Final Batch Loss: 4.7708367674204055e-06\n",
      "Epoch 3787, Loss: 2.9475272640411276e-05, Final Batch Loss: 1.521337435406167e-05\n",
      "Epoch 3788, Loss: 0.00029936917235318106, Final Batch Loss: 1.1021720638382249e-05\n",
      "Epoch 3789, Loss: 0.0009292934119002894, Final Batch Loss: 5.07799704791978e-05\n",
      "Epoch 3790, Loss: 0.0006139855977380648, Final Batch Loss: 0.000575584766920656\n",
      "Epoch 3791, Loss: 5.913572545068746e-05, Final Batch Loss: 2.2856199848320102e-06\n",
      "Epoch 3792, Loss: 0.001056180855812272, Final Batch Loss: 1.7208101780852303e-05\n",
      "Epoch 3793, Loss: 0.0019706514231074834, Final Batch Loss: 0.0019599127117544413\n",
      "Epoch 3794, Loss: 5.948809939582134e-05, Final Batch Loss: 1.5238162632158492e-05\n",
      "Epoch 3795, Loss: 2.0677927750512026e-05, Final Batch Loss: 1.5129332496144343e-05\n",
      "Epoch 3796, Loss: 4.882393295702059e-05, Final Batch Loss: 2.9072112738504075e-05\n",
      "Epoch 3797, Loss: 5.160427008377155e-05, Final Batch Loss: 3.823517545242794e-05\n",
      "Epoch 3798, Loss: 4.0388890738540795e-05, Final Batch Loss: 3.0331533707794733e-05\n",
      "Epoch 3799, Loss: 6.969764035602566e-05, Final Batch Loss: 5.308280015015043e-05\n",
      "Epoch 3800, Loss: 0.00014286750592873432, Final Batch Loss: 9.380220581078902e-05\n",
      "Epoch 3801, Loss: 3.728146748471772e-05, Final Batch Loss: 1.0265063792758156e-05\n",
      "Epoch 3802, Loss: 2.2087754928179493e-05, Final Batch Loss: 2.0260204109945334e-05\n",
      "Epoch 3803, Loss: 0.0010346017079427838, Final Batch Loss: 0.0006634888704866171\n",
      "Epoch 3804, Loss: 1.0297164635630907e-05, Final Batch Loss: 3.6625276607082924e-06\n",
      "Epoch 3805, Loss: 3.354383034093189e-05, Final Batch Loss: 6.193592980707763e-06\n",
      "Epoch 3806, Loss: 3.0160709684423637e-05, Final Batch Loss: 1.487847384851193e-05\n",
      "Epoch 3807, Loss: 0.001391374971717596, Final Batch Loss: 0.0007097000489011407\n",
      "Epoch 3808, Loss: 5.669556344400917e-06, Final Batch Loss: 9.410788379682344e-07\n",
      "Epoch 3809, Loss: 4.341303065302782e-05, Final Batch Loss: 8.184309990610927e-06\n",
      "Epoch 3810, Loss: 5.938200592936482e-05, Final Batch Loss: 4.2218824091833085e-05\n",
      "Epoch 3811, Loss: 0.0006001223805469635, Final Batch Loss: 3.4143445191148203e-06\n",
      "Epoch 3812, Loss: 0.0006027058225299697, Final Batch Loss: 0.0005616267444565892\n",
      "Epoch 3813, Loss: 0.00012446873734006658, Final Batch Loss: 8.413358591496944e-05\n",
      "Epoch 3814, Loss: 0.00024999170273076743, Final Batch Loss: 7.866864325478673e-05\n",
      "Epoch 3815, Loss: 0.00019101268117083237, Final Batch Loss: 0.0001811589754652232\n",
      "Epoch 3816, Loss: 6.276331737353757e-05, Final Batch Loss: 3.2005493721953826e-06\n",
      "Epoch 3817, Loss: 0.0004858888642047532, Final Batch Loss: 8.722014172235504e-05\n",
      "Epoch 3818, Loss: 4.0866715607990045e-05, Final Batch Loss: 1.3595204109151382e-05\n",
      "Epoch 3819, Loss: 0.00026401762443128973, Final Batch Loss: 0.0002510235644876957\n",
      "Epoch 3820, Loss: 0.0055136675264293444, Final Batch Loss: 8.0283980423701e-06\n",
      "Epoch 3821, Loss: 0.0008486538135912269, Final Batch Loss: 0.0002547456242609769\n",
      "Epoch 3822, Loss: 4.18272138631437e-05, Final Batch Loss: 1.422289824404288e-05\n",
      "Epoch 3823, Loss: 0.00022053838711144635, Final Batch Loss: 8.832947969494853e-06\n",
      "Epoch 3824, Loss: 4.378200191013093e-05, Final Batch Loss: 2.8136145147072966e-07\n",
      "Epoch 3825, Loss: 0.001009063164019608, Final Batch Loss: 0.0009809494949877262\n",
      "Epoch 3826, Loss: 0.0018276199698448181, Final Batch Loss: 0.000273496494628489\n",
      "Epoch 3827, Loss: 1.0654812626853527e-05, Final Batch Loss: 1.7621836150283343e-06\n",
      "Epoch 3828, Loss: 0.0002036082764789171, Final Batch Loss: 5.677651188307209e-06\n",
      "Epoch 3829, Loss: 0.0018606181765790097, Final Batch Loss: 0.00010176171053899452\n",
      "Epoch 3830, Loss: 0.0001988011181310867, Final Batch Loss: 7.700143214606214e-06\n",
      "Epoch 3831, Loss: 1.017050635709893e-05, Final Batch Loss: 4.50438164989464e-06\n",
      "Epoch 3832, Loss: 1.1601038295339094e-05, Final Batch Loss: 9.04103580978699e-06\n",
      "Epoch 3833, Loss: 3.0482336114801e-05, Final Batch Loss: 2.3738235540804453e-05\n",
      "Epoch 3834, Loss: 0.0003665603762783576, Final Batch Loss: 3.2285508495988324e-05\n",
      "Epoch 3835, Loss: 0.00012821955829167564, Final Batch Loss: 2.9445066047628643e-06\n",
      "Epoch 3836, Loss: 1.5066352261783322e-05, Final Batch Loss: 1.2711971976386849e-05\n",
      "Epoch 3837, Loss: 0.0017595417630218435, Final Batch Loss: 4.141983299632557e-05\n",
      "Epoch 3838, Loss: 0.0011104538643849082, Final Batch Loss: 8.972909563453868e-05\n",
      "Epoch 3839, Loss: 0.0008442982617680173, Final Batch Loss: 0.0008424239931628108\n",
      "Epoch 3840, Loss: 0.0001000550837488845, Final Batch Loss: 5.054618668509647e-05\n",
      "Epoch 3841, Loss: 0.0004976743801421435, Final Batch Loss: 4.190804361314804e-07\n",
      "Epoch 3842, Loss: 8.059222500378382e-05, Final Batch Loss: 7.78302492108196e-05\n",
      "Epoch 3843, Loss: 8.146178743118071e-06, Final Batch Loss: 6.105439751991071e-06\n",
      "Epoch 3844, Loss: 0.02016996225574985, Final Batch Loss: 0.020106680691242218\n",
      "Epoch 3845, Loss: 2.3569914446852636e-05, Final Batch Loss: 1.536232048238162e-05\n",
      "Epoch 3846, Loss: 2.6476347557036206e-05, Final Batch Loss: 1.0102343367179856e-05\n",
      "Epoch 3847, Loss: 9.664288972999202e-05, Final Batch Loss: 8.460713434033096e-05\n",
      "Epoch 3848, Loss: 1.472504897037652e-05, Final Batch Loss: 7.507829309361114e-07\n",
      "Epoch 3849, Loss: 2.6274215088051278e-05, Final Batch Loss: 1.5306062778108753e-05\n",
      "Epoch 3850, Loss: 1.7792671314964537e-05, Final Batch Loss: 9.777550076250918e-06\n",
      "Epoch 3851, Loss: 4.392417076815036e-05, Final Batch Loss: 1.0683766049623955e-06\n",
      "Epoch 3852, Loss: 1.1527455171744805e-05, Final Batch Loss: 6.140222012618324e-06\n",
      "Epoch 3853, Loss: 3.86072140372562e-05, Final Batch Loss: 2.2537976747116772e-06\n",
      "Epoch 3854, Loss: 0.0013342780148377642, Final Batch Loss: 0.0012937154388055205\n",
      "Epoch 3855, Loss: 0.00036915927921654657, Final Batch Loss: 7.74237050791271e-05\n",
      "Epoch 3856, Loss: 0.0006315523751254659, Final Batch Loss: 2.32291167776566e-05\n",
      "Epoch 3857, Loss: 2.1069870854262263e-05, Final Batch Loss: 8.692579285707325e-06\n",
      "Epoch 3858, Loss: 5.881329707335681e-05, Final Batch Loss: 1.8425023881718516e-05\n",
      "Epoch 3859, Loss: 5.527310167963151e-05, Final Batch Loss: 3.359890979481861e-05\n",
      "Epoch 3860, Loss: 0.00010380790126873762, Final Batch Loss: 9.891220543067902e-05\n",
      "Epoch 3861, Loss: 6.429976929211989e-05, Final Batch Loss: 3.320024552522227e-05\n",
      "Epoch 3862, Loss: 1.7852332803158788e-05, Final Batch Loss: 4.710118901130045e-06\n",
      "Epoch 3863, Loss: 3.190133702446474e-05, Final Batch Loss: 5.108470759296324e-06\n",
      "Epoch 3864, Loss: 1.4769056861041463e-05, Final Batch Loss: 1.0996187484124675e-05\n",
      "Epoch 3865, Loss: 2.9870412618038245e-05, Final Batch Loss: 2.2789841750636697e-05\n",
      "Epoch 3866, Loss: 0.005895618814975023, Final Batch Loss: 0.0032004632521420717\n",
      "Epoch 3867, Loss: 7.033811129986134e-06, Final Batch Loss: 5.189015610085335e-06\n",
      "Epoch 3868, Loss: 2.838592649823113e-06, Final Batch Loss: 2.1486180230567697e-06\n",
      "Epoch 3869, Loss: 3.177349481120473e-05, Final Batch Loss: 1.7047972505679354e-05\n",
      "Epoch 3870, Loss: 0.0001355370925466559, Final Batch Loss: 1.4260015177569585e-06\n",
      "Epoch 3871, Loss: 0.0009250301718566334, Final Batch Loss: 0.0009159015608020127\n",
      "Epoch 3872, Loss: 0.0011619222113949945, Final Batch Loss: 0.0011568753980100155\n",
      "Epoch 3873, Loss: 0.0001649952209845651, Final Batch Loss: 0.0001305567129747942\n",
      "Epoch 3874, Loss: 6.728659536747728e-05, Final Batch Loss: 1.2451515431166627e-05\n",
      "Epoch 3875, Loss: 9.317963235844218e-05, Final Batch Loss: 3.7988513668096857e-06\n",
      "Epoch 3876, Loss: 5.605294177257747e-05, Final Batch Loss: 3.0103885819698917e-06\n",
      "Epoch 3877, Loss: 6.642122389166616e-05, Final Batch Loss: 1.9376220734557137e-05\n",
      "Epoch 3878, Loss: 8.569115243517444e-05, Final Batch Loss: 7.867877138778567e-05\n",
      "Epoch 3879, Loss: 0.0001975155209947843, Final Batch Loss: 0.0001664333394728601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3880, Loss: 6.538595516758505e-05, Final Batch Loss: 7.665292287128977e-06\n",
      "Epoch 3881, Loss: 2.1646104414685396e-05, Final Batch Loss: 4.3921058932028245e-06\n",
      "Epoch 3882, Loss: 7.974588697834406e-05, Final Batch Loss: 7.348402141360566e-05\n",
      "Epoch 3883, Loss: 0.0013283286443765974, Final Batch Loss: 0.0013239884283393621\n",
      "Epoch 3884, Loss: 5.030803504268988e-05, Final Batch Loss: 4.5727036194875836e-05\n",
      "Epoch 3885, Loss: 1.8879632762036636e-05, Final Batch Loss: 3.566754230632796e-06\n",
      "Epoch 3886, Loss: 0.004852783835303853, Final Batch Loss: 2.7808982849819586e-06\n",
      "Epoch 3887, Loss: 0.0032140510006684053, Final Batch Loss: 0.003209624672308564\n",
      "Epoch 3888, Loss: 0.000181051655090414, Final Batch Loss: 0.00013133668107911944\n",
      "Epoch 3889, Loss: 6.0308062529657036e-05, Final Batch Loss: 2.425029015284963e-05\n",
      "Epoch 3890, Loss: 0.00018025453528025537, Final Batch Loss: 0.0001751505769789219\n",
      "Epoch 3891, Loss: 0.0004429591826919932, Final Batch Loss: 0.00042608013609424233\n",
      "Epoch 3892, Loss: 0.00010303908493369818, Final Batch Loss: 5.6078293710015714e-05\n",
      "Epoch 3893, Loss: 1.7309804206888657e-05, Final Batch Loss: 9.798236533242743e-06\n",
      "Epoch 3894, Loss: 5.291581419442082e-05, Final Batch Loss: 1.393754155287752e-05\n",
      "Epoch 3895, Loss: 0.0009188667336275103, Final Batch Loss: 1.0443460269016214e-05\n",
      "Epoch 3896, Loss: 2.0384404706419446e-05, Final Batch Loss: 4.581645043799654e-06\n",
      "Epoch 3897, Loss: 3.007566283486085e-05, Final Batch Loss: 1.577456532686483e-05\n",
      "Epoch 3898, Loss: 6.821148872404592e-05, Final Batch Loss: 1.2330748177191708e-05\n",
      "Epoch 3899, Loss: 6.879898319311906e-05, Final Batch Loss: 1.0192286936216988e-05\n",
      "Epoch 3900, Loss: 4.838523136641015e-05, Final Batch Loss: 6.658443908236222e-06\n",
      "Epoch 3901, Loss: 4.3597341573331505e-05, Final Batch Loss: 2.2862986952532083e-06\n",
      "Epoch 3902, Loss: 0.000898721904377453, Final Batch Loss: 0.00018065380572807044\n",
      "Epoch 3903, Loss: 8.588604941905942e-06, Final Batch Loss: 2.1849637050763704e-06\n",
      "Epoch 3904, Loss: 1.345826012766338e-05, Final Batch Loss: 4.0084364627546165e-06\n",
      "Epoch 3905, Loss: 0.0005377109482651576, Final Batch Loss: 0.00010589875455480069\n",
      "Epoch 3906, Loss: 0.00012988035086891614, Final Batch Loss: 3.2831387215992436e-05\n",
      "Epoch 3907, Loss: 3.956205046051764e-05, Final Batch Loss: 4.5694455366174225e-06\n",
      "Epoch 3908, Loss: 0.0007398023672067211, Final Batch Loss: 0.0007283024024218321\n",
      "Epoch 3909, Loss: 6.769189531041775e-05, Final Batch Loss: 4.23150158894714e-05\n",
      "Epoch 3910, Loss: 0.000421270578954136, Final Batch Loss: 0.00036218969034962356\n",
      "Epoch 3911, Loss: 9.360450167150702e-05, Final Batch Loss: 8.44077076180838e-05\n",
      "Epoch 3912, Loss: 0.00021505601762328297, Final Batch Loss: 3.137813473585993e-05\n",
      "Epoch 3913, Loss: 0.00015488326107515604, Final Batch Loss: 0.0001490677968831733\n",
      "Epoch 3914, Loss: 7.931434447527863e-05, Final Batch Loss: 7.402628398267552e-06\n",
      "Epoch 3915, Loss: 3.764644225157099e-05, Final Batch Loss: 2.9472932510543615e-05\n",
      "Epoch 3916, Loss: 7.380462193395942e-05, Final Batch Loss: 6.285336712608114e-05\n",
      "Epoch 3917, Loss: 0.0004294341488275677, Final Batch Loss: 0.00012404474546201527\n",
      "Epoch 3918, Loss: 1.8936935703095514e-05, Final Batch Loss: 4.2610117816366255e-06\n",
      "Epoch 3919, Loss: 0.00011574779955481063, Final Batch Loss: 2.2529816305905115e-06\n",
      "Epoch 3920, Loss: 5.876765953871654e-06, Final Batch Loss: 3.1169986414170125e-06\n",
      "Epoch 3921, Loss: 0.00013878767974517814, Final Batch Loss: 1.2068964849731856e-07\n",
      "Epoch 3922, Loss: 0.0050367823023407254, Final Batch Loss: 2.0463779947021976e-05\n",
      "Epoch 3923, Loss: 3.826222155112191e-05, Final Batch Loss: 3.298306546639651e-05\n",
      "Epoch 3924, Loss: 9.372025715492782e-06, Final Batch Loss: 7.062479198793881e-06\n",
      "Epoch 3925, Loss: 9.438360575586557e-05, Final Batch Loss: 4.049162089359015e-05\n",
      "Epoch 3926, Loss: 2.3746514443701017e-06, Final Batch Loss: 8.226099907915341e-07\n",
      "Epoch 3927, Loss: 0.0008286073316412512, Final Batch Loss: 0.0007858907338231802\n",
      "Epoch 3928, Loss: 3.620748020694009e-05, Final Batch Loss: 6.947667770873522e-06\n",
      "Epoch 3929, Loss: 0.00011499834135975107, Final Batch Loss: 0.00010901865607593209\n",
      "Epoch 3930, Loss: 4.0844780414772686e-05, Final Batch Loss: 9.210128155245911e-06\n",
      "Epoch 3931, Loss: 3.34820720127027e-05, Final Batch Loss: 3.482804004306672e-06\n",
      "Epoch 3932, Loss: 1.3955771919427207e-05, Final Batch Loss: 9.274838703277055e-06\n",
      "Epoch 3933, Loss: 0.000144806811476883, Final Batch Loss: 4.807287950825412e-06\n",
      "Epoch 3934, Loss: 2.7895857783732936e-05, Final Batch Loss: 1.8483822714188136e-05\n",
      "Epoch 3935, Loss: 3.838239013020939e-05, Final Batch Loss: 3.683466275106184e-05\n",
      "Epoch 3936, Loss: 0.00013146872879588045, Final Batch Loss: 6.2092185544315726e-06\n",
      "Epoch 3937, Loss: 2.4995892090373673e-05, Final Batch Loss: 3.705548806465231e-06\n",
      "Epoch 3938, Loss: 0.0008145115243678447, Final Batch Loss: 1.4999557606643066e-05\n",
      "Epoch 3939, Loss: 0.00030050158966332674, Final Batch Loss: 6.585846131201833e-05\n",
      "Epoch 3940, Loss: 0.00015615780284861103, Final Batch Loss: 2.2239772079046816e-05\n",
      "Epoch 3941, Loss: 0.00015592557247146033, Final Batch Loss: 4.3945368815911934e-05\n",
      "Epoch 3942, Loss: 0.010072823039081413, Final Batch Loss: 1.2071228411514312e-05\n",
      "Epoch 3943, Loss: 0.002150297548865865, Final Batch Loss: 4.220402445298532e-07\n",
      "Epoch 3944, Loss: 0.0006255108291952638, Final Batch Loss: 1.7699099771562032e-05\n",
      "Epoch 3945, Loss: 0.0017739904960762942, Final Batch Loss: 2.397239768470172e-05\n",
      "Epoch 3946, Loss: 0.00019717120721907122, Final Batch Loss: 0.0001878242037491873\n",
      "Epoch 3947, Loss: 1.5323173329306883e-05, Final Batch Loss: 2.967806040032883e-06\n",
      "Epoch 3948, Loss: 0.00032196977554121986, Final Batch Loss: 9.581281483406201e-05\n",
      "Epoch 3949, Loss: 1.6524456896149786e-05, Final Batch Loss: 1.3464774383464828e-05\n",
      "Epoch 3950, Loss: 1.1286806056887144e-05, Final Batch Loss: 3.3290984902123455e-06\n",
      "Epoch 3951, Loss: 3.4390394318961626e-05, Final Batch Loss: 8.759147362980002e-07\n",
      "Epoch 3952, Loss: 5.112465532874921e-05, Final Batch Loss: 3.647904304671101e-05\n",
      "Epoch 3953, Loss: 6.993150600465015e-05, Final Batch Loss: 1.790304304449819e-05\n",
      "Epoch 3954, Loss: 0.0014727975196819898, Final Batch Loss: 2.47887351179088e-06\n",
      "Epoch 3955, Loss: 0.0002788469864754006, Final Batch Loss: 0.00026270002126693726\n",
      "Epoch 3956, Loss: 0.0032601126484905762, Final Batch Loss: 1.180965114144783e-06\n",
      "Epoch 3957, Loss: 0.0013644524151459336, Final Batch Loss: 0.0009939537849277258\n",
      "Epoch 3958, Loss: 2.1266125486363308e-05, Final Batch Loss: 1.5696480204496766e-06\n",
      "Epoch 3959, Loss: 4.919555976812262e-06, Final Batch Loss: 1.3409000985120656e-06\n",
      "Epoch 3960, Loss: 0.0001688331410605315, Final Batch Loss: 1.8124571852240479e-06\n",
      "Epoch 3961, Loss: 0.00020881964337604586, Final Batch Loss: 0.00019475148292258382\n",
      "Epoch 3962, Loss: 0.000523721711942926, Final Batch Loss: 6.227820995263755e-05\n",
      "Epoch 3963, Loss: 0.000650528039159326, Final Batch Loss: 3.442786010054988e-06\n",
      "Epoch 3964, Loss: 0.00013218739059084328, Final Batch Loss: 1.004248497338267e-05\n",
      "Epoch 3965, Loss: 7.05015931998787e-05, Final Batch Loss: 4.076545792486286e-06\n",
      "Epoch 3966, Loss: 9.391242247147602e-05, Final Batch Loss: 6.238239166123094e-06\n",
      "Epoch 3967, Loss: 0.007896426111983601, Final Batch Loss: 3.093478881055489e-05\n",
      "Epoch 3968, Loss: 5.647145189868752e-05, Final Batch Loss: 3.6382833059178665e-05\n",
      "Epoch 3969, Loss: 1.8211270344181685e-05, Final Batch Loss: 1.610905565030407e-05\n",
      "Epoch 3970, Loss: 0.0001029660998028703, Final Batch Loss: 6.104885687818751e-05\n",
      "Epoch 3971, Loss: 0.00018800908219418488, Final Batch Loss: 2.595656769699417e-05\n",
      "Epoch 3972, Loss: 0.0001692679234110983, Final Batch Loss: 0.00014662885223515332\n",
      "Epoch 3973, Loss: 0.00015558220547973178, Final Batch Loss: 0.00011394135799491778\n",
      "Epoch 3974, Loss: 0.00023717671138001606, Final Batch Loss: 0.00020255176059436053\n",
      "Epoch 3975, Loss: 0.008295333660498727, Final Batch Loss: 2.6266738132108003e-05\n",
      "Epoch 3976, Loss: 3.235538588342024e-05, Final Batch Loss: 5.330642125045415e-06\n",
      "Epoch 3977, Loss: 0.0004327865408413345, Final Batch Loss: 2.7503710953169502e-05\n",
      "Epoch 3978, Loss: 0.0001133944679168053, Final Batch Loss: 7.807843940099701e-05\n",
      "Epoch 3979, Loss: 0.00013086462786304764, Final Batch Loss: 3.7789246562169865e-05\n",
      "Epoch 3980, Loss: 0.012538005277747288, Final Batch Loss: 0.012521683238446712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3981, Loss: 4.169271596765611e-05, Final Batch Loss: 4.582192559610121e-06\n",
      "Epoch 3982, Loss: 0.0009639481277190498, Final Batch Loss: 9.116817636822816e-06\n",
      "Epoch 3983, Loss: 0.00010803283203131286, Final Batch Loss: 1.509769481344847e-05\n",
      "Epoch 3984, Loss: 4.3918986193602905e-05, Final Batch Loss: 1.826227889978327e-05\n",
      "Epoch 3985, Loss: 1.4857265796308639e-05, Final Batch Loss: 1.8176956473325845e-06\n",
      "Epoch 3986, Loss: 0.0022652782863588072, Final Batch Loss: 0.002224586671218276\n",
      "Epoch 3987, Loss: 0.00037346372846513987, Final Batch Loss: 0.00032523699337616563\n",
      "Epoch 3988, Loss: 0.00014563864533556625, Final Batch Loss: 0.00011083005665568635\n",
      "Epoch 3989, Loss: 0.0024978739056678023, Final Batch Loss: 0.0024541178718209267\n",
      "Epoch 3990, Loss: 2.273857944601332e-05, Final Batch Loss: 5.286676696414361e-06\n",
      "Epoch 3991, Loss: 0.0007507131667807698, Final Batch Loss: 6.319041131064296e-05\n",
      "Epoch 3992, Loss: 0.0006836228960764856, Final Batch Loss: 3.562711981430766e-06\n",
      "Epoch 3993, Loss: 3.441525768721476e-05, Final Batch Loss: 1.3538305211113766e-05\n",
      "Epoch 3994, Loss: 2.4119517547660507e-05, Final Batch Loss: 2.0098254026379436e-05\n",
      "Epoch 3995, Loss: 6.239010690478608e-05, Final Batch Loss: 4.0235208871308714e-05\n",
      "Epoch 3996, Loss: 0.000128388299344806, Final Batch Loss: 0.00011757855827454478\n",
      "Epoch 3997, Loss: 1.551464265503455e-05, Final Batch Loss: 4.350437848188449e-06\n",
      "Epoch 3998, Loss: 0.00040054560668068007, Final Batch Loss: 0.0003670153091661632\n",
      "Epoch 3999, Loss: 2.9043657377769705e-05, Final Batch Loss: 1.3262518223200459e-05\n",
      "Epoch 4000, Loss: 9.07749890757259e-05, Final Batch Loss: 4.6835997636662796e-05\n",
      "Epoch 4001, Loss: 0.00030550704104825854, Final Batch Loss: 0.00026110283215530217\n",
      "Epoch 4002, Loss: 0.0010376179125159979, Final Batch Loss: 0.000169447623193264\n",
      "Epoch 4003, Loss: 5.364339267543983e-05, Final Batch Loss: 1.1312577044009231e-05\n",
      "Epoch 4004, Loss: 0.00010017576278187335, Final Batch Loss: 4.808833182323724e-06\n",
      "Epoch 4005, Loss: 0.00019877946397173218, Final Batch Loss: 0.00014649594959337264\n",
      "Epoch 4006, Loss: 4.580567929224344e-05, Final Batch Loss: 1.4870846825942863e-05\n",
      "Epoch 4007, Loss: 2.4607159048173344e-05, Final Batch Loss: 3.850552730000345e-06\n",
      "Epoch 4008, Loss: 2.070444679702632e-05, Final Batch Loss: 1.013711607811274e-05\n",
      "Epoch 4009, Loss: 0.0008180957083823159, Final Batch Loss: 3.1503106583841145e-05\n",
      "Epoch 4010, Loss: 7.621980330441147e-05, Final Batch Loss: 4.609406823874451e-05\n",
      "Epoch 4011, Loss: 6.740086519130273e-05, Final Batch Loss: 5.242016050033271e-05\n",
      "Epoch 4012, Loss: 0.00020404981842148118, Final Batch Loss: 4.8345649702241644e-05\n",
      "Epoch 4013, Loss: 2.193225441260438e-05, Final Batch Loss: 3.257819798818673e-06\n",
      "Epoch 4014, Loss: 0.00010032106001744978, Final Batch Loss: 3.7994755984982476e-05\n",
      "Epoch 4015, Loss: 0.0001537293901492376, Final Batch Loss: 9.76806550170295e-05\n",
      "Epoch 4016, Loss: 6.057798964320682e-05, Final Batch Loss: 3.038875547645148e-05\n",
      "Epoch 4017, Loss: 0.0037095357256475836, Final Batch Loss: 4.838212043978274e-05\n",
      "Epoch 4018, Loss: 3.676378219097387e-05, Final Batch Loss: 1.1038746379199438e-05\n",
      "Epoch 4019, Loss: 5.479839819599874e-05, Final Batch Loss: 2.5059729523491114e-05\n",
      "Epoch 4020, Loss: 5.705760395358084e-05, Final Batch Loss: 7.761594133626204e-06\n",
      "Epoch 4021, Loss: 8.473276102449745e-05, Final Batch Loss: 5.3531872254097834e-05\n",
      "Epoch 4022, Loss: 5.1247670853626914e-05, Final Batch Loss: 3.6956382245989516e-05\n",
      "Epoch 4023, Loss: 0.00011175455938428058, Final Batch Loss: 6.327767096081516e-06\n",
      "Epoch 4024, Loss: 3.996425630248268e-05, Final Batch Loss: 5.058184342487948e-06\n",
      "Epoch 4025, Loss: 4.8727197281550616e-05, Final Batch Loss: 3.21667903335765e-05\n",
      "Epoch 4026, Loss: 4.615396755980328e-05, Final Batch Loss: 5.795514880446717e-06\n",
      "Epoch 4027, Loss: 6.926829883013852e-05, Final Batch Loss: 3.1859901355346665e-05\n",
      "Epoch 4028, Loss: 2.7289559511700645e-05, Final Batch Loss: 2.302225402672775e-05\n",
      "Epoch 4029, Loss: 4.820577578357188e-05, Final Batch Loss: 1.3912295798945706e-05\n",
      "Epoch 4030, Loss: 0.006104512805450213, Final Batch Loss: 4.07846118832822e-06\n",
      "Epoch 4031, Loss: 0.0005983337759971619, Final Batch Loss: 0.00022152301971800625\n",
      "Epoch 4032, Loss: 1.140616882366885e-05, Final Batch Loss: 3.204196445949492e-06\n",
      "Epoch 4033, Loss: 0.00017358501827402506, Final Batch Loss: 2.642630170157645e-05\n",
      "Epoch 4034, Loss: 1.2119704251745134e-05, Final Batch Loss: 8.885515853762627e-06\n",
      "Epoch 4035, Loss: 4.524144787865225e-05, Final Batch Loss: 2.16794760490302e-05\n",
      "Epoch 4036, Loss: 7.348268945861491e-05, Final Batch Loss: 4.675930085795699e-06\n",
      "Epoch 4037, Loss: 4.793963671545498e-05, Final Batch Loss: 2.1299039872246794e-05\n",
      "Epoch 4038, Loss: 4.905842070002109e-05, Final Batch Loss: 2.9109010938555002e-05\n",
      "Epoch 4039, Loss: 4.106169171791407e-05, Final Batch Loss: 3.675390325952321e-05\n",
      "Epoch 4040, Loss: 1.1523102102728444e-05, Final Batch Loss: 3.050900659218314e-06\n",
      "Epoch 4041, Loss: 1.5112390428839717e-05, Final Batch Loss: 1.0504441888770089e-05\n",
      "Epoch 4042, Loss: 2.6930442345474148e-05, Final Batch Loss: 2.0264355043764226e-05\n",
      "Epoch 4043, Loss: 1.3338013559405226e-05, Final Batch Loss: 8.599206012149807e-06\n",
      "Epoch 4044, Loss: 1.9484075437503634e-05, Final Batch Loss: 1.7816628314903937e-05\n",
      "Epoch 4045, Loss: 0.0015169476928349468, Final Batch Loss: 1.271283963433234e-05\n",
      "Epoch 4046, Loss: 5.2784656872972846e-05, Final Batch Loss: 1.939404319273308e-05\n",
      "Epoch 4047, Loss: 0.0034610979491844773, Final Batch Loss: 0.002135602990165353\n",
      "Epoch 4048, Loss: 7.495200043194927e-05, Final Batch Loss: 3.67183456546627e-05\n",
      "Epoch 4049, Loss: 1.404245904268464e-05, Final Batch Loss: 6.239712092792615e-06\n",
      "Epoch 4050, Loss: 1.960113240784267e-05, Final Batch Loss: 3.826294232567307e-06\n",
      "Epoch 4051, Loss: 9.943085206032265e-05, Final Batch Loss: 7.17661896487698e-05\n",
      "Epoch 4052, Loss: 7.127305821086338e-05, Final Batch Loss: 7.018066389719024e-05\n",
      "Epoch 4053, Loss: 0.0002398026845185086, Final Batch Loss: 3.700359957292676e-05\n",
      "Epoch 4054, Loss: 9.031981392126909e-06, Final Batch Loss: 7.337590091083257e-07\n",
      "Epoch 4055, Loss: 5.970206348138163e-05, Final Batch Loss: 3.705591552716214e-06\n",
      "Epoch 4056, Loss: 7.173088420131535e-06, Final Batch Loss: 1.6666186866132193e-06\n",
      "Epoch 4057, Loss: 4.55249510196154e-05, Final Batch Loss: 3.896858834195882e-05\n",
      "Epoch 4058, Loss: 6.345615474856459e-06, Final Batch Loss: 2.340299943170976e-06\n",
      "Epoch 4059, Loss: 1.8615441149449907e-05, Final Batch Loss: 9.578822755429428e-06\n",
      "Epoch 4060, Loss: 0.00020089836471015587, Final Batch Loss: 7.049676059978083e-05\n",
      "Epoch 4061, Loss: 0.004334803321398795, Final Batch Loss: 0.0033435621298849583\n",
      "Epoch 4062, Loss: 3.434666450630175e-05, Final Batch Loss: 2.0756933736265637e-05\n",
      "Epoch 4063, Loss: 6.103379109845264e-05, Final Batch Loss: 5.4745632951380685e-05\n",
      "Epoch 4064, Loss: 0.00013337416021386161, Final Batch Loss: 0.00010231421038042754\n",
      "Epoch 4065, Loss: 1.031771944326465e-05, Final Batch Loss: 4.274764251022134e-06\n",
      "Epoch 4066, Loss: 0.00011822512186654421, Final Batch Loss: 0.00011762241047108546\n",
      "Epoch 4067, Loss: 1.5751440969324904e-05, Final Batch Loss: 6.483283414127072e-06\n",
      "Epoch 4068, Loss: 1.7757083242031513e-05, Final Batch Loss: 1.0998056495736819e-05\n",
      "Epoch 4069, Loss: 6.711084279231727e-05, Final Batch Loss: 2.8379796276567504e-05\n",
      "Epoch 4070, Loss: 0.000923728701309301, Final Batch Loss: 0.0009150328114628792\n",
      "Epoch 4071, Loss: 0.001668273880113702, Final Batch Loss: 0.0016655635554343462\n",
      "Epoch 4072, Loss: 9.786514556253678e-05, Final Batch Loss: 6.52226435704506e-06\n",
      "Epoch 4073, Loss: 2.5851000827969983e-05, Final Batch Loss: 1.0336079867556691e-06\n",
      "Epoch 4074, Loss: 1.6144077562785242e-05, Final Batch Loss: 2.6920606615021825e-06\n",
      "Epoch 4075, Loss: 5.0394649861118523e-05, Final Batch Loss: 4.3792944779852405e-05\n",
      "Epoch 4076, Loss: 1.3116416084812954e-05, Final Batch Loss: 4.10888696933398e-06\n",
      "Epoch 4077, Loss: 2.6283499209966976e-05, Final Batch Loss: 2.4375298380618915e-05\n",
      "Epoch 4078, Loss: 9.422654528634666e-06, Final Batch Loss: 4.294472262245108e-07\n",
      "Epoch 4079, Loss: 1.0185895689573954e-05, Final Batch Loss: 3.4445786241121823e-06\n",
      "Epoch 4080, Loss: 0.001165671110356925, Final Batch Loss: 0.0011575911194086075\n",
      "Epoch 4081, Loss: 0.00017376400683133397, Final Batch Loss: 0.0001549954613437876\n",
      "Epoch 4082, Loss: 0.003488287969958037, Final Batch Loss: 0.002943179337307811\n",
      "Epoch 4083, Loss: 1.8418557147015235e-05, Final Batch Loss: 1.464877732360037e-05\n",
      "Epoch 4084, Loss: 4.408008680911735e-05, Final Batch Loss: 1.8036540495813824e-05\n",
      "Epoch 4085, Loss: 0.00013830733405484352, Final Batch Loss: 2.7238254915573634e-05\n",
      "Epoch 4086, Loss: 0.0002797409642880666, Final Batch Loss: 9.639053132559638e-06\n",
      "Epoch 4087, Loss: 0.00031653941914555617, Final Batch Loss: 0.00030675099696964025\n",
      "Epoch 4088, Loss: 1.0041824225481832e-05, Final Batch Loss: 2.5632284632592928e-06\n",
      "Epoch 4089, Loss: 0.00014415455189009663, Final Batch Loss: 2.089076406264212e-05\n",
      "Epoch 4090, Loss: 0.00014168085158416943, Final Batch Loss: 0.00013804661284666508\n",
      "Epoch 4091, Loss: 0.00038386176311178133, Final Batch Loss: 0.00010276323155267164\n",
      "Epoch 4092, Loss: 0.0041415909843181, Final Batch Loss: 2.652833018146339e-06\n",
      "Epoch 4093, Loss: 0.0009008880019791832, Final Batch Loss: 0.0008942790445871651\n",
      "Epoch 4094, Loss: 1.3131807463651057e-05, Final Batch Loss: 9.000454156193882e-06\n",
      "Epoch 4095, Loss: 7.429798824887257e-05, Final Batch Loss: 4.651708877645433e-05\n",
      "Epoch 4096, Loss: 5.399378596848692e-05, Final Batch Loss: 6.926183687028242e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4097, Loss: 0.0015952036542330461, Final Batch Loss: 4.319363597460324e-06\n",
      "Epoch 4098, Loss: 0.00018043956561086816, Final Batch Loss: 0.00017676505376584828\n",
      "Epoch 4099, Loss: 0.0002474291468388401, Final Batch Loss: 0.0001346901844954118\n",
      "Epoch 4100, Loss: 1.919099668157287e-05, Final Batch Loss: 9.376813977723941e-06\n",
      "Epoch 4101, Loss: 7.972930688993074e-06, Final Batch Loss: 1.0817370821314398e-06\n",
      "Epoch 4102, Loss: 1.8947432181448676e-05, Final Batch Loss: 1.0059304258902557e-05\n",
      "Epoch 4103, Loss: 1.4879444279358722e-05, Final Batch Loss: 4.841334884986281e-06\n",
      "Epoch 4104, Loss: 1.05335857369937e-05, Final Batch Loss: 5.2851196414849255e-06\n",
      "Epoch 4105, Loss: 6.169152038637549e-05, Final Batch Loss: 1.8599814211484045e-05\n",
      "Epoch 4106, Loss: 1.8430926502333023e-05, Final Batch Loss: 1.2801718185073696e-05\n",
      "Epoch 4107, Loss: 0.0013517905701974087, Final Batch Loss: 3.524890644257539e-06\n",
      "Epoch 4108, Loss: 0.0009465140356041957, Final Batch Loss: 1.739904473652132e-05\n",
      "Epoch 4109, Loss: 5.752981269324664e-05, Final Batch Loss: 2.788882193272002e-05\n",
      "Epoch 4110, Loss: 0.0017443154861211951, Final Batch Loss: 4.916560556011973e-06\n",
      "Epoch 4111, Loss: 1.4862015632388648e-05, Final Batch Loss: 8.624904694443103e-06\n",
      "Epoch 4112, Loss: 1.930857388288132e-05, Final Batch Loss: 1.5287852875189856e-05\n",
      "Epoch 4113, Loss: 4.767332120536594e-05, Final Batch Loss: 3.4727316233329475e-05\n",
      "Epoch 4114, Loss: 7.129387449822389e-05, Final Batch Loss: 1.9273174984846264e-05\n",
      "Epoch 4115, Loss: 6.375522445978277e-06, Final Batch Loss: 9.329292538495793e-07\n",
      "Epoch 4116, Loss: 0.00032833654950081836, Final Batch Loss: 4.206141966278665e-06\n",
      "Epoch 4117, Loss: 2.870608113880735e-05, Final Batch Loss: 7.978625944815576e-06\n",
      "Epoch 4118, Loss: 0.00013241728993307333, Final Batch Loss: 1.5065414117998444e-05\n",
      "Epoch 4119, Loss: 0.00011567334877327085, Final Batch Loss: 9.32458569877781e-05\n",
      "Epoch 4120, Loss: 0.0004958275756052899, Final Batch Loss: 2.377950977461296e-06\n",
      "Epoch 4121, Loss: 7.21673245607235e-06, Final Batch Loss: 2.6787499791680602e-06\n",
      "Epoch 4122, Loss: 1.8604553588374984e-05, Final Batch Loss: 2.720135853451211e-06\n",
      "Epoch 4123, Loss: 6.720756755385082e-05, Final Batch Loss: 4.566805000649765e-05\n",
      "Epoch 4124, Loss: 3.059315076825442e-05, Final Batch Loss: 4.112865099159535e-06\n",
      "Epoch 4125, Loss: 1.1091092346759979e-05, Final Batch Loss: 5.800176950288005e-06\n",
      "Epoch 4126, Loss: 0.0010579882364254445, Final Batch Loss: 0.00012988757225684822\n",
      "Epoch 4127, Loss: 6.144576400402002e-05, Final Batch Loss: 1.5955487469909713e-05\n",
      "Epoch 4128, Loss: 0.00011679740964609664, Final Batch Loss: 2.074708572763484e-05\n",
      "Epoch 4129, Loss: 7.405524956993759e-05, Final Batch Loss: 3.555855801096186e-05\n",
      "Epoch 4130, Loss: 2.1126584215380717e-06, Final Batch Loss: 9.558838200973696e-07\n",
      "Epoch 4131, Loss: 3.970662055508001e-05, Final Batch Loss: 2.648745612532366e-05\n",
      "Epoch 4132, Loss: 0.00019535556202754378, Final Batch Loss: 0.00015553913544863462\n",
      "Epoch 4133, Loss: 1.3791821174891084e-05, Final Batch Loss: 2.993336011059e-06\n",
      "Epoch 4134, Loss: 1.2929427384733572e-05, Final Batch Loss: 1.0363372894062195e-05\n",
      "Epoch 4135, Loss: 1.3449043876789801e-05, Final Batch Loss: 1.5888673488007043e-06\n",
      "Epoch 4136, Loss: 5.4838202231621835e-05, Final Batch Loss: 1.4256843314797152e-05\n",
      "Epoch 4137, Loss: 3.9237915189005435e-05, Final Batch Loss: 1.8694025129661895e-05\n",
      "Epoch 4138, Loss: 0.0018083522945744335, Final Batch Loss: 0.0017946826992556453\n",
      "Epoch 4139, Loss: 7.392035513476003e-05, Final Batch Loss: 5.85565430810675e-05\n",
      "Epoch 4140, Loss: 0.0004581658431561664, Final Batch Loss: 4.47856291430071e-05\n",
      "Epoch 4141, Loss: 1.8380135315965163e-05, Final Batch Loss: 1.2134534699725918e-05\n",
      "Epoch 4142, Loss: 7.924293095129542e-05, Final Batch Loss: 4.216542583890259e-05\n",
      "Epoch 4143, Loss: 0.0001927225512190489, Final Batch Loss: 7.784530680510215e-06\n",
      "Epoch 4144, Loss: 0.00039783440047358454, Final Batch Loss: 0.0003956177388317883\n",
      "Epoch 4145, Loss: 1.5024407730379608e-05, Final Batch Loss: 6.406476131814998e-06\n",
      "Epoch 4146, Loss: 0.00036974351795038274, Final Batch Loss: 3.25047295746117e-07\n",
      "Epoch 4147, Loss: 0.00015587376401526853, Final Batch Loss: 3.577025927370414e-05\n",
      "Epoch 4148, Loss: 5.5369906476698816e-05, Final Batch Loss: 4.563377660815604e-05\n",
      "Epoch 4149, Loss: 0.0002458192248013802, Final Batch Loss: 4.646696470445022e-05\n",
      "Epoch 4150, Loss: 6.729150356932223e-06, Final Batch Loss: 4.338872372500191e-07\n",
      "Epoch 4151, Loss: 0.00015257129325618735, Final Batch Loss: 0.00013904168736189604\n",
      "Epoch 4152, Loss: 3.050834243367717e-05, Final Batch Loss: 2.7781044991570525e-05\n",
      "Epoch 4153, Loss: 5.394208892539609e-05, Final Batch Loss: 1.7484517229604535e-05\n",
      "Epoch 4154, Loss: 8.751881750868051e-06, Final Batch Loss: 3.5033792755712057e-06\n",
      "Epoch 4155, Loss: 0.02075545612751739, Final Batch Loss: 6.219122587935999e-05\n",
      "Epoch 4156, Loss: 7.681348506594077e-06, Final Batch Loss: 1.962088845175458e-06\n",
      "Epoch 4157, Loss: 1.354284722765442e-05, Final Batch Loss: 4.8744304876890965e-06\n",
      "Epoch 4158, Loss: 0.00014959134557557263, Final Batch Loss: 1.0106740546689252e-06\n",
      "Epoch 4159, Loss: 5.014386920265679e-05, Final Batch Loss: 3.4301222058275016e-06\n",
      "Epoch 4160, Loss: 3.875074116876931e-05, Final Batch Loss: 4.500283921515802e-06\n",
      "Epoch 4161, Loss: 5.724753373215208e-05, Final Batch Loss: 1.5023201740405057e-05\n",
      "Epoch 4162, Loss: 1.9197034589524264e-05, Final Batch Loss: 2.0471732113946928e-06\n",
      "Epoch 4163, Loss: 0.0012920814333483577, Final Batch Loss: 0.0006301211542449892\n",
      "Epoch 4164, Loss: 3.0676654205308296e-05, Final Batch Loss: 1.2597229215316474e-05\n",
      "Epoch 4165, Loss: 5.985402367514325e-06, Final Batch Loss: 2.0575503185682464e-06\n",
      "Epoch 4166, Loss: 3.0112294325590483e-05, Final Batch Loss: 2.380391151746153e-06\n",
      "Epoch 4167, Loss: 1.8924414689536206e-05, Final Batch Loss: 7.361622010648716e-06\n",
      "Epoch 4168, Loss: 6.065572233637795e-05, Final Batch Loss: 1.4798384654568508e-05\n",
      "Epoch 4169, Loss: 1.5205714817057014e-05, Final Batch Loss: 1.3222641428001225e-05\n",
      "Epoch 4170, Loss: 6.637172191403806e-05, Final Batch Loss: 3.273542824899778e-05\n",
      "Epoch 4171, Loss: 9.067609789781272e-05, Final Batch Loss: 6.839246634626761e-05\n",
      "Epoch 4172, Loss: 0.002011124891168947, Final Batch Loss: 2.4062198917818023e-06\n",
      "Epoch 4173, Loss: 0.0012494215561673627, Final Batch Loss: 0.0012427683686837554\n",
      "Epoch 4174, Loss: 1.0696156778067234e-05, Final Batch Loss: 8.538093425158877e-06\n",
      "Epoch 4175, Loss: 1.0600231235002866e-05, Final Batch Loss: 2.143490291928174e-06\n",
      "Epoch 4176, Loss: 1.5451242916242336e-05, Final Batch Loss: 1.2977526239410508e-05\n",
      "Epoch 4177, Loss: 1.7346619188174373e-05, Final Batch Loss: 1.4709317838423885e-05\n",
      "Epoch 4178, Loss: 5.185199199786439e-06, Final Batch Loss: 6.256589699660253e-07\n",
      "Epoch 4179, Loss: 0.00010570989979896694, Final Batch Loss: 1.931723818415776e-05\n",
      "Epoch 4180, Loss: 0.010088502553116996, Final Batch Loss: 0.01005643978714943\n",
      "Epoch 4181, Loss: 0.0001127201430790592, Final Batch Loss: 8.657532453071326e-05\n",
      "Epoch 4182, Loss: 2.4024031972658122e-05, Final Batch Loss: 5.768867140432121e-06\n",
      "Epoch 4183, Loss: 9.46722266235156e-05, Final Batch Loss: 2.23981751332758e-05\n",
      "Epoch 4184, Loss: 4.2759452071550186e-05, Final Batch Loss: 3.026604417755152e-06\n",
      "Epoch 4185, Loss: 0.0006019401262165047, Final Batch Loss: 4.804613126907498e-06\n",
      "Epoch 4186, Loss: 0.0008074116885836702, Final Batch Loss: 1.3019027392147109e-05\n",
      "Epoch 4187, Loss: 0.001902897929539904, Final Batch Loss: 1.8561113392934203e-05\n",
      "Epoch 4188, Loss: 0.0004907419884148112, Final Batch Loss: 6.700526228087256e-06\n",
      "Epoch 4189, Loss: 4.6324181312229484e-05, Final Batch Loss: 1.225420055561699e-05\n",
      "Epoch 4190, Loss: 3.4618777135619894e-05, Final Batch Loss: 9.220555512001738e-06\n",
      "Epoch 4191, Loss: 9.129560658038827e-05, Final Batch Loss: 1.206834440381499e-05\n",
      "Epoch 4192, Loss: 1.3794797496302635e-05, Final Batch Loss: 1.0796043170557823e-05\n",
      "Epoch 4193, Loss: 5.9716796613429324e-05, Final Batch Loss: 2.4766634396655718e-06\n",
      "Epoch 4194, Loss: 6.651920671174594e-06, Final Batch Loss: 1.4452804180109524e-06\n",
      "Epoch 4195, Loss: 3.145425125694601e-05, Final Batch Loss: 1.9096711184829473e-05\n",
      "Epoch 4196, Loss: 0.0017642004822846502, Final Batch Loss: 0.00046528803068213165\n",
      "Epoch 4197, Loss: 0.0001204739382956177, Final Batch Loss: 0.00010492723231436685\n",
      "Epoch 4198, Loss: 5.433920887298882e-05, Final Batch Loss: 2.3315769794862717e-05\n",
      "Epoch 4199, Loss: 4.6542751078959554e-05, Final Batch Loss: 2.944555672002025e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4200, Loss: 3.359954098414164e-05, Final Batch Loss: 2.8978265618206933e-06\n",
      "Epoch 4201, Loss: 4.362588197182049e-05, Final Batch Loss: 5.813712505187141e-06\n",
      "Epoch 4202, Loss: 9.938904531736625e-05, Final Batch Loss: 9.419366688234732e-05\n",
      "Epoch 4203, Loss: 4.124405404581921e-05, Final Batch Loss: 3.6715218811878003e-06\n",
      "Epoch 4204, Loss: 0.0005457635925267823, Final Batch Loss: 0.0005061657284386456\n",
      "Epoch 4205, Loss: 7.420293695759028e-05, Final Batch Loss: 3.155384911224246e-05\n",
      "Epoch 4206, Loss: 0.0001808799570426345, Final Batch Loss: 2.476335794199258e-05\n",
      "Epoch 4207, Loss: 0.0011649390989987296, Final Batch Loss: 0.0011621268931776285\n",
      "Epoch 4208, Loss: 1.2118071936129127e-05, Final Batch Loss: 6.091790510254214e-06\n",
      "Epoch 4209, Loss: 9.427024224351044e-06, Final Batch Loss: 6.87102601659717e-06\n",
      "Epoch 4210, Loss: 0.00011333161273796577, Final Batch Loss: 9.822639185586013e-06\n",
      "Epoch 4211, Loss: 9.186587249132572e-06, Final Batch Loss: 2.002795099542709e-06\n",
      "Epoch 4212, Loss: 4.8096559225996316e-05, Final Batch Loss: 1.2912806823806022e-06\n",
      "Epoch 4213, Loss: 5.437185700429836e-05, Final Batch Loss: 4.7901354264467955e-05\n",
      "Epoch 4214, Loss: 0.00011592699365792214, Final Batch Loss: 0.00010873937571886927\n",
      "Epoch 4215, Loss: 7.206797090475447e-05, Final Batch Loss: 4.041435386170633e-05\n",
      "Epoch 4216, Loss: 2.67456125584431e-05, Final Batch Loss: 1.5792516933288425e-05\n",
      "Epoch 4217, Loss: 1.67035232152557e-05, Final Batch Loss: 8.16380179458065e-06\n",
      "Epoch 4218, Loss: 0.0007966259458953573, Final Batch Loss: 1.1602264748944435e-06\n",
      "Epoch 4219, Loss: 3.0063326448726002e-05, Final Batch Loss: 9.46209820540389e-06\n",
      "Epoch 4220, Loss: 5.3537115036306204e-05, Final Batch Loss: 5.974605755909579e-06\n",
      "Epoch 4221, Loss: 0.0009086708187169279, Final Batch Loss: 3.463984285190236e-06\n",
      "Epoch 4222, Loss: 0.040167187404222204, Final Batch Loss: 0.04013892635703087\n",
      "Epoch 4223, Loss: 2.1809696590935346e-05, Final Batch Loss: 1.2541464457171969e-05\n",
      "Epoch 4224, Loss: 0.0001210820864798734, Final Batch Loss: 9.092866093851626e-05\n",
      "Epoch 4225, Loss: 3.8039928767830133e-05, Final Batch Loss: 1.4646684576291591e-05\n",
      "Epoch 4226, Loss: 8.553200495953206e-05, Final Batch Loss: 1.2403828804963268e-05\n",
      "Epoch 4227, Loss: 0.0001947219716385007, Final Batch Loss: 0.00011021948012057692\n",
      "Epoch 4228, Loss: 0.004403858740261057, Final Batch Loss: 0.004368721507489681\n",
      "Epoch 4229, Loss: 4.3406605982454494e-05, Final Batch Loss: 1.5877774785622023e-05\n",
      "Epoch 4230, Loss: 0.00014370398821483832, Final Batch Loss: 0.00011751037527574226\n",
      "Epoch 4231, Loss: 0.0020534738578135148, Final Batch Loss: 0.0020070504397153854\n",
      "Epoch 4232, Loss: 0.000871469615958631, Final Batch Loss: 0.00011437729699537158\n",
      "Epoch 4233, Loss: 0.00038430454151239246, Final Batch Loss: 0.00012042750313412398\n",
      "Epoch 4234, Loss: 0.0017279545863857493, Final Batch Loss: 8.820682705845684e-05\n",
      "Epoch 4235, Loss: 6.427869993785862e-05, Final Batch Loss: 3.8549154851352796e-05\n",
      "Epoch 4236, Loss: 0.01750833820551634, Final Batch Loss: 0.010304966010153294\n",
      "Epoch 4237, Loss: 0.00010009037396230269, Final Batch Loss: 1.527050517324824e-05\n",
      "Epoch 4238, Loss: 0.0009796265840122942, Final Batch Loss: 0.0009232539450749755\n",
      "Epoch 4239, Loss: 0.00010413761992822401, Final Batch Loss: 1.3593187759397551e-05\n",
      "Epoch 4240, Loss: 0.0011441403730714228, Final Batch Loss: 3.477523205219768e-05\n",
      "Epoch 4241, Loss: 0.00014079341781325638, Final Batch Loss: 8.421155507676303e-05\n",
      "Epoch 4242, Loss: 5.995509491185658e-05, Final Batch Loss: 4.0359460399486125e-05\n",
      "Epoch 4243, Loss: 0.0008286271222459618, Final Batch Loss: 3.466729322099127e-05\n",
      "Epoch 4244, Loss: 5.173364024813054e-05, Final Batch Loss: 7.451227247656789e-06\n",
      "Epoch 4245, Loss: 0.00012140601756982505, Final Batch Loss: 4.300541331758723e-05\n",
      "Epoch 4246, Loss: 0.00017395102622685954, Final Batch Loss: 8.464648271910846e-05\n",
      "Epoch 4247, Loss: 0.00020757559104822576, Final Batch Loss: 0.00012962231994606555\n",
      "Epoch 4248, Loss: 0.00017813152953749523, Final Batch Loss: 3.266285784775391e-05\n",
      "Epoch 4249, Loss: 2.9133216230547987e-05, Final Batch Loss: 1.028336919262074e-05\n",
      "Epoch 4250, Loss: 0.00018478606216376647, Final Batch Loss: 0.00015338079538196325\n",
      "Epoch 4251, Loss: 0.00018592498236102983, Final Batch Loss: 2.624849003041163e-05\n",
      "Epoch 4252, Loss: 0.0010401253821328282, Final Batch Loss: 0.0008192505920305848\n",
      "Epoch 4253, Loss: 0.00011680920215439983, Final Batch Loss: 9.226972906617448e-05\n",
      "Epoch 4254, Loss: 0.0001193053467432037, Final Batch Loss: 5.529498594114557e-05\n",
      "Epoch 4255, Loss: 0.00021710361397708766, Final Batch Loss: 0.0001695561222732067\n",
      "Epoch 4256, Loss: 0.00023465032063541003, Final Batch Loss: 2.6718935259850696e-05\n",
      "Epoch 4257, Loss: 0.00014006953279022127, Final Batch Loss: 5.478166713146493e-05\n",
      "Epoch 4258, Loss: 5.404449439083692e-05, Final Batch Loss: 2.522074464650359e-05\n",
      "Epoch 4259, Loss: 5.167646850168239e-05, Final Batch Loss: 2.029040661000181e-05\n",
      "Epoch 4260, Loss: 0.00029877173074055463, Final Batch Loss: 0.0001878779148682952\n",
      "Epoch 4261, Loss: 0.00011968830222031102, Final Batch Loss: 1.5964367776177824e-05\n",
      "Epoch 4262, Loss: 1.280995365959825e-05, Final Batch Loss: 6.299029337242246e-06\n",
      "Epoch 4263, Loss: 0.0010447487147757784, Final Batch Loss: 3.129489778075367e-05\n",
      "Epoch 4264, Loss: 0.0001605418565304717, Final Batch Loss: 3.0254062949097715e-05\n",
      "Epoch 4265, Loss: 1.818126384023344e-05, Final Batch Loss: 4.961126251146197e-06\n",
      "Epoch 4266, Loss: 0.00012787599916919135, Final Batch Loss: 2.601190863060765e-05\n",
      "Epoch 4267, Loss: 0.00023286888972506858, Final Batch Loss: 0.00018945378542412072\n",
      "Epoch 4268, Loss: 0.0002121467186952941, Final Batch Loss: 6.689631118206307e-05\n",
      "Epoch 4269, Loss: 0.0001657899520068895, Final Batch Loss: 0.00010643200948834419\n",
      "Epoch 4270, Loss: 2.980590124934679e-05, Final Batch Loss: 8.33298599900445e-06\n",
      "Epoch 4271, Loss: 4.925481334794313e-05, Final Batch Loss: 2.0891437088721432e-05\n",
      "Epoch 4272, Loss: 5.769318522652611e-05, Final Batch Loss: 4.907195398118347e-05\n",
      "Epoch 4273, Loss: 6.433571979869157e-05, Final Batch Loss: 1.8382921552984044e-05\n",
      "Epoch 4274, Loss: 5.892834087717347e-05, Final Batch Loss: 3.4477659937692806e-05\n",
      "Epoch 4275, Loss: 3.6318632737675216e-05, Final Batch Loss: 1.0507398656045552e-05\n",
      "Epoch 4276, Loss: 2.1388177628978156e-05, Final Batch Loss: 9.529805538477376e-06\n",
      "Epoch 4277, Loss: 0.0018465145878963085, Final Batch Loss: 3.4908919133158633e-06\n",
      "Epoch 4278, Loss: 0.00022272212481766474, Final Batch Loss: 0.000211472186492756\n",
      "Epoch 4279, Loss: 0.0002827157804858871, Final Batch Loss: 0.00024452246725559235\n",
      "Epoch 4280, Loss: 4.428361353348009e-05, Final Batch Loss: 2.7359601517673582e-05\n",
      "Epoch 4281, Loss: 9.493803190707695e-05, Final Batch Loss: 1.838704883994069e-05\n",
      "Epoch 4282, Loss: 8.729243654670427e-05, Final Batch Loss: 8.086834895948414e-06\n",
      "Epoch 4283, Loss: 4.290912147553172e-05, Final Batch Loss: 2.202890937041957e-05\n",
      "Epoch 4284, Loss: 8.638978761155158e-05, Final Batch Loss: 5.3696228860644624e-05\n",
      "Epoch 4285, Loss: 0.00014079652282816824, Final Batch Loss: 0.00011524064029799774\n",
      "Epoch 4286, Loss: 2.5288393771916162e-05, Final Batch Loss: 7.719735549471807e-06\n",
      "Epoch 4287, Loss: 0.00011488179234220297, Final Batch Loss: 4.687152340920875e-06\n",
      "Epoch 4288, Loss: 5.613080020339112e-05, Final Batch Loss: 4.417931904754369e-06\n",
      "Epoch 4289, Loss: 6.792129170207772e-05, Final Batch Loss: 2.5764655219973065e-05\n",
      "Epoch 4290, Loss: 3.8038683669583406e-05, Final Batch Loss: 1.3388223123911303e-05\n",
      "Epoch 4291, Loss: 0.00010143661938855075, Final Batch Loss: 9.438526467420161e-05\n",
      "Epoch 4292, Loss: 0.00013508367260328669, Final Batch Loss: 2.3774525743647246e-06\n",
      "Epoch 4293, Loss: 4.181173972028773e-05, Final Batch Loss: 1.3030614354647696e-05\n",
      "Epoch 4294, Loss: 4.660224021790782e-05, Final Batch Loss: 1.5057089512993116e-05\n",
      "Epoch 4295, Loss: 1.8957903876071214e-05, Final Batch Loss: 1.524070103187114e-05\n",
      "Epoch 4296, Loss: 0.0009020522848004475, Final Batch Loss: 0.0008833209285512567\n",
      "Epoch 4297, Loss: 2.8998079869779758e-05, Final Batch Loss: 2.108254011545796e-05\n",
      "Epoch 4298, Loss: 3.5761340768658556e-05, Final Batch Loss: 1.0403164196759462e-05\n",
      "Epoch 4299, Loss: 4.743466342915781e-05, Final Batch Loss: 1.5243818779708818e-05\n",
      "Epoch 4300, Loss: 9.58408163569402e-05, Final Batch Loss: 8.380565122934058e-05\n",
      "Epoch 4301, Loss: 0.00020068863909727952, Final Batch Loss: 0.00019765993056353182\n",
      "Epoch 4302, Loss: 4.580260610964615e-05, Final Batch Loss: 2.1771820684080012e-05\n",
      "Epoch 4303, Loss: 1.6003193195501808e-05, Final Batch Loss: 3.5011062209377997e-06\n",
      "Epoch 4304, Loss: 2.0277090698073152e-05, Final Batch Loss: 1.4401420230569784e-05\n",
      "Epoch 4305, Loss: 4.287778756406624e-05, Final Batch Loss: 1.5831457858439535e-05\n",
      "Epoch 4306, Loss: 3.025361911568325e-05, Final Batch Loss: 1.0715577445807867e-05\n",
      "Epoch 4307, Loss: 2.0252991816960275e-05, Final Batch Loss: 1.1880213605763856e-05\n",
      "Epoch 4308, Loss: 0.0013836001853633206, Final Batch Loss: 1.9604816770879552e-05\n",
      "Epoch 4309, Loss: 0.0009866823675110936, Final Batch Loss: 0.0008433283655904233\n",
      "Epoch 4310, Loss: 0.00012236787370056845, Final Batch Loss: 3.7612418964272365e-05\n",
      "Epoch 4311, Loss: 3.081304021179676e-05, Final Batch Loss: 1.2801143384422176e-05\n",
      "Epoch 4312, Loss: 0.000548540658201091, Final Batch Loss: 0.0004907514085061848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4313, Loss: 3.876338632835541e-05, Final Batch Loss: 5.482916094479151e-06\n",
      "Epoch 4314, Loss: 0.0005473747594351153, Final Batch Loss: 2.2559404442290543e-06\n",
      "Epoch 4315, Loss: 0.00011682624608511105, Final Batch Loss: 7.320401346078143e-05\n",
      "Epoch 4316, Loss: 2.9637321858899668e-05, Final Batch Loss: 1.7423513781977817e-05\n",
      "Epoch 4317, Loss: 3.2190630918194074e-05, Final Batch Loss: 6.900699190737214e-06\n",
      "Epoch 4318, Loss: 0.0025746390480207992, Final Batch Loss: 1.1868565934491926e-06\n",
      "Epoch 4319, Loss: 5.4350322898244485e-05, Final Batch Loss: 1.921995499287732e-05\n",
      "Epoch 4320, Loss: 0.00018764078049571253, Final Batch Loss: 4.335501944296993e-05\n",
      "Epoch 4321, Loss: 3.9680431655142456e-05, Final Batch Loss: 2.9061258828733116e-05\n",
      "Epoch 4322, Loss: 0.0035137972117809113, Final Batch Loss: 0.0034777787514030933\n",
      "Epoch 4323, Loss: 1.6025819604692515e-05, Final Batch Loss: 8.171927220246289e-06\n",
      "Epoch 4324, Loss: 0.0001789589223335497, Final Batch Loss: 7.031777931842953e-05\n",
      "Epoch 4325, Loss: 3.098213301200303e-05, Final Batch Loss: 4.506203822529642e-06\n",
      "Epoch 4326, Loss: 2.7440809390100185e-05, Final Batch Loss: 2.139811113011092e-05\n",
      "Epoch 4327, Loss: 0.0017942837907867215, Final Batch Loss: 6.341655080177588e-06\n",
      "Epoch 4328, Loss: 5.227095971349627e-05, Final Batch Loss: 8.665560017107055e-06\n",
      "Epoch 4329, Loss: 1.6074375707830768e-05, Final Batch Loss: 8.015264938876498e-06\n",
      "Epoch 4330, Loss: 0.00017012906573654618, Final Batch Loss: 0.00016187058645300567\n",
      "Epoch 4331, Loss: 0.0011678957962431014, Final Batch Loss: 0.00028679531533271074\n",
      "Epoch 4332, Loss: 7.329134950850857e-05, Final Batch Loss: 6.730079621775076e-05\n",
      "Epoch 4333, Loss: 0.02128062505653361, Final Batch Loss: 8.374002209166065e-05\n",
      "Epoch 4334, Loss: 2.58561904047383e-05, Final Batch Loss: 1.3159379705030005e-05\n",
      "Epoch 4335, Loss: 0.00010735526666394435, Final Batch Loss: 7.4940369813703e-05\n",
      "Epoch 4336, Loss: 4.198491240003932e-05, Final Batch Loss: 1.254250832971593e-06\n",
      "Epoch 4337, Loss: 0.0006086992743803421, Final Batch Loss: 1.1982740034000017e-05\n",
      "Epoch 4338, Loss: 2.9339438697206788e-05, Final Batch Loss: 1.7320428014500067e-05\n",
      "Epoch 4339, Loss: 8.362674816453364e-05, Final Batch Loss: 5.726968083763495e-05\n",
      "Epoch 4340, Loss: 0.0013921655072408612, Final Batch Loss: 0.0013826288050040603\n",
      "Epoch 4341, Loss: 2.3711074391030706e-05, Final Batch Loss: 1.0802728866110556e-05\n",
      "Epoch 4342, Loss: 2.9484845981642138e-05, Final Batch Loss: 1.1687729966070037e-05\n",
      "Epoch 4343, Loss: 4.657159479393158e-05, Final Batch Loss: 2.380344449193217e-05\n",
      "Epoch 4344, Loss: 0.00031271728312276537, Final Batch Loss: 8.498115676047746e-06\n",
      "Epoch 4345, Loss: 0.00012606934797076974, Final Batch Loss: 2.081374441331718e-05\n",
      "Epoch 4346, Loss: 4.054916098539252e-05, Final Batch Loss: 1.8965833078254946e-05\n",
      "Epoch 4347, Loss: 0.001705571829006658, Final Batch Loss: 0.0016910919221118093\n",
      "Epoch 4348, Loss: 8.00655618604651e-06, Final Batch Loss: 6.186029622767819e-06\n",
      "Epoch 4349, Loss: 6.954859054530971e-05, Final Batch Loss: 1.4653483958682045e-05\n",
      "Epoch 4350, Loss: 0.0005612283712252975, Final Batch Loss: 2.5009852834045887e-05\n",
      "Epoch 4351, Loss: 0.00015110479762370232, Final Batch Loss: 1.1617545169428922e-05\n",
      "Epoch 4352, Loss: 2.786208915495081e-05, Final Batch Loss: 1.7249119991902262e-05\n",
      "Epoch 4353, Loss: 5.316466013027821e-05, Final Batch Loss: 3.0257140679168515e-05\n",
      "Epoch 4354, Loss: 2.407374790891481e-05, Final Batch Loss: 3.65086611964216e-06\n",
      "Epoch 4355, Loss: 7.559398363810033e-05, Final Batch Loss: 4.498144699027762e-05\n",
      "Epoch 4356, Loss: 0.0002550169206188002, Final Batch Loss: 5.144790975464275e-06\n",
      "Epoch 4357, Loss: 5.8222911320626736e-05, Final Batch Loss: 1.7565969756105915e-05\n",
      "Epoch 4358, Loss: 0.0010665743366189417, Final Batch Loss: 6.148567081254441e-06\n",
      "Epoch 4359, Loss: 9.704036710900255e-05, Final Batch Loss: 1.0773725080071017e-05\n",
      "Epoch 4360, Loss: 0.00010235554100290756, Final Batch Loss: 2.8512909011624288e-06\n",
      "Epoch 4361, Loss: 8.542231807950884e-05, Final Batch Loss: 3.088109951931983e-05\n",
      "Epoch 4362, Loss: 0.0001294978419537074, Final Batch Loss: 5.48180742043769e-06\n",
      "Epoch 4363, Loss: 0.0004167833067185711, Final Batch Loss: 3.383679359103553e-05\n",
      "Epoch 4364, Loss: 0.0003638668349594809, Final Batch Loss: 1.2265554687473923e-05\n",
      "Epoch 4365, Loss: 0.00011264079421380302, Final Batch Loss: 0.000105832536064554\n",
      "Epoch 4366, Loss: 0.0005643545446218923, Final Batch Loss: 0.0003675477928481996\n",
      "Epoch 4367, Loss: 0.0015098938019946218, Final Batch Loss: 0.0001912721199914813\n",
      "Epoch 4368, Loss: 0.0005419214794528671, Final Batch Loss: 0.0005241308244876564\n",
      "Epoch 4369, Loss: 0.0009116178953263443, Final Batch Loss: 0.0008714308496564627\n",
      "Epoch 4370, Loss: 3.7434068417496746e-05, Final Batch Loss: 6.504518296424067e-06\n",
      "Epoch 4371, Loss: 0.00014574392480426468, Final Batch Loss: 0.00012264818360563368\n",
      "Epoch 4372, Loss: 2.832470909197582e-05, Final Batch Loss: 5.680159119947348e-06\n",
      "Epoch 4373, Loss: 1.56793674364053e-05, Final Batch Loss: 1.4919775821908843e-05\n",
      "Epoch 4374, Loss: 0.0005094182020002336, Final Batch Loss: 0.0005020728567615151\n",
      "Epoch 4375, Loss: 0.00022798791451350553, Final Batch Loss: 7.838522833480965e-06\n",
      "Epoch 4376, Loss: 4.582578003464732e-05, Final Batch Loss: 1.8120559616363607e-05\n",
      "Epoch 4377, Loss: 0.0002891082954192825, Final Batch Loss: 4.37108656115015e-06\n",
      "Epoch 4378, Loss: 5.7097118769888766e-05, Final Batch Loss: 5.4494223149959e-05\n",
      "Epoch 4379, Loss: 0.000353613720562862, Final Batch Loss: 0.00034640132798813283\n",
      "Epoch 4380, Loss: 7.607216502947267e-05, Final Batch Loss: 6.707703505526297e-06\n",
      "Epoch 4381, Loss: 3.802147966780467e-05, Final Batch Loss: 2.76627361017745e-05\n",
      "Epoch 4382, Loss: 2.8947424652869813e-05, Final Batch Loss: 1.7071437468985096e-05\n",
      "Epoch 4383, Loss: 8.732693459023722e-06, Final Batch Loss: 4.439058102434501e-06\n",
      "Epoch 4384, Loss: 1.2544671790237771e-05, Final Batch Loss: 2.9955485842947382e-06\n",
      "Epoch 4385, Loss: 2.0124146203670534e-05, Final Batch Loss: 2.249248382213409e-06\n",
      "Epoch 4386, Loss: 5.541447353607509e-05, Final Batch Loss: 2.6560928745311685e-05\n",
      "Epoch 4387, Loss: 1.9936192984459922e-05, Final Batch Loss: 7.890713277447503e-06\n",
      "Epoch 4388, Loss: 0.00010454496339207253, Final Batch Loss: 9.188541980620357e-07\n",
      "Epoch 4389, Loss: 0.0012049312701947201, Final Batch Loss: 2.124206957887509e-06\n",
      "Epoch 4390, Loss: 1.1441048627602868e-05, Final Batch Loss: 6.02238105784636e-06\n",
      "Epoch 4391, Loss: 6.278471300902311e-05, Final Batch Loss: 5.508745744009502e-06\n",
      "Epoch 4392, Loss: 7.519700375269167e-06, Final Batch Loss: 4.988765795133077e-06\n",
      "Epoch 4393, Loss: 0.00024886589744710363, Final Batch Loss: 0.00021245330572128296\n",
      "Epoch 4394, Loss: 1.4635600109613733e-05, Final Batch Loss: 6.410634796338854e-06\n",
      "Epoch 4395, Loss: 7.868199554650346e-05, Final Batch Loss: 6.839278648840263e-05\n",
      "Epoch 4396, Loss: 0.0004965555272065103, Final Batch Loss: 0.0001988764270208776\n",
      "Epoch 4397, Loss: 1.4943004089218448e-05, Final Batch Loss: 1.1790573807957117e-05\n",
      "Epoch 4398, Loss: 0.000591729140978714, Final Batch Loss: 8.04175124358153e-06\n",
      "Epoch 4399, Loss: 8.781759242992848e-05, Final Batch Loss: 7.819869642844424e-05\n",
      "Epoch 4400, Loss: 0.0006810655722802039, Final Batch Loss: 0.0006624227971769869\n",
      "Epoch 4401, Loss: 0.0016807254687591922, Final Batch Loss: 0.0016617263900116086\n",
      "Epoch 4402, Loss: 1.284489576391934e-05, Final Batch Loss: 1.1428254765633028e-05\n",
      "Epoch 4403, Loss: 1.1123317790406873e-05, Final Batch Loss: 8.023039299587253e-06\n",
      "Epoch 4404, Loss: 0.00029257353799039265, Final Batch Loss: 4.926120709569659e-06\n",
      "Epoch 4405, Loss: 3.6509054552880116e-05, Final Batch Loss: 6.573252903763205e-06\n",
      "Epoch 4406, Loss: 3.1193228835491027e-06, Final Batch Loss: 2.9371719847404165e-06\n",
      "Epoch 4407, Loss: 0.0003032870008610189, Final Batch Loss: 5.045824218541384e-05\n",
      "Epoch 4408, Loss: 2.102750750054838e-05, Final Batch Loss: 1.160999818239361e-05\n",
      "Epoch 4409, Loss: 0.0003035274830835988, Final Batch Loss: 0.0003010090731550008\n",
      "Epoch 4410, Loss: 5.804012016596971e-05, Final Batch Loss: 4.652568168239668e-05\n",
      "Epoch 4411, Loss: 2.269249853270594e-05, Final Batch Loss: 1.0681149433366954e-05\n",
      "Epoch 4412, Loss: 2.275891984027112e-05, Final Batch Loss: 1.0696639037632849e-05\n",
      "Epoch 4413, Loss: 1.666631476382463e-05, Final Batch Loss: 1.601399048922758e-06\n",
      "Epoch 4414, Loss: 0.00037998100651748246, Final Batch Loss: 1.2518546100181993e-05\n",
      "Epoch 4415, Loss: 5.595850910822264e-05, Final Batch Loss: 7.248704037010612e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4416, Loss: 9.453664006287e-06, Final Batch Loss: 7.551243470516056e-06\n",
      "Epoch 4417, Loss: 1.426165408702218e-05, Final Batch Loss: 6.72426449455088e-06\n",
      "Epoch 4418, Loss: 0.00021499029844562756, Final Batch Loss: 0.00020256053539924324\n",
      "Epoch 4419, Loss: 2.6287423679605126e-05, Final Batch Loss: 4.725707185571082e-06\n",
      "Epoch 4420, Loss: 1.833374881243799e-05, Final Batch Loss: 1.1146893484692555e-05\n",
      "Epoch 4421, Loss: 6.747883708158042e-05, Final Batch Loss: 2.5841289243544452e-05\n",
      "Epoch 4422, Loss: 6.953981096557982e-05, Final Batch Loss: 6.58718854538165e-05\n",
      "Epoch 4423, Loss: 7.924822511995444e-06, Final Batch Loss: 3.1051690712047275e-06\n",
      "Epoch 4424, Loss: 0.0012955776619492099, Final Batch Loss: 0.0012623906368389726\n",
      "Epoch 4425, Loss: 1.4872208339511417e-05, Final Batch Loss: 1.1512817764014471e-05\n",
      "Epoch 4426, Loss: 0.0007119210495147854, Final Batch Loss: 0.0006484815385192633\n",
      "Epoch 4427, Loss: 1.669960875005927e-05, Final Batch Loss: 5.631026397168171e-06\n",
      "Epoch 4428, Loss: 5.213702479522908e-05, Final Batch Loss: 4.8088826588355005e-05\n",
      "Epoch 4429, Loss: 0.045019433804554865, Final Batch Loss: 0.04470384120941162\n",
      "Epoch 4430, Loss: 0.0002860812655853806, Final Batch Loss: 0.0002603347529657185\n",
      "Epoch 4431, Loss: 9.991220485972008e-05, Final Batch Loss: 5.29482258571079e-06\n",
      "Epoch 4432, Loss: 2.571385084593203e-05, Final Batch Loss: 1.61376956384629e-05\n",
      "Epoch 4433, Loss: 0.0005804231332149357, Final Batch Loss: 0.00022854958660900593\n",
      "Epoch 4434, Loss: 1.7815838418755447e-05, Final Batch Loss: 1.4297012967290357e-05\n",
      "Epoch 4435, Loss: 0.00042242504423484206, Final Batch Loss: 1.84852397069335e-05\n",
      "Epoch 4436, Loss: 3.7377798435045406e-05, Final Batch Loss: 2.5081502826651558e-05\n",
      "Epoch 4437, Loss: 2.8958235816389788e-05, Final Batch Loss: 1.808542037906591e-05\n",
      "Epoch 4438, Loss: 2.2777296635467792e-05, Final Batch Loss: 4.47706997874775e-06\n",
      "Epoch 4439, Loss: 0.0001349203521385789, Final Batch Loss: 8.80318257259205e-05\n",
      "Epoch 4440, Loss: 5.681045695382636e-05, Final Batch Loss: 1.7898704754770733e-05\n",
      "Epoch 4441, Loss: 0.00038910458533791825, Final Batch Loss: 0.0003737666120287031\n",
      "Epoch 4442, Loss: 1.6676920949976193e-05, Final Batch Loss: 7.486710728699109e-06\n",
      "Epoch 4443, Loss: 3.3125319987448165e-05, Final Batch Loss: 2.5572113372618333e-05\n",
      "Epoch 4444, Loss: 0.00015734292537672445, Final Batch Loss: 0.00014251827087718993\n",
      "Epoch 4445, Loss: 8.374398566957098e-05, Final Batch Loss: 6.825134187238291e-05\n",
      "Epoch 4446, Loss: 6.12970397924073e-05, Final Batch Loss: 3.5183333238819614e-05\n",
      "Epoch 4447, Loss: 0.00011570376227609813, Final Batch Loss: 2.449018938932568e-05\n",
      "Epoch 4448, Loss: 5.750623677158728e-05, Final Batch Loss: 4.0087601519189775e-05\n",
      "Epoch 4449, Loss: 7.095466025930364e-05, Final Batch Loss: 4.5812499593012035e-05\n",
      "Epoch 4450, Loss: 0.0004890898621852102, Final Batch Loss: 0.0004850036057177931\n",
      "Epoch 4451, Loss: 6.0654601838905364e-05, Final Batch Loss: 4.155643910053186e-05\n",
      "Epoch 4452, Loss: 5.589178726950195e-05, Final Batch Loss: 2.0674766346928664e-05\n",
      "Epoch 4453, Loss: 0.0007616420843987726, Final Batch Loss: 0.0006923385662958026\n",
      "Epoch 4454, Loss: 3.98689521716733e-05, Final Batch Loss: 3.0007872737769503e-06\n",
      "Epoch 4455, Loss: 5.168438292457722e-05, Final Batch Loss: 8.710667316336185e-06\n",
      "Epoch 4456, Loss: 3.063052736251848e-05, Final Batch Loss: 3.715261300385464e-06\n",
      "Epoch 4457, Loss: 3.2108742743730545e-05, Final Batch Loss: 1.4331113561638631e-05\n",
      "Epoch 4458, Loss: 3.0459765184787102e-05, Final Batch Loss: 1.18246280180756e-05\n",
      "Epoch 4459, Loss: 0.0006474605215771589, Final Batch Loss: 0.0006093484116718173\n",
      "Epoch 4460, Loss: 9.260342812922318e-05, Final Batch Loss: 7.38631933927536e-05\n",
      "Epoch 4461, Loss: 5.446584509627428e-05, Final Batch Loss: 2.4289038265123963e-05\n",
      "Epoch 4462, Loss: 1.487513668507745e-05, Final Batch Loss: 2.143492338291253e-06\n",
      "Epoch 4463, Loss: 5.115211388329044e-05, Final Batch Loss: 2.777833833533805e-05\n",
      "Epoch 4464, Loss: 6.096146535128355e-05, Final Batch Loss: 3.6625297070713714e-05\n",
      "Epoch 4465, Loss: 0.0001873136825452093, Final Batch Loss: 2.369079811614938e-05\n",
      "Epoch 4466, Loss: 0.0002435434071230702, Final Batch Loss: 9.472746023675427e-05\n",
      "Epoch 4467, Loss: 0.00014674865269626025, Final Batch Loss: 6.130730980657972e-06\n",
      "Epoch 4468, Loss: 4.17573446611641e-05, Final Batch Loss: 1.566477476444561e-05\n",
      "Epoch 4469, Loss: 6.95778289809823e-05, Final Batch Loss: 5.832135138916783e-05\n",
      "Epoch 4470, Loss: 0.006388935453287559, Final Batch Loss: 0.0063807484693825245\n",
      "Epoch 4471, Loss: 9.718313413031865e-05, Final Batch Loss: 7.769701915094629e-05\n",
      "Epoch 4472, Loss: 2.6440493002155563e-05, Final Batch Loss: 5.951718321739463e-06\n",
      "Epoch 4473, Loss: 0.00010564758485998027, Final Batch Loss: 7.238586840685457e-05\n",
      "Epoch 4474, Loss: 5.6148881412809715e-05, Final Batch Loss: 4.598539453581907e-05\n",
      "Epoch 4475, Loss: 3.379839108674787e-05, Final Batch Loss: 7.2000730142463e-06\n",
      "Epoch 4476, Loss: 0.001794956002413528, Final Batch Loss: 3.2196596293943e-05\n",
      "Epoch 4477, Loss: 5.926054473093245e-05, Final Batch Loss: 2.4048809791565873e-05\n",
      "Epoch 4478, Loss: 6.163268335512839e-05, Final Batch Loss: 3.812818613369018e-05\n",
      "Epoch 4479, Loss: 1.8462774278305005e-05, Final Batch Loss: 4.392668415675871e-06\n",
      "Epoch 4480, Loss: 0.00017275202844757587, Final Batch Loss: 3.585897502489388e-05\n",
      "Epoch 4481, Loss: 0.00026458648790139705, Final Batch Loss: 7.303962775040418e-05\n",
      "Epoch 4482, Loss: 9.908986794471275e-05, Final Batch Loss: 6.899442087160423e-05\n",
      "Epoch 4483, Loss: 0.00011067615105275763, Final Batch Loss: 4.409291250340175e-06\n",
      "Epoch 4484, Loss: 8.644091576570645e-05, Final Batch Loss: 4.520696893450804e-05\n",
      "Epoch 4485, Loss: 0.00010898759501287714, Final Batch Loss: 6.883987953187898e-05\n",
      "Epoch 4486, Loss: 7.82314582465915e-05, Final Batch Loss: 1.316731322731357e-05\n",
      "Epoch 4487, Loss: 8.996410133477184e-05, Final Batch Loss: 2.4424002731393557e-06\n",
      "Epoch 4488, Loss: 8.150262146955356e-05, Final Batch Loss: 5.1215829444117844e-05\n",
      "Epoch 4489, Loss: 0.0008488712937833043, Final Batch Loss: 1.7335858501610346e-05\n",
      "Epoch 4490, Loss: 0.00044047665141988546, Final Batch Loss: 0.00020738174498546869\n",
      "Epoch 4491, Loss: 9.067390783457085e-05, Final Batch Loss: 7.897269824752584e-05\n",
      "Epoch 4492, Loss: 0.0008293923456221819, Final Batch Loss: 0.0008062207489274442\n",
      "Epoch 4493, Loss: 0.00015506013005506247, Final Batch Loss: 5.5927521316334605e-06\n",
      "Epoch 4494, Loss: 0.00024383587515330873, Final Batch Loss: 0.0001881567732198164\n",
      "Epoch 4495, Loss: 3.1442653380509e-05, Final Batch Loss: 8.97405971045373e-06\n",
      "Epoch 4496, Loss: 2.482167337802821e-05, Final Batch Loss: 5.420115940069081e-06\n",
      "Epoch 4497, Loss: 0.0003508780534957623, Final Batch Loss: 1.4282156826084247e-06\n",
      "Epoch 4498, Loss: 7.632800407009199e-05, Final Batch Loss: 4.321313099353574e-05\n",
      "Epoch 4499, Loss: 2.6854778298002202e-05, Final Batch Loss: 1.1682236618071329e-05\n",
      "Epoch 4500, Loss: 4.4738565520674456e-05, Final Batch Loss: 1.020570289256284e-05\n",
      "Epoch 4501, Loss: 4.6485363782267086e-05, Final Batch Loss: 2.4892187866498716e-05\n",
      "Epoch 4502, Loss: 4.8417012294521555e-05, Final Batch Loss: 4.080105645698495e-05\n",
      "Epoch 4503, Loss: 8.039531530812383e-05, Final Batch Loss: 5.745286762248725e-05\n",
      "Epoch 4504, Loss: 0.00036686238263428095, Final Batch Loss: 6.507019406853942e-06\n",
      "Epoch 4505, Loss: 6.999358629400376e-05, Final Batch Loss: 1.5381263438030146e-05\n",
      "Epoch 4506, Loss: 2.173465873056557e-05, Final Batch Loss: 1.3172121725801844e-05\n",
      "Epoch 4507, Loss: 0.0017515454201202374, Final Batch Loss: 0.001728183589875698\n",
      "Epoch 4508, Loss: 2.325679270143155e-05, Final Batch Loss: 1.0984585060214158e-05\n",
      "Epoch 4509, Loss: 2.349417945879395e-05, Final Batch Loss: 3.843367721856339e-06\n",
      "Epoch 4510, Loss: 0.00031853145628701895, Final Batch Loss: 4.8948670155368745e-05\n",
      "Epoch 4511, Loss: 6.060433815946453e-05, Final Batch Loss: 4.003223239124054e-06\n",
      "Epoch 4512, Loss: 6.128336553956615e-05, Final Batch Loss: 4.7005221858853474e-05\n",
      "Epoch 4513, Loss: 3.0243826358855586e-06, Final Batch Loss: 1.0765455726868822e-06\n",
      "Epoch 4514, Loss: 1.2458199762477307e-05, Final Batch Loss: 8.165912731783465e-06\n",
      "Epoch 4515, Loss: 6.108561865403317e-05, Final Batch Loss: 5.6769276852719486e-05\n",
      "Epoch 4516, Loss: 1.5174568943621125e-05, Final Batch Loss: 2.1225123418844305e-06\n",
      "Epoch 4517, Loss: 1.7045801996573573e-05, Final Batch Loss: 3.11396297547617e-06\n",
      "Epoch 4518, Loss: 0.0010993053620040882, Final Batch Loss: 5.337311449693516e-06\n",
      "Epoch 4519, Loss: 2.1455010937643237e-05, Final Batch Loss: 5.458716259454377e-06\n",
      "Epoch 4520, Loss: 2.0531454310912522e-05, Final Batch Loss: 3.1355800729215844e-06\n",
      "Epoch 4521, Loss: 3.0225375667214394e-05, Final Batch Loss: 1.426456765329931e-05\n",
      "Epoch 4522, Loss: 1.9239419998484664e-05, Final Batch Loss: 8.877111213223543e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4523, Loss: 7.798005526638008e-05, Final Batch Loss: 1.4622432900068816e-06\n",
      "Epoch 4524, Loss: 3.316692436783342e-05, Final Batch Loss: 6.151199158921372e-06\n",
      "Epoch 4525, Loss: 0.00021503553398360964, Final Batch Loss: 8.530672857887112e-06\n",
      "Epoch 4526, Loss: 9.945258625521092e-06, Final Batch Loss: 6.073677468521055e-06\n",
      "Epoch 4527, Loss: 1.6773816696513677e-05, Final Batch Loss: 6.319006843114039e-06\n",
      "Epoch 4528, Loss: 8.266127406386659e-05, Final Batch Loss: 2.312353899469599e-05\n",
      "Epoch 4529, Loss: 0.00010359637008150457, Final Batch Loss: 4.01130591853871e-06\n",
      "Epoch 4530, Loss: 2.523918192309793e-05, Final Batch Loss: 1.2371529919619206e-05\n",
      "Epoch 4531, Loss: 0.0001897714701044606, Final Batch Loss: 0.000182726580533199\n",
      "Epoch 4532, Loss: 6.604681766475551e-05, Final Batch Loss: 4.8502650315640494e-05\n",
      "Epoch 4533, Loss: 1.1148430530738551e-05, Final Batch Loss: 4.3461727727844846e-06\n",
      "Epoch 4534, Loss: 1.4881614788464503e-05, Final Batch Loss: 4.844929662795039e-06\n",
      "Epoch 4535, Loss: 0.0015276417589120683, Final Batch Loss: 0.001517086406238377\n",
      "Epoch 4536, Loss: 0.000272221330760658, Final Batch Loss: 3.4441386560501996e-06\n",
      "Epoch 4537, Loss: 2.3471669919672422e-05, Final Batch Loss: 9.66913557931548e-06\n",
      "Epoch 4538, Loss: 6.597465835511684e-05, Final Batch Loss: 4.6708344598300755e-05\n",
      "Epoch 4539, Loss: 0.00022654981694358867, Final Batch Loss: 1.7321608538622968e-05\n",
      "Epoch 4540, Loss: 3.494834982120665e-05, Final Batch Loss: 1.515697567811003e-05\n",
      "Epoch 4541, Loss: 0.005963524687103927, Final Batch Loss: 0.001492706942372024\n",
      "Epoch 4542, Loss: 2.3566856725665275e-05, Final Batch Loss: 1.0368126822868362e-05\n",
      "Epoch 4543, Loss: 1.826166953833308e-05, Final Batch Loss: 1.1427099707361776e-05\n",
      "Epoch 4544, Loss: 3.168658986396622e-05, Final Batch Loss: 2.6506422727834433e-06\n",
      "Epoch 4545, Loss: 3.993066911789356e-05, Final Batch Loss: 3.0998591682873666e-05\n",
      "Epoch 4546, Loss: 2.982825998287808e-05, Final Batch Loss: 6.937704597476113e-07\n",
      "Epoch 4547, Loss: 2.4846972337400075e-05, Final Batch Loss: 1.2918048923893366e-05\n",
      "Epoch 4548, Loss: 3.425612067076145e-05, Final Batch Loss: 9.608646905689966e-06\n",
      "Epoch 4549, Loss: 3.882389319187496e-05, Final Batch Loss: 2.1048484995844774e-05\n",
      "Epoch 4550, Loss: 6.315594646366662e-05, Final Batch Loss: 3.806786025961628e-06\n",
      "Epoch 4551, Loss: 2.352438423258718e-05, Final Batch Loss: 1.2503868674684782e-05\n",
      "Epoch 4552, Loss: 0.0016377574793295935, Final Batch Loss: 0.0001797223958419636\n",
      "Epoch 4553, Loss: 0.0007951356819830835, Final Batch Loss: 3.831059439107776e-05\n",
      "Epoch 4554, Loss: 4.825517225981457e-05, Final Batch Loss: 3.559063043212518e-05\n",
      "Epoch 4555, Loss: 7.188641666289186e-05, Final Batch Loss: 4.1339071685797535e-06\n",
      "Epoch 4556, Loss: 2.897662955092528e-05, Final Batch Loss: 2.7245287128607742e-05\n",
      "Epoch 4557, Loss: 3.185146942996653e-05, Final Batch Loss: 1.2925708688271698e-05\n",
      "Epoch 4558, Loss: 0.0003635511820903048, Final Batch Loss: 6.960915925446898e-05\n",
      "Epoch 4559, Loss: 0.0002151642256649211, Final Batch Loss: 0.00020334594591986388\n",
      "Epoch 4560, Loss: 3.885189653374255e-05, Final Batch Loss: 1.0873827704926953e-05\n",
      "Epoch 4561, Loss: 0.00028474940518208314, Final Batch Loss: 0.00026035861810669303\n",
      "Epoch 4562, Loss: 5.11416301378631e-05, Final Batch Loss: 4.3120147893205285e-05\n",
      "Epoch 4563, Loss: 8.083536613412434e-06, Final Batch Loss: 2.746866812231019e-06\n",
      "Epoch 4564, Loss: 1.3689512570635998e-05, Final Batch Loss: 3.5633559036796214e-06\n",
      "Epoch 4565, Loss: 5.915755082241958e-06, Final Batch Loss: 1.9694698494276963e-06\n",
      "Epoch 4566, Loss: 2.8113093321735505e-05, Final Batch Loss: 2.0005776605103165e-05\n",
      "Epoch 4567, Loss: 7.761896472402441e-05, Final Batch Loss: 3.4574279652588302e-06\n",
      "Epoch 4568, Loss: 1.2744601917802356e-05, Final Batch Loss: 5.505850822373759e-06\n",
      "Epoch 4569, Loss: 0.000486046157675446, Final Batch Loss: 7.984863259480335e-06\n",
      "Epoch 4570, Loss: 7.104668429747107e-05, Final Batch Loss: 4.060958872287301e-06\n",
      "Epoch 4571, Loss: 1.8497913970350055e-05, Final Batch Loss: 2.367683464399306e-06\n",
      "Epoch 4572, Loss: 4.0461187381879427e-05, Final Batch Loss: 1.0540821676841006e-05\n",
      "Epoch 4573, Loss: 3.138516603939934e-05, Final Batch Loss: 1.8442015061737038e-05\n",
      "Epoch 4574, Loss: 5.4167283451533876e-05, Final Batch Loss: 1.3975992260384373e-05\n",
      "Epoch 4575, Loss: 4.063205960846972e-05, Final Batch Loss: 3.3066346077248454e-05\n",
      "Epoch 4576, Loss: 2.9908322176197544e-05, Final Batch Loss: 1.7161626601591706e-05\n",
      "Epoch 4577, Loss: 2.0002059045509668e-05, Final Batch Loss: 1.2861032701039221e-05\n",
      "Epoch 4578, Loss: 0.00011399207596696215, Final Batch Loss: 1.3192407095630188e-05\n",
      "Epoch 4579, Loss: 3.1880484812063514e-06, Final Batch Loss: 1.0958120810755645e-06\n",
      "Epoch 4580, Loss: 0.0013589593436336145, Final Batch Loss: 7.198388630058616e-05\n",
      "Epoch 4581, Loss: 7.455616639617801e-05, Final Batch Loss: 1.6170632761713932e-06\n",
      "Epoch 4582, Loss: 0.00018937731147161685, Final Batch Loss: 0.00016855919966474175\n",
      "Epoch 4583, Loss: 1.0956707683362765e-05, Final Batch Loss: 5.7477218433632515e-06\n",
      "Epoch 4584, Loss: 3.3026814890035894e-05, Final Batch Loss: 2.359561221965123e-05\n",
      "Epoch 4585, Loss: 7.625722355442122e-05, Final Batch Loss: 3.801258571911603e-05\n",
      "Epoch 4586, Loss: 6.573153655153874e-06, Final Batch Loss: 4.992039066564757e-06\n",
      "Epoch 4587, Loss: 0.00010021620448696922, Final Batch Loss: 1.714755967441306e-06\n",
      "Epoch 4588, Loss: 7.614475725858938e-05, Final Batch Loss: 1.20169479487231e-05\n",
      "Epoch 4589, Loss: 0.0005278743142298481, Final Batch Loss: 1.4556376299879048e-06\n",
      "Epoch 4590, Loss: 0.00015585675396323495, Final Batch Loss: 2.917900246757199e-06\n",
      "Epoch 4591, Loss: 0.0009652760709286667, Final Batch Loss: 1.8395869119558483e-05\n",
      "Epoch 4592, Loss: 2.439725176373031e-05, Final Batch Loss: 8.897572115529329e-06\n",
      "Epoch 4593, Loss: 2.0329658127593575e-05, Final Batch Loss: 1.5661300494684838e-05\n",
      "Epoch 4594, Loss: 3.9257616890608915e-05, Final Batch Loss: 2.243368953713798e-06\n",
      "Epoch 4595, Loss: 7.549784641014412e-05, Final Batch Loss: 6.497721187770367e-06\n",
      "Epoch 4596, Loss: 1.1244752840866568e-05, Final Batch Loss: 4.295552571420558e-06\n",
      "Epoch 4597, Loss: 0.0003639815313363215, Final Batch Loss: 0.0003586177190300077\n",
      "Epoch 4598, Loss: 0.000642124105070252, Final Batch Loss: 1.3773045793641359e-05\n",
      "Epoch 4599, Loss: 1.2976651760254754e-05, Final Batch Loss: 5.1230485951236915e-06\n",
      "Epoch 4600, Loss: 5.857674841536209e-05, Final Batch Loss: 2.868287992896512e-06\n",
      "Epoch 4601, Loss: 2.0177824353595497e-05, Final Batch Loss: 3.077774181292625e-06\n",
      "Epoch 4602, Loss: 4.058278364027501e-06, Final Batch Loss: 1.2668233466683887e-06\n",
      "Epoch 4603, Loss: 9.565526306687389e-05, Final Batch Loss: 7.319447468034923e-05\n",
      "Epoch 4604, Loss: 6.702654991386225e-05, Final Batch Loss: 1.0906805073318537e-05\n",
      "Epoch 4605, Loss: 1.014653935271781e-05, Final Batch Loss: 5.137733296578517e-06\n",
      "Epoch 4606, Loss: 2.469663490956009e-05, Final Batch Loss: 1.5185789834504249e-06\n",
      "Epoch 4607, Loss: 2.675097107385227e-05, Final Batch Loss: 2.4606268198112957e-05\n",
      "Epoch 4608, Loss: 0.00020205177042953437, Final Batch Loss: 1.2371586308290716e-05\n",
      "Epoch 4609, Loss: 0.0001224057846229698, Final Batch Loss: 0.00011584066669456661\n",
      "Epoch 4610, Loss: 1.2631023992071277e-05, Final Batch Loss: 1.5163120679062558e-06\n",
      "Epoch 4611, Loss: 0.0013045771290762787, Final Batch Loss: 3.222866098440136e-06\n",
      "Epoch 4612, Loss: 3.650202870630892e-05, Final Batch Loss: 3.511301656544674e-06\n",
      "Epoch 4613, Loss: 3.738919531315332e-05, Final Batch Loss: 2.4418322936980985e-06\n",
      "Epoch 4614, Loss: 6.742577625118429e-06, Final Batch Loss: 3.701680498124915e-06\n",
      "Epoch 4615, Loss: 7.059852759994101e-05, Final Batch Loss: 7.057247785269283e-06\n",
      "Epoch 4616, Loss: 0.003366053524587187, Final Batch Loss: 3.2924126571742818e-06\n",
      "Epoch 4617, Loss: 5.9361426338000456e-05, Final Batch Loss: 5.421907189884223e-05\n",
      "Epoch 4618, Loss: 3.2741490940679796e-05, Final Batch Loss: 9.62209924182389e-06\n",
      "Epoch 4619, Loss: 2.8864017394880648e-05, Final Batch Loss: 1.1957606602663873e-06\n",
      "Epoch 4620, Loss: 0.00024768397361185635, Final Batch Loss: 0.00023619105922989547\n",
      "Epoch 4621, Loss: 0.00016539776925128535, Final Batch Loss: 4.4984794840274844e-06\n",
      "Epoch 4622, Loss: 0.00046793445108050946, Final Batch Loss: 1.730770782160107e-05\n",
      "Epoch 4623, Loss: 0.0024203659809245437, Final Batch Loss: 7.610240118083311e-06\n",
      "Epoch 4624, Loss: 0.0008302255173475714, Final Batch Loss: 2.6734300263342448e-05\n",
      "Epoch 4625, Loss: 3.8354263779183384e-05, Final Batch Loss: 1.3032785318500828e-05\n",
      "Epoch 4626, Loss: 5.557373879128136e-05, Final Batch Loss: 3.9559385186294094e-05\n",
      "Epoch 4627, Loss: 0.0003699334629345685, Final Batch Loss: 0.00033002442796714604\n",
      "Epoch 4628, Loss: 8.679534948896617e-05, Final Batch Loss: 1.7430284060537815e-05\n",
      "Epoch 4629, Loss: 5.8424095186637715e-05, Final Batch Loss: 3.2643201848259196e-05\n",
      "Epoch 4630, Loss: 0.00013495854364009574, Final Batch Loss: 0.00010238033428322524\n",
      "Epoch 4631, Loss: 0.00012945709659106797, Final Batch Loss: 0.00011686667130561545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4632, Loss: 0.00033823699050117284, Final Batch Loss: 4.6248300350271165e-05\n",
      "Epoch 4633, Loss: 0.002570693573943572, Final Batch Loss: 2.454077548463829e-05\n",
      "Epoch 4634, Loss: 0.0022805492244515335, Final Batch Loss: 0.002253638580441475\n",
      "Epoch 4635, Loss: 1.7449250663048588e-05, Final Batch Loss: 5.693827915820293e-06\n",
      "Epoch 4636, Loss: 1.9690376120706787e-05, Final Batch Loss: 4.901659394818125e-06\n",
      "Epoch 4637, Loss: 1.829668644859339e-05, Final Batch Loss: 1.1184201866853982e-05\n",
      "Epoch 4638, Loss: 1.908831848140835e-06, Final Batch Loss: 1.1172958238603314e-06\n",
      "Epoch 4639, Loss: 0.00012249588144186419, Final Batch Loss: 6.7691344156628475e-06\n",
      "Epoch 4640, Loss: 4.836457310375408e-05, Final Batch Loss: 4.370935130282305e-05\n",
      "Epoch 4641, Loss: 6.952671901672147e-05, Final Batch Loss: 4.249577614245936e-06\n",
      "Epoch 4642, Loss: 0.0003278178446635138, Final Batch Loss: 3.891552842105739e-05\n",
      "Epoch 4643, Loss: 6.98040298630076e-06, Final Batch Loss: 3.953401119360933e-06\n",
      "Epoch 4644, Loss: 9.530577472105506e-06, Final Batch Loss: 2.2656083729089005e-06\n",
      "Epoch 4645, Loss: 5.261458682070952e-05, Final Batch Loss: 3.942461262340657e-06\n",
      "Epoch 4646, Loss: 0.00019689995315275155, Final Batch Loss: 5.1784936658805236e-05\n",
      "Epoch 4647, Loss: 2.7773247893492226e-05, Final Batch Loss: 1.038837308442453e-05\n",
      "Epoch 4648, Loss: 0.0003723724494193448, Final Batch Loss: 0.0003681069356389344\n",
      "Epoch 4649, Loss: 2.390792087680893e-05, Final Batch Loss: 5.136950676387642e-06\n",
      "Epoch 4650, Loss: 0.0019147182392771356, Final Batch Loss: 8.781527139944956e-05\n",
      "Epoch 4651, Loss: 0.0036728988197864965, Final Batch Loss: 0.0036290313582867384\n",
      "Epoch 4652, Loss: 1.4817955388934934e-05, Final Batch Loss: 2.468338834660244e-06\n",
      "Epoch 4653, Loss: 5.994532102704397e-06, Final Batch Loss: 3.037042233700049e-06\n",
      "Epoch 4654, Loss: 7.999174067663262e-05, Final Batch Loss: 5.688009878213052e-06\n",
      "Epoch 4655, Loss: 1.675798932865291e-05, Final Batch Loss: 1.6473969708385994e-06\n",
      "Epoch 4656, Loss: 2.5789660185182584e-05, Final Batch Loss: 2.3080936443875544e-05\n",
      "Epoch 4657, Loss: 2.639355261635501e-05, Final Batch Loss: 6.790711267967708e-06\n",
      "Epoch 4658, Loss: 1.667922788328724e-05, Final Batch Loss: 8.506298399879597e-06\n",
      "Epoch 4659, Loss: 1.5766909200465307e-05, Final Batch Loss: 2.977049007313326e-06\n",
      "Epoch 4660, Loss: 3.964560573876952e-05, Final Batch Loss: 3.735929203685373e-05\n",
      "Epoch 4661, Loss: 2.0616454548871843e-05, Final Batch Loss: 1.7887761714519e-05\n",
      "Epoch 4662, Loss: 0.003969471586060536, Final Batch Loss: 5.193204742681701e-06\n",
      "Epoch 4663, Loss: 7.350207732770286e-05, Final Batch Loss: 7.27482110960409e-05\n",
      "Epoch 4664, Loss: 6.794978662583162e-05, Final Batch Loss: 6.221981038834201e-06\n",
      "Epoch 4665, Loss: 4.425227825777256e-05, Final Batch Loss: 3.8455513276858255e-05\n",
      "Epoch 4666, Loss: 0.00017701992010188405, Final Batch Loss: 7.5567118074104656e-06\n",
      "Epoch 4667, Loss: 4.595033260557102e-06, Final Batch Loss: 2.29581564781256e-06\n",
      "Epoch 4668, Loss: 1.369235314996331e-05, Final Batch Loss: 7.501661002606852e-06\n",
      "Epoch 4669, Loss: 2.6350668122177012e-05, Final Batch Loss: 2.365394902881235e-05\n",
      "Epoch 4670, Loss: 0.000704460972428933, Final Batch Loss: 6.686800134048099e-06\n",
      "Epoch 4671, Loss: 7.916531899354595e-06, Final Batch Loss: 1.737728211992362e-06\n",
      "Epoch 4672, Loss: 1.2232579820192768e-05, Final Batch Loss: 1.3778187621937832e-06\n",
      "Epoch 4673, Loss: 0.0002607720502965094, Final Batch Loss: 0.00025520287454128265\n",
      "Epoch 4674, Loss: 2.2788327891376525e-06, Final Batch Loss: 1.2587315190160098e-08\n",
      "Epoch 4675, Loss: 1.648088482397725e-05, Final Batch Loss: 1.4194559298630338e-05\n",
      "Epoch 4676, Loss: 7.433887503793812e-06, Final Batch Loss: 1.106915760828997e-06\n",
      "Epoch 4677, Loss: 6.647816462646006e-05, Final Batch Loss: 4.458200237422716e-06\n",
      "Epoch 4678, Loss: 2.1096118643981754e-05, Final Batch Loss: 1.935241016326472e-05\n",
      "Epoch 4679, Loss: 0.00011661873395496514, Final Batch Loss: 9.414609667146578e-05\n",
      "Epoch 4680, Loss: 7.687249990340206e-06, Final Batch Loss: 6.525252501887735e-06\n",
      "Epoch 4681, Loss: 9.24886307984707e-06, Final Batch Loss: 8.018751941563096e-06\n",
      "Epoch 4682, Loss: 1.1789808922912925e-05, Final Batch Loss: 7.352904503932223e-06\n",
      "Epoch 4683, Loss: 0.0001015734351312858, Final Batch Loss: 6.258354005694855e-06\n",
      "Epoch 4684, Loss: 6.928608513590007e-06, Final Batch Loss: 5.2502855396596715e-06\n",
      "Epoch 4685, Loss: 6.530953214678448e-06, Final Batch Loss: 2.35664083447773e-06\n",
      "Epoch 4686, Loss: 2.885991125367582e-05, Final Batch Loss: 2.3038697690935805e-05\n",
      "Epoch 4687, Loss: 2.3054350094753318e-05, Final Batch Loss: 2.284008587594144e-06\n",
      "Epoch 4688, Loss: 5.354012500902172e-06, Final Batch Loss: 2.2624349185207393e-06\n",
      "Epoch 4689, Loss: 1.5242606878018705e-05, Final Batch Loss: 8.345497008122038e-06\n",
      "Epoch 4690, Loss: 3.7596269521600334e-05, Final Batch Loss: 6.186287919263123e-06\n",
      "Epoch 4691, Loss: 7.760822285263203e-05, Final Batch Loss: 6.99677400461951e-07\n",
      "Epoch 4692, Loss: 5.161538501852192e-05, Final Batch Loss: 3.0097096896497533e-05\n",
      "Epoch 4693, Loss: 3.418820688239066e-05, Final Batch Loss: 2.5518405891489238e-05\n",
      "Epoch 4694, Loss: 9.707550191251357e-06, Final Batch Loss: 7.670471973142412e-07\n",
      "Epoch 4695, Loss: 2.0368343029986136e-05, Final Batch Loss: 1.2729897207464091e-05\n",
      "Epoch 4696, Loss: 0.0006684155619041121, Final Batch Loss: 0.000662545207887888\n",
      "Epoch 4697, Loss: 0.0012658095665756264, Final Batch Loss: 9.75657985691214e-06\n",
      "Epoch 4698, Loss: 6.888292546136654e-06, Final Batch Loss: 2.007199100262369e-06\n",
      "Epoch 4699, Loss: 6.67252970742993e-05, Final Batch Loss: 1.914521271828562e-05\n",
      "Epoch 4700, Loss: 1.1996373132205917e-05, Final Batch Loss: 3.74059322894027e-06\n",
      "Epoch 4701, Loss: 5.39231391485373e-05, Final Batch Loss: 3.845280389214167e-06\n",
      "Epoch 4702, Loss: 1.1568297054509458e-05, Final Batch Loss: 1.0176492651225999e-05\n",
      "Epoch 4703, Loss: 6.842600669187959e-06, Final Batch Loss: 3.981849658885039e-06\n",
      "Epoch 4704, Loss: 0.0004313651611482783, Final Batch Loss: 0.00042610327363945544\n",
      "Epoch 4705, Loss: 4.117164257877448e-05, Final Batch Loss: 3.0413937111006817e-06\n",
      "Epoch 4706, Loss: 1.1008312185367686e-05, Final Batch Loss: 1.5192420050880173e-06\n",
      "Epoch 4707, Loss: 2.5069516595976893e-05, Final Batch Loss: 1.5354331480921246e-05\n",
      "Epoch 4708, Loss: 7.548706662419136e-05, Final Batch Loss: 3.6569213079928886e-06\n",
      "Epoch 4709, Loss: 3.301144352008123e-05, Final Batch Loss: 1.637000241316855e-05\n",
      "Epoch 4710, Loss: 2.6018563858087873e-05, Final Batch Loss: 1.8686123439692892e-05\n",
      "Epoch 4711, Loss: 6.397565357474377e-06, Final Batch Loss: 3.769539262066246e-06\n",
      "Epoch 4712, Loss: 3.201059007551521e-05, Final Batch Loss: 4.598707164404914e-06\n",
      "Epoch 4713, Loss: 0.0011777911859098822, Final Batch Loss: 0.001115538994781673\n",
      "Epoch 4714, Loss: 0.00036520272169582313, Final Batch Loss: 0.0003548585809767246\n",
      "Epoch 4715, Loss: 2.4453789592371322e-05, Final Batch Loss: 7.42697375244461e-06\n",
      "Epoch 4716, Loss: 0.0003497552675071347, Final Batch Loss: 2.2278250071394723e-06\n",
      "Epoch 4717, Loss: 1.1688259974107496e-05, Final Batch Loss: 1.2941798104293412e-06\n",
      "Epoch 4718, Loss: 5.483835820996319e-06, Final Batch Loss: 8.692411483934848e-07\n",
      "Epoch 4719, Loss: 0.00012973483308087452, Final Batch Loss: 2.094513092743e-06\n",
      "Epoch 4720, Loss: 1.6095508499347488e-06, Final Batch Loss: 3.7983147649356397e-07\n",
      "Epoch 4721, Loss: 5.959096313290502e-06, Final Batch Loss: 5.266261268843664e-06\n",
      "Epoch 4722, Loss: 2.007722287089564e-05, Final Batch Loss: 1.373675786453532e-05\n",
      "Epoch 4723, Loss: 3.543977982189972e-05, Final Batch Loss: 1.6386811694246717e-05\n",
      "Epoch 4724, Loss: 4.239031113684177e-06, Final Batch Loss: 1.731781821945333e-06\n",
      "Epoch 4725, Loss: 2.445215648094745e-05, Final Batch Loss: 1.3608736253445386e-06\n",
      "Epoch 4726, Loss: 5.744716008848627e-05, Final Batch Loss: 2.2603603611059953e-06\n",
      "Epoch 4727, Loss: 1.5679059970352682e-06, Final Batch Loss: 4.664594825953827e-07\n",
      "Epoch 4728, Loss: 9.279890946345404e-05, Final Batch Loss: 5.765616879216395e-05\n",
      "Epoch 4729, Loss: 1.2519537449406926e-05, Final Batch Loss: 4.0000531953410245e-06\n",
      "Epoch 4730, Loss: 1.2399064644341706e-05, Final Batch Loss: 1.0962462511088233e-05\n",
      "Epoch 4731, Loss: 2.1341257479434717e-05, Final Batch Loss: 1.8705581169342622e-05\n",
      "Epoch 4732, Loss: 1.9016526636050912e-05, Final Batch Loss: 1.875236011983361e-05\n",
      "Epoch 4733, Loss: 4.6028234237383e-06, Final Batch Loss: 4.116933268960565e-06\n",
      "Epoch 4734, Loss: 1.8892379785029334e-05, Final Batch Loss: 2.260419250887935e-06\n",
      "Epoch 4735, Loss: 0.003571588604245335, Final Batch Loss: 7.259525591507554e-05\n",
      "Epoch 4736, Loss: 2.938530485607771e-06, Final Batch Loss: 8.114652132462652e-07\n",
      "Epoch 4737, Loss: 2.457719290305249e-06, Final Batch Loss: 9.46249940625421e-07\n",
      "Epoch 4738, Loss: 9.504355602985015e-06, Final Batch Loss: 3.4340687307121698e-06\n",
      "Epoch 4739, Loss: 5.5795364914956735e-06, Final Batch Loss: 3.6837629977526376e-06\n",
      "Epoch 4740, Loss: 3.163491577140576e-06, Final Batch Loss: 3.099118657701183e-06\n",
      "Epoch 4741, Loss: 3.0494437282868603e-05, Final Batch Loss: 1.0106690524480655e-06\n",
      "Epoch 4742, Loss: 0.00029114433709764853, Final Batch Loss: 1.1115982488263398e-05\n",
      "Epoch 4743, Loss: 0.00442765384377708, Final Batch Loss: 0.004423247650265694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4744, Loss: 0.00031623138647773885, Final Batch Loss: 0.0003110254474449903\n",
      "Epoch 4745, Loss: 1.1716701465047663e-05, Final Batch Loss: 2.9022271519352216e-06\n",
      "Epoch 4746, Loss: 1.5241486380546121e-05, Final Batch Loss: 6.2150552366802e-06\n",
      "Epoch 4747, Loss: 2.0500114260357805e-05, Final Batch Loss: 1.6429465176770464e-05\n",
      "Epoch 4748, Loss: 0.0006430868559164082, Final Batch Loss: 0.0006408019689843059\n",
      "Epoch 4749, Loss: 7.767263105051825e-05, Final Batch Loss: 6.884623144287616e-05\n",
      "Epoch 4750, Loss: 8.316881576320156e-06, Final Batch Loss: 3.899624971381854e-06\n",
      "Epoch 4751, Loss: 2.9388746952463407e-05, Final Batch Loss: 1.1804800124082249e-05\n",
      "Epoch 4752, Loss: 7.871989794239198e-06, Final Batch Loss: 4.0723244865148445e-07\n",
      "Epoch 4753, Loss: 0.0004665971405302116, Final Batch Loss: 0.0004621853877324611\n",
      "Epoch 4754, Loss: 6.8331077613947855e-06, Final Batch Loss: 7.396660635095031e-07\n",
      "Epoch 4755, Loss: 1.2571279057738138e-05, Final Batch Loss: 1.066308504960034e-05\n",
      "Epoch 4756, Loss: 3.2249312425847165e-05, Final Batch Loss: 1.64613411470782e-05\n",
      "Epoch 4757, Loss: 4.6462396767310565e-05, Final Batch Loss: 4.3726508010877296e-05\n",
      "Epoch 4758, Loss: 0.001086425215817144, Final Batch Loss: 4.613020337274065e-06\n",
      "Epoch 4759, Loss: 2.4321346245415043e-05, Final Batch Loss: 8.360852916666772e-06\n",
      "Epoch 4760, Loss: 3.66026191045421e-06, Final Batch Loss: 3.198629485723359e-07\n",
      "Epoch 4761, Loss: 9.837615607466432e-06, Final Batch Loss: 7.47144486012985e-06\n",
      "Epoch 4762, Loss: 7.234750228235498e-06, Final Batch Loss: 2.7082865017291624e-06\n",
      "Epoch 4763, Loss: 4.522292147157714e-05, Final Batch Loss: 1.2031479855068028e-05\n",
      "Epoch 4764, Loss: 0.005030217450183727, Final Batch Loss: 1.2513257274804346e-07\n",
      "Epoch 4765, Loss: 0.00036321555944596184, Final Batch Loss: 1.2202933248772752e-05\n",
      "Epoch 4766, Loss: 7.107780402293429e-05, Final Batch Loss: 5.3885512897977605e-05\n",
      "Epoch 4767, Loss: 3.271838136242877e-05, Final Batch Loss: 3.1330870115198195e-05\n",
      "Epoch 4768, Loss: 1.1428663128754124e-05, Final Batch Loss: 3.778622158279177e-06\n",
      "Epoch 4769, Loss: 1.744188853081141e-05, Final Batch Loss: 1.4216633644537069e-05\n",
      "Epoch 4770, Loss: 2.1361731342040002e-05, Final Batch Loss: 4.7017056203912944e-07\n",
      "Epoch 4771, Loss: 9.237578524334822e-06, Final Batch Loss: 3.199857019353658e-06\n",
      "Epoch 4772, Loss: 4.0179032112064306e-05, Final Batch Loss: 1.2145111213612836e-05\n",
      "Epoch 4773, Loss: 1.3605503227154259e-05, Final Batch Loss: 6.033819772710558e-06\n",
      "Epoch 4774, Loss: 2.1990328605170362e-05, Final Batch Loss: 1.0298002052877564e-05\n",
      "Epoch 4775, Loss: 3.957538410759298e-05, Final Batch Loss: 1.3988356840854976e-05\n",
      "Epoch 4776, Loss: 2.0550914541672682e-05, Final Batch Loss: 1.725684887787793e-05\n",
      "Epoch 4777, Loss: 0.0007492720678783371, Final Batch Loss: 0.0007358056609518826\n",
      "Epoch 4778, Loss: 0.0003945886819565203, Final Batch Loss: 7.864258805057034e-06\n",
      "Epoch 4779, Loss: 1.456445016856378e-05, Final Batch Loss: 1.3926462997915223e-05\n",
      "Epoch 4780, Loss: 0.0006861498186481185, Final Batch Loss: 5.975610838504508e-05\n",
      "Epoch 4781, Loss: 8.25993083708454e-06, Final Batch Loss: 3.5678503991221078e-06\n",
      "Epoch 4782, Loss: 0.0002038993529254185, Final Batch Loss: 0.00020294904243201017\n",
      "Epoch 4783, Loss: 7.950906956466497e-05, Final Batch Loss: 3.259907771280268e-06\n",
      "Epoch 4784, Loss: 0.0005635358684230596, Final Batch Loss: 0.00018413248471915722\n",
      "Epoch 4785, Loss: 1.6266529200947843e-05, Final Batch Loss: 8.085979970928747e-06\n",
      "Epoch 4786, Loss: 0.00041518593570799567, Final Batch Loss: 3.1790150387678295e-06\n",
      "Epoch 4787, Loss: 8.441390491498169e-06, Final Batch Loss: 6.524618129333248e-06\n",
      "Epoch 4788, Loss: 0.0007019414421165493, Final Batch Loss: 0.0007008214015513659\n",
      "Epoch 4789, Loss: 1.5994041405065218e-05, Final Batch Loss: 3.5625594136945438e-06\n",
      "Epoch 4790, Loss: 8.905359891286935e-06, Final Batch Loss: 2.031540361713269e-06\n",
      "Epoch 4791, Loss: 1.3693722621610505e-05, Final Batch Loss: 3.358765070515801e-06\n",
      "Epoch 4792, Loss: 8.521297786501236e-06, Final Batch Loss: 7.722601367277093e-07\n",
      "Epoch 4793, Loss: 8.266796066891402e-05, Final Batch Loss: 5.0346163334324956e-05\n",
      "Epoch 4794, Loss: 2.6419598725624382e-05, Final Batch Loss: 2.2107124095782638e-05\n",
      "Epoch 4795, Loss: 8.192259701900184e-05, Final Batch Loss: 5.99949671595823e-05\n",
      "Epoch 4796, Loss: 0.00041830583359114826, Final Batch Loss: 0.00037532890564762056\n",
      "Epoch 4797, Loss: 0.00641223934565005, Final Batch Loss: 0.0064107985235750675\n",
      "Epoch 4798, Loss: 3.266642875132675e-05, Final Batch Loss: 3.167274553561583e-05\n",
      "Epoch 4799, Loss: 4.142601255807676e-06, Final Batch Loss: 3.046389338123845e-06\n",
      "Epoch 4800, Loss: 5.15702304255683e-05, Final Batch Loss: 2.1072628442198038e-05\n",
      "Epoch 4801, Loss: 6.819867166996119e-06, Final Batch Loss: 2.537003410907346e-06\n",
      "Epoch 4802, Loss: 1.7274043784709647e-05, Final Batch Loss: 1.4553944311046507e-05\n",
      "Epoch 4803, Loss: 0.00045560329454019666, Final Batch Loss: 5.396344931796193e-06\n",
      "Epoch 4804, Loss: 0.00012151735199950053, Final Batch Loss: 3.176156951667508e-06\n",
      "Epoch 4805, Loss: 0.000138129702918377, Final Batch Loss: 0.0001333911350229755\n",
      "Epoch 4806, Loss: 1.9855263872159412e-05, Final Batch Loss: 1.3071197827230208e-05\n",
      "Epoch 4807, Loss: 9.658004216817062e-06, Final Batch Loss: 8.857412467477843e-06\n",
      "Epoch 4808, Loss: 0.00022907755749201897, Final Batch Loss: 0.00022840143356006593\n",
      "Epoch 4809, Loss: 1.3370524811762152e-05, Final Batch Loss: 5.233296633377904e-06\n",
      "Epoch 4810, Loss: 2.7802493605122436e-05, Final Batch Loss: 2.2848613298265263e-05\n",
      "Epoch 4811, Loss: 1.7842190572991967e-05, Final Batch Loss: 1.236418029293418e-06\n",
      "Epoch 4812, Loss: 4.182822635812045e-06, Final Batch Loss: 9.381025165566825e-07\n",
      "Epoch 4813, Loss: 3.068239834647102e-05, Final Batch Loss: 1.9391115984035423e-06\n",
      "Epoch 4814, Loss: 4.4980532948102336e-05, Final Batch Loss: 3.043270407943055e-05\n",
      "Epoch 4815, Loss: 1.7295725228905212e-05, Final Batch Loss: 4.105652806174476e-06\n",
      "Epoch 4816, Loss: 5.989831265651446e-06, Final Batch Loss: 1.4770458847124246e-06\n",
      "Epoch 4817, Loss: 6.838206729753438e-06, Final Batch Loss: 6.485352059826255e-06\n",
      "Epoch 4818, Loss: 3.327794388496841e-05, Final Batch Loss: 5.44945805813768e-07\n",
      "Epoch 4819, Loss: 0.00026644509671314154, Final Batch Loss: 8.146855179802515e-06\n",
      "Epoch 4820, Loss: 0.000226218182433513, Final Batch Loss: 0.00020643214520532638\n",
      "Epoch 4821, Loss: 8.355060231224343e-06, Final Batch Loss: 1.8627882809596485e-06\n",
      "Epoch 4822, Loss: 0.00047049103818608273, Final Batch Loss: 0.0004696818650700152\n",
      "Epoch 4823, Loss: 0.011077729289354465, Final Batch Loss: 0.011072293855249882\n",
      "Epoch 4824, Loss: 4.858056672674138e-05, Final Batch Loss: 1.118692489399109e-05\n",
      "Epoch 4825, Loss: 1.0174248018302023e-05, Final Batch Loss: 2.6334678295825142e-06\n",
      "Epoch 4826, Loss: 8.865542895364342e-06, Final Batch Loss: 1.330522991338512e-06\n",
      "Epoch 4827, Loss: 1.4924243373570789e-05, Final Batch Loss: 1.3912422218709253e-05\n",
      "Epoch 4828, Loss: 2.9237377930257935e-05, Final Batch Loss: 2.2805692424299195e-05\n",
      "Epoch 4829, Loss: 1.1056923199248558e-05, Final Batch Loss: 1.4415469422601745e-06\n",
      "Epoch 4830, Loss: 4.7146197175607085e-05, Final Batch Loss: 1.856238850450609e-05\n",
      "Epoch 4831, Loss: 0.004863589761498588, Final Batch Loss: 6.478504928963957e-06\n",
      "Epoch 4832, Loss: 4.83264161630359e-05, Final Batch Loss: 4.234405787428841e-05\n",
      "Epoch 4833, Loss: 0.00018838869254977908, Final Batch Loss: 1.655622872931417e-05\n",
      "Epoch 4834, Loss: 5.176812919671647e-05, Final Batch Loss: 3.5754004784394056e-05\n",
      "Epoch 4835, Loss: 4.6753774313401664e-05, Final Batch Loss: 7.118879238987574e-06\n",
      "Epoch 4836, Loss: 0.0008502216896886239, Final Batch Loss: 7.196236765594222e-06\n",
      "Epoch 4837, Loss: 4.053570228279568e-05, Final Batch Loss: 3.102489063167013e-05\n",
      "Epoch 4838, Loss: 0.00011816236292361282, Final Batch Loss: 1.715242615318857e-05\n",
      "Epoch 4839, Loss: 2.3712319944024784e-05, Final Batch Loss: 4.7383578021253925e-06\n",
      "Epoch 4840, Loss: 0.00034191791201010346, Final Batch Loss: 1.5880534192547202e-05\n",
      "Epoch 4841, Loss: 0.00014453082985710353, Final Batch Loss: 8.536536915926263e-05\n",
      "Epoch 4842, Loss: 1.5653157333872514e-05, Final Batch Loss: 2.8038016353093553e-06\n",
      "Epoch 4843, Loss: 3.042239313799655e-06, Final Batch Loss: 1.1083559456892544e-06\n",
      "Epoch 4844, Loss: 1.228332303071511e-05, Final Batch Loss: 5.931546638748841e-06\n",
      "Epoch 4845, Loss: 1.514649056844064e-05, Final Batch Loss: 5.44668318980257e-06\n",
      "Epoch 4846, Loss: 5.6614244726915786e-05, Final Batch Loss: 1.8953072640215396e-06\n",
      "Epoch 4847, Loss: 1.5180007267190376e-05, Final Batch Loss: 3.2569055292697158e-06\n",
      "Epoch 4848, Loss: 0.0003134870928533928, Final Batch Loss: 0.0003119603788945824\n",
      "Epoch 4849, Loss: 3.9133352856879355e-05, Final Batch Loss: 2.3610487005498726e-06\n",
      "Epoch 4850, Loss: 1.2243614946783055e-05, Final Batch Loss: 7.644956895092037e-06\n",
      "Epoch 4851, Loss: 0.0004065114721925056, Final Batch Loss: 0.0004037769977003336\n",
      "Epoch 4852, Loss: 1.4792944512009853e-05, Final Batch Loss: 4.803826868737815e-06\n",
      "Epoch 4853, Loss: 0.00016389898610214004, Final Batch Loss: 0.00015327022993005812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4854, Loss: 4.768898861584603e-06, Final Batch Loss: 2.2995959625404794e-06\n",
      "Epoch 4855, Loss: 5.038679773861077e-05, Final Batch Loss: 2.2844673367217183e-05\n",
      "Epoch 4856, Loss: 6.308757406259247e-06, Final Batch Loss: 1.3866957715436001e-06\n",
      "Epoch 4857, Loss: 6.587882808162249e-06, Final Batch Loss: 4.206238827464404e-06\n",
      "Epoch 4858, Loss: 9.378128197568003e-05, Final Batch Loss: 8.485319267492741e-05\n",
      "Epoch 4859, Loss: 5.8511316410658765e-05, Final Batch Loss: 5.495400182553567e-05\n",
      "Epoch 4860, Loss: 0.009015292167532607, Final Batch Loss: 0.008998263627290726\n",
      "Epoch 4861, Loss: 5.328790825842589e-05, Final Batch Loss: 5.567987955146236e-07\n",
      "Epoch 4862, Loss: 2.789128848235123e-05, Final Batch Loss: 1.679670276644174e-05\n",
      "Epoch 4863, Loss: 7.550633597475098e-06, Final Batch Loss: 6.411964363906009e-07\n",
      "Epoch 4864, Loss: 2.624944318085909e-05, Final Batch Loss: 1.048077319865115e-05\n",
      "Epoch 4865, Loss: 2.2129815988591872e-05, Final Batch Loss: 6.718260920024477e-06\n",
      "Epoch 4866, Loss: 3.649575501185609e-05, Final Batch Loss: 2.5177772840834223e-05\n",
      "Epoch 4867, Loss: 1.080109200302104e-05, Final Batch Loss: 9.486509952694178e-06\n",
      "Epoch 4868, Loss: 1.2625157978618518e-05, Final Batch Loss: 3.672852471936494e-06\n",
      "Epoch 4869, Loss: 0.0015101133903954178, Final Batch Loss: 0.0014713110867887735\n",
      "Epoch 4870, Loss: 1.1522391332619009e-05, Final Batch Loss: 8.086743036983535e-06\n",
      "Epoch 4871, Loss: 2.3776166017341893e-05, Final Batch Loss: 1.1074069334426895e-05\n",
      "Epoch 4872, Loss: 1.566753417137079e-05, Final Batch Loss: 1.017035810946254e-05\n",
      "Epoch 4873, Loss: 0.0002699512515391689, Final Batch Loss: 1.572839028085582e-05\n",
      "Epoch 4874, Loss: 1.2422990494087571e-05, Final Batch Loss: 3.694477072713198e-06\n",
      "Epoch 4875, Loss: 3.088502126047388e-05, Final Batch Loss: 1.729731411614921e-05\n",
      "Epoch 4876, Loss: 0.0003934427550120745, Final Batch Loss: 0.0003615127061493695\n",
      "Epoch 4877, Loss: 1.5880257706157863e-05, Final Batch Loss: 7.3353339757886715e-06\n",
      "Epoch 4878, Loss: 2.9109323804732412e-05, Final Batch Loss: 1.710895412543323e-05\n",
      "Epoch 4879, Loss: 8.732462265470531e-05, Final Batch Loss: 8.03633447503671e-05\n",
      "Epoch 4880, Loss: 0.00014223856442185934, Final Batch Loss: 2.446653070364846e-06\n",
      "Epoch 4881, Loss: 4.25206235377118e-05, Final Batch Loss: 3.73867223970592e-05\n",
      "Epoch 4882, Loss: 0.00022244772480917163, Final Batch Loss: 5.259532554191537e-05\n",
      "Epoch 4883, Loss: 1.3056318039161852e-05, Final Batch Loss: 9.153763130598236e-06\n",
      "Epoch 4884, Loss: 2.9436619797706953e-05, Final Batch Loss: 3.2539608127990505e-06\n",
      "Epoch 4885, Loss: 1.8843982161342865e-05, Final Batch Loss: 1.2060280823789071e-05\n",
      "Epoch 4886, Loss: 3.7949425632177736e-05, Final Batch Loss: 2.37070958064578e-06\n",
      "Epoch 4887, Loss: 6.57581540508545e-06, Final Batch Loss: 2.8444999315979658e-06\n",
      "Epoch 4888, Loss: 4.2685121570684714e-06, Final Batch Loss: 2.594890929685789e-06\n",
      "Epoch 4889, Loss: 2.1111653950356413e-05, Final Batch Loss: 5.9075300669064745e-06\n",
      "Epoch 4890, Loss: 1.5331747817981523e-05, Final Batch Loss: 8.194204383471515e-06\n",
      "Epoch 4891, Loss: 4.1689517388476816e-05, Final Batch Loss: 1.3830623402100173e-06\n",
      "Epoch 4892, Loss: 7.739679131191224e-05, Final Batch Loss: 6.326977018034086e-05\n",
      "Epoch 4893, Loss: 7.135104578992468e-05, Final Batch Loss: 2.187640802731039e-06\n",
      "Epoch 4894, Loss: 0.0004964877198290196, Final Batch Loss: 0.0004888243856839836\n",
      "Epoch 4895, Loss: 9.524145866635081e-06, Final Batch Loss: 2.517436996640754e-07\n",
      "Epoch 4896, Loss: 6.013382335368078e-05, Final Batch Loss: 6.6850025177700445e-06\n",
      "Epoch 4897, Loss: 2.936390956165269e-05, Final Batch Loss: 2.2415546482079662e-05\n",
      "Epoch 4898, Loss: 2.2050180973565148e-05, Final Batch Loss: 2.0619256247300655e-05\n",
      "Epoch 4899, Loss: 0.0005744535228586756, Final Batch Loss: 0.0005469328607432544\n",
      "Epoch 4900, Loss: 1.752984982772432e-05, Final Batch Loss: 1.4660483316220052e-07\n",
      "Epoch 4901, Loss: 0.0025389738530066097, Final Batch Loss: 0.002534757601097226\n",
      "Epoch 4902, Loss: 0.0002456226220033386, Final Batch Loss: 0.00024480486172251403\n",
      "Epoch 4903, Loss: 0.00010217554108749027, Final Batch Loss: 9.525582572678104e-05\n",
      "Epoch 4904, Loss: 0.0016519017590326257, Final Batch Loss: 0.00010738382843555883\n",
      "Epoch 4905, Loss: 0.0004914345731776848, Final Batch Loss: 6.224650405783905e-06\n",
      "Epoch 4906, Loss: 1.8650097445060965e-05, Final Batch Loss: 1.6378997315769084e-05\n",
      "Epoch 4907, Loss: 2.129071117451531e-05, Final Batch Loss: 4.753061602968955e-06\n",
      "Epoch 4908, Loss: 0.00020750920606360523, Final Batch Loss: 0.00020686215430032462\n",
      "Epoch 4909, Loss: 1.3152797691873275e-05, Final Batch Loss: 7.610772627231199e-06\n",
      "Epoch 4910, Loss: 3.5728980947169475e-05, Final Batch Loss: 1.9603510736487806e-05\n",
      "Epoch 4911, Loss: 1.0964278317260323e-05, Final Batch Loss: 7.088429356372217e-06\n",
      "Epoch 4912, Loss: 0.00026015175370730503, Final Batch Loss: 0.0002594331745058298\n",
      "Epoch 4913, Loss: 5.2174803840898676e-05, Final Batch Loss: 4.6446955821011215e-05\n",
      "Epoch 4914, Loss: 6.752951549060526e-05, Final Batch Loss: 6.0965623561060056e-05\n",
      "Epoch 4915, Loss: 0.00012288989455555566, Final Batch Loss: 0.000114920869236812\n",
      "Epoch 4916, Loss: 6.183587174746208e-06, Final Batch Loss: 3.716560286193271e-06\n",
      "Epoch 4917, Loss: 1.0230893167317845e-05, Final Batch Loss: 7.2094389906851575e-06\n",
      "Epoch 4918, Loss: 2.232047245342983e-05, Final Batch Loss: 1.2700218576355837e-05\n",
      "Epoch 4919, Loss: 0.00033769742913136724, Final Batch Loss: 2.4631535779917613e-06\n",
      "Epoch 4920, Loss: 0.0006907970637257677, Final Batch Loss: 0.0006391274509951472\n",
      "Epoch 4921, Loss: 1.4441419352806406e-05, Final Batch Loss: 1.0228247447230387e-05\n",
      "Epoch 4922, Loss: 5.604692614724627e-05, Final Batch Loss: 5.193313700146973e-05\n",
      "Epoch 4923, Loss: 1.6323472209478496e-05, Final Batch Loss: 4.094830273970729e-06\n",
      "Epoch 4924, Loss: 8.158857076523418e-05, Final Batch Loss: 7.860510959289968e-05\n",
      "Epoch 4925, Loss: 5.594930257757369e-06, Final Batch Loss: 5.242176257524989e-07\n",
      "Epoch 4926, Loss: 0.001657148331105418, Final Batch Loss: 0.0016434566350653768\n",
      "Epoch 4927, Loss: 9.143855550064472e-06, Final Batch Loss: 4.452971552382223e-06\n",
      "Epoch 4928, Loss: 5.520770628208993e-06, Final Batch Loss: 2.3810850962036056e-06\n",
      "Epoch 4929, Loss: 1.1378025192243513e-05, Final Batch Loss: 5.388941190176411e-06\n",
      "Epoch 4930, Loss: 3.3991841519309673e-05, Final Batch Loss: 2.2814308977103792e-05\n",
      "Epoch 4931, Loss: 0.0001312666215653735, Final Batch Loss: 1.9554215668904362e-06\n",
      "Epoch 4932, Loss: 1.3175485946703702e-05, Final Batch Loss: 5.870126187801361e-06\n",
      "Epoch 4933, Loss: 2.1743147499364568e-05, Final Batch Loss: 6.457422841776861e-06\n",
      "Epoch 4934, Loss: 4.2880330056505045e-05, Final Batch Loss: 3.667721466626972e-05\n",
      "Epoch 4935, Loss: 6.636385387537302e-05, Final Batch Loss: 4.79340542369755e-06\n",
      "Epoch 4936, Loss: 4.901324814454711e-06, Final Batch Loss: 1.6718339566068607e-06\n",
      "Epoch 4937, Loss: 0.00028929932523169555, Final Batch Loss: 0.00027263755328021944\n",
      "Epoch 4938, Loss: 9.638329686367797e-06, Final Batch Loss: 8.721850122128672e-07\n",
      "Epoch 4939, Loss: 0.0002330440283913049, Final Batch Loss: 9.996404514822643e-06\n",
      "Epoch 4940, Loss: 1.4673519672214752e-05, Final Batch Loss: 3.103653853031574e-06\n",
      "Epoch 4941, Loss: 1.8850867490982637e-05, Final Batch Loss: 1.618202259123791e-05\n",
      "Epoch 4942, Loss: 3.4609420140441216e-05, Final Batch Loss: 3.353752981638536e-05\n",
      "Epoch 4943, Loss: 2.194300338942412e-05, Final Batch Loss: 1.3423535847323365e-06\n",
      "Epoch 4944, Loss: 6.536668024637038e-06, Final Batch Loss: 5.7928177739086095e-06\n",
      "Epoch 4945, Loss: 1.4217702300811652e-05, Final Batch Loss: 1.0460355042596348e-05\n",
      "Epoch 4946, Loss: 8.829466787574347e-05, Final Batch Loss: 7.707472832407802e-05\n",
      "Epoch 4947, Loss: 3.704752930389077e-05, Final Batch Loss: 2.0213451534800697e-07\n",
      "Epoch 4948, Loss: 0.00019159918883815408, Final Batch Loss: 6.676460907328874e-05\n",
      "Epoch 4949, Loss: 3.76492698705988e-05, Final Batch Loss: 1.421315573679749e-05\n",
      "Epoch 4950, Loss: 0.00019819254794128938, Final Batch Loss: 0.00018869982159230858\n",
      "Epoch 4951, Loss: 8.736161862543668e-05, Final Batch Loss: 5.253222752799047e-06\n",
      "Epoch 4952, Loss: 5.426038296718616e-05, Final Batch Loss: 4.886561509920284e-05\n",
      "Epoch 4953, Loss: 0.00017908290328705334, Final Batch Loss: 4.5796828089805786e-06\n",
      "Epoch 4954, Loss: 2.325886043763603e-06, Final Batch Loss: 9.055186183104524e-07\n",
      "Epoch 4955, Loss: 0.00028765601018676534, Final Batch Loss: 0.00017259047308471054\n",
      "Epoch 4956, Loss: 0.0018262974299432244, Final Batch Loss: 0.0018049785867333412\n",
      "Epoch 4957, Loss: 6.554520791723917e-05, Final Batch Loss: 2.1130383629497373e-06\n",
      "Epoch 4958, Loss: 9.590657816715975e-05, Final Batch Loss: 5.649397962770308e-07\n",
      "Epoch 4959, Loss: 2.76087314432516e-06, Final Batch Loss: 7.463294195986236e-07\n",
      "Epoch 4960, Loss: 0.00019857870779560471, Final Batch Loss: 1.0158094028156484e-06\n",
      "Epoch 4961, Loss: 3.1482695703743957e-06, Final Batch Loss: 1.2253535714989994e-06\n",
      "Epoch 4962, Loss: 5.012916699342895e-05, Final Batch Loss: 2.1407664462458342e-05\n",
      "Epoch 4963, Loss: 1.1567297747205885e-05, Final Batch Loss: 1.7347132370559848e-06\n",
      "Epoch 4964, Loss: 0.0011154515077578253, Final Batch Loss: 5.060980583948549e-06\n",
      "Epoch 4965, Loss: 3.8142538869578857e-06, Final Batch Loss: 1.2453592717065476e-06\n",
      "Epoch 4966, Loss: 0.000850008660563617, Final Batch Loss: 0.0008264624630101025\n",
      "Epoch 4967, Loss: 5.274822001410939e-06, Final Batch Loss: 3.671512558867107e-06\n",
      "Epoch 4968, Loss: 2.9348466910050774e-06, Final Batch Loss: 7.426438628499454e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4969, Loss: 1.5458991470040928e-05, Final Batch Loss: 7.019178838163498e-07\n",
      "Epoch 4970, Loss: 6.389041288912267e-06, Final Batch Loss: 3.3467193816250074e-07\n",
      "Epoch 4971, Loss: 8.330279683832487e-06, Final Batch Loss: 8.418577408519923e-07\n",
      "Epoch 4972, Loss: 1.1356714821886271e-05, Final Batch Loss: 5.1167799028917216e-06\n",
      "Epoch 4973, Loss: 1.201825881480545e-05, Final Batch Loss: 1.1760291272366885e-05\n",
      "Epoch 4974, Loss: 0.00021741634213867655, Final Batch Loss: 0.0002157518465537578\n",
      "Epoch 4975, Loss: 5.951610091869952e-06, Final Batch Loss: 3.789012453125906e-06\n",
      "Epoch 4976, Loss: 0.003265443039708771, Final Batch Loss: 0.003240765305235982\n",
      "Epoch 4977, Loss: 6.594523341618697e-06, Final Batch Loss: 3.1023463975543564e-07\n",
      "Epoch 4978, Loss: 4.762222118870341e-06, Final Batch Loss: 3.9834603171584604e-07\n",
      "Epoch 4979, Loss: 4.272451974429714e-06, Final Batch Loss: 2.7814826353278477e-06\n",
      "Epoch 4980, Loss: 0.00745954077137867, Final Batch Loss: 6.781345291528851e-06\n",
      "Epoch 4981, Loss: 0.00042195877904305235, Final Batch Loss: 0.0003105339710600674\n",
      "Epoch 4982, Loss: 3.505905056044867e-06, Final Batch Loss: 9.751244078870513e-07\n",
      "Epoch 4983, Loss: 1.8226851409508527e-05, Final Batch Loss: 1.7671829482424073e-05\n",
      "Epoch 4984, Loss: 1.111485175897542e-05, Final Batch Loss: 9.346355909656268e-06\n",
      "Epoch 4985, Loss: 1.1514070592966164e-05, Final Batch Loss: 6.16131410424714e-06\n",
      "Epoch 4986, Loss: 4.1563012928236276e-05, Final Batch Loss: 1.8586384612717666e-05\n",
      "Epoch 4987, Loss: 2.2297742248156283e-06, Final Batch Loss: 8.96634048785927e-07\n",
      "Epoch 4988, Loss: 0.00012524324120022357, Final Batch Loss: 8.642363536637276e-05\n",
      "Epoch 4989, Loss: 4.9256984084422584e-05, Final Batch Loss: 1.069113523044507e-06\n",
      "Epoch 4990, Loss: 1.5009439948698855e-05, Final Batch Loss: 1.8879443359764991e-06\n",
      "Epoch 4991, Loss: 6.157888492452912e-05, Final Batch Loss: 3.513353658490814e-05\n",
      "Epoch 4992, Loss: 4.167841279922868e-05, Final Batch Loss: 4.7772296056791674e-06\n",
      "Epoch 4993, Loss: 8.307569032695028e-06, Final Batch Loss: 3.2331965940102236e-06\n",
      "Epoch 4994, Loss: 5.326398058969062e-05, Final Batch Loss: 2.7214873625780456e-05\n",
      "Epoch 4995, Loss: 7.246331279020524e-06, Final Batch Loss: 6.626928552577738e-06\n",
      "Epoch 4996, Loss: 8.595592362325988e-06, Final Batch Loss: 5.800371582154185e-06\n",
      "Epoch 4997, Loss: 1.737629704123833e-05, Final Batch Loss: 5.7753499760337945e-08\n",
      "Epoch 4998, Loss: 2.6939295025840693e-06, Final Batch Loss: 3.6576972206603386e-07\n",
      "Epoch 4999, Loss: 2.638203059746047e-05, Final Batch Loss: 2.2953045686335827e-07\n",
      "Epoch 5000, Loss: 0.00033551917113072705, Final Batch Loss: 0.00033114629331976175\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0  0]\n",
      " [ 0 22  0]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        21\n",
      "           1      1.000     1.000     1.000        22\n",
      "           2      1.000     1.000     1.000        30\n",
      "\n",
      "    accuracy                          1.000        73\n",
      "   macro avg      1.000     1.000     1.000        73\n",
      "weighted avg      1.000     1.000     1.000        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../saved_models/UCI 3 Label Classifier Group 3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
