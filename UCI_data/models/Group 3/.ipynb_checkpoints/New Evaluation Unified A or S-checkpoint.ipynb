{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.228675961494446, Final Batch Loss: 1.1141164302825928\n",
      "Epoch 2, Loss: 2.2191648483276367, Final Batch Loss: 1.1008628606796265\n",
      "Epoch 3, Loss: 2.2173930406570435, Final Batch Loss: 1.1030791997909546\n",
      "Epoch 4, Loss: 2.2127872705459595, Final Batch Loss: 1.1099773645401\n",
      "Epoch 5, Loss: 2.2014949321746826, Final Batch Loss: 1.0978608131408691\n",
      "Epoch 6, Loss: 2.1921404600143433, Final Batch Loss: 1.0932320356369019\n",
      "Epoch 7, Loss: 2.184659719467163, Final Batch Loss: 1.090456247329712\n",
      "Epoch 8, Loss: 2.177707552909851, Final Batch Loss: 1.0895155668258667\n",
      "Epoch 9, Loss: 2.1618374586105347, Final Batch Loss: 1.0804816484451294\n",
      "Epoch 10, Loss: 2.157435655593872, Final Batch Loss: 1.08070969581604\n",
      "Epoch 11, Loss: 2.1411495208740234, Final Batch Loss: 1.076888084411621\n",
      "Epoch 12, Loss: 2.12445604801178, Final Batch Loss: 1.0673270225524902\n",
      "Epoch 13, Loss: 2.099590301513672, Final Batch Loss: 1.0431901216506958\n",
      "Epoch 14, Loss: 2.091481328010559, Final Batch Loss: 1.0360907316207886\n",
      "Epoch 15, Loss: 2.061334490776062, Final Batch Loss: 1.030684232711792\n",
      "Epoch 16, Loss: 2.042112708091736, Final Batch Loss: 1.0011858940124512\n",
      "Epoch 17, Loss: 2.012495994567871, Final Batch Loss: 1.0109742879867554\n",
      "Epoch 18, Loss: 1.9889285564422607, Final Batch Loss: 0.9964942932128906\n",
      "Epoch 19, Loss: 1.9436076283454895, Final Batch Loss: 0.9571292400360107\n",
      "Epoch 20, Loss: 1.9328057765960693, Final Batch Loss: 0.9660905003547668\n",
      "Epoch 21, Loss: 1.8929093480110168, Final Batch Loss: 0.9400087594985962\n",
      "Epoch 22, Loss: 1.8634312748908997, Final Batch Loss: 0.934651255607605\n",
      "Epoch 23, Loss: 1.8164073824882507, Final Batch Loss: 0.8998911380767822\n",
      "Epoch 24, Loss: 1.7975335717201233, Final Batch Loss: 0.9154769778251648\n",
      "Epoch 25, Loss: 1.7606130242347717, Final Batch Loss: 0.8852441310882568\n",
      "Epoch 26, Loss: 1.732709527015686, Final Batch Loss: 0.8941490650177002\n",
      "Epoch 27, Loss: 1.6725444793701172, Final Batch Loss: 0.8373342156410217\n",
      "Epoch 28, Loss: 1.6280556917190552, Final Batch Loss: 0.7852696776390076\n",
      "Epoch 29, Loss: 1.6148015856742859, Final Batch Loss: 0.8076204657554626\n",
      "Epoch 30, Loss: 1.5636250972747803, Final Batch Loss: 0.765783429145813\n",
      "Epoch 31, Loss: 1.5693727135658264, Final Batch Loss: 0.7737323641777039\n",
      "Epoch 32, Loss: 1.5293456315994263, Final Batch Loss: 0.7432319521903992\n",
      "Epoch 33, Loss: 1.5484357476234436, Final Batch Loss: 0.830470860004425\n",
      "Epoch 34, Loss: 1.5202870965003967, Final Batch Loss: 0.7952129244804382\n",
      "Epoch 35, Loss: 1.4880142211914062, Final Batch Loss: 0.7405615448951721\n",
      "Epoch 36, Loss: 1.4673060178756714, Final Batch Loss: 0.7141158580780029\n",
      "Epoch 37, Loss: 1.4769547581672668, Final Batch Loss: 0.7655968070030212\n",
      "Epoch 38, Loss: 1.4487951397895813, Final Batch Loss: 0.7256523966789246\n",
      "Epoch 39, Loss: 1.444750189781189, Final Batch Loss: 0.7315027713775635\n",
      "Epoch 40, Loss: 1.403368890285492, Final Batch Loss: 0.6671833992004395\n",
      "Epoch 41, Loss: 1.3965113759040833, Final Batch Loss: 0.6838972568511963\n",
      "Epoch 42, Loss: 1.3819341659545898, Final Batch Loss: 0.662059485912323\n",
      "Epoch 43, Loss: 1.391460359096527, Final Batch Loss: 0.6945993900299072\n",
      "Epoch 44, Loss: 1.3713369965553284, Final Batch Loss: 0.6743426322937012\n",
      "Epoch 45, Loss: 1.369639813899994, Final Batch Loss: 0.6828060746192932\n",
      "Epoch 46, Loss: 1.334863543510437, Final Batch Loss: 0.6505705714225769\n",
      "Epoch 47, Loss: 1.351676344871521, Final Batch Loss: 0.7054339647293091\n",
      "Epoch 48, Loss: 1.338440179824829, Final Batch Loss: 0.6912223100662231\n",
      "Epoch 49, Loss: 1.323606550693512, Final Batch Loss: 0.6688942909240723\n",
      "Epoch 50, Loss: 1.2894397377967834, Final Batch Loss: 0.621295154094696\n",
      "Epoch 51, Loss: 1.3122597336769104, Final Batch Loss: 0.65113765001297\n",
      "Epoch 52, Loss: 1.2635985016822815, Final Batch Loss: 0.6150290369987488\n",
      "Epoch 53, Loss: 1.2542536854743958, Final Batch Loss: 0.602292001247406\n",
      "Epoch 54, Loss: 1.2787730693817139, Final Batch Loss: 0.6768099069595337\n",
      "Epoch 55, Loss: 1.2581667304039001, Final Batch Loss: 0.6461432576179504\n",
      "Epoch 56, Loss: 1.2548378109931946, Final Batch Loss: 0.6342217326164246\n",
      "Epoch 57, Loss: 1.2100016474723816, Final Batch Loss: 0.5875204205513\n",
      "Epoch 58, Loss: 1.1973700523376465, Final Batch Loss: 0.5841866731643677\n",
      "Epoch 59, Loss: 1.2213809490203857, Final Batch Loss: 0.6734626293182373\n",
      "Epoch 60, Loss: 1.1816698908805847, Final Batch Loss: 0.5853778123855591\n",
      "Epoch 61, Loss: 1.1718515157699585, Final Batch Loss: 0.5799931287765503\n",
      "Epoch 62, Loss: 1.1446645259857178, Final Batch Loss: 0.5589633584022522\n",
      "Epoch 63, Loss: 1.1335938572883606, Final Batch Loss: 0.548847496509552\n",
      "Epoch 64, Loss: 1.1283127069473267, Final Batch Loss: 0.559877872467041\n",
      "Epoch 65, Loss: 1.1134063005447388, Final Batch Loss: 0.5662775039672852\n",
      "Epoch 66, Loss: 1.084758698940277, Final Batch Loss: 0.5136592388153076\n",
      "Epoch 67, Loss: 1.085530400276184, Final Batch Loss: 0.5443229079246521\n",
      "Epoch 68, Loss: 1.073823630809784, Final Batch Loss: 0.5042481422424316\n",
      "Epoch 69, Loss: 1.0651301741600037, Final Batch Loss: 0.5337885022163391\n",
      "Epoch 70, Loss: 1.0580434799194336, Final Batch Loss: 0.5038564205169678\n",
      "Epoch 71, Loss: 1.0440035462379456, Final Batch Loss: 0.5251938104629517\n",
      "Epoch 72, Loss: 1.0269308686256409, Final Batch Loss: 0.5114069581031799\n",
      "Epoch 73, Loss: 1.0488154888153076, Final Batch Loss: 0.5415935516357422\n",
      "Epoch 74, Loss: 0.995370477437973, Final Batch Loss: 0.45125719904899597\n",
      "Epoch 75, Loss: 0.9896819293498993, Final Batch Loss: 0.4700700342655182\n",
      "Epoch 76, Loss: 1.0215534567832947, Final Batch Loss: 0.5023002028465271\n",
      "Epoch 77, Loss: 1.0270172655582428, Final Batch Loss: 0.5355146527290344\n",
      "Epoch 78, Loss: 1.0055406987667084, Final Batch Loss: 0.5067003965377808\n",
      "Epoch 79, Loss: 1.001402884721756, Final Batch Loss: 0.5065803527832031\n",
      "Epoch 80, Loss: 0.9581823348999023, Final Batch Loss: 0.44796788692474365\n",
      "Epoch 81, Loss: 0.9764847457408905, Final Batch Loss: 0.4973500669002533\n",
      "Epoch 82, Loss: 0.9752752184867859, Final Batch Loss: 0.48720601201057434\n",
      "Epoch 83, Loss: 0.9608760476112366, Final Batch Loss: 0.4983222484588623\n",
      "Epoch 84, Loss: 0.9617281556129456, Final Batch Loss: 0.5024299621582031\n",
      "Epoch 85, Loss: 0.9641600847244263, Final Batch Loss: 0.49138709902763367\n",
      "Epoch 86, Loss: 0.9551734626293182, Final Batch Loss: 0.49888959527015686\n",
      "Epoch 87, Loss: 0.9051792025566101, Final Batch Loss: 0.4318397641181946\n",
      "Epoch 88, Loss: 0.9138690233230591, Final Batch Loss: 0.4518110752105713\n",
      "Epoch 89, Loss: 0.8982266187667847, Final Batch Loss: 0.456819087266922\n",
      "Epoch 90, Loss: 0.8985167443752289, Final Batch Loss: 0.47043946385383606\n",
      "Epoch 91, Loss: 0.8759896457195282, Final Batch Loss: 0.4574560523033142\n",
      "Epoch 92, Loss: 0.8717390298843384, Final Batch Loss: 0.4354550540447235\n",
      "Epoch 93, Loss: 0.8568404316902161, Final Batch Loss: 0.41987380385398865\n",
      "Epoch 94, Loss: 0.8211726248264313, Final Batch Loss: 0.4045765697956085\n",
      "Epoch 95, Loss: 0.8517519235610962, Final Batch Loss: 0.42970606684684753\n",
      "Epoch 96, Loss: 0.8153616487979889, Final Batch Loss: 0.39367803931236267\n",
      "Epoch 97, Loss: 0.7765132784843445, Final Batch Loss: 0.36468765139579773\n",
      "Epoch 98, Loss: 0.7928720712661743, Final Batch Loss: 0.4195684492588043\n",
      "Epoch 99, Loss: 0.7471269071102142, Final Batch Loss: 0.3955223560333252\n",
      "Epoch 100, Loss: 0.7101808488368988, Final Batch Loss: 0.3473525643348694\n",
      "Epoch 101, Loss: 0.6840881109237671, Final Batch Loss: 0.36191117763519287\n",
      "Epoch 102, Loss: 0.6363649070262909, Final Batch Loss: 0.2920917868614197\n",
      "Epoch 103, Loss: 0.6527969837188721, Final Batch Loss: 0.3274596035480499\n",
      "Epoch 104, Loss: 0.6128886640071869, Final Batch Loss: 0.2817370593547821\n",
      "Epoch 105, Loss: 0.5895837247371674, Final Batch Loss: 0.3054358959197998\n",
      "Epoch 106, Loss: 0.6229846775531769, Final Batch Loss: 0.368425577878952\n",
      "Epoch 107, Loss: 0.5155488550662994, Final Batch Loss: 0.20044872164726257\n",
      "Epoch 108, Loss: 0.4988187998533249, Final Batch Loss: 0.252429336309433\n",
      "Epoch 109, Loss: 0.41840267181396484, Final Batch Loss: 0.1967376470565796\n",
      "Epoch 110, Loss: 0.4546833485364914, Final Batch Loss: 0.22828520834445953\n",
      "Epoch 111, Loss: 0.4940293878316879, Final Batch Loss: 0.2737545967102051\n",
      "Epoch 112, Loss: 0.4360797256231308, Final Batch Loss: 0.2069052904844284\n",
      "Epoch 113, Loss: 0.37224946916103363, Final Batch Loss: 0.1804746836423874\n",
      "Epoch 114, Loss: 0.40449416637420654, Final Batch Loss: 0.19464997947216034\n",
      "Epoch 115, Loss: 0.39921650290489197, Final Batch Loss: 0.16384291648864746\n",
      "Epoch 116, Loss: 0.41409458220005035, Final Batch Loss: 0.19665522873401642\n",
      "Epoch 117, Loss: 0.35641127824783325, Final Batch Loss: 0.1734960526227951\n",
      "Epoch 118, Loss: 0.36669139564037323, Final Batch Loss: 0.18790218234062195\n",
      "Epoch 119, Loss: 0.40292564034461975, Final Batch Loss: 0.19678285717964172\n",
      "Epoch 120, Loss: 0.3145572990179062, Final Batch Loss: 0.1667812019586563\n",
      "Epoch 121, Loss: 0.4110749363899231, Final Batch Loss: 0.2580662667751312\n",
      "Epoch 122, Loss: 0.3232342302799225, Final Batch Loss: 0.1842038482427597\n",
      "Epoch 123, Loss: 0.2626633048057556, Final Batch Loss: 0.12676385045051575\n",
      "Epoch 124, Loss: 0.3545438349246979, Final Batch Loss: 0.2312447726726532\n",
      "Epoch 125, Loss: 0.3239370584487915, Final Batch Loss: 0.1324443370103836\n",
      "Epoch 126, Loss: 0.340935543179512, Final Batch Loss: 0.16212794184684753\n",
      "Epoch 127, Loss: 0.4179934412240982, Final Batch Loss: 0.19530701637268066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128, Loss: 0.2708587795495987, Final Batch Loss: 0.12963247299194336\n",
      "Epoch 129, Loss: 0.2866133004426956, Final Batch Loss: 0.15572963654994965\n",
      "Epoch 130, Loss: 0.30962296575307846, Final Batch Loss: 0.18744221329689026\n",
      "Epoch 131, Loss: 0.27170710265636444, Final Batch Loss: 0.1333816796541214\n",
      "Epoch 132, Loss: 0.3122946172952652, Final Batch Loss: 0.19781877100467682\n",
      "Epoch 133, Loss: 0.3031744509935379, Final Batch Loss: 0.14029255509376526\n",
      "Epoch 134, Loss: 0.2814003527164459, Final Batch Loss: 0.17457135021686554\n",
      "Epoch 135, Loss: 0.25639282166957855, Final Batch Loss: 0.1037425845861435\n",
      "Epoch 136, Loss: 0.36778198182582855, Final Batch Loss: 0.18866081535816193\n",
      "Epoch 137, Loss: 0.27683059871196747, Final Batch Loss: 0.13120190799236298\n",
      "Epoch 138, Loss: 0.2439255192875862, Final Batch Loss: 0.1154588982462883\n",
      "Epoch 139, Loss: 0.26190905272960663, Final Batch Loss: 0.10989491641521454\n",
      "Epoch 140, Loss: 0.24961789697408676, Final Batch Loss: 0.11799075454473495\n",
      "Epoch 141, Loss: 0.2485203519463539, Final Batch Loss: 0.1158861592411995\n",
      "Epoch 142, Loss: 0.22167732566595078, Final Batch Loss: 0.10039326548576355\n",
      "Epoch 143, Loss: 0.2632821351289749, Final Batch Loss: 0.1679706573486328\n",
      "Epoch 144, Loss: 0.27196428179740906, Final Batch Loss: 0.12505874037742615\n",
      "Epoch 145, Loss: 0.24222828447818756, Final Batch Loss: 0.10784865915775299\n",
      "Epoch 146, Loss: 0.2739340513944626, Final Batch Loss: 0.1655602604150772\n",
      "Epoch 147, Loss: 0.3138592690229416, Final Batch Loss: 0.21772558987140656\n",
      "Epoch 148, Loss: 0.3135896623134613, Final Batch Loss: 0.18213306367397308\n",
      "Epoch 149, Loss: 0.249505415558815, Final Batch Loss: 0.14075569808483124\n",
      "Epoch 150, Loss: 0.21977558732032776, Final Batch Loss: 0.08659249544143677\n",
      "Epoch 151, Loss: 0.23522274941205978, Final Batch Loss: 0.13059251010417938\n",
      "Epoch 152, Loss: 0.2511398494243622, Final Batch Loss: 0.10205128788948059\n",
      "Epoch 153, Loss: 0.29977457225322723, Final Batch Loss: 0.19000455737113953\n",
      "Epoch 154, Loss: 0.20909586548805237, Final Batch Loss: 0.09865106642246246\n",
      "Epoch 155, Loss: 0.19458585232496262, Final Batch Loss: 0.08718302100896835\n",
      "Epoch 156, Loss: 0.23598844558000565, Final Batch Loss: 0.10880754142999649\n",
      "Epoch 157, Loss: 0.2888169437646866, Final Batch Loss: 0.1880781352519989\n",
      "Epoch 158, Loss: 0.17934876680374146, Final Batch Loss: 0.07079644501209259\n",
      "Epoch 159, Loss: 0.1853724718093872, Final Batch Loss: 0.0990346297621727\n",
      "Epoch 160, Loss: 0.21236956119537354, Final Batch Loss: 0.09357407689094543\n",
      "Epoch 161, Loss: 0.20244337618350983, Final Batch Loss: 0.10712224245071411\n",
      "Epoch 162, Loss: 0.18338535726070404, Final Batch Loss: 0.07210720330476761\n",
      "Epoch 163, Loss: 0.17269153147935867, Final Batch Loss: 0.06715409457683563\n",
      "Epoch 164, Loss: 0.19819147884845734, Final Batch Loss: 0.10758232325315475\n",
      "Epoch 165, Loss: 0.23928246647119522, Final Batch Loss: 0.13799145817756653\n",
      "Epoch 166, Loss: 0.17285028100013733, Final Batch Loss: 0.09078540652990341\n",
      "Epoch 167, Loss: 0.1832408830523491, Final Batch Loss: 0.10169496387243271\n",
      "Epoch 168, Loss: 0.2212832123041153, Final Batch Loss: 0.12027128040790558\n",
      "Epoch 169, Loss: 0.1681734099984169, Final Batch Loss: 0.08408123254776001\n",
      "Epoch 170, Loss: 0.19459225237369537, Final Batch Loss: 0.11800657957792282\n",
      "Epoch 171, Loss: 0.1928640455007553, Final Batch Loss: 0.10640908032655716\n",
      "Epoch 172, Loss: 0.17721617221832275, Final Batch Loss: 0.07896102964878082\n",
      "Epoch 173, Loss: 0.1989520564675331, Final Batch Loss: 0.1358773559331894\n",
      "Epoch 174, Loss: 0.21490253508090973, Final Batch Loss: 0.09114719927310944\n",
      "Epoch 175, Loss: 0.14478466287255287, Final Batch Loss: 0.05726812407374382\n",
      "Epoch 176, Loss: 0.20477477461099625, Final Batch Loss: 0.08154895156621933\n",
      "Epoch 177, Loss: 0.20558587461709976, Final Batch Loss: 0.10035528242588043\n",
      "Epoch 178, Loss: 0.16313625127077103, Final Batch Loss: 0.06455542147159576\n",
      "Epoch 179, Loss: 0.21354255080223083, Final Batch Loss: 0.1342332810163498\n",
      "Epoch 180, Loss: 0.19388846307992935, Final Batch Loss: 0.10619176179170609\n",
      "Epoch 181, Loss: 0.1732718124985695, Final Batch Loss: 0.09565087407827377\n",
      "Epoch 182, Loss: 0.22976772487163544, Final Batch Loss: 0.14635661244392395\n",
      "Epoch 183, Loss: 0.1975894346833229, Final Batch Loss: 0.09387746453285217\n",
      "Epoch 184, Loss: 0.1734663024544716, Final Batch Loss: 0.08324246853590012\n",
      "Epoch 185, Loss: 0.1789233535528183, Final Batch Loss: 0.07989943772554398\n",
      "Epoch 186, Loss: 0.22523145377635956, Final Batch Loss: 0.14579486846923828\n",
      "Epoch 187, Loss: 0.18876133114099503, Final Batch Loss: 0.09302251785993576\n",
      "Epoch 188, Loss: 0.19379738718271255, Final Batch Loss: 0.11864462494850159\n",
      "Epoch 189, Loss: 0.20088301599025726, Final Batch Loss: 0.12768077850341797\n",
      "Epoch 190, Loss: 0.15173181891441345, Final Batch Loss: 0.06626377999782562\n",
      "Epoch 191, Loss: 0.20147879421710968, Final Batch Loss: 0.13476869463920593\n",
      "Epoch 192, Loss: 0.14351478591561317, Final Batch Loss: 0.04829482361674309\n",
      "Epoch 193, Loss: 0.19244344532489777, Final Batch Loss: 0.0619269460439682\n",
      "Epoch 194, Loss: 0.15796950459480286, Final Batch Loss: 0.06823574006557465\n",
      "Epoch 195, Loss: 0.15067486837506294, Final Batch Loss: 0.09544455260038376\n",
      "Epoch 196, Loss: 0.1778760477900505, Final Batch Loss: 0.125255286693573\n",
      "Epoch 197, Loss: 0.22597848623991013, Final Batch Loss: 0.10938532650470734\n",
      "Epoch 198, Loss: 0.12379441410303116, Final Batch Loss: 0.04227717965841293\n",
      "Epoch 199, Loss: 0.17972487956285477, Final Batch Loss: 0.1016106903553009\n",
      "Epoch 200, Loss: 0.15717913955450058, Final Batch Loss: 0.062754325568676\n",
      "Epoch 201, Loss: 0.1448022872209549, Final Batch Loss: 0.08038488030433655\n",
      "Epoch 202, Loss: 0.11063838005065918, Final Batch Loss: 0.04727279394865036\n",
      "Epoch 203, Loss: 0.1863228976726532, Final Batch Loss: 0.10014645010232925\n",
      "Epoch 204, Loss: 0.2866433709859848, Final Batch Loss: 0.13195611536502838\n",
      "Epoch 205, Loss: 0.16082217544317245, Final Batch Loss: 0.047732867300510406\n",
      "Epoch 206, Loss: 0.1645245999097824, Final Batch Loss: 0.07897929102182388\n",
      "Epoch 207, Loss: 0.1537952795624733, Final Batch Loss: 0.07369132339954376\n",
      "Epoch 208, Loss: 0.17987851053476334, Final Batch Loss: 0.10215362906455994\n",
      "Epoch 209, Loss: 0.20030809193849564, Final Batch Loss: 0.14858345687389374\n",
      "Epoch 210, Loss: 0.14193303138017654, Final Batch Loss: 0.06301842629909515\n",
      "Epoch 211, Loss: 0.14684268087148666, Final Batch Loss: 0.06644386798143387\n",
      "Epoch 212, Loss: 0.1430964507162571, Final Batch Loss: 0.08274369686841965\n",
      "Epoch 213, Loss: 0.12450936809182167, Final Batch Loss: 0.03104664757847786\n",
      "Epoch 214, Loss: 0.20615315437316895, Final Batch Loss: 0.12154129892587662\n",
      "Epoch 215, Loss: 0.1428099349141121, Final Batch Loss: 0.07276741415262222\n",
      "Epoch 216, Loss: 0.11774773523211479, Final Batch Loss: 0.05179985240101814\n",
      "Epoch 217, Loss: 0.1670479029417038, Final Batch Loss: 0.04814276844263077\n",
      "Epoch 218, Loss: 0.15638026595115662, Final Batch Loss: 0.0799252912402153\n",
      "Epoch 219, Loss: 0.18793591856956482, Final Batch Loss: 0.1209726557135582\n",
      "Epoch 220, Loss: 0.15395983308553696, Final Batch Loss: 0.07632576674222946\n",
      "Epoch 221, Loss: 0.14684892445802689, Final Batch Loss: 0.06019023805856705\n",
      "Epoch 222, Loss: 0.16424402594566345, Final Batch Loss: 0.08540643751621246\n",
      "Epoch 223, Loss: 0.11588256061077118, Final Batch Loss: 0.05405573546886444\n",
      "Epoch 224, Loss: 0.15757836028933525, Final Batch Loss: 0.10358914732933044\n",
      "Epoch 225, Loss: 0.1664874292910099, Final Batch Loss: 0.11984870582818985\n",
      "Epoch 226, Loss: 0.13382355496287346, Final Batch Loss: 0.04192086681723595\n",
      "Epoch 227, Loss: 0.12983879819512367, Final Batch Loss: 0.06854240596294403\n",
      "Epoch 228, Loss: 0.1666676551103592, Final Batch Loss: 0.08263815939426422\n",
      "Epoch 229, Loss: 0.16700923442840576, Final Batch Loss: 0.06889096647500992\n",
      "Epoch 230, Loss: 0.13200299069285393, Final Batch Loss: 0.0828632339835167\n",
      "Epoch 231, Loss: 0.14980558305978775, Final Batch Loss: 0.07066922634840012\n",
      "Epoch 232, Loss: 0.1671202890574932, Final Batch Loss: 0.04387920722365379\n",
      "Epoch 233, Loss: 0.1121218204498291, Final Batch Loss: 0.041074156761169434\n",
      "Epoch 234, Loss: 0.14106008782982826, Final Batch Loss: 0.0816587284207344\n",
      "Epoch 235, Loss: 0.1468263566493988, Final Batch Loss: 0.09209737181663513\n",
      "Epoch 236, Loss: 0.13032368570566177, Final Batch Loss: 0.05576249212026596\n",
      "Epoch 237, Loss: 0.09709366783499718, Final Batch Loss: 0.0429682619869709\n",
      "Epoch 238, Loss: 0.10827096924185753, Final Batch Loss: 0.06615190953016281\n",
      "Epoch 239, Loss: 0.16628599911928177, Final Batch Loss: 0.09875305742025375\n",
      "Epoch 240, Loss: 0.13560742139816284, Final Batch Loss: 0.06751499325037003\n",
      "Epoch 241, Loss: 0.17260557413101196, Final Batch Loss: 0.05661267787218094\n",
      "Epoch 242, Loss: 0.20388483256101608, Final Batch Loss: 0.12143257260322571\n",
      "Epoch 243, Loss: 0.1093575619161129, Final Batch Loss: 0.03983689472079277\n",
      "Epoch 244, Loss: 0.13396675512194633, Final Batch Loss: 0.07528939098119736\n",
      "Epoch 245, Loss: 0.10567710176110268, Final Batch Loss: 0.0538153275847435\n",
      "Epoch 246, Loss: 0.11771182715892792, Final Batch Loss: 0.05813009664416313\n",
      "Epoch 247, Loss: 0.12986119464039803, Final Batch Loss: 0.03904074802994728\n",
      "Epoch 248, Loss: 0.14813563227653503, Final Batch Loss: 0.08113086968660355\n",
      "Epoch 249, Loss: 0.09122077375650406, Final Batch Loss: 0.037779614329338074\n",
      "Epoch 250, Loss: 0.13376560434699059, Final Batch Loss: 0.0784207135438919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251, Loss: 0.12114151194691658, Final Batch Loss: 0.06358268857002258\n",
      "Epoch 252, Loss: 0.15010624378919601, Final Batch Loss: 0.08002454042434692\n",
      "Epoch 253, Loss: 0.1315280869603157, Final Batch Loss: 0.05359216779470444\n",
      "Epoch 254, Loss: 0.136518944054842, Final Batch Loss: 0.03665565326809883\n",
      "Epoch 255, Loss: 0.09929965063929558, Final Batch Loss: 0.032113779336214066\n",
      "Epoch 256, Loss: 0.16434873640537262, Final Batch Loss: 0.08101874589920044\n",
      "Epoch 257, Loss: 0.13956021144986153, Final Batch Loss: 0.0591064877808094\n",
      "Epoch 258, Loss: 0.12485510483384132, Final Batch Loss: 0.03573274984955788\n",
      "Epoch 259, Loss: 0.16312111914157867, Final Batch Loss: 0.0793127492070198\n",
      "Epoch 260, Loss: 0.08880766667425632, Final Batch Loss: 0.029213322326540947\n",
      "Epoch 261, Loss: 0.13417311757802963, Final Batch Loss: 0.04215363413095474\n",
      "Epoch 262, Loss: 0.10121140256524086, Final Batch Loss: 0.035995807498693466\n",
      "Epoch 263, Loss: 0.18173955380916595, Final Batch Loss: 0.099545918405056\n",
      "Epoch 264, Loss: 0.12231959402561188, Final Batch Loss: 0.021889880299568176\n",
      "Epoch 265, Loss: 0.14421210438013077, Final Batch Loss: 0.0667550265789032\n",
      "Epoch 266, Loss: 0.12775148078799248, Final Batch Loss: 0.0756855309009552\n",
      "Epoch 267, Loss: 0.16217811405658722, Final Batch Loss: 0.09377192705869675\n",
      "Epoch 268, Loss: 0.13162045553326607, Final Batch Loss: 0.04923455789685249\n",
      "Epoch 269, Loss: 0.14191025868058205, Final Batch Loss: 0.0874025896191597\n",
      "Epoch 270, Loss: 0.1422927901148796, Final Batch Loss: 0.11186517030000687\n",
      "Epoch 271, Loss: 0.09381340816617012, Final Batch Loss: 0.0413537472486496\n",
      "Epoch 272, Loss: 0.14342136308550835, Final Batch Loss: 0.05807161703705788\n",
      "Epoch 273, Loss: 0.12479405477643013, Final Batch Loss: 0.06039070710539818\n",
      "Epoch 274, Loss: 0.15004001557826996, Final Batch Loss: 0.08583663403987885\n",
      "Epoch 275, Loss: 0.0819540973752737, Final Batch Loss: 0.01768229715526104\n",
      "Epoch 276, Loss: 0.12729204446077347, Final Batch Loss: 0.05010414868593216\n",
      "Epoch 277, Loss: 0.09445081278681755, Final Batch Loss: 0.04905950278043747\n",
      "Epoch 278, Loss: 0.12331769987940788, Final Batch Loss: 0.04019836708903313\n",
      "Epoch 279, Loss: 0.12091940268874168, Final Batch Loss: 0.07030916959047318\n",
      "Epoch 280, Loss: 0.1628514751791954, Final Batch Loss: 0.09158425778150558\n",
      "Epoch 281, Loss: 0.09198544546961784, Final Batch Loss: 0.04903031513094902\n",
      "Epoch 282, Loss: 0.1432337872684002, Final Batch Loss: 0.08347033709287643\n",
      "Epoch 283, Loss: 0.11909355223178864, Final Batch Loss: 0.07026734203100204\n",
      "Epoch 284, Loss: 0.10189490392804146, Final Batch Loss: 0.04125036299228668\n",
      "Epoch 285, Loss: 0.18557560443878174, Final Batch Loss: 0.1159074455499649\n",
      "Epoch 286, Loss: 0.1371918059885502, Final Batch Loss: 0.06188223883509636\n",
      "Epoch 287, Loss: 0.18994726613163948, Final Batch Loss: 0.12963801622390747\n",
      "Epoch 288, Loss: 0.1109815314412117, Final Batch Loss: 0.07927902042865753\n",
      "Epoch 289, Loss: 0.09319521300494671, Final Batch Loss: 0.02416848950088024\n",
      "Epoch 290, Loss: 0.11126633733510971, Final Batch Loss: 0.06576430052518845\n",
      "Epoch 291, Loss: 0.17075714096426964, Final Batch Loss: 0.11588845402002335\n",
      "Epoch 292, Loss: 0.19590657204389572, Final Batch Loss: 0.12007077783346176\n",
      "Epoch 293, Loss: 0.14128770306706429, Final Batch Loss: 0.06034240499138832\n",
      "Epoch 294, Loss: 0.09138662740588188, Final Batch Loss: 0.04853221774101257\n",
      "Epoch 295, Loss: 0.16819693706929684, Final Batch Loss: 0.14180351793766022\n",
      "Epoch 296, Loss: 0.1287338025867939, Final Batch Loss: 0.0813070610165596\n",
      "Epoch 297, Loss: 0.14146070182323456, Final Batch Loss: 0.05787539482116699\n",
      "Epoch 298, Loss: 0.13914842158555984, Final Batch Loss: 0.07639612257480621\n",
      "Epoch 299, Loss: 0.10272536613047123, Final Batch Loss: 0.07389462739229202\n",
      "Epoch 300, Loss: 0.11243153735995293, Final Batch Loss: 0.041552308946847916\n",
      "Epoch 301, Loss: 0.1662796288728714, Final Batch Loss: 0.0732882097363472\n",
      "Epoch 302, Loss: 0.11259443685412407, Final Batch Loss: 0.07272546738386154\n",
      "Epoch 303, Loss: 0.09951514005661011, Final Batch Loss: 0.04601339250802994\n",
      "Epoch 304, Loss: 0.11197682097554207, Final Batch Loss: 0.060257378965616226\n",
      "Epoch 305, Loss: 0.10095588304102421, Final Batch Loss: 0.029999645426869392\n",
      "Epoch 306, Loss: 0.11230756714940071, Final Batch Loss: 0.07039958983659744\n",
      "Epoch 307, Loss: 0.09760883264243603, Final Batch Loss: 0.02107415907084942\n",
      "Epoch 308, Loss: 0.09801649302244186, Final Batch Loss: 0.036741066724061966\n",
      "Epoch 309, Loss: 0.15518425405025482, Final Batch Loss: 0.11640086770057678\n",
      "Epoch 310, Loss: 0.11716047674417496, Final Batch Loss: 0.07366062700748444\n",
      "Epoch 311, Loss: 0.10601336881518364, Final Batch Loss: 0.03797407075762749\n",
      "Epoch 312, Loss: 0.12594846449792385, Final Batch Loss: 0.09941182285547256\n",
      "Epoch 313, Loss: 0.1347731240093708, Final Batch Loss: 0.09061175584793091\n",
      "Epoch 314, Loss: 0.07064779847860336, Final Batch Loss: 0.022785842418670654\n",
      "Epoch 315, Loss: 0.11270036548376083, Final Batch Loss: 0.054141029715538025\n",
      "Epoch 316, Loss: 0.14216546341776848, Final Batch Loss: 0.08037648350000381\n",
      "Epoch 317, Loss: 0.14101387932896614, Final Batch Loss: 0.08372168987989426\n",
      "Epoch 318, Loss: 0.14154084026813507, Final Batch Loss: 0.07838357239961624\n",
      "Epoch 319, Loss: 0.15821077674627304, Final Batch Loss: 0.11905047297477722\n",
      "Epoch 320, Loss: 0.12289654463529587, Final Batch Loss: 0.06414631754159927\n",
      "Epoch 321, Loss: 0.12331553548574448, Final Batch Loss: 0.04079291224479675\n",
      "Epoch 322, Loss: 0.1776132471859455, Final Batch Loss: 0.14188270270824432\n",
      "Epoch 323, Loss: 0.11900579184293747, Final Batch Loss: 0.03182292729616165\n",
      "Epoch 324, Loss: 0.11418623849749565, Final Batch Loss: 0.03509710356593132\n",
      "Epoch 325, Loss: 0.16370651870965958, Final Batch Loss: 0.06677181273698807\n",
      "Epoch 326, Loss: 0.0976070873439312, Final Batch Loss: 0.0498475655913353\n",
      "Epoch 327, Loss: 0.12925328314304352, Final Batch Loss: 0.05028420686721802\n",
      "Epoch 328, Loss: 0.09978550672531128, Final Batch Loss: 0.05093879625201225\n",
      "Epoch 329, Loss: 0.1543060652911663, Final Batch Loss: 0.09214002639055252\n",
      "Epoch 330, Loss: 0.10702797770500183, Final Batch Loss: 0.05251002684235573\n",
      "Epoch 331, Loss: 0.14054224267601967, Final Batch Loss: 0.0839754119515419\n",
      "Epoch 332, Loss: 0.0858992151916027, Final Batch Loss: 0.04083523899316788\n",
      "Epoch 333, Loss: 0.10936653986573219, Final Batch Loss: 0.04244242236018181\n",
      "Epoch 334, Loss: 0.12160086259245872, Final Batch Loss: 0.06292926520109177\n",
      "Epoch 335, Loss: 0.08843511156737804, Final Batch Loss: 0.028386836871504784\n",
      "Epoch 336, Loss: 0.09763438254594803, Final Batch Loss: 0.05591311305761337\n",
      "Epoch 337, Loss: 0.09256452322006226, Final Batch Loss: 0.05015232414007187\n",
      "Epoch 338, Loss: 0.14399470388889313, Final Batch Loss: 0.06794798374176025\n",
      "Epoch 339, Loss: 0.09451698139309883, Final Batch Loss: 0.06396221369504929\n",
      "Epoch 340, Loss: 0.0856146402657032, Final Batch Loss: 0.040040917694568634\n",
      "Epoch 341, Loss: 0.08550065010786057, Final Batch Loss: 0.04549722746014595\n",
      "Epoch 342, Loss: 0.1005965992808342, Final Batch Loss: 0.021303638815879822\n",
      "Epoch 343, Loss: 0.1473740041255951, Final Batch Loss: 0.11788018047809601\n",
      "Epoch 344, Loss: 0.11035937070846558, Final Batch Loss: 0.04399024695158005\n",
      "Epoch 345, Loss: 0.11433576419949532, Final Batch Loss: 0.08472828567028046\n",
      "Epoch 346, Loss: 0.10610608011484146, Final Batch Loss: 0.032284773886203766\n",
      "Epoch 347, Loss: 0.12640945985913277, Final Batch Loss: 0.09104254841804504\n",
      "Epoch 348, Loss: 0.10087405145168304, Final Batch Loss: 0.039186395704746246\n",
      "Epoch 349, Loss: 0.11698007211089134, Final Batch Loss: 0.07204720377922058\n",
      "Epoch 350, Loss: 0.1562693789601326, Final Batch Loss: 0.09868266433477402\n",
      "Epoch 351, Loss: 0.09889344125986099, Final Batch Loss: 0.03559402376413345\n",
      "Epoch 352, Loss: 0.09176019951701164, Final Batch Loss: 0.03579488396644592\n",
      "Epoch 353, Loss: 0.11369819939136505, Final Batch Loss: 0.06189937889575958\n",
      "Epoch 354, Loss: 0.12964509427547455, Final Batch Loss: 0.061720654368400574\n",
      "Epoch 355, Loss: 0.10553887486457825, Final Batch Loss: 0.07242126762866974\n",
      "Epoch 356, Loss: 0.1271110661327839, Final Batch Loss: 0.06175284460186958\n",
      "Epoch 357, Loss: 0.11821899563074112, Final Batch Loss: 0.03662484884262085\n",
      "Epoch 358, Loss: 0.08684389106929302, Final Batch Loss: 0.02937779761850834\n",
      "Epoch 359, Loss: 0.11080285534262657, Final Batch Loss: 0.0658259391784668\n",
      "Epoch 360, Loss: 0.12484045699238777, Final Batch Loss: 0.0788249745965004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361, Loss: 0.21873221546411514, Final Batch Loss: 0.18151549994945526\n",
      "Epoch 362, Loss: 0.11164690926671028, Final Batch Loss: 0.06761442124843597\n",
      "Epoch 363, Loss: 0.11262331530451775, Final Batch Loss: 0.05616667494177818\n",
      "Epoch 364, Loss: 0.11132479086518288, Final Batch Loss: 0.048619937151670456\n",
      "Epoch 365, Loss: 0.11764822155237198, Final Batch Loss: 0.056357670575380325\n",
      "Epoch 366, Loss: 0.0886999350041151, Final Batch Loss: 0.057568471878767014\n",
      "Epoch 367, Loss: 0.07972964830696583, Final Batch Loss: 0.018430115655064583\n",
      "Epoch 368, Loss: 0.1400603912770748, Final Batch Loss: 0.05474123731255531\n",
      "Epoch 369, Loss: 0.08650368824601173, Final Batch Loss: 0.041532427072525024\n",
      "Epoch 370, Loss: 0.08693596720695496, Final Batch Loss: 0.04364737495779991\n",
      "Epoch 371, Loss: 0.08628085255622864, Final Batch Loss: 0.061584971845149994\n",
      "Epoch 372, Loss: 0.0813791025429964, Final Batch Loss: 0.027122152969241142\n",
      "Epoch 373, Loss: 0.11671344377100468, Final Batch Loss: 0.08820193260908127\n",
      "Epoch 374, Loss: 0.09483474306762218, Final Batch Loss: 0.03064080886542797\n",
      "Epoch 375, Loss: 0.09055930748581886, Final Batch Loss: 0.04475509375333786\n",
      "Epoch 376, Loss: 0.08316738903522491, Final Batch Loss: 0.047685813158750534\n",
      "Epoch 377, Loss: 0.12525702267885208, Final Batch Loss: 0.07469117641448975\n",
      "Epoch 378, Loss: 0.09170886501669884, Final Batch Loss: 0.0441097617149353\n",
      "Epoch 379, Loss: 0.07649577781558037, Final Batch Loss: 0.03447438403964043\n",
      "Epoch 380, Loss: 0.09105765074491501, Final Batch Loss: 0.03183847293257713\n",
      "Epoch 381, Loss: 0.12155188992619514, Final Batch Loss: 0.06240004673600197\n",
      "Epoch 382, Loss: 0.07830816134810448, Final Batch Loss: 0.04523439332842827\n",
      "Epoch 383, Loss: 0.09004388190805912, Final Batch Loss: 0.06078900396823883\n",
      "Epoch 384, Loss: 0.0991847775876522, Final Batch Loss: 0.03782381862401962\n",
      "Epoch 385, Loss: 0.09158549830317497, Final Batch Loss: 0.03991171345114708\n",
      "Epoch 386, Loss: 0.1646505892276764, Final Batch Loss: 0.10079406201839447\n",
      "Epoch 387, Loss: 0.13486112654209137, Final Batch Loss: 0.05030226707458496\n",
      "Epoch 388, Loss: 0.08337577804923058, Final Batch Loss: 0.0455145500600338\n",
      "Epoch 389, Loss: 0.1269899159669876, Final Batch Loss: 0.06261162459850311\n",
      "Epoch 390, Loss: 0.08588553220033646, Final Batch Loss: 0.043383900076150894\n",
      "Epoch 391, Loss: 0.15670432895421982, Final Batch Loss: 0.09847427904605865\n",
      "Epoch 392, Loss: 0.07783660292625427, Final Batch Loss: 0.037927430123090744\n",
      "Epoch 393, Loss: 0.15081900358200073, Final Batch Loss: 0.07946109771728516\n",
      "Epoch 394, Loss: 0.10814309865236282, Final Batch Loss: 0.05245412886142731\n",
      "Epoch 395, Loss: 0.08599800243973732, Final Batch Loss: 0.03360461816191673\n",
      "Epoch 396, Loss: 0.14203133434057236, Final Batch Loss: 0.1049823984503746\n",
      "Epoch 397, Loss: 0.10150511935353279, Final Batch Loss: 0.043070100247859955\n",
      "Epoch 398, Loss: 0.11527734808623791, Final Batch Loss: 0.0878157988190651\n",
      "Epoch 399, Loss: 0.13463563472032547, Final Batch Loss: 0.07146423310041428\n",
      "Epoch 400, Loss: 0.11730136722326279, Final Batch Loss: 0.048756763339042664\n",
      "Epoch 401, Loss: 0.09939751029014587, Final Batch Loss: 0.05562615394592285\n",
      "Epoch 402, Loss: 0.09726141020655632, Final Batch Loss: 0.07224588096141815\n",
      "Epoch 403, Loss: 0.08885318785905838, Final Batch Loss: 0.0357532724738121\n",
      "Epoch 404, Loss: 0.11862988770008087, Final Batch Loss: 0.0710335522890091\n",
      "Epoch 405, Loss: 0.1051841750741005, Final Batch Loss: 0.062439605593681335\n",
      "Epoch 406, Loss: 0.07953977584838867, Final Batch Loss: 0.03854411467909813\n",
      "Epoch 407, Loss: 0.09951301291584969, Final Batch Loss: 0.06686162203550339\n",
      "Epoch 408, Loss: 0.12103337049484253, Final Batch Loss: 0.06939838081598282\n",
      "Epoch 409, Loss: 0.08424623683094978, Final Batch Loss: 0.030521370470523834\n",
      "Epoch 410, Loss: 0.10364580526947975, Final Batch Loss: 0.057172905653715134\n",
      "Epoch 411, Loss: 0.10685919597744942, Final Batch Loss: 0.04271971061825752\n",
      "Epoch 412, Loss: 0.07547060400247574, Final Batch Loss: 0.027525950223207474\n",
      "Epoch 413, Loss: 0.11965777352452278, Final Batch Loss: 0.06904904544353485\n",
      "Epoch 414, Loss: 0.09134963154792786, Final Batch Loss: 0.04478287324309349\n",
      "Epoch 415, Loss: 0.06519299745559692, Final Batch Loss: 0.03584762662649155\n",
      "Epoch 416, Loss: 0.10055874288082123, Final Batch Loss: 0.022309109568595886\n",
      "Epoch 417, Loss: 0.09898898936808109, Final Batch Loss: 0.07192321866750717\n",
      "Epoch 418, Loss: 0.08359761163592339, Final Batch Loss: 0.03453580662608147\n",
      "Epoch 419, Loss: 0.054158756509423256, Final Batch Loss: 0.03395577520132065\n",
      "Epoch 420, Loss: 0.11249010264873505, Final Batch Loss: 0.06836030632257462\n",
      "Epoch 421, Loss: 0.06722995266318321, Final Batch Loss: 0.038573574274778366\n",
      "Epoch 422, Loss: 0.08578899130225182, Final Batch Loss: 0.023691736161708832\n",
      "Epoch 423, Loss: 0.07945168949663639, Final Batch Loss: 0.03096511773765087\n",
      "Epoch 424, Loss: 0.09892428293824196, Final Batch Loss: 0.043470680713653564\n",
      "Epoch 425, Loss: 0.08818723261356354, Final Batch Loss: 0.05042504146695137\n",
      "Epoch 426, Loss: 0.06788795068860054, Final Batch Loss: 0.03825642541050911\n",
      "Epoch 427, Loss: 0.12257266417145729, Final Batch Loss: 0.07835617661476135\n",
      "Epoch 428, Loss: 0.09146938845515251, Final Batch Loss: 0.058475758880376816\n",
      "Epoch 429, Loss: 0.09656026214361191, Final Batch Loss: 0.07559595257043839\n",
      "Epoch 430, Loss: 0.10203664749860764, Final Batch Loss: 0.03095528483390808\n",
      "Epoch 431, Loss: 0.08931241743266582, Final Batch Loss: 0.030625099316239357\n",
      "Epoch 432, Loss: 0.08996784500777721, Final Batch Loss: 0.025947412475943565\n",
      "Epoch 433, Loss: 0.0588600505143404, Final Batch Loss: 0.017783520743250847\n",
      "Epoch 434, Loss: 0.09287670627236366, Final Batch Loss: 0.05780801177024841\n",
      "Epoch 435, Loss: 0.08982467278838158, Final Batch Loss: 0.038435112684965134\n",
      "Epoch 436, Loss: 0.09115339815616608, Final Batch Loss: 0.06881967931985855\n",
      "Epoch 437, Loss: 0.09120862931013107, Final Batch Loss: 0.05285901203751564\n",
      "Epoch 438, Loss: 0.08889112994074821, Final Batch Loss: 0.04400957003235817\n",
      "Epoch 439, Loss: 0.11174558848142624, Final Batch Loss: 0.07550936937332153\n",
      "Epoch 440, Loss: 0.08915981650352478, Final Batch Loss: 0.03466670215129852\n",
      "Epoch 441, Loss: 0.06446091271936893, Final Batch Loss: 0.020542455837130547\n",
      "Epoch 442, Loss: 0.10435960814356804, Final Batch Loss: 0.03181617334485054\n",
      "Epoch 443, Loss: 0.09502020105719566, Final Batch Loss: 0.06345875561237335\n",
      "Epoch 444, Loss: 0.08858348801732063, Final Batch Loss: 0.04919280484318733\n",
      "Epoch 445, Loss: 0.10906414315104485, Final Batch Loss: 0.08210459351539612\n",
      "Epoch 446, Loss: 0.10361186787486076, Final Batch Loss: 0.05109994113445282\n",
      "Epoch 447, Loss: 0.08988212049007416, Final Batch Loss: 0.03192978724837303\n",
      "Epoch 448, Loss: 0.08864559233188629, Final Batch Loss: 0.05627134442329407\n",
      "Epoch 449, Loss: 0.09972876310348511, Final Batch Loss: 0.0572458952665329\n",
      "Epoch 450, Loss: 0.08177408576011658, Final Batch Loss: 0.0403057262301445\n",
      "Epoch 451, Loss: 0.1108822226524353, Final Batch Loss: 0.054685838520526886\n",
      "Epoch 452, Loss: 0.06972581706941128, Final Batch Loss: 0.01791703887283802\n",
      "Epoch 453, Loss: 0.10228827968239784, Final Batch Loss: 0.05425196886062622\n",
      "Epoch 454, Loss: 0.1091957688331604, Final Batch Loss: 0.07363393902778625\n",
      "Epoch 455, Loss: 0.07108522392809391, Final Batch Loss: 0.01918346993625164\n",
      "Epoch 456, Loss: 0.09865588508546352, Final Batch Loss: 0.020883334800601006\n",
      "Epoch 457, Loss: 0.08174963667988777, Final Batch Loss: 0.027564194053411484\n",
      "Epoch 458, Loss: 0.08933444693684578, Final Batch Loss: 0.03203894570469856\n",
      "Epoch 459, Loss: 0.07159659266471863, Final Batch Loss: 0.03670801222324371\n",
      "Epoch 460, Loss: 0.08850600197911263, Final Batch Loss: 0.021882209926843643\n",
      "Epoch 461, Loss: 0.0794522762298584, Final Batch Loss: 0.0320655032992363\n",
      "Epoch 462, Loss: 0.07074880227446556, Final Batch Loss: 0.0360790453851223\n",
      "Epoch 463, Loss: 0.0643201544880867, Final Batch Loss: 0.01825035735964775\n",
      "Epoch 464, Loss: 0.13284100964665413, Final Batch Loss: 0.0724072977900505\n",
      "Epoch 465, Loss: 0.08987375348806381, Final Batch Loss: 0.03106466308236122\n",
      "Epoch 466, Loss: 0.07646763138473034, Final Batch Loss: 0.015933269634842873\n",
      "Epoch 467, Loss: 0.09725010395050049, Final Batch Loss: 0.04293811693787575\n",
      "Epoch 468, Loss: 0.11169898882508278, Final Batch Loss: 0.0599929541349411\n",
      "Epoch 469, Loss: 0.06031193025410175, Final Batch Loss: 0.0379800908267498\n",
      "Epoch 470, Loss: 0.08947846665978432, Final Batch Loss: 0.06765066087245941\n",
      "Epoch 471, Loss: 0.07956602424383163, Final Batch Loss: 0.03802088275551796\n",
      "Epoch 472, Loss: 0.1089557483792305, Final Batch Loss: 0.04810059443116188\n",
      "Epoch 473, Loss: 0.07142266444861889, Final Batch Loss: 0.01663537137210369\n",
      "Epoch 474, Loss: 0.07766691967844963, Final Batch Loss: 0.03518814593553543\n",
      "Epoch 475, Loss: 0.08824090845882893, Final Batch Loss: 0.028599193319678307\n",
      "Epoch 476, Loss: 0.062296463176608086, Final Batch Loss: 0.03287898376584053\n",
      "Epoch 477, Loss: 0.09082842245697975, Final Batch Loss: 0.05113751068711281\n",
      "Epoch 478, Loss: 0.07291695103049278, Final Batch Loss: 0.03527495637536049\n",
      "Epoch 479, Loss: 0.061961669474840164, Final Batch Loss: 0.01595909520983696\n",
      "Epoch 480, Loss: 0.06259719282388687, Final Batch Loss: 0.0265035517513752\n",
      "Epoch 481, Loss: 0.09545614570379257, Final Batch Loss: 0.07083992660045624\n",
      "Epoch 482, Loss: 0.09007410705089569, Final Batch Loss: 0.04276689514517784\n",
      "Epoch 483, Loss: 0.095961669459939, Final Batch Loss: 0.028273964300751686\n",
      "Epoch 484, Loss: 0.07803882472217083, Final Batch Loss: 0.04851821810007095\n",
      "Epoch 485, Loss: 0.09570544958114624, Final Batch Loss: 0.06293361634016037\n",
      "Epoch 486, Loss: 0.05197591707110405, Final Batch Loss: 0.03550633788108826\n",
      "Epoch 487, Loss: 0.04966411925852299, Final Batch Loss: 0.01619976945221424\n",
      "Epoch 488, Loss: 0.08840932324528694, Final Batch Loss: 0.05128936842083931\n",
      "Epoch 489, Loss: 0.10718128085136414, Final Batch Loss: 0.056473907083272934\n",
      "Epoch 490, Loss: 0.07382513582706451, Final Batch Loss: 0.053479596972465515\n",
      "Epoch 491, Loss: 0.0627442542463541, Final Batch Loss: 0.02529476396739483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492, Loss: 0.11018384620547295, Final Batch Loss: 0.06327197700738907\n",
      "Epoch 493, Loss: 0.08438600040972233, Final Batch Loss: 0.025885486975312233\n",
      "Epoch 494, Loss: 0.09928411617875099, Final Batch Loss: 0.05887312442064285\n",
      "Epoch 495, Loss: 0.07602472230792046, Final Batch Loss: 0.0416426919400692\n",
      "Epoch 496, Loss: 0.05796293169260025, Final Batch Loss: 0.020943865180015564\n",
      "Epoch 497, Loss: 0.067810432985425, Final Batch Loss: 0.024903668090701103\n",
      "Epoch 498, Loss: 0.09486491605639458, Final Batch Loss: 0.05829504877328873\n",
      "Epoch 499, Loss: 0.09278737753629684, Final Batch Loss: 0.06056705117225647\n",
      "Epoch 500, Loss: 0.08363918215036392, Final Batch Loss: 0.042293861508369446\n",
      "Epoch 501, Loss: 0.054807672277092934, Final Batch Loss: 0.024910876527428627\n",
      "Epoch 502, Loss: 0.08778966963291168, Final Batch Loss: 0.040648747235536575\n",
      "Epoch 503, Loss: 0.06851491890847683, Final Batch Loss: 0.05075811594724655\n",
      "Epoch 504, Loss: 0.06304604932665825, Final Batch Loss: 0.03439471870660782\n",
      "Epoch 505, Loss: 0.10779624804854393, Final Batch Loss: 0.07287274301052094\n",
      "Epoch 506, Loss: 0.08982800506055355, Final Batch Loss: 0.06447779387235641\n",
      "Epoch 507, Loss: 0.07878690212965012, Final Batch Loss: 0.06112401559948921\n",
      "Epoch 508, Loss: 0.08211608044803143, Final Batch Loss: 0.05933595448732376\n",
      "Epoch 509, Loss: 0.06730255857110023, Final Batch Loss: 0.02562835067510605\n",
      "Epoch 510, Loss: 0.09223520383238792, Final Batch Loss: 0.05903017520904541\n",
      "Epoch 511, Loss: 0.0758046805858612, Final Batch Loss: 0.04063401743769646\n",
      "Epoch 512, Loss: 0.05896430276334286, Final Batch Loss: 0.02690207026898861\n",
      "Epoch 513, Loss: 0.0567963644862175, Final Batch Loss: 0.016276270151138306\n",
      "Epoch 514, Loss: 0.0643036849796772, Final Batch Loss: 0.032058876007795334\n",
      "Epoch 515, Loss: 0.07952224649488926, Final Batch Loss: 0.057408321648836136\n",
      "Epoch 516, Loss: 0.06938873883336782, Final Batch Loss: 0.01087410282343626\n",
      "Epoch 517, Loss: 0.08618536591529846, Final Batch Loss: 0.04158264398574829\n",
      "Epoch 518, Loss: 0.0636798907071352, Final Batch Loss: 0.021755637601017952\n",
      "Epoch 519, Loss: 0.05624571442604065, Final Batch Loss: 0.025464214384555817\n",
      "Epoch 520, Loss: 0.07051736488938332, Final Batch Loss: 0.017176389694213867\n",
      "Epoch 521, Loss: 0.06403733417391777, Final Batch Loss: 0.04005121812224388\n",
      "Epoch 522, Loss: 0.06222863681614399, Final Batch Loss: 0.0312558077275753\n",
      "Epoch 523, Loss: 0.07065668515861034, Final Batch Loss: 0.030724914744496346\n",
      "Epoch 524, Loss: 0.08146537840366364, Final Batch Loss: 0.057669300585985184\n",
      "Epoch 525, Loss: 0.07365027070045471, Final Batch Loss: 0.032395701855421066\n",
      "Epoch 526, Loss: 0.07541713491082191, Final Batch Loss: 0.050974734127521515\n",
      "Epoch 527, Loss: 0.05146721750497818, Final Batch Loss: 0.014849375933408737\n",
      "Epoch 528, Loss: 0.06322446092963219, Final Batch Loss: 0.0113820880651474\n",
      "Epoch 529, Loss: 0.07228102907538414, Final Batch Loss: 0.016292277723550797\n",
      "Epoch 530, Loss: 0.047652531415224075, Final Batch Loss: 0.031661130487918854\n",
      "Epoch 531, Loss: 0.07978390157222748, Final Batch Loss: 0.048247989267110825\n",
      "Epoch 532, Loss: 0.0748140886425972, Final Batch Loss: 0.050674062222242355\n",
      "Epoch 533, Loss: 0.07586866989731789, Final Batch Loss: 0.044651586562395096\n",
      "Epoch 534, Loss: 0.06476639397442341, Final Batch Loss: 0.03710392490029335\n",
      "Epoch 535, Loss: 0.07207255437970161, Final Batch Loss: 0.03897187486290932\n",
      "Epoch 536, Loss: 0.05478212796151638, Final Batch Loss: 0.018563253805041313\n",
      "Epoch 537, Loss: 0.0538095161318779, Final Batch Loss: 0.0318915992975235\n",
      "Epoch 538, Loss: 0.07498340867459774, Final Batch Loss: 0.04771581292152405\n",
      "Epoch 539, Loss: 0.05422805994749069, Final Batch Loss: 0.03751403093338013\n",
      "Epoch 540, Loss: 0.04114566557109356, Final Batch Loss: 0.028841009363532066\n",
      "Epoch 541, Loss: 0.07601511850953102, Final Batch Loss: 0.03187249228358269\n",
      "Epoch 542, Loss: 0.045026930049061775, Final Batch Loss: 0.02468479424715042\n",
      "Epoch 543, Loss: 0.05809524841606617, Final Batch Loss: 0.013668151572346687\n",
      "Epoch 544, Loss: 0.05963083729147911, Final Batch Loss: 0.032890915870666504\n",
      "Epoch 545, Loss: 0.042255512438714504, Final Batch Loss: 0.012486112304031849\n",
      "Epoch 546, Loss: 0.05770222656428814, Final Batch Loss: 0.038571570068597794\n",
      "Epoch 547, Loss: 0.07344010099768639, Final Batch Loss: 0.023836687207221985\n",
      "Epoch 548, Loss: 0.04668581672012806, Final Batch Loss: 0.022469721734523773\n",
      "Epoch 549, Loss: 0.05975211039185524, Final Batch Loss: 0.03166652470827103\n",
      "Epoch 550, Loss: 0.05013316310942173, Final Batch Loss: 0.031779151409864426\n",
      "Epoch 551, Loss: 0.04620033409446478, Final Batch Loss: 0.011637887917459011\n",
      "Epoch 552, Loss: 0.06280012428760529, Final Batch Loss: 0.01737477257847786\n",
      "Epoch 553, Loss: 0.059420350939035416, Final Batch Loss: 0.0209389366209507\n",
      "Epoch 554, Loss: 0.06026533432304859, Final Batch Loss: 0.03713085129857063\n",
      "Epoch 555, Loss: 0.0390086155384779, Final Batch Loss: 0.010241465643048286\n",
      "Epoch 556, Loss: 0.06703954748809338, Final Batch Loss: 0.0500037744641304\n",
      "Epoch 557, Loss: 0.0638210317119956, Final Batch Loss: 0.05406351387500763\n",
      "Epoch 558, Loss: 0.06941412761807442, Final Batch Loss: 0.03583594039082527\n",
      "Epoch 559, Loss: 0.046775855123996735, Final Batch Loss: 0.021581849083304405\n",
      "Epoch 560, Loss: 0.09279614686965942, Final Batch Loss: 0.07779746502637863\n",
      "Epoch 561, Loss: 0.04591797851026058, Final Batch Loss: 0.027273349463939667\n",
      "Epoch 562, Loss: 0.0643515270203352, Final Batch Loss: 0.04412086308002472\n",
      "Epoch 563, Loss: 0.026976625435054302, Final Batch Loss: 0.008155806921422482\n",
      "Epoch 564, Loss: 0.06933902576565742, Final Batch Loss: 0.038085341453552246\n",
      "Epoch 565, Loss: 0.060932667925953865, Final Batch Loss: 0.03909023851156235\n",
      "Epoch 566, Loss: 0.06956471130251884, Final Batch Loss: 0.03745456784963608\n",
      "Epoch 567, Loss: 0.09256449528038502, Final Batch Loss: 0.0668996274471283\n",
      "Epoch 568, Loss: 0.05683563090860844, Final Batch Loss: 0.02569020912051201\n",
      "Epoch 569, Loss: 0.049649765715003014, Final Batch Loss: 0.027115873992443085\n",
      "Epoch 570, Loss: 0.06881656870245934, Final Batch Loss: 0.05153128504753113\n",
      "Epoch 571, Loss: 0.045575303956866264, Final Batch Loss: 0.01398257352411747\n",
      "Epoch 572, Loss: 0.056060925126075745, Final Batch Loss: 0.04156861826777458\n",
      "Epoch 573, Loss: 0.0650683119893074, Final Batch Loss: 0.04141062870621681\n",
      "Epoch 574, Loss: 0.058641135692596436, Final Batch Loss: 0.03183753043413162\n",
      "Epoch 575, Loss: 0.06555585004389286, Final Batch Loss: 0.048229046165943146\n",
      "Epoch 576, Loss: 0.04996925685554743, Final Batch Loss: 0.035579998046159744\n",
      "Epoch 577, Loss: 0.04916640557348728, Final Batch Loss: 0.03662111982703209\n",
      "Epoch 578, Loss: 0.06493022106587887, Final Batch Loss: 0.04163810610771179\n",
      "Epoch 579, Loss: 0.033028415869921446, Final Batch Loss: 0.00447141332551837\n",
      "Epoch 580, Loss: 0.04129336215555668, Final Batch Loss: 0.016495712101459503\n",
      "Epoch 581, Loss: 0.04340672679245472, Final Batch Loss: 0.017503192648291588\n",
      "Epoch 582, Loss: 0.033889214508235455, Final Batch Loss: 0.011219902895390987\n",
      "Epoch 583, Loss: 0.034477535635232925, Final Batch Loss: 0.021366886794567108\n",
      "Epoch 584, Loss: 0.045306358486413956, Final Batch Loss: 0.02275758609175682\n",
      "Epoch 585, Loss: 0.047004397958517075, Final Batch Loss: 0.023990822955965996\n",
      "Epoch 586, Loss: 0.04298497224226594, Final Batch Loss: 0.0045797997154295444\n",
      "Epoch 587, Loss: 0.032059235498309135, Final Batch Loss: 0.016576798632740974\n",
      "Epoch 588, Loss: 0.036558665335178375, Final Batch Loss: 0.023439235985279083\n",
      "Epoch 589, Loss: 0.048613439314067364, Final Batch Loss: 0.036690760403871536\n",
      "Epoch 590, Loss: 0.03970814310014248, Final Batch Loss: 0.010945243760943413\n",
      "Epoch 591, Loss: 0.05091242026537657, Final Batch Loss: 0.039932627230882645\n",
      "Epoch 592, Loss: 0.03889298811554909, Final Batch Loss: 0.030194301158189774\n",
      "Epoch 593, Loss: 0.04303092882037163, Final Batch Loss: 0.020154496654868126\n",
      "Epoch 594, Loss: 0.0427087377756834, Final Batch Loss: 0.02142120525240898\n",
      "Epoch 595, Loss: 0.03919098153710365, Final Batch Loss: 0.016813062131404877\n",
      "Epoch 596, Loss: 0.10939821787178516, Final Batch Loss: 0.08555890619754791\n",
      "Epoch 597, Loss: 0.04307665675878525, Final Batch Loss: 0.024624353274703026\n",
      "Epoch 598, Loss: 0.057106731459498405, Final Batch Loss: 0.040050115436315536\n",
      "Epoch 599, Loss: 0.037877295166254044, Final Batch Loss: 0.0197116881608963\n",
      "Epoch 600, Loss: 0.04502044804394245, Final Batch Loss: 0.021295074373483658\n",
      "Epoch 601, Loss: 0.041452353820204735, Final Batch Loss: 0.028897229582071304\n",
      "Epoch 602, Loss: 0.046121079474687576, Final Batch Loss: 0.021012576296925545\n",
      "Epoch 603, Loss: 0.01822739839553833, Final Batch Loss: 0.004564893431961536\n",
      "Epoch 604, Loss: 0.061776503920555115, Final Batch Loss: 0.04281266778707504\n",
      "Epoch 605, Loss: 0.03479602374136448, Final Batch Loss: 0.013891737908124924\n",
      "Epoch 606, Loss: 0.040271615609526634, Final Batch Loss: 0.021696852520108223\n",
      "Epoch 607, Loss: 0.048723192885518074, Final Batch Loss: 0.03229336813092232\n",
      "Epoch 608, Loss: 0.09191063418984413, Final Batch Loss: 0.047573380172252655\n",
      "Epoch 609, Loss: 0.06454224698245525, Final Batch Loss: 0.03123370371758938\n",
      "Epoch 610, Loss: 0.03840757766738534, Final Batch Loss: 0.007270891685038805\n",
      "Epoch 611, Loss: 0.033416557125747204, Final Batch Loss: 0.011021134443581104\n",
      "Epoch 612, Loss: 0.03551926091313362, Final Batch Loss: 0.02312600612640381\n",
      "Epoch 613, Loss: 0.040329111739993095, Final Batch Loss: 0.031316906213760376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614, Loss: 0.03871484566479921, Final Batch Loss: 0.009244206361472607\n",
      "Epoch 615, Loss: 0.05603992938995361, Final Batch Loss: 0.03425851836800575\n",
      "Epoch 616, Loss: 0.024398131296038628, Final Batch Loss: 0.01269556488841772\n",
      "Epoch 617, Loss: 0.06201767176389694, Final Batch Loss: 0.029442086815834045\n",
      "Epoch 618, Loss: 0.028146859258413315, Final Batch Loss: 0.013402367942035198\n",
      "Epoch 619, Loss: 0.058255648240447044, Final Batch Loss: 0.029475828632712364\n",
      "Epoch 620, Loss: 0.047340692952275276, Final Batch Loss: 0.023614075034856796\n",
      "Epoch 621, Loss: 0.03890006709843874, Final Batch Loss: 0.02963503636419773\n",
      "Epoch 622, Loss: 0.055893922224640846, Final Batch Loss: 0.017450226470828056\n",
      "Epoch 623, Loss: 0.0269027017056942, Final Batch Loss: 0.012944856658577919\n",
      "Epoch 624, Loss: 0.056480500381439924, Final Batch Loss: 0.007596212904900312\n",
      "Epoch 625, Loss: 0.021117827855050564, Final Batch Loss: 0.011414541862905025\n",
      "Epoch 626, Loss: 0.02986360713839531, Final Batch Loss: 0.009440705180168152\n",
      "Epoch 627, Loss: 0.05183450132608414, Final Batch Loss: 0.026002300903201103\n",
      "Epoch 628, Loss: 0.035501633770763874, Final Batch Loss: 0.007483488880097866\n",
      "Epoch 629, Loss: 0.0483777467161417, Final Batch Loss: 0.016939425840973854\n",
      "Epoch 630, Loss: 0.04236136935651302, Final Batch Loss: 0.02343284711241722\n",
      "Epoch 631, Loss: 0.01933593349531293, Final Batch Loss: 0.005763451103121042\n",
      "Epoch 632, Loss: 0.05937538854777813, Final Batch Loss: 0.02362820692360401\n",
      "Epoch 633, Loss: 0.02967315260320902, Final Batch Loss: 0.008531452156603336\n",
      "Epoch 634, Loss: 0.04667509347200394, Final Batch Loss: 0.03430342674255371\n",
      "Epoch 635, Loss: 0.023006854578852654, Final Batch Loss: 0.015201166272163391\n",
      "Epoch 636, Loss: 0.02102555800229311, Final Batch Loss: 0.006038441322743893\n",
      "Epoch 637, Loss: 0.04018841031938791, Final Batch Loss: 0.014219905249774456\n",
      "Epoch 638, Loss: 0.04521972592920065, Final Batch Loss: 0.03446619212627411\n",
      "Epoch 639, Loss: 0.03597644064575434, Final Batch Loss: 0.014814346097409725\n",
      "Epoch 640, Loss: 0.03307656943798065, Final Batch Loss: 0.022450949996709824\n",
      "Epoch 641, Loss: 0.04312850907444954, Final Batch Loss: 0.027207374572753906\n",
      "Epoch 642, Loss: 0.050129203125834465, Final Batch Loss: 0.036074448376894\n",
      "Epoch 643, Loss: 0.03569226060062647, Final Batch Loss: 0.027291132137179375\n",
      "Epoch 644, Loss: 0.03679127711802721, Final Batch Loss: 0.022989943623542786\n",
      "Epoch 645, Loss: 0.0343053825199604, Final Batch Loss: 0.025098104029893875\n",
      "Epoch 646, Loss: 0.02797441277652979, Final Batch Loss: 0.017988264560699463\n",
      "Epoch 647, Loss: 0.02246639598160982, Final Batch Loss: 0.012644249945878983\n",
      "Epoch 648, Loss: 0.03180577885359526, Final Batch Loss: 0.022971171885728836\n",
      "Epoch 649, Loss: 0.02812287677079439, Final Batch Loss: 0.012233796529471874\n",
      "Epoch 650, Loss: 0.01977414730936289, Final Batch Loss: 0.007662416435778141\n",
      "Epoch 651, Loss: 0.05654316721484065, Final Batch Loss: 0.050335656851530075\n",
      "Epoch 652, Loss: 0.02681472711265087, Final Batch Loss: 0.01267552562057972\n",
      "Epoch 653, Loss: 0.049750758334994316, Final Batch Loss: 0.02559535577893257\n",
      "Epoch 654, Loss: 0.03131246846169233, Final Batch Loss: 0.019185423851013184\n",
      "Epoch 655, Loss: 0.026747508905828, Final Batch Loss: 0.006455284543335438\n",
      "Epoch 656, Loss: 0.03133350145071745, Final Batch Loss: 0.007228543050587177\n",
      "Epoch 657, Loss: 0.05473823053762317, Final Batch Loss: 0.006615623366087675\n",
      "Epoch 658, Loss: 0.07930480968207121, Final Batch Loss: 0.06725146621465683\n",
      "Epoch 659, Loss: 0.04028177447617054, Final Batch Loss: 0.02902473695576191\n",
      "Epoch 660, Loss: 0.019042729400098324, Final Batch Loss: 0.011866804212331772\n",
      "Epoch 661, Loss: 0.0369347408413887, Final Batch Loss: 0.017839713022112846\n",
      "Epoch 662, Loss: 0.030670457053929567, Final Batch Loss: 0.004837163258343935\n",
      "Epoch 663, Loss: 0.04274853318929672, Final Batch Loss: 0.019541466608643532\n",
      "Epoch 664, Loss: 0.03701369650661945, Final Batch Loss: 0.025489380583167076\n",
      "Epoch 665, Loss: 0.0411910442635417, Final Batch Loss: 0.011089383624494076\n",
      "Epoch 666, Loss: 0.0480105746537447, Final Batch Loss: 0.023990189656615257\n",
      "Epoch 667, Loss: 0.026353057473897934, Final Batch Loss: 0.006864452734589577\n",
      "Epoch 668, Loss: 0.022429033648222685, Final Batch Loss: 0.007602110970765352\n",
      "Epoch 669, Loss: 0.028356924653053284, Final Batch Loss: 0.02323855273425579\n",
      "Epoch 670, Loss: 0.044581420719623566, Final Batch Loss: 0.028127459809184074\n",
      "Epoch 671, Loss: 0.03963145613670349, Final Batch Loss: 0.01797630824148655\n",
      "Epoch 672, Loss: 0.03712543472647667, Final Batch Loss: 0.02150464430451393\n",
      "Epoch 673, Loss: 0.035323201678693295, Final Batch Loss: 0.024406051263213158\n",
      "Epoch 674, Loss: 0.027939023450016975, Final Batch Loss: 0.014311065897345543\n",
      "Epoch 675, Loss: 0.03812724258750677, Final Batch Loss: 0.03382503241300583\n",
      "Epoch 676, Loss: 0.09190457127988338, Final Batch Loss: 0.07171129435300827\n",
      "Epoch 677, Loss: 0.0588277205824852, Final Batch Loss: 0.03547877073287964\n",
      "Epoch 678, Loss: 0.014440078288316727, Final Batch Loss: 0.001725560985505581\n",
      "Epoch 679, Loss: 0.02441514888778329, Final Batch Loss: 0.006288128439337015\n",
      "Epoch 680, Loss: 0.04181668255478144, Final Batch Loss: 0.014347747899591923\n",
      "Epoch 681, Loss: 0.0723898196592927, Final Batch Loss: 0.05887627229094505\n",
      "Epoch 682, Loss: 0.03716791607439518, Final Batch Loss: 0.01945372484624386\n",
      "Epoch 683, Loss: 0.03775333613157272, Final Batch Loss: 0.018235713243484497\n",
      "Epoch 684, Loss: 0.040697640273720026, Final Batch Loss: 0.03394278883934021\n",
      "Epoch 685, Loss: 0.02747263852506876, Final Batch Loss: 0.015146920457482338\n",
      "Epoch 686, Loss: 0.04498624801635742, Final Batch Loss: 0.028255624696612358\n",
      "Epoch 687, Loss: 0.018088811542838812, Final Batch Loss: 0.0063307383097708225\n",
      "Epoch 688, Loss: 0.0506820697337389, Final Batch Loss: 0.01724146492779255\n",
      "Epoch 689, Loss: 0.03904848080128431, Final Batch Loss: 0.030310004949569702\n",
      "Epoch 690, Loss: 0.024834947660565376, Final Batch Loss: 0.01022186130285263\n",
      "Epoch 691, Loss: 0.046745902858674526, Final Batch Loss: 0.03113672323524952\n",
      "Epoch 692, Loss: 0.0389636866748333, Final Batch Loss: 0.023943651467561722\n",
      "Epoch 693, Loss: 0.024310371838510036, Final Batch Loss: 0.013419164344668388\n",
      "Epoch 694, Loss: 0.039410997182130814, Final Batch Loss: 0.016194354742765427\n",
      "Epoch 695, Loss: 0.019838448613882065, Final Batch Loss: 0.0142148956656456\n",
      "Epoch 696, Loss: 0.027217970695346594, Final Batch Loss: 0.00541643938049674\n",
      "Epoch 697, Loss: 0.01878042332828045, Final Batch Loss: 0.00851262267678976\n",
      "Epoch 698, Loss: 0.022855606861412525, Final Batch Loss: 0.014241667464375496\n",
      "Epoch 699, Loss: 0.01864304067566991, Final Batch Loss: 0.005583878140896559\n",
      "Epoch 700, Loss: 0.03141569904983044, Final Batch Loss: 0.01991155743598938\n",
      "Epoch 701, Loss: 0.020726731978356838, Final Batch Loss: 0.008875317871570587\n",
      "Epoch 702, Loss: 0.039762173779308796, Final Batch Loss: 0.030982600525021553\n",
      "Epoch 703, Loss: 0.05022753123193979, Final Batch Loss: 0.03841284662485123\n",
      "Epoch 704, Loss: 0.04161234200000763, Final Batch Loss: 0.014066416770219803\n",
      "Epoch 705, Loss: 0.07527321390807629, Final Batch Loss: 0.06426919251680374\n",
      "Epoch 706, Loss: 0.08389429375529289, Final Batch Loss: 0.06374417990446091\n",
      "Epoch 707, Loss: 0.055832275189459324, Final Batch Loss: 0.0465189591050148\n",
      "Epoch 708, Loss: 0.03578577656298876, Final Batch Loss: 0.015321486629545689\n",
      "Epoch 709, Loss: 0.0685674138367176, Final Batch Loss: 0.015627756714820862\n",
      "Epoch 710, Loss: 0.04093465534970164, Final Batch Loss: 0.005986168514937162\n",
      "Epoch 711, Loss: 0.02853390108793974, Final Batch Loss: 0.014805360697209835\n",
      "Epoch 712, Loss: 0.049848584458231926, Final Batch Loss: 0.012678707018494606\n",
      "Epoch 713, Loss: 0.02005679067224264, Final Batch Loss: 0.009785452857613564\n",
      "Epoch 714, Loss: 0.061691309325397015, Final Batch Loss: 0.04947842285037041\n",
      "Epoch 715, Loss: 0.01987891737371683, Final Batch Loss: 0.004536652006208897\n",
      "Epoch 716, Loss: 0.03686471842229366, Final Batch Loss: 0.012066200375556946\n",
      "Epoch 717, Loss: 0.030576415359973907, Final Batch Loss: 0.020029550418257713\n",
      "Epoch 718, Loss: 0.06928874552249908, Final Batch Loss: 0.03678441047668457\n",
      "Epoch 719, Loss: 0.022573683876544237, Final Batch Loss: 0.006171387154608965\n",
      "Epoch 720, Loss: 0.02695447369478643, Final Batch Loss: 0.003853387897834182\n",
      "Epoch 721, Loss: 0.029457679949700832, Final Batch Loss: 0.023533180356025696\n",
      "Epoch 722, Loss: 0.06991462549194694, Final Batch Loss: 0.06526904553174973\n",
      "Epoch 723, Loss: 0.04443094041198492, Final Batch Loss: 0.030064141377806664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724, Loss: 0.04368940554559231, Final Batch Loss: 0.019214436411857605\n",
      "Epoch 725, Loss: 0.028086034581065178, Final Batch Loss: 0.005838891491293907\n",
      "Epoch 726, Loss: 0.037898555397987366, Final Batch Loss: 0.017596609890460968\n",
      "Epoch 727, Loss: 0.024117931723594666, Final Batch Loss: 0.012759458273649216\n",
      "Epoch 728, Loss: 0.019595124758780003, Final Batch Loss: 0.005944703705608845\n",
      "Epoch 729, Loss: 0.04736041184514761, Final Batch Loss: 0.014744791202247143\n",
      "Epoch 730, Loss: 0.02847894374281168, Final Batch Loss: 0.01484671700745821\n",
      "Epoch 731, Loss: 0.026849019341170788, Final Batch Loss: 0.013765453360974789\n",
      "Epoch 732, Loss: 0.02938952576369047, Final Batch Loss: 0.008672106079757214\n",
      "Epoch 733, Loss: 0.033649678342044353, Final Batch Loss: 0.012198126874864101\n",
      "Epoch 734, Loss: 0.018694262951612473, Final Batch Loss: 0.009681390598416328\n",
      "Epoch 735, Loss: 0.030066469218581915, Final Batch Loss: 0.006549203302711248\n",
      "Epoch 736, Loss: 0.03057091310620308, Final Batch Loss: 0.019031625241041183\n",
      "Epoch 737, Loss: 0.01926392689347267, Final Batch Loss: 0.007854287512600422\n",
      "Epoch 738, Loss: 0.02190379425883293, Final Batch Loss: 0.00844511017203331\n",
      "Epoch 739, Loss: 0.015225102193653584, Final Batch Loss: 0.005854959599673748\n",
      "Epoch 740, Loss: 0.01874061394482851, Final Batch Loss: 0.0053511718288064\n",
      "Epoch 741, Loss: 0.02649234514683485, Final Batch Loss: 0.007179015316069126\n",
      "Epoch 742, Loss: 0.022186134243384004, Final Batch Loss: 0.0020700993482023478\n",
      "Epoch 743, Loss: 0.018288564402610064, Final Batch Loss: 0.007200431544333696\n",
      "Epoch 744, Loss: 0.03533880040049553, Final Batch Loss: 0.03140810877084732\n",
      "Epoch 745, Loss: 0.014685342088341713, Final Batch Loss: 0.008936245925724506\n",
      "Epoch 746, Loss: 0.02058868668973446, Final Batch Loss: 0.008059466257691383\n",
      "Epoch 747, Loss: 0.028502969536930323, Final Batch Loss: 0.023325029760599136\n",
      "Epoch 748, Loss: 0.03531504049897194, Final Batch Loss: 0.023183055222034454\n",
      "Epoch 749, Loss: 0.023646624758839607, Final Batch Loss: 0.0061112139374017715\n",
      "Epoch 750, Loss: 0.032883957494050264, Final Batch Loss: 0.025688068941235542\n",
      "Epoch 751, Loss: 0.03464811202138662, Final Batch Loss: 0.021478410810232162\n",
      "Epoch 752, Loss: 0.00669285049661994, Final Batch Loss: 0.0026318971067667007\n",
      "Epoch 753, Loss: 0.014715277589857578, Final Batch Loss: 0.0013067135587334633\n",
      "Epoch 754, Loss: 0.011786559130996466, Final Batch Loss: 0.005323642399162054\n",
      "Epoch 755, Loss: 0.02227603830397129, Final Batch Loss: 0.004048960283398628\n",
      "Epoch 756, Loss: 0.023185742553323507, Final Batch Loss: 0.002954149153083563\n",
      "Epoch 757, Loss: 0.02689589117653668, Final Batch Loss: 0.0032497469801455736\n",
      "Epoch 758, Loss: 0.021931716240942478, Final Batch Loss: 0.0130827147513628\n",
      "Epoch 759, Loss: 0.016067347954958677, Final Batch Loss: 0.010491964407265186\n",
      "Epoch 760, Loss: 0.02254522079601884, Final Batch Loss: 0.01611558347940445\n",
      "Epoch 761, Loss: 0.01597618591040373, Final Batch Loss: 0.008520113304257393\n",
      "Epoch 762, Loss: 0.017908097244799137, Final Batch Loss: 0.004638399928808212\n",
      "Epoch 763, Loss: 0.01814395748078823, Final Batch Loss: 0.010677213780581951\n",
      "Epoch 764, Loss: 0.013643271289765835, Final Batch Loss: 0.0064615183509886265\n",
      "Epoch 765, Loss: 0.014811644330620766, Final Batch Loss: 0.0040429141372442245\n",
      "Epoch 766, Loss: 0.025637583807110786, Final Batch Loss: 0.011548646725714207\n",
      "Epoch 767, Loss: 0.00937518896535039, Final Batch Loss: 0.003497364930808544\n",
      "Epoch 768, Loss: 0.010863803094252944, Final Batch Loss: 0.003105592681095004\n",
      "Epoch 769, Loss: 0.0164655027911067, Final Batch Loss: 0.009139595553278923\n",
      "Epoch 770, Loss: 0.017318207770586014, Final Batch Loss: 0.0070229023694992065\n",
      "Epoch 771, Loss: 0.023226748686283827, Final Batch Loss: 0.018515154719352722\n",
      "Epoch 772, Loss: 0.02250604867003858, Final Batch Loss: 0.0036362612154334784\n",
      "Epoch 773, Loss: 0.02059314399957657, Final Batch Loss: 0.0163869746029377\n",
      "Epoch 774, Loss: 0.0350353978574276, Final Batch Loss: 0.0066644661128520966\n",
      "Epoch 775, Loss: 0.01735144993290305, Final Batch Loss: 0.007395221386104822\n",
      "Epoch 776, Loss: 0.021128226071596146, Final Batch Loss: 0.009047690778970718\n",
      "Epoch 777, Loss: 0.01045737974345684, Final Batch Loss: 0.005885373800992966\n",
      "Epoch 778, Loss: 0.031096061691641808, Final Batch Loss: 0.011236932128667831\n",
      "Epoch 779, Loss: 0.04887521546334028, Final Batch Loss: 0.034009356051683426\n",
      "Epoch 780, Loss: 0.017893044278025627, Final Batch Loss: 0.011724326759576797\n",
      "Epoch 781, Loss: 0.024275842122733593, Final Batch Loss: 0.008396717719733715\n",
      "Epoch 782, Loss: 0.026067967992275953, Final Batch Loss: 0.023675264790654182\n",
      "Epoch 783, Loss: 0.025415327632799745, Final Batch Loss: 0.002202399307861924\n",
      "Epoch 784, Loss: 0.042114910669624805, Final Batch Loss: 0.033594824373722076\n",
      "Epoch 785, Loss: 0.02142493613064289, Final Batch Loss: 0.005879109725356102\n",
      "Epoch 786, Loss: 0.03219871548935771, Final Batch Loss: 0.024423634633421898\n",
      "Epoch 787, Loss: 0.05060914438217878, Final Batch Loss: 0.014339982531964779\n",
      "Epoch 788, Loss: 0.009665334830060601, Final Batch Loss: 0.0035652818623930216\n",
      "Epoch 789, Loss: 0.008141399594023824, Final Batch Loss: 0.002405524952337146\n",
      "Epoch 790, Loss: 0.04065302945673466, Final Batch Loss: 0.03173289820551872\n",
      "Epoch 791, Loss: 0.0201632184907794, Final Batch Loss: 0.009936484508216381\n",
      "Epoch 792, Loss: 0.022728285752236843, Final Batch Loss: 0.008805240504443645\n",
      "Epoch 793, Loss: 0.028841390274465084, Final Batch Loss: 0.019454823806881905\n",
      "Epoch 794, Loss: 0.010955644305795431, Final Batch Loss: 0.0031969938427209854\n",
      "Epoch 795, Loss: 0.015731749124825, Final Batch Loss: 0.007886004634201527\n",
      "Epoch 796, Loss: 0.019851576536893845, Final Batch Loss: 0.014885432086884975\n",
      "Epoch 797, Loss: 0.02918778918683529, Final Batch Loss: 0.017151111736893654\n",
      "Epoch 798, Loss: 0.010093193035572767, Final Batch Loss: 0.006145807448774576\n",
      "Epoch 799, Loss: 0.020037014037370682, Final Batch Loss: 0.01651088520884514\n",
      "Epoch 800, Loss: 0.03514338191598654, Final Batch Loss: 0.008979392237961292\n",
      "Epoch 801, Loss: 0.02545578801073134, Final Batch Loss: 0.021926825866103172\n",
      "Epoch 802, Loss: 0.018235401250422, Final Batch Loss: 0.013158042915165424\n",
      "Epoch 803, Loss: 0.03912304434925318, Final Batch Loss: 0.014804682694375515\n",
      "Epoch 804, Loss: 0.015300356782972813, Final Batch Loss: 0.00923851691186428\n",
      "Epoch 805, Loss: 0.01202065171673894, Final Batch Loss: 0.0029727150686085224\n",
      "Epoch 806, Loss: 0.027944261208176613, Final Batch Loss: 0.01907680369913578\n",
      "Epoch 807, Loss: 0.02478139940649271, Final Batch Loss: 0.01372017152607441\n",
      "Epoch 808, Loss: 0.024272494483739138, Final Batch Loss: 0.00771040515974164\n",
      "Epoch 809, Loss: 0.021152593661099672, Final Batch Loss: 0.0050064572133123875\n",
      "Epoch 810, Loss: 0.016405163798481226, Final Batch Loss: 0.0063304477371275425\n",
      "Epoch 811, Loss: 0.008694599382579327, Final Batch Loss: 0.005324226804077625\n",
      "Epoch 812, Loss: 0.018453107215464115, Final Batch Loss: 0.00666226539760828\n",
      "Epoch 813, Loss: 0.010258863680064678, Final Batch Loss: 0.006002812180668116\n",
      "Epoch 814, Loss: 0.02269318513572216, Final Batch Loss: 0.018376266583800316\n",
      "Epoch 815, Loss: 0.010969087015837431, Final Batch Loss: 0.0015002558939158916\n",
      "Epoch 816, Loss: 0.012697136495262384, Final Batch Loss: 0.003998443018645048\n",
      "Epoch 817, Loss: 0.015369117725640535, Final Batch Loss: 0.009897112846374512\n",
      "Epoch 818, Loss: 0.010506469523534179, Final Batch Loss: 0.007289168890565634\n",
      "Epoch 819, Loss: 0.014908959157764912, Final Batch Loss: 0.009916630573570728\n",
      "Epoch 820, Loss: 0.013877187855541706, Final Batch Loss: 0.006722065154463053\n",
      "Epoch 821, Loss: 0.008431536378338933, Final Batch Loss: 0.00669693062081933\n",
      "Epoch 822, Loss: 0.024084276985377073, Final Batch Loss: 0.0037442627362906933\n",
      "Epoch 823, Loss: 0.026899555698037148, Final Batch Loss: 0.01884300448000431\n",
      "Epoch 824, Loss: 0.005434291670098901, Final Batch Loss: 0.003784448839724064\n",
      "Epoch 825, Loss: 0.010151396971195936, Final Batch Loss: 0.007945352233946323\n",
      "Epoch 826, Loss: 0.007526899047661573, Final Batch Loss: 0.0005376444314606488\n",
      "Epoch 827, Loss: 0.01062754518352449, Final Batch Loss: 0.0036108007188886404\n",
      "Epoch 828, Loss: 0.01293779001571238, Final Batch Loss: 0.003890377702191472\n",
      "Epoch 829, Loss: 0.01614605449140072, Final Batch Loss: 0.009247309528291225\n",
      "Epoch 830, Loss: 0.0077786685433238745, Final Batch Loss: 0.003822554601356387\n",
      "Epoch 831, Loss: 0.012422837782651186, Final Batch Loss: 0.008244159631431103\n",
      "Epoch 832, Loss: 0.0237429307308048, Final Batch Loss: 0.020985182374715805\n",
      "Epoch 833, Loss: 0.012333524879068136, Final Batch Loss: 0.005271607078611851\n",
      "Epoch 834, Loss: 0.01379006588831544, Final Batch Loss: 0.0025651040486991405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835, Loss: 0.015873870346695185, Final Batch Loss: 0.006595337297767401\n",
      "Epoch 836, Loss: 0.011096802074462175, Final Batch Loss: 0.005075701046735048\n",
      "Epoch 837, Loss: 0.010956859681755304, Final Batch Loss: 0.00785726960748434\n",
      "Epoch 838, Loss: 0.011168241035193205, Final Batch Loss: 0.007987621240317822\n",
      "Epoch 839, Loss: 0.004968313383869827, Final Batch Loss: 0.000795261817984283\n",
      "Epoch 840, Loss: 0.015692800749093294, Final Batch Loss: 0.0076021612621843815\n",
      "Epoch 841, Loss: 0.011700916569679976, Final Batch Loss: 0.008764175698161125\n",
      "Epoch 842, Loss: 0.004605248104780912, Final Batch Loss: 0.0015311234164983034\n",
      "Epoch 843, Loss: 0.02712769154459238, Final Batch Loss: 0.006375775672495365\n",
      "Epoch 844, Loss: 0.007783722365275025, Final Batch Loss: 0.006338426843285561\n",
      "Epoch 845, Loss: 0.054412796162068844, Final Batch Loss: 0.0485738143324852\n",
      "Epoch 846, Loss: 0.011532601900398731, Final Batch Loss: 0.006596106104552746\n",
      "Epoch 847, Loss: 0.013983842451125383, Final Batch Loss: 0.005245495121926069\n",
      "Epoch 848, Loss: 0.00828198395902291, Final Batch Loss: 0.0007738061831332743\n",
      "Epoch 849, Loss: 0.006976204691454768, Final Batch Loss: 0.004106526728719473\n",
      "Epoch 850, Loss: 0.008830542443320155, Final Batch Loss: 0.005882405675947666\n",
      "Epoch 851, Loss: 0.07026831433176994, Final Batch Loss: 0.049665916711091995\n",
      "Epoch 852, Loss: 0.03128066682256758, Final Batch Loss: 0.029321037232875824\n",
      "Epoch 853, Loss: 0.030812771059572697, Final Batch Loss: 0.008018906228244305\n",
      "Epoch 854, Loss: 0.010597024112939835, Final Batch Loss: 0.004862976260483265\n",
      "Epoch 855, Loss: 0.013102517928928137, Final Batch Loss: 0.004864322487264872\n",
      "Epoch 856, Loss: 0.01618522754870355, Final Batch Loss: 0.012408190406858921\n",
      "Epoch 857, Loss: 0.023672908544540405, Final Batch Loss: 0.013202803209424019\n",
      "Epoch 858, Loss: 0.012708476628176868, Final Batch Loss: 0.0011101196287199855\n",
      "Epoch 859, Loss: 0.02379452809691429, Final Batch Loss: 0.013205843977630138\n",
      "Epoch 860, Loss: 0.010500066448003054, Final Batch Loss: 0.003035846631973982\n",
      "Epoch 861, Loss: 0.021730199456214905, Final Batch Loss: 0.006119297817349434\n",
      "Epoch 862, Loss: 0.008224283927120268, Final Batch Loss: 0.0006421083817258477\n",
      "Epoch 863, Loss: 0.029615149833261967, Final Batch Loss: 0.020160643383860588\n",
      "Epoch 864, Loss: 0.018687443458475173, Final Batch Loss: 0.0018680390203371644\n",
      "Epoch 865, Loss: 0.01765228435397148, Final Batch Loss: 0.00904532428830862\n",
      "Epoch 866, Loss: 0.01825879141688347, Final Batch Loss: 0.009695944376289845\n",
      "Epoch 867, Loss: 0.01001410884782672, Final Batch Loss: 0.0018042703159153461\n",
      "Epoch 868, Loss: 0.005517445970326662, Final Batch Loss: 0.003412809455767274\n",
      "Epoch 869, Loss: 0.017940526828169823, Final Batch Loss: 0.00820096768438816\n",
      "Epoch 870, Loss: 0.04746536957100034, Final Batch Loss: 0.041391585022211075\n",
      "Epoch 871, Loss: 0.006799705093726516, Final Batch Loss: 0.002986474893987179\n",
      "Epoch 872, Loss: 0.018778696656227112, Final Batch Loss: 0.0057359738275408745\n",
      "Epoch 873, Loss: 0.020945564843714237, Final Batch Loss: 0.01665070652961731\n",
      "Epoch 874, Loss: 0.01685518748126924, Final Batch Loss: 0.0026937087532132864\n",
      "Epoch 875, Loss: 0.007214272627606988, Final Batch Loss: 0.0044890157878398895\n",
      "Epoch 876, Loss: 0.00961917347740382, Final Batch Loss: 0.00107875547837466\n",
      "Epoch 877, Loss: 0.0064186808886006474, Final Batch Loss: 0.0010134597541764379\n",
      "Epoch 878, Loss: 0.009590527042746544, Final Batch Loss: 0.006187572609633207\n",
      "Epoch 879, Loss: 0.007273681403603405, Final Batch Loss: 0.0004066321416758001\n",
      "Epoch 880, Loss: 0.012482835445553064, Final Batch Loss: 0.007903549820184708\n",
      "Epoch 881, Loss: 0.032482560724020004, Final Batch Loss: 0.016839483752846718\n",
      "Epoch 882, Loss: 0.005721974652260542, Final Batch Loss: 0.002352795796468854\n",
      "Epoch 883, Loss: 0.005930438870564103, Final Batch Loss: 0.004260125104337931\n",
      "Epoch 884, Loss: 0.011289285961538553, Final Batch Loss: 0.007310886867344379\n",
      "Epoch 885, Loss: 0.01736096665263176, Final Batch Loss: 0.011608261615037918\n",
      "Epoch 886, Loss: 0.007752295816317201, Final Batch Loss: 0.004486663267016411\n",
      "Epoch 887, Loss: 0.013094258261844516, Final Batch Loss: 0.002706279745325446\n",
      "Epoch 888, Loss: 0.011277475743554533, Final Batch Loss: 0.001302997930906713\n",
      "Epoch 889, Loss: 0.01054233149625361, Final Batch Loss: 0.0022999851498752832\n",
      "Epoch 890, Loss: 0.017304103821516037, Final Batch Loss: 0.014417562633752823\n",
      "Epoch 891, Loss: 0.008188629755750299, Final Batch Loss: 0.005773880518972874\n",
      "Epoch 892, Loss: 0.004096327931620181, Final Batch Loss: 0.002241896465420723\n",
      "Epoch 893, Loss: 0.008062841603532434, Final Batch Loss: 0.002930013695731759\n",
      "Epoch 894, Loss: 0.014191394438967109, Final Batch Loss: 0.002854801481589675\n",
      "Epoch 895, Loss: 0.01675264909863472, Final Batch Loss: 0.010813974775373936\n",
      "Epoch 896, Loss: 0.006455240887589753, Final Batch Loss: 0.001006706734187901\n",
      "Epoch 897, Loss: 0.012794143403880298, Final Batch Loss: 0.001691022771410644\n",
      "Epoch 898, Loss: 0.010799146257340908, Final Batch Loss: 0.004884811118245125\n",
      "Epoch 899, Loss: 0.016358145512640476, Final Batch Loss: 0.00247980747371912\n",
      "Epoch 900, Loss: 0.009273545583710074, Final Batch Loss: 0.0021519402507692575\n",
      "Epoch 901, Loss: 0.007633853238075972, Final Batch Loss: 0.003150381613522768\n",
      "Epoch 902, Loss: 0.007031051907688379, Final Batch Loss: 0.0036566327325999737\n",
      "Epoch 903, Loss: 0.022883085999637842, Final Batch Loss: 0.017403310164809227\n",
      "Epoch 904, Loss: 0.010615705279633403, Final Batch Loss: 0.00730106933042407\n",
      "Epoch 905, Loss: 0.08275144640356302, Final Batch Loss: 0.07883400470018387\n",
      "Epoch 906, Loss: 0.011906725354492664, Final Batch Loss: 0.005043426062911749\n",
      "Epoch 907, Loss: 0.007931943284347653, Final Batch Loss: 0.002810753183439374\n",
      "Epoch 908, Loss: 0.005454630125313997, Final Batch Loss: 0.001869011903181672\n",
      "Epoch 909, Loss: 0.016549015417695045, Final Batch Loss: 0.006174891255795956\n",
      "Epoch 910, Loss: 0.014893336221575737, Final Batch Loss: 0.009000351652503014\n",
      "Epoch 911, Loss: 0.007013419643044472, Final Batch Loss: 0.003761537140235305\n",
      "Epoch 912, Loss: 0.005218002595938742, Final Batch Loss: 0.0017155370442196727\n",
      "Epoch 913, Loss: 0.01021043537184596, Final Batch Loss: 0.004003169480711222\n",
      "Epoch 914, Loss: 0.007791007868945599, Final Batch Loss: 0.004531422164291143\n",
      "Epoch 915, Loss: 0.010951229487545788, Final Batch Loss: 0.0012877342524006963\n",
      "Epoch 916, Loss: 0.014824038604274392, Final Batch Loss: 0.01125386729836464\n",
      "Epoch 917, Loss: 0.02183433808386326, Final Batch Loss: 0.01710594817996025\n",
      "Epoch 918, Loss: 0.017212657490745187, Final Batch Loss: 0.014917753636837006\n",
      "Epoch 919, Loss: 0.01603906776290387, Final Batch Loss: 0.0012737567303702235\n",
      "Epoch 920, Loss: 0.01127759600058198, Final Batch Loss: 0.006310489494353533\n",
      "Epoch 921, Loss: 0.03029553685337305, Final Batch Loss: 0.02190428413450718\n",
      "Epoch 922, Loss: 0.013633228605613112, Final Batch Loss: 0.0008417533244937658\n",
      "Epoch 923, Loss: 0.013920188415795565, Final Batch Loss: 0.008696655742824078\n",
      "Epoch 924, Loss: 0.019695022143423557, Final Batch Loss: 0.016162650659680367\n",
      "Epoch 925, Loss: 0.013385394588112831, Final Batch Loss: 0.0026838332414627075\n",
      "Epoch 926, Loss: 0.008158916607499123, Final Batch Loss: 0.004517770372331142\n",
      "Epoch 927, Loss: 0.022943923249840736, Final Batch Loss: 0.0014774426817893982\n",
      "Epoch 928, Loss: 0.02629057550802827, Final Batch Loss: 0.020165780559182167\n",
      "Epoch 929, Loss: 0.029046874959021807, Final Batch Loss: 0.023566169664263725\n",
      "Epoch 930, Loss: 0.005377457186114043, Final Batch Loss: 0.004530870355665684\n",
      "Epoch 931, Loss: 0.018675566650927067, Final Batch Loss: 0.00253965612500906\n",
      "Epoch 932, Loss: 0.015722401440143585, Final Batch Loss: 0.011740272864699364\n",
      "Epoch 933, Loss: 0.01681991759687662, Final Batch Loss: 0.009276566095650196\n",
      "Epoch 934, Loss: 0.01478390651755035, Final Batch Loss: 0.0012338792439550161\n",
      "Epoch 935, Loss: 0.04680744744837284, Final Batch Loss: 0.03081807680428028\n",
      "Epoch 936, Loss: 0.021102406084537506, Final Batch Loss: 0.0024819131940603256\n",
      "Epoch 937, Loss: 0.014281780691817403, Final Batch Loss: 0.003743462497368455\n",
      "Epoch 938, Loss: 0.03153419028967619, Final Batch Loss: 0.00239426176995039\n",
      "Epoch 939, Loss: 0.028681783471256495, Final Batch Loss: 0.0037500360049307346\n",
      "Epoch 940, Loss: 0.022605151403695345, Final Batch Loss: 0.006338958162814379\n",
      "Epoch 941, Loss: 0.012861207593232393, Final Batch Loss: 0.004916264209896326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 942, Loss: 0.01690532616339624, Final Batch Loss: 0.0012088620569556952\n",
      "Epoch 943, Loss: 0.03567110002040863, Final Batch Loss: 0.0031419433653354645\n",
      "Epoch 944, Loss: 0.026801616419106722, Final Batch Loss: 0.02039545401930809\n",
      "Epoch 945, Loss: 0.02568953763693571, Final Batch Loss: 0.02180521748960018\n",
      "Epoch 946, Loss: 0.015899390447884798, Final Batch Loss: 0.005462138447910547\n",
      "Epoch 947, Loss: 0.011786133050918579, Final Batch Loss: 0.0018673380836844444\n",
      "Epoch 948, Loss: 0.01796020194888115, Final Batch Loss: 0.015483676455914974\n",
      "Epoch 949, Loss: 0.017294556833803654, Final Batch Loss: 0.0011993730440735817\n",
      "Epoch 950, Loss: 0.004152582958340645, Final Batch Loss: 0.002133037894964218\n",
      "Epoch 951, Loss: 0.00562270893715322, Final Batch Loss: 0.0026721132453531027\n",
      "Epoch 952, Loss: 0.0370044254232198, Final Batch Loss: 0.034351896494627\n",
      "Epoch 953, Loss: 0.02878747321665287, Final Batch Loss: 0.02147822268307209\n",
      "Epoch 954, Loss: 0.021708061918616295, Final Batch Loss: 0.0103871189057827\n",
      "Epoch 955, Loss: 0.005344869336113334, Final Batch Loss: 0.0026185642927885056\n",
      "Epoch 956, Loss: 0.007800213526934385, Final Batch Loss: 0.0028524519875645638\n",
      "Epoch 957, Loss: 0.0063525596633553505, Final Batch Loss: 0.0027710294816643\n",
      "Epoch 958, Loss: 0.031327041098847985, Final Batch Loss: 0.027899544686079025\n",
      "Epoch 959, Loss: 0.019971496425569057, Final Batch Loss: 0.01020016148686409\n",
      "Epoch 960, Loss: 0.019593324977904558, Final Batch Loss: 0.013063709251582623\n",
      "Epoch 961, Loss: 0.007347794016823173, Final Batch Loss: 0.003023583209142089\n",
      "Epoch 962, Loss: 0.008632396347820759, Final Batch Loss: 0.0019898610189557076\n",
      "Epoch 963, Loss: 0.010166999301873147, Final Batch Loss: 0.0011867958819493651\n",
      "Epoch 964, Loss: 0.011115586734376848, Final Batch Loss: 0.009607868269085884\n",
      "Epoch 965, Loss: 0.017928721848875284, Final Batch Loss: 0.004903689492493868\n",
      "Epoch 966, Loss: 0.026124015916138887, Final Batch Loss: 0.02367548458278179\n",
      "Epoch 967, Loss: 0.013721029739826918, Final Batch Loss: 0.0012655952014029026\n",
      "Epoch 968, Loss: 0.007908537751063704, Final Batch Loss: 0.0029258897993713617\n",
      "Epoch 969, Loss: 0.007631559972651303, Final Batch Loss: 0.0016307808691635728\n",
      "Epoch 970, Loss: 0.033385541290044785, Final Batch Loss: 0.017002852633595467\n",
      "Epoch 971, Loss: 0.015285309171304107, Final Batch Loss: 0.003773346310481429\n",
      "Epoch 972, Loss: 0.009301437996327877, Final Batch Loss: 0.006834130734205246\n",
      "Epoch 973, Loss: 0.009450339013710618, Final Batch Loss: 0.0072881244122982025\n",
      "Epoch 974, Loss: 0.0064657339826226234, Final Batch Loss: 0.002038154285401106\n",
      "Epoch 975, Loss: 0.0109215856064111, Final Batch Loss: 0.0031926517840474844\n",
      "Epoch 976, Loss: 0.02267887583002448, Final Batch Loss: 0.019858533516526222\n",
      "Epoch 977, Loss: 0.010788029758259654, Final Batch Loss: 0.0017908893059939146\n",
      "Epoch 978, Loss: 0.009248070884495974, Final Batch Loss: 0.003803740255534649\n",
      "Epoch 979, Loss: 0.008599099004641175, Final Batch Loss: 0.0060657840222120285\n",
      "Epoch 980, Loss: 0.010674074292182922, Final Batch Loss: 0.007274925243109465\n",
      "Epoch 981, Loss: 0.026749235577881336, Final Batch Loss: 0.015579014085233212\n",
      "Epoch 982, Loss: 0.004627957416232675, Final Batch Loss: 0.003910507541149855\n",
      "Epoch 983, Loss: 0.005005544458981603, Final Batch Loss: 0.0006812507635913789\n",
      "Epoch 984, Loss: 0.006751982495188713, Final Batch Loss: 0.00275225518271327\n",
      "Epoch 985, Loss: 0.002832185593433678, Final Batch Loss: 0.0007963856915012002\n",
      "Epoch 986, Loss: 0.008648531744256616, Final Batch Loss: 0.004755302332341671\n",
      "Epoch 987, Loss: 0.004347080714069307, Final Batch Loss: 0.0009943622862920165\n",
      "Epoch 988, Loss: 0.00485442706849426, Final Batch Loss: 0.0015779774403199553\n",
      "Epoch 989, Loss: 0.00801059982040897, Final Batch Loss: 0.00740564102306962\n",
      "Epoch 990, Loss: 0.002137303294148296, Final Batch Loss: 0.0007566407439298928\n",
      "Epoch 991, Loss: 0.012930831930134445, Final Batch Loss: 0.0009099208400584757\n",
      "Epoch 992, Loss: 0.015551993623375893, Final Batch Loss: 0.004887234419584274\n",
      "Epoch 993, Loss: 0.003430803306400776, Final Batch Loss: 0.001696586492471397\n",
      "Epoch 994, Loss: 0.0036108491476625204, Final Batch Loss: 0.0018975089769810438\n",
      "Epoch 995, Loss: 0.007392438943497837, Final Batch Loss: 0.00625966489315033\n",
      "Epoch 996, Loss: 0.007579165510833263, Final Batch Loss: 0.0019572842866182327\n",
      "Epoch 997, Loss: 0.00901472195982933, Final Batch Loss: 0.004565830808132887\n",
      "Epoch 998, Loss: 0.0026421527145430446, Final Batch Loss: 0.0014025709824636579\n",
      "Epoch 999, Loss: 0.005111203179694712, Final Batch Loss: 0.0036071916110813618\n",
      "Epoch 1000, Loss: 0.0035211952636018395, Final Batch Loss: 0.0020645700860768557\n",
      "Epoch 1001, Loss: 0.008468143409118056, Final Batch Loss: 0.0027820297982543707\n",
      "Epoch 1002, Loss: 0.00395647925324738, Final Batch Loss: 0.0007046789396554232\n",
      "Epoch 1003, Loss: 0.03735084063373506, Final Batch Loss: 0.03390555828809738\n",
      "Epoch 1004, Loss: 0.005997257889248431, Final Batch Loss: 0.00434649595990777\n",
      "Epoch 1005, Loss: 0.0198955429950729, Final Batch Loss: 0.01895804889500141\n",
      "Epoch 1006, Loss: 0.00586313265375793, Final Batch Loss: 0.004161008168011904\n",
      "Epoch 1007, Loss: 0.005322055658325553, Final Batch Loss: 0.0035759275779128075\n",
      "Epoch 1008, Loss: 0.011439209338277578, Final Batch Loss: 0.004031606018543243\n",
      "Epoch 1009, Loss: 0.012935157399624586, Final Batch Loss: 0.005603361874818802\n",
      "Epoch 1010, Loss: 0.02483129594475031, Final Batch Loss: 0.0026675695553421974\n",
      "Epoch 1011, Loss: 0.007675181375816464, Final Batch Loss: 0.0013839260209351778\n",
      "Epoch 1012, Loss: 0.006194934365339577, Final Batch Loss: 0.0008403427200391889\n",
      "Epoch 1013, Loss: 0.005474866600707173, Final Batch Loss: 0.003390902653336525\n",
      "Epoch 1014, Loss: 0.02171879354864359, Final Batch Loss: 0.008661283180117607\n",
      "Epoch 1015, Loss: 0.028487551724538207, Final Batch Loss: 0.002831598510965705\n",
      "Epoch 1016, Loss: 0.005030157160945237, Final Batch Loss: 0.0013189964229241014\n",
      "Epoch 1017, Loss: 0.008004405302926898, Final Batch Loss: 0.0025035568978637457\n",
      "Epoch 1018, Loss: 0.017276305181439966, Final Batch Loss: 0.0006273644394241273\n",
      "Epoch 1019, Loss: 0.016187630244530737, Final Batch Loss: 0.014501857571303844\n",
      "Epoch 1020, Loss: 0.006078154314309359, Final Batch Loss: 0.002833262085914612\n",
      "Epoch 1021, Loss: 0.0038400215562433004, Final Batch Loss: 0.002209703903645277\n",
      "Epoch 1022, Loss: 0.0022098616464063525, Final Batch Loss: 0.0005626180209219456\n",
      "Epoch 1023, Loss: 0.004700089048128575, Final Batch Loss: 0.0005391721497289836\n",
      "Epoch 1024, Loss: 0.0068696856033056974, Final Batch Loss: 0.004163805861026049\n",
      "Epoch 1025, Loss: 0.011679925955832005, Final Batch Loss: 0.00415152357891202\n",
      "Epoch 1026, Loss: 0.03394751250743866, Final Batch Loss: 0.017112236469984055\n",
      "Epoch 1027, Loss: 0.0481336428783834, Final Batch Loss: 0.04277855530381203\n",
      "Epoch 1028, Loss: 0.014995157020166516, Final Batch Loss: 0.0037218418437987566\n",
      "Epoch 1029, Loss: 0.0048578770365566015, Final Batch Loss: 0.002361286198720336\n",
      "Epoch 1030, Loss: 0.029332694713957608, Final Batch Loss: 0.02781560830771923\n",
      "Epoch 1031, Loss: 0.004953811061568558, Final Batch Loss: 0.0006116932490840554\n",
      "Epoch 1032, Loss: 0.019419735996052623, Final Batch Loss: 0.017537757754325867\n",
      "Epoch 1033, Loss: 0.006696843542158604, Final Batch Loss: 0.003204463515430689\n",
      "Epoch 1034, Loss: 0.006059648469090462, Final Batch Loss: 0.002501965733245015\n",
      "Epoch 1035, Loss: 0.028590841218829155, Final Batch Loss: 0.021137701347470284\n",
      "Epoch 1036, Loss: 0.021629889961332083, Final Batch Loss: 0.005604892503470182\n",
      "Epoch 1037, Loss: 0.017532159574329853, Final Batch Loss: 0.005456600338220596\n",
      "Epoch 1038, Loss: 0.0038158722454681993, Final Batch Loss: 0.0018736586207523942\n",
      "Epoch 1039, Loss: 0.004356104996986687, Final Batch Loss: 0.0014394627651199698\n",
      "Epoch 1040, Loss: 0.0048539567505940795, Final Batch Loss: 0.0029488131403923035\n",
      "Epoch 1041, Loss: 0.03434495907276869, Final Batch Loss: 0.026481598615646362\n",
      "Epoch 1042, Loss: 0.0026969293248839676, Final Batch Loss: 0.0018256553448736668\n",
      "Epoch 1043, Loss: 0.026579550467431545, Final Batch Loss: 0.0225361417979002\n",
      "Epoch 1044, Loss: 0.014979911269620061, Final Batch Loss: 0.0028723946306854486\n",
      "Epoch 1045, Loss: 0.006254957523196936, Final Batch Loss: 0.0035034604370594025\n",
      "Epoch 1046, Loss: 0.008401602506637573, Final Batch Loss: 0.0014353315345942974\n",
      "Epoch 1047, Loss: 0.003234518924728036, Final Batch Loss: 0.0007209738250821829\n",
      "Epoch 1048, Loss: 0.016017954563722014, Final Batch Loss: 0.002147168619558215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1049, Loss: 0.035668350057676435, Final Batch Loss: 0.03394391015172005\n",
      "Epoch 1050, Loss: 0.013901514117605984, Final Batch Loss: 0.0018809038447216153\n",
      "Epoch 1051, Loss: 0.002148399595171213, Final Batch Loss: 0.0011274507269263268\n",
      "Epoch 1052, Loss: 0.0026129168982151896, Final Batch Loss: 0.00038826573290862143\n",
      "Epoch 1053, Loss: 0.006792247528210282, Final Batch Loss: 0.0013019477482885122\n",
      "Epoch 1054, Loss: 0.006599356420338154, Final Batch Loss: 0.004153784364461899\n",
      "Epoch 1055, Loss: 0.018181084655225277, Final Batch Loss: 0.004195346496999264\n",
      "Epoch 1056, Loss: 0.009873857721686363, Final Batch Loss: 0.006314845290035009\n",
      "Epoch 1057, Loss: 0.004760790412547067, Final Batch Loss: 0.0004273427475709468\n",
      "Epoch 1058, Loss: 0.010984688764438033, Final Batch Loss: 0.0026310819666832685\n",
      "Epoch 1059, Loss: 0.0023653116077184677, Final Batch Loss: 0.000870365765877068\n",
      "Epoch 1060, Loss: 0.003849674598313868, Final Batch Loss: 0.0008293596329167485\n",
      "Epoch 1061, Loss: 0.01269196206703782, Final Batch Loss: 0.0023522614501416683\n",
      "Epoch 1062, Loss: 0.004511263396125287, Final Batch Loss: 0.0007791427779011428\n",
      "Epoch 1063, Loss: 0.016250339336693287, Final Batch Loss: 0.009065750055015087\n",
      "Epoch 1064, Loss: 0.006946665816940367, Final Batch Loss: 0.0011544596636667848\n",
      "Epoch 1065, Loss: 0.01844885852187872, Final Batch Loss: 0.00901775248348713\n",
      "Epoch 1066, Loss: 0.007146239280700684, Final Batch Loss: 0.0030261268839240074\n",
      "Epoch 1067, Loss: 0.006899817628436722, Final Batch Loss: 0.00021737093629781157\n",
      "Epoch 1068, Loss: 0.02881988533772528, Final Batch Loss: 0.02711310237646103\n",
      "Epoch 1069, Loss: 0.022258388809859753, Final Batch Loss: 0.019125672057271004\n",
      "Epoch 1070, Loss: 0.0013818233856000006, Final Batch Loss: 0.0005723692593164742\n",
      "Epoch 1071, Loss: 0.0037810233188793063, Final Batch Loss: 0.002153758192434907\n",
      "Epoch 1072, Loss: 0.008295435458421707, Final Batch Loss: 0.0029934230260550976\n",
      "Epoch 1073, Loss: 0.01012395741418004, Final Batch Loss: 0.0080272126942873\n",
      "Epoch 1074, Loss: 0.011534085962921381, Final Batch Loss: 0.008379545994102955\n",
      "Epoch 1075, Loss: 0.008620961802080274, Final Batch Loss: 0.006170631852000952\n",
      "Epoch 1076, Loss: 0.004932288662530482, Final Batch Loss: 0.0019134922185912728\n",
      "Epoch 1077, Loss: 0.012444861116819084, Final Batch Loss: 0.0018616466550156474\n",
      "Epoch 1078, Loss: 0.007427367614582181, Final Batch Loss: 0.0028724016156047583\n",
      "Epoch 1079, Loss: 0.008227167534641922, Final Batch Loss: 0.0014602652518078685\n",
      "Epoch 1080, Loss: 0.004197596339508891, Final Batch Loss: 0.0020474346820265055\n",
      "Epoch 1081, Loss: 0.004762101569212973, Final Batch Loss: 0.004036803729832172\n",
      "Epoch 1082, Loss: 0.00223925564205274, Final Batch Loss: 0.0006830394850112498\n",
      "Epoch 1083, Loss: 0.015466684388229623, Final Batch Loss: 0.00030604275525547564\n",
      "Epoch 1084, Loss: 0.003715158556587994, Final Batch Loss: 0.0019450682448223233\n",
      "Epoch 1085, Loss: 0.006607640068978071, Final Batch Loss: 0.004540577065199614\n",
      "Epoch 1086, Loss: 0.008861632086336613, Final Batch Loss: 0.0007834304124116898\n",
      "Epoch 1087, Loss: 0.005638601025566459, Final Batch Loss: 0.001828446052968502\n",
      "Epoch 1088, Loss: 0.0039018188836053014, Final Batch Loss: 0.0012787248706445098\n",
      "Epoch 1089, Loss: 0.016914142936002463, Final Batch Loss: 0.016115432605147362\n",
      "Epoch 1090, Loss: 0.004803810326848179, Final Batch Loss: 0.0007250630878843367\n",
      "Epoch 1091, Loss: 0.0019953151349909604, Final Batch Loss: 0.000617586134467274\n",
      "Epoch 1092, Loss: 0.015497126441914588, Final Batch Loss: 0.0003293778863735497\n",
      "Epoch 1093, Loss: 0.004258563043549657, Final Batch Loss: 0.00295932125300169\n",
      "Epoch 1094, Loss: 0.0037985292728990316, Final Batch Loss: 0.0020241164602339268\n",
      "Epoch 1095, Loss: 0.009405360091477633, Final Batch Loss: 0.003980002366006374\n",
      "Epoch 1096, Loss: 0.009583606501109898, Final Batch Loss: 0.0018778779776766896\n",
      "Epoch 1097, Loss: 0.002081823244225234, Final Batch Loss: 0.0005600890726782382\n",
      "Epoch 1098, Loss: 0.0017575377714820206, Final Batch Loss: 0.0006889072828926146\n",
      "Epoch 1099, Loss: 0.0013950834982097149, Final Batch Loss: 0.001020411029458046\n",
      "Epoch 1100, Loss: 0.0014936100342310965, Final Batch Loss: 0.00045474228681996465\n",
      "Epoch 1101, Loss: 0.009200066095218062, Final Batch Loss: 0.003365978831425309\n",
      "Epoch 1102, Loss: 0.0039530760841444135, Final Batch Loss: 0.002357607241719961\n",
      "Epoch 1103, Loss: 0.02135047037154436, Final Batch Loss: 0.004896500147879124\n",
      "Epoch 1104, Loss: 0.018357277614995837, Final Batch Loss: 0.014676778577268124\n",
      "Epoch 1105, Loss: 0.01039849710650742, Final Batch Loss: 0.00907113403081894\n",
      "Epoch 1106, Loss: 0.006855112733319402, Final Batch Loss: 0.004164459183812141\n",
      "Epoch 1107, Loss: 0.05885197827592492, Final Batch Loss: 0.052103616297245026\n",
      "Epoch 1108, Loss: 0.0035715525154955685, Final Batch Loss: 0.0006719639641232789\n",
      "Epoch 1109, Loss: 0.020498936995863914, Final Batch Loss: 0.0007842946797609329\n",
      "Epoch 1110, Loss: 0.0061019512941129506, Final Batch Loss: 0.0005153434467501938\n",
      "Epoch 1111, Loss: 0.01926668349187821, Final Batch Loss: 0.01732574962079525\n",
      "Epoch 1112, Loss: 0.014916144544258714, Final Batch Loss: 0.011776656843721867\n",
      "Epoch 1113, Loss: 0.035624452866613865, Final Batch Loss: 0.027719929814338684\n",
      "Epoch 1114, Loss: 0.01662372681312263, Final Batch Loss: 0.01376761682331562\n",
      "Epoch 1115, Loss: 0.0025069378316402435, Final Batch Loss: 0.0012863726587966084\n",
      "Epoch 1116, Loss: 0.0035769451642408967, Final Batch Loss: 0.0005365092074498534\n",
      "Epoch 1117, Loss: 0.0023543783463537693, Final Batch Loss: 0.00044862343929708004\n",
      "Epoch 1118, Loss: 0.013075432041659951, Final Batch Loss: 0.0009635270107537508\n",
      "Epoch 1119, Loss: 0.02157188835553825, Final Batch Loss: 0.019161313772201538\n",
      "Epoch 1120, Loss: 0.006706473883241415, Final Batch Loss: 0.004687913693487644\n",
      "Epoch 1121, Loss: 0.007477631559595466, Final Batch Loss: 0.006490575149655342\n",
      "Epoch 1122, Loss: 0.003742820117622614, Final Batch Loss: 0.0011573906522244215\n",
      "Epoch 1123, Loss: 0.003026162274181843, Final Batch Loss: 0.0005458269733935595\n",
      "Epoch 1124, Loss: 0.005557099706493318, Final Batch Loss: 0.004983332473784685\n",
      "Epoch 1125, Loss: 0.005151496501639485, Final Batch Loss: 0.0009282778482884169\n",
      "Epoch 1126, Loss: 0.004462864366360009, Final Batch Loss: 0.002694325288757682\n",
      "Epoch 1127, Loss: 0.00510180089622736, Final Batch Loss: 0.002863904694095254\n",
      "Epoch 1128, Loss: 0.00336345168761909, Final Batch Loss: 0.0011666661594063044\n",
      "Epoch 1129, Loss: 0.009447083808481693, Final Batch Loss: 0.0010266313329339027\n",
      "Epoch 1130, Loss: 0.005355417495593429, Final Batch Loss: 0.0022331608925014734\n",
      "Epoch 1131, Loss: 0.0019260392291471362, Final Batch Loss: 0.0010278740664944053\n",
      "Epoch 1132, Loss: 0.009955123183317482, Final Batch Loss: 0.0004998455988243222\n",
      "Epoch 1133, Loss: 0.009022621088661253, Final Batch Loss: 0.0009778799721971154\n",
      "Epoch 1134, Loss: 0.00367929064668715, Final Batch Loss: 0.0017971456982195377\n",
      "Epoch 1135, Loss: 0.006574279512278736, Final Batch Loss: 0.0016386372735723853\n",
      "Epoch 1136, Loss: 0.003776849596761167, Final Batch Loss: 0.003088699420914054\n",
      "Epoch 1137, Loss: 0.009182716254144907, Final Batch Loss: 0.003332957159727812\n",
      "Epoch 1138, Loss: 0.0016000789473764598, Final Batch Loss: 0.000464466807898134\n",
      "Epoch 1139, Loss: 0.012950439646374434, Final Batch Loss: 0.000808602839242667\n",
      "Epoch 1140, Loss: 0.008956489153206348, Final Batch Loss: 0.0016646357253193855\n",
      "Epoch 1141, Loss: 0.012312866922002286, Final Batch Loss: 0.0007029829430393875\n",
      "Epoch 1142, Loss: 0.004875351558439434, Final Batch Loss: 0.0030571874231100082\n",
      "Epoch 1143, Loss: 0.002562281908467412, Final Batch Loss: 0.0007917960174381733\n",
      "Epoch 1144, Loss: 0.0013040078920312226, Final Batch Loss: 0.0005597480922006071\n",
      "Epoch 1145, Loss: 0.014187241438776255, Final Batch Loss: 0.011861531063914299\n",
      "Epoch 1146, Loss: 0.007337627233937383, Final Batch Loss: 0.006019502878189087\n",
      "Epoch 1147, Loss: 0.005619893549010158, Final Batch Loss: 0.003563649021089077\n",
      "Epoch 1148, Loss: 0.00427421648055315, Final Batch Loss: 0.0023874177131801844\n",
      "Epoch 1149, Loss: 0.002040609484538436, Final Batch Loss: 0.0014760199701413512\n",
      "Epoch 1150, Loss: 0.033903858507983387, Final Batch Loss: 0.0017235976411029696\n",
      "Epoch 1151, Loss: 0.001779454411007464, Final Batch Loss: 0.001018649316392839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1152, Loss: 0.001896055822726339, Final Batch Loss: 0.0008937902166508138\n",
      "Epoch 1153, Loss: 0.0086308887694031, Final Batch Loss: 0.004990457557141781\n",
      "Epoch 1154, Loss: 0.006901534972712398, Final Batch Loss: 0.0058180359192192554\n",
      "Epoch 1155, Loss: 0.0012724464177154005, Final Batch Loss: 0.0005129502969793975\n",
      "Epoch 1156, Loss: 0.004055430996231735, Final Batch Loss: 0.0006921988679096103\n",
      "Epoch 1157, Loss: 0.0146612455137074, Final Batch Loss: 0.009871533140540123\n",
      "Epoch 1158, Loss: 0.0021420204429887235, Final Batch Loss: 0.0001802269252948463\n",
      "Epoch 1159, Loss: 0.0016220667166635394, Final Batch Loss: 0.00041222875006496906\n",
      "Epoch 1160, Loss: 0.007842306047677994, Final Batch Loss: 0.0037898048758506775\n",
      "Epoch 1161, Loss: 0.0015645887469872832, Final Batch Loss: 0.0004792812978848815\n",
      "Epoch 1162, Loss: 0.02018259558826685, Final Batch Loss: 0.01880522072315216\n",
      "Epoch 1163, Loss: 0.002311518299393356, Final Batch Loss: 0.00041692215017974377\n",
      "Epoch 1164, Loss: 0.00569601880852133, Final Batch Loss: 0.000594489392824471\n",
      "Epoch 1165, Loss: 0.004410456400364637, Final Batch Loss: 0.002165796235203743\n",
      "Epoch 1166, Loss: 0.002833856735378504, Final Batch Loss: 0.0013090692227706313\n",
      "Epoch 1167, Loss: 0.003409988945350051, Final Batch Loss: 0.0025357892736792564\n",
      "Epoch 1168, Loss: 0.0006870737997815013, Final Batch Loss: 0.0001688558841124177\n",
      "Epoch 1169, Loss: 0.000692987785441801, Final Batch Loss: 0.00024942291202023625\n",
      "Epoch 1170, Loss: 0.0024615359725430608, Final Batch Loss: 0.0002383360406383872\n",
      "Epoch 1171, Loss: 0.005052782595157623, Final Batch Loss: 0.001091532874852419\n",
      "Epoch 1172, Loss: 0.003454313729889691, Final Batch Loss: 0.0022350619547069073\n",
      "Epoch 1173, Loss: 0.003048284095712006, Final Batch Loss: 0.0012410382041707635\n",
      "Epoch 1174, Loss: 0.008626337395980954, Final Batch Loss: 0.007224010769277811\n",
      "Epoch 1175, Loss: 0.002932058530859649, Final Batch Loss: 0.0009629029082134366\n",
      "Epoch 1176, Loss: 0.0015981109463609755, Final Batch Loss: 0.0003458270221017301\n",
      "Epoch 1177, Loss: 0.003534032846800983, Final Batch Loss: 0.0031410008668899536\n",
      "Epoch 1178, Loss: 0.006822743394877762, Final Batch Loss: 0.0005206753849051893\n",
      "Epoch 1179, Loss: 0.007986761629581451, Final Batch Loss: 0.006945149507373571\n",
      "Epoch 1180, Loss: 0.00402682222193107, Final Batch Loss: 0.000530894089024514\n",
      "Epoch 1181, Loss: 0.011159327230416238, Final Batch Loss: 0.009251756593585014\n",
      "Epoch 1182, Loss: 0.0026413039304316044, Final Batch Loss: 0.0012376777594909072\n",
      "Epoch 1183, Loss: 0.006885451904963702, Final Batch Loss: 0.006354377139359713\n",
      "Epoch 1184, Loss: 0.002724769408814609, Final Batch Loss: 0.0014920819085091352\n",
      "Epoch 1185, Loss: 0.0022044661454856396, Final Batch Loss: 0.0014576069079339504\n",
      "Epoch 1186, Loss: 0.00284122908487916, Final Batch Loss: 0.0015913743991404772\n",
      "Epoch 1187, Loss: 0.008790694526396692, Final Batch Loss: 0.007385998498648405\n",
      "Epoch 1188, Loss: 0.0019062925421167165, Final Batch Loss: 0.00043052484397776425\n",
      "Epoch 1189, Loss: 0.0037449070950970054, Final Batch Loss: 0.002352772280573845\n",
      "Epoch 1190, Loss: 0.005265005631372333, Final Batch Loss: 0.0032796310260891914\n",
      "Epoch 1191, Loss: 0.002996027353219688, Final Batch Loss: 0.001189262024126947\n",
      "Epoch 1192, Loss: 0.03222703794017434, Final Batch Loss: 0.00459417374804616\n",
      "Epoch 1193, Loss: 0.007252843817695975, Final Batch Loss: 0.004006318282335997\n",
      "Epoch 1194, Loss: 0.019842146430164576, Final Batch Loss: 0.015607044100761414\n",
      "Epoch 1195, Loss: 0.010355768346926197, Final Batch Loss: 0.009963330812752247\n",
      "Epoch 1196, Loss: 0.01019127608742565, Final Batch Loss: 0.00180659384932369\n",
      "Epoch 1197, Loss: 0.0025604813708923757, Final Batch Loss: 0.001604410819709301\n",
      "Epoch 1198, Loss: 0.002596346545033157, Final Batch Loss: 0.0020730942487716675\n",
      "Epoch 1199, Loss: 0.0017686726641841233, Final Batch Loss: 0.0012556668370962143\n",
      "Epoch 1200, Loss: 0.005958095425739884, Final Batch Loss: 0.003507028566673398\n",
      "Epoch 1201, Loss: 0.003649034770205617, Final Batch Loss: 0.0008561962749809027\n",
      "Epoch 1202, Loss: 0.001993426092667505, Final Batch Loss: 0.00029676835401915014\n",
      "Epoch 1203, Loss: 0.013467990094795823, Final Batch Loss: 0.0017347477842122316\n",
      "Epoch 1204, Loss: 0.012201422825455666, Final Batch Loss: 0.008869490586221218\n",
      "Epoch 1205, Loss: 0.010405887383967638, Final Batch Loss: 0.0051069119945168495\n",
      "Epoch 1206, Loss: 0.007348193321377039, Final Batch Loss: 0.006737119518220425\n",
      "Epoch 1207, Loss: 0.008370596915483475, Final Batch Loss: 0.005502472165971994\n",
      "Epoch 1208, Loss: 0.002408767002634704, Final Batch Loss: 0.0006915046833455563\n",
      "Epoch 1209, Loss: 0.003191336872987449, Final Batch Loss: 0.002367079723626375\n",
      "Epoch 1210, Loss: 0.007720933092059568, Final Batch Loss: 0.0003391963255126029\n",
      "Epoch 1211, Loss: 0.0019442671036813408, Final Batch Loss: 0.0003879224241245538\n",
      "Epoch 1212, Loss: 0.010111006238730624, Final Batch Loss: 0.0003870365035254508\n",
      "Epoch 1213, Loss: 0.0028768726624548435, Final Batch Loss: 0.0009607532992959023\n",
      "Epoch 1214, Loss: 0.0028304677689448, Final Batch Loss: 0.0014126040041446686\n",
      "Epoch 1215, Loss: 0.0017347231623716652, Final Batch Loss: 0.0009112311527132988\n",
      "Epoch 1216, Loss: 0.0024779802188277245, Final Batch Loss: 0.0007754017133265734\n",
      "Epoch 1217, Loss: 0.044572196900844574, Final Batch Loss: 0.01611998677253723\n",
      "Epoch 1218, Loss: 0.00654469383880496, Final Batch Loss: 0.005999651271849871\n",
      "Epoch 1219, Loss: 0.0020958472159691155, Final Batch Loss: 0.001166856731288135\n",
      "Epoch 1220, Loss: 0.0029759096796624362, Final Batch Loss: 0.0005199871375225484\n",
      "Epoch 1221, Loss: 0.00454144983086735, Final Batch Loss: 0.003352901665493846\n",
      "Epoch 1222, Loss: 0.006482014898210764, Final Batch Loss: 0.0007789428345859051\n",
      "Epoch 1223, Loss: 0.008625735761597753, Final Batch Loss: 0.00555575592443347\n",
      "Epoch 1224, Loss: 0.004141137818805873, Final Batch Loss: 0.0010485189268365502\n",
      "Epoch 1225, Loss: 0.010258281079586595, Final Batch Loss: 0.0006214915192686021\n",
      "Epoch 1226, Loss: 0.028829452581703663, Final Batch Loss: 0.01804262585937977\n",
      "Epoch 1227, Loss: 0.007341965916566551, Final Batch Loss: 0.0014185019535943866\n",
      "Epoch 1228, Loss: 0.003945050411857665, Final Batch Loss: 0.0012282392708584666\n",
      "Epoch 1229, Loss: 0.021882892993744463, Final Batch Loss: 0.021254772320389748\n",
      "Epoch 1230, Loss: 0.005693730665370822, Final Batch Loss: 0.0029763232450932264\n",
      "Epoch 1231, Loss: 0.043054601876065135, Final Batch Loss: 0.04176003858447075\n",
      "Epoch 1232, Loss: 0.0030790743185207248, Final Batch Loss: 0.0020699412561953068\n",
      "Epoch 1233, Loss: 0.006055339821614325, Final Batch Loss: 0.0043243346735835075\n",
      "Epoch 1234, Loss: 0.001124558097217232, Final Batch Loss: 0.00044957513455301523\n",
      "Epoch 1235, Loss: 0.005817151628434658, Final Batch Loss: 0.0034986664541065693\n",
      "Epoch 1236, Loss: 0.005849685869179666, Final Batch Loss: 0.004187572281807661\n",
      "Epoch 1237, Loss: 0.003691425110446289, Final Batch Loss: 0.00040528064710088074\n",
      "Epoch 1238, Loss: 0.006327836192212999, Final Batch Loss: 0.0005123716546222568\n",
      "Epoch 1239, Loss: 0.036918028024956584, Final Batch Loss: 0.003622188000008464\n",
      "Epoch 1240, Loss: 0.0028900784091092646, Final Batch Loss: 0.0020479552913457155\n",
      "Epoch 1241, Loss: 0.0018728841678239405, Final Batch Loss: 0.0001865951926447451\n",
      "Epoch 1242, Loss: 0.005398462759330869, Final Batch Loss: 0.0008128772024065256\n",
      "Epoch 1243, Loss: 0.010156965960050002, Final Batch Loss: 0.0004876434395555407\n",
      "Epoch 1244, Loss: 0.0623624287545681, Final Batch Loss: 0.030995693057775497\n",
      "Epoch 1245, Loss: 0.009080856922082603, Final Batch Loss: 0.0019092288566753268\n",
      "Epoch 1246, Loss: 0.017835801641922444, Final Batch Loss: 0.0005529617774300277\n",
      "Epoch 1247, Loss: 0.0019049454713240266, Final Batch Loss: 0.0008878903463482857\n",
      "Epoch 1248, Loss: 0.002729322965024039, Final Batch Loss: 0.0022485493682324886\n",
      "Epoch 1249, Loss: 0.004696083255112171, Final Batch Loss: 0.0022315203677862883\n",
      "Epoch 1250, Loss: 0.00946794165065512, Final Batch Loss: 0.00851083267480135\n",
      "Epoch 1251, Loss: 0.0018710838630795479, Final Batch Loss: 0.0006894428515806794\n",
      "Epoch 1252, Loss: 0.004017525410745293, Final Batch Loss: 0.003220881102606654\n",
      "Epoch 1253, Loss: 0.0022258988756220788, Final Batch Loss: 0.0018856142414733768\n",
      "Epoch 1254, Loss: 0.009077781462110579, Final Batch Loss: 0.007373542059212923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1255, Loss: 0.01503409433644265, Final Batch Loss: 0.013965225778520107\n",
      "Epoch 1256, Loss: 0.009193077799864113, Final Batch Loss: 0.0015984728233888745\n",
      "Epoch 1257, Loss: 0.03335593920201063, Final Batch Loss: 0.0010310551151633263\n",
      "Epoch 1258, Loss: 0.002833442558767274, Final Batch Loss: 0.0023566328454762697\n",
      "Epoch 1259, Loss: 0.008147084678057581, Final Batch Loss: 0.00032963656121864915\n",
      "Epoch 1260, Loss: 0.021276508923619986, Final Batch Loss: 0.006430066656321287\n",
      "Epoch 1261, Loss: 0.0018133423873223364, Final Batch Loss: 0.0010607835138216615\n",
      "Epoch 1262, Loss: 0.0032581575214862823, Final Batch Loss: 0.0014771617716178298\n",
      "Epoch 1263, Loss: 0.01083393394947052, Final Batch Loss: 0.007922026328742504\n",
      "Epoch 1264, Loss: 0.010998675366863608, Final Batch Loss: 0.0038212419021874666\n",
      "Epoch 1265, Loss: 0.0072684291517362, Final Batch Loss: 0.0013169700978323817\n",
      "Epoch 1266, Loss: 0.002692541340366006, Final Batch Loss: 0.0016153556061908603\n",
      "Epoch 1267, Loss: 0.004040830419398844, Final Batch Loss: 0.002726037288084626\n",
      "Epoch 1268, Loss: 0.006071034353226423, Final Batch Loss: 0.005446203984320164\n",
      "Epoch 1269, Loss: 0.004552953992970288, Final Batch Loss: 0.0017090648179873824\n",
      "Epoch 1270, Loss: 0.0029727588407695293, Final Batch Loss: 0.0011986043537035584\n",
      "Epoch 1271, Loss: 0.004519227659329772, Final Batch Loss: 0.0017186887562274933\n",
      "Epoch 1272, Loss: 0.0036168269580230117, Final Batch Loss: 0.0011489506578072906\n",
      "Epoch 1273, Loss: 0.001484475185861811, Final Batch Loss: 0.0011212730314582586\n",
      "Epoch 1274, Loss: 0.015384090133011341, Final Batch Loss: 0.012226355262100697\n",
      "Epoch 1275, Loss: 0.0025306380121037364, Final Batch Loss: 0.0006452070083469152\n",
      "Epoch 1276, Loss: 0.0043713312479667366, Final Batch Loss: 0.0007248657639138401\n",
      "Epoch 1277, Loss: 0.0055316638899967074, Final Batch Loss: 0.0005319960182532668\n",
      "Epoch 1278, Loss: 0.01604167849291116, Final Batch Loss: 0.014263205230236053\n",
      "Epoch 1279, Loss: 0.0057711421977728605, Final Batch Loss: 0.0036964749451726675\n",
      "Epoch 1280, Loss: 0.003958709887228906, Final Batch Loss: 0.001804178929887712\n",
      "Epoch 1281, Loss: 0.002709867083467543, Final Batch Loss: 0.0012024830793961883\n",
      "Epoch 1282, Loss: 0.011680347000947222, Final Batch Loss: 0.0002866639697458595\n",
      "Epoch 1283, Loss: 0.011869490845128894, Final Batch Loss: 0.0023265068884938955\n",
      "Epoch 1284, Loss: 0.002156555827241391, Final Batch Loss: 0.0007946042460389435\n",
      "Epoch 1285, Loss: 0.003188989241607487, Final Batch Loss: 0.0021718849893659353\n",
      "Epoch 1286, Loss: 0.01923070685006678, Final Batch Loss: 0.0017502906266599894\n",
      "Epoch 1287, Loss: 0.0005855767230968922, Final Batch Loss: 0.0002532858052290976\n",
      "Epoch 1288, Loss: 0.003487947164103389, Final Batch Loss: 0.0015171142295002937\n",
      "Epoch 1289, Loss: 0.006688463792670518, Final Batch Loss: 0.005945262033492327\n",
      "Epoch 1290, Loss: 0.005223821324761957, Final Batch Loss: 0.0005520684062503278\n",
      "Epoch 1291, Loss: 0.0036894511431455612, Final Batch Loss: 0.0010000753682106733\n",
      "Epoch 1292, Loss: 0.01400646148249507, Final Batch Loss: 0.0006534620188176632\n",
      "Epoch 1293, Loss: 0.004617612692527473, Final Batch Loss: 0.0016237172530964017\n",
      "Epoch 1294, Loss: 0.004431592591572553, Final Batch Loss: 0.000630884722340852\n",
      "Epoch 1295, Loss: 0.002053214411716908, Final Batch Loss: 0.001368109486065805\n",
      "Epoch 1296, Loss: 0.005078700138255954, Final Batch Loss: 0.0020315968431532383\n",
      "Epoch 1297, Loss: 0.0328131950518582, Final Batch Loss: 0.00032108640880323946\n",
      "Epoch 1298, Loss: 0.0038410660345107317, Final Batch Loss: 0.0030272274743765593\n",
      "Epoch 1299, Loss: 0.022965380136156455, Final Batch Loss: 0.00029516141512431204\n",
      "Epoch 1300, Loss: 0.010038330918177962, Final Batch Loss: 0.003759110113605857\n",
      "Epoch 1301, Loss: 0.003661860420834273, Final Batch Loss: 0.00035889208083972335\n",
      "Epoch 1302, Loss: 0.0295112079475075, Final Batch Loss: 0.0027988797519356012\n",
      "Epoch 1303, Loss: 0.007759928790619597, Final Batch Loss: 0.00045951092033647\n",
      "Epoch 1304, Loss: 0.001889927254524082, Final Batch Loss: 0.000762195501010865\n",
      "Epoch 1305, Loss: 0.004208235535770655, Final Batch Loss: 0.0014804189559072256\n",
      "Epoch 1306, Loss: 0.003991521429270506, Final Batch Loss: 0.0024211646523326635\n",
      "Epoch 1307, Loss: 0.004378169542178512, Final Batch Loss: 0.0023826961405575275\n",
      "Epoch 1308, Loss: 0.0011058475356549025, Final Batch Loss: 0.0005086376331746578\n",
      "Epoch 1309, Loss: 0.006031124386936426, Final Batch Loss: 0.002891355659812689\n",
      "Epoch 1310, Loss: 0.00832681474275887, Final Batch Loss: 0.0023943001870065928\n",
      "Epoch 1311, Loss: 0.005538109457120299, Final Batch Loss: 0.0023390266578644514\n",
      "Epoch 1312, Loss: 0.0020973747014068067, Final Batch Loss: 0.001131177064962685\n",
      "Epoch 1313, Loss: 0.050232562818564475, Final Batch Loss: 0.04973183199763298\n",
      "Epoch 1314, Loss: 0.0034228371223434806, Final Batch Loss: 0.0019620335660874844\n",
      "Epoch 1315, Loss: 0.0041188919567503035, Final Batch Loss: 0.0006236530025489628\n",
      "Epoch 1316, Loss: 0.002399752615019679, Final Batch Loss: 0.001892782631330192\n",
      "Epoch 1317, Loss: 0.009240974439308047, Final Batch Loss: 0.006026135291904211\n",
      "Epoch 1318, Loss: 0.009600552264600992, Final Batch Loss: 0.004360421560704708\n",
      "Epoch 1319, Loss: 0.0020023590768687427, Final Batch Loss: 0.0013546720147132874\n",
      "Epoch 1320, Loss: 0.033378164283931255, Final Batch Loss: 0.029523486271500587\n",
      "Epoch 1321, Loss: 0.003607084508985281, Final Batch Loss: 0.0019271532073616982\n",
      "Epoch 1322, Loss: 0.004829938756301999, Final Batch Loss: 0.002671404043212533\n",
      "Epoch 1323, Loss: 0.005746268550865352, Final Batch Loss: 0.004183596931397915\n",
      "Epoch 1324, Loss: 0.011922753881663084, Final Batch Loss: 0.004136588890105486\n",
      "Epoch 1325, Loss: 0.002583680907264352, Final Batch Loss: 0.001460363157093525\n",
      "Epoch 1326, Loss: 0.04425952606834471, Final Batch Loss: 0.04247099161148071\n",
      "Epoch 1327, Loss: 0.006030958378687501, Final Batch Loss: 0.005289031658321619\n",
      "Epoch 1328, Loss: 0.0008392462332267314, Final Batch Loss: 0.000428687286330387\n",
      "Epoch 1329, Loss: 0.003333259024657309, Final Batch Loss: 0.0006678380304947495\n",
      "Epoch 1330, Loss: 0.018563927616924047, Final Batch Loss: 0.0007888353429734707\n",
      "Epoch 1331, Loss: 0.035996559308841825, Final Batch Loss: 0.034478019922971725\n",
      "Epoch 1332, Loss: 0.009409380378201604, Final Batch Loss: 0.006712223868817091\n",
      "Epoch 1333, Loss: 0.02359957800945267, Final Batch Loss: 0.022678036242723465\n",
      "Epoch 1334, Loss: 0.003540429985150695, Final Batch Loss: 0.0003399739507585764\n",
      "Epoch 1335, Loss: 0.0023166369646787643, Final Batch Loss: 0.0016952974256128073\n",
      "Epoch 1336, Loss: 0.0055845328606665134, Final Batch Loss: 0.0008899867534637451\n",
      "Epoch 1337, Loss: 0.004564011003822088, Final Batch Loss: 0.0034984678495675325\n",
      "Epoch 1338, Loss: 0.005563046899624169, Final Batch Loss: 0.0006223275559023023\n",
      "Epoch 1339, Loss: 0.006167187704704702, Final Batch Loss: 0.0011011272436007857\n",
      "Epoch 1340, Loss: 0.004851419944316149, Final Batch Loss: 0.0022550553549081087\n",
      "Epoch 1341, Loss: 0.0019982176600024104, Final Batch Loss: 0.001021712669171393\n",
      "Epoch 1342, Loss: 0.007279576268047094, Final Batch Loss: 0.004346396774053574\n",
      "Epoch 1343, Loss: 0.0010258086840622127, Final Batch Loss: 0.0007578954682685435\n",
      "Epoch 1344, Loss: 0.004770885570906103, Final Batch Loss: 0.001357951550744474\n",
      "Epoch 1345, Loss: 0.0011713037092704326, Final Batch Loss: 0.00028034221031703055\n",
      "Epoch 1346, Loss: 0.024483744869939983, Final Batch Loss: 0.022893881425261497\n",
      "Epoch 1347, Loss: 0.0032221595756709576, Final Batch Loss: 0.0019078315235674381\n",
      "Epoch 1348, Loss: 0.004390661953948438, Final Batch Loss: 0.0030248432885855436\n",
      "Epoch 1349, Loss: 0.0019904031651094556, Final Batch Loss: 0.0013801350723952055\n",
      "Epoch 1350, Loss: 0.0041255685209762305, Final Batch Loss: 0.00030486585455946624\n",
      "Epoch 1351, Loss: 0.0009622806683182716, Final Batch Loss: 0.0005193223478272557\n",
      "Epoch 1352, Loss: 0.004483256721869111, Final Batch Loss: 0.0007610926404595375\n",
      "Epoch 1353, Loss: 0.008071509306319058, Final Batch Loss: 0.007241850718855858\n",
      "Epoch 1354, Loss: 0.013551972340792418, Final Batch Loss: 0.005611242260783911\n",
      "Epoch 1355, Loss: 0.0013758962450083345, Final Batch Loss: 0.0002685750077944249\n",
      "Epoch 1356, Loss: 0.010486122075235471, Final Batch Loss: 0.00035940096131525934\n",
      "Epoch 1357, Loss: 0.021955322241410613, Final Batch Loss: 0.021046945825219154\n",
      "Epoch 1358, Loss: 0.009822709485888481, Final Batch Loss: 0.004212399013340473\n",
      "Epoch 1359, Loss: 0.011876037227921188, Final Batch Loss: 0.010778112336993217\n",
      "Epoch 1360, Loss: 0.001781478407792747, Final Batch Loss: 0.0007880383636802435\n",
      "Epoch 1361, Loss: 0.002358313649892807, Final Batch Loss: 0.000506493030115962\n",
      "Epoch 1362, Loss: 0.0059596330393105745, Final Batch Loss: 0.0038986545987427235\n",
      "Epoch 1363, Loss: 0.0031711780466139317, Final Batch Loss: 0.0009045107290148735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1364, Loss: 0.001342851493973285, Final Batch Loss: 0.0006653076270595193\n",
      "Epoch 1365, Loss: 0.0023074205964803696, Final Batch Loss: 0.0005238987505435944\n",
      "Epoch 1366, Loss: 0.0012422957515809685, Final Batch Loss: 0.0002836496278177947\n",
      "Epoch 1367, Loss: 0.002035068639088422, Final Batch Loss: 0.001424694200977683\n",
      "Epoch 1368, Loss: 0.008514285320416093, Final Batch Loss: 0.0036496848333626986\n",
      "Epoch 1369, Loss: 0.0023043894325383008, Final Batch Loss: 0.0017670163651928306\n",
      "Epoch 1370, Loss: 0.002570976794231683, Final Batch Loss: 0.0016511583235114813\n",
      "Epoch 1371, Loss: 0.005135538405738771, Final Batch Loss: 0.001507589709945023\n",
      "Epoch 1372, Loss: 0.003938349196687341, Final Batch Loss: 0.002736632013693452\n",
      "Epoch 1373, Loss: 0.018329051672481, Final Batch Loss: 0.0003259306540712714\n",
      "Epoch 1374, Loss: 0.0037589321727864444, Final Batch Loss: 0.000458529160823673\n",
      "Epoch 1375, Loss: 0.004909401875920594, Final Batch Loss: 0.0011939130490645766\n",
      "Epoch 1376, Loss: 0.004569738171994686, Final Batch Loss: 0.003735311096534133\n",
      "Epoch 1377, Loss: 0.0023908484145067632, Final Batch Loss: 0.0006362550775520504\n",
      "Epoch 1378, Loss: 0.0021691014408133924, Final Batch Loss: 0.00014505366561934352\n",
      "Epoch 1379, Loss: 0.0025663843262009323, Final Batch Loss: 0.0018000961281359196\n",
      "Epoch 1380, Loss: 0.0021234018495306373, Final Batch Loss: 0.0006182130891829729\n",
      "Epoch 1381, Loss: 0.008059510495513678, Final Batch Loss: 0.004319986328482628\n",
      "Epoch 1382, Loss: 0.0024825806613080204, Final Batch Loss: 0.0017369854031130672\n",
      "Epoch 1383, Loss: 0.007807831163518131, Final Batch Loss: 0.001806203625164926\n",
      "Epoch 1384, Loss: 0.006796453148126602, Final Batch Loss: 0.004755832254886627\n",
      "Epoch 1385, Loss: 0.013530596625059843, Final Batch Loss: 0.005404059309512377\n",
      "Epoch 1386, Loss: 0.0035423163790255785, Final Batch Loss: 0.0021866783499717712\n",
      "Epoch 1387, Loss: 0.0038073096657171845, Final Batch Loss: 0.0004771897802129388\n",
      "Epoch 1388, Loss: 0.003226097207516432, Final Batch Loss: 0.002157079055905342\n",
      "Epoch 1389, Loss: 0.014359239488840103, Final Batch Loss: 0.007626923732459545\n",
      "Epoch 1390, Loss: 0.003355388587806374, Final Batch Loss: 0.0007006428786553442\n",
      "Epoch 1391, Loss: 0.0018731046584434807, Final Batch Loss: 0.001318256021477282\n",
      "Epoch 1392, Loss: 0.01107312086969614, Final Batch Loss: 0.0041625057347118855\n",
      "Epoch 1393, Loss: 0.0016003494383767247, Final Batch Loss: 0.0005546425236389041\n",
      "Epoch 1394, Loss: 0.0022857841686345637, Final Batch Loss: 0.0016604490811005235\n",
      "Epoch 1395, Loss: 0.020632972940802574, Final Batch Loss: 0.01844896748661995\n",
      "Epoch 1396, Loss: 0.002537689986638725, Final Batch Loss: 0.001345205120742321\n",
      "Epoch 1397, Loss: 0.0045647403749171644, Final Batch Loss: 0.00021525160991586745\n",
      "Epoch 1398, Loss: 0.0041350648971274495, Final Batch Loss: 0.0018426409224048257\n",
      "Epoch 1399, Loss: 0.004475489433389157, Final Batch Loss: 0.0037830558139830828\n",
      "Epoch 1400, Loss: 0.015374372946098447, Final Batch Loss: 0.0015995914582163095\n",
      "Epoch 1401, Loss: 0.021941562416031957, Final Batch Loss: 0.0032645605970174074\n",
      "Epoch 1402, Loss: 0.0016362660098820925, Final Batch Loss: 0.0007331186207011342\n",
      "Epoch 1403, Loss: 0.015485923504456878, Final Batch Loss: 0.013027152977883816\n",
      "Epoch 1404, Loss: 0.003893556189723313, Final Batch Loss: 0.002636618446558714\n",
      "Epoch 1405, Loss: 0.000800700334366411, Final Batch Loss: 0.00022398930741474032\n",
      "Epoch 1406, Loss: 0.0005130549398018047, Final Batch Loss: 0.00016765993495937437\n",
      "Epoch 1407, Loss: 0.01260965852998197, Final Batch Loss: 0.0008473496418446302\n",
      "Epoch 1408, Loss: 0.0010729737696237862, Final Batch Loss: 0.000614493153989315\n",
      "Epoch 1409, Loss: 0.002765684330370277, Final Batch Loss: 0.0019615732599049807\n",
      "Epoch 1410, Loss: 0.026877863449044526, Final Batch Loss: 0.0260819923132658\n",
      "Epoch 1411, Loss: 0.017885736422613263, Final Batch Loss: 0.014952659606933594\n",
      "Epoch 1412, Loss: 0.0006970707036089152, Final Batch Loss: 0.0004115976335015148\n",
      "Epoch 1413, Loss: 0.0030619609169662, Final Batch Loss: 0.0018399666296318173\n",
      "Epoch 1414, Loss: 0.005253607174381614, Final Batch Loss: 0.001086806645616889\n",
      "Epoch 1415, Loss: 0.005342510063201189, Final Batch Loss: 0.0027311211451888084\n",
      "Epoch 1416, Loss: 0.002372027898672968, Final Batch Loss: 0.0002853377372957766\n",
      "Epoch 1417, Loss: 0.0018029880593530834, Final Batch Loss: 0.0009479988948442042\n",
      "Epoch 1418, Loss: 0.0027195060974918306, Final Batch Loss: 0.002070341259241104\n",
      "Epoch 1419, Loss: 0.0031088818795979023, Final Batch Loss: 0.0009849290363490582\n",
      "Epoch 1420, Loss: 0.0017382960068061948, Final Batch Loss: 0.0005645946366712451\n",
      "Epoch 1421, Loss: 0.010661937150871381, Final Batch Loss: 0.0003660878574009985\n",
      "Epoch 1422, Loss: 0.0029129009344615042, Final Batch Loss: 0.002375784795731306\n",
      "Epoch 1423, Loss: 0.0013355092669371516, Final Batch Loss: 0.0004736390255857259\n",
      "Epoch 1424, Loss: 0.02141358144581318, Final Batch Loss: 0.017973050475120544\n",
      "Epoch 1425, Loss: 0.00809474298148416, Final Batch Loss: 0.0003121687041129917\n",
      "Epoch 1426, Loss: 0.004102466453332454, Final Batch Loss: 0.000738995207939297\n",
      "Epoch 1427, Loss: 0.0017126703169196844, Final Batch Loss: 0.0007299276767298579\n",
      "Epoch 1428, Loss: 0.005919589544646442, Final Batch Loss: 0.0019425958162173629\n",
      "Epoch 1429, Loss: 0.0038714080583304167, Final Batch Loss: 0.0025383250322192907\n",
      "Epoch 1430, Loss: 0.0033061369322240353, Final Batch Loss: 0.0012411016505211592\n",
      "Epoch 1431, Loss: 0.0016489517292939126, Final Batch Loss: 0.0010021395282819867\n",
      "Epoch 1432, Loss: 0.007277944590896368, Final Batch Loss: 0.002608964219689369\n",
      "Epoch 1433, Loss: 0.0045252624549902976, Final Batch Loss: 0.0003725640126504004\n",
      "Epoch 1434, Loss: 0.012829074868932366, Final Batch Loss: 0.01086497399955988\n",
      "Epoch 1435, Loss: 0.0016731227515265346, Final Batch Loss: 0.0010412025731056929\n",
      "Epoch 1436, Loss: 0.002986492123454809, Final Batch Loss: 0.0010538597125560045\n",
      "Epoch 1437, Loss: 0.0019518648623488843, Final Batch Loss: 0.0007718786946497858\n",
      "Epoch 1438, Loss: 0.06407069368287921, Final Batch Loss: 0.05983765423297882\n",
      "Epoch 1439, Loss: 0.004800654714927077, Final Batch Loss: 0.0014674118719995022\n",
      "Epoch 1440, Loss: 0.007063401280902326, Final Batch Loss: 0.0058569819666445255\n",
      "Epoch 1441, Loss: 0.007135121384635568, Final Batch Loss: 0.004623540677130222\n",
      "Epoch 1442, Loss: 0.0037978722248226404, Final Batch Loss: 0.0024973112158477306\n",
      "Epoch 1443, Loss: 0.005399157293140888, Final Batch Loss: 0.0017431362066417933\n",
      "Epoch 1444, Loss: 0.0035853537265211344, Final Batch Loss: 0.0015513747930526733\n",
      "Epoch 1445, Loss: 0.0017224554321728647, Final Batch Loss: 0.001067322795279324\n",
      "Epoch 1446, Loss: 0.005317510571330786, Final Batch Loss: 0.0034782509319484234\n",
      "Epoch 1447, Loss: 0.003465758403763175, Final Batch Loss: 0.0024703883100301027\n",
      "Epoch 1448, Loss: 0.0013190569879952818, Final Batch Loss: 0.0004707627522293478\n",
      "Epoch 1449, Loss: 0.002502273302525282, Final Batch Loss: 0.001115116523578763\n",
      "Epoch 1450, Loss: 0.0019651552429422736, Final Batch Loss: 0.0012267476413398981\n",
      "Epoch 1451, Loss: 0.006195907772053033, Final Batch Loss: 0.0009565034997649491\n",
      "Epoch 1452, Loss: 0.008515290566720068, Final Batch Loss: 0.0017936226213350892\n",
      "Epoch 1453, Loss: 0.0014476398355327547, Final Batch Loss: 0.0005943789146840572\n",
      "Epoch 1454, Loss: 0.003734424477443099, Final Batch Loss: 0.0026096089277416468\n",
      "Epoch 1455, Loss: 0.006670273200143129, Final Batch Loss: 0.0006910882075317204\n",
      "Epoch 1456, Loss: 0.003750369301997125, Final Batch Loss: 0.0017039660597220063\n",
      "Epoch 1457, Loss: 0.003413589089177549, Final Batch Loss: 0.0012115031713619828\n",
      "Epoch 1458, Loss: 0.002589490613900125, Final Batch Loss: 0.0014509896282106638\n",
      "Epoch 1459, Loss: 0.000915928918402642, Final Batch Loss: 0.0002635698765516281\n",
      "Epoch 1460, Loss: 0.0019689672626554966, Final Batch Loss: 0.0007655712543055415\n",
      "Epoch 1461, Loss: 0.00117260028491728, Final Batch Loss: 0.0007099140202626586\n",
      "Epoch 1462, Loss: 0.0017527430318295956, Final Batch Loss: 0.001013119937852025\n",
      "Epoch 1463, Loss: 0.0027334278565831482, Final Batch Loss: 0.0007532991585321724\n",
      "Epoch 1464, Loss: 0.001003831799607724, Final Batch Loss: 0.0005557960830628872\n",
      "Epoch 1465, Loss: 0.0011351772118359804, Final Batch Loss: 0.0006104152998887002\n",
      "Epoch 1466, Loss: 0.0014511214394588023, Final Batch Loss: 0.001090337405912578\n",
      "Epoch 1467, Loss: 0.0007623085984960198, Final Batch Loss: 0.0002457463997416198\n",
      "Epoch 1468, Loss: 0.002655456308275461, Final Batch Loss: 0.0012503790203481913\n",
      "Epoch 1469, Loss: 0.0025914842262864113, Final Batch Loss: 0.0007212564814835787\n",
      "Epoch 1470, Loss: 0.002330126822926104, Final Batch Loss: 0.0013259605038911104\n",
      "Epoch 1471, Loss: 0.005141195171745494, Final Batch Loss: 0.00027580306050367653\n",
      "Epoch 1472, Loss: 0.001467863388825208, Final Batch Loss: 0.0009584887884557247\n",
      "Epoch 1473, Loss: 0.0010531284642638639, Final Batch Loss: 0.0001811059337342158\n",
      "Epoch 1474, Loss: 0.001885244797449559, Final Batch Loss: 0.00137061788700521\n",
      "Epoch 1475, Loss: 0.005270697030937299, Final Batch Loss: 0.000464344717329368\n",
      "Epoch 1476, Loss: 0.0012939367443323135, Final Batch Loss: 0.0005519125261344016\n",
      "Epoch 1477, Loss: 0.005105135263875127, Final Batch Loss: 0.003303593024611473\n",
      "Epoch 1478, Loss: 0.017541780456667766, Final Batch Loss: 0.0001556606439407915\n",
      "Epoch 1479, Loss: 0.003404802700970322, Final Batch Loss: 0.002823107410222292\n",
      "Epoch 1480, Loss: 0.007748181000351906, Final Batch Loss: 0.006591259501874447\n",
      "Epoch 1481, Loss: 0.02751237154006958, Final Batch Loss: 0.011629117652773857\n",
      "Epoch 1482, Loss: 0.002270886761834845, Final Batch Loss: 0.001918060821481049\n",
      "Epoch 1483, Loss: 0.001257341355085373, Final Batch Loss: 0.0008914480567909777\n",
      "Epoch 1484, Loss: 0.008353003591764718, Final Batch Loss: 0.007849586196243763\n",
      "Epoch 1485, Loss: 0.0009200640488415956, Final Batch Loss: 0.00029730552341789007\n",
      "Epoch 1486, Loss: 0.00932356616249308, Final Batch Loss: 0.0002036410733126104\n",
      "Epoch 1487, Loss: 0.0006866903422633186, Final Batch Loss: 0.00013523742381948978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1488, Loss: 0.011381080374121666, Final Batch Loss: 0.0030950503423810005\n",
      "Epoch 1489, Loss: 0.019845223345328122, Final Batch Loss: 0.019390735775232315\n",
      "Epoch 1490, Loss: 0.008664484223118052, Final Batch Loss: 0.00017293737619183958\n",
      "Epoch 1491, Loss: 0.0023135822266340256, Final Batch Loss: 0.0010091217700392008\n",
      "Epoch 1492, Loss: 0.002819051791448146, Final Batch Loss: 0.00035805703373625875\n",
      "Epoch 1493, Loss: 0.0015825005830265582, Final Batch Loss: 0.0003554587601684034\n",
      "Epoch 1494, Loss: 0.002380065052420832, Final Batch Loss: 0.0002260754263261333\n",
      "Epoch 1495, Loss: 0.000766629382269457, Final Batch Loss: 0.0004527694545686245\n",
      "Epoch 1496, Loss: 0.0011202118184883147, Final Batch Loss: 0.0002504369767848402\n",
      "Epoch 1497, Loss: 0.001776244433131069, Final Batch Loss: 0.0007814886630512774\n",
      "Epoch 1498, Loss: 0.003999563166871667, Final Batch Loss: 0.00029893149621784687\n",
      "Epoch 1499, Loss: 0.002012296987231821, Final Batch Loss: 0.0003607520484365523\n",
      "Epoch 1500, Loss: 0.0187935889698565, Final Batch Loss: 0.013064003549516201\n",
      "Epoch 1501, Loss: 0.010392147523816675, Final Batch Loss: 0.0005790362483821809\n",
      "Epoch 1502, Loss: 0.021680715028196573, Final Batch Loss: 0.0002928641624748707\n",
      "Epoch 1503, Loss: 0.0024768634466454387, Final Batch Loss: 0.0014331747079268098\n",
      "Epoch 1504, Loss: 0.0026642161537893116, Final Batch Loss: 0.001957903616130352\n",
      "Epoch 1505, Loss: 0.0015334897325374186, Final Batch Loss: 0.000466665078420192\n",
      "Epoch 1506, Loss: 0.004618947801645845, Final Batch Loss: 0.004017868544906378\n",
      "Epoch 1507, Loss: 0.01681602979078889, Final Batch Loss: 0.007470662239938974\n",
      "Epoch 1508, Loss: 0.00893190293572843, Final Batch Loss: 0.001276940805837512\n",
      "Epoch 1509, Loss: 0.004340964951552451, Final Batch Loss: 0.0016474613221362233\n",
      "Epoch 1510, Loss: 0.012083218432962894, Final Batch Loss: 0.0010445108637213707\n",
      "Epoch 1511, Loss: 0.016082732763607055, Final Batch Loss: 0.0004918424529023468\n",
      "Epoch 1512, Loss: 0.002029242808930576, Final Batch Loss: 0.0009439177811145782\n",
      "Epoch 1513, Loss: 0.004306531976908445, Final Batch Loss: 0.0023172260262072086\n",
      "Epoch 1514, Loss: 0.0011917112715309486, Final Batch Loss: 0.00022115818865131587\n",
      "Epoch 1515, Loss: 0.0022897418530192226, Final Batch Loss: 0.0018277234630659223\n",
      "Epoch 1516, Loss: 0.0016780178266344592, Final Batch Loss: 0.00020185804169159383\n",
      "Epoch 1517, Loss: 0.004624148947186768, Final Batch Loss: 0.003917315974831581\n",
      "Epoch 1518, Loss: 0.0026645732577890158, Final Batch Loss: 0.0018089960794895887\n",
      "Epoch 1519, Loss: 0.0033922113361768425, Final Batch Loss: 0.0005009611486457288\n",
      "Epoch 1520, Loss: 0.005920924537349492, Final Batch Loss: 0.0004549676668830216\n",
      "Epoch 1521, Loss: 0.002258415275719017, Final Batch Loss: 0.0013102969387546182\n",
      "Epoch 1522, Loss: 0.005059415765572339, Final Batch Loss: 0.0005418670480139554\n",
      "Epoch 1523, Loss: 0.013583527877926826, Final Batch Loss: 0.005296595394611359\n",
      "Epoch 1524, Loss: 0.001142580935265869, Final Batch Loss: 0.0004438722971826792\n",
      "Epoch 1525, Loss: 0.0014751195267308503, Final Batch Loss: 0.0011503177229315042\n",
      "Epoch 1526, Loss: 0.0015124724304769188, Final Batch Loss: 0.0011828026035800576\n",
      "Epoch 1527, Loss: 0.004564864910207689, Final Batch Loss: 0.0040086195804178715\n",
      "Epoch 1528, Loss: 0.0019959547207690775, Final Batch Loss: 0.0005509571055881679\n",
      "Epoch 1529, Loss: 0.0011787551920861006, Final Batch Loss: 0.0002279742038808763\n",
      "Epoch 1530, Loss: 0.004407814820297062, Final Batch Loss: 0.0035035007167607546\n",
      "Epoch 1531, Loss: 0.003828085435088724, Final Batch Loss: 0.0004809491219930351\n",
      "Epoch 1532, Loss: 0.0036776843189727515, Final Batch Loss: 0.003218883415684104\n",
      "Epoch 1533, Loss: 0.004197414848022163, Final Batch Loss: 0.003286847611889243\n",
      "Epoch 1534, Loss: 0.00417051010299474, Final Batch Loss: 0.0035051556769758463\n",
      "Epoch 1535, Loss: 0.004310369549784809, Final Batch Loss: 0.0007761733722873032\n",
      "Epoch 1536, Loss: 0.002926733228377998, Final Batch Loss: 0.0012639565393328667\n",
      "Epoch 1537, Loss: 0.0007293066155398265, Final Batch Loss: 0.0001503692619735375\n",
      "Epoch 1538, Loss: 0.020707362913526595, Final Batch Loss: 0.019958922639489174\n",
      "Epoch 1539, Loss: 0.0013505584502127022, Final Batch Loss: 0.00015271114534698427\n",
      "Epoch 1540, Loss: 0.0015396561648231, Final Batch Loss: 0.0002771846193354577\n",
      "Epoch 1541, Loss: 0.011526431713718921, Final Batch Loss: 0.0003918947768397629\n",
      "Epoch 1542, Loss: 0.0032980877440422773, Final Batch Loss: 0.002035542158409953\n",
      "Epoch 1543, Loss: 0.0024412915809080005, Final Batch Loss: 0.0015877027763053775\n",
      "Epoch 1544, Loss: 0.0005177815910428762, Final Batch Loss: 0.0002471500192768872\n",
      "Epoch 1545, Loss: 0.0026118176174350083, Final Batch Loss: 0.0006077683647163212\n",
      "Epoch 1546, Loss: 0.006866662879474461, Final Batch Loss: 0.0006813030922785401\n",
      "Epoch 1547, Loss: 0.0012552193802548572, Final Batch Loss: 0.0002111405337927863\n",
      "Epoch 1548, Loss: 0.006944013817701489, Final Batch Loss: 0.006244378630071878\n",
      "Epoch 1549, Loss: 0.0022879972821101546, Final Batch Loss: 0.0009640794014558196\n",
      "Epoch 1550, Loss: 0.0019366855849511921, Final Batch Loss: 0.0002540547284297645\n",
      "Epoch 1551, Loss: 0.0014481100370176136, Final Batch Loss: 0.000999352429062128\n",
      "Epoch 1552, Loss: 0.005312935361871496, Final Batch Loss: 0.00032135137007571757\n",
      "Epoch 1553, Loss: 0.01146416098345071, Final Batch Loss: 0.0008578795241191983\n",
      "Epoch 1554, Loss: 0.0013006224762648344, Final Batch Loss: 0.0010298636043444276\n",
      "Epoch 1555, Loss: 0.0039056087844073772, Final Batch Loss: 0.003162988694384694\n",
      "Epoch 1556, Loss: 0.002045188331976533, Final Batch Loss: 0.0017934876959770918\n",
      "Epoch 1557, Loss: 0.008343607652932405, Final Batch Loss: 0.0063418373465538025\n",
      "Epoch 1558, Loss: 0.005353426677174866, Final Batch Loss: 0.0012223176890984178\n",
      "Epoch 1559, Loss: 0.010488101514056325, Final Batch Loss: 0.009729566983878613\n",
      "Epoch 1560, Loss: 0.0010866677621379495, Final Batch Loss: 0.000815296545624733\n",
      "Epoch 1561, Loss: 0.0006630072020925581, Final Batch Loss: 0.00022491131676360965\n",
      "Epoch 1562, Loss: 0.000838237174320966, Final Batch Loss: 0.00037289189640432596\n",
      "Epoch 1563, Loss: 0.0087504101684317, Final Batch Loss: 0.0019361114827916026\n",
      "Epoch 1564, Loss: 0.006740505923517048, Final Batch Loss: 0.0049628885462880135\n",
      "Epoch 1565, Loss: 0.006490849802503362, Final Batch Loss: 0.0002860575041268021\n",
      "Epoch 1566, Loss: 0.0006990666734054685, Final Batch Loss: 0.0002869493036996573\n",
      "Epoch 1567, Loss: 0.005537407472729683, Final Batch Loss: 0.004319217521697283\n",
      "Epoch 1568, Loss: 0.002305077388882637, Final Batch Loss: 0.0008934487123042345\n",
      "Epoch 1569, Loss: 0.0005567464831983671, Final Batch Loss: 0.0003326116711832583\n",
      "Epoch 1570, Loss: 0.004393377690576017, Final Batch Loss: 0.0017325886292383075\n",
      "Epoch 1571, Loss: 0.007256136421347037, Final Batch Loss: 0.00045506717287935317\n",
      "Epoch 1572, Loss: 0.024032206973060966, Final Batch Loss: 0.021509164944291115\n",
      "Epoch 1573, Loss: 0.0015410202031489462, Final Batch Loss: 0.00048600390437059104\n",
      "Epoch 1574, Loss: 0.0027726181433536112, Final Batch Loss: 0.0004959414363838732\n",
      "Epoch 1575, Loss: 0.0024980726011563092, Final Batch Loss: 0.0022281326819211245\n",
      "Epoch 1576, Loss: 0.0034114580776076764, Final Batch Loss: 0.0002767480618786067\n",
      "Epoch 1577, Loss: 0.0016419166058767587, Final Batch Loss: 0.000334631564328447\n",
      "Epoch 1578, Loss: 0.0011006031709257513, Final Batch Loss: 0.0002311818825546652\n",
      "Epoch 1579, Loss: 0.003439681138843298, Final Batch Loss: 0.0018033883534371853\n",
      "Epoch 1580, Loss: 0.003571724344510585, Final Batch Loss: 0.003369365120306611\n",
      "Epoch 1581, Loss: 0.0010408399975858629, Final Batch Loss: 0.00029497704235836864\n",
      "Epoch 1582, Loss: 0.0016158516227733344, Final Batch Loss: 0.0012130099348723888\n",
      "Epoch 1583, Loss: 0.038788507285062224, Final Batch Loss: 0.03806411474943161\n",
      "Epoch 1584, Loss: 0.0029753727139905095, Final Batch Loss: 0.0011092701461166143\n",
      "Epoch 1585, Loss: 0.012850515326135792, Final Batch Loss: 0.00020876132475677878\n",
      "Epoch 1586, Loss: 0.00388633762486279, Final Batch Loss: 0.0016756763216108084\n",
      "Epoch 1587, Loss: 0.003970023477450013, Final Batch Loss: 0.002766973804682493\n",
      "Epoch 1588, Loss: 0.01949785917531699, Final Batch Loss: 0.0005386479897424579\n",
      "Epoch 1589, Loss: 0.0035567221930250525, Final Batch Loss: 0.002222443697974086\n",
      "Epoch 1590, Loss: 0.004037588136270642, Final Batch Loss: 0.0026538725942373276\n",
      "Epoch 1591, Loss: 0.0010250990453641862, Final Batch Loss: 0.00024732216843403876\n",
      "Epoch 1592, Loss: 0.007513780699810013, Final Batch Loss: 0.007172678597271442\n",
      "Epoch 1593, Loss: 0.005246890359558165, Final Batch Loss: 0.0015643826918676496\n",
      "Epoch 1594, Loss: 0.0061534413835033774, Final Batch Loss: 0.0010895751183852553\n",
      "Epoch 1595, Loss: 0.013831535819917917, Final Batch Loss: 0.0049054003320634365\n",
      "Epoch 1596, Loss: 0.005399459972977638, Final Batch Loss: 0.0025518755428493023\n",
      "Epoch 1597, Loss: 0.0014991883945185691, Final Batch Loss: 0.0011915222276002169\n",
      "Epoch 1598, Loss: 0.0016430579707957804, Final Batch Loss: 0.000703903497196734\n",
      "Epoch 1599, Loss: 0.0010089170536957681, Final Batch Loss: 0.000389243068639189\n",
      "Epoch 1600, Loss: 0.005213337950408459, Final Batch Loss: 0.00241494202055037\n",
      "Epoch 1601, Loss: 0.0011600588622968644, Final Batch Loss: 0.0009738521184772253\n",
      "Epoch 1602, Loss: 0.001981247332878411, Final Batch Loss: 0.001035028719343245\n",
      "Epoch 1603, Loss: 0.0006762387783965096, Final Batch Loss: 0.00022603188699577004\n",
      "Epoch 1604, Loss: 0.0032204336603172123, Final Batch Loss: 0.0006340477266348898\n",
      "Epoch 1605, Loss: 0.0009404440061189234, Final Batch Loss: 0.0006321294349618256\n",
      "Epoch 1606, Loss: 0.002400948666036129, Final Batch Loss: 0.0009966596262529492\n",
      "Epoch 1607, Loss: 0.001235930307302624, Final Batch Loss: 0.0008280776091851294\n",
      "Epoch 1608, Loss: 0.0027850023470818996, Final Batch Loss: 0.0004094298928976059\n",
      "Epoch 1609, Loss: 0.0006903137400513515, Final Batch Loss: 0.0002030564210144803\n",
      "Epoch 1610, Loss: 0.028703568154014647, Final Batch Loss: 0.027528241276741028\n",
      "Epoch 1611, Loss: 0.0026016045012511313, Final Batch Loss: 0.002086128806695342\n",
      "Epoch 1612, Loss: 0.007355439011007547, Final Batch Loss: 0.005652695428580046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1613, Loss: 0.016717755075660534, Final Batch Loss: 0.0002381306403549388\n",
      "Epoch 1614, Loss: 0.002202924297307618, Final Batch Loss: 0.00012712292664218694\n",
      "Epoch 1615, Loss: 0.0020693681435659528, Final Batch Loss: 0.0014857904752716422\n",
      "Epoch 1616, Loss: 0.0008456084251520224, Final Batch Loss: 0.00011808879935415462\n",
      "Epoch 1617, Loss: 0.009588015265762806, Final Batch Loss: 0.00418923469260335\n",
      "Epoch 1618, Loss: 0.005684170173481107, Final Batch Loss: 0.0022782275918871164\n",
      "Epoch 1619, Loss: 0.0006339998653857037, Final Batch Loss: 0.00023303933267015964\n",
      "Epoch 1620, Loss: 0.009703364223241806, Final Batch Loss: 0.008467051200568676\n",
      "Epoch 1621, Loss: 0.0016335199470631778, Final Batch Loss: 0.000537948973942548\n",
      "Epoch 1622, Loss: 0.008084540662821382, Final Batch Loss: 0.0008222935139201581\n",
      "Epoch 1623, Loss: 0.002125707280356437, Final Batch Loss: 0.0004645391018129885\n",
      "Epoch 1624, Loss: 0.0019572114979382604, Final Batch Loss: 0.0003693480684887618\n",
      "Epoch 1625, Loss: 0.002485856879502535, Final Batch Loss: 0.0010199001990258694\n",
      "Epoch 1626, Loss: 0.002025294932536781, Final Batch Loss: 0.0001437236787751317\n",
      "Epoch 1627, Loss: 0.0022069659898988903, Final Batch Loss: 0.0015311073511838913\n",
      "Epoch 1628, Loss: 0.0006635096506215632, Final Batch Loss: 0.00041596422670409083\n",
      "Epoch 1629, Loss: 0.0018055981781799346, Final Batch Loss: 0.0013510420685634017\n",
      "Epoch 1630, Loss: 0.0009155928564723581, Final Batch Loss: 0.0008451821049675345\n",
      "Epoch 1631, Loss: 0.012840400624554604, Final Batch Loss: 0.0007004087674431503\n",
      "Epoch 1632, Loss: 0.027768976549850777, Final Batch Loss: 0.027519794180989265\n",
      "Epoch 1633, Loss: 0.0019764582393690944, Final Batch Loss: 0.00015467626508325338\n",
      "Epoch 1634, Loss: 0.000810026831459254, Final Batch Loss: 0.00047959593939594924\n",
      "Epoch 1635, Loss: 0.003109075885731727, Final Batch Loss: 0.0027805487625300884\n",
      "Epoch 1636, Loss: 0.014598216759623028, Final Batch Loss: 0.00023641054576728493\n",
      "Epoch 1637, Loss: 0.0033657473977655172, Final Batch Loss: 0.0012230167631059885\n",
      "Epoch 1638, Loss: 0.0017129149637185037, Final Batch Loss: 0.00035025953548029065\n",
      "Epoch 1639, Loss: 0.010325337992981076, Final Batch Loss: 0.002530388766899705\n",
      "Epoch 1640, Loss: 0.006070349831134081, Final Batch Loss: 0.001308173406869173\n",
      "Epoch 1641, Loss: 0.012720412341877818, Final Batch Loss: 0.00951203890144825\n",
      "Epoch 1642, Loss: 0.0020001306547783315, Final Batch Loss: 0.0009641377837397158\n",
      "Epoch 1643, Loss: 0.011092392262071371, Final Batch Loss: 0.006904114503413439\n",
      "Epoch 1644, Loss: 0.002692695881705731, Final Batch Loss: 0.002171166939660907\n",
      "Epoch 1645, Loss: 0.006020575616275892, Final Batch Loss: 0.0002522089926060289\n",
      "Epoch 1646, Loss: 0.0019235176732763648, Final Batch Loss: 0.0013309995410963893\n",
      "Epoch 1647, Loss: 0.0015988806262612343, Final Batch Loss: 0.00027703307569026947\n",
      "Epoch 1648, Loss: 0.006456888280808926, Final Batch Loss: 0.003249198431149125\n",
      "Epoch 1649, Loss: 0.004140729201026261, Final Batch Loss: 0.001103471382521093\n",
      "Epoch 1650, Loss: 0.004293406323995441, Final Batch Loss: 0.0007931100553832948\n",
      "Epoch 1651, Loss: 0.0013567529967986047, Final Batch Loss: 0.0004375266144052148\n",
      "Epoch 1652, Loss: 0.006031383207300678, Final Batch Loss: 0.0004574078193400055\n",
      "Epoch 1653, Loss: 0.0021477281115949154, Final Batch Loss: 0.0017955652438104153\n",
      "Epoch 1654, Loss: 0.005303730838932097, Final Batch Loss: 0.004385034088045359\n",
      "Epoch 1655, Loss: 0.005163046167581342, Final Batch Loss: 0.00016380623856093735\n",
      "Epoch 1656, Loss: 0.000952904112637043, Final Batch Loss: 0.0006531416438519955\n",
      "Epoch 1657, Loss: 0.0017097992240451276, Final Batch Loss: 0.001010141451843083\n",
      "Epoch 1658, Loss: 0.000992600260360632, Final Batch Loss: 7.860377809265628e-05\n",
      "Epoch 1659, Loss: 0.007233078446006402, Final Batch Loss: 0.006827604956924915\n",
      "Epoch 1660, Loss: 0.0007834882126189768, Final Batch Loss: 8.693698327988386e-05\n",
      "Epoch 1661, Loss: 0.0011687373626045883, Final Batch Loss: 0.000483235577121377\n",
      "Epoch 1662, Loss: 0.012975497636944056, Final Batch Loss: 0.012401342391967773\n",
      "Epoch 1663, Loss: 0.02701184619218111, Final Batch Loss: 0.024916574358940125\n",
      "Epoch 1664, Loss: 0.0058695776970125735, Final Batch Loss: 0.005038150120526552\n",
      "Epoch 1665, Loss: 0.005600119708105922, Final Batch Loss: 0.002460119314491749\n",
      "Epoch 1666, Loss: 0.0013432792911771685, Final Batch Loss: 0.00019298403640277684\n",
      "Epoch 1667, Loss: 0.001985583599889651, Final Batch Loss: 0.0002524385054130107\n",
      "Epoch 1668, Loss: 0.006185428122989833, Final Batch Loss: 0.004681976977735758\n",
      "Epoch 1669, Loss: 0.0022855063434690237, Final Batch Loss: 0.000535392202436924\n",
      "Epoch 1670, Loss: 0.0008986750326585025, Final Batch Loss: 5.414502811618149e-05\n",
      "Epoch 1671, Loss: 0.0015493638929910958, Final Batch Loss: 0.0008423083927482367\n",
      "Epoch 1672, Loss: 0.0016421222826465964, Final Batch Loss: 0.0002932134084403515\n",
      "Epoch 1673, Loss: 0.014623533934354782, Final Batch Loss: 0.009813189506530762\n",
      "Epoch 1674, Loss: 0.0017972015484701842, Final Batch Loss: 0.0002945336455013603\n",
      "Epoch 1675, Loss: 0.01559848798206076, Final Batch Loss: 0.00027882488211616874\n",
      "Epoch 1676, Loss: 0.0012997570956940763, Final Batch Loss: 6.495246634585783e-05\n",
      "Epoch 1677, Loss: 0.0021068731148261577, Final Batch Loss: 0.00048271557898260653\n",
      "Epoch 1678, Loss: 0.007502271211706102, Final Batch Loss: 0.006874216720461845\n",
      "Epoch 1679, Loss: 0.004696636577136815, Final Batch Loss: 0.0013494679005816579\n",
      "Epoch 1680, Loss: 0.005347359809093177, Final Batch Loss: 0.0003712553298100829\n",
      "Epoch 1681, Loss: 0.00216036758502014, Final Batch Loss: 0.0004169410385657102\n",
      "Epoch 1682, Loss: 0.0011982605792582035, Final Batch Loss: 0.0005848926957696676\n",
      "Epoch 1683, Loss: 0.004252397688105702, Final Batch Loss: 0.0015139977913349867\n",
      "Epoch 1684, Loss: 0.010903213522396982, Final Batch Loss: 0.0019195586210116744\n",
      "Epoch 1685, Loss: 0.002600679494207725, Final Batch Loss: 0.0004432775021996349\n",
      "Epoch 1686, Loss: 0.012807691236957908, Final Batch Loss: 0.010276450775563717\n",
      "Epoch 1687, Loss: 0.001123902024119161, Final Batch Loss: 0.0002327429101569578\n",
      "Epoch 1688, Loss: 0.0019525353563949466, Final Batch Loss: 0.001220407080836594\n",
      "Epoch 1689, Loss: 0.0008136381075019017, Final Batch Loss: 0.00018959796580020338\n",
      "Epoch 1690, Loss: 0.007932813721708953, Final Batch Loss: 0.006699241232126951\n",
      "Epoch 1691, Loss: 0.0014499165408778936, Final Batch Loss: 0.0011510547483339906\n",
      "Epoch 1692, Loss: 0.0019182701944373548, Final Batch Loss: 0.0013559873914346099\n",
      "Epoch 1693, Loss: 0.0076704662351403385, Final Batch Loss: 0.00022624098346568644\n",
      "Epoch 1694, Loss: 0.0018565735372249037, Final Batch Loss: 0.0003184543747920543\n",
      "Epoch 1695, Loss: 0.0003147811657981947, Final Batch Loss: 0.00023347881506197155\n",
      "Epoch 1696, Loss: 0.00040667476423550397, Final Batch Loss: 6.16107281530276e-05\n",
      "Epoch 1697, Loss: 0.0007147713622543961, Final Batch Loss: 0.0005076437955722213\n",
      "Epoch 1698, Loss: 0.005495889083249494, Final Batch Loss: 0.0053623272106051445\n",
      "Epoch 1699, Loss: 0.0016886350931599736, Final Batch Loss: 0.0011124591110274196\n",
      "Epoch 1700, Loss: 0.0024229222908616066, Final Batch Loss: 0.0013711937936022878\n",
      "Epoch 1701, Loss: 0.004762352182297036, Final Batch Loss: 0.0003375063824933022\n",
      "Epoch 1702, Loss: 0.0007836095319362357, Final Batch Loss: 0.00016782993043307215\n",
      "Epoch 1703, Loss: 0.0006861787551315501, Final Batch Loss: 0.0004900099593214691\n",
      "Epoch 1704, Loss: 0.0034958443138748407, Final Batch Loss: 0.0021103688050061464\n",
      "Epoch 1705, Loss: 0.003646999190095812, Final Batch Loss: 0.0027593958657234907\n",
      "Epoch 1706, Loss: 0.0011121442366857082, Final Batch Loss: 0.0002580840664450079\n",
      "Epoch 1707, Loss: 0.000927915534703061, Final Batch Loss: 0.0002860251406673342\n",
      "Epoch 1708, Loss: 0.009757736988831311, Final Batch Loss: 0.0003208446432836354\n",
      "Epoch 1709, Loss: 0.0006188889674376696, Final Batch Loss: 0.00046427262714132667\n",
      "Epoch 1710, Loss: 0.005503507418325171, Final Batch Loss: 0.0052045537158846855\n",
      "Epoch 1711, Loss: 0.0011779199048760347, Final Batch Loss: 5.487503221957013e-05\n",
      "Epoch 1712, Loss: 0.004865183436777443, Final Batch Loss: 0.004233791492879391\n",
      "Epoch 1713, Loss: 0.009121264854911715, Final Batch Loss: 0.009008272551000118\n",
      "Epoch 1714, Loss: 0.00095264505216619, Final Batch Loss: 0.00012148755922680721\n",
      "Epoch 1715, Loss: 0.0010606970463413745, Final Batch Loss: 0.0003586621314752847\n",
      "Epoch 1716, Loss: 0.0009927691571647301, Final Batch Loss: 0.00014246739738155156\n",
      "Epoch 1717, Loss: 0.014744525717105716, Final Batch Loss: 0.013769874349236488\n",
      "Epoch 1718, Loss: 0.002998232957907021, Final Batch Loss: 0.002469609724357724\n",
      "Epoch 1719, Loss: 0.00782490536221303, Final Batch Loss: 0.0073530529625713825\n",
      "Epoch 1720, Loss: 0.00040659176011104137, Final Batch Loss: 0.00015997588343452662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1721, Loss: 0.0014416942140087485, Final Batch Loss: 0.000447723432444036\n",
      "Epoch 1722, Loss: 0.009659255127189681, Final Batch Loss: 0.009399882517755032\n",
      "Epoch 1723, Loss: 0.0005337369220796973, Final Batch Loss: 0.00011814472964033484\n",
      "Epoch 1724, Loss: 0.0014809816639171913, Final Batch Loss: 0.0013781823217868805\n",
      "Epoch 1725, Loss: 0.0008630766242276877, Final Batch Loss: 0.0005168784409761429\n",
      "Epoch 1726, Loss: 0.00026384322700323537, Final Batch Loss: 0.0001945060648722574\n",
      "Epoch 1727, Loss: 0.0034674036724027246, Final Batch Loss: 0.00011843335232697427\n",
      "Epoch 1728, Loss: 0.001994307618588209, Final Batch Loss: 0.00045840523671358824\n",
      "Epoch 1729, Loss: 0.0016682339191902429, Final Batch Loss: 0.0002786749100778252\n",
      "Epoch 1730, Loss: 0.0020835379837080836, Final Batch Loss: 0.0013313944218680263\n",
      "Epoch 1731, Loss: 0.004525714859482832, Final Batch Loss: 0.00015689416613895446\n",
      "Epoch 1732, Loss: 0.001465594512410462, Final Batch Loss: 0.001106078503653407\n",
      "Epoch 1733, Loss: 0.0025896007718984038, Final Batch Loss: 0.0004796419816557318\n",
      "Epoch 1734, Loss: 0.011979687493294477, Final Batch Loss: 0.01075756922364235\n",
      "Epoch 1735, Loss: 0.00166565747349523, Final Batch Loss: 0.0004401707265060395\n",
      "Epoch 1736, Loss: 0.0006595932645723224, Final Batch Loss: 0.0004226217861287296\n",
      "Epoch 1737, Loss: 0.005610301857814193, Final Batch Loss: 0.003387749893590808\n",
      "Epoch 1738, Loss: 0.03812379133887589, Final Batch Loss: 0.03681498020887375\n",
      "Epoch 1739, Loss: 0.002595138386823237, Final Batch Loss: 0.0017062962288036942\n",
      "Epoch 1740, Loss: 0.0025398958241567016, Final Batch Loss: 0.0010123084066435695\n",
      "Epoch 1741, Loss: 0.0006056686979718506, Final Batch Loss: 0.00016312068328261375\n",
      "Epoch 1742, Loss: 0.0014078851090744138, Final Batch Loss: 0.0008513653883710504\n",
      "Epoch 1743, Loss: 0.000699627969879657, Final Batch Loss: 0.00045945262536406517\n",
      "Epoch 1744, Loss: 0.0008980930142570287, Final Batch Loss: 0.0005960768321529031\n",
      "Epoch 1745, Loss: 0.0018112086690962315, Final Batch Loss: 0.0011399512877687812\n",
      "Epoch 1746, Loss: 0.028726475822622888, Final Batch Loss: 0.02852093055844307\n",
      "Epoch 1747, Loss: 0.0009041097582667135, Final Batch Loss: 0.0007948994752950966\n",
      "Epoch 1748, Loss: 0.0017825833056122065, Final Batch Loss: 0.0015044808387756348\n",
      "Epoch 1749, Loss: 0.0038582009146921337, Final Batch Loss: 0.0007421040791086853\n",
      "Epoch 1750, Loss: 0.03071311433450319, Final Batch Loss: 0.0003746463044080883\n",
      "Epoch 1751, Loss: 0.0012403445434756577, Final Batch Loss: 0.0009629857959225774\n",
      "Epoch 1752, Loss: 0.0026102702249772847, Final Batch Loss: 0.0016409405507147312\n",
      "Epoch 1753, Loss: 0.0044265902834013104, Final Batch Loss: 0.0034275290090590715\n",
      "Epoch 1754, Loss: 0.0017611689982004464, Final Batch Loss: 0.0008260185713879764\n",
      "Epoch 1755, Loss: 0.002583770197816193, Final Batch Loss: 0.002090474823489785\n",
      "Epoch 1756, Loss: 0.005297560273902491, Final Batch Loss: 0.00017498669330962002\n",
      "Epoch 1757, Loss: 0.0011122720316052437, Final Batch Loss: 0.0004215413355268538\n",
      "Epoch 1758, Loss: 0.006007660063914955, Final Batch Loss: 0.0014310524566099048\n",
      "Epoch 1759, Loss: 0.08921913069207221, Final Batch Loss: 0.0879182368516922\n",
      "Epoch 1760, Loss: 0.003987098403740674, Final Batch Loss: 0.0005617805873043835\n",
      "Epoch 1761, Loss: 0.0008871765166986734, Final Batch Loss: 0.00030043613514862955\n",
      "Epoch 1762, Loss: 0.0020194058306515217, Final Batch Loss: 0.0007845065556466579\n",
      "Epoch 1763, Loss: 0.0023301613982766867, Final Batch Loss: 0.0016854064306244254\n",
      "Epoch 1764, Loss: 0.027145743370056152, Final Batch Loss: 0.017240561544895172\n",
      "Epoch 1765, Loss: 0.009474517777562141, Final Batch Loss: 0.004060609731823206\n",
      "Epoch 1766, Loss: 0.0052258470095694065, Final Batch Loss: 0.004899425897747278\n",
      "Epoch 1767, Loss: 0.003098790068179369, Final Batch Loss: 0.00014591426588594913\n",
      "Epoch 1768, Loss: 0.001190599097753875, Final Batch Loss: 0.00015663057274650782\n",
      "Epoch 1769, Loss: 0.002080005535390228, Final Batch Loss: 0.0013410516548901796\n",
      "Epoch 1770, Loss: 0.0019591010932344943, Final Batch Loss: 0.001656154403463006\n",
      "Epoch 1771, Loss: 0.003098307701293379, Final Batch Loss: 0.00033270131098106503\n",
      "Epoch 1772, Loss: 0.0016512916190549731, Final Batch Loss: 0.00013729312922805548\n",
      "Epoch 1773, Loss: 0.0019519931520335376, Final Batch Loss: 0.0008662745240144432\n",
      "Epoch 1774, Loss: 0.0019390549277886748, Final Batch Loss: 0.0007080540526658297\n",
      "Epoch 1775, Loss: 0.0018996751750819385, Final Batch Loss: 0.00047105521662160754\n",
      "Epoch 1776, Loss: 0.004548152326606214, Final Batch Loss: 0.0031927612144500017\n",
      "Epoch 1777, Loss: 0.0005732487043133005, Final Batch Loss: 0.000425612844992429\n",
      "Epoch 1778, Loss: 0.0016266109887510538, Final Batch Loss: 0.0005569788627326488\n",
      "Epoch 1779, Loss: 0.0044768815860152245, Final Batch Loss: 0.0022693141363561153\n",
      "Epoch 1780, Loss: 0.0028624199330806732, Final Batch Loss: 0.001417272724211216\n",
      "Epoch 1781, Loss: 0.0037336552049964666, Final Batch Loss: 0.0022161798551678658\n",
      "Epoch 1782, Loss: 0.0051282745553180575, Final Batch Loss: 0.001414754311554134\n",
      "Epoch 1783, Loss: 0.001337047724518925, Final Batch Loss: 0.00011152419028803706\n",
      "Epoch 1784, Loss: 0.001761118182912469, Final Batch Loss: 0.0007064646342769265\n",
      "Epoch 1785, Loss: 0.011946028331294656, Final Batch Loss: 0.00296304770745337\n",
      "Epoch 1786, Loss: 0.0011040354729630053, Final Batch Loss: 0.0007347698556259274\n",
      "Epoch 1787, Loss: 0.001106564304791391, Final Batch Loss: 0.0006001638248562813\n",
      "Epoch 1788, Loss: 0.004454505397006869, Final Batch Loss: 0.001119483495131135\n",
      "Epoch 1789, Loss: 0.0013770401128567755, Final Batch Loss: 0.0009740074165165424\n",
      "Epoch 1790, Loss: 0.0014707307891512755, Final Batch Loss: 4.609968527802266e-05\n",
      "Epoch 1791, Loss: 0.0019575156620703638, Final Batch Loss: 0.0011636209674179554\n",
      "Epoch 1792, Loss: 0.0010490243439562619, Final Batch Loss: 0.0005885256687179208\n",
      "Epoch 1793, Loss: 0.0012789591564796865, Final Batch Loss: 0.00021800125250592828\n",
      "Epoch 1794, Loss: 0.0019644674321170896, Final Batch Loss: 0.0017446435522288084\n",
      "Epoch 1795, Loss: 0.002841161098331213, Final Batch Loss: 0.0025407844223082066\n",
      "Epoch 1796, Loss: 0.0019490121630951762, Final Batch Loss: 0.0009344354039058089\n",
      "Epoch 1797, Loss: 0.0008374898025067523, Final Batch Loss: 0.0001476117322454229\n",
      "Epoch 1798, Loss: 0.019033568096347153, Final Batch Loss: 0.0006315839709714055\n",
      "Epoch 1799, Loss: 0.005429102951893583, Final Batch Loss: 0.005105573683977127\n",
      "Epoch 1800, Loss: 0.0005131319776410237, Final Batch Loss: 0.00015417746908497065\n",
      "Epoch 1801, Loss: 0.0010775313712656498, Final Batch Loss: 0.0002612955286167562\n",
      "Epoch 1802, Loss: 0.010375317884609103, Final Batch Loss: 0.008786541409790516\n",
      "Epoch 1803, Loss: 0.0016695170779712498, Final Batch Loss: 0.0004080681246705353\n",
      "Epoch 1804, Loss: 0.003001307850354351, Final Batch Loss: 0.00022647438163403422\n",
      "Epoch 1805, Loss: 0.000919611455174163, Final Batch Loss: 0.0006001160363666713\n",
      "Epoch 1806, Loss: 0.01881584117654711, Final Batch Loss: 0.0015725359553471208\n",
      "Epoch 1807, Loss: 0.003824958810582757, Final Batch Loss: 0.002353380899876356\n",
      "Epoch 1808, Loss: 0.002433470741380006, Final Batch Loss: 0.002140240278095007\n",
      "Epoch 1809, Loss: 0.0017914503114297986, Final Batch Loss: 0.00135053473059088\n",
      "Epoch 1810, Loss: 0.002673670183867216, Final Batch Loss: 0.0006204622332006693\n",
      "Epoch 1811, Loss: 0.0037650377489626408, Final Batch Loss: 0.001375886145979166\n",
      "Epoch 1812, Loss: 0.01691969856619835, Final Batch Loss: 0.004646997898817062\n",
      "Epoch 1813, Loss: 0.006128033273853362, Final Batch Loss: 0.001006107428111136\n",
      "Epoch 1814, Loss: 0.00023650429648114368, Final Batch Loss: 0.0001374952116748318\n",
      "Epoch 1815, Loss: 0.0028528972761705518, Final Batch Loss: 0.0018624933436512947\n",
      "Epoch 1816, Loss: 0.002160981748602353, Final Batch Loss: 0.0001458355545764789\n",
      "Epoch 1817, Loss: 0.0008115049276966602, Final Batch Loss: 0.00037987451651133597\n",
      "Epoch 1818, Loss: 0.08595609525218606, Final Batch Loss: 0.08522781729698181\n",
      "Epoch 1819, Loss: 0.00338372535770759, Final Batch Loss: 0.002774531953036785\n",
      "Epoch 1820, Loss: 0.003297919814940542, Final Batch Loss: 0.002940367441624403\n",
      "Epoch 1821, Loss: 0.0011619464785326272, Final Batch Loss: 0.0008194767287932336\n",
      "Epoch 1822, Loss: 0.0011951555352425203, Final Batch Loss: 8.728481770958751e-05\n",
      "Epoch 1823, Loss: 0.0008388835703954101, Final Batch Loss: 0.0005910408799536526\n",
      "Epoch 1824, Loss: 0.0029357608291320503, Final Batch Loss: 0.0026435048785060644\n",
      "Epoch 1825, Loss: 0.005862534744665027, Final Batch Loss: 0.004956679418683052\n",
      "Epoch 1826, Loss: 0.0018740971572697163, Final Batch Loss: 0.001057938439771533\n",
      "Epoch 1827, Loss: 0.0015596926677972078, Final Batch Loss: 0.0006668303976766765\n",
      "Epoch 1828, Loss: 0.0015505814808420837, Final Batch Loss: 0.0009205808746628463\n",
      "Epoch 1829, Loss: 0.0031603658135281876, Final Batch Loss: 0.00017509372264612466\n",
      "Epoch 1830, Loss: 0.001882425269286614, Final Batch Loss: 0.00010721035505412146\n",
      "Epoch 1831, Loss: 0.00035317741276230663, Final Batch Loss: 0.00021648906113114208\n",
      "Epoch 1832, Loss: 0.0016977930208668113, Final Batch Loss: 0.0011625863844528794\n",
      "Epoch 1833, Loss: 0.003458473307546228, Final Batch Loss: 0.0005610936204902828\n",
      "Epoch 1834, Loss: 0.0013932234141975641, Final Batch Loss: 0.0004569075535982847\n",
      "Epoch 1835, Loss: 0.0070115323178470135, Final Batch Loss: 0.0016920422203838825\n",
      "Epoch 1836, Loss: 0.0015163729840423912, Final Batch Loss: 0.0011054874630644917\n",
      "Epoch 1837, Loss: 0.0009724481787998229, Final Batch Loss: 0.0003834486997220665\n",
      "Epoch 1838, Loss: 0.006679782294668257, Final Batch Loss: 0.004910790361464024\n",
      "Epoch 1839, Loss: 0.02315756632015109, Final Batch Loss: 0.0063670179806649685\n",
      "Epoch 1840, Loss: 0.0014333809958770871, Final Batch Loss: 0.0004936255281791091\n",
      "Epoch 1841, Loss: 0.0031675584614276886, Final Batch Loss: 0.0010576562490314245\n",
      "Epoch 1842, Loss: 0.002095468051265925, Final Batch Loss: 0.0004932649317197502\n",
      "Epoch 1843, Loss: 0.010772465262562037, Final Batch Loss: 0.0064262161031365395\n",
      "Epoch 1844, Loss: 0.003559602366294712, Final Batch Loss: 0.0007855397998355329\n",
      "Epoch 1845, Loss: 0.012444650754332542, Final Batch Loss: 0.011441824026405811\n",
      "Epoch 1846, Loss: 0.000661051002680324, Final Batch Loss: 0.00020584392768796533\n",
      "Epoch 1847, Loss: 0.015438654576428235, Final Batch Loss: 0.013577159494161606\n",
      "Epoch 1848, Loss: 0.0038708128267899156, Final Batch Loss: 0.0027047365438193083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1849, Loss: 0.0026305570791009814, Final Batch Loss: 0.002166688209399581\n",
      "Epoch 1850, Loss: 0.003585368220228702, Final Batch Loss: 0.0008556054090149701\n",
      "Epoch 1851, Loss: 0.0022197815123945475, Final Batch Loss: 0.000984717276878655\n",
      "Epoch 1852, Loss: 0.000872372547746636, Final Batch Loss: 0.00014641288726124913\n",
      "Epoch 1853, Loss: 0.0018283818499185145, Final Batch Loss: 0.00033327919663861394\n",
      "Epoch 1854, Loss: 0.0009516216086922213, Final Batch Loss: 0.00022767535119783133\n",
      "Epoch 1855, Loss: 0.000925559397728648, Final Batch Loss: 7.17283328413032e-05\n",
      "Epoch 1856, Loss: 0.0005045842990512028, Final Batch Loss: 0.00017495315114501864\n",
      "Epoch 1857, Loss: 0.0014791201101616025, Final Batch Loss: 0.0009882202139124274\n",
      "Epoch 1858, Loss: 0.030599288875237107, Final Batch Loss: 0.0009612387511879206\n",
      "Epoch 1859, Loss: 0.002271522069349885, Final Batch Loss: 0.0007827786030247808\n",
      "Epoch 1860, Loss: 0.0008780838106758893, Final Batch Loss: 0.0002958662807941437\n",
      "Epoch 1861, Loss: 0.0066560199920786545, Final Batch Loss: 0.00019508790865074843\n",
      "Epoch 1862, Loss: 0.0009220856009051204, Final Batch Loss: 0.0001303142635151744\n",
      "Epoch 1863, Loss: 0.010051852907054126, Final Batch Loss: 0.008201375603675842\n",
      "Epoch 1864, Loss: 0.0046350117190741, Final Batch Loss: 0.003954390995204449\n",
      "Epoch 1865, Loss: 0.0010571755556156859, Final Batch Loss: 9.972041880246252e-05\n",
      "Epoch 1866, Loss: 0.0006796164525439963, Final Batch Loss: 0.00018105846538674086\n",
      "Epoch 1867, Loss: 0.0009958714508684352, Final Batch Loss: 0.00011502737470436841\n",
      "Epoch 1868, Loss: 0.001373563674860634, Final Batch Loss: 0.00011837856436613947\n",
      "Epoch 1869, Loss: 0.007782034110277891, Final Batch Loss: 0.005523367319256067\n",
      "Epoch 1870, Loss: 0.005817007855512202, Final Batch Loss: 0.00023844523821026087\n",
      "Epoch 1871, Loss: 0.000954129354795441, Final Batch Loss: 0.0006205171230249107\n",
      "Epoch 1872, Loss: 0.0007324831385631114, Final Batch Loss: 0.0003901273012161255\n",
      "Epoch 1873, Loss: 0.0018569391831988469, Final Batch Loss: 0.0016489754198119044\n",
      "Epoch 1874, Loss: 0.009344032849185169, Final Batch Loss: 0.0017128268955275416\n",
      "Epoch 1875, Loss: 0.0022202194086275995, Final Batch Loss: 0.0012518077855929732\n",
      "Epoch 1876, Loss: 0.043047661063610576, Final Batch Loss: 0.04286676645278931\n",
      "Epoch 1877, Loss: 0.0013540128711611032, Final Batch Loss: 0.0003239379730075598\n",
      "Epoch 1878, Loss: 0.001586834157933481, Final Batch Loss: 0.00020477788348216563\n",
      "Epoch 1879, Loss: 0.002696072100661695, Final Batch Loss: 0.0014537237584590912\n",
      "Epoch 1880, Loss: 0.015580927531118505, Final Batch Loss: 0.01538714300841093\n",
      "Epoch 1881, Loss: 0.001110148907173425, Final Batch Loss: 0.00023897754726931453\n",
      "Epoch 1882, Loss: 0.0035175496013835073, Final Batch Loss: 0.0026004095561802387\n",
      "Epoch 1883, Loss: 0.00340706022689119, Final Batch Loss: 0.00029510894091799855\n",
      "Epoch 1884, Loss: 0.027650012751109898, Final Batch Loss: 0.026518210768699646\n",
      "Epoch 1885, Loss: 0.030633256770670414, Final Batch Loss: 0.008118006400763988\n",
      "Epoch 1886, Loss: 0.0003462512686382979, Final Batch Loss: 0.00026366059319116175\n",
      "Epoch 1887, Loss: 0.03381269148667343, Final Batch Loss: 0.0002567181654740125\n",
      "Epoch 1888, Loss: 0.0007583623882965185, Final Batch Loss: 0.00011990135681116953\n",
      "Epoch 1889, Loss: 0.04134418029570952, Final Batch Loss: 0.0001759450533427298\n",
      "Epoch 1890, Loss: 0.0015013710362836719, Final Batch Loss: 0.0004754912806674838\n",
      "Epoch 1891, Loss: 0.003401542315259576, Final Batch Loss: 0.001709439093247056\n",
      "Epoch 1892, Loss: 0.0016734213277231902, Final Batch Loss: 0.0012879937421530485\n",
      "Epoch 1893, Loss: 0.001404357171850279, Final Batch Loss: 0.00036865464062429965\n",
      "Epoch 1894, Loss: 0.0016203159611904994, Final Batch Loss: 0.0001906050747493282\n",
      "Epoch 1895, Loss: 0.0071930117410374805, Final Batch Loss: 0.0001353137631667778\n",
      "Epoch 1896, Loss: 0.000784233576268889, Final Batch Loss: 0.00024007663887459785\n",
      "Epoch 1897, Loss: 0.0042711031856015325, Final Batch Loss: 0.003184148110449314\n",
      "Epoch 1898, Loss: 0.004422190831974149, Final Batch Loss: 0.0034188295248895884\n",
      "Epoch 1899, Loss: 0.007146168878534809, Final Batch Loss: 0.00012149839312769473\n",
      "Epoch 1900, Loss: 0.004625505767762661, Final Batch Loss: 0.0026179186534136534\n",
      "Epoch 1901, Loss: 0.004970583715476096, Final Batch Loss: 0.0036024386063218117\n",
      "Epoch 1902, Loss: 0.004412320093251765, Final Batch Loss: 0.003557915100827813\n",
      "Epoch 1903, Loss: 0.0011146945180371404, Final Batch Loss: 0.00027480925200507045\n",
      "Epoch 1904, Loss: 0.002903875894844532, Final Batch Loss: 0.0006749879103153944\n",
      "Epoch 1905, Loss: 0.0021030373172834516, Final Batch Loss: 0.0016436768928542733\n",
      "Epoch 1906, Loss: 0.0004213658539811149, Final Batch Loss: 0.00014674830890726298\n",
      "Epoch 1907, Loss: 0.0019280065316706896, Final Batch Loss: 0.0012809580657631159\n",
      "Epoch 1908, Loss: 0.0017357164761051536, Final Batch Loss: 0.00031323847360908985\n",
      "Epoch 1909, Loss: 0.0014702579355798662, Final Batch Loss: 0.0002287504612468183\n",
      "Epoch 1910, Loss: 0.0043447710340842605, Final Batch Loss: 0.0008532797219231725\n",
      "Epoch 1911, Loss: 0.009763773647136986, Final Batch Loss: 0.00047000416088849306\n",
      "Epoch 1912, Loss: 0.004029761883430183, Final Batch Loss: 0.0006516586290672421\n",
      "Epoch 1913, Loss: 0.0011339749617036432, Final Batch Loss: 0.00028446639771573246\n",
      "Epoch 1914, Loss: 0.002517011307645589, Final Batch Loss: 0.0005609843065030873\n",
      "Epoch 1915, Loss: 0.005801826424431056, Final Batch Loss: 0.0003219234640710056\n",
      "Epoch 1916, Loss: 0.0063242592150345445, Final Batch Loss: 0.00014086638111621141\n",
      "Epoch 1917, Loss: 0.0012231591099407524, Final Batch Loss: 0.0009634069283492863\n",
      "Epoch 1918, Loss: 0.0009372867061756551, Final Batch Loss: 0.00022378971334546804\n",
      "Epoch 1919, Loss: 0.00120321566646453, Final Batch Loss: 0.001078178989700973\n",
      "Epoch 1920, Loss: 0.0013310660142451525, Final Batch Loss: 0.0006750797037966549\n",
      "Epoch 1921, Loss: 0.0012357603554846719, Final Batch Loss: 0.0002235620777355507\n",
      "Epoch 1922, Loss: 0.029875320149585605, Final Batch Loss: 0.02905569039285183\n",
      "Epoch 1923, Loss: 0.0037380399589892477, Final Batch Loss: 0.0034653693437576294\n",
      "Epoch 1924, Loss: 0.0039049985352903605, Final Batch Loss: 0.0034153214655816555\n",
      "Epoch 1925, Loss: 0.004166498314589262, Final Batch Loss: 0.002220490714535117\n",
      "Epoch 1926, Loss: 0.007525260327383876, Final Batch Loss: 0.005211797077208757\n",
      "Epoch 1927, Loss: 0.0032135089859366417, Final Batch Loss: 0.0007402466144412756\n",
      "Epoch 1928, Loss: 0.007201172993518412, Final Batch Loss: 0.0010068818228319287\n",
      "Epoch 1929, Loss: 0.0021921275183558464, Final Batch Loss: 0.0007875055307522416\n",
      "Epoch 1930, Loss: 0.0009957306610886008, Final Batch Loss: 0.0004773530235979706\n",
      "Epoch 1931, Loss: 0.0008065455622272566, Final Batch Loss: 0.00010381337779108435\n",
      "Epoch 1932, Loss: 0.0020782715582754463, Final Batch Loss: 0.0003692318859975785\n",
      "Epoch 1933, Loss: 0.005699125933460891, Final Batch Loss: 0.0014126746682450175\n",
      "Epoch 1934, Loss: 0.0017442493117414415, Final Batch Loss: 0.0012206988176330924\n",
      "Epoch 1935, Loss: 0.0010892350692301989, Final Batch Loss: 0.0005381911178119481\n",
      "Epoch 1936, Loss: 0.0008234864071710035, Final Batch Loss: 8.298420289065689e-05\n",
      "Epoch 1937, Loss: 0.0031592818413628265, Final Batch Loss: 0.00023588193289469928\n",
      "Epoch 1938, Loss: 0.0006700959784211591, Final Batch Loss: 0.0004749898798763752\n",
      "Epoch 1939, Loss: 0.001202746934723109, Final Batch Loss: 0.0006536772707477212\n",
      "Epoch 1940, Loss: 0.027933748555369675, Final Batch Loss: 0.027136653661727905\n",
      "Epoch 1941, Loss: 0.0017024170083459467, Final Batch Loss: 0.00024498565471731126\n",
      "Epoch 1942, Loss: 0.0003951965845772065, Final Batch Loss: 3.884782927343622e-05\n",
      "Epoch 1943, Loss: 0.003583474550396204, Final Batch Loss: 0.0006805984303355217\n",
      "Epoch 1944, Loss: 0.0049255265039391816, Final Batch Loss: 0.0039848219603300095\n",
      "Epoch 1945, Loss: 0.0025183812249451876, Final Batch Loss: 0.0008173967944458127\n",
      "Epoch 1946, Loss: 0.0012254452740307897, Final Batch Loss: 0.0004819950263481587\n",
      "Epoch 1947, Loss: 0.0034371461952105165, Final Batch Loss: 0.0005128568736836314\n",
      "Epoch 1948, Loss: 0.00480877970403526, Final Batch Loss: 0.000230975347221829\n",
      "Epoch 1949, Loss: 0.0017827546398621053, Final Batch Loss: 0.0003067316429223865\n",
      "Epoch 1950, Loss: 0.010844265343621373, Final Batch Loss: 0.009424882009625435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1951, Loss: 0.0038639629492536187, Final Batch Loss: 0.0017070918111130595\n",
      "Epoch 1952, Loss: 0.0066531505435705185, Final Batch Loss: 0.006109454669058323\n",
      "Epoch 1953, Loss: 0.000518085558724124, Final Batch Loss: 0.00010632334306137636\n",
      "Epoch 1954, Loss: 0.0013374156842473894, Final Batch Loss: 0.0009582988568581641\n",
      "Epoch 1955, Loss: 0.00362227218283806, Final Batch Loss: 0.0034930699039250612\n",
      "Epoch 1956, Loss: 0.006961052669794299, Final Batch Loss: 0.0002329362469026819\n",
      "Epoch 1957, Loss: 0.0034664970880839974, Final Batch Loss: 0.0032135634683072567\n",
      "Epoch 1958, Loss: 0.0008613449754193425, Final Batch Loss: 0.0005871555767953396\n",
      "Epoch 1959, Loss: 0.033823327044956386, Final Batch Loss: 0.03276785463094711\n",
      "Epoch 1960, Loss: 0.0042691732523962855, Final Batch Loss: 0.0014975612284615636\n",
      "Epoch 1961, Loss: 0.002019998792093247, Final Batch Loss: 0.0010659625986590981\n",
      "Epoch 1962, Loss: 0.00038917968049645424, Final Batch Loss: 0.000171397186932154\n",
      "Epoch 1963, Loss: 0.007037757968646474, Final Batch Loss: 0.00011751994316000491\n",
      "Epoch 1964, Loss: 0.0016396601567976177, Final Batch Loss: 0.0009303396218456328\n",
      "Epoch 1965, Loss: 0.000862356013385579, Final Batch Loss: 0.0003913092950824648\n",
      "Epoch 1966, Loss: 0.0011792517761932686, Final Batch Loss: 6.935496639925987e-05\n",
      "Epoch 1967, Loss: 0.0007942509546410292, Final Batch Loss: 0.0005751183489337564\n",
      "Epoch 1968, Loss: 0.0007941174553707242, Final Batch Loss: 7.54122156649828e-05\n",
      "Epoch 1969, Loss: 0.00080653972690925, Final Batch Loss: 0.0005214536213316023\n",
      "Epoch 1970, Loss: 0.0015624561929143965, Final Batch Loss: 0.0014595253160223365\n",
      "Epoch 1971, Loss: 0.0005327998260327149, Final Batch Loss: 5.5424945458071306e-05\n",
      "Epoch 1972, Loss: 0.0016480866179335862, Final Batch Loss: 0.0011743627255782485\n",
      "Epoch 1973, Loss: 0.002178691269364208, Final Batch Loss: 0.0013556811027228832\n",
      "Epoch 1974, Loss: 0.0009858550620265305, Final Batch Loss: 0.0005843142280355096\n",
      "Epoch 1975, Loss: 0.003568482934497297, Final Batch Loss: 0.002404895145446062\n",
      "Epoch 1976, Loss: 0.0025326660834252834, Final Batch Loss: 0.001255897106602788\n",
      "Epoch 1977, Loss: 0.0017892340547405183, Final Batch Loss: 0.001213714829646051\n",
      "Epoch 1978, Loss: 0.001321839721640572, Final Batch Loss: 0.0010619425447657704\n",
      "Epoch 1979, Loss: 0.0005686057556886226, Final Batch Loss: 0.0004273238009773195\n",
      "Epoch 1980, Loss: 0.002645102154929191, Final Batch Loss: 0.0021484331227838993\n",
      "Epoch 1981, Loss: 0.0025142544764094055, Final Batch Loss: 0.002162002958357334\n",
      "Epoch 1982, Loss: 0.003088068391662091, Final Batch Loss: 0.0003558564349077642\n",
      "Epoch 1983, Loss: 0.0007388911617454141, Final Batch Loss: 0.00036712782457470894\n",
      "Epoch 1984, Loss: 0.0003745430658455007, Final Batch Loss: 0.00010914514859905466\n",
      "Epoch 1985, Loss: 0.0003905144039890729, Final Batch Loss: 0.0002980775898322463\n",
      "Epoch 1986, Loss: 0.0030889742774888873, Final Batch Loss: 0.001243634382262826\n",
      "Epoch 1987, Loss: 0.0011194608523510396, Final Batch Loss: 0.0006197743932716548\n",
      "Epoch 1988, Loss: 0.003530215471982956, Final Batch Loss: 0.002243642695248127\n",
      "Epoch 1989, Loss: 0.0004343273612903431, Final Batch Loss: 0.00024212247808463871\n",
      "Epoch 1990, Loss: 0.004264516464900225, Final Batch Loss: 0.0036586900241672993\n",
      "Epoch 1991, Loss: 0.012204399012262002, Final Batch Loss: 0.0002759282069746405\n",
      "Epoch 1992, Loss: 0.003712826524861157, Final Batch Loss: 0.003435308812186122\n",
      "Epoch 1993, Loss: 0.0003327181839267723, Final Batch Loss: 0.0002422016259515658\n",
      "Epoch 1994, Loss: 0.005421497888164595, Final Batch Loss: 0.00044440620695240796\n",
      "Epoch 1995, Loss: 0.0009451477089896798, Final Batch Loss: 0.00018453074153512716\n",
      "Epoch 1996, Loss: 0.026535753917414695, Final Batch Loss: 0.025787480175495148\n",
      "Epoch 1997, Loss: 0.000621624116320163, Final Batch Loss: 0.00036909402115270495\n",
      "Epoch 1998, Loss: 0.0009019051067298278, Final Batch Loss: 0.0007059522904455662\n",
      "Epoch 1999, Loss: 0.0002751844731392339, Final Batch Loss: 0.00013598520308732986\n",
      "Epoch 2000, Loss: 0.0019067488610744476, Final Batch Loss: 0.0002585871843621135\n",
      "Epoch 2001, Loss: 0.0017422977252863348, Final Batch Loss: 0.0007929209969006479\n",
      "Epoch 2002, Loss: 0.012130939539929386, Final Batch Loss: 0.012034486047923565\n",
      "Epoch 2003, Loss: 0.004111496629775502, Final Batch Loss: 0.00015247463306877762\n",
      "Epoch 2004, Loss: 0.017970496090129018, Final Batch Loss: 0.002409883076325059\n",
      "Epoch 2005, Loss: 0.035192147304769605, Final Batch Loss: 0.00048338662600144744\n",
      "Epoch 2006, Loss: 0.001775480355718173, Final Batch Loss: 0.00023681229504290968\n",
      "Epoch 2007, Loss: 0.002365521853789687, Final Batch Loss: 0.0012259271461516619\n",
      "Epoch 2008, Loss: 0.001520883641205728, Final Batch Loss: 0.0008474425412714481\n",
      "Epoch 2009, Loss: 0.0111310463398695, Final Batch Loss: 0.008417961187660694\n",
      "Epoch 2010, Loss: 0.005834557116031647, Final Batch Loss: 0.004836982116103172\n",
      "Epoch 2011, Loss: 0.0065248082973994315, Final Batch Loss: 0.0005706246593035758\n",
      "Epoch 2012, Loss: 0.0032812471326906234, Final Batch Loss: 0.002908754860982299\n",
      "Epoch 2013, Loss: 0.009359835181385279, Final Batch Loss: 0.004811273887753487\n",
      "Epoch 2014, Loss: 0.00040216812340077013, Final Batch Loss: 7.10413878550753e-05\n",
      "Epoch 2015, Loss: 0.0015476326225325465, Final Batch Loss: 0.0009355204529128969\n",
      "Epoch 2016, Loss: 0.002786622993880883, Final Batch Loss: 0.00028735879459418356\n",
      "Epoch 2017, Loss: 0.0014983800065238029, Final Batch Loss: 0.0003199883794877678\n",
      "Epoch 2018, Loss: 0.01705800532363355, Final Batch Loss: 0.013824758119881153\n",
      "Epoch 2019, Loss: 0.0008001377282198519, Final Batch Loss: 0.00020123578724451363\n",
      "Epoch 2020, Loss: 0.001812363916542381, Final Batch Loss: 0.0016603304538875818\n",
      "Epoch 2021, Loss: 0.005637114518322051, Final Batch Loss: 0.00021891819778829813\n",
      "Epoch 2022, Loss: 0.006154603091999888, Final Batch Loss: 0.003165106987580657\n",
      "Epoch 2023, Loss: 0.00047338228614535183, Final Batch Loss: 0.0001621057017473504\n",
      "Epoch 2024, Loss: 0.008479827898554504, Final Batch Loss: 0.0010773794492706656\n",
      "Epoch 2025, Loss: 0.005118963308632374, Final Batch Loss: 0.0016367966309189796\n",
      "Epoch 2026, Loss: 0.048239369643852115, Final Batch Loss: 0.0031374997925013304\n",
      "Epoch 2027, Loss: 0.0017490191967226565, Final Batch Loss: 0.0008555776439607143\n",
      "Epoch 2028, Loss: 0.0015551300602965057, Final Batch Loss: 0.0012516924180090427\n",
      "Epoch 2029, Loss: 0.0009722435788717121, Final Batch Loss: 0.00014627285418100655\n",
      "Epoch 2030, Loss: 0.0010459399491082877, Final Batch Loss: 0.0006343814311549067\n",
      "Epoch 2031, Loss: 0.0022511726710945368, Final Batch Loss: 0.0012516562128439546\n",
      "Epoch 2032, Loss: 0.0015200316265691072, Final Batch Loss: 0.0004709807981271297\n",
      "Epoch 2033, Loss: 0.00118152768118307, Final Batch Loss: 0.0008089286857284606\n",
      "Epoch 2034, Loss: 0.0037529638648265973, Final Batch Loss: 0.00020979928376618773\n",
      "Epoch 2035, Loss: 0.0031064737122505903, Final Batch Loss: 0.0017355692107230425\n",
      "Epoch 2036, Loss: 0.0009202314831782132, Final Batch Loss: 0.0006467771017923951\n",
      "Epoch 2037, Loss: 0.002085945743601769, Final Batch Loss: 0.00029730022652074695\n",
      "Epoch 2038, Loss: 0.0015522619214607403, Final Batch Loss: 0.00023524653806816787\n",
      "Epoch 2039, Loss: 0.0009049457294167951, Final Batch Loss: 0.0006895404658280313\n",
      "Epoch 2040, Loss: 0.0005844408733537421, Final Batch Loss: 0.00023596394748892635\n",
      "Epoch 2041, Loss: 0.00058451370568946, Final Batch Loss: 0.00019230169709771872\n",
      "Epoch 2042, Loss: 0.0018998848390765488, Final Batch Loss: 0.0009705692646093667\n",
      "Epoch 2043, Loss: 0.0050390122924000025, Final Batch Loss: 0.00472459988668561\n",
      "Epoch 2044, Loss: 0.0013281757710501552, Final Batch Loss: 0.0004085614928044379\n",
      "Epoch 2045, Loss: 0.00019127523410134017, Final Batch Loss: 0.00010489221313036978\n",
      "Epoch 2046, Loss: 0.0004644322762032971, Final Batch Loss: 0.00010831760300789028\n",
      "Epoch 2047, Loss: 0.00039708579424768686, Final Batch Loss: 6.762240082025528e-05\n",
      "Epoch 2048, Loss: 0.002302209788467735, Final Batch Loss: 0.001886243699118495\n",
      "Epoch 2049, Loss: 0.0013161104288883507, Final Batch Loss: 0.0005653553525917232\n",
      "Epoch 2050, Loss: 0.0018669191049411893, Final Batch Loss: 0.0013193287886679173\n",
      "Epoch 2051, Loss: 0.0033506161416880786, Final Batch Loss: 0.002828216180205345\n",
      "Epoch 2052, Loss: 0.004509924299782142, Final Batch Loss: 0.004096076823771\n",
      "Epoch 2053, Loss: 0.0011691284889820963, Final Batch Loss: 0.0007217554957605898\n",
      "Epoch 2054, Loss: 0.0023330174735747278, Final Batch Loss: 0.0017405892722308636\n",
      "Epoch 2055, Loss: 0.0018730732263065875, Final Batch Loss: 0.001466827467083931\n",
      "Epoch 2056, Loss: 0.0019735131645575166, Final Batch Loss: 0.0009858121629804373\n",
      "Epoch 2057, Loss: 0.0036942713413736783, Final Batch Loss: 0.003621067386120558\n",
      "Epoch 2058, Loss: 0.001482831605244428, Final Batch Loss: 0.0006287213764153421\n",
      "Epoch 2059, Loss: 0.0024387767480220646, Final Batch Loss: 0.002085716463625431\n",
      "Epoch 2060, Loss: 0.0036150649539195, Final Batch Loss: 0.0008231477695517242\n",
      "Epoch 2061, Loss: 0.0012710265291389078, Final Batch Loss: 8.510085172019899e-05\n",
      "Epoch 2062, Loss: 0.0024610881227999926, Final Batch Loss: 0.0013279838021844625\n",
      "Epoch 2063, Loss: 0.0012483983300626278, Final Batch Loss: 0.0004035292658954859\n",
      "Epoch 2064, Loss: 0.0019798900902969763, Final Batch Loss: 7.212224591057748e-05\n",
      "Epoch 2065, Loss: 0.00021092648967169225, Final Batch Loss: 0.00011042773985536769\n",
      "Epoch 2066, Loss: 0.0004998803997295909, Final Batch Loss: 9.83235877356492e-05\n",
      "Epoch 2067, Loss: 0.00043550392729230225, Final Batch Loss: 0.0002500267291907221\n",
      "Epoch 2068, Loss: 0.0010876536252908409, Final Batch Loss: 0.0005891611217521131\n",
      "Epoch 2069, Loss: 0.001110135082853958, Final Batch Loss: 0.00017635998665355146\n",
      "Epoch 2070, Loss: 0.010090666357427835, Final Batch Loss: 0.005568782798945904\n",
      "Epoch 2071, Loss: 0.0009260886145057157, Final Batch Loss: 0.00010537136404309422\n",
      "Epoch 2072, Loss: 0.0010106053086929023, Final Batch Loss: 0.0006227110861800611\n",
      "Epoch 2073, Loss: 0.0006153538997750729, Final Batch Loss: 0.00023651059018447995\n",
      "Epoch 2074, Loss: 0.0044630935590248555, Final Batch Loss: 0.00402631051838398\n",
      "Epoch 2075, Loss: 0.004214249252981972, Final Batch Loss: 9.125208453042433e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2076, Loss: 0.0003970800607930869, Final Batch Loss: 0.00010151657625101507\n",
      "Epoch 2077, Loss: 0.0006287894211709499, Final Batch Loss: 0.0003760326944757253\n",
      "Epoch 2078, Loss: 0.0014717738231411204, Final Batch Loss: 0.00019130446889903396\n",
      "Epoch 2079, Loss: 0.0019902258936781436, Final Batch Loss: 0.001826740219257772\n",
      "Epoch 2080, Loss: 0.0012566622463054955, Final Batch Loss: 0.00041371298721060157\n",
      "Epoch 2081, Loss: 0.00575850710447412, Final Batch Loss: 0.005639733746647835\n",
      "Epoch 2082, Loss: 0.0009722122631501406, Final Batch Loss: 0.0005794817698188126\n",
      "Epoch 2083, Loss: 0.0007235413650050759, Final Batch Loss: 0.00022194202756509185\n",
      "Epoch 2084, Loss: 0.0004438995965756476, Final Batch Loss: 0.00017104920698329806\n",
      "Epoch 2085, Loss: 0.0015343739796662703, Final Batch Loss: 0.0013535687467083335\n",
      "Epoch 2086, Loss: 0.005258976627374068, Final Batch Loss: 0.0050790393725037575\n",
      "Epoch 2087, Loss: 0.03366010835452471, Final Batch Loss: 0.03347727656364441\n",
      "Epoch 2088, Loss: 0.0018287144193891436, Final Batch Loss: 0.00026975831133313477\n",
      "Epoch 2089, Loss: 0.002704676298890263, Final Batch Loss: 0.0006554497522301972\n",
      "Epoch 2090, Loss: 0.000857058068504557, Final Batch Loss: 0.00045614567352458835\n",
      "Epoch 2091, Loss: 0.025758215204405133, Final Batch Loss: 0.02567816525697708\n",
      "Epoch 2092, Loss: 0.00037635247281286865, Final Batch Loss: 0.00012518301082309335\n",
      "Epoch 2093, Loss: 0.00235264396542334, Final Batch Loss: 5.8120323956245556e-05\n",
      "Epoch 2094, Loss: 0.008256641332991421, Final Batch Loss: 0.0008677338482812047\n",
      "Epoch 2095, Loss: 0.0025550860445946455, Final Batch Loss: 0.0007446033414453268\n",
      "Epoch 2096, Loss: 0.010690101771615446, Final Batch Loss: 0.009043709374964237\n",
      "Epoch 2097, Loss: 0.0007890019624028355, Final Batch Loss: 0.00024118690635077655\n",
      "Epoch 2098, Loss: 0.015537198734818958, Final Batch Loss: 0.015377657487988472\n",
      "Epoch 2099, Loss: 0.00024144035705830902, Final Batch Loss: 7.471199205610901e-05\n",
      "Epoch 2100, Loss: 0.0013588073197752237, Final Batch Loss: 0.0007549605215899646\n",
      "Epoch 2101, Loss: 0.0007342184526351048, Final Batch Loss: 2.9742366677965038e-05\n",
      "Epoch 2102, Loss: 0.0012650122225750238, Final Batch Loss: 6.780659896321595e-05\n",
      "Epoch 2103, Loss: 0.02626412478275597, Final Batch Loss: 0.0012434639502316713\n",
      "Epoch 2104, Loss: 0.0004851734411204234, Final Batch Loss: 0.0002508521138224751\n",
      "Epoch 2105, Loss: 0.0021107169886818156, Final Batch Loss: 0.00016304953896906227\n",
      "Epoch 2106, Loss: 0.0024922094598878175, Final Batch Loss: 0.000393516878830269\n",
      "Epoch 2107, Loss: 0.0006484873956651427, Final Batch Loss: 0.0001137603321694769\n",
      "Epoch 2108, Loss: 0.009192506317049265, Final Batch Loss: 0.00839806254953146\n",
      "Epoch 2109, Loss: 0.0038120274839457124, Final Batch Loss: 0.0002814951294567436\n",
      "Epoch 2110, Loss: 0.0009065303893294185, Final Batch Loss: 0.00035636723623611033\n",
      "Epoch 2111, Loss: 0.0013338596909306943, Final Batch Loss: 0.000802615424618125\n",
      "Epoch 2112, Loss: 0.0005856927018612623, Final Batch Loss: 0.0001841954654082656\n",
      "Epoch 2113, Loss: 0.003542170743457973, Final Batch Loss: 0.003363116644322872\n",
      "Epoch 2114, Loss: 0.007674439591937698, Final Batch Loss: 0.0074357218109071255\n",
      "Epoch 2115, Loss: 0.007072641630657017, Final Batch Loss: 0.005967993754893541\n",
      "Epoch 2116, Loss: 0.0005271046684356406, Final Batch Loss: 0.00017614253738429397\n",
      "Epoch 2117, Loss: 0.0010924520465778187, Final Batch Loss: 0.0009657899499870837\n",
      "Epoch 2118, Loss: 0.0014346133029903285, Final Batch Loss: 0.0013409786624833941\n",
      "Epoch 2119, Loss: 0.0012775417126249522, Final Batch Loss: 0.00018927696510218084\n",
      "Epoch 2120, Loss: 0.003216331300791353, Final Batch Loss: 0.0005299290060065687\n",
      "Epoch 2121, Loss: 0.0011075386719312519, Final Batch Loss: 0.0008530328050255775\n",
      "Epoch 2122, Loss: 0.0016107089322758839, Final Batch Loss: 0.00018706922128330916\n",
      "Epoch 2123, Loss: 0.016809336841106415, Final Batch Loss: 0.0055287787690758705\n",
      "Epoch 2124, Loss: 0.02088651852682233, Final Batch Loss: 0.013559664599597454\n",
      "Epoch 2125, Loss: 0.00118095354991965, Final Batch Loss: 0.0008041305118240416\n",
      "Epoch 2126, Loss: 0.00554067175835371, Final Batch Loss: 0.0031361361034214497\n",
      "Epoch 2127, Loss: 0.007166568655520678, Final Batch Loss: 0.002015853300690651\n",
      "Epoch 2128, Loss: 0.0008422487881034613, Final Batch Loss: 0.0005216846475377679\n",
      "Epoch 2129, Loss: 0.003521570994053036, Final Batch Loss: 0.00269900425337255\n",
      "Epoch 2130, Loss: 0.0028082760400138795, Final Batch Loss: 0.0008406647830270231\n",
      "Epoch 2131, Loss: 0.001524904786492698, Final Batch Loss: 0.0014078631065785885\n",
      "Epoch 2132, Loss: 0.0004423897262313403, Final Batch Loss: 0.00010472792928339913\n",
      "Epoch 2133, Loss: 0.00015251806325977668, Final Batch Loss: 5.647310899803415e-05\n",
      "Epoch 2134, Loss: 0.0006219333736225963, Final Batch Loss: 0.0002405750856269151\n",
      "Epoch 2135, Loss: 0.0025674925709608942, Final Batch Loss: 0.002141556702554226\n",
      "Epoch 2136, Loss: 0.0007615423819515854, Final Batch Loss: 0.0004906150279566646\n",
      "Epoch 2137, Loss: 0.0002423306395940017, Final Batch Loss: 6.0410700825741515e-05\n",
      "Epoch 2138, Loss: 0.0001135468301072251, Final Batch Loss: 4.125410850974731e-05\n",
      "Epoch 2139, Loss: 0.00038699865399394184, Final Batch Loss: 0.0001784708583727479\n",
      "Epoch 2140, Loss: 0.00042936753015965223, Final Batch Loss: 0.000311089534079656\n",
      "Epoch 2141, Loss: 0.0009078975563170388, Final Batch Loss: 0.00024048839986789972\n",
      "Epoch 2142, Loss: 0.0004127438151044771, Final Batch Loss: 0.00023460955708287656\n",
      "Epoch 2143, Loss: 0.0004699200399045367, Final Batch Loss: 4.037794496980496e-05\n",
      "Epoch 2144, Loss: 0.0015852643409743905, Final Batch Loss: 0.00025107793044298887\n",
      "Epoch 2145, Loss: 0.0004951171868015081, Final Batch Loss: 0.00027249357663095\n",
      "Epoch 2146, Loss: 0.001075211592251435, Final Batch Loss: 0.0008106200257316232\n",
      "Epoch 2147, Loss: 0.0011607401684159413, Final Batch Loss: 0.00010644506255630404\n",
      "Epoch 2148, Loss: 0.0006214455352164805, Final Batch Loss: 0.0002449230814818293\n",
      "Epoch 2149, Loss: 0.002159280877094716, Final Batch Loss: 0.0003120643668808043\n",
      "Epoch 2150, Loss: 0.0019292006618343294, Final Batch Loss: 0.0006027748459018767\n",
      "Epoch 2151, Loss: 0.000569987649214454, Final Batch Loss: 0.00017670793749857694\n",
      "Epoch 2152, Loss: 0.0024434001243207604, Final Batch Loss: 0.00044008917757309973\n",
      "Epoch 2153, Loss: 0.0045964933960931376, Final Batch Loss: 0.00018126350187230855\n",
      "Epoch 2154, Loss: 0.0013643109341501258, Final Batch Loss: 9.485656482866034e-05\n",
      "Epoch 2155, Loss: 0.0024841157646733336, Final Batch Loss: 9.74710492300801e-05\n",
      "Epoch 2156, Loss: 0.0005194728873902932, Final Batch Loss: 0.0001895766326924786\n",
      "Epoch 2157, Loss: 0.000566078131669201, Final Batch Loss: 0.00041379162576049566\n",
      "Epoch 2158, Loss: 0.0011897040458279662, Final Batch Loss: 0.0010731412330642343\n",
      "Epoch 2159, Loss: 0.04475125082535669, Final Batch Loss: 0.044231485575437546\n",
      "Epoch 2160, Loss: 0.0385398780927062, Final Batch Loss: 0.0003126552328467369\n",
      "Epoch 2161, Loss: 0.0027689699199981987, Final Batch Loss: 0.0018032797379419208\n",
      "Epoch 2162, Loss: 0.00039272896538022906, Final Batch Loss: 0.0003072788240388036\n",
      "Epoch 2163, Loss: 0.0006247588607948273, Final Batch Loss: 0.00028987551922909915\n",
      "Epoch 2164, Loss: 0.0003444692410994321, Final Batch Loss: 0.00015162525232881308\n",
      "Epoch 2165, Loss: 0.0004028442417620681, Final Batch Loss: 8.10522396932356e-05\n",
      "Epoch 2166, Loss: 0.0013968853745609522, Final Batch Loss: 0.0007555640186183155\n",
      "Epoch 2167, Loss: 0.00036573178658727556, Final Batch Loss: 0.00016997683269437402\n",
      "Epoch 2168, Loss: 0.010870247788261622, Final Batch Loss: 9.374291403219104e-05\n",
      "Epoch 2169, Loss: 0.0008963300424511544, Final Batch Loss: 0.00011484661808935925\n",
      "Epoch 2170, Loss: 0.00284886168083176, Final Batch Loss: 0.00030202436028048396\n",
      "Epoch 2171, Loss: 0.020889690989861265, Final Batch Loss: 0.020427299663424492\n",
      "Epoch 2172, Loss: 0.011585512896999717, Final Batch Loss: 0.0022916567977517843\n",
      "Epoch 2173, Loss: 0.00043843992170877755, Final Batch Loss: 0.00018639181507751346\n",
      "Epoch 2174, Loss: 0.0022880029282532632, Final Batch Loss: 0.0003546802909113467\n",
      "Epoch 2175, Loss: 0.00029866702971048653, Final Batch Loss: 0.00011395387991797179\n",
      "Epoch 2176, Loss: 0.002067089866613969, Final Batch Loss: 0.001724767847917974\n",
      "Epoch 2177, Loss: 0.0004902278597000986, Final Batch Loss: 0.00011927986633963883\n",
      "Epoch 2178, Loss: 0.009064483223482966, Final Batch Loss: 0.003716096980497241\n",
      "Epoch 2179, Loss: 0.021671103830158245, Final Batch Loss: 0.00011528148752404377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2180, Loss: 0.0015340262616518885, Final Batch Loss: 0.0013291190844029188\n",
      "Epoch 2181, Loss: 0.0007657470123376697, Final Batch Loss: 0.0003160550841130316\n",
      "Epoch 2182, Loss: 0.0023612206568941474, Final Batch Loss: 0.0010056461906060576\n",
      "Epoch 2183, Loss: 0.0105685752350837, Final Batch Loss: 0.008203397504985332\n",
      "Epoch 2184, Loss: 0.00027920701541006565, Final Batch Loss: 0.000127966923173517\n",
      "Epoch 2185, Loss: 0.00467891961307032, Final Batch Loss: 0.004568268544971943\n",
      "Epoch 2186, Loss: 0.0018335655331611633, Final Batch Loss: 0.0008325137896463275\n",
      "Epoch 2187, Loss: 0.0012632361322175711, Final Batch Loss: 0.0004541100061032921\n",
      "Epoch 2188, Loss: 0.002217187255155295, Final Batch Loss: 0.0007238827529363334\n",
      "Epoch 2189, Loss: 0.0007518415950471535, Final Batch Loss: 0.0006247048731893301\n",
      "Epoch 2190, Loss: 0.001431566895917058, Final Batch Loss: 0.0009076204150915146\n",
      "Epoch 2191, Loss: 0.0012443532759789377, Final Batch Loss: 0.000783535826485604\n",
      "Epoch 2192, Loss: 0.0016731447831261903, Final Batch Loss: 0.00014903911505825818\n",
      "Epoch 2193, Loss: 0.0016103321104310453, Final Batch Loss: 0.0010089437710121274\n",
      "Epoch 2194, Loss: 0.002416079252725467, Final Batch Loss: 0.0003927697835024446\n",
      "Epoch 2195, Loss: 0.009694116888567805, Final Batch Loss: 0.003460276173427701\n",
      "Epoch 2196, Loss: 0.0012576941153383814, Final Batch Loss: 4.551375604933128e-05\n",
      "Epoch 2197, Loss: 0.0006732446818205062, Final Batch Loss: 4.752559834741987e-05\n",
      "Epoch 2198, Loss: 0.006965044653043151, Final Batch Loss: 0.005810663569718599\n",
      "Epoch 2199, Loss: 0.0003680998634081334, Final Batch Loss: 0.0002397722564637661\n",
      "Epoch 2200, Loss: 0.0005800954531878233, Final Batch Loss: 0.0002170197549276054\n",
      "Epoch 2201, Loss: 0.00499410682823509, Final Batch Loss: 0.00472990283742547\n",
      "Epoch 2202, Loss: 0.0031275541114155203, Final Batch Loss: 0.0002543482987675816\n",
      "Epoch 2203, Loss: 0.0003209102542314213, Final Batch Loss: 0.00026292388793081045\n",
      "Epoch 2204, Loss: 0.0003257080461480655, Final Batch Loss: 0.0002159512514481321\n",
      "Epoch 2205, Loss: 0.003186865826137364, Final Batch Loss: 0.002148658037185669\n",
      "Epoch 2206, Loss: 0.000275593702099286, Final Batch Loss: 0.0001317287387792021\n",
      "Epoch 2207, Loss: 0.0005928462705924176, Final Batch Loss: 6.649232091149315e-05\n",
      "Epoch 2208, Loss: 0.03166762362525333, Final Batch Loss: 0.00012793760106433183\n",
      "Epoch 2209, Loss: 0.006634314078837633, Final Batch Loss: 0.0016685165464878082\n",
      "Epoch 2210, Loss: 0.0004046662215841934, Final Batch Loss: 0.00028416854911483824\n",
      "Epoch 2211, Loss: 0.0015083521720953286, Final Batch Loss: 0.000729006715118885\n",
      "Epoch 2212, Loss: 0.0020013252506032586, Final Batch Loss: 0.0007775037083774805\n",
      "Epoch 2213, Loss: 0.00039760760773788206, Final Batch Loss: 0.0003426091279834509\n",
      "Epoch 2214, Loss: 0.0018939863657578826, Final Batch Loss: 0.0004247967153787613\n",
      "Epoch 2215, Loss: 0.005903314333409071, Final Batch Loss: 0.004620739724487066\n",
      "Epoch 2216, Loss: 0.0009663439705036581, Final Batch Loss: 0.0004322100430727005\n",
      "Epoch 2217, Loss: 0.0010699279446271248, Final Batch Loss: 4.213245847495273e-05\n",
      "Epoch 2218, Loss: 0.0007374169654212892, Final Batch Loss: 0.0001754298573359847\n",
      "Epoch 2219, Loss: 0.00013216998559073545, Final Batch Loss: 5.377160050556995e-05\n",
      "Epoch 2220, Loss: 0.0011085361074947286, Final Batch Loss: 5.768992195953615e-05\n",
      "Epoch 2221, Loss: 0.000302376996842213, Final Batch Loss: 0.00017948049935512245\n",
      "Epoch 2222, Loss: 0.003149321477394551, Final Batch Loss: 0.0007192734046839178\n",
      "Epoch 2223, Loss: 0.0016662553389323875, Final Batch Loss: 2.9464761610142887e-05\n",
      "Epoch 2224, Loss: 0.0006350583353196271, Final Batch Loss: 8.97629142855294e-05\n",
      "Epoch 2225, Loss: 0.0008241225586971268, Final Batch Loss: 0.0001440656342310831\n",
      "Epoch 2226, Loss: 0.0011093725624959916, Final Batch Loss: 0.0006491087842732668\n",
      "Epoch 2227, Loss: 0.0035047090059379116, Final Batch Loss: 0.0001047057012328878\n",
      "Epoch 2228, Loss: 0.0005207456415519118, Final Batch Loss: 0.0001711764489300549\n",
      "Epoch 2229, Loss: 0.003724732610862702, Final Batch Loss: 0.00020272069377824664\n",
      "Epoch 2230, Loss: 0.005149486591108143, Final Batch Loss: 0.0006335974903777242\n",
      "Epoch 2231, Loss: 0.0005078400572529063, Final Batch Loss: 0.0003503372718114406\n",
      "Epoch 2232, Loss: 0.0010462812788318843, Final Batch Loss: 0.0002768405538517982\n",
      "Epoch 2233, Loss: 0.002400647383183241, Final Batch Loss: 0.0006288666045293212\n",
      "Epoch 2234, Loss: 0.0010156054850085638, Final Batch Loss: 8.261642506113276e-05\n",
      "Epoch 2235, Loss: 0.00030572800096706487, Final Batch Loss: 1.6951616998994723e-05\n",
      "Epoch 2236, Loss: 0.0002794933934637811, Final Batch Loss: 5.6494256568839774e-05\n",
      "Epoch 2237, Loss: 0.000884727603988722, Final Batch Loss: 0.0001315377012360841\n",
      "Epoch 2238, Loss: 0.00025472476772847585, Final Batch Loss: 6.0291738918749616e-05\n",
      "Epoch 2239, Loss: 0.0020265908096916974, Final Batch Loss: 0.0006725876010023057\n",
      "Epoch 2240, Loss: 0.011753946790122427, Final Batch Loss: 0.00010043034853879362\n",
      "Epoch 2241, Loss: 0.006476092559751123, Final Batch Loss: 0.00037076970329508185\n",
      "Epoch 2242, Loss: 0.0009357664384879172, Final Batch Loss: 0.00014518876560032368\n",
      "Epoch 2243, Loss: 0.0010862202034331858, Final Batch Loss: 0.000660228542983532\n",
      "Epoch 2244, Loss: 0.0011248676310060546, Final Batch Loss: 0.0009507713257335126\n",
      "Epoch 2245, Loss: 0.00014624400864704512, Final Batch Loss: 5.198954386287369e-05\n",
      "Epoch 2246, Loss: 0.058427728712558746, Final Batch Loss: 0.0006385110318660736\n",
      "Epoch 2247, Loss: 0.0017791633727028966, Final Batch Loss: 0.0012107322691008449\n",
      "Epoch 2248, Loss: 0.000733151740860194, Final Batch Loss: 0.00044976381468586624\n",
      "Epoch 2249, Loss: 0.030644344151369296, Final Batch Loss: 0.030571090057492256\n",
      "Epoch 2250, Loss: 0.0021801545517519116, Final Batch Loss: 0.0019407657673582435\n",
      "Epoch 2251, Loss: 0.005361909905332141, Final Batch Loss: 0.00021915223624091595\n",
      "Epoch 2252, Loss: 0.02413500053808093, Final Batch Loss: 0.02103447914123535\n",
      "Epoch 2253, Loss: 0.005823589279316366, Final Batch Loss: 0.004016880877315998\n",
      "Epoch 2254, Loss: 0.0016184701671591029, Final Batch Loss: 0.00138843001332134\n",
      "Epoch 2255, Loss: 0.0021171376574784517, Final Batch Loss: 0.0014679348096251488\n",
      "Epoch 2256, Loss: 0.0035452561278361827, Final Batch Loss: 0.00023048001457937062\n",
      "Epoch 2257, Loss: 0.0008065023575909436, Final Batch Loss: 0.00041107763536274433\n",
      "Epoch 2258, Loss: 0.0019825098861474544, Final Batch Loss: 0.0002680792531464249\n",
      "Epoch 2259, Loss: 0.0023564164293929935, Final Batch Loss: 0.00031328981276601553\n",
      "Epoch 2260, Loss: 0.0008283176430268213, Final Batch Loss: 0.00022675828950013965\n",
      "Epoch 2261, Loss: 0.0012914942344650626, Final Batch Loss: 0.0009636113536544144\n",
      "Epoch 2262, Loss: 0.0018403162830509245, Final Batch Loss: 0.0010040736524388194\n",
      "Epoch 2263, Loss: 0.0013778361171716824, Final Batch Loss: 0.0012744937557727098\n",
      "Epoch 2264, Loss: 0.04856966168154031, Final Batch Loss: 0.0010434436844661832\n",
      "Epoch 2265, Loss: 0.004567104508168995, Final Batch Loss: 0.004104361869394779\n",
      "Epoch 2266, Loss: 0.014123245375230908, Final Batch Loss: 0.000996691407635808\n",
      "Epoch 2267, Loss: 0.0010090057039633393, Final Batch Loss: 0.00039492256473749876\n",
      "Epoch 2268, Loss: 0.0014404561516130343, Final Batch Loss: 0.0012104875640943646\n",
      "Epoch 2269, Loss: 0.002523853036109358, Final Batch Loss: 0.00048058718675747514\n",
      "Epoch 2270, Loss: 0.006324070040136576, Final Batch Loss: 0.00039600906893610954\n",
      "Epoch 2271, Loss: 0.005747024202719331, Final Batch Loss: 0.005231775809079409\n",
      "Epoch 2272, Loss: 0.0006686349079245701, Final Batch Loss: 0.00014239131996873766\n",
      "Epoch 2273, Loss: 0.0022744420857634395, Final Batch Loss: 0.0003384687879588455\n",
      "Epoch 2274, Loss: 0.005296803246892523, Final Batch Loss: 6.700323865516111e-05\n",
      "Epoch 2275, Loss: 0.004533620784059167, Final Batch Loss: 0.00046325079165399075\n",
      "Epoch 2276, Loss: 0.0003887507991748862, Final Batch Loss: 0.00011889286543009803\n",
      "Epoch 2277, Loss: 0.004132473957724869, Final Batch Loss: 0.0003728916635736823\n",
      "Epoch 2278, Loss: 0.0008924280118662864, Final Batch Loss: 0.00031168918940238655\n",
      "Epoch 2279, Loss: 0.0015463248419109732, Final Batch Loss: 0.0012520932359620929\n",
      "Epoch 2280, Loss: 0.0019563857349567115, Final Batch Loss: 0.0004521627561189234\n",
      "Epoch 2281, Loss: 0.0005195731937419623, Final Batch Loss: 0.00035175654920749366\n",
      "Epoch 2282, Loss: 0.0003331376356072724, Final Batch Loss: 0.0002048994938377291\n",
      "Epoch 2283, Loss: 0.002336008648853749, Final Batch Loss: 0.001671122619882226\n",
      "Epoch 2284, Loss: 0.006979040874284692, Final Batch Loss: 0.0002024840359808877\n",
      "Epoch 2285, Loss: 0.0009762199479155242, Final Batch Loss: 0.0002686177031137049\n",
      "Epoch 2286, Loss: 0.0008653074619360268, Final Batch Loss: 0.0002804399118758738\n",
      "Epoch 2287, Loss: 0.0004736256996693555, Final Batch Loss: 4.345976412878372e-05\n",
      "Epoch 2288, Loss: 0.0012276687484700233, Final Batch Loss: 0.00037092852289788425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2289, Loss: 0.00042964723252225667, Final Batch Loss: 0.00021941863815300167\n",
      "Epoch 2290, Loss: 0.007589442131575197, Final Batch Loss: 0.007350066211074591\n",
      "Epoch 2291, Loss: 0.0009632225264795125, Final Batch Loss: 0.0005065141594968736\n",
      "Epoch 2292, Loss: 0.00038716676499461755, Final Batch Loss: 6.14715027040802e-05\n",
      "Epoch 2293, Loss: 0.002280767075717449, Final Batch Loss: 0.0015693408204242587\n",
      "Epoch 2294, Loss: 0.00038548225711565465, Final Batch Loss: 0.0001571298489579931\n",
      "Epoch 2295, Loss: 0.01781753497198224, Final Batch Loss: 0.01511218398809433\n",
      "Epoch 2296, Loss: 0.0017552243662066758, Final Batch Loss: 0.0006319753010757267\n",
      "Epoch 2297, Loss: 0.0003329215687699616, Final Batch Loss: 0.00018038178677670658\n",
      "Epoch 2298, Loss: 0.0004062534717377275, Final Batch Loss: 0.00022447342053055763\n",
      "Epoch 2299, Loss: 0.0005143734597368166, Final Batch Loss: 4.740695294458419e-05\n",
      "Epoch 2300, Loss: 0.0010498088522581384, Final Batch Loss: 0.00018086079217027873\n",
      "Epoch 2301, Loss: 0.0005414892657427117, Final Batch Loss: 0.00033717945916578174\n",
      "Epoch 2302, Loss: 0.0011722224007826298, Final Batch Loss: 0.0001683733134996146\n",
      "Epoch 2303, Loss: 0.0007034729060251266, Final Batch Loss: 6.85454870108515e-05\n",
      "Epoch 2304, Loss: 0.001008981780614704, Final Batch Loss: 0.0005945037701167166\n",
      "Epoch 2305, Loss: 0.0010609683085931465, Final Batch Loss: 0.00020090553152840585\n",
      "Epoch 2306, Loss: 0.0008703393250470981, Final Batch Loss: 0.00018432793149258941\n",
      "Epoch 2307, Loss: 0.0018740228842943907, Final Batch Loss: 0.0007616864750161767\n",
      "Epoch 2308, Loss: 0.0014837186899967492, Final Batch Loss: 0.0007959696231409907\n",
      "Epoch 2309, Loss: 0.0010691310744732618, Final Batch Loss: 0.0006977063021622598\n",
      "Epoch 2310, Loss: 0.004548554454231635, Final Batch Loss: 0.0003141846100334078\n",
      "Epoch 2311, Loss: 0.0015909618232399225, Final Batch Loss: 0.0007781526655890048\n",
      "Epoch 2312, Loss: 0.0009966871584765613, Final Batch Loss: 0.0007185318390838802\n",
      "Epoch 2313, Loss: 0.002730845008045435, Final Batch Loss: 0.00011290912516415119\n",
      "Epoch 2314, Loss: 0.00042641235631890595, Final Batch Loss: 0.0001356895372737199\n",
      "Epoch 2315, Loss: 0.00040149560663849115, Final Batch Loss: 0.000140105199534446\n",
      "Epoch 2316, Loss: 0.000410081454901956, Final Batch Loss: 0.00025457434821873903\n",
      "Epoch 2317, Loss: 0.002947365544969216, Final Batch Loss: 0.002740010619163513\n",
      "Epoch 2318, Loss: 0.0013616661890409887, Final Batch Loss: 0.0005563038284890354\n",
      "Epoch 2319, Loss: 0.001158106024377048, Final Batch Loss: 0.000319536542519927\n",
      "Epoch 2320, Loss: 0.0009900110453600064, Final Batch Loss: 8.71073134476319e-05\n",
      "Epoch 2321, Loss: 0.001648707955610007, Final Batch Loss: 0.0014178226701915264\n",
      "Epoch 2322, Loss: 0.0004853228892898187, Final Batch Loss: 0.00020405287796165794\n",
      "Epoch 2323, Loss: 0.0011360038770362735, Final Batch Loss: 0.0004101883969269693\n",
      "Epoch 2324, Loss: 0.0044738478791259695, Final Batch Loss: 5.6034961744444445e-05\n",
      "Epoch 2325, Loss: 0.001423846755642444, Final Batch Loss: 0.0008780185016803443\n",
      "Epoch 2326, Loss: 0.0007381585164694116, Final Batch Loss: 8.177843119483441e-05\n",
      "Epoch 2327, Loss: 0.00394581351429224, Final Batch Loss: 0.0020184225868433714\n",
      "Epoch 2328, Loss: 0.0005317197792464867, Final Batch Loss: 3.278722579125315e-05\n",
      "Epoch 2329, Loss: 0.0005608725405181758, Final Batch Loss: 0.00011333356815157458\n",
      "Epoch 2330, Loss: 0.0005377365305321291, Final Batch Loss: 0.00029555463697761297\n",
      "Epoch 2331, Loss: 0.0026296633877791464, Final Batch Loss: 0.0020655589178204536\n",
      "Epoch 2332, Loss: 0.0004659993282984942, Final Batch Loss: 0.0003253117320127785\n",
      "Epoch 2333, Loss: 0.0029434105090331286, Final Batch Loss: 0.00031804104219190776\n",
      "Epoch 2334, Loss: 0.0011473559025034774, Final Batch Loss: 5.759300620411523e-05\n",
      "Epoch 2335, Loss: 0.001598481321707368, Final Batch Loss: 0.0009142774506472051\n",
      "Epoch 2336, Loss: 0.002398077253019437, Final Batch Loss: 0.000124933518236503\n",
      "Epoch 2337, Loss: 0.0015596855955664068, Final Batch Loss: 0.0013027854729443789\n",
      "Epoch 2338, Loss: 0.002004398440476507, Final Batch Loss: 0.0017601103754714131\n",
      "Epoch 2339, Loss: 0.0009216805920004845, Final Batch Loss: 0.000320891966111958\n",
      "Epoch 2340, Loss: 0.00012284438344067894, Final Batch Loss: 6.092498733778484e-05\n",
      "Epoch 2341, Loss: 0.0015837976825423539, Final Batch Loss: 0.0014199215220287442\n",
      "Epoch 2342, Loss: 0.0043713901250157505, Final Batch Loss: 0.0042378767393529415\n",
      "Epoch 2343, Loss: 0.0006444182436098345, Final Batch Loss: 0.0005794843309558928\n",
      "Epoch 2344, Loss: 0.0025768590858206153, Final Batch Loss: 0.0003366792807355523\n",
      "Epoch 2345, Loss: 0.000710184860508889, Final Batch Loss: 0.0002024460700340569\n",
      "Epoch 2346, Loss: 0.00043522690248209983, Final Batch Loss: 0.00011420522059779614\n",
      "Epoch 2347, Loss: 0.0016969304415397346, Final Batch Loss: 0.0013020371552556753\n",
      "Epoch 2348, Loss: 0.0015431413485202938, Final Batch Loss: 6.748261512257159e-05\n",
      "Epoch 2349, Loss: 0.0013355305854929611, Final Batch Loss: 0.00014742631174158305\n",
      "Epoch 2350, Loss: 0.001206363260280341, Final Batch Loss: 0.0007108093705028296\n",
      "Epoch 2351, Loss: 0.00032448492129333317, Final Batch Loss: 0.00014581947471015155\n",
      "Epoch 2352, Loss: 0.0006399361154763028, Final Batch Loss: 0.0004547184507828206\n",
      "Epoch 2353, Loss: 0.0015864327433519065, Final Batch Loss: 0.00046253594337031245\n",
      "Epoch 2354, Loss: 0.0015229231357807294, Final Batch Loss: 0.0002115522656822577\n",
      "Epoch 2355, Loss: 0.0008457883086521178, Final Batch Loss: 0.0003675303014460951\n",
      "Epoch 2356, Loss: 0.001009208062896505, Final Batch Loss: 0.0007247235043905675\n",
      "Epoch 2357, Loss: 0.0006248248682823032, Final Batch Loss: 0.00018131372053176165\n",
      "Epoch 2358, Loss: 0.0002638310397742316, Final Batch Loss: 8.148803317453712e-05\n",
      "Epoch 2359, Loss: 0.0007676814857404679, Final Batch Loss: 0.0004249408666510135\n",
      "Epoch 2360, Loss: 0.001429080220987089, Final Batch Loss: 0.00017824508540797979\n",
      "Epoch 2361, Loss: 0.0002431053144391626, Final Batch Loss: 0.00015742778487037867\n",
      "Epoch 2362, Loss: 0.0009311807953054085, Final Batch Loss: 4.964940308127552e-05\n",
      "Epoch 2363, Loss: 0.0004356428107712418, Final Batch Loss: 0.00021465880854520947\n",
      "Epoch 2364, Loss: 0.00023597684048581868, Final Batch Loss: 9.411090286448598e-05\n",
      "Epoch 2365, Loss: 0.0002561477667768486, Final Batch Loss: 0.0001704043970676139\n",
      "Epoch 2366, Loss: 0.0011388312268536538, Final Batch Loss: 0.0007960829534567893\n",
      "Epoch 2367, Loss: 0.00021520437439903617, Final Batch Loss: 7.967992860358208e-05\n",
      "Epoch 2368, Loss: 0.0009337934679933824, Final Batch Loss: 9.545367356622592e-05\n",
      "Epoch 2369, Loss: 0.0019019030878553167, Final Batch Loss: 8.032041660044342e-05\n",
      "Epoch 2370, Loss: 0.0006857832049718127, Final Batch Loss: 0.00017309175746049732\n",
      "Epoch 2371, Loss: 0.0005053799104643986, Final Batch Loss: 0.00018900736176874489\n",
      "Epoch 2372, Loss: 0.00023633884848095477, Final Batch Loss: 0.00014010962331667542\n",
      "Epoch 2373, Loss: 0.0016715155070414767, Final Batch Loss: 0.00011723370698746294\n",
      "Epoch 2374, Loss: 0.0012006006436422467, Final Batch Loss: 7.362384349107742e-05\n",
      "Epoch 2375, Loss: 0.00036731993895955384, Final Batch Loss: 0.0001204974832944572\n",
      "Epoch 2376, Loss: 0.000880496299942024, Final Batch Loss: 0.0007180327665992081\n",
      "Epoch 2377, Loss: 0.011665141209959984, Final Batch Loss: 0.0015215445309877396\n",
      "Epoch 2378, Loss: 0.002561145869549364, Final Batch Loss: 0.00171721912920475\n",
      "Epoch 2379, Loss: 0.001710151380393654, Final Batch Loss: 0.00035300181480124593\n",
      "Epoch 2380, Loss: 0.0007203740242403001, Final Batch Loss: 0.000157582777319476\n",
      "Epoch 2381, Loss: 0.001784692023647949, Final Batch Loss: 0.0003641391813289374\n",
      "Epoch 2382, Loss: 0.0028722111819661222, Final Batch Loss: 0.00010461688361829147\n",
      "Epoch 2383, Loss: 0.0004396581425680779, Final Batch Loss: 0.0003718753869179636\n",
      "Epoch 2384, Loss: 0.001642091607209295, Final Batch Loss: 0.00030617014272138476\n",
      "Epoch 2385, Loss: 0.003765297238714993, Final Batch Loss: 0.0008936250815168023\n",
      "Epoch 2386, Loss: 0.0002112982219841797, Final Batch Loss: 4.2356146877864376e-05\n",
      "Epoch 2387, Loss: 0.0003991178164142184, Final Batch Loss: 8.726389933144674e-05\n",
      "Epoch 2388, Loss: 0.0017815747414715588, Final Batch Loss: 0.0009096688590943813\n",
      "Epoch 2389, Loss: 0.0010678360995370895, Final Batch Loss: 0.0002079318801406771\n",
      "Epoch 2390, Loss: 0.0004571216704789549, Final Batch Loss: 5.730570410378277e-05\n",
      "Epoch 2391, Loss: 0.0003935075510526076, Final Batch Loss: 0.0002337286132387817\n",
      "Epoch 2392, Loss: 0.07771433305606479, Final Batch Loss: 0.07764046639204025\n",
      "Epoch 2393, Loss: 0.0012698447389993817, Final Batch Loss: 0.0010113110765814781\n",
      "Epoch 2394, Loss: 0.006011057063005865, Final Batch Loss: 0.0008440547389909625\n",
      "Epoch 2395, Loss: 0.0005874226553714834, Final Batch Loss: 7.507573900511488e-05\n",
      "Epoch 2396, Loss: 0.0005465813737828285, Final Batch Loss: 8.4287254139781e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2397, Loss: 0.0006192790751811117, Final Batch Loss: 0.0003426186158321798\n",
      "Epoch 2398, Loss: 0.0010723678024078254, Final Batch Loss: 0.0010146533604711294\n",
      "Epoch 2399, Loss: 0.0010322049638489261, Final Batch Loss: 0.000890208117198199\n",
      "Epoch 2400, Loss: 0.0013618243829114363, Final Batch Loss: 0.0012685881229117513\n",
      "Epoch 2401, Loss: 0.003283105092123151, Final Batch Loss: 0.0009955442510545254\n",
      "Epoch 2402, Loss: 0.00044597344822250307, Final Batch Loss: 0.00021415657829493284\n",
      "Epoch 2403, Loss: 0.0017299202154390514, Final Batch Loss: 0.001220407080836594\n",
      "Epoch 2404, Loss: 0.009115684675634839, Final Batch Loss: 0.008971585892140865\n",
      "Epoch 2405, Loss: 0.002348929614527151, Final Batch Loss: 0.0019665835425257683\n",
      "Epoch 2406, Loss: 0.0006511005631182343, Final Batch Loss: 0.0003721585962921381\n",
      "Epoch 2407, Loss: 0.0016721459396649152, Final Batch Loss: 0.0014003366231918335\n",
      "Epoch 2408, Loss: 0.00022477757738670334, Final Batch Loss: 0.00010967634443659335\n",
      "Epoch 2409, Loss: 0.0070258814812405035, Final Batch Loss: 0.006934426259249449\n",
      "Epoch 2410, Loss: 0.0006051475356798619, Final Batch Loss: 0.0003643780364654958\n",
      "Epoch 2411, Loss: 0.0007023935177130625, Final Batch Loss: 0.00022997539781499654\n",
      "Epoch 2412, Loss: 0.0006713402108289301, Final Batch Loss: 0.00026823158259503543\n",
      "Epoch 2413, Loss: 0.001045169890858233, Final Batch Loss: 0.0008265146752819419\n",
      "Epoch 2414, Loss: 0.0006292029866017401, Final Batch Loss: 0.0005533279036171734\n",
      "Epoch 2415, Loss: 0.057370179623831064, Final Batch Loss: 0.0566190741956234\n",
      "Epoch 2416, Loss: 0.011773323858506046, Final Batch Loss: 0.01157323271036148\n",
      "Epoch 2417, Loss: 0.0014912211918272078, Final Batch Loss: 0.0007994314655661583\n",
      "Epoch 2418, Loss: 0.0020019052317366004, Final Batch Loss: 0.0013260162668302655\n",
      "Epoch 2419, Loss: 0.012562063056975603, Final Batch Loss: 0.004067510832101107\n",
      "Epoch 2420, Loss: 0.011976380163105205, Final Batch Loss: 0.01180307101458311\n",
      "Epoch 2421, Loss: 0.017683090060018003, Final Batch Loss: 0.016180144622921944\n",
      "Epoch 2422, Loss: 0.003977020343882032, Final Batch Loss: 8.773997251410037e-05\n",
      "Epoch 2423, Loss: 0.005971445003524423, Final Batch Loss: 0.004468592815101147\n",
      "Epoch 2424, Loss: 0.002172768348827958, Final Batch Loss: 0.0018005910096690059\n",
      "Epoch 2425, Loss: 0.0005118191329529509, Final Batch Loss: 0.0002106817701132968\n",
      "Epoch 2426, Loss: 0.003219980630092323, Final Batch Loss: 0.0025886965449899435\n",
      "Epoch 2427, Loss: 0.0007132469690986909, Final Batch Loss: 8.369665738428012e-05\n",
      "Epoch 2428, Loss: 0.0009548861999064684, Final Batch Loss: 0.000523881521075964\n",
      "Epoch 2429, Loss: 0.0004480225979932584, Final Batch Loss: 0.00033074553357437253\n",
      "Epoch 2430, Loss: 0.002121161625836976, Final Batch Loss: 0.00014626416668761522\n",
      "Epoch 2431, Loss: 0.00052470518858172, Final Batch Loss: 0.00038680131547152996\n",
      "Epoch 2432, Loss: 0.00915643951157108, Final Batch Loss: 0.00865991972386837\n",
      "Epoch 2433, Loss: 0.002043482061708346, Final Batch Loss: 0.00045223350753076375\n",
      "Epoch 2434, Loss: 0.0008580363646615297, Final Batch Loss: 0.0005034482455812395\n",
      "Epoch 2435, Loss: 0.002282841451233253, Final Batch Loss: 0.0003542186168488115\n",
      "Epoch 2436, Loss: 0.0003593529327190481, Final Batch Loss: 0.0002567296614870429\n",
      "Epoch 2437, Loss: 0.0009040224831551313, Final Batch Loss: 0.0008283165516331792\n",
      "Epoch 2438, Loss: 0.0013045265222899616, Final Batch Loss: 0.0009593616705387831\n",
      "Epoch 2439, Loss: 0.0001646653763600625, Final Batch Loss: 7.840709440642968e-05\n",
      "Epoch 2440, Loss: 0.000661510945064947, Final Batch Loss: 0.0002883130218833685\n",
      "Epoch 2441, Loss: 0.00342942654970102, Final Batch Loss: 0.002957760589197278\n",
      "Epoch 2442, Loss: 0.002996488066855818, Final Batch Loss: 0.002735871821641922\n",
      "Epoch 2443, Loss: 0.0013128536520525813, Final Batch Loss: 0.00030898384284228086\n",
      "Epoch 2444, Loss: 0.0006369683032971807, Final Batch Loss: 0.000535478291567415\n",
      "Epoch 2445, Loss: 0.0003019206633325666, Final Batch Loss: 0.0001676233805483207\n",
      "Epoch 2446, Loss: 0.00020602895529009402, Final Batch Loss: 0.00012971917749382555\n",
      "Epoch 2447, Loss: 0.0026846769615076482, Final Batch Loss: 0.0019617711659520864\n",
      "Epoch 2448, Loss: 0.0015638633049093187, Final Batch Loss: 0.0006984305800870061\n",
      "Epoch 2449, Loss: 0.00016681001216056757, Final Batch Loss: 0.00011234983685426414\n",
      "Epoch 2450, Loss: 0.0005748827097704634, Final Batch Loss: 0.0001775578857632354\n",
      "Epoch 2451, Loss: 0.0007324273028643802, Final Batch Loss: 0.0004909326671622694\n",
      "Epoch 2452, Loss: 0.0052587027894333005, Final Batch Loss: 0.0012349189491942525\n",
      "Epoch 2453, Loss: 0.0010794257104862481, Final Batch Loss: 0.0005936446832492948\n",
      "Epoch 2454, Loss: 0.0003028132559848018, Final Batch Loss: 8.280856854980811e-05\n",
      "Epoch 2455, Loss: 0.0004856024024775252, Final Batch Loss: 4.945367982145399e-05\n",
      "Epoch 2456, Loss: 0.0003783388456213288, Final Batch Loss: 6.21475264779292e-05\n",
      "Epoch 2457, Loss: 0.00034520144981797785, Final Batch Loss: 0.00013215196668170393\n",
      "Epoch 2458, Loss: 0.00014661438763141632, Final Batch Loss: 8.132246148306876e-05\n",
      "Epoch 2459, Loss: 0.004110425943508744, Final Batch Loss: 0.0032522929832339287\n",
      "Epoch 2460, Loss: 0.0003327220620121807, Final Batch Loss: 0.00018411803466733545\n",
      "Epoch 2461, Loss: 0.00018904893659055233, Final Batch Loss: 0.00010788220242829993\n",
      "Epoch 2462, Loss: 0.022512891562655568, Final Batch Loss: 0.00013066758401691914\n",
      "Epoch 2463, Loss: 0.0014130631752777845, Final Batch Loss: 0.00101306545548141\n",
      "Epoch 2464, Loss: 0.0006802768766647205, Final Batch Loss: 0.00015364015416707844\n",
      "Epoch 2465, Loss: 0.0039442318375222385, Final Batch Loss: 0.0004685317981056869\n",
      "Epoch 2466, Loss: 0.030347312451340258, Final Batch Loss: 0.029336770996451378\n",
      "Epoch 2467, Loss: 0.002015486068557948, Final Batch Loss: 0.000389024440664798\n",
      "Epoch 2468, Loss: 0.0010106211993843317, Final Batch Loss: 0.00030990963568910956\n",
      "Epoch 2469, Loss: 0.011201908229850233, Final Batch Loss: 0.0009464513277634978\n",
      "Epoch 2470, Loss: 0.0008432407630607486, Final Batch Loss: 0.0004219294642098248\n",
      "Epoch 2471, Loss: 0.0014382106310222298, Final Batch Loss: 0.00012604825315065682\n",
      "Epoch 2472, Loss: 0.05307130119763315, Final Batch Loss: 0.05109908804297447\n",
      "Epoch 2473, Loss: 0.0014940793043933809, Final Batch Loss: 0.001252533751539886\n",
      "Epoch 2474, Loss: 0.00317031895974651, Final Batch Loss: 0.0025548338890075684\n",
      "Epoch 2475, Loss: 0.0006876533443573862, Final Batch Loss: 0.00042970204958692193\n",
      "Epoch 2476, Loss: 0.0030823540728306398, Final Batch Loss: 5.874921043869108e-05\n",
      "Epoch 2477, Loss: 0.0008767145045567304, Final Batch Loss: 0.0004030013515148312\n",
      "Epoch 2478, Loss: 0.017160772884381004, Final Batch Loss: 0.01696445606648922\n",
      "Epoch 2479, Loss: 0.0005613517496385612, Final Batch Loss: 0.0004879342741332948\n",
      "Epoch 2480, Loss: 0.0008317735591845121, Final Batch Loss: 0.0007736939005553722\n",
      "Epoch 2481, Loss: 0.009672635998867918, Final Batch Loss: 0.009558278135955334\n",
      "Epoch 2482, Loss: 0.00027954179677180946, Final Batch Loss: 0.0001416574086761102\n",
      "Epoch 2483, Loss: 0.0007259444682858884, Final Batch Loss: 0.0006846132455393672\n",
      "Epoch 2484, Loss: 0.008715179043065291, Final Batch Loss: 0.00010465946252224967\n",
      "Epoch 2485, Loss: 0.0015685748803662136, Final Batch Loss: 0.00017512690101284534\n",
      "Epoch 2486, Loss: 0.0017418852221453562, Final Batch Loss: 0.0015930638182908297\n",
      "Epoch 2487, Loss: 0.0009446422336623073, Final Batch Loss: 0.000689936859998852\n",
      "Epoch 2488, Loss: 0.0005807235720567405, Final Batch Loss: 0.00017759326146915555\n",
      "Epoch 2489, Loss: 0.009475630475208163, Final Batch Loss: 0.006901951041072607\n",
      "Epoch 2490, Loss: 0.004654498363379389, Final Batch Loss: 0.0037104920484125614\n",
      "Epoch 2491, Loss: 0.00122718203056138, Final Batch Loss: 0.0002329148555872962\n",
      "Epoch 2492, Loss: 0.000860203115735203, Final Batch Loss: 0.0005512047791853547\n",
      "Epoch 2493, Loss: 0.0008098341058939695, Final Batch Loss: 0.000274496094789356\n",
      "Epoch 2494, Loss: 0.0018301006930414587, Final Batch Loss: 0.0001885969249997288\n",
      "Epoch 2495, Loss: 0.0004396152216941118, Final Batch Loss: 0.0002640074526425451\n",
      "Epoch 2496, Loss: 0.0003283436963101849, Final Batch Loss: 0.00015002081636339426\n",
      "Epoch 2497, Loss: 0.002477878297213465, Final Batch Loss: 0.0023346806410700083\n",
      "Epoch 2498, Loss: 0.026006308566138614, Final Batch Loss: 9.568146924721077e-05\n",
      "Epoch 2499, Loss: 0.0017362965154461563, Final Batch Loss: 0.0011320816120132804\n",
      "Epoch 2500, Loss: 0.0007304885366465896, Final Batch Loss: 0.000574980047531426\n",
      "Epoch 2501, Loss: 0.001636492961551994, Final Batch Loss: 0.0014698791783303022\n",
      "Epoch 2502, Loss: 0.0004877380997641012, Final Batch Loss: 0.0003586867533158511\n",
      "Epoch 2503, Loss: 0.001047448196914047, Final Batch Loss: 0.0006990384426899254\n",
      "Epoch 2504, Loss: 0.0013171239697840065, Final Batch Loss: 0.0001537209318485111\n",
      "Epoch 2505, Loss: 0.0003522889492160175, Final Batch Loss: 5.665870048687793e-05\n",
      "Epoch 2506, Loss: 0.0003028886712854728, Final Batch Loss: 0.00018721137894317508\n",
      "Epoch 2507, Loss: 0.0007298508571693674, Final Batch Loss: 0.000486543431179598\n",
      "Epoch 2508, Loss: 0.0011954579094890505, Final Batch Loss: 0.00034261654946021736\n",
      "Epoch 2509, Loss: 0.0012458418495953083, Final Batch Loss: 0.00105835881549865\n",
      "Epoch 2510, Loss: 0.0022151922166813165, Final Batch Loss: 0.0019883897621184587\n",
      "Epoch 2511, Loss: 0.0023227234196383506, Final Batch Loss: 0.0019951965659856796\n",
      "Epoch 2512, Loss: 0.0022439304157160223, Final Batch Loss: 0.0015917266719043255\n",
      "Epoch 2513, Loss: 0.0028369836509227753, Final Batch Loss: 0.001781046623364091\n",
      "Epoch 2514, Loss: 0.0020846266706939787, Final Batch Loss: 0.0004370030655991286\n",
      "Epoch 2515, Loss: 0.029608975601149723, Final Batch Loss: 5.338850314728916e-05\n",
      "Epoch 2516, Loss: 0.0011008808724000119, Final Batch Loss: 0.000984244397841394\n",
      "Epoch 2517, Loss: 0.000599234423134476, Final Batch Loss: 0.0003842729202006012\n",
      "Epoch 2518, Loss: 0.0011752165737561882, Final Batch Loss: 0.0007165931165218353\n",
      "Epoch 2519, Loss: 0.0007705559255555272, Final Batch Loss: 0.0004531870363280177\n",
      "Epoch 2520, Loss: 0.0003231700320611708, Final Batch Loss: 0.0002580569125711918\n",
      "Epoch 2521, Loss: 0.0009399432092322968, Final Batch Loss: 8.305763913085684e-05\n",
      "Epoch 2522, Loss: 0.0006924259141669609, Final Batch Loss: 5.258367309579626e-05\n",
      "Epoch 2523, Loss: 0.0005280316254356876, Final Batch Loss: 0.00023450453591067344\n",
      "Epoch 2524, Loss: 0.001656804495723918, Final Batch Loss: 0.0013828377705067396\n",
      "Epoch 2525, Loss: 0.0008155324248946272, Final Batch Loss: 7.961599476402625e-05\n",
      "Epoch 2526, Loss: 0.002480445138644427, Final Batch Loss: 0.0018075488042086363\n",
      "Epoch 2527, Loss: 0.0009543724299874157, Final Batch Loss: 0.0007002194179221988\n",
      "Epoch 2528, Loss: 0.0005955754168098792, Final Batch Loss: 0.0004278013948351145\n",
      "Epoch 2529, Loss: 0.0012775593713740818, Final Batch Loss: 5.141837027622387e-05\n",
      "Epoch 2530, Loss: 0.0006468173378380015, Final Batch Loss: 0.00013437385496217757\n",
      "Epoch 2531, Loss: 0.005485320929437876, Final Batch Loss: 0.0032679664436727762\n",
      "Epoch 2532, Loss: 0.00022471983538707718, Final Batch Loss: 6.768918683519587e-05\n",
      "Epoch 2533, Loss: 0.001369691628497094, Final Batch Loss: 0.0013025541556999087\n",
      "Epoch 2534, Loss: 0.0008814370521577075, Final Batch Loss: 0.0006580083281733096\n",
      "Epoch 2535, Loss: 0.00015117307339096442, Final Batch Loss: 5.712213896913454e-05\n",
      "Epoch 2536, Loss: 0.0022370803053490818, Final Batch Loss: 0.0017709723906591535\n",
      "Epoch 2537, Loss: 0.0025962408835766837, Final Batch Loss: 0.0024517709389328957\n",
      "Epoch 2538, Loss: 0.0014159300189930946, Final Batch Loss: 0.00022117714979685843\n",
      "Epoch 2539, Loss: 0.003123759350273758, Final Batch Loss: 0.00228366837836802\n",
      "Epoch 2540, Loss: 0.0005215110468270723, Final Batch Loss: 3.446438131504692e-05\n",
      "Epoch 2541, Loss: 0.0007741269073449075, Final Batch Loss: 0.000301087973639369\n",
      "Epoch 2542, Loss: 0.0013679496623808518, Final Batch Loss: 0.00013350510562304407\n",
      "Epoch 2543, Loss: 0.001951202102645766, Final Batch Loss: 0.0018973962869495153\n",
      "Epoch 2544, Loss: 0.0018904315074905753, Final Batch Loss: 0.0008607222698628902\n",
      "Epoch 2545, Loss: 0.0003546472580637783, Final Batch Loss: 0.00021248198754619807\n",
      "Epoch 2546, Loss: 0.00843541273206938, Final Batch Loss: 0.00010901638597715646\n",
      "Epoch 2547, Loss: 0.0002766435245575849, Final Batch Loss: 0.00022380519658327103\n",
      "Epoch 2548, Loss: 0.00043478964653331786, Final Batch Loss: 0.0002268920943606645\n",
      "Epoch 2549, Loss: 0.0018413481302559376, Final Batch Loss: 0.0009558855672366917\n",
      "Epoch 2550, Loss: 0.0005527904286282137, Final Batch Loss: 0.0003948799567297101\n",
      "Epoch 2551, Loss: 0.0056938547641038895, Final Batch Loss: 0.0018310092855244875\n",
      "Epoch 2552, Loss: 0.0007697103501413949, Final Batch Loss: 9.849144407780841e-05\n",
      "Epoch 2553, Loss: 0.0021419073455035686, Final Batch Loss: 0.0013771799858659506\n",
      "Epoch 2554, Loss: 0.000427381120971404, Final Batch Loss: 0.00020596449030563235\n",
      "Epoch 2555, Loss: 0.0004458913754206151, Final Batch Loss: 0.00031366405892185867\n",
      "Epoch 2556, Loss: 0.00036258433829061687, Final Batch Loss: 0.00010230441694147885\n",
      "Epoch 2557, Loss: 0.006915732461493462, Final Batch Loss: 0.006737357936799526\n",
      "Epoch 2558, Loss: 0.0037949806719552726, Final Batch Loss: 0.003365228185430169\n",
      "Epoch 2559, Loss: 0.0010371401731390506, Final Batch Loss: 0.0009105995413847268\n",
      "Epoch 2560, Loss: 0.0015031685470603406, Final Batch Loss: 0.0012747164582833648\n",
      "Epoch 2561, Loss: 0.00034779457200784236, Final Batch Loss: 0.00012102241453249007\n",
      "Epoch 2562, Loss: 0.0010197898554906715, Final Batch Loss: 0.0009821075946092606\n",
      "Epoch 2563, Loss: 0.0006018964340910316, Final Batch Loss: 0.00014906332944519818\n",
      "Epoch 2564, Loss: 0.000268259162112372, Final Batch Loss: 4.2537478293525055e-05\n",
      "Epoch 2565, Loss: 0.0014284413191489875, Final Batch Loss: 0.0005345370154827833\n",
      "Epoch 2566, Loss: 0.00037030796374892816, Final Batch Loss: 0.00011859478399856016\n",
      "Epoch 2567, Loss: 0.0015678689087508246, Final Batch Loss: 0.0014878660440444946\n",
      "Epoch 2568, Loss: 0.003644306052592583, Final Batch Loss: 0.003449667477980256\n",
      "Epoch 2569, Loss: 0.001528369313746225, Final Batch Loss: 0.0001015558882500045\n",
      "Epoch 2570, Loss: 0.0007117232598830014, Final Batch Loss: 0.00022556708427146077\n",
      "Epoch 2571, Loss: 0.0051739725458901376, Final Batch Loss: 0.00488513708114624\n",
      "Epoch 2572, Loss: 0.0009440931316930801, Final Batch Loss: 0.0008330896380357444\n",
      "Epoch 2573, Loss: 0.0005922919954173267, Final Batch Loss: 0.00028734063380397856\n",
      "Epoch 2574, Loss: 0.00021372720948420465, Final Batch Loss: 0.00010179402306675911\n",
      "Epoch 2575, Loss: 0.0002226269425591454, Final Batch Loss: 0.00013722591393161565\n",
      "Epoch 2576, Loss: 0.00046074653073446825, Final Batch Loss: 0.0003717935469467193\n",
      "Epoch 2577, Loss: 0.006508083548396826, Final Batch Loss: 0.0054664164781570435\n",
      "Epoch 2578, Loss: 0.001451694726711139, Final Batch Loss: 0.0012202843790873885\n",
      "Epoch 2579, Loss: 0.0009808877221075818, Final Batch Loss: 9.548517118673772e-05\n",
      "Epoch 2580, Loss: 0.002039118349784985, Final Batch Loss: 0.00047599515528418124\n",
      "Epoch 2581, Loss: 0.0024954822765721474, Final Batch Loss: 5.3381725592771545e-05\n",
      "Epoch 2582, Loss: 0.0010079641069751233, Final Batch Loss: 0.0004399260797072202\n",
      "Epoch 2583, Loss: 0.0008735633673495613, Final Batch Loss: 0.0007564277038909495\n",
      "Epoch 2584, Loss: 0.00137272325810045, Final Batch Loss: 0.00011503638233989477\n",
      "Epoch 2585, Loss: 0.0007522848609369248, Final Batch Loss: 0.0003015063120983541\n",
      "Epoch 2586, Loss: 0.0035851824650308117, Final Batch Loss: 0.00014433181786444038\n",
      "Epoch 2587, Loss: 0.0005644479024340399, Final Batch Loss: 0.00010338542779209092\n",
      "Epoch 2588, Loss: 0.0010719941928982735, Final Batch Loss: 0.0006247152923606336\n",
      "Epoch 2589, Loss: 0.0006693592586088926, Final Batch Loss: 0.00012541361502371728\n",
      "Epoch 2590, Loss: 0.001060517126461491, Final Batch Loss: 0.0006881912122480571\n",
      "Epoch 2591, Loss: 0.0022362883610185236, Final Batch Loss: 0.00033634676947258413\n",
      "Epoch 2592, Loss: 0.002073451782052871, Final Batch Loss: 3.482205647742376e-05\n",
      "Epoch 2593, Loss: 0.0011736395244952291, Final Batch Loss: 0.0009654827299527824\n",
      "Epoch 2594, Loss: 0.0002181441268476192, Final Batch Loss: 4.270216231816448e-05\n",
      "Epoch 2595, Loss: 0.015688328276155517, Final Batch Loss: 0.015547680668532848\n",
      "Epoch 2596, Loss: 0.00034278424573130906, Final Batch Loss: 0.0002407889551250264\n",
      "Epoch 2597, Loss: 0.00037781397986691445, Final Batch Loss: 0.00016562908422201872\n",
      "Epoch 2598, Loss: 0.0033710293064359576, Final Batch Loss: 0.003026655176654458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2599, Loss: 0.0009244603279512376, Final Batch Loss: 0.0004860058834310621\n",
      "Epoch 2600, Loss: 0.0002907455200329423, Final Batch Loss: 0.00021181412739679217\n",
      "Epoch 2601, Loss: 0.0015738623042125255, Final Batch Loss: 0.001260249176993966\n",
      "Epoch 2602, Loss: 0.025286982534453273, Final Batch Loss: 0.0035140502732247114\n",
      "Epoch 2603, Loss: 0.0007866622327128425, Final Batch Loss: 0.0006102594779804349\n",
      "Epoch 2604, Loss: 0.0009183365327771753, Final Batch Loss: 0.0006905375048518181\n",
      "Epoch 2605, Loss: 0.0007731241057626903, Final Batch Loss: 0.00018324702978134155\n",
      "Epoch 2606, Loss: 0.0009426924079889432, Final Batch Loss: 0.00019183453696314245\n",
      "Epoch 2607, Loss: 0.0005272161943139508, Final Batch Loss: 0.00034310962655581534\n",
      "Epoch 2608, Loss: 0.0014768997207283974, Final Batch Loss: 0.0011471461039036512\n",
      "Epoch 2609, Loss: 0.016683612717315555, Final Batch Loss: 0.015081580728292465\n",
      "Epoch 2610, Loss: 0.007458907086402178, Final Batch Loss: 0.0008910410106182098\n",
      "Epoch 2611, Loss: 0.013413425593171269, Final Batch Loss: 0.0004765717894770205\n",
      "Epoch 2612, Loss: 0.00035826305611408316, Final Batch Loss: 4.548005745164119e-05\n",
      "Epoch 2613, Loss: 0.016677007675752975, Final Batch Loss: 0.0002262132620671764\n",
      "Epoch 2614, Loss: 0.0007719717250438407, Final Batch Loss: 0.00011924428690690547\n",
      "Epoch 2615, Loss: 0.018223413062514737, Final Batch Loss: 0.01778663881123066\n",
      "Epoch 2616, Loss: 0.009445503121241927, Final Batch Loss: 0.0035438050981611013\n",
      "Epoch 2617, Loss: 0.010038082516985014, Final Batch Loss: 0.0004875501908827573\n",
      "Epoch 2618, Loss: 0.0032944558188319206, Final Batch Loss: 0.002702753758057952\n",
      "Epoch 2619, Loss: 0.0010249625192955136, Final Batch Loss: 0.0008182178135029972\n",
      "Epoch 2620, Loss: 0.015545958100119606, Final Batch Loss: 0.00037562978104688227\n",
      "Epoch 2621, Loss: 0.01541938295122236, Final Batch Loss: 0.00035010126885026693\n",
      "Epoch 2622, Loss: 0.0004805453463632148, Final Batch Loss: 3.8119771488709375e-05\n",
      "Epoch 2623, Loss: 0.003243977320380509, Final Batch Loss: 0.0022449791431427\n",
      "Epoch 2624, Loss: 0.0015371022163890302, Final Batch Loss: 0.0011103411670774221\n",
      "Epoch 2625, Loss: 0.0018505798070691526, Final Batch Loss: 0.0013332875678315759\n",
      "Epoch 2626, Loss: 0.006372954812832177, Final Batch Loss: 0.0047566709108650684\n",
      "Epoch 2627, Loss: 0.011881841521244496, Final Batch Loss: 0.011406485922634602\n",
      "Epoch 2628, Loss: 0.00021026243848609738, Final Batch Loss: 0.000156404435983859\n",
      "Epoch 2629, Loss: 0.00046289755846373737, Final Batch Loss: 0.0001846335071604699\n",
      "Epoch 2630, Loss: 0.0053879000479355454, Final Batch Loss: 0.004163981880992651\n",
      "Epoch 2631, Loss: 0.0008517875103279948, Final Batch Loss: 0.0001705704489722848\n",
      "Epoch 2632, Loss: 0.001808680382964667, Final Batch Loss: 0.0017117250245064497\n",
      "Epoch 2633, Loss: 0.0008545246964786202, Final Batch Loss: 0.0003925792407244444\n",
      "Epoch 2634, Loss: 0.0005752521537942812, Final Batch Loss: 7.531866140197963e-05\n",
      "Epoch 2635, Loss: 0.0017462000832892954, Final Batch Loss: 0.00113037065602839\n",
      "Epoch 2636, Loss: 0.0008671283430885524, Final Batch Loss: 0.0005223557818681002\n",
      "Epoch 2637, Loss: 0.0010130505543202162, Final Batch Loss: 0.00013310957001522183\n",
      "Epoch 2638, Loss: 0.0004756944254040718, Final Batch Loss: 0.00011597975390031934\n",
      "Epoch 2639, Loss: 0.0009816708479775116, Final Batch Loss: 0.00024012172070797533\n",
      "Epoch 2640, Loss: 0.002980219040182419, Final Batch Loss: 0.0002371797600062564\n",
      "Epoch 2641, Loss: 0.002265132963657379, Final Batch Loss: 0.0010543153621256351\n",
      "Epoch 2642, Loss: 0.0007461395871359855, Final Batch Loss: 0.0005096601089462638\n",
      "Epoch 2643, Loss: 0.00032430911960545927, Final Batch Loss: 8.781402721069753e-05\n",
      "Epoch 2644, Loss: 0.0008740269913687371, Final Batch Loss: 0.0007934164023026824\n",
      "Epoch 2645, Loss: 0.016589830454904586, Final Batch Loss: 0.01626456156373024\n",
      "Epoch 2646, Loss: 0.0004952728049829602, Final Batch Loss: 0.00027865832089446485\n",
      "Epoch 2647, Loss: 0.0003520749378367327, Final Batch Loss: 0.00023439936921931803\n",
      "Epoch 2648, Loss: 0.00014975563681218773, Final Batch Loss: 4.0283943235408515e-05\n",
      "Epoch 2649, Loss: 0.0010623022681102157, Final Batch Loss: 0.0006557097076438367\n",
      "Epoch 2650, Loss: 0.0005012072724639438, Final Batch Loss: 8.570646605221555e-05\n",
      "Epoch 2651, Loss: 0.00025699628895381466, Final Batch Loss: 3.08608214254491e-05\n",
      "Epoch 2652, Loss: 0.00028360596479615197, Final Batch Loss: 0.00022189260926097631\n",
      "Epoch 2653, Loss: 0.0007394678614218719, Final Batch Loss: 0.0006316353101283312\n",
      "Epoch 2654, Loss: 0.003078702102357056, Final Batch Loss: 4.452300345292315e-05\n",
      "Epoch 2655, Loss: 0.0006704138359054923, Final Batch Loss: 0.0004125226987525821\n",
      "Epoch 2656, Loss: 0.0006042357708793133, Final Batch Loss: 0.0002841995155904442\n",
      "Epoch 2657, Loss: 0.07000164868441061, Final Batch Loss: 0.06996127218008041\n",
      "Epoch 2658, Loss: 0.0007841390179237351, Final Batch Loss: 0.0006848720367997885\n",
      "Epoch 2659, Loss: 0.002309290721314028, Final Batch Loss: 0.0001282939047086984\n",
      "Epoch 2660, Loss: 0.0005473683195305057, Final Batch Loss: 6.354478682624176e-05\n",
      "Epoch 2661, Loss: 0.0005042965349275619, Final Batch Loss: 0.00011274748248979449\n",
      "Epoch 2662, Loss: 0.05446434374607634, Final Batch Loss: 0.054223328828811646\n",
      "Epoch 2663, Loss: 0.0014951921621104702, Final Batch Loss: 0.00015344841813202947\n",
      "Epoch 2664, Loss: 0.0010161210229853168, Final Batch Loss: 0.00018928719509858638\n",
      "Epoch 2665, Loss: 0.0019045449153054506, Final Batch Loss: 0.0016105440445244312\n",
      "Epoch 2666, Loss: 0.00027184923965251073, Final Batch Loss: 0.00018814820214174688\n",
      "Epoch 2667, Loss: 0.00035437352198641747, Final Batch Loss: 8.878095832187682e-05\n",
      "Epoch 2668, Loss: 0.0024998090229928493, Final Batch Loss: 0.00232585403136909\n",
      "Epoch 2669, Loss: 0.0006164989026729017, Final Batch Loss: 0.00039436673978343606\n",
      "Epoch 2670, Loss: 0.0006589496915694326, Final Batch Loss: 0.0001552254834678024\n",
      "Epoch 2671, Loss: 0.0014626511256210506, Final Batch Loss: 0.0011209504446014762\n",
      "Epoch 2672, Loss: 0.005100283771753311, Final Batch Loss: 0.002466897014528513\n",
      "Epoch 2673, Loss: 0.0002714549336815253, Final Batch Loss: 7.145966810639948e-05\n",
      "Epoch 2674, Loss: 0.0007323434110730886, Final Batch Loss: 0.00027124202460981905\n",
      "Epoch 2675, Loss: 0.006764064441085793, Final Batch Loss: 0.00017431181913707405\n",
      "Epoch 2676, Loss: 0.00772272574249655, Final Batch Loss: 0.00022754736710339785\n",
      "Epoch 2677, Loss: 0.0016296974354190752, Final Batch Loss: 0.0002236720611108467\n",
      "Epoch 2678, Loss: 0.0003799470578087494, Final Batch Loss: 0.0002886835136450827\n",
      "Epoch 2679, Loss: 0.00038749385566916317, Final Batch Loss: 0.0002617702994029969\n",
      "Epoch 2680, Loss: 0.001262558449525386, Final Batch Loss: 0.0007643434801138937\n",
      "Epoch 2681, Loss: 0.004382115221233107, Final Batch Loss: 0.0001566008577356115\n",
      "Epoch 2682, Loss: 0.000624324798991438, Final Batch Loss: 0.00012003166921203956\n",
      "Epoch 2683, Loss: 0.0011640290031209588, Final Batch Loss: 0.0010365688940510154\n",
      "Epoch 2684, Loss: 0.0005438947409857064, Final Batch Loss: 0.00013805489288643003\n",
      "Epoch 2685, Loss: 0.0005219411686994135, Final Batch Loss: 0.000342873070621863\n",
      "Epoch 2686, Loss: 0.0006507223297376186, Final Batch Loss: 0.00040667469147592783\n",
      "Epoch 2687, Loss: 0.001328536367509514, Final Batch Loss: 0.0007602399564348161\n",
      "Epoch 2688, Loss: 0.0006218457856448367, Final Batch Loss: 0.0004854505241382867\n",
      "Epoch 2689, Loss: 0.0008791962172836065, Final Batch Loss: 0.0006208796985447407\n",
      "Epoch 2690, Loss: 0.0012494168477132916, Final Batch Loss: 0.000865745882038027\n",
      "Epoch 2691, Loss: 0.0006551801925525069, Final Batch Loss: 0.000500270863994956\n",
      "Epoch 2692, Loss: 0.0003755206853384152, Final Batch Loss: 0.00021048058988526464\n",
      "Epoch 2693, Loss: 0.005397505359724164, Final Batch Loss: 0.0029351154807955027\n",
      "Epoch 2694, Loss: 0.007484624802600592, Final Batch Loss: 0.0003971123951487243\n",
      "Epoch 2695, Loss: 0.0006800464470870793, Final Batch Loss: 0.00042770610889419913\n",
      "Epoch 2696, Loss: 0.009304825551225804, Final Batch Loss: 7.877811731304973e-05\n",
      "Epoch 2697, Loss: 0.0003660924412542954, Final Batch Loss: 0.0001327580539509654\n",
      "Epoch 2698, Loss: 0.0017246700590476394, Final Batch Loss: 0.001097160391509533\n",
      "Epoch 2699, Loss: 0.0005617656715912744, Final Batch Loss: 0.000333381409291178\n",
      "Epoch 2700, Loss: 0.00032363478385377675, Final Batch Loss: 0.00017300894251093268\n",
      "Epoch 2701, Loss: 0.000632427167147398, Final Batch Loss: 0.0002979188575409353\n",
      "Epoch 2702, Loss: 0.005816871183924377, Final Batch Loss: 0.0009990724502131343\n",
      "Epoch 2703, Loss: 0.00112934282515198, Final Batch Loss: 0.0005149891949258745\n",
      "Epoch 2704, Loss: 0.001448879309464246, Final Batch Loss: 0.0004972774186171591\n",
      "Epoch 2705, Loss: 0.0011848431313410401, Final Batch Loss: 0.0007487143157050014\n",
      "Epoch 2706, Loss: 0.0003539425233611837, Final Batch Loss: 0.00022812232782598585\n",
      "Epoch 2707, Loss: 0.0003409414639463648, Final Batch Loss: 9.907082130666822e-05\n",
      "Epoch 2708, Loss: 0.00353907256067032, Final Batch Loss: 0.00010285291500622407\n",
      "Epoch 2709, Loss: 0.003028040111530572, Final Batch Loss: 0.00039804360130801797\n",
      "Epoch 2710, Loss: 0.00030582839099224657, Final Batch Loss: 6.005029717925936e-05\n",
      "Epoch 2711, Loss: 0.0077656743305851705, Final Batch Loss: 0.00010260177805321291\n",
      "Epoch 2712, Loss: 0.0009163198410533369, Final Batch Loss: 0.0005361266084946692\n",
      "Epoch 2713, Loss: 0.003870794316753745, Final Batch Loss: 0.0033278597984462976\n",
      "Epoch 2714, Loss: 0.000959197583142668, Final Batch Loss: 0.0006739069940522313\n",
      "Epoch 2715, Loss: 0.0007844885112717748, Final Batch Loss: 0.0002054732758551836\n",
      "Epoch 2716, Loss: 0.023536375461844727, Final Batch Loss: 0.0003540448087733239\n",
      "Epoch 2717, Loss: 0.009968620201107115, Final Batch Loss: 0.009570807218551636\n",
      "Epoch 2718, Loss: 0.0002315738020115532, Final Batch Loss: 7.583286060253158e-05\n",
      "Epoch 2719, Loss: 0.0007460752822225913, Final Batch Loss: 0.00012758465891238302\n",
      "Epoch 2720, Loss: 0.07548162032617256, Final Batch Loss: 0.000514943792950362\n",
      "Epoch 2721, Loss: 0.006854187507997267, Final Batch Loss: 0.00017781722999643534\n",
      "Epoch 2722, Loss: 0.00043277569784549996, Final Batch Loss: 4.850091499974951e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2723, Loss: 0.0011966290039708838, Final Batch Loss: 0.00015704087854828686\n",
      "Epoch 2724, Loss: 0.0029853704618290067, Final Batch Loss: 0.0012473724782466888\n",
      "Epoch 2725, Loss: 0.0020012530439998955, Final Batch Loss: 0.001655231462791562\n",
      "Epoch 2726, Loss: 0.0014025399286765605, Final Batch Loss: 0.0004626652516890317\n",
      "Epoch 2727, Loss: 0.006201817799592391, Final Batch Loss: 0.00032602218561805785\n",
      "Epoch 2728, Loss: 0.0007773558245389722, Final Batch Loss: 8.80827647051774e-05\n",
      "Epoch 2729, Loss: 0.000831005130748963, Final Batch Loss: 5.093126310384832e-05\n",
      "Epoch 2730, Loss: 0.00047649579573771916, Final Batch Loss: 5.7677327276906e-05\n",
      "Epoch 2731, Loss: 0.0005741945351473987, Final Batch Loss: 0.00020421008230187\n",
      "Epoch 2732, Loss: 0.00146520504495129, Final Batch Loss: 0.0011786625254899263\n",
      "Epoch 2733, Loss: 0.00047524095862172544, Final Batch Loss: 0.00010797270806506276\n",
      "Epoch 2734, Loss: 0.00034500450419727713, Final Batch Loss: 0.00025330117205157876\n",
      "Epoch 2735, Loss: 0.00019439508469076827, Final Batch Loss: 0.00011852345778606832\n",
      "Epoch 2736, Loss: 0.00043188745621591806, Final Batch Loss: 0.0001996429346036166\n",
      "Epoch 2737, Loss: 0.001408989104675129, Final Batch Loss: 0.0011449711164459586\n",
      "Epoch 2738, Loss: 0.002946366759715602, Final Batch Loss: 8.659527520649135e-05\n",
      "Epoch 2739, Loss: 0.0013524877140298486, Final Batch Loss: 0.00013488426338881254\n",
      "Epoch 2740, Loss: 0.0011218346771784127, Final Batch Loss: 0.0005123568698763847\n",
      "Epoch 2741, Loss: 0.00022025035286787897, Final Batch Loss: 0.00012983327906113118\n",
      "Epoch 2742, Loss: 0.002502682851627469, Final Batch Loss: 0.0013875149888917804\n",
      "Epoch 2743, Loss: 0.0021339200902730227, Final Batch Loss: 0.001867605489678681\n",
      "Epoch 2744, Loss: 0.00021552148609771393, Final Batch Loss: 0.00016757297271396965\n",
      "Epoch 2745, Loss: 0.0006203246593941003, Final Batch Loss: 6.959898746572435e-05\n",
      "Epoch 2746, Loss: 0.0005329237865225878, Final Batch Loss: 2.962263170047663e-05\n",
      "Epoch 2747, Loss: 0.004535852116532624, Final Batch Loss: 0.003956170286983252\n",
      "Epoch 2748, Loss: 0.00042549616773612797, Final Batch Loss: 0.00021263324015308172\n",
      "Epoch 2749, Loss: 0.0005384210817283019, Final Batch Loss: 0.0004369142116047442\n",
      "Epoch 2750, Loss: 0.0004583391928463243, Final Batch Loss: 5.0816066504921764e-05\n",
      "Epoch 2751, Loss: 0.001356391134322621, Final Batch Loss: 0.00019201113900635391\n",
      "Epoch 2752, Loss: 0.0007737853156868368, Final Batch Loss: 0.0006034660036675632\n",
      "Epoch 2753, Loss: 0.0006629551680816803, Final Batch Loss: 5.788827911601402e-05\n",
      "Epoch 2754, Loss: 0.000371438218280673, Final Batch Loss: 7.138267392292619e-05\n",
      "Epoch 2755, Loss: 0.03635689173825085, Final Batch Loss: 0.03588167577981949\n",
      "Epoch 2756, Loss: 0.0003133664285996929, Final Batch Loss: 0.00010183324047829956\n",
      "Epoch 2757, Loss: 0.000955304378294386, Final Batch Loss: 4.511822771746665e-05\n",
      "Epoch 2758, Loss: 0.010323186823370634, Final Batch Loss: 5.192630851524882e-05\n",
      "Epoch 2759, Loss: 0.022858351934701204, Final Batch Loss: 0.01712670549750328\n",
      "Epoch 2760, Loss: 0.0017237933934666216, Final Batch Loss: 0.00050644128350541\n",
      "Epoch 2761, Loss: 0.0012940609594807029, Final Batch Loss: 0.000538524123840034\n",
      "Epoch 2762, Loss: 0.0004537232161965221, Final Batch Loss: 9.729654993861914e-05\n",
      "Epoch 2763, Loss: 0.0008107048124657013, Final Batch Loss: 0.0001215483425767161\n",
      "Epoch 2764, Loss: 0.0006906092457938939, Final Batch Loss: 0.00043917365837842226\n",
      "Epoch 2765, Loss: 0.0008615804836153984, Final Batch Loss: 0.0006766509613953531\n",
      "Epoch 2766, Loss: 0.0006009425560478121, Final Batch Loss: 6.44809624645859e-05\n",
      "Epoch 2767, Loss: 0.0008651993703097105, Final Batch Loss: 0.00015427271137014031\n",
      "Epoch 2768, Loss: 0.0015666668623453006, Final Batch Loss: 0.0013449303805828094\n",
      "Epoch 2769, Loss: 0.0003561166813597083, Final Batch Loss: 0.00020096328807994723\n",
      "Epoch 2770, Loss: 0.00031617071363143623, Final Batch Loss: 0.00011622191232163459\n",
      "Epoch 2771, Loss: 0.00042530577047728, Final Batch Loss: 0.00016718156985007226\n",
      "Epoch 2772, Loss: 0.0026686088167480193, Final Batch Loss: 7.427008677041158e-05\n",
      "Epoch 2773, Loss: 0.0006462370802182704, Final Batch Loss: 0.0005045633297413588\n",
      "Epoch 2774, Loss: 0.0004700579011114314, Final Batch Loss: 0.00011279426689725369\n",
      "Epoch 2775, Loss: 0.0013757191627519205, Final Batch Loss: 0.0001307084021391347\n",
      "Epoch 2776, Loss: 0.000994744652416557, Final Batch Loss: 0.0004956829361617565\n",
      "Epoch 2777, Loss: 0.003424235910642892, Final Batch Loss: 0.0009211456053890288\n",
      "Epoch 2778, Loss: 0.000864650821313262, Final Batch Loss: 0.0004453777801245451\n",
      "Epoch 2779, Loss: 0.0008115226228255779, Final Batch Loss: 0.00027962509193457663\n",
      "Epoch 2780, Loss: 0.0010865911026485264, Final Batch Loss: 0.00036249664844945073\n",
      "Epoch 2781, Loss: 0.0002547914409660734, Final Batch Loss: 7.45143843232654e-05\n",
      "Epoch 2782, Loss: 0.0004754744077217765, Final Batch Loss: 0.00011925982107641175\n",
      "Epoch 2783, Loss: 0.007451698649674654, Final Batch Loss: 0.004129502456635237\n",
      "Epoch 2784, Loss: 0.008325406233780086, Final Batch Loss: 0.006918720435351133\n",
      "Epoch 2785, Loss: 0.002574236481450498, Final Batch Loss: 0.0006741600809618831\n",
      "Epoch 2786, Loss: 0.00046318021486513317, Final Batch Loss: 0.00014560730778612196\n",
      "Epoch 2787, Loss: 0.0025269368197768927, Final Batch Loss: 0.0011967188911512494\n",
      "Epoch 2788, Loss: 0.0034724354918580502, Final Batch Loss: 0.00010844084317795932\n",
      "Epoch 2789, Loss: 0.001059813192114234, Final Batch Loss: 0.00035434908932074904\n",
      "Epoch 2790, Loss: 0.0005367415142245591, Final Batch Loss: 0.0004088957794010639\n",
      "Epoch 2791, Loss: 0.0013068258413113654, Final Batch Loss: 0.0005258806049823761\n",
      "Epoch 2792, Loss: 0.00023110132315196097, Final Batch Loss: 9.815201337914914e-05\n",
      "Epoch 2793, Loss: 0.0014050721547391731, Final Batch Loss: 0.0013446781085804105\n",
      "Epoch 2794, Loss: 0.0033907265242305584, Final Batch Loss: 0.003318711882457137\n",
      "Epoch 2795, Loss: 0.0003201678191544488, Final Batch Loss: 0.0001384177739964798\n",
      "Epoch 2796, Loss: 0.0012624167138710618, Final Batch Loss: 0.00017007917631417513\n",
      "Epoch 2797, Loss: 0.0005709542310796678, Final Batch Loss: 0.00036727424594573677\n",
      "Epoch 2798, Loss: 0.0027444272054708563, Final Batch Loss: 0.002665210049599409\n",
      "Epoch 2799, Loss: 0.001033119362546131, Final Batch Loss: 0.0009729500161483884\n",
      "Epoch 2800, Loss: 0.0007789260998833925, Final Batch Loss: 0.0003881349985022098\n",
      "Epoch 2801, Loss: 0.0013584349899247172, Final Batch Loss: 9.387697900820058e-06\n",
      "Epoch 2802, Loss: 0.005830854643136263, Final Batch Loss: 0.004941283259540796\n",
      "Epoch 2803, Loss: 0.005382384289987385, Final Batch Loss: 0.000858334475196898\n",
      "Epoch 2804, Loss: 0.0007569256631541066, Final Batch Loss: 8.875212370185181e-05\n",
      "Epoch 2805, Loss: 0.00010174037925025914, Final Batch Loss: 1.6369451259379275e-05\n",
      "Epoch 2806, Loss: 0.0011923817219212651, Final Batch Loss: 0.000668409513309598\n",
      "Epoch 2807, Loss: 0.0014707351510878652, Final Batch Loss: 0.0011827296111732721\n",
      "Epoch 2808, Loss: 0.0009092301334021613, Final Batch Loss: 0.0007843628409318626\n",
      "Epoch 2809, Loss: 0.0007438873581122607, Final Batch Loss: 0.00035749253584071994\n",
      "Epoch 2810, Loss: 0.0010001456503232475, Final Batch Loss: 4.997636642656289e-05\n",
      "Epoch 2811, Loss: 0.0007461992063326761, Final Batch Loss: 0.00015232832811307162\n",
      "Epoch 2812, Loss: 0.00017832011144491844, Final Batch Loss: 5.399189467425458e-05\n",
      "Epoch 2813, Loss: 0.007948148850118741, Final Batch Loss: 0.000134758505737409\n",
      "Epoch 2814, Loss: 0.006625165115110576, Final Batch Loss: 0.0004502966767176986\n",
      "Epoch 2815, Loss: 0.0007051929424051195, Final Batch Loss: 0.0006311014294624329\n",
      "Epoch 2816, Loss: 0.0004633166245184839, Final Batch Loss: 0.00030329369474202394\n",
      "Epoch 2817, Loss: 0.0009251190931536257, Final Batch Loss: 0.0004420408222358674\n",
      "Epoch 2818, Loss: 0.0004689921042881906, Final Batch Loss: 0.00011620079749263823\n",
      "Epoch 2819, Loss: 0.00027727098495233804, Final Batch Loss: 9.595506708137691e-05\n",
      "Epoch 2820, Loss: 0.00046007467608433217, Final Batch Loss: 0.00022836214338894933\n",
      "Epoch 2821, Loss: 0.0031615553307347, Final Batch Loss: 0.0024665184319019318\n",
      "Epoch 2822, Loss: 0.00047543046093778685, Final Batch Loss: 0.00043303307029418647\n",
      "Epoch 2823, Loss: 0.0004924804088659585, Final Batch Loss: 0.00012046130723319948\n",
      "Epoch 2824, Loss: 0.009663870267104357, Final Batch Loss: 0.0002694341237656772\n",
      "Epoch 2825, Loss: 0.0011211741948500276, Final Batch Loss: 0.0008858394576236606\n",
      "Epoch 2826, Loss: 0.0006648826383752748, Final Batch Loss: 0.00019966821128036827\n",
      "Epoch 2827, Loss: 0.0009070239320863038, Final Batch Loss: 0.0005993182421661913\n",
      "Epoch 2828, Loss: 0.008621725719422102, Final Batch Loss: 0.005039631854742765\n",
      "Epoch 2829, Loss: 0.0001098783868656028, Final Batch Loss: 5.101450369693339e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2830, Loss: 0.00017362373910145834, Final Batch Loss: 0.0001333819527644664\n",
      "Epoch 2831, Loss: 0.00023552190396003425, Final Batch Loss: 0.00012928294017910957\n",
      "Epoch 2832, Loss: 0.0006241863302420825, Final Batch Loss: 0.00020455417688935995\n",
      "Epoch 2833, Loss: 0.0016877722518984228, Final Batch Loss: 0.0002725264348555356\n",
      "Epoch 2834, Loss: 0.0030592464609071612, Final Batch Loss: 0.0017184948083013296\n",
      "Epoch 2835, Loss: 0.000520892979693599, Final Batch Loss: 0.00046899469452910125\n",
      "Epoch 2836, Loss: 0.0003813625662587583, Final Batch Loss: 3.359746187925339e-05\n",
      "Epoch 2837, Loss: 0.0009357024682685733, Final Batch Loss: 0.0006356488447636366\n",
      "Epoch 2838, Loss: 0.001072168437531218, Final Batch Loss: 0.0004128528235014528\n",
      "Epoch 2839, Loss: 0.00027554395273909904, Final Batch Loss: 0.00023299496388062835\n",
      "Epoch 2840, Loss: 0.000518363478477113, Final Batch Loss: 0.00010615056089591235\n",
      "Epoch 2841, Loss: 0.0008949946641223505, Final Batch Loss: 0.000750918232370168\n",
      "Epoch 2842, Loss: 0.0001549449298181571, Final Batch Loss: 7.566577551187947e-05\n",
      "Epoch 2843, Loss: 9.229860734194517e-05, Final Batch Loss: 1.3125725672580302e-05\n",
      "Epoch 2844, Loss: 0.0009641782962717116, Final Batch Loss: 0.00022788916248828173\n",
      "Epoch 2845, Loss: 0.00026899841031990945, Final Batch Loss: 5.79520856263116e-05\n",
      "Epoch 2846, Loss: 0.003310492138552945, Final Batch Loss: 3.349163307575509e-05\n",
      "Epoch 2847, Loss: 9.432602382730693e-05, Final Batch Loss: 1.724612229736522e-05\n",
      "Epoch 2848, Loss: 0.0004800398455699906, Final Batch Loss: 0.0003272073809057474\n",
      "Epoch 2849, Loss: 0.0014229702501324937, Final Batch Loss: 6.444174505304545e-05\n",
      "Epoch 2850, Loss: 0.0026685717166401446, Final Batch Loss: 0.0007179463864304125\n",
      "Epoch 2851, Loss: 0.00019513863662723452, Final Batch Loss: 0.00010433192801428959\n",
      "Epoch 2852, Loss: 0.00022485637600766495, Final Batch Loss: 4.668953624786809e-05\n",
      "Epoch 2853, Loss: 0.00018019442359218374, Final Batch Loss: 2.0030995074193925e-05\n",
      "Epoch 2854, Loss: 0.0008641259701107629, Final Batch Loss: 3.059925074921921e-05\n",
      "Epoch 2855, Loss: 0.00029690557857975364, Final Batch Loss: 0.00016494806914124638\n",
      "Epoch 2856, Loss: 0.00048685658839531243, Final Batch Loss: 0.00036126599297858775\n",
      "Epoch 2857, Loss: 0.0002538605549489148, Final Batch Loss: 9.056035924004391e-05\n",
      "Epoch 2858, Loss: 0.002834009617799893, Final Batch Loss: 0.0023933416232466698\n",
      "Epoch 2859, Loss: 0.001097635817131959, Final Batch Loss: 0.0009604484657756984\n",
      "Epoch 2860, Loss: 6.77799016557401e-05, Final Batch Loss: 2.159355608455371e-05\n",
      "Epoch 2861, Loss: 9.860409772954881e-05, Final Batch Loss: 7.276571705006063e-05\n",
      "Epoch 2862, Loss: 0.00032422483491245657, Final Batch Loss: 0.0002012994373217225\n",
      "Epoch 2863, Loss: 0.00010705351087381132, Final Batch Loss: 6.423404556699097e-05\n",
      "Epoch 2864, Loss: 0.0003183521912433207, Final Batch Loss: 0.0002482558775227517\n",
      "Epoch 2865, Loss: 0.0010231441010546405, Final Batch Loss: 2.428538937238045e-05\n",
      "Epoch 2866, Loss: 0.0029762495032628067, Final Batch Loss: 0.002907410729676485\n",
      "Epoch 2867, Loss: 0.00041553819028194994, Final Batch Loss: 0.0002743935910984874\n",
      "Epoch 2868, Loss: 0.00026193047960987315, Final Batch Loss: 4.799983435077593e-05\n",
      "Epoch 2869, Loss: 0.0005722353816963732, Final Batch Loss: 0.0005398204084485769\n",
      "Epoch 2870, Loss: 0.00035395589293329976, Final Batch Loss: 0.0003045228368137032\n",
      "Epoch 2871, Loss: 0.0012168807443231344, Final Batch Loss: 0.0005601419252343476\n",
      "Epoch 2872, Loss: 0.00021829883189639077, Final Batch Loss: 8.984948362922296e-05\n",
      "Epoch 2873, Loss: 0.000814194034319371, Final Batch Loss: 0.00038045516703277826\n",
      "Epoch 2874, Loss: 0.0006777001217415091, Final Batch Loss: 2.9417245968943462e-05\n",
      "Epoch 2875, Loss: 0.0008698755409568548, Final Batch Loss: 0.00011120032286271453\n",
      "Epoch 2876, Loss: 0.001664508308749646, Final Batch Loss: 0.0001576387439854443\n",
      "Epoch 2877, Loss: 0.0016843907069414854, Final Batch Loss: 0.0001466601388528943\n",
      "Epoch 2878, Loss: 0.00025931634445441887, Final Batch Loss: 0.0001524139370303601\n",
      "Epoch 2879, Loss: 0.0001045758581312839, Final Batch Loss: 4.127718057134189e-05\n",
      "Epoch 2880, Loss: 0.015002489410107955, Final Batch Loss: 0.014888741075992584\n",
      "Epoch 2881, Loss: 0.0011930964537896216, Final Batch Loss: 0.0008751103305257857\n",
      "Epoch 2882, Loss: 0.005821587110403925, Final Batch Loss: 0.00014377670595422387\n",
      "Epoch 2883, Loss: 0.0007918737828731537, Final Batch Loss: 0.00031868572114035487\n",
      "Epoch 2884, Loss: 0.0020452604512684047, Final Batch Loss: 0.0013866734225302935\n",
      "Epoch 2885, Loss: 0.001520816091215238, Final Batch Loss: 0.001191386952996254\n",
      "Epoch 2886, Loss: 0.0004840634937863797, Final Batch Loss: 0.00023931730538606644\n",
      "Epoch 2887, Loss: 0.0007583616825286299, Final Batch Loss: 0.000623149739112705\n",
      "Epoch 2888, Loss: 0.0011414236796554178, Final Batch Loss: 0.0002761706418823451\n",
      "Epoch 2889, Loss: 0.0015159263566602021, Final Batch Loss: 6.622078944928944e-05\n",
      "Epoch 2890, Loss: 0.00015856896789046004, Final Batch Loss: 6.203669909154996e-05\n",
      "Epoch 2891, Loss: 0.0016396699138567783, Final Batch Loss: 0.00010384646157035604\n",
      "Epoch 2892, Loss: 0.0025397807112312876, Final Batch Loss: 0.00010060614295070991\n",
      "Epoch 2893, Loss: 0.0019395352646824904, Final Batch Loss: 0.0018212784780189395\n",
      "Epoch 2894, Loss: 0.0026076656067743897, Final Batch Loss: 0.0018084673210978508\n",
      "Epoch 2895, Loss: 0.00022606006677960977, Final Batch Loss: 7.860625191824511e-05\n",
      "Epoch 2896, Loss: 0.001564121776027605, Final Batch Loss: 0.0014972538920119405\n",
      "Epoch 2897, Loss: 0.00018841754354070872, Final Batch Loss: 0.00012450164649635553\n",
      "Epoch 2898, Loss: 0.001082763701560907, Final Batch Loss: 0.0008626566850580275\n",
      "Epoch 2899, Loss: 0.0005830719601362944, Final Batch Loss: 0.00016840975149534643\n",
      "Epoch 2900, Loss: 0.0012558098169392906, Final Batch Loss: 5.0576891226228327e-05\n",
      "Epoch 2901, Loss: 0.01107245366438292, Final Batch Loss: 0.00022291354252956808\n",
      "Epoch 2902, Loss: 0.0008361467043869197, Final Batch Loss: 0.0005875932401977479\n",
      "Epoch 2903, Loss: 0.0013317271950654685, Final Batch Loss: 0.00020108191529288888\n",
      "Epoch 2904, Loss: 0.00020419542488525622, Final Batch Loss: 3.62287501047831e-05\n",
      "Epoch 2905, Loss: 0.00022894619905855507, Final Batch Loss: 0.00013583739928435534\n",
      "Epoch 2906, Loss: 0.0006077889120206237, Final Batch Loss: 0.0003528466622810811\n",
      "Epoch 2907, Loss: 0.0008829774742480367, Final Batch Loss: 0.000573681085370481\n",
      "Epoch 2908, Loss: 0.020111417150474153, Final Batch Loss: 0.00019588296709116548\n",
      "Epoch 2909, Loss: 0.00039670596015639603, Final Batch Loss: 3.347257734276354e-05\n",
      "Epoch 2910, Loss: 0.0005031212640460581, Final Batch Loss: 0.00010520915384404361\n",
      "Epoch 2911, Loss: 0.0011019104131264612, Final Batch Loss: 0.0009137338493019342\n",
      "Epoch 2912, Loss: 0.0018276974369655363, Final Batch Loss: 0.00011932726920349523\n",
      "Epoch 2913, Loss: 0.00021661361097358167, Final Batch Loss: 4.1122460970655084e-05\n",
      "Epoch 2914, Loss: 0.002816602871462237, Final Batch Loss: 0.002727131126448512\n",
      "Epoch 2915, Loss: 0.009153112332569435, Final Batch Loss: 0.0001398581371176988\n",
      "Epoch 2916, Loss: 0.0002685318231669953, Final Batch Loss: 2.8027459848090075e-05\n",
      "Epoch 2917, Loss: 0.00017675426715868525, Final Batch Loss: 0.0001414501020917669\n",
      "Epoch 2918, Loss: 0.0010667290189303458, Final Batch Loss: 2.273119753226638e-05\n",
      "Epoch 2919, Loss: 0.0005043854034738615, Final Batch Loss: 0.00011125845776405185\n",
      "Epoch 2920, Loss: 0.0008361279615201056, Final Batch Loss: 0.0004370321985334158\n",
      "Epoch 2921, Loss: 0.00046085728536127135, Final Batch Loss: 3.8549267628695816e-05\n",
      "Epoch 2922, Loss: 0.0016125866477523232, Final Batch Loss: 1.919919486681465e-05\n",
      "Epoch 2923, Loss: 0.0008303687209263444, Final Batch Loss: 0.00041183101711794734\n",
      "Epoch 2924, Loss: 0.00038439009222202003, Final Batch Loss: 0.0001483401283621788\n",
      "Epoch 2925, Loss: 0.0005293017748044804, Final Batch Loss: 0.0003355934168212116\n",
      "Epoch 2926, Loss: 0.005098275025375187, Final Batch Loss: 2.577539999037981e-05\n",
      "Epoch 2927, Loss: 0.0003020208823727444, Final Batch Loss: 0.00017068960005417466\n",
      "Epoch 2928, Loss: 0.00029745068604825065, Final Batch Loss: 0.00012076041457476094\n",
      "Epoch 2929, Loss: 0.00023487046200898476, Final Batch Loss: 4.746760896523483e-05\n",
      "Epoch 2930, Loss: 0.0029450193032971583, Final Batch Loss: 9.241737279808149e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2931, Loss: 0.003985913586802781, Final Batch Loss: 0.0036186049692332745\n",
      "Epoch 2932, Loss: 0.00100109900085954, Final Batch Loss: 0.0009229392744600773\n",
      "Epoch 2933, Loss: 0.0010039842254627729, Final Batch Loss: 3.0059056371101178e-05\n",
      "Epoch 2934, Loss: 0.0004437804818735458, Final Batch Loss: 0.00010724241292336956\n",
      "Epoch 2935, Loss: 0.0008448856897302903, Final Batch Loss: 7.764364272588864e-05\n",
      "Epoch 2936, Loss: 0.0009162174683297053, Final Batch Loss: 0.00012564031931106\n",
      "Epoch 2937, Loss: 0.00016944538583629765, Final Batch Loss: 3.8757632864871994e-05\n",
      "Epoch 2938, Loss: 0.00026177083782386035, Final Batch Loss: 0.00019747547048609704\n",
      "Epoch 2939, Loss: 0.00175514051807113, Final Batch Loss: 0.0016845657955855131\n",
      "Epoch 2940, Loss: 0.0005557516487897374, Final Batch Loss: 4.266753239789978e-05\n",
      "Epoch 2941, Loss: 0.006515941524412483, Final Batch Loss: 0.0003639808273874223\n",
      "Epoch 2942, Loss: 0.003288020299805794, Final Batch Loss: 0.003181047271937132\n",
      "Epoch 2943, Loss: 0.0005569705317611806, Final Batch Loss: 0.00046276068314909935\n",
      "Epoch 2944, Loss: 0.0005163880705367774, Final Batch Loss: 0.0002870706666726619\n",
      "Epoch 2945, Loss: 0.000831482007924933, Final Batch Loss: 9.159692126559094e-05\n",
      "Epoch 2946, Loss: 0.0049418709822930396, Final Batch Loss: 0.004594052210450172\n",
      "Epoch 2947, Loss: 0.00042930110430461355, Final Batch Loss: 4.078967685927637e-05\n",
      "Epoch 2948, Loss: 0.0010350482116336934, Final Batch Loss: 0.0009678019559942186\n",
      "Epoch 2949, Loss: 0.0024747361458139494, Final Batch Loss: 0.002427981235086918\n",
      "Epoch 2950, Loss: 0.0050453562289476395, Final Batch Loss: 0.0028233022894710302\n",
      "Epoch 2951, Loss: 0.004849948396440595, Final Batch Loss: 0.004332726821303368\n",
      "Epoch 2952, Loss: 0.0003979513712693006, Final Batch Loss: 0.00015440369315911084\n",
      "Epoch 2953, Loss: 0.0011739331093849614, Final Batch Loss: 2.46502022491768e-05\n",
      "Epoch 2954, Loss: 0.0009457426203880459, Final Batch Loss: 0.0005386306438595057\n",
      "Epoch 2955, Loss: 0.00031602728995494545, Final Batch Loss: 0.00017671722162049264\n",
      "Epoch 2956, Loss: 0.002173671731725335, Final Batch Loss: 0.001036495203152299\n",
      "Epoch 2957, Loss: 0.0012930600787512958, Final Batch Loss: 0.0006516902940347791\n",
      "Epoch 2958, Loss: 0.0006514603592222556, Final Batch Loss: 0.0005324868834577501\n",
      "Epoch 2959, Loss: 0.0004601914879458491, Final Batch Loss: 0.00042120637954212725\n",
      "Epoch 2960, Loss: 0.00041834759758785367, Final Batch Loss: 0.00031460713944397867\n",
      "Epoch 2961, Loss: 0.0006971589536988176, Final Batch Loss: 3.598721377784386e-05\n",
      "Epoch 2962, Loss: 0.003938287953133113, Final Batch Loss: 2.6601823265082203e-05\n",
      "Epoch 2963, Loss: 0.00045087988837622106, Final Batch Loss: 8.873996557667851e-05\n",
      "Epoch 2964, Loss: 0.0008191235247068107, Final Batch Loss: 0.0001646495657041669\n",
      "Epoch 2965, Loss: 9.418623267265502e-05, Final Batch Loss: 2.5078852559090592e-05\n",
      "Epoch 2966, Loss: 0.002315870653546881, Final Batch Loss: 0.002242929534986615\n",
      "Epoch 2967, Loss: 0.00040871625242289156, Final Batch Loss: 7.118664507288486e-05\n",
      "Epoch 2968, Loss: 0.000576522303163074, Final Batch Loss: 0.00016058269829954952\n",
      "Epoch 2969, Loss: 0.00018122183246305212, Final Batch Loss: 7.880912744440138e-05\n",
      "Epoch 2970, Loss: 0.0014786440879106522, Final Batch Loss: 0.0003834750968962908\n",
      "Epoch 2971, Loss: 0.0005042308912379667, Final Batch Loss: 0.00015928219363559037\n",
      "Epoch 2972, Loss: 0.0008512879849149613, Final Batch Loss: 2.5500323317828588e-05\n",
      "Epoch 2973, Loss: 0.00044383575732354075, Final Batch Loss: 5.6762699387036264e-05\n",
      "Epoch 2974, Loss: 0.0017553407233208418, Final Batch Loss: 0.001384921371936798\n",
      "Epoch 2975, Loss: 0.0023366911482298747, Final Batch Loss: 8.936134690884501e-05\n",
      "Epoch 2976, Loss: 0.0003232802264392376, Final Batch Loss: 0.00022097653709352016\n",
      "Epoch 2977, Loss: 0.0005387562778196298, Final Batch Loss: 6.993352872086689e-05\n",
      "Epoch 2978, Loss: 0.0006725263956468552, Final Batch Loss: 0.0006030634976923466\n",
      "Epoch 2979, Loss: 0.0009338947347714566, Final Batch Loss: 0.0008162345038726926\n",
      "Epoch 2980, Loss: 0.0007447271564160474, Final Batch Loss: 5.0912211008835584e-05\n",
      "Epoch 2981, Loss: 0.0003316962902317755, Final Batch Loss: 7.93555736890994e-05\n",
      "Epoch 2982, Loss: 0.0004814869025722146, Final Batch Loss: 0.000420285010477528\n",
      "Epoch 2983, Loss: 0.0004988289729226381, Final Batch Loss: 0.000316450372338295\n",
      "Epoch 2984, Loss: 0.003266463245381601, Final Batch Loss: 0.0002352741576032713\n",
      "Epoch 2985, Loss: 0.0012951567659911234, Final Batch Loss: 5.965830132481642e-05\n",
      "Epoch 2986, Loss: 0.0008055395010160282, Final Batch Loss: 0.0006645902176387608\n",
      "Epoch 2987, Loss: 0.0010843186828424223, Final Batch Loss: 9.035442053573206e-05\n",
      "Epoch 2988, Loss: 0.012069572694599628, Final Batch Loss: 0.002375674434006214\n",
      "Epoch 2989, Loss: 0.0017738665628712624, Final Batch Loss: 0.0016173706389963627\n",
      "Epoch 2990, Loss: 0.0004376751894596964, Final Batch Loss: 0.00028705206932500005\n",
      "Epoch 2991, Loss: 0.003475009580142796, Final Batch Loss: 0.0015342060942202806\n",
      "Epoch 2992, Loss: 0.0011143247247673571, Final Batch Loss: 0.0008272836566902697\n",
      "Epoch 2993, Loss: 0.003131911926175235, Final Batch Loss: 2.1909199858782813e-05\n",
      "Epoch 2994, Loss: 0.00012755188072333112, Final Batch Loss: 3.644957178039476e-05\n",
      "Epoch 2995, Loss: 0.00022745868773199618, Final Batch Loss: 4.229444311931729e-05\n",
      "Epoch 2996, Loss: 0.00015471637743758038, Final Batch Loss: 5.85183224757202e-05\n",
      "Epoch 2997, Loss: 0.0012357819359749556, Final Batch Loss: 0.00017965014558285475\n",
      "Epoch 2998, Loss: 0.002505947730242042, Final Batch Loss: 0.0024706432595849037\n",
      "Epoch 2999, Loss: 6.068493166822009e-05, Final Batch Loss: 3.067767829634249e-05\n",
      "Epoch 3000, Loss: 0.0003210346258128993, Final Batch Loss: 0.00011932146298931912\n",
      "Epoch 3001, Loss: 0.0004702933938460774, Final Batch Loss: 9.22940580494469e-06\n",
      "Epoch 3002, Loss: 0.0005841319507453591, Final Batch Loss: 0.00023215141845867038\n",
      "Epoch 3003, Loss: 0.0011214694241061807, Final Batch Loss: 0.0004634096985682845\n",
      "Epoch 3004, Loss: 0.0016605513956164941, Final Batch Loss: 0.0014764646766707301\n",
      "Epoch 3005, Loss: 0.0003318936287541874, Final Batch Loss: 0.0002536655229050666\n",
      "Epoch 3006, Loss: 0.0002349959540879354, Final Batch Loss: 0.00019242212874814868\n",
      "Epoch 3007, Loss: 0.0005107467877678573, Final Batch Loss: 0.00027196898008696735\n",
      "Epoch 3008, Loss: 0.0003693189792102203, Final Batch Loss: 0.0001428054820280522\n",
      "Epoch 3009, Loss: 0.000997805647784844, Final Batch Loss: 0.0005972193903289735\n",
      "Epoch 3010, Loss: 0.0011905476567335427, Final Batch Loss: 0.0005847708671353757\n",
      "Epoch 3011, Loss: 0.0002742393044172786, Final Batch Loss: 0.00018562865443527699\n",
      "Epoch 3012, Loss: 0.0003699755143315997, Final Batch Loss: 5.3064748499309644e-05\n",
      "Epoch 3013, Loss: 0.0010861805913009448, Final Batch Loss: 3.0065215469221584e-05\n",
      "Epoch 3014, Loss: 0.00021104904590174556, Final Batch Loss: 0.00015249660646077245\n",
      "Epoch 3015, Loss: 0.000275475402304437, Final Batch Loss: 0.0001766372297424823\n",
      "Epoch 3016, Loss: 0.0003991005396528635, Final Batch Loss: 0.0003533978306222707\n",
      "Epoch 3017, Loss: 0.003355934808496386, Final Batch Loss: 0.0028350953944027424\n",
      "Epoch 3018, Loss: 0.0001462129657738842, Final Batch Loss: 9.990091348299757e-05\n",
      "Epoch 3019, Loss: 0.013088207226246595, Final Batch Loss: 0.0024555702693760395\n",
      "Epoch 3020, Loss: 0.00044033178710378706, Final Batch Loss: 0.00028108168044127524\n",
      "Epoch 3021, Loss: 0.0001973488656403788, Final Batch Loss: 4.35299853052129e-06\n",
      "Epoch 3022, Loss: 0.0005355888715712354, Final Batch Loss: 6.357887468766421e-05\n",
      "Epoch 3023, Loss: 0.00011185189032403287, Final Batch Loss: 9.229120041709393e-05\n",
      "Epoch 3024, Loss: 0.000721298260941694, Final Batch Loss: 7.063718840072397e-06\n",
      "Epoch 3025, Loss: 0.00028173129248898476, Final Batch Loss: 0.00024708383716642857\n",
      "Epoch 3026, Loss: 0.00014905076022841968, Final Batch Loss: 5.875402348465286e-05\n",
      "Epoch 3027, Loss: 0.00022610913219978102, Final Batch Loss: 4.499330316320993e-05\n",
      "Epoch 3028, Loss: 9.185790440824348e-05, Final Batch Loss: 2.3428796339430846e-05\n",
      "Epoch 3029, Loss: 0.001903926364320796, Final Batch Loss: 0.0018246127292513847\n",
      "Epoch 3030, Loss: 0.0023344396613538265, Final Batch Loss: 0.0010468708351254463\n",
      "Epoch 3031, Loss: 0.003292847282864386, Final Batch Loss: 0.0032393212895840406\n",
      "Epoch 3032, Loss: 0.0002718884206842631, Final Batch Loss: 3.631188883446157e-05\n",
      "Epoch 3033, Loss: 5.7183264289051294e-05, Final Batch Loss: 2.52242389251478e-05\n",
      "Epoch 3034, Loss: 0.00018235933384858072, Final Batch Loss: 0.0001280625001527369\n",
      "Epoch 3035, Loss: 0.0001920561699080281, Final Batch Loss: 0.0001728101633489132\n",
      "Epoch 3036, Loss: 0.0002461987969581969, Final Batch Loss: 0.00010031587589764968\n",
      "Epoch 3037, Loss: 0.0011457182554295287, Final Batch Loss: 0.0001183382555609569\n",
      "Epoch 3038, Loss: 0.0012182024656794965, Final Batch Loss: 0.0009943399345502257\n",
      "Epoch 3039, Loss: 7.904317317297682e-05, Final Batch Loss: 4.299639840610325e-05\n",
      "Epoch 3040, Loss: 0.0002631925672176294, Final Batch Loss: 0.0001041026771417819\n",
      "Epoch 3041, Loss: 0.00018649285811989103, Final Batch Loss: 0.0001581701944814995\n",
      "Epoch 3042, Loss: 0.0004431562701938674, Final Batch Loss: 0.00010540684161242098\n",
      "Epoch 3043, Loss: 0.00017038664009305649, Final Batch Loss: 0.00011339638149365783\n",
      "Epoch 3044, Loss: 0.01188858842033369, Final Batch Loss: 2.943595427495893e-05\n",
      "Epoch 3045, Loss: 0.00024433783619315363, Final Batch Loss: 3.3131003874586895e-05\n",
      "Epoch 3046, Loss: 0.006381685874657705, Final Batch Loss: 3.518446465022862e-05\n",
      "Epoch 3047, Loss: 6.43955972918775e-05, Final Batch Loss: 2.1882315195398405e-05\n",
      "Epoch 3048, Loss: 0.10127490827289876, Final Batch Loss: 0.10114231705665588\n",
      "Epoch 3049, Loss: 0.0023369965711026452, Final Batch Loss: 4.4631735363509506e-05\n",
      "Epoch 3050, Loss: 0.009653141692979261, Final Batch Loss: 0.009483236819505692\n",
      "Epoch 3051, Loss: 0.0015523173788096756, Final Batch Loss: 0.0013625813880935311\n",
      "Epoch 3052, Loss: 0.003050946514122188, Final Batch Loss: 0.0014022341929376125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3053, Loss: 0.0019460665062069893, Final Batch Loss: 0.0007110667647793889\n",
      "Epoch 3054, Loss: 0.005833117174915969, Final Batch Loss: 0.001130560296587646\n",
      "Epoch 3055, Loss: 0.009979896247386932, Final Batch Loss: 0.004580586217343807\n",
      "Epoch 3056, Loss: 0.001402186586346943, Final Batch Loss: 6.384216976584867e-05\n",
      "Epoch 3057, Loss: 0.00040969887049868703, Final Batch Loss: 5.298838368616998e-05\n",
      "Epoch 3058, Loss: 0.00010408935668237973, Final Batch Loss: 7.810549141140655e-05\n",
      "Epoch 3059, Loss: 0.003188152622897178, Final Batch Loss: 0.002883658977225423\n",
      "Epoch 3060, Loss: 0.0010651434058672749, Final Batch Loss: 0.0009656519978307188\n",
      "Epoch 3061, Loss: 0.0023438300122506917, Final Batch Loss: 0.0020979740656912327\n",
      "Epoch 3062, Loss: 0.0007701459981035441, Final Batch Loss: 0.0005397850181907415\n",
      "Epoch 3063, Loss: 0.0003821667796728434, Final Batch Loss: 2.7565418349695392e-05\n",
      "Epoch 3064, Loss: 0.001070445985533297, Final Batch Loss: 0.0005353764863684773\n",
      "Epoch 3065, Loss: 0.005813961965031922, Final Batch Loss: 0.0005023559788241982\n",
      "Epoch 3066, Loss: 0.0014642170572187752, Final Batch Loss: 0.0001036125177051872\n",
      "Epoch 3067, Loss: 0.00011047864973079413, Final Batch Loss: 4.116877244086936e-05\n",
      "Epoch 3068, Loss: 0.006806233257520944, Final Batch Loss: 0.00655483640730381\n",
      "Epoch 3069, Loss: 0.002492338651791215, Final Batch Loss: 0.0018386704614385962\n",
      "Epoch 3070, Loss: 0.00013638122254633345, Final Batch Loss: 4.833544880966656e-05\n",
      "Epoch 3071, Loss: 0.002036437756032683, Final Batch Loss: 0.0001365384232485667\n",
      "Epoch 3072, Loss: 0.00020042137839482166, Final Batch Loss: 0.0001627148303668946\n",
      "Epoch 3073, Loss: 0.0002045070123131154, Final Batch Loss: 2.3544967916677706e-05\n",
      "Epoch 3074, Loss: 0.00041461188084213063, Final Batch Loss: 0.0003129878896288574\n",
      "Epoch 3075, Loss: 0.0023232855019159615, Final Batch Loss: 0.001458243583329022\n",
      "Epoch 3076, Loss: 0.0005610129592241719, Final Batch Loss: 0.00023429708380717784\n",
      "Epoch 3077, Loss: 0.0011965834128204733, Final Batch Loss: 0.0007855443982407451\n",
      "Epoch 3078, Loss: 0.0004972069946234114, Final Batch Loss: 0.00038666947511956096\n",
      "Epoch 3079, Loss: 0.0004976189193257596, Final Batch Loss: 5.195484482101165e-05\n",
      "Epoch 3080, Loss: 0.0007263191364472732, Final Batch Loss: 0.00015729320875834674\n",
      "Epoch 3081, Loss: 0.004613390890881419, Final Batch Loss: 0.0036579763982445\n",
      "Epoch 3082, Loss: 0.00038760871393606067, Final Batch Loss: 0.000271962839178741\n",
      "Epoch 3083, Loss: 0.00020855755428783596, Final Batch Loss: 7.058822666294873e-05\n",
      "Epoch 3084, Loss: 0.0001751735180732794, Final Batch Loss: 5.838496144860983e-05\n",
      "Epoch 3085, Loss: 0.0004798761656275019, Final Batch Loss: 0.00012348986638244241\n",
      "Epoch 3086, Loss: 0.0008315562445204705, Final Batch Loss: 2.823866088874638e-05\n",
      "Epoch 3087, Loss: 0.0007624218087585177, Final Batch Loss: 4.7541569074383005e-05\n",
      "Epoch 3088, Loss: 0.0014263868579291739, Final Batch Loss: 5.726397648686543e-05\n",
      "Epoch 3089, Loss: 0.000910828443011269, Final Batch Loss: 0.0008431996684521437\n",
      "Epoch 3090, Loss: 0.00033687181712593883, Final Batch Loss: 0.0001586835423950106\n",
      "Epoch 3091, Loss: 0.0009434979874640703, Final Batch Loss: 0.0007834534044377506\n",
      "Epoch 3092, Loss: 0.0012740219135594089, Final Batch Loss: 0.0012300957459956408\n",
      "Epoch 3093, Loss: 0.0006748058294760995, Final Batch Loss: 0.0005929968319833279\n",
      "Epoch 3094, Loss: 0.09146229911129922, Final Batch Loss: 0.08967741578817368\n",
      "Epoch 3095, Loss: 0.0017182083684019744, Final Batch Loss: 0.0005325280944816768\n",
      "Epoch 3096, Loss: 0.0075814444571733475, Final Batch Loss: 0.006082730833441019\n",
      "Epoch 3097, Loss: 0.022120037581771612, Final Batch Loss: 0.006978947203606367\n",
      "Epoch 3098, Loss: 0.00876031196094118, Final Batch Loss: 0.00018355841166339815\n",
      "Epoch 3099, Loss: 0.00253938116657082, Final Batch Loss: 0.0023282652255147696\n",
      "Epoch 3100, Loss: 0.0006932762044016272, Final Batch Loss: 0.00029590577469207346\n",
      "Epoch 3101, Loss: 0.0033682180801406503, Final Batch Loss: 0.0026655644178390503\n",
      "Epoch 3102, Loss: 0.0005478244784171693, Final Batch Loss: 0.00011770382843678817\n",
      "Epoch 3103, Loss: 0.003230429458199069, Final Batch Loss: 0.0004208129539620131\n",
      "Epoch 3104, Loss: 0.00035229903005529195, Final Batch Loss: 0.00015126993821468204\n",
      "Epoch 3105, Loss: 0.00044529075967147946, Final Batch Loss: 0.00021671352442353964\n",
      "Epoch 3106, Loss: 0.0035225889296270907, Final Batch Loss: 0.0032694574911147356\n",
      "Epoch 3107, Loss: 0.005370470404159278, Final Batch Loss: 0.004980916623026133\n",
      "Epoch 3108, Loss: 0.0008939697872847319, Final Batch Loss: 0.00017344264779239893\n",
      "Epoch 3109, Loss: 0.011734036961570382, Final Batch Loss: 0.0027492160443216562\n",
      "Epoch 3110, Loss: 0.0006430426619772334, Final Batch Loss: 4.713777525466867e-05\n",
      "Epoch 3111, Loss: 0.0029521738761104643, Final Batch Loss: 0.002788177691400051\n",
      "Epoch 3112, Loss: 0.0016772844101069495, Final Batch Loss: 0.0015454406384378672\n",
      "Epoch 3113, Loss: 0.0002953064158646157, Final Batch Loss: 2.1060468498035334e-05\n",
      "Epoch 3114, Loss: 0.0005285931401886046, Final Batch Loss: 0.00018019392155110836\n",
      "Epoch 3115, Loss: 0.0005832985043525696, Final Batch Loss: 0.00020553197828121483\n",
      "Epoch 3116, Loss: 0.00282939471071586, Final Batch Loss: 0.0023847888223826885\n",
      "Epoch 3117, Loss: 0.00011967362661380321, Final Batch Loss: 6.04971319262404e-05\n",
      "Epoch 3118, Loss: 0.0010949897696264088, Final Batch Loss: 0.0003763306303881109\n",
      "Epoch 3119, Loss: 0.0023597488325322047, Final Batch Loss: 5.8188350521959364e-05\n",
      "Epoch 3120, Loss: 0.000676321596984053, Final Batch Loss: 4.036634709336795e-05\n",
      "Epoch 3121, Loss: 0.004395144176669419, Final Batch Loss: 0.0014101109700277448\n",
      "Epoch 3122, Loss: 0.0002836881030816585, Final Batch Loss: 7.871008710935712e-05\n",
      "Epoch 3123, Loss: 0.0001105122864828445, Final Batch Loss: 2.902167761931196e-05\n",
      "Epoch 3124, Loss: 0.0057581530418246984, Final Batch Loss: 0.0024660653434693813\n",
      "Epoch 3125, Loss: 0.007346548140048981, Final Batch Loss: 0.002859951462596655\n",
      "Epoch 3126, Loss: 0.0006827378965681419, Final Batch Loss: 0.0005923609132878482\n",
      "Epoch 3127, Loss: 0.0004997008363716304, Final Batch Loss: 0.0002883815614040941\n",
      "Epoch 3128, Loss: 0.032208996497502085, Final Batch Loss: 0.03211431950330734\n",
      "Epoch 3129, Loss: 0.001142182998592034, Final Batch Loss: 0.0008306330419145525\n",
      "Epoch 3130, Loss: 0.0016792513779364526, Final Batch Loss: 0.0006857462576590478\n",
      "Epoch 3131, Loss: 0.047421365161426365, Final Batch Loss: 0.04587360844016075\n",
      "Epoch 3132, Loss: 0.015719820963568054, Final Batch Loss: 7.835145515855402e-05\n",
      "Epoch 3133, Loss: 0.0005014976086386014, Final Batch Loss: 4.877733954344876e-05\n",
      "Epoch 3134, Loss: 0.00656428569345735, Final Batch Loss: 0.00027162357582710683\n",
      "Epoch 3135, Loss: 0.026568438857793808, Final Batch Loss: 0.009513525292277336\n",
      "Epoch 3136, Loss: 0.005231947900028899, Final Batch Loss: 0.00016281221178360283\n",
      "Epoch 3137, Loss: 0.0004902604268863797, Final Batch Loss: 0.0001679933920968324\n",
      "Epoch 3138, Loss: 0.0358650031266734, Final Batch Loss: 0.001707846182398498\n",
      "Epoch 3139, Loss: 0.004425632418133318, Final Batch Loss: 0.0006634650053456426\n",
      "Epoch 3140, Loss: 0.011778970016166568, Final Batch Loss: 0.009449479170143604\n",
      "Epoch 3141, Loss: 0.007949454477056861, Final Batch Loss: 0.006935903802514076\n",
      "Epoch 3142, Loss: 0.003422661335207522, Final Batch Loss: 0.0022488299291580915\n",
      "Epoch 3143, Loss: 0.017208509612828493, Final Batch Loss: 0.010889269411563873\n",
      "Epoch 3144, Loss: 0.0007659484836040065, Final Batch Loss: 0.0005668478552252054\n",
      "Epoch 3145, Loss: 0.004759829491376877, Final Batch Loss: 0.0009805834852159023\n",
      "Epoch 3146, Loss: 0.009583040868164971, Final Batch Loss: 0.009312828071415424\n",
      "Epoch 3147, Loss: 0.0007068726990837604, Final Batch Loss: 0.0003112483536824584\n",
      "Epoch 3148, Loss: 0.0033994898258242756, Final Batch Loss: 0.00042715450399555266\n",
      "Epoch 3149, Loss: 0.00747223908547312, Final Batch Loss: 0.0006691595772281289\n",
      "Epoch 3150, Loss: 0.0006938632177480031, Final Batch Loss: 4.2412564653204754e-05\n",
      "Epoch 3151, Loss: 0.0005242020561126992, Final Batch Loss: 0.00030557921854779124\n",
      "Epoch 3152, Loss: 0.0012101034371880814, Final Batch Loss: 0.0002188913495047018\n",
      "Epoch 3153, Loss: 0.0043446367781143636, Final Batch Loss: 0.00042337385821156204\n",
      "Epoch 3154, Loss: 0.0012009538768325, Final Batch Loss: 0.0011336535681039095\n",
      "Epoch 3155, Loss: 0.0008155588293448091, Final Batch Loss: 0.0002428781590424478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3156, Loss: 0.006646794441621751, Final Batch Loss: 0.0061097112484276295\n",
      "Epoch 3157, Loss: 0.0008054503996390849, Final Batch Loss: 0.0004484221281018108\n",
      "Epoch 3158, Loss: 0.002480712442775257, Final Batch Loss: 0.00017486415163148195\n",
      "Epoch 3159, Loss: 0.021493735490366817, Final Batch Loss: 0.003343241987749934\n",
      "Epoch 3160, Loss: 0.00020800383936148137, Final Batch Loss: 0.00013545656111091375\n",
      "Epoch 3161, Loss: 0.005810120899695903, Final Batch Loss: 0.0008088870090432465\n",
      "Epoch 3162, Loss: 0.0009292177128372714, Final Batch Loss: 0.00013042740465607494\n",
      "Epoch 3163, Loss: 0.0003400148270884529, Final Batch Loss: 0.00012827925093006343\n",
      "Epoch 3164, Loss: 0.004151973291300237, Final Batch Loss: 0.003044141223654151\n",
      "Epoch 3165, Loss: 0.0010436941520310938, Final Batch Loss: 0.00018099183216691017\n",
      "Epoch 3166, Loss: 0.0035700261396414135, Final Batch Loss: 5.8217094192514196e-05\n",
      "Epoch 3167, Loss: 0.0003484639382804744, Final Batch Loss: 9.684409451438114e-05\n",
      "Epoch 3168, Loss: 0.0010239398980047554, Final Batch Loss: 0.000868020229972899\n",
      "Epoch 3169, Loss: 0.0023248298093676567, Final Batch Loss: 0.0013120861258357763\n",
      "Epoch 3170, Loss: 0.002236038417322561, Final Batch Loss: 0.0003074010310228914\n",
      "Epoch 3171, Loss: 0.0002680824400158599, Final Batch Loss: 0.00018122860637959093\n",
      "Epoch 3172, Loss: 0.0019308891642140225, Final Batch Loss: 0.00023306017101276666\n",
      "Epoch 3173, Loss: 0.0005484445500769652, Final Batch Loss: 9.502218017587438e-05\n",
      "Epoch 3174, Loss: 0.0008967844332801178, Final Batch Loss: 0.0001855334994615987\n",
      "Epoch 3175, Loss: 0.0018996104481630027, Final Batch Loss: 0.0005966181051917374\n",
      "Epoch 3176, Loss: 0.0008573590312153101, Final Batch Loss: 7.244281005114317e-05\n",
      "Epoch 3177, Loss: 0.002231308550108224, Final Batch Loss: 0.0006792399217374623\n",
      "Epoch 3178, Loss: 0.03988995304098353, Final Batch Loss: 0.039213817566633224\n",
      "Epoch 3179, Loss: 0.0006244035175768659, Final Batch Loss: 0.0001488811249146238\n",
      "Epoch 3180, Loss: 0.000969504049862735, Final Batch Loss: 0.000746033270843327\n",
      "Epoch 3181, Loss: 0.0023438664502464235, Final Batch Loss: 0.0016751803923398256\n",
      "Epoch 3182, Loss: 0.002024403540417552, Final Batch Loss: 0.0014896852662786841\n",
      "Epoch 3183, Loss: 0.003918700385838747, Final Batch Loss: 0.0008698734454810619\n",
      "Epoch 3184, Loss: 0.004241279442794621, Final Batch Loss: 0.000748168327845633\n",
      "Epoch 3185, Loss: 0.0024606192018836737, Final Batch Loss: 0.0009717531502246857\n",
      "Epoch 3186, Loss: 0.0037002330645918846, Final Batch Loss: 0.0016453133430331945\n",
      "Epoch 3187, Loss: 0.0006934281118446961, Final Batch Loss: 0.00048505241284146905\n",
      "Epoch 3188, Loss: 0.012311625992879272, Final Batch Loss: 0.011869735084474087\n",
      "Epoch 3189, Loss: 0.002953228307887912, Final Batch Loss: 0.00014614290557801723\n",
      "Epoch 3190, Loss: 0.00043596909745247103, Final Batch Loss: 0.0004009850381407887\n",
      "Epoch 3191, Loss: 0.011319923069095239, Final Batch Loss: 0.0002123879676219076\n",
      "Epoch 3192, Loss: 0.0004279203276382759, Final Batch Loss: 0.00011713961430359632\n",
      "Epoch 3193, Loss: 0.0011643687612377107, Final Batch Loss: 0.0002313433215022087\n",
      "Epoch 3194, Loss: 0.000372381393390242, Final Batch Loss: 7.740435103187338e-05\n",
      "Epoch 3195, Loss: 0.003831670052022673, Final Batch Loss: 0.00021628140530083328\n",
      "Epoch 3196, Loss: 0.0011969966581091285, Final Batch Loss: 0.0008214516565203667\n",
      "Epoch 3197, Loss: 0.00021415462833829224, Final Batch Loss: 0.00011584728781599551\n",
      "Epoch 3198, Loss: 0.0008693705167388543, Final Batch Loss: 0.00022946226818021387\n",
      "Epoch 3199, Loss: 0.0008959139668149874, Final Batch Loss: 0.00021791817562188953\n",
      "Epoch 3200, Loss: 0.0002653382543940097, Final Batch Loss: 0.00015130940300878137\n",
      "Epoch 3201, Loss: 0.004197517642751336, Final Batch Loss: 0.0012106273788958788\n",
      "Epoch 3202, Loss: 0.0005623237666441128, Final Batch Loss: 0.00032464112155139446\n",
      "Epoch 3203, Loss: 0.00038487817073473707, Final Batch Loss: 8.409916335949674e-05\n",
      "Epoch 3204, Loss: 0.00044343869376461953, Final Batch Loss: 0.00015025983157102019\n",
      "Epoch 3205, Loss: 0.0015798218664713204, Final Batch Loss: 0.0010052609723061323\n",
      "Epoch 3206, Loss: 0.0005739612242905423, Final Batch Loss: 0.0003499047306831926\n",
      "Epoch 3207, Loss: 0.00026921381504507735, Final Batch Loss: 6.015308463247493e-05\n",
      "Epoch 3208, Loss: 0.004344276792835444, Final Batch Loss: 0.0005088371108286083\n",
      "Epoch 3209, Loss: 0.005625158315524459, Final Batch Loss: 0.0035979284439235926\n",
      "Epoch 3210, Loss: 0.0009836724493652582, Final Batch Loss: 0.0003947365330532193\n",
      "Epoch 3211, Loss: 0.0012613823637366295, Final Batch Loss: 0.00029353302670642734\n",
      "Epoch 3212, Loss: 0.0027742182719521224, Final Batch Loss: 0.0018086358904838562\n",
      "Epoch 3213, Loss: 0.002985977887874469, Final Batch Loss: 0.00018130274838767946\n",
      "Epoch 3214, Loss: 0.0052359955734573305, Final Batch Loss: 0.004952260293066502\n",
      "Epoch 3215, Loss: 0.0015789877506904304, Final Batch Loss: 0.0003897884744219482\n",
      "Epoch 3216, Loss: 0.0005761164502473548, Final Batch Loss: 0.00012875306128989905\n",
      "Epoch 3217, Loss: 0.0004003114881925285, Final Batch Loss: 0.000270490680122748\n",
      "Epoch 3218, Loss: 0.010929365875199437, Final Batch Loss: 0.007069926708936691\n",
      "Epoch 3219, Loss: 0.0012262640047993045, Final Batch Loss: 4.748355058836751e-05\n",
      "Epoch 3220, Loss: 0.004896023776382208, Final Batch Loss: 0.003871298162266612\n",
      "Epoch 3221, Loss: 0.0016737239784561098, Final Batch Loss: 0.0012306387070566416\n",
      "Epoch 3222, Loss: 0.0003392913786228746, Final Batch Loss: 0.00015826149319764227\n",
      "Epoch 3223, Loss: 0.0006722891121171415, Final Batch Loss: 0.00040311829070560634\n",
      "Epoch 3224, Loss: 0.012965265719685704, Final Batch Loss: 0.0005403422401286662\n",
      "Epoch 3225, Loss: 0.0001213066243508365, Final Batch Loss: 4.953443931299262e-05\n",
      "Epoch 3226, Loss: 0.0036468756807153113, Final Batch Loss: 7.914839807199314e-05\n",
      "Epoch 3227, Loss: 0.0009426280157640576, Final Batch Loss: 0.0001875801826827228\n",
      "Epoch 3228, Loss: 0.0005978879962640349, Final Batch Loss: 0.0005371961160562932\n",
      "Epoch 3229, Loss: 0.0002255293875350617, Final Batch Loss: 8.142146543832496e-05\n",
      "Epoch 3230, Loss: 0.00034285391666344367, Final Batch Loss: 4.8673824494471774e-05\n",
      "Epoch 3231, Loss: 0.0005436103674583137, Final Batch Loss: 0.00014821795048192143\n",
      "Epoch 3232, Loss: 0.00032730774546507746, Final Batch Loss: 0.00017963275604415685\n",
      "Epoch 3233, Loss: 0.0024009331027627923, Final Batch Loss: 4.982625978300348e-05\n",
      "Epoch 3234, Loss: 0.00031422747633769177, Final Batch Loss: 0.0002795762848109007\n",
      "Epoch 3235, Loss: 0.0020167388720437884, Final Batch Loss: 0.001063761068508029\n",
      "Epoch 3236, Loss: 0.008946035450208, Final Batch Loss: 0.00018486606131773442\n",
      "Epoch 3237, Loss: 0.0014452420873567462, Final Batch Loss: 0.0009469598880968988\n",
      "Epoch 3238, Loss: 0.0002698065436561592, Final Batch Loss: 0.00015106362116057426\n",
      "Epoch 3239, Loss: 0.0020492141447903123, Final Batch Loss: 4.039791747345589e-05\n",
      "Epoch 3240, Loss: 0.00100416346322163, Final Batch Loss: 4.187621743767522e-05\n",
      "Epoch 3241, Loss: 0.0026582003047224134, Final Batch Loss: 0.00030383592820726335\n",
      "Epoch 3242, Loss: 0.00037884744233451784, Final Batch Loss: 0.00017822235531639308\n",
      "Epoch 3243, Loss: 0.0005500607949215919, Final Batch Loss: 0.00015958910807967186\n",
      "Epoch 3244, Loss: 0.0022957056062296033, Final Batch Loss: 0.0010398642625659704\n",
      "Epoch 3245, Loss: 0.004845713789109141, Final Batch Loss: 0.0009191143908537924\n",
      "Epoch 3246, Loss: 0.0007759011641610414, Final Batch Loss: 0.0005153142847120762\n",
      "Epoch 3247, Loss: 0.003278811967902584, Final Batch Loss: 5.8048910432262346e-05\n",
      "Epoch 3248, Loss: 0.0048357284686062485, Final Batch Loss: 0.0004441164492163807\n",
      "Epoch 3249, Loss: 0.004728960157081019, Final Batch Loss: 0.004666733555495739\n",
      "Epoch 3250, Loss: 0.0011468734592199326, Final Batch Loss: 0.0005493765929713845\n",
      "Epoch 3251, Loss: 0.00035488269713823684, Final Batch Loss: 0.0003253800969105214\n",
      "Epoch 3252, Loss: 0.0038992562622297555, Final Batch Loss: 0.0035636303946375847\n",
      "Epoch 3253, Loss: 0.0004533367609838024, Final Batch Loss: 0.0003337220987305045\n",
      "Epoch 3254, Loss: 0.006807500729337335, Final Batch Loss: 0.0048348186537623405\n",
      "Epoch 3255, Loss: 0.0009614694499759935, Final Batch Loss: 0.0008698987658135593\n",
      "Epoch 3256, Loss: 0.0013206991425249726, Final Batch Loss: 0.0011319495970383286\n",
      "Epoch 3257, Loss: 0.009410243656020612, Final Batch Loss: 0.008887124247848988\n",
      "Epoch 3258, Loss: 0.02606654172996059, Final Batch Loss: 0.02554395981132984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3259, Loss: 0.0012986428919248283, Final Batch Loss: 0.0011415028711780906\n",
      "Epoch 3260, Loss: 0.000739404815249145, Final Batch Loss: 0.0005319819319993258\n",
      "Epoch 3261, Loss: 0.0009498994331806898, Final Batch Loss: 0.0006931868265382946\n",
      "Epoch 3262, Loss: 0.003059805167140439, Final Batch Loss: 0.0004524940450210124\n",
      "Epoch 3263, Loss: 0.00757165729010012, Final Batch Loss: 0.007343770004808903\n",
      "Epoch 3264, Loss: 0.00170463179165381, Final Batch Loss: 4.6977027523098513e-05\n",
      "Epoch 3265, Loss: 0.0014675979618914425, Final Batch Loss: 0.0005196972051635385\n",
      "Epoch 3266, Loss: 0.0012155345757491887, Final Batch Loss: 0.0005565175670199096\n",
      "Epoch 3267, Loss: 0.0004733972455142066, Final Batch Loss: 0.00011349971464369446\n",
      "Epoch 3268, Loss: 0.0036445987643674016, Final Batch Loss: 0.0018931209342554212\n",
      "Epoch 3269, Loss: 0.0008228978149418253, Final Batch Loss: 5.3205400035949424e-05\n",
      "Epoch 3270, Loss: 0.0010212658671662211, Final Batch Loss: 0.0007372050313279033\n",
      "Epoch 3271, Loss: 0.0034668805528781377, Final Batch Loss: 9.119175228988752e-05\n",
      "Epoch 3272, Loss: 0.007634593988768756, Final Batch Loss: 0.0006012612720951438\n",
      "Epoch 3273, Loss: 0.0017973101930692792, Final Batch Loss: 0.0005219243466854095\n",
      "Epoch 3274, Loss: 0.0004073430027347058, Final Batch Loss: 0.00034257490187883377\n",
      "Epoch 3275, Loss: 0.001736217993311584, Final Batch Loss: 0.0006131688132882118\n",
      "Epoch 3276, Loss: 0.00023764920479152352, Final Batch Loss: 8.799044007901102e-05\n",
      "Epoch 3277, Loss: 0.004509516758844256, Final Batch Loss: 0.00024581816978752613\n",
      "Epoch 3278, Loss: 0.004533739229373168, Final Batch Loss: 0.004494082182645798\n",
      "Epoch 3279, Loss: 0.0018125914793927222, Final Batch Loss: 0.00014901687973178923\n",
      "Epoch 3280, Loss: 0.0023012112360447645, Final Batch Loss: 0.00038675381802022457\n",
      "Epoch 3281, Loss: 0.001411865665431833, Final Batch Loss: 5.1702339987969026e-05\n",
      "Epoch 3282, Loss: 0.0050039188718074, Final Batch Loss: 0.004912845324724913\n",
      "Epoch 3283, Loss: 0.000674292723488179, Final Batch Loss: 2.0758876416948624e-05\n",
      "Epoch 3284, Loss: 0.0009381713171023875, Final Batch Loss: 0.0002363678941037506\n",
      "Epoch 3285, Loss: 0.0021884923335164785, Final Batch Loss: 0.0008244391065090895\n",
      "Epoch 3286, Loss: 0.0015416846254083794, Final Batch Loss: 5.327166218194179e-05\n",
      "Epoch 3287, Loss: 0.006386922446836252, Final Batch Loss: 2.057082747342065e-05\n",
      "Epoch 3288, Loss: 0.005707304284442216, Final Batch Loss: 0.0002598174032755196\n",
      "Epoch 3289, Loss: 0.0022442038753069937, Final Batch Loss: 0.0006587964599020779\n",
      "Epoch 3290, Loss: 0.00017520289111416787, Final Batch Loss: 4.2694780859164894e-05\n",
      "Epoch 3291, Loss: 0.0007572420217911713, Final Batch Loss: 0.00010803149052662775\n",
      "Epoch 3292, Loss: 0.0010507020924706012, Final Batch Loss: 0.0007161354878917336\n",
      "Epoch 3293, Loss: 0.0002487115125404671, Final Batch Loss: 3.330651088617742e-05\n",
      "Epoch 3294, Loss: 0.000281447220913833, Final Batch Loss: 0.00023552960192319006\n",
      "Epoch 3295, Loss: 0.00020063045667484403, Final Batch Loss: 0.00013524171663448215\n",
      "Epoch 3296, Loss: 0.0006100112077547237, Final Batch Loss: 0.0005100122070871294\n",
      "Epoch 3297, Loss: 0.001194839638628764, Final Batch Loss: 0.0011394955217838287\n",
      "Epoch 3298, Loss: 0.00034280717227375135, Final Batch Loss: 0.00023329243413172662\n",
      "Epoch 3299, Loss: 0.0006109719288360793, Final Batch Loss: 3.652384111774154e-05\n",
      "Epoch 3300, Loss: 0.0002921645063906908, Final Batch Loss: 1.6634236089885235e-05\n",
      "Epoch 3301, Loss: 0.00017248899530386552, Final Batch Loss: 6.26224500592798e-05\n",
      "Epoch 3302, Loss: 0.001194989905343391, Final Batch Loss: 0.0011214623227715492\n",
      "Epoch 3303, Loss: 0.00012377935127005912, Final Batch Loss: 6.55056064715609e-05\n",
      "Epoch 3304, Loss: 0.0004244106385158375, Final Batch Loss: 0.0003212230803910643\n",
      "Epoch 3305, Loss: 0.0005992388760205358, Final Batch Loss: 0.00041791825788095593\n",
      "Epoch 3306, Loss: 0.000774452812038362, Final Batch Loss: 0.0003487974463496357\n",
      "Epoch 3307, Loss: 0.0001257448675460182, Final Batch Loss: 2.6260953745804727e-05\n",
      "Epoch 3308, Loss: 0.002578126237494871, Final Batch Loss: 0.002404127037152648\n",
      "Epoch 3309, Loss: 0.002233812410850078, Final Batch Loss: 0.0017216793494299054\n",
      "Epoch 3310, Loss: 0.0004443616489879787, Final Batch Loss: 0.0002952999493572861\n",
      "Epoch 3311, Loss: 0.00015863121188885998, Final Batch Loss: 2.4332299290108494e-05\n",
      "Epoch 3312, Loss: 0.00018774631098494865, Final Batch Loss: 1.7798800399759784e-05\n",
      "Epoch 3313, Loss: 0.0006252339780985494, Final Batch Loss: 1.3856738405593205e-05\n",
      "Epoch 3314, Loss: 0.0019343377207405865, Final Batch Loss: 0.0005737104802392423\n",
      "Epoch 3315, Loss: 0.004632440424757078, Final Batch Loss: 0.004341114778071642\n",
      "Epoch 3316, Loss: 0.006381203304044902, Final Batch Loss: 0.005533560644835234\n",
      "Epoch 3317, Loss: 0.0024305202532559633, Final Batch Loss: 0.0013825998175889254\n",
      "Epoch 3318, Loss: 0.0018199656769866124, Final Batch Loss: 3.135263978037983e-05\n",
      "Epoch 3319, Loss: 0.00017374395247315988, Final Batch Loss: 2.193803811678663e-05\n",
      "Epoch 3320, Loss: 0.01383466413244605, Final Batch Loss: 0.008950847201049328\n",
      "Epoch 3321, Loss: 0.00016579014118178748, Final Batch Loss: 0.00011528838513186201\n",
      "Epoch 3322, Loss: 0.0006798747926950455, Final Batch Loss: 0.00042804685654118657\n",
      "Epoch 3323, Loss: 0.0005963886214885861, Final Batch Loss: 0.00013736277469433844\n",
      "Epoch 3324, Loss: 0.0029056807052256772, Final Batch Loss: 2.580452746769879e-05\n",
      "Epoch 3325, Loss: 0.01393333324813284, Final Batch Loss: 0.00033172746771015227\n",
      "Epoch 3326, Loss: 0.0008943495049607009, Final Batch Loss: 0.00024933446547947824\n",
      "Epoch 3327, Loss: 0.0013782887981506065, Final Batch Loss: 0.0012855494860559702\n",
      "Epoch 3328, Loss: 0.000506639109516982, Final Batch Loss: 9.427380427950993e-05\n",
      "Epoch 3329, Loss: 0.001333345657258178, Final Batch Loss: 2.833246071531903e-05\n",
      "Epoch 3330, Loss: 0.0029843120428267866, Final Batch Loss: 6.268979632295668e-05\n",
      "Epoch 3331, Loss: 0.00038172198401298374, Final Batch Loss: 6.190074782352895e-05\n",
      "Epoch 3332, Loss: 0.0009379337716381997, Final Batch Loss: 0.0006304567796178162\n",
      "Epoch 3333, Loss: 0.0016203367849811912, Final Batch Loss: 0.0009937490103766322\n",
      "Epoch 3334, Loss: 0.0007585833664052188, Final Batch Loss: 0.0004645897715818137\n",
      "Epoch 3335, Loss: 0.0013606789289042354, Final Batch Loss: 0.0007784746121615171\n",
      "Epoch 3336, Loss: 0.00030836583755444735, Final Batch Loss: 0.000140999341965653\n",
      "Epoch 3337, Loss: 0.000146396821946837, Final Batch Loss: 0.00011294171417830512\n",
      "Epoch 3338, Loss: 0.0005454991187434644, Final Batch Loss: 6.589433178305626e-05\n",
      "Epoch 3339, Loss: 0.00037002438330091536, Final Batch Loss: 0.0001568995794514194\n",
      "Epoch 3340, Loss: 0.0006825276650488377, Final Batch Loss: 4.2138679418712854e-05\n",
      "Epoch 3341, Loss: 0.05831339582800865, Final Batch Loss: 0.015653979033231735\n",
      "Epoch 3342, Loss: 0.0003625907702371478, Final Batch Loss: 6.43428647890687e-05\n",
      "Epoch 3343, Loss: 0.0010979925718856975, Final Batch Loss: 0.00020135425438638777\n",
      "Epoch 3344, Loss: 0.0006215809517016169, Final Batch Loss: 0.0005657953443005681\n",
      "Epoch 3345, Loss: 0.0018910084036178887, Final Batch Loss: 0.00013627199223265052\n",
      "Epoch 3346, Loss: 0.0002795299660647288, Final Batch Loss: 0.00015955751587171108\n",
      "Epoch 3347, Loss: 0.0006282356771407649, Final Batch Loss: 0.00044090949813835323\n",
      "Epoch 3348, Loss: 0.0015650912901037373, Final Batch Loss: 0.0015234273159876466\n",
      "Epoch 3349, Loss: 0.0013414411951089278, Final Batch Loss: 0.0011847189161926508\n",
      "Epoch 3350, Loss: 0.0004345908346294891, Final Batch Loss: 4.943455496686511e-05\n",
      "Epoch 3351, Loss: 0.00020398438209667802, Final Batch Loss: 0.00010500654752831906\n",
      "Epoch 3352, Loss: 0.0003750966498046182, Final Batch Loss: 7.978121720952913e-05\n",
      "Epoch 3353, Loss: 0.00044984358828514814, Final Batch Loss: 0.00012496602721512318\n",
      "Epoch 3354, Loss: 0.0003997897292720154, Final Batch Loss: 0.00010464734805282205\n",
      "Epoch 3355, Loss: 0.0033374450067640282, Final Batch Loss: 9.93793728412129e-05\n",
      "Epoch 3356, Loss: 0.0001977683132281527, Final Batch Loss: 5.438474181573838e-05\n",
      "Epoch 3357, Loss: 0.00035294293775223196, Final Batch Loss: 0.00021019828272983432\n",
      "Epoch 3358, Loss: 0.0005116210813866928, Final Batch Loss: 0.00028797975392080843\n",
      "Epoch 3359, Loss: 0.000678209908073768, Final Batch Loss: 0.00030215014703571796\n",
      "Epoch 3360, Loss: 0.00041236673132516444, Final Batch Loss: 0.00016521458746865392\n",
      "Epoch 3361, Loss: 0.0001895011664601043, Final Batch Loss: 4.654606163967401e-05\n",
      "Epoch 3362, Loss: 0.00015685823746025562, Final Batch Loss: 0.00010979809303535149\n",
      "Epoch 3363, Loss: 0.0011481501860544086, Final Batch Loss: 0.0003843632875941694\n",
      "Epoch 3364, Loss: 0.0004780945455422625, Final Batch Loss: 0.0004070725408382714\n",
      "Epoch 3365, Loss: 0.0008592797021265142, Final Batch Loss: 0.0007612482295371592\n",
      "Epoch 3366, Loss: 0.003182851418387145, Final Batch Loss: 0.0026992897037416697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3367, Loss: 0.004310358468501363, Final Batch Loss: 5.923506250837818e-05\n",
      "Epoch 3368, Loss: 0.0003179738196195103, Final Batch Loss: 6.154011498438194e-05\n",
      "Epoch 3369, Loss: 0.0010939360363408923, Final Batch Loss: 0.0002500938717275858\n",
      "Epoch 3370, Loss: 0.0021799888054374605, Final Batch Loss: 0.0019282483262941241\n",
      "Epoch 3371, Loss: 0.003489240596536547, Final Batch Loss: 9.942968608811498e-05\n",
      "Epoch 3372, Loss: 0.0005766532049165107, Final Batch Loss: 0.0005258027231320739\n",
      "Epoch 3373, Loss: 0.0023388006375171244, Final Batch Loss: 0.0022054261062294245\n",
      "Epoch 3374, Loss: 0.003982461697887629, Final Batch Loss: 0.0036069678608328104\n",
      "Epoch 3375, Loss: 0.0003139881227980368, Final Batch Loss: 2.6094399800058454e-05\n",
      "Epoch 3376, Loss: 0.0013949423446319997, Final Batch Loss: 0.0010019479086622596\n",
      "Epoch 3377, Loss: 0.001639803722355282, Final Batch Loss: 4.363045081845485e-05\n",
      "Epoch 3378, Loss: 0.00035822817517328076, Final Batch Loss: 2.8018588636768982e-05\n",
      "Epoch 3379, Loss: 0.001228453402291052, Final Batch Loss: 0.0011741906637325883\n",
      "Epoch 3380, Loss: 0.0006095523640397005, Final Batch Loss: 0.0005274871946312487\n",
      "Epoch 3381, Loss: 0.0001514563919045031, Final Batch Loss: 7.982548413565382e-05\n",
      "Epoch 3382, Loss: 0.0008076680533122271, Final Batch Loss: 0.0003441722656134516\n",
      "Epoch 3383, Loss: 0.000977441348368302, Final Batch Loss: 0.00021215996821410954\n",
      "Epoch 3384, Loss: 0.0007750606528134085, Final Batch Loss: 8.806426922092214e-05\n",
      "Epoch 3385, Loss: 0.00042205867066513747, Final Batch Loss: 0.0002641519531607628\n",
      "Epoch 3386, Loss: 0.0018845181039068848, Final Batch Loss: 0.0004297786217648536\n",
      "Epoch 3387, Loss: 0.0017653745308052748, Final Batch Loss: 0.0014412832679226995\n",
      "Epoch 3388, Loss: 0.00031239075178746134, Final Batch Loss: 0.00014024409756530076\n",
      "Epoch 3389, Loss: 0.00019498764231684618, Final Batch Loss: 4.477564289118163e-05\n",
      "Epoch 3390, Loss: 0.00019925505330320448, Final Batch Loss: 6.635182944592088e-05\n",
      "Epoch 3391, Loss: 0.00011448338409536518, Final Batch Loss: 5.384445103118196e-05\n",
      "Epoch 3392, Loss: 0.00038858174957567826, Final Batch Loss: 0.00012010563659714535\n",
      "Epoch 3393, Loss: 0.10906944965245202, Final Batch Loss: 0.10857901722192764\n",
      "Epoch 3394, Loss: 0.0008978066325653344, Final Batch Loss: 0.0003118203312624246\n",
      "Epoch 3395, Loss: 0.012364882764813956, Final Batch Loss: 0.012333652935922146\n",
      "Epoch 3396, Loss: 0.0012979464845557231, Final Batch Loss: 0.0012586740776896477\n",
      "Epoch 3397, Loss: 0.000852647382998839, Final Batch Loss: 0.00024057141854427755\n",
      "Epoch 3398, Loss: 0.0006475319023593329, Final Batch Loss: 5.3633433708455414e-05\n",
      "Epoch 3399, Loss: 0.0003098007036896888, Final Batch Loss: 0.00026550237089395523\n",
      "Epoch 3400, Loss: 0.0009497702412772924, Final Batch Loss: 0.00045204328489489853\n",
      "Epoch 3401, Loss: 0.0013106456026434898, Final Batch Loss: 0.000757017929572612\n",
      "Epoch 3402, Loss: 0.0010741153673734516, Final Batch Loss: 0.0004426862287800759\n",
      "Epoch 3403, Loss: 0.0012678539496846497, Final Batch Loss: 0.0006361848209053278\n",
      "Epoch 3404, Loss: 0.00031916525040287524, Final Batch Loss: 0.0001499268546467647\n",
      "Epoch 3405, Loss: 0.0007438686661771499, Final Batch Loss: 6.160177144920453e-05\n",
      "Epoch 3406, Loss: 0.010420219972729683, Final Batch Loss: 0.009909981861710548\n",
      "Epoch 3407, Loss: 0.0019971311558037996, Final Batch Loss: 0.0006758366944268346\n",
      "Epoch 3408, Loss: 0.0005185027839615941, Final Batch Loss: 0.00015153535059653223\n",
      "Epoch 3409, Loss: 0.00040616539627080783, Final Batch Loss: 9.805824811337516e-05\n",
      "Epoch 3410, Loss: 0.0005675274005625397, Final Batch Loss: 0.0003016168484464288\n",
      "Epoch 3411, Loss: 0.00016359026631107554, Final Batch Loss: 6.658994243480265e-05\n",
      "Epoch 3412, Loss: 0.0009261839586542919, Final Batch Loss: 0.00014611463120672852\n",
      "Epoch 3413, Loss: 0.040648853610036895, Final Batch Loss: 0.0402023121714592\n",
      "Epoch 3414, Loss: 0.00043764735164586455, Final Batch Loss: 8.12102371128276e-05\n",
      "Epoch 3415, Loss: 0.001256934876437299, Final Batch Loss: 0.00015282216190826148\n",
      "Epoch 3416, Loss: 0.0006055413468857296, Final Batch Loss: 0.00011404697579564527\n",
      "Epoch 3417, Loss: 0.0005643022013828158, Final Batch Loss: 0.0004155391070526093\n",
      "Epoch 3418, Loss: 0.006462265271693468, Final Batch Loss: 0.00015043187886476517\n",
      "Epoch 3419, Loss: 0.0026200442807748914, Final Batch Loss: 0.0021951112430542707\n",
      "Epoch 3420, Loss: 0.004118367505725473, Final Batch Loss: 0.0007719077984802425\n",
      "Epoch 3421, Loss: 0.000529582510353066, Final Batch Loss: 0.0003731535980477929\n",
      "Epoch 3422, Loss: 0.0003955522697651759, Final Batch Loss: 0.0002853780461009592\n",
      "Epoch 3423, Loss: 0.0002124602542608045, Final Batch Loss: 5.448486626846716e-05\n",
      "Epoch 3424, Loss: 0.00011114769222331233, Final Batch Loss: 5.242732004262507e-05\n",
      "Epoch 3425, Loss: 0.0002681737532839179, Final Batch Loss: 0.00019204233831260353\n",
      "Epoch 3426, Loss: 0.0006971198381506838, Final Batch Loss: 4.702280421042815e-05\n",
      "Epoch 3427, Loss: 0.006613637437112629, Final Batch Loss: 0.006112792994827032\n",
      "Epoch 3428, Loss: 0.0006690088630421087, Final Batch Loss: 0.0002340786886634305\n",
      "Epoch 3429, Loss: 0.00021606620430247858, Final Batch Loss: 5.021788092562929e-05\n",
      "Epoch 3430, Loss: 0.0006837515102233738, Final Batch Loss: 0.00017235815175808966\n",
      "Epoch 3431, Loss: 0.0003178946644766256, Final Batch Loss: 0.00015741652168799192\n",
      "Epoch 3432, Loss: 0.003316463786177337, Final Batch Loss: 0.0006898314459249377\n",
      "Epoch 3433, Loss: 0.013444157855701633, Final Batch Loss: 0.013248706236481667\n",
      "Epoch 3434, Loss: 0.0006957764126127586, Final Batch Loss: 0.0004530991427600384\n",
      "Epoch 3435, Loss: 0.0027764945407398045, Final Batch Loss: 0.0026186415925621986\n",
      "Epoch 3436, Loss: 0.000627204412012361, Final Batch Loss: 0.00020166234753560275\n",
      "Epoch 3437, Loss: 0.01434722961857915, Final Batch Loss: 0.003941513132303953\n",
      "Epoch 3438, Loss: 0.0012616517778951675, Final Batch Loss: 0.00044980269740335643\n",
      "Epoch 3439, Loss: 0.003120423119980842, Final Batch Loss: 0.00037533725844696164\n",
      "Epoch 3440, Loss: 0.002386024221777916, Final Batch Loss: 0.0007716877153143287\n",
      "Epoch 3441, Loss: 0.0003254125113016926, Final Batch Loss: 6.955727440072224e-05\n",
      "Epoch 3442, Loss: 0.0020271162502467632, Final Batch Loss: 0.00036486145108938217\n",
      "Epoch 3443, Loss: 0.0031851139792706817, Final Batch Loss: 0.00019538294873200357\n",
      "Epoch 3444, Loss: 0.004396187548991293, Final Batch Loss: 0.00020939524983987212\n",
      "Epoch 3445, Loss: 0.0006085712666390464, Final Batch Loss: 0.0005147708579897881\n",
      "Epoch 3446, Loss: 0.020873527508229017, Final Batch Loss: 0.015034806914627552\n",
      "Epoch 3447, Loss: 0.0038190162740647793, Final Batch Loss: 0.0020646541379392147\n",
      "Epoch 3448, Loss: 0.004099877085536718, Final Batch Loss: 0.0017366884276270866\n",
      "Epoch 3449, Loss: 0.011277556419372559, Final Batch Loss: 0.008616959676146507\n",
      "Epoch 3450, Loss: 0.06885561524541117, Final Batch Loss: 0.06851986795663834\n",
      "Epoch 3451, Loss: 0.03418106958270073, Final Batch Loss: 0.016132870689034462\n",
      "Epoch 3452, Loss: 0.0005393122846726328, Final Batch Loss: 8.418792276643217e-05\n",
      "Epoch 3453, Loss: 0.00020579880219884217, Final Batch Loss: 0.00013401638716459274\n",
      "Epoch 3454, Loss: 0.003126883806544356, Final Batch Loss: 0.002912451047450304\n",
      "Epoch 3455, Loss: 0.0721925804100465, Final Batch Loss: 0.00012468636850826442\n",
      "Epoch 3456, Loss: 0.0010895735467784107, Final Batch Loss: 0.0005731850978918374\n",
      "Epoch 3457, Loss: 0.0010717705881688744, Final Batch Loss: 0.000655549403745681\n",
      "Epoch 3458, Loss: 0.0019772675586864352, Final Batch Loss: 0.0012036466505378485\n",
      "Epoch 3459, Loss: 0.00047965437261154875, Final Batch Loss: 0.0001073049716069363\n",
      "Epoch 3460, Loss: 0.0008941584237618372, Final Batch Loss: 0.00020324169599916786\n",
      "Epoch 3461, Loss: 0.0037857459974475205, Final Batch Loss: 0.0029986018780618906\n",
      "Epoch 3462, Loss: 0.00339620525483042, Final Batch Loss: 0.0031616445630788803\n",
      "Epoch 3463, Loss: 0.0055639122147113085, Final Batch Loss: 0.0030082615558058023\n",
      "Epoch 3464, Loss: 0.0013419635142781772, Final Batch Loss: 0.0012374375946819782\n",
      "Epoch 3465, Loss: 0.0018846354214474559, Final Batch Loss: 0.0004361323080956936\n",
      "Epoch 3466, Loss: 0.004933339871058706, Final Batch Loss: 0.0001072248924174346\n",
      "Epoch 3467, Loss: 0.0003880819131154567, Final Batch Loss: 0.0002608842041809112\n",
      "Epoch 3468, Loss: 0.0019593033648561686, Final Batch Loss: 0.0017425016267225146\n",
      "Epoch 3469, Loss: 0.0014020844537299126, Final Batch Loss: 0.0009332159534096718\n",
      "Epoch 3470, Loss: 0.01084342086687684, Final Batch Loss: 0.004413151182234287\n",
      "Epoch 3471, Loss: 0.0005631781386910006, Final Batch Loss: 0.00023276272986549884\n",
      "Epoch 3472, Loss: 0.0023256394342752174, Final Batch Loss: 0.002195027656853199\n",
      "Epoch 3473, Loss: 0.0003451232987572439, Final Batch Loss: 8.219146548071876e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3474, Loss: 0.0021183475910220295, Final Batch Loss: 0.0018232886213809252\n",
      "Epoch 3475, Loss: 0.009905612096190453, Final Batch Loss: 0.0025466675870120525\n",
      "Epoch 3476, Loss: 0.004649866503314115, Final Batch Loss: 0.00019004441855940968\n",
      "Epoch 3477, Loss: 0.0010395188728580251, Final Batch Loss: 4.652842471841723e-05\n",
      "Epoch 3478, Loss: 0.002194936096202582, Final Batch Loss: 0.0017910886090248823\n",
      "Epoch 3479, Loss: 0.0005482312990352511, Final Batch Loss: 0.00020533072529360652\n",
      "Epoch 3480, Loss: 0.0016946428222581744, Final Batch Loss: 0.0009693016763776541\n",
      "Epoch 3481, Loss: 0.0011418850044719875, Final Batch Loss: 0.001001270255073905\n",
      "Epoch 3482, Loss: 0.0016031140112318099, Final Batch Loss: 0.000630284019280225\n",
      "Epoch 3483, Loss: 0.001853317276982125, Final Batch Loss: 0.00010903403017437086\n",
      "Epoch 3484, Loss: 0.0002013594057643786, Final Batch Loss: 0.00012218339543323964\n",
      "Epoch 3485, Loss: 0.00027484361271490343, Final Batch Loss: 5.2340565162012354e-05\n",
      "Epoch 3486, Loss: 0.0010965976980514824, Final Batch Loss: 0.0004311148659326136\n",
      "Epoch 3487, Loss: 0.0004843620117753744, Final Batch Loss: 0.00015387361054308712\n",
      "Epoch 3488, Loss: 0.0006072324322303757, Final Batch Loss: 0.0004200842813588679\n",
      "Epoch 3489, Loss: 0.000970759560004808, Final Batch Loss: 0.00013022923667449504\n",
      "Epoch 3490, Loss: 0.0005899776006117463, Final Batch Loss: 0.0002604210749268532\n",
      "Epoch 3491, Loss: 0.0006493554101325572, Final Batch Loss: 0.00022004154743626714\n",
      "Epoch 3492, Loss: 0.0009325337596237659, Final Batch Loss: 0.0005801494116894901\n",
      "Epoch 3493, Loss: 0.00034561647044029087, Final Batch Loss: 0.00021925230976194143\n",
      "Epoch 3494, Loss: 0.0012507632563938387, Final Batch Loss: 0.0011716564185917377\n",
      "Epoch 3495, Loss: 0.009583608742104843, Final Batch Loss: 0.00016214841161854565\n",
      "Epoch 3496, Loss: 0.0003440357104409486, Final Batch Loss: 0.0001750470546539873\n",
      "Epoch 3497, Loss: 0.0003625926765380427, Final Batch Loss: 0.00016310709179379046\n",
      "Epoch 3498, Loss: 0.001343062351224944, Final Batch Loss: 0.0010223517892882228\n",
      "Epoch 3499, Loss: 0.0036107941559748724, Final Batch Loss: 0.00012921933375764638\n",
      "Epoch 3500, Loss: 0.00020922306975990068, Final Batch Loss: 1.5610870832460932e-05\n",
      "Epoch 3501, Loss: 0.0007825698849046603, Final Batch Loss: 0.0005720193730667233\n",
      "Epoch 3502, Loss: 0.0003365803713677451, Final Batch Loss: 4.0718980017118156e-05\n",
      "Epoch 3503, Loss: 0.0007936572073958814, Final Batch Loss: 0.00028761994326487184\n",
      "Epoch 3504, Loss: 0.010750313966127578, Final Batch Loss: 0.01065786462277174\n",
      "Epoch 3505, Loss: 0.000991682056337595, Final Batch Loss: 0.0002743880031630397\n",
      "Epoch 3506, Loss: 0.007920157629996538, Final Batch Loss: 0.00242995610460639\n",
      "Epoch 3507, Loss: 0.0011166241529281251, Final Batch Loss: 0.0010334120597690344\n",
      "Epoch 3508, Loss: 0.0009086271456908435, Final Batch Loss: 0.0001947676355484873\n",
      "Epoch 3509, Loss: 0.000986882281722501, Final Batch Loss: 0.0004692588991019875\n",
      "Epoch 3510, Loss: 0.002977721393108368, Final Batch Loss: 0.0014764356892555952\n",
      "Epoch 3511, Loss: 0.002755716079263948, Final Batch Loss: 7.389821985270828e-05\n",
      "Epoch 3512, Loss: 0.0023644758039154112, Final Batch Loss: 0.0007389505044557154\n",
      "Epoch 3513, Loss: 0.0009484329784754664, Final Batch Loss: 0.0006867272895760834\n",
      "Epoch 3514, Loss: 0.008468353655189276, Final Batch Loss: 0.0047795455902814865\n",
      "Epoch 3515, Loss: 0.0027059409039793536, Final Batch Loss: 0.0024836768861860037\n",
      "Epoch 3516, Loss: 0.0005031020700698718, Final Batch Loss: 0.0001624026772333309\n",
      "Epoch 3517, Loss: 0.0006850747449789196, Final Batch Loss: 0.000328974740114063\n",
      "Epoch 3518, Loss: 0.0012069704825989902, Final Batch Loss: 0.00029836816247552633\n",
      "Epoch 3519, Loss: 0.0006329370298772119, Final Batch Loss: 0.00011637587886070833\n",
      "Epoch 3520, Loss: 0.0006602656430914067, Final Batch Loss: 0.0005794488824903965\n",
      "Epoch 3521, Loss: 0.0008693111885804683, Final Batch Loss: 0.0004573845071718097\n",
      "Epoch 3522, Loss: 0.002513928680855315, Final Batch Loss: 0.00011711927800206468\n",
      "Epoch 3523, Loss: 0.0008460158278467134, Final Batch Loss: 0.0007091565639711916\n",
      "Epoch 3524, Loss: 0.0010237733295070939, Final Batch Loss: 5.5234871979337186e-05\n",
      "Epoch 3525, Loss: 0.0018250925350002944, Final Batch Loss: 0.0010501253418624401\n",
      "Epoch 3526, Loss: 0.00020003457757411525, Final Batch Loss: 6.89560329192318e-05\n",
      "Epoch 3527, Loss: 0.001643091265577823, Final Batch Loss: 0.0010750521905720234\n",
      "Epoch 3528, Loss: 0.001813419396057725, Final Batch Loss: 4.9866968765854836e-05\n",
      "Epoch 3529, Loss: 0.00024827181914588436, Final Batch Loss: 0.00016703932487871498\n",
      "Epoch 3530, Loss: 0.001116236875532195, Final Batch Loss: 0.00034271818003617227\n",
      "Epoch 3531, Loss: 0.00037027820508228615, Final Batch Loss: 8.71903685037978e-05\n",
      "Epoch 3532, Loss: 0.005397541041020304, Final Batch Loss: 0.0051165176555514336\n",
      "Epoch 3533, Loss: 0.0001349225094600115, Final Batch Loss: 4.483792508835904e-05\n",
      "Epoch 3534, Loss: 0.000810404701041989, Final Batch Loss: 0.00014484096027445048\n",
      "Epoch 3535, Loss: 0.0005641663010464981, Final Batch Loss: 0.00012447986227925867\n",
      "Epoch 3536, Loss: 0.0006553882267326117, Final Batch Loss: 0.0004060868814121932\n",
      "Epoch 3537, Loss: 0.0019712601642822847, Final Batch Loss: 0.000151837695739232\n",
      "Epoch 3538, Loss: 0.00014593300147680566, Final Batch Loss: 6.73791000735946e-05\n",
      "Epoch 3539, Loss: 0.0006555295040016063, Final Batch Loss: 0.0005648961523547769\n",
      "Epoch 3540, Loss: 0.0001827183732530102, Final Batch Loss: 3.928205114789307e-05\n",
      "Epoch 3541, Loss: 0.0022958608460612595, Final Batch Loss: 0.0004982523969374597\n",
      "Epoch 3542, Loss: 0.00015986321159289218, Final Batch Loss: 3.4334883821429685e-05\n",
      "Epoch 3543, Loss: 0.00023201713702292182, Final Batch Loss: 3.926112913177349e-05\n",
      "Epoch 3544, Loss: 0.0006863997114123777, Final Batch Loss: 3.297628427390009e-05\n",
      "Epoch 3545, Loss: 0.0006221049843588844, Final Batch Loss: 0.00019267383322585374\n",
      "Epoch 3546, Loss: 0.0010951829754048958, Final Batch Loss: 0.0010187389561906457\n",
      "Epoch 3547, Loss: 0.00019838391381199472, Final Batch Loss: 0.00014746752276550978\n",
      "Epoch 3548, Loss: 0.0005124792805872858, Final Batch Loss: 0.00020194626995362341\n",
      "Epoch 3549, Loss: 0.0009791550983209163, Final Batch Loss: 0.00021365287830121815\n",
      "Epoch 3550, Loss: 0.0010443788196425885, Final Batch Loss: 0.000203821953618899\n",
      "Epoch 3551, Loss: 0.0006593276921194047, Final Batch Loss: 0.00022772292140871286\n",
      "Epoch 3552, Loss: 0.0024217074969783425, Final Batch Loss: 0.0007925485260784626\n",
      "Epoch 3553, Loss: 0.00026600843557389453, Final Batch Loss: 8.079873077804223e-05\n",
      "Epoch 3554, Loss: 0.0012535563146229833, Final Batch Loss: 0.0010902181966230273\n",
      "Epoch 3555, Loss: 0.0005503051943378523, Final Batch Loss: 0.00022397101565729827\n",
      "Epoch 3556, Loss: 0.00036900168925058097, Final Batch Loss: 5.3196316002868116e-05\n",
      "Epoch 3557, Loss: 0.007929963059723377, Final Batch Loss: 0.003925517667084932\n",
      "Epoch 3558, Loss: 0.005529326292162295, Final Batch Loss: 0.00010316483530914411\n",
      "Epoch 3559, Loss: 0.0014131255102256546, Final Batch Loss: 2.1702342564822175e-05\n",
      "Epoch 3560, Loss: 0.000523268201504834, Final Batch Loss: 0.0003749722964130342\n",
      "Epoch 3561, Loss: 0.00040942437772173434, Final Batch Loss: 0.00030094306566752493\n",
      "Epoch 3562, Loss: 0.0008449458837276325, Final Batch Loss: 0.0002194363478338346\n",
      "Epoch 3563, Loss: 0.0077458739979192615, Final Batch Loss: 0.006757795810699463\n",
      "Epoch 3564, Loss: 0.0031497724121436477, Final Batch Loss: 0.0005893373163416982\n",
      "Epoch 3565, Loss: 0.0013535256584873423, Final Batch Loss: 0.0011357661569491029\n",
      "Epoch 3566, Loss: 0.0006421779035008512, Final Batch Loss: 8.454472845187411e-05\n",
      "Epoch 3567, Loss: 0.00013152269821148366, Final Batch Loss: 8.347634866368026e-05\n",
      "Epoch 3568, Loss: 0.0009211187571054325, Final Batch Loss: 0.0008171996450982988\n",
      "Epoch 3569, Loss: 0.00030725690885446966, Final Batch Loss: 5.644359043799341e-05\n",
      "Epoch 3570, Loss: 0.0016209366076509468, Final Batch Loss: 7.083411765052006e-05\n",
      "Epoch 3571, Loss: 0.000474832093459554, Final Batch Loss: 0.0003857942356262356\n",
      "Epoch 3572, Loss: 0.0008632132376078516, Final Batch Loss: 0.0006114557036198676\n",
      "Epoch 3573, Loss: 0.0013192619662731886, Final Batch Loss: 0.00021413888316601515\n",
      "Epoch 3574, Loss: 0.00018868888582801446, Final Batch Loss: 0.00010966326954076067\n",
      "Epoch 3575, Loss: 0.0005456649232655764, Final Batch Loss: 0.0003065782366320491\n",
      "Epoch 3576, Loss: 0.000906334062165115, Final Batch Loss: 6.740584649378434e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3577, Loss: 0.0005750539203290828, Final Batch Loss: 5.682273331331089e-05\n",
      "Epoch 3578, Loss: 0.0007958615897223353, Final Batch Loss: 0.00012969819363206625\n",
      "Epoch 3579, Loss: 0.0003220180224161595, Final Batch Loss: 0.00020192160445731133\n",
      "Epoch 3580, Loss: 0.0022797762940172106, Final Batch Loss: 0.00022353875101543963\n",
      "Epoch 3581, Loss: 0.00013744094212597702, Final Batch Loss: 2.8845346605521627e-05\n",
      "Epoch 3582, Loss: 0.0002179371331294533, Final Batch Loss: 5.5542619520565495e-05\n",
      "Epoch 3583, Loss: 0.00246898818295449, Final Batch Loss: 0.0004713671514764428\n",
      "Epoch 3584, Loss: 0.0005382064846344292, Final Batch Loss: 0.00026217990671284497\n",
      "Epoch 3585, Loss: 0.0030145366181386635, Final Batch Loss: 0.0029189535416662693\n",
      "Epoch 3586, Loss: 0.006466220969741698, Final Batch Loss: 0.00011723572242772207\n",
      "Epoch 3587, Loss: 0.00033407494629500434, Final Batch Loss: 0.0001018003313220106\n",
      "Epoch 3588, Loss: 0.0017498831075499766, Final Batch Loss: 0.0016872066771611571\n",
      "Epoch 3589, Loss: 0.0020909865270368755, Final Batch Loss: 0.0011745668016374111\n",
      "Epoch 3590, Loss: 0.0003353235515533015, Final Batch Loss: 2.8093912987969816e-05\n",
      "Epoch 3591, Loss: 0.005183207191294059, Final Batch Loss: 0.004905440844595432\n",
      "Epoch 3592, Loss: 0.0007457589890691452, Final Batch Loss: 9.751866309670731e-05\n",
      "Epoch 3593, Loss: 0.0007290802168427035, Final Batch Loss: 8.19460692582652e-05\n",
      "Epoch 3594, Loss: 0.0013888002431485802, Final Batch Loss: 0.0001491260773036629\n",
      "Epoch 3595, Loss: 0.00034786300238920376, Final Batch Loss: 7.854634168324992e-05\n",
      "Epoch 3596, Loss: 0.001173849574115593, Final Batch Loss: 0.0010967205744236708\n",
      "Epoch 3597, Loss: 0.0004064741369802505, Final Batch Loss: 0.00027913201483897865\n",
      "Epoch 3598, Loss: 0.00031282059353543445, Final Batch Loss: 0.00023843368398956954\n",
      "Epoch 3599, Loss: 0.002986077350215055, Final Batch Loss: 0.002820095280185342\n",
      "Epoch 3600, Loss: 0.0020521984006336424, Final Batch Loss: 0.0019929271657019854\n",
      "Epoch 3601, Loss: 0.0010078767372760922, Final Batch Loss: 0.0007129820878617465\n",
      "Epoch 3602, Loss: 0.0004770512750837952, Final Batch Loss: 0.0003403611481189728\n",
      "Epoch 3603, Loss: 0.00031860101444181055, Final Batch Loss: 7.646653102710843e-05\n",
      "Epoch 3604, Loss: 0.0006261136804823764, Final Batch Loss: 0.0005620727897621691\n",
      "Epoch 3605, Loss: 0.0017299482715316117, Final Batch Loss: 0.0004971045418642461\n",
      "Epoch 3606, Loss: 0.0003065034543396905, Final Batch Loss: 0.00013367386418394744\n",
      "Epoch 3607, Loss: 0.0002778600792225916, Final Batch Loss: 6.05012355663348e-05\n",
      "Epoch 3608, Loss: 0.00020154130106675439, Final Batch Loss: 0.0001660515263210982\n",
      "Epoch 3609, Loss: 0.0003794593721977435, Final Batch Loss: 8.928760507842526e-05\n",
      "Epoch 3610, Loss: 0.0008214891568059102, Final Batch Loss: 9.83163045020774e-05\n",
      "Epoch 3611, Loss: 0.00016284515004372224, Final Batch Loss: 9.362364653497934e-05\n",
      "Epoch 3612, Loss: 0.0008456665673293173, Final Batch Loss: 0.0002794609754346311\n",
      "Epoch 3613, Loss: 0.0002637068973854184, Final Batch Loss: 0.00017335338634438813\n",
      "Epoch 3614, Loss: 0.0004033199802506715, Final Batch Loss: 0.00010708268382586539\n",
      "Epoch 3615, Loss: 0.0004609767820511479, Final Batch Loss: 3.2536761864321306e-05\n",
      "Epoch 3616, Loss: 0.0009295824129367247, Final Batch Loss: 0.0007037650793790817\n",
      "Epoch 3617, Loss: 0.00010025435403804295, Final Batch Loss: 3.993017162429169e-05\n",
      "Epoch 3618, Loss: 0.000112667512439657, Final Batch Loss: 7.583341357531026e-05\n",
      "Epoch 3619, Loss: 0.0003013563764397986, Final Batch Loss: 0.00018841170822270215\n",
      "Epoch 3620, Loss: 0.00018568537052487954, Final Batch Loss: 0.00011366214312147349\n",
      "Epoch 3621, Loss: 0.0001903853117255494, Final Batch Loss: 0.00011522283602971584\n",
      "Epoch 3622, Loss: 0.00045942265569465235, Final Batch Loss: 4.842275666305795e-05\n",
      "Epoch 3623, Loss: 0.02579001904814504, Final Batch Loss: 0.0003276393690612167\n",
      "Epoch 3624, Loss: 0.0014261041505960748, Final Batch Loss: 0.00023677600256633013\n",
      "Epoch 3625, Loss: 0.00013798581130686216, Final Batch Loss: 7.960919901961461e-05\n",
      "Epoch 3626, Loss: 0.0006832489889347926, Final Batch Loss: 0.0001538563083158806\n",
      "Epoch 3627, Loss: 0.0006090770475566387, Final Batch Loss: 0.0004211048944853246\n",
      "Epoch 3628, Loss: 0.0004835973959416151, Final Batch Loss: 0.00013214501086622477\n",
      "Epoch 3629, Loss: 0.0007601450706715696, Final Batch Loss: 9.577959281159565e-05\n",
      "Epoch 3630, Loss: 0.0003774230062845163, Final Batch Loss: 8.953219366958365e-05\n",
      "Epoch 3631, Loss: 0.0015923389582894742, Final Batch Loss: 0.0007386332144960761\n",
      "Epoch 3632, Loss: 0.0007589249289594591, Final Batch Loss: 0.0005092603387311101\n",
      "Epoch 3633, Loss: 0.0011578006233321503, Final Batch Loss: 0.0009936329443007708\n",
      "Epoch 3634, Loss: 0.0009396798304805998, Final Batch Loss: 0.0008907862356863916\n",
      "Epoch 3635, Loss: 0.00014821386866969988, Final Batch Loss: 3.462607855908573e-05\n",
      "Epoch 3636, Loss: 0.0008872965408954769, Final Batch Loss: 0.0003064800112042576\n",
      "Epoch 3637, Loss: 0.00026815145974978805, Final Batch Loss: 0.00010000800830312073\n",
      "Epoch 3638, Loss: 0.00019896398589480668, Final Batch Loss: 0.00012903893366456032\n",
      "Epoch 3639, Loss: 0.00013009551548748277, Final Batch Loss: 7.221549458336085e-05\n",
      "Epoch 3640, Loss: 0.0011124513112008572, Final Batch Loss: 0.0009409791091457009\n",
      "Epoch 3641, Loss: 0.0005123571172589436, Final Batch Loss: 0.0004314457764849067\n",
      "Epoch 3642, Loss: 0.0006212364387465641, Final Batch Loss: 0.00020029341976623982\n",
      "Epoch 3643, Loss: 0.0012279704315005802, Final Batch Loss: 6.145840598037466e-05\n",
      "Epoch 3644, Loss: 0.00022108927078079432, Final Batch Loss: 8.409864676650614e-05\n",
      "Epoch 3645, Loss: 0.001584489393280819, Final Batch Loss: 0.001356526860035956\n",
      "Epoch 3646, Loss: 0.0005263222046778537, Final Batch Loss: 0.00046616827603429556\n",
      "Epoch 3647, Loss: 0.00042871080222539604, Final Batch Loss: 0.00035687987110577524\n",
      "Epoch 3648, Loss: 0.0008262987539637834, Final Batch Loss: 0.0006275113555602729\n",
      "Epoch 3649, Loss: 8.635462472739164e-05, Final Batch Loss: 6.394967931555584e-05\n",
      "Epoch 3650, Loss: 0.0002064479631371796, Final Batch Loss: 8.410515147261322e-05\n",
      "Epoch 3651, Loss: 0.0001639080946915783, Final Batch Loss: 6.923973705852404e-05\n",
      "Epoch 3652, Loss: 0.0007365915625996422, Final Batch Loss: 6.081284300307743e-05\n",
      "Epoch 3653, Loss: 0.0003558046373655088, Final Batch Loss: 7.798226579325274e-05\n",
      "Epoch 3654, Loss: 0.0017125519589171745, Final Batch Loss: 7.71723352954723e-05\n",
      "Epoch 3655, Loss: 0.0003523764025885612, Final Batch Loss: 0.00016665447037667036\n",
      "Epoch 3656, Loss: 0.00014485913743556011, Final Batch Loss: 2.2287875253823586e-05\n",
      "Epoch 3657, Loss: 0.0006092265393817797, Final Batch Loss: 6.62561651552096e-05\n",
      "Epoch 3658, Loss: 0.0008297987369587645, Final Batch Loss: 0.0001425832015229389\n",
      "Epoch 3659, Loss: 9.078336734091863e-05, Final Batch Loss: 3.4842712921090424e-05\n",
      "Epoch 3660, Loss: 0.0002607859642012045, Final Batch Loss: 6.601077620871365e-05\n",
      "Epoch 3661, Loss: 0.00019565347247407772, Final Batch Loss: 4.67897807538975e-05\n",
      "Epoch 3662, Loss: 0.0030099685973254964, Final Batch Loss: 0.0028825693298131227\n",
      "Epoch 3663, Loss: 0.00014991028001531959, Final Batch Loss: 5.619551666313782e-05\n",
      "Epoch 3664, Loss: 0.0003166943570249714, Final Batch Loss: 6.266131094889715e-05\n",
      "Epoch 3665, Loss: 0.0002176016423618421, Final Batch Loss: 8.49594798637554e-05\n",
      "Epoch 3666, Loss: 0.0003413086524233222, Final Batch Loss: 0.0002805336844176054\n",
      "Epoch 3667, Loss: 0.00023578957188874483, Final Batch Loss: 9.303330443799496e-05\n",
      "Epoch 3668, Loss: 0.0002376451375312172, Final Batch Loss: 3.8814971048850566e-05\n",
      "Epoch 3669, Loss: 0.0003104908100795001, Final Batch Loss: 0.00023536698427051306\n",
      "Epoch 3670, Loss: 0.0006329877214739099, Final Batch Loss: 0.0001354717678623274\n",
      "Epoch 3671, Loss: 0.00018391821868135594, Final Batch Loss: 0.00012453844828996807\n",
      "Epoch 3672, Loss: 8.660608455102192e-05, Final Batch Loss: 1.1013716175511945e-05\n",
      "Epoch 3673, Loss: 0.001410947210388258, Final Batch Loss: 0.0010520119685679674\n",
      "Epoch 3674, Loss: 0.0001302843593293801, Final Batch Loss: 3.7419042200781405e-05\n",
      "Epoch 3675, Loss: 0.0005812636518385261, Final Batch Loss: 0.00029942160472273827\n",
      "Epoch 3676, Loss: 0.0004178776180197019, Final Batch Loss: 0.00035978335654363036\n",
      "Epoch 3677, Loss: 9.820986451813951e-05, Final Batch Loss: 4.3445008486742154e-05\n",
      "Epoch 3678, Loss: 0.0013710064813494682, Final Batch Loss: 6.565719377249479e-05\n",
      "Epoch 3679, Loss: 0.00013613463670480996, Final Batch Loss: 5.189073272049427e-05\n",
      "Epoch 3680, Loss: 0.0014386814291356131, Final Batch Loss: 0.00011277738667558879\n",
      "Epoch 3681, Loss: 0.0001417347648384748, Final Batch Loss: 0.00011586163600441068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3682, Loss: 0.0224648373623495, Final Batch Loss: 6.776623922633007e-05\n",
      "Epoch 3683, Loss: 0.000986397048109211, Final Batch Loss: 0.0008081949781626463\n",
      "Epoch 3684, Loss: 0.003645135941042099, Final Batch Loss: 7.026122329989448e-05\n",
      "Epoch 3685, Loss: 0.00042603243491612375, Final Batch Loss: 0.0001381758484058082\n",
      "Epoch 3686, Loss: 0.0003399427114345599, Final Batch Loss: 0.00030688682454638183\n",
      "Epoch 3687, Loss: 0.00031234992638928816, Final Batch Loss: 5.839842924615368e-05\n",
      "Epoch 3688, Loss: 0.0011202511232113466, Final Batch Loss: 0.0009148558019660413\n",
      "Epoch 3689, Loss: 0.0007265702734002843, Final Batch Loss: 0.00018847444152925164\n",
      "Epoch 3690, Loss: 0.0004417267264216207, Final Batch Loss: 0.0003335707006044686\n",
      "Epoch 3691, Loss: 0.0007445005703630159, Final Batch Loss: 1.9671069821924902e-05\n",
      "Epoch 3692, Loss: 0.0008976697572506964, Final Batch Loss: 0.0003995154402218759\n",
      "Epoch 3693, Loss: 0.0004166759899817407, Final Batch Loss: 8.391655865125358e-05\n",
      "Epoch 3694, Loss: 0.0007504038621846121, Final Batch Loss: 0.0007094539469107985\n",
      "Epoch 3695, Loss: 0.0002949750196421519, Final Batch Loss: 0.00017079687677323818\n",
      "Epoch 3696, Loss: 0.0003500230159261264, Final Batch Loss: 6.609297270188108e-05\n",
      "Epoch 3697, Loss: 0.0008611912780907005, Final Batch Loss: 0.00013033472350798547\n",
      "Epoch 3698, Loss: 0.00011721067676262464, Final Batch Loss: 9.925993072101846e-05\n",
      "Epoch 3699, Loss: 9.614425653126091e-05, Final Batch Loss: 5.95322999288328e-05\n",
      "Epoch 3700, Loss: 0.0008767775834712666, Final Batch Loss: 0.0008480952237732708\n",
      "Epoch 3701, Loss: 0.0030011231428943574, Final Batch Loss: 0.0025073466822504997\n",
      "Epoch 3702, Loss: 0.0018867813050746918, Final Batch Loss: 0.0011710993712767959\n",
      "Epoch 3703, Loss: 0.0005761861539212987, Final Batch Loss: 7.753160025458783e-05\n",
      "Epoch 3704, Loss: 0.0010164921895920997, Final Batch Loss: 2.222687726316508e-05\n",
      "Epoch 3705, Loss: 0.00012694716497207992, Final Batch Loss: 2.0722716726595536e-05\n",
      "Epoch 3706, Loss: 0.0005272371890896466, Final Batch Loss: 5.319775300449692e-05\n",
      "Epoch 3707, Loss: 0.0008012947655515745, Final Batch Loss: 6.161282362882048e-05\n",
      "Epoch 3708, Loss: 0.020628908881917596, Final Batch Loss: 0.018525704741477966\n",
      "Epoch 3709, Loss: 0.00010818877854035236, Final Batch Loss: 9.228680573869497e-05\n",
      "Epoch 3710, Loss: 0.0003175913152517751, Final Batch Loss: 3.900450246874243e-05\n",
      "Epoch 3711, Loss: 0.0012705024419119582, Final Batch Loss: 0.0010740277357399464\n",
      "Epoch 3712, Loss: 8.758479816606268e-05, Final Batch Loss: 4.728914427687414e-05\n",
      "Epoch 3713, Loss: 0.00021325913985492662, Final Batch Loss: 0.00012730457819998264\n",
      "Epoch 3714, Loss: 0.0003719861269928515, Final Batch Loss: 0.00019832001999020576\n",
      "Epoch 3715, Loss: 0.001700468797935173, Final Batch Loss: 0.00036952292430214584\n",
      "Epoch 3716, Loss: 0.0003023840981768444, Final Batch Loss: 2.808049612212926e-05\n",
      "Epoch 3717, Loss: 0.0021020904896431603, Final Batch Loss: 0.00011182667367393151\n",
      "Epoch 3718, Loss: 0.0011471413890831172, Final Batch Loss: 0.0005284495418891311\n",
      "Epoch 3719, Loss: 0.00010686768655432388, Final Batch Loss: 5.402311944635585e-05\n",
      "Epoch 3720, Loss: 0.0001664611463638721, Final Batch Loss: 1.201939994643908e-05\n",
      "Epoch 3721, Loss: 0.00047879142221063375, Final Batch Loss: 0.00043262753752060235\n",
      "Epoch 3722, Loss: 4.26298902311828e-05, Final Batch Loss: 1.92638053704286e-05\n",
      "Epoch 3723, Loss: 0.000606085108302068, Final Batch Loss: 6.965517968637869e-05\n",
      "Epoch 3724, Loss: 0.00023050137679092586, Final Batch Loss: 7.061436190269887e-05\n",
      "Epoch 3725, Loss: 0.0004392360715428367, Final Batch Loss: 0.00011627776257228106\n",
      "Epoch 3726, Loss: 0.00014067094161873683, Final Batch Loss: 7.840195030439645e-05\n",
      "Epoch 3727, Loss: 0.00020091682381462306, Final Batch Loss: 0.00016652159683872014\n",
      "Epoch 3728, Loss: 9.894362665363587e-05, Final Batch Loss: 2.41892812482547e-05\n",
      "Epoch 3729, Loss: 0.001362753740977496, Final Batch Loss: 0.0010798913426697254\n",
      "Epoch 3730, Loss: 0.002189541068219114, Final Batch Loss: 6.88888321747072e-05\n",
      "Epoch 3731, Loss: 0.0006441499353968538, Final Batch Loss: 6.948665395611897e-05\n",
      "Epoch 3732, Loss: 7.139062654459849e-05, Final Batch Loss: 5.9072448493679985e-05\n",
      "Epoch 3733, Loss: 0.0004374439740786329, Final Batch Loss: 7.035628368612379e-05\n",
      "Epoch 3734, Loss: 0.00013989832223160192, Final Batch Loss: 0.00011389278370188549\n",
      "Epoch 3735, Loss: 0.0021851094788871706, Final Batch Loss: 0.0015868316404521465\n",
      "Epoch 3736, Loss: 0.00025703476421767846, Final Batch Loss: 7.472259312635288e-05\n",
      "Epoch 3737, Loss: 0.00020863582540187053, Final Batch Loss: 5.289665932650678e-05\n",
      "Epoch 3738, Loss: 0.0007625313883181661, Final Batch Loss: 3.125416697002947e-05\n",
      "Epoch 3739, Loss: 0.00015918239296297543, Final Batch Loss: 3.1955230952007696e-05\n",
      "Epoch 3740, Loss: 0.0001052508559951093, Final Batch Loss: 5.132097430760041e-05\n",
      "Epoch 3741, Loss: 0.00027822752053907607, Final Batch Loss: 2.271585435664747e-05\n",
      "Epoch 3742, Loss: 0.00025515454035485163, Final Batch Loss: 2.0985644368920475e-05\n",
      "Epoch 3743, Loss: 6.811025377828628e-05, Final Batch Loss: 2.5311801437055692e-05\n",
      "Epoch 3744, Loss: 0.0003814404917648062, Final Batch Loss: 0.00026364187942817807\n",
      "Epoch 3745, Loss: 0.0002507109566067811, Final Batch Loss: 0.00021368682791944593\n",
      "Epoch 3746, Loss: 0.0005708253738703206, Final Batch Loss: 0.00012858079571742564\n",
      "Epoch 3747, Loss: 0.000317961384098453, Final Batch Loss: 8.79244089446729e-06\n",
      "Epoch 3748, Loss: 3.5618872061604634e-05, Final Batch Loss: 8.349015843123198e-06\n",
      "Epoch 3749, Loss: 0.0005186032503843307, Final Batch Loss: 6.0744088841602206e-05\n",
      "Epoch 3750, Loss: 0.00026665225232136436, Final Batch Loss: 0.00021015484526287764\n",
      "Epoch 3751, Loss: 0.00035412051329331007, Final Batch Loss: 2.6876752599491738e-05\n",
      "Epoch 3752, Loss: 0.0003448800271144137, Final Batch Loss: 0.00030757320928387344\n",
      "Epoch 3753, Loss: 8.723662540432997e-05, Final Batch Loss: 6.768233288312331e-05\n",
      "Epoch 3754, Loss: 0.001726990994939115, Final Batch Loss: 4.9162736104335636e-05\n",
      "Epoch 3755, Loss: 0.0001931409860844724, Final Batch Loss: 9.113581472774968e-05\n",
      "Epoch 3756, Loss: 0.0029877915512770414, Final Batch Loss: 0.0007955634500831366\n",
      "Epoch 3757, Loss: 0.00019279750267742202, Final Batch Loss: 0.00012904776667710394\n",
      "Epoch 3758, Loss: 0.0016544370628253091, Final Batch Loss: 1.7443690012441948e-05\n",
      "Epoch 3759, Loss: 4.544465809885878e-05, Final Batch Loss: 2.0881998352706432e-05\n",
      "Epoch 3760, Loss: 0.0004603434063028544, Final Batch Loss: 0.00030754279578104615\n",
      "Epoch 3761, Loss: 0.000801908339781221, Final Batch Loss: 7.69546240917407e-05\n",
      "Epoch 3762, Loss: 0.0007778669823892415, Final Batch Loss: 0.00010519794886931777\n",
      "Epoch 3763, Loss: 0.00020268600928829983, Final Batch Loss: 3.3306794648524374e-05\n",
      "Epoch 3764, Loss: 4.979838286089944e-05, Final Batch Loss: 1.4621281479776371e-05\n",
      "Epoch 3765, Loss: 0.0005569974600803107, Final Batch Loss: 0.00021867977920919657\n",
      "Epoch 3766, Loss: 0.0004079258724232204, Final Batch Loss: 6.311751349130645e-05\n",
      "Epoch 3767, Loss: 0.003614483699493576, Final Batch Loss: 0.00351171987131238\n",
      "Epoch 3768, Loss: 0.0002496727101970464, Final Batch Loss: 6.470261723734438e-05\n",
      "Epoch 3769, Loss: 6.188335646584164e-05, Final Batch Loss: 2.1091103917569853e-05\n",
      "Epoch 3770, Loss: 0.0004272449223208241, Final Batch Loss: 3.8181628042366356e-05\n",
      "Epoch 3771, Loss: 0.00021490949802682735, Final Batch Loss: 3.111889600404538e-05\n",
      "Epoch 3772, Loss: 0.0007913238514447585, Final Batch Loss: 0.00016408094961661845\n",
      "Epoch 3773, Loss: 0.00041381254050065763, Final Batch Loss: 0.00037597835762426257\n",
      "Epoch 3774, Loss: 0.00036208150413585827, Final Batch Loss: 0.00011001308303093538\n",
      "Epoch 3775, Loss: 0.0010809307277668267, Final Batch Loss: 0.00026088932645507157\n",
      "Epoch 3776, Loss: 0.004094571449968498, Final Batch Loss: 0.004017201717942953\n",
      "Epoch 3777, Loss: 0.00014590381033485755, Final Batch Loss: 6.920834130141884e-05\n",
      "Epoch 3778, Loss: 0.00014121219646767713, Final Batch Loss: 0.00012040080036967993\n",
      "Epoch 3779, Loss: 0.0039451743141398765, Final Batch Loss: 0.003918707836419344\n",
      "Epoch 3780, Loss: 0.0008447480577160604, Final Batch Loss: 8.357916522072628e-05\n",
      "Epoch 3781, Loss: 3.543946695572231e-05, Final Batch Loss: 1.930142752826214e-05\n",
      "Epoch 3782, Loss: 0.0001824237551772967, Final Batch Loss: 0.0001473777083447203\n",
      "Epoch 3783, Loss: 7.305757935682777e-05, Final Batch Loss: 1.6799987861304544e-05\n",
      "Epoch 3784, Loss: 0.00018013891531154513, Final Batch Loss: 0.00011203742178622633\n",
      "Epoch 3785, Loss: 0.00602872425224632, Final Batch Loss: 0.004682977683842182\n",
      "Epoch 3786, Loss: 0.00016852058251970448, Final Batch Loss: 0.00014898930385243148\n",
      "Epoch 3787, Loss: 0.0013681244163308293, Final Batch Loss: 0.0010392967378720641\n",
      "Epoch 3788, Loss: 0.0029280699604896654, Final Batch Loss: 4.297057330404641e-06\n",
      "Epoch 3789, Loss: 0.0001451641037419904, Final Batch Loss: 3.755442958208732e-05\n",
      "Epoch 3790, Loss: 0.0036771148443222046, Final Batch Loss: 0.002467233221977949\n",
      "Epoch 3791, Loss: 0.00016238886746577919, Final Batch Loss: 5.4149051720742136e-05\n",
      "Epoch 3792, Loss: 0.00010959745122818276, Final Batch Loss: 6.2122184317559e-05\n",
      "Epoch 3793, Loss: 8.336071914527565e-05, Final Batch Loss: 3.799507248913869e-05\n",
      "Epoch 3794, Loss: 0.0002495513981557451, Final Batch Loss: 9.833965305006132e-05\n",
      "Epoch 3795, Loss: 0.00038188886537682265, Final Batch Loss: 0.00018461585568729788\n",
      "Epoch 3796, Loss: 0.000321186113069416, Final Batch Loss: 0.00030036328826099634\n",
      "Epoch 3797, Loss: 0.0003500648122098937, Final Batch Loss: 4.438722953636898e-06\n",
      "Epoch 3798, Loss: 0.04265997454058379, Final Batch Loss: 0.0016028647078201175\n",
      "Epoch 3799, Loss: 0.0006439413409680128, Final Batch Loss: 0.0005094489315524697\n",
      "Epoch 3800, Loss: 0.00016846617654664442, Final Batch Loss: 3.2164294680114836e-05\n",
      "Epoch 3801, Loss: 0.0006295006933214609, Final Batch Loss: 5.132382284500636e-05\n",
      "Epoch 3802, Loss: 0.0004932167612423655, Final Batch Loss: 4.57921669294592e-05\n",
      "Epoch 3803, Loss: 0.00058691059530247, Final Batch Loss: 0.00010683857544790953\n",
      "Epoch 3804, Loss: 0.0010098731436301023, Final Batch Loss: 0.0008248666417784989\n",
      "Epoch 3805, Loss: 0.0002159515061066486, Final Batch Loss: 6.941837636986747e-05\n",
      "Epoch 3806, Loss: 0.0006767140876036137, Final Batch Loss: 0.00011893242481164634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3807, Loss: 0.0008149148779921234, Final Batch Loss: 0.00068608985748142\n",
      "Epoch 3808, Loss: 9.771999611984938e-05, Final Batch Loss: 8.077325765043497e-05\n",
      "Epoch 3809, Loss: 0.0004048454648000188, Final Batch Loss: 4.9692469474393874e-05\n",
      "Epoch 3810, Loss: 0.011904332437552512, Final Batch Loss: 0.010822826996445656\n",
      "Epoch 3811, Loss: 0.00020850136934313923, Final Batch Loss: 9.375888475915417e-05\n",
      "Epoch 3812, Loss: 0.00027959400904364884, Final Batch Loss: 0.00018423155415803194\n",
      "Epoch 3813, Loss: 9.723391485749744e-05, Final Batch Loss: 4.297542545828037e-05\n",
      "Epoch 3814, Loss: 0.0004874729966104496, Final Batch Loss: 0.00045065581798553467\n",
      "Epoch 3815, Loss: 0.0002599151848698966, Final Batch Loss: 0.0001541526144137606\n",
      "Epoch 3816, Loss: 0.0012803063673345605, Final Batch Loss: 0.0012586687225848436\n",
      "Epoch 3817, Loss: 0.024272714275866747, Final Batch Loss: 0.022098084911704063\n",
      "Epoch 3818, Loss: 0.00012730138405459002, Final Batch Loss: 3.090789687121287e-05\n",
      "Epoch 3819, Loss: 0.00011848511712742038, Final Batch Loss: 0.00010846353688975796\n",
      "Epoch 3820, Loss: 0.0003191970281477552, Final Batch Loss: 0.0002686116786208004\n",
      "Epoch 3821, Loss: 0.0007912296714494005, Final Batch Loss: 0.0006516255089081824\n",
      "Epoch 3822, Loss: 0.001966790237929672, Final Batch Loss: 0.00026162591530010104\n",
      "Epoch 3823, Loss: 0.006890238459163811, Final Batch Loss: 8.715662261238322e-05\n",
      "Epoch 3824, Loss: 0.009215070575010031, Final Batch Loss: 0.000730676285456866\n",
      "Epoch 3825, Loss: 0.01143070526450174, Final Batch Loss: 7.669098704354838e-05\n",
      "Epoch 3826, Loss: 0.0025003578048199415, Final Batch Loss: 0.0023633516393601894\n",
      "Epoch 3827, Loss: 0.0023924492415972054, Final Batch Loss: 0.0014924363931640983\n",
      "Epoch 3828, Loss: 0.019403551938012242, Final Batch Loss: 0.016140902414917946\n",
      "Epoch 3829, Loss: 0.028210773307364434, Final Batch Loss: 0.0009310461464338005\n",
      "Epoch 3830, Loss: 0.0023223483294714242, Final Batch Loss: 2.032218617387116e-05\n",
      "Epoch 3831, Loss: 0.0013154233747627586, Final Batch Loss: 0.00041072399471886456\n",
      "Epoch 3832, Loss: 0.00011262746556894854, Final Batch Loss: 4.9497102736495435e-05\n",
      "Epoch 3833, Loss: 0.0016845918726176023, Final Batch Loss: 0.00086918321903795\n",
      "Epoch 3834, Loss: 0.004589072872477118, Final Batch Loss: 8.927888848120347e-05\n",
      "Epoch 3835, Loss: 0.043313510715961456, Final Batch Loss: 0.015450939536094666\n",
      "Epoch 3836, Loss: 8.463036283501424e-05, Final Batch Loss: 4.3305994040565565e-05\n",
      "Epoch 3837, Loss: 0.018643661820533453, Final Batch Loss: 0.018599705770611763\n",
      "Epoch 3838, Loss: 0.05897065810859203, Final Batch Loss: 0.030043819919228554\n",
      "Epoch 3839, Loss: 0.006986437598243356, Final Batch Loss: 0.0038349791429936886\n",
      "Epoch 3840, Loss: 0.00030088465427979827, Final Batch Loss: 6.517412839457393e-05\n",
      "Epoch 3841, Loss: 5.091453704153537e-05, Final Batch Loss: 4.711329438578105e-06\n",
      "Epoch 3842, Loss: 0.004135308132390492, Final Batch Loss: 0.004001286346465349\n",
      "Epoch 3843, Loss: 0.002784934898954816, Final Batch Loss: 0.002575246151536703\n",
      "Epoch 3844, Loss: 0.0221110787242651, Final Batch Loss: 0.02091660164296627\n",
      "Epoch 3845, Loss: 0.00926808244548738, Final Batch Loss: 0.005955906119197607\n",
      "Epoch 3846, Loss: 0.010978145815897733, Final Batch Loss: 0.0001640695263631642\n",
      "Epoch 3847, Loss: 0.002765907085631625, Final Batch Loss: 1.9988156054751016e-05\n",
      "Epoch 3848, Loss: 0.005920272087678313, Final Batch Loss: 0.00381650822237134\n",
      "Epoch 3849, Loss: 0.0006247726378205698, Final Batch Loss: 0.0006076457793824375\n",
      "Epoch 3850, Loss: 7.145654308260418e-05, Final Batch Loss: 2.3574855731567368e-05\n",
      "Epoch 3851, Loss: 5.836256059410516e-05, Final Batch Loss: 8.579789209761657e-06\n",
      "Epoch 3852, Loss: 0.030336602678289637, Final Batch Loss: 0.030084285885095596\n",
      "Epoch 3853, Loss: 0.00019509029516484588, Final Batch Loss: 1.9908606191165745e-05\n",
      "Epoch 3854, Loss: 0.0001598421804374084, Final Batch Loss: 5.667926598107442e-05\n",
      "Epoch 3855, Loss: 0.005214224049268523, Final Batch Loss: 3.328820821479894e-05\n",
      "Epoch 3856, Loss: 9.476975901634432e-05, Final Batch Loss: 3.240801379433833e-05\n",
      "Epoch 3857, Loss: 0.00012087173035979504, Final Batch Loss: 8.166899533534888e-06\n",
      "Epoch 3858, Loss: 0.00016732277072151192, Final Batch Loss: 4.8801415687194094e-05\n",
      "Epoch 3859, Loss: 0.0010730589274317026, Final Batch Loss: 0.0006053586839698255\n",
      "Epoch 3860, Loss: 7.080733848852105e-05, Final Batch Loss: 4.220171467750333e-05\n",
      "Epoch 3861, Loss: 0.0005955433589406312, Final Batch Loss: 0.0002352258306927979\n",
      "Epoch 3862, Loss: 0.0011339957709424198, Final Batch Loss: 0.0007264745654538274\n",
      "Epoch 3863, Loss: 0.0033022176357917488, Final Batch Loss: 0.0008367155096493661\n",
      "Epoch 3864, Loss: 0.00018728766690401244, Final Batch Loss: 5.4912011364649516e-06\n",
      "Epoch 3865, Loss: 0.00013143230171408504, Final Batch Loss: 6.389171903720126e-05\n",
      "Epoch 3866, Loss: 0.00011966892998316325, Final Batch Loss: 9.407983452547342e-05\n",
      "Epoch 3867, Loss: 0.0008659647428430617, Final Batch Loss: 0.0007354099652729928\n",
      "Epoch 3868, Loss: 0.0004848645730817225, Final Batch Loss: 2.2061369236325845e-05\n",
      "Epoch 3869, Loss: 7.451319652318489e-05, Final Batch Loss: 1.8094580809702165e-05\n",
      "Epoch 3870, Loss: 0.0001781364971975563, Final Batch Loss: 0.000165394798386842\n",
      "Epoch 3871, Loss: 0.00071161253072205, Final Batch Loss: 3.8282665627775714e-05\n",
      "Epoch 3872, Loss: 0.0004154219714109786, Final Batch Loss: 0.0003357413806952536\n",
      "Epoch 3873, Loss: 0.0001753948199620936, Final Batch Loss: 1.5543137124041095e-05\n",
      "Epoch 3874, Loss: 0.00022744537636754103, Final Batch Loss: 4.0140137571142986e-05\n",
      "Epoch 3875, Loss: 0.00023667583445785567, Final Batch Loss: 4.332538082962856e-05\n",
      "Epoch 3876, Loss: 0.00029804735095240176, Final Batch Loss: 0.00022877793526276946\n",
      "Epoch 3877, Loss: 0.0006010389552102424, Final Batch Loss: 0.0005644420743919909\n",
      "Epoch 3878, Loss: 6.356873745971825e-05, Final Batch Loss: 2.6929197701974772e-05\n",
      "Epoch 3879, Loss: 0.0027352101169526577, Final Batch Loss: 0.00023997202515602112\n",
      "Epoch 3880, Loss: 0.001049227768817218, Final Batch Loss: 4.373501360532828e-05\n",
      "Epoch 3881, Loss: 0.010301520436769351, Final Batch Loss: 0.009996600449085236\n",
      "Epoch 3882, Loss: 0.006069491246307734, Final Batch Loss: 0.005980208981782198\n",
      "Epoch 3883, Loss: 7.927322621981148e-05, Final Batch Loss: 9.9383632914396e-06\n",
      "Epoch 3884, Loss: 0.00014170893700793386, Final Batch Loss: 8.120903657982126e-05\n",
      "Epoch 3885, Loss: 0.0014890234306221828, Final Batch Loss: 7.881606870796531e-05\n",
      "Epoch 3886, Loss: 0.00010065397509606555, Final Batch Loss: 8.142734441207722e-05\n",
      "Epoch 3887, Loss: 0.00027271379076410085, Final Batch Loss: 0.0001318852009717375\n",
      "Epoch 3888, Loss: 0.00019010140385944396, Final Batch Loss: 6.697447679471225e-05\n",
      "Epoch 3889, Loss: 0.00018914925021817908, Final Batch Loss: 4.31087173637934e-05\n",
      "Epoch 3890, Loss: 0.00014446265413425863, Final Batch Loss: 7.13842673576437e-05\n",
      "Epoch 3891, Loss: 0.0006914106525073294, Final Batch Loss: 4.0954826545203105e-05\n",
      "Epoch 3892, Loss: 8.54681557029835e-05, Final Batch Loss: 1.2892923223262187e-05\n",
      "Epoch 3893, Loss: 0.0039668657882430125, Final Batch Loss: 4.5577256969409063e-05\n",
      "Epoch 3894, Loss: 0.00018039982751361094, Final Batch Loss: 4.789135346072726e-05\n",
      "Epoch 3895, Loss: 0.00034886470530182123, Final Batch Loss: 0.00020219999714754522\n",
      "Epoch 3896, Loss: 0.00012575930304592475, Final Batch Loss: 4.435226583154872e-05\n",
      "Epoch 3897, Loss: 0.0004245820273354184, Final Batch Loss: 5.0717655540211126e-05\n",
      "Epoch 3898, Loss: 0.0004337175269029103, Final Batch Loss: 0.0003306785656604916\n",
      "Epoch 3899, Loss: 0.0003355891130922828, Final Batch Loss: 0.0002952284994535148\n",
      "Epoch 3900, Loss: 0.000261713721556589, Final Batch Loss: 0.00023494964989367872\n",
      "Epoch 3901, Loss: 0.000492537918034941, Final Batch Loss: 0.00028550109709613025\n",
      "Epoch 3902, Loss: 0.00010828553422470577, Final Batch Loss: 2.3781907657394186e-05\n",
      "Epoch 3903, Loss: 0.0007108233330654912, Final Batch Loss: 0.0001086480260710232\n",
      "Epoch 3904, Loss: 0.00014754098083358258, Final Batch Loss: 9.84806683845818e-05\n",
      "Epoch 3905, Loss: 0.0002166379381378647, Final Batch Loss: 0.00015931820962578058\n",
      "Epoch 3906, Loss: 0.00015931018788251095, Final Batch Loss: 9.965302160708234e-05\n",
      "Epoch 3907, Loss: 0.0002655741263879463, Final Batch Loss: 0.00015413206710945815\n",
      "Epoch 3908, Loss: 0.0026682280004024506, Final Batch Loss: 0.0018363171257078648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3909, Loss: 0.0005202806678425986, Final Batch Loss: 3.247907807235606e-05\n",
      "Epoch 3910, Loss: 0.0003195658246113453, Final Batch Loss: 0.00027677288744598627\n",
      "Epoch 3911, Loss: 0.0009574778669048101, Final Batch Loss: 0.0005324211670085788\n",
      "Epoch 3912, Loss: 0.0005684963834937662, Final Batch Loss: 0.0005381668452173471\n",
      "Epoch 3913, Loss: 0.0008277788110717665, Final Batch Loss: 3.8175650843186304e-05\n",
      "Epoch 3914, Loss: 0.0005142778682056814, Final Batch Loss: 0.00015181672642938793\n",
      "Epoch 3915, Loss: 0.000495199101351318, Final Batch Loss: 1.624626929697115e-05\n",
      "Epoch 3916, Loss: 0.0014633942628279328, Final Batch Loss: 0.00039317156188189983\n",
      "Epoch 3917, Loss: 0.0006215761168277822, Final Batch Loss: 0.0005459263920783997\n",
      "Epoch 3918, Loss: 0.006013946607708931, Final Batch Loss: 0.0036205360665917397\n",
      "Epoch 3919, Loss: 0.0006426236977858935, Final Batch Loss: 0.0006167702376842499\n",
      "Epoch 3920, Loss: 0.00038492643216159195, Final Batch Loss: 0.00023608685296494514\n",
      "Epoch 3921, Loss: 0.00011262379121035337, Final Batch Loss: 1.8337203073315322e-05\n",
      "Epoch 3922, Loss: 7.938755879877135e-05, Final Batch Loss: 5.500824408954941e-05\n",
      "Epoch 3923, Loss: 0.00016246929590124637, Final Batch Loss: 9.627789404476061e-05\n",
      "Epoch 3924, Loss: 0.0006866089825052768, Final Batch Loss: 7.706144242547452e-05\n",
      "Epoch 3925, Loss: 8.977728430181742e-05, Final Batch Loss: 4.575137427309528e-05\n",
      "Epoch 3926, Loss: 0.00017189651407534257, Final Batch Loss: 0.00012462178710848093\n",
      "Epoch 3927, Loss: 0.0010082952358061448, Final Batch Loss: 0.0008924308349378407\n",
      "Epoch 3928, Loss: 8.249639358837157e-05, Final Batch Loss: 3.875934271491133e-05\n",
      "Epoch 3929, Loss: 0.00012659983894991456, Final Batch Loss: 0.00011362353689037263\n",
      "Epoch 3930, Loss: 0.00021338777150958776, Final Batch Loss: 7.946301775518805e-05\n",
      "Epoch 3931, Loss: 8.479037569486536e-05, Final Batch Loss: 5.30856050318107e-05\n",
      "Epoch 3932, Loss: 0.00030805659480392933, Final Batch Loss: 0.00013873139687348157\n",
      "Epoch 3933, Loss: 0.00013651968947669957, Final Batch Loss: 0.00012142209016019478\n",
      "Epoch 3934, Loss: 0.0007700648147874745, Final Batch Loss: 1.6508261978742667e-05\n",
      "Epoch 3935, Loss: 0.00036630124213843374, Final Batch Loss: 1.1852093848574441e-05\n",
      "Epoch 3936, Loss: 8.746638923184946e-05, Final Batch Loss: 6.083890548325144e-05\n",
      "Epoch 3937, Loss: 7.38589842512738e-05, Final Batch Loss: 2.102800499415025e-05\n",
      "Epoch 3938, Loss: 8.240655370173045e-05, Final Batch Loss: 2.0970033801859245e-05\n",
      "Epoch 3939, Loss: 0.000221665812205174, Final Batch Loss: 1.53648234118009e-05\n",
      "Epoch 3940, Loss: 0.000853510748129338, Final Batch Loss: 0.0006109336391091347\n",
      "Epoch 3941, Loss: 0.001072640816346393, Final Batch Loss: 0.0010614845668897033\n",
      "Epoch 3942, Loss: 3.9269976696232334e-05, Final Batch Loss: 2.1637926693074405e-05\n",
      "Epoch 3943, Loss: 0.00023954768403200433, Final Batch Loss: 9.998029418056831e-05\n",
      "Epoch 3944, Loss: 0.00021770791499875486, Final Batch Loss: 7.908463885542005e-05\n",
      "Epoch 3945, Loss: 0.000635947854789265, Final Batch Loss: 0.0006232502055354416\n",
      "Epoch 3946, Loss: 9.010337726067519e-05, Final Batch Loss: 1.1459479537734296e-05\n",
      "Epoch 3947, Loss: 0.0019582735985750332, Final Batch Loss: 0.00020842849335167557\n",
      "Epoch 3948, Loss: 0.002302909502759576, Final Batch Loss: 4.071393050253391e-05\n",
      "Epoch 3949, Loss: 0.0001669041121203918, Final Batch Loss: 3.250030931667425e-05\n",
      "Epoch 3950, Loss: 0.0003400918303668732, Final Batch Loss: 1.9140783479087986e-05\n",
      "Epoch 3951, Loss: 0.0013914526152802864, Final Batch Loss: 0.0013678513932973146\n",
      "Epoch 3952, Loss: 0.0007850246765883639, Final Batch Loss: 0.00010385505447629839\n",
      "Epoch 3953, Loss: 0.00024061180238277302, Final Batch Loss: 5.036536549596349e-06\n",
      "Epoch 3954, Loss: 0.000139021452923771, Final Batch Loss: 6.622901128139347e-05\n",
      "Epoch 3955, Loss: 0.0003095053252764046, Final Batch Loss: 0.00022330897627398372\n",
      "Epoch 3956, Loss: 0.00011099950643256307, Final Batch Loss: 2.949440386146307e-05\n",
      "Epoch 3957, Loss: 0.00034700558899203315, Final Batch Loss: 0.0003156668972223997\n",
      "Epoch 3958, Loss: 0.0010236782545689493, Final Batch Loss: 0.0004136066709179431\n",
      "Epoch 3959, Loss: 0.00011016785174433608, Final Batch Loss: 8.510056431987323e-06\n",
      "Epoch 3960, Loss: 0.00020118564134463668, Final Batch Loss: 3.037464921362698e-05\n",
      "Epoch 3961, Loss: 0.0004653862451959867, Final Batch Loss: 3.5538123484002426e-05\n",
      "Epoch 3962, Loss: 0.00015992488260963, Final Batch Loss: 5.5036831327015534e-05\n",
      "Epoch 3963, Loss: 0.0012522084434749559, Final Batch Loss: 2.637792204041034e-05\n",
      "Epoch 3964, Loss: 0.0003645027263701195, Final Batch Loss: 0.0003470488009043038\n",
      "Epoch 3965, Loss: 0.0027685528875736054, Final Batch Loss: 0.0027207150124013424\n",
      "Epoch 3966, Loss: 0.011928732797969133, Final Batch Loss: 0.011777997948229313\n",
      "Epoch 3967, Loss: 0.0004476885369513184, Final Batch Loss: 0.00022075451852288097\n",
      "Epoch 3968, Loss: 0.0003460403604549356, Final Batch Loss: 5.049040919402614e-05\n",
      "Epoch 3969, Loss: 0.00016027021229092497, Final Batch Loss: 0.00013475908781401813\n",
      "Epoch 3970, Loss: 0.0002378228928137105, Final Batch Loss: 4.466961763682775e-05\n",
      "Epoch 3971, Loss: 0.0019972877598775085, Final Batch Loss: 0.0019523698138073087\n",
      "Epoch 3972, Loss: 0.00024098420544760302, Final Batch Loss: 9.829620103118941e-05\n",
      "Epoch 3973, Loss: 0.000195910519323661, Final Batch Loss: 2.356636650802102e-05\n",
      "Epoch 3974, Loss: 0.0001270052744075656, Final Batch Loss: 2.767556725302711e-05\n",
      "Epoch 3975, Loss: 0.0004274509774404578, Final Batch Loss: 0.0003096172004006803\n",
      "Epoch 3976, Loss: 0.0003274484697612934, Final Batch Loss: 0.000215867068618536\n",
      "Epoch 3977, Loss: 0.00046218166971812025, Final Batch Loss: 0.00040919805178418756\n",
      "Epoch 3978, Loss: 0.00037250729474180844, Final Batch Loss: 0.0003507208311930299\n",
      "Epoch 3979, Loss: 0.0018354017520323396, Final Batch Loss: 0.0004330407828092575\n",
      "Epoch 3980, Loss: 0.0007579339362564497, Final Batch Loss: 0.0006910418742336333\n",
      "Epoch 3981, Loss: 6.240004859137116e-05, Final Batch Loss: 1.4050830031919759e-05\n",
      "Epoch 3982, Loss: 0.00019105033788946457, Final Batch Loss: 2.834288534359075e-05\n",
      "Epoch 3983, Loss: 4.6938358536863234e-05, Final Batch Loss: 3.376236418262124e-05\n",
      "Epoch 3984, Loss: 0.00014792361253057607, Final Batch Loss: 0.00011119808914372697\n",
      "Epoch 3985, Loss: 0.00021984051090839785, Final Batch Loss: 1.3274982848088257e-05\n",
      "Epoch 3986, Loss: 0.002306913309439551, Final Batch Loss: 0.00011561001156223938\n",
      "Epoch 3987, Loss: 3.9320004361798055e-05, Final Batch Loss: 2.6777903258334845e-05\n",
      "Epoch 3988, Loss: 0.00020299295283621177, Final Batch Loss: 0.00016768404748290777\n",
      "Epoch 3989, Loss: 0.0051836171332979575, Final Batch Loss: 0.00016505784878972918\n",
      "Epoch 3990, Loss: 0.0005308863237587502, Final Batch Loss: 8.54841164255049e-06\n",
      "Epoch 3991, Loss: 0.0007097018824424595, Final Batch Loss: 0.0002897639642469585\n",
      "Epoch 3992, Loss: 0.00012358893582131714, Final Batch Loss: 1.2803153367713094e-05\n",
      "Epoch 3993, Loss: 0.0003856403454847168, Final Batch Loss: 2.7072568627772853e-05\n",
      "Epoch 3994, Loss: 0.0019024523717234842, Final Batch Loss: 3.395490784896538e-05\n",
      "Epoch 3995, Loss: 0.0006724826816935092, Final Batch Loss: 0.0001697697734925896\n",
      "Epoch 3996, Loss: 0.00048777573465486057, Final Batch Loss: 0.000448988372227177\n",
      "Epoch 3997, Loss: 0.00015596463526890147, Final Batch Loss: 2.6737719963421114e-05\n",
      "Epoch 3998, Loss: 0.0001965476549230516, Final Batch Loss: 0.00012401293497532606\n",
      "Epoch 3999, Loss: 0.00023628917188034393, Final Batch Loss: 0.00018656070460565388\n",
      "Epoch 4000, Loss: 0.0002310300787939923, Final Batch Loss: 1.912082552735228e-05\n",
      "Epoch 4001, Loss: 0.0018732779863057658, Final Batch Loss: 9.504977788310498e-05\n",
      "Epoch 4002, Loss: 9.172702084470075e-05, Final Batch Loss: 6.436714465962723e-05\n",
      "Epoch 4003, Loss: 0.00032714691769797355, Final Batch Loss: 0.00023176209651865065\n",
      "Epoch 4004, Loss: 0.00014450442358793225, Final Batch Loss: 1.641359085624572e-05\n",
      "Epoch 4005, Loss: 9.881672121991869e-05, Final Batch Loss: 1.1007772627635859e-05\n",
      "Epoch 4006, Loss: 7.87975932325935e-05, Final Batch Loss: 1.25606147776125e-05\n",
      "Epoch 4007, Loss: 0.00013749139361607376, Final Batch Loss: 1.6362982933060266e-05\n",
      "Epoch 4008, Loss: 0.002733048651862191, Final Batch Loss: 0.002708620857447386\n",
      "Epoch 4009, Loss: 0.00015018715885162237, Final Batch Loss: 0.00014412167365662754\n",
      "Epoch 4010, Loss: 0.00020558353025990073, Final Batch Loss: 0.00018391828052699566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4011, Loss: 0.0009408436599187553, Final Batch Loss: 0.00013046810636296868\n",
      "Epoch 4012, Loss: 0.0002112356887664646, Final Batch Loss: 4.2712781578302383e-05\n",
      "Epoch 4013, Loss: 7.993654435267672e-05, Final Batch Loss: 4.4268999772612005e-05\n",
      "Epoch 4014, Loss: 0.001062030169123318, Final Batch Loss: 6.768813909729943e-05\n",
      "Epoch 4015, Loss: 0.0022192416254256386, Final Batch Loss: 4.563136099022813e-05\n",
      "Epoch 4016, Loss: 0.0018988353403983638, Final Batch Loss: 0.0018633533036336303\n",
      "Epoch 4017, Loss: 0.0023535026048193686, Final Batch Loss: 0.0023216817062348127\n",
      "Epoch 4018, Loss: 0.00015226869072648697, Final Batch Loss: 0.00010733956150943413\n",
      "Epoch 4019, Loss: 0.000494509789859876, Final Batch Loss: 0.00031670284806750715\n",
      "Epoch 4020, Loss: 0.0003345523646203219, Final Batch Loss: 1.2765892279276159e-05\n",
      "Epoch 4021, Loss: 0.0002015970130742062, Final Batch Loss: 4.348096626927145e-05\n",
      "Epoch 4022, Loss: 0.00017855813348433003, Final Batch Loss: 4.636433004634455e-05\n",
      "Epoch 4023, Loss: 0.00020775636221515015, Final Batch Loss: 6.0655314882751554e-05\n",
      "Epoch 4024, Loss: 0.001107352291001007, Final Batch Loss: 0.0008578065317124128\n",
      "Epoch 4025, Loss: 0.0005263073981041089, Final Batch Loss: 0.0004188228340353817\n",
      "Epoch 4026, Loss: 0.0001864506757556228, Final Batch Loss: 1.30158423417015e-05\n",
      "Epoch 4027, Loss: 0.0008072205237112939, Final Batch Loss: 0.0007421671180054545\n",
      "Epoch 4028, Loss: 0.00014867334903101437, Final Batch Loss: 4.360785169410519e-05\n",
      "Epoch 4029, Loss: 7.375631594186416e-05, Final Batch Loss: 6.132733687991276e-05\n",
      "Epoch 4030, Loss: 9.94496513158083e-05, Final Batch Loss: 4.4682623411063105e-05\n",
      "Epoch 4031, Loss: 0.00024773726545390673, Final Batch Loss: 2.7046513423556462e-05\n",
      "Epoch 4032, Loss: 0.00014482407641480677, Final Batch Loss: 9.361505362903699e-05\n",
      "Epoch 4033, Loss: 0.0019935599266318604, Final Batch Loss: 0.00013450002006720752\n",
      "Epoch 4034, Loss: 0.0003711857134476304, Final Batch Loss: 0.00016166907153092325\n",
      "Epoch 4035, Loss: 0.00010933294834103435, Final Batch Loss: 6.928586662979797e-05\n",
      "Epoch 4036, Loss: 0.0002979119344672654, Final Batch Loss: 5.923479693592526e-05\n",
      "Epoch 4037, Loss: 0.0006315527352853678, Final Batch Loss: 6.4161627960857e-05\n",
      "Epoch 4038, Loss: 0.0001367471659250441, Final Batch Loss: 1.039767357724486e-05\n",
      "Epoch 4039, Loss: 8.3162678492954e-05, Final Batch Loss: 7.88884426583536e-06\n",
      "Epoch 4040, Loss: 0.0010552024104981683, Final Batch Loss: 0.0010183985577896237\n",
      "Epoch 4041, Loss: 0.0006307677540462464, Final Batch Loss: 0.000608769478276372\n",
      "Epoch 4042, Loss: 0.000135747346575954, Final Batch Loss: 2.4612427296233363e-05\n",
      "Epoch 4043, Loss: 0.0002464618082740344, Final Batch Loss: 0.00018925331823993474\n",
      "Epoch 4044, Loss: 0.00020104772556805983, Final Batch Loss: 0.00016107426199596375\n",
      "Epoch 4045, Loss: 0.0007308341409952845, Final Batch Loss: 0.0006904496694914997\n",
      "Epoch 4046, Loss: 7.858919343561865e-05, Final Batch Loss: 4.464311132323928e-05\n",
      "Epoch 4047, Loss: 0.00020284041238483042, Final Batch Loss: 0.00012632562720682472\n",
      "Epoch 4048, Loss: 0.000608603106229566, Final Batch Loss: 0.00047273826203309\n",
      "Epoch 4049, Loss: 1.3554977158491965e-05, Final Batch Loss: 6.5113999880850315e-06\n",
      "Epoch 4050, Loss: 4.264920971763786e-05, Final Batch Loss: 2.0092717022635043e-05\n",
      "Epoch 4051, Loss: 7.394756357825827e-05, Final Batch Loss: 1.724329740682151e-05\n",
      "Epoch 4052, Loss: 7.316857409023214e-05, Final Batch Loss: 4.600563261192292e-05\n",
      "Epoch 4053, Loss: 0.00016917130778892897, Final Batch Loss: 0.0001250774075742811\n",
      "Epoch 4054, Loss: 0.00015236075523716863, Final Batch Loss: 2.612674688862171e-05\n",
      "Epoch 4055, Loss: 0.00019104540115222335, Final Batch Loss: 0.00011988869664492086\n",
      "Epoch 4056, Loss: 9.340618089481723e-05, Final Batch Loss: 2.1985526473145e-05\n",
      "Epoch 4057, Loss: 3.478721919236705e-05, Final Batch Loss: 1.7796071915654466e-05\n",
      "Epoch 4058, Loss: 0.001761126499332022, Final Batch Loss: 0.001661038724705577\n",
      "Epoch 4059, Loss: 9.706426135380752e-05, Final Batch Loss: 5.0153248594142497e-05\n",
      "Epoch 4060, Loss: 0.0002532118269300554, Final Batch Loss: 0.00021032772201579064\n",
      "Epoch 4061, Loss: 0.0002943696017609909, Final Batch Loss: 0.00013558694627135992\n",
      "Epoch 4062, Loss: 0.00016316592154907994, Final Batch Loss: 5.7430766901234165e-05\n",
      "Epoch 4063, Loss: 0.0003260332450736314, Final Batch Loss: 5.882175173610449e-05\n",
      "Epoch 4064, Loss: 4.720079232356511e-05, Final Batch Loss: 1.7505697542219423e-05\n",
      "Epoch 4065, Loss: 0.0004112220376555342, Final Batch Loss: 6.0725626099156216e-05\n",
      "Epoch 4066, Loss: 5.615744703391101e-05, Final Batch Loss: 2.513453182473313e-05\n",
      "Epoch 4067, Loss: 0.0003311587279313244, Final Batch Loss: 8.227743819588795e-05\n",
      "Epoch 4068, Loss: 6.818684505560668e-05, Final Batch Loss: 1.1034390809072647e-05\n",
      "Epoch 4069, Loss: 4.624132452590857e-05, Final Batch Loss: 6.957126970519312e-06\n",
      "Epoch 4070, Loss: 4.0327414353669155e-05, Final Batch Loss: 2.7692145522451028e-05\n",
      "Epoch 4071, Loss: 2.3370903818431543e-05, Final Batch Loss: 5.994811090204166e-06\n",
      "Epoch 4072, Loss: 3.3940984394575935e-05, Final Batch Loss: 2.3130343834054656e-05\n",
      "Epoch 4073, Loss: 0.0001571724860696122, Final Batch Loss: 0.00012195319141028449\n",
      "Epoch 4074, Loss: 0.00031854510598350316, Final Batch Loss: 9.042069723363966e-05\n",
      "Epoch 4075, Loss: 0.00018627545068738982, Final Batch Loss: 0.0001630378101253882\n",
      "Epoch 4076, Loss: 7.814033597242087e-05, Final Batch Loss: 2.305394082213752e-05\n",
      "Epoch 4077, Loss: 7.951859697641339e-05, Final Batch Loss: 5.020587195758708e-05\n",
      "Epoch 4078, Loss: 6.564808973053005e-05, Final Batch Loss: 3.6518980778055266e-05\n",
      "Epoch 4079, Loss: 3.461262849668856e-05, Final Batch Loss: 4.3643372009682935e-06\n",
      "Epoch 4080, Loss: 0.00018171610645367764, Final Batch Loss: 0.00014035470667295158\n",
      "Epoch 4081, Loss: 0.00011210749926249264, Final Batch Loss: 9.72770340013085e-06\n",
      "Epoch 4082, Loss: 0.0003878070538121392, Final Batch Loss: 1.3557871170633007e-05\n",
      "Epoch 4083, Loss: 0.00013387076342041837, Final Batch Loss: 8.00321595306741e-06\n",
      "Epoch 4084, Loss: 0.0004358020632935222, Final Batch Loss: 0.00038440251955762506\n",
      "Epoch 4085, Loss: 0.0004098023191545508, Final Batch Loss: 9.293594303017017e-06\n",
      "Epoch 4086, Loss: 6.514659980894066e-05, Final Batch Loss: 1.795241769286804e-05\n",
      "Epoch 4087, Loss: 0.0003230611050639709, Final Batch Loss: 5.1596448429336306e-06\n",
      "Epoch 4088, Loss: 2.2614884983340744e-05, Final Batch Loss: 1.8019314666162245e-05\n",
      "Epoch 4089, Loss: 0.00010725968058977742, Final Batch Loss: 7.888453546911478e-05\n",
      "Epoch 4090, Loss: 7.330074413403054e-05, Final Batch Loss: 6.687254062853754e-05\n",
      "Epoch 4091, Loss: 0.0009273612540710019, Final Batch Loss: 0.0009026039624586701\n",
      "Epoch 4092, Loss: 0.00018147237278753892, Final Batch Loss: 6.689476867904887e-05\n",
      "Epoch 4093, Loss: 0.00021298805586411618, Final Batch Loss: 0.00017492304323241115\n",
      "Epoch 4094, Loss: 0.000269904518063413, Final Batch Loss: 4.0243499825010076e-05\n",
      "Epoch 4095, Loss: 0.0002464972494635731, Final Batch Loss: 0.00013010346447117627\n",
      "Epoch 4096, Loss: 0.00014169470887281932, Final Batch Loss: 9.481180313741788e-05\n",
      "Epoch 4097, Loss: 0.004980509540473577, Final Batch Loss: 0.004961761180311441\n",
      "Epoch 4098, Loss: 0.0002987668922287412, Final Batch Loss: 0.00022759691637475044\n",
      "Epoch 4099, Loss: 0.000670971585350344, Final Batch Loss: 3.8088801375124604e-06\n",
      "Epoch 4100, Loss: 0.000191426785022486, Final Batch Loss: 8.10791170806624e-05\n",
      "Epoch 4101, Loss: 0.00010513903180253692, Final Batch Loss: 4.824507414014079e-05\n",
      "Epoch 4102, Loss: 4.5701217459281906e-05, Final Batch Loss: 3.8009155105100945e-05\n",
      "Epoch 4103, Loss: 0.0003358247304277029, Final Batch Loss: 4.160223397775553e-05\n",
      "Epoch 4104, Loss: 0.00018812649523169966, Final Batch Loss: 4.069214810442645e-06\n",
      "Epoch 4105, Loss: 0.00016762258019298315, Final Batch Loss: 8.886501746019349e-05\n",
      "Epoch 4106, Loss: 4.1956440327339806e-05, Final Batch Loss: 1.8282386008650064e-05\n",
      "Epoch 4107, Loss: 0.000151700320202508, Final Batch Loss: 0.00013474657316692173\n",
      "Epoch 4108, Loss: 0.0003896626440109685, Final Batch Loss: 0.0003217711637262255\n",
      "Epoch 4109, Loss: 0.00019384745246497914, Final Batch Loss: 2.663057966856286e-05\n",
      "Epoch 4110, Loss: 3.251396810810547e-05, Final Batch Loss: 1.7846021364675835e-05\n",
      "Epoch 4111, Loss: 0.00011850062583107501, Final Batch Loss: 7.756989361951128e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4112, Loss: 0.00010295233732904308, Final Batch Loss: 7.475981692550704e-05\n",
      "Epoch 4113, Loss: 5.9116098782396875e-05, Final Batch Loss: 1.70571784110507e-05\n",
      "Epoch 4114, Loss: 0.0001565147740620887, Final Batch Loss: 9.463887181482278e-06\n",
      "Epoch 4115, Loss: 0.0002500098416930996, Final Batch Loss: 0.00018909019127022475\n",
      "Epoch 4116, Loss: 0.00011575773169170134, Final Batch Loss: 2.4616132577648386e-05\n",
      "Epoch 4117, Loss: 2.4605791622889228e-05, Final Batch Loss: 1.1364431884430815e-05\n",
      "Epoch 4118, Loss: 0.00011560614257177804, Final Batch Loss: 2.7570154998102225e-05\n",
      "Epoch 4119, Loss: 6.323235356830992e-05, Final Batch Loss: 3.1714047509012744e-05\n",
      "Epoch 4120, Loss: 9.307755499321502e-05, Final Batch Loss: 1.8380413166596554e-05\n",
      "Epoch 4121, Loss: 0.0016145900190167595, Final Batch Loss: 0.0015576574951410294\n",
      "Epoch 4122, Loss: 0.00035809192195301875, Final Batch Loss: 5.183292523724958e-05\n",
      "Epoch 4123, Loss: 0.00204799413040746, Final Batch Loss: 0.0018212773138657212\n",
      "Epoch 4124, Loss: 0.0015162874769885093, Final Batch Loss: 0.00027924394817091525\n",
      "Epoch 4125, Loss: 0.0014902016046107747, Final Batch Loss: 0.0013868556125089526\n",
      "Epoch 4126, Loss: 6.22057978034718e-05, Final Batch Loss: 2.4469709387631156e-05\n",
      "Epoch 4127, Loss: 0.0013288680383993778, Final Batch Loss: 3.3482156140962616e-05\n",
      "Epoch 4128, Loss: 0.00017287622540607117, Final Batch Loss: 0.0001604168355697766\n",
      "Epoch 4129, Loss: 3.427949468459701e-05, Final Batch Loss: 1.1523473403940443e-05\n",
      "Epoch 4130, Loss: 0.00010738627315731719, Final Batch Loss: 2.281325578223914e-05\n",
      "Epoch 4131, Loss: 6.863292583147995e-05, Final Batch Loss: 2.4771459720795974e-05\n",
      "Epoch 4132, Loss: 0.00014481037942459807, Final Batch Loss: 0.0001383523631375283\n",
      "Epoch 4133, Loss: 6.821935312473215e-05, Final Batch Loss: 3.187609763699584e-05\n",
      "Epoch 4134, Loss: 2.908738133555744e-05, Final Batch Loss: 1.6472004062961787e-05\n",
      "Epoch 4135, Loss: 0.0004888711482635699, Final Batch Loss: 0.00010537436901358888\n",
      "Epoch 4136, Loss: 0.00023921834144857712, Final Batch Loss: 4.214584259898402e-05\n",
      "Epoch 4137, Loss: 0.0033122196546173654, Final Batch Loss: 0.003257055301219225\n",
      "Epoch 4138, Loss: 0.00032893905881792307, Final Batch Loss: 0.0001567842991789803\n",
      "Epoch 4139, Loss: 5.580308697972214e-05, Final Batch Loss: 1.2587238416017499e-05\n",
      "Epoch 4140, Loss: 0.0011732281782315113, Final Batch Loss: 2.1581225155387074e-05\n",
      "Epoch 4141, Loss: 7.012057540123351e-05, Final Batch Loss: 5.407662320067175e-05\n",
      "Epoch 4142, Loss: 7.985418415046297e-05, Final Batch Loss: 4.099708530702628e-05\n",
      "Epoch 4143, Loss: 0.00016402308210672345, Final Batch Loss: 1.641241215111222e-05\n",
      "Epoch 4144, Loss: 8.036635699681938e-05, Final Batch Loss: 3.5765788197750226e-05\n",
      "Epoch 4145, Loss: 0.00023411918846250046, Final Batch Loss: 8.431730748270638e-06\n",
      "Epoch 4146, Loss: 0.000220007925236132, Final Batch Loss: 0.00013675508671440184\n",
      "Epoch 4147, Loss: 8.741306919546332e-05, Final Batch Loss: 9.345121725345962e-06\n",
      "Epoch 4148, Loss: 7.082155752868857e-05, Final Batch Loss: 2.445730751787778e-05\n",
      "Epoch 4149, Loss: 7.901528260845225e-05, Final Batch Loss: 5.8157078456133604e-05\n",
      "Epoch 4150, Loss: 0.00026811366842594, Final Batch Loss: 6.294056947808713e-05\n",
      "Epoch 4151, Loss: 0.0003619094695750391, Final Batch Loss: 8.194698239094578e-06\n",
      "Epoch 4152, Loss: 3.790818027482601e-05, Final Batch Loss: 2.864094676624518e-05\n",
      "Epoch 4153, Loss: 7.245145116030471e-05, Final Batch Loss: 9.795022378966678e-06\n",
      "Epoch 4154, Loss: 0.0004022176581202075, Final Batch Loss: 1.9049752154387534e-05\n",
      "Epoch 4155, Loss: 0.0001128335643443279, Final Batch Loss: 4.559577791951597e-05\n",
      "Epoch 4156, Loss: 6.670288166787941e-05, Final Batch Loss: 2.816562664520461e-05\n",
      "Epoch 4157, Loss: 4.533588798949495e-05, Final Batch Loss: 4.898633051197976e-06\n",
      "Epoch 4158, Loss: 8.88926770130638e-05, Final Batch Loss: 5.848443470313214e-05\n",
      "Epoch 4159, Loss: 0.00040219661605078727, Final Batch Loss: 0.00033361060195602477\n",
      "Epoch 4160, Loss: 2.1290843505994417e-05, Final Batch Loss: 1.2448293091438245e-05\n",
      "Epoch 4161, Loss: 0.000651444643153809, Final Batch Loss: 0.00013131576997693628\n",
      "Epoch 4162, Loss: 0.00011467977401480312, Final Batch Loss: 4.842725502385292e-06\n",
      "Epoch 4163, Loss: 0.009235686313331826, Final Batch Loss: 0.00920348521322012\n",
      "Epoch 4164, Loss: 0.0001337498688371852, Final Batch Loss: 1.0757503332570195e-05\n",
      "Epoch 4165, Loss: 0.0005565863148149219, Final Batch Loss: 1.0779539479699451e-05\n",
      "Epoch 4166, Loss: 0.00016576759662711993, Final Batch Loss: 8.520430856151506e-05\n",
      "Epoch 4167, Loss: 0.00048176558630075306, Final Batch Loss: 8.509542385581881e-05\n",
      "Epoch 4168, Loss: 0.00011512207129271701, Final Batch Loss: 0.00010527895938139409\n",
      "Epoch 4169, Loss: 3.946528704545926e-05, Final Batch Loss: 1.0225499863736331e-05\n",
      "Epoch 4170, Loss: 0.0001858146206359379, Final Batch Loss: 5.582279845839366e-05\n",
      "Epoch 4171, Loss: 4.008156247437e-05, Final Batch Loss: 1.647913632041309e-05\n",
      "Epoch 4172, Loss: 0.00041554903145879507, Final Batch Loss: 0.00025331886718049645\n",
      "Epoch 4173, Loss: 0.0004654882213799283, Final Batch Loss: 0.00015732516476418823\n",
      "Epoch 4174, Loss: 8.891127436072566e-05, Final Batch Loss: 3.112606282229535e-05\n",
      "Epoch 4175, Loss: 2.8712887797155418e-05, Final Batch Loss: 2.3098369638319127e-05\n",
      "Epoch 4176, Loss: 5.708105527446605e-05, Final Batch Loss: 1.9956267351517454e-05\n",
      "Epoch 4177, Loss: 0.0005119602719787508, Final Batch Loss: 0.0003993768186774105\n",
      "Epoch 4178, Loss: 0.0006699384757666849, Final Batch Loss: 0.0006221424555405974\n",
      "Epoch 4179, Loss: 4.280091525288299e-05, Final Batch Loss: 2.6843454179470427e-05\n",
      "Epoch 4180, Loss: 0.0020747760063386522, Final Batch Loss: 8.199715375667438e-05\n",
      "Epoch 4181, Loss: 6.121412570792018e-05, Final Batch Loss: 4.845965122513007e-06\n",
      "Epoch 4182, Loss: 4.091097343916772e-05, Final Batch Loss: 8.057383638515603e-06\n",
      "Epoch 4183, Loss: 0.0004725401886389591, Final Batch Loss: 1.6724785382393748e-05\n",
      "Epoch 4184, Loss: 0.0001778252303665795, Final Batch Loss: 4.589787295117276e-06\n",
      "Epoch 4185, Loss: 0.000204129209578241, Final Batch Loss: 5.356785095500527e-06\n",
      "Epoch 4186, Loss: 3.075215454373392e-05, Final Batch Loss: 2.745921301539056e-05\n",
      "Epoch 4187, Loss: 0.00022877002993482165, Final Batch Loss: 3.619395647547208e-05\n",
      "Epoch 4188, Loss: 0.0009470688128203619, Final Batch Loss: 0.0009136857697740197\n",
      "Epoch 4189, Loss: 4.465265647013439e-05, Final Batch Loss: 3.5791646951111034e-05\n",
      "Epoch 4190, Loss: 0.0010278190020471811, Final Batch Loss: 0.0005230807582847774\n",
      "Epoch 4191, Loss: 0.00011214544792892411, Final Batch Loss: 1.703463203739375e-05\n",
      "Epoch 4192, Loss: 0.0002480174589436501, Final Batch Loss: 3.1190531444735825e-05\n",
      "Epoch 4193, Loss: 0.0001437789833289571, Final Batch Loss: 5.908227467443794e-05\n",
      "Epoch 4194, Loss: 0.00010133836622117087, Final Batch Loss: 3.900431329384446e-05\n",
      "Epoch 4195, Loss: 2.8842196115874685e-05, Final Batch Loss: 6.965392458369024e-06\n",
      "Epoch 4196, Loss: 0.00018046320110443048, Final Batch Loss: 3.603826553444378e-05\n",
      "Epoch 4197, Loss: 0.0001721480439300649, Final Batch Loss: 0.00010818887676578015\n",
      "Epoch 4198, Loss: 6.620639032917097e-05, Final Batch Loss: 3.8352402043528855e-05\n",
      "Epoch 4199, Loss: 8.357740080100484e-05, Final Batch Loss: 4.857651947531849e-05\n",
      "Epoch 4200, Loss: 9.691798186395317e-05, Final Batch Loss: 4.3229163566138595e-05\n",
      "Epoch 4201, Loss: 7.759714117128169e-05, Final Batch Loss: 1.2831506865040865e-05\n",
      "Epoch 4202, Loss: 0.00040174328751163557, Final Batch Loss: 0.0003152536228299141\n",
      "Epoch 4203, Loss: 6.3608239088353e-05, Final Batch Loss: 5.034015430283034e-06\n",
      "Epoch 4204, Loss: 3.652147006505402e-05, Final Batch Loss: 1.1593100680329371e-05\n",
      "Epoch 4205, Loss: 0.00014986338283051737, Final Batch Loss: 2.221891554654576e-05\n",
      "Epoch 4206, Loss: 0.0012642235960811377, Final Batch Loss: 0.0005455458303913474\n",
      "Epoch 4207, Loss: 6.303382906480692e-05, Final Batch Loss: 4.497327608987689e-06\n",
      "Epoch 4208, Loss: 9.98959512799047e-06, Final Batch Loss: 3.956468390242662e-06\n",
      "Epoch 4209, Loss: 0.0007306080406124238, Final Batch Loss: 0.0007127004791982472\n",
      "Epoch 4210, Loss: 0.00010363512319599977, Final Batch Loss: 9.560511534800753e-05\n",
      "Epoch 4211, Loss: 0.0015039289528431254, Final Batch Loss: 1.3051710084255319e-05\n",
      "Epoch 4212, Loss: 0.00014297376856120536, Final Batch Loss: 1.3754012798017357e-05\n",
      "Epoch 4213, Loss: 0.00021491035658982582, Final Batch Loss: 0.0001577666844241321\n",
      "Epoch 4214, Loss: 6.511371066153515e-05, Final Batch Loss: 4.382456245366484e-05\n",
      "Epoch 4215, Loss: 0.00010259998816763982, Final Batch Loss: 6.284215487539768e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4216, Loss: 0.0005370544822653756, Final Batch Loss: 0.00030185197829268873\n",
      "Epoch 4217, Loss: 0.0007924618548713624, Final Batch Loss: 0.0003069742233492434\n",
      "Epoch 4218, Loss: 0.00010212926508756937, Final Batch Loss: 9.597667667549103e-05\n",
      "Epoch 4219, Loss: 0.00012809801955881994, Final Batch Loss: 0.00011212631216039881\n",
      "Epoch 4220, Loss: 0.0009917632523865905, Final Batch Loss: 0.0009342519333586097\n",
      "Epoch 4221, Loss: 0.00011789659401983954, Final Batch Loss: 4.444110891199671e-05\n",
      "Epoch 4222, Loss: 4.573265141516458e-05, Final Batch Loss: 1.8429700503475033e-05\n",
      "Epoch 4223, Loss: 0.00039182030195661355, Final Batch Loss: 1.7496991858934052e-05\n",
      "Epoch 4224, Loss: 0.000186215014764457, Final Batch Loss: 1.6522308214916848e-05\n",
      "Epoch 4225, Loss: 0.00018964217815664597, Final Batch Loss: 0.00014310941332951188\n",
      "Epoch 4226, Loss: 2.6936652830045205e-05, Final Batch Loss: 8.651454663777258e-06\n",
      "Epoch 4227, Loss: 5.225659333518706e-05, Final Batch Loss: 1.317711576120928e-05\n",
      "Epoch 4228, Loss: 0.00020327960919530597, Final Batch Loss: 0.0001940886868396774\n",
      "Epoch 4229, Loss: 6.05187028668297e-05, Final Batch Loss: 7.057381935737794e-06\n",
      "Epoch 4230, Loss: 4.342713714322599e-05, Final Batch Loss: 3.0263711323641473e-06\n",
      "Epoch 4231, Loss: 4.82088644275791e-05, Final Batch Loss: 3.675154584925622e-05\n",
      "Epoch 4232, Loss: 4.092061135452241e-05, Final Batch Loss: 1.1050973625970073e-05\n",
      "Epoch 4233, Loss: 0.0003517467703204602, Final Batch Loss: 0.00011326892126817256\n",
      "Epoch 4234, Loss: 3.277158430137206e-05, Final Batch Loss: 2.4461998691549525e-05\n",
      "Epoch 4235, Loss: 5.1805409384542145e-05, Final Batch Loss: 2.657067852851469e-05\n",
      "Epoch 4236, Loss: 0.0004367893561720848, Final Batch Loss: 9.69998654909432e-06\n",
      "Epoch 4237, Loss: 0.0006819672125857323, Final Batch Loss: 0.00030690012499690056\n",
      "Epoch 4238, Loss: 0.00041618262639531167, Final Batch Loss: 7.3263699960079975e-06\n",
      "Epoch 4239, Loss: 2.5001484573294874e-05, Final Batch Loss: 1.4562780961568933e-05\n",
      "Epoch 4240, Loss: 0.0005038460840296466, Final Batch Loss: 0.0004460700729396194\n",
      "Epoch 4241, Loss: 0.000192409770534141, Final Batch Loss: 3.355898297741078e-05\n",
      "Epoch 4242, Loss: 0.0007339117310039001, Final Batch Loss: 2.9691060262848623e-05\n",
      "Epoch 4243, Loss: 0.001274136428037309, Final Batch Loss: 1.5058971257531084e-05\n",
      "Epoch 4244, Loss: 0.0002468300265263679, Final Batch Loss: 3.6921594528394053e-06\n",
      "Epoch 4245, Loss: 3.5788718378171325e-05, Final Batch Loss: 2.594843681436032e-05\n",
      "Epoch 4246, Loss: 3.8587670132983476e-05, Final Batch Loss: 2.308661350980401e-05\n",
      "Epoch 4247, Loss: 0.00021750052110292017, Final Batch Loss: 0.00016673485515639186\n",
      "Epoch 4248, Loss: 0.00024077219859464094, Final Batch Loss: 0.0001887748803710565\n",
      "Epoch 4249, Loss: 0.0007089149439707398, Final Batch Loss: 9.218620834872127e-05\n",
      "Epoch 4250, Loss: 0.0008917805225792108, Final Batch Loss: 8.446788342553191e-06\n",
      "Epoch 4251, Loss: 0.0004756543021358084, Final Batch Loss: 1.9800219888566062e-05\n",
      "Epoch 4252, Loss: 7.488934716093354e-05, Final Batch Loss: 3.0636882001999766e-05\n",
      "Epoch 4253, Loss: 0.00021068721252959222, Final Batch Loss: 0.00017864217807073146\n",
      "Epoch 4254, Loss: 3.325146144561586e-05, Final Batch Loss: 3.7626618905051146e-06\n",
      "Epoch 4255, Loss: 0.00010224282959825359, Final Batch Loss: 4.669666668632999e-05\n",
      "Epoch 4256, Loss: 0.00012211615830892697, Final Batch Loss: 4.4840737245976925e-05\n",
      "Epoch 4257, Loss: 0.00014789923716307385, Final Batch Loss: 1.2482591955631506e-05\n",
      "Epoch 4258, Loss: 0.0010277691326336935, Final Batch Loss: 9.221796062774956e-06\n",
      "Epoch 4259, Loss: 0.00025278003158746287, Final Batch Loss: 1.2638258340302855e-05\n",
      "Epoch 4260, Loss: 0.00032928665314102545, Final Batch Loss: 7.95635933172889e-05\n",
      "Epoch 4261, Loss: 0.0006251744562177919, Final Batch Loss: 8.41206856421195e-05\n",
      "Epoch 4262, Loss: 8.227911348512862e-05, Final Batch Loss: 5.743970177718438e-06\n",
      "Epoch 4263, Loss: 0.0010322635353077203, Final Batch Loss: 0.0009344227146357298\n",
      "Epoch 4264, Loss: 6.51706741336966e-05, Final Batch Loss: 1.1493628335301764e-05\n",
      "Epoch 4265, Loss: 0.0001378274755552411, Final Batch Loss: 1.9987688574474305e-05\n",
      "Epoch 4266, Loss: 0.0006198941628099419, Final Batch Loss: 7.690839993301779e-06\n",
      "Epoch 4267, Loss: 5.1648461521836e-05, Final Batch Loss: 1.0076750186271966e-05\n",
      "Epoch 4268, Loss: 0.0001271866203751415, Final Batch Loss: 5.236925062490627e-05\n",
      "Epoch 4269, Loss: 0.0003016169594047824, Final Batch Loss: 2.072375536954496e-05\n",
      "Epoch 4270, Loss: 0.00012306107782933395, Final Batch Loss: 1.0146008207811974e-05\n",
      "Epoch 4271, Loss: 3.592532902985113e-05, Final Batch Loss: 2.674033385119401e-05\n",
      "Epoch 4272, Loss: 9.756684085004963e-05, Final Batch Loss: 4.507078119786456e-05\n",
      "Epoch 4273, Loss: 0.00014828827988822013, Final Batch Loss: 3.260601806687191e-05\n",
      "Epoch 4274, Loss: 8.933941717259586e-05, Final Batch Loss: 5.6264390877913684e-05\n",
      "Epoch 4275, Loss: 0.0003745979556697421, Final Batch Loss: 4.383303894428536e-05\n",
      "Epoch 4276, Loss: 3.0465665986412205e-05, Final Batch Loss: 1.2734695701510645e-05\n",
      "Epoch 4277, Loss: 0.0005232600597082637, Final Batch Loss: 0.0004851289850194007\n",
      "Epoch 4278, Loss: 0.00014389703028427903, Final Batch Loss: 2.5248593374271877e-05\n",
      "Epoch 4279, Loss: 2.538915941840969e-05, Final Batch Loss: 1.1227250070078298e-05\n",
      "Epoch 4280, Loss: 0.00014836929767625406, Final Batch Loss: 0.00011307367094559595\n",
      "Epoch 4281, Loss: 0.0001954643303179182, Final Batch Loss: 5.694988794857636e-05\n",
      "Epoch 4282, Loss: 3.4368043998256326e-05, Final Batch Loss: 2.0524228602880612e-05\n",
      "Epoch 4283, Loss: 0.008294704632135108, Final Batch Loss: 0.008162309415638447\n",
      "Epoch 4284, Loss: 0.00010074195961351506, Final Batch Loss: 3.849027052638121e-05\n",
      "Epoch 4285, Loss: 7.229806669784011e-05, Final Batch Loss: 1.0240099982183892e-05\n",
      "Epoch 4286, Loss: 0.0004845740331802517, Final Batch Loss: 0.0002715891459956765\n",
      "Epoch 4287, Loss: 1.2311035789025482e-05, Final Batch Loss: 5.039690222474746e-06\n",
      "Epoch 4288, Loss: 0.00060305766237434, Final Batch Loss: 3.9659018511883914e-05\n",
      "Epoch 4289, Loss: 0.014515926381136524, Final Batch Loss: 0.014491175301373005\n",
      "Epoch 4290, Loss: 0.00011317278949718457, Final Batch Loss: 8.84402652445715e-06\n",
      "Epoch 4291, Loss: 2.9879662179155275e-05, Final Batch Loss: 9.439463610760868e-06\n",
      "Epoch 4292, Loss: 5.342252552509308e-05, Final Batch Loss: 3.7176265323068947e-05\n",
      "Epoch 4293, Loss: 0.00011133439693367109, Final Batch Loss: 6.058848157408647e-05\n",
      "Epoch 4294, Loss: 8.14643744888599e-05, Final Batch Loss: 8.931626325647812e-06\n",
      "Epoch 4295, Loss: 3.400586956558982e-05, Final Batch Loss: 8.377936865144875e-06\n",
      "Epoch 4296, Loss: 0.008640716201625764, Final Batch Loss: 0.006969936192035675\n",
      "Epoch 4297, Loss: 9.373313514515758e-05, Final Batch Loss: 4.2869331082329154e-05\n",
      "Epoch 4298, Loss: 1.9528659322531894e-05, Final Batch Loss: 1.2666073416767176e-05\n",
      "Epoch 4299, Loss: 2.9309303499758244e-05, Final Batch Loss: 1.0983763786498457e-05\n",
      "Epoch 4300, Loss: 0.000336685283400584, Final Batch Loss: 0.0003185684618074447\n",
      "Epoch 4301, Loss: 1.4921566616976634e-05, Final Batch Loss: 1.073663224815391e-05\n",
      "Epoch 4302, Loss: 0.0005727318457502406, Final Batch Loss: 0.0005183268222026527\n",
      "Epoch 4303, Loss: 0.00039760986896908435, Final Batch Loss: 3.161667564199888e-06\n",
      "Epoch 4304, Loss: 4.535825610219035e-05, Final Batch Loss: 2.2252248527365737e-05\n",
      "Epoch 4305, Loss: 0.00020275762653909624, Final Batch Loss: 7.547946006525308e-05\n",
      "Epoch 4306, Loss: 5.6321912779822014e-05, Final Batch Loss: 1.9630146198323928e-05\n",
      "Epoch 4307, Loss: 0.00017274546553380787, Final Batch Loss: 1.0378847946412861e-05\n",
      "Epoch 4308, Loss: 3.9689879486104473e-05, Final Batch Loss: 6.757065420970321e-06\n",
      "Epoch 4309, Loss: 8.301184243464377e-05, Final Batch Loss: 2.7387590307625942e-05\n",
      "Epoch 4310, Loss: 1.656275435379939e-05, Final Batch Loss: 9.988988495024387e-06\n",
      "Epoch 4311, Loss: 3.097339504165575e-05, Final Batch Loss: 1.2871838407590985e-05\n",
      "Epoch 4312, Loss: 0.0007299190779122, Final Batch Loss: 5.9293392951076385e-06\n",
      "Epoch 4313, Loss: 0.0005194502373342402, Final Batch Loss: 0.0004682355502154678\n",
      "Epoch 4314, Loss: 5.331395186658483e-05, Final Batch Loss: 1.8913246094598435e-05\n",
      "Epoch 4315, Loss: 4.5824694097973406e-05, Final Batch Loss: 1.5821839042473584e-05\n",
      "Epoch 4316, Loss: 0.02674363204278052, Final Batch Loss: 0.024303894490003586\n",
      "Epoch 4317, Loss: 0.00034697075443546055, Final Batch Loss: 1.2959334526385646e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4318, Loss: 1.3714823126065312e-05, Final Batch Loss: 1.2626355783140752e-06\n",
      "Epoch 4319, Loss: 1.2014881804134347e-05, Final Batch Loss: 1.3437268080451759e-06\n",
      "Epoch 4320, Loss: 0.0010014499421231449, Final Batch Loss: 0.0008920703548938036\n",
      "Epoch 4321, Loss: 0.00039220944745466113, Final Batch Loss: 0.00023200188297778368\n",
      "Epoch 4322, Loss: 0.0002064492364297621, Final Batch Loss: 0.00017648561333771795\n",
      "Epoch 4323, Loss: 0.00015828074515411572, Final Batch Loss: 3.603606955948635e-06\n",
      "Epoch 4324, Loss: 0.002815400050167227, Final Batch Loss: 1.825558501877822e-05\n",
      "Epoch 4325, Loss: 9.812853932089638e-05, Final Batch Loss: 7.732887024758384e-05\n",
      "Epoch 4326, Loss: 0.00043691988685168326, Final Batch Loss: 0.0001624008291400969\n",
      "Epoch 4327, Loss: 2.2484760847873986e-05, Final Batch Loss: 1.4760089470655657e-05\n",
      "Epoch 4328, Loss: 0.0001075577674782835, Final Batch Loss: 1.842757046688348e-05\n",
      "Epoch 4329, Loss: 6.934501288924366e-05, Final Batch Loss: 4.156616341788322e-06\n",
      "Epoch 4330, Loss: 0.0003374066454853164, Final Batch Loss: 8.188975698431022e-06\n",
      "Epoch 4331, Loss: 0.00018404334878141526, Final Batch Loss: 0.00017384448437951505\n",
      "Epoch 4332, Loss: 0.00012991734547540545, Final Batch Loss: 2.0098952518310398e-05\n",
      "Epoch 4333, Loss: 2.2483847715193406e-05, Final Batch Loss: 1.3515026694221888e-05\n",
      "Epoch 4334, Loss: 0.000156304806296248, Final Batch Loss: 9.394755034008995e-05\n",
      "Epoch 4335, Loss: 3.245123900796898e-05, Final Batch Loss: 1.7864609844764345e-06\n",
      "Epoch 4336, Loss: 0.045643670338904485, Final Batch Loss: 0.04556984826922417\n",
      "Epoch 4337, Loss: 0.00034840994339901954, Final Batch Loss: 7.796195859555155e-05\n",
      "Epoch 4338, Loss: 0.00015646356405341066, Final Batch Loss: 3.506935536279343e-05\n",
      "Epoch 4339, Loss: 0.0020313656896178145, Final Batch Loss: 0.002019037725403905\n",
      "Epoch 4340, Loss: 0.0006220152754394803, Final Batch Loss: 0.0006008480559103191\n",
      "Epoch 4341, Loss: 8.0566434917273e-05, Final Batch Loss: 2.895168654504232e-05\n",
      "Epoch 4342, Loss: 0.0014193542874636478, Final Batch Loss: 8.500704097968992e-06\n",
      "Epoch 4343, Loss: 3.146465405734489e-05, Final Batch Loss: 1.1186871233803686e-05\n",
      "Epoch 4344, Loss: 0.002172042628444615, Final Batch Loss: 2.607751048344653e-05\n",
      "Epoch 4345, Loss: 7.461040695488919e-05, Final Batch Loss: 2.244081588287372e-05\n",
      "Epoch 4346, Loss: 0.0006466840131906793, Final Batch Loss: 0.000503378629218787\n",
      "Epoch 4347, Loss: 8.712509225006215e-05, Final Batch Loss: 4.135022027185187e-05\n",
      "Epoch 4348, Loss: 3.408253542147577e-05, Final Batch Loss: 1.8402040950604714e-05\n",
      "Epoch 4349, Loss: 0.00012300114758545533, Final Batch Loss: 2.4502180167473853e-05\n",
      "Epoch 4350, Loss: 0.00014891958198859356, Final Batch Loss: 0.00012943406181875616\n",
      "Epoch 4351, Loss: 7.928076411189977e-05, Final Batch Loss: 2.2264508515945636e-05\n",
      "Epoch 4352, Loss: 0.0019848000220008544, Final Batch Loss: 0.001974988030269742\n",
      "Epoch 4353, Loss: 0.00013209868120611645, Final Batch Loss: 9.718778892420232e-05\n",
      "Epoch 4354, Loss: 0.0011740672925952822, Final Batch Loss: 0.000288221548544243\n",
      "Epoch 4355, Loss: 2.979333294206299e-05, Final Batch Loss: 1.2125574357924052e-05\n",
      "Epoch 4356, Loss: 0.00018423438450554386, Final Batch Loss: 8.867256838129833e-05\n",
      "Epoch 4357, Loss: 0.00011897092190338299, Final Batch Loss: 9.427218174096197e-06\n",
      "Epoch 4358, Loss: 0.00011355567130522104, Final Batch Loss: 1.438289928046288e-05\n",
      "Epoch 4359, Loss: 0.0001175150136987213, Final Batch Loss: 6.424290040740743e-05\n",
      "Epoch 4360, Loss: 0.00023296229846891947, Final Batch Loss: 0.00021753802138846368\n",
      "Epoch 4361, Loss: 0.0009863163941190578, Final Batch Loss: 0.0008831158047541976\n",
      "Epoch 4362, Loss: 5.530055386770982e-05, Final Batch Loss: 3.0743573006475344e-05\n",
      "Epoch 4363, Loss: 0.00011074747089878656, Final Batch Loss: 2.8043639758834615e-05\n",
      "Epoch 4364, Loss: 0.0001392346530337818, Final Batch Loss: 2.395835326751694e-05\n",
      "Epoch 4365, Loss: 0.0002839573426172137, Final Batch Loss: 0.00023999414406716824\n",
      "Epoch 4366, Loss: 4.091017945029307e-05, Final Batch Loss: 1.5779502064106055e-05\n",
      "Epoch 4367, Loss: 7.016404924797826e-05, Final Batch Loss: 3.1956245948094875e-05\n",
      "Epoch 4368, Loss: 4.316433296480682e-05, Final Batch Loss: 2.0502289771684445e-05\n",
      "Epoch 4369, Loss: 0.00041255218093283474, Final Batch Loss: 0.00014321226626634598\n",
      "Epoch 4370, Loss: 0.00011658602306852117, Final Batch Loss: 2.123405283782631e-05\n",
      "Epoch 4371, Loss: 0.0009366731646878179, Final Batch Loss: 0.0008758884505368769\n",
      "Epoch 4372, Loss: 0.0008323331239807885, Final Batch Loss: 0.0008162815938703716\n",
      "Epoch 4373, Loss: 0.0001225977648573462, Final Batch Loss: 8.13828592072241e-05\n",
      "Epoch 4374, Loss: 0.00012640134809771553, Final Batch Loss: 4.279079439584166e-05\n",
      "Epoch 4375, Loss: 0.0003930667498934781, Final Batch Loss: 0.0003695818886626512\n",
      "Epoch 4376, Loss: 0.0004810574246221222, Final Batch Loss: 0.00039449636824429035\n",
      "Epoch 4377, Loss: 0.0019435504218563437, Final Batch Loss: 0.0019080543424934149\n",
      "Epoch 4378, Loss: 0.0001561462486279197, Final Batch Loss: 8.632809476694092e-05\n",
      "Epoch 4379, Loss: 0.0013199026579968631, Final Batch Loss: 0.00012911559315398335\n",
      "Epoch 4380, Loss: 8.747525862418115e-05, Final Batch Loss: 1.624217111384496e-05\n",
      "Epoch 4381, Loss: 5.6312982451345306e-05, Final Batch Loss: 4.1180865082424134e-05\n",
      "Epoch 4382, Loss: 0.0002838080963556422, Final Batch Loss: 2.6589024855638854e-05\n",
      "Epoch 4383, Loss: 0.00016105760732898489, Final Batch Loss: 7.034277950879186e-05\n",
      "Epoch 4384, Loss: 4.889112460659817e-05, Final Batch Loss: 2.2770034775021486e-05\n",
      "Epoch 4385, Loss: 0.00028861552164016757, Final Batch Loss: 0.00025886789080686867\n",
      "Epoch 4386, Loss: 0.00015278237333404832, Final Batch Loss: 2.7485260943649337e-05\n",
      "Epoch 4387, Loss: 0.00047581658873241395, Final Batch Loss: 6.276626663748175e-05\n",
      "Epoch 4388, Loss: 0.0002153612113033887, Final Batch Loss: 0.00018367386655882\n",
      "Epoch 4389, Loss: 0.00022141866065794602, Final Batch Loss: 2.3140550183597952e-05\n",
      "Epoch 4390, Loss: 0.0002100806450471282, Final Batch Loss: 6.322967237792909e-05\n",
      "Epoch 4391, Loss: 0.0008586800977354869, Final Batch Loss: 5.505558510776609e-05\n",
      "Epoch 4392, Loss: 5.933337888563983e-05, Final Batch Loss: 2.387069253018126e-05\n",
      "Epoch 4393, Loss: 0.0009552987066854257, Final Batch Loss: 2.1214236767264083e-05\n",
      "Epoch 4394, Loss: 0.002035296998656122, Final Batch Loss: 0.001982101472094655\n",
      "Epoch 4395, Loss: 0.00011939930664084386, Final Batch Loss: 2.5085928427870385e-05\n",
      "Epoch 4396, Loss: 0.0007545990974904271, Final Batch Loss: 5.0819817261071876e-06\n",
      "Epoch 4397, Loss: 5.2987154049333185e-05, Final Batch Loss: 3.4480151953175664e-05\n",
      "Epoch 4398, Loss: 5.111351538289455e-05, Final Batch Loss: 6.816273980803089e-06\n",
      "Epoch 4399, Loss: 0.0001721731314319186, Final Batch Loss: 0.0001073391831596382\n",
      "Epoch 4400, Loss: 0.0004934540556860156, Final Batch Loss: 7.566260319435969e-05\n",
      "Epoch 4401, Loss: 0.026865127263590693, Final Batch Loss: 0.025621838867664337\n",
      "Epoch 4402, Loss: 0.00010828945232788101, Final Batch Loss: 5.029486783314496e-05\n",
      "Epoch 4403, Loss: 0.00022586438717553392, Final Batch Loss: 9.062721801456064e-06\n",
      "Epoch 4404, Loss: 3.54503613380075e-05, Final Batch Loss: 6.634462351939874e-06\n",
      "Epoch 4405, Loss: 0.007346135573243373, Final Batch Loss: 0.007336173672229052\n",
      "Epoch 4406, Loss: 0.00039939484850037843, Final Batch Loss: 2.0410734578035772e-05\n",
      "Epoch 4407, Loss: 0.0012187192996861995, Final Batch Loss: 1.0205673788732383e-05\n",
      "Epoch 4408, Loss: 1.2011533272016095e-05, Final Batch Loss: 5.8758078012033366e-06\n",
      "Epoch 4409, Loss: 0.0013654871836479288, Final Batch Loss: 0.0013256617821753025\n",
      "Epoch 4410, Loss: 3.4218874361613416e-05, Final Batch Loss: 2.722272483879351e-06\n",
      "Epoch 4411, Loss: 0.0023998653632588685, Final Batch Loss: 0.002309249248355627\n",
      "Epoch 4412, Loss: 0.00031382770248455927, Final Batch Loss: 0.00010214905341854319\n",
      "Epoch 4413, Loss: 9.528359078103676e-05, Final Batch Loss: 4.718845957540907e-05\n",
      "Epoch 4414, Loss: 0.00011952347858823487, Final Batch Loss: 0.00011404795077396557\n",
      "Epoch 4415, Loss: 0.0003911928288289346, Final Batch Loss: 8.613733371021226e-05\n",
      "Epoch 4416, Loss: 0.0008435017298324965, Final Batch Loss: 4.943194653606042e-05\n",
      "Epoch 4417, Loss: 0.0005202234042371856, Final Batch Loss: 2.7821924959425814e-05\n",
      "Epoch 4418, Loss: 0.00024341821062989766, Final Batch Loss: 4.854854523728136e-06\n",
      "Epoch 4419, Loss: 0.00037001505188527517, Final Batch Loss: 5.7207431382266805e-05\n",
      "Epoch 4420, Loss: 3.2361970170313725e-05, Final Batch Loss: 2.779776150418911e-05\n",
      "Epoch 4421, Loss: 0.0005654437700286508, Final Batch Loss: 0.00016080567729659379\n",
      "Epoch 4422, Loss: 0.0002491581399226561, Final Batch Loss: 4.3253370677120984e-05\n",
      "Epoch 4423, Loss: 0.017690039945591707, Final Batch Loss: 0.017607267946004868\n",
      "Epoch 4424, Loss: 0.011867364373756573, Final Batch Loss: 0.00047554398770444095\n",
      "Epoch 4425, Loss: 8.038331361603923e-05, Final Batch Loss: 5.703375063603744e-05\n",
      "Epoch 4426, Loss: 0.0003549045941326767, Final Batch Loss: 6.60049554426223e-05\n",
      "Epoch 4427, Loss: 0.00017002115419018082, Final Batch Loss: 4.132566027692519e-05\n",
      "Epoch 4428, Loss: 0.0019836608225887176, Final Batch Loss: 1.2648841220652685e-05\n",
      "Epoch 4429, Loss: 0.00041211055213352665, Final Batch Loss: 0.0003783798310905695\n",
      "Epoch 4430, Loss: 0.00020181992294965312, Final Batch Loss: 9.34147828957066e-05\n",
      "Epoch 4431, Loss: 0.0009339342941530049, Final Batch Loss: 0.0001858617179095745\n",
      "Epoch 4432, Loss: 0.004662859864765778, Final Batch Loss: 0.00022504260414279997\n",
      "Epoch 4433, Loss: 0.00010396020661573857, Final Batch Loss: 3.7798075936734676e-05\n",
      "Epoch 4434, Loss: 3.6866536902380176e-05, Final Batch Loss: 8.346720278495923e-06\n",
      "Epoch 4435, Loss: 7.075209214235656e-05, Final Batch Loss: 4.909796916763298e-05\n",
      "Epoch 4436, Loss: 0.0005678979214280844, Final Batch Loss: 9.405295713804662e-05\n",
      "Epoch 4437, Loss: 0.00022164921392686665, Final Batch Loss: 0.00013829611998517066\n",
      "Epoch 4438, Loss: 0.00026846398395719007, Final Batch Loss: 0.00021992325491737574\n",
      "Epoch 4439, Loss: 0.0007137496941140853, Final Batch Loss: 0.0006809431943111122\n",
      "Epoch 4440, Loss: 0.0004285109607735649, Final Batch Loss: 6.95098569849506e-05\n",
      "Epoch 4441, Loss: 0.0011383874953025952, Final Batch Loss: 0.0010415386641398072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4442, Loss: 0.00011646111306617968, Final Batch Loss: 4.0798851841827855e-05\n",
      "Epoch 4443, Loss: 0.00016697017417754978, Final Batch Loss: 4.987908323528245e-05\n",
      "Epoch 4444, Loss: 0.00029619473207276314, Final Batch Loss: 7.258022378664464e-05\n",
      "Epoch 4445, Loss: 5.01104677823605e-05, Final Batch Loss: 2.2949005142436363e-05\n",
      "Epoch 4446, Loss: 0.0004178871604381129, Final Batch Loss: 0.0002164382312912494\n",
      "Epoch 4447, Loss: 0.00010830377141246572, Final Batch Loss: 7.13322006049566e-05\n",
      "Epoch 4448, Loss: 0.00016395132661273237, Final Batch Loss: 2.7110427254228853e-05\n",
      "Epoch 4449, Loss: 7.778279177728109e-05, Final Batch Loss: 1.0372586984885857e-05\n",
      "Epoch 4450, Loss: 0.00020838205091422424, Final Batch Loss: 1.1013333278242499e-05\n",
      "Epoch 4451, Loss: 0.00011145140524604358, Final Batch Loss: 4.50261177320499e-05\n",
      "Epoch 4452, Loss: 0.00038083175604697317, Final Batch Loss: 4.586456634569913e-05\n",
      "Epoch 4453, Loss: 3.306377220724244e-05, Final Batch Loss: 1.710789729258977e-05\n",
      "Epoch 4454, Loss: 5.6576387578388676e-05, Final Batch Loss: 2.180973024223931e-05\n",
      "Epoch 4455, Loss: 0.0004723066813312471, Final Batch Loss: 0.0003365853917784989\n",
      "Epoch 4456, Loss: 7.799895684001967e-05, Final Batch Loss: 3.907354039256461e-05\n",
      "Epoch 4457, Loss: 0.00022470878320746124, Final Batch Loss: 7.181457476690412e-05\n",
      "Epoch 4458, Loss: 7.808550435584038e-05, Final Batch Loss: 3.734030542545952e-05\n",
      "Epoch 4459, Loss: 0.000218811535887653, Final Batch Loss: 0.00019681188859976828\n",
      "Epoch 4460, Loss: 0.00030905062158126384, Final Batch Loss: 0.00022618322691414505\n",
      "Epoch 4461, Loss: 0.00011309106412227266, Final Batch Loss: 3.69025619875174e-05\n",
      "Epoch 4462, Loss: 0.00040884701593313366, Final Batch Loss: 0.0002569435746408999\n",
      "Epoch 4463, Loss: 0.00019107396656181663, Final Batch Loss: 3.846069739665836e-05\n",
      "Epoch 4464, Loss: 0.0002221717732027173, Final Batch Loss: 0.00012834118388127536\n",
      "Epoch 4465, Loss: 3.346024823258631e-05, Final Batch Loss: 1.5564599380013533e-05\n",
      "Epoch 4466, Loss: 0.0013983060198370367, Final Batch Loss: 3.975865547545254e-05\n",
      "Epoch 4467, Loss: 0.0009912352543324232, Final Batch Loss: 0.0004068042035214603\n",
      "Epoch 4468, Loss: 0.000109464399429271, Final Batch Loss: 1.6040681657614186e-05\n",
      "Epoch 4469, Loss: 6.389894406311214e-05, Final Batch Loss: 4.6515142457792535e-05\n",
      "Epoch 4470, Loss: 0.0014942205198167358, Final Batch Loss: 2.944813240901567e-05\n",
      "Epoch 4471, Loss: 6.949660200916696e-05, Final Batch Loss: 4.604178320732899e-05\n",
      "Epoch 4472, Loss: 0.0005616476846626028, Final Batch Loss: 0.00011747259122785181\n",
      "Epoch 4473, Loss: 0.0003072547260671854, Final Batch Loss: 3.4115451853722334e-05\n",
      "Epoch 4474, Loss: 6.892072269693017e-05, Final Batch Loss: 3.143795402138494e-05\n",
      "Epoch 4475, Loss: 0.000356602635292802, Final Batch Loss: 0.0002832267200574279\n",
      "Epoch 4476, Loss: 0.0003857226110994816, Final Batch Loss: 0.00037358791450969875\n",
      "Epoch 4477, Loss: 0.0020636240878957324, Final Batch Loss: 0.0020158756524324417\n",
      "Epoch 4478, Loss: 0.00047237058970495127, Final Batch Loss: 0.00041624350706115365\n",
      "Epoch 4479, Loss: 7.724363968009129e-05, Final Batch Loss: 1.458796759834513e-05\n",
      "Epoch 4480, Loss: 0.00013339557881408837, Final Batch Loss: 1.3304945241543464e-05\n",
      "Epoch 4481, Loss: 0.00010759426368167624, Final Batch Loss: 3.131150879198685e-05\n",
      "Epoch 4482, Loss: 0.0007536340417573228, Final Batch Loss: 0.0006202063523232937\n",
      "Epoch 4483, Loss: 0.00011740170157281682, Final Batch Loss: 9.369612234877422e-05\n",
      "Epoch 4484, Loss: 0.0010506051185075194, Final Batch Loss: 0.0007783571491017938\n",
      "Epoch 4485, Loss: 0.00018485412147128955, Final Batch Loss: 7.78724133851938e-05\n",
      "Epoch 4486, Loss: 0.0012847576072090305, Final Batch Loss: 6.280674278968945e-05\n",
      "Epoch 4487, Loss: 0.00034225582203362137, Final Batch Loss: 0.00013899161422159523\n",
      "Epoch 4488, Loss: 0.00021930437651462853, Final Batch Loss: 5.529413465410471e-05\n",
      "Epoch 4489, Loss: 0.00024030102940741926, Final Batch Loss: 0.00019704036822076887\n",
      "Epoch 4490, Loss: 0.00037884325138293207, Final Batch Loss: 2.547932672314346e-05\n",
      "Epoch 4491, Loss: 4.5828684960724786e-05, Final Batch Loss: 1.917315603350289e-05\n",
      "Epoch 4492, Loss: 0.00028916748487972654, Final Batch Loss: 2.8312850190559402e-05\n",
      "Epoch 4493, Loss: 0.00018431978696753504, Final Batch Loss: 1.5152710147958715e-05\n",
      "Epoch 4494, Loss: 0.000224176183110103, Final Batch Loss: 0.0001246386527782306\n",
      "Epoch 4495, Loss: 0.0004016199236502871, Final Batch Loss: 0.0003712859470397234\n",
      "Epoch 4496, Loss: 0.00023692920149187557, Final Batch Loss: 0.00021775494678877294\n",
      "Epoch 4497, Loss: 0.0006577393996849423, Final Batch Loss: 1.3702656360692345e-05\n",
      "Epoch 4498, Loss: 4.890802847512532e-05, Final Batch Loss: 1.967199750652071e-05\n",
      "Epoch 4499, Loss: 0.00027530741863301955, Final Batch Loss: 3.852115696645342e-05\n",
      "Epoch 4500, Loss: 0.0004961233889844152, Final Batch Loss: 1.3314241186890285e-05\n",
      "Epoch 4501, Loss: 0.00016898739249882055, Final Batch Loss: 7.903860932856333e-06\n",
      "Epoch 4502, Loss: 0.0002744434241321869, Final Batch Loss: 0.0001720715081319213\n",
      "Epoch 4503, Loss: 8.941713895183057e-05, Final Batch Loss: 2.7934009267482907e-05\n",
      "Epoch 4504, Loss: 0.001768776448443532, Final Batch Loss: 0.0006335264770314097\n",
      "Epoch 4505, Loss: 0.00014039849702385254, Final Batch Loss: 4.365083805168979e-05\n",
      "Epoch 4506, Loss: 0.00013197704538470134, Final Batch Loss: 6.628279516007751e-05\n",
      "Epoch 4507, Loss: 7.413144521706272e-05, Final Batch Loss: 4.510876533458941e-05\n",
      "Epoch 4508, Loss: 9.28042736632051e-05, Final Batch Loss: 1.6914966181502678e-05\n",
      "Epoch 4509, Loss: 0.0001359536145173479, Final Batch Loss: 4.185174111626111e-05\n",
      "Epoch 4510, Loss: 0.00011694750173774082, Final Batch Loss: 9.471940575167537e-05\n",
      "Epoch 4511, Loss: 0.0004668055917136371, Final Batch Loss: 1.5619967598468065e-05\n",
      "Epoch 4512, Loss: 4.075011020177044e-05, Final Batch Loss: 2.1252562873996794e-05\n",
      "Epoch 4513, Loss: 0.001127060913859168, Final Batch Loss: 4.3369425839046016e-05\n",
      "Epoch 4514, Loss: 0.00013463030154525768, Final Batch Loss: 0.00011122311843791977\n",
      "Epoch 4515, Loss: 6.426991058106069e-05, Final Batch Loss: 4.832306512980722e-05\n",
      "Epoch 4516, Loss: 0.00015259089923347346, Final Batch Loss: 4.240914495312609e-05\n",
      "Epoch 4517, Loss: 8.160418292391114e-05, Final Batch Loss: 5.261347541818395e-05\n",
      "Epoch 4518, Loss: 5.165114635019563e-05, Final Batch Loss: 1.7449921870138496e-05\n",
      "Epoch 4519, Loss: 0.0004636919020413188, Final Batch Loss: 1.8102013200405054e-05\n",
      "Epoch 4520, Loss: 0.00014226783605408855, Final Batch Loss: 9.233885066350922e-05\n",
      "Epoch 4521, Loss: 0.00026466842064110097, Final Batch Loss: 0.0002483369898982346\n",
      "Epoch 4522, Loss: 0.0005887350416742265, Final Batch Loss: 7.926532998681068e-05\n",
      "Epoch 4523, Loss: 0.00018922848903457634, Final Batch Loss: 3.246495543862693e-05\n",
      "Epoch 4524, Loss: 0.0004968798020854592, Final Batch Loss: 0.0002851114550139755\n",
      "Epoch 4525, Loss: 0.0007404630632663611, Final Batch Loss: 0.0007008010288700461\n",
      "Epoch 4526, Loss: 0.0003307720326120034, Final Batch Loss: 0.00017444949480704963\n",
      "Epoch 4527, Loss: 0.00011266461206105305, Final Batch Loss: 0.00010100882354890928\n",
      "Epoch 4528, Loss: 5.351130312192254e-05, Final Batch Loss: 1.692372461548075e-05\n",
      "Epoch 4529, Loss: 0.0001655983960517915, Final Batch Loss: 1.9636137949419208e-05\n",
      "Epoch 4530, Loss: 0.0005789034730696585, Final Batch Loss: 2.8392005333444104e-05\n",
      "Epoch 4531, Loss: 0.0003452440942055546, Final Batch Loss: 0.00022499714395962656\n",
      "Epoch 4532, Loss: 0.0002973093251057435, Final Batch Loss: 0.0002437406947137788\n",
      "Epoch 4533, Loss: 4.3375217046559555e-05, Final Batch Loss: 3.7617708585457876e-05\n",
      "Epoch 4534, Loss: 0.0006788907630834728, Final Batch Loss: 0.00010091581498272717\n",
      "Epoch 4535, Loss: 9.557530211168341e-05, Final Batch Loss: 3.093487976002507e-05\n",
      "Epoch 4536, Loss: 0.00038821362613816746, Final Batch Loss: 5.397740824264474e-05\n",
      "Epoch 4537, Loss: 7.040739546937402e-05, Final Batch Loss: 5.8739999076351523e-05\n",
      "Epoch 4538, Loss: 0.00023824138042982668, Final Batch Loss: 0.0001661499700276181\n",
      "Epoch 4539, Loss: 0.0005661511859216262, Final Batch Loss: 8.866209100233391e-06\n",
      "Epoch 4540, Loss: 9.589169712853618e-05, Final Batch Loss: 5.436547871795483e-05\n",
      "Epoch 4541, Loss: 0.00010666084926924668, Final Batch Loss: 7.979985093697906e-05\n",
      "Epoch 4542, Loss: 0.0003902151947841048, Final Batch Loss: 0.00018064051982946694\n",
      "Epoch 4543, Loss: 0.00022781531879445538, Final Batch Loss: 0.00019176497880835086\n",
      "Epoch 4544, Loss: 9.34672680159565e-05, Final Batch Loss: 5.1662998885149136e-05\n",
      "Epoch 4545, Loss: 0.00026179783162660897, Final Batch Loss: 5.6217817473225296e-05\n",
      "Epoch 4546, Loss: 4.399677982291905e-05, Final Batch Loss: 3.290624590590596e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4547, Loss: 0.00012939299995196052, Final Batch Loss: 0.00011032279871869832\n",
      "Epoch 4548, Loss: 0.0016136047634063289, Final Batch Loss: 0.00022926127712707967\n",
      "Epoch 4549, Loss: 5.634963599732146e-05, Final Batch Loss: 3.5445344110485166e-05\n",
      "Epoch 4550, Loss: 0.0006395577947841957, Final Batch Loss: 0.00015528082440141588\n",
      "Epoch 4551, Loss: 0.0009254979595425539, Final Batch Loss: 0.0008576282998546958\n",
      "Epoch 4552, Loss: 2.3447102648788132e-05, Final Batch Loss: 5.796315235784277e-06\n",
      "Epoch 4553, Loss: 0.008501471602357924, Final Batch Loss: 0.007852583192288876\n",
      "Epoch 4554, Loss: 0.00023529576719738543, Final Batch Loss: 0.00012594556028489023\n",
      "Epoch 4555, Loss: 0.0006789021099393722, Final Batch Loss: 3.94226772186812e-05\n",
      "Epoch 4556, Loss: 0.00010404164822830353, Final Batch Loss: 8.096770761767402e-05\n",
      "Epoch 4557, Loss: 2.7113947453472065e-05, Final Batch Loss: 7.534143605880672e-06\n",
      "Epoch 4558, Loss: 0.0031272795677068643, Final Batch Loss: 0.003107283730059862\n",
      "Epoch 4559, Loss: 2.9379292755038477e-05, Final Batch Loss: 6.313495759968646e-06\n",
      "Epoch 4560, Loss: 0.0006459623982664198, Final Batch Loss: 0.00039317546179518104\n",
      "Epoch 4561, Loss: 5.080630762677174e-05, Final Batch Loss: 3.9130049117375165e-05\n",
      "Epoch 4562, Loss: 4.875223385170102e-05, Final Batch Loss: 1.260341377928853e-05\n",
      "Epoch 4563, Loss: 0.00015136772708501667, Final Batch Loss: 8.12729267636314e-05\n",
      "Epoch 4564, Loss: 1.9479530237731524e-05, Final Batch Loss: 2.499302354408428e-06\n",
      "Epoch 4565, Loss: 0.005477293257627025, Final Batch Loss: 6.729600045218831e-06\n",
      "Epoch 4566, Loss: 0.0006734590060659684, Final Batch Loss: 1.8427941540721804e-05\n",
      "Epoch 4567, Loss: 2.7551214316190453e-05, Final Batch Loss: 4.733976766146952e-06\n",
      "Epoch 4568, Loss: 0.003608039696700871, Final Batch Loss: 0.0011365326354280114\n",
      "Epoch 4569, Loss: 0.004351980451247073, Final Batch Loss: 1.5280607840395533e-05\n",
      "Epoch 4570, Loss: 0.00015405533122248016, Final Batch Loss: 3.074573396588676e-05\n",
      "Epoch 4571, Loss: 1.874876943475101e-05, Final Batch Loss: 1.0500910320843104e-05\n",
      "Epoch 4572, Loss: 0.006469569860200863, Final Batch Loss: 0.006447100546211004\n",
      "Epoch 4573, Loss: 0.0003456348131294362, Final Batch Loss: 0.00031774205854162574\n",
      "Epoch 4574, Loss: 0.00022440047905547544, Final Batch Loss: 0.0001261696743313223\n",
      "Epoch 4575, Loss: 5.925086952629499e-05, Final Batch Loss: 2.2247550077736378e-05\n",
      "Epoch 4576, Loss: 0.0013543000313802622, Final Batch Loss: 5.6333337852265686e-05\n",
      "Epoch 4577, Loss: 0.00029616174288094044, Final Batch Loss: 4.955497570335865e-05\n",
      "Epoch 4578, Loss: 0.00023203818818728905, Final Batch Loss: 0.00021328675211407244\n",
      "Epoch 4579, Loss: 0.0013882162947993493, Final Batch Loss: 0.0013603195548057556\n",
      "Epoch 4580, Loss: 0.0002439351192151662, Final Batch Loss: 0.000189589976798743\n",
      "Epoch 4581, Loss: 0.0003099857385677751, Final Batch Loss: 0.00026546468143351376\n",
      "Epoch 4582, Loss: 4.514029023994226e-05, Final Batch Loss: 1.862536373664625e-05\n",
      "Epoch 4583, Loss: 0.00018469089991413057, Final Batch Loss: 1.370643440168351e-05\n",
      "Epoch 4584, Loss: 0.00020649994257837534, Final Batch Loss: 7.93082726886496e-05\n",
      "Epoch 4585, Loss: 0.00015266479749698192, Final Batch Loss: 8.540642738807946e-05\n",
      "Epoch 4586, Loss: 0.002043433749349788, Final Batch Loss: 0.0020058397203683853\n",
      "Epoch 4587, Loss: 0.00039132661186158657, Final Batch Loss: 0.00024864362785592675\n",
      "Epoch 4588, Loss: 7.429004290315788e-05, Final Batch Loss: 1.1117821486550383e-05\n",
      "Epoch 4589, Loss: 0.0001516330084996298, Final Batch Loss: 0.0001090517034754157\n",
      "Epoch 4590, Loss: 0.00020676921485573985, Final Batch Loss: 0.00018795364303514361\n",
      "Epoch 4591, Loss: 0.0008534526277799159, Final Batch Loss: 4.635946243070066e-05\n",
      "Epoch 4592, Loss: 7.611609544255771e-05, Final Batch Loss: 9.433762897970155e-06\n",
      "Epoch 4593, Loss: 0.001316209978540428, Final Batch Loss: 0.00010894874867517501\n",
      "Epoch 4594, Loss: 0.003326902611206606, Final Batch Loss: 5.922725449636346e-06\n",
      "Epoch 4595, Loss: 0.0002972108413814567, Final Batch Loss: 0.0002585707406979054\n",
      "Epoch 4596, Loss: 4.0794784581521526e-05, Final Batch Loss: 1.88553112820955e-05\n",
      "Epoch 4597, Loss: 0.00040606358015793376, Final Batch Loss: 1.2179265468148515e-05\n",
      "Epoch 4598, Loss: 0.0005075678691355279, Final Batch Loss: 1.3488786862581037e-05\n",
      "Epoch 4599, Loss: 0.00014172756709740497, Final Batch Loss: 1.8432041542837396e-05\n",
      "Epoch 4600, Loss: 8.906804214348085e-05, Final Batch Loss: 5.46297051187139e-05\n",
      "Epoch 4601, Loss: 3.310486499685794e-05, Final Batch Loss: 1.8823448044713587e-05\n",
      "Epoch 4602, Loss: 0.0019563800742616877, Final Batch Loss: 0.0017811715370044112\n",
      "Epoch 4603, Loss: 0.0001039558628690429, Final Batch Loss: 5.1810882723657414e-05\n",
      "Epoch 4604, Loss: 0.00018993453886650968, Final Batch Loss: 2.9629985874635167e-05\n",
      "Epoch 4605, Loss: 0.00010691197530832142, Final Batch Loss: 4.977024582331069e-05\n",
      "Epoch 4606, Loss: 0.00029175327563280007, Final Batch Loss: 1.4181720871420112e-05\n",
      "Epoch 4607, Loss: 0.00035717053106054664, Final Batch Loss: 0.00013957895862404257\n",
      "Epoch 4608, Loss: 0.00012807816347049084, Final Batch Loss: 0.00011044801794923842\n",
      "Epoch 4609, Loss: 4.5037510062684305e-05, Final Batch Loss: 1.208539651997853e-05\n",
      "Epoch 4610, Loss: 2.7806611797132064e-05, Final Batch Loss: 9.151010999630671e-06\n",
      "Epoch 4611, Loss: 0.0004144250278841355, Final Batch Loss: 0.0004003565409220755\n",
      "Epoch 4612, Loss: 0.0004642159674403956, Final Batch Loss: 7.449072654708289e-06\n",
      "Epoch 4613, Loss: 3.501649280224228e-05, Final Batch Loss: 2.4556640710216016e-05\n",
      "Epoch 4614, Loss: 6.446507723012473e-05, Final Batch Loss: 2.3008955395198427e-05\n",
      "Epoch 4615, Loss: 6.519706084873178e-05, Final Batch Loss: 6.2454987528326456e-06\n",
      "Epoch 4616, Loss: 7.945594006741885e-05, Final Batch Loss: 2.812507409544196e-05\n",
      "Epoch 4617, Loss: 0.0004766650035890052, Final Batch Loss: 0.0004570885212160647\n",
      "Epoch 4618, Loss: 3.528584602463525e-05, Final Batch Loss: 5.358133421395905e-06\n",
      "Epoch 4619, Loss: 4.412614907778334e-05, Final Batch Loss: 2.5635516067268327e-05\n",
      "Epoch 4620, Loss: 0.0001698340565781109, Final Batch Loss: 2.3783963115420192e-05\n",
      "Epoch 4621, Loss: 0.0009860048594418913, Final Batch Loss: 0.00020390420104376972\n",
      "Epoch 4622, Loss: 0.00010332333840779029, Final Batch Loss: 5.928705650148913e-05\n",
      "Epoch 4623, Loss: 0.00018375780746282544, Final Batch Loss: 1.945351505128201e-05\n",
      "Epoch 4624, Loss: 5.74308887735242e-05, Final Batch Loss: 1.4950916011002846e-05\n",
      "Epoch 4625, Loss: 0.00018212675058748573, Final Batch Loss: 2.5484056095592678e-05\n",
      "Epoch 4626, Loss: 6.246641169127543e-05, Final Batch Loss: 1.3821512766298838e-05\n",
      "Epoch 4627, Loss: 0.00011421052295190748, Final Batch Loss: 2.2842874386697076e-05\n",
      "Epoch 4628, Loss: 0.0015282193489838392, Final Batch Loss: 6.292018224485219e-05\n",
      "Epoch 4629, Loss: 0.0005732599965995178, Final Batch Loss: 0.0005468790768645704\n",
      "Epoch 4630, Loss: 0.00043074123095721006, Final Batch Loss: 0.00017536888481117785\n",
      "Epoch 4631, Loss: 0.00018471202474756865, Final Batch Loss: 0.0001712506782496348\n",
      "Epoch 4632, Loss: 2.620543000375619e-05, Final Batch Loss: 1.7443873730371706e-05\n",
      "Epoch 4633, Loss: 8.460723256575875e-05, Final Batch Loss: 4.544201146927662e-05\n",
      "Epoch 4634, Loss: 0.000314561551931547, Final Batch Loss: 0.00028243238921277225\n",
      "Epoch 4635, Loss: 0.0015183599607553333, Final Batch Loss: 0.00029707219800911844\n",
      "Epoch 4636, Loss: 0.00018767002438835334, Final Batch Loss: 5.5846012401161715e-06\n",
      "Epoch 4637, Loss: 3.3008789614541456e-05, Final Batch Loss: 1.603784585313406e-05\n",
      "Epoch 4638, Loss: 0.00016792085079941899, Final Batch Loss: 1.7342405044473708e-05\n",
      "Epoch 4639, Loss: 0.0002014169658650644, Final Batch Loss: 3.48993853549473e-05\n",
      "Epoch 4640, Loss: 0.0005295429691614117, Final Batch Loss: 3.768951501115225e-05\n",
      "Epoch 4641, Loss: 7.93218714534305e-05, Final Batch Loss: 5.959179543424398e-05\n",
      "Epoch 4642, Loss: 0.0001485923621658003, Final Batch Loss: 0.00011930117034353316\n",
      "Epoch 4643, Loss: 5.391272861743346e-05, Final Batch Loss: 2.9409218768705614e-05\n",
      "Epoch 4644, Loss: 4.816211367142387e-05, Final Batch Loss: 3.0508042982546613e-05\n",
      "Epoch 4645, Loss: 0.00038883146407897584, Final Batch Loss: 0.0003589080006349832\n",
      "Epoch 4646, Loss: 1.6452308500447543e-05, Final Batch Loss: 5.039704319642624e-06\n",
      "Epoch 4647, Loss: 4.090114634891506e-05, Final Batch Loss: 1.9361614249646664e-05\n",
      "Epoch 4648, Loss: 0.0002939746373158414, Final Batch Loss: 5.8275476476410404e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4649, Loss: 5.046213300374802e-05, Final Batch Loss: 1.827534106269013e-05\n",
      "Epoch 4650, Loss: 0.0001915977572934935, Final Batch Loss: 1.4471088434220292e-05\n",
      "Epoch 4651, Loss: 0.0003085131029365584, Final Batch Loss: 0.00019942529615946114\n",
      "Epoch 4652, Loss: 0.0012232057815708686, Final Batch Loss: 1.8000795535044745e-05\n",
      "Epoch 4653, Loss: 7.065040699671954e-05, Final Batch Loss: 2.4087912606773898e-05\n",
      "Epoch 4654, Loss: 0.00018790314425132237, Final Batch Loss: 4.4361655454849824e-05\n",
      "Epoch 4655, Loss: 2.7856963242811617e-05, Final Batch Loss: 1.4227392057364341e-05\n",
      "Epoch 4656, Loss: 2.644585674715927e-05, Final Batch Loss: 8.35033006296726e-06\n",
      "Epoch 4657, Loss: 0.00019791971044469392, Final Batch Loss: 1.1104652912763413e-05\n",
      "Epoch 4658, Loss: 5.75889389438089e-05, Final Batch Loss: 1.7189890058944002e-05\n",
      "Epoch 4659, Loss: 6.930169683982967e-05, Final Batch Loss: 6.8114145506115165e-06\n",
      "Epoch 4660, Loss: 0.00017177853942484944, Final Batch Loss: 4.098275439901045e-06\n",
      "Epoch 4661, Loss: 0.00018716242630034685, Final Batch Loss: 9.570753900334239e-05\n",
      "Epoch 4662, Loss: 0.003440663953369949, Final Batch Loss: 5.905426951358095e-05\n",
      "Epoch 4663, Loss: 0.0001741180894896388, Final Batch Loss: 7.903319055913016e-05\n",
      "Epoch 4664, Loss: 0.00032320263744622935, Final Batch Loss: 1.4905179341440089e-05\n",
      "Epoch 4665, Loss: 0.0004498284761211835, Final Batch Loss: 0.0003489843802526593\n",
      "Epoch 4666, Loss: 9.778190360520966e-05, Final Batch Loss: 2.1559961169259623e-05\n",
      "Epoch 4667, Loss: 3.025934347533621e-05, Final Batch Loss: 5.85688030696474e-06\n",
      "Epoch 4668, Loss: 0.0011711271909007337, Final Batch Loss: 2.7821395633509383e-05\n",
      "Epoch 4669, Loss: 1.7055374883057084e-05, Final Batch Loss: 4.868533324042801e-06\n",
      "Epoch 4670, Loss: 0.0001972208010556642, Final Batch Loss: 2.0771538402186707e-05\n",
      "Epoch 4671, Loss: 0.0002344332579014008, Final Batch Loss: 0.00022491604613605887\n",
      "Epoch 4672, Loss: 6.227445010154042e-05, Final Batch Loss: 2.1630154151353054e-05\n",
      "Epoch 4673, Loss: 0.0001655893647694029, Final Batch Loss: 6.0174956161063164e-05\n",
      "Epoch 4674, Loss: 4.586739214573754e-05, Final Batch Loss: 1.280844571738271e-05\n",
      "Epoch 4675, Loss: 0.00022409375196730252, Final Batch Loss: 1.6828742445795797e-05\n",
      "Epoch 4676, Loss: 2.5180212787745404e-05, Final Batch Loss: 2.4352054879273055e-06\n",
      "Epoch 4677, Loss: 7.899958927737316e-05, Final Batch Loss: 8.08968525234377e-06\n",
      "Epoch 4678, Loss: 0.0001356794819002971, Final Batch Loss: 5.1303140935488045e-05\n",
      "Epoch 4679, Loss: 0.0012624550709006144, Final Batch Loss: 0.0012322686379775405\n",
      "Epoch 4680, Loss: 4.1114099531114334e-05, Final Batch Loss: 7.358174570981646e-06\n",
      "Epoch 4681, Loss: 0.00023591207900608424, Final Batch Loss: 8.424796760664321e-06\n",
      "Epoch 4682, Loss: 0.00012199826960568316, Final Batch Loss: 5.049046376370825e-05\n",
      "Epoch 4683, Loss: 6.95542312314501e-05, Final Batch Loss: 4.326664929976687e-05\n",
      "Epoch 4684, Loss: 0.0003107243783233571, Final Batch Loss: 1.2415209312166553e-05\n",
      "Epoch 4685, Loss: 0.0006647884147241712, Final Batch Loss: 0.00034559794585220516\n",
      "Epoch 4686, Loss: 0.0023765663590893382, Final Batch Loss: 2.04180341825122e-05\n",
      "Epoch 4687, Loss: 0.0005072518561064498, Final Batch Loss: 2.1247253243927844e-05\n",
      "Epoch 4688, Loss: 4.087787965545431e-05, Final Batch Loss: 1.9658958990476094e-05\n",
      "Epoch 4689, Loss: 2.1996198938722955e-05, Final Batch Loss: 1.4994613593444228e-05\n",
      "Epoch 4690, Loss: 0.0006603542362881853, Final Batch Loss: 2.531706968511571e-06\n",
      "Epoch 4691, Loss: 7.097781235643197e-05, Final Batch Loss: 5.217943180468865e-05\n",
      "Epoch 4692, Loss: 0.0009113726664509159, Final Batch Loss: 2.2681790142087266e-05\n",
      "Epoch 4693, Loss: 0.00029498304502340034, Final Batch Loss: 0.0002518307010177523\n",
      "Epoch 4694, Loss: 7.950314102345146e-05, Final Batch Loss: 2.236956061096862e-05\n",
      "Epoch 4695, Loss: 0.0035784518563559686, Final Batch Loss: 7.415118943754351e-06\n",
      "Epoch 4696, Loss: 4.420098457558197e-05, Final Batch Loss: 3.874530739267357e-05\n",
      "Epoch 4697, Loss: 3.615669356804574e-05, Final Batch Loss: 1.5247264855133835e-05\n",
      "Epoch 4698, Loss: 0.0001248664684680989, Final Batch Loss: 8.57648228702601e-06\n",
      "Epoch 4699, Loss: 0.00020248699047442642, Final Batch Loss: 0.00019497419998515397\n",
      "Epoch 4700, Loss: 0.0003139508971798932, Final Batch Loss: 1.918078305607196e-05\n",
      "Epoch 4701, Loss: 0.0009425743046449497, Final Batch Loss: 3.527141234371811e-05\n",
      "Epoch 4702, Loss: 9.493656762060709e-05, Final Batch Loss: 2.509200930944644e-05\n",
      "Epoch 4703, Loss: 0.00010825797289726324, Final Batch Loss: 6.652912270510569e-05\n",
      "Epoch 4704, Loss: 0.0010948882845696062, Final Batch Loss: 0.0009476373088546097\n",
      "Epoch 4705, Loss: 1.761664088917314e-05, Final Batch Loss: 5.352735115593532e-06\n",
      "Epoch 4706, Loss: 0.00037680574678233825, Final Batch Loss: 3.79056109522935e-05\n",
      "Epoch 4707, Loss: 0.000348119512636913, Final Batch Loss: 0.00030343924299813807\n",
      "Epoch 4708, Loss: 0.00021250768259051256, Final Batch Loss: 0.00015960955352056772\n",
      "Epoch 4709, Loss: 4.003885442216415e-05, Final Batch Loss: 2.017884071392473e-05\n",
      "Epoch 4710, Loss: 0.0002056793891824782, Final Batch Loss: 3.944500349462032e-05\n",
      "Epoch 4711, Loss: 0.00018885295139625669, Final Batch Loss: 0.00011546509631443769\n",
      "Epoch 4712, Loss: 0.0006406368338502944, Final Batch Loss: 0.0004991997848264873\n",
      "Epoch 4713, Loss: 6.928277070983313e-05, Final Batch Loss: 4.252371581969783e-05\n",
      "Epoch 4714, Loss: 5.250332833384164e-05, Final Batch Loss: 3.6625657230615616e-05\n",
      "Epoch 4715, Loss: 7.236691089929081e-05, Final Batch Loss: 3.195107274223119e-05\n",
      "Epoch 4716, Loss: 0.00015106284627108835, Final Batch Loss: 3.791540439124219e-05\n",
      "Epoch 4717, Loss: 0.00017538601969135925, Final Batch Loss: 2.133835369022563e-05\n",
      "Epoch 4718, Loss: 1.814120969356736e-05, Final Batch Loss: 9.723245057102758e-06\n",
      "Epoch 4719, Loss: 0.00022296074166661128, Final Batch Loss: 9.209360723616555e-05\n",
      "Epoch 4720, Loss: 7.301931157144281e-05, Final Batch Loss: 1.5131937516343896e-06\n",
      "Epoch 4721, Loss: 9.822272841120139e-05, Final Batch Loss: 4.52557833341416e-05\n",
      "Epoch 4722, Loss: 0.0015725790581200272, Final Batch Loss: 0.0014804010279476643\n",
      "Epoch 4723, Loss: 0.00959870658152795, Final Batch Loss: 0.009577441960573196\n",
      "Epoch 4724, Loss: 0.00012842714568250813, Final Batch Loss: 9.782498091226444e-05\n",
      "Epoch 4725, Loss: 0.0026927004219032824, Final Batch Loss: 0.002353465184569359\n",
      "Epoch 4726, Loss: 0.006273577715546708, Final Batch Loss: 2.0581557691912167e-05\n",
      "Epoch 4727, Loss: 0.0047587482404196635, Final Batch Loss: 0.00012913347745779902\n",
      "Epoch 4728, Loss: 0.00898337072680988, Final Batch Loss: 3.5444925288175e-06\n",
      "Epoch 4729, Loss: 0.00035059179663221585, Final Batch Loss: 1.5071488633111585e-05\n",
      "Epoch 4730, Loss: 0.0002929702468463802, Final Batch Loss: 2.5576455300324596e-06\n",
      "Epoch 4731, Loss: 0.0012413778458721936, Final Batch Loss: 0.0009520538151264191\n",
      "Epoch 4732, Loss: 0.0007156951869546901, Final Batch Loss: 4.274850289220922e-05\n",
      "Epoch 4733, Loss: 0.00020800813217647374, Final Batch Loss: 3.218490746803582e-05\n",
      "Epoch 4734, Loss: 5.6643127209099475e-05, Final Batch Loss: 4.416591036715545e-05\n",
      "Epoch 4735, Loss: 0.009443536822800525, Final Batch Loss: 0.009233423508703709\n",
      "Epoch 4736, Loss: 5.830854206578806e-05, Final Batch Loss: 3.127140007563867e-05\n",
      "Epoch 4737, Loss: 0.020123230875469744, Final Batch Loss: 0.018831485882401466\n",
      "Epoch 4738, Loss: 0.0008110729104373604, Final Batch Loss: 3.826283500529826e-05\n",
      "Epoch 4739, Loss: 0.0004283494854462333, Final Batch Loss: 0.00010953887976938859\n",
      "Epoch 4740, Loss: 0.00011795781574619468, Final Batch Loss: 9.463296737521887e-05\n",
      "Epoch 4741, Loss: 0.004099007672948574, Final Batch Loss: 1.7159388789877994e-06\n",
      "Epoch 4742, Loss: 0.012967422108431492, Final Batch Loss: 0.012963320128619671\n",
      "Epoch 4743, Loss: 0.0010208595485892147, Final Batch Loss: 0.0002009370073210448\n",
      "Epoch 4744, Loss: 7.187313326539879e-05, Final Batch Loss: 2.5503775304969167e-06\n",
      "Epoch 4745, Loss: 0.0002756559233603184, Final Batch Loss: 9.941123607859481e-06\n",
      "Epoch 4746, Loss: 2.4997001673909836e-05, Final Batch Loss: 1.326052824879298e-05\n",
      "Epoch 4747, Loss: 0.00014599454789276933, Final Batch Loss: 9.069494808500167e-06\n",
      "Epoch 4748, Loss: 0.0003430779106565751, Final Batch Loss: 2.8725953598041087e-05\n",
      "Epoch 4749, Loss: 0.00582603455404751, Final Batch Loss: 0.0003038807481061667\n",
      "Epoch 4750, Loss: 0.0006162381905596703, Final Batch Loss: 0.00025562700466252863\n",
      "Epoch 4751, Loss: 7.647435995750129e-05, Final Batch Loss: 3.599252158892341e-05\n",
      "Epoch 4752, Loss: 5.641002280754037e-05, Final Batch Loss: 1.3429194950731471e-05\n",
      "Epoch 4753, Loss: 4.140154669585172e-05, Final Batch Loss: 1.972715836018324e-05\n",
      "Epoch 4754, Loss: 4.9336500524077564e-05, Final Batch Loss: 1.2790067557943985e-05\n",
      "Epoch 4755, Loss: 2.761694213404553e-05, Final Batch Loss: 1.7314823708147742e-05\n",
      "Epoch 4756, Loss: 0.0007106341108737979, Final Batch Loss: 0.0006825437885709107\n",
      "Epoch 4757, Loss: 1.3123049484420335e-05, Final Batch Loss: 8.864183655532543e-06\n",
      "Epoch 4758, Loss: 0.014238395378924906, Final Batch Loss: 0.014046408236026764\n",
      "Epoch 4759, Loss: 0.00031707990638096817, Final Batch Loss: 1.0491308785276487e-05\n",
      "Epoch 4760, Loss: 5.0318953071837313e-05, Final Batch Loss: 1.927080847963225e-05\n",
      "Epoch 4761, Loss: 2.652293869687128e-05, Final Batch Loss: 7.0033652264100965e-06\n",
      "Epoch 4762, Loss: 6.0690281316055916e-05, Final Batch Loss: 4.711882138508372e-05\n",
      "Epoch 4763, Loss: 0.0005508742815436563, Final Batch Loss: 1.9140896256431006e-05\n",
      "Epoch 4764, Loss: 0.00015159113172558136, Final Batch Loss: 2.3537406377727166e-05\n",
      "Epoch 4765, Loss: 0.1737171834865876, Final Batch Loss: 0.1736832708120346\n",
      "Epoch 4766, Loss: 3.477746440694318e-05, Final Batch Loss: 5.255559244687902e-06\n",
      "Epoch 4767, Loss: 0.004443721840289072, Final Batch Loss: 2.4819741156534292e-05\n",
      "Epoch 4768, Loss: 0.03310903627425432, Final Batch Loss: 0.018408093601465225\n",
      "Epoch 4769, Loss: 0.05619967234088108, Final Batch Loss: 0.00017583247972652316\n",
      "Epoch 4770, Loss: 0.004367084449768299, Final Batch Loss: 5.567886182689108e-05\n",
      "Epoch 4771, Loss: 0.0010155220297747292, Final Batch Loss: 4.494554741540924e-05\n",
      "Epoch 4772, Loss: 0.0005079158581793308, Final Batch Loss: 0.0003022682503797114\n",
      "Epoch 4773, Loss: 0.0005305549566401169, Final Batch Loss: 0.00013741424481850117\n",
      "Epoch 4774, Loss: 0.03262379378065816, Final Batch Loss: 0.03258352354168892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4775, Loss: 0.05187202354136389, Final Batch Loss: 0.0001851033157436177\n",
      "Epoch 4776, Loss: 0.007198018138296902, Final Batch Loss: 0.007124388124793768\n",
      "Epoch 4777, Loss: 0.02365486789494753, Final Batch Loss: 0.01613985188305378\n",
      "Epoch 4778, Loss: 0.047263532876968384, Final Batch Loss: 0.010607041418552399\n",
      "Epoch 4779, Loss: 0.04094703681766987, Final Batch Loss: 0.008472306653857231\n",
      "Epoch 4780, Loss: 0.002931488095782697, Final Batch Loss: 0.002219666261225939\n",
      "Epoch 4781, Loss: 0.0007022538047749549, Final Batch Loss: 0.00013256925740279257\n",
      "Epoch 4782, Loss: 0.00136065055266954, Final Batch Loss: 0.00042292315629310906\n",
      "Epoch 4783, Loss: 0.0017453833424951881, Final Batch Loss: 0.00038055735058151186\n",
      "Epoch 4784, Loss: 0.0011192129459232092, Final Batch Loss: 0.0006611568969674408\n",
      "Epoch 4785, Loss: 0.005797429010272026, Final Batch Loss: 0.0003504878841340542\n",
      "Epoch 4786, Loss: 0.0007871197012718767, Final Batch Loss: 6.462880992330611e-05\n",
      "Epoch 4787, Loss: 0.004475692170672119, Final Batch Loss: 0.0033317208290100098\n",
      "Epoch 4788, Loss: 0.0061358974780887365, Final Batch Loss: 0.0005396280903369188\n",
      "Epoch 4789, Loss: 0.0012113122502341866, Final Batch Loss: 0.0007659320253878832\n",
      "Epoch 4790, Loss: 0.0023726685903966427, Final Batch Loss: 0.001311062485910952\n",
      "Epoch 4791, Loss: 0.0010221777483820915, Final Batch Loss: 0.0003464307519607246\n",
      "Epoch 4792, Loss: 0.0006091622781241313, Final Batch Loss: 0.00015122797049116343\n",
      "Epoch 4793, Loss: 0.0001977297361008823, Final Batch Loss: 0.00014328128600027412\n",
      "Epoch 4794, Loss: 0.003946170909330249, Final Batch Loss: 0.0030735095497220755\n",
      "Epoch 4795, Loss: 0.001415766542777419, Final Batch Loss: 0.0006460148724727333\n",
      "Epoch 4796, Loss: 0.0014916999789420515, Final Batch Loss: 7.906908285804093e-05\n",
      "Epoch 4797, Loss: 0.0014990578638389707, Final Batch Loss: 0.0009925409685820341\n",
      "Epoch 4798, Loss: 0.0012638586922548711, Final Batch Loss: 0.0006625960231758654\n",
      "Epoch 4799, Loss: 0.00151537861165707, Final Batch Loss: 2.648892768775113e-05\n",
      "Epoch 4800, Loss: 0.0068987279664725065, Final Batch Loss: 0.002318652579560876\n",
      "Epoch 4801, Loss: 0.009613698231987655, Final Batch Loss: 0.0004814293934032321\n",
      "Epoch 4802, Loss: 0.000965212209848687, Final Batch Loss: 0.000788225675933063\n",
      "Epoch 4803, Loss: 0.00024041809956543148, Final Batch Loss: 0.00011872116010636091\n",
      "Epoch 4804, Loss: 0.0004834317951463163, Final Batch Loss: 0.0002591216762084514\n",
      "Epoch 4805, Loss: 0.0003819609701167792, Final Batch Loss: 0.00022217979130800813\n",
      "Epoch 4806, Loss: 0.0015997430673451163, Final Batch Loss: 6.414266681531444e-05\n",
      "Epoch 4807, Loss: 0.0023701327154412866, Final Batch Loss: 0.0005909440806135535\n",
      "Epoch 4808, Loss: 0.0009758477899595164, Final Batch Loss: 1.8430255295243114e-05\n",
      "Epoch 4809, Loss: 0.0006914479890838265, Final Batch Loss: 0.0002626709174364805\n",
      "Epoch 4810, Loss: 0.06575482955668122, Final Batch Loss: 0.001353821367956698\n",
      "Epoch 4811, Loss: 0.0013002370033063926, Final Batch Loss: 0.0011846618726849556\n",
      "Epoch 4812, Loss: 0.0010147399152629077, Final Batch Loss: 0.00037483900086954236\n",
      "Epoch 4813, Loss: 0.0010203486308455467, Final Batch Loss: 0.00023588008480146527\n",
      "Epoch 4814, Loss: 0.0006250055739656091, Final Batch Loss: 0.0003185236710123718\n",
      "Epoch 4815, Loss: 0.0003598543262341991, Final Batch Loss: 5.124679591972381e-05\n",
      "Epoch 4816, Loss: 0.0013527275586966425, Final Batch Loss: 0.00045681014307774603\n",
      "Epoch 4817, Loss: 0.00036031301715411246, Final Batch Loss: 0.00016018457245081663\n",
      "Epoch 4818, Loss: 0.0006648882190347649, Final Batch Loss: 0.0005963332951068878\n",
      "Epoch 4819, Loss: 0.001044999313307926, Final Batch Loss: 0.0006800004048272967\n",
      "Epoch 4820, Loss: 0.0020318751339800656, Final Batch Loss: 0.0012535653077065945\n",
      "Epoch 4821, Loss: 0.0022391202801372856, Final Batch Loss: 0.0018724438268691301\n",
      "Epoch 4822, Loss: 0.001496894888987299, Final Batch Loss: 0.0013886127853766084\n",
      "Epoch 4823, Loss: 0.0009154280705843121, Final Batch Loss: 0.00029081464163027704\n",
      "Epoch 4824, Loss: 0.0012383646972011775, Final Batch Loss: 0.00020054573542438447\n",
      "Epoch 4825, Loss: 0.0006544617790495977, Final Batch Loss: 0.0005051563493907452\n",
      "Epoch 4826, Loss: 0.0008128522749757394, Final Batch Loss: 0.00020444973779376596\n",
      "Epoch 4827, Loss: 0.00013975291949464008, Final Batch Loss: 7.505760731874034e-05\n",
      "Epoch 4828, Loss: 0.0003042297757929191, Final Batch Loss: 0.00021797134832013398\n",
      "Epoch 4829, Loss: 0.00011531205382198095, Final Batch Loss: 3.503546759020537e-05\n",
      "Epoch 4830, Loss: 0.003499880142044276, Final Batch Loss: 0.002950030378997326\n",
      "Epoch 4831, Loss: 0.003218073397874832, Final Batch Loss: 0.002661628182977438\n",
      "Epoch 4832, Loss: 0.0005591955268755555, Final Batch Loss: 6.41033984720707e-05\n",
      "Epoch 4833, Loss: 0.0010917813378910068, Final Batch Loss: 0.0010338644497096539\n",
      "Epoch 4834, Loss: 0.0004721517252619378, Final Batch Loss: 0.00036891887430101633\n",
      "Epoch 4835, Loss: 0.003800183883868158, Final Batch Loss: 0.0013683001743629575\n",
      "Epoch 4836, Loss: 0.0003113164893875364, Final Batch Loss: 2.270800541737117e-05\n",
      "Epoch 4837, Loss: 0.0007348771614488214, Final Batch Loss: 0.0006495523848570883\n",
      "Epoch 4838, Loss: 0.0003354703221702948, Final Batch Loss: 0.00015709770377725363\n",
      "Epoch 4839, Loss: 0.0013653863134095445, Final Batch Loss: 0.001172079355455935\n",
      "Epoch 4840, Loss: 0.0002053228090517223, Final Batch Loss: 0.00013608174049295485\n",
      "Epoch 4841, Loss: 0.0004538358080026228, Final Batch Loss: 0.0004005488008260727\n",
      "Epoch 4842, Loss: 0.0003104315837845206, Final Batch Loss: 0.00018244470993522555\n",
      "Epoch 4843, Loss: 0.001805522886570543, Final Batch Loss: 0.00014058867236599326\n",
      "Epoch 4844, Loss: 0.0006558547611348331, Final Batch Loss: 0.0004958566860295832\n",
      "Epoch 4845, Loss: 0.00029409619310172275, Final Batch Loss: 0.00021686128457076848\n",
      "Epoch 4846, Loss: 0.000654150775517337, Final Batch Loss: 0.00015636223542969674\n",
      "Epoch 4847, Loss: 0.0002376424272370059, Final Batch Loss: 0.0001822662743506953\n",
      "Epoch 4848, Loss: 9.660642535891384e-05, Final Batch Loss: 3.84694903914351e-05\n",
      "Epoch 4849, Loss: 0.0011542869688128121, Final Batch Loss: 5.888246960239485e-05\n",
      "Epoch 4850, Loss: 0.0003197982005076483, Final Batch Loss: 4.613188502844423e-05\n",
      "Epoch 4851, Loss: 0.00021199893308221363, Final Batch Loss: 5.2072919061174616e-05\n",
      "Epoch 4852, Loss: 0.0005578960699494928, Final Batch Loss: 0.00016921147471293807\n",
      "Epoch 4853, Loss: 0.0019360029109520838, Final Batch Loss: 7.058113988023251e-05\n",
      "Epoch 4854, Loss: 0.0007580015226267278, Final Batch Loss: 0.00025528366677463055\n",
      "Epoch 4855, Loss: 0.0003496264253044501, Final Batch Loss: 3.651336010079831e-05\n",
      "Epoch 4856, Loss: 0.0012477078707888722, Final Batch Loss: 0.0007640951662324369\n",
      "Epoch 4857, Loss: 0.00023328952374868095, Final Batch Loss: 7.436846499331295e-05\n",
      "Epoch 4858, Loss: 0.0003831003559753299, Final Batch Loss: 0.00016103482630569488\n",
      "Epoch 4859, Loss: 0.0036613460215448868, Final Batch Loss: 4.1842326027108356e-05\n",
      "Epoch 4860, Loss: 0.0010097380436491221, Final Batch Loss: 0.0002346005931030959\n",
      "Epoch 4861, Loss: 0.0001670575002208352, Final Batch Loss: 0.00012195867020636797\n",
      "Epoch 4862, Loss: 0.00022465476649813354, Final Batch Loss: 4.442664794623852e-05\n",
      "Epoch 4863, Loss: 0.0002332534932065755, Final Batch Loss: 3.674723848234862e-05\n",
      "Epoch 4864, Loss: 0.0009285134146921337, Final Batch Loss: 0.00031269912142306566\n",
      "Epoch 4865, Loss: 0.0008256542132585309, Final Batch Loss: 0.000798186520114541\n",
      "Epoch 4866, Loss: 0.0019083057486568578, Final Batch Loss: 9.35892530833371e-05\n",
      "Epoch 4867, Loss: 0.00022806978086009622, Final Batch Loss: 8.975726086646318e-05\n",
      "Epoch 4868, Loss: 0.00039709429256618023, Final Batch Loss: 0.00019696557137649506\n",
      "Epoch 4869, Loss: 0.0010175211864407174, Final Batch Loss: 5.994980892864987e-05\n",
      "Epoch 4870, Loss: 0.0002861266584659461, Final Batch Loss: 0.00024370565370190889\n",
      "Epoch 4871, Loss: 7.36158308427548e-05, Final Batch Loss: 1.7629148715059273e-05\n",
      "Epoch 4872, Loss: 0.0002723302932281513, Final Batch Loss: 1.7449714505346492e-05\n",
      "Epoch 4873, Loss: 0.00013341890007723123, Final Batch Loss: 6.996309821261093e-05\n",
      "Epoch 4874, Loss: 0.0001248135304194875, Final Batch Loss: 8.350701682502404e-05\n",
      "Epoch 4875, Loss: 0.0007839738973416388, Final Batch Loss: 0.0005210672388784587\n",
      "Epoch 4876, Loss: 0.00021207228928687982, Final Batch Loss: 0.00017395104805473238\n",
      "Epoch 4877, Loss: 0.0004731950684799813, Final Batch Loss: 0.0004180037067271769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4878, Loss: 0.0007197207014542073, Final Batch Loss: 0.0006157918251119554\n",
      "Epoch 4879, Loss: 0.0002132200897904113, Final Batch Loss: 9.20099628274329e-05\n",
      "Epoch 4880, Loss: 0.0014316524320747703, Final Batch Loss: 0.0013464910443872213\n",
      "Epoch 4881, Loss: 0.00016215970390476286, Final Batch Loss: 7.948416168801486e-05\n",
      "Epoch 4882, Loss: 0.00021728668070863932, Final Batch Loss: 6.290448072832078e-05\n",
      "Epoch 4883, Loss: 0.003752157776034437, Final Batch Loss: 0.00012735695054288954\n",
      "Epoch 4884, Loss: 0.00011677872316795401, Final Batch Loss: 2.7621139452094212e-05\n",
      "Epoch 4885, Loss: 0.0003576659510144964, Final Batch Loss: 0.00028936509625054896\n",
      "Epoch 4886, Loss: 0.00012199682169011794, Final Batch Loss: 9.066922211786732e-05\n",
      "Epoch 4887, Loss: 0.0008136177129927091, Final Batch Loss: 0.0006974865100346506\n",
      "Epoch 4888, Loss: 7.111547165550292e-05, Final Batch Loss: 3.191687574144453e-05\n",
      "Epoch 4889, Loss: 0.00016509414490428753, Final Batch Loss: 5.0264967285329476e-05\n",
      "Epoch 4890, Loss: 0.00010427565575810149, Final Batch Loss: 3.164297231705859e-05\n",
      "Epoch 4891, Loss: 0.0012346053845249116, Final Batch Loss: 0.0005392375169321895\n",
      "Epoch 4892, Loss: 0.002433808367641177, Final Batch Loss: 0.002371277892962098\n",
      "Epoch 4893, Loss: 0.0013049384288024157, Final Batch Loss: 0.0012350035831332207\n",
      "Epoch 4894, Loss: 0.00013403363846009597, Final Batch Loss: 3.2735631975810975e-05\n",
      "Epoch 4895, Loss: 0.003545358049450442, Final Batch Loss: 0.003444087691605091\n",
      "Epoch 4896, Loss: 0.0002795977216010215, Final Batch Loss: 2.8105730962124653e-05\n",
      "Epoch 4897, Loss: 0.0006761772965546697, Final Batch Loss: 0.00016621153918094933\n",
      "Epoch 4898, Loss: 0.0011640301381703466, Final Batch Loss: 0.0003660414076875895\n",
      "Epoch 4899, Loss: 0.00034412351669743657, Final Batch Loss: 0.00014149615890346467\n",
      "Epoch 4900, Loss: 0.0033223514910787344, Final Batch Loss: 0.0026382585056126118\n",
      "Epoch 4901, Loss: 0.0004526485463429708, Final Batch Loss: 3.6914618249284104e-05\n",
      "Epoch 4902, Loss: 0.0003760566542041488, Final Batch Loss: 0.00010841835319297388\n",
      "Epoch 4903, Loss: 6.254499930946622e-05, Final Batch Loss: 1.5297677236958407e-05\n",
      "Epoch 4904, Loss: 4.508016718318686e-05, Final Batch Loss: 2.4197819584514946e-05\n",
      "Epoch 4905, Loss: 0.00011823002387245651, Final Batch Loss: 9.161751222563908e-05\n",
      "Epoch 4906, Loss: 0.00024669025879120454, Final Batch Loss: 7.358480797847733e-05\n",
      "Epoch 4907, Loss: 7.75761618569959e-05, Final Batch Loss: 3.527909575495869e-05\n",
      "Epoch 4908, Loss: 0.00041829675865301397, Final Batch Loss: 1.7707241568132304e-05\n",
      "Epoch 4909, Loss: 0.00030908504413673654, Final Batch Loss: 0.000245106901274994\n",
      "Epoch 4910, Loss: 0.000814718132460257, Final Batch Loss: 5.997984771966003e-05\n",
      "Epoch 4911, Loss: 0.001460040919482708, Final Batch Loss: 0.0009439769200980663\n",
      "Epoch 4912, Loss: 9.622272409615107e-05, Final Batch Loss: 3.33124517055694e-05\n",
      "Epoch 4913, Loss: 0.007098100846633315, Final Batch Loss: 0.005822801496833563\n",
      "Epoch 4914, Loss: 0.00022404266564990394, Final Batch Loss: 0.00016743832384236157\n",
      "Epoch 4915, Loss: 0.0001257322473975364, Final Batch Loss: 2.48103569902014e-05\n",
      "Epoch 4916, Loss: 0.0008559747220715508, Final Batch Loss: 0.0007611304172314703\n",
      "Epoch 4917, Loss: 0.0002855550246749772, Final Batch Loss: 2.7845087970490567e-05\n",
      "Epoch 4918, Loss: 0.00026968033125740476, Final Batch Loss: 0.0002294401201652363\n",
      "Epoch 4919, Loss: 0.0005248424167803023, Final Batch Loss: 4.210111001157202e-05\n",
      "Epoch 4920, Loss: 0.004889719333732501, Final Batch Loss: 0.004449878819286823\n",
      "Epoch 4921, Loss: 0.0005931936320848763, Final Batch Loss: 0.0004372727998998016\n",
      "Epoch 4922, Loss: 6.943030530237593e-05, Final Batch Loss: 3.23200220009312e-05\n",
      "Epoch 4923, Loss: 5.110904930916149e-05, Final Batch Loss: 1.7820670109358616e-05\n",
      "Epoch 4924, Loss: 9.030107139551546e-05, Final Batch Loss: 6.18250560364686e-05\n",
      "Epoch 4925, Loss: 0.0020313011773396283, Final Batch Loss: 0.0016254496295005083\n",
      "Epoch 4926, Loss: 0.000641497754259035, Final Batch Loss: 0.0003378479741513729\n",
      "Epoch 4927, Loss: 0.00026831136892724317, Final Batch Loss: 0.00024353778280783445\n",
      "Epoch 4928, Loss: 9.120993854594417e-05, Final Batch Loss: 2.0073948689969257e-05\n",
      "Epoch 4929, Loss: 0.00028852348623331636, Final Batch Loss: 9.782676352187991e-05\n",
      "Epoch 4930, Loss: 0.0001719942520139739, Final Batch Loss: 7.099418871803209e-05\n",
      "Epoch 4931, Loss: 0.0010582701725070365, Final Batch Loss: 4.105893458472565e-05\n",
      "Epoch 4932, Loss: 0.00020708902775368188, Final Batch Loss: 1.5288658687495627e-05\n",
      "Epoch 4933, Loss: 0.004918373393593356, Final Batch Loss: 0.004568865057080984\n",
      "Epoch 4934, Loss: 0.00011286067456239834, Final Batch Loss: 7.2188071499113e-05\n",
      "Epoch 4935, Loss: 0.0003727846633410081, Final Batch Loss: 0.00026526983128860593\n",
      "Epoch 4936, Loss: 8.232626169046853e-05, Final Batch Loss: 5.885865539312363e-05\n",
      "Epoch 4937, Loss: 0.00013285437671584077, Final Batch Loss: 3.454905890976079e-05\n",
      "Epoch 4938, Loss: 0.0001780615457391832, Final Batch Loss: 0.0001335371343884617\n",
      "Epoch 4939, Loss: 5.342684016795829e-05, Final Batch Loss: 2.8585733161889948e-05\n",
      "Epoch 4940, Loss: 0.0001966260388144292, Final Batch Loss: 5.73750221519731e-05\n",
      "Epoch 4941, Loss: 0.0182761611577007, Final Batch Loss: 3.995245060650632e-05\n",
      "Epoch 4942, Loss: 0.00011444592746556737, Final Batch Loss: 4.1888361010933295e-05\n",
      "Epoch 4943, Loss: 0.00029522230761358514, Final Batch Loss: 0.00020095377112738788\n",
      "Epoch 4944, Loss: 0.0004964490144629963, Final Batch Loss: 4.929793794872239e-05\n",
      "Epoch 4945, Loss: 0.0001299714349443093, Final Batch Loss: 6.357805250445381e-05\n",
      "Epoch 4946, Loss: 0.005392996434238739, Final Batch Loss: 0.00016504696395713836\n",
      "Epoch 4947, Loss: 0.00020307454542489722, Final Batch Loss: 0.00014940134133212268\n",
      "Epoch 4948, Loss: 0.0007089404098223895, Final Batch Loss: 0.0001438345352653414\n",
      "Epoch 4949, Loss: 0.0004989143344573677, Final Batch Loss: 2.677051816135645e-05\n",
      "Epoch 4950, Loss: 0.001051046321663307, Final Batch Loss: 4.2461924749659374e-05\n",
      "Epoch 4951, Loss: 0.0011467076110420749, Final Batch Loss: 0.0009722838294692338\n",
      "Epoch 4952, Loss: 0.000810516627097968, Final Batch Loss: 0.0007415346335619688\n",
      "Epoch 4953, Loss: 6.548444707732415e-05, Final Batch Loss: 5.313245492288843e-05\n",
      "Epoch 4954, Loss: 8.312943100463599e-05, Final Batch Loss: 3.843736703856848e-05\n",
      "Epoch 4955, Loss: 0.0005065894220024347, Final Batch Loss: 0.00017380350618623197\n",
      "Epoch 4956, Loss: 0.006769989442545921, Final Batch Loss: 0.00010634801583364606\n",
      "Epoch 4957, Loss: 0.00023371518909698352, Final Batch Loss: 0.00016842724289745092\n",
      "Epoch 4958, Loss: 0.0002216006614617072, Final Batch Loss: 0.00017696895520202816\n",
      "Epoch 4959, Loss: 0.0002991908786498243, Final Batch Loss: 1.2335638530203141e-05\n",
      "Epoch 4960, Loss: 0.0007561353772871371, Final Batch Loss: 5.8361833907838445e-06\n",
      "Epoch 4961, Loss: 0.00016072009020717815, Final Batch Loss: 0.0001257685071323067\n",
      "Epoch 4962, Loss: 0.0009074051631614566, Final Batch Loss: 9.6877571195364e-05\n",
      "Epoch 4963, Loss: 0.0030218145111575723, Final Batch Loss: 0.002436630195006728\n",
      "Epoch 4964, Loss: 0.0004377786099212244, Final Batch Loss: 0.00016739957209210843\n",
      "Epoch 4965, Loss: 0.0010330574441468343, Final Batch Loss: 0.0008864349802024662\n",
      "Epoch 4966, Loss: 7.457921674358658e-05, Final Batch Loss: 2.2289030312094837e-05\n",
      "Epoch 4967, Loss: 0.0004871529818046838, Final Batch Loss: 0.0002824233379215002\n",
      "Epoch 4968, Loss: 0.0001497300800110679, Final Batch Loss: 0.00012682328815571964\n",
      "Epoch 4969, Loss: 0.0011568738555070013, Final Batch Loss: 0.00020616300753317773\n",
      "Epoch 4970, Loss: 0.00035883899181499146, Final Batch Loss: 0.0003325194993522018\n",
      "Epoch 4971, Loss: 0.0013905897358199582, Final Batch Loss: 0.0001640152040636167\n",
      "Epoch 4972, Loss: 0.0060568022017832845, Final Batch Loss: 6.42289815004915e-05\n",
      "Epoch 4973, Loss: 5.7729886975721456e-05, Final Batch Loss: 4.0038514271145687e-05\n",
      "Epoch 4974, Loss: 6.820105045335367e-05, Final Batch Loss: 2.0229814253980294e-05\n",
      "Epoch 4975, Loss: 0.0001642701136006508, Final Batch Loss: 0.00010880701302085072\n",
      "Epoch 4976, Loss: 0.005326269136276096, Final Batch Loss: 0.005195025820285082\n",
      "Epoch 4977, Loss: 0.000978746946202591, Final Batch Loss: 0.0002570237556938082\n",
      "Epoch 4978, Loss: 0.0003058107031392865, Final Batch Loss: 2.827497519319877e-05\n",
      "Epoch 4979, Loss: 0.0003526154032442719, Final Batch Loss: 0.00019668399181682616\n",
      "Epoch 4980, Loss: 0.00020340790797490627, Final Batch Loss: 0.0001337598223472014\n",
      "Epoch 4981, Loss: 0.0001294166886509629, Final Batch Loss: 2.2794805772718973e-05\n",
      "Epoch 4982, Loss: 0.0001377485241391696, Final Batch Loss: 4.936413461109623e-05\n",
      "Epoch 4983, Loss: 0.00034800427238224074, Final Batch Loss: 0.00024261490034405142\n",
      "Epoch 4984, Loss: 0.0014786727842874825, Final Batch Loss: 0.0012791891349479556\n",
      "Epoch 4985, Loss: 0.001675642270129174, Final Batch Loss: 0.0006855711690150201\n",
      "Epoch 4986, Loss: 0.0005044926947448403, Final Batch Loss: 0.0003957774315495044\n",
      "Epoch 4987, Loss: 9.494939649812295e-05, Final Batch Loss: 7.050771728245309e-06\n",
      "Epoch 4988, Loss: 0.00017165551980724558, Final Batch Loss: 3.235751501051709e-05\n",
      "Epoch 4989, Loss: 0.000332513960529468, Final Batch Loss: 0.00030699229682795703\n",
      "Epoch 4990, Loss: 0.0004352439727881574, Final Batch Loss: 0.0004207701131235808\n",
      "Epoch 4991, Loss: 2.054205833701417e-05, Final Batch Loss: 1.3475193554768339e-05\n",
      "Epoch 4992, Loss: 0.00010130439659405965, Final Batch Loss: 7.289567292900756e-05\n",
      "Epoch 4993, Loss: 0.00016933261576923542, Final Batch Loss: 2.6316654839320108e-05\n",
      "Epoch 4994, Loss: 0.004238459663611138, Final Batch Loss: 0.0041824704967439175\n",
      "Epoch 4995, Loss: 0.0003994146445620572, Final Batch Loss: 2.2019279640517198e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4996, Loss: 0.0003771018600673415, Final Batch Loss: 9.612425492377952e-05\n",
      "Epoch 4997, Loss: 0.0022595155733142747, Final Batch Loss: 2.775399298116099e-05\n",
      "Epoch 4998, Loss: 0.00015091950081114192, Final Batch Loss: 1.786081884347368e-05\n",
      "Epoch 4999, Loss: 0.00016217594020417891, Final Batch Loss: 4.720985089079477e-05\n",
      "Epoch 5000, Loss: 9.661212789069396e-05, Final Batch Loss: 2.8368076527840458e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  0  0]\n",
      " [ 1 31  0]\n",
      " [ 0  0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97778   1.00000   0.98876        44\n",
      "           1    1.00000   0.96875   0.98413        32\n",
      "           2    1.00000   1.00000   1.00000        24\n",
      "\n",
      "    accuracy                        0.99000       100\n",
      "   macro avg    0.99259   0.98958   0.99096       100\n",
      "weighted avg    0.99022   0.99000   0.98998       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=106, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=46, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 106)\n",
    "load_model(gen, \"cGAN_UCI_Group_2_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 3)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  0  0]\n",
      " [ 0 38  0]\n",
      " [ 0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        34\n",
      "           1    1.00000   1.00000   1.00000        38\n",
      "           2    1.00000   1.00000   1.00000        28\n",
      "\n",
      "    accuracy                        1.00000       100\n",
      "   macro avg    1.00000   1.00000   1.00000       100\n",
      "weighted avg    1.00000   1.00000   1.00000       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 7:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.203994393348694, Final Batch Loss: 1.1000040769577026\n",
      "Epoch 2, Loss: 2.2036038637161255, Final Batch Loss: 1.101256012916565\n",
      "Epoch 3, Loss: 2.2006388902664185, Final Batch Loss: 1.1004390716552734\n",
      "Epoch 4, Loss: 2.202997922897339, Final Batch Loss: 1.1057400703430176\n",
      "Epoch 5, Loss: 2.1989552974700928, Final Batch Loss: 1.101136565208435\n",
      "Epoch 6, Loss: 2.1980044841766357, Final Batch Loss: 1.0986533164978027\n",
      "Epoch 7, Loss: 2.1947219371795654, Final Batch Loss: 1.0946176052093506\n",
      "Epoch 8, Loss: 2.194211959838867, Final Batch Loss: 1.0963627099990845\n",
      "Epoch 9, Loss: 2.193641781806946, Final Batch Loss: 1.0981088876724243\n",
      "Epoch 10, Loss: 2.1915544271469116, Final Batch Loss: 1.0959713459014893\n",
      "Epoch 11, Loss: 2.1894999742507935, Final Batch Loss: 1.0922125577926636\n",
      "Epoch 12, Loss: 2.1899948120117188, Final Batch Loss: 1.0988733768463135\n",
      "Epoch 13, Loss: 2.187502145767212, Final Batch Loss: 1.0931771993637085\n",
      "Epoch 14, Loss: 2.184057354927063, Final Batch Loss: 1.0904802083969116\n",
      "Epoch 15, Loss: 2.18410325050354, Final Batch Loss: 1.0966507196426392\n",
      "Epoch 16, Loss: 2.1796774864196777, Final Batch Loss: 1.0926343202590942\n",
      "Epoch 17, Loss: 2.1771234273910522, Final Batch Loss: 1.0939351320266724\n",
      "Epoch 18, Loss: 2.17251193523407, Final Batch Loss: 1.0786546468734741\n",
      "Epoch 19, Loss: 2.170679450035095, Final Batch Loss: 1.0826255083084106\n",
      "Epoch 20, Loss: 2.1650407314300537, Final Batch Loss: 1.0862921476364136\n",
      "Epoch 21, Loss: 2.1565663814544678, Final Batch Loss: 1.0744116306304932\n",
      "Epoch 22, Loss: 2.1529335975646973, Final Batch Loss: 1.0741498470306396\n",
      "Epoch 23, Loss: 2.144657254219055, Final Batch Loss: 1.0650582313537598\n",
      "Epoch 24, Loss: 2.1447452306747437, Final Batch Loss: 1.0705851316452026\n",
      "Epoch 25, Loss: 2.1364129781723022, Final Batch Loss: 1.066874623298645\n",
      "Epoch 26, Loss: 2.1284350156784058, Final Batch Loss: 1.064367651939392\n",
      "Epoch 27, Loss: 2.121874213218689, Final Batch Loss: 1.0511738061904907\n",
      "Epoch 28, Loss: 2.123214602470398, Final Batch Loss: 1.0647538900375366\n",
      "Epoch 29, Loss: 2.1177759170532227, Final Batch Loss: 1.0669000148773193\n",
      "Epoch 30, Loss: 2.1027005910873413, Final Batch Loss: 1.0476487874984741\n",
      "Epoch 31, Loss: 2.0930851697921753, Final Batch Loss: 1.048554539680481\n",
      "Epoch 32, Loss: 2.0706993341445923, Final Batch Loss: 1.0360385179519653\n",
      "Epoch 33, Loss: 2.0610570907592773, Final Batch Loss: 1.0266615152359009\n",
      "Epoch 34, Loss: 2.0471078157424927, Final Batch Loss: 1.021322250366211\n",
      "Epoch 35, Loss: 2.0345948934555054, Final Batch Loss: 1.0323090553283691\n",
      "Epoch 36, Loss: 2.0037550926208496, Final Batch Loss: 0.9968831539154053\n",
      "Epoch 37, Loss: 1.990057349205017, Final Batch Loss: 0.9947431683540344\n",
      "Epoch 38, Loss: 1.987381935119629, Final Batch Loss: 1.0028799772262573\n",
      "Epoch 39, Loss: 1.9517012238502502, Final Batch Loss: 0.984298586845398\n",
      "Epoch 40, Loss: 1.9541414976119995, Final Batch Loss: 0.9886050820350647\n",
      "Epoch 41, Loss: 1.9062796831130981, Final Batch Loss: 0.9735479950904846\n",
      "Epoch 42, Loss: 1.8729442954063416, Final Batch Loss: 0.9560542702674866\n",
      "Epoch 43, Loss: 1.8557003140449524, Final Batch Loss: 0.9361440539360046\n",
      "Epoch 44, Loss: 1.847281277179718, Final Batch Loss: 0.9357129335403442\n",
      "Epoch 45, Loss: 1.7943240404129028, Final Batch Loss: 0.9023114442825317\n",
      "Epoch 46, Loss: 1.7778122425079346, Final Batch Loss: 0.9057916402816772\n",
      "Epoch 47, Loss: 1.731520175933838, Final Batch Loss: 0.8584259152412415\n",
      "Epoch 48, Loss: 1.6854407787322998, Final Batch Loss: 0.8301857709884644\n",
      "Epoch 49, Loss: 1.6795061230659485, Final Batch Loss: 0.8286027908325195\n",
      "Epoch 50, Loss: 1.6513946056365967, Final Batch Loss: 0.8413860201835632\n",
      "Epoch 51, Loss: 1.6050286889076233, Final Batch Loss: 0.820769727230072\n",
      "Epoch 52, Loss: 1.5996195673942566, Final Batch Loss: 0.8173325657844543\n",
      "Epoch 53, Loss: 1.5316994786262512, Final Batch Loss: 0.7247267365455627\n",
      "Epoch 54, Loss: 1.5048065185546875, Final Batch Loss: 0.7382215857505798\n",
      "Epoch 55, Loss: 1.4957073330879211, Final Batch Loss: 0.7598416209220886\n",
      "Epoch 56, Loss: 1.44416344165802, Final Batch Loss: 0.70282381772995\n",
      "Epoch 57, Loss: 1.4333418011665344, Final Batch Loss: 0.7218068242073059\n",
      "Epoch 58, Loss: 1.3826241493225098, Final Batch Loss: 0.6378960609436035\n",
      "Epoch 59, Loss: 1.350582778453827, Final Batch Loss: 0.6720789670944214\n",
      "Epoch 60, Loss: 1.3302016258239746, Final Batch Loss: 0.6487451195716858\n",
      "Epoch 61, Loss: 1.2949806451797485, Final Batch Loss: 0.622742235660553\n",
      "Epoch 62, Loss: 1.2621325850486755, Final Batch Loss: 0.6575291156768799\n",
      "Epoch 63, Loss: 1.2694013118743896, Final Batch Loss: 0.6363543272018433\n",
      "Epoch 64, Loss: 1.1945255994796753, Final Batch Loss: 0.5644712448120117\n",
      "Epoch 65, Loss: 1.2180790305137634, Final Batch Loss: 0.6100823879241943\n",
      "Epoch 66, Loss: 1.196040689945221, Final Batch Loss: 0.5672441124916077\n",
      "Epoch 67, Loss: 1.1465625166893005, Final Batch Loss: 0.6001220941543579\n",
      "Epoch 68, Loss: 1.1444223523139954, Final Batch Loss: 0.5946139693260193\n",
      "Epoch 69, Loss: 1.1191925406455994, Final Batch Loss: 0.5469386577606201\n",
      "Epoch 70, Loss: 1.174955129623413, Final Batch Loss: 0.6464501619338989\n",
      "Epoch 71, Loss: 1.0776474475860596, Final Batch Loss: 0.5704876184463501\n",
      "Epoch 72, Loss: 1.1225053071975708, Final Batch Loss: 0.5634485483169556\n",
      "Epoch 73, Loss: 0.9795771241188049, Final Batch Loss: 0.4115946888923645\n",
      "Epoch 74, Loss: 1.0504848062992096, Final Batch Loss: 0.6156745553016663\n",
      "Epoch 75, Loss: 0.9589300751686096, Final Batch Loss: 0.4588606357574463\n",
      "Epoch 76, Loss: 0.9557878971099854, Final Batch Loss: 0.5025070309638977\n",
      "Epoch 77, Loss: 0.9767524898052216, Final Batch Loss: 0.48812615871429443\n",
      "Epoch 78, Loss: 0.9742758572101593, Final Batch Loss: 0.5090335607528687\n",
      "Epoch 79, Loss: 0.9051981568336487, Final Batch Loss: 0.4147438704967499\n",
      "Epoch 80, Loss: 0.9334000945091248, Final Batch Loss: 0.5198655128479004\n",
      "Epoch 81, Loss: 0.89189413189888, Final Batch Loss: 0.4247841536998749\n",
      "Epoch 82, Loss: 0.9121757447719574, Final Batch Loss: 0.46295851469039917\n",
      "Epoch 83, Loss: 0.8128667175769806, Final Batch Loss: 0.37618350982666016\n",
      "Epoch 84, Loss: 0.8372526466846466, Final Batch Loss: 0.3522038757801056\n",
      "Epoch 85, Loss: 0.807539165019989, Final Batch Loss: 0.3772446811199188\n",
      "Epoch 86, Loss: 0.8489223420619965, Final Batch Loss: 0.45136189460754395\n",
      "Epoch 87, Loss: 0.7921607196331024, Final Batch Loss: 0.4017643332481384\n",
      "Epoch 88, Loss: 0.7953595519065857, Final Batch Loss: 0.38316860795021057\n",
      "Epoch 89, Loss: 0.7431194186210632, Final Batch Loss: 0.38253623247146606\n",
      "Epoch 90, Loss: 0.7463858127593994, Final Batch Loss: 0.3729580342769623\n",
      "Epoch 91, Loss: 0.7148727476596832, Final Batch Loss: 0.31871315836906433\n",
      "Epoch 92, Loss: 0.745468020439148, Final Batch Loss: 0.4242786169052124\n",
      "Epoch 93, Loss: 0.7589388191699982, Final Batch Loss: 0.4183226227760315\n",
      "Epoch 94, Loss: 0.6787557005882263, Final Batch Loss: 0.38431549072265625\n",
      "Epoch 95, Loss: 0.6916936337947845, Final Batch Loss: 0.3201904296875\n",
      "Epoch 96, Loss: 0.6796447932720184, Final Batch Loss: 0.3081967830657959\n",
      "Epoch 97, Loss: 0.6018272042274475, Final Batch Loss: 0.2673739492893219\n",
      "Epoch 98, Loss: 0.6123415231704712, Final Batch Loss: 0.3017734885215759\n",
      "Epoch 99, Loss: 0.6512446105480194, Final Batch Loss: 0.3298656940460205\n",
      "Epoch 100, Loss: 0.6634753346443176, Final Batch Loss: 0.2976500988006592\n",
      "Epoch 101, Loss: 0.6392752528190613, Final Batch Loss: 0.32938358187675476\n",
      "Epoch 102, Loss: 0.6413993835449219, Final Batch Loss: 0.3261057138442993\n",
      "Epoch 103, Loss: 0.6135213673114777, Final Batch Loss: 0.2807280421257019\n",
      "Epoch 104, Loss: 0.5985468924045563, Final Batch Loss: 0.26776620745658875\n",
      "Epoch 105, Loss: 0.67218217253685, Final Batch Loss: 0.3440093994140625\n",
      "Epoch 106, Loss: 0.5896991193294525, Final Batch Loss: 0.2948976457118988\n",
      "Epoch 107, Loss: 0.6453483700752258, Final Batch Loss: 0.33311066031455994\n",
      "Epoch 108, Loss: 0.5916367173194885, Final Batch Loss: 0.3079638183116913\n",
      "Epoch 109, Loss: 0.5683942139148712, Final Batch Loss: 0.27520430088043213\n",
      "Epoch 110, Loss: 0.603389322757721, Final Batch Loss: 0.3418951630592346\n",
      "Epoch 111, Loss: 0.5857151448726654, Final Batch Loss: 0.33759117126464844\n",
      "Epoch 112, Loss: 0.5658693611621857, Final Batch Loss: 0.25616326928138733\n",
      "Epoch 113, Loss: 0.5663915574550629, Final Batch Loss: 0.24992433190345764\n",
      "Epoch 114, Loss: 0.6134976446628571, Final Batch Loss: 0.3241886496543884\n",
      "Epoch 115, Loss: 0.5282068252563477, Final Batch Loss: 0.25581952929496765\n",
      "Epoch 116, Loss: 0.5623826086521149, Final Batch Loss: 0.2749710977077484\n",
      "Epoch 117, Loss: 0.538163423538208, Final Batch Loss: 0.25153714418411255\n",
      "Epoch 118, Loss: 0.4924010783433914, Final Batch Loss: 0.24842509627342224\n",
      "Epoch 119, Loss: 0.5431885868310928, Final Batch Loss: 0.2376139611005783\n",
      "Epoch 120, Loss: 0.5399288833141327, Final Batch Loss: 0.23003873229026794\n",
      "Epoch 121, Loss: 0.5522566437721252, Final Batch Loss: 0.30971911549568176\n",
      "Epoch 122, Loss: 0.5456220209598541, Final Batch Loss: 0.2848915755748749\n",
      "Epoch 123, Loss: 0.49276183545589447, Final Batch Loss: 0.20849774777889252\n",
      "Epoch 124, Loss: 0.509601816534996, Final Batch Loss: 0.1890157014131546\n",
      "Epoch 125, Loss: 0.5016936808824539, Final Batch Loss: 0.258386492729187\n",
      "Epoch 126, Loss: 0.5013855248689651, Final Batch Loss: 0.23745130002498627\n",
      "Epoch 127, Loss: 0.496677428483963, Final Batch Loss: 0.220102459192276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128, Loss: 0.5674177408218384, Final Batch Loss: 0.2976674437522888\n",
      "Epoch 129, Loss: 0.5266542136669159, Final Batch Loss: 0.27424851059913635\n",
      "Epoch 130, Loss: 0.4543667584657669, Final Batch Loss: 0.21514616906642914\n",
      "Epoch 131, Loss: 0.5362471044063568, Final Batch Loss: 0.25385069847106934\n",
      "Epoch 132, Loss: 0.4971386045217514, Final Batch Loss: 0.23186607658863068\n",
      "Epoch 133, Loss: 0.5080455541610718, Final Batch Loss: 0.2624872028827667\n",
      "Epoch 134, Loss: 0.4606468081474304, Final Batch Loss: 0.23500239849090576\n",
      "Epoch 135, Loss: 0.49845369160175323, Final Batch Loss: 0.20715750753879547\n",
      "Epoch 136, Loss: 0.4613261818885803, Final Batch Loss: 0.20858940482139587\n",
      "Epoch 137, Loss: 0.5629709661006927, Final Batch Loss: 0.32899370789527893\n",
      "Epoch 138, Loss: 0.4720441848039627, Final Batch Loss: 0.23520930111408234\n",
      "Epoch 139, Loss: 0.48355691134929657, Final Batch Loss: 0.26621779799461365\n",
      "Epoch 140, Loss: 0.44323183596134186, Final Batch Loss: 0.19542397558689117\n",
      "Epoch 141, Loss: 0.48970717191696167, Final Batch Loss: 0.22687003016471863\n",
      "Epoch 142, Loss: 0.47206979990005493, Final Batch Loss: 0.24138949811458588\n",
      "Epoch 143, Loss: 0.48431496322155, Final Batch Loss: 0.20797277987003326\n",
      "Epoch 144, Loss: 0.4811237007379532, Final Batch Loss: 0.2715030610561371\n",
      "Epoch 145, Loss: 0.502913311123848, Final Batch Loss: 0.2771676778793335\n",
      "Epoch 146, Loss: 0.46811822056770325, Final Batch Loss: 0.2557260990142822\n",
      "Epoch 147, Loss: 0.5221756547689438, Final Batch Loss: 0.30363667011260986\n",
      "Epoch 148, Loss: 0.5093289166688919, Final Batch Loss: 0.2460431009531021\n",
      "Epoch 149, Loss: 0.5220372378826141, Final Batch Loss: 0.27050065994262695\n",
      "Epoch 150, Loss: 0.45775727927684784, Final Batch Loss: 0.2351343035697937\n",
      "Epoch 151, Loss: 0.45930737257003784, Final Batch Loss: 0.2237602025270462\n",
      "Epoch 152, Loss: 0.548802375793457, Final Batch Loss: 0.2901989817619324\n",
      "Epoch 153, Loss: 0.5062907487154007, Final Batch Loss: 0.24944598972797394\n",
      "Epoch 154, Loss: 0.456082284450531, Final Batch Loss: 0.20779375731945038\n",
      "Epoch 155, Loss: 0.4739619940519333, Final Batch Loss: 0.2715984880924225\n",
      "Epoch 156, Loss: 0.4612431824207306, Final Batch Loss: 0.2148810625076294\n",
      "Epoch 157, Loss: 0.4435158371925354, Final Batch Loss: 0.2667901813983917\n",
      "Epoch 158, Loss: 0.45686638355255127, Final Batch Loss: 0.2114374339580536\n",
      "Epoch 159, Loss: 0.5131726711988449, Final Batch Loss: 0.2674843966960907\n",
      "Epoch 160, Loss: 0.48323383927345276, Final Batch Loss: 0.2956438660621643\n",
      "Epoch 161, Loss: 0.47560927271842957, Final Batch Loss: 0.23833367228507996\n",
      "Epoch 162, Loss: 0.501344159245491, Final Batch Loss: 0.22697152197360992\n",
      "Epoch 163, Loss: 0.47279076278209686, Final Batch Loss: 0.2582290768623352\n",
      "Epoch 164, Loss: 0.42136040329933167, Final Batch Loss: 0.20433440804481506\n",
      "Epoch 165, Loss: 0.4416359215974808, Final Batch Loss: 0.20103640854358673\n",
      "Epoch 166, Loss: 0.4803222566843033, Final Batch Loss: 0.25760746002197266\n",
      "Epoch 167, Loss: 0.44320254027843475, Final Batch Loss: 0.17891551554203033\n",
      "Epoch 168, Loss: 0.4370805621147156, Final Batch Loss: 0.2271963655948639\n",
      "Epoch 169, Loss: 0.4475845694541931, Final Batch Loss: 0.20967060327529907\n",
      "Epoch 170, Loss: 0.5036531686782837, Final Batch Loss: 0.26549819111824036\n",
      "Epoch 171, Loss: 0.4659242331981659, Final Batch Loss: 0.2342052310705185\n",
      "Epoch 172, Loss: 0.44476111233234406, Final Batch Loss: 0.24762925505638123\n",
      "Epoch 173, Loss: 0.4343826323747635, Final Batch Loss: 0.2048712819814682\n",
      "Epoch 174, Loss: 0.42660069465637207, Final Batch Loss: 0.21675249934196472\n",
      "Epoch 175, Loss: 0.4074176400899887, Final Batch Loss: 0.19138947129249573\n",
      "Epoch 176, Loss: 0.42922912538051605, Final Batch Loss: 0.23576830327510834\n",
      "Epoch 177, Loss: 0.42302776873111725, Final Batch Loss: 0.2145121544599533\n",
      "Epoch 178, Loss: 0.4261194318532944, Final Batch Loss: 0.22649912536144257\n",
      "Epoch 179, Loss: 0.3998102992773056, Final Batch Loss: 0.1986866295337677\n",
      "Epoch 180, Loss: 0.4124258905649185, Final Batch Loss: 0.18583808839321136\n",
      "Epoch 181, Loss: 0.4294552654027939, Final Batch Loss: 0.21495020389556885\n",
      "Epoch 182, Loss: 0.38223637640476227, Final Batch Loss: 0.18866916000843048\n",
      "Epoch 183, Loss: 0.4353637397289276, Final Batch Loss: 0.2029392570257187\n",
      "Epoch 184, Loss: 0.4463380426168442, Final Batch Loss: 0.22481679916381836\n",
      "Epoch 185, Loss: 0.416763037443161, Final Batch Loss: 0.17125791311264038\n",
      "Epoch 186, Loss: 0.4238739609718323, Final Batch Loss: 0.20723839104175568\n",
      "Epoch 187, Loss: 0.4485538452863693, Final Batch Loss: 0.23851488530635834\n",
      "Epoch 188, Loss: 0.4483272433280945, Final Batch Loss: 0.20897163450717926\n",
      "Epoch 189, Loss: 0.4577442407608032, Final Batch Loss: 0.26241111755371094\n",
      "Epoch 190, Loss: 0.4137018769979477, Final Batch Loss: 0.19981421530246735\n",
      "Epoch 191, Loss: 0.45360755920410156, Final Batch Loss: 0.21670784056186676\n",
      "Epoch 192, Loss: 0.4325401782989502, Final Batch Loss: 0.2338659018278122\n",
      "Epoch 193, Loss: 0.4252767115831375, Final Batch Loss: 0.22890828549861908\n",
      "Epoch 194, Loss: 0.41697433590888977, Final Batch Loss: 0.17872080206871033\n",
      "Epoch 195, Loss: 0.4059111475944519, Final Batch Loss: 0.21285641193389893\n",
      "Epoch 196, Loss: 0.36456581950187683, Final Batch Loss: 0.15238462388515472\n",
      "Epoch 197, Loss: 0.4223001003265381, Final Batch Loss: 0.22508086264133453\n",
      "Epoch 198, Loss: 0.3759477436542511, Final Batch Loss: 0.15978467464447021\n",
      "Epoch 199, Loss: 0.4257098138332367, Final Batch Loss: 0.20786066353321075\n",
      "Epoch 200, Loss: 0.4201691746711731, Final Batch Loss: 0.2476278841495514\n",
      "Epoch 201, Loss: 0.41427280008792877, Final Batch Loss: 0.20956625044345856\n",
      "Epoch 202, Loss: 0.4038224220275879, Final Batch Loss: 0.22085826098918915\n",
      "Epoch 203, Loss: 0.44385071098804474, Final Batch Loss: 0.2731808125972748\n",
      "Epoch 204, Loss: 0.39128051698207855, Final Batch Loss: 0.15951533615589142\n",
      "Epoch 205, Loss: 0.41123394668102264, Final Batch Loss: 0.18032024800777435\n",
      "Epoch 206, Loss: 0.37815462052822113, Final Batch Loss: 0.17691288888454437\n",
      "Epoch 207, Loss: 0.4015132635831833, Final Batch Loss: 0.17814400792121887\n",
      "Epoch 208, Loss: 0.41260194778442383, Final Batch Loss: 0.22416682541370392\n",
      "Epoch 209, Loss: 0.387709379196167, Final Batch Loss: 0.21566849946975708\n",
      "Epoch 210, Loss: 0.41431809961795807, Final Batch Loss: 0.19275003671646118\n",
      "Epoch 211, Loss: 0.3841117322444916, Final Batch Loss: 0.2028297334909439\n",
      "Epoch 212, Loss: 0.38557107746601105, Final Batch Loss: 0.18259254097938538\n",
      "Epoch 213, Loss: 0.4340693950653076, Final Batch Loss: 0.2235950082540512\n",
      "Epoch 214, Loss: 0.44390806555747986, Final Batch Loss: 0.2597486078739166\n",
      "Epoch 215, Loss: 0.42829789221286774, Final Batch Loss: 0.23533451557159424\n",
      "Epoch 216, Loss: 0.40794216096401215, Final Batch Loss: 0.22657379508018494\n",
      "Epoch 217, Loss: 0.40647175908088684, Final Batch Loss: 0.20141224563121796\n",
      "Epoch 218, Loss: 0.392178937792778, Final Batch Loss: 0.18734025955200195\n",
      "Epoch 219, Loss: 0.35156309604644775, Final Batch Loss: 0.1382732093334198\n",
      "Epoch 220, Loss: 0.3965204656124115, Final Batch Loss: 0.22675032913684845\n",
      "Epoch 221, Loss: 0.4175645262002945, Final Batch Loss: 0.21612611413002014\n",
      "Epoch 222, Loss: 0.40350937843322754, Final Batch Loss: 0.20327483117580414\n",
      "Epoch 223, Loss: 0.424144983291626, Final Batch Loss: 0.2302267700433731\n",
      "Epoch 224, Loss: 0.38654039800167084, Final Batch Loss: 0.21731330454349518\n",
      "Epoch 225, Loss: 0.4159307926893234, Final Batch Loss: 0.18609167635440826\n",
      "Epoch 226, Loss: 0.4005075842142105, Final Batch Loss: 0.19192099571228027\n",
      "Epoch 227, Loss: 0.4205431640148163, Final Batch Loss: 0.27560093998908997\n",
      "Epoch 228, Loss: 0.38296449184417725, Final Batch Loss: 0.16814292967319489\n",
      "Epoch 229, Loss: 0.40478718280792236, Final Batch Loss: 0.2348458617925644\n",
      "Epoch 230, Loss: 0.3921206593513489, Final Batch Loss: 0.2088654339313507\n",
      "Epoch 231, Loss: 0.38853439688682556, Final Batch Loss: 0.17559748888015747\n",
      "Epoch 232, Loss: 0.3900064677000046, Final Batch Loss: 0.21932287514209747\n",
      "Epoch 233, Loss: 0.36939626932144165, Final Batch Loss: 0.18494722247123718\n",
      "Epoch 234, Loss: 0.3903271555900574, Final Batch Loss: 0.1839747428894043\n",
      "Epoch 235, Loss: 0.40926311910152435, Final Batch Loss: 0.2419537901878357\n",
      "Epoch 236, Loss: 0.3739485740661621, Final Batch Loss: 0.18730290234088898\n",
      "Epoch 237, Loss: 0.34586483240127563, Final Batch Loss: 0.16265860199928284\n",
      "Epoch 238, Loss: 0.40375906229019165, Final Batch Loss: 0.19592267274856567\n",
      "Epoch 239, Loss: 0.3854549378156662, Final Batch Loss: 0.20740574598312378\n",
      "Epoch 240, Loss: 0.3486759066581726, Final Batch Loss: 0.147955983877182\n",
      "Epoch 241, Loss: 0.3455958217382431, Final Batch Loss: 0.1726510375738144\n",
      "Epoch 242, Loss: 0.37930551171302795, Final Batch Loss: 0.16789932548999786\n",
      "Epoch 243, Loss: 0.379504531621933, Final Batch Loss: 0.19881190359592438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244, Loss: 0.3550427407026291, Final Batch Loss: 0.14504195749759674\n",
      "Epoch 245, Loss: 0.37607239186763763, Final Batch Loss: 0.17859001457691193\n",
      "Epoch 246, Loss: 0.38140495121479034, Final Batch Loss: 0.2273673266172409\n",
      "Epoch 247, Loss: 0.4077853262424469, Final Batch Loss: 0.1863686889410019\n",
      "Epoch 248, Loss: 0.3323471397161484, Final Batch Loss: 0.12703661620616913\n",
      "Epoch 249, Loss: 0.3363982290029526, Final Batch Loss: 0.15135131776332855\n",
      "Epoch 250, Loss: 0.3269941657781601, Final Batch Loss: 0.12466380000114441\n",
      "Epoch 251, Loss: 0.35731272399425507, Final Batch Loss: 0.14837545156478882\n",
      "Epoch 252, Loss: 0.35403119027614594, Final Batch Loss: 0.17411774396896362\n",
      "Epoch 253, Loss: 0.35961075127124786, Final Batch Loss: 0.20460404455661774\n",
      "Epoch 254, Loss: 0.372539222240448, Final Batch Loss: 0.19661827385425568\n",
      "Epoch 255, Loss: 0.36851900815963745, Final Batch Loss: 0.1743786782026291\n",
      "Epoch 256, Loss: 0.3602093905210495, Final Batch Loss: 0.19861602783203125\n",
      "Epoch 257, Loss: 0.35015183687210083, Final Batch Loss: 0.15312890708446503\n",
      "Epoch 258, Loss: 0.3264865279197693, Final Batch Loss: 0.17214570939540863\n",
      "Epoch 259, Loss: 0.34236791729927063, Final Batch Loss: 0.14816786348819733\n",
      "Epoch 260, Loss: 0.37528471648693085, Final Batch Loss: 0.1805907040834427\n",
      "Epoch 261, Loss: 0.36788032948970795, Final Batch Loss: 0.19460970163345337\n",
      "Epoch 262, Loss: 0.3583095371723175, Final Batch Loss: 0.19973675906658173\n",
      "Epoch 263, Loss: 0.37298645079135895, Final Batch Loss: 0.21023127436637878\n",
      "Epoch 264, Loss: 0.3319033533334732, Final Batch Loss: 0.14311876893043518\n",
      "Epoch 265, Loss: 0.34669679403305054, Final Batch Loss: 0.1943739801645279\n",
      "Epoch 266, Loss: 0.3729572296142578, Final Batch Loss: 0.22351175546646118\n",
      "Epoch 267, Loss: 0.35824112594127655, Final Batch Loss: 0.16940578818321228\n",
      "Epoch 268, Loss: 0.3737362325191498, Final Batch Loss: 0.200473815202713\n",
      "Epoch 269, Loss: 0.3397127836942673, Final Batch Loss: 0.17298002541065216\n",
      "Epoch 270, Loss: 0.3455383777618408, Final Batch Loss: 0.1467704325914383\n",
      "Epoch 271, Loss: 0.3026159852743149, Final Batch Loss: 0.13486061990261078\n",
      "Epoch 272, Loss: 0.3260260745882988, Final Batch Loss: 0.12319029122591019\n",
      "Epoch 273, Loss: 0.32307302206754684, Final Batch Loss: 0.12399137765169144\n",
      "Epoch 274, Loss: 0.33393990993499756, Final Batch Loss: 0.1602598875761032\n",
      "Epoch 275, Loss: 0.33904051780700684, Final Batch Loss: 0.14971746504306793\n",
      "Epoch 276, Loss: 0.3494963049888611, Final Batch Loss: 0.17824599146842957\n",
      "Epoch 277, Loss: 0.37743376195430756, Final Batch Loss: 0.20743553340435028\n",
      "Epoch 278, Loss: 0.37463195621967316, Final Batch Loss: 0.1854529231786728\n",
      "Epoch 279, Loss: 0.3471471220254898, Final Batch Loss: 0.13909083604812622\n",
      "Epoch 280, Loss: 0.3662192225456238, Final Batch Loss: 0.19147415459156036\n",
      "Epoch 281, Loss: 0.382050022482872, Final Batch Loss: 0.20821133255958557\n",
      "Epoch 282, Loss: 0.352637842297554, Final Batch Loss: 0.18120177090168\n",
      "Epoch 283, Loss: 0.37105925381183624, Final Batch Loss: 0.18608097732067108\n",
      "Epoch 284, Loss: 0.3846573382616043, Final Batch Loss: 0.1709042638540268\n",
      "Epoch 285, Loss: 0.3622736930847168, Final Batch Loss: 0.20751336216926575\n",
      "Epoch 286, Loss: 0.37469203770160675, Final Batch Loss: 0.17856140434741974\n",
      "Epoch 287, Loss: 0.2958809435367584, Final Batch Loss: 0.11838570237159729\n",
      "Epoch 288, Loss: 0.34227195382118225, Final Batch Loss: 0.17702724039554596\n",
      "Epoch 289, Loss: 0.3470737934112549, Final Batch Loss: 0.17929619550704956\n",
      "Epoch 290, Loss: 0.3196391463279724, Final Batch Loss: 0.15891140699386597\n",
      "Epoch 291, Loss: 0.32424691319465637, Final Batch Loss: 0.13400717079639435\n",
      "Epoch 292, Loss: 0.43282657861709595, Final Batch Loss: 0.20023088157176971\n",
      "Epoch 293, Loss: 0.3673117160797119, Final Batch Loss: 0.21318070590496063\n",
      "Epoch 294, Loss: 0.3838617205619812, Final Batch Loss: 0.2471528798341751\n",
      "Epoch 295, Loss: 0.3004743978381157, Final Batch Loss: 0.10624834150075912\n",
      "Epoch 296, Loss: 0.3182157725095749, Final Batch Loss: 0.14915363490581512\n",
      "Epoch 297, Loss: 0.3610348552465439, Final Batch Loss: 0.11976440250873566\n",
      "Epoch 298, Loss: 0.360314279794693, Final Batch Loss: 0.18488581478595734\n",
      "Epoch 299, Loss: 0.3302581459283829, Final Batch Loss: 0.1720115840435028\n",
      "Epoch 300, Loss: 0.34783293306827545, Final Batch Loss: 0.1661963313817978\n",
      "Epoch 301, Loss: 0.3285631537437439, Final Batch Loss: 0.16606943309307098\n",
      "Epoch 302, Loss: 0.32343149185180664, Final Batch Loss: 0.16652564704418182\n",
      "Epoch 303, Loss: 0.34927789866924286, Final Batch Loss: 0.1630910187959671\n",
      "Epoch 304, Loss: 0.324844554066658, Final Batch Loss: 0.158278226852417\n",
      "Epoch 305, Loss: 0.3845324069261551, Final Batch Loss: 0.23659536242485046\n",
      "Epoch 306, Loss: 0.3316393196582794, Final Batch Loss: 0.15895937383174896\n",
      "Epoch 307, Loss: 0.3315815031528473, Final Batch Loss: 0.15126493573188782\n",
      "Epoch 308, Loss: 0.351566806435585, Final Batch Loss: 0.17966748774051666\n",
      "Epoch 309, Loss: 0.375069722533226, Final Batch Loss: 0.23269681632518768\n",
      "Epoch 310, Loss: 0.2988825738430023, Final Batch Loss: 0.14739052951335907\n",
      "Epoch 311, Loss: 0.32656992971897125, Final Batch Loss: 0.1497916728258133\n",
      "Epoch 312, Loss: 0.33928218483924866, Final Batch Loss: 0.14700156450271606\n",
      "Epoch 313, Loss: 0.3554469496011734, Final Batch Loss: 0.18184776604175568\n",
      "Epoch 314, Loss: 0.3721410185098648, Final Batch Loss: 0.1845933496952057\n",
      "Epoch 315, Loss: 0.339494451880455, Final Batch Loss: 0.17780828475952148\n",
      "Epoch 316, Loss: 0.30789659917354584, Final Batch Loss: 0.1284722089767456\n",
      "Epoch 317, Loss: 0.3508664220571518, Final Batch Loss: 0.16658957302570343\n",
      "Epoch 318, Loss: 0.3334130346775055, Final Batch Loss: 0.1797340363264084\n",
      "Epoch 319, Loss: 0.39358390867710114, Final Batch Loss: 0.24437884986400604\n",
      "Epoch 320, Loss: 0.3170219361782074, Final Batch Loss: 0.14480090141296387\n",
      "Epoch 321, Loss: 0.32399775087833405, Final Batch Loss: 0.16837672889232635\n",
      "Epoch 322, Loss: 0.312618613243103, Final Batch Loss: 0.1276426911354065\n",
      "Epoch 323, Loss: 0.33560165762901306, Final Batch Loss: 0.1679566502571106\n",
      "Epoch 324, Loss: 0.3152441382408142, Final Batch Loss: 0.1600552797317505\n",
      "Epoch 325, Loss: 0.354669451713562, Final Batch Loss: 0.1745883971452713\n",
      "Epoch 326, Loss: 0.34281736612319946, Final Batch Loss: 0.185261070728302\n",
      "Epoch 327, Loss: 0.314565509557724, Final Batch Loss: 0.14887581765651703\n",
      "Epoch 328, Loss: 0.3494538515806198, Final Batch Loss: 0.1929938793182373\n",
      "Epoch 329, Loss: 0.31354252994060516, Final Batch Loss: 0.16343346238136292\n",
      "Epoch 330, Loss: 0.3548851013183594, Final Batch Loss: 0.199317067861557\n",
      "Epoch 331, Loss: 0.35437316447496414, Final Batch Loss: 0.24150775372982025\n",
      "Epoch 332, Loss: 0.3652064949274063, Final Batch Loss: 0.20498807728290558\n",
      "Epoch 333, Loss: 0.3154441565275192, Final Batch Loss: 0.13585036993026733\n",
      "Epoch 334, Loss: 0.3088456243276596, Final Batch Loss: 0.1358165442943573\n",
      "Epoch 335, Loss: 0.3529277741909027, Final Batch Loss: 0.17949554324150085\n",
      "Epoch 336, Loss: 0.2914605587720871, Final Batch Loss: 0.13320133090019226\n",
      "Epoch 337, Loss: 0.28448423743247986, Final Batch Loss: 0.1424228698015213\n",
      "Epoch 338, Loss: 0.32240167260169983, Final Batch Loss: 0.16944006085395813\n",
      "Epoch 339, Loss: 0.3221264183521271, Final Batch Loss: 0.1493130326271057\n",
      "Epoch 340, Loss: 0.3280156999826431, Final Batch Loss: 0.17943263053894043\n",
      "Epoch 341, Loss: 0.3408781960606575, Final Batch Loss: 0.23171447217464447\n",
      "Epoch 342, Loss: 0.36219918727874756, Final Batch Loss: 0.13771937787532806\n",
      "Epoch 343, Loss: 0.30110371112823486, Final Batch Loss: 0.14451298117637634\n",
      "Epoch 344, Loss: 0.34140075743198395, Final Batch Loss: 0.19522546231746674\n",
      "Epoch 345, Loss: 0.35781122744083405, Final Batch Loss: 0.18711213767528534\n",
      "Epoch 346, Loss: 0.31364499032497406, Final Batch Loss: 0.1484951674938202\n",
      "Epoch 347, Loss: 0.32630138099193573, Final Batch Loss: 0.1501196324825287\n",
      "Epoch 348, Loss: 0.3540785163640976, Final Batch Loss: 0.18876302242279053\n",
      "Epoch 349, Loss: 0.29636581242084503, Final Batch Loss: 0.17322123050689697\n",
      "Epoch 350, Loss: 0.3306096941232681, Final Batch Loss: 0.13523975014686584\n",
      "Epoch 351, Loss: 0.30666032433509827, Final Batch Loss: 0.1581581085920334\n",
      "Epoch 352, Loss: 0.3122010976076126, Final Batch Loss: 0.1476372331380844\n",
      "Epoch 353, Loss: 0.30947746336460114, Final Batch Loss: 0.16585764288902283\n",
      "Epoch 354, Loss: 0.3634055107831955, Final Batch Loss: 0.14701277017593384\n",
      "Epoch 355, Loss: 0.3094090670347214, Final Batch Loss: 0.1641763299703598\n",
      "Epoch 356, Loss: 0.3322157710790634, Final Batch Loss: 0.15801353752613068\n",
      "Epoch 357, Loss: 0.3167831003665924, Final Batch Loss: 0.16464464366436005\n",
      "Epoch 358, Loss: 0.340615838766098, Final Batch Loss: 0.17184917628765106\n",
      "Epoch 359, Loss: 0.34442681074142456, Final Batch Loss: 0.20069849491119385\n",
      "Epoch 360, Loss: 0.3557717949151993, Final Batch Loss: 0.20980802178382874\n",
      "Epoch 361, Loss: 0.3427906632423401, Final Batch Loss: 0.1876247078180313\n",
      "Epoch 362, Loss: 0.2829502522945404, Final Batch Loss: 0.13775303959846497\n",
      "Epoch 363, Loss: 0.32205528020858765, Final Batch Loss: 0.1922568827867508\n",
      "Epoch 364, Loss: 0.2778443992137909, Final Batch Loss: 0.12889304757118225\n",
      "Epoch 365, Loss: 0.28424906730651855, Final Batch Loss: 0.13337862491607666\n",
      "Epoch 366, Loss: 0.3228037506341934, Final Batch Loss: 0.174189031124115\n",
      "Epoch 367, Loss: 0.29366573691368103, Final Batch Loss: 0.15761339664459229\n",
      "Epoch 368, Loss: 0.33129072189331055, Final Batch Loss: 0.1659889966249466\n",
      "Epoch 369, Loss: 0.3170422315597534, Final Batch Loss: 0.177140474319458\n",
      "Epoch 370, Loss: 0.29564420878887177, Final Batch Loss: 0.13955383002758026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371, Loss: 0.2874445915222168, Final Batch Loss: 0.14541877806186676\n",
      "Epoch 372, Loss: 0.3043471872806549, Final Batch Loss: 0.14447379112243652\n",
      "Epoch 373, Loss: 0.3051585853099823, Final Batch Loss: 0.1723913550376892\n",
      "Epoch 374, Loss: 0.343403622508049, Final Batch Loss: 0.16411082446575165\n",
      "Epoch 375, Loss: 0.38067756593227386, Final Batch Loss: 0.18332035839557648\n",
      "Epoch 376, Loss: 0.3053204417228699, Final Batch Loss: 0.13332350552082062\n",
      "Epoch 377, Loss: 0.289621040225029, Final Batch Loss: 0.15044216811656952\n",
      "Epoch 378, Loss: 0.30614766478538513, Final Batch Loss: 0.15959088504314423\n",
      "Epoch 379, Loss: 0.30029359459877014, Final Batch Loss: 0.1550324708223343\n",
      "Epoch 380, Loss: 0.29631562530994415, Final Batch Loss: 0.1279747039079666\n",
      "Epoch 381, Loss: 0.3111584037542343, Final Batch Loss: 0.15001563727855682\n",
      "Epoch 382, Loss: 0.28665751218795776, Final Batch Loss: 0.13224001228809357\n",
      "Epoch 383, Loss: 0.27884015440940857, Final Batch Loss: 0.14505136013031006\n",
      "Epoch 384, Loss: 0.32282087206840515, Final Batch Loss: 0.15679778158664703\n",
      "Epoch 385, Loss: 0.2801625281572342, Final Batch Loss: 0.17466485500335693\n",
      "Epoch 386, Loss: 0.2764285057783127, Final Batch Loss: 0.11952342092990875\n",
      "Epoch 387, Loss: 0.3691300302743912, Final Batch Loss: 0.2163017839193344\n",
      "Epoch 388, Loss: 0.2907934635877609, Final Batch Loss: 0.16166411340236664\n",
      "Epoch 389, Loss: 0.29195402562618256, Final Batch Loss: 0.14411689341068268\n",
      "Epoch 390, Loss: 0.30746957659721375, Final Batch Loss: 0.14600087702274323\n",
      "Epoch 391, Loss: 0.2911217659711838, Final Batch Loss: 0.13492287695407867\n",
      "Epoch 392, Loss: 0.2906264066696167, Final Batch Loss: 0.14238472282886505\n",
      "Epoch 393, Loss: 0.28300485014915466, Final Batch Loss: 0.16957086324691772\n",
      "Epoch 394, Loss: 0.2764616459608078, Final Batch Loss: 0.13289423286914825\n",
      "Epoch 395, Loss: 0.2701716497540474, Final Batch Loss: 0.09991968423128128\n",
      "Epoch 396, Loss: 0.31162403523921967, Final Batch Loss: 0.15489605069160461\n",
      "Epoch 397, Loss: 0.3149784356355667, Final Batch Loss: 0.1506538838148117\n",
      "Epoch 398, Loss: 0.30039121210575104, Final Batch Loss: 0.11674319207668304\n",
      "Epoch 399, Loss: 0.3265542984008789, Final Batch Loss: 0.16574396193027496\n",
      "Epoch 400, Loss: 0.29344069957733154, Final Batch Loss: 0.16137148439884186\n",
      "Epoch 401, Loss: 0.28239570558071136, Final Batch Loss: 0.14023996889591217\n",
      "Epoch 402, Loss: 0.2664511725306511, Final Batch Loss: 0.1125272735953331\n",
      "Epoch 403, Loss: 0.31881532073020935, Final Batch Loss: 0.18191471695899963\n",
      "Epoch 404, Loss: 0.2925897538661957, Final Batch Loss: 0.11244472861289978\n",
      "Epoch 405, Loss: 0.2742195129394531, Final Batch Loss: 0.13722555339336395\n",
      "Epoch 406, Loss: 0.3351050615310669, Final Batch Loss: 0.18866069614887238\n",
      "Epoch 407, Loss: 0.2460724040865898, Final Batch Loss: 0.09881211072206497\n",
      "Epoch 408, Loss: 0.3190200477838516, Final Batch Loss: 0.17266744375228882\n",
      "Epoch 409, Loss: 0.26103147864341736, Final Batch Loss: 0.11267633736133575\n",
      "Epoch 410, Loss: 0.29944004118442535, Final Batch Loss: 0.11765800416469574\n",
      "Epoch 411, Loss: 0.27220870554447174, Final Batch Loss: 0.10058356821537018\n",
      "Epoch 412, Loss: 0.34125977754592896, Final Batch Loss: 0.1935303807258606\n",
      "Epoch 413, Loss: 0.2790820822119713, Final Batch Loss: 0.11904146522283554\n",
      "Epoch 414, Loss: 0.28902213275432587, Final Batch Loss: 0.19027985632419586\n",
      "Epoch 415, Loss: 0.30811750888824463, Final Batch Loss: 0.15332618355751038\n",
      "Epoch 416, Loss: 0.30392199754714966, Final Batch Loss: 0.1611466109752655\n",
      "Epoch 417, Loss: 0.24793417006731033, Final Batch Loss: 0.11969027668237686\n",
      "Epoch 418, Loss: 0.32935433089733124, Final Batch Loss: 0.21632853150367737\n",
      "Epoch 419, Loss: 0.25182632356882095, Final Batch Loss: 0.11708246916532516\n",
      "Epoch 420, Loss: 0.2664679065346718, Final Batch Loss: 0.11482513695955276\n",
      "Epoch 421, Loss: 0.34596188366413116, Final Batch Loss: 0.21923768520355225\n",
      "Epoch 422, Loss: 0.2692273110151291, Final Batch Loss: 0.1496042013168335\n",
      "Epoch 423, Loss: 0.27103930711746216, Final Batch Loss: 0.142771378159523\n",
      "Epoch 424, Loss: 0.30505193024873734, Final Batch Loss: 0.1850324124097824\n",
      "Epoch 425, Loss: 0.2783428132534027, Final Batch Loss: 0.14461706578731537\n",
      "Epoch 426, Loss: 0.3118012621998787, Final Batch Loss: 0.2007637321949005\n",
      "Epoch 427, Loss: 0.25506674498319626, Final Batch Loss: 0.14004641771316528\n",
      "Epoch 428, Loss: 0.28598977625370026, Final Batch Loss: 0.15246349573135376\n",
      "Epoch 429, Loss: 0.27179355919361115, Final Batch Loss: 0.13664847612380981\n",
      "Epoch 430, Loss: 0.2462514489889145, Final Batch Loss: 0.08330708742141724\n",
      "Epoch 431, Loss: 0.3118739575147629, Final Batch Loss: 0.12331980466842651\n",
      "Epoch 432, Loss: 0.2785862386226654, Final Batch Loss: 0.16670666635036469\n",
      "Epoch 433, Loss: 0.30427974462509155, Final Batch Loss: 0.1816035509109497\n",
      "Epoch 434, Loss: 0.2837728410959244, Final Batch Loss: 0.11955443024635315\n",
      "Epoch 435, Loss: 0.2695365473628044, Final Batch Loss: 0.11499319225549698\n",
      "Epoch 436, Loss: 0.2659408152103424, Final Batch Loss: 0.09957723319530487\n",
      "Epoch 437, Loss: 0.31579989194869995, Final Batch Loss: 0.16663329303264618\n",
      "Epoch 438, Loss: 0.2788095325231552, Final Batch Loss: 0.12131750583648682\n",
      "Epoch 439, Loss: 0.3449152708053589, Final Batch Loss: 0.19483448565006256\n",
      "Epoch 440, Loss: 0.31751854717731476, Final Batch Loss: 0.17405040562152863\n",
      "Epoch 441, Loss: 0.25835828483104706, Final Batch Loss: 0.09170053899288177\n",
      "Epoch 442, Loss: 0.243341825902462, Final Batch Loss: 0.10806881636381149\n",
      "Epoch 443, Loss: 0.28135690093040466, Final Batch Loss: 0.16075272858142853\n",
      "Epoch 444, Loss: 0.2726658508181572, Final Batch Loss: 0.1248653307557106\n",
      "Epoch 445, Loss: 0.25736718624830246, Final Batch Loss: 0.11593834310770035\n",
      "Epoch 446, Loss: 0.26363954693078995, Final Batch Loss: 0.12160799652338028\n",
      "Epoch 447, Loss: 0.2506447657942772, Final Batch Loss: 0.10406500846147537\n",
      "Epoch 448, Loss: 0.2564024180173874, Final Batch Loss: 0.13228893280029297\n",
      "Epoch 449, Loss: 0.26639556139707565, Final Batch Loss: 0.1668277084827423\n",
      "Epoch 450, Loss: 0.2958104833960533, Final Batch Loss: 0.1712678074836731\n",
      "Epoch 451, Loss: 0.2939640134572983, Final Batch Loss: 0.16802802681922913\n",
      "Epoch 452, Loss: 0.25870323181152344, Final Batch Loss: 0.13332198560237885\n",
      "Epoch 453, Loss: 0.2706443816423416, Final Batch Loss: 0.1331612765789032\n",
      "Epoch 454, Loss: 0.2820494845509529, Final Batch Loss: 0.15961052477359772\n",
      "Epoch 455, Loss: 0.3397633582353592, Final Batch Loss: 0.18432526290416718\n",
      "Epoch 456, Loss: 0.3366173654794693, Final Batch Loss: 0.21375900506973267\n",
      "Epoch 457, Loss: 0.28739385306835175, Final Batch Loss: 0.15698286890983582\n",
      "Epoch 458, Loss: 0.2962574362754822, Final Batch Loss: 0.1430206596851349\n",
      "Epoch 459, Loss: 0.2647007927298546, Final Batch Loss: 0.12442361563444138\n",
      "Epoch 460, Loss: 0.2684432715177536, Final Batch Loss: 0.1404782086610794\n",
      "Epoch 461, Loss: 0.27459756284952164, Final Batch Loss: 0.1669633388519287\n",
      "Epoch 462, Loss: 0.2879151329398155, Final Batch Loss: 0.12459438294172287\n",
      "Epoch 463, Loss: 0.257130429148674, Final Batch Loss: 0.12047463655471802\n",
      "Epoch 464, Loss: 0.2832443565130234, Final Batch Loss: 0.1386474221944809\n",
      "Epoch 465, Loss: 0.2808411121368408, Final Batch Loss: 0.1276383101940155\n",
      "Epoch 466, Loss: 0.29543551802635193, Final Batch Loss: 0.10115182399749756\n",
      "Epoch 467, Loss: 0.25854863971471786, Final Batch Loss: 0.114864282310009\n",
      "Epoch 468, Loss: 0.24453964084386826, Final Batch Loss: 0.1425638496875763\n",
      "Epoch 469, Loss: 0.3151448220014572, Final Batch Loss: 0.16776955127716064\n",
      "Epoch 470, Loss: 0.25242363661527634, Final Batch Loss: 0.14061371982097626\n",
      "Epoch 471, Loss: 0.2525367885828018, Final Batch Loss: 0.11681719124317169\n",
      "Epoch 472, Loss: 0.24768291413784027, Final Batch Loss: 0.13252444565296173\n",
      "Epoch 473, Loss: 0.26040019094944, Final Batch Loss: 0.11165651679039001\n",
      "Epoch 474, Loss: 0.24847429245710373, Final Batch Loss: 0.12617748975753784\n",
      "Epoch 475, Loss: 0.24486035853624344, Final Batch Loss: 0.11378435045480728\n",
      "Epoch 476, Loss: 0.2696617394685745, Final Batch Loss: 0.1294461339712143\n",
      "Epoch 477, Loss: 0.3091692626476288, Final Batch Loss: 0.18239136040210724\n",
      "Epoch 478, Loss: 0.2653702199459076, Final Batch Loss: 0.15112240612506866\n",
      "Epoch 479, Loss: 0.23966269195079803, Final Batch Loss: 0.13359718024730682\n",
      "Epoch 480, Loss: 0.2722179591655731, Final Batch Loss: 0.16417524218559265\n",
      "Epoch 481, Loss: 0.2292039468884468, Final Batch Loss: 0.10616704076528549\n",
      "Epoch 482, Loss: 0.24664194881916046, Final Batch Loss: 0.14457090198993683\n",
      "Epoch 483, Loss: 0.24962107092142105, Final Batch Loss: 0.08696519583463669\n",
      "Epoch 484, Loss: 0.2629821002483368, Final Batch Loss: 0.13078851997852325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485, Loss: 0.22161144763231277, Final Batch Loss: 0.10085417330265045\n",
      "Epoch 486, Loss: 0.2838738411664963, Final Batch Loss: 0.15134698152542114\n",
      "Epoch 487, Loss: 0.25530560314655304, Final Batch Loss: 0.1272004395723343\n",
      "Epoch 488, Loss: 0.24977990239858627, Final Batch Loss: 0.11743932217359543\n",
      "Epoch 489, Loss: 0.28361331671476364, Final Batch Loss: 0.11675506085157394\n",
      "Epoch 490, Loss: 0.26177211105823517, Final Batch Loss: 0.13473747670650482\n",
      "Epoch 491, Loss: 0.2637612149119377, Final Batch Loss: 0.1474112719297409\n",
      "Epoch 492, Loss: 0.2803846597671509, Final Batch Loss: 0.1318197399377823\n",
      "Epoch 493, Loss: 0.23917873203754425, Final Batch Loss: 0.10952308773994446\n",
      "Epoch 494, Loss: 0.283408522605896, Final Batch Loss: 0.14775873720645905\n",
      "Epoch 495, Loss: 0.2930910885334015, Final Batch Loss: 0.17783428728580475\n",
      "Epoch 496, Loss: 0.2978769391775131, Final Batch Loss: 0.16851933300495148\n",
      "Epoch 497, Loss: 0.29183343052864075, Final Batch Loss: 0.14601975679397583\n",
      "Epoch 498, Loss: 0.24684126675128937, Final Batch Loss: 0.12588395178318024\n",
      "Epoch 499, Loss: 0.25316815078258514, Final Batch Loss: 0.10655471682548523\n",
      "Epoch 500, Loss: 0.2338576391339302, Final Batch Loss: 0.09670846909284592\n",
      "Epoch 501, Loss: 0.3090796172618866, Final Batch Loss: 0.1802605390548706\n",
      "Epoch 502, Loss: 0.23823262751102448, Final Batch Loss: 0.11571751534938812\n",
      "Epoch 503, Loss: 0.25600939989089966, Final Batch Loss: 0.14428286254405975\n",
      "Epoch 504, Loss: 0.2582789212465286, Final Batch Loss: 0.12572862207889557\n",
      "Epoch 505, Loss: 0.2797280550003052, Final Batch Loss: 0.14692334830760956\n",
      "Epoch 506, Loss: 0.25052787363529205, Final Batch Loss: 0.11224555969238281\n",
      "Epoch 507, Loss: 0.23678988218307495, Final Batch Loss: 0.12155870348215103\n",
      "Epoch 508, Loss: 0.27281472086906433, Final Batch Loss: 0.12724992632865906\n",
      "Epoch 509, Loss: 0.18861576914787292, Final Batch Loss: 0.07192840427160263\n",
      "Epoch 510, Loss: 0.23254818469285965, Final Batch Loss: 0.08698668330907822\n",
      "Epoch 511, Loss: 0.2629820629954338, Final Batch Loss: 0.14305992424488068\n",
      "Epoch 512, Loss: 0.25547609478235245, Final Batch Loss: 0.11784590035676956\n",
      "Epoch 513, Loss: 0.29434968531131744, Final Batch Loss: 0.12124553322792053\n",
      "Epoch 514, Loss: 0.24937015771865845, Final Batch Loss: 0.12105652689933777\n",
      "Epoch 515, Loss: 0.25285349041223526, Final Batch Loss: 0.13173529505729675\n",
      "Epoch 516, Loss: 0.2663109451532364, Final Batch Loss: 0.13290472328662872\n",
      "Epoch 517, Loss: 0.21150373667478561, Final Batch Loss: 0.1071164533495903\n",
      "Epoch 518, Loss: 0.25863122940063477, Final Batch Loss: 0.11640028655529022\n",
      "Epoch 519, Loss: 0.22976231575012207, Final Batch Loss: 0.11842503398656845\n",
      "Epoch 520, Loss: 0.23978076875209808, Final Batch Loss: 0.11553500592708588\n",
      "Epoch 521, Loss: 0.23803319036960602, Final Batch Loss: 0.11983318626880646\n",
      "Epoch 522, Loss: 0.23077066987752914, Final Batch Loss: 0.13296614587306976\n",
      "Epoch 523, Loss: 0.2194974198937416, Final Batch Loss: 0.0916057750582695\n",
      "Epoch 524, Loss: 0.25087466835975647, Final Batch Loss: 0.12502776086330414\n",
      "Epoch 525, Loss: 0.2527364417910576, Final Batch Loss: 0.07411564141511917\n",
      "Epoch 526, Loss: 0.23798306286334991, Final Batch Loss: 0.10966452956199646\n",
      "Epoch 527, Loss: 0.23097185045480728, Final Batch Loss: 0.13964706659317017\n",
      "Epoch 528, Loss: 0.2365490421652794, Final Batch Loss: 0.13059288263320923\n",
      "Epoch 529, Loss: 0.21305285394191742, Final Batch Loss: 0.08900735527276993\n",
      "Epoch 530, Loss: 0.20788413286209106, Final Batch Loss: 0.10419988632202148\n",
      "Epoch 531, Loss: 0.27536696195602417, Final Batch Loss: 0.143072709441185\n",
      "Epoch 532, Loss: 0.23519713431596756, Final Batch Loss: 0.1201847493648529\n",
      "Epoch 533, Loss: 0.23717213422060013, Final Batch Loss: 0.10764973610639572\n",
      "Epoch 534, Loss: 0.21698515862226486, Final Batch Loss: 0.0928364098072052\n",
      "Epoch 535, Loss: 0.21325574815273285, Final Batch Loss: 0.11557064950466156\n",
      "Epoch 536, Loss: 0.23142408579587936, Final Batch Loss: 0.09526490420103073\n",
      "Epoch 537, Loss: 0.25667405873537064, Final Batch Loss: 0.10567935556173325\n",
      "Epoch 538, Loss: 0.23665693402290344, Final Batch Loss: 0.14410142600536346\n",
      "Epoch 539, Loss: 0.21618927270174026, Final Batch Loss: 0.09508948028087616\n",
      "Epoch 540, Loss: 0.1905713900923729, Final Batch Loss: 0.07343755662441254\n",
      "Epoch 541, Loss: 0.26258736103773117, Final Batch Loss: 0.15668107569217682\n",
      "Epoch 542, Loss: 0.24583367258310318, Final Batch Loss: 0.13928759098052979\n",
      "Epoch 543, Loss: 0.25569382309913635, Final Batch Loss: 0.1217292994260788\n",
      "Epoch 544, Loss: 0.2905126363039017, Final Batch Loss: 0.1798691600561142\n",
      "Epoch 545, Loss: 0.2822144627571106, Final Batch Loss: 0.1442474126815796\n",
      "Epoch 546, Loss: 0.25224974751472473, Final Batch Loss: 0.08862830698490143\n",
      "Epoch 547, Loss: 0.2295355200767517, Final Batch Loss: 0.073786661028862\n",
      "Epoch 548, Loss: 0.2163505256175995, Final Batch Loss: 0.08742992579936981\n",
      "Epoch 549, Loss: 0.2958909124135971, Final Batch Loss: 0.1495140641927719\n",
      "Epoch 550, Loss: 0.21496378630399704, Final Batch Loss: 0.07087104767560959\n",
      "Epoch 551, Loss: 0.24600915610790253, Final Batch Loss: 0.15403935313224792\n",
      "Epoch 552, Loss: 0.2313413843512535, Final Batch Loss: 0.12019245326519012\n",
      "Epoch 553, Loss: 0.2677273005247116, Final Batch Loss: 0.15397310256958008\n",
      "Epoch 554, Loss: 0.22944384068250656, Final Batch Loss: 0.07982733100652695\n",
      "Epoch 555, Loss: 0.26350776851177216, Final Batch Loss: 0.1273917257785797\n",
      "Epoch 556, Loss: 0.2872411161661148, Final Batch Loss: 0.14201346039772034\n",
      "Epoch 557, Loss: 0.23678771406412125, Final Batch Loss: 0.13406550884246826\n",
      "Epoch 558, Loss: 0.23739474266767502, Final Batch Loss: 0.1103910580277443\n",
      "Epoch 559, Loss: 0.24019338190555573, Final Batch Loss: 0.12939956784248352\n",
      "Epoch 560, Loss: 0.30056752264499664, Final Batch Loss: 0.1542711704969406\n",
      "Epoch 561, Loss: 0.22579479962587357, Final Batch Loss: 0.08926530927419662\n",
      "Epoch 562, Loss: 0.20499733835458755, Final Batch Loss: 0.08408715575933456\n",
      "Epoch 563, Loss: 0.20272286981344223, Final Batch Loss: 0.09019094705581665\n",
      "Epoch 564, Loss: 0.20944290608167648, Final Batch Loss: 0.09654849767684937\n",
      "Epoch 565, Loss: 0.29800642281770706, Final Batch Loss: 0.17840032279491425\n",
      "Epoch 566, Loss: 0.2770092263817787, Final Batch Loss: 0.17026348412036896\n",
      "Epoch 567, Loss: 0.2579282522201538, Final Batch Loss: 0.12896494567394257\n",
      "Epoch 568, Loss: 0.23450521379709244, Final Batch Loss: 0.12437298893928528\n",
      "Epoch 569, Loss: 0.23185620456933975, Final Batch Loss: 0.12126754969358444\n",
      "Epoch 570, Loss: 0.2345755249261856, Final Batch Loss: 0.12053821980953217\n",
      "Epoch 571, Loss: 0.2289079651236534, Final Batch Loss: 0.0903683677315712\n",
      "Epoch 572, Loss: 0.24986881017684937, Final Batch Loss: 0.11769938468933105\n",
      "Epoch 573, Loss: 0.23064812272787094, Final Batch Loss: 0.12228873372077942\n",
      "Epoch 574, Loss: 0.2256428226828575, Final Batch Loss: 0.09269393235445023\n",
      "Epoch 575, Loss: 0.20622673630714417, Final Batch Loss: 0.10332628339529037\n",
      "Epoch 576, Loss: 0.22002331912517548, Final Batch Loss: 0.11640657484531403\n",
      "Epoch 577, Loss: 0.29946912825107574, Final Batch Loss: 0.15596012771129608\n",
      "Epoch 578, Loss: 0.2130938321352005, Final Batch Loss: 0.09125479310750961\n",
      "Epoch 579, Loss: 0.24349520355463028, Final Batch Loss: 0.12674175202846527\n",
      "Epoch 580, Loss: 0.21159635484218597, Final Batch Loss: 0.11273655295372009\n",
      "Epoch 581, Loss: 0.20760861784219742, Final Batch Loss: 0.09497630596160889\n",
      "Epoch 582, Loss: 0.21948609501123428, Final Batch Loss: 0.09132292121648788\n",
      "Epoch 583, Loss: 0.2929455414414406, Final Batch Loss: 0.18359379470348358\n",
      "Epoch 584, Loss: 0.25033020228147507, Final Batch Loss: 0.15416471660137177\n",
      "Epoch 585, Loss: 0.2613157629966736, Final Batch Loss: 0.11074787378311157\n",
      "Epoch 586, Loss: 0.22588037699460983, Final Batch Loss: 0.10884398221969604\n",
      "Epoch 587, Loss: 0.22059178352355957, Final Batch Loss: 0.12245351821184158\n",
      "Epoch 588, Loss: 0.26920758932828903, Final Batch Loss: 0.14504115283489227\n",
      "Epoch 589, Loss: 0.2050229161977768, Final Batch Loss: 0.12532389163970947\n",
      "Epoch 590, Loss: 0.20584052801132202, Final Batch Loss: 0.08706329017877579\n",
      "Epoch 591, Loss: 0.2108081579208374, Final Batch Loss: 0.09539240598678589\n",
      "Epoch 592, Loss: 0.2350340485572815, Final Batch Loss: 0.10965809226036072\n",
      "Epoch 593, Loss: 0.2279479280114174, Final Batch Loss: 0.11849290132522583\n",
      "Epoch 594, Loss: 0.23545416444540024, Final Batch Loss: 0.12271127104759216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595, Loss: 0.2653873488306999, Final Batch Loss: 0.16342800855636597\n",
      "Epoch 596, Loss: 0.2578217536211014, Final Batch Loss: 0.16569624841213226\n",
      "Epoch 597, Loss: 0.21873369067907333, Final Batch Loss: 0.14256618916988373\n",
      "Epoch 598, Loss: 0.23202654719352722, Final Batch Loss: 0.12135341018438339\n",
      "Epoch 599, Loss: 0.2057155892252922, Final Batch Loss: 0.08765574544668198\n",
      "Epoch 600, Loss: 0.21695023030042648, Final Batch Loss: 0.07934247702360153\n",
      "Epoch 601, Loss: 0.2602027654647827, Final Batch Loss: 0.14431093633174896\n",
      "Epoch 602, Loss: 0.2300329953432083, Final Batch Loss: 0.13177242875099182\n",
      "Epoch 603, Loss: 0.2232941836118698, Final Batch Loss: 0.12002827227115631\n",
      "Epoch 604, Loss: 0.2261793166399002, Final Batch Loss: 0.0795702189207077\n",
      "Epoch 605, Loss: 0.19449759274721146, Final Batch Loss: 0.0918010026216507\n",
      "Epoch 606, Loss: 0.27023009955883026, Final Batch Loss: 0.1537812054157257\n",
      "Epoch 607, Loss: 0.23945948481559753, Final Batch Loss: 0.11672049760818481\n",
      "Epoch 608, Loss: 0.32216110825538635, Final Batch Loss: 0.21076276898384094\n",
      "Epoch 609, Loss: 0.22474277764558792, Final Batch Loss: 0.08808254450559616\n",
      "Epoch 610, Loss: 0.2560238093137741, Final Batch Loss: 0.15264995396137238\n",
      "Epoch 611, Loss: 0.2345215082168579, Final Batch Loss: 0.12360252439975739\n",
      "Epoch 612, Loss: 0.2176007628440857, Final Batch Loss: 0.1088426485657692\n",
      "Epoch 613, Loss: 0.22820042818784714, Final Batch Loss: 0.10814739763736725\n",
      "Epoch 614, Loss: 0.1993543952703476, Final Batch Loss: 0.06360390782356262\n",
      "Epoch 615, Loss: 0.23625874519348145, Final Batch Loss: 0.1182924285531044\n",
      "Epoch 616, Loss: 0.2445654645562172, Final Batch Loss: 0.09468335658311844\n",
      "Epoch 617, Loss: 0.2675940915942192, Final Batch Loss: 0.14843705296516418\n",
      "Epoch 618, Loss: 0.19800246506929398, Final Batch Loss: 0.09621833264827728\n",
      "Epoch 619, Loss: 0.23133698850870132, Final Batch Loss: 0.1443977653980255\n",
      "Epoch 620, Loss: 0.2561537101864815, Final Batch Loss: 0.14443740248680115\n",
      "Epoch 621, Loss: 0.22998256981372833, Final Batch Loss: 0.12592074275016785\n",
      "Epoch 622, Loss: 0.19530637562274933, Final Batch Loss: 0.09087871760129929\n",
      "Epoch 623, Loss: 0.26774103939533234, Final Batch Loss: 0.18872621655464172\n",
      "Epoch 624, Loss: 0.23834285885095596, Final Batch Loss: 0.14368897676467896\n",
      "Epoch 625, Loss: 0.2776651009917259, Final Batch Loss: 0.18310491740703583\n",
      "Epoch 626, Loss: 0.26457563787698746, Final Batch Loss: 0.11579661816358566\n",
      "Epoch 627, Loss: 0.25607243180274963, Final Batch Loss: 0.10116724669933319\n",
      "Epoch 628, Loss: 0.2382015511393547, Final Batch Loss: 0.12710435688495636\n",
      "Epoch 629, Loss: 0.29488836228847504, Final Batch Loss: 0.16568267345428467\n",
      "Epoch 630, Loss: 0.19253730028867722, Final Batch Loss: 0.0922636091709137\n",
      "Epoch 631, Loss: 0.22461790591478348, Final Batch Loss: 0.11124703288078308\n",
      "Epoch 632, Loss: 0.2489643692970276, Final Batch Loss: 0.1737438440322876\n",
      "Epoch 633, Loss: 0.24168353527784348, Final Batch Loss: 0.12038036435842514\n",
      "Epoch 634, Loss: 0.24835895746946335, Final Batch Loss: 0.1378040611743927\n",
      "Epoch 635, Loss: 0.20909641683101654, Final Batch Loss: 0.09731676429510117\n",
      "Epoch 636, Loss: 0.25557342171669006, Final Batch Loss: 0.11812794208526611\n",
      "Epoch 637, Loss: 0.2400486096739769, Final Batch Loss: 0.0965275838971138\n",
      "Epoch 638, Loss: 0.20349527895450592, Final Batch Loss: 0.1072152629494667\n",
      "Epoch 639, Loss: 0.21359648555517197, Final Batch Loss: 0.09635887295007706\n",
      "Epoch 640, Loss: 0.25898489356040955, Final Batch Loss: 0.1255485564470291\n",
      "Epoch 641, Loss: 0.19660792499780655, Final Batch Loss: 0.11042838543653488\n",
      "Epoch 642, Loss: 0.1924924999475479, Final Batch Loss: 0.07351385056972504\n",
      "Epoch 643, Loss: 0.2677372545003891, Final Batch Loss: 0.17679908871650696\n",
      "Epoch 644, Loss: 0.25841472297906876, Final Batch Loss: 0.1569553017616272\n",
      "Epoch 645, Loss: 0.21138212829828262, Final Batch Loss: 0.12244050949811935\n",
      "Epoch 646, Loss: 0.21295906603336334, Final Batch Loss: 0.08278177678585052\n",
      "Epoch 647, Loss: 0.20718279480934143, Final Batch Loss: 0.08912406116724014\n",
      "Epoch 648, Loss: 0.21619942039251328, Final Batch Loss: 0.09601516276597977\n",
      "Epoch 649, Loss: 0.22807951271533966, Final Batch Loss: 0.09777142107486725\n",
      "Epoch 650, Loss: 0.2211518958210945, Final Batch Loss: 0.11303931474685669\n",
      "Epoch 651, Loss: 0.24772866815328598, Final Batch Loss: 0.08906704932451248\n",
      "Epoch 652, Loss: 0.24954649060964584, Final Batch Loss: 0.14457939565181732\n",
      "Epoch 653, Loss: 0.2163207232952118, Final Batch Loss: 0.09169400483369827\n",
      "Epoch 654, Loss: 0.22849804908037186, Final Batch Loss: 0.08362757414579391\n",
      "Epoch 655, Loss: 0.23101335018873215, Final Batch Loss: 0.11567039042711258\n",
      "Epoch 656, Loss: 0.22064830362796783, Final Batch Loss: 0.11111252009868622\n",
      "Epoch 657, Loss: 0.2858012765645981, Final Batch Loss: 0.1505788266658783\n",
      "Epoch 658, Loss: 0.2321184277534485, Final Batch Loss: 0.12212947756052017\n",
      "Epoch 659, Loss: 0.24224907904863358, Final Batch Loss: 0.15033023059368134\n",
      "Epoch 660, Loss: 0.21985659003257751, Final Batch Loss: 0.07686582207679749\n",
      "Epoch 661, Loss: 0.19676803052425385, Final Batch Loss: 0.10533271729946136\n",
      "Epoch 662, Loss: 0.21687738597393036, Final Batch Loss: 0.11074291914701462\n",
      "Epoch 663, Loss: 0.24124322086572647, Final Batch Loss: 0.12515312433242798\n",
      "Epoch 664, Loss: 0.20107372850179672, Final Batch Loss: 0.0908828005194664\n",
      "Epoch 665, Loss: 0.22289152443408966, Final Batch Loss: 0.10655789822340012\n",
      "Epoch 666, Loss: 0.18964297324419022, Final Batch Loss: 0.09302041679620743\n",
      "Epoch 667, Loss: 0.2137087732553482, Final Batch Loss: 0.09450086951255798\n",
      "Epoch 668, Loss: 0.18235907703638077, Final Batch Loss: 0.0916578620672226\n",
      "Epoch 669, Loss: 0.2096797674894333, Final Batch Loss: 0.12004297971725464\n",
      "Epoch 670, Loss: 0.21344123780727386, Final Batch Loss: 0.11591760814189911\n",
      "Epoch 671, Loss: 0.25199144333601, Final Batch Loss: 0.13997139036655426\n",
      "Epoch 672, Loss: 0.18918541818857193, Final Batch Loss: 0.07225193828344345\n",
      "Epoch 673, Loss: 0.22744551301002502, Final Batch Loss: 0.10905029624700546\n",
      "Epoch 674, Loss: 0.21202319860458374, Final Batch Loss: 0.1138339638710022\n",
      "Epoch 675, Loss: 0.17314314097166061, Final Batch Loss: 0.07072899490594864\n",
      "Epoch 676, Loss: 0.21510422974824905, Final Batch Loss: 0.10152308642864227\n",
      "Epoch 677, Loss: 0.20628999918699265, Final Batch Loss: 0.08687736839056015\n",
      "Epoch 678, Loss: 0.23916149884462357, Final Batch Loss: 0.1287968009710312\n",
      "Epoch 679, Loss: 0.19710151106119156, Final Batch Loss: 0.10355404764413834\n",
      "Epoch 680, Loss: 0.2539616599678993, Final Batch Loss: 0.13868014514446259\n",
      "Epoch 681, Loss: 0.20785760134458542, Final Batch Loss: 0.10891706496477127\n",
      "Epoch 682, Loss: 0.22162757813930511, Final Batch Loss: 0.1325220912694931\n",
      "Epoch 683, Loss: 0.20673009008169174, Final Batch Loss: 0.11076552420854568\n",
      "Epoch 684, Loss: 0.21761366724967957, Final Batch Loss: 0.10652569681406021\n",
      "Epoch 685, Loss: 0.1961914300918579, Final Batch Loss: 0.08440537005662918\n",
      "Epoch 686, Loss: 0.1894528567790985, Final Batch Loss: 0.11102867126464844\n",
      "Epoch 687, Loss: 0.16487542539834976, Final Batch Loss: 0.0779746025800705\n",
      "Epoch 688, Loss: 0.18223857879638672, Final Batch Loss: 0.08412554115056992\n",
      "Epoch 689, Loss: 0.20486444234848022, Final Batch Loss: 0.08964131027460098\n",
      "Epoch 690, Loss: 0.22947729378938675, Final Batch Loss: 0.1242360845208168\n",
      "Epoch 691, Loss: 0.2313276082277298, Final Batch Loss: 0.12722474336624146\n",
      "Epoch 692, Loss: 0.2075783982872963, Final Batch Loss: 0.113859161734581\n",
      "Epoch 693, Loss: 0.2909204959869385, Final Batch Loss: 0.18710225820541382\n",
      "Epoch 694, Loss: 0.1880982555449009, Final Batch Loss: 0.056714195758104324\n",
      "Epoch 695, Loss: 0.24602071940898895, Final Batch Loss: 0.11421798169612885\n",
      "Epoch 696, Loss: 0.1928604543209076, Final Batch Loss: 0.06310752034187317\n",
      "Epoch 697, Loss: 0.2626562714576721, Final Batch Loss: 0.10362999141216278\n",
      "Epoch 698, Loss: 0.2191370278596878, Final Batch Loss: 0.1427951455116272\n",
      "Epoch 699, Loss: 0.2166450396180153, Final Batch Loss: 0.09659586101770401\n",
      "Epoch 700, Loss: 0.20831039547920227, Final Batch Loss: 0.09608017653226852\n",
      "Epoch 701, Loss: 0.1946004554629326, Final Batch Loss: 0.10471341758966446\n",
      "Epoch 702, Loss: 0.23063161969184875, Final Batch Loss: 0.11270629614591599\n",
      "Epoch 703, Loss: 0.19598521292209625, Final Batch Loss: 0.09308556467294693\n",
      "Epoch 704, Loss: 0.19687582552433014, Final Batch Loss: 0.10309017449617386\n",
      "Epoch 705, Loss: 0.22639299929141998, Final Batch Loss: 0.0962359607219696\n",
      "Epoch 706, Loss: 0.19184711575508118, Final Batch Loss: 0.10339394956827164\n",
      "Epoch 707, Loss: 0.21298722922801971, Final Batch Loss: 0.09931187331676483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708, Loss: 0.21673569083213806, Final Batch Loss: 0.1298317015171051\n",
      "Epoch 709, Loss: 0.2059333771467209, Final Batch Loss: 0.10891158133745193\n",
      "Epoch 710, Loss: 0.18817128986120224, Final Batch Loss: 0.08848167955875397\n",
      "Epoch 711, Loss: 0.19827013462781906, Final Batch Loss: 0.08938746899366379\n",
      "Epoch 712, Loss: 0.22221101820468903, Final Batch Loss: 0.10949874669313431\n",
      "Epoch 713, Loss: 0.20879025757312775, Final Batch Loss: 0.07837249338626862\n",
      "Epoch 714, Loss: 0.257585771381855, Final Batch Loss: 0.10044429451227188\n",
      "Epoch 715, Loss: 0.23472364246845245, Final Batch Loss: 0.0975300669670105\n",
      "Epoch 716, Loss: 0.22685369849205017, Final Batch Loss: 0.15900234878063202\n",
      "Epoch 717, Loss: 0.22662855684757233, Final Batch Loss: 0.12598523497581482\n",
      "Epoch 718, Loss: 0.2727481722831726, Final Batch Loss: 0.14513753354549408\n",
      "Epoch 719, Loss: 0.20063257962465286, Final Batch Loss: 0.1002906784415245\n",
      "Epoch 720, Loss: 0.22582998871803284, Final Batch Loss: 0.12627039849758148\n",
      "Epoch 721, Loss: 0.2294226735830307, Final Batch Loss: 0.09065987169742584\n",
      "Epoch 722, Loss: 0.19468173384666443, Final Batch Loss: 0.11380867660045624\n",
      "Epoch 723, Loss: 0.21184886246919632, Final Batch Loss: 0.10322539508342743\n",
      "Epoch 724, Loss: 0.2302234172821045, Final Batch Loss: 0.1288340985774994\n",
      "Epoch 725, Loss: 0.19611570984125137, Final Batch Loss: 0.11322875320911407\n",
      "Epoch 726, Loss: 0.19853194802999496, Final Batch Loss: 0.09539745002985\n",
      "Epoch 727, Loss: 0.21473029255867004, Final Batch Loss: 0.09609527885913849\n",
      "Epoch 728, Loss: 0.20333828032016754, Final Batch Loss: 0.09376011043787003\n",
      "Epoch 729, Loss: 0.16038750112056732, Final Batch Loss: 0.07115308195352554\n",
      "Epoch 730, Loss: 0.2189120277762413, Final Batch Loss: 0.12207694351673126\n",
      "Epoch 731, Loss: 0.277419775724411, Final Batch Loss: 0.14558137953281403\n",
      "Epoch 732, Loss: 0.24964341521263123, Final Batch Loss: 0.16154272854328156\n",
      "Epoch 733, Loss: 0.23420710116624832, Final Batch Loss: 0.11331608891487122\n",
      "Epoch 734, Loss: 0.18822813779115677, Final Batch Loss: 0.10412699729204178\n",
      "Epoch 735, Loss: 0.1657058745622635, Final Batch Loss: 0.0764743909239769\n",
      "Epoch 736, Loss: 0.21559803932905197, Final Batch Loss: 0.11260022222995758\n",
      "Epoch 737, Loss: 0.2008541151881218, Final Batch Loss: 0.08611030131578445\n",
      "Epoch 738, Loss: 0.23208550363779068, Final Batch Loss: 0.1485811024904251\n",
      "Epoch 739, Loss: 0.21620085090398788, Final Batch Loss: 0.10515976697206497\n",
      "Epoch 740, Loss: 0.1862427145242691, Final Batch Loss: 0.06283638626337051\n",
      "Epoch 741, Loss: 0.2147914171218872, Final Batch Loss: 0.11002177000045776\n",
      "Epoch 742, Loss: 0.19893406331539154, Final Batch Loss: 0.1146266981959343\n",
      "Epoch 743, Loss: 0.20250146090984344, Final Batch Loss: 0.09654229134321213\n",
      "Epoch 744, Loss: 0.21852970123291016, Final Batch Loss: 0.10166937857866287\n",
      "Epoch 745, Loss: 0.19963788241147995, Final Batch Loss: 0.09125860780477524\n",
      "Epoch 746, Loss: 0.2364184707403183, Final Batch Loss: 0.1325926035642624\n",
      "Epoch 747, Loss: 0.2280028983950615, Final Batch Loss: 0.12600578367710114\n",
      "Epoch 748, Loss: 0.1943216398358345, Final Batch Loss: 0.10387919843196869\n",
      "Epoch 749, Loss: 0.22834737598896027, Final Batch Loss: 0.11022607982158661\n",
      "Epoch 750, Loss: 0.19589054584503174, Final Batch Loss: 0.10402227938175201\n",
      "Epoch 751, Loss: 0.17755430936813354, Final Batch Loss: 0.07936818152666092\n",
      "Epoch 752, Loss: 0.1871965304017067, Final Batch Loss: 0.09405813366174698\n",
      "Epoch 753, Loss: 0.1890426054596901, Final Batch Loss: 0.08947844803333282\n",
      "Epoch 754, Loss: 0.1800360158085823, Final Batch Loss: 0.08517087250947952\n",
      "Epoch 755, Loss: 0.1939854845404625, Final Batch Loss: 0.09819941222667694\n",
      "Epoch 756, Loss: 0.19342823326587677, Final Batch Loss: 0.07353424280881882\n",
      "Epoch 757, Loss: 0.21322515606880188, Final Batch Loss: 0.08073402941226959\n",
      "Epoch 758, Loss: 0.20387441664934158, Final Batch Loss: 0.10141365230083466\n",
      "Epoch 759, Loss: 0.22320614755153656, Final Batch Loss: 0.10900735855102539\n",
      "Epoch 760, Loss: 0.22801902890205383, Final Batch Loss: 0.08542634546756744\n",
      "Epoch 761, Loss: 0.20453764498233795, Final Batch Loss: 0.09577802568674088\n",
      "Epoch 762, Loss: 0.2289499118924141, Final Batch Loss: 0.12403129041194916\n",
      "Epoch 763, Loss: 0.208741694688797, Final Batch Loss: 0.11502757668495178\n",
      "Epoch 764, Loss: 0.2476542741060257, Final Batch Loss: 0.13466063141822815\n",
      "Epoch 765, Loss: 0.20461564511060715, Final Batch Loss: 0.08855979144573212\n",
      "Epoch 766, Loss: 0.22923903167247772, Final Batch Loss: 0.11292228102684021\n",
      "Epoch 767, Loss: 0.20197968184947968, Final Batch Loss: 0.0801757276058197\n",
      "Epoch 768, Loss: 0.19229807704687119, Final Batch Loss: 0.07857200503349304\n",
      "Epoch 769, Loss: 0.2110021561384201, Final Batch Loss: 0.1293283998966217\n",
      "Epoch 770, Loss: 0.19411128759384155, Final Batch Loss: 0.08190473914146423\n",
      "Epoch 771, Loss: 0.2242327481508255, Final Batch Loss: 0.11218177527189255\n",
      "Epoch 772, Loss: 0.22636601328849792, Final Batch Loss: 0.15532858669757843\n",
      "Epoch 773, Loss: 0.1583181396126747, Final Batch Loss: 0.06607488542795181\n",
      "Epoch 774, Loss: 0.17164316400885582, Final Batch Loss: 0.05834135040640831\n",
      "Epoch 775, Loss: 0.20612549781799316, Final Batch Loss: 0.11663178354501724\n",
      "Epoch 776, Loss: 0.1759631335735321, Final Batch Loss: 0.10616528987884521\n",
      "Epoch 777, Loss: 0.20588617771863937, Final Batch Loss: 0.12204490602016449\n",
      "Epoch 778, Loss: 0.1879822164773941, Final Batch Loss: 0.10560543835163116\n",
      "Epoch 779, Loss: 0.20475950092077255, Final Batch Loss: 0.12080570310354233\n",
      "Epoch 780, Loss: 0.20372037589550018, Final Batch Loss: 0.10059592127799988\n",
      "Epoch 781, Loss: 0.15867853537201881, Final Batch Loss: 0.06209861859679222\n",
      "Epoch 782, Loss: 0.18537308275699615, Final Batch Loss: 0.09500227868556976\n",
      "Epoch 783, Loss: 0.1872032955288887, Final Batch Loss: 0.09886372834444046\n",
      "Epoch 784, Loss: 0.22575953602790833, Final Batch Loss: 0.12945859134197235\n",
      "Epoch 785, Loss: 0.22394758462905884, Final Batch Loss: 0.11733321100473404\n",
      "Epoch 786, Loss: 0.16675151884555817, Final Batch Loss: 0.0822816863656044\n",
      "Epoch 787, Loss: 0.2791537344455719, Final Batch Loss: 0.14923278987407684\n",
      "Epoch 788, Loss: 0.24487992376089096, Final Batch Loss: 0.10694149881601334\n",
      "Epoch 789, Loss: 0.18175232410430908, Final Batch Loss: 0.09376510232686996\n",
      "Epoch 790, Loss: 0.22324145585298538, Final Batch Loss: 0.11043168604373932\n",
      "Epoch 791, Loss: 0.16079236567020416, Final Batch Loss: 0.07587619870901108\n",
      "Epoch 792, Loss: 0.2166987657546997, Final Batch Loss: 0.09559530764818192\n",
      "Epoch 793, Loss: 0.21687772870063782, Final Batch Loss: 0.13461299240589142\n",
      "Epoch 794, Loss: 0.2066178023815155, Final Batch Loss: 0.09913181513547897\n",
      "Epoch 795, Loss: 0.2182299718260765, Final Batch Loss: 0.07473532110452652\n",
      "Epoch 796, Loss: 0.22856461256742477, Final Batch Loss: 0.13451629877090454\n",
      "Epoch 797, Loss: 0.18158765137195587, Final Batch Loss: 0.08223973214626312\n",
      "Epoch 798, Loss: 0.18383950740098953, Final Batch Loss: 0.08076665550470352\n",
      "Epoch 799, Loss: 0.21181225031614304, Final Batch Loss: 0.12994754314422607\n",
      "Epoch 800, Loss: 0.20448710024356842, Final Batch Loss: 0.11586064845323563\n",
      "Epoch 801, Loss: 0.16240885481238365, Final Batch Loss: 0.06089774891734123\n",
      "Epoch 802, Loss: 0.22389812767505646, Final Batch Loss: 0.14128544926643372\n",
      "Epoch 803, Loss: 0.23970457166433334, Final Batch Loss: 0.15271124243736267\n",
      "Epoch 804, Loss: 0.2026507332921028, Final Batch Loss: 0.06113036721944809\n",
      "Epoch 805, Loss: 0.1789383962750435, Final Batch Loss: 0.11530503630638123\n",
      "Epoch 806, Loss: 0.22396975755691528, Final Batch Loss: 0.1444789171218872\n",
      "Epoch 807, Loss: 0.193126879632473, Final Batch Loss: 0.0750555619597435\n",
      "Epoch 808, Loss: 0.23202074319124222, Final Batch Loss: 0.12900272011756897\n",
      "Epoch 809, Loss: 0.199313685297966, Final Batch Loss: 0.10992004722356796\n",
      "Epoch 810, Loss: 0.2144382894039154, Final Batch Loss: 0.11784005910158157\n",
      "Epoch 811, Loss: 0.18620606511831284, Final Batch Loss: 0.10445361584424973\n",
      "Epoch 812, Loss: 0.19037220627069473, Final Batch Loss: 0.08833471685647964\n",
      "Epoch 813, Loss: 0.21018036454916, Final Batch Loss: 0.09678757190704346\n",
      "Epoch 814, Loss: 0.17930030822753906, Final Batch Loss: 0.05915725976228714\n",
      "Epoch 815, Loss: 0.2032456025481224, Final Batch Loss: 0.10559701174497604\n",
      "Epoch 816, Loss: 0.20853931456804276, Final Batch Loss: 0.11771364510059357\n",
      "Epoch 817, Loss: 0.18260980397462845, Final Batch Loss: 0.10884644091129303\n",
      "Epoch 818, Loss: 0.1907893270254135, Final Batch Loss: 0.09543651342391968\n",
      "Epoch 819, Loss: 0.1668616309762001, Final Batch Loss: 0.05017466098070145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820, Loss: 0.23438867926597595, Final Batch Loss: 0.16252930462360382\n",
      "Epoch 821, Loss: 0.18193452805280685, Final Batch Loss: 0.07730010151863098\n",
      "Epoch 822, Loss: 0.18864208459854126, Final Batch Loss: 0.10697627067565918\n",
      "Epoch 823, Loss: 0.24795843660831451, Final Batch Loss: 0.13583897054195404\n",
      "Epoch 824, Loss: 0.19036293029785156, Final Batch Loss: 0.07550044357776642\n",
      "Epoch 825, Loss: 0.1859022006392479, Final Batch Loss: 0.0750180035829544\n",
      "Epoch 826, Loss: 0.19437728822231293, Final Batch Loss: 0.09407927095890045\n",
      "Epoch 827, Loss: 0.18734943866729736, Final Batch Loss: 0.06377598643302917\n",
      "Epoch 828, Loss: 0.16628916934132576, Final Batch Loss: 0.049181174486875534\n",
      "Epoch 829, Loss: 0.1881355568766594, Final Batch Loss: 0.063214510679245\n",
      "Epoch 830, Loss: 0.20504216104745865, Final Batch Loss: 0.09172045439481735\n",
      "Epoch 831, Loss: 0.23789897561073303, Final Batch Loss: 0.15910127758979797\n",
      "Epoch 832, Loss: 0.17295102030038834, Final Batch Loss: 0.07779152691364288\n",
      "Epoch 833, Loss: 0.15861061215400696, Final Batch Loss: 0.06998495012521744\n",
      "Epoch 834, Loss: 0.17048782855272293, Final Batch Loss: 0.0988779067993164\n",
      "Epoch 835, Loss: 0.19730934500694275, Final Batch Loss: 0.12122531980276108\n",
      "Epoch 836, Loss: 0.2129283770918846, Final Batch Loss: 0.14471781253814697\n",
      "Epoch 837, Loss: 0.20163249969482422, Final Batch Loss: 0.0992899164557457\n",
      "Epoch 838, Loss: 0.2138623669743538, Final Batch Loss: 0.14751878380775452\n",
      "Epoch 839, Loss: 0.17099851369857788, Final Batch Loss: 0.08812389522790909\n",
      "Epoch 840, Loss: 0.19635418057441711, Final Batch Loss: 0.0782083198428154\n",
      "Epoch 841, Loss: 0.17226315289735794, Final Batch Loss: 0.06809322535991669\n",
      "Epoch 842, Loss: 0.17717291414737701, Final Batch Loss: 0.06825181841850281\n",
      "Epoch 843, Loss: 0.14812258630990982, Final Batch Loss: 0.05545765906572342\n",
      "Epoch 844, Loss: 0.16215725988149643, Final Batch Loss: 0.07098071277141571\n",
      "Epoch 845, Loss: 0.18348507583141327, Final Batch Loss: 0.08719025552272797\n",
      "Epoch 846, Loss: 0.18243660032749176, Final Batch Loss: 0.08858572691679001\n",
      "Epoch 847, Loss: 0.1727321520447731, Final Batch Loss: 0.06749402731657028\n",
      "Epoch 848, Loss: 0.18823734670877457, Final Batch Loss: 0.095414899289608\n",
      "Epoch 849, Loss: 0.2064405381679535, Final Batch Loss: 0.10193344205617905\n",
      "Epoch 850, Loss: 0.1878792867064476, Final Batch Loss: 0.08879383653402328\n",
      "Epoch 851, Loss: 0.18474595248699188, Final Batch Loss: 0.07568331062793732\n",
      "Epoch 852, Loss: 0.18709741532802582, Final Batch Loss: 0.08749597519636154\n",
      "Epoch 853, Loss: 0.22030837088823318, Final Batch Loss: 0.12517842650413513\n",
      "Epoch 854, Loss: 0.2107226476073265, Final Batch Loss: 0.12800514698028564\n",
      "Epoch 855, Loss: 0.23333986103534698, Final Batch Loss: 0.16680434346199036\n",
      "Epoch 856, Loss: 0.20392581075429916, Final Batch Loss: 0.10463021695613861\n",
      "Epoch 857, Loss: 0.17427263408899307, Final Batch Loss: 0.07463233172893524\n",
      "Epoch 858, Loss: 0.2299344539642334, Final Batch Loss: 0.1382138580083847\n",
      "Epoch 859, Loss: 0.20937759429216385, Final Batch Loss: 0.10916168987751007\n",
      "Epoch 860, Loss: 0.15913350507616997, Final Batch Loss: 0.058322492986917496\n",
      "Epoch 861, Loss: 0.21943169832229614, Final Batch Loss: 0.12055069953203201\n",
      "Epoch 862, Loss: 0.19123391062021255, Final Batch Loss: 0.08455625176429749\n",
      "Epoch 863, Loss: 0.1825396493077278, Final Batch Loss: 0.09655222296714783\n",
      "Epoch 864, Loss: 0.17411842197179794, Final Batch Loss: 0.09717277437448502\n",
      "Epoch 865, Loss: 0.16421132534742355, Final Batch Loss: 0.07906391471624374\n",
      "Epoch 866, Loss: 0.21012120693922043, Final Batch Loss: 0.08422795683145523\n",
      "Epoch 867, Loss: 0.18009080737829208, Final Batch Loss: 0.06971527636051178\n",
      "Epoch 868, Loss: 0.20058811455965042, Final Batch Loss: 0.1140945702791214\n",
      "Epoch 869, Loss: 0.16885916143655777, Final Batch Loss: 0.07001703232526779\n",
      "Epoch 870, Loss: 0.17111998051404953, Final Batch Loss: 0.08408981561660767\n",
      "Epoch 871, Loss: 0.17035268247127533, Final Batch Loss: 0.07054010778665543\n",
      "Epoch 872, Loss: 0.19722367823123932, Final Batch Loss: 0.09621020406484604\n",
      "Epoch 873, Loss: 0.20444771647453308, Final Batch Loss: 0.09107698500156403\n",
      "Epoch 874, Loss: 0.1850704699754715, Final Batch Loss: 0.08413916826248169\n",
      "Epoch 875, Loss: 0.17300955206155777, Final Batch Loss: 0.07759127020835876\n",
      "Epoch 876, Loss: 0.23715921491384506, Final Batch Loss: 0.1288088709115982\n",
      "Epoch 877, Loss: 0.16857270151376724, Final Batch Loss: 0.0759231299161911\n",
      "Epoch 878, Loss: 0.23972541093826294, Final Batch Loss: 0.10540257394313812\n",
      "Epoch 879, Loss: 0.199449822306633, Final Batch Loss: 0.058431461453437805\n",
      "Epoch 880, Loss: 0.18500276654958725, Final Batch Loss: 0.09805235266685486\n",
      "Epoch 881, Loss: 0.17066794633865356, Final Batch Loss: 0.08423880487680435\n",
      "Epoch 882, Loss: 0.14813832566142082, Final Batch Loss: 0.05735514685511589\n",
      "Epoch 883, Loss: 0.19157636165618896, Final Batch Loss: 0.07840322703123093\n",
      "Epoch 884, Loss: 0.1706596091389656, Final Batch Loss: 0.08097708225250244\n",
      "Epoch 885, Loss: 0.17834848165512085, Final Batch Loss: 0.11224310845136642\n",
      "Epoch 886, Loss: 0.1589522659778595, Final Batch Loss: 0.0913676992058754\n",
      "Epoch 887, Loss: 0.17932816222310066, Final Batch Loss: 0.04285793378949165\n",
      "Epoch 888, Loss: 0.14925120025873184, Final Batch Loss: 0.07104051113128662\n",
      "Epoch 889, Loss: 0.22613932192325592, Final Batch Loss: 0.13362380862236023\n",
      "Epoch 890, Loss: 0.1832520142197609, Final Batch Loss: 0.11623823642730713\n",
      "Epoch 891, Loss: 0.19902263581752777, Final Batch Loss: 0.12550830841064453\n",
      "Epoch 892, Loss: 0.18557006865739822, Final Batch Loss: 0.09574228525161743\n",
      "Epoch 893, Loss: 0.16707934439182281, Final Batch Loss: 0.08008936792612076\n",
      "Epoch 894, Loss: 0.17215148359537125, Final Batch Loss: 0.10294007509946823\n",
      "Epoch 895, Loss: 0.17688463628292084, Final Batch Loss: 0.08936883509159088\n",
      "Epoch 896, Loss: 0.17774495482444763, Final Batch Loss: 0.07734368741512299\n",
      "Epoch 897, Loss: 0.2028873711824417, Final Batch Loss: 0.0909801498055458\n",
      "Epoch 898, Loss: 0.19398055225610733, Final Batch Loss: 0.11224501579999924\n",
      "Epoch 899, Loss: 0.15500354766845703, Final Batch Loss: 0.09088802337646484\n",
      "Epoch 900, Loss: 0.1850854605436325, Final Batch Loss: 0.09645519405603409\n",
      "Epoch 901, Loss: 0.16954173892736435, Final Batch Loss: 0.11057368665933609\n",
      "Epoch 902, Loss: 0.1480519212782383, Final Batch Loss: 0.047954995185136795\n",
      "Epoch 903, Loss: 0.1489855796098709, Final Batch Loss: 0.07621276378631592\n",
      "Epoch 904, Loss: 0.16982895135879517, Final Batch Loss: 0.05659962445497513\n",
      "Epoch 905, Loss: 0.17324361205101013, Final Batch Loss: 0.06733071804046631\n",
      "Epoch 906, Loss: 0.17193447053432465, Final Batch Loss: 0.08840463310480118\n",
      "Epoch 907, Loss: 0.19514059275388718, Final Batch Loss: 0.0719512477517128\n",
      "Epoch 908, Loss: 0.18182311207056046, Final Batch Loss: 0.06770382076501846\n",
      "Epoch 909, Loss: 0.15773673355579376, Final Batch Loss: 0.0792277455329895\n",
      "Epoch 910, Loss: 0.17895641177892685, Final Batch Loss: 0.08072824031114578\n",
      "Epoch 911, Loss: 0.2096586972475052, Final Batch Loss: 0.14923439919948578\n",
      "Epoch 912, Loss: 0.17385654151439667, Final Batch Loss: 0.09711203724145889\n",
      "Epoch 913, Loss: 0.16620592772960663, Final Batch Loss: 0.08276285231113434\n",
      "Epoch 914, Loss: 0.15991578996181488, Final Batch Loss: 0.055344827473163605\n",
      "Epoch 915, Loss: 0.16139183938503265, Final Batch Loss: 0.06394482403993607\n",
      "Epoch 916, Loss: 0.21106891334056854, Final Batch Loss: 0.09533999115228653\n",
      "Epoch 917, Loss: 0.17158371210098267, Final Batch Loss: 0.0753248855471611\n",
      "Epoch 918, Loss: 0.1615273654460907, Final Batch Loss: 0.06125064194202423\n",
      "Epoch 919, Loss: 0.14309820532798767, Final Batch Loss: 0.056629881262779236\n",
      "Epoch 920, Loss: 0.15509111434221268, Final Batch Loss: 0.09383778274059296\n",
      "Epoch 921, Loss: 0.16168656200170517, Final Batch Loss: 0.08344322443008423\n",
      "Epoch 922, Loss: 0.17142615467309952, Final Batch Loss: 0.08944793790578842\n",
      "Epoch 923, Loss: 0.20540133863687515, Final Batch Loss: 0.10125795751810074\n",
      "Epoch 924, Loss: 0.19313590228557587, Final Batch Loss: 0.059150129556655884\n",
      "Epoch 925, Loss: 0.17669084668159485, Final Batch Loss: 0.09057912230491638\n",
      "Epoch 926, Loss: 0.16559067368507385, Final Batch Loss: 0.0779685229063034\n",
      "Epoch 927, Loss: 0.1745820865035057, Final Batch Loss: 0.10256318002939224\n",
      "Epoch 928, Loss: 0.15993233025074005, Final Batch Loss: 0.08662376552820206\n",
      "Epoch 929, Loss: 0.1763738989830017, Final Batch Loss: 0.09809760004281998\n",
      "Epoch 930, Loss: 0.1766708567738533, Final Batch Loss: 0.06712232530117035\n",
      "Epoch 931, Loss: 0.15913506597280502, Final Batch Loss: 0.08678678423166275\n",
      "Epoch 932, Loss: 0.15537506341934204, Final Batch Loss: 0.07709574699401855\n",
      "Epoch 933, Loss: 0.19562430679798126, Final Batch Loss: 0.09155824035406113\n",
      "Epoch 934, Loss: 0.1762700378894806, Final Batch Loss: 0.08092107623815536\n",
      "Epoch 935, Loss: 0.20936258882284164, Final Batch Loss: 0.0851978063583374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936, Loss: 0.17715834081172943, Final Batch Loss: 0.09205412119626999\n",
      "Epoch 937, Loss: 0.21705808490514755, Final Batch Loss: 0.10829215496778488\n",
      "Epoch 938, Loss: 0.18539659678936005, Final Batch Loss: 0.09087107330560684\n",
      "Epoch 939, Loss: 0.23116730898618698, Final Batch Loss: 0.1298229843378067\n",
      "Epoch 940, Loss: 0.16985464841127396, Final Batch Loss: 0.06836845725774765\n",
      "Epoch 941, Loss: 0.16980335116386414, Final Batch Loss: 0.06957707554101944\n",
      "Epoch 942, Loss: 0.17742792516946793, Final Batch Loss: 0.10759220272302628\n",
      "Epoch 943, Loss: 0.16442399471998215, Final Batch Loss: 0.07469374686479568\n",
      "Epoch 944, Loss: 0.20444126427173615, Final Batch Loss: 0.107390396296978\n",
      "Epoch 945, Loss: 0.16712265461683273, Final Batch Loss: 0.08395913988351822\n",
      "Epoch 946, Loss: 0.14545873552560806, Final Batch Loss: 0.043969541788101196\n",
      "Epoch 947, Loss: 0.1621580347418785, Final Batch Loss: 0.062289901077747345\n",
      "Epoch 948, Loss: 0.15536587685346603, Final Batch Loss: 0.07918206602334976\n",
      "Epoch 949, Loss: 0.16618991643190384, Final Batch Loss: 0.06264151632785797\n",
      "Epoch 950, Loss: 0.1721917986869812, Final Batch Loss: 0.07804996520280838\n",
      "Epoch 951, Loss: 0.1764063537120819, Final Batch Loss: 0.0745360255241394\n",
      "Epoch 952, Loss: 0.1850777342915535, Final Batch Loss: 0.11032244563102722\n",
      "Epoch 953, Loss: 0.19508057087659836, Final Batch Loss: 0.07259507477283478\n",
      "Epoch 954, Loss: 0.2005825899541378, Final Batch Loss: 0.1415116935968399\n",
      "Epoch 955, Loss: 0.16710371524095535, Final Batch Loss: 0.07134969532489777\n",
      "Epoch 956, Loss: 0.16867657005786896, Final Batch Loss: 0.10711423307657242\n",
      "Epoch 957, Loss: 0.16496798396110535, Final Batch Loss: 0.10100701451301575\n",
      "Epoch 958, Loss: 0.15647006034851074, Final Batch Loss: 0.07715802639722824\n",
      "Epoch 959, Loss: 0.19247474521398544, Final Batch Loss: 0.10083870589733124\n",
      "Epoch 960, Loss: 0.1577317789196968, Final Batch Loss: 0.08088348060846329\n",
      "Epoch 961, Loss: 0.20460787415504456, Final Batch Loss: 0.13450050354003906\n",
      "Epoch 962, Loss: 0.1884615197777748, Final Batch Loss: 0.10077816247940063\n",
      "Epoch 963, Loss: 0.1936880499124527, Final Batch Loss: 0.040267691016197205\n",
      "Epoch 964, Loss: 0.17318417131900787, Final Batch Loss: 0.0733746737241745\n",
      "Epoch 965, Loss: 0.23043694347143173, Final Batch Loss: 0.1563318520784378\n",
      "Epoch 966, Loss: 0.17657621949911118, Final Batch Loss: 0.08927717804908752\n",
      "Epoch 967, Loss: 0.17911241948604584, Final Batch Loss: 0.105678029358387\n",
      "Epoch 968, Loss: 0.21430820226669312, Final Batch Loss: 0.13576777279376984\n",
      "Epoch 969, Loss: 0.18129917234182358, Final Batch Loss: 0.10270963609218597\n",
      "Epoch 970, Loss: 0.190803162753582, Final Batch Loss: 0.12405823916196823\n",
      "Epoch 971, Loss: 0.17612707614898682, Final Batch Loss: 0.09306736290454865\n",
      "Epoch 972, Loss: 0.16852135956287384, Final Batch Loss: 0.06247369199991226\n",
      "Epoch 973, Loss: 0.16743474826216698, Final Batch Loss: 0.10612177848815918\n",
      "Epoch 974, Loss: 0.1808459721505642, Final Batch Loss: 0.05581718310713768\n",
      "Epoch 975, Loss: 0.19984665513038635, Final Batch Loss: 0.12504540383815765\n",
      "Epoch 976, Loss: 0.15142006427049637, Final Batch Loss: 0.08497706800699234\n",
      "Epoch 977, Loss: 0.15860681980848312, Final Batch Loss: 0.0863707959651947\n",
      "Epoch 978, Loss: 0.16824044287204742, Final Batch Loss: 0.0505385622382164\n",
      "Epoch 979, Loss: 0.1676788032054901, Final Batch Loss: 0.09671040624380112\n",
      "Epoch 980, Loss: 0.16788869351148605, Final Batch Loss: 0.08487872034311295\n",
      "Epoch 981, Loss: 0.21273518353700638, Final Batch Loss: 0.12066240608692169\n",
      "Epoch 982, Loss: 0.24142525345087051, Final Batch Loss: 0.08358675986528397\n",
      "Epoch 983, Loss: 0.19555829465389252, Final Batch Loss: 0.12881676852703094\n",
      "Epoch 984, Loss: 0.18144945055246353, Final Batch Loss: 0.09267298877239227\n",
      "Epoch 985, Loss: 0.1771038994193077, Final Batch Loss: 0.09023410826921463\n",
      "Epoch 986, Loss: 0.22722579538822174, Final Batch Loss: 0.12842591106891632\n",
      "Epoch 987, Loss: 0.20070276409387589, Final Batch Loss: 0.10187861323356628\n",
      "Epoch 988, Loss: 0.16314450651407242, Final Batch Loss: 0.07740630954504013\n",
      "Epoch 989, Loss: 0.24075287580490112, Final Batch Loss: 0.1458902359008789\n",
      "Epoch 990, Loss: 0.1948428452014923, Final Batch Loss: 0.06476901471614838\n",
      "Epoch 991, Loss: 0.16695872694253922, Final Batch Loss: 0.0961935743689537\n",
      "Epoch 992, Loss: 0.19831667095422745, Final Batch Loss: 0.09735368937253952\n",
      "Epoch 993, Loss: 0.20105287432670593, Final Batch Loss: 0.10292467474937439\n",
      "Epoch 994, Loss: 0.22836145013570786, Final Batch Loss: 0.10128279775381088\n",
      "Epoch 995, Loss: 0.17758015543222427, Final Batch Loss: 0.10403776913881302\n",
      "Epoch 996, Loss: 0.1589047648012638, Final Batch Loss: 0.0998140275478363\n",
      "Epoch 997, Loss: 0.1841587871313095, Final Batch Loss: 0.1353759616613388\n",
      "Epoch 998, Loss: 0.16211088746786118, Final Batch Loss: 0.06123679131269455\n",
      "Epoch 999, Loss: 0.19876039028167725, Final Batch Loss: 0.07854511588811874\n",
      "Epoch 1000, Loss: 0.1559348739683628, Final Batch Loss: 0.04372900351881981\n",
      "Epoch 1001, Loss: 0.1702825427055359, Final Batch Loss: 0.08152240514755249\n",
      "Epoch 1002, Loss: 0.13994431868195534, Final Batch Loss: 0.06069121137261391\n",
      "Epoch 1003, Loss: 0.21613123267889023, Final Batch Loss: 0.1416080892086029\n",
      "Epoch 1004, Loss: 0.20315410941839218, Final Batch Loss: 0.10497093945741653\n",
      "Epoch 1005, Loss: 0.17534851282835007, Final Batch Loss: 0.10182104259729385\n",
      "Epoch 1006, Loss: 0.16130372136831284, Final Batch Loss: 0.08160196244716644\n",
      "Epoch 1007, Loss: 0.1661011427640915, Final Batch Loss: 0.08328830450773239\n",
      "Epoch 1008, Loss: 0.23138803988695145, Final Batch Loss: 0.13507689535617828\n",
      "Epoch 1009, Loss: 0.1794729307293892, Final Batch Loss: 0.11426009982824326\n",
      "Epoch 1010, Loss: 0.22430748119950294, Final Batch Loss: 0.16484291851520538\n",
      "Epoch 1011, Loss: 0.16254696995019913, Final Batch Loss: 0.09482456743717194\n",
      "Epoch 1012, Loss: 0.17820435762405396, Final Batch Loss: 0.09862256050109863\n",
      "Epoch 1013, Loss: 0.1733679622411728, Final Batch Loss: 0.07133873552083969\n",
      "Epoch 1014, Loss: 0.1463044285774231, Final Batch Loss: 0.06888023763895035\n",
      "Epoch 1015, Loss: 0.18077898770570755, Final Batch Loss: 0.08077205717563629\n",
      "Epoch 1016, Loss: 0.19398093223571777, Final Batch Loss: 0.09865262359380722\n",
      "Epoch 1017, Loss: 0.17400700598955154, Final Batch Loss: 0.06918101012706757\n",
      "Epoch 1018, Loss: 0.1683582216501236, Final Batch Loss: 0.07690417021512985\n",
      "Epoch 1019, Loss: 0.19378956407308578, Final Batch Loss: 0.09780724346637726\n",
      "Epoch 1020, Loss: 0.19522660970687866, Final Batch Loss: 0.11420199275016785\n",
      "Epoch 1021, Loss: 0.168630450963974, Final Batch Loss: 0.09072215110063553\n",
      "Epoch 1022, Loss: 0.1701945662498474, Final Batch Loss: 0.04151451587677002\n",
      "Epoch 1023, Loss: 0.1539192572236061, Final Batch Loss: 0.067281574010849\n",
      "Epoch 1024, Loss: 0.16447991132736206, Final Batch Loss: 0.06957899779081345\n",
      "Epoch 1025, Loss: 0.16801929473876953, Final Batch Loss: 0.07228758186101913\n",
      "Epoch 1026, Loss: 0.1692458763718605, Final Batch Loss: 0.07837565988302231\n",
      "Epoch 1027, Loss: 0.17833208292722702, Final Batch Loss: 0.09270362555980682\n",
      "Epoch 1028, Loss: 0.17244141548871994, Final Batch Loss: 0.10188235342502594\n",
      "Epoch 1029, Loss: 0.23316263407468796, Final Batch Loss: 0.15827085077762604\n",
      "Epoch 1030, Loss: 0.2086648866534233, Final Batch Loss: 0.12542249262332916\n",
      "Epoch 1031, Loss: 0.17564652860164642, Final Batch Loss: 0.08771342039108276\n",
      "Epoch 1032, Loss: 0.17628194391727448, Final Batch Loss: 0.11028716713190079\n",
      "Epoch 1033, Loss: 0.17656394094228745, Final Batch Loss: 0.09051845967769623\n",
      "Epoch 1034, Loss: 0.18777313828468323, Final Batch Loss: 0.11867169290781021\n",
      "Epoch 1035, Loss: 0.17210832238197327, Final Batch Loss: 0.09719030559062958\n",
      "Epoch 1036, Loss: 0.1513526774942875, Final Batch Loss: 0.06026321277022362\n",
      "Epoch 1037, Loss: 0.2278161644935608, Final Batch Loss: 0.06336681544780731\n",
      "Epoch 1038, Loss: 0.1914190873503685, Final Batch Loss: 0.12836600840091705\n",
      "Epoch 1039, Loss: 0.17319124937057495, Final Batch Loss: 0.06130488961935043\n",
      "Epoch 1040, Loss: 0.15844080597162247, Final Batch Loss: 0.07749655842781067\n",
      "Epoch 1041, Loss: 0.18786437809467316, Final Batch Loss: 0.0896528884768486\n",
      "Epoch 1042, Loss: 0.16873446106910706, Final Batch Loss: 0.08855301141738892\n",
      "Epoch 1043, Loss: 0.18570692837238312, Final Batch Loss: 0.07032773643732071\n",
      "Epoch 1044, Loss: 0.16550900042057037, Final Batch Loss: 0.10434997081756592\n",
      "Epoch 1045, Loss: 0.15150834619998932, Final Batch Loss: 0.07075152546167374\n",
      "Epoch 1046, Loss: 0.19096651673316956, Final Batch Loss: 0.09403704851865768\n",
      "Epoch 1047, Loss: 0.16598711162805557, Final Batch Loss: 0.08910827338695526\n",
      "Epoch 1048, Loss: 0.22753220796585083, Final Batch Loss: 0.11486296355724335\n",
      "Epoch 1049, Loss: 0.16250599175691605, Final Batch Loss: 0.08991158753633499\n",
      "Epoch 1050, Loss: 0.15099086984992027, Final Batch Loss: 0.06175379827618599\n",
      "Epoch 1051, Loss: 0.1748593971133232, Final Batch Loss: 0.07018385827541351\n",
      "Epoch 1052, Loss: 0.1981581673026085, Final Batch Loss: 0.0863993912935257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1053, Loss: 0.16607538983225822, Final Batch Loss: 0.05513520911335945\n",
      "Epoch 1054, Loss: 0.2019931599497795, Final Batch Loss: 0.100509412586689\n",
      "Epoch 1055, Loss: 0.18957240134477615, Final Batch Loss: 0.08289308100938797\n",
      "Epoch 1056, Loss: 0.1760507971048355, Final Batch Loss: 0.07103390991687775\n",
      "Epoch 1057, Loss: 0.17480658739805222, Final Batch Loss: 0.0715198740363121\n",
      "Epoch 1058, Loss: 0.15302379429340363, Final Batch Loss: 0.08865293860435486\n",
      "Epoch 1059, Loss: 0.16581887006759644, Final Batch Loss: 0.06922564655542374\n",
      "Epoch 1060, Loss: 0.21333174407482147, Final Batch Loss: 0.1335185021162033\n",
      "Epoch 1061, Loss: 0.1745544821023941, Final Batch Loss: 0.06743177026510239\n",
      "Epoch 1062, Loss: 0.14302846789360046, Final Batch Loss: 0.07047802209854126\n",
      "Epoch 1063, Loss: 0.1674276515841484, Final Batch Loss: 0.0848613977432251\n",
      "Epoch 1064, Loss: 0.17594777792692184, Final Batch Loss: 0.0666920393705368\n",
      "Epoch 1065, Loss: 0.1885424479842186, Final Batch Loss: 0.06955478340387344\n",
      "Epoch 1066, Loss: 0.14855948835611343, Final Batch Loss: 0.06923523545265198\n",
      "Epoch 1067, Loss: 0.16361960768699646, Final Batch Loss: 0.07392992079257965\n",
      "Epoch 1068, Loss: 0.143572635948658, Final Batch Loss: 0.05493323504924774\n",
      "Epoch 1069, Loss: 0.1856229230761528, Final Batch Loss: 0.10779386758804321\n",
      "Epoch 1070, Loss: 0.1357034668326378, Final Batch Loss: 0.04502920061349869\n",
      "Epoch 1071, Loss: 0.19085747748613358, Final Batch Loss: 0.12188015878200531\n",
      "Epoch 1072, Loss: 0.18899983167648315, Final Batch Loss: 0.08973433822393417\n",
      "Epoch 1073, Loss: 0.18249671161174774, Final Batch Loss: 0.0984228104352951\n",
      "Epoch 1074, Loss: 0.15016448497772217, Final Batch Loss: 0.06676710397005081\n",
      "Epoch 1075, Loss: 0.14065586030483246, Final Batch Loss: 0.06504528224468231\n",
      "Epoch 1076, Loss: 0.16475637257099152, Final Batch Loss: 0.07862381637096405\n",
      "Epoch 1077, Loss: 0.1976848766207695, Final Batch Loss: 0.10577792674303055\n",
      "Epoch 1078, Loss: 0.17276275902986526, Final Batch Loss: 0.07930780947208405\n",
      "Epoch 1079, Loss: 0.17586928606033325, Final Batch Loss: 0.09658090025186539\n",
      "Epoch 1080, Loss: 0.13593024015426636, Final Batch Loss: 0.06595928221940994\n",
      "Epoch 1081, Loss: 0.18275443464517593, Final Batch Loss: 0.09964533895254135\n",
      "Epoch 1082, Loss: 0.17811844497919083, Final Batch Loss: 0.10925819724798203\n",
      "Epoch 1083, Loss: 0.13576405867934227, Final Batch Loss: 0.05772527679800987\n",
      "Epoch 1084, Loss: 0.18542194366455078, Final Batch Loss: 0.09313355386257172\n",
      "Epoch 1085, Loss: 0.15965858101844788, Final Batch Loss: 0.07846063375473022\n",
      "Epoch 1086, Loss: 0.15749560296535492, Final Batch Loss: 0.07582987844944\n",
      "Epoch 1087, Loss: 0.1538124457001686, Final Batch Loss: 0.06454962491989136\n",
      "Epoch 1088, Loss: 0.17597611993551254, Final Batch Loss: 0.07601764798164368\n",
      "Epoch 1089, Loss: 0.16180668026208878, Final Batch Loss: 0.10518354177474976\n",
      "Epoch 1090, Loss: 0.18829115480184555, Final Batch Loss: 0.1239122524857521\n",
      "Epoch 1091, Loss: 0.13150690868496895, Final Batch Loss: 0.05828793719410896\n",
      "Epoch 1092, Loss: 0.19115407764911652, Final Batch Loss: 0.11333700269460678\n",
      "Epoch 1093, Loss: 0.15519510209560394, Final Batch Loss: 0.0692397952079773\n",
      "Epoch 1094, Loss: 0.2381959930062294, Final Batch Loss: 0.16198091208934784\n",
      "Epoch 1095, Loss: 0.2799680531024933, Final Batch Loss: 0.19681639969348907\n",
      "Epoch 1096, Loss: 0.23684603720903397, Final Batch Loss: 0.1446131467819214\n",
      "Epoch 1097, Loss: 0.20130152255296707, Final Batch Loss: 0.07548365741968155\n",
      "Epoch 1098, Loss: 0.13731581717729568, Final Batch Loss: 0.06486563384532928\n",
      "Epoch 1099, Loss: 0.1657615378499031, Final Batch Loss: 0.08431025594472885\n",
      "Epoch 1100, Loss: 0.17943064123392105, Final Batch Loss: 0.0969269797205925\n",
      "Epoch 1101, Loss: 0.17223044484853745, Final Batch Loss: 0.10881461203098297\n",
      "Epoch 1102, Loss: 0.143539160490036, Final Batch Loss: 0.07844827324151993\n",
      "Epoch 1103, Loss: 0.19697248190641403, Final Batch Loss: 0.09935858845710754\n",
      "Epoch 1104, Loss: 0.14726155251264572, Final Batch Loss: 0.061838261783123016\n",
      "Epoch 1105, Loss: 0.13491398841142654, Final Batch Loss: 0.057508327066898346\n",
      "Epoch 1106, Loss: 0.16055155918002129, Final Batch Loss: 0.05259813740849495\n",
      "Epoch 1107, Loss: 0.16228706389665604, Final Batch Loss: 0.08298001438379288\n",
      "Epoch 1108, Loss: 0.16710837185382843, Final Batch Loss: 0.0841159075498581\n",
      "Epoch 1109, Loss: 0.1602565534412861, Final Batch Loss: 0.05722636356949806\n",
      "Epoch 1110, Loss: 0.12599607929587364, Final Batch Loss: 0.04421944543719292\n",
      "Epoch 1111, Loss: 0.12135584279894829, Final Batch Loss: 0.05649198219180107\n",
      "Epoch 1112, Loss: 0.16161306574940681, Final Batch Loss: 0.04960731789469719\n",
      "Epoch 1113, Loss: 0.1409555748105049, Final Batch Loss: 0.06360739469528198\n",
      "Epoch 1114, Loss: 0.17042190581560135, Final Batch Loss: 0.05985456705093384\n",
      "Epoch 1115, Loss: 0.21809668838977814, Final Batch Loss: 0.13809773325920105\n",
      "Epoch 1116, Loss: 0.13289786502718925, Final Batch Loss: 0.06134789064526558\n",
      "Epoch 1117, Loss: 0.15267230570316315, Final Batch Loss: 0.07829126715660095\n",
      "Epoch 1118, Loss: 0.11306459084153175, Final Batch Loss: 0.042282428592443466\n",
      "Epoch 1119, Loss: 0.1509525217115879, Final Batch Loss: 0.04847465828061104\n",
      "Epoch 1120, Loss: 0.21902120113372803, Final Batch Loss: 0.13648366928100586\n",
      "Epoch 1121, Loss: 0.15999571233987808, Final Batch Loss: 0.06703288853168488\n",
      "Epoch 1122, Loss: 0.16678015887737274, Final Batch Loss: 0.08474550396203995\n",
      "Epoch 1123, Loss: 0.1768980696797371, Final Batch Loss: 0.10261885076761246\n",
      "Epoch 1124, Loss: 0.13209105283021927, Final Batch Loss: 0.0637417584657669\n",
      "Epoch 1125, Loss: 0.14036334306001663, Final Batch Loss: 0.0678023248910904\n",
      "Epoch 1126, Loss: 0.16396936774253845, Final Batch Loss: 0.06452718377113342\n",
      "Epoch 1127, Loss: 0.17748761922121048, Final Batch Loss: 0.07952779531478882\n",
      "Epoch 1128, Loss: 0.1862769052386284, Final Batch Loss: 0.10584753751754761\n",
      "Epoch 1129, Loss: 0.1315147876739502, Final Batch Loss: 0.0738348513841629\n",
      "Epoch 1130, Loss: 0.14384547993540764, Final Batch Loss: 0.05471494421362877\n",
      "Epoch 1131, Loss: 0.18477221578359604, Final Batch Loss: 0.10993786156177521\n",
      "Epoch 1132, Loss: 0.1818017065525055, Final Batch Loss: 0.05882478505373001\n",
      "Epoch 1133, Loss: 0.1714540459215641, Final Batch Loss: 0.06153731420636177\n",
      "Epoch 1134, Loss: 0.17328830808401108, Final Batch Loss: 0.08743809908628464\n",
      "Epoch 1135, Loss: 0.1710229068994522, Final Batch Loss: 0.0815824493765831\n",
      "Epoch 1136, Loss: 0.14231336116790771, Final Batch Loss: 0.047285646200180054\n",
      "Epoch 1137, Loss: 0.23815498501062393, Final Batch Loss: 0.16177888214588165\n",
      "Epoch 1138, Loss: 0.1922173649072647, Final Batch Loss: 0.09933808445930481\n",
      "Epoch 1139, Loss: 0.18297558277845383, Final Batch Loss: 0.0925680622458458\n",
      "Epoch 1140, Loss: 0.19228190928697586, Final Batch Loss: 0.09217370301485062\n",
      "Epoch 1141, Loss: 0.1223076693713665, Final Batch Loss: 0.0545940063893795\n",
      "Epoch 1142, Loss: 0.14030827954411507, Final Batch Loss: 0.07889599353075027\n",
      "Epoch 1143, Loss: 0.15841475129127502, Final Batch Loss: 0.09380371123552322\n",
      "Epoch 1144, Loss: 0.16567430272698402, Final Batch Loss: 0.1040453389286995\n",
      "Epoch 1145, Loss: 0.17721504718065262, Final Batch Loss: 0.08362926542758942\n",
      "Epoch 1146, Loss: 0.1730721965432167, Final Batch Loss: 0.10265810042619705\n",
      "Epoch 1147, Loss: 0.15827017277479172, Final Batch Loss: 0.06970381736755371\n",
      "Epoch 1148, Loss: 0.1602361649274826, Final Batch Loss: 0.06611732393503189\n",
      "Epoch 1149, Loss: 0.18335730582475662, Final Batch Loss: 0.06321185827255249\n",
      "Epoch 1150, Loss: 0.13961521163582802, Final Batch Loss: 0.05693553760647774\n",
      "Epoch 1151, Loss: 0.14993185549974442, Final Batch Loss: 0.07820570468902588\n",
      "Epoch 1152, Loss: 0.2115798518061638, Final Batch Loss: 0.13779716193675995\n",
      "Epoch 1153, Loss: 0.1542549952864647, Final Batch Loss: 0.09000904113054276\n",
      "Epoch 1154, Loss: 0.1439293771982193, Final Batch Loss: 0.06978471577167511\n",
      "Epoch 1155, Loss: 0.1817023977637291, Final Batch Loss: 0.08505301177501678\n",
      "Epoch 1156, Loss: 0.17982327565550804, Final Batch Loss: 0.1300484538078308\n",
      "Epoch 1157, Loss: 0.12492498010396957, Final Batch Loss: 0.045486778020858765\n",
      "Epoch 1158, Loss: 0.15816707909107208, Final Batch Loss: 0.09049822390079498\n",
      "Epoch 1159, Loss: 0.2420949712395668, Final Batch Loss: 0.12697778642177582\n",
      "Epoch 1160, Loss: 0.14471330121159554, Final Batch Loss: 0.061556991189718246\n",
      "Epoch 1161, Loss: 0.19514226913452148, Final Batch Loss: 0.06679004430770874\n",
      "Epoch 1162, Loss: 0.12154148146510124, Final Batch Loss: 0.05683273449540138\n",
      "Epoch 1163, Loss: 0.14340050518512726, Final Batch Loss: 0.06206752359867096\n",
      "Epoch 1164, Loss: 0.1492486596107483, Final Batch Loss: 0.09722672402858734\n",
      "Epoch 1165, Loss: 0.1769421398639679, Final Batch Loss: 0.09792444854974747\n",
      "Epoch 1166, Loss: 0.1443997211754322, Final Batch Loss: 0.09004728496074677\n",
      "Epoch 1167, Loss: 0.15142250806093216, Final Batch Loss: 0.08110886812210083\n",
      "Epoch 1168, Loss: 0.17215732485055923, Final Batch Loss: 0.10944721847772598\n",
      "Epoch 1169, Loss: 0.12882483005523682, Final Batch Loss: 0.02963889390230179\n",
      "Epoch 1170, Loss: 0.17947350442409515, Final Batch Loss: 0.11676842719316483\n",
      "Epoch 1171, Loss: 0.15327467024326324, Final Batch Loss: 0.06715665012598038\n",
      "Epoch 1172, Loss: 0.1390606313943863, Final Batch Loss: 0.07924339920282364\n",
      "Epoch 1173, Loss: 0.1673165075480938, Final Batch Loss: 0.05121148005127907\n",
      "Epoch 1174, Loss: 0.1544528603553772, Final Batch Loss: 0.07817185670137405\n",
      "Epoch 1175, Loss: 0.2019578441977501, Final Batch Loss: 0.09273511916399002\n",
      "Epoch 1176, Loss: 0.1426483392715454, Final Batch Loss: 0.05293145030736923\n",
      "Epoch 1177, Loss: 0.13958580046892166, Final Batch Loss: 0.06278117001056671\n",
      "Epoch 1178, Loss: 0.16382917016744614, Final Batch Loss: 0.09078580141067505\n",
      "Epoch 1179, Loss: 0.13652468100190163, Final Batch Loss: 0.03795171156525612\n",
      "Epoch 1180, Loss: 0.22305332124233246, Final Batch Loss: 0.14607706665992737\n",
      "Epoch 1181, Loss: 0.16901162266731262, Final Batch Loss: 0.09620953351259232\n",
      "Epoch 1182, Loss: 0.15903480350971222, Final Batch Loss: 0.08943725377321243\n",
      "Epoch 1183, Loss: 0.17020660266280174, Final Batch Loss: 0.05977152660489082\n",
      "Epoch 1184, Loss: 0.10550103336572647, Final Batch Loss: 0.03607971966266632\n",
      "Epoch 1185, Loss: 0.1918708235025406, Final Batch Loss: 0.08877281099557877\n",
      "Epoch 1186, Loss: 0.14847445487976074, Final Batch Loss: 0.06650805473327637\n",
      "Epoch 1187, Loss: 0.15694891661405563, Final Batch Loss: 0.05098479241132736\n",
      "Epoch 1188, Loss: 0.1745893880724907, Final Batch Loss: 0.10519768297672272\n",
      "Epoch 1189, Loss: 0.16530638188123703, Final Batch Loss: 0.09421949088573456\n",
      "Epoch 1190, Loss: 0.12950369715690613, Final Batch Loss: 0.08181695640087128\n",
      "Epoch 1191, Loss: 0.14101070538163185, Final Batch Loss: 0.029348354786634445\n",
      "Epoch 1192, Loss: 0.1429510861635208, Final Batch Loss: 0.07497430592775345\n",
      "Epoch 1193, Loss: 0.13007723912596703, Final Batch Loss: 0.04083755239844322\n",
      "Epoch 1194, Loss: 0.09612619504332542, Final Batch Loss: 0.03459993749856949\n",
      "Epoch 1195, Loss: 0.2093406543135643, Final Batch Loss: 0.12922602891921997\n",
      "Epoch 1196, Loss: 0.17886892706155777, Final Batch Loss: 0.09182365983724594\n",
      "Epoch 1197, Loss: 0.1521250084042549, Final Batch Loss: 0.07473510503768921\n",
      "Epoch 1198, Loss: 0.12174592167139053, Final Batch Loss: 0.06230193376541138\n",
      "Epoch 1199, Loss: 0.14340761303901672, Final Batch Loss: 0.05465999245643616\n",
      "Epoch 1200, Loss: 0.12963354960083961, Final Batch Loss: 0.04291418567299843\n",
      "Epoch 1201, Loss: 0.12493780255317688, Final Batch Loss: 0.045204080641269684\n",
      "Epoch 1202, Loss: 0.13705860823392868, Final Batch Loss: 0.07037681341171265\n",
      "Epoch 1203, Loss: 0.13227960467338562, Final Batch Loss: 0.048704542219638824\n",
      "Epoch 1204, Loss: 0.1553383693099022, Final Batch Loss: 0.06737992912530899\n",
      "Epoch 1205, Loss: 0.15599046647548676, Final Batch Loss: 0.0824589803814888\n",
      "Epoch 1206, Loss: 0.13719675689935684, Final Batch Loss: 0.06704648584127426\n",
      "Epoch 1207, Loss: 0.12706677615642548, Final Batch Loss: 0.08180902898311615\n",
      "Epoch 1208, Loss: 0.15319663286209106, Final Batch Loss: 0.08261299878358841\n",
      "Epoch 1209, Loss: 0.15592791885137558, Final Batch Loss: 0.07145734876394272\n",
      "Epoch 1210, Loss: 0.1171860508620739, Final Batch Loss: 0.04329838976264\n",
      "Epoch 1211, Loss: 0.13025924190878868, Final Batch Loss: 0.08190199732780457\n",
      "Epoch 1212, Loss: 0.1599218100309372, Final Batch Loss: 0.08749742060899734\n",
      "Epoch 1213, Loss: 0.15216927230358124, Final Batch Loss: 0.08165907859802246\n",
      "Epoch 1214, Loss: 0.17250803858041763, Final Batch Loss: 0.06649209558963776\n",
      "Epoch 1215, Loss: 0.14846521615982056, Final Batch Loss: 0.0648127943277359\n",
      "Epoch 1216, Loss: 0.15399150550365448, Final Batch Loss: 0.0681215152144432\n",
      "Epoch 1217, Loss: 0.16962918639183044, Final Batch Loss: 0.12136721611022949\n",
      "Epoch 1218, Loss: 0.16143882274627686, Final Batch Loss: 0.07291489839553833\n",
      "Epoch 1219, Loss: 0.2060137838125229, Final Batch Loss: 0.06676000356674194\n",
      "Epoch 1220, Loss: 0.13580826297402382, Final Batch Loss: 0.09207286685705185\n",
      "Epoch 1221, Loss: 0.24931658804416656, Final Batch Loss: 0.08520956337451935\n",
      "Epoch 1222, Loss: 0.16798758506774902, Final Batch Loss: 0.08652453869581223\n",
      "Epoch 1223, Loss: 0.14031877741217613, Final Batch Loss: 0.08218128979206085\n",
      "Epoch 1224, Loss: 0.18180117011070251, Final Batch Loss: 0.10818924754858017\n",
      "Epoch 1225, Loss: 0.1897195652127266, Final Batch Loss: 0.07862458378076553\n",
      "Epoch 1226, Loss: 0.10460438579320908, Final Batch Loss: 0.04698611795902252\n",
      "Epoch 1227, Loss: 0.1354643739759922, Final Batch Loss: 0.03518272563815117\n",
      "Epoch 1228, Loss: 0.1732242926955223, Final Batch Loss: 0.0681375041604042\n",
      "Epoch 1229, Loss: 0.11596009507775307, Final Batch Loss: 0.05825718119740486\n",
      "Epoch 1230, Loss: 0.16698238253593445, Final Batch Loss: 0.097075916826725\n",
      "Epoch 1231, Loss: 0.123479925096035, Final Batch Loss: 0.053314633667469025\n",
      "Epoch 1232, Loss: 0.23667539656162262, Final Batch Loss: 0.12843935191631317\n",
      "Epoch 1233, Loss: 0.17061509937047958, Final Batch Loss: 0.09040165692567825\n",
      "Epoch 1234, Loss: 0.14218229800462723, Final Batch Loss: 0.073395274579525\n",
      "Epoch 1235, Loss: 0.11429806798696518, Final Batch Loss: 0.06199910119175911\n",
      "Epoch 1236, Loss: 0.13305117189884186, Final Batch Loss: 0.06677404046058655\n",
      "Epoch 1237, Loss: 0.12974154949188232, Final Batch Loss: 0.07145703583955765\n",
      "Epoch 1238, Loss: 0.18728624284267426, Final Batch Loss: 0.10499486327171326\n",
      "Epoch 1239, Loss: 0.16874013096094131, Final Batch Loss: 0.09314902871847153\n",
      "Epoch 1240, Loss: 0.1412702202796936, Final Batch Loss: 0.041358768939971924\n",
      "Epoch 1241, Loss: 0.13811523094773293, Final Batch Loss: 0.042375240474939346\n",
      "Epoch 1242, Loss: 0.1150577962398529, Final Batch Loss: 0.04086455702781677\n",
      "Epoch 1243, Loss: 0.15415535122156143, Final Batch Loss: 0.0797104462981224\n",
      "Epoch 1244, Loss: 0.12219389155507088, Final Batch Loss: 0.09350280463695526\n",
      "Epoch 1245, Loss: 0.12230299040675163, Final Batch Loss: 0.05718284472823143\n",
      "Epoch 1246, Loss: 0.13349438458681107, Final Batch Loss: 0.07041555643081665\n",
      "Epoch 1247, Loss: 0.12600650265812874, Final Batch Loss: 0.07512012869119644\n",
      "Epoch 1248, Loss: 0.1390162892639637, Final Batch Loss: 0.05169365927577019\n",
      "Epoch 1249, Loss: 0.1496763527393341, Final Batch Loss: 0.08465643972158432\n",
      "Epoch 1250, Loss: 0.14568520337343216, Final Batch Loss: 0.05295572429895401\n",
      "Epoch 1251, Loss: 0.13797260075807571, Final Batch Loss: 0.06381203979253769\n",
      "Epoch 1252, Loss: 0.15959201753139496, Final Batch Loss: 0.07847001403570175\n",
      "Epoch 1253, Loss: 0.1526738777756691, Final Batch Loss: 0.08855418115854263\n",
      "Epoch 1254, Loss: 0.12126589938998222, Final Batch Loss: 0.05517314746975899\n",
      "Epoch 1255, Loss: 0.13005372509360313, Final Batch Loss: 0.049720119684934616\n",
      "Epoch 1256, Loss: 0.10337197035551071, Final Batch Loss: 0.043300729244947433\n",
      "Epoch 1257, Loss: 0.13245907425880432, Final Batch Loss: 0.07127021253108978\n",
      "Epoch 1258, Loss: 0.14016041159629822, Final Batch Loss: 0.053436391055583954\n",
      "Epoch 1259, Loss: 0.21643253415822983, Final Batch Loss: 0.10768265277147293\n",
      "Epoch 1260, Loss: 0.1620449274778366, Final Batch Loss: 0.0813818946480751\n",
      "Epoch 1261, Loss: 0.08894368633627892, Final Batch Loss: 0.04613833129405975\n",
      "Epoch 1262, Loss: 0.16534586250782013, Final Batch Loss: 0.08325347304344177\n",
      "Epoch 1263, Loss: 0.155329167842865, Final Batch Loss: 0.08405070006847382\n",
      "Epoch 1264, Loss: 0.1406247615814209, Final Batch Loss: 0.06311671435832977\n",
      "Epoch 1265, Loss: 0.2196594551205635, Final Batch Loss: 0.1584593653678894\n",
      "Epoch 1266, Loss: 0.09826061129570007, Final Batch Loss: 0.041753772646188736\n",
      "Epoch 1267, Loss: 0.11506736278533936, Final Batch Loss: 0.06658537685871124\n",
      "Epoch 1268, Loss: 0.1341836228966713, Final Batch Loss: 0.08891651034355164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1269, Loss: 0.11843348294496536, Final Batch Loss: 0.04465503245592117\n",
      "Epoch 1270, Loss: 0.1528296321630478, Final Batch Loss: 0.08070597052574158\n",
      "Epoch 1271, Loss: 0.13498858362436295, Final Batch Loss: 0.06529039144515991\n",
      "Epoch 1272, Loss: 0.1136119719594717, Final Batch Loss: 0.021878136321902275\n",
      "Epoch 1273, Loss: 0.10908674076199532, Final Batch Loss: 0.037054721266031265\n",
      "Epoch 1274, Loss: 0.15400642901659012, Final Batch Loss: 0.08464831858873367\n",
      "Epoch 1275, Loss: 0.1493639051914215, Final Batch Loss: 0.07980049401521683\n",
      "Epoch 1276, Loss: 0.12853389605879784, Final Batch Loss: 0.05943984165787697\n",
      "Epoch 1277, Loss: 0.1408371552824974, Final Batch Loss: 0.06811218708753586\n",
      "Epoch 1278, Loss: 0.11796510219573975, Final Batch Loss: 0.04920952022075653\n",
      "Epoch 1279, Loss: 0.1493566781282425, Final Batch Loss: 0.05954344570636749\n",
      "Epoch 1280, Loss: 0.1439313292503357, Final Batch Loss: 0.08507232367992401\n",
      "Epoch 1281, Loss: 0.12567878141999245, Final Batch Loss: 0.08298515528440475\n",
      "Epoch 1282, Loss: 0.1068919189274311, Final Batch Loss: 0.04655350372195244\n",
      "Epoch 1283, Loss: 0.13765878602862358, Final Batch Loss: 0.05452875420451164\n",
      "Epoch 1284, Loss: 0.09633299335837364, Final Batch Loss: 0.03636937588453293\n",
      "Epoch 1285, Loss: 0.14796146377921104, Final Batch Loss: 0.06239214912056923\n",
      "Epoch 1286, Loss: 0.16904300451278687, Final Batch Loss: 0.08767537772655487\n",
      "Epoch 1287, Loss: 0.11116484925150871, Final Batch Loss: 0.07138021290302277\n",
      "Epoch 1288, Loss: 0.12676862254738808, Final Batch Loss: 0.04689920321106911\n",
      "Epoch 1289, Loss: 0.1498691290616989, Final Batch Loss: 0.06705678254365921\n",
      "Epoch 1290, Loss: 0.1175706647336483, Final Batch Loss: 0.04827357456088066\n",
      "Epoch 1291, Loss: 0.11940447241067886, Final Batch Loss: 0.03977504372596741\n",
      "Epoch 1292, Loss: 0.10975952446460724, Final Batch Loss: 0.05360063537955284\n",
      "Epoch 1293, Loss: 0.12337253987789154, Final Batch Loss: 0.05200773477554321\n",
      "Epoch 1294, Loss: 0.1030498519539833, Final Batch Loss: 0.0489702969789505\n",
      "Epoch 1295, Loss: 0.10946452990174294, Final Batch Loss: 0.03533567860722542\n",
      "Epoch 1296, Loss: 0.10450167581439018, Final Batch Loss: 0.0386461578309536\n",
      "Epoch 1297, Loss: 0.14798761159181595, Final Batch Loss: 0.12427650392055511\n",
      "Epoch 1298, Loss: 0.1223348043859005, Final Batch Loss: 0.04504835233092308\n",
      "Epoch 1299, Loss: 0.13654769212007523, Final Batch Loss: 0.08216188102960587\n",
      "Epoch 1300, Loss: 0.16273675858974457, Final Batch Loss: 0.07022366672754288\n",
      "Epoch 1301, Loss: 0.19819265976548195, Final Batch Loss: 0.041849661618471146\n",
      "Epoch 1302, Loss: 0.16034048795700073, Final Batch Loss: 0.06970692425966263\n",
      "Epoch 1303, Loss: 0.1597662940621376, Final Batch Loss: 0.07525613903999329\n",
      "Epoch 1304, Loss: 0.19703303277492523, Final Batch Loss: 0.08702380210161209\n",
      "Epoch 1305, Loss: 0.15857449173927307, Final Batch Loss: 0.12099539488554001\n",
      "Epoch 1306, Loss: 0.1686846688389778, Final Batch Loss: 0.06454966962337494\n",
      "Epoch 1307, Loss: 0.1637881025671959, Final Batch Loss: 0.10932403057813644\n",
      "Epoch 1308, Loss: 0.10614790767431259, Final Batch Loss: 0.046144966036081314\n",
      "Epoch 1309, Loss: 0.1254776567220688, Final Batch Loss: 0.08560942113399506\n",
      "Epoch 1310, Loss: 0.12236528098583221, Final Batch Loss: 0.06047860532999039\n",
      "Epoch 1311, Loss: 0.13951795920729637, Final Batch Loss: 0.09122592210769653\n",
      "Epoch 1312, Loss: 0.16890588402748108, Final Batch Loss: 0.10524525493383408\n",
      "Epoch 1313, Loss: 0.15961134433746338, Final Batch Loss: 0.08872782438993454\n",
      "Epoch 1314, Loss: 0.12518758699297905, Final Batch Loss: 0.05982291325926781\n",
      "Epoch 1315, Loss: 0.13423001766204834, Final Batch Loss: 0.05858892947435379\n",
      "Epoch 1316, Loss: 0.12706498801708221, Final Batch Loss: 0.05701024830341339\n",
      "Epoch 1317, Loss: 0.13487916439771652, Final Batch Loss: 0.058453306555747986\n",
      "Epoch 1318, Loss: 0.15972962230443954, Final Batch Loss: 0.090306855738163\n",
      "Epoch 1319, Loss: 0.09649242833256721, Final Batch Loss: 0.03620655834674835\n",
      "Epoch 1320, Loss: 0.09288812801241875, Final Batch Loss: 0.045180484652519226\n",
      "Epoch 1321, Loss: 0.16121353954076767, Final Batch Loss: 0.10333600640296936\n",
      "Epoch 1322, Loss: 0.12751039117574692, Final Batch Loss: 0.07521085441112518\n",
      "Epoch 1323, Loss: 0.12539194151759148, Final Batch Loss: 0.04563925042748451\n",
      "Epoch 1324, Loss: 0.15316549688577652, Final Batch Loss: 0.05508548021316528\n",
      "Epoch 1325, Loss: 0.11396906897425652, Final Batch Loss: 0.04228851571679115\n",
      "Epoch 1326, Loss: 0.1203625239431858, Final Batch Loss: 0.04944624379277229\n",
      "Epoch 1327, Loss: 0.11989128217101097, Final Batch Loss: 0.041204262524843216\n",
      "Epoch 1328, Loss: 0.10264428332448006, Final Batch Loss: 0.04478572681546211\n",
      "Epoch 1329, Loss: 0.15570712089538574, Final Batch Loss: 0.06519109755754471\n",
      "Epoch 1330, Loss: 0.12157008796930313, Final Batch Loss: 0.04834074527025223\n",
      "Epoch 1331, Loss: 0.1305607631802559, Final Batch Loss: 0.06609839200973511\n",
      "Epoch 1332, Loss: 0.157794289290905, Final Batch Loss: 0.08439984917640686\n",
      "Epoch 1333, Loss: 0.10117432475090027, Final Batch Loss: 0.028128422796726227\n",
      "Epoch 1334, Loss: 0.10283933952450752, Final Batch Loss: 0.05931909382343292\n",
      "Epoch 1335, Loss: 0.1664801426231861, Final Batch Loss: 0.1045747846364975\n",
      "Epoch 1336, Loss: 0.1445562168955803, Final Batch Loss: 0.07670507580041885\n",
      "Epoch 1337, Loss: 0.13538655638694763, Final Batch Loss: 0.06359905749559402\n",
      "Epoch 1338, Loss: 0.09833799302577972, Final Batch Loss: 0.018655233085155487\n",
      "Epoch 1339, Loss: 0.11767398938536644, Final Batch Loss: 0.07463432848453522\n",
      "Epoch 1340, Loss: 0.12562837079167366, Final Batch Loss: 0.07033659517765045\n",
      "Epoch 1341, Loss: 0.12259231880307198, Final Batch Loss: 0.06664369255304337\n",
      "Epoch 1342, Loss: 0.22129195928573608, Final Batch Loss: 0.14459416270256042\n",
      "Epoch 1343, Loss: 0.10551633313298225, Final Batch Loss: 0.03728766366839409\n",
      "Epoch 1344, Loss: 0.160676509141922, Final Batch Loss: 0.03877720981836319\n",
      "Epoch 1345, Loss: 0.15260886773467064, Final Batch Loss: 0.05983561649918556\n",
      "Epoch 1346, Loss: 0.14817125350236893, Final Batch Loss: 0.08326582610607147\n",
      "Epoch 1347, Loss: 0.12057559564709663, Final Batch Loss: 0.06102703884243965\n",
      "Epoch 1348, Loss: 0.11040468886494637, Final Batch Loss: 0.0555674284696579\n",
      "Epoch 1349, Loss: 0.10650880262255669, Final Batch Loss: 0.061370182782411575\n",
      "Epoch 1350, Loss: 0.13774458318948746, Final Batch Loss: 0.0530337318778038\n",
      "Epoch 1351, Loss: 0.1994992271065712, Final Batch Loss: 0.1129155158996582\n",
      "Epoch 1352, Loss: 0.13395504280924797, Final Batch Loss: 0.04344289377331734\n",
      "Epoch 1353, Loss: 0.15011471882462502, Final Batch Loss: 0.056211743503808975\n",
      "Epoch 1354, Loss: 0.14748670905828476, Final Batch Loss: 0.10225610435009003\n",
      "Epoch 1355, Loss: 0.08669144101440907, Final Batch Loss: 0.025967912748456\n",
      "Epoch 1356, Loss: 0.17633544653654099, Final Batch Loss: 0.08598018437623978\n",
      "Epoch 1357, Loss: 0.10684056580066681, Final Batch Loss: 0.06243477389216423\n",
      "Epoch 1358, Loss: 0.13776936382055283, Final Batch Loss: 0.0802854672074318\n",
      "Epoch 1359, Loss: 0.1535896733403206, Final Batch Loss: 0.07345801591873169\n",
      "Epoch 1360, Loss: 0.10834980383515358, Final Batch Loss: 0.05873432382941246\n",
      "Epoch 1361, Loss: 0.13092435896396637, Final Batch Loss: 0.06710506975650787\n",
      "Epoch 1362, Loss: 0.10952615365386009, Final Batch Loss: 0.05138903483748436\n",
      "Epoch 1363, Loss: 0.16203321143984795, Final Batch Loss: 0.06076463684439659\n",
      "Epoch 1364, Loss: 0.18484434485435486, Final Batch Loss: 0.042745620012283325\n",
      "Epoch 1365, Loss: 0.18161046132445335, Final Batch Loss: 0.13394862413406372\n",
      "Epoch 1366, Loss: 0.1317082867026329, Final Batch Loss: 0.04852944612503052\n",
      "Epoch 1367, Loss: 0.12249085307121277, Final Batch Loss: 0.08216290175914764\n",
      "Epoch 1368, Loss: 0.17137055471539497, Final Batch Loss: 0.05798086151480675\n",
      "Epoch 1369, Loss: 0.11156080663204193, Final Batch Loss: 0.05823748931288719\n",
      "Epoch 1370, Loss: 0.1584223322570324, Final Batch Loss: 0.10600123554468155\n",
      "Epoch 1371, Loss: 0.1782582402229309, Final Batch Loss: 0.07192680239677429\n",
      "Epoch 1372, Loss: 0.18832025676965714, Final Batch Loss: 0.12835262715816498\n",
      "Epoch 1373, Loss: 0.13134757429361343, Final Batch Loss: 0.05733489245176315\n",
      "Epoch 1374, Loss: 0.1554175764322281, Final Batch Loss: 0.06645224243402481\n",
      "Epoch 1375, Loss: 0.22025351971387863, Final Batch Loss: 0.13971002399921417\n",
      "Epoch 1376, Loss: 0.11309768632054329, Final Batch Loss: 0.04796707257628441\n",
      "Epoch 1377, Loss: 0.1680702194571495, Final Batch Loss: 0.09680920839309692\n",
      "Epoch 1378, Loss: 0.11323806643486023, Final Batch Loss: 0.06467346101999283\n",
      "Epoch 1379, Loss: 0.12240882590413094, Final Batch Loss: 0.03372037783265114\n",
      "Epoch 1380, Loss: 0.11190493404865265, Final Batch Loss: 0.06196855008602142\n",
      "Epoch 1381, Loss: 0.10369317978620529, Final Batch Loss: 0.05976320803165436\n",
      "Epoch 1382, Loss: 0.10162646695971489, Final Batch Loss: 0.054031144827604294\n",
      "Epoch 1383, Loss: 0.15750900655984879, Final Batch Loss: 0.09803944826126099\n",
      "Epoch 1384, Loss: 0.13471899181604385, Final Batch Loss: 0.0639142170548439\n",
      "Epoch 1385, Loss: 0.09389924257993698, Final Batch Loss: 0.027002230286598206\n",
      "Epoch 1386, Loss: 0.1269647814333439, Final Batch Loss: 0.08124815672636032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1387, Loss: 0.12932636588811874, Final Batch Loss: 0.07363341003656387\n",
      "Epoch 1388, Loss: 0.18299053609371185, Final Batch Loss: 0.10448095947504044\n",
      "Epoch 1389, Loss: 0.15342754870653152, Final Batch Loss: 0.06910833716392517\n",
      "Epoch 1390, Loss: 0.1213187500834465, Final Batch Loss: 0.052046723663806915\n",
      "Epoch 1391, Loss: 0.14442316442728043, Final Batch Loss: 0.06846679747104645\n",
      "Epoch 1392, Loss: 0.1265493929386139, Final Batch Loss: 0.05987934023141861\n",
      "Epoch 1393, Loss: 0.10000172629952431, Final Batch Loss: 0.03597057983279228\n",
      "Epoch 1394, Loss: 0.10518031194806099, Final Batch Loss: 0.03729083016514778\n",
      "Epoch 1395, Loss: 0.16569949686527252, Final Batch Loss: 0.07084883749485016\n",
      "Epoch 1396, Loss: 0.15089144557714462, Final Batch Loss: 0.10449355840682983\n",
      "Epoch 1397, Loss: 0.08791325241327286, Final Batch Loss: 0.04030083492398262\n",
      "Epoch 1398, Loss: 0.14483099430799484, Final Batch Loss: 0.06324341148138046\n",
      "Epoch 1399, Loss: 0.0917934998869896, Final Batch Loss: 0.0358140729367733\n",
      "Epoch 1400, Loss: 0.1464756242930889, Final Batch Loss: 0.08585608750581741\n",
      "Epoch 1401, Loss: 0.10032323002815247, Final Batch Loss: 0.06274913996458054\n",
      "Epoch 1402, Loss: 0.10804467275738716, Final Batch Loss: 0.05750657990574837\n",
      "Epoch 1403, Loss: 0.14945527538657188, Final Batch Loss: 0.05517197772860527\n",
      "Epoch 1404, Loss: 0.11648911982774734, Final Batch Loss: 0.031114958226680756\n",
      "Epoch 1405, Loss: 0.16667017340660095, Final Batch Loss: 0.09612420946359634\n",
      "Epoch 1406, Loss: 0.12960591167211533, Final Batch Loss: 0.08358752727508545\n",
      "Epoch 1407, Loss: 0.13137565180659294, Final Batch Loss: 0.07272637635469437\n",
      "Epoch 1408, Loss: 0.12461937218904495, Final Batch Loss: 0.044865719974040985\n",
      "Epoch 1409, Loss: 0.1227339394390583, Final Batch Loss: 0.05037154629826546\n",
      "Epoch 1410, Loss: 0.13375216722488403, Final Batch Loss: 0.0834534540772438\n",
      "Epoch 1411, Loss: 0.161052867770195, Final Batch Loss: 0.07805564254522324\n",
      "Epoch 1412, Loss: 0.14958421140909195, Final Batch Loss: 0.07966683804988861\n",
      "Epoch 1413, Loss: 0.09105680882930756, Final Batch Loss: 0.03491143137216568\n",
      "Epoch 1414, Loss: 0.10769541561603546, Final Batch Loss: 0.04660356044769287\n",
      "Epoch 1415, Loss: 0.1212974265217781, Final Batch Loss: 0.07998523861169815\n",
      "Epoch 1416, Loss: 0.12197703495621681, Final Batch Loss: 0.03401673957705498\n",
      "Epoch 1417, Loss: 0.12363489344716072, Final Batch Loss: 0.0638321042060852\n",
      "Epoch 1418, Loss: 0.131049282848835, Final Batch Loss: 0.0799526572227478\n",
      "Epoch 1419, Loss: 0.14700277894735336, Final Batch Loss: 0.05507107079029083\n",
      "Epoch 1420, Loss: 0.10393509268760681, Final Batch Loss: 0.05611256882548332\n",
      "Epoch 1421, Loss: 0.13529356941580772, Final Batch Loss: 0.07910965383052826\n",
      "Epoch 1422, Loss: 0.10788021981716156, Final Batch Loss: 0.06389258056879044\n",
      "Epoch 1423, Loss: 0.14028699323534966, Final Batch Loss: 0.05375758185982704\n",
      "Epoch 1424, Loss: 0.09724396839737892, Final Batch Loss: 0.06653972715139389\n",
      "Epoch 1425, Loss: 0.1229311041533947, Final Batch Loss: 0.04304173216223717\n",
      "Epoch 1426, Loss: 0.08284593001008034, Final Batch Loss: 0.04756809026002884\n",
      "Epoch 1427, Loss: 0.124473687261343, Final Batch Loss: 0.07867218554019928\n",
      "Epoch 1428, Loss: 0.15146560966968536, Final Batch Loss: 0.1024758517742157\n",
      "Epoch 1429, Loss: 0.09350490756332874, Final Batch Loss: 0.06730370968580246\n",
      "Epoch 1430, Loss: 0.13327795639634132, Final Batch Loss: 0.08208034187555313\n",
      "Epoch 1431, Loss: 0.1025453731417656, Final Batch Loss: 0.051339082419872284\n",
      "Epoch 1432, Loss: 0.1203036829829216, Final Batch Loss: 0.0668366551399231\n",
      "Epoch 1433, Loss: 0.10890395566821098, Final Batch Loss: 0.03847045078873634\n",
      "Epoch 1434, Loss: 0.11395232006907463, Final Batch Loss: 0.052969906479120255\n",
      "Epoch 1435, Loss: 0.11103153973817825, Final Batch Loss: 0.05814496427774429\n",
      "Epoch 1436, Loss: 0.1381714642047882, Final Batch Loss: 0.06532179564237595\n",
      "Epoch 1437, Loss: 0.1341250166296959, Final Batch Loss: 0.06963923573493958\n",
      "Epoch 1438, Loss: 0.1315264329314232, Final Batch Loss: 0.07350184768438339\n",
      "Epoch 1439, Loss: 0.1251293085515499, Final Batch Loss: 0.05234292522072792\n",
      "Epoch 1440, Loss: 0.14994776248931885, Final Batch Loss: 0.07434304058551788\n",
      "Epoch 1441, Loss: 0.1334116943180561, Final Batch Loss: 0.07715287059545517\n",
      "Epoch 1442, Loss: 0.08604262582957745, Final Batch Loss: 0.05562799051403999\n",
      "Epoch 1443, Loss: 0.1400674432516098, Final Batch Loss: 0.07904087752103806\n",
      "Epoch 1444, Loss: 0.12001048773527145, Final Batch Loss: 0.06579991430044174\n",
      "Epoch 1445, Loss: 0.1138300783932209, Final Batch Loss: 0.06889220327138901\n",
      "Epoch 1446, Loss: 0.11861930042505264, Final Batch Loss: 0.06664259731769562\n",
      "Epoch 1447, Loss: 0.2200039103627205, Final Batch Loss: 0.17339155077934265\n",
      "Epoch 1448, Loss: 0.14165066927671432, Final Batch Loss: 0.06656698137521744\n",
      "Epoch 1449, Loss: 0.12734758108854294, Final Batch Loss: 0.06276850402355194\n",
      "Epoch 1450, Loss: 0.10103422403335571, Final Batch Loss: 0.05698215588927269\n",
      "Epoch 1451, Loss: 0.09293046966195107, Final Batch Loss: 0.01741272583603859\n",
      "Epoch 1452, Loss: 0.10307251662015915, Final Batch Loss: 0.0393485426902771\n",
      "Epoch 1453, Loss: 0.10756183788180351, Final Batch Loss: 0.06433187425136566\n",
      "Epoch 1454, Loss: 0.10117189213633537, Final Batch Loss: 0.06121416762471199\n",
      "Epoch 1455, Loss: 0.08093472197651863, Final Batch Loss: 0.03936227783560753\n",
      "Epoch 1456, Loss: 0.11568317003548145, Final Batch Loss: 0.02946295775473118\n",
      "Epoch 1457, Loss: 0.1579628363251686, Final Batch Loss: 0.10792610049247742\n",
      "Epoch 1458, Loss: 0.09234659001231194, Final Batch Loss: 0.03977639973163605\n",
      "Epoch 1459, Loss: 0.14195355772972107, Final Batch Loss: 0.08373664319515228\n",
      "Epoch 1460, Loss: 0.13787657022476196, Final Batch Loss: 0.061301231384277344\n",
      "Epoch 1461, Loss: 0.10161767899990082, Final Batch Loss: 0.05433548241853714\n",
      "Epoch 1462, Loss: 0.10627428069710732, Final Batch Loss: 0.030899997800588608\n",
      "Epoch 1463, Loss: 0.15802236646413803, Final Batch Loss: 0.08168292045593262\n",
      "Epoch 1464, Loss: 0.12753574922680855, Final Batch Loss: 0.037621770054101944\n",
      "Epoch 1465, Loss: 0.09758048877120018, Final Batch Loss: 0.032922279089689255\n",
      "Epoch 1466, Loss: 0.14159156382083893, Final Batch Loss: 0.07562915980815887\n",
      "Epoch 1467, Loss: 0.1373826041817665, Final Batch Loss: 0.0941852405667305\n",
      "Epoch 1468, Loss: 0.1511007621884346, Final Batch Loss: 0.09339606761932373\n",
      "Epoch 1469, Loss: 0.1033836081624031, Final Batch Loss: 0.056974995881319046\n",
      "Epoch 1470, Loss: 0.12299549952149391, Final Batch Loss: 0.06235814839601517\n",
      "Epoch 1471, Loss: 0.13255644589662552, Final Batch Loss: 0.08152231574058533\n",
      "Epoch 1472, Loss: 0.11471658945083618, Final Batch Loss: 0.05934689939022064\n",
      "Epoch 1473, Loss: 0.13114003837108612, Final Batch Loss: 0.06901218742132187\n",
      "Epoch 1474, Loss: 0.09843206778168678, Final Batch Loss: 0.06271523982286453\n",
      "Epoch 1475, Loss: 0.1442275010049343, Final Batch Loss: 0.04718385264277458\n",
      "Epoch 1476, Loss: 0.10753452032804489, Final Batch Loss: 0.0493483729660511\n",
      "Epoch 1477, Loss: 0.11062395945191383, Final Batch Loss: 0.06406646966934204\n",
      "Epoch 1478, Loss: 0.11252371966838837, Final Batch Loss: 0.0555090494453907\n",
      "Epoch 1479, Loss: 0.10195537656545639, Final Batch Loss: 0.06778789311647415\n",
      "Epoch 1480, Loss: 0.13277238234877586, Final Batch Loss: 0.09664455056190491\n",
      "Epoch 1481, Loss: 0.09090558812022209, Final Batch Loss: 0.027674678713083267\n",
      "Epoch 1482, Loss: 0.0893910825252533, Final Batch Loss: 0.04643078148365021\n",
      "Epoch 1483, Loss: 0.11378055065870285, Final Batch Loss: 0.046493224799633026\n",
      "Epoch 1484, Loss: 0.13983380421996117, Final Batch Loss: 0.041463565081357956\n",
      "Epoch 1485, Loss: 0.1073233149945736, Final Batch Loss: 0.06546248495578766\n",
      "Epoch 1486, Loss: 0.14388437941670418, Final Batch Loss: 0.039701174944639206\n",
      "Epoch 1487, Loss: 0.13714883476495743, Final Batch Loss: 0.0938052386045456\n",
      "Epoch 1488, Loss: 0.17484041303396225, Final Batch Loss: 0.11309520155191422\n",
      "Epoch 1489, Loss: 0.09813645854592323, Final Batch Loss: 0.04863271117210388\n",
      "Epoch 1490, Loss: 0.0907156877219677, Final Batch Loss: 0.039770711213350296\n",
      "Epoch 1491, Loss: 0.13523608818650246, Final Batch Loss: 0.0484888069331646\n",
      "Epoch 1492, Loss: 0.08646909892559052, Final Batch Loss: 0.03990688920021057\n",
      "Epoch 1493, Loss: 0.12187942117452621, Final Batch Loss: 0.055543385446071625\n",
      "Epoch 1494, Loss: 0.1478414162993431, Final Batch Loss: 0.0941847413778305\n",
      "Epoch 1495, Loss: 0.10365187749266624, Final Batch Loss: 0.03203161433339119\n",
      "Epoch 1496, Loss: 0.12886279448866844, Final Batch Loss: 0.07847065478563309\n",
      "Epoch 1497, Loss: 0.07384397462010384, Final Batch Loss: 0.024830937385559082\n",
      "Epoch 1498, Loss: 0.13567401841282845, Final Batch Loss: 0.059121306985616684\n",
      "Epoch 1499, Loss: 0.1762402281165123, Final Batch Loss: 0.09846237301826477\n",
      "Epoch 1500, Loss: 0.16300632804632187, Final Batch Loss: 0.0787743628025055\n",
      "Epoch 1501, Loss: 0.12198126316070557, Final Batch Loss: 0.06246081367135048\n",
      "Epoch 1502, Loss: 0.17849547415971756, Final Batch Loss: 0.09270917624235153\n",
      "Epoch 1503, Loss: 0.10455908998847008, Final Batch Loss: 0.06485944241285324\n",
      "Epoch 1504, Loss: 0.14175524935126305, Final Batch Loss: 0.061407420784235\n",
      "Epoch 1505, Loss: 0.12715330347418785, Final Batch Loss: 0.045362379401922226\n",
      "Epoch 1506, Loss: 0.12289762496948242, Final Batch Loss: 0.03409969061613083\n",
      "Epoch 1507, Loss: 0.12065327540040016, Final Batch Loss: 0.05172266438603401\n",
      "Epoch 1508, Loss: 0.11289336532354355, Final Batch Loss: 0.054984670132398605\n",
      "Epoch 1509, Loss: 0.10576310381293297, Final Batch Loss: 0.047898922115564346\n",
      "Epoch 1510, Loss: 0.10472132451832294, Final Batch Loss: 0.07932479679584503\n",
      "Epoch 1511, Loss: 0.13699842244386673, Final Batch Loss: 0.07118034362792969\n",
      "Epoch 1512, Loss: 0.09955592080950737, Final Batch Loss: 0.04904678091406822\n",
      "Epoch 1513, Loss: 0.12083355709910393, Final Batch Loss: 0.06730853766202927\n",
      "Epoch 1514, Loss: 0.11910483241081238, Final Batch Loss: 0.050526924431324005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1515, Loss: 0.1538422703742981, Final Batch Loss: 0.09233888238668442\n",
      "Epoch 1516, Loss: 0.12479100003838539, Final Batch Loss: 0.07245873659849167\n",
      "Epoch 1517, Loss: 0.1421845369040966, Final Batch Loss: 0.08793702721595764\n",
      "Epoch 1518, Loss: 0.17316148430109024, Final Batch Loss: 0.07733942568302155\n",
      "Epoch 1519, Loss: 0.16521644592285156, Final Batch Loss: 0.09706654399633408\n",
      "Epoch 1520, Loss: 0.11427698656916618, Final Batch Loss: 0.0613878034055233\n",
      "Epoch 1521, Loss: 0.11085724085569382, Final Batch Loss: 0.04528393596410751\n",
      "Epoch 1522, Loss: 0.1189497783780098, Final Batch Loss: 0.032479189336299896\n",
      "Epoch 1523, Loss: 0.11389758065342903, Final Batch Loss: 0.059230174869298935\n",
      "Epoch 1524, Loss: 0.1236020177602768, Final Batch Loss: 0.05129829794168472\n",
      "Epoch 1525, Loss: 0.12382637709379196, Final Batch Loss: 0.06878210604190826\n",
      "Epoch 1526, Loss: 0.06167665310204029, Final Batch Loss: 0.024273870512843132\n",
      "Epoch 1527, Loss: 0.14052703976631165, Final Batch Loss: 0.06996013224124908\n",
      "Epoch 1528, Loss: 0.1378777138888836, Final Batch Loss: 0.05188990756869316\n",
      "Epoch 1529, Loss: 0.08923282101750374, Final Batch Loss: 0.05701354891061783\n",
      "Epoch 1530, Loss: 0.10775106027722359, Final Batch Loss: 0.0415988452732563\n",
      "Epoch 1531, Loss: 0.1398499608039856, Final Batch Loss: 0.09449919313192368\n",
      "Epoch 1532, Loss: 0.101399976760149, Final Batch Loss: 0.046922966837882996\n",
      "Epoch 1533, Loss: 0.08582664653658867, Final Batch Loss: 0.039020758122205734\n",
      "Epoch 1534, Loss: 0.1548318862915039, Final Batch Loss: 0.11232835054397583\n",
      "Epoch 1535, Loss: 0.1293684020638466, Final Batch Loss: 0.06693948805332184\n",
      "Epoch 1536, Loss: 0.10604401305317879, Final Batch Loss: 0.032348912209272385\n",
      "Epoch 1537, Loss: 0.12838756293058395, Final Batch Loss: 0.0648488700389862\n",
      "Epoch 1538, Loss: 0.13006753474473953, Final Batch Loss: 0.07600861042737961\n",
      "Epoch 1539, Loss: 0.18570098280906677, Final Batch Loss: 0.09344931691884995\n",
      "Epoch 1540, Loss: 0.12085310369729996, Final Batch Loss: 0.05450495332479477\n",
      "Epoch 1541, Loss: 0.09960116818547249, Final Batch Loss: 0.03933147341012955\n",
      "Epoch 1542, Loss: 0.14195577800273895, Final Batch Loss: 0.07470164448022842\n",
      "Epoch 1543, Loss: 0.10359740629792213, Final Batch Loss: 0.055996526032686234\n",
      "Epoch 1544, Loss: 0.11101497337222099, Final Batch Loss: 0.042869534343481064\n",
      "Epoch 1545, Loss: 0.09343068674206734, Final Batch Loss: 0.04376615211367607\n",
      "Epoch 1546, Loss: 0.0987168699502945, Final Batch Loss: 0.05519307032227516\n",
      "Epoch 1547, Loss: 0.13232262432575226, Final Batch Loss: 0.06555214524269104\n",
      "Epoch 1548, Loss: 0.11324027925729752, Final Batch Loss: 0.053815808147192\n",
      "Epoch 1549, Loss: 0.10815845429897308, Final Batch Loss: 0.05450147017836571\n",
      "Epoch 1550, Loss: 0.11367057263851166, Final Batch Loss: 0.07681477069854736\n",
      "Epoch 1551, Loss: 0.13159825652837753, Final Batch Loss: 0.07924798876047134\n",
      "Epoch 1552, Loss: 0.07787696830928326, Final Batch Loss: 0.02061859332025051\n",
      "Epoch 1553, Loss: 0.10750867426395416, Final Batch Loss: 0.061916202306747437\n",
      "Epoch 1554, Loss: 0.10693291947245598, Final Batch Loss: 0.06935697048902512\n",
      "Epoch 1555, Loss: 0.15673810243606567, Final Batch Loss: 0.10410340875387192\n",
      "Epoch 1556, Loss: 0.07542432844638824, Final Batch Loss: 0.025943096727132797\n",
      "Epoch 1557, Loss: 0.11434595845639706, Final Batch Loss: 0.08864845335483551\n",
      "Epoch 1558, Loss: 0.15983134880661964, Final Batch Loss: 0.112265944480896\n",
      "Epoch 1559, Loss: 0.12844198942184448, Final Batch Loss: 0.062436044216156006\n",
      "Epoch 1560, Loss: 0.10406316444277763, Final Batch Loss: 0.047813188284635544\n",
      "Epoch 1561, Loss: 0.11665751785039902, Final Batch Loss: 0.059763889759778976\n",
      "Epoch 1562, Loss: 0.1437934674322605, Final Batch Loss: 0.03438495472073555\n",
      "Epoch 1563, Loss: 0.08948718383908272, Final Batch Loss: 0.0439276248216629\n",
      "Epoch 1564, Loss: 0.10185993649065495, Final Batch Loss: 0.023804964497685432\n",
      "Epoch 1565, Loss: 0.15079057961702347, Final Batch Loss: 0.06573859602212906\n",
      "Epoch 1566, Loss: 0.13032985478639603, Final Batch Loss: 0.08463868498802185\n",
      "Epoch 1567, Loss: 0.07524888962507248, Final Batch Loss: 0.038603466004133224\n",
      "Epoch 1568, Loss: 0.10185934230685234, Final Batch Loss: 0.03986404091119766\n",
      "Epoch 1569, Loss: 0.10049452632665634, Final Batch Loss: 0.044657595455646515\n",
      "Epoch 1570, Loss: 0.07370662316679955, Final Batch Loss: 0.03660925477743149\n",
      "Epoch 1571, Loss: 0.138135626912117, Final Batch Loss: 0.08657439798116684\n",
      "Epoch 1572, Loss: 0.12262947112321854, Final Batch Loss: 0.05558133125305176\n",
      "Epoch 1573, Loss: 0.14175484329462051, Final Batch Loss: 0.07036833465099335\n",
      "Epoch 1574, Loss: 0.09311566315591335, Final Batch Loss: 0.030675796791911125\n",
      "Epoch 1575, Loss: 0.07756910473108292, Final Batch Loss: 0.03617430105805397\n",
      "Epoch 1576, Loss: 0.13641027733683586, Final Batch Loss: 0.07949740439653397\n",
      "Epoch 1577, Loss: 0.1161322370171547, Final Batch Loss: 0.035818278789520264\n",
      "Epoch 1578, Loss: 0.10301036387681961, Final Batch Loss: 0.026247091591358185\n",
      "Epoch 1579, Loss: 0.19419335573911667, Final Batch Loss: 0.11754688620567322\n",
      "Epoch 1580, Loss: 0.12359578534960747, Final Batch Loss: 0.05515659227967262\n",
      "Epoch 1581, Loss: 0.11157754436135292, Final Batch Loss: 0.05790781229734421\n",
      "Epoch 1582, Loss: 0.09704569727182388, Final Batch Loss: 0.05052090436220169\n",
      "Epoch 1583, Loss: 0.08943548984825611, Final Batch Loss: 0.02647685445845127\n",
      "Epoch 1584, Loss: 0.095354825258255, Final Batch Loss: 0.0393553227186203\n",
      "Epoch 1585, Loss: 0.10369374603033066, Final Batch Loss: 0.05605601146817207\n",
      "Epoch 1586, Loss: 0.08293548971414566, Final Batch Loss: 0.045828063040971756\n",
      "Epoch 1587, Loss: 0.08481288701295853, Final Batch Loss: 0.0334249809384346\n",
      "Epoch 1588, Loss: 0.12202560156583786, Final Batch Loss: 0.05811339616775513\n",
      "Epoch 1589, Loss: 0.11514715850353241, Final Batch Loss: 0.07404119521379471\n",
      "Epoch 1590, Loss: 0.07790087535977364, Final Batch Loss: 0.031989093869924545\n",
      "Epoch 1591, Loss: 0.05715065822005272, Final Batch Loss: 0.017077460885047913\n",
      "Epoch 1592, Loss: 0.08009016886353493, Final Batch Loss: 0.03772342950105667\n",
      "Epoch 1593, Loss: 0.13353240489959717, Final Batch Loss: 0.07079529017210007\n",
      "Epoch 1594, Loss: 0.1023612879216671, Final Batch Loss: 0.04722770303487778\n",
      "Epoch 1595, Loss: 0.10897613316774368, Final Batch Loss: 0.05512881651520729\n",
      "Epoch 1596, Loss: 0.1534263975918293, Final Batch Loss: 0.11961844563484192\n",
      "Epoch 1597, Loss: 0.10656530037522316, Final Batch Loss: 0.04390520974993706\n",
      "Epoch 1598, Loss: 0.08248201757669449, Final Batch Loss: 0.03415555879473686\n",
      "Epoch 1599, Loss: 0.14047198742628098, Final Batch Loss: 0.10150288790464401\n",
      "Epoch 1600, Loss: 0.10209540277719498, Final Batch Loss: 0.04850363731384277\n",
      "Epoch 1601, Loss: 0.10110814869403839, Final Batch Loss: 0.047952961176633835\n",
      "Epoch 1602, Loss: 0.09648366272449493, Final Batch Loss: 0.06329349428415298\n",
      "Epoch 1603, Loss: 0.145036518573761, Final Batch Loss: 0.08571481704711914\n",
      "Epoch 1604, Loss: 0.10033474117517471, Final Batch Loss: 0.033862873911857605\n",
      "Epoch 1605, Loss: 0.08214262500405312, Final Batch Loss: 0.03413461521267891\n",
      "Epoch 1606, Loss: 0.0806974545121193, Final Batch Loss: 0.022392727434635162\n",
      "Epoch 1607, Loss: 0.09312409162521362, Final Batch Loss: 0.04166989400982857\n",
      "Epoch 1608, Loss: 0.12348871305584908, Final Batch Loss: 0.05930226668715477\n",
      "Epoch 1609, Loss: 0.10121199488639832, Final Batch Loss: 0.030810333788394928\n",
      "Epoch 1610, Loss: 0.10212486982345581, Final Batch Loss: 0.0501241572201252\n",
      "Epoch 1611, Loss: 0.12364744208753109, Final Batch Loss: 0.023254429921507835\n",
      "Epoch 1612, Loss: 0.15556053817272186, Final Batch Loss: 0.07455381751060486\n",
      "Epoch 1613, Loss: 0.10920070484280586, Final Batch Loss: 0.05142277106642723\n",
      "Epoch 1614, Loss: 0.13655410706996918, Final Batch Loss: 0.10069148242473602\n",
      "Epoch 1615, Loss: 0.11658590659499168, Final Batch Loss: 0.041667092591524124\n",
      "Epoch 1616, Loss: 0.12446805089712143, Final Batch Loss: 0.038156718015670776\n",
      "Epoch 1617, Loss: 0.1502278670668602, Final Batch Loss: 0.09623856097459793\n",
      "Epoch 1618, Loss: 0.13274184986948967, Final Batch Loss: 0.0458163283765316\n",
      "Epoch 1619, Loss: 0.09555129520595074, Final Batch Loss: 0.023094190284609795\n",
      "Epoch 1620, Loss: 0.14193586260080338, Final Batch Loss: 0.0800483375787735\n",
      "Epoch 1621, Loss: 0.10607336834073067, Final Batch Loss: 0.05935097858309746\n",
      "Epoch 1622, Loss: 0.10770216956734657, Final Batch Loss: 0.036863040179014206\n",
      "Epoch 1623, Loss: 0.11969300359487534, Final Batch Loss: 0.05898497626185417\n",
      "Epoch 1624, Loss: 0.10118024796247482, Final Batch Loss: 0.05630587413907051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1625, Loss: 0.11836538091301918, Final Batch Loss: 0.038199279457330704\n",
      "Epoch 1626, Loss: 0.09576097130775452, Final Batch Loss: 0.054439395666122437\n",
      "Epoch 1627, Loss: 0.1167263612151146, Final Batch Loss: 0.0666889175772667\n",
      "Epoch 1628, Loss: 0.13047124445438385, Final Batch Loss: 0.0550994873046875\n",
      "Epoch 1629, Loss: 0.16167007759213448, Final Batch Loss: 0.049941595643758774\n",
      "Epoch 1630, Loss: 0.09103570878505707, Final Batch Loss: 0.06141028180718422\n",
      "Epoch 1631, Loss: 0.09228435903787613, Final Batch Loss: 0.04678225517272949\n",
      "Epoch 1632, Loss: 0.08706341311335564, Final Batch Loss: 0.03619801998138428\n",
      "Epoch 1633, Loss: 0.15500442683696747, Final Batch Loss: 0.09184752404689789\n",
      "Epoch 1634, Loss: 0.13119568675756454, Final Batch Loss: 0.07986129075288773\n",
      "Epoch 1635, Loss: 0.07273396104574203, Final Batch Loss: 0.03876994550228119\n",
      "Epoch 1636, Loss: 0.0818747840821743, Final Batch Loss: 0.035706982016563416\n",
      "Epoch 1637, Loss: 0.07026331126689911, Final Batch Loss: 0.039913859218358994\n",
      "Epoch 1638, Loss: 0.1467582806944847, Final Batch Loss: 0.07277806103229523\n",
      "Epoch 1639, Loss: 0.09852986596524715, Final Batch Loss: 0.02528219483792782\n",
      "Epoch 1640, Loss: 0.1003369502723217, Final Batch Loss: 0.050161946564912796\n",
      "Epoch 1641, Loss: 0.08341844007372856, Final Batch Loss: 0.02442096546292305\n",
      "Epoch 1642, Loss: 0.1224689781665802, Final Batch Loss: 0.06399083137512207\n",
      "Epoch 1643, Loss: 0.11211708560585976, Final Batch Loss: 0.06050538644194603\n",
      "Epoch 1644, Loss: 0.09284069389104843, Final Batch Loss: 0.04873033985495567\n",
      "Epoch 1645, Loss: 0.12303707376122475, Final Batch Loss: 0.07760333269834518\n",
      "Epoch 1646, Loss: 0.1060046274214983, Final Batch Loss: 0.020377935841679573\n",
      "Epoch 1647, Loss: 0.11818493530154228, Final Batch Loss: 0.07103937119245529\n",
      "Epoch 1648, Loss: 0.11638624593615532, Final Batch Loss: 0.052038345485925674\n",
      "Epoch 1649, Loss: 0.09020683914422989, Final Batch Loss: 0.0164395272731781\n",
      "Epoch 1650, Loss: 0.09750441461801529, Final Batch Loss: 0.01928563416004181\n",
      "Epoch 1651, Loss: 0.10815010964870453, Final Batch Loss: 0.048691947013139725\n",
      "Epoch 1652, Loss: 0.09215426445007324, Final Batch Loss: 0.03296637907624245\n",
      "Epoch 1653, Loss: 0.10548428818583488, Final Batch Loss: 0.04893647879362106\n",
      "Epoch 1654, Loss: 0.12181141600012779, Final Batch Loss: 0.05947931110858917\n",
      "Epoch 1655, Loss: 0.08954519778490067, Final Batch Loss: 0.03374452516436577\n",
      "Epoch 1656, Loss: 0.14259528741240501, Final Batch Loss: 0.054467011243104935\n",
      "Epoch 1657, Loss: 0.11029715463519096, Final Batch Loss: 0.0668901577591896\n",
      "Epoch 1658, Loss: 0.09618455916643143, Final Batch Loss: 0.06928660720586777\n",
      "Epoch 1659, Loss: 0.12034218572080135, Final Batch Loss: 0.030857926234602928\n",
      "Epoch 1660, Loss: 0.10993178561329842, Final Batch Loss: 0.08233468234539032\n",
      "Epoch 1661, Loss: 0.11816541105508804, Final Batch Loss: 0.059120964258909225\n",
      "Epoch 1662, Loss: 0.08523753099143505, Final Batch Loss: 0.030613409355282784\n",
      "Epoch 1663, Loss: 0.10057070106267929, Final Batch Loss: 0.06810900568962097\n",
      "Epoch 1664, Loss: 0.10001067444682121, Final Batch Loss: 0.06407874822616577\n",
      "Epoch 1665, Loss: 0.07404353097081184, Final Batch Loss: 0.037300579249858856\n",
      "Epoch 1666, Loss: 0.10849888250231743, Final Batch Loss: 0.04622510448098183\n",
      "Epoch 1667, Loss: 0.09209533408284187, Final Batch Loss: 0.05050020292401314\n",
      "Epoch 1668, Loss: 0.1389019750058651, Final Batch Loss: 0.06249656155705452\n",
      "Epoch 1669, Loss: 0.1158904992043972, Final Batch Loss: 0.07321395725011826\n",
      "Epoch 1670, Loss: 0.06366341933608055, Final Batch Loss: 0.03186391666531563\n",
      "Epoch 1671, Loss: 0.11351772397756577, Final Batch Loss: 0.054693687707185745\n",
      "Epoch 1672, Loss: 0.10818681120872498, Final Batch Loss: 0.042051203548908234\n",
      "Epoch 1673, Loss: 0.10690413415431976, Final Batch Loss: 0.046158317476511\n",
      "Epoch 1674, Loss: 0.10703232139348984, Final Batch Loss: 0.05920102074742317\n",
      "Epoch 1675, Loss: 0.10440731793642044, Final Batch Loss: 0.06768224388360977\n",
      "Epoch 1676, Loss: 0.07556473836302757, Final Batch Loss: 0.03462129831314087\n",
      "Epoch 1677, Loss: 0.08078973926603794, Final Batch Loss: 0.029064545407891273\n",
      "Epoch 1678, Loss: 0.1086500957608223, Final Batch Loss: 0.06052219122648239\n",
      "Epoch 1679, Loss: 0.08533279970288277, Final Batch Loss: 0.05276233330368996\n",
      "Epoch 1680, Loss: 0.09400045312941074, Final Batch Loss: 0.07534536719322205\n",
      "Epoch 1681, Loss: 0.06923121772706509, Final Batch Loss: 0.03804478049278259\n",
      "Epoch 1682, Loss: 0.096904456615448, Final Batch Loss: 0.02109849452972412\n",
      "Epoch 1683, Loss: 0.13827713951468468, Final Batch Loss: 0.07970844209194183\n",
      "Epoch 1684, Loss: 0.1509772688150406, Final Batch Loss: 0.0883789211511612\n",
      "Epoch 1685, Loss: 0.16031760349869728, Final Batch Loss: 0.10451950132846832\n",
      "Epoch 1686, Loss: 0.10822676122188568, Final Batch Loss: 0.06944643706083298\n",
      "Epoch 1687, Loss: 0.06202229857444763, Final Batch Loss: 0.020342860370874405\n",
      "Epoch 1688, Loss: 0.12743674963712692, Final Batch Loss: 0.04646936058998108\n",
      "Epoch 1689, Loss: 0.13008978962898254, Final Batch Loss: 0.049464136362075806\n",
      "Epoch 1690, Loss: 0.06284726597368717, Final Batch Loss: 0.02832120843231678\n",
      "Epoch 1691, Loss: 0.09647486731410027, Final Batch Loss: 0.041309505701065063\n",
      "Epoch 1692, Loss: 0.09483771212399006, Final Batch Loss: 0.030623020604252815\n",
      "Epoch 1693, Loss: 0.11464051157236099, Final Batch Loss: 0.07608888298273087\n",
      "Epoch 1694, Loss: 0.08130637556314468, Final Batch Loss: 0.023642048239707947\n",
      "Epoch 1695, Loss: 0.13988085091114044, Final Batch Loss: 0.06500472873449326\n",
      "Epoch 1696, Loss: 0.08657626435160637, Final Batch Loss: 0.0400385856628418\n",
      "Epoch 1697, Loss: 0.08747723139822483, Final Batch Loss: 0.058854348957538605\n",
      "Epoch 1698, Loss: 0.11495694890618324, Final Batch Loss: 0.07007855921983719\n",
      "Epoch 1699, Loss: 0.07729380205273628, Final Batch Loss: 0.04196346551179886\n",
      "Epoch 1700, Loss: 0.11057742685079575, Final Batch Loss: 0.041288428008556366\n",
      "Epoch 1701, Loss: 0.1906304731965065, Final Batch Loss: 0.1242758184671402\n",
      "Epoch 1702, Loss: 0.10477304831147194, Final Batch Loss: 0.07606059312820435\n",
      "Epoch 1703, Loss: 0.09059171751141548, Final Batch Loss: 0.03254925087094307\n",
      "Epoch 1704, Loss: 0.08612391352653503, Final Batch Loss: 0.03636545687913895\n",
      "Epoch 1705, Loss: 0.10152522847056389, Final Batch Loss: 0.04550781100988388\n",
      "Epoch 1706, Loss: 0.10208289697766304, Final Batch Loss: 0.07053316384553909\n",
      "Epoch 1707, Loss: 0.14744061417877674, Final Batch Loss: 0.11789726465940475\n",
      "Epoch 1708, Loss: 0.05901149846613407, Final Batch Loss: 0.016256937757134438\n",
      "Epoch 1709, Loss: 0.14321019873023033, Final Batch Loss: 0.08992032706737518\n",
      "Epoch 1710, Loss: 0.09935612231492996, Final Batch Loss: 0.052546534687280655\n",
      "Epoch 1711, Loss: 0.1253143958747387, Final Batch Loss: 0.0808056890964508\n",
      "Epoch 1712, Loss: 0.1100564431399107, Final Batch Loss: 0.028897276148200035\n",
      "Epoch 1713, Loss: 0.09836889430880547, Final Batch Loss: 0.0600115992128849\n",
      "Epoch 1714, Loss: 0.10736777633428574, Final Batch Loss: 0.03278374671936035\n",
      "Epoch 1715, Loss: 0.11348260566592216, Final Batch Loss: 0.04491887614130974\n",
      "Epoch 1716, Loss: 0.08386335894465446, Final Batch Loss: 0.03175456076860428\n",
      "Epoch 1717, Loss: 0.12354734539985657, Final Batch Loss: 0.08126701414585114\n",
      "Epoch 1718, Loss: 0.10599329695105553, Final Batch Loss: 0.06621405482292175\n",
      "Epoch 1719, Loss: 0.07270655781030655, Final Batch Loss: 0.0314667783677578\n",
      "Epoch 1720, Loss: 0.09595886617898941, Final Batch Loss: 0.05682562664151192\n",
      "Epoch 1721, Loss: 0.07389620132744312, Final Batch Loss: 0.026145605370402336\n",
      "Epoch 1722, Loss: 0.14661230146884918, Final Batch Loss: 0.10288656502962112\n",
      "Epoch 1723, Loss: 0.1600705087184906, Final Batch Loss: 0.11416039615869522\n",
      "Epoch 1724, Loss: 0.12998434156179428, Final Batch Loss: 0.026893027126789093\n",
      "Epoch 1725, Loss: 0.13977910950779915, Final Batch Loss: 0.059845540672540665\n",
      "Epoch 1726, Loss: 0.19189411401748657, Final Batch Loss: 0.12363322079181671\n",
      "Epoch 1727, Loss: 0.08562205359339714, Final Batch Loss: 0.04335938021540642\n",
      "Epoch 1728, Loss: 0.1315978653728962, Final Batch Loss: 0.08790304511785507\n",
      "Epoch 1729, Loss: 0.12532520294189453, Final Batch Loss: 0.08572719246149063\n",
      "Epoch 1730, Loss: 0.08472279459238052, Final Batch Loss: 0.04948705807328224\n",
      "Epoch 1731, Loss: 0.10991354659199715, Final Batch Loss: 0.031257156282663345\n",
      "Epoch 1732, Loss: 0.1143665760755539, Final Batch Loss: 0.04742646962404251\n",
      "Epoch 1733, Loss: 0.10355900973081589, Final Batch Loss: 0.04155856743454933\n",
      "Epoch 1734, Loss: 0.10694514960050583, Final Batch Loss: 0.06531063467264175\n",
      "Epoch 1735, Loss: 0.10631078109145164, Final Batch Loss: 0.03954878821969032\n",
      "Epoch 1736, Loss: 0.12687072902917862, Final Batch Loss: 0.06476716697216034\n",
      "Epoch 1737, Loss: 0.10981836542487144, Final Batch Loss: 0.038761477917432785\n",
      "Epoch 1738, Loss: 0.11513761803507805, Final Batch Loss: 0.08175793290138245\n",
      "Epoch 1739, Loss: 0.12019297853112221, Final Batch Loss: 0.05886087566614151\n",
      "Epoch 1740, Loss: 0.0741365272551775, Final Batch Loss: 0.049525611102581024\n",
      "Epoch 1741, Loss: 0.1026746816933155, Final Batch Loss: 0.049030400812625885\n",
      "Epoch 1742, Loss: 0.1071479506790638, Final Batch Loss: 0.05448441952466965\n",
      "Epoch 1743, Loss: 0.0813894160091877, Final Batch Loss: 0.032521091401576996\n",
      "Epoch 1744, Loss: 0.08424798026680946, Final Batch Loss: 0.03174363076686859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1745, Loss: 0.1744644157588482, Final Batch Loss: 0.11442508548498154\n",
      "Epoch 1746, Loss: 0.10518817231059074, Final Batch Loss: 0.05455400422215462\n",
      "Epoch 1747, Loss: 0.12017994746565819, Final Batch Loss: 0.07335365563631058\n",
      "Epoch 1748, Loss: 0.11344537138938904, Final Batch Loss: 0.041983991861343384\n",
      "Epoch 1749, Loss: 0.07200875505805016, Final Batch Loss: 0.03514872118830681\n",
      "Epoch 1750, Loss: 0.10054283402860165, Final Batch Loss: 0.07537062466144562\n",
      "Epoch 1751, Loss: 0.11078332364559174, Final Batch Loss: 0.06590193510055542\n",
      "Epoch 1752, Loss: 0.10773922875523567, Final Batch Loss: 0.029921863228082657\n",
      "Epoch 1753, Loss: 0.07805002853274345, Final Batch Loss: 0.03127312287688255\n",
      "Epoch 1754, Loss: 0.07598362676799297, Final Batch Loss: 0.027595913037657738\n",
      "Epoch 1755, Loss: 0.11115448549389839, Final Batch Loss: 0.06288368999958038\n",
      "Epoch 1756, Loss: 0.07766202092170715, Final Batch Loss: 0.053214650601148605\n",
      "Epoch 1757, Loss: 0.08074249513447285, Final Batch Loss: 0.020179813727736473\n",
      "Epoch 1758, Loss: 0.19229362159967422, Final Batch Loss: 0.11253806203603745\n",
      "Epoch 1759, Loss: 0.0944274365901947, Final Batch Loss: 0.04291963949799538\n",
      "Epoch 1760, Loss: 0.12173812463879585, Final Batch Loss: 0.05934392288327217\n",
      "Epoch 1761, Loss: 0.11204101890325546, Final Batch Loss: 0.07899371534585953\n",
      "Epoch 1762, Loss: 0.11571741849184036, Final Batch Loss: 0.05931529402732849\n",
      "Epoch 1763, Loss: 0.09356680139899254, Final Batch Loss: 0.03936993330717087\n",
      "Epoch 1764, Loss: 0.14520149677991867, Final Batch Loss: 0.08044391870498657\n",
      "Epoch 1765, Loss: 0.1265013925731182, Final Batch Loss: 0.08191563189029694\n",
      "Epoch 1766, Loss: 0.13684933260083199, Final Batch Loss: 0.08801458030939102\n",
      "Epoch 1767, Loss: 0.09587050601840019, Final Batch Loss: 0.03476659208536148\n",
      "Epoch 1768, Loss: 0.08399923704564571, Final Batch Loss: 0.013048311695456505\n",
      "Epoch 1769, Loss: 0.067294642329216, Final Batch Loss: 0.033318836241960526\n",
      "Epoch 1770, Loss: 0.11374618858098984, Final Batch Loss: 0.07569395750761032\n",
      "Epoch 1771, Loss: 0.15507782995700836, Final Batch Loss: 0.08932501077651978\n",
      "Epoch 1772, Loss: 0.10150568932294846, Final Batch Loss: 0.04634088650345802\n",
      "Epoch 1773, Loss: 0.11645429581403732, Final Batch Loss: 0.07436195760965347\n",
      "Epoch 1774, Loss: 0.09066531620919704, Final Batch Loss: 0.061300914734601974\n",
      "Epoch 1775, Loss: 0.10431207343935966, Final Batch Loss: 0.03789603337645531\n",
      "Epoch 1776, Loss: 0.12258337810635567, Final Batch Loss: 0.06237916275858879\n",
      "Epoch 1777, Loss: 0.07024781592190266, Final Batch Loss: 0.04113258048892021\n",
      "Epoch 1778, Loss: 0.11279074847698212, Final Batch Loss: 0.05933535099029541\n",
      "Epoch 1779, Loss: 0.06761632300913334, Final Batch Loss: 0.027347201481461525\n",
      "Epoch 1780, Loss: 0.11325569823384285, Final Batch Loss: 0.07847458124160767\n",
      "Epoch 1781, Loss: 0.0875236727297306, Final Batch Loss: 0.03869052976369858\n",
      "Epoch 1782, Loss: 0.05272706039249897, Final Batch Loss: 0.02341553382575512\n",
      "Epoch 1783, Loss: 0.08028418198227882, Final Batch Loss: 0.02385452389717102\n",
      "Epoch 1784, Loss: 0.07971149869263172, Final Batch Loss: 0.0262338537722826\n",
      "Epoch 1785, Loss: 0.17169764265418053, Final Batch Loss: 0.061529193073511124\n",
      "Epoch 1786, Loss: 0.077114537358284, Final Batch Loss: 0.05351948365569115\n",
      "Epoch 1787, Loss: 0.06781439110636711, Final Batch Loss: 0.030507441610097885\n",
      "Epoch 1788, Loss: 0.1167296115309, Final Batch Loss: 0.08934628218412399\n",
      "Epoch 1789, Loss: 0.08986417204141617, Final Batch Loss: 0.06513809412717819\n",
      "Epoch 1790, Loss: 0.1862495243549347, Final Batch Loss: 0.08269191533327103\n",
      "Epoch 1791, Loss: 0.09606443718075752, Final Batch Loss: 0.03810534626245499\n",
      "Epoch 1792, Loss: 0.08684064261615276, Final Batch Loss: 0.018163612112402916\n",
      "Epoch 1793, Loss: 0.14035071432590485, Final Batch Loss: 0.0774691253900528\n",
      "Epoch 1794, Loss: 0.18685176968574524, Final Batch Loss: 0.09842975437641144\n",
      "Epoch 1795, Loss: 0.11556153371930122, Final Batch Loss: 0.07019145786762238\n",
      "Epoch 1796, Loss: 0.13233640789985657, Final Batch Loss: 0.0726323053240776\n",
      "Epoch 1797, Loss: 0.15685465186834335, Final Batch Loss: 0.0862831398844719\n",
      "Epoch 1798, Loss: 0.09912175312638283, Final Batch Loss: 0.05256776884198189\n",
      "Epoch 1799, Loss: 0.09895476698875427, Final Batch Loss: 0.0447663776576519\n",
      "Epoch 1800, Loss: 0.13038359582424164, Final Batch Loss: 0.09183594584465027\n",
      "Epoch 1801, Loss: 0.07433628477156162, Final Batch Loss: 0.029115786775946617\n",
      "Epoch 1802, Loss: 0.1283716857433319, Final Batch Loss: 0.06170664727687836\n",
      "Epoch 1803, Loss: 0.13074752315878868, Final Batch Loss: 0.09376485645771027\n",
      "Epoch 1804, Loss: 0.08542605675756931, Final Batch Loss: 0.026564298197627068\n",
      "Epoch 1805, Loss: 0.1802474707365036, Final Batch Loss: 0.08875487744808197\n",
      "Epoch 1806, Loss: 0.06133168190717697, Final Batch Loss: 0.022877197712659836\n",
      "Epoch 1807, Loss: 0.11400054022669792, Final Batch Loss: 0.06794728338718414\n",
      "Epoch 1808, Loss: 0.11356077343225479, Final Batch Loss: 0.0425315797328949\n",
      "Epoch 1809, Loss: 0.10850182175636292, Final Batch Loss: 0.05450884625315666\n",
      "Epoch 1810, Loss: 0.09336530789732933, Final Batch Loss: 0.03397911787033081\n",
      "Epoch 1811, Loss: 0.12325573712587357, Final Batch Loss: 0.07252255827188492\n",
      "Epoch 1812, Loss: 0.09077967703342438, Final Batch Loss: 0.05432044714689255\n",
      "Epoch 1813, Loss: 0.09685627371072769, Final Batch Loss: 0.05445271357893944\n",
      "Epoch 1814, Loss: 0.11030883342027664, Final Batch Loss: 0.07409268617630005\n",
      "Epoch 1815, Loss: 0.09118544682860374, Final Batch Loss: 0.044531580060720444\n",
      "Epoch 1816, Loss: 0.10184227302670479, Final Batch Loss: 0.05102367699146271\n",
      "Epoch 1817, Loss: 0.06815210916101933, Final Batch Loss: 0.022106600925326347\n",
      "Epoch 1818, Loss: 0.08719463646411896, Final Batch Loss: 0.039934948086738586\n",
      "Epoch 1819, Loss: 0.12383635342121124, Final Batch Loss: 0.06220410764217377\n",
      "Epoch 1820, Loss: 0.11490239948034286, Final Batch Loss: 0.05314941331744194\n",
      "Epoch 1821, Loss: 0.11190543696284294, Final Batch Loss: 0.03760493919253349\n",
      "Epoch 1822, Loss: 0.07232917286455631, Final Batch Loss: 0.023610027506947517\n",
      "Epoch 1823, Loss: 0.11415573582053185, Final Batch Loss: 0.05436599254608154\n",
      "Epoch 1824, Loss: 0.11315800249576569, Final Batch Loss: 0.06197050213813782\n",
      "Epoch 1825, Loss: 0.09042841382324696, Final Batch Loss: 0.019702622666954994\n",
      "Epoch 1826, Loss: 0.1310679018497467, Final Batch Loss: 0.0802394449710846\n",
      "Epoch 1827, Loss: 0.12397165969014168, Final Batch Loss: 0.062185950577259064\n",
      "Epoch 1828, Loss: 0.12125274911522865, Final Batch Loss: 0.07941020280122757\n",
      "Epoch 1829, Loss: 0.09911508485674858, Final Batch Loss: 0.07225622981786728\n",
      "Epoch 1830, Loss: 0.08069934323430061, Final Batch Loss: 0.03242599219083786\n",
      "Epoch 1831, Loss: 0.10547356493771076, Final Batch Loss: 0.08341214805841446\n",
      "Epoch 1832, Loss: 0.09213612973690033, Final Batch Loss: 0.03643076494336128\n",
      "Epoch 1833, Loss: 0.10505189746618271, Final Batch Loss: 0.06567323952913284\n",
      "Epoch 1834, Loss: 0.09821442142128944, Final Batch Loss: 0.04833056032657623\n",
      "Epoch 1835, Loss: 0.09873266890645027, Final Batch Loss: 0.05516548082232475\n",
      "Epoch 1836, Loss: 0.07669225335121155, Final Batch Loss: 0.03738575056195259\n",
      "Epoch 1837, Loss: 0.09585040807723999, Final Batch Loss: 0.04477504640817642\n",
      "Epoch 1838, Loss: 0.10145485959947109, Final Batch Loss: 0.07485001534223557\n",
      "Epoch 1839, Loss: 0.08095579780638218, Final Batch Loss: 0.027720442041754723\n",
      "Epoch 1840, Loss: 0.14643080905079842, Final Batch Loss: 0.11232890188694\n",
      "Epoch 1841, Loss: 0.14142761752009392, Final Batch Loss: 0.09048444032669067\n",
      "Epoch 1842, Loss: 0.10984228178858757, Final Batch Loss: 0.05723169445991516\n",
      "Epoch 1843, Loss: 0.08476191386580467, Final Batch Loss: 0.034904588013887405\n",
      "Epoch 1844, Loss: 0.15736979991197586, Final Batch Loss: 0.07273360341787338\n",
      "Epoch 1845, Loss: 0.1522640399634838, Final Batch Loss: 0.09907671809196472\n",
      "Epoch 1846, Loss: 0.08769555017352104, Final Batch Loss: 0.03390415385365486\n",
      "Epoch 1847, Loss: 0.12087249383330345, Final Batch Loss: 0.06176314130425453\n",
      "Epoch 1848, Loss: 0.1484401673078537, Final Batch Loss: 0.07197558134794235\n",
      "Epoch 1849, Loss: 0.07758494466543198, Final Batch Loss: 0.03660591319203377\n",
      "Epoch 1850, Loss: 0.08403856493532658, Final Batch Loss: 0.0266630370169878\n",
      "Epoch 1851, Loss: 0.13538704439997673, Final Batch Loss: 0.041964564472436905\n",
      "Epoch 1852, Loss: 0.10201823338866234, Final Batch Loss: 0.030282843858003616\n",
      "Epoch 1853, Loss: 0.08452194556593895, Final Batch Loss: 0.043521855026483536\n",
      "Epoch 1854, Loss: 0.1437128335237503, Final Batch Loss: 0.07227127999067307\n",
      "Epoch 1855, Loss: 0.12096160277724266, Final Batch Loss: 0.031326133757829666\n",
      "Epoch 1856, Loss: 0.12086311727762222, Final Batch Loss: 0.05402553081512451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1857, Loss: 0.10748332366347313, Final Batch Loss: 0.037477802485227585\n",
      "Epoch 1858, Loss: 0.12780247256159782, Final Batch Loss: 0.03188220039010048\n",
      "Epoch 1859, Loss: 0.17521698772907257, Final Batch Loss: 0.1258775144815445\n",
      "Epoch 1860, Loss: 0.1080620028078556, Final Batch Loss: 0.0562627799808979\n",
      "Epoch 1861, Loss: 0.12015162035822868, Final Batch Loss: 0.06136765703558922\n",
      "Epoch 1862, Loss: 0.10404106974601746, Final Batch Loss: 0.018153496086597443\n",
      "Epoch 1863, Loss: 0.11194943636655807, Final Batch Loss: 0.07283443957567215\n",
      "Epoch 1864, Loss: 0.1375424489378929, Final Batch Loss: 0.07253868877887726\n",
      "Epoch 1865, Loss: 0.09516039118170738, Final Batch Loss: 0.03696488216519356\n",
      "Epoch 1866, Loss: 0.12879091128706932, Final Batch Loss: 0.07034972310066223\n",
      "Epoch 1867, Loss: 0.08854040689766407, Final Batch Loss: 0.023373575881123543\n",
      "Epoch 1868, Loss: 0.07326015271246433, Final Batch Loss: 0.02899952046573162\n",
      "Epoch 1869, Loss: 0.12131689488887787, Final Batch Loss: 0.08019349724054337\n",
      "Epoch 1870, Loss: 0.10062986239790916, Final Batch Loss: 0.04387568309903145\n",
      "Epoch 1871, Loss: 0.06997002474963665, Final Batch Loss: 0.03121221624314785\n",
      "Epoch 1872, Loss: 0.08036034926772118, Final Batch Loss: 0.032703131437301636\n",
      "Epoch 1873, Loss: 0.05101667903363705, Final Batch Loss: 0.01716647483408451\n",
      "Epoch 1874, Loss: 0.08239155635237694, Final Batch Loss: 0.028780609369277954\n",
      "Epoch 1875, Loss: 0.16279734298586845, Final Batch Loss: 0.1010967269539833\n",
      "Epoch 1876, Loss: 0.14239582791924477, Final Batch Loss: 0.0841648057103157\n",
      "Epoch 1877, Loss: 0.06302033644169569, Final Batch Loss: 0.012586484663188457\n",
      "Epoch 1878, Loss: 0.0893356204032898, Final Batch Loss: 0.03779730945825577\n",
      "Epoch 1879, Loss: 0.07439988479018211, Final Batch Loss: 0.023293253034353256\n",
      "Epoch 1880, Loss: 0.15362852811813354, Final Batch Loss: 0.07684072107076645\n",
      "Epoch 1881, Loss: 0.10756716132164001, Final Batch Loss: 0.07329998165369034\n",
      "Epoch 1882, Loss: 0.09162210300564766, Final Batch Loss: 0.0639466643333435\n",
      "Epoch 1883, Loss: 0.08796989172697067, Final Batch Loss: 0.04457481577992439\n",
      "Epoch 1884, Loss: 0.05865912511944771, Final Batch Loss: 0.03715433180332184\n",
      "Epoch 1885, Loss: 0.09298335015773773, Final Batch Loss: 0.03627791255712509\n",
      "Epoch 1886, Loss: 0.08566492423415184, Final Batch Loss: 0.04387088119983673\n",
      "Epoch 1887, Loss: 0.08683254197239876, Final Batch Loss: 0.025615546852350235\n",
      "Epoch 1888, Loss: 0.11168007180094719, Final Batch Loss: 0.04055121913552284\n",
      "Epoch 1889, Loss: 0.13247867301106453, Final Batch Loss: 0.05896395817399025\n",
      "Epoch 1890, Loss: 0.10580061748623848, Final Batch Loss: 0.03719149902462959\n",
      "Epoch 1891, Loss: 0.07754696160554886, Final Batch Loss: 0.03481348603963852\n",
      "Epoch 1892, Loss: 0.09251488000154495, Final Batch Loss: 0.04976949095726013\n",
      "Epoch 1893, Loss: 0.10372204147279263, Final Batch Loss: 0.030563844367861748\n",
      "Epoch 1894, Loss: 0.09611717611551285, Final Batch Loss: 0.0642327070236206\n",
      "Epoch 1895, Loss: 0.1849922500550747, Final Batch Loss: 0.12483026832342148\n",
      "Epoch 1896, Loss: 0.10714520886540413, Final Batch Loss: 0.048089392483234406\n",
      "Epoch 1897, Loss: 0.08262357860803604, Final Batch Loss: 0.050570324063301086\n",
      "Epoch 1898, Loss: 0.09071406349539757, Final Batch Loss: 0.05296255648136139\n",
      "Epoch 1899, Loss: 0.10142464563250542, Final Batch Loss: 0.06426741182804108\n",
      "Epoch 1900, Loss: 0.08791124820709229, Final Batch Loss: 0.03962588682770729\n",
      "Epoch 1901, Loss: 0.08385806158185005, Final Batch Loss: 0.017691317945718765\n",
      "Epoch 1902, Loss: 0.11052301153540611, Final Batch Loss: 0.07259703427553177\n",
      "Epoch 1903, Loss: 0.07897161319851875, Final Batch Loss: 0.03408237546682358\n",
      "Epoch 1904, Loss: 0.06916679069399834, Final Batch Loss: 0.02392534539103508\n",
      "Epoch 1905, Loss: 0.08047123998403549, Final Batch Loss: 0.02526278793811798\n",
      "Epoch 1906, Loss: 0.12904325872659683, Final Batch Loss: 0.06636355817317963\n",
      "Epoch 1907, Loss: 0.09026747941970825, Final Batch Loss: 0.0416342057287693\n",
      "Epoch 1908, Loss: 0.10751739144325256, Final Batch Loss: 0.041955575346946716\n",
      "Epoch 1909, Loss: 0.07800690829753876, Final Batch Loss: 0.03445979952812195\n",
      "Epoch 1910, Loss: 0.05451136454939842, Final Batch Loss: 0.01735527440905571\n",
      "Epoch 1911, Loss: 0.13222027570009232, Final Batch Loss: 0.09790647029876709\n",
      "Epoch 1912, Loss: 0.061080656945705414, Final Batch Loss: 0.037745460867881775\n",
      "Epoch 1913, Loss: 0.08779989555478096, Final Batch Loss: 0.02484104409813881\n",
      "Epoch 1914, Loss: 0.07253726571798325, Final Batch Loss: 0.02844233438372612\n",
      "Epoch 1915, Loss: 0.07605922967195511, Final Batch Loss: 0.03961692377924919\n",
      "Epoch 1916, Loss: 0.07219305634498596, Final Batch Loss: 0.04778141900897026\n",
      "Epoch 1917, Loss: 0.06111066974699497, Final Batch Loss: 0.024799073114991188\n",
      "Epoch 1918, Loss: 0.08046716637909412, Final Batch Loss: 0.019515158608555794\n",
      "Epoch 1919, Loss: 0.06570789404213428, Final Batch Loss: 0.040145143866539\n",
      "Epoch 1920, Loss: 0.149948351085186, Final Batch Loss: 0.0993056371808052\n",
      "Epoch 1921, Loss: 0.10713355056941509, Final Batch Loss: 0.016739754006266594\n",
      "Epoch 1922, Loss: 0.13304580375552177, Final Batch Loss: 0.04217034950852394\n",
      "Epoch 1923, Loss: 0.08846579119563103, Final Batch Loss: 0.04362726956605911\n",
      "Epoch 1924, Loss: 0.12917353585362434, Final Batch Loss: 0.07915335893630981\n",
      "Epoch 1925, Loss: 0.1269523799419403, Final Batch Loss: 0.06435910612344742\n",
      "Epoch 1926, Loss: 0.11291498318314552, Final Batch Loss: 0.037583235651254654\n",
      "Epoch 1927, Loss: 0.12089039757847786, Final Batch Loss: 0.062327709048986435\n",
      "Epoch 1928, Loss: 0.09955825097858906, Final Batch Loss: 0.019907185807824135\n",
      "Epoch 1929, Loss: 0.12592874839901924, Final Batch Loss: 0.06367896497249603\n",
      "Epoch 1930, Loss: 0.11050526425242424, Final Batch Loss: 0.08014554530382156\n",
      "Epoch 1931, Loss: 0.1164499782025814, Final Batch Loss: 0.07281912863254547\n",
      "Epoch 1932, Loss: 0.07898958027362823, Final Batch Loss: 0.0328032411634922\n",
      "Epoch 1933, Loss: 0.113144151866436, Final Batch Loss: 0.06143099442124367\n",
      "Epoch 1934, Loss: 0.0709441788494587, Final Batch Loss: 0.028681382536888123\n",
      "Epoch 1935, Loss: 0.07860387861728668, Final Batch Loss: 0.033138349652290344\n",
      "Epoch 1936, Loss: 0.07792210951447487, Final Batch Loss: 0.04323485121130943\n",
      "Epoch 1937, Loss: 0.07591700367629528, Final Batch Loss: 0.047941964119672775\n",
      "Epoch 1938, Loss: 0.07744242064654827, Final Batch Loss: 0.020676637068390846\n",
      "Epoch 1939, Loss: 0.12725622206926346, Final Batch Loss: 0.07351400703191757\n",
      "Epoch 1940, Loss: 0.08589188568294048, Final Batch Loss: 0.023593513295054436\n",
      "Epoch 1941, Loss: 0.0914344023913145, Final Batch Loss: 0.06763505935668945\n",
      "Epoch 1942, Loss: 0.16646964102983475, Final Batch Loss: 0.0693635568022728\n",
      "Epoch 1943, Loss: 0.06817706301808357, Final Batch Loss: 0.038970138877630234\n",
      "Epoch 1944, Loss: 0.061763448640704155, Final Batch Loss: 0.012397756800055504\n",
      "Epoch 1945, Loss: 0.15891322493553162, Final Batch Loss: 0.10854359716176987\n",
      "Epoch 1946, Loss: 0.11225497722625732, Final Batch Loss: 0.0525982528924942\n",
      "Epoch 1947, Loss: 0.06376480497419834, Final Batch Loss: 0.020623425021767616\n",
      "Epoch 1948, Loss: 0.10930826142430305, Final Batch Loss: 0.05591890588402748\n",
      "Epoch 1949, Loss: 0.1239108145236969, Final Batch Loss: 0.04676268994808197\n",
      "Epoch 1950, Loss: 0.09017905592918396, Final Batch Loss: 0.053685739636421204\n",
      "Epoch 1951, Loss: 0.0954764075577259, Final Batch Loss: 0.05472023785114288\n",
      "Epoch 1952, Loss: 0.09705374762415886, Final Batch Loss: 0.0359528623521328\n",
      "Epoch 1953, Loss: 0.1439027488231659, Final Batch Loss: 0.08037760853767395\n",
      "Epoch 1954, Loss: 0.08160213753581047, Final Batch Loss: 0.02029506489634514\n",
      "Epoch 1955, Loss: 0.09626756608486176, Final Batch Loss: 0.06182979419827461\n",
      "Epoch 1956, Loss: 0.09482544660568237, Final Batch Loss: 0.0503576286137104\n",
      "Epoch 1957, Loss: 0.0856909304857254, Final Batch Loss: 0.04663626104593277\n",
      "Epoch 1958, Loss: 0.08584096282720566, Final Batch Loss: 0.04783182591199875\n",
      "Epoch 1959, Loss: 0.0667610727250576, Final Batch Loss: 0.03713587298989296\n",
      "Epoch 1960, Loss: 0.12509343028068542, Final Batch Loss: 0.09100055694580078\n",
      "Epoch 1961, Loss: 0.09865930303931236, Final Batch Loss: 0.05865863338112831\n",
      "Epoch 1962, Loss: 0.11925463378429413, Final Batch Loss: 0.07089271396398544\n",
      "Epoch 1963, Loss: 0.11637862771749496, Final Batch Loss: 0.05451391264796257\n",
      "Epoch 1964, Loss: 0.07733742147684097, Final Batch Loss: 0.04486590623855591\n",
      "Epoch 1965, Loss: 0.11288740113377571, Final Batch Loss: 0.07217458635568619\n",
      "Epoch 1966, Loss: 0.11146993190050125, Final Batch Loss: 0.04096737504005432\n",
      "Epoch 1967, Loss: 0.08717185258865356, Final Batch Loss: 0.034425895661115646\n",
      "Epoch 1968, Loss: 0.06639487482607365, Final Batch Loss: 0.025142254307866096\n",
      "Epoch 1969, Loss: 0.0830472931265831, Final Batch Loss: 0.04611721634864807\n",
      "Epoch 1970, Loss: 0.10783754289150238, Final Batch Loss: 0.06892986595630646\n",
      "Epoch 1971, Loss: 0.08545500785112381, Final Batch Loss: 0.036221008747816086\n",
      "Epoch 1972, Loss: 0.09202027320861816, Final Batch Loss: 0.0442645326256752\n",
      "Epoch 1973, Loss: 0.07423869147896767, Final Batch Loss: 0.05187242478132248\n",
      "Epoch 1974, Loss: 0.12272602692246437, Final Batch Loss: 0.07300670444965363\n",
      "Epoch 1975, Loss: 0.11379380524158478, Final Batch Loss: 0.06454779952764511\n",
      "Epoch 1976, Loss: 0.11152667552232742, Final Batch Loss: 0.06077910587191582\n",
      "Epoch 1977, Loss: 0.1748305931687355, Final Batch Loss: 0.10988859832286835\n",
      "Epoch 1978, Loss: 0.09005139395594597, Final Batch Loss: 0.04241904988884926\n",
      "Epoch 1979, Loss: 0.07545947656035423, Final Batch Loss: 0.037431251257658005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1980, Loss: 0.1530681662261486, Final Batch Loss: 0.10272719711065292\n",
      "Epoch 1981, Loss: 0.12693249806761742, Final Batch Loss: 0.0553831122815609\n",
      "Epoch 1982, Loss: 0.12938403338193893, Final Batch Loss: 0.0910937562584877\n",
      "Epoch 1983, Loss: 0.06760294735431671, Final Batch Loss: 0.03444613516330719\n",
      "Epoch 1984, Loss: 0.10888800770044327, Final Batch Loss: 0.05971040576696396\n",
      "Epoch 1985, Loss: 0.1395050622522831, Final Batch Loss: 0.07740101218223572\n",
      "Epoch 1986, Loss: 0.11586802452802658, Final Batch Loss: 0.06915946304798126\n",
      "Epoch 1987, Loss: 0.09585567936301231, Final Batch Loss: 0.03542109578847885\n",
      "Epoch 1988, Loss: 0.09509427286684513, Final Batch Loss: 0.027150267735123634\n",
      "Epoch 1989, Loss: 0.05151382461190224, Final Batch Loss: 0.020298294723033905\n",
      "Epoch 1990, Loss: 0.14629943668842316, Final Batch Loss: 0.07611516118049622\n",
      "Epoch 1991, Loss: 0.09299691021442413, Final Batch Loss: 0.05261046066880226\n",
      "Epoch 1992, Loss: 0.07056339830160141, Final Batch Loss: 0.02571392059326172\n",
      "Epoch 1993, Loss: 0.061304258182644844, Final Batch Loss: 0.028519539162516594\n",
      "Epoch 1994, Loss: 0.10368888452649117, Final Batch Loss: 0.046181805431842804\n",
      "Epoch 1995, Loss: 0.07534996047616005, Final Batch Loss: 0.03004799783229828\n",
      "Epoch 1996, Loss: 0.09998306259512901, Final Batch Loss: 0.054029446095228195\n",
      "Epoch 1997, Loss: 0.09564127027988434, Final Batch Loss: 0.05303343012928963\n",
      "Epoch 1998, Loss: 0.1444055251777172, Final Batch Loss: 0.08768347650766373\n",
      "Epoch 1999, Loss: 0.0860222727060318, Final Batch Loss: 0.017052792012691498\n",
      "Epoch 2000, Loss: 0.12062719091773033, Final Batch Loss: 0.04032622650265694\n",
      "Epoch 2001, Loss: 0.15490970015525818, Final Batch Loss: 0.09312590956687927\n",
      "Epoch 2002, Loss: 0.12377909943461418, Final Batch Loss: 0.06504940986633301\n",
      "Epoch 2003, Loss: 0.10003386437892914, Final Batch Loss: 0.06367626041173935\n",
      "Epoch 2004, Loss: 0.0733735840767622, Final Batch Loss: 0.018540771678090096\n",
      "Epoch 2005, Loss: 0.08704912476241589, Final Batch Loss: 0.031074179336428642\n",
      "Epoch 2006, Loss: 0.09581159427762032, Final Batch Loss: 0.03559538349509239\n",
      "Epoch 2007, Loss: 0.106320321559906, Final Batch Loss: 0.06424137204885483\n",
      "Epoch 2008, Loss: 0.1136220134794712, Final Batch Loss: 0.05748102068901062\n",
      "Epoch 2009, Loss: 0.09120679274201393, Final Batch Loss: 0.06263142824172974\n",
      "Epoch 2010, Loss: 0.07940246537327766, Final Batch Loss: 0.03426066040992737\n",
      "Epoch 2011, Loss: 0.12063165381550789, Final Batch Loss: 0.044192876666784286\n",
      "Epoch 2012, Loss: 0.09667764231562614, Final Batch Loss: 0.05231532081961632\n",
      "Epoch 2013, Loss: 0.12049622647464275, Final Batch Loss: 0.09070621430873871\n",
      "Epoch 2014, Loss: 0.06993549689650536, Final Batch Loss: 0.03857513517141342\n",
      "Epoch 2015, Loss: 0.09703538194298744, Final Batch Loss: 0.04659220203757286\n",
      "Epoch 2016, Loss: 0.06475883536040783, Final Batch Loss: 0.03081888146698475\n",
      "Epoch 2017, Loss: 0.08576108142733574, Final Batch Loss: 0.05410786345601082\n",
      "Epoch 2018, Loss: 0.09369374066591263, Final Batch Loss: 0.04815582185983658\n",
      "Epoch 2019, Loss: 0.12490283325314522, Final Batch Loss: 0.07164235413074493\n",
      "Epoch 2020, Loss: 0.0684911459684372, Final Batch Loss: 0.02608780562877655\n",
      "Epoch 2021, Loss: 0.08255871944129467, Final Batch Loss: 0.022388005629181862\n",
      "Epoch 2022, Loss: 0.10143854469060898, Final Batch Loss: 0.06381049007177353\n",
      "Epoch 2023, Loss: 0.06349719129502773, Final Batch Loss: 0.020995570346713066\n",
      "Epoch 2024, Loss: 0.07373452745378017, Final Batch Loss: 0.024828201159834862\n",
      "Epoch 2025, Loss: 0.08144214376807213, Final Batch Loss: 0.05039263889193535\n",
      "Epoch 2026, Loss: 0.11483963578939438, Final Batch Loss: 0.04717499762773514\n",
      "Epoch 2027, Loss: 0.09393800050020218, Final Batch Loss: 0.048926763236522675\n",
      "Epoch 2028, Loss: 0.1368383765220642, Final Batch Loss: 0.06541508436203003\n",
      "Epoch 2029, Loss: 0.13027947396039963, Final Batch Loss: 0.06922321766614914\n",
      "Epoch 2030, Loss: 0.07079658098518848, Final Batch Loss: 0.015773804858326912\n",
      "Epoch 2031, Loss: 0.1046362817287445, Final Batch Loss: 0.03361702710390091\n",
      "Epoch 2032, Loss: 0.08814177103340626, Final Batch Loss: 0.024677405133843422\n",
      "Epoch 2033, Loss: 0.1117674969136715, Final Batch Loss: 0.06501637399196625\n",
      "Epoch 2034, Loss: 0.09148430824279785, Final Batch Loss: 0.045701541006565094\n",
      "Epoch 2035, Loss: 0.07439826987683773, Final Batch Loss: 0.022578375414013863\n",
      "Epoch 2036, Loss: 0.06977234221994877, Final Batch Loss: 0.029714899137616158\n",
      "Epoch 2037, Loss: 0.11861402913928032, Final Batch Loss: 0.0577019602060318\n",
      "Epoch 2038, Loss: 0.08889883756637573, Final Batch Loss: 0.045262373983860016\n",
      "Epoch 2039, Loss: 0.09515612572431564, Final Batch Loss: 0.05619683489203453\n",
      "Epoch 2040, Loss: 0.09247987903654575, Final Batch Loss: 0.07127975672483444\n",
      "Epoch 2041, Loss: 0.10626937076449394, Final Batch Loss: 0.03605405613780022\n",
      "Epoch 2042, Loss: 0.0867355726659298, Final Batch Loss: 0.03781568631529808\n",
      "Epoch 2043, Loss: 0.06731497868895531, Final Batch Loss: 0.03270965442061424\n",
      "Epoch 2044, Loss: 0.09064027667045593, Final Batch Loss: 0.03497754782438278\n",
      "Epoch 2045, Loss: 0.08467479050159454, Final Batch Loss: 0.04405982792377472\n",
      "Epoch 2046, Loss: 0.13433946669101715, Final Batch Loss: 0.08573392778635025\n",
      "Epoch 2047, Loss: 0.08557812497019768, Final Batch Loss: 0.03855385258793831\n",
      "Epoch 2048, Loss: 0.09114415943622589, Final Batch Loss: 0.048389989882707596\n",
      "Epoch 2049, Loss: 0.1738508641719818, Final Batch Loss: 0.13815633952617645\n",
      "Epoch 2050, Loss: 0.10422486439347267, Final Batch Loss: 0.07108118385076523\n",
      "Epoch 2051, Loss: 0.07634729705750942, Final Batch Loss: 0.04711061716079712\n",
      "Epoch 2052, Loss: 0.08994805812835693, Final Batch Loss: 0.04202432557940483\n",
      "Epoch 2053, Loss: 0.07207674905657768, Final Batch Loss: 0.028507061302661896\n",
      "Epoch 2054, Loss: 0.08867248147726059, Final Batch Loss: 0.0535755380988121\n",
      "Epoch 2055, Loss: 0.08717813342809677, Final Batch Loss: 0.041042085736989975\n",
      "Epoch 2056, Loss: 0.08919888362288475, Final Batch Loss: 0.030941762030124664\n",
      "Epoch 2057, Loss: 0.047293731942772865, Final Batch Loss: 0.025787808001041412\n",
      "Epoch 2058, Loss: 0.1156781055033207, Final Batch Loss: 0.04163352772593498\n",
      "Epoch 2059, Loss: 0.1053360216319561, Final Batch Loss: 0.06658205389976501\n",
      "Epoch 2060, Loss: 0.1127934381365776, Final Batch Loss: 0.03245621174573898\n",
      "Epoch 2061, Loss: 0.03962255176156759, Final Batch Loss: 0.015268906019628048\n",
      "Epoch 2062, Loss: 0.06077349931001663, Final Batch Loss: 0.01746465638279915\n",
      "Epoch 2063, Loss: 0.06251039355993271, Final Batch Loss: 0.028068460524082184\n",
      "Epoch 2064, Loss: 0.08166998438537121, Final Batch Loss: 0.029205812141299248\n",
      "Epoch 2065, Loss: 0.1243121549487114, Final Batch Loss: 0.051079973578453064\n",
      "Epoch 2066, Loss: 0.06656335107982159, Final Batch Loss: 0.04330533742904663\n",
      "Epoch 2067, Loss: 0.08378493040800095, Final Batch Loss: 0.03961580991744995\n",
      "Epoch 2068, Loss: 0.029907447285950184, Final Batch Loss: 0.014824808575212955\n",
      "Epoch 2069, Loss: 0.07339347898960114, Final Batch Loss: 0.031364090740680695\n",
      "Epoch 2070, Loss: 0.05031351838260889, Final Batch Loss: 0.009957478381693363\n",
      "Epoch 2071, Loss: 0.08609143830835819, Final Batch Loss: 0.05815916135907173\n",
      "Epoch 2072, Loss: 0.0555378682911396, Final Batch Loss: 0.03536132723093033\n",
      "Epoch 2073, Loss: 0.07799326628446579, Final Batch Loss: 0.04667825624346733\n",
      "Epoch 2074, Loss: 0.067893385887146, Final Batch Loss: 0.02968754991889\n",
      "Epoch 2075, Loss: 0.06142419949173927, Final Batch Loss: 0.025768745690584183\n",
      "Epoch 2076, Loss: 0.08277074620127678, Final Batch Loss: 0.00909910723567009\n",
      "Epoch 2077, Loss: 0.08864156901836395, Final Batch Loss: 0.03475262224674225\n",
      "Epoch 2078, Loss: 0.09695375338196754, Final Batch Loss: 0.03726888447999954\n",
      "Epoch 2079, Loss: 0.052841916680336, Final Batch Loss: 0.03738219663500786\n",
      "Epoch 2080, Loss: 0.09979300200939178, Final Batch Loss: 0.06858224421739578\n",
      "Epoch 2081, Loss: 0.09851600788533688, Final Batch Loss: 0.06910927593708038\n",
      "Epoch 2082, Loss: 0.11278567090630531, Final Batch Loss: 0.05155503749847412\n",
      "Epoch 2083, Loss: 0.15291881561279297, Final Batch Loss: 0.08422959595918655\n",
      "Epoch 2084, Loss: 0.10275790095329285, Final Batch Loss: 0.03696364164352417\n",
      "Epoch 2085, Loss: 0.09085961431264877, Final Batch Loss: 0.0548979714512825\n",
      "Epoch 2086, Loss: 0.11546247825026512, Final Batch Loss: 0.06136202812194824\n",
      "Epoch 2087, Loss: 0.07450378499925137, Final Batch Loss: 0.05116704851388931\n",
      "Epoch 2088, Loss: 0.09406592324376106, Final Batch Loss: 0.03694431483745575\n",
      "Epoch 2089, Loss: 0.09933450818061829, Final Batch Loss: 0.08325359970331192\n",
      "Epoch 2090, Loss: 0.08303521014750004, Final Batch Loss: 0.026906708255410194\n",
      "Epoch 2091, Loss: 0.10626138933002949, Final Batch Loss: 0.029427269473671913\n",
      "Epoch 2092, Loss: 0.17718059569597244, Final Batch Loss: 0.12528350949287415\n",
      "Epoch 2093, Loss: 0.12507348880171776, Final Batch Loss: 0.062017250806093216\n",
      "Epoch 2094, Loss: 0.07869606465101242, Final Batch Loss: 0.04469102621078491\n",
      "Epoch 2095, Loss: 0.056093327701091766, Final Batch Loss: 0.022778604179620743\n",
      "Epoch 2096, Loss: 0.15745243430137634, Final Batch Loss: 0.07537590712308884\n",
      "Epoch 2097, Loss: 0.10551265440881252, Final Batch Loss: 0.025828903540968895\n",
      "Epoch 2098, Loss: 0.10067993402481079, Final Batch Loss: 0.05822164937853813\n",
      "Epoch 2099, Loss: 0.06814385764300823, Final Batch Loss: 0.04349260404706001\n",
      "Epoch 2100, Loss: 0.07387642376124859, Final Batch Loss: 0.05222587659955025\n",
      "Epoch 2101, Loss: 0.08428940176963806, Final Batch Loss: 0.0524863637983799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2102, Loss: 0.048797089606523514, Final Batch Loss: 0.018995434045791626\n",
      "Epoch 2103, Loss: 0.058219827711582184, Final Batch Loss: 0.026811987161636353\n",
      "Epoch 2104, Loss: 0.06966369785368443, Final Batch Loss: 0.022955598309636116\n",
      "Epoch 2105, Loss: 0.0988076813519001, Final Batch Loss: 0.02363763377070427\n",
      "Epoch 2106, Loss: 0.05483050085604191, Final Batch Loss: 0.023820478469133377\n",
      "Epoch 2107, Loss: 0.0850270539522171, Final Batch Loss: 0.042830392718315125\n",
      "Epoch 2108, Loss: 0.06190857104957104, Final Batch Loss: 0.015448296442627907\n",
      "Epoch 2109, Loss: 0.13195692747831345, Final Batch Loss: 0.05045366287231445\n",
      "Epoch 2110, Loss: 0.09077789261937141, Final Batch Loss: 0.050470802932977676\n",
      "Epoch 2111, Loss: 0.07138310372829437, Final Batch Loss: 0.021627038717269897\n",
      "Epoch 2112, Loss: 0.08602075837552547, Final Batch Loss: 0.02755291946232319\n",
      "Epoch 2113, Loss: 0.10485237836837769, Final Batch Loss: 0.05101519450545311\n",
      "Epoch 2114, Loss: 0.08005346357822418, Final Batch Loss: 0.023859411478042603\n",
      "Epoch 2115, Loss: 0.09020091220736504, Final Batch Loss: 0.0475274920463562\n",
      "Epoch 2116, Loss: 0.05432108789682388, Final Batch Loss: 0.033639468252658844\n",
      "Epoch 2117, Loss: 0.10854865238070488, Final Batch Loss: 0.058252185583114624\n",
      "Epoch 2118, Loss: 0.1673387736082077, Final Batch Loss: 0.07202979922294617\n",
      "Epoch 2119, Loss: 0.06717054732143879, Final Batch Loss: 0.042816225439310074\n",
      "Epoch 2120, Loss: 0.08805130049586296, Final Batch Loss: 0.028996523469686508\n",
      "Epoch 2121, Loss: 0.09008805826306343, Final Batch Loss: 0.056893907487392426\n",
      "Epoch 2122, Loss: 0.08984028920531273, Final Batch Loss: 0.03796430677175522\n",
      "Epoch 2123, Loss: 0.06507292669266462, Final Batch Loss: 0.011074292473495007\n",
      "Epoch 2124, Loss: 0.09312927350401878, Final Batch Loss: 0.04748784750699997\n",
      "Epoch 2125, Loss: 0.07828090339899063, Final Batch Loss: 0.027169331908226013\n",
      "Epoch 2126, Loss: 0.16965826600790024, Final Batch Loss: 0.08439788967370987\n",
      "Epoch 2127, Loss: 0.08794576115906239, Final Batch Loss: 0.023853043094277382\n",
      "Epoch 2128, Loss: 0.10688234120607376, Final Batch Loss: 0.051043543964624405\n",
      "Epoch 2129, Loss: 0.08856789395213127, Final Batch Loss: 0.031495269387960434\n",
      "Epoch 2130, Loss: 0.07030721195042133, Final Batch Loss: 0.02042037434875965\n",
      "Epoch 2131, Loss: 0.05611865594983101, Final Batch Loss: 0.01644463837146759\n",
      "Epoch 2132, Loss: 0.09924999065697193, Final Batch Loss: 0.02658204920589924\n",
      "Epoch 2133, Loss: 0.0950973778963089, Final Batch Loss: 0.026955507695674896\n",
      "Epoch 2134, Loss: 0.09577411971986294, Final Batch Loss: 0.017237721011042595\n",
      "Epoch 2135, Loss: 0.12995604798197746, Final Batch Loss: 0.036193568259477615\n",
      "Epoch 2136, Loss: 0.14653685688972473, Final Batch Loss: 0.08971697837114334\n",
      "Epoch 2137, Loss: 0.0574028305709362, Final Batch Loss: 0.03515885770320892\n",
      "Epoch 2138, Loss: 0.109681136906147, Final Batch Loss: 0.031905412673950195\n",
      "Epoch 2139, Loss: 0.07907210662961006, Final Batch Loss: 0.04156043753027916\n",
      "Epoch 2140, Loss: 0.06676325760781765, Final Batch Loss: 0.029392635449767113\n",
      "Epoch 2141, Loss: 0.056453337892889977, Final Batch Loss: 0.025321388617157936\n",
      "Epoch 2142, Loss: 0.16112306155264378, Final Batch Loss: 0.13529124855995178\n",
      "Epoch 2143, Loss: 0.0816975049674511, Final Batch Loss: 0.05879971757531166\n",
      "Epoch 2144, Loss: 0.11071215197443962, Final Batch Loss: 0.034688036888837814\n",
      "Epoch 2145, Loss: 0.09009949490427971, Final Batch Loss: 0.03908621892333031\n",
      "Epoch 2146, Loss: 0.05856390856206417, Final Batch Loss: 0.02114405669271946\n",
      "Epoch 2147, Loss: 0.04846948757767677, Final Batch Loss: 0.018120521679520607\n",
      "Epoch 2148, Loss: 0.07603886164724827, Final Batch Loss: 0.029368305578827858\n",
      "Epoch 2149, Loss: 0.0853709802031517, Final Batch Loss: 0.02782806009054184\n",
      "Epoch 2150, Loss: 0.07965827360749245, Final Batch Loss: 0.036759234964847565\n",
      "Epoch 2151, Loss: 0.09991675242781639, Final Batch Loss: 0.013887207955121994\n",
      "Epoch 2152, Loss: 0.14703848958015442, Final Batch Loss: 0.05820665508508682\n",
      "Epoch 2153, Loss: 0.08661795780062675, Final Batch Loss: 0.02709691971540451\n",
      "Epoch 2154, Loss: 0.08432851731777191, Final Batch Loss: 0.029308989644050598\n",
      "Epoch 2155, Loss: 0.08440813049674034, Final Batch Loss: 0.051433056592941284\n",
      "Epoch 2156, Loss: 0.060560147278010845, Final Batch Loss: 0.048238594084978104\n",
      "Epoch 2157, Loss: 0.06990749016404152, Final Batch Loss: 0.047013260424137115\n",
      "Epoch 2158, Loss: 0.09866306558251381, Final Batch Loss: 0.04526619240641594\n",
      "Epoch 2159, Loss: 0.08367397263646126, Final Batch Loss: 0.03380465507507324\n",
      "Epoch 2160, Loss: 0.13363579101860523, Final Batch Loss: 0.024180883541703224\n",
      "Epoch 2161, Loss: 0.1309063956141472, Final Batch Loss: 0.08250290155410767\n",
      "Epoch 2162, Loss: 0.07223841175436974, Final Batch Loss: 0.024799156934022903\n",
      "Epoch 2163, Loss: 0.09422348812222481, Final Batch Loss: 0.04930364340543747\n",
      "Epoch 2164, Loss: 0.08476238697767258, Final Batch Loss: 0.04200306162238121\n",
      "Epoch 2165, Loss: 0.09478281438350677, Final Batch Loss: 0.06033739820122719\n",
      "Epoch 2166, Loss: 0.10605022311210632, Final Batch Loss: 0.043533600866794586\n",
      "Epoch 2167, Loss: 0.11733687669038773, Final Batch Loss: 0.0735255554318428\n",
      "Epoch 2168, Loss: 0.14783447980880737, Final Batch Loss: 0.08052219450473785\n",
      "Epoch 2169, Loss: 0.06782805360853672, Final Batch Loss: 0.025509504601359367\n",
      "Epoch 2170, Loss: 0.09652986004948616, Final Batch Loss: 0.037857796996831894\n",
      "Epoch 2171, Loss: 0.07718984130769968, Final Batch Loss: 0.008623414672911167\n",
      "Epoch 2172, Loss: 0.0672761332243681, Final Batch Loss: 0.038390498608350754\n",
      "Epoch 2173, Loss: 0.08550994843244553, Final Batch Loss: 0.0381171852350235\n",
      "Epoch 2174, Loss: 0.086750578135252, Final Batch Loss: 0.05359623581171036\n",
      "Epoch 2175, Loss: 0.08299606293439865, Final Batch Loss: 0.04205526411533356\n",
      "Epoch 2176, Loss: 0.11846181750297546, Final Batch Loss: 0.04646401107311249\n",
      "Epoch 2177, Loss: 0.10343462973833084, Final Batch Loss: 0.05888861045241356\n",
      "Epoch 2178, Loss: 0.0824804175645113, Final Batch Loss: 0.014644557610154152\n",
      "Epoch 2179, Loss: 0.07589237950742245, Final Batch Loss: 0.028050212189555168\n",
      "Epoch 2180, Loss: 0.10922009125351906, Final Batch Loss: 0.047084204852581024\n",
      "Epoch 2181, Loss: 0.11571337282657623, Final Batch Loss: 0.05970411375164986\n",
      "Epoch 2182, Loss: 0.08560840599238873, Final Batch Loss: 0.057367824018001556\n",
      "Epoch 2183, Loss: 0.12380454689264297, Final Batch Loss: 0.08486361056566238\n",
      "Epoch 2184, Loss: 0.07744746468961239, Final Batch Loss: 0.02541150338947773\n",
      "Epoch 2185, Loss: 0.08312063664197922, Final Batch Loss: 0.05136288329958916\n",
      "Epoch 2186, Loss: 0.07204550132155418, Final Batch Loss: 0.048891887068748474\n",
      "Epoch 2187, Loss: 0.12547967955470085, Final Batch Loss: 0.0674334466457367\n",
      "Epoch 2188, Loss: 0.08313558995723724, Final Batch Loss: 0.04431686922907829\n",
      "Epoch 2189, Loss: 0.10234609991312027, Final Batch Loss: 0.037212073802948\n",
      "Epoch 2190, Loss: 0.09068238362669945, Final Batch Loss: 0.03196336701512337\n",
      "Epoch 2191, Loss: 0.07449338957667351, Final Batch Loss: 0.03680674731731415\n",
      "Epoch 2192, Loss: 0.12056571058928967, Final Batch Loss: 0.02769564650952816\n",
      "Epoch 2193, Loss: 0.09506839141249657, Final Batch Loss: 0.048678722232580185\n",
      "Epoch 2194, Loss: 0.15198377147316933, Final Batch Loss: 0.09850651025772095\n",
      "Epoch 2195, Loss: 0.12671885266900063, Final Batch Loss: 0.06105218455195427\n",
      "Epoch 2196, Loss: 0.08834889903664589, Final Batch Loss: 0.03759287670254707\n",
      "Epoch 2197, Loss: 0.06537345796823502, Final Batch Loss: 0.022303685545921326\n",
      "Epoch 2198, Loss: 0.059266552329063416, Final Batch Loss: 0.023305274546146393\n",
      "Epoch 2199, Loss: 0.09842874854803085, Final Batch Loss: 0.04694962501525879\n",
      "Epoch 2200, Loss: 0.12550010159611702, Final Batch Loss: 0.058968160301446915\n",
      "Epoch 2201, Loss: 0.07781565003097057, Final Batch Loss: 0.028356513008475304\n",
      "Epoch 2202, Loss: 0.09778425469994545, Final Batch Loss: 0.029653828591108322\n",
      "Epoch 2203, Loss: 0.09732723981142044, Final Batch Loss: 0.04208845645189285\n",
      "Epoch 2204, Loss: 0.10158981755375862, Final Batch Loss: 0.031339410692453384\n",
      "Epoch 2205, Loss: 0.08767673745751381, Final Batch Loss: 0.04197201877832413\n",
      "Epoch 2206, Loss: 0.08146410062909126, Final Batch Loss: 0.027093376964330673\n",
      "Epoch 2207, Loss: 0.11493409425020218, Final Batch Loss: 0.06923260539770126\n",
      "Epoch 2208, Loss: 0.08666448667645454, Final Batch Loss: 0.051478464156389236\n",
      "Epoch 2209, Loss: 0.13803694024682045, Final Batch Loss: 0.09636183828115463\n",
      "Epoch 2210, Loss: 0.06967784184962511, Final Batch Loss: 0.011055820621550083\n",
      "Epoch 2211, Loss: 0.09896524623036385, Final Batch Loss: 0.058688934892416\n",
      "Epoch 2212, Loss: 0.08269874006509781, Final Batch Loss: 0.03697608783841133\n",
      "Epoch 2213, Loss: 0.08008177578449249, Final Batch Loss: 0.028464343398809433\n",
      "Epoch 2214, Loss: 0.06406884454190731, Final Batch Loss: 0.03576425090432167\n",
      "Epoch 2215, Loss: 0.11093450710177422, Final Batch Loss: 0.07671152800321579\n",
      "Epoch 2216, Loss: 0.1844550147652626, Final Batch Loss: 0.11946745961904526\n",
      "Epoch 2217, Loss: 0.12576265260577202, Final Batch Loss: 0.08726086467504501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2218, Loss: 0.14852549880743027, Final Batch Loss: 0.10121094435453415\n",
      "Epoch 2219, Loss: 0.09791143611073494, Final Batch Loss: 0.05472678318619728\n",
      "Epoch 2220, Loss: 0.07552258484065533, Final Batch Loss: 0.027661463245749474\n",
      "Epoch 2221, Loss: 0.14320091903209686, Final Batch Loss: 0.05332431197166443\n",
      "Epoch 2222, Loss: 0.10246973857283592, Final Batch Loss: 0.05686667189002037\n",
      "Epoch 2223, Loss: 0.07664346694946289, Final Batch Loss: 0.027773384004831314\n",
      "Epoch 2224, Loss: 0.12453484162688255, Final Batch Loss: 0.09105855226516724\n",
      "Epoch 2225, Loss: 0.0937940776348114, Final Batch Loss: 0.03182965889573097\n",
      "Epoch 2226, Loss: 0.09733381494879723, Final Batch Loss: 0.05288351699709892\n",
      "Epoch 2227, Loss: 0.07874935492873192, Final Batch Loss: 0.04839632287621498\n",
      "Epoch 2228, Loss: 0.09762144647538662, Final Batch Loss: 0.02744962088763714\n",
      "Epoch 2229, Loss: 0.08014271780848503, Final Batch Loss: 0.03991318866610527\n",
      "Epoch 2230, Loss: 0.06496593169867992, Final Batch Loss: 0.026773372665047646\n",
      "Epoch 2231, Loss: 0.07452867180109024, Final Batch Loss: 0.030806787312030792\n",
      "Epoch 2232, Loss: 0.08437355980277061, Final Batch Loss: 0.03175322338938713\n",
      "Epoch 2233, Loss: 0.07957455143332481, Final Batch Loss: 0.03821606561541557\n",
      "Epoch 2234, Loss: 0.08184068091213703, Final Batch Loss: 0.05140379071235657\n",
      "Epoch 2235, Loss: 0.05302409268915653, Final Batch Loss: 0.019835812970995903\n",
      "Epoch 2236, Loss: 0.08698589727282524, Final Batch Loss: 0.03609715774655342\n",
      "Epoch 2237, Loss: 0.04965361766517162, Final Batch Loss: 0.02057781256735325\n",
      "Epoch 2238, Loss: 0.09079278819262981, Final Batch Loss: 0.07264616340398788\n",
      "Epoch 2239, Loss: 0.08454069122672081, Final Batch Loss: 0.039037562906742096\n",
      "Epoch 2240, Loss: 0.10761895403265953, Final Batch Loss: 0.05231062322854996\n",
      "Epoch 2241, Loss: 0.06546786241233349, Final Batch Loss: 0.021131539717316628\n",
      "Epoch 2242, Loss: 0.04986041970551014, Final Batch Loss: 0.031518321484327316\n",
      "Epoch 2243, Loss: 0.06606319360435009, Final Batch Loss: 0.01905863545835018\n",
      "Epoch 2244, Loss: 0.08976147323846817, Final Batch Loss: 0.04671216011047363\n",
      "Epoch 2245, Loss: 0.07913912087678909, Final Batch Loss: 0.04163298010826111\n",
      "Epoch 2246, Loss: 0.07655380293726921, Final Batch Loss: 0.032793089747428894\n",
      "Epoch 2247, Loss: 0.05575728975236416, Final Batch Loss: 0.01564832217991352\n",
      "Epoch 2248, Loss: 0.056838477961719036, Final Batch Loss: 0.012174795381724834\n",
      "Epoch 2249, Loss: 0.09546015411615372, Final Batch Loss: 0.060436662286520004\n",
      "Epoch 2250, Loss: 0.03974311426281929, Final Batch Loss: 0.018630117177963257\n",
      "Epoch 2251, Loss: 0.0575900562107563, Final Batch Loss: 0.02850678749382496\n",
      "Epoch 2252, Loss: 0.07912981510162354, Final Batch Loss: 0.030298352241516113\n",
      "Epoch 2253, Loss: 0.0659118015319109, Final Batch Loss: 0.017161959782242775\n",
      "Epoch 2254, Loss: 0.10872822627425194, Final Batch Loss: 0.049969881772994995\n",
      "Epoch 2255, Loss: 0.10868371278047562, Final Batch Loss: 0.0565161406993866\n",
      "Epoch 2256, Loss: 0.06476349383592606, Final Batch Loss: 0.021642297506332397\n",
      "Epoch 2257, Loss: 0.09824059158563614, Final Batch Loss: 0.015197552740573883\n",
      "Epoch 2258, Loss: 0.111698467284441, Final Batch Loss: 0.07721707969903946\n",
      "Epoch 2259, Loss: 0.07148696109652519, Final Batch Loss: 0.018627144396305084\n",
      "Epoch 2260, Loss: 0.0755617804825306, Final Batch Loss: 0.028904084116220474\n",
      "Epoch 2261, Loss: 0.10378094017505646, Final Batch Loss: 0.03381919860839844\n",
      "Epoch 2262, Loss: 0.08597688004374504, Final Batch Loss: 0.03290857374668121\n",
      "Epoch 2263, Loss: 0.10384602844715118, Final Batch Loss: 0.05665893480181694\n",
      "Epoch 2264, Loss: 0.07102740835398436, Final Batch Loss: 0.01210062112659216\n",
      "Epoch 2265, Loss: 0.05677133426070213, Final Batch Loss: 0.0210823155939579\n",
      "Epoch 2266, Loss: 0.0950336866080761, Final Batch Loss: 0.04087378829717636\n",
      "Epoch 2267, Loss: 0.1317611150443554, Final Batch Loss: 0.08653926104307175\n",
      "Epoch 2268, Loss: 0.049764773808419704, Final Batch Loss: 0.011390897445380688\n",
      "Epoch 2269, Loss: 0.08945399895310402, Final Batch Loss: 0.04800400882959366\n",
      "Epoch 2270, Loss: 0.09074265509843826, Final Batch Loss: 0.024285152554512024\n",
      "Epoch 2271, Loss: 0.09657535888254642, Final Batch Loss: 0.024098875001072884\n",
      "Epoch 2272, Loss: 0.11539378017187119, Final Batch Loss: 0.06013514846563339\n",
      "Epoch 2273, Loss: 0.10145502537488937, Final Batch Loss: 0.07971733808517456\n",
      "Epoch 2274, Loss: 0.1115117184817791, Final Batch Loss: 0.03373737260699272\n",
      "Epoch 2275, Loss: 0.1250588335096836, Final Batch Loss: 0.07639877498149872\n",
      "Epoch 2276, Loss: 0.09373794496059418, Final Batch Loss: 0.0596451461315155\n",
      "Epoch 2277, Loss: 0.08478746935725212, Final Batch Loss: 0.04688505083322525\n",
      "Epoch 2278, Loss: 0.07048103027045727, Final Batch Loss: 0.029452228918671608\n",
      "Epoch 2279, Loss: 0.09009361639618874, Final Batch Loss: 0.05443103238940239\n",
      "Epoch 2280, Loss: 0.08608106151223183, Final Batch Loss: 0.04461289569735527\n",
      "Epoch 2281, Loss: 0.08659710735082626, Final Batch Loss: 0.043025363236665726\n",
      "Epoch 2282, Loss: 0.10659884661436081, Final Batch Loss: 0.04566912353038788\n",
      "Epoch 2283, Loss: 0.13657522946596146, Final Batch Loss: 0.05392041802406311\n",
      "Epoch 2284, Loss: 0.1370425634086132, Final Batch Loss: 0.0916566327214241\n",
      "Epoch 2285, Loss: 0.09992215782403946, Final Batch Loss: 0.043011803179979324\n",
      "Epoch 2286, Loss: 0.07960998639464378, Final Batch Loss: 0.03361968323588371\n",
      "Epoch 2287, Loss: 0.055698929354548454, Final Batch Loss: 0.01789371855556965\n",
      "Epoch 2288, Loss: 0.08957833983004093, Final Batch Loss: 0.026676783338189125\n",
      "Epoch 2289, Loss: 0.07611600682139397, Final Batch Loss: 0.03444996476173401\n",
      "Epoch 2290, Loss: 0.07604829780757427, Final Batch Loss: 0.027476975694298744\n",
      "Epoch 2291, Loss: 0.10865654051303864, Final Batch Loss: 0.046450112015008926\n",
      "Epoch 2292, Loss: 0.05492740496993065, Final Batch Loss: 0.030914494767785072\n",
      "Epoch 2293, Loss: 0.0836879312992096, Final Batch Loss: 0.059410154819488525\n",
      "Epoch 2294, Loss: 0.0819561704993248, Final Batch Loss: 0.04514692351222038\n",
      "Epoch 2295, Loss: 0.051900219172239304, Final Batch Loss: 0.01897544041275978\n",
      "Epoch 2296, Loss: 0.08327318355441093, Final Batch Loss: 0.04638785123825073\n",
      "Epoch 2297, Loss: 0.07594778202474117, Final Batch Loss: 0.046070847660303116\n",
      "Epoch 2298, Loss: 0.08406517282128334, Final Batch Loss: 0.05757752060890198\n",
      "Epoch 2299, Loss: 0.10939326509833336, Final Batch Loss: 0.019495751708745956\n",
      "Epoch 2300, Loss: 0.09889551997184753, Final Batch Loss: 0.06414927542209625\n",
      "Epoch 2301, Loss: 0.09054841287434101, Final Batch Loss: 0.06460441648960114\n",
      "Epoch 2302, Loss: 0.11773061752319336, Final Batch Loss: 0.059950362890958786\n",
      "Epoch 2303, Loss: 0.060107396915555, Final Batch Loss: 0.025856545194983482\n",
      "Epoch 2304, Loss: 0.08869596943259239, Final Batch Loss: 0.04727553203701973\n",
      "Epoch 2305, Loss: 0.07667011767625809, Final Batch Loss: 0.05271217226982117\n",
      "Epoch 2306, Loss: 0.07066803984344006, Final Batch Loss: 0.045294519513845444\n",
      "Epoch 2307, Loss: 0.06896322779357433, Final Batch Loss: 0.017545675858855247\n",
      "Epoch 2308, Loss: 0.0786343663930893, Final Batch Loss: 0.0348578579723835\n",
      "Epoch 2309, Loss: 0.08447365462779999, Final Batch Loss: 0.012693114578723907\n",
      "Epoch 2310, Loss: 0.09369892254471779, Final Batch Loss: 0.04105541482567787\n",
      "Epoch 2311, Loss: 0.06414877995848656, Final Batch Loss: 0.03297262638807297\n",
      "Epoch 2312, Loss: 0.10097853094339371, Final Batch Loss: 0.05249819904565811\n",
      "Epoch 2313, Loss: 0.08377739042043686, Final Batch Loss: 0.04746389389038086\n",
      "Epoch 2314, Loss: 0.0933085884898901, Final Batch Loss: 0.06665311753749847\n",
      "Epoch 2315, Loss: 0.06881118379533291, Final Batch Loss: 0.027043091133236885\n",
      "Epoch 2316, Loss: 0.10153749957680702, Final Batch Loss: 0.07140852510929108\n",
      "Epoch 2317, Loss: 0.07487664744257927, Final Batch Loss: 0.03900400176644325\n",
      "Epoch 2318, Loss: 0.0968865156173706, Final Batch Loss: 0.05278113856911659\n",
      "Epoch 2319, Loss: 0.04760053567588329, Final Batch Loss: 0.02055365964770317\n",
      "Epoch 2320, Loss: 0.08722135424613953, Final Batch Loss: 0.03308694809675217\n",
      "Epoch 2321, Loss: 0.09131834656000137, Final Batch Loss: 0.05191045626997948\n",
      "Epoch 2322, Loss: 0.10472562536597252, Final Batch Loss: 0.04475560784339905\n",
      "Epoch 2323, Loss: 0.04851375333964825, Final Batch Loss: 0.020552514120936394\n",
      "Epoch 2324, Loss: 0.12873800471425056, Final Batch Loss: 0.10324448347091675\n",
      "Epoch 2325, Loss: 0.06358686089515686, Final Batch Loss: 0.010536722838878632\n",
      "Epoch 2326, Loss: 0.11586254835128784, Final Batch Loss: 0.04784391075372696\n",
      "Epoch 2327, Loss: 0.10769110918045044, Final Batch Loss: 0.057342320680618286\n",
      "Epoch 2328, Loss: 0.07774009183049202, Final Batch Loss: 0.05295700207352638\n",
      "Epoch 2329, Loss: 0.12308893725275993, Final Batch Loss: 0.05313458666205406\n",
      "Epoch 2330, Loss: 0.1215774305164814, Final Batch Loss: 0.06483244895935059\n",
      "Epoch 2331, Loss: 0.08988196030259132, Final Batch Loss: 0.046455010771751404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2332, Loss: 0.09372741729021072, Final Batch Loss: 0.04251952841877937\n",
      "Epoch 2333, Loss: 0.15043354406952858, Final Batch Loss: 0.11561911553144455\n",
      "Epoch 2334, Loss: 0.1121971495449543, Final Batch Loss: 0.054781224578619\n",
      "Epoch 2335, Loss: 0.15158842876553535, Final Batch Loss: 0.10007301717996597\n",
      "Epoch 2336, Loss: 0.11315003037452698, Final Batch Loss: 0.07226163893938065\n",
      "Epoch 2337, Loss: 0.08353604562580585, Final Batch Loss: 0.058346740901470184\n",
      "Epoch 2338, Loss: 0.050925154238939285, Final Batch Loss: 0.01440582424402237\n",
      "Epoch 2339, Loss: 0.15765061974525452, Final Batch Loss: 0.09482105076313019\n",
      "Epoch 2340, Loss: 0.08304993622004986, Final Batch Loss: 0.05300522223114967\n",
      "Epoch 2341, Loss: 0.06412162631750107, Final Batch Loss: 0.018329132348299026\n",
      "Epoch 2342, Loss: 0.11278323084115982, Final Batch Loss: 0.07327252626419067\n",
      "Epoch 2343, Loss: 0.1567000225186348, Final Batch Loss: 0.09167014807462692\n",
      "Epoch 2344, Loss: 0.06492755748331547, Final Batch Loss: 0.037970442324876785\n",
      "Epoch 2345, Loss: 0.07817529141902924, Final Batch Loss: 0.040887556970119476\n",
      "Epoch 2346, Loss: 0.056812191382050514, Final Batch Loss: 0.026970377191901207\n",
      "Epoch 2347, Loss: 0.09653084725141525, Final Batch Loss: 0.06343888491392136\n",
      "Epoch 2348, Loss: 0.08482113853096962, Final Batch Loss: 0.05251190438866615\n",
      "Epoch 2349, Loss: 0.09395083039999008, Final Batch Loss: 0.04029588773846626\n",
      "Epoch 2350, Loss: 0.08174585364758968, Final Batch Loss: 0.022620512172579765\n",
      "Epoch 2351, Loss: 0.08496187627315521, Final Batch Loss: 0.04984559118747711\n",
      "Epoch 2352, Loss: 0.06401407532393932, Final Batch Loss: 0.02653842233121395\n",
      "Epoch 2353, Loss: 0.08493481203913689, Final Batch Loss: 0.02028600499033928\n",
      "Epoch 2354, Loss: 0.06505098938941956, Final Batch Loss: 0.0418824702501297\n",
      "Epoch 2355, Loss: 0.05980602279305458, Final Batch Loss: 0.02969195321202278\n",
      "Epoch 2356, Loss: 0.08749637752771378, Final Batch Loss: 0.04655463993549347\n",
      "Epoch 2357, Loss: 0.09555413946509361, Final Batch Loss: 0.06717914342880249\n",
      "Epoch 2358, Loss: 0.04477114602923393, Final Batch Loss: 0.013587629422545433\n",
      "Epoch 2359, Loss: 0.04770572762936354, Final Batch Loss: 0.011796924285590649\n",
      "Epoch 2360, Loss: 0.08048155158758163, Final Batch Loss: 0.02806360274553299\n",
      "Epoch 2361, Loss: 0.13551203161478043, Final Batch Loss: 0.06006436049938202\n",
      "Epoch 2362, Loss: 0.10664551705121994, Final Batch Loss: 0.08728291094303131\n",
      "Epoch 2363, Loss: 0.062305325642228127, Final Batch Loss: 0.02239229343831539\n",
      "Epoch 2364, Loss: 0.0826546773314476, Final Batch Loss: 0.06515204161405563\n",
      "Epoch 2365, Loss: 0.0834122970700264, Final Batch Loss: 0.04705161601305008\n",
      "Epoch 2366, Loss: 0.10660165175795555, Final Batch Loss: 0.05304175615310669\n",
      "Epoch 2367, Loss: 0.13557611405849457, Final Batch Loss: 0.054158806800842285\n",
      "Epoch 2368, Loss: 0.06766434479504824, Final Batch Loss: 0.011616096831858158\n",
      "Epoch 2369, Loss: 0.09219906106591225, Final Batch Loss: 0.03417114540934563\n",
      "Epoch 2370, Loss: 0.07967003062367439, Final Batch Loss: 0.036340851336717606\n",
      "Epoch 2371, Loss: 0.09457230567932129, Final Batch Loss: 0.0381055511534214\n",
      "Epoch 2372, Loss: 0.11213574558496475, Final Batch Loss: 0.03459811955690384\n",
      "Epoch 2373, Loss: 0.05241778306663036, Final Batch Loss: 0.018586428835988045\n",
      "Epoch 2374, Loss: 0.06258668564260006, Final Batch Loss: 0.0395076759159565\n",
      "Epoch 2375, Loss: 0.08320077322423458, Final Batch Loss: 0.022448236122727394\n",
      "Epoch 2376, Loss: 0.0837172269821167, Final Batch Loss: 0.04629303142428398\n",
      "Epoch 2377, Loss: 0.07519989088177681, Final Batch Loss: 0.04431569576263428\n",
      "Epoch 2378, Loss: 0.10965008288621902, Final Batch Loss: 0.047106899321079254\n",
      "Epoch 2379, Loss: 0.06517938524484634, Final Batch Loss: 0.04232673719525337\n",
      "Epoch 2380, Loss: 0.05308923311531544, Final Batch Loss: 0.016723250970244408\n",
      "Epoch 2381, Loss: 0.052062464877963066, Final Batch Loss: 0.03068707510828972\n",
      "Epoch 2382, Loss: 0.05665922723710537, Final Batch Loss: 0.026449745520949364\n",
      "Epoch 2383, Loss: 0.08430996164679527, Final Batch Loss: 0.03903475031256676\n",
      "Epoch 2384, Loss: 0.07093067467212677, Final Batch Loss: 0.027833588421344757\n",
      "Epoch 2385, Loss: 0.10602440685033798, Final Batch Loss: 0.04412541165947914\n",
      "Epoch 2386, Loss: 0.08813434839248657, Final Batch Loss: 0.049412909895181656\n",
      "Epoch 2387, Loss: 0.08240976929664612, Final Batch Loss: 0.04199414327740669\n",
      "Epoch 2388, Loss: 0.04628218896687031, Final Batch Loss: 0.020408961921930313\n",
      "Epoch 2389, Loss: 0.05501347407698631, Final Batch Loss: 0.034259241074323654\n",
      "Epoch 2390, Loss: 0.04515058547258377, Final Batch Loss: 0.02190716750919819\n",
      "Epoch 2391, Loss: 0.07352402061223984, Final Batch Loss: 0.03220689296722412\n",
      "Epoch 2392, Loss: 0.07522319629788399, Final Batch Loss: 0.030353926122188568\n",
      "Epoch 2393, Loss: 0.05527683347463608, Final Batch Loss: 0.02241174504160881\n",
      "Epoch 2394, Loss: 0.1367722824215889, Final Batch Loss: 0.10082324594259262\n",
      "Epoch 2395, Loss: 0.12585829570889473, Final Batch Loss: 0.0619070790708065\n",
      "Epoch 2396, Loss: 0.07048642449080944, Final Batch Loss: 0.045689795166254044\n",
      "Epoch 2397, Loss: 0.0783572867512703, Final Batch Loss: 0.052548155188560486\n",
      "Epoch 2398, Loss: 0.0720345638692379, Final Batch Loss: 0.038043346256017685\n",
      "Epoch 2399, Loss: 0.08317152597010136, Final Batch Loss: 0.02370261959731579\n",
      "Epoch 2400, Loss: 0.06445823423564434, Final Batch Loss: 0.019387247040867805\n",
      "Epoch 2401, Loss: 0.0973692536354065, Final Batch Loss: 0.06082054600119591\n",
      "Epoch 2402, Loss: 0.09145761001855135, Final Batch Loss: 0.01420267391949892\n",
      "Epoch 2403, Loss: 0.08083745837211609, Final Batch Loss: 0.03957686945796013\n",
      "Epoch 2404, Loss: 0.12341408059000969, Final Batch Loss: 0.06626423448324203\n",
      "Epoch 2405, Loss: 0.09788866713643074, Final Batch Loss: 0.07484208047389984\n",
      "Epoch 2406, Loss: 0.10346757993102074, Final Batch Loss: 0.06306411325931549\n",
      "Epoch 2407, Loss: 0.11863542348146439, Final Batch Loss: 0.036967627704143524\n",
      "Epoch 2408, Loss: 0.05809435807168484, Final Batch Loss: 0.036135509610176086\n",
      "Epoch 2409, Loss: 0.05796650983393192, Final Batch Loss: 0.032002102583646774\n",
      "Epoch 2410, Loss: 0.08311472460627556, Final Batch Loss: 0.05003371089696884\n",
      "Epoch 2411, Loss: 0.073619918897748, Final Batch Loss: 0.03074193187057972\n",
      "Epoch 2412, Loss: 0.061343880370259285, Final Batch Loss: 0.03803275153040886\n",
      "Epoch 2413, Loss: 0.09968618303537369, Final Batch Loss: 0.05606767535209656\n",
      "Epoch 2414, Loss: 0.1541684828698635, Final Batch Loss: 0.03323252871632576\n",
      "Epoch 2415, Loss: 0.1059819757938385, Final Batch Loss: 0.05817003920674324\n",
      "Epoch 2416, Loss: 0.1481223776936531, Final Batch Loss: 0.08278585970401764\n",
      "Epoch 2417, Loss: 0.08687551319599152, Final Batch Loss: 0.04378171265125275\n",
      "Epoch 2418, Loss: 0.12072452530264854, Final Batch Loss: 0.0879049003124237\n",
      "Epoch 2419, Loss: 0.08810630813241005, Final Batch Loss: 0.030382979661226273\n",
      "Epoch 2420, Loss: 0.06466564908623695, Final Batch Loss: 0.029090099036693573\n",
      "Epoch 2421, Loss: 0.11818207055330276, Final Batch Loss: 0.08216248452663422\n",
      "Epoch 2422, Loss: 0.08366336673498154, Final Batch Loss: 0.04881065711379051\n",
      "Epoch 2423, Loss: 0.13091089576482773, Final Batch Loss: 0.06352388858795166\n",
      "Epoch 2424, Loss: 0.08488757535815239, Final Batch Loss: 0.050917644053697586\n",
      "Epoch 2425, Loss: 0.09223732724785805, Final Batch Loss: 0.05291036516427994\n",
      "Epoch 2426, Loss: 0.08481229096651077, Final Batch Loss: 0.027141768485307693\n",
      "Epoch 2427, Loss: 0.06487336754798889, Final Batch Loss: 0.01627221703529358\n",
      "Epoch 2428, Loss: 0.11442293226718903, Final Batch Loss: 0.05678333342075348\n",
      "Epoch 2429, Loss: 0.14343830198049545, Final Batch Loss: 0.04242388904094696\n",
      "Epoch 2430, Loss: 0.05725047364830971, Final Batch Loss: 0.02399347722530365\n",
      "Epoch 2431, Loss: 0.06915276497602463, Final Batch Loss: 0.03163096308708191\n",
      "Epoch 2432, Loss: 0.06516910903155804, Final Batch Loss: 0.04431964084506035\n",
      "Epoch 2433, Loss: 0.10144661366939545, Final Batch Loss: 0.04618968069553375\n",
      "Epoch 2434, Loss: 0.10449189506471157, Final Batch Loss: 0.07454891502857208\n",
      "Epoch 2435, Loss: 0.09899050369858742, Final Batch Loss: 0.06403323262929916\n",
      "Epoch 2436, Loss: 0.07350725680589676, Final Batch Loss: 0.04027336835861206\n",
      "Epoch 2437, Loss: 0.057135120034217834, Final Batch Loss: 0.018214549869298935\n",
      "Epoch 2438, Loss: 0.09542882442474365, Final Batch Loss: 0.05320306867361069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2439, Loss: 0.12010311335325241, Final Batch Loss: 0.0646531730890274\n",
      "Epoch 2440, Loss: 0.048905353993177414, Final Batch Loss: 0.020991932600736618\n",
      "Epoch 2441, Loss: 0.16679203137755394, Final Batch Loss: 0.1303543746471405\n",
      "Epoch 2442, Loss: 0.06478935852646828, Final Batch Loss: 0.04802211746573448\n",
      "Epoch 2443, Loss: 0.05801683850586414, Final Batch Loss: 0.032621994614601135\n",
      "Epoch 2444, Loss: 0.08318517729640007, Final Batch Loss: 0.04835209250450134\n",
      "Epoch 2445, Loss: 0.07188940979540348, Final Batch Loss: 0.0293899979442358\n",
      "Epoch 2446, Loss: 0.04609944298863411, Final Batch Loss: 0.022856630384922028\n",
      "Epoch 2447, Loss: 0.06169959716498852, Final Batch Loss: 0.027339568361639977\n",
      "Epoch 2448, Loss: 0.0663591343909502, Final Batch Loss: 0.027942465618252754\n",
      "Epoch 2449, Loss: 0.12757980823516846, Final Batch Loss: 0.05721549689769745\n",
      "Epoch 2450, Loss: 0.07871322333812714, Final Batch Loss: 0.0469207689166069\n",
      "Epoch 2451, Loss: 0.08438289165496826, Final Batch Loss: 0.03568040207028389\n",
      "Epoch 2452, Loss: 0.07395123317837715, Final Batch Loss: 0.036561883985996246\n",
      "Epoch 2453, Loss: 0.12384084984660149, Final Batch Loss: 0.0875108614563942\n",
      "Epoch 2454, Loss: 0.05024655908346176, Final Batch Loss: 0.02152186445891857\n",
      "Epoch 2455, Loss: 0.06883813813328743, Final Batch Loss: 0.03762443736195564\n",
      "Epoch 2456, Loss: 0.03956977277994156, Final Batch Loss: 0.013940902426838875\n",
      "Epoch 2457, Loss: 0.12157631292939186, Final Batch Loss: 0.08432754874229431\n",
      "Epoch 2458, Loss: 0.12692051753401756, Final Batch Loss: 0.07720968127250671\n",
      "Epoch 2459, Loss: 0.08572043664753437, Final Batch Loss: 0.026234997436404228\n",
      "Epoch 2460, Loss: 0.08004215359687805, Final Batch Loss: 0.03864789009094238\n",
      "Epoch 2461, Loss: 0.05716576986014843, Final Batch Loss: 0.026237409561872482\n",
      "Epoch 2462, Loss: 0.07121463678777218, Final Batch Loss: 0.05259772017598152\n",
      "Epoch 2463, Loss: 0.07613879814743996, Final Batch Loss: 0.0496063232421875\n",
      "Epoch 2464, Loss: 0.08319558575749397, Final Batch Loss: 0.04279258847236633\n",
      "Epoch 2465, Loss: 0.05176355130970478, Final Batch Loss: 0.023099245503544807\n",
      "Epoch 2466, Loss: 0.06417361460626125, Final Batch Loss: 0.024973036721348763\n",
      "Epoch 2467, Loss: 0.09529141709208488, Final Batch Loss: 0.05011146888136864\n",
      "Epoch 2468, Loss: 0.1052481159567833, Final Batch Loss: 0.0749945342540741\n",
      "Epoch 2469, Loss: 0.050300268456339836, Final Batch Loss: 0.02330791763961315\n",
      "Epoch 2470, Loss: 0.07741260901093483, Final Batch Loss: 0.06169505417346954\n",
      "Epoch 2471, Loss: 0.09434299543499947, Final Batch Loss: 0.05973228067159653\n",
      "Epoch 2472, Loss: 0.06106937304139137, Final Batch Loss: 0.0158461332321167\n",
      "Epoch 2473, Loss: 0.08691191300749779, Final Batch Loss: 0.025991417467594147\n",
      "Epoch 2474, Loss: 0.08265339583158493, Final Batch Loss: 0.037970900535583496\n",
      "Epoch 2475, Loss: 0.08833329752087593, Final Batch Loss: 0.03208308294415474\n",
      "Epoch 2476, Loss: 0.06017292756587267, Final Batch Loss: 0.011213180609047413\n",
      "Epoch 2477, Loss: 0.08309827744960785, Final Batch Loss: 0.04573068022727966\n",
      "Epoch 2478, Loss: 0.07381740026175976, Final Batch Loss: 0.0436178483068943\n",
      "Epoch 2479, Loss: 0.0997781939804554, Final Batch Loss: 0.056747566908597946\n",
      "Epoch 2480, Loss: 0.05883810296654701, Final Batch Loss: 0.04182174801826477\n",
      "Epoch 2481, Loss: 0.05820450186729431, Final Batch Loss: 0.034528251737356186\n",
      "Epoch 2482, Loss: 0.07241819985210896, Final Batch Loss: 0.042648475617170334\n",
      "Epoch 2483, Loss: 0.07225928083062172, Final Batch Loss: 0.03986537083983421\n",
      "Epoch 2484, Loss: 0.049881599843502045, Final Batch Loss: 0.026055924594402313\n",
      "Epoch 2485, Loss: 0.07596633769571781, Final Batch Loss: 0.05229839310050011\n",
      "Epoch 2486, Loss: 0.05806938000023365, Final Batch Loss: 0.04103961959481239\n",
      "Epoch 2487, Loss: 0.08205347508192062, Final Batch Loss: 0.048418596386909485\n",
      "Epoch 2488, Loss: 0.08203825540840626, Final Batch Loss: 0.06429438292980194\n",
      "Epoch 2489, Loss: 0.06557311303913593, Final Batch Loss: 0.0410316102206707\n",
      "Epoch 2490, Loss: 0.11691626161336899, Final Batch Loss: 0.06914348155260086\n",
      "Epoch 2491, Loss: 0.14384817332029343, Final Batch Loss: 0.04446838051080704\n",
      "Epoch 2492, Loss: 0.1041707992553711, Final Batch Loss: 0.07863344997167587\n",
      "Epoch 2493, Loss: 0.09338277019560337, Final Batch Loss: 0.02577575482428074\n",
      "Epoch 2494, Loss: 0.09779388830065727, Final Batch Loss: 0.03194640949368477\n",
      "Epoch 2495, Loss: 0.11948052793741226, Final Batch Loss: 0.06979268044233322\n",
      "Epoch 2496, Loss: 0.10138116031885147, Final Batch Loss: 0.04521392285823822\n",
      "Epoch 2497, Loss: 0.08499610796570778, Final Batch Loss: 0.043675389140844345\n",
      "Epoch 2498, Loss: 0.06633226945996284, Final Batch Loss: 0.04060941934585571\n",
      "Epoch 2499, Loss: 0.042656783014535904, Final Batch Loss: 0.02315555140376091\n",
      "Epoch 2500, Loss: 0.1727205514907837, Final Batch Loss: 0.0804816409945488\n",
      "Epoch 2501, Loss: 0.09367146342992783, Final Batch Loss: 0.04520738869905472\n",
      "Epoch 2502, Loss: 0.09600105509161949, Final Batch Loss: 0.03945281729102135\n",
      "Epoch 2503, Loss: 0.07709144055843353, Final Batch Loss: 0.032234836369752884\n",
      "Epoch 2504, Loss: 0.10179315879940987, Final Batch Loss: 0.046149395406246185\n",
      "Epoch 2505, Loss: 0.07239717617630959, Final Batch Loss: 0.04055318608880043\n",
      "Epoch 2506, Loss: 0.07847778871655464, Final Batch Loss: 0.042480405420064926\n",
      "Epoch 2507, Loss: 0.0707368478178978, Final Batch Loss: 0.03908118978142738\n",
      "Epoch 2508, Loss: 0.056889383122324944, Final Batch Loss: 0.032038383185863495\n",
      "Epoch 2509, Loss: 0.07387789152562618, Final Batch Loss: 0.026969460770487785\n",
      "Epoch 2510, Loss: 0.057105354964733124, Final Batch Loss: 0.015414975583553314\n",
      "Epoch 2511, Loss: 0.07000059261918068, Final Batch Loss: 0.03998076915740967\n",
      "Epoch 2512, Loss: 0.10858835279941559, Final Batch Loss: 0.04722601920366287\n",
      "Epoch 2513, Loss: 0.14027177542448044, Final Batch Loss: 0.04359900951385498\n",
      "Epoch 2514, Loss: 0.1048203706741333, Final Batch Loss: 0.057901881635189056\n",
      "Epoch 2515, Loss: 0.14238060265779495, Final Batch Loss: 0.07370494306087494\n",
      "Epoch 2516, Loss: 0.0877522099763155, Final Batch Loss: 0.028022324666380882\n",
      "Epoch 2517, Loss: 0.16537386924028397, Final Batch Loss: 0.11971333622932434\n",
      "Epoch 2518, Loss: 0.10406426712870598, Final Batch Loss: 0.01777012273669243\n",
      "Epoch 2519, Loss: 0.1089165173470974, Final Batch Loss: 0.03580690547823906\n",
      "Epoch 2520, Loss: 0.14001700282096863, Final Batch Loss: 0.061404868960380554\n",
      "Epoch 2521, Loss: 0.15197397023439407, Final Batch Loss: 0.08843158185482025\n",
      "Epoch 2522, Loss: 0.12197424471378326, Final Batch Loss: 0.04503016918897629\n",
      "Epoch 2523, Loss: 0.08418189734220505, Final Batch Loss: 0.0489257387816906\n",
      "Epoch 2524, Loss: 0.09560700133442879, Final Batch Loss: 0.06503438949584961\n",
      "Epoch 2525, Loss: 0.13983114063739777, Final Batch Loss: 0.07060164958238602\n",
      "Epoch 2526, Loss: 0.06836439110338688, Final Batch Loss: 0.030359530821442604\n",
      "Epoch 2527, Loss: 0.07637708261609077, Final Batch Loss: 0.038484230637550354\n",
      "Epoch 2528, Loss: 0.14665564894676208, Final Batch Loss: 0.09888757765293121\n",
      "Epoch 2529, Loss: 0.0850466825067997, Final Batch Loss: 0.04064938426017761\n",
      "Epoch 2530, Loss: 0.11515093222260475, Final Batch Loss: 0.060887161642313004\n",
      "Epoch 2531, Loss: 0.12709908187389374, Final Batch Loss: 0.06278424710035324\n",
      "Epoch 2532, Loss: 0.10153614729642868, Final Batch Loss: 0.031722456216812134\n",
      "Epoch 2533, Loss: 0.10963663458824158, Final Batch Loss: 0.06837871670722961\n",
      "Epoch 2534, Loss: 0.1085641086101532, Final Batch Loss: 0.04802323877811432\n",
      "Epoch 2535, Loss: 0.10688817128539085, Final Batch Loss: 0.04662707820534706\n",
      "Epoch 2536, Loss: 0.04841665457934141, Final Batch Loss: 0.013266428373754025\n",
      "Epoch 2537, Loss: 0.08148420043289661, Final Batch Loss: 0.05966679006814957\n",
      "Epoch 2538, Loss: 0.05912398174405098, Final Batch Loss: 0.02977527305483818\n",
      "Epoch 2539, Loss: 0.05187191441655159, Final Batch Loss: 0.020465601235628128\n",
      "Epoch 2540, Loss: 0.10650228708982468, Final Batch Loss: 0.07137937843799591\n",
      "Epoch 2541, Loss: 0.07769492268562317, Final Batch Loss: 0.03402678668498993\n",
      "Epoch 2542, Loss: 0.11634540185332298, Final Batch Loss: 0.06136537343263626\n",
      "Epoch 2543, Loss: 0.06830737739801407, Final Batch Loss: 0.032273098826408386\n",
      "Epoch 2544, Loss: 0.07946497574448586, Final Batch Loss: 0.039003122597932816\n",
      "Epoch 2545, Loss: 0.13498470559716225, Final Batch Loss: 0.08617608994245529\n",
      "Epoch 2546, Loss: 0.09211568906903267, Final Batch Loss: 0.051230233162641525\n",
      "Epoch 2547, Loss: 0.07635124400258064, Final Batch Loss: 0.027432166039943695\n",
      "Epoch 2548, Loss: 0.06117802858352661, Final Batch Loss: 0.03185555338859558\n",
      "Epoch 2549, Loss: 0.1068037860095501, Final Batch Loss: 0.04061298444867134\n",
      "Epoch 2550, Loss: 0.08609946817159653, Final Batch Loss: 0.034239355474710464\n",
      "Epoch 2551, Loss: 0.049268568865954876, Final Batch Loss: 0.013799908570945263\n",
      "Epoch 2552, Loss: 0.05958628095686436, Final Batch Loss: 0.027405301108956337\n",
      "Epoch 2553, Loss: 0.13134651631116867, Final Batch Loss: 0.0859181359410286\n",
      "Epoch 2554, Loss: 0.0671783946454525, Final Batch Loss: 0.038293808698654175\n",
      "Epoch 2555, Loss: 0.06399601511657238, Final Batch Loss: 0.018884768709540367\n",
      "Epoch 2556, Loss: 0.08079649321734905, Final Batch Loss: 0.058461327105760574\n",
      "Epoch 2557, Loss: 0.06889052502810955, Final Batch Loss: 0.02034488506615162\n",
      "Epoch 2558, Loss: 0.10981516167521477, Final Batch Loss: 0.05173194780945778\n",
      "Epoch 2559, Loss: 0.09582579880952835, Final Batch Loss: 0.048542335629463196\n",
      "Epoch 2560, Loss: 0.08126828633248806, Final Batch Loss: 0.05166434124112129\n",
      "Epoch 2561, Loss: 0.11176496371626854, Final Batch Loss: 0.06823436915874481\n",
      "Epoch 2562, Loss: 0.07143230177462101, Final Batch Loss: 0.01079343818128109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2563, Loss: 0.061322109773755074, Final Batch Loss: 0.022807350382208824\n",
      "Epoch 2564, Loss: 0.08255453035235405, Final Batch Loss: 0.04285737872123718\n",
      "Epoch 2565, Loss: 0.1135767474770546, Final Batch Loss: 0.046389296650886536\n",
      "Epoch 2566, Loss: 0.09522287547588348, Final Batch Loss: 0.055733006447553635\n",
      "Epoch 2567, Loss: 0.08873365074396133, Final Batch Loss: 0.023952297866344452\n",
      "Epoch 2568, Loss: 0.058831630274653435, Final Batch Loss: 0.029875585809350014\n",
      "Epoch 2569, Loss: 0.0852244459092617, Final Batch Loss: 0.031788911670446396\n",
      "Epoch 2570, Loss: 0.058755217120051384, Final Batch Loss: 0.019172651693224907\n",
      "Epoch 2571, Loss: 0.06771865300834179, Final Batch Loss: 0.023420078679919243\n",
      "Epoch 2572, Loss: 0.11256411299109459, Final Batch Loss: 0.07039966434240341\n",
      "Epoch 2573, Loss: 0.08861872181296349, Final Batch Loss: 0.0593099407851696\n",
      "Epoch 2574, Loss: 0.11768004298210144, Final Batch Loss: 0.0415077731013298\n",
      "Epoch 2575, Loss: 0.17034617438912392, Final Batch Loss: 0.14305828511714935\n",
      "Epoch 2576, Loss: 0.0709131509065628, Final Batch Loss: 0.023441359400749207\n",
      "Epoch 2577, Loss: 0.05390126071870327, Final Batch Loss: 0.017991160973906517\n",
      "Epoch 2578, Loss: 0.041309055872261524, Final Batch Loss: 0.012370712123811245\n",
      "Epoch 2579, Loss: 0.08349323272705078, Final Batch Loss: 0.04973464086651802\n",
      "Epoch 2580, Loss: 0.06480595469474792, Final Batch Loss: 0.03644752874970436\n",
      "Epoch 2581, Loss: 0.04513055831193924, Final Batch Loss: 0.02213943377137184\n",
      "Epoch 2582, Loss: 0.06562401726841927, Final Batch Loss: 0.04162393882870674\n",
      "Epoch 2583, Loss: 0.07700952515006065, Final Batch Loss: 0.034390639513731\n",
      "Epoch 2584, Loss: 0.09093749150633812, Final Batch Loss: 0.04613560810685158\n",
      "Epoch 2585, Loss: 0.09273134358227253, Final Batch Loss: 0.07214734703302383\n",
      "Epoch 2586, Loss: 0.07849913462996483, Final Batch Loss: 0.01754763349890709\n",
      "Epoch 2587, Loss: 0.055997664108872414, Final Batch Loss: 0.03274768963456154\n",
      "Epoch 2588, Loss: 0.06671079061925411, Final Batch Loss: 0.04362943023443222\n",
      "Epoch 2589, Loss: 0.0714181661605835, Final Batch Loss: 0.016008097678422928\n",
      "Epoch 2590, Loss: 0.07822187431156635, Final Batch Loss: 0.04780816286802292\n",
      "Epoch 2591, Loss: 0.11604513972997665, Final Batch Loss: 0.051231808960437775\n",
      "Epoch 2592, Loss: 0.05704474449157715, Final Batch Loss: 0.0233885757625103\n",
      "Epoch 2593, Loss: 0.09727834537625313, Final Batch Loss: 0.07443365454673767\n",
      "Epoch 2594, Loss: 0.08272162824869156, Final Batch Loss: 0.037959933280944824\n",
      "Epoch 2595, Loss: 0.09532179683446884, Final Batch Loss: 0.060330603271722794\n",
      "Epoch 2596, Loss: 0.09687137417495251, Final Batch Loss: 0.0678916722536087\n",
      "Epoch 2597, Loss: 0.09748125448822975, Final Batch Loss: 0.04668513685464859\n",
      "Epoch 2598, Loss: 0.12480528652667999, Final Batch Loss: 0.0800260528922081\n",
      "Epoch 2599, Loss: 0.09492646530270576, Final Batch Loss: 0.04965205118060112\n",
      "Epoch 2600, Loss: 0.06961299851536751, Final Batch Loss: 0.03779391199350357\n",
      "Epoch 2601, Loss: 0.09966885671019554, Final Batch Loss: 0.043332137167453766\n",
      "Epoch 2602, Loss: 0.07365774363279343, Final Batch Loss: 0.02966148406267166\n",
      "Epoch 2603, Loss: 0.08522160910069942, Final Batch Loss: 0.05755152553319931\n",
      "Epoch 2604, Loss: 0.07310186326503754, Final Batch Loss: 0.05047670751810074\n",
      "Epoch 2605, Loss: 0.06424174457788467, Final Batch Loss: 0.021128270775079727\n",
      "Epoch 2606, Loss: 0.11360883712768555, Final Batch Loss: 0.06674414128065109\n",
      "Epoch 2607, Loss: 0.10539896413683891, Final Batch Loss: 0.052726082503795624\n",
      "Epoch 2608, Loss: 0.07837126590311527, Final Batch Loss: 0.027988376095891\n",
      "Epoch 2609, Loss: 0.1180732287466526, Final Batch Loss: 0.05862416326999664\n",
      "Epoch 2610, Loss: 0.0794912725687027, Final Batch Loss: 0.026810966432094574\n",
      "Epoch 2611, Loss: 0.06461410410702229, Final Batch Loss: 0.016218477860093117\n",
      "Epoch 2612, Loss: 0.11696934327483177, Final Batch Loss: 0.034474264830350876\n",
      "Epoch 2613, Loss: 0.08703581616282463, Final Batch Loss: 0.030284807085990906\n",
      "Epoch 2614, Loss: 0.04579583462327719, Final Batch Loss: 0.011604405008256435\n",
      "Epoch 2615, Loss: 0.06332367472350597, Final Batch Loss: 0.026544412598013878\n",
      "Epoch 2616, Loss: 0.066516799852252, Final Batch Loss: 0.04067116230726242\n",
      "Epoch 2617, Loss: 0.14605126529932022, Final Batch Loss: 0.1122492179274559\n",
      "Epoch 2618, Loss: 0.06498860754072666, Final Batch Loss: 0.039124585688114166\n",
      "Epoch 2619, Loss: 0.06028050556778908, Final Batch Loss: 0.01909705623984337\n",
      "Epoch 2620, Loss: 0.09767986834049225, Final Batch Loss: 0.06320010125637054\n",
      "Epoch 2621, Loss: 0.06750606931746006, Final Batch Loss: 0.027718110010027885\n",
      "Epoch 2622, Loss: 0.10169614851474762, Final Batch Loss: 0.044200241565704346\n",
      "Epoch 2623, Loss: 0.07113775610923767, Final Batch Loss: 0.029892750084400177\n",
      "Epoch 2624, Loss: 0.0390478540211916, Final Batch Loss: 0.014424009248614311\n",
      "Epoch 2625, Loss: 0.08611149713397026, Final Batch Loss: 0.0670829489827156\n",
      "Epoch 2626, Loss: 0.07283823564648628, Final Batch Loss: 0.04019324481487274\n",
      "Epoch 2627, Loss: 0.05342235416173935, Final Batch Loss: 0.025469910353422165\n",
      "Epoch 2628, Loss: 0.0699265943840146, Final Batch Loss: 0.011330951936542988\n",
      "Epoch 2629, Loss: 0.06248440407216549, Final Batch Loss: 0.03071492724120617\n",
      "Epoch 2630, Loss: 0.04451131448149681, Final Batch Loss: 0.01964324153959751\n",
      "Epoch 2631, Loss: 0.09948750212788582, Final Batch Loss: 0.04985415190458298\n",
      "Epoch 2632, Loss: 0.06308109872043133, Final Batch Loss: 0.024424823001027107\n",
      "Epoch 2633, Loss: 0.046232023276388645, Final Batch Loss: 0.007782940752804279\n",
      "Epoch 2634, Loss: 0.12396970763802528, Final Batch Loss: 0.06721508502960205\n",
      "Epoch 2635, Loss: 0.06671418063342571, Final Batch Loss: 0.043648187071084976\n",
      "Epoch 2636, Loss: 0.05039164982736111, Final Batch Loss: 0.02855975367128849\n",
      "Epoch 2637, Loss: 0.06400899402797222, Final Batch Loss: 0.035917337983846664\n",
      "Epoch 2638, Loss: 0.07832498848438263, Final Batch Loss: 0.02380264922976494\n",
      "Epoch 2639, Loss: 0.05980621837079525, Final Batch Loss: 0.017147717997431755\n",
      "Epoch 2640, Loss: 0.1209278479218483, Final Batch Loss: 0.08378095179796219\n",
      "Epoch 2641, Loss: 0.050755711272358894, Final Batch Loss: 0.025200285017490387\n",
      "Epoch 2642, Loss: 0.08653029426932335, Final Batch Loss: 0.050001662224531174\n",
      "Epoch 2643, Loss: 0.13603629544377327, Final Batch Loss: 0.07761628180742264\n",
      "Epoch 2644, Loss: 0.08052417822182178, Final Batch Loss: 0.020451584830880165\n",
      "Epoch 2645, Loss: 0.0953671745955944, Final Batch Loss: 0.08159228414297104\n",
      "Epoch 2646, Loss: 0.08149933442473412, Final Batch Loss: 0.027272425591945648\n",
      "Epoch 2647, Loss: 0.06690585426986217, Final Batch Loss: 0.03749450668692589\n",
      "Epoch 2648, Loss: 0.0690645333379507, Final Batch Loss: 0.0264593493193388\n",
      "Epoch 2649, Loss: 0.06041009910404682, Final Batch Loss: 0.02375216595828533\n",
      "Epoch 2650, Loss: 0.06427774531766772, Final Batch Loss: 0.007757346611469984\n",
      "Epoch 2651, Loss: 0.07363194972276688, Final Batch Loss: 0.04247311130166054\n",
      "Epoch 2652, Loss: 0.0780637264251709, Final Batch Loss: 0.04790903255343437\n",
      "Epoch 2653, Loss: 0.09087936580181122, Final Batch Loss: 0.062027089297771454\n",
      "Epoch 2654, Loss: 0.06451401486992836, Final Batch Loss: 0.018101312220096588\n",
      "Epoch 2655, Loss: 0.10580103099346161, Final Batch Loss: 0.06370049715042114\n",
      "Epoch 2656, Loss: 0.058927783742547035, Final Batch Loss: 0.018397046253085136\n",
      "Epoch 2657, Loss: 0.057495586574077606, Final Batch Loss: 0.019563380628824234\n",
      "Epoch 2658, Loss: 0.14216623455286026, Final Batch Loss: 0.0891946479678154\n",
      "Epoch 2659, Loss: 0.09861364215612411, Final Batch Loss: 0.023737765848636627\n",
      "Epoch 2660, Loss: 0.07719972729682922, Final Batch Loss: 0.027374424040317535\n",
      "Epoch 2661, Loss: 0.066706707701087, Final Batch Loss: 0.02165801264345646\n",
      "Epoch 2662, Loss: 0.06907250359654427, Final Batch Loss: 0.024995654821395874\n",
      "Epoch 2663, Loss: 0.07299553044140339, Final Batch Loss: 0.04781193286180496\n",
      "Epoch 2664, Loss: 0.09368602931499481, Final Batch Loss: 0.04050694406032562\n",
      "Epoch 2665, Loss: 0.07579629123210907, Final Batch Loss: 0.03488481789827347\n",
      "Epoch 2666, Loss: 0.10586332529783249, Final Batch Loss: 0.06148065999150276\n",
      "Epoch 2667, Loss: 0.06440778821706772, Final Batch Loss: 0.03795064240694046\n",
      "Epoch 2668, Loss: 0.06684064120054245, Final Batch Loss: 0.014366786926984787\n",
      "Epoch 2669, Loss: 0.08773371949791908, Final Batch Loss: 0.03920648247003555\n",
      "Epoch 2670, Loss: 0.08555922657251358, Final Batch Loss: 0.051803797483444214\n",
      "Epoch 2671, Loss: 0.12493085861206055, Final Batch Loss: 0.08684030920267105\n",
      "Epoch 2672, Loss: 0.06056348979473114, Final Batch Loss: 0.040746964514255524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2673, Loss: 0.09349166601896286, Final Batch Loss: 0.024710506200790405\n",
      "Epoch 2674, Loss: 0.04275601264089346, Final Batch Loss: 0.013368046842515469\n",
      "Epoch 2675, Loss: 0.06995261646807194, Final Batch Loss: 0.014190612360835075\n",
      "Epoch 2676, Loss: 0.07086756825447083, Final Batch Loss: 0.024722333997488022\n",
      "Epoch 2677, Loss: 0.07756208628416061, Final Batch Loss: 0.042047321796417236\n",
      "Epoch 2678, Loss: 0.07304929569363594, Final Batch Loss: 0.03278472274541855\n",
      "Epoch 2679, Loss: 0.10766411945223808, Final Batch Loss: 0.04234445467591286\n",
      "Epoch 2680, Loss: 0.04585691262036562, Final Batch Loss: 0.011587285436689854\n",
      "Epoch 2681, Loss: 0.04609524458646774, Final Batch Loss: 0.023761386051774025\n",
      "Epoch 2682, Loss: 0.09382233768701553, Final Batch Loss: 0.03244383633136749\n",
      "Epoch 2683, Loss: 0.08860476687550545, Final Batch Loss: 0.0473824180662632\n",
      "Epoch 2684, Loss: 0.07439384236931801, Final Batch Loss: 0.04330000281333923\n",
      "Epoch 2685, Loss: 0.0707867220044136, Final Batch Loss: 0.024860337376594543\n",
      "Epoch 2686, Loss: 0.0624379962682724, Final Batch Loss: 0.04276413097977638\n",
      "Epoch 2687, Loss: 0.04114432446658611, Final Batch Loss: 0.0223345085978508\n",
      "Epoch 2688, Loss: 0.0607011653482914, Final Batch Loss: 0.03410962596535683\n",
      "Epoch 2689, Loss: 0.041490672156214714, Final Batch Loss: 0.019113291054964066\n",
      "Epoch 2690, Loss: 0.05823289789259434, Final Batch Loss: 0.03380214050412178\n",
      "Epoch 2691, Loss: 0.04699546843767166, Final Batch Loss: 0.02741386368870735\n",
      "Epoch 2692, Loss: 0.08813060075044632, Final Batch Loss: 0.05022396519780159\n",
      "Epoch 2693, Loss: 0.09000824019312859, Final Batch Loss: 0.04040806367993355\n",
      "Epoch 2694, Loss: 0.08852590620517731, Final Batch Loss: 0.05392990633845329\n",
      "Epoch 2695, Loss: 0.10022978484630585, Final Batch Loss: 0.03705029934644699\n",
      "Epoch 2696, Loss: 0.042868226766586304, Final Batch Loss: 0.016796372830867767\n",
      "Epoch 2697, Loss: 0.0751758087426424, Final Batch Loss: 0.027558082714676857\n",
      "Epoch 2698, Loss: 0.09036620706319809, Final Batch Loss: 0.03746242821216583\n",
      "Epoch 2699, Loss: 0.07077823765575886, Final Batch Loss: 0.02068239264190197\n",
      "Epoch 2700, Loss: 0.033604695461690426, Final Batch Loss: 0.009185793809592724\n",
      "Epoch 2701, Loss: 0.04297572560608387, Final Batch Loss: 0.01874551922082901\n",
      "Epoch 2702, Loss: 0.09413151815533638, Final Batch Loss: 0.06268753111362457\n",
      "Epoch 2703, Loss: 0.07341858372092247, Final Batch Loss: 0.039818961173295975\n",
      "Epoch 2704, Loss: 0.05901351943612099, Final Batch Loss: 0.019549064338207245\n",
      "Epoch 2705, Loss: 0.07046575471758842, Final Batch Loss: 0.03374723345041275\n",
      "Epoch 2706, Loss: 0.08042104914784431, Final Batch Loss: 0.04466098174452782\n",
      "Epoch 2707, Loss: 0.05298461299389601, Final Batch Loss: 0.012822593562304974\n",
      "Epoch 2708, Loss: 0.07233712263405323, Final Batch Loss: 0.026564376428723335\n",
      "Epoch 2709, Loss: 0.05736425705254078, Final Batch Loss: 0.03785555809736252\n",
      "Epoch 2710, Loss: 0.050844840705394745, Final Batch Loss: 0.014010217040777206\n",
      "Epoch 2711, Loss: 0.03897278755903244, Final Batch Loss: 0.01813421957194805\n",
      "Epoch 2712, Loss: 0.05620073154568672, Final Batch Loss: 0.029836313799023628\n",
      "Epoch 2713, Loss: 0.03720847796648741, Final Batch Loss: 0.015382681973278522\n",
      "Epoch 2714, Loss: 0.048851124942302704, Final Batch Loss: 0.017207849770784378\n",
      "Epoch 2715, Loss: 0.05123088229447603, Final Batch Loss: 0.04123473912477493\n",
      "Epoch 2716, Loss: 0.06838482059538364, Final Batch Loss: 0.025639833882451057\n",
      "Epoch 2717, Loss: 0.04757075384259224, Final Batch Loss: 0.019292160868644714\n",
      "Epoch 2718, Loss: 0.13411178439855576, Final Batch Loss: 0.08706200122833252\n",
      "Epoch 2719, Loss: 0.0919797271490097, Final Batch Loss: 0.022965185344219208\n",
      "Epoch 2720, Loss: 0.06216439791023731, Final Batch Loss: 0.04356769844889641\n",
      "Epoch 2721, Loss: 0.049587080255150795, Final Batch Loss: 0.027061576023697853\n",
      "Epoch 2722, Loss: 0.05870160460472107, Final Batch Loss: 0.020862307399511337\n",
      "Epoch 2723, Loss: 0.07497363910079002, Final Batch Loss: 0.04664987698197365\n",
      "Epoch 2724, Loss: 0.05439659208059311, Final Batch Loss: 0.016914714127779007\n",
      "Epoch 2725, Loss: 0.05019437149167061, Final Batch Loss: 0.0256312545388937\n",
      "Epoch 2726, Loss: 0.07971693761646748, Final Batch Loss: 0.02779007889330387\n",
      "Epoch 2727, Loss: 0.0686911940574646, Final Batch Loss: 0.03872345760464668\n",
      "Epoch 2728, Loss: 0.061218369752168655, Final Batch Loss: 0.042804282158613205\n",
      "Epoch 2729, Loss: 0.06020018830895424, Final Batch Loss: 0.03870724141597748\n",
      "Epoch 2730, Loss: 0.04759090766310692, Final Batch Loss: 0.02257726714015007\n",
      "Epoch 2731, Loss: 0.05647018365561962, Final Batch Loss: 0.0300668366253376\n",
      "Epoch 2732, Loss: 0.04124358110129833, Final Batch Loss: 0.022542759776115417\n",
      "Epoch 2733, Loss: 0.04387122392654419, Final Batch Loss: 0.010015498846769333\n",
      "Epoch 2734, Loss: 0.1308303214609623, Final Batch Loss: 0.08162710070610046\n",
      "Epoch 2735, Loss: 0.04013321083039045, Final Batch Loss: 0.013735800050199032\n",
      "Epoch 2736, Loss: 0.0731818713247776, Final Batch Loss: 0.026129327714443207\n",
      "Epoch 2737, Loss: 0.054048423655331135, Final Batch Loss: 0.008605987764894962\n",
      "Epoch 2738, Loss: 0.08210524171590805, Final Batch Loss: 0.040349747985601425\n",
      "Epoch 2739, Loss: 0.13803761824965477, Final Batch Loss: 0.08469180762767792\n",
      "Epoch 2740, Loss: 0.07369394414126873, Final Batch Loss: 0.04278389364480972\n",
      "Epoch 2741, Loss: 0.12856481410562992, Final Batch Loss: 0.10093449801206589\n",
      "Epoch 2742, Loss: 0.13328281044960022, Final Batch Loss: 0.06810905784368515\n",
      "Epoch 2743, Loss: 0.08500327542424202, Final Batch Loss: 0.0677759125828743\n",
      "Epoch 2744, Loss: 0.05620944872498512, Final Batch Loss: 0.007195699959993362\n",
      "Epoch 2745, Loss: 0.06340278312563896, Final Batch Loss: 0.036985911428928375\n",
      "Epoch 2746, Loss: 0.05803401954472065, Final Batch Loss: 0.014083733782172203\n",
      "Epoch 2747, Loss: 0.08523287624120712, Final Batch Loss: 0.04821379482746124\n",
      "Epoch 2748, Loss: 0.08012142032384872, Final Batch Loss: 0.037080053240060806\n",
      "Epoch 2749, Loss: 0.08560547139495611, Final Batch Loss: 0.011858372949063778\n",
      "Epoch 2750, Loss: 0.08185357507318258, Final Batch Loss: 0.06666509062051773\n",
      "Epoch 2751, Loss: 0.09837381169199944, Final Batch Loss: 0.06210074946284294\n",
      "Epoch 2752, Loss: 0.06179816462099552, Final Batch Loss: 0.044576358050107956\n",
      "Epoch 2753, Loss: 0.0884024165570736, Final Batch Loss: 0.03243229165673256\n",
      "Epoch 2754, Loss: 0.07994362525641918, Final Batch Loss: 0.05373368784785271\n",
      "Epoch 2755, Loss: 0.0552325751632452, Final Batch Loss: 0.03367689624428749\n",
      "Epoch 2756, Loss: 0.12319039925932884, Final Batch Loss: 0.06998520344495773\n",
      "Epoch 2757, Loss: 0.04076032806187868, Final Batch Loss: 0.015488066710531712\n",
      "Epoch 2758, Loss: 0.030582260340452194, Final Batch Loss: 0.012509267777204514\n",
      "Epoch 2759, Loss: 0.09313784912228584, Final Batch Loss: 0.03770652413368225\n",
      "Epoch 2760, Loss: 0.12161242961883545, Final Batch Loss: 0.08639714866876602\n",
      "Epoch 2761, Loss: 0.10231645405292511, Final Batch Loss: 0.08481557667255402\n",
      "Epoch 2762, Loss: 0.0737958773970604, Final Batch Loss: 0.04754090681672096\n",
      "Epoch 2763, Loss: 0.06735372170805931, Final Batch Loss: 0.03627944365143776\n",
      "Epoch 2764, Loss: 0.14409547671675682, Final Batch Loss: 0.10803475230932236\n",
      "Epoch 2765, Loss: 0.10184137150645256, Final Batch Loss: 0.0841796025633812\n",
      "Epoch 2766, Loss: 0.07326526567339897, Final Batch Loss: 0.037626102566719055\n",
      "Epoch 2767, Loss: 0.10855705849826336, Final Batch Loss: 0.025206459686160088\n",
      "Epoch 2768, Loss: 0.06278124079108238, Final Batch Loss: 0.028155509382486343\n",
      "Epoch 2769, Loss: 0.10496478527784348, Final Batch Loss: 0.06704704463481903\n",
      "Epoch 2770, Loss: 0.09965288639068604, Final Batch Loss: 0.04303830489516258\n",
      "Epoch 2771, Loss: 0.08708538115024567, Final Batch Loss: 0.04829341918230057\n",
      "Epoch 2772, Loss: 0.10198492556810379, Final Batch Loss: 0.06412386894226074\n",
      "Epoch 2773, Loss: 0.07489471882581711, Final Batch Loss: 0.038032133132219315\n",
      "Epoch 2774, Loss: 0.09719296544790268, Final Batch Loss: 0.06265898793935776\n",
      "Epoch 2775, Loss: 0.07336453348398209, Final Batch Loss: 0.04173647612333298\n",
      "Epoch 2776, Loss: 0.0657589789479971, Final Batch Loss: 0.025671547278761864\n",
      "Epoch 2777, Loss: 0.05800866149365902, Final Batch Loss: 0.027989303693175316\n",
      "Epoch 2778, Loss: 0.08075455110520124, Final Batch Loss: 0.013722511939704418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2779, Loss: 0.05974640138447285, Final Batch Loss: 0.04350493103265762\n",
      "Epoch 2780, Loss: 0.043969493359327316, Final Batch Loss: 0.023617863655090332\n",
      "Epoch 2781, Loss: 0.03580689989030361, Final Batch Loss: 0.018040010705590248\n",
      "Epoch 2782, Loss: 0.056192802265286446, Final Batch Loss: 0.033179283142089844\n",
      "Epoch 2783, Loss: 0.033229460939764977, Final Batch Loss: 0.014815503731369972\n",
      "Epoch 2784, Loss: 0.018357672728598118, Final Batch Loss: 0.009435079991817474\n",
      "Epoch 2785, Loss: 0.05900890938937664, Final Batch Loss: 0.015758788213133812\n",
      "Epoch 2786, Loss: 0.05929353088140488, Final Batch Loss: 0.037128157913684845\n",
      "Epoch 2787, Loss: 0.08729067072272301, Final Batch Loss: 0.027417264878749847\n",
      "Epoch 2788, Loss: 0.049374522641301155, Final Batch Loss: 0.022736746817827225\n",
      "Epoch 2789, Loss: 0.03867062460631132, Final Batch Loss: 0.013807720504701138\n",
      "Epoch 2790, Loss: 0.10996654443442822, Final Batch Loss: 0.02018074505031109\n",
      "Epoch 2791, Loss: 0.06985942833125591, Final Batch Loss: 0.016471752896904945\n",
      "Epoch 2792, Loss: 0.03911209851503372, Final Batch Loss: 0.018038228154182434\n",
      "Epoch 2793, Loss: 0.09602917730808258, Final Batch Loss: 0.04451761394739151\n",
      "Epoch 2794, Loss: 0.05005316808819771, Final Batch Loss: 0.023040616884827614\n",
      "Epoch 2795, Loss: 0.025011680088937283, Final Batch Loss: 0.01083807460963726\n",
      "Epoch 2796, Loss: 0.041594513691961765, Final Batch Loss: 0.01377770397812128\n",
      "Epoch 2797, Loss: 0.039943838492035866, Final Batch Loss: 0.030157994478940964\n",
      "Epoch 2798, Loss: 0.08765872195363045, Final Batch Loss: 0.05113862827420235\n",
      "Epoch 2799, Loss: 0.06214428134262562, Final Batch Loss: 0.04432898387312889\n",
      "Epoch 2800, Loss: 0.0493705365806818, Final Batch Loss: 0.024426504969596863\n",
      "Epoch 2801, Loss: 0.09392331913113594, Final Batch Loss: 0.04052773118019104\n",
      "Epoch 2802, Loss: 0.16489608958363533, Final Batch Loss: 0.05168091878294945\n",
      "Epoch 2803, Loss: 0.048322686925530434, Final Batch Loss: 0.027673589065670967\n",
      "Epoch 2804, Loss: 0.08571824431419373, Final Batch Loss: 0.041229989379644394\n",
      "Epoch 2805, Loss: 0.045244934037327766, Final Batch Loss: 0.026491355150938034\n",
      "Epoch 2806, Loss: 0.06745345145463943, Final Batch Loss: 0.04428008943796158\n",
      "Epoch 2807, Loss: 0.03438636939972639, Final Batch Loss: 0.008614004589617252\n",
      "Epoch 2808, Loss: 0.05177326127886772, Final Batch Loss: 0.023261431604623795\n",
      "Epoch 2809, Loss: 0.1309036947786808, Final Batch Loss: 0.08798912912607193\n",
      "Epoch 2810, Loss: 0.05226122587919235, Final Batch Loss: 0.018024764955043793\n",
      "Epoch 2811, Loss: 0.054264819249510765, Final Batch Loss: 0.019934365525841713\n",
      "Epoch 2812, Loss: 0.060004244558513165, Final Batch Loss: 0.008939920924603939\n",
      "Epoch 2813, Loss: 0.06588678061962128, Final Batch Loss: 0.02856055647134781\n",
      "Epoch 2814, Loss: 0.0509198484942317, Final Batch Loss: 0.03752724826335907\n",
      "Epoch 2815, Loss: 0.034612467512488365, Final Batch Loss: 0.015908043831586838\n",
      "Epoch 2816, Loss: 0.09818269312381744, Final Batch Loss: 0.04637628048658371\n",
      "Epoch 2817, Loss: 0.12861069664359093, Final Batch Loss: 0.11103206127882004\n",
      "Epoch 2818, Loss: 0.07277451828122139, Final Batch Loss: 0.028316069394350052\n",
      "Epoch 2819, Loss: 0.025655018631368876, Final Batch Loss: 0.0077908639796078205\n",
      "Epoch 2820, Loss: 0.06932418420910835, Final Batch Loss: 0.047934066504240036\n",
      "Epoch 2821, Loss: 0.12875047326087952, Final Batch Loss: 0.04763316363096237\n",
      "Epoch 2822, Loss: 0.06827788427472115, Final Batch Loss: 0.016795620322227478\n",
      "Epoch 2823, Loss: 0.07174466922879219, Final Batch Loss: 0.054670847952365875\n",
      "Epoch 2824, Loss: 0.02959228865802288, Final Batch Loss: 0.01435722503811121\n",
      "Epoch 2825, Loss: 0.08801206201314926, Final Batch Loss: 0.05327756702899933\n",
      "Epoch 2826, Loss: 0.05552619509398937, Final Batch Loss: 0.02778598852455616\n",
      "Epoch 2827, Loss: 0.06880120187997818, Final Batch Loss: 0.028211813420057297\n",
      "Epoch 2828, Loss: 0.0963861458003521, Final Batch Loss: 0.06894835829734802\n",
      "Epoch 2829, Loss: 0.05646462179720402, Final Batch Loss: 0.02920280583202839\n",
      "Epoch 2830, Loss: 0.12204313278198242, Final Batch Loss: 0.06191759184002876\n",
      "Epoch 2831, Loss: 0.07983266189694405, Final Batch Loss: 0.03267478570342064\n",
      "Epoch 2832, Loss: 0.05384648684412241, Final Batch Loss: 0.015194249339401722\n",
      "Epoch 2833, Loss: 0.05117095820605755, Final Batch Loss: 0.016254013404250145\n",
      "Epoch 2834, Loss: 0.12227077782154083, Final Batch Loss: 0.06783982366323471\n",
      "Epoch 2835, Loss: 0.0856863223016262, Final Batch Loss: 0.04289504885673523\n",
      "Epoch 2836, Loss: 0.08180077373981476, Final Batch Loss: 0.032662536948919296\n",
      "Epoch 2837, Loss: 0.06528843380510807, Final Batch Loss: 0.04547766223549843\n",
      "Epoch 2838, Loss: 0.06568494811654091, Final Batch Loss: 0.044352419674396515\n",
      "Epoch 2839, Loss: 0.09708274155855179, Final Batch Loss: 0.040874894708395004\n",
      "Epoch 2840, Loss: 0.07248270697891712, Final Batch Loss: 0.04235582426190376\n",
      "Epoch 2841, Loss: 0.07859768159687519, Final Batch Loss: 0.020953966304659843\n",
      "Epoch 2842, Loss: 0.074460718780756, Final Batch Loss: 0.05074857920408249\n",
      "Epoch 2843, Loss: 0.12002513185143471, Final Batch Loss: 0.03995324298739433\n",
      "Epoch 2844, Loss: 0.10208817385137081, Final Batch Loss: 0.02106442116200924\n",
      "Epoch 2845, Loss: 0.06287385895848274, Final Batch Loss: 0.04032450169324875\n",
      "Epoch 2846, Loss: 0.06830767169594765, Final Batch Loss: 0.031398214399814606\n",
      "Epoch 2847, Loss: 0.0977480337023735, Final Batch Loss: 0.059842199087142944\n",
      "Epoch 2848, Loss: 0.07647805288434029, Final Batch Loss: 0.02948153391480446\n",
      "Epoch 2849, Loss: 0.05606583505868912, Final Batch Loss: 0.03591529652476311\n",
      "Epoch 2850, Loss: 0.09532048180699348, Final Batch Loss: 0.07807271927595139\n",
      "Epoch 2851, Loss: 0.05869442597031593, Final Batch Loss: 0.02341955155134201\n",
      "Epoch 2852, Loss: 0.07330676913261414, Final Batch Loss: 0.046926070004701614\n",
      "Epoch 2853, Loss: 0.11808072403073311, Final Batch Loss: 0.07764793932437897\n",
      "Epoch 2854, Loss: 0.07633225247263908, Final Batch Loss: 0.03358328714966774\n",
      "Epoch 2855, Loss: 0.07345646992325783, Final Batch Loss: 0.0351191870868206\n",
      "Epoch 2856, Loss: 0.05477483570575714, Final Batch Loss: 0.017504792660474777\n",
      "Epoch 2857, Loss: 0.054631391540169716, Final Batch Loss: 0.03826117515563965\n",
      "Epoch 2858, Loss: 0.039518533274531364, Final Batch Loss: 0.01821093261241913\n",
      "Epoch 2859, Loss: 0.05586370825767517, Final Batch Loss: 0.02433450147509575\n",
      "Epoch 2860, Loss: 0.0451999194920063, Final Batch Loss: 0.017491178587079048\n",
      "Epoch 2861, Loss: 0.03503435477614403, Final Batch Loss: 0.019343197345733643\n",
      "Epoch 2862, Loss: 0.06160046346485615, Final Batch Loss: 0.013840613886713982\n",
      "Epoch 2863, Loss: 0.040835280902683735, Final Batch Loss: 0.012531016953289509\n",
      "Epoch 2864, Loss: 0.06579727679491043, Final Batch Loss: 0.024355195462703705\n",
      "Epoch 2865, Loss: 0.051367517560720444, Final Batch Loss: 0.022829264402389526\n",
      "Epoch 2866, Loss: 0.050488291308283806, Final Batch Loss: 0.02063526026904583\n",
      "Epoch 2867, Loss: 0.043686393648386, Final Batch Loss: 0.021590707823634148\n",
      "Epoch 2868, Loss: 0.06983765959739685, Final Batch Loss: 0.033318258821964264\n",
      "Epoch 2869, Loss: 0.06276991590857506, Final Batch Loss: 0.01674928516149521\n",
      "Epoch 2870, Loss: 0.06159777566790581, Final Batch Loss: 0.018632277846336365\n",
      "Epoch 2871, Loss: 0.041351896710693836, Final Batch Loss: 0.027399592101573944\n",
      "Epoch 2872, Loss: 0.039437174797058105, Final Batch Loss: 0.02886529453098774\n",
      "Epoch 2873, Loss: 0.06189923174679279, Final Batch Loss: 0.04146196320652962\n",
      "Epoch 2874, Loss: 0.09136111289262772, Final Batch Loss: 0.05351782962679863\n",
      "Epoch 2875, Loss: 0.04218322038650513, Final Batch Loss: 0.024420781061053276\n",
      "Epoch 2876, Loss: 0.07450915314257145, Final Batch Loss: 0.029056111350655556\n",
      "Epoch 2877, Loss: 0.062143053859472275, Final Batch Loss: 0.028318580240011215\n",
      "Epoch 2878, Loss: 0.10413824021816254, Final Batch Loss: 0.05750231072306633\n",
      "Epoch 2879, Loss: 0.08372176252305508, Final Batch Loss: 0.05704342573881149\n",
      "Epoch 2880, Loss: 0.08056746050715446, Final Batch Loss: 0.01199386641383171\n",
      "Epoch 2881, Loss: 0.10027449578046799, Final Batch Loss: 0.049234434962272644\n",
      "Epoch 2882, Loss: 0.06590421311557293, Final Batch Loss: 0.052800025790929794\n",
      "Epoch 2883, Loss: 0.03930852189660072, Final Batch Loss: 0.01952933706343174\n",
      "Epoch 2884, Loss: 0.06449159048497677, Final Batch Loss: 0.015559060499072075\n",
      "Epoch 2885, Loss: 0.0702263256534934, Final Batch Loss: 0.015478658489882946\n",
      "Epoch 2886, Loss: 0.056707751005887985, Final Batch Loss: 0.023065045475959778\n",
      "Epoch 2887, Loss: 0.08084098994731903, Final Batch Loss: 0.05333615466952324\n",
      "Epoch 2888, Loss: 0.12381227314472198, Final Batch Loss: 0.07940253615379333\n",
      "Epoch 2889, Loss: 0.030242977663874626, Final Batch Loss: 0.019249487668275833\n",
      "Epoch 2890, Loss: 0.08003192394971848, Final Batch Loss: 0.02719494327902794\n",
      "Epoch 2891, Loss: 0.08447832986712456, Final Batch Loss: 0.07169482856988907\n",
      "Epoch 2892, Loss: 0.04219628777354956, Final Batch Loss: 0.010290584526956081\n",
      "Epoch 2893, Loss: 0.026240131817758083, Final Batch Loss: 0.00707764457911253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2894, Loss: 0.06451260298490524, Final Batch Loss: 0.018666692078113556\n",
      "Epoch 2895, Loss: 0.04153819289058447, Final Batch Loss: 0.01520079467445612\n",
      "Epoch 2896, Loss: 0.05665101483464241, Final Batch Loss: 0.03016260638833046\n",
      "Epoch 2897, Loss: 0.08207209408283234, Final Batch Loss: 0.03421927988529205\n",
      "Epoch 2898, Loss: 0.06999977305531502, Final Batch Loss: 0.04461517930030823\n",
      "Epoch 2899, Loss: 0.04772127978503704, Final Batch Loss: 0.021198080852627754\n",
      "Epoch 2900, Loss: 0.07735026441514492, Final Batch Loss: 0.04697006195783615\n",
      "Epoch 2901, Loss: 0.04980474337935448, Final Batch Loss: 0.01621527597308159\n",
      "Epoch 2902, Loss: 0.08763548359274864, Final Batch Loss: 0.0594974048435688\n",
      "Epoch 2903, Loss: 0.06349469535052776, Final Batch Loss: 0.04923129826784134\n",
      "Epoch 2904, Loss: 0.11276548728346825, Final Batch Loss: 0.06265895813703537\n",
      "Epoch 2905, Loss: 0.06013050675392151, Final Batch Loss: 0.03403770178556442\n",
      "Epoch 2906, Loss: 0.05374433100223541, Final Batch Loss: 0.03455823287367821\n",
      "Epoch 2907, Loss: 0.04795916844159365, Final Batch Loss: 0.015000388957560062\n",
      "Epoch 2908, Loss: 0.09241651371121407, Final Batch Loss: 0.03261258825659752\n",
      "Epoch 2909, Loss: 0.09329067170619965, Final Batch Loss: 0.06163272261619568\n",
      "Epoch 2910, Loss: 0.1163470409810543, Final Batch Loss: 0.06560264527797699\n",
      "Epoch 2911, Loss: 0.11002524197101593, Final Batch Loss: 0.060299523174762726\n",
      "Epoch 2912, Loss: 0.04885272681713104, Final Batch Loss: 0.014435332268476486\n",
      "Epoch 2913, Loss: 0.0584320742636919, Final Batch Loss: 0.028973456472158432\n",
      "Epoch 2914, Loss: 0.0714865680783987, Final Batch Loss: 0.04262026771903038\n",
      "Epoch 2915, Loss: 0.05032844003289938, Final Batch Loss: 0.012004519812762737\n",
      "Epoch 2916, Loss: 0.07899322733283043, Final Batch Loss: 0.05644073709845543\n",
      "Epoch 2917, Loss: 0.04194168001413345, Final Batch Loss: 0.021991576999425888\n",
      "Epoch 2918, Loss: 0.05693471617996693, Final Batch Loss: 0.026346510276198387\n",
      "Epoch 2919, Loss: 0.05283170938491821, Final Batch Loss: 0.028964532539248466\n",
      "Epoch 2920, Loss: 0.05587777774780989, Final Batch Loss: 0.04062408581376076\n",
      "Epoch 2921, Loss: 0.07243094779551029, Final Batch Loss: 0.030917959287762642\n",
      "Epoch 2922, Loss: 0.044425494968891144, Final Batch Loss: 0.028043217957019806\n",
      "Epoch 2923, Loss: 0.0921591967344284, Final Batch Loss: 0.05940522998571396\n",
      "Epoch 2924, Loss: 0.06453461293131113, Final Batch Loss: 0.05325320363044739\n",
      "Epoch 2925, Loss: 0.04873115383088589, Final Batch Loss: 0.01821829378604889\n",
      "Epoch 2926, Loss: 0.03698839247226715, Final Batch Loss: 0.021495399996638298\n",
      "Epoch 2927, Loss: 0.060906123369932175, Final Batch Loss: 0.027862995862960815\n",
      "Epoch 2928, Loss: 0.07412478979676962, Final Batch Loss: 0.06277809292078018\n",
      "Epoch 2929, Loss: 0.053293073549866676, Final Batch Loss: 0.029750486835837364\n",
      "Epoch 2930, Loss: 0.07206548377871513, Final Batch Loss: 0.0405469574034214\n",
      "Epoch 2931, Loss: 0.043054066598415375, Final Batch Loss: 0.023952307179570198\n",
      "Epoch 2932, Loss: 0.06738319993019104, Final Batch Loss: 0.03926127776503563\n",
      "Epoch 2933, Loss: 0.03510128706693649, Final Batch Loss: 0.014408214017748833\n",
      "Epoch 2934, Loss: 0.037328590638935566, Final Batch Loss: 0.014883910305798054\n",
      "Epoch 2935, Loss: 0.09969364479184151, Final Batch Loss: 0.06076193228363991\n",
      "Epoch 2936, Loss: 0.04770665057003498, Final Batch Loss: 0.027313122525811195\n",
      "Epoch 2937, Loss: 0.09267939068377018, Final Batch Loss: 0.06844262033700943\n",
      "Epoch 2938, Loss: 0.08494448661804199, Final Batch Loss: 0.06301862001419067\n",
      "Epoch 2939, Loss: 0.08102216850966215, Final Batch Loss: 0.01374525111168623\n",
      "Epoch 2940, Loss: 0.09428758174180984, Final Batch Loss: 0.060172975063323975\n",
      "Epoch 2941, Loss: 0.04843680467456579, Final Batch Loss: 0.012632845900952816\n",
      "Epoch 2942, Loss: 0.05599100515246391, Final Batch Loss: 0.020304836332798004\n",
      "Epoch 2943, Loss: 0.03923535021021962, Final Batch Loss: 0.03167460486292839\n",
      "Epoch 2944, Loss: 0.05610794387757778, Final Batch Loss: 0.025750460103154182\n",
      "Epoch 2945, Loss: 0.10165209323167801, Final Batch Loss: 0.03715997189283371\n",
      "Epoch 2946, Loss: 0.05818740651011467, Final Batch Loss: 0.035082098096609116\n",
      "Epoch 2947, Loss: 0.04602179303765297, Final Batch Loss: 0.027438435703516006\n",
      "Epoch 2948, Loss: 0.0895199254155159, Final Batch Loss: 0.03429220989346504\n",
      "Epoch 2949, Loss: 0.07488090172410011, Final Batch Loss: 0.04219633340835571\n",
      "Epoch 2950, Loss: 0.0712326280772686, Final Batch Loss: 0.036733049899339676\n",
      "Epoch 2951, Loss: 0.0474898386746645, Final Batch Loss: 0.018798260018229485\n",
      "Epoch 2952, Loss: 0.07037975266575813, Final Batch Loss: 0.03939518332481384\n",
      "Epoch 2953, Loss: 0.04216439835727215, Final Batch Loss: 0.026136882603168488\n",
      "Epoch 2954, Loss: 0.07736381143331528, Final Batch Loss: 0.04216741770505905\n",
      "Epoch 2955, Loss: 0.03964782878756523, Final Batch Loss: 0.023627249523997307\n",
      "Epoch 2956, Loss: 0.04885106906294823, Final Batch Loss: 0.019359856843948364\n",
      "Epoch 2957, Loss: 0.0528845377266407, Final Batch Loss: 0.029297124594449997\n",
      "Epoch 2958, Loss: 0.04946667328476906, Final Batch Loss: 0.015282947570085526\n",
      "Epoch 2959, Loss: 0.07288574054837227, Final Batch Loss: 0.04540099576115608\n",
      "Epoch 2960, Loss: 0.0597113948315382, Final Batch Loss: 0.01756538264453411\n",
      "Epoch 2961, Loss: 0.11022162064909935, Final Batch Loss: 0.09436773508787155\n",
      "Epoch 2962, Loss: 0.09372547827661037, Final Batch Loss: 0.02911006473004818\n",
      "Epoch 2963, Loss: 0.05595021415501833, Final Batch Loss: 0.011513439007103443\n",
      "Epoch 2964, Loss: 0.10268858447670937, Final Batch Loss: 0.06426230818033218\n",
      "Epoch 2965, Loss: 0.037404708564281464, Final Batch Loss: 0.01755978912115097\n",
      "Epoch 2966, Loss: 0.032118567265570164, Final Batch Loss: 0.017934361472725868\n",
      "Epoch 2967, Loss: 0.06727582681924105, Final Batch Loss: 0.013198559172451496\n",
      "Epoch 2968, Loss: 0.06635196879506111, Final Batch Loss: 0.048906706273555756\n",
      "Epoch 2969, Loss: 0.04683683626353741, Final Batch Loss: 0.005964947864413261\n",
      "Epoch 2970, Loss: 0.044197577983140945, Final Batch Loss: 0.020932894200086594\n",
      "Epoch 2971, Loss: 0.07176635321229696, Final Batch Loss: 0.006958081386983395\n",
      "Epoch 2972, Loss: 0.06550053134560585, Final Batch Loss: 0.03806840628385544\n",
      "Epoch 2973, Loss: 0.05745153035968542, Final Batch Loss: 0.012831530533730984\n",
      "Epoch 2974, Loss: 0.08044642489403486, Final Batch Loss: 0.011647271923720837\n",
      "Epoch 2975, Loss: 0.05959691014140844, Final Batch Loss: 0.04684114456176758\n",
      "Epoch 2976, Loss: 0.03529568389058113, Final Batch Loss: 0.019448168575763702\n",
      "Epoch 2977, Loss: 0.08216002210974693, Final Batch Loss: 0.05202869325876236\n",
      "Epoch 2978, Loss: 0.05569863133132458, Final Batch Loss: 0.018618980422616005\n",
      "Epoch 2979, Loss: 0.02772586327046156, Final Batch Loss: 0.01306096836924553\n",
      "Epoch 2980, Loss: 0.048824410885572433, Final Batch Loss: 0.031011275947093964\n",
      "Epoch 2981, Loss: 0.052034031599760056, Final Batch Loss: 0.031123466789722443\n",
      "Epoch 2982, Loss: 0.03431352507323027, Final Batch Loss: 0.014943921007215977\n",
      "Epoch 2983, Loss: 0.05041762441396713, Final Batch Loss: 0.030054235830903053\n",
      "Epoch 2984, Loss: 0.05153123289346695, Final Batch Loss: 0.012957070022821426\n",
      "Epoch 2985, Loss: 0.050769733265042305, Final Batch Loss: 0.017826514318585396\n",
      "Epoch 2986, Loss: 0.05487911216914654, Final Batch Loss: 0.024017054587602615\n",
      "Epoch 2987, Loss: 0.10328270494937897, Final Batch Loss: 0.05581997334957123\n",
      "Epoch 2988, Loss: 0.06227044202387333, Final Batch Loss: 0.02633323334157467\n",
      "Epoch 2989, Loss: 0.06475500762462616, Final Batch Loss: 0.028380021452903748\n",
      "Epoch 2990, Loss: 0.05775407515466213, Final Batch Loss: 0.007532747462391853\n",
      "Epoch 2991, Loss: 0.08399787824600935, Final Batch Loss: 0.07172969728708267\n",
      "Epoch 2992, Loss: 0.06684516184031963, Final Batch Loss: 0.02281195856630802\n",
      "Epoch 2993, Loss: 0.08338584937155247, Final Batch Loss: 0.06320412456989288\n",
      "Epoch 2994, Loss: 0.07640568353235722, Final Batch Loss: 0.05712999776005745\n",
      "Epoch 2995, Loss: 0.0590357668697834, Final Batch Loss: 0.02085477113723755\n",
      "Epoch 2996, Loss: 0.10620052367448807, Final Batch Loss: 0.06559278815984726\n",
      "Epoch 2997, Loss: 0.09944100491702557, Final Batch Loss: 0.03011438064277172\n",
      "Epoch 2998, Loss: 0.05387410148978233, Final Batch Loss: 0.021522101014852524\n",
      "Epoch 2999, Loss: 0.03249015100300312, Final Batch Loss: 0.01144067756831646\n",
      "Epoch 3000, Loss: 0.06455009803175926, Final Batch Loss: 0.01797506958246231\n",
      "Epoch 3001, Loss: 0.0725688636302948, Final Batch Loss: 0.031418703496456146\n",
      "Epoch 3002, Loss: 0.09811782091856003, Final Batch Loss: 0.05725177377462387\n",
      "Epoch 3003, Loss: 0.0716848373413086, Final Batch Loss: 0.03486110270023346\n",
      "Epoch 3004, Loss: 0.047426242381334305, Final Batch Loss: 0.029661081731319427\n",
      "Epoch 3005, Loss: 0.03833794593811035, Final Batch Loss: 0.01957602985203266\n",
      "Epoch 3006, Loss: 0.04352319799363613, Final Batch Loss: 0.019249489530920982\n",
      "Epoch 3007, Loss: 0.06794414669275284, Final Batch Loss: 0.026029769331216812\n",
      "Epoch 3008, Loss: 0.14281041640788317, Final Batch Loss: 0.13145694136619568\n",
      "Epoch 3009, Loss: 0.08216628152877092, Final Batch Loss: 0.06884802877902985\n",
      "Epoch 3010, Loss: 0.06711901910603046, Final Batch Loss: 0.04392394423484802\n",
      "Epoch 3011, Loss: 0.11284980922937393, Final Batch Loss: 0.05658546835184097\n",
      "Epoch 3012, Loss: 0.11878080293536186, Final Batch Loss: 0.030087117105722427\n",
      "Epoch 3013, Loss: 0.11708194389939308, Final Batch Loss: 0.03936491534113884\n",
      "Epoch 3014, Loss: 0.04434639774262905, Final Batch Loss: 0.021436650305986404\n",
      "Epoch 3015, Loss: 0.06415199674665928, Final Batch Loss: 0.031110180541872978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3016, Loss: 0.06623122841119766, Final Batch Loss: 0.04885884001851082\n",
      "Epoch 3017, Loss: 0.08811116218566895, Final Batch Loss: 0.030952483415603638\n",
      "Epoch 3018, Loss: 0.05663002375513315, Final Batch Loss: 0.04413500428199768\n",
      "Epoch 3019, Loss: 0.07882453501224518, Final Batch Loss: 0.05169834569096565\n",
      "Epoch 3020, Loss: 0.10475094988942146, Final Batch Loss: 0.05342195928096771\n",
      "Epoch 3021, Loss: 0.08030981570482254, Final Batch Loss: 0.042375218123197556\n",
      "Epoch 3022, Loss: 0.04472077824175358, Final Batch Loss: 0.028827151283621788\n",
      "Epoch 3023, Loss: 0.08570355921983719, Final Batch Loss: 0.017163880169391632\n",
      "Epoch 3024, Loss: 0.11700845137238503, Final Batch Loss: 0.045038554817438126\n",
      "Epoch 3025, Loss: 0.056120963767170906, Final Batch Loss: 0.02126373164355755\n",
      "Epoch 3026, Loss: 0.06383310630917549, Final Batch Loss: 0.03357884660363197\n",
      "Epoch 3027, Loss: 0.09113050624728203, Final Batch Loss: 0.04528583213686943\n",
      "Epoch 3028, Loss: 0.10015645250678062, Final Batch Loss: 0.05265730991959572\n",
      "Epoch 3029, Loss: 0.12599473632872105, Final Batch Loss: 0.09576239436864853\n",
      "Epoch 3030, Loss: 0.07566524855792522, Final Batch Loss: 0.0220137070864439\n",
      "Epoch 3031, Loss: 0.102131437510252, Final Batch Loss: 0.08156713843345642\n",
      "Epoch 3032, Loss: 0.060819754377007484, Final Batch Loss: 0.03160335496068001\n",
      "Epoch 3033, Loss: 0.08570046164095402, Final Batch Loss: 0.06137332320213318\n",
      "Epoch 3034, Loss: 0.08403097465634346, Final Batch Loss: 0.04310676455497742\n",
      "Epoch 3035, Loss: 0.11101565882563591, Final Batch Loss: 0.06336391717195511\n",
      "Epoch 3036, Loss: 0.10481773037463427, Final Batch Loss: 0.09271400421857834\n",
      "Epoch 3037, Loss: 0.08254057355225086, Final Batch Loss: 0.05428064242005348\n",
      "Epoch 3038, Loss: 0.094361063092947, Final Batch Loss: 0.047093454748392105\n",
      "Epoch 3039, Loss: 0.05772705376148224, Final Batch Loss: 0.0315094031393528\n",
      "Epoch 3040, Loss: 0.09724204987287521, Final Batch Loss: 0.054637838155031204\n",
      "Epoch 3041, Loss: 0.06838103383779526, Final Batch Loss: 0.03576391190290451\n",
      "Epoch 3042, Loss: 0.07496798783540726, Final Batch Loss: 0.01823064684867859\n",
      "Epoch 3043, Loss: 0.08261323347687721, Final Batch Loss: 0.0316789411008358\n",
      "Epoch 3044, Loss: 0.10180041193962097, Final Batch Loss: 0.0698990523815155\n",
      "Epoch 3045, Loss: 0.0527022834867239, Final Batch Loss: 0.02349413000047207\n",
      "Epoch 3046, Loss: 0.09438995644450188, Final Batch Loss: 0.031984321773052216\n",
      "Epoch 3047, Loss: 0.096330925822258, Final Batch Loss: 0.0620114728808403\n",
      "Epoch 3048, Loss: 0.041126894764602184, Final Batch Loss: 0.015537605620920658\n",
      "Epoch 3049, Loss: 0.04526577051728964, Final Batch Loss: 0.006883098743855953\n",
      "Epoch 3050, Loss: 0.07266189903020859, Final Batch Loss: 0.05424298346042633\n",
      "Epoch 3051, Loss: 0.041703181341290474, Final Batch Loss: 0.012163285166025162\n",
      "Epoch 3052, Loss: 0.047493595629930496, Final Batch Loss: 0.021908890455961227\n",
      "Epoch 3053, Loss: 0.0463846530765295, Final Batch Loss: 0.017480354756116867\n",
      "Epoch 3054, Loss: 0.06477035768330097, Final Batch Loss: 0.050016142427921295\n",
      "Epoch 3055, Loss: 0.05264856666326523, Final Batch Loss: 0.012704439461231232\n",
      "Epoch 3056, Loss: 0.026678902097046375, Final Batch Loss: 0.012592470273375511\n",
      "Epoch 3057, Loss: 0.06250072456896305, Final Batch Loss: 0.02553931437432766\n",
      "Epoch 3058, Loss: 0.1113971471786499, Final Batch Loss: 0.046986185014247894\n",
      "Epoch 3059, Loss: 0.03069137129932642, Final Batch Loss: 0.017835894599556923\n",
      "Epoch 3060, Loss: 0.024894670583307743, Final Batch Loss: 0.010085231624543667\n",
      "Epoch 3061, Loss: 0.037470011971890926, Final Batch Loss: 0.02685481868684292\n",
      "Epoch 3062, Loss: 0.10833780840039253, Final Batch Loss: 0.0853416845202446\n",
      "Epoch 3063, Loss: 0.05589548870921135, Final Batch Loss: 0.03167795017361641\n",
      "Epoch 3064, Loss: 0.07132447138428688, Final Batch Loss: 0.05896981433033943\n",
      "Epoch 3065, Loss: 0.04785289242863655, Final Batch Loss: 0.013598352670669556\n",
      "Epoch 3066, Loss: 0.08159130811691284, Final Batch Loss: 0.03467632457613945\n",
      "Epoch 3067, Loss: 0.03993724565953016, Final Batch Loss: 0.015056627802550793\n",
      "Epoch 3068, Loss: 0.0451164934784174, Final Batch Loss: 0.031331948935985565\n",
      "Epoch 3069, Loss: 0.044933220371603966, Final Batch Loss: 0.016185980290174484\n",
      "Epoch 3070, Loss: 0.0657178983092308, Final Batch Loss: 0.018644511699676514\n",
      "Epoch 3071, Loss: 0.061820195987820625, Final Batch Loss: 0.03647596389055252\n",
      "Epoch 3072, Loss: 0.05202487297356129, Final Batch Loss: 0.023820802569389343\n",
      "Epoch 3073, Loss: 0.09403063729405403, Final Batch Loss: 0.03715434670448303\n",
      "Epoch 3074, Loss: 0.04656385816633701, Final Batch Loss: 0.021098127588629723\n",
      "Epoch 3075, Loss: 0.02106468938291073, Final Batch Loss: 0.011100099422037601\n",
      "Epoch 3076, Loss: 0.08428941294550896, Final Batch Loss: 0.02312673255801201\n",
      "Epoch 3077, Loss: 0.09779433161020279, Final Batch Loss: 0.05946463719010353\n",
      "Epoch 3078, Loss: 0.05330207385122776, Final Batch Loss: 0.020172378048300743\n",
      "Epoch 3079, Loss: 0.04913102835416794, Final Batch Loss: 0.029968641698360443\n",
      "Epoch 3080, Loss: 0.046470243483781815, Final Batch Loss: 0.009298935532569885\n",
      "Epoch 3081, Loss: 0.06561275944113731, Final Batch Loss: 0.026201441884040833\n",
      "Epoch 3082, Loss: 0.09479549527168274, Final Batch Loss: 0.03475876525044441\n",
      "Epoch 3083, Loss: 0.04613730311393738, Final Batch Loss: 0.017832076177001\n",
      "Epoch 3084, Loss: 0.04279721388593316, Final Batch Loss: 0.007708071265369654\n",
      "Epoch 3085, Loss: 0.10929341614246368, Final Batch Loss: 0.06428349763154984\n",
      "Epoch 3086, Loss: 0.07361747696995735, Final Batch Loss: 0.037188801914453506\n",
      "Epoch 3087, Loss: 0.03945310413837433, Final Batch Loss: 0.017081504687666893\n",
      "Epoch 3088, Loss: 0.06951463222503662, Final Batch Loss: 0.020053233951330185\n",
      "Epoch 3089, Loss: 0.06516607664525509, Final Batch Loss: 0.039263688027858734\n",
      "Epoch 3090, Loss: 0.05780330300331116, Final Batch Loss: 0.03001536801457405\n",
      "Epoch 3091, Loss: 0.12000232934951782, Final Batch Loss: 0.08833024650812149\n",
      "Epoch 3092, Loss: 0.05990021117031574, Final Batch Loss: 0.034515056759119034\n",
      "Epoch 3093, Loss: 0.08544299006462097, Final Batch Loss: 0.036893993616104126\n",
      "Epoch 3094, Loss: 0.0754716768860817, Final Batch Loss: 0.034477170556783676\n",
      "Epoch 3095, Loss: 0.04546197410672903, Final Batch Loss: 0.012345950119197369\n",
      "Epoch 3096, Loss: 0.08035615179687738, Final Batch Loss: 0.06984572857618332\n",
      "Epoch 3097, Loss: 0.03336376044899225, Final Batch Loss: 0.012030345387756824\n",
      "Epoch 3098, Loss: 0.03100665844976902, Final Batch Loss: 0.011490104719996452\n",
      "Epoch 3099, Loss: 0.06989484466612339, Final Batch Loss: 0.03884352743625641\n",
      "Epoch 3100, Loss: 0.05286227725446224, Final Batch Loss: 0.023188358172774315\n",
      "Epoch 3101, Loss: 0.09418176300823689, Final Batch Loss: 0.06786955147981644\n",
      "Epoch 3102, Loss: 0.16949985921382904, Final Batch Loss: 0.09743890166282654\n",
      "Epoch 3103, Loss: 0.06885271519422531, Final Batch Loss: 0.04247528687119484\n",
      "Epoch 3104, Loss: 0.0763055831193924, Final Batch Loss: 0.04322823882102966\n",
      "Epoch 3105, Loss: 0.06369977630674839, Final Batch Loss: 0.03632250800728798\n",
      "Epoch 3106, Loss: 0.08875828795135021, Final Batch Loss: 0.0140679981559515\n",
      "Epoch 3107, Loss: 0.09141997806727886, Final Batch Loss: 0.07668597251176834\n",
      "Epoch 3108, Loss: 0.048125048633664846, Final Batch Loss: 0.004198519047349691\n",
      "Epoch 3109, Loss: 0.04776156507432461, Final Batch Loss: 0.013933481648564339\n",
      "Epoch 3110, Loss: 0.05931811034679413, Final Batch Loss: 0.01789271831512451\n",
      "Epoch 3111, Loss: 0.054612147621810436, Final Batch Loss: 0.007598939351737499\n",
      "Epoch 3112, Loss: 0.07436240278184414, Final Batch Loss: 0.04584355652332306\n",
      "Epoch 3113, Loss: 0.08087393455207348, Final Batch Loss: 0.022077465429902077\n",
      "Epoch 3114, Loss: 0.0859153475612402, Final Batch Loss: 0.030554989352822304\n",
      "Epoch 3115, Loss: 0.07855799607932568, Final Batch Loss: 0.030283117666840553\n",
      "Epoch 3116, Loss: 0.05397609807550907, Final Batch Loss: 0.01517699845135212\n",
      "Epoch 3117, Loss: 0.071097856387496, Final Batch Loss: 0.017475878819823265\n",
      "Epoch 3118, Loss: 0.027437550947070122, Final Batch Loss: 0.011311529204249382\n",
      "Epoch 3119, Loss: 0.08131019584834576, Final Batch Loss: 0.02983136661350727\n",
      "Epoch 3120, Loss: 0.06717859581112862, Final Batch Loss: 0.026252448558807373\n",
      "Epoch 3121, Loss: 0.06459910422563553, Final Batch Loss: 0.025467775762081146\n",
      "Epoch 3122, Loss: 0.08218752220273018, Final Batch Loss: 0.039421871304512024\n",
      "Epoch 3123, Loss: 0.07584751024842262, Final Batch Loss: 0.01597721129655838\n",
      "Epoch 3124, Loss: 0.04553081654012203, Final Batch Loss: 0.025254352018237114\n",
      "Epoch 3125, Loss: 0.09998972341418266, Final Batch Loss: 0.057501502335071564\n",
      "Epoch 3126, Loss: 0.04942091275006533, Final Batch Loss: 0.03392637521028519\n",
      "Epoch 3127, Loss: 0.09974260069429874, Final Batch Loss: 0.07746423035860062\n",
      "Epoch 3128, Loss: 0.039071954786777496, Final Batch Loss: 0.015712639316916466\n",
      "Epoch 3129, Loss: 0.056746406480669975, Final Batch Loss: 0.041881635785102844\n",
      "Epoch 3130, Loss: 0.029212885536253452, Final Batch Loss: 0.014510751701891422\n",
      "Epoch 3131, Loss: 0.050981054082512856, Final Batch Loss: 0.034293875098228455\n",
      "Epoch 3132, Loss: 0.08844902738928795, Final Batch Loss: 0.0370597206056118\n",
      "Epoch 3133, Loss: 0.03636162541806698, Final Batch Loss: 0.012684065848588943\n",
      "Epoch 3134, Loss: 0.105682123452425, Final Batch Loss: 0.059466127306222916\n",
      "Epoch 3135, Loss: 0.07147900573909283, Final Batch Loss: 0.015347307547926903\n",
      "Epoch 3136, Loss: 0.08226195350289345, Final Batch Loss: 0.053281355649232864\n",
      "Epoch 3137, Loss: 0.08433679863810539, Final Batch Loss: 0.040013495832681656\n",
      "Epoch 3138, Loss: 0.038608063012361526, Final Batch Loss: 0.020629048347473145\n",
      "Epoch 3139, Loss: 0.08002868667244911, Final Batch Loss: 0.03679202124476433\n",
      "Epoch 3140, Loss: 0.06614386662840843, Final Batch Loss: 0.029166191816329956\n",
      "Epoch 3141, Loss: 0.05466275289654732, Final Batch Loss: 0.03198418766260147\n",
      "Epoch 3142, Loss: 0.08583039417862892, Final Batch Loss: 0.03649052977561951\n",
      "Epoch 3143, Loss: 0.0723040122538805, Final Batch Loss: 0.047561515122652054\n",
      "Epoch 3144, Loss: 0.06638943776488304, Final Batch Loss: 0.038092199712991714\n",
      "Epoch 3145, Loss: 0.07957114651799202, Final Batch Loss: 0.057626932859420776\n",
      "Epoch 3146, Loss: 0.04509638622403145, Final Batch Loss: 0.01653374172747135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3147, Loss: 0.06924241222441196, Final Batch Loss: 0.04051092639565468\n",
      "Epoch 3148, Loss: 0.04715992137789726, Final Batch Loss: 0.020393624901771545\n",
      "Epoch 3149, Loss: 0.03651384450495243, Final Batch Loss: 0.019958114251494408\n",
      "Epoch 3150, Loss: 0.05396968312561512, Final Batch Loss: 0.021250372752547264\n",
      "Epoch 3151, Loss: 0.03254256024956703, Final Batch Loss: 0.012587344273924828\n",
      "Epoch 3152, Loss: 0.09157290309667587, Final Batch Loss: 0.042846664786338806\n",
      "Epoch 3153, Loss: 0.12317102216184139, Final Batch Loss: 0.029570920392870903\n",
      "Epoch 3154, Loss: 0.07507245615124702, Final Batch Loss: 0.023110195994377136\n",
      "Epoch 3155, Loss: 0.10826023854315281, Final Batch Loss: 0.08288921415805817\n",
      "Epoch 3156, Loss: 0.061476098373532295, Final Batch Loss: 0.01635727845132351\n",
      "Epoch 3157, Loss: 0.04576605185866356, Final Batch Loss: 0.02630920708179474\n",
      "Epoch 3158, Loss: 0.07582699321210384, Final Batch Loss: 0.05568326637148857\n",
      "Epoch 3159, Loss: 0.04969152621924877, Final Batch Loss: 0.022519130259752274\n",
      "Epoch 3160, Loss: 0.09223372861742973, Final Batch Loss: 0.039554182440042496\n",
      "Epoch 3161, Loss: 0.06667271442711353, Final Batch Loss: 0.04695253446698189\n",
      "Epoch 3162, Loss: 0.07753914594650269, Final Batch Loss: 0.04461095854640007\n",
      "Epoch 3163, Loss: 0.04676314443349838, Final Batch Loss: 0.03353596478700638\n",
      "Epoch 3164, Loss: 0.0311732841655612, Final Batch Loss: 0.012898317538201809\n",
      "Epoch 3165, Loss: 0.0704499464482069, Final Batch Loss: 0.025850391015410423\n",
      "Epoch 3166, Loss: 0.08906645700335503, Final Batch Loss: 0.04054754972457886\n",
      "Epoch 3167, Loss: 0.050585406832396984, Final Batch Loss: 0.009550820104777813\n",
      "Epoch 3168, Loss: 0.06764762848615646, Final Batch Loss: 0.0464085191488266\n",
      "Epoch 3169, Loss: 0.09086501598358154, Final Batch Loss: 0.07482989132404327\n",
      "Epoch 3170, Loss: 0.062226055189967155, Final Batch Loss: 0.027881959453225136\n",
      "Epoch 3171, Loss: 0.060495899990200996, Final Batch Loss: 0.020334864035248756\n",
      "Epoch 3172, Loss: 0.045327529311180115, Final Batch Loss: 0.023469796404242516\n",
      "Epoch 3173, Loss: 0.03249084763228893, Final Batch Loss: 0.011978013440966606\n",
      "Epoch 3174, Loss: 0.05071045085787773, Final Batch Loss: 0.026166308671236038\n",
      "Epoch 3175, Loss: 0.027065850794315338, Final Batch Loss: 0.013875458389520645\n",
      "Epoch 3176, Loss: 0.03330832812935114, Final Batch Loss: 0.011845470406115055\n",
      "Epoch 3177, Loss: 0.053271010518074036, Final Batch Loss: 0.01649383455514908\n",
      "Epoch 3178, Loss: 0.04742507264018059, Final Batch Loss: 0.01842407137155533\n",
      "Epoch 3179, Loss: 0.08312280848622322, Final Batch Loss: 0.04021896794438362\n",
      "Epoch 3180, Loss: 0.03248509578406811, Final Batch Loss: 0.008345305919647217\n",
      "Epoch 3181, Loss: 0.06598402746021748, Final Batch Loss: 0.04919196292757988\n",
      "Epoch 3182, Loss: 0.04875572770833969, Final Batch Loss: 0.0307586882263422\n",
      "Epoch 3183, Loss: 0.03931709472090006, Final Batch Loss: 0.011839578859508038\n",
      "Epoch 3184, Loss: 0.04034853633493185, Final Batch Loss: 0.014260872267186642\n",
      "Epoch 3185, Loss: 0.034355128183960915, Final Batch Loss: 0.025498010218143463\n",
      "Epoch 3186, Loss: 0.08401797339320183, Final Batch Loss: 0.048147037625312805\n",
      "Epoch 3187, Loss: 0.047912842594087124, Final Batch Loss: 0.03591451048851013\n",
      "Epoch 3188, Loss: 0.05835104547441006, Final Batch Loss: 0.023008203133940697\n",
      "Epoch 3189, Loss: 0.04821166954934597, Final Batch Loss: 0.017114652320742607\n",
      "Epoch 3190, Loss: 0.04397503659129143, Final Batch Loss: 0.012550771236419678\n",
      "Epoch 3191, Loss: 0.10142684727907181, Final Batch Loss: 0.06887761503458023\n",
      "Epoch 3192, Loss: 0.028537687845528126, Final Batch Loss: 0.013196537271142006\n",
      "Epoch 3193, Loss: 0.11117686703801155, Final Batch Loss: 0.08706726133823395\n",
      "Epoch 3194, Loss: 0.045157527551054955, Final Batch Loss: 0.023605475202202797\n",
      "Epoch 3195, Loss: 0.05010392423719168, Final Batch Loss: 0.03925758972764015\n",
      "Epoch 3196, Loss: 0.06230913661420345, Final Batch Loss: 0.03203056752681732\n",
      "Epoch 3197, Loss: 0.06216121278703213, Final Batch Loss: 0.024401219561696053\n",
      "Epoch 3198, Loss: 0.07527471706271172, Final Batch Loss: 0.03286679834127426\n",
      "Epoch 3199, Loss: 0.10871091485023499, Final Batch Loss: 0.07533415406942368\n",
      "Epoch 3200, Loss: 0.033341084606945515, Final Batch Loss: 0.009733323939144611\n",
      "Epoch 3201, Loss: 0.12159710004925728, Final Batch Loss: 0.06191135570406914\n",
      "Epoch 3202, Loss: 0.08591192588210106, Final Batch Loss: 0.04156436398625374\n",
      "Epoch 3203, Loss: 0.05922074057161808, Final Batch Loss: 0.03240454941987991\n",
      "Epoch 3204, Loss: 0.06481599435210228, Final Batch Loss: 0.02013186365365982\n",
      "Epoch 3205, Loss: 0.05236015189439058, Final Batch Loss: 0.042751163244247437\n",
      "Epoch 3206, Loss: 0.0823078453540802, Final Batch Loss: 0.05075344070792198\n",
      "Epoch 3207, Loss: 0.07587515935301781, Final Batch Loss: 0.031749386340379715\n",
      "Epoch 3208, Loss: 0.0707300566136837, Final Batch Loss: 0.033710453659296036\n",
      "Epoch 3209, Loss: 0.07570943050086498, Final Batch Loss: 0.024816812947392464\n",
      "Epoch 3210, Loss: 0.0445734579116106, Final Batch Loss: 0.022638054564595222\n",
      "Epoch 3211, Loss: 0.0922311581671238, Final Batch Loss: 0.03876155614852905\n",
      "Epoch 3212, Loss: 0.05198110640048981, Final Batch Loss: 0.023129256442189217\n",
      "Epoch 3213, Loss: 0.03403498791158199, Final Batch Loss: 0.021877067163586617\n",
      "Epoch 3214, Loss: 0.050910637713968754, Final Batch Loss: 0.014997673220932484\n",
      "Epoch 3215, Loss: 0.058039095252752304, Final Batch Loss: 0.04501444473862648\n",
      "Epoch 3216, Loss: 0.06015333905816078, Final Batch Loss: 0.03122747875750065\n",
      "Epoch 3217, Loss: 0.07987646758556366, Final Batch Loss: 0.043210119009017944\n",
      "Epoch 3218, Loss: 0.04836210608482361, Final Batch Loss: 0.02146889828145504\n",
      "Epoch 3219, Loss: 0.06634934432804585, Final Batch Loss: 0.03716002777218819\n",
      "Epoch 3220, Loss: 0.07379942573606968, Final Batch Loss: 0.04603356495499611\n",
      "Epoch 3221, Loss: 0.06319349631667137, Final Batch Loss: 0.041316919028759\n",
      "Epoch 3222, Loss: 0.09332145750522614, Final Batch Loss: 0.05006850138306618\n",
      "Epoch 3223, Loss: 0.14352587051689625, Final Batch Loss: 0.031161652877926826\n",
      "Epoch 3224, Loss: 0.034548765048384666, Final Batch Loss: 0.02510898932814598\n",
      "Epoch 3225, Loss: 0.06834124587476254, Final Batch Loss: 0.04133830592036247\n",
      "Epoch 3226, Loss: 0.05736847035586834, Final Batch Loss: 0.020427489653229713\n",
      "Epoch 3227, Loss: 0.09954116120934486, Final Batch Loss: 0.04450608417391777\n",
      "Epoch 3228, Loss: 0.10719946585595608, Final Batch Loss: 0.08873150497674942\n",
      "Epoch 3229, Loss: 0.10106386616826057, Final Batch Loss: 0.06270185858011246\n",
      "Epoch 3230, Loss: 0.05190974473953247, Final Batch Loss: 0.026071542873978615\n",
      "Epoch 3231, Loss: 0.11375015415251255, Final Batch Loss: 0.027895519509911537\n",
      "Epoch 3232, Loss: 0.08133844286203384, Final Batch Loss: 0.05104108899831772\n",
      "Epoch 3233, Loss: 0.10614104568958282, Final Batch Loss: 0.058392465114593506\n",
      "Epoch 3234, Loss: 0.06346266902983189, Final Batch Loss: 0.02671178989112377\n",
      "Epoch 3235, Loss: 0.03766839951276779, Final Batch Loss: 0.01550980657339096\n",
      "Epoch 3236, Loss: 0.0702028926461935, Final Batch Loss: 0.022761626169085503\n",
      "Epoch 3237, Loss: 0.11454546824097633, Final Batch Loss: 0.03479256108403206\n",
      "Epoch 3238, Loss: 0.05624124128371477, Final Batch Loss: 0.007831853814423084\n",
      "Epoch 3239, Loss: 0.0680724997073412, Final Batch Loss: 0.04670747369527817\n",
      "Epoch 3240, Loss: 0.06893733702600002, Final Batch Loss: 0.04788915067911148\n",
      "Epoch 3241, Loss: 0.037480952218174934, Final Batch Loss: 0.02522432804107666\n",
      "Epoch 3242, Loss: 0.0534905893728137, Final Batch Loss: 0.03988223522901535\n",
      "Epoch 3243, Loss: 0.0428757406771183, Final Batch Loss: 0.01957404799759388\n",
      "Epoch 3244, Loss: 0.062214162200689316, Final Batch Loss: 0.03330013528466225\n",
      "Epoch 3245, Loss: 0.058153677731752396, Final Batch Loss: 0.02766295149922371\n",
      "Epoch 3246, Loss: 0.05178946629166603, Final Batch Loss: 0.017980333417654037\n",
      "Epoch 3247, Loss: 0.042762573808431625, Final Batch Loss: 0.025851063430309296\n",
      "Epoch 3248, Loss: 0.0825147032737732, Final Batch Loss: 0.03167198225855827\n",
      "Epoch 3249, Loss: 0.11061222106218338, Final Batch Loss: 0.07251270860433578\n",
      "Epoch 3250, Loss: 0.08870187401771545, Final Batch Loss: 0.038417551666498184\n",
      "Epoch 3251, Loss: 0.07755861058831215, Final Batch Loss: 0.039435382932424545\n",
      "Epoch 3252, Loss: 0.04103315807878971, Final Batch Loss: 0.02198522351682186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3253, Loss: 0.06976818107068539, Final Batch Loss: 0.01769317500293255\n",
      "Epoch 3254, Loss: 0.08645839244127274, Final Batch Loss: 0.05487402528524399\n",
      "Epoch 3255, Loss: 0.0776042602956295, Final Batch Loss: 0.03543661907315254\n",
      "Epoch 3256, Loss: 0.06978824362158775, Final Batch Loss: 0.025475621223449707\n",
      "Epoch 3257, Loss: 0.05493565648794174, Final Batch Loss: 0.028554731979966164\n",
      "Epoch 3258, Loss: 0.11299825832247734, Final Batch Loss: 0.06520935148000717\n",
      "Epoch 3259, Loss: 0.0599625576287508, Final Batch Loss: 0.041553325951099396\n",
      "Epoch 3260, Loss: 0.07024459354579449, Final Batch Loss: 0.03910825029015541\n",
      "Epoch 3261, Loss: 0.047684251330792904, Final Batch Loss: 0.014492916874587536\n",
      "Epoch 3262, Loss: 0.059704605489969254, Final Batch Loss: 0.026613354682922363\n",
      "Epoch 3263, Loss: 0.06620879285037518, Final Batch Loss: 0.01928071118891239\n",
      "Epoch 3264, Loss: 0.09385433420538902, Final Batch Loss: 0.052527595311403275\n",
      "Epoch 3265, Loss: 0.08908073976635933, Final Batch Loss: 0.041221484541893005\n",
      "Epoch 3266, Loss: 0.09174641966819763, Final Batch Loss: 0.0551772266626358\n",
      "Epoch 3267, Loss: 0.0776185505092144, Final Batch Loss: 0.03217697888612747\n",
      "Epoch 3268, Loss: 0.05391542427241802, Final Batch Loss: 0.01861310563981533\n",
      "Epoch 3269, Loss: 0.12034299224615097, Final Batch Loss: 0.08467066287994385\n",
      "Epoch 3270, Loss: 0.07365433499217033, Final Batch Loss: 0.03965448960661888\n",
      "Epoch 3271, Loss: 0.10364923253655434, Final Batch Loss: 0.06647024303674698\n",
      "Epoch 3272, Loss: 0.10418125614523888, Final Batch Loss: 0.04293357580900192\n",
      "Epoch 3273, Loss: 0.0638725645840168, Final Batch Loss: 0.042508579790592194\n",
      "Epoch 3274, Loss: 0.11840039119124413, Final Batch Loss: 0.048238445073366165\n",
      "Epoch 3275, Loss: 0.05749513767659664, Final Batch Loss: 0.015995455905795097\n",
      "Epoch 3276, Loss: 0.07123350538313389, Final Batch Loss: 0.04654208943247795\n",
      "Epoch 3277, Loss: 0.0995392668992281, Final Batch Loss: 0.0717255175113678\n",
      "Epoch 3278, Loss: 0.1287614293396473, Final Batch Loss: 0.07903016358613968\n",
      "Epoch 3279, Loss: 0.13794750347733498, Final Batch Loss: 0.09902290254831314\n",
      "Epoch 3280, Loss: 0.04890233650803566, Final Batch Loss: 0.0137869194149971\n",
      "Epoch 3281, Loss: 0.04652935825288296, Final Batch Loss: 0.019628025591373444\n",
      "Epoch 3282, Loss: 0.07438857853412628, Final Batch Loss: 0.02680474892258644\n",
      "Epoch 3283, Loss: 0.05424135457724333, Final Batch Loss: 0.0067036813125014305\n",
      "Epoch 3284, Loss: 0.041771551594138145, Final Batch Loss: 0.02607334777712822\n",
      "Epoch 3285, Loss: 0.049399444833397865, Final Batch Loss: 0.013817144557833672\n",
      "Epoch 3286, Loss: 0.06265604123473167, Final Batch Loss: 0.02504224330186844\n",
      "Epoch 3287, Loss: 0.0518497284501791, Final Batch Loss: 0.025628212839365005\n",
      "Epoch 3288, Loss: 0.08142851665616035, Final Batch Loss: 0.028629153966903687\n",
      "Epoch 3289, Loss: 0.05219471640884876, Final Batch Loss: 0.039478905498981476\n",
      "Epoch 3290, Loss: 0.03306324500590563, Final Batch Loss: 0.01196883525699377\n",
      "Epoch 3291, Loss: 0.055696386843919754, Final Batch Loss: 0.03582251816987991\n",
      "Epoch 3292, Loss: 0.028144149109721184, Final Batch Loss: 0.009327627718448639\n",
      "Epoch 3293, Loss: 0.039440734311938286, Final Batch Loss: 0.018292782828211784\n",
      "Epoch 3294, Loss: 0.09069406613707542, Final Batch Loss: 0.06933784484863281\n",
      "Epoch 3295, Loss: 0.04473209287971258, Final Batch Loss: 0.010650376789271832\n",
      "Epoch 3296, Loss: 0.02603250741958618, Final Batch Loss: 0.015760166570544243\n",
      "Epoch 3297, Loss: 0.05671788565814495, Final Batch Loss: 0.01986645720899105\n",
      "Epoch 3298, Loss: 0.04310337454080582, Final Batch Loss: 0.018463686108589172\n",
      "Epoch 3299, Loss: 0.08222882077097893, Final Batch Loss: 0.027113769203424454\n",
      "Epoch 3300, Loss: 0.06286492571234703, Final Batch Loss: 0.0334555059671402\n",
      "Epoch 3301, Loss: 0.047355866990983486, Final Batch Loss: 0.01045206468552351\n",
      "Epoch 3302, Loss: 0.026508180424571037, Final Batch Loss: 0.008502094075083733\n",
      "Epoch 3303, Loss: 0.04304589331150055, Final Batch Loss: 0.026432104408740997\n",
      "Epoch 3304, Loss: 0.05310724209994078, Final Batch Loss: 0.04058019816875458\n",
      "Epoch 3305, Loss: 0.06561346910893917, Final Batch Loss: 0.03484274819493294\n",
      "Epoch 3306, Loss: 0.10896993800997734, Final Batch Loss: 0.07306184619665146\n",
      "Epoch 3307, Loss: 0.05225443746894598, Final Batch Loss: 0.015476926229894161\n",
      "Epoch 3308, Loss: 0.07711726054549217, Final Batch Loss: 0.04005502164363861\n",
      "Epoch 3309, Loss: 0.07518437691032887, Final Batch Loss: 0.061359237879514694\n",
      "Epoch 3310, Loss: 0.056133806705474854, Final Batch Loss: 0.015001147985458374\n",
      "Epoch 3311, Loss: 0.0637626014649868, Final Batch Loss: 0.03620399162173271\n",
      "Epoch 3312, Loss: 0.041384607553482056, Final Batch Loss: 0.018369028344750404\n",
      "Epoch 3313, Loss: 0.03728514350950718, Final Batch Loss: 0.008175592869520187\n",
      "Epoch 3314, Loss: 0.03190820850431919, Final Batch Loss: 0.014927903190255165\n",
      "Epoch 3315, Loss: 0.04927941784262657, Final Batch Loss: 0.019918004050850868\n",
      "Epoch 3316, Loss: 0.07814842741936445, Final Batch Loss: 0.013764108531177044\n",
      "Epoch 3317, Loss: 0.026602088939398527, Final Batch Loss: 0.006455765571445227\n",
      "Epoch 3318, Loss: 0.061020491644740105, Final Batch Loss: 0.016295714303851128\n",
      "Epoch 3319, Loss: 0.0373325003311038, Final Batch Loss: 0.023219579830765724\n",
      "Epoch 3320, Loss: 0.05825002118945122, Final Batch Loss: 0.031823620200157166\n",
      "Epoch 3321, Loss: 0.06214275769889355, Final Batch Loss: 0.013200728222727776\n",
      "Epoch 3322, Loss: 0.05356547888368368, Final Batch Loss: 0.04430042952299118\n",
      "Epoch 3323, Loss: 0.02494517806917429, Final Batch Loss: 0.014194963499903679\n",
      "Epoch 3324, Loss: 0.030747649259865284, Final Batch Loss: 0.02154035121202469\n",
      "Epoch 3325, Loss: 0.09731878712773323, Final Batch Loss: 0.059571169316768646\n",
      "Epoch 3326, Loss: 0.08956585451960564, Final Batch Loss: 0.034888193011283875\n",
      "Epoch 3327, Loss: 0.03504753112792969, Final Batch Loss: 0.024408873170614243\n",
      "Epoch 3328, Loss: 0.0712025947868824, Final Batch Loss: 0.04841527342796326\n",
      "Epoch 3329, Loss: 0.058707913383841515, Final Batch Loss: 0.03224967047572136\n",
      "Epoch 3330, Loss: 0.05550868529826403, Final Batch Loss: 0.01544066984206438\n",
      "Epoch 3331, Loss: 0.026575427502393723, Final Batch Loss: 0.01652558706700802\n",
      "Epoch 3332, Loss: 0.043689021840691566, Final Batch Loss: 0.029226822778582573\n",
      "Epoch 3333, Loss: 0.07520602084696293, Final Batch Loss: 0.052049022167921066\n",
      "Epoch 3334, Loss: 0.027020835783332586, Final Batch Loss: 0.004164982121437788\n",
      "Epoch 3335, Loss: 0.05050152726471424, Final Batch Loss: 0.03241122514009476\n",
      "Epoch 3336, Loss: 0.05354239698499441, Final Batch Loss: 0.008095062337815762\n",
      "Epoch 3337, Loss: 0.11917605064809322, Final Batch Loss: 0.09950389713048935\n",
      "Epoch 3338, Loss: 0.07140282727777958, Final Batch Loss: 0.043730128556489944\n",
      "Epoch 3339, Loss: 0.05022366438060999, Final Batch Loss: 0.03696513921022415\n",
      "Epoch 3340, Loss: 0.05712824501097202, Final Batch Loss: 0.03483913093805313\n",
      "Epoch 3341, Loss: 0.071975271217525, Final Batch Loss: 0.008916723541915417\n",
      "Epoch 3342, Loss: 0.016570488922297955, Final Batch Loss: 0.011100005358457565\n",
      "Epoch 3343, Loss: 0.06506235525012016, Final Batch Loss: 0.04769802838563919\n",
      "Epoch 3344, Loss: 0.08844005316495895, Final Batch Loss: 0.031519815325737\n",
      "Epoch 3345, Loss: 0.12560740113258362, Final Batch Loss: 0.07820484042167664\n",
      "Epoch 3346, Loss: 0.04306424781680107, Final Batch Loss: 0.01587199792265892\n",
      "Epoch 3347, Loss: 0.04166185110807419, Final Batch Loss: 0.02347644418478012\n",
      "Epoch 3348, Loss: 0.035048604011535645, Final Batch Loss: 0.014299018308520317\n",
      "Epoch 3349, Loss: 0.04648871719837189, Final Batch Loss: 0.017875073477625847\n",
      "Epoch 3350, Loss: 0.041548293083906174, Final Batch Loss: 0.013340722769498825\n",
      "Epoch 3351, Loss: 0.07160268165171146, Final Batch Loss: 0.043880071491003036\n",
      "Epoch 3352, Loss: 0.06105976924300194, Final Batch Loss: 0.03536760061979294\n",
      "Epoch 3353, Loss: 0.061234256252646446, Final Batch Loss: 0.028927667066454887\n",
      "Epoch 3354, Loss: 0.15523266792297363, Final Batch Loss: 0.061581119894981384\n",
      "Epoch 3355, Loss: 0.04805027320981026, Final Batch Loss: 0.025253569707274437\n",
      "Epoch 3356, Loss: 0.05784711241722107, Final Batch Loss: 0.02123134583234787\n",
      "Epoch 3357, Loss: 0.04193694703280926, Final Batch Loss: 0.012994805350899696\n",
      "Epoch 3358, Loss: 0.059468064457178116, Final Batch Loss: 0.022658556699752808\n",
      "Epoch 3359, Loss: 0.09971622750163078, Final Batch Loss: 0.02252274379134178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3360, Loss: 0.02671953570097685, Final Batch Loss: 0.012220238335430622\n",
      "Epoch 3361, Loss: 0.06505590677261353, Final Batch Loss: 0.029508236795663834\n",
      "Epoch 3362, Loss: 0.08346522599458694, Final Batch Loss: 0.03805551305413246\n",
      "Epoch 3363, Loss: 0.05160425789654255, Final Batch Loss: 0.0245656780898571\n",
      "Epoch 3364, Loss: 0.025311562232673168, Final Batch Loss: 0.014685296453535557\n",
      "Epoch 3365, Loss: 0.051448505371809006, Final Batch Loss: 0.023329639807343483\n",
      "Epoch 3366, Loss: 0.04708473198115826, Final Batch Loss: 0.03130166605114937\n",
      "Epoch 3367, Loss: 0.057322947308421135, Final Batch Loss: 0.02305416576564312\n",
      "Epoch 3368, Loss: 0.05818468518555164, Final Batch Loss: 0.017018871381878853\n",
      "Epoch 3369, Loss: 0.04356543440371752, Final Batch Loss: 0.009653796441853046\n",
      "Epoch 3370, Loss: 0.12345210835337639, Final Batch Loss: 0.09240791946649551\n",
      "Epoch 3371, Loss: 0.03682779800146818, Final Batch Loss: 0.012401477433741093\n",
      "Epoch 3372, Loss: 0.06659336760640144, Final Batch Loss: 0.030730072408914566\n",
      "Epoch 3373, Loss: 0.05015191622078419, Final Batch Loss: 0.023203983902931213\n",
      "Epoch 3374, Loss: 0.04477144591510296, Final Batch Loss: 0.010685345157980919\n",
      "Epoch 3375, Loss: 0.05049647204577923, Final Batch Loss: 0.02487238496541977\n",
      "Epoch 3376, Loss: 0.03163495101034641, Final Batch Loss: 0.010226022452116013\n",
      "Epoch 3377, Loss: 0.03154947329312563, Final Batch Loss: 0.014672460965812206\n",
      "Epoch 3378, Loss: 0.04508562944829464, Final Batch Loss: 0.010282998904585838\n",
      "Epoch 3379, Loss: 0.030448628589510918, Final Batch Loss: 0.009642083197832108\n",
      "Epoch 3380, Loss: 0.045124717988073826, Final Batch Loss: 0.009188500232994556\n",
      "Epoch 3381, Loss: 0.17140551656484604, Final Batch Loss: 0.09092708677053452\n",
      "Epoch 3382, Loss: 0.04527456872165203, Final Batch Loss: 0.016354523599147797\n",
      "Epoch 3383, Loss: 0.09081266447901726, Final Batch Loss: 0.052832115441560745\n",
      "Epoch 3384, Loss: 0.07656088843941689, Final Batch Loss: 0.0432165190577507\n",
      "Epoch 3385, Loss: 0.10986128821969032, Final Batch Loss: 0.06207074224948883\n",
      "Epoch 3386, Loss: 0.06213941238820553, Final Batch Loss: 0.04549981281161308\n",
      "Epoch 3387, Loss: 0.0625892523676157, Final Batch Loss: 0.020592844113707542\n",
      "Epoch 3388, Loss: 0.10278838872909546, Final Batch Loss: 0.07362883538007736\n",
      "Epoch 3389, Loss: 0.037280602380633354, Final Batch Loss: 0.013780143111944199\n",
      "Epoch 3390, Loss: 0.053964887745678425, Final Batch Loss: 0.0066041359677910805\n",
      "Epoch 3391, Loss: 0.018636486027389765, Final Batch Loss: 0.006335904356092215\n",
      "Epoch 3392, Loss: 0.0382981700822711, Final Batch Loss: 0.012901403941214085\n",
      "Epoch 3393, Loss: 0.037786711007356644, Final Batch Loss: 0.02311771549284458\n",
      "Epoch 3394, Loss: 0.11990102753043175, Final Batch Loss: 0.07737687230110168\n",
      "Epoch 3395, Loss: 0.042932639829814434, Final Batch Loss: 0.029609719291329384\n",
      "Epoch 3396, Loss: 0.04971222020685673, Final Batch Loss: 0.02965424954891205\n",
      "Epoch 3397, Loss: 0.07485242560505867, Final Batch Loss: 0.020889706909656525\n",
      "Epoch 3398, Loss: 0.039153462275862694, Final Batch Loss: 0.016394607722759247\n",
      "Epoch 3399, Loss: 0.052065806463360786, Final Batch Loss: 0.03153906390070915\n",
      "Epoch 3400, Loss: 0.017777728848159313, Final Batch Loss: 0.008074297569692135\n",
      "Epoch 3401, Loss: 0.030290808528661728, Final Batch Loss: 0.02209397405385971\n",
      "Epoch 3402, Loss: 0.027116650715470314, Final Batch Loss: 0.017939185723662376\n",
      "Epoch 3403, Loss: 0.027253124862909317, Final Batch Loss: 0.008145075291395187\n",
      "Epoch 3404, Loss: 0.044312573969364166, Final Batch Loss: 0.027610188350081444\n",
      "Epoch 3405, Loss: 0.0776809323579073, Final Batch Loss: 0.02909099869430065\n",
      "Epoch 3406, Loss: 0.020574949216097593, Final Batch Loss: 0.0042329332791268826\n",
      "Epoch 3407, Loss: 0.03793321177363396, Final Batch Loss: 0.015223139896988869\n",
      "Epoch 3408, Loss: 0.053852916695177555, Final Batch Loss: 0.009932172484695911\n",
      "Epoch 3409, Loss: 0.06156640872359276, Final Batch Loss: 0.046949293464422226\n",
      "Epoch 3410, Loss: 0.050979772582650185, Final Batch Loss: 0.027559122070670128\n",
      "Epoch 3411, Loss: 0.01867624744772911, Final Batch Loss: 0.008426375687122345\n",
      "Epoch 3412, Loss: 0.07939505204558372, Final Batch Loss: 0.0607667975127697\n",
      "Epoch 3413, Loss: 0.08104433864355087, Final Batch Loss: 0.02606729045510292\n",
      "Epoch 3414, Loss: 0.10221780836582184, Final Batch Loss: 0.07056491076946259\n",
      "Epoch 3415, Loss: 0.10702230781316757, Final Batch Loss: 0.061448413878679276\n",
      "Epoch 3416, Loss: 0.041273124516010284, Final Batch Loss: 0.018269434571266174\n",
      "Epoch 3417, Loss: 0.04787283018231392, Final Batch Loss: 0.014724843204021454\n",
      "Epoch 3418, Loss: 0.031713894568383694, Final Batch Loss: 0.024543238803744316\n",
      "Epoch 3419, Loss: 0.0556869525462389, Final Batch Loss: 0.018280895426869392\n",
      "Epoch 3420, Loss: 0.0814116969704628, Final Batch Loss: 0.01251993328332901\n",
      "Epoch 3421, Loss: 0.07734723575413227, Final Batch Loss: 0.027451151981949806\n",
      "Epoch 3422, Loss: 0.07517345994710922, Final Batch Loss: 0.013955265283584595\n",
      "Epoch 3423, Loss: 0.08850932121276855, Final Batch Loss: 0.04496309906244278\n",
      "Epoch 3424, Loss: 0.06597925908863544, Final Batch Loss: 0.04838024452328682\n",
      "Epoch 3425, Loss: 0.07997090369462967, Final Batch Loss: 0.06824570894241333\n",
      "Epoch 3426, Loss: 0.0632664505392313, Final Batch Loss: 0.03679131716489792\n",
      "Epoch 3427, Loss: 0.10773739591240883, Final Batch Loss: 0.018091652542352676\n",
      "Epoch 3428, Loss: 0.04845874011516571, Final Batch Loss: 0.019649820402264595\n",
      "Epoch 3429, Loss: 0.024710094556212425, Final Batch Loss: 0.012378303334116936\n",
      "Epoch 3430, Loss: 0.015606270637363195, Final Batch Loss: 0.004916368518024683\n",
      "Epoch 3431, Loss: 0.0243922071531415, Final Batch Loss: 0.01279720664024353\n",
      "Epoch 3432, Loss: 0.06663129292428493, Final Batch Loss: 0.02803158201277256\n",
      "Epoch 3433, Loss: 0.07778458017855883, Final Batch Loss: 0.0657983273267746\n",
      "Epoch 3434, Loss: 0.04003270249813795, Final Batch Loss: 0.008698723278939724\n",
      "Epoch 3435, Loss: 0.03186512552201748, Final Batch Loss: 0.01629249006509781\n",
      "Epoch 3436, Loss: 0.04882344603538513, Final Batch Loss: 0.02365747280418873\n",
      "Epoch 3437, Loss: 0.035594687797129154, Final Batch Loss: 0.014303994365036488\n",
      "Epoch 3438, Loss: 0.05071678385138512, Final Batch Loss: 0.029605843126773834\n",
      "Epoch 3439, Loss: 0.029685920104384422, Final Batch Loss: 0.01225188560783863\n",
      "Epoch 3440, Loss: 0.04316328838467598, Final Batch Loss: 0.023943064734339714\n",
      "Epoch 3441, Loss: 0.03826330043375492, Final Batch Loss: 0.02320767007768154\n",
      "Epoch 3442, Loss: 0.026764729991555214, Final Batch Loss: 0.017870966345071793\n",
      "Epoch 3443, Loss: 0.11492981761693954, Final Batch Loss: 0.07930043339729309\n",
      "Epoch 3444, Loss: 0.0909361019730568, Final Batch Loss: 0.02107052505016327\n",
      "Epoch 3445, Loss: 0.027117081452161074, Final Batch Loss: 0.005915970075875521\n",
      "Epoch 3446, Loss: 0.09525711834430695, Final Batch Loss: 0.05042609944939613\n",
      "Epoch 3447, Loss: 0.036657433956861496, Final Batch Loss: 0.02247067540884018\n",
      "Epoch 3448, Loss: 0.056602843105793, Final Batch Loss: 0.028411339968442917\n",
      "Epoch 3449, Loss: 0.052809013053774834, Final Batch Loss: 0.01817134954035282\n",
      "Epoch 3450, Loss: 0.0379808247089386, Final Batch Loss: 0.011890709400177002\n",
      "Epoch 3451, Loss: 0.05546262301504612, Final Batch Loss: 0.011990895494818687\n",
      "Epoch 3452, Loss: 0.05895961634814739, Final Batch Loss: 0.03690247982740402\n",
      "Epoch 3453, Loss: 0.0637388750910759, Final Batch Loss: 0.04710172489285469\n",
      "Epoch 3454, Loss: 0.06145006790757179, Final Batch Loss: 0.033935919404029846\n",
      "Epoch 3455, Loss: 0.05416586250066757, Final Batch Loss: 0.03294973447918892\n",
      "Epoch 3456, Loss: 0.10599048063158989, Final Batch Loss: 0.052762873470783234\n",
      "Epoch 3457, Loss: 0.057165445759892464, Final Batch Loss: 0.040097836405038834\n",
      "Epoch 3458, Loss: 0.06333337724208832, Final Batch Loss: 0.047121237963438034\n",
      "Epoch 3459, Loss: 0.04142184741795063, Final Batch Loss: 0.009488975629210472\n",
      "Epoch 3460, Loss: 0.06782870646566153, Final Batch Loss: 0.05242609232664108\n",
      "Epoch 3461, Loss: 0.054507920518517494, Final Batch Loss: 0.03773249685764313\n",
      "Epoch 3462, Loss: 0.05108178034424782, Final Batch Loss: 0.02813062258064747\n",
      "Epoch 3463, Loss: 0.1188754215836525, Final Batch Loss: 0.03739730268716812\n",
      "Epoch 3464, Loss: 0.11623946204781532, Final Batch Loss: 0.03708966448903084\n",
      "Epoch 3465, Loss: 0.026020206976681948, Final Batch Loss: 0.00541528919711709\n",
      "Epoch 3466, Loss: 0.04690994694828987, Final Batch Loss: 0.02046324871480465\n",
      "Epoch 3467, Loss: 0.027895944193005562, Final Batch Loss: 0.012578904628753662\n",
      "Epoch 3468, Loss: 0.04170704632997513, Final Batch Loss: 0.020257072523236275\n",
      "Epoch 3469, Loss: 0.08566773124039173, Final Batch Loss: 0.02862592600286007\n",
      "Epoch 3470, Loss: 0.06364109925925732, Final Batch Loss: 0.020496198907494545\n",
      "Epoch 3471, Loss: 0.0728868879377842, Final Batch Loss: 0.04130244627594948\n",
      "Epoch 3472, Loss: 0.07552549242973328, Final Batch Loss: 0.039845965802669525\n",
      "Epoch 3473, Loss: 0.03746809344738722, Final Batch Loss: 0.015166147612035275\n",
      "Epoch 3474, Loss: 0.10080552473664284, Final Batch Loss: 0.07975177466869354\n",
      "Epoch 3475, Loss: 0.044119687750935555, Final Batch Loss: 0.023091215640306473\n",
      "Epoch 3476, Loss: 0.052824826911091805, Final Batch Loss: 0.02859816886484623\n",
      "Epoch 3477, Loss: 0.06882139854133129, Final Batch Loss: 0.041848257184028625\n",
      "Epoch 3478, Loss: 0.05188760720193386, Final Batch Loss: 0.009844465181231499\n",
      "Epoch 3479, Loss: 0.03191810380667448, Final Batch Loss: 0.017458336427807808\n",
      "Epoch 3480, Loss: 0.05343529675155878, Final Batch Loss: 0.010612406767904758\n",
      "Epoch 3481, Loss: 0.028592312708497047, Final Batch Loss: 0.01774301938712597\n",
      "Epoch 3482, Loss: 0.05856833979487419, Final Batch Loss: 0.01595957949757576\n",
      "Epoch 3483, Loss: 0.0679861530661583, Final Batch Loss: 0.02528408169746399\n",
      "Epoch 3484, Loss: 0.08890409767627716, Final Batch Loss: 0.032759182155132294\n",
      "Epoch 3485, Loss: 0.11260320898145437, Final Batch Loss: 0.0984182059764862\n",
      "Epoch 3486, Loss: 0.060346098616719246, Final Batch Loss: 0.011676738038659096\n",
      "Epoch 3487, Loss: 0.03090925980359316, Final Batch Loss: 0.021116549149155617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3488, Loss: 0.06050291284918785, Final Batch Loss: 0.03761035576462746\n",
      "Epoch 3489, Loss: 0.07269302010536194, Final Batch Loss: 0.03786282613873482\n",
      "Epoch 3490, Loss: 0.05628231540322304, Final Batch Loss: 0.02606559358537197\n",
      "Epoch 3491, Loss: 0.09575308486819267, Final Batch Loss: 0.039223093539476395\n",
      "Epoch 3492, Loss: 0.05243345722556114, Final Batch Loss: 0.024963613599538803\n",
      "Epoch 3493, Loss: 0.05934331752359867, Final Batch Loss: 0.025703279301524162\n",
      "Epoch 3494, Loss: 0.07290894910693169, Final Batch Loss: 0.019483786076307297\n",
      "Epoch 3495, Loss: 0.09455312788486481, Final Batch Loss: 0.06719501316547394\n",
      "Epoch 3496, Loss: 0.09785981848835945, Final Batch Loss: 0.06827979534864426\n",
      "Epoch 3497, Loss: 0.0804742518812418, Final Batch Loss: 0.05081534758210182\n",
      "Epoch 3498, Loss: 0.07881958223879337, Final Batch Loss: 0.019834717735648155\n",
      "Epoch 3499, Loss: 0.0664794621989131, Final Batch Loss: 0.013636994175612926\n",
      "Epoch 3500, Loss: 0.09310982748866081, Final Batch Loss: 0.05610191076993942\n",
      "Epoch 3501, Loss: 0.05575724318623543, Final Batch Loss: 0.03427306190133095\n",
      "Epoch 3502, Loss: 0.04525227099657059, Final Batch Loss: 0.031167319044470787\n",
      "Epoch 3503, Loss: 0.112473389133811, Final Batch Loss: 0.08824200928211212\n",
      "Epoch 3504, Loss: 0.0529483575373888, Final Batch Loss: 0.0312090665102005\n",
      "Epoch 3505, Loss: 0.05961153283715248, Final Batch Loss: 0.025602541863918304\n",
      "Epoch 3506, Loss: 0.03974241763353348, Final Batch Loss: 0.009080769494175911\n",
      "Epoch 3507, Loss: 0.07179811969399452, Final Batch Loss: 0.04991607740521431\n",
      "Epoch 3508, Loss: 0.0380931468680501, Final Batch Loss: 0.009740178473293781\n",
      "Epoch 3509, Loss: 0.045252615585923195, Final Batch Loss: 0.02319410815834999\n",
      "Epoch 3510, Loss: 0.04094389081001282, Final Batch Loss: 0.023617273196578026\n",
      "Epoch 3511, Loss: 0.04170358180999756, Final Batch Loss: 0.03326251730322838\n",
      "Epoch 3512, Loss: 0.02111506089568138, Final Batch Loss: 0.011957703158259392\n",
      "Epoch 3513, Loss: 0.055778469890356064, Final Batch Loss: 0.008725710213184357\n",
      "Epoch 3514, Loss: 0.03664783202111721, Final Batch Loss: 0.015956297516822815\n",
      "Epoch 3515, Loss: 0.05063740909099579, Final Batch Loss: 0.031229674816131592\n",
      "Epoch 3516, Loss: 0.03556634858250618, Final Batch Loss: 0.009608760476112366\n",
      "Epoch 3517, Loss: 0.055145155638456345, Final Batch Loss: 0.016222044825553894\n",
      "Epoch 3518, Loss: 0.03062931727617979, Final Batch Loss: 0.005329993553459644\n",
      "Epoch 3519, Loss: 0.11734453588724136, Final Batch Loss: 0.07004436105489731\n",
      "Epoch 3520, Loss: 0.053583343513309956, Final Batch Loss: 0.008208886720240116\n",
      "Epoch 3521, Loss: 0.03354051895439625, Final Batch Loss: 0.016888083890080452\n",
      "Epoch 3522, Loss: 0.0393853634595871, Final Batch Loss: 0.016628434881567955\n",
      "Epoch 3523, Loss: 0.03861168306320906, Final Batch Loss: 0.014270051382482052\n",
      "Epoch 3524, Loss: 0.06242641992866993, Final Batch Loss: 0.0429237000644207\n",
      "Epoch 3525, Loss: 0.06809044256806374, Final Batch Loss: 0.005256909877061844\n",
      "Epoch 3526, Loss: 0.05435129348188639, Final Batch Loss: 0.015072894282639027\n",
      "Epoch 3527, Loss: 0.0652424618601799, Final Batch Loss: 0.023174472153186798\n",
      "Epoch 3528, Loss: 0.05527276732027531, Final Batch Loss: 0.02422487735748291\n",
      "Epoch 3529, Loss: 0.06529453583061695, Final Batch Loss: 0.036422502249479294\n",
      "Epoch 3530, Loss: 0.044868615455925465, Final Batch Loss: 0.03981390967965126\n",
      "Epoch 3531, Loss: 0.10161867551505566, Final Batch Loss: 0.07613177597522736\n",
      "Epoch 3532, Loss: 0.0715841855853796, Final Batch Loss: 0.047945309430360794\n",
      "Epoch 3533, Loss: 0.0363532193005085, Final Batch Loss: 0.018850019201636314\n",
      "Epoch 3534, Loss: 0.05539954453706741, Final Batch Loss: 0.022567667067050934\n",
      "Epoch 3535, Loss: 0.06550774723291397, Final Batch Loss: 0.04524354264140129\n",
      "Epoch 3536, Loss: 0.1045859158039093, Final Batch Loss: 0.04970141127705574\n",
      "Epoch 3537, Loss: 0.05888247583061457, Final Batch Loss: 0.006994054652750492\n",
      "Epoch 3538, Loss: 0.09844795800745487, Final Batch Loss: 0.07547029852867126\n",
      "Epoch 3539, Loss: 0.11082802712917328, Final Batch Loss: 0.07463650405406952\n",
      "Epoch 3540, Loss: 0.053516361862421036, Final Batch Loss: 0.03632301837205887\n",
      "Epoch 3541, Loss: 0.03857946768403053, Final Batch Loss: 0.01861647143959999\n",
      "Epoch 3542, Loss: 0.023479074239730835, Final Batch Loss: 0.009794114157557487\n",
      "Epoch 3543, Loss: 0.07152902521193027, Final Batch Loss: 0.025341277942061424\n",
      "Epoch 3544, Loss: 0.05080833937972784, Final Batch Loss: 0.014945964328944683\n",
      "Epoch 3545, Loss: 0.029598547145724297, Final Batch Loss: 0.011414524167776108\n",
      "Epoch 3546, Loss: 0.05361199378967285, Final Batch Loss: 0.011115342378616333\n",
      "Epoch 3547, Loss: 0.08658210933208466, Final Batch Loss: 0.055726777762174606\n",
      "Epoch 3548, Loss: 0.08941624127328396, Final Batch Loss: 0.06710778921842575\n",
      "Epoch 3549, Loss: 0.06578555516898632, Final Batch Loss: 0.04085327684879303\n",
      "Epoch 3550, Loss: 0.05297951027750969, Final Batch Loss: 0.03048788383603096\n",
      "Epoch 3551, Loss: 0.04768503736704588, Final Batch Loss: 0.00913147535175085\n",
      "Epoch 3552, Loss: 0.023012359626591206, Final Batch Loss: 0.010451557114720345\n",
      "Epoch 3553, Loss: 0.04055885225534439, Final Batch Loss: 0.032411135733127594\n",
      "Epoch 3554, Loss: 0.06789130344986916, Final Batch Loss: 0.02938992902636528\n",
      "Epoch 3555, Loss: 0.05994659289717674, Final Batch Loss: 0.021719861775636673\n",
      "Epoch 3556, Loss: 0.07705412805080414, Final Batch Loss: 0.03150495886802673\n",
      "Epoch 3557, Loss: 0.01597439614124596, Final Batch Loss: 0.0033379963133484125\n",
      "Epoch 3558, Loss: 0.038041260093450546, Final Batch Loss: 0.01617252454161644\n",
      "Epoch 3559, Loss: 0.06883649528026581, Final Batch Loss: 0.03501371294260025\n",
      "Epoch 3560, Loss: 0.04015548527240753, Final Batch Loss: 0.013139978051185608\n",
      "Epoch 3561, Loss: 0.10458959639072418, Final Batch Loss: 0.071570485830307\n",
      "Epoch 3562, Loss: 0.06896593421697617, Final Batch Loss: 0.03175709396600723\n",
      "Epoch 3563, Loss: 0.025879982858896255, Final Batch Loss: 0.004739739000797272\n",
      "Epoch 3564, Loss: 0.07074102386832237, Final Batch Loss: 0.02109987661242485\n",
      "Epoch 3565, Loss: 0.03726355452090502, Final Batch Loss: 0.02445880137383938\n",
      "Epoch 3566, Loss: 0.15345168486237526, Final Batch Loss: 0.09569943696260452\n",
      "Epoch 3567, Loss: 0.05304285138845444, Final Batch Loss: 0.022698571905493736\n",
      "Epoch 3568, Loss: 0.06443293578922749, Final Batch Loss: 0.0255922619253397\n",
      "Epoch 3569, Loss: 0.12541012093424797, Final Batch Loss: 0.09308862686157227\n",
      "Epoch 3570, Loss: 0.031022888608276844, Final Batch Loss: 0.019583934918045998\n",
      "Epoch 3571, Loss: 0.05418569594621658, Final Batch Loss: 0.01387830451130867\n",
      "Epoch 3572, Loss: 0.09458763524889946, Final Batch Loss: 0.05656880885362625\n",
      "Epoch 3573, Loss: 0.10425405949354172, Final Batch Loss: 0.06259714812040329\n",
      "Epoch 3574, Loss: 0.030843719840049744, Final Batch Loss: 0.009453630074858665\n",
      "Epoch 3575, Loss: 0.03604917414486408, Final Batch Loss: 0.013035779818892479\n",
      "Epoch 3576, Loss: 0.07002759538590908, Final Batch Loss: 0.025247765704989433\n",
      "Epoch 3577, Loss: 0.05832317564636469, Final Batch Loss: 0.011244934983551502\n",
      "Epoch 3578, Loss: 0.0370249692350626, Final Batch Loss: 0.01521119475364685\n",
      "Epoch 3579, Loss: 0.04188549146056175, Final Batch Loss: 0.01842966116964817\n",
      "Epoch 3580, Loss: 0.03983686491847038, Final Batch Loss: 0.01889602094888687\n",
      "Epoch 3581, Loss: 0.04279841482639313, Final Batch Loss: 0.028953460976481438\n",
      "Epoch 3582, Loss: 0.03153097163885832, Final Batch Loss: 0.012468929402530193\n",
      "Epoch 3583, Loss: 0.11968382447957993, Final Batch Loss: 0.03217500448226929\n",
      "Epoch 3584, Loss: 0.07972796447575092, Final Batch Loss: 0.052480366080999374\n",
      "Epoch 3585, Loss: 0.06613453384488821, Final Batch Loss: 0.007421149872243404\n",
      "Epoch 3586, Loss: 0.07735528983175755, Final Batch Loss: 0.06527087092399597\n",
      "Epoch 3587, Loss: 0.06118282675743103, Final Batch Loss: 0.006974432617425919\n",
      "Epoch 3588, Loss: 0.04520541988313198, Final Batch Loss: 0.023123953491449356\n",
      "Epoch 3589, Loss: 0.08060997724533081, Final Batch Loss: 0.05062061920762062\n",
      "Epoch 3590, Loss: 0.015215396881103516, Final Batch Loss: 0.010439272969961166\n",
      "Epoch 3591, Loss: 0.06383859738707542, Final Batch Loss: 0.04245864972472191\n",
      "Epoch 3592, Loss: 0.043462663888931274, Final Batch Loss: 0.022246073931455612\n",
      "Epoch 3593, Loss: 0.05191348120570183, Final Batch Loss: 0.03208155184984207\n",
      "Epoch 3594, Loss: 0.05823594518005848, Final Batch Loss: 0.032952290028333664\n",
      "Epoch 3595, Loss: 0.04826962575316429, Final Batch Loss: 0.00810539722442627\n",
      "Epoch 3596, Loss: 0.04384663142263889, Final Batch Loss: 0.010241957381367683\n",
      "Epoch 3597, Loss: 0.039368610829114914, Final Batch Loss: 0.013338997960090637\n",
      "Epoch 3598, Loss: 0.06738694757223129, Final Batch Loss: 0.04485638439655304\n",
      "Epoch 3599, Loss: 0.04188654199242592, Final Batch Loss: 0.019513705745339394\n",
      "Epoch 3600, Loss: 0.026559720747172832, Final Batch Loss: 0.013537275604903698\n",
      "Epoch 3601, Loss: 0.032380628399550915, Final Batch Loss: 0.013494814746081829\n",
      "Epoch 3602, Loss: 0.020970765501260757, Final Batch Loss: 0.004873236641287804\n",
      "Epoch 3603, Loss: 0.09699166566133499, Final Batch Loss: 0.08091770857572556\n",
      "Epoch 3604, Loss: 0.1480749286711216, Final Batch Loss: 0.10997332632541656\n",
      "Epoch 3605, Loss: 0.03311049658805132, Final Batch Loss: 0.01107905711978674\n",
      "Epoch 3606, Loss: 0.04988090135157108, Final Batch Loss: 0.011034758761525154\n",
      "Epoch 3607, Loss: 0.04787992127239704, Final Batch Loss: 0.021455055102705956\n",
      "Epoch 3608, Loss: 0.05726536922156811, Final Batch Loss: 0.04209915176033974\n",
      "Epoch 3609, Loss: 0.05268429731950164, Final Batch Loss: 0.006796789821237326\n",
      "Epoch 3610, Loss: 0.07833177223801613, Final Batch Loss: 0.06647815555334091\n",
      "Epoch 3611, Loss: 0.057636923622339964, Final Batch Loss: 0.006245132070034742\n",
      "Epoch 3612, Loss: 0.037554048001766205, Final Batch Loss: 0.009875649586319923\n",
      "Epoch 3613, Loss: 0.06272701919078827, Final Batch Loss: 0.038109276443719864\n",
      "Epoch 3614, Loss: 0.07773311715573072, Final Batch Loss: 0.06829344481229782\n",
      "Epoch 3615, Loss: 0.04771417938172817, Final Batch Loss: 0.028337040916085243\n",
      "Epoch 3616, Loss: 0.048794956877827644, Final Batch Loss: 0.01899893581867218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3617, Loss: 0.03157535940408707, Final Batch Loss: 0.008698126301169395\n",
      "Epoch 3618, Loss: 0.030941066332161427, Final Batch Loss: 0.015663722530007362\n",
      "Epoch 3619, Loss: 0.03483335021883249, Final Batch Loss: 0.025394106283783913\n",
      "Epoch 3620, Loss: 0.06556407548487186, Final Batch Loss: 0.03820253536105156\n",
      "Epoch 3621, Loss: 0.0495385592803359, Final Batch Loss: 0.03749274089932442\n",
      "Epoch 3622, Loss: 0.041828940622508526, Final Batch Loss: 0.013147513382136822\n",
      "Epoch 3623, Loss: 0.07854845561087132, Final Batch Loss: 0.05064166337251663\n",
      "Epoch 3624, Loss: 0.04043898172676563, Final Batch Loss: 0.01695362664759159\n",
      "Epoch 3625, Loss: 0.06552551500499249, Final Batch Loss: 0.045071497559547424\n",
      "Epoch 3626, Loss: 0.05598224047571421, Final Batch Loss: 0.008753621019423008\n",
      "Epoch 3627, Loss: 0.057758793234825134, Final Batch Loss: 0.02349723130464554\n",
      "Epoch 3628, Loss: 0.05749388597905636, Final Batch Loss: 0.023604700341820717\n",
      "Epoch 3629, Loss: 0.03685007430613041, Final Batch Loss: 0.01646062545478344\n",
      "Epoch 3630, Loss: 0.029325817711651325, Final Batch Loss: 0.010056479834020138\n",
      "Epoch 3631, Loss: 0.030508995056152344, Final Batch Loss: 0.014168398454785347\n",
      "Epoch 3632, Loss: 0.022039401344954967, Final Batch Loss: 0.013792409561574459\n",
      "Epoch 3633, Loss: 0.050060760229825974, Final Batch Loss: 0.012042205780744553\n",
      "Epoch 3634, Loss: 0.036679985001683235, Final Batch Loss: 0.021553823724389076\n",
      "Epoch 3635, Loss: 0.030994457192718983, Final Batch Loss: 0.020004460588097572\n",
      "Epoch 3636, Loss: 0.030417817644774914, Final Batch Loss: 0.011392616666853428\n",
      "Epoch 3637, Loss: 0.09394395351409912, Final Batch Loss: 0.0499357171356678\n",
      "Epoch 3638, Loss: 0.034377007745206356, Final Batch Loss: 0.019235221669077873\n",
      "Epoch 3639, Loss: 0.03811011416837573, Final Batch Loss: 0.032579876482486725\n",
      "Epoch 3640, Loss: 0.10316970199346542, Final Batch Loss: 0.06782440841197968\n",
      "Epoch 3641, Loss: 0.04363520257174969, Final Batch Loss: 0.009437331929802895\n",
      "Epoch 3642, Loss: 0.054847123101353645, Final Batch Loss: 0.032063860446214676\n",
      "Epoch 3643, Loss: 0.040002090856432915, Final Batch Loss: 0.024288464337587357\n",
      "Epoch 3644, Loss: 0.058707986027002335, Final Batch Loss: 0.01044592633843422\n",
      "Epoch 3645, Loss: 0.0697164498269558, Final Batch Loss: 0.03343312442302704\n",
      "Epoch 3646, Loss: 0.013491689111106098, Final Batch Loss: 0.0014840149087831378\n",
      "Epoch 3647, Loss: 0.04550615604966879, Final Batch Loss: 0.008205424062907696\n",
      "Epoch 3648, Loss: 0.03238460421562195, Final Batch Loss: 0.013458142057061195\n",
      "Epoch 3649, Loss: 0.03437684942036867, Final Batch Loss: 0.003984403796494007\n",
      "Epoch 3650, Loss: 0.050342857837677, Final Batch Loss: 0.03023098222911358\n",
      "Epoch 3651, Loss: 0.057395837269723415, Final Batch Loss: 0.010677742771804333\n",
      "Epoch 3652, Loss: 0.03309388738125563, Final Batch Loss: 0.022412486374378204\n",
      "Epoch 3653, Loss: 0.018016216345131397, Final Batch Loss: 0.007158292457461357\n",
      "Epoch 3654, Loss: 0.054128373973071575, Final Batch Loss: 0.045392025262117386\n",
      "Epoch 3655, Loss: 0.07019020989537239, Final Batch Loss: 0.04533066973090172\n",
      "Epoch 3656, Loss: 0.038407113403081894, Final Batch Loss: 0.019876567646861076\n",
      "Epoch 3657, Loss: 0.040909141302108765, Final Batch Loss: 0.022754687815904617\n",
      "Epoch 3658, Loss: 0.0519693517126143, Final Batch Loss: 0.004611352924257517\n",
      "Epoch 3659, Loss: 0.041751532815396786, Final Batch Loss: 0.014338000677525997\n",
      "Epoch 3660, Loss: 0.08636119961738586, Final Batch Loss: 0.030034322291612625\n",
      "Epoch 3661, Loss: 0.06705700419843197, Final Batch Loss: 0.027072561904788017\n",
      "Epoch 3662, Loss: 0.017741401679813862, Final Batch Loss: 0.010412768460810184\n",
      "Epoch 3663, Loss: 0.028533337637782097, Final Batch Loss: 0.010019147768616676\n",
      "Epoch 3664, Loss: 0.05787220038473606, Final Batch Loss: 0.04015381261706352\n",
      "Epoch 3665, Loss: 0.07306150905787945, Final Batch Loss: 0.05652392655611038\n",
      "Epoch 3666, Loss: 0.06892098300158978, Final Batch Loss: 0.022340675815939903\n",
      "Epoch 3667, Loss: 0.09084088541567326, Final Batch Loss: 0.021074162796139717\n",
      "Epoch 3668, Loss: 0.03290225565433502, Final Batch Loss: 0.013069812208414078\n",
      "Epoch 3669, Loss: 0.054240355268120766, Final Batch Loss: 0.027578677982091904\n",
      "Epoch 3670, Loss: 0.08859197981655598, Final Batch Loss: 0.06856678426265717\n",
      "Epoch 3671, Loss: 0.0633680047467351, Final Batch Loss: 0.01033071894198656\n",
      "Epoch 3672, Loss: 0.05386323295533657, Final Batch Loss: 0.036061111837625504\n",
      "Epoch 3673, Loss: 0.06437842547893524, Final Batch Loss: 0.023997068405151367\n",
      "Epoch 3674, Loss: 0.025163370184600353, Final Batch Loss: 0.009888936765491962\n",
      "Epoch 3675, Loss: 0.03147786948829889, Final Batch Loss: 0.02419743314385414\n",
      "Epoch 3676, Loss: 0.09538142196834087, Final Batch Loss: 0.029843268916010857\n",
      "Epoch 3677, Loss: 0.07621914148330688, Final Batch Loss: 0.07177524268627167\n",
      "Epoch 3678, Loss: 0.08751178160309792, Final Batch Loss: 0.0606081448495388\n",
      "Epoch 3679, Loss: 0.0710134282708168, Final Batch Loss: 0.04742244631052017\n",
      "Epoch 3680, Loss: 0.09667769819498062, Final Batch Loss: 0.0424736812710762\n",
      "Epoch 3681, Loss: 0.024305855855345726, Final Batch Loss: 0.006053674966096878\n",
      "Epoch 3682, Loss: 0.04204742610454559, Final Batch Loss: 0.021609338000416756\n",
      "Epoch 3683, Loss: 0.10798213630914688, Final Batch Loss: 0.06601207703351974\n",
      "Epoch 3684, Loss: 0.08346075564622879, Final Batch Loss: 0.056565530598163605\n",
      "Epoch 3685, Loss: 0.0817963108420372, Final Batch Loss: 0.053537823259830475\n",
      "Epoch 3686, Loss: 0.03192170336842537, Final Batch Loss: 0.016994209960103035\n",
      "Epoch 3687, Loss: 0.07559340074658394, Final Batch Loss: 0.016256872564554214\n",
      "Epoch 3688, Loss: 0.019827323500066996, Final Batch Loss: 0.005896469112485647\n",
      "Epoch 3689, Loss: 0.05889655090868473, Final Batch Loss: 0.03235086053609848\n",
      "Epoch 3690, Loss: 0.038594769313931465, Final Batch Loss: 0.019824720919132233\n",
      "Epoch 3691, Loss: 0.03751222789287567, Final Batch Loss: 0.01863749511539936\n",
      "Epoch 3692, Loss: 0.030477574095129967, Final Batch Loss: 0.017010945826768875\n",
      "Epoch 3693, Loss: 0.034753465093672276, Final Batch Loss: 0.006007506512105465\n",
      "Epoch 3694, Loss: 0.05550517328083515, Final Batch Loss: 0.028331827372312546\n",
      "Epoch 3695, Loss: 0.050387630239129066, Final Batch Loss: 0.0317625030875206\n",
      "Epoch 3696, Loss: 0.026158527471125126, Final Batch Loss: 0.007996140979230404\n",
      "Epoch 3697, Loss: 0.06959868781268597, Final Batch Loss: 0.0233225766569376\n",
      "Epoch 3698, Loss: 0.03475662227720022, Final Batch Loss: 0.005986697040498257\n",
      "Epoch 3699, Loss: 0.04081497713923454, Final Batch Loss: 0.016919326037168503\n",
      "Epoch 3700, Loss: 0.09564950317144394, Final Batch Loss: 0.04910678789019585\n",
      "Epoch 3701, Loss: 0.13497645780444145, Final Batch Loss: 0.09163443744182587\n",
      "Epoch 3702, Loss: 0.09685074724256992, Final Batch Loss: 0.06778038293123245\n",
      "Epoch 3703, Loss: 0.059311602264642715, Final Batch Loss: 0.01068495586514473\n",
      "Epoch 3704, Loss: 0.042490238323807716, Final Batch Loss: 0.025679387152194977\n",
      "Epoch 3705, Loss: 0.07972917426377535, Final Batch Loss: 0.06588533520698547\n",
      "Epoch 3706, Loss: 0.1242060549557209, Final Batch Loss: 0.04407104477286339\n",
      "Epoch 3707, Loss: 0.07910890132188797, Final Batch Loss: 0.020227253437042236\n",
      "Epoch 3708, Loss: 0.02099343528971076, Final Batch Loss: 0.007647674065083265\n",
      "Epoch 3709, Loss: 0.08853630349040031, Final Batch Loss: 0.06279952824115753\n",
      "Epoch 3710, Loss: 0.09180720336735249, Final Batch Loss: 0.019271941855549812\n",
      "Epoch 3711, Loss: 0.07078501954674721, Final Batch Loss: 0.04742245376110077\n",
      "Epoch 3712, Loss: 0.07574291154742241, Final Batch Loss: 0.041403837502002716\n",
      "Epoch 3713, Loss: 0.05448808893561363, Final Batch Loss: 0.024875126779079437\n",
      "Epoch 3714, Loss: 0.08069713413715363, Final Batch Loss: 0.03477317467331886\n",
      "Epoch 3715, Loss: 0.04592043813318014, Final Batch Loss: 0.014931096695363522\n",
      "Epoch 3716, Loss: 0.03547245543450117, Final Batch Loss: 0.022486424073576927\n",
      "Epoch 3717, Loss: 0.05479197017848492, Final Batch Loss: 0.018500057980418205\n",
      "Epoch 3718, Loss: 0.06292635481804609, Final Batch Loss: 0.004136252216994762\n",
      "Epoch 3719, Loss: 0.02431358490139246, Final Batch Loss: 0.008128662593662739\n",
      "Epoch 3720, Loss: 0.052569965831935406, Final Batch Loss: 0.006025421433150768\n",
      "Epoch 3721, Loss: 0.09050758183002472, Final Batch Loss: 0.05543607473373413\n",
      "Epoch 3722, Loss: 0.046195538714528084, Final Batch Loss: 0.02559320628643036\n",
      "Epoch 3723, Loss: 0.08247776702046394, Final Batch Loss: 0.06115932762622833\n",
      "Epoch 3724, Loss: 0.04701245203614235, Final Batch Loss: 0.02128971554338932\n",
      "Epoch 3725, Loss: 0.06241680309176445, Final Batch Loss: 0.029080796986818314\n",
      "Epoch 3726, Loss: 0.06638802960515022, Final Batch Loss: 0.02477443590760231\n",
      "Epoch 3727, Loss: 0.06233556754887104, Final Batch Loss: 0.019273633137345314\n",
      "Epoch 3728, Loss: 0.05716004129499197, Final Batch Loss: 0.01234095823019743\n",
      "Epoch 3729, Loss: 0.045178879983723164, Final Batch Loss: 0.011763137765228748\n",
      "Epoch 3730, Loss: 0.06409759260714054, Final Batch Loss: 0.047534745186567307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3731, Loss: 0.03626661840826273, Final Batch Loss: 0.007690274156630039\n",
      "Epoch 3732, Loss: 0.03119844477623701, Final Batch Loss: 0.016331661492586136\n",
      "Epoch 3733, Loss: 0.05023820884525776, Final Batch Loss: 0.03287941962480545\n",
      "Epoch 3734, Loss: 0.020008539780974388, Final Batch Loss: 0.012141337618231773\n",
      "Epoch 3735, Loss: 0.06172407977283001, Final Batch Loss: 0.02725965715944767\n",
      "Epoch 3736, Loss: 0.04703383892774582, Final Batch Loss: 0.022121788933873177\n",
      "Epoch 3737, Loss: 0.07359669916331768, Final Batch Loss: 0.017054827883839607\n",
      "Epoch 3738, Loss: 0.020980853587388992, Final Batch Loss: 0.009149909019470215\n",
      "Epoch 3739, Loss: 0.04284509737044573, Final Batch Loss: 0.011571635492146015\n",
      "Epoch 3740, Loss: 0.028045648708939552, Final Batch Loss: 0.006837347522377968\n",
      "Epoch 3741, Loss: 0.03305928036570549, Final Batch Loss: 0.0141521655023098\n",
      "Epoch 3742, Loss: 0.033854661509394646, Final Batch Loss: 0.012939084321260452\n",
      "Epoch 3743, Loss: 0.023280696012079716, Final Batch Loss: 0.007937372662127018\n",
      "Epoch 3744, Loss: 0.059525014366954565, Final Batch Loss: 0.00769583648070693\n",
      "Epoch 3745, Loss: 0.036592329852283, Final Batch Loss: 0.009852628223598003\n",
      "Epoch 3746, Loss: 0.06166886631399393, Final Batch Loss: 0.011446313001215458\n",
      "Epoch 3747, Loss: 0.030252153053879738, Final Batch Loss: 0.016285182908177376\n",
      "Epoch 3748, Loss: 0.026216276921331882, Final Batch Loss: 0.013525519520044327\n",
      "Epoch 3749, Loss: 0.04045346565544605, Final Batch Loss: 0.016830960288643837\n",
      "Epoch 3750, Loss: 0.05630883015692234, Final Batch Loss: 0.032196834683418274\n",
      "Epoch 3751, Loss: 0.05842752940952778, Final Batch Loss: 0.028492381796240807\n",
      "Epoch 3752, Loss: 0.023893868550658226, Final Batch Loss: 0.014881356619298458\n",
      "Epoch 3753, Loss: 0.03487154841423035, Final Batch Loss: 0.022671407088637352\n",
      "Epoch 3754, Loss: 0.06750673148781061, Final Batch Loss: 0.006509826518595219\n",
      "Epoch 3755, Loss: 0.0350777986459434, Final Batch Loss: 0.02728908881545067\n",
      "Epoch 3756, Loss: 0.041465193033218384, Final Batch Loss: 0.03379521146416664\n",
      "Epoch 3757, Loss: 0.012161846738308668, Final Batch Loss: 0.008104532957077026\n",
      "Epoch 3758, Loss: 0.0615554959513247, Final Batch Loss: 0.05693370848894119\n",
      "Epoch 3759, Loss: 0.031152825336903334, Final Batch Loss: 0.007209699135273695\n",
      "Epoch 3760, Loss: 0.03263550437986851, Final Batch Loss: 0.02135067991912365\n",
      "Epoch 3761, Loss: 0.03717762790620327, Final Batch Loss: 0.01923634298145771\n",
      "Epoch 3762, Loss: 0.06918994709849358, Final Batch Loss: 0.03342632204294205\n",
      "Epoch 3763, Loss: 0.03736585192382336, Final Batch Loss: 0.009000837802886963\n",
      "Epoch 3764, Loss: 0.014643017901107669, Final Batch Loss: 0.0030718825291842222\n",
      "Epoch 3765, Loss: 0.0454565011896193, Final Batch Loss: 0.04057057201862335\n",
      "Epoch 3766, Loss: 0.04812245815992355, Final Batch Loss: 0.020531753078103065\n",
      "Epoch 3767, Loss: 0.04015640541911125, Final Batch Loss: 0.022048914805054665\n",
      "Epoch 3768, Loss: 0.035356744192540646, Final Batch Loss: 0.025188475847244263\n",
      "Epoch 3769, Loss: 0.05362231656908989, Final Batch Loss: 0.013258807361125946\n",
      "Epoch 3770, Loss: 0.07119658589363098, Final Batch Loss: 0.04341953247785568\n",
      "Epoch 3771, Loss: 0.05634551867842674, Final Batch Loss: 0.016207750886678696\n",
      "Epoch 3772, Loss: 0.10150758363306522, Final Batch Loss: 0.09466215968132019\n",
      "Epoch 3773, Loss: 0.0895066112279892, Final Batch Loss: 0.04711643606424332\n",
      "Epoch 3774, Loss: 0.033836702816188335, Final Batch Loss: 0.021011987701058388\n",
      "Epoch 3775, Loss: 0.04109626682475209, Final Batch Loss: 0.005452216137200594\n",
      "Epoch 3776, Loss: 0.07001307047903538, Final Batch Loss: 0.03932589665055275\n",
      "Epoch 3777, Loss: 0.06384606473147869, Final Batch Loss: 0.009751832112669945\n",
      "Epoch 3778, Loss: 0.09339831210672855, Final Batch Loss: 0.07200582325458527\n",
      "Epoch 3779, Loss: 0.08111748844385147, Final Batch Loss: 0.0559338815510273\n",
      "Epoch 3780, Loss: 0.06361133605241776, Final Batch Loss: 0.05302303284406662\n",
      "Epoch 3781, Loss: 0.03702221158891916, Final Batch Loss: 0.02893628552556038\n",
      "Epoch 3782, Loss: 0.07998993620276451, Final Batch Loss: 0.01822821795940399\n",
      "Epoch 3783, Loss: 0.048186780884861946, Final Batch Loss: 0.011770294979214668\n",
      "Epoch 3784, Loss: 0.03343449532985687, Final Batch Loss: 0.017668310552835464\n",
      "Epoch 3785, Loss: 0.04352917429059744, Final Batch Loss: 0.011644410900771618\n",
      "Epoch 3786, Loss: 0.03779642470180988, Final Batch Loss: 0.008834503591060638\n",
      "Epoch 3787, Loss: 0.05722827650606632, Final Batch Loss: 0.039627376943826675\n",
      "Epoch 3788, Loss: 0.026121883653104305, Final Batch Loss: 0.008185640908777714\n",
      "Epoch 3789, Loss: 0.036578839644789696, Final Batch Loss: 0.027279045432806015\n",
      "Epoch 3790, Loss: 0.06366611644625664, Final Batch Loss: 0.015263780951499939\n",
      "Epoch 3791, Loss: 0.05298569239675999, Final Batch Loss: 0.02071245200932026\n",
      "Epoch 3792, Loss: 0.10734711587429047, Final Batch Loss: 0.05713494494557381\n",
      "Epoch 3793, Loss: 0.028165645897388458, Final Batch Loss: 0.012126125395298004\n",
      "Epoch 3794, Loss: 0.0400524977594614, Final Batch Loss: 0.010756151750683784\n",
      "Epoch 3795, Loss: 0.03355803340673447, Final Batch Loss: 0.012048538774251938\n",
      "Epoch 3796, Loss: 0.04049317818135023, Final Batch Loss: 0.011957426555454731\n",
      "Epoch 3797, Loss: 0.06795975938439369, Final Batch Loss: 0.028703562915325165\n",
      "Epoch 3798, Loss: 0.054884192533791065, Final Batch Loss: 0.04642508924007416\n",
      "Epoch 3799, Loss: 0.05555386655032635, Final Batch Loss: 0.021850710734725\n",
      "Epoch 3800, Loss: 0.0618414469063282, Final Batch Loss: 0.02958596870303154\n",
      "Epoch 3801, Loss: 0.03956400603055954, Final Batch Loss: 0.03079046495258808\n",
      "Epoch 3802, Loss: 0.06301075592637062, Final Batch Loss: 0.031605951488018036\n",
      "Epoch 3803, Loss: 0.03956397157162428, Final Batch Loss: 0.014201470650732517\n",
      "Epoch 3804, Loss: 0.11202726699411869, Final Batch Loss: 0.0926300659775734\n",
      "Epoch 3805, Loss: 0.037328677251935005, Final Batch Loss: 0.011854933574795723\n",
      "Epoch 3806, Loss: 0.044130561873316765, Final Batch Loss: 0.025441639125347137\n",
      "Epoch 3807, Loss: 0.06248575076460838, Final Batch Loss: 0.04404747486114502\n",
      "Epoch 3808, Loss: 0.06695070397108793, Final Batch Loss: 0.057872604578733444\n",
      "Epoch 3809, Loss: 0.08675073739141226, Final Batch Loss: 0.07277192175388336\n",
      "Epoch 3810, Loss: 0.040359596721827984, Final Batch Loss: 0.02860734984278679\n",
      "Epoch 3811, Loss: 0.03714902838692069, Final Batch Loss: 0.005442725028842688\n",
      "Epoch 3812, Loss: 0.06091424077749252, Final Batch Loss: 0.011521190404891968\n",
      "Epoch 3813, Loss: 0.053472209721803665, Final Batch Loss: 0.03314758464694023\n",
      "Epoch 3814, Loss: 0.10516585782170296, Final Batch Loss: 0.09690221399068832\n",
      "Epoch 3815, Loss: 0.086920615285635, Final Batch Loss: 0.050740960985422134\n",
      "Epoch 3816, Loss: 0.034387052059173584, Final Batch Loss: 0.008240412920713425\n",
      "Epoch 3817, Loss: 0.02991640055552125, Final Batch Loss: 0.006677704397588968\n",
      "Epoch 3818, Loss: 0.04762718640267849, Final Batch Loss: 0.02823062427341938\n",
      "Epoch 3819, Loss: 0.03670526295900345, Final Batch Loss: 0.014240693300962448\n",
      "Epoch 3820, Loss: 0.026572640985250473, Final Batch Loss: 0.015029734000563622\n",
      "Epoch 3821, Loss: 0.0390853825956583, Final Batch Loss: 0.016736440360546112\n",
      "Epoch 3822, Loss: 0.03421131428331137, Final Batch Loss: 0.019970297813415527\n",
      "Epoch 3823, Loss: 0.057381815277040005, Final Batch Loss: 0.04772753268480301\n",
      "Epoch 3824, Loss: 0.05038888845592737, Final Batch Loss: 0.03930171579122543\n",
      "Epoch 3825, Loss: 0.04155470430850983, Final Batch Loss: 0.025183793157339096\n",
      "Epoch 3826, Loss: 0.053384535014629364, Final Batch Loss: 0.03305498883128166\n",
      "Epoch 3827, Loss: 0.02280887309461832, Final Batch Loss: 0.010194282978773117\n",
      "Epoch 3828, Loss: 0.027148285880684853, Final Batch Loss: 0.016630342230200768\n",
      "Epoch 3829, Loss: 0.06502078659832478, Final Batch Loss: 0.029525650665163994\n",
      "Epoch 3830, Loss: 0.022464320063591003, Final Batch Loss: 0.013287629932165146\n",
      "Epoch 3831, Loss: 0.04531048983335495, Final Batch Loss: 0.020599886775016785\n",
      "Epoch 3832, Loss: 0.03851786442101002, Final Batch Loss: 0.011942652985453606\n",
      "Epoch 3833, Loss: 0.0487067811191082, Final Batch Loss: 0.03850988298654556\n",
      "Epoch 3834, Loss: 0.09143224451690912, Final Batch Loss: 0.07773958891630173\n",
      "Epoch 3835, Loss: 0.08175339922308922, Final Batch Loss: 0.04686238244175911\n",
      "Epoch 3836, Loss: 0.029447082430124283, Final Batch Loss: 0.013627376407384872\n",
      "Epoch 3837, Loss: 0.05487195495516062, Final Batch Loss: 0.04291722550988197\n",
      "Epoch 3838, Loss: 0.04549991153180599, Final Batch Loss: 0.03126160427927971\n",
      "Epoch 3839, Loss: 0.04298291075974703, Final Batch Loss: 0.007960964925587177\n",
      "Epoch 3840, Loss: 0.02434959914535284, Final Batch Loss: 0.016361137852072716\n",
      "Epoch 3841, Loss: 0.04647653177380562, Final Batch Loss: 0.0063575804233551025\n",
      "Epoch 3842, Loss: 0.06882059294730425, Final Batch Loss: 0.05363360047340393\n",
      "Epoch 3843, Loss: 0.03364328760653734, Final Batch Loss: 0.007548238150775433\n",
      "Epoch 3844, Loss: 0.05428047478199005, Final Batch Loss: 0.02697545289993286\n",
      "Epoch 3845, Loss: 0.050240826793015, Final Batch Loss: 0.010722518898546696\n",
      "Epoch 3846, Loss: 0.040325827896595, Final Batch Loss: 0.018445372581481934\n",
      "Epoch 3847, Loss: 0.0296506155282259, Final Batch Loss: 0.013919312506914139\n",
      "Epoch 3848, Loss: 0.10093466052785516, Final Batch Loss: 0.0937790796160698\n",
      "Epoch 3849, Loss: 0.02629508450627327, Final Batch Loss: 0.00953923910856247\n",
      "Epoch 3850, Loss: 0.05776890553534031, Final Batch Loss: 0.0351831428706646\n",
      "Epoch 3851, Loss: 0.05945391207933426, Final Batch Loss: 0.028925905004143715\n",
      "Epoch 3852, Loss: 0.08478442952036858, Final Batch Loss: 0.06417828798294067\n",
      "Epoch 3853, Loss: 0.052637748420238495, Final Batch Loss: 0.030651848763227463\n",
      "Epoch 3854, Loss: 0.06300622969865799, Final Batch Loss: 0.03426245599985123\n",
      "Epoch 3855, Loss: 0.02247836533933878, Final Batch Loss: 0.010123616084456444\n",
      "Epoch 3856, Loss: 0.04286921117454767, Final Batch Loss: 0.029844358563423157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3857, Loss: 0.11102211475372314, Final Batch Loss: 0.0366341769695282\n",
      "Epoch 3858, Loss: 0.034887395799160004, Final Batch Loss: 0.013755561783909798\n",
      "Epoch 3859, Loss: 0.13722436875104904, Final Batch Loss: 0.0720987543463707\n",
      "Epoch 3860, Loss: 0.038289863616228104, Final Batch Loss: 0.018536321818828583\n",
      "Epoch 3861, Loss: 0.05240091122686863, Final Batch Loss: 0.028150038793683052\n",
      "Epoch 3862, Loss: 0.033547195605933666, Final Batch Loss: 0.014291553758084774\n",
      "Epoch 3863, Loss: 0.170184213668108, Final Batch Loss: 0.12327595055103302\n",
      "Epoch 3864, Loss: 0.07638087682425976, Final Batch Loss: 0.019887378439307213\n",
      "Epoch 3865, Loss: 0.08615163713693619, Final Batch Loss: 0.0747259110212326\n",
      "Epoch 3866, Loss: 0.09693988040089607, Final Batch Loss: 0.0485202930867672\n",
      "Epoch 3867, Loss: 0.0936814621090889, Final Batch Loss: 0.05645785108208656\n",
      "Epoch 3868, Loss: 0.05131830647587776, Final Batch Loss: 0.02810286544263363\n",
      "Epoch 3869, Loss: 0.07332755625247955, Final Batch Loss: 0.0370134562253952\n",
      "Epoch 3870, Loss: 0.05125699192285538, Final Batch Loss: 0.01638755202293396\n",
      "Epoch 3871, Loss: 0.08209064602851868, Final Batch Loss: 0.06497707217931747\n",
      "Epoch 3872, Loss: 0.03813745640218258, Final Batch Loss: 0.011447854340076447\n",
      "Epoch 3873, Loss: 0.07081455178558826, Final Batch Loss: 0.050663504749536514\n",
      "Epoch 3874, Loss: 0.02007596241310239, Final Batch Loss: 0.013320552185177803\n",
      "Epoch 3875, Loss: 0.04874005727469921, Final Batch Loss: 0.01761459745466709\n",
      "Epoch 3876, Loss: 0.04135413747280836, Final Batch Loss: 0.008657514117658138\n",
      "Epoch 3877, Loss: 0.015095823910087347, Final Batch Loss: 0.0035500754602253437\n",
      "Epoch 3878, Loss: 0.058278098702430725, Final Batch Loss: 0.04263053834438324\n",
      "Epoch 3879, Loss: 0.0709608681499958, Final Batch Loss: 0.03921585530042648\n",
      "Epoch 3880, Loss: 0.044857071712613106, Final Batch Loss: 0.02725541777908802\n",
      "Epoch 3881, Loss: 0.03348630643449724, Final Batch Loss: 0.0027828419115394354\n",
      "Epoch 3882, Loss: 0.03828672785311937, Final Batch Loss: 0.007853769697248936\n",
      "Epoch 3883, Loss: 0.029780722223222256, Final Batch Loss: 0.020035043358802795\n",
      "Epoch 3884, Loss: 0.03377601224929094, Final Batch Loss: 0.022430818527936935\n",
      "Epoch 3885, Loss: 0.03756124526262283, Final Batch Loss: 0.009048404172062874\n",
      "Epoch 3886, Loss: 0.04413457587361336, Final Batch Loss: 0.0167341697961092\n",
      "Epoch 3887, Loss: 0.04102305322885513, Final Batch Loss: 0.0239963810890913\n",
      "Epoch 3888, Loss: 0.06331830471754074, Final Batch Loss: 0.01451246440410614\n",
      "Epoch 3889, Loss: 0.05883300118148327, Final Batch Loss: 0.02912994660437107\n",
      "Epoch 3890, Loss: 0.07086283341050148, Final Batch Loss: 0.04715241864323616\n",
      "Epoch 3891, Loss: 0.02924583898857236, Final Batch Loss: 0.007120218593627214\n",
      "Epoch 3892, Loss: 0.042994823306798935, Final Batch Loss: 0.016016550362110138\n",
      "Epoch 3893, Loss: 0.024139723274856806, Final Batch Loss: 0.005443390924483538\n",
      "Epoch 3894, Loss: 0.01782485330477357, Final Batch Loss: 0.005644687917083502\n",
      "Epoch 3895, Loss: 0.026685192249715328, Final Batch Loss: 0.012982109561562538\n",
      "Epoch 3896, Loss: 0.024550204165279865, Final Batch Loss: 0.010486744344234467\n",
      "Epoch 3897, Loss: 0.040103303268551826, Final Batch Loss: 0.03213737532496452\n",
      "Epoch 3898, Loss: 0.0819273591041565, Final Batch Loss: 0.04422874376177788\n",
      "Epoch 3899, Loss: 0.06031337473541498, Final Batch Loss: 0.050271470099687576\n",
      "Epoch 3900, Loss: 0.04166960529983044, Final Batch Loss: 0.026601063087582588\n",
      "Epoch 3901, Loss: 0.06731922924518585, Final Batch Loss: 0.03263363987207413\n",
      "Epoch 3902, Loss: 0.033655752427875996, Final Batch Loss: 0.010875639505684376\n",
      "Epoch 3903, Loss: 0.05452081002295017, Final Batch Loss: 0.017555469647049904\n",
      "Epoch 3904, Loss: 0.02280660904943943, Final Batch Loss: 0.0062315091490745544\n",
      "Epoch 3905, Loss: 0.1007072227075696, Final Batch Loss: 0.09116110950708389\n",
      "Epoch 3906, Loss: 0.04549825843423605, Final Batch Loss: 0.032857004553079605\n",
      "Epoch 3907, Loss: 0.04069998115301132, Final Batch Loss: 0.025002455338835716\n",
      "Epoch 3908, Loss: 0.021985210478305817, Final Batch Loss: 0.007655054330825806\n",
      "Epoch 3909, Loss: 0.189902164041996, Final Batch Loss: 0.14000394940376282\n",
      "Epoch 3910, Loss: 0.06878610886633396, Final Batch Loss: 0.026922469958662987\n",
      "Epoch 3911, Loss: 0.028099440969526768, Final Batch Loss: 0.010102384723722935\n",
      "Epoch 3912, Loss: 0.014187277294695377, Final Batch Loss: 0.004920954816043377\n",
      "Epoch 3913, Loss: 0.06536458618938923, Final Batch Loss: 0.036683641374111176\n",
      "Epoch 3914, Loss: 0.03590904548764229, Final Batch Loss: 0.016762901097536087\n",
      "Epoch 3915, Loss: 0.018963404931128025, Final Batch Loss: 0.012211058288812637\n",
      "Epoch 3916, Loss: 0.05158792436122894, Final Batch Loss: 0.02453460916876793\n",
      "Epoch 3917, Loss: 0.06306664645671844, Final Batch Loss: 0.037298474460840225\n",
      "Epoch 3918, Loss: 0.042748553678393364, Final Batch Loss: 0.016559423878788948\n",
      "Epoch 3919, Loss: 0.05337115190923214, Final Batch Loss: 0.011959334835410118\n",
      "Epoch 3920, Loss: 0.03569572698324919, Final Batch Loss: 0.015511131845414639\n",
      "Epoch 3921, Loss: 0.029517119750380516, Final Batch Loss: 0.018952559679746628\n",
      "Epoch 3922, Loss: 0.061050696298480034, Final Batch Loss: 0.04095545411109924\n",
      "Epoch 3923, Loss: 0.03478603716939688, Final Batch Loss: 0.010746547020971775\n",
      "Epoch 3924, Loss: 0.10596780106425285, Final Batch Loss: 0.0773073062300682\n",
      "Epoch 3925, Loss: 0.06383566744625568, Final Batch Loss: 0.03693831339478493\n",
      "Epoch 3926, Loss: 0.13583244010806084, Final Batch Loss: 0.1147899255156517\n",
      "Epoch 3927, Loss: 0.08486835565418005, Final Batch Loss: 0.008591367863118649\n",
      "Epoch 3928, Loss: 0.07402592152357101, Final Batch Loss: 0.04226161167025566\n",
      "Epoch 3929, Loss: 0.056429979391396046, Final Batch Loss: 0.01478008646517992\n",
      "Epoch 3930, Loss: 0.027130924863740802, Final Batch Loss: 0.0035179860424250364\n",
      "Epoch 3931, Loss: 0.05631317384541035, Final Batch Loss: 0.028854602947831154\n",
      "Epoch 3932, Loss: 0.045599290169775486, Final Batch Loss: 0.031380485743284225\n",
      "Epoch 3933, Loss: 0.028654299676418304, Final Batch Loss: 0.012726608663797379\n",
      "Epoch 3934, Loss: 0.062977135181427, Final Batch Loss: 0.049570392817258835\n",
      "Epoch 3935, Loss: 0.03977613244205713, Final Batch Loss: 0.015096900053322315\n",
      "Epoch 3936, Loss: 0.08748940005898476, Final Batch Loss: 0.03319106251001358\n",
      "Epoch 3937, Loss: 0.06306570582091808, Final Batch Loss: 0.04592176526784897\n",
      "Epoch 3938, Loss: 0.07735109329223633, Final Batch Loss: 0.040079351514577866\n",
      "Epoch 3939, Loss: 0.05569751001894474, Final Batch Loss: 0.035944048315286636\n",
      "Epoch 3940, Loss: 0.03609219938516617, Final Batch Loss: 0.019461311399936676\n",
      "Epoch 3941, Loss: 0.051637038588523865, Final Batch Loss: 0.03379867598414421\n",
      "Epoch 3942, Loss: 0.07436682097613811, Final Batch Loss: 0.048226822167634964\n",
      "Epoch 3943, Loss: 0.06199185736477375, Final Batch Loss: 0.031210120767354965\n",
      "Epoch 3944, Loss: 0.05240125232376158, Final Batch Loss: 0.002564400667324662\n",
      "Epoch 3945, Loss: 0.05527353845536709, Final Batch Loss: 0.016001449897885323\n",
      "Epoch 3946, Loss: 0.03268397506326437, Final Batch Loss: 0.014515557326376438\n",
      "Epoch 3947, Loss: 0.03446010686457157, Final Batch Loss: 0.027861906215548515\n",
      "Epoch 3948, Loss: 0.03157742787152529, Final Batch Loss: 0.02335253544151783\n",
      "Epoch 3949, Loss: 0.05963604897260666, Final Batch Loss: 0.04474703595042229\n",
      "Epoch 3950, Loss: 0.028870473615825176, Final Batch Loss: 0.010734385810792446\n",
      "Epoch 3951, Loss: 0.015890586655586958, Final Batch Loss: 0.01188637875020504\n",
      "Epoch 3952, Loss: 0.03609563875943422, Final Batch Loss: 0.010104489512741566\n",
      "Epoch 3953, Loss: 0.0490553043782711, Final Batch Loss: 0.03106250800192356\n",
      "Epoch 3954, Loss: 0.03774140402674675, Final Batch Loss: 0.029089856892824173\n",
      "Epoch 3955, Loss: 0.04484655987471342, Final Batch Loss: 0.03644269332289696\n",
      "Epoch 3956, Loss: 0.045470669865608215, Final Batch Loss: 0.009537849575281143\n",
      "Epoch 3957, Loss: 0.07977020740509033, Final Batch Loss: 0.04714972898364067\n",
      "Epoch 3958, Loss: 0.032984720543026924, Final Batch Loss: 0.01695888489484787\n",
      "Epoch 3959, Loss: 0.05454442277550697, Final Batch Loss: 0.012702703475952148\n",
      "Epoch 3960, Loss: 0.028084459714591503, Final Batch Loss: 0.006797683425247669\n",
      "Epoch 3961, Loss: 0.04297351185232401, Final Batch Loss: 0.035708703100681305\n",
      "Epoch 3962, Loss: 0.06104981992393732, Final Batch Loss: 0.04736880958080292\n",
      "Epoch 3963, Loss: 0.030616451986134052, Final Batch Loss: 0.015836702659726143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3964, Loss: 0.05523451417684555, Final Batch Loss: 0.04363984242081642\n",
      "Epoch 3965, Loss: 0.019143112935125828, Final Batch Loss: 0.007803025655448437\n",
      "Epoch 3966, Loss: 0.03381329122930765, Final Batch Loss: 0.025862207636237144\n",
      "Epoch 3967, Loss: 0.0159890940412879, Final Batch Loss: 0.0060439445078372955\n",
      "Epoch 3968, Loss: 0.07218483090400696, Final Batch Loss: 0.024960815906524658\n",
      "Epoch 3969, Loss: 0.0341045381501317, Final Batch Loss: 0.011985703371465206\n",
      "Epoch 3970, Loss: 0.04037626925855875, Final Batch Loss: 0.03304792940616608\n",
      "Epoch 3971, Loss: 0.043705688789486885, Final Batch Loss: 0.019806116819381714\n",
      "Epoch 3972, Loss: 0.033651530742645264, Final Batch Loss: 0.01859002746641636\n",
      "Epoch 3973, Loss: 0.04611672228202224, Final Batch Loss: 0.0059076338075101376\n",
      "Epoch 3974, Loss: 0.02101349737495184, Final Batch Loss: 0.007171378470957279\n",
      "Epoch 3975, Loss: 0.011640844866633415, Final Batch Loss: 0.004874569829553366\n",
      "Epoch 3976, Loss: 0.09250077232718468, Final Batch Loss: 0.053187865763902664\n",
      "Epoch 3977, Loss: 0.01672474294900894, Final Batch Loss: 0.0026845233514904976\n",
      "Epoch 3978, Loss: 0.048358744010329247, Final Batch Loss: 0.010370975360274315\n",
      "Epoch 3979, Loss: 0.06703132577240467, Final Batch Loss: 0.026403414085507393\n",
      "Epoch 3980, Loss: 0.05157172679901123, Final Batch Loss: 0.02905963361263275\n",
      "Epoch 3981, Loss: 0.032090906985104084, Final Batch Loss: 0.018028413876891136\n",
      "Epoch 3982, Loss: 0.04873089864850044, Final Batch Loss: 0.026759570464491844\n",
      "Epoch 3983, Loss: 0.040793489664793015, Final Batch Loss: 0.01905735209584236\n",
      "Epoch 3984, Loss: 0.028459423687309027, Final Batch Loss: 0.02204354852437973\n",
      "Epoch 3985, Loss: 0.07367268577218056, Final Batch Loss: 0.005269814282655716\n",
      "Epoch 3986, Loss: 0.05537044815719128, Final Batch Loss: 0.016285089775919914\n",
      "Epoch 3987, Loss: 0.08707578293979168, Final Batch Loss: 0.06875458359718323\n",
      "Epoch 3988, Loss: 0.03850115090608597, Final Batch Loss: 0.008820567280054092\n",
      "Epoch 3989, Loss: 0.05363492947071791, Final Batch Loss: 0.041005928069353104\n",
      "Epoch 3990, Loss: 0.06368137896060944, Final Batch Loss: 0.0357065312564373\n",
      "Epoch 3991, Loss: 0.023796973284333944, Final Batch Loss: 0.007527881767600775\n",
      "Epoch 3992, Loss: 0.03887130506336689, Final Batch Loss: 0.022179609164595604\n",
      "Epoch 3993, Loss: 0.02450545411556959, Final Batch Loss: 0.010776410810649395\n",
      "Epoch 3994, Loss: 0.038668671157211065, Final Batch Loss: 0.03172096237540245\n",
      "Epoch 3995, Loss: 0.03493128530681133, Final Batch Loss: 0.008822001516819\n",
      "Epoch 3996, Loss: 0.05492404103279114, Final Batch Loss: 0.009958118200302124\n",
      "Epoch 3997, Loss: 0.06450996734201908, Final Batch Loss: 0.043801747262477875\n",
      "Epoch 3998, Loss: 0.030204347800463438, Final Batch Loss: 0.0046204677782952785\n",
      "Epoch 3999, Loss: 0.06976915430277586, Final Batch Loss: 0.062375593930482864\n",
      "Epoch 4000, Loss: 0.020610697101801634, Final Batch Loss: 0.013226307928562164\n",
      "Epoch 4001, Loss: 0.03660739678889513, Final Batch Loss: 0.014902333728969097\n",
      "Epoch 4002, Loss: 0.08795412257313728, Final Batch Loss: 0.03609507903456688\n",
      "Epoch 4003, Loss: 0.08182786405086517, Final Batch Loss: 0.06088816002011299\n",
      "Epoch 4004, Loss: 0.0346960611641407, Final Batch Loss: 0.02617250382900238\n",
      "Epoch 4005, Loss: 0.06501286942511797, Final Batch Loss: 0.014465724118053913\n",
      "Epoch 4006, Loss: 0.025940380059182644, Final Batch Loss: 0.015383357182145119\n",
      "Epoch 4007, Loss: 0.016062330454587936, Final Batch Loss: 0.009014151990413666\n",
      "Epoch 4008, Loss: 0.04352019354701042, Final Batch Loss: 0.01855820044875145\n",
      "Epoch 4009, Loss: 0.019785013049840927, Final Batch Loss: 0.009187099523842335\n",
      "Epoch 4010, Loss: 0.0768890306353569, Final Batch Loss: 0.038896288722753525\n",
      "Epoch 4011, Loss: 0.025498450733721256, Final Batch Loss: 0.015813691541552544\n",
      "Epoch 4012, Loss: 0.018716291524469852, Final Batch Loss: 0.003197506070137024\n",
      "Epoch 4013, Loss: 0.05860439874231815, Final Batch Loss: 0.04242156818509102\n",
      "Epoch 4014, Loss: 0.03371731098741293, Final Batch Loss: 0.014384462498128414\n",
      "Epoch 4015, Loss: 0.03252785932272673, Final Batch Loss: 0.01151383388787508\n",
      "Epoch 4016, Loss: 0.039578943978995085, Final Batch Loss: 0.005684747826308012\n",
      "Epoch 4017, Loss: 0.02606609184294939, Final Batch Loss: 0.009944022633135319\n",
      "Epoch 4018, Loss: 0.03554836520925164, Final Batch Loss: 0.007408069912344217\n",
      "Epoch 4019, Loss: 0.035927362740039825, Final Batch Loss: 0.023748544976115227\n",
      "Epoch 4020, Loss: 0.048728303983807564, Final Batch Loss: 0.03077508881688118\n",
      "Epoch 4021, Loss: 0.13845670968294144, Final Batch Loss: 0.047630615532398224\n",
      "Epoch 4022, Loss: 0.021767467260360718, Final Batch Loss: 0.009203276596963406\n",
      "Epoch 4023, Loss: 0.02173603605479002, Final Batch Loss: 0.006689812988042831\n",
      "Epoch 4024, Loss: 0.027149956673383713, Final Batch Loss: 0.008566025644540787\n",
      "Epoch 4025, Loss: 0.0465818103402853, Final Batch Loss: 0.02836831472814083\n",
      "Epoch 4026, Loss: 0.019833138678222895, Final Batch Loss: 0.012120789848268032\n",
      "Epoch 4027, Loss: 0.05291961692273617, Final Batch Loss: 0.023226920515298843\n",
      "Epoch 4028, Loss: 0.043042782694101334, Final Batch Loss: 0.02036711387336254\n",
      "Epoch 4029, Loss: 0.03499505016952753, Final Batch Loss: 0.011372937820851803\n",
      "Epoch 4030, Loss: 0.058880070224404335, Final Batch Loss: 0.02679419331252575\n",
      "Epoch 4031, Loss: 0.06265956535935402, Final Batch Loss: 0.01146998256444931\n",
      "Epoch 4032, Loss: 0.029361616354435682, Final Batch Loss: 0.0016403901390731335\n",
      "Epoch 4033, Loss: 0.08349621668457985, Final Batch Loss: 0.059376075863838196\n",
      "Epoch 4034, Loss: 0.037139907479286194, Final Batch Loss: 0.01810872182250023\n",
      "Epoch 4035, Loss: 0.0378366457298398, Final Batch Loss: 0.007949174381792545\n",
      "Epoch 4036, Loss: 0.06454608030617237, Final Batch Loss: 0.015640025958418846\n",
      "Epoch 4037, Loss: 0.04597253352403641, Final Batch Loss: 0.027002371847629547\n",
      "Epoch 4038, Loss: 0.028273093979805708, Final Batch Loss: 0.007533892523497343\n",
      "Epoch 4039, Loss: 0.07610331103205681, Final Batch Loss: 0.03463994711637497\n",
      "Epoch 4040, Loss: 0.013869308400899172, Final Batch Loss: 0.005213747266680002\n",
      "Epoch 4041, Loss: 0.025635949801653624, Final Batch Loss: 0.004039404448121786\n",
      "Epoch 4042, Loss: 0.06184874475002289, Final Batch Loss: 0.011359117925167084\n",
      "Epoch 4043, Loss: 0.04994168318808079, Final Batch Loss: 0.012707805261015892\n",
      "Epoch 4044, Loss: 0.04313746839761734, Final Batch Loss: 0.02594672329723835\n",
      "Epoch 4045, Loss: 0.05087469145655632, Final Batch Loss: 0.020888393744826317\n",
      "Epoch 4046, Loss: 0.03090524859726429, Final Batch Loss: 0.021824724972248077\n",
      "Epoch 4047, Loss: 0.0484438706189394, Final Batch Loss: 0.023772429674863815\n",
      "Epoch 4048, Loss: 0.06986933015286922, Final Batch Loss: 0.057083096355199814\n",
      "Epoch 4049, Loss: 0.04205767251551151, Final Batch Loss: 0.018999332562088966\n",
      "Epoch 4050, Loss: 0.10068925842642784, Final Batch Loss: 0.07353859394788742\n",
      "Epoch 4051, Loss: 0.03465361800044775, Final Batch Loss: 0.0207345150411129\n",
      "Epoch 4052, Loss: 0.04155108705163002, Final Batch Loss: 0.027963126078248024\n",
      "Epoch 4053, Loss: 0.08381901308894157, Final Batch Loss: 0.06498545408248901\n",
      "Epoch 4054, Loss: 0.06346993986517191, Final Batch Loss: 0.007872537709772587\n",
      "Epoch 4055, Loss: 0.06360218301415443, Final Batch Loss: 0.028038397431373596\n",
      "Epoch 4056, Loss: 0.06825202330946922, Final Batch Loss: 0.028036396950483322\n",
      "Epoch 4057, Loss: 0.06651711277663708, Final Batch Loss: 0.02268984355032444\n",
      "Epoch 4058, Loss: 0.026852005161345005, Final Batch Loss: 0.009977140463888645\n",
      "Epoch 4059, Loss: 0.12054938822984695, Final Batch Loss: 0.07271338999271393\n",
      "Epoch 4060, Loss: 0.03572116419672966, Final Batch Loss: 0.015741894021630287\n",
      "Epoch 4061, Loss: 0.04030153946951032, Final Batch Loss: 0.007404517848044634\n",
      "Epoch 4062, Loss: 0.0503929378464818, Final Batch Loss: 0.03732740134000778\n",
      "Epoch 4063, Loss: 0.07409677933901548, Final Batch Loss: 0.058895014226436615\n",
      "Epoch 4064, Loss: 0.06064494326710701, Final Batch Loss: 0.04298434779047966\n",
      "Epoch 4065, Loss: 0.05201123654842377, Final Batch Loss: 0.03066813200712204\n",
      "Epoch 4066, Loss: 0.04675477184355259, Final Batch Loss: 0.028519699349999428\n",
      "Epoch 4067, Loss: 0.035456012934446335, Final Batch Loss: 0.01771877147257328\n",
      "Epoch 4068, Loss: 0.031200872734189034, Final Batch Loss: 0.01637021265923977\n",
      "Epoch 4069, Loss: 0.1024609636515379, Final Batch Loss: 0.07375568151473999\n",
      "Epoch 4070, Loss: 0.039619642309844494, Final Batch Loss: 0.011005259118974209\n",
      "Epoch 4071, Loss: 0.06374027021229267, Final Batch Loss: 0.03582848981022835\n",
      "Epoch 4072, Loss: 0.07171682640910149, Final Batch Loss: 0.03265804424881935\n",
      "Epoch 4073, Loss: 0.14824405685067177, Final Batch Loss: 0.11638704687356949\n",
      "Epoch 4074, Loss: 0.12749864906072617, Final Batch Loss: 0.07987842708826065\n",
      "Epoch 4075, Loss: 0.05860455986112356, Final Batch Loss: 0.014870389364659786\n",
      "Epoch 4076, Loss: 0.06260173209011555, Final Batch Loss: 0.028424600139260292\n",
      "Epoch 4077, Loss: 0.146176278591156, Final Batch Loss: 0.0655898004770279\n",
      "Epoch 4078, Loss: 0.05573303624987602, Final Batch Loss: 0.02666601538658142\n",
      "Epoch 4079, Loss: 0.14644714444875717, Final Batch Loss: 0.06529395282268524\n",
      "Epoch 4080, Loss: 0.05377455987036228, Final Batch Loss: 0.012150121852755547\n",
      "Epoch 4081, Loss: 0.15618928708136082, Final Batch Loss: 0.12590181827545166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4082, Loss: 0.09782584942877293, Final Batch Loss: 0.06939584761857986\n",
      "Epoch 4083, Loss: 0.03950747475028038, Final Batch Loss: 0.021579686552286148\n",
      "Epoch 4084, Loss: 0.06004383787512779, Final Batch Loss: 0.03076954558491707\n",
      "Epoch 4085, Loss: 0.06998565047979355, Final Batch Loss: 0.03711884841322899\n",
      "Epoch 4086, Loss: 0.06025371514260769, Final Batch Loss: 0.04443204030394554\n",
      "Epoch 4087, Loss: 0.060117374174296856, Final Batch Loss: 0.01370298769325018\n",
      "Epoch 4088, Loss: 0.03888747841119766, Final Batch Loss: 0.009507598355412483\n",
      "Epoch 4089, Loss: 0.030847110552713275, Final Batch Loss: 0.003519781632348895\n",
      "Epoch 4090, Loss: 0.029469470493495464, Final Batch Loss: 0.011281977407634258\n",
      "Epoch 4091, Loss: 0.03619134984910488, Final Batch Loss: 0.01219397783279419\n",
      "Epoch 4092, Loss: 0.10262964479625225, Final Batch Loss: 0.07474547624588013\n",
      "Epoch 4093, Loss: 0.061721181496977806, Final Batch Loss: 0.020669152960181236\n",
      "Epoch 4094, Loss: 0.0934922844171524, Final Batch Loss: 0.05094710737466812\n",
      "Epoch 4095, Loss: 0.04442266374826431, Final Batch Loss: 0.017889192327857018\n",
      "Epoch 4096, Loss: 0.026771019212901592, Final Batch Loss: 0.011105705983936787\n",
      "Epoch 4097, Loss: 0.060868844389915466, Final Batch Loss: 0.029460154473781586\n",
      "Epoch 4098, Loss: 0.026774952188134193, Final Batch Loss: 0.012692565098404884\n",
      "Epoch 4099, Loss: 0.04124290309846401, Final Batch Loss: 0.025382820516824722\n",
      "Epoch 4100, Loss: 0.020050100050866604, Final Batch Loss: 0.009034152142703533\n",
      "Epoch 4101, Loss: 0.05961589328944683, Final Batch Loss: 0.02310260199010372\n",
      "Epoch 4102, Loss: 0.06700493209064007, Final Batch Loss: 0.03888174891471863\n",
      "Epoch 4103, Loss: 0.04066149238497019, Final Batch Loss: 0.03025473654270172\n",
      "Epoch 4104, Loss: 0.026707596378400922, Final Batch Loss: 0.003732749493792653\n",
      "Epoch 4105, Loss: 0.043330240063369274, Final Batch Loss: 0.030737945809960365\n",
      "Epoch 4106, Loss: 0.0359631534665823, Final Batch Loss: 0.015624282881617546\n",
      "Epoch 4107, Loss: 0.04829666577279568, Final Batch Loss: 0.01036427728831768\n",
      "Epoch 4108, Loss: 0.030285369604825974, Final Batch Loss: 0.005812790244817734\n",
      "Epoch 4109, Loss: 0.015348228625953197, Final Batch Loss: 0.0072356415912508965\n",
      "Epoch 4110, Loss: 0.05414726212620735, Final Batch Loss: 0.0318135991692543\n",
      "Epoch 4111, Loss: 0.062006331980228424, Final Batch Loss: 0.041781481355428696\n",
      "Epoch 4112, Loss: 0.04111531935632229, Final Batch Loss: 0.0303391981869936\n",
      "Epoch 4113, Loss: 0.05229316093027592, Final Batch Loss: 0.03251869976520538\n",
      "Epoch 4114, Loss: 0.03751397039741278, Final Batch Loss: 0.012732903473079205\n",
      "Epoch 4115, Loss: 0.024170625023543835, Final Batch Loss: 0.011591621674597263\n",
      "Epoch 4116, Loss: 0.06146998517215252, Final Batch Loss: 0.03789924457669258\n",
      "Epoch 4117, Loss: 0.03424038179218769, Final Batch Loss: 0.011474056169390678\n",
      "Epoch 4118, Loss: 0.0321383778937161, Final Batch Loss: 0.026567582041025162\n",
      "Epoch 4119, Loss: 0.033720516599714756, Final Batch Loss: 0.008389427326619625\n",
      "Epoch 4120, Loss: 0.07874877657741308, Final Batch Loss: 0.06822232156991959\n",
      "Epoch 4121, Loss: 0.026825059205293655, Final Batch Loss: 0.0171694066375494\n",
      "Epoch 4122, Loss: 0.036798978224396706, Final Batch Loss: 0.01289243996143341\n",
      "Epoch 4123, Loss: 0.057449592277407646, Final Batch Loss: 0.018323345109820366\n",
      "Epoch 4124, Loss: 0.059091111179441214, Final Batch Loss: 0.004260023590177298\n",
      "Epoch 4125, Loss: 0.06040691211819649, Final Batch Loss: 0.032064467668533325\n",
      "Epoch 4126, Loss: 0.04361867904663086, Final Batch Loss: 0.019349928945302963\n",
      "Epoch 4127, Loss: 0.04284078814089298, Final Batch Loss: 0.024994568899273872\n",
      "Epoch 4128, Loss: 0.049624644219875336, Final Batch Loss: 0.03326542675495148\n",
      "Epoch 4129, Loss: 0.07319354638457298, Final Batch Loss: 0.050979942083358765\n",
      "Epoch 4130, Loss: 0.06689809635281563, Final Batch Loss: 0.04140849784016609\n",
      "Epoch 4131, Loss: 0.02775907889008522, Final Batch Loss: 0.017491059377789497\n",
      "Epoch 4132, Loss: 0.03926971182227135, Final Batch Loss: 0.026595961302518845\n",
      "Epoch 4133, Loss: 0.0783473877236247, Final Batch Loss: 0.06823235750198364\n",
      "Epoch 4134, Loss: 0.016932349652051926, Final Batch Loss: 0.011739896610379219\n",
      "Epoch 4135, Loss: 0.027560514397919178, Final Batch Loss: 0.0028956932947039604\n",
      "Epoch 4136, Loss: 0.08535835333168507, Final Batch Loss: 0.0723494216799736\n",
      "Epoch 4137, Loss: 0.08213017135858536, Final Batch Loss: 0.038013797253370285\n",
      "Epoch 4138, Loss: 0.058788590133190155, Final Batch Loss: 0.037032268941402435\n",
      "Epoch 4139, Loss: 0.014647775329649448, Final Batch Loss: 0.00622245017439127\n",
      "Epoch 4140, Loss: 0.03340957406908274, Final Batch Loss: 0.010311133228242397\n",
      "Epoch 4141, Loss: 0.10183708555996418, Final Batch Loss: 0.02924657054245472\n",
      "Epoch 4142, Loss: 0.029434841126203537, Final Batch Loss: 0.009287988767027855\n",
      "Epoch 4143, Loss: 0.044373088516294956, Final Batch Loss: 0.03443596139550209\n",
      "Epoch 4144, Loss: 0.04801132529973984, Final Batch Loss: 0.015461131930351257\n",
      "Epoch 4145, Loss: 0.027841069269925356, Final Batch Loss: 0.020742040127515793\n",
      "Epoch 4146, Loss: 0.024514303542673588, Final Batch Loss: 0.019792569801211357\n",
      "Epoch 4147, Loss: 0.08096860349178314, Final Batch Loss: 0.05964817479252815\n",
      "Epoch 4148, Loss: 0.02160088298842311, Final Batch Loss: 0.007014385890215635\n",
      "Epoch 4149, Loss: 0.06649473682045937, Final Batch Loss: 0.016453508287668228\n",
      "Epoch 4150, Loss: 0.05778704769909382, Final Batch Loss: 0.03472462296485901\n",
      "Epoch 4151, Loss: 0.047331043519079685, Final Batch Loss: 0.034376952797174454\n",
      "Epoch 4152, Loss: 0.021391008980572224, Final Batch Loss: 0.006087698973715305\n",
      "Epoch 4153, Loss: 0.021148764062672853, Final Batch Loss: 0.004654897842556238\n",
      "Epoch 4154, Loss: 0.04078728426247835, Final Batch Loss: 0.015002216212451458\n",
      "Epoch 4155, Loss: 0.05783556401729584, Final Batch Loss: 0.02968713454902172\n",
      "Epoch 4156, Loss: 0.1251337267458439, Final Batch Loss: 0.1015518382191658\n",
      "Epoch 4157, Loss: 0.017823778558522463, Final Batch Loss: 0.010238965041935444\n",
      "Epoch 4158, Loss: 0.03980366140604019, Final Batch Loss: 0.01879015937447548\n",
      "Epoch 4159, Loss: 0.04956127889454365, Final Batch Loss: 0.03159879893064499\n",
      "Epoch 4160, Loss: 0.03608699422329664, Final Batch Loss: 0.003976001404225826\n",
      "Epoch 4161, Loss: 0.036902882158756256, Final Batch Loss: 0.028504231944680214\n",
      "Epoch 4162, Loss: 0.04509806074202061, Final Batch Loss: 0.028083009645342827\n",
      "Epoch 4163, Loss: 0.022646128199994564, Final Batch Loss: 0.00899236835539341\n",
      "Epoch 4164, Loss: 0.019151242449879646, Final Batch Loss: 0.011765480041503906\n",
      "Epoch 4165, Loss: 0.03777625085785985, Final Batch Loss: 0.03376968204975128\n",
      "Epoch 4166, Loss: 0.02622660156339407, Final Batch Loss: 0.01971001923084259\n",
      "Epoch 4167, Loss: 0.0562991164624691, Final Batch Loss: 0.04764958471059799\n",
      "Epoch 4168, Loss: 0.036692127119749784, Final Batch Loss: 0.005852050613611937\n",
      "Epoch 4169, Loss: 0.08818777557462454, Final Batch Loss: 0.009221210144460201\n",
      "Epoch 4170, Loss: 0.046359192579984665, Final Batch Loss: 0.030703041702508926\n",
      "Epoch 4171, Loss: 0.06690027937293053, Final Batch Loss: 0.05097552388906479\n",
      "Epoch 4172, Loss: 0.07225579768419266, Final Batch Loss: 0.0606817826628685\n",
      "Epoch 4173, Loss: 0.03154357708990574, Final Batch Loss: 0.019840791821479797\n",
      "Epoch 4174, Loss: 0.025133376708254218, Final Batch Loss: 0.0028285456355661154\n",
      "Epoch 4175, Loss: 0.016895947512239218, Final Batch Loss: 0.009936603717505932\n",
      "Epoch 4176, Loss: 0.016721033491194248, Final Batch Loss: 0.006393576040863991\n",
      "Epoch 4177, Loss: 0.016174781136214733, Final Batch Loss: 0.00792741123586893\n",
      "Epoch 4178, Loss: 0.0744127631187439, Final Batch Loss: 0.022279594093561172\n",
      "Epoch 4179, Loss: 0.05268571339547634, Final Batch Loss: 0.01025463081896305\n",
      "Epoch 4180, Loss: 0.033663463313132524, Final Batch Loss: 0.006215760949999094\n",
      "Epoch 4181, Loss: 0.0419858954846859, Final Batch Loss: 0.018341779708862305\n",
      "Epoch 4182, Loss: 0.03099422063678503, Final Batch Loss: 0.014737174846231937\n",
      "Epoch 4183, Loss: 0.05198952695354819, Final Batch Loss: 0.007025150116533041\n",
      "Epoch 4184, Loss: 0.04279387928545475, Final Batch Loss: 0.013435885310173035\n",
      "Epoch 4185, Loss: 0.055001985281705856, Final Batch Loss: 0.029202990233898163\n",
      "Epoch 4186, Loss: 0.02533192466944456, Final Batch Loss: 0.013728472404181957\n",
      "Epoch 4187, Loss: 0.10831550136208534, Final Batch Loss: 0.08639071881771088\n",
      "Epoch 4188, Loss: 0.02990814298391342, Final Batch Loss: 0.016119197010993958\n",
      "Epoch 4189, Loss: 0.04149226006120443, Final Batch Loss: 0.012705287896096706\n",
      "Epoch 4190, Loss: 0.04087571706622839, Final Batch Loss: 0.012606133706867695\n",
      "Epoch 4191, Loss: 0.02032224927097559, Final Batch Loss: 0.011448497883975506\n",
      "Epoch 4192, Loss: 0.030151241458952427, Final Batch Loss: 0.00727101881057024\n",
      "Epoch 4193, Loss: 0.015619158977642655, Final Batch Loss: 0.0037327709142118692\n",
      "Epoch 4194, Loss: 0.016945877578109503, Final Batch Loss: 0.007555424701422453\n",
      "Epoch 4195, Loss: 0.03204837255179882, Final Batch Loss: 0.0213336031883955\n",
      "Epoch 4196, Loss: 0.03389029670506716, Final Batch Loss: 0.009497872553765774\n",
      "Epoch 4197, Loss: 0.058321207761764526, Final Batch Loss: 0.03446558490395546\n",
      "Epoch 4198, Loss: 0.042407065629959106, Final Batch Loss: 0.015924494713544846\n",
      "Epoch 4199, Loss: 0.02650962397456169, Final Batch Loss: 0.008185077458620071\n",
      "Epoch 4200, Loss: 0.048711986280977726, Final Batch Loss: 0.008489218540489674\n",
      "Epoch 4201, Loss: 0.043095771223306656, Final Batch Loss: 0.02676653116941452\n",
      "Epoch 4202, Loss: 0.06389857269823551, Final Batch Loss: 0.03494800999760628\n",
      "Epoch 4203, Loss: 0.06822261027991772, Final Batch Loss: 0.045226652175188065\n",
      "Epoch 4204, Loss: 0.0293216067366302, Final Batch Loss: 0.022462377324700356\n",
      "Epoch 4205, Loss: 0.013987930491566658, Final Batch Loss: 0.005065716803073883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4206, Loss: 0.010661468841135502, Final Batch Loss: 0.002820117399096489\n",
      "Epoch 4207, Loss: 0.02030364330857992, Final Batch Loss: 0.006020977161824703\n",
      "Epoch 4208, Loss: 0.03427513130009174, Final Batch Loss: 0.006135111674666405\n",
      "Epoch 4209, Loss: 0.06717724353075027, Final Batch Loss: 0.020418789237737656\n",
      "Epoch 4210, Loss: 0.029289228841662407, Final Batch Loss: 0.011311005800962448\n",
      "Epoch 4211, Loss: 0.03562959935516119, Final Batch Loss: 0.029491467401385307\n",
      "Epoch 4212, Loss: 0.04935641400516033, Final Batch Loss: 0.027520840987563133\n",
      "Epoch 4213, Loss: 0.059126428328454494, Final Batch Loss: 0.004649492911994457\n",
      "Epoch 4214, Loss: 0.028875897638499737, Final Batch Loss: 0.008518981747329235\n",
      "Epoch 4215, Loss: 0.02737194299697876, Final Batch Loss: 0.012225975282490253\n",
      "Epoch 4216, Loss: 0.035694670397788286, Final Batch Loss: 0.007407851982861757\n",
      "Epoch 4217, Loss: 0.03594203246757388, Final Batch Loss: 0.00485281040892005\n",
      "Epoch 4218, Loss: 0.038165132980793715, Final Batch Loss: 0.004274267237633467\n",
      "Epoch 4219, Loss: 0.06324388133361936, Final Batch Loss: 0.006559405941516161\n",
      "Epoch 4220, Loss: 0.045165179297327995, Final Batch Loss: 0.023474378511309624\n",
      "Epoch 4221, Loss: 0.04580739792436361, Final Batch Loss: 0.01298606675118208\n",
      "Epoch 4222, Loss: 0.017434784211218357, Final Batch Loss: 0.005181136541068554\n",
      "Epoch 4223, Loss: 0.02373493555933237, Final Batch Loss: 0.014817675575613976\n",
      "Epoch 4224, Loss: 0.06253770366311073, Final Batch Loss: 0.041101887822151184\n",
      "Epoch 4225, Loss: 0.023351782001554966, Final Batch Loss: 0.004531732760369778\n",
      "Epoch 4226, Loss: 0.026307882741093636, Final Batch Loss: 0.005415160208940506\n",
      "Epoch 4227, Loss: 0.05395999178290367, Final Batch Loss: 0.03684404492378235\n",
      "Epoch 4228, Loss: 0.035000916570425034, Final Batch Loss: 0.015335431322455406\n",
      "Epoch 4229, Loss: 0.06065049162134528, Final Batch Loss: 0.007474669720977545\n",
      "Epoch 4230, Loss: 0.03499342501163483, Final Batch Loss: 0.010171497240662575\n",
      "Epoch 4231, Loss: 0.019597086124122143, Final Batch Loss: 0.010644531808793545\n",
      "Epoch 4232, Loss: 0.065153568983078, Final Batch Loss: 0.03210189566016197\n",
      "Epoch 4233, Loss: 0.059297602623701096, Final Batch Loss: 0.03701561316847801\n",
      "Epoch 4234, Loss: 0.03494033683091402, Final Batch Loss: 0.008199094794690609\n",
      "Epoch 4235, Loss: 0.026435249485075474, Final Batch Loss: 0.0066690100356936455\n",
      "Epoch 4236, Loss: 0.10626273043453693, Final Batch Loss: 0.08375190198421478\n",
      "Epoch 4237, Loss: 0.05806002393364906, Final Batch Loss: 0.016194425523281097\n",
      "Epoch 4238, Loss: 0.046085748821496964, Final Batch Loss: 0.03501206636428833\n",
      "Epoch 4239, Loss: 0.06072278879582882, Final Batch Loss: 0.014710275456309319\n",
      "Epoch 4240, Loss: 0.05626161769032478, Final Batch Loss: 0.020812328904867172\n",
      "Epoch 4241, Loss: 0.08635885268449783, Final Batch Loss: 0.0332924947142601\n",
      "Epoch 4242, Loss: 0.05621260963380337, Final Batch Loss: 0.01735466904938221\n",
      "Epoch 4243, Loss: 0.07614242658019066, Final Batch Loss: 0.0328192412853241\n",
      "Epoch 4244, Loss: 0.038298347033560276, Final Batch Loss: 0.02362360991537571\n",
      "Epoch 4245, Loss: 0.06826165085658431, Final Batch Loss: 0.005610679741948843\n",
      "Epoch 4246, Loss: 0.14650676026940346, Final Batch Loss: 0.12967880070209503\n",
      "Epoch 4247, Loss: 0.079665282741189, Final Batch Loss: 0.05138358473777771\n",
      "Epoch 4248, Loss: 0.08650210872292519, Final Batch Loss: 0.04853931814432144\n",
      "Epoch 4249, Loss: 0.08360105380415916, Final Batch Loss: 0.03230825439095497\n",
      "Epoch 4250, Loss: 0.14998901635408401, Final Batch Loss: 0.11423931270837784\n",
      "Epoch 4251, Loss: 0.05423560552299023, Final Batch Loss: 0.007320145145058632\n",
      "Epoch 4252, Loss: 0.05795264430344105, Final Batch Loss: 0.013006700202822685\n",
      "Epoch 4253, Loss: 0.14935199171304703, Final Batch Loss: 0.05642087012529373\n",
      "Epoch 4254, Loss: 0.14142829924821854, Final Batch Loss: 0.05585584044456482\n",
      "Epoch 4255, Loss: 0.06906678527593613, Final Batch Loss: 0.0323413722217083\n",
      "Epoch 4256, Loss: 0.1783563829958439, Final Batch Loss: 0.14236615598201752\n",
      "Epoch 4257, Loss: 0.05800615809857845, Final Batch Loss: 0.042174775153398514\n",
      "Epoch 4258, Loss: 0.07939280942082405, Final Batch Loss: 0.04064958542585373\n",
      "Epoch 4259, Loss: 0.05949834920465946, Final Batch Loss: 0.014393316581845284\n",
      "Epoch 4260, Loss: 0.07764573022723198, Final Batch Loss: 0.03247135132551193\n",
      "Epoch 4261, Loss: 0.024629742838442326, Final Batch Loss: 0.00761192012578249\n",
      "Epoch 4262, Loss: 0.09194165095686913, Final Batch Loss: 0.044384658336639404\n",
      "Epoch 4263, Loss: 0.07269704155623913, Final Batch Loss: 0.05510196462273598\n",
      "Epoch 4264, Loss: 0.058822352439165115, Final Batch Loss: 0.0425131618976593\n",
      "Epoch 4265, Loss: 0.07699964009225368, Final Batch Loss: 0.0186296459287405\n",
      "Epoch 4266, Loss: 0.0707105603069067, Final Batch Loss: 0.051361992955207825\n",
      "Epoch 4267, Loss: 0.06460265535861254, Final Batch Loss: 0.05097965896129608\n",
      "Epoch 4268, Loss: 0.10796786844730377, Final Batch Loss: 0.0591169148683548\n",
      "Epoch 4269, Loss: 0.05529558099806309, Final Batch Loss: 0.028194596990942955\n",
      "Epoch 4270, Loss: 0.03080058842897415, Final Batch Loss: 0.020044006407260895\n",
      "Epoch 4271, Loss: 0.0680623147636652, Final Batch Loss: 0.05145201459527016\n",
      "Epoch 4272, Loss: 0.1360553875565529, Final Batch Loss: 0.060214243829250336\n",
      "Epoch 4273, Loss: 0.040517259389162064, Final Batch Loss: 0.03173883631825447\n",
      "Epoch 4274, Loss: 0.04644622653722763, Final Batch Loss: 0.032238636165857315\n",
      "Epoch 4275, Loss: 0.05994376167654991, Final Batch Loss: 0.021777376532554626\n",
      "Epoch 4276, Loss: 0.07890993542969227, Final Batch Loss: 0.06308668106794357\n",
      "Epoch 4277, Loss: 0.07548603042960167, Final Batch Loss: 0.03259991854429245\n",
      "Epoch 4278, Loss: 0.042130012065172195, Final Batch Loss: 0.019783494994044304\n",
      "Epoch 4279, Loss: 0.07749693281948566, Final Batch Loss: 0.0636458620429039\n",
      "Epoch 4280, Loss: 0.04210318252444267, Final Batch Loss: 0.015793709084391594\n",
      "Epoch 4281, Loss: 0.07394738867878914, Final Batch Loss: 0.025561131536960602\n",
      "Epoch 4282, Loss: 0.05963808484375477, Final Batch Loss: 0.03936607018113136\n",
      "Epoch 4283, Loss: 0.03298071678727865, Final Batch Loss: 0.01138074230402708\n",
      "Epoch 4284, Loss: 0.03819816932082176, Final Batch Loss: 0.017124686390161514\n",
      "Epoch 4285, Loss: 0.056877308525145054, Final Batch Loss: 0.012944293208420277\n",
      "Epoch 4286, Loss: 0.036485292948782444, Final Batch Loss: 0.01354640070348978\n",
      "Epoch 4287, Loss: 0.04121267609298229, Final Batch Loss: 0.02257390320301056\n",
      "Epoch 4288, Loss: 0.052055226638913155, Final Batch Loss: 0.015964319929480553\n",
      "Epoch 4289, Loss: 0.08365285955369473, Final Batch Loss: 0.06168918311595917\n",
      "Epoch 4290, Loss: 0.10512332990765572, Final Batch Loss: 0.07112480700016022\n",
      "Epoch 4291, Loss: 0.10128530487418175, Final Batch Loss: 0.0610460601747036\n",
      "Epoch 4292, Loss: 0.03022631350904703, Final Batch Loss: 0.014301673509180546\n",
      "Epoch 4293, Loss: 0.07059607841074467, Final Batch Loss: 0.02402040921151638\n",
      "Epoch 4294, Loss: 0.031119801104068756, Final Batch Loss: 0.019312595948576927\n",
      "Epoch 4295, Loss: 0.06657322682440281, Final Batch Loss: 0.024786366149783134\n",
      "Epoch 4296, Loss: 0.05120321549475193, Final Batch Loss: 0.031203562393784523\n",
      "Epoch 4297, Loss: 0.051237357780337334, Final Batch Loss: 0.011666325852274895\n",
      "Epoch 4298, Loss: 0.02932708989828825, Final Batch Loss: 0.013877182267606258\n",
      "Epoch 4299, Loss: 0.05142476037144661, Final Batch Loss: 0.021902775391936302\n",
      "Epoch 4300, Loss: 0.09266263619065285, Final Batch Loss: 0.048584647476673126\n",
      "Epoch 4301, Loss: 0.028884890489280224, Final Batch Loss: 0.011612494476139545\n",
      "Epoch 4302, Loss: 0.028975178487598896, Final Batch Loss: 0.017014598473906517\n",
      "Epoch 4303, Loss: 0.05959846545010805, Final Batch Loss: 0.05238733068108559\n",
      "Epoch 4304, Loss: 0.08768992125988007, Final Batch Loss: 0.052836716175079346\n",
      "Epoch 4305, Loss: 0.056419143453240395, Final Batch Loss: 0.03336220234632492\n",
      "Epoch 4306, Loss: 0.08756408840417862, Final Batch Loss: 0.032770268619060516\n",
      "Epoch 4307, Loss: 0.06204803381115198, Final Batch Loss: 0.049691107124090195\n",
      "Epoch 4308, Loss: 0.0874580591917038, Final Batch Loss: 0.04706814885139465\n",
      "Epoch 4309, Loss: 0.05035579949617386, Final Batch Loss: 0.009264014661312103\n",
      "Epoch 4310, Loss: 0.041194939985871315, Final Batch Loss: 0.023615015670657158\n",
      "Epoch 4311, Loss: 0.09252243675291538, Final Batch Loss: 0.06547962129116058\n",
      "Epoch 4312, Loss: 0.045627154409885406, Final Batch Loss: 0.02841939963400364\n",
      "Epoch 4313, Loss: 0.04233517870306969, Final Batch Loss: 0.02257498912513256\n",
      "Epoch 4314, Loss: 0.041088638827204704, Final Batch Loss: 0.02230469137430191\n",
      "Epoch 4315, Loss: 0.0645283730700612, Final Batch Loss: 0.011041072197258472\n",
      "Epoch 4316, Loss: 0.029043717309832573, Final Batch Loss: 0.010282425209879875\n",
      "Epoch 4317, Loss: 0.03829216491430998, Final Batch Loss: 0.02270081639289856\n",
      "Epoch 4318, Loss: 0.03477276489138603, Final Batch Loss: 0.023888569325208664\n",
      "Epoch 4319, Loss: 0.12631957605481148, Final Batch Loss: 0.07164108753204346\n",
      "Epoch 4320, Loss: 0.06757704354822636, Final Batch Loss: 0.04797524958848953\n",
      "Epoch 4321, Loss: 0.06979159452021122, Final Batch Loss: 0.04470868408679962\n",
      "Epoch 4322, Loss: 0.028893963433802128, Final Batch Loss: 0.01881001703441143\n",
      "Epoch 4323, Loss: 0.057076772674918175, Final Batch Loss: 0.03064086101949215\n",
      "Epoch 4324, Loss: 0.017530682031065226, Final Batch Loss: 0.00635203393176198\n",
      "Epoch 4325, Loss: 0.08334401994943619, Final Batch Loss: 0.02607721835374832\n",
      "Epoch 4326, Loss: 0.08748845849186182, Final Batch Loss: 0.006718368269503117\n",
      "Epoch 4327, Loss: 0.0972779169678688, Final Batch Loss: 0.0861542671918869\n",
      "Epoch 4328, Loss: 0.08053936250507832, Final Batch Loss: 0.07007964700460434\n",
      "Epoch 4329, Loss: 0.09186015278100967, Final Batch Loss: 0.019516155123710632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4330, Loss: 0.05509740300476551, Final Batch Loss: 0.022524183616042137\n",
      "Epoch 4331, Loss: 0.04230482131242752, Final Batch Loss: 0.026255911216139793\n",
      "Epoch 4332, Loss: 0.021574423648416996, Final Batch Loss: 0.00783148780465126\n",
      "Epoch 4333, Loss: 0.08905311534181237, Final Batch Loss: 0.08172374218702316\n",
      "Epoch 4334, Loss: 0.09053949266672134, Final Batch Loss: 0.06510553508996964\n",
      "Epoch 4335, Loss: 0.05311162211000919, Final Batch Loss: 0.012071071192622185\n",
      "Epoch 4336, Loss: 0.09673869423568249, Final Batch Loss: 0.06988610327243805\n",
      "Epoch 4337, Loss: 0.0569097176194191, Final Batch Loss: 0.024700138717889786\n",
      "Epoch 4338, Loss: 0.032334369607269764, Final Batch Loss: 0.017936408519744873\n",
      "Epoch 4339, Loss: 0.04883892089128494, Final Batch Loss: 0.02375967428088188\n",
      "Epoch 4340, Loss: 0.07064591906964779, Final Batch Loss: 0.028528129681944847\n",
      "Epoch 4341, Loss: 0.08811933174729347, Final Batch Loss: 0.05382706597447395\n",
      "Epoch 4342, Loss: 0.04986508935689926, Final Batch Loss: 0.009936127811670303\n",
      "Epoch 4343, Loss: 0.07387700863182545, Final Batch Loss: 0.027417225763201714\n",
      "Epoch 4344, Loss: 0.05687331221997738, Final Batch Loss: 0.01649295724928379\n",
      "Epoch 4345, Loss: 0.037865868769586086, Final Batch Loss: 0.010614116676151752\n",
      "Epoch 4346, Loss: 0.059505694545805454, Final Batch Loss: 0.007824436761438847\n",
      "Epoch 4347, Loss: 0.046702682971954346, Final Batch Loss: 0.023126769810914993\n",
      "Epoch 4348, Loss: 0.021806059405207634, Final Batch Loss: 0.010616369545459747\n",
      "Epoch 4349, Loss: 0.09505495429039001, Final Batch Loss: 0.06325245648622513\n",
      "Epoch 4350, Loss: 0.03219674341380596, Final Batch Loss: 0.019039541482925415\n",
      "Epoch 4351, Loss: 0.06262527965009212, Final Batch Loss: 0.043074820190668106\n",
      "Epoch 4352, Loss: 0.05740273976698518, Final Batch Loss: 0.004076758865267038\n",
      "Epoch 4353, Loss: 0.043727004900574684, Final Batch Loss: 0.014543984085321426\n",
      "Epoch 4354, Loss: 0.03806273639202118, Final Batch Loss: 0.02922482043504715\n",
      "Epoch 4355, Loss: 0.08952116966247559, Final Batch Loss: 0.048176348209381104\n",
      "Epoch 4356, Loss: 0.03905772045254707, Final Batch Loss: 0.02639857679605484\n",
      "Epoch 4357, Loss: 0.06716267950832844, Final Batch Loss: 0.025359196588397026\n",
      "Epoch 4358, Loss: 0.027664706110954285, Final Batch Loss: 0.009154945611953735\n",
      "Epoch 4359, Loss: 0.04680198058485985, Final Batch Loss: 0.024124540388584137\n",
      "Epoch 4360, Loss: 0.02655034326016903, Final Batch Loss: 0.011171403340995312\n",
      "Epoch 4361, Loss: 0.021810862235724926, Final Batch Loss: 0.01350014191120863\n",
      "Epoch 4362, Loss: 0.05455440655350685, Final Batch Loss: 0.029488204047083855\n",
      "Epoch 4363, Loss: 0.014025931479409337, Final Batch Loss: 0.0038214970845729113\n",
      "Epoch 4364, Loss: 0.04368084855377674, Final Batch Loss: 0.01767238974571228\n",
      "Epoch 4365, Loss: 0.06821933761239052, Final Batch Loss: 0.0343841053545475\n",
      "Epoch 4366, Loss: 0.024266506545245647, Final Batch Loss: 0.01512145809829235\n",
      "Epoch 4367, Loss: 0.0552569180727005, Final Batch Loss: 0.0358181893825531\n",
      "Epoch 4368, Loss: 0.03520153649151325, Final Batch Loss: 0.01009645126760006\n",
      "Epoch 4369, Loss: 0.0373292900621891, Final Batch Loss: 0.009159699082374573\n",
      "Epoch 4370, Loss: 0.06757883727550507, Final Batch Loss: 0.04428200051188469\n",
      "Epoch 4371, Loss: 0.038126252591609955, Final Batch Loss: 0.016414156183600426\n",
      "Epoch 4372, Loss: 0.041463812813162804, Final Batch Loss: 0.016842016950249672\n",
      "Epoch 4373, Loss: 0.035754503682255745, Final Batch Loss: 0.019594067707657814\n",
      "Epoch 4374, Loss: 0.04731180891394615, Final Batch Loss: 0.01236928254365921\n",
      "Epoch 4375, Loss: 0.027314395643770695, Final Batch Loss: 0.008425199426710606\n",
      "Epoch 4376, Loss: 0.04296716395765543, Final Batch Loss: 0.028856072574853897\n",
      "Epoch 4377, Loss: 0.0384517265483737, Final Batch Loss: 0.010095969773828983\n",
      "Epoch 4378, Loss: 0.023695396725088358, Final Batch Loss: 0.006450964603573084\n",
      "Epoch 4379, Loss: 0.03835487551987171, Final Batch Loss: 0.014574229717254639\n",
      "Epoch 4380, Loss: 0.025714147835969925, Final Batch Loss: 0.008051030337810516\n",
      "Epoch 4381, Loss: 0.029783896170556545, Final Batch Loss: 0.021128982305526733\n",
      "Epoch 4382, Loss: 0.018565113190561533, Final Batch Loss: 0.0035478067584335804\n",
      "Epoch 4383, Loss: 0.030974293127655983, Final Batch Loss: 0.010237012058496475\n",
      "Epoch 4384, Loss: 0.04823638591915369, Final Batch Loss: 0.013758079148828983\n",
      "Epoch 4385, Loss: 0.028773046098649502, Final Batch Loss: 0.015535150654613972\n",
      "Epoch 4386, Loss: 0.051285699009895325, Final Batch Loss: 0.026013940572738647\n",
      "Epoch 4387, Loss: 0.06830475153401494, Final Batch Loss: 0.006587047595530748\n",
      "Epoch 4388, Loss: 0.03396577946841717, Final Batch Loss: 0.018200384452939034\n",
      "Epoch 4389, Loss: 0.02924963552504778, Final Batch Loss: 0.010300696827471256\n",
      "Epoch 4390, Loss: 0.059483638033270836, Final Batch Loss: 0.03384215012192726\n",
      "Epoch 4391, Loss: 0.031555176712572575, Final Batch Loss: 0.011568297632038593\n",
      "Epoch 4392, Loss: 0.04356645327061415, Final Batch Loss: 0.00875817146152258\n",
      "Epoch 4393, Loss: 0.05738700553774834, Final Batch Loss: 0.025037601590156555\n",
      "Epoch 4394, Loss: 0.033467093482613564, Final Batch Loss: 0.010409880429506302\n",
      "Epoch 4395, Loss: 0.10613085702061653, Final Batch Loss: 0.0380108617246151\n",
      "Epoch 4396, Loss: 0.050523098558187485, Final Batch Loss: 0.015970200300216675\n",
      "Epoch 4397, Loss: 0.045455423183739185, Final Batch Loss: 0.0401102751493454\n",
      "Epoch 4398, Loss: 0.0381151307374239, Final Batch Loss: 0.022294992581009865\n",
      "Epoch 4399, Loss: 0.02783981431275606, Final Batch Loss: 0.00969503540545702\n",
      "Epoch 4400, Loss: 0.0785803459584713, Final Batch Loss: 0.04516170173883438\n",
      "Epoch 4401, Loss: 0.034429917111992836, Final Batch Loss: 0.025958944112062454\n",
      "Epoch 4402, Loss: 0.036659469828009605, Final Batch Loss: 0.018487876281142235\n",
      "Epoch 4403, Loss: 0.04629297903738916, Final Batch Loss: 0.003369536017999053\n",
      "Epoch 4404, Loss: 0.02755257999524474, Final Batch Loss: 0.006136307027190924\n",
      "Epoch 4405, Loss: 0.03748749941587448, Final Batch Loss: 0.004330810159444809\n",
      "Epoch 4406, Loss: 0.05257799196988344, Final Batch Loss: 0.009031944908201694\n",
      "Epoch 4407, Loss: 0.02984591294080019, Final Batch Loss: 0.011370797641575336\n",
      "Epoch 4408, Loss: 0.03920592227950692, Final Batch Loss: 0.006566750351339579\n",
      "Epoch 4409, Loss: 0.03999679069966078, Final Batch Loss: 0.011542520485818386\n",
      "Epoch 4410, Loss: 0.021898106671869755, Final Batch Loss: 0.010095939971506596\n",
      "Epoch 4411, Loss: 0.01900220150128007, Final Batch Loss: 0.006621988024562597\n",
      "Epoch 4412, Loss: 0.08756661601364613, Final Batch Loss: 0.059563759714365005\n",
      "Epoch 4413, Loss: 0.01840092334896326, Final Batch Loss: 0.006794662214815617\n",
      "Epoch 4414, Loss: 0.02601771056652069, Final Batch Loss: 0.011808856390416622\n",
      "Epoch 4415, Loss: 0.04180099815130234, Final Batch Loss: 0.016347071155905724\n",
      "Epoch 4416, Loss: 0.028329490683972836, Final Batch Loss: 0.022678710520267487\n",
      "Epoch 4417, Loss: 0.023921498097479343, Final Batch Loss: 0.014682396315038204\n",
      "Epoch 4418, Loss: 0.02486448921263218, Final Batch Loss: 0.009481505490839481\n",
      "Epoch 4419, Loss: 0.019915713695809245, Final Batch Loss: 0.0036187719088047743\n",
      "Epoch 4420, Loss: 0.04053064249455929, Final Batch Loss: 0.014773622155189514\n",
      "Epoch 4421, Loss: 0.055319126695394516, Final Batch Loss: 0.014792580157518387\n",
      "Epoch 4422, Loss: 0.03396984888240695, Final Batch Loss: 0.02633308805525303\n",
      "Epoch 4423, Loss: 0.07532886415719986, Final Batch Loss: 0.02898397296667099\n",
      "Epoch 4424, Loss: 0.07131804339587688, Final Batch Loss: 0.051064275205135345\n",
      "Epoch 4425, Loss: 0.05002145655453205, Final Batch Loss: 0.023291921243071556\n",
      "Epoch 4426, Loss: 0.029935095459222794, Final Batch Loss: 0.013738352805376053\n",
      "Epoch 4427, Loss: 0.022295652888715267, Final Batch Loss: 0.008429708890616894\n",
      "Epoch 4428, Loss: 0.038294417317956686, Final Batch Loss: 0.03489900007843971\n",
      "Epoch 4429, Loss: 0.10810710862278938, Final Batch Loss: 0.04786272346973419\n",
      "Epoch 4430, Loss: 0.03848747629672289, Final Batch Loss: 0.0099840322509408\n",
      "Epoch 4431, Loss: 0.043276756070554256, Final Batch Loss: 0.03365926072001457\n",
      "Epoch 4432, Loss: 0.04995354078710079, Final Batch Loss: 0.020940391346812248\n",
      "Epoch 4433, Loss: 0.02572560589760542, Final Batch Loss: 0.01468007080256939\n",
      "Epoch 4434, Loss: 0.04250599257647991, Final Batch Loss: 0.025840677320957184\n",
      "Epoch 4435, Loss: 0.06504320725798607, Final Batch Loss: 0.030253183096647263\n",
      "Epoch 4436, Loss: 0.06396921444684267, Final Batch Loss: 0.049158912152051926\n",
      "Epoch 4437, Loss: 0.04500961862504482, Final Batch Loss: 0.027608638629317284\n",
      "Epoch 4438, Loss: 0.04396406374871731, Final Batch Loss: 0.007903555408120155\n",
      "Epoch 4439, Loss: 0.042670671828091145, Final Batch Loss: 0.02875199355185032\n",
      "Epoch 4440, Loss: 0.04797884775325656, Final Batch Loss: 0.006264399271458387\n",
      "Epoch 4441, Loss: 0.050502095371484756, Final Batch Loss: 0.03457491099834442\n",
      "Epoch 4442, Loss: 0.03759604133665562, Final Batch Loss: 0.01564531773328781\n",
      "Epoch 4443, Loss: 0.05997583828866482, Final Batch Loss: 0.047459449619054794\n",
      "Epoch 4444, Loss: 0.05737907998263836, Final Batch Loss: 0.01827852986752987\n",
      "Epoch 4445, Loss: 0.0630215872079134, Final Batch Loss: 0.0405515655875206\n",
      "Epoch 4446, Loss: 0.03667581453919411, Final Batch Loss: 0.01969956047832966\n",
      "Epoch 4447, Loss: 0.0508752204477787, Final Batch Loss: 0.01704999804496765\n",
      "Epoch 4448, Loss: 0.03483978658914566, Final Batch Loss: 0.015466440469026566\n",
      "Epoch 4449, Loss: 0.04111539293080568, Final Batch Loss: 0.013732192106544971\n",
      "Epoch 4450, Loss: 0.04180158115923405, Final Batch Loss: 0.028144534677267075\n",
      "Epoch 4451, Loss: 0.031414217315614223, Final Batch Loss: 0.015035337768495083\n",
      "Epoch 4452, Loss: 0.01539389742538333, Final Batch Loss: 0.008278094232082367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4453, Loss: 0.061299458146095276, Final Batch Loss: 0.04433076083660126\n",
      "Epoch 4454, Loss: 0.028533300384879112, Final Batch Loss: 0.015423212200403214\n",
      "Epoch 4455, Loss: 0.040398694574832916, Final Batch Loss: 0.007589660584926605\n",
      "Epoch 4456, Loss: 0.036863867193460464, Final Batch Loss: 0.02981668896973133\n",
      "Epoch 4457, Loss: 0.0769359152764082, Final Batch Loss: 0.011799914762377739\n",
      "Epoch 4458, Loss: 0.019407224841415882, Final Batch Loss: 0.009817088022828102\n",
      "Epoch 4459, Loss: 0.013470167759805918, Final Batch Loss: 0.004222237970679998\n",
      "Epoch 4460, Loss: 0.038411518558859825, Final Batch Loss: 0.021451734006404877\n",
      "Epoch 4461, Loss: 0.09895937889814377, Final Batch Loss: 0.06647804379463196\n",
      "Epoch 4462, Loss: 0.03795840870589018, Final Batch Loss: 0.0114860525354743\n",
      "Epoch 4463, Loss: 0.015700451098382473, Final Batch Loss: 0.005633829161524773\n",
      "Epoch 4464, Loss: 0.03084786795079708, Final Batch Loss: 0.02149158902466297\n",
      "Epoch 4465, Loss: 0.02859537350013852, Final Batch Loss: 0.024263452738523483\n",
      "Epoch 4466, Loss: 0.08687655255198479, Final Batch Loss: 0.048309825360774994\n",
      "Epoch 4467, Loss: 0.05427742004394531, Final Batch Loss: 0.0048843324184417725\n",
      "Epoch 4468, Loss: 0.09687319584190845, Final Batch Loss: 0.07121042162179947\n",
      "Epoch 4469, Loss: 0.028589559253305197, Final Batch Loss: 0.0025108209811151028\n",
      "Epoch 4470, Loss: 0.02800685167312622, Final Batch Loss: 0.01747620478272438\n",
      "Epoch 4471, Loss: 0.08116264082491398, Final Batch Loss: 0.06613578647375107\n",
      "Epoch 4472, Loss: 0.12424608319997787, Final Batch Loss: 0.06852088123559952\n",
      "Epoch 4473, Loss: 0.06845701299607754, Final Batch Loss: 0.019274817779660225\n",
      "Epoch 4474, Loss: 0.010714191943407059, Final Batch Loss: 0.006611750926822424\n",
      "Epoch 4475, Loss: 0.01753610000014305, Final Batch Loss: 0.004236131906509399\n",
      "Epoch 4476, Loss: 0.11677644401788712, Final Batch Loss: 0.06618014723062515\n",
      "Epoch 4477, Loss: 0.08596029877662659, Final Batch Loss: 0.0398034006357193\n",
      "Epoch 4478, Loss: 0.06127118691802025, Final Batch Loss: 0.021288439631462097\n",
      "Epoch 4479, Loss: 0.05228465050458908, Final Batch Loss: 0.011391740292310715\n",
      "Epoch 4480, Loss: 0.1110959630459547, Final Batch Loss: 0.09506405144929886\n",
      "Epoch 4481, Loss: 0.06604803819209337, Final Batch Loss: 0.014009379781782627\n",
      "Epoch 4482, Loss: 0.04702853597700596, Final Batch Loss: 0.017947785556316376\n",
      "Epoch 4483, Loss: 0.020047211088240147, Final Batch Loss: 0.01016388088464737\n",
      "Epoch 4484, Loss: 0.045608172193169594, Final Batch Loss: 0.02305416762828827\n",
      "Epoch 4485, Loss: 0.0882098451256752, Final Batch Loss: 0.054529689252376556\n",
      "Epoch 4486, Loss: 0.027618736028671265, Final Batch Loss: 0.010686501860618591\n",
      "Epoch 4487, Loss: 0.038670897483825684, Final Batch Loss: 0.014040179550647736\n",
      "Epoch 4488, Loss: 0.04725557845085859, Final Batch Loss: 0.00722608994692564\n",
      "Epoch 4489, Loss: 0.045881737023591995, Final Batch Loss: 0.012897983193397522\n",
      "Epoch 4490, Loss: 0.022335052955895662, Final Batch Loss: 0.006192060653120279\n",
      "Epoch 4491, Loss: 0.02481585368514061, Final Batch Loss: 0.019205326214432716\n",
      "Epoch 4492, Loss: 0.10102862119674683, Final Batch Loss: 0.04038093239068985\n",
      "Epoch 4493, Loss: 0.051061613485217094, Final Batch Loss: 0.029672693461179733\n",
      "Epoch 4494, Loss: 0.026159840635955334, Final Batch Loss: 0.015459377318620682\n",
      "Epoch 4495, Loss: 0.04290854185819626, Final Batch Loss: 0.020245956256985664\n",
      "Epoch 4496, Loss: 0.04501323215663433, Final Batch Loss: 0.007853837683796883\n",
      "Epoch 4497, Loss: 0.021236402913928032, Final Batch Loss: 0.006775681860744953\n",
      "Epoch 4498, Loss: 0.04410357028245926, Final Batch Loss: 0.009068172425031662\n",
      "Epoch 4499, Loss: 0.2727646566927433, Final Batch Loss: 0.22113992273807526\n",
      "Epoch 4500, Loss: 0.024637414142489433, Final Batch Loss: 0.006491409614682198\n",
      "Epoch 4501, Loss: 0.07816392928361893, Final Batch Loss: 0.041944924741983414\n",
      "Epoch 4502, Loss: 0.04843819793313742, Final Batch Loss: 0.011262244544923306\n",
      "Epoch 4503, Loss: 0.03454440180212259, Final Batch Loss: 0.014541794545948505\n",
      "Epoch 4504, Loss: 0.06021301448345184, Final Batch Loss: 0.03985880687832832\n",
      "Epoch 4505, Loss: 0.016163735184818506, Final Batch Loss: 0.00691581005230546\n",
      "Epoch 4506, Loss: 0.04288826137781143, Final Batch Loss: 0.014620382338762283\n",
      "Epoch 4507, Loss: 0.08838823810219765, Final Batch Loss: 0.035658806562423706\n",
      "Epoch 4508, Loss: 0.046102278865873814, Final Batch Loss: 0.030785618349909782\n",
      "Epoch 4509, Loss: 0.026307810097932816, Final Batch Loss: 0.016919152811169624\n",
      "Epoch 4510, Loss: 0.10610576346516609, Final Batch Loss: 0.04550427198410034\n",
      "Epoch 4511, Loss: 0.0627343337982893, Final Batch Loss: 0.0057502854615449905\n",
      "Epoch 4512, Loss: 0.07299499213695526, Final Batch Loss: 0.03977847099304199\n",
      "Epoch 4513, Loss: 0.04025922901928425, Final Batch Loss: 0.022219901904463768\n",
      "Epoch 4514, Loss: 0.04696359857916832, Final Batch Loss: 0.02883232943713665\n",
      "Epoch 4515, Loss: 0.04075788892805576, Final Batch Loss: 0.025510353967547417\n",
      "Epoch 4516, Loss: 0.059058668091893196, Final Batch Loss: 0.017403243109583855\n",
      "Epoch 4517, Loss: 0.0162390423938632, Final Batch Loss: 0.005332896485924721\n",
      "Epoch 4518, Loss: 0.04550612438470125, Final Batch Loss: 0.014288707636296749\n",
      "Epoch 4519, Loss: 0.030688256956636906, Final Batch Loss: 0.0068542202934622765\n",
      "Epoch 4520, Loss: 0.046830281149595976, Final Batch Loss: 0.03922155126929283\n",
      "Epoch 4521, Loss: 0.05304646119475365, Final Batch Loss: 0.01276601105928421\n",
      "Epoch 4522, Loss: 0.043894680216908455, Final Batch Loss: 0.03258686140179634\n",
      "Epoch 4523, Loss: 0.018492494709789753, Final Batch Loss: 0.011034803465008736\n",
      "Epoch 4524, Loss: 0.03264526277780533, Final Batch Loss: 0.02240525372326374\n",
      "Epoch 4525, Loss: 0.030776241794228554, Final Batch Loss: 0.011254684999585152\n",
      "Epoch 4526, Loss: 0.05105939880013466, Final Batch Loss: 0.024717483669519424\n",
      "Epoch 4527, Loss: 0.024298436008393764, Final Batch Loss: 0.012539258226752281\n",
      "Epoch 4528, Loss: 0.09536277875304222, Final Batch Loss: 0.047036491334438324\n",
      "Epoch 4529, Loss: 0.0815828237682581, Final Batch Loss: 0.0691675916314125\n",
      "Epoch 4530, Loss: 0.03339832229539752, Final Batch Loss: 0.0074028740637004375\n",
      "Epoch 4531, Loss: 0.056819917634129524, Final Batch Loss: 0.023053141310811043\n",
      "Epoch 4532, Loss: 0.016261757351458073, Final Batch Loss: 0.007242957130074501\n",
      "Epoch 4533, Loss: 0.027777576819062233, Final Batch Loss: 0.01602778211236\n",
      "Epoch 4534, Loss: 0.06767779588699341, Final Batch Loss: 0.032684918493032455\n",
      "Epoch 4535, Loss: 0.04138474725186825, Final Batch Loss: 0.020384900271892548\n",
      "Epoch 4536, Loss: 0.07754511013627052, Final Batch Loss: 0.05012029409408569\n",
      "Epoch 4537, Loss: 0.04087158013135195, Final Batch Loss: 0.027018962427973747\n",
      "Epoch 4538, Loss: 0.1299009956419468, Final Batch Loss: 0.04351707920432091\n",
      "Epoch 4539, Loss: 0.06943836063146591, Final Batch Loss: 0.050706181675195694\n",
      "Epoch 4540, Loss: 0.07424918934702873, Final Batch Loss: 0.03158419951796532\n",
      "Epoch 4541, Loss: 0.0276156859472394, Final Batch Loss: 0.013210834935307503\n",
      "Epoch 4542, Loss: 0.046758116222918034, Final Batch Loss: 0.03607126325368881\n",
      "Epoch 4543, Loss: 0.03724394319579005, Final Batch Loss: 0.007616441231220961\n",
      "Epoch 4544, Loss: 0.10572252422571182, Final Batch Loss: 0.027518250048160553\n",
      "Epoch 4545, Loss: 0.02877409104257822, Final Batch Loss: 0.01762627810239792\n",
      "Epoch 4546, Loss: 0.028231949545443058, Final Batch Loss: 0.017012914642691612\n",
      "Epoch 4547, Loss: 0.05845732241868973, Final Batch Loss: 0.01234329491853714\n",
      "Epoch 4548, Loss: 0.07588700763881207, Final Batch Loss: 0.05444635823369026\n",
      "Epoch 4549, Loss: 0.05497979372739792, Final Batch Loss: 0.016017679125070572\n",
      "Epoch 4550, Loss: 0.08038278762251139, Final Batch Loss: 0.06798010319471359\n",
      "Epoch 4551, Loss: 0.10391303151845932, Final Batch Loss: 0.08531396836042404\n",
      "Epoch 4552, Loss: 0.09929926320910454, Final Batch Loss: 0.07770153135061264\n",
      "Epoch 4553, Loss: 0.045401533134281635, Final Batch Loss: 0.014906023629009724\n",
      "Epoch 4554, Loss: 0.03924141451716423, Final Batch Loss: 0.015358936041593552\n",
      "Epoch 4555, Loss: 0.0802907943725586, Final Batch Loss: 0.05802459642291069\n",
      "Epoch 4556, Loss: 0.03722486924380064, Final Batch Loss: 0.013070422224700451\n",
      "Epoch 4557, Loss: 0.030484461691230536, Final Batch Loss: 0.007553336676210165\n",
      "Epoch 4558, Loss: 0.09137590415775776, Final Batch Loss: 0.01795090176165104\n",
      "Epoch 4559, Loss: 0.026578215416520834, Final Batch Loss: 0.005816848482936621\n",
      "Epoch 4560, Loss: 0.035475390031933784, Final Batch Loss: 0.0201604925096035\n",
      "Epoch 4561, Loss: 0.062307706102728844, Final Batch Loss: 0.04454446956515312\n",
      "Epoch 4562, Loss: 0.04947897046804428, Final Batch Loss: 0.01045200228691101\n",
      "Epoch 4563, Loss: 0.0800167191773653, Final Batch Loss: 0.050887271761894226\n",
      "Epoch 4564, Loss: 0.018176652491092682, Final Batch Loss: 0.007015536539256573\n",
      "Epoch 4565, Loss: 0.05403821263462305, Final Batch Loss: 0.04794548079371452\n",
      "Epoch 4566, Loss: 0.08581684902310371, Final Batch Loss: 0.04818622022867203\n",
      "Epoch 4567, Loss: 0.078972727060318, Final Batch Loss: 0.0426984541118145\n",
      "Epoch 4568, Loss: 0.07840055506676435, Final Batch Loss: 0.011775302700698376\n",
      "Epoch 4569, Loss: 0.04993403237313032, Final Batch Loss: 0.011683772318065166\n",
      "Epoch 4570, Loss: 0.024560132063925266, Final Batch Loss: 0.011929087340831757\n",
      "Epoch 4571, Loss: 0.04874206706881523, Final Batch Loss: 0.025179557502269745\n",
      "Epoch 4572, Loss: 0.09005452133715153, Final Batch Loss: 0.05976973474025726\n",
      "Epoch 4573, Loss: 0.02963497443124652, Final Batch Loss: 0.007070218678563833\n",
      "Epoch 4574, Loss: 0.03294902294874191, Final Batch Loss: 0.006103107705712318\n",
      "Epoch 4575, Loss: 0.035419899970293045, Final Batch Loss: 0.022197028622031212\n",
      "Epoch 4576, Loss: 0.02648225799202919, Final Batch Loss: 0.008375724777579308\n",
      "Epoch 4577, Loss: 0.05584997870028019, Final Batch Loss: 0.015534410253167152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4578, Loss: 0.06989726889878511, Final Batch Loss: 0.05914834141731262\n",
      "Epoch 4579, Loss: 0.050226977095007896, Final Batch Loss: 0.027430878952145576\n",
      "Epoch 4580, Loss: 0.045059205032885075, Final Batch Loss: 0.029612060636281967\n",
      "Epoch 4581, Loss: 0.03942498005926609, Final Batch Loss: 0.011609131470322609\n",
      "Epoch 4582, Loss: 0.059129251167178154, Final Batch Loss: 0.011920271441340446\n",
      "Epoch 4583, Loss: 0.03413222171366215, Final Batch Loss: 0.0181896910071373\n",
      "Epoch 4584, Loss: 0.017786138225346804, Final Batch Loss: 0.0069265603087842464\n",
      "Epoch 4585, Loss: 0.03288788627833128, Final Batch Loss: 0.018842220306396484\n",
      "Epoch 4586, Loss: 0.03423447674140334, Final Batch Loss: 0.007651689928025007\n",
      "Epoch 4587, Loss: 0.07414508610963821, Final Batch Loss: 0.03961079195141792\n",
      "Epoch 4588, Loss: 0.06927316635847092, Final Batch Loss: 0.04108353331685066\n",
      "Epoch 4589, Loss: 0.08584280963987112, Final Batch Loss: 0.07635197788476944\n",
      "Epoch 4590, Loss: 0.016527224332094193, Final Batch Loss: 0.009959128685295582\n",
      "Epoch 4591, Loss: 0.053097073920071125, Final Batch Loss: 0.04494909197092056\n",
      "Epoch 4592, Loss: 0.036416636779904366, Final Batch Loss: 0.02943248115479946\n",
      "Epoch 4593, Loss: 0.07239294797182083, Final Batch Loss: 0.047930728644132614\n",
      "Epoch 4594, Loss: 0.06281023658812046, Final Batch Loss: 0.024446720257401466\n",
      "Epoch 4595, Loss: 0.052728740498423576, Final Batch Loss: 0.01741941086947918\n",
      "Epoch 4596, Loss: 0.07968013919889927, Final Batch Loss: 0.056274328380823135\n",
      "Epoch 4597, Loss: 0.06579024344682693, Final Batch Loss: 0.03900442644953728\n",
      "Epoch 4598, Loss: 0.07447029277682304, Final Batch Loss: 0.03294937312602997\n",
      "Epoch 4599, Loss: 0.08508982881903648, Final Batch Loss: 0.03932509198784828\n",
      "Epoch 4600, Loss: 0.07250544428825378, Final Batch Loss: 0.05526556447148323\n",
      "Epoch 4601, Loss: 0.08455540053546429, Final Batch Loss: 0.05539329722523689\n",
      "Epoch 4602, Loss: 0.08615086041390896, Final Batch Loss: 0.016475772485136986\n",
      "Epoch 4603, Loss: 0.05123887397348881, Final Batch Loss: 0.012279776856303215\n",
      "Epoch 4604, Loss: 0.04804491996765137, Final Batch Loss: 0.026499902829527855\n",
      "Epoch 4605, Loss: 0.05762219615280628, Final Batch Loss: 0.041776515543460846\n",
      "Epoch 4606, Loss: 0.04724053479731083, Final Batch Loss: 0.022465655580163002\n",
      "Epoch 4607, Loss: 0.03766943980008364, Final Batch Loss: 0.024962760508060455\n",
      "Epoch 4608, Loss: 0.029043445363640785, Final Batch Loss: 0.01570194587111473\n",
      "Epoch 4609, Loss: 0.07247276697307825, Final Batch Loss: 0.05708867684006691\n",
      "Epoch 4610, Loss: 0.02762457635253668, Final Batch Loss: 0.015063095837831497\n",
      "Epoch 4611, Loss: 0.050661223009228706, Final Batch Loss: 0.01952335052192211\n",
      "Epoch 4612, Loss: 0.03072893526405096, Final Batch Loss: 0.022907715290784836\n",
      "Epoch 4613, Loss: 0.04887589253485203, Final Batch Loss: 0.02262665331363678\n",
      "Epoch 4614, Loss: 0.05521079711616039, Final Batch Loss: 0.03232986479997635\n",
      "Epoch 4615, Loss: 0.06661901250481606, Final Batch Loss: 0.04978691786527634\n",
      "Epoch 4616, Loss: 0.03617253340780735, Final Batch Loss: 0.01667420193552971\n",
      "Epoch 4617, Loss: 0.0200260728597641, Final Batch Loss: 0.009822491556406021\n",
      "Epoch 4618, Loss: 0.013652692548930645, Final Batch Loss: 0.0083049600943923\n",
      "Epoch 4619, Loss: 0.03298191074281931, Final Batch Loss: 0.012394054792821407\n",
      "Epoch 4620, Loss: 0.032702068798244, Final Batch Loss: 0.01433583814650774\n",
      "Epoch 4621, Loss: 0.08952897973358631, Final Batch Loss: 0.07250743359327316\n",
      "Epoch 4622, Loss: 0.01837790757417679, Final Batch Loss: 0.009789758361876011\n",
      "Epoch 4623, Loss: 0.030957797542214394, Final Batch Loss: 0.011634493246674538\n",
      "Epoch 4624, Loss: 0.0647512897849083, Final Batch Loss: 0.04531560838222504\n",
      "Epoch 4625, Loss: 0.022923775017261505, Final Batch Loss: 0.010943322442471981\n",
      "Epoch 4626, Loss: 0.04518282879143953, Final Batch Loss: 0.03644540533423424\n",
      "Epoch 4627, Loss: 0.04204103723168373, Final Batch Loss: 0.009324513375759125\n",
      "Epoch 4628, Loss: 0.027372916229069233, Final Batch Loss: 0.012475100345909595\n",
      "Epoch 4629, Loss: 0.03216233430430293, Final Batch Loss: 0.025005480274558067\n",
      "Epoch 4630, Loss: 0.026536729652434587, Final Batch Loss: 0.006475385744124651\n",
      "Epoch 4631, Loss: 0.039348749443888664, Final Batch Loss: 0.008163439109921455\n",
      "Epoch 4632, Loss: 0.042245098389685154, Final Batch Loss: 0.03356584906578064\n",
      "Epoch 4633, Loss: 0.05289880558848381, Final Batch Loss: 0.033953819423913956\n",
      "Epoch 4634, Loss: 0.05535014159977436, Final Batch Loss: 0.029268164187669754\n",
      "Epoch 4635, Loss: 0.06984902173280716, Final Batch Loss: 0.029463037848472595\n",
      "Epoch 4636, Loss: 0.046110755763947964, Final Batch Loss: 0.033861324191093445\n",
      "Epoch 4637, Loss: 0.03575277887284756, Final Batch Loss: 0.007930167019367218\n",
      "Epoch 4638, Loss: 0.08478927426040173, Final Batch Loss: 0.058029863983392715\n",
      "Epoch 4639, Loss: 0.03453834541141987, Final Batch Loss: 0.01845090277493\n",
      "Epoch 4640, Loss: 0.02630720380693674, Final Batch Loss: 0.008939565159380436\n",
      "Epoch 4641, Loss: 0.03447097446769476, Final Batch Loss: 0.024940019473433495\n",
      "Epoch 4642, Loss: 0.035240862518548965, Final Batch Loss: 0.021878432482481003\n",
      "Epoch 4643, Loss: 0.09653611481189728, Final Batch Loss: 0.03516064211726189\n",
      "Epoch 4644, Loss: 0.02487117610871792, Final Batch Loss: 0.014198876917362213\n",
      "Epoch 4645, Loss: 0.03980682697147131, Final Batch Loss: 0.027859872207045555\n",
      "Epoch 4646, Loss: 0.04694616049528122, Final Batch Loss: 0.004959847778081894\n",
      "Epoch 4647, Loss: 0.01987374946475029, Final Batch Loss: 0.006788303144276142\n",
      "Epoch 4648, Loss: 0.05503504443913698, Final Batch Loss: 0.005795028991997242\n",
      "Epoch 4649, Loss: 0.029101826949045062, Final Batch Loss: 0.0038889970164746046\n",
      "Epoch 4650, Loss: 0.02605096809566021, Final Batch Loss: 0.010717594996094704\n",
      "Epoch 4651, Loss: 0.03894583601504564, Final Batch Loss: 0.014188372530043125\n",
      "Epoch 4652, Loss: 0.0230344170704484, Final Batch Loss: 0.01681436412036419\n",
      "Epoch 4653, Loss: 0.0591988917440176, Final Batch Loss: 0.027531856670975685\n",
      "Epoch 4654, Loss: 0.035661738365888596, Final Batch Loss: 0.013527868315577507\n",
      "Epoch 4655, Loss: 0.05779673345386982, Final Batch Loss: 0.01916857250034809\n",
      "Epoch 4656, Loss: 0.07285493984818459, Final Batch Loss: 0.012974478304386139\n",
      "Epoch 4657, Loss: 0.04073241259902716, Final Batch Loss: 0.026257196441292763\n",
      "Epoch 4658, Loss: 0.01906577032059431, Final Batch Loss: 0.00961893331259489\n",
      "Epoch 4659, Loss: 0.027934287674725056, Final Batch Loss: 0.007348029874265194\n",
      "Epoch 4660, Loss: 0.022365352138876915, Final Batch Loss: 0.01087888702750206\n",
      "Epoch 4661, Loss: 0.07599050365388393, Final Batch Loss: 0.028765736147761345\n",
      "Epoch 4662, Loss: 0.04386893566697836, Final Batch Loss: 0.014315237291157246\n",
      "Epoch 4663, Loss: 0.08918555453419685, Final Batch Loss: 0.07781831175088882\n",
      "Epoch 4664, Loss: 0.029209713451564312, Final Batch Loss: 0.01548871211707592\n",
      "Epoch 4665, Loss: 0.10551000945270061, Final Batch Loss: 0.08080187439918518\n",
      "Epoch 4666, Loss: 0.029762012884020805, Final Batch Loss: 0.018748125061392784\n",
      "Epoch 4667, Loss: 0.0974277351051569, Final Batch Loss: 0.08420389890670776\n",
      "Epoch 4668, Loss: 0.026970958337187767, Final Batch Loss: 0.010449754074215889\n",
      "Epoch 4669, Loss: 0.04043221194297075, Final Batch Loss: 0.025912674143910408\n",
      "Epoch 4670, Loss: 0.11822237446904182, Final Batch Loss: 0.0598997138440609\n",
      "Epoch 4671, Loss: 0.07399981282651424, Final Batch Loss: 0.05769221484661102\n",
      "Epoch 4672, Loss: 0.05358516424894333, Final Batch Loss: 0.03298746794462204\n",
      "Epoch 4673, Loss: 0.04351244680583477, Final Batch Loss: 0.019204406067728996\n",
      "Epoch 4674, Loss: 0.028974719811230898, Final Batch Loss: 0.022134071215987206\n",
      "Epoch 4675, Loss: 0.06589855253696442, Final Batch Loss: 0.019526831805706024\n",
      "Epoch 4676, Loss: 0.07302073948085308, Final Batch Loss: 0.01819360814988613\n",
      "Epoch 4677, Loss: 0.0631129015237093, Final Batch Loss: 0.040865279734134674\n",
      "Epoch 4678, Loss: 0.07458537817001343, Final Batch Loss: 0.04516689479351044\n",
      "Epoch 4679, Loss: 0.0213153762742877, Final Batch Loss: 0.005237459205091\n",
      "Epoch 4680, Loss: 0.04531925544142723, Final Batch Loss: 0.017097171396017075\n",
      "Epoch 4681, Loss: 0.09890867955982685, Final Batch Loss: 0.06958024948835373\n",
      "Epoch 4682, Loss: 0.03373450040817261, Final Batch Loss: 0.009679744020104408\n",
      "Epoch 4683, Loss: 0.10425789281725883, Final Batch Loss: 0.054633334279060364\n",
      "Epoch 4684, Loss: 0.025022539775818586, Final Batch Loss: 0.007563011255115271\n",
      "Epoch 4685, Loss: 0.029388451017439365, Final Batch Loss: 0.008279883302748203\n",
      "Epoch 4686, Loss: 0.06975858099758625, Final Batch Loss: 0.04832116514444351\n",
      "Epoch 4687, Loss: 0.026611991226673126, Final Batch Loss: 0.012512478977441788\n",
      "Epoch 4688, Loss: 0.014681410044431686, Final Batch Loss: 0.007953422144055367\n",
      "Epoch 4689, Loss: 0.027018218534067273, Final Batch Loss: 0.0018616628367453814\n",
      "Epoch 4690, Loss: 0.054361697752028704, Final Batch Loss: 0.004708167631179094\n",
      "Epoch 4691, Loss: 0.05498674698174, Final Batch Loss: 0.014856955036520958\n",
      "Epoch 4692, Loss: 0.014251392567530274, Final Batch Loss: 0.011354522779583931\n",
      "Epoch 4693, Loss: 0.03771580569446087, Final Batch Loss: 0.030514197424054146\n",
      "Epoch 4694, Loss: 0.018766366876661777, Final Batch Loss: 0.01218066643923521\n",
      "Epoch 4695, Loss: 0.025302927941083908, Final Batch Loss: 0.014909652993083\n",
      "Epoch 4696, Loss: 0.02503986470401287, Final Batch Loss: 0.012822254560887814\n",
      "Epoch 4697, Loss: 0.061399731785058975, Final Batch Loss: 0.0439915768802166\n",
      "Epoch 4698, Loss: 0.06696052849292755, Final Batch Loss: 0.03240538015961647\n",
      "Epoch 4699, Loss: 0.04289659298956394, Final Batch Loss: 0.01759674772620201\n",
      "Epoch 4700, Loss: 0.044592252001166344, Final Batch Loss: 0.030112450942397118\n",
      "Epoch 4701, Loss: 0.035603022668510675, Final Batch Loss: 0.00471176253631711\n",
      "Epoch 4702, Loss: 0.052057905588299036, Final Batch Loss: 0.048163965344429016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4703, Loss: 0.019101513549685478, Final Batch Loss: 0.012990690767765045\n",
      "Epoch 4704, Loss: 0.0346831358037889, Final Batch Loss: 0.0055541000328958035\n",
      "Epoch 4705, Loss: 0.030503597110509872, Final Batch Loss: 0.011989941820502281\n",
      "Epoch 4706, Loss: 0.05311896279454231, Final Batch Loss: 0.033025894314050674\n",
      "Epoch 4707, Loss: 0.04943074472248554, Final Batch Loss: 0.039731405675411224\n",
      "Epoch 4708, Loss: 0.0376144228503108, Final Batch Loss: 0.005320324562489986\n",
      "Epoch 4709, Loss: 0.01504121907055378, Final Batch Loss: 0.005245780572295189\n",
      "Epoch 4710, Loss: 0.05232234112918377, Final Batch Loss: 0.01492324285209179\n",
      "Epoch 4711, Loss: 0.0601672176271677, Final Batch Loss: 0.014659369364380836\n",
      "Epoch 4712, Loss: 0.060466399416327477, Final Batch Loss: 0.04186611250042915\n",
      "Epoch 4713, Loss: 0.032773373648524284, Final Batch Loss: 0.011294035241007805\n",
      "Epoch 4714, Loss: 0.05521131446585059, Final Batch Loss: 0.007495650555938482\n",
      "Epoch 4715, Loss: 0.03915311396121979, Final Batch Loss: 0.023193392902612686\n",
      "Epoch 4716, Loss: 0.02564550470560789, Final Batch Loss: 0.013932009227573872\n",
      "Epoch 4717, Loss: 0.05991793517023325, Final Batch Loss: 0.011460383422672749\n",
      "Epoch 4718, Loss: 0.03434848412871361, Final Batch Loss: 0.02306910790503025\n",
      "Epoch 4719, Loss: 0.05029359087347984, Final Batch Loss: 0.03204142302274704\n",
      "Epoch 4720, Loss: 0.031047826167196035, Final Batch Loss: 0.006776941474527121\n",
      "Epoch 4721, Loss: 0.05324363708496094, Final Batch Loss: 0.03519761189818382\n",
      "Epoch 4722, Loss: 0.05790263880044222, Final Batch Loss: 0.014394179917871952\n",
      "Epoch 4723, Loss: 0.0286544484551996, Final Batch Loss: 0.0036353205796331167\n",
      "Epoch 4724, Loss: 0.036561788991093636, Final Batch Loss: 0.015754355117678642\n",
      "Epoch 4725, Loss: 0.04552282392978668, Final Batch Loss: 0.028214525431394577\n",
      "Epoch 4726, Loss: 0.03688373044133186, Final Batch Loss: 0.008274637162685394\n",
      "Epoch 4727, Loss: 0.03398684412240982, Final Batch Loss: 0.012456845492124557\n",
      "Epoch 4728, Loss: 0.03792979521676898, Final Batch Loss: 0.0334954708814621\n",
      "Epoch 4729, Loss: 0.048829639330506325, Final Batch Loss: 0.022394312545657158\n",
      "Epoch 4730, Loss: 0.08271678537130356, Final Batch Loss: 0.05595517158508301\n",
      "Epoch 4731, Loss: 0.036596208810806274, Final Batch Loss: 0.016671085730195045\n",
      "Epoch 4732, Loss: 0.0564170116558671, Final Batch Loss: 0.04365731403231621\n",
      "Epoch 4733, Loss: 0.09124870225787163, Final Batch Loss: 0.04566582292318344\n",
      "Epoch 4734, Loss: 0.06758400052785873, Final Batch Loss: 0.018846794962882996\n",
      "Epoch 4735, Loss: 0.026927517727017403, Final Batch Loss: 0.006149204447865486\n",
      "Epoch 4736, Loss: 0.023324254900217056, Final Batch Loss: 0.00655611976981163\n",
      "Epoch 4737, Loss: 0.0899473475292325, Final Batch Loss: 0.014932011254131794\n",
      "Epoch 4738, Loss: 0.07854277640581131, Final Batch Loss: 0.05416354909539223\n",
      "Epoch 4739, Loss: 0.034959265030920506, Final Batch Loss: 0.026604240760207176\n",
      "Epoch 4740, Loss: 0.07201489061117172, Final Batch Loss: 0.03237272426486015\n",
      "Epoch 4741, Loss: 0.06225976161658764, Final Batch Loss: 0.05190884694457054\n",
      "Epoch 4742, Loss: 0.05157649517059326, Final Batch Loss: 0.021073544397950172\n",
      "Epoch 4743, Loss: 0.039661258459091187, Final Batch Loss: 0.022443434223532677\n",
      "Epoch 4744, Loss: 0.022770380601286888, Final Batch Loss: 0.014840594492852688\n",
      "Epoch 4745, Loss: 0.04834895581007004, Final Batch Loss: 0.029027186334133148\n",
      "Epoch 4746, Loss: 0.06032693572342396, Final Batch Loss: 0.04258887842297554\n",
      "Epoch 4747, Loss: 0.060641282238066196, Final Batch Loss: 0.05087510496377945\n",
      "Epoch 4748, Loss: 0.05380689352750778, Final Batch Loss: 0.04021872207522392\n",
      "Epoch 4749, Loss: 0.0465015284717083, Final Batch Loss: 0.030697327107191086\n",
      "Epoch 4750, Loss: 0.041695695836097, Final Batch Loss: 0.00490576820448041\n",
      "Epoch 4751, Loss: 0.03515084274113178, Final Batch Loss: 0.015124322846531868\n",
      "Epoch 4752, Loss: 0.06253496557474136, Final Batch Loss: 0.03736811503767967\n",
      "Epoch 4753, Loss: 0.07301403395831585, Final Batch Loss: 0.012895425781607628\n",
      "Epoch 4754, Loss: 0.024753949604928493, Final Batch Loss: 0.009508882649242878\n",
      "Epoch 4755, Loss: 0.0567336268723011, Final Batch Loss: 0.031222298741340637\n",
      "Epoch 4756, Loss: 0.05315546877682209, Final Batch Loss: 0.021552128717303276\n",
      "Epoch 4757, Loss: 0.04222697904333472, Final Batch Loss: 0.007473492529243231\n",
      "Epoch 4758, Loss: 0.027862771414220333, Final Batch Loss: 0.018865976482629776\n",
      "Epoch 4759, Loss: 0.06558073125779629, Final Batch Loss: 0.05135973170399666\n",
      "Epoch 4760, Loss: 0.028305374085903168, Final Batch Loss: 0.012281157076358795\n",
      "Epoch 4761, Loss: 0.025525348260998726, Final Batch Loss: 0.016933167353272438\n",
      "Epoch 4762, Loss: 0.018860897049307823, Final Batch Loss: 0.008612604811787605\n",
      "Epoch 4763, Loss: 0.039357767440378666, Final Batch Loss: 0.008218272589147091\n",
      "Epoch 4764, Loss: 0.05906463600695133, Final Batch Loss: 0.038616154342889786\n",
      "Epoch 4765, Loss: 0.026813204400241375, Final Batch Loss: 0.01526529248803854\n",
      "Epoch 4766, Loss: 0.013084324542433023, Final Batch Loss: 0.0035231481306254864\n",
      "Epoch 4767, Loss: 0.07435508072376251, Final Batch Loss: 0.039133232086896896\n",
      "Epoch 4768, Loss: 0.02534074243158102, Final Batch Loss: 0.01865692436695099\n",
      "Epoch 4769, Loss: 0.03782545542344451, Final Batch Loss: 0.0044453381560742855\n",
      "Epoch 4770, Loss: 0.05012982804328203, Final Batch Loss: 0.009661768563091755\n",
      "Epoch 4771, Loss: 0.0302695045247674, Final Batch Loss: 0.008609197102487087\n",
      "Epoch 4772, Loss: 0.04762996733188629, Final Batch Loss: 0.01648283749818802\n",
      "Epoch 4773, Loss: 0.04620547033846378, Final Batch Loss: 0.01674293540418148\n",
      "Epoch 4774, Loss: 0.08598043769598007, Final Batch Loss: 0.07023495435714722\n",
      "Epoch 4775, Loss: 0.04142946004867554, Final Batch Loss: 0.011738210916519165\n",
      "Epoch 4776, Loss: 0.028789765201509, Final Batch Loss: 0.012993169017136097\n",
      "Epoch 4777, Loss: 0.03326321113854647, Final Batch Loss: 0.012017742730677128\n",
      "Epoch 4778, Loss: 0.024816010147333145, Final Batch Loss: 0.008385742083191872\n",
      "Epoch 4779, Loss: 0.06357990391552448, Final Batch Loss: 0.00589851476252079\n",
      "Epoch 4780, Loss: 0.137201938778162, Final Batch Loss: 0.08624956756830215\n",
      "Epoch 4781, Loss: 0.042496491223573685, Final Batch Loss: 0.023190457373857498\n",
      "Epoch 4782, Loss: 0.06854877434670925, Final Batch Loss: 0.049982376396656036\n",
      "Epoch 4783, Loss: 0.05503816530108452, Final Batch Loss: 0.016456369310617447\n",
      "Epoch 4784, Loss: 0.19230789318680763, Final Batch Loss: 0.13800688087940216\n",
      "Epoch 4785, Loss: 0.06883146055042744, Final Batch Loss: 0.04930688440799713\n",
      "Epoch 4786, Loss: 0.12554844096302986, Final Batch Loss: 0.08297701925039291\n",
      "Epoch 4787, Loss: 0.11831021308898926, Final Batch Loss: 0.056611351668834686\n",
      "Epoch 4788, Loss: 0.03431544080376625, Final Batch Loss: 0.017410071566700935\n",
      "Epoch 4789, Loss: 0.08674340322613716, Final Batch Loss: 0.04193500429391861\n",
      "Epoch 4790, Loss: 0.07318044546991587, Final Batch Loss: 0.015172240324318409\n",
      "Epoch 4791, Loss: 0.05690748989582062, Final Batch Loss: 0.010249398648738861\n",
      "Epoch 4792, Loss: 0.07058485224843025, Final Batch Loss: 0.01953991875052452\n",
      "Epoch 4793, Loss: 0.04081165697425604, Final Batch Loss: 0.028628196567296982\n",
      "Epoch 4794, Loss: 0.09182550758123398, Final Batch Loss: 0.0712248831987381\n",
      "Epoch 4795, Loss: 0.018978380132466555, Final Batch Loss: 0.006757187191396952\n",
      "Epoch 4796, Loss: 0.04322982393205166, Final Batch Loss: 0.028877809643745422\n",
      "Epoch 4797, Loss: 0.05769705306738615, Final Batch Loss: 0.015153578482568264\n",
      "Epoch 4798, Loss: 0.06145390495657921, Final Batch Loss: 0.03056410141289234\n",
      "Epoch 4799, Loss: 0.04989865608513355, Final Batch Loss: 0.024395590648055077\n",
      "Epoch 4800, Loss: 0.026961782947182655, Final Batch Loss: 0.008568288758397102\n",
      "Epoch 4801, Loss: 0.021922915242612362, Final Batch Loss: 0.008426280692219734\n",
      "Epoch 4802, Loss: 0.057623633183538914, Final Batch Loss: 0.015429616905748844\n",
      "Epoch 4803, Loss: 0.04842266999185085, Final Batch Loss: 0.016010241582989693\n",
      "Epoch 4804, Loss: 0.04714902117848396, Final Batch Loss: 0.018884215503931046\n",
      "Epoch 4805, Loss: 0.03653344139456749, Final Batch Loss: 0.021899746730923653\n",
      "Epoch 4806, Loss: 0.020193592179566622, Final Batch Loss: 0.013838463462889194\n",
      "Epoch 4807, Loss: 0.04657255206257105, Final Batch Loss: 0.0412910021841526\n",
      "Epoch 4808, Loss: 0.03369911666959524, Final Batch Loss: 0.02310791052877903\n",
      "Epoch 4809, Loss: 0.053126394748687744, Final Batch Loss: 0.02341957576572895\n",
      "Epoch 4810, Loss: 0.030257062520831823, Final Batch Loss: 0.022779643535614014\n",
      "Epoch 4811, Loss: 0.07525789365172386, Final Batch Loss: 0.03406771644949913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4812, Loss: 0.10174516588449478, Final Batch Loss: 0.06187174841761589\n",
      "Epoch 4813, Loss: 0.035843749064952135, Final Batch Loss: 0.029594872146844864\n",
      "Epoch 4814, Loss: 0.03108994010835886, Final Batch Loss: 0.022045819088816643\n",
      "Epoch 4815, Loss: 0.057752576656639576, Final Batch Loss: 0.048399511724710464\n",
      "Epoch 4816, Loss: 0.12724271416664124, Final Batch Loss: 0.061287589371204376\n",
      "Epoch 4817, Loss: 0.039943956304341555, Final Batch Loss: 0.00672119902446866\n",
      "Epoch 4818, Loss: 0.04223223030567169, Final Batch Loss: 0.01629648171365261\n",
      "Epoch 4819, Loss: 0.050027668476104736, Final Batch Loss: 0.025393780320882797\n",
      "Epoch 4820, Loss: 0.08865336887538433, Final Batch Loss: 0.030645186081528664\n",
      "Epoch 4821, Loss: 0.02841305546462536, Final Batch Loss: 0.007947828620672226\n",
      "Epoch 4822, Loss: 0.057271892204880714, Final Batch Loss: 0.034622907638549805\n",
      "Epoch 4823, Loss: 0.02311500022187829, Final Batch Loss: 0.0036033359356224537\n",
      "Epoch 4824, Loss: 0.030752806458622217, Final Batch Loss: 0.023628920316696167\n",
      "Epoch 4825, Loss: 0.042240651324391365, Final Batch Loss: 0.01962062530219555\n",
      "Epoch 4826, Loss: 0.037326172925531864, Final Batch Loss: 0.023943383246660233\n",
      "Epoch 4827, Loss: 0.05733657628297806, Final Batch Loss: 0.0394754521548748\n",
      "Epoch 4828, Loss: 0.07118168659508228, Final Batch Loss: 0.016309307888150215\n",
      "Epoch 4829, Loss: 0.019409717991948128, Final Batch Loss: 0.0057675642892718315\n",
      "Epoch 4830, Loss: 0.040990933775901794, Final Batch Loss: 0.020542725920677185\n",
      "Epoch 4831, Loss: 0.050299832597374916, Final Batch Loss: 0.03298284485936165\n",
      "Epoch 4832, Loss: 0.054102763533592224, Final Batch Loss: 0.02923634834587574\n",
      "Epoch 4833, Loss: 0.08363764872774482, Final Batch Loss: 0.0037899105809628963\n",
      "Epoch 4834, Loss: 0.05193724296987057, Final Batch Loss: 0.024308042600750923\n",
      "Epoch 4835, Loss: 0.15385644882917404, Final Batch Loss: 0.1121816411614418\n",
      "Epoch 4836, Loss: 0.09568478725850582, Final Batch Loss: 0.07340719550848007\n",
      "Epoch 4837, Loss: 0.10995735600590706, Final Batch Loss: 0.04708246514201164\n",
      "Epoch 4838, Loss: 0.03425617050379515, Final Batch Loss: 0.008730259723961353\n",
      "Epoch 4839, Loss: 0.08401649817824364, Final Batch Loss: 0.014195669442415237\n",
      "Epoch 4840, Loss: 0.04621933586895466, Final Batch Loss: 0.020053289830684662\n",
      "Epoch 4841, Loss: 0.07555332966148853, Final Batch Loss: 0.0510089136660099\n",
      "Epoch 4842, Loss: 0.08533803001046181, Final Batch Loss: 0.04122002795338631\n",
      "Epoch 4843, Loss: 0.03313711378723383, Final Batch Loss: 0.012114147655665874\n",
      "Epoch 4844, Loss: 0.026966174133121967, Final Batch Loss: 0.008455309085547924\n",
      "Epoch 4845, Loss: 0.12573811784386635, Final Batch Loss: 0.07611603289842606\n",
      "Epoch 4846, Loss: 0.037586516700685024, Final Batch Loss: 0.008588389493525028\n",
      "Epoch 4847, Loss: 0.03221097541972995, Final Batch Loss: 0.004301571752876043\n",
      "Epoch 4848, Loss: 0.02701780293136835, Final Batch Loss: 0.00862011220306158\n",
      "Epoch 4849, Loss: 0.04579809308052063, Final Batch Loss: 0.019849851727485657\n",
      "Epoch 4850, Loss: 0.03637626953423023, Final Batch Loss: 0.018566954880952835\n",
      "Epoch 4851, Loss: 0.07097781449556351, Final Batch Loss: 0.03595466911792755\n",
      "Epoch 4852, Loss: 0.045152654871344566, Final Batch Loss: 0.02028062380850315\n",
      "Epoch 4853, Loss: 0.027215879410505295, Final Batch Loss: 0.01227887999266386\n",
      "Epoch 4854, Loss: 0.05425761826336384, Final Batch Loss: 0.017876731231808662\n",
      "Epoch 4855, Loss: 0.06712825689464808, Final Batch Loss: 0.013894227333366871\n",
      "Epoch 4856, Loss: 0.08395219221711159, Final Batch Loss: 0.02822588011622429\n",
      "Epoch 4857, Loss: 0.053800261579453945, Final Batch Loss: 0.013753685168921947\n",
      "Epoch 4858, Loss: 0.03270396962761879, Final Batch Loss: 0.010613977909088135\n",
      "Epoch 4859, Loss: 0.08795789256691933, Final Batch Loss: 0.03126348555088043\n",
      "Epoch 4860, Loss: 0.05233676824718714, Final Batch Loss: 0.03864463046193123\n",
      "Epoch 4861, Loss: 0.03296726290136576, Final Batch Loss: 0.02351071685552597\n",
      "Epoch 4862, Loss: 0.04275509715080261, Final Batch Loss: 0.015651103109121323\n",
      "Epoch 4863, Loss: 0.03708047419786453, Final Batch Loss: 0.02004433609545231\n",
      "Epoch 4864, Loss: 0.05735940299928188, Final Batch Loss: 0.008324192836880684\n",
      "Epoch 4865, Loss: 0.06489260215312243, Final Batch Loss: 0.06023538112640381\n",
      "Epoch 4866, Loss: 0.05290322098881006, Final Batch Loss: 0.03732669726014137\n",
      "Epoch 4867, Loss: 0.01679600588977337, Final Batch Loss: 0.01062892097979784\n",
      "Epoch 4868, Loss: 0.08377608098089695, Final Batch Loss: 0.06160207465291023\n",
      "Epoch 4869, Loss: 0.12598606757819653, Final Batch Loss: 0.11777716875076294\n",
      "Epoch 4870, Loss: 0.030017059296369553, Final Batch Loss: 0.013218816369771957\n",
      "Epoch 4871, Loss: 0.04980184230953455, Final Batch Loss: 0.012313717044889927\n",
      "Epoch 4872, Loss: 0.03588523343205452, Final Batch Loss: 0.00852263905107975\n",
      "Epoch 4873, Loss: 0.04457077011466026, Final Batch Loss: 0.026769258081912994\n",
      "Epoch 4874, Loss: 0.043018145486712456, Final Batch Loss: 0.02405281737446785\n",
      "Epoch 4875, Loss: 0.05139102879911661, Final Batch Loss: 0.0030461112037301064\n",
      "Epoch 4876, Loss: 0.013406625017523766, Final Batch Loss: 0.007539655081927776\n",
      "Epoch 4877, Loss: 0.08258007280528545, Final Batch Loss: 0.019492080435156822\n",
      "Epoch 4878, Loss: 0.040136972442269325, Final Batch Loss: 0.023516107350587845\n",
      "Epoch 4879, Loss: 0.04977200459688902, Final Batch Loss: 0.011975298635661602\n",
      "Epoch 4880, Loss: 0.049507565796375275, Final Batch Loss: 0.031472694128751755\n",
      "Epoch 4881, Loss: 0.027541160583496094, Final Batch Loss: 0.014680393971502781\n",
      "Epoch 4882, Loss: 0.036402507685124874, Final Batch Loss: 0.028958866372704506\n",
      "Epoch 4883, Loss: 0.015772037208080292, Final Batch Loss: 0.007888241671025753\n",
      "Epoch 4884, Loss: 0.029172662645578384, Final Batch Loss: 0.02204947918653488\n",
      "Epoch 4885, Loss: 0.07632776536047459, Final Batch Loss: 0.03050805814564228\n",
      "Epoch 4886, Loss: 0.032690417021512985, Final Batch Loss: 0.017077969387173653\n",
      "Epoch 4887, Loss: 0.09383602067828178, Final Batch Loss: 0.04132811352610588\n",
      "Epoch 4888, Loss: 0.045779299922287464, Final Batch Loss: 0.03606138005852699\n",
      "Epoch 4889, Loss: 0.03622736781835556, Final Batch Loss: 0.012049034237861633\n",
      "Epoch 4890, Loss: 0.060254212468862534, Final Batch Loss: 0.026565153151750565\n",
      "Epoch 4891, Loss: 0.08477664180099964, Final Batch Loss: 0.05581530183553696\n",
      "Epoch 4892, Loss: 0.0761458519846201, Final Batch Loss: 0.04512700438499451\n",
      "Epoch 4893, Loss: 0.043344445526599884, Final Batch Loss: 0.022475775331258774\n",
      "Epoch 4894, Loss: 0.047380889765918255, Final Batch Loss: 0.014819989912211895\n",
      "Epoch 4895, Loss: 0.034933919087052345, Final Batch Loss: 0.016943426802754402\n",
      "Epoch 4896, Loss: 0.02095460332930088, Final Batch Loss: 0.005495080724358559\n",
      "Epoch 4897, Loss: 0.01480004983022809, Final Batch Loss: 0.007295523304492235\n",
      "Epoch 4898, Loss: 0.07954231090843678, Final Batch Loss: 0.017728572711348534\n",
      "Epoch 4899, Loss: 0.02854528557509184, Final Batch Loss: 0.013149639591574669\n",
      "Epoch 4900, Loss: 0.03248892351984978, Final Batch Loss: 0.023378880694508553\n",
      "Epoch 4901, Loss: 0.041079651564359665, Final Batch Loss: 0.015928158536553383\n",
      "Epoch 4902, Loss: 0.03532349690794945, Final Batch Loss: 0.02165498584508896\n",
      "Epoch 4903, Loss: 0.020242957398295403, Final Batch Loss: 0.0079982690513134\n",
      "Epoch 4904, Loss: 0.09595061838626862, Final Batch Loss: 0.037350498139858246\n",
      "Epoch 4905, Loss: 0.03398636635392904, Final Batch Loss: 0.013518002815544605\n",
      "Epoch 4906, Loss: 0.0413464717566967, Final Batch Loss: 0.019279301166534424\n",
      "Epoch 4907, Loss: 0.05676902085542679, Final Batch Loss: 0.009439624845981598\n",
      "Epoch 4908, Loss: 0.019662471022456884, Final Batch Loss: 0.005486675072461367\n",
      "Epoch 4909, Loss: 0.018338315188884735, Final Batch Loss: 0.00866907462477684\n",
      "Epoch 4910, Loss: 0.0967523567378521, Final Batch Loss: 0.06999490410089493\n",
      "Epoch 4911, Loss: 0.04428898170590401, Final Batch Loss: 0.02038084715604782\n",
      "Epoch 4912, Loss: 0.058090812526643276, Final Batch Loss: 0.045055802911520004\n",
      "Epoch 4913, Loss: 0.034954389557242393, Final Batch Loss: 0.014342496171593666\n",
      "Epoch 4914, Loss: 0.013718724250793457, Final Batch Loss: 0.006899911444634199\n",
      "Epoch 4915, Loss: 0.05867953039705753, Final Batch Loss: 0.02239326201379299\n",
      "Epoch 4916, Loss: 0.012008109129965305, Final Batch Loss: 0.007007481995970011\n",
      "Epoch 4917, Loss: 0.04620181932114065, Final Batch Loss: 0.002294314792379737\n",
      "Epoch 4918, Loss: 0.0269951606169343, Final Batch Loss: 0.012324499897658825\n",
      "Epoch 4919, Loss: 0.060997702181339264, Final Batch Loss: 0.02986731566488743\n",
      "Epoch 4920, Loss: 0.04406323982402682, Final Batch Loss: 0.004203430842608213\n",
      "Epoch 4921, Loss: 0.03393407352268696, Final Batch Loss: 0.013589765876531601\n",
      "Epoch 4922, Loss: 0.02172898594290018, Final Batch Loss: 0.008871649391949177\n",
      "Epoch 4923, Loss: 0.06463968381285667, Final Batch Loss: 0.04621347784996033\n",
      "Epoch 4924, Loss: 0.0520857609808445, Final Batch Loss: 0.012230180203914642\n",
      "Epoch 4925, Loss: 0.038601518608629704, Final Batch Loss: 0.012220765464007854\n",
      "Epoch 4926, Loss: 0.047216622158885, Final Batch Loss: 0.029660500586032867\n",
      "Epoch 4927, Loss: 0.01907941699028015, Final Batch Loss: 0.009742043912410736\n",
      "Epoch 4928, Loss: 0.02522538579069078, Final Batch Loss: 0.003795074066147208\n",
      "Epoch 4929, Loss: 0.10018246620893478, Final Batch Loss: 0.06959007680416107\n",
      "Epoch 4930, Loss: 0.049813331104815006, Final Batch Loss: 0.03655777871608734\n",
      "Epoch 4931, Loss: 0.02460628841072321, Final Batch Loss: 0.014540490694344044\n",
      "Epoch 4932, Loss: 0.058269142638891935, Final Batch Loss: 0.05114447697997093\n",
      "Epoch 4933, Loss: 0.057672495022416115, Final Batch Loss: 0.02727683074772358\n",
      "Epoch 4934, Loss: 0.1110009104013443, Final Batch Loss: 0.06228645518422127\n",
      "Epoch 4935, Loss: 0.024338815361261368, Final Batch Loss: 0.008865846320986748\n",
      "Epoch 4936, Loss: 0.05502267088741064, Final Batch Loss: 0.047146089375019073\n",
      "Epoch 4937, Loss: 0.07796060666441917, Final Batch Loss: 0.05769466236233711\n",
      "Epoch 4938, Loss: 0.0727345421910286, Final Batch Loss: 0.01175745204091072\n",
      "Epoch 4939, Loss: 0.03811174817383289, Final Batch Loss: 0.016955595463514328\n",
      "Epoch 4940, Loss: 0.07482882961630821, Final Batch Loss: 0.034989506006240845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4941, Loss: 0.10158026218414307, Final Batch Loss: 0.095967598259449\n",
      "Epoch 4942, Loss: 0.06062313262373209, Final Batch Loss: 0.04865526035428047\n",
      "Epoch 4943, Loss: 0.12370255216956139, Final Batch Loss: 0.08677732199430466\n",
      "Epoch 4944, Loss: 0.06962849944829941, Final Batch Loss: 0.04590689390897751\n",
      "Epoch 4945, Loss: 0.1290530152618885, Final Batch Loss: 0.05222740396857262\n",
      "Epoch 4946, Loss: 0.09632377326488495, Final Batch Loss: 0.06373818218708038\n",
      "Epoch 4947, Loss: 0.019617576152086258, Final Batch Loss: 0.009092124179005623\n",
      "Epoch 4948, Loss: 0.03497367538511753, Final Batch Loss: 0.01867307536303997\n",
      "Epoch 4949, Loss: 0.0714516993612051, Final Batch Loss: 0.026552343741059303\n",
      "Epoch 4950, Loss: 0.07521262019872665, Final Batch Loss: 0.024405837059020996\n",
      "Epoch 4951, Loss: 0.08699574135243893, Final Batch Loss: 0.05748899281024933\n",
      "Epoch 4952, Loss: 0.08019735291600227, Final Batch Loss: 0.01724223420023918\n",
      "Epoch 4953, Loss: 0.046363841742277145, Final Batch Loss: 0.02630838379263878\n",
      "Epoch 4954, Loss: 0.0235361335799098, Final Batch Loss: 0.012542717158794403\n",
      "Epoch 4955, Loss: 0.051629407331347466, Final Batch Loss: 0.03212016448378563\n",
      "Epoch 4956, Loss: 0.04207397345453501, Final Batch Loss: 0.03170177713036537\n",
      "Epoch 4957, Loss: 0.04746789112687111, Final Batch Loss: 0.024210499599575996\n",
      "Epoch 4958, Loss: 0.06842778250575066, Final Batch Loss: 0.03418123722076416\n",
      "Epoch 4959, Loss: 0.09288371726870537, Final Batch Loss: 0.06032171845436096\n",
      "Epoch 4960, Loss: 0.04090228397399187, Final Batch Loss: 0.02852707728743553\n",
      "Epoch 4961, Loss: 0.05960317142307758, Final Batch Loss: 0.036578088998794556\n",
      "Epoch 4962, Loss: 0.026480876374989748, Final Batch Loss: 0.006347802001982927\n",
      "Epoch 4963, Loss: 0.07086603529751301, Final Batch Loss: 0.04809069633483887\n",
      "Epoch 4964, Loss: 0.05128992022946477, Final Batch Loss: 0.006349292118102312\n",
      "Epoch 4965, Loss: 0.043878957629203796, Final Batch Loss: 0.026314109563827515\n",
      "Epoch 4966, Loss: 0.059044365771114826, Final Batch Loss: 0.013262459076941013\n",
      "Epoch 4967, Loss: 0.043413907289505005, Final Batch Loss: 0.007978331297636032\n",
      "Epoch 4968, Loss: 0.022483108565211296, Final Batch Loss: 0.012584451586008072\n",
      "Epoch 4969, Loss: 0.040917135775089264, Final Batch Loss: 0.022383173927664757\n",
      "Epoch 4970, Loss: 0.07008492574095726, Final Batch Loss: 0.03885749727487564\n",
      "Epoch 4971, Loss: 0.05077829211950302, Final Batch Loss: 0.021562879905104637\n",
      "Epoch 4972, Loss: 0.022708074189722538, Final Batch Loss: 0.009931725449860096\n",
      "Epoch 4973, Loss: 0.022443485911935568, Final Batch Loss: 0.007607725914567709\n",
      "Epoch 4974, Loss: 0.03852519765496254, Final Batch Loss: 0.01389838382601738\n",
      "Epoch 4975, Loss: 0.058757160790264606, Final Batch Loss: 0.011619863100349903\n",
      "Epoch 4976, Loss: 0.032586184330284595, Final Batch Loss: 0.023188794031739235\n",
      "Epoch 4977, Loss: 0.04774399008601904, Final Batch Loss: 0.03350742906332016\n",
      "Epoch 4978, Loss: 0.10733018442988396, Final Batch Loss: 0.05715057998895645\n",
      "Epoch 4979, Loss: 0.0437933299690485, Final Batch Loss: 0.015827538445591927\n",
      "Epoch 4980, Loss: 0.044486042112112045, Final Batch Loss: 0.032554980367422104\n",
      "Epoch 4981, Loss: 0.0461625549942255, Final Batch Loss: 0.039413463324308395\n",
      "Epoch 4982, Loss: 0.10940921306610107, Final Batch Loss: 0.07334566116333008\n",
      "Epoch 4983, Loss: 0.10386412590742111, Final Batch Loss: 0.05572446808218956\n",
      "Epoch 4984, Loss: 0.05692318640649319, Final Batch Loss: 0.028447063639760017\n",
      "Epoch 4985, Loss: 0.032507927156984806, Final Batch Loss: 0.011117319576442242\n",
      "Epoch 4986, Loss: 0.025207053869962692, Final Batch Loss: 0.01442994549870491\n",
      "Epoch 4987, Loss: 0.04959926847368479, Final Batch Loss: 0.011081335134804249\n",
      "Epoch 4988, Loss: 0.05613075941801071, Final Batch Loss: 0.04302451014518738\n",
      "Epoch 4989, Loss: 0.03944624215364456, Final Batch Loss: 0.021019652485847473\n",
      "Epoch 4990, Loss: 0.03299260977655649, Final Batch Loss: 0.013419750146567822\n",
      "Epoch 4991, Loss: 0.06748172454535961, Final Batch Loss: 0.049335405230522156\n",
      "Epoch 4992, Loss: 0.054666029289364815, Final Batch Loss: 0.035216622054576874\n",
      "Epoch 4993, Loss: 0.023435747250914574, Final Batch Loss: 0.010785020887851715\n",
      "Epoch 4994, Loss: 0.05865277163684368, Final Batch Loss: 0.018323013558983803\n",
      "Epoch 4995, Loss: 0.024534914642572403, Final Batch Loss: 0.014378607273101807\n",
      "Epoch 4996, Loss: 0.06922097131609917, Final Batch Loss: 0.023546021431684494\n",
      "Epoch 4997, Loss: 0.025525882840156555, Final Batch Loss: 0.004449406638741493\n",
      "Epoch 4998, Loss: 0.06813045218586922, Final Batch Loss: 0.03231975436210632\n",
      "Epoch 4999, Loss: 0.042927373200654984, Final Batch Loss: 0.005887921899557114\n",
      "Epoch 5000, Loss: 0.059742510318756104, Final Batch Loss: 0.04205820709466934\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  0  0]\n",
      " [ 0 32  0]\n",
      " [ 0  0 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        36\n",
      "           1    1.00000   1.00000   1.00000        32\n",
      "           2    1.00000   1.00000   1.00000        32\n",
      "\n",
      "    accuracy                        1.00000       100\n",
      "   macro avg    1.00000   1.00000   1.00000       100\n",
      "weighted avg    1.00000   1.00000   1.00000       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  0  0]\n",
      " [ 6 27  0]\n",
      " [ 0  0 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85000   1.00000   0.91892        34\n",
      "           1    1.00000   0.81818   0.90000        33\n",
      "           2    1.00000   1.00000   1.00000        33\n",
      "\n",
      "    accuracy                        0.94000       100\n",
      "   macro avg    0.95000   0.93939   0.93964       100\n",
      "weighted avg    0.94900   0.94000   0.93943       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
