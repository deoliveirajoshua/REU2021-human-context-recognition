{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [14, 15, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.17890465259552, Final Batch Loss: 1.0856107473373413\n",
      "Epoch 2, Loss: 2.1756207942962646, Final Batch Loss: 1.0881683826446533\n",
      "Epoch 3, Loss: 2.172484040260315, Final Batch Loss: 1.0921766757965088\n",
      "Epoch 4, Loss: 2.163689136505127, Final Batch Loss: 1.0777283906936646\n",
      "Epoch 5, Loss: 2.1630829572677612, Final Batch Loss: 1.0812480449676514\n",
      "Epoch 6, Loss: 2.1561315059661865, Final Batch Loss: 1.0729554891586304\n",
      "Epoch 7, Loss: 2.141640067100525, Final Batch Loss: 1.0662823915481567\n",
      "Epoch 8, Loss: 2.1359835863113403, Final Batch Loss: 1.069787621498108\n",
      "Epoch 9, Loss: 2.123955726623535, Final Batch Loss: 1.059021234512329\n",
      "Epoch 10, Loss: 2.116565465927124, Final Batch Loss: 1.0589808225631714\n",
      "Epoch 11, Loss: 2.1026781797409058, Final Batch Loss: 1.0537225008010864\n",
      "Epoch 12, Loss: 2.0900216102600098, Final Batch Loss: 1.0458992719650269\n",
      "Epoch 13, Loss: 2.0687891244888306, Final Batch Loss: 1.0298360586166382\n",
      "Epoch 14, Loss: 2.052584171295166, Final Batch Loss: 1.0273311138153076\n",
      "Epoch 15, Loss: 2.040870189666748, Final Batch Loss: 1.0249642133712769\n",
      "Epoch 16, Loss: 2.0187766551971436, Final Batch Loss: 1.0084383487701416\n",
      "Epoch 17, Loss: 1.9901884198188782, Final Batch Loss: 0.9929562211036682\n",
      "Epoch 18, Loss: 1.9659992456436157, Final Batch Loss: 0.9835519194602966\n",
      "Epoch 19, Loss: 1.9305179119110107, Final Batch Loss: 0.9631707668304443\n",
      "Epoch 20, Loss: 1.8720453977584839, Final Batch Loss: 0.9139294624328613\n",
      "Epoch 21, Loss: 1.8663101196289062, Final Batch Loss: 0.929927408695221\n",
      "Epoch 22, Loss: 1.8307732343673706, Final Batch Loss: 0.9012954235076904\n",
      "Epoch 23, Loss: 1.8108241558074951, Final Batch Loss: 0.8992998003959656\n",
      "Epoch 24, Loss: 1.7188684940338135, Final Batch Loss: 0.8577562570571899\n",
      "Epoch 25, Loss: 1.7160249948501587, Final Batch Loss: 0.8555492162704468\n",
      "Epoch 26, Loss: 1.6398459672927856, Final Batch Loss: 0.8308808207511902\n",
      "Epoch 27, Loss: 1.5894713997840881, Final Batch Loss: 0.7693519592285156\n",
      "Epoch 28, Loss: 1.5717207789421082, Final Batch Loss: 0.7958879470825195\n",
      "Epoch 29, Loss: 1.5285317301750183, Final Batch Loss: 0.748164176940918\n",
      "Epoch 30, Loss: 1.4795734882354736, Final Batch Loss: 0.7505932450294495\n",
      "Epoch 31, Loss: 1.399705171585083, Final Batch Loss: 0.6729721426963806\n",
      "Epoch 32, Loss: 1.35855370759964, Final Batch Loss: 0.6667866110801697\n",
      "Epoch 33, Loss: 1.305848240852356, Final Batch Loss: 0.6363140940666199\n",
      "Epoch 34, Loss: 1.2649458050727844, Final Batch Loss: 0.637931764125824\n",
      "Epoch 35, Loss: 1.188646137714386, Final Batch Loss: 0.5611885190010071\n",
      "Epoch 36, Loss: 1.2164884805679321, Final Batch Loss: 0.6082279086112976\n",
      "Epoch 37, Loss: 1.1141356825828552, Final Batch Loss: 0.5323934555053711\n",
      "Epoch 38, Loss: 1.067852795124054, Final Batch Loss: 0.5178106427192688\n",
      "Epoch 39, Loss: 1.074950397014618, Final Batch Loss: 0.5492094159126282\n",
      "Epoch 40, Loss: 1.0353187322616577, Final Batch Loss: 0.5207304358482361\n",
      "Epoch 41, Loss: 0.9387422800064087, Final Batch Loss: 0.46033650636672974\n",
      "Epoch 42, Loss: 0.9691745936870575, Final Batch Loss: 0.4950093626976013\n",
      "Epoch 43, Loss: 0.8913860321044922, Final Batch Loss: 0.42349621653556824\n",
      "Epoch 44, Loss: 0.93036949634552, Final Batch Loss: 0.4736202359199524\n",
      "Epoch 45, Loss: 0.9182696342468262, Final Batch Loss: 0.45903876423835754\n",
      "Epoch 46, Loss: 0.8831358850002289, Final Batch Loss: 0.45744588971138\n",
      "Epoch 47, Loss: 0.87151700258255, Final Batch Loss: 0.4528084397315979\n",
      "Epoch 48, Loss: 0.8566415011882782, Final Batch Loss: 0.4301377832889557\n",
      "Epoch 49, Loss: 0.748941034078598, Final Batch Loss: 0.32681289315223694\n",
      "Epoch 50, Loss: 0.80487921833992, Final Batch Loss: 0.4352991282939911\n",
      "Epoch 51, Loss: 0.8070583343505859, Final Batch Loss: 0.3810625970363617\n",
      "Epoch 52, Loss: 0.7911165654659271, Final Batch Loss: 0.39247259497642517\n",
      "Epoch 53, Loss: 0.757207602262497, Final Batch Loss: 0.3823290169239044\n",
      "Epoch 54, Loss: 0.7628145813941956, Final Batch Loss: 0.3902724087238312\n",
      "Epoch 55, Loss: 0.7100998759269714, Final Batch Loss: 0.391454815864563\n",
      "Epoch 56, Loss: 0.6985888481140137, Final Batch Loss: 0.35800451040267944\n",
      "Epoch 57, Loss: 0.6674045026302338, Final Batch Loss: 0.33413198590278625\n",
      "Epoch 58, Loss: 0.6486218273639679, Final Batch Loss: 0.3176087439060211\n",
      "Epoch 59, Loss: 0.6092407703399658, Final Batch Loss: 0.29153504967689514\n",
      "Epoch 60, Loss: 0.6952806115150452, Final Batch Loss: 0.33882662653923035\n",
      "Epoch 61, Loss: 0.6736287176609039, Final Batch Loss: 0.3326013386249542\n",
      "Epoch 62, Loss: 0.729129821062088, Final Batch Loss: 0.4639224410057068\n",
      "Epoch 63, Loss: 0.6124114990234375, Final Batch Loss: 0.3148252069950104\n",
      "Epoch 64, Loss: 0.5964837670326233, Final Batch Loss: 0.3047686219215393\n",
      "Epoch 65, Loss: 0.6524581611156464, Final Batch Loss: 0.3332894742488861\n",
      "Epoch 66, Loss: 0.6265826225280762, Final Batch Loss: 0.3521319627761841\n",
      "Epoch 67, Loss: 0.564707338809967, Final Batch Loss: 0.2994121015071869\n",
      "Epoch 68, Loss: 0.5896448791027069, Final Batch Loss: 0.2863074839115143\n",
      "Epoch 69, Loss: 0.5271947383880615, Final Batch Loss: 0.27075862884521484\n",
      "Epoch 70, Loss: 0.4997328668832779, Final Batch Loss: 0.2452072650194168\n",
      "Epoch 71, Loss: 0.5243896394968033, Final Batch Loss: 0.24109087884426117\n",
      "Epoch 72, Loss: 0.521041676402092, Final Batch Loss: 0.2913825511932373\n",
      "Epoch 73, Loss: 0.563264012336731, Final Batch Loss: 0.27362751960754395\n",
      "Epoch 74, Loss: 0.47259804606437683, Final Batch Loss: 0.22930170595645905\n",
      "Epoch 75, Loss: 0.4938453137874603, Final Batch Loss: 0.24292171001434326\n",
      "Epoch 76, Loss: 0.4299364537000656, Final Batch Loss: 0.18524496257305145\n",
      "Epoch 77, Loss: 0.5277769267559052, Final Batch Loss: 0.26898378133773804\n",
      "Epoch 78, Loss: 0.5114263892173767, Final Batch Loss: 0.2631557285785675\n",
      "Epoch 79, Loss: 0.43815797567367554, Final Batch Loss: 0.19625017046928406\n",
      "Epoch 80, Loss: 0.4667775332927704, Final Batch Loss: 0.21368345618247986\n",
      "Epoch 81, Loss: 0.41847459971904755, Final Batch Loss: 0.20756351947784424\n",
      "Epoch 82, Loss: 0.4367263615131378, Final Batch Loss: 0.2080538123846054\n",
      "Epoch 83, Loss: 0.5127353370189667, Final Batch Loss: 0.2495952844619751\n",
      "Epoch 84, Loss: 0.4234827160835266, Final Batch Loss: 0.19264157116413116\n",
      "Epoch 85, Loss: 0.4669969081878662, Final Batch Loss: 0.21539992094039917\n",
      "Epoch 86, Loss: 0.45836567878723145, Final Batch Loss: 0.1955711543560028\n",
      "Epoch 87, Loss: 0.5019980520009995, Final Batch Loss: 0.2674051523208618\n",
      "Epoch 88, Loss: 0.38730528950691223, Final Batch Loss: 0.22353261709213257\n",
      "Epoch 89, Loss: 0.3616790324449539, Final Batch Loss: 0.18723495304584503\n",
      "Epoch 90, Loss: 0.35145533084869385, Final Batch Loss: 0.1530587375164032\n",
      "Epoch 91, Loss: 0.3738684356212616, Final Batch Loss: 0.16770897805690765\n",
      "Epoch 92, Loss: 0.35319386422634125, Final Batch Loss: 0.14274263381958008\n",
      "Epoch 93, Loss: 0.4009304642677307, Final Batch Loss: 0.19778206944465637\n",
      "Epoch 94, Loss: 0.355734720826149, Final Batch Loss: 0.15606671571731567\n",
      "Epoch 95, Loss: 0.3375342935323715, Final Batch Loss: 0.1377183198928833\n",
      "Epoch 96, Loss: 0.37882037460803986, Final Batch Loss: 0.21010728180408478\n",
      "Epoch 97, Loss: 0.3236648142337799, Final Batch Loss: 0.16501131653785706\n",
      "Epoch 98, Loss: 0.38260650634765625, Final Batch Loss: 0.15987275540828705\n",
      "Epoch 99, Loss: 0.3170939087867737, Final Batch Loss: 0.1714806854724884\n",
      "Epoch 100, Loss: 0.2686045616865158, Final Batch Loss: 0.12739023566246033\n",
      "Epoch 101, Loss: 0.33952704071998596, Final Batch Loss: 0.20653443038463593\n",
      "Epoch 102, Loss: 0.2685849517583847, Final Batch Loss: 0.1369263231754303\n",
      "Epoch 103, Loss: 0.28869569301605225, Final Batch Loss: 0.14545831084251404\n",
      "Epoch 104, Loss: 0.2740907222032547, Final Batch Loss: 0.11480925977230072\n",
      "Epoch 105, Loss: 0.3083326667547226, Final Batch Loss: 0.18191835284233093\n",
      "Epoch 106, Loss: 0.31466875970363617, Final Batch Loss: 0.18713445961475372\n",
      "Epoch 107, Loss: 0.2054990530014038, Final Batch Loss: 0.09668778628110886\n",
      "Epoch 108, Loss: 0.29106609523296356, Final Batch Loss: 0.1487051546573639\n",
      "Epoch 109, Loss: 0.2436348870396614, Final Batch Loss: 0.1360228955745697\n",
      "Epoch 110, Loss: 0.21553711593151093, Final Batch Loss: 0.09564771503210068\n",
      "Epoch 111, Loss: 0.2050558477640152, Final Batch Loss: 0.08825815469026566\n",
      "Epoch 112, Loss: 0.20563530921936035, Final Batch Loss: 0.10981602221727371\n",
      "Epoch 113, Loss: 0.1614527776837349, Final Batch Loss: 0.07472605258226395\n",
      "Epoch 114, Loss: 0.17807050794363022, Final Batch Loss: 0.08513336628675461\n",
      "Epoch 115, Loss: 0.17882803827524185, Final Batch Loss: 0.08124017715454102\n",
      "Epoch 116, Loss: 0.15140531957149506, Final Batch Loss: 0.07856520265340805\n",
      "Epoch 117, Loss: 0.1989956572651863, Final Batch Loss: 0.11647635698318481\n",
      "Epoch 118, Loss: 0.19516099244356155, Final Batch Loss: 0.11185067147016525\n",
      "Epoch 119, Loss: 0.12614313513040543, Final Batch Loss: 0.06591646373271942\n",
      "Epoch 120, Loss: 0.18491464853286743, Final Batch Loss: 0.12209751456975937\n",
      "Epoch 121, Loss: 0.13647133111953735, Final Batch Loss: 0.05326763540506363\n",
      "Epoch 122, Loss: 0.13467030227184296, Final Batch Loss: 0.07137134671211243\n",
      "Epoch 123, Loss: 0.12638096511363983, Final Batch Loss: 0.05627299100160599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124, Loss: 0.0841636024415493, Final Batch Loss: 0.04312380030751228\n",
      "Epoch 125, Loss: 0.13602055236697197, Final Batch Loss: 0.05359899625182152\n",
      "Epoch 126, Loss: 0.12838851287961006, Final Batch Loss: 0.056383755058050156\n",
      "Epoch 127, Loss: 0.10134702920913696, Final Batch Loss: 0.04733125865459442\n",
      "Epoch 128, Loss: 0.08835840225219727, Final Batch Loss: 0.03603600338101387\n",
      "Epoch 129, Loss: 0.089250098913908, Final Batch Loss: 0.026749413460493088\n",
      "Epoch 130, Loss: 0.0990169532597065, Final Batch Loss: 0.045787613838911057\n",
      "Epoch 131, Loss: 0.09214109554886818, Final Batch Loss: 0.039983101189136505\n",
      "Epoch 132, Loss: 0.09923917055130005, Final Batch Loss: 0.05149802193045616\n",
      "Epoch 133, Loss: 0.09697598218917847, Final Batch Loss: 0.0622529499232769\n",
      "Epoch 134, Loss: 0.1107722707092762, Final Batch Loss: 0.07532406598329544\n",
      "Epoch 135, Loss: 0.10068311914801598, Final Batch Loss: 0.037699680775403976\n",
      "Epoch 136, Loss: 0.11499547213315964, Final Batch Loss: 0.08755038678646088\n",
      "Epoch 137, Loss: 0.06156724505126476, Final Batch Loss: 0.017933277413249016\n",
      "Epoch 138, Loss: 0.08522971346974373, Final Batch Loss: 0.04025859013199806\n",
      "Epoch 139, Loss: 0.06779325380921364, Final Batch Loss: 0.03530718758702278\n",
      "Epoch 140, Loss: 0.055959174409508705, Final Batch Loss: 0.029363984242081642\n",
      "Epoch 141, Loss: 0.08991754613816738, Final Batch Loss: 0.06951659917831421\n",
      "Epoch 142, Loss: 0.06076343543827534, Final Batch Loss: 0.01970200426876545\n",
      "Epoch 143, Loss: 0.06532856822013855, Final Batch Loss: 0.027225233614444733\n",
      "Epoch 144, Loss: 0.0680437795817852, Final Batch Loss: 0.03284621983766556\n",
      "Epoch 145, Loss: 0.07212411053478718, Final Batch Loss: 0.0440441370010376\n",
      "Epoch 146, Loss: 0.052956344559788704, Final Batch Loss: 0.020604783669114113\n",
      "Epoch 147, Loss: 0.0646061897277832, Final Batch Loss: 0.04505864158272743\n",
      "Epoch 148, Loss: 0.0647339504212141, Final Batch Loss: 0.02483493648469448\n",
      "Epoch 149, Loss: 0.06645329296588898, Final Batch Loss: 0.03579827398061752\n",
      "Epoch 150, Loss: 0.047282446175813675, Final Batch Loss: 0.021829897537827492\n",
      "Epoch 151, Loss: 0.052050589583814144, Final Batch Loss: 0.014565340243279934\n",
      "Epoch 152, Loss: 0.05354693345725536, Final Batch Loss: 0.029308754950761795\n",
      "Epoch 153, Loss: 0.05716978758573532, Final Batch Loss: 0.03407676890492439\n",
      "Epoch 154, Loss: 0.07478846609592438, Final Batch Loss: 0.031045541167259216\n",
      "Epoch 155, Loss: 0.08062368258833885, Final Batch Loss: 0.04780297726392746\n",
      "Epoch 156, Loss: 0.06858731620013714, Final Batch Loss: 0.018932199105620384\n",
      "Epoch 157, Loss: 0.05736061558127403, Final Batch Loss: 0.023928258568048477\n",
      "Epoch 158, Loss: 0.07160891406238079, Final Batch Loss: 0.04795794188976288\n",
      "Epoch 159, Loss: 0.053136734291911125, Final Batch Loss: 0.031231122091412544\n",
      "Epoch 160, Loss: 0.0463935062289238, Final Batch Loss: 0.0228367168456316\n",
      "Epoch 161, Loss: 0.05396012682467699, Final Batch Loss: 0.012504630722105503\n",
      "Epoch 162, Loss: 0.049272570759058, Final Batch Loss: 0.01387191191315651\n",
      "Epoch 163, Loss: 0.05329987592995167, Final Batch Loss: 0.03754458203911781\n",
      "Epoch 164, Loss: 0.04898778349161148, Final Batch Loss: 0.022691192105412483\n",
      "Epoch 165, Loss: 0.04973752424120903, Final Batch Loss: 0.031862523406744\n",
      "Epoch 166, Loss: 0.02837454993277788, Final Batch Loss: 0.013959042727947235\n",
      "Epoch 167, Loss: 0.03216845355927944, Final Batch Loss: 0.01633298397064209\n",
      "Epoch 168, Loss: 0.023894193582236767, Final Batch Loss: 0.013304069638252258\n",
      "Epoch 169, Loss: 0.05222257412970066, Final Batch Loss: 0.03256494551897049\n",
      "Epoch 170, Loss: 0.04615841247141361, Final Batch Loss: 0.012582672759890556\n",
      "Epoch 171, Loss: 0.03292768355458975, Final Batch Loss: 0.01357917208224535\n",
      "Epoch 172, Loss: 0.023877888917922974, Final Batch Loss: 0.009503100998699665\n",
      "Epoch 173, Loss: 0.03578571230173111, Final Batch Loss: 0.019555803388357162\n",
      "Epoch 174, Loss: 0.03255348186939955, Final Batch Loss: 0.011816048063337803\n",
      "Epoch 175, Loss: 0.03678848780691624, Final Batch Loss: 0.01607869192957878\n",
      "Epoch 176, Loss: 0.02528494317084551, Final Batch Loss: 0.017412327229976654\n",
      "Epoch 177, Loss: 0.040097156539559364, Final Batch Loss: 0.016621960327029228\n",
      "Epoch 178, Loss: 0.022053788416087627, Final Batch Loss: 0.009355660527944565\n",
      "Epoch 179, Loss: 0.031505187042057514, Final Batch Loss: 0.017638593912124634\n",
      "Epoch 180, Loss: 0.018335480708628893, Final Batch Loss: 0.007040617521852255\n",
      "Epoch 181, Loss: 0.015507789794355631, Final Batch Loss: 0.009190471842885017\n",
      "Epoch 182, Loss: 0.027213886380195618, Final Batch Loss: 0.011813336983323097\n",
      "Epoch 183, Loss: 0.02893985342234373, Final Batch Loss: 0.009114614687860012\n",
      "Epoch 184, Loss: 0.028583861887454987, Final Batch Loss: 0.014630232006311417\n",
      "Epoch 185, Loss: 0.021904267370700836, Final Batch Loss: 0.008325251750648022\n",
      "Epoch 186, Loss: 0.025479014962911606, Final Batch Loss: 0.01629244163632393\n",
      "Epoch 187, Loss: 0.02009978797286749, Final Batch Loss: 0.010031611658632755\n",
      "Epoch 188, Loss: 0.02307027578353882, Final Batch Loss: 0.01118840929120779\n",
      "Epoch 189, Loss: 0.011290835216641426, Final Batch Loss: 0.004455279093235731\n",
      "Epoch 190, Loss: 0.04374921694397926, Final Batch Loss: 0.03183159604668617\n",
      "Epoch 191, Loss: 0.026718090288341045, Final Batch Loss: 0.01121019572019577\n",
      "Epoch 192, Loss: 0.013790744356811047, Final Batch Loss: 0.009790085256099701\n",
      "Epoch 193, Loss: 0.012223377590999007, Final Batch Loss: 0.0039021994452923536\n",
      "Epoch 194, Loss: 0.03290349058806896, Final Batch Loss: 0.014568798243999481\n",
      "Epoch 195, Loss: 0.020612366497516632, Final Batch Loss: 0.010762490332126617\n",
      "Epoch 196, Loss: 0.022271367255598307, Final Batch Loss: 0.004504859913140535\n",
      "Epoch 197, Loss: 0.02117961924523115, Final Batch Loss: 0.008186670020222664\n",
      "Epoch 198, Loss: 0.019253842532634735, Final Batch Loss: 0.010218576528131962\n",
      "Epoch 199, Loss: 0.03890755772590637, Final Batch Loss: 0.018487270921468735\n",
      "Epoch 200, Loss: 0.022836917079985142, Final Batch Loss: 0.007309239357709885\n",
      "Epoch 201, Loss: 0.030087893828749657, Final Batch Loss: 0.01955060102045536\n",
      "Epoch 202, Loss: 0.013854111544787884, Final Batch Loss: 0.006881882436573505\n",
      "Epoch 203, Loss: 0.019846153911203146, Final Batch Loss: 0.013110523112118244\n",
      "Epoch 204, Loss: 0.021152514964342117, Final Batch Loss: 0.00392574816942215\n",
      "Epoch 205, Loss: 0.013254986610263586, Final Batch Loss: 0.00794392079114914\n",
      "Epoch 206, Loss: 0.015513603575527668, Final Batch Loss: 0.0084050502628088\n",
      "Epoch 207, Loss: 0.012677892111241817, Final Batch Loss: 0.005905574653297663\n",
      "Epoch 208, Loss: 0.0171166704967618, Final Batch Loss: 0.008398117497563362\n",
      "Epoch 209, Loss: 0.0054537751711905, Final Batch Loss: 0.0020955463405698538\n",
      "Epoch 210, Loss: 0.020049133338034153, Final Batch Loss: 0.0050984760746359825\n",
      "Epoch 211, Loss: 0.006212261971086264, Final Batch Loss: 0.0024447478353977203\n",
      "Epoch 212, Loss: 0.009314138675108552, Final Batch Loss: 0.003138727741315961\n",
      "Epoch 213, Loss: 0.04007166437804699, Final Batch Loss: 0.0192132368683815\n",
      "Epoch 214, Loss: 0.03378064464777708, Final Batch Loss: 0.030328061431646347\n",
      "Epoch 215, Loss: 0.009811952011659741, Final Batch Loss: 0.006643951404839754\n",
      "Epoch 216, Loss: 0.026166527066379786, Final Batch Loss: 0.01845202036201954\n",
      "Epoch 217, Loss: 0.013974986970424652, Final Batch Loss: 0.005414319224655628\n",
      "Epoch 218, Loss: 0.014330642763525248, Final Batch Loss: 0.008737382479012012\n",
      "Epoch 219, Loss: 0.016903799027204514, Final Batch Loss: 0.011474080383777618\n",
      "Epoch 220, Loss: 0.01481564505957067, Final Batch Loss: 0.002515337197110057\n",
      "Epoch 221, Loss: 0.024928578175604343, Final Batch Loss: 0.0066545503214001656\n",
      "Epoch 222, Loss: 0.0098903882317245, Final Batch Loss: 0.0039662886410951614\n",
      "Epoch 223, Loss: 0.015975636430084705, Final Batch Loss: 0.009285501204431057\n",
      "Epoch 224, Loss: 0.021609588991850615, Final Batch Loss: 0.01400185190141201\n",
      "Epoch 225, Loss: 0.06423763930797577, Final Batch Loss: 0.049492593854665756\n",
      "Epoch 226, Loss: 0.02184108505025506, Final Batch Loss: 0.016208989545702934\n",
      "Epoch 227, Loss: 0.014142237836495042, Final Batch Loss: 0.0010723110754042864\n",
      "Epoch 228, Loss: 0.020358534529805183, Final Batch Loss: 0.012804070487618446\n",
      "Epoch 229, Loss: 0.015432935208082199, Final Batch Loss: 0.008930029347538948\n",
      "Epoch 230, Loss: 0.035412746481597424, Final Batch Loss: 0.02243754081428051\n",
      "Epoch 231, Loss: 0.011630916967988014, Final Batch Loss: 0.005590380635112524\n",
      "Epoch 232, Loss: 0.039555374067276716, Final Batch Loss: 0.035451602190732956\n",
      "Epoch 233, Loss: 0.01065752748399973, Final Batch Loss: 0.0025885114446282387\n",
      "Epoch 234, Loss: 0.015511445119045675, Final Batch Loss: 0.001567425555549562\n",
      "Epoch 235, Loss: 0.009214160963892937, Final Batch Loss: 0.004675811156630516\n",
      "Epoch 236, Loss: 0.012483859900385141, Final Batch Loss: 0.005501183215528727\n",
      "Epoch 237, Loss: 0.02179017663002014, Final Batch Loss: 0.004290491342544556\n",
      "Epoch 238, Loss: 0.005960924085229635, Final Batch Loss: 0.0011070938780903816\n",
      "Epoch 239, Loss: 0.01043555373325944, Final Batch Loss: 0.0035128071904182434\n",
      "Epoch 240, Loss: 0.015198064502328634, Final Batch Loss: 0.010380263440310955\n",
      "Epoch 241, Loss: 0.0059528229758143425, Final Batch Loss: 0.0031353302765637636\n",
      "Epoch 242, Loss: 0.00661629275418818, Final Batch Loss: 0.0031028769444674253\n",
      "Epoch 243, Loss: 0.017769405618309975, Final Batch Loss: 0.011746656149625778\n",
      "Epoch 244, Loss: 0.014877655310556293, Final Batch Loss: 0.01136440597474575\n",
      "Epoch 245, Loss: 0.01960432343184948, Final Batch Loss: 0.01114029623568058\n",
      "Epoch 246, Loss: 0.003665760043077171, Final Batch Loss: 0.0012938611907884479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247, Loss: 0.01824135333299637, Final Batch Loss: 0.015533833764493465\n",
      "Epoch 248, Loss: 0.022907700389623642, Final Batch Loss: 0.01378594059497118\n",
      "Epoch 249, Loss: 0.010731697548180819, Final Batch Loss: 0.0018435087986290455\n",
      "Epoch 250, Loss: 0.005510726943612099, Final Batch Loss: 0.004589650314301252\n",
      "Epoch 251, Loss: 0.00540820905007422, Final Batch Loss: 0.0026623986195772886\n",
      "Epoch 252, Loss: 0.017216285690665245, Final Batch Loss: 0.010543699376285076\n",
      "Epoch 253, Loss: 0.0055260497611016035, Final Batch Loss: 0.002551630837842822\n",
      "Epoch 254, Loss: 0.007724222959950566, Final Batch Loss: 0.0036615219432860613\n",
      "Epoch 255, Loss: 0.014949595090001822, Final Batch Loss: 0.011252754367887974\n",
      "Epoch 256, Loss: 0.012371520511806011, Final Batch Loss: 0.007418765686452389\n",
      "Epoch 257, Loss: 0.011971579864621162, Final Batch Loss: 0.009612812660634518\n",
      "Epoch 258, Loss: 0.014450350776314735, Final Batch Loss: 0.009931380860507488\n",
      "Epoch 259, Loss: 0.011036132229492068, Final Batch Loss: 0.002640698803588748\n",
      "Epoch 260, Loss: 0.01528705982491374, Final Batch Loss: 0.010542986914515495\n",
      "Epoch 261, Loss: 0.028864176012575626, Final Batch Loss: 0.00898799393326044\n",
      "Epoch 262, Loss: 0.014836279209703207, Final Batch Loss: 0.005604626145213842\n",
      "Epoch 263, Loss: 0.007556247524917126, Final Batch Loss: 0.0026304316706955433\n",
      "Epoch 264, Loss: 0.03390005952678621, Final Batch Loss: 0.0030383558478206396\n",
      "Epoch 265, Loss: 0.0225482857786119, Final Batch Loss: 0.017687078565359116\n",
      "Epoch 266, Loss: 0.0037778744008392096, Final Batch Loss: 0.0018712617456912994\n",
      "Epoch 267, Loss: 0.006874525279272348, Final Batch Loss: 0.0007635944639332592\n",
      "Epoch 268, Loss: 0.023771947249770164, Final Batch Loss: 0.01338838879019022\n",
      "Epoch 269, Loss: 0.011443490628153086, Final Batch Loss: 0.007299778982996941\n",
      "Epoch 270, Loss: 0.014624292962253094, Final Batch Loss: 0.006124233826994896\n",
      "Epoch 271, Loss: 0.003474459983408451, Final Batch Loss: 0.0012189249973744154\n",
      "Epoch 272, Loss: 0.0033719322527758777, Final Batch Loss: 0.000935366319026798\n",
      "Epoch 273, Loss: 0.00757216929923743, Final Batch Loss: 0.006529453210532665\n",
      "Epoch 274, Loss: 0.010205278755165637, Final Batch Loss: 0.0017361805075779557\n",
      "Epoch 275, Loss: 0.012615642044693232, Final Batch Loss: 0.006096636410802603\n",
      "Epoch 276, Loss: 0.0059677057433873415, Final Batch Loss: 0.0034825503826141357\n",
      "Epoch 277, Loss: 0.007408613106235862, Final Batch Loss: 0.0038605218287557364\n",
      "Epoch 278, Loss: 0.011116977781057358, Final Batch Loss: 0.00604378804564476\n",
      "Epoch 279, Loss: 0.016313062980771065, Final Batch Loss: 0.005173850804567337\n",
      "Epoch 280, Loss: 0.007351550972089171, Final Batch Loss: 0.002530349651351571\n",
      "Epoch 281, Loss: 0.009126556455157697, Final Batch Loss: 0.0013756005791947246\n",
      "Epoch 282, Loss: 0.006687189219519496, Final Batch Loss: 0.0021759828086942434\n",
      "Epoch 283, Loss: 0.013968973886221647, Final Batch Loss: 0.006822127383202314\n",
      "Epoch 284, Loss: 0.01833112956956029, Final Batch Loss: 0.003137787338346243\n",
      "Epoch 285, Loss: 0.0041659504640847445, Final Batch Loss: 0.0016386238858103752\n",
      "Epoch 286, Loss: 0.003737730556167662, Final Batch Loss: 0.0011735375737771392\n",
      "Epoch 287, Loss: 0.010978500358760357, Final Batch Loss: 0.00434290524572134\n",
      "Epoch 288, Loss: 0.007174301310442388, Final Batch Loss: 0.006504534278064966\n",
      "Epoch 289, Loss: 0.010065621696412563, Final Batch Loss: 0.004391181282699108\n",
      "Epoch 290, Loss: 0.01664546364918351, Final Batch Loss: 0.011705921962857246\n",
      "Epoch 291, Loss: 0.01578661985695362, Final Batch Loss: 0.0032345568761229515\n",
      "Epoch 292, Loss: 0.003515076241455972, Final Batch Loss: 0.0013042400823906064\n",
      "Epoch 293, Loss: 0.012489346321672201, Final Batch Loss: 0.0077599165961146355\n",
      "Epoch 294, Loss: 0.010453494265675545, Final Batch Loss: 0.007181320805102587\n",
      "Epoch 295, Loss: 0.007455428596585989, Final Batch Loss: 0.0023440131917595863\n",
      "Epoch 296, Loss: 0.010832206346094608, Final Batch Loss: 0.005731197539716959\n",
      "Epoch 297, Loss: 0.01626623049378395, Final Batch Loss: 0.0012152809649705887\n",
      "Epoch 298, Loss: 0.013016771234106272, Final Batch Loss: 0.0008979548583738506\n",
      "Epoch 299, Loss: 0.0033458847319707274, Final Batch Loss: 0.0012878273846581578\n",
      "Epoch 300, Loss: 0.0034760847338475287, Final Batch Loss: 0.002563528483733535\n",
      "Epoch 301, Loss: 0.008569956989958882, Final Batch Loss: 0.006163671147078276\n",
      "Epoch 302, Loss: 0.002703302714508027, Final Batch Loss: 0.0006898755091242492\n",
      "Epoch 303, Loss: 0.004865319700911641, Final Batch Loss: 0.0011466178111732006\n",
      "Epoch 304, Loss: 0.003416441148146987, Final Batch Loss: 0.0026852572336792946\n",
      "Epoch 305, Loss: 0.0033852960914373398, Final Batch Loss: 0.0025112659204751253\n",
      "Epoch 306, Loss: 0.0033549186773598194, Final Batch Loss: 0.0009370625484734774\n",
      "Epoch 307, Loss: 0.005738172214478254, Final Batch Loss: 0.004577831830829382\n",
      "Epoch 308, Loss: 0.0024528346257284284, Final Batch Loss: 0.001314933761022985\n",
      "Epoch 309, Loss: 0.003511750721372664, Final Batch Loss: 0.0014409847790375352\n",
      "Epoch 310, Loss: 0.00461546506267041, Final Batch Loss: 0.0030881331767886877\n",
      "Epoch 311, Loss: 0.005300508579239249, Final Batch Loss: 0.0025518781039863825\n",
      "Epoch 312, Loss: 0.005026099272072315, Final Batch Loss: 0.0021253295708447695\n",
      "Epoch 313, Loss: 0.004402415594086051, Final Batch Loss: 0.0020802663639187813\n",
      "Epoch 314, Loss: 0.019538577878847718, Final Batch Loss: 0.0031430425588041544\n",
      "Epoch 315, Loss: 0.016844123252667487, Final Batch Loss: 0.01523903850466013\n",
      "Epoch 316, Loss: 0.01926710340194404, Final Batch Loss: 0.018094917759299278\n",
      "Epoch 317, Loss: 0.008616540115326643, Final Batch Loss: 0.0026589524932205677\n",
      "Epoch 318, Loss: 0.006300843320786953, Final Batch Loss: 0.0008551729843020439\n",
      "Epoch 319, Loss: 0.004207562189549208, Final Batch Loss: 0.0017637880519032478\n",
      "Epoch 320, Loss: 0.0018890638166340068, Final Batch Loss: 0.0017036419594660401\n",
      "Epoch 321, Loss: 0.001633819774724543, Final Batch Loss: 0.0009140566107816994\n",
      "Epoch 322, Loss: 0.007641947828233242, Final Batch Loss: 0.005205286201089621\n",
      "Epoch 323, Loss: 0.005217412486672401, Final Batch Loss: 0.0022961897775530815\n",
      "Epoch 324, Loss: 0.005708671757020056, Final Batch Loss: 0.0009813472861424088\n",
      "Epoch 325, Loss: 0.005083423340693116, Final Batch Loss: 0.0022656910587102175\n",
      "Epoch 326, Loss: 0.0025763491285033524, Final Batch Loss: 0.0007800966850481927\n",
      "Epoch 327, Loss: 0.0044672267977148294, Final Batch Loss: 0.0016364678740501404\n",
      "Epoch 328, Loss: 0.008245027158409357, Final Batch Loss: 0.005333969835191965\n",
      "Epoch 329, Loss: 0.0030491967918351293, Final Batch Loss: 0.0009936633286997676\n",
      "Epoch 330, Loss: 0.005279423494357616, Final Batch Loss: 0.0009559884783811867\n",
      "Epoch 331, Loss: 0.00670463964343071, Final Batch Loss: 0.005141131579875946\n",
      "Epoch 332, Loss: 0.006195632595336065, Final Batch Loss: 0.00042741777724586427\n",
      "Epoch 333, Loss: 0.007349747815169394, Final Batch Loss: 0.0057379514910280704\n",
      "Epoch 334, Loss: 0.016384867019951344, Final Batch Loss: 0.0028954623267054558\n",
      "Epoch 335, Loss: 0.0031764390878379345, Final Batch Loss: 0.0015189081896096468\n",
      "Epoch 336, Loss: 0.002899669576436281, Final Batch Loss: 0.001182273030281067\n",
      "Epoch 337, Loss: 0.003991010948084295, Final Batch Loss: 0.001730467309243977\n",
      "Epoch 338, Loss: 0.002865427639335394, Final Batch Loss: 0.0016102077206596732\n",
      "Epoch 339, Loss: 0.005875244794879109, Final Batch Loss: 0.0005171639495529234\n",
      "Epoch 340, Loss: 0.005616742419078946, Final Batch Loss: 0.0002959833946079016\n",
      "Epoch 341, Loss: 0.007091601029969752, Final Batch Loss: 0.0014788844855502248\n",
      "Epoch 342, Loss: 0.0026280198944732547, Final Batch Loss: 0.0005125327734276652\n",
      "Epoch 343, Loss: 0.011917178984731436, Final Batch Loss: 0.0023197284899652004\n",
      "Epoch 344, Loss: 0.0030758943175897002, Final Batch Loss: 0.0015831824857741594\n",
      "Epoch 345, Loss: 0.019052244955673814, Final Batch Loss: 0.002167975762858987\n",
      "Epoch 346, Loss: 0.004392725182697177, Final Batch Loss: 0.002889102092012763\n",
      "Epoch 347, Loss: 0.0022586898412555456, Final Batch Loss: 0.0015009447233751416\n",
      "Epoch 348, Loss: 0.004004344678833149, Final Batch Loss: 0.00021565436327364296\n",
      "Epoch 349, Loss: 0.04018586315214634, Final Batch Loss: 0.021724147722125053\n",
      "Epoch 350, Loss: 0.010572834871709347, Final Batch Loss: 0.0039310092106461525\n",
      "Epoch 351, Loss: 0.0028040711185894907, Final Batch Loss: 0.0005155784892849624\n",
      "Epoch 352, Loss: 0.004309171694330871, Final Batch Loss: 0.002870219759643078\n",
      "Epoch 353, Loss: 0.009989168494939804, Final Batch Loss: 0.0005394900217652321\n",
      "Epoch 354, Loss: 0.002721487428061664, Final Batch Loss: 0.000737580587156117\n",
      "Epoch 355, Loss: 0.016969283227808774, Final Batch Loss: 0.015742463991045952\n",
      "Epoch 356, Loss: 0.025391351897269487, Final Batch Loss: 0.006080857012420893\n",
      "Epoch 357, Loss: 0.00586447399109602, Final Batch Loss: 0.003849594620987773\n",
      "Epoch 358, Loss: 0.019689794862642884, Final Batch Loss: 0.018462851643562317\n",
      "Epoch 359, Loss: 0.005473126191645861, Final Batch Loss: 0.0032574834767729044\n",
      "Epoch 360, Loss: 0.006866604322567582, Final Batch Loss: 0.001439506420865655\n",
      "Epoch 361, Loss: 0.003927582409232855, Final Batch Loss: 0.0027269325219094753\n",
      "Epoch 362, Loss: 0.0018195780576206744, Final Batch Loss: 0.00033055379753932357\n",
      "Epoch 363, Loss: 0.0026357839815318584, Final Batch Loss: 0.0005803233943879604\n",
      "Epoch 364, Loss: 0.004157853429205716, Final Batch Loss: 0.001830330933444202\n",
      "Epoch 365, Loss: 0.004982047248631716, Final Batch Loss: 0.0034123705700039864\n",
      "Epoch 366, Loss: 0.0028593004681169987, Final Batch Loss: 0.001379065215587616\n",
      "Epoch 367, Loss: 0.0018459553248248994, Final Batch Loss: 0.0008722424972802401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368, Loss: 0.0090628566686064, Final Batch Loss: 0.00610940670594573\n",
      "Epoch 369, Loss: 0.014194258983479813, Final Batch Loss: 0.00030015179072506726\n",
      "Epoch 370, Loss: 0.004620229417923838, Final Batch Loss: 0.0039243074133992195\n",
      "Epoch 371, Loss: 0.0022984453244134784, Final Batch Loss: 0.0006660163635388017\n",
      "Epoch 372, Loss: 0.0021418322576209903, Final Batch Loss: 0.0015996844740584493\n",
      "Epoch 373, Loss: 0.0010510481370147318, Final Batch Loss: 0.0003076922439504415\n",
      "Epoch 374, Loss: 0.0012736371718347073, Final Batch Loss: 0.00027463282458484173\n",
      "Epoch 375, Loss: 0.0021182170312386006, Final Batch Loss: 0.000471182371256873\n",
      "Epoch 376, Loss: 0.009894606948364526, Final Batch Loss: 0.009242072701454163\n",
      "Epoch 377, Loss: 0.0027782561955973506, Final Batch Loss: 0.0013830942334607244\n",
      "Epoch 378, Loss: 0.003119909204542637, Final Batch Loss: 0.0013334908289834857\n",
      "Epoch 379, Loss: 0.0017903833650052547, Final Batch Loss: 0.0005682306364178658\n",
      "Epoch 380, Loss: 0.0034040441969409585, Final Batch Loss: 0.0004233968211337924\n",
      "Epoch 381, Loss: 0.001262082194443792, Final Batch Loss: 0.0002580799045972526\n",
      "Epoch 382, Loss: 0.004075707867741585, Final Batch Loss: 0.002102449769154191\n",
      "Epoch 383, Loss: 0.0015117052535060793, Final Batch Loss: 0.0002458205271977931\n",
      "Epoch 384, Loss: 0.00599629757925868, Final Batch Loss: 0.0029790650587528944\n",
      "Epoch 385, Loss: 0.0018693991005420685, Final Batch Loss: 0.0006308438023552299\n",
      "Epoch 386, Loss: 0.009599780663847923, Final Batch Loss: 0.0010652225464582443\n",
      "Epoch 387, Loss: 0.006984050269238651, Final Batch Loss: 0.0051094465889036655\n",
      "Epoch 388, Loss: 0.0077725371811538935, Final Batch Loss: 0.004523767624050379\n",
      "Epoch 389, Loss: 0.0050536495400592685, Final Batch Loss: 0.0013354666298255324\n",
      "Epoch 390, Loss: 0.005683698924258351, Final Batch Loss: 0.004050264600664377\n",
      "Epoch 391, Loss: 0.0012954127741977572, Final Batch Loss: 0.0008992812945507467\n",
      "Epoch 392, Loss: 0.0022976223845034838, Final Batch Loss: 0.0013777853455394506\n",
      "Epoch 393, Loss: 0.02473622711841017, Final Batch Loss: 0.0014608778292313218\n",
      "Epoch 394, Loss: 0.002052408002782613, Final Batch Loss: 0.0005363255622796714\n",
      "Epoch 395, Loss: 0.0009004893363453448, Final Batch Loss: 0.00027390412287786603\n",
      "Epoch 396, Loss: 0.009466379880905151, Final Batch Loss: 0.0031798705458641052\n",
      "Epoch 397, Loss: 0.006199927069246769, Final Batch Loss: 0.0002181483432650566\n",
      "Epoch 398, Loss: 0.002597629325464368, Final Batch Loss: 0.001006220350973308\n",
      "Epoch 399, Loss: 0.0019900986517313868, Final Batch Loss: 0.00030478896223939955\n",
      "Epoch 400, Loss: 0.009121053852140903, Final Batch Loss: 0.0037335827946662903\n",
      "Epoch 401, Loss: 0.000811624777270481, Final Batch Loss: 0.0005495569203048944\n",
      "Epoch 402, Loss: 0.003236884716898203, Final Batch Loss: 0.0010941128712147474\n",
      "Epoch 403, Loss: 0.03267411794513464, Final Batch Loss: 0.019720328971743584\n",
      "Epoch 404, Loss: 0.008143023704178631, Final Batch Loss: 0.00720953568816185\n",
      "Epoch 405, Loss: 0.010295639745891094, Final Batch Loss: 0.006901211570948362\n",
      "Epoch 406, Loss: 0.002506265649572015, Final Batch Loss: 0.002060981234535575\n",
      "Epoch 407, Loss: 0.009181310888379812, Final Batch Loss: 0.005282444879412651\n",
      "Epoch 408, Loss: 0.011621721554547548, Final Batch Loss: 0.0039023561403155327\n",
      "Epoch 409, Loss: 0.003990250523202121, Final Batch Loss: 0.0026701639872044325\n",
      "Epoch 410, Loss: 0.006606534036109224, Final Batch Loss: 0.006178533658385277\n",
      "Epoch 411, Loss: 0.006520008202642202, Final Batch Loss: 0.0034827375784516335\n",
      "Epoch 412, Loss: 0.003089775040280074, Final Batch Loss: 0.0007338290452025831\n",
      "Epoch 413, Loss: 0.009171102894470096, Final Batch Loss: 0.001055075554177165\n",
      "Epoch 414, Loss: 0.009500063490122557, Final Batch Loss: 0.003728581126779318\n",
      "Epoch 415, Loss: 0.030180178117007017, Final Batch Loss: 0.02876533381640911\n",
      "Epoch 416, Loss: 0.0023121439735405147, Final Batch Loss: 0.0019917490426450968\n",
      "Epoch 417, Loss: 0.0018299890216439962, Final Batch Loss: 0.0012729467125609517\n",
      "Epoch 418, Loss: 0.0030360532691702247, Final Batch Loss: 0.0016082716174423695\n",
      "Epoch 419, Loss: 0.005133581114932895, Final Batch Loss: 0.003009901847690344\n",
      "Epoch 420, Loss: 0.001528364373371005, Final Batch Loss: 0.0005174988182261586\n",
      "Epoch 421, Loss: 0.0029372370336204767, Final Batch Loss: 0.002339546335861087\n",
      "Epoch 422, Loss: 0.003117087238933891, Final Batch Loss: 0.0028316345997154713\n",
      "Epoch 423, Loss: 0.0029909657314419746, Final Batch Loss: 0.0005922147538512945\n",
      "Epoch 424, Loss: 0.027700571808964014, Final Batch Loss: 0.005433874670416117\n",
      "Epoch 425, Loss: 0.0032388867693953216, Final Batch Loss: 0.0007344209006987512\n",
      "Epoch 426, Loss: 0.01701812178362161, Final Batch Loss: 0.00043052167166024446\n",
      "Epoch 427, Loss: 0.00260264053940773, Final Batch Loss: 0.0007848000386729836\n",
      "Epoch 428, Loss: 0.021373304538428783, Final Batch Loss: 0.002133130095899105\n",
      "Epoch 429, Loss: 0.001936127635417506, Final Batch Loss: 0.0002725997183006257\n",
      "Epoch 430, Loss: 0.0032188063487410545, Final Batch Loss: 0.0009378297254443169\n",
      "Epoch 431, Loss: 0.0003024530742550269, Final Batch Loss: 0.00010667767492122948\n",
      "Epoch 432, Loss: 0.0027906461036764085, Final Batch Loss: 0.0009084350313059986\n",
      "Epoch 433, Loss: 0.006069403199944645, Final Batch Loss: 0.0008896110230125487\n",
      "Epoch 434, Loss: 0.0017794756568036973, Final Batch Loss: 0.0006520980386994779\n",
      "Epoch 435, Loss: 0.0024154328857548535, Final Batch Loss: 0.0005709982360713184\n",
      "Epoch 436, Loss: 0.0018104882910847664, Final Batch Loss: 0.0012751329923048615\n",
      "Epoch 437, Loss: 0.003095428692176938, Final Batch Loss: 0.001119678607210517\n",
      "Epoch 438, Loss: 0.006036239676177502, Final Batch Loss: 0.00016147363930940628\n",
      "Epoch 439, Loss: 0.0024200283805839717, Final Batch Loss: 0.0016786785563454032\n",
      "Epoch 440, Loss: 0.0018494373362045735, Final Batch Loss: 0.0015618600882589817\n",
      "Epoch 441, Loss: 0.002938613761216402, Final Batch Loss: 0.0011521622072905302\n",
      "Epoch 442, Loss: 0.0033936083782464266, Final Batch Loss: 0.001969204982742667\n",
      "Epoch 443, Loss: 0.0052298197988420725, Final Batch Loss: 0.0018130710814148188\n",
      "Epoch 444, Loss: 0.0009657277987571433, Final Batch Loss: 0.00015162421914283186\n",
      "Epoch 445, Loss: 0.0023165963357314467, Final Batch Loss: 0.0013917309697717428\n",
      "Epoch 446, Loss: 0.00040308166353497654, Final Batch Loss: 0.00010474982263986021\n",
      "Epoch 447, Loss: 0.002763881755527109, Final Batch Loss: 0.0007759725558571517\n",
      "Epoch 448, Loss: 0.0026298876327928156, Final Batch Loss: 0.0002924416621681303\n",
      "Epoch 449, Loss: 0.003222555620595813, Final Batch Loss: 0.0015368741005659103\n",
      "Epoch 450, Loss: 0.011844652239233255, Final Batch Loss: 0.0019681635312736034\n",
      "Epoch 451, Loss: 0.0013410360552370548, Final Batch Loss: 0.00018179439939558506\n",
      "Epoch 452, Loss: 0.0010098645580001175, Final Batch Loss: 0.00047773285768926144\n",
      "Epoch 453, Loss: 0.0012280028022360057, Final Batch Loss: 0.00038135642535053194\n",
      "Epoch 454, Loss: 0.0034489938989281654, Final Batch Loss: 0.0019298717379570007\n",
      "Epoch 455, Loss: 0.0035389151889830828, Final Batch Loss: 0.0019111024448648095\n",
      "Epoch 456, Loss: 0.0036320069921202958, Final Batch Loss: 0.0029666966293007135\n",
      "Epoch 457, Loss: 0.00244446360738948, Final Batch Loss: 0.0014962839195504785\n",
      "Epoch 458, Loss: 0.005335552676115185, Final Batch Loss: 0.004367894493043423\n",
      "Epoch 459, Loss: 0.0017643595638219267, Final Batch Loss: 0.001314594759605825\n",
      "Epoch 460, Loss: 0.002737856120802462, Final Batch Loss: 0.0025139297358691692\n",
      "Epoch 461, Loss: 0.002685300656594336, Final Batch Loss: 0.001969490200281143\n",
      "Epoch 462, Loss: 0.0023420327925123274, Final Batch Loss: 0.000666921550873667\n",
      "Epoch 463, Loss: 0.004290647862944752, Final Batch Loss: 0.000851919932756573\n",
      "Epoch 464, Loss: 0.0023199276765808463, Final Batch Loss: 0.0014826528495177627\n",
      "Epoch 465, Loss: 0.002718628558795899, Final Batch Loss: 0.0004899855121038854\n",
      "Epoch 466, Loss: 0.005205878289416432, Final Batch Loss: 0.002775017637759447\n",
      "Epoch 467, Loss: 0.0005927857346250676, Final Batch Loss: 0.00010338561696698889\n",
      "Epoch 468, Loss: 0.0014089957694523036, Final Batch Loss: 0.0006887617637403309\n",
      "Epoch 469, Loss: 0.0027851926861330867, Final Batch Loss: 0.00021760992240160704\n",
      "Epoch 470, Loss: 0.0023223822354339063, Final Batch Loss: 0.00040653854375705123\n",
      "Epoch 471, Loss: 0.0007328181527554989, Final Batch Loss: 0.00041218704427592456\n",
      "Epoch 472, Loss: 0.002659225952811539, Final Batch Loss: 0.0004641901468858123\n",
      "Epoch 473, Loss: 0.001344588861684315, Final Batch Loss: 0.00024126416246872395\n",
      "Epoch 474, Loss: 0.006307356525212526, Final Batch Loss: 0.004931626375764608\n",
      "Epoch 475, Loss: 0.023903905297629535, Final Batch Loss: 0.00029949552845209837\n",
      "Epoch 476, Loss: 0.0006651650037383661, Final Batch Loss: 0.0004415869479998946\n",
      "Epoch 477, Loss: 0.0012100217572879046, Final Batch Loss: 0.0004458945186343044\n",
      "Epoch 478, Loss: 0.007516551995649934, Final Batch Loss: 0.0010704866144806147\n",
      "Epoch 479, Loss: 0.0018538815784268081, Final Batch Loss: 0.00027311156736686826\n",
      "Epoch 480, Loss: 0.004718222888186574, Final Batch Loss: 0.0014364277012646198\n",
      "Epoch 481, Loss: 0.0013096022885292768, Final Batch Loss: 0.0009081181487999856\n",
      "Epoch 482, Loss: 0.003798112622462213, Final Batch Loss: 0.002268090844154358\n",
      "Epoch 483, Loss: 0.002887074733735062, Final Batch Loss: 0.0026811533607542515\n",
      "Epoch 484, Loss: 0.0030358127551153302, Final Batch Loss: 0.0017637170385569334\n",
      "Epoch 485, Loss: 0.002292668796144426, Final Batch Loss: 0.0010447498643770814\n",
      "Epoch 486, Loss: 0.0010227040911559016, Final Batch Loss: 0.0003363817522767931\n",
      "Epoch 487, Loss: 0.002643690153490752, Final Batch Loss: 0.002148717874661088\n",
      "Epoch 488, Loss: 0.0013449990801746026, Final Batch Loss: 0.00018745499255601317\n",
      "Epoch 489, Loss: 0.006072228075936437, Final Batch Loss: 0.0020498514641076326\n",
      "Epoch 490, Loss: 0.003704977687448263, Final Batch Loss: 0.0029837442561984062\n",
      "Epoch 491, Loss: 0.0003805383021244779, Final Batch Loss: 0.0002294019068358466\n",
      "Epoch 492, Loss: 0.00431703613139689, Final Batch Loss: 0.003316726768389344\n",
      "Epoch 493, Loss: 0.0030175525389495306, Final Batch Loss: 0.0028993163723498583\n",
      "Epoch 494, Loss: 0.0011564686137717217, Final Batch Loss: 0.00018176375306211412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495, Loss: 0.0008464625861961395, Final Batch Loss: 0.00032817121245898306\n",
      "Epoch 496, Loss: 0.0029989758622832596, Final Batch Loss: 0.0005685841315425932\n",
      "Epoch 497, Loss: 0.0038534447085112333, Final Batch Loss: 0.003055605571717024\n",
      "Epoch 498, Loss: 0.0017882663232740015, Final Batch Loss: 0.0014400782529264688\n",
      "Epoch 499, Loss: 0.0033123934408649802, Final Batch Loss: 0.0015655466122552752\n",
      "Epoch 500, Loss: 0.000360765028744936, Final Batch Loss: 0.00018986911163665354\n",
      "Epoch 501, Loss: 0.0017085261642932892, Final Batch Loss: 0.0010123519459739327\n",
      "Epoch 502, Loss: 0.0008108469191938639, Final Batch Loss: 0.0005396079504862428\n",
      "Epoch 503, Loss: 0.0013540777727030218, Final Batch Loss: 0.0009278235374949872\n",
      "Epoch 504, Loss: 0.0012362125198706053, Final Batch Loss: 0.00010125288827111945\n",
      "Epoch 505, Loss: 0.002298672392498702, Final Batch Loss: 0.001910950755700469\n",
      "Epoch 506, Loss: 0.0035857873735949397, Final Batch Loss: 0.002165322657674551\n",
      "Epoch 507, Loss: 0.0024035390233621, Final Batch Loss: 0.0004846784286201\n",
      "Epoch 508, Loss: 0.0030624883947893977, Final Batch Loss: 0.0011966570746153593\n",
      "Epoch 509, Loss: 0.0029147304594516754, Final Batch Loss: 0.001846961909905076\n",
      "Epoch 510, Loss: 0.014172365874401294, Final Batch Loss: 0.0001580584648763761\n",
      "Epoch 511, Loss: 0.0010903813818003982, Final Batch Loss: 0.0006825970485806465\n",
      "Epoch 512, Loss: 0.0006634799647144973, Final Batch Loss: 0.0005234642303548753\n",
      "Epoch 513, Loss: 0.003348352911416441, Final Batch Loss: 0.0026747507508844137\n",
      "Epoch 514, Loss: 0.0011266936489846557, Final Batch Loss: 0.0004215894441585988\n",
      "Epoch 515, Loss: 0.0007674966473132372, Final Batch Loss: 0.00023271358804777265\n",
      "Epoch 516, Loss: 0.0008689069654792547, Final Batch Loss: 0.0004854123981203884\n",
      "Epoch 517, Loss: 0.0023517595836892724, Final Batch Loss: 0.0012092457618564367\n",
      "Epoch 518, Loss: 0.001873617002274841, Final Batch Loss: 0.0006176594761200249\n",
      "Epoch 519, Loss: 0.0014631882077082992, Final Batch Loss: 0.0004944673273712397\n",
      "Epoch 520, Loss: 0.0006889197538839653, Final Batch Loss: 0.0005226351786404848\n",
      "Epoch 521, Loss: 0.001863736950326711, Final Batch Loss: 0.0011796121252700686\n",
      "Epoch 522, Loss: 0.009804042550968006, Final Batch Loss: 0.009349568746984005\n",
      "Epoch 523, Loss: 0.002284725138451904, Final Batch Loss: 0.00140490778721869\n",
      "Epoch 524, Loss: 0.0020621202420443296, Final Batch Loss: 0.0005836761556565762\n",
      "Epoch 525, Loss: 0.0010205883445451036, Final Batch Loss: 8.075185178313404e-05\n",
      "Epoch 526, Loss: 0.0010334389517083764, Final Batch Loss: 0.00013487058458849788\n",
      "Epoch 527, Loss: 0.0029764994396828115, Final Batch Loss: 0.002477779984474182\n",
      "Epoch 528, Loss: 0.003981524205300957, Final Batch Loss: 0.0005540946149267256\n",
      "Epoch 529, Loss: 0.002140130731277168, Final Batch Loss: 0.0017114105867221951\n",
      "Epoch 530, Loss: 0.001049469065037556, Final Batch Loss: 0.00014178153651300818\n",
      "Epoch 531, Loss: 0.0043561061611399055, Final Batch Loss: 0.0035648164339363575\n",
      "Epoch 532, Loss: 0.0005299286131048575, Final Batch Loss: 8.780056668911129e-05\n",
      "Epoch 533, Loss: 0.001889857288915664, Final Batch Loss: 0.0010778210125863552\n",
      "Epoch 534, Loss: 0.0012668522103922442, Final Batch Loss: 0.00021688344713766128\n",
      "Epoch 535, Loss: 0.0007388252852251753, Final Batch Loss: 0.0005590873770415783\n",
      "Epoch 536, Loss: 0.0005459588719531894, Final Batch Loss: 0.00029525626450777054\n",
      "Epoch 537, Loss: 0.001537279546028003, Final Batch Loss: 0.0013291777577251196\n",
      "Epoch 538, Loss: 0.0009237058984581381, Final Batch Loss: 0.00036590322270058095\n",
      "Epoch 539, Loss: 0.0007325190963456407, Final Batch Loss: 0.00017149596533272415\n",
      "Epoch 540, Loss: 0.001550794462673366, Final Batch Loss: 0.0001601563999429345\n",
      "Epoch 541, Loss: 0.0007701826543780044, Final Batch Loss: 0.00012885384785477072\n",
      "Epoch 542, Loss: 0.003550114284735173, Final Batch Loss: 0.00015633803559467196\n",
      "Epoch 543, Loss: 0.001620450901100412, Final Batch Loss: 0.0004143490514252335\n",
      "Epoch 544, Loss: 0.02374941024754662, Final Batch Loss: 0.023547101765871048\n",
      "Epoch 545, Loss: 0.00025614420155761763, Final Batch Loss: 8.93831966095604e-05\n",
      "Epoch 546, Loss: 0.0014684940106235445, Final Batch Loss: 0.0012321352260187268\n",
      "Epoch 547, Loss: 0.005471132579259574, Final Batch Loss: 0.0017693162662908435\n",
      "Epoch 548, Loss: 0.0002517946559237316, Final Batch Loss: 0.00016412721015512943\n",
      "Epoch 549, Loss: 0.0012296413478907198, Final Batch Loss: 0.00010040434426628053\n",
      "Epoch 550, Loss: 0.001317067799391225, Final Batch Loss: 0.0004810861137229949\n",
      "Epoch 551, Loss: 0.001981216249987483, Final Batch Loss: 0.0012979746097698808\n",
      "Epoch 552, Loss: 0.0016744645545259118, Final Batch Loss: 0.0002756178146228194\n",
      "Epoch 553, Loss: 0.0026919813826680183, Final Batch Loss: 0.0006013221573084593\n",
      "Epoch 554, Loss: 0.000687127438141033, Final Batch Loss: 0.0003335947694722563\n",
      "Epoch 555, Loss: 0.0032567225862294436, Final Batch Loss: 0.002954175230115652\n",
      "Epoch 556, Loss: 0.0007151150202844292, Final Batch Loss: 0.0003365330630913377\n",
      "Epoch 557, Loss: 0.002304969122633338, Final Batch Loss: 0.0015914548421278596\n",
      "Epoch 558, Loss: 0.005477735481690615, Final Batch Loss: 0.00018548796651884913\n",
      "Epoch 559, Loss: 0.001126764458604157, Final Batch Loss: 0.0005069540347903967\n",
      "Epoch 560, Loss: 0.002084390085656196, Final Batch Loss: 0.000498118984978646\n",
      "Epoch 561, Loss: 0.00028771910001523793, Final Batch Loss: 0.00011035785428248346\n",
      "Epoch 562, Loss: 0.001736837024509441, Final Batch Loss: 6.512743857456371e-05\n",
      "Epoch 563, Loss: 0.0011297609307803214, Final Batch Loss: 0.0005332311266101897\n",
      "Epoch 564, Loss: 0.0009104569908231497, Final Batch Loss: 0.0005899782991036773\n",
      "Epoch 565, Loss: 0.0010354573896620423, Final Batch Loss: 0.00019068640540353954\n",
      "Epoch 566, Loss: 0.0033725559333106503, Final Batch Loss: 0.00021085199841763824\n",
      "Epoch 567, Loss: 0.0005213376425672323, Final Batch Loss: 0.0001225524756591767\n",
      "Epoch 568, Loss: 0.002345892309676856, Final Batch Loss: 0.0016864021308720112\n",
      "Epoch 569, Loss: 0.013087925399304368, Final Batch Loss: 0.012880363501608372\n",
      "Epoch 570, Loss: 0.0017200151341967285, Final Batch Loss: 0.0003596500610001385\n",
      "Epoch 571, Loss: 0.0011753674480132759, Final Batch Loss: 7.585895946249366e-05\n",
      "Epoch 572, Loss: 0.0019673844799399376, Final Batch Loss: 0.001440559048205614\n",
      "Epoch 573, Loss: 0.0003729409072548151, Final Batch Loss: 8.066883310675621e-05\n",
      "Epoch 574, Loss: 0.0004548717988654971, Final Batch Loss: 0.00017636772827245295\n",
      "Epoch 575, Loss: 0.0028982045187149197, Final Batch Loss: 0.00017217491404153407\n",
      "Epoch 576, Loss: 0.0021657561301253736, Final Batch Loss: 7.930089486762881e-05\n",
      "Epoch 577, Loss: 0.0012711494055110961, Final Batch Loss: 0.00012875013635493815\n",
      "Epoch 578, Loss: 0.0013845527137164026, Final Batch Loss: 0.00044580872054211795\n",
      "Epoch 579, Loss: 0.001408849871950224, Final Batch Loss: 0.0012286149431020021\n",
      "Epoch 580, Loss: 0.00084003756637685, Final Batch Loss: 0.0003451697120908648\n",
      "Epoch 581, Loss: 0.006466776976594701, Final Batch Loss: 0.00018115565762855113\n",
      "Epoch 582, Loss: 0.014938136795535684, Final Batch Loss: 0.0005064320284873247\n",
      "Epoch 583, Loss: 0.0009069664592971094, Final Batch Loss: 3.610895510064438e-05\n",
      "Epoch 584, Loss: 0.0015184773365035653, Final Batch Loss: 0.0010706632165238261\n",
      "Epoch 585, Loss: 0.0013007063826080412, Final Batch Loss: 0.0003526527725625783\n",
      "Epoch 586, Loss: 0.0012270091683603823, Final Batch Loss: 0.00043743656715378165\n",
      "Epoch 587, Loss: 0.00039388852019328624, Final Batch Loss: 0.00013962951197754592\n",
      "Epoch 588, Loss: 0.0002550834688008763, Final Batch Loss: 0.00014138620463199914\n",
      "Epoch 589, Loss: 0.0012297866996959783, Final Batch Loss: 9.378340473631397e-05\n",
      "Epoch 590, Loss: 0.0007692964281886816, Final Batch Loss: 0.0003576723684091121\n",
      "Epoch 591, Loss: 0.0008124530722852796, Final Batch Loss: 0.0006099052843637764\n",
      "Epoch 592, Loss: 0.0013699115079361945, Final Batch Loss: 0.0010801396565511823\n",
      "Epoch 593, Loss: 0.0021031894721090794, Final Batch Loss: 0.0002503959694877267\n",
      "Epoch 594, Loss: 0.0008796686888672411, Final Batch Loss: 0.0006260450463742018\n",
      "Epoch 595, Loss: 0.030354736372828484, Final Batch Loss: 0.001519225537776947\n",
      "Epoch 596, Loss: 0.0006258883513510227, Final Batch Loss: 0.00048208600492216647\n",
      "Epoch 597, Loss: 0.002053199539659545, Final Batch Loss: 0.0016901693306863308\n",
      "Epoch 598, Loss: 0.0004953952302457765, Final Batch Loss: 0.0003461811866145581\n",
      "Epoch 599, Loss: 0.0009230556788679678, Final Batch Loss: 3.601388380047865e-05\n",
      "Epoch 600, Loss: 0.005667026794981211, Final Batch Loss: 0.005039156414568424\n",
      "Epoch 601, Loss: 0.0005414971674326807, Final Batch Loss: 0.000364702136721462\n",
      "Epoch 602, Loss: 0.0012659816347877495, Final Batch Loss: 3.072240360779688e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 603, Loss: 0.009688012127298862, Final Batch Loss: 0.0005319573101587594\n",
      "Epoch 604, Loss: 0.0012975349673070014, Final Batch Loss: 0.0005410127341747284\n",
      "Epoch 605, Loss: 0.003539890283718705, Final Batch Loss: 0.002242626389488578\n",
      "Epoch 606, Loss: 0.0011353307800163748, Final Batch Loss: 1.0914302038145252e-05\n",
      "Epoch 607, Loss: 0.0002677751108421944, Final Batch Loss: 9.714141924632713e-05\n",
      "Epoch 608, Loss: 0.0020646610646508634, Final Batch Loss: 0.0008075017831288278\n",
      "Epoch 609, Loss: 0.0017336457822239026, Final Batch Loss: 0.0015286592533811927\n",
      "Epoch 610, Loss: 0.0006135168805485591, Final Batch Loss: 0.0003800767008215189\n",
      "Epoch 611, Loss: 0.0026238224090775475, Final Batch Loss: 0.0002415302296867594\n",
      "Epoch 612, Loss: 0.015155022236285731, Final Batch Loss: 0.014808992855250835\n",
      "Epoch 613, Loss: 0.0020166451286058873, Final Batch Loss: 0.0004780949966516346\n",
      "Epoch 614, Loss: 0.0035735659766942263, Final Batch Loss: 0.002561967819929123\n",
      "Epoch 615, Loss: 0.00031174142350209877, Final Batch Loss: 8.650008385302499e-05\n",
      "Epoch 616, Loss: 0.0010132735187653452, Final Batch Loss: 0.0006579560576938093\n",
      "Epoch 617, Loss: 0.0016307553742080927, Final Batch Loss: 0.0011740061454474926\n",
      "Epoch 618, Loss: 0.010344538881327026, Final Batch Loss: 8.438252552878112e-05\n",
      "Epoch 619, Loss: 0.0008167491760104895, Final Batch Loss: 0.0005107029573991895\n",
      "Epoch 620, Loss: 0.0028965777019038796, Final Batch Loss: 0.0012910357909277081\n",
      "Epoch 621, Loss: 0.0017703142948448658, Final Batch Loss: 0.00027972180396318436\n",
      "Epoch 622, Loss: 0.0017996454334934242, Final Batch Loss: 0.00011292316048638895\n",
      "Epoch 623, Loss: 0.0010668967297533527, Final Batch Loss: 0.0002387962449574843\n",
      "Epoch 624, Loss: 0.0019385188352316618, Final Batch Loss: 0.0006177540635690093\n",
      "Epoch 625, Loss: 0.001910566701553762, Final Batch Loss: 0.0009318526135757565\n",
      "Epoch 626, Loss: 0.016168323170859367, Final Batch Loss: 0.015344790183007717\n",
      "Epoch 627, Loss: 0.0009651043219491839, Final Batch Loss: 0.00026109640020877123\n",
      "Epoch 628, Loss: 0.0012625313247554004, Final Batch Loss: 0.00011165864998474717\n",
      "Epoch 629, Loss: 0.0006489094812422991, Final Batch Loss: 0.0003201418148819357\n",
      "Epoch 630, Loss: 0.0019765737233683467, Final Batch Loss: 0.0015928379725664854\n",
      "Epoch 631, Loss: 0.03361784273874946, Final Batch Loss: 0.033153023570775986\n",
      "Epoch 632, Loss: 0.005435355240479112, Final Batch Loss: 0.003284050850197673\n",
      "Epoch 633, Loss: 0.002408295578788966, Final Batch Loss: 0.0005987100885249674\n",
      "Epoch 634, Loss: 0.011874715957674198, Final Batch Loss: 0.00021368094894569367\n",
      "Epoch 635, Loss: 0.0016005437355488539, Final Batch Loss: 0.00046590121928602457\n",
      "Epoch 636, Loss: 0.0026823485968634486, Final Batch Loss: 0.0007493979064747691\n",
      "Epoch 637, Loss: 0.0008104248117888346, Final Batch Loss: 0.0006492664106190205\n",
      "Epoch 638, Loss: 0.001990228600334376, Final Batch Loss: 0.0010179753880947828\n",
      "Epoch 639, Loss: 0.003363629730301909, Final Batch Loss: 9.875085379462689e-05\n",
      "Epoch 640, Loss: 0.001237485950696282, Final Batch Loss: 6.274732004385442e-05\n",
      "Epoch 641, Loss: 0.001368196273688227, Final Batch Loss: 0.0005625246558338404\n",
      "Epoch 642, Loss: 0.0006641010186285712, Final Batch Loss: 0.00011545557208592072\n",
      "Epoch 643, Loss: 0.004719565768027678, Final Batch Loss: 0.00463059451431036\n",
      "Epoch 644, Loss: 0.0011532101198099554, Final Batch Loss: 0.000822727452032268\n",
      "Epoch 645, Loss: 0.0014246887731133029, Final Batch Loss: 0.00010801867756526917\n",
      "Epoch 646, Loss: 0.0007573986804345623, Final Batch Loss: 0.00019332249939907342\n",
      "Epoch 647, Loss: 0.0005851604510098696, Final Batch Loss: 0.0001530108565930277\n",
      "Epoch 648, Loss: 0.002549504511989653, Final Batch Loss: 0.00040201458614319563\n",
      "Epoch 649, Loss: 0.003003677586093545, Final Batch Loss: 0.0009423166047781706\n",
      "Epoch 650, Loss: 0.0072642611630726606, Final Batch Loss: 0.00026068606530316174\n",
      "Epoch 651, Loss: 0.0006494518602266908, Final Batch Loss: 0.00021267679403536022\n",
      "Epoch 652, Loss: 0.0001952595448528882, Final Batch Loss: 0.00013735237007495016\n",
      "Epoch 653, Loss: 0.0004346637142589316, Final Batch Loss: 0.00022386616910807788\n",
      "Epoch 654, Loss: 0.0005794945464003831, Final Batch Loss: 0.0001904214732348919\n",
      "Epoch 655, Loss: 0.0008703429193701595, Final Batch Loss: 0.0005935232038609684\n",
      "Epoch 656, Loss: 0.00014161612853058614, Final Batch Loss: 4.995638664695434e-05\n",
      "Epoch 657, Loss: 0.0008779604104347527, Final Batch Loss: 0.00038974234485067427\n",
      "Epoch 658, Loss: 0.0009356278751511127, Final Batch Loss: 0.00022068919497542083\n",
      "Epoch 659, Loss: 0.0019454897847026587, Final Batch Loss: 0.0010391876567155123\n",
      "Epoch 660, Loss: 0.0005171676821191795, Final Batch Loss: 6.578767352038994e-05\n",
      "Epoch 661, Loss: 0.0008054440259002149, Final Batch Loss: 0.0003167680115438998\n",
      "Epoch 662, Loss: 0.0021764208686363418, Final Batch Loss: 3.4903281630249694e-05\n",
      "Epoch 663, Loss: 0.002914140815846622, Final Batch Loss: 0.0011819748906418681\n",
      "Epoch 664, Loss: 0.00207110884366557, Final Batch Loss: 0.0015063462778925896\n",
      "Epoch 665, Loss: 0.0019200468668714166, Final Batch Loss: 0.0005805967375636101\n",
      "Epoch 666, Loss: 0.00060853167087771, Final Batch Loss: 0.00028997549088671803\n",
      "Epoch 667, Loss: 0.023830765392631292, Final Batch Loss: 0.0023501417599618435\n",
      "Epoch 668, Loss: 0.0003240392070438247, Final Batch Loss: 3.590366031858139e-05\n",
      "Epoch 669, Loss: 0.0015330131573136896, Final Batch Loss: 0.001395589322783053\n",
      "Epoch 670, Loss: 0.0019046243687625974, Final Batch Loss: 0.00021545737399719656\n",
      "Epoch 671, Loss: 0.0004892477008979768, Final Batch Loss: 0.00027876521926373243\n",
      "Epoch 672, Loss: 0.0010990665177814662, Final Batch Loss: 0.00034489401150494814\n",
      "Epoch 673, Loss: 0.00133432904840447, Final Batch Loss: 0.0008731433772481978\n",
      "Epoch 674, Loss: 0.0217238963523414, Final Batch Loss: 0.021356360986828804\n",
      "Epoch 675, Loss: 0.0014768668916076422, Final Batch Loss: 0.0005903964629396796\n",
      "Epoch 676, Loss: 0.0016066005919128656, Final Batch Loss: 0.0006927975919097662\n",
      "Epoch 677, Loss: 0.004600986372679472, Final Batch Loss: 0.001336743589490652\n",
      "Epoch 678, Loss: 0.0011069774045608938, Final Batch Loss: 0.00037042569601908326\n",
      "Epoch 679, Loss: 0.0007467595278285444, Final Batch Loss: 0.0004964083200320601\n",
      "Epoch 680, Loss: 0.0011582013103179634, Final Batch Loss: 8.977396646514535e-05\n",
      "Epoch 681, Loss: 0.0010125946428161114, Final Batch Loss: 0.0003068392106797546\n",
      "Epoch 682, Loss: 0.0012913604150526226, Final Batch Loss: 0.000933711533434689\n",
      "Epoch 683, Loss: 0.00036930224450770766, Final Batch Loss: 0.0001957465137820691\n",
      "Epoch 684, Loss: 0.0012931622623000294, Final Batch Loss: 0.0009166136151179671\n",
      "Epoch 685, Loss: 0.0011986583122052252, Final Batch Loss: 0.0006548430537804961\n",
      "Epoch 686, Loss: 0.0039011096087051556, Final Batch Loss: 0.00015035252727102488\n",
      "Epoch 687, Loss: 0.0006440935248974711, Final Batch Loss: 0.0002475440560374409\n",
      "Epoch 688, Loss: 0.0007430016121361405, Final Batch Loss: 0.0005626236670650542\n",
      "Epoch 689, Loss: 0.0014674508711323142, Final Batch Loss: 0.00048691360279917717\n",
      "Epoch 690, Loss: 0.0005852420581504703, Final Batch Loss: 0.00048273149877786636\n",
      "Epoch 691, Loss: 0.0014689289382658899, Final Batch Loss: 0.0009520974126644433\n",
      "Epoch 692, Loss: 0.0006367143068928272, Final Batch Loss: 0.0001792222319636494\n",
      "Epoch 693, Loss: 0.0018994807032868266, Final Batch Loss: 0.000829398981295526\n",
      "Epoch 694, Loss: 0.001442922803107649, Final Batch Loss: 0.00019121315563097596\n",
      "Epoch 695, Loss: 0.0017661731108091772, Final Batch Loss: 0.001057309447787702\n",
      "Epoch 696, Loss: 0.0006779189425287768, Final Batch Loss: 0.00019630858150776476\n",
      "Epoch 697, Loss: 0.0008697003067936748, Final Batch Loss: 0.0003188930277246982\n",
      "Epoch 698, Loss: 0.002446446131216362, Final Batch Loss: 8.430986781604588e-05\n",
      "Epoch 699, Loss: 0.0007214557681436418, Final Batch Loss: 1.761338899086695e-05\n",
      "Epoch 700, Loss: 0.00170366998645477, Final Batch Loss: 0.00140656519215554\n",
      "Epoch 701, Loss: 0.0010468721011420712, Final Batch Loss: 0.00019949684792663902\n",
      "Epoch 702, Loss: 0.00034765328018693253, Final Batch Loss: 0.00023075350327417254\n",
      "Epoch 703, Loss: 0.00032298785663442686, Final Batch Loss: 8.291980338981375e-05\n",
      "Epoch 704, Loss: 0.00033476958924438804, Final Batch Loss: 0.00022369054204318672\n",
      "Epoch 705, Loss: 0.0005811832379549742, Final Batch Loss: 0.0003194238233845681\n",
      "Epoch 706, Loss: 0.0009474778635194525, Final Batch Loss: 0.0002158654242521152\n",
      "Epoch 707, Loss: 0.0006962464976822957, Final Batch Loss: 0.00020219919679220766\n",
      "Epoch 708, Loss: 0.04385359713342041, Final Batch Loss: 0.04245230555534363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709, Loss: 0.0006441031728172675, Final Batch Loss: 0.00045753776794299483\n",
      "Epoch 710, Loss: 0.0028487274976214394, Final Batch Loss: 0.00010614037455525249\n",
      "Epoch 711, Loss: 0.00029715278651565313, Final Batch Loss: 0.0001377266744384542\n",
      "Epoch 712, Loss: 0.0036149112274870276, Final Batch Loss: 0.0013049411354586482\n",
      "Epoch 713, Loss: 0.0005660975730279461, Final Batch Loss: 0.00038203527219593525\n",
      "Epoch 714, Loss: 0.003893904678989202, Final Batch Loss: 0.0034090522676706314\n",
      "Epoch 715, Loss: 0.0014880783419357613, Final Batch Loss: 0.0013521803775802255\n",
      "Epoch 716, Loss: 0.0005552511429414153, Final Batch Loss: 0.00019839522428810596\n",
      "Epoch 717, Loss: 0.0013946735416539013, Final Batch Loss: 0.0005974261439405382\n",
      "Epoch 718, Loss: 0.0009300134261138737, Final Batch Loss: 0.0006130184629000723\n",
      "Epoch 719, Loss: 0.001496263976150658, Final Batch Loss: 9.855973621597514e-05\n",
      "Epoch 720, Loss: 0.0025931656709872186, Final Batch Loss: 0.00020988861797377467\n",
      "Epoch 721, Loss: 0.001694593287538737, Final Batch Loss: 0.0005213495460338891\n",
      "Epoch 722, Loss: 0.0029724164051003754, Final Batch Loss: 0.0009014967945404351\n",
      "Epoch 723, Loss: 0.00013441633200272918, Final Batch Loss: 6.53369861538522e-05\n",
      "Epoch 724, Loss: 0.0020516770891845226, Final Batch Loss: 0.0008803544333204627\n",
      "Epoch 725, Loss: 0.0015982984914444387, Final Batch Loss: 0.0005999175482429564\n",
      "Epoch 726, Loss: 0.0019015913276234642, Final Batch Loss: 0.0017737532034516335\n",
      "Epoch 727, Loss: 0.0015690569998696446, Final Batch Loss: 0.0010602036491036415\n",
      "Epoch 728, Loss: 0.003525238891597837, Final Batch Loss: 0.0029839687049388885\n",
      "Epoch 729, Loss: 0.0011525032459758222, Final Batch Loss: 0.0007909352425485849\n",
      "Epoch 730, Loss: 0.0005765960377175361, Final Batch Loss: 0.00016146429697982967\n",
      "Epoch 731, Loss: 0.0013631318288389593, Final Batch Loss: 0.00011709894170053303\n",
      "Epoch 732, Loss: 0.0020095230429433286, Final Batch Loss: 0.001327048521488905\n",
      "Epoch 733, Loss: 0.0008276776061393321, Final Batch Loss: 0.0007106273551471531\n",
      "Epoch 734, Loss: 0.0005095366504974663, Final Batch Loss: 7.433994323946536e-05\n",
      "Epoch 735, Loss: 0.000637076998827979, Final Batch Loss: 5.2897637942805886e-05\n",
      "Epoch 736, Loss: 0.009261502447770908, Final Batch Loss: 0.008837336674332619\n",
      "Epoch 737, Loss: 0.0007762673121760599, Final Batch Loss: 9.863508603302762e-05\n",
      "Epoch 738, Loss: 0.0018670862482395023, Final Batch Loss: 0.0014123794389888644\n",
      "Epoch 739, Loss: 0.001922099501825869, Final Batch Loss: 0.001371664577163756\n",
      "Epoch 740, Loss: 0.004059398721437901, Final Batch Loss: 0.0003239497891627252\n",
      "Epoch 741, Loss: 0.0011180853616679087, Final Batch Loss: 0.0009250841103494167\n",
      "Epoch 742, Loss: 0.0016157181380549446, Final Batch Loss: 5.7737939641810954e-05\n",
      "Epoch 743, Loss: 0.0006241492810659111, Final Batch Loss: 6.752903573215008e-05\n",
      "Epoch 744, Loss: 0.0013554730685427785, Final Batch Loss: 0.0006058225408196449\n",
      "Epoch 745, Loss: 0.0008974828233476728, Final Batch Loss: 0.0004598564701154828\n",
      "Epoch 746, Loss: 0.00020990406119381078, Final Batch Loss: 3.3878492104122415e-05\n",
      "Epoch 747, Loss: 0.007029689193586819, Final Batch Loss: 0.00023041693202685565\n",
      "Epoch 748, Loss: 0.005336618458386511, Final Batch Loss: 0.004372183699160814\n",
      "Epoch 749, Loss: 0.00238921822165139, Final Batch Loss: 0.00020382183720357716\n",
      "Epoch 750, Loss: 0.0031611036392860115, Final Batch Loss: 0.0028900173492729664\n",
      "Epoch 751, Loss: 0.0008945495937950909, Final Batch Loss: 0.00039782444946467876\n",
      "Epoch 752, Loss: 0.0016466355882585049, Final Batch Loss: 0.0006625410169363022\n",
      "Epoch 753, Loss: 0.019617312907939777, Final Batch Loss: 0.019210148602724075\n",
      "Epoch 754, Loss: 0.013062628917396069, Final Batch Loss: 0.0008574090898036957\n",
      "Epoch 755, Loss: 0.0009294989285990596, Final Batch Loss: 0.0005273421411402524\n",
      "Epoch 756, Loss: 0.0010852378836716525, Final Batch Loss: 0.0009933271212503314\n",
      "Epoch 757, Loss: 0.0011236856225878, Final Batch Loss: 0.0006045821355655789\n",
      "Epoch 758, Loss: 0.0011476116487756371, Final Batch Loss: 0.00021857459796592593\n",
      "Epoch 759, Loss: 0.00016804698316263966, Final Batch Loss: 0.00012049787619616836\n",
      "Epoch 760, Loss: 0.000940532612730749, Final Batch Loss: 0.0007502487278543413\n",
      "Epoch 761, Loss: 0.001155305391876027, Final Batch Loss: 0.00022672218619845808\n",
      "Epoch 762, Loss: 0.0005506382731255144, Final Batch Loss: 0.00021769327577203512\n",
      "Epoch 763, Loss: 0.003940500726457685, Final Batch Loss: 0.003486275440081954\n",
      "Epoch 764, Loss: 0.00025038701642188244, Final Batch Loss: 5.059253817307763e-05\n",
      "Epoch 765, Loss: 0.00016587465506745502, Final Batch Loss: 5.622340540867299e-05\n",
      "Epoch 766, Loss: 0.0018070719088427722, Final Batch Loss: 0.001526189618743956\n",
      "Epoch 767, Loss: 0.00031970205600373447, Final Batch Loss: 0.00010152434697374701\n",
      "Epoch 768, Loss: 0.002187976206187159, Final Batch Loss: 0.00041145627619698644\n",
      "Epoch 769, Loss: 0.0019309654016979039, Final Batch Loss: 0.0007974457112140954\n",
      "Epoch 770, Loss: 0.0012292982428334653, Final Batch Loss: 0.0006165556842461228\n",
      "Epoch 771, Loss: 0.00021465724421432242, Final Batch Loss: 0.00012562770280055702\n",
      "Epoch 772, Loss: 0.0018417714745737612, Final Batch Loss: 0.0011427962454035878\n",
      "Epoch 773, Loss: 0.015202838403638452, Final Batch Loss: 0.014618931338191032\n",
      "Epoch 774, Loss: 0.000605222365265945, Final Batch Loss: 4.820304820896126e-05\n",
      "Epoch 775, Loss: 0.00016194517775147688, Final Batch Loss: 1.759300175763201e-05\n",
      "Epoch 776, Loss: 0.0007950063154567033, Final Batch Loss: 0.00046741674304939806\n",
      "Epoch 777, Loss: 0.002414067042991519, Final Batch Loss: 0.00028258049860596657\n",
      "Epoch 778, Loss: 0.0007281023281393573, Final Batch Loss: 4.030116542708129e-05\n",
      "Epoch 779, Loss: 0.0003902048265445046, Final Batch Loss: 0.00033699977211654186\n",
      "Epoch 780, Loss: 0.0005870585446245968, Final Batch Loss: 0.00034411464002914727\n",
      "Epoch 781, Loss: 0.002027495647780597, Final Batch Loss: 0.001780606689862907\n",
      "Epoch 782, Loss: 0.0014577734982594848, Final Batch Loss: 0.0012926611816510558\n",
      "Epoch 783, Loss: 0.0015668108535464853, Final Batch Loss: 0.0003308548766653985\n",
      "Epoch 784, Loss: 0.0008924448484322056, Final Batch Loss: 0.00023584840528201312\n",
      "Epoch 785, Loss: 0.001140086769737536, Final Batch Loss: 2.1817253582412377e-05\n",
      "Epoch 786, Loss: 0.0009767248411662877, Final Batch Loss: 0.0001782737672328949\n",
      "Epoch 787, Loss: 0.0014013004547450691, Final Batch Loss: 0.00040927217924036086\n",
      "Epoch 788, Loss: 0.0007180086249718443, Final Batch Loss: 0.0004964534309692681\n",
      "Epoch 789, Loss: 0.0007719638815615326, Final Batch Loss: 0.0006413289811462164\n",
      "Epoch 790, Loss: 0.0009539239399600774, Final Batch Loss: 0.000292675249511376\n",
      "Epoch 791, Loss: 0.00033722537773428485, Final Batch Loss: 0.00026277100550942123\n",
      "Epoch 792, Loss: 0.00030346606217790395, Final Batch Loss: 0.00016190014139283448\n",
      "Epoch 793, Loss: 0.0005110185156809166, Final Batch Loss: 0.00027362167020328343\n",
      "Epoch 794, Loss: 0.008788000282947905, Final Batch Loss: 0.00011479710519779474\n",
      "Epoch 795, Loss: 0.0006652222946286201, Final Batch Loss: 0.00016744009917601943\n",
      "Epoch 796, Loss: 0.0018577382143121213, Final Batch Loss: 0.0002540052810218185\n",
      "Epoch 797, Loss: 0.0017555488739162683, Final Batch Loss: 0.0013889048714190722\n",
      "Epoch 798, Loss: 0.0014197310083545744, Final Batch Loss: 0.0008603138267062604\n",
      "Epoch 799, Loss: 0.0008083055436145514, Final Batch Loss: 0.00018670366262085736\n",
      "Epoch 800, Loss: 0.0013018327299505472, Final Batch Loss: 0.000570904347114265\n",
      "Epoch 801, Loss: 0.00026740053726825863, Final Batch Loss: 0.00010678332182578743\n",
      "Epoch 802, Loss: 0.001513841598352883, Final Batch Loss: 6.983968341955915e-05\n",
      "Epoch 803, Loss: 0.00023269539087777957, Final Batch Loss: 0.000142433971632272\n",
      "Epoch 804, Loss: 0.0003350904444232583, Final Batch Loss: 0.00012858911941293627\n",
      "Epoch 805, Loss: 0.007636533737240825, Final Batch Loss: 8.117329707602039e-05\n",
      "Epoch 806, Loss: 0.0005972704093437642, Final Batch Loss: 0.00012572764535434544\n",
      "Epoch 807, Loss: 0.0018070080550387502, Final Batch Loss: 0.0008197580464184284\n",
      "Epoch 808, Loss: 0.0024128439254127443, Final Batch Loss: 0.0005612640525214374\n",
      "Epoch 809, Loss: 0.0013816550344927236, Final Batch Loss: 0.0011423215037211776\n",
      "Epoch 810, Loss: 0.0010216913142357953, Final Batch Loss: 0.00010583393304841593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811, Loss: 0.0016509148990735412, Final Batch Loss: 0.0009144782670773566\n",
      "Epoch 812, Loss: 0.0035089130396954715, Final Batch Loss: 0.003067297162488103\n",
      "Epoch 813, Loss: 0.0010354034893680364, Final Batch Loss: 0.00045106836478225887\n",
      "Epoch 814, Loss: 0.0029705858323723078, Final Batch Loss: 0.000964080449193716\n",
      "Epoch 815, Loss: 0.0005006826759199612, Final Batch Loss: 3.665714029921219e-05\n",
      "Epoch 816, Loss: 0.0007861450576456264, Final Batch Loss: 0.0005938929971307516\n",
      "Epoch 817, Loss: 0.0027797400107374415, Final Batch Loss: 0.00013472545833792537\n",
      "Epoch 818, Loss: 0.001239905206602998, Final Batch Loss: 0.0010872475104406476\n",
      "Epoch 819, Loss: 0.0008631782839074731, Final Batch Loss: 0.00020069640595465899\n",
      "Epoch 820, Loss: 0.0028989827260375023, Final Batch Loss: 0.0021960486192256212\n",
      "Epoch 821, Loss: 0.000474397063953802, Final Batch Loss: 0.0002357532357564196\n",
      "Epoch 822, Loss: 0.0003717848885571584, Final Batch Loss: 0.0002896802907343954\n",
      "Epoch 823, Loss: 0.0007042442884994671, Final Batch Loss: 0.0005443855188786983\n",
      "Epoch 824, Loss: 0.00022490450646728277, Final Batch Loss: 0.00014189023931976408\n",
      "Epoch 825, Loss: 0.0006563587448908947, Final Batch Loss: 0.0005365899996832013\n",
      "Epoch 826, Loss: 0.000319892234983854, Final Batch Loss: 0.00022477135644294322\n",
      "Epoch 827, Loss: 0.0004051132491440512, Final Batch Loss: 0.00035813357681035995\n",
      "Epoch 828, Loss: 0.000749164042645134, Final Batch Loss: 0.0005537958350032568\n",
      "Epoch 829, Loss: 0.005394210500526242, Final Batch Loss: 0.00012255033652763814\n",
      "Epoch 830, Loss: 0.0025704067084006965, Final Batch Loss: 0.0018746898276731372\n",
      "Epoch 831, Loss: 0.0004129721983190393, Final Batch Loss: 1.7612435840419494e-05\n",
      "Epoch 832, Loss: 0.00028417232533684, Final Batch Loss: 0.00010576794011285529\n",
      "Epoch 833, Loss: 0.001226746680913493, Final Batch Loss: 0.00035160905099473894\n",
      "Epoch 834, Loss: 0.0002740289783105254, Final Batch Loss: 0.00015766610158607364\n",
      "Epoch 835, Loss: 0.00032870732684386894, Final Batch Loss: 6.474664405686781e-05\n",
      "Epoch 836, Loss: 0.0007689744452363811, Final Batch Loss: 5.089988553663716e-05\n",
      "Epoch 837, Loss: 0.0002902402338804677, Final Batch Loss: 0.00013267295435070992\n",
      "Epoch 838, Loss: 0.0007698597910348326, Final Batch Loss: 0.00013373602996580303\n",
      "Epoch 839, Loss: 0.0005595387192443013, Final Batch Loss: 0.0002761234645731747\n",
      "Epoch 840, Loss: 0.0017518953391117975, Final Batch Loss: 0.0015497107524424791\n",
      "Epoch 841, Loss: 0.0005049979081377387, Final Batch Loss: 0.0003156040620524436\n",
      "Epoch 842, Loss: 0.0004567939031403512, Final Batch Loss: 0.00030791445169597864\n",
      "Epoch 843, Loss: 0.0005107308334117988, Final Batch Loss: 1.3996550478623249e-05\n",
      "Epoch 844, Loss: 0.00048732291543274187, Final Batch Loss: 5.399342262535356e-05\n",
      "Epoch 845, Loss: 0.0001899007957035792, Final Batch Loss: 1.427757251803996e-05\n",
      "Epoch 846, Loss: 0.006830514081229921, Final Batch Loss: 0.006773015018552542\n",
      "Epoch 847, Loss: 0.0005274516370263882, Final Batch Loss: 0.00042782636592164636\n",
      "Epoch 848, Loss: 0.0003099791065324098, Final Batch Loss: 8.414301555603743e-05\n",
      "Epoch 849, Loss: 0.0017860554507933557, Final Batch Loss: 0.0005141496076248586\n",
      "Epoch 850, Loss: 0.00038738088915124536, Final Batch Loss: 0.00016958721971604973\n",
      "Epoch 851, Loss: 0.0011847805726574734, Final Batch Loss: 0.001135857542976737\n",
      "Epoch 852, Loss: 0.00035941194801125675, Final Batch Loss: 0.00019083173538092524\n",
      "Epoch 853, Loss: 0.0004789658996742219, Final Batch Loss: 0.00043606400140561163\n",
      "Epoch 854, Loss: 0.01840482378611341, Final Batch Loss: 0.01817484013736248\n",
      "Epoch 855, Loss: 0.00045362293894868344, Final Batch Loss: 0.00017842075612861663\n",
      "Epoch 856, Loss: 0.00025519226437609177, Final Batch Loss: 0.00024391498300246894\n",
      "Epoch 857, Loss: 0.0009629172418499365, Final Batch Loss: 0.0007611937471665442\n",
      "Epoch 858, Loss: 7.04736121406313e-05, Final Batch Loss: 5.685194264515303e-05\n",
      "Epoch 859, Loss: 0.0005668691519531421, Final Batch Loss: 0.00047820713371038437\n",
      "Epoch 860, Loss: 0.017795822932384908, Final Batch Loss: 0.0010244579752907157\n",
      "Epoch 861, Loss: 0.0008059234824031591, Final Batch Loss: 0.00043309430475346744\n",
      "Epoch 862, Loss: 0.0006368144095176831, Final Batch Loss: 8.499501564074308e-05\n",
      "Epoch 863, Loss: 0.0002928493486251682, Final Batch Loss: 9.90410044323653e-05\n",
      "Epoch 864, Loss: 0.0011721093760570511, Final Batch Loss: 9.440035501029342e-05\n",
      "Epoch 865, Loss: 0.002184066874178825, Final Batch Loss: 0.0021248513367027044\n",
      "Epoch 866, Loss: 0.010633923087880248, Final Batch Loss: 3.759932951652445e-05\n",
      "Epoch 867, Loss: 0.0011057203519158065, Final Batch Loss: 0.000980900484137237\n",
      "Epoch 868, Loss: 0.00025547552650095895, Final Batch Loss: 6.785838195355609e-05\n",
      "Epoch 869, Loss: 0.0019287506584078074, Final Batch Loss: 0.001487245550379157\n",
      "Epoch 870, Loss: 0.004937065110425465, Final Batch Loss: 0.00012908251665066928\n",
      "Epoch 871, Loss: 0.0010087932751048356, Final Batch Loss: 0.0005815264885313809\n",
      "Epoch 872, Loss: 0.0008300566551042721, Final Batch Loss: 0.0006897065904922783\n",
      "Epoch 873, Loss: 0.0006476330454461277, Final Batch Loss: 0.0003559921169653535\n",
      "Epoch 874, Loss: 0.0020732437260448933, Final Batch Loss: 0.0018446173053234816\n",
      "Epoch 875, Loss: 0.0008523414144292474, Final Batch Loss: 0.00039262292557395995\n",
      "Epoch 876, Loss: 0.008423206625593593, Final Batch Loss: 0.008376367390155792\n",
      "Epoch 877, Loss: 0.01293265690037515, Final Batch Loss: 7.27443111827597e-05\n",
      "Epoch 878, Loss: 0.0003415718583710259, Final Batch Loss: 2.654748641361948e-05\n",
      "Epoch 879, Loss: 0.00016329857317032292, Final Batch Loss: 8.923921268433332e-05\n",
      "Epoch 880, Loss: 0.0005650078383041546, Final Batch Loss: 0.00012316358333919197\n",
      "Epoch 881, Loss: 0.0002676865187822841, Final Batch Loss: 0.0001461062056478113\n",
      "Epoch 882, Loss: 0.0005439124361146241, Final Batch Loss: 0.00014948562602512538\n",
      "Epoch 883, Loss: 0.0004256503816577606, Final Batch Loss: 0.00011525709851412103\n",
      "Epoch 884, Loss: 0.00026053463807329535, Final Batch Loss: 0.00015076053387019783\n",
      "Epoch 885, Loss: 0.00014972220378695056, Final Batch Loss: 9.241575025953352e-05\n",
      "Epoch 886, Loss: 0.0007047221006359905, Final Batch Loss: 0.0004016705206595361\n",
      "Epoch 887, Loss: 0.00018068867939291522, Final Batch Loss: 0.00014320618356578052\n",
      "Epoch 888, Loss: 0.0010454875882714987, Final Batch Loss: 0.0007677261019125581\n",
      "Epoch 889, Loss: 0.004073482006788254, Final Batch Loss: 0.0007137227803468704\n",
      "Epoch 890, Loss: 0.002496234024874866, Final Batch Loss: 0.0010453022550791502\n",
      "Epoch 891, Loss: 0.0006783496937714517, Final Batch Loss: 0.00026873944443650544\n",
      "Epoch 892, Loss: 0.00011793967860285193, Final Batch Loss: 1.1125630408059806e-05\n",
      "Epoch 893, Loss: 0.0016047521494328976, Final Batch Loss: 0.0013473068829625845\n",
      "Epoch 894, Loss: 0.0009399051195941865, Final Batch Loss: 0.00028279307298362255\n",
      "Epoch 895, Loss: 0.0011329501867294312, Final Batch Loss: 0.0002031734911724925\n",
      "Epoch 896, Loss: 0.0008849048463162035, Final Batch Loss: 8.224204066209495e-05\n",
      "Epoch 897, Loss: 6.795919580326881e-05, Final Batch Loss: 2.2120480934972875e-05\n",
      "Epoch 898, Loss: 0.00029505851125577465, Final Batch Loss: 0.0001850665721576661\n",
      "Epoch 899, Loss: 0.0009190975833917037, Final Batch Loss: 0.00011342049401719123\n",
      "Epoch 900, Loss: 0.00022769650968257338, Final Batch Loss: 0.00017840250802692026\n",
      "Epoch 901, Loss: 0.0007692069630138576, Final Batch Loss: 0.0005004170234315097\n",
      "Epoch 902, Loss: 0.00024088477221084759, Final Batch Loss: 8.04886149126105e-05\n",
      "Epoch 903, Loss: 0.00047945528058335185, Final Batch Loss: 0.00035354579449631274\n",
      "Epoch 904, Loss: 0.0003019593204953708, Final Batch Loss: 0.00010939676576526836\n",
      "Epoch 905, Loss: 0.0002569582466094289, Final Batch Loss: 4.821084803552367e-05\n",
      "Epoch 906, Loss: 0.0004465553065529093, Final Batch Loss: 4.754906694870442e-05\n",
      "Epoch 907, Loss: 0.0002115452371072024, Final Batch Loss: 0.00012519322626758367\n",
      "Epoch 908, Loss: 0.0004978873912477866, Final Batch Loss: 0.00031889887759462\n",
      "Epoch 909, Loss: 0.00030568669899366796, Final Batch Loss: 0.00013024396321270615\n",
      "Epoch 910, Loss: 0.0005502249405253679, Final Batch Loss: 0.0002464348799549043\n",
      "Epoch 911, Loss: 0.0002103611441270914, Final Batch Loss: 2.4192642740672454e-05\n",
      "Epoch 912, Loss: 0.00028516831662273034, Final Batch Loss: 9.622777724871412e-05\n",
      "Epoch 913, Loss: 0.0005601861339528114, Final Batch Loss: 0.00031399301951751113\n",
      "Epoch 914, Loss: 0.000564961665077135, Final Batch Loss: 0.0004096241027582437\n",
      "Epoch 915, Loss: 0.00019078185869148, Final Batch Loss: 0.0001233867515111342\n",
      "Epoch 916, Loss: 0.0002376548363827169, Final Batch Loss: 0.00016528755077160895\n",
      "Epoch 917, Loss: 0.006066696543712169, Final Batch Loss: 0.00015090202214196324\n",
      "Epoch 918, Loss: 0.0012774600181728601, Final Batch Loss: 0.0008553122752346098\n",
      "Epoch 919, Loss: 0.0004571230383589864, Final Batch Loss: 0.00034399013384245336\n",
      "Epoch 920, Loss: 0.004343285079812631, Final Batch Loss: 0.00030916588730178773\n",
      "Epoch 921, Loss: 0.00017878376456792466, Final Batch Loss: 0.00012922228779643774\n",
      "Epoch 922, Loss: 0.00039526847831439227, Final Batch Loss: 0.0002962445141747594\n",
      "Epoch 923, Loss: 0.00011716945664375089, Final Batch Loss: 4.217668538331054e-05\n",
      "Epoch 924, Loss: 0.00027422624407336116, Final Batch Loss: 0.0001431285054422915\n",
      "Epoch 925, Loss: 0.004252623388310894, Final Batch Loss: 0.00013584745465777814\n",
      "Epoch 926, Loss: 0.0005838700162712485, Final Batch Loss: 0.0005010933382436633\n",
      "Epoch 927, Loss: 0.0002073865689453669, Final Batch Loss: 0.00016342216986231506\n",
      "Epoch 928, Loss: 0.0005127321564941667, Final Batch Loss: 0.00011192668898729607\n",
      "Epoch 929, Loss: 7.121702037693467e-05, Final Batch Loss: 2.0618173948605545e-05\n",
      "Epoch 930, Loss: 0.00023503733973484486, Final Batch Loss: 0.000186738048796542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 931, Loss: 0.0005484666035044938, Final Batch Loss: 8.532684296369553e-05\n",
      "Epoch 932, Loss: 0.0003500424500089139, Final Batch Loss: 0.0002334246237296611\n",
      "Epoch 933, Loss: 0.000249425764195621, Final Batch Loss: 5.732923455070704e-05\n",
      "Epoch 934, Loss: 0.0006333134224405512, Final Batch Loss: 5.56788727408275e-05\n",
      "Epoch 935, Loss: 0.0002672040936886333, Final Batch Loss: 0.00022433830599766225\n",
      "Epoch 936, Loss: 0.0007260773272719234, Final Batch Loss: 0.0004716759722214192\n",
      "Epoch 937, Loss: 0.0006141606863820925, Final Batch Loss: 4.0319704567082226e-05\n",
      "Epoch 938, Loss: 0.0010396486104582436, Final Batch Loss: 0.0009605977102182806\n",
      "Epoch 939, Loss: 0.003423077694606036, Final Batch Loss: 0.0006772013730369508\n",
      "Epoch 940, Loss: 0.0021711961744586006, Final Batch Loss: 0.00015465322940144688\n",
      "Epoch 941, Loss: 0.001475786863011308, Final Batch Loss: 5.428861186373979e-05\n",
      "Epoch 942, Loss: 0.001282658278796589, Final Batch Loss: 4.460950367501937e-05\n",
      "Epoch 943, Loss: 0.0011428622819948941, Final Batch Loss: 0.0007871210109442472\n",
      "Epoch 944, Loss: 0.00038347806548699737, Final Batch Loss: 0.00026575400261208415\n",
      "Epoch 945, Loss: 0.000192824169062078, Final Batch Loss: 0.00011067401646869257\n",
      "Epoch 946, Loss: 0.000561718741664663, Final Batch Loss: 0.00015616737073287368\n",
      "Epoch 947, Loss: 0.0006996648662607186, Final Batch Loss: 0.00010406510409666225\n",
      "Epoch 948, Loss: 0.00012773675916832872, Final Batch Loss: 3.784357613767497e-05\n",
      "Epoch 949, Loss: 0.0009729746670927852, Final Batch Loss: 0.0003773120988626033\n",
      "Epoch 950, Loss: 0.0005937837850069627, Final Batch Loss: 0.00043424381874501705\n",
      "Epoch 951, Loss: 0.0005589831198449247, Final Batch Loss: 0.00043794032535515726\n",
      "Epoch 952, Loss: 0.00028687684243777767, Final Batch Loss: 1.642358984099701e-05\n",
      "Epoch 953, Loss: 0.0002526183116060565, Final Batch Loss: 1.1198341780982446e-05\n",
      "Epoch 954, Loss: 0.0041976821958087385, Final Batch Loss: 0.0009243031381629407\n",
      "Epoch 955, Loss: 0.0005125056650285842, Final Batch Loss: 1.4646577255916782e-05\n",
      "Epoch 956, Loss: 0.00010539308277657256, Final Batch Loss: 5.580258584814146e-05\n",
      "Epoch 957, Loss: 0.0020282426266930997, Final Batch Loss: 0.0016175252385437489\n",
      "Epoch 958, Loss: 0.0005440309369078022, Final Batch Loss: 1.4102105524216313e-05\n",
      "Epoch 959, Loss: 7.090065446391236e-05, Final Batch Loss: 2.861319990188349e-05\n",
      "Epoch 960, Loss: 0.00026625749160302803, Final Batch Loss: 0.00019801750022452325\n",
      "Epoch 961, Loss: 0.00031607340497430414, Final Batch Loss: 0.00023761250486131757\n",
      "Epoch 962, Loss: 0.0002067380073640379, Final Batch Loss: 1.0939208550553303e-05\n",
      "Epoch 963, Loss: 0.0008254104031948373, Final Batch Loss: 0.0006137335440143943\n",
      "Epoch 964, Loss: 0.0001905969747895142, Final Batch Loss: 5.891159162274562e-06\n",
      "Epoch 965, Loss: 0.0005855148046975955, Final Batch Loss: 0.00039855000795796514\n",
      "Epoch 966, Loss: 0.00016897599925869144, Final Batch Loss: 0.00011235619604121894\n",
      "Epoch 967, Loss: 0.000743983153370209, Final Batch Loss: 0.00014715212455485016\n",
      "Epoch 968, Loss: 0.0005896578004467301, Final Batch Loss: 4.102969978703186e-05\n",
      "Epoch 969, Loss: 0.00031225958082359284, Final Batch Loss: 0.00020995934028178453\n",
      "Epoch 970, Loss: 0.00047121767420321703, Final Batch Loss: 0.0003383168950676918\n",
      "Epoch 971, Loss: 0.00019490120212140027, Final Batch Loss: 0.00017299999308306724\n",
      "Epoch 972, Loss: 0.00035997654777020216, Final Batch Loss: 0.000275701517239213\n",
      "Epoch 973, Loss: 0.0008308563192258589, Final Batch Loss: 0.0007583105470985174\n",
      "Epoch 974, Loss: 4.9277958169113845e-05, Final Batch Loss: 1.9649023670353927e-05\n",
      "Epoch 975, Loss: 0.00044342080582282506, Final Batch Loss: 8.974540833150968e-06\n",
      "Epoch 976, Loss: 0.0008045403519645333, Final Batch Loss: 0.0006043800967745483\n",
      "Epoch 977, Loss: 0.0002636993940541288, Final Batch Loss: 0.0002374997129663825\n",
      "Epoch 978, Loss: 0.0006626296817557886, Final Batch Loss: 0.0005211418610997498\n",
      "Epoch 979, Loss: 0.00013805214621243067, Final Batch Loss: 8.181590965250507e-05\n",
      "Epoch 980, Loss: 0.007575669358629966, Final Batch Loss: 0.007533671334385872\n",
      "Epoch 981, Loss: 0.001041202514898032, Final Batch Loss: 0.00013660878175869584\n",
      "Epoch 982, Loss: 0.0017830271390266716, Final Batch Loss: 0.0003723081317730248\n",
      "Epoch 983, Loss: 0.0011537274695001543, Final Batch Loss: 0.0006212496082298458\n",
      "Epoch 984, Loss: 0.00038202178257051855, Final Batch Loss: 0.0003067067882511765\n",
      "Epoch 985, Loss: 8.560305468563456e-05, Final Batch Loss: 4.416689989739098e-06\n",
      "Epoch 986, Loss: 0.0005902467528358102, Final Batch Loss: 4.316441481932998e-05\n",
      "Epoch 987, Loss: 0.00010968557762680575, Final Batch Loss: 6.290456803981215e-05\n",
      "Epoch 988, Loss: 6.251267586776521e-05, Final Batch Loss: 3.4182725357823074e-05\n",
      "Epoch 989, Loss: 0.00038992577174212784, Final Batch Loss: 0.00023280372261069715\n",
      "Epoch 990, Loss: 0.0006316547660389915, Final Batch Loss: 0.00012404467270243913\n",
      "Epoch 991, Loss: 0.0003697518623084761, Final Batch Loss: 0.00010813505650730804\n",
      "Epoch 992, Loss: 0.0036039327897015028, Final Batch Loss: 0.003565466031432152\n",
      "Epoch 993, Loss: 8.659469312988222e-05, Final Batch Loss: 6.982828199397773e-05\n",
      "Epoch 994, Loss: 0.00021016873688495252, Final Batch Loss: 0.0001824128848966211\n",
      "Epoch 995, Loss: 0.00014254122470447328, Final Batch Loss: 2.0631579900509678e-05\n",
      "Epoch 996, Loss: 0.002174746652599424, Final Batch Loss: 0.0020386262331157923\n",
      "Epoch 997, Loss: 0.0010683121799957007, Final Batch Loss: 0.0008694950374774635\n",
      "Epoch 998, Loss: 0.0001423786670784466, Final Batch Loss: 8.075009827734903e-05\n",
      "Epoch 999, Loss: 0.0004876845341641456, Final Batch Loss: 0.0003012722881976515\n",
      "Epoch 1000, Loss: 0.0007054845482343808, Final Batch Loss: 0.00047790934331715107\n",
      "Epoch 1001, Loss: 0.0009991309780161828, Final Batch Loss: 0.00042588895303197205\n",
      "Epoch 1002, Loss: 0.00018138825544156134, Final Batch Loss: 0.00011867110879393294\n",
      "Epoch 1003, Loss: 0.0016316270921379328, Final Batch Loss: 0.001363874296657741\n",
      "Epoch 1004, Loss: 0.0005619346193270758, Final Batch Loss: 0.00032773116254247725\n",
      "Epoch 1005, Loss: 0.0003830277710221708, Final Batch Loss: 0.00010560077498666942\n",
      "Epoch 1006, Loss: 0.002730055643041851, Final Batch Loss: 5.280987898004241e-05\n",
      "Epoch 1007, Loss: 0.0044842876377515495, Final Batch Loss: 0.00036442390410229564\n",
      "Epoch 1008, Loss: 0.000129294643556932, Final Batch Loss: 2.2401716705644503e-05\n",
      "Epoch 1009, Loss: 0.00864867476047948, Final Batch Loss: 0.00835034903138876\n",
      "Epoch 1010, Loss: 0.0006815709093643818, Final Batch Loss: 4.680746133089997e-05\n",
      "Epoch 1011, Loss: 0.0004563019174383953, Final Batch Loss: 0.000305618392303586\n",
      "Epoch 1012, Loss: 0.00027235624111199286, Final Batch Loss: 1.8372729755355977e-05\n",
      "Epoch 1013, Loss: 0.0004241344504407607, Final Batch Loss: 7.691958307987079e-05\n",
      "Epoch 1014, Loss: 0.0010716599390434567, Final Batch Loss: 0.001030576415359974\n",
      "Epoch 1015, Loss: 0.004127473381231539, Final Batch Loss: 0.003945017699152231\n",
      "Epoch 1016, Loss: 0.0002170635198126547, Final Batch Loss: 7.243904838105664e-05\n",
      "Epoch 1017, Loss: 0.0016447205671283882, Final Batch Loss: 4.49373728770297e-05\n",
      "Epoch 1018, Loss: 0.0034677282674238086, Final Batch Loss: 0.002403999213129282\n",
      "Epoch 1019, Loss: 0.012156421318650246, Final Batch Loss: 0.007778170518577099\n",
      "Epoch 1020, Loss: 0.0025694300638861023, Final Batch Loss: 0.002515573287382722\n",
      "Epoch 1021, Loss: 0.0002466301230015233, Final Batch Loss: 0.00021676984033547342\n",
      "Epoch 1022, Loss: 0.0014256531485443702, Final Batch Loss: 2.266970659547951e-05\n",
      "Epoch 1023, Loss: 0.005358862108550966, Final Batch Loss: 0.005305037368088961\n",
      "Epoch 1024, Loss: 0.000767539459047839, Final Batch Loss: 0.00045188309741206467\n",
      "Epoch 1025, Loss: 0.00035631652281153947, Final Batch Loss: 0.00012961402535438538\n",
      "Epoch 1026, Loss: 0.004419238422997296, Final Batch Loss: 0.00391699094325304\n",
      "Epoch 1027, Loss: 0.001190662063891068, Final Batch Loss: 0.000789988087490201\n",
      "Epoch 1028, Loss: 0.0004304058675188571, Final Batch Loss: 0.00019648131274152547\n",
      "Epoch 1029, Loss: 0.0006379582919180393, Final Batch Loss: 0.00026196838007308543\n",
      "Epoch 1030, Loss: 0.00026791785330715356, Final Batch Loss: 9.250342372979503e-06\n",
      "Epoch 1031, Loss: 0.0003316470993013354, Final Batch Loss: 2.7772550311055966e-05\n",
      "Epoch 1032, Loss: 0.00044029478158336133, Final Batch Loss: 6.09222479397431e-05\n",
      "Epoch 1033, Loss: 0.0025303122674813494, Final Batch Loss: 0.0024138474836945534\n",
      "Epoch 1034, Loss: 0.0014092829951550812, Final Batch Loss: 0.0003373324580024928\n",
      "Epoch 1035, Loss: 0.0004753031735162949, Final Batch Loss: 0.00045145206968300045\n",
      "Epoch 1036, Loss: 6.590826433239272e-05, Final Batch Loss: 1.4338183063955512e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1037, Loss: 0.0025640096282586455, Final Batch Loss: 0.0017744043143466115\n",
      "Epoch 1038, Loss: 0.00030042029084142996, Final Batch Loss: 1.2556632100313436e-05\n",
      "Epoch 1039, Loss: 0.0003586188322515227, Final Batch Loss: 9.03098625713028e-05\n",
      "Epoch 1040, Loss: 0.00035234028473496437, Final Batch Loss: 0.00020546736777760088\n",
      "Epoch 1041, Loss: 0.0951035421458073, Final Batch Loss: 0.09459294378757477\n",
      "Epoch 1042, Loss: 0.0017524566646898165, Final Batch Loss: 0.0016328516649082303\n",
      "Epoch 1043, Loss: 0.00017484195268480107, Final Batch Loss: 8.632719982415438e-05\n",
      "Epoch 1044, Loss: 0.0003259262739447877, Final Batch Loss: 0.00024251360446214676\n",
      "Epoch 1045, Loss: 0.0019018925049749669, Final Batch Loss: 0.0018697974737733603\n",
      "Epoch 1046, Loss: 0.0006023419155098964, Final Batch Loss: 0.0005537408869713545\n",
      "Epoch 1047, Loss: 0.0017998581461142749, Final Batch Loss: 0.0001988999720197171\n",
      "Epoch 1048, Loss: 0.001118476371630095, Final Batch Loss: 0.0001266194594791159\n",
      "Epoch 1049, Loss: 0.0008976004319265485, Final Batch Loss: 9.912619134411216e-05\n",
      "Epoch 1050, Loss: 0.0001665405507083051, Final Batch Loss: 1.527435233583674e-05\n",
      "Epoch 1051, Loss: 0.001510993781266734, Final Batch Loss: 0.0010664897272363305\n",
      "Epoch 1052, Loss: 0.0002768711347016506, Final Batch Loss: 0.00017581232532393187\n",
      "Epoch 1053, Loss: 0.0003844638995360583, Final Batch Loss: 0.00013272705837152898\n",
      "Epoch 1054, Loss: 0.009678532209363766, Final Batch Loss: 0.009458005428314209\n",
      "Epoch 1055, Loss: 0.0009165062801912427, Final Batch Loss: 0.00028684717835858464\n",
      "Epoch 1056, Loss: 0.00041827514360193163, Final Batch Loss: 0.0003385741147212684\n",
      "Epoch 1057, Loss: 0.0006235046821529977, Final Batch Loss: 3.4217075153719634e-05\n",
      "Epoch 1058, Loss: 0.0016582194075454026, Final Batch Loss: 0.0004666005552280694\n",
      "Epoch 1059, Loss: 0.0005878274387214333, Final Batch Loss: 0.0002324880042579025\n",
      "Epoch 1060, Loss: 0.0019395574927330017, Final Batch Loss: 0.0010991819435730577\n",
      "Epoch 1061, Loss: 0.00024049651256063953, Final Batch Loss: 0.0001657725078985095\n",
      "Epoch 1062, Loss: 0.00027131486422149464, Final Batch Loss: 0.00010219647811027244\n",
      "Epoch 1063, Loss: 0.00018382354028290138, Final Batch Loss: 0.00014798685151617974\n",
      "Epoch 1064, Loss: 0.000584757566684857, Final Batch Loss: 0.00034425040939822793\n",
      "Epoch 1065, Loss: 0.002532836122554727, Final Batch Loss: 0.002437955467030406\n",
      "Epoch 1066, Loss: 0.0001738666760502383, Final Batch Loss: 7.483991066692397e-05\n",
      "Epoch 1067, Loss: 5.338230857887538e-05, Final Batch Loss: 1.4858132090012077e-05\n",
      "Epoch 1068, Loss: 0.00023308945674216375, Final Batch Loss: 0.00015391423949040473\n",
      "Epoch 1069, Loss: 0.0004664876214519609, Final Batch Loss: 0.0004266329051461071\n",
      "Epoch 1070, Loss: 0.002505853626644239, Final Batch Loss: 0.0020465715788304806\n",
      "Epoch 1071, Loss: 0.0025743773803696968, Final Batch Loss: 0.00011518333485582843\n",
      "Epoch 1072, Loss: 0.010404205415397882, Final Batch Loss: 0.00027698976919054985\n",
      "Epoch 1073, Loss: 0.0007047871185932308, Final Batch Loss: 9.433340164832771e-05\n",
      "Epoch 1074, Loss: 0.0037774759548483416, Final Batch Loss: 4.902125510852784e-05\n",
      "Epoch 1075, Loss: 0.0010228187456959859, Final Batch Loss: 0.0007950742146931589\n",
      "Epoch 1076, Loss: 5.725618848373415e-05, Final Batch Loss: 7.5797370300279e-06\n",
      "Epoch 1077, Loss: 0.0001747775822877884, Final Batch Loss: 0.00010216396913165227\n",
      "Epoch 1078, Loss: 0.00025035300495801494, Final Batch Loss: 0.00015359465032815933\n",
      "Epoch 1079, Loss: 0.00036175339482724667, Final Batch Loss: 0.00016759785648901016\n",
      "Epoch 1080, Loss: 0.000494532214361243, Final Batch Loss: 0.00019282630819361657\n",
      "Epoch 1081, Loss: 0.001079239576938562, Final Batch Loss: 0.0010468835243955255\n",
      "Epoch 1082, Loss: 0.00018017934417002834, Final Batch Loss: 3.047603604500182e-05\n",
      "Epoch 1083, Loss: 0.00014889891644997988, Final Batch Loss: 2.596982267277781e-05\n",
      "Epoch 1084, Loss: 1.4653262496722164e-05, Final Batch Loss: 8.614507351012435e-06\n",
      "Epoch 1085, Loss: 5.2948900702176616e-05, Final Batch Loss: 1.6183039406314492e-05\n",
      "Epoch 1086, Loss: 0.0008390613365918398, Final Batch Loss: 0.00022008770611137152\n",
      "Epoch 1087, Loss: 0.0008136467658914626, Final Batch Loss: 0.0006676784250885248\n",
      "Epoch 1088, Loss: 0.0010010587866418064, Final Batch Loss: 0.00023106945445761085\n",
      "Epoch 1089, Loss: 0.002953206072561443, Final Batch Loss: 0.002541343914344907\n",
      "Epoch 1090, Loss: 0.0003278931471868418, Final Batch Loss: 0.0002626929781399667\n",
      "Epoch 1091, Loss: 0.0009511837397440104, Final Batch Loss: 2.5109109628829174e-05\n",
      "Epoch 1092, Loss: 0.0004081827682966832, Final Batch Loss: 0.00035655233659781516\n",
      "Epoch 1093, Loss: 0.004592138728185091, Final Batch Loss: 5.036072252551094e-05\n",
      "Epoch 1094, Loss: 0.0007788891889504157, Final Batch Loss: 0.0007173393969424069\n",
      "Epoch 1095, Loss: 0.00029695090779569, Final Batch Loss: 0.0001585285790497437\n",
      "Epoch 1096, Loss: 0.0007723102753516287, Final Batch Loss: 0.00045050145126879215\n",
      "Epoch 1097, Loss: 0.00011826265108538792, Final Batch Loss: 5.1648188673425466e-05\n",
      "Epoch 1098, Loss: 0.00044914069439982995, Final Batch Loss: 6.929036317160353e-05\n",
      "Epoch 1099, Loss: 0.00112639367034717, Final Batch Loss: 0.0010970989242196083\n",
      "Epoch 1100, Loss: 0.0012339691388660867, Final Batch Loss: 3.292480414529564e-06\n",
      "Epoch 1101, Loss: 0.00020987632888136432, Final Batch Loss: 6.180105992825702e-05\n",
      "Epoch 1102, Loss: 0.001709918782580644, Final Batch Loss: 0.0005838977522216737\n",
      "Epoch 1103, Loss: 0.00012518895891844295, Final Batch Loss: 7.389460370177403e-05\n",
      "Epoch 1104, Loss: 0.0002636736608110368, Final Batch Loss: 0.00014079868560656905\n",
      "Epoch 1105, Loss: 0.000775281572714448, Final Batch Loss: 0.00028312671929597855\n",
      "Epoch 1106, Loss: 0.00019561285625968594, Final Batch Loss: 0.00016702839639037848\n",
      "Epoch 1107, Loss: 0.006665533437626436, Final Batch Loss: 0.00028027084772475064\n",
      "Epoch 1108, Loss: 0.00014949981414247304, Final Batch Loss: 6.814347580075264e-05\n",
      "Epoch 1109, Loss: 0.0006130970577942207, Final Batch Loss: 1.714403333608061e-05\n",
      "Epoch 1110, Loss: 0.002595872152596712, Final Batch Loss: 0.0011394376633688807\n",
      "Epoch 1111, Loss: 0.0006949833477847278, Final Batch Loss: 0.00043262727558612823\n",
      "Epoch 1112, Loss: 0.00035330479295225814, Final Batch Loss: 0.0003072644176427275\n",
      "Epoch 1113, Loss: 0.0014947437703085598, Final Batch Loss: 0.0014392210869118571\n",
      "Epoch 1114, Loss: 0.0008348125138581963, Final Batch Loss: 9.806697562453337e-06\n",
      "Epoch 1115, Loss: 0.0004789402591995895, Final Batch Loss: 0.00016641055117361248\n",
      "Epoch 1116, Loss: 0.0004970789887011051, Final Batch Loss: 0.00013242659042589366\n",
      "Epoch 1117, Loss: 0.0004475806199479848, Final Batch Loss: 0.00041021924698725343\n",
      "Epoch 1118, Loss: 0.0006810612103436142, Final Batch Loss: 0.00046582374488934875\n",
      "Epoch 1119, Loss: 0.0007408585515804589, Final Batch Loss: 0.0005414501065388322\n",
      "Epoch 1120, Loss: 0.0007007315252849367, Final Batch Loss: 5.799694554298185e-05\n",
      "Epoch 1121, Loss: 0.00017495290376245975, Final Batch Loss: 0.00010948073759209365\n",
      "Epoch 1122, Loss: 0.0010154308729397599, Final Batch Loss: 4.549368532025255e-05\n",
      "Epoch 1123, Loss: 0.0003848074411507696, Final Batch Loss: 0.00015589773829560727\n",
      "Epoch 1124, Loss: 0.00010822997865034267, Final Batch Loss: 1.5146222722250968e-05\n",
      "Epoch 1125, Loss: 0.00014244114208850078, Final Batch Loss: 0.00011110000195913017\n",
      "Epoch 1126, Loss: 0.0005256443255348131, Final Batch Loss: 0.00041033708839677274\n",
      "Epoch 1127, Loss: 0.000755679215217242, Final Batch Loss: 3.847811967716552e-05\n",
      "Epoch 1128, Loss: 0.0007333988833124749, Final Batch Loss: 0.0007032178109511733\n",
      "Epoch 1129, Loss: 0.00017585540444997605, Final Batch Loss: 1.608308775757905e-05\n",
      "Epoch 1130, Loss: 0.0006111325928941369, Final Batch Loss: 0.0004961236263625324\n",
      "Epoch 1131, Loss: 0.0006309475593297975, Final Batch Loss: 1.1211524906684645e-05\n",
      "Epoch 1132, Loss: 0.00040191845619119704, Final Batch Loss: 7.12346809450537e-05\n",
      "Epoch 1133, Loss: 0.0005354238383006305, Final Batch Loss: 0.0004051566938869655\n",
      "Epoch 1134, Loss: 0.000392125773942098, Final Batch Loss: 0.0003503059851936996\n",
      "Epoch 1135, Loss: 0.000312385855067987, Final Batch Loss: 0.00024698901688680053\n",
      "Epoch 1136, Loss: 0.0008361962391063571, Final Batch Loss: 0.000260507978964597\n",
      "Epoch 1137, Loss: 0.00018903849286289187, Final Batch Loss: 1.5009519302111585e-05\n",
      "Epoch 1138, Loss: 0.00021041386207798496, Final Batch Loss: 3.33893476636149e-05\n",
      "Epoch 1139, Loss: 0.00044892609730595723, Final Batch Loss: 0.0001087687342078425\n",
      "Epoch 1140, Loss: 0.0006487522332463413, Final Batch Loss: 0.00025239988462999463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1141, Loss: 0.0002873545963666402, Final Batch Loss: 4.1968443838413805e-05\n",
      "Epoch 1142, Loss: 0.00055207768582477, Final Batch Loss: 1.3935054994362872e-05\n",
      "Epoch 1143, Loss: 0.004600083804689348, Final Batch Loss: 0.0002271136036142707\n",
      "Epoch 1144, Loss: 0.010392311523901299, Final Batch Loss: 0.00026296035503037274\n",
      "Epoch 1145, Loss: 0.00010485589882591739, Final Batch Loss: 8.218330913223326e-05\n",
      "Epoch 1146, Loss: 0.0001234771843883209, Final Batch Loss: 7.994994666660205e-05\n",
      "Epoch 1147, Loss: 0.0001281604086216248, Final Batch Loss: 5.919940576859517e-06\n",
      "Epoch 1148, Loss: 0.000186405378372001, Final Batch Loss: 1.3017198398301844e-05\n",
      "Epoch 1149, Loss: 0.03225077144452371, Final Batch Loss: 0.00040185279794968665\n",
      "Epoch 1150, Loss: 0.0009118501620832831, Final Batch Loss: 0.0002300892083439976\n",
      "Epoch 1151, Loss: 0.0003617614747781772, Final Batch Loss: 5.300577686284669e-05\n",
      "Epoch 1152, Loss: 0.00033441651248722337, Final Batch Loss: 2.477355519658886e-05\n",
      "Epoch 1153, Loss: 0.00023510884057031944, Final Batch Loss: 0.00010920468048425391\n",
      "Epoch 1154, Loss: 0.00020000024596811272, Final Batch Loss: 3.5434411984169856e-05\n",
      "Epoch 1155, Loss: 0.0011365171085344627, Final Batch Loss: 0.0010031781857833266\n",
      "Epoch 1156, Loss: 0.0007191487238742411, Final Batch Loss: 0.00039557184209115803\n",
      "Epoch 1157, Loss: 5.3466272220248356e-05, Final Batch Loss: 2.924329055531416e-05\n",
      "Epoch 1158, Loss: 0.0006236861954675987, Final Batch Loss: 0.0004904385423287749\n",
      "Epoch 1159, Loss: 0.00014749211550224572, Final Batch Loss: 4.8193738621193916e-05\n",
      "Epoch 1160, Loss: 0.00012197814430692233, Final Batch Loss: 8.337476174347103e-05\n",
      "Epoch 1161, Loss: 0.007982514769537374, Final Batch Loss: 0.007805062923580408\n",
      "Epoch 1162, Loss: 0.00023567307653138414, Final Batch Loss: 0.00013667086022906005\n",
      "Epoch 1163, Loss: 0.0002755641944531817, Final Batch Loss: 3.560453842510469e-05\n",
      "Epoch 1164, Loss: 0.00011850363443954848, Final Batch Loss: 3.606026075431146e-05\n",
      "Epoch 1165, Loss: 0.0007357971626333892, Final Batch Loss: 0.00030364806298166513\n",
      "Epoch 1166, Loss: 0.010582721326500177, Final Batch Loss: 0.009492932818830013\n",
      "Epoch 1167, Loss: 0.0003832445217994973, Final Batch Loss: 7.160908717196435e-05\n",
      "Epoch 1168, Loss: 0.0002230655009043403, Final Batch Loss: 7.680943963350728e-05\n",
      "Epoch 1169, Loss: 0.00015426744721480645, Final Batch Loss: 2.5242410629289225e-05\n",
      "Epoch 1170, Loss: 0.0004356715508038178, Final Batch Loss: 0.00015378753596451133\n",
      "Epoch 1171, Loss: 0.00018325163182453252, Final Batch Loss: 4.729682768811472e-05\n",
      "Epoch 1172, Loss: 0.000782292328949552, Final Batch Loss: 0.000720322597771883\n",
      "Epoch 1173, Loss: 0.0012991533731110394, Final Batch Loss: 0.000767508230637759\n",
      "Epoch 1174, Loss: 0.0034884322158177383, Final Batch Loss: 7.2573842771817e-05\n",
      "Epoch 1175, Loss: 0.00036540756991598755, Final Batch Loss: 9.475617844145745e-05\n",
      "Epoch 1176, Loss: 0.0009529262024443597, Final Batch Loss: 0.000509988225530833\n",
      "Epoch 1177, Loss: 0.0005733879534091102, Final Batch Loss: 1.5416591850225814e-05\n",
      "Epoch 1178, Loss: 0.00301386573119089, Final Batch Loss: 0.0004927892587147653\n",
      "Epoch 1179, Loss: 0.00016204051644308493, Final Batch Loss: 8.711192640475929e-05\n",
      "Epoch 1180, Loss: 0.0005288356478558853, Final Batch Loss: 0.0001908140111481771\n",
      "Epoch 1181, Loss: 0.0007959600134199718, Final Batch Loss: 2.6947056539938785e-05\n",
      "Epoch 1182, Loss: 0.0005560550125665031, Final Batch Loss: 0.0004617575032170862\n",
      "Epoch 1183, Loss: 4.4551678001880646e-05, Final Batch Loss: 1.530571171315387e-05\n",
      "Epoch 1184, Loss: 0.0006229534919839352, Final Batch Loss: 0.00012344124843366444\n",
      "Epoch 1185, Loss: 0.0006691714952467009, Final Batch Loss: 0.0005464695859700441\n",
      "Epoch 1186, Loss: 0.0005322430515661836, Final Batch Loss: 0.00028167356504127383\n",
      "Epoch 1187, Loss: 0.0014896183565724641, Final Batch Loss: 0.00010980039951391518\n",
      "Epoch 1188, Loss: 0.0006866548646939918, Final Batch Loss: 0.000549544463865459\n",
      "Epoch 1189, Loss: 0.00017815549654187635, Final Batch Loss: 7.517979975091293e-05\n",
      "Epoch 1190, Loss: 0.0003482955144136213, Final Batch Loss: 6.285926065174863e-05\n",
      "Epoch 1191, Loss: 0.00019767056437558495, Final Batch Loss: 4.730274304165505e-05\n",
      "Epoch 1192, Loss: 0.0008564250092604198, Final Batch Loss: 0.0007852116832509637\n",
      "Epoch 1193, Loss: 0.00042549363570287824, Final Batch Loss: 0.0002054519864032045\n",
      "Epoch 1194, Loss: 0.013987852493301034, Final Batch Loss: 0.01336519606411457\n",
      "Epoch 1195, Loss: 0.0005070292463642545, Final Batch Loss: 0.00011093164357589558\n",
      "Epoch 1196, Loss: 0.00037940568290650845, Final Batch Loss: 0.00016462631174363196\n",
      "Epoch 1197, Loss: 0.0014858109825581778, Final Batch Loss: 0.001438729465007782\n",
      "Epoch 1198, Loss: 0.0001460754792788066, Final Batch Loss: 3.475978155620396e-05\n",
      "Epoch 1199, Loss: 0.0006352679920382798, Final Batch Loss: 0.00030856739613227546\n",
      "Epoch 1200, Loss: 0.0005590851505985484, Final Batch Loss: 0.00047649460611864924\n",
      "Epoch 1201, Loss: 0.00015406365128001198, Final Batch Loss: 7.930742867756635e-06\n",
      "Epoch 1202, Loss: 0.00025852945691440254, Final Batch Loss: 0.00015375821385532618\n",
      "Epoch 1203, Loss: 0.00039911544445203617, Final Batch Loss: 5.9093064919579774e-05\n",
      "Epoch 1204, Loss: 0.0004986267449567094, Final Batch Loss: 0.00014390023716259748\n",
      "Epoch 1205, Loss: 0.0003915776760550216, Final Batch Loss: 3.545034269336611e-05\n",
      "Epoch 1206, Loss: 0.0036407439329195768, Final Batch Loss: 1.283062738366425e-05\n",
      "Epoch 1207, Loss: 0.0001817599950300064, Final Batch Loss: 9.189647244056687e-06\n",
      "Epoch 1208, Loss: 0.00021245089010335505, Final Batch Loss: 0.00012315638014115393\n",
      "Epoch 1209, Loss: 3.4262152439623605e-05, Final Batch Loss: 1.0000357178796548e-05\n",
      "Epoch 1210, Loss: 0.00012458970741136, Final Batch Loss: 3.77274482161738e-05\n",
      "Epoch 1211, Loss: 0.00021419699623947963, Final Batch Loss: 0.0001434817531844601\n",
      "Epoch 1212, Loss: 0.00020260152086848393, Final Batch Loss: 6.814781954744831e-05\n",
      "Epoch 1213, Loss: 0.0006815621673013084, Final Batch Loss: 8.449039160041139e-05\n",
      "Epoch 1214, Loss: 0.00016176416465896182, Final Batch Loss: 0.00010628662130329758\n",
      "Epoch 1215, Loss: 0.00018495076074032113, Final Batch Loss: 3.0510746000800282e-05\n",
      "Epoch 1216, Loss: 0.0004905403620796278, Final Batch Loss: 0.00023855130712036043\n",
      "Epoch 1217, Loss: 0.001399829277943354, Final Batch Loss: 0.00010692991054384038\n",
      "Epoch 1218, Loss: 0.0005941142153460532, Final Batch Loss: 0.00024096551351249218\n",
      "Epoch 1219, Loss: 4.747798084281385e-05, Final Batch Loss: 2.1015905076637864e-05\n",
      "Epoch 1220, Loss: 0.0016272913489956409, Final Batch Loss: 0.0012700047809630632\n",
      "Epoch 1221, Loss: 0.0002316205427632667, Final Batch Loss: 0.0001951006706804037\n",
      "Epoch 1222, Loss: 0.0002703609397940454, Final Batch Loss: 6.015853614371736e-06\n",
      "Epoch 1223, Loss: 0.001758623169735074, Final Batch Loss: 0.001465222449041903\n",
      "Epoch 1224, Loss: 0.0006643535089096986, Final Batch Loss: 8.783421799307689e-05\n",
      "Epoch 1225, Loss: 0.001570478401845321, Final Batch Loss: 0.0013584484113380313\n",
      "Epoch 1226, Loss: 0.03927101640874753, Final Batch Loss: 0.03924274444580078\n",
      "Epoch 1227, Loss: 0.0007783171604387462, Final Batch Loss: 0.0002555666724219918\n",
      "Epoch 1228, Loss: 0.0008819938884698786, Final Batch Loss: 0.0008051356417126954\n",
      "Epoch 1229, Loss: 0.0003849124477710575, Final Batch Loss: 0.00030486745527014136\n",
      "Epoch 1230, Loss: 0.00012181255806353875, Final Batch Loss: 8.866456482792273e-05\n",
      "Epoch 1231, Loss: 0.000279918109299615, Final Batch Loss: 0.00015619679470546544\n",
      "Epoch 1232, Loss: 0.0013279475970193744, Final Batch Loss: 0.00034210667945444584\n",
      "Epoch 1233, Loss: 0.0016075244056992233, Final Batch Loss: 0.0012673505116254091\n",
      "Epoch 1234, Loss: 0.0060687823133775964, Final Batch Loss: 0.005853717215359211\n",
      "Epoch 1235, Loss: 0.0012565397046273574, Final Batch Loss: 7.575702329631895e-05\n",
      "Epoch 1236, Loss: 0.00281821982935071, Final Batch Loss: 0.0013933500740677118\n",
      "Epoch 1237, Loss: 0.000555024977074936, Final Batch Loss: 0.00033772093593142927\n",
      "Epoch 1238, Loss: 0.00011525905756570864, Final Batch Loss: 1.4656538041890599e-05\n",
      "Epoch 1239, Loss: 0.001436998078133911, Final Batch Loss: 0.000673931441269815\n",
      "Epoch 1240, Loss: 0.0005213207550696097, Final Batch Loss: 2.9120907129254192e-05\n",
      "Epoch 1241, Loss: 0.00045654000132344663, Final Batch Loss: 0.0003467810747679323\n",
      "Epoch 1242, Loss: 0.004362575389677659, Final Batch Loss: 0.0003603470104280859\n",
      "Epoch 1243, Loss: 0.00010407815352664329, Final Batch Loss: 8.342177898157388e-05\n",
      "Epoch 1244, Loss: 0.0003644071111921221, Final Batch Loss: 0.0002992966619785875\n",
      "Epoch 1245, Loss: 0.012238798197358847, Final Batch Loss: 0.005787932313978672\n",
      "Epoch 1246, Loss: 0.00043420570727903396, Final Batch Loss: 0.0002899362298194319\n",
      "Epoch 1247, Loss: 0.0004452107386896387, Final Batch Loss: 0.00029870288562960923\n",
      "Epoch 1248, Loss: 0.00015685077596572228, Final Batch Loss: 0.00011374041787348688\n",
      "Epoch 1249, Loss: 0.0006819582195021212, Final Batch Loss: 0.00037705636350438\n",
      "Epoch 1250, Loss: 0.0066796906176023185, Final Batch Loss: 0.006097746547311544\n",
      "Epoch 1251, Loss: 0.0006261984890443273, Final Batch Loss: 2.5420340534765273e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1252, Loss: 0.0014341623973450623, Final Batch Loss: 0.001360851339995861\n",
      "Epoch 1253, Loss: 0.0006773055938538164, Final Batch Loss: 0.00025561347138136625\n",
      "Epoch 1254, Loss: 0.00023349488037638366, Final Batch Loss: 0.00016812499961815774\n",
      "Epoch 1255, Loss: 0.0026132324965146836, Final Batch Loss: 3.832278525806032e-05\n",
      "Epoch 1256, Loss: 0.002462188449499081, Final Batch Loss: 2.0940757167409174e-05\n",
      "Epoch 1257, Loss: 0.000563474193768343, Final Batch Loss: 4.615384023054503e-05\n",
      "Epoch 1258, Loss: 0.00371534371515736, Final Batch Loss: 0.0032094146590679884\n",
      "Epoch 1259, Loss: 0.000306315632769838, Final Batch Loss: 6.299148662947118e-05\n",
      "Epoch 1260, Loss: 0.0004172658082097769, Final Batch Loss: 0.0002455319627188146\n",
      "Epoch 1261, Loss: 0.0007398458037641831, Final Batch Loss: 2.9364491638261825e-05\n",
      "Epoch 1262, Loss: 0.0002269734104629606, Final Batch Loss: 3.465855843387544e-05\n",
      "Epoch 1263, Loss: 0.00352447067052708, Final Batch Loss: 5.952717401669361e-05\n",
      "Epoch 1264, Loss: 0.0003186922112945467, Final Batch Loss: 7.767425267957151e-05\n",
      "Epoch 1265, Loss: 0.0010921825742116198, Final Batch Loss: 0.0010018721222877502\n",
      "Epoch 1266, Loss: 7.868060856708325e-05, Final Batch Loss: 6.193108856678009e-05\n",
      "Epoch 1267, Loss: 0.00031810501604923047, Final Batch Loss: 4.932782394462265e-05\n",
      "Epoch 1268, Loss: 0.00017339766054647043, Final Batch Loss: 7.691128848819062e-05\n",
      "Epoch 1269, Loss: 0.00036006740447191987, Final Batch Loss: 1.9056338715017773e-05\n",
      "Epoch 1270, Loss: 0.02136644064739812, Final Batch Loss: 2.8070950065739453e-05\n",
      "Epoch 1271, Loss: 0.0005849672597832978, Final Batch Loss: 0.00041504361433908343\n",
      "Epoch 1272, Loss: 0.00010860513248189818, Final Batch Loss: 1.6063740986282937e-05\n",
      "Epoch 1273, Loss: 0.0002461644762661308, Final Batch Loss: 0.0001025201054289937\n",
      "Epoch 1274, Loss: 0.00010364171225774044, Final Batch Loss: 2.8974643555557122e-06\n",
      "Epoch 1275, Loss: 0.0005675454776792321, Final Batch Loss: 2.5530989660182968e-05\n",
      "Epoch 1276, Loss: 0.0005103174189571291, Final Batch Loss: 0.00013756362022832036\n",
      "Epoch 1277, Loss: 0.0006201141222845763, Final Batch Loss: 0.0002810369769576937\n",
      "Epoch 1278, Loss: 0.0006433217495214194, Final Batch Loss: 0.0002600832376629114\n",
      "Epoch 1279, Loss: 0.001246600179001689, Final Batch Loss: 0.0004171296604909003\n",
      "Epoch 1280, Loss: 0.00017649227083893493, Final Batch Loss: 0.00011695494322339073\n",
      "Epoch 1281, Loss: 0.0015263298409990966, Final Batch Loss: 0.0005098186084069312\n",
      "Epoch 1282, Loss: 0.0008188952051568776, Final Batch Loss: 0.0007441784837283194\n",
      "Epoch 1283, Loss: 0.008734807459404692, Final Batch Loss: 0.008572225458920002\n",
      "Epoch 1284, Loss: 0.00011397898560971953, Final Batch Loss: 5.158168278285302e-05\n",
      "Epoch 1285, Loss: 0.00023827377299312502, Final Batch Loss: 0.00013772460806649178\n",
      "Epoch 1286, Loss: 0.0008221613534260541, Final Batch Loss: 0.0004127205174881965\n",
      "Epoch 1287, Loss: 0.0014208142383722588, Final Batch Loss: 0.0013518426567316055\n",
      "Epoch 1288, Loss: 0.0013530435899156146, Final Batch Loss: 0.0012761973775923252\n",
      "Epoch 1289, Loss: 0.00018774978707369883, Final Batch Loss: 2.7414456781116314e-05\n",
      "Epoch 1290, Loss: 0.0004603737033903599, Final Batch Loss: 6.013858364894986e-05\n",
      "Epoch 1291, Loss: 0.0008962485298980027, Final Batch Loss: 0.00028855426353402436\n",
      "Epoch 1292, Loss: 0.0018759602680802345, Final Batch Loss: 0.0013996211346238852\n",
      "Epoch 1293, Loss: 0.00023184315796243027, Final Batch Loss: 6.580600893357769e-05\n",
      "Epoch 1294, Loss: 0.009329570981208235, Final Batch Loss: 0.0089329294860363\n",
      "Epoch 1295, Loss: 0.00010392006788606523, Final Batch Loss: 1.4421569176192861e-05\n",
      "Epoch 1296, Loss: 0.00030755398620385677, Final Batch Loss: 0.00020616466645151377\n",
      "Epoch 1297, Loss: 0.0002754373708739877, Final Batch Loss: 0.00011017599899787456\n",
      "Epoch 1298, Loss: 0.0002778875714284368, Final Batch Loss: 0.00019707155297510326\n",
      "Epoch 1299, Loss: 0.005990596313495189, Final Batch Loss: 0.000720042095053941\n",
      "Epoch 1300, Loss: 0.00044186341983731836, Final Batch Loss: 0.0002417095092823729\n",
      "Epoch 1301, Loss: 0.00013839079747413052, Final Batch Loss: 1.2574370884976815e-05\n",
      "Epoch 1302, Loss: 0.0007241599960252643, Final Batch Loss: 0.00015247840201482177\n",
      "Epoch 1303, Loss: 0.00036419059324543923, Final Batch Loss: 0.00020631069492083043\n",
      "Epoch 1304, Loss: 0.0008864330156939104, Final Batch Loss: 2.309268165845424e-05\n",
      "Epoch 1305, Loss: 0.0004884560548816808, Final Batch Loss: 0.00044834858272224665\n",
      "Epoch 1306, Loss: 0.00027923421112063807, Final Batch Loss: 1.7869531802716665e-05\n",
      "Epoch 1307, Loss: 0.0005067230595159344, Final Batch Loss: 7.09695668774657e-05\n",
      "Epoch 1308, Loss: 0.00030092931410763413, Final Batch Loss: 0.00013551604934036732\n",
      "Epoch 1309, Loss: 0.006217934671440162, Final Batch Loss: 0.006105483043938875\n",
      "Epoch 1310, Loss: 5.200818668527063e-05, Final Batch Loss: 1.7657244825386442e-05\n",
      "Epoch 1311, Loss: 0.0001412886722391704, Final Batch Loss: 0.00011514681682456285\n",
      "Epoch 1312, Loss: 5.025770678912522e-05, Final Batch Loss: 8.03236343926983e-06\n",
      "Epoch 1313, Loss: 5.5034113756846637e-05, Final Batch Loss: 2.2411259124055505e-05\n",
      "Epoch 1314, Loss: 7.673661821172573e-05, Final Batch Loss: 4.8060104745673016e-05\n",
      "Epoch 1315, Loss: 0.00012310991587582976, Final Batch Loss: 8.600848377682269e-05\n",
      "Epoch 1316, Loss: 0.0005252138216746971, Final Batch Loss: 0.00016037181194406003\n",
      "Epoch 1317, Loss: 0.00045164884886617074, Final Batch Loss: 9.411954124516342e-06\n",
      "Epoch 1318, Loss: 0.004851137840887532, Final Batch Loss: 0.00046391840442083776\n",
      "Epoch 1319, Loss: 0.00046293309060274623, Final Batch Loss: 5.455733844428323e-05\n",
      "Epoch 1320, Loss: 0.00014361103239934891, Final Batch Loss: 0.00012329111632425338\n",
      "Epoch 1321, Loss: 0.0003210693539585918, Final Batch Loss: 0.00020474815391935408\n",
      "Epoch 1322, Loss: 0.0009594162911525927, Final Batch Loss: 0.0008585336618125439\n",
      "Epoch 1323, Loss: 0.000409774456784362, Final Batch Loss: 2.4972428946057335e-05\n",
      "Epoch 1324, Loss: 0.0001702602930890862, Final Batch Loss: 5.7279907196061686e-05\n",
      "Epoch 1325, Loss: 0.0001660781945247436, Final Batch Loss: 0.00014796254981774837\n",
      "Epoch 1326, Loss: 0.00019019199498870876, Final Batch Loss: 2.9172055292292498e-05\n",
      "Epoch 1327, Loss: 0.0011667992221191525, Final Batch Loss: 0.0006685911794193089\n",
      "Epoch 1328, Loss: 0.00012789477568730945, Final Batch Loss: 6.221606781764422e-06\n",
      "Epoch 1329, Loss: 0.00027969677466899157, Final Batch Loss: 0.00010154182382393628\n",
      "Epoch 1330, Loss: 0.001406296796631068, Final Batch Loss: 0.0010443789651617408\n",
      "Epoch 1331, Loss: 0.0009985636570490897, Final Batch Loss: 0.0007856508018448949\n",
      "Epoch 1332, Loss: 0.0004150250751990825, Final Batch Loss: 4.392783739604056e-05\n",
      "Epoch 1333, Loss: 0.0001227678803843446, Final Batch Loss: 3.3802774851210415e-05\n",
      "Epoch 1334, Loss: 0.00031669669260736555, Final Batch Loss: 0.00014610399375669658\n",
      "Epoch 1335, Loss: 0.00021319221923477016, Final Batch Loss: 5.655272616422735e-05\n",
      "Epoch 1336, Loss: 0.00022808004723628983, Final Batch Loss: 0.0001859702606452629\n",
      "Epoch 1337, Loss: 0.0002189044389524497, Final Batch Loss: 4.578338848659769e-05\n",
      "Epoch 1338, Loss: 3.8084256630099844e-05, Final Batch Loss: 2.6882835300057195e-05\n",
      "Epoch 1339, Loss: 0.00011936974624404684, Final Batch Loss: 1.9525330571923405e-05\n",
      "Epoch 1340, Loss: 0.0014935018261894584, Final Batch Loss: 0.0006507050129584968\n",
      "Epoch 1341, Loss: 0.00045080698328092694, Final Batch Loss: 0.00024499112623743713\n",
      "Epoch 1342, Loss: 0.0001634785221540369, Final Batch Loss: 1.615183282410726e-05\n",
      "Epoch 1343, Loss: 1.601628628122853e-05, Final Batch Loss: 4.582712790579535e-06\n",
      "Epoch 1344, Loss: 0.0006249222778933472, Final Batch Loss: 8.317641004396137e-06\n",
      "Epoch 1345, Loss: 0.00097579114662949, Final Batch Loss: 0.0008654678240418434\n",
      "Epoch 1346, Loss: 0.0001758887228788808, Final Batch Loss: 6.28222114755772e-05\n",
      "Epoch 1347, Loss: 0.0003484006301732734, Final Batch Loss: 3.193093289155513e-05\n",
      "Epoch 1348, Loss: 0.00023114938812796026, Final Batch Loss: 3.636919427663088e-05\n",
      "Epoch 1349, Loss: 0.0009925837766786572, Final Batch Loss: 3.183897570124827e-05\n",
      "Epoch 1350, Loss: 0.0008627903298474848, Final Batch Loss: 0.000740479095838964\n",
      "Epoch 1351, Loss: 5.933539978286717e-05, Final Batch Loss: 2.608065005915705e-05\n",
      "Epoch 1352, Loss: 3.607235339586623e-05, Final Batch Loss: 7.889493645052426e-06\n",
      "Epoch 1353, Loss: 0.00014472471593762748, Final Batch Loss: 3.3208070817636326e-05\n",
      "Epoch 1354, Loss: 0.00016335063628503121, Final Batch Loss: 0.0001290932996198535\n",
      "Epoch 1355, Loss: 0.001137970422860235, Final Batch Loss: 0.0009963815100491047\n",
      "Epoch 1356, Loss: 0.00018035252287518233, Final Batch Loss: 6.47590568405576e-05\n",
      "Epoch 1357, Loss: 0.0003492497471597744, Final Batch Loss: 0.0003278250514995307\n",
      "Epoch 1358, Loss: 0.00019072063741987222, Final Batch Loss: 3.8526254684256855e-06\n",
      "Epoch 1359, Loss: 0.0006116707663750276, Final Batch Loss: 2.1968313376419246e-05\n",
      "Epoch 1360, Loss: 5.6140519518521614e-05, Final Batch Loss: 4.507822814048268e-05\n",
      "Epoch 1361, Loss: 0.0004413987189764157, Final Batch Loss: 0.0003038142458535731\n",
      "Epoch 1362, Loss: 0.000445063371444121, Final Batch Loss: 5.729103577323258e-05\n",
      "Epoch 1363, Loss: 9.690488514024764e-05, Final Batch Loss: 8.426795102423057e-05\n",
      "Epoch 1364, Loss: 0.00040642826206749305, Final Batch Loss: 6.41698352410458e-05\n",
      "Epoch 1365, Loss: 8.588181663071737e-05, Final Batch Loss: 4.061925210407935e-05\n",
      "Epoch 1366, Loss: 5.237195364315994e-05, Final Batch Loss: 2.7222686185268685e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1367, Loss: 0.002261390196508728, Final Batch Loss: 0.002202435163781047\n",
      "Epoch 1368, Loss: 0.00026628171690390445, Final Batch Loss: 0.00021609214309137315\n",
      "Epoch 1369, Loss: 0.00010064434536616318, Final Batch Loss: 6.67627391521819e-05\n",
      "Epoch 1370, Loss: 0.0004541931048152037, Final Batch Loss: 0.000401314755436033\n",
      "Epoch 1371, Loss: 0.0003896063135471195, Final Batch Loss: 6.433206726796925e-05\n",
      "Epoch 1372, Loss: 0.00023965174477780238, Final Batch Loss: 9.57046213443391e-05\n",
      "Epoch 1373, Loss: 0.00024736725754337385, Final Batch Loss: 6.757640221621841e-06\n",
      "Epoch 1374, Loss: 0.00014510631262965035, Final Batch Loss: 6.71417910780292e-06\n",
      "Epoch 1375, Loss: 0.026908377923973603, Final Batch Loss: 4.859342516283505e-05\n",
      "Epoch 1376, Loss: 0.00017194196698255837, Final Batch Loss: 3.0103488825261593e-05\n",
      "Epoch 1377, Loss: 0.003177491671522148, Final Batch Loss: 0.0002125212486134842\n",
      "Epoch 1378, Loss: 0.001356900523319382, Final Batch Loss: 1.3495729263013345e-06\n",
      "Epoch 1379, Loss: 0.0015736733912490308, Final Batch Loss: 0.0013753558741882443\n",
      "Epoch 1380, Loss: 0.001324752054642886, Final Batch Loss: 0.00038367154775187373\n",
      "Epoch 1381, Loss: 0.000470772281914833, Final Batch Loss: 1.1880021702381782e-05\n",
      "Epoch 1382, Loss: 0.00045994216634426266, Final Batch Loss: 1.3313445379026234e-05\n",
      "Epoch 1383, Loss: 8.580487155995797e-05, Final Batch Loss: 2.8256783480173908e-05\n",
      "Epoch 1384, Loss: 0.00013861954903404694, Final Batch Loss: 1.2039568900945596e-05\n",
      "Epoch 1385, Loss: 0.0007987511926330626, Final Batch Loss: 2.9252434615045786e-05\n",
      "Epoch 1386, Loss: 0.00026227331545669585, Final Batch Loss: 0.00014563457807525992\n",
      "Epoch 1387, Loss: 0.003198429592885077, Final Batch Loss: 0.0017146618338301778\n",
      "Epoch 1388, Loss: 0.0005718477041227743, Final Batch Loss: 6.332054908853024e-05\n",
      "Epoch 1389, Loss: 0.0003951916005462408, Final Batch Loss: 0.0001626773737370968\n",
      "Epoch 1390, Loss: 0.00011941912089241669, Final Batch Loss: 3.745043068192899e-05\n",
      "Epoch 1391, Loss: 0.00010101121370098554, Final Batch Loss: 6.45010732114315e-05\n",
      "Epoch 1392, Loss: 0.01195172590087168, Final Batch Loss: 0.011920593678951263\n",
      "Epoch 1393, Loss: 0.00031979658160707913, Final Batch Loss: 4.165107020526193e-05\n",
      "Epoch 1394, Loss: 0.0013305384491104633, Final Batch Loss: 0.0008808295824564993\n",
      "Epoch 1395, Loss: 7.603599442518316e-05, Final Batch Loss: 4.144299236941151e-05\n",
      "Epoch 1396, Loss: 0.0003788287940551527, Final Batch Loss: 4.709157656179741e-05\n",
      "Epoch 1397, Loss: 0.0004897401231573895, Final Batch Loss: 0.00042967015178874135\n",
      "Epoch 1398, Loss: 0.0005622975004371256, Final Batch Loss: 0.00013720928109250963\n",
      "Epoch 1399, Loss: 0.003321830419736216, Final Batch Loss: 5.44313843420241e-05\n",
      "Epoch 1400, Loss: 0.0006398370569513645, Final Batch Loss: 0.000586936017498374\n",
      "Epoch 1401, Loss: 6.214923496372649e-05, Final Batch Loss: 7.39213146516704e-06\n",
      "Epoch 1402, Loss: 0.006116352393291891, Final Batch Loss: 0.0041693770326673985\n",
      "Epoch 1403, Loss: 0.00047846408597251866, Final Batch Loss: 1.547895408293698e-05\n",
      "Epoch 1404, Loss: 0.00030135684210108593, Final Batch Loss: 0.00020669963851105422\n",
      "Epoch 1405, Loss: 0.0007774207188049331, Final Batch Loss: 0.0006671934388577938\n",
      "Epoch 1406, Loss: 0.0002211389110016171, Final Batch Loss: 0.000161844291142188\n",
      "Epoch 1407, Loss: 0.0004974316725565586, Final Batch Loss: 0.00046547851525247097\n",
      "Epoch 1408, Loss: 0.0005888004016014747, Final Batch Loss: 3.8188234611880034e-05\n",
      "Epoch 1409, Loss: 0.015506681724218652, Final Batch Loss: 0.015243756584823132\n",
      "Epoch 1410, Loss: 0.0005215194541960955, Final Batch Loss: 5.378579953685403e-05\n",
      "Epoch 1411, Loss: 0.0007563473336631432, Final Batch Loss: 0.0005850644083693624\n",
      "Epoch 1412, Loss: 0.00015610728951287456, Final Batch Loss: 0.00010366038623033091\n",
      "Epoch 1413, Loss: 0.0003587720129871741, Final Batch Loss: 0.00029383430955931544\n",
      "Epoch 1414, Loss: 7.006031410128344e-05, Final Batch Loss: 2.9603916118503548e-05\n",
      "Epoch 1415, Loss: 0.00013820286221744027, Final Batch Loss: 1.1591202564886771e-05\n",
      "Epoch 1416, Loss: 0.00025270462083426537, Final Batch Loss: 8.060033906076569e-06\n",
      "Epoch 1417, Loss: 0.00030897065153112635, Final Batch Loss: 0.00020329485414549708\n",
      "Epoch 1418, Loss: 0.0002575514590716921, Final Batch Loss: 0.00017204403411597013\n",
      "Epoch 1419, Loss: 7.065938189043663e-05, Final Batch Loss: 3.5685330658452585e-05\n",
      "Epoch 1420, Loss: 0.00061160970471974, Final Batch Loss: 0.0005863141268491745\n",
      "Epoch 1421, Loss: 0.0003146398303215392, Final Batch Loss: 4.130215529585257e-05\n",
      "Epoch 1422, Loss: 0.00028233652119524777, Final Batch Loss: 0.00015409836487378925\n",
      "Epoch 1423, Loss: 0.0010274949891027063, Final Batch Loss: 0.00046936035505495965\n",
      "Epoch 1424, Loss: 0.00013659519754583016, Final Batch Loss: 6.347410089801997e-05\n",
      "Epoch 1425, Loss: 0.0020062261828570627, Final Batch Loss: 6.126876542111859e-05\n",
      "Epoch 1426, Loss: 0.00018011850625043735, Final Batch Loss: 0.00010159356315853074\n",
      "Epoch 1427, Loss: 0.0001609827195352409, Final Batch Loss: 0.00014907743025105447\n",
      "Epoch 1428, Loss: 0.0001813914213926182, Final Batch Loss: 8.425552550761495e-06\n",
      "Epoch 1429, Loss: 0.00014970636038924567, Final Batch Loss: 5.1390754379099235e-05\n",
      "Epoch 1430, Loss: 0.00011499592801555991, Final Batch Loss: 6.424546882044524e-05\n",
      "Epoch 1431, Loss: 0.0006194074157974683, Final Batch Loss: 0.0001173430573544465\n",
      "Epoch 1432, Loss: 0.008161412319168448, Final Batch Loss: 0.0006372386123985052\n",
      "Epoch 1433, Loss: 0.0008489432766509708, Final Batch Loss: 3.1161962397163734e-05\n",
      "Epoch 1434, Loss: 0.0008567749464418739, Final Batch Loss: 0.0006425406318157911\n",
      "Epoch 1435, Loss: 0.0001665005929680774, Final Batch Loss: 1.8326385543332435e-05\n",
      "Epoch 1436, Loss: 0.00043918775918427855, Final Batch Loss: 0.0003704658302012831\n",
      "Epoch 1437, Loss: 0.0005857783144165296, Final Batch Loss: 0.0005287958192639053\n",
      "Epoch 1438, Loss: 0.00025214785273419693, Final Batch Loss: 0.00013987957208883017\n",
      "Epoch 1439, Loss: 0.0003188236660207622, Final Batch Loss: 0.00022281394922174513\n",
      "Epoch 1440, Loss: 7.225920489872806e-05, Final Batch Loss: 4.477918992051855e-05\n",
      "Epoch 1441, Loss: 0.00027262437106401194, Final Batch Loss: 2.853843216144014e-05\n",
      "Epoch 1442, Loss: 0.0013342050951905549, Final Batch Loss: 0.0010616949293762445\n",
      "Epoch 1443, Loss: 0.00018325266137253493, Final Batch Loss: 7.579967495985329e-05\n",
      "Epoch 1444, Loss: 0.00010652692799340002, Final Batch Loss: 5.52465244254563e-05\n",
      "Epoch 1445, Loss: 0.002844462520442903, Final Batch Loss: 0.0016226180596277118\n",
      "Epoch 1446, Loss: 0.0003333061613375321, Final Batch Loss: 0.0001989625015994534\n",
      "Epoch 1447, Loss: 0.00019821074147330364, Final Batch Loss: 1.1638686373771634e-05\n",
      "Epoch 1448, Loss: 0.00036244130023987964, Final Batch Loss: 0.0002901733387261629\n",
      "Epoch 1449, Loss: 0.0006705196865368634, Final Batch Loss: 0.0003891833475790918\n",
      "Epoch 1450, Loss: 7.930756692076102e-05, Final Batch Loss: 4.792014442500658e-05\n",
      "Epoch 1451, Loss: 0.0005709312172257341, Final Batch Loss: 7.453651778632775e-05\n",
      "Epoch 1452, Loss: 0.0011368872656021267, Final Batch Loss: 0.000443817611085251\n",
      "Epoch 1453, Loss: 6.987615870457375e-05, Final Batch Loss: 1.4069178178033326e-05\n",
      "Epoch 1454, Loss: 0.00017101088451454416, Final Batch Loss: 7.807389192748815e-05\n",
      "Epoch 1455, Loss: 6.274206862144638e-05, Final Batch Loss: 3.660955189843662e-05\n",
      "Epoch 1456, Loss: 0.0013129302533343434, Final Batch Loss: 0.0012552537955343723\n",
      "Epoch 1457, Loss: 0.0001861507353169145, Final Batch Loss: 0.00016271235654130578\n",
      "Epoch 1458, Loss: 0.0003935016429750249, Final Batch Loss: 0.0002546804607845843\n",
      "Epoch 1459, Loss: 3.637441614046111e-05, Final Batch Loss: 7.529389677074505e-06\n",
      "Epoch 1460, Loss: 6.792954718548572e-05, Final Batch Loss: 6.500070412585046e-06\n",
      "Epoch 1461, Loss: 0.0003243688533984823, Final Batch Loss: 0.00029695703415200114\n",
      "Epoch 1462, Loss: 0.00011583996456465684, Final Batch Loss: 6.807554018450901e-05\n",
      "Epoch 1463, Loss: 0.00026543052081251517, Final Batch Loss: 4.9271729949396104e-05\n",
      "Epoch 1464, Loss: 0.0007348345352511387, Final Batch Loss: 0.000686679792124778\n",
      "Epoch 1465, Loss: 0.0004435454902704805, Final Batch Loss: 0.0001752582029439509\n",
      "Epoch 1466, Loss: 0.002739470568485558, Final Batch Loss: 0.0019346310291439295\n",
      "Epoch 1467, Loss: 0.00022646297657047398, Final Batch Loss: 4.029042975162156e-05\n",
      "Epoch 1468, Loss: 0.0006577147505595349, Final Batch Loss: 0.0005999120767228305\n",
      "Epoch 1469, Loss: 0.001126380440837238, Final Batch Loss: 6.28879206487909e-06\n",
      "Epoch 1470, Loss: 0.001842668221797794, Final Batch Loss: 0.0014084933791309595\n",
      "Epoch 1471, Loss: 0.0003450149524724111, Final Batch Loss: 0.00017394470341969281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1472, Loss: 0.0009630052954889834, Final Batch Loss: 0.0005628666840493679\n",
      "Epoch 1473, Loss: 0.00016894178588700015, Final Batch Loss: 1.7309068425674923e-05\n",
      "Epoch 1474, Loss: 0.0018351054968661629, Final Batch Loss: 0.0017991152126342058\n",
      "Epoch 1475, Loss: 8.760915898164967e-05, Final Batch Loss: 1.5157392226683442e-05\n",
      "Epoch 1476, Loss: 0.00013421073754216195, Final Batch Loss: 5.82620350542129e-06\n",
      "Epoch 1477, Loss: 0.0009265526314266026, Final Batch Loss: 0.00028783915331587195\n",
      "Epoch 1478, Loss: 0.0030085568796494044, Final Batch Loss: 0.0029485211707651615\n",
      "Epoch 1479, Loss: 0.0001620821531105321, Final Batch Loss: 0.0001263843005290255\n",
      "Epoch 1480, Loss: 0.00022509440896101296, Final Batch Loss: 8.253748819697648e-05\n",
      "Epoch 1481, Loss: 0.0026589623739710078, Final Batch Loss: 0.00023837397748138756\n",
      "Epoch 1482, Loss: 6.438396485464182e-05, Final Batch Loss: 4.5329314161790535e-05\n",
      "Epoch 1483, Loss: 0.00012123553824494593, Final Batch Loss: 1.665149102336727e-05\n",
      "Epoch 1484, Loss: 0.00018430117597745266, Final Batch Loss: 0.00016509750275872648\n",
      "Epoch 1485, Loss: 0.00016065361705841497, Final Batch Loss: 7.998503861017525e-05\n",
      "Epoch 1486, Loss: 6.902579116285779e-06, Final Batch Loss: 2.307555405423045e-06\n",
      "Epoch 1487, Loss: 0.00010102456872118637, Final Batch Loss: 6.88443033141084e-05\n",
      "Epoch 1488, Loss: 0.0015912450471660122, Final Batch Loss: 0.0014266639482229948\n",
      "Epoch 1489, Loss: 9.839157428359613e-05, Final Batch Loss: 2.2861873731017113e-05\n",
      "Epoch 1490, Loss: 0.00022595386690227315, Final Batch Loss: 9.065758058568463e-05\n",
      "Epoch 1491, Loss: 8.081371197476983e-05, Final Batch Loss: 3.728230149135925e-05\n",
      "Epoch 1492, Loss: 0.00011067045716117718, Final Batch Loss: 7.104913038347149e-06\n",
      "Epoch 1493, Loss: 0.002941025421023369, Final Batch Loss: 0.0011329676490277052\n",
      "Epoch 1494, Loss: 0.0002347626505070366, Final Batch Loss: 0.00013999322254676372\n",
      "Epoch 1495, Loss: 4.032772812934127e-05, Final Batch Loss: 6.804528311477043e-06\n",
      "Epoch 1496, Loss: 0.0026012405378423864, Final Batch Loss: 1.0492754881852306e-05\n",
      "Epoch 1497, Loss: 6.783126445952803e-05, Final Batch Loss: 3.022062810487114e-05\n",
      "Epoch 1498, Loss: 0.0018635971646290272, Final Batch Loss: 0.00010546876001171768\n",
      "Epoch 1499, Loss: 0.0016253314206551295, Final Batch Loss: 0.0015786699950695038\n",
      "Epoch 1500, Loss: 0.005462962784804404, Final Batch Loss: 0.005111769773066044\n",
      "Epoch 1501, Loss: 0.0011670911044348031, Final Batch Loss: 0.0008707855013199151\n",
      "Epoch 1502, Loss: 0.0001688517868387862, Final Batch Loss: 0.0001611197367310524\n",
      "Epoch 1503, Loss: 0.00034679238160606474, Final Batch Loss: 0.00011514189827721566\n",
      "Epoch 1504, Loss: 0.0010419273603474721, Final Batch Loss: 0.0010176714276894927\n",
      "Epoch 1505, Loss: 7.769437888782704e-05, Final Batch Loss: 1.2513280125858728e-05\n",
      "Epoch 1506, Loss: 0.00011104860459454358, Final Batch Loss: 3.9919905248098075e-05\n",
      "Epoch 1507, Loss: 0.00028683589334832504, Final Batch Loss: 0.00022613941109739244\n",
      "Epoch 1508, Loss: 0.001984254820854403, Final Batch Loss: 0.0019717086106538773\n",
      "Epoch 1509, Loss: 0.00332585463183932, Final Batch Loss: 0.00016190690803341568\n",
      "Epoch 1510, Loss: 0.0014066801813896745, Final Batch Loss: 0.0011486416915431619\n",
      "Epoch 1511, Loss: 0.0005055262372479774, Final Batch Loss: 9.94755100691691e-06\n",
      "Epoch 1512, Loss: 0.00020916117864544503, Final Batch Loss: 2.0483417756622657e-05\n",
      "Epoch 1513, Loss: 0.0018850588821806014, Final Batch Loss: 0.0017583778826519847\n",
      "Epoch 1514, Loss: 9.108297672355548e-05, Final Batch Loss: 3.727936928044073e-05\n",
      "Epoch 1515, Loss: 3.527890453369764e-05, Final Batch Loss: 2.9000818813074147e-06\n",
      "Epoch 1516, Loss: 0.004264719391358085, Final Batch Loss: 0.004174766130745411\n",
      "Epoch 1517, Loss: 9.571833470545243e-05, Final Batch Loss: 6.542803021147847e-05\n",
      "Epoch 1518, Loss: 9.23877814784646e-05, Final Batch Loss: 6.046433190931566e-05\n",
      "Epoch 1519, Loss: 0.00017030741219059564, Final Batch Loss: 0.0001119764638133347\n",
      "Epoch 1520, Loss: 0.00021209055921644904, Final Batch Loss: 5.8563706261338666e-05\n",
      "Epoch 1521, Loss: 0.00031089255935512483, Final Batch Loss: 0.00011888337030541152\n",
      "Epoch 1522, Loss: 8.603897185821552e-05, Final Batch Loss: 2.1555586499744095e-05\n",
      "Epoch 1523, Loss: 0.00019934268084398354, Final Batch Loss: 5.436344054032816e-06\n",
      "Epoch 1524, Loss: 8.617397179477848e-05, Final Batch Loss: 3.8539561501238495e-05\n",
      "Epoch 1525, Loss: 0.0004496688789004111, Final Batch Loss: 8.748117579671089e-06\n",
      "Epoch 1526, Loss: 0.0002597216735011898, Final Batch Loss: 3.6728444683831185e-05\n",
      "Epoch 1527, Loss: 0.0004139347802265547, Final Batch Loss: 0.0003052120446227491\n",
      "Epoch 1528, Loss: 0.0003397417767700972, Final Batch Loss: 0.00031301748822443187\n",
      "Epoch 1529, Loss: 0.00021225262753432617, Final Batch Loss: 0.00010414655116619542\n",
      "Epoch 1530, Loss: 0.00030600872128161427, Final Batch Loss: 2.700852974157897e-06\n",
      "Epoch 1531, Loss: 0.00021975798881612718, Final Batch Loss: 6.547592056449503e-05\n",
      "Epoch 1532, Loss: 0.0008096964002106688, Final Batch Loss: 0.0007981695234775543\n",
      "Epoch 1533, Loss: 0.0020400219946168363, Final Batch Loss: 0.00037917488953098655\n",
      "Epoch 1534, Loss: 5.0503352099440235e-05, Final Batch Loss: 1.5496797232117387e-06\n",
      "Epoch 1535, Loss: 0.00035265139194962103, Final Batch Loss: 3.970011675846763e-06\n",
      "Epoch 1536, Loss: 0.0026112546074728016, Final Batch Loss: 0.0025675164069980383\n",
      "Epoch 1537, Loss: 0.00016877557936822996, Final Batch Loss: 0.00010033482249127701\n",
      "Epoch 1538, Loss: 0.00047860340418992564, Final Batch Loss: 0.0004488869453780353\n",
      "Epoch 1539, Loss: 0.01040127538726665, Final Batch Loss: 0.010290117003023624\n",
      "Epoch 1540, Loss: 2.9829890536348103e-05, Final Batch Loss: 6.166102593851974e-06\n",
      "Epoch 1541, Loss: 0.00020309415413066745, Final Batch Loss: 3.054055559914559e-05\n",
      "Epoch 1542, Loss: 0.00020028536528116092, Final Batch Loss: 0.00015631395217496902\n",
      "Epoch 1543, Loss: 0.00036776019078388344, Final Batch Loss: 2.8227075745235197e-05\n",
      "Epoch 1544, Loss: 0.0007198951334430603, Final Batch Loss: 1.7765107259037904e-05\n",
      "Epoch 1545, Loss: 0.000241329129494261, Final Batch Loss: 0.0001409229007549584\n",
      "Epoch 1546, Loss: 3.8681223486491945e-05, Final Batch Loss: 1.2937090104969684e-05\n",
      "Epoch 1547, Loss: 0.00018475594515621196, Final Batch Loss: 0.00016306260658893734\n",
      "Epoch 1548, Loss: 2.0403189409989864e-05, Final Batch Loss: 8.304050425067544e-06\n",
      "Epoch 1549, Loss: 0.00019369041547179222, Final Batch Loss: 6.392793147824705e-05\n",
      "Epoch 1550, Loss: 0.00015444341624970548, Final Batch Loss: 0.00012015914398944005\n",
      "Epoch 1551, Loss: 0.0007789909141138196, Final Batch Loss: 0.0003516867000143975\n",
      "Epoch 1552, Loss: 0.00024592774934717454, Final Batch Loss: 4.0167960833059624e-05\n",
      "Epoch 1553, Loss: 0.00024546934128011344, Final Batch Loss: 0.0002325098612345755\n",
      "Epoch 1554, Loss: 0.0004532301682047546, Final Batch Loss: 0.0003801673592533916\n",
      "Epoch 1555, Loss: 0.00047538916260236874, Final Batch Loss: 9.057211718754843e-05\n",
      "Epoch 1556, Loss: 0.00015537134822807275, Final Batch Loss: 4.88884215883445e-05\n",
      "Epoch 1557, Loss: 0.00022505371816805564, Final Batch Loss: 0.00018869385530706495\n",
      "Epoch 1558, Loss: 8.994957534014247e-05, Final Batch Loss: 3.135381848551333e-05\n",
      "Epoch 1559, Loss: 0.00013392531809586217, Final Batch Loss: 5.3795488383912016e-06\n",
      "Epoch 1560, Loss: 0.0001518106637377059, Final Batch Loss: 1.9877528757206164e-05\n",
      "Epoch 1561, Loss: 0.00044565144344232976, Final Batch Loss: 0.0001386043441016227\n",
      "Epoch 1562, Loss: 0.0001244945015059784, Final Batch Loss: 8.072771015577018e-05\n",
      "Epoch 1563, Loss: 0.0011969000843237154, Final Batch Loss: 0.0011458252556622028\n",
      "Epoch 1564, Loss: 0.0001285329672100488, Final Batch Loss: 5.5520340538350865e-05\n",
      "Epoch 1565, Loss: 6.532221959787421e-05, Final Batch Loss: 1.61565731104929e-05\n",
      "Epoch 1566, Loss: 0.00012762721235048957, Final Batch Loss: 7.077102782204747e-05\n",
      "Epoch 1567, Loss: 7.250742237374652e-05, Final Batch Loss: 7.991025995579548e-06\n",
      "Epoch 1568, Loss: 0.00014004095646669157, Final Batch Loss: 5.332877844921313e-05\n",
      "Epoch 1569, Loss: 0.0025003393566294108, Final Batch Loss: 3.172172364429571e-05\n",
      "Epoch 1570, Loss: 0.00013261274943943135, Final Batch Loss: 1.728274583001621e-05\n",
      "Epoch 1571, Loss: 0.0007798506012477446, Final Batch Loss: 0.0007290744688361883\n",
      "Epoch 1572, Loss: 0.00016299499839078635, Final Batch Loss: 7.731426740065217e-05\n",
      "Epoch 1573, Loss: 0.0004134044829697814, Final Batch Loss: 0.00036518368870019913\n",
      "Epoch 1574, Loss: 0.00010890443809330463, Final Batch Loss: 9.948635124601424e-06\n",
      "Epoch 1575, Loss: 0.00011120648832729785, Final Batch Loss: 4.282114787201863e-06\n",
      "Epoch 1576, Loss: 2.798939681269985e-05, Final Batch Loss: 2.509321529942099e-05\n",
      "Epoch 1577, Loss: 3.090653353865491e-05, Final Batch Loss: 1.8422402717988007e-05\n",
      "Epoch 1578, Loss: 0.00012410805584295304, Final Batch Loss: 6.614713583985576e-06\n",
      "Epoch 1579, Loss: 0.0001207981476909481, Final Batch Loss: 0.0001049360798788257\n",
      "Epoch 1580, Loss: 0.00032652654772391543, Final Batch Loss: 1.8176324374508113e-05\n",
      "Epoch 1581, Loss: 4.109675455765682e-05, Final Batch Loss: 3.634597305790521e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1582, Loss: 0.00017502783748568618, Final Batch Loss: 6.944630968064303e-06\n",
      "Epoch 1583, Loss: 0.0001307911443291232, Final Batch Loss: 6.173217116156593e-05\n",
      "Epoch 1584, Loss: 0.0003056744044442894, Final Batch Loss: 2.840282286342699e-05\n",
      "Epoch 1585, Loss: 0.0005011938665120397, Final Batch Loss: 0.0004862761707045138\n",
      "Epoch 1586, Loss: 6.348530951072462e-05, Final Batch Loss: 1.8490944057703018e-05\n",
      "Epoch 1587, Loss: 0.0001191503179143183, Final Batch Loss: 0.00010136210767086595\n",
      "Epoch 1588, Loss: 0.0003219354730390478, Final Batch Loss: 3.9517402910860255e-05\n",
      "Epoch 1589, Loss: 0.0012660394713748246, Final Batch Loss: 0.0002641263708937913\n",
      "Epoch 1590, Loss: 0.0003278773365309462, Final Batch Loss: 0.00023950320610310882\n",
      "Epoch 1591, Loss: 0.00012324847193667665, Final Batch Loss: 9.86457453109324e-05\n",
      "Epoch 1592, Loss: 8.165064718923531e-05, Final Batch Loss: 3.4808599593816325e-05\n",
      "Epoch 1593, Loss: 0.002339709986699745, Final Batch Loss: 0.002101030433550477\n",
      "Epoch 1594, Loss: 7.214553988887928e-05, Final Batch Loss: 1.4922690752428025e-05\n",
      "Epoch 1595, Loss: 0.00041281304220319726, Final Batch Loss: 0.0003568610700313002\n",
      "Epoch 1596, Loss: 0.0037671476038667606, Final Batch Loss: 2.7698175472323783e-05\n",
      "Epoch 1597, Loss: 0.00012949337542522699, Final Batch Loss: 6.441499863285571e-05\n",
      "Epoch 1598, Loss: 9.82066812866833e-05, Final Batch Loss: 3.25526598317083e-05\n",
      "Epoch 1599, Loss: 0.00019682331185322255, Final Batch Loss: 2.5941830244846642e-05\n",
      "Epoch 1600, Loss: 0.0001913486003104481, Final Batch Loss: 0.00018191848357673734\n",
      "Epoch 1601, Loss: 0.0002793812109302962, Final Batch Loss: 2.3687587599852122e-05\n",
      "Epoch 1602, Loss: 6.080647426642827e-05, Final Batch Loss: 3.4010931813099887e-06\n",
      "Epoch 1603, Loss: 5.6351958846789785e-05, Final Batch Loss: 1.1163128874613903e-05\n",
      "Epoch 1604, Loss: 0.0003451984084676951, Final Batch Loss: 0.00018651806749403477\n",
      "Epoch 1605, Loss: 0.000186467201274354, Final Batch Loss: 9.112800762522966e-05\n",
      "Epoch 1606, Loss: 0.00016100886023195926, Final Batch Loss: 3.975315848947503e-06\n",
      "Epoch 1607, Loss: 0.002477317044395022, Final Batch Loss: 0.002335251308977604\n",
      "Epoch 1608, Loss: 6.796423804189544e-05, Final Batch Loss: 3.8822490751044825e-05\n",
      "Epoch 1609, Loss: 0.00015425498713739216, Final Batch Loss: 3.479101724224165e-05\n",
      "Epoch 1610, Loss: 4.522907420323463e-05, Final Batch Loss: 2.073445102723781e-06\n",
      "Epoch 1611, Loss: 4.125347732042428e-05, Final Batch Loss: 2.463823875586968e-05\n",
      "Epoch 1612, Loss: 5.595463153440505e-05, Final Batch Loss: 4.258412809576839e-05\n",
      "Epoch 1613, Loss: 7.029015887383139e-05, Final Batch Loss: 6.543980271089822e-05\n",
      "Epoch 1614, Loss: 0.0004149225424043834, Final Batch Loss: 6.620649946853518e-05\n",
      "Epoch 1615, Loss: 7.665508383070119e-05, Final Batch Loss: 4.608984090737067e-05\n",
      "Epoch 1616, Loss: 4.2635228965082206e-05, Final Batch Loss: 1.8384465874987654e-05\n",
      "Epoch 1617, Loss: 7.487109905923717e-05, Final Batch Loss: 4.825087307835929e-05\n",
      "Epoch 1618, Loss: 5.706890260626096e-05, Final Batch Loss: 2.2873262423672713e-05\n",
      "Epoch 1619, Loss: 5.0898253903142177e-05, Final Batch Loss: 1.2300986782065593e-05\n",
      "Epoch 1620, Loss: 0.0025911582924891263, Final Batch Loss: 0.0022702424321323633\n",
      "Epoch 1621, Loss: 6.146031591924839e-05, Final Batch Loss: 2.7878460969077423e-05\n",
      "Epoch 1622, Loss: 1.870892037914018e-05, Final Batch Loss: 1.3639791177411098e-05\n",
      "Epoch 1623, Loss: 0.0028543251014525595, Final Batch Loss: 0.0028492361307144165\n",
      "Epoch 1624, Loss: 5.123605478729587e-05, Final Batch Loss: 9.451347068534233e-06\n",
      "Epoch 1625, Loss: 1.54561107592599e-05, Final Batch Loss: 6.836276497779181e-06\n",
      "Epoch 1626, Loss: 0.00101446107692027, Final Batch Loss: 0.0009905757615342736\n",
      "Epoch 1627, Loss: 5.766007234342396e-05, Final Batch Loss: 4.395829819259234e-05\n",
      "Epoch 1628, Loss: 7.004522944953351e-05, Final Batch Loss: 3.0383455396076897e-06\n",
      "Epoch 1629, Loss: 0.00043956167064607143, Final Batch Loss: 0.00012295786291360855\n",
      "Epoch 1630, Loss: 0.0001554704285808839, Final Batch Loss: 8.330560376634821e-05\n",
      "Epoch 1631, Loss: 4.851789981330512e-05, Final Batch Loss: 1.3816849786962848e-05\n",
      "Epoch 1632, Loss: 0.00025101436222030316, Final Batch Loss: 0.0002386507112532854\n",
      "Epoch 1633, Loss: 5.1617926146718673e-05, Final Batch Loss: 2.3775162844685838e-05\n",
      "Epoch 1634, Loss: 0.00018798996734403772, Final Batch Loss: 0.0001792504481272772\n",
      "Epoch 1635, Loss: 8.136353608279023e-05, Final Batch Loss: 6.328320159809664e-05\n",
      "Epoch 1636, Loss: 0.00030465419695246965, Final Batch Loss: 0.00023374312149826437\n",
      "Epoch 1637, Loss: 0.0002466893620294286, Final Batch Loss: 0.0002213188272435218\n",
      "Epoch 1638, Loss: 0.0003148405121464748, Final Batch Loss: 0.0002653982082847506\n",
      "Epoch 1639, Loss: 8.448486369161401e-05, Final Batch Loss: 6.296162609942257e-05\n",
      "Epoch 1640, Loss: 0.00012642215006053448, Final Batch Loss: 0.00011608106433413923\n",
      "Epoch 1641, Loss: 0.00027673388831317425, Final Batch Loss: 6.623002991545945e-05\n",
      "Epoch 1642, Loss: 0.00010270224447594956, Final Batch Loss: 8.56274418765679e-05\n",
      "Epoch 1643, Loss: 4.8878950110520236e-05, Final Batch Loss: 2.671122274477966e-06\n",
      "Epoch 1644, Loss: 0.00018365897540206788, Final Batch Loss: 1.2353596503089648e-05\n",
      "Epoch 1645, Loss: 3.274874234193703e-05, Final Batch Loss: 1.148880892287707e-05\n",
      "Epoch 1646, Loss: 0.00021956139244139194, Final Batch Loss: 0.0001337374997092411\n",
      "Epoch 1647, Loss: 0.00016746952132962178, Final Batch Loss: 1.3300696082296781e-05\n",
      "Epoch 1648, Loss: 8.785154750512447e-05, Final Batch Loss: 6.0494723584270105e-05\n",
      "Epoch 1649, Loss: 9.893336755339988e-05, Final Batch Loss: 6.0912698245374486e-05\n",
      "Epoch 1650, Loss: 1.918233238029643e-05, Final Batch Loss: 1.7593562006368302e-05\n",
      "Epoch 1651, Loss: 0.00013253118413558695, Final Batch Loss: 7.1977647166932e-06\n",
      "Epoch 1652, Loss: 0.0012104640481993556, Final Batch Loss: 0.0011598237324506044\n",
      "Epoch 1653, Loss: 7.461299537681043e-05, Final Batch Loss: 2.685104846023023e-06\n",
      "Epoch 1654, Loss: 0.0003620319257606752, Final Batch Loss: 7.753467798465863e-05\n",
      "Epoch 1655, Loss: 0.0012575452128658071, Final Batch Loss: 0.0010935062309727073\n",
      "Epoch 1656, Loss: 0.00011280100443400443, Final Batch Loss: 6.183140794746578e-05\n",
      "Epoch 1657, Loss: 6.190741078171413e-05, Final Batch Loss: 1.4029561498318799e-05\n",
      "Epoch 1658, Loss: 0.0005736954917665571, Final Batch Loss: 0.000348162924638018\n",
      "Epoch 1659, Loss: 0.00022388552497432102, Final Batch Loss: 2.749593295447994e-05\n",
      "Epoch 1660, Loss: 0.00030937258088670205, Final Batch Loss: 1.6463365682284348e-05\n",
      "Epoch 1661, Loss: 3.301499418739695e-05, Final Batch Loss: 1.7147543985629454e-05\n",
      "Epoch 1662, Loss: 0.0003206423825758975, Final Batch Loss: 3.298798037576489e-05\n",
      "Epoch 1663, Loss: 3.3002003988258366e-05, Final Batch Loss: 1.698425990070973e-06\n",
      "Epoch 1664, Loss: 0.0005153770207471098, Final Batch Loss: 0.0005025811260566115\n",
      "Epoch 1665, Loss: 0.0001678040582646645, Final Batch Loss: 2.2231554339668946e-06\n",
      "Epoch 1666, Loss: 7.2499124144087546e-06, Final Batch Loss: 3.1662498258810956e-06\n",
      "Epoch 1667, Loss: 5.028989653510507e-05, Final Batch Loss: 2.0409679564181715e-05\n",
      "Epoch 1668, Loss: 8.453382906736806e-05, Final Batch Loss: 5.2955794672016054e-05\n",
      "Epoch 1669, Loss: 0.0004033029417769285, Final Batch Loss: 0.00037717632949352264\n",
      "Epoch 1670, Loss: 0.005349363149434794, Final Batch Loss: 7.418910536216572e-05\n",
      "Epoch 1671, Loss: 0.00012605735173565336, Final Batch Loss: 4.754666952067055e-05\n",
      "Epoch 1672, Loss: 0.00026886476643994683, Final Batch Loss: 1.0214281246589962e-05\n",
      "Epoch 1673, Loss: 0.0013614063063869253, Final Batch Loss: 0.0012528973165899515\n",
      "Epoch 1674, Loss: 9.073219007404987e-05, Final Batch Loss: 6.05056484346278e-05\n",
      "Epoch 1675, Loss: 0.00011920833640033379, Final Batch Loss: 9.70051041804254e-06\n",
      "Epoch 1676, Loss: 0.00014325877418741584, Final Batch Loss: 0.0001118762229452841\n",
      "Epoch 1677, Loss: 0.0003516891592880711, Final Batch Loss: 0.00021052129159215838\n",
      "Epoch 1678, Loss: 0.00017839284555520862, Final Batch Loss: 8.86826092028059e-05\n",
      "Epoch 1679, Loss: 0.00020855332968494622, Final Batch Loss: 1.1492501471366268e-05\n",
      "Epoch 1680, Loss: 0.00010266341632814147, Final Batch Loss: 8.107832400128245e-05\n",
      "Epoch 1681, Loss: 3.0617240213359764e-05, Final Batch Loss: 7.230788696688251e-07\n",
      "Epoch 1682, Loss: 7.098523565218784e-05, Final Batch Loss: 5.316803071764298e-05\n",
      "Epoch 1683, Loss: 0.00011378303952369606, Final Batch Loss: 8.429465196968522e-06\n",
      "Epoch 1684, Loss: 0.0005542046897062392, Final Batch Loss: 0.000547512958291918\n",
      "Epoch 1685, Loss: 4.964115942129865e-05, Final Batch Loss: 2.5469731554039754e-05\n",
      "Epoch 1686, Loss: 1.2774676633853232e-05, Final Batch Loss: 4.273942522559082e-06\n",
      "Epoch 1687, Loss: 0.0011350821987434756, Final Batch Loss: 3.5366490919841453e-05\n",
      "Epoch 1688, Loss: 0.0002483245698385872, Final Batch Loss: 0.00010646324517438188\n",
      "Epoch 1689, Loss: 0.0004374729651317466, Final Batch Loss: 2.0044204575242475e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1690, Loss: 0.00010297803964931518, Final Batch Loss: 6.37816046946682e-05\n",
      "Epoch 1691, Loss: 1.653456547501264e-05, Final Batch Loss: 7.408415513054933e-06\n",
      "Epoch 1692, Loss: 0.0005591066505985509, Final Batch Loss: 5.660119768435834e-06\n",
      "Epoch 1693, Loss: 0.002475413406500593, Final Batch Loss: 0.0023655379191040993\n",
      "Epoch 1694, Loss: 1.3622911865240894e-05, Final Batch Loss: 1.2320988389546983e-06\n",
      "Epoch 1695, Loss: 0.00016462379062431864, Final Batch Loss: 5.555320967687294e-06\n",
      "Epoch 1696, Loss: 0.0001958793873200193, Final Batch Loss: 6.539221794810146e-05\n",
      "Epoch 1697, Loss: 7.81384023866849e-05, Final Batch Loss: 1.4667910363641568e-05\n",
      "Epoch 1698, Loss: 9.901593875838444e-05, Final Batch Loss: 3.5268756619188935e-05\n",
      "Epoch 1699, Loss: 9.585635234543588e-05, Final Batch Loss: 1.7755699445842765e-05\n",
      "Epoch 1700, Loss: 2.8653098524955567e-05, Final Batch Loss: 6.49197227176046e-06\n",
      "Epoch 1701, Loss: 0.0002747532998910174, Final Batch Loss: 0.00025035676662810147\n",
      "Epoch 1702, Loss: 2.6078203518409282e-05, Final Batch Loss: 6.627287802984938e-06\n",
      "Epoch 1703, Loss: 0.006374083770197103, Final Batch Loss: 2.785896640489227e-06\n",
      "Epoch 1704, Loss: 2.781853709166171e-05, Final Batch Loss: 8.42819736135425e-06\n",
      "Epoch 1705, Loss: 7.058841219986789e-05, Final Batch Loss: 3.717402069014497e-05\n",
      "Epoch 1706, Loss: 0.00013552397649618797, Final Batch Loss: 7.74972650106065e-05\n",
      "Epoch 1707, Loss: 4.754979454446584e-05, Final Batch Loss: 2.8097852919017896e-05\n",
      "Epoch 1708, Loss: 0.00017742264390108176, Final Batch Loss: 2.0394381863297895e-05\n",
      "Epoch 1709, Loss: 2.4137825676007196e-05, Final Batch Loss: 1.4425664630834945e-05\n",
      "Epoch 1710, Loss: 0.00011634020120254718, Final Batch Loss: 4.228552643326111e-05\n",
      "Epoch 1711, Loss: 1.1274591997789685e-05, Final Batch Loss: 6.9004163378849626e-06\n",
      "Epoch 1712, Loss: 0.003760544932447374, Final Batch Loss: 0.0004938802449032664\n",
      "Epoch 1713, Loss: 2.2638184418610763e-05, Final Batch Loss: 7.240233571792487e-06\n",
      "Epoch 1714, Loss: 0.0005481095540744718, Final Batch Loss: 0.0005341959767974913\n",
      "Epoch 1715, Loss: 0.0003084838535869494, Final Batch Loss: 0.00017424928955733776\n",
      "Epoch 1716, Loss: 0.00030895151394361164, Final Batch Loss: 0.00029138708487153053\n",
      "Epoch 1717, Loss: 5.866869514647988e-05, Final Batch Loss: 4.772632109961705e-06\n",
      "Epoch 1718, Loss: 0.00010971334904752439, Final Batch Loss: 0.000106855331978295\n",
      "Epoch 1719, Loss: 0.00023100862745195627, Final Batch Loss: 1.9980143406428397e-05\n",
      "Epoch 1720, Loss: 5.487666476255981e-05, Final Batch Loss: 5.200891973800026e-05\n",
      "Epoch 1721, Loss: 0.00011103393808298279, Final Batch Loss: 3.0260505809565075e-05\n",
      "Epoch 1722, Loss: 0.00020622314332285896, Final Batch Loss: 3.525142528815195e-05\n",
      "Epoch 1723, Loss: 0.00798359955297201, Final Batch Loss: 0.007959822192788124\n",
      "Epoch 1724, Loss: 3.325856596347876e-05, Final Batch Loss: 2.1581825421890244e-05\n",
      "Epoch 1725, Loss: 0.00029807360260747373, Final Batch Loss: 0.0002130235661752522\n",
      "Epoch 1726, Loss: 5.117231921758503e-05, Final Batch Loss: 2.1528976503759623e-05\n",
      "Epoch 1727, Loss: 5.721275738324039e-05, Final Batch Loss: 8.052964403759688e-06\n",
      "Epoch 1728, Loss: 0.0005544396840377885, Final Batch Loss: 5.76944103158894e-06\n",
      "Epoch 1729, Loss: 7.652616113773547e-05, Final Batch Loss: 6.282190588535741e-05\n",
      "Epoch 1730, Loss: 2.6392982363176998e-05, Final Batch Loss: 9.496888196736109e-06\n",
      "Epoch 1731, Loss: 0.00023170325584942475, Final Batch Loss: 0.00014039553934708238\n",
      "Epoch 1732, Loss: 4.18814397562528e-05, Final Batch Loss: 1.8468776033842005e-05\n",
      "Epoch 1733, Loss: 0.0001651624534133589, Final Batch Loss: 2.278698048030492e-05\n",
      "Epoch 1734, Loss: 0.00028608990396605805, Final Batch Loss: 3.1065377697814256e-05\n",
      "Epoch 1735, Loss: 1.4472358088823967e-05, Final Batch Loss: 2.5085055312956683e-06\n",
      "Epoch 1736, Loss: 0.0007646716694580391, Final Batch Loss: 8.002524555195123e-05\n",
      "Epoch 1737, Loss: 2.011408696489525e-05, Final Batch Loss: 1.5115236237761565e-05\n",
      "Epoch 1738, Loss: 0.0003087377263000235, Final Batch Loss: 0.0002949369663838297\n",
      "Epoch 1739, Loss: 0.00010604706039885059, Final Batch Loss: 8.846840501064435e-05\n",
      "Epoch 1740, Loss: 2.3806353169675276e-05, Final Batch Loss: 1.0250024615743314e-06\n",
      "Epoch 1741, Loss: 0.00022201035244506784, Final Batch Loss: 3.8028654671506956e-05\n",
      "Epoch 1742, Loss: 0.0003280848090980726, Final Batch Loss: 5.592452453129226e-06\n",
      "Epoch 1743, Loss: 4.4478622385213384e-05, Final Batch Loss: 7.52282585381181e-06\n",
      "Epoch 1744, Loss: 7.761138294881675e-05, Final Batch Loss: 2.5414616175112315e-05\n",
      "Epoch 1745, Loss: 2.834811130014714e-05, Final Batch Loss: 4.142240868532099e-06\n",
      "Epoch 1746, Loss: 0.00029664666726603173, Final Batch Loss: 1.0673476936062798e-05\n",
      "Epoch 1747, Loss: 2.2563699076272314e-05, Final Batch Loss: 5.46054388905759e-06\n",
      "Epoch 1748, Loss: 0.00017779568770492915, Final Batch Loss: 0.00014983357687015086\n",
      "Epoch 1749, Loss: 0.0002610933152027428, Final Batch Loss: 0.00017704283527564257\n",
      "Epoch 1750, Loss: 0.000281873009953415, Final Batch Loss: 2.130359280272387e-05\n",
      "Epoch 1751, Loss: 0.00026990774040314136, Final Batch Loss: 1.0482947800483089e-05\n",
      "Epoch 1752, Loss: 3.3746960070857313e-06, Final Batch Loss: 8.805754987406544e-07\n",
      "Epoch 1753, Loss: 0.00018085500414599665, Final Batch Loss: 0.00014964170986786485\n",
      "Epoch 1754, Loss: 2.8746747375407722e-05, Final Batch Loss: 1.3414494787866715e-05\n",
      "Epoch 1755, Loss: 3.491207826300524e-05, Final Batch Loss: 1.8530776287661865e-05\n",
      "Epoch 1756, Loss: 0.000516131789481733, Final Batch Loss: 0.0004193865752313286\n",
      "Epoch 1757, Loss: 0.00018829500550054945, Final Batch Loss: 2.0046780264237896e-05\n",
      "Epoch 1758, Loss: 0.00022156665909278672, Final Batch Loss: 4.990301022189669e-06\n",
      "Epoch 1759, Loss: 0.00028260947203762044, Final Batch Loss: 1.5923147884677746e-06\n",
      "Epoch 1760, Loss: 8.912484736356419e-05, Final Batch Loss: 1.6129981304402463e-05\n",
      "Epoch 1761, Loss: 0.0003423753059905721, Final Batch Loss: 2.228258927061688e-05\n",
      "Epoch 1762, Loss: 0.0002475815626894473, Final Batch Loss: 1.297037579206517e-05\n",
      "Epoch 1763, Loss: 0.00018005681710064891, Final Batch Loss: 8.048701261031965e-07\n",
      "Epoch 1764, Loss: 8.098865328065585e-05, Final Batch Loss: 5.473000055644661e-05\n",
      "Epoch 1765, Loss: 3.682513397507137e-05, Final Batch Loss: 2.211884748248849e-05\n",
      "Epoch 1766, Loss: 8.038051964831538e-05, Final Batch Loss: 5.9264475567033514e-05\n",
      "Epoch 1767, Loss: 0.00018119716878572945, Final Batch Loss: 0.00015768002776894718\n",
      "Epoch 1768, Loss: 2.8259752070880495e-05, Final Batch Loss: 7.593127520522103e-06\n",
      "Epoch 1769, Loss: 0.0076043429880883195, Final Batch Loss: 0.007593072019517422\n",
      "Epoch 1770, Loss: 0.00018464113804839144, Final Batch Loss: 2.993116368088522e-06\n",
      "Epoch 1771, Loss: 4.9484414375911e-05, Final Batch Loss: 8.97345398698235e-06\n",
      "Epoch 1772, Loss: 0.0011174885512446053, Final Batch Loss: 4.0347287722397596e-05\n",
      "Epoch 1773, Loss: 0.00020029390725539997, Final Batch Loss: 5.678719753632322e-05\n",
      "Epoch 1774, Loss: 0.000102230111224344, Final Batch Loss: 6.673604366369545e-05\n",
      "Epoch 1775, Loss: 0.00025596410489470145, Final Batch Loss: 8.179246151485131e-07\n",
      "Epoch 1776, Loss: 0.00023377599313789688, Final Batch Loss: 0.0002309170668013394\n",
      "Epoch 1777, Loss: 3.853037560475059e-05, Final Batch Loss: 2.0400988432811573e-05\n",
      "Epoch 1778, Loss: 6.234937973204069e-05, Final Batch Loss: 2.3191005311673507e-05\n",
      "Epoch 1779, Loss: 0.0008539699260836642, Final Batch Loss: 0.0008495082147419453\n",
      "Epoch 1780, Loss: 0.00048096300452016294, Final Batch Loss: 0.0003570599074009806\n",
      "Epoch 1781, Loss: 0.0005755907241109526, Final Batch Loss: 0.0005549068446271122\n",
      "Epoch 1782, Loss: 0.0007915661408333108, Final Batch Loss: 0.0005692190025001764\n",
      "Epoch 1783, Loss: 5.840117864863714e-06, Final Batch Loss: 2.0290383417886915e-06\n",
      "Epoch 1784, Loss: 0.00044950921983399894, Final Batch Loss: 1.7539719920023344e-05\n",
      "Epoch 1785, Loss: 4.063644837515312e-05, Final Batch Loss: 4.166820417594863e-06\n",
      "Epoch 1786, Loss: 1.4721116258442635e-05, Final Batch Loss: 6.444953669415554e-06\n",
      "Epoch 1787, Loss: 0.0002156224836653564, Final Batch Loss: 4.1476050682831556e-06\n",
      "Epoch 1788, Loss: 0.0003842662899842253, Final Batch Loss: 1.245114799530711e-05\n",
      "Epoch 1789, Loss: 0.00033754954893083777, Final Batch Loss: 3.0009305191924796e-06\n",
      "Epoch 1790, Loss: 9.40824712643007e-05, Final Batch Loss: 4.916247462460888e-07\n",
      "Epoch 1791, Loss: 7.795509327479522e-05, Final Batch Loss: 6.2205976973928045e-06\n",
      "Epoch 1792, Loss: 4.1416867134103086e-05, Final Batch Loss: 3.3365897252224386e-05\n",
      "Epoch 1793, Loss: 0.00015115292535483604, Final Batch Loss: 4.896631253359374e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1794, Loss: 3.9370610465994105e-05, Final Batch Loss: 1.1353760783094913e-05\n",
      "Epoch 1795, Loss: 7.796770660206676e-05, Final Batch Loss: 4.248416735208593e-05\n",
      "Epoch 1796, Loss: 0.0003967325842495484, Final Batch Loss: 1.2373143363220152e-06\n",
      "Epoch 1797, Loss: 0.0009180406696032151, Final Batch Loss: 0.0009058826835826039\n",
      "Epoch 1798, Loss: 2.9241126867418643e-05, Final Batch Loss: 1.2718060133920517e-05\n",
      "Epoch 1799, Loss: 0.00010276604962200508, Final Batch Loss: 4.47036518380628e-06\n",
      "Epoch 1800, Loss: 0.00013054058763373177, Final Batch Loss: 0.00011226554488530383\n",
      "Epoch 1801, Loss: 2.6755499902719748e-05, Final Batch Loss: 3.577840516300057e-06\n",
      "Epoch 1802, Loss: 2.8908711101394147e-05, Final Batch Loss: 2.7459673219709657e-05\n",
      "Epoch 1803, Loss: 0.00022000307762937155, Final Batch Loss: 0.00020754679280798882\n",
      "Epoch 1804, Loss: 7.420007750624791e-05, Final Batch Loss: 6.475225382018834e-05\n",
      "Epoch 1805, Loss: 0.00011284190577498521, Final Batch Loss: 0.00010530552390264347\n",
      "Epoch 1806, Loss: 3.856491957776598e-05, Final Batch Loss: 3.358779940754175e-05\n",
      "Epoch 1807, Loss: 0.00010225623248061311, Final Batch Loss: 1.09807717763033e-06\n",
      "Epoch 1808, Loss: 2.6338142106396845e-05, Final Batch Loss: 4.544915555015905e-06\n",
      "Epoch 1809, Loss: 0.00016264511987174046, Final Batch Loss: 0.0001559201773488894\n",
      "Epoch 1810, Loss: 0.0009368066966999322, Final Batch Loss: 0.00047801865730434656\n",
      "Epoch 1811, Loss: 2.2063502910896204e-05, Final Batch Loss: 1.7014453987940215e-05\n",
      "Epoch 1812, Loss: 1.4332690625451505e-05, Final Batch Loss: 7.062808890623273e-06\n",
      "Epoch 1813, Loss: 5.990769750496838e-05, Final Batch Loss: 3.615382593125105e-05\n",
      "Epoch 1814, Loss: 0.00014934711725800298, Final Batch Loss: 0.00010555063636275008\n",
      "Epoch 1815, Loss: 0.00010254327435177402, Final Batch Loss: 5.299102667777333e-07\n",
      "Epoch 1816, Loss: 7.748032408017025e-05, Final Batch Loss: 7.469765841960907e-05\n",
      "Epoch 1817, Loss: 0.001295616566494573, Final Batch Loss: 2.995885006384924e-05\n",
      "Epoch 1818, Loss: 5.917376620345749e-05, Final Batch Loss: 2.1626427042065188e-05\n",
      "Epoch 1819, Loss: 8.364279210582026e-06, Final Batch Loss: 5.3899616432318e-06\n",
      "Epoch 1820, Loss: 5.007867730455473e-05, Final Batch Loss: 2.555022365413606e-05\n",
      "Epoch 1821, Loss: 9.678778224042617e-05, Final Batch Loss: 6.898293941048905e-05\n",
      "Epoch 1822, Loss: 0.000877657772434759, Final Batch Loss: 0.000856220256537199\n",
      "Epoch 1823, Loss: 0.0003218869105694466, Final Batch Loss: 1.1351688044669572e-05\n",
      "Epoch 1824, Loss: 0.00034309896454942646, Final Batch Loss: 8.00246652943315e-06\n",
      "Epoch 1825, Loss: 2.383584615017753e-05, Final Batch Loss: 1.1057560186600313e-05\n",
      "Epoch 1826, Loss: 7.982842066667217e-05, Final Batch Loss: 2.1203711639827816e-06\n",
      "Epoch 1827, Loss: 0.0001122062813010416, Final Batch Loss: 9.803305874811485e-05\n",
      "Epoch 1828, Loss: 0.0001942601302289404, Final Batch Loss: 0.0001319243892794475\n",
      "Epoch 1829, Loss: 0.00024497405138390604, Final Batch Loss: 2.1880123313167132e-05\n",
      "Epoch 1830, Loss: 3.925015334971249e-05, Final Batch Loss: 3.079975795117207e-05\n",
      "Epoch 1831, Loss: 0.0007401783659588546, Final Batch Loss: 2.378618228249252e-05\n",
      "Epoch 1832, Loss: 0.00015617402095813304, Final Batch Loss: 0.00012966028589289635\n",
      "Epoch 1833, Loss: 0.0013074993312329752, Final Batch Loss: 0.0013021474005654454\n",
      "Epoch 1834, Loss: 2.4910566366997955e-05, Final Batch Loss: 1.7567666645845748e-06\n",
      "Epoch 1835, Loss: 0.00034139055696869036, Final Batch Loss: 8.288951903523412e-06\n",
      "Epoch 1836, Loss: 3.9793421819922514e-05, Final Batch Loss: 2.332563599338755e-05\n",
      "Epoch 1837, Loss: 0.0054035851597973306, Final Batch Loss: 0.005402176175266504\n",
      "Epoch 1838, Loss: 0.0001057146982930135, Final Batch Loss: 9.971149847842753e-05\n",
      "Epoch 1839, Loss: 0.00014477498393716814, Final Batch Loss: 1.592316266396665e-06\n",
      "Epoch 1840, Loss: 0.0002223644478362985, Final Batch Loss: 3.113375714747235e-05\n",
      "Epoch 1841, Loss: 9.598162432666868e-05, Final Batch Loss: 4.733811874757521e-05\n",
      "Epoch 1842, Loss: 0.00011132127792734536, Final Batch Loss: 2.0768707145180088e-06\n",
      "Epoch 1843, Loss: 5.670007521985099e-05, Final Batch Loss: 2.904749271692708e-05\n",
      "Epoch 1844, Loss: 0.00010133087744179647, Final Batch Loss: 8.301607886096463e-05\n",
      "Epoch 1845, Loss: 5.0944340273417765e-05, Final Batch Loss: 4.4963003347220365e-06\n",
      "Epoch 1846, Loss: 6.293332626228221e-05, Final Batch Loss: 5.0197169912280515e-05\n",
      "Epoch 1847, Loss: 1.9520396108418936e-05, Final Batch Loss: 2.183115157095017e-06\n",
      "Epoch 1848, Loss: 0.004720474833447952, Final Batch Loss: 8.200924639822915e-05\n",
      "Epoch 1849, Loss: 0.00012350684846751392, Final Batch Loss: 7.69866383052431e-05\n",
      "Epoch 1850, Loss: 1.954484741872875e-05, Final Batch Loss: 1.3814330486638937e-05\n",
      "Epoch 1851, Loss: 0.00011210779507564439, Final Batch Loss: 1.4531108263327042e-06\n",
      "Epoch 1852, Loss: 2.7628343559626956e-05, Final Batch Loss: 1.3854200005880557e-05\n",
      "Epoch 1853, Loss: 0.005971669088467024, Final Batch Loss: 0.00583444070070982\n",
      "Epoch 1854, Loss: 1.7359901903546415e-05, Final Batch Loss: 1.1441898095654324e-06\n",
      "Epoch 1855, Loss: 7.361551365647756e-05, Final Batch Loss: 7.013967115199193e-05\n",
      "Epoch 1856, Loss: 2.185082325922849e-05, Final Batch Loss: 1.9570779841160402e-05\n",
      "Epoch 1857, Loss: 0.0002227945442427881, Final Batch Loss: 3.2873555028345436e-05\n",
      "Epoch 1858, Loss: 0.0003184431807312649, Final Batch Loss: 0.0003021357406396419\n",
      "Epoch 1859, Loss: 6.673040479654446e-05, Final Batch Loss: 3.5776822187472135e-05\n",
      "Epoch 1860, Loss: 1.9654743027786026e-05, Final Batch Loss: 6.53524284643936e-06\n",
      "Epoch 1861, Loss: 0.00022534609161084518, Final Batch Loss: 0.00016830679669510573\n",
      "Epoch 1862, Loss: 0.00018576611182652414, Final Batch Loss: 0.0001219706391566433\n",
      "Epoch 1863, Loss: 7.14665566192707e-05, Final Batch Loss: 4.2779553041327745e-05\n",
      "Epoch 1864, Loss: 0.00013078341908112634, Final Batch Loss: 4.2492920329095796e-06\n",
      "Epoch 1865, Loss: 0.00011390316285542212, Final Batch Loss: 4.869129406870343e-05\n",
      "Epoch 1866, Loss: 0.0004419924134708708, Final Batch Loss: 1.1554939192137681e-05\n",
      "Epoch 1867, Loss: 0.0011510633376019541, Final Batch Loss: 0.001117509207688272\n",
      "Epoch 1868, Loss: 4.732299021270592e-05, Final Batch Loss: 1.6258100004051812e-05\n",
      "Epoch 1869, Loss: 0.00010192008267040364, Final Batch Loss: 4.785533019457944e-05\n",
      "Epoch 1870, Loss: 0.0002106834126607282, Final Batch Loss: 0.00018334774358663708\n",
      "Epoch 1871, Loss: 0.004179670090707077, Final Batch Loss: 0.004175680689513683\n",
      "Epoch 1872, Loss: 5.5156020607682876e-05, Final Batch Loss: 1.6854852219694294e-05\n",
      "Epoch 1873, Loss: 0.00016549967403989285, Final Batch Loss: 0.00014931568875908852\n",
      "Epoch 1874, Loss: 0.00018523425387684256, Final Batch Loss: 9.467980999033898e-05\n",
      "Epoch 1875, Loss: 0.0010298695269739255, Final Batch Loss: 0.0008515116642229259\n",
      "Epoch 1876, Loss: 0.00033338971024932107, Final Batch Loss: 0.0003242803504690528\n",
      "Epoch 1877, Loss: 0.0003987170275649987, Final Batch Loss: 0.0002849737647920847\n",
      "Epoch 1878, Loss: 0.0009834340926317964, Final Batch Loss: 2.3099946702132e-05\n",
      "Epoch 1879, Loss: 0.04077314771711826, Final Batch Loss: 0.004745138809084892\n",
      "Epoch 1880, Loss: 3.9429485696018673e-05, Final Batch Loss: 8.562294169678353e-06\n",
      "Epoch 1881, Loss: 0.00039152164390543476, Final Batch Loss: 0.0001135277925641276\n",
      "Epoch 1882, Loss: 0.0003985953517258167, Final Batch Loss: 0.000306236237520352\n",
      "Epoch 1883, Loss: 0.002347538475987676, Final Batch Loss: 0.0023421894293278456\n",
      "Epoch 1884, Loss: 0.0005042137163400184, Final Batch Loss: 5.8682704548118636e-05\n",
      "Epoch 1885, Loss: 4.8266649173456244e-05, Final Batch Loss: 3.1855208362685516e-05\n",
      "Epoch 1886, Loss: 6.507501620944822e-05, Final Batch Loss: 5.255074938759208e-05\n",
      "Epoch 1887, Loss: 0.00018128576084563974, Final Batch Loss: 0.00015640065248589963\n",
      "Epoch 1888, Loss: 0.007639505289262161, Final Batch Loss: 0.0073184664361178875\n",
      "Epoch 1889, Loss: 5.6851287808967754e-05, Final Batch Loss: 6.779227987863123e-06\n",
      "Epoch 1890, Loss: 3.424189276302059e-05, Final Batch Loss: 3.7875099678785773e-06\n",
      "Epoch 1891, Loss: 0.00010015330190071836, Final Batch Loss: 1.8052669474855065e-05\n",
      "Epoch 1892, Loss: 0.00046516506517946254, Final Batch Loss: 2.8784414098481648e-05\n",
      "Epoch 1893, Loss: 0.023750640804792056, Final Batch Loss: 0.02370671182870865\n",
      "Epoch 1894, Loss: 0.004107420947548235, Final Batch Loss: 9.309649612987414e-06\n",
      "Epoch 1895, Loss: 0.000517701635544654, Final Batch Loss: 5.20713729201816e-05\n",
      "Epoch 1896, Loss: 2.7020518245990388e-05, Final Batch Loss: 1.1535621524672024e-05\n",
      "Epoch 1897, Loss: 0.0005008697830817255, Final Batch Loss: 5.427477390185231e-06\n",
      "Epoch 1898, Loss: 0.0004502019419305725, Final Batch Loss: 0.00042547748307697475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1899, Loss: 0.0006084063497837633, Final Batch Loss: 0.0004702783771790564\n",
      "Epoch 1900, Loss: 0.0037099116598255932, Final Batch Loss: 0.003464656649157405\n",
      "Epoch 1901, Loss: 0.0017196735716424882, Final Batch Loss: 0.001019651535898447\n",
      "Epoch 1902, Loss: 0.0286085580883082, Final Batch Loss: 0.00046892030513845384\n",
      "Epoch 1903, Loss: 7.984900730662048e-05, Final Batch Loss: 3.2297342841047794e-05\n",
      "Epoch 1904, Loss: 6.358294831443345e-05, Final Batch Loss: 1.3152136489225086e-05\n",
      "Epoch 1905, Loss: 3.7670648453058675e-05, Final Batch Loss: 1.615336259419564e-05\n",
      "Epoch 1906, Loss: 0.0003474200639175251, Final Batch Loss: 0.00022460891341324896\n",
      "Epoch 1907, Loss: 1.0261505394737469e-05, Final Batch Loss: 4.663042091124225e-06\n",
      "Epoch 1908, Loss: 0.00010508380728424527, Final Batch Loss: 9.189494448946789e-06\n",
      "Epoch 1909, Loss: 0.00021821829432155937, Final Batch Loss: 9.450477955397218e-05\n",
      "Epoch 1910, Loss: 0.0028400823393894825, Final Batch Loss: 2.489280086592771e-05\n",
      "Epoch 1911, Loss: 6.921845488250256e-05, Final Batch Loss: 1.1892061593243852e-05\n",
      "Epoch 1912, Loss: 0.0007913788540463429, Final Batch Loss: 0.0007342913304455578\n",
      "Epoch 1913, Loss: 0.0005240957689238712, Final Batch Loss: 0.00014195060066413134\n",
      "Epoch 1914, Loss: 0.00013113907789374935, Final Batch Loss: 0.00011956752859987319\n",
      "Epoch 1915, Loss: 7.275820826180279e-05, Final Batch Loss: 2.2970449208514765e-05\n",
      "Epoch 1916, Loss: 0.00017274211131734774, Final Batch Loss: 8.557082765037194e-05\n",
      "Epoch 1917, Loss: 0.0008205924823414534, Final Batch Loss: 0.0006525327917188406\n",
      "Epoch 1918, Loss: 0.0007251937204273418, Final Batch Loss: 0.0006066421628929675\n",
      "Epoch 1919, Loss: 0.0004100834539713105, Final Batch Loss: 3.0130910090520047e-05\n",
      "Epoch 1920, Loss: 3.643413856480038e-05, Final Batch Loss: 2.2155873011797667e-05\n",
      "Epoch 1921, Loss: 0.00010582040340523235, Final Batch Loss: 6.38001220067963e-05\n",
      "Epoch 1922, Loss: 7.205152724054642e-05, Final Batch Loss: 3.00226456602104e-05\n",
      "Epoch 1923, Loss: 0.00017799549823394045, Final Batch Loss: 0.00011964410077780485\n",
      "Epoch 1924, Loss: 3.0972028071118984e-05, Final Batch Loss: 8.92387924977811e-06\n",
      "Epoch 1925, Loss: 7.65892468734819e-05, Final Batch Loss: 2.3231909835885745e-06\n",
      "Epoch 1926, Loss: 0.0001870195810624864, Final Batch Loss: 3.4208216675324365e-05\n",
      "Epoch 1927, Loss: 0.00011445759628259111, Final Batch Loss: 9.672197484178469e-05\n",
      "Epoch 1928, Loss: 0.0006289565271799802, Final Batch Loss: 0.0006137419841252267\n",
      "Epoch 1929, Loss: 8.667473230161704e-05, Final Batch Loss: 2.4400429538218305e-05\n",
      "Epoch 1930, Loss: 0.08443358429940417, Final Batch Loss: 0.08381684124469757\n",
      "Epoch 1931, Loss: 1.567429126225761e-05, Final Batch Loss: 7.359640676440904e-06\n",
      "Epoch 1932, Loss: 0.0003654029278550297, Final Batch Loss: 0.0001896009052870795\n",
      "Epoch 1933, Loss: 0.0002704916914808564, Final Batch Loss: 6.897745333844796e-05\n",
      "Epoch 1934, Loss: 9.697994028101675e-05, Final Batch Loss: 8.07829710538499e-05\n",
      "Epoch 1935, Loss: 3.917571848432999e-05, Final Batch Loss: 1.6607844372629188e-05\n",
      "Epoch 1936, Loss: 0.00027403904459788464, Final Batch Loss: 0.00025972456205636263\n",
      "Epoch 1937, Loss: 0.00015078953947522677, Final Batch Loss: 2.504259828128852e-05\n",
      "Epoch 1938, Loss: 0.00018729914609139087, Final Batch Loss: 4.402482773002703e-06\n",
      "Epoch 1939, Loss: 0.00010809787818288896, Final Batch Loss: 1.2147787856520154e-05\n",
      "Epoch 1940, Loss: 0.0009188044823531527, Final Batch Loss: 0.0009022621088661253\n",
      "Epoch 1941, Loss: 0.0032332463924831245, Final Batch Loss: 0.0031853171531111\n",
      "Epoch 1942, Loss: 0.00029611292120534927, Final Batch Loss: 9.558831516187638e-05\n",
      "Epoch 1943, Loss: 0.0009076565838768147, Final Batch Loss: 0.00011475852079456672\n",
      "Epoch 1944, Loss: 0.00014916887721483363, Final Batch Loss: 1.0761144039861392e-05\n",
      "Epoch 1945, Loss: 0.0004095726471859962, Final Batch Loss: 0.00016248133033514023\n",
      "Epoch 1946, Loss: 0.0011917810843442567, Final Batch Loss: 7.237058161990717e-05\n",
      "Epoch 1947, Loss: 0.011511584074469283, Final Batch Loss: 0.00038151376065798104\n",
      "Epoch 1948, Loss: 0.0001568761799717322, Final Batch Loss: 2.399447839707136e-05\n",
      "Epoch 1949, Loss: 6.243706775421742e-05, Final Batch Loss: 3.802897117566317e-05\n",
      "Epoch 1950, Loss: 0.0001952989932760829, Final Batch Loss: 0.00017895684868562967\n",
      "Epoch 1951, Loss: 7.035071075733867e-05, Final Batch Loss: 3.723027930391254e-06\n",
      "Epoch 1952, Loss: 0.0007600797835038975, Final Batch Loss: 0.0006259878282435238\n",
      "Epoch 1953, Loss: 9.638257688493468e-05, Final Batch Loss: 3.7132471334189177e-05\n",
      "Epoch 1954, Loss: 0.0005859964521732763, Final Batch Loss: 1.1408375030441675e-05\n",
      "Epoch 1955, Loss: 9.198445150104817e-05, Final Batch Loss: 2.7858111934619956e-05\n",
      "Epoch 1956, Loss: 6.066177047614474e-05, Final Batch Loss: 3.529954483383335e-05\n",
      "Epoch 1957, Loss: 6.674109044979559e-05, Final Batch Loss: 5.8288598665967584e-05\n",
      "Epoch 1958, Loss: 0.0002887906666728668, Final Batch Loss: 0.00017424991528969258\n",
      "Epoch 1959, Loss: 0.00011207697752979584, Final Batch Loss: 8.293262362712994e-05\n",
      "Epoch 1960, Loss: 6.463062027250999e-05, Final Batch Loss: 4.381514827400679e-06\n",
      "Epoch 1961, Loss: 0.0023904211939225206, Final Batch Loss: 1.6778672943473794e-05\n",
      "Epoch 1962, Loss: 6.852399565104861e-05, Final Batch Loss: 3.918502989108674e-05\n",
      "Epoch 1963, Loss: 0.00019361410704732407, Final Batch Loss: 1.1293815987301059e-05\n",
      "Epoch 1964, Loss: 0.0008197299321182072, Final Batch Loss: 0.0001073150779120624\n",
      "Epoch 1965, Loss: 0.00028586048574652523, Final Batch Loss: 0.00012260381481610239\n",
      "Epoch 1966, Loss: 0.0009599986951798201, Final Batch Loss: 0.0005732764257118106\n",
      "Epoch 1967, Loss: 0.0003185599471180467, Final Batch Loss: 0.0002997946576215327\n",
      "Epoch 1968, Loss: 0.0002966715401271358, Final Batch Loss: 9.850728383753449e-05\n",
      "Epoch 1969, Loss: 0.0002854226986528374, Final Batch Loss: 0.00025359008577652276\n",
      "Epoch 1970, Loss: 0.00010860599650186487, Final Batch Loss: 3.386142270755954e-05\n",
      "Epoch 1971, Loss: 0.001161742449767189, Final Batch Loss: 0.0011279084719717503\n",
      "Epoch 1972, Loss: 0.0002264579088659957, Final Batch Loss: 5.190416413825005e-05\n",
      "Epoch 1973, Loss: 0.0004918485938105732, Final Batch Loss: 0.00046650177682749927\n",
      "Epoch 1974, Loss: 0.00012278634267204325, Final Batch Loss: 4.520999482338084e-06\n",
      "Epoch 1975, Loss: 0.0002251699916087091, Final Batch Loss: 0.0001692037476459518\n",
      "Epoch 1976, Loss: 0.0006118723249528557, Final Batch Loss: 4.8750865971669555e-05\n",
      "Epoch 1977, Loss: 4.9327611122862436e-05, Final Batch Loss: 3.0387553124455735e-05\n",
      "Epoch 1978, Loss: 0.00013578740436059888, Final Batch Loss: 7.922126314952038e-06\n",
      "Epoch 1979, Loss: 5.403117393143475e-05, Final Batch Loss: 2.040659819613211e-05\n",
      "Epoch 1980, Loss: 0.00014990986710472498, Final Batch Loss: 2.0459434381336905e-05\n",
      "Epoch 1981, Loss: 0.00012905075800517807, Final Batch Loss: 1.1863486179208849e-05\n",
      "Epoch 1982, Loss: 0.005471909898915328, Final Batch Loss: 0.0053668855689466\n",
      "Epoch 1983, Loss: 4.1354518543812446e-05, Final Batch Loss: 1.2240161595400423e-05\n",
      "Epoch 1984, Loss: 0.00020856493119936204, Final Batch Loss: 9.69292796071386e-06\n",
      "Epoch 1985, Loss: 0.0005595962575171143, Final Batch Loss: 0.00014692710828967392\n",
      "Epoch 1986, Loss: 0.0003262756326876115, Final Batch Loss: 0.0002961814752779901\n",
      "Epoch 1987, Loss: 0.0005044932513555977, Final Batch Loss: 4.6997363824630156e-05\n",
      "Epoch 1988, Loss: 0.00016084144863270922, Final Batch Loss: 1.3971703992865514e-05\n",
      "Epoch 1989, Loss: 0.0004813133473362541, Final Batch Loss: 2.7503256205818616e-05\n",
      "Epoch 1990, Loss: 0.00010806126010720618, Final Batch Loss: 2.7145910280523822e-05\n",
      "Epoch 1991, Loss: 0.00037665647687390447, Final Batch Loss: 0.00021753099281340837\n",
      "Epoch 1992, Loss: 0.0015824874049030768, Final Batch Loss: 0.001575202215462923\n",
      "Epoch 1993, Loss: 0.0003264202969148755, Final Batch Loss: 0.00013872611452825367\n",
      "Epoch 1994, Loss: 0.00012074509231752018, Final Batch Loss: 1.1000615813827608e-05\n",
      "Epoch 1995, Loss: 5.366637651604833e-05, Final Batch Loss: 1.3033743925916497e-05\n",
      "Epoch 1996, Loss: 7.705644748057239e-05, Final Batch Loss: 1.6169873561011627e-05\n",
      "Epoch 1997, Loss: 1.8810736037266906e-05, Final Batch Loss: 1.4005273442307953e-05\n",
      "Epoch 1998, Loss: 0.0001016172445815755, Final Batch Loss: 7.453780563082546e-05\n",
      "Epoch 1999, Loss: 0.0007657786482013762, Final Batch Loss: 0.0003752020711544901\n",
      "Epoch 2000, Loss: 5.770038114860654e-05, Final Batch Loss: 2.2712254576617852e-05\n",
      "Epoch 2001, Loss: 0.00011495463547817053, Final Batch Loss: 1.1485593631732627e-06\n",
      "Epoch 2002, Loss: 6.232308987819124e-05, Final Batch Loss: 4.106338383280672e-05\n",
      "Epoch 2003, Loss: 7.88037505117245e-05, Final Batch Loss: 6.564967043232173e-05\n",
      "Epoch 2004, Loss: 0.00011001276106981095, Final Batch Loss: 2.9421191356959753e-05\n",
      "Epoch 2005, Loss: 0.000252655638178112, Final Batch Loss: 0.00020034225599374622\n",
      "Epoch 2006, Loss: 0.0005662058138113935, Final Batch Loss: 3.129370816168375e-05\n",
      "Epoch 2007, Loss: 9.826851783145685e-05, Final Batch Loss: 7.336496491916478e-05\n",
      "Epoch 2008, Loss: 0.00038882141234353185, Final Batch Loss: 9.152747225016356e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2009, Loss: 0.028229387899045832, Final Batch Loss: 0.02812252938747406\n",
      "Epoch 2010, Loss: 4.3727380216296297e-05, Final Batch Loss: 3.88281223422382e-05\n",
      "Epoch 2011, Loss: 0.0010166986612603068, Final Batch Loss: 9.090779349207878e-05\n",
      "Epoch 2012, Loss: 0.0007781318490742706, Final Batch Loss: 0.00010260604176437482\n",
      "Epoch 2013, Loss: 9.175199375022203e-05, Final Batch Loss: 4.099070429219864e-05\n",
      "Epoch 2014, Loss: 0.0004020141059299931, Final Batch Loss: 0.00034080096520483494\n",
      "Epoch 2015, Loss: 0.0005132506630616263, Final Batch Loss: 4.65040939161554e-05\n",
      "Epoch 2016, Loss: 0.0003786097659030929, Final Batch Loss: 0.00014263062621466815\n",
      "Epoch 2017, Loss: 0.03958322734251851, Final Batch Loss: 0.03953881189227104\n",
      "Epoch 2018, Loss: 0.0004297928317100741, Final Batch Loss: 8.204283221857622e-05\n",
      "Epoch 2019, Loss: 0.00020378026238176972, Final Batch Loss: 0.00010603156988509\n",
      "Epoch 2020, Loss: 5.579712524195202e-05, Final Batch Loss: 2.0973177015548572e-05\n",
      "Epoch 2021, Loss: 6.141454105090816e-05, Final Batch Loss: 3.93352638639044e-06\n",
      "Epoch 2022, Loss: 0.00039328555430984125, Final Batch Loss: 7.46660734876059e-05\n",
      "Epoch 2023, Loss: 0.0005510000337380916, Final Batch Loss: 0.0004143180849496275\n",
      "Epoch 2024, Loss: 0.00012601634261955041, Final Batch Loss: 7.822383849998005e-06\n",
      "Epoch 2025, Loss: 0.00013874372234568, Final Batch Loss: 0.00010059489432023838\n",
      "Epoch 2026, Loss: 2.153324442133453e-05, Final Batch Loss: 1.6488689880134189e-06\n",
      "Epoch 2027, Loss: 4.17030705648358e-05, Final Batch Loss: 2.714696165639907e-05\n",
      "Epoch 2028, Loss: 7.438563261530362e-05, Final Batch Loss: 3.244780236855149e-05\n",
      "Epoch 2029, Loss: 0.00019337770208949223, Final Batch Loss: 4.2600535380188376e-05\n",
      "Epoch 2030, Loss: 0.0001243678120772529, Final Batch Loss: 7.232992629724322e-06\n",
      "Epoch 2031, Loss: 0.03270572474139044, Final Batch Loss: 3.3330674341414124e-05\n",
      "Epoch 2032, Loss: 6.278010368987452e-05, Final Batch Loss: 2.4344099074369296e-06\n",
      "Epoch 2033, Loss: 0.00030572849209420383, Final Batch Loss: 0.0001950727018993348\n",
      "Epoch 2034, Loss: 0.0002667884764377959, Final Batch Loss: 3.8909442082513124e-05\n",
      "Epoch 2035, Loss: 0.0003989685355918482, Final Batch Loss: 0.0003003807214554399\n",
      "Epoch 2036, Loss: 0.0012642638030229136, Final Batch Loss: 0.00010115797340404242\n",
      "Epoch 2037, Loss: 0.0002548866414144868, Final Batch Loss: 1.21444263641024e-05\n",
      "Epoch 2038, Loss: 0.00018457716214470565, Final Batch Loss: 0.00014215234841685742\n",
      "Epoch 2039, Loss: 6.39737440906174e-05, Final Batch Loss: 6.191015563672408e-05\n",
      "Epoch 2040, Loss: 0.00029201833785919007, Final Batch Loss: 0.0002693654678296298\n",
      "Epoch 2041, Loss: 4.318987703300081e-05, Final Batch Loss: 2.222950934083201e-05\n",
      "Epoch 2042, Loss: 0.00038886778929736465, Final Batch Loss: 0.0002509158512111753\n",
      "Epoch 2043, Loss: 0.00010842997380677843, Final Batch Loss: 1.0930621101579163e-05\n",
      "Epoch 2044, Loss: 1.1747468875000777e-05, Final Batch Loss: 1.802829160624242e-06\n",
      "Epoch 2045, Loss: 6.691588896501344e-05, Final Batch Loss: 4.484008240979165e-05\n",
      "Epoch 2046, Loss: 0.00423850177321583, Final Batch Loss: 0.003779768478125334\n",
      "Epoch 2047, Loss: 0.01319469312147703, Final Batch Loss: 0.013177056796848774\n",
      "Epoch 2048, Loss: 0.0029963437700644135, Final Batch Loss: 0.0005014558555558324\n",
      "Epoch 2049, Loss: 0.00029269455262692645, Final Batch Loss: 0.00017996113456320018\n",
      "Epoch 2050, Loss: 0.0001341720635537058, Final Batch Loss: 2.756709000095725e-05\n",
      "Epoch 2051, Loss: 0.019661325652123196, Final Batch Loss: 1.952393722604029e-05\n",
      "Epoch 2052, Loss: 0.0033644617069512606, Final Batch Loss: 0.0002665815409272909\n",
      "Epoch 2053, Loss: 0.0002657755321706645, Final Batch Loss: 1.588861778145656e-05\n",
      "Epoch 2054, Loss: 0.00015181336129899137, Final Batch Loss: 3.707612268044613e-05\n",
      "Epoch 2055, Loss: 0.00015349147702181654, Final Batch Loss: 3.021021029780968e-06\n",
      "Epoch 2056, Loss: 0.0001659893459873274, Final Batch Loss: 4.5615721319336444e-05\n",
      "Epoch 2057, Loss: 5.999248242005706e-05, Final Batch Loss: 3.5831537388730794e-05\n",
      "Epoch 2058, Loss: 0.0002379182551521808, Final Batch Loss: 0.00017601418949197978\n",
      "Epoch 2059, Loss: 0.00027358740408089943, Final Batch Loss: 0.0002261759655084461\n",
      "Epoch 2060, Loss: 8.653371332911775e-05, Final Batch Loss: 6.14332384429872e-05\n",
      "Epoch 2061, Loss: 0.0006481222262664232, Final Batch Loss: 0.0006017987034283578\n",
      "Epoch 2062, Loss: 0.0001215794327436015, Final Batch Loss: 8.118966070469469e-05\n",
      "Epoch 2063, Loss: 0.0002758687478490174, Final Batch Loss: 7.729153730906546e-05\n",
      "Epoch 2064, Loss: 0.0006337135855574161, Final Batch Loss: 0.0004383779305499047\n",
      "Epoch 2065, Loss: 0.0002361110527999699, Final Batch Loss: 0.0001122141839005053\n",
      "Epoch 2066, Loss: 0.00031466077780351043, Final Batch Loss: 0.00018074743275064975\n",
      "Epoch 2067, Loss: 0.0005492209384101443, Final Batch Loss: 0.0005175117403268814\n",
      "Epoch 2068, Loss: 0.0005071356863481924, Final Batch Loss: 0.00029466740670613945\n",
      "Epoch 2069, Loss: 0.0030645050792372786, Final Batch Loss: 8.41284854686819e-05\n",
      "Epoch 2070, Loss: 0.0001833502683439292, Final Batch Loss: 7.591288886032999e-05\n",
      "Epoch 2071, Loss: 0.0001898407281260006, Final Batch Loss: 0.00014703204215038568\n",
      "Epoch 2072, Loss: 0.00034490355756133795, Final Batch Loss: 0.0001358491717837751\n",
      "Epoch 2073, Loss: 0.0014844671241007745, Final Batch Loss: 0.0006367384921759367\n",
      "Epoch 2074, Loss: 0.0012412271171342582, Final Batch Loss: 0.0010666379239410162\n",
      "Epoch 2075, Loss: 0.0005131856742082164, Final Batch Loss: 0.00022943296062294394\n",
      "Epoch 2076, Loss: 0.00048782244994072244, Final Batch Loss: 0.0004029878182336688\n",
      "Epoch 2077, Loss: 0.00022051334053685423, Final Batch Loss: 1.716640508675482e-05\n",
      "Epoch 2078, Loss: 0.0001750202873154194, Final Batch Loss: 1.327202426182339e-05\n",
      "Epoch 2079, Loss: 0.0005032687968196115, Final Batch Loss: 2.3305246941163205e-05\n",
      "Epoch 2080, Loss: 0.011640313467069063, Final Batch Loss: 3.3602504117880017e-05\n",
      "Epoch 2081, Loss: 0.00020395981846377254, Final Batch Loss: 8.171869558282197e-05\n",
      "Epoch 2082, Loss: 0.002187015488743782, Final Batch Loss: 0.002077906159684062\n",
      "Epoch 2083, Loss: 0.0002076068558380939, Final Batch Loss: 0.00011484206333989277\n",
      "Epoch 2084, Loss: 0.000267942450591363, Final Batch Loss: 0.00014195112453307956\n",
      "Epoch 2085, Loss: 0.004400408448418602, Final Batch Loss: 0.00025849472149275243\n",
      "Epoch 2086, Loss: 0.0008074550423771143, Final Batch Loss: 0.0001894736778922379\n",
      "Epoch 2087, Loss: 0.00016384108675993048, Final Batch Loss: 0.00013440268230624497\n",
      "Epoch 2088, Loss: 0.008107141242362559, Final Batch Loss: 0.006847987417131662\n",
      "Epoch 2089, Loss: 0.00036863464629277587, Final Batch Loss: 8.16700339782983e-05\n",
      "Epoch 2090, Loss: 0.0004273157537681982, Final Batch Loss: 0.00014029322483111173\n",
      "Epoch 2091, Loss: 8.489036190439947e-05, Final Batch Loss: 4.651162089430727e-05\n",
      "Epoch 2092, Loss: 0.0013915826712036505, Final Batch Loss: 6.332366319838911e-05\n",
      "Epoch 2093, Loss: 3.874939193337923e-05, Final Batch Loss: 1.2866977158410009e-05\n",
      "Epoch 2094, Loss: 0.0005164630274521187, Final Batch Loss: 0.00036261609056964517\n",
      "Epoch 2095, Loss: 0.0004404577011882793, Final Batch Loss: 5.943727956037037e-05\n",
      "Epoch 2096, Loss: 0.001163308166724164, Final Batch Loss: 0.0010513650486245751\n",
      "Epoch 2097, Loss: 4.082305167685263e-05, Final Batch Loss: 1.314303335675504e-05\n",
      "Epoch 2098, Loss: 0.0006313439585028391, Final Batch Loss: 4.275621449778555e-06\n",
      "Epoch 2099, Loss: 0.0001364901509077754, Final Batch Loss: 8.389110735151917e-05\n",
      "Epoch 2100, Loss: 0.0008735888259252533, Final Batch Loss: 0.0006882985471747816\n",
      "Epoch 2101, Loss: 6.532430415973067e-05, Final Batch Loss: 3.0859126127325e-05\n",
      "Epoch 2102, Loss: 0.00023601565408171155, Final Batch Loss: 0.0002107880136463791\n",
      "Epoch 2103, Loss: 0.00026685185912356246, Final Batch Loss: 2.710637818381656e-05\n",
      "Epoch 2104, Loss: 0.0004122426325920969, Final Batch Loss: 0.0003189395065419376\n",
      "Epoch 2105, Loss: 0.00434787837730255, Final Batch Loss: 0.004236394539475441\n",
      "Epoch 2106, Loss: 0.0005487981397891417, Final Batch Loss: 0.00015050875663291663\n",
      "Epoch 2107, Loss: 0.00015381051343865693, Final Batch Loss: 5.5290336604230106e-05\n",
      "Epoch 2108, Loss: 0.00014387590999831446, Final Batch Loss: 3.6439148971112445e-05\n",
      "Epoch 2109, Loss: 0.00021924674001638778, Final Batch Loss: 4.025765883852728e-05\n",
      "Epoch 2110, Loss: 4.4005879999531317e-05, Final Batch Loss: 1.0746159659902332e-06\n",
      "Epoch 2111, Loss: 0.0004658682473746012, Final Batch Loss: 1.155160407506628e-05\n",
      "Epoch 2112, Loss: 0.0008163412458088715, Final Batch Loss: 0.0007799227605573833\n",
      "Epoch 2113, Loss: 0.00026508198061492294, Final Batch Loss: 6.774440407752991e-05\n",
      "Epoch 2114, Loss: 3.688422111736145e-05, Final Batch Loss: 1.7985237718676217e-05\n",
      "Epoch 2115, Loss: 0.002825846466294024, Final Batch Loss: 6.114764983067289e-05\n",
      "Epoch 2116, Loss: 0.0003759347164304927, Final Batch Loss: 0.00014614028623327613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2117, Loss: 0.0012182020145701244, Final Batch Loss: 0.0011714741121977568\n",
      "Epoch 2118, Loss: 0.00020476380268519279, Final Batch Loss: 1.7126474631368183e-05\n",
      "Epoch 2119, Loss: 0.0010641362096066587, Final Batch Loss: 6.093299452913925e-05\n",
      "Epoch 2120, Loss: 0.00021358056255849078, Final Batch Loss: 0.00015469947538804263\n",
      "Epoch 2121, Loss: 4.0434772017761134e-05, Final Batch Loss: 1.1036068826797418e-05\n",
      "Epoch 2122, Loss: 0.0014732059426023625, Final Batch Loss: 0.0014240385498851538\n",
      "Epoch 2123, Loss: 0.0009468650969211012, Final Batch Loss: 0.0007803441840223968\n",
      "Epoch 2124, Loss: 0.0009606774910935201, Final Batch Loss: 0.0008552023209631443\n",
      "Epoch 2125, Loss: 0.00012019643145322334, Final Batch Loss: 9.019573553814553e-06\n",
      "Epoch 2126, Loss: 4.379918664199067e-05, Final Batch Loss: 3.388259210623801e-05\n",
      "Epoch 2127, Loss: 9.285709529649466e-05, Final Batch Loss: 3.848251435556449e-05\n",
      "Epoch 2128, Loss: 0.00012085618254786823, Final Batch Loss: 9.798724204301834e-05\n",
      "Epoch 2129, Loss: 0.00012921045345137827, Final Batch Loss: 1.761447128956206e-05\n",
      "Epoch 2130, Loss: 0.0002211744686064776, Final Batch Loss: 0.00018563683261163533\n",
      "Epoch 2131, Loss: 0.0007921160431578755, Final Batch Loss: 0.0007226595771498978\n",
      "Epoch 2132, Loss: 5.7837260101223364e-05, Final Batch Loss: 2.7382318876334466e-05\n",
      "Epoch 2133, Loss: 0.00015796998559380881, Final Batch Loss: 0.00011723344505298883\n",
      "Epoch 2134, Loss: 0.00015100899508979637, Final Batch Loss: 1.6257270544883795e-05\n",
      "Epoch 2135, Loss: 0.005307507854013238, Final Batch Loss: 1.0843075870070606e-05\n",
      "Epoch 2136, Loss: 0.00031314701118390076, Final Batch Loss: 0.00027258816407993436\n",
      "Epoch 2137, Loss: 0.00011972362699452788, Final Batch Loss: 6.594029400730506e-05\n",
      "Epoch 2138, Loss: 0.00020020067313453183, Final Batch Loss: 0.0001097133063012734\n",
      "Epoch 2139, Loss: 4.181621716270456e-05, Final Batch Loss: 2.8164253308204934e-05\n",
      "Epoch 2140, Loss: 5.11847183588543e-05, Final Batch Loss: 1.3592853974842e-05\n",
      "Epoch 2141, Loss: 0.0008915685175452381, Final Batch Loss: 0.0006287031574174762\n",
      "Epoch 2142, Loss: 0.0003720815439010039, Final Batch Loss: 0.00012855966633651406\n",
      "Epoch 2143, Loss: 0.00014386555449164007, Final Batch Loss: 1.7231324818567373e-05\n",
      "Epoch 2144, Loss: 0.00023611404321854934, Final Batch Loss: 0.0001248268090421334\n",
      "Epoch 2145, Loss: 0.0001691782963462174, Final Batch Loss: 4.92118633701466e-05\n",
      "Epoch 2146, Loss: 0.0002472243140800856, Final Batch Loss: 3.685645788209513e-05\n",
      "Epoch 2147, Loss: 0.0018791109396261163, Final Batch Loss: 6.144936924101785e-05\n",
      "Epoch 2148, Loss: 0.001697298328508623, Final Batch Loss: 0.0016214540228247643\n",
      "Epoch 2149, Loss: 0.00010395100343885133, Final Batch Loss: 9.043335739988834e-05\n",
      "Epoch 2150, Loss: 0.00277402160645579, Final Batch Loss: 4.0452014218317345e-05\n",
      "Epoch 2151, Loss: 7.438369175361004e-05, Final Batch Loss: 1.916728615469765e-05\n",
      "Epoch 2152, Loss: 0.0003876817791024223, Final Batch Loss: 0.00030648161191493273\n",
      "Epoch 2153, Loss: 0.0004397979355417192, Final Batch Loss: 0.00021546697826124728\n",
      "Epoch 2154, Loss: 0.00023170412532635964, Final Batch Loss: 0.00017131974163930863\n",
      "Epoch 2155, Loss: 0.00015289782459149137, Final Batch Loss: 0.0001366526266792789\n",
      "Epoch 2156, Loss: 8.825059194350615e-05, Final Batch Loss: 4.1118168155662715e-05\n",
      "Epoch 2157, Loss: 0.001120330358389765, Final Batch Loss: 0.0002635775017552078\n",
      "Epoch 2158, Loss: 0.00013522883818950504, Final Batch Loss: 8.915632497519255e-05\n",
      "Epoch 2159, Loss: 0.00011901565449079499, Final Batch Loss: 2.1237152395769954e-05\n",
      "Epoch 2160, Loss: 8.257876288553234e-05, Final Batch Loss: 2.352798946958501e-05\n",
      "Epoch 2161, Loss: 0.00035297237627673894, Final Batch Loss: 0.0002677836164366454\n",
      "Epoch 2162, Loss: 0.00020637913985410705, Final Batch Loss: 0.0001376308937324211\n",
      "Epoch 2163, Loss: 0.0004200253442832036, Final Batch Loss: 2.9068525691400282e-05\n",
      "Epoch 2164, Loss: 0.00063354035228258, Final Batch Loss: 0.000567982264328748\n",
      "Epoch 2165, Loss: 0.00020140394917689264, Final Batch Loss: 5.0720758736133575e-05\n",
      "Epoch 2166, Loss: 0.00048293294821633026, Final Batch Loss: 5.181290180189535e-05\n",
      "Epoch 2167, Loss: 0.0001825766303227283, Final Batch Loss: 1.8389015167485923e-05\n",
      "Epoch 2168, Loss: 9.165459141513566e-05, Final Batch Loss: 1.1671386346279178e-05\n",
      "Epoch 2169, Loss: 0.00011488309792184737, Final Batch Loss: 7.735206963843666e-06\n",
      "Epoch 2170, Loss: 0.00013315411888470408, Final Batch Loss: 1.397330743202474e-05\n",
      "Epoch 2171, Loss: 0.00024541256061638705, Final Batch Loss: 0.00019086309475824237\n",
      "Epoch 2172, Loss: 0.00019463869830360636, Final Batch Loss: 0.0001408079988323152\n",
      "Epoch 2173, Loss: 0.0001380847406835528, Final Batch Loss: 0.00011317074677208439\n",
      "Epoch 2174, Loss: 2.510800004529301e-05, Final Batch Loss: 7.598457159474492e-06\n",
      "Epoch 2175, Loss: 0.00040732773049967363, Final Batch Loss: 0.0003416623512748629\n",
      "Epoch 2176, Loss: 0.00011382789125491399, Final Batch Loss: 1.6827945728437044e-05\n",
      "Epoch 2177, Loss: 0.00018965124763781205, Final Batch Loss: 0.00010634492355166003\n",
      "Epoch 2178, Loss: 0.00011062623161706142, Final Batch Loss: 9.276519995182753e-05\n",
      "Epoch 2179, Loss: 3.415130140638212e-05, Final Batch Loss: 2.2814521798864007e-05\n",
      "Epoch 2180, Loss: 0.0002914923206844833, Final Batch Loss: 3.289579399279319e-05\n",
      "Epoch 2181, Loss: 7.368603110080585e-05, Final Batch Loss: 5.451383185572922e-05\n",
      "Epoch 2182, Loss: 6.272506652749144e-05, Final Batch Loss: 4.270069257472642e-05\n",
      "Epoch 2183, Loss: 0.0002246630369882041, Final Batch Loss: 4.740233180200448e-06\n",
      "Epoch 2184, Loss: 0.0005460032007249538, Final Batch Loss: 0.0005078936810605228\n",
      "Epoch 2185, Loss: 3.080516398767941e-05, Final Batch Loss: 1.292488377657719e-05\n",
      "Epoch 2186, Loss: 4.904506931779906e-05, Final Batch Loss: 2.732048960751854e-05\n",
      "Epoch 2187, Loss: 9.429860074305907e-05, Final Batch Loss: 4.796111534233205e-05\n",
      "Epoch 2188, Loss: 0.00011010448361048475, Final Batch Loss: 5.488475289894268e-05\n",
      "Epoch 2189, Loss: 0.001525948420749046, Final Batch Loss: 0.001469011534936726\n",
      "Epoch 2190, Loss: 0.00036598621954908594, Final Batch Loss: 4.097978671779856e-05\n",
      "Epoch 2191, Loss: 5.4002766773919575e-05, Final Batch Loss: 3.2433024898637086e-05\n",
      "Epoch 2192, Loss: 0.00012148712994530797, Final Batch Loss: 7.342523895204067e-05\n",
      "Epoch 2193, Loss: 0.00012024262969134725, Final Batch Loss: 4.86213093608967e-06\n",
      "Epoch 2194, Loss: 0.00012119912207708694, Final Batch Loss: 3.2757609005784616e-05\n",
      "Epoch 2195, Loss: 0.0001499388636148069, Final Batch Loss: 4.787648867932148e-05\n",
      "Epoch 2196, Loss: 5.2637617955042515e-05, Final Batch Loss: 1.300566964346217e-05\n",
      "Epoch 2197, Loss: 6.668662990705343e-06, Final Batch Loss: 4.0709878703637514e-06\n",
      "Epoch 2198, Loss: 0.0002246656149509363, Final Batch Loss: 7.291774818440899e-05\n",
      "Epoch 2199, Loss: 4.3621621443890035e-05, Final Batch Loss: 3.621034920797683e-05\n",
      "Epoch 2200, Loss: 0.0005992109981889371, Final Batch Loss: 0.0005440160166472197\n",
      "Epoch 2201, Loss: 0.00023469100779038854, Final Batch Loss: 3.3870823244797066e-05\n",
      "Epoch 2202, Loss: 0.0003954485146095976, Final Batch Loss: 0.00017932822811417282\n",
      "Epoch 2203, Loss: 0.00010376693535363302, Final Batch Loss: 5.1122271543135867e-05\n",
      "Epoch 2204, Loss: 0.0001413406789652072, Final Batch Loss: 5.081437120679766e-05\n",
      "Epoch 2205, Loss: 9.460732508159708e-05, Final Batch Loss: 2.8300955818849616e-05\n",
      "Epoch 2206, Loss: 0.0009251393130398355, Final Batch Loss: 3.363357245689258e-05\n",
      "Epoch 2207, Loss: 3.686799664137652e-05, Final Batch Loss: 2.4573046175646596e-05\n",
      "Epoch 2208, Loss: 0.00023570231496705674, Final Batch Loss: 5.5191729188663885e-05\n",
      "Epoch 2209, Loss: 2.8299119549046736e-05, Final Batch Loss: 7.564461157016922e-06\n",
      "Epoch 2210, Loss: 0.00010451421076140832, Final Batch Loss: 7.862373604439199e-05\n",
      "Epoch 2211, Loss: 0.0010078540653921664, Final Batch Loss: 0.00016553880413994193\n",
      "Epoch 2212, Loss: 0.0005762488581240177, Final Batch Loss: 0.00030183669878169894\n",
      "Epoch 2213, Loss: 8.194295332941692e-05, Final Batch Loss: 2.8088305043638684e-05\n",
      "Epoch 2214, Loss: 0.00032959957752609625, Final Batch Loss: 3.24810462188907e-05\n",
      "Epoch 2215, Loss: 0.0002057132005575113, Final Batch Loss: 7.186814764281735e-05\n",
      "Epoch 2216, Loss: 3.9610700696357526e-05, Final Batch Loss: 1.946342490555253e-05\n",
      "Epoch 2217, Loss: 7.315328730328474e-05, Final Batch Loss: 5.0655511586228386e-05\n",
      "Epoch 2218, Loss: 7.230568371596746e-05, Final Batch Loss: 2.8817557904403657e-05\n",
      "Epoch 2219, Loss: 0.0001123930901485437, Final Batch Loss: 6.605490398214897e-06\n",
      "Epoch 2220, Loss: 0.0001389829831168754, Final Batch Loss: 4.3672607716871426e-06\n",
      "Epoch 2221, Loss: 0.00029097618971718475, Final Batch Loss: 0.00011943204299313948\n",
      "Epoch 2222, Loss: 9.47361950238701e-05, Final Batch Loss: 1.4198860299075022e-05\n",
      "Epoch 2223, Loss: 9.134293031820562e-05, Final Batch Loss: 8.583877934142947e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2224, Loss: 0.00011935036309296265, Final Batch Loss: 8.75051409821026e-05\n",
      "Epoch 2225, Loss: 0.0005148844866198488, Final Batch Loss: 0.0004981749807484448\n",
      "Epoch 2226, Loss: 0.0006777275939384708, Final Batch Loss: 2.4476577891618945e-05\n",
      "Epoch 2227, Loss: 3.505060522002168e-05, Final Batch Loss: 9.988672900362872e-06\n",
      "Epoch 2228, Loss: 9.240300641977228e-05, Final Batch Loss: 6.124664650997147e-06\n",
      "Epoch 2229, Loss: 0.00011412062485760543, Final Batch Loss: 9.703463001642376e-05\n",
      "Epoch 2230, Loss: 0.0003228538407711312, Final Batch Loss: 0.00018087179341819137\n",
      "Epoch 2231, Loss: 3.307844508526614e-05, Final Batch Loss: 9.588819921191316e-06\n",
      "Epoch 2232, Loss: 0.00032436107358080335, Final Batch Loss: 0.0002703735081013292\n",
      "Epoch 2233, Loss: 0.0013985408295411617, Final Batch Loss: 0.00021527826902456582\n",
      "Epoch 2234, Loss: 0.0016019945612697484, Final Batch Loss: 2.953631110358401e-06\n",
      "Epoch 2235, Loss: 8.706539756531129e-05, Final Batch Loss: 1.3750091056863312e-05\n",
      "Epoch 2236, Loss: 0.0002049533650279045, Final Batch Loss: 7.941736839711666e-06\n",
      "Epoch 2237, Loss: 5.686026270268485e-05, Final Batch Loss: 2.707262319745496e-05\n",
      "Epoch 2238, Loss: 0.00022161843480716925, Final Batch Loss: 2.4176069928216748e-05\n",
      "Epoch 2239, Loss: 5.815842450829223e-05, Final Batch Loss: 1.1865642591146752e-05\n",
      "Epoch 2240, Loss: 0.0005689739159606688, Final Batch Loss: 4.407160759001272e-06\n",
      "Epoch 2241, Loss: 0.00012993946074857377, Final Batch Loss: 2.1352712792577222e-05\n",
      "Epoch 2242, Loss: 0.0004443091165740043, Final Batch Loss: 5.208954098634422e-05\n",
      "Epoch 2243, Loss: 0.00024552844843128696, Final Batch Loss: 7.674877269892022e-05\n",
      "Epoch 2244, Loss: 0.00023370271492240136, Final Batch Loss: 4.368401732790517e-06\n",
      "Epoch 2245, Loss: 1.7453857253713068e-05, Final Batch Loss: 9.174518709187396e-06\n",
      "Epoch 2246, Loss: 0.0001219587902596686, Final Batch Loss: 7.988290599314496e-05\n",
      "Epoch 2247, Loss: 0.0001255304814549163, Final Batch Loss: 9.635859169065952e-05\n",
      "Epoch 2248, Loss: 0.00019296186655992642, Final Batch Loss: 0.00018355422071181238\n",
      "Epoch 2249, Loss: 0.0024463475856464356, Final Batch Loss: 0.0024302012752741575\n",
      "Epoch 2250, Loss: 3.894063502229983e-05, Final Batch Loss: 1.0920711247308645e-05\n",
      "Epoch 2251, Loss: 5.8672962040873244e-05, Final Batch Loss: 3.638947237050161e-05\n",
      "Epoch 2252, Loss: 0.00010128072904080909, Final Batch Loss: 3.689277264129487e-06\n",
      "Epoch 2253, Loss: 0.00010628794188960455, Final Batch Loss: 1.4563247532350942e-05\n",
      "Epoch 2254, Loss: 0.00012158345634816214, Final Batch Loss: 1.580431853653863e-05\n",
      "Epoch 2255, Loss: 0.012237935501616448, Final Batch Loss: 0.01163273025304079\n",
      "Epoch 2256, Loss: 0.00010200356837231084, Final Batch Loss: 9.712386236060411e-05\n",
      "Epoch 2257, Loss: 0.00059288179181749, Final Batch Loss: 0.0004957044729962945\n",
      "Epoch 2258, Loss: 0.00018112736142938957, Final Batch Loss: 0.0001340768940281123\n",
      "Epoch 2259, Loss: 7.86144555604551e-05, Final Batch Loss: 1.7915179341798648e-05\n",
      "Epoch 2260, Loss: 0.0002843098973244196, Final Batch Loss: 4.285937393433414e-06\n",
      "Epoch 2261, Loss: 3.935355562134646e-05, Final Batch Loss: 1.8996059225173667e-05\n",
      "Epoch 2262, Loss: 2.4315249447681708e-05, Final Batch Loss: 7.058011306071421e-06\n",
      "Epoch 2263, Loss: 7.340915180975571e-05, Final Batch Loss: 1.9100021745543927e-05\n",
      "Epoch 2264, Loss: 4.1695861909829546e-05, Final Batch Loss: 3.419527274672873e-05\n",
      "Epoch 2265, Loss: 2.7009378754883073e-05, Final Batch Loss: 1.0434603609610349e-05\n",
      "Epoch 2266, Loss: 1.781774744813447e-05, Final Batch Loss: 1.1359635209373664e-05\n",
      "Epoch 2267, Loss: 7.897182331362274e-05, Final Batch Loss: 1.9541201254469343e-05\n",
      "Epoch 2268, Loss: 0.00016698007675586268, Final Batch Loss: 0.00013651838526129723\n",
      "Epoch 2269, Loss: 0.005305101436533732, Final Batch Loss: 0.005258361343294382\n",
      "Epoch 2270, Loss: 0.0007613591296831146, Final Batch Loss: 0.0006235619075596333\n",
      "Epoch 2271, Loss: 0.0002566635885159485, Final Batch Loss: 0.00016572998720221221\n",
      "Epoch 2272, Loss: 0.00027200452927900187, Final Batch Loss: 4.968449047737522e-07\n",
      "Epoch 2273, Loss: 0.00015899038771749474, Final Batch Loss: 0.0001017047034110874\n",
      "Epoch 2274, Loss: 0.00043341718810552265, Final Batch Loss: 0.0004230707127135247\n",
      "Epoch 2275, Loss: 0.0006651395597145893, Final Batch Loss: 1.797141885617748e-05\n",
      "Epoch 2276, Loss: 7.08342431607889e-05, Final Batch Loss: 2.16460812225705e-05\n",
      "Epoch 2277, Loss: 8.189060963559314e-06, Final Batch Loss: 2.354456000830396e-06\n",
      "Epoch 2278, Loss: 8.726575742912246e-06, Final Batch Loss: 6.432117970689433e-06\n",
      "Epoch 2279, Loss: 5.597468316409504e-05, Final Batch Loss: 4.596731378114782e-05\n",
      "Epoch 2280, Loss: 0.00023995690480660414, Final Batch Loss: 1.0402683074062224e-05\n",
      "Epoch 2281, Loss: 4.732683373731561e-05, Final Batch Loss: 1.8031492800218984e-05\n",
      "Epoch 2282, Loss: 0.00032071649548015557, Final Batch Loss: 1.3871784176444635e-05\n",
      "Epoch 2283, Loss: 0.00026227403577649966, Final Batch Loss: 0.00018340865790378302\n",
      "Epoch 2284, Loss: 0.0002001691646000836, Final Batch Loss: 0.00018631106649991125\n",
      "Epoch 2285, Loss: 0.0005260232960608846, Final Batch Loss: 0.0005210047820582986\n",
      "Epoch 2286, Loss: 0.0002772484513116069, Final Batch Loss: 0.0002240072499262169\n",
      "Epoch 2287, Loss: 9.770973701961339e-05, Final Batch Loss: 4.0826158510753885e-05\n",
      "Epoch 2288, Loss: 0.0002259601460536942, Final Batch Loss: 8.965675078798085e-05\n",
      "Epoch 2289, Loss: 9.36994438234251e-05, Final Batch Loss: 6.930051313247532e-05\n",
      "Epoch 2290, Loss: 0.0007064061646815389, Final Batch Loss: 0.0006446050247177482\n",
      "Epoch 2291, Loss: 1.835889588619466e-05, Final Batch Loss: 7.125612228264799e-06\n",
      "Epoch 2292, Loss: 0.0006035785772837698, Final Batch Loss: 0.00043608207488432527\n",
      "Epoch 2293, Loss: 0.0002583583267892209, Final Batch Loss: 8.614301236775646e-07\n",
      "Epoch 2294, Loss: 0.00034261515247635543, Final Batch Loss: 9.095872519537807e-05\n",
      "Epoch 2295, Loss: 1.797703134798212e-05, Final Batch Loss: 2.7484347810968757e-06\n",
      "Epoch 2296, Loss: 0.0005402981187216938, Final Batch Loss: 8.98783328011632e-05\n",
      "Epoch 2297, Loss: 5.990003774059005e-05, Final Batch Loss: 1.558549774927087e-05\n",
      "Epoch 2298, Loss: 0.00021412188652902842, Final Batch Loss: 0.00013272668002173305\n",
      "Epoch 2299, Loss: 7.366730278590694e-05, Final Batch Loss: 1.9704308215295896e-05\n",
      "Epoch 2300, Loss: 0.00035990159813081846, Final Batch Loss: 0.0002774763270281255\n",
      "Epoch 2301, Loss: 1.2110197303627501e-05, Final Batch Loss: 8.628997420601081e-06\n",
      "Epoch 2302, Loss: 2.115445568051655e-05, Final Batch Loss: 8.693074960319791e-06\n",
      "Epoch 2303, Loss: 6.37953526165802e-05, Final Batch Loss: 5.320372656569816e-05\n",
      "Epoch 2304, Loss: 9.576787761034211e-06, Final Batch Loss: 4.219966285745613e-06\n",
      "Epoch 2305, Loss: 0.0003332075539219659, Final Batch Loss: 0.00028863392071798444\n",
      "Epoch 2306, Loss: 0.00017802726506488398, Final Batch Loss: 4.296324186725542e-05\n",
      "Epoch 2307, Loss: 6.323170237010345e-05, Final Batch Loss: 1.2306194548727944e-05\n",
      "Epoch 2308, Loss: 0.000669449073029682, Final Batch Loss: 0.0005886251456104219\n",
      "Epoch 2309, Loss: 0.0002542048823670484, Final Batch Loss: 8.620507287560031e-05\n",
      "Epoch 2310, Loss: 2.898964794439962e-05, Final Batch Loss: 9.761643923411611e-06\n",
      "Epoch 2311, Loss: 0.0004174876912657055, Final Batch Loss: 8.008612894627731e-06\n",
      "Epoch 2312, Loss: 5.4775621720182244e-05, Final Batch Loss: 1.3039215446042363e-05\n",
      "Epoch 2313, Loss: 5.280161212795065e-05, Final Batch Loss: 2.0978318389097694e-06\n",
      "Epoch 2314, Loss: 6.802819007134531e-05, Final Batch Loss: 4.211442865198478e-05\n",
      "Epoch 2315, Loss: 0.0002552036203269381, Final Batch Loss: 2.1905467292526737e-05\n",
      "Epoch 2316, Loss: 9.756463077792432e-05, Final Batch Loss: 8.218879520427436e-05\n",
      "Epoch 2317, Loss: 2.506251712475205e-05, Final Batch Loss: 8.371723197342362e-06\n",
      "Epoch 2318, Loss: 0.00026234969300276134, Final Batch Loss: 0.00024239330377895385\n",
      "Epoch 2319, Loss: 0.0003204015902156243, Final Batch Loss: 0.00031257193768396974\n",
      "Epoch 2320, Loss: 2.999610387632856e-05, Final Batch Loss: 1.4762638784304727e-05\n",
      "Epoch 2321, Loss: 0.0007832341361790895, Final Batch Loss: 0.000767338031437248\n",
      "Epoch 2322, Loss: 0.0017289641982642934, Final Batch Loss: 0.0015467030461877584\n",
      "Epoch 2323, Loss: 0.00019170019004377536, Final Batch Loss: 3.2670297514414415e-05\n",
      "Epoch 2324, Loss: 1.338495439995313e-05, Final Batch Loss: 6.443166967073921e-06\n",
      "Epoch 2325, Loss: 5.939957372902427e-05, Final Batch Loss: 8.026743671507575e-06\n",
      "Epoch 2326, Loss: 8.17531836219132e-05, Final Batch Loss: 2.8440950700314716e-05\n",
      "Epoch 2327, Loss: 6.92532566972659e-05, Final Batch Loss: 6.0536101955221966e-05\n",
      "Epoch 2328, Loss: 7.492985469070845e-05, Final Batch Loss: 4.722226094600046e-06\n",
      "Epoch 2329, Loss: 0.0007610508328070864, Final Batch Loss: 0.0006832563667558134\n",
      "Epoch 2330, Loss: 1.2389095672915573e-05, Final Batch Loss: 2.5083816126425518e-06\n",
      "Epoch 2331, Loss: 0.00012514924674178474, Final Batch Loss: 0.00010602761176414788\n",
      "Epoch 2332, Loss: 0.000699608281138353, Final Batch Loss: 0.00023603173031006008\n",
      "Epoch 2333, Loss: 0.00017583508633833844, Final Batch Loss: 1.0183592166868038e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2334, Loss: 0.00022440910856857954, Final Batch Loss: 1.692337036729441e-06\n",
      "Epoch 2335, Loss: 6.744048778273282e-05, Final Batch Loss: 5.872294877917739e-06\n",
      "Epoch 2336, Loss: 1.3635959021485178e-05, Final Batch Loss: 5.742348093917826e-06\n",
      "Epoch 2337, Loss: 0.00018271029694005847, Final Batch Loss: 4.879510379396379e-05\n",
      "Epoch 2338, Loss: 7.913626177469268e-05, Final Batch Loss: 7.408278906950727e-05\n",
      "Epoch 2339, Loss: 0.0002574172758613713, Final Batch Loss: 3.184208617312834e-05\n",
      "Epoch 2340, Loss: 0.00039212660340126604, Final Batch Loss: 0.00013512403529603034\n",
      "Epoch 2341, Loss: 3.36651328325388e-05, Final Batch Loss: 2.040231083810795e-05\n",
      "Epoch 2342, Loss: 0.001281337987165898, Final Batch Loss: 0.001193494419567287\n",
      "Epoch 2343, Loss: 0.00036179812741465867, Final Batch Loss: 0.00029841967625543475\n",
      "Epoch 2344, Loss: 2.658143581868444e-05, Final Batch Loss: 2.184040255315267e-07\n",
      "Epoch 2345, Loss: 4.986347857993678e-05, Final Batch Loss: 4.6984994696686044e-05\n",
      "Epoch 2346, Loss: 4.285967713713035e-05, Final Batch Loss: 4.155757778789848e-05\n",
      "Epoch 2347, Loss: 0.0005006597648389288, Final Batch Loss: 0.0004921923973597586\n",
      "Epoch 2348, Loss: 6.342884898913326e-05, Final Batch Loss: 1.452677770430455e-05\n",
      "Epoch 2349, Loss: 0.00012999244790989906, Final Batch Loss: 8.847732533467934e-05\n",
      "Epoch 2350, Loss: 9.957269958249526e-05, Final Batch Loss: 9.125919314101338e-05\n",
      "Epoch 2351, Loss: 0.02980605538778036, Final Batch Loss: 6.1004220697213896e-06\n",
      "Epoch 2352, Loss: 9.604011938790791e-05, Final Batch Loss: 3.982938142144121e-05\n",
      "Epoch 2353, Loss: 0.00044820063340011984, Final Batch Loss: 0.0003172219730913639\n",
      "Epoch 2354, Loss: 0.0006365347217069939, Final Batch Loss: 0.00014402503438759595\n",
      "Epoch 2355, Loss: 0.0004037139005959034, Final Batch Loss: 1.8293358152732253e-05\n",
      "Epoch 2356, Loss: 0.001651217384278425, Final Batch Loss: 1.7277934603043832e-05\n",
      "Epoch 2357, Loss: 2.2386841919797007e-05, Final Batch Loss: 8.09059292805614e-06\n",
      "Epoch 2358, Loss: 0.0004547307144093793, Final Batch Loss: 1.5299399819923565e-05\n",
      "Epoch 2359, Loss: 3.117939536423364e-05, Final Batch Loss: 3.3192825412697857e-06\n",
      "Epoch 2360, Loss: 0.0008011598401935771, Final Batch Loss: 0.0005730520933866501\n",
      "Epoch 2361, Loss: 5.6341426898143254e-05, Final Batch Loss: 7.712425940553658e-06\n",
      "Epoch 2362, Loss: 0.00041812540439423174, Final Batch Loss: 1.5767247532494366e-05\n",
      "Epoch 2363, Loss: 0.0003617320271587232, Final Batch Loss: 0.00034289146424271166\n",
      "Epoch 2364, Loss: 0.0011389888077246724, Final Batch Loss: 0.0011272215051576495\n",
      "Epoch 2365, Loss: 0.0003356058005010709, Final Batch Loss: 0.0003191497235093266\n",
      "Epoch 2366, Loss: 3.0546298148692586e-05, Final Batch Loss: 1.6226651496253908e-05\n",
      "Epoch 2367, Loss: 0.0002112957590725273, Final Batch Loss: 5.569294444285333e-06\n",
      "Epoch 2368, Loss: 1.8868445295083802e-05, Final Batch Loss: 1.1799416824942455e-05\n",
      "Epoch 2369, Loss: 0.00012890828838862944, Final Batch Loss: 8.979290214483626e-06\n",
      "Epoch 2370, Loss: 5.7342384025105275e-05, Final Batch Loss: 1.278675154026132e-05\n",
      "Epoch 2371, Loss: 0.00014055405699764378, Final Batch Loss: 5.2988831157563254e-05\n",
      "Epoch 2372, Loss: 0.00023920438616187312, Final Batch Loss: 6.867561751278117e-06\n",
      "Epoch 2373, Loss: 5.098043584439438e-05, Final Batch Loss: 2.7220639822189696e-05\n",
      "Epoch 2374, Loss: 0.00018949740479001775, Final Batch Loss: 0.00010345033660996705\n",
      "Epoch 2375, Loss: 5.933047395956237e-05, Final Batch Loss: 1.9238808818045072e-05\n",
      "Epoch 2376, Loss: 2.0355098968138918e-05, Final Batch Loss: 1.1028125300072134e-05\n",
      "Epoch 2377, Loss: 0.0003576569288270548, Final Batch Loss: 0.00011330134293530136\n",
      "Epoch 2378, Loss: 0.0005555272664423683, Final Batch Loss: 1.334816715825582e-05\n",
      "Epoch 2379, Loss: 0.00015763669580337591, Final Batch Loss: 2.5770543288672343e-05\n",
      "Epoch 2380, Loss: 9.380279334436636e-05, Final Batch Loss: 7.44846256566234e-05\n",
      "Epoch 2381, Loss: 0.00034246633367729373, Final Batch Loss: 4.7754921979503706e-05\n",
      "Epoch 2382, Loss: 9.005194806377403e-05, Final Batch Loss: 5.572556619881652e-05\n",
      "Epoch 2383, Loss: 0.0008675852113810834, Final Batch Loss: 0.0008227807120420039\n",
      "Epoch 2384, Loss: 0.00013817531998938648, Final Batch Loss: 9.025442523125093e-06\n",
      "Epoch 2385, Loss: 0.00011863645340781659, Final Batch Loss: 0.00010958608618238941\n",
      "Epoch 2386, Loss: 0.00028022826882079244, Final Batch Loss: 0.00013833731645718217\n",
      "Epoch 2387, Loss: 0.00011539483148226282, Final Batch Loss: 4.791937499248888e-06\n",
      "Epoch 2388, Loss: 0.00028258988822926767, Final Batch Loss: 3.666522752610035e-05\n",
      "Epoch 2389, Loss: 0.00015221906596707413, Final Batch Loss: 1.33912481032894e-05\n",
      "Epoch 2390, Loss: 0.0010337217536289245, Final Batch Loss: 0.0004280256398487836\n",
      "Epoch 2391, Loss: 0.00028000449765386293, Final Batch Loss: 1.0504570127523039e-05\n",
      "Epoch 2392, Loss: 2.28184171646717e-05, Final Batch Loss: 1.4627514246967621e-05\n",
      "Epoch 2393, Loss: 0.0007526460876761121, Final Batch Loss: 1.4750771697435994e-05\n",
      "Epoch 2394, Loss: 6.570930418092757e-05, Final Batch Loss: 3.2330463000107557e-05\n",
      "Epoch 2395, Loss: 0.00021500221191672608, Final Batch Loss: 0.00018102745525538921\n",
      "Epoch 2396, Loss: 0.00042159457007073797, Final Batch Loss: 4.4617427192861214e-05\n",
      "Epoch 2397, Loss: 3.1377582672575954e-05, Final Batch Loss: 2.3129117835196666e-05\n",
      "Epoch 2398, Loss: 1.6664856957504526e-05, Final Batch Loss: 5.66768449061783e-06\n",
      "Epoch 2399, Loss: 0.0007642236162155314, Final Batch Loss: 2.00558883989288e-06\n",
      "Epoch 2400, Loss: 0.0001356692773697432, Final Batch Loss: 5.083385985926725e-05\n",
      "Epoch 2401, Loss: 5.073992429061036e-05, Final Batch Loss: 2.708617785174283e-06\n",
      "Epoch 2402, Loss: 0.0005898242452531122, Final Batch Loss: 0.0005673589184880257\n",
      "Epoch 2403, Loss: 0.0002873571283998899, Final Batch Loss: 0.00020662706810981035\n",
      "Epoch 2404, Loss: 3.749144889297895e-05, Final Batch Loss: 2.24446011998225e-05\n",
      "Epoch 2405, Loss: 0.00012901150330435485, Final Batch Loss: 6.657191988779232e-05\n",
      "Epoch 2406, Loss: 0.0002794698011712171, Final Batch Loss: 0.0002628930378705263\n",
      "Epoch 2407, Loss: 1.9287221221020445e-05, Final Batch Loss: 3.2863972592167556e-06\n",
      "Epoch 2408, Loss: 1.1655764865281526e-05, Final Batch Loss: 4.6279551497718785e-06\n",
      "Epoch 2409, Loss: 0.0001582152362971101, Final Batch Loss: 5.274411887512542e-05\n",
      "Epoch 2410, Loss: 0.0010734360321293934, Final Batch Loss: 0.0010644380236044526\n",
      "Epoch 2411, Loss: 1.91355834431306e-05, Final Batch Loss: 7.387141067738412e-06\n",
      "Epoch 2412, Loss: 7.887615402069059e-05, Final Batch Loss: 5.990885711071314e-06\n",
      "Epoch 2413, Loss: 0.0003335527089802781, Final Batch Loss: 1.1854421245516278e-05\n",
      "Epoch 2414, Loss: 0.00014755506344954483, Final Batch Loss: 0.00013531029981095344\n",
      "Epoch 2415, Loss: 3.846528761641821e-05, Final Batch Loss: 2.9489656299119815e-05\n",
      "Epoch 2416, Loss: 0.0005386688026192132, Final Batch Loss: 0.00048162086750380695\n",
      "Epoch 2417, Loss: 5.8272522437619045e-05, Final Batch Loss: 2.2127580450614914e-05\n",
      "Epoch 2418, Loss: 0.0003316176516818814, Final Batch Loss: 0.00011009796435246244\n",
      "Epoch 2419, Loss: 0.00046131013891681505, Final Batch Loss: 1.0885321444220608e-06\n",
      "Epoch 2420, Loss: 0.000290575684630312, Final Batch Loss: 0.0002242547197965905\n",
      "Epoch 2421, Loss: 0.0007121724775061011, Final Batch Loss: 0.000405189668526873\n",
      "Epoch 2422, Loss: 3.096846603511949e-05, Final Batch Loss: 2.872322147595696e-05\n",
      "Epoch 2423, Loss: 1.3223691212260746e-05, Final Batch Loss: 3.584746309570619e-06\n",
      "Epoch 2424, Loss: 1.2499484910222236e-05, Final Batch Loss: 5.490289822773775e-06\n",
      "Epoch 2425, Loss: 7.81355320214061e-05, Final Batch Loss: 7.047152757877484e-05\n",
      "Epoch 2426, Loss: 3.0736088319827104e-05, Final Batch Loss: 7.391800409095595e-06\n",
      "Epoch 2427, Loss: 0.00017173269270642777, Final Batch Loss: 3.4201189009763766e-06\n",
      "Epoch 2428, Loss: 7.903864297986729e-05, Final Batch Loss: 7.12194450898096e-05\n",
      "Epoch 2429, Loss: 0.00017472658146289177, Final Batch Loss: 0.00012823457655031234\n",
      "Epoch 2430, Loss: 4.348878064774908e-05, Final Batch Loss: 1.536893796583172e-05\n",
      "Epoch 2431, Loss: 0.0001429102239853819, Final Batch Loss: 3.165402631566394e-06\n",
      "Epoch 2432, Loss: 0.00012161458653281443, Final Batch Loss: 7.737660052953288e-05\n",
      "Epoch 2433, Loss: 8.64393273332098e-05, Final Batch Loss: 6.569467132067075e-06\n",
      "Epoch 2434, Loss: 5.1010725655942224e-05, Final Batch Loss: 1.6853691704454832e-05\n",
      "Epoch 2435, Loss: 7.201598236861173e-06, Final Batch Loss: 2.8113595362810884e-06\n",
      "Epoch 2436, Loss: 0.0012323734918027185, Final Batch Loss: 6.44287429167889e-05\n",
      "Epoch 2437, Loss: 7.57001571400906e-05, Final Batch Loss: 9.984493772208225e-06\n",
      "Epoch 2438, Loss: 3.505262247927021e-05, Final Batch Loss: 1.1309017281746492e-05\n",
      "Epoch 2439, Loss: 0.003157253442623187, Final Batch Loss: 3.047619975404814e-05\n",
      "Epoch 2440, Loss: 9.856947508524172e-05, Final Batch Loss: 8.812717715045437e-05\n",
      "Epoch 2441, Loss: 2.546971472838777e-05, Final Batch Loss: 6.880779892526334e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2442, Loss: 0.0003866114711854607, Final Batch Loss: 0.0003684788243845105\n",
      "Epoch 2443, Loss: 5.264628362056101e-05, Final Batch Loss: 1.0243101314699743e-05\n",
      "Epoch 2444, Loss: 0.00018167618691222742, Final Batch Loss: 0.00013354240218177438\n",
      "Epoch 2445, Loss: 3.246936694267788e-05, Final Batch Loss: 2.6196803446509875e-05\n",
      "Epoch 2446, Loss: 0.00014705094145028852, Final Batch Loss: 4.390327012515627e-05\n",
      "Epoch 2447, Loss: 4.449334664968774e-05, Final Batch Loss: 2.071598828479182e-05\n",
      "Epoch 2448, Loss: 0.00033901752067322377, Final Batch Loss: 0.00032710126833990216\n",
      "Epoch 2449, Loss: 2.8566221544679138e-05, Final Batch Loss: 3.359399443070288e-06\n",
      "Epoch 2450, Loss: 0.00019117861302220263, Final Batch Loss: 5.638827133225277e-06\n",
      "Epoch 2451, Loss: 1.9051337403652724e-05, Final Batch Loss: 1.3459207366395276e-05\n",
      "Epoch 2452, Loss: 9.115054274388967e-05, Final Batch Loss: 1.836809701671882e-06\n",
      "Epoch 2453, Loss: 0.00015699877440056298, Final Batch Loss: 1.825863182602916e-05\n",
      "Epoch 2454, Loss: 4.406490006658714e-05, Final Batch Loss: 1.6956137187662534e-05\n",
      "Epoch 2455, Loss: 5.192976504986291e-05, Final Batch Loss: 4.8038265958894044e-05\n",
      "Epoch 2456, Loss: 7.807674955984112e-05, Final Batch Loss: 2.2603313482250087e-05\n",
      "Epoch 2457, Loss: 0.00016246314316958888, Final Batch Loss: 6.443008714995813e-06\n",
      "Epoch 2458, Loss: 0.0006773299537599087, Final Batch Loss: 0.00021197443129494786\n",
      "Epoch 2459, Loss: 3.944561444768624e-05, Final Batch Loss: 2.420612645437359e-06\n",
      "Epoch 2460, Loss: 6.238334935915191e-05, Final Batch Loss: 1.3986233170726337e-05\n",
      "Epoch 2461, Loss: 0.00010835493958438747, Final Batch Loss: 2.215889617218636e-05\n",
      "Epoch 2462, Loss: 0.0004856656269112136, Final Batch Loss: 0.00043682073010131717\n",
      "Epoch 2463, Loss: 7.117406283896344e-05, Final Batch Loss: 7.08440929884091e-05\n",
      "Epoch 2464, Loss: 3.322535076222266e-05, Final Batch Loss: 4.672042905440321e-06\n",
      "Epoch 2465, Loss: 3.9764890061633196e-05, Final Batch Loss: 2.4870918423403054e-05\n",
      "Epoch 2466, Loss: 0.0006060636387701379, Final Batch Loss: 0.0005897539085708559\n",
      "Epoch 2467, Loss: 9.807215064938646e-05, Final Batch Loss: 2.2854363123769872e-05\n",
      "Epoch 2468, Loss: 0.00027685081886374974, Final Batch Loss: 6.750392003596062e-06\n",
      "Epoch 2469, Loss: 0.0004286191615392454, Final Batch Loss: 0.00037852925015613437\n",
      "Epoch 2470, Loss: 1.4821024933553417e-05, Final Batch Loss: 2.8086699330742704e-06\n",
      "Epoch 2471, Loss: 4.876488719673944e-05, Final Batch Loss: 5.463269644678803e-06\n",
      "Epoch 2472, Loss: 3.367702862533406e-05, Final Batch Loss: 9.423425240129291e-07\n",
      "Epoch 2473, Loss: 4.439545409695711e-05, Final Batch Loss: 1.2313708793953992e-05\n",
      "Epoch 2474, Loss: 0.0004415074701000776, Final Batch Loss: 1.1007115290340153e-06\n",
      "Epoch 2475, Loss: 0.001291556480282452, Final Batch Loss: 0.0011870835442095995\n",
      "Epoch 2476, Loss: 1.9511304344632663e-05, Final Batch Loss: 3.879542418872006e-06\n",
      "Epoch 2477, Loss: 0.0001120014208026987, Final Batch Loss: 0.00010450552508700639\n",
      "Epoch 2478, Loss: 5.460257807499147e-05, Final Batch Loss: 4.8415586206829175e-05\n",
      "Epoch 2479, Loss: 0.00020918512745993212, Final Batch Loss: 1.4206314517650753e-05\n",
      "Epoch 2480, Loss: 7.216577841973049e-06, Final Batch Loss: 4.123031430935953e-06\n",
      "Epoch 2481, Loss: 0.00017643529645283706, Final Batch Loss: 0.00014274459681473672\n",
      "Epoch 2482, Loss: 6.982368722674437e-05, Final Batch Loss: 2.283094363519922e-05\n",
      "Epoch 2483, Loss: 3.193694465153385e-05, Final Batch Loss: 1.6629614037810825e-05\n",
      "Epoch 2484, Loss: 3.822705139100435e-05, Final Batch Loss: 7.465019280061824e-06\n",
      "Epoch 2485, Loss: 0.00021428809139933946, Final Batch Loss: 8.240096462941437e-07\n",
      "Epoch 2486, Loss: 2.082424953187001e-05, Final Batch Loss: 1.6024487194954418e-05\n",
      "Epoch 2487, Loss: 8.724431972950697e-05, Final Batch Loss: 8.236619032686576e-05\n",
      "Epoch 2488, Loss: 0.00014142267536954023, Final Batch Loss: 0.00012939573207404464\n",
      "Epoch 2489, Loss: 0.00011871112928929506, Final Batch Loss: 1.058321777236415e-05\n",
      "Epoch 2490, Loss: 6.283649321403573e-05, Final Batch Loss: 4.6987310042823083e-07\n",
      "Epoch 2491, Loss: 1.157644283011905e-05, Final Batch Loss: 4.760208412335487e-06\n",
      "Epoch 2492, Loss: 0.00010708550689741969, Final Batch Loss: 3.712230682140216e-05\n",
      "Epoch 2493, Loss: 0.0001169455954368459, Final Batch Loss: 9.23760853765998e-06\n",
      "Epoch 2494, Loss: 0.00014967125389375724, Final Batch Loss: 1.1739368346752599e-05\n",
      "Epoch 2495, Loss: 0.00030127615536912344, Final Batch Loss: 3.906429265043698e-05\n",
      "Epoch 2496, Loss: 0.00010312218364560977, Final Batch Loss: 4.032237484352663e-05\n",
      "Epoch 2497, Loss: 1.14399751964811e-05, Final Batch Loss: 2.175293730033445e-06\n",
      "Epoch 2498, Loss: 0.0006858261476736516, Final Batch Loss: 0.0004937023622915149\n",
      "Epoch 2499, Loss: 0.00028549310445669107, Final Batch Loss: 1.0859581379918382e-05\n",
      "Epoch 2500, Loss: 0.0013740990298174438, Final Batch Loss: 8.107953362923581e-06\n",
      "Epoch 2501, Loss: 0.0006149292312329635, Final Batch Loss: 9.866493928711861e-05\n",
      "Epoch 2502, Loss: 0.00011072453708038665, Final Batch Loss: 2.0886709535261616e-05\n",
      "Epoch 2503, Loss: 7.302951200927055e-05, Final Batch Loss: 7.848553877920494e-07\n",
      "Epoch 2504, Loss: 2.613952077012982e-05, Final Batch Loss: 4.046133028623444e-07\n",
      "Epoch 2505, Loss: 9.832553041633219e-05, Final Batch Loss: 4.063982851221226e-05\n",
      "Epoch 2506, Loss: 7.37043728804565e-06, Final Batch Loss: 5.437411346065346e-06\n",
      "Epoch 2507, Loss: 0.00015766133219585754, Final Batch Loss: 0.00012302056711632758\n",
      "Epoch 2508, Loss: 8.862746653903741e-05, Final Batch Loss: 6.447527994168922e-05\n",
      "Epoch 2509, Loss: 7.824546992196701e-05, Final Batch Loss: 5.820607839268632e-05\n",
      "Epoch 2510, Loss: 4.283919543013326e-05, Final Batch Loss: 7.532985819125315e-06\n",
      "Epoch 2511, Loss: 0.00011166502190462779, Final Batch Loss: 9.371431224280968e-05\n",
      "Epoch 2512, Loss: 2.9288855330378283e-05, Final Batch Loss: 1.4771850146644283e-05\n",
      "Epoch 2513, Loss: 2.5092685064009856e-05, Final Batch Loss: 5.6291928558493964e-06\n",
      "Epoch 2514, Loss: 3.79419057026098e-05, Final Batch Loss: 6.400538495654473e-06\n",
      "Epoch 2515, Loss: 0.00010463617172717932, Final Batch Loss: 4.385066404211102e-06\n",
      "Epoch 2516, Loss: 0.0001168751059594797, Final Batch Loss: 9.731990576256067e-05\n",
      "Epoch 2517, Loss: 9.17019096959848e-05, Final Batch Loss: 7.475327583961189e-05\n",
      "Epoch 2518, Loss: 9.184303962683771e-05, Final Batch Loss: 4.368181180325337e-06\n",
      "Epoch 2519, Loss: 0.00012368919033178827, Final Batch Loss: 0.00012043958849972114\n",
      "Epoch 2520, Loss: 0.007623164834512863, Final Batch Loss: 0.007610801141709089\n",
      "Epoch 2521, Loss: 0.00012732557615890983, Final Batch Loss: 0.0001201360864797607\n",
      "Epoch 2522, Loss: 2.142708433439111e-05, Final Batch Loss: 1.822849640120694e-06\n",
      "Epoch 2523, Loss: 0.0001960098093150009, Final Batch Loss: 0.00019099769997410476\n",
      "Epoch 2524, Loss: 2.684742139535956e-05, Final Batch Loss: 1.4999194718257058e-05\n",
      "Epoch 2525, Loss: 5.176242484594695e-05, Final Batch Loss: 1.4822227967670187e-05\n",
      "Epoch 2526, Loss: 1.7145532638096483e-05, Final Batch Loss: 1.4633795217378065e-05\n",
      "Epoch 2527, Loss: 2.9443126550177112e-05, Final Batch Loss: 1.0209681931883097e-05\n",
      "Epoch 2528, Loss: 0.00042817057146748994, Final Batch Loss: 2.0908419173792936e-05\n",
      "Epoch 2529, Loss: 5.6865554142859764e-05, Final Batch Loss: 3.7458819861058146e-05\n",
      "Epoch 2530, Loss: 5.267027336230967e-05, Final Batch Loss: 2.2401680325856432e-05\n",
      "Epoch 2531, Loss: 1.8698391158977756e-05, Final Batch Loss: 1.1069048923673108e-05\n",
      "Epoch 2532, Loss: 5.8826439271797426e-05, Final Batch Loss: 3.289270534878597e-05\n",
      "Epoch 2533, Loss: 8.566636824980378e-05, Final Batch Loss: 2.827284697559662e-05\n",
      "Epoch 2534, Loss: 0.00031244615092873573, Final Batch Loss: 0.0001784028427209705\n",
      "Epoch 2535, Loss: 4.9506910727359354e-05, Final Batch Loss: 2.3772186978021637e-05\n",
      "Epoch 2536, Loss: 0.00014187759370543063, Final Batch Loss: 7.576358621008694e-05\n",
      "Epoch 2537, Loss: 4.590783646563068e-06, Final Batch Loss: 1.8228886347060325e-06\n",
      "Epoch 2538, Loss: 0.00014357572899825755, Final Batch Loss: 6.85783697917941e-06\n",
      "Epoch 2539, Loss: 0.00016447031885036267, Final Batch Loss: 0.0001434516452718526\n",
      "Epoch 2540, Loss: 8.939953659137245e-05, Final Batch Loss: 2.164929719583597e-05\n",
      "Epoch 2541, Loss: 4.043939679831965e-05, Final Batch Loss: 9.221686013916042e-06\n",
      "Epoch 2542, Loss: 9.296348798670806e-05, Final Batch Loss: 4.421861740411259e-05\n",
      "Epoch 2543, Loss: 0.00040932537103799405, Final Batch Loss: 1.1683722732414026e-05\n",
      "Epoch 2544, Loss: 0.00011550088311196305, Final Batch Loss: 2.983792728628032e-05\n",
      "Epoch 2545, Loss: 0.00010851058777916478, Final Batch Loss: 3.8770858736825176e-06\n",
      "Epoch 2546, Loss: 5.1373061069170944e-05, Final Batch Loss: 4.222972711431794e-05\n",
      "Epoch 2547, Loss: 7.673420986975543e-05, Final Batch Loss: 4.000968692707829e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2548, Loss: 0.005702986654114284, Final Batch Loss: 0.005701245274394751\n",
      "Epoch 2549, Loss: 0.000120481683552498, Final Batch Loss: 4.854827784583904e-05\n",
      "Epoch 2550, Loss: 0.00011834751421702094, Final Batch Loss: 7.489634299417958e-05\n",
      "Epoch 2551, Loss: 0.0018089413351844996, Final Batch Loss: 0.0003097989538218826\n",
      "Epoch 2552, Loss: 9.406571280123899e-05, Final Batch Loss: 8.024855924304575e-05\n",
      "Epoch 2553, Loss: 7.634389589838975e-06, Final Batch Loss: 1.3704453749596723e-06\n",
      "Epoch 2554, Loss: 0.00031356832005258184, Final Batch Loss: 1.2315997082623653e-05\n",
      "Epoch 2555, Loss: 0.00023421403602696955, Final Batch Loss: 0.00018742545216809958\n",
      "Epoch 2556, Loss: 4.258483977537253e-05, Final Batch Loss: 6.19820866631926e-06\n",
      "Epoch 2557, Loss: 0.00016450440307380632, Final Batch Loss: 8.012862235773355e-05\n",
      "Epoch 2558, Loss: 4.993770380679052e-05, Final Batch Loss: 1.5935487681417726e-05\n",
      "Epoch 2559, Loss: 5.698449331248412e-05, Final Batch Loss: 4.403280036058277e-05\n",
      "Epoch 2560, Loss: 7.615762297064066e-05, Final Batch Loss: 6.026117262081243e-05\n",
      "Epoch 2561, Loss: 0.0001645158622523013, Final Batch Loss: 0.00016004018834792078\n",
      "Epoch 2562, Loss: 9.298478835262358e-05, Final Batch Loss: 1.520751538919285e-05\n",
      "Epoch 2563, Loss: 0.0003477629288681783, Final Batch Loss: 0.00010169455345021561\n",
      "Epoch 2564, Loss: 4.623182030627504e-05, Final Batch Loss: 2.6264102416462265e-05\n",
      "Epoch 2565, Loss: 0.00016107205738080665, Final Batch Loss: 9.065362246474251e-05\n",
      "Epoch 2566, Loss: 7.166543582570739e-05, Final Batch Loss: 1.2689008144661784e-05\n",
      "Epoch 2567, Loss: 5.878572619621991e-05, Final Batch Loss: 2.886984930228209e-06\n",
      "Epoch 2568, Loss: 3.7527329368458595e-05, Final Batch Loss: 1.1587319932004903e-05\n",
      "Epoch 2569, Loss: 0.0001570080139572383, Final Batch Loss: 0.00014298013411462307\n",
      "Epoch 2570, Loss: 0.0007052358414512128, Final Batch Loss: 0.0006611250573769212\n",
      "Epoch 2571, Loss: 6.585086839550058e-05, Final Batch Loss: 6.5435228862043004e-06\n",
      "Epoch 2572, Loss: 0.00038323051558109, Final Batch Loss: 2.5054388970602304e-05\n",
      "Epoch 2573, Loss: 0.0001364961535728071, Final Batch Loss: 9.95311129372567e-05\n",
      "Epoch 2574, Loss: 0.00043779227689810796, Final Batch Loss: 0.00042954468517564237\n",
      "Epoch 2575, Loss: 0.0010617408333928324, Final Batch Loss: 0.001027824473567307\n",
      "Epoch 2576, Loss: 1.5864371107454645e-05, Final Batch Loss: 2.3483412405767012e-06\n",
      "Epoch 2577, Loss: 0.0002176464804506395, Final Batch Loss: 0.00017611266230233014\n",
      "Epoch 2578, Loss: 2.0354613525341847e-05, Final Batch Loss: 3.1435849905392388e-06\n",
      "Epoch 2579, Loss: 2.9438089768518694e-05, Final Batch Loss: 8.179336873581633e-06\n",
      "Epoch 2580, Loss: 4.441297642188147e-05, Final Batch Loss: 2.826367381203454e-05\n",
      "Epoch 2581, Loss: 0.0012340188841335475, Final Batch Loss: 0.0003769151517190039\n",
      "Epoch 2582, Loss: 0.0008262008232122753, Final Batch Loss: 0.0007654373766854405\n",
      "Epoch 2583, Loss: 0.000814768848613312, Final Batch Loss: 0.0008069410105235875\n",
      "Epoch 2584, Loss: 2.812482762237778e-05, Final Batch Loss: 6.908810064487625e-06\n",
      "Epoch 2585, Loss: 6.947751671759761e-06, Final Batch Loss: 2.2029373667464824e-06\n",
      "Epoch 2586, Loss: 0.0006639774570658119, Final Batch Loss: 1.4922612763257348e-06\n",
      "Epoch 2587, Loss: 1.9682902461681806e-05, Final Batch Loss: 1.8881511323343148e-06\n",
      "Epoch 2588, Loss: 4.086857006768696e-05, Final Batch Loss: 3.287426079623401e-05\n",
      "Epoch 2589, Loss: 0.00022341436897477251, Final Batch Loss: 2.7312275960866828e-06\n",
      "Epoch 2590, Loss: 0.00040099202897181385, Final Batch Loss: 4.434352831594879e-06\n",
      "Epoch 2591, Loss: 5.5658463224972365e-05, Final Batch Loss: 5.703087936126394e-06\n",
      "Epoch 2592, Loss: 3.0231481105147395e-05, Final Batch Loss: 1.3606349057226907e-05\n",
      "Epoch 2593, Loss: 1.698598134680651e-05, Final Batch Loss: 1.3896493328502402e-05\n",
      "Epoch 2594, Loss: 0.000198364767129533, Final Batch Loss: 0.00017553461657371372\n",
      "Epoch 2595, Loss: 2.2529799480253132e-05, Final Batch Loss: 4.36517666457803e-06\n",
      "Epoch 2596, Loss: 7.252443765537464e-06, Final Batch Loss: 3.75915828954021e-06\n",
      "Epoch 2597, Loss: 0.0003355781555001158, Final Batch Loss: 0.00033057061955332756\n",
      "Epoch 2598, Loss: 2.015518839471042e-05, Final Batch Loss: 8.856370186549611e-06\n",
      "Epoch 2599, Loss: 8.772526246048074e-05, Final Batch Loss: 1.3895715937906061e-06\n",
      "Epoch 2600, Loss: 6.7663806930795545e-06, Final Batch Loss: 3.719600726981298e-06\n",
      "Epoch 2601, Loss: 5.932695921728737e-05, Final Batch Loss: 1.0859198482648935e-06\n",
      "Epoch 2602, Loss: 5.1190488193242345e-05, Final Batch Loss: 3.775057848542929e-05\n",
      "Epoch 2603, Loss: 0.0009559539716974541, Final Batch Loss: 2.00555541596259e-06\n",
      "Epoch 2604, Loss: 1.81533869181294e-05, Final Batch Loss: 6.603960173379164e-06\n",
      "Epoch 2605, Loss: 0.00045120218419469893, Final Batch Loss: 6.538472371175885e-05\n",
      "Epoch 2606, Loss: 4.305833681428339e-05, Final Batch Loss: 3.4023571060970426e-05\n",
      "Epoch 2607, Loss: 0.00013547570068794812, Final Batch Loss: 8.805693028079986e-07\n",
      "Epoch 2608, Loss: 1.5019755892353714e-05, Final Batch Loss: 2.7843182124343002e-06\n",
      "Epoch 2609, Loss: 0.00010927248695224989, Final Batch Loss: 1.2696773410425521e-05\n",
      "Epoch 2610, Loss: 8.041635373956524e-05, Final Batch Loss: 6.318080704659224e-05\n",
      "Epoch 2611, Loss: 8.5921410118317e-05, Final Batch Loss: 2.6894099391938653e-06\n",
      "Epoch 2612, Loss: 9.968133781512734e-06, Final Batch Loss: 6.044831025064923e-06\n",
      "Epoch 2613, Loss: 0.0033623718366015964, Final Batch Loss: 0.003360389731824398\n",
      "Epoch 2614, Loss: 0.001687008339104068, Final Batch Loss: 0.0016797741409391165\n",
      "Epoch 2615, Loss: 0.0001714049885777058, Final Batch Loss: 0.00016650707402732223\n",
      "Epoch 2616, Loss: 4.087158231413923e-05, Final Batch Loss: 3.231202936149202e-05\n",
      "Epoch 2617, Loss: 7.984015974216163e-05, Final Batch Loss: 3.090831160079688e-05\n",
      "Epoch 2618, Loss: 5.284363760438282e-05, Final Batch Loss: 2.4894214220694266e-05\n",
      "Epoch 2619, Loss: 3.5220400377511396e-05, Final Batch Loss: 1.531319639980211e-06\n",
      "Epoch 2620, Loss: 1.2497268556899144e-05, Final Batch Loss: 4.5160149397815985e-07\n",
      "Epoch 2621, Loss: 0.0004031072744510311, Final Batch Loss: 0.0003985117073170841\n",
      "Epoch 2622, Loss: 4.2268619836249854e-05, Final Batch Loss: 5.087246790935751e-06\n",
      "Epoch 2623, Loss: 0.00011386084406694863, Final Batch Loss: 5.823110768687911e-06\n",
      "Epoch 2624, Loss: 0.00014503424608847126, Final Batch Loss: 9.20451566344127e-05\n",
      "Epoch 2625, Loss: 0.00019136667651764583, Final Batch Loss: 8.110129783744924e-06\n",
      "Epoch 2626, Loss: 2.800303491312661e-06, Final Batch Loss: 7.004568942647893e-07\n",
      "Epoch 2627, Loss: 4.83421381431981e-05, Final Batch Loss: 3.94258058804553e-05\n",
      "Epoch 2628, Loss: 0.00022284903570835013, Final Batch Loss: 0.00020121548732277006\n",
      "Epoch 2629, Loss: 5.0513772293925285e-05, Final Batch Loss: 3.948553421651013e-05\n",
      "Epoch 2630, Loss: 0.0001538819096822408, Final Batch Loss: 4.8740375859779306e-06\n",
      "Epoch 2631, Loss: 8.947608193921042e-06, Final Batch Loss: 2.627607273097965e-06\n",
      "Epoch 2632, Loss: 3.1481855558013194e-06, Final Batch Loss: 1.7949789707927266e-06\n",
      "Epoch 2633, Loss: 0.0002700245677260682, Final Batch Loss: 0.0002527635369915515\n",
      "Epoch 2634, Loss: 1.9483275536913425e-05, Final Batch Loss: 1.0173864211537875e-05\n",
      "Epoch 2635, Loss: 1.5560727206320735e-05, Final Batch Loss: 7.978698704391718e-06\n",
      "Epoch 2636, Loss: 1.3969125802759663e-06, Final Batch Loss: 9.954184179150616e-07\n",
      "Epoch 2637, Loss: 3.1040830435813405e-05, Final Batch Loss: 2.592574128357228e-05\n",
      "Epoch 2638, Loss: 3.3224049730051775e-05, Final Batch Loss: 1.998656807700172e-05\n",
      "Epoch 2639, Loss: 3.669676152640022e-05, Final Batch Loss: 2.3813445295672864e-05\n",
      "Epoch 2640, Loss: 0.0003596215865400154, Final Batch Loss: 4.493502274272032e-05\n",
      "Epoch 2641, Loss: 0.0003680267800518777, Final Batch Loss: 3.477540667518042e-05\n",
      "Epoch 2642, Loss: 2.1185540845181094e-05, Final Batch Loss: 6.968954494368518e-06\n",
      "Epoch 2643, Loss: 7.627032209711615e-05, Final Batch Loss: 5.499461622093804e-05\n",
      "Epoch 2644, Loss: 1.4938992535462603e-05, Final Batch Loss: 1.3142380339559168e-05\n",
      "Epoch 2645, Loss: 7.164455814745452e-05, Final Batch Loss: 7.055503374431282e-05\n",
      "Epoch 2646, Loss: 1.3025546195422066e-05, Final Batch Loss: 1.3104095160088036e-06\n",
      "Epoch 2647, Loss: 1.0060827662528027e-05, Final Batch Loss: 6.481983291450888e-06\n",
      "Epoch 2648, Loss: 2.908471469709184e-05, Final Batch Loss: 4.767791324411519e-06\n",
      "Epoch 2649, Loss: 4.2631530050130095e-05, Final Batch Loss: 7.085621291480493e-06\n",
      "Epoch 2650, Loss: 3.480300620140042e-05, Final Batch Loss: 2.735091584327165e-05\n",
      "Epoch 2651, Loss: 7.193012834250112e-06, Final Batch Loss: 5.332559339876752e-06\n",
      "Epoch 2652, Loss: 8.149718803451833e-05, Final Batch Loss: 8.091831841738895e-05\n",
      "Epoch 2653, Loss: 2.6537596568232402e-05, Final Batch Loss: 1.4281988114817068e-05\n",
      "Epoch 2654, Loss: 0.0035303094912251254, Final Batch Loss: 1.5748221358080627e-06\n",
      "Epoch 2655, Loss: 0.000563872108614305, Final Batch Loss: 0.0005367152043618262\n",
      "Epoch 2656, Loss: 4.927003897137183e-05, Final Batch Loss: 3.00607348435733e-06\n",
      "Epoch 2657, Loss: 0.005375889971560355, Final Batch Loss: 1.6367097259717411e-06\n",
      "Epoch 2658, Loss: 5.104427259539079e-06, Final Batch Loss: 1.270377765649755e-06\n",
      "Epoch 2659, Loss: 7.56880285734951e-06, Final Batch Loss: 3.2428508802695433e-06\n",
      "Epoch 2660, Loss: 0.0001785265185390017, Final Batch Loss: 0.0001744910259731114\n",
      "Epoch 2661, Loss: 0.0006055150297470391, Final Batch Loss: 0.00045555311953648925\n",
      "Epoch 2662, Loss: 1.647440058150096e-05, Final Batch Loss: 1.0804850717249792e-05\n",
      "Epoch 2663, Loss: 0.011007648547092685, Final Batch Loss: 0.011003773659467697\n",
      "Epoch 2664, Loss: 0.00011308068133075722, Final Batch Loss: 4.4411415728973225e-05\n",
      "Epoch 2665, Loss: 0.00010735704927355982, Final Batch Loss: 3.380086491233669e-05\n",
      "Epoch 2666, Loss: 3.0007755412952974e-05, Final Batch Loss: 1.3797272913507186e-05\n",
      "Epoch 2667, Loss: 4.472733780858107e-05, Final Batch Loss: 2.503724863345269e-05\n",
      "Epoch 2668, Loss: 7.973365427460521e-06, Final Batch Loss: 3.278536951256683e-06\n",
      "Epoch 2669, Loss: 8.11215395515319e-05, Final Batch Loss: 3.497406578389928e-05\n",
      "Epoch 2670, Loss: 4.564607388601871e-05, Final Batch Loss: 4.228122270433232e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2671, Loss: 0.0002659694400790613, Final Batch Loss: 2.0580639102263376e-05\n",
      "Epoch 2672, Loss: 1.1560977327462751e-05, Final Batch Loss: 6.42505256109871e-06\n",
      "Epoch 2673, Loss: 2.1145682694623247e-05, Final Batch Loss: 6.231321094674058e-06\n",
      "Epoch 2674, Loss: 0.0002441754077153746, Final Batch Loss: 3.633268715930171e-05\n",
      "Epoch 2675, Loss: 0.0006113717272455688, Final Batch Loss: 1.4196400115906727e-05\n",
      "Epoch 2676, Loss: 0.0036182284293317934, Final Batch Loss: 1.2010516002192162e-05\n",
      "Epoch 2677, Loss: 0.0022551935398951173, Final Batch Loss: 0.002032037591561675\n",
      "Epoch 2678, Loss: 0.0004242072166107391, Final Batch Loss: 0.0004232287756167352\n",
      "Epoch 2679, Loss: 0.0005149192206772568, Final Batch Loss: 0.0005108103505335748\n",
      "Epoch 2680, Loss: 2.000712811423e-05, Final Batch Loss: 1.8496657503419556e-05\n",
      "Epoch 2681, Loss: 8.43575639919436e-06, Final Batch Loss: 6.225277047633426e-06\n",
      "Epoch 2682, Loss: 5.6383532864856534e-05, Final Batch Loss: 2.042389132839162e-05\n",
      "Epoch 2683, Loss: 5.5519426496175583e-05, Final Batch Loss: 3.2323978302883916e-06\n",
      "Epoch 2684, Loss: 0.0002133742964360863, Final Batch Loss: 0.00017281723557971418\n",
      "Epoch 2685, Loss: 4.5153840801503975e-05, Final Batch Loss: 3.3034961234079674e-05\n",
      "Epoch 2686, Loss: 0.0001221999973495258, Final Batch Loss: 7.69481084716972e-06\n",
      "Epoch 2687, Loss: 9.974558588510263e-05, Final Batch Loss: 9.61394325713627e-05\n",
      "Epoch 2688, Loss: 1.3438118827480139e-05, Final Batch Loss: 2.9323192052288505e-07\n",
      "Epoch 2689, Loss: 0.0009830819035414606, Final Batch Loss: 0.00045539168058894575\n",
      "Epoch 2690, Loss: 0.000144760308558034, Final Batch Loss: 0.00014266697689890862\n",
      "Epoch 2691, Loss: 0.00016688976211298723, Final Batch Loss: 2.464960743964184e-05\n",
      "Epoch 2692, Loss: 0.0046602228248957545, Final Batch Loss: 0.0044439067132771015\n",
      "Epoch 2693, Loss: 5.4502819693880156e-05, Final Batch Loss: 2.3764234356349334e-05\n",
      "Epoch 2694, Loss: 5.218442038312787e-05, Final Batch Loss: 3.8585319998674095e-05\n",
      "Epoch 2695, Loss: 1.4718123566126451e-05, Final Batch Loss: 7.004878170846496e-06\n",
      "Epoch 2696, Loss: 1.9738616288123012e-05, Final Batch Loss: 1.4844009683656623e-06\n",
      "Epoch 2697, Loss: 9.487197939961334e-05, Final Batch Loss: 8.893806079868227e-05\n",
      "Epoch 2698, Loss: 6.313126482382359e-05, Final Batch Loss: 3.2364766866521677e-06\n",
      "Epoch 2699, Loss: 1.8859891042666277e-05, Final Batch Loss: 1.6320662325597368e-05\n",
      "Epoch 2700, Loss: 3.128267172769483e-05, Final Batch Loss: 3.515354478622612e-07\n",
      "Epoch 2701, Loss: 0.0001108554140500928, Final Batch Loss: 1.0571973234618781e-06\n",
      "Epoch 2702, Loss: 0.00013772448892268585, Final Batch Loss: 5.150371180207003e-06\n",
      "Epoch 2703, Loss: 8.287527452921495e-05, Final Batch Loss: 4.056384204886854e-05\n",
      "Epoch 2704, Loss: 0.003508684714915944, Final Batch Loss: 3.646384584499174e-06\n",
      "Epoch 2705, Loss: 0.0003913564480626519, Final Batch Loss: 2.242251184725319e-06\n",
      "Epoch 2706, Loss: 0.004670513386372477, Final Batch Loss: 0.004242542199790478\n",
      "Epoch 2707, Loss: 1.6425679405074334e-05, Final Batch Loss: 1.1084896868851501e-05\n",
      "Epoch 2708, Loss: 0.00123483850620687, Final Batch Loss: 0.0005740555352531374\n",
      "Epoch 2709, Loss: 0.00010979307990055531, Final Batch Loss: 8.884762064553797e-05\n",
      "Epoch 2710, Loss: 1.6049453279265435e-05, Final Batch Loss: 4.1856960706354585e-06\n",
      "Epoch 2711, Loss: 5.224539927439764e-05, Final Batch Loss: 4.437905954546295e-05\n",
      "Epoch 2712, Loss: 0.00018449651403784628, Final Batch Loss: 0.0001841145713115111\n",
      "Epoch 2713, Loss: 2.1527569629142818e-06, Final Batch Loss: 5.316429110280296e-07\n",
      "Epoch 2714, Loss: 6.839570369265857e-05, Final Batch Loss: 6.843576102255611e-06\n",
      "Epoch 2715, Loss: 0.00027081356165581383, Final Batch Loss: 4.336161146056838e-05\n",
      "Epoch 2716, Loss: 2.4999685138027417e-05, Final Batch Loss: 1.9034076103707775e-05\n",
      "Epoch 2717, Loss: 2.343704181839712e-05, Final Batch Loss: 1.849491491157096e-05\n",
      "Epoch 2718, Loss: 1.0832175803443533e-05, Final Batch Loss: 1.0394925993750803e-05\n",
      "Epoch 2719, Loss: 2.3827978111512493e-05, Final Batch Loss: 1.616259578440804e-05\n",
      "Epoch 2720, Loss: 1.604025987944624e-05, Final Batch Loss: 1.4991266652941704e-05\n",
      "Epoch 2721, Loss: 1.1750018416023522e-05, Final Batch Loss: 6.247472583709168e-07\n",
      "Epoch 2722, Loss: 0.001533958105937927, Final Batch Loss: 7.3176106525352225e-06\n",
      "Epoch 2723, Loss: 1.0246469912544853e-06, Final Batch Loss: 7.108924364729319e-07\n",
      "Epoch 2724, Loss: 2.5289575660281116e-05, Final Batch Loss: 5.858668828295777e-06\n",
      "Epoch 2725, Loss: 2.395629357465623e-05, Final Batch Loss: 3.38480589334722e-07\n",
      "Epoch 2726, Loss: 0.00043189087591599673, Final Batch Loss: 0.0002297479222761467\n",
      "Epoch 2727, Loss: 0.0004658594180000364, Final Batch Loss: 0.00045359888463281095\n",
      "Epoch 2728, Loss: 0.0015828894369747104, Final Batch Loss: 3.149884264530556e-07\n",
      "Epoch 2729, Loss: 5.5475365456914005e-06, Final Batch Loss: 3.5849546975441626e-07\n",
      "Epoch 2730, Loss: 0.00021218291794866673, Final Batch Loss: 0.00020703781046904624\n",
      "Epoch 2731, Loss: 4.600306419888511e-05, Final Batch Loss: 3.684195689857006e-05\n",
      "Epoch 2732, Loss: 0.0005135436003911309, Final Batch Loss: 9.62701378739439e-05\n",
      "Epoch 2733, Loss: 2.1401853700808715e-05, Final Batch Loss: 5.112976396048907e-06\n",
      "Epoch 2734, Loss: 0.0004234868101775646, Final Batch Loss: 8.558676927350461e-05\n",
      "Epoch 2735, Loss: 5.175231933662872e-06, Final Batch Loss: 7.091518341439951e-07\n",
      "Epoch 2736, Loss: 1.159116368398827e-05, Final Batch Loss: 1.9340889139130013e-06\n",
      "Epoch 2737, Loss: 9.249259124999298e-05, Final Batch Loss: 9.170248813461512e-05\n",
      "Epoch 2738, Loss: 1.9235082163504558e-05, Final Batch Loss: 2.0472075448196847e-06\n",
      "Epoch 2739, Loss: 6.639344792347401e-05, Final Batch Loss: 1.3814693375024945e-05\n",
      "Epoch 2740, Loss: 0.0006461839657276869, Final Batch Loss: 9.973702253773808e-05\n",
      "Epoch 2741, Loss: 7.506008842028677e-05, Final Batch Loss: 5.3805357310920954e-05\n",
      "Epoch 2742, Loss: 3.730013486347161e-05, Final Batch Loss: 2.0159313862677664e-06\n",
      "Epoch 2743, Loss: 8.902036461222451e-05, Final Batch Loss: 8.05495583335869e-05\n",
      "Epoch 2744, Loss: 1.843841982918093e-05, Final Batch Loss: 1.0262584510201123e-05\n",
      "Epoch 2745, Loss: 0.00013305515312822536, Final Batch Loss: 7.590225141029805e-05\n",
      "Epoch 2746, Loss: 2.7144214072905015e-05, Final Batch Loss: 1.6382979083573446e-05\n",
      "Epoch 2747, Loss: 7.630627305843518e-05, Final Batch Loss: 3.58495981345186e-07\n",
      "Epoch 2748, Loss: 0.0015277355635134882, Final Batch Loss: 2.8286087854212383e-06\n",
      "Epoch 2749, Loss: 8.126008196995826e-06, Final Batch Loss: 2.9790935514029115e-06\n",
      "Epoch 2750, Loss: 1.3651590279550874e-05, Final Batch Loss: 3.6576614093064563e-06\n",
      "Epoch 2751, Loss: 6.126017365204461e-05, Final Batch Loss: 1.1276799796178238e-06\n",
      "Epoch 2752, Loss: 0.00015940855018925504, Final Batch Loss: 0.0001574679190525785\n",
      "Epoch 2753, Loss: 6.755527738278033e-05, Final Batch Loss: 1.2789195352524985e-05\n",
      "Epoch 2754, Loss: 0.00015742367838811333, Final Batch Loss: 5.742884923165548e-07\n",
      "Epoch 2755, Loss: 1.4876031542598867e-05, Final Batch Loss: 1.4620449292124249e-05\n",
      "Epoch 2756, Loss: 0.0003534171664796304, Final Batch Loss: 0.0003119950997643173\n",
      "Epoch 2757, Loss: 0.00012161918130004779, Final Batch Loss: 7.98594337538816e-05\n",
      "Epoch 2758, Loss: 1.5676648672524607e-05, Final Batch Loss: 4.40223493569647e-06\n",
      "Epoch 2759, Loss: 2.8695108767351485e-05, Final Batch Loss: 2.5483899662503973e-05\n",
      "Epoch 2760, Loss: 0.0007537395449617179, Final Batch Loss: 1.3256723832455464e-05\n",
      "Epoch 2761, Loss: 0.0002578095027274685, Final Batch Loss: 0.0002460310934111476\n",
      "Epoch 2762, Loss: 0.0037338030947466905, Final Batch Loss: 0.0037282886914908886\n",
      "Epoch 2763, Loss: 1.3860407051424772e-05, Final Batch Loss: 1.2268966997908137e-07\n",
      "Epoch 2764, Loss: 6.205418799254403e-06, Final Batch Loss: 1.0676332067305339e-06\n",
      "Epoch 2765, Loss: 0.00030066564795561135, Final Batch Loss: 0.00012980206520296633\n",
      "Epoch 2766, Loss: 1.671313157203258e-05, Final Batch Loss: 4.038023234897992e-06\n",
      "Epoch 2767, Loss: 0.00017451948951929808, Final Batch Loss: 0.0001265411265194416\n",
      "Epoch 2768, Loss: 9.680287530500209e-05, Final Batch Loss: 8.658598380861804e-05\n",
      "Epoch 2769, Loss: 0.00010188519303255816, Final Batch Loss: 8.005176255210245e-07\n",
      "Epoch 2770, Loss: 0.00014206713967723772, Final Batch Loss: 3.9116763218771666e-05\n",
      "Epoch 2771, Loss: 0.005888618255539768, Final Batch Loss: 0.005887335166335106\n",
      "Epoch 2772, Loss: 0.00011654435002128594, Final Batch Loss: 0.00010189785098191351\n",
      "Epoch 2773, Loss: 9.106112884182949e-05, Final Batch Loss: 1.9734385205083527e-05\n",
      "Epoch 2774, Loss: 4.820646427106112e-05, Final Batch Loss: 1.2619559129234403e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2775, Loss: 0.0001102798653391801, Final Batch Loss: 2.2177648588694865e-06\n",
      "Epoch 2776, Loss: 1.2003304032504047e-05, Final Batch Loss: 3.7416025833181266e-08\n",
      "Epoch 2777, Loss: 6.297890877249301e-06, Final Batch Loss: 2.590919848444173e-06\n",
      "Epoch 2778, Loss: 9.324297627699707e-05, Final Batch Loss: 1.3025570524405339e-06\n",
      "Epoch 2779, Loss: 0.00017544079673825763, Final Batch Loss: 1.7797250620787963e-05\n",
      "Epoch 2780, Loss: 3.885468504449818e-05, Final Batch Loss: 1.9300978237879463e-05\n",
      "Epoch 2781, Loss: 4.092729659532779e-05, Final Batch Loss: 4.801534032594645e-06\n",
      "Epoch 2782, Loss: 0.0004974036110070301, Final Batch Loss: 0.00048069143667817116\n",
      "Epoch 2783, Loss: 0.0003399458032617986, Final Batch Loss: 1.1476763575046789e-06\n",
      "Epoch 2784, Loss: 1.0242629992163188e-05, Final Batch Loss: 2.0013226631476755e-08\n",
      "Epoch 2785, Loss: 1.0248613477870094e-05, Final Batch Loss: 9.829479495238047e-06\n",
      "Epoch 2786, Loss: 0.0053350422604125924, Final Batch Loss: 0.005292063113301992\n",
      "Epoch 2787, Loss: 0.0007410940233967267, Final Batch Loss: 0.0007218784885481\n",
      "Epoch 2788, Loss: 3.734294932655757e-05, Final Batch Loss: 2.14550436794525e-06\n",
      "Epoch 2789, Loss: 0.003834012277366128, Final Batch Loss: 7.022180216154084e-05\n",
      "Epoch 2790, Loss: 8.031542074604658e-05, Final Batch Loss: 8.68438928591786e-06\n",
      "Epoch 2791, Loss: 9.690785464044893e-05, Final Batch Loss: 7.783485671097878e-06\n",
      "Epoch 2792, Loss: 3.5575945730670355e-05, Final Batch Loss: 3.956802174798213e-06\n",
      "Epoch 2793, Loss: 4.987201009498676e-06, Final Batch Loss: 1.4147378806228517e-06\n",
      "Epoch 2794, Loss: 9.095464429265121e-05, Final Batch Loss: 4.016518687421922e-06\n",
      "Epoch 2795, Loss: 0.00020865873216280306, Final Batch Loss: 0.0002058857207885012\n",
      "Epoch 2796, Loss: 9.629776059227879e-05, Final Batch Loss: 7.515143352065934e-06\n",
      "Epoch 2797, Loss: 0.000657658776617609, Final Batch Loss: 0.0005444684065878391\n",
      "Epoch 2798, Loss: 2.544557355577126e-05, Final Batch Loss: 6.464002581196837e-06\n",
      "Epoch 2799, Loss: 4.157412112704151e-05, Final Batch Loss: 4.110444206162356e-05\n",
      "Epoch 2800, Loss: 2.11825556561962e-06, Final Batch Loss: 1.4330552176033962e-06\n",
      "Epoch 2801, Loss: 0.000118985084554879, Final Batch Loss: 3.136035593342967e-05\n",
      "Epoch 2802, Loss: 2.6626695671438938e-05, Final Batch Loss: 1.5522959984082263e-06\n",
      "Epoch 2803, Loss: 8.844661351758987e-05, Final Batch Loss: 8.97036079550162e-06\n",
      "Epoch 2804, Loss: 0.0001863168613454036, Final Batch Loss: 0.0001825825311243534\n",
      "Epoch 2805, Loss: 9.14760249770552e-06, Final Batch Loss: 8.658850674692076e-06\n",
      "Epoch 2806, Loss: 0.0009370982297696173, Final Batch Loss: 0.0006009531207382679\n",
      "Epoch 2807, Loss: 2.4846491214702837e-05, Final Batch Loss: 9.406399840372615e-06\n",
      "Epoch 2808, Loss: 3.484780813778343e-05, Final Batch Loss: 2.5787251161091262e-06\n",
      "Epoch 2809, Loss: 4.6431898681476014e-05, Final Batch Loss: 4.0258852095576e-05\n",
      "Epoch 2810, Loss: 0.005504603448571288, Final Batch Loss: 0.005487653426826\n",
      "Epoch 2811, Loss: 1.1660763902909821e-05, Final Batch Loss: 6.84105179971084e-06\n",
      "Epoch 2812, Loss: 0.0004649142883863533, Final Batch Loss: 0.0004568130534607917\n",
      "Epoch 2813, Loss: 2.773830881608319e-05, Final Batch Loss: 1.949111521071245e-07\n",
      "Epoch 2814, Loss: 0.0001002133593601684, Final Batch Loss: 4.820557251150603e-07\n",
      "Epoch 2815, Loss: 9.267099699172832e-06, Final Batch Loss: 7.3660266934894025e-06\n",
      "Epoch 2816, Loss: 0.00019815550695057027, Final Batch Loss: 0.00016784733452368528\n",
      "Epoch 2817, Loss: 0.0010383885535247828, Final Batch Loss: 2.30988439398061e-06\n",
      "Epoch 2818, Loss: 0.002853195594980207, Final Batch Loss: 9.58092732616933e-06\n",
      "Epoch 2819, Loss: 4.080379881088447e-06, Final Batch Loss: 3.121023837593384e-06\n",
      "Epoch 2820, Loss: 1.008173553884717e-05, Final Batch Loss: 1.392222230833795e-07\n",
      "Epoch 2821, Loss: 2.1378989959686123e-05, Final Batch Loss: 1.9143090668194418e-08\n",
      "Epoch 2822, Loss: 5.224999904385186e-05, Final Batch Loss: 4.815575812244788e-05\n",
      "Epoch 2823, Loss: 0.0001619195973034948, Final Batch Loss: 0.0001226168969878927\n",
      "Epoch 2824, Loss: 0.0001224605574634552, Final Batch Loss: 0.00012136579607613385\n",
      "Epoch 2825, Loss: 9.299776866100729e-05, Final Batch Loss: 6.254923937376589e-05\n",
      "Epoch 2826, Loss: 0.0027643686189549044, Final Batch Loss: 2.399245568085462e-05\n",
      "Epoch 2827, Loss: 5.052801998317591e-05, Final Batch Loss: 1.4861520867270883e-06\n",
      "Epoch 2828, Loss: 1.0484040785740945e-05, Final Batch Loss: 7.106481461960357e-06\n",
      "Epoch 2829, Loss: 0.00011133320322187501, Final Batch Loss: 0.00010422927880426869\n",
      "Epoch 2830, Loss: 1.6910967815420008e-05, Final Batch Loss: 2.2324891233438393e-06\n",
      "Epoch 2831, Loss: 0.00035502871890003007, Final Batch Loss: 1.3721552249990054e-06\n",
      "Epoch 2832, Loss: 4.884617425204851e-06, Final Batch Loss: 2.697421734865202e-07\n",
      "Epoch 2833, Loss: 6.157517509564059e-05, Final Batch Loss: 3.73922102880897e-06\n",
      "Epoch 2834, Loss: 2.110932837240398e-05, Final Batch Loss: 6.970571121200919e-06\n",
      "Epoch 2835, Loss: 9.527074928428192e-05, Final Batch Loss: 6.717315272908309e-07\n",
      "Epoch 2836, Loss: 5.0742257826641435e-06, Final Batch Loss: 2.9805923986714333e-06\n",
      "Epoch 2837, Loss: 1.2327860190453066e-06, Final Batch Loss: 3.8024938930902863e-07\n",
      "Epoch 2838, Loss: 3.5764745916821994e-05, Final Batch Loss: 1.2244170648045838e-05\n",
      "Epoch 2839, Loss: 7.010673698459868e-06, Final Batch Loss: 2.2248102595767705e-06\n",
      "Epoch 2840, Loss: 6.0351296269800514e-05, Final Batch Loss: 5.216877980274148e-05\n",
      "Epoch 2841, Loss: 2.6213833734800573e-05, Final Batch Loss: 1.2559903552755713e-05\n",
      "Epoch 2842, Loss: 0.00048710974988352973, Final Batch Loss: 1.682561014604289e-05\n",
      "Epoch 2843, Loss: 2.0130746634094976e-05, Final Batch Loss: 7.029010703263339e-06\n",
      "Epoch 2844, Loss: 1.4811569542416692e-05, Final Batch Loss: 3.750273549485428e-07\n",
      "Epoch 2845, Loss: 1.4415055503036456e-05, Final Batch Loss: 1.557547335551135e-07\n",
      "Epoch 2846, Loss: 6.792314059111959e-05, Final Batch Loss: 6.673685129499063e-05\n",
      "Epoch 2847, Loss: 0.00012257095295353793, Final Batch Loss: 3.695443956530653e-05\n",
      "Epoch 2848, Loss: 0.00010578480578260496, Final Batch Loss: 6.187988037709147e-05\n",
      "Epoch 2849, Loss: 0.0001595251615071902, Final Batch Loss: 2.90097468678141e-05\n",
      "Epoch 2850, Loss: 7.421477857860737e-05, Final Batch Loss: 3.314829882583581e-05\n",
      "Epoch 2851, Loss: 0.00023848345881560817, Final Batch Loss: 0.00020352224237285554\n",
      "Epoch 2852, Loss: 5.748532203142531e-05, Final Batch Loss: 2.6904417609330267e-05\n",
      "Epoch 2853, Loss: 0.00010013807695941068, Final Batch Loss: 4.52774838777259e-05\n",
      "Epoch 2854, Loss: 3.3484082848644903e-06, Final Batch Loss: 3.3151681577692216e-07\n",
      "Epoch 2855, Loss: 6.38261579410937e-06, Final Batch Loss: 1.3400111242845014e-07\n",
      "Epoch 2856, Loss: 3.0352732665051008e-05, Final Batch Loss: 4.7539547267660964e-06\n",
      "Epoch 2857, Loss: 5.776905936727417e-06, Final Batch Loss: 4.776998594024917e-06\n",
      "Epoch 2858, Loss: 0.0002632097966852598, Final Batch Loss: 9.970114479074255e-05\n",
      "Epoch 2859, Loss: 2.4779722252787906e-05, Final Batch Loss: 2.219539601355791e-05\n",
      "Epoch 2860, Loss: 1.8627346435096115e-05, Final Batch Loss: 6.493312866950873e-06\n",
      "Epoch 2861, Loss: 1.4698654467792949e-05, Final Batch Loss: 5.3156804824538995e-06\n",
      "Epoch 2862, Loss: 0.00013762939784101036, Final Batch Loss: 2.3316999886446865e-06\n",
      "Epoch 2863, Loss: 1.395227741340932e-05, Final Batch Loss: 1.0550720617175102e-05\n",
      "Epoch 2864, Loss: 0.00013196766303735785, Final Batch Loss: 1.1559935956029221e-05\n",
      "Epoch 2865, Loss: 4.9142746547659044e-05, Final Batch Loss: 4.75754750368651e-05\n",
      "Epoch 2866, Loss: 9.544383374304743e-06, Final Batch Loss: 4.057330897921929e-06\n",
      "Epoch 2867, Loss: 7.156464207014324e-05, Final Batch Loss: 3.515343394155934e-07\n",
      "Epoch 2868, Loss: 1.02663429970562e-05, Final Batch Loss: 6.7893533923779614e-06\n",
      "Epoch 2869, Loss: 0.0001273139158683989, Final Batch Loss: 8.092127927739057e-07\n",
      "Epoch 2870, Loss: 3.525675174387288e-05, Final Batch Loss: 2.88061401079176e-05\n",
      "Epoch 2871, Loss: 1.7133545497927116e-05, Final Batch Loss: 3.3321553019050043e-06\n",
      "Epoch 2872, Loss: 5.208861466599046e-06, Final Batch Loss: 2.7571857117436593e-06\n",
      "Epoch 2873, Loss: 0.00010597084633445775, Final Batch Loss: 1.6288338429149007e-06\n",
      "Epoch 2874, Loss: 5.794169192085974e-05, Final Batch Loss: 1.471882569603622e-05\n",
      "Epoch 2875, Loss: 1.1217382962058764e-05, Final Batch Loss: 1.1381007425370626e-06\n",
      "Epoch 2876, Loss: 1.5674769535678479e-06, Final Batch Loss: 1.5121639762583072e-06\n",
      "Epoch 2877, Loss: 0.00022274845105130225, Final Batch Loss: 0.00014528256724588573\n",
      "Epoch 2878, Loss: 3.3088205782405566e-05, Final Batch Loss: 8.918471394281369e-06\n",
      "Epoch 2879, Loss: 2.632985228956386e-06, Final Batch Loss: 8.535981805835036e-07\n",
      "Epoch 2880, Loss: 0.0005922504458339972, Final Batch Loss: 0.0005894079222343862\n",
      "Epoch 2881, Loss: 9.654547829995863e-05, Final Batch Loss: 3.596087481128052e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2882, Loss: 0.0007113904737252597, Final Batch Loss: 9.205703008774435e-07\n",
      "Epoch 2883, Loss: 0.00014996061872807331, Final Batch Loss: 9.27346627577208e-05\n",
      "Epoch 2884, Loss: 0.00011828022093141044, Final Batch Loss: 0.00011558082769624889\n",
      "Epoch 2885, Loss: 5.824755589856068e-05, Final Batch Loss: 1.4420377738133539e-05\n",
      "Epoch 2886, Loss: 5.683465190031711e-05, Final Batch Loss: 5.588100611930713e-05\n",
      "Epoch 2887, Loss: 3.9920520066516474e-05, Final Batch Loss: 1.0911287972703576e-05\n",
      "Epoch 2888, Loss: 3.098553770541912e-05, Final Batch Loss: 2.1954376279609278e-05\n",
      "Epoch 2889, Loss: 2.700180743886449e-06, Final Batch Loss: 1.0780681805044878e-06\n",
      "Epoch 2890, Loss: 1.8060467141367553e-05, Final Batch Loss: 1.6522895975867868e-06\n",
      "Epoch 2891, Loss: 1.4926774923651465e-05, Final Batch Loss: 3.906876315795671e-07\n",
      "Epoch 2892, Loss: 0.00015214361519610975, Final Batch Loss: 2.251224395877216e-05\n",
      "Epoch 2893, Loss: 0.00020926502293150406, Final Batch Loss: 5.516905730473809e-06\n",
      "Epoch 2894, Loss: 1.993009209400043e-05, Final Batch Loss: 1.1821038242487703e-05\n",
      "Epoch 2895, Loss: 0.0008315939708154474, Final Batch Loss: 0.0008297811727970839\n",
      "Epoch 2896, Loss: 7.102344216036727e-05, Final Batch Loss: 6.961114559089765e-05\n",
      "Epoch 2897, Loss: 1.6673012339651905e-06, Final Batch Loss: 1.2677165841523674e-06\n",
      "Epoch 2898, Loss: 7.232833695525187e-06, Final Batch Loss: 3.3362696285621496e-06\n",
      "Epoch 2899, Loss: 1.6622035900581977e-05, Final Batch Loss: 1.3505317838280462e-05\n",
      "Epoch 2900, Loss: 7.538613772339886e-06, Final Batch Loss: 1.995077127503464e-06\n",
      "Epoch 2901, Loss: 1.9092881302640308e-05, Final Batch Loss: 1.2007205441477709e-05\n",
      "Epoch 2902, Loss: 8.682437986351488e-05, Final Batch Loss: 1.235596158721819e-07\n",
      "Epoch 2903, Loss: 1.700094983903e-06, Final Batch Loss: 1.5723029491709895e-06\n",
      "Epoch 2904, Loss: 0.0005591615026787622, Final Batch Loss: 6.632964868913405e-06\n",
      "Epoch 2905, Loss: 9.687333232477613e-06, Final Batch Loss: 2.1840381236870599e-07\n",
      "Epoch 2906, Loss: 5.092695460007235e-06, Final Batch Loss: 1.3190730214773794e-06\n",
      "Epoch 2907, Loss: 0.0002240630055894144, Final Batch Loss: 0.00013331159425433725\n",
      "Epoch 2908, Loss: 2.0189211682009045e-05, Final Batch Loss: 4.379814527055714e-06\n",
      "Epoch 2909, Loss: 7.023661623861699e-06, Final Batch Loss: 6.858676442789147e-06\n",
      "Epoch 2910, Loss: 1.455830721397433e-05, Final Batch Loss: 1.3957504961581435e-05\n",
      "Epoch 2911, Loss: 5.358404617084034e-05, Final Batch Loss: 1.3139090526692598e-07\n",
      "Epoch 2912, Loss: 2.2083695057517616e-05, Final Batch Loss: 6.227749963727547e-06\n",
      "Epoch 2913, Loss: 0.0001053644282364985, Final Batch Loss: 2.9395005185506307e-05\n",
      "Epoch 2914, Loss: 3.0593699875680613e-06, Final Batch Loss: 2.9062505291221896e-07\n",
      "Epoch 2915, Loss: 3.876012431192066e-05, Final Batch Loss: 1.5200306506812922e-06\n",
      "Epoch 2916, Loss: 8.011006758579242e-05, Final Batch Loss: 5.725440246351354e-07\n",
      "Epoch 2917, Loss: 3.96003492824093e-05, Final Batch Loss: 3.500363527564332e-05\n",
      "Epoch 2918, Loss: 0.0004339888309914386, Final Batch Loss: 2.6909305233857594e-05\n",
      "Epoch 2919, Loss: 0.005178374875640657, Final Batch Loss: 0.0051763299852609634\n",
      "Epoch 2920, Loss: 1.3375018625083612e-05, Final Batch Loss: 6.550923899339978e-06\n",
      "Epoch 2921, Loss: 1.46609500006889e-05, Final Batch Loss: 1.0578080946288537e-05\n",
      "Epoch 2922, Loss: 0.00020350466365925968, Final Batch Loss: 3.797105455305427e-05\n",
      "Epoch 2923, Loss: 1.4059988188819261e-05, Final Batch Loss: 2.068189587589586e-06\n",
      "Epoch 2924, Loss: 3.188858681824058e-05, Final Batch Loss: 2.594596844573971e-05\n",
      "Epoch 2925, Loss: 7.907480983249116e-05, Final Batch Loss: 4.646507250072318e-07\n",
      "Epoch 2926, Loss: 8.113971034617862e-06, Final Batch Loss: 7.535068107245024e-07\n",
      "Epoch 2927, Loss: 5.798864492589928e-06, Final Batch Loss: 8.144347134475538e-07\n",
      "Epoch 2928, Loss: 0.00011672215259750374, Final Batch Loss: 6.334621866699308e-05\n",
      "Epoch 2929, Loss: 0.0001725701581563044, Final Batch Loss: 4.348650236352114e-06\n",
      "Epoch 2930, Loss: 1.4208756056177663e-05, Final Batch Loss: 5.9249373407510575e-06\n",
      "Epoch 2931, Loss: 3.7401981671791873e-06, Final Batch Loss: 1.209465267493215e-06\n",
      "Epoch 2932, Loss: 7.939104671095265e-05, Final Batch Loss: 5.569464519794565e-06\n",
      "Epoch 2933, Loss: 1.766988907547784e-05, Final Batch Loss: 6.686541837552795e-06\n",
      "Epoch 2934, Loss: 1.950809206618942e-06, Final Batch Loss: 1.5626729918949422e-06\n",
      "Epoch 2935, Loss: 2.1967094880892546e-06, Final Batch Loss: 1.36083713186963e-06\n",
      "Epoch 2936, Loss: 3.1185880970951985e-06, Final Batch Loss: 2.465816805852228e-06\n",
      "Epoch 2937, Loss: 0.0004261189026237844, Final Batch Loss: 2.0228910670994082e-06\n",
      "Epoch 2938, Loss: 5.929607823418337e-06, Final Batch Loss: 3.5583298085839488e-06\n",
      "Epoch 2939, Loss: 1.1275557994849805e-05, Final Batch Loss: 1.0301880138285924e-05\n",
      "Epoch 2940, Loss: 0.00022393852623281418, Final Batch Loss: 4.749313575302949e-06\n",
      "Epoch 2941, Loss: 0.000189848961220207, Final Batch Loss: 1.009360701687001e-07\n",
      "Epoch 2942, Loss: 1.0334168109693564e-05, Final Batch Loss: 9.519281775283162e-06\n",
      "Epoch 2943, Loss: 4.694503422797425e-05, Final Batch Loss: 3.7447251088451594e-05\n",
      "Epoch 2944, Loss: 7.486719823646126e-06, Final Batch Loss: 3.3121009437309112e-06\n",
      "Epoch 2945, Loss: 8.297032115933689e-05, Final Batch Loss: 1.1354794651197153e-06\n",
      "Epoch 2946, Loss: 0.002570725735040469, Final Batch Loss: 1.7296893020102289e-06\n",
      "Epoch 2947, Loss: 3.831683613952919e-06, Final Batch Loss: 9.275269690078858e-07\n",
      "Epoch 2948, Loss: 0.00038919334201636957, Final Batch Loss: 0.0003774876531679183\n",
      "Epoch 2949, Loss: 1.1440415391916758e-05, Final Batch Loss: 2.0750910607603146e-06\n",
      "Epoch 2950, Loss: 4.8908072130871005e-05, Final Batch Loss: 2.7048332412960008e-05\n",
      "Epoch 2951, Loss: 3.680905308556248e-06, Final Batch Loss: 4.550772132461134e-07\n",
      "Epoch 2952, Loss: 1.030244015964854e-05, Final Batch Loss: 8.229959348682314e-06\n",
      "Epoch 2953, Loss: 6.003154885547701e-05, Final Batch Loss: 3.339870090712793e-06\n",
      "Epoch 2954, Loss: 0.0001549980529489403, Final Batch Loss: 3.9535239011456724e-06\n",
      "Epoch 2955, Loss: 3.0128691292929943e-06, Final Batch Loss: 8.179303279121086e-08\n",
      "Epoch 2956, Loss: 3.527244388124018e-06, Final Batch Loss: 2.4624861794109165e-07\n",
      "Epoch 2957, Loss: 0.00016957424645624997, Final Batch Loss: 1.0110595667356392e-06\n",
      "Epoch 2958, Loss: 7.408009014397976e-05, Final Batch Loss: 7.578710665256949e-06\n",
      "Epoch 2959, Loss: 0.003953146364437998, Final Batch Loss: 0.003936085384339094\n",
      "Epoch 2960, Loss: 0.00011516673441747116, Final Batch Loss: 0.00011446198914200068\n",
      "Epoch 2961, Loss: 5.511793642654084e-05, Final Batch Loss: 3.2533160265302286e-05\n",
      "Epoch 2962, Loss: 0.0007899415026599854, Final Batch Loss: 4.289717594474496e-07\n",
      "Epoch 2963, Loss: 3.103474773524795e-05, Final Batch Loss: 1.8665754396351986e-05\n",
      "Epoch 2964, Loss: 0.0030226968228816986, Final Batch Loss: 0.0002759143244475126\n",
      "Epoch 2965, Loss: 7.58343289817276e-05, Final Batch Loss: 7.395340071525425e-05\n",
      "Epoch 2966, Loss: 0.00040009649283945237, Final Batch Loss: 1.4618318289194576e-07\n",
      "Epoch 2967, Loss: 3.085091722709876e-05, Final Batch Loss: 1.5140378195610538e-07\n",
      "Epoch 2968, Loss: 4.1138487176795024e-06, Final Batch Loss: 1.3304195363161853e-06\n",
      "Epoch 2969, Loss: 2.6382018347703706e-05, Final Batch Loss: 7.587386221530323e-07\n",
      "Epoch 2970, Loss: 9.008009979538656e-05, Final Batch Loss: 8.977588004199788e-05\n",
      "Epoch 2971, Loss: 5.363896946164459e-06, Final Batch Loss: 4.0548007973484346e-07\n",
      "Epoch 2972, Loss: 0.0002610214281029144, Final Batch Loss: 8.701406706279613e-09\n",
      "Epoch 2973, Loss: 0.00020115000438636343, Final Batch Loss: 3.595167754610884e-06\n",
      "Epoch 2974, Loss: 0.0005835427781448743, Final Batch Loss: 0.0005817547207698226\n",
      "Epoch 2975, Loss: 5.344734518075711e-06, Final Batch Loss: 4.6771842789894436e-06\n",
      "Epoch 2976, Loss: 2.1565672227552568e-05, Final Batch Loss: 2.1753419332526391e-07\n",
      "Epoch 2977, Loss: 2.7506841888680356e-06, Final Batch Loss: 6.090840543038212e-07\n",
      "Epoch 2978, Loss: 0.00013143811793270288, Final Batch Loss: 0.00012998864986002445\n",
      "Epoch 2979, Loss: 8.820660923447576e-05, Final Batch Loss: 4.584268481266918e-06\n",
      "Epoch 2980, Loss: 1.4499944654744468e-05, Final Batch Loss: 1.1714465472323354e-05\n",
      "Epoch 2981, Loss: 0.00012402268839650787, Final Batch Loss: 6.653602031292394e-05\n",
      "Epoch 2982, Loss: 7.189298912635422e-06, Final Batch Loss: 4.0274780985782854e-06\n",
      "Epoch 2983, Loss: 3.897885744663654e-05, Final Batch Loss: 7.613443813170306e-07\n",
      "Epoch 2984, Loss: 0.0003039495255734437, Final Batch Loss: 1.382582581754832e-06\n",
      "Epoch 2985, Loss: 1.976973436512708e-06, Final Batch Loss: 4.39416140807225e-07\n",
      "Epoch 2986, Loss: 1.7593542906979565e-05, Final Batch Loss: 2.6057969080284238e-06\n",
      "Epoch 2987, Loss: 0.008199293196412327, Final Batch Loss: 0.008190833032131195\n",
      "Epoch 2988, Loss: 6.496072728623403e-05, Final Batch Loss: 5.418956425273791e-05\n",
      "Epoch 2989, Loss: 8.367762893612962e-05, Final Batch Loss: 6.201959331519902e-05\n",
      "Epoch 2990, Loss: 0.0005076441382243502, Final Batch Loss: 0.00050433783326298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2991, Loss: 0.017265250207856297, Final Batch Loss: 0.0023268035147339106\n",
      "Epoch 2992, Loss: 0.00042350626608822495, Final Batch Loss: 0.00021767646830994636\n",
      "Epoch 2993, Loss: 0.003040843155758921, Final Batch Loss: 0.0030092124361544847\n",
      "Epoch 2994, Loss: 1.546877638247679e-05, Final Batch Loss: 8.419693585892674e-06\n",
      "Epoch 2995, Loss: 0.00011927829791602562, Final Batch Loss: 0.00011794798047048971\n",
      "Epoch 2996, Loss: 0.005516071320016636, Final Batch Loss: 0.005499721970409155\n",
      "Epoch 2997, Loss: 0.0005552719740080647, Final Batch Loss: 0.0005170355434529483\n",
      "Epoch 2998, Loss: 0.00015783078015374485, Final Batch Loss: 1.0340556400478818e-05\n",
      "Epoch 2999, Loss: 4.383522923490091e-05, Final Batch Loss: 2.80948029285355e-06\n",
      "Epoch 3000, Loss: 9.068831059266813e-05, Final Batch Loss: 3.7006269849371165e-05\n",
      "Epoch 3001, Loss: 3.621651922003366e-05, Final Batch Loss: 1.3104410754749551e-05\n",
      "Epoch 3002, Loss: 0.0003411298368973803, Final Batch Loss: 2.2414008071791613e-06\n",
      "Epoch 3003, Loss: 0.00034114632035198156, Final Batch Loss: 0.00033534460817463696\n",
      "Epoch 3004, Loss: 0.00020832443988183513, Final Batch Loss: 4.042874934384599e-05\n",
      "Epoch 3005, Loss: 4.644633236239315e-06, Final Batch Loss: 1.1841943887702655e-06\n",
      "Epoch 3006, Loss: 0.0004097059920695756, Final Batch Loss: 1.3339069937501336e-06\n",
      "Epoch 3007, Loss: 0.00010845771612366661, Final Batch Loss: 9.606024832464755e-05\n",
      "Epoch 3008, Loss: 0.00017994654490394169, Final Batch Loss: 3.7243066799419466e-06\n",
      "Epoch 3009, Loss: 1.0039774110737198e-05, Final Batch Loss: 1.2825415751649416e-06\n",
      "Epoch 3010, Loss: 4.5780253458360676e-05, Final Batch Loss: 1.0900709639827255e-05\n",
      "Epoch 3011, Loss: 0.0024031584473505063, Final Batch Loss: 2.6903437628789106e-06\n",
      "Epoch 3012, Loss: 0.00012720128233922878, Final Batch Loss: 0.00012149639951530844\n",
      "Epoch 3013, Loss: 3.95320976167568e-05, Final Batch Loss: 4.826310942007694e-06\n",
      "Epoch 3014, Loss: 0.00011212458957743365, Final Batch Loss: 0.0001097592175938189\n",
      "Epoch 3015, Loss: 7.843771891202778e-05, Final Batch Loss: 1.059158967109397e-05\n",
      "Epoch 3016, Loss: 7.384209493466187e-05, Final Batch Loss: 2.631855932122562e-05\n",
      "Epoch 3017, Loss: 5.183775516570677e-05, Final Batch Loss: 7.491640303669556e-07\n",
      "Epoch 3018, Loss: 0.00014615334293921478, Final Batch Loss: 9.47407097555697e-05\n",
      "Epoch 3019, Loss: 3.5137123177264584e-05, Final Batch Loss: 5.908182174607646e-07\n",
      "Epoch 3020, Loss: 6.600747110496741e-05, Final Batch Loss: 2.7886029783985578e-05\n",
      "Epoch 3021, Loss: 0.00012766818622367282, Final Batch Loss: 0.000125602658954449\n",
      "Epoch 3022, Loss: 2.8217327781021595e-05, Final Batch Loss: 1.3194082384870853e-05\n",
      "Epoch 3023, Loss: 0.0001554349660182197, Final Batch Loss: 6.987357210164191e-06\n",
      "Epoch 3024, Loss: 4.54723704024218e-05, Final Batch Loss: 2.7572043109103106e-05\n",
      "Epoch 3025, Loss: 0.06565254924498731, Final Batch Loss: 1.495329343015328e-05\n",
      "Epoch 3026, Loss: 8.613293357484508e-05, Final Batch Loss: 2.974438939418178e-05\n",
      "Epoch 3027, Loss: 0.0005391910999605898, Final Batch Loss: 5.560354111366905e-05\n",
      "Epoch 3028, Loss: 2.2175605863594683e-05, Final Batch Loss: 1.808566776162479e-05\n",
      "Epoch 3029, Loss: 8.118196433315461e-06, Final Batch Loss: 1.498330561844341e-06\n",
      "Epoch 3030, Loss: 3.693024700623937e-05, Final Batch Loss: 1.8701834051171318e-05\n",
      "Epoch 3031, Loss: 9.26900847844081e-05, Final Batch Loss: 8.159216667991132e-05\n",
      "Epoch 3032, Loss: 9.561266233504284e-05, Final Batch Loss: 8.696073564351536e-06\n",
      "Epoch 3033, Loss: 2.1455359274114016e-05, Final Batch Loss: 1.2686880836554337e-05\n",
      "Epoch 3034, Loss: 0.00015509222203036188, Final Batch Loss: 5.463230536406627e-06\n",
      "Epoch 3035, Loss: 0.0002870739590434823, Final Batch Loss: 0.00025279284454882145\n",
      "Epoch 3036, Loss: 7.652548083569854e-05, Final Batch Loss: 3.1989493436412886e-05\n",
      "Epoch 3037, Loss: 4.004563061243971e-05, Final Batch Loss: 7.339735475397902e-06\n",
      "Epoch 3038, Loss: 0.0001042099474943825, Final Batch Loss: 6.253075298445765e-06\n",
      "Epoch 3039, Loss: 8.463858421237092e-06, Final Batch Loss: 3.342725221955334e-06\n",
      "Epoch 3040, Loss: 0.0001407322743034456, Final Batch Loss: 5.538547338801436e-05\n",
      "Epoch 3041, Loss: 2.3921864794829162e-05, Final Batch Loss: 5.555938059842447e-06\n",
      "Epoch 3042, Loss: 0.0004704392358689802, Final Batch Loss: 2.0795328964595683e-05\n",
      "Epoch 3043, Loss: 4.119151435588719e-05, Final Batch Loss: 7.008974534983281e-06\n",
      "Epoch 3044, Loss: 0.000277615381492069, Final Batch Loss: 0.0002435596688883379\n",
      "Epoch 3045, Loss: 2.715353934945597e-05, Final Batch Loss: 1.1816284768428886e-06\n",
      "Epoch 3046, Loss: 3.173671029799152e-05, Final Batch Loss: 2.0377534383442253e-05\n",
      "Epoch 3047, Loss: 1.5473713574465364e-05, Final Batch Loss: 6.31420061836252e-06\n",
      "Epoch 3048, Loss: 6.588346150238067e-05, Final Batch Loss: 5.664596756105311e-05\n",
      "Epoch 3049, Loss: 0.0010166732827201486, Final Batch Loss: 0.000144116987939924\n",
      "Epoch 3050, Loss: 0.00019924873777199537, Final Batch Loss: 7.011705019976944e-05\n",
      "Epoch 3051, Loss: 6.61380199744599e-05, Final Batch Loss: 2.621718704176601e-05\n",
      "Epoch 3052, Loss: 8.923742370825494e-06, Final Batch Loss: 2.989585937029915e-06\n",
      "Epoch 3053, Loss: 1.884417542896699e-05, Final Batch Loss: 1.0114556062035263e-05\n",
      "Epoch 3054, Loss: 0.00011115579764009453, Final Batch Loss: 3.154346995870583e-05\n",
      "Epoch 3055, Loss: 7.829517653590301e-05, Final Batch Loss: 6.983382627367973e-05\n",
      "Epoch 3056, Loss: 8.850472659105435e-05, Final Batch Loss: 2.805395342875272e-05\n",
      "Epoch 3057, Loss: 9.361744832858676e-05, Final Batch Loss: 8.551094651920721e-05\n",
      "Epoch 3058, Loss: 3.5952881262346637e-05, Final Batch Loss: 2.6607112886267714e-06\n",
      "Epoch 3059, Loss: 0.006465342565206811, Final Batch Loss: 0.006423747632652521\n",
      "Epoch 3060, Loss: 0.00018302884063814417, Final Batch Loss: 3.7544837141467724e-06\n",
      "Epoch 3061, Loss: 1.1923205192942987e-05, Final Batch Loss: 1.783754441930796e-06\n",
      "Epoch 3062, Loss: 0.002956212642857281, Final Batch Loss: 7.099383765307721e-06\n",
      "Epoch 3063, Loss: 6.156038762128446e-05, Final Batch Loss: 2.5515104425721802e-05\n",
      "Epoch 3064, Loss: 6.001838846714236e-05, Final Batch Loss: 2.908100577769801e-05\n",
      "Epoch 3065, Loss: 2.015421250689542e-05, Final Batch Loss: 1.0220519470749423e-05\n",
      "Epoch 3066, Loss: 0.00013421173935057595, Final Batch Loss: 0.00010001680493587628\n",
      "Epoch 3067, Loss: 0.005310288510372629, Final Batch Loss: 0.005285854451358318\n",
      "Epoch 3068, Loss: 3.739489693543874e-05, Final Batch Loss: 1.5627729226252995e-05\n",
      "Epoch 3069, Loss: 2.1344830201996956e-05, Final Batch Loss: 2.1778896552859806e-06\n",
      "Epoch 3070, Loss: 2.6202656044915784e-05, Final Batch Loss: 1.4348466720548458e-05\n",
      "Epoch 3071, Loss: 0.0001542297195555875, Final Batch Loss: 1.8098371583619155e-05\n",
      "Epoch 3072, Loss: 0.0004076722834724933, Final Batch Loss: 8.927247836254537e-05\n",
      "Epoch 3073, Loss: 0.00017416197442798875, Final Batch Loss: 3.4853783290600404e-05\n",
      "Epoch 3074, Loss: 3.498644628052716e-05, Final Batch Loss: 5.187123406358296e-06\n",
      "Epoch 3075, Loss: 5.3932435548631474e-05, Final Batch Loss: 3.456913691479713e-05\n",
      "Epoch 3076, Loss: 0.00032717211433919147, Final Batch Loss: 0.00031028318335302174\n",
      "Epoch 3077, Loss: 0.0003557238742359914, Final Batch Loss: 0.0002597613201942295\n",
      "Epoch 3078, Loss: 0.00023288892771233805, Final Batch Loss: 2.773137020994909e-05\n",
      "Epoch 3079, Loss: 1.6827167200972326e-05, Final Batch Loss: 7.12044675310608e-06\n",
      "Epoch 3080, Loss: 0.000567557487556769, Final Batch Loss: 1.0179727723880205e-05\n",
      "Epoch 3081, Loss: 7.976477718329988e-05, Final Batch Loss: 6.253328319871798e-05\n",
      "Epoch 3082, Loss: 3.5759673664870206e-05, Final Batch Loss: 8.587040611018892e-06\n",
      "Epoch 3083, Loss: 0.0001203970386995934, Final Batch Loss: 6.847189069958404e-05\n",
      "Epoch 3084, Loss: 7.079701026668772e-05, Final Batch Loss: 4.0180362702813e-05\n",
      "Epoch 3085, Loss: 0.0012220708740642294, Final Batch Loss: 0.0010626439470797777\n",
      "Epoch 3086, Loss: 0.00033488569170003757, Final Batch Loss: 0.00032166202436201274\n",
      "Epoch 3087, Loss: 5.651858418787015e-05, Final Batch Loss: 4.997810174245387e-05\n",
      "Epoch 3088, Loss: 2.1143693857084145e-05, Final Batch Loss: 1.949103534570895e-05\n",
      "Epoch 3089, Loss: 0.00017886071873363107, Final Batch Loss: 0.00014552690845448524\n",
      "Epoch 3090, Loss: 4.652675397665007e-05, Final Batch Loss: 3.479270890238695e-05\n",
      "Epoch 3091, Loss: 0.0006244946707738563, Final Batch Loss: 1.653707295190543e-05\n",
      "Epoch 3092, Loss: 9.317004787590122e-05, Final Batch Loss: 7.75990974943852e-06\n",
      "Epoch 3093, Loss: 0.0001477374107707874, Final Batch Loss: 6.053619472368155e-06\n",
      "Epoch 3094, Loss: 0.0006340560057651601, Final Batch Loss: 0.0006239367066882551\n",
      "Epoch 3095, Loss: 5.3501675893130596e-05, Final Batch Loss: 1.4513668702420546e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3096, Loss: 7.753669342491776e-05, Final Batch Loss: 3.949694655602798e-05\n",
      "Epoch 3097, Loss: 0.007902131619630381, Final Batch Loss: 0.00034764522570185363\n",
      "Epoch 3098, Loss: 8.35526673199638e-05, Final Batch Loss: 1.4165063930704491e-06\n",
      "Epoch 3099, Loss: 3.196821762685431e-05, Final Batch Loss: 1.4326599739433732e-05\n",
      "Epoch 3100, Loss: 0.0004606969087035395, Final Batch Loss: 0.00011570819333428517\n",
      "Epoch 3101, Loss: 5.4369108056562254e-05, Final Batch Loss: 4.789263039128855e-05\n",
      "Epoch 3102, Loss: 2.5069315825021476e-05, Final Batch Loss: 2.886883748942637e-06\n",
      "Epoch 3103, Loss: 0.00015252873038207326, Final Batch Loss: 0.00015102913312148303\n",
      "Epoch 3104, Loss: 0.0006856236850580899, Final Batch Loss: 0.0006793365464545786\n",
      "Epoch 3105, Loss: 2.6842806619242765e-05, Final Batch Loss: 2.0708594092866406e-06\n",
      "Epoch 3106, Loss: 1.5389149893962895e-05, Final Batch Loss: 1.3654963368026074e-05\n",
      "Epoch 3107, Loss: 7.613552952534519e-06, Final Batch Loss: 3.330494109832216e-06\n",
      "Epoch 3108, Loss: 1.257561359579995e-05, Final Batch Loss: 1.07662262962549e-05\n",
      "Epoch 3109, Loss: 0.0008798039383464129, Final Batch Loss: 6.856611207695096e-07\n",
      "Epoch 3110, Loss: 0.00745651607576292, Final Batch Loss: 3.323021519463509e-05\n",
      "Epoch 3111, Loss: 3.0578710138229326e-05, Final Batch Loss: 1.86209362595946e-07\n",
      "Epoch 3112, Loss: 0.00011865722990478389, Final Batch Loss: 0.00010552468302194029\n",
      "Epoch 3113, Loss: 0.00023606399554410018, Final Batch Loss: 0.0002316573663847521\n",
      "Epoch 3114, Loss: 0.00011312798278595437, Final Batch Loss: 0.00010985397238982841\n",
      "Epoch 3115, Loss: 2.938432680821279e-05, Final Batch Loss: 7.648147402505856e-06\n",
      "Epoch 3116, Loss: 1.6930641322687734e-05, Final Batch Loss: 1.2262282325536944e-05\n",
      "Epoch 3117, Loss: 1.7223875829586177e-05, Final Batch Loss: 1.4698031009174883e-05\n",
      "Epoch 3118, Loss: 8.673687625559978e-05, Final Batch Loss: 5.114929808769375e-05\n",
      "Epoch 3119, Loss: 9.01097464520717e-05, Final Batch Loss: 6.47048291284591e-05\n",
      "Epoch 3120, Loss: 0.0005231661421021272, Final Batch Loss: 4.805268417840125e-06\n",
      "Epoch 3121, Loss: 0.00028736525109707145, Final Batch Loss: 0.00027752568712458014\n",
      "Epoch 3122, Loss: 7.71192782167418e-06, Final Batch Loss: 6.908469913469162e-06\n",
      "Epoch 3123, Loss: 1.6030399365263293e-05, Final Batch Loss: 9.353839232062455e-07\n",
      "Epoch 3124, Loss: 0.0003395939929760061, Final Batch Loss: 0.00028109867707826197\n",
      "Epoch 3125, Loss: 7.958272902897079e-06, Final Batch Loss: 2.897555475556146e-07\n",
      "Epoch 3126, Loss: 4.280427637581852e-05, Final Batch Loss: 3.645869526280876e-07\n",
      "Epoch 3127, Loss: 6.858786809971207e-05, Final Batch Loss: 6.467822822742164e-05\n",
      "Epoch 3128, Loss: 0.0004822532464459073, Final Batch Loss: 4.308409916120581e-05\n",
      "Epoch 3129, Loss: 6.492647571576526e-06, Final Batch Loss: 2.423205842205789e-06\n",
      "Epoch 3130, Loss: 0.00029399720961009734, Final Batch Loss: 0.0002883898268919438\n",
      "Epoch 3131, Loss: 5.482258336542145e-05, Final Batch Loss: 5.307408355292864e-05\n",
      "Epoch 3132, Loss: 6.6650962253334e-05, Final Batch Loss: 9.294340998167172e-06\n",
      "Epoch 3133, Loss: 0.00021809169447806198, Final Batch Loss: 3.2472180464537814e-06\n",
      "Epoch 3134, Loss: 0.00014490686953649856, Final Batch Loss: 9.329846943728626e-05\n",
      "Epoch 3135, Loss: 0.00030864579321132624, Final Batch Loss: 0.00030293044983409345\n",
      "Epoch 3136, Loss: 7.15470483783065e-05, Final Batch Loss: 7.021916098892689e-05\n",
      "Epoch 3137, Loss: 5.769563722424209e-05, Final Batch Loss: 3.380042107892223e-05\n",
      "Epoch 3138, Loss: 0.001369444351439597, Final Batch Loss: 0.0013375674607232213\n",
      "Epoch 3139, Loss: 2.4753906700425432e-05, Final Batch Loss: 2.0577356281137327e-06\n",
      "Epoch 3140, Loss: 1.654399679296148e-05, Final Batch Loss: 2.8018152420372644e-07\n",
      "Epoch 3141, Loss: 7.472563538613031e-06, Final Batch Loss: 3.8376738302758895e-06\n",
      "Epoch 3142, Loss: 0.00017886715227177774, Final Batch Loss: 2.095957597703091e-06\n",
      "Epoch 3143, Loss: 5.42382690582599e-06, Final Batch Loss: 3.3965254715440096e-06\n",
      "Epoch 3144, Loss: 0.00016986147238640115, Final Batch Loss: 2.5459863536525518e-05\n",
      "Epoch 3145, Loss: 7.267150067491457e-06, Final Batch Loss: 1.0145522537641227e-06\n",
      "Epoch 3146, Loss: 0.00010455458240699045, Final Batch Loss: 4.7248167334146274e-07\n",
      "Epoch 3147, Loss: 3.2050467780209146e-05, Final Batch Loss: 1.955389052454848e-05\n",
      "Epoch 3148, Loss: 0.0002349884143768577, Final Batch Loss: 0.0002251259284093976\n",
      "Epoch 3149, Loss: 0.0002289985766310565, Final Batch Loss: 3.601051275836653e-06\n",
      "Epoch 3150, Loss: 2.2648543790637632e-05, Final Batch Loss: 2.0633116946555674e-05\n",
      "Epoch 3151, Loss: 0.000709000061306142, Final Batch Loss: 0.0007075468311086297\n",
      "Epoch 3152, Loss: 1.5667621084958228e-06, Final Batch Loss: 4.6290827526718203e-07\n",
      "Epoch 3153, Loss: 0.00010821125670190668, Final Batch Loss: 1.0574897714832332e-05\n",
      "Epoch 3154, Loss: 9.102613603317877e-06, Final Batch Loss: 1.0180433491768781e-06\n",
      "Epoch 3155, Loss: 8.804699700704077e-05, Final Batch Loss: 1.2592398888955358e-05\n",
      "Epoch 3156, Loss: 0.00010376244574672455, Final Batch Loss: 9.571009513820172e-07\n",
      "Epoch 3157, Loss: 0.00011896774617525807, Final Batch Loss: 0.00011595492105698213\n",
      "Epoch 3158, Loss: 2.11294042173904e-06, Final Batch Loss: 5.977704518045357e-07\n",
      "Epoch 3159, Loss: 1.0938616469502449e-05, Final Batch Loss: 4.172764874965651e-06\n",
      "Epoch 3160, Loss: 0.00014182798713591183, Final Batch Loss: 1.3328784007171635e-05\n",
      "Epoch 3161, Loss: 0.00012561115818243707, Final Batch Loss: 3.2260004445561208e-06\n",
      "Epoch 3162, Loss: 2.3904753589931715e-06, Final Batch Loss: 6.700061305764393e-08\n",
      "Epoch 3163, Loss: 9.05872911971528e-06, Final Batch Loss: 3.176770860591205e-06\n",
      "Epoch 3164, Loss: 7.978488065418787e-05, Final Batch Loss: 4.909079143544659e-05\n",
      "Epoch 3165, Loss: 0.0007838979290681891, Final Batch Loss: 5.100253474665806e-05\n",
      "Epoch 3166, Loss: 0.0024255682656075805, Final Batch Loss: 4.1936145862564445e-05\n",
      "Epoch 3167, Loss: 2.8787694645870943e-05, Final Batch Loss: 1.8263914171257056e-05\n",
      "Epoch 3168, Loss: 1.5874345649535826e-05, Final Batch Loss: 1.6052978253355832e-06\n",
      "Epoch 3169, Loss: 2.7522842628968647e-05, Final Batch Loss: 6.940895673324121e-06\n",
      "Epoch 3170, Loss: 8.996218275569845e-05, Final Batch Loss: 6.647930422332138e-05\n",
      "Epoch 3171, Loss: 0.00010832858242793009, Final Batch Loss: 9.026657062349841e-05\n",
      "Epoch 3172, Loss: 0.0007525852161052171, Final Batch Loss: 3.454179750406183e-05\n",
      "Epoch 3173, Loss: 3.3902720133482944e-05, Final Batch Loss: 4.267270014679525e-06\n",
      "Epoch 3174, Loss: 1.576323347762809e-05, Final Batch Loss: 7.436929536197567e-06\n",
      "Epoch 3175, Loss: 2.2595186237595044e-05, Final Batch Loss: 1.0077630577143282e-05\n",
      "Epoch 3176, Loss: 0.0007277916229213588, Final Batch Loss: 0.000664277991745621\n",
      "Epoch 3177, Loss: 6.4124518246444495e-06, Final Batch Loss: 1.218193972363224e-07\n",
      "Epoch 3178, Loss: 0.0002211803657701239, Final Batch Loss: 0.000211967111681588\n",
      "Epoch 3179, Loss: 9.541174222249538e-05, Final Batch Loss: 4.323889152146876e-05\n",
      "Epoch 3180, Loss: 0.0001026251120492816, Final Batch Loss: 8.613359386799857e-05\n",
      "Epoch 3181, Loss: 0.0011161693446410936, Final Batch Loss: 7.944491699163336e-06\n",
      "Epoch 3182, Loss: 9.793688604986528e-06, Final Batch Loss: 5.141844667377882e-06\n",
      "Epoch 3183, Loss: 2.5218902692358824e-05, Final Batch Loss: 2.2474839624919696e-06\n",
      "Epoch 3184, Loss: 0.00010584118808765197, Final Batch Loss: 9.896740084514022e-05\n",
      "Epoch 3185, Loss: 4.924843210574181e-06, Final Batch Loss: 3.304145820948179e-06\n",
      "Epoch 3186, Loss: 6.231987208593637e-05, Final Batch Loss: 2.7442067221272737e-05\n",
      "Epoch 3187, Loss: 1.2435269582056208e-05, Final Batch Loss: 1.1472567166492809e-05\n",
      "Epoch 3188, Loss: 2.3244630256158416e-06, Final Batch Loss: 4.968444500264013e-07\n",
      "Epoch 3189, Loss: 0.00034854450495913625, Final Batch Loss: 8.352324948646128e-05\n",
      "Epoch 3190, Loss: 1.1026323022633733e-05, Final Batch Loss: 3.5588561786426e-07\n",
      "Epoch 3191, Loss: 0.00016691592736606253, Final Batch Loss: 5.616096132143866e-06\n",
      "Epoch 3192, Loss: 0.00011858591642521787, Final Batch Loss: 2.0115558072575368e-05\n",
      "Epoch 3193, Loss: 3.0867384339217097e-05, Final Batch Loss: 2.1541960450122133e-05\n",
      "Epoch 3194, Loss: 2.289914277753269e-05, Final Batch Loss: 2.0125078663113527e-05\n",
      "Epoch 3195, Loss: 1.3173854654269235e-05, Final Batch Loss: 1.0589404837446637e-06\n",
      "Epoch 3196, Loss: 0.0012852330110035837, Final Batch Loss: 4.340446321293712e-05\n",
      "Epoch 3197, Loss: 1.5566878118988825e-05, Final Batch Loss: 1.6679719010426197e-06\n",
      "Epoch 3198, Loss: 1.5698383776907576e-05, Final Batch Loss: 7.307177384063834e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3199, Loss: 5.441846042231191e-05, Final Batch Loss: 2.771515937638469e-05\n",
      "Epoch 3200, Loss: 8.437424412477412e-05, Final Batch Loss: 7.950108556542546e-05\n",
      "Epoch 3201, Loss: 0.0003476474666967988, Final Batch Loss: 0.00023260120360646397\n",
      "Epoch 3202, Loss: 0.001359882007818669, Final Batch Loss: 7.535639451816678e-05\n",
      "Epoch 3203, Loss: 4.126321800868027e-05, Final Batch Loss: 3.668192948680371e-05\n",
      "Epoch 3204, Loss: 1.1850627117837575e-05, Final Batch Loss: 6.395351306309749e-07\n",
      "Epoch 3205, Loss: 0.000960722922172863, Final Batch Loss: 0.000927909801248461\n",
      "Epoch 3206, Loss: 8.625883674540091e-05, Final Batch Loss: 1.3886246961192228e-05\n",
      "Epoch 3207, Loss: 6.049503053873195e-05, Final Batch Loss: 5.498312020790763e-05\n",
      "Epoch 3208, Loss: 3.062077576032607e-05, Final Batch Loss: 2.291115015395917e-05\n",
      "Epoch 3209, Loss: 4.162558434472885e-05, Final Batch Loss: 1.3442166164168157e-05\n",
      "Epoch 3210, Loss: 0.00042380159925414773, Final Batch Loss: 1.372160340906703e-06\n",
      "Epoch 3211, Loss: 4.26761375820206e-05, Final Batch Loss: 5.382198196457466e-06\n",
      "Epoch 3212, Loss: 2.269944275212765e-06, Final Batch Loss: 2.60170395449677e-07\n",
      "Epoch 3213, Loss: 1.9598529888753546e-05, Final Batch Loss: 4.0927402551460546e-06\n",
      "Epoch 3214, Loss: 9.579405377735384e-05, Final Batch Loss: 2.1411276975413784e-05\n",
      "Epoch 3215, Loss: 0.00026503096876240306, Final Batch Loss: 0.00026335593429394066\n",
      "Epoch 3216, Loss: 0.00018506227752368432, Final Batch Loss: 6.291591489571147e-06\n",
      "Epoch 3217, Loss: 1.943033203133382e-05, Final Batch Loss: 3.964694769820198e-06\n",
      "Epoch 3218, Loss: 4.015491504105739e-05, Final Batch Loss: 3.144340735161677e-05\n",
      "Epoch 3219, Loss: 7.483680383302271e-05, Final Batch Loss: 5.098415931570344e-05\n",
      "Epoch 3220, Loss: 2.094311503242352e-05, Final Batch Loss: 5.334683464752743e-06\n",
      "Epoch 3221, Loss: 1.4327762755783624e-05, Final Batch Loss: 1.1968585567956325e-05\n",
      "Epoch 3222, Loss: 0.0005869540182175115, Final Batch Loss: 0.00035344570642337203\n",
      "Epoch 3223, Loss: 0.00016676657105563208, Final Batch Loss: 0.00014666077913716435\n",
      "Epoch 3224, Loss: 0.00012865304233855568, Final Batch Loss: 0.0001014388762996532\n",
      "Epoch 3225, Loss: 0.00022819176956545562, Final Batch Loss: 0.00020322318596299738\n",
      "Epoch 3226, Loss: 0.0007684130250709131, Final Batch Loss: 0.00010669477342162281\n",
      "Epoch 3227, Loss: 0.0002263448060233486, Final Batch Loss: 1.4618318289194576e-07\n",
      "Epoch 3228, Loss: 1.3073785339656752e-05, Final Batch Loss: 5.142979716765694e-06\n",
      "Epoch 3229, Loss: 3.761652274647531e-05, Final Batch Loss: 3.2455878340442723e-07\n",
      "Epoch 3230, Loss: 1.9312003587401705e-06, Final Batch Loss: 9.084160410566255e-07\n",
      "Epoch 3231, Loss: 0.00013301899525686167, Final Batch Loss: 0.00011020281090168282\n",
      "Epoch 3232, Loss: 1.2872396382590523e-05, Final Batch Loss: 1.6357530512323137e-06\n",
      "Epoch 3233, Loss: 4.621077187039191e-05, Final Batch Loss: 7.271018148458097e-06\n",
      "Epoch 3234, Loss: 1.924142452480737e-05, Final Batch Loss: 1.5505484043387696e-06\n",
      "Epoch 3235, Loss: 3.8671261791023426e-05, Final Batch Loss: 1.6301752111758105e-05\n",
      "Epoch 3236, Loss: 0.001349482059595175, Final Batch Loss: 0.00015363907732535154\n",
      "Epoch 3237, Loss: 0.00010563346677372465, Final Batch Loss: 9.365536971017718e-05\n",
      "Epoch 3238, Loss: 1.2328497263069949e-05, Final Batch Loss: 2.897532738188602e-07\n",
      "Epoch 3239, Loss: 2.747341397935088e-06, Final Batch Loss: 2.045450628429535e-06\n",
      "Epoch 3240, Loss: 2.825786509674799e-06, Final Batch Loss: 1.3591102288046386e-06\n",
      "Epoch 3241, Loss: 7.425867124766228e-06, Final Batch Loss: 4.873082616541069e-06\n",
      "Epoch 3242, Loss: 1.2347611573204631e-05, Final Batch Loss: 4.439054009708343e-06\n",
      "Epoch 3243, Loss: 1.172984173081204e-05, Final Batch Loss: 1.5331173699451028e-06\n",
      "Epoch 3244, Loss: 7.776631173328497e-05, Final Batch Loss: 5.637568392558023e-05\n",
      "Epoch 3245, Loss: 7.320322674786439e-05, Final Batch Loss: 6.436586409108713e-05\n",
      "Epoch 3246, Loss: 2.9818810617143754e-05, Final Batch Loss: 2.0246758140274324e-05\n",
      "Epoch 3247, Loss: 5.7813709645415656e-05, Final Batch Loss: 2.0506782675511204e-05\n",
      "Epoch 3248, Loss: 6.594714614038821e-05, Final Batch Loss: 4.280154098523781e-05\n",
      "Epoch 3249, Loss: 0.00015907277315818646, Final Batch Loss: 2.727679884628742e-06\n",
      "Epoch 3250, Loss: 0.00014518417083309032, Final Batch Loss: 5.438852167571895e-05\n",
      "Epoch 3251, Loss: 0.00021425538190911197, Final Batch Loss: 5.220838161790198e-08\n",
      "Epoch 3252, Loss: 1.416568568401999e-05, Final Batch Loss: 1.2978878658032045e-05\n",
      "Epoch 3253, Loss: 9.908703577821143e-05, Final Batch Loss: 4.1352312109665945e-05\n",
      "Epoch 3254, Loss: 1.8454590986038966e-05, Final Batch Loss: 1.769770619830524e-06\n",
      "Epoch 3255, Loss: 1.570798545458274e-05, Final Batch Loss: 4.7335075237242563e-07\n",
      "Epoch 3256, Loss: 9.852369657892268e-06, Final Batch Loss: 3.839148121187463e-06\n",
      "Epoch 3257, Loss: 4.666942004405428e-05, Final Batch Loss: 1.477292062190827e-05\n",
      "Epoch 3258, Loss: 3.6378883578436216e-05, Final Batch Loss: 5.876748673472321e-06\n",
      "Epoch 3259, Loss: 1.856352560025698e-05, Final Batch Loss: 1.731715747155249e-05\n",
      "Epoch 3260, Loss: 0.0006978461860853713, Final Batch Loss: 0.000689194246660918\n",
      "Epoch 3261, Loss: 1.665291711105965e-05, Final Batch Loss: 7.908874977147207e-06\n",
      "Epoch 3262, Loss: 3.371777347638272e-05, Final Batch Loss: 1.7737884263624437e-05\n",
      "Epoch 3263, Loss: 6.245576406627151e-05, Final Batch Loss: 6.517137194350653e-07\n",
      "Epoch 3264, Loss: 1.5822581417523907e-05, Final Batch Loss: 1.2015868378512096e-05\n",
      "Epoch 3265, Loss: 2.0701987523352727e-05, Final Batch Loss: 1.040155257214792e-05\n",
      "Epoch 3266, Loss: 0.0006026400806149468, Final Batch Loss: 0.00012088565563317388\n",
      "Epoch 3267, Loss: 4.502615138335386e-05, Final Batch Loss: 8.624997462902684e-06\n",
      "Epoch 3268, Loss: 1.1336326224409277e-05, Final Batch Loss: 5.045528268965427e-06\n",
      "Epoch 3269, Loss: 5.639352650632645e-06, Final Batch Loss: 6.943549237803381e-07\n",
      "Epoch 3270, Loss: 1.7999231687326755e-06, Final Batch Loss: 4.959800037340756e-08\n",
      "Epoch 3271, Loss: 1.3228759371486376e-05, Final Batch Loss: 1.0178669981542043e-05\n",
      "Epoch 3272, Loss: 2.8610270916828995e-06, Final Batch Loss: 7.483190955781538e-08\n",
      "Epoch 3273, Loss: 0.0004138027062481342, Final Batch Loss: 7.778791086821002e-07\n",
      "Epoch 3274, Loss: 0.00012928285832458641, Final Batch Loss: 5.635991328745149e-06\n",
      "Epoch 3275, Loss: 1.5567646073577635e-05, Final Batch Loss: 1.4430907867790665e-05\n",
      "Epoch 3276, Loss: 2.643974312377395e-06, Final Batch Loss: 1.1668115575957927e-06\n",
      "Epoch 3277, Loss: 0.0005265508283542886, Final Batch Loss: 1.4705291562222556e-07\n",
      "Epoch 3278, Loss: 0.003130702541966457, Final Batch Loss: 5.7096600357908756e-05\n",
      "Epoch 3279, Loss: 0.00013075900005787844, Final Batch Loss: 6.988369023019914e-06\n",
      "Epoch 3280, Loss: 0.0002260262494928611, Final Batch Loss: 0.0002210588863817975\n",
      "Epoch 3281, Loss: 8.03098373580724e-06, Final Batch Loss: 5.69063558941707e-07\n",
      "Epoch 3282, Loss: 3.039017155970214e-05, Final Batch Loss: 1.1562579857127275e-05\n",
      "Epoch 3283, Loss: 7.821933877494303e-06, Final Batch Loss: 4.455630914890207e-06\n",
      "Epoch 3284, Loss: 9.72677257777832e-05, Final Batch Loss: 9.514592966297641e-05\n",
      "Epoch 3285, Loss: 6.655451443293714e-06, Final Batch Loss: 3.18257275466749e-06\n",
      "Epoch 3286, Loss: 2.337744956548704e-05, Final Batch Loss: 1.5227120684357942e-06\n",
      "Epoch 3287, Loss: 4.473343114597128e-06, Final Batch Loss: 4.872778802678113e-08\n",
      "Epoch 3288, Loss: 1.58921775437193e-05, Final Batch Loss: 7.418789209623355e-06\n",
      "Epoch 3289, Loss: 2.6337801728004706e-05, Final Batch Loss: 1.6088154097815277e-06\n",
      "Epoch 3290, Loss: 7.95057258073939e-06, Final Batch Loss: 4.210241058899555e-06\n",
      "Epoch 3291, Loss: 0.00017487271520622016, Final Batch Loss: 1.1189765700692078e-06\n",
      "Epoch 3292, Loss: 0.00014903602945537386, Final Batch Loss: 2.801819789510773e-07\n",
      "Epoch 3293, Loss: 3.6970857763662934e-05, Final Batch Loss: 2.444422716507688e-05\n",
      "Epoch 3294, Loss: 0.0001627102137717884, Final Batch Loss: 0.00015324227570090443\n",
      "Epoch 3295, Loss: 5.893242280308186e-05, Final Batch Loss: 5.681978336724569e-07\n",
      "Epoch 3296, Loss: 6.691829639748903e-05, Final Batch Loss: 5.763390436186455e-05\n",
      "Epoch 3297, Loss: 0.0035443168972051353, Final Batch Loss: 0.0035390572156757116\n",
      "Epoch 3298, Loss: 7.167177091105259e-05, Final Batch Loss: 6.128525910753524e-06\n",
      "Epoch 3299, Loss: 0.00012681199405051302, Final Batch Loss: 0.00010817829752340913\n",
      "Epoch 3300, Loss: 0.00015646382598788477, Final Batch Loss: 5.072280691820197e-05\n",
      "Epoch 3301, Loss: 9.074395052266482e-06, Final Batch Loss: 7.6935693869018e-06\n",
      "Epoch 3302, Loss: 0.0002592359833215596, Final Batch Loss: 0.0002417014038655907\n",
      "Epoch 3303, Loss: 3.428297304708394e-05, Final Batch Loss: 2.9351620469242334e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3304, Loss: 0.0007849981361687242, Final Batch Loss: 0.0007796555291861296\n",
      "Epoch 3305, Loss: 1.6551388398511335e-05, Final Batch Loss: 1.2557484296848997e-05\n",
      "Epoch 3306, Loss: 6.626921106089867e-06, Final Batch Loss: 9.144912951342121e-07\n",
      "Epoch 3307, Loss: 1.3949869867246889e-05, Final Batch Loss: 1.4782464177187649e-06\n",
      "Epoch 3308, Loss: 7.636674405731014e-06, Final Batch Loss: 2.9584777294644482e-08\n",
      "Epoch 3309, Loss: 6.797803325753193e-05, Final Batch Loss: 6.36353506706655e-05\n",
      "Epoch 3310, Loss: 5.810661218674795e-05, Final Batch Loss: 7.874511993577471e-07\n",
      "Epoch 3311, Loss: 3.470046976872254e-06, Final Batch Loss: 1.9977383090008516e-06\n",
      "Epoch 3312, Loss: 6.339478750305716e-05, Final Batch Loss: 2.9841730793123133e-05\n",
      "Epoch 3313, Loss: 8.995647021947661e-06, Final Batch Loss: 4.112966507818783e-06\n",
      "Epoch 3314, Loss: 2.088012553613794e-05, Final Batch Loss: 3.9156308417886976e-08\n",
      "Epoch 3315, Loss: 0.004681639195041498, Final Batch Loss: 5.221535320742987e-05\n",
      "Epoch 3316, Loss: 0.0001853903017945413, Final Batch Loss: 0.00018443141016177833\n",
      "Epoch 3317, Loss: 1.7945410149877716e-05, Final Batch Loss: 6.273522785704699e-07\n",
      "Epoch 3318, Loss: 1.890581006591674e-05, Final Batch Loss: 7.853805072954856e-06\n",
      "Epoch 3319, Loss: 3.414927232370246e-05, Final Batch Loss: 2.114355083904229e-06\n",
      "Epoch 3320, Loss: 8.550632378501177e-05, Final Batch Loss: 1.540979837955092e-06\n",
      "Epoch 3321, Loss: 1.0444592589919921e-05, Final Batch Loss: 5.724453330913093e-06\n",
      "Epoch 3322, Loss: 2.4417304302915e-05, Final Batch Loss: 9.220434549206402e-06\n",
      "Epoch 3323, Loss: 4.087419347342802e-05, Final Batch Loss: 3.3728894777596e-05\n",
      "Epoch 3324, Loss: 0.0011603297816691338, Final Batch Loss: 0.001149762305431068\n",
      "Epoch 3325, Loss: 8.807302833702124e-06, Final Batch Loss: 5.264272431304562e-07\n",
      "Epoch 3326, Loss: 4.707298226946932e-05, Final Batch Loss: 3.7416029385894944e-08\n",
      "Epoch 3327, Loss: 0.00010785660015244503, Final Batch Loss: 9.997565939556807e-05\n",
      "Epoch 3328, Loss: 3.281694353063358e-05, Final Batch Loss: 1.1507004273880739e-05\n",
      "Epoch 3329, Loss: 1.3728032627113862e-05, Final Batch Loss: 1.0337849744246341e-05\n",
      "Epoch 3330, Loss: 2.8097327685827622e-05, Final Batch Loss: 1.2077257451892365e-06\n",
      "Epoch 3331, Loss: 3.488676156848669e-05, Final Batch Loss: 1.0528674465604126e-07\n",
      "Epoch 3332, Loss: 1.7444561422053084e-06, Final Batch Loss: 1.03018294339563e-06\n",
      "Epoch 3333, Loss: 8.931674642553844e-06, Final Batch Loss: 7.101702976797242e-06\n",
      "Epoch 3334, Loss: 9.559474392517586e-06, Final Batch Loss: 7.090683993737912e-06\n",
      "Epoch 3335, Loss: 1.1726305274351034e-05, Final Batch Loss: 8.656717000121716e-06\n",
      "Epoch 3336, Loss: 1.0937780245967588e-05, Final Batch Loss: 8.17925467799796e-07\n",
      "Epoch 3337, Loss: 2.147868235624628e-05, Final Batch Loss: 1.0159106750506908e-05\n",
      "Epoch 3338, Loss: 5.8580823861120734e-05, Final Batch Loss: 9.17865054361755e-06\n",
      "Epoch 3339, Loss: 4.097786273860038e-05, Final Batch Loss: 2.9671406309716986e-07\n",
      "Epoch 3340, Loss: 1.4918362921889639e-05, Final Batch Loss: 3.898379418387776e-06\n",
      "Epoch 3341, Loss: 5.410405265138252e-05, Final Batch Loss: 1.0447924978507217e-05\n",
      "Epoch 3342, Loss: 0.0001346867197753454, Final Batch Loss: 5.899478310311679e-07\n",
      "Epoch 3343, Loss: 0.004319091745173864, Final Batch Loss: 0.004316037055104971\n",
      "Epoch 3344, Loss: 4.870588600169867e-05, Final Batch Loss: 1.702895315247588e-05\n",
      "Epoch 3345, Loss: 0.00010141144139197422, Final Batch Loss: 1.266022718482418e-05\n",
      "Epoch 3346, Loss: 1.4186687451456237e-06, Final Batch Loss: 1.1659490155579988e-06\n",
      "Epoch 3347, Loss: 2.4331334316229913e-06, Final Batch Loss: 1.277321075576765e-06\n",
      "Epoch 3348, Loss: 1.5901642740345778e-05, Final Batch Loss: 2.5059770791813207e-07\n",
      "Epoch 3349, Loss: 8.774310572334798e-06, Final Batch Loss: 1.6418985069321934e-06\n",
      "Epoch 3350, Loss: 8.345698734046891e-05, Final Batch Loss: 4.6237619244493544e-05\n",
      "Epoch 3351, Loss: 3.332079131723731e-05, Final Batch Loss: 2.8462367481552064e-05\n",
      "Epoch 3352, Loss: 6.835476938249485e-05, Final Batch Loss: 2.173459279219969e-06\n",
      "Epoch 3353, Loss: 0.00012220848265087625, Final Batch Loss: 6.45631814677472e-07\n",
      "Epoch 3354, Loss: 2.4686120468686568e-05, Final Batch Loss: 1.9396293282625265e-05\n",
      "Epoch 3355, Loss: 0.00019678103586784346, Final Batch Loss: 7.11760606009193e-07\n",
      "Epoch 3356, Loss: 1.619419072085293e-05, Final Batch Loss: 4.38722508988576e-06\n",
      "Epoch 3357, Loss: 9.338012205262203e-06, Final Batch Loss: 4.600051397574134e-06\n",
      "Epoch 3358, Loss: 0.0001000037827907363, Final Batch Loss: 2.7363512344891205e-06\n",
      "Epoch 3359, Loss: 0.00035011979707633145, Final Batch Loss: 0.00033417323720641434\n",
      "Epoch 3360, Loss: 5.692377999366727e-05, Final Batch Loss: 4.7403846110682935e-05\n",
      "Epoch 3361, Loss: 9.842592044151388e-05, Final Batch Loss: 6.482048775069416e-05\n",
      "Epoch 3362, Loss: 1.2647324183490127e-05, Final Batch Loss: 4.528624231170397e-06\n",
      "Epoch 3363, Loss: 2.085007963614771e-05, Final Batch Loss: 7.818618541932665e-06\n",
      "Epoch 3364, Loss: 0.0024683613009983674, Final Batch Loss: 7.999144145287573e-06\n",
      "Epoch 3365, Loss: 8.940909083321458e-06, Final Batch Loss: 1.9507474462443497e-06\n",
      "Epoch 3366, Loss: 5.8764946970768506e-06, Final Batch Loss: 3.108833197984495e-06\n",
      "Epoch 3367, Loss: 6.779850446037017e-05, Final Batch Loss: 9.807790775084868e-06\n",
      "Epoch 3368, Loss: 5.739202697441215e-05, Final Batch Loss: 4.750172229250893e-05\n",
      "Epoch 3369, Loss: 3.5843146179104224e-05, Final Batch Loss: 1.2686929039773531e-05\n",
      "Epoch 3370, Loss: 9.124028597540246e-05, Final Batch Loss: 3.741602228046759e-08\n",
      "Epoch 3371, Loss: 1.922279511745728e-05, Final Batch Loss: 3.6724929941556184e-06\n",
      "Epoch 3372, Loss: 2.7242287501394458e-06, Final Batch Loss: 5.534008664653811e-07\n",
      "Epoch 3373, Loss: 1.5075652754603652e-05, Final Batch Loss: 2.758014034043299e-06\n",
      "Epoch 3374, Loss: 0.002718820580867032, Final Batch Loss: 7.183402431110153e-06\n",
      "Epoch 3375, Loss: 1.7292993561568437e-05, Final Batch Loss: 1.615483961359132e-05\n",
      "Epoch 3376, Loss: 2.2310235635814024e-05, Final Batch Loss: 1.6186200809897855e-05\n",
      "Epoch 3377, Loss: 2.474912162142573e-05, Final Batch Loss: 1.0937778824882116e-05\n",
      "Epoch 3378, Loss: 9.281573625230521e-06, Final Batch Loss: 7.804884489814867e-07\n",
      "Epoch 3379, Loss: 1.5446742054336937e-05, Final Batch Loss: 9.50105913943844e-06\n",
      "Epoch 3380, Loss: 2.2154492285153538e-06, Final Batch Loss: 8.37923096241866e-07\n",
      "Epoch 3381, Loss: 2.1527735043491703e-05, Final Batch Loss: 1.1620508303167298e-05\n",
      "Epoch 3382, Loss: 0.024502244419636554, Final Batch Loss: 7.983870091265999e-06\n",
      "Epoch 3383, Loss: 0.00033032449209713377, Final Batch Loss: 0.0002914097858592868\n",
      "Epoch 3384, Loss: 3.313320814868348e-05, Final Batch Loss: 1.4339526615003706e-06\n",
      "Epoch 3385, Loss: 1.6562641576456372e-05, Final Batch Loss: 1.1309338333376218e-05\n",
      "Epoch 3386, Loss: 6.657292033196427e-05, Final Batch Loss: 1.533587055746466e-05\n",
      "Epoch 3387, Loss: 0.000735532466933364, Final Batch Loss: 0.0007274310337379575\n",
      "Epoch 3388, Loss: 9.792756827664562e-06, Final Batch Loss: 5.983436949463794e-06\n",
      "Epoch 3389, Loss: 0.00020936136752425227, Final Batch Loss: 0.00019383954349905252\n",
      "Epoch 3390, Loss: 0.0017376133528159698, Final Batch Loss: 0.0017190849175676703\n",
      "Epoch 3391, Loss: 0.0005864121339982376, Final Batch Loss: 3.058910078834742e-05\n",
      "Epoch 3392, Loss: 0.00037370410427683964, Final Batch Loss: 4.243831062922254e-05\n",
      "Epoch 3393, Loss: 3.801388356805546e-05, Final Batch Loss: 1.0134631338587496e-05\n",
      "Epoch 3394, Loss: 3.495517194096465e-05, Final Batch Loss: 1.5768411685712636e-05\n",
      "Epoch 3395, Loss: 3.170033778587822e-06, Final Batch Loss: 1.7010904684866546e-06\n",
      "Epoch 3396, Loss: 0.00010313534585293382, Final Batch Loss: 5.9984278777847067e-05\n",
      "Epoch 3397, Loss: 8.11468862593756e-06, Final Batch Loss: 5.236664492258569e-06\n",
      "Epoch 3398, Loss: 1.826551215344807e-05, Final Batch Loss: 1.138888910645619e-05\n",
      "Epoch 3399, Loss: 0.00012620235247595701, Final Batch Loss: 2.7732176022254862e-05\n",
      "Epoch 3400, Loss: 0.003370925176568562, Final Batch Loss: 0.003344176569953561\n",
      "Epoch 3401, Loss: 0.000801361686171731, Final Batch Loss: 3.0204184440663084e-05\n",
      "Epoch 3402, Loss: 1.7902727904584026e-05, Final Batch Loss: 6.827704510214971e-06\n",
      "Epoch 3403, Loss: 8.63177451719821e-05, Final Batch Loss: 5.157355644769268e-06\n",
      "Epoch 3404, Loss: 1.8825421193469083e-05, Final Batch Loss: 6.166456387290964e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3405, Loss: 2.819340693349659e-06, Final Batch Loss: 1.7941712258107145e-06\n",
      "Epoch 3406, Loss: 0.00010580060188658535, Final Batch Loss: 5.449529635370709e-05\n",
      "Epoch 3407, Loss: 0.00031491067534261674, Final Batch Loss: 0.00031372960074804723\n",
      "Epoch 3408, Loss: 4.6426262088061776e-05, Final Batch Loss: 3.8530779420398176e-05\n",
      "Epoch 3409, Loss: 9.832879641180625e-06, Final Batch Loss: 2.571803634054959e-06\n",
      "Epoch 3410, Loss: 0.0007942580705275759, Final Batch Loss: 0.0007059669587761164\n",
      "Epoch 3411, Loss: 0.00017518534150440246, Final Batch Loss: 0.00010694319644244388\n",
      "Epoch 3412, Loss: 3.161167933285469e-05, Final Batch Loss: 1.3584100997832138e-05\n",
      "Epoch 3413, Loss: 4.194328835183114e-05, Final Batch Loss: 2.0360359940241324e-06\n",
      "Epoch 3414, Loss: 0.00034895935732492944, Final Batch Loss: 1.3778487300442066e-05\n",
      "Epoch 3415, Loss: 1.87382215699472e-05, Final Batch Loss: 1.145085843745619e-05\n",
      "Epoch 3416, Loss: 4.050931784149725e-05, Final Batch Loss: 2.1127161744516343e-05\n",
      "Epoch 3417, Loss: 9.621870475484684e-06, Final Batch Loss: 3.9417179209522146e-07\n",
      "Epoch 3418, Loss: 6.928679067641497e-05, Final Batch Loss: 3.3341057132929564e-05\n",
      "Epoch 3419, Loss: 4.084047350261244e-05, Final Batch Loss: 3.4834920370485634e-05\n",
      "Epoch 3420, Loss: 2.5691532641758386e-05, Final Batch Loss: 1.145955025094736e-06\n",
      "Epoch 3421, Loss: 9.831848274188815e-06, Final Batch Loss: 7.834996722522192e-06\n",
      "Epoch 3422, Loss: 0.00015320628881454468, Final Batch Loss: 3.4710166801232845e-05\n",
      "Epoch 3423, Loss: 2.54700116784079e-05, Final Batch Loss: 7.918006303953007e-07\n",
      "Epoch 3424, Loss: 2.6111601982847787e-05, Final Batch Loss: 8.131639333441854e-06\n",
      "Epoch 3425, Loss: 0.00011050558657643705, Final Batch Loss: 1.335634237875638e-06\n",
      "Epoch 3426, Loss: 0.00010727825474532438, Final Batch Loss: 7.597620879096212e-06\n",
      "Epoch 3427, Loss: 9.670480721979402e-05, Final Batch Loss: 7.188912422861904e-05\n",
      "Epoch 3428, Loss: 3.426013745411183e-05, Final Batch Loss: 7.411068054352654e-06\n",
      "Epoch 3429, Loss: 1.965377032320248e-05, Final Batch Loss: 9.661089279688895e-06\n",
      "Epoch 3430, Loss: 2.873080063636735e-06, Final Batch Loss: 8.414123726652178e-07\n",
      "Epoch 3431, Loss: 2.6739167878986336e-05, Final Batch Loss: 5.5396176321664825e-06\n",
      "Epoch 3432, Loss: 3.297318471595645e-06, Final Batch Loss: 1.7619576055949437e-06\n",
      "Epoch 3433, Loss: 1.0951329073805027e-05, Final Batch Loss: 2.732228097102052e-07\n",
      "Epoch 3434, Loss: 6.106627733970527e-05, Final Batch Loss: 1.1808746421593241e-05\n",
      "Epoch 3435, Loss: 0.0017176471010316163, Final Batch Loss: 0.0012466198531910777\n",
      "Epoch 3436, Loss: 1.26226350403158e-05, Final Batch Loss: 6.6535044425108936e-06\n",
      "Epoch 3437, Loss: 3.192644771843334e-05, Final Batch Loss: 6.782046057196567e-06\n",
      "Epoch 3438, Loss: 3.457897855696501e-05, Final Batch Loss: 8.284329851449002e-06\n",
      "Epoch 3439, Loss: 8.606083429185674e-05, Final Batch Loss: 1.7127589671872556e-05\n",
      "Epoch 3440, Loss: 5.656868596304321e-05, Final Batch Loss: 1.8185890837685292e-07\n",
      "Epoch 3441, Loss: 0.0004917630571981135, Final Batch Loss: 2.604210294521181e-06\n",
      "Epoch 3442, Loss: 0.00019298229472042294, Final Batch Loss: 6.118080818851013e-06\n",
      "Epoch 3443, Loss: 0.000457315948779069, Final Batch Loss: 1.1546464975253912e-06\n",
      "Epoch 3444, Loss: 1.5405320482386742e-05, Final Batch Loss: 7.054746674839407e-06\n",
      "Epoch 3445, Loss: 2.473294671290205e-05, Final Batch Loss: 2.273536847496871e-05\n",
      "Epoch 3446, Loss: 8.814463114958926e-06, Final Batch Loss: 8.159298886312172e-06\n",
      "Epoch 3447, Loss: 6.787590791645925e-05, Final Batch Loss: 5.9240559494355693e-05\n",
      "Epoch 3448, Loss: 0.0001303878617591181, Final Batch Loss: 1.3121117490300094e-06\n",
      "Epoch 3449, Loss: 0.000323627251873404, Final Batch Loss: 6.429958830267424e-06\n",
      "Epoch 3450, Loss: 0.0030351386521942914, Final Batch Loss: 0.00037013698602095246\n",
      "Epoch 3451, Loss: 0.0005120511586937937, Final Batch Loss: 1.5140448340389412e-05\n",
      "Epoch 3452, Loss: 1.3534109143620299e-05, Final Batch Loss: 8.701221076989896e-07\n",
      "Epoch 3453, Loss: 9.224105588145903e-05, Final Batch Loss: 5.230941951595014e-06\n",
      "Epoch 3454, Loss: 0.0001329218048340408, Final Batch Loss: 4.034138328279369e-06\n",
      "Epoch 3455, Loss: 2.3337357561104e-05, Final Batch Loss: 1.532062015030533e-05\n",
      "Epoch 3456, Loss: 0.00010502250734134577, Final Batch Loss: 1.707812407403253e-05\n",
      "Epoch 3457, Loss: 0.00021412722765035141, Final Batch Loss: 1.7776479808162549e-06\n",
      "Epoch 3458, Loss: 1.075404964012705e-05, Final Batch Loss: 9.492974868408055e-07\n",
      "Epoch 3459, Loss: 0.00026147096582462837, Final Batch Loss: 0.0002599499421194196\n",
      "Epoch 3460, Loss: 2.279806085425662e-05, Final Batch Loss: 5.080805749457795e-06\n",
      "Epoch 3461, Loss: 9.409521555880929e-05, Final Batch Loss: 1.0006590400735149e-07\n",
      "Epoch 3462, Loss: 0.0009520313369648647, Final Batch Loss: 2.516889253456611e-06\n",
      "Epoch 3463, Loss: 3.713136584337917e-05, Final Batch Loss: 3.2002553780330345e-05\n",
      "Epoch 3464, Loss: 4.4823593270848505e-05, Final Batch Loss: 2.5962248400901444e-05\n",
      "Epoch 3465, Loss: 7.635334304723074e-05, Final Batch Loss: 6.995443982305005e-05\n",
      "Epoch 3466, Loss: 4.531158765530563e-06, Final Batch Loss: 2.151577518816339e-06\n",
      "Epoch 3467, Loss: 0.00040739016458246624, Final Batch Loss: 0.0003958531015086919\n",
      "Epoch 3468, Loss: 4.729189481622598e-05, Final Batch Loss: 3.3881190120155225e-06\n",
      "Epoch 3469, Loss: 7.730888773949118e-05, Final Batch Loss: 7.181106047937647e-05\n",
      "Epoch 3470, Loss: 5.096582913211023e-05, Final Batch Loss: 6.473762823588913e-07\n",
      "Epoch 3471, Loss: 1.4745473038146883e-06, Final Batch Loss: 1.2094929502382001e-07\n",
      "Epoch 3472, Loss: 4.821726724912878e-05, Final Batch Loss: 2.5836536224232987e-05\n",
      "Epoch 3473, Loss: 0.0003157142782583833, Final Batch Loss: 0.0003118473687209189\n",
      "Epoch 3474, Loss: 4.08004918028837e-06, Final Batch Loss: 2.0187145821637387e-07\n",
      "Epoch 3475, Loss: 1.8588030911814712e-05, Final Batch Loss: 1.1381126796550234e-06\n",
      "Epoch 3476, Loss: 3.3829197832346836e-05, Final Batch Loss: 1.5922090597086935e-06\n",
      "Epoch 3477, Loss: 1.5198022083495744e-05, Final Batch Loss: 6.5245776568190195e-06\n",
      "Epoch 3478, Loss: 1.2489482287492137e-05, Final Batch Loss: 2.378817953285761e-06\n",
      "Epoch 3479, Loss: 3.455981618571968e-05, Final Batch Loss: 3.0635308121418348e-06\n",
      "Epoch 3480, Loss: 2.6605909170029918e-05, Final Batch Loss: 1.94603835552698e-05\n",
      "Epoch 3481, Loss: 6.3406199686255604e-06, Final Batch Loss: 1.1746886485752839e-07\n",
      "Epoch 3482, Loss: 6.686548204015708e-05, Final Batch Loss: 1.3667772691405844e-05\n",
      "Epoch 3483, Loss: 6.962796032894403e-05, Final Batch Loss: 4.9599089834373444e-05\n",
      "Epoch 3484, Loss: 1.1551519037311664e-05, Final Batch Loss: 4.013510533695808e-06\n",
      "Epoch 3485, Loss: 6.434367060137447e-05, Final Batch Loss: 1.6574462279095314e-05\n",
      "Epoch 3486, Loss: 4.103403989574872e-05, Final Batch Loss: 2.394493822066579e-05\n",
      "Epoch 3487, Loss: 0.00016178301939362427, Final Batch Loss: 1.3616087926493492e-05\n",
      "Epoch 3488, Loss: 0.0004057880437358108, Final Batch Loss: 1.2485838851716835e-06\n",
      "Epoch 3489, Loss: 6.249766421717595e-06, Final Batch Loss: 9.136451950553237e-08\n",
      "Epoch 3490, Loss: 3.852189638564596e-05, Final Batch Loss: 2.8121312425355427e-05\n",
      "Epoch 3491, Loss: 3.032891618204303e-05, Final Batch Loss: 1.8515944248065352e-05\n",
      "Epoch 3492, Loss: 7.480526846848079e-06, Final Batch Loss: 4.09826816394343e-06\n",
      "Epoch 3493, Loss: 0.0005998571156737853, Final Batch Loss: 0.000599091814365238\n",
      "Epoch 3494, Loss: 0.0002271021188562372, Final Batch Loss: 1.5792724070706754e-06\n",
      "Epoch 3495, Loss: 3.5303488630233915e-06, Final Batch Loss: 5.69935878047545e-07\n",
      "Epoch 3496, Loss: 1.0786450275190873e-05, Final Batch Loss: 3.938372628908837e-06\n",
      "Epoch 3497, Loss: 0.00018528869168221718, Final Batch Loss: 1.19845781227923e-05\n",
      "Epoch 3498, Loss: 4.842502312385477e-05, Final Batch Loss: 8.660968887852505e-06\n",
      "Epoch 3499, Loss: 0.0003807140278695442, Final Batch Loss: 0.00037651282036677003\n",
      "Epoch 3500, Loss: 1.125594781115069e-05, Final Batch Loss: 4.59825378129608e-06\n",
      "Epoch 3501, Loss: 3.283092291894718e-05, Final Batch Loss: 3.058630682062358e-05\n",
      "Epoch 3502, Loss: 1.648213719818159e-05, Final Batch Loss: 9.11979532247642e-06\n",
      "Epoch 3503, Loss: 1.7911427221406484e-05, Final Batch Loss: 1.4222673598851543e-05\n",
      "Epoch 3504, Loss: 5.367582105009205e-06, Final Batch Loss: 4.926990641251905e-06\n",
      "Epoch 3505, Loss: 2.8159435714769643e-05, Final Batch Loss: 1.8133143385057338e-05\n",
      "Epoch 3506, Loss: 0.0002057434971902694, Final Batch Loss: 2.1672235561709385e-06\n",
      "Epoch 3507, Loss: 1.418613044279482e-05, Final Batch Loss: 5.116374950375757e-07\n",
      "Epoch 3508, Loss: 0.0008388175047002733, Final Batch Loss: 2.1669198758900166e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3509, Loss: 5.514384884008905e-05, Final Batch Loss: 5.01023605465889e-05\n",
      "Epoch 3510, Loss: 1.080917400031467e-05, Final Batch Loss: 6.848348675703164e-06\n",
      "Epoch 3511, Loss: 0.0001684360984199884, Final Batch Loss: 1.3903706985729514e-06\n",
      "Epoch 3512, Loss: 9.550172308081528e-06, Final Batch Loss: 4.127428837819025e-06\n",
      "Epoch 3513, Loss: 0.004326054466787355, Final Batch Loss: 0.004324955865740776\n",
      "Epoch 3514, Loss: 5.351030949896085e-06, Final Batch Loss: 3.4349402540101437e-06\n",
      "Epoch 3515, Loss: 5.2833321433354286e-06, Final Batch Loss: 1.2042083881169674e-06\n",
      "Epoch 3516, Loss: 8.029792866182106e-06, Final Batch Loss: 7.651665328012314e-06\n",
      "Epoch 3517, Loss: 5.533748890229617e-06, Final Batch Loss: 1.4043591818335699e-06\n",
      "Epoch 3518, Loss: 2.953469493149896e-05, Final Batch Loss: 4.653764790418791e-06\n",
      "Epoch 3519, Loss: 5.183226380722772e-05, Final Batch Loss: 4.8079844418680295e-05\n",
      "Epoch 3520, Loss: 1.6293216731355642e-05, Final Batch Loss: 1.5332918337662704e-05\n",
      "Epoch 3521, Loss: 0.00015601632884454375, Final Batch Loss: 0.00015511512174271047\n",
      "Epoch 3522, Loss: 1.6695952808731818e-05, Final Batch Loss: 3.33807042807166e-06\n",
      "Epoch 3523, Loss: 2.562112740633893e-06, Final Batch Loss: 8.318424988829065e-07\n",
      "Epoch 3524, Loss: 3.172380218074977e-05, Final Batch Loss: 1.5765884882057435e-06\n",
      "Epoch 3525, Loss: 1.249608567377436e-05, Final Batch Loss: 1.0167706932406873e-05\n",
      "Epoch 3526, Loss: 3.2781606478238245e-05, Final Batch Loss: 2.7327252610120922e-05\n",
      "Epoch 3527, Loss: 8.852179325913312e-05, Final Batch Loss: 8.577048720326275e-05\n",
      "Epoch 3528, Loss: 6.403635239848882e-07, Final Batch Loss: 2.0883310014596645e-07\n",
      "Epoch 3529, Loss: 5.574255524720684e-05, Final Batch Loss: 5.5383978178724647e-05\n",
      "Epoch 3530, Loss: 7.115859261830337e-06, Final Batch Loss: 4.21849745180225e-06\n",
      "Epoch 3531, Loss: 7.427221203215595e-05, Final Batch Loss: 7.220861152745783e-05\n",
      "Epoch 3532, Loss: 1.991210086771389e-05, Final Batch Loss: 1.9513470761012286e-05\n",
      "Epoch 3533, Loss: 5.061127922090236e-05, Final Batch Loss: 2.0559728000080213e-06\n",
      "Epoch 3534, Loss: 0.0002396719469288655, Final Batch Loss: 0.0002391212183283642\n",
      "Epoch 3535, Loss: 2.5844018637144472e-05, Final Batch Loss: 1.604748649697285e-05\n",
      "Epoch 3536, Loss: 8.498354645780637e-06, Final Batch Loss: 6.39991640127846e-06\n",
      "Epoch 3537, Loss: 2.5303785150754265e-05, Final Batch Loss: 2.0736213627969846e-05\n",
      "Epoch 3538, Loss: 1.9675622297654627e-05, Final Batch Loss: 1.7969150576391257e-05\n",
      "Epoch 3539, Loss: 4.7264343141506515e-06, Final Batch Loss: 1.1311827918802919e-08\n",
      "Epoch 3540, Loss: 8.937723578128498e-05, Final Batch Loss: 7.314742833841592e-05\n",
      "Epoch 3541, Loss: 5.330073406639713e-06, Final Batch Loss: 1.6619623011138174e-07\n",
      "Epoch 3542, Loss: 3.582159843062982e-05, Final Batch Loss: 2.7160096578882076e-05\n",
      "Epoch 3543, Loss: 8.492916978752874e-05, Final Batch Loss: 3.7676520037166483e-07\n",
      "Epoch 3544, Loss: 1.1641613241408777e-05, Final Batch Loss: 1.3678119330506888e-06\n",
      "Epoch 3545, Loss: 0.00011002315977748367, Final Batch Loss: 0.0001074615356628783\n",
      "Epoch 3546, Loss: 0.004070863060974261, Final Batch Loss: 0.004069829359650612\n",
      "Epoch 3547, Loss: 2.6254754629917443e-05, Final Batch Loss: 2.2345182514982298e-05\n",
      "Epoch 3548, Loss: 0.00016497618344146758, Final Batch Loss: 0.0001477242331020534\n",
      "Epoch 3549, Loss: 1.7927273390228038e-06, Final Batch Loss: 8.005286389334287e-08\n",
      "Epoch 3550, Loss: 0.0004288645377528155, Final Batch Loss: 5.658346708514728e-06\n",
      "Epoch 3551, Loss: 0.0003165906437061494, Final Batch Loss: 2.8414729968062602e-05\n",
      "Epoch 3552, Loss: 1.9655660139505926e-05, Final Batch Loss: 1.4939877246433753e-06\n",
      "Epoch 3553, Loss: 6.056959080069646e-06, Final Batch Loss: 3.0367795034180745e-07\n",
      "Epoch 3554, Loss: 5.8604037349141436e-05, Final Batch Loss: 5.393143874243833e-05\n",
      "Epoch 3555, Loss: 2.407661065717548e-05, Final Batch Loss: 2.56689759225992e-07\n",
      "Epoch 3556, Loss: 8.533976597391302e-06, Final Batch Loss: 4.48674518338521e-06\n",
      "Epoch 3557, Loss: 3.114524474767677e-05, Final Batch Loss: 3.3254752906941576e-06\n",
      "Epoch 3558, Loss: 3.0133621294226032e-05, Final Batch Loss: 1.1266748515481595e-05\n",
      "Epoch 3559, Loss: 1.0756578717519005e-05, Final Batch Loss: 8.692480832905858e-07\n",
      "Epoch 3560, Loss: 6.577820045094995e-06, Final Batch Loss: 1.876787450783013e-06\n",
      "Epoch 3561, Loss: 5.668996436725138e-07, Final Batch Loss: 3.1846914794186887e-07\n",
      "Epoch 3562, Loss: 4.329735361352505e-06, Final Batch Loss: 1.3251716382001177e-06\n",
      "Epoch 3563, Loss: 0.0006328214149107225, Final Batch Loss: 0.0006253515020944178\n",
      "Epoch 3564, Loss: 0.0002679599492694251, Final Batch Loss: 0.0001556743955006823\n",
      "Epoch 3565, Loss: 5.049239825893892e-05, Final Batch Loss: 3.6355711927171797e-05\n",
      "Epoch 3566, Loss: 6.550254266812772e-05, Final Batch Loss: 6.498567381640896e-05\n",
      "Epoch 3567, Loss: 3.3929226447071414e-05, Final Batch Loss: 9.496779057371896e-06\n",
      "Epoch 3568, Loss: 7.797434204803722e-05, Final Batch Loss: 1.0815563200594625e-06\n",
      "Epoch 3569, Loss: 6.073780787119176e-05, Final Batch Loss: 5.092601350042969e-05\n",
      "Epoch 3570, Loss: 3.5771859757005586e-05, Final Batch Loss: 3.444345929892734e-05\n",
      "Epoch 3571, Loss: 2.8825450499425642e-05, Final Batch Loss: 1.0508098057471216e-05\n",
      "Epoch 3572, Loss: 1.4555128075244284e-05, Final Batch Loss: 6.543373842760047e-07\n",
      "Epoch 3573, Loss: 9.888769824328847e-06, Final Batch Loss: 3.967819850458909e-07\n",
      "Epoch 3574, Loss: 2.784895485774541e-06, Final Batch Loss: 5.39486961770308e-08\n",
      "Epoch 3575, Loss: 4.530509556843754e-06, Final Batch Loss: 4.6639109996249317e-07\n",
      "Epoch 3576, Loss: 0.0012090349918025822, Final Batch Loss: 8.9622324139782e-07\n",
      "Epoch 3577, Loss: 6.585636037925724e-05, Final Batch Loss: 5.197136488277465e-05\n",
      "Epoch 3578, Loss: 2.4162622139556333e-05, Final Batch Loss: 1.3245318768895231e-05\n",
      "Epoch 3579, Loss: 2.4962614588730503e-05, Final Batch Loss: 2.1198275135247968e-05\n",
      "Epoch 3580, Loss: 1.554383146640248e-06, Final Batch Loss: 4.1766119807107316e-07\n",
      "Epoch 3581, Loss: 1.3351623692869907e-05, Final Batch Loss: 1.4148176887829322e-06\n",
      "Epoch 3582, Loss: 2.5045708298421232e-05, Final Batch Loss: 2.000575295824092e-05\n",
      "Epoch 3583, Loss: 4.723196354916581e-06, Final Batch Loss: 8.083237048595038e-07\n",
      "Epoch 3584, Loss: 1.0676019428501604e-05, Final Batch Loss: 4.326040198066039e-06\n",
      "Epoch 3585, Loss: 0.00023771863976662644, Final Batch Loss: 0.00023682840401306748\n",
      "Epoch 3586, Loss: 1.2839892860938562e-05, Final Batch Loss: 7.830099093553144e-06\n",
      "Epoch 3587, Loss: 6.860075700387824e-05, Final Batch Loss: 9.001409125630744e-06\n",
      "Epoch 3588, Loss: 3.522599763527978e-05, Final Batch Loss: 7.525930413976312e-06\n",
      "Epoch 3589, Loss: 6.364089244925708e-06, Final Batch Loss: 9.892938805933227e-07\n",
      "Epoch 3590, Loss: 0.00010386575559095945, Final Batch Loss: 7.702181028435007e-05\n",
      "Epoch 3591, Loss: 2.0768788715486153e-06, Final Batch Loss: 1.8968987092193856e-07\n",
      "Epoch 3592, Loss: 3.5624934753286652e-06, Final Batch Loss: 2.9860152608307544e-06\n",
      "Epoch 3593, Loss: 9.28268509596819e-05, Final Batch Loss: 7.219250983325765e-05\n",
      "Epoch 3594, Loss: 1.56079030091405e-05, Final Batch Loss: 1.5148241800488904e-05\n",
      "Epoch 3595, Loss: 2.2040696421754546e-05, Final Batch Loss: 6.491854946943931e-06\n",
      "Epoch 3596, Loss: 2.9541733397309144e-06, Final Batch Loss: 7.526556942138996e-07\n",
      "Epoch 3597, Loss: 0.00011389490454405404, Final Batch Loss: 0.00011368175910320133\n",
      "Epoch 3598, Loss: 3.105500763922464e-05, Final Batch Loss: 1.5760013411636464e-05\n",
      "Epoch 3599, Loss: 2.634369991483254e-06, Final Batch Loss: 1.703611246739456e-06\n",
      "Epoch 3600, Loss: 1.968029664567439e-05, Final Batch Loss: 4.188822458672803e-06\n",
      "Epoch 3601, Loss: 1.487312482595371e-05, Final Batch Loss: 2.445082714075397e-07\n",
      "Epoch 3602, Loss: 0.0019063309318880783, Final Batch Loss: 7.883298167143948e-06\n",
      "Epoch 3603, Loss: 4.497222334975959e-06, Final Batch Loss: 3.759095761779463e-06\n",
      "Epoch 3604, Loss: 0.00019426658764132299, Final Batch Loss: 7.19445597496815e-06\n",
      "Epoch 3605, Loss: 1.6573037100897636e-05, Final Batch Loss: 5.823609171784483e-06\n",
      "Epoch 3606, Loss: 9.103067895921413e-06, Final Batch Loss: 5.996057097945595e-06\n",
      "Epoch 3607, Loss: 0.008186031258901494, Final Batch Loss: 1.954972049134085e-06\n",
      "Epoch 3608, Loss: 7.637952954553384e-06, Final Batch Loss: 1.13118026945358e-07\n",
      "Epoch 3609, Loss: 0.0013102718257869128, Final Batch Loss: 4.54191213066224e-05\n",
      "Epoch 3610, Loss: 5.172911369299982e-05, Final Batch Loss: 2.785060860333033e-05\n",
      "Epoch 3611, Loss: 1.746976067806827e-06, Final Batch Loss: 1.5009292155809817e-06\n",
      "Epoch 3612, Loss: 1.4555687926076644e-06, Final Batch Loss: 6.17791613422014e-07\n",
      "Epoch 3613, Loss: 0.0004875619342783466, Final Batch Loss: 0.00036862504202872515\n",
      "Epoch 3614, Loss: 1.7268097138867233e-06, Final Batch Loss: 1.809888630077694e-07\n",
      "Epoch 3615, Loss: 1.563153273309581e-05, Final Batch Loss: 4.228161742503289e-06\n",
      "Epoch 3616, Loss: 3.106485166881612e-05, Final Batch Loss: 2.9226734113763086e-05\n",
      "Epoch 3617, Loss: 7.209867419533111e-06, Final Batch Loss: 9.031737704390252e-07\n",
      "Epoch 3618, Loss: 4.069827127750614e-06, Final Batch Loss: 2.8067299808753887e-06\n",
      "Epoch 3619, Loss: 4.794726211798661e-05, Final Batch Loss: 4.5420912897498056e-07\n",
      "Epoch 3620, Loss: 1.8735984042450582e-05, Final Batch Loss: 2.8366440574245644e-07\n",
      "Epoch 3621, Loss: 0.00018888012982642977, Final Batch Loss: 8.795551366347354e-06\n",
      "Epoch 3622, Loss: 4.0040378507910646e-05, Final Batch Loss: 5.734161732107168e-07\n",
      "Epoch 3623, Loss: 0.00016996097338051186, Final Batch Loss: 0.00016348333156201988\n",
      "Epoch 3624, Loss: 0.00010555196604400408, Final Batch Loss: 9.771447366802022e-07\n",
      "Epoch 3625, Loss: 6.866431613161694e-05, Final Batch Loss: 4.3452637328300625e-05\n",
      "Epoch 3626, Loss: 8.468551277474035e-05, Final Batch Loss: 1.2302874893066473e-05\n",
      "Epoch 3627, Loss: 2.1469603325385833e-05, Final Batch Loss: 4.884447207587073e-06\n",
      "Epoch 3628, Loss: 3.4937595501105534e-05, Final Batch Loss: 3.370025660842657e-05\n",
      "Epoch 3629, Loss: 0.0005228991601597954, Final Batch Loss: 2.3560812678624643e-06\n",
      "Epoch 3630, Loss: 1.3708820915780962e-05, Final Batch Loss: 6.3449192566622514e-06\n",
      "Epoch 3631, Loss: 9.36264450501767e-06, Final Batch Loss: 7.075486337271286e-06\n",
      "Epoch 3632, Loss: 0.0002336296092835255, Final Batch Loss: 0.00017033285985235125\n",
      "Epoch 3633, Loss: 1.6716078846457094e-05, Final Batch Loss: 1.5952216926962137e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3634, Loss: 1.2133995028307254e-05, Final Batch Loss: 1.1351995453878772e-05\n",
      "Epoch 3635, Loss: 7.224141199912992e-06, Final Batch Loss: 9.014295301312814e-07\n",
      "Epoch 3636, Loss: 0.0038896944342923234, Final Batch Loss: 0.003877725452184677\n",
      "Epoch 3637, Loss: 1.081725895346608e-05, Final Batch Loss: 6.743037374690175e-06\n",
      "Epoch 3638, Loss: 3.9292897866971543e-05, Final Batch Loss: 2.41898391095674e-07\n",
      "Epoch 3639, Loss: 8.158139098668471e-05, Final Batch Loss: 3.14266471832525e-05\n",
      "Epoch 3640, Loss: 1.2116156767660868e-05, Final Batch Loss: 2.246489430035581e-06\n",
      "Epoch 3641, Loss: 0.00031773111652455555, Final Batch Loss: 1.4643602526120958e-06\n",
      "Epoch 3642, Loss: 0.005941105293459259, Final Batch Loss: 0.00018595739675220102\n",
      "Epoch 3643, Loss: 1.0039081018931029e-05, Final Batch Loss: 8.666468716000963e-07\n",
      "Epoch 3644, Loss: 1.2647749372263206e-06, Final Batch Loss: 6.334527142826119e-07\n",
      "Epoch 3645, Loss: 9.855650148438144e-06, Final Batch Loss: 9.07556022866629e-06\n",
      "Epoch 3646, Loss: 6.70978261041455e-06, Final Batch Loss: 2.8623576326936018e-06\n",
      "Epoch 3647, Loss: 7.132315749913687e-05, Final Batch Loss: 5.868212610948831e-05\n",
      "Epoch 3648, Loss: 1.0268088772136252e-05, Final Batch Loss: 7.400572030746844e-06\n",
      "Epoch 3649, Loss: 9.229319903170108e-05, Final Batch Loss: 9.02953979675658e-05\n",
      "Epoch 3650, Loss: 6.1207194903545314e-06, Final Batch Loss: 1.617541556697688e-06\n",
      "Epoch 3651, Loss: 0.0001212345505336998, Final Batch Loss: 0.00011768902913900092\n",
      "Epoch 3652, Loss: 2.101179916280671e-05, Final Batch Loss: 1.7111897250288166e-05\n",
      "Epoch 3653, Loss: 7.242501624205033e-06, Final Batch Loss: 2.702402298382367e-06\n",
      "Epoch 3654, Loss: 1.5385664028144674e-05, Final Batch Loss: 5.857468295289436e-06\n",
      "Epoch 3655, Loss: 5.7431427990195516e-05, Final Batch Loss: 5.601719385595061e-05\n",
      "Epoch 3656, Loss: 1.538890455776709e-05, Final Batch Loss: 6.0529550864885096e-06\n",
      "Epoch 3657, Loss: 4.801540779908464e-05, Final Batch Loss: 9.223105621458672e-07\n",
      "Epoch 3658, Loss: 2.551453610522003e-05, Final Batch Loss: 2.360827238589991e-05\n",
      "Epoch 3659, Loss: 7.72442876950663e-06, Final Batch Loss: 2.6927425551548367e-06\n",
      "Epoch 3660, Loss: 0.0015041637288959464, Final Batch Loss: 0.0014770275447517633\n",
      "Epoch 3661, Loss: 3.166670558130136e-05, Final Batch Loss: 4.874677870247979e-06\n",
      "Epoch 3662, Loss: 1.2348147890861583e-06, Final Batch Loss: 3.593600297335797e-07\n",
      "Epoch 3663, Loss: 1.9886065842911194e-06, Final Batch Loss: 7.674483981645608e-07\n",
      "Epoch 3664, Loss: 0.00033114197594841244, Final Batch Loss: 0.00032996281515806913\n",
      "Epoch 3665, Loss: 0.0002772754495481422, Final Batch Loss: 0.0002767413971014321\n",
      "Epoch 3666, Loss: 3.932223876290664e-06, Final Batch Loss: 2.505600832591881e-06\n",
      "Epoch 3667, Loss: 0.0002194693915953394, Final Batch Loss: 0.00019516731845214963\n",
      "Epoch 3668, Loss: 0.00011117664325865917, Final Batch Loss: 4.4735923438565806e-05\n",
      "Epoch 3669, Loss: 2.728102776927699e-05, Final Batch Loss: 2.3504793716710992e-05\n",
      "Epoch 3670, Loss: 2.2365903305399115e-05, Final Batch Loss: 1.4321965409180848e-06\n",
      "Epoch 3671, Loss: 8.926785540097626e-06, Final Batch Loss: 5.3139983720029704e-06\n",
      "Epoch 3672, Loss: 7.312677325899131e-06, Final Batch Loss: 4.321262167650275e-06\n",
      "Epoch 3673, Loss: 5.994233143269412e-05, Final Batch Loss: 5.969723861198872e-05\n",
      "Epoch 3674, Loss: 0.00010251674939354416, Final Batch Loss: 9.649433923186734e-05\n",
      "Epoch 3675, Loss: 1.8174148863181472e-05, Final Batch Loss: 1.1260282917646691e-05\n",
      "Epoch 3676, Loss: 4.922579194044374e-06, Final Batch Loss: 4.594520305545302e-06\n",
      "Epoch 3677, Loss: 3.475076755421469e-05, Final Batch Loss: 7.1340227805194445e-06\n",
      "Epoch 3678, Loss: 1.0761193834696314e-05, Final Batch Loss: 9.30498481466202e-06\n",
      "Epoch 3679, Loss: 0.0021782900580546993, Final Batch Loss: 0.002171522006392479\n",
      "Epoch 3680, Loss: 1.36775030341596e-05, Final Batch Loss: 1.4078419781071716e-06\n",
      "Epoch 3681, Loss: 5.95829782241708e-05, Final Batch Loss: 1.5618655879734433e-06\n",
      "Epoch 3682, Loss: 1.194249364289135e-06, Final Batch Loss: 8.11829579561163e-07\n",
      "Epoch 3683, Loss: 1.2006518318230519e-05, Final Batch Loss: 9.189752745442092e-06\n",
      "Epoch 3684, Loss: 0.0005350815081328619, Final Batch Loss: 1.0122912499355152e-05\n",
      "Epoch 3685, Loss: 4.80298646010624e-06, Final Batch Loss: 4.3507007774223894e-08\n",
      "Epoch 3686, Loss: 3.5350377345366724e-06, Final Batch Loss: 4.4463953940976353e-07\n",
      "Epoch 3687, Loss: 2.5167417447846674e-06, Final Batch Loss: 2.1038067643530667e-06\n",
      "Epoch 3688, Loss: 1.0834010026883334e-05, Final Batch Loss: 6.742168807249982e-06\n",
      "Epoch 3689, Loss: 7.057755055939197e-06, Final Batch Loss: 4.936507593811257e-06\n",
      "Epoch 3690, Loss: 4.974088733433746e-05, Final Batch Loss: 2.4348042643396184e-05\n",
      "Epoch 3691, Loss: 1.0042238301366524e-05, Final Batch Loss: 2.758331731911312e-07\n",
      "Epoch 3692, Loss: 1.268559435629868e-05, Final Batch Loss: 3.4567769944260363e-06\n",
      "Epoch 3693, Loss: 2.3598155109993968e-05, Final Batch Loss: 3.3326244874842814e-07\n",
      "Epoch 3694, Loss: 2.0604379074029566e-05, Final Batch Loss: 2.9584441563201835e-07\n",
      "Epoch 3695, Loss: 1.1907066934213617e-05, Final Batch Loss: 1.609756026255127e-07\n",
      "Epoch 3696, Loss: 1.0084517953146133e-05, Final Batch Loss: 8.893445738067385e-06\n",
      "Epoch 3697, Loss: 0.00010871911490539787, Final Batch Loss: 1.3259118532005232e-05\n",
      "Epoch 3698, Loss: 3.947633695133845e-05, Final Batch Loss: 3.622794974944554e-05\n",
      "Epoch 3699, Loss: 0.000515473020641366, Final Batch Loss: 2.5584366085240617e-05\n",
      "Epoch 3700, Loss: 7.351227623075829e-06, Final Batch Loss: 4.452291705092648e-06\n",
      "Epoch 3701, Loss: 7.921118367448798e-06, Final Batch Loss: 1.9419546788412845e-06\n",
      "Epoch 3702, Loss: 3.0362017923835083e-05, Final Batch Loss: 3.177288590450189e-06\n",
      "Epoch 3703, Loss: 8.486550905217882e-05, Final Batch Loss: 6.588642281712964e-05\n",
      "Epoch 3704, Loss: 0.0001186759072879795, Final Batch Loss: 9.481501183472574e-05\n",
      "Epoch 3705, Loss: 3.0122050276304435e-07, Final Batch Loss: 8.092298031669998e-08\n",
      "Epoch 3706, Loss: 3.4731200230453396e-05, Final Batch Loss: 5.67305551157915e-06\n",
      "Epoch 3707, Loss: 3.087667906953584e-05, Final Batch Loss: 1.0963746177594658e-07\n",
      "Epoch 3708, Loss: 6.858993941705194e-06, Final Batch Loss: 1.4183260077516024e-07\n",
      "Epoch 3709, Loss: 5.635362424527557e-05, Final Batch Loss: 9.692968205854413e-07\n",
      "Epoch 3710, Loss: 2.5086369532800745e-05, Final Batch Loss: 1.8619730326463468e-06\n",
      "Epoch 3711, Loss: 5.2147036626593035e-06, Final Batch Loss: 4.286861440050416e-06\n",
      "Epoch 3712, Loss: 3.781271291813937e-05, Final Batch Loss: 4.472472312500031e-07\n",
      "Epoch 3713, Loss: 5.695757863577455e-06, Final Batch Loss: 1.001470081973821e-06\n",
      "Epoch 3714, Loss: 0.001897046763929211, Final Batch Loss: 1.1311634580124519e-06\n",
      "Epoch 3715, Loss: 1.0514080713619478e-05, Final Batch Loss: 7.987043318280485e-06\n",
      "Epoch 3716, Loss: 1.79612975443888e-05, Final Batch Loss: 5.269585471978644e-06\n",
      "Epoch 3717, Loss: 2.4877037503756583e-05, Final Batch Loss: 1.0308879609510768e-05\n",
      "Epoch 3718, Loss: 9.609544690647454e-06, Final Batch Loss: 5.177272441869718e-07\n",
      "Epoch 3719, Loss: 8.687343574820261e-05, Final Batch Loss: 8.415344200329855e-05\n",
      "Epoch 3720, Loss: 1.2734333267871989e-05, Final Batch Loss: 6.055991889297729e-06\n",
      "Epoch 3721, Loss: 4.03515597682258e-05, Final Batch Loss: 8.266321316341418e-08\n",
      "Epoch 3722, Loss: 0.00011255781373620266, Final Batch Loss: 0.00010658899554982781\n",
      "Epoch 3723, Loss: 0.00024207445153479057, Final Batch Loss: 3.407005578992539e-06\n",
      "Epoch 3724, Loss: 2.497365471754165e-06, Final Batch Loss: 1.1937888757529436e-06\n",
      "Epoch 3725, Loss: 4.978856986781466e-05, Final Batch Loss: 1.9584872461564373e-06\n",
      "Epoch 3726, Loss: 1.9475326780593605e-05, Final Batch Loss: 4.864016318606446e-07\n",
      "Epoch 3727, Loss: 1.4549346929015883e-05, Final Batch Loss: 1.8184501868745429e-06\n",
      "Epoch 3728, Loss: 2.158887764380779e-05, Final Batch Loss: 1.0728144843596965e-06\n",
      "Epoch 3729, Loss: 3.620409916038625e-05, Final Batch Loss: 8.08812546893023e-06\n",
      "Epoch 3730, Loss: 5.386143180885483e-05, Final Batch Loss: 4.994531650481804e-07\n",
      "Epoch 3731, Loss: 3.814886042619037e-06, Final Batch Loss: 3.6928167901351117e-06\n",
      "Epoch 3732, Loss: 3.6740914765687194e-05, Final Batch Loss: 2.278665306221228e-06\n",
      "Epoch 3733, Loss: 1.582900665653142e-05, Final Batch Loss: 1.4444310636463342e-07\n",
      "Epoch 3734, Loss: 0.003919988287634624, Final Batch Loss: 0.00391771923750639\n",
      "Epoch 3735, Loss: 2.12338183303018e-06, Final Batch Loss: 1.2704028051757632e-07\n",
      "Epoch 3736, Loss: 3.3687794314118946e-06, Final Batch Loss: 1.5140372511268652e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3737, Loss: 1.600870632501028e-06, Final Batch Loss: 5.194605137148756e-07\n",
      "Epoch 3738, Loss: 4.703634999714268e-06, Final Batch Loss: 3.644608113972936e-06\n",
      "Epoch 3739, Loss: 1.898411142065015e-05, Final Batch Loss: 4.924852419208037e-07\n",
      "Epoch 3740, Loss: 8.631374228684763e-06, Final Batch Loss: 1.4531299541431508e-07\n",
      "Epoch 3741, Loss: 8.198708584927772e-06, Final Batch Loss: 7.972688763402402e-06\n",
      "Epoch 3742, Loss: 0.00022374561558535788, Final Batch Loss: 0.00021611363627016544\n",
      "Epoch 3743, Loss: 8.720710582110769e-06, Final Batch Loss: 8.083668944891542e-06\n",
      "Epoch 3744, Loss: 0.0018495275334089456, Final Batch Loss: 5.586233555732179e-07\n",
      "Epoch 3745, Loss: 1.937231161264208e-06, Final Batch Loss: 1.2720702216029167e-06\n",
      "Epoch 3746, Loss: 6.51791614245667e-05, Final Batch Loss: 6.450301589211449e-05\n",
      "Epoch 3747, Loss: 6.455394228055411e-05, Final Batch Loss: 3.445694858328352e-07\n",
      "Epoch 3748, Loss: 1.9917558802262647e-05, Final Batch Loss: 4.165647169429576e-06\n",
      "Epoch 3749, Loss: 6.0353657318046317e-05, Final Batch Loss: 3.0082317607593723e-05\n",
      "Epoch 3750, Loss: 0.000299918552627787, Final Batch Loss: 0.00013933319132775068\n",
      "Epoch 3751, Loss: 1.7416279547433078e-06, Final Batch Loss: 9.057674787982251e-07\n",
      "Epoch 3752, Loss: 2.066978424863919e-06, Final Batch Loss: 1.2120823384975665e-06\n",
      "Epoch 3753, Loss: 1.4766079345918115e-06, Final Batch Loss: 4.1331324496240995e-07\n",
      "Epoch 3754, Loss: 4.2210386794749866e-06, Final Batch Loss: 1.0876702560835838e-07\n",
      "Epoch 3755, Loss: 4.6819797262287466e-05, Final Batch Loss: 6.164376372908009e-06\n",
      "Epoch 3756, Loss: 8.304672434178428e-06, Final Batch Loss: 4.655184113744326e-07\n",
      "Epoch 3757, Loss: 4.59937375296704e-07, Final Batch Loss: 1.1137773725522493e-07\n",
      "Epoch 3758, Loss: 1.3367861811275361e-05, Final Batch Loss: 7.450616976711899e-06\n",
      "Epoch 3759, Loss: 1.1204966085642809e-05, Final Batch Loss: 8.97450081538409e-06\n",
      "Epoch 3760, Loss: 0.00045178719847172033, Final Batch Loss: 1.9352415620232932e-05\n",
      "Epoch 3761, Loss: 4.523554616753245e-05, Final Batch Loss: 9.818239959713537e-06\n",
      "Epoch 3762, Loss: 2.1824938812642358e-05, Final Batch Loss: 2.440572643536143e-06\n",
      "Epoch 3763, Loss: 1.3082283430776442e-05, Final Batch Loss: 1.4930353700037813e-06\n",
      "Epoch 3764, Loss: 2.3870455152064096e-05, Final Batch Loss: 4.815457032236736e-06\n",
      "Epoch 3765, Loss: 3.659321411220162e-06, Final Batch Loss: 5.3948671308035046e-08\n",
      "Epoch 3766, Loss: 6.391803864858048e-06, Final Batch Loss: 7.918258404515655e-08\n",
      "Epoch 3767, Loss: 3.4278007490229356e-06, Final Batch Loss: 4.5159552541917947e-07\n",
      "Epoch 3768, Loss: 1.5540867707386496e-05, Final Batch Loss: 2.2080919279687805e-06\n",
      "Epoch 3769, Loss: 8.490944765071617e-07, Final Batch Loss: 1.8011877500612172e-07\n",
      "Epoch 3770, Loss: 5.339825520422892e-06, Final Batch Loss: 1.653259005252039e-07\n",
      "Epoch 3771, Loss: 2.520726866350742e-06, Final Batch Loss: 1.3372930425248342e-06\n",
      "Epoch 3772, Loss: 4.7542009269818664e-05, Final Batch Loss: 1.0930143616860732e-05\n",
      "Epoch 3773, Loss: 1.5121740943868645e-06, Final Batch Loss: 1.4330192925626761e-06\n",
      "Epoch 3774, Loss: 6.203949851624202e-07, Final Batch Loss: 5.916950840401114e-08\n",
      "Epoch 3775, Loss: 1.7214106264873408e-05, Final Batch Loss: 1.1441438800829928e-05\n",
      "Epoch 3776, Loss: 6.155267058716163e-06, Final Batch Loss: 5.958811016171239e-06\n",
      "Epoch 3777, Loss: 7.01981343809166e-06, Final Batch Loss: 1.9498597794154193e-06\n",
      "Epoch 3778, Loss: 1.5018334352134843e-05, Final Batch Loss: 1.7775921605789335e-06\n",
      "Epoch 3779, Loss: 3.2283104474117863e-06, Final Batch Loss: 2.8764097805833444e-06\n",
      "Epoch 3780, Loss: 1.661326621160697e-06, Final Batch Loss: 8.979470749181928e-07\n",
      "Epoch 3781, Loss: 3.311878630540832e-05, Final Batch Loss: 1.757677097202759e-07\n",
      "Epoch 3782, Loss: 0.001215040058013983, Final Batch Loss: 0.00020498324010986835\n",
      "Epoch 3783, Loss: 5.514462463906966e-05, Final Batch Loss: 1.081360096577555e-05\n",
      "Epoch 3784, Loss: 7.200847433708191e-05, Final Batch Loss: 7.19503004802391e-05\n",
      "Epoch 3785, Loss: 5.442896431873123e-05, Final Batch Loss: 3.3500251106488577e-07\n",
      "Epoch 3786, Loss: 1.24016121461068e-06, Final Batch Loss: 3.480561261426374e-08\n",
      "Epoch 3787, Loss: 2.217014474581447e-05, Final Batch Loss: 9.023005418384855e-07\n",
      "Epoch 3788, Loss: 9.174302704195725e-07, Final Batch Loss: 3.028053470188752e-07\n",
      "Epoch 3789, Loss: 1.1946179938604473e-05, Final Batch Loss: 2.1229432149993954e-06\n",
      "Epoch 3790, Loss: 1.3302092384037678e-05, Final Batch Loss: 1.2527251783467364e-05\n",
      "Epoch 3791, Loss: 9.798323645782148e-06, Final Batch Loss: 3.149887390918593e-07\n",
      "Epoch 3792, Loss: 5.9024560414400185e-05, Final Batch Loss: 4.191270363662625e-06\n",
      "Epoch 3793, Loss: 1.6086080904642586e-05, Final Batch Loss: 1.0449335604789667e-05\n",
      "Epoch 3794, Loss: 2.4474671818097704e-06, Final Batch Loss: 1.0832968655449804e-06\n",
      "Epoch 3795, Loss: 0.0007048498928270419, Final Batch Loss: 8.915781108953524e-06\n",
      "Epoch 3796, Loss: 2.912169804858422e-05, Final Batch Loss: 1.5705514897490502e-06\n",
      "Epoch 3797, Loss: 5.787843974758289e-06, Final Batch Loss: 2.1656148874171777e-06\n",
      "Epoch 3798, Loss: 0.0006976042020596651, Final Batch Loss: 0.000694775371812284\n",
      "Epoch 3799, Loss: 7.363811459981662e-05, Final Batch Loss: 7.063246448524296e-05\n",
      "Epoch 3800, Loss: 7.713967988820514e-06, Final Batch Loss: 5.3197177294350695e-06\n",
      "Epoch 3801, Loss: 3.9590882806805894e-05, Final Batch Loss: 4.396773874759674e-06\n",
      "Epoch 3802, Loss: 1.0927291441475973e-05, Final Batch Loss: 7.926068064989522e-06\n",
      "Epoch 3803, Loss: 0.011938880604020596, Final Batch Loss: 3.0197541036613984e-06\n",
      "Epoch 3804, Loss: 7.607441034451767e-06, Final Batch Loss: 6.378185389621649e-06\n",
      "Epoch 3805, Loss: 0.01809938605060779, Final Batch Loss: 0.018097123131155968\n",
      "Epoch 3806, Loss: 0.00014267586220739759, Final Batch Loss: 0.00014018340152688324\n",
      "Epoch 3807, Loss: 1.4346806437970372e-05, Final Batch Loss: 7.118951998563716e-06\n",
      "Epoch 3808, Loss: 4.9317781304125674e-05, Final Batch Loss: 1.4857085261610337e-05\n",
      "Epoch 3809, Loss: 1.0947227110591484e-05, Final Batch Loss: 6.971315997361671e-06\n",
      "Epoch 3810, Loss: 0.008070622816603645, Final Batch Loss: 0.008067851886153221\n",
      "Epoch 3811, Loss: 0.00014902861562404723, Final Batch Loss: 3.4060137750202557e-06\n",
      "Epoch 3812, Loss: 0.00015039770278235665, Final Batch Loss: 6.092165676818695e-06\n",
      "Epoch 3813, Loss: 0.00021090413110869122, Final Batch Loss: 3.836532869172515e-06\n",
      "Epoch 3814, Loss: 3.0189214157871902e-05, Final Batch Loss: 2.3144039005273953e-06\n",
      "Epoch 3815, Loss: 0.0003034875530829595, Final Batch Loss: 0.0003018058487214148\n",
      "Epoch 3816, Loss: 2.6030079880001722e-05, Final Batch Loss: 2.2958325644140132e-05\n",
      "Epoch 3817, Loss: 0.0033292316630024743, Final Batch Loss: 4.4985520730733697e-07\n",
      "Epoch 3818, Loss: 2.6653137865650933e-05, Final Batch Loss: 1.051277376973303e-05\n",
      "Epoch 3819, Loss: 3.6865237689198693e-06, Final Batch Loss: 9.179723292618291e-07\n",
      "Epoch 3820, Loss: 6.661174722921714e-06, Final Batch Loss: 6.029873134139052e-07\n",
      "Epoch 3821, Loss: 0.007275002712049172, Final Batch Loss: 9.566248991177417e-06\n",
      "Epoch 3822, Loss: 9.34716540541558e-05, Final Batch Loss: 8.815551700536162e-05\n",
      "Epoch 3823, Loss: 0.0004235587542780195, Final Batch Loss: 1.6184583273570752e-07\n",
      "Epoch 3824, Loss: 3.163711983944495e-06, Final Batch Loss: 3.6545873882687374e-08\n",
      "Epoch 3825, Loss: 2.808707947998812e-06, Final Batch Loss: 8.701406706279613e-09\n",
      "Epoch 3826, Loss: 1.5523658930760575e-05, Final Batch Loss: 2.0013021639897488e-07\n",
      "Epoch 3827, Loss: 0.0002768758022284601, Final Batch Loss: 1.8540631572250277e-06\n",
      "Epoch 3828, Loss: 5.719757183442198e-06, Final Batch Loss: 2.8366051196826447e-07\n",
      "Epoch 3829, Loss: 0.0010116653946283805, Final Batch Loss: 0.0010109706781804562\n",
      "Epoch 3830, Loss: 0.0003648003166745184, Final Batch Loss: 0.00033479617559351027\n",
      "Epoch 3831, Loss: 1.9793722458416596e-05, Final Batch Loss: 7.356105015787762e-06\n",
      "Epoch 3832, Loss: 2.7715067972167162e-05, Final Batch Loss: 5.12155520482338e-06\n",
      "Epoch 3833, Loss: 2.0433239797057468e-05, Final Batch Loss: 7.535243184975116e-07\n",
      "Epoch 3834, Loss: 4.960805563314352e-05, Final Batch Loss: 3.68448490917217e-05\n",
      "Epoch 3835, Loss: 8.32436711561968e-07, Final Batch Loss: 1.4966352068768174e-07\n",
      "Epoch 3836, Loss: 2.597079458155349e-07, Final Batch Loss: 1.2094905343928986e-07\n",
      "Epoch 3837, Loss: 6.163316720630974e-05, Final Batch Loss: 1.9498285837471485e-05\n",
      "Epoch 3838, Loss: 1.692013307774687e-05, Final Batch Loss: 3.8720560269212e-07\n",
      "Epoch 3839, Loss: 1.2077266092092032e-05, Final Batch Loss: 4.723900019598659e-06\n",
      "Epoch 3840, Loss: 4.244384706453275e-05, Final Batch Loss: 2.392874876022688e-07\n",
      "Epoch 3841, Loss: 0.0010862345288842334, Final Batch Loss: 0.001084261341020465\n",
      "Epoch 3842, Loss: 7.694128163393543e-05, Final Batch Loss: 7.62913768994622e-05\n",
      "Epoch 3843, Loss: 0.00012414721823006403, Final Batch Loss: 0.00012196513125672936\n",
      "Epoch 3844, Loss: 6.938493015695713e-07, Final Batch Loss: 4.463764469164744e-07\n",
      "Epoch 3845, Loss: 1.355637607503013e-06, Final Batch Loss: 1.479233446843864e-07\n",
      "Epoch 3846, Loss: 0.00010815721634571673, Final Batch Loss: 4.742677447211463e-06\n",
      "Epoch 3847, Loss: 1.777813300130049e-06, Final Batch Loss: 1.4792381541894883e-08\n",
      "Epoch 3848, Loss: 1.8645648367510148e-06, Final Batch Loss: 1.7348660321658826e-06\n",
      "Epoch 3849, Loss: 1.6208317163091124e-05, Final Batch Loss: 1.5419651390402578e-05\n",
      "Epoch 3850, Loss: 8.823581723049756e-07, Final Batch Loss: 6.700060595221657e-08\n",
      "Epoch 3851, Loss: 0.002587767662589613, Final Batch Loss: 0.002575789811089635\n",
      "Epoch 3852, Loss: 0.0008063585960371711, Final Batch Loss: 5.699225766875315e-07\n",
      "Epoch 3853, Loss: 2.8643170963960074e-06, Final Batch Loss: 2.6430659545439994e-06\n",
      "Epoch 3854, Loss: 1.4096873428570689e-06, Final Batch Loss: 6.186483005876653e-07\n",
      "Epoch 3855, Loss: 1.771053305787973e-06, Final Batch Loss: 1.6322942428814713e-06\n",
      "Epoch 3856, Loss: 6.121902697486803e-05, Final Batch Loss: 2.1569529053522274e-05\n",
      "Epoch 3857, Loss: 3.3248548731990013e-06, Final Batch Loss: 1.8881982555285504e-07\n",
      "Epoch 3858, Loss: 0.0012816791208933864, Final Batch Loss: 4.504553089645924e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3859, Loss: 8.33317562864977e-06, Final Batch Loss: 6.1443206504918635e-06\n",
      "Epoch 3860, Loss: 6.682765501864196e-06, Final Batch Loss: 2.3580685137858381e-07\n",
      "Epoch 3861, Loss: 2.6368767976236995e-05, Final Batch Loss: 1.6184820196940564e-05\n",
      "Epoch 3862, Loss: 2.945483231542312e-06, Final Batch Loss: 2.0872089407930616e-06\n",
      "Epoch 3863, Loss: 5.929997342946081e-06, Final Batch Loss: 3.019349890109879e-07\n",
      "Epoch 3864, Loss: 4.2310673279644107e-05, Final Batch Loss: 3.99787058995571e-05\n",
      "Epoch 3865, Loss: 7.455545585344225e-07, Final Batch Loss: 5.386086741054896e-07\n",
      "Epoch 3866, Loss: 4.8635262714924465e-06, Final Batch Loss: 8.039848466978583e-07\n",
      "Epoch 3867, Loss: 2.205858820047979e-05, Final Batch Loss: 3.985225873748277e-07\n",
      "Epoch 3868, Loss: 3.253237885303406e-06, Final Batch Loss: 4.6987572943635314e-08\n",
      "Epoch 3869, Loss: 2.025034649477675e-05, Final Batch Loss: 1.6445613937321468e-07\n",
      "Epoch 3870, Loss: 0.006191364022924972, Final Batch Loss: 4.253349288774189e-06\n",
      "Epoch 3871, Loss: 3.89723875287018e-05, Final Batch Loss: 3.8069313177402364e-06\n",
      "Epoch 3872, Loss: 1.1750449857572676e-05, Final Batch Loss: 8.495776455674786e-06\n",
      "Epoch 3873, Loss: 3.963776464388502e-06, Final Batch Loss: 5.847246598023048e-07\n",
      "Epoch 3874, Loss: 9.352926554129226e-06, Final Batch Loss: 2.8399122129485477e-06\n",
      "Epoch 3875, Loss: 9.842436156759504e-06, Final Batch Loss: 5.902494649490109e-06\n",
      "Epoch 3876, Loss: 8.653061911445548e-07, Final Batch Loss: 3.193367490439414e-07\n",
      "Epoch 3877, Loss: 3.0886205991009774e-05, Final Batch Loss: 6.160522616482922e-07\n",
      "Epoch 3878, Loss: 2.0343078631412936e-05, Final Batch Loss: 1.3486517673300114e-05\n",
      "Epoch 3879, Loss: 3.5340542808626196e-05, Final Batch Loss: 1.3434198535833275e-06\n",
      "Epoch 3880, Loss: 0.000771218249354888, Final Batch Loss: 0.0007707466720603406\n",
      "Epoch 3881, Loss: 2.9509332648558484e-06, Final Batch Loss: 3.767683551814116e-07\n",
      "Epoch 3882, Loss: 4.1535280615789816e-05, Final Batch Loss: 2.3324268113356084e-05\n",
      "Epoch 3883, Loss: 8.209684961002495e-05, Final Batch Loss: 3.6765857203135965e-06\n",
      "Epoch 3884, Loss: 5.593167998085846e-06, Final Batch Loss: 3.1321160349762067e-06\n",
      "Epoch 3885, Loss: 1.5904744259387371e-06, Final Batch Loss: 3.245604602852836e-07\n",
      "Epoch 3886, Loss: 3.4605809048571246e-05, Final Batch Loss: 3.444988396950066e-05\n",
      "Epoch 3887, Loss: 6.237763682293007e-05, Final Batch Loss: 6.021804074407555e-05\n",
      "Epoch 3888, Loss: 2.6460228127689334e-05, Final Batch Loss: 2.0151297576376237e-05\n",
      "Epoch 3889, Loss: 1.242036222137699e-05, Final Batch Loss: 1.2392705684760585e-05\n",
      "Epoch 3890, Loss: 5.2669248248093936e-05, Final Batch Loss: 5.0993417971767485e-05\n",
      "Epoch 3891, Loss: 0.0011386968938609243, Final Batch Loss: 2.4363845341213164e-07\n",
      "Epoch 3892, Loss: 4.628206852430594e-06, Final Batch Loss: 3.087635377596598e-06\n",
      "Epoch 3893, Loss: 0.0002954046651666431, Final Batch Loss: 0.0002925249864347279\n",
      "Epoch 3894, Loss: 2.843472373115219e-07, Final Batch Loss: 1.3748174865213514e-07\n",
      "Epoch 3895, Loss: 1.8705757156567415e-06, Final Batch Loss: 1.1920528777409345e-06\n",
      "Epoch 3896, Loss: 5.2804378611881475e-06, Final Batch Loss: 1.9578085641569487e-07\n",
      "Epoch 3897, Loss: 5.104030151414918e-06, Final Batch Loss: 3.3667238312773407e-06\n",
      "Epoch 3898, Loss: 0.00012947576760780066, Final Batch Loss: 4.499743954511359e-05\n",
      "Epoch 3899, Loss: 4.025201860713423e-06, Final Batch Loss: 1.4783097412873758e-06\n",
      "Epoch 3900, Loss: 2.5327374828520988e-06, Final Batch Loss: 6.613055347770569e-08\n",
      "Epoch 3901, Loss: 2.9285098378295515e-05, Final Batch Loss: 3.9503555626652087e-07\n",
      "Epoch 3902, Loss: 3.565171300579095e-05, Final Batch Loss: 1.1722294402716216e-05\n",
      "Epoch 3903, Loss: 1.2238062225833346e-06, Final Batch Loss: 1.0302128430339508e-06\n",
      "Epoch 3904, Loss: 0.00011571858158276882, Final Batch Loss: 1.5067793356138282e-05\n",
      "Epoch 3905, Loss: 2.984719230880728e-05, Final Batch Loss: 2.387877248111181e-05\n",
      "Epoch 3906, Loss: 4.189220953776385e-05, Final Batch Loss: 1.2912237252749037e-06\n",
      "Epoch 3907, Loss: 1.8573650322650792e-05, Final Batch Loss: 1.3573942851508036e-05\n",
      "Epoch 3908, Loss: 4.579207961796783e-05, Final Batch Loss: 1.1189476936124265e-06\n",
      "Epoch 3909, Loss: 1.312671923869857e-05, Final Batch Loss: 4.011303076367767e-07\n",
      "Epoch 3910, Loss: 0.0004480813763620972, Final Batch Loss: 0.00044578415690921247\n",
      "Epoch 3911, Loss: 3.165725024700805e-05, Final Batch Loss: 1.6975106973404763e-06\n",
      "Epoch 3912, Loss: 2.3897500938119265e-05, Final Batch Loss: 4.1591570720811433e-07\n",
      "Epoch 3913, Loss: 7.77416701112088e-05, Final Batch Loss: 2.6500549665797735e-06\n",
      "Epoch 3914, Loss: 9.681857318355469e-05, Final Batch Loss: 9.367184975417331e-05\n",
      "Epoch 3915, Loss: 2.2344539941876462e-05, Final Batch Loss: 1.131182525426766e-08\n",
      "Epoch 3916, Loss: 1.096401039291095e-05, Final Batch Loss: 9.310489446079373e-08\n",
      "Epoch 3917, Loss: 0.0001762196709478303, Final Batch Loss: 3.252972646805574e-06\n",
      "Epoch 3918, Loss: 3.383489547559293e-05, Final Batch Loss: 2.4061579097178765e-05\n",
      "Epoch 3919, Loss: 1.4435704542847816e-05, Final Batch Loss: 3.3244969017687254e-06\n",
      "Epoch 3920, Loss: 1.4698770542054262e-05, Final Batch Loss: 6.995834382905741e-07\n",
      "Epoch 3921, Loss: 1.7449799088353757e-05, Final Batch Loss: 1.9549852368072607e-06\n",
      "Epoch 3922, Loss: 2.0807901819352992e-05, Final Batch Loss: 1.9400387827772647e-05\n",
      "Epoch 3923, Loss: 2.534266093334736e-05, Final Batch Loss: 2.3824553863960318e-05\n",
      "Epoch 3924, Loss: 7.766425255795184e-06, Final Batch Loss: 5.15113129040401e-07\n",
      "Epoch 3925, Loss: 9.523264452582225e-06, Final Batch Loss: 1.560091732244473e-06\n",
      "Epoch 3926, Loss: 2.559648089395239e-05, Final Batch Loss: 2.5572639060555957e-05\n",
      "Epoch 3927, Loss: 1.0536387890169863e-05, Final Batch Loss: 1.962942405953072e-06\n",
      "Epoch 3928, Loss: 2.546714895856894e-05, Final Batch Loss: 2.5048018869711086e-05\n",
      "Epoch 3929, Loss: 4.9459122390516086e-05, Final Batch Loss: 4.940571670886129e-05\n",
      "Epoch 3930, Loss: 6.189841633386095e-05, Final Batch Loss: 7.152307262003887e-07\n",
      "Epoch 3931, Loss: 6.612223160118447e-07, Final Batch Loss: 3.889498145781545e-07\n",
      "Epoch 3932, Loss: 6.976128119617897e-05, Final Batch Loss: 2.601699122806167e-07\n",
      "Epoch 3933, Loss: 0.002017194779654119, Final Batch Loss: 0.00201693014241755\n",
      "Epoch 3934, Loss: 2.0677675252045447e-06, Final Batch Loss: 1.4068883729123627e-06\n",
      "Epoch 3935, Loss: 7.371063929895172e-06, Final Batch Loss: 2.6893817448581103e-06\n",
      "Epoch 3936, Loss: 2.6839317683879926e-06, Final Batch Loss: 1.6793654822322424e-07\n",
      "Epoch 3937, Loss: 3.1678196137363557e-06, Final Batch Loss: 2.0620971099560848e-06\n",
      "Epoch 3938, Loss: 1.3303385486551633e-06, Final Batch Loss: 1.7837813004462078e-07\n",
      "Epoch 3939, Loss: 2.186426081607351e-05, Final Batch Loss: 1.1114349945273716e-05\n",
      "Epoch 3940, Loss: 2.3946618057379965e-05, Final Batch Loss: 1.9583969333325513e-05\n",
      "Epoch 3941, Loss: 2.211896969583904e-06, Final Batch Loss: 1.4313505971585982e-06\n",
      "Epoch 3942, Loss: 4.572594662022311e-06, Final Batch Loss: 1.5722168882348342e-06\n",
      "Epoch 3943, Loss: 1.6714834998765582e-05, Final Batch Loss: 5.908108846597315e-07\n",
      "Epoch 3944, Loss: 3.79158182113315e-05, Final Batch Loss: 3.592530629248358e-05\n",
      "Epoch 3945, Loss: 7.312213654131483e-06, Final Batch Loss: 4.5942482529426343e-07\n",
      "Epoch 3946, Loss: 0.00025866113719530404, Final Batch Loss: 0.00018402640125714242\n",
      "Epoch 3947, Loss: 3.1242265663422586e-05, Final Batch Loss: 2.9701212042709813e-05\n",
      "Epoch 3948, Loss: 5.886226699658437e-05, Final Batch Loss: 5.484533539856784e-05\n",
      "Epoch 3949, Loss: 0.0004040149833599571, Final Batch Loss: 0.00039277286850847304\n",
      "Epoch 3950, Loss: 2.3768500341248e-06, Final Batch Loss: 4.507228368311189e-07\n",
      "Epoch 3951, Loss: 4.902134935491631e-05, Final Batch Loss: 4.3767761326307664e-07\n",
      "Epoch 3952, Loss: 2.060164278816501e-05, Final Batch Loss: 1.2181935460375826e-07\n",
      "Epoch 3953, Loss: 3.937351834792935e-06, Final Batch Loss: 2.4092501007544342e-06\n",
      "Epoch 3954, Loss: 4.723413061924475e-05, Final Batch Loss: 4.020001540538942e-07\n",
      "Epoch 3955, Loss: 7.693805059716396e-06, Final Batch Loss: 1.40783606639161e-06\n",
      "Epoch 3956, Loss: 1.4083950645726873e-05, Final Batch Loss: 5.635450634144945e-06\n",
      "Epoch 3957, Loss: 9.855795155999658e-06, Final Batch Loss: 2.184045797548606e-07\n",
      "Epoch 3958, Loss: 0.00020582891397680214, Final Batch Loss: 3.639306896729977e-06\n",
      "Epoch 3959, Loss: 3.7615761556253346e-05, Final Batch Loss: 3.0106750159575313e-07\n",
      "Epoch 3960, Loss: 1.1877313454533578e-05, Final Batch Loss: 3.3763392366381595e-06\n",
      "Epoch 3961, Loss: 2.4121081878547557e-05, Final Batch Loss: 9.812597454583738e-06\n",
      "Epoch 3962, Loss: 1.596187757968437e-05, Final Batch Loss: 9.871255315374583e-06\n",
      "Epoch 3963, Loss: 0.00016694936493877321, Final Batch Loss: 9.207971743308008e-06\n",
      "Epoch 3964, Loss: 0.0004412576286085823, Final Batch Loss: 0.000440519506810233\n",
      "Epoch 3965, Loss: 1.7929355919932277e-06, Final Batch Loss: 2.906257634549547e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3966, Loss: 0.0005934571236139163, Final Batch Loss: 0.0003615669265855104\n",
      "Epoch 3967, Loss: 2.5566544593402796e-05, Final Batch Loss: 2.4537717990824603e-07\n",
      "Epoch 3968, Loss: 0.00011799688581959344, Final Batch Loss: 4.132685353397392e-05\n",
      "Epoch 3969, Loss: 4.896410857213596e-06, Final Batch Loss: 4.665146207116777e-06\n",
      "Epoch 3970, Loss: 4.308003610731248e-06, Final Batch Loss: 3.906990968971513e-06\n",
      "Epoch 3971, Loss: 0.00021867849864065647, Final Batch Loss: 0.00020237745775375515\n",
      "Epoch 3972, Loss: 6.482549042630126e-05, Final Batch Loss: 6.335310899885371e-05\n",
      "Epoch 3973, Loss: 0.0008607879681221675, Final Batch Loss: 0.0008312477148137987\n",
      "Epoch 3974, Loss: 1.2621925776556964e-05, Final Batch Loss: 3.428332604471507e-07\n",
      "Epoch 3975, Loss: 6.5057765823439695e-06, Final Batch Loss: 9.893356036627665e-07\n",
      "Epoch 3976, Loss: 0.0002096431126119569, Final Batch Loss: 1.5425306628458202e-05\n",
      "Epoch 3977, Loss: 6.793994748477417e-05, Final Batch Loss: 2.809292936944985e-06\n",
      "Epoch 3978, Loss: 1.8221144983954218e-06, Final Batch Loss: 1.686216251073347e-06\n",
      "Epoch 3979, Loss: 7.56856388761662e-05, Final Batch Loss: 3.181568899890408e-05\n",
      "Epoch 3980, Loss: 0.00014087443651078502, Final Batch Loss: 0.00013506716641131788\n",
      "Epoch 3981, Loss: 1.5180898571998114e-05, Final Batch Loss: 7.890207598393317e-06\n",
      "Epoch 3982, Loss: 0.00015835350495763123, Final Batch Loss: 2.2429157979786396e-06\n",
      "Epoch 3983, Loss: 2.082413040227493e-06, Final Batch Loss: 7.744242935814327e-08\n",
      "Epoch 3984, Loss: 5.2339968306114315e-05, Final Batch Loss: 4.928316411678679e-05\n",
      "Epoch 3985, Loss: 2.321184058473591e-05, Final Batch Loss: 2.2307778635877185e-05\n",
      "Epoch 3986, Loss: 0.00023034772311802953, Final Batch Loss: 1.579261152073741e-06\n",
      "Epoch 3987, Loss: 1.0118713362317067e-05, Final Batch Loss: 9.417305591341574e-06\n",
      "Epoch 3988, Loss: 0.0009210347852786072, Final Batch Loss: 0.0008375507313758135\n",
      "Epoch 3989, Loss: 1.3535765077676842e-05, Final Batch Loss: 2.836614783063851e-07\n",
      "Epoch 3990, Loss: 1.7309254758401948e-06, Final Batch Loss: 1.3399247791312519e-06\n",
      "Epoch 3991, Loss: 1.7200095498992596e-06, Final Batch Loss: 1.324241225120204e-06\n",
      "Epoch 3992, Loss: 0.0007963770149217453, Final Batch Loss: 8.88434806256555e-06\n",
      "Epoch 3993, Loss: 0.002232257160358131, Final Batch Loss: 4.537298809736967e-05\n",
      "Epoch 3994, Loss: 8.872879334376194e-06, Final Batch Loss: 2.36402775044553e-06\n",
      "Epoch 3995, Loss: 3.188516359386995e-05, Final Batch Loss: 5.74292471355875e-08\n",
      "Epoch 3996, Loss: 0.00013938036863692105, Final Batch Loss: 4.326444468460977e-06\n",
      "Epoch 3997, Loss: 2.3500286658872938e-05, Final Batch Loss: 3.8372894550775527e-07\n",
      "Epoch 3998, Loss: 5.6891795452429506e-06, Final Batch Loss: 1.4879339005346992e-07\n",
      "Epoch 3999, Loss: 1.0432578960717365e-06, Final Batch Loss: 8.892404821381206e-07\n",
      "Epoch 4000, Loss: 2.2738578763892292e-05, Final Batch Loss: 3.6473918498813873e-06\n",
      "Epoch 4001, Loss: 1.4108438108451082e-05, Final Batch Loss: 1.6418359791714465e-06\n",
      "Epoch 4002, Loss: 6.371294966811547e-05, Final Batch Loss: 8.138763405440841e-06\n",
      "Epoch 4003, Loss: 6.552582273400276e-05, Final Batch Loss: 1.2442980334981257e-07\n",
      "Epoch 4004, Loss: 2.666832642717054e-06, Final Batch Loss: 2.074135636576102e-06\n",
      "Epoch 4005, Loss: 8.755450016906252e-05, Final Batch Loss: 5.246277396508958e-06\n",
      "Epoch 4006, Loss: 3.384134538464423e-05, Final Batch Loss: 3.231892333133146e-05\n",
      "Epoch 4007, Loss: 7.985162710610894e-06, Final Batch Loss: 2.678998725968995e-06\n",
      "Epoch 4008, Loss: 2.352119736315217e-05, Final Batch Loss: 6.299733286141418e-06\n",
      "Epoch 4009, Loss: 5.951452976660221e-06, Final Batch Loss: 5.14611701873946e-06\n",
      "Epoch 4010, Loss: 2.3619025682819483e-05, Final Batch Loss: 2.1977561118546873e-05\n",
      "Epoch 4011, Loss: 2.1411839952634182e-05, Final Batch Loss: 1.249530578206759e-05\n",
      "Epoch 4012, Loss: 0.0002292560602654703, Final Batch Loss: 7.559045479865745e-05\n",
      "Epoch 4013, Loss: 5.5917575082276016e-05, Final Batch Loss: 5.091409548185766e-06\n",
      "Epoch 4014, Loss: 0.0033452927593486947, Final Batch Loss: 2.3841786855882674e-07\n",
      "Epoch 4015, Loss: 7.085218612701283e-06, Final Batch Loss: 2.328173422938562e-06\n",
      "Epoch 4016, Loss: 0.000910605105886475, Final Batch Loss: 4.089655192274222e-08\n",
      "Epoch 4017, Loss: 3.102806033439265e-06, Final Batch Loss: 2.3317829800362233e-06\n",
      "Epoch 4018, Loss: 1.397657072743641e-06, Final Batch Loss: 1.6271503966436285e-07\n",
      "Epoch 4019, Loss: 1.6037960222092806e-05, Final Batch Loss: 3.707393034346751e-06\n",
      "Epoch 4020, Loss: 3.4257228662681882e-06, Final Batch Loss: 2.9069342417642474e-06\n",
      "Epoch 4021, Loss: 2.9824618650309276e-05, Final Batch Loss: 2.366569788136985e-06\n",
      "Epoch 4022, Loss: 0.0033556703747308347, Final Batch Loss: 0.0033503056038171053\n",
      "Epoch 4023, Loss: 1.3583739928435534e-05, Final Batch Loss: 1.1789834388764575e-06\n",
      "Epoch 4024, Loss: 0.00044023521826375145, Final Batch Loss: 5.50787660813512e-07\n",
      "Epoch 4025, Loss: 6.180039918035618e-06, Final Batch Loss: 4.321465894463472e-06\n",
      "Epoch 4026, Loss: 2.230976224382175e-05, Final Batch Loss: 1.964154580491595e-05\n",
      "Epoch 4027, Loss: 2.137053590445248e-05, Final Batch Loss: 1.7663725770944438e-07\n",
      "Epoch 4028, Loss: 3.785244663845333e-05, Final Batch Loss: 2.5582014018254995e-07\n",
      "Epoch 4029, Loss: 3.7956432947794383e-06, Final Batch Loss: 7.369973786808259e-07\n",
      "Epoch 4030, Loss: 1.2169837191322586e-06, Final Batch Loss: 3.062842210965755e-07\n",
      "Epoch 4031, Loss: 7.267279926281844e-06, Final Batch Loss: 4.663818629069283e-07\n",
      "Epoch 4032, Loss: 4.7078087419549774e-06, Final Batch Loss: 6.265004515171313e-08\n",
      "Epoch 4033, Loss: 1.8476342120266054e-05, Final Batch Loss: 3.7951022022753023e-06\n",
      "Epoch 4034, Loss: 6.873194223544488e-06, Final Batch Loss: 3.349987025558221e-07\n",
      "Epoch 4035, Loss: 6.330788821173883e-05, Final Batch Loss: 1.3835162349096208e-07\n",
      "Epoch 4036, Loss: 0.0006909142703079851, Final Batch Loss: 0.0006841826834715903\n",
      "Epoch 4037, Loss: 6.011613429279805e-07, Final Batch Loss: 2.0883373252900128e-08\n",
      "Epoch 4038, Loss: 2.8725619358738186e-06, Final Batch Loss: 2.30133787226805e-06\n",
      "Epoch 4039, Loss: 8.540978615201311e-05, Final Batch Loss: 7.866127270972356e-05\n",
      "Epoch 4040, Loss: 1.8147169384974404e-06, Final Batch Loss: 1.4599531823478173e-06\n",
      "Epoch 4041, Loss: 1.4631267731601838e-05, Final Batch Loss: 6.950072929612361e-06\n",
      "Epoch 4042, Loss: 2.215151471318677e-05, Final Batch Loss: 1.676662577665411e-06\n",
      "Epoch 4043, Loss: 6.840487685622065e-06, Final Batch Loss: 3.1407489586854354e-06\n",
      "Epoch 4044, Loss: 4.2741312427097e-06, Final Batch Loss: 4.803123374585994e-07\n",
      "Epoch 4045, Loss: 0.0001195265314208882, Final Batch Loss: 8.074667903201771e-07\n",
      "Epoch 4046, Loss: 6.416365749828401e-06, Final Batch Loss: 4.083452495251549e-06\n",
      "Epoch 4047, Loss: 2.0466478872549487e-05, Final Batch Loss: 1.9275412341812626e-05\n",
      "Epoch 4048, Loss: 0.00022084360512053536, Final Batch Loss: 2.0289296571718296e-06\n",
      "Epoch 4049, Loss: 1.2858664035775291e-05, Final Batch Loss: 1.1181959962414112e-05\n",
      "Epoch 4050, Loss: 9.769354647914952e-06, Final Batch Loss: 4.611665929132869e-07\n",
      "Epoch 4051, Loss: 2.0976467254740783e-05, Final Batch Loss: 2.0817204131162725e-05\n",
      "Epoch 4052, Loss: 5.541470802228332e-07, Final Batch Loss: 5.307820742928016e-07\n",
      "Epoch 4053, Loss: 1.4660763014262557e-05, Final Batch Loss: 1.4458587429544423e-05\n",
      "Epoch 4054, Loss: 2.278603645322619e-06, Final Batch Loss: 8.701381659648177e-08\n",
      "Epoch 4055, Loss: 2.818893960920832e-06, Final Batch Loss: 5.107553420202748e-07\n",
      "Epoch 4056, Loss: 2.0568049990288273e-05, Final Batch Loss: 1.3077534504191135e-06\n",
      "Epoch 4057, Loss: 8.745024540957047e-06, Final Batch Loss: 4.4377127750294676e-08\n",
      "Epoch 4058, Loss: 2.2740750281968758e-05, Final Batch Loss: 3.7416029385894944e-08\n",
      "Epoch 4059, Loss: 0.00025836269196588546, Final Batch Loss: 8.993996016215533e-05\n",
      "Epoch 4060, Loss: 3.4735984328904124e-06, Final Batch Loss: 9.397501088415083e-08\n",
      "Epoch 4061, Loss: 0.00027757620151191986, Final Batch Loss: 2.5755903720892093e-07\n",
      "Epoch 4062, Loss: 1.158297345682513e-05, Final Batch Loss: 7.865382031013723e-06\n",
      "Epoch 4063, Loss: 0.00021054446915513836, Final Batch Loss: 5.5861273722257465e-06\n",
      "Epoch 4064, Loss: 5.4918468777032103e-05, Final Batch Loss: 5.0549297156976536e-05\n",
      "Epoch 4065, Loss: 8.306258287404944e-06, Final Batch Loss: 4.95979932679802e-08\n",
      "Epoch 4066, Loss: 0.0001202559305397699, Final Batch Loss: 2.67131269993115e-07\n",
      "Epoch 4067, Loss: 4.996739562557195e-06, Final Batch Loss: 2.6615100523486035e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4068, Loss: 7.601742072438356e-05, Final Batch Loss: 4.594772690325044e-06\n",
      "Epoch 4069, Loss: 3.2648907733801025e-05, Final Batch Loss: 8.466283247798856e-07\n",
      "Epoch 4070, Loss: 2.9086527632671277e-05, Final Batch Loss: 3.3500268159514235e-07\n",
      "Epoch 4071, Loss: 3.6562023240094277e-06, Final Batch Loss: 1.714174402422941e-07\n",
      "Epoch 4072, Loss: 2.180841548238277e-06, Final Batch Loss: 1.3487068883932807e-07\n",
      "Epoch 4073, Loss: 0.0002899885780474065, Final Batch Loss: 1.13118270306245e-08\n",
      "Epoch 4074, Loss: 1.0131182673234207e-05, Final Batch Loss: 2.5234069056523367e-08\n",
      "Epoch 4075, Loss: 7.397700898081894e-06, Final Batch Loss: 2.427674701266369e-07\n",
      "Epoch 4076, Loss: 4.318233436606533e-06, Final Batch Loss: 7.926722673801123e-07\n",
      "Epoch 4077, Loss: 1.1792420195888553e-06, Final Batch Loss: 5.803635190204659e-07\n",
      "Epoch 4078, Loss: 4.522509470916702e-06, Final Batch Loss: 3.841594207187882e-06\n",
      "Epoch 4079, Loss: 0.00017386271713348833, Final Batch Loss: 0.00017271272372454405\n",
      "Epoch 4080, Loss: 0.0001500647748002848, Final Batch Loss: 0.00014965613081585616\n",
      "Epoch 4081, Loss: 2.6228768206237874e-06, Final Batch Loss: 3.993905579591228e-07\n",
      "Epoch 4082, Loss: 8.923157750473365e-07, Final Batch Loss: 1.305210872715179e-08\n",
      "Epoch 4083, Loss: 1.6809141243356862e-06, Final Batch Loss: 1.0667592960089678e-06\n",
      "Epoch 4084, Loss: 4.459304932424857e-06, Final Batch Loss: 3.087583536398597e-06\n",
      "Epoch 4085, Loss: 9.237228368874639e-07, Final Batch Loss: 6.247490773603204e-07\n",
      "Epoch 4086, Loss: 1.977515864837187e-06, Final Batch Loss: 1.105889054997533e-06\n",
      "Epoch 4087, Loss: 9.233352216142521e-07, Final Batch Loss: 5.890757392990054e-07\n",
      "Epoch 4088, Loss: 9.846252879697204e-06, Final Batch Loss: 9.540128303342499e-06\n",
      "Epoch 4089, Loss: 4.979024868134729e-05, Final Batch Loss: 7.857173613956547e-07\n",
      "Epoch 4090, Loss: 0.00027812435143914627, Final Batch Loss: 0.0002762521617114544\n",
      "Epoch 4091, Loss: 1.142367898410157e-05, Final Batch Loss: 3.06287688545126e-07\n",
      "Epoch 4092, Loss: 3.876905267929942e-07, Final Batch Loss: 3.175956067025254e-07\n",
      "Epoch 4093, Loss: 0.0001972764130186988, Final Batch Loss: 0.00018632262072060257\n",
      "Epoch 4094, Loss: 1.1146555607410846e-06, Final Batch Loss: 9.571510872774525e-08\n",
      "Epoch 4095, Loss: 5.172459395907936e-05, Final Batch Loss: 4.735397669719532e-05\n",
      "Epoch 4096, Loss: 5.096915447211359e-05, Final Batch Loss: 3.170917261741124e-05\n",
      "Epoch 4097, Loss: 0.00015372848588413035, Final Batch Loss: 1.165057028629235e-06\n",
      "Epoch 4098, Loss: 0.00023466335369448643, Final Batch Loss: 2.2369144062395208e-05\n",
      "Epoch 4099, Loss: 3.1414480190505856e-06, Final Batch Loss: 4.785714509125683e-07\n",
      "Epoch 4100, Loss: 0.00020644863809593517, Final Batch Loss: 1.177270064545155e-06\n",
      "Epoch 4101, Loss: 1.9848815906442496e-06, Final Batch Loss: 1.961039743036963e-06\n",
      "Epoch 4102, Loss: 0.0007442175537022422, Final Batch Loss: 6.439030642013677e-08\n",
      "Epoch 4103, Loss: 0.00010622899208101444, Final Batch Loss: 6.626703543588519e-05\n",
      "Epoch 4104, Loss: 4.022398059078114e-06, Final Batch Loss: 3.1322103950515157e-06\n",
      "Epoch 4105, Loss: 2.1682254207178175e-05, Final Batch Loss: 2.162789496651385e-05\n",
      "Epoch 4106, Loss: 9.348413414045353e-06, Final Batch Loss: 6.594191745534772e-06\n",
      "Epoch 4107, Loss: 2.797483762151387e-05, Final Batch Loss: 3.5966670566267567e-06\n",
      "Epoch 4108, Loss: 1.678507112501393e-05, Final Batch Loss: 2.723526222325745e-07\n",
      "Epoch 4109, Loss: 0.0009479031959926942, Final Batch Loss: 2.38040756812552e-05\n",
      "Epoch 4110, Loss: 4.978658523668855e-06, Final Batch Loss: 4.500399882090278e-06\n",
      "Epoch 4111, Loss: 5.6047951261462003e-05, Final Batch Loss: 5.471666736411862e-05\n",
      "Epoch 4112, Loss: 0.0025709271665164124, Final Batch Loss: 0.002568737603724003\n",
      "Epoch 4113, Loss: 4.914706366321298e-07, Final Batch Loss: 8.092296610584526e-08\n",
      "Epoch 4114, Loss: 0.00013230117474449798, Final Batch Loss: 6.248757563298568e-05\n",
      "Epoch 4115, Loss: 6.6328934735793155e-06, Final Batch Loss: 5.477588729263516e-06\n",
      "Epoch 4116, Loss: 0.00012572560888202133, Final Batch Loss: 1.0423835874462384e-06\n",
      "Epoch 4117, Loss: 8.297580279759131e-06, Final Batch Loss: 4.342313332017511e-06\n",
      "Epoch 4118, Loss: 4.551764561711025e-06, Final Batch Loss: 7.804924848642258e-07\n",
      "Epoch 4119, Loss: 1.5748104686963416e-06, Final Batch Loss: 8.527369743660529e-08\n",
      "Epoch 4120, Loss: 2.038825712702419e-06, Final Batch Loss: 1.3748179128469928e-07\n",
      "Epoch 4121, Loss: 5.490458391932407e-06, Final Batch Loss: 8.527362638233171e-08\n",
      "Epoch 4122, Loss: 5.063761591372895e-06, Final Batch Loss: 2.952151135104941e-06\n",
      "Epoch 4123, Loss: 1.8451555661158636e-06, Final Batch Loss: 1.0989517704729224e-06\n",
      "Epoch 4124, Loss: 0.00011360437611074303, Final Batch Loss: 0.00010793465480674058\n",
      "Epoch 4125, Loss: 7.691108112339862e-05, Final Batch Loss: 4.4390624680090696e-05\n",
      "Epoch 4126, Loss: 6.241126538952813e-05, Final Batch Loss: 4.671241185860708e-06\n",
      "Epoch 4127, Loss: 6.083368657527899e-05, Final Batch Loss: 2.4534326712455368e-06\n",
      "Epoch 4128, Loss: 0.000593994467635639, Final Batch Loss: 0.00013242319982964545\n",
      "Epoch 4129, Loss: 2.8361405242094406e-06, Final Batch Loss: 2.6535130928095896e-06\n",
      "Epoch 4130, Loss: 4.898937618236232e-05, Final Batch Loss: 4.5560118451248854e-05\n",
      "Epoch 4131, Loss: 8.001256719580851e-05, Final Batch Loss: 3.222125451429747e-05\n",
      "Epoch 4132, Loss: 1.715593455742237e-05, Final Batch Loss: 1.096373409836815e-07\n",
      "Epoch 4133, Loss: 6.48986810958263e-07, Final Batch Loss: 2.4363925987813673e-08\n",
      "Epoch 4134, Loss: 3.929380689271511e-06, Final Batch Loss: 6.439018562787169e-08\n",
      "Epoch 4135, Loss: 9.117766421695706e-05, Final Batch Loss: 7.157590516726486e-06\n",
      "Epoch 4136, Loss: 1.162742159976915e-05, Final Batch Loss: 3.708478516273317e-06\n",
      "Epoch 4137, Loss: 1.18123800803005e-05, Final Batch Loss: 9.783133464225102e-06\n",
      "Epoch 4138, Loss: 5.299274403114396e-05, Final Batch Loss: 5.064539800514467e-05\n",
      "Epoch 4139, Loss: 3.864385746510379e-06, Final Batch Loss: 4.959798616255284e-08\n",
      "Epoch 4140, Loss: 3.931397342782361e-06, Final Batch Loss: 1.7402809859845547e-08\n",
      "Epoch 4141, Loss: 1.6427977698185714e-06, Final Batch Loss: 1.0067111588796251e-06\n",
      "Epoch 4142, Loss: 1.0622090087508695e-06, Final Batch Loss: 4.437609675278509e-07\n",
      "Epoch 4143, Loss: 1.1044490406675322e-05, Final Batch Loss: 1.1215421409360715e-06\n",
      "Epoch 4144, Loss: 4.868614098541002e-06, Final Batch Loss: 4.724133304989664e-06\n",
      "Epoch 4145, Loss: 1.771872780409467e-05, Final Batch Loss: 1.0223841400147649e-06\n",
      "Epoch 4146, Loss: 0.00012859069988735428, Final Batch Loss: 0.00012662990775424987\n",
      "Epoch 4147, Loss: 2.6238688235480367e-06, Final Batch Loss: 2.359703330512275e-06\n",
      "Epoch 4148, Loss: 0.0002767592450254597, Final Batch Loss: 0.0001855280133895576\n",
      "Epoch 4149, Loss: 2.262497309857281e-05, Final Batch Loss: 1.0589955309114885e-05\n",
      "Epoch 4150, Loss: 4.021331541537165e-05, Final Batch Loss: 8.614360069714166e-08\n",
      "Epoch 4151, Loss: 4.593004021558045e-07, Final Batch Loss: 7.831258841406452e-08\n",
      "Epoch 4152, Loss: 6.793326974730007e-06, Final Batch Loss: 1.2111668183933944e-06\n",
      "Epoch 4153, Loss: 1.5862509314956696e-06, Final Batch Loss: 1.1780912245740183e-06\n",
      "Epoch 4154, Loss: 5.243403620625031e-06, Final Batch Loss: 4.9782843234424945e-06\n",
      "Epoch 4155, Loss: 0.00010498549204385199, Final Batch Loss: 9.945372312358813e-07\n",
      "Epoch 4156, Loss: 1.4581009963876568e-05, Final Batch Loss: 5.401172529673204e-06\n",
      "Epoch 4157, Loss: 1.9176807796839057e-05, Final Batch Loss: 1.2094929502382001e-07\n",
      "Epoch 4158, Loss: 2.9701516268687556e-07, Final Batch Loss: 1.644555993607355e-07\n",
      "Epoch 4159, Loss: 0.00031539048433160133, Final Batch Loss: 3.341272645229765e-07\n",
      "Epoch 4160, Loss: 1.7675428125585313e-06, Final Batch Loss: 1.226839799528534e-06\n",
      "Epoch 4161, Loss: 4.418865060529242e-06, Final Batch Loss: 2.288443425868536e-07\n",
      "Epoch 4162, Loss: 3.2040352039075515e-05, Final Batch Loss: 3.166461829096079e-05\n",
      "Epoch 4163, Loss: 0.0060444247792474926, Final Batch Loss: 0.00534948380663991\n",
      "Epoch 4164, Loss: 4.681710834120167e-06, Final Batch Loss: 4.0713803173275664e-06\n",
      "Epoch 4165, Loss: 4.366445557479892e-05, Final Batch Loss: 1.84467921826581e-07\n",
      "Epoch 4166, Loss: 1.973176833303114e-05, Final Batch Loss: 4.655200598335796e-07\n",
      "Epoch 4167, Loss: 2.6010835085799044e-06, Final Batch Loss: 2.352653837078833e-06\n",
      "Epoch 4168, Loss: 3.9244359584245103e-07, Final Batch Loss: 2.532091798457259e-07\n",
      "Epoch 4169, Loss: 5.505382425496919e-07, Final Batch Loss: 4.176667900424036e-08\n",
      "Epoch 4170, Loss: 6.143627508947702e-07, Final Batch Loss: 3.741603293860862e-08\n",
      "Epoch 4171, Loss: 2.2227289882437162e-05, Final Batch Loss: 2.2114280000096187e-05\n",
      "Epoch 4172, Loss: 0.000692765970597975, Final Batch Loss: 0.0005039663519710302\n",
      "Epoch 4173, Loss: 1.0333737385792574e-06, Final Batch Loss: 4.872783065934527e-08\n",
      "Epoch 4174, Loss: 2.1553300886267834e-05, Final Batch Loss: 1.3052105174438111e-08\n",
      "Epoch 4175, Loss: 2.174934820686758e-06, Final Batch Loss: 1.8950338471768191e-06\n",
      "Epoch 4176, Loss: 3.121419005935877e-06, Final Batch Loss: 9.91958515328406e-08\n",
      "Epoch 4177, Loss: 1.8055178543363581e-06, Final Batch Loss: 8.41411065266584e-07\n",
      "Epoch 4178, Loss: 0.00010212375516971406, Final Batch Loss: 0.00010188152373302728\n",
      "Epoch 4179, Loss: 1.158866280093207e-05, Final Batch Loss: 5.462481567519717e-06\n",
      "Epoch 4180, Loss: 1.5347252428909997e-05, Final Batch Loss: 5.2556883929355536e-06\n",
      "Epoch 4181, Loss: 3.952124814077251e-06, Final Batch Loss: 3.6045162232767325e-06\n",
      "Epoch 4182, Loss: 6.062246484361822e-06, Final Batch Loss: 3.737234237632947e-06\n",
      "Epoch 4183, Loss: 2.0144889276707545e-06, Final Batch Loss: 9.640730240789708e-07\n",
      "Epoch 4184, Loss: 1.8825540792022366e-05, Final Batch Loss: 1.4088578609516844e-05\n",
      "Epoch 4185, Loss: 3.3804315648922056e-06, Final Batch Loss: 2.827942466865352e-07\n",
      "Epoch 4186, Loss: 1.7005506833811523e-06, Final Batch Loss: 7.230720484585618e-07\n",
      "Epoch 4187, Loss: 0.00010982992171193473, Final Batch Loss: 9.493507241131738e-05\n",
      "Epoch 4188, Loss: 5.505580111275776e-05, Final Batch Loss: 2.384074377914658e-06\n",
      "Epoch 4189, Loss: 9.700414466351504e-06, Final Batch Loss: 2.2334711502480786e-06\n",
      "Epoch 4190, Loss: 1.2869627994405164e-06, Final Batch Loss: 8.787982892499713e-07\n",
      "Epoch 4191, Loss: 1.070136541869715e-05, Final Batch Loss: 1.0626979019434657e-05\n",
      "Epoch 4192, Loss: 2.5843989988061367e-06, Final Batch Loss: 1.2947090226589353e-06\n",
      "Epoch 4193, Loss: 1.261030274690711e-05, Final Batch Loss: 1.0866697266465053e-05\n",
      "Epoch 4194, Loss: 0.001818547236325685, Final Batch Loss: 6.991028931224719e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4195, Loss: 2.1830343399642516e-07, Final Batch Loss: 3.5675718379479804e-08\n",
      "Epoch 4196, Loss: 5.824500101425656e-05, Final Batch Loss: 1.4817231885899673e-06\n",
      "Epoch 4197, Loss: 0.0004293024423134284, Final Batch Loss: 2.49728287826656e-07\n",
      "Epoch 4198, Loss: 5.315087037160993e-07, Final Batch Loss: 1.0093606306327274e-07\n",
      "Epoch 4199, Loss: 2.0626063701456587e-06, Final Batch Loss: 1.6339459989467287e-06\n",
      "Epoch 4200, Loss: 4.802445512375186e-06, Final Batch Loss: 4.793862444785191e-06\n",
      "Epoch 4201, Loss: 0.005472842214658158, Final Batch Loss: 1.3121014490025118e-05\n",
      "Epoch 4202, Loss: 9.47205137435958e-07, Final Batch Loss: 1.3661156117450446e-07\n",
      "Epoch 4203, Loss: 1.0123924766958226e-05, Final Batch Loss: 5.527707344299415e-06\n",
      "Epoch 4204, Loss: 0.01318927723377783, Final Batch Loss: 0.013188156299293041\n",
      "Epoch 4205, Loss: 8.961780963545607e-06, Final Batch Loss: 7.990990525286179e-06\n",
      "Epoch 4206, Loss: 2.382786203725118e-05, Final Batch Loss: 1.2155354625065229e-06\n",
      "Epoch 4207, Loss: 2.7574477599046077e-05, Final Batch Loss: 2.61713212239556e-05\n",
      "Epoch 4208, Loss: 0.0001647942965519178, Final Batch Loss: 0.00016243831487372518\n",
      "Epoch 4209, Loss: 6.661593488388462e-05, Final Batch Loss: 1.1120091585326008e-06\n",
      "Epoch 4210, Loss: 6.594967576489807e-07, Final Batch Loss: 2.4363922435099994e-08\n",
      "Epoch 4211, Loss: 2.2861655111228174e-06, Final Batch Loss: 1.938554305525031e-06\n",
      "Epoch 4212, Loss: 2.8461270630941726e-05, Final Batch Loss: 1.535779119876679e-05\n",
      "Epoch 4213, Loss: 2.739124397521664e-06, Final Batch Loss: 9.649597814131994e-07\n",
      "Epoch 4214, Loss: 5.432980856312497e-05, Final Batch Loss: 5.33380480192136e-05\n",
      "Epoch 4215, Loss: 3.441959847805265e-05, Final Batch Loss: 3.202749894626322e-06\n",
      "Epoch 4216, Loss: 3.319008646940347e-05, Final Batch Loss: 2.0668419892899692e-05\n",
      "Epoch 4217, Loss: 1.1624759125083983e-05, Final Batch Loss: 1.2878065547283768e-07\n",
      "Epoch 4218, Loss: 4.279238737581181e-06, Final Batch Loss: 2.93277230412059e-06\n",
      "Epoch 4219, Loss: 8.549588892492466e-05, Final Batch Loss: 3.4815053368220106e-05\n",
      "Epoch 4220, Loss: 3.236471820855513e-05, Final Batch Loss: 1.8496493794373237e-05\n",
      "Epoch 4221, Loss: 3.539824820109061e-05, Final Batch Loss: 3.093373743467964e-05\n",
      "Epoch 4222, Loss: 0.00018806291592454727, Final Batch Loss: 3.045450398531102e-07\n",
      "Epoch 4223, Loss: 0.00032881076685953303, Final Batch Loss: 8.318143045471516e-07\n",
      "Epoch 4224, Loss: 0.0001120718807214871, Final Batch Loss: 2.0472849428188056e-05\n",
      "Epoch 4225, Loss: 2.8989662382628012e-05, Final Batch Loss: 8.327032219312969e-07\n",
      "Epoch 4226, Loss: 0.00025322282453998923, Final Batch Loss: 4.905661626253277e-05\n",
      "Epoch 4227, Loss: 2.8250468176338472e-05, Final Batch Loss: 5.185959253140027e-07\n",
      "Epoch 4228, Loss: 0.00035436934444987855, Final Batch Loss: 2.650280976013164e-06\n",
      "Epoch 4229, Loss: 0.0001418802476109704, Final Batch Loss: 0.0001126580173149705\n",
      "Epoch 4230, Loss: 0.0008542670257156715, Final Batch Loss: 0.0006931697716936469\n",
      "Epoch 4231, Loss: 9.511495136393933e-06, Final Batch Loss: 9.440814210393e-07\n",
      "Epoch 4232, Loss: 4.430561313029102e-05, Final Batch Loss: 8.28361237381614e-07\n",
      "Epoch 4233, Loss: 6.203350335454161e-05, Final Batch Loss: 1.9758756479859585e-06\n",
      "Epoch 4234, Loss: 1.8221219306724379e-06, Final Batch Loss: 8.370465138796135e-07\n",
      "Epoch 4235, Loss: 8.297991669792282e-06, Final Batch Loss: 1.4009249582613847e-07\n",
      "Epoch 4236, Loss: 0.0002952549075416755, Final Batch Loss: 1.6790563677204773e-05\n",
      "Epoch 4237, Loss: 3.611919055401813e-05, Final Batch Loss: 2.6429086574353278e-05\n",
      "Epoch 4238, Loss: 3.893943130606203e-06, Final Batch Loss: 2.0081915863556787e-06\n",
      "Epoch 4239, Loss: 5.557763824981521e-05, Final Batch Loss: 5.119655907037668e-05\n",
      "Epoch 4240, Loss: 6.996627121225174e-06, Final Batch Loss: 1.2755693887811503e-06\n",
      "Epoch 4241, Loss: 2.1216085542619112e-05, Final Batch Loss: 2.6946534035232617e-06\n",
      "Epoch 4242, Loss: 3.339978275107569e-05, Final Batch Loss: 4.3245154301985167e-07\n",
      "Epoch 4243, Loss: 0.01521696483897017, Final Batch Loss: 0.015216663479804993\n",
      "Epoch 4244, Loss: 3.119084249192383e-05, Final Batch Loss: 2.1059971913928166e-05\n",
      "Epoch 4245, Loss: 1.4306316984402656e-05, Final Batch Loss: 1.0223874369330588e-06\n",
      "Epoch 4246, Loss: 1.187706334349059e-05, Final Batch Loss: 9.12349332793383e-06\n",
      "Epoch 4247, Loss: 1.3625860958654812e-05, Final Batch Loss: 3.0019469932085485e-07\n",
      "Epoch 4248, Loss: 3.176362042722758e-06, Final Batch Loss: 9.954044344340218e-07\n",
      "Epoch 4249, Loss: 3.554330529342842e-05, Final Batch Loss: 1.7402814744826856e-09\n",
      "Epoch 4250, Loss: 7.409426245885697e-07, Final Batch Loss: 6.212568450791878e-07\n",
      "Epoch 4251, Loss: 8.881971183427595e-06, Final Batch Loss: 8.410393093072344e-06\n",
      "Epoch 4252, Loss: 0.0025819733083380925, Final Batch Loss: 1.922991259561968e-07\n",
      "Epoch 4253, Loss: 1.0139939448094992e-06, Final Batch Loss: 9.31024658257229e-07\n",
      "Epoch 4254, Loss: 5.3252287980143365e-05, Final Batch Loss: 3.567569351048405e-08\n",
      "Epoch 4255, Loss: 0.004050298476840908, Final Batch Loss: 0.004049526061862707\n",
      "Epoch 4256, Loss: 1.7031813968060305e-06, Final Batch Loss: 1.1572188896025182e-06\n",
      "Epoch 4257, Loss: 0.0009236347591325966, Final Batch Loss: 1.131182614244608e-08\n",
      "Epoch 4258, Loss: 3.9759172965059264e-07, Final Batch Loss: 8.701407372413428e-10\n",
      "Epoch 4259, Loss: 3.151391780420454e-05, Final Batch Loss: 8.675042977301928e-07\n",
      "Epoch 4260, Loss: 5.425315233509309e-06, Final Batch Loss: 5.377631623559864e-06\n",
      "Epoch 4261, Loss: 2.9317623528868353e-06, Final Batch Loss: 1.801181923610784e-07\n",
      "Epoch 4262, Loss: 2.0222918273304913e-07, Final Batch Loss: 1.9316928501211805e-07\n",
      "Epoch 4263, Loss: 1.421181613947553e-06, Final Batch Loss: 1.7402814744826856e-09\n",
      "Epoch 4264, Loss: 9.863862096892717e-06, Final Batch Loss: 3.8286152914679406e-08\n",
      "Epoch 4265, Loss: 2.180897837433804e-05, Final Batch Loss: 6.351813794935879e-07\n",
      "Epoch 4266, Loss: 0.0002336565448786132, Final Batch Loss: 2.1498963178601116e-05\n",
      "Epoch 4267, Loss: 1.3108387975080404e-06, Final Batch Loss: 6.264997409743955e-08\n",
      "Epoch 4268, Loss: 0.012633501784875989, Final Batch Loss: 0.010714538395404816\n",
      "Epoch 4269, Loss: 2.1464668691351108e-06, Final Batch Loss: 1.9967410480603576e-06\n",
      "Epoch 4270, Loss: 4.641650548364851e-06, Final Batch Loss: 1.0997957815561676e-06\n",
      "Epoch 4271, Loss: 2.60528963735851e-06, Final Batch Loss: 1.7470700868216227e-06\n",
      "Epoch 4272, Loss: 7.278110388142522e-05, Final Batch Loss: 2.4419970941380598e-05\n",
      "Epoch 4273, Loss: 5.362695810617879e-05, Final Batch Loss: 3.7313617212930694e-05\n",
      "Epoch 4274, Loss: 0.01602827835092846, Final Batch Loss: 2.8714636002291627e-08\n",
      "Epoch 4275, Loss: 2.9759836479570367e-06, Final Batch Loss: 1.5408734270749846e-06\n",
      "Epoch 4276, Loss: 5.4247556477093895e-05, Final Batch Loss: 1.0798095217978698e-06\n",
      "Epoch 4277, Loss: 2.2834149149275618e-06, Final Batch Loss: 7.491726137232035e-07\n",
      "Epoch 4278, Loss: 0.056062482678102654, Final Batch Loss: 7.831262749391499e-09\n",
      "Epoch 4279, Loss: 0.0002585919628472766, Final Batch Loss: 0.00025800548610277474\n",
      "Epoch 4280, Loss: 0.0015284231371879287, Final Batch Loss: 0.0015233047306537628\n",
      "Epoch 4281, Loss: 3.224223019060446e-05, Final Batch Loss: 2.8152926461189054e-06\n",
      "Epoch 4282, Loss: 2.211927210282738e-06, Final Batch Loss: 6.691279281767493e-07\n",
      "Epoch 4283, Loss: 0.00011471242396510206, Final Batch Loss: 3.2459243811899796e-05\n",
      "Epoch 4284, Loss: 7.192374937403656e-06, Final Batch Loss: 5.8612249631551094e-06\n",
      "Epoch 4285, Loss: 8.23671371108503e-06, Final Batch Loss: 5.832012902828865e-06\n",
      "Epoch 4286, Loss: 1.1458089943516825e-06, Final Batch Loss: 9.483994176662236e-07\n",
      "Epoch 4287, Loss: 5.9052562107808626e-05, Final Batch Loss: 9.310194286626938e-07\n",
      "Epoch 4288, Loss: 0.0012076923763970626, Final Batch Loss: 1.6313884998453432e-06\n",
      "Epoch 4289, Loss: 0.00017573888999322662, Final Batch Loss: 0.00016905429947655648\n",
      "Epoch 4290, Loss: 3.8850833334436174e-05, Final Batch Loss: 1.5088550753716845e-05\n",
      "Epoch 4291, Loss: 4.031029857287649e-05, Final Batch Loss: 1.9174733097315766e-05\n",
      "Epoch 4292, Loss: 0.0002444333783842012, Final Batch Loss: 1.5079110653459793e-06\n",
      "Epoch 4293, Loss: 2.3237790628627408e-05, Final Batch Loss: 1.4834673493169248e-05\n",
      "Epoch 4294, Loss: 5.136177763631622e-05, Final Batch Loss: 1.287805702077094e-07\n",
      "Epoch 4295, Loss: 0.00022164730836493618, Final Batch Loss: 9.023213465297886e-07\n",
      "Epoch 4296, Loss: 9.628583683252145e-06, Final Batch Loss: 4.0026199599196843e-07\n",
      "Epoch 4297, Loss: 0.00019626150242402218, Final Batch Loss: 0.0001836793526308611\n",
      "Epoch 4298, Loss: 0.010893093055074132, Final Batch Loss: 7.4613894867070485e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4299, Loss: 4.6228366045397706e-05, Final Batch Loss: 4.041664215037599e-05\n",
      "Epoch 4300, Loss: 0.00016450749535579234, Final Batch Loss: 0.00011725529475370422\n",
      "Epoch 4301, Loss: 1.5271815300366143e-05, Final Batch Loss: 6.7036230575467926e-06\n",
      "Epoch 4302, Loss: 7.348758344960515e-06, Final Batch Loss: 2.1753453438577708e-07\n",
      "Epoch 4303, Loss: 0.00010804518024087884, Final Batch Loss: 1.1649044608930126e-05\n",
      "Epoch 4304, Loss: 1.9592162914250366e-06, Final Batch Loss: 4.176598338290205e-07\n",
      "Epoch 4305, Loss: 7.477787949028425e-05, Final Batch Loss: 5.039931784267537e-05\n",
      "Epoch 4306, Loss: 4.4927198018740455e-05, Final Batch Loss: 1.3939467180534848e-06\n",
      "Epoch 4307, Loss: 3.5390551147429505e-06, Final Batch Loss: 1.239015318788006e-06\n",
      "Epoch 4308, Loss: 8.642241982670384e-05, Final Batch Loss: 8.252103725681081e-05\n",
      "Epoch 4309, Loss: 3.537658162144908e-05, Final Batch Loss: 3.50141926901415e-05\n",
      "Epoch 4310, Loss: 9.997384267990128e-06, Final Batch Loss: 6.936104455235181e-06\n",
      "Epoch 4311, Loss: 1.8156476926378673e-05, Final Batch Loss: 1.331810653937282e-05\n",
      "Epoch 4312, Loss: 0.00027812995176645927, Final Batch Loss: 0.0002694700378924608\n",
      "Epoch 4313, Loss: 1.19871498327484e-05, Final Batch Loss: 1.0947688679152634e-05\n",
      "Epoch 4314, Loss: 1.190154731034454e-05, Final Batch Loss: 4.019972550395323e-07\n",
      "Epoch 4315, Loss: 1.348462274108897e-05, Final Batch Loss: 8.701984370418359e-06\n",
      "Epoch 4316, Loss: 3.5728067814488895e-05, Final Batch Loss: 3.314848436275497e-05\n",
      "Epoch 4317, Loss: 2.2482264029122234e-05, Final Batch Loss: 4.568180145270162e-07\n",
      "Epoch 4318, Loss: 4.627409225577139e-05, Final Batch Loss: 2.8572126211656723e-06\n",
      "Epoch 4319, Loss: 4.975207275492721e-06, Final Batch Loss: 3.836104951915331e-06\n",
      "Epoch 4320, Loss: 1.4923776348041429e-06, Final Batch Loss: 6.813070854150283e-07\n",
      "Epoch 4321, Loss: 6.189969354863933e-07, Final Batch Loss: 4.959732677889406e-07\n",
      "Epoch 4322, Loss: 5.241449457571434e-06, Final Batch Loss: 4.04659976993571e-06\n",
      "Epoch 4323, Loss: 1.5797807009221287e-05, Final Batch Loss: 6.610684522456722e-06\n",
      "Epoch 4324, Loss: 0.00011264943577771191, Final Batch Loss: 0.00011171963706146926\n",
      "Epoch 4325, Loss: 0.0003812346621998586, Final Batch Loss: 3.921232564607635e-05\n",
      "Epoch 4326, Loss: 2.015027007473691e-06, Final Batch Loss: 1.241612608282594e-06\n",
      "Epoch 4327, Loss: 7.21429110441818e-05, Final Batch Loss: 4.002645681566719e-08\n",
      "Epoch 4328, Loss: 3.0498773213594177e-06, Final Batch Loss: 1.9491092473344906e-07\n",
      "Epoch 4329, Loss: 2.0011138076370116e-05, Final Batch Loss: 1.3793992366117891e-05\n",
      "Epoch 4330, Loss: 2.4614160338387592e-05, Final Batch Loss: 2.1758873117505573e-05\n",
      "Epoch 4331, Loss: 8.512032763974275e-06, Final Batch Loss: 4.3332602217560634e-07\n",
      "Epoch 4332, Loss: 1.0793848105095094e-05, Final Batch Loss: 5.08884158989531e-06\n",
      "Epoch 4333, Loss: 5.043402597948443e-05, Final Batch Loss: 4.9081303586717695e-05\n",
      "Epoch 4334, Loss: 2.752563773356087e-06, Final Batch Loss: 1.17811907784926e-06\n",
      "Epoch 4335, Loss: 1.3548327615353628e-05, Final Batch Loss: 3.3133071610791376e-06\n",
      "Epoch 4336, Loss: 4.5735601815977134e-05, Final Batch Loss: 1.300325857300777e-05\n",
      "Epoch 4337, Loss: 2.8687670408089616e-06, Final Batch Loss: 2.9323470585040923e-07\n",
      "Epoch 4338, Loss: 0.0002066921147161338, Final Batch Loss: 0.00020162141299806535\n",
      "Epoch 4339, Loss: 3.0655891691822035e-06, Final Batch Loss: 2.2526005523104686e-06\n",
      "Epoch 4340, Loss: 4.5681104666073225e-05, Final Batch Loss: 1.225072765009827e-06\n",
      "Epoch 4341, Loss: 2.8464260140026454e-05, Final Batch Loss: 2.0704819689854048e-05\n",
      "Epoch 4342, Loss: 0.00036258747559259064, Final Batch Loss: 4.961411377735203e-06\n",
      "Epoch 4343, Loss: 1.4740056712980731e-06, Final Batch Loss: 6.090888291510055e-07\n",
      "Epoch 4344, Loss: 1.7946024399861926e-06, Final Batch Loss: 1.133728460445127e-06\n",
      "Epoch 4345, Loss: 8.015297908059438e-06, Final Batch Loss: 6.097676759964088e-06\n",
      "Epoch 4346, Loss: 5.7451199609204195e-05, Final Batch Loss: 6.367487003444694e-06\n",
      "Epoch 4347, Loss: 0.0013238919603253407, Final Batch Loss: 1.5836512545774895e-07\n",
      "Epoch 4348, Loss: 4.840891767798894e-05, Final Batch Loss: 8.997047871162067e-07\n",
      "Epoch 4349, Loss: 2.7417981129929103e-06, Final Batch Loss: 3.1585878446094284e-07\n",
      "Epoch 4350, Loss: 1.3801108380562255e-06, Final Batch Loss: 9.223473540487248e-08\n",
      "Epoch 4351, Loss: 2.1544919377447513e-06, Final Batch Loss: 7.326240734073508e-07\n",
      "Epoch 4352, Loss: 5.5054611948435195e-05, Final Batch Loss: 2.4449573174933903e-05\n",
      "Epoch 4353, Loss: 1.796991814728699e-05, Final Batch Loss: 1.40962541195222e-07\n",
      "Epoch 4354, Loss: 1.2812948057217e-05, Final Batch Loss: 1.5548988585578627e-06\n",
      "Epoch 4355, Loss: 5.838525368062619e-06, Final Batch Loss: 2.1318376752788026e-07\n",
      "Epoch 4356, Loss: 1.3750457128480775e-06, Final Batch Loss: 7.70916301462421e-07\n",
      "Epoch 4357, Loss: 5.455647738017433e-06, Final Batch Loss: 6.465025990110007e-07\n",
      "Epoch 4358, Loss: 1.84707163271014e-05, Final Batch Loss: 1.8759377553578815e-06\n",
      "Epoch 4359, Loss: 8.220670906666783e-06, Final Batch Loss: 2.421304316158057e-06\n",
      "Epoch 4360, Loss: 7.99044158839024e-06, Final Batch Loss: 2.540795662753226e-07\n",
      "Epoch 4361, Loss: 1.291498597311147e-05, Final Batch Loss: 3.6371716305438895e-07\n",
      "Epoch 4362, Loss: 4.503577599734854e-06, Final Batch Loss: 8.10066183021263e-07\n",
      "Epoch 4363, Loss: 9.764001234202624e-07, Final Batch Loss: 1.1050773451870555e-07\n",
      "Epoch 4364, Loss: 0.0006162410718388855, Final Batch Loss: 0.0002738312177825719\n",
      "Epoch 4365, Loss: 1.7874675435791687e-05, Final Batch Loss: 1.131182614244608e-08\n",
      "Epoch 4366, Loss: 2.8955734933333588e-05, Final Batch Loss: 6.003876933391439e-07\n",
      "Epoch 4367, Loss: 2.068899141249858e-05, Final Batch Loss: 1.948360113601666e-05\n",
      "Epoch 4368, Loss: 1.1072895546249129e-05, Final Batch Loss: 1.067569428414572e-05\n",
      "Epoch 4369, Loss: 8.648988659842871e-05, Final Batch Loss: 1.1273183190496638e-05\n",
      "Epoch 4370, Loss: 2.5605688733776333e-05, Final Batch Loss: 4.773074124386767e-06\n",
      "Epoch 4371, Loss: 1.605117108738341e-05, Final Batch Loss: 1.4175888281897642e-05\n",
      "Epoch 4372, Loss: 1.5305884062399855e-05, Final Batch Loss: 1.0598750122881029e-05\n",
      "Epoch 4373, Loss: 7.899674599798345e-06, Final Batch Loss: 3.828616002010676e-08\n",
      "Epoch 4374, Loss: 2.6723912014858797e-05, Final Batch Loss: 1.3203161870478652e-05\n",
      "Epoch 4375, Loss: 0.0001151432399453256, Final Batch Loss: 1.139880438927321e-07\n",
      "Epoch 4376, Loss: 0.0017339141827505955, Final Batch Loss: 5.464700279844692e-06\n",
      "Epoch 4377, Loss: 3.7484363247131114e-05, Final Batch Loss: 3.1982465316104935e-06\n",
      "Epoch 4378, Loss: 2.190449561112473e-05, Final Batch Loss: 2.10786620300496e-05\n",
      "Epoch 4379, Loss: 3.0239109491958516e-06, Final Batch Loss: 2.24906170842587e-06\n",
      "Epoch 4380, Loss: 0.0001292848965022131, Final Batch Loss: 2.2202939362614416e-06\n",
      "Epoch 4381, Loss: 3.757760339340166e-06, Final Batch Loss: 6.151641969154298e-07\n",
      "Epoch 4382, Loss: 0.00011195962906640489, Final Batch Loss: 1.5093270121724345e-05\n",
      "Epoch 4383, Loss: 9.782550264958445e-05, Final Batch Loss: 3.0889864888195007e-07\n",
      "Epoch 4384, Loss: 0.00015327384971897118, Final Batch Loss: 1.7467984434915707e-05\n",
      "Epoch 4385, Loss: 0.0001244611753463687, Final Batch Loss: 5.578518084803363e-06\n",
      "Epoch 4386, Loss: 3.344383821968222e-05, Final Batch Loss: 3.1047627999214455e-05\n",
      "Epoch 4387, Loss: 1.5027309245851939e-06, Final Batch Loss: 1.7576792288309662e-07\n",
      "Epoch 4388, Loss: 6.824947104178136e-05, Final Batch Loss: 5.133824743097648e-08\n",
      "Epoch 4389, Loss: 3.827908329867569e-06, Final Batch Loss: 3.69248755305307e-06\n",
      "Epoch 4390, Loss: 8.806851667486626e-06, Final Batch Loss: 7.309016041290306e-07\n",
      "Epoch 4391, Loss: 1.7512828435428673e-05, Final Batch Loss: 1.2216481991345063e-05\n",
      "Epoch 4392, Loss: 7.176753001658653e-06, Final Batch Loss: 3.906906158590573e-07\n",
      "Epoch 4393, Loss: 1.6504006907780422e-06, Final Batch Loss: 1.3590595244750148e-06\n",
      "Epoch 4394, Loss: 6.560203166827705e-05, Final Batch Loss: 5.76893057768757e-07\n",
      "Epoch 4395, Loss: 2.8194121057367738e-05, Final Batch Loss: 7.935449843898823e-07\n",
      "Epoch 4396, Loss: 4.599155090545537e-06, Final Batch Loss: 1.935991349455435e-06\n",
      "Epoch 4397, Loss: 6.9688453834260145e-06, Final Batch Loss: 2.7670060376294714e-07\n",
      "Epoch 4398, Loss: 0.00019690113822434796, Final Batch Loss: 5.994067578285467e-06\n",
      "Epoch 4399, Loss: 3.035189874367461e-05, Final Batch Loss: 3.4892363487415423e-07\n",
      "Epoch 4400, Loss: 1.2414044704200933e-05, Final Batch Loss: 5.031185537518468e-06\n",
      "Epoch 4401, Loss: 0.00011473767349912123, Final Batch Loss: 2.7844194505632913e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4402, Loss: 0.0001464381593905273, Final Batch Loss: 8.675629032950383e-06\n",
      "Epoch 4403, Loss: 9.64099308475852e-06, Final Batch Loss: 5.3173944252193905e-06\n",
      "Epoch 4404, Loss: 3.6773636935549803e-06, Final Batch Loss: 1.5575496092878893e-07\n",
      "Epoch 4405, Loss: 8.854701218297123e-05, Final Batch Loss: 3.999089585704496e-06\n",
      "Epoch 4406, Loss: 4.2260912096026004e-05, Final Batch Loss: 2.2413480564864585e-06\n",
      "Epoch 4407, Loss: 6.757933624612633e-05, Final Batch Loss: 1.9762841475312598e-05\n",
      "Epoch 4408, Loss: 4.368717725355964e-07, Final Batch Loss: 1.6793671875348082e-07\n",
      "Epoch 4409, Loss: 1.3284600299812155e-05, Final Batch Loss: 7.530178208980942e-06\n",
      "Epoch 4410, Loss: 9.970825897198665e-05, Final Batch Loss: 9.910316293826327e-05\n",
      "Epoch 4411, Loss: 4.047088850711589e-05, Final Batch Loss: 4.692825768870534e-06\n",
      "Epoch 4412, Loss: 1.7441293607589614e-05, Final Batch Loss: 1.6350802980014123e-05\n",
      "Epoch 4413, Loss: 8.415497063651856e-06, Final Batch Loss: 7.143561333577964e-07\n",
      "Epoch 4414, Loss: 4.997444133891804e-05, Final Batch Loss: 3.4022318118331896e-07\n",
      "Epoch 4415, Loss: 2.0265968942112522e-05, Final Batch Loss: 1.3101253898639698e-05\n",
      "Epoch 4416, Loss: 0.00018089308241542312, Final Batch Loss: 7.1847603066999e-06\n",
      "Epoch 4417, Loss: 4.284765054762829e-05, Final Batch Loss: 1.3854774806532077e-05\n",
      "Epoch 4418, Loss: 1.185074461318436e-05, Final Batch Loss: 1.0823657248693053e-05\n",
      "Epoch 4419, Loss: 0.00014175334581523202, Final Batch Loss: 5.225537097430788e-05\n",
      "Epoch 4420, Loss: 9.861952776191174e-06, Final Batch Loss: 1.5226412415358936e-06\n",
      "Epoch 4421, Loss: 0.0005326732857611205, Final Batch Loss: 4.583583631756483e-06\n",
      "Epoch 4422, Loss: 4.770183477376122e-05, Final Batch Loss: 2.6029918444692157e-05\n",
      "Epoch 4423, Loss: 0.00034726910234894603, Final Batch Loss: 1.10426772153005e-05\n",
      "Epoch 4424, Loss: 5.859996633716946e-05, Final Batch Loss: 1.3869615713701933e-06\n",
      "Epoch 4425, Loss: 5.592790117248114e-06, Final Batch Loss: 5.372969098971225e-06\n",
      "Epoch 4426, Loss: 1.6451703231723513e-05, Final Batch Loss: 1.4910671779944096e-05\n",
      "Epoch 4427, Loss: 4.035323740936292e-05, Final Batch Loss: 3.683254180941731e-05\n",
      "Epoch 4428, Loss: 2.0614809727703687e-05, Final Batch Loss: 1.2500782759161666e-05\n",
      "Epoch 4429, Loss: 6.841254639766703e-05, Final Batch Loss: 6.525935987156117e-07\n",
      "Epoch 4430, Loss: 0.00010564124386291951, Final Batch Loss: 2.1108935470692813e-05\n",
      "Epoch 4431, Loss: 8.333133564519812e-06, Final Batch Loss: 1.3329661214811495e-06\n",
      "Epoch 4432, Loss: 0.0032963784585717804, Final Batch Loss: 1.989927795875701e-06\n",
      "Epoch 4433, Loss: 7.58898650019546e-05, Final Batch Loss: 9.353691893920768e-06\n",
      "Epoch 4434, Loss: 1.3864697621102096e-06, Final Batch Loss: 9.30149099076516e-07\n",
      "Epoch 4435, Loss: 0.00011666617263017542, Final Batch Loss: 1.091995159185899e-06\n",
      "Epoch 4436, Loss: 2.808296471812355e-06, Final Batch Loss: 1.1033156397388666e-06\n",
      "Epoch 4437, Loss: 8.271222179700999e-05, Final Batch Loss: 6.978385727052228e-07\n",
      "Epoch 4438, Loss: 5.502831487547155e-05, Final Batch Loss: 5.412282916950062e-05\n",
      "Epoch 4439, Loss: 1.986716867463656e-06, Final Batch Loss: 1.2094896817416156e-07\n",
      "Epoch 4440, Loss: 3.456602348705928e-05, Final Batch Loss: 8.883878308552084e-07\n",
      "Epoch 4441, Loss: 3.365386510267854e-05, Final Batch Loss: 1.940192305482924e-06\n",
      "Epoch 4442, Loss: 1.4766108961339341e-05, Final Batch Loss: 1.0617583939165343e-05\n",
      "Epoch 4443, Loss: 2.0157241124252323e-05, Final Batch Loss: 1.2467135093174875e-05\n",
      "Epoch 4444, Loss: 1.712654807306535e-06, Final Batch Loss: 6.117049906606553e-07\n",
      "Epoch 4445, Loss: 9.947598357484821e-05, Final Batch Loss: 1.1146263432237902e-06\n",
      "Epoch 4446, Loss: 3.2756229302322026e-06, Final Batch Loss: 2.595209480205085e-06\n",
      "Epoch 4447, Loss: 0.0002756312824203633, Final Batch Loss: 0.0001014856607071124\n",
      "Epoch 4448, Loss: 5.299533620473085e-05, Final Batch Loss: 1.5653098444090574e-06\n",
      "Epoch 4449, Loss: 1.802860037969367e-05, Final Batch Loss: 1.731481279421132e-05\n",
      "Epoch 4450, Loss: 3.1876727007329464e-05, Final Batch Loss: 1.1964148143306375e-06\n",
      "Epoch 4451, Loss: 3.5093827136734035e-05, Final Batch Loss: 2.8885564461234026e-05\n",
      "Epoch 4452, Loss: 1.381726781346515e-05, Final Batch Loss: 7.204586154330173e-07\n",
      "Epoch 4453, Loss: 5.7050569012062624e-05, Final Batch Loss: 7.0253627200145274e-06\n",
      "Epoch 4454, Loss: 7.774867481202818e-05, Final Batch Loss: 2.997068440890871e-05\n",
      "Epoch 4455, Loss: 6.900831976963673e-06, Final Batch Loss: 2.4995497369673103e-06\n",
      "Epoch 4456, Loss: 2.3746410761305015e-05, Final Batch Loss: 2.3151376353780506e-06\n",
      "Epoch 4457, Loss: 5.229549742580275e-06, Final Batch Loss: 3.523563009366626e-06\n",
      "Epoch 4458, Loss: 2.9753486700201393e-05, Final Batch Loss: 1.2268955629224365e-07\n",
      "Epoch 4459, Loss: 8.735004030313576e-06, Final Batch Loss: 1.470408733439399e-06\n",
      "Epoch 4460, Loss: 7.838788076242054e-05, Final Batch Loss: 7.744759932393208e-05\n",
      "Epoch 4461, Loss: 4.011603948583797e-06, Final Batch Loss: 8.239998692260997e-07\n",
      "Epoch 4462, Loss: 6.154731330809682e-06, Final Batch Loss: 1.0963746177594658e-07\n",
      "Epoch 4463, Loss: 2.0852480389521588e-05, Final Batch Loss: 1.949107684140472e-07\n",
      "Epoch 4464, Loss: 2.787475023069419e-05, Final Batch Loss: 7.489956260542385e-06\n",
      "Epoch 4465, Loss: 3.918247159617749e-06, Final Batch Loss: 5.829843416904623e-07\n",
      "Epoch 4466, Loss: 1.4556070595972415e-05, Final Batch Loss: 3.097674152741092e-07\n",
      "Epoch 4467, Loss: 1.5222054514651973e-06, Final Batch Loss: 2.8018334319313e-07\n",
      "Epoch 4468, Loss: 5.9874121973280126e-05, Final Batch Loss: 5.933196371188387e-05\n",
      "Epoch 4469, Loss: 4.890973968940671e-06, Final Batch Loss: 1.4886752524034819e-06\n",
      "Epoch 4470, Loss: 4.49455292255152e-05, Final Batch Loss: 3.506286157062277e-05\n",
      "Epoch 4471, Loss: 6.981984537191011e-07, Final Batch Loss: 2.3493788248174496e-08\n",
      "Epoch 4472, Loss: 2.1070619141028146e-05, Final Batch Loss: 1.745351937643136e-06\n",
      "Epoch 4473, Loss: 0.00010945140456897207, Final Batch Loss: 4.058498234371655e-05\n",
      "Epoch 4474, Loss: 7.3756277743086684e-06, Final Batch Loss: 2.044595021288842e-06\n",
      "Epoch 4475, Loss: 2.9592311875603627e-05, Final Batch Loss: 2.852092802640982e-05\n",
      "Epoch 4476, Loss: 4.369114975588673e-06, Final Batch Loss: 4.1235452954424545e-06\n",
      "Epoch 4477, Loss: 6.549923057264095e-07, Final Batch Loss: 4.289731521112117e-07\n",
      "Epoch 4478, Loss: 9.456084899284178e-05, Final Batch Loss: 8.669745875522494e-05\n",
      "Epoch 4479, Loss: 2.066064936911971e-05, Final Batch Loss: 3.889456081651588e-07\n",
      "Epoch 4480, Loss: 6.714879035030208e-06, Final Batch Loss: 6.478846444224473e-06\n",
      "Epoch 4481, Loss: 2.775823782030784e-05, Final Batch Loss: 2.7790295007434906e-06\n",
      "Epoch 4482, Loss: 1.270169292411083e-06, Final Batch Loss: 2.0013231960547273e-08\n",
      "Epoch 4483, Loss: 4.4584282917981e-05, Final Batch Loss: 1.8881972607687203e-07\n",
      "Epoch 4484, Loss: 7.104944643288036e-06, Final Batch Loss: 6.943774678802583e-06\n",
      "Epoch 4485, Loss: 4.747916946712394e-06, Final Batch Loss: 4.617264494299889e-06\n",
      "Epoch 4486, Loss: 2.6001107471529394e-05, Final Batch Loss: 1.3469380064634606e-06\n",
      "Epoch 4487, Loss: 4.819850232706813e-06, Final Batch Loss: 3.7994643662386807e-06\n",
      "Epoch 4488, Loss: 4.8319557436116156e-05, Final Batch Loss: 6.386719633155735e-07\n",
      "Epoch 4489, Loss: 2.4444771952403244e-05, Final Batch Loss: 1.9297680410090834e-05\n",
      "Epoch 4490, Loss: 3.181535419116699e-06, Final Batch Loss: 2.39621795117273e-06\n",
      "Epoch 4491, Loss: 0.0007210557105281623, Final Batch Loss: 0.0006975971045903862\n",
      "Epoch 4492, Loss: 3.4167784406236024e-06, Final Batch Loss: 6.656472351096454e-07\n",
      "Epoch 4493, Loss: 1.1425841954348925e-05, Final Batch Loss: 8.61437783328256e-08\n",
      "Epoch 4494, Loss: 0.00038362117993528955, Final Batch Loss: 0.0003743913257494569\n",
      "Epoch 4495, Loss: 1.6431730955446255e-05, Final Batch Loss: 2.605809868327924e-06\n",
      "Epoch 4496, Loss: 3.194158398400759e-05, Final Batch Loss: 7.69414964452153e-06\n",
      "Epoch 4497, Loss: 0.00013123972894391045, Final Batch Loss: 7.846782682463527e-05\n",
      "Epoch 4498, Loss: 0.0001301910801885242, Final Batch Loss: 0.00012473277456592768\n",
      "Epoch 4499, Loss: 1.2642536148632644e-05, Final Batch Loss: 2.4073656277323607e-06\n",
      "Epoch 4500, Loss: 1.643671112105949e-05, Final Batch Loss: 1.0731398106145207e-05\n",
      "Epoch 4501, Loss: 1.195026726463766e-06, Final Batch Loss: 3.3151772527162393e-07\n",
      "Epoch 4502, Loss: 0.00021530965591409768, Final Batch Loss: 2.896440719268867e-06\n",
      "Epoch 4503, Loss: 0.0006447594314522576, Final Batch Loss: 0.0006415682728402317\n",
      "Epoch 4504, Loss: 1.4112205803940014e-06, Final Batch Loss: 5.029334602113522e-07\n",
      "Epoch 4505, Loss: 6.988279096731276e-06, Final Batch Loss: 1.3921413710704655e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4506, Loss: 4.717498944728504e-05, Final Batch Loss: 4.689890192821622e-05\n",
      "Epoch 4507, Loss: 1.3617736840387806e-05, Final Batch Loss: 4.378496669232845e-06\n",
      "Epoch 4508, Loss: 1.1241129016070772e-05, Final Batch Loss: 8.997067766358668e-07\n",
      "Epoch 4509, Loss: 1.0880756917686085e-05, Final Batch Loss: 9.765974937181454e-06\n",
      "Epoch 4510, Loss: 7.176676808740012e-05, Final Batch Loss: 3.5196928365621716e-05\n",
      "Epoch 4511, Loss: 2.026099673457793e-05, Final Batch Loss: 1.7394077076460235e-05\n",
      "Epoch 4512, Loss: 2.7175931336387293e-06, Final Batch Loss: 1.1293831221337314e-06\n",
      "Epoch 4513, Loss: 8.366671181647689e-06, Final Batch Loss: 3.1443462376046227e-06\n",
      "Epoch 4514, Loss: 3.86021993108443e-05, Final Batch Loss: 3.8174030123627745e-06\n",
      "Epoch 4515, Loss: 1.8107463120031753e-06, Final Batch Loss: 2.697419176911353e-07\n",
      "Epoch 4516, Loss: 8.418202241955441e-07, Final Batch Loss: 5.142375698596879e-07\n",
      "Epoch 4517, Loss: 3.04585017829595e-06, Final Batch Loss: 6.421439024961728e-07\n",
      "Epoch 4518, Loss: 0.0005269887078611646, Final Batch Loss: 0.00047456592437811196\n",
      "Epoch 4519, Loss: 3.8450544934676145e-06, Final Batch Loss: 2.6926443297270453e-06\n",
      "Epoch 4520, Loss: 3.711083678581417e-06, Final Batch Loss: 2.149237445792096e-07\n",
      "Epoch 4521, Loss: 4.364052358596382e-06, Final Batch Loss: 5.50795050457964e-07\n",
      "Epoch 4522, Loss: 1.5491960141389427e-05, Final Batch Loss: 1.4803460544499103e-05\n",
      "Epoch 4523, Loss: 8.13052179182705e-05, Final Batch Loss: 7.847455708542839e-05\n",
      "Epoch 4524, Loss: 5.328986674157932e-06, Final Batch Loss: 4.2375478415124235e-07\n",
      "Epoch 4525, Loss: 5.338418191058736e-06, Final Batch Loss: 1.5191361626420985e-06\n",
      "Epoch 4526, Loss: 8.102616538963048e-05, Final Batch Loss: 2.762480107776355e-06\n",
      "Epoch 4527, Loss: 3.634351713799333e-06, Final Batch Loss: 4.020004951144074e-07\n",
      "Epoch 4528, Loss: 7.792046154975196e-07, Final Batch Loss: 5.3948699729744476e-08\n",
      "Epoch 4529, Loss: 0.00159181024218924, Final Batch Loss: 0.0015889917267486453\n",
      "Epoch 4530, Loss: 0.0006288907151770218, Final Batch Loss: 8.605547350271081e-07\n",
      "Epoch 4531, Loss: 4.684980467573041e-05, Final Batch Loss: 3.310164174763486e-05\n",
      "Epoch 4532, Loss: 5.3708731684309896e-05, Final Batch Loss: 3.867924169753678e-05\n",
      "Epoch 4533, Loss: 7.54995389229407e-06, Final Batch Loss: 1.3226107853370195e-07\n",
      "Epoch 4534, Loss: 2.4846326027727628e-06, Final Batch Loss: 6.656480877609283e-07\n",
      "Epoch 4535, Loss: 0.0001279451410027832, Final Batch Loss: 5.011845587432617e-07\n",
      "Epoch 4536, Loss: 1.3276657227834221e-05, Final Batch Loss: 1.1082925084338058e-05\n",
      "Epoch 4537, Loss: 7.497680144297192e-06, Final Batch Loss: 5.587662599282339e-06\n",
      "Epoch 4538, Loss: 4.525610890482312e-07, Final Batch Loss: 1.0876700429207631e-07\n",
      "Epoch 4539, Loss: 0.0013306208145422715, Final Batch Loss: 0.0013271239586174488\n",
      "Epoch 4540, Loss: 0.00031133209995459765, Final Batch Loss: 6.93340552970767e-05\n",
      "Epoch 4541, Loss: 7.709865940341842e-06, Final Batch Loss: 3.7750930914626224e-06\n",
      "Epoch 4542, Loss: 2.2408841005017166e-06, Final Batch Loss: 9.849472917267121e-07\n",
      "Epoch 4543, Loss: 1.2485734242062563e-06, Final Batch Loss: 2.6974360523013274e-08\n",
      "Epoch 4544, Loss: 0.00016335903274011798, Final Batch Loss: 0.00014591087528970093\n",
      "Epoch 4545, Loss: 9.306370429840172e-06, Final Batch Loss: 1.2807454368157778e-06\n",
      "Epoch 4546, Loss: 2.4068118705145025e-05, Final Batch Loss: 3.5674963783094427e-07\n",
      "Epoch 4547, Loss: 0.0021937441742920782, Final Batch Loss: 6.75825504004024e-06\n",
      "Epoch 4548, Loss: 8.152923101079068e-07, Final Batch Loss: 5.969027938590443e-07\n",
      "Epoch 4549, Loss: 0.009563357380102389, Final Batch Loss: 2.47813732130453e-05\n",
      "Epoch 4550, Loss: 1.0670859865058446e-05, Final Batch Loss: 3.8764610508223996e-06\n",
      "Epoch 4551, Loss: 7.442993421591382e-06, Final Batch Loss: 6.498459697468206e-06\n",
      "Epoch 4552, Loss: 4.127902866457589e-05, Final Batch Loss: 1.582827462698333e-05\n",
      "Epoch 4553, Loss: 0.0016294470924549387, Final Batch Loss: 9.609263543097768e-06\n",
      "Epoch 4554, Loss: 3.9812064187572105e-06, Final Batch Loss: 8.648719358461676e-07\n",
      "Epoch 4555, Loss: 5.985244706607773e-05, Final Batch Loss: 5.479612445924431e-05\n",
      "Epoch 4556, Loss: 4.093619565992412e-06, Final Batch Loss: 3.83469887310639e-06\n",
      "Epoch 4557, Loss: 2.6454600629222114e-05, Final Batch Loss: 7.099025424395222e-06\n",
      "Epoch 4558, Loss: 7.153349059763059e-06, Final Batch Loss: 6.692733677482465e-06\n",
      "Epoch 4559, Loss: 7.434943228190605e-06, Final Batch Loss: 4.6986136226223607e-07\n",
      "Epoch 4560, Loss: 4.662173887481913e-05, Final Batch Loss: 1.8349741367273964e-05\n",
      "Epoch 4561, Loss: 4.574537706503179e-05, Final Batch Loss: 5.829480869579129e-06\n",
      "Epoch 4562, Loss: 3.801153354743292e-06, Final Batch Loss: 2.908548367486219e-06\n",
      "Epoch 4563, Loss: 4.078955839759146e-06, Final Batch Loss: 9.59709382186702e-07\n",
      "Epoch 4564, Loss: 1.7305802657574532e-06, Final Batch Loss: 7.474296808140934e-07\n",
      "Epoch 4565, Loss: 2.471280436111556e-05, Final Batch Loss: 2.093701550620608e-05\n",
      "Epoch 4566, Loss: 1.0390581223873596e-05, Final Batch Loss: 8.899714885046706e-06\n",
      "Epoch 4567, Loss: 5.711888206860749e-06, Final Batch Loss: 8.353135854122229e-07\n",
      "Epoch 4568, Loss: 3.405408551770961e-05, Final Batch Loss: 2.772404332063161e-05\n",
      "Epoch 4569, Loss: 3.023496628884459e-05, Final Batch Loss: 4.318234459788073e-06\n",
      "Epoch 4570, Loss: 0.00023548259417793815, Final Batch Loss: 2.775727239168191e-07\n",
      "Epoch 4571, Loss: 0.0002452932503729244, Final Batch Loss: 4.76279547001468e-06\n",
      "Epoch 4572, Loss: 1.5455364916761027e-06, Final Batch Loss: 1.1955438594668522e-06\n",
      "Epoch 4573, Loss: 9.526651592750568e-05, Final Batch Loss: 1.5382023775600828e-05\n",
      "Epoch 4574, Loss: 7.202641199910431e-05, Final Batch Loss: 6.988484528847039e-05\n",
      "Epoch 4575, Loss: 8.561847789678723e-05, Final Batch Loss: 4.227946192258969e-05\n",
      "Epoch 4576, Loss: 9.356548815731003e-07, Final Batch Loss: 4.785771068327449e-08\n",
      "Epoch 4577, Loss: 6.926632750037243e-06, Final Batch Loss: 3.895848749380093e-06\n",
      "Epoch 4578, Loss: 8.759963918691938e-07, Final Batch Loss: 1.6793634927125822e-07\n",
      "Epoch 4579, Loss: 0.0007639758023287868, Final Batch Loss: 1.7068368833861314e-05\n",
      "Epoch 4580, Loss: 3.322911015857244e-05, Final Batch Loss: 1.3777281310467515e-05\n",
      "Epoch 4581, Loss: 1.136552191383089e-05, Final Batch Loss: 1.549637545394944e-06\n",
      "Epoch 4582, Loss: 4.82000007195893e-06, Final Batch Loss: 4.1853411403280916e-07\n",
      "Epoch 4583, Loss: 6.313552773917763e-06, Final Batch Loss: 5.879166110389633e-06\n",
      "Epoch 4584, Loss: 2.6048963306379846e-06, Final Batch Loss: 1.0615695344995402e-07\n",
      "Epoch 4585, Loss: 1.1271650954824963e-06, Final Batch Loss: 5.220844201403452e-09\n",
      "Epoch 4586, Loss: 4.9704311777531984e-06, Final Batch Loss: 7.839765885364613e-07\n",
      "Epoch 4587, Loss: 0.00045342837802309077, Final Batch Loss: 0.00043978652684018016\n",
      "Epoch 4588, Loss: 4.5228471776681545e-06, Final Batch Loss: 4.071286184625933e-06\n",
      "Epoch 4589, Loss: 6.541484026456601e-06, Final Batch Loss: 3.5146792924933834e-06\n",
      "Epoch 4590, Loss: 4.527948135546467e-06, Final Batch Loss: 1.7062271808754303e-06\n",
      "Epoch 4591, Loss: 1.1761782616304117e-05, Final Batch Loss: 2.8362026114336913e-06\n",
      "Epoch 4592, Loss: 8.22156721369538e-05, Final Batch Loss: 4.918183094559936e-06\n",
      "Epoch 4593, Loss: 3.9518446328656864e-06, Final Batch Loss: 1.14939928153035e-06\n",
      "Epoch 4594, Loss: 3.898275750202629e-06, Final Batch Loss: 2.0274116252494423e-07\n",
      "Epoch 4595, Loss: 1.1624781677710416e-05, Final Batch Loss: 1.062298451870447e-05\n",
      "Epoch 4596, Loss: 3.177610233251471e-05, Final Batch Loss: 3.064800694119185e-05\n",
      "Epoch 4597, Loss: 8.094404428860003e-05, Final Batch Loss: 4.524726548993385e-08\n",
      "Epoch 4598, Loss: 7.883929242780141e-06, Final Batch Loss: 7.283599188667722e-06\n",
      "Epoch 4599, Loss: 6.424765231827223e-06, Final Batch Loss: 6.268840024858946e-06\n",
      "Epoch 4600, Loss: 0.00012950149073276407, Final Batch Loss: 0.00012770593457389623\n",
      "Epoch 4601, Loss: 1.540161264301787e-06, Final Batch Loss: 6.874105906717887e-08\n",
      "Epoch 4602, Loss: 9.182672783936141e-06, Final Batch Loss: 4.873820216744207e-06\n",
      "Epoch 4603, Loss: 2.0738548869303486e-06, Final Batch Loss: 8.170488285941246e-07\n",
      "Epoch 4604, Loss: 0.00026588156902107585, Final Batch Loss: 1.042358007907751e-06\n",
      "Epoch 4605, Loss: 9.172370809551467e-06, Final Batch Loss: 1.2355972955901962e-07\n",
      "Epoch 4606, Loss: 7.452914701389091e-06, Final Batch Loss: 1.2398867283991422e-06\n",
      "Epoch 4607, Loss: 0.0017822389438748587, Final Batch Loss: 6.961114706882654e-08\n",
      "Epoch 4608, Loss: 4.200880852067712e-06, Final Batch Loss: 2.9584666094706336e-07\n",
      "Epoch 4609, Loss: 1.787571000022581e-05, Final Batch Loss: 8.727879503567237e-06\n",
      "Epoch 4610, Loss: 3.2700872907298617e-06, Final Batch Loss: 5.716776740882779e-07\n",
      "Epoch 4611, Loss: 0.00015131008109392496, Final Batch Loss: 1.1659864185276092e-07\n",
      "Epoch 4612, Loss: 0.00016412741206295323, Final Batch Loss: 0.00014858822396490723\n",
      "Epoch 4613, Loss: 0.0005162652610124496, Final Batch Loss: 0.0005121179856359959\n",
      "Epoch 4614, Loss: 6.8623478455265285e-06, Final Batch Loss: 1.2050998066115426e-06\n",
      "Epoch 4615, Loss: 1.71915118016841e-05, Final Batch Loss: 1.55030757014174e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4616, Loss: 9.067487553693354e-06, Final Batch Loss: 1.8071696104016155e-06\n",
      "Epoch 4617, Loss: 2.931441667897161e-05, Final Batch Loss: 2.5452869522268884e-05\n",
      "Epoch 4618, Loss: 0.00019362299576641817, Final Batch Loss: 1.2111988780816318e-06\n",
      "Epoch 4619, Loss: 0.00013648059393744916, Final Batch Loss: 5.9316123952157795e-05\n",
      "Epoch 4620, Loss: 9.011189081320481e-05, Final Batch Loss: 2.242231630589231e-06\n",
      "Epoch 4621, Loss: 1.9678856233440456e-06, Final Batch Loss: 1.3313126601133263e-07\n",
      "Epoch 4622, Loss: 7.715455649304204e-05, Final Batch Loss: 2.4618984753033146e-05\n",
      "Epoch 4623, Loss: 0.004261390576175472, Final Batch Loss: 0.004251847509294748\n",
      "Epoch 4624, Loss: 3.7557871905846696e-06, Final Batch Loss: 6.282297704274242e-07\n",
      "Epoch 4625, Loss: 4.462761444301577e-05, Final Batch Loss: 4.215421540720854e-06\n",
      "Epoch 4626, Loss: 4.0435642176817055e-05, Final Batch Loss: 3.7959645851515234e-05\n",
      "Epoch 4627, Loss: 9.529590670354082e-06, Final Batch Loss: 6.110617050580913e-06\n",
      "Epoch 4628, Loss: 6.702216796838911e-05, Final Batch Loss: 5.240738391876221e-05\n",
      "Epoch 4629, Loss: 6.952100534363126e-06, Final Batch Loss: 1.2207345889692078e-06\n",
      "Epoch 4630, Loss: 0.0009094233610085212, Final Batch Loss: 0.0008257578010670841\n",
      "Epoch 4631, Loss: 1.8189115507993847e-05, Final Batch Loss: 1.551575041958131e-05\n",
      "Epoch 4632, Loss: 1.5938872479637212e-06, Final Batch Loss: 1.0049989214166999e-06\n",
      "Epoch 4633, Loss: 0.0005417904335445201, Final Batch Loss: 0.0005361770745366812\n",
      "Epoch 4634, Loss: 1.844854557475628e-05, Final Batch Loss: 1.749489274516236e-05\n",
      "Epoch 4635, Loss: 1.2004272207377653e-06, Final Batch Loss: 4.0461162598148803e-07\n",
      "Epoch 4636, Loss: 1.3243803209661564e-06, Final Batch Loss: 2.358070219088404e-07\n",
      "Epoch 4637, Loss: 1.1899264677595056e-05, Final Batch Loss: 1.2807903431166778e-06\n",
      "Epoch 4638, Loss: 0.00032174506554838445, Final Batch Loss: 0.00031794013921171427\n",
      "Epoch 4639, Loss: 1.4332496903080028e-05, Final Batch Loss: 7.205969268397894e-06\n",
      "Epoch 4640, Loss: 1.4982450124989555e-06, Final Batch Loss: 7.892051030466973e-07\n",
      "Epoch 4641, Loss: 7.240652678319748e-06, Final Batch Loss: 5.255599830888968e-07\n",
      "Epoch 4642, Loss: 1.3859205182598089e-05, Final Batch Loss: 2.6007685391959967e-06\n",
      "Epoch 4643, Loss: 2.8437124569791195e-05, Final Batch Loss: 1.8975816828969982e-06\n",
      "Epoch 4644, Loss: 2.0387116592246457e-05, Final Batch Loss: 1.968128117368906e-06\n",
      "Epoch 4645, Loss: 2.7000056661563576e-05, Final Batch Loss: 1.4434883723879466e-06\n",
      "Epoch 4646, Loss: 1.6474935137011926e-05, Final Batch Loss: 2.6815839646587847e-06\n",
      "Epoch 4647, Loss: 2.1889176480272e-05, Final Batch Loss: 3.8894728504601517e-07\n",
      "Epoch 4648, Loss: 0.00016269925617962144, Final Batch Loss: 0.00010728520283009857\n",
      "Epoch 4649, Loss: 8.180526947398903e-06, Final Batch Loss: 7.145851213863352e-06\n",
      "Epoch 4650, Loss: 3.3510045795992482e-06, Final Batch Loss: 1.5348150554927997e-06\n",
      "Epoch 4651, Loss: 2.9373978804869694e-06, Final Batch Loss: 7.900754326328752e-07\n",
      "Epoch 4652, Loss: 0.00027947799799221684, Final Batch Loss: 1.9150579646520782e-06\n",
      "Epoch 4653, Loss: 1.606446937785222e-05, Final Batch Loss: 6.743456424374017e-07\n",
      "Epoch 4654, Loss: 5.223264452069998e-05, Final Batch Loss: 8.519065886503085e-06\n",
      "Epoch 4655, Loss: 0.00015733909458504058, Final Batch Loss: 0.00014112665667198598\n",
      "Epoch 4656, Loss: 4.241973965690704e-05, Final Batch Loss: 3.893998291459866e-05\n",
      "Epoch 4657, Loss: 8.933954177337e-06, Final Batch Loss: 4.620772870111978e-06\n",
      "Epoch 4658, Loss: 5.685119394627236e-05, Final Batch Loss: 1.2529999082744325e-07\n",
      "Epoch 4659, Loss: 1.9989417978649726e-05, Final Batch Loss: 5.403152954386314e-06\n",
      "Epoch 4660, Loss: 5.784646646134206e-06, Final Batch Loss: 1.9099045402981574e-06\n",
      "Epoch 4661, Loss: 0.00013587911689683096, Final Batch Loss: 0.00012965041969437152\n",
      "Epoch 4662, Loss: 3.374857078597415e-05, Final Batch Loss: 1.0893727449001744e-06\n",
      "Epoch 4663, Loss: 6.696992068100371e-05, Final Batch Loss: 5.721047728002304e-06\n",
      "Epoch 4664, Loss: 5.942547659287811e-06, Final Batch Loss: 1.7593563370610354e-06\n",
      "Epoch 4665, Loss: 6.4031176520984445e-06, Final Batch Loss: 5.525301389752713e-07\n",
      "Epoch 4666, Loss: 7.500974348317868e-06, Final Batch Loss: 1.2617012146165507e-07\n",
      "Epoch 4667, Loss: 2.7485081773193087e-05, Final Batch Loss: 8.006335519894492e-06\n",
      "Epoch 4668, Loss: 5.699735083908308e-05, Final Batch Loss: 1.1011781680281274e-05\n",
      "Epoch 4669, Loss: 0.0009062613466994662, Final Batch Loss: 4.77572802992654e-06\n",
      "Epoch 4670, Loss: 3.3991410873568384e-05, Final Batch Loss: 4.210327006148873e-06\n",
      "Epoch 4671, Loss: 1.6483747231177404e-05, Final Batch Loss: 1.4077882042329293e-05\n",
      "Epoch 4672, Loss: 1.1360709095242782e-05, Final Batch Loss: 9.212742043018807e-06\n",
      "Epoch 4673, Loss: 9.02594820217928e-06, Final Batch Loss: 8.528612852387596e-06\n",
      "Epoch 4674, Loss: 4.910501672839018e-06, Final Batch Loss: 4.186684691376286e-06\n",
      "Epoch 4675, Loss: 8.461353900202084e-05, Final Batch Loss: 5.8550685935188085e-05\n",
      "Epoch 4676, Loss: 0.000149091170783322, Final Batch Loss: 0.0001475254539400339\n",
      "Epoch 4677, Loss: 0.00043723127510020277, Final Batch Loss: 1.3630261491925921e-05\n",
      "Epoch 4678, Loss: 9.24027111182113e-06, Final Batch Loss: 2.7931358204114076e-07\n",
      "Epoch 4679, Loss: 5.5394985736256785e-06, Final Batch Loss: 4.315866988235939e-07\n",
      "Epoch 4680, Loss: 2.460726705066918e-06, Final Batch Loss: 1.0441248150527827e-06\n",
      "Epoch 4681, Loss: 4.718757440969057e-05, Final Batch Loss: 1.530478357381071e-06\n",
      "Epoch 4682, Loss: 3.577515485631011e-06, Final Batch Loss: 1.5539723108304315e-06\n",
      "Epoch 4683, Loss: 1.258801376025076e-05, Final Batch Loss: 5.399064775701845e-06\n",
      "Epoch 4684, Loss: 8.408269309256866e-06, Final Batch Loss: 1.3399852605289198e-06\n",
      "Epoch 4685, Loss: 2.055011282209307e-05, Final Batch Loss: 1.734637226036284e-05\n",
      "Epoch 4686, Loss: 3.514317359076813e-05, Final Batch Loss: 1.3006951121496968e-05\n",
      "Epoch 4687, Loss: 5.0490200010244735e-05, Final Batch Loss: 2.5630406526033767e-05\n",
      "Epoch 4688, Loss: 2.5622405928515946e-05, Final Batch Loss: 2.31718149734661e-05\n",
      "Epoch 4689, Loss: 1.0126203733307193e-06, Final Batch Loss: 6.473709959209373e-07\n",
      "Epoch 4690, Loss: 4.083511157659814e-05, Final Batch Loss: 2.112513357133139e-05\n",
      "Epoch 4691, Loss: 2.7899864619485015e-05, Final Batch Loss: 2.7235142852077843e-07\n",
      "Epoch 4692, Loss: 8.384685088458355e-07, Final Batch Loss: 3.6545534953802417e-07\n",
      "Epoch 4693, Loss: 1.1456889410510485e-06, Final Batch Loss: 7.761474876133434e-07\n",
      "Epoch 4694, Loss: 3.4670174500206485e-06, Final Batch Loss: 1.3216535990068223e-06\n",
      "Epoch 4695, Loss: 3.0514506306644762e-05, Final Batch Loss: 6.306891464191722e-06\n",
      "Epoch 4696, Loss: 1.264994273242337e-05, Final Batch Loss: 6.943620292076957e-07\n",
      "Epoch 4697, Loss: 3.4679983400565106e-06, Final Batch Loss: 1.3878100162401097e-06\n",
      "Epoch 4698, Loss: 1.024645507641253e-05, Final Batch Loss: 7.383911906799767e-06\n",
      "Epoch 4699, Loss: 1.833249427818373e-06, Final Batch Loss: 1.1284993206572835e-06\n",
      "Epoch 4700, Loss: 0.00013837708138453308, Final Batch Loss: 0.00011974712106166407\n",
      "Epoch 4701, Loss: 2.7588284865487367e-05, Final Batch Loss: 1.7424057659809478e-05\n",
      "Epoch 4702, Loss: 0.0002047802281595068, Final Batch Loss: 0.00019135148613713682\n",
      "Epoch 4703, Loss: 0.00025980357770549745, Final Batch Loss: 1.7010303281494998e-06\n",
      "Epoch 4704, Loss: 4.140461641100046e-06, Final Batch Loss: 1.6184569062716037e-07\n",
      "Epoch 4705, Loss: 1.0508397508601774e-05, Final Batch Loss: 7.529939466621727e-06\n",
      "Epoch 4706, Loss: 0.00034020493694697507, Final Batch Loss: 3.2879361242521554e-06\n",
      "Epoch 4707, Loss: 2.3646783233743918e-06, Final Batch Loss: 4.84662962207949e-07\n",
      "Epoch 4708, Loss: 0.0029209123458713293, Final Batch Loss: 0.0006488203071057796\n",
      "Epoch 4709, Loss: 3.119163693554583e-06, Final Batch Loss: 9.031532499648165e-07\n",
      "Epoch 4710, Loss: 0.00010665888476069085, Final Batch Loss: 8.622622408438474e-05\n",
      "Epoch 4711, Loss: 1.856037954439671e-06, Final Batch Loss: 2.505990437384753e-07\n",
      "Epoch 4712, Loss: 1.5578452575937263e-05, Final Batch Loss: 1.3638301425089594e-05\n",
      "Epoch 4713, Loss: 2.9395362417972137e-05, Final Batch Loss: 4.254896168731648e-07\n",
      "Epoch 4714, Loss: 4.6257674739536014e-06, Final Batch Loss: 8.796847623671056e-07\n",
      "Epoch 4715, Loss: 9.308462324497668e-06, Final Batch Loss: 8.300999638777284e-07\n",
      "Epoch 4716, Loss: 0.00022168703688407732, Final Batch Loss: 1.9055985944760323e-07\n",
      "Epoch 4717, Loss: 7.558514596439636e-07, Final Batch Loss: 1.8794955281009607e-07\n",
      "Epoch 4718, Loss: 5.3430928460329596e-05, Final Batch Loss: 5.1639697630889714e-05\n",
      "Epoch 4719, Loss: 0.0002520346606615931, Final Batch Loss: 0.00018922948220279068\n",
      "Epoch 4720, Loss: 0.0010884168928555482, Final Batch Loss: 8.788407512838603e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4721, Loss: 6.339572792057879e-06, Final Batch Loss: 8.909919415600598e-07\n",
      "Epoch 4722, Loss: 9.747085130129562e-07, Final Batch Loss: 2.0274129042263667e-07\n",
      "Epoch 4723, Loss: 0.00029352273122640327, Final Batch Loss: 0.00023167351901065558\n",
      "Epoch 4724, Loss: 5.447817500225938e-06, Final Batch Loss: 4.68128007469204e-07\n",
      "Epoch 4725, Loss: 6.61268506974011e-06, Final Batch Loss: 7.21336732567579e-07\n",
      "Epoch 4726, Loss: 2.0729952893816517e-05, Final Batch Loss: 1.8270295186084695e-05\n",
      "Epoch 4727, Loss: 2.876127229001213e-05, Final Batch Loss: 2.3145668137658504e-07\n",
      "Epoch 4728, Loss: 0.0025785751022340264, Final Batch Loss: 7.679624104639515e-06\n",
      "Epoch 4729, Loss: 0.0018202631499661948, Final Batch Loss: 0.00181566271930933\n",
      "Epoch 4730, Loss: 1.3311390432590997e-05, Final Batch Loss: 1.2918484571855515e-05\n",
      "Epoch 4731, Loss: 7.156123865570407e-05, Final Batch Loss: 5.434520426206291e-05\n",
      "Epoch 4732, Loss: 1.2129178230679827e-05, Final Batch Loss: 6.1911705415695906e-06\n",
      "Epoch 4733, Loss: 0.00016979114116111305, Final Batch Loss: 8.850814992911182e-06\n",
      "Epoch 4734, Loss: 9.09454083739547e-05, Final Batch Loss: 7.218496466521174e-05\n",
      "Epoch 4735, Loss: 2.21367454855681e-06, Final Batch Loss: 2.845332858214533e-07\n",
      "Epoch 4736, Loss: 6.763706301171624e-05, Final Batch Loss: 6.657620542682707e-05\n",
      "Epoch 4737, Loss: 1.4475648413281306e-05, Final Batch Loss: 6.30839849691256e-07\n",
      "Epoch 4738, Loss: 0.00015460392023669556, Final Batch Loss: 8.851164602674544e-05\n",
      "Epoch 4739, Loss: 1.2858026821049862e-05, Final Batch Loss: 8.785065801930614e-06\n",
      "Epoch 4740, Loss: 6.111752952620009e-06, Final Batch Loss: 2.358059987273009e-07\n",
      "Epoch 4741, Loss: 4.6254497192421695e-06, Final Batch Loss: 2.2743411136616487e-06\n",
      "Epoch 4742, Loss: 0.00016343605648216908, Final Batch Loss: 6.146180112409638e-06\n",
      "Epoch 4743, Loss: 1.2972866898053326e-05, Final Batch Loss: 8.239244380092714e-06\n",
      "Epoch 4744, Loss: 0.0004232896617395454, Final Batch Loss: 0.00041918325587175786\n",
      "Epoch 4745, Loss: 8.662076379550854e-05, Final Batch Loss: 4.70151371700922e-06\n",
      "Epoch 4746, Loss: 0.0006309182592758589, Final Batch Loss: 2.116789119099849e-06\n",
      "Epoch 4747, Loss: 2.2935925912292987e-05, Final Batch Loss: 1.479231599432751e-07\n",
      "Epoch 4748, Loss: 5.977279840863048e-06, Final Batch Loss: 7.378450277428783e-07\n",
      "Epoch 4749, Loss: 1.05913387073997e-05, Final Batch Loss: 6.995879289206641e-07\n",
      "Epoch 4750, Loss: 2.16365128835605e-06, Final Batch Loss: 1.3425658380583627e-06\n",
      "Epoch 4751, Loss: 3.692441600833263e-05, Final Batch Loss: 2.4394946649408666e-06\n",
      "Epoch 4752, Loss: 3.95664140739882e-05, Final Batch Loss: 3.9378541259793565e-05\n",
      "Epoch 4753, Loss: 2.2933478760478465e-06, Final Batch Loss: 1.8436990103509743e-06\n",
      "Epoch 4754, Loss: 1.751595118548721e-05, Final Batch Loss: 1.2441208127711434e-05\n",
      "Epoch 4755, Loss: 5.840050074645831e-07, Final Batch Loss: 6.090985049667097e-09\n",
      "Epoch 4756, Loss: 6.9744987740705255e-06, Final Batch Loss: 3.884350007865578e-06\n",
      "Epoch 4757, Loss: 2.202756155611496e-05, Final Batch Loss: 2.125795799656771e-05\n",
      "Epoch 4758, Loss: 3.899599391843367e-06, Final Batch Loss: 2.806794327625539e-06\n",
      "Epoch 4759, Loss: 5.337505740499182e-06, Final Batch Loss: 3.697293323057238e-06\n",
      "Epoch 4760, Loss: 2.90021064870416e-05, Final Batch Loss: 9.266653364647937e-07\n",
      "Epoch 4761, Loss: 2.600762385895905e-06, Final Batch Loss: 1.705459311551749e-07\n",
      "Epoch 4762, Loss: 0.0001559308911964763, Final Batch Loss: 0.00014639033179264516\n",
      "Epoch 4763, Loss: 2.1169851834201836e-05, Final Batch Loss: 2.7615226372290635e-06\n",
      "Epoch 4764, Loss: 4.2879347574853455e-05, Final Batch Loss: 4.1438448533881456e-05\n",
      "Epoch 4765, Loss: 1.0352265235269442e-05, Final Batch Loss: 7.397157787636388e-06\n",
      "Epoch 4766, Loss: 3.0676739015689236e-06, Final Batch Loss: 1.941947175509995e-06\n",
      "Epoch 4767, Loss: 8.661768561069039e-06, Final Batch Loss: 5.63398589292774e-06\n",
      "Epoch 4768, Loss: 1.843152585934149e-05, Final Batch Loss: 7.111151717253961e-06\n",
      "Epoch 4769, Loss: 5.75175619133006e-06, Final Batch Loss: 4.341953285802447e-07\n",
      "Epoch 4770, Loss: 8.272071170267736e-07, Final Batch Loss: 3.9329455603365204e-07\n",
      "Epoch 4771, Loss: 5.4574328999024146e-05, Final Batch Loss: 5.387482815422118e-05\n",
      "Epoch 4772, Loss: 3.681177895487053e-05, Final Batch Loss: 8.231766514654737e-06\n",
      "Epoch 4773, Loss: 7.491609039789182e-06, Final Batch Loss: 8.918557341530686e-07\n",
      "Epoch 4774, Loss: 0.00013980547373648733, Final Batch Loss: 2.9570801416411996e-06\n",
      "Epoch 4775, Loss: 8.30784836125531e-06, Final Batch Loss: 6.523217507492518e-06\n",
      "Epoch 4776, Loss: 5.172411317744263e-05, Final Batch Loss: 5.097264511277899e-05\n",
      "Epoch 4777, Loss: 3.184906177011726e-06, Final Batch Loss: 1.6452593172289198e-06\n",
      "Epoch 4778, Loss: 6.414778226826456e-06, Final Batch Loss: 2.843103175109718e-06\n",
      "Epoch 4779, Loss: 6.926617857061501e-06, Final Batch Loss: 4.768324970427784e-07\n",
      "Epoch 4780, Loss: 4.319341684322353e-06, Final Batch Loss: 3.7850705325581657e-07\n",
      "Epoch 4781, Loss: 4.120944777241675e-05, Final Batch Loss: 3.680525696836412e-05\n",
      "Epoch 4782, Loss: 1.6153543583641294e-05, Final Batch Loss: 1.3435846994980238e-05\n",
      "Epoch 4783, Loss: 0.00010130781618045148, Final Batch Loss: 1.2303297580729122e-06\n",
      "Epoch 4784, Loss: 7.606515026736815e-07, Final Batch Loss: 1.975212029492468e-07\n",
      "Epoch 4785, Loss: 0.00010609810044570622, Final Batch Loss: 0.00010512639710213989\n",
      "Epoch 4786, Loss: 2.532556499090788e-05, Final Batch Loss: 8.370599857698835e-07\n",
      "Epoch 4787, Loss: 1.927847779370495e-05, Final Batch Loss: 2.0081611182831693e-06\n",
      "Epoch 4788, Loss: 1.3614149906970852e-05, Final Batch Loss: 1.2773099342666683e-06\n",
      "Epoch 4789, Loss: 0.00017841164856235991, Final Batch Loss: 7.100044285834883e-07\n",
      "Epoch 4790, Loss: 0.0001326257042819634, Final Batch Loss: 2.048167516477406e-06\n",
      "Epoch 4791, Loss: 1.3383428409952103e-05, Final Batch Loss: 2.758335142516444e-07\n",
      "Epoch 4792, Loss: 0.00015777530688865227, Final Batch Loss: 0.00015356655057985336\n",
      "Epoch 4793, Loss: 0.0042604533914527565, Final Batch Loss: 1.2903433344035875e-06\n",
      "Epoch 4794, Loss: 2.671819947863696e-05, Final Batch Loss: 1.765771594364196e-05\n",
      "Epoch 4795, Loss: 1.0246182000628323e-05, Final Batch Loss: 1.1206868748558918e-06\n",
      "Epoch 4796, Loss: 8.38381848140557e-05, Final Batch Loss: 8.005286389334287e-08\n",
      "Epoch 4797, Loss: 1.980028878278972e-05, Final Batch Loss: 2.6928189527097857e-06\n",
      "Epoch 4798, Loss: 3.808653627856984e-05, Final Batch Loss: 3.5715089325094596e-05\n",
      "Epoch 4799, Loss: 1.4482554888672894e-06, Final Batch Loss: 6.638936724812083e-07\n",
      "Epoch 4800, Loss: 1.253537084267009e-05, Final Batch Loss: 5.924003744439688e-06\n",
      "Epoch 4801, Loss: 0.0002363112186003491, Final Batch Loss: 0.00023509678430855274\n",
      "Epoch 4802, Loss: 2.827223624990438e-06, Final Batch Loss: 7.352448392339284e-07\n",
      "Epoch 4803, Loss: 1.3370383840083377e-06, Final Batch Loss: 5.412164227891481e-07\n",
      "Epoch 4804, Loss: 0.00012369519686217245, Final Batch Loss: 0.000121910466987174\n",
      "Epoch 4805, Loss: 1.4022411676251068e-05, Final Batch Loss: 1.3539391147787683e-05\n",
      "Epoch 4806, Loss: 4.405146910357871e-06, Final Batch Loss: 2.060373162748874e-06\n",
      "Epoch 4807, Loss: 6.3496671032226e-07, Final Batch Loss: 1.5575440670545504e-07\n",
      "Epoch 4808, Loss: 7.759804532270209e-07, Final Batch Loss: 2.862742292109033e-07\n",
      "Epoch 4809, Loss: 0.00017923993118529324, Final Batch Loss: 0.0001785361673682928\n",
      "Epoch 4810, Loss: 9.250919674741453e-06, Final Batch Loss: 2.6354789497418096e-06\n",
      "Epoch 4811, Loss: 1.5551273619962558e-06, Final Batch Loss: 4.1766718084090826e-08\n",
      "Epoch 4812, Loss: 7.266086527124571e-06, Final Batch Loss: 1.0562963552729343e-06\n",
      "Epoch 4813, Loss: 7.667889803997241e-06, Final Batch Loss: 7.166273917391663e-06\n",
      "Epoch 4814, Loss: 9.423430810784339e-06, Final Batch Loss: 5.788841463072458e-06\n",
      "Epoch 4815, Loss: 5.581157938649994e-05, Final Batch Loss: 4.752579570777016e-06\n",
      "Epoch 4816, Loss: 0.00010993952400895068, Final Batch Loss: 1.2997218618693296e-05\n",
      "Epoch 4817, Loss: 1.8591068510431796e-05, Final Batch Loss: 1.5443325537489727e-05\n",
      "Epoch 4818, Loss: 0.00030977194910519756, Final Batch Loss: 5.44052199984435e-05\n",
      "Epoch 4819, Loss: 6.350669536914211e-07, Final Batch Loss: 3.384780313808733e-07\n",
      "Epoch 4820, Loss: 8.188124775188044e-05, Final Batch Loss: 1.0847521480172873e-05\n",
      "Epoch 4821, Loss: 2.1241098238533596e-05, Final Batch Loss: 1.9181303287041374e-05\n",
      "Epoch 4822, Loss: 0.0005589772772509605, Final Batch Loss: 9.877420961856842e-05\n",
      "Epoch 4823, Loss: 1.3423429209069582e-05, Final Batch Loss: 1.2078833606210537e-05\n",
      "Epoch 4824, Loss: 1.291764704092202e-05, Final Batch Loss: 1.2268475302334991e-06\n",
      "Epoch 4825, Loss: 0.0002524637420719955, Final Batch Loss: 2.7876558306161314e-06\n",
      "Epoch 4826, Loss: 6.330262306164514e-05, Final Batch Loss: 8.152875352607225e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4827, Loss: 6.870287506899331e-06, Final Batch Loss: 2.1143464437045623e-06\n",
      "Epoch 4828, Loss: 1.0695370747271227e-05, Final Batch Loss: 3.2510151868336834e-06\n",
      "Epoch 4829, Loss: 7.194841828095377e-06, Final Batch Loss: 6.172091161715798e-06\n",
      "Epoch 4830, Loss: 6.890622898936272e-06, Final Batch Loss: 2.283940830238862e-06\n",
      "Epoch 4831, Loss: 5.294259025845349e-06, Final Batch Loss: 1.8011802183082182e-07\n",
      "Epoch 4832, Loss: 1.5519905858241145e-06, Final Batch Loss: 1.0441653586212851e-07\n",
      "Epoch 4833, Loss: 8.398657655561692e-06, Final Batch Loss: 6.013851816533133e-06\n",
      "Epoch 4834, Loss: 3.4697711726039415e-06, Final Batch Loss: 2.614395725686336e-06\n",
      "Epoch 4835, Loss: 4.143973319514771e-05, Final Batch Loss: 4.729543888970511e-06\n",
      "Epoch 4836, Loss: 5.9567106518443325e-06, Final Batch Loss: 4.086806256964337e-06\n",
      "Epoch 4837, Loss: 1.2833447954108124e-05, Final Batch Loss: 1.0831021427293308e-05\n",
      "Epoch 4838, Loss: 5.127906632651502e-07, Final Batch Loss: 1.2704033736099518e-07\n",
      "Epoch 4839, Loss: 4.74107537229429e-05, Final Batch Loss: 1.3551451957027894e-05\n",
      "Epoch 4840, Loss: 7.4854227079868e-05, Final Batch Loss: 7.397591980407014e-05\n",
      "Epoch 4841, Loss: 0.010856474109914416, Final Batch Loss: 0.010850753635168076\n",
      "Epoch 4842, Loss: 0.0004270789522706764, Final Batch Loss: 0.0003992107231169939\n",
      "Epoch 4843, Loss: 7.32157766947239e-06, Final Batch Loss: 7.058843493723543e-06\n",
      "Epoch 4844, Loss: 7.430613010228626e-06, Final Batch Loss: 6.961412964301417e-06\n",
      "Epoch 4845, Loss: 1.0457517419126816e-05, Final Batch Loss: 5.086866167403059e-06\n",
      "Epoch 4846, Loss: 6.337636841635685e-05, Final Batch Loss: 1.0737259799498133e-05\n",
      "Epoch 4847, Loss: 9.496681275322771e-05, Final Batch Loss: 9.919574495143024e-08\n",
      "Epoch 4848, Loss: 9.553065289935603e-06, Final Batch Loss: 3.74160364913223e-08\n",
      "Epoch 4849, Loss: 2.1372095488914056e-06, Final Batch Loss: 8.466095096082427e-07\n",
      "Epoch 4850, Loss: 4.4756288843927905e-05, Final Batch Loss: 7.786249625496566e-06\n",
      "Epoch 4851, Loss: 3.871231882612847e-06, Final Batch Loss: 2.819242297391611e-07\n",
      "Epoch 4852, Loss: 1.8861474245568388e-05, Final Batch Loss: 3.5355662930669496e-06\n",
      "Epoch 4853, Loss: 7.798592150720651e-06, Final Batch Loss: 4.858325610257452e-06\n",
      "Epoch 4854, Loss: 2.5869363753372454e-06, Final Batch Loss: 3.0889771096553886e-07\n",
      "Epoch 4855, Loss: 6.245732947718352e-06, Final Batch Loss: 2.6005657218775013e-06\n",
      "Epoch 4856, Loss: 2.562550889706472e-06, Final Batch Loss: 1.0911227263932233e-06\n",
      "Epoch 4857, Loss: 3.916799426129103e-05, Final Batch Loss: 1.5662523722426158e-08\n",
      "Epoch 4858, Loss: 4.310252165851125e-06, Final Batch Loss: 3.014741878359928e-06\n",
      "Epoch 4859, Loss: 4.6583978246417246e-05, Final Batch Loss: 4.516169065027498e-05\n",
      "Epoch 4860, Loss: 4.0591780319232384e-06, Final Batch Loss: 9.571517267659146e-08\n",
      "Epoch 4861, Loss: 1.3017235502843505e-06, Final Batch Loss: 5.916950129858378e-08\n",
      "Epoch 4862, Loss: 4.9567610176382004e-06, Final Batch Loss: 1.6948446273090667e-06\n",
      "Epoch 4863, Loss: 5.090747197300516e-05, Final Batch Loss: 5.464402192956186e-07\n",
      "Epoch 4864, Loss: 3.414709090066026e-05, Final Batch Loss: 4.34262574344757e-06\n",
      "Epoch 4865, Loss: 2.1283691751250444e-05, Final Batch Loss: 2.073868381557986e-05\n",
      "Epoch 4866, Loss: 5.35381252575462e-06, Final Batch Loss: 1.0754730510598165e-06\n",
      "Epoch 4867, Loss: 4.50823487199159e-05, Final Batch Loss: 4.420214827405289e-05\n",
      "Epoch 4868, Loss: 9.192604238705826e-06, Final Batch Loss: 1.7740192106430186e-06\n",
      "Epoch 4869, Loss: 9.330532930107438e-05, Final Batch Loss: 4.315689238865161e-06\n",
      "Epoch 4870, Loss: 1.3529735383599473e-05, Final Batch Loss: 1.180612434836803e-05\n",
      "Epoch 4871, Loss: 1.1063361398555571e-05, Final Batch Loss: 6.478032446466386e-06\n",
      "Epoch 4872, Loss: 0.00013484120449902548, Final Batch Loss: 6.995690000621835e-07\n",
      "Epoch 4873, Loss: 1.8740189879906666e-06, Final Batch Loss: 4.5247286806215925e-08\n",
      "Epoch 4874, Loss: 0.0007050143676678999, Final Batch Loss: 0.0006988078239373863\n",
      "Epoch 4875, Loss: 5.0503407464930206e-05, Final Batch Loss: 9.571499504090752e-08\n",
      "Epoch 4876, Loss: 3.934052961085399e-05, Final Batch Loss: 2.889309826059616e-06\n",
      "Epoch 4877, Loss: 3.7066095615045924e-07, Final Batch Loss: 1.8707950744101254e-07\n",
      "Epoch 4878, Loss: 2.9012606432843313e-06, Final Batch Loss: 3.1585869919581455e-07\n",
      "Epoch 4879, Loss: 9.868347547126177e-06, Final Batch Loss: 1.3816860473525594e-06\n",
      "Epoch 4880, Loss: 2.0268880234652897e-05, Final Batch Loss: 4.149932919972343e-06\n",
      "Epoch 4881, Loss: 5.238377113414572e-06, Final Batch Loss: 1.85338691949255e-07\n",
      "Epoch 4882, Loss: 5.3325664737258194e-05, Final Batch Loss: 4.820544177164265e-07\n",
      "Epoch 4883, Loss: 0.003523334612509643, Final Batch Loss: 0.0035159268882125616\n",
      "Epoch 4884, Loss: 8.71450720296707e-06, Final Batch Loss: 6.660881808784325e-06\n",
      "Epoch 4885, Loss: 3.00386500384775e-06, Final Batch Loss: 1.1720312613761052e-06\n",
      "Epoch 4886, Loss: 4.8784525120026956e-05, Final Batch Loss: 4.7080888180062175e-05\n",
      "Epoch 4887, Loss: 1.910330695409357e-06, Final Batch Loss: 1.3877460105504724e-06\n",
      "Epoch 4888, Loss: 5.035423328081379e-06, Final Batch Loss: 1.9872609300364275e-06\n",
      "Epoch 4889, Loss: 3.378302494638774e-06, Final Batch Loss: 3.689341383505962e-07\n",
      "Epoch 4890, Loss: 2.5004880626511294e-05, Final Batch Loss: 4.712544068752322e-06\n",
      "Epoch 4891, Loss: 5.760429942824885e-05, Final Batch Loss: 5.723236972698942e-05\n",
      "Epoch 4892, Loss: 5.345431368652953e-06, Final Batch Loss: 3.393547132191088e-08\n",
      "Epoch 4893, Loss: 1.6342907656508032e-05, Final Batch Loss: 9.8236068879487e-07\n",
      "Epoch 4894, Loss: 3.1529320096979063e-06, Final Batch Loss: 3.0260941912274575e-06\n",
      "Epoch 4895, Loss: 1.3802184923861205e-06, Final Batch Loss: 1.2581484725160408e-06\n",
      "Epoch 4896, Loss: 3.2243899568129564e-05, Final Batch Loss: 6.188466159073869e-06\n",
      "Epoch 4897, Loss: 1.0836753858711745e-06, Final Batch Loss: 3.045479388674721e-07\n",
      "Epoch 4898, Loss: 3.526710429468949e-05, Final Batch Loss: 1.247738737220061e-06\n",
      "Epoch 4899, Loss: 0.00013330332058103522, Final Batch Loss: 0.00013225241855252534\n",
      "Epoch 4900, Loss: 8.088162917374575e-05, Final Batch Loss: 3.025739488293766e-06\n",
      "Epoch 4901, Loss: 2.1886253549041612e-05, Final Batch Loss: 2.1666370741968421e-07\n",
      "Epoch 4902, Loss: 3.9103990928879284e-05, Final Batch Loss: 8.701383080733649e-08\n",
      "Epoch 4903, Loss: 1.790827639069903e-06, Final Batch Loss: 7.56137353619124e-07\n",
      "Epoch 4904, Loss: 3.6223924780642847e-05, Final Batch Loss: 3.1941221095621586e-05\n",
      "Epoch 4905, Loss: 1.5547408906968485e-06, Final Batch Loss: 1.4469760571955703e-06\n",
      "Epoch 4906, Loss: 0.0001408611424267292, Final Batch Loss: 0.00013960192154627293\n",
      "Epoch 4907, Loss: 8.663433925448771e-05, Final Batch Loss: 8.509333565598354e-05\n",
      "Epoch 4908, Loss: 4.844677505388972e-06, Final Batch Loss: 1.9523986338754185e-06\n",
      "Epoch 4909, Loss: 3.2064755259852973e-06, Final Batch Loss: 2.823105205607135e-06\n",
      "Epoch 4910, Loss: 1.3191243510846107e-06, Final Batch Loss: 3.845933065349527e-07\n",
      "Epoch 4911, Loss: 2.6224004230357423e-05, Final Batch Loss: 7.831256709778245e-08\n",
      "Epoch 4912, Loss: 3.011440270483945e-06, Final Batch Loss: 2.575603446075547e-07\n",
      "Epoch 4913, Loss: 1.0389352496531501e-05, Final Batch Loss: 1.0815582527357037e-06\n",
      "Epoch 4914, Loss: 2.747244650436187e-06, Final Batch Loss: 9.527781799079094e-07\n",
      "Epoch 4915, Loss: 3.883057399889367e-05, Final Batch Loss: 1.2607703183675767e-06\n",
      "Epoch 4916, Loss: 4.242336909499045e-05, Final Batch Loss: 4.228985562804155e-05\n",
      "Epoch 4917, Loss: 3.853314979096467e-06, Final Batch Loss: 9.605836339687812e-07\n",
      "Epoch 4918, Loss: 7.686763638048433e-05, Final Batch Loss: 3.3579450246179476e-05\n",
      "Epoch 4919, Loss: 0.0001845508213023095, Final Batch Loss: 6.439034905270091e-08\n",
      "Epoch 4920, Loss: 9.996023209168925e-06, Final Batch Loss: 1.2947100458404748e-06\n",
      "Epoch 4921, Loss: 1.923706804518588e-06, Final Batch Loss: 1.0458832093718229e-06\n",
      "Epoch 4922, Loss: 7.292297402727854e-05, Final Batch Loss: 1.7636356233197148e-06\n",
      "Epoch 4923, Loss: 0.0006201458061809717, Final Batch Loss: 0.0006197357433848083\n",
      "Epoch 4924, Loss: 0.00013754772371044055, Final Batch Loss: 1.5053373658702185e-07\n",
      "Epoch 4925, Loss: 3.8689735504249256e-07, Final Batch Loss: 1.8185828309924545e-07\n",
      "Epoch 4926, Loss: 4.637836735810197e-05, Final Batch Loss: 4.618620369001292e-05\n",
      "Epoch 4927, Loss: 0.0004563113925257767, Final Batch Loss: 1.6097507682388823e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4928, Loss: 8.640302922913179e-06, Final Batch Loss: 2.4972953838187095e-07\n",
      "Epoch 4929, Loss: 6.691424687232939e-06, Final Batch Loss: 4.902570253761951e-06\n",
      "Epoch 4930, Loss: 4.6835671625444775e-06, Final Batch Loss: 6.177975109267209e-08\n",
      "Epoch 4931, Loss: 0.0034136007742517904, Final Batch Loss: 0.00341215031221509\n",
      "Epoch 4932, Loss: 0.00024402654116784106, Final Batch Loss: 0.00024293512979056686\n",
      "Epoch 4933, Loss: 0.0003179542660518564, Final Batch Loss: 0.0003168080002069473\n",
      "Epoch 4934, Loss: 5.466195523240458e-05, Final Batch Loss: 5.41469817108009e-05\n",
      "Epoch 4935, Loss: 7.307430746550381e-05, Final Batch Loss: 7.2357666795142e-05\n",
      "Epoch 4936, Loss: 5.230060082794807e-06, Final Batch Loss: 1.5792464864716749e-06\n",
      "Epoch 4937, Loss: 6.769624576463684e-06, Final Batch Loss: 7.970351703079359e-07\n",
      "Epoch 4938, Loss: 2.673593326107948e-05, Final Batch Loss: 2.209820013376884e-05\n",
      "Epoch 4939, Loss: 0.00011257342112003244, Final Batch Loss: 0.00011143047595396638\n",
      "Epoch 4940, Loss: 5.117137931165416e-07, Final Batch Loss: 2.2275297340001998e-07\n",
      "Epoch 4941, Loss: 4.2797515334314085e-05, Final Batch Loss: 3.5199097965232795e-06\n",
      "Epoch 4942, Loss: 7.39761508157244e-05, Final Batch Loss: 7.17073999112472e-05\n",
      "Epoch 4943, Loss: 1.5548929468423012e-06, Final Batch Loss: 6.856475351924018e-07\n",
      "Epoch 4944, Loss: 2.7504290642355045e-05, Final Batch Loss: 1.0919842452494777e-06\n",
      "Epoch 4945, Loss: 8.679302482050844e-05, Final Batch Loss: 5.314364534569904e-05\n",
      "Epoch 4946, Loss: 2.8839425283422315e-06, Final Batch Loss: 4.1852908339024e-07\n",
      "Epoch 4947, Loss: 0.005170442323696456, Final Batch Loss: 4.350703797229016e-09\n",
      "Epoch 4948, Loss: 2.5189374852629953e-07, Final Batch Loss: 5.8299274741102636e-08\n",
      "Epoch 4949, Loss: 3.937062729164609e-06, Final Batch Loss: 1.2790605978807434e-06\n",
      "Epoch 4950, Loss: 0.00020001298253191635, Final Batch Loss: 0.00012926332419738173\n",
      "Epoch 4951, Loss: 5.581149277844588e-06, Final Batch Loss: 9.571547110454048e-09\n",
      "Epoch 4952, Loss: 9.507853945933675e-06, Final Batch Loss: 9.207447874359787e-06\n",
      "Epoch 4953, Loss: 4.303513492232014e-07, Final Batch Loss: 1.5140363984755822e-07\n",
      "Epoch 4954, Loss: 9.385930206917692e-05, Final Batch Loss: 2.656840115378145e-05\n",
      "Epoch 4955, Loss: 0.00011731177009721705, Final Batch Loss: 8.701405818101193e-09\n",
      "Epoch 4956, Loss: 1.8015544469562883e-06, Final Batch Loss: 6.534596082019561e-07\n",
      "Epoch 4957, Loss: 5.103735389866415e-07, Final Batch Loss: 1.522742962833945e-07\n",
      "Epoch 4958, Loss: 4.448577873716886e-05, Final Batch Loss: 1.183388960157572e-07\n",
      "Epoch 4959, Loss: 0.00010019643286796054, Final Batch Loss: 9.064857295015827e-05\n",
      "Epoch 4960, Loss: 3.61616753252747e-06, Final Batch Loss: 1.315597046414041e-06\n",
      "Epoch 4961, Loss: 4.205741572604893e-05, Final Batch Loss: 1.7836879351307289e-06\n",
      "Epoch 4962, Loss: 3.552599366685172e-05, Final Batch Loss: 8.440139254162204e-07\n",
      "Epoch 4963, Loss: 6.758687902674865e-07, Final Batch Loss: 4.846579031436704e-07\n",
      "Epoch 4964, Loss: 7.4049240801343785e-06, Final Batch Loss: 3.654588809354209e-08\n",
      "Epoch 4965, Loss: 3.233870984331588e-05, Final Batch Loss: 7.36119318389683e-06\n",
      "Epoch 4966, Loss: 3.232507992834144e-06, Final Batch Loss: 2.471044808771694e-06\n",
      "Epoch 4967, Loss: 0.0003098108063568361, Final Batch Loss: 5.433979822555557e-05\n",
      "Epoch 4968, Loss: 6.0655627180494776e-05, Final Batch Loss: 1.8733184106167755e-06\n",
      "Epoch 4969, Loss: 1.586354301252868e-06, Final Batch Loss: 8.144160688061675e-07\n",
      "Epoch 4970, Loss: 0.0001549257940496318, Final Batch Loss: 3.25734363286756e-05\n",
      "Epoch 4971, Loss: 5.596739369195802e-05, Final Batch Loss: 1.487934611077435e-07\n",
      "Epoch 4972, Loss: 1.7204308846885397e-05, Final Batch Loss: 1.5420746422023512e-05\n",
      "Epoch 4973, Loss: 2.412271786056408e-05, Final Batch Loss: 2.3904804038465954e-05\n",
      "Epoch 4974, Loss: 0.00039286742253352713, Final Batch Loss: 0.00039256940362975\n",
      "Epoch 4975, Loss: 2.2436295807892748e-06, Final Batch Loss: 1.3138291024006321e-06\n",
      "Epoch 4976, Loss: 2.5661375389063323e-06, Final Batch Loss: 4.663903041546291e-07\n",
      "Epoch 4977, Loss: 4.5968705762788886e-05, Final Batch Loss: 6.019794909661869e-06\n",
      "Epoch 4978, Loss: 1.1636053841357352e-05, Final Batch Loss: 8.873242222762201e-06\n",
      "Epoch 4979, Loss: 3.340633338666521e-05, Final Batch Loss: 1.942711060110014e-05\n",
      "Epoch 4980, Loss: 4.7050473561682793e-07, Final Batch Loss: 2.6104194361664668e-08\n",
      "Epoch 4981, Loss: 1.2935059316987463e-06, Final Batch Loss: 5.873305326531408e-07\n",
      "Epoch 4982, Loss: 1.590868692247227e-05, Final Batch Loss: 3.1325047444852316e-08\n",
      "Epoch 4983, Loss: 3.3272149948970764e-05, Final Batch Loss: 3.2588388421572745e-05\n",
      "Epoch 4984, Loss: 0.0005894800924579613, Final Batch Loss: 0.0005249528912827373\n",
      "Epoch 4985, Loss: 1.8686760938635416e-06, Final Batch Loss: 2.810522516938363e-07\n",
      "Epoch 4986, Loss: 2.720041599690859e-05, Final Batch Loss: 1.3922243802255707e-08\n",
      "Epoch 4987, Loss: 7.674766442278269e-05, Final Batch Loss: 1.070270059244649e-07\n",
      "Epoch 4988, Loss: 3.844683035936214e-06, Final Batch Loss: 3.6868511870125076e-06\n",
      "Epoch 4989, Loss: 2.0730132490598407e-06, Final Batch Loss: 1.627160344241929e-07\n",
      "Epoch 4990, Loss: 1.1869255445162707e-06, Final Batch Loss: 6.247518058444257e-07\n",
      "Epoch 4991, Loss: 3.3751635953649384e-05, Final Batch Loss: 3.286095306975767e-05\n",
      "Epoch 4992, Loss: 1.3273598142404808e-05, Final Batch Loss: 7.1279509938904084e-06\n",
      "Epoch 4993, Loss: 0.0001616975473552884, Final Batch Loss: 0.00015574312419630587\n",
      "Epoch 4994, Loss: 0.00016353110913769342, Final Batch Loss: 0.00015428582264576107\n",
      "Epoch 4995, Loss: 4.570265792835926e-05, Final Batch Loss: 4.486059333430603e-05\n",
      "Epoch 4996, Loss: 1.633742785500658e-06, Final Batch Loss: 2.610422100701726e-09\n",
      "Epoch 4997, Loss: 5.420441624437444e-07, Final Batch Loss: 3.1411826739713433e-07\n",
      "Epoch 4998, Loss: 2.255052822874859e-05, Final Batch Loss: 3.8459438655991107e-07\n",
      "Epoch 4999, Loss: 6.479654280155955e-05, Final Batch Loss: 6.243550160434097e-05\n",
      "Epoch 5000, Loss: 0.00020100936490052845, Final Batch Loss: 0.00019514342420734465\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0  0]\n",
      " [ 0 24  0]\n",
      " [ 0  0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        33\n",
      "           1    1.00000   1.00000   1.00000        24\n",
      "           2    1.00000   1.00000   1.00000        40\n",
      "\n",
      "    accuracy                        1.00000        97\n",
      "   macro avg    1.00000   1.00000   1.00000        97\n",
      "weighted avg    1.00000   1.00000   1.00000        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=106, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=46, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 106)\n",
    "load_model(gen, \"cGAN_UCI_Group_3_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 3)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 0 25  0]\n",
      " [ 0  0 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        30\n",
      "           1    1.00000   1.00000   1.00000        25\n",
      "           2    1.00000   1.00000   1.00000        42\n",
      "\n",
      "    accuracy                        1.00000        97\n",
      "   macro avg    1.00000   1.00000   1.00000        97\n",
      "weighted avg    1.00000   1.00000   1.00000        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [14, 15, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 14:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 15:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.217699885368347, Final Batch Loss: 1.119359016418457\n",
      "Epoch 2, Loss: 2.2090342044830322, Final Batch Loss: 1.1033437252044678\n",
      "Epoch 3, Loss: 2.212479829788208, Final Batch Loss: 1.1099441051483154\n",
      "Epoch 4, Loss: 2.2085607051849365, Final Batch Loss: 1.1047834157943726\n",
      "Epoch 5, Loss: 2.2087886333465576, Final Batch Loss: 1.104820966720581\n",
      "Epoch 6, Loss: 2.2152249813079834, Final Batch Loss: 1.122309923171997\n",
      "Epoch 7, Loss: 2.2055141925811768, Final Batch Loss: 1.1034730672836304\n",
      "Epoch 8, Loss: 2.203434109687805, Final Batch Loss: 1.0988510847091675\n",
      "Epoch 9, Loss: 2.198675274848938, Final Batch Loss: 1.0893535614013672\n",
      "Epoch 10, Loss: 2.2043462991714478, Final Batch Loss: 1.105796456336975\n",
      "Epoch 11, Loss: 2.204877734184265, Final Batch Loss: 1.1073110103607178\n",
      "Epoch 12, Loss: 2.199535608291626, Final Batch Loss: 1.098240852355957\n",
      "Epoch 13, Loss: 2.196805000305176, Final Batch Loss: 1.0940277576446533\n",
      "Epoch 14, Loss: 2.2031521797180176, Final Batch Loss: 1.10940420627594\n",
      "Epoch 15, Loss: 2.2016801834106445, Final Batch Loss: 1.1061357259750366\n",
      "Epoch 16, Loss: 2.1965869665145874, Final Batch Loss: 1.0999821424484253\n",
      "Epoch 17, Loss: 2.2026463747024536, Final Batch Loss: 1.1113358736038208\n",
      "Epoch 18, Loss: 2.1936259269714355, Final Batch Loss: 1.0977709293365479\n",
      "Epoch 19, Loss: 2.1931480169296265, Final Batch Loss: 1.0969433784484863\n",
      "Epoch 20, Loss: 2.1901049613952637, Final Batch Loss: 1.088439702987671\n",
      "Epoch 21, Loss: 2.1949753761291504, Final Batch Loss: 1.1070022583007812\n",
      "Epoch 22, Loss: 2.187933921813965, Final Batch Loss: 1.095423936843872\n",
      "Epoch 23, Loss: 2.183518886566162, Final Batch Loss: 1.092452883720398\n",
      "Epoch 24, Loss: 2.1732171773910522, Final Batch Loss: 1.0744911432266235\n",
      "Epoch 25, Loss: 2.1794817447662354, Final Batch Loss: 1.0905171632766724\n",
      "Epoch 26, Loss: 2.1834975481033325, Final Batch Loss: 1.0997238159179688\n",
      "Epoch 27, Loss: 2.1733232736587524, Final Batch Loss: 1.0844696760177612\n",
      "Epoch 28, Loss: 2.1675608158111572, Final Batch Loss: 1.081110954284668\n",
      "Epoch 29, Loss: 2.1640270948410034, Final Batch Loss: 1.0804781913757324\n",
      "Epoch 30, Loss: 2.162995219230652, Final Batch Loss: 1.0801289081573486\n",
      "Epoch 31, Loss: 2.1612799167633057, Final Batch Loss: 1.0858036279678345\n",
      "Epoch 32, Loss: 2.1530325412750244, Final Batch Loss: 1.0749274492263794\n",
      "Epoch 33, Loss: 2.1519795656204224, Final Batch Loss: 1.0800127983093262\n",
      "Epoch 34, Loss: 2.1335673332214355, Final Batch Loss: 1.0626531839370728\n",
      "Epoch 35, Loss: 2.1361578702926636, Final Batch Loss: 1.0734070539474487\n",
      "Epoch 36, Loss: 2.124217391014099, Final Batch Loss: 1.0609917640686035\n",
      "Epoch 37, Loss: 2.104759454727173, Final Batch Loss: 1.0419557094573975\n",
      "Epoch 38, Loss: 2.1025441884994507, Final Batch Loss: 1.0526328086853027\n",
      "Epoch 39, Loss: 2.079535722732544, Final Batch Loss: 1.0246561765670776\n",
      "Epoch 40, Loss: 2.088226556777954, Final Batch Loss: 1.0615876913070679\n",
      "Epoch 41, Loss: 2.0557141304016113, Final Batch Loss: 1.0208431482315063\n",
      "Epoch 42, Loss: 2.046353340148926, Final Batch Loss: 1.0219109058380127\n",
      "Epoch 43, Loss: 2.028834819793701, Final Batch Loss: 1.0168980360031128\n",
      "Epoch 44, Loss: 1.998969316482544, Final Batch Loss: 0.998138427734375\n",
      "Epoch 45, Loss: 1.9921739101409912, Final Batch Loss: 0.9938231706619263\n",
      "Epoch 46, Loss: 1.9364871978759766, Final Batch Loss: 0.9683501720428467\n",
      "Epoch 47, Loss: 1.9185491800308228, Final Batch Loss: 0.9433979392051697\n",
      "Epoch 48, Loss: 1.900555968284607, Final Batch Loss: 0.9403479099273682\n",
      "Epoch 49, Loss: 1.8908957839012146, Final Batch Loss: 0.9429536461830139\n",
      "Epoch 50, Loss: 1.8648546934127808, Final Batch Loss: 0.9557436108589172\n",
      "Epoch 51, Loss: 1.8504661321640015, Final Batch Loss: 0.9277970194816589\n",
      "Epoch 52, Loss: 1.8083981275558472, Final Batch Loss: 0.8943818211555481\n",
      "Epoch 53, Loss: 1.7889134883880615, Final Batch Loss: 0.8922598958015442\n",
      "Epoch 54, Loss: 1.781004250049591, Final Batch Loss: 0.8997514247894287\n",
      "Epoch 55, Loss: 1.730221688747406, Final Batch Loss: 0.8202124238014221\n",
      "Epoch 56, Loss: 1.710070788860321, Final Batch Loss: 0.830036461353302\n",
      "Epoch 57, Loss: 1.684767723083496, Final Batch Loss: 0.8260782957077026\n",
      "Epoch 58, Loss: 1.679568886756897, Final Batch Loss: 0.8315407037734985\n",
      "Epoch 59, Loss: 1.6642202138900757, Final Batch Loss: 0.8001247644424438\n",
      "Epoch 60, Loss: 1.6580728888511658, Final Batch Loss: 0.8323811888694763\n",
      "Epoch 61, Loss: 1.6309902667999268, Final Batch Loss: 0.8245285749435425\n",
      "Epoch 62, Loss: 1.6449397206306458, Final Batch Loss: 0.8189951181411743\n",
      "Epoch 63, Loss: 1.6409329771995544, Final Batch Loss: 0.8661206364631653\n",
      "Epoch 64, Loss: 1.624670147895813, Final Batch Loss: 0.8371359705924988\n",
      "Epoch 65, Loss: 1.5832473039627075, Final Batch Loss: 0.7998926639556885\n",
      "Epoch 66, Loss: 1.5992441773414612, Final Batch Loss: 0.8086673617362976\n",
      "Epoch 67, Loss: 1.6025193333625793, Final Batch Loss: 0.8126658797264099\n",
      "Epoch 68, Loss: 1.5913237929344177, Final Batch Loss: 0.8336292505264282\n",
      "Epoch 69, Loss: 1.552115261554718, Final Batch Loss: 0.7892695069313049\n",
      "Epoch 70, Loss: 1.5160796642303467, Final Batch Loss: 0.7484056949615479\n",
      "Epoch 71, Loss: 1.462981104850769, Final Batch Loss: 0.6918483376502991\n",
      "Epoch 72, Loss: 1.47358900308609, Final Batch Loss: 0.7148041129112244\n",
      "Epoch 73, Loss: 1.4415552616119385, Final Batch Loss: 0.6887521147727966\n",
      "Epoch 74, Loss: 1.4723562598228455, Final Batch Loss: 0.784598171710968\n",
      "Epoch 75, Loss: 1.430052101612091, Final Batch Loss: 0.7408296465873718\n",
      "Epoch 76, Loss: 1.4043781161308289, Final Batch Loss: 0.6748558878898621\n",
      "Epoch 77, Loss: 1.3884449005126953, Final Batch Loss: 0.67368084192276\n",
      "Epoch 78, Loss: 1.3692256808280945, Final Batch Loss: 0.678220808506012\n",
      "Epoch 79, Loss: 1.3838403224945068, Final Batch Loss: 0.6622939705848694\n",
      "Epoch 80, Loss: 1.3347387909889221, Final Batch Loss: 0.6487439274787903\n",
      "Epoch 81, Loss: 1.2933722138404846, Final Batch Loss: 0.6378675103187561\n",
      "Epoch 82, Loss: 1.3259897828102112, Final Batch Loss: 0.6385732889175415\n",
      "Epoch 83, Loss: 1.311706304550171, Final Batch Loss: 0.6338149905204773\n",
      "Epoch 84, Loss: 1.279933750629425, Final Batch Loss: 0.6087744235992432\n",
      "Epoch 85, Loss: 1.3010965585708618, Final Batch Loss: 0.6150869727134705\n",
      "Epoch 86, Loss: 1.2878291010856628, Final Batch Loss: 0.6361883282661438\n",
      "Epoch 87, Loss: 1.312002420425415, Final Batch Loss: 0.7066554427146912\n",
      "Epoch 88, Loss: 1.2823402285575867, Final Batch Loss: 0.6726102828979492\n",
      "Epoch 89, Loss: 1.1997917890548706, Final Batch Loss: 0.5710572600364685\n",
      "Epoch 90, Loss: 1.2505136132240295, Final Batch Loss: 0.6556020975112915\n",
      "Epoch 91, Loss: 1.2102267742156982, Final Batch Loss: 0.6177997589111328\n",
      "Epoch 92, Loss: 1.2353291511535645, Final Batch Loss: 0.6342872977256775\n",
      "Epoch 93, Loss: 1.2064061164855957, Final Batch Loss: 0.591968297958374\n",
      "Epoch 94, Loss: 1.1780608892440796, Final Batch Loss: 0.5813067555427551\n",
      "Epoch 95, Loss: 1.218492567539215, Final Batch Loss: 0.6151643991470337\n",
      "Epoch 96, Loss: 1.1938868761062622, Final Batch Loss: 0.6192441582679749\n",
      "Epoch 97, Loss: 1.173743486404419, Final Batch Loss: 0.6130512952804565\n",
      "Epoch 98, Loss: 1.1277018785476685, Final Batch Loss: 0.5412686467170715\n",
      "Epoch 99, Loss: 1.11958509683609, Final Batch Loss: 0.543521523475647\n",
      "Epoch 100, Loss: 1.1882404685020447, Final Batch Loss: 0.6115494966506958\n",
      "Epoch 101, Loss: 1.1072490215301514, Final Batch Loss: 0.5777320265769958\n",
      "Epoch 102, Loss: 1.0802457928657532, Final Batch Loss: 0.504745364189148\n",
      "Epoch 103, Loss: 1.0761707425117493, Final Batch Loss: 0.5283336639404297\n",
      "Epoch 104, Loss: 1.0336523652076721, Final Batch Loss: 0.4745261073112488\n",
      "Epoch 105, Loss: 1.0630435347557068, Final Batch Loss: 0.5377124547958374\n",
      "Epoch 106, Loss: 1.045157790184021, Final Batch Loss: 0.499053955078125\n",
      "Epoch 107, Loss: 1.081752896308899, Final Batch Loss: 0.5697705149650574\n",
      "Epoch 108, Loss: 1.056260347366333, Final Batch Loss: 0.5176193714141846\n",
      "Epoch 109, Loss: 1.0037397146224976, Final Batch Loss: 0.5017517805099487\n",
      "Epoch 110, Loss: 0.967111349105835, Final Batch Loss: 0.44931483268737793\n",
      "Epoch 111, Loss: 1.0450976490974426, Final Batch Loss: 0.5664852857589722\n",
      "Epoch 112, Loss: 0.9896327257156372, Final Batch Loss: 0.46240830421447754\n",
      "Epoch 113, Loss: 0.9908776581287384, Final Batch Loss: 0.5154330134391785\n",
      "Epoch 114, Loss: 1.0188828110694885, Final Batch Loss: 0.5471464991569519\n",
      "Epoch 115, Loss: 1.0074950754642487, Final Batch Loss: 0.5268666744232178\n",
      "Epoch 116, Loss: 0.9913588464260101, Final Batch Loss: 0.48345741629600525\n",
      "Epoch 117, Loss: 0.9602282643318176, Final Batch Loss: 0.49679142236709595\n",
      "Epoch 118, Loss: 0.9680680632591248, Final Batch Loss: 0.5203810930252075\n",
      "Epoch 119, Loss: 0.9206058084964752, Final Batch Loss: 0.4652644395828247\n",
      "Epoch 120, Loss: 0.87196946144104, Final Batch Loss: 0.3579266667366028\n",
      "Epoch 121, Loss: 0.8726515173912048, Final Batch Loss: 0.399997740983963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Loss: 0.9032156765460968, Final Batch Loss: 0.4729790687561035\n",
      "Epoch 123, Loss: 0.9008489549160004, Final Batch Loss: 0.41604024171829224\n",
      "Epoch 124, Loss: 0.9041068851947784, Final Batch Loss: 0.4601951837539673\n",
      "Epoch 125, Loss: 0.8790995180606842, Final Batch Loss: 0.44201284646987915\n",
      "Epoch 126, Loss: 0.8469703793525696, Final Batch Loss: 0.40832793712615967\n",
      "Epoch 127, Loss: 0.867369145154953, Final Batch Loss: 0.4666025936603546\n",
      "Epoch 128, Loss: 0.8274988830089569, Final Batch Loss: 0.3870810568332672\n",
      "Epoch 129, Loss: 0.8835499286651611, Final Batch Loss: 0.47291380167007446\n",
      "Epoch 130, Loss: 0.840597003698349, Final Batch Loss: 0.3843845725059509\n",
      "Epoch 131, Loss: 0.8582369089126587, Final Batch Loss: 0.43113043904304504\n",
      "Epoch 132, Loss: 0.8290387392044067, Final Batch Loss: 0.41628366708755493\n",
      "Epoch 133, Loss: 0.8293172121047974, Final Batch Loss: 0.43426942825317383\n",
      "Epoch 134, Loss: 0.8132847845554352, Final Batch Loss: 0.3944415748119354\n",
      "Epoch 135, Loss: 0.7520247101783752, Final Batch Loss: 0.3599293828010559\n",
      "Epoch 136, Loss: 0.8973362445831299, Final Batch Loss: 0.5203205347061157\n",
      "Epoch 137, Loss: 0.7831195592880249, Final Batch Loss: 0.36033275723457336\n",
      "Epoch 138, Loss: 0.7617367208003998, Final Batch Loss: 0.3563324511051178\n",
      "Epoch 139, Loss: 0.8085125684738159, Final Batch Loss: 0.4344695210456848\n",
      "Epoch 140, Loss: 0.7573384046554565, Final Batch Loss: 0.3680698275566101\n",
      "Epoch 141, Loss: 0.7449167668819427, Final Batch Loss: 0.37017494440078735\n",
      "Epoch 142, Loss: 0.7020244300365448, Final Batch Loss: 0.3332951068878174\n",
      "Epoch 143, Loss: 0.7280522286891937, Final Batch Loss: 0.36544302105903625\n",
      "Epoch 144, Loss: 0.7477249205112457, Final Batch Loss: 0.38195541501045227\n",
      "Epoch 145, Loss: 0.770108699798584, Final Batch Loss: 0.40052884817123413\n",
      "Epoch 146, Loss: 0.7501420676708221, Final Batch Loss: 0.3660300076007843\n",
      "Epoch 147, Loss: 0.7371204793453217, Final Batch Loss: 0.3352484703063965\n",
      "Epoch 148, Loss: 0.7395561933517456, Final Batch Loss: 0.38030165433883667\n",
      "Epoch 149, Loss: 0.6897379755973816, Final Batch Loss: 0.3559706509113312\n",
      "Epoch 150, Loss: 0.6669213771820068, Final Batch Loss: 0.2671075761318207\n",
      "Epoch 151, Loss: 0.7261880934238434, Final Batch Loss: 0.3963348865509033\n",
      "Epoch 152, Loss: 0.6602621078491211, Final Batch Loss: 0.3201451897621155\n",
      "Epoch 153, Loss: 0.6906639337539673, Final Batch Loss: 0.3620133101940155\n",
      "Epoch 154, Loss: 0.6431359648704529, Final Batch Loss: 0.2744775712490082\n",
      "Epoch 155, Loss: 0.6867274940013885, Final Batch Loss: 0.3412155508995056\n",
      "Epoch 156, Loss: 0.690399169921875, Final Batch Loss: 0.3448176085948944\n",
      "Epoch 157, Loss: 0.6250661015510559, Final Batch Loss: 0.26328396797180176\n",
      "Epoch 158, Loss: 0.6519741415977478, Final Batch Loss: 0.32062771916389465\n",
      "Epoch 159, Loss: 0.6869506537914276, Final Batch Loss: 0.38438859581947327\n",
      "Epoch 160, Loss: 0.6762038469314575, Final Batch Loss: 0.3703267574310303\n",
      "Epoch 161, Loss: 0.6616131663322449, Final Batch Loss: 0.3204227089881897\n",
      "Epoch 162, Loss: 0.6421796083450317, Final Batch Loss: 0.29707974195480347\n",
      "Epoch 163, Loss: 0.6541154980659485, Final Batch Loss: 0.36277198791503906\n",
      "Epoch 164, Loss: 0.6685073375701904, Final Batch Loss: 0.39930176734924316\n",
      "Epoch 165, Loss: 0.6588830053806305, Final Batch Loss: 0.3232957124710083\n",
      "Epoch 166, Loss: 0.6766729354858398, Final Batch Loss: 0.376446396112442\n",
      "Epoch 167, Loss: 0.6503761112689972, Final Batch Loss: 0.33521175384521484\n",
      "Epoch 168, Loss: 0.6407958269119263, Final Batch Loss: 0.3319593667984009\n",
      "Epoch 169, Loss: 0.6513681709766388, Final Batch Loss: 0.3625422716140747\n",
      "Epoch 170, Loss: 0.60482457280159, Final Batch Loss: 0.27989792823791504\n",
      "Epoch 171, Loss: 0.6202485263347626, Final Batch Loss: 0.31160542368888855\n",
      "Epoch 172, Loss: 0.6238714456558228, Final Batch Loss: 0.29702696204185486\n",
      "Epoch 173, Loss: 0.6490198969841003, Final Batch Loss: 0.3248600959777832\n",
      "Epoch 174, Loss: 0.6459057331085205, Final Batch Loss: 0.30983370542526245\n",
      "Epoch 175, Loss: 0.6200174987316132, Final Batch Loss: 0.27720487117767334\n",
      "Epoch 176, Loss: 0.6223585903644562, Final Batch Loss: 0.2587658166885376\n",
      "Epoch 177, Loss: 0.6166930794715881, Final Batch Loss: 0.34425681829452515\n",
      "Epoch 178, Loss: 0.5932953357696533, Final Batch Loss: 0.28917744755744934\n",
      "Epoch 179, Loss: 0.6162537336349487, Final Batch Loss: 0.30831378698349\n",
      "Epoch 180, Loss: 0.6394992768764496, Final Batch Loss: 0.35456785559654236\n",
      "Epoch 181, Loss: 0.5924918353557587, Final Batch Loss: 0.3003044128417969\n",
      "Epoch 182, Loss: 0.61399245262146, Final Batch Loss: 0.3184691071510315\n",
      "Epoch 183, Loss: 0.5865364968776703, Final Batch Loss: 0.305442750453949\n",
      "Epoch 184, Loss: 0.5833287537097931, Final Batch Loss: 0.2808842658996582\n",
      "Epoch 185, Loss: 0.5990001559257507, Final Batch Loss: 0.2840488851070404\n",
      "Epoch 186, Loss: 0.5993328988552094, Final Batch Loss: 0.27817338705062866\n",
      "Epoch 187, Loss: 0.5727234482765198, Final Batch Loss: 0.25783658027648926\n",
      "Epoch 188, Loss: 0.6345077157020569, Final Batch Loss: 0.35276150703430176\n",
      "Epoch 189, Loss: 0.6133789420127869, Final Batch Loss: 0.3275841474533081\n",
      "Epoch 190, Loss: 0.5884532034397125, Final Batch Loss: 0.27588415145874023\n",
      "Epoch 191, Loss: 0.612756073474884, Final Batch Loss: 0.3303454518318176\n",
      "Epoch 192, Loss: 0.5669168829917908, Final Batch Loss: 0.22831788659095764\n",
      "Epoch 193, Loss: 0.6270030736923218, Final Batch Loss: 0.3428647816181183\n",
      "Epoch 194, Loss: 0.6217493414878845, Final Batch Loss: 0.3233659267425537\n",
      "Epoch 195, Loss: 0.6160247623920441, Final Batch Loss: 0.3055287301540375\n",
      "Epoch 196, Loss: 0.5936141014099121, Final Batch Loss: 0.32118523120880127\n",
      "Epoch 197, Loss: 0.5699970424175262, Final Batch Loss: 0.2747346758842468\n",
      "Epoch 198, Loss: 0.5778952836990356, Final Batch Loss: 0.2908220887184143\n",
      "Epoch 199, Loss: 0.5916299521923065, Final Batch Loss: 0.30502188205718994\n",
      "Epoch 200, Loss: 0.5431418567895889, Final Batch Loss: 0.23288239538669586\n",
      "Epoch 201, Loss: 0.5704586803913116, Final Batch Loss: 0.2327270805835724\n",
      "Epoch 202, Loss: 0.6395864486694336, Final Batch Loss: 0.36992114782333374\n",
      "Epoch 203, Loss: 0.5330756455659866, Final Batch Loss: 0.2338620275259018\n",
      "Epoch 204, Loss: 0.5492098331451416, Final Batch Loss: 0.2704370319843292\n",
      "Epoch 205, Loss: 0.6054644882678986, Final Batch Loss: 0.3073037564754486\n",
      "Epoch 206, Loss: 0.5521996915340424, Final Batch Loss: 0.26840776205062866\n",
      "Epoch 207, Loss: 0.5679527223110199, Final Batch Loss: 0.293706476688385\n",
      "Epoch 208, Loss: 0.5695368349552155, Final Batch Loss: 0.29548200964927673\n",
      "Epoch 209, Loss: 0.5924905240535736, Final Batch Loss: 0.298045814037323\n",
      "Epoch 210, Loss: 0.5920975506305695, Final Batch Loss: 0.29197895526885986\n",
      "Epoch 211, Loss: 0.5741281807422638, Final Batch Loss: 0.30850157141685486\n",
      "Epoch 212, Loss: 0.5577808022499084, Final Batch Loss: 0.2882581353187561\n",
      "Epoch 213, Loss: 0.5711641311645508, Final Batch Loss: 0.2734226882457733\n",
      "Epoch 214, Loss: 0.5719742178916931, Final Batch Loss: 0.2676328718662262\n",
      "Epoch 215, Loss: 0.5543331205844879, Final Batch Loss: 0.28652235865592957\n",
      "Epoch 216, Loss: 0.6038207560777664, Final Batch Loss: 0.3796011805534363\n",
      "Epoch 217, Loss: 0.5359513014554977, Final Batch Loss: 0.2294863611459732\n",
      "Epoch 218, Loss: 0.5636299848556519, Final Batch Loss: 0.30086973309516907\n",
      "Epoch 219, Loss: 0.529713973402977, Final Batch Loss: 0.23180095851421356\n",
      "Epoch 220, Loss: 0.5604517757892609, Final Batch Loss: 0.2600845694541931\n",
      "Epoch 221, Loss: 0.5753903090953827, Final Batch Loss: 0.3181259334087372\n",
      "Epoch 222, Loss: 0.5342190265655518, Final Batch Loss: 0.22412502765655518\n",
      "Epoch 223, Loss: 0.5478543639183044, Final Batch Loss: 0.25289300084114075\n",
      "Epoch 224, Loss: 0.5285135805606842, Final Batch Loss: 0.2137254774570465\n",
      "Epoch 225, Loss: 0.5737963765859604, Final Batch Loss: 0.32565730810165405\n",
      "Epoch 226, Loss: 0.5839486569166183, Final Batch Loss: 0.334613174200058\n",
      "Epoch 227, Loss: 0.5622119903564453, Final Batch Loss: 0.29780349135398865\n",
      "Epoch 228, Loss: 0.5233055651187897, Final Batch Loss: 0.2508705258369446\n",
      "Epoch 229, Loss: 0.5385339260101318, Final Batch Loss: 0.24909675121307373\n",
      "Epoch 230, Loss: 0.5441234111785889, Final Batch Loss: 0.2791198194026947\n",
      "Epoch 231, Loss: 0.550649881362915, Final Batch Loss: 0.26904550194740295\n",
      "Epoch 232, Loss: 0.5740059614181519, Final Batch Loss: 0.30373701453208923\n",
      "Epoch 233, Loss: 0.5596423447132111, Final Batch Loss: 0.2643664479255676\n",
      "Epoch 234, Loss: 0.5458610355854034, Final Batch Loss: 0.3114398121833801\n",
      "Epoch 235, Loss: 0.54432712495327, Final Batch Loss: 0.2269364446401596\n",
      "Epoch 236, Loss: 0.5675938129425049, Final Batch Loss: 0.27965232729911804\n",
      "Epoch 237, Loss: 0.5330094397068024, Final Batch Loss: 0.25322291254997253\n",
      "Epoch 238, Loss: 0.5426875948905945, Final Batch Loss: 0.26009202003479004\n",
      "Epoch 239, Loss: 0.569544643163681, Final Batch Loss: 0.29945483803749084\n",
      "Epoch 240, Loss: 0.5510905981063843, Final Batch Loss: 0.3133103549480438\n",
      "Epoch 241, Loss: 0.5256232172250748, Final Batch Loss: 0.22600595653057098\n",
      "Epoch 242, Loss: 0.5472032427787781, Final Batch Loss: 0.25991612672805786\n",
      "Epoch 243, Loss: 0.5744317471981049, Final Batch Loss: 0.29765433073043823\n",
      "Epoch 244, Loss: 0.527621790766716, Final Batch Loss: 0.24812094867229462\n",
      "Epoch 245, Loss: 0.5575365126132965, Final Batch Loss: 0.3008049726486206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246, Loss: 0.5520505309104919, Final Batch Loss: 0.31134089827537537\n",
      "Epoch 247, Loss: 0.5333132445812225, Final Batch Loss: 0.30241477489471436\n",
      "Epoch 248, Loss: 0.5306800901889801, Final Batch Loss: 0.24132665991783142\n",
      "Epoch 249, Loss: 0.5490382015705109, Final Batch Loss: 0.2880197763442993\n",
      "Epoch 250, Loss: 0.5449821352958679, Final Batch Loss: 0.3231327533721924\n",
      "Epoch 251, Loss: 0.5074972361326218, Final Batch Loss: 0.24138103425502777\n",
      "Epoch 252, Loss: 0.5275499373674393, Final Batch Loss: 0.27882882952690125\n",
      "Epoch 253, Loss: 0.5859870612621307, Final Batch Loss: 0.341363787651062\n",
      "Epoch 254, Loss: 0.5586755573749542, Final Batch Loss: 0.29169997572898865\n",
      "Epoch 255, Loss: 0.5602753758430481, Final Batch Loss: 0.31673043966293335\n",
      "Epoch 256, Loss: 0.5488959848880768, Final Batch Loss: 0.270349383354187\n",
      "Epoch 257, Loss: 0.532558798789978, Final Batch Loss: 0.24442386627197266\n",
      "Epoch 258, Loss: 0.5700439363718033, Final Batch Loss: 0.32090499997138977\n",
      "Epoch 259, Loss: 0.5262443125247955, Final Batch Loss: 0.24580645561218262\n",
      "Epoch 260, Loss: 0.5693337917327881, Final Batch Loss: 0.30743807554244995\n",
      "Epoch 261, Loss: 0.49983130395412445, Final Batch Loss: 0.23228390514850616\n",
      "Epoch 262, Loss: 0.5130771100521088, Final Batch Loss: 0.2542165517807007\n",
      "Epoch 263, Loss: 0.5488767027854919, Final Batch Loss: 0.28284600377082825\n",
      "Epoch 264, Loss: 0.5455165058374405, Final Batch Loss: 0.2434576004743576\n",
      "Epoch 265, Loss: 0.5606723427772522, Final Batch Loss: 0.31813845038414\n",
      "Epoch 266, Loss: 0.5509946346282959, Final Batch Loss: 0.31804248690605164\n",
      "Epoch 267, Loss: 0.5590818822383881, Final Batch Loss: 0.2701050639152527\n",
      "Epoch 268, Loss: 0.5214248299598694, Final Batch Loss: 0.25356799364089966\n",
      "Epoch 269, Loss: 0.5583391487598419, Final Batch Loss: 0.3034728467464447\n",
      "Epoch 270, Loss: 0.5458466410636902, Final Batch Loss: 0.2933022081851959\n",
      "Epoch 271, Loss: 0.5283440202474594, Final Batch Loss: 0.2939074635505676\n",
      "Epoch 272, Loss: 0.552860677242279, Final Batch Loss: 0.3006737530231476\n",
      "Epoch 273, Loss: 0.5382156819105148, Final Batch Loss: 0.29032036662101746\n",
      "Epoch 274, Loss: 0.5659539699554443, Final Batch Loss: 0.3099861443042755\n",
      "Epoch 275, Loss: 0.5700568556785583, Final Batch Loss: 0.33347442746162415\n",
      "Epoch 276, Loss: 0.5236078500747681, Final Batch Loss: 0.26954561471939087\n",
      "Epoch 277, Loss: 0.5306103676557541, Final Batch Loss: 0.21569322049617767\n",
      "Epoch 278, Loss: 0.5560064613819122, Final Batch Loss: 0.2658441662788391\n",
      "Epoch 279, Loss: 0.5477030277252197, Final Batch Loss: 0.2953017055988312\n",
      "Epoch 280, Loss: 0.5509481132030487, Final Batch Loss: 0.2677476108074188\n",
      "Epoch 281, Loss: 0.5536955893039703, Final Batch Loss: 0.28394877910614014\n",
      "Epoch 282, Loss: 0.5335111021995544, Final Batch Loss: 0.2879256010055542\n",
      "Epoch 283, Loss: 0.5883044004440308, Final Batch Loss: 0.29999107122421265\n",
      "Epoch 284, Loss: 0.5138641893863678, Final Batch Loss: 0.22436803579330444\n",
      "Epoch 285, Loss: 0.521663248538971, Final Batch Loss: 0.2530224621295929\n",
      "Epoch 286, Loss: 0.5348361432552338, Final Batch Loss: 0.25193849205970764\n",
      "Epoch 287, Loss: 0.5628778040409088, Final Batch Loss: 0.3103751540184021\n",
      "Epoch 288, Loss: 0.5759623050689697, Final Batch Loss: 0.3095065653324127\n",
      "Epoch 289, Loss: 0.5092587918043137, Final Batch Loss: 0.21435268223285675\n",
      "Epoch 290, Loss: 0.5199239403009415, Final Batch Loss: 0.2265351563692093\n",
      "Epoch 291, Loss: 0.5057244896888733, Final Batch Loss: 0.20958653092384338\n",
      "Epoch 292, Loss: 0.5161300599575043, Final Batch Loss: 0.239599347114563\n",
      "Epoch 293, Loss: 0.523545116186142, Final Batch Loss: 0.2951386868953705\n",
      "Epoch 294, Loss: 0.5328068733215332, Final Batch Loss: 0.26745495200157166\n",
      "Epoch 295, Loss: 0.4875328689813614, Final Batch Loss: 0.2118559628725052\n",
      "Epoch 296, Loss: 0.5728089809417725, Final Batch Loss: 0.3216438293457031\n",
      "Epoch 297, Loss: 0.5356213748455048, Final Batch Loss: 0.30066460371017456\n",
      "Epoch 298, Loss: 0.5279912352561951, Final Batch Loss: 0.25746065378189087\n",
      "Epoch 299, Loss: 0.5392729490995407, Final Batch Loss: 0.2447231560945511\n",
      "Epoch 300, Loss: 0.5237747430801392, Final Batch Loss: 0.2635972201824188\n",
      "Epoch 301, Loss: 0.5680276453495026, Final Batch Loss: 0.3014739751815796\n",
      "Epoch 302, Loss: 0.5372916609048843, Final Batch Loss: 0.3222852647304535\n",
      "Epoch 303, Loss: 0.5109703242778778, Final Batch Loss: 0.22281184792518616\n",
      "Epoch 304, Loss: 0.5108417272567749, Final Batch Loss: 0.2737620174884796\n",
      "Epoch 305, Loss: 0.4981393963098526, Final Batch Loss: 0.2289683073759079\n",
      "Epoch 306, Loss: 0.48893801867961884, Final Batch Loss: 0.21858178079128265\n",
      "Epoch 307, Loss: 0.5540349334478378, Final Batch Loss: 0.32172420620918274\n",
      "Epoch 308, Loss: 0.5171053111553192, Final Batch Loss: 0.23515954613685608\n",
      "Epoch 309, Loss: 0.5585763454437256, Final Batch Loss: 0.3024565875530243\n",
      "Epoch 310, Loss: 0.5076409876346588, Final Batch Loss: 0.2832548916339874\n",
      "Epoch 311, Loss: 0.5252456068992615, Final Batch Loss: 0.2651132643222809\n",
      "Epoch 312, Loss: 0.5166342407464981, Final Batch Loss: 0.2866891026496887\n",
      "Epoch 313, Loss: 0.5020047724246979, Final Batch Loss: 0.25828370451927185\n",
      "Epoch 314, Loss: 0.5301994383335114, Final Batch Loss: 0.2619613707065582\n",
      "Epoch 315, Loss: 0.5523719489574432, Final Batch Loss: 0.30326157808303833\n",
      "Epoch 316, Loss: 0.5457356125116348, Final Batch Loss: 0.3070240616798401\n",
      "Epoch 317, Loss: 0.5064381659030914, Final Batch Loss: 0.22693860530853271\n",
      "Epoch 318, Loss: 0.46815311908721924, Final Batch Loss: 0.20185938477516174\n",
      "Epoch 319, Loss: 0.5095324963331223, Final Batch Loss: 0.2126695066690445\n",
      "Epoch 320, Loss: 0.5571200549602509, Final Batch Loss: 0.3333851397037506\n",
      "Epoch 321, Loss: 0.5164031386375427, Final Batch Loss: 0.2655464708805084\n",
      "Epoch 322, Loss: 0.5080132186412811, Final Batch Loss: 0.22917205095291138\n",
      "Epoch 323, Loss: 0.48213455080986023, Final Batch Loss: 0.19252455234527588\n",
      "Epoch 324, Loss: 0.511028841137886, Final Batch Loss: 0.24730955064296722\n",
      "Epoch 325, Loss: 0.5464188754558563, Final Batch Loss: 0.3032916188240051\n",
      "Epoch 326, Loss: 0.4760773330926895, Final Batch Loss: 0.1898338943719864\n",
      "Epoch 327, Loss: 0.5190955400466919, Final Batch Loss: 0.2555670738220215\n",
      "Epoch 328, Loss: 0.5141558796167374, Final Batch Loss: 0.28224170207977295\n",
      "Epoch 329, Loss: 0.5310960710048676, Final Batch Loss: 0.26775383949279785\n",
      "Epoch 330, Loss: 0.5139726400375366, Final Batch Loss: 0.27795034646987915\n",
      "Epoch 331, Loss: 0.48836347460746765, Final Batch Loss: 0.22308403253555298\n",
      "Epoch 332, Loss: 0.5045512616634369, Final Batch Loss: 0.2712723910808563\n",
      "Epoch 333, Loss: 0.4768197536468506, Final Batch Loss: 0.22826756536960602\n",
      "Epoch 334, Loss: 0.5273707360029221, Final Batch Loss: 0.28471505641937256\n",
      "Epoch 335, Loss: 0.5366061627864838, Final Batch Loss: 0.27625778317451477\n",
      "Epoch 336, Loss: 0.5365092158317566, Final Batch Loss: 0.2673857510089874\n",
      "Epoch 337, Loss: 0.49930042028427124, Final Batch Loss: 0.2577764093875885\n",
      "Epoch 338, Loss: 0.5170459151268005, Final Batch Loss: 0.2656095325946808\n",
      "Epoch 339, Loss: 0.5071368962526321, Final Batch Loss: 0.26636984944343567\n",
      "Epoch 340, Loss: 0.5058595836162567, Final Batch Loss: 0.26916182041168213\n",
      "Epoch 341, Loss: 0.5008412450551987, Final Batch Loss: 0.25895532965660095\n",
      "Epoch 342, Loss: 0.547756016254425, Final Batch Loss: 0.27606937289237976\n",
      "Epoch 343, Loss: 0.5031614005565643, Final Batch Loss: 0.26849645376205444\n",
      "Epoch 344, Loss: 0.514491006731987, Final Batch Loss: 0.2440815418958664\n",
      "Epoch 345, Loss: 0.5281344205141068, Final Batch Loss: 0.22988642752170563\n",
      "Epoch 346, Loss: 0.4631286859512329, Final Batch Loss: 0.19392043352127075\n",
      "Epoch 347, Loss: 0.5045118629932404, Final Batch Loss: 0.2568945586681366\n",
      "Epoch 348, Loss: 0.5042659342288971, Final Batch Loss: 0.25227969884872437\n",
      "Epoch 349, Loss: 0.48258426785469055, Final Batch Loss: 0.2243821620941162\n",
      "Epoch 350, Loss: 0.5099713951349258, Final Batch Loss: 0.26931846141815186\n",
      "Epoch 351, Loss: 0.4623408317565918, Final Batch Loss: 0.20130082964897156\n",
      "Epoch 352, Loss: 0.5208978652954102, Final Batch Loss: 0.29421380162239075\n",
      "Epoch 353, Loss: 0.5229404717683792, Final Batch Loss: 0.2858807146549225\n",
      "Epoch 354, Loss: 0.5403927266597748, Final Batch Loss: 0.3241589069366455\n",
      "Epoch 355, Loss: 0.5049291700124741, Final Batch Loss: 0.26297810673713684\n",
      "Epoch 356, Loss: 0.43468077480793, Final Batch Loss: 0.14572392404079437\n",
      "Epoch 357, Loss: 0.5140343904495239, Final Batch Loss: 0.31372129917144775\n",
      "Epoch 358, Loss: 0.4823192059993744, Final Batch Loss: 0.22128981351852417\n",
      "Epoch 359, Loss: 0.47024472057819366, Final Batch Loss: 0.19472335278987885\n",
      "Epoch 360, Loss: 0.4869992583990097, Final Batch Loss: 0.24442258477210999\n",
      "Epoch 361, Loss: 0.4629117548465729, Final Batch Loss: 0.2292865514755249\n",
      "Epoch 362, Loss: 0.4953058212995529, Final Batch Loss: 0.28274407982826233\n",
      "Epoch 363, Loss: 0.45656558871269226, Final Batch Loss: 0.19485247135162354\n",
      "Epoch 364, Loss: 0.4923507124185562, Final Batch Loss: 0.22325871884822845\n",
      "Epoch 365, Loss: 0.4979615658521652, Final Batch Loss: 0.24078978598117828\n",
      "Epoch 366, Loss: 0.4580751210451126, Final Batch Loss: 0.21207818388938904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367, Loss: 0.48663952946662903, Final Batch Loss: 0.25856608152389526\n",
      "Epoch 368, Loss: 0.490381196141243, Final Batch Loss: 0.2258189469575882\n",
      "Epoch 369, Loss: 0.5069656819105148, Final Batch Loss: 0.2900691330432892\n",
      "Epoch 370, Loss: 0.4928916245698929, Final Batch Loss: 0.25265732407569885\n",
      "Epoch 371, Loss: 0.4926377832889557, Final Batch Loss: 0.2611995041370392\n",
      "Epoch 372, Loss: 0.5429114699363708, Final Batch Loss: 0.33559301495552063\n",
      "Epoch 373, Loss: 0.48660077154636383, Final Batch Loss: 0.2480163872241974\n",
      "Epoch 374, Loss: 0.4822608232498169, Final Batch Loss: 0.21832561492919922\n",
      "Epoch 375, Loss: 0.5053221732378006, Final Batch Loss: 0.26189085841178894\n",
      "Epoch 376, Loss: 0.5449854731559753, Final Batch Loss: 0.27497291564941406\n",
      "Epoch 377, Loss: 0.518206387758255, Final Batch Loss: 0.263232558965683\n",
      "Epoch 378, Loss: 0.5273492932319641, Final Batch Loss: 0.31308987736701965\n",
      "Epoch 379, Loss: 0.5006712228059769, Final Batch Loss: 0.2545808255672455\n",
      "Epoch 380, Loss: 0.47430139780044556, Final Batch Loss: 0.2308531552553177\n",
      "Epoch 381, Loss: 0.4806005209684372, Final Batch Loss: 0.21688471734523773\n",
      "Epoch 382, Loss: 0.5111435055732727, Final Batch Loss: 0.2654927670955658\n",
      "Epoch 383, Loss: 0.4981316030025482, Final Batch Loss: 0.22005370259284973\n",
      "Epoch 384, Loss: 0.48330000042915344, Final Batch Loss: 0.23940399289131165\n",
      "Epoch 385, Loss: 0.45745205879211426, Final Batch Loss: 0.18341287970542908\n",
      "Epoch 386, Loss: 0.4754664897918701, Final Batch Loss: 0.2363351434469223\n",
      "Epoch 387, Loss: 0.47511492669582367, Final Batch Loss: 0.24591609835624695\n",
      "Epoch 388, Loss: 0.5020966082811356, Final Batch Loss: 0.29876136779785156\n",
      "Epoch 389, Loss: 0.4910757392644882, Final Batch Loss: 0.25843289494514465\n",
      "Epoch 390, Loss: 0.44523459672927856, Final Batch Loss: 0.1953040212392807\n",
      "Epoch 391, Loss: 0.46037349104881287, Final Batch Loss: 0.19246673583984375\n",
      "Epoch 392, Loss: 0.42915530502796173, Final Batch Loss: 0.17495422065258026\n",
      "Epoch 393, Loss: 0.4978515952825546, Final Batch Loss: 0.26955029368400574\n",
      "Epoch 394, Loss: 0.4925090819597244, Final Batch Loss: 0.22410206496715546\n",
      "Epoch 395, Loss: 0.45064176619052887, Final Batch Loss: 0.19240929186344147\n",
      "Epoch 396, Loss: 0.45562656223773956, Final Batch Loss: 0.18125422298908234\n",
      "Epoch 397, Loss: 0.46302245557308197, Final Batch Loss: 0.2461727112531662\n",
      "Epoch 398, Loss: 0.46752120554447174, Final Batch Loss: 0.2503340244293213\n",
      "Epoch 399, Loss: 0.4657275080680847, Final Batch Loss: 0.2140427529811859\n",
      "Epoch 400, Loss: 0.4353591650724411, Final Batch Loss: 0.20446400344371796\n",
      "Epoch 401, Loss: 0.4670300930738449, Final Batch Loss: 0.2272227555513382\n",
      "Epoch 402, Loss: 0.5457020252943039, Final Batch Loss: 0.3134341239929199\n",
      "Epoch 403, Loss: 0.48269127309322357, Final Batch Loss: 0.29127469658851624\n",
      "Epoch 404, Loss: 0.43126486241817474, Final Batch Loss: 0.18607456982135773\n",
      "Epoch 405, Loss: 0.4513135403394699, Final Batch Loss: 0.16029579937458038\n",
      "Epoch 406, Loss: 0.47434914112091064, Final Batch Loss: 0.2526951730251312\n",
      "Epoch 407, Loss: 0.45885735750198364, Final Batch Loss: 0.25968819856643677\n",
      "Epoch 408, Loss: 0.44684451818466187, Final Batch Loss: 0.18315812945365906\n",
      "Epoch 409, Loss: 0.4756809324026108, Final Batch Loss: 0.26492512226104736\n",
      "Epoch 410, Loss: 0.44618767499923706, Final Batch Loss: 0.24193508923053741\n",
      "Epoch 411, Loss: 0.4206780642271042, Final Batch Loss: 0.19930966198444366\n",
      "Epoch 412, Loss: 0.3894818425178528, Final Batch Loss: 0.18464535474777222\n",
      "Epoch 413, Loss: 0.4519905149936676, Final Batch Loss: 0.24206437170505524\n",
      "Epoch 414, Loss: 0.44625651836395264, Final Batch Loss: 0.21265198290348053\n",
      "Epoch 415, Loss: 0.44041670858860016, Final Batch Loss: 0.21748444437980652\n",
      "Epoch 416, Loss: 0.45802049338817596, Final Batch Loss: 0.23226574063301086\n",
      "Epoch 417, Loss: 0.4200054109096527, Final Batch Loss: 0.16822287440299988\n",
      "Epoch 418, Loss: 0.45277029275894165, Final Batch Loss: 0.259464293718338\n",
      "Epoch 419, Loss: 0.4377955347299576, Final Batch Loss: 0.2078694999217987\n",
      "Epoch 420, Loss: 0.47027555108070374, Final Batch Loss: 0.205732524394989\n",
      "Epoch 421, Loss: 0.4361107498407364, Final Batch Loss: 0.16319797933101654\n",
      "Epoch 422, Loss: 0.4262983947992325, Final Batch Loss: 0.19555237889289856\n",
      "Epoch 423, Loss: 0.48034699261188507, Final Batch Loss: 0.19956959784030914\n",
      "Epoch 424, Loss: 0.4560253173112869, Final Batch Loss: 0.26883113384246826\n",
      "Epoch 425, Loss: 0.45316991209983826, Final Batch Loss: 0.25531911849975586\n",
      "Epoch 426, Loss: 0.42789462208747864, Final Batch Loss: 0.2197871208190918\n",
      "Epoch 427, Loss: 0.45400674641132355, Final Batch Loss: 0.2515518367290497\n",
      "Epoch 428, Loss: 0.4346996396780014, Final Batch Loss: 0.17370669543743134\n",
      "Epoch 429, Loss: 0.47280465066432953, Final Batch Loss: 0.2773033380508423\n",
      "Epoch 430, Loss: 0.45113328099250793, Final Batch Loss: 0.24746111035346985\n",
      "Epoch 431, Loss: 0.4648914635181427, Final Batch Loss: 0.24362976849079132\n",
      "Epoch 432, Loss: 0.43667493760585785, Final Batch Loss: 0.17598502337932587\n",
      "Epoch 433, Loss: 0.4405481368303299, Final Batch Loss: 0.23577697575092316\n",
      "Epoch 434, Loss: 0.44149473309516907, Final Batch Loss: 0.23978309333324432\n",
      "Epoch 435, Loss: 0.39476701617240906, Final Batch Loss: 0.1541832536458969\n",
      "Epoch 436, Loss: 0.40804509818553925, Final Batch Loss: 0.1933155357837677\n",
      "Epoch 437, Loss: 0.46190524101257324, Final Batch Loss: 0.22028526663780212\n",
      "Epoch 438, Loss: 0.46912555396556854, Final Batch Loss: 0.2246488779783249\n",
      "Epoch 439, Loss: 0.4042119234800339, Final Batch Loss: 0.16989900171756744\n",
      "Epoch 440, Loss: 0.4073841720819473, Final Batch Loss: 0.17753447592258453\n",
      "Epoch 441, Loss: 0.42814837396144867, Final Batch Loss: 0.16790758073329926\n",
      "Epoch 442, Loss: 0.4489385485649109, Final Batch Loss: 0.2436191290616989\n",
      "Epoch 443, Loss: 0.4667179733514786, Final Batch Loss: 0.24888309836387634\n",
      "Epoch 444, Loss: 0.4148416221141815, Final Batch Loss: 0.18909123539924622\n",
      "Epoch 445, Loss: 0.42768555879592896, Final Batch Loss: 0.2358429878950119\n",
      "Epoch 446, Loss: 0.44941459596157074, Final Batch Loss: 0.2191169112920761\n",
      "Epoch 447, Loss: 0.41020001471042633, Final Batch Loss: 0.1830335259437561\n",
      "Epoch 448, Loss: 0.42365115880966187, Final Batch Loss: 0.1985420286655426\n",
      "Epoch 449, Loss: 0.4208088517189026, Final Batch Loss: 0.2073836624622345\n",
      "Epoch 450, Loss: 0.46921737492084503, Final Batch Loss: 0.26082804799079895\n",
      "Epoch 451, Loss: 0.48306484520435333, Final Batch Loss: 0.27042433619499207\n",
      "Epoch 452, Loss: 0.3958905190229416, Final Batch Loss: 0.16368773579597473\n",
      "Epoch 453, Loss: 0.4138714075088501, Final Batch Loss: 0.16152095794677734\n",
      "Epoch 454, Loss: 0.4256315529346466, Final Batch Loss: 0.21023914217948914\n",
      "Epoch 455, Loss: 0.4459955245256424, Final Batch Loss: 0.24450527131557465\n",
      "Epoch 456, Loss: 0.39830291271209717, Final Batch Loss: 0.1891971081495285\n",
      "Epoch 457, Loss: 0.4261089414358139, Final Batch Loss: 0.20320983231067657\n",
      "Epoch 458, Loss: 0.42020653188228607, Final Batch Loss: 0.2331307977437973\n",
      "Epoch 459, Loss: 0.37985070049762726, Final Batch Loss: 0.16725414991378784\n",
      "Epoch 460, Loss: 0.37887439131736755, Final Batch Loss: 0.19721361994743347\n",
      "Epoch 461, Loss: 0.429582417011261, Final Batch Loss: 0.22721339762210846\n",
      "Epoch 462, Loss: 0.35086965560913086, Final Batch Loss: 0.12692058086395264\n",
      "Epoch 463, Loss: 0.4122559577226639, Final Batch Loss: 0.17366456985473633\n",
      "Epoch 464, Loss: 0.4009717106819153, Final Batch Loss: 0.2025616317987442\n",
      "Epoch 465, Loss: 0.4052065312862396, Final Batch Loss: 0.215642511844635\n",
      "Epoch 466, Loss: 0.4182940274477005, Final Batch Loss: 0.20926542580127716\n",
      "Epoch 467, Loss: 0.35016535222530365, Final Batch Loss: 0.14241187274456024\n",
      "Epoch 468, Loss: 0.40559886395931244, Final Batch Loss: 0.19632253050804138\n",
      "Epoch 469, Loss: 0.3893274664878845, Final Batch Loss: 0.22986207902431488\n",
      "Epoch 470, Loss: 0.3585917204618454, Final Batch Loss: 0.17312844097614288\n",
      "Epoch 471, Loss: 0.3790433406829834, Final Batch Loss: 0.17286615073680878\n",
      "Epoch 472, Loss: 0.4057076722383499, Final Batch Loss: 0.20408640801906586\n",
      "Epoch 473, Loss: 0.38713088631629944, Final Batch Loss: 0.19563867151737213\n",
      "Epoch 474, Loss: 0.39274320006370544, Final Batch Loss: 0.2015998661518097\n",
      "Epoch 475, Loss: 0.3899442255496979, Final Batch Loss: 0.18637077510356903\n",
      "Epoch 476, Loss: 0.3982103615999222, Final Batch Loss: 0.17874281108379364\n",
      "Epoch 477, Loss: 0.4229590892791748, Final Batch Loss: 0.20925937592983246\n",
      "Epoch 478, Loss: 0.3841215968132019, Final Batch Loss: 0.12559783458709717\n",
      "Epoch 479, Loss: 0.3702957332134247, Final Batch Loss: 0.17283865809440613\n",
      "Epoch 480, Loss: 0.36667998135089874, Final Batch Loss: 0.18703804910182953\n",
      "Epoch 481, Loss: 0.40745915472507477, Final Batch Loss: 0.20696163177490234\n",
      "Epoch 482, Loss: 0.45302920043468475, Final Batch Loss: 0.2137499749660492\n",
      "Epoch 483, Loss: 0.394566610455513, Final Batch Loss: 0.1917511224746704\n",
      "Epoch 484, Loss: 0.4076079726219177, Final Batch Loss: 0.21582026779651642\n",
      "Epoch 485, Loss: 0.40225252509117126, Final Batch Loss: 0.2240408957004547\n",
      "Epoch 486, Loss: 0.383651927113533, Final Batch Loss: 0.1622857302427292\n",
      "Epoch 487, Loss: 0.4017684906721115, Final Batch Loss: 0.21627269685268402\n",
      "Epoch 488, Loss: 0.40764227509498596, Final Batch Loss: 0.21603849530220032\n",
      "Epoch 489, Loss: 0.37321557104587555, Final Batch Loss: 0.13975399732589722\n",
      "Epoch 490, Loss: 0.39504802227020264, Final Batch Loss: 0.20279231667518616\n",
      "Epoch 491, Loss: 0.37634986639022827, Final Batch Loss: 0.20724599063396454\n",
      "Epoch 492, Loss: 0.3816155195236206, Final Batch Loss: 0.1889103800058365\n",
      "Epoch 493, Loss: 0.45086488127708435, Final Batch Loss: 0.2622395157814026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494, Loss: 0.3706824332475662, Final Batch Loss: 0.18981927633285522\n",
      "Epoch 495, Loss: 0.3963233679533005, Final Batch Loss: 0.20307476818561554\n",
      "Epoch 496, Loss: 0.37290674448013306, Final Batch Loss: 0.20622912049293518\n",
      "Epoch 497, Loss: 0.36939921975135803, Final Batch Loss: 0.16852693259716034\n",
      "Epoch 498, Loss: 0.4657554626464844, Final Batch Loss: 0.2956545054912567\n",
      "Epoch 499, Loss: 0.4020984023809433, Final Batch Loss: 0.19155602157115936\n",
      "Epoch 500, Loss: 0.3644197881221771, Final Batch Loss: 0.18413835763931274\n",
      "Epoch 501, Loss: 0.3889175355434418, Final Batch Loss: 0.21248821914196014\n",
      "Epoch 502, Loss: 0.38314560055732727, Final Batch Loss: 0.20006249845027924\n",
      "Epoch 503, Loss: 0.3846203237771988, Final Batch Loss: 0.177102193236351\n",
      "Epoch 504, Loss: 0.39729154109954834, Final Batch Loss: 0.1759689897298813\n",
      "Epoch 505, Loss: 0.42056845128536224, Final Batch Loss: 0.23509497940540314\n",
      "Epoch 506, Loss: 0.38759854435920715, Final Batch Loss: 0.19140522181987762\n",
      "Epoch 507, Loss: 0.4034382551908493, Final Batch Loss: 0.23251645267009735\n",
      "Epoch 508, Loss: 0.3439978212118149, Final Batch Loss: 0.1490965187549591\n",
      "Epoch 509, Loss: 0.442867711186409, Final Batch Loss: 0.21411892771720886\n",
      "Epoch 510, Loss: 0.3748881071805954, Final Batch Loss: 0.17205239832401276\n",
      "Epoch 511, Loss: 0.40015245974063873, Final Batch Loss: 0.2206047922372818\n",
      "Epoch 512, Loss: 0.38880953192710876, Final Batch Loss: 0.2108970582485199\n",
      "Epoch 513, Loss: 0.35207049548625946, Final Batch Loss: 0.18474480509757996\n",
      "Epoch 514, Loss: 0.37745508551597595, Final Batch Loss: 0.18340566754341125\n",
      "Epoch 515, Loss: 0.3542333096265793, Final Batch Loss: 0.16328197717666626\n",
      "Epoch 516, Loss: 0.3692759573459625, Final Batch Loss: 0.1938323974609375\n",
      "Epoch 517, Loss: 0.3674548417329788, Final Batch Loss: 0.1498178392648697\n",
      "Epoch 518, Loss: 0.3405715823173523, Final Batch Loss: 0.1503862738609314\n",
      "Epoch 519, Loss: 0.37229982018470764, Final Batch Loss: 0.16008776426315308\n",
      "Epoch 520, Loss: 0.3449437767267227, Final Batch Loss: 0.1650356948375702\n",
      "Epoch 521, Loss: 0.3781667798757553, Final Batch Loss: 0.19638630747795105\n",
      "Epoch 522, Loss: 0.3758454918861389, Final Batch Loss: 0.1451457291841507\n",
      "Epoch 523, Loss: 0.3813222795724869, Final Batch Loss: 0.2151317447423935\n",
      "Epoch 524, Loss: 0.3759539872407913, Final Batch Loss: 0.1984758824110031\n",
      "Epoch 525, Loss: 0.3283614218235016, Final Batch Loss: 0.1337205171585083\n",
      "Epoch 526, Loss: 0.39415405690670013, Final Batch Loss: 0.18504032492637634\n",
      "Epoch 527, Loss: 0.3843084126710892, Final Batch Loss: 0.20681127905845642\n",
      "Epoch 528, Loss: 0.3833523392677307, Final Batch Loss: 0.17492781579494476\n",
      "Epoch 529, Loss: 0.36100374162197113, Final Batch Loss: 0.1785898208618164\n",
      "Epoch 530, Loss: 0.43420395255088806, Final Batch Loss: 0.25239965319633484\n",
      "Epoch 531, Loss: 0.3758358806371689, Final Batch Loss: 0.2019766867160797\n",
      "Epoch 532, Loss: 0.3489265590906143, Final Batch Loss: 0.19187165796756744\n",
      "Epoch 533, Loss: 0.3673461824655533, Final Batch Loss: 0.19983355700969696\n",
      "Epoch 534, Loss: 0.36591053009033203, Final Batch Loss: 0.18181867897510529\n",
      "Epoch 535, Loss: 0.3650951087474823, Final Batch Loss: 0.20029842853546143\n",
      "Epoch 536, Loss: 0.34373368322849274, Final Batch Loss: 0.17356528341770172\n",
      "Epoch 537, Loss: 0.3585888296365738, Final Batch Loss: 0.19483810663223267\n",
      "Epoch 538, Loss: 0.30321548879146576, Final Batch Loss: 0.1555805206298828\n",
      "Epoch 539, Loss: 0.44969697296619415, Final Batch Loss: 0.26357904076576233\n",
      "Epoch 540, Loss: 0.35914070904254913, Final Batch Loss: 0.17140483856201172\n",
      "Epoch 541, Loss: 0.3483857810497284, Final Batch Loss: 0.15360672771930695\n",
      "Epoch 542, Loss: 0.4145883768796921, Final Batch Loss: 0.1972731500864029\n",
      "Epoch 543, Loss: 0.40519243478775024, Final Batch Loss: 0.2233714759349823\n",
      "Epoch 544, Loss: 0.3631552904844284, Final Batch Loss: 0.16757142543792725\n",
      "Epoch 545, Loss: 0.37787197530269623, Final Batch Loss: 0.2114839255809784\n",
      "Epoch 546, Loss: 0.3590777963399887, Final Batch Loss: 0.1474185436964035\n",
      "Epoch 547, Loss: 0.36377593874931335, Final Batch Loss: 0.17038193345069885\n",
      "Epoch 548, Loss: 0.33396880328655243, Final Batch Loss: 0.15536019206047058\n",
      "Epoch 549, Loss: 0.36406800150871277, Final Batch Loss: 0.18519878387451172\n",
      "Epoch 550, Loss: 0.38185761868953705, Final Batch Loss: 0.21716095507144928\n",
      "Epoch 551, Loss: 0.3877132534980774, Final Batch Loss: 0.2198602557182312\n",
      "Epoch 552, Loss: 0.3512903302907944, Final Batch Loss: 0.19235900044441223\n",
      "Epoch 553, Loss: 0.33827680349349976, Final Batch Loss: 0.17231586575508118\n",
      "Epoch 554, Loss: 0.35619083046913147, Final Batch Loss: 0.13299214839935303\n",
      "Epoch 555, Loss: 0.35854633152484894, Final Batch Loss: 0.14116571843624115\n",
      "Epoch 556, Loss: 0.35680800676345825, Final Batch Loss: 0.19770869612693787\n",
      "Epoch 557, Loss: 0.36274950206279755, Final Batch Loss: 0.16408760845661163\n",
      "Epoch 558, Loss: 0.3516695350408554, Final Batch Loss: 0.16393564641475677\n",
      "Epoch 559, Loss: 0.3266502618789673, Final Batch Loss: 0.16591820120811462\n",
      "Epoch 560, Loss: 0.3362227529287338, Final Batch Loss: 0.14552901685237885\n",
      "Epoch 561, Loss: 0.3529558777809143, Final Batch Loss: 0.20787836611270905\n",
      "Epoch 562, Loss: 0.3922266960144043, Final Batch Loss: 0.19804924726486206\n",
      "Epoch 563, Loss: 0.27655933797359467, Final Batch Loss: 0.10886132717132568\n",
      "Epoch 564, Loss: 0.3622395098209381, Final Batch Loss: 0.18402770161628723\n",
      "Epoch 565, Loss: 0.3659902960062027, Final Batch Loss: 0.18032243847846985\n",
      "Epoch 566, Loss: 0.387240469455719, Final Batch Loss: 0.1826869547367096\n",
      "Epoch 567, Loss: 0.33536501228809357, Final Batch Loss: 0.14614956080913544\n",
      "Epoch 568, Loss: 0.35989536345005035, Final Batch Loss: 0.1890040785074234\n",
      "Epoch 569, Loss: 0.3281795084476471, Final Batch Loss: 0.1633252501487732\n",
      "Epoch 570, Loss: 0.33534543216228485, Final Batch Loss: 0.18312521278858185\n",
      "Epoch 571, Loss: 0.33337874710559845, Final Batch Loss: 0.1624607890844345\n",
      "Epoch 572, Loss: 0.39302264153957367, Final Batch Loss: 0.18803806602954865\n",
      "Epoch 573, Loss: 0.3452157825231552, Final Batch Loss: 0.18956369161605835\n",
      "Epoch 574, Loss: 0.3548247367143631, Final Batch Loss: 0.15037952363491058\n",
      "Epoch 575, Loss: 0.34420129656791687, Final Batch Loss: 0.197554349899292\n",
      "Epoch 576, Loss: 0.34919290244579315, Final Batch Loss: 0.17195910215377808\n",
      "Epoch 577, Loss: 0.30407220125198364, Final Batch Loss: 0.13821175694465637\n",
      "Epoch 578, Loss: 0.3262960612773895, Final Batch Loss: 0.1516839861869812\n",
      "Epoch 579, Loss: 0.34517811238765717, Final Batch Loss: 0.19264636933803558\n",
      "Epoch 580, Loss: 0.31753963232040405, Final Batch Loss: 0.13814766705036163\n",
      "Epoch 581, Loss: 0.3323785215616226, Final Batch Loss: 0.1666622757911682\n",
      "Epoch 582, Loss: 0.3478239178657532, Final Batch Loss: 0.17821994423866272\n",
      "Epoch 583, Loss: 0.3803451955318451, Final Batch Loss: 0.180339515209198\n",
      "Epoch 584, Loss: 0.3281109929084778, Final Batch Loss: 0.18394404649734497\n",
      "Epoch 585, Loss: 0.3209693282842636, Final Batch Loss: 0.1510089784860611\n",
      "Epoch 586, Loss: 0.37697452306747437, Final Batch Loss: 0.20001782476902008\n",
      "Epoch 587, Loss: 0.3980511873960495, Final Batch Loss: 0.2183811515569687\n",
      "Epoch 588, Loss: 0.35889796912670135, Final Batch Loss: 0.19096674025058746\n",
      "Epoch 589, Loss: 0.32570140063762665, Final Batch Loss: 0.15213750302791595\n",
      "Epoch 590, Loss: 0.3049955666065216, Final Batch Loss: 0.15961866080760956\n",
      "Epoch 591, Loss: 0.30436623096466064, Final Batch Loss: 0.15103685855865479\n",
      "Epoch 592, Loss: 0.3120872676372528, Final Batch Loss: 0.1355423480272293\n",
      "Epoch 593, Loss: 0.3546039015054703, Final Batch Loss: 0.1724814772605896\n",
      "Epoch 594, Loss: 0.34659504890441895, Final Batch Loss: 0.16661971807479858\n",
      "Epoch 595, Loss: 0.36252714693546295, Final Batch Loss: 0.17403993010520935\n",
      "Epoch 596, Loss: 0.35362814366817474, Final Batch Loss: 0.19516606628894806\n",
      "Epoch 597, Loss: 0.31476356089115143, Final Batch Loss: 0.1522105187177658\n",
      "Epoch 598, Loss: 0.2832755595445633, Final Batch Loss: 0.1185830682516098\n",
      "Epoch 599, Loss: 0.38189975917339325, Final Batch Loss: 0.19610968232154846\n",
      "Epoch 600, Loss: 0.34037886559963226, Final Batch Loss: 0.1705932468175888\n",
      "Epoch 601, Loss: 0.2882320135831833, Final Batch Loss: 0.13068577647209167\n",
      "Epoch 602, Loss: 0.29756391048431396, Final Batch Loss: 0.14785455167293549\n",
      "Epoch 603, Loss: 0.32737457752227783, Final Batch Loss: 0.11042746901512146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 604, Loss: 0.3525819480419159, Final Batch Loss: 0.15506979823112488\n",
      "Epoch 605, Loss: 0.30288155376911163, Final Batch Loss: 0.13524819910526276\n",
      "Epoch 606, Loss: 0.3209088295698166, Final Batch Loss: 0.14285403490066528\n",
      "Epoch 607, Loss: 0.36266323924064636, Final Batch Loss: 0.1524030864238739\n",
      "Epoch 608, Loss: 0.35389216244220734, Final Batch Loss: 0.17641785740852356\n",
      "Epoch 609, Loss: 0.2954375147819519, Final Batch Loss: 0.12517763674259186\n",
      "Epoch 610, Loss: 0.35070548951625824, Final Batch Loss: 0.2150610238313675\n",
      "Epoch 611, Loss: 0.3150824308395386, Final Batch Loss: 0.12345224618911743\n",
      "Epoch 612, Loss: 0.3350284695625305, Final Batch Loss: 0.19252151250839233\n",
      "Epoch 613, Loss: 0.3422587215900421, Final Batch Loss: 0.18770989775657654\n",
      "Epoch 614, Loss: 0.3842158615589142, Final Batch Loss: 0.22950950264930725\n",
      "Epoch 615, Loss: 0.29922372102737427, Final Batch Loss: 0.13649994134902954\n",
      "Epoch 616, Loss: 0.32601866126060486, Final Batch Loss: 0.15650789439678192\n",
      "Epoch 617, Loss: 0.30661314725875854, Final Batch Loss: 0.1495531052350998\n",
      "Epoch 618, Loss: 0.3307593911886215, Final Batch Loss: 0.1656690090894699\n",
      "Epoch 619, Loss: 0.28607673943042755, Final Batch Loss: 0.14072585105895996\n",
      "Epoch 620, Loss: 0.33328284323215485, Final Batch Loss: 0.1887618452310562\n",
      "Epoch 621, Loss: 0.3322724401950836, Final Batch Loss: 0.15312327444553375\n",
      "Epoch 622, Loss: 0.34995365142822266, Final Batch Loss: 0.16503828763961792\n",
      "Epoch 623, Loss: 0.30956728756427765, Final Batch Loss: 0.16018404066562653\n",
      "Epoch 624, Loss: 0.3326118439435959, Final Batch Loss: 0.16962452232837677\n",
      "Epoch 625, Loss: 0.28237318247556686, Final Batch Loss: 0.11695938557386398\n",
      "Epoch 626, Loss: 0.34195931255817413, Final Batch Loss: 0.18371202051639557\n",
      "Epoch 627, Loss: 0.341355636715889, Final Batch Loss: 0.17438620328903198\n",
      "Epoch 628, Loss: 0.3717406839132309, Final Batch Loss: 0.17920391261577606\n",
      "Epoch 629, Loss: 0.2822730094194412, Final Batch Loss: 0.1461530178785324\n",
      "Epoch 630, Loss: 0.2931595891714096, Final Batch Loss: 0.15581567585468292\n",
      "Epoch 631, Loss: 0.32601042091846466, Final Batch Loss: 0.16832922399044037\n",
      "Epoch 632, Loss: 0.3175526112318039, Final Batch Loss: 0.16652923822402954\n",
      "Epoch 633, Loss: 0.28938696533441544, Final Batch Loss: 0.11642765253782272\n",
      "Epoch 634, Loss: 0.28293347358703613, Final Batch Loss: 0.13841499388217926\n",
      "Epoch 635, Loss: 0.3056727349758148, Final Batch Loss: 0.17553770542144775\n",
      "Epoch 636, Loss: 0.32647983729839325, Final Batch Loss: 0.17515386641025543\n",
      "Epoch 637, Loss: 0.2611183077096939, Final Batch Loss: 0.08612528443336487\n",
      "Epoch 638, Loss: 0.3040185123682022, Final Batch Loss: 0.1110837459564209\n",
      "Epoch 639, Loss: 0.32896773517131805, Final Batch Loss: 0.17854174971580505\n",
      "Epoch 640, Loss: 0.2757040560245514, Final Batch Loss: 0.14199642837047577\n",
      "Epoch 641, Loss: 0.27012675255537033, Final Batch Loss: 0.10659082978963852\n",
      "Epoch 642, Loss: 0.279853880405426, Final Batch Loss: 0.13723549246788025\n",
      "Epoch 643, Loss: 0.26666728407144547, Final Batch Loss: 0.1441626250743866\n",
      "Epoch 644, Loss: 0.3250492215156555, Final Batch Loss: 0.15792781114578247\n",
      "Epoch 645, Loss: 0.32822106778621674, Final Batch Loss: 0.21546056866645813\n",
      "Epoch 646, Loss: 0.27365758270025253, Final Batch Loss: 0.09954487532377243\n",
      "Epoch 647, Loss: 0.30835282802581787, Final Batch Loss: 0.15849967300891876\n",
      "Epoch 648, Loss: 0.28415247797966003, Final Batch Loss: 0.1378992646932602\n",
      "Epoch 649, Loss: 0.28684042394161224, Final Batch Loss: 0.14505566656589508\n",
      "Epoch 650, Loss: 0.302307590842247, Final Batch Loss: 0.13509558141231537\n",
      "Epoch 651, Loss: 0.33449822664260864, Final Batch Loss: 0.13024267554283142\n",
      "Epoch 652, Loss: 0.29112696647644043, Final Batch Loss: 0.12961937487125397\n",
      "Epoch 653, Loss: 0.269662544131279, Final Batch Loss: 0.14334236085414886\n",
      "Epoch 654, Loss: 0.3305126428604126, Final Batch Loss: 0.12274913489818573\n",
      "Epoch 655, Loss: 0.26088374853134155, Final Batch Loss: 0.1354878693819046\n",
      "Epoch 656, Loss: 0.322637602686882, Final Batch Loss: 0.174361452460289\n",
      "Epoch 657, Loss: 0.29349781572818756, Final Batch Loss: 0.14314182102680206\n",
      "Epoch 658, Loss: 0.28405363857746124, Final Batch Loss: 0.11707988381385803\n",
      "Epoch 659, Loss: 0.33315257728099823, Final Batch Loss: 0.1934596449136734\n",
      "Epoch 660, Loss: 0.3492698147892952, Final Batch Loss: 0.2373402714729309\n",
      "Epoch 661, Loss: 0.3022245019674301, Final Batch Loss: 0.15429292619228363\n",
      "Epoch 662, Loss: 0.30856903642416, Final Batch Loss: 0.18778963387012482\n",
      "Epoch 663, Loss: 0.29639895260334015, Final Batch Loss: 0.16386526823043823\n",
      "Epoch 664, Loss: 0.2848467156291008, Final Batch Loss: 0.1741136610507965\n",
      "Epoch 665, Loss: 0.31823641061782837, Final Batch Loss: 0.13819962739944458\n",
      "Epoch 666, Loss: 0.3095736652612686, Final Batch Loss: 0.13298040628433228\n",
      "Epoch 667, Loss: 0.2956525385379791, Final Batch Loss: 0.1535489410161972\n",
      "Epoch 668, Loss: 0.2885092571377754, Final Batch Loss: 0.10847633332014084\n",
      "Epoch 669, Loss: 0.35185277462005615, Final Batch Loss: 0.1704232096672058\n",
      "Epoch 670, Loss: 0.2632269859313965, Final Batch Loss: 0.1290380358695984\n",
      "Epoch 671, Loss: 0.325697585940361, Final Batch Loss: 0.18011260032653809\n",
      "Epoch 672, Loss: 0.2807294875383377, Final Batch Loss: 0.14831894636154175\n",
      "Epoch 673, Loss: 0.2714596390724182, Final Batch Loss: 0.14033730328083038\n",
      "Epoch 674, Loss: 0.2816201001405716, Final Batch Loss: 0.15071389079093933\n",
      "Epoch 675, Loss: 0.3246449679136276, Final Batch Loss: 0.17226436734199524\n",
      "Epoch 676, Loss: 0.27573953568935394, Final Batch Loss: 0.14166224002838135\n",
      "Epoch 677, Loss: 0.3181924372911453, Final Batch Loss: 0.16499890387058258\n",
      "Epoch 678, Loss: 0.2714635878801346, Final Batch Loss: 0.1399690955877304\n",
      "Epoch 679, Loss: 0.27919769287109375, Final Batch Loss: 0.13941775262355804\n",
      "Epoch 680, Loss: 0.3070825934410095, Final Batch Loss: 0.14496535062789917\n",
      "Epoch 681, Loss: 0.2966777831315994, Final Batch Loss: 0.1587333083152771\n",
      "Epoch 682, Loss: 0.301037922501564, Final Batch Loss: 0.15404464304447174\n",
      "Epoch 683, Loss: 0.3527655750513077, Final Batch Loss: 0.21874625980854034\n",
      "Epoch 684, Loss: 0.27904702723026276, Final Batch Loss: 0.13012218475341797\n",
      "Epoch 685, Loss: 0.27857348322868347, Final Batch Loss: 0.1420830637216568\n",
      "Epoch 686, Loss: 0.2929654121398926, Final Batch Loss: 0.15056781470775604\n",
      "Epoch 687, Loss: 0.25089336186647415, Final Batch Loss: 0.10807997733354568\n",
      "Epoch 688, Loss: 0.2669311687350273, Final Batch Loss: 0.10871555656194687\n",
      "Epoch 689, Loss: 0.3170805275440216, Final Batch Loss: 0.16828159987926483\n",
      "Epoch 690, Loss: 0.2554119825363159, Final Batch Loss: 0.13081501424312592\n",
      "Epoch 691, Loss: 0.2688058093190193, Final Batch Loss: 0.15681251883506775\n",
      "Epoch 692, Loss: 0.3070766031742096, Final Batch Loss: 0.149636372923851\n",
      "Epoch 693, Loss: 0.2920118123292923, Final Batch Loss: 0.13449904322624207\n",
      "Epoch 694, Loss: 0.31440840661525726, Final Batch Loss: 0.1372838169336319\n",
      "Epoch 695, Loss: 0.25559794902801514, Final Batch Loss: 0.10737359523773193\n",
      "Epoch 696, Loss: 0.33439840376377106, Final Batch Loss: 0.18669293820858002\n",
      "Epoch 697, Loss: 0.2872820198535919, Final Batch Loss: 0.14367283880710602\n",
      "Epoch 698, Loss: 0.24835271388292313, Final Batch Loss: 0.11225908249616623\n",
      "Epoch 699, Loss: 0.27519725263118744, Final Batch Loss: 0.14365798234939575\n",
      "Epoch 700, Loss: 0.2808731347322464, Final Batch Loss: 0.13315431773662567\n",
      "Epoch 701, Loss: 0.29149776697158813, Final Batch Loss: 0.14531758427619934\n",
      "Epoch 702, Loss: 0.26056432723999023, Final Batch Loss: 0.12993451952934265\n",
      "Epoch 703, Loss: 0.23984557390213013, Final Batch Loss: 0.11140468716621399\n",
      "Epoch 704, Loss: 0.33696727454662323, Final Batch Loss: 0.18842898309230804\n",
      "Epoch 705, Loss: 0.29215721786022186, Final Batch Loss: 0.14055685698986053\n",
      "Epoch 706, Loss: 0.28801385313272476, Final Batch Loss: 0.17385254800319672\n",
      "Epoch 707, Loss: 0.30951830744743347, Final Batch Loss: 0.19205477833747864\n",
      "Epoch 708, Loss: 0.2735873758792877, Final Batch Loss: 0.13701774179935455\n",
      "Epoch 709, Loss: 0.2978637143969536, Final Batch Loss: 0.17431829869747162\n",
      "Epoch 710, Loss: 0.27927301824092865, Final Batch Loss: 0.13546474277973175\n",
      "Epoch 711, Loss: 0.3165903612971306, Final Batch Loss: 0.21876735985279083\n",
      "Epoch 712, Loss: 0.2658226639032364, Final Batch Loss: 0.12345905601978302\n",
      "Epoch 713, Loss: 0.3024556040763855, Final Batch Loss: 0.13073459267616272\n",
      "Epoch 714, Loss: 0.2715364247560501, Final Batch Loss: 0.1275746375322342\n",
      "Epoch 715, Loss: 0.29067008197307587, Final Batch Loss: 0.1308509260416031\n",
      "Epoch 716, Loss: 0.28649844229221344, Final Batch Loss: 0.136918842792511\n",
      "Epoch 717, Loss: 0.3347024619579315, Final Batch Loss: 0.17792131006717682\n",
      "Epoch 718, Loss: 0.24914833903312683, Final Batch Loss: 0.13137322664260864\n",
      "Epoch 719, Loss: 0.2642269879579544, Final Batch Loss: 0.12324020266532898\n",
      "Epoch 720, Loss: 0.2531839609146118, Final Batch Loss: 0.12672916054725647\n",
      "Epoch 721, Loss: 0.27456000447273254, Final Batch Loss: 0.1293988823890686\n",
      "Epoch 722, Loss: 0.3026778846979141, Final Batch Loss: 0.17792776226997375\n",
      "Epoch 723, Loss: 0.2817966118454933, Final Batch Loss: 0.1786080151796341\n",
      "Epoch 724, Loss: 0.2996085286140442, Final Batch Loss: 0.1487044245004654\n",
      "Epoch 725, Loss: 0.29292309284210205, Final Batch Loss: 0.15454934537410736\n",
      "Epoch 726, Loss: 0.31432249397039413, Final Batch Loss: 0.22681036591529846\n",
      "Epoch 727, Loss: 0.2830159142613411, Final Batch Loss: 0.11269631236791611\n",
      "Epoch 728, Loss: 0.2632240131497383, Final Batch Loss: 0.15511561930179596\n",
      "Epoch 729, Loss: 0.26355238258838654, Final Batch Loss: 0.13722896575927734\n",
      "Epoch 730, Loss: 0.2893047630786896, Final Batch Loss: 0.15600194036960602\n",
      "Epoch 731, Loss: 0.2688957080245018, Final Batch Loss: 0.11502312868833542\n",
      "Epoch 732, Loss: 0.22990057617425919, Final Batch Loss: 0.08304715901613235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 733, Loss: 0.26707665622234344, Final Batch Loss: 0.12996454536914825\n",
      "Epoch 734, Loss: 0.253317691385746, Final Batch Loss: 0.10337250679731369\n",
      "Epoch 735, Loss: 0.2562730610370636, Final Batch Loss: 0.0943334698677063\n",
      "Epoch 736, Loss: 0.2792676314711571, Final Batch Loss: 0.17112046480178833\n",
      "Epoch 737, Loss: 0.21406736224889755, Final Batch Loss: 0.0974370613694191\n",
      "Epoch 738, Loss: 0.2803717106580734, Final Batch Loss: 0.13876566290855408\n",
      "Epoch 739, Loss: 0.21595121920108795, Final Batch Loss: 0.10088731348514557\n",
      "Epoch 740, Loss: 0.2436780333518982, Final Batch Loss: 0.1353820115327835\n",
      "Epoch 741, Loss: 0.23714083433151245, Final Batch Loss: 0.10668933391571045\n",
      "Epoch 742, Loss: 0.2812778949737549, Final Batch Loss: 0.15941862761974335\n",
      "Epoch 743, Loss: 0.24959320574998856, Final Batch Loss: 0.12596330046653748\n",
      "Epoch 744, Loss: 0.27305978536605835, Final Batch Loss: 0.12819607555866241\n",
      "Epoch 745, Loss: 0.2538590580224991, Final Batch Loss: 0.12824270129203796\n",
      "Epoch 746, Loss: 0.2636317312717438, Final Batch Loss: 0.12005293369293213\n",
      "Epoch 747, Loss: 0.28713907301425934, Final Batch Loss: 0.1579059660434723\n",
      "Epoch 748, Loss: 0.2662097290158272, Final Batch Loss: 0.11492376774549484\n",
      "Epoch 749, Loss: 0.25866060703992844, Final Batch Loss: 0.12171878665685654\n",
      "Epoch 750, Loss: 0.25745266675949097, Final Batch Loss: 0.13317584991455078\n",
      "Epoch 751, Loss: 0.2717302441596985, Final Batch Loss: 0.12988030910491943\n",
      "Epoch 752, Loss: 0.24127402901649475, Final Batch Loss: 0.110296830534935\n",
      "Epoch 753, Loss: 0.2266446352005005, Final Batch Loss: 0.094231978058815\n",
      "Epoch 754, Loss: 0.24070166796445847, Final Batch Loss: 0.14419743418693542\n",
      "Epoch 755, Loss: 0.2670891284942627, Final Batch Loss: 0.1172231137752533\n",
      "Epoch 756, Loss: 0.25321678817272186, Final Batch Loss: 0.12794607877731323\n",
      "Epoch 757, Loss: 0.22626567631959915, Final Batch Loss: 0.11226044595241547\n",
      "Epoch 758, Loss: 0.2564084231853485, Final Batch Loss: 0.14818093180656433\n",
      "Epoch 759, Loss: 0.24002093076705933, Final Batch Loss: 0.11416766047477722\n",
      "Epoch 760, Loss: 0.21103039383888245, Final Batch Loss: 0.09562109410762787\n",
      "Epoch 761, Loss: 0.2346637025475502, Final Batch Loss: 0.11254279315471649\n",
      "Epoch 762, Loss: 0.2411285862326622, Final Batch Loss: 0.11273955553770065\n",
      "Epoch 763, Loss: 0.24037951976060867, Final Batch Loss: 0.12952978909015656\n",
      "Epoch 764, Loss: 0.26647546142339706, Final Batch Loss: 0.14991097152233124\n",
      "Epoch 765, Loss: 0.2366122528910637, Final Batch Loss: 0.11013340204954147\n",
      "Epoch 766, Loss: 0.22896737605333328, Final Batch Loss: 0.13636885583400726\n",
      "Epoch 767, Loss: 0.24213698506355286, Final Batch Loss: 0.11792919039726257\n",
      "Epoch 768, Loss: 0.26504994183778763, Final Batch Loss: 0.14279299974441528\n",
      "Epoch 769, Loss: 0.21930015832185745, Final Batch Loss: 0.09481874853372574\n",
      "Epoch 770, Loss: 0.36082668602466583, Final Batch Loss: 0.2672092914581299\n",
      "Epoch 771, Loss: 0.2784736230969429, Final Batch Loss: 0.17254774272441864\n",
      "Epoch 772, Loss: 0.2744094356894493, Final Batch Loss: 0.17080029845237732\n",
      "Epoch 773, Loss: 0.2539273425936699, Final Batch Loss: 0.13697946071624756\n",
      "Epoch 774, Loss: 0.23858121037483215, Final Batch Loss: 0.12528634071350098\n",
      "Epoch 775, Loss: 0.2350776121020317, Final Batch Loss: 0.11816579103469849\n",
      "Epoch 776, Loss: 0.20768412202596664, Final Batch Loss: 0.0838233232498169\n",
      "Epoch 777, Loss: 0.22289709001779556, Final Batch Loss: 0.1034780889749527\n",
      "Epoch 778, Loss: 0.24731501936912537, Final Batch Loss: 0.1275956928730011\n",
      "Epoch 779, Loss: 0.22118058800697327, Final Batch Loss: 0.11437983810901642\n",
      "Epoch 780, Loss: 0.2504447028040886, Final Batch Loss: 0.12845391035079956\n",
      "Epoch 781, Loss: 0.22091607749462128, Final Batch Loss: 0.11034772545099258\n",
      "Epoch 782, Loss: 0.26890066266059875, Final Batch Loss: 0.14539581537246704\n",
      "Epoch 783, Loss: 0.2370442971587181, Final Batch Loss: 0.11081702262163162\n",
      "Epoch 784, Loss: 0.2078460082411766, Final Batch Loss: 0.09718581289052963\n",
      "Epoch 785, Loss: 0.24702809005975723, Final Batch Loss: 0.13087467849254608\n",
      "Epoch 786, Loss: 0.2708473205566406, Final Batch Loss: 0.1485307663679123\n",
      "Epoch 787, Loss: 0.2788075730204582, Final Batch Loss: 0.1612815409898758\n",
      "Epoch 788, Loss: 0.21995951235294342, Final Batch Loss: 0.07892285287380219\n",
      "Epoch 789, Loss: 0.21027033030986786, Final Batch Loss: 0.11352042853832245\n",
      "Epoch 790, Loss: 0.20761635154485703, Final Batch Loss: 0.10698027908802032\n",
      "Epoch 791, Loss: 0.24016453325748444, Final Batch Loss: 0.12776607275009155\n",
      "Epoch 792, Loss: 0.24102798849344254, Final Batch Loss: 0.11329241842031479\n",
      "Epoch 793, Loss: 0.27397139370441437, Final Batch Loss: 0.17666982114315033\n",
      "Epoch 794, Loss: 0.21003759652376175, Final Batch Loss: 0.0796646997332573\n",
      "Epoch 795, Loss: 0.2551680728793144, Final Batch Loss: 0.11068352311849594\n",
      "Epoch 796, Loss: 0.27916575223207474, Final Batch Loss: 0.10326658934354782\n",
      "Epoch 797, Loss: 0.2554616928100586, Final Batch Loss: 0.1525246948003769\n",
      "Epoch 798, Loss: 0.22994018346071243, Final Batch Loss: 0.10522951930761337\n",
      "Epoch 799, Loss: 0.2326759397983551, Final Batch Loss: 0.10250474512577057\n",
      "Epoch 800, Loss: 0.20797283202409744, Final Batch Loss: 0.09088893979787827\n",
      "Epoch 801, Loss: 0.2549731209874153, Final Batch Loss: 0.11357984691858292\n",
      "Epoch 802, Loss: 0.2210749238729477, Final Batch Loss: 0.11529961228370667\n",
      "Epoch 803, Loss: 0.24928484112024307, Final Batch Loss: 0.09976381808519363\n",
      "Epoch 804, Loss: 0.2686261683702469, Final Batch Loss: 0.1270381361246109\n",
      "Epoch 805, Loss: 0.19671611487865448, Final Batch Loss: 0.08638106286525726\n",
      "Epoch 806, Loss: 0.1844501718878746, Final Batch Loss: 0.06497646868228912\n",
      "Epoch 807, Loss: 0.2167763188481331, Final Batch Loss: 0.1051318570971489\n",
      "Epoch 808, Loss: 0.2644185572862625, Final Batch Loss: 0.1383974254131317\n",
      "Epoch 809, Loss: 0.2206900492310524, Final Batch Loss: 0.0899951383471489\n",
      "Epoch 810, Loss: 0.23452196270227432, Final Batch Loss: 0.10579284280538559\n",
      "Epoch 811, Loss: 0.22283007204532623, Final Batch Loss: 0.07644425332546234\n",
      "Epoch 812, Loss: 0.21812975406646729, Final Batch Loss: 0.10198922455310822\n",
      "Epoch 813, Loss: 0.2721148356795311, Final Batch Loss: 0.17987684905529022\n",
      "Epoch 814, Loss: 0.2160605862736702, Final Batch Loss: 0.11690982431173325\n",
      "Epoch 815, Loss: 0.21805914491415024, Final Batch Loss: 0.09063222259283066\n",
      "Epoch 816, Loss: 0.2357908934354782, Final Batch Loss: 0.11336600035429001\n",
      "Epoch 817, Loss: 0.208171546459198, Final Batch Loss: 0.09826548397541046\n",
      "Epoch 818, Loss: 0.2029038593173027, Final Batch Loss: 0.0852246880531311\n",
      "Epoch 819, Loss: 0.2351619303226471, Final Batch Loss: 0.12088440358638763\n",
      "Epoch 820, Loss: 0.22806650400161743, Final Batch Loss: 0.10164505243301392\n",
      "Epoch 821, Loss: 0.3083033487200737, Final Batch Loss: 0.19578544795513153\n",
      "Epoch 822, Loss: 0.22284919768571854, Final Batch Loss: 0.13055701553821564\n",
      "Epoch 823, Loss: 0.2634369283914566, Final Batch Loss: 0.13178738951683044\n",
      "Epoch 824, Loss: 0.2091558426618576, Final Batch Loss: 0.09054221957921982\n",
      "Epoch 825, Loss: 0.18135817348957062, Final Batch Loss: 0.07594703137874603\n",
      "Epoch 826, Loss: 0.23102007806301117, Final Batch Loss: 0.11908939480781555\n",
      "Epoch 827, Loss: 0.23162535578012466, Final Batch Loss: 0.11168600618839264\n",
      "Epoch 828, Loss: 0.2330082654953003, Final Batch Loss: 0.11685033142566681\n",
      "Epoch 829, Loss: 0.25332754105329514, Final Batch Loss: 0.15326012670993805\n",
      "Epoch 830, Loss: 0.20532630383968353, Final Batch Loss: 0.08706298470497131\n",
      "Epoch 831, Loss: 0.40318284928798676, Final Batch Loss: 0.26387888193130493\n",
      "Epoch 832, Loss: 0.22345534712076187, Final Batch Loss: 0.09792136400938034\n",
      "Epoch 833, Loss: 0.2041022703051567, Final Batch Loss: 0.08219364285469055\n",
      "Epoch 834, Loss: 0.27298589050769806, Final Batch Loss: 0.13279424607753754\n",
      "Epoch 835, Loss: 0.2640124410390854, Final Batch Loss: 0.14870896935462952\n",
      "Epoch 836, Loss: 0.2182702273130417, Final Batch Loss: 0.08814951777458191\n",
      "Epoch 837, Loss: 0.2237435206770897, Final Batch Loss: 0.11608471721410751\n",
      "Epoch 838, Loss: 0.23447637259960175, Final Batch Loss: 0.11782892793416977\n",
      "Epoch 839, Loss: 0.20445480197668076, Final Batch Loss: 0.09848181158304214\n",
      "Epoch 840, Loss: 0.19533632695674896, Final Batch Loss: 0.08597494661808014\n",
      "Epoch 841, Loss: 0.20213916897773743, Final Batch Loss: 0.09473433345556259\n",
      "Epoch 842, Loss: 0.20130998641252518, Final Batch Loss: 0.09563916176557541\n",
      "Epoch 843, Loss: 0.19943425059318542, Final Batch Loss: 0.10184254497289658\n",
      "Epoch 844, Loss: 0.29964131116867065, Final Batch Loss: 0.1711149662733078\n",
      "Epoch 845, Loss: 0.24883809685707092, Final Batch Loss: 0.16840733587741852\n",
      "Epoch 846, Loss: 0.1970435455441475, Final Batch Loss: 0.08948047459125519\n",
      "Epoch 847, Loss: 0.20516549795866013, Final Batch Loss: 0.09146226197481155\n",
      "Epoch 848, Loss: 0.23516934365034103, Final Batch Loss: 0.12459565699100494\n",
      "Epoch 849, Loss: 0.19778678566217422, Final Batch Loss: 0.08378161489963531\n",
      "Epoch 850, Loss: 0.20869719982147217, Final Batch Loss: 0.08341796696186066\n",
      "Epoch 851, Loss: 0.22590996325016022, Final Batch Loss: 0.13359837234020233\n",
      "Epoch 852, Loss: 0.19959750771522522, Final Batch Loss: 0.10507331788539886\n",
      "Epoch 853, Loss: 0.23579644411802292, Final Batch Loss: 0.13110744953155518\n",
      "Epoch 854, Loss: 0.21369782090187073, Final Batch Loss: 0.12970268726348877\n",
      "Epoch 855, Loss: 0.22477316111326218, Final Batch Loss: 0.09873401373624802\n",
      "Epoch 856, Loss: 0.2570623755455017, Final Batch Loss: 0.10991790890693665\n",
      "Epoch 857, Loss: 0.190471850335598, Final Batch Loss: 0.102336585521698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 858, Loss: 0.25291359424591064, Final Batch Loss: 0.1319657266139984\n",
      "Epoch 859, Loss: 0.1974189653992653, Final Batch Loss: 0.0836910605430603\n",
      "Epoch 860, Loss: 0.23894745856523514, Final Batch Loss: 0.12077092379331589\n",
      "Epoch 861, Loss: 0.19647366553544998, Final Batch Loss: 0.10064621269702911\n",
      "Epoch 862, Loss: 0.2999144718050957, Final Batch Loss: 0.18923072516918182\n",
      "Epoch 863, Loss: 0.23387786746025085, Final Batch Loss: 0.13133344054222107\n",
      "Epoch 864, Loss: 0.19197072833776474, Final Batch Loss: 0.07766389101743698\n",
      "Epoch 865, Loss: 0.22509749233722687, Final Batch Loss: 0.13730613887310028\n",
      "Epoch 866, Loss: 0.2290695384144783, Final Batch Loss: 0.09591811150312424\n",
      "Epoch 867, Loss: 0.19993556290864944, Final Batch Loss: 0.09505319595336914\n",
      "Epoch 868, Loss: 0.2625061795115471, Final Batch Loss: 0.1716901659965515\n",
      "Epoch 869, Loss: 0.2025671824812889, Final Batch Loss: 0.09248373657464981\n",
      "Epoch 870, Loss: 0.23915699124336243, Final Batch Loss: 0.15926192700862885\n",
      "Epoch 871, Loss: 0.22573485225439072, Final Batch Loss: 0.11429811269044876\n",
      "Epoch 872, Loss: 0.23822467029094696, Final Batch Loss: 0.11107797920703888\n",
      "Epoch 873, Loss: 0.2041512429714203, Final Batch Loss: 0.0913686454296112\n",
      "Epoch 874, Loss: 0.23669560253620148, Final Batch Loss: 0.11663908511400223\n",
      "Epoch 875, Loss: 0.23230210691690445, Final Batch Loss: 0.13314594328403473\n",
      "Epoch 876, Loss: 0.2153676375746727, Final Batch Loss: 0.10614332556724548\n",
      "Epoch 877, Loss: 0.2204180806875229, Final Batch Loss: 0.1242886409163475\n",
      "Epoch 878, Loss: 0.18350274115800858, Final Batch Loss: 0.09104305505752563\n",
      "Epoch 879, Loss: 0.22418361902236938, Final Batch Loss: 0.12970395386219025\n",
      "Epoch 880, Loss: 0.23457691818475723, Final Batch Loss: 0.12408430874347687\n",
      "Epoch 881, Loss: 0.2143562287092209, Final Batch Loss: 0.11802151054143906\n",
      "Epoch 882, Loss: 0.19078414142131805, Final Batch Loss: 0.11534133553504944\n",
      "Epoch 883, Loss: 0.186883807182312, Final Batch Loss: 0.08380085974931717\n",
      "Epoch 884, Loss: 0.1704331934452057, Final Batch Loss: 0.0788663700222969\n",
      "Epoch 885, Loss: 0.2463477998971939, Final Batch Loss: 0.11652296781539917\n",
      "Epoch 886, Loss: 0.1981501206755638, Final Batch Loss: 0.08063100278377533\n",
      "Epoch 887, Loss: 0.22431600838899612, Final Batch Loss: 0.09715039283037186\n",
      "Epoch 888, Loss: 0.21042919158935547, Final Batch Loss: 0.09871609508991241\n",
      "Epoch 889, Loss: 0.22354904562234879, Final Batch Loss: 0.13260625302791595\n",
      "Epoch 890, Loss: 0.20648354291915894, Final Batch Loss: 0.09984846413135529\n",
      "Epoch 891, Loss: 0.20622266829013824, Final Batch Loss: 0.10592656582593918\n",
      "Epoch 892, Loss: 0.21823427826166153, Final Batch Loss: 0.1204066053032875\n",
      "Epoch 893, Loss: 0.18136343359947205, Final Batch Loss: 0.10185331106185913\n",
      "Epoch 894, Loss: 0.21628724038600922, Final Batch Loss: 0.1398129165172577\n",
      "Epoch 895, Loss: 0.20191650092601776, Final Batch Loss: 0.10513735562562943\n",
      "Epoch 896, Loss: 0.15091679245233536, Final Batch Loss: 0.05074964463710785\n",
      "Epoch 897, Loss: 0.18451479822397232, Final Batch Loss: 0.0635666698217392\n",
      "Epoch 898, Loss: 0.21889495849609375, Final Batch Loss: 0.11426996439695358\n",
      "Epoch 899, Loss: 0.2117702215909958, Final Batch Loss: 0.1327039748430252\n",
      "Epoch 900, Loss: 0.1924145519733429, Final Batch Loss: 0.08751969039440155\n",
      "Epoch 901, Loss: 0.19294214993715286, Final Batch Loss: 0.06632284075021744\n",
      "Epoch 902, Loss: 0.20847217738628387, Final Batch Loss: 0.10787376016378403\n",
      "Epoch 903, Loss: 0.24753030389547348, Final Batch Loss: 0.11757474392652512\n",
      "Epoch 904, Loss: 0.20719031244516373, Final Batch Loss: 0.07196333259344101\n",
      "Epoch 905, Loss: 0.22173482924699783, Final Batch Loss: 0.13395541906356812\n",
      "Epoch 906, Loss: 0.2676331400871277, Final Batch Loss: 0.14175547659397125\n",
      "Epoch 907, Loss: 0.22686633467674255, Final Batch Loss: 0.10129176080226898\n",
      "Epoch 908, Loss: 0.2555084154009819, Final Batch Loss: 0.15285247564315796\n",
      "Epoch 909, Loss: 0.21300102025270462, Final Batch Loss: 0.1122371256351471\n",
      "Epoch 910, Loss: 0.17144615575671196, Final Batch Loss: 0.05987809970974922\n",
      "Epoch 911, Loss: 0.1887008249759674, Final Batch Loss: 0.08815949410200119\n",
      "Epoch 912, Loss: 0.1794508546590805, Final Batch Loss: 0.06721417605876923\n",
      "Epoch 913, Loss: 0.16739073395729065, Final Batch Loss: 0.06528288125991821\n",
      "Epoch 914, Loss: 0.18375496566295624, Final Batch Loss: 0.08385509252548218\n",
      "Epoch 915, Loss: 0.1906384453177452, Final Batch Loss: 0.10320572555065155\n",
      "Epoch 916, Loss: 0.21706825494766235, Final Batch Loss: 0.10013159364461899\n",
      "Epoch 917, Loss: 0.1669081300497055, Final Batch Loss: 0.06763329356908798\n",
      "Epoch 918, Loss: 0.20420453697443008, Final Batch Loss: 0.07770421355962753\n",
      "Epoch 919, Loss: 0.22072339057922363, Final Batch Loss: 0.10402301698923111\n",
      "Epoch 920, Loss: 0.22589457035064697, Final Batch Loss: 0.12012285739183426\n",
      "Epoch 921, Loss: 0.26090459525585175, Final Batch Loss: 0.14902538061141968\n",
      "Epoch 922, Loss: 0.22019018232822418, Final Batch Loss: 0.14056390523910522\n",
      "Epoch 923, Loss: 0.16795118898153305, Final Batch Loss: 0.07786588370800018\n",
      "Epoch 924, Loss: 0.20809650421142578, Final Batch Loss: 0.09298983961343765\n",
      "Epoch 925, Loss: 0.22963117808103561, Final Batch Loss: 0.11072146147489548\n",
      "Epoch 926, Loss: 0.23169808089733124, Final Batch Loss: 0.11863800138235092\n",
      "Epoch 927, Loss: 0.206959530711174, Final Batch Loss: 0.10493659973144531\n",
      "Epoch 928, Loss: 0.254249669611454, Final Batch Loss: 0.15254828333854675\n",
      "Epoch 929, Loss: 0.1914861798286438, Final Batch Loss: 0.08168884366750717\n",
      "Epoch 930, Loss: 0.1892029047012329, Final Batch Loss: 0.07244444638490677\n",
      "Epoch 931, Loss: 0.1937573477625847, Final Batch Loss: 0.09467071294784546\n",
      "Epoch 932, Loss: 0.17958122491836548, Final Batch Loss: 0.08716633915901184\n",
      "Epoch 933, Loss: 0.2625872939825058, Final Batch Loss: 0.12793900072574615\n",
      "Epoch 934, Loss: 0.1992047354578972, Final Batch Loss: 0.11647133529186249\n",
      "Epoch 935, Loss: 0.19626539945602417, Final Batch Loss: 0.08574584126472473\n",
      "Epoch 936, Loss: 0.30720991641283035, Final Batch Loss: 0.2004895806312561\n",
      "Epoch 937, Loss: 0.2341112568974495, Final Batch Loss: 0.153476282954216\n",
      "Epoch 938, Loss: 0.1742774434387684, Final Batch Loss: 0.05166397616267204\n",
      "Epoch 939, Loss: 0.19469133764505386, Final Batch Loss: 0.07868699729442596\n",
      "Epoch 940, Loss: 0.22708584368228912, Final Batch Loss: 0.09236361086368561\n",
      "Epoch 941, Loss: 0.19356290996074677, Final Batch Loss: 0.0774959996342659\n",
      "Epoch 942, Loss: 0.18494099378585815, Final Batch Loss: 0.08899038285017014\n",
      "Epoch 943, Loss: 0.22744105756282806, Final Batch Loss: 0.1361849457025528\n",
      "Epoch 944, Loss: 0.22669223695993423, Final Batch Loss: 0.0796261802315712\n",
      "Epoch 945, Loss: 0.21707765758037567, Final Batch Loss: 0.11290357261896133\n",
      "Epoch 946, Loss: 0.22775674611330032, Final Batch Loss: 0.130747988820076\n",
      "Epoch 947, Loss: 0.25340285152196884, Final Batch Loss: 0.14240401983261108\n",
      "Epoch 948, Loss: 0.1694752722978592, Final Batch Loss: 0.07755395770072937\n",
      "Epoch 949, Loss: 0.18375073373317719, Final Batch Loss: 0.10112635046243668\n",
      "Epoch 950, Loss: 0.16129612922668457, Final Batch Loss: 0.0701761469244957\n",
      "Epoch 951, Loss: 0.2180386632680893, Final Batch Loss: 0.09308140724897385\n",
      "Epoch 952, Loss: 0.20462746918201447, Final Batch Loss: 0.07555131614208221\n",
      "Epoch 953, Loss: 0.20051193237304688, Final Batch Loss: 0.0897245928645134\n",
      "Epoch 954, Loss: 0.22134075313806534, Final Batch Loss: 0.14065757393836975\n",
      "Epoch 955, Loss: 0.2116726040840149, Final Batch Loss: 0.10546498745679855\n",
      "Epoch 956, Loss: 0.17213814705610275, Final Batch Loss: 0.07834901660680771\n",
      "Epoch 957, Loss: 0.17991838604211807, Final Batch Loss: 0.10000397264957428\n",
      "Epoch 958, Loss: 0.23869383335113525, Final Batch Loss: 0.0963350236415863\n",
      "Epoch 959, Loss: 0.1751539260149002, Final Batch Loss: 0.07302355766296387\n",
      "Epoch 960, Loss: 0.20723871886730194, Final Batch Loss: 0.08042646944522858\n",
      "Epoch 961, Loss: 0.18127014487981796, Final Batch Loss: 0.09428448975086212\n",
      "Epoch 962, Loss: 0.19483467191457748, Final Batch Loss: 0.058694012463092804\n",
      "Epoch 963, Loss: 0.16936719417572021, Final Batch Loss: 0.09425731748342514\n",
      "Epoch 964, Loss: 0.19695180654525757, Final Batch Loss: 0.09745308011770248\n",
      "Epoch 965, Loss: 0.2045852690935135, Final Batch Loss: 0.13082493841648102\n",
      "Epoch 966, Loss: 0.20974283665418625, Final Batch Loss: 0.13093097507953644\n",
      "Epoch 967, Loss: 0.15981081873178482, Final Batch Loss: 0.06691783666610718\n",
      "Epoch 968, Loss: 0.18393470346927643, Final Batch Loss: 0.08300165832042694\n",
      "Epoch 969, Loss: 0.2115873172879219, Final Batch Loss: 0.11759315431118011\n",
      "Epoch 970, Loss: 0.1841651201248169, Final Batch Loss: 0.07923069596290588\n",
      "Epoch 971, Loss: 0.17792116850614548, Final Batch Loss: 0.0947381854057312\n",
      "Epoch 972, Loss: 0.17518718540668488, Final Batch Loss: 0.09070154279470444\n",
      "Epoch 973, Loss: 0.16335247084498405, Final Batch Loss: 0.04915845766663551\n",
      "Epoch 974, Loss: 0.14695797115564346, Final Batch Loss: 0.04083217680454254\n",
      "Epoch 975, Loss: 0.19260122627019882, Final Batch Loss: 0.0714314728975296\n",
      "Epoch 976, Loss: 0.19818007200956345, Final Batch Loss: 0.09331648051738739\n",
      "Epoch 977, Loss: 0.19370097666978836, Final Batch Loss: 0.08485429733991623\n",
      "Epoch 978, Loss: 0.21869756281375885, Final Batch Loss: 0.10598593205213547\n",
      "Epoch 979, Loss: 0.22833219915628433, Final Batch Loss: 0.1304781585931778\n",
      "Epoch 980, Loss: 0.1989891603589058, Final Batch Loss: 0.09268871694803238\n",
      "Epoch 981, Loss: 0.23872382193803787, Final Batch Loss: 0.11570446193218231\n",
      "Epoch 982, Loss: 0.2310798242688179, Final Batch Loss: 0.12145835906267166\n",
      "Epoch 983, Loss: 0.2078009843826294, Final Batch Loss: 0.10697150230407715\n",
      "Epoch 984, Loss: 0.17513498663902283, Final Batch Loss: 0.09413609653711319\n",
      "Epoch 985, Loss: 0.20133039355278015, Final Batch Loss: 0.1254022717475891\n",
      "Epoch 986, Loss: 0.20394083112478256, Final Batch Loss: 0.09387898445129395\n",
      "Epoch 987, Loss: 0.21988052129745483, Final Batch Loss: 0.11987002938985825\n",
      "Epoch 988, Loss: 0.20209676027297974, Final Batch Loss: 0.10025631636381149\n",
      "Epoch 989, Loss: 0.1625080183148384, Final Batch Loss: 0.0448506698012352\n",
      "Epoch 990, Loss: 0.17929981648921967, Final Batch Loss: 0.083652064204216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991, Loss: 0.207929790019989, Final Batch Loss: 0.13700318336486816\n",
      "Epoch 992, Loss: 0.177818663418293, Final Batch Loss: 0.09040302038192749\n",
      "Epoch 993, Loss: 0.23542456328868866, Final Batch Loss: 0.14461851119995117\n",
      "Epoch 994, Loss: 0.2046840861439705, Final Batch Loss: 0.09954924136400223\n",
      "Epoch 995, Loss: 0.20696982741355896, Final Batch Loss: 0.10153626650571823\n",
      "Epoch 996, Loss: 0.1659046709537506, Final Batch Loss: 0.0901511088013649\n",
      "Epoch 997, Loss: 0.18313553929328918, Final Batch Loss: 0.06678465753793716\n",
      "Epoch 998, Loss: 0.21627182513475418, Final Batch Loss: 0.11961749196052551\n",
      "Epoch 999, Loss: 0.1907346174120903, Final Batch Loss: 0.10630044341087341\n",
      "Epoch 1000, Loss: 0.20444762706756592, Final Batch Loss: 0.11136077344417572\n",
      "Epoch 1001, Loss: 0.20821720361709595, Final Batch Loss: 0.10149101912975311\n",
      "Epoch 1002, Loss: 0.1708625927567482, Final Batch Loss: 0.07494080811738968\n",
      "Epoch 1003, Loss: 0.1793031096458435, Final Batch Loss: 0.07580932974815369\n",
      "Epoch 1004, Loss: 0.1974087730050087, Final Batch Loss: 0.0855565071105957\n",
      "Epoch 1005, Loss: 0.1568661704659462, Final Batch Loss: 0.0759933665394783\n",
      "Epoch 1006, Loss: 0.22303738445043564, Final Batch Loss: 0.10808345675468445\n",
      "Epoch 1007, Loss: 0.20617428421974182, Final Batch Loss: 0.12724393606185913\n",
      "Epoch 1008, Loss: 0.18686015903949738, Final Batch Loss: 0.06851792335510254\n",
      "Epoch 1009, Loss: 0.18998228013515472, Final Batch Loss: 0.09097812324762344\n",
      "Epoch 1010, Loss: 0.23200146108865738, Final Batch Loss: 0.1438124030828476\n",
      "Epoch 1011, Loss: 0.2032882273197174, Final Batch Loss: 0.09363212436437607\n",
      "Epoch 1012, Loss: 0.20214339345693588, Final Batch Loss: 0.10793119668960571\n",
      "Epoch 1013, Loss: 0.1931883543729782, Final Batch Loss: 0.04924827814102173\n",
      "Epoch 1014, Loss: 0.17559795826673508, Final Batch Loss: 0.09576655179262161\n",
      "Epoch 1015, Loss: 0.24543871730566025, Final Batch Loss: 0.14338140189647675\n",
      "Epoch 1016, Loss: 0.18078047037124634, Final Batch Loss: 0.06815089285373688\n",
      "Epoch 1017, Loss: 0.26247725635766983, Final Batch Loss: 0.16235513985157013\n",
      "Epoch 1018, Loss: 0.19556017965078354, Final Batch Loss: 0.07932626456022263\n",
      "Epoch 1019, Loss: 0.23896382749080658, Final Batch Loss: 0.09627190232276917\n",
      "Epoch 1020, Loss: 0.2330182045698166, Final Batch Loss: 0.1323409527540207\n",
      "Epoch 1021, Loss: 0.18978436291217804, Final Batch Loss: 0.11163007467985153\n",
      "Epoch 1022, Loss: 0.16530706733465195, Final Batch Loss: 0.0711800828576088\n",
      "Epoch 1023, Loss: 0.16716628521680832, Final Batch Loss: 0.074717678129673\n",
      "Epoch 1024, Loss: 0.15162630379199982, Final Batch Loss: 0.0658741444349289\n",
      "Epoch 1025, Loss: 0.2008119374513626, Final Batch Loss: 0.09911086410284042\n",
      "Epoch 1026, Loss: 0.2673549950122833, Final Batch Loss: 0.15554778277873993\n",
      "Epoch 1027, Loss: 0.19435682147741318, Final Batch Loss: 0.10336163640022278\n",
      "Epoch 1028, Loss: 0.17986895889043808, Final Batch Loss: 0.08035025745630264\n",
      "Epoch 1029, Loss: 0.2864178419113159, Final Batch Loss: 0.11867965757846832\n",
      "Epoch 1030, Loss: 0.16048675030469894, Final Batch Loss: 0.055882491171360016\n",
      "Epoch 1031, Loss: 0.21782836318016052, Final Batch Loss: 0.12081356346607208\n",
      "Epoch 1032, Loss: 0.2009783610701561, Final Batch Loss: 0.09691089391708374\n",
      "Epoch 1033, Loss: 0.17508623749017715, Final Batch Loss: 0.10479066520929337\n",
      "Epoch 1034, Loss: 0.19409912824630737, Final Batch Loss: 0.11553589254617691\n",
      "Epoch 1035, Loss: 0.18645577132701874, Final Batch Loss: 0.09110967814922333\n",
      "Epoch 1036, Loss: 0.21774083375930786, Final Batch Loss: 0.11811719834804535\n",
      "Epoch 1037, Loss: 0.15798775106668472, Final Batch Loss: 0.06946724653244019\n",
      "Epoch 1038, Loss: 0.16019005328416824, Final Batch Loss: 0.054967135190963745\n",
      "Epoch 1039, Loss: 0.21859224885702133, Final Batch Loss: 0.12459412217140198\n",
      "Epoch 1040, Loss: 0.16125348210334778, Final Batch Loss: 0.09154050052165985\n",
      "Epoch 1041, Loss: 0.1554763726890087, Final Batch Loss: 0.05373984947800636\n",
      "Epoch 1042, Loss: 0.2228403389453888, Final Batch Loss: 0.1400163322687149\n",
      "Epoch 1043, Loss: 0.16130229830741882, Final Batch Loss: 0.05176717787981033\n",
      "Epoch 1044, Loss: 0.16529672965407372, Final Batch Loss: 0.05548550561070442\n",
      "Epoch 1045, Loss: 0.15712133795022964, Final Batch Loss: 0.06627845764160156\n",
      "Epoch 1046, Loss: 0.16871773451566696, Final Batch Loss: 0.060546956956386566\n",
      "Epoch 1047, Loss: 0.1410672962665558, Final Batch Loss: 0.058649592101573944\n",
      "Epoch 1048, Loss: 0.16073857992887497, Final Batch Loss: 0.07685544341802597\n",
      "Epoch 1049, Loss: 0.15653550997376442, Final Batch Loss: 0.054488468915224075\n",
      "Epoch 1050, Loss: 0.18266505002975464, Final Batch Loss: 0.09400001913309097\n",
      "Epoch 1051, Loss: 0.19978377223014832, Final Batch Loss: 0.09233064949512482\n",
      "Epoch 1052, Loss: 0.1933935359120369, Final Batch Loss: 0.12591348588466644\n",
      "Epoch 1053, Loss: 0.2134242132306099, Final Batch Loss: 0.07925335317850113\n",
      "Epoch 1054, Loss: 0.18091019988059998, Final Batch Loss: 0.08661241829395294\n",
      "Epoch 1055, Loss: 0.17700472474098206, Final Batch Loss: 0.08778926730155945\n",
      "Epoch 1056, Loss: 0.17326456308364868, Final Batch Loss: 0.07995810359716415\n",
      "Epoch 1057, Loss: 0.18784797191619873, Final Batch Loss: 0.07906161993741989\n",
      "Epoch 1058, Loss: 0.2376173660159111, Final Batch Loss: 0.14747650921344757\n",
      "Epoch 1059, Loss: 0.20490416884422302, Final Batch Loss: 0.1339227706193924\n",
      "Epoch 1060, Loss: 0.18230995535850525, Final Batch Loss: 0.08879753202199936\n",
      "Epoch 1061, Loss: 0.2077496349811554, Final Batch Loss: 0.09619740396738052\n",
      "Epoch 1062, Loss: 0.16291920840740204, Final Batch Loss: 0.06803422421216965\n",
      "Epoch 1063, Loss: 0.17824319005012512, Final Batch Loss: 0.0664706826210022\n",
      "Epoch 1064, Loss: 0.19572503119707108, Final Batch Loss: 0.09150578081607819\n",
      "Epoch 1065, Loss: 0.21525133401155472, Final Batch Loss: 0.13523679971694946\n",
      "Epoch 1066, Loss: 0.17172635346651077, Final Batch Loss: 0.08830320835113525\n",
      "Epoch 1067, Loss: 0.1647912859916687, Final Batch Loss: 0.06882963329553604\n",
      "Epoch 1068, Loss: 0.17901551723480225, Final Batch Loss: 0.10165944695472717\n",
      "Epoch 1069, Loss: 0.16773027554154396, Final Batch Loss: 0.056867342442274094\n",
      "Epoch 1070, Loss: 0.1620466336607933, Final Batch Loss: 0.08533458411693573\n",
      "Epoch 1071, Loss: 0.18103694170713425, Final Batch Loss: 0.10639947652816772\n",
      "Epoch 1072, Loss: 0.19954130053520203, Final Batch Loss: 0.11214413493871689\n",
      "Epoch 1073, Loss: 0.24019872397184372, Final Batch Loss: 0.08362484723329544\n",
      "Epoch 1074, Loss: 0.15421024709939957, Final Batch Loss: 0.05304552614688873\n",
      "Epoch 1075, Loss: 0.16395330056548119, Final Batch Loss: 0.05050047114491463\n",
      "Epoch 1076, Loss: 0.14800802618265152, Final Batch Loss: 0.07971803843975067\n",
      "Epoch 1077, Loss: 0.20881296694278717, Final Batch Loss: 0.11111104488372803\n",
      "Epoch 1078, Loss: 0.15001288801431656, Final Batch Loss: 0.07042700797319412\n",
      "Epoch 1079, Loss: 0.17147847265005112, Final Batch Loss: 0.10935036092996597\n",
      "Epoch 1080, Loss: 0.17424293607473373, Final Batch Loss: 0.09116148948669434\n",
      "Epoch 1081, Loss: 0.1930157095193863, Final Batch Loss: 0.10694415122270584\n",
      "Epoch 1082, Loss: 0.21301167458295822, Final Batch Loss: 0.09804152697324753\n",
      "Epoch 1083, Loss: 0.23514067381620407, Final Batch Loss: 0.07246313244104385\n",
      "Epoch 1084, Loss: 0.21438082307577133, Final Batch Loss: 0.12267022579908371\n",
      "Epoch 1085, Loss: 0.23614373803138733, Final Batch Loss: 0.13788577914237976\n",
      "Epoch 1086, Loss: 0.16984319314360619, Final Batch Loss: 0.04545072838664055\n",
      "Epoch 1087, Loss: 0.156414482742548, Final Batch Loss: 0.060210395604372025\n",
      "Epoch 1088, Loss: 0.15399669855833054, Final Batch Loss: 0.0794750303030014\n",
      "Epoch 1089, Loss: 0.3197868764400482, Final Batch Loss: 0.163752943277359\n",
      "Epoch 1090, Loss: 0.18983972817659378, Final Batch Loss: 0.09060908108949661\n",
      "Epoch 1091, Loss: 0.1863073706626892, Final Batch Loss: 0.06984041631221771\n",
      "Epoch 1092, Loss: 0.17973457276821136, Final Batch Loss: 0.09777476638555527\n",
      "Epoch 1093, Loss: 0.18875335156917572, Final Batch Loss: 0.08603152632713318\n",
      "Epoch 1094, Loss: 0.17787669599056244, Final Batch Loss: 0.07462012022733688\n",
      "Epoch 1095, Loss: 0.17304175347089767, Final Batch Loss: 0.06949673593044281\n",
      "Epoch 1096, Loss: 0.17602002620697021, Final Batch Loss: 0.07251780480146408\n",
      "Epoch 1097, Loss: 0.16681073978543282, Final Batch Loss: 0.05960531905293465\n",
      "Epoch 1098, Loss: 0.19067619740962982, Final Batch Loss: 0.07668717950582504\n",
      "Epoch 1099, Loss: 0.19436103105545044, Final Batch Loss: 0.08557640761137009\n",
      "Epoch 1100, Loss: 0.1720251441001892, Final Batch Loss: 0.06516499817371368\n",
      "Epoch 1101, Loss: 0.14779502153396606, Final Batch Loss: 0.06419839709997177\n",
      "Epoch 1102, Loss: 0.1878434345126152, Final Batch Loss: 0.08341588824987411\n",
      "Epoch 1103, Loss: 0.17198771238327026, Final Batch Loss: 0.08785243332386017\n",
      "Epoch 1104, Loss: 0.19267188757658005, Final Batch Loss: 0.07228284329175949\n",
      "Epoch 1105, Loss: 0.1901780590415001, Final Batch Loss: 0.08047989755868912\n",
      "Epoch 1106, Loss: 0.18500757217407227, Final Batch Loss: 0.0815698578953743\n",
      "Epoch 1107, Loss: 0.22247924655675888, Final Batch Loss: 0.08874040096998215\n",
      "Epoch 1108, Loss: 0.16377921402454376, Final Batch Loss: 0.07241885364055634\n",
      "Epoch 1109, Loss: 0.20312285423278809, Final Batch Loss: 0.09000126272439957\n",
      "Epoch 1110, Loss: 0.1851116567850113, Final Batch Loss: 0.11442432552576065\n",
      "Epoch 1111, Loss: 0.15177468210458755, Final Batch Loss: 0.07165247201919556\n",
      "Epoch 1112, Loss: 0.1940600425004959, Final Batch Loss: 0.12618261575698853\n",
      "Epoch 1113, Loss: 0.20657066255807877, Final Batch Loss: 0.09827577322721481\n",
      "Epoch 1114, Loss: 0.13102325052022934, Final Batch Loss: 0.043730542063713074\n",
      "Epoch 1115, Loss: 0.16075795888900757, Final Batch Loss: 0.06340039521455765\n",
      "Epoch 1116, Loss: 0.19245034456253052, Final Batch Loss: 0.10696874558925629\n",
      "Epoch 1117, Loss: 0.2011827751994133, Final Batch Loss: 0.07673116773366928\n",
      "Epoch 1118, Loss: 0.19007769599556923, Final Batch Loss: 0.1277293860912323\n",
      "Epoch 1119, Loss: 0.17090560495853424, Final Batch Loss: 0.0836925283074379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1120, Loss: 0.18589504063129425, Final Batch Loss: 0.11957577615976334\n",
      "Epoch 1121, Loss: 0.22242910414934158, Final Batch Loss: 0.13076114654541016\n",
      "Epoch 1122, Loss: 0.18813569098711014, Final Batch Loss: 0.09127330780029297\n",
      "Epoch 1123, Loss: 0.16470257192850113, Final Batch Loss: 0.0823388323187828\n",
      "Epoch 1124, Loss: 0.18115904182195663, Final Batch Loss: 0.10370047390460968\n",
      "Epoch 1125, Loss: 0.1616705358028412, Final Batch Loss: 0.0733671560883522\n",
      "Epoch 1126, Loss: 0.16570980101823807, Final Batch Loss: 0.080379419028759\n",
      "Epoch 1127, Loss: 0.1718394160270691, Final Batch Loss: 0.06829464435577393\n",
      "Epoch 1128, Loss: 0.1859511062502861, Final Batch Loss: 0.09738457202911377\n",
      "Epoch 1129, Loss: 0.15477528423070908, Final Batch Loss: 0.05275533348321915\n",
      "Epoch 1130, Loss: 0.1889539361000061, Final Batch Loss: 0.09491518884897232\n",
      "Epoch 1131, Loss: 0.3297124356031418, Final Batch Loss: 0.23099273443222046\n",
      "Epoch 1132, Loss: 0.17024175822734833, Final Batch Loss: 0.06928712874650955\n",
      "Epoch 1133, Loss: 0.16142204403877258, Final Batch Loss: 0.08820999413728714\n",
      "Epoch 1134, Loss: 0.14373967796564102, Final Batch Loss: 0.04598306119441986\n",
      "Epoch 1135, Loss: 0.19622135162353516, Final Batch Loss: 0.07944583892822266\n",
      "Epoch 1136, Loss: 0.17148347198963165, Final Batch Loss: 0.102988101541996\n",
      "Epoch 1137, Loss: 0.18817508965730667, Final Batch Loss: 0.09268344938755035\n",
      "Epoch 1138, Loss: 0.22776499390602112, Final Batch Loss: 0.15453685820102692\n",
      "Epoch 1139, Loss: 0.13806891441345215, Final Batch Loss: 0.06860716640949249\n",
      "Epoch 1140, Loss: 0.18558911979198456, Final Batch Loss: 0.09353594481945038\n",
      "Epoch 1141, Loss: 0.14069579541683197, Final Batch Loss: 0.06951528042554855\n",
      "Epoch 1142, Loss: 0.1821989193558693, Final Batch Loss: 0.11281972378492355\n",
      "Epoch 1143, Loss: 0.18117527663707733, Final Batch Loss: 0.10636839270591736\n",
      "Epoch 1144, Loss: 0.1384296417236328, Final Batch Loss: 0.07023020088672638\n",
      "Epoch 1145, Loss: 0.2006787285208702, Final Batch Loss: 0.09473337233066559\n",
      "Epoch 1146, Loss: 0.16386612504720688, Final Batch Loss: 0.08345487713813782\n",
      "Epoch 1147, Loss: 0.16311952099204063, Final Batch Loss: 0.058001626282930374\n",
      "Epoch 1148, Loss: 0.162730373442173, Final Batch Loss: 0.07793952524662018\n",
      "Epoch 1149, Loss: 0.18864382058382034, Final Batch Loss: 0.09918203949928284\n",
      "Epoch 1150, Loss: 0.3161603659391403, Final Batch Loss: 0.11350128054618835\n",
      "Epoch 1151, Loss: 0.18788472563028336, Final Batch Loss: 0.10587070882320404\n",
      "Epoch 1152, Loss: 0.1742541268467903, Final Batch Loss: 0.09494839608669281\n",
      "Epoch 1153, Loss: 0.18142129480838776, Final Batch Loss: 0.08130960166454315\n",
      "Epoch 1154, Loss: 0.1730172261595726, Final Batch Loss: 0.09241104871034622\n",
      "Epoch 1155, Loss: 0.16090569645166397, Final Batch Loss: 0.06876354664564133\n",
      "Epoch 1156, Loss: 0.1974986493587494, Final Batch Loss: 0.10772209614515305\n",
      "Epoch 1157, Loss: 0.14755013585090637, Final Batch Loss: 0.0644845962524414\n",
      "Epoch 1158, Loss: 0.15510783344507217, Final Batch Loss: 0.07998853176832199\n",
      "Epoch 1159, Loss: 0.19665376842021942, Final Batch Loss: 0.12364143878221512\n",
      "Epoch 1160, Loss: 0.17645878344774246, Final Batch Loss: 0.06586822122335434\n",
      "Epoch 1161, Loss: 0.13916625082492828, Final Batch Loss: 0.06007213890552521\n",
      "Epoch 1162, Loss: 0.14279728010296822, Final Batch Loss: 0.06060469523072243\n",
      "Epoch 1163, Loss: 0.16993428766727448, Final Batch Loss: 0.08492107689380646\n",
      "Epoch 1164, Loss: 0.1525525078177452, Final Batch Loss: 0.07162952423095703\n",
      "Epoch 1165, Loss: 0.1954706683754921, Final Batch Loss: 0.1108895093202591\n",
      "Epoch 1166, Loss: 0.1933499351143837, Final Batch Loss: 0.09494956582784653\n",
      "Epoch 1167, Loss: 0.18551236391067505, Final Batch Loss: 0.09017845243215561\n",
      "Epoch 1168, Loss: 0.14693675935268402, Final Batch Loss: 0.07643817365169525\n",
      "Epoch 1169, Loss: 0.15365204215049744, Final Batch Loss: 0.0641612634062767\n",
      "Epoch 1170, Loss: 0.17311935871839523, Final Batch Loss: 0.07415299862623215\n",
      "Epoch 1171, Loss: 0.1742503121495247, Final Batch Loss: 0.06341982632875443\n",
      "Epoch 1172, Loss: 0.21121466904878616, Final Batch Loss: 0.10356961935758591\n",
      "Epoch 1173, Loss: 0.14125479757785797, Final Batch Loss: 0.07550317794084549\n",
      "Epoch 1174, Loss: 0.2208709642291069, Final Batch Loss: 0.13891439139842987\n",
      "Epoch 1175, Loss: 0.15041770786046982, Final Batch Loss: 0.08061788231134415\n",
      "Epoch 1176, Loss: 0.2184114158153534, Final Batch Loss: 0.1262478083372116\n",
      "Epoch 1177, Loss: 0.14203907549381256, Final Batch Loss: 0.06894747912883759\n",
      "Epoch 1178, Loss: 0.15028523281216621, Final Batch Loss: 0.05319661274552345\n",
      "Epoch 1179, Loss: 0.16734764724969864, Final Batch Loss: 0.10862810164690018\n",
      "Epoch 1180, Loss: 0.18089056387543678, Final Batch Loss: 0.1196770891547203\n",
      "Epoch 1181, Loss: 0.15583135187625885, Final Batch Loss: 0.07973313331604004\n",
      "Epoch 1182, Loss: 0.1722170189023018, Final Batch Loss: 0.08184260874986649\n",
      "Epoch 1183, Loss: 0.1466524675488472, Final Batch Loss: 0.06758007407188416\n",
      "Epoch 1184, Loss: 0.22781047970056534, Final Batch Loss: 0.11882514506578445\n",
      "Epoch 1185, Loss: 0.2449398711323738, Final Batch Loss: 0.10384746640920639\n",
      "Epoch 1186, Loss: 0.20174406468868256, Final Batch Loss: 0.11355257034301758\n",
      "Epoch 1187, Loss: 0.16906282305717468, Final Batch Loss: 0.10304614156484604\n",
      "Epoch 1188, Loss: 0.14893698692321777, Final Batch Loss: 0.06483510881662369\n",
      "Epoch 1189, Loss: 0.17877385020256042, Final Batch Loss: 0.0900835245847702\n",
      "Epoch 1190, Loss: 0.24052775651216507, Final Batch Loss: 0.11589929461479187\n",
      "Epoch 1191, Loss: 0.21808188408613205, Final Batch Loss: 0.09986046701669693\n",
      "Epoch 1192, Loss: 0.1728326678276062, Final Batch Loss: 0.09912971407175064\n",
      "Epoch 1193, Loss: 0.18694134056568146, Final Batch Loss: 0.07983213663101196\n",
      "Epoch 1194, Loss: 0.20804251730442047, Final Batch Loss: 0.11261682212352753\n",
      "Epoch 1195, Loss: 0.16437092423439026, Final Batch Loss: 0.09643630683422089\n",
      "Epoch 1196, Loss: 0.16864127665758133, Final Batch Loss: 0.09680476039648056\n",
      "Epoch 1197, Loss: 0.15994253009557724, Final Batch Loss: 0.08501571416854858\n",
      "Epoch 1198, Loss: 0.26072894781827927, Final Batch Loss: 0.12253094464540482\n",
      "Epoch 1199, Loss: 0.19914373755455017, Final Batch Loss: 0.10842052102088928\n",
      "Epoch 1200, Loss: 0.17646274715662003, Final Batch Loss: 0.07329250127077103\n",
      "Epoch 1201, Loss: 0.15333791822195053, Final Batch Loss: 0.08709393441677094\n",
      "Epoch 1202, Loss: 0.17163049429655075, Final Batch Loss: 0.10762869566679001\n",
      "Epoch 1203, Loss: 0.18217606842517853, Final Batch Loss: 0.0863853469491005\n",
      "Epoch 1204, Loss: 0.17235621809959412, Final Batch Loss: 0.09981610625982285\n",
      "Epoch 1205, Loss: 0.20983608812093735, Final Batch Loss: 0.11002159863710403\n",
      "Epoch 1206, Loss: 0.2304687723517418, Final Batch Loss: 0.1433786004781723\n",
      "Epoch 1207, Loss: 0.17751934379339218, Final Batch Loss: 0.1089661568403244\n",
      "Epoch 1208, Loss: 0.15092924609780312, Final Batch Loss: 0.09180936217308044\n",
      "Epoch 1209, Loss: 0.15729208290576935, Final Batch Loss: 0.06619443744421005\n",
      "Epoch 1210, Loss: 0.1996711641550064, Final Batch Loss: 0.13490016758441925\n",
      "Epoch 1211, Loss: 0.18094433844089508, Final Batch Loss: 0.09906534850597382\n",
      "Epoch 1212, Loss: 0.2818790674209595, Final Batch Loss: 0.18829485774040222\n",
      "Epoch 1213, Loss: 0.19392038136720657, Final Batch Loss: 0.11064896732568741\n",
      "Epoch 1214, Loss: 0.16172867268323898, Final Batch Loss: 0.0662049725651741\n",
      "Epoch 1215, Loss: 0.1730940267443657, Final Batch Loss: 0.09053552895784378\n",
      "Epoch 1216, Loss: 0.1888613924384117, Final Batch Loss: 0.1137189045548439\n",
      "Epoch 1217, Loss: 0.18496977537870407, Final Batch Loss: 0.09653262048959732\n",
      "Epoch 1218, Loss: 0.16510045528411865, Final Batch Loss: 0.07740429788827896\n",
      "Epoch 1219, Loss: 0.18089743703603745, Final Batch Loss: 0.08447141200304031\n",
      "Epoch 1220, Loss: 0.14890024811029434, Final Batch Loss: 0.0825321301817894\n",
      "Epoch 1221, Loss: 0.15569007396697998, Final Batch Loss: 0.09983929991722107\n",
      "Epoch 1222, Loss: 0.18201859295368195, Final Batch Loss: 0.08433066308498383\n",
      "Epoch 1223, Loss: 0.19283007085323334, Final Batch Loss: 0.08096197992563248\n",
      "Epoch 1224, Loss: 0.18936968594789505, Final Batch Loss: 0.11589574068784714\n",
      "Epoch 1225, Loss: 0.15633654594421387, Final Batch Loss: 0.08364496380090714\n",
      "Epoch 1226, Loss: 0.15288615971803665, Final Batch Loss: 0.07769070565700531\n",
      "Epoch 1227, Loss: 0.1292531006038189, Final Batch Loss: 0.05685191974043846\n",
      "Epoch 1228, Loss: 0.16553419083356857, Final Batch Loss: 0.1002560704946518\n",
      "Epoch 1229, Loss: 0.16296321898698807, Final Batch Loss: 0.06887905299663544\n",
      "Epoch 1230, Loss: 0.16474376618862152, Final Batch Loss: 0.09799548983573914\n",
      "Epoch 1231, Loss: 0.15720184892416, Final Batch Loss: 0.09536531567573547\n",
      "Epoch 1232, Loss: 0.16144352406263351, Final Batch Loss: 0.06995174288749695\n",
      "Epoch 1233, Loss: 0.15273328125476837, Final Batch Loss: 0.07733612507581711\n",
      "Epoch 1234, Loss: 0.14391620829701424, Final Batch Loss: 0.042783576995134354\n",
      "Epoch 1235, Loss: 0.15329069271683693, Final Batch Loss: 0.05182379111647606\n",
      "Epoch 1236, Loss: 0.1289445087313652, Final Batch Loss: 0.058449022471904755\n",
      "Epoch 1237, Loss: 0.1637684553861618, Final Batch Loss: 0.0705270767211914\n",
      "Epoch 1238, Loss: 0.17813844233751297, Final Batch Loss: 0.09069770574569702\n",
      "Epoch 1239, Loss: 0.14896131306886673, Final Batch Loss: 0.07925646752119064\n",
      "Epoch 1240, Loss: 0.14356454834342003, Final Batch Loss: 0.056622106581926346\n",
      "Epoch 1241, Loss: 0.14371896535158157, Final Batch Loss: 0.07369615137577057\n",
      "Epoch 1242, Loss: 0.15410223603248596, Final Batch Loss: 0.08569703996181488\n",
      "Epoch 1243, Loss: 0.10599779896438122, Final Batch Loss: 0.026883786544203758\n",
      "Epoch 1244, Loss: 0.15541866421699524, Final Batch Loss: 0.06767231971025467\n",
      "Epoch 1245, Loss: 0.11703049764037132, Final Batch Loss: 0.06892658025026321\n",
      "Epoch 1246, Loss: 0.1895224153995514, Final Batch Loss: 0.0750332623720169\n",
      "Epoch 1247, Loss: 0.15255224704742432, Final Batch Loss: 0.06992574036121368\n",
      "Epoch 1248, Loss: 0.16092386096715927, Final Batch Loss: 0.09182620048522949\n",
      "Epoch 1249, Loss: 0.1752535030245781, Final Batch Loss: 0.06993881613016129\n",
      "Epoch 1250, Loss: 0.1463444083929062, Final Batch Loss: 0.06404983252286911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1251, Loss: 0.17137177288532257, Final Batch Loss: 0.08836200833320618\n",
      "Epoch 1252, Loss: 0.16988074034452438, Final Batch Loss: 0.09332633763551712\n",
      "Epoch 1253, Loss: 0.15008065849542618, Final Batch Loss: 0.09625447541475296\n",
      "Epoch 1254, Loss: 0.1337343193590641, Final Batch Loss: 0.04989929124712944\n",
      "Epoch 1255, Loss: 0.13572631403803825, Final Batch Loss: 0.07835905253887177\n",
      "Epoch 1256, Loss: 0.1467631310224533, Final Batch Loss: 0.07597453892230988\n",
      "Epoch 1257, Loss: 0.1498468667268753, Final Batch Loss: 0.07678632438182831\n",
      "Epoch 1258, Loss: 0.16821301728487015, Final Batch Loss: 0.08245956897735596\n",
      "Epoch 1259, Loss: 0.1473740190267563, Final Batch Loss: 0.07125973701477051\n",
      "Epoch 1260, Loss: 0.13758467137813568, Final Batch Loss: 0.05109576880931854\n",
      "Epoch 1261, Loss: 0.14155039936304092, Final Batch Loss: 0.07229503989219666\n",
      "Epoch 1262, Loss: 0.22821279242634773, Final Batch Loss: 0.1751040667295456\n",
      "Epoch 1263, Loss: 0.1557188555598259, Final Batch Loss: 0.0788937360048294\n",
      "Epoch 1264, Loss: 0.16914337128400803, Final Batch Loss: 0.08353685587644577\n",
      "Epoch 1265, Loss: 0.14638559520244598, Final Batch Loss: 0.06040085107088089\n",
      "Epoch 1266, Loss: 0.1820659637451172, Final Batch Loss: 0.07741686701774597\n",
      "Epoch 1267, Loss: 0.17435050010681152, Final Batch Loss: 0.11451256275177002\n",
      "Epoch 1268, Loss: 0.13590071350336075, Final Batch Loss: 0.06364074349403381\n",
      "Epoch 1269, Loss: 0.15559305250644684, Final Batch Loss: 0.07593400776386261\n",
      "Epoch 1270, Loss: 0.1523488648235798, Final Batch Loss: 0.038154613226652145\n",
      "Epoch 1271, Loss: 0.17435894906520844, Final Batch Loss: 0.0922430008649826\n",
      "Epoch 1272, Loss: 0.13647933304309845, Final Batch Loss: 0.06911177188158035\n",
      "Epoch 1273, Loss: 0.148627121001482, Final Batch Loss: 0.09333490580320358\n",
      "Epoch 1274, Loss: 0.12359834834933281, Final Batch Loss: 0.052952561527490616\n",
      "Epoch 1275, Loss: 0.13023143634200096, Final Batch Loss: 0.05684960260987282\n",
      "Epoch 1276, Loss: 0.1582847684621811, Final Batch Loss: 0.07287951558828354\n",
      "Epoch 1277, Loss: 0.16198483109474182, Final Batch Loss: 0.0941842794418335\n",
      "Epoch 1278, Loss: 0.15202289819717407, Final Batch Loss: 0.07066327333450317\n",
      "Epoch 1279, Loss: 0.15331175923347473, Final Batch Loss: 0.08269447833299637\n",
      "Epoch 1280, Loss: 0.19687149673700333, Final Batch Loss: 0.12630847096443176\n",
      "Epoch 1281, Loss: 0.13515140488743782, Final Batch Loss: 0.05952828750014305\n",
      "Epoch 1282, Loss: 0.1513579934835434, Final Batch Loss: 0.06603613495826721\n",
      "Epoch 1283, Loss: 0.16423280537128448, Final Batch Loss: 0.08105939626693726\n",
      "Epoch 1284, Loss: 0.186739981174469, Final Batch Loss: 0.09441780298948288\n",
      "Epoch 1285, Loss: 0.19981345534324646, Final Batch Loss: 0.10187217593193054\n",
      "Epoch 1286, Loss: 0.19051465392112732, Final Batch Loss: 0.08537127822637558\n",
      "Epoch 1287, Loss: 0.16687056422233582, Final Batch Loss: 0.07862837612628937\n",
      "Epoch 1288, Loss: 0.14115489274263382, Final Batch Loss: 0.06634746491909027\n",
      "Epoch 1289, Loss: 0.1335364580154419, Final Batch Loss: 0.07486389577388763\n",
      "Epoch 1290, Loss: 0.15955624729394913, Final Batch Loss: 0.06915250420570374\n",
      "Epoch 1291, Loss: 0.13125521689653397, Final Batch Loss: 0.05950260907411575\n",
      "Epoch 1292, Loss: 0.13428494706749916, Final Batch Loss: 0.08951050043106079\n",
      "Epoch 1293, Loss: 0.15955305099487305, Final Batch Loss: 0.07929415255784988\n",
      "Epoch 1294, Loss: 0.1554701328277588, Final Batch Loss: 0.09828241914510727\n",
      "Epoch 1295, Loss: 0.13747713714838028, Final Batch Loss: 0.05220524221658707\n",
      "Epoch 1296, Loss: 0.16612061858177185, Final Batch Loss: 0.09854449331760406\n",
      "Epoch 1297, Loss: 0.11599763669073582, Final Batch Loss: 0.017881715670228004\n",
      "Epoch 1298, Loss: 0.1595209240913391, Final Batch Loss: 0.08050205558538437\n",
      "Epoch 1299, Loss: 0.1480194851756096, Final Batch Loss: 0.05682932585477829\n",
      "Epoch 1300, Loss: 0.17811482399702072, Final Batch Loss: 0.11122068017721176\n",
      "Epoch 1301, Loss: 0.09195603802800179, Final Batch Loss: 0.03568495810031891\n",
      "Epoch 1302, Loss: 0.18742024898529053, Final Batch Loss: 0.10489773005247116\n",
      "Epoch 1303, Loss: 0.21036889404058456, Final Batch Loss: 0.1287500560283661\n",
      "Epoch 1304, Loss: 0.19101568311452866, Final Batch Loss: 0.10755576938390732\n",
      "Epoch 1305, Loss: 0.12855610623955727, Final Batch Loss: 0.043722618371248245\n",
      "Epoch 1306, Loss: 0.15800748020410538, Final Batch Loss: 0.08523456007242203\n",
      "Epoch 1307, Loss: 0.1269470416009426, Final Batch Loss: 0.059839535504579544\n",
      "Epoch 1308, Loss: 0.1437193751335144, Final Batch Loss: 0.08141167461872101\n",
      "Epoch 1309, Loss: 0.2244849130511284, Final Batch Loss: 0.1144188642501831\n",
      "Epoch 1310, Loss: 0.16297055780887604, Final Batch Loss: 0.06770509481430054\n",
      "Epoch 1311, Loss: 0.2081933245062828, Final Batch Loss: 0.08639498054981232\n",
      "Epoch 1312, Loss: 0.1436314396560192, Final Batch Loss: 0.057854097336530685\n",
      "Epoch 1313, Loss: 0.16550850868225098, Final Batch Loss: 0.09553956240415573\n",
      "Epoch 1314, Loss: 0.18446779251098633, Final Batch Loss: 0.10443995147943497\n",
      "Epoch 1315, Loss: 0.16842500865459442, Final Batch Loss: 0.0842539444565773\n",
      "Epoch 1316, Loss: 0.14040125161409378, Final Batch Loss: 0.06425672024488449\n",
      "Epoch 1317, Loss: 0.16139143705368042, Final Batch Loss: 0.07486045360565186\n",
      "Epoch 1318, Loss: 0.22433558106422424, Final Batch Loss: 0.0996159166097641\n",
      "Epoch 1319, Loss: 0.17796291410923004, Final Batch Loss: 0.07460174709558487\n",
      "Epoch 1320, Loss: 0.19732916355133057, Final Batch Loss: 0.13370266556739807\n",
      "Epoch 1321, Loss: 0.13333187252283096, Final Batch Loss: 0.06752350181341171\n",
      "Epoch 1322, Loss: 0.21332012116909027, Final Batch Loss: 0.12261879444122314\n",
      "Epoch 1323, Loss: 0.15014034509658813, Final Batch Loss: 0.0807594433426857\n",
      "Epoch 1324, Loss: 0.1395685039460659, Final Batch Loss: 0.05601781979203224\n",
      "Epoch 1325, Loss: 0.16831661760807037, Final Batch Loss: 0.110471710562706\n",
      "Epoch 1326, Loss: 0.12557273730635643, Final Batch Loss: 0.06906484812498093\n",
      "Epoch 1327, Loss: 0.15457215905189514, Final Batch Loss: 0.06996554136276245\n",
      "Epoch 1328, Loss: 0.10992776602506638, Final Batch Loss: 0.055046677589416504\n",
      "Epoch 1329, Loss: 0.15043014287948608, Final Batch Loss: 0.06431011855602264\n",
      "Epoch 1330, Loss: 0.16741246730089188, Final Batch Loss: 0.10779111087322235\n",
      "Epoch 1331, Loss: 0.1381026953458786, Final Batch Loss: 0.06051763892173767\n",
      "Epoch 1332, Loss: 0.12903503328561783, Final Batch Loss: 0.06513591855764389\n",
      "Epoch 1333, Loss: 0.19941995292901993, Final Batch Loss: 0.13412509858608246\n",
      "Epoch 1334, Loss: 0.12955356016755104, Final Batch Loss: 0.04864263907074928\n",
      "Epoch 1335, Loss: 0.17216937988996506, Final Batch Loss: 0.09835667163133621\n",
      "Epoch 1336, Loss: 0.1768263876438141, Final Batch Loss: 0.09794160723686218\n",
      "Epoch 1337, Loss: 0.1289610117673874, Final Batch Loss: 0.05089772492647171\n",
      "Epoch 1338, Loss: 0.15370939671993256, Final Batch Loss: 0.0774456113576889\n",
      "Epoch 1339, Loss: 0.16017238795757294, Final Batch Loss: 0.06928830593824387\n",
      "Epoch 1340, Loss: 0.13965879008173943, Final Batch Loss: 0.0825759693980217\n",
      "Epoch 1341, Loss: 0.14973101392388344, Final Batch Loss: 0.09577056020498276\n",
      "Epoch 1342, Loss: 0.12486187368631363, Final Batch Loss: 0.05955324321985245\n",
      "Epoch 1343, Loss: 0.14391357079148293, Final Batch Loss: 0.04112139716744423\n",
      "Epoch 1344, Loss: 0.11140446364879608, Final Batch Loss: 0.05186043307185173\n",
      "Epoch 1345, Loss: 0.13682657480239868, Final Batch Loss: 0.08447746187448502\n",
      "Epoch 1346, Loss: 0.14265355095267296, Final Batch Loss: 0.09649544954299927\n",
      "Epoch 1347, Loss: 0.16506806761026382, Final Batch Loss: 0.061396703124046326\n",
      "Epoch 1348, Loss: 0.14693257957696915, Final Batch Loss: 0.06460253149271011\n",
      "Epoch 1349, Loss: 0.15262894332408905, Final Batch Loss: 0.07495192438364029\n",
      "Epoch 1350, Loss: 0.18550769612193108, Final Batch Loss: 0.12505117058753967\n",
      "Epoch 1351, Loss: 0.17393384128808975, Final Batch Loss: 0.06683564186096191\n",
      "Epoch 1352, Loss: 0.18185383081436157, Final Batch Loss: 0.11378943175077438\n",
      "Epoch 1353, Loss: 0.13478540629148483, Final Batch Loss: 0.055136650800704956\n",
      "Epoch 1354, Loss: 0.19651789218187332, Final Batch Loss: 0.11926218122243881\n",
      "Epoch 1355, Loss: 0.10317521542310715, Final Batch Loss: 0.04441198706626892\n",
      "Epoch 1356, Loss: 0.1670048013329506, Final Batch Loss: 0.08981244266033173\n",
      "Epoch 1357, Loss: 0.17889535427093506, Final Batch Loss: 0.0663096159696579\n",
      "Epoch 1358, Loss: 0.16482891142368317, Final Batch Loss: 0.08620623499155045\n",
      "Epoch 1359, Loss: 0.14477716758847237, Final Batch Loss: 0.0588265024125576\n",
      "Epoch 1360, Loss: 0.1482073813676834, Final Batch Loss: 0.0681978389620781\n",
      "Epoch 1361, Loss: 0.14840693026781082, Final Batch Loss: 0.06944788992404938\n",
      "Epoch 1362, Loss: 0.13663897663354874, Final Batch Loss: 0.0753314197063446\n",
      "Epoch 1363, Loss: 0.158722884953022, Final Batch Loss: 0.07009825110435486\n",
      "Epoch 1364, Loss: 0.13661961257457733, Final Batch Loss: 0.06770764291286469\n",
      "Epoch 1365, Loss: 0.13631075620651245, Final Batch Loss: 0.08996552973985672\n",
      "Epoch 1366, Loss: 0.13757968693971634, Final Batch Loss: 0.057271890342235565\n",
      "Epoch 1367, Loss: 0.1932799071073532, Final Batch Loss: 0.13699455559253693\n",
      "Epoch 1368, Loss: 0.16511714458465576, Final Batch Loss: 0.08843819051980972\n",
      "Epoch 1369, Loss: 0.13403750211000443, Final Batch Loss: 0.06679680198431015\n",
      "Epoch 1370, Loss: 0.1222287081182003, Final Batch Loss: 0.06260133534669876\n",
      "Epoch 1371, Loss: 0.12689370289444923, Final Batch Loss: 0.0794263407588005\n",
      "Epoch 1372, Loss: 0.1438090093433857, Final Batch Loss: 0.08184414356946945\n",
      "Epoch 1373, Loss: 0.11689361929893494, Final Batch Loss: 0.0641898587346077\n",
      "Epoch 1374, Loss: 0.17971491068601608, Final Batch Loss: 0.10694414377212524\n",
      "Epoch 1375, Loss: 0.1360776349902153, Final Batch Loss: 0.059359110891819\n",
      "Epoch 1376, Loss: 0.15482649952173233, Final Batch Loss: 0.07540477067232132\n",
      "Epoch 1377, Loss: 0.14826686680316925, Final Batch Loss: 0.08923125267028809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1378, Loss: 0.13870429247617722, Final Batch Loss: 0.06429200619459152\n",
      "Epoch 1379, Loss: 0.17114707827568054, Final Batch Loss: 0.09792885929346085\n",
      "Epoch 1380, Loss: 0.15872448682785034, Final Batch Loss: 0.0708669126033783\n",
      "Epoch 1381, Loss: 0.15627069026231766, Final Batch Loss: 0.08883962035179138\n",
      "Epoch 1382, Loss: 0.13969680294394493, Final Batch Loss: 0.05339584872126579\n",
      "Epoch 1383, Loss: 0.18453829735517502, Final Batch Loss: 0.08853289484977722\n",
      "Epoch 1384, Loss: 0.18359655141830444, Final Batch Loss: 0.11558699607849121\n",
      "Epoch 1385, Loss: 0.17829611897468567, Final Batch Loss: 0.10051357746124268\n",
      "Epoch 1386, Loss: 0.18201538175344467, Final Batch Loss: 0.09322406351566315\n",
      "Epoch 1387, Loss: 0.1775931715965271, Final Batch Loss: 0.08538182824850082\n",
      "Epoch 1388, Loss: 0.1819174624979496, Final Batch Loss: 0.12706109881401062\n",
      "Epoch 1389, Loss: 0.22939538955688477, Final Batch Loss: 0.14413627982139587\n",
      "Epoch 1390, Loss: 0.13782556727528572, Final Batch Loss: 0.07602573186159134\n",
      "Epoch 1391, Loss: 0.17547884956002235, Final Batch Loss: 0.12463175505399704\n",
      "Epoch 1392, Loss: 0.15195049718022346, Final Batch Loss: 0.04132607951760292\n",
      "Epoch 1393, Loss: 0.1572015844285488, Final Batch Loss: 0.0609482042491436\n",
      "Epoch 1394, Loss: 0.13999278470873833, Final Batch Loss: 0.0524236299097538\n",
      "Epoch 1395, Loss: 0.14433952048420906, Final Batch Loss: 0.057517942041158676\n",
      "Epoch 1396, Loss: 0.12812186032533646, Final Batch Loss: 0.04639505594968796\n",
      "Epoch 1397, Loss: 0.13960035145282745, Final Batch Loss: 0.06257615983486176\n",
      "Epoch 1398, Loss: 0.14101958274841309, Final Batch Loss: 0.08037202805280685\n",
      "Epoch 1399, Loss: 0.13004065304994583, Final Batch Loss: 0.06580647826194763\n",
      "Epoch 1400, Loss: 0.1681094542145729, Final Batch Loss: 0.0663222074508667\n",
      "Epoch 1401, Loss: 0.13017836585640907, Final Batch Loss: 0.060546841472387314\n",
      "Epoch 1402, Loss: 0.12152641639113426, Final Batch Loss: 0.06710381805896759\n",
      "Epoch 1403, Loss: 0.14745734632015228, Final Batch Loss: 0.08289895951747894\n",
      "Epoch 1404, Loss: 0.14391254633665085, Final Batch Loss: 0.05251185595989227\n",
      "Epoch 1405, Loss: 0.15027731657028198, Final Batch Loss: 0.05901645869016647\n",
      "Epoch 1406, Loss: 0.15717490017414093, Final Batch Loss: 0.089577816426754\n",
      "Epoch 1407, Loss: 0.14884716272354126, Final Batch Loss: 0.06919115036725998\n",
      "Epoch 1408, Loss: 0.17007899284362793, Final Batch Loss: 0.08298857510089874\n",
      "Epoch 1409, Loss: 0.11996542289853096, Final Batch Loss: 0.061142921447753906\n",
      "Epoch 1410, Loss: 0.13666686043143272, Final Batch Loss: 0.07621672004461288\n",
      "Epoch 1411, Loss: 0.13289016485214233, Final Batch Loss: 0.07047989964485168\n",
      "Epoch 1412, Loss: 0.13857132196426392, Final Batch Loss: 0.06790166348218918\n",
      "Epoch 1413, Loss: 0.11601506173610687, Final Batch Loss: 0.043277889490127563\n",
      "Epoch 1414, Loss: 0.1825864389538765, Final Batch Loss: 0.09110032021999359\n",
      "Epoch 1415, Loss: 0.19481754302978516, Final Batch Loss: 0.05927427113056183\n",
      "Epoch 1416, Loss: 0.11932307481765747, Final Batch Loss: 0.046624019742012024\n",
      "Epoch 1417, Loss: 0.1820100173354149, Final Batch Loss: 0.07617495954036713\n",
      "Epoch 1418, Loss: 0.12709276750683784, Final Batch Loss: 0.0649806559085846\n",
      "Epoch 1419, Loss: 0.12180163711309433, Final Batch Loss: 0.059199199080467224\n",
      "Epoch 1420, Loss: 0.11509785801172256, Final Batch Loss: 0.07516293227672577\n",
      "Epoch 1421, Loss: 0.13596175238490105, Final Batch Loss: 0.08805657923221588\n",
      "Epoch 1422, Loss: 0.16382967680692673, Final Batch Loss: 0.09473352134227753\n",
      "Epoch 1423, Loss: 0.14044060558080673, Final Batch Loss: 0.08057297021150589\n",
      "Epoch 1424, Loss: 0.20403368026018143, Final Batch Loss: 0.13708648085594177\n",
      "Epoch 1425, Loss: 0.12658652290701866, Final Batch Loss: 0.03170279040932655\n",
      "Epoch 1426, Loss: 0.12866031751036644, Final Batch Loss: 0.08182334899902344\n",
      "Epoch 1427, Loss: 0.1386331021785736, Final Batch Loss: 0.07000231742858887\n",
      "Epoch 1428, Loss: 0.21544456854462624, Final Batch Loss: 0.16050803661346436\n",
      "Epoch 1429, Loss: 0.12435572221875191, Final Batch Loss: 0.06233398988842964\n",
      "Epoch 1430, Loss: 0.10699425265192986, Final Batch Loss: 0.03119971975684166\n",
      "Epoch 1431, Loss: 0.11841466650366783, Final Batch Loss: 0.06086158752441406\n",
      "Epoch 1432, Loss: 0.09583764523267746, Final Batch Loss: 0.037149425595998764\n",
      "Epoch 1433, Loss: 0.12743262201547623, Final Batch Loss: 0.0739736333489418\n",
      "Epoch 1434, Loss: 0.12731754034757614, Final Batch Loss: 0.08622756600379944\n",
      "Epoch 1435, Loss: 0.1315423958003521, Final Batch Loss: 0.06949606537818909\n",
      "Epoch 1436, Loss: 0.10495465248823166, Final Batch Loss: 0.03233986347913742\n",
      "Epoch 1437, Loss: 0.10787681117653847, Final Batch Loss: 0.0439751110970974\n",
      "Epoch 1438, Loss: 0.14977025613188744, Final Batch Loss: 0.05903281643986702\n",
      "Epoch 1439, Loss: 0.16943541169166565, Final Batch Loss: 0.10329467058181763\n",
      "Epoch 1440, Loss: 0.14273255318403244, Final Batch Loss: 0.07221981883049011\n",
      "Epoch 1441, Loss: 0.16242074966430664, Final Batch Loss: 0.06840795278549194\n",
      "Epoch 1442, Loss: 0.12609875947237015, Final Batch Loss: 0.06235272437334061\n",
      "Epoch 1443, Loss: 0.11302920430898666, Final Batch Loss: 0.04553154855966568\n",
      "Epoch 1444, Loss: 0.1729009933769703, Final Batch Loss: 0.11565131694078445\n",
      "Epoch 1445, Loss: 0.1714821308851242, Final Batch Loss: 0.09631258249282837\n",
      "Epoch 1446, Loss: 0.10996851697564125, Final Batch Loss: 0.05295954644680023\n",
      "Epoch 1447, Loss: 0.16788896173238754, Final Batch Loss: 0.10095042735338211\n",
      "Epoch 1448, Loss: 0.17988768219947815, Final Batch Loss: 0.08142244070768356\n",
      "Epoch 1449, Loss: 0.12793777510523796, Final Batch Loss: 0.07580317556858063\n",
      "Epoch 1450, Loss: 0.13400659710168839, Final Batch Loss: 0.0662485733628273\n",
      "Epoch 1451, Loss: 0.14496199041604996, Final Batch Loss: 0.06888798624277115\n",
      "Epoch 1452, Loss: 0.1247931681573391, Final Batch Loss: 0.06234723702073097\n",
      "Epoch 1453, Loss: 0.1445859558880329, Final Batch Loss: 0.05663389340043068\n",
      "Epoch 1454, Loss: 0.124785415828228, Final Batch Loss: 0.0797903761267662\n",
      "Epoch 1455, Loss: 0.15943600237369537, Final Batch Loss: 0.07411305606365204\n",
      "Epoch 1456, Loss: 0.1329903081059456, Final Batch Loss: 0.05673632025718689\n",
      "Epoch 1457, Loss: 0.14543693512678146, Final Batch Loss: 0.07776010781526566\n",
      "Epoch 1458, Loss: 0.10938507318496704, Final Batch Loss: 0.03991106152534485\n",
      "Epoch 1459, Loss: 0.13039583340287209, Final Batch Loss: 0.07604821026325226\n",
      "Epoch 1460, Loss: 0.17078959196805954, Final Batch Loss: 0.07843992859125137\n",
      "Epoch 1461, Loss: 0.1972879245877266, Final Batch Loss: 0.1071849912405014\n",
      "Epoch 1462, Loss: 0.09935195744037628, Final Batch Loss: 0.039314210414886475\n",
      "Epoch 1463, Loss: 0.1332516260445118, Final Batch Loss: 0.059034693986177444\n",
      "Epoch 1464, Loss: 0.136478029191494, Final Batch Loss: 0.06624581664800644\n",
      "Epoch 1465, Loss: 0.13809753954410553, Final Batch Loss: 0.0728243887424469\n",
      "Epoch 1466, Loss: 0.19314652681350708, Final Batch Loss: 0.10338544845581055\n",
      "Epoch 1467, Loss: 0.18064366281032562, Final Batch Loss: 0.06534974277019501\n",
      "Epoch 1468, Loss: 0.1292191706597805, Final Batch Loss: 0.037485864013433456\n",
      "Epoch 1469, Loss: 0.15329183638095856, Final Batch Loss: 0.0791536271572113\n",
      "Epoch 1470, Loss: 0.11363424360752106, Final Batch Loss: 0.0474805012345314\n",
      "Epoch 1471, Loss: 0.20115464180707932, Final Batch Loss: 0.14017629623413086\n",
      "Epoch 1472, Loss: 0.1442892774939537, Final Batch Loss: 0.07376748323440552\n",
      "Epoch 1473, Loss: 0.1382608264684677, Final Batch Loss: 0.07032207399606705\n",
      "Epoch 1474, Loss: 0.14943454414606094, Final Batch Loss: 0.0837046355009079\n",
      "Epoch 1475, Loss: 0.1194167509675026, Final Batch Loss: 0.04266752302646637\n",
      "Epoch 1476, Loss: 0.13066432625055313, Final Batch Loss: 0.06430388242006302\n",
      "Epoch 1477, Loss: 0.17410965263843536, Final Batch Loss: 0.09155090153217316\n",
      "Epoch 1478, Loss: 0.20313521474599838, Final Batch Loss: 0.07787766307592392\n",
      "Epoch 1479, Loss: 0.1321232095360756, Final Batch Loss: 0.06815881282091141\n",
      "Epoch 1480, Loss: 0.18709629401564598, Final Batch Loss: 0.06007557734847069\n",
      "Epoch 1481, Loss: 0.1488638035953045, Final Batch Loss: 0.09131055325269699\n",
      "Epoch 1482, Loss: 0.13608870655298233, Final Batch Loss: 0.06774812936782837\n",
      "Epoch 1483, Loss: 0.13687323033809662, Final Batch Loss: 0.07419431954622269\n",
      "Epoch 1484, Loss: 0.12911273166537285, Final Batch Loss: 0.08417607098817825\n",
      "Epoch 1485, Loss: 0.15343672037124634, Final Batch Loss: 0.08351679891347885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1486, Loss: 0.1548592671751976, Final Batch Loss: 0.07276662439107895\n",
      "Epoch 1487, Loss: 0.09263934195041656, Final Batch Loss: 0.042506467550992966\n",
      "Epoch 1488, Loss: 0.12425780296325684, Final Batch Loss: 0.047682985663414\n",
      "Epoch 1489, Loss: 0.11227011680603027, Final Batch Loss: 0.046666860580444336\n",
      "Epoch 1490, Loss: 0.09891847521066666, Final Batch Loss: 0.04897305369377136\n",
      "Epoch 1491, Loss: 0.14019333943724632, Final Batch Loss: 0.047779981046915054\n",
      "Epoch 1492, Loss: 0.11662238836288452, Final Batch Loss: 0.04160648584365845\n",
      "Epoch 1493, Loss: 0.13771896064281464, Final Batch Loss: 0.07388724386692047\n",
      "Epoch 1494, Loss: 0.12518134713172913, Final Batch Loss: 0.04277241230010986\n",
      "Epoch 1495, Loss: 0.13639070093631744, Final Batch Loss: 0.08754928410053253\n",
      "Epoch 1496, Loss: 0.11550295352935791, Final Batch Loss: 0.05699281767010689\n",
      "Epoch 1497, Loss: 0.11273658275604248, Final Batch Loss: 0.0547100268304348\n",
      "Epoch 1498, Loss: 0.11414016783237457, Final Batch Loss: 0.047106944024562836\n",
      "Epoch 1499, Loss: 0.18463754653930664, Final Batch Loss: 0.06283339858055115\n",
      "Epoch 1500, Loss: 0.1246441937983036, Final Batch Loss: 0.05074083432555199\n",
      "Epoch 1501, Loss: 0.11400416493415833, Final Batch Loss: 0.05552754923701286\n",
      "Epoch 1502, Loss: 0.14145050197839737, Final Batch Loss: 0.07576682418584824\n",
      "Epoch 1503, Loss: 0.11288519948720932, Final Batch Loss: 0.06692530959844589\n",
      "Epoch 1504, Loss: 0.1258549802005291, Final Batch Loss: 0.06667199730873108\n",
      "Epoch 1505, Loss: 0.1382918916642666, Final Batch Loss: 0.07592959702014923\n",
      "Epoch 1506, Loss: 0.14660333096981049, Final Batch Loss: 0.08531107753515244\n",
      "Epoch 1507, Loss: 0.17288349568843842, Final Batch Loss: 0.1003875657916069\n",
      "Epoch 1508, Loss: 0.10804718732833862, Final Batch Loss: 0.03678704798221588\n",
      "Epoch 1509, Loss: 0.12259377911686897, Final Batch Loss: 0.05874015763401985\n",
      "Epoch 1510, Loss: 0.1413446068763733, Final Batch Loss: 0.07086654007434845\n",
      "Epoch 1511, Loss: 0.13856196030974388, Final Batch Loss: 0.09084853529930115\n",
      "Epoch 1512, Loss: 0.11224274709820747, Final Batch Loss: 0.041921209543943405\n",
      "Epoch 1513, Loss: 0.10230341926217079, Final Batch Loss: 0.057946573942899704\n",
      "Epoch 1514, Loss: 0.1253928318619728, Final Batch Loss: 0.06281700730323792\n",
      "Epoch 1515, Loss: 0.12574058771133423, Final Batch Loss: 0.045185744762420654\n",
      "Epoch 1516, Loss: 0.13181418180465698, Final Batch Loss: 0.04839511215686798\n",
      "Epoch 1517, Loss: 0.1294538788497448, Final Batch Loss: 0.06116999313235283\n",
      "Epoch 1518, Loss: 0.1266646310687065, Final Batch Loss: 0.07518863677978516\n",
      "Epoch 1519, Loss: 0.12026353925466537, Final Batch Loss: 0.05663543939590454\n",
      "Epoch 1520, Loss: 0.10285349190235138, Final Batch Loss: 0.051455799490213394\n",
      "Epoch 1521, Loss: 0.1134008839726448, Final Batch Loss: 0.0661582499742508\n",
      "Epoch 1522, Loss: 0.12856897711753845, Final Batch Loss: 0.061113156378269196\n",
      "Epoch 1523, Loss: 0.1277700550854206, Final Batch Loss: 0.0538252554833889\n",
      "Epoch 1524, Loss: 0.11209233850240707, Final Batch Loss: 0.046461351215839386\n",
      "Epoch 1525, Loss: 0.12131409347057343, Final Batch Loss: 0.07012934237718582\n",
      "Epoch 1526, Loss: 0.18499546498060226, Final Batch Loss: 0.10272480547428131\n",
      "Epoch 1527, Loss: 0.10068711265921593, Final Batch Loss: 0.05025970935821533\n",
      "Epoch 1528, Loss: 0.10529916360974312, Final Batch Loss: 0.04360691085457802\n",
      "Epoch 1529, Loss: 0.15752117335796356, Final Batch Loss: 0.08558820933103561\n",
      "Epoch 1530, Loss: 0.10248154774308205, Final Batch Loss: 0.04650716856122017\n",
      "Epoch 1531, Loss: 0.12436191737651825, Final Batch Loss: 0.04753682762384415\n",
      "Epoch 1532, Loss: 0.14436984062194824, Final Batch Loss: 0.07132770121097565\n",
      "Epoch 1533, Loss: 0.34414392709732056, Final Batch Loss: 0.039451271295547485\n",
      "Epoch 1534, Loss: 0.12802518159151077, Final Batch Loss: 0.052026987075805664\n",
      "Epoch 1535, Loss: 0.1327430158853531, Final Batch Loss: 0.06781049817800522\n",
      "Epoch 1536, Loss: 0.10914366319775581, Final Batch Loss: 0.0676242783665657\n",
      "Epoch 1537, Loss: 0.09714610874652863, Final Batch Loss: 0.04402535408735275\n",
      "Epoch 1538, Loss: 0.08674160577356815, Final Batch Loss: 0.01822749711573124\n",
      "Epoch 1539, Loss: 0.1250661537051201, Final Batch Loss: 0.08177108317613602\n",
      "Epoch 1540, Loss: 0.08877569437026978, Final Batch Loss: 0.042987797409296036\n",
      "Epoch 1541, Loss: 0.12833844125270844, Final Batch Loss: 0.07783656567335129\n",
      "Epoch 1542, Loss: 0.1361416131258011, Final Batch Loss: 0.07127445191144943\n",
      "Epoch 1543, Loss: 0.12298846989870071, Final Batch Loss: 0.07408249378204346\n",
      "Epoch 1544, Loss: 0.11526983603835106, Final Batch Loss: 0.06286502629518509\n",
      "Epoch 1545, Loss: 0.12871870771050453, Final Batch Loss: 0.04062666371464729\n",
      "Epoch 1546, Loss: 0.09537388011813164, Final Batch Loss: 0.04887109622359276\n",
      "Epoch 1547, Loss: 0.1020982600748539, Final Batch Loss: 0.04776328057050705\n",
      "Epoch 1548, Loss: 0.12230413034558296, Final Batch Loss: 0.06068635359406471\n",
      "Epoch 1549, Loss: 0.12738868966698647, Final Batch Loss: 0.0885545089840889\n",
      "Epoch 1550, Loss: 0.08427131548523903, Final Batch Loss: 0.043355509638786316\n",
      "Epoch 1551, Loss: 0.14108889549970627, Final Batch Loss: 0.08295120298862457\n",
      "Epoch 1552, Loss: 0.20265111327171326, Final Batch Loss: 0.14480987191200256\n",
      "Epoch 1553, Loss: 0.16687177121639252, Final Batch Loss: 0.09765072166919708\n",
      "Epoch 1554, Loss: 0.11672614514827728, Final Batch Loss: 0.06974192708730698\n",
      "Epoch 1555, Loss: 0.11294605955481529, Final Batch Loss: 0.06191270425915718\n",
      "Epoch 1556, Loss: 0.125381700694561, Final Batch Loss: 0.06134267896413803\n",
      "Epoch 1557, Loss: 0.12461826950311661, Final Batch Loss: 0.0981404110789299\n",
      "Epoch 1558, Loss: 0.11751729249954224, Final Batch Loss: 0.05839615687727928\n",
      "Epoch 1559, Loss: 0.12244613468647003, Final Batch Loss: 0.05959828197956085\n",
      "Epoch 1560, Loss: 0.09811806306242943, Final Batch Loss: 0.04726172611117363\n",
      "Epoch 1561, Loss: 0.12583652883768082, Final Batch Loss: 0.06271708756685257\n",
      "Epoch 1562, Loss: 0.10438204184174538, Final Batch Loss: 0.07157602161169052\n",
      "Epoch 1563, Loss: 0.15074202418327332, Final Batch Loss: 0.10164806991815567\n",
      "Epoch 1564, Loss: 0.1150573268532753, Final Batch Loss: 0.07411705702543259\n",
      "Epoch 1565, Loss: 0.11783409118652344, Final Batch Loss: 0.04536806046962738\n",
      "Epoch 1566, Loss: 0.12378855794668198, Final Batch Loss: 0.06173919141292572\n",
      "Epoch 1567, Loss: 0.17209887504577637, Final Batch Loss: 0.09087388217449188\n",
      "Epoch 1568, Loss: 0.0976690836250782, Final Batch Loss: 0.06049097701907158\n",
      "Epoch 1569, Loss: 0.18294178694486618, Final Batch Loss: 0.08568311482667923\n",
      "Epoch 1570, Loss: 0.08354967087507248, Final Batch Loss: 0.03234958276152611\n",
      "Epoch 1571, Loss: 0.1052185706794262, Final Batch Loss: 0.04286975413560867\n",
      "Epoch 1572, Loss: 0.18146000802516937, Final Batch Loss: 0.08193990588188171\n",
      "Epoch 1573, Loss: 0.11837499961256981, Final Batch Loss: 0.06950945407152176\n",
      "Epoch 1574, Loss: 0.13309074565768242, Final Batch Loss: 0.07425463944673538\n",
      "Epoch 1575, Loss: 0.11912349238991737, Final Batch Loss: 0.0702119916677475\n",
      "Epoch 1576, Loss: 0.09456571936607361, Final Batch Loss: 0.025294460356235504\n",
      "Epoch 1577, Loss: 0.0852217748761177, Final Batch Loss: 0.021224811673164368\n",
      "Epoch 1578, Loss: 0.09928800538182259, Final Batch Loss: 0.05137920752167702\n",
      "Epoch 1579, Loss: 0.11675916612148285, Final Batch Loss: 0.03720270097255707\n",
      "Epoch 1580, Loss: 0.08357919752597809, Final Batch Loss: 0.03128994628787041\n",
      "Epoch 1581, Loss: 0.09392969310283661, Final Batch Loss: 0.06238562986254692\n",
      "Epoch 1582, Loss: 0.08270217478275299, Final Batch Loss: 0.043738849461078644\n",
      "Epoch 1583, Loss: 0.11685885861515999, Final Batch Loss: 0.057570114731788635\n",
      "Epoch 1584, Loss: 0.14535705000162125, Final Batch Loss: 0.08129860460758209\n",
      "Epoch 1585, Loss: 0.08980917185544968, Final Batch Loss: 0.04655396193265915\n",
      "Epoch 1586, Loss: 0.09465321153402328, Final Batch Loss: 0.04926179721951485\n",
      "Epoch 1587, Loss: 0.09352276474237442, Final Batch Loss: 0.03651488199830055\n",
      "Epoch 1588, Loss: 0.07312804833054543, Final Batch Loss: 0.028720572590827942\n",
      "Epoch 1589, Loss: 0.09742476418614388, Final Batch Loss: 0.019707810133695602\n",
      "Epoch 1590, Loss: 0.0904831551015377, Final Batch Loss: 0.04285666346549988\n",
      "Epoch 1591, Loss: 0.15837346389889717, Final Batch Loss: 0.09628120064735413\n",
      "Epoch 1592, Loss: 0.08818717300891876, Final Batch Loss: 0.05394725501537323\n",
      "Epoch 1593, Loss: 0.1536778099834919, Final Batch Loss: 0.09965477883815765\n",
      "Epoch 1594, Loss: 0.07115641236305237, Final Batch Loss: 0.037325579673051834\n",
      "Epoch 1595, Loss: 0.11870917677879333, Final Batch Loss: 0.04668419063091278\n",
      "Epoch 1596, Loss: 0.10411520302295685, Final Batch Loss: 0.06018996983766556\n",
      "Epoch 1597, Loss: 0.15993765741586685, Final Batch Loss: 0.07711968570947647\n",
      "Epoch 1598, Loss: 0.13983553647994995, Final Batch Loss: 0.09118939936161041\n",
      "Epoch 1599, Loss: 0.0948949083685875, Final Batch Loss: 0.041678350418806076\n",
      "Epoch 1600, Loss: 0.14085927605628967, Final Batch Loss: 0.07176367938518524\n",
      "Epoch 1601, Loss: 0.1250366773456335, Final Batch Loss: 0.02721410058438778\n",
      "Epoch 1602, Loss: 0.09699887409806252, Final Batch Loss: 0.030534323304891586\n",
      "Epoch 1603, Loss: 0.10986975952982903, Final Batch Loss: 0.03951587900519371\n",
      "Epoch 1604, Loss: 0.10582979395985603, Final Batch Loss: 0.05031821131706238\n",
      "Epoch 1605, Loss: 0.09966903924942017, Final Batch Loss: 0.03904084116220474\n",
      "Epoch 1606, Loss: 0.08100631088018417, Final Batch Loss: 0.024197883903980255\n",
      "Epoch 1607, Loss: 0.11204961687326431, Final Batch Loss: 0.07193879783153534\n",
      "Epoch 1608, Loss: 0.07501247525215149, Final Batch Loss: 0.03587517514824867\n",
      "Epoch 1609, Loss: 0.09463370218873024, Final Batch Loss: 0.04826430231332779\n",
      "Epoch 1610, Loss: 0.08417009934782982, Final Batch Loss: 0.05273377150297165\n",
      "Epoch 1611, Loss: 0.10532686859369278, Final Batch Loss: 0.06034701317548752\n",
      "Epoch 1612, Loss: 0.0886488389223814, Final Batch Loss: 0.062061455100774765\n",
      "Epoch 1613, Loss: 0.13658009096980095, Final Batch Loss: 0.0539761520922184\n",
      "Epoch 1614, Loss: 0.12728694453835487, Final Batch Loss: 0.05228985473513603\n",
      "Epoch 1615, Loss: 0.09359833598136902, Final Batch Loss: 0.0519045889377594\n",
      "Epoch 1616, Loss: 0.1041829027235508, Final Batch Loss: 0.03865479305386543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1617, Loss: 0.09584222733974457, Final Batch Loss: 0.04514574259519577\n",
      "Epoch 1618, Loss: 0.12073096260428429, Final Batch Loss: 0.056543175131082535\n",
      "Epoch 1619, Loss: 0.11128251627087593, Final Batch Loss: 0.0482739619910717\n",
      "Epoch 1620, Loss: 0.13736513257026672, Final Batch Loss: 0.06711581349372864\n",
      "Epoch 1621, Loss: 0.0862400233745575, Final Batch Loss: 0.029767248779535294\n",
      "Epoch 1622, Loss: 0.0777219869196415, Final Batch Loss: 0.04381096363067627\n",
      "Epoch 1623, Loss: 0.1075969822704792, Final Batch Loss: 0.04590225964784622\n",
      "Epoch 1624, Loss: 0.09841027855873108, Final Batch Loss: 0.05030665919184685\n",
      "Epoch 1625, Loss: 0.1418340876698494, Final Batch Loss: 0.07833843678236008\n",
      "Epoch 1626, Loss: 0.16405852884054184, Final Batch Loss: 0.06767060607671738\n",
      "Epoch 1627, Loss: 0.12275281921029091, Final Batch Loss: 0.07998419553041458\n",
      "Epoch 1628, Loss: 0.11797646060585976, Final Batch Loss: 0.06839971989393234\n",
      "Epoch 1629, Loss: 0.08623353019356728, Final Batch Loss: 0.04907083138823509\n",
      "Epoch 1630, Loss: 0.072937723249197, Final Batch Loss: 0.021896842867136\n",
      "Epoch 1631, Loss: 0.11868488788604736, Final Batch Loss: 0.04562358558177948\n",
      "Epoch 1632, Loss: 0.10787920653820038, Final Batch Loss: 0.03855213522911072\n",
      "Epoch 1633, Loss: 0.08846199885010719, Final Batch Loss: 0.037737466394901276\n",
      "Epoch 1634, Loss: 0.1183386817574501, Final Batch Loss: 0.06815226376056671\n",
      "Epoch 1635, Loss: 0.08160584047436714, Final Batch Loss: 0.043118055909872055\n",
      "Epoch 1636, Loss: 0.13668584823608398, Final Batch Loss: 0.05259118974208832\n",
      "Epoch 1637, Loss: 0.14619404077529907, Final Batch Loss: 0.07450012117624283\n",
      "Epoch 1638, Loss: 0.08176523447036743, Final Batch Loss: 0.040601834654808044\n",
      "Epoch 1639, Loss: 0.1308635175228119, Final Batch Loss: 0.06006369739770889\n",
      "Epoch 1640, Loss: 0.08394904062151909, Final Batch Loss: 0.03857004642486572\n",
      "Epoch 1641, Loss: 0.09434549883008003, Final Batch Loss: 0.04409719258546829\n",
      "Epoch 1642, Loss: 0.10021672025322914, Final Batch Loss: 0.05348129943013191\n",
      "Epoch 1643, Loss: 0.1323520503938198, Final Batch Loss: 0.05033925548195839\n",
      "Epoch 1644, Loss: 0.13708055019378662, Final Batch Loss: 0.09521105140447617\n",
      "Epoch 1645, Loss: 0.10460291802883148, Final Batch Loss: 0.06286384165287018\n",
      "Epoch 1646, Loss: 0.1293787769973278, Final Batch Loss: 0.04135318472981453\n",
      "Epoch 1647, Loss: 0.0795079879462719, Final Batch Loss: 0.03204081580042839\n",
      "Epoch 1648, Loss: 0.11730585619807243, Final Batch Loss: 0.07305851578712463\n",
      "Epoch 1649, Loss: 0.09886728599667549, Final Batch Loss: 0.043162595480680466\n",
      "Epoch 1650, Loss: 0.11073541268706322, Final Batch Loss: 0.07895316928625107\n",
      "Epoch 1651, Loss: 0.12123507633805275, Final Batch Loss: 0.07654215395450592\n",
      "Epoch 1652, Loss: 0.08667000010609627, Final Batch Loss: 0.025171976536512375\n",
      "Epoch 1653, Loss: 0.08266371116042137, Final Batch Loss: 0.032876040786504745\n",
      "Epoch 1654, Loss: 0.07008469477295876, Final Batch Loss: 0.023049257695674896\n",
      "Epoch 1655, Loss: 0.0682748332619667, Final Batch Loss: 0.03579988330602646\n",
      "Epoch 1656, Loss: 0.1672603040933609, Final Batch Loss: 0.10903988033533096\n",
      "Epoch 1657, Loss: 0.11683599650859833, Final Batch Loss: 0.07061456888914108\n",
      "Epoch 1658, Loss: 0.16432815045118332, Final Batch Loss: 0.07877638190984726\n",
      "Epoch 1659, Loss: 0.08214734122157097, Final Batch Loss: 0.03769836202263832\n",
      "Epoch 1660, Loss: 0.09208788722753525, Final Batch Loss: 0.032150980085134506\n",
      "Epoch 1661, Loss: 0.10235808044672012, Final Batch Loss: 0.054164983332157135\n",
      "Epoch 1662, Loss: 0.09548470750451088, Final Batch Loss: 0.018955815583467484\n",
      "Epoch 1663, Loss: 0.07653597369790077, Final Batch Loss: 0.03879007324576378\n",
      "Epoch 1664, Loss: 0.15198466926813126, Final Batch Loss: 0.09315883368253708\n",
      "Epoch 1665, Loss: 0.07482057996094227, Final Batch Loss: 0.02842753939330578\n",
      "Epoch 1666, Loss: 0.11487439274787903, Final Batch Loss: 0.07480086386203766\n",
      "Epoch 1667, Loss: 0.25696753710508347, Final Batch Loss: 0.1751480996608734\n",
      "Epoch 1668, Loss: 0.13398213684558868, Final Batch Loss: 0.05219218134880066\n",
      "Epoch 1669, Loss: 0.07475262135267258, Final Batch Loss: 0.029966503381729126\n",
      "Epoch 1670, Loss: 0.12292030081152916, Final Batch Loss: 0.07374785095453262\n",
      "Epoch 1671, Loss: 0.14463844895362854, Final Batch Loss: 0.05713683366775513\n",
      "Epoch 1672, Loss: 0.08857328817248344, Final Batch Loss: 0.051311787217855453\n",
      "Epoch 1673, Loss: 0.12839966267347336, Final Batch Loss: 0.05106012523174286\n",
      "Epoch 1674, Loss: 0.08557866513729095, Final Batch Loss: 0.0443929024040699\n",
      "Epoch 1675, Loss: 0.22036220878362656, Final Batch Loss: 0.13881850242614746\n",
      "Epoch 1676, Loss: 0.14310838282108307, Final Batch Loss: 0.036196351051330566\n",
      "Epoch 1677, Loss: 0.08711301162838936, Final Batch Loss: 0.04638098552823067\n",
      "Epoch 1678, Loss: 0.11844919994473457, Final Batch Loss: 0.08074194192886353\n",
      "Epoch 1679, Loss: 0.09042414277791977, Final Batch Loss: 0.04924923926591873\n",
      "Epoch 1680, Loss: 0.14453298598527908, Final Batch Loss: 0.08547208458185196\n",
      "Epoch 1681, Loss: 0.10155177116394043, Final Batch Loss: 0.032385505735874176\n",
      "Epoch 1682, Loss: 0.08997967652976513, Final Batch Loss: 0.021416841074824333\n",
      "Epoch 1683, Loss: 0.07098197564482689, Final Batch Loss: 0.03435783460736275\n",
      "Epoch 1684, Loss: 0.10564323328435421, Final Batch Loss: 0.07660870999097824\n",
      "Epoch 1685, Loss: 0.13649943470954895, Final Batch Loss: 0.04904061555862427\n",
      "Epoch 1686, Loss: 0.1735134720802307, Final Batch Loss: 0.08376290649175644\n",
      "Epoch 1687, Loss: 0.13025376945734024, Final Batch Loss: 0.06620143353939056\n",
      "Epoch 1688, Loss: 0.10422590374946594, Final Batch Loss: 0.0488031730055809\n",
      "Epoch 1689, Loss: 0.10589924827218056, Final Batch Loss: 0.06423153728246689\n",
      "Epoch 1690, Loss: 0.13301041722297668, Final Batch Loss: 0.03777741640806198\n",
      "Epoch 1691, Loss: 0.16586921364068985, Final Batch Loss: 0.0821710079908371\n",
      "Epoch 1692, Loss: 0.12065499648451805, Final Batch Loss: 0.05055764690041542\n",
      "Epoch 1693, Loss: 0.08469589985907078, Final Batch Loss: 0.06347537040710449\n",
      "Epoch 1694, Loss: 0.11905384063720703, Final Batch Loss: 0.08248195797204971\n",
      "Epoch 1695, Loss: 0.10072819516062737, Final Batch Loss: 0.04111804813146591\n",
      "Epoch 1696, Loss: 0.08704839274287224, Final Batch Loss: 0.05031798779964447\n",
      "Epoch 1697, Loss: 0.13626241870224476, Final Batch Loss: 0.030007818713784218\n",
      "Epoch 1698, Loss: 0.10858316347002983, Final Batch Loss: 0.08273010700941086\n",
      "Epoch 1699, Loss: 0.11249702796339989, Final Batch Loss: 0.05824534595012665\n",
      "Epoch 1700, Loss: 0.08654876425862312, Final Batch Loss: 0.04395516216754913\n",
      "Epoch 1701, Loss: 0.09405486285686493, Final Batch Loss: 0.0441807359457016\n",
      "Epoch 1702, Loss: 0.05900692567229271, Final Batch Loss: 0.01878008246421814\n",
      "Epoch 1703, Loss: 0.0764600858092308, Final Batch Loss: 0.02887016162276268\n",
      "Epoch 1704, Loss: 0.128627248108387, Final Batch Loss: 0.0309746116399765\n",
      "Epoch 1705, Loss: 0.09974807873368263, Final Batch Loss: 0.05482364818453789\n",
      "Epoch 1706, Loss: 0.07459677755832672, Final Batch Loss: 0.037916149944067\n",
      "Epoch 1707, Loss: 0.10028747469186783, Final Batch Loss: 0.038026489317417145\n",
      "Epoch 1708, Loss: 0.08356048539280891, Final Batch Loss: 0.04486330598592758\n",
      "Epoch 1709, Loss: 0.08347319811582565, Final Batch Loss: 0.04258362576365471\n",
      "Epoch 1710, Loss: 0.08818303793668747, Final Batch Loss: 0.04244951903820038\n",
      "Epoch 1711, Loss: 0.23241890221834183, Final Batch Loss: 0.18859286606311798\n",
      "Epoch 1712, Loss: 0.12252546101808548, Final Batch Loss: 0.05644650757312775\n",
      "Epoch 1713, Loss: 0.0936531089246273, Final Batch Loss: 0.04845242574810982\n",
      "Epoch 1714, Loss: 0.11717253923416138, Final Batch Loss: 0.06695019453763962\n",
      "Epoch 1715, Loss: 0.0802731104195118, Final Batch Loss: 0.04723398759961128\n",
      "Epoch 1716, Loss: 0.06524876225739717, Final Batch Loss: 0.005934861488640308\n",
      "Epoch 1717, Loss: 0.06954705715179443, Final Batch Loss: 0.03820936754345894\n",
      "Epoch 1718, Loss: 0.08496549911797047, Final Batch Loss: 0.06352090835571289\n",
      "Epoch 1719, Loss: 0.10825219936668873, Final Batch Loss: 0.02559989131987095\n",
      "Epoch 1720, Loss: 0.10475050657987595, Final Batch Loss: 0.05614452809095383\n",
      "Epoch 1721, Loss: 0.11147653684020042, Final Batch Loss: 0.046039339154958725\n",
      "Epoch 1722, Loss: 0.09289830550551414, Final Batch Loss: 0.02493656799197197\n",
      "Epoch 1723, Loss: 0.091272734105587, Final Batch Loss: 0.05183686316013336\n",
      "Epoch 1724, Loss: 0.09034930542111397, Final Batch Loss: 0.056598953902721405\n",
      "Epoch 1725, Loss: 0.11933507025241852, Final Batch Loss: 0.0740140900015831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1726, Loss: 0.14059317111968994, Final Batch Loss: 0.09337949007749557\n",
      "Epoch 1727, Loss: 0.1586105339229107, Final Batch Loss: 0.10529693216085434\n",
      "Epoch 1728, Loss: 0.0808866024017334, Final Batch Loss: 0.019957616925239563\n",
      "Epoch 1729, Loss: 0.09650056064128876, Final Batch Loss: 0.042612411081790924\n",
      "Epoch 1730, Loss: 0.07981693372130394, Final Batch Loss: 0.031806282699108124\n",
      "Epoch 1731, Loss: 0.09375235438346863, Final Batch Loss: 0.052199918776750565\n",
      "Epoch 1732, Loss: 0.10202112421393394, Final Batch Loss: 0.06671439111232758\n",
      "Epoch 1733, Loss: 0.05280214548110962, Final Batch Loss: 0.024668509140610695\n",
      "Epoch 1734, Loss: 0.09860606491565704, Final Batch Loss: 0.05434811860322952\n",
      "Epoch 1735, Loss: 0.11897343397140503, Final Batch Loss: 0.046878084540367126\n",
      "Epoch 1736, Loss: 0.11873011663556099, Final Batch Loss: 0.060999125242233276\n",
      "Epoch 1737, Loss: 0.1421462558209896, Final Batch Loss: 0.08073870092630386\n",
      "Epoch 1738, Loss: 0.12635333463549614, Final Batch Loss: 0.03677656874060631\n",
      "Epoch 1739, Loss: 0.07575853541493416, Final Batch Loss: 0.04117586463689804\n",
      "Epoch 1740, Loss: 0.08122211880981922, Final Batch Loss: 0.029537072405219078\n",
      "Epoch 1741, Loss: 0.0963999591767788, Final Batch Loss: 0.03314393386244774\n",
      "Epoch 1742, Loss: 0.07373078912496567, Final Batch Loss: 0.04716009274125099\n",
      "Epoch 1743, Loss: 0.06978479400277138, Final Batch Loss: 0.03641689568758011\n",
      "Epoch 1744, Loss: 0.12682828679680824, Final Batch Loss: 0.07313564419746399\n",
      "Epoch 1745, Loss: 0.0679964255541563, Final Batch Loss: 0.038803186267614365\n",
      "Epoch 1746, Loss: 0.12550535425543785, Final Batch Loss: 0.08300533145666122\n",
      "Epoch 1747, Loss: 0.08453681319952011, Final Batch Loss: 0.0526316799223423\n",
      "Epoch 1748, Loss: 0.12943124771118164, Final Batch Loss: 0.08337263017892838\n",
      "Epoch 1749, Loss: 0.06066375784575939, Final Batch Loss: 0.031454022973775864\n",
      "Epoch 1750, Loss: 0.07135211303830147, Final Batch Loss: 0.03157532215118408\n",
      "Epoch 1751, Loss: 0.10866621136665344, Final Batch Loss: 0.03226622939109802\n",
      "Epoch 1752, Loss: 0.08972655981779099, Final Batch Loss: 0.04418758675456047\n",
      "Epoch 1753, Loss: 0.13549581170082092, Final Batch Loss: 0.055374979972839355\n",
      "Epoch 1754, Loss: 0.08229012787342072, Final Batch Loss: 0.034014299511909485\n",
      "Epoch 1755, Loss: 0.10141066461801529, Final Batch Loss: 0.05318201333284378\n",
      "Epoch 1756, Loss: 0.054092058911919594, Final Batch Loss: 0.016238095238804817\n",
      "Epoch 1757, Loss: 0.11593692563474178, Final Batch Loss: 0.023211730644106865\n",
      "Epoch 1758, Loss: 0.1181115210056305, Final Batch Loss: 0.061289507895708084\n",
      "Epoch 1759, Loss: 0.13781239092350006, Final Batch Loss: 0.04195268452167511\n",
      "Epoch 1760, Loss: 0.07604456320405006, Final Batch Loss: 0.019631758332252502\n",
      "Epoch 1761, Loss: 0.05692375265061855, Final Batch Loss: 0.03339224308729172\n",
      "Epoch 1762, Loss: 0.10711739584803581, Final Batch Loss: 0.06807056069374084\n",
      "Epoch 1763, Loss: 0.08974146470427513, Final Batch Loss: 0.04340492561459541\n",
      "Epoch 1764, Loss: 0.13036881759762764, Final Batch Loss: 0.05971882864832878\n",
      "Epoch 1765, Loss: 0.08627496287226677, Final Batch Loss: 0.046013474464416504\n",
      "Epoch 1766, Loss: 0.13027215749025345, Final Batch Loss: 0.05941212922334671\n",
      "Epoch 1767, Loss: 0.12266815081238747, Final Batch Loss: 0.058795567601919174\n",
      "Epoch 1768, Loss: 0.10751430690288544, Final Batch Loss: 0.07188478857278824\n",
      "Epoch 1769, Loss: 0.09839591570198536, Final Batch Loss: 0.024783359840512276\n",
      "Epoch 1770, Loss: 0.09599003940820694, Final Batch Loss: 0.0444774366915226\n",
      "Epoch 1771, Loss: 0.0809051226824522, Final Batch Loss: 0.025172503665089607\n",
      "Epoch 1772, Loss: 0.08601118996739388, Final Batch Loss: 0.04047806188464165\n",
      "Epoch 1773, Loss: 0.07789266295731068, Final Batch Loss: 0.0506327822804451\n",
      "Epoch 1774, Loss: 0.09009579569101334, Final Batch Loss: 0.0558750294148922\n",
      "Epoch 1775, Loss: 0.08094574138522148, Final Batch Loss: 0.037930700927972794\n",
      "Epoch 1776, Loss: 0.10417342185974121, Final Batch Loss: 0.046124417334795\n",
      "Epoch 1777, Loss: 0.09313900396227837, Final Batch Loss: 0.04576463997364044\n",
      "Epoch 1778, Loss: 0.07971938699483871, Final Batch Loss: 0.03322197496891022\n",
      "Epoch 1779, Loss: 0.08870955929160118, Final Batch Loss: 0.055720970034599304\n",
      "Epoch 1780, Loss: 0.07989953085780144, Final Batch Loss: 0.0396314412355423\n",
      "Epoch 1781, Loss: 0.05474863015115261, Final Batch Loss: 0.024870282039046288\n",
      "Epoch 1782, Loss: 0.078175725415349, Final Batch Loss: 0.02966884709894657\n",
      "Epoch 1783, Loss: 0.10722099989652634, Final Batch Loss: 0.05764595791697502\n",
      "Epoch 1784, Loss: 0.08493149653077126, Final Batch Loss: 0.027252819389104843\n",
      "Epoch 1785, Loss: 0.07346698269248009, Final Batch Loss: 0.036227721720933914\n",
      "Epoch 1786, Loss: 0.06435692496597767, Final Batch Loss: 0.02182532288134098\n",
      "Epoch 1787, Loss: 0.07701209560036659, Final Batch Loss: 0.0219515822827816\n",
      "Epoch 1788, Loss: 0.1261301189661026, Final Batch Loss: 0.08389732241630554\n",
      "Epoch 1789, Loss: 0.07979607954621315, Final Batch Loss: 0.046424008905887604\n",
      "Epoch 1790, Loss: 0.10237275809049606, Final Batch Loss: 0.04383828490972519\n",
      "Epoch 1791, Loss: 0.06937983818352222, Final Batch Loss: 0.038510244339704514\n",
      "Epoch 1792, Loss: 0.0743902251124382, Final Batch Loss: 0.03376815840601921\n",
      "Epoch 1793, Loss: 0.12160224467515945, Final Batch Loss: 0.06211952492594719\n",
      "Epoch 1794, Loss: 0.05657476745545864, Final Batch Loss: 0.02787289209663868\n",
      "Epoch 1795, Loss: 0.0687105543911457, Final Batch Loss: 0.03328753262758255\n",
      "Epoch 1796, Loss: 0.07571960985660553, Final Batch Loss: 0.03482409939169884\n",
      "Epoch 1797, Loss: 0.0991717129945755, Final Batch Loss: 0.05476460978388786\n",
      "Epoch 1798, Loss: 0.08510958217084408, Final Batch Loss: 0.059532757848501205\n",
      "Epoch 1799, Loss: 0.05870857089757919, Final Batch Loss: 0.03180177882313728\n",
      "Epoch 1800, Loss: 0.13637477159500122, Final Batch Loss: 0.06594227999448776\n",
      "Epoch 1801, Loss: 0.06177892908453941, Final Batch Loss: 0.022326219826936722\n",
      "Epoch 1802, Loss: 0.16497565805912018, Final Batch Loss: 0.10454772412776947\n",
      "Epoch 1803, Loss: 0.07391984760761261, Final Batch Loss: 0.045693427324295044\n",
      "Epoch 1804, Loss: 0.054118094965815544, Final Batch Loss: 0.01640155352652073\n",
      "Epoch 1805, Loss: 0.0911162756383419, Final Batch Loss: 0.05294404551386833\n",
      "Epoch 1806, Loss: 0.08368805050849915, Final Batch Loss: 0.05150206759572029\n",
      "Epoch 1807, Loss: 0.09105910547077656, Final Batch Loss: 0.02689007855951786\n",
      "Epoch 1808, Loss: 0.2047068551182747, Final Batch Loss: 0.13872548937797546\n",
      "Epoch 1809, Loss: 0.08519822359085083, Final Batch Loss: 0.047544095665216446\n",
      "Epoch 1810, Loss: 0.10976896435022354, Final Batch Loss: 0.0586971715092659\n",
      "Epoch 1811, Loss: 0.08368795365095139, Final Batch Loss: 0.05033871904015541\n",
      "Epoch 1812, Loss: 0.20471281558275223, Final Batch Loss: 0.1350921392440796\n",
      "Epoch 1813, Loss: 0.05738644674420357, Final Batch Loss: 0.040509000420570374\n",
      "Epoch 1814, Loss: 0.1281728446483612, Final Batch Loss: 0.06630676239728928\n",
      "Epoch 1815, Loss: 0.08626386895775795, Final Batch Loss: 0.05669690668582916\n",
      "Epoch 1816, Loss: 0.0745941512286663, Final Batch Loss: 0.037523239850997925\n",
      "Epoch 1817, Loss: 0.10423947125673294, Final Batch Loss: 0.058417562395334244\n",
      "Epoch 1818, Loss: 0.17773357033729553, Final Batch Loss: 0.10291927307844162\n",
      "Epoch 1819, Loss: 0.10533567890524864, Final Batch Loss: 0.06489796191453934\n",
      "Epoch 1820, Loss: 0.14082278311252594, Final Batch Loss: 0.07138827443122864\n",
      "Epoch 1821, Loss: 0.07366901636123657, Final Batch Loss: 0.031967297196388245\n",
      "Epoch 1822, Loss: 0.12181971967220306, Final Batch Loss: 0.07090391963720322\n",
      "Epoch 1823, Loss: 0.11378279700875282, Final Batch Loss: 0.07259804010391235\n",
      "Epoch 1824, Loss: 0.1290506199002266, Final Batch Loss: 0.04665597528219223\n",
      "Epoch 1825, Loss: 0.1031247153878212, Final Batch Loss: 0.04714516922831535\n",
      "Epoch 1826, Loss: 0.09198522195219994, Final Batch Loss: 0.047693610191345215\n",
      "Epoch 1827, Loss: 0.1091516986489296, Final Batch Loss: 0.05850031226873398\n",
      "Epoch 1828, Loss: 0.08330903947353363, Final Batch Loss: 0.025300148874521255\n",
      "Epoch 1829, Loss: 0.07752400450408459, Final Batch Loss: 0.029157964512705803\n",
      "Epoch 1830, Loss: 0.1169724240899086, Final Batch Loss: 0.06487805396318436\n",
      "Epoch 1831, Loss: 0.08967826142907143, Final Batch Loss: 0.04532723128795624\n",
      "Epoch 1832, Loss: 0.1934855431318283, Final Batch Loss: 0.12750118970870972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1833, Loss: 0.11071943119168282, Final Batch Loss: 0.046008575707674026\n",
      "Epoch 1834, Loss: 0.08683663234114647, Final Batch Loss: 0.06509795039892197\n",
      "Epoch 1835, Loss: 0.07792152278125286, Final Batch Loss: 0.0508866049349308\n",
      "Epoch 1836, Loss: 0.16452762484550476, Final Batch Loss: 0.09874529391527176\n",
      "Epoch 1837, Loss: 0.08399427868425846, Final Batch Loss: 0.06528552621603012\n",
      "Epoch 1838, Loss: 0.15028172731399536, Final Batch Loss: 0.08280698210000992\n",
      "Epoch 1839, Loss: 0.11006230860948563, Final Batch Loss: 0.05576154217123985\n",
      "Epoch 1840, Loss: 0.1478673219680786, Final Batch Loss: 0.07293723523616791\n",
      "Epoch 1841, Loss: 0.05880734883248806, Final Batch Loss: 0.030600568279623985\n",
      "Epoch 1842, Loss: 0.12219801545143127, Final Batch Loss: 0.07080937176942825\n",
      "Epoch 1843, Loss: 0.0770852379500866, Final Batch Loss: 0.052548643201589584\n",
      "Epoch 1844, Loss: 0.16311375051736832, Final Batch Loss: 0.07910623401403427\n",
      "Epoch 1845, Loss: 0.11534860730171204, Final Batch Loss: 0.058072421699762344\n",
      "Epoch 1846, Loss: 0.09575497359037399, Final Batch Loss: 0.04765892028808594\n",
      "Epoch 1847, Loss: 0.0628542099148035, Final Batch Loss: 0.017488552257418633\n",
      "Epoch 1848, Loss: 0.06872129999101162, Final Batch Loss: 0.02734752558171749\n",
      "Epoch 1849, Loss: 0.13983915746212006, Final Batch Loss: 0.1119208037853241\n",
      "Epoch 1850, Loss: 0.10304601490497589, Final Batch Loss: 0.07776427268981934\n",
      "Epoch 1851, Loss: 0.05107859801501036, Final Batch Loss: 0.012620708905160427\n",
      "Epoch 1852, Loss: 0.06971758976578712, Final Batch Loss: 0.033155787736177444\n",
      "Epoch 1853, Loss: 0.1495930179953575, Final Batch Loss: 0.08790136128664017\n",
      "Epoch 1854, Loss: 0.08837622404098511, Final Batch Loss: 0.04501114785671234\n",
      "Epoch 1855, Loss: 0.08175083622336388, Final Batch Loss: 0.027351118624210358\n",
      "Epoch 1856, Loss: 0.11157691851258278, Final Batch Loss: 0.07567228376865387\n",
      "Epoch 1857, Loss: 0.0950988419353962, Final Batch Loss: 0.028763387352228165\n",
      "Epoch 1858, Loss: 0.15508932620286942, Final Batch Loss: 0.09139479696750641\n",
      "Epoch 1859, Loss: 0.10966159775853157, Final Batch Loss: 0.05889468640089035\n",
      "Epoch 1860, Loss: 0.08380493894219398, Final Batch Loss: 0.04749984294176102\n",
      "Epoch 1861, Loss: 0.0544667337089777, Final Batch Loss: 0.020460011437535286\n",
      "Epoch 1862, Loss: 0.07541108690202236, Final Batch Loss: 0.027869513258337975\n",
      "Epoch 1863, Loss: 0.10436532646417618, Final Batch Loss: 0.062411725521087646\n",
      "Epoch 1864, Loss: 0.05415510758757591, Final Batch Loss: 0.026113415136933327\n",
      "Epoch 1865, Loss: 0.05377249885350466, Final Batch Loss: 0.01403664518147707\n",
      "Epoch 1866, Loss: 0.14317389950156212, Final Batch Loss: 0.09155090153217316\n",
      "Epoch 1867, Loss: 0.08385297283530235, Final Batch Loss: 0.044476669281721115\n",
      "Epoch 1868, Loss: 0.13232115656137466, Final Batch Loss: 0.08138024061918259\n",
      "Epoch 1869, Loss: 0.060131071135401726, Final Batch Loss: 0.03795362263917923\n",
      "Epoch 1870, Loss: 0.08261868730187416, Final Batch Loss: 0.04910169541835785\n",
      "Epoch 1871, Loss: 0.07951760664582253, Final Batch Loss: 0.033949144184589386\n",
      "Epoch 1872, Loss: 0.17361070588231087, Final Batch Loss: 0.1369599550962448\n",
      "Epoch 1873, Loss: 0.0730336382985115, Final Batch Loss: 0.033074598759412766\n",
      "Epoch 1874, Loss: 0.10594982840120792, Final Batch Loss: 0.07703379541635513\n",
      "Epoch 1875, Loss: 0.11107955127954483, Final Batch Loss: 0.07414717227220535\n",
      "Epoch 1876, Loss: 0.14328421652317047, Final Batch Loss: 0.07140015810728073\n",
      "Epoch 1877, Loss: 0.12246489897370338, Final Batch Loss: 0.06808687746524811\n",
      "Epoch 1878, Loss: 0.06926313787698746, Final Batch Loss: 0.03204364329576492\n",
      "Epoch 1879, Loss: 0.06219624541699886, Final Batch Loss: 0.03150748834013939\n",
      "Epoch 1880, Loss: 0.07887371815741062, Final Batch Loss: 0.02786915935575962\n",
      "Epoch 1881, Loss: 0.12585149332880974, Final Batch Loss: 0.06825912743806839\n",
      "Epoch 1882, Loss: 0.20546136796474457, Final Batch Loss: 0.06068241596221924\n",
      "Epoch 1883, Loss: 0.0828939862549305, Final Batch Loss: 0.03599732741713524\n",
      "Epoch 1884, Loss: 0.1131870225071907, Final Batch Loss: 0.05502135306596756\n",
      "Epoch 1885, Loss: 0.05931829661130905, Final Batch Loss: 0.016324207186698914\n",
      "Epoch 1886, Loss: 0.08772040903568268, Final Batch Loss: 0.044624678790569305\n",
      "Epoch 1887, Loss: 0.05834841635078192, Final Batch Loss: 0.015291552059352398\n",
      "Epoch 1888, Loss: 0.12327639758586884, Final Batch Loss: 0.08373501896858215\n",
      "Epoch 1889, Loss: 0.09851974248886108, Final Batch Loss: 0.03662124276161194\n",
      "Epoch 1890, Loss: 0.10028854385018349, Final Batch Loss: 0.06319669634103775\n",
      "Epoch 1891, Loss: 0.062436668202281, Final Batch Loss: 0.021675968542695045\n",
      "Epoch 1892, Loss: 0.059529831632971764, Final Batch Loss: 0.023095307871699333\n",
      "Epoch 1893, Loss: 0.06716469116508961, Final Batch Loss: 0.03113405592739582\n",
      "Epoch 1894, Loss: 0.09506164863705635, Final Batch Loss: 0.0372733436524868\n",
      "Epoch 1895, Loss: 0.06626652181148529, Final Batch Loss: 0.032071106135845184\n",
      "Epoch 1896, Loss: 0.07933778688311577, Final Batch Loss: 0.034978531301021576\n",
      "Epoch 1897, Loss: 0.03914349339902401, Final Batch Loss: 0.01323222927749157\n",
      "Epoch 1898, Loss: 0.0719597153365612, Final Batch Loss: 0.04132070764899254\n",
      "Epoch 1899, Loss: 0.09327039495110512, Final Batch Loss: 0.04145609587430954\n",
      "Epoch 1900, Loss: 0.06222918629646301, Final Batch Loss: 0.009765829890966415\n",
      "Epoch 1901, Loss: 0.1158454492688179, Final Batch Loss: 0.033981435000896454\n",
      "Epoch 1902, Loss: 0.16228851675987244, Final Batch Loss: 0.1257135421037674\n",
      "Epoch 1903, Loss: 0.11505940556526184, Final Batch Loss: 0.050028666853904724\n",
      "Epoch 1904, Loss: 0.09491273388266563, Final Batch Loss: 0.04602862149477005\n",
      "Epoch 1905, Loss: 0.08801403269171715, Final Batch Loss: 0.05164279416203499\n",
      "Epoch 1906, Loss: 0.11239806562662125, Final Batch Loss: 0.0756569355726242\n",
      "Epoch 1907, Loss: 0.06990073900669813, Final Batch Loss: 0.013037762604653835\n",
      "Epoch 1908, Loss: 0.06554017402231693, Final Batch Loss: 0.02818514220416546\n",
      "Epoch 1909, Loss: 0.11157257109880447, Final Batch Loss: 0.07116871327161789\n",
      "Epoch 1910, Loss: 0.13796217739582062, Final Batch Loss: 0.0908108726143837\n",
      "Epoch 1911, Loss: 0.10438303276896477, Final Batch Loss: 0.047846149653196335\n",
      "Epoch 1912, Loss: 0.0666463989764452, Final Batch Loss: 0.024217253550887108\n",
      "Epoch 1913, Loss: 0.0955936424434185, Final Batch Loss: 0.06602653115987778\n",
      "Epoch 1914, Loss: 0.06132154539227486, Final Batch Loss: 0.03726588934659958\n",
      "Epoch 1915, Loss: 0.09826142340898514, Final Batch Loss: 0.042928606271743774\n",
      "Epoch 1916, Loss: 0.07186482287943363, Final Batch Loss: 0.02800624631345272\n",
      "Epoch 1917, Loss: 0.1114991195499897, Final Batch Loss: 0.0742465928196907\n",
      "Epoch 1918, Loss: 0.08428173512220383, Final Batch Loss: 0.033747054636478424\n",
      "Epoch 1919, Loss: 0.04339708387851715, Final Batch Loss: 0.01747835986316204\n",
      "Epoch 1920, Loss: 0.08261040970683098, Final Batch Loss: 0.047283537685871124\n",
      "Epoch 1921, Loss: 0.1092216707766056, Final Batch Loss: 0.05953426659107208\n",
      "Epoch 1922, Loss: 0.15199456363916397, Final Batch Loss: 0.08926508575677872\n",
      "Epoch 1923, Loss: 0.10822633467614651, Final Batch Loss: 0.027106469497084618\n",
      "Epoch 1924, Loss: 0.1252141147851944, Final Batch Loss: 0.08249786496162415\n",
      "Epoch 1925, Loss: 0.049833014607429504, Final Batch Loss: 0.03045165352523327\n",
      "Epoch 1926, Loss: 0.1148279644548893, Final Batch Loss: 0.056376855820417404\n",
      "Epoch 1927, Loss: 0.09887692518532276, Final Batch Loss: 0.06806739419698715\n",
      "Epoch 1928, Loss: 0.11324190348386765, Final Batch Loss: 0.06553860753774643\n",
      "Epoch 1929, Loss: 0.11252522468566895, Final Batch Loss: 0.03655122220516205\n",
      "Epoch 1930, Loss: 0.09879467077553272, Final Batch Loss: 0.07381772249937057\n",
      "Epoch 1931, Loss: 0.08332411199808121, Final Batch Loss: 0.03360268846154213\n",
      "Epoch 1932, Loss: 0.11080310866236687, Final Batch Loss: 0.03566839173436165\n",
      "Epoch 1933, Loss: 0.1282861903309822, Final Batch Loss: 0.089060939848423\n",
      "Epoch 1934, Loss: 0.08929722011089325, Final Batch Loss: 0.03200913220643997\n",
      "Epoch 1935, Loss: 0.13777633011341095, Final Batch Loss: 0.022403031587600708\n",
      "Epoch 1936, Loss: 0.07824206724762917, Final Batch Loss: 0.03622521087527275\n",
      "Epoch 1937, Loss: 0.060039231553673744, Final Batch Loss: 0.030782779678702354\n",
      "Epoch 1938, Loss: 0.12188655138015747, Final Batch Loss: 0.027179069817066193\n",
      "Epoch 1939, Loss: 0.0968860313296318, Final Batch Loss: 0.055557653307914734\n",
      "Epoch 1940, Loss: 0.044546103104949, Final Batch Loss: 0.01499602384865284\n",
      "Epoch 1941, Loss: 0.07449661195278168, Final Batch Loss: 0.032498475164175034\n",
      "Epoch 1942, Loss: 0.08399885706603527, Final Batch Loss: 0.05769652500748634\n",
      "Epoch 1943, Loss: 0.09162122011184692, Final Batch Loss: 0.03947928920388222\n",
      "Epoch 1944, Loss: 0.08889636024832726, Final Batch Loss: 0.038907721638679504\n",
      "Epoch 1945, Loss: 0.11201993189752102, Final Batch Loss: 0.015669507905840874\n",
      "Epoch 1946, Loss: 0.1221826858818531, Final Batch Loss: 0.07672695070505142\n",
      "Epoch 1947, Loss: 0.06630689091980457, Final Batch Loss: 0.03838774561882019\n",
      "Epoch 1948, Loss: 0.12751570716500282, Final Batch Loss: 0.07653090357780457\n",
      "Epoch 1949, Loss: 0.16926945000886917, Final Batch Loss: 0.11567524075508118\n",
      "Epoch 1950, Loss: 0.08917904645204544, Final Batch Loss: 0.038438912481069565\n",
      "Epoch 1951, Loss: 0.06608826667070389, Final Batch Loss: 0.043219663202762604\n",
      "Epoch 1952, Loss: 0.07923414744436741, Final Batch Loss: 0.05480721592903137\n",
      "Epoch 1953, Loss: 0.07352861762046814, Final Batch Loss: 0.03602798283100128\n",
      "Epoch 1954, Loss: 0.10171117261052132, Final Batch Loss: 0.03866663947701454\n",
      "Epoch 1955, Loss: 0.10307314246892929, Final Batch Loss: 0.044093456119298935\n",
      "Epoch 1956, Loss: 0.10123871639370918, Final Batch Loss: 0.04160727933049202\n",
      "Epoch 1957, Loss: 0.08545451052486897, Final Batch Loss: 0.026047157123684883\n",
      "Epoch 1958, Loss: 0.08504453301429749, Final Batch Loss: 0.025048144161701202\n",
      "Epoch 1959, Loss: 0.07773083075881004, Final Batch Loss: 0.03801359236240387\n",
      "Epoch 1960, Loss: 0.09378597512841225, Final Batch Loss: 0.01903378590941429\n",
      "Epoch 1961, Loss: 0.11994511634111404, Final Batch Loss: 0.06845419108867645\n",
      "Epoch 1962, Loss: 0.16269953176379204, Final Batch Loss: 0.10457183420658112\n",
      "Epoch 1963, Loss: 0.10157504118978977, Final Batch Loss: 0.015665197744965553\n",
      "Epoch 1964, Loss: 0.07365181297063828, Final Batch Loss: 0.035784315317869186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1965, Loss: 0.08618176355957985, Final Batch Loss: 0.04470866918563843\n",
      "Epoch 1966, Loss: 0.06191854737699032, Final Batch Loss: 0.03997045382857323\n",
      "Epoch 1967, Loss: 0.1340380236506462, Final Batch Loss: 0.09802694618701935\n",
      "Epoch 1968, Loss: 0.1332753300666809, Final Batch Loss: 0.054024048149585724\n",
      "Epoch 1969, Loss: 0.09024186432361603, Final Batch Loss: 0.03304188698530197\n",
      "Epoch 1970, Loss: 0.05526030249893665, Final Batch Loss: 0.027646560221910477\n",
      "Epoch 1971, Loss: 0.06659086979925632, Final Batch Loss: 0.01871461234986782\n",
      "Epoch 1972, Loss: 0.06732477433979511, Final Batch Loss: 0.04086437076330185\n",
      "Epoch 1973, Loss: 0.11690372042357922, Final Batch Loss: 0.09154213964939117\n",
      "Epoch 1974, Loss: 0.1174146942794323, Final Batch Loss: 0.05759682133793831\n",
      "Epoch 1975, Loss: 0.1069890521466732, Final Batch Loss: 0.06711321324110031\n",
      "Epoch 1976, Loss: 0.0781125109642744, Final Batch Loss: 0.0573282428085804\n",
      "Epoch 1977, Loss: 0.06439036503434181, Final Batch Loss: 0.0246502086520195\n",
      "Epoch 1978, Loss: 0.10074255988001823, Final Batch Loss: 0.03297455981373787\n",
      "Epoch 1979, Loss: 0.13339367136359215, Final Batch Loss: 0.07789893448352814\n",
      "Epoch 1980, Loss: 0.07075325027108192, Final Batch Loss: 0.04636804386973381\n",
      "Epoch 1981, Loss: 0.10318020544946194, Final Batch Loss: 0.0759393647313118\n",
      "Epoch 1982, Loss: 0.07784770801663399, Final Batch Loss: 0.03662833943963051\n",
      "Epoch 1983, Loss: 0.14420194551348686, Final Batch Loss: 0.10063609480857849\n",
      "Epoch 1984, Loss: 0.07770619541406631, Final Batch Loss: 0.043855030089616776\n",
      "Epoch 1985, Loss: 0.07944359257817268, Final Batch Loss: 0.029142510145902634\n",
      "Epoch 1986, Loss: 0.11922556161880493, Final Batch Loss: 0.06055189296603203\n",
      "Epoch 1987, Loss: 0.07662833295762539, Final Batch Loss: 0.013234099373221397\n",
      "Epoch 1988, Loss: 0.05675824545323849, Final Batch Loss: 0.026345308870077133\n",
      "Epoch 1989, Loss: 0.0716606117784977, Final Batch Loss: 0.033859558403491974\n",
      "Epoch 1990, Loss: 0.10586267709732056, Final Batch Loss: 0.04602086544036865\n",
      "Epoch 1991, Loss: 0.07325415313243866, Final Batch Loss: 0.028609909117221832\n",
      "Epoch 1992, Loss: 0.11286154389381409, Final Batch Loss: 0.058480389416217804\n",
      "Epoch 1993, Loss: 0.14525830373167992, Final Batch Loss: 0.10337883979082108\n",
      "Epoch 1994, Loss: 0.10820843279361725, Final Batch Loss: 0.03006856143474579\n",
      "Epoch 1995, Loss: 0.07734201289713383, Final Batch Loss: 0.05396256595849991\n",
      "Epoch 1996, Loss: 0.05726595222949982, Final Batch Loss: 0.017248596996068954\n",
      "Epoch 1997, Loss: 0.09988674148917198, Final Batch Loss: 0.06687656790018082\n",
      "Epoch 1998, Loss: 0.10382959246635437, Final Batch Loss: 0.03487010300159454\n",
      "Epoch 1999, Loss: 0.07067884504795074, Final Batch Loss: 0.03633170574903488\n",
      "Epoch 2000, Loss: 0.09317222982645035, Final Batch Loss: 0.06799179315567017\n",
      "Epoch 2001, Loss: 0.13852689787745476, Final Batch Loss: 0.0856856107711792\n",
      "Epoch 2002, Loss: 0.1401720568537712, Final Batch Loss: 0.06472884118556976\n",
      "Epoch 2003, Loss: 0.0675823912024498, Final Batch Loss: 0.023562230169773102\n",
      "Epoch 2004, Loss: 0.0778190903365612, Final Batch Loss: 0.03414458408951759\n",
      "Epoch 2005, Loss: 0.0669778510928154, Final Batch Loss: 0.025520391762256622\n",
      "Epoch 2006, Loss: 0.1001758985221386, Final Batch Loss: 0.0335833840072155\n",
      "Epoch 2007, Loss: 0.08698750287294388, Final Batch Loss: 0.060617845505476\n",
      "Epoch 2008, Loss: 0.054307445883750916, Final Batch Loss: 0.01941583678126335\n",
      "Epoch 2009, Loss: 0.10378548316657543, Final Batch Loss: 0.0725986510515213\n",
      "Epoch 2010, Loss: 0.09124187380075455, Final Batch Loss: 0.04140038788318634\n",
      "Epoch 2011, Loss: 0.06683865934610367, Final Batch Loss: 0.04322289675474167\n",
      "Epoch 2012, Loss: 0.0803453903645277, Final Batch Loss: 0.021244758740067482\n",
      "Epoch 2013, Loss: 0.0746444296091795, Final Batch Loss: 0.023782311007380486\n",
      "Epoch 2014, Loss: 0.09087683260440826, Final Batch Loss: 0.02192031592130661\n",
      "Epoch 2015, Loss: 0.07479205913841724, Final Batch Loss: 0.048263031989336014\n",
      "Epoch 2016, Loss: 0.09741947799921036, Final Batch Loss: 0.058162491768598557\n",
      "Epoch 2017, Loss: 0.0696352943778038, Final Batch Loss: 0.028743498027324677\n",
      "Epoch 2018, Loss: 0.07798022404313087, Final Batch Loss: 0.026508018374443054\n",
      "Epoch 2019, Loss: 0.11212019249796867, Final Batch Loss: 0.07360028475522995\n",
      "Epoch 2020, Loss: 0.09938899800181389, Final Batch Loss: 0.027536366134881973\n",
      "Epoch 2021, Loss: 0.0738893635571003, Final Batch Loss: 0.03196563571691513\n",
      "Epoch 2022, Loss: 0.048439495265483856, Final Batch Loss: 0.02885153703391552\n",
      "Epoch 2023, Loss: 0.10754795745015144, Final Batch Loss: 0.03342272713780403\n",
      "Epoch 2024, Loss: 0.09613045677542686, Final Batch Loss: 0.04108220711350441\n",
      "Epoch 2025, Loss: 0.059957120567560196, Final Batch Loss: 0.04230749234557152\n",
      "Epoch 2026, Loss: 0.11127206683158875, Final Batch Loss: 0.07182519137859344\n",
      "Epoch 2027, Loss: 0.05584152601659298, Final Batch Loss: 0.015524124726653099\n",
      "Epoch 2028, Loss: 0.07377075776457787, Final Batch Loss: 0.03698282688856125\n",
      "Epoch 2029, Loss: 0.05293578468263149, Final Batch Loss: 0.0119247455149889\n",
      "Epoch 2030, Loss: 0.08011711947619915, Final Batch Loss: 0.01636691950261593\n",
      "Epoch 2031, Loss: 0.05119595304131508, Final Batch Loss: 0.027206525206565857\n",
      "Epoch 2032, Loss: 0.06684074178338051, Final Batch Loss: 0.029012560844421387\n",
      "Epoch 2033, Loss: 0.11902249604463577, Final Batch Loss: 0.06974609941244125\n",
      "Epoch 2034, Loss: 0.06443194951862097, Final Batch Loss: 0.013977373950183392\n",
      "Epoch 2035, Loss: 0.10626185685396194, Final Batch Loss: 0.06542525440454483\n",
      "Epoch 2036, Loss: 0.08190898224711418, Final Batch Loss: 0.029366537928581238\n",
      "Epoch 2037, Loss: 0.14580198377370834, Final Batch Loss: 0.0365033894777298\n",
      "Epoch 2038, Loss: 0.09531625732779503, Final Batch Loss: 0.05556482449173927\n",
      "Epoch 2039, Loss: 0.08712401241064072, Final Batch Loss: 0.043927934020757675\n",
      "Epoch 2040, Loss: 0.18411348015069962, Final Batch Loss: 0.12732312083244324\n",
      "Epoch 2041, Loss: 0.0741376057267189, Final Batch Loss: 0.05482570081949234\n",
      "Epoch 2042, Loss: 0.12319586053490639, Final Batch Loss: 0.054043326526880264\n",
      "Epoch 2043, Loss: 0.08455352112650871, Final Batch Loss: 0.033711425960063934\n",
      "Epoch 2044, Loss: 0.10292165726423264, Final Batch Loss: 0.06797082722187042\n",
      "Epoch 2045, Loss: 0.07599844038486481, Final Batch Loss: 0.054549723863601685\n",
      "Epoch 2046, Loss: 0.1024966686964035, Final Batch Loss: 0.03313249349594116\n",
      "Epoch 2047, Loss: 0.0765303447842598, Final Batch Loss: 0.04108724370598793\n",
      "Epoch 2048, Loss: 0.05263897031545639, Final Batch Loss: 0.015033431351184845\n",
      "Epoch 2049, Loss: 0.11131491139531136, Final Batch Loss: 0.06036839261651039\n",
      "Epoch 2050, Loss: 0.07257862016558647, Final Batch Loss: 0.02029145136475563\n",
      "Epoch 2051, Loss: 0.0520381685346365, Final Batch Loss: 0.03115611895918846\n",
      "Epoch 2052, Loss: 0.07584518566727638, Final Batch Loss: 0.046033237129449844\n",
      "Epoch 2053, Loss: 0.052861616015434265, Final Batch Loss: 0.017912622541189194\n",
      "Epoch 2054, Loss: 0.08990669250488281, Final Batch Loss: 0.05982980132102966\n",
      "Epoch 2055, Loss: 0.05197406746447086, Final Batch Loss: 0.03235843777656555\n",
      "Epoch 2056, Loss: 0.0944360289722681, Final Batch Loss: 0.06864970177412033\n",
      "Epoch 2057, Loss: 0.04981956444680691, Final Batch Loss: 0.032074764370918274\n",
      "Epoch 2058, Loss: 0.07297997549176216, Final Batch Loss: 0.03634563460946083\n",
      "Epoch 2059, Loss: 0.08944598957896233, Final Batch Loss: 0.052637916058301926\n",
      "Epoch 2060, Loss: 0.10099321231245995, Final Batch Loss: 0.03290339186787605\n",
      "Epoch 2061, Loss: 0.0550537072122097, Final Batch Loss: 0.02181083709001541\n",
      "Epoch 2062, Loss: 0.07165633700788021, Final Batch Loss: 0.02705935575067997\n",
      "Epoch 2063, Loss: 0.04933306761085987, Final Batch Loss: 0.0215402003377676\n",
      "Epoch 2064, Loss: 0.051357731223106384, Final Batch Loss: 0.032123733311891556\n",
      "Epoch 2065, Loss: 0.06066614203155041, Final Batch Loss: 0.037111543118953705\n",
      "Epoch 2066, Loss: 0.0982964988797903, Final Batch Loss: 0.02595732919871807\n",
      "Epoch 2067, Loss: 0.11299492046236992, Final Batch Loss: 0.061506014317274094\n",
      "Epoch 2068, Loss: 0.0888840314000845, Final Batch Loss: 0.05949479714035988\n",
      "Epoch 2069, Loss: 0.1021769754588604, Final Batch Loss: 0.041653767228126526\n",
      "Epoch 2070, Loss: 0.09796033427119255, Final Batch Loss: 0.05616365373134613\n",
      "Epoch 2071, Loss: 0.0527063449844718, Final Batch Loss: 0.009681149385869503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2072, Loss: 0.13166111707687378, Final Batch Loss: 0.06457947194576263\n",
      "Epoch 2073, Loss: 0.09056852757930756, Final Batch Loss: 0.0526178702712059\n",
      "Epoch 2074, Loss: 0.1334669627249241, Final Batch Loss: 0.10018596798181534\n",
      "Epoch 2075, Loss: 0.08004077523946762, Final Batch Loss: 0.014365650713443756\n",
      "Epoch 2076, Loss: 0.11899185925722122, Final Batch Loss: 0.0760662853717804\n",
      "Epoch 2077, Loss: 0.08814651519060135, Final Batch Loss: 0.03943061828613281\n",
      "Epoch 2078, Loss: 0.06653496623039246, Final Batch Loss: 0.027977585792541504\n",
      "Epoch 2079, Loss: 0.11062314733862877, Final Batch Loss: 0.06204580143094063\n",
      "Epoch 2080, Loss: 0.06865577399730682, Final Batch Loss: 0.029011525213718414\n",
      "Epoch 2081, Loss: 0.08917218819260597, Final Batch Loss: 0.04507302865386009\n",
      "Epoch 2082, Loss: 0.06366360187530518, Final Batch Loss: 0.031879082322120667\n",
      "Epoch 2083, Loss: 0.07905261963605881, Final Batch Loss: 0.05153542757034302\n",
      "Epoch 2084, Loss: 0.08921430259943008, Final Batch Loss: 0.024000905454158783\n",
      "Epoch 2085, Loss: 0.0849167387932539, Final Batch Loss: 0.02959069423377514\n",
      "Epoch 2086, Loss: 0.08866842091083527, Final Batch Loss: 0.060619793832302094\n",
      "Epoch 2087, Loss: 0.06964536942541599, Final Batch Loss: 0.02602221630513668\n",
      "Epoch 2088, Loss: 0.05373305827379227, Final Batch Loss: 0.030556723475456238\n",
      "Epoch 2089, Loss: 0.06005016714334488, Final Batch Loss: 0.01573803275823593\n",
      "Epoch 2090, Loss: 0.08612570911645889, Final Batch Loss: 0.0351322740316391\n",
      "Epoch 2091, Loss: 0.09124342352151871, Final Batch Loss: 0.050192371010780334\n",
      "Epoch 2092, Loss: 0.12735862657427788, Final Batch Loss: 0.07851241528987885\n",
      "Epoch 2093, Loss: 0.08132511749863625, Final Batch Loss: 0.050858981907367706\n",
      "Epoch 2094, Loss: 0.09180119261145592, Final Batch Loss: 0.06334884464740753\n",
      "Epoch 2095, Loss: 0.09090873971581459, Final Batch Loss: 0.04409463331103325\n",
      "Epoch 2096, Loss: 0.11144303157925606, Final Batch Loss: 0.05909711495041847\n",
      "Epoch 2097, Loss: 0.1496056690812111, Final Batch Loss: 0.032351359724998474\n",
      "Epoch 2098, Loss: 0.09047848172485828, Final Batch Loss: 0.02558680810034275\n",
      "Epoch 2099, Loss: 0.06642112508416176, Final Batch Loss: 0.028973355889320374\n",
      "Epoch 2100, Loss: 0.04300091229379177, Final Batch Loss: 0.009540127590298653\n",
      "Epoch 2101, Loss: 0.14556580781936646, Final Batch Loss: 0.0711350291967392\n",
      "Epoch 2102, Loss: 0.07164219208061695, Final Batch Loss: 0.05046841502189636\n",
      "Epoch 2103, Loss: 0.09721333160996437, Final Batch Loss: 0.06559508293867111\n",
      "Epoch 2104, Loss: 0.06080993078649044, Final Batch Loss: 0.038134101778268814\n",
      "Epoch 2105, Loss: 0.04717831313610077, Final Batch Loss: 0.016085505485534668\n",
      "Epoch 2106, Loss: 0.10483346879482269, Final Batch Loss: 0.03356529772281647\n",
      "Epoch 2107, Loss: 0.09175846353173256, Final Batch Loss: 0.03529135882854462\n",
      "Epoch 2108, Loss: 0.10330427810549736, Final Batch Loss: 0.0512985996901989\n",
      "Epoch 2109, Loss: 0.053643690422177315, Final Batch Loss: 0.02408134937286377\n",
      "Epoch 2110, Loss: 0.13699122332036495, Final Batch Loss: 0.11799703538417816\n",
      "Epoch 2111, Loss: 0.09266931936144829, Final Batch Loss: 0.037489306181669235\n",
      "Epoch 2112, Loss: 0.09850878268480301, Final Batch Loss: 0.053210802376270294\n",
      "Epoch 2113, Loss: 0.14349283650517464, Final Batch Loss: 0.09801726043224335\n",
      "Epoch 2114, Loss: 0.1056167408823967, Final Batch Loss: 0.052244048565626144\n",
      "Epoch 2115, Loss: 0.0550385657697916, Final Batch Loss: 0.020830245688557625\n",
      "Epoch 2116, Loss: 0.07409770414233208, Final Batch Loss: 0.03253079578280449\n",
      "Epoch 2117, Loss: 0.11002523452043533, Final Batch Loss: 0.05997513607144356\n",
      "Epoch 2118, Loss: 0.06909955106675625, Final Batch Loss: 0.02939434163272381\n",
      "Epoch 2119, Loss: 0.07588838785886765, Final Batch Loss: 0.04792603477835655\n",
      "Epoch 2120, Loss: 0.10483594611287117, Final Batch Loss: 0.05648140609264374\n",
      "Epoch 2121, Loss: 0.08975307643413544, Final Batch Loss: 0.03108919784426689\n",
      "Epoch 2122, Loss: 0.10412124916911125, Final Batch Loss: 0.054130919277668\n",
      "Epoch 2123, Loss: 0.08544115535914898, Final Batch Loss: 0.06349129974842072\n",
      "Epoch 2124, Loss: 0.08113870024681091, Final Batch Loss: 0.046389155089855194\n",
      "Epoch 2125, Loss: 0.10818225517868996, Final Batch Loss: 0.07186780869960785\n",
      "Epoch 2126, Loss: 0.1482909359037876, Final Batch Loss: 0.037742067128419876\n",
      "Epoch 2127, Loss: 0.12432153895497322, Final Batch Loss: 0.050901543349027634\n",
      "Epoch 2128, Loss: 0.09546918421983719, Final Batch Loss: 0.045832760632038116\n",
      "Epoch 2129, Loss: 0.08293328806757927, Final Batch Loss: 0.03902195766568184\n",
      "Epoch 2130, Loss: 0.08492565900087357, Final Batch Loss: 0.049261026084423065\n",
      "Epoch 2131, Loss: 0.08526125177741051, Final Batch Loss: 0.04867243766784668\n",
      "Epoch 2132, Loss: 0.07911044359207153, Final Batch Loss: 0.041888922452926636\n",
      "Epoch 2133, Loss: 0.11045798286795616, Final Batch Loss: 0.05859321355819702\n",
      "Epoch 2134, Loss: 0.06762093305587769, Final Batch Loss: 0.02877480536699295\n",
      "Epoch 2135, Loss: 0.07303368858993053, Final Batch Loss: 0.02675139345228672\n",
      "Epoch 2136, Loss: 0.08403128199279308, Final Batch Loss: 0.057892944663763046\n",
      "Epoch 2137, Loss: 0.0647945236414671, Final Batch Loss: 0.03388454392552376\n",
      "Epoch 2138, Loss: 0.0755503922700882, Final Batch Loss: 0.033727675676345825\n",
      "Epoch 2139, Loss: 0.053978873416781425, Final Batch Loss: 0.02720922976732254\n",
      "Epoch 2140, Loss: 0.07943982258439064, Final Batch Loss: 0.04296282306313515\n",
      "Epoch 2141, Loss: 0.07672946341335773, Final Batch Loss: 0.01939074508845806\n",
      "Epoch 2142, Loss: 0.13694023340940475, Final Batch Loss: 0.08020883053541183\n",
      "Epoch 2143, Loss: 0.05268209148198366, Final Batch Loss: 0.005846631713211536\n",
      "Epoch 2144, Loss: 0.07679656893014908, Final Batch Loss: 0.039972227066755295\n",
      "Epoch 2145, Loss: 0.17532265931367874, Final Batch Loss: 0.10554827749729156\n",
      "Epoch 2146, Loss: 0.0953714232891798, Final Batch Loss: 0.031095480546355247\n",
      "Epoch 2147, Loss: 0.08413585275411606, Final Batch Loss: 0.04468776285648346\n",
      "Epoch 2148, Loss: 0.14746832847595215, Final Batch Loss: 0.07904285192489624\n",
      "Epoch 2149, Loss: 0.0940043032169342, Final Batch Loss: 0.04759979248046875\n",
      "Epoch 2150, Loss: 0.08166871219873428, Final Batch Loss: 0.03198555111885071\n",
      "Epoch 2151, Loss: 0.08657963201403618, Final Batch Loss: 0.048699259757995605\n",
      "Epoch 2152, Loss: 0.098086167126894, Final Batch Loss: 0.04205392301082611\n",
      "Epoch 2153, Loss: 0.06438947282731533, Final Batch Loss: 0.025637617334723473\n",
      "Epoch 2154, Loss: 0.1723027229309082, Final Batch Loss: 0.09234893321990967\n",
      "Epoch 2155, Loss: 0.11248829960823059, Final Batch Loss: 0.07777028530836105\n",
      "Epoch 2156, Loss: 0.061373259872198105, Final Batch Loss: 0.04152496159076691\n",
      "Epoch 2157, Loss: 0.12154652550816536, Final Batch Loss: 0.08219487965106964\n",
      "Epoch 2158, Loss: 0.07190319150686264, Final Batch Loss: 0.03644303232431412\n",
      "Epoch 2159, Loss: 0.17090941220521927, Final Batch Loss: 0.10792847722768784\n",
      "Epoch 2160, Loss: 0.07834768481552601, Final Batch Loss: 0.027649516239762306\n",
      "Epoch 2161, Loss: 0.042057985439896584, Final Batch Loss: 0.022588644176721573\n",
      "Epoch 2162, Loss: 0.12190042063593864, Final Batch Loss: 0.07051592320203781\n",
      "Epoch 2163, Loss: 0.10558785125613213, Final Batch Loss: 0.04707922786474228\n",
      "Epoch 2164, Loss: 0.15767521411180496, Final Batch Loss: 0.1097172349691391\n",
      "Epoch 2165, Loss: 0.06056269071996212, Final Batch Loss: 0.0179945956915617\n",
      "Epoch 2166, Loss: 0.053435005247592926, Final Batch Loss: 0.03328293561935425\n",
      "Epoch 2167, Loss: 0.06766918674111366, Final Batch Loss: 0.0306929349899292\n",
      "Epoch 2168, Loss: 0.10640426352620125, Final Batch Loss: 0.043889883905649185\n",
      "Epoch 2169, Loss: 0.06419547274708748, Final Batch Loss: 0.02508140727877617\n",
      "Epoch 2170, Loss: 0.0493696890771389, Final Batch Loss: 0.02115331031382084\n",
      "Epoch 2171, Loss: 0.08429141342639923, Final Batch Loss: 0.05181591585278511\n",
      "Epoch 2172, Loss: 0.06745085120201111, Final Batch Loss: 0.032445039600133896\n",
      "Epoch 2173, Loss: 0.06123051978647709, Final Batch Loss: 0.03291323408484459\n",
      "Epoch 2174, Loss: 0.09906001761555672, Final Batch Loss: 0.03432392701506615\n",
      "Epoch 2175, Loss: 0.06977301090955734, Final Batch Loss: 0.036308012902736664\n",
      "Epoch 2176, Loss: 0.13032760098576546, Final Batch Loss: 0.03649212047457695\n",
      "Epoch 2177, Loss: 0.11146699637174606, Final Batch Loss: 0.06515302509069443\n",
      "Epoch 2178, Loss: 0.07651813328266144, Final Batch Loss: 0.04028545320034027\n",
      "Epoch 2179, Loss: 0.06194721721112728, Final Batch Loss: 0.023791572079062462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2180, Loss: 0.11785712838172913, Final Batch Loss: 0.0534353032708168\n",
      "Epoch 2181, Loss: 0.057567376643419266, Final Batch Loss: 0.021913014352321625\n",
      "Epoch 2182, Loss: 0.061466194689273834, Final Batch Loss: 0.02412039041519165\n",
      "Epoch 2183, Loss: 0.09346247091889381, Final Batch Loss: 0.042414505034685135\n",
      "Epoch 2184, Loss: 0.08625634759664536, Final Batch Loss: 0.019843943417072296\n",
      "Epoch 2185, Loss: 0.09843648597598076, Final Batch Loss: 0.040431153029203415\n",
      "Epoch 2186, Loss: 0.0672850739210844, Final Batch Loss: 0.01754826493561268\n",
      "Epoch 2187, Loss: 0.10358632728457451, Final Batch Loss: 0.035078126937150955\n",
      "Epoch 2188, Loss: 0.1199192926287651, Final Batch Loss: 0.05796678364276886\n",
      "Epoch 2189, Loss: 0.07935604453086853, Final Batch Loss: 0.03542802482843399\n",
      "Epoch 2190, Loss: 0.10234059393405914, Final Batch Loss: 0.04133997857570648\n",
      "Epoch 2191, Loss: 0.06649972684681416, Final Batch Loss: 0.025811871513724327\n",
      "Epoch 2192, Loss: 0.07118917256593704, Final Batch Loss: 0.041460927575826645\n",
      "Epoch 2193, Loss: 0.07002956047654152, Final Batch Loss: 0.03276902809739113\n",
      "Epoch 2194, Loss: 0.04913444444537163, Final Batch Loss: 0.0176800936460495\n",
      "Epoch 2195, Loss: 0.07653878629207611, Final Batch Loss: 0.058629244565963745\n",
      "Epoch 2196, Loss: 0.06971774622797966, Final Batch Loss: 0.018693819642066956\n",
      "Epoch 2197, Loss: 0.08436834067106247, Final Batch Loss: 0.03746288642287254\n",
      "Epoch 2198, Loss: 0.06229826621711254, Final Batch Loss: 0.022014623507857323\n",
      "Epoch 2199, Loss: 0.06699609570205212, Final Batch Loss: 0.038057584315538406\n",
      "Epoch 2200, Loss: 0.08646508678793907, Final Batch Loss: 0.04637594148516655\n",
      "Epoch 2201, Loss: 0.041127489879727364, Final Batch Loss: 0.01936076581478119\n",
      "Epoch 2202, Loss: 0.055128030478954315, Final Batch Loss: 0.03126131370663643\n",
      "Epoch 2203, Loss: 0.04910258762538433, Final Batch Loss: 0.03602444753050804\n",
      "Epoch 2204, Loss: 0.057691892609000206, Final Batch Loss: 0.03824453800916672\n",
      "Epoch 2205, Loss: 0.08203710056841373, Final Batch Loss: 0.01948968507349491\n",
      "Epoch 2206, Loss: 0.08424678817391396, Final Batch Loss: 0.06778443604707718\n",
      "Epoch 2207, Loss: 0.1326497159898281, Final Batch Loss: 0.09731892496347427\n",
      "Epoch 2208, Loss: 0.0787890050560236, Final Batch Loss: 0.03059098683297634\n",
      "Epoch 2209, Loss: 0.08643384464085102, Final Batch Loss: 0.02408224157989025\n",
      "Epoch 2210, Loss: 0.07051464729011059, Final Batch Loss: 0.022231491282582283\n",
      "Epoch 2211, Loss: 0.06642185151576996, Final Batch Loss: 0.025142736732959747\n",
      "Epoch 2212, Loss: 0.059144677594304085, Final Batch Loss: 0.03990263119339943\n",
      "Epoch 2213, Loss: 0.0590706467628479, Final Batch Loss: 0.021701931953430176\n",
      "Epoch 2214, Loss: 0.14221211522817612, Final Batch Loss: 0.1029168963432312\n",
      "Epoch 2215, Loss: 0.09825709834694862, Final Batch Loss: 0.06841745227575302\n",
      "Epoch 2216, Loss: 0.09438162110745907, Final Batch Loss: 0.027711769565939903\n",
      "Epoch 2217, Loss: 0.09374351426959038, Final Batch Loss: 0.04878833144903183\n",
      "Epoch 2218, Loss: 0.08076696284115314, Final Batch Loss: 0.052605073899030685\n",
      "Epoch 2219, Loss: 0.0715335663408041, Final Batch Loss: 0.02813279815018177\n",
      "Epoch 2220, Loss: 0.11769477277994156, Final Batch Loss: 0.0830913633108139\n",
      "Epoch 2221, Loss: 0.10673633217811584, Final Batch Loss: 0.0604061558842659\n",
      "Epoch 2222, Loss: 0.06525411177426577, Final Batch Loss: 0.014132105745375156\n",
      "Epoch 2223, Loss: 0.08132410421967506, Final Batch Loss: 0.022377561777830124\n",
      "Epoch 2224, Loss: 0.08318446204066277, Final Batch Loss: 0.026768874377012253\n",
      "Epoch 2225, Loss: 0.09287585318088531, Final Batch Loss: 0.04103939235210419\n",
      "Epoch 2226, Loss: 0.10575532913208008, Final Batch Loss: 0.04919906333088875\n",
      "Epoch 2227, Loss: 0.09651161916553974, Final Batch Loss: 0.07702396810054779\n",
      "Epoch 2228, Loss: 0.07391991466283798, Final Batch Loss: 0.04223495349287987\n",
      "Epoch 2229, Loss: 0.11156325414776802, Final Batch Loss: 0.0476660318672657\n",
      "Epoch 2230, Loss: 0.05160179175436497, Final Batch Loss: 0.028669551014900208\n",
      "Epoch 2231, Loss: 0.13562556728720665, Final Batch Loss: 0.07801903784275055\n",
      "Epoch 2232, Loss: 0.05920620635151863, Final Batch Loss: 0.032491181045770645\n",
      "Epoch 2233, Loss: 0.12454919144511223, Final Batch Loss: 0.06480731070041656\n",
      "Epoch 2234, Loss: 0.06828536093235016, Final Batch Loss: 0.03717677295207977\n",
      "Epoch 2235, Loss: 0.1306176371872425, Final Batch Loss: 0.07850836962461472\n",
      "Epoch 2236, Loss: 0.1524202562868595, Final Batch Loss: 0.02382766082882881\n",
      "Epoch 2237, Loss: 0.05086091160774231, Final Batch Loss: 0.013835620135068893\n",
      "Epoch 2238, Loss: 0.06731737591326237, Final Batch Loss: 0.042171478271484375\n",
      "Epoch 2239, Loss: 0.0494614876806736, Final Batch Loss: 0.01883009448647499\n",
      "Epoch 2240, Loss: 0.05681533366441727, Final Batch Loss: 0.033516544848680496\n",
      "Epoch 2241, Loss: 0.09130395576357841, Final Batch Loss: 0.0329274907708168\n",
      "Epoch 2242, Loss: 0.08211077377200127, Final Batch Loss: 0.03279350697994232\n",
      "Epoch 2243, Loss: 0.04637972451746464, Final Batch Loss: 0.018671175464987755\n",
      "Epoch 2244, Loss: 0.08061228320002556, Final Batch Loss: 0.048713233321905136\n",
      "Epoch 2245, Loss: 0.030167234130203724, Final Batch Loss: 0.012805369682610035\n",
      "Epoch 2246, Loss: 0.06206494942307472, Final Batch Loss: 0.0346694253385067\n",
      "Epoch 2247, Loss: 0.04331364203244448, Final Batch Loss: 0.00996477622538805\n",
      "Epoch 2248, Loss: 0.07415930926799774, Final Batch Loss: 0.03715846315026283\n",
      "Epoch 2249, Loss: 0.046185276471078396, Final Batch Loss: 0.012429720722138882\n",
      "Epoch 2250, Loss: 0.031032332219183445, Final Batch Loss: 0.013136387802660465\n",
      "Epoch 2251, Loss: 0.049301618710160255, Final Batch Loss: 0.027068529278039932\n",
      "Epoch 2252, Loss: 0.07307818718254566, Final Batch Loss: 0.043180014938116074\n",
      "Epoch 2253, Loss: 0.06521707773208618, Final Batch Loss: 0.03838922828435898\n",
      "Epoch 2254, Loss: 0.07882882468402386, Final Batch Loss: 0.05789238214492798\n",
      "Epoch 2255, Loss: 0.06656568497419357, Final Batch Loss: 0.02712225168943405\n",
      "Epoch 2256, Loss: 0.062198489904403687, Final Batch Loss: 0.029719926416873932\n",
      "Epoch 2257, Loss: 0.06321947276592255, Final Batch Loss: 0.03253934159874916\n",
      "Epoch 2258, Loss: 0.07257649675011635, Final Batch Loss: 0.017734572291374207\n",
      "Epoch 2259, Loss: 0.05573795735836029, Final Batch Loss: 0.04363514482975006\n",
      "Epoch 2260, Loss: 0.061849648132920265, Final Batch Loss: 0.04194004088640213\n",
      "Epoch 2261, Loss: 0.06314503867179155, Final Batch Loss: 0.04836931824684143\n",
      "Epoch 2262, Loss: 0.06537378951907158, Final Batch Loss: 0.02376873418688774\n",
      "Epoch 2263, Loss: 0.08249228075146675, Final Batch Loss: 0.04302121698856354\n",
      "Epoch 2264, Loss: 0.05005384050309658, Final Batch Loss: 0.019367562606930733\n",
      "Epoch 2265, Loss: 0.07676631212234497, Final Batch Loss: 0.0263986736536026\n",
      "Epoch 2266, Loss: 0.07225925847887993, Final Batch Loss: 0.031708620488643646\n",
      "Epoch 2267, Loss: 0.07786803506314754, Final Batch Loss: 0.053508415818214417\n",
      "Epoch 2268, Loss: 0.07872628048062325, Final Batch Loss: 0.052642516791820526\n",
      "Epoch 2269, Loss: 0.08560488000512123, Final Batch Loss: 0.02762501686811447\n",
      "Epoch 2270, Loss: 0.0672563686966896, Final Batch Loss: 0.04192979261279106\n",
      "Epoch 2271, Loss: 0.14072535932064056, Final Batch Loss: 0.06780406832695007\n",
      "Epoch 2272, Loss: 0.058327801525592804, Final Batch Loss: 0.036200881004333496\n",
      "Epoch 2273, Loss: 0.05716019310057163, Final Batch Loss: 0.036799389868974686\n",
      "Epoch 2274, Loss: 0.05977268144488335, Final Batch Loss: 0.03247390314936638\n",
      "Epoch 2275, Loss: 0.07196249440312386, Final Batch Loss: 0.04805641621351242\n",
      "Epoch 2276, Loss: 0.08312994241714478, Final Batch Loss: 0.02810165286064148\n",
      "Epoch 2277, Loss: 0.1280619353055954, Final Batch Loss: 0.07875300198793411\n",
      "Epoch 2278, Loss: 0.08017676696181297, Final Batch Loss: 0.046820227056741714\n",
      "Epoch 2279, Loss: 0.04615308716893196, Final Batch Loss: 0.024130290374159813\n",
      "Epoch 2280, Loss: 0.08024262636899948, Final Batch Loss: 0.042689040303230286\n",
      "Epoch 2281, Loss: 0.07565764337778091, Final Batch Loss: 0.05548961088061333\n",
      "Epoch 2282, Loss: 0.06575514934957027, Final Batch Loss: 0.04802261292934418\n",
      "Epoch 2283, Loss: 0.07047029212117195, Final Batch Loss: 0.03674948960542679\n",
      "Epoch 2284, Loss: 0.07424277812242508, Final Batch Loss: 0.035719141364097595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2285, Loss: 0.09946931526064873, Final Batch Loss: 0.053652163594961166\n",
      "Epoch 2286, Loss: 0.048177093267440796, Final Batch Loss: 0.02890162542462349\n",
      "Epoch 2287, Loss: 0.10148278996348381, Final Batch Loss: 0.056627415120601654\n",
      "Epoch 2288, Loss: 0.08715372160077095, Final Batch Loss: 0.04718068614602089\n",
      "Epoch 2289, Loss: 0.08232757146470249, Final Batch Loss: 0.003341999603435397\n",
      "Epoch 2290, Loss: 0.060195207595825195, Final Batch Loss: 0.022400103509426117\n",
      "Epoch 2291, Loss: 0.048470464535057545, Final Batch Loss: 0.03603208810091019\n",
      "Epoch 2292, Loss: 0.043776512145996094, Final Batch Loss: 0.01874607801437378\n",
      "Epoch 2293, Loss: 0.08245943114161491, Final Batch Loss: 0.030998550355434418\n",
      "Epoch 2294, Loss: 0.11715282499790192, Final Batch Loss: 0.021717652678489685\n",
      "Epoch 2295, Loss: 0.07786723226308823, Final Batch Loss: 0.03914594650268555\n",
      "Epoch 2296, Loss: 0.02882370911538601, Final Batch Loss: 0.011555403470993042\n",
      "Epoch 2297, Loss: 0.06597035750746727, Final Batch Loss: 0.03227009251713753\n",
      "Epoch 2298, Loss: 0.06489433534443378, Final Batch Loss: 0.02396385557949543\n",
      "Epoch 2299, Loss: 0.056762898340821266, Final Batch Loss: 0.021953491494059563\n",
      "Epoch 2300, Loss: 0.06512460485100746, Final Batch Loss: 0.04911807179450989\n",
      "Epoch 2301, Loss: 0.03330811392515898, Final Batch Loss: 0.008777855895459652\n",
      "Epoch 2302, Loss: 0.033979473635554314, Final Batch Loss: 0.016701368615031242\n",
      "Epoch 2303, Loss: 0.04664124082773924, Final Batch Loss: 0.03452550247311592\n",
      "Epoch 2304, Loss: 0.10290094837546349, Final Batch Loss: 0.06166032701730728\n",
      "Epoch 2305, Loss: 0.12009835615754128, Final Batch Loss: 0.07898608595132828\n",
      "Epoch 2306, Loss: 0.0514715313911438, Final Batch Loss: 0.02816784381866455\n",
      "Epoch 2307, Loss: 0.02823924832046032, Final Batch Loss: 0.004883415997028351\n",
      "Epoch 2308, Loss: 0.05471846088767052, Final Batch Loss: 0.035850975662469864\n",
      "Epoch 2309, Loss: 0.06164154224097729, Final Batch Loss: 0.023129912093281746\n",
      "Epoch 2310, Loss: 0.06552107632160187, Final Batch Loss: 0.015676196664571762\n",
      "Epoch 2311, Loss: 0.08741634339094162, Final Batch Loss: 0.04619208350777626\n",
      "Epoch 2312, Loss: 0.07506829127669334, Final Batch Loss: 0.0384436696767807\n",
      "Epoch 2313, Loss: 0.056789349764585495, Final Batch Loss: 0.03415635600686073\n",
      "Epoch 2314, Loss: 0.05493910424411297, Final Batch Loss: 0.025847580283880234\n",
      "Epoch 2315, Loss: 0.0510833952575922, Final Batch Loss: 0.028682615607976913\n",
      "Epoch 2316, Loss: 0.0595181155949831, Final Batch Loss: 0.01822878234088421\n",
      "Epoch 2317, Loss: 0.06579125113785267, Final Batch Loss: 0.03658969700336456\n",
      "Epoch 2318, Loss: 0.06389954313635826, Final Batch Loss: 0.034812379628419876\n",
      "Epoch 2319, Loss: 0.09900039434432983, Final Batch Loss: 0.06297329813241959\n",
      "Epoch 2320, Loss: 0.05443050153553486, Final Batch Loss: 0.03188277408480644\n",
      "Epoch 2321, Loss: 0.07206287607550621, Final Batch Loss: 0.048381563276052475\n",
      "Epoch 2322, Loss: 0.05713835917413235, Final Batch Loss: 0.03207240626215935\n",
      "Epoch 2323, Loss: 0.06038269028067589, Final Batch Loss: 0.015874214470386505\n",
      "Epoch 2324, Loss: 0.08558118529617786, Final Batch Loss: 0.028282852843403816\n",
      "Epoch 2325, Loss: 0.06799757853150368, Final Batch Loss: 0.0335744172334671\n",
      "Epoch 2326, Loss: 0.03269721940159798, Final Batch Loss: 0.01585294120013714\n",
      "Epoch 2327, Loss: 0.05636686459183693, Final Batch Loss: 0.023994263261556625\n",
      "Epoch 2328, Loss: 0.0703680869191885, Final Batch Loss: 0.019320087507367134\n",
      "Epoch 2329, Loss: 0.07187004387378693, Final Batch Loss: 0.029529258608818054\n",
      "Epoch 2330, Loss: 0.0882528405636549, Final Batch Loss: 0.009830622002482414\n",
      "Epoch 2331, Loss: 0.059475526213645935, Final Batch Loss: 0.022001441568136215\n",
      "Epoch 2332, Loss: 0.05539590306580067, Final Batch Loss: 0.015851503238081932\n",
      "Epoch 2333, Loss: 0.078038789331913, Final Batch Loss: 0.04464306682348251\n",
      "Epoch 2334, Loss: 0.14474467188119888, Final Batch Loss: 0.11035352200269699\n",
      "Epoch 2335, Loss: 0.06162936985492706, Final Batch Loss: 0.025897447019815445\n",
      "Epoch 2336, Loss: 0.0666371937841177, Final Batch Loss: 0.02629648707807064\n",
      "Epoch 2337, Loss: 0.15197759494185448, Final Batch Loss: 0.09880609810352325\n",
      "Epoch 2338, Loss: 0.054389553144574165, Final Batch Loss: 0.033522315323352814\n",
      "Epoch 2339, Loss: 0.06738265231251717, Final Batch Loss: 0.0229787677526474\n",
      "Epoch 2340, Loss: 0.041849710047245026, Final Batch Loss: 0.016941772773861885\n",
      "Epoch 2341, Loss: 0.03565093595534563, Final Batch Loss: 0.015490573830902576\n",
      "Epoch 2342, Loss: 0.088789913803339, Final Batch Loss: 0.053493935614824295\n",
      "Epoch 2343, Loss: 0.07207990251481533, Final Batch Loss: 0.0412522628903389\n",
      "Epoch 2344, Loss: 0.04956431407481432, Final Batch Loss: 0.036326099187135696\n",
      "Epoch 2345, Loss: 0.07223723083734512, Final Batch Loss: 0.055089883506298065\n",
      "Epoch 2346, Loss: 0.07781106978654861, Final Batch Loss: 0.036833666265010834\n",
      "Epoch 2347, Loss: 0.10826495662331581, Final Batch Loss: 0.06854166835546494\n",
      "Epoch 2348, Loss: 0.04365769028663635, Final Batch Loss: 0.015240941196680069\n",
      "Epoch 2349, Loss: 0.07776563242077827, Final Batch Loss: 0.04059518128633499\n",
      "Epoch 2350, Loss: 0.08853783831000328, Final Batch Loss: 0.04742912948131561\n",
      "Epoch 2351, Loss: 0.08230521529912949, Final Batch Loss: 0.0524924136698246\n",
      "Epoch 2352, Loss: 0.03779349848628044, Final Batch Loss: 0.021511076018214226\n",
      "Epoch 2353, Loss: 0.07684331387281418, Final Batch Loss: 0.03788299858570099\n",
      "Epoch 2354, Loss: 0.06236801762133837, Final Batch Loss: 0.010223356075584888\n",
      "Epoch 2355, Loss: 0.07890812680125237, Final Batch Loss: 0.03629809990525246\n",
      "Epoch 2356, Loss: 0.07847360149025917, Final Batch Loss: 0.020384859293699265\n",
      "Epoch 2357, Loss: 0.04638674482703209, Final Batch Loss: 0.024547908455133438\n",
      "Epoch 2358, Loss: 0.17419136688113213, Final Batch Loss: 0.14370183646678925\n",
      "Epoch 2359, Loss: 0.027876478619873524, Final Batch Loss: 0.01594163291156292\n",
      "Epoch 2360, Loss: 0.07063666824251413, Final Batch Loss: 0.057773008942604065\n",
      "Epoch 2361, Loss: 0.0584132419899106, Final Batch Loss: 0.042827308177948\n",
      "Epoch 2362, Loss: 0.046858277171850204, Final Batch Loss: 0.012728285044431686\n",
      "Epoch 2363, Loss: 0.07293541356921196, Final Batch Loss: 0.02134670317173004\n",
      "Epoch 2364, Loss: 0.09219672903418541, Final Batch Loss: 0.03229852020740509\n",
      "Epoch 2365, Loss: 0.044338202103972435, Final Batch Loss: 0.024424316361546516\n",
      "Epoch 2366, Loss: 0.054160911589860916, Final Batch Loss: 0.02925405092537403\n",
      "Epoch 2367, Loss: 0.12672322988510132, Final Batch Loss: 0.06417928636074066\n",
      "Epoch 2368, Loss: 0.03185180760920048, Final Batch Loss: 0.01786685548722744\n",
      "Epoch 2369, Loss: 0.05653923749923706, Final Batch Loss: 0.021083779633045197\n",
      "Epoch 2370, Loss: 0.05509260483086109, Final Batch Loss: 0.02997894026339054\n",
      "Epoch 2371, Loss: 0.08182895183563232, Final Batch Loss: 0.04707340523600578\n",
      "Epoch 2372, Loss: 0.11925026029348373, Final Batch Loss: 0.09376849979162216\n",
      "Epoch 2373, Loss: 0.11727108061313629, Final Batch Loss: 0.08112363517284393\n",
      "Epoch 2374, Loss: 0.034873650409281254, Final Batch Loss: 0.028384260833263397\n",
      "Epoch 2375, Loss: 0.05228205397725105, Final Batch Loss: 0.017437957227230072\n",
      "Epoch 2376, Loss: 0.034208061173558235, Final Batch Loss: 0.013281580060720444\n",
      "Epoch 2377, Loss: 0.056164588779211044, Final Batch Loss: 0.03177851438522339\n",
      "Epoch 2378, Loss: 0.08967400901019573, Final Batch Loss: 0.023200472816824913\n",
      "Epoch 2379, Loss: 0.07022412866353989, Final Batch Loss: 0.030881725251674652\n",
      "Epoch 2380, Loss: 0.045281782746315, Final Batch Loss: 0.0221386831253767\n",
      "Epoch 2381, Loss: 0.08544962108135223, Final Batch Loss: 0.04926983639597893\n",
      "Epoch 2382, Loss: 0.11850356869399548, Final Batch Loss: 0.0877542644739151\n",
      "Epoch 2383, Loss: 0.07934010773897171, Final Batch Loss: 0.03519381955265999\n",
      "Epoch 2384, Loss: 0.10738915205001831, Final Batch Loss: 0.06057216599583626\n",
      "Epoch 2385, Loss: 0.04801368713378906, Final Batch Loss: 0.029328053817152977\n",
      "Epoch 2386, Loss: 0.09007086232304573, Final Batch Loss: 0.03404008224606514\n",
      "Epoch 2387, Loss: 0.042194562032818794, Final Batch Loss: 0.013166040182113647\n",
      "Epoch 2388, Loss: 0.071892861276865, Final Batch Loss: 0.04001593962311745\n",
      "Epoch 2389, Loss: 0.08153447136282921, Final Batch Loss: 0.01888381317257881\n",
      "Epoch 2390, Loss: 0.05183761194348335, Final Batch Loss: 0.03301055729389191\n",
      "Epoch 2391, Loss: 0.06303444318473339, Final Batch Loss: 0.05516756698489189\n",
      "Epoch 2392, Loss: 0.037740662693977356, Final Batch Loss: 0.01747860200703144\n",
      "Epoch 2393, Loss: 0.06343594286590815, Final Batch Loss: 0.014616125263273716\n",
      "Epoch 2394, Loss: 0.04662627726793289, Final Batch Loss: 0.01628929376602173\n",
      "Epoch 2395, Loss: 0.09451725147664547, Final Batch Loss: 0.06660492718219757\n",
      "Epoch 2396, Loss: 0.09617689996957779, Final Batch Loss: 0.03177676349878311\n",
      "Epoch 2397, Loss: 0.06725239381194115, Final Batch Loss: 0.02517997846007347\n",
      "Epoch 2398, Loss: 0.09313877299427986, Final Batch Loss: 0.05472562462091446\n",
      "Epoch 2399, Loss: 0.0697130598127842, Final Batch Loss: 0.0349469892680645\n",
      "Epoch 2400, Loss: 0.027857583947479725, Final Batch Loss: 0.014472718350589275\n",
      "Epoch 2401, Loss: 0.058746008202433586, Final Batch Loss: 0.02960679866373539\n",
      "Epoch 2402, Loss: 0.05015729833394289, Final Batch Loss: 0.010309291072189808\n",
      "Epoch 2403, Loss: 0.05332382768392563, Final Batch Loss: 0.024700718000531197\n",
      "Epoch 2404, Loss: 0.06356653943657875, Final Batch Loss: 0.01265515387058258\n",
      "Epoch 2405, Loss: 0.042100705206394196, Final Batch Loss: 0.014745660126209259\n",
      "Epoch 2406, Loss: 0.047281289473176, Final Batch Loss: 0.02225225791335106\n",
      "Epoch 2407, Loss: 0.09815552085638046, Final Batch Loss: 0.0476241372525692\n",
      "Epoch 2408, Loss: 0.05287299491465092, Final Batch Loss: 0.03120051696896553\n",
      "Epoch 2409, Loss: 0.06414121389389038, Final Batch Loss: 0.043140314519405365\n",
      "Epoch 2410, Loss: 0.1053568534553051, Final Batch Loss: 0.036811549216508865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2411, Loss: 0.16313665360212326, Final Batch Loss: 0.12571002542972565\n",
      "Epoch 2412, Loss: 0.16287776082754135, Final Batch Loss: 0.06738337874412537\n",
      "Epoch 2413, Loss: 0.10912428423762321, Final Batch Loss: 0.062071528285741806\n",
      "Epoch 2414, Loss: 0.15683205798268318, Final Batch Loss: 0.1211654469370842\n",
      "Epoch 2415, Loss: 0.11480710282921791, Final Batch Loss: 0.052664224058389664\n",
      "Epoch 2416, Loss: 0.09987091831862926, Final Batch Loss: 0.026715895161032677\n",
      "Epoch 2417, Loss: 0.09194812923669815, Final Batch Loss: 0.05325952544808388\n",
      "Epoch 2418, Loss: 0.051085309125483036, Final Batch Loss: 0.012210150249302387\n",
      "Epoch 2419, Loss: 0.09744024649262428, Final Batch Loss: 0.06500895321369171\n",
      "Epoch 2420, Loss: 0.07249581813812256, Final Batch Loss: 0.028109513223171234\n",
      "Epoch 2421, Loss: 0.10257243365049362, Final Batch Loss: 0.06184198707342148\n",
      "Epoch 2422, Loss: 0.08400536142289639, Final Batch Loss: 0.029300125315785408\n",
      "Epoch 2423, Loss: 0.09069054201245308, Final Batch Loss: 0.04551583528518677\n",
      "Epoch 2424, Loss: 0.08732504397630692, Final Batch Loss: 0.029317542910575867\n",
      "Epoch 2425, Loss: 0.14656295627355576, Final Batch Loss: 0.07928179204463959\n",
      "Epoch 2426, Loss: 0.12197045236825943, Final Batch Loss: 0.08153095841407776\n",
      "Epoch 2427, Loss: 0.043307652696967125, Final Batch Loss: 0.011114558205008507\n",
      "Epoch 2428, Loss: 0.07537444122135639, Final Batch Loss: 0.023414822295308113\n",
      "Epoch 2429, Loss: 0.10526091977953911, Final Batch Loss: 0.07172249257564545\n",
      "Epoch 2430, Loss: 0.07961733266711235, Final Batch Loss: 0.04713258147239685\n",
      "Epoch 2431, Loss: 0.12609796971082687, Final Batch Loss: 0.08016424626111984\n",
      "Epoch 2432, Loss: 0.06342571042478085, Final Batch Loss: 0.02014007233083248\n",
      "Epoch 2433, Loss: 0.08079997450113297, Final Batch Loss: 0.038254816085100174\n",
      "Epoch 2434, Loss: 0.05491752177476883, Final Batch Loss: 0.03393580764532089\n",
      "Epoch 2435, Loss: 0.05420573242008686, Final Batch Loss: 0.025665218010544777\n",
      "Epoch 2436, Loss: 0.04512516222894192, Final Batch Loss: 0.020819032564759254\n",
      "Epoch 2437, Loss: 0.028470474295318127, Final Batch Loss: 0.007613779045641422\n",
      "Epoch 2438, Loss: 0.08562977984547615, Final Batch Loss: 0.03988337144255638\n",
      "Epoch 2439, Loss: 0.05348210223019123, Final Batch Loss: 0.026337193325161934\n",
      "Epoch 2440, Loss: 0.07278037816286087, Final Batch Loss: 0.037261996418237686\n",
      "Epoch 2441, Loss: 0.047320254147052765, Final Batch Loss: 0.02332399971783161\n",
      "Epoch 2442, Loss: 0.07862591184675694, Final Batch Loss: 0.06295346468687057\n",
      "Epoch 2443, Loss: 0.04604669101536274, Final Batch Loss: 0.02253144234418869\n",
      "Epoch 2444, Loss: 0.08933982998132706, Final Batch Loss: 0.03412440046668053\n",
      "Epoch 2445, Loss: 0.0805534590035677, Final Batch Loss: 0.05859895050525665\n",
      "Epoch 2446, Loss: 0.05259264074265957, Final Batch Loss: 0.012926856055855751\n",
      "Epoch 2447, Loss: 0.07556300982832909, Final Batch Loss: 0.026289161294698715\n",
      "Epoch 2448, Loss: 0.08055948093533516, Final Batch Loss: 0.04862719029188156\n",
      "Epoch 2449, Loss: 0.037720754742622375, Final Batch Loss: 0.01865454576909542\n",
      "Epoch 2450, Loss: 0.0909951739013195, Final Batch Loss: 0.02689686045050621\n",
      "Epoch 2451, Loss: 0.04033704660832882, Final Batch Loss: 0.021989019587635994\n",
      "Epoch 2452, Loss: 0.10113880038261414, Final Batch Loss: 0.04593368619680405\n",
      "Epoch 2453, Loss: 0.06586511246860027, Final Batch Loss: 0.01679266057908535\n",
      "Epoch 2454, Loss: 0.09740568324923515, Final Batch Loss: 0.056901395320892334\n",
      "Epoch 2455, Loss: 0.05643502622842789, Final Batch Loss: 0.030066775158047676\n",
      "Epoch 2456, Loss: 0.04659207817167044, Final Batch Loss: 0.03200629726052284\n",
      "Epoch 2457, Loss: 0.05861394852399826, Final Batch Loss: 0.020063407719135284\n",
      "Epoch 2458, Loss: 0.03279008809477091, Final Batch Loss: 0.013698768801987171\n",
      "Epoch 2459, Loss: 0.09693675115704536, Final Batch Loss: 0.0175095833837986\n",
      "Epoch 2460, Loss: 0.06285174377262592, Final Batch Loss: 0.02867657132446766\n",
      "Epoch 2461, Loss: 0.05215423367917538, Final Batch Loss: 0.03220311924815178\n",
      "Epoch 2462, Loss: 0.039626291021704674, Final Batch Loss: 0.009136563166975975\n",
      "Epoch 2463, Loss: 0.06365928240120411, Final Batch Loss: 0.02753959409892559\n",
      "Epoch 2464, Loss: 0.07650741934776306, Final Batch Loss: 0.044121693819761276\n",
      "Epoch 2465, Loss: 0.06336915120482445, Final Batch Loss: 0.03706028312444687\n",
      "Epoch 2466, Loss: 0.07917245849967003, Final Batch Loss: 0.030718527734279633\n",
      "Epoch 2467, Loss: 0.044631900265812874, Final Batch Loss: 0.024585213512182236\n",
      "Epoch 2468, Loss: 0.06489377096295357, Final Batch Loss: 0.03479292616248131\n",
      "Epoch 2469, Loss: 0.0603924160823226, Final Batch Loss: 0.04598312824964523\n",
      "Epoch 2470, Loss: 0.13353475369513035, Final Batch Loss: 0.022338250651955605\n",
      "Epoch 2471, Loss: 0.08036607503890991, Final Batch Loss: 0.027276460081338882\n",
      "Epoch 2472, Loss: 0.05500502698123455, Final Batch Loss: 0.027413245290517807\n",
      "Epoch 2473, Loss: 0.13968874141573906, Final Batch Loss: 0.057590682059526443\n",
      "Epoch 2474, Loss: 0.18561598658561707, Final Batch Loss: 0.06617782264947891\n",
      "Epoch 2475, Loss: 0.11925223097205162, Final Batch Loss: 0.025192540138959885\n",
      "Epoch 2476, Loss: 0.08671527355909348, Final Batch Loss: 0.04292204603552818\n",
      "Epoch 2477, Loss: 0.08806419000029564, Final Batch Loss: 0.026567645370960236\n",
      "Epoch 2478, Loss: 0.0697606485337019, Final Batch Loss: 0.026444165036082268\n",
      "Epoch 2479, Loss: 0.05252085626125336, Final Batch Loss: 0.024522962048649788\n",
      "Epoch 2480, Loss: 0.05859110318124294, Final Batch Loss: 0.028990665450692177\n",
      "Epoch 2481, Loss: 0.07596606388688087, Final Batch Loss: 0.0427870936691761\n",
      "Epoch 2482, Loss: 0.03313554264605045, Final Batch Loss: 0.022737912833690643\n",
      "Epoch 2483, Loss: 0.12021378800272942, Final Batch Loss: 0.05007481202483177\n",
      "Epoch 2484, Loss: 0.04818273335695267, Final Batch Loss: 0.025202590972185135\n",
      "Epoch 2485, Loss: 0.04732937179505825, Final Batch Loss: 0.02241474762558937\n",
      "Epoch 2486, Loss: 0.08216506242752075, Final Batch Loss: 0.03680943697690964\n",
      "Epoch 2487, Loss: 0.07337229140102863, Final Batch Loss: 0.02543989010155201\n",
      "Epoch 2488, Loss: 0.02663694554939866, Final Batch Loss: 0.004950099159032106\n",
      "Epoch 2489, Loss: 0.06483909860253334, Final Batch Loss: 0.038218144327402115\n",
      "Epoch 2490, Loss: 0.06979123689234257, Final Batch Loss: 0.049983445554971695\n",
      "Epoch 2491, Loss: 0.03413842525333166, Final Batch Loss: 0.012036860920488834\n",
      "Epoch 2492, Loss: 0.09025711752474308, Final Batch Loss: 0.03066154755651951\n",
      "Epoch 2493, Loss: 0.12253819033503532, Final Batch Loss: 0.08756688982248306\n",
      "Epoch 2494, Loss: 0.07601450383663177, Final Batch Loss: 0.016469869762659073\n",
      "Epoch 2495, Loss: 0.057434191927313805, Final Batch Loss: 0.028999460861086845\n",
      "Epoch 2496, Loss: 0.05976678431034088, Final Batch Loss: 0.025824610143899918\n",
      "Epoch 2497, Loss: 0.05360800214111805, Final Batch Loss: 0.011288536712527275\n",
      "Epoch 2498, Loss: 0.06353593431413174, Final Batch Loss: 0.038341253995895386\n",
      "Epoch 2499, Loss: 0.08676226809620857, Final Batch Loss: 0.04456326737999916\n",
      "Epoch 2500, Loss: 0.03343822155147791, Final Batch Loss: 0.013680892996490002\n",
      "Epoch 2501, Loss: 0.06333467550575733, Final Batch Loss: 0.029889026656746864\n",
      "Epoch 2502, Loss: 0.06232110224664211, Final Batch Loss: 0.025330716744065285\n",
      "Epoch 2503, Loss: 0.11961090937256813, Final Batch Loss: 0.06660468876361847\n",
      "Epoch 2504, Loss: 0.05219161603599787, Final Batch Loss: 0.011681252159178257\n",
      "Epoch 2505, Loss: 0.04631262365728617, Final Batch Loss: 0.012065169401466846\n",
      "Epoch 2506, Loss: 0.031349495984613895, Final Batch Loss: 0.020158659666776657\n",
      "Epoch 2507, Loss: 0.0695327427238226, Final Batch Loss: 0.022033551707863808\n",
      "Epoch 2508, Loss: 0.021537725813686848, Final Batch Loss: 0.007307622581720352\n",
      "Epoch 2509, Loss: 0.05157669447362423, Final Batch Loss: 0.016343379393219948\n",
      "Epoch 2510, Loss: 0.07695149257779121, Final Batch Loss: 0.024216726422309875\n",
      "Epoch 2511, Loss: 0.07826254516839981, Final Batch Loss: 0.04342426359653473\n",
      "Epoch 2512, Loss: 0.06818611174821854, Final Batch Loss: 0.021992720663547516\n",
      "Epoch 2513, Loss: 0.07599723525345325, Final Batch Loss: 0.030148522928357124\n",
      "Epoch 2514, Loss: 0.06345316022634506, Final Batch Loss: 0.02709970995783806\n",
      "Epoch 2515, Loss: 0.06976119428873062, Final Batch Loss: 0.022277701646089554\n",
      "Epoch 2516, Loss: 0.03990219719707966, Final Batch Loss: 0.01989687606692314\n",
      "Epoch 2517, Loss: 0.04866386763751507, Final Batch Loss: 0.015986906364560127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2518, Loss: 0.027776609174907207, Final Batch Loss: 0.011659928597509861\n",
      "Epoch 2519, Loss: 0.05240807123482227, Final Batch Loss: 0.006117081269621849\n",
      "Epoch 2520, Loss: 0.08911359682679176, Final Batch Loss: 0.04496608301997185\n",
      "Epoch 2521, Loss: 0.08238115906715393, Final Batch Loss: 0.0654582530260086\n",
      "Epoch 2522, Loss: 0.09407590329647064, Final Batch Loss: 0.05779913812875748\n",
      "Epoch 2523, Loss: 0.052983978763222694, Final Batch Loss: 0.02234114147722721\n",
      "Epoch 2524, Loss: 0.0399971604347229, Final Batch Loss: 0.023280350491404533\n",
      "Epoch 2525, Loss: 0.08720260113477707, Final Batch Loss: 0.017349429428577423\n",
      "Epoch 2526, Loss: 0.05445089936256409, Final Batch Loss: 0.010269995778799057\n",
      "Epoch 2527, Loss: 0.07459357008337975, Final Batch Loss: 0.03466168791055679\n",
      "Epoch 2528, Loss: 0.05118103325366974, Final Batch Loss: 0.016786843538284302\n",
      "Epoch 2529, Loss: 0.08991557359695435, Final Batch Loss: 0.054092541337013245\n",
      "Epoch 2530, Loss: 0.033936251886188984, Final Batch Loss: 0.012615197338163853\n",
      "Epoch 2531, Loss: 0.07825271412730217, Final Batch Loss: 0.03553282842040062\n",
      "Epoch 2532, Loss: 0.060450354591012, Final Batch Loss: 0.03555445745587349\n",
      "Epoch 2533, Loss: 0.06724956445395947, Final Batch Loss: 0.03916022181510925\n",
      "Epoch 2534, Loss: 0.05859941802918911, Final Batch Loss: 0.008864527568221092\n",
      "Epoch 2535, Loss: 0.034187586046755314, Final Batch Loss: 0.012827831320464611\n",
      "Epoch 2536, Loss: 0.07746192440390587, Final Batch Loss: 0.028573937714099884\n",
      "Epoch 2537, Loss: 0.03855526074767113, Final Batch Loss: 0.018176119774580002\n",
      "Epoch 2538, Loss: 0.06679979898035526, Final Batch Loss: 0.040074218064546585\n",
      "Epoch 2539, Loss: 0.0389507208019495, Final Batch Loss: 0.012527184560894966\n",
      "Epoch 2540, Loss: 0.11084118112921715, Final Batch Loss: 0.07707203179597855\n",
      "Epoch 2541, Loss: 0.06929467059671879, Final Batch Loss: 0.03962051495909691\n",
      "Epoch 2542, Loss: 0.10801523923873901, Final Batch Loss: 0.08556433022022247\n",
      "Epoch 2543, Loss: 0.05455024912953377, Final Batch Loss: 0.016655676066875458\n",
      "Epoch 2544, Loss: 0.07159102149307728, Final Batch Loss: 0.05532172694802284\n",
      "Epoch 2545, Loss: 0.04632769711315632, Final Batch Loss: 0.014840571209788322\n",
      "Epoch 2546, Loss: 0.0759433601051569, Final Batch Loss: 0.02213078923523426\n",
      "Epoch 2547, Loss: 0.06912481039762497, Final Batch Loss: 0.034571412950754166\n",
      "Epoch 2548, Loss: 0.08214676007628441, Final Batch Loss: 0.042357418686151505\n",
      "Epoch 2549, Loss: 0.06540918350219727, Final Batch Loss: 0.016811881214380264\n",
      "Epoch 2550, Loss: 0.03946343995630741, Final Batch Loss: 0.008146172389388084\n",
      "Epoch 2551, Loss: 0.09212498553097248, Final Batch Loss: 0.06734185665845871\n",
      "Epoch 2552, Loss: 0.028846677392721176, Final Batch Loss: 0.016556428745388985\n",
      "Epoch 2553, Loss: 0.06751717254519463, Final Batch Loss: 0.03436891362071037\n",
      "Epoch 2554, Loss: 0.04031991679221392, Final Batch Loss: 0.010319608263671398\n",
      "Epoch 2555, Loss: 0.09328771010041237, Final Batch Loss: 0.05206222087144852\n",
      "Epoch 2556, Loss: 0.04547933582216501, Final Batch Loss: 0.00931584183126688\n",
      "Epoch 2557, Loss: 0.06844712607562542, Final Batch Loss: 0.042784400284290314\n",
      "Epoch 2558, Loss: 0.11269231140613556, Final Batch Loss: 0.027378559112548828\n",
      "Epoch 2559, Loss: 0.04360017366707325, Final Batch Loss: 0.021181156858801842\n",
      "Epoch 2560, Loss: 0.03386153280735016, Final Batch Loss: 0.015244003385305405\n",
      "Epoch 2561, Loss: 0.06264947727322578, Final Batch Loss: 0.012354589998722076\n",
      "Epoch 2562, Loss: 0.059374429285526276, Final Batch Loss: 0.02379506081342697\n",
      "Epoch 2563, Loss: 0.07345846481621265, Final Batch Loss: 0.049885060638189316\n",
      "Epoch 2564, Loss: 0.06525303982198238, Final Batch Loss: 0.023158187046647072\n",
      "Epoch 2565, Loss: 0.07308921031653881, Final Batch Loss: 0.031237037852406502\n",
      "Epoch 2566, Loss: 0.03917246591299772, Final Batch Loss: 0.013923955149948597\n",
      "Epoch 2567, Loss: 0.06065029837191105, Final Batch Loss: 0.027212107554078102\n",
      "Epoch 2568, Loss: 0.07719597592949867, Final Batch Loss: 0.055782824754714966\n",
      "Epoch 2569, Loss: 0.05885964073240757, Final Batch Loss: 0.02847665175795555\n",
      "Epoch 2570, Loss: 0.0780351422727108, Final Batch Loss: 0.058245427906513214\n",
      "Epoch 2571, Loss: 0.08712302148342133, Final Batch Loss: 0.02551858499646187\n",
      "Epoch 2572, Loss: 0.08972102403640747, Final Batch Loss: 0.053184960037469864\n",
      "Epoch 2573, Loss: 0.060420144349336624, Final Batch Loss: 0.03248362988233566\n",
      "Epoch 2574, Loss: 0.07684395834803581, Final Batch Loss: 0.03371075168251991\n",
      "Epoch 2575, Loss: 0.04466094356030226, Final Batch Loss: 0.011945134960114956\n",
      "Epoch 2576, Loss: 0.04062073025852442, Final Batch Loss: 0.004967932589352131\n",
      "Epoch 2577, Loss: 0.0491251815110445, Final Batch Loss: 0.017200222238898277\n",
      "Epoch 2578, Loss: 0.16106177866458893, Final Batch Loss: 0.08129158616065979\n",
      "Epoch 2579, Loss: 0.057182205840945244, Final Batch Loss: 0.028658371418714523\n",
      "Epoch 2580, Loss: 0.03484658617526293, Final Batch Loss: 0.013573245145380497\n",
      "Epoch 2581, Loss: 0.03995637595653534, Final Batch Loss: 0.015923842787742615\n",
      "Epoch 2582, Loss: 0.04275723826140165, Final Batch Loss: 0.013957825489342213\n",
      "Epoch 2583, Loss: 0.022399350069463253, Final Batch Loss: 0.0068647973239421844\n",
      "Epoch 2584, Loss: 0.04082485195249319, Final Batch Loss: 0.031532686203718185\n",
      "Epoch 2585, Loss: 0.039531865157186985, Final Batch Loss: 0.015005712397396564\n",
      "Epoch 2586, Loss: 0.07492243498563766, Final Batch Loss: 0.05547070875763893\n",
      "Epoch 2587, Loss: 0.04361335746943951, Final Batch Loss: 0.014474175870418549\n",
      "Epoch 2588, Loss: 0.06312407180666924, Final Batch Loss: 0.04080438241362572\n",
      "Epoch 2589, Loss: 0.0402644369751215, Final Batch Loss: 0.016296381130814552\n",
      "Epoch 2590, Loss: 0.045893823727965355, Final Batch Loss: 0.020423592999577522\n",
      "Epoch 2591, Loss: 0.06196017190814018, Final Batch Loss: 0.045147962868213654\n",
      "Epoch 2592, Loss: 0.04710477963089943, Final Batch Loss: 0.017380008473992348\n",
      "Epoch 2593, Loss: 0.06562977656722069, Final Batch Loss: 0.0325743742287159\n",
      "Epoch 2594, Loss: 0.10822470858693123, Final Batch Loss: 0.050878021866083145\n",
      "Epoch 2595, Loss: 0.04211671091616154, Final Batch Loss: 0.017928972840309143\n",
      "Epoch 2596, Loss: 0.0612383596599102, Final Batch Loss: 0.024006754159927368\n",
      "Epoch 2597, Loss: 0.042037272825837135, Final Batch Loss: 0.015481391921639442\n",
      "Epoch 2598, Loss: 0.11886755004525185, Final Batch Loss: 0.06202488765120506\n",
      "Epoch 2599, Loss: 0.07992079854011536, Final Batch Loss: 0.03249237313866615\n",
      "Epoch 2600, Loss: 0.030498037114739418, Final Batch Loss: 0.011916708201169968\n",
      "Epoch 2601, Loss: 0.03478166460990906, Final Batch Loss: 0.018762217834591866\n",
      "Epoch 2602, Loss: 0.059502504765987396, Final Batch Loss: 0.04336855188012123\n",
      "Epoch 2603, Loss: 0.08005775138735771, Final Batch Loss: 0.04009084030985832\n",
      "Epoch 2604, Loss: 0.07352307438850403, Final Batch Loss: 0.029157336801290512\n",
      "Epoch 2605, Loss: 0.024395888671278954, Final Batch Loss: 0.010621584951877594\n",
      "Epoch 2606, Loss: 0.1416129358112812, Final Batch Loss: 0.10922286659479141\n",
      "Epoch 2607, Loss: 0.037420034408569336, Final Batch Loss: 0.013013599440455437\n",
      "Epoch 2608, Loss: 0.07352406531572342, Final Batch Loss: 0.04446786269545555\n",
      "Epoch 2609, Loss: 0.074214574880898, Final Batch Loss: 0.06272000074386597\n",
      "Epoch 2610, Loss: 0.05859597958624363, Final Batch Loss: 0.027859177440404892\n",
      "Epoch 2611, Loss: 0.11087740585207939, Final Batch Loss: 0.05733872950077057\n",
      "Epoch 2612, Loss: 0.06005318835377693, Final Batch Loss: 0.02547096461057663\n",
      "Epoch 2613, Loss: 0.0610042680054903, Final Batch Loss: 0.04107503965497017\n",
      "Epoch 2614, Loss: 0.06697568856179714, Final Batch Loss: 0.05376550555229187\n",
      "Epoch 2615, Loss: 0.10491080954670906, Final Batch Loss: 0.07224032282829285\n",
      "Epoch 2616, Loss: 0.09262311272323132, Final Batch Loss: 0.022435186430811882\n",
      "Epoch 2617, Loss: 0.10229958593845367, Final Batch Loss: 0.04670410603284836\n",
      "Epoch 2618, Loss: 0.18342032097280025, Final Batch Loss: 0.15753306448459625\n",
      "Epoch 2619, Loss: 0.07806009985506535, Final Batch Loss: 0.026474254205822945\n",
      "Epoch 2620, Loss: 0.03606812097132206, Final Batch Loss: 0.013090990483760834\n",
      "Epoch 2621, Loss: 0.10146334394812584, Final Batch Loss: 0.02915981039404869\n",
      "Epoch 2622, Loss: 0.12997428700327873, Final Batch Loss: 0.05328371748328209\n",
      "Epoch 2623, Loss: 0.06258553639054298, Final Batch Loss: 0.03235280513763428\n",
      "Epoch 2624, Loss: 0.030822652392089367, Final Batch Loss: 0.014899772591888905\n",
      "Epoch 2625, Loss: 0.04258823208510876, Final Batch Loss: 0.030747994780540466\n",
      "Epoch 2626, Loss: 0.06994941830635071, Final Batch Loss: 0.03406720608472824\n",
      "Epoch 2627, Loss: 0.04698486812412739, Final Batch Loss: 0.025881735607981682\n",
      "Epoch 2628, Loss: 0.10337493754923344, Final Batch Loss: 0.08281289041042328\n",
      "Epoch 2629, Loss: 0.035054635955020785, Final Batch Loss: 0.0029890730511397123\n",
      "Epoch 2630, Loss: 0.05895728059113026, Final Batch Loss: 0.0226112250238657\n",
      "Epoch 2631, Loss: 0.07444024085998535, Final Batch Loss: 0.023425854742527008\n",
      "Epoch 2632, Loss: 0.0685755480080843, Final Batch Loss: 0.026368191465735435\n",
      "Epoch 2633, Loss: 0.054354517720639706, Final Batch Loss: 0.040280282497406006\n",
      "Epoch 2634, Loss: 0.10335532855242491, Final Batch Loss: 0.013181845657527447\n",
      "Epoch 2635, Loss: 0.10615526139736176, Final Batch Loss: 0.07301166653633118\n",
      "Epoch 2636, Loss: 0.06954888626933098, Final Batch Loss: 0.03362477943301201\n",
      "Epoch 2637, Loss: 0.03347280714660883, Final Batch Loss: 0.010212662629783154\n",
      "Epoch 2638, Loss: 0.03200794290751219, Final Batch Loss: 0.023241480812430382\n",
      "Epoch 2639, Loss: 0.06949109956622124, Final Batch Loss: 0.016361229121685028\n",
      "Epoch 2640, Loss: 0.08709144778549671, Final Batch Loss: 0.05665256828069687\n",
      "Epoch 2641, Loss: 0.10061335936188698, Final Batch Loss: 0.06267786026000977\n",
      "Epoch 2642, Loss: 0.0651346892118454, Final Batch Loss: 0.03815452754497528\n",
      "Epoch 2643, Loss: 0.08842417784035206, Final Batch Loss: 0.01305515505373478\n",
      "Epoch 2644, Loss: 0.03061230294406414, Final Batch Loss: 0.012500438839197159\n",
      "Epoch 2645, Loss: 0.11842898279428482, Final Batch Loss: 0.07068844884634018\n",
      "Epoch 2646, Loss: 0.03746447712182999, Final Batch Loss: 0.01440075971186161\n",
      "Epoch 2647, Loss: 0.046485502272844315, Final Batch Loss: 0.014385789632797241\n",
      "Epoch 2648, Loss: 0.047266094014048576, Final Batch Loss: 0.02944006584584713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2649, Loss: 0.050490367226302624, Final Batch Loss: 0.014322894625365734\n",
      "Epoch 2650, Loss: 0.0548112103715539, Final Batch Loss: 0.041662007570266724\n",
      "Epoch 2651, Loss: 0.06755683571100235, Final Batch Loss: 0.0362342968583107\n",
      "Epoch 2652, Loss: 0.0777868889272213, Final Batch Loss: 0.031731199473142624\n",
      "Epoch 2653, Loss: 0.08606601879000664, Final Batch Loss: 0.04364989697933197\n",
      "Epoch 2654, Loss: 0.04715208616107702, Final Batch Loss: 0.012162442319095135\n",
      "Epoch 2655, Loss: 0.037049200385808945, Final Batch Loss: 0.020293835550546646\n",
      "Epoch 2656, Loss: 0.0805722326040268, Final Batch Loss: 0.03828082233667374\n",
      "Epoch 2657, Loss: 0.06993761658668518, Final Batch Loss: 0.037729162722826004\n",
      "Epoch 2658, Loss: 0.023879134096205235, Final Batch Loss: 0.013934802263975143\n",
      "Epoch 2659, Loss: 0.07256822474300861, Final Batch Loss: 0.04504485800862312\n",
      "Epoch 2660, Loss: 0.0505256038159132, Final Batch Loss: 0.016098523512482643\n",
      "Epoch 2661, Loss: 0.05493360944092274, Final Batch Loss: 0.03821984678506851\n",
      "Epoch 2662, Loss: 0.03715843241661787, Final Batch Loss: 0.022231612354516983\n",
      "Epoch 2663, Loss: 0.04852254316210747, Final Batch Loss: 0.030066097155213356\n",
      "Epoch 2664, Loss: 0.03441174887120724, Final Batch Loss: 0.013132400810718536\n",
      "Epoch 2665, Loss: 0.0598296532407403, Final Batch Loss: 0.012290229089558125\n",
      "Epoch 2666, Loss: 0.043635301291942596, Final Batch Loss: 0.026420893147587776\n",
      "Epoch 2667, Loss: 0.07052696123719215, Final Batch Loss: 0.034752801060676575\n",
      "Epoch 2668, Loss: 0.06979318708181381, Final Batch Loss: 0.0332612469792366\n",
      "Epoch 2669, Loss: 0.027638768777251244, Final Batch Loss: 0.007850458845496178\n",
      "Epoch 2670, Loss: 0.051908948458731174, Final Batch Loss: 0.014974587596952915\n",
      "Epoch 2671, Loss: 0.039907601196318865, Final Batch Loss: 0.0076971095986664295\n",
      "Epoch 2672, Loss: 0.04057004675269127, Final Batch Loss: 0.02461876906454563\n",
      "Epoch 2673, Loss: 0.07080556079745293, Final Batch Loss: 0.033009715378284454\n",
      "Epoch 2674, Loss: 0.02724272757768631, Final Batch Loss: 0.016947545111179352\n",
      "Epoch 2675, Loss: 0.13542453572154045, Final Batch Loss: 0.09903442859649658\n",
      "Epoch 2676, Loss: 0.07623652555048466, Final Batch Loss: 0.06216675788164139\n",
      "Epoch 2677, Loss: 0.05077698267996311, Final Batch Loss: 0.0350889153778553\n",
      "Epoch 2678, Loss: 0.11384832486510277, Final Batch Loss: 0.061658553779125214\n",
      "Epoch 2679, Loss: 0.07530331425368786, Final Batch Loss: 0.05616122484207153\n",
      "Epoch 2680, Loss: 0.10026729851961136, Final Batch Loss: 0.042041752487421036\n",
      "Epoch 2681, Loss: 0.07877735607326031, Final Batch Loss: 0.025366390123963356\n",
      "Epoch 2682, Loss: 0.08014226704835892, Final Batch Loss: 0.039483603090047836\n",
      "Epoch 2683, Loss: 0.04401317052543163, Final Batch Loss: 0.02006329409778118\n",
      "Epoch 2684, Loss: 0.08049913123250008, Final Batch Loss: 0.04782050475478172\n",
      "Epoch 2685, Loss: 0.07596665807068348, Final Batch Loss: 0.04675537347793579\n",
      "Epoch 2686, Loss: 0.07008656859397888, Final Batch Loss: 0.05181295424699783\n",
      "Epoch 2687, Loss: 0.06751652806997299, Final Batch Loss: 0.03730425983667374\n",
      "Epoch 2688, Loss: 0.08005628921091557, Final Batch Loss: 0.022770090028643608\n",
      "Epoch 2689, Loss: 0.0684819258749485, Final Batch Loss: 0.028114691376686096\n",
      "Epoch 2690, Loss: 0.09506332874298096, Final Batch Loss: 0.035055749118328094\n",
      "Epoch 2691, Loss: 0.03325145971029997, Final Batch Loss: 0.01060278620570898\n",
      "Epoch 2692, Loss: 0.047410376369953156, Final Batch Loss: 0.017846399918198586\n",
      "Epoch 2693, Loss: 0.05716637894511223, Final Batch Loss: 0.023261990398168564\n",
      "Epoch 2694, Loss: 0.07229824736714363, Final Batch Loss: 0.032376762479543686\n",
      "Epoch 2695, Loss: 0.06801028735935688, Final Batch Loss: 0.04522045701742172\n",
      "Epoch 2696, Loss: 0.07164163328707218, Final Batch Loss: 0.058463241904973984\n",
      "Epoch 2697, Loss: 0.049614185467362404, Final Batch Loss: 0.010230297222733498\n",
      "Epoch 2698, Loss: 0.07388497702777386, Final Batch Loss: 0.04299643263220787\n",
      "Epoch 2699, Loss: 0.028499296866357327, Final Batch Loss: 0.01515149511396885\n",
      "Epoch 2700, Loss: 0.0452409191057086, Final Batch Loss: 0.03390634432435036\n",
      "Epoch 2701, Loss: 0.05829107575118542, Final Batch Loss: 0.02989097312092781\n",
      "Epoch 2702, Loss: 0.07182378461584449, Final Batch Loss: 0.0062891109846532345\n",
      "Epoch 2703, Loss: 0.1340663731098175, Final Batch Loss: 0.08268900215625763\n",
      "Epoch 2704, Loss: 0.11883466690778732, Final Batch Loss: 0.053586773574352264\n",
      "Epoch 2705, Loss: 0.06468316912651062, Final Batch Loss: 0.03368963301181793\n",
      "Epoch 2706, Loss: 0.04713458847254515, Final Batch Loss: 0.03343480825424194\n",
      "Epoch 2707, Loss: 0.0685585979372263, Final Batch Loss: 0.017626876011490822\n",
      "Epoch 2708, Loss: 0.04114561155438423, Final Batch Loss: 0.024267300963401794\n",
      "Epoch 2709, Loss: 0.027610351331532, Final Batch Loss: 0.0123490821570158\n",
      "Epoch 2710, Loss: 0.055722419172525406, Final Batch Loss: 0.023532509803771973\n",
      "Epoch 2711, Loss: 0.03809321019798517, Final Batch Loss: 0.00772660318762064\n",
      "Epoch 2712, Loss: 0.04521439969539642, Final Batch Loss: 0.028717251494526863\n",
      "Epoch 2713, Loss: 0.05254511162638664, Final Batch Loss: 0.03392606973648071\n",
      "Epoch 2714, Loss: 0.05397875560447574, Final Batch Loss: 0.005542058032006025\n",
      "Epoch 2715, Loss: 0.07306197937577963, Final Batch Loss: 0.015554594807326794\n",
      "Epoch 2716, Loss: 0.07332579232752323, Final Batch Loss: 0.04209192469716072\n",
      "Epoch 2717, Loss: 0.06627848744392395, Final Batch Loss: 0.034789033234119415\n",
      "Epoch 2718, Loss: 0.027196071110665798, Final Batch Loss: 0.01582147181034088\n",
      "Epoch 2719, Loss: 0.0658987108618021, Final Batch Loss: 0.029643816873431206\n",
      "Epoch 2720, Loss: 0.04395731445401907, Final Batch Loss: 0.01545181218534708\n",
      "Epoch 2721, Loss: 0.07319940626621246, Final Batch Loss: 0.0473128966987133\n",
      "Epoch 2722, Loss: 0.0541226901113987, Final Batch Loss: 0.017790693789720535\n",
      "Epoch 2723, Loss: 0.05788167379796505, Final Batch Loss: 0.02088593877851963\n",
      "Epoch 2724, Loss: 0.07321431115269661, Final Batch Loss: 0.02366715297102928\n",
      "Epoch 2725, Loss: 0.03578594699501991, Final Batch Loss: 0.020069776102900505\n",
      "Epoch 2726, Loss: 0.08582382090389729, Final Batch Loss: 0.056412968784570694\n",
      "Epoch 2727, Loss: 0.037020646035671234, Final Batch Loss: 0.023598652333021164\n",
      "Epoch 2728, Loss: 0.07265449687838554, Final Batch Loss: 0.0479920320212841\n",
      "Epoch 2729, Loss: 0.06308338046073914, Final Batch Loss: 0.035500649362802505\n",
      "Epoch 2730, Loss: 0.04982572980225086, Final Batch Loss: 0.01962921768426895\n",
      "Epoch 2731, Loss: 0.060491714626550674, Final Batch Loss: 0.024956732988357544\n",
      "Epoch 2732, Loss: 0.03713168855756521, Final Batch Loss: 0.01490215864032507\n",
      "Epoch 2733, Loss: 0.0307401604950428, Final Batch Loss: 0.007810765877366066\n",
      "Epoch 2734, Loss: 0.03986512962728739, Final Batch Loss: 0.029985612258315086\n",
      "Epoch 2735, Loss: 0.04827610030770302, Final Batch Loss: 0.02502514235675335\n",
      "Epoch 2736, Loss: 0.04561668261885643, Final Batch Loss: 0.018898608162999153\n",
      "Epoch 2737, Loss: 0.05416523106396198, Final Batch Loss: 0.02778777852654457\n",
      "Epoch 2738, Loss: 0.065117746591568, Final Batch Loss: 0.037474196404218674\n",
      "Epoch 2739, Loss: 0.04160755127668381, Final Batch Loss: 0.018569575622677803\n",
      "Epoch 2740, Loss: 0.049405405297875404, Final Batch Loss: 0.02671654522418976\n",
      "Epoch 2741, Loss: 0.056070610880851746, Final Batch Loss: 0.025367258116602898\n",
      "Epoch 2742, Loss: 0.052712876349687576, Final Batch Loss: 0.020609743893146515\n",
      "Epoch 2743, Loss: 0.04295944422483444, Final Batch Loss: 0.02850961685180664\n",
      "Epoch 2744, Loss: 0.05012126825749874, Final Batch Loss: 0.028137631714344025\n",
      "Epoch 2745, Loss: 0.0808622557669878, Final Batch Loss: 0.05794476717710495\n",
      "Epoch 2746, Loss: 0.04966365173459053, Final Batch Loss: 0.027449969202280045\n",
      "Epoch 2747, Loss: 0.03081690752878785, Final Batch Loss: 0.007315973285585642\n",
      "Epoch 2748, Loss: 0.03251705737784505, Final Batch Loss: 0.00737449387088418\n",
      "Epoch 2749, Loss: 0.09286651201546192, Final Batch Loss: 0.010476725175976753\n",
      "Epoch 2750, Loss: 0.04265462048351765, Final Batch Loss: 0.029046418145298958\n",
      "Epoch 2751, Loss: 0.11137736216187477, Final Batch Loss: 0.017194364219903946\n",
      "Epoch 2752, Loss: 0.0913587398827076, Final Batch Loss: 0.05284159630537033\n",
      "Epoch 2753, Loss: 0.05828343704342842, Final Batch Loss: 0.028741108253598213\n",
      "Epoch 2754, Loss: 0.07895468920469284, Final Batch Loss: 0.0435333214700222\n",
      "Epoch 2755, Loss: 0.05703026428818703, Final Batch Loss: 0.020421244204044342\n",
      "Epoch 2756, Loss: 0.09716124087572098, Final Batch Loss: 0.06147773191332817\n",
      "Epoch 2757, Loss: 0.027898279018700123, Final Batch Loss: 0.019065121188759804\n",
      "Epoch 2758, Loss: 0.07152640633285046, Final Batch Loss: 0.04473224654793739\n",
      "Epoch 2759, Loss: 0.06330627202987671, Final Batch Loss: 0.03140011802315712\n",
      "Epoch 2760, Loss: 0.08275237679481506, Final Batch Loss: 0.048983536660671234\n",
      "Epoch 2761, Loss: 0.07195108197629452, Final Batch Loss: 0.02412048913538456\n",
      "Epoch 2762, Loss: 0.07272663153707981, Final Batch Loss: 0.044236063957214355\n",
      "Epoch 2763, Loss: 0.07681680493988097, Final Batch Loss: 0.003866210812702775\n",
      "Epoch 2764, Loss: 0.03039893787354231, Final Batch Loss: 0.013349288143217564\n",
      "Epoch 2765, Loss: 0.04682460147887468, Final Batch Loss: 0.004853897728025913\n",
      "Epoch 2766, Loss: 0.042182475328445435, Final Batch Loss: 0.021543629467487335\n",
      "Epoch 2767, Loss: 0.06987599842250347, Final Batch Loss: 0.051475126296281815\n",
      "Epoch 2768, Loss: 0.0751529186964035, Final Batch Loss: 0.022920187562704086\n",
      "Epoch 2769, Loss: 0.07721088081598282, Final Batch Loss: 0.038742076605558395\n",
      "Epoch 2770, Loss: 0.10461674630641937, Final Batch Loss: 0.08338404446840286\n",
      "Epoch 2771, Loss: 0.08329426124691963, Final Batch Loss: 0.03141670674085617\n",
      "Epoch 2772, Loss: 0.05368215590715408, Final Batch Loss: 0.03011980466544628\n",
      "Epoch 2773, Loss: 0.034016167744994164, Final Batch Loss: 0.010375678539276123\n",
      "Epoch 2774, Loss: 0.04690024349838495, Final Batch Loss: 0.014867396093904972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2775, Loss: 0.0726071186363697, Final Batch Loss: 0.042092595249414444\n",
      "Epoch 2776, Loss: 0.06005197763442993, Final Batch Loss: 0.04288967326283455\n",
      "Epoch 2777, Loss: 0.08703185804188251, Final Batch Loss: 0.024237656965851784\n",
      "Epoch 2778, Loss: 0.15764418989419937, Final Batch Loss: 0.0883515477180481\n",
      "Epoch 2779, Loss: 0.05021060165017843, Final Batch Loss: 0.014385025016963482\n",
      "Epoch 2780, Loss: 0.03408882720395923, Final Batch Loss: 0.027295349165797234\n",
      "Epoch 2781, Loss: 0.03351163491606712, Final Batch Loss: 0.008025428280234337\n",
      "Epoch 2782, Loss: 0.0761876329779625, Final Batch Loss: 0.03850644454360008\n",
      "Epoch 2783, Loss: 0.04528134874999523, Final Batch Loss: 0.01049942709505558\n",
      "Epoch 2784, Loss: 0.032848821487277746, Final Batch Loss: 0.005493321921676397\n",
      "Epoch 2785, Loss: 0.10293478146195412, Final Batch Loss: 0.06908443570137024\n",
      "Epoch 2786, Loss: 0.1219564862549305, Final Batch Loss: 0.07387174665927887\n",
      "Epoch 2787, Loss: 0.08295155316591263, Final Batch Loss: 0.04918823018670082\n",
      "Epoch 2788, Loss: 0.08454316668212414, Final Batch Loss: 0.05909685790538788\n",
      "Epoch 2789, Loss: 0.05244029127061367, Final Batch Loss: 0.0375741571187973\n",
      "Epoch 2790, Loss: 0.05219587683677673, Final Batch Loss: 0.023769643157720566\n",
      "Epoch 2791, Loss: 0.03393000178039074, Final Batch Loss: 0.017499206587672234\n",
      "Epoch 2792, Loss: 0.07266971841454506, Final Batch Loss: 0.054888881742954254\n",
      "Epoch 2793, Loss: 0.020150969736278057, Final Batch Loss: 0.007161987014114857\n",
      "Epoch 2794, Loss: 0.05089503899216652, Final Batch Loss: 0.016850102692842484\n",
      "Epoch 2795, Loss: 0.046901898458600044, Final Batch Loss: 0.033945053815841675\n",
      "Epoch 2796, Loss: 0.08800323866307735, Final Batch Loss: 0.0716889277100563\n",
      "Epoch 2797, Loss: 0.08413271233439445, Final Batch Loss: 0.0497351735830307\n",
      "Epoch 2798, Loss: 0.0740498173981905, Final Batch Loss: 0.011721847578883171\n",
      "Epoch 2799, Loss: 0.09716762602329254, Final Batch Loss: 0.045883502811193466\n",
      "Epoch 2800, Loss: 0.04613041691482067, Final Batch Loss: 0.02816457487642765\n",
      "Epoch 2801, Loss: 0.034174672327935696, Final Batch Loss: 0.013877061195671558\n",
      "Epoch 2802, Loss: 0.05632077716290951, Final Batch Loss: 0.03651570528745651\n",
      "Epoch 2803, Loss: 0.13964173942804337, Final Batch Loss: 0.07581054419279099\n",
      "Epoch 2804, Loss: 0.13613531738519669, Final Batch Loss: 0.07393376529216766\n",
      "Epoch 2805, Loss: 0.06113000772893429, Final Batch Loss: 0.03510977700352669\n",
      "Epoch 2806, Loss: 0.09909669309854507, Final Batch Loss: 0.06149420142173767\n",
      "Epoch 2807, Loss: 0.03681502491235733, Final Batch Loss: 0.013842806220054626\n",
      "Epoch 2808, Loss: 0.10428615659475327, Final Batch Loss: 0.06632979959249496\n",
      "Epoch 2809, Loss: 0.08257913589477539, Final Batch Loss: 0.049894992262125015\n",
      "Epoch 2810, Loss: 0.057569993659853935, Final Batch Loss: 0.01798447035253048\n",
      "Epoch 2811, Loss: 0.04720527771860361, Final Batch Loss: 0.010200236923992634\n",
      "Epoch 2812, Loss: 0.07918489165604115, Final Batch Loss: 0.020025188103318214\n",
      "Epoch 2813, Loss: 0.052298007532954216, Final Batch Loss: 0.022829890251159668\n",
      "Epoch 2814, Loss: 0.025565940886735916, Final Batch Loss: 0.013353869318962097\n",
      "Epoch 2815, Loss: 0.08219497092068195, Final Batch Loss: 0.056782353669404984\n",
      "Epoch 2816, Loss: 0.14189615100622177, Final Batch Loss: 0.021216981112957\n",
      "Epoch 2817, Loss: 0.05212530493736267, Final Batch Loss: 0.03453724831342697\n",
      "Epoch 2818, Loss: 0.04949145298451185, Final Batch Loss: 0.012110891751945019\n",
      "Epoch 2819, Loss: 0.11665056645870209, Final Batch Loss: 0.06474824994802475\n",
      "Epoch 2820, Loss: 0.04756586439907551, Final Batch Loss: 0.01993737742304802\n",
      "Epoch 2821, Loss: 0.09897710010409355, Final Batch Loss: 0.04783673584461212\n",
      "Epoch 2822, Loss: 0.0579969622194767, Final Batch Loss: 0.026716623455286026\n",
      "Epoch 2823, Loss: 0.0648624561727047, Final Batch Loss: 0.01293766126036644\n",
      "Epoch 2824, Loss: 0.26421086490154266, Final Batch Loss: 0.11220672726631165\n",
      "Epoch 2825, Loss: 0.0782720260322094, Final Batch Loss: 0.03285195678472519\n",
      "Epoch 2826, Loss: 0.0425791721791029, Final Batch Loss: 0.014035573229193687\n",
      "Epoch 2827, Loss: 0.06569521874189377, Final Batch Loss: 0.016964055597782135\n",
      "Epoch 2828, Loss: 0.08103359490633011, Final Batch Loss: 0.0396612323820591\n",
      "Epoch 2829, Loss: 0.1284502111375332, Final Batch Loss: 0.09416879713535309\n",
      "Epoch 2830, Loss: 0.05358911398798227, Final Batch Loss: 0.01361172366887331\n",
      "Epoch 2831, Loss: 0.10321923717856407, Final Batch Loss: 0.054275840520858765\n",
      "Epoch 2832, Loss: 0.25357992947101593, Final Batch Loss: 0.20042641460895538\n",
      "Epoch 2833, Loss: 0.05722977966070175, Final Batch Loss: 0.02779514342546463\n",
      "Epoch 2834, Loss: 0.34691429138183594, Final Batch Loss: 0.3146892189979553\n",
      "Epoch 2835, Loss: 0.12932897172868252, Final Batch Loss: 0.09981127828359604\n",
      "Epoch 2836, Loss: 0.06564003601670265, Final Batch Loss: 0.04402952641248703\n",
      "Epoch 2837, Loss: 0.20247936248779297, Final Batch Loss: 0.13873469829559326\n",
      "Epoch 2838, Loss: 0.12931258231401443, Final Batch Loss: 0.03106509894132614\n",
      "Epoch 2839, Loss: 0.11865610629320145, Final Batch Loss: 0.06846108287572861\n",
      "Epoch 2840, Loss: 0.05585542693734169, Final Batch Loss: 0.03173798695206642\n",
      "Epoch 2841, Loss: 0.1834314912557602, Final Batch Loss: 0.12187927216291428\n",
      "Epoch 2842, Loss: 0.10735098831355572, Final Batch Loss: 0.022329499945044518\n",
      "Epoch 2843, Loss: 0.1286909393966198, Final Batch Loss: 0.020283479243516922\n",
      "Epoch 2844, Loss: 0.13042739778757095, Final Batch Loss: 0.06557664275169373\n",
      "Epoch 2845, Loss: 0.06675891764461994, Final Batch Loss: 0.03951345756649971\n",
      "Epoch 2846, Loss: 0.10503216087818146, Final Batch Loss: 0.06543854624032974\n",
      "Epoch 2847, Loss: 0.06343307346105576, Final Batch Loss: 0.013204775750637054\n",
      "Epoch 2848, Loss: 0.09030795097351074, Final Batch Loss: 0.049053892493247986\n",
      "Epoch 2849, Loss: 0.08314481563866138, Final Batch Loss: 0.030805150046944618\n",
      "Epoch 2850, Loss: 0.12615204975008965, Final Batch Loss: 0.03416113182902336\n",
      "Epoch 2851, Loss: 0.058235252276062965, Final Batch Loss: 0.0218632984906435\n",
      "Epoch 2852, Loss: 0.12644008174538612, Final Batch Loss: 0.07074597477912903\n",
      "Epoch 2853, Loss: 0.12754517048597336, Final Batch Loss: 0.06598540395498276\n",
      "Epoch 2854, Loss: 0.10317474231123924, Final Batch Loss: 0.07331981509923935\n",
      "Epoch 2855, Loss: 0.06172286160290241, Final Batch Loss: 0.012339839711785316\n",
      "Epoch 2856, Loss: 0.07455844804644585, Final Batch Loss: 0.02929624542593956\n",
      "Epoch 2857, Loss: 0.06359303742647171, Final Batch Loss: 0.03795141354203224\n",
      "Epoch 2858, Loss: 0.10692236758768559, Final Batch Loss: 0.016818391159176826\n",
      "Epoch 2859, Loss: 0.06104974262416363, Final Batch Loss: 0.03895869851112366\n",
      "Epoch 2860, Loss: 0.09076890721917152, Final Batch Loss: 0.06778869032859802\n",
      "Epoch 2861, Loss: 0.14274492859840393, Final Batch Loss: 0.10323149710893631\n",
      "Epoch 2862, Loss: 0.06238735094666481, Final Batch Loss: 0.04327753931283951\n",
      "Epoch 2863, Loss: 0.10050541535019875, Final Batch Loss: 0.054028816521167755\n",
      "Epoch 2864, Loss: 0.11182665452361107, Final Batch Loss: 0.07968082278966904\n",
      "Epoch 2865, Loss: 0.041627852246165276, Final Batch Loss: 0.02427215874195099\n",
      "Epoch 2866, Loss: 0.06632795464247465, Final Batch Loss: 0.010868753306567669\n",
      "Epoch 2867, Loss: 0.08287672698497772, Final Batch Loss: 0.04091062396764755\n",
      "Epoch 2868, Loss: 0.0979735441505909, Final Batch Loss: 0.04956428334116936\n",
      "Epoch 2869, Loss: 0.07426601462066174, Final Batch Loss: 0.029852112755179405\n",
      "Epoch 2870, Loss: 0.10987704992294312, Final Batch Loss: 0.07020910084247589\n",
      "Epoch 2871, Loss: 0.14404631033539772, Final Batch Loss: 0.12062877416610718\n",
      "Epoch 2872, Loss: 0.03892241418361664, Final Batch Loss: 0.015180161222815514\n",
      "Epoch 2873, Loss: 0.06117982417345047, Final Batch Loss: 0.03180481120944023\n",
      "Epoch 2874, Loss: 0.06230258010327816, Final Batch Loss: 0.043961744755506516\n",
      "Epoch 2875, Loss: 0.04703733418136835, Final Batch Loss: 0.011823226697742939\n",
      "Epoch 2876, Loss: 0.12338309362530708, Final Batch Loss: 0.07102271914482117\n",
      "Epoch 2877, Loss: 0.06722704321146011, Final Batch Loss: 0.036046069115400314\n",
      "Epoch 2878, Loss: 0.08690492436289787, Final Batch Loss: 0.01839086040854454\n",
      "Epoch 2879, Loss: 0.05444331094622612, Final Batch Loss: 0.024172529578208923\n",
      "Epoch 2880, Loss: 0.08086908794939518, Final Batch Loss: 0.019441233947873116\n",
      "Epoch 2881, Loss: 0.12139524891972542, Final Batch Loss: 0.07496926933526993\n",
      "Epoch 2882, Loss: 0.052700042724609375, Final Batch Loss: 0.02189750410616398\n",
      "Epoch 2883, Loss: 0.1046595573425293, Final Batch Loss: 0.057016655802726746\n",
      "Epoch 2884, Loss: 0.06838853843510151, Final Batch Loss: 0.037722956389188766\n",
      "Epoch 2885, Loss: 0.10341513156890869, Final Batch Loss: 0.06266579031944275\n",
      "Epoch 2886, Loss: 0.06000214070081711, Final Batch Loss: 0.02113541215658188\n",
      "Epoch 2887, Loss: 0.03145867586135864, Final Batch Loss: 0.010390890762209892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2888, Loss: 0.070879265666008, Final Batch Loss: 0.03643861413002014\n",
      "Epoch 2889, Loss: 0.07889322191476822, Final Batch Loss: 0.04745980724692345\n",
      "Epoch 2890, Loss: 0.06429336965084076, Final Batch Loss: 0.04631606489419937\n",
      "Epoch 2891, Loss: 0.056988662108778954, Final Batch Loss: 0.037846606224775314\n",
      "Epoch 2892, Loss: 0.05289905332028866, Final Batch Loss: 0.01837761513888836\n",
      "Epoch 2893, Loss: 0.06118268519639969, Final Batch Loss: 0.03865809738636017\n",
      "Epoch 2894, Loss: 0.06589407473802567, Final Batch Loss: 0.044274162501096725\n",
      "Epoch 2895, Loss: 0.06561972480267286, Final Batch Loss: 0.051261868327856064\n",
      "Epoch 2896, Loss: 0.05124381557106972, Final Batch Loss: 0.016438130289316177\n",
      "Epoch 2897, Loss: 0.046956367790699005, Final Batch Loss: 0.024439387023448944\n",
      "Epoch 2898, Loss: 0.04243251774460077, Final Batch Loss: 0.015013816766440868\n",
      "Epoch 2899, Loss: 0.0824507623910904, Final Batch Loss: 0.0465039499104023\n",
      "Epoch 2900, Loss: 0.04148983582854271, Final Batch Loss: 0.021534280851483345\n",
      "Epoch 2901, Loss: 0.05761760100722313, Final Batch Loss: 0.034942325204610825\n",
      "Epoch 2902, Loss: 0.06775759533047676, Final Batch Loss: 0.03493364155292511\n",
      "Epoch 2903, Loss: 0.08749894797801971, Final Batch Loss: 0.06519880145788193\n",
      "Epoch 2904, Loss: 0.08306958340108395, Final Batch Loss: 0.025669226422905922\n",
      "Epoch 2905, Loss: 0.08822866156697273, Final Batch Loss: 0.015649262815713882\n",
      "Epoch 2906, Loss: 0.06375664286315441, Final Batch Loss: 0.027379235252738\n",
      "Epoch 2907, Loss: 0.08129960484802723, Final Batch Loss: 0.016400376334786415\n",
      "Epoch 2908, Loss: 0.0641317842528224, Final Batch Loss: 0.04981354996562004\n",
      "Epoch 2909, Loss: 0.06342599913477898, Final Batch Loss: 0.030026379972696304\n",
      "Epoch 2910, Loss: 0.07734312117099762, Final Batch Loss: 0.05376945063471794\n",
      "Epoch 2911, Loss: 0.03834428358823061, Final Batch Loss: 0.023043667897582054\n",
      "Epoch 2912, Loss: 0.03072850964963436, Final Batch Loss: 0.007548050954937935\n",
      "Epoch 2913, Loss: 0.05435296148061752, Final Batch Loss: 0.024214519187808037\n",
      "Epoch 2914, Loss: 0.059751853346824646, Final Batch Loss: 0.02053948864340782\n",
      "Epoch 2915, Loss: 0.04950358904898167, Final Batch Loss: 0.01776166819036007\n",
      "Epoch 2916, Loss: 0.04717535153031349, Final Batch Loss: 0.01736276037991047\n",
      "Epoch 2917, Loss: 0.053875211626291275, Final Batch Loss: 0.023940496146678925\n",
      "Epoch 2918, Loss: 0.04764427989721298, Final Batch Loss: 0.03827626630663872\n",
      "Epoch 2919, Loss: 0.016561838798224926, Final Batch Loss: 0.005881178192794323\n",
      "Epoch 2920, Loss: 0.0590413361787796, Final Batch Loss: 0.043420713394880295\n",
      "Epoch 2921, Loss: 0.05591064877808094, Final Batch Loss: 0.03144441917538643\n",
      "Epoch 2922, Loss: 0.0629649618640542, Final Batch Loss: 0.048931460827589035\n",
      "Epoch 2923, Loss: 0.056140074506402016, Final Batch Loss: 0.022947637364268303\n",
      "Epoch 2924, Loss: 0.054925305768847466, Final Batch Loss: 0.027507752180099487\n",
      "Epoch 2925, Loss: 0.04813846480101347, Final Batch Loss: 0.01039197202771902\n",
      "Epoch 2926, Loss: 0.06179310381412506, Final Batch Loss: 0.01971178501844406\n",
      "Epoch 2927, Loss: 0.051832450553774834, Final Batch Loss: 0.03536435589194298\n",
      "Epoch 2928, Loss: 0.05115753971040249, Final Batch Loss: 0.01618192158639431\n",
      "Epoch 2929, Loss: 0.0771185364574194, Final Batch Loss: 0.05161624029278755\n",
      "Epoch 2930, Loss: 0.07946650870144367, Final Batch Loss: 0.059121228754520416\n",
      "Epoch 2931, Loss: 0.06388428993523121, Final Batch Loss: 0.04743606224656105\n",
      "Epoch 2932, Loss: 0.07098320499062538, Final Batch Loss: 0.05464838072657585\n",
      "Epoch 2933, Loss: 0.049309270456433296, Final Batch Loss: 0.023922545835375786\n",
      "Epoch 2934, Loss: 0.06154720298945904, Final Batch Loss: 0.03369772434234619\n",
      "Epoch 2935, Loss: 0.04451592452824116, Final Batch Loss: 0.0270390547811985\n",
      "Epoch 2936, Loss: 0.06748785637319088, Final Batch Loss: 0.0430404394865036\n",
      "Epoch 2937, Loss: 0.10218871384859085, Final Batch Loss: 0.054557833820581436\n",
      "Epoch 2938, Loss: 0.04417596571147442, Final Batch Loss: 0.027510277926921844\n",
      "Epoch 2939, Loss: 0.029988139867782593, Final Batch Loss: 0.0039215087890625\n",
      "Epoch 2940, Loss: 0.03982618823647499, Final Batch Loss: 0.0234017726033926\n",
      "Epoch 2941, Loss: 0.09664615616202354, Final Batch Loss: 0.04024190455675125\n",
      "Epoch 2942, Loss: 0.04573508072644472, Final Batch Loss: 0.0325753316283226\n",
      "Epoch 2943, Loss: 0.05996955558657646, Final Batch Loss: 0.02319268509745598\n",
      "Epoch 2944, Loss: 0.023367727641016245, Final Batch Loss: 0.005066801328212023\n",
      "Epoch 2945, Loss: 0.050315871834754944, Final Batch Loss: 0.029879430308938026\n",
      "Epoch 2946, Loss: 0.049446502700448036, Final Batch Loss: 0.015039490535855293\n",
      "Epoch 2947, Loss: 0.07696001045405865, Final Batch Loss: 0.020212626084685326\n",
      "Epoch 2948, Loss: 0.03046637959778309, Final Batch Loss: 0.015521841123700142\n",
      "Epoch 2949, Loss: 0.050290840677917004, Final Batch Loss: 0.03758013993501663\n",
      "Epoch 2950, Loss: 0.03909967606887221, Final Batch Loss: 0.003464893903583288\n",
      "Epoch 2951, Loss: 0.029215102083981037, Final Batch Loss: 0.014119473285973072\n",
      "Epoch 2952, Loss: 0.045697348192334175, Final Batch Loss: 0.031821172684431076\n",
      "Epoch 2953, Loss: 0.10366179049015045, Final Batch Loss: 0.06501813977956772\n",
      "Epoch 2954, Loss: 0.05126419477164745, Final Batch Loss: 0.029568219557404518\n",
      "Epoch 2955, Loss: 0.05485888384282589, Final Batch Loss: 0.019621388986706734\n",
      "Epoch 2956, Loss: 0.03992047719657421, Final Batch Loss: 0.017091289162635803\n",
      "Epoch 2957, Loss: 0.08795065991580486, Final Batch Loss: 0.05994493141770363\n",
      "Epoch 2958, Loss: 0.03608600236475468, Final Batch Loss: 0.015398427844047546\n",
      "Epoch 2959, Loss: 0.03623146843165159, Final Batch Loss: 0.02498098835349083\n",
      "Epoch 2960, Loss: 0.06315362080931664, Final Batch Loss: 0.025081023573875427\n",
      "Epoch 2961, Loss: 0.05970412539318204, Final Batch Loss: 0.005951945204287767\n",
      "Epoch 2962, Loss: 0.03477584570646286, Final Batch Loss: 0.008937578648328781\n",
      "Epoch 2963, Loss: 0.037881527096033096, Final Batch Loss: 0.02356010302901268\n",
      "Epoch 2964, Loss: 0.05181332863867283, Final Batch Loss: 0.026627445593476295\n",
      "Epoch 2965, Loss: 0.06526889652013779, Final Batch Loss: 0.017931871116161346\n",
      "Epoch 2966, Loss: 0.04489819519221783, Final Batch Loss: 0.014233766123652458\n",
      "Epoch 2967, Loss: 0.04226539842784405, Final Batch Loss: 0.012712273746728897\n",
      "Epoch 2968, Loss: 0.07714043371379375, Final Batch Loss: 0.051684025675058365\n",
      "Epoch 2969, Loss: 0.04614499770104885, Final Batch Loss: 0.018220700323581696\n",
      "Epoch 2970, Loss: 0.10846561938524246, Final Batch Loss: 0.06918758153915405\n",
      "Epoch 2971, Loss: 0.04711043555289507, Final Batch Loss: 0.03233771026134491\n",
      "Epoch 2972, Loss: 0.09944373928010464, Final Batch Loss: 0.07585391402244568\n",
      "Epoch 2973, Loss: 0.14057371206581593, Final Batch Loss: 0.11317114531993866\n",
      "Epoch 2974, Loss: 0.08903759345412254, Final Batch Loss: 0.04652712494134903\n",
      "Epoch 2975, Loss: 0.08833828382194042, Final Batch Loss: 0.0604524128139019\n",
      "Epoch 2976, Loss: 0.12150182574987411, Final Batch Loss: 0.05963720381259918\n",
      "Epoch 2977, Loss: 0.08539778552949429, Final Batch Loss: 0.06797897815704346\n",
      "Epoch 2978, Loss: 0.07430441677570343, Final Batch Loss: 0.020764488726854324\n",
      "Epoch 2979, Loss: 0.031179782934486866, Final Batch Loss: 0.012676280923187733\n",
      "Epoch 2980, Loss: 0.06759157404303551, Final Batch Loss: 0.013065304607152939\n",
      "Epoch 2981, Loss: 0.04203479178249836, Final Batch Loss: 0.017139805480837822\n",
      "Epoch 2982, Loss: 0.04252537712454796, Final Batch Loss: 0.022264912724494934\n",
      "Epoch 2983, Loss: 0.03133072145283222, Final Batch Loss: 0.011224543675780296\n",
      "Epoch 2984, Loss: 0.047551884315907955, Final Batch Loss: 0.011139239184558392\n",
      "Epoch 2985, Loss: 0.061792172491550446, Final Batch Loss: 0.04525512829422951\n",
      "Epoch 2986, Loss: 0.0594631414860487, Final Batch Loss: 0.04661710932850838\n",
      "Epoch 2987, Loss: 0.08735042065382004, Final Batch Loss: 0.049896351993083954\n",
      "Epoch 2988, Loss: 0.05311063677072525, Final Batch Loss: 0.02371174842119217\n",
      "Epoch 2989, Loss: 0.05399572476744652, Final Batch Loss: 0.02706303820014\n",
      "Epoch 2990, Loss: 0.049852658063173294, Final Batch Loss: 0.02973451465368271\n",
      "Epoch 2991, Loss: 0.07698465511202812, Final Batch Loss: 0.03401099145412445\n",
      "Epoch 2992, Loss: 0.04200200457125902, Final Batch Loss: 0.011040314100682735\n",
      "Epoch 2993, Loss: 0.04826608579605818, Final Batch Loss: 0.012784834019839764\n",
      "Epoch 2994, Loss: 0.06911973655223846, Final Batch Loss: 0.023351158946752548\n",
      "Epoch 2995, Loss: 0.11070285364985466, Final Batch Loss: 0.017670024186372757\n",
      "Epoch 2996, Loss: 0.1178574189543724, Final Batch Loss: 0.08052008599042892\n",
      "Epoch 2997, Loss: 0.07217963971197605, Final Batch Loss: 0.010325098410248756\n",
      "Epoch 2998, Loss: 0.08142049238085747, Final Batch Loss: 0.03733589127659798\n",
      "Epoch 2999, Loss: 0.08412506058812141, Final Batch Loss: 0.03922722116112709\n",
      "Epoch 3000, Loss: 0.07102371007204056, Final Batch Loss: 0.041844166815280914\n",
      "Epoch 3001, Loss: 0.062019504606723785, Final Batch Loss: 0.03475075587630272\n",
      "Epoch 3002, Loss: 0.07346338033676147, Final Batch Loss: 0.040495336055755615\n",
      "Epoch 3003, Loss: 0.047652432695031166, Final Batch Loss: 0.02771737426519394\n",
      "Epoch 3004, Loss: 0.09674894995987415, Final Batch Loss: 0.08583957701921463\n",
      "Epoch 3005, Loss: 0.06493272632360458, Final Batch Loss: 0.05008591711521149\n",
      "Epoch 3006, Loss: 0.03367115184664726, Final Batch Loss: 0.016040068119764328\n",
      "Epoch 3007, Loss: 0.0637787189334631, Final Batch Loss: 0.03775321692228317\n",
      "Epoch 3008, Loss: 0.06844288110733032, Final Batch Loss: 0.03673534840345383\n",
      "Epoch 3009, Loss: 0.030128762125968933, Final Batch Loss: 0.01278425008058548\n",
      "Epoch 3010, Loss: 0.047938022762537, Final Batch Loss: 0.009670983999967575\n",
      "Epoch 3011, Loss: 0.05861554853618145, Final Batch Loss: 0.03738673776388168\n",
      "Epoch 3012, Loss: 0.09976642578840256, Final Batch Loss: 0.055041391402482986\n",
      "Epoch 3013, Loss: 0.14401011914014816, Final Batch Loss: 0.06189250200986862\n",
      "Epoch 3014, Loss: 0.13126502372324467, Final Batch Loss: 0.10626217722892761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3015, Loss: 0.18772262334823608, Final Batch Loss: 0.10653649270534515\n",
      "Epoch 3016, Loss: 0.08704602345824242, Final Batch Loss: 0.018138263374567032\n",
      "Epoch 3017, Loss: 0.06369131430983543, Final Batch Loss: 0.015016615390777588\n",
      "Epoch 3018, Loss: 0.1641247794032097, Final Batch Loss: 0.09331606328487396\n",
      "Epoch 3019, Loss: 0.1475352719426155, Final Batch Loss: 0.05657046288251877\n",
      "Epoch 3020, Loss: 0.17316406965255737, Final Batch Loss: 0.10740583389997482\n",
      "Epoch 3021, Loss: 0.13979313522577286, Final Batch Loss: 0.06583856046199799\n",
      "Epoch 3022, Loss: 0.11328960955142975, Final Batch Loss: 0.062463127076625824\n",
      "Epoch 3023, Loss: 0.06832379847764969, Final Batch Loss: 0.03211882710456848\n",
      "Epoch 3024, Loss: 0.06281650438904762, Final Batch Loss: 0.038727786391973495\n",
      "Epoch 3025, Loss: 0.052843889221549034, Final Batch Loss: 0.018235625699162483\n",
      "Epoch 3026, Loss: 0.052334537729620934, Final Batch Loss: 0.01285666786134243\n",
      "Epoch 3027, Loss: 0.049118051305413246, Final Batch Loss: 0.021372273564338684\n",
      "Epoch 3028, Loss: 0.08407715708017349, Final Batch Loss: 0.018725112080574036\n",
      "Epoch 3029, Loss: 0.07374019920825958, Final Batch Loss: 0.04206208139657974\n",
      "Epoch 3030, Loss: 0.038613810669630766, Final Batch Loss: 0.007150630932301283\n",
      "Epoch 3031, Loss: 0.0830807201564312, Final Batch Loss: 0.024224791675806046\n",
      "Epoch 3032, Loss: 0.0443066842854023, Final Batch Loss: 0.024006705731153488\n",
      "Epoch 3033, Loss: 0.0876026451587677, Final Batch Loss: 0.06339279562234879\n",
      "Epoch 3034, Loss: 0.05843260511755943, Final Batch Loss: 0.011270139366388321\n",
      "Epoch 3035, Loss: 0.03659285698086023, Final Batch Loss: 0.012345141731202602\n",
      "Epoch 3036, Loss: 0.06817341595888138, Final Batch Loss: 0.03812680020928383\n",
      "Epoch 3037, Loss: 0.10366867110133171, Final Batch Loss: 0.04055693373084068\n",
      "Epoch 3038, Loss: 0.11406314745545387, Final Batch Loss: 0.046472880989313126\n",
      "Epoch 3039, Loss: 0.07937943562865257, Final Batch Loss: 0.059394121170043945\n",
      "Epoch 3040, Loss: 0.09764893352985382, Final Batch Loss: 0.08081076294183731\n",
      "Epoch 3041, Loss: 0.0665902178734541, Final Batch Loss: 0.021717717871069908\n",
      "Epoch 3042, Loss: 0.053293626755476, Final Batch Loss: 0.029785068705677986\n",
      "Epoch 3043, Loss: 0.075055330991745, Final Batch Loss: 0.047586590051651\n",
      "Epoch 3044, Loss: 0.054672593250870705, Final Batch Loss: 0.019748250022530556\n",
      "Epoch 3045, Loss: 0.05571842007339001, Final Batch Loss: 0.029299167916178703\n",
      "Epoch 3046, Loss: 0.10087987594306469, Final Batch Loss: 0.0794471874833107\n",
      "Epoch 3047, Loss: 0.15453260391950607, Final Batch Loss: 0.11684778332710266\n",
      "Epoch 3048, Loss: 0.028778010047972202, Final Batch Loss: 0.00829154159873724\n",
      "Epoch 3049, Loss: 0.056656861677765846, Final Batch Loss: 0.029714111238718033\n",
      "Epoch 3050, Loss: 0.07394618168473244, Final Batch Loss: 0.03380128741264343\n",
      "Epoch 3051, Loss: 0.08725871704518795, Final Batch Loss: 0.05874498188495636\n",
      "Epoch 3052, Loss: 0.03866940550506115, Final Batch Loss: 0.027805594727396965\n",
      "Epoch 3053, Loss: 0.11468306556344032, Final Batch Loss: 0.08943773806095123\n",
      "Epoch 3054, Loss: 0.10132396221160889, Final Batch Loss: 0.064401775598526\n",
      "Epoch 3055, Loss: 0.04713798686861992, Final Batch Loss: 0.019667522981762886\n",
      "Epoch 3056, Loss: 0.051096487790346146, Final Batch Loss: 0.00953647494316101\n",
      "Epoch 3057, Loss: 0.04605480469763279, Final Batch Loss: 0.020871222019195557\n",
      "Epoch 3058, Loss: 0.05089593306183815, Final Batch Loss: 0.03426623344421387\n",
      "Epoch 3059, Loss: 0.03139543533325195, Final Batch Loss: 0.01867118664085865\n",
      "Epoch 3060, Loss: 0.03858083114027977, Final Batch Loss: 0.020306851714849472\n",
      "Epoch 3061, Loss: 0.06201345659792423, Final Batch Loss: 0.01675361581146717\n",
      "Epoch 3062, Loss: 0.056821294128894806, Final Batch Loss: 0.01998906210064888\n",
      "Epoch 3063, Loss: 0.05557530000805855, Final Batch Loss: 0.02345871552824974\n",
      "Epoch 3064, Loss: 0.05592247657477856, Final Batch Loss: 0.018715964630246162\n",
      "Epoch 3065, Loss: 0.034400900825858116, Final Batch Loss: 0.007238941267132759\n",
      "Epoch 3066, Loss: 0.050987047143280506, Final Batch Loss: 0.03921506553888321\n",
      "Epoch 3067, Loss: 0.06382817029953003, Final Batch Loss: 0.02665754407644272\n",
      "Epoch 3068, Loss: 0.04773368872702122, Final Batch Loss: 0.016004933044314384\n",
      "Epoch 3069, Loss: 0.03776104003190994, Final Batch Loss: 0.016218101605772972\n",
      "Epoch 3070, Loss: 0.06137038767337799, Final Batch Loss: 0.04617852345108986\n",
      "Epoch 3071, Loss: 0.02087818644940853, Final Batch Loss: 0.009258485399186611\n",
      "Epoch 3072, Loss: 0.037053415551781654, Final Batch Loss: 0.01708378829061985\n",
      "Epoch 3073, Loss: 0.09232626855373383, Final Batch Loss: 0.04101497307419777\n",
      "Epoch 3074, Loss: 0.06586300767958164, Final Batch Loss: 0.00855245627462864\n",
      "Epoch 3075, Loss: 0.029909933917224407, Final Batch Loss: 0.017733203247189522\n",
      "Epoch 3076, Loss: 0.045758893713355064, Final Batch Loss: 0.019888728857040405\n",
      "Epoch 3077, Loss: 0.032158846501260996, Final Batch Loss: 0.004788715858012438\n",
      "Epoch 3078, Loss: 0.05724300816655159, Final Batch Loss: 0.046263426542282104\n",
      "Epoch 3079, Loss: 0.048015858978033066, Final Batch Loss: 0.022381793707609177\n",
      "Epoch 3080, Loss: 0.07908890768885612, Final Batch Loss: 0.055269405245780945\n",
      "Epoch 3081, Loss: 0.07003189064562321, Final Batch Loss: 0.026945868507027626\n",
      "Epoch 3082, Loss: 0.10850447043776512, Final Batch Loss: 0.04012502357363701\n",
      "Epoch 3083, Loss: 0.06210595369338989, Final Batch Loss: 0.046005040407180786\n",
      "Epoch 3084, Loss: 0.0706300288438797, Final Batch Loss: 0.04016321152448654\n",
      "Epoch 3085, Loss: 0.07938503101468086, Final Batch Loss: 0.0474209301173687\n",
      "Epoch 3086, Loss: 0.08213217556476593, Final Batch Loss: 0.051391638815402985\n",
      "Epoch 3087, Loss: 0.05106392316520214, Final Batch Loss: 0.017704902216792107\n",
      "Epoch 3088, Loss: 0.04489608993753791, Final Batch Loss: 0.0073114014230668545\n",
      "Epoch 3089, Loss: 0.05399295315146446, Final Batch Loss: 0.03125925362110138\n",
      "Epoch 3090, Loss: 0.06948556192219257, Final Batch Loss: 0.05183032155036926\n",
      "Epoch 3091, Loss: 0.050428079441189766, Final Batch Loss: 0.011960221454501152\n",
      "Epoch 3092, Loss: 0.03908403217792511, Final Batch Loss: 0.018388018012046814\n",
      "Epoch 3093, Loss: 0.07461812347173691, Final Batch Loss: 0.03360883519053459\n",
      "Epoch 3094, Loss: 0.06530646607279778, Final Batch Loss: 0.04399466514587402\n",
      "Epoch 3095, Loss: 0.03618238307535648, Final Batch Loss: 0.017894424498081207\n",
      "Epoch 3096, Loss: 0.03597313538193703, Final Batch Loss: 0.019856201484799385\n",
      "Epoch 3097, Loss: 0.03234729263931513, Final Batch Loss: 0.013679900206625462\n",
      "Epoch 3098, Loss: 0.03853241354227066, Final Batch Loss: 0.014434773474931717\n",
      "Epoch 3099, Loss: 0.06888709776103497, Final Batch Loss: 0.0217644814401865\n",
      "Epoch 3100, Loss: 0.04833278525620699, Final Batch Loss: 0.009060596115887165\n",
      "Epoch 3101, Loss: 0.023721782490611076, Final Batch Loss: 0.004920948296785355\n",
      "Epoch 3102, Loss: 0.050679344683885574, Final Batch Loss: 0.005816962569952011\n",
      "Epoch 3103, Loss: 0.028200439177453518, Final Batch Loss: 0.007674134336411953\n",
      "Epoch 3104, Loss: 0.09717262908816338, Final Batch Loss: 0.03566993772983551\n",
      "Epoch 3105, Loss: 0.044059790670871735, Final Batch Loss: 0.019061144441366196\n",
      "Epoch 3106, Loss: 0.04704676754772663, Final Batch Loss: 0.00799805112183094\n",
      "Epoch 3107, Loss: 0.04484059475362301, Final Batch Loss: 0.01573878899216652\n",
      "Epoch 3108, Loss: 0.01713894959539175, Final Batch Loss: 0.004411985166370869\n",
      "Epoch 3109, Loss: 0.04203573986887932, Final Batch Loss: 0.02577507309615612\n",
      "Epoch 3110, Loss: 0.07586449943482876, Final Batch Loss: 0.03049377165734768\n",
      "Epoch 3111, Loss: 0.05822131782770157, Final Batch Loss: 0.019701678305864334\n",
      "Epoch 3112, Loss: 0.06929792650043964, Final Batch Loss: 0.006617391481995583\n",
      "Epoch 3113, Loss: 0.02387447375804186, Final Batch Loss: 0.010943676345050335\n",
      "Epoch 3114, Loss: 0.05071509163826704, Final Batch Loss: 0.03542495518922806\n",
      "Epoch 3115, Loss: 0.0360421072691679, Final Batch Loss: 0.018879100680351257\n",
      "Epoch 3116, Loss: 0.04095856612548232, Final Batch Loss: 0.006447297986596823\n",
      "Epoch 3117, Loss: 0.05341753736138344, Final Batch Loss: 0.03576153144240379\n",
      "Epoch 3118, Loss: 0.08582632429897785, Final Batch Loss: 0.05879974365234375\n",
      "Epoch 3119, Loss: 0.07681015133857727, Final Batch Loss: 0.0581769235432148\n",
      "Epoch 3120, Loss: 0.02670380286872387, Final Batch Loss: 0.01622666046023369\n",
      "Epoch 3121, Loss: 0.09239245019853115, Final Batch Loss: 0.06303905695676804\n",
      "Epoch 3122, Loss: 0.020528361201286316, Final Batch Loss: 0.008819990791380405\n",
      "Epoch 3123, Loss: 0.026543323881924152, Final Batch Loss: 0.005996718071401119\n",
      "Epoch 3124, Loss: 0.02448223903775215, Final Batch Loss: 0.01343762781471014\n",
      "Epoch 3125, Loss: 0.05873357690870762, Final Batch Loss: 0.02752269059419632\n",
      "Epoch 3126, Loss: 0.06029217317700386, Final Batch Loss: 0.016558047384023666\n",
      "Epoch 3127, Loss: 0.06977076269686222, Final Batch Loss: 0.046312116086483\n",
      "Epoch 3128, Loss: 0.04056011699140072, Final Batch Loss: 0.010706603527069092\n",
      "Epoch 3129, Loss: 0.07685690373182297, Final Batch Loss: 0.01706981658935547\n",
      "Epoch 3130, Loss: 0.06641961261630058, Final Batch Loss: 0.03463001921772957\n",
      "Epoch 3131, Loss: 0.025616695173084736, Final Batch Loss: 0.012139976024627686\n",
      "Epoch 3132, Loss: 0.0319965947419405, Final Batch Loss: 0.011434851214289665\n",
      "Epoch 3133, Loss: 0.021040400490164757, Final Batch Loss: 0.007044512778520584\n",
      "Epoch 3134, Loss: 0.11388820223510265, Final Batch Loss: 0.08666565269231796\n",
      "Epoch 3135, Loss: 0.024262438993901014, Final Batch Loss: 0.00772364204749465\n",
      "Epoch 3136, Loss: 0.05104183964431286, Final Batch Loss: 0.033509597182273865\n",
      "Epoch 3137, Loss: 0.07065683789551258, Final Batch Loss: 0.04657075181603432\n",
      "Epoch 3138, Loss: 0.022685054689645767, Final Batch Loss: 0.010697520337998867\n",
      "Epoch 3139, Loss: 0.022080324590206146, Final Batch Loss: 0.008959691040217876\n",
      "Epoch 3140, Loss: 0.037197485100477934, Final Batch Loss: 0.00750975264236331\n",
      "Epoch 3141, Loss: 0.04793095774948597, Final Batch Loss: 0.009064802899956703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3142, Loss: 0.08654452674090862, Final Batch Loss: 0.058855362236499786\n",
      "Epoch 3143, Loss: 0.0650525651872158, Final Batch Loss: 0.01880715787410736\n",
      "Epoch 3144, Loss: 0.032888757064938545, Final Batch Loss: 0.02286621369421482\n",
      "Epoch 3145, Loss: 0.06635250337421894, Final Batch Loss: 0.0308836679905653\n",
      "Epoch 3146, Loss: 0.050371257588267326, Final Batch Loss: 0.020830200985074043\n",
      "Epoch 3147, Loss: 0.019732430577278137, Final Batch Loss: 0.009220761246979237\n",
      "Epoch 3148, Loss: 0.08981597796082497, Final Batch Loss: 0.0714985728263855\n",
      "Epoch 3149, Loss: 0.06376283336430788, Final Batch Loss: 0.014238541014492512\n",
      "Epoch 3150, Loss: 0.037326148711144924, Final Batch Loss: 0.014948721043765545\n",
      "Epoch 3151, Loss: 0.0552390580996871, Final Batch Loss: 0.015150508843362331\n",
      "Epoch 3152, Loss: 0.04184396751224995, Final Batch Loss: 0.021206578239798546\n",
      "Epoch 3153, Loss: 0.06991458497941494, Final Batch Loss: 0.02698693983256817\n",
      "Epoch 3154, Loss: 0.046915603801608086, Final Batch Loss: 0.011105431243777275\n",
      "Epoch 3155, Loss: 0.09200270846486092, Final Batch Loss: 0.046562060713768005\n",
      "Epoch 3156, Loss: 0.05555172637104988, Final Batch Loss: 0.023610524833202362\n",
      "Epoch 3157, Loss: 0.025873580016195774, Final Batch Loss: 0.00875562522560358\n",
      "Epoch 3158, Loss: 0.059536177664995193, Final Batch Loss: 0.019367333501577377\n",
      "Epoch 3159, Loss: 0.03398245666176081, Final Batch Loss: 0.021463416516780853\n",
      "Epoch 3160, Loss: 0.07058518752455711, Final Batch Loss: 0.032020170241594315\n",
      "Epoch 3161, Loss: 0.1044958159327507, Final Batch Loss: 0.07030820846557617\n",
      "Epoch 3162, Loss: 0.04840536043047905, Final Batch Loss: 0.02958887629210949\n",
      "Epoch 3163, Loss: 0.038174429908394814, Final Batch Loss: 0.02154034562408924\n",
      "Epoch 3164, Loss: 0.11272358521819115, Final Batch Loss: 0.07988628000020981\n",
      "Epoch 3165, Loss: 0.06568165682256222, Final Batch Loss: 0.04395938292145729\n",
      "Epoch 3166, Loss: 0.06360398977994919, Final Batch Loss: 0.03815999999642372\n",
      "Epoch 3167, Loss: 0.07068346627056599, Final Batch Loss: 0.044526275247335434\n",
      "Epoch 3168, Loss: 0.07115104049444199, Final Batch Loss: 0.04633918032050133\n",
      "Epoch 3169, Loss: 0.10300616919994354, Final Batch Loss: 0.03834778815507889\n",
      "Epoch 3170, Loss: 0.035466748755425215, Final Batch Loss: 0.006774913053959608\n",
      "Epoch 3171, Loss: 0.07505695521831512, Final Batch Loss: 0.05881381779909134\n",
      "Epoch 3172, Loss: 0.036324345506727695, Final Batch Loss: 0.012929915450513363\n",
      "Epoch 3173, Loss: 0.05159158259630203, Final Batch Loss: 0.02659151703119278\n",
      "Epoch 3174, Loss: 0.07655594870448112, Final Batch Loss: 0.037117887288331985\n",
      "Epoch 3175, Loss: 0.03467907290905714, Final Batch Loss: 0.01980852335691452\n",
      "Epoch 3176, Loss: 0.06025511585175991, Final Batch Loss: 0.028313877061009407\n",
      "Epoch 3177, Loss: 0.05316208116710186, Final Batch Loss: 0.02336004190146923\n",
      "Epoch 3178, Loss: 0.03214127849787474, Final Batch Loss: 0.02352486364543438\n",
      "Epoch 3179, Loss: 0.023748088628053665, Final Batch Loss: 0.010558666661381721\n",
      "Epoch 3180, Loss: 0.03645530994981527, Final Batch Loss: 0.02252180129289627\n",
      "Epoch 3181, Loss: 0.07517652586102486, Final Batch Loss: 0.018987804651260376\n",
      "Epoch 3182, Loss: 0.06880710273981094, Final Batch Loss: 0.03525101765990257\n",
      "Epoch 3183, Loss: 0.09496507421135902, Final Batch Loss: 0.04693443700671196\n",
      "Epoch 3184, Loss: 0.05315921548753977, Final Batch Loss: 0.011396602727472782\n",
      "Epoch 3185, Loss: 0.05258564278483391, Final Batch Loss: 0.025765595957636833\n",
      "Epoch 3186, Loss: 0.04740096069872379, Final Batch Loss: 0.02030826173722744\n",
      "Epoch 3187, Loss: 0.03920239582657814, Final Batch Loss: 0.019774489104747772\n",
      "Epoch 3188, Loss: 0.03753637708723545, Final Batch Loss: 0.027351809665560722\n",
      "Epoch 3189, Loss: 0.03621930442750454, Final Batch Loss: 0.013270299881696701\n",
      "Epoch 3190, Loss: 0.033661994617432356, Final Batch Loss: 0.007173329126089811\n",
      "Epoch 3191, Loss: 0.07905983738601208, Final Batch Loss: 0.0613565593957901\n",
      "Epoch 3192, Loss: 0.03566490858793259, Final Batch Loss: 0.014950092881917953\n",
      "Epoch 3193, Loss: 0.10706460103392601, Final Batch Loss: 0.0434468649327755\n",
      "Epoch 3194, Loss: 0.045475286431610584, Final Batch Loss: 0.03154870495200157\n",
      "Epoch 3195, Loss: 0.05105039943009615, Final Batch Loss: 0.008263283409178257\n",
      "Epoch 3196, Loss: 0.0313446931540966, Final Batch Loss: 0.01761762984097004\n",
      "Epoch 3197, Loss: 0.06513986736536026, Final Batch Loss: 0.038625240325927734\n",
      "Epoch 3198, Loss: 0.05496455542743206, Final Batch Loss: 0.03428108990192413\n",
      "Epoch 3199, Loss: 0.05815422534942627, Final Batch Loss: 0.04084402322769165\n",
      "Epoch 3200, Loss: 0.04817148111760616, Final Batch Loss: 0.02092915028333664\n",
      "Epoch 3201, Loss: 0.06992856040596962, Final Batch Loss: 0.04330027475953102\n",
      "Epoch 3202, Loss: 0.07615168765187263, Final Batch Loss: 0.0392892099916935\n",
      "Epoch 3203, Loss: 0.041115010157227516, Final Batch Loss: 0.018750546500086784\n",
      "Epoch 3204, Loss: 0.08505285903811455, Final Batch Loss: 0.05031212046742439\n",
      "Epoch 3205, Loss: 0.044292643666267395, Final Batch Loss: 0.01673288643360138\n",
      "Epoch 3206, Loss: 0.0393422981724143, Final Batch Loss: 0.014005678705871105\n",
      "Epoch 3207, Loss: 0.06870699394494295, Final Batch Loss: 0.008607217110693455\n",
      "Epoch 3208, Loss: 0.10284682735800743, Final Batch Loss: 0.07359445840120316\n",
      "Epoch 3209, Loss: 0.036044749431312084, Final Batch Loss: 0.023815760388970375\n",
      "Epoch 3210, Loss: 0.04952786955982447, Final Batch Loss: 0.015134950168430805\n",
      "Epoch 3211, Loss: 0.03460662439465523, Final Batch Loss: 0.015990685671567917\n",
      "Epoch 3212, Loss: 0.09668135643005371, Final Batch Loss: 0.043435078114271164\n",
      "Epoch 3213, Loss: 0.04844237305223942, Final Batch Loss: 0.01709139160811901\n",
      "Epoch 3214, Loss: 0.07350116409361362, Final Batch Loss: 0.04565146565437317\n",
      "Epoch 3215, Loss: 0.0524259265512228, Final Batch Loss: 0.017339562997221947\n",
      "Epoch 3216, Loss: 0.07482147589325905, Final Batch Loss: 0.06422535330057144\n",
      "Epoch 3217, Loss: 0.062353234738111496, Final Batch Loss: 0.03939324617385864\n",
      "Epoch 3218, Loss: 0.30294324830174446, Final Batch Loss: 0.26422226428985596\n",
      "Epoch 3219, Loss: 0.06518877483904362, Final Batch Loss: 0.03966739773750305\n",
      "Epoch 3220, Loss: 0.035443480126559734, Final Batch Loss: 0.021265383809804916\n",
      "Epoch 3221, Loss: 0.03761079255491495, Final Batch Loss: 0.014099390245974064\n",
      "Epoch 3222, Loss: 0.08292410895228386, Final Batch Loss: 0.03748305141925812\n",
      "Epoch 3223, Loss: 0.03400346636772156, Final Batch Loss: 0.010632669553160667\n",
      "Epoch 3224, Loss: 0.05703523615375161, Final Batch Loss: 0.003021086100488901\n",
      "Epoch 3225, Loss: 0.0457223504781723, Final Batch Loss: 0.02514510788023472\n",
      "Epoch 3226, Loss: 0.07362054847180843, Final Batch Loss: 0.015034357085824013\n",
      "Epoch 3227, Loss: 0.014021247625350952, Final Batch Loss: 0.0047378139570355415\n",
      "Epoch 3228, Loss: 0.05293229501694441, Final Batch Loss: 0.012172072194516659\n",
      "Epoch 3229, Loss: 0.0484023280441761, Final Batch Loss: 0.01591857522726059\n",
      "Epoch 3230, Loss: 0.07043896615505219, Final Batch Loss: 0.053043268620967865\n",
      "Epoch 3231, Loss: 0.036766935139894485, Final Batch Loss: 0.022349458187818527\n",
      "Epoch 3232, Loss: 0.047114547342061996, Final Batch Loss: 0.005072485655546188\n",
      "Epoch 3233, Loss: 0.053306715562939644, Final Batch Loss: 0.02426278591156006\n",
      "Epoch 3234, Loss: 0.11903344094753265, Final Batch Loss: 0.08179154992103577\n",
      "Epoch 3235, Loss: 0.0380566231906414, Final Batch Loss: 0.01331767626106739\n",
      "Epoch 3236, Loss: 0.03153645992279053, Final Batch Loss: 0.013108909130096436\n",
      "Epoch 3237, Loss: 0.07307235151529312, Final Batch Loss: 0.03647102043032646\n",
      "Epoch 3238, Loss: 0.07326095923781395, Final Batch Loss: 0.04003722593188286\n",
      "Epoch 3239, Loss: 0.11190593242645264, Final Batch Loss: 0.05938743054866791\n",
      "Epoch 3240, Loss: 0.09214667975902557, Final Batch Loss: 0.04449990391731262\n",
      "Epoch 3241, Loss: 0.05602968856692314, Final Batch Loss: 0.01985836774110794\n",
      "Epoch 3242, Loss: 0.03362078592181206, Final Batch Loss: 0.014693103730678558\n",
      "Epoch 3243, Loss: 0.08786395750939846, Final Batch Loss: 0.06557901948690414\n",
      "Epoch 3244, Loss: 0.0671207644045353, Final Batch Loss: 0.024255581200122833\n",
      "Epoch 3245, Loss: 0.08190646767616272, Final Batch Loss: 0.06275011599063873\n",
      "Epoch 3246, Loss: 0.06171051599085331, Final Batch Loss: 0.03424367308616638\n",
      "Epoch 3247, Loss: 0.146769929677248, Final Batch Loss: 0.08667515963315964\n",
      "Epoch 3248, Loss: 0.02993965521454811, Final Batch Loss: 0.016194652765989304\n",
      "Epoch 3249, Loss: 0.0848466195166111, Final Batch Loss: 0.02778870239853859\n",
      "Epoch 3250, Loss: 0.1028946116566658, Final Batch Loss: 0.03176208585500717\n",
      "Epoch 3251, Loss: 0.022804157808423042, Final Batch Loss: 0.00889542419463396\n",
      "Epoch 3252, Loss: 0.06864163000136614, Final Batch Loss: 0.012441926635801792\n",
      "Epoch 3253, Loss: 0.0438347477465868, Final Batch Loss: 0.01625094749033451\n",
      "Epoch 3254, Loss: 0.05002710968255997, Final Batch Loss: 0.011477958410978317\n",
      "Epoch 3255, Loss: 0.058659497648477554, Final Batch Loss: 0.010948102921247482\n",
      "Epoch 3256, Loss: 0.06788038648664951, Final Batch Loss: 0.041795432567596436\n",
      "Epoch 3257, Loss: 0.05978820100426674, Final Batch Loss: 0.035637736320495605\n",
      "Epoch 3258, Loss: 0.04105195123702288, Final Batch Loss: 0.0280900951474905\n",
      "Epoch 3259, Loss: 0.04702145792543888, Final Batch Loss: 0.018916834145784378\n",
      "Epoch 3260, Loss: 0.04091968759894371, Final Batch Loss: 0.016832517459988594\n",
      "Epoch 3261, Loss: 0.056183287873864174, Final Batch Loss: 0.04939253628253937\n",
      "Epoch 3262, Loss: 0.07783227413892746, Final Batch Loss: 0.019843194633722305\n",
      "Epoch 3263, Loss: 0.06550097838044167, Final Batch Loss: 0.02083582431077957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3264, Loss: 0.06429864466190338, Final Batch Loss: 0.017885100096464157\n",
      "Epoch 3265, Loss: 0.04067662172019482, Final Batch Loss: 0.011099105700850487\n",
      "Epoch 3266, Loss: 0.041431624442338943, Final Batch Loss: 0.017577897757291794\n",
      "Epoch 3267, Loss: 0.0874713696539402, Final Batch Loss: 0.049834802746772766\n",
      "Epoch 3268, Loss: 0.03623857907950878, Final Batch Loss: 0.01585780642926693\n",
      "Epoch 3269, Loss: 0.023238644935190678, Final Batch Loss: 0.0057616522535681725\n",
      "Epoch 3270, Loss: 0.04064768739044666, Final Batch Loss: 0.020440327003598213\n",
      "Epoch 3271, Loss: 0.09890571236610413, Final Batch Loss: 0.07032746821641922\n",
      "Epoch 3272, Loss: 0.039742209017276764, Final Batch Loss: 0.022687366232275963\n",
      "Epoch 3273, Loss: 0.035535769537091255, Final Batch Loss: 0.010688941925764084\n",
      "Epoch 3274, Loss: 0.04660347104072571, Final Batch Loss: 0.02800014242529869\n",
      "Epoch 3275, Loss: 0.07115203887224197, Final Batch Loss: 0.04421914368867874\n",
      "Epoch 3276, Loss: 0.03709747456014156, Final Batch Loss: 0.017354654148221016\n",
      "Epoch 3277, Loss: 0.05737737566232681, Final Batch Loss: 0.019618462771177292\n",
      "Epoch 3278, Loss: 0.04882035218179226, Final Batch Loss: 0.02706204354763031\n",
      "Epoch 3279, Loss: 0.05345635861158371, Final Batch Loss: 0.02358022704720497\n",
      "Epoch 3280, Loss: 0.0667983815073967, Final Batch Loss: 0.03342109173536301\n",
      "Epoch 3281, Loss: 0.06472925934940577, Final Batch Loss: 0.05114088952541351\n",
      "Epoch 3282, Loss: 0.07940161228179932, Final Batch Loss: 0.03955157473683357\n",
      "Epoch 3283, Loss: 0.044746026396751404, Final Batch Loss: 0.012037262320518494\n",
      "Epoch 3284, Loss: 0.05776136461645365, Final Batch Loss: 0.012156923301517963\n",
      "Epoch 3285, Loss: 0.032670595683157444, Final Batch Loss: 0.017441608011722565\n",
      "Epoch 3286, Loss: 0.06664827093482018, Final Batch Loss: 0.02347608655691147\n",
      "Epoch 3287, Loss: 0.11140374653041363, Final Batch Loss: 0.08605503290891647\n",
      "Epoch 3288, Loss: 0.029887237586081028, Final Batch Loss: 0.01536301989108324\n",
      "Epoch 3289, Loss: 0.05765249393880367, Final Batch Loss: 0.02561507560312748\n",
      "Epoch 3290, Loss: 0.03439997881650925, Final Batch Loss: 0.01712101325392723\n",
      "Epoch 3291, Loss: 0.03296435810625553, Final Batch Loss: 0.012149786576628685\n",
      "Epoch 3292, Loss: 0.04396550543606281, Final Batch Loss: 0.027351055294275284\n",
      "Epoch 3293, Loss: 0.018405191600322723, Final Batch Loss: 0.0066164834424853325\n",
      "Epoch 3294, Loss: 0.09658899530768394, Final Batch Loss: 0.07280433177947998\n",
      "Epoch 3295, Loss: 0.03767670597881079, Final Batch Loss: 0.00454214122146368\n",
      "Epoch 3296, Loss: 0.042365171015262604, Final Batch Loss: 0.024331187829375267\n",
      "Epoch 3297, Loss: 0.02475488092750311, Final Batch Loss: 0.01301523670554161\n",
      "Epoch 3298, Loss: 0.09013607539236546, Final Batch Loss: 0.06024247035384178\n",
      "Epoch 3299, Loss: 0.05647680535912514, Final Batch Loss: 0.04493674263358116\n",
      "Epoch 3300, Loss: 0.0908966027200222, Final Batch Loss: 0.04493393376469612\n",
      "Epoch 3301, Loss: 0.06417093984782696, Final Batch Loss: 0.04280691221356392\n",
      "Epoch 3302, Loss: 0.07257563807070255, Final Batch Loss: 0.0226165559142828\n",
      "Epoch 3303, Loss: 0.06359250098466873, Final Batch Loss: 0.020342055708169937\n",
      "Epoch 3304, Loss: 0.05781999230384827, Final Batch Loss: 0.016874685883522034\n",
      "Epoch 3305, Loss: 0.06543875206261873, Final Batch Loss: 0.015581590123474598\n",
      "Epoch 3306, Loss: 0.04933471418917179, Final Batch Loss: 0.01703728176653385\n",
      "Epoch 3307, Loss: 0.06248888745903969, Final Batch Loss: 0.04010968282818794\n",
      "Epoch 3308, Loss: 0.06574583798646927, Final Batch Loss: 0.017336122691631317\n",
      "Epoch 3309, Loss: 0.02404006477445364, Final Batch Loss: 0.011679565533995628\n",
      "Epoch 3310, Loss: 0.15457049012184143, Final Batch Loss: 0.1314174234867096\n",
      "Epoch 3311, Loss: 0.028643955010920763, Final Batch Loss: 0.004132355097681284\n",
      "Epoch 3312, Loss: 0.10622544214129448, Final Batch Loss: 0.017751622945070267\n",
      "Epoch 3313, Loss: 0.06616825237870216, Final Batch Loss: 0.052329208701848984\n",
      "Epoch 3314, Loss: 0.09472248330712318, Final Batch Loss: 0.032189417630434036\n",
      "Epoch 3315, Loss: 0.04728799685835838, Final Batch Loss: 0.01840853877365589\n",
      "Epoch 3316, Loss: 0.02565642260015011, Final Batch Loss: 0.01450152974575758\n",
      "Epoch 3317, Loss: 0.03948577307164669, Final Batch Loss: 0.020371438935399055\n",
      "Epoch 3318, Loss: 0.07250219956040382, Final Batch Loss: 0.026372473686933517\n",
      "Epoch 3319, Loss: 0.06854818016290665, Final Batch Loss: 0.04454732686281204\n",
      "Epoch 3320, Loss: 0.07737264595925808, Final Batch Loss: 0.057941947132349014\n",
      "Epoch 3321, Loss: 0.10490346141159534, Final Batch Loss: 0.07384584844112396\n",
      "Epoch 3322, Loss: 0.02968176268041134, Final Batch Loss: 0.019808633252978325\n",
      "Epoch 3323, Loss: 0.024486075155436993, Final Batch Loss: 0.004687893204391003\n",
      "Epoch 3324, Loss: 0.04842320643365383, Final Batch Loss: 0.006470115855336189\n",
      "Epoch 3325, Loss: 0.07698495499789715, Final Batch Loss: 0.01537519134581089\n",
      "Epoch 3326, Loss: 0.03933203965425491, Final Batch Loss: 0.02120460942387581\n",
      "Epoch 3327, Loss: 0.04873621091246605, Final Batch Loss: 0.02539934404194355\n",
      "Epoch 3328, Loss: 0.028834382072091103, Final Batch Loss: 0.008735014125704765\n",
      "Epoch 3329, Loss: 0.05127299763262272, Final Batch Loss: 0.024430492892861366\n",
      "Epoch 3330, Loss: 0.04423360340297222, Final Batch Loss: 0.02566036768257618\n",
      "Epoch 3331, Loss: 0.05527040548622608, Final Batch Loss: 0.008102631196379662\n",
      "Epoch 3332, Loss: 0.056349409744143486, Final Batch Loss: 0.01931280829012394\n",
      "Epoch 3333, Loss: 0.07389957830309868, Final Batch Loss: 0.055321257561445236\n",
      "Epoch 3334, Loss: 0.1142064668238163, Final Batch Loss: 0.07324408739805222\n",
      "Epoch 3335, Loss: 0.04952691588550806, Final Batch Loss: 0.03728310391306877\n",
      "Epoch 3336, Loss: 0.07972552627325058, Final Batch Loss: 0.022657249122858047\n",
      "Epoch 3337, Loss: 0.08488588407635689, Final Batch Loss: 0.03769524767994881\n",
      "Epoch 3338, Loss: 0.027421116828918457, Final Batch Loss: 0.01835598237812519\n",
      "Epoch 3339, Loss: 0.056785909458994865, Final Batch Loss: 0.037175148725509644\n",
      "Epoch 3340, Loss: 0.04617070499807596, Final Batch Loss: 0.01552323903888464\n",
      "Epoch 3341, Loss: 0.03680033050477505, Final Batch Loss: 0.01566377282142639\n",
      "Epoch 3342, Loss: 0.03917396627366543, Final Batch Loss: 0.021704817190766335\n",
      "Epoch 3343, Loss: 0.11051607877016068, Final Batch Loss: 0.07591865956783295\n",
      "Epoch 3344, Loss: 0.04816839098930359, Final Batch Loss: 0.016308557242155075\n",
      "Epoch 3345, Loss: 0.09748854488134384, Final Batch Loss: 0.07885604351758957\n",
      "Epoch 3346, Loss: 0.06904755532741547, Final Batch Loss: 0.042672041803598404\n",
      "Epoch 3347, Loss: 0.06203928031027317, Final Batch Loss: 0.029044242575764656\n",
      "Epoch 3348, Loss: 0.031073165126144886, Final Batch Loss: 0.015098457224667072\n",
      "Epoch 3349, Loss: 0.033062029629945755, Final Batch Loss: 0.014242241159081459\n",
      "Epoch 3350, Loss: 0.08994166925549507, Final Batch Loss: 0.023990299552679062\n",
      "Epoch 3351, Loss: 0.019578532315790653, Final Batch Loss: 0.011759837158024311\n",
      "Epoch 3352, Loss: 0.059239232912659645, Final Batch Loss: 0.029011419042944908\n",
      "Epoch 3353, Loss: 0.044626953080296516, Final Batch Loss: 0.014116451144218445\n",
      "Epoch 3354, Loss: 0.021647265180945396, Final Batch Loss: 0.008498155511915684\n",
      "Epoch 3355, Loss: 0.058258889243006706, Final Batch Loss: 0.02201724983751774\n",
      "Epoch 3356, Loss: 0.04216706566512585, Final Batch Loss: 0.017209310084581375\n",
      "Epoch 3357, Loss: 0.0414094552397728, Final Batch Loss: 0.015668969601392746\n",
      "Epoch 3358, Loss: 0.07633025571703911, Final Batch Loss: 0.03326698765158653\n",
      "Epoch 3359, Loss: 0.03573239501565695, Final Batch Loss: 0.007896949537098408\n",
      "Epoch 3360, Loss: 0.07364245504140854, Final Batch Loss: 0.026135016232728958\n",
      "Epoch 3361, Loss: 0.0269613154232502, Final Batch Loss: 0.013303365558385849\n",
      "Epoch 3362, Loss: 0.06004815921187401, Final Batch Loss: 0.026403315365314484\n",
      "Epoch 3363, Loss: 0.05565853416919708, Final Batch Loss: 0.03346959874033928\n",
      "Epoch 3364, Loss: 0.061979034915566444, Final Batch Loss: 0.04399167373776436\n",
      "Epoch 3365, Loss: 0.045834897086024284, Final Batch Loss: 0.02030138112604618\n",
      "Epoch 3366, Loss: 0.06081696227192879, Final Batch Loss: 0.026091597974300385\n",
      "Epoch 3367, Loss: 0.05225330195389688, Final Batch Loss: 0.003044124459847808\n",
      "Epoch 3368, Loss: 0.11760503053665161, Final Batch Loss: 0.07683444023132324\n",
      "Epoch 3369, Loss: 0.033055094070732594, Final Batch Loss: 0.010566960088908672\n",
      "Epoch 3370, Loss: 0.014487174339592457, Final Batch Loss: 0.008158400654792786\n",
      "Epoch 3371, Loss: 0.05076785944402218, Final Batch Loss: 0.025152195245027542\n",
      "Epoch 3372, Loss: 0.09636296331882477, Final Batch Loss: 0.03735734149813652\n",
      "Epoch 3373, Loss: 0.06364158913493156, Final Batch Loss: 0.03075948730111122\n",
      "Epoch 3374, Loss: 0.045476894825696945, Final Batch Loss: 0.014372196048498154\n",
      "Epoch 3375, Loss: 0.10601454228162766, Final Batch Loss: 0.04873482137918472\n",
      "Epoch 3376, Loss: 0.02966990345157683, Final Batch Loss: 0.00329193496145308\n",
      "Epoch 3377, Loss: 0.02360245492309332, Final Batch Loss: 0.01164097897708416\n",
      "Epoch 3378, Loss: 0.03731434140354395, Final Batch Loss: 0.01467157807201147\n",
      "Epoch 3379, Loss: 0.08766373433172703, Final Batch Loss: 0.0742010697722435\n",
      "Epoch 3380, Loss: 0.0716700479388237, Final Batch Loss: 0.028979357331991196\n",
      "Epoch 3381, Loss: 0.030711419880390167, Final Batch Loss: 0.02504727803170681\n",
      "Epoch 3382, Loss: 0.056876836344599724, Final Batch Loss: 0.03294835612177849\n",
      "Epoch 3383, Loss: 0.05116056650876999, Final Batch Loss: 0.036489248275756836\n",
      "Epoch 3384, Loss: 0.0443718284368515, Final Batch Loss: 0.019969848915934563\n",
      "Epoch 3385, Loss: 0.07346008718013763, Final Batch Loss: 0.04734468460083008\n",
      "Epoch 3386, Loss: 0.037829541601240635, Final Batch Loss: 0.024758322164416313\n",
      "Epoch 3387, Loss: 0.05400916375219822, Final Batch Loss: 0.031832609325647354\n",
      "Epoch 3388, Loss: 0.023035474121570587, Final Batch Loss: 0.011520978063344955\n",
      "Epoch 3389, Loss: 0.0560531048104167, Final Batch Loss: 0.012445899657905102\n",
      "Epoch 3390, Loss: 0.03616320341825485, Final Batch Loss: 0.01966436766088009\n",
      "Epoch 3391, Loss: 0.048776380717754364, Final Batch Loss: 0.023354586213827133\n",
      "Epoch 3392, Loss: 0.0527548473328352, Final Batch Loss: 0.030761422589421272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3393, Loss: 0.04665830358862877, Final Batch Loss: 0.023553259670734406\n",
      "Epoch 3394, Loss: 0.042564221657812595, Final Batch Loss: 0.0316222608089447\n",
      "Epoch 3395, Loss: 0.03248372208327055, Final Batch Loss: 0.008052644319832325\n",
      "Epoch 3396, Loss: 0.042695197742432356, Final Batch Loss: 0.00748473359271884\n",
      "Epoch 3397, Loss: 0.031920787412673235, Final Batch Loss: 0.007516535464674234\n",
      "Epoch 3398, Loss: 0.04403318930417299, Final Batch Loss: 0.014505532570183277\n",
      "Epoch 3399, Loss: 0.06079574581235647, Final Batch Loss: 0.04609287902712822\n",
      "Epoch 3400, Loss: 0.07404300384223461, Final Batch Loss: 0.02315998636186123\n",
      "Epoch 3401, Loss: 0.03976897895336151, Final Batch Loss: 0.00954187661409378\n",
      "Epoch 3402, Loss: 0.08460618555545807, Final Batch Loss: 0.06639745831489563\n",
      "Epoch 3403, Loss: 0.09057917445898056, Final Batch Loss: 0.05139002576470375\n",
      "Epoch 3404, Loss: 0.03509105555713177, Final Batch Loss: 0.012292206287384033\n",
      "Epoch 3405, Loss: 0.03334537334740162, Final Batch Loss: 0.016713496297597885\n",
      "Epoch 3406, Loss: 0.03753434680402279, Final Batch Loss: 0.01718156784772873\n",
      "Epoch 3407, Loss: 0.07367120310664177, Final Batch Loss: 0.0356791689991951\n",
      "Epoch 3408, Loss: 0.059430379420518875, Final Batch Loss: 0.0397789403796196\n",
      "Epoch 3409, Loss: 0.03949466347694397, Final Batch Loss: 0.014756262302398682\n",
      "Epoch 3410, Loss: 0.11727696005254984, Final Batch Loss: 0.012437992729246616\n",
      "Epoch 3411, Loss: 0.058744294568896294, Final Batch Loss: 0.042185064405202866\n",
      "Epoch 3412, Loss: 0.030314678326249123, Final Batch Loss: 0.020322127267718315\n",
      "Epoch 3413, Loss: 0.03024411667138338, Final Batch Loss: 0.012286302633583546\n",
      "Epoch 3414, Loss: 0.03754018247127533, Final Batch Loss: 0.013975942507386208\n",
      "Epoch 3415, Loss: 0.07029693573713303, Final Batch Loss: 0.023402541875839233\n",
      "Epoch 3416, Loss: 0.07864882983267307, Final Batch Loss: 0.06929052621126175\n",
      "Epoch 3417, Loss: 0.08007245883345604, Final Batch Loss: 0.06668032705783844\n",
      "Epoch 3418, Loss: 0.023737726267427206, Final Batch Loss: 0.017033720389008522\n",
      "Epoch 3419, Loss: 0.05994401313364506, Final Batch Loss: 0.015548786148428917\n",
      "Epoch 3420, Loss: 0.08589768782258034, Final Batch Loss: 0.05162777751684189\n",
      "Epoch 3421, Loss: 0.03441705834120512, Final Batch Loss: 0.007985635660588741\n",
      "Epoch 3422, Loss: 0.052493294700980186, Final Batch Loss: 0.02729242853820324\n",
      "Epoch 3423, Loss: 0.046961864456534386, Final Batch Loss: 0.019253935664892197\n",
      "Epoch 3424, Loss: 0.07794808968901634, Final Batch Loss: 0.04272215813398361\n",
      "Epoch 3425, Loss: 0.032613473013043404, Final Batch Loss: 0.012694904580712318\n",
      "Epoch 3426, Loss: 0.04859945550560951, Final Batch Loss: 0.028594553470611572\n",
      "Epoch 3427, Loss: 0.0517093688249588, Final Batch Loss: 0.021511251106858253\n",
      "Epoch 3428, Loss: 0.07359835971146822, Final Batch Loss: 0.006914784200489521\n",
      "Epoch 3429, Loss: 0.04144498519599438, Final Batch Loss: 0.027906375005841255\n",
      "Epoch 3430, Loss: 0.051255399361252785, Final Batch Loss: 0.025782205164432526\n",
      "Epoch 3431, Loss: 0.08608750440180302, Final Batch Loss: 0.05969276651740074\n",
      "Epoch 3432, Loss: 0.051958512514829636, Final Batch Loss: 0.03034154884517193\n",
      "Epoch 3433, Loss: 0.07372814416885376, Final Batch Loss: 0.05413268506526947\n",
      "Epoch 3434, Loss: 0.04042568104341626, Final Batch Loss: 0.007654671091586351\n",
      "Epoch 3435, Loss: 0.06522711925208569, Final Batch Loss: 0.04759727418422699\n",
      "Epoch 3436, Loss: 0.13445138931274414, Final Batch Loss: 0.0348413810133934\n",
      "Epoch 3437, Loss: 0.03999266307801008, Final Batch Loss: 0.0087547292932868\n",
      "Epoch 3438, Loss: 0.04674882534891367, Final Batch Loss: 0.03416673466563225\n",
      "Epoch 3439, Loss: 0.03727836534380913, Final Batch Loss: 0.019769325852394104\n",
      "Epoch 3440, Loss: 0.043016182258725166, Final Batch Loss: 0.012271855026483536\n",
      "Epoch 3441, Loss: 0.05676494538784027, Final Batch Loss: 0.03013896942138672\n",
      "Epoch 3442, Loss: 0.07926458865404129, Final Batch Loss: 0.06733051687479019\n",
      "Epoch 3443, Loss: 0.03701957035809755, Final Batch Loss: 0.02313472516834736\n",
      "Epoch 3444, Loss: 0.07026913203299046, Final Batch Loss: 0.04111797735095024\n",
      "Epoch 3445, Loss: 0.028652945533394814, Final Batch Loss: 0.010302675887942314\n",
      "Epoch 3446, Loss: 0.06324294582009315, Final Batch Loss: 0.029134143143892288\n",
      "Epoch 3447, Loss: 0.052173079922795296, Final Batch Loss: 0.007775137200951576\n",
      "Epoch 3448, Loss: 0.056187829002738, Final Batch Loss: 0.02339051477611065\n",
      "Epoch 3449, Loss: 0.05614592507481575, Final Batch Loss: 0.018952365964651108\n",
      "Epoch 3450, Loss: 0.07225876301527023, Final Batch Loss: 0.043565534055233\n",
      "Epoch 3451, Loss: 0.047762248665094376, Final Batch Loss: 0.011337783187627792\n",
      "Epoch 3452, Loss: 0.022913057822734118, Final Batch Loss: 0.004049757961183786\n",
      "Epoch 3453, Loss: 0.04364497773349285, Final Batch Loss: 0.023158114403486252\n",
      "Epoch 3454, Loss: 0.02167938696220517, Final Batch Loss: 0.004219899419695139\n",
      "Epoch 3455, Loss: 0.03139702137559652, Final Batch Loss: 0.02025272324681282\n",
      "Epoch 3456, Loss: 0.03474609553813934, Final Batch Loss: 0.01596277393400669\n",
      "Epoch 3457, Loss: 0.04655191861093044, Final Batch Loss: 0.019779615104198456\n",
      "Epoch 3458, Loss: 0.06386253423988819, Final Batch Loss: 0.014107892289757729\n",
      "Epoch 3459, Loss: 0.04690195992588997, Final Batch Loss: 0.023712461814284325\n",
      "Epoch 3460, Loss: 0.053587095346301794, Final Batch Loss: 0.04777217656373978\n",
      "Epoch 3461, Loss: 0.05591465625911951, Final Batch Loss: 0.04423332214355469\n",
      "Epoch 3462, Loss: 0.043430959805846214, Final Batch Loss: 0.015149282291531563\n",
      "Epoch 3463, Loss: 0.052932173013687134, Final Batch Loss: 0.03655019402503967\n",
      "Epoch 3464, Loss: 0.05907364748418331, Final Batch Loss: 0.03671957179903984\n",
      "Epoch 3465, Loss: 0.04132796544581652, Final Batch Loss: 0.015309506095945835\n",
      "Epoch 3466, Loss: 0.017429335042834282, Final Batch Loss: 0.010901707224547863\n",
      "Epoch 3467, Loss: 0.0963708907365799, Final Batch Loss: 0.06033729016780853\n",
      "Epoch 3468, Loss: 0.06298294849693775, Final Batch Loss: 0.03762698918581009\n",
      "Epoch 3469, Loss: 0.067035723477602, Final Batch Loss: 0.031197771430015564\n",
      "Epoch 3470, Loss: 0.17154185473918915, Final Batch Loss: 0.10167872160673141\n",
      "Epoch 3471, Loss: 0.08736660331487656, Final Batch Loss: 0.04446171969175339\n",
      "Epoch 3472, Loss: 0.034231312572956085, Final Batch Loss: 0.01918630488216877\n",
      "Epoch 3473, Loss: 0.05354374647140503, Final Batch Loss: 0.01320868730545044\n",
      "Epoch 3474, Loss: 0.05328611098229885, Final Batch Loss: 0.013066938146948814\n",
      "Epoch 3475, Loss: 0.077347032725811, Final Batch Loss: 0.05107886716723442\n",
      "Epoch 3476, Loss: 0.024242177605628967, Final Batch Loss: 0.012684249319136143\n",
      "Epoch 3477, Loss: 0.07928833924233913, Final Batch Loss: 0.059692952781915665\n",
      "Epoch 3478, Loss: 0.04024536069482565, Final Batch Loss: 0.010982290841639042\n",
      "Epoch 3479, Loss: 0.08864780887961388, Final Batch Loss: 0.03984944522380829\n",
      "Epoch 3480, Loss: 0.09783447906374931, Final Batch Loss: 0.051781367510557175\n",
      "Epoch 3481, Loss: 0.05085223354399204, Final Batch Loss: 0.03893459960818291\n",
      "Epoch 3482, Loss: 0.026302197948098183, Final Batch Loss: 0.013541650027036667\n",
      "Epoch 3483, Loss: 0.05072006583213806, Final Batch Loss: 0.012553960084915161\n",
      "Epoch 3484, Loss: 0.06767111923545599, Final Batch Loss: 0.015287521295249462\n",
      "Epoch 3485, Loss: 0.0511514525860548, Final Batch Loss: 0.029774313792586327\n",
      "Epoch 3486, Loss: 0.04427617136389017, Final Batch Loss: 0.01161136943846941\n",
      "Epoch 3487, Loss: 0.03552505187690258, Final Batch Loss: 0.013403767719864845\n",
      "Epoch 3488, Loss: 0.04863404296338558, Final Batch Loss: 0.03143727034330368\n",
      "Epoch 3489, Loss: 0.0554616954177618, Final Batch Loss: 0.0217344518750906\n",
      "Epoch 3490, Loss: 0.030637653544545174, Final Batch Loss: 0.011844409629702568\n",
      "Epoch 3491, Loss: 0.048252927139401436, Final Batch Loss: 0.014007123187184334\n",
      "Epoch 3492, Loss: 0.05409071035683155, Final Batch Loss: 0.031005002558231354\n",
      "Epoch 3493, Loss: 0.05808056704699993, Final Batch Loss: 0.026331933215260506\n",
      "Epoch 3494, Loss: 0.059794340282678604, Final Batch Loss: 0.03489025682210922\n",
      "Epoch 3495, Loss: 0.06983681954443455, Final Batch Loss: 0.01994563452899456\n",
      "Epoch 3496, Loss: 0.06783933378756046, Final Batch Loss: 0.02185683511197567\n",
      "Epoch 3497, Loss: 0.042911773547530174, Final Batch Loss: 0.015446841716766357\n",
      "Epoch 3498, Loss: 0.0732831321656704, Final Batch Loss: 0.05480285733938217\n",
      "Epoch 3499, Loss: 0.03946959786117077, Final Batch Loss: 0.011529188603162766\n",
      "Epoch 3500, Loss: 0.04557558707892895, Final Batch Loss: 0.019626930356025696\n",
      "Epoch 3501, Loss: 0.03891967236995697, Final Batch Loss: 0.021516093984246254\n",
      "Epoch 3502, Loss: 0.03892207145690918, Final Batch Loss: 0.016671817749738693\n",
      "Epoch 3503, Loss: 0.017397559247910976, Final Batch Loss: 0.0045132506638765335\n",
      "Epoch 3504, Loss: 0.035265338607132435, Final Batch Loss: 0.009122070856392384\n",
      "Epoch 3505, Loss: 0.03813735954463482, Final Batch Loss: 0.013803541660308838\n",
      "Epoch 3506, Loss: 0.03355594724416733, Final Batch Loss: 0.018019795417785645\n",
      "Epoch 3507, Loss: 0.040278881788253784, Final Batch Loss: 0.009629923850297928\n",
      "Epoch 3508, Loss: 0.07456421665847301, Final Batch Loss: 0.05500412732362747\n",
      "Epoch 3509, Loss: 0.02934956457465887, Final Batch Loss: 0.01432058960199356\n",
      "Epoch 3510, Loss: 0.08163511008024216, Final Batch Loss: 0.06054734066128731\n",
      "Epoch 3511, Loss: 0.05746828764677048, Final Batch Loss: 0.032429855316877365\n",
      "Epoch 3512, Loss: 0.027614922262728214, Final Batch Loss: 0.011331266723573208\n",
      "Epoch 3513, Loss: 0.0679280860349536, Final Batch Loss: 0.05250326544046402\n",
      "Epoch 3514, Loss: 0.0527215301990509, Final Batch Loss: 0.021510817110538483\n",
      "Epoch 3515, Loss: 0.04987973999232054, Final Batch Loss: 0.03544666990637779\n",
      "Epoch 3516, Loss: 0.03245765529572964, Final Batch Loss: 0.008751742541790009\n",
      "Epoch 3517, Loss: 0.07425476238131523, Final Batch Loss: 0.024486053735017776\n",
      "Epoch 3518, Loss: 0.02458041813224554, Final Batch Loss: 0.01373288594186306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3519, Loss: 0.028219853527843952, Final Batch Loss: 0.01132871676236391\n",
      "Epoch 3520, Loss: 0.036996311508119106, Final Batch Loss: 0.02420002780854702\n",
      "Epoch 3521, Loss: 0.03174046892672777, Final Batch Loss: 0.01425927598029375\n",
      "Epoch 3522, Loss: 0.0278258565813303, Final Batch Loss: 0.005726361647248268\n",
      "Epoch 3523, Loss: 0.05210713017731905, Final Batch Loss: 0.014859099872410297\n",
      "Epoch 3524, Loss: 0.037588045466691256, Final Batch Loss: 0.005947448778897524\n",
      "Epoch 3525, Loss: 0.04824217967689037, Final Batch Loss: 0.019995518028736115\n",
      "Epoch 3526, Loss: 0.04557824693620205, Final Batch Loss: 0.020534425973892212\n",
      "Epoch 3527, Loss: 0.07006782293319702, Final Batch Loss: 0.02634093165397644\n",
      "Epoch 3528, Loss: 0.047029216773808, Final Batch Loss: 0.03340600058436394\n",
      "Epoch 3529, Loss: 0.015176932327449322, Final Batch Loss: 0.008538303896784782\n",
      "Epoch 3530, Loss: 0.02580846566706896, Final Batch Loss: 0.010436183772981167\n",
      "Epoch 3531, Loss: 0.047702252864837646, Final Batch Loss: 0.02955094911158085\n",
      "Epoch 3532, Loss: 0.08147814497351646, Final Batch Loss: 0.047237373888492584\n",
      "Epoch 3533, Loss: 0.06044889613986015, Final Batch Loss: 0.022854633629322052\n",
      "Epoch 3534, Loss: 0.038199334405362606, Final Batch Loss: 0.005332226864993572\n",
      "Epoch 3535, Loss: 0.05658160336315632, Final Batch Loss: 0.024541286751627922\n",
      "Epoch 3536, Loss: 0.0882586408406496, Final Batch Loss: 0.06430134177207947\n",
      "Epoch 3537, Loss: 0.029222169425338507, Final Batch Loss: 0.005054287146776915\n",
      "Epoch 3538, Loss: 0.06975241377949715, Final Batch Loss: 0.055488064885139465\n",
      "Epoch 3539, Loss: 0.14288435131311417, Final Batch Loss: 0.03093031793832779\n",
      "Epoch 3540, Loss: 0.0564587265253067, Final Batch Loss: 0.03989535942673683\n",
      "Epoch 3541, Loss: 0.12245030701160431, Final Batch Loss: 0.06415851414203644\n",
      "Epoch 3542, Loss: 0.11899017915129662, Final Batch Loss: 0.046938005834817886\n",
      "Epoch 3543, Loss: 0.14939085394144058, Final Batch Loss: 0.08022676408290863\n",
      "Epoch 3544, Loss: 0.08201185055077076, Final Batch Loss: 0.020615672692656517\n",
      "Epoch 3545, Loss: 0.02612663060426712, Final Batch Loss: 0.011163749732077122\n",
      "Epoch 3546, Loss: 0.26862122118473053, Final Batch Loss: 0.17452746629714966\n",
      "Epoch 3547, Loss: 0.14625266939401627, Final Batch Loss: 0.061085186898708344\n",
      "Epoch 3548, Loss: 0.05170361790806055, Final Batch Loss: 0.015380152501165867\n",
      "Epoch 3549, Loss: 0.16268017888069153, Final Batch Loss: 0.0942128598690033\n",
      "Epoch 3550, Loss: 0.02772526815533638, Final Batch Loss: 0.006832201033830643\n",
      "Epoch 3551, Loss: 0.1272955983877182, Final Batch Loss: 0.029548481106758118\n",
      "Epoch 3552, Loss: 0.047819314524531364, Final Batch Loss: 0.02818307653069496\n",
      "Epoch 3553, Loss: 0.03951816912740469, Final Batch Loss: 0.009403432719409466\n",
      "Epoch 3554, Loss: 0.06388903968036175, Final Batch Loss: 0.03396647050976753\n",
      "Epoch 3555, Loss: 0.0447885487228632, Final Batch Loss: 0.01563359797000885\n",
      "Epoch 3556, Loss: 0.02417471120133996, Final Batch Loss: 0.0044313655234873295\n",
      "Epoch 3557, Loss: 0.08752690628170967, Final Batch Loss: 0.05058212950825691\n",
      "Epoch 3558, Loss: 0.06275191716849804, Final Batch Loss: 0.019483407959342003\n",
      "Epoch 3559, Loss: 0.10518247075378895, Final Batch Loss: 0.07874086499214172\n",
      "Epoch 3560, Loss: 0.0631784163415432, Final Batch Loss: 0.030778784304857254\n",
      "Epoch 3561, Loss: 0.07772337086498737, Final Batch Loss: 0.016967294737696648\n",
      "Epoch 3562, Loss: 0.05292748659849167, Final Batch Loss: 0.02175068110227585\n",
      "Epoch 3563, Loss: 0.05001661367714405, Final Batch Loss: 0.012249888852238655\n",
      "Epoch 3564, Loss: 0.06353012472391129, Final Batch Loss: 0.04686910659074783\n",
      "Epoch 3565, Loss: 0.036141022108495235, Final Batch Loss: 0.015114874579012394\n",
      "Epoch 3566, Loss: 0.059577103704214096, Final Batch Loss: 0.03661039099097252\n",
      "Epoch 3567, Loss: 0.08188628405332565, Final Batch Loss: 0.06447503715753555\n",
      "Epoch 3568, Loss: 0.07475600205361843, Final Batch Loss: 0.050748828798532486\n",
      "Epoch 3569, Loss: 0.024561152793467045, Final Batch Loss: 0.011296807788312435\n",
      "Epoch 3570, Loss: 0.04156804829835892, Final Batch Loss: 0.020382672548294067\n",
      "Epoch 3571, Loss: 0.045481717213988304, Final Batch Loss: 0.02447904273867607\n",
      "Epoch 3572, Loss: 0.042260327842086554, Final Batch Loss: 0.00719711696729064\n",
      "Epoch 3573, Loss: 0.08982679061591625, Final Batch Loss: 0.06472497433423996\n",
      "Epoch 3574, Loss: 0.037565479055047035, Final Batch Loss: 0.012975964695215225\n",
      "Epoch 3575, Loss: 0.027651832439005375, Final Batch Loss: 0.015342985279858112\n",
      "Epoch 3576, Loss: 0.035667186602950096, Final Batch Loss: 0.02428179234266281\n",
      "Epoch 3577, Loss: 0.012102891225367785, Final Batch Loss: 0.003103975672274828\n",
      "Epoch 3578, Loss: 0.05879390053451061, Final Batch Loss: 0.04218893125653267\n",
      "Epoch 3579, Loss: 0.09785504639148712, Final Batch Loss: 0.06064777076244354\n",
      "Epoch 3580, Loss: 0.06260044686496258, Final Batch Loss: 0.037031397223472595\n",
      "Epoch 3581, Loss: 0.03164489381015301, Final Batch Loss: 0.005993574857711792\n",
      "Epoch 3582, Loss: 0.03786943107843399, Final Batch Loss: 0.009075319394469261\n",
      "Epoch 3583, Loss: 0.06210637465119362, Final Batch Loss: 0.02277076616883278\n",
      "Epoch 3584, Loss: 0.03503150213509798, Final Batch Loss: 0.012107961811125278\n",
      "Epoch 3585, Loss: 0.028155164793133736, Final Batch Loss: 0.0056279804557561874\n",
      "Epoch 3586, Loss: 0.02222267910838127, Final Batch Loss: 0.011082028038799763\n",
      "Epoch 3587, Loss: 0.08835742250084877, Final Batch Loss: 0.03777743875980377\n",
      "Epoch 3588, Loss: 0.034728921949863434, Final Batch Loss: 0.004688948392868042\n",
      "Epoch 3589, Loss: 0.04045192990452051, Final Batch Loss: 0.027248565107584\n",
      "Epoch 3590, Loss: 0.029183017555624247, Final Batch Loss: 0.006143162492662668\n",
      "Epoch 3591, Loss: 0.06453029438853264, Final Batch Loss: 0.026059430092573166\n",
      "Epoch 3592, Loss: 0.03694774582982063, Final Batch Loss: 0.019722020253539085\n",
      "Epoch 3593, Loss: 0.0678520705550909, Final Batch Loss: 0.01823355443775654\n",
      "Epoch 3594, Loss: 0.031142456457018852, Final Batch Loss: 0.009779484942555428\n",
      "Epoch 3595, Loss: 0.08016734290868044, Final Batch Loss: 0.06528668850660324\n",
      "Epoch 3596, Loss: 0.0282184686511755, Final Batch Loss: 0.017495114356279373\n",
      "Epoch 3597, Loss: 0.021935282042250037, Final Batch Loss: 0.0017428246792405844\n",
      "Epoch 3598, Loss: 0.04744391515851021, Final Batch Loss: 0.01817198283970356\n",
      "Epoch 3599, Loss: 0.0339904660359025, Final Batch Loss: 0.027329817414283752\n",
      "Epoch 3600, Loss: 0.04243685118854046, Final Batch Loss: 0.02333635278046131\n",
      "Epoch 3601, Loss: 0.033262849785387516, Final Batch Loss: 0.007868428714573383\n",
      "Epoch 3602, Loss: 0.09139353968203068, Final Batch Loss: 0.026725614443421364\n",
      "Epoch 3603, Loss: 0.0733465813100338, Final Batch Loss: 0.017381835728883743\n",
      "Epoch 3604, Loss: 0.041671670973300934, Final Batch Loss: 0.03297574445605278\n",
      "Epoch 3605, Loss: 0.04696071147918701, Final Batch Loss: 0.030277308076620102\n",
      "Epoch 3606, Loss: 0.06694161705672741, Final Batch Loss: 0.027716802433133125\n",
      "Epoch 3607, Loss: 0.03742143977433443, Final Batch Loss: 0.014934970997273922\n",
      "Epoch 3608, Loss: 0.04665001388639212, Final Batch Loss: 0.008051472716033459\n",
      "Epoch 3609, Loss: 0.018954521510750055, Final Batch Loss: 0.013920768164098263\n",
      "Epoch 3610, Loss: 0.03112597856670618, Final Batch Loss: 0.011402183212339878\n",
      "Epoch 3611, Loss: 0.07622800394892693, Final Batch Loss: 0.033866748213768005\n",
      "Epoch 3612, Loss: 0.05260498635470867, Final Batch Loss: 0.03856198862195015\n",
      "Epoch 3613, Loss: 0.055369201116263866, Final Batch Loss: 0.045040033757686615\n",
      "Epoch 3614, Loss: 0.06681341864168644, Final Batch Loss: 0.05084555596113205\n",
      "Epoch 3615, Loss: 0.03870380111038685, Final Batch Loss: 0.029888946563005447\n",
      "Epoch 3616, Loss: 0.08225692994892597, Final Batch Loss: 0.06207103282213211\n",
      "Epoch 3617, Loss: 0.03993509663268924, Final Batch Loss: 0.032645951956510544\n",
      "Epoch 3618, Loss: 0.020119350403547287, Final Batch Loss: 0.0033858399838209152\n",
      "Epoch 3619, Loss: 0.03159076254814863, Final Batch Loss: 0.008302153088152409\n",
      "Epoch 3620, Loss: 0.06529617868363857, Final Batch Loss: 0.02835182659327984\n",
      "Epoch 3621, Loss: 0.0354026285931468, Final Batch Loss: 0.022116366773843765\n",
      "Epoch 3622, Loss: 0.02598361112177372, Final Batch Loss: 0.0042796265333890915\n",
      "Epoch 3623, Loss: 0.030683948658406734, Final Batch Loss: 0.015844494104385376\n",
      "Epoch 3624, Loss: 0.04708026349544525, Final Batch Loss: 0.00815264880657196\n",
      "Epoch 3625, Loss: 0.032106226310133934, Final Batch Loss: 0.014757443219423294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3626, Loss: 0.10048267617821693, Final Batch Loss: 0.048724886029958725\n",
      "Epoch 3627, Loss: 0.037502119317650795, Final Batch Loss: 0.007025090977549553\n",
      "Epoch 3628, Loss: 0.035097386687994, Final Batch Loss: 0.0251073706895113\n",
      "Epoch 3629, Loss: 0.016758740413933992, Final Batch Loss: 0.010088754817843437\n",
      "Epoch 3630, Loss: 0.03885188139975071, Final Batch Loss: 0.016129709780216217\n",
      "Epoch 3631, Loss: 0.030987316742539406, Final Batch Loss: 0.009166667237877846\n",
      "Epoch 3632, Loss: 0.01799248903989792, Final Batch Loss: 0.010613841004669666\n",
      "Epoch 3633, Loss: 0.07305525802075863, Final Batch Loss: 0.05555202439427376\n",
      "Epoch 3634, Loss: 0.019777947571128607, Final Batch Loss: 0.01414315216243267\n",
      "Epoch 3635, Loss: 0.05378522165119648, Final Batch Loss: 0.02744665928184986\n",
      "Epoch 3636, Loss: 0.030040952377021313, Final Batch Loss: 0.01881159283220768\n",
      "Epoch 3637, Loss: 0.014741085469722748, Final Batch Loss: 0.006020925007760525\n",
      "Epoch 3638, Loss: 0.019903667736798525, Final Batch Loss: 0.012858111411333084\n",
      "Epoch 3639, Loss: 0.02553468942642212, Final Batch Loss: 0.01417810469865799\n",
      "Epoch 3640, Loss: 0.03211179934442043, Final Batch Loss: 0.024171315133571625\n",
      "Epoch 3641, Loss: 0.07866857759654522, Final Batch Loss: 0.06247377023100853\n",
      "Epoch 3642, Loss: 0.01954627549275756, Final Batch Loss: 0.005181462969630957\n",
      "Epoch 3643, Loss: 0.06922659743577242, Final Batch Loss: 0.05640502646565437\n",
      "Epoch 3644, Loss: 0.052234464325010777, Final Batch Loss: 0.003567584790289402\n",
      "Epoch 3645, Loss: 0.03453408135101199, Final Batch Loss: 0.002290892880409956\n",
      "Epoch 3646, Loss: 0.0394377252086997, Final Batch Loss: 0.012978616170585155\n",
      "Epoch 3647, Loss: 0.019574263133108616, Final Batch Loss: 0.008764564990997314\n",
      "Epoch 3648, Loss: 0.04443074110895395, Final Batch Loss: 0.030155574902892113\n",
      "Epoch 3649, Loss: 0.02246176451444626, Final Batch Loss: 0.009310001507401466\n",
      "Epoch 3650, Loss: 0.05479871854186058, Final Batch Loss: 0.02097770944237709\n",
      "Epoch 3651, Loss: 0.05833389610052109, Final Batch Loss: 0.036386508494615555\n",
      "Epoch 3652, Loss: 0.02772931382060051, Final Batch Loss: 0.010509863495826721\n",
      "Epoch 3653, Loss: 0.040169380605220795, Final Batch Loss: 0.01524750143289566\n",
      "Epoch 3654, Loss: 0.033513124100863934, Final Batch Loss: 0.011159203015267849\n",
      "Epoch 3655, Loss: 0.045852480456233025, Final Batch Loss: 0.02022489905357361\n",
      "Epoch 3656, Loss: 0.031349544413387775, Final Batch Loss: 0.022888435050845146\n",
      "Epoch 3657, Loss: 0.043960072100162506, Final Batch Loss: 0.017485707998275757\n",
      "Epoch 3658, Loss: 0.0765802226960659, Final Batch Loss: 0.05397908762097359\n",
      "Epoch 3659, Loss: 0.07991117238998413, Final Batch Loss: 0.03174547106027603\n",
      "Epoch 3660, Loss: 0.022207470145076513, Final Batch Loss: 0.004214848857372999\n",
      "Epoch 3661, Loss: 0.10309384018182755, Final Batch Loss: 0.03659282624721527\n",
      "Epoch 3662, Loss: 0.04979921132326126, Final Batch Loss: 0.03159636631608009\n",
      "Epoch 3663, Loss: 0.05087481811642647, Final Batch Loss: 0.026721501722931862\n",
      "Epoch 3664, Loss: 0.04121486213989556, Final Batch Loss: 0.002371077658608556\n",
      "Epoch 3665, Loss: 0.07333590160124004, Final Batch Loss: 0.003327020211145282\n",
      "Epoch 3666, Loss: 0.045802026987075806, Final Batch Loss: 0.033821117132902145\n",
      "Epoch 3667, Loss: 0.0924772284924984, Final Batch Loss: 0.049973856657743454\n",
      "Epoch 3668, Loss: 0.04926203191280365, Final Batch Loss: 0.015010252594947815\n",
      "Epoch 3669, Loss: 0.03193112462759018, Final Batch Loss: 0.014879167079925537\n",
      "Epoch 3670, Loss: 0.05130147002637386, Final Batch Loss: 0.015286186710000038\n",
      "Epoch 3671, Loss: 0.11456121504306793, Final Batch Loss: 0.05974530801177025\n",
      "Epoch 3672, Loss: 0.08249988779425621, Final Batch Loss: 0.025305088609457016\n",
      "Epoch 3673, Loss: 0.03730478137731552, Final Batch Loss: 0.026036666706204414\n",
      "Epoch 3674, Loss: 0.04071834124624729, Final Batch Loss: 0.014212504029273987\n",
      "Epoch 3675, Loss: 0.040518052875995636, Final Batch Loss: 0.021920587867498398\n",
      "Epoch 3676, Loss: 0.05450152046978474, Final Batch Loss: 0.031453996896743774\n",
      "Epoch 3677, Loss: 0.058827364817261696, Final Batch Loss: 0.03705533221364021\n",
      "Epoch 3678, Loss: 0.06536571495234966, Final Batch Loss: 0.021885516121983528\n",
      "Epoch 3679, Loss: 0.03122283983975649, Final Batch Loss: 0.013472643680870533\n",
      "Epoch 3680, Loss: 0.07644882425665855, Final Batch Loss: 0.042031820863485336\n",
      "Epoch 3681, Loss: 0.07920552417635918, Final Batch Loss: 0.016970187425613403\n",
      "Epoch 3682, Loss: 0.044441547244787216, Final Batch Loss: 0.014320168644189835\n",
      "Epoch 3683, Loss: 0.0224705352447927, Final Batch Loss: 0.004258075263351202\n",
      "Epoch 3684, Loss: 0.09623999893665314, Final Batch Loss: 0.024758614599704742\n",
      "Epoch 3685, Loss: 0.09833622351288795, Final Batch Loss: 0.07429323345422745\n",
      "Epoch 3686, Loss: 0.07244513183832169, Final Batch Loss: 0.05380589887499809\n",
      "Epoch 3687, Loss: 0.05322798155248165, Final Batch Loss: 0.015475006774067879\n",
      "Epoch 3688, Loss: 0.07372731156647205, Final Batch Loss: 0.03055046685039997\n",
      "Epoch 3689, Loss: 0.10340152308344841, Final Batch Loss: 0.07522940635681152\n",
      "Epoch 3690, Loss: 0.05561298690736294, Final Batch Loss: 0.04857756197452545\n",
      "Epoch 3691, Loss: 0.06969190016388893, Final Batch Loss: 0.03412935882806778\n",
      "Epoch 3692, Loss: 0.04588613286614418, Final Batch Loss: 0.024321820586919785\n",
      "Epoch 3693, Loss: 0.05600794218480587, Final Batch Loss: 0.033476028591394424\n",
      "Epoch 3694, Loss: 0.053609587252140045, Final Batch Loss: 0.03342641517519951\n",
      "Epoch 3695, Loss: 0.05778196267783642, Final Batch Loss: 0.01811785064637661\n",
      "Epoch 3696, Loss: 0.018265796825289726, Final Batch Loss: 0.0044901734218001366\n",
      "Epoch 3697, Loss: 0.05183708667755127, Final Batch Loss: 0.03109016828238964\n",
      "Epoch 3698, Loss: 0.047970470041036606, Final Batch Loss: 0.023896072059869766\n",
      "Epoch 3699, Loss: 0.03047723975032568, Final Batch Loss: 0.017142778262495995\n",
      "Epoch 3700, Loss: 0.03186568943783641, Final Batch Loss: 0.004190798383206129\n",
      "Epoch 3701, Loss: 0.022145649418234825, Final Batch Loss: 0.009189006872475147\n",
      "Epoch 3702, Loss: 0.055074578151106834, Final Batch Loss: 0.02838376723229885\n",
      "Epoch 3703, Loss: 0.05140850134193897, Final Batch Loss: 0.014373855665326118\n",
      "Epoch 3704, Loss: 0.0831329058855772, Final Batch Loss: 0.018712935969233513\n",
      "Epoch 3705, Loss: 0.03715452644973993, Final Batch Loss: 0.0074722496792674065\n",
      "Epoch 3706, Loss: 0.04112129285931587, Final Batch Loss: 0.01702393963932991\n",
      "Epoch 3707, Loss: 0.1439579613506794, Final Batch Loss: 0.06098319962620735\n",
      "Epoch 3708, Loss: 0.03843798488378525, Final Batch Loss: 0.025545379146933556\n",
      "Epoch 3709, Loss: 0.062034059315919876, Final Batch Loss: 0.016483061015605927\n",
      "Epoch 3710, Loss: 0.057808300480246544, Final Batch Loss: 0.03855963051319122\n",
      "Epoch 3711, Loss: 0.08664806373417377, Final Batch Loss: 0.06897225230932236\n",
      "Epoch 3712, Loss: 0.060821701772511005, Final Batch Loss: 0.04557717591524124\n",
      "Epoch 3713, Loss: 0.06862034276127815, Final Batch Loss: 0.04251838102936745\n",
      "Epoch 3714, Loss: 0.06112603843212128, Final Batch Loss: 0.021524734795093536\n",
      "Epoch 3715, Loss: 0.14870554022490978, Final Batch Loss: 0.13283675909042358\n",
      "Epoch 3716, Loss: 0.05372995883226395, Final Batch Loss: 0.03158276155591011\n",
      "Epoch 3717, Loss: 0.045181660912930965, Final Batch Loss: 0.03570053353905678\n",
      "Epoch 3718, Loss: 0.049316367134451866, Final Batch Loss: 0.0318806953728199\n",
      "Epoch 3719, Loss: 0.04787740297615528, Final Batch Loss: 0.028890009969472885\n",
      "Epoch 3720, Loss: 0.03678016271442175, Final Batch Loss: 0.02139526791870594\n",
      "Epoch 3721, Loss: 0.09748011454939842, Final Batch Loss: 0.06517089903354645\n",
      "Epoch 3722, Loss: 0.07033011317253113, Final Batch Loss: 0.05717183277010918\n",
      "Epoch 3723, Loss: 0.14170407503843307, Final Batch Loss: 0.09043911099433899\n",
      "Epoch 3724, Loss: 0.09268343076109886, Final Batch Loss: 0.040313612669706345\n",
      "Epoch 3725, Loss: 0.06771347299218178, Final Batch Loss: 0.014054369181394577\n",
      "Epoch 3726, Loss: 0.0708591528236866, Final Batch Loss: 0.017668113112449646\n",
      "Epoch 3727, Loss: 0.03356469329446554, Final Batch Loss: 0.012282724492251873\n",
      "Epoch 3728, Loss: 0.033326076809316874, Final Batch Loss: 0.005054666195064783\n",
      "Epoch 3729, Loss: 0.07922366634011269, Final Batch Loss: 0.018553730100393295\n",
      "Epoch 3730, Loss: 0.055603223852813244, Final Batch Loss: 0.041894204914569855\n",
      "Epoch 3731, Loss: 0.0984086561948061, Final Batch Loss: 0.020583027973771095\n",
      "Epoch 3732, Loss: 0.0801105760037899, Final Batch Loss: 0.048219792544841766\n",
      "Epoch 3733, Loss: 0.07830459624528885, Final Batch Loss: 0.05540281906723976\n",
      "Epoch 3734, Loss: 0.04789928253740072, Final Batch Loss: 0.008500388823449612\n",
      "Epoch 3735, Loss: 0.052464064210653305, Final Batch Loss: 0.010460995137691498\n",
      "Epoch 3736, Loss: 0.038112347945570946, Final Batch Loss: 0.0132595244795084\n",
      "Epoch 3737, Loss: 0.037999581545591354, Final Batch Loss: 0.025227218866348267\n",
      "Epoch 3738, Loss: 0.05068153142929077, Final Batch Loss: 0.018266256898641586\n",
      "Epoch 3739, Loss: 0.022259418852627277, Final Batch Loss: 0.011383171193301678\n",
      "Epoch 3740, Loss: 0.07220638543367386, Final Batch Loss: 0.033276092261075974\n",
      "Epoch 3741, Loss: 0.09474772959947586, Final Batch Loss: 0.05431924760341644\n",
      "Epoch 3742, Loss: 0.024655761197209358, Final Batch Loss: 0.00644729845225811\n",
      "Epoch 3743, Loss: 0.02189397206529975, Final Batch Loss: 0.007794931065291166\n",
      "Epoch 3744, Loss: 0.04111473076045513, Final Batch Loss: 0.024056315422058105\n",
      "Epoch 3745, Loss: 0.09821858443319798, Final Batch Loss: 0.0780082494020462\n",
      "Epoch 3746, Loss: 0.0707942470908165, Final Batch Loss: 0.04951949045062065\n",
      "Epoch 3747, Loss: 0.05098315421491861, Final Batch Loss: 0.013251886703073978\n",
      "Epoch 3748, Loss: 0.06654972583055496, Final Batch Loss: 0.054246678948402405\n",
      "Epoch 3749, Loss: 0.054112949408590794, Final Batch Loss: 0.011536856181919575\n",
      "Epoch 3750, Loss: 0.05458723474293947, Final Batch Loss: 0.00995516125112772\n",
      "Epoch 3751, Loss: 0.06072811782360077, Final Batch Loss: 0.03609853237867355\n",
      "Epoch 3752, Loss: 0.05845014564692974, Final Batch Loss: 0.03771619126200676\n",
      "Epoch 3753, Loss: 0.02950501162558794, Final Batch Loss: 0.009318466298282146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3754, Loss: 0.05075506027787924, Final Batch Loss: 0.043916068971157074\n",
      "Epoch 3755, Loss: 0.10394537635147572, Final Batch Loss: 0.08679123222827911\n",
      "Epoch 3756, Loss: 0.044343724846839905, Final Batch Loss: 0.00966113805770874\n",
      "Epoch 3757, Loss: 0.049278950318694115, Final Batch Loss: 0.022007426247000694\n",
      "Epoch 3758, Loss: 0.04184645041823387, Final Batch Loss: 0.016232090070843697\n",
      "Epoch 3759, Loss: 0.05052998661994934, Final Batch Loss: 0.016110744327306747\n",
      "Epoch 3760, Loss: 0.04076269455254078, Final Batch Loss: 0.012467775493860245\n",
      "Epoch 3761, Loss: 0.04977399483323097, Final Batch Loss: 0.0122453011572361\n",
      "Epoch 3762, Loss: 0.03170241368934512, Final Batch Loss: 0.006569467019289732\n",
      "Epoch 3763, Loss: 0.06113127991557121, Final Batch Loss: 0.0267934612929821\n",
      "Epoch 3764, Loss: 0.027501223608851433, Final Batch Loss: 0.0049283187836408615\n",
      "Epoch 3765, Loss: 0.039755482226610184, Final Batch Loss: 0.018508872017264366\n",
      "Epoch 3766, Loss: 0.036899430211633444, Final Batch Loss: 0.006395637523382902\n",
      "Epoch 3767, Loss: 0.05872366391122341, Final Batch Loss: 0.037973787635564804\n",
      "Epoch 3768, Loss: 0.04863831400871277, Final Batch Loss: 0.014093991369009018\n",
      "Epoch 3769, Loss: 0.05930761434137821, Final Batch Loss: 0.03187452629208565\n",
      "Epoch 3770, Loss: 0.03685540985316038, Final Batch Loss: 0.013455872423946857\n",
      "Epoch 3771, Loss: 0.05085893161594868, Final Batch Loss: 0.0256480872631073\n",
      "Epoch 3772, Loss: 0.08968047052621841, Final Batch Loss: 0.04771355912089348\n",
      "Epoch 3773, Loss: 0.025999734178185463, Final Batch Loss: 0.008776310831308365\n",
      "Epoch 3774, Loss: 0.04728208668529987, Final Batch Loss: 0.02321540378034115\n",
      "Epoch 3775, Loss: 0.04153561778366566, Final Batch Loss: 0.024965930730104446\n",
      "Epoch 3776, Loss: 0.07137568481266499, Final Batch Loss: 0.029242118820548058\n",
      "Epoch 3777, Loss: 0.04627622105181217, Final Batch Loss: 0.0202386025339365\n",
      "Epoch 3778, Loss: 0.05204186122864485, Final Batch Loss: 0.009387842379510403\n",
      "Epoch 3779, Loss: 0.028461549431085587, Final Batch Loss: 0.010017931461334229\n",
      "Epoch 3780, Loss: 0.02545769838616252, Final Batch Loss: 0.0051369923166930676\n",
      "Epoch 3781, Loss: 0.09013964980840683, Final Batch Loss: 0.05652575567364693\n",
      "Epoch 3782, Loss: 0.04529980383813381, Final Batch Loss: 0.0241677388548851\n",
      "Epoch 3783, Loss: 0.0585293248295784, Final Batch Loss: 0.034927770495414734\n",
      "Epoch 3784, Loss: 0.07587811164557934, Final Batch Loss: 0.056467581540346146\n",
      "Epoch 3785, Loss: 0.0275931004434824, Final Batch Loss: 0.01124025322496891\n",
      "Epoch 3786, Loss: 0.04606745857745409, Final Batch Loss: 0.011401955969631672\n",
      "Epoch 3787, Loss: 0.046429919078946114, Final Batch Loss: 0.011293375864624977\n",
      "Epoch 3788, Loss: 0.16571990121155977, Final Batch Loss: 0.014054601080715656\n",
      "Epoch 3789, Loss: 0.04950793460011482, Final Batch Loss: 0.028032638132572174\n",
      "Epoch 3790, Loss: 0.08424117043614388, Final Batch Loss: 0.024861108511686325\n",
      "Epoch 3791, Loss: 0.08943444490432739, Final Batch Loss: 0.04931981861591339\n",
      "Epoch 3792, Loss: 0.03376874607056379, Final Batch Loss: 0.015236997045576572\n",
      "Epoch 3793, Loss: 0.04479760676622391, Final Batch Loss: 0.02871732786297798\n",
      "Epoch 3794, Loss: 0.07557690888643265, Final Batch Loss: 0.024848729372024536\n",
      "Epoch 3795, Loss: 0.05166418105363846, Final Batch Loss: 0.032154034823179245\n",
      "Epoch 3796, Loss: 0.06804628018289804, Final Batch Loss: 0.060856059193611145\n",
      "Epoch 3797, Loss: 0.07078288681805134, Final Batch Loss: 0.02308580093085766\n",
      "Epoch 3798, Loss: 0.0135716930963099, Final Batch Loss: 0.006058496423065662\n",
      "Epoch 3799, Loss: 0.06918022781610489, Final Batch Loss: 0.04142101854085922\n",
      "Epoch 3800, Loss: 0.05430249497294426, Final Batch Loss: 0.03987159579992294\n",
      "Epoch 3801, Loss: 0.06297224387526512, Final Batch Loss: 0.010468363761901855\n",
      "Epoch 3802, Loss: 0.020049366168677807, Final Batch Loss: 0.01068293396383524\n",
      "Epoch 3803, Loss: 0.04106064606457949, Final Batch Loss: 0.008497861213982105\n",
      "Epoch 3804, Loss: 0.07801634445786476, Final Batch Loss: 0.04440246522426605\n",
      "Epoch 3805, Loss: 0.03783850045874715, Final Batch Loss: 0.005987462121993303\n",
      "Epoch 3806, Loss: 0.0539594404399395, Final Batch Loss: 0.022817518562078476\n",
      "Epoch 3807, Loss: 0.03482069168239832, Final Batch Loss: 0.022541921585798264\n",
      "Epoch 3808, Loss: 0.1113320142030716, Final Batch Loss: 0.08658529818058014\n",
      "Epoch 3809, Loss: 0.1157142836600542, Final Batch Loss: 0.08802410215139389\n",
      "Epoch 3810, Loss: 0.017673788592219353, Final Batch Loss: 0.009343001060187817\n",
      "Epoch 3811, Loss: 0.04328744672238827, Final Batch Loss: 0.02378353849053383\n",
      "Epoch 3812, Loss: 0.03278497699648142, Final Batch Loss: 0.02279139868915081\n",
      "Epoch 3813, Loss: 0.10421856492757797, Final Batch Loss: 0.053273774683475494\n",
      "Epoch 3814, Loss: 0.15254176408052444, Final Batch Loss: 0.08618660271167755\n",
      "Epoch 3815, Loss: 0.04088958539068699, Final Batch Loss: 0.02023538015782833\n",
      "Epoch 3816, Loss: 0.18683920800685883, Final Batch Loss: 0.08842754364013672\n",
      "Epoch 3817, Loss: 0.10245505347847939, Final Batch Loss: 0.051144327968358994\n",
      "Epoch 3818, Loss: 0.07512281090021133, Final Batch Loss: 0.03600034490227699\n",
      "Epoch 3819, Loss: 0.1605052351951599, Final Batch Loss: 0.07617329061031342\n",
      "Epoch 3820, Loss: 0.049898398108780384, Final Batch Loss: 0.01524998340755701\n",
      "Epoch 3821, Loss: 0.08419692888855934, Final Batch Loss: 0.03556831181049347\n",
      "Epoch 3822, Loss: 0.11277042515575886, Final Batch Loss: 0.08456241339445114\n",
      "Epoch 3823, Loss: 0.06759194657206535, Final Batch Loss: 0.023066289722919464\n",
      "Epoch 3824, Loss: 0.10681658796966076, Final Batch Loss: 0.030291756615042686\n",
      "Epoch 3825, Loss: 0.07665203139185905, Final Batch Loss: 0.032056841999292374\n",
      "Epoch 3826, Loss: 0.07256887201219797, Final Batch Loss: 0.06091056764125824\n",
      "Epoch 3827, Loss: 0.05860393866896629, Final Batch Loss: 0.027666231617331505\n",
      "Epoch 3828, Loss: 0.10450418293476105, Final Batch Loss: 0.06140420213341713\n",
      "Epoch 3829, Loss: 0.05431763827800751, Final Batch Loss: 0.008572984486818314\n",
      "Epoch 3830, Loss: 0.0629772013053298, Final Batch Loss: 0.05348588526248932\n",
      "Epoch 3831, Loss: 0.09086910262703896, Final Batch Loss: 0.04698791727423668\n",
      "Epoch 3832, Loss: 0.025737222284078598, Final Batch Loss: 0.013561216183006763\n",
      "Epoch 3833, Loss: 0.03255596198141575, Final Batch Loss: 0.020690683275461197\n",
      "Epoch 3834, Loss: 0.16124478355050087, Final Batch Loss: 0.12325498461723328\n",
      "Epoch 3835, Loss: 0.07632840797305107, Final Batch Loss: 0.02586052566766739\n",
      "Epoch 3836, Loss: 0.09870423749089241, Final Batch Loss: 0.06360922008752823\n",
      "Epoch 3837, Loss: 0.27978796511888504, Final Batch Loss: 0.17760302126407623\n",
      "Epoch 3838, Loss: 0.1145177036523819, Final Batch Loss: 0.03911958634853363\n",
      "Epoch 3839, Loss: 0.13997019082307816, Final Batch Loss: 0.033193230628967285\n",
      "Epoch 3840, Loss: 0.17718027532100677, Final Batch Loss: 0.13551989197731018\n",
      "Epoch 3841, Loss: 0.10884302854537964, Final Batch Loss: 0.049437180161476135\n",
      "Epoch 3842, Loss: 0.09091819822788239, Final Batch Loss: 0.04314389079809189\n",
      "Epoch 3843, Loss: 0.058721451088786125, Final Batch Loss: 0.036695148795843124\n",
      "Epoch 3844, Loss: 0.05411765049211681, Final Batch Loss: 0.0025095909368246794\n",
      "Epoch 3845, Loss: 0.08842695131897926, Final Batch Loss: 0.0332673117518425\n",
      "Epoch 3846, Loss: 0.03696704562753439, Final Batch Loss: 0.011083590798079967\n",
      "Epoch 3847, Loss: 0.12011398747563362, Final Batch Loss: 0.08374931663274765\n",
      "Epoch 3848, Loss: 0.05531292222440243, Final Batch Loss: 0.01660110242664814\n",
      "Epoch 3849, Loss: 0.09525319933891296, Final Batch Loss: 0.0530862919986248\n",
      "Epoch 3850, Loss: 0.07618704438209534, Final Batch Loss: 0.04972752928733826\n",
      "Epoch 3851, Loss: 0.06247488409280777, Final Batch Loss: 0.0249023400247097\n",
      "Epoch 3852, Loss: 0.055631959810853004, Final Batch Loss: 0.024195609614253044\n",
      "Epoch 3853, Loss: 0.06197292264550924, Final Batch Loss: 0.015427201054990292\n",
      "Epoch 3854, Loss: 0.09676815941929817, Final Batch Loss: 0.049425989389419556\n",
      "Epoch 3855, Loss: 0.06796785071492195, Final Batch Loss: 0.05130339041352272\n",
      "Epoch 3856, Loss: 0.04237397760152817, Final Batch Loss: 0.024347927421331406\n",
      "Epoch 3857, Loss: 0.08037186041474342, Final Batch Loss: 0.02739519625902176\n",
      "Epoch 3858, Loss: 0.11456418037414551, Final Batch Loss: 0.053102120757102966\n",
      "Epoch 3859, Loss: 0.13528332114219666, Final Batch Loss: 0.06615198403596878\n",
      "Epoch 3860, Loss: 0.11044074222445488, Final Batch Loss: 0.04278576001524925\n",
      "Epoch 3861, Loss: 0.0921064019203186, Final Batch Loss: 0.05493906885385513\n",
      "Epoch 3862, Loss: 0.058516040444374084, Final Batch Loss: 0.04048602655529976\n",
      "Epoch 3863, Loss: 0.15593339875340462, Final Batch Loss: 0.13901934027671814\n",
      "Epoch 3864, Loss: 0.05196883901953697, Final Batch Loss: 0.02940318174660206\n",
      "Epoch 3865, Loss: 0.07486683130264282, Final Batch Loss: 0.032461218535900116\n",
      "Epoch 3866, Loss: 0.08159234933555126, Final Batch Loss: 0.028133532032370567\n",
      "Epoch 3867, Loss: 0.043792568147182465, Final Batch Loss: 0.030082393437623978\n",
      "Epoch 3868, Loss: 0.1120198629796505, Final Batch Loss: 0.06182447820901871\n",
      "Epoch 3869, Loss: 0.06623325869441032, Final Batch Loss: 0.03608695790171623\n",
      "Epoch 3870, Loss: 0.16189438849687576, Final Batch Loss: 0.025329865515232086\n",
      "Epoch 3871, Loss: 0.1251465231180191, Final Batch Loss: 0.09383280575275421\n",
      "Epoch 3872, Loss: 0.12817516550421715, Final Batch Loss: 0.05208824202418327\n",
      "Epoch 3873, Loss: 0.14513564109802246, Final Batch Loss: 0.11577039211988449\n",
      "Epoch 3874, Loss: 0.0947475116699934, Final Batch Loss: 0.016724271699786186\n",
      "Epoch 3875, Loss: 0.19977287203073502, Final Batch Loss: 0.10435230284929276\n",
      "Epoch 3876, Loss: 0.08500738255679607, Final Batch Loss: 0.02700570784509182\n",
      "Epoch 3877, Loss: 0.14753605425357819, Final Batch Loss: 0.08197285979986191\n",
      "Epoch 3878, Loss: 0.08541178144514561, Final Batch Loss: 0.06396399438381195\n",
      "Epoch 3879, Loss: 0.12754325196146965, Final Batch Loss: 0.04217943176627159\n",
      "Epoch 3880, Loss: 0.0660405308008194, Final Batch Loss: 0.032478466629981995\n",
      "Epoch 3881, Loss: 0.04037090390920639, Final Batch Loss: 0.010028300806879997\n",
      "Epoch 3882, Loss: 0.040550779551267624, Final Batch Loss: 0.024012399837374687\n",
      "Epoch 3883, Loss: 0.086589515209198, Final Batch Loss: 0.04345792159438133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3884, Loss: 0.11227886006236076, Final Batch Loss: 0.06604825705289841\n",
      "Epoch 3885, Loss: 0.05870147794485092, Final Batch Loss: 0.013259734958410263\n",
      "Epoch 3886, Loss: 0.08453100733458996, Final Batch Loss: 0.02498774044215679\n",
      "Epoch 3887, Loss: 0.05171234346926212, Final Batch Loss: 0.026856934651732445\n",
      "Epoch 3888, Loss: 0.10090659186244011, Final Batch Loss: 0.06368140131235123\n",
      "Epoch 3889, Loss: 0.022475129924714565, Final Batch Loss: 0.007979163900017738\n",
      "Epoch 3890, Loss: 0.06251334585249424, Final Batch Loss: 0.046546224504709244\n",
      "Epoch 3891, Loss: 0.04610641673207283, Final Batch Loss: 0.011750448495149612\n",
      "Epoch 3892, Loss: 0.10816072579473257, Final Batch Loss: 0.007945305667817593\n",
      "Epoch 3893, Loss: 0.04051702283322811, Final Batch Loss: 0.01983785256743431\n",
      "Epoch 3894, Loss: 0.12903983145952225, Final Batch Loss: 0.03199275583028793\n",
      "Epoch 3895, Loss: 0.055982592049986124, Final Batch Loss: 0.005814346019178629\n",
      "Epoch 3896, Loss: 0.14160773903131485, Final Batch Loss: 0.08497752249240875\n",
      "Epoch 3897, Loss: 0.05218309536576271, Final Batch Loss: 0.029253674671053886\n",
      "Epoch 3898, Loss: 0.01961308903992176, Final Batch Loss: 0.006452593952417374\n",
      "Epoch 3899, Loss: 0.0384388267993927, Final Batch Loss: 0.02296089567244053\n",
      "Epoch 3900, Loss: 0.0688661951571703, Final Batch Loss: 0.01589115522801876\n",
      "Epoch 3901, Loss: 0.09615284949541092, Final Batch Loss: 0.05267561972141266\n",
      "Epoch 3902, Loss: 0.03787749167531729, Final Batch Loss: 0.012993116863071918\n",
      "Epoch 3903, Loss: 0.06179138459265232, Final Batch Loss: 0.02914874441921711\n",
      "Epoch 3904, Loss: 0.015397308394312859, Final Batch Loss: 0.006980760022997856\n",
      "Epoch 3905, Loss: 0.04005621559917927, Final Batch Loss: 0.014175737276673317\n",
      "Epoch 3906, Loss: 0.07351585105061531, Final Batch Loss: 0.010393921285867691\n",
      "Epoch 3907, Loss: 0.05932195484638214, Final Batch Loss: 0.032365866005420685\n",
      "Epoch 3908, Loss: 0.05409995373338461, Final Batch Loss: 0.04439927265048027\n",
      "Epoch 3909, Loss: 0.05168411508202553, Final Batch Loss: 0.022882604971528053\n",
      "Epoch 3910, Loss: 0.0688120387494564, Final Batch Loss: 0.03217395767569542\n",
      "Epoch 3911, Loss: 0.06797563470900059, Final Batch Loss: 0.037294164299964905\n",
      "Epoch 3912, Loss: 0.07003013975918293, Final Batch Loss: 0.04681015759706497\n",
      "Epoch 3913, Loss: 0.0417470159009099, Final Batch Loss: 0.03146227076649666\n",
      "Epoch 3914, Loss: 0.09569152444601059, Final Batch Loss: 0.07810552418231964\n",
      "Epoch 3915, Loss: 0.03368321107700467, Final Batch Loss: 0.026931339874863625\n",
      "Epoch 3916, Loss: 0.06156777776777744, Final Batch Loss: 0.026703571900725365\n",
      "Epoch 3917, Loss: 0.06420564092695713, Final Batch Loss: 0.042707718908786774\n",
      "Epoch 3918, Loss: 0.07162874937057495, Final Batch Loss: 0.03272978216409683\n",
      "Epoch 3919, Loss: 0.0747379157692194, Final Batch Loss: 0.030874958261847496\n",
      "Epoch 3920, Loss: 0.07208590768277645, Final Batch Loss: 0.051308248192071915\n",
      "Epoch 3921, Loss: 0.058369170874357224, Final Batch Loss: 0.0288817398250103\n",
      "Epoch 3922, Loss: 0.10507459193468094, Final Batch Loss: 0.055457744747400284\n",
      "Epoch 3923, Loss: 0.03941278997808695, Final Batch Loss: 0.010550645180046558\n",
      "Epoch 3924, Loss: 0.07808070443570614, Final Batch Loss: 0.051647964864969254\n",
      "Epoch 3925, Loss: 0.03191677434369922, Final Batch Loss: 0.0071164402179419994\n",
      "Epoch 3926, Loss: 0.03445560857653618, Final Batch Loss: 0.017306752502918243\n",
      "Epoch 3927, Loss: 0.032782094553112984, Final Batch Loss: 0.02210358716547489\n",
      "Epoch 3928, Loss: 0.08033429086208344, Final Batch Loss: 0.03238154202699661\n",
      "Epoch 3929, Loss: 0.04181122966110706, Final Batch Loss: 0.019961806014180183\n",
      "Epoch 3930, Loss: 0.04759468510746956, Final Batch Loss: 0.039665136486291885\n",
      "Epoch 3931, Loss: 0.042236894369125366, Final Batch Loss: 0.022551339119672775\n",
      "Epoch 3932, Loss: 0.07006409764289856, Final Batch Loss: 0.05214571952819824\n",
      "Epoch 3933, Loss: 0.09157205373048782, Final Batch Loss: 0.0509217195212841\n",
      "Epoch 3934, Loss: 0.07911674678325653, Final Batch Loss: 0.03267265856266022\n",
      "Epoch 3935, Loss: 0.11857992224395275, Final Batch Loss: 0.10347552597522736\n",
      "Epoch 3936, Loss: 0.02694285288453102, Final Batch Loss: 0.008221928030252457\n",
      "Epoch 3937, Loss: 0.09059890918433666, Final Batch Loss: 0.06357655674219131\n",
      "Epoch 3938, Loss: 0.03501843474805355, Final Batch Loss: 0.01755235530436039\n",
      "Epoch 3939, Loss: 0.11169994994997978, Final Batch Loss: 0.05382620543241501\n",
      "Epoch 3940, Loss: 0.06505664624273777, Final Batch Loss: 0.027038196101784706\n",
      "Epoch 3941, Loss: 0.07686791568994522, Final Batch Loss: 0.030728697776794434\n",
      "Epoch 3942, Loss: 0.06657532416284084, Final Batch Loss: 0.03714519366621971\n",
      "Epoch 3943, Loss: 0.020007358863949776, Final Batch Loss: 0.007249324582517147\n",
      "Epoch 3944, Loss: 0.053195102140307426, Final Batch Loss: 0.013149833306670189\n",
      "Epoch 3945, Loss: 0.046199167147278786, Final Batch Loss: 0.027194954454898834\n",
      "Epoch 3946, Loss: 0.08495188876986504, Final Batch Loss: 0.05789573863148689\n",
      "Epoch 3947, Loss: 0.054374461993575096, Final Batch Loss: 0.024105342105031013\n",
      "Epoch 3948, Loss: 0.09010790288448334, Final Batch Loss: 0.028881486505270004\n",
      "Epoch 3949, Loss: 0.0474961269646883, Final Batch Loss: 0.02588588371872902\n",
      "Epoch 3950, Loss: 0.0794958546757698, Final Batch Loss: 0.062370892614126205\n",
      "Epoch 3951, Loss: 0.05188760161399841, Final Batch Loss: 0.023907272145152092\n",
      "Epoch 3952, Loss: 0.10426515340805054, Final Batch Loss: 0.04991281032562256\n",
      "Epoch 3953, Loss: 0.0439321706071496, Final Batch Loss: 0.02905345894396305\n",
      "Epoch 3954, Loss: 0.016940077301114798, Final Batch Loss: 0.002706411760300398\n",
      "Epoch 3955, Loss: 0.06192485988140106, Final Batch Loss: 0.024695269763469696\n",
      "Epoch 3956, Loss: 0.052575767040252686, Final Batch Loss: 0.01806856319308281\n",
      "Epoch 3957, Loss: 0.056395117193460464, Final Batch Loss: 0.03965430334210396\n",
      "Epoch 3958, Loss: 0.029559600166976452, Final Batch Loss: 0.014848620630800724\n",
      "Epoch 3959, Loss: 0.03254326619207859, Final Batch Loss: 0.010806240141391754\n",
      "Epoch 3960, Loss: 0.04842871055006981, Final Batch Loss: 0.023075168952345848\n",
      "Epoch 3961, Loss: 0.04820525739341974, Final Batch Loss: 0.034512199461460114\n",
      "Epoch 3962, Loss: 0.06718143820762634, Final Batch Loss: 0.014327708631753922\n",
      "Epoch 3963, Loss: 0.05300098843872547, Final Batch Loss: 0.02430935762822628\n",
      "Epoch 3964, Loss: 0.05664594657719135, Final Batch Loss: 0.017128078266978264\n",
      "Epoch 3965, Loss: 0.036476143170148134, Final Batch Loss: 0.005393458995968103\n",
      "Epoch 3966, Loss: 0.08171318843960762, Final Batch Loss: 0.05030852556228638\n",
      "Epoch 3967, Loss: 0.03643241245299578, Final Batch Loss: 0.014737485907971859\n",
      "Epoch 3968, Loss: 0.03139772545546293, Final Batch Loss: 0.01182395126670599\n",
      "Epoch 3969, Loss: 0.057044245302677155, Final Batch Loss: 0.03058057650923729\n",
      "Epoch 3970, Loss: 0.06714498996734619, Final Batch Loss: 0.029855147004127502\n",
      "Epoch 3971, Loss: 0.06460015382617712, Final Batch Loss: 0.05508369207382202\n",
      "Epoch 3972, Loss: 0.07656240370124578, Final Batch Loss: 0.010248436592519283\n",
      "Epoch 3973, Loss: 0.0686650425195694, Final Batch Loss: 0.031752873212099075\n",
      "Epoch 3974, Loss: 0.09978047758340836, Final Batch Loss: 0.06827246397733688\n",
      "Epoch 3975, Loss: 0.09327801316976547, Final Batch Loss: 0.04370682314038277\n",
      "Epoch 3976, Loss: 0.05701622739434242, Final Batch Loss: 0.03169484809041023\n",
      "Epoch 3977, Loss: 0.04500526748597622, Final Batch Loss: 0.013125447556376457\n",
      "Epoch 3978, Loss: 0.058484675362706184, Final Batch Loss: 0.021363062784075737\n",
      "Epoch 3979, Loss: 0.08157651871442795, Final Batch Loss: 0.039881572127342224\n",
      "Epoch 3980, Loss: 0.033388989977538586, Final Batch Loss: 0.009294182993471622\n",
      "Epoch 3981, Loss: 0.04267565906047821, Final Batch Loss: 0.025725869461894035\n",
      "Epoch 3982, Loss: 0.07204944919794798, Final Batch Loss: 0.011870021931827068\n",
      "Epoch 3983, Loss: 0.06612365134060383, Final Batch Loss: 0.03598914295434952\n",
      "Epoch 3984, Loss: 0.045109763741493225, Final Batch Loss: 0.019232990220189095\n",
      "Epoch 3985, Loss: 0.08694622293114662, Final Batch Loss: 0.03223586082458496\n",
      "Epoch 3986, Loss: 0.06865078769624233, Final Batch Loss: 0.045635975897312164\n",
      "Epoch 3987, Loss: 0.0634845606982708, Final Batch Loss: 0.033174075186252594\n",
      "Epoch 3988, Loss: 0.04594707675278187, Final Batch Loss: 0.016360685229301453\n",
      "Epoch 3989, Loss: 0.025531557388603687, Final Batch Loss: 0.010120714083313942\n",
      "Epoch 3990, Loss: 0.07721291482448578, Final Batch Loss: 0.03959816321730614\n",
      "Epoch 3991, Loss: 0.048218417912721634, Final Batch Loss: 0.028217779472470284\n",
      "Epoch 3992, Loss: 0.0768562126904726, Final Batch Loss: 0.025314627215266228\n",
      "Epoch 3993, Loss: 0.03469220642000437, Final Batch Loss: 0.015609941445291042\n",
      "Epoch 3994, Loss: 0.058847587555646896, Final Batch Loss: 0.02819155715405941\n",
      "Epoch 3995, Loss: 0.04352577030658722, Final Batch Loss: 0.018102705478668213\n",
      "Epoch 3996, Loss: 0.03938216436654329, Final Batch Loss: 0.008642255328595638\n",
      "Epoch 3997, Loss: 0.09376271441578865, Final Batch Loss: 0.04011320695281029\n",
      "Epoch 3998, Loss: 0.07886152528226376, Final Batch Loss: 0.026082580909132957\n",
      "Epoch 3999, Loss: 0.05618451628834009, Final Batch Loss: 0.04238699749112129\n",
      "Epoch 4000, Loss: 0.055087022483348846, Final Batch Loss: 0.0394226536154747\n",
      "Epoch 4001, Loss: 0.0934797003865242, Final Batch Loss: 0.03957134857773781\n",
      "Epoch 4002, Loss: 0.04982484504580498, Final Batch Loss: 0.0056968554854393005\n",
      "Epoch 4003, Loss: 0.10379978641867638, Final Batch Loss: 0.04944603890180588\n",
      "Epoch 4004, Loss: 0.01815339783206582, Final Batch Loss: 0.0061188447289168835\n",
      "Epoch 4005, Loss: 0.031410411931574345, Final Batch Loss: 0.024655062705278397\n",
      "Epoch 4006, Loss: 0.03941322024911642, Final Batch Loss: 0.010138674639165401\n",
      "Epoch 4007, Loss: 0.08513783849775791, Final Batch Loss: 0.023652000352740288\n",
      "Epoch 4008, Loss: 0.15591174364089966, Final Batch Loss: 0.08087757974863052\n",
      "Epoch 4009, Loss: 0.03657222539186478, Final Batch Loss: 0.010814644396305084\n",
      "Epoch 4010, Loss: 0.08868156373500824, Final Batch Loss: 0.05666163191199303\n",
      "Epoch 4011, Loss: 0.050647612661123276, Final Batch Loss: 0.033035192638635635\n",
      "Epoch 4012, Loss: 0.07728921622037888, Final Batch Loss: 0.028282735496759415\n",
      "Epoch 4013, Loss: 0.0896487832069397, Final Batch Loss: 0.06599456816911697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4014, Loss: 0.046246305108070374, Final Batch Loss: 0.030178602784872055\n",
      "Epoch 4015, Loss: 0.0519641637802124, Final Batch Loss: 0.0359332412481308\n",
      "Epoch 4016, Loss: 0.060157932341098785, Final Batch Loss: 0.021931342780590057\n",
      "Epoch 4017, Loss: 0.11226920038461685, Final Batch Loss: 0.08026143163442612\n",
      "Epoch 4018, Loss: 0.05462847091257572, Final Batch Loss: 0.0373530276119709\n",
      "Epoch 4019, Loss: 0.09558839723467827, Final Batch Loss: 0.03870217874646187\n",
      "Epoch 4020, Loss: 0.1136714443564415, Final Batch Loss: 0.0956282988190651\n",
      "Epoch 4021, Loss: 0.08061198145151138, Final Batch Loss: 0.035694681107997894\n",
      "Epoch 4022, Loss: 0.04134941101074219, Final Batch Loss: 0.01040562428534031\n",
      "Epoch 4023, Loss: 0.052825430408120155, Final Batch Loss: 0.024364816024899483\n",
      "Epoch 4024, Loss: 0.0526135116815567, Final Batch Loss: 0.02289394848048687\n",
      "Epoch 4025, Loss: 0.08566303923726082, Final Batch Loss: 0.05466654151678085\n",
      "Epoch 4026, Loss: 0.053412603214383125, Final Batch Loss: 0.02760683372616768\n",
      "Epoch 4027, Loss: 0.04744602181017399, Final Batch Loss: 0.02304885908961296\n",
      "Epoch 4028, Loss: 0.05303668975830078, Final Batch Loss: 0.022098565474152565\n",
      "Epoch 4029, Loss: 0.04102198965847492, Final Batch Loss: 0.021598679944872856\n",
      "Epoch 4030, Loss: 0.046765733510255814, Final Batch Loss: 0.0298426803201437\n",
      "Epoch 4031, Loss: 0.05922698229551315, Final Batch Loss: 0.025650646537542343\n",
      "Epoch 4032, Loss: 0.04919983074069023, Final Batch Loss: 0.017250802367925644\n",
      "Epoch 4033, Loss: 0.06356391869485378, Final Batch Loss: 0.021731583401560783\n",
      "Epoch 4034, Loss: 0.06506595015525818, Final Batch Loss: 0.03314004838466644\n",
      "Epoch 4035, Loss: 0.040911316871643066, Final Batch Loss: 0.034233856946229935\n",
      "Epoch 4036, Loss: 0.05866623669862747, Final Batch Loss: 0.03962027281522751\n",
      "Epoch 4037, Loss: 0.12797120586037636, Final Batch Loss: 0.0783889889717102\n",
      "Epoch 4038, Loss: 0.07025018520653248, Final Batch Loss: 0.020365262404084206\n",
      "Epoch 4039, Loss: 0.05202656798064709, Final Batch Loss: 0.03722501918673515\n",
      "Epoch 4040, Loss: 0.05217702779918909, Final Batch Loss: 0.013723180629312992\n",
      "Epoch 4041, Loss: 0.13677562400698662, Final Batch Loss: 0.09946537017822266\n",
      "Epoch 4042, Loss: 0.056399524211883545, Final Batch Loss: 0.017412453889846802\n",
      "Epoch 4043, Loss: 0.0974028930068016, Final Batch Loss: 0.046981267631053925\n",
      "Epoch 4044, Loss: 0.06273231841623783, Final Batch Loss: 0.004779567942023277\n",
      "Epoch 4045, Loss: 0.047091612592339516, Final Batch Loss: 0.01528359018266201\n",
      "Epoch 4046, Loss: 0.08735836669802666, Final Batch Loss: 0.05571680888533592\n",
      "Epoch 4047, Loss: 0.09012334793806076, Final Batch Loss: 0.07115904241800308\n",
      "Epoch 4048, Loss: 0.06697183474898338, Final Batch Loss: 0.055428992956876755\n",
      "Epoch 4049, Loss: 0.085037961602211, Final Batch Loss: 0.02729281410574913\n",
      "Epoch 4050, Loss: 0.048585555516183376, Final Batch Loss: 0.03409139811992645\n",
      "Epoch 4051, Loss: 0.06310736574232578, Final Batch Loss: 0.02982190065085888\n",
      "Epoch 4052, Loss: 0.07015928998589516, Final Batch Loss: 0.032916150987148285\n",
      "Epoch 4053, Loss: 0.03887373488396406, Final Batch Loss: 0.015239152126014233\n",
      "Epoch 4054, Loss: 0.04300004243850708, Final Batch Loss: 0.015785831958055496\n",
      "Epoch 4055, Loss: 0.051920680329203606, Final Batch Loss: 0.015326255932450294\n",
      "Epoch 4056, Loss: 0.07664976455271244, Final Batch Loss: 0.04971236735582352\n",
      "Epoch 4057, Loss: 0.07596384733915329, Final Batch Loss: 0.04709123075008392\n",
      "Epoch 4058, Loss: 0.07982615567743778, Final Batch Loss: 0.05823474004864693\n",
      "Epoch 4059, Loss: 0.05424779839813709, Final Batch Loss: 0.017139723524451256\n",
      "Epoch 4060, Loss: 0.0509724672883749, Final Batch Loss: 0.029470356181263924\n",
      "Epoch 4061, Loss: 0.1034419871866703, Final Batch Loss: 0.07348306477069855\n",
      "Epoch 4062, Loss: 0.06657202169299126, Final Batch Loss: 0.04903029277920723\n",
      "Epoch 4063, Loss: 0.04920658655464649, Final Batch Loss: 0.022505048662424088\n",
      "Epoch 4064, Loss: 0.13515115715563297, Final Batch Loss: 0.029949331656098366\n",
      "Epoch 4065, Loss: 0.06668930035084486, Final Batch Loss: 0.006211209110915661\n",
      "Epoch 4066, Loss: 0.027385336346924305, Final Batch Loss: 0.016330089420080185\n",
      "Epoch 4067, Loss: 0.11327114328742027, Final Batch Loss: 0.07299001514911652\n",
      "Epoch 4068, Loss: 0.07447127252817154, Final Batch Loss: 0.031840816140174866\n",
      "Epoch 4069, Loss: 0.042404395528137684, Final Batch Loss: 0.028916016221046448\n",
      "Epoch 4070, Loss: 0.0731155201792717, Final Batch Loss: 0.041174810379743576\n",
      "Epoch 4071, Loss: 0.0743479561060667, Final Batch Loss: 0.020961033180356026\n",
      "Epoch 4072, Loss: 0.05403579492121935, Final Batch Loss: 0.03910521790385246\n",
      "Epoch 4073, Loss: 0.08577226288616657, Final Batch Loss: 0.020454922690987587\n",
      "Epoch 4074, Loss: 0.042293332517147064, Final Batch Loss: 0.027439210563898087\n",
      "Epoch 4075, Loss: 0.15258684754371643, Final Batch Loss: 0.07974421232938766\n",
      "Epoch 4076, Loss: 0.08303110674023628, Final Batch Loss: 0.03105125203728676\n",
      "Epoch 4077, Loss: 0.07731669954955578, Final Batch Loss: 0.06354683637619019\n",
      "Epoch 4078, Loss: 0.03057802841067314, Final Batch Loss: 0.011583682149648666\n",
      "Epoch 4079, Loss: 0.08244418725371361, Final Batch Loss: 0.03761177882552147\n",
      "Epoch 4080, Loss: 0.04727567359805107, Final Batch Loss: 0.021095849573612213\n",
      "Epoch 4081, Loss: 0.10615376941859722, Final Batch Loss: 0.08743666857481003\n",
      "Epoch 4082, Loss: 0.06679751351475716, Final Batch Loss: 0.04868580400943756\n",
      "Epoch 4083, Loss: 0.05957277491688728, Final Batch Loss: 0.039779722690582275\n",
      "Epoch 4084, Loss: 0.09330204501748085, Final Batch Loss: 0.0548926517367363\n",
      "Epoch 4085, Loss: 0.05122432857751846, Final Batch Loss: 0.024241918697953224\n",
      "Epoch 4086, Loss: 0.05927932448685169, Final Batch Loss: 0.045921534299850464\n",
      "Epoch 4087, Loss: 0.08385872095823288, Final Batch Loss: 0.05237617343664169\n",
      "Epoch 4088, Loss: 0.04310306068509817, Final Batch Loss: 0.013820760883390903\n",
      "Epoch 4089, Loss: 0.05617564916610718, Final Batch Loss: 0.02667071297764778\n",
      "Epoch 4090, Loss: 0.0414496511220932, Final Batch Loss: 0.02415318228304386\n",
      "Epoch 4091, Loss: 0.06285450421273708, Final Batch Loss: 0.04143369570374489\n",
      "Epoch 4092, Loss: 0.04552355222404003, Final Batch Loss: 0.027818841859698296\n",
      "Epoch 4093, Loss: 0.05791877396404743, Final Batch Loss: 0.03534649312496185\n",
      "Epoch 4094, Loss: 0.03258204087615013, Final Batch Loss: 0.015873515978455544\n",
      "Epoch 4095, Loss: 0.022193418350070715, Final Batch Loss: 0.0064069046638906\n",
      "Epoch 4096, Loss: 0.052673459984362125, Final Batch Loss: 0.008325752802193165\n",
      "Epoch 4097, Loss: 0.02572638727724552, Final Batch Loss: 0.010584563948214054\n",
      "Epoch 4098, Loss: 0.030082253739237785, Final Batch Loss: 0.01520791556686163\n",
      "Epoch 4099, Loss: 0.0472672451287508, Final Batch Loss: 0.017091352492570877\n",
      "Epoch 4100, Loss: 0.030169617384672165, Final Batch Loss: 0.016436442732810974\n",
      "Epoch 4101, Loss: 0.01624649204313755, Final Batch Loss: 0.00928346998989582\n",
      "Epoch 4102, Loss: 0.02143259160220623, Final Batch Loss: 0.013734513893723488\n",
      "Epoch 4103, Loss: 0.039470840245485306, Final Batch Loss: 0.02891816943883896\n",
      "Epoch 4104, Loss: 0.03632813133299351, Final Batch Loss: 0.021905208006501198\n",
      "Epoch 4105, Loss: 0.020726162008941174, Final Batch Loss: 0.0053611816838383675\n",
      "Epoch 4106, Loss: 0.04706626199185848, Final Batch Loss: 0.013376640155911446\n",
      "Epoch 4107, Loss: 0.045088086277246475, Final Batch Loss: 0.01252298429608345\n",
      "Epoch 4108, Loss: 0.030936257913708687, Final Batch Loss: 0.019767535850405693\n",
      "Epoch 4109, Loss: 0.0999412052333355, Final Batch Loss: 0.06705713272094727\n",
      "Epoch 4110, Loss: 0.041705005802214146, Final Batch Loss: 0.02963508851826191\n",
      "Epoch 4111, Loss: 0.0655415952205658, Final Batch Loss: 0.045877452939748764\n",
      "Epoch 4112, Loss: 0.04434464871883392, Final Batch Loss: 0.01861719973385334\n",
      "Epoch 4113, Loss: 0.08048058301210403, Final Batch Loss: 0.06252739578485489\n",
      "Epoch 4114, Loss: 0.0654007438570261, Final Batch Loss: 0.02140033431351185\n",
      "Epoch 4115, Loss: 0.04253205098211765, Final Batch Loss: 0.028308801352977753\n",
      "Epoch 4116, Loss: 0.0397918289527297, Final Batch Loss: 0.02984144352376461\n",
      "Epoch 4117, Loss: 0.023278786800801754, Final Batch Loss: 0.010580544359982014\n",
      "Epoch 4118, Loss: 0.04079413414001465, Final Batch Loss: 0.026274466887116432\n",
      "Epoch 4119, Loss: 0.061344485729932785, Final Batch Loss: 0.01755845546722412\n",
      "Epoch 4120, Loss: 0.05481837969273329, Final Batch Loss: 0.04963766783475876\n",
      "Epoch 4121, Loss: 0.0906100682914257, Final Batch Loss: 0.03709552064538002\n",
      "Epoch 4122, Loss: 0.06891647167503834, Final Batch Loss: 0.012087414041161537\n",
      "Epoch 4123, Loss: 0.033551469910889864, Final Batch Loss: 0.007768851239234209\n",
      "Epoch 4124, Loss: 0.03824230097234249, Final Batch Loss: 0.018528925254940987\n",
      "Epoch 4125, Loss: 0.06753574963659048, Final Batch Loss: 0.014989390037953854\n",
      "Epoch 4126, Loss: 0.03993832226842642, Final Batch Loss: 0.015585781075060368\n",
      "Epoch 4127, Loss: 0.03258283529430628, Final Batch Loss: 0.013369348831474781\n",
      "Epoch 4128, Loss: 0.03203013073652983, Final Batch Loss: 0.019612425938248634\n",
      "Epoch 4129, Loss: 0.025574595667421818, Final Batch Loss: 0.00798089150339365\n",
      "Epoch 4130, Loss: 0.03218735754489899, Final Batch Loss: 0.014412257820367813\n",
      "Epoch 4131, Loss: 0.03390756715089083, Final Batch Loss: 0.006098068319261074\n",
      "Epoch 4132, Loss: 0.09536759927868843, Final Batch Loss: 0.05851069837808609\n",
      "Epoch 4133, Loss: 0.03876941651105881, Final Batch Loss: 0.017861204221844673\n",
      "Epoch 4134, Loss: 0.04948702082037926, Final Batch Loss: 0.023371266201138496\n",
      "Epoch 4135, Loss: 0.057559944689273834, Final Batch Loss: 0.01667337864637375\n",
      "Epoch 4136, Loss: 0.03758672624826431, Final Batch Loss: 0.009036252275109291\n",
      "Epoch 4137, Loss: 0.04363286681473255, Final Batch Loss: 0.028042851015925407\n",
      "Epoch 4138, Loss: 0.05633500963449478, Final Batch Loss: 0.03946736827492714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4139, Loss: 0.05853321310132742, Final Batch Loss: 0.052388470619916916\n",
      "Epoch 4140, Loss: 0.027864646166563034, Final Batch Loss: 0.015448670834302902\n",
      "Epoch 4141, Loss: 0.0303766168653965, Final Batch Loss: 0.01185966283082962\n",
      "Epoch 4142, Loss: 0.043847912922501564, Final Batch Loss: 0.017110927030444145\n",
      "Epoch 4143, Loss: 0.04307390935719013, Final Batch Loss: 0.022219616919755936\n",
      "Epoch 4144, Loss: 0.04113850789144635, Final Batch Loss: 0.03508719056844711\n",
      "Epoch 4145, Loss: 0.050200240686535835, Final Batch Loss: 0.021932285279035568\n",
      "Epoch 4146, Loss: 0.07978208549320698, Final Batch Loss: 0.022918066009879112\n",
      "Epoch 4147, Loss: 0.0886753462255001, Final Batch Loss: 0.040337465703487396\n",
      "Epoch 4148, Loss: 0.04438403807580471, Final Batch Loss: 0.020444883033633232\n",
      "Epoch 4149, Loss: 0.05378889013081789, Final Batch Loss: 0.011105344630777836\n",
      "Epoch 4150, Loss: 0.029439860954880714, Final Batch Loss: 0.019785529002547264\n",
      "Epoch 4151, Loss: 0.03829670138657093, Final Batch Loss: 0.02566089853644371\n",
      "Epoch 4152, Loss: 0.07554547488689423, Final Batch Loss: 0.021252136677503586\n",
      "Epoch 4153, Loss: 0.02140184910967946, Final Batch Loss: 0.006968666333705187\n",
      "Epoch 4154, Loss: 0.04880084842443466, Final Batch Loss: 0.03329639881849289\n",
      "Epoch 4155, Loss: 0.03519114851951599, Final Batch Loss: 0.02542201243340969\n",
      "Epoch 4156, Loss: 0.031392477452754974, Final Batch Loss: 0.023052208125591278\n",
      "Epoch 4157, Loss: 0.08520816918462515, Final Batch Loss: 0.07458560913801193\n",
      "Epoch 4158, Loss: 0.030614775605499744, Final Batch Loss: 0.008569634519517422\n",
      "Epoch 4159, Loss: 0.049723364412784576, Final Batch Loss: 0.025433585047721863\n",
      "Epoch 4160, Loss: 0.03784906677901745, Final Batch Loss: 0.019270459190011024\n",
      "Epoch 4161, Loss: 0.037239717319607735, Final Batch Loss: 0.016219576820731163\n",
      "Epoch 4162, Loss: 0.06490237638354301, Final Batch Loss: 0.032553739845752716\n",
      "Epoch 4163, Loss: 0.03337111696600914, Final Batch Loss: 0.01584813930094242\n",
      "Epoch 4164, Loss: 0.018485402688384056, Final Batch Loss: 0.012619138695299625\n",
      "Epoch 4165, Loss: 0.08646298944950104, Final Batch Loss: 0.07010763883590698\n",
      "Epoch 4166, Loss: 0.04276980459690094, Final Batch Loss: 0.027678370475769043\n",
      "Epoch 4167, Loss: 0.04994902387261391, Final Batch Loss: 0.0176394023001194\n",
      "Epoch 4168, Loss: 0.0895396787673235, Final Batch Loss: 0.015466580167412758\n",
      "Epoch 4169, Loss: 0.04399758763611317, Final Batch Loss: 0.02244690991938114\n",
      "Epoch 4170, Loss: 0.03520670533180237, Final Batch Loss: 0.026086527854204178\n",
      "Epoch 4171, Loss: 0.030325173400342464, Final Batch Loss: 0.005786987952888012\n",
      "Epoch 4172, Loss: 0.11063881497830153, Final Batch Loss: 0.09960847347974777\n",
      "Epoch 4173, Loss: 0.029856021516025066, Final Batch Loss: 0.0045768702402710915\n",
      "Epoch 4174, Loss: 0.024138277396559715, Final Batch Loss: 0.0023219306021928787\n",
      "Epoch 4175, Loss: 0.047375560738146305, Final Batch Loss: 0.033874060958623886\n",
      "Epoch 4176, Loss: 0.029329860117286444, Final Batch Loss: 0.005582812707871199\n",
      "Epoch 4177, Loss: 0.07122878916561604, Final Batch Loss: 0.049000926315784454\n",
      "Epoch 4178, Loss: 0.031417977064847946, Final Batch Loss: 0.008659416809678078\n",
      "Epoch 4179, Loss: 0.11501901783049107, Final Batch Loss: 0.029105255380272865\n",
      "Epoch 4180, Loss: 0.06551767233759165, Final Batch Loss: 0.011094742454588413\n",
      "Epoch 4181, Loss: 0.06270596757531166, Final Batch Loss: 0.031281840056180954\n",
      "Epoch 4182, Loss: 0.041867561638355255, Final Batch Loss: 0.010243970900774002\n",
      "Epoch 4183, Loss: 0.06758558936417103, Final Batch Loss: 0.01965886540710926\n",
      "Epoch 4184, Loss: 0.026889551896601915, Final Batch Loss: 0.004322611261159182\n",
      "Epoch 4185, Loss: 0.030761574395000935, Final Batch Loss: 0.024167561903595924\n",
      "Epoch 4186, Loss: 0.02850261889398098, Final Batch Loss: 0.009613016620278358\n",
      "Epoch 4187, Loss: 0.0375553909689188, Final Batch Loss: 0.006153928115963936\n",
      "Epoch 4188, Loss: 0.04599848948419094, Final Batch Loss: 0.019139787182211876\n",
      "Epoch 4189, Loss: 0.028954245150089264, Final Batch Loss: 0.007787106558680534\n",
      "Epoch 4190, Loss: 0.0393280778080225, Final Batch Loss: 0.015783976763486862\n",
      "Epoch 4191, Loss: 0.029477830044925213, Final Batch Loss: 0.008820558898150921\n",
      "Epoch 4192, Loss: 0.1018809862434864, Final Batch Loss: 0.03523872420191765\n",
      "Epoch 4193, Loss: 0.019383177161216736, Final Batch Loss: 0.010318079963326454\n",
      "Epoch 4194, Loss: 0.06012995354831219, Final Batch Loss: 0.02289132960140705\n",
      "Epoch 4195, Loss: 0.06188234128057957, Final Batch Loss: 0.030468272045254707\n",
      "Epoch 4196, Loss: 0.05714688450098038, Final Batch Loss: 0.03578575700521469\n",
      "Epoch 4197, Loss: 0.030769518576562405, Final Batch Loss: 0.018151780590415\n",
      "Epoch 4198, Loss: 0.013932801317423582, Final Batch Loss: 0.004408692475408316\n",
      "Epoch 4199, Loss: 0.10178414732217789, Final Batch Loss: 0.06779474765062332\n",
      "Epoch 4200, Loss: 0.0738285444676876, Final Batch Loss: 0.040324240922927856\n",
      "Epoch 4201, Loss: 0.04936617519706488, Final Batch Loss: 0.04254778474569321\n",
      "Epoch 4202, Loss: 0.028554130345582962, Final Batch Loss: 0.012117983773350716\n",
      "Epoch 4203, Loss: 0.010785665363073349, Final Batch Loss: 0.005023816134780645\n",
      "Epoch 4204, Loss: 0.07410637103021145, Final Batch Loss: 0.01970456726849079\n",
      "Epoch 4205, Loss: 0.036995391361415386, Final Batch Loss: 0.02275434136390686\n",
      "Epoch 4206, Loss: 0.06318032555282116, Final Batch Loss: 0.047049734741449356\n",
      "Epoch 4207, Loss: 0.07237083092331886, Final Batch Loss: 0.028231658041477203\n",
      "Epoch 4208, Loss: 0.04164510406553745, Final Batch Loss: 0.020499132573604584\n",
      "Epoch 4209, Loss: 0.06611451506614685, Final Batch Loss: 0.0495058111846447\n",
      "Epoch 4210, Loss: 0.059446850791573524, Final Batch Loss: 0.03283693268895149\n",
      "Epoch 4211, Loss: 0.04087579622864723, Final Batch Loss: 0.018676303327083588\n",
      "Epoch 4212, Loss: 0.029040968976914883, Final Batch Loss: 0.01005468424409628\n",
      "Epoch 4213, Loss: 0.014192859875038266, Final Batch Loss: 0.0022651052568107843\n",
      "Epoch 4214, Loss: 0.050206372514367104, Final Batch Loss: 0.02801073156297207\n",
      "Epoch 4215, Loss: 0.06579668819904327, Final Batch Loss: 0.04528428241610527\n",
      "Epoch 4216, Loss: 0.06753656081855297, Final Batch Loss: 0.04459865391254425\n",
      "Epoch 4217, Loss: 0.03836184274405241, Final Batch Loss: 0.029919415712356567\n",
      "Epoch 4218, Loss: 0.05469578318297863, Final Batch Loss: 0.03904477506875992\n",
      "Epoch 4219, Loss: 0.02938581258058548, Final Batch Loss: 0.012542201206088066\n",
      "Epoch 4220, Loss: 0.03923476114869118, Final Batch Loss: 0.030359288677573204\n",
      "Epoch 4221, Loss: 0.028998393565416336, Final Batch Loss: 0.015123076736927032\n",
      "Epoch 4222, Loss: 0.04876261577010155, Final Batch Loss: 0.028704365715384483\n",
      "Epoch 4223, Loss: 0.04967395402491093, Final Batch Loss: 0.017461193725466728\n",
      "Epoch 4224, Loss: 0.049186114221811295, Final Batch Loss: 0.022690603509545326\n",
      "Epoch 4225, Loss: 0.04879271611571312, Final Batch Loss: 0.01893354021012783\n",
      "Epoch 4226, Loss: 0.04809287656098604, Final Batch Loss: 0.036437004804611206\n",
      "Epoch 4227, Loss: 0.05418871343135834, Final Batch Loss: 0.04367160052061081\n",
      "Epoch 4228, Loss: 0.07048103772103786, Final Batch Loss: 0.046278342604637146\n",
      "Epoch 4229, Loss: 0.019433865323662758, Final Batch Loss: 0.011387521401047707\n",
      "Epoch 4230, Loss: 0.05722234211862087, Final Batch Loss: 0.025608466938138008\n",
      "Epoch 4231, Loss: 0.08448965847492218, Final Batch Loss: 0.0514129176735878\n",
      "Epoch 4232, Loss: 0.022749250754714012, Final Batch Loss: 0.008356557227671146\n",
      "Epoch 4233, Loss: 0.029072681441903114, Final Batch Loss: 0.01304677501320839\n",
      "Epoch 4234, Loss: 0.042660124599933624, Final Batch Loss: 0.018888723105192184\n",
      "Epoch 4235, Loss: 0.035518608056008816, Final Batch Loss: 0.021382588893175125\n",
      "Epoch 4236, Loss: 0.06155222840607166, Final Batch Loss: 0.029211482033133507\n",
      "Epoch 4237, Loss: 0.040929667185992, Final Batch Loss: 0.03469909355044365\n",
      "Epoch 4238, Loss: 0.028837507590651512, Final Batch Loss: 0.004492407664656639\n",
      "Epoch 4239, Loss: 0.024808002170175314, Final Batch Loss: 0.002851590048521757\n",
      "Epoch 4240, Loss: 0.023657063022255898, Final Batch Loss: 0.01439338643103838\n",
      "Epoch 4241, Loss: 0.04730807617306709, Final Batch Loss: 0.025902001187205315\n",
      "Epoch 4242, Loss: 0.035620410460978746, Final Batch Loss: 0.007270168978720903\n",
      "Epoch 4243, Loss: 0.09463085606694221, Final Batch Loss: 0.06971833854913712\n",
      "Epoch 4244, Loss: 0.03029285278171301, Final Batch Loss: 0.009779217652976513\n",
      "Epoch 4245, Loss: 0.0326855294406414, Final Batch Loss: 0.02266123704612255\n",
      "Epoch 4246, Loss: 0.028409510850906372, Final Batch Loss: 0.017560331150889397\n",
      "Epoch 4247, Loss: 0.03464040160179138, Final Batch Loss: 0.013795871287584305\n",
      "Epoch 4248, Loss: 0.03097155410796404, Final Batch Loss: 0.026245178654789925\n",
      "Epoch 4249, Loss: 0.09697256097570062, Final Batch Loss: 0.0892522931098938\n",
      "Epoch 4250, Loss: 0.02705340040847659, Final Batch Loss: 0.00378091586753726\n",
      "Epoch 4251, Loss: 0.021818893030285835, Final Batch Loss: 0.01383399497717619\n",
      "Epoch 4252, Loss: 0.05163166578859091, Final Batch Loss: 0.03800394386053085\n",
      "Epoch 4253, Loss: 0.02753263246268034, Final Batch Loss: 0.01659601554274559\n",
      "Epoch 4254, Loss: 0.025050504133105278, Final Batch Loss: 0.008336443454027176\n",
      "Epoch 4255, Loss: 0.039520660415291786, Final Batch Loss: 0.013059746474027634\n",
      "Epoch 4256, Loss: 0.03156166663393378, Final Batch Loss: 0.005972299259155989\n",
      "Epoch 4257, Loss: 0.017812970094382763, Final Batch Loss: 0.006775642745196819\n",
      "Epoch 4258, Loss: 0.028119369875639677, Final Batch Loss: 0.02256557159125805\n",
      "Epoch 4259, Loss: 0.013977756490930915, Final Batch Loss: 0.003521365812048316\n",
      "Epoch 4260, Loss: 0.03083968162536621, Final Batch Loss: 0.01877916418015957\n",
      "Epoch 4261, Loss: 0.025189482839778066, Final Batch Loss: 0.0038191296625882387\n",
      "Epoch 4262, Loss: 0.013755074702203274, Final Batch Loss: 0.006173697300255299\n",
      "Epoch 4263, Loss: 0.03473793063312769, Final Batch Loss: 0.02161325514316559\n",
      "Epoch 4264, Loss: 0.03588547185063362, Final Batch Loss: 0.014497589319944382\n",
      "Epoch 4265, Loss: 0.03473495412617922, Final Batch Loss: 0.01204689871519804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4266, Loss: 0.045168425887823105, Final Batch Loss: 0.03482847660779953\n",
      "Epoch 4267, Loss: 0.06266964040696621, Final Batch Loss: 0.01598605327308178\n",
      "Epoch 4268, Loss: 0.04951923154294491, Final Batch Loss: 0.024847574532032013\n",
      "Epoch 4269, Loss: 0.053417643532156944, Final Batch Loss: 0.02216370217502117\n",
      "Epoch 4270, Loss: 0.04354799725115299, Final Batch Loss: 0.01654416136443615\n",
      "Epoch 4271, Loss: 0.07912038266658783, Final Batch Loss: 0.06212954223155975\n",
      "Epoch 4272, Loss: 0.09644921869039536, Final Batch Loss: 0.04107911139726639\n",
      "Epoch 4273, Loss: 0.02929388266056776, Final Batch Loss: 0.011611451394855976\n",
      "Epoch 4274, Loss: 0.03912738710641861, Final Batch Loss: 0.004254542291164398\n",
      "Epoch 4275, Loss: 0.011924423277378082, Final Batch Loss: 0.003083770163357258\n",
      "Epoch 4276, Loss: 0.031708952970802784, Final Batch Loss: 0.018543967977166176\n",
      "Epoch 4277, Loss: 0.0694698691368103, Final Batch Loss: 0.032558947801589966\n",
      "Epoch 4278, Loss: 0.0511914286762476, Final Batch Loss: 0.018982788547873497\n",
      "Epoch 4279, Loss: 0.049422405660152435, Final Batch Loss: 0.02926718257367611\n",
      "Epoch 4280, Loss: 0.012258965987712145, Final Batch Loss: 0.00780533067882061\n",
      "Epoch 4281, Loss: 0.0314889932051301, Final Batch Loss: 0.01689263805747032\n",
      "Epoch 4282, Loss: 0.07449859008193016, Final Batch Loss: 0.03408459946513176\n",
      "Epoch 4283, Loss: 0.0643271841108799, Final Batch Loss: 0.04211466386914253\n",
      "Epoch 4284, Loss: 0.027482152450829744, Final Batch Loss: 0.004788948688656092\n",
      "Epoch 4285, Loss: 0.052736569195985794, Final Batch Loss: 0.02380128763616085\n",
      "Epoch 4286, Loss: 0.039779593236744404, Final Batch Loss: 0.02648772858083248\n",
      "Epoch 4287, Loss: 0.03722542989999056, Final Batch Loss: 0.023818714544177055\n",
      "Epoch 4288, Loss: 0.016247582156211138, Final Batch Loss: 0.006483167875558138\n",
      "Epoch 4289, Loss: 0.01754650194197893, Final Batch Loss: 0.005116354674100876\n",
      "Epoch 4290, Loss: 0.03898043371737003, Final Batch Loss: 0.019852759316563606\n",
      "Epoch 4291, Loss: 0.08287624642252922, Final Batch Loss: 0.024830572307109833\n",
      "Epoch 4292, Loss: 0.033162868581712246, Final Batch Loss: 0.01753995381295681\n",
      "Epoch 4293, Loss: 0.03772139362990856, Final Batch Loss: 0.02377219870686531\n",
      "Epoch 4294, Loss: 0.06374632194638252, Final Batch Loss: 0.03615037724375725\n",
      "Epoch 4295, Loss: 0.03918656031601131, Final Batch Loss: 0.0033756352495402098\n",
      "Epoch 4296, Loss: 0.031452028546482325, Final Batch Loss: 0.007559383753687143\n",
      "Epoch 4297, Loss: 0.1155874989926815, Final Batch Loss: 0.06679563224315643\n",
      "Epoch 4298, Loss: 0.04300156980752945, Final Batch Loss: 0.03721622750163078\n",
      "Epoch 4299, Loss: 0.07522816210985184, Final Batch Loss: 0.04971476271748543\n",
      "Epoch 4300, Loss: 0.03991629742085934, Final Batch Loss: 0.01987500861287117\n",
      "Epoch 4301, Loss: 0.056435076519846916, Final Batch Loss: 0.025063449516892433\n",
      "Epoch 4302, Loss: 0.08317644521594048, Final Batch Loss: 0.051104094833135605\n",
      "Epoch 4303, Loss: 0.03216478135436773, Final Batch Loss: 0.014022222720086575\n",
      "Epoch 4304, Loss: 0.049980130046606064, Final Batch Loss: 0.03300412744283676\n",
      "Epoch 4305, Loss: 0.09294161200523376, Final Batch Loss: 0.015039846301078796\n",
      "Epoch 4306, Loss: 0.050872670486569405, Final Batch Loss: 0.016510995104908943\n",
      "Epoch 4307, Loss: 0.051581788808107376, Final Batch Loss: 0.03401535749435425\n",
      "Epoch 4308, Loss: 0.05147630721330643, Final Batch Loss: 0.017388269305229187\n",
      "Epoch 4309, Loss: 0.027808817103505135, Final Batch Loss: 0.0038408227264881134\n",
      "Epoch 4310, Loss: 0.05616488866508007, Final Batch Loss: 0.028547212481498718\n",
      "Epoch 4311, Loss: 0.022684860043227673, Final Batch Loss: 0.007268673740327358\n",
      "Epoch 4312, Loss: 0.11195177212357521, Final Batch Loss: 0.07619365304708481\n",
      "Epoch 4313, Loss: 0.053434235975146294, Final Batch Loss: 0.0132762361317873\n",
      "Epoch 4314, Loss: 0.04153639264404774, Final Batch Loss: 0.021275965496897697\n",
      "Epoch 4315, Loss: 0.07177955843508244, Final Batch Loss: 0.04561642184853554\n",
      "Epoch 4316, Loss: 0.05034053511917591, Final Batch Loss: 0.018688084557652473\n",
      "Epoch 4317, Loss: 0.1310972198843956, Final Batch Loss: 0.07037322223186493\n",
      "Epoch 4318, Loss: 0.06843092665076256, Final Batch Loss: 0.03475659713149071\n",
      "Epoch 4319, Loss: 0.2539108395576477, Final Batch Loss: 0.1658717542886734\n",
      "Epoch 4320, Loss: 0.11707183718681335, Final Batch Loss: 0.044318608939647675\n",
      "Epoch 4321, Loss: 0.14775177463889122, Final Batch Loss: 0.10530252754688263\n",
      "Epoch 4322, Loss: 0.13420629128813744, Final Batch Loss: 0.08389919251203537\n",
      "Epoch 4323, Loss: 0.144036415964365, Final Batch Loss: 0.11317796260118484\n",
      "Epoch 4324, Loss: 0.05353631637990475, Final Batch Loss: 0.022144926711916924\n",
      "Epoch 4325, Loss: 0.0879264660179615, Final Batch Loss: 0.03323545306921005\n",
      "Epoch 4326, Loss: 0.07748780213296413, Final Batch Loss: 0.02052261121571064\n",
      "Epoch 4327, Loss: 0.030995160341262817, Final Batch Loss: 0.0059857554733753204\n",
      "Epoch 4328, Loss: 0.0772440917789936, Final Batch Loss: 0.032277025282382965\n",
      "Epoch 4329, Loss: 0.06547916494309902, Final Batch Loss: 0.02478761039674282\n",
      "Epoch 4330, Loss: 0.13748033344745636, Final Batch Loss: 0.04743357002735138\n",
      "Epoch 4331, Loss: 0.02596278116106987, Final Batch Loss: 0.008035873994231224\n",
      "Epoch 4332, Loss: 0.09105299040675163, Final Batch Loss: 0.03600357100367546\n",
      "Epoch 4333, Loss: 0.14088404923677444, Final Batch Loss: 0.08481183648109436\n",
      "Epoch 4334, Loss: 0.07800413807854056, Final Batch Loss: 0.007634887006133795\n",
      "Epoch 4335, Loss: 0.05361633934080601, Final Batch Loss: 0.03181934356689453\n",
      "Epoch 4336, Loss: 0.08325587213039398, Final Batch Loss: 0.036725252866744995\n",
      "Epoch 4337, Loss: 0.10367409139871597, Final Batch Loss: 0.04115092754364014\n",
      "Epoch 4338, Loss: 0.08618596568703651, Final Batch Loss: 0.026846401393413544\n",
      "Epoch 4339, Loss: 0.05019500106573105, Final Batch Loss: 0.022679822519421577\n",
      "Epoch 4340, Loss: 0.04269159771502018, Final Batch Loss: 0.009148186072707176\n",
      "Epoch 4341, Loss: 0.0633354876190424, Final Batch Loss: 0.03442380204796791\n",
      "Epoch 4342, Loss: 0.04592714086174965, Final Batch Loss: 0.0348086953163147\n",
      "Epoch 4343, Loss: 0.059218715876340866, Final Batch Loss: 0.03936579450964928\n",
      "Epoch 4344, Loss: 0.08619966730475426, Final Batch Loss: 0.0468176007270813\n",
      "Epoch 4345, Loss: 0.0694042518734932, Final Batch Loss: 0.025965876877307892\n",
      "Epoch 4346, Loss: 0.058904699981212616, Final Batch Loss: 0.043111275881528854\n",
      "Epoch 4347, Loss: 0.02557539753615856, Final Batch Loss: 0.011939853429794312\n",
      "Epoch 4348, Loss: 0.05364049784839153, Final Batch Loss: 0.024009941145777702\n",
      "Epoch 4349, Loss: 0.05393059365451336, Final Batch Loss: 0.040850624442100525\n",
      "Epoch 4350, Loss: 0.02694376651197672, Final Batch Loss: 0.010046075098216534\n",
      "Epoch 4351, Loss: 0.03966009244322777, Final Batch Loss: 0.02106066420674324\n",
      "Epoch 4352, Loss: 0.03778851591050625, Final Batch Loss: 0.02182348258793354\n",
      "Epoch 4353, Loss: 0.04386391490697861, Final Batch Loss: 0.011379100382328033\n",
      "Epoch 4354, Loss: 0.04802782088518143, Final Batch Loss: 0.025812914595007896\n",
      "Epoch 4355, Loss: 0.06255904771387577, Final Batch Loss: 0.0357377752661705\n",
      "Epoch 4356, Loss: 0.09288667887449265, Final Batch Loss: 0.030287854373455048\n",
      "Epoch 4357, Loss: 0.03824402391910553, Final Batch Loss: 0.019502466544508934\n",
      "Epoch 4358, Loss: 0.03548464830964804, Final Batch Loss: 0.009494374506175518\n",
      "Epoch 4359, Loss: 0.09042023681104183, Final Batch Loss: 0.06221175193786621\n",
      "Epoch 4360, Loss: 0.039130426943302155, Final Batch Loss: 0.017034072428941727\n",
      "Epoch 4361, Loss: 0.053091440349817276, Final Batch Loss: 0.021079346537590027\n",
      "Epoch 4362, Loss: 0.04853472672402859, Final Batch Loss: 0.0345938503742218\n",
      "Epoch 4363, Loss: 0.03849572502076626, Final Batch Loss: 0.020158326253294945\n",
      "Epoch 4364, Loss: 0.05992290563881397, Final Batch Loss: 0.008823422715067863\n",
      "Epoch 4365, Loss: 0.06279397197067738, Final Batch Loss: 0.04359085112810135\n",
      "Epoch 4366, Loss: 0.03192778304219246, Final Batch Loss: 0.011917805299162865\n",
      "Epoch 4367, Loss: 0.0784328281879425, Final Batch Loss: 0.034784067422151566\n",
      "Epoch 4368, Loss: 0.029520914889872074, Final Batch Loss: 0.017579711973667145\n",
      "Epoch 4369, Loss: 0.024973731487989426, Final Batch Loss: 0.00996293406933546\n",
      "Epoch 4370, Loss: 0.06990423146635294, Final Batch Loss: 0.012338300235569477\n",
      "Epoch 4371, Loss: 0.06466715969145298, Final Batch Loss: 0.024405458942055702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4372, Loss: 0.04253538325428963, Final Batch Loss: 0.010160565376281738\n",
      "Epoch 4373, Loss: 0.03151520388200879, Final Batch Loss: 0.005004195962101221\n",
      "Epoch 4374, Loss: 0.033528667874634266, Final Batch Loss: 0.02542073279619217\n",
      "Epoch 4375, Loss: 0.020515637006610632, Final Batch Loss: 0.014423470012843609\n",
      "Epoch 4376, Loss: 0.0833678636699915, Final Batch Loss: 0.05651882663369179\n",
      "Epoch 4377, Loss: 0.03531502466648817, Final Batch Loss: 0.013119111768901348\n",
      "Epoch 4378, Loss: 0.060261186212301254, Final Batch Loss: 0.03276502341032028\n",
      "Epoch 4379, Loss: 0.04014447517693043, Final Batch Loss: 0.024560168385505676\n",
      "Epoch 4380, Loss: 0.015258805360645056, Final Batch Loss: 0.009710573591291904\n",
      "Epoch 4381, Loss: 0.0981206875294447, Final Batch Loss: 0.07751823961734772\n",
      "Epoch 4382, Loss: 0.11059144511818886, Final Batch Loss: 0.0843966156244278\n",
      "Epoch 4383, Loss: 0.03360212780535221, Final Batch Loss: 0.021685374900698662\n",
      "Epoch 4384, Loss: 0.059067653492093086, Final Batch Loss: 0.031659889966249466\n",
      "Epoch 4385, Loss: 0.09380605071783066, Final Batch Loss: 0.05006418004631996\n",
      "Epoch 4386, Loss: 0.043310604989528656, Final Batch Loss: 0.01391834206879139\n",
      "Epoch 4387, Loss: 0.04622336104512215, Final Batch Loss: 0.012435663491487503\n",
      "Epoch 4388, Loss: 0.032369088381528854, Final Batch Loss: 0.008700869977474213\n",
      "Epoch 4389, Loss: 0.09539664164185524, Final Batch Loss: 0.08749403059482574\n",
      "Epoch 4390, Loss: 0.044562848284840584, Final Batch Loss: 0.012902641668915749\n",
      "Epoch 4391, Loss: 0.07049472816288471, Final Batch Loss: 0.043931737542152405\n",
      "Epoch 4392, Loss: 0.05458908528089523, Final Batch Loss: 0.01845913752913475\n",
      "Epoch 4393, Loss: 0.027490429347380996, Final Batch Loss: 0.0243231151252985\n",
      "Epoch 4394, Loss: 0.055465107783675194, Final Batch Loss: 0.033991772681474686\n",
      "Epoch 4395, Loss: 0.03276137728244066, Final Batch Loss: 0.005308880470693111\n",
      "Epoch 4396, Loss: 0.06040441058576107, Final Batch Loss: 0.035084303468465805\n",
      "Epoch 4397, Loss: 0.057510415092110634, Final Batch Loss: 0.034077394753694534\n",
      "Epoch 4398, Loss: 0.03836763743311167, Final Batch Loss: 0.015456636436283588\n",
      "Epoch 4399, Loss: 0.010121173923835158, Final Batch Loss: 0.006590455770492554\n",
      "Epoch 4400, Loss: 0.0377247529104352, Final Batch Loss: 0.02625737339258194\n",
      "Epoch 4401, Loss: 0.04811856336891651, Final Batch Loss: 0.027502968907356262\n",
      "Epoch 4402, Loss: 0.03286427818238735, Final Batch Loss: 0.009297173470258713\n",
      "Epoch 4403, Loss: 0.047391289845108986, Final Batch Loss: 0.02737334556877613\n",
      "Epoch 4404, Loss: 0.04662438854575157, Final Batch Loss: 0.031053073704242706\n",
      "Epoch 4405, Loss: 0.05733952857553959, Final Batch Loss: 0.03053484484553337\n",
      "Epoch 4406, Loss: 0.05518195778131485, Final Batch Loss: 0.033104803413152695\n",
      "Epoch 4407, Loss: 0.027161236852407455, Final Batch Loss: 0.011854827404022217\n",
      "Epoch 4408, Loss: 0.06342499144375324, Final Batch Loss: 0.03771660476922989\n",
      "Epoch 4409, Loss: 0.09571817331016064, Final Batch Loss: 0.07830911129713058\n",
      "Epoch 4410, Loss: 0.07190830633044243, Final Batch Loss: 0.03161384537816048\n",
      "Epoch 4411, Loss: 0.045688116922974586, Final Batch Loss: 0.018300944939255714\n",
      "Epoch 4412, Loss: 0.04687141813337803, Final Batch Loss: 0.011095879599452019\n",
      "Epoch 4413, Loss: 0.04428034648299217, Final Batch Loss: 0.025936409831047058\n",
      "Epoch 4414, Loss: 0.023579314351081848, Final Batch Loss: 0.009499480947852135\n",
      "Epoch 4415, Loss: 0.033562202006578445, Final Batch Loss: 0.013935316354036331\n",
      "Epoch 4416, Loss: 0.046755312010645866, Final Batch Loss: 0.02289455197751522\n",
      "Epoch 4417, Loss: 0.019330293871462345, Final Batch Loss: 0.008221975527703762\n",
      "Epoch 4418, Loss: 0.0710721854120493, Final Batch Loss: 0.04402998089790344\n",
      "Epoch 4419, Loss: 0.15924958884716034, Final Batch Loss: 0.11364652216434479\n",
      "Epoch 4420, Loss: 0.026753158774226904, Final Batch Loss: 0.006178220268338919\n",
      "Epoch 4421, Loss: 0.06551597127690911, Final Batch Loss: 0.007172523532062769\n",
      "Epoch 4422, Loss: 0.035178561229258776, Final Batch Loss: 0.004241785500198603\n",
      "Epoch 4423, Loss: 0.11625861003994942, Final Batch Loss: 0.0836484283208847\n",
      "Epoch 4424, Loss: 0.06890164315700531, Final Batch Loss: 0.030328381806612015\n",
      "Epoch 4425, Loss: 0.08506037015467882, Final Batch Loss: 0.07119900733232498\n",
      "Epoch 4426, Loss: 0.0495372898876667, Final Batch Loss: 0.02802255004644394\n",
      "Epoch 4427, Loss: 0.06256823055446148, Final Batch Loss: 0.047508854418992996\n",
      "Epoch 4428, Loss: 0.08594786003232002, Final Batch Loss: 0.024386253207921982\n",
      "Epoch 4429, Loss: 0.05615837313234806, Final Batch Loss: 0.033763643354177475\n",
      "Epoch 4430, Loss: 0.04028651490807533, Final Batch Loss: 0.0048820339143276215\n",
      "Epoch 4431, Loss: 0.0709052961319685, Final Batch Loss: 0.04389128461480141\n",
      "Epoch 4432, Loss: 0.05177732463926077, Final Batch Loss: 0.015346693806350231\n",
      "Epoch 4433, Loss: 0.040311203338205814, Final Batch Loss: 0.01204019133001566\n",
      "Epoch 4434, Loss: 0.07867314666509628, Final Batch Loss: 0.05963081866502762\n",
      "Epoch 4435, Loss: 0.055539509281516075, Final Batch Loss: 0.024149814620614052\n",
      "Epoch 4436, Loss: 0.05208739824593067, Final Batch Loss: 0.016552263870835304\n",
      "Epoch 4437, Loss: 0.05192210525274277, Final Batch Loss: 0.034166786819696426\n",
      "Epoch 4438, Loss: 0.05563058517873287, Final Batch Loss: 0.020111842080950737\n",
      "Epoch 4439, Loss: 0.015843079891055822, Final Batch Loss: 0.008296494372189045\n",
      "Epoch 4440, Loss: 0.0491686649620533, Final Batch Loss: 0.028678005561232567\n",
      "Epoch 4441, Loss: 0.0719975121319294, Final Batch Loss: 0.0452384315431118\n",
      "Epoch 4442, Loss: 0.06321445945650339, Final Batch Loss: 0.05095784366130829\n",
      "Epoch 4443, Loss: 0.031724946573376656, Final Batch Loss: 0.02093801461160183\n",
      "Epoch 4444, Loss: 0.04337697848677635, Final Batch Loss: 0.02496587298810482\n",
      "Epoch 4445, Loss: 0.050982194021344185, Final Batch Loss: 0.03415891155600548\n",
      "Epoch 4446, Loss: 0.05468281731009483, Final Batch Loss: 0.04093252122402191\n",
      "Epoch 4447, Loss: 0.04556231014430523, Final Batch Loss: 0.00951446034014225\n",
      "Epoch 4448, Loss: 0.03715433459728956, Final Batch Loss: 0.010406267829239368\n",
      "Epoch 4449, Loss: 0.050698649138212204, Final Batch Loss: 0.04230698198080063\n",
      "Epoch 4450, Loss: 0.048999032005667686, Final Batch Loss: 0.0356704518198967\n",
      "Epoch 4451, Loss: 0.0721898041665554, Final Batch Loss: 0.03946512192487717\n",
      "Epoch 4452, Loss: 0.045751648023724556, Final Batch Loss: 0.019131967797875404\n",
      "Epoch 4453, Loss: 0.06098165921866894, Final Batch Loss: 0.03356466814875603\n",
      "Epoch 4454, Loss: 0.0911237895488739, Final Batch Loss: 0.08357878029346466\n",
      "Epoch 4455, Loss: 0.0972532294690609, Final Batch Loss: 0.0448848158121109\n",
      "Epoch 4456, Loss: 0.02784084714949131, Final Batch Loss: 0.007833527401089668\n",
      "Epoch 4457, Loss: 0.05517679080367088, Final Batch Loss: 0.031080573797225952\n",
      "Epoch 4458, Loss: 0.0573893329128623, Final Batch Loss: 0.010733860544860363\n",
      "Epoch 4459, Loss: 0.03453034069389105, Final Batch Loss: 0.011574453674256802\n",
      "Epoch 4460, Loss: 0.032263852655887604, Final Batch Loss: 0.010870607569813728\n",
      "Epoch 4461, Loss: 0.05332373455166817, Final Batch Loss: 0.026752622798085213\n",
      "Epoch 4462, Loss: 0.029835619032382965, Final Batch Loss: 0.011136254295706749\n",
      "Epoch 4463, Loss: 0.03388787433505058, Final Batch Loss: 0.021102475002408028\n",
      "Epoch 4464, Loss: 0.029479223769158125, Final Batch Loss: 0.025358982384204865\n",
      "Epoch 4465, Loss: 0.023942010942846537, Final Batch Loss: 0.004173510242253542\n",
      "Epoch 4466, Loss: 0.04386528395116329, Final Batch Loss: 0.009871428832411766\n",
      "Epoch 4467, Loss: 0.05359218642115593, Final Batch Loss: 0.02318902127444744\n",
      "Epoch 4468, Loss: 0.018419945612549782, Final Batch Loss: 0.007424250245094299\n",
      "Epoch 4469, Loss: 0.042287399992346764, Final Batch Loss: 0.02887311577796936\n",
      "Epoch 4470, Loss: 0.05050760321319103, Final Batch Loss: 0.01900731958448887\n",
      "Epoch 4471, Loss: 0.05721449665725231, Final Batch Loss: 0.02979889325797558\n",
      "Epoch 4472, Loss: 0.06509496830403805, Final Batch Loss: 0.027915338054299355\n",
      "Epoch 4473, Loss: 0.028556570410728455, Final Batch Loss: 0.015301618725061417\n",
      "Epoch 4474, Loss: 0.09431164711713791, Final Batch Loss: 0.06466331332921982\n",
      "Epoch 4475, Loss: 0.0526523869484663, Final Batch Loss: 0.012439338490366936\n",
      "Epoch 4476, Loss: 0.030158162117004395, Final Batch Loss: 0.01670483499765396\n",
      "Epoch 4477, Loss: 0.06094006169587374, Final Batch Loss: 0.008091473020613194\n",
      "Epoch 4478, Loss: 0.02233092812821269, Final Batch Loss: 0.0049222311936318874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4479, Loss: 0.07024407759308815, Final Batch Loss: 0.03282984718680382\n",
      "Epoch 4480, Loss: 0.0341351144015789, Final Batch Loss: 0.01749284379184246\n",
      "Epoch 4481, Loss: 0.07413435913622379, Final Batch Loss: 0.030774084851145744\n",
      "Epoch 4482, Loss: 0.044535474851727486, Final Batch Loss: 0.022025562822818756\n",
      "Epoch 4483, Loss: 0.028941906057298183, Final Batch Loss: 0.02170017547905445\n",
      "Epoch 4484, Loss: 0.04879453778266907, Final Batch Loss: 0.0296846441924572\n",
      "Epoch 4485, Loss: 0.045857563614845276, Final Batch Loss: 0.024805715307593346\n",
      "Epoch 4486, Loss: 0.07409043191000819, Final Batch Loss: 0.0693596675992012\n",
      "Epoch 4487, Loss: 0.03908157255500555, Final Batch Loss: 0.005648202262818813\n",
      "Epoch 4488, Loss: 0.09913798049092293, Final Batch Loss: 0.06217543035745621\n",
      "Epoch 4489, Loss: 0.0766170471906662, Final Batch Loss: 0.04135245829820633\n",
      "Epoch 4490, Loss: 0.05101974681019783, Final Batch Loss: 0.02706022746860981\n",
      "Epoch 4491, Loss: 0.04120447160676122, Final Batch Loss: 0.005844444502145052\n",
      "Epoch 4492, Loss: 0.021889164112508297, Final Batch Loss: 0.0027753720059990883\n",
      "Epoch 4493, Loss: 0.04274545516818762, Final Batch Loss: 0.02802428975701332\n",
      "Epoch 4494, Loss: 0.019812400452792645, Final Batch Loss: 0.012257594615221024\n",
      "Epoch 4495, Loss: 0.03685242682695389, Final Batch Loss: 0.009590419009327888\n",
      "Epoch 4496, Loss: 0.037563775666058064, Final Batch Loss: 0.01140929851680994\n",
      "Epoch 4497, Loss: 0.06665410846471786, Final Batch Loss: 0.050438545644283295\n",
      "Epoch 4498, Loss: 0.037370611913502216, Final Batch Loss: 0.026144957169890404\n",
      "Epoch 4499, Loss: 0.051232040859758854, Final Batch Loss: 0.03883538022637367\n",
      "Epoch 4500, Loss: 0.026830784510821104, Final Batch Loss: 0.019655385985970497\n",
      "Epoch 4501, Loss: 0.023484883829951286, Final Batch Loss: 0.014904584735631943\n",
      "Epoch 4502, Loss: 0.050377787090837955, Final Batch Loss: 0.0394904762506485\n",
      "Epoch 4503, Loss: 0.029640459455549717, Final Batch Loss: 0.0068871742114424706\n",
      "Epoch 4504, Loss: 0.0734675507992506, Final Batch Loss: 0.04264795780181885\n",
      "Epoch 4505, Loss: 0.020616051275283098, Final Batch Loss: 0.003424071241170168\n",
      "Epoch 4506, Loss: 0.04081057384610176, Final Batch Loss: 0.01800418272614479\n",
      "Epoch 4507, Loss: 0.035045504570007324, Final Batch Loss: 0.01587262935936451\n",
      "Epoch 4508, Loss: 0.08774929866194725, Final Batch Loss: 0.03335927426815033\n",
      "Epoch 4509, Loss: 0.04782852344214916, Final Batch Loss: 0.03356628865003586\n",
      "Epoch 4510, Loss: 0.058946412056684494, Final Batch Loss: 0.028480347245931625\n",
      "Epoch 4511, Loss: 0.08660721406340599, Final Batch Loss: 0.045253705233335495\n",
      "Epoch 4512, Loss: 0.025111348368227482, Final Batch Loss: 0.01811775378882885\n",
      "Epoch 4513, Loss: 0.05463992618024349, Final Batch Loss: 0.034737128764390945\n",
      "Epoch 4514, Loss: 0.018192180432379246, Final Batch Loss: 0.00860551930963993\n",
      "Epoch 4515, Loss: 0.049934931099414825, Final Batch Loss: 0.017152126878499985\n",
      "Epoch 4516, Loss: 0.06062051095068455, Final Batch Loss: 0.03873460739850998\n",
      "Epoch 4517, Loss: 0.0702609084546566, Final Batch Loss: 0.03715313971042633\n",
      "Epoch 4518, Loss: 0.060814681462943554, Final Batch Loss: 0.01351307611912489\n",
      "Epoch 4519, Loss: 0.02764155389741063, Final Batch Loss: 0.004355097655206919\n",
      "Epoch 4520, Loss: 0.04347681999206543, Final Batch Loss: 0.02376653254032135\n",
      "Epoch 4521, Loss: 0.02157503180205822, Final Batch Loss: 0.007877537980675697\n",
      "Epoch 4522, Loss: 0.07622171565890312, Final Batch Loss: 0.04859958589076996\n",
      "Epoch 4523, Loss: 0.057063596323132515, Final Batch Loss: 0.012546291574835777\n",
      "Epoch 4524, Loss: 0.02729792520403862, Final Batch Loss: 0.017747625708580017\n",
      "Epoch 4525, Loss: 0.03216465190052986, Final Batch Loss: 0.010487321764230728\n",
      "Epoch 4526, Loss: 0.04518702067434788, Final Batch Loss: 0.02135622687637806\n",
      "Epoch 4527, Loss: 0.057364095002412796, Final Batch Loss: 0.037095941603183746\n",
      "Epoch 4528, Loss: 0.03314728569239378, Final Batch Loss: 0.012392873875796795\n",
      "Epoch 4529, Loss: 0.052866918966174126, Final Batch Loss: 0.024153273552656174\n",
      "Epoch 4530, Loss: 0.07200245838612318, Final Batch Loss: 0.05777416750788689\n",
      "Epoch 4531, Loss: 0.04922458715736866, Final Batch Loss: 0.02124251052737236\n",
      "Epoch 4532, Loss: 0.02919012401252985, Final Batch Loss: 0.009131808765232563\n",
      "Epoch 4533, Loss: 0.05808344855904579, Final Batch Loss: 0.025166399776935577\n",
      "Epoch 4534, Loss: 0.07166075520217419, Final Batch Loss: 0.06042163074016571\n",
      "Epoch 4535, Loss: 0.08780176192522049, Final Batch Loss: 0.046895068138837814\n",
      "Epoch 4536, Loss: 0.08215642347931862, Final Batch Loss: 0.04703212156891823\n",
      "Epoch 4537, Loss: 0.034342752769589424, Final Batch Loss: 0.008492426946759224\n",
      "Epoch 4538, Loss: 0.06868059374392033, Final Batch Loss: 0.031147079542279243\n",
      "Epoch 4539, Loss: 0.052873603999614716, Final Batch Loss: 0.02476349100470543\n",
      "Epoch 4540, Loss: 0.0595913901925087, Final Batch Loss: 0.03846113383769989\n",
      "Epoch 4541, Loss: 0.03180365264415741, Final Batch Loss: 0.020547470077872276\n",
      "Epoch 4542, Loss: 0.05477093160152435, Final Batch Loss: 0.01370634138584137\n",
      "Epoch 4543, Loss: 0.05128082260489464, Final Batch Loss: 0.03914982080459595\n",
      "Epoch 4544, Loss: 0.05336449667811394, Final Batch Loss: 0.03084305301308632\n",
      "Epoch 4545, Loss: 0.05480202101171017, Final Batch Loss: 0.03392016515135765\n",
      "Epoch 4546, Loss: 0.044062916189432144, Final Batch Loss: 0.0270624291151762\n",
      "Epoch 4547, Loss: 0.037555236369371414, Final Batch Loss: 0.008013220503926277\n",
      "Epoch 4548, Loss: 0.025913693010807037, Final Batch Loss: 0.013851274736225605\n",
      "Epoch 4549, Loss: 0.04614556208252907, Final Batch Loss: 0.012620076537132263\n",
      "Epoch 4550, Loss: 0.039515161886811256, Final Batch Loss: 0.019633067771792412\n",
      "Epoch 4551, Loss: 0.023072885815054178, Final Batch Loss: 0.004534164909273386\n",
      "Epoch 4552, Loss: 0.07188773341476917, Final Batch Loss: 0.04256754368543625\n",
      "Epoch 4553, Loss: 0.04075692780315876, Final Batch Loss: 0.01633116416633129\n",
      "Epoch 4554, Loss: 0.03719719429500401, Final Batch Loss: 0.0028856650460511446\n",
      "Epoch 4555, Loss: 0.03222137503325939, Final Batch Loss: 0.018815288320183754\n",
      "Epoch 4556, Loss: 0.046046145260334015, Final Batch Loss: 0.022299692034721375\n",
      "Epoch 4557, Loss: 0.029030901845544577, Final Batch Loss: 0.02600139193236828\n",
      "Epoch 4558, Loss: 0.09708640724420547, Final Batch Loss: 0.040452372282743454\n",
      "Epoch 4559, Loss: 0.010438052704557776, Final Batch Loss: 0.003485617460682988\n",
      "Epoch 4560, Loss: 0.06464217230677605, Final Batch Loss: 0.048262473195791245\n",
      "Epoch 4561, Loss: 0.04293626546859741, Final Batch Loss: 0.004758324474096298\n",
      "Epoch 4562, Loss: 0.05094560980796814, Final Batch Loss: 0.026902347803115845\n",
      "Epoch 4563, Loss: 0.0408880989998579, Final Batch Loss: 0.01587151549756527\n",
      "Epoch 4564, Loss: 0.014970537507906556, Final Batch Loss: 0.011351467110216618\n",
      "Epoch 4565, Loss: 0.07281076908111572, Final Batch Loss: 0.018156636506319046\n",
      "Epoch 4566, Loss: 0.05022386834025383, Final Batch Loss: 0.016977455466985703\n",
      "Epoch 4567, Loss: 0.04499348998069763, Final Batch Loss: 0.02639317698776722\n",
      "Epoch 4568, Loss: 0.049553923308849335, Final Batch Loss: 0.03211088851094246\n",
      "Epoch 4569, Loss: 0.01146663073450327, Final Batch Loss: 0.007994476705789566\n",
      "Epoch 4570, Loss: 0.024496826343238354, Final Batch Loss: 0.013565187342464924\n",
      "Epoch 4571, Loss: 0.029097951017320156, Final Batch Loss: 0.008509297855198383\n",
      "Epoch 4572, Loss: 0.02749190665781498, Final Batch Loss: 0.007782392203807831\n",
      "Epoch 4573, Loss: 0.07999852858483791, Final Batch Loss: 0.052679579704999924\n",
      "Epoch 4574, Loss: 0.08747402112931013, Final Batch Loss: 0.08122847229242325\n",
      "Epoch 4575, Loss: 0.05071304924786091, Final Batch Loss: 0.010147681459784508\n",
      "Epoch 4576, Loss: 0.05423697270452976, Final Batch Loss: 0.02593272551894188\n",
      "Epoch 4577, Loss: 0.07049937546253204, Final Batch Loss: 0.045264773070812225\n",
      "Epoch 4578, Loss: 0.03444120194762945, Final Batch Loss: 0.023045329377055168\n",
      "Epoch 4579, Loss: 0.07678351644426584, Final Batch Loss: 0.006095291115343571\n",
      "Epoch 4580, Loss: 0.057086361572146416, Final Batch Loss: 0.029842756688594818\n",
      "Epoch 4581, Loss: 0.024179786443710327, Final Batch Loss: 0.011476893909275532\n",
      "Epoch 4582, Loss: 0.03498611692339182, Final Batch Loss: 0.007931091822683811\n",
      "Epoch 4583, Loss: 0.024618866969831288, Final Batch Loss: 0.0014652080135419965\n",
      "Epoch 4584, Loss: 0.049615176394581795, Final Batch Loss: 0.03454633429646492\n",
      "Epoch 4585, Loss: 0.06094757467508316, Final Batch Loss: 0.03269188851118088\n",
      "Epoch 4586, Loss: 0.03668268769979477, Final Batch Loss: 0.010852590203285217\n",
      "Epoch 4587, Loss: 0.04773786850273609, Final Batch Loss: 0.025672171264886856\n",
      "Epoch 4588, Loss: 0.06792275048792362, Final Batch Loss: 0.04804550111293793\n",
      "Epoch 4589, Loss: 0.08329496160149574, Final Batch Loss: 0.05176764726638794\n",
      "Epoch 4590, Loss: 0.06595072150230408, Final Batch Loss: 0.03889576345682144\n",
      "Epoch 4591, Loss: 0.058148118667304516, Final Batch Loss: 0.04399999976158142\n",
      "Epoch 4592, Loss: 0.07594041340053082, Final Batch Loss: 0.04900355637073517\n",
      "Epoch 4593, Loss: 0.07968967407941818, Final Batch Loss: 0.05602819845080376\n",
      "Epoch 4594, Loss: 0.021311636082828045, Final Batch Loss: 0.004079964943230152\n",
      "Epoch 4595, Loss: 0.03791323397308588, Final Batch Loss: 0.014510915614664555\n",
      "Epoch 4596, Loss: 0.016999191138893366, Final Batch Loss: 0.006585933733731508\n",
      "Epoch 4597, Loss: 0.03588131442666054, Final Batch Loss: 0.016467690467834473\n",
      "Epoch 4598, Loss: 0.06294616125524044, Final Batch Loss: 0.03617125004529953\n",
      "Epoch 4599, Loss: 0.028144992422312498, Final Batch Loss: 0.005208426620811224\n",
      "Epoch 4600, Loss: 0.04723260970786214, Final Batch Loss: 0.042733971029520035\n",
      "Epoch 4601, Loss: 0.04778172168880701, Final Batch Loss: 0.014233202673494816\n",
      "Epoch 4602, Loss: 0.0329155633226037, Final Batch Loss: 0.023742735385894775\n",
      "Epoch 4603, Loss: 0.024531924165785313, Final Batch Loss: 0.01478540152311325\n",
      "Epoch 4604, Loss: 0.05033579748123884, Final Batch Loss: 0.040100689977407455\n",
      "Epoch 4605, Loss: 0.036598455626517534, Final Batch Loss: 0.003114823717623949\n",
      "Epoch 4606, Loss: 0.03699868731200695, Final Batch Loss: 0.021786822006106377\n",
      "Epoch 4607, Loss: 0.04951541684567928, Final Batch Loss: 0.03068915568292141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4608, Loss: 0.020187570713460445, Final Batch Loss: 0.011394789442420006\n",
      "Epoch 4609, Loss: 0.031565879471600056, Final Batch Loss: 0.016894929111003876\n",
      "Epoch 4610, Loss: 0.0663855979219079, Final Batch Loss: 0.00815438199788332\n",
      "Epoch 4611, Loss: 0.032147957012057304, Final Batch Loss: 0.016540560871362686\n",
      "Epoch 4612, Loss: 0.032811093144118786, Final Batch Loss: 0.014391676522791386\n",
      "Epoch 4613, Loss: 0.05054265446960926, Final Batch Loss: 0.02928652986884117\n",
      "Epoch 4614, Loss: 0.023880979977548122, Final Batch Loss: 0.010287489742040634\n",
      "Epoch 4615, Loss: 0.03720728540793061, Final Batch Loss: 0.007476492319256067\n",
      "Epoch 4616, Loss: 0.052658991888165474, Final Batch Loss: 0.028512049466371536\n",
      "Epoch 4617, Loss: 0.0308632031083107, Final Batch Loss: 0.02011345513164997\n",
      "Epoch 4618, Loss: 0.035818912088871, Final Batch Loss: 0.025684967637062073\n",
      "Epoch 4619, Loss: 0.0740491934120655, Final Batch Loss: 0.055537257343530655\n",
      "Epoch 4620, Loss: 0.035441553220152855, Final Batch Loss: 0.025599438697099686\n",
      "Epoch 4621, Loss: 0.05843738280236721, Final Batch Loss: 0.04463617503643036\n",
      "Epoch 4622, Loss: 0.04985283222049475, Final Batch Loss: 0.044212568551301956\n",
      "Epoch 4623, Loss: 0.023334389086812735, Final Batch Loss: 0.006205819081515074\n",
      "Epoch 4624, Loss: 0.018632626393809915, Final Batch Loss: 0.0030877983663231134\n",
      "Epoch 4625, Loss: 0.0536518357694149, Final Batch Loss: 0.02905835397541523\n",
      "Epoch 4626, Loss: 0.03172622062265873, Final Batch Loss: 0.015528889372944832\n",
      "Epoch 4627, Loss: 0.04130600579082966, Final Batch Loss: 0.021712295711040497\n",
      "Epoch 4628, Loss: 0.04104890674352646, Final Batch Loss: 0.019610758870840073\n",
      "Epoch 4629, Loss: 0.0603875033557415, Final Batch Loss: 0.038141652941703796\n",
      "Epoch 4630, Loss: 0.1791775356978178, Final Batch Loss: 0.023889077827334404\n",
      "Epoch 4631, Loss: 0.04461781308054924, Final Batch Loss: 0.029032884165644646\n",
      "Epoch 4632, Loss: 0.07466287352144718, Final Batch Loss: 0.02843520976603031\n",
      "Epoch 4633, Loss: 0.030917804688215256, Final Batch Loss: 0.0036084800958633423\n",
      "Epoch 4634, Loss: 0.04023495316505432, Final Batch Loss: 0.021754169836640358\n",
      "Epoch 4635, Loss: 0.06490354798734188, Final Batch Loss: 0.01994905434548855\n",
      "Epoch 4636, Loss: 0.14870217069983482, Final Batch Loss: 0.04720119759440422\n",
      "Epoch 4637, Loss: 0.05027880519628525, Final Batch Loss: 0.023378392681479454\n",
      "Epoch 4638, Loss: 0.05828957352787256, Final Batch Loss: 0.014391017146408558\n",
      "Epoch 4639, Loss: 0.05148480739444494, Final Batch Loss: 0.013576156459748745\n",
      "Epoch 4640, Loss: 0.016118203289806843, Final Batch Loss: 0.006933433935046196\n",
      "Epoch 4641, Loss: 0.03014755412004888, Final Batch Loss: 0.003589007770642638\n",
      "Epoch 4642, Loss: 0.04532776027917862, Final Batch Loss: 0.00789908692240715\n",
      "Epoch 4643, Loss: 0.018962533213198185, Final Batch Loss: 0.004631277173757553\n",
      "Epoch 4644, Loss: 0.027098240330815315, Final Batch Loss: 0.011758890002965927\n",
      "Epoch 4645, Loss: 0.02946457825601101, Final Batch Loss: 0.02077009528875351\n",
      "Epoch 4646, Loss: 0.04614953696727753, Final Batch Loss: 0.013035021722316742\n",
      "Epoch 4647, Loss: 0.023546379059553146, Final Batch Loss: 0.008549144491553307\n",
      "Epoch 4648, Loss: 0.02287113480269909, Final Batch Loss: 0.005681293085217476\n",
      "Epoch 4649, Loss: 0.03345666406676173, Final Batch Loss: 0.02674402855336666\n",
      "Epoch 4650, Loss: 0.02822938933968544, Final Batch Loss: 0.005046779289841652\n",
      "Epoch 4651, Loss: 0.03330139024183154, Final Batch Loss: 0.005143407266587019\n",
      "Epoch 4652, Loss: 0.04442291334271431, Final Batch Loss: 0.016587452962994576\n",
      "Epoch 4653, Loss: 0.0202519241720438, Final Batch Loss: 0.012821299955248833\n",
      "Epoch 4654, Loss: 0.027324541471898556, Final Batch Loss: 0.017810385674238205\n",
      "Epoch 4655, Loss: 0.0709436722099781, Final Batch Loss: 0.03885416314005852\n",
      "Epoch 4656, Loss: 0.04905066266655922, Final Batch Loss: 0.022980963811278343\n",
      "Epoch 4657, Loss: 0.08148057386279106, Final Batch Loss: 0.04653530567884445\n",
      "Epoch 4658, Loss: 0.20994197949767113, Final Batch Loss: 0.03905637189745903\n",
      "Epoch 4659, Loss: 0.025983999483287334, Final Batch Loss: 0.007681882940232754\n",
      "Epoch 4660, Loss: 0.04157298803329468, Final Batch Loss: 0.029458502307534218\n",
      "Epoch 4661, Loss: 0.02608313038945198, Final Batch Loss: 0.017572443932294846\n",
      "Epoch 4662, Loss: 0.05208873748779297, Final Batch Loss: 0.01612205058336258\n",
      "Epoch 4663, Loss: 0.054265640676021576, Final Batch Loss: 0.024138567969202995\n",
      "Epoch 4664, Loss: 0.02180987922474742, Final Batch Loss: 0.0069712321273982525\n",
      "Epoch 4665, Loss: 0.03362609911710024, Final Batch Loss: 0.025496793910861015\n",
      "Epoch 4666, Loss: 0.03669967129826546, Final Batch Loss: 0.019152425229549408\n",
      "Epoch 4667, Loss: 0.020081039052456617, Final Batch Loss: 0.0042985281907022\n",
      "Epoch 4668, Loss: 0.04343896731734276, Final Batch Loss: 0.03105110675096512\n",
      "Epoch 4669, Loss: 0.04158635716885328, Final Batch Loss: 0.006919573061168194\n",
      "Epoch 4670, Loss: 0.07022894639521837, Final Batch Loss: 0.05625998601317406\n",
      "Epoch 4671, Loss: 0.035538909025490284, Final Batch Loss: 0.024327201768755913\n",
      "Epoch 4672, Loss: 0.026520241983234882, Final Batch Loss: 0.009912536479532719\n",
      "Epoch 4673, Loss: 0.05896110273897648, Final Batch Loss: 0.03913510590791702\n",
      "Epoch 4674, Loss: 0.04676067642867565, Final Batch Loss: 0.016166774556040764\n",
      "Epoch 4675, Loss: 0.053249442018568516, Final Batch Loss: 0.0377940908074379\n",
      "Epoch 4676, Loss: 0.026404784992337227, Final Batch Loss: 0.018546568229794502\n",
      "Epoch 4677, Loss: 0.043730078265070915, Final Batch Loss: 0.02360265515744686\n",
      "Epoch 4678, Loss: 0.02450061170384288, Final Batch Loss: 0.01734398864209652\n",
      "Epoch 4679, Loss: 0.03771498100832105, Final Batch Loss: 0.006633928511291742\n",
      "Epoch 4680, Loss: 0.029354541562497616, Final Batch Loss: 0.013354736380279064\n",
      "Epoch 4681, Loss: 0.05310371704399586, Final Batch Loss: 0.03711925074458122\n",
      "Epoch 4682, Loss: 0.025397063232958317, Final Batch Loss: 0.019761204719543457\n",
      "Epoch 4683, Loss: 0.027975089848041534, Final Batch Loss: 0.01695011928677559\n",
      "Epoch 4684, Loss: 0.06080352142453194, Final Batch Loss: 0.029687020927667618\n",
      "Epoch 4685, Loss: 0.031189308501780033, Final Batch Loss: 0.017520321533083916\n",
      "Epoch 4686, Loss: 0.022872001631185412, Final Batch Loss: 0.002822232199832797\n",
      "Epoch 4687, Loss: 0.03535879775881767, Final Batch Loss: 0.015685729682445526\n",
      "Epoch 4688, Loss: 0.10781634971499443, Final Batch Loss: 0.06529392302036285\n",
      "Epoch 4689, Loss: 0.04246120061725378, Final Batch Loss: 0.02745581604540348\n",
      "Epoch 4690, Loss: 0.030590123031288385, Final Batch Loss: 0.005082112271338701\n",
      "Epoch 4691, Loss: 0.044561900198459625, Final Batch Loss: 0.021573934704065323\n",
      "Epoch 4692, Loss: 0.028941131196916103, Final Batch Loss: 0.0065324148163199425\n",
      "Epoch 4693, Loss: 0.06633740104734898, Final Batch Loss: 0.03735712915658951\n",
      "Epoch 4694, Loss: 0.09680771455168724, Final Batch Loss: 0.06433549523353577\n",
      "Epoch 4695, Loss: 0.033333027735352516, Final Batch Loss: 0.01683436892926693\n",
      "Epoch 4696, Loss: 0.018923364114016294, Final Batch Loss: 0.006510643754154444\n",
      "Epoch 4697, Loss: 0.03294508485123515, Final Batch Loss: 0.0269725751131773\n",
      "Epoch 4698, Loss: 0.006321469787508249, Final Batch Loss: 0.002947546076029539\n",
      "Epoch 4699, Loss: 0.02591012232005596, Final Batch Loss: 0.017527665942907333\n",
      "Epoch 4700, Loss: 0.06968855112791061, Final Batch Loss: 0.05187775939702988\n",
      "Epoch 4701, Loss: 0.03322387579828501, Final Batch Loss: 0.023012153804302216\n",
      "Epoch 4702, Loss: 0.03347288491204381, Final Batch Loss: 0.027303634211421013\n",
      "Epoch 4703, Loss: 0.03874839097261429, Final Batch Loss: 0.019032234326004982\n",
      "Epoch 4704, Loss: 0.035571685060858727, Final Batch Loss: 0.008850939571857452\n",
      "Epoch 4705, Loss: 0.0239340765401721, Final Batch Loss: 0.009339862503111362\n",
      "Epoch 4706, Loss: 0.10632647201418877, Final Batch Loss: 0.08124437928199768\n",
      "Epoch 4707, Loss: 0.07389296405017376, Final Batch Loss: 0.048827674239873886\n",
      "Epoch 4708, Loss: 0.050585320219397545, Final Batch Loss: 0.029956793412566185\n",
      "Epoch 4709, Loss: 0.06142393685877323, Final Batch Loss: 0.025435222312808037\n",
      "Epoch 4710, Loss: 0.024688060395419598, Final Batch Loss: 0.004353857599198818\n",
      "Epoch 4711, Loss: 0.06798964273184538, Final Batch Loss: 0.058325812220573425\n",
      "Epoch 4712, Loss: 0.019928008317947388, Final Batch Loss: 0.00918112974613905\n",
      "Epoch 4713, Loss: 0.013715469744056463, Final Batch Loss: 0.0074056037701666355\n",
      "Epoch 4714, Loss: 0.012835305649787188, Final Batch Loss: 0.008060709573328495\n",
      "Epoch 4715, Loss: 0.02955014444887638, Final Batch Loss: 0.008359948173165321\n",
      "Epoch 4716, Loss: 0.12455014139413834, Final Batch Loss: 0.06239592283964157\n",
      "Epoch 4717, Loss: 0.07914619147777557, Final Batch Loss: 0.055219829082489014\n",
      "Epoch 4718, Loss: 0.07558578625321388, Final Batch Loss: 0.04303980618715286\n",
      "Epoch 4719, Loss: 0.023093107156455517, Final Batch Loss: 0.013788735494017601\n",
      "Epoch 4720, Loss: 0.07653788663446903, Final Batch Loss: 0.052566953003406525\n",
      "Epoch 4721, Loss: 0.026731451973319054, Final Batch Loss: 0.0064315032213926315\n",
      "Epoch 4722, Loss: 0.025063873268663883, Final Batch Loss: 0.012665331363677979\n",
      "Epoch 4723, Loss: 0.055801739916205406, Final Batch Loss: 0.03148646280169487\n",
      "Epoch 4724, Loss: 0.23562975507229567, Final Batch Loss: 0.012832450680434704\n",
      "Epoch 4725, Loss: 0.07463922584429383, Final Batch Loss: 0.06852301210165024\n",
      "Epoch 4726, Loss: 0.0576349850744009, Final Batch Loss: 0.03206716477870941\n",
      "Epoch 4727, Loss: 0.033385882154107094, Final Batch Loss: 0.009957954287528992\n",
      "Epoch 4728, Loss: 0.06462776474654675, Final Batch Loss: 0.04621600732207298\n",
      "Epoch 4729, Loss: 0.0340422298759222, Final Batch Loss: 0.019362427294254303\n",
      "Epoch 4730, Loss: 0.044042423367500305, Final Batch Loss: 0.03617735952138901\n",
      "Epoch 4731, Loss: 0.04501296579837799, Final Batch Loss: 0.0236761886626482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4732, Loss: 0.0449655968695879, Final Batch Loss: 0.032367706298828125\n",
      "Epoch 4733, Loss: 0.027405750937759876, Final Batch Loss: 0.005770317278802395\n",
      "Epoch 4734, Loss: 0.07708261162042618, Final Batch Loss: 0.03589228168129921\n",
      "Epoch 4735, Loss: 0.05157384555786848, Final Batch Loss: 0.038898371160030365\n",
      "Epoch 4736, Loss: 0.04301067441701889, Final Batch Loss: 0.013137996196746826\n",
      "Epoch 4737, Loss: 0.018483224557712674, Final Batch Loss: 0.015226674266159534\n",
      "Epoch 4738, Loss: 0.046500956639647484, Final Batch Loss: 0.028619468212127686\n",
      "Epoch 4739, Loss: 0.08420176804065704, Final Batch Loss: 0.06864803284406662\n",
      "Epoch 4740, Loss: 0.04545214772224426, Final Batch Loss: 0.016817988827824593\n",
      "Epoch 4741, Loss: 0.03709980100393295, Final Batch Loss: 0.01866946369409561\n",
      "Epoch 4742, Loss: 0.028152827639132738, Final Batch Loss: 0.0028254021890461445\n",
      "Epoch 4743, Loss: 0.07810785993933678, Final Batch Loss: 0.055673304945230484\n",
      "Epoch 4744, Loss: 0.04813570901751518, Final Batch Loss: 0.008680813014507294\n",
      "Epoch 4745, Loss: 0.028291492722928524, Final Batch Loss: 0.011349706910550594\n",
      "Epoch 4746, Loss: 0.03330387361347675, Final Batch Loss: 0.020118048414587975\n",
      "Epoch 4747, Loss: 0.08444958832114935, Final Batch Loss: 0.010445660911500454\n",
      "Epoch 4748, Loss: 0.06597188487648964, Final Batch Loss: 0.043327320367097855\n",
      "Epoch 4749, Loss: 0.059417860582470894, Final Batch Loss: 0.050985634326934814\n",
      "Epoch 4750, Loss: 0.06447605229914188, Final Batch Loss: 0.023863201960921288\n",
      "Epoch 4751, Loss: 0.030914297327399254, Final Batch Loss: 0.02152175083756447\n",
      "Epoch 4752, Loss: 0.05312957428395748, Final Batch Loss: 0.037081360816955566\n",
      "Epoch 4753, Loss: 0.06348868645727634, Final Batch Loss: 0.025256993249058723\n",
      "Epoch 4754, Loss: 0.02395590953528881, Final Batch Loss: 0.01049260888248682\n",
      "Epoch 4755, Loss: 0.03581366315484047, Final Batch Loss: 0.024829979985952377\n",
      "Epoch 4756, Loss: 0.03797663655132055, Final Batch Loss: 0.014059801585972309\n",
      "Epoch 4757, Loss: 0.052794959396123886, Final Batch Loss: 0.016315899789333344\n",
      "Epoch 4758, Loss: 0.01833464065566659, Final Batch Loss: 0.007220034953206778\n",
      "Epoch 4759, Loss: 0.011557440739125013, Final Batch Loss: 0.006612774450331926\n",
      "Epoch 4760, Loss: 0.02258103946223855, Final Batch Loss: 0.01923726499080658\n",
      "Epoch 4761, Loss: 0.018109839409589767, Final Batch Loss: 0.005187242291867733\n",
      "Epoch 4762, Loss: 0.03720981488004327, Final Batch Loss: 0.02985411323606968\n",
      "Epoch 4763, Loss: 0.013433339074254036, Final Batch Loss: 0.006687637884169817\n",
      "Epoch 4764, Loss: 0.02831867802888155, Final Batch Loss: 0.010571970604360104\n",
      "Epoch 4765, Loss: 0.03918445482850075, Final Batch Loss: 0.01805036887526512\n",
      "Epoch 4766, Loss: 0.03290023375302553, Final Batch Loss: 0.02017621323466301\n",
      "Epoch 4767, Loss: 0.0609355578199029, Final Batch Loss: 0.011240311898291111\n",
      "Epoch 4768, Loss: 0.035373357124626637, Final Batch Loss: 0.011636362411081791\n",
      "Epoch 4769, Loss: 0.011055071372538805, Final Batch Loss: 0.005859047640115023\n",
      "Epoch 4770, Loss: 0.019925895147025585, Final Batch Loss: 0.008278481662273407\n",
      "Epoch 4771, Loss: 0.026164749637246132, Final Batch Loss: 0.008745143190026283\n",
      "Epoch 4772, Loss: 0.06370584387332201, Final Batch Loss: 0.015127797611057758\n",
      "Epoch 4773, Loss: 0.02284002350643277, Final Batch Loss: 0.004038170445710421\n",
      "Epoch 4774, Loss: 0.03036627359688282, Final Batch Loss: 0.016451913863420486\n",
      "Epoch 4775, Loss: 0.027675248216837645, Final Batch Loss: 0.007383353542536497\n",
      "Epoch 4776, Loss: 0.020347016397863626, Final Batch Loss: 0.014211677946150303\n",
      "Epoch 4777, Loss: 0.0632234551012516, Final Batch Loss: 0.038685206323862076\n",
      "Epoch 4778, Loss: 0.042946976609528065, Final Batch Loss: 0.011834134347736835\n",
      "Epoch 4779, Loss: 0.04374726954847574, Final Batch Loss: 0.012549732811748981\n",
      "Epoch 4780, Loss: 0.06049295188859105, Final Batch Loss: 0.05470949038863182\n",
      "Epoch 4781, Loss: 0.04599962569773197, Final Batch Loss: 0.008206801488995552\n",
      "Epoch 4782, Loss: 0.015439820475876331, Final Batch Loss: 0.008555781096220016\n",
      "Epoch 4783, Loss: 0.014137454330921173, Final Batch Loss: 0.008474020287394524\n",
      "Epoch 4784, Loss: 0.01668434194289148, Final Batch Loss: 0.003053763648495078\n",
      "Epoch 4785, Loss: 0.009024863597005606, Final Batch Loss: 0.0053713200613856316\n",
      "Epoch 4786, Loss: 0.08041694480925798, Final Batch Loss: 0.06837348639965057\n",
      "Epoch 4787, Loss: 0.030970824183896184, Final Batch Loss: 0.003513868199661374\n",
      "Epoch 4788, Loss: 0.04634907562285662, Final Batch Loss: 0.013378617353737354\n",
      "Epoch 4789, Loss: 0.0759231187403202, Final Batch Loss: 0.02931394800543785\n",
      "Epoch 4790, Loss: 0.06190790981054306, Final Batch Loss: 0.017706528306007385\n",
      "Epoch 4791, Loss: 0.034379140473902225, Final Batch Loss: 0.011162330396473408\n",
      "Epoch 4792, Loss: 0.04513873532414436, Final Batch Loss: 0.019244665279984474\n",
      "Epoch 4793, Loss: 0.009420670568943024, Final Batch Loss: 0.005879627075046301\n",
      "Epoch 4794, Loss: 0.051143365912139416, Final Batch Loss: 0.03743914142251015\n",
      "Epoch 4795, Loss: 0.03946493286639452, Final Batch Loss: 0.027824468910694122\n",
      "Epoch 4796, Loss: 0.05301445722579956, Final Batch Loss: 0.02818523719906807\n",
      "Epoch 4797, Loss: 0.11519999615848064, Final Batch Loss: 0.027472546324133873\n",
      "Epoch 4798, Loss: 0.08119886182248592, Final Batch Loss: 0.025767339393496513\n",
      "Epoch 4799, Loss: 0.03322042338550091, Final Batch Loss: 0.018809694796800613\n",
      "Epoch 4800, Loss: 0.040671081747859716, Final Batch Loss: 0.0075575015507638454\n",
      "Epoch 4801, Loss: 0.06723728682845831, Final Batch Loss: 0.012232533656060696\n",
      "Epoch 4802, Loss: 0.08953253272920847, Final Batch Loss: 0.07943768799304962\n",
      "Epoch 4803, Loss: 0.020631413906812668, Final Batch Loss: 0.010219313204288483\n",
      "Epoch 4804, Loss: 0.01700108265504241, Final Batch Loss: 0.006461623590439558\n",
      "Epoch 4805, Loss: 0.030370694119483232, Final Batch Loss: 0.02283557318150997\n",
      "Epoch 4806, Loss: 0.04028616286814213, Final Batch Loss: 0.023166418075561523\n",
      "Epoch 4807, Loss: 0.06482413224875927, Final Batch Loss: 0.03513789549469948\n",
      "Epoch 4808, Loss: 0.061233459040522575, Final Batch Loss: 0.037660688161849976\n",
      "Epoch 4809, Loss: 0.07334899716079235, Final Batch Loss: 0.06019841507077217\n",
      "Epoch 4810, Loss: 0.05532805249094963, Final Batch Loss: 0.03149896860122681\n",
      "Epoch 4811, Loss: 0.05004596617072821, Final Batch Loss: 0.010641015134751797\n",
      "Epoch 4812, Loss: 0.046811191365122795, Final Batch Loss: 0.028124762699007988\n",
      "Epoch 4813, Loss: 0.018313156440854073, Final Batch Loss: 0.008710956200957298\n",
      "Epoch 4814, Loss: 0.06438284832984209, Final Batch Loss: 0.008901887573301792\n",
      "Epoch 4815, Loss: 0.03770744800567627, Final Batch Loss: 0.011225845664739609\n",
      "Epoch 4816, Loss: 0.04832269810140133, Final Batch Loss: 0.0402257964015007\n",
      "Epoch 4817, Loss: 0.06582261994481087, Final Batch Loss: 0.044812001287937164\n",
      "Epoch 4818, Loss: 0.04045656695961952, Final Batch Loss: 0.020532747730612755\n",
      "Epoch 4819, Loss: 0.029592884704470634, Final Batch Loss: 0.01813633181154728\n",
      "Epoch 4820, Loss: 0.04945242777466774, Final Batch Loss: 0.029155943542718887\n",
      "Epoch 4821, Loss: 0.061826542019844055, Final Batch Loss: 0.024191074073314667\n",
      "Epoch 4822, Loss: 0.04028616473078728, Final Batch Loss: 0.016732696443796158\n",
      "Epoch 4823, Loss: 0.07572583295404911, Final Batch Loss: 0.04980131611227989\n",
      "Epoch 4824, Loss: 0.09147490188479424, Final Batch Loss: 0.05923578143119812\n",
      "Epoch 4825, Loss: 0.0681051667779684, Final Batch Loss: 0.03095482476055622\n",
      "Epoch 4826, Loss: 0.08310987614095211, Final Batch Loss: 0.06298921257257462\n",
      "Epoch 4827, Loss: 0.026845745742321014, Final Batch Loss: 0.01591702550649643\n",
      "Epoch 4828, Loss: 0.03267310839146376, Final Batch Loss: 0.018745897337794304\n",
      "Epoch 4829, Loss: 0.03166963532567024, Final Batch Loss: 0.02369684725999832\n",
      "Epoch 4830, Loss: 0.08115858025848866, Final Batch Loss: 0.06375636160373688\n",
      "Epoch 4831, Loss: 0.07181232050061226, Final Batch Loss: 0.03676396980881691\n",
      "Epoch 4832, Loss: 0.04850266873836517, Final Batch Loss: 0.022563347592949867\n",
      "Epoch 4833, Loss: 0.04759389441460371, Final Batch Loss: 0.03755097836256027\n",
      "Epoch 4834, Loss: 0.04964457731693983, Final Batch Loss: 0.008106584660708904\n",
      "Epoch 4835, Loss: 0.035764857195317745, Final Batch Loss: 0.010440890677273273\n",
      "Epoch 4836, Loss: 0.07646412216126919, Final Batch Loss: 0.07056895643472672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4837, Loss: 0.043437860207632184, Final Batch Loss: 0.0031878382433205843\n",
      "Epoch 4838, Loss: 0.05822737701237202, Final Batch Loss: 0.04547152668237686\n",
      "Epoch 4839, Loss: 0.020229455083608627, Final Batch Loss: 0.01132376678287983\n",
      "Epoch 4840, Loss: 0.0754506029188633, Final Batch Loss: 0.0395735539495945\n",
      "Epoch 4841, Loss: 0.01745130540803075, Final Batch Loss: 0.005293041933327913\n",
      "Epoch 4842, Loss: 0.03281147126108408, Final Batch Loss: 0.00928403902798891\n",
      "Epoch 4843, Loss: 0.08422750979661942, Final Batch Loss: 0.01840360462665558\n",
      "Epoch 4844, Loss: 0.02663939632475376, Final Batch Loss: 0.018537990748882294\n",
      "Epoch 4845, Loss: 0.03993136901408434, Final Batch Loss: 0.015347021631896496\n",
      "Epoch 4846, Loss: 0.05224723555147648, Final Batch Loss: 0.032569848001003265\n",
      "Epoch 4847, Loss: 0.021772019565105438, Final Batch Loss: 0.01230320893228054\n",
      "Epoch 4848, Loss: 0.025259443558752537, Final Batch Loss: 0.015621691942214966\n",
      "Epoch 4849, Loss: 0.06366687454283237, Final Batch Loss: 0.01915859617292881\n",
      "Epoch 4850, Loss: 0.03393076080828905, Final Batch Loss: 0.007659369148313999\n",
      "Epoch 4851, Loss: 0.04283595830202103, Final Batch Loss: 0.03291498124599457\n",
      "Epoch 4852, Loss: 0.016562446486204863, Final Batch Loss: 0.006297834683209658\n",
      "Epoch 4853, Loss: 0.017549637705087662, Final Batch Loss: 0.008996870368719101\n",
      "Epoch 4854, Loss: 0.040997181087732315, Final Batch Loss: 0.013391217216849327\n",
      "Epoch 4855, Loss: 0.027859645429998636, Final Batch Loss: 0.005565835628658533\n",
      "Epoch 4856, Loss: 0.013411017134785652, Final Batch Loss: 0.009491883218288422\n",
      "Epoch 4857, Loss: 0.09955092892050743, Final Batch Loss: 0.04239639639854431\n",
      "Epoch 4858, Loss: 0.026973020285367966, Final Batch Loss: 0.0063664596527814865\n",
      "Epoch 4859, Loss: 0.020576720125973225, Final Batch Loss: 0.004779173992574215\n",
      "Epoch 4860, Loss: 0.03879807237535715, Final Batch Loss: 0.03222815692424774\n",
      "Epoch 4861, Loss: 0.03183820564299822, Final Batch Loss: 0.02159414067864418\n",
      "Epoch 4862, Loss: 0.04763201251626015, Final Batch Loss: 0.03718532249331474\n",
      "Epoch 4863, Loss: 0.0642313938587904, Final Batch Loss: 0.019820308312773705\n",
      "Epoch 4864, Loss: 0.05137595208361745, Final Batch Loss: 0.004768047947436571\n",
      "Epoch 4865, Loss: 0.04275207594037056, Final Batch Loss: 0.0217361468821764\n",
      "Epoch 4866, Loss: 0.012804431142285466, Final Batch Loss: 0.0028179476503282785\n",
      "Epoch 4867, Loss: 0.02781346719712019, Final Batch Loss: 0.011195163242518902\n",
      "Epoch 4868, Loss: 0.02401318307965994, Final Batch Loss: 0.00974941160529852\n",
      "Epoch 4869, Loss: 0.016380190616473556, Final Batch Loss: 0.003381365677341819\n",
      "Epoch 4870, Loss: 0.015059920959174633, Final Batch Loss: 0.0028969543054699898\n",
      "Epoch 4871, Loss: 0.017682083416730165, Final Batch Loss: 0.005069735925644636\n",
      "Epoch 4872, Loss: 0.046181969344615936, Final Batch Loss: 0.013445913791656494\n",
      "Epoch 4873, Loss: 0.06007116660475731, Final Batch Loss: 0.0499890074133873\n",
      "Epoch 4874, Loss: 0.06402672454714775, Final Batch Loss: 0.02569180727005005\n",
      "Epoch 4875, Loss: 0.04964635148644447, Final Batch Loss: 0.00998850166797638\n",
      "Epoch 4876, Loss: 0.03419232647866011, Final Batch Loss: 0.022380774840712547\n",
      "Epoch 4877, Loss: 0.07615558244287968, Final Batch Loss: 0.02823827601969242\n",
      "Epoch 4878, Loss: 0.047966647893190384, Final Batch Loss: 0.02502363547682762\n",
      "Epoch 4879, Loss: 0.035866412334144115, Final Batch Loss: 0.02490958757698536\n",
      "Epoch 4880, Loss: 0.023483602330088615, Final Batch Loss: 0.01002199575304985\n",
      "Epoch 4881, Loss: 0.03560828883200884, Final Batch Loss: 0.010950573720037937\n",
      "Epoch 4882, Loss: 0.016876470763236284, Final Batch Loss: 0.006552592385560274\n",
      "Epoch 4883, Loss: 0.027053761295974255, Final Batch Loss: 0.009401560761034489\n",
      "Epoch 4884, Loss: 0.07249440252780914, Final Batch Loss: 0.03474724292755127\n",
      "Epoch 4885, Loss: 0.08434787206351757, Final Batch Loss: 0.07634926587343216\n",
      "Epoch 4886, Loss: 0.03492654673755169, Final Batch Loss: 0.013629792258143425\n",
      "Epoch 4887, Loss: 0.08286605030298233, Final Batch Loss: 0.06629212200641632\n",
      "Epoch 4888, Loss: 0.01952325738966465, Final Batch Loss: 0.011425447650253773\n",
      "Epoch 4889, Loss: 0.05072464980185032, Final Batch Loss: 0.017704689875245094\n",
      "Epoch 4890, Loss: 0.04248202499002218, Final Batch Loss: 0.015085848979651928\n",
      "Epoch 4891, Loss: 0.029013755032792687, Final Batch Loss: 0.0034696387592703104\n",
      "Epoch 4892, Loss: 0.043309563770890236, Final Batch Loss: 0.03316938504576683\n",
      "Epoch 4893, Loss: 0.05664936453104019, Final Batch Loss: 0.026999851688742638\n",
      "Epoch 4894, Loss: 0.08077746629714966, Final Batch Loss: 0.02134733647108078\n",
      "Epoch 4895, Loss: 0.05901504121720791, Final Batch Loss: 0.027937453240156174\n",
      "Epoch 4896, Loss: 0.041774556040763855, Final Batch Loss: 0.014485882595181465\n",
      "Epoch 4897, Loss: 0.06171899475157261, Final Batch Loss: 0.01603085733950138\n",
      "Epoch 4898, Loss: 0.06068745627999306, Final Batch Loss: 0.03267252817749977\n",
      "Epoch 4899, Loss: 0.014023176860064268, Final Batch Loss: 0.008925288915634155\n",
      "Epoch 4900, Loss: 0.058821409940719604, Final Batch Loss: 0.01884271577000618\n",
      "Epoch 4901, Loss: 0.05954667180776596, Final Batch Loss: 0.027845349162817\n",
      "Epoch 4902, Loss: 0.037183426320552826, Final Batch Loss: 0.024511700496077538\n",
      "Epoch 4903, Loss: 0.028476987965404987, Final Batch Loss: 0.010469942353665829\n",
      "Epoch 4904, Loss: 0.06015203893184662, Final Batch Loss: 0.04865239933133125\n",
      "Epoch 4905, Loss: 0.03382916934788227, Final Batch Loss: 0.004807703197002411\n",
      "Epoch 4906, Loss: 0.06438888423144817, Final Batch Loss: 0.0487992949783802\n",
      "Epoch 4907, Loss: 0.029060675762593746, Final Batch Loss: 0.010611404664814472\n",
      "Epoch 4908, Loss: 0.026638785609975457, Final Batch Loss: 0.0030577334109693766\n",
      "Epoch 4909, Loss: 0.047878109849989414, Final Batch Loss: 0.010492698289453983\n",
      "Epoch 4910, Loss: 0.05720251239836216, Final Batch Loss: 0.02077850140631199\n",
      "Epoch 4911, Loss: 0.02444468718022108, Final Batch Loss: 0.0058139776811003685\n",
      "Epoch 4912, Loss: 0.03800249006599188, Final Batch Loss: 0.010542170144617558\n",
      "Epoch 4913, Loss: 0.043206432834267616, Final Batch Loss: 0.033005837351083755\n",
      "Epoch 4914, Loss: 0.05341523792594671, Final Batch Loss: 0.04255449399352074\n",
      "Epoch 4915, Loss: 0.05757760442793369, Final Batch Loss: 0.022816987708210945\n",
      "Epoch 4916, Loss: 0.09046151861548424, Final Batch Loss: 0.030857618898153305\n",
      "Epoch 4917, Loss: 0.08896395564079285, Final Batch Loss: 0.009942427277565002\n",
      "Epoch 4918, Loss: 0.024290106259286404, Final Batch Loss: 0.002606731839478016\n",
      "Epoch 4919, Loss: 0.023043815977871418, Final Batch Loss: 0.01714971475303173\n",
      "Epoch 4920, Loss: 0.0322858989238739, Final Batch Loss: 0.007869632914662361\n",
      "Epoch 4921, Loss: 0.014041077112779021, Final Batch Loss: 0.002774586668238044\n",
      "Epoch 4922, Loss: 0.06399707496166229, Final Batch Loss: 0.048093464225530624\n",
      "Epoch 4923, Loss: 0.03825748059898615, Final Batch Loss: 0.005414814688265324\n",
      "Epoch 4924, Loss: 0.05644380301237106, Final Batch Loss: 0.03544125333428383\n",
      "Epoch 4925, Loss: 0.019986387342214584, Final Batch Loss: 0.00932804774492979\n",
      "Epoch 4926, Loss: 0.0641394555568695, Final Batch Loss: 0.032493457198143005\n",
      "Epoch 4927, Loss: 0.020038895774632692, Final Batch Loss: 0.014500274322926998\n",
      "Epoch 4928, Loss: 0.03109013382345438, Final Batch Loss: 0.007864878512918949\n",
      "Epoch 4929, Loss: 0.09349801391363144, Final Batch Loss: 0.0608673095703125\n",
      "Epoch 4930, Loss: 0.03956007584929466, Final Batch Loss: 0.012160399928689003\n",
      "Epoch 4931, Loss: 0.028226196765899658, Final Batch Loss: 0.010532928630709648\n",
      "Epoch 4932, Loss: 0.0358650628477335, Final Batch Loss: 0.01058368943631649\n",
      "Epoch 4933, Loss: 0.05250006727874279, Final Batch Loss: 0.02355237491428852\n",
      "Epoch 4934, Loss: 0.04057207517325878, Final Batch Loss: 0.02197587676346302\n",
      "Epoch 4935, Loss: 0.02921593002974987, Final Batch Loss: 0.014363606460392475\n",
      "Epoch 4936, Loss: 0.019836301915347576, Final Batch Loss: 0.00763475988060236\n",
      "Epoch 4937, Loss: 0.03191854525357485, Final Batch Loss: 0.013034620322287083\n",
      "Epoch 4938, Loss: 0.10011907666921616, Final Batch Loss: 0.0873437449336052\n",
      "Epoch 4939, Loss: 0.02847421169281006, Final Batch Loss: 0.004137365147471428\n",
      "Epoch 4940, Loss: 0.022659152280539274, Final Batch Loss: 0.005333497654646635\n",
      "Epoch 4941, Loss: 0.030707665719091892, Final Batch Loss: 0.010622727684676647\n",
      "Epoch 4942, Loss: 0.03399825468659401, Final Batch Loss: 0.02524713985621929\n",
      "Epoch 4943, Loss: 0.030096172355115414, Final Batch Loss: 0.013825449161231518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4944, Loss: 0.0345479529350996, Final Batch Loss: 0.01082288846373558\n",
      "Epoch 4945, Loss: 0.10074398666620255, Final Batch Loss: 0.06399708986282349\n",
      "Epoch 4946, Loss: 0.04414632171392441, Final Batch Loss: 0.012124080210924149\n",
      "Epoch 4947, Loss: 0.05563867464661598, Final Batch Loss: 0.028673820197582245\n",
      "Epoch 4948, Loss: 0.06465079262852669, Final Batch Loss: 0.04080589488148689\n",
      "Epoch 4949, Loss: 0.04881568718701601, Final Batch Loss: 0.013188404031097889\n",
      "Epoch 4950, Loss: 0.027285161428153515, Final Batch Loss: 0.008549981750547886\n",
      "Epoch 4951, Loss: 0.01705992128700018, Final Batch Loss: 0.004262172617018223\n",
      "Epoch 4952, Loss: 0.03276061359792948, Final Batch Loss: 0.008044279180467129\n",
      "Epoch 4953, Loss: 0.0548320934176445, Final Batch Loss: 0.017160508781671524\n",
      "Epoch 4954, Loss: 0.05021301284432411, Final Batch Loss: 0.01752842590212822\n",
      "Epoch 4955, Loss: 0.030647968873381615, Final Batch Loss: 0.021949527785182\n",
      "Epoch 4956, Loss: 0.06142880953848362, Final Batch Loss: 0.03910699114203453\n",
      "Epoch 4957, Loss: 0.055685168132185936, Final Batch Loss: 0.02996617741882801\n",
      "Epoch 4958, Loss: 0.032227905467152596, Final Batch Loss: 0.009745687246322632\n",
      "Epoch 4959, Loss: 0.018755119293928146, Final Batch Loss: 0.013197451829910278\n",
      "Epoch 4960, Loss: 0.04249425930902362, Final Batch Loss: 0.004876795690506697\n",
      "Epoch 4961, Loss: 0.053808122873306274, Final Batch Loss: 0.013550490140914917\n",
      "Epoch 4962, Loss: 0.016220510937273502, Final Batch Loss: 0.009147842414677143\n",
      "Epoch 4963, Loss: 0.029580657370388508, Final Batch Loss: 0.021263914182782173\n",
      "Epoch 4964, Loss: 0.05988919734954834, Final Batch Loss: 0.021705377846956253\n",
      "Epoch 4965, Loss: 0.03777134697884321, Final Batch Loss: 0.024643581360578537\n",
      "Epoch 4966, Loss: 0.05408991686999798, Final Batch Loss: 0.04499349743127823\n",
      "Epoch 4967, Loss: 0.023862685542553663, Final Batch Loss: 0.004544389899820089\n",
      "Epoch 4968, Loss: 0.03793717920780182, Final Batch Loss: 0.013817060738801956\n",
      "Epoch 4969, Loss: 0.030388619750738144, Final Batch Loss: 0.021807271987199783\n",
      "Epoch 4970, Loss: 0.037031032145023346, Final Batch Loss: 0.00972321629524231\n",
      "Epoch 4971, Loss: 0.03260587900876999, Final Batch Loss: 0.0278011541813612\n",
      "Epoch 4972, Loss: 0.031010441947728395, Final Batch Loss: 0.004527749959379435\n",
      "Epoch 4973, Loss: 0.06917177513241768, Final Batch Loss: 0.054083067923784256\n",
      "Epoch 4974, Loss: 0.03772306255996227, Final Batch Loss: 0.01044035516679287\n",
      "Epoch 4975, Loss: 0.04635526426136494, Final Batch Loss: 0.019210591912269592\n",
      "Epoch 4976, Loss: 0.016564870718866587, Final Batch Loss: 0.010182663798332214\n",
      "Epoch 4977, Loss: 0.016287176636978984, Final Batch Loss: 0.00277701742015779\n",
      "Epoch 4978, Loss: 0.02830942254513502, Final Batch Loss: 0.009940742515027523\n",
      "Epoch 4979, Loss: 0.04764006286859512, Final Batch Loss: 0.022502217441797256\n",
      "Epoch 4980, Loss: 0.018518267199397087, Final Batch Loss: 0.00869814958423376\n",
      "Epoch 4981, Loss: 0.016606624703854322, Final Batch Loss: 0.006254497449845076\n",
      "Epoch 4982, Loss: 0.030509937554597855, Final Batch Loss: 0.014587650075554848\n",
      "Epoch 4983, Loss: 0.04988726461306214, Final Batch Loss: 0.04335476830601692\n",
      "Epoch 4984, Loss: 0.04655063897371292, Final Batch Loss: 0.01646595261991024\n",
      "Epoch 4985, Loss: 0.05720449425280094, Final Batch Loss: 0.04477180540561676\n",
      "Epoch 4986, Loss: 0.025216720066964626, Final Batch Loss: 0.01701919175684452\n",
      "Epoch 4987, Loss: 0.044744525104761124, Final Batch Loss: 0.02400842308998108\n",
      "Epoch 4988, Loss: 0.05417269375175238, Final Batch Loss: 0.039503876119852066\n",
      "Epoch 4989, Loss: 0.13363122195005417, Final Batch Loss: 0.0870039090514183\n",
      "Epoch 4990, Loss: 0.03816871903836727, Final Batch Loss: 0.013170151039958\n",
      "Epoch 4991, Loss: 0.08729998953640461, Final Batch Loss: 0.011250795796513557\n",
      "Epoch 4992, Loss: 0.07611119467765093, Final Batch Loss: 0.010020938701927662\n",
      "Epoch 4993, Loss: 0.07550586387515068, Final Batch Loss: 0.03815007954835892\n",
      "Epoch 4994, Loss: 0.037638443522155285, Final Batch Loss: 0.01452163141220808\n",
      "Epoch 4995, Loss: 0.031486835330724716, Final Batch Loss: 0.015642181038856506\n",
      "Epoch 4996, Loss: 0.07408055290579796, Final Batch Loss: 0.04530538246035576\n",
      "Epoch 4997, Loss: 0.08837857283651829, Final Batch Loss: 0.02057567425072193\n",
      "Epoch 4998, Loss: 0.04465254954993725, Final Batch Loss: 0.02528398483991623\n",
      "Epoch 4999, Loss: 0.05351871997117996, Final Batch Loss: 0.03924599289894104\n",
      "Epoch 5000, Loss: 0.03426198661327362, Final Batch Loss: 0.016998164355754852\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  1  1]\n",
      " [ 0 31  1]\n",
      " [ 0  0 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.93103   0.96429        29\n",
      "           1    0.96875   0.96875   0.96875        32\n",
      "           2    0.94737   1.00000   0.97297        36\n",
      "\n",
      "    accuracy                        0.96907        97\n",
      "   macro avg    0.97204   0.96659   0.96867        97\n",
      "weighted avg    0.97016   0.96907   0.96898        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  0  0]\n",
      " [ 0 28  0]\n",
      " [ 0  1 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        37\n",
      "           1    0.96552   1.00000   0.98246        28\n",
      "           2    1.00000   0.96875   0.98413        32\n",
      "\n",
      "    accuracy                        0.98969        97\n",
      "   macro avg    0.98851   0.98958   0.98886        97\n",
      "weighted avg    0.99005   0.98969   0.98970        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
