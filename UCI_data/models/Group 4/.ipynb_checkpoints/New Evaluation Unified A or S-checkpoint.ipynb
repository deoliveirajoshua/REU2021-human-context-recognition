{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [19, 21, 22]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.21428120136261, Final Batch Loss: 1.1156206130981445\n",
      "Epoch 2, Loss: 2.2011531591415405, Final Batch Loss: 1.106269121170044\n",
      "Epoch 3, Loss: 2.1813652515411377, Final Batch Loss: 1.0861399173736572\n",
      "Epoch 4, Loss: 2.1803165674209595, Final Batch Loss: 1.1010513305664062\n",
      "Epoch 5, Loss: 2.169122338294983, Final Batch Loss: 1.0967949628829956\n",
      "Epoch 6, Loss: 2.1556047201156616, Final Batch Loss: 1.0769214630126953\n",
      "Epoch 7, Loss: 2.147786498069763, Final Batch Loss: 1.080621600151062\n",
      "Epoch 8, Loss: 2.1329824924468994, Final Batch Loss: 1.0620627403259277\n",
      "Epoch 9, Loss: 2.124019980430603, Final Batch Loss: 1.0470795631408691\n",
      "Epoch 10, Loss: 2.1124050617218018, Final Batch Loss: 1.0450090169906616\n",
      "Epoch 11, Loss: 2.1111867427825928, Final Batch Loss: 1.057515263557434\n",
      "Epoch 12, Loss: 2.103480577468872, Final Batch Loss: 1.0626769065856934\n",
      "Epoch 13, Loss: 2.0844167470932007, Final Batch Loss: 1.042601466178894\n",
      "Epoch 14, Loss: 2.0730875730514526, Final Batch Loss: 1.0484825372695923\n",
      "Epoch 15, Loss: 2.0628039836883545, Final Batch Loss: 1.0339014530181885\n",
      "Epoch 16, Loss: 2.0474480986595154, Final Batch Loss: 1.0488181114196777\n",
      "Epoch 17, Loss: 2.0202924013137817, Final Batch Loss: 1.0040076971054077\n",
      "Epoch 18, Loss: 2.005101442337036, Final Batch Loss: 1.0090179443359375\n",
      "Epoch 19, Loss: 1.9917511343955994, Final Batch Loss: 1.0107172727584839\n",
      "Epoch 20, Loss: 1.9719944596290588, Final Batch Loss: 0.9996708631515503\n",
      "Epoch 21, Loss: 1.927613079547882, Final Batch Loss: 0.9568912386894226\n",
      "Epoch 22, Loss: 1.9090408086776733, Final Batch Loss: 0.9400142431259155\n",
      "Epoch 23, Loss: 1.9002342820167542, Final Batch Loss: 0.9526788592338562\n",
      "Epoch 24, Loss: 1.8701996803283691, Final Batch Loss: 0.9499797821044922\n",
      "Epoch 25, Loss: 1.8123645782470703, Final Batch Loss: 0.8947191834449768\n",
      "Epoch 26, Loss: 1.7799381613731384, Final Batch Loss: 0.900170087814331\n",
      "Epoch 27, Loss: 1.7285844087600708, Final Batch Loss: 0.8450980186462402\n",
      "Epoch 28, Loss: 1.6815446019172668, Final Batch Loss: 0.8265078067779541\n",
      "Epoch 29, Loss: 1.6373969912528992, Final Batch Loss: 0.8106594085693359\n",
      "Epoch 30, Loss: 1.579445242881775, Final Batch Loss: 0.7949323058128357\n",
      "Epoch 31, Loss: 1.5177353024482727, Final Batch Loss: 0.7480515837669373\n",
      "Epoch 32, Loss: 1.459228277206421, Final Batch Loss: 0.7169763445854187\n",
      "Epoch 33, Loss: 1.3976745009422302, Final Batch Loss: 0.6782236695289612\n",
      "Epoch 34, Loss: 1.3462257981300354, Final Batch Loss: 0.687344491481781\n",
      "Epoch 35, Loss: 1.266743779182434, Final Batch Loss: 0.6358340978622437\n",
      "Epoch 36, Loss: 1.2339650392532349, Final Batch Loss: 0.6386029124259949\n",
      "Epoch 37, Loss: 1.1586159467697144, Final Batch Loss: 0.571186363697052\n",
      "Epoch 38, Loss: 1.0929557085037231, Final Batch Loss: 0.5062990784645081\n",
      "Epoch 39, Loss: 1.0718643069267273, Final Batch Loss: 0.5364931225776672\n",
      "Epoch 40, Loss: 1.0374351739883423, Final Batch Loss: 0.5125308036804199\n",
      "Epoch 41, Loss: 0.9970270991325378, Final Batch Loss: 0.4816420078277588\n",
      "Epoch 42, Loss: 0.927296906709671, Final Batch Loss: 0.4176531732082367\n",
      "Epoch 43, Loss: 0.9282273352146149, Final Batch Loss: 0.4650312662124634\n",
      "Epoch 44, Loss: 0.9069925546646118, Final Batch Loss: 0.44218572974205017\n",
      "Epoch 45, Loss: 0.8925038576126099, Final Batch Loss: 0.4409625232219696\n",
      "Epoch 46, Loss: 0.8141146004199982, Final Batch Loss: 0.32988905906677246\n",
      "Epoch 47, Loss: 0.8328823149204254, Final Batch Loss: 0.4219370186328888\n",
      "Epoch 48, Loss: 0.8016183376312256, Final Batch Loss: 0.37037181854248047\n",
      "Epoch 49, Loss: 0.7931458950042725, Final Batch Loss: 0.3844086825847626\n",
      "Epoch 50, Loss: 0.7877791523933411, Final Batch Loss: 0.36211445927619934\n",
      "Epoch 51, Loss: 0.7882293462753296, Final Batch Loss: 0.3948327600955963\n",
      "Epoch 52, Loss: 0.7535086870193481, Final Batch Loss: 0.3674517273902893\n",
      "Epoch 53, Loss: 0.7518717646598816, Final Batch Loss: 0.3653745651245117\n",
      "Epoch 54, Loss: 0.7324849367141724, Final Batch Loss: 0.3923793435096741\n",
      "Epoch 55, Loss: 0.6745408773422241, Final Batch Loss: 0.3203638195991516\n",
      "Epoch 56, Loss: 0.6545842587947845, Final Batch Loss: 0.3119031488895416\n",
      "Epoch 57, Loss: 0.6564956307411194, Final Batch Loss: 0.33911678194999695\n",
      "Epoch 58, Loss: 0.5674862265586853, Final Batch Loss: 0.25608378648757935\n",
      "Epoch 59, Loss: 0.58678138256073, Final Batch Loss: 0.2883438467979431\n",
      "Epoch 60, Loss: 0.6056423783302307, Final Batch Loss: 0.30923527479171753\n",
      "Epoch 61, Loss: 0.5764710009098053, Final Batch Loss: 0.2798479497432709\n",
      "Epoch 62, Loss: 0.5408474504947662, Final Batch Loss: 0.2529822587966919\n",
      "Epoch 63, Loss: 0.48998890817165375, Final Batch Loss: 0.2602364420890808\n",
      "Epoch 64, Loss: 0.42977145314216614, Final Batch Loss: 0.20939026772975922\n",
      "Epoch 65, Loss: 0.47853511571884155, Final Batch Loss: 0.2526736557483673\n",
      "Epoch 66, Loss: 0.4103053957223892, Final Batch Loss: 0.21643617749214172\n",
      "Epoch 67, Loss: 0.35438650846481323, Final Batch Loss: 0.16940869390964508\n",
      "Epoch 68, Loss: 0.30685584247112274, Final Batch Loss: 0.1271117627620697\n",
      "Epoch 69, Loss: 0.3678770065307617, Final Batch Loss: 0.20065775513648987\n",
      "Epoch 70, Loss: 0.28635190427303314, Final Batch Loss: 0.11068589985370636\n",
      "Epoch 71, Loss: 0.276390865445137, Final Batch Loss: 0.12506605684757233\n",
      "Epoch 72, Loss: 0.24833302944898605, Final Batch Loss: 0.1186254695057869\n",
      "Epoch 73, Loss: 0.2547398954629898, Final Batch Loss: 0.13660800457000732\n",
      "Epoch 74, Loss: 0.2842649891972542, Final Batch Loss: 0.16119243204593658\n",
      "Epoch 75, Loss: 0.24299409985542297, Final Batch Loss: 0.10329033434391022\n",
      "Epoch 76, Loss: 0.2000250592827797, Final Batch Loss: 0.09859934449195862\n",
      "Epoch 77, Loss: 0.22870364785194397, Final Batch Loss: 0.1201687902212143\n",
      "Epoch 78, Loss: 0.20616929233074188, Final Batch Loss: 0.09718555212020874\n",
      "Epoch 79, Loss: 0.23121324181556702, Final Batch Loss: 0.1313057392835617\n",
      "Epoch 80, Loss: 0.21134276688098907, Final Batch Loss: 0.13071945309638977\n",
      "Epoch 81, Loss: 0.16022749245166779, Final Batch Loss: 0.0905836820602417\n",
      "Epoch 82, Loss: 0.210840106010437, Final Batch Loss: 0.11219745129346848\n",
      "Epoch 83, Loss: 0.17675144225358963, Final Batch Loss: 0.08680988848209381\n",
      "Epoch 84, Loss: 0.16395480930805206, Final Batch Loss: 0.0923430323600769\n",
      "Epoch 85, Loss: 0.16301437467336655, Final Batch Loss: 0.07557787001132965\n",
      "Epoch 86, Loss: 0.16375672817230225, Final Batch Loss: 0.07428031414747238\n",
      "Epoch 87, Loss: 0.12708041071891785, Final Batch Loss: 0.05322616547346115\n",
      "Epoch 88, Loss: 0.12591301649808884, Final Batch Loss: 0.06473326683044434\n",
      "Epoch 89, Loss: 0.14527202397584915, Final Batch Loss: 0.08953657746315002\n",
      "Epoch 90, Loss: 0.11104778200387955, Final Batch Loss: 0.0654556080698967\n",
      "Epoch 91, Loss: 0.14474690705537796, Final Batch Loss: 0.07091918587684631\n",
      "Epoch 92, Loss: 0.1588606908917427, Final Batch Loss: 0.09226475656032562\n",
      "Epoch 93, Loss: 0.12481735646724701, Final Batch Loss: 0.07162493467330933\n",
      "Epoch 94, Loss: 0.13187045231461525, Final Batch Loss: 0.08727605640888214\n",
      "Epoch 95, Loss: 0.152275949716568, Final Batch Loss: 0.06623294204473495\n",
      "Epoch 96, Loss: 0.11680729314684868, Final Batch Loss: 0.054537370800971985\n",
      "Epoch 97, Loss: 0.0835956484079361, Final Batch Loss: 0.03458429500460625\n",
      "Epoch 98, Loss: 0.11814690753817558, Final Batch Loss: 0.044904064387083054\n",
      "Epoch 99, Loss: 0.0815747007727623, Final Batch Loss: 0.030305448919534683\n",
      "Epoch 100, Loss: 0.11298457533121109, Final Batch Loss: 0.06118873879313469\n",
      "Epoch 101, Loss: 0.06730950623750687, Final Batch Loss: 0.03738539293408394\n",
      "Epoch 102, Loss: 0.11718762293457985, Final Batch Loss: 0.06073524057865143\n",
      "Epoch 103, Loss: 0.13315877690911293, Final Batch Loss: 0.08642420172691345\n",
      "Epoch 104, Loss: 0.09171690791845322, Final Batch Loss: 0.05232866853475571\n",
      "Epoch 105, Loss: 0.1183386892080307, Final Batch Loss: 0.034879960119724274\n",
      "Epoch 106, Loss: 0.07468695752322674, Final Batch Loss: 0.025557952001690865\n",
      "Epoch 107, Loss: 0.12067147716879845, Final Batch Loss: 0.08921309560537338\n",
      "Epoch 108, Loss: 0.1139298640191555, Final Batch Loss: 0.06561033427715302\n",
      "Epoch 109, Loss: 0.06875529885292053, Final Batch Loss: 0.04015966132283211\n",
      "Epoch 110, Loss: 0.11322718486189842, Final Batch Loss: 0.055581096559762955\n",
      "Epoch 111, Loss: 0.0928961280733347, Final Batch Loss: 0.06264778226613998\n",
      "Epoch 112, Loss: 0.08526525273919106, Final Batch Loss: 0.03567858785390854\n",
      "Epoch 113, Loss: 0.06181473471224308, Final Batch Loss: 0.023317603394389153\n",
      "Epoch 114, Loss: 0.05796045996248722, Final Batch Loss: 0.04091876000165939\n",
      "Epoch 115, Loss: 0.09988650679588318, Final Batch Loss: 0.070281483232975\n",
      "Epoch 116, Loss: 0.05938362143933773, Final Batch Loss: 0.020213639363646507\n",
      "Epoch 117, Loss: 0.049866389483213425, Final Batch Loss: 0.021759700030088425\n",
      "Epoch 118, Loss: 0.030302006751298904, Final Batch Loss: 0.011476706713438034\n",
      "Epoch 119, Loss: 0.03448040969669819, Final Batch Loss: 0.019708402454853058\n",
      "Epoch 120, Loss: 0.0904013030230999, Final Batch Loss: 0.036609847098588943\n",
      "Epoch 121, Loss: 0.08906934037804604, Final Batch Loss: 0.048325520008802414\n",
      "Epoch 122, Loss: 0.07276581600308418, Final Batch Loss: 0.0313350111246109\n",
      "Epoch 123, Loss: 0.08880898170173168, Final Batch Loss: 0.02266470156610012\n",
      "Epoch 124, Loss: 0.051813749596476555, Final Batch Loss: 0.03314695507287979\n",
      "Epoch 125, Loss: 0.05570222996175289, Final Batch Loss: 0.03089088387787342\n",
      "Epoch 126, Loss: 0.09408093243837357, Final Batch Loss: 0.0379931814968586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127, Loss: 0.03362740483134985, Final Batch Loss: 0.014972253702580929\n",
      "Epoch 128, Loss: 0.08161067962646484, Final Batch Loss: 0.035310473293066025\n",
      "Epoch 129, Loss: 0.07293584570288658, Final Batch Loss: 0.030291695147752762\n",
      "Epoch 130, Loss: 0.07018417119979858, Final Batch Loss: 0.04712909460067749\n",
      "Epoch 131, Loss: 0.058790476992726326, Final Batch Loss: 0.031036440283060074\n",
      "Epoch 132, Loss: 0.07635114900767803, Final Batch Loss: 0.05070456489920616\n",
      "Epoch 133, Loss: 0.038636647164821625, Final Batch Loss: 0.019743632525205612\n",
      "Epoch 134, Loss: 0.07041694223880768, Final Batch Loss: 0.04128587618470192\n",
      "Epoch 135, Loss: 0.03580972086638212, Final Batch Loss: 0.013754657469689846\n",
      "Epoch 136, Loss: 0.03598572500050068, Final Batch Loss: 0.013210749253630638\n",
      "Epoch 137, Loss: 0.04796392749994993, Final Batch Loss: 0.012126683257520199\n",
      "Epoch 138, Loss: 0.0607781708240509, Final Batch Loss: 0.033287011086940765\n",
      "Epoch 139, Loss: 0.10543409734964371, Final Batch Loss: 0.01894932985305786\n",
      "Epoch 140, Loss: 0.0322840241715312, Final Batch Loss: 0.012468601576983929\n",
      "Epoch 141, Loss: 0.07348995842039585, Final Batch Loss: 0.055282577872276306\n",
      "Epoch 142, Loss: 0.037946099415421486, Final Batch Loss: 0.013563955202698708\n",
      "Epoch 143, Loss: 0.03757144883275032, Final Batch Loss: 0.011236153542995453\n",
      "Epoch 144, Loss: 0.03793881740421057, Final Batch Loss: 0.024806277826428413\n",
      "Epoch 145, Loss: 0.040314413607120514, Final Batch Loss: 0.013027358800172806\n",
      "Epoch 146, Loss: 0.03413862455636263, Final Batch Loss: 0.011527066119015217\n",
      "Epoch 147, Loss: 0.044554328545928, Final Batch Loss: 0.0270379688590765\n",
      "Epoch 148, Loss: 0.039288842119276524, Final Batch Loss: 0.0068708742037415504\n",
      "Epoch 149, Loss: 0.055638136342167854, Final Batch Loss: 0.029676994308829308\n",
      "Epoch 150, Loss: 0.03686528606340289, Final Batch Loss: 0.005454096477478743\n",
      "Epoch 151, Loss: 0.03470370452851057, Final Batch Loss: 0.010111802257597446\n",
      "Epoch 152, Loss: 0.032090360298752785, Final Batch Loss: 0.014589667320251465\n",
      "Epoch 153, Loss: 0.0355299711227417, Final Batch Loss: 0.017350099980831146\n",
      "Epoch 154, Loss: 0.03860468836501241, Final Batch Loss: 0.006864909548312426\n",
      "Epoch 155, Loss: 0.03881038445979357, Final Batch Loss: 0.013971599750220776\n",
      "Epoch 156, Loss: 0.03064489457756281, Final Batch Loss: 0.021758951246738434\n",
      "Epoch 157, Loss: 0.03422409109771252, Final Batch Loss: 0.018917091190814972\n",
      "Epoch 158, Loss: 0.05538715049624443, Final Batch Loss: 0.024720629677176476\n",
      "Epoch 159, Loss: 0.019606538582593203, Final Batch Loss: 0.005699146073311567\n",
      "Epoch 160, Loss: 0.020862162113189697, Final Batch Loss: 0.01124881487339735\n",
      "Epoch 161, Loss: 0.03750038240104914, Final Batch Loss: 0.028145423159003258\n",
      "Epoch 162, Loss: 0.041477352380752563, Final Batch Loss: 0.016458818688988686\n",
      "Epoch 163, Loss: 0.06550328806042671, Final Batch Loss: 0.03430496156215668\n",
      "Epoch 164, Loss: 0.030258959159255028, Final Batch Loss: 0.00670977309346199\n",
      "Epoch 165, Loss: 0.025478094816207886, Final Batch Loss: 0.013286505825817585\n",
      "Epoch 166, Loss: 0.01864489819854498, Final Batch Loss: 0.010074359364807606\n",
      "Epoch 167, Loss: 0.039559995755553246, Final Batch Loss: 0.013166632503271103\n",
      "Epoch 168, Loss: 0.07125852629542351, Final Batch Loss: 0.05605126917362213\n",
      "Epoch 169, Loss: 0.022174936719238758, Final Batch Loss: 0.011792237870395184\n",
      "Epoch 170, Loss: 0.019731258042156696, Final Batch Loss: 0.010838971473276615\n",
      "Epoch 171, Loss: 0.01972530223429203, Final Batch Loss: 0.00984246376901865\n",
      "Epoch 172, Loss: 0.03600860945880413, Final Batch Loss: 0.009261485189199448\n",
      "Epoch 173, Loss: 0.02264937199652195, Final Batch Loss: 0.013014254160225391\n",
      "Epoch 174, Loss: 0.02461240626871586, Final Batch Loss: 0.014293200336396694\n",
      "Epoch 175, Loss: 0.03466470818966627, Final Batch Loss: 0.025224007666110992\n",
      "Epoch 176, Loss: 0.037026082165539265, Final Batch Loss: 0.022213011980056763\n",
      "Epoch 177, Loss: 0.0108143943361938, Final Batch Loss: 0.005179143510758877\n",
      "Epoch 178, Loss: 0.025373932905495167, Final Batch Loss: 0.012072956189513206\n",
      "Epoch 179, Loss: 0.03423524834215641, Final Batch Loss: 0.017761753872036934\n",
      "Epoch 180, Loss: 0.036500727757811546, Final Batch Loss: 0.027203507721424103\n",
      "Epoch 181, Loss: 0.028668702580034733, Final Batch Loss: 0.010294307954609394\n",
      "Epoch 182, Loss: 0.01700491923838854, Final Batch Loss: 0.012967219576239586\n",
      "Epoch 183, Loss: 0.022237517405301332, Final Batch Loss: 0.007542835082858801\n",
      "Epoch 184, Loss: 0.04384406842291355, Final Batch Loss: 0.021323390305042267\n",
      "Epoch 185, Loss: 0.019703635945916176, Final Batch Loss: 0.006143469363451004\n",
      "Epoch 186, Loss: 0.02825685776770115, Final Batch Loss: 0.017683111131191254\n",
      "Epoch 187, Loss: 0.02724472340196371, Final Batch Loss: 0.019133081659674644\n",
      "Epoch 188, Loss: 0.022564380429685116, Final Batch Loss: 0.016488555818796158\n",
      "Epoch 189, Loss: 0.014052978716790676, Final Batch Loss: 0.0022467216476798058\n",
      "Epoch 190, Loss: 0.018235755153000355, Final Batch Loss: 0.007044137455523014\n",
      "Epoch 191, Loss: 0.031561351381242275, Final Batch Loss: 0.004451201297342777\n",
      "Epoch 192, Loss: 0.02531106793321669, Final Batch Loss: 0.003542024875059724\n",
      "Epoch 193, Loss: 0.01586213894188404, Final Batch Loss: 0.0074180373921990395\n",
      "Epoch 194, Loss: 0.03084216360002756, Final Batch Loss: 0.005931842140853405\n",
      "Epoch 195, Loss: 0.041967498138546944, Final Batch Loss: 0.021499380469322205\n",
      "Epoch 196, Loss: 0.017508214805275202, Final Batch Loss: 0.0052318754605948925\n",
      "Epoch 197, Loss: 0.01853516884148121, Final Batch Loss: 0.01055105496197939\n",
      "Epoch 198, Loss: 0.008918172214180231, Final Batch Loss: 0.003966460004448891\n",
      "Epoch 199, Loss: 0.019568894058465958, Final Batch Loss: 0.015721764415502548\n",
      "Epoch 200, Loss: 0.030414889566600323, Final Batch Loss: 0.014827525243163109\n",
      "Epoch 201, Loss: 0.04051671363413334, Final Batch Loss: 0.014193249866366386\n",
      "Epoch 202, Loss: 0.00958324084058404, Final Batch Loss: 0.005139431916177273\n",
      "Epoch 203, Loss: 0.04196697473526001, Final Batch Loss: 0.030672114342451096\n",
      "Epoch 204, Loss: 0.025236153975129128, Final Batch Loss: 0.013658197596669197\n",
      "Epoch 205, Loss: 0.016095882281661034, Final Batch Loss: 0.010717024095356464\n",
      "Epoch 206, Loss: 0.018653268925845623, Final Batch Loss: 0.007009460590779781\n",
      "Epoch 207, Loss: 0.02704744227230549, Final Batch Loss: 0.010521724820137024\n",
      "Epoch 208, Loss: 0.03057216200977564, Final Batch Loss: 0.011044821701943874\n",
      "Epoch 209, Loss: 0.012443925719708204, Final Batch Loss: 0.007618658244609833\n",
      "Epoch 210, Loss: 0.013781161047518253, Final Batch Loss: 0.00960424542427063\n",
      "Epoch 211, Loss: 0.010921090375632048, Final Batch Loss: 0.004515651147812605\n",
      "Epoch 212, Loss: 0.02195352502167225, Final Batch Loss: 0.006251469254493713\n",
      "Epoch 213, Loss: 0.04555688612163067, Final Batch Loss: 0.009523497894406319\n",
      "Epoch 214, Loss: 0.012060678331181407, Final Batch Loss: 0.003378400346264243\n",
      "Epoch 215, Loss: 0.019200189970433712, Final Batch Loss: 0.002723908983170986\n",
      "Epoch 216, Loss: 0.022848560009151697, Final Batch Loss: 0.005661022383719683\n",
      "Epoch 217, Loss: 0.027274237480014563, Final Batch Loss: 0.005981949623674154\n",
      "Epoch 218, Loss: 0.028557688929140568, Final Batch Loss: 0.013224170543253422\n",
      "Epoch 219, Loss: 0.03635813947767019, Final Batch Loss: 0.008462333120405674\n",
      "Epoch 220, Loss: 0.011825672816485167, Final Batch Loss: 0.005706556607037783\n",
      "Epoch 221, Loss: 0.0596588421612978, Final Batch Loss: 0.05293077230453491\n",
      "Epoch 222, Loss: 0.007930048042908311, Final Batch Loss: 0.004517834167927504\n",
      "Epoch 223, Loss: 0.036919779144227505, Final Batch Loss: 0.022370239719748497\n",
      "Epoch 224, Loss: 0.026211478281766176, Final Batch Loss: 0.021665694192051888\n",
      "Epoch 225, Loss: 0.020764806773513556, Final Batch Loss: 0.015277247875928879\n",
      "Epoch 226, Loss: 0.0643224660307169, Final Batch Loss: 0.04216861352324486\n",
      "Epoch 227, Loss: 0.011222629342228174, Final Batch Loss: 0.0032604276202619076\n",
      "Epoch 228, Loss: 0.013872732408344746, Final Batch Loss: 0.009537877514958382\n",
      "Epoch 229, Loss: 0.06702752690762281, Final Batch Loss: 0.06047212705016136\n",
      "Epoch 230, Loss: 0.03034930396825075, Final Batch Loss: 0.02648296020925045\n",
      "Epoch 231, Loss: 0.009648119797930121, Final Batch Loss: 0.0031979193445295095\n",
      "Epoch 232, Loss: 0.028788707219064236, Final Batch Loss: 0.02047753892838955\n",
      "Epoch 233, Loss: 0.03554567112587392, Final Batch Loss: 0.031842079013586044\n",
      "Epoch 234, Loss: 0.018825875595211983, Final Batch Loss: 0.003369544632732868\n",
      "Epoch 235, Loss: 0.01008876389823854, Final Batch Loss: 0.0036731676664203405\n",
      "Epoch 236, Loss: 0.03337598126381636, Final Batch Loss: 0.019762391224503517\n",
      "Epoch 237, Loss: 0.008469472639262676, Final Batch Loss: 0.005177777260541916\n",
      "Epoch 238, Loss: 0.017301535699516535, Final Batch Loss: 0.007259089965373278\n",
      "Epoch 239, Loss: 0.061340609565377235, Final Batch Loss: 0.04695092514157295\n",
      "Epoch 240, Loss: 0.017825047252699733, Final Batch Loss: 0.003271797439083457\n",
      "Epoch 241, Loss: 0.0248173912987113, Final Batch Loss: 0.01957056112587452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242, Loss: 0.01807668525725603, Final Batch Loss: 0.009791227988898754\n",
      "Epoch 243, Loss: 0.007801099913194776, Final Batch Loss: 0.004166983067989349\n",
      "Epoch 244, Loss: 0.01673691114410758, Final Batch Loss: 0.01078836526721716\n",
      "Epoch 245, Loss: 0.02806088561192155, Final Batch Loss: 0.004889302421361208\n",
      "Epoch 246, Loss: 0.014310411177575588, Final Batch Loss: 0.010067347437143326\n",
      "Epoch 247, Loss: 0.029828174971044064, Final Batch Loss: 0.00599562656134367\n",
      "Epoch 248, Loss: 0.016125975642353296, Final Batch Loss: 0.005736927036195993\n",
      "Epoch 249, Loss: 0.032771497033536434, Final Batch Loss: 0.012413165532052517\n",
      "Epoch 250, Loss: 0.01164529426023364, Final Batch Loss: 0.0064867278560996056\n",
      "Epoch 251, Loss: 0.010541815776377916, Final Batch Loss: 0.00404687225818634\n",
      "Epoch 252, Loss: 0.016071271616965532, Final Batch Loss: 0.007259200792759657\n",
      "Epoch 253, Loss: 0.011378542287275195, Final Batch Loss: 0.007999416440725327\n",
      "Epoch 254, Loss: 0.014806229155510664, Final Batch Loss: 0.002877767663449049\n",
      "Epoch 255, Loss: 0.012712105177342892, Final Batch Loss: 0.004904828034341335\n",
      "Epoch 256, Loss: 0.023391843074932694, Final Batch Loss: 0.019795389845967293\n",
      "Epoch 257, Loss: 0.0393370445817709, Final Batch Loss: 0.008635120466351509\n",
      "Epoch 258, Loss: 0.03756729234009981, Final Batch Loss: 0.027339817956089973\n",
      "Epoch 259, Loss: 0.01825962821021676, Final Batch Loss: 0.004181354772299528\n",
      "Epoch 260, Loss: 0.008858710993081331, Final Batch Loss: 0.005093677435070276\n",
      "Epoch 261, Loss: 0.0052314732456579804, Final Batch Loss: 0.0019125017570331693\n",
      "Epoch 262, Loss: 0.012621215544641018, Final Batch Loss: 0.006575857289135456\n",
      "Epoch 263, Loss: 0.005738653126172721, Final Batch Loss: 0.001220798003487289\n",
      "Epoch 264, Loss: 0.00585961970500648, Final Batch Loss: 0.0030011984053999186\n",
      "Epoch 265, Loss: 0.009392995154485106, Final Batch Loss: 0.006714072544127703\n",
      "Epoch 266, Loss: 0.014776856172829866, Final Batch Loss: 0.0043244450353085995\n",
      "Epoch 267, Loss: 0.018727713264524937, Final Batch Loss: 0.013146473094820976\n",
      "Epoch 268, Loss: 0.0070707290433347225, Final Batch Loss: 0.002775775268673897\n",
      "Epoch 269, Loss: 0.0098815206438303, Final Batch Loss: 0.0039549157954752445\n",
      "Epoch 270, Loss: 0.019572870805859566, Final Batch Loss: 0.017302436754107475\n",
      "Epoch 271, Loss: 0.008104501059278846, Final Batch Loss: 0.003184676868841052\n",
      "Epoch 272, Loss: 0.018232204020023346, Final Batch Loss: 0.01038326695561409\n",
      "Epoch 273, Loss: 0.02099880250170827, Final Batch Loss: 0.01828177459537983\n",
      "Epoch 274, Loss: 0.023224621545523405, Final Batch Loss: 0.0058846971951425076\n",
      "Epoch 275, Loss: 0.0168925360776484, Final Batch Loss: 0.00264562526717782\n",
      "Epoch 276, Loss: 0.007522598607465625, Final Batch Loss: 0.0034042533952742815\n",
      "Epoch 277, Loss: 0.015398919116705656, Final Batch Loss: 0.004587193485349417\n",
      "Epoch 278, Loss: 0.0086321453563869, Final Batch Loss: 0.00617625517770648\n",
      "Epoch 279, Loss: 0.00478505389764905, Final Batch Loss: 0.002870556665584445\n",
      "Epoch 280, Loss: 0.01822878047823906, Final Batch Loss: 0.012461964040994644\n",
      "Epoch 281, Loss: 0.019844037480652332, Final Batch Loss: 0.016469541937112808\n",
      "Epoch 282, Loss: 0.009203696390613914, Final Batch Loss: 0.003325696801766753\n",
      "Epoch 283, Loss: 0.018828008323907852, Final Batch Loss: 0.006356978788971901\n",
      "Epoch 284, Loss: 0.00679794093593955, Final Batch Loss: 0.002967671025544405\n",
      "Epoch 285, Loss: 0.00482084765098989, Final Batch Loss: 0.0018475227989256382\n",
      "Epoch 286, Loss: 0.0178376785479486, Final Batch Loss: 0.013624622486531734\n",
      "Epoch 287, Loss: 0.010344594717025757, Final Batch Loss: 0.00394862238317728\n",
      "Epoch 288, Loss: 0.03507514437660575, Final Batch Loss: 0.029657138511538506\n",
      "Epoch 289, Loss: 0.0026610265485942364, Final Batch Loss: 0.0010109314462170005\n",
      "Epoch 290, Loss: 0.020059037022292614, Final Batch Loss: 0.008088150061666965\n",
      "Epoch 291, Loss: 0.01005203160457313, Final Batch Loss: 0.003102113725617528\n",
      "Epoch 292, Loss: 0.007194048259407282, Final Batch Loss: 0.003003496676683426\n",
      "Epoch 293, Loss: 0.018376242835074663, Final Batch Loss: 0.011875144205987453\n",
      "Epoch 294, Loss: 0.018082209397107363, Final Batch Loss: 0.013450558297336102\n",
      "Epoch 295, Loss: 0.02046220237389207, Final Batch Loss: 0.006254023406654596\n",
      "Epoch 296, Loss: 0.008911898592486978, Final Batch Loss: 0.0030567168723791838\n",
      "Epoch 297, Loss: 0.007874772883951664, Final Batch Loss: 0.004497167654335499\n",
      "Epoch 298, Loss: 0.011914882808923721, Final Batch Loss: 0.005872901063412428\n",
      "Epoch 299, Loss: 0.006475314381532371, Final Batch Loss: 0.0015625491505488753\n",
      "Epoch 300, Loss: 0.01514321705326438, Final Batch Loss: 0.011231273412704468\n",
      "Epoch 301, Loss: 0.02122847130522132, Final Batch Loss: 0.0036565284244716167\n",
      "Epoch 302, Loss: 0.03228839300572872, Final Batch Loss: 0.01587461493909359\n",
      "Epoch 303, Loss: 0.019776069559156895, Final Batch Loss: 0.01595643348991871\n",
      "Epoch 304, Loss: 0.008393226191401482, Final Batch Loss: 0.004287754651159048\n",
      "Epoch 305, Loss: 0.006663987413048744, Final Batch Loss: 0.004322780761867762\n",
      "Epoch 306, Loss: 0.012147088535130024, Final Batch Loss: 0.005113779567182064\n",
      "Epoch 307, Loss: 0.0053823558846488595, Final Batch Loss: 0.0016198199009522796\n",
      "Epoch 308, Loss: 0.011803249595686793, Final Batch Loss: 0.00205817143432796\n",
      "Epoch 309, Loss: 0.011942691868171096, Final Batch Loss: 0.0035917952191084623\n",
      "Epoch 310, Loss: 0.004809534410014749, Final Batch Loss: 0.0026700536254793406\n",
      "Epoch 311, Loss: 0.019044497166760266, Final Batch Loss: 0.001792389084585011\n",
      "Epoch 312, Loss: 0.010929652489721775, Final Batch Loss: 0.0071905734948813915\n",
      "Epoch 313, Loss: 0.011590375564992428, Final Batch Loss: 0.003578552044928074\n",
      "Epoch 314, Loss: 0.0071265315636992455, Final Batch Loss: 0.0048681143671274185\n",
      "Epoch 315, Loss: 0.021228655241429806, Final Batch Loss: 0.0035637272521853447\n",
      "Epoch 316, Loss: 0.004180153249762952, Final Batch Loss: 0.001636955770663917\n",
      "Epoch 317, Loss: 0.00829557329416275, Final Batch Loss: 0.0033770198933780193\n",
      "Epoch 318, Loss: 0.0091300995554775, Final Batch Loss: 0.002090164227411151\n",
      "Epoch 319, Loss: 0.00847203645389527, Final Batch Loss: 0.0071978191845119\n",
      "Epoch 320, Loss: 0.017514526611194015, Final Batch Loss: 0.003197099780663848\n",
      "Epoch 321, Loss: 0.009338801493868232, Final Batch Loss: 0.0028410840313881636\n",
      "Epoch 322, Loss: 0.0174035532400012, Final Batch Loss: 0.006620435975492001\n",
      "Epoch 323, Loss: 0.009107294725254178, Final Batch Loss: 0.007293735630810261\n",
      "Epoch 324, Loss: 0.0078068680595606565, Final Batch Loss: 0.006006625946611166\n",
      "Epoch 325, Loss: 0.030203680973500013, Final Batch Loss: 0.02389700524508953\n",
      "Epoch 326, Loss: 0.003415372862946242, Final Batch Loss: 0.000547638104762882\n",
      "Epoch 327, Loss: 0.010765345999971032, Final Batch Loss: 0.0022571871522814035\n",
      "Epoch 328, Loss: 0.007691894541494548, Final Batch Loss: 0.006547488737851381\n",
      "Epoch 329, Loss: 0.004846288007684052, Final Batch Loss: 0.0009484601905569434\n",
      "Epoch 330, Loss: 0.014891731087118387, Final Batch Loss: 0.0036364453844726086\n",
      "Epoch 331, Loss: 0.008745967177674174, Final Batch Loss: 0.003000754164531827\n",
      "Epoch 332, Loss: 0.011336059309542179, Final Batch Loss: 0.004126457031816244\n",
      "Epoch 333, Loss: 0.01034995261579752, Final Batch Loss: 0.006569522898644209\n",
      "Epoch 334, Loss: 0.006343331420794129, Final Batch Loss: 0.003350544022396207\n",
      "Epoch 335, Loss: 0.00719930324703455, Final Batch Loss: 0.0012829406186938286\n",
      "Epoch 336, Loss: 0.008511214517056942, Final Batch Loss: 0.0016008876264095306\n",
      "Epoch 337, Loss: 0.009112565661780536, Final Batch Loss: 0.0018314154585823417\n",
      "Epoch 338, Loss: 0.006549272075062618, Final Batch Loss: 0.0004333526303526014\n",
      "Epoch 339, Loss: 0.005575615563429892, Final Batch Loss: 0.0016962663503363729\n",
      "Epoch 340, Loss: 0.005654066102579236, Final Batch Loss: 0.0013183353003114462\n",
      "Epoch 341, Loss: 0.007148892153054476, Final Batch Loss: 0.0027017011307179928\n",
      "Epoch 342, Loss: 0.003095093765296042, Final Batch Loss: 0.0011473154881969094\n",
      "Epoch 343, Loss: 0.021036696154624224, Final Batch Loss: 0.007149709854274988\n",
      "Epoch 344, Loss: 0.006365894572809339, Final Batch Loss: 0.002098454860970378\n",
      "Epoch 345, Loss: 0.00856924569234252, Final Batch Loss: 0.005426081828773022\n",
      "Epoch 346, Loss: 0.012089498457498848, Final Batch Loss: 0.0015011579962447286\n",
      "Epoch 347, Loss: 0.01166481664404273, Final Batch Loss: 0.004986873362213373\n",
      "Epoch 348, Loss: 0.014176357071846724, Final Batch Loss: 0.009749026969075203\n",
      "Epoch 349, Loss: 0.0067106804344803095, Final Batch Loss: 0.002360402373597026\n",
      "Epoch 350, Loss: 0.004386048531159759, Final Batch Loss: 0.0017053380142897367\n",
      "Epoch 351, Loss: 0.0036302831722423434, Final Batch Loss: 0.0017051262548193336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352, Loss: 0.0020829716813750565, Final Batch Loss: 0.000802042952273041\n",
      "Epoch 353, Loss: 0.028953131288290024, Final Batch Loss: 0.026280419901013374\n",
      "Epoch 354, Loss: 0.023355099372565746, Final Batch Loss: 0.005716937594115734\n",
      "Epoch 355, Loss: 0.004413104034028947, Final Batch Loss: 0.0016368207288905978\n",
      "Epoch 356, Loss: 0.01417099719401449, Final Batch Loss: 0.0014210831141099334\n",
      "Epoch 357, Loss: 0.004287288407795131, Final Batch Loss: 0.0012117204023525119\n",
      "Epoch 358, Loss: 0.0035960186505690217, Final Batch Loss: 0.0025814424734562635\n",
      "Epoch 359, Loss: 0.01548718917183578, Final Batch Loss: 0.014506068080663681\n",
      "Epoch 360, Loss: 0.003078159876167774, Final Batch Loss: 0.0017017725622281432\n",
      "Epoch 361, Loss: 0.007757162558846176, Final Batch Loss: 0.006624821573495865\n",
      "Epoch 362, Loss: 0.00424588262103498, Final Batch Loss: 0.0017461746465414762\n",
      "Epoch 363, Loss: 0.0035722899483516812, Final Batch Loss: 0.002440954092890024\n",
      "Epoch 364, Loss: 0.0033404107962269336, Final Batch Loss: 0.0004492181178648025\n",
      "Epoch 365, Loss: 0.014690989744849503, Final Batch Loss: 0.0012818417744711041\n",
      "Epoch 366, Loss: 0.005514279706403613, Final Batch Loss: 0.0035411438439041376\n",
      "Epoch 367, Loss: 0.00445245741866529, Final Batch Loss: 0.0012472760863602161\n",
      "Epoch 368, Loss: 0.008076969999819994, Final Batch Loss: 0.00599883496761322\n",
      "Epoch 369, Loss: 0.010894310660660267, Final Batch Loss: 0.0055085900239646435\n",
      "Epoch 370, Loss: 0.01232495903968811, Final Batch Loss: 0.010723169893026352\n",
      "Epoch 371, Loss: 0.002647685119882226, Final Batch Loss: 0.0016531858127564192\n",
      "Epoch 372, Loss: 0.007172417361289263, Final Batch Loss: 0.002099364995956421\n",
      "Epoch 373, Loss: 0.0026940726675093174, Final Batch Loss: 0.0015297490172088146\n",
      "Epoch 374, Loss: 0.01014133170247078, Final Batch Loss: 0.003907668869942427\n",
      "Epoch 375, Loss: 0.011589567176997662, Final Batch Loss: 0.004071033094078302\n",
      "Epoch 376, Loss: 0.015478270361199975, Final Batch Loss: 0.012559940107166767\n",
      "Epoch 377, Loss: 0.008898731786757708, Final Batch Loss: 0.0011103702709078789\n",
      "Epoch 378, Loss: 0.015993629349395633, Final Batch Loss: 0.012114131823182106\n",
      "Epoch 379, Loss: 0.007642215816304088, Final Batch Loss: 0.004741251934319735\n",
      "Epoch 380, Loss: 0.01545557240024209, Final Batch Loss: 0.013999005779623985\n",
      "Epoch 381, Loss: 0.005596182192675769, Final Batch Loss: 0.0037922582123428583\n",
      "Epoch 382, Loss: 0.0039632366970181465, Final Batch Loss: 0.0010523488745093346\n",
      "Epoch 383, Loss: 0.0077928476966917515, Final Batch Loss: 0.004745150450617075\n",
      "Epoch 384, Loss: 0.007081351242959499, Final Batch Loss: 0.001252995803952217\n",
      "Epoch 385, Loss: 0.020053720101714134, Final Batch Loss: 0.01247712317854166\n",
      "Epoch 386, Loss: 0.013059443794190884, Final Batch Loss: 0.001159164123237133\n",
      "Epoch 387, Loss: 0.022638412658125162, Final Batch Loss: 0.019875580444931984\n",
      "Epoch 388, Loss: 0.0033821918768808246, Final Batch Loss: 0.0010344776092097163\n",
      "Epoch 389, Loss: 0.0037549291737377644, Final Batch Loss: 0.0005404965486377478\n",
      "Epoch 390, Loss: 0.010248534148558974, Final Batch Loss: 0.008812781423330307\n",
      "Epoch 391, Loss: 0.010196376708336174, Final Batch Loss: 0.00103440519887954\n",
      "Epoch 392, Loss: 0.007232321135234088, Final Batch Loss: 0.0009475217084400356\n",
      "Epoch 393, Loss: 0.0037463458138518035, Final Batch Loss: 0.000716417736839503\n",
      "Epoch 394, Loss: 0.0021930955699644983, Final Batch Loss: 0.0006913790130056441\n",
      "Epoch 395, Loss: 0.0034649749868549407, Final Batch Loss: 0.0008596494444645941\n",
      "Epoch 396, Loss: 0.006395641248673201, Final Batch Loss: 0.0028336569666862488\n",
      "Epoch 397, Loss: 0.00371423433534801, Final Batch Loss: 0.0007338393479585648\n",
      "Epoch 398, Loss: 0.0020486401044763625, Final Batch Loss: 0.0008969697519205511\n",
      "Epoch 399, Loss: 0.010066562099382281, Final Batch Loss: 0.006983976345509291\n",
      "Epoch 400, Loss: 0.005281817750073969, Final Batch Loss: 0.003924435470253229\n",
      "Epoch 401, Loss: 0.003710475633852184, Final Batch Loss: 0.0007181229302659631\n",
      "Epoch 402, Loss: 0.0024825655855238438, Final Batch Loss: 0.0012734995689243078\n",
      "Epoch 403, Loss: 0.008612105273641646, Final Batch Loss: 0.007595268543809652\n",
      "Epoch 404, Loss: 0.0023036831407807767, Final Batch Loss: 0.001432268531061709\n",
      "Epoch 405, Loss: 0.00138740090187639, Final Batch Loss: 0.00108145282138139\n",
      "Epoch 406, Loss: 0.008471384877339005, Final Batch Loss: 0.004624376073479652\n",
      "Epoch 407, Loss: 0.008162838406860828, Final Batch Loss: 0.006062069442123175\n",
      "Epoch 408, Loss: 0.003766282694414258, Final Batch Loss: 0.0016309022903442383\n",
      "Epoch 409, Loss: 0.010727825807407498, Final Batch Loss: 0.003089126432314515\n",
      "Epoch 410, Loss: 0.004656436387449503, Final Batch Loss: 0.0019529759883880615\n",
      "Epoch 411, Loss: 0.006677740253508091, Final Batch Loss: 0.0015472974628210068\n",
      "Epoch 412, Loss: 0.004598997998982668, Final Batch Loss: 0.0007677625399082899\n",
      "Epoch 413, Loss: 0.0033455821685492992, Final Batch Loss: 0.0014131811913102865\n",
      "Epoch 414, Loss: 0.020800318336114287, Final Batch Loss: 0.0034198106732219458\n",
      "Epoch 415, Loss: 0.01594590541208163, Final Batch Loss: 0.0151126803830266\n",
      "Epoch 416, Loss: 0.008209554245695472, Final Batch Loss: 0.004370315000414848\n",
      "Epoch 417, Loss: 0.0027698794146999717, Final Batch Loss: 0.001569691812619567\n",
      "Epoch 418, Loss: 0.0035864353412762284, Final Batch Loss: 0.0015557586448267102\n",
      "Epoch 419, Loss: 0.027142059057950974, Final Batch Loss: 0.004076991230249405\n",
      "Epoch 420, Loss: 0.0033725263783708215, Final Batch Loss: 0.002034322125837207\n",
      "Epoch 421, Loss: 0.009984976379200816, Final Batch Loss: 0.00885678082704544\n",
      "Epoch 422, Loss: 0.0066160495625808835, Final Batch Loss: 0.0055978065356612206\n",
      "Epoch 423, Loss: 0.01158171659335494, Final Batch Loss: 0.005368711426854134\n",
      "Epoch 424, Loss: 0.025476304814219475, Final Batch Loss: 0.0015232712030410767\n",
      "Epoch 425, Loss: 0.002985678263939917, Final Batch Loss: 0.0006907099159434438\n",
      "Epoch 426, Loss: 0.016316328546963632, Final Batch Loss: 0.00045856309588998556\n",
      "Epoch 427, Loss: 0.004078391473740339, Final Batch Loss: 0.0012251995503902435\n",
      "Epoch 428, Loss: 0.004753347835503519, Final Batch Loss: 0.0016387762734666467\n",
      "Epoch 429, Loss: 0.006204165518283844, Final Batch Loss: 0.004051845986396074\n",
      "Epoch 430, Loss: 0.005189591902308166, Final Batch Loss: 0.0014505247818306088\n",
      "Epoch 431, Loss: 0.005042223026975989, Final Batch Loss: 0.0022973648738116026\n",
      "Epoch 432, Loss: 0.0032567057060077786, Final Batch Loss: 0.0022382084280252457\n",
      "Epoch 433, Loss: 0.010023922892287374, Final Batch Loss: 0.007695351727306843\n",
      "Epoch 434, Loss: 0.012081058113835752, Final Batch Loss: 0.0011126858880743384\n",
      "Epoch 435, Loss: 0.0038429577834904194, Final Batch Loss: 0.0014133155345916748\n",
      "Epoch 436, Loss: 0.0025094833690673113, Final Batch Loss: 0.0011958495015278459\n",
      "Epoch 437, Loss: 0.006822316907346249, Final Batch Loss: 0.0041576107032597065\n",
      "Epoch 438, Loss: 0.004837189335376024, Final Batch Loss: 0.002275201492011547\n",
      "Epoch 439, Loss: 0.002622780972160399, Final Batch Loss: 0.0008227457292377949\n",
      "Epoch 440, Loss: 0.007239262922666967, Final Batch Loss: 0.005649950820952654\n",
      "Epoch 441, Loss: 0.0029153486248105764, Final Batch Loss: 0.001202503452077508\n",
      "Epoch 442, Loss: 0.0030778292566537857, Final Batch Loss: 0.0020787420216947794\n",
      "Epoch 443, Loss: 0.008064683061093092, Final Batch Loss: 0.005182135850191116\n",
      "Epoch 444, Loss: 0.004089467693120241, Final Batch Loss: 0.0024293242022395134\n",
      "Epoch 445, Loss: 0.0030061709694564342, Final Batch Loss: 0.001571064698509872\n",
      "Epoch 446, Loss: 0.009330666041933, Final Batch Loss: 0.007392808794975281\n",
      "Epoch 447, Loss: 0.004169898806139827, Final Batch Loss: 0.0022814003750681877\n",
      "Epoch 448, Loss: 0.012497253308538347, Final Batch Loss: 0.011959463357925415\n",
      "Epoch 449, Loss: 0.003007947059813887, Final Batch Loss: 0.0007750678923912346\n",
      "Epoch 450, Loss: 0.0019274734077043831, Final Batch Loss: 0.0007468867697753012\n",
      "Epoch 451, Loss: 0.008409602101892233, Final Batch Loss: 0.005457381717860699\n",
      "Epoch 452, Loss: 0.004369678790681064, Final Batch Loss: 0.0007305346662178636\n",
      "Epoch 453, Loss: 0.0063731062691658735, Final Batch Loss: 0.0013919661287218332\n",
      "Epoch 454, Loss: 0.01009074691683054, Final Batch Loss: 0.0023485044948756695\n",
      "Epoch 455, Loss: 0.003397771273739636, Final Batch Loss: 0.0016600952949374914\n",
      "Epoch 456, Loss: 0.0016144909313879907, Final Batch Loss: 0.0009600479970686138\n",
      "Epoch 457, Loss: 0.00218675791984424, Final Batch Loss: 0.0007817877340130508\n",
      "Epoch 458, Loss: 0.005412358732428402, Final Batch Loss: 0.004954942502081394\n",
      "Epoch 459, Loss: 0.015473395178560168, Final Batch Loss: 0.0007104552933014929\n",
      "Epoch 460, Loss: 0.002138509997166693, Final Batch Loss: 0.0009131678380072117\n",
      "Epoch 461, Loss: 0.0023323780624195933, Final Batch Loss: 0.0007804651977494359\n",
      "Epoch 462, Loss: 0.006863882706966251, Final Batch Loss: 0.000276909617241472\n",
      "Epoch 463, Loss: 0.04217149270698428, Final Batch Loss: 0.0041194516234099865\n",
      "Epoch 464, Loss: 0.011009846581146121, Final Batch Loss: 0.00242323218844831\n",
      "Epoch 465, Loss: 0.008085828390903771, Final Batch Loss: 0.0007409212412312627\n",
      "Epoch 466, Loss: 0.018759157741442323, Final Batch Loss: 0.015812214463949203\n",
      "Epoch 467, Loss: 0.0031678846571594477, Final Batch Loss: 0.0002635836135596037\n",
      "Epoch 468, Loss: 0.004942143335938454, Final Batch Loss: 0.0035046914126724005\n",
      "Epoch 469, Loss: 0.0033162068284582347, Final Batch Loss: 0.0004484299279283732\n",
      "Epoch 470, Loss: 0.0014076735824346542, Final Batch Loss: 0.0010736797703430057\n",
      "Epoch 471, Loss: 0.0019157390343025327, Final Batch Loss: 0.0005005728453397751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472, Loss: 0.006544527132064104, Final Batch Loss: 0.005046889651566744\n",
      "Epoch 473, Loss: 0.007338079973123968, Final Batch Loss: 0.0009982906049117446\n",
      "Epoch 474, Loss: 0.0009797957027330995, Final Batch Loss: 0.0002533057704567909\n",
      "Epoch 475, Loss: 0.0038073944742791355, Final Batch Loss: 0.0007881333003751934\n",
      "Epoch 476, Loss: 0.004721768491435796, Final Batch Loss: 0.0004962988314218819\n",
      "Epoch 477, Loss: 0.0028385005425661802, Final Batch Loss: 0.0007249258924275637\n",
      "Epoch 478, Loss: 0.0024430608609691262, Final Batch Loss: 0.0008916162187233567\n",
      "Epoch 479, Loss: 0.009156786371022463, Final Batch Loss: 0.003102456219494343\n",
      "Epoch 480, Loss: 0.0033814003691077232, Final Batch Loss: 0.0008905797731131315\n",
      "Epoch 481, Loss: 0.002097160613629967, Final Batch Loss: 0.0004376568249426782\n",
      "Epoch 482, Loss: 0.006661329185590148, Final Batch Loss: 0.0017900739330798388\n",
      "Epoch 483, Loss: 0.001730043615680188, Final Batch Loss: 0.0008081549312919378\n",
      "Epoch 484, Loss: 0.004566455027088523, Final Batch Loss: 0.0007675879169255495\n",
      "Epoch 485, Loss: 0.007517110789194703, Final Batch Loss: 0.006125751417130232\n",
      "Epoch 486, Loss: 0.0036946353502571583, Final Batch Loss: 0.0022907524835318327\n",
      "Epoch 487, Loss: 0.008304664865136147, Final Batch Loss: 0.0059853410348296165\n",
      "Epoch 488, Loss: 0.008634614641778171, Final Batch Loss: 0.007858740165829659\n",
      "Epoch 489, Loss: 0.003063017502427101, Final Batch Loss: 0.0011615693802013993\n",
      "Epoch 490, Loss: 0.013702699216082692, Final Batch Loss: 0.011540231294929981\n",
      "Epoch 491, Loss: 0.003452769189607352, Final Batch Loss: 0.0006683843093924224\n",
      "Epoch 492, Loss: 0.0033925450989045203, Final Batch Loss: 0.0008883770206011832\n",
      "Epoch 493, Loss: 0.010414125048555434, Final Batch Loss: 0.00961711723357439\n",
      "Epoch 494, Loss: 0.006845375755801797, Final Batch Loss: 0.0023959886748343706\n",
      "Epoch 495, Loss: 0.0011396916233934462, Final Batch Loss: 0.0002009981544688344\n",
      "Epoch 496, Loss: 0.007836872333427891, Final Batch Loss: 0.00023161116405390203\n",
      "Epoch 497, Loss: 0.009854564676061273, Final Batch Loss: 0.002578807296231389\n",
      "Epoch 498, Loss: 0.007736552506685257, Final Batch Loss: 0.004008531104773283\n",
      "Epoch 499, Loss: 0.008097310550510883, Final Batch Loss: 0.005795539356768131\n",
      "Epoch 500, Loss: 0.0063612626399844885, Final Batch Loss: 0.005030938424170017\n",
      "Epoch 501, Loss: 0.007871616398915648, Final Batch Loss: 0.006330682430416346\n",
      "Epoch 502, Loss: 0.00581591617083177, Final Batch Loss: 0.0007197642116807401\n",
      "Epoch 503, Loss: 0.007229803595691919, Final Batch Loss: 0.005633760243654251\n",
      "Epoch 504, Loss: 0.0008880542882252485, Final Batch Loss: 0.00036397724761627614\n",
      "Epoch 505, Loss: 0.003327826620079577, Final Batch Loss: 0.0007126311538740993\n",
      "Epoch 506, Loss: 0.0035058665671385825, Final Batch Loss: 0.0005009512533433735\n",
      "Epoch 507, Loss: 0.01539974077604711, Final Batch Loss: 0.011506040580570698\n",
      "Epoch 508, Loss: 0.003059660375583917, Final Batch Loss: 0.0006018491112627089\n",
      "Epoch 509, Loss: 0.007848989975173026, Final Batch Loss: 0.006995953619480133\n",
      "Epoch 510, Loss: 0.002898631908465177, Final Batch Loss: 0.0008177683339454234\n",
      "Epoch 511, Loss: 0.002453948953188956, Final Batch Loss: 0.0006137645104900002\n",
      "Epoch 512, Loss: 0.0019349452340975404, Final Batch Loss: 0.0010051371064037085\n",
      "Epoch 513, Loss: 0.004763621909660287, Final Batch Loss: 0.004575361032038927\n",
      "Epoch 514, Loss: 0.00936894677579403, Final Batch Loss: 0.006328750867396593\n",
      "Epoch 515, Loss: 0.002852674340829253, Final Batch Loss: 0.0011762416688725352\n",
      "Epoch 516, Loss: 0.0026973943458870053, Final Batch Loss: 0.0010012638522312045\n",
      "Epoch 517, Loss: 0.003963227616623044, Final Batch Loss: 0.0026788790710270405\n",
      "Epoch 518, Loss: 0.004144518868997693, Final Batch Loss: 0.0011609927751123905\n",
      "Epoch 519, Loss: 0.0014976661186665297, Final Batch Loss: 0.000871273223310709\n",
      "Epoch 520, Loss: 0.001939663547091186, Final Batch Loss: 0.001357239088974893\n",
      "Epoch 521, Loss: 0.012734535965137184, Final Batch Loss: 0.0006839920533820987\n",
      "Epoch 522, Loss: 0.0009535113640595227, Final Batch Loss: 0.00042395220953039825\n",
      "Epoch 523, Loss: 0.0026340599870309234, Final Batch Loss: 0.0014234880218282342\n",
      "Epoch 524, Loss: 0.0017527687014080584, Final Batch Loss: 0.0002826419076882303\n",
      "Epoch 525, Loss: 0.0015043173043522984, Final Batch Loss: 0.00017259668675251305\n",
      "Epoch 526, Loss: 0.000913838593987748, Final Batch Loss: 0.00025380656006745994\n",
      "Epoch 527, Loss: 0.014668275136500597, Final Batch Loss: 0.0044054207392036915\n",
      "Epoch 528, Loss: 0.005157493462320417, Final Batch Loss: 0.00042157102143391967\n",
      "Epoch 529, Loss: 0.001455341000109911, Final Batch Loss: 0.0005833417526446283\n",
      "Epoch 530, Loss: 0.0025596316118026152, Final Batch Loss: 0.00021031383948866278\n",
      "Epoch 531, Loss: 0.004361825645901263, Final Batch Loss: 0.0013700291747227311\n",
      "Epoch 532, Loss: 0.008295285340864211, Final Batch Loss: 0.007490490563213825\n",
      "Epoch 533, Loss: 0.010024109855294228, Final Batch Loss: 0.002879754640161991\n",
      "Epoch 534, Loss: 0.0011910456814803183, Final Batch Loss: 0.0005890961037948728\n",
      "Epoch 535, Loss: 0.0046335888328030705, Final Batch Loss: 0.003210077527910471\n",
      "Epoch 536, Loss: 0.0027992241084575653, Final Batch Loss: 0.0013157161884009838\n",
      "Epoch 537, Loss: 0.0016420024039689451, Final Batch Loss: 0.0003967735974583775\n",
      "Epoch 538, Loss: 0.0015632447830284946, Final Batch Loss: 0.00010293971718056127\n",
      "Epoch 539, Loss: 0.0018032410298474133, Final Batch Loss: 0.0012322955299168825\n",
      "Epoch 540, Loss: 0.002881408901885152, Final Batch Loss: 0.0011679672170430422\n",
      "Epoch 541, Loss: 0.0018798515084199607, Final Batch Loss: 0.0013558806385844946\n",
      "Epoch 542, Loss: 0.004771224281284958, Final Batch Loss: 0.0005369620048440993\n",
      "Epoch 543, Loss: 0.0017800861969590187, Final Batch Loss: 0.0004793985281139612\n",
      "Epoch 544, Loss: 0.0019750638166442513, Final Batch Loss: 0.000539375701919198\n",
      "Epoch 545, Loss: 0.002948594861663878, Final Batch Loss: 0.0012585946824401617\n",
      "Epoch 546, Loss: 0.004342490457929671, Final Batch Loss: 0.00306352274492383\n",
      "Epoch 547, Loss: 0.0019675116636790335, Final Batch Loss: 0.0006596039165742695\n",
      "Epoch 548, Loss: 0.002500265254639089, Final Batch Loss: 0.0017511140322312713\n",
      "Epoch 549, Loss: 0.0034564111847430468, Final Batch Loss: 0.0019285234156996012\n",
      "Epoch 550, Loss: 0.004124575469177216, Final Batch Loss: 0.0009583206265233457\n",
      "Epoch 551, Loss: 0.003755853686016053, Final Batch Loss: 0.0028505187947303057\n",
      "Epoch 552, Loss: 0.0015815766237210482, Final Batch Loss: 0.0011410154402256012\n",
      "Epoch 553, Loss: 0.0011651743843685836, Final Batch Loss: 0.0002203117765020579\n",
      "Epoch 554, Loss: 0.0034905113861896098, Final Batch Loss: 0.0002647117362357676\n",
      "Epoch 555, Loss: 0.0037869514198973775, Final Batch Loss: 0.00029565009754151106\n",
      "Epoch 556, Loss: 0.006678463076241314, Final Batch Loss: 0.006131349131464958\n",
      "Epoch 557, Loss: 0.006247679717489518, Final Batch Loss: 0.00019147527927998453\n",
      "Epoch 558, Loss: 0.008361911517567933, Final Batch Loss: 0.00031465955544263124\n",
      "Epoch 559, Loss: 0.0026007640408352017, Final Batch Loss: 0.0012148937676101923\n",
      "Epoch 560, Loss: 0.0031553643057122827, Final Batch Loss: 0.0010686971945688128\n",
      "Epoch 561, Loss: 0.0035693192621693015, Final Batch Loss: 0.000730702537111938\n",
      "Epoch 562, Loss: 0.0024055922694969922, Final Batch Loss: 0.0019676918163895607\n",
      "Epoch 563, Loss: 0.0007514450990129262, Final Batch Loss: 0.00028957834001630545\n",
      "Epoch 564, Loss: 0.002021072490606457, Final Batch Loss: 0.00025280140107497573\n",
      "Epoch 565, Loss: 0.0009716830390971154, Final Batch Loss: 0.000487689976580441\n",
      "Epoch 566, Loss: 0.0021964417537674308, Final Batch Loss: 0.0007544808322563767\n",
      "Epoch 567, Loss: 0.011193784303031862, Final Batch Loss: 0.00041997653897851706\n",
      "Epoch 568, Loss: 0.001479951199144125, Final Batch Loss: 0.0005087562021799386\n",
      "Epoch 569, Loss: 0.002114092232659459, Final Batch Loss: 0.0013529561692848802\n",
      "Epoch 570, Loss: 0.0023294533893931657, Final Batch Loss: 0.00187278154771775\n",
      "Epoch 571, Loss: 0.008037595893256366, Final Batch Loss: 0.007296157535165548\n",
      "Epoch 572, Loss: 0.00222495539492229, Final Batch Loss: 6.239015056053177e-05\n",
      "Epoch 573, Loss: 0.0014808462583459914, Final Batch Loss: 0.0001943624229170382\n",
      "Epoch 574, Loss: 0.0006621915672440082, Final Batch Loss: 0.0003659012436401099\n",
      "Epoch 575, Loss: 0.003309709776658565, Final Batch Loss: 0.0002474790089763701\n",
      "Epoch 576, Loss: 0.0007949348582769744, Final Batch Loss: 0.00010184599523199722\n",
      "Epoch 577, Loss: 0.0022262866841629148, Final Batch Loss: 0.0011994600063189864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578, Loss: 0.0013209094759076834, Final Batch Loss: 0.00032280723098665476\n",
      "Epoch 579, Loss: 0.0005040993419243023, Final Batch Loss: 0.000185780503670685\n",
      "Epoch 580, Loss: 0.00686533167026937, Final Batch Loss: 0.006019483786076307\n",
      "Epoch 581, Loss: 0.0020596332906279713, Final Batch Loss: 0.0003652499581221491\n",
      "Epoch 582, Loss: 0.004027553732157685, Final Batch Loss: 0.00017939544341061264\n",
      "Epoch 583, Loss: 0.0013114812900312245, Final Batch Loss: 0.0007275590323843062\n",
      "Epoch 584, Loss: 0.0018824497237801552, Final Batch Loss: 0.0008515460649505258\n",
      "Epoch 585, Loss: 0.0021327786380425096, Final Batch Loss: 0.0010920899221673608\n",
      "Epoch 586, Loss: 0.007946918485686183, Final Batch Loss: 0.006199951283633709\n",
      "Epoch 587, Loss: 0.0010936071921605617, Final Batch Loss: 0.0006732077454216778\n",
      "Epoch 588, Loss: 0.001475718163419515, Final Batch Loss: 0.0002554633538238704\n",
      "Epoch 589, Loss: 0.024579592631198466, Final Batch Loss: 0.0016124012181535363\n",
      "Epoch 590, Loss: 0.0010530668077990413, Final Batch Loss: 0.00038480659713968635\n",
      "Epoch 591, Loss: 0.0025015375285875052, Final Batch Loss: 0.0022319776471704245\n",
      "Epoch 592, Loss: 0.0033553962130099535, Final Batch Loss: 0.0005644187331199646\n",
      "Epoch 593, Loss: 0.004526563338004053, Final Batch Loss: 0.004303742665797472\n",
      "Epoch 594, Loss: 0.0016735310200601816, Final Batch Loss: 0.000341991544701159\n",
      "Epoch 595, Loss: 0.004192525404505432, Final Batch Loss: 0.0011020383099094033\n",
      "Epoch 596, Loss: 0.003500354359857738, Final Batch Loss: 0.0016540794167667627\n",
      "Epoch 597, Loss: 0.0004666903696488589, Final Batch Loss: 0.00023983909341041\n",
      "Epoch 598, Loss: 0.0011175740510225296, Final Batch Loss: 0.000772396451793611\n",
      "Epoch 599, Loss: 0.0038030155119486153, Final Batch Loss: 0.0034029267262667418\n",
      "Epoch 600, Loss: 0.002287908020662144, Final Batch Loss: 0.0018181774066761136\n",
      "Epoch 601, Loss: 0.003557239309884608, Final Batch Loss: 0.0005726300878450274\n",
      "Epoch 602, Loss: 0.0031600386137142777, Final Batch Loss: 0.0014863424003124237\n",
      "Epoch 603, Loss: 0.003326338774058968, Final Batch Loss: 0.0025307845789939165\n",
      "Epoch 604, Loss: 0.007399701571557671, Final Batch Loss: 0.006958161946386099\n",
      "Epoch 605, Loss: 0.0020953154380549677, Final Batch Loss: 8.976908429758623e-05\n",
      "Epoch 606, Loss: 0.006070652772905305, Final Batch Loss: 0.0057305521331727505\n",
      "Epoch 607, Loss: 0.0029245057958178222, Final Batch Loss: 0.0007947338162921369\n",
      "Epoch 608, Loss: 0.0019948306726291776, Final Batch Loss: 0.000963725964538753\n",
      "Epoch 609, Loss: 0.001204376239911653, Final Batch Loss: 0.0002070161426672712\n",
      "Epoch 610, Loss: 0.0036776325141545385, Final Batch Loss: 0.003217762103304267\n",
      "Epoch 611, Loss: 0.0012301372189540416, Final Batch Loss: 0.0003776133817154914\n",
      "Epoch 612, Loss: 0.010526438825763762, Final Batch Loss: 0.009505792520940304\n",
      "Epoch 613, Loss: 0.001801796373911202, Final Batch Loss: 0.0009645227692089975\n",
      "Epoch 614, Loss: 0.013295711250975728, Final Batch Loss: 0.01116870529949665\n",
      "Epoch 615, Loss: 0.000329935341142118, Final Batch Loss: 0.000168447702890262\n",
      "Epoch 616, Loss: 0.017867272486910224, Final Batch Loss: 0.0020367649849504232\n",
      "Epoch 617, Loss: 0.0018332856707274914, Final Batch Loss: 0.0009802152635529637\n",
      "Epoch 618, Loss: 0.0008751527057029307, Final Batch Loss: 0.00016314827371388674\n",
      "Epoch 619, Loss: 0.0023397149343509227, Final Batch Loss: 0.0003803298168350011\n",
      "Epoch 620, Loss: 0.008447448439255822, Final Batch Loss: 7.283472950803116e-05\n",
      "Epoch 621, Loss: 0.00046271692554000765, Final Batch Loss: 0.00022752008226234466\n",
      "Epoch 622, Loss: 0.000514870960614644, Final Batch Loss: 0.00022963907395023853\n",
      "Epoch 623, Loss: 0.0009004336316138506, Final Batch Loss: 0.00035560806281864643\n",
      "Epoch 624, Loss: 0.0011323296348564327, Final Batch Loss: 0.0007880607154220343\n",
      "Epoch 625, Loss: 0.0029518417723011225, Final Batch Loss: 0.00038563573616556823\n",
      "Epoch 626, Loss: 0.0014695509598823264, Final Batch Loss: 0.000165135323186405\n",
      "Epoch 627, Loss: 0.0008838684880174696, Final Batch Loss: 0.00042785523692145944\n",
      "Epoch 628, Loss: 0.0011549245682545006, Final Batch Loss: 0.0006663014064542949\n",
      "Epoch 629, Loss: 0.0013700720155611634, Final Batch Loss: 0.0007730498909950256\n",
      "Epoch 630, Loss: 0.000321078572596889, Final Batch Loss: 6.180020136525854e-05\n",
      "Epoch 631, Loss: 0.004990975488908589, Final Batch Loss: 0.0002817801432684064\n",
      "Epoch 632, Loss: 0.001972994301468134, Final Batch Loss: 0.0012960246531292796\n",
      "Epoch 633, Loss: 0.0006034275284036994, Final Batch Loss: 0.00030044952291063964\n",
      "Epoch 634, Loss: 0.005629656370729208, Final Batch Loss: 0.004930911585688591\n",
      "Epoch 635, Loss: 0.002559954358730465, Final Batch Loss: 0.0009140443871729076\n",
      "Epoch 636, Loss: 0.0014506953884847462, Final Batch Loss: 0.0005871945177204907\n",
      "Epoch 637, Loss: 0.000723566219676286, Final Batch Loss: 0.00040631924639455974\n",
      "Epoch 638, Loss: 0.0010579887821222655, Final Batch Loss: 0.0001049858910846524\n",
      "Epoch 639, Loss: 0.0012767209555022418, Final Batch Loss: 0.00057936244411394\n",
      "Epoch 640, Loss: 0.013897078577429056, Final Batch Loss: 0.012531802989542484\n",
      "Epoch 641, Loss: 0.007918019211501814, Final Batch Loss: 0.0002224318595835939\n",
      "Epoch 642, Loss: 0.025577364896889776, Final Batch Loss: 0.024921339005231857\n",
      "Epoch 643, Loss: 0.0005389313446357846, Final Batch Loss: 0.00029229128267616034\n",
      "Epoch 644, Loss: 0.0022414698323700577, Final Batch Loss: 0.00037670720485039055\n",
      "Epoch 645, Loss: 0.0049705926212482154, Final Batch Loss: 0.004703941289335489\n",
      "Epoch 646, Loss: 0.0020216110860928893, Final Batch Loss: 0.0013929386623203754\n",
      "Epoch 647, Loss: 0.0042566643096506596, Final Batch Loss: 0.00046781403943896294\n",
      "Epoch 648, Loss: 0.0003204913082299754, Final Batch Loss: 0.0001564180274726823\n",
      "Epoch 649, Loss: 0.001986163668334484, Final Batch Loss: 0.0015620215563103557\n",
      "Epoch 650, Loss: 0.0012578816676978022, Final Batch Loss: 0.00043952613486908376\n",
      "Epoch 651, Loss: 0.0018505480547901243, Final Batch Loss: 0.00044786473154090345\n",
      "Epoch 652, Loss: 0.0012166172091383487, Final Batch Loss: 0.0007734897662885487\n",
      "Epoch 653, Loss: 0.0005334858869900927, Final Batch Loss: 0.00029251258820295334\n",
      "Epoch 654, Loss: 0.006749764259438962, Final Batch Loss: 0.006421651225537062\n",
      "Epoch 655, Loss: 0.0024652936699567363, Final Batch Loss: 0.0001731798256514594\n",
      "Epoch 656, Loss: 0.003413263417314738, Final Batch Loss: 0.002441635588183999\n",
      "Epoch 657, Loss: 0.0015664238599129021, Final Batch Loss: 0.0008896873914636672\n",
      "Epoch 658, Loss: 0.0025337766855955124, Final Batch Loss: 0.00038130022585392\n",
      "Epoch 659, Loss: 0.0033302851661574095, Final Batch Loss: 0.0002570850483607501\n",
      "Epoch 660, Loss: 0.0029197618132457137, Final Batch Loss: 0.0014493780909106135\n",
      "Epoch 661, Loss: 0.0012948075745953247, Final Batch Loss: 0.0002387393469689414\n",
      "Epoch 662, Loss: 0.0010632213961798698, Final Batch Loss: 0.0006811751518398523\n",
      "Epoch 663, Loss: 0.0026801718049682677, Final Batch Loss: 0.000454917608294636\n",
      "Epoch 664, Loss: 0.0013040528865531087, Final Batch Loss: 0.0007728721830062568\n",
      "Epoch 665, Loss: 0.0035495499469107017, Final Batch Loss: 0.0001196197554236278\n",
      "Epoch 666, Loss: 0.003712695324793458, Final Batch Loss: 0.0030294833704829216\n",
      "Epoch 667, Loss: 0.0015091239183675498, Final Batch Loss: 0.0003843398008029908\n",
      "Epoch 668, Loss: 0.004734393209218979, Final Batch Loss: 0.0044224439188838005\n",
      "Epoch 669, Loss: 0.0063954247161746025, Final Batch Loss: 0.0011136936955153942\n",
      "Epoch 670, Loss: 0.0020367697288747877, Final Batch Loss: 0.0003272931498941034\n",
      "Epoch 671, Loss: 0.0003945997741539031, Final Batch Loss: 8.053623605519533e-05\n",
      "Epoch 672, Loss: 0.006047842529369518, Final Batch Loss: 0.0003165453381370753\n",
      "Epoch 673, Loss: 0.0028935370573890395, Final Batch Loss: 0.00010983809625031427\n",
      "Epoch 674, Loss: 0.008693960087839514, Final Batch Loss: 0.008380393497645855\n",
      "Epoch 675, Loss: 0.0004299993015592918, Final Batch Loss: 0.00014676865248475224\n",
      "Epoch 676, Loss: 0.0034708211896941066, Final Batch Loss: 0.0012057471321895719\n",
      "Epoch 677, Loss: 0.0031373289093608037, Final Batch Loss: 0.00021007565374020487\n",
      "Epoch 678, Loss: 0.000798613327788189, Final Batch Loss: 0.0006120105390436947\n",
      "Epoch 679, Loss: 0.0003518816374707967, Final Batch Loss: 0.00014753389405086637\n",
      "Epoch 680, Loss: 0.0006060272717149928, Final Batch Loss: 0.00048530357889831066\n",
      "Epoch 681, Loss: 0.005700293375412002, Final Batch Loss: 0.005289228167384863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682, Loss: 0.0021744408295489848, Final Batch Loss: 0.000332580937538296\n",
      "Epoch 683, Loss: 0.0009924183832481503, Final Batch Loss: 0.0005579240387305617\n",
      "Epoch 684, Loss: 0.0005646861245622858, Final Batch Loss: 0.00020424673857633024\n",
      "Epoch 685, Loss: 0.0008852374012349173, Final Batch Loss: 0.0007103290408849716\n",
      "Epoch 686, Loss: 0.0007954854518175125, Final Batch Loss: 0.00041584557038731873\n",
      "Epoch 687, Loss: 0.001973380916751921, Final Batch Loss: 0.00043898168951272964\n",
      "Epoch 688, Loss: 0.0006463791651185602, Final Batch Loss: 0.00032757766894064844\n",
      "Epoch 689, Loss: 0.00026012029411504045, Final Batch Loss: 1.4827885024715215e-05\n",
      "Epoch 690, Loss: 0.0060042847362637985, Final Batch Loss: 3.3726584661053494e-05\n",
      "Epoch 691, Loss: 0.0061840524431318045, Final Batch Loss: 0.001449814299121499\n",
      "Epoch 692, Loss: 0.0010145743726752698, Final Batch Loss: 0.0002677428419701755\n",
      "Epoch 693, Loss: 0.0005771103751612827, Final Batch Loss: 0.000341435574227944\n",
      "Epoch 694, Loss: 0.005687925266101956, Final Batch Loss: 0.00021109473891556263\n",
      "Epoch 695, Loss: 0.0014652848622063175, Final Batch Loss: 0.0012821841519325972\n",
      "Epoch 696, Loss: 0.0018070272308250424, Final Batch Loss: 5.801263250759803e-05\n",
      "Epoch 697, Loss: 0.00181546964449808, Final Batch Loss: 0.0005820617661811411\n",
      "Epoch 698, Loss: 0.00023464244441129267, Final Batch Loss: 7.130386075004935e-05\n",
      "Epoch 699, Loss: 0.03852786053903401, Final Batch Loss: 0.035421695560216904\n",
      "Epoch 700, Loss: 0.0006531890976475552, Final Batch Loss: 0.0004608943418134004\n",
      "Epoch 701, Loss: 0.0019785447511821985, Final Batch Loss: 0.00013956334441900253\n",
      "Epoch 702, Loss: 0.0013362770550884306, Final Batch Loss: 0.00020669243531301618\n",
      "Epoch 703, Loss: 0.011083954886998981, Final Batch Loss: 0.01078222319483757\n",
      "Epoch 704, Loss: 0.023636164842173457, Final Batch Loss: 0.021461239084601402\n",
      "Epoch 705, Loss: 0.011686790181556717, Final Batch Loss: 0.00016715694800950587\n",
      "Epoch 706, Loss: 0.0023353959841188043, Final Batch Loss: 0.001973693026229739\n",
      "Epoch 707, Loss: 0.0008366037509404123, Final Batch Loss: 0.00025346141774207354\n",
      "Epoch 708, Loss: 0.007341264979913831, Final Batch Loss: 0.004916694480925798\n",
      "Epoch 709, Loss: 0.000733596010832116, Final Batch Loss: 0.0004283613816369325\n",
      "Epoch 710, Loss: 0.0027142206236021593, Final Batch Loss: 0.00022657839872408658\n",
      "Epoch 711, Loss: 0.0053844478679820895, Final Batch Loss: 0.0010048829717561603\n",
      "Epoch 712, Loss: 0.005226844048593193, Final Batch Loss: 0.00028789654606953263\n",
      "Epoch 713, Loss: 0.0009201804059557617, Final Batch Loss: 0.0005550728528760374\n",
      "Epoch 714, Loss: 0.0027606736111920327, Final Batch Loss: 0.002303226152434945\n",
      "Epoch 715, Loss: 0.000515454012202099, Final Batch Loss: 0.00021863187430426478\n",
      "Epoch 716, Loss: 0.002715105307288468, Final Batch Loss: 0.0003126418450847268\n",
      "Epoch 717, Loss: 0.004073809483088553, Final Batch Loss: 0.0012352355988696218\n",
      "Epoch 718, Loss: 0.016044261399656534, Final Batch Loss: 0.00021161185577511787\n",
      "Epoch 719, Loss: 0.01222428574692458, Final Batch Loss: 0.011398802511394024\n",
      "Epoch 720, Loss: 0.006611101882299408, Final Batch Loss: 0.00620571942999959\n",
      "Epoch 721, Loss: 0.0050118472427129745, Final Batch Loss: 0.004451789893209934\n",
      "Epoch 722, Loss: 0.004763236967846751, Final Batch Loss: 0.0007397222798317671\n",
      "Epoch 723, Loss: 0.03129589091986418, Final Batch Loss: 0.0004858868196606636\n",
      "Epoch 724, Loss: 0.008409450994804502, Final Batch Loss: 0.0005495010409504175\n",
      "Epoch 725, Loss: 0.008723543141968548, Final Batch Loss: 0.001542852376587689\n",
      "Epoch 726, Loss: 0.0027836435474455357, Final Batch Loss: 0.0012937234714627266\n",
      "Epoch 727, Loss: 0.0008418915240326896, Final Batch Loss: 6.768324237782508e-05\n",
      "Epoch 728, Loss: 0.004198159906081855, Final Batch Loss: 0.001897108624689281\n",
      "Epoch 729, Loss: 0.0015372663619928062, Final Batch Loss: 0.0006667926209047437\n",
      "Epoch 730, Loss: 0.002748406357568456, Final Batch Loss: 6.004339593346231e-05\n",
      "Epoch 731, Loss: 0.002578468876890838, Final Batch Loss: 0.0021574224811047316\n",
      "Epoch 732, Loss: 0.0008474280475638807, Final Batch Loss: 0.00048599482397548854\n",
      "Epoch 733, Loss: 0.0018135389254894108, Final Batch Loss: 0.00012436285032890737\n",
      "Epoch 734, Loss: 0.0004199694958515465, Final Batch Loss: 0.0002414775954093784\n",
      "Epoch 735, Loss: 0.0012618765467777848, Final Batch Loss: 0.000882735475897789\n",
      "Epoch 736, Loss: 0.001637123161344789, Final Batch Loss: 7.859522884245962e-05\n",
      "Epoch 737, Loss: 0.0029587482422357425, Final Batch Loss: 0.0027377409860491753\n",
      "Epoch 738, Loss: 0.0018491418450139463, Final Batch Loss: 0.0009208665578626096\n",
      "Epoch 739, Loss: 0.0008103533036774024, Final Batch Loss: 0.000568073708564043\n",
      "Epoch 740, Loss: 0.0008750292763579637, Final Batch Loss: 0.00035484382533468306\n",
      "Epoch 741, Loss: 0.001496317912824452, Final Batch Loss: 0.0010593516053631902\n",
      "Epoch 742, Loss: 0.0007739827706245705, Final Batch Loss: 0.00011502792767714709\n",
      "Epoch 743, Loss: 0.0010898502368945628, Final Batch Loss: 0.0003894404217135161\n",
      "Epoch 744, Loss: 0.0006671531882602721, Final Batch Loss: 0.00032052304595708847\n",
      "Epoch 745, Loss: 0.0007310406799660996, Final Batch Loss: 0.0006293050828389823\n",
      "Epoch 746, Loss: 0.0005581347359111533, Final Batch Loss: 0.0001502761006122455\n",
      "Epoch 747, Loss: 0.001429106545401737, Final Batch Loss: 0.0010622564004734159\n",
      "Epoch 748, Loss: 0.0036657145828939974, Final Batch Loss: 0.0006629163981415331\n",
      "Epoch 749, Loss: 0.006698842043988407, Final Batch Loss: 0.005753498990088701\n",
      "Epoch 750, Loss: 0.00708519449835876, Final Batch Loss: 0.006988525390625\n",
      "Epoch 751, Loss: 0.0017830674842116423, Final Batch Loss: 6.462413148256019e-05\n",
      "Epoch 752, Loss: 0.0027037947438657284, Final Batch Loss: 0.0005826668348163366\n",
      "Epoch 753, Loss: 0.0006645653920713812, Final Batch Loss: 0.00031584384851157665\n",
      "Epoch 754, Loss: 0.0025161431985907257, Final Batch Loss: 0.0017081027617678046\n",
      "Epoch 755, Loss: 0.0015018194098956883, Final Batch Loss: 0.0009228684939444065\n",
      "Epoch 756, Loss: 0.0022795861586928368, Final Batch Loss: 0.0005632269894704223\n",
      "Epoch 757, Loss: 0.00032588589238002896, Final Batch Loss: 0.00011333463771734387\n",
      "Epoch 758, Loss: 0.0021115475974511355, Final Batch Loss: 0.00036335698678158224\n",
      "Epoch 759, Loss: 0.0025306194293079898, Final Batch Loss: 0.0023377337493002415\n",
      "Epoch 760, Loss: 0.0011921935365535319, Final Batch Loss: 0.0005524001317098737\n",
      "Epoch 761, Loss: 0.0007504000677727163, Final Batch Loss: 0.0004567102587316185\n",
      "Epoch 762, Loss: 0.0006673123862128705, Final Batch Loss: 0.00044665884342975914\n",
      "Epoch 763, Loss: 0.0016015618457458913, Final Batch Loss: 0.0010053639998659492\n",
      "Epoch 764, Loss: 0.015380570868728682, Final Batch Loss: 0.015050379559397697\n",
      "Epoch 765, Loss: 0.001525473315268755, Final Batch Loss: 0.0008909005555324256\n",
      "Epoch 766, Loss: 0.0020439434447325766, Final Batch Loss: 0.0013740644790232182\n",
      "Epoch 767, Loss: 0.003368685662280768, Final Batch Loss: 0.000501564412843436\n",
      "Epoch 768, Loss: 0.0020336732268333435, Final Batch Loss: 0.0015883418964222074\n",
      "Epoch 769, Loss: 0.002789446349197533, Final Batch Loss: 6.46914922981523e-05\n",
      "Epoch 770, Loss: 0.004573573227389716, Final Batch Loss: 0.0002089867921313271\n",
      "Epoch 771, Loss: 0.0010694107040762901, Final Batch Loss: 0.0003384443698450923\n",
      "Epoch 772, Loss: 0.0009130084654316306, Final Batch Loss: 0.00027839367976412177\n",
      "Epoch 773, Loss: 0.001451393764000386, Final Batch Loss: 0.0008982180734165013\n",
      "Epoch 774, Loss: 0.0014587401528842747, Final Batch Loss: 0.0008683601627126336\n",
      "Epoch 775, Loss: 0.00023600328131578863, Final Batch Loss: 8.815582259558141e-05\n",
      "Epoch 776, Loss: 0.003804005798883736, Final Batch Loss: 0.002193841617554426\n",
      "Epoch 777, Loss: 0.0023609136405866593, Final Batch Loss: 0.00015647939289920032\n",
      "Epoch 778, Loss: 0.0004366591019788757, Final Batch Loss: 0.000341822364134714\n",
      "Epoch 779, Loss: 0.007452901190845296, Final Batch Loss: 0.0003233828756492585\n",
      "Epoch 780, Loss: 0.003782317799050361, Final Batch Loss: 0.00040221918607130647\n",
      "Epoch 781, Loss: 0.002819446352077648, Final Batch Loss: 0.00017124877194873989\n",
      "Epoch 782, Loss: 0.0004133872425882146, Final Batch Loss: 0.00015717251517344266\n",
      "Epoch 783, Loss: 0.000909392285393551, Final Batch Loss: 0.0002599099825602025\n",
      "Epoch 784, Loss: 0.0007046369573799893, Final Batch Loss: 0.00018337454821448773\n",
      "Epoch 785, Loss: 0.0037585153768304735, Final Batch Loss: 0.00020286176004447043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 786, Loss: 0.0007286115433089435, Final Batch Loss: 0.00027309326105751097\n",
      "Epoch 787, Loss: 0.00969067175174132, Final Batch Loss: 0.0005587558844126761\n",
      "Epoch 788, Loss: 0.0007501574291381985, Final Batch Loss: 0.0004931772127747536\n",
      "Epoch 789, Loss: 0.0014152719522826374, Final Batch Loss: 0.000984066748060286\n",
      "Epoch 790, Loss: 0.0006067900394555181, Final Batch Loss: 0.00032384891528636217\n",
      "Epoch 791, Loss: 0.0002007840885198675, Final Batch Loss: 0.00010272321378579363\n",
      "Epoch 792, Loss: 0.0003968898963648826, Final Batch Loss: 7.050202111713588e-05\n",
      "Epoch 793, Loss: 0.0013690090272575617, Final Batch Loss: 0.0006016003899276257\n",
      "Epoch 794, Loss: 0.0008643640030641109, Final Batch Loss: 0.0006011571967974305\n",
      "Epoch 795, Loss: 0.002952133771032095, Final Batch Loss: 0.0018993817502632737\n",
      "Epoch 796, Loss: 0.00034588250855449587, Final Batch Loss: 0.00010944322275463492\n",
      "Epoch 797, Loss: 0.0033268071711063385, Final Batch Loss: 0.00248191156424582\n",
      "Epoch 798, Loss: 0.0008362668813788332, Final Batch Loss: 5.78209655941464e-05\n",
      "Epoch 799, Loss: 0.0005930652259849012, Final Batch Loss: 0.0002557869302108884\n",
      "Epoch 800, Loss: 0.0004188863531453535, Final Batch Loss: 0.00027260457864031196\n",
      "Epoch 801, Loss: 0.0004037908074678853, Final Batch Loss: 0.00017578256665728986\n",
      "Epoch 802, Loss: 0.0011147001932840794, Final Batch Loss: 0.0002075562661048025\n",
      "Epoch 803, Loss: 0.0056301699369214475, Final Batch Loss: 0.005141628440469503\n",
      "Epoch 804, Loss: 0.0009138349269051105, Final Batch Loss: 0.0006837575929239392\n",
      "Epoch 805, Loss: 0.0007777794962748885, Final Batch Loss: 0.00047776207793504\n",
      "Epoch 806, Loss: 0.002132252440787852, Final Batch Loss: 0.0007148077711462975\n",
      "Epoch 807, Loss: 0.0004475399327930063, Final Batch Loss: 0.0002487421443220228\n",
      "Epoch 808, Loss: 0.019969962013419718, Final Batch Loss: 0.01967352256178856\n",
      "Epoch 809, Loss: 0.004838992317672819, Final Batch Loss: 0.0007603628910146654\n",
      "Epoch 810, Loss: 0.0005719973123632371, Final Batch Loss: 0.0004404992505442351\n",
      "Epoch 811, Loss: 0.009974782326025888, Final Batch Loss: 9.866149048320949e-05\n",
      "Epoch 812, Loss: 0.0018713493482209742, Final Batch Loss: 0.0008224970079027116\n",
      "Epoch 813, Loss: 0.0010470238630659878, Final Batch Loss: 0.0006377784884534776\n",
      "Epoch 814, Loss: 0.0011494039790704846, Final Batch Loss: 0.0007875491864979267\n",
      "Epoch 815, Loss: 0.006767151411622763, Final Batch Loss: 0.0038933842442929745\n",
      "Epoch 816, Loss: 0.0029010520956944674, Final Batch Loss: 0.0002341412182431668\n",
      "Epoch 817, Loss: 0.0018655274761840701, Final Batch Loss: 0.0013672432396560907\n",
      "Epoch 818, Loss: 0.0025901876215357333, Final Batch Loss: 0.002224297495558858\n",
      "Epoch 819, Loss: 0.0005898326980968704, Final Batch Loss: 2.3329723262577318e-05\n",
      "Epoch 820, Loss: 0.0007652392159798183, Final Batch Loss: 6.444604514399543e-05\n",
      "Epoch 821, Loss: 0.0008166664192685857, Final Batch Loss: 5.388889985624701e-05\n",
      "Epoch 822, Loss: 0.004961613361956552, Final Batch Loss: 0.004577317275106907\n",
      "Epoch 823, Loss: 0.0021309113362804055, Final Batch Loss: 0.0005348692648112774\n",
      "Epoch 824, Loss: 0.0010716872347984463, Final Batch Loss: 0.0003831279173027724\n",
      "Epoch 825, Loss: 0.003410799370612949, Final Batch Loss: 0.00024043692974373698\n",
      "Epoch 826, Loss: 0.0007132957107387483, Final Batch Loss: 0.00024653904256410897\n",
      "Epoch 827, Loss: 0.00030146212156978436, Final Batch Loss: 6.0784721426898614e-05\n",
      "Epoch 828, Loss: 0.0031085514929145575, Final Batch Loss: 0.0023614708334207535\n",
      "Epoch 829, Loss: 0.0013031958951614797, Final Batch Loss: 0.0005952392239123583\n",
      "Epoch 830, Loss: 0.003422881767619401, Final Batch Loss: 0.0009383608703501523\n",
      "Epoch 831, Loss: 0.00895104929804802, Final Batch Loss: 0.005265773274004459\n",
      "Epoch 832, Loss: 0.0004164527199463919, Final Batch Loss: 0.0002072524803224951\n",
      "Epoch 833, Loss: 0.0004369272501207888, Final Batch Loss: 0.0003257332427892834\n",
      "Epoch 834, Loss: 0.0013396319700405002, Final Batch Loss: 0.0011632342357188463\n",
      "Epoch 835, Loss: 0.0005450809476315044, Final Batch Loss: 0.00042781958472914994\n",
      "Epoch 836, Loss: 0.0006506688805529848, Final Batch Loss: 0.00021109690715093166\n",
      "Epoch 837, Loss: 0.006454137386754155, Final Batch Loss: 0.00227041426114738\n",
      "Epoch 838, Loss: 0.003646750934422016, Final Batch Loss: 0.0017696195282042027\n",
      "Epoch 839, Loss: 0.0002838853106368333, Final Batch Loss: 7.598767115268856e-05\n",
      "Epoch 840, Loss: 0.007113478262908757, Final Batch Loss: 0.0018712809542194009\n",
      "Epoch 841, Loss: 0.0001555415910843294, Final Batch Loss: 3.443872628849931e-05\n",
      "Epoch 842, Loss: 0.0008363445522263646, Final Batch Loss: 0.0002659233286976814\n",
      "Epoch 843, Loss: 0.004244579075020738, Final Batch Loss: 0.004060266073793173\n",
      "Epoch 844, Loss: 0.002746471989667043, Final Batch Loss: 0.0022992740850895643\n",
      "Epoch 845, Loss: 0.0009498313520452939, Final Batch Loss: 8.979983249446377e-05\n",
      "Epoch 846, Loss: 0.009118898306041956, Final Batch Loss: 0.008395310491323471\n",
      "Epoch 847, Loss: 0.0002531174905016087, Final Batch Loss: 0.00011392421583877876\n",
      "Epoch 848, Loss: 0.0002875910940929316, Final Batch Loss: 0.0001786478387657553\n",
      "Epoch 849, Loss: 0.004719570497400127, Final Batch Loss: 0.00018921330047305673\n",
      "Epoch 850, Loss: 0.0037677872023778036, Final Batch Loss: 0.0035364204086363316\n",
      "Epoch 851, Loss: 0.0009402994182892144, Final Batch Loss: 0.00022963806986808777\n",
      "Epoch 852, Loss: 0.0004263126102159731, Final Batch Loss: 8.277020970126614e-05\n",
      "Epoch 853, Loss: 0.009525842731818557, Final Batch Loss: 0.008539407514035702\n",
      "Epoch 854, Loss: 0.004337068385211751, Final Batch Loss: 0.0004163502890150994\n",
      "Epoch 855, Loss: 0.0011279257596470416, Final Batch Loss: 9.217177284881473e-05\n",
      "Epoch 856, Loss: 0.004221840121317655, Final Batch Loss: 0.0036687457468360662\n",
      "Epoch 857, Loss: 0.00020971341291442513, Final Batch Loss: 0.00016039008914958686\n",
      "Epoch 858, Loss: 0.00582953417324461, Final Batch Loss: 0.0002627746725920588\n",
      "Epoch 859, Loss: 0.0005482918495545164, Final Batch Loss: 0.0001911163708427921\n",
      "Epoch 860, Loss: 0.007770293625071645, Final Batch Loss: 0.004181774333119392\n",
      "Epoch 861, Loss: 0.006562027207110077, Final Batch Loss: 0.0004855557926930487\n",
      "Epoch 862, Loss: 0.0013497185573214665, Final Batch Loss: 0.00013594016490969807\n",
      "Epoch 863, Loss: 0.0004317296334193088, Final Batch Loss: 0.00032214648672379553\n",
      "Epoch 864, Loss: 0.003388224635273218, Final Batch Loss: 0.002163283759728074\n",
      "Epoch 865, Loss: 0.0006130396795924753, Final Batch Loss: 0.0005039501120336354\n",
      "Epoch 866, Loss: 0.0038066242123022676, Final Batch Loss: 0.0033066817559301853\n",
      "Epoch 867, Loss: 0.0010231194028165191, Final Batch Loss: 0.0007164800772443414\n",
      "Epoch 868, Loss: 0.00506398594006896, Final Batch Loss: 0.0014804659876972437\n",
      "Epoch 869, Loss: 0.0010461672209203243, Final Batch Loss: 0.000552635348867625\n",
      "Epoch 870, Loss: 0.001961801841389388, Final Batch Loss: 0.00011915742652490735\n",
      "Epoch 871, Loss: 0.0012681816006079316, Final Batch Loss: 0.0011304591316729784\n",
      "Epoch 872, Loss: 0.0002612233074614778, Final Batch Loss: 6.887302151881158e-05\n",
      "Epoch 873, Loss: 0.00460506445961073, Final Batch Loss: 0.00426130648702383\n",
      "Epoch 874, Loss: 0.0005473801138577983, Final Batch Loss: 0.00015260062355082482\n",
      "Epoch 875, Loss: 0.0002583638488431461, Final Batch Loss: 8.737533789826557e-05\n",
      "Epoch 876, Loss: 0.0002585391848697327, Final Batch Loss: 9.364439029013738e-05\n",
      "Epoch 877, Loss: 0.0036569012445397675, Final Batch Loss: 0.00048473692731931806\n",
      "Epoch 878, Loss: 9.812159805733245e-05, Final Batch Loss: 6.801685958635062e-05\n",
      "Epoch 879, Loss: 0.00041073958345805295, Final Batch Loss: 0.00036239324253983796\n",
      "Epoch 880, Loss: 0.00048423685075249523, Final Batch Loss: 0.00011976818495895714\n",
      "Epoch 881, Loss: 0.008746845065616071, Final Batch Loss: 0.00015953590627759695\n",
      "Epoch 882, Loss: 0.0003541132900863886, Final Batch Loss: 6.668452988378704e-05\n",
      "Epoch 883, Loss: 0.00038256632251432166, Final Batch Loss: 0.00026424796669743955\n",
      "Epoch 884, Loss: 0.00028309036133578047, Final Batch Loss: 7.544839900219813e-05\n",
      "Epoch 885, Loss: 0.003469871764536947, Final Batch Loss: 0.0005161042208783329\n",
      "Epoch 886, Loss: 0.003391435428056866, Final Batch Loss: 0.0025418067816644907\n",
      "Epoch 887, Loss: 0.000614846358075738, Final Batch Loss: 9.733461774885654e-05\n",
      "Epoch 888, Loss: 0.0011125036980956793, Final Batch Loss: 0.00047732406528666615\n",
      "Epoch 889, Loss: 0.0004789559752680361, Final Batch Loss: 0.00016359874280169606\n",
      "Epoch 890, Loss: 0.0031368090712931007, Final Batch Loss: 0.0030058894772082567\n",
      "Epoch 891, Loss: 0.0043459054722916335, Final Batch Loss: 0.00047017933684401214\n",
      "Epoch 892, Loss: 0.0023499999660998583, Final Batch Loss: 0.0019608824513852596\n",
      "Epoch 893, Loss: 0.0029786002851324156, Final Batch Loss: 7.7027318184264e-05\n",
      "Epoch 894, Loss: 0.0019184270640835166, Final Batch Loss: 0.001593932625837624\n",
      "Epoch 895, Loss: 0.0019056517630815506, Final Batch Loss: 0.00037827633786946535\n",
      "Epoch 896, Loss: 0.0006425177562050521, Final Batch Loss: 0.00032470683800056577\n",
      "Epoch 897, Loss: 0.0021497689449461177, Final Batch Loss: 0.0020681917667388916\n",
      "Epoch 898, Loss: 0.0006127522501628846, Final Batch Loss: 0.0004021881613880396\n",
      "Epoch 899, Loss: 0.00035507523716660216, Final Batch Loss: 0.0001077668639481999\n",
      "Epoch 900, Loss: 0.002614407683722675, Final Batch Loss: 0.0007818451849743724\n",
      "Epoch 901, Loss: 0.005075485285487957, Final Batch Loss: 0.004969144705682993\n",
      "Epoch 902, Loss: 0.0010223427671007812, Final Batch Loss: 0.0005884531419724226\n",
      "Epoch 903, Loss: 0.022300782147794962, Final Batch Loss: 0.0013494365848600864\n",
      "Epoch 904, Loss: 0.0012373403733363375, Final Batch Loss: 0.00011431144957896322\n",
      "Epoch 905, Loss: 0.004969768109731376, Final Batch Loss: 0.0030428755562752485\n",
      "Epoch 906, Loss: 0.0028242890257388353, Final Batch Loss: 0.00010913400910794735\n",
      "Epoch 907, Loss: 0.0006915542253409512, Final Batch Loss: 4.412997077452019e-05\n",
      "Epoch 908, Loss: 0.00032540079700993374, Final Batch Loss: 0.0002599652507342398\n",
      "Epoch 909, Loss: 0.002658679921296425, Final Batch Loss: 0.002489078091457486\n",
      "Epoch 910, Loss: 0.0030665149679407477, Final Batch Loss: 0.0007748232455924153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911, Loss: 0.0030032384674996138, Final Batch Loss: 0.0009503897745162249\n",
      "Epoch 912, Loss: 0.0011018167570000514, Final Batch Loss: 0.00020251351816114038\n",
      "Epoch 913, Loss: 0.0005671815597452223, Final Batch Loss: 0.0003366276796441525\n",
      "Epoch 914, Loss: 0.0022479405743069947, Final Batch Loss: 0.00018482451559975743\n",
      "Epoch 915, Loss: 0.00026590861671138555, Final Batch Loss: 0.00018251911387778819\n",
      "Epoch 916, Loss: 0.0011507621093187481, Final Batch Loss: 0.0003510335518512875\n",
      "Epoch 917, Loss: 0.0004719076241599396, Final Batch Loss: 0.0002503660798538476\n",
      "Epoch 918, Loss: 0.00048242072807624936, Final Batch Loss: 0.00019370121299289167\n",
      "Epoch 919, Loss: 0.0044464581114880275, Final Batch Loss: 5.648521982948296e-05\n",
      "Epoch 920, Loss: 0.00023732697809464298, Final Batch Loss: 3.823611405096017e-05\n",
      "Epoch 921, Loss: 0.00044073566823499277, Final Batch Loss: 5.9292193327564746e-05\n",
      "Epoch 922, Loss: 0.00040688457374926656, Final Batch Loss: 0.00024370080791413784\n",
      "Epoch 923, Loss: 0.004412405251059681, Final Batch Loss: 0.004145780112594366\n",
      "Epoch 924, Loss: 0.00015153073036344722, Final Batch Loss: 4.05622340622358e-05\n",
      "Epoch 925, Loss: 0.0006517493457067758, Final Batch Loss: 0.0002856957435142249\n",
      "Epoch 926, Loss: 0.00019723420518857893, Final Batch Loss: 2.020387000811752e-05\n",
      "Epoch 927, Loss: 0.003142735604342306, Final Batch Loss: 4.5658238377654925e-05\n",
      "Epoch 928, Loss: 0.002405330742476508, Final Batch Loss: 0.0023448418360203505\n",
      "Epoch 929, Loss: 0.0019267309980932623, Final Batch Loss: 0.0002499224210623652\n",
      "Epoch 930, Loss: 0.008964714535977691, Final Batch Loss: 0.008677950128912926\n",
      "Epoch 931, Loss: 0.00020351131752249785, Final Batch Loss: 1.786611755960621e-05\n",
      "Epoch 932, Loss: 0.0006310075696092099, Final Batch Loss: 0.00041306184721179307\n",
      "Epoch 933, Loss: 0.001900038740132004, Final Batch Loss: 0.0006945873028598726\n",
      "Epoch 934, Loss: 0.001386162213748321, Final Batch Loss: 0.0010748804779723287\n",
      "Epoch 935, Loss: 0.0005237190489424393, Final Batch Loss: 0.00014241279859561473\n",
      "Epoch 936, Loss: 0.0019770123180933297, Final Batch Loss: 0.00024355732602998614\n",
      "Epoch 937, Loss: 0.001247955864528194, Final Batch Loss: 0.0009876334806904197\n",
      "Epoch 938, Loss: 0.0002951827409560792, Final Batch Loss: 7.105712575139478e-05\n",
      "Epoch 939, Loss: 0.020811138580029365, Final Batch Loss: 7.62752242735587e-05\n",
      "Epoch 940, Loss: 0.0006612322758883238, Final Batch Loss: 0.00015316938515752554\n",
      "Epoch 941, Loss: 0.0014095207443460822, Final Batch Loss: 0.0007437917520292103\n",
      "Epoch 942, Loss: 0.0024329579591721995, Final Batch Loss: 0.002419694559648633\n",
      "Epoch 943, Loss: 0.0005717396852560341, Final Batch Loss: 0.0003808535111602396\n",
      "Epoch 944, Loss: 0.0013004378852201626, Final Batch Loss: 0.00021135997667443007\n",
      "Epoch 945, Loss: 0.0003127908712485805, Final Batch Loss: 0.00015058575081638992\n",
      "Epoch 946, Loss: 0.004504607670241967, Final Batch Loss: 0.004166572354733944\n",
      "Epoch 947, Loss: 0.0019923576328437775, Final Batch Loss: 0.00017376136383973062\n",
      "Epoch 948, Loss: 0.00034642820901353844, Final Batch Loss: 0.0003084545605815947\n",
      "Epoch 949, Loss: 0.0002617989302962087, Final Batch Loss: 0.0001649080659262836\n",
      "Epoch 950, Loss: 0.0012340348257566802, Final Batch Loss: 0.0011531882919371128\n",
      "Epoch 951, Loss: 0.0052984217763878405, Final Batch Loss: 0.00015802920097485185\n",
      "Epoch 952, Loss: 0.017650268273428082, Final Batch Loss: 0.0009943314362317324\n",
      "Epoch 953, Loss: 0.0026943848934024572, Final Batch Loss: 0.001598079688847065\n",
      "Epoch 954, Loss: 0.0003205530229024589, Final Batch Loss: 0.00019031178089790046\n",
      "Epoch 955, Loss: 0.0009892153611872345, Final Batch Loss: 0.0003434582322370261\n",
      "Epoch 956, Loss: 0.0009462431771680713, Final Batch Loss: 0.000785471114795655\n",
      "Epoch 957, Loss: 0.002555956758442335, Final Batch Loss: 0.00021581367764156312\n",
      "Epoch 958, Loss: 0.0003515052085276693, Final Batch Loss: 0.0001059081987477839\n",
      "Epoch 959, Loss: 0.0018935666885226965, Final Batch Loss: 0.0002993157831951976\n",
      "Epoch 960, Loss: 0.0013404637284111232, Final Batch Loss: 0.00025072714197449386\n",
      "Epoch 961, Loss: 0.001970742247067392, Final Batch Loss: 0.0017178631387650967\n",
      "Epoch 962, Loss: 0.0005610391381196678, Final Batch Loss: 0.00014831655425950885\n",
      "Epoch 963, Loss: 0.00018680968787521124, Final Batch Loss: 0.0001058032939909026\n",
      "Epoch 964, Loss: 0.0005728279211325571, Final Batch Loss: 0.000519445282407105\n",
      "Epoch 965, Loss: 0.0007488443952752277, Final Batch Loss: 0.00016316153050865978\n",
      "Epoch 966, Loss: 0.0004606111324392259, Final Batch Loss: 0.00028081887285225093\n",
      "Epoch 967, Loss: 0.0026291473623132333, Final Batch Loss: 0.00015916767006274313\n",
      "Epoch 968, Loss: 0.0008080581101239659, Final Batch Loss: 0.0007388030062429607\n",
      "Epoch 969, Loss: 0.0019413994741626084, Final Batch Loss: 0.0002623955369926989\n",
      "Epoch 970, Loss: 0.00026883614191319793, Final Batch Loss: 9.423073788639158e-05\n",
      "Epoch 971, Loss: 0.004708700347691774, Final Batch Loss: 0.002191664418205619\n",
      "Epoch 972, Loss: 0.0006086968642193824, Final Batch Loss: 0.00028861372265964746\n",
      "Epoch 973, Loss: 0.0047141392569756135, Final Batch Loss: 0.004478150047361851\n",
      "Epoch 974, Loss: 0.0029145153239369392, Final Batch Loss: 0.0007968884892761707\n",
      "Epoch 975, Loss: 0.0006717975629726425, Final Batch Loss: 0.0002001340180868283\n",
      "Epoch 976, Loss: 0.005894389236345887, Final Batch Loss: 0.0035614408552646637\n",
      "Epoch 977, Loss: 0.000897536076081451, Final Batch Loss: 8.324454393004999e-05\n",
      "Epoch 978, Loss: 0.0003258192664361559, Final Batch Loss: 6.733106420142576e-05\n",
      "Epoch 979, Loss: 0.00019463736862235237, Final Batch Loss: 2.5955452656489797e-05\n",
      "Epoch 980, Loss: 0.00018096543499268591, Final Batch Loss: 3.0908777262084186e-05\n",
      "Epoch 981, Loss: 0.0008374823228223249, Final Batch Loss: 0.0006798329413868487\n",
      "Epoch 982, Loss: 0.0005252675255178474, Final Batch Loss: 0.0004473125154618174\n",
      "Epoch 983, Loss: 0.0008315814775414765, Final Batch Loss: 0.000703087483998388\n",
      "Epoch 984, Loss: 0.0021001920104026794, Final Batch Loss: 0.0014212486566975713\n",
      "Epoch 985, Loss: 0.0016574314795434475, Final Batch Loss: 0.00045732874423265457\n",
      "Epoch 986, Loss: 0.001791564907762222, Final Batch Loss: 0.00159284973051399\n",
      "Epoch 987, Loss: 0.002406668136245571, Final Batch Loss: 8.081643318291754e-05\n",
      "Epoch 988, Loss: 0.0009144749346887693, Final Batch Loss: 0.0006831068894825876\n",
      "Epoch 989, Loss: 0.0008057674021983985, Final Batch Loss: 4.855424413108267e-05\n",
      "Epoch 990, Loss: 0.0007054684974718839, Final Batch Loss: 0.0001462843210902065\n",
      "Epoch 991, Loss: 0.007075108354911208, Final Batch Loss: 0.00565699627622962\n",
      "Epoch 992, Loss: 0.00015060945588629693, Final Batch Loss: 6.232391024241224e-05\n",
      "Epoch 993, Loss: 0.0002547642798162997, Final Batch Loss: 0.0001284215395571664\n",
      "Epoch 994, Loss: 0.0011170216021127999, Final Batch Loss: 0.0004512735758908093\n",
      "Epoch 995, Loss: 0.0013677577953785658, Final Batch Loss: 8.144916500896215e-05\n",
      "Epoch 996, Loss: 0.00035638094414025545, Final Batch Loss: 6.886728806421161e-05\n",
      "Epoch 997, Loss: 0.026871513342484832, Final Batch Loss: 0.023901792243123055\n",
      "Epoch 998, Loss: 0.0009970908286049962, Final Batch Loss: 3.742577973753214e-05\n",
      "Epoch 999, Loss: 0.002489938327926211, Final Batch Loss: 0.002422554651275277\n",
      "Epoch 1000, Loss: 0.0008618057472631335, Final Batch Loss: 0.00021744315745308995\n",
      "Epoch 1001, Loss: 0.0010346129420213401, Final Batch Loss: 0.00027633964782580733\n",
      "Epoch 1002, Loss: 0.0004032297001685947, Final Batch Loss: 2.6305409846827388e-05\n",
      "Epoch 1003, Loss: 0.00035243420279584825, Final Batch Loss: 0.00023776151647325605\n",
      "Epoch 1004, Loss: 0.002466418343828991, Final Batch Loss: 0.0001582950644660741\n",
      "Epoch 1005, Loss: 6.926287096575834e-05, Final Batch Loss: 4.375886419438757e-05\n",
      "Epoch 1006, Loss: 0.00021715475304517895, Final Batch Loss: 0.00013445320655591786\n",
      "Epoch 1007, Loss: 0.03432699042605236, Final Batch Loss: 0.033601559698581696\n",
      "Epoch 1008, Loss: 0.0006397188699338585, Final Batch Loss: 0.0003189589479006827\n",
      "Epoch 1009, Loss: 0.0006710535235470161, Final Batch Loss: 0.00010658857354428619\n",
      "Epoch 1010, Loss: 0.001496566277637612, Final Batch Loss: 0.00011591117799980566\n",
      "Epoch 1011, Loss: 0.0014734985888935626, Final Batch Loss: 0.00029506656574085355\n",
      "Epoch 1012, Loss: 0.0006830109050497413, Final Batch Loss: 0.00027183457859791815\n",
      "Epoch 1013, Loss: 0.006252856299397536, Final Batch Loss: 0.006022246554493904\n",
      "Epoch 1014, Loss: 0.014205510262399912, Final Batch Loss: 0.002846780698746443\n",
      "Epoch 1015, Loss: 0.0027049367199651897, Final Batch Loss: 0.0006295381463132799\n",
      "Epoch 1016, Loss: 0.0003452606688369997, Final Batch Loss: 2.9722061299253255e-05\n",
      "Epoch 1017, Loss: 0.00026196527323918417, Final Batch Loss: 9.087015496334061e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1018, Loss: 0.003863997117150575, Final Batch Loss: 0.0035939007066190243\n",
      "Epoch 1019, Loss: 0.0070638966280967, Final Batch Loss: 0.00420945230871439\n",
      "Epoch 1020, Loss: 0.001349591912003234, Final Batch Loss: 0.00014786681276746094\n",
      "Epoch 1021, Loss: 0.0021302430250216275, Final Batch Loss: 0.0017354429000988603\n",
      "Epoch 1022, Loss: 0.00041908388084266335, Final Batch Loss: 0.00024994954583235085\n",
      "Epoch 1023, Loss: 0.0020773247815668583, Final Batch Loss: 0.0005454734200611711\n",
      "Epoch 1024, Loss: 0.0004556815401883796, Final Batch Loss: 0.0002817034546751529\n",
      "Epoch 1025, Loss: 0.0005443757836474106, Final Batch Loss: 0.00046608297270722687\n",
      "Epoch 1026, Loss: 0.0003021716693183407, Final Batch Loss: 8.408489520661533e-05\n",
      "Epoch 1027, Loss: 0.0009045710175996646, Final Batch Loss: 0.00017858283536043018\n",
      "Epoch 1028, Loss: 0.0018097521970048547, Final Batch Loss: 0.0015725170960649848\n",
      "Epoch 1029, Loss: 0.0006901914021000266, Final Batch Loss: 0.0003740222891792655\n",
      "Epoch 1030, Loss: 0.001375060761347413, Final Batch Loss: 0.0008545252494513988\n",
      "Epoch 1031, Loss: 0.0012456319236662239, Final Batch Loss: 0.00045041859266348183\n",
      "Epoch 1032, Loss: 0.00011682078547892161, Final Batch Loss: 5.405276533565484e-05\n",
      "Epoch 1033, Loss: 0.0014052187325432897, Final Batch Loss: 0.0008207748760469258\n",
      "Epoch 1034, Loss: 0.0023148772888816893, Final Batch Loss: 0.00025264808209612966\n",
      "Epoch 1035, Loss: 0.00032251969241769984, Final Batch Loss: 9.151911217486486e-05\n",
      "Epoch 1036, Loss: 0.0006695333868265152, Final Batch Loss: 0.0005371246952563524\n",
      "Epoch 1037, Loss: 0.001162764267064631, Final Batch Loss: 0.00013477983884513378\n",
      "Epoch 1038, Loss: 0.0020545695442706347, Final Batch Loss: 0.0006682309322059155\n",
      "Epoch 1039, Loss: 0.0008007596334209666, Final Batch Loss: 0.0006358051323331892\n",
      "Epoch 1040, Loss: 0.0003384300071047619, Final Batch Loss: 0.00010148926230613142\n",
      "Epoch 1041, Loss: 0.0021197498572291806, Final Batch Loss: 7.648726750630885e-05\n",
      "Epoch 1042, Loss: 0.00048030114703578874, Final Batch Loss: 8.320764027303085e-05\n",
      "Epoch 1043, Loss: 0.0004273696322343312, Final Batch Loss: 0.00033914504456333816\n",
      "Epoch 1044, Loss: 0.0032514990234631114, Final Batch Loss: 5.828309076605365e-05\n",
      "Epoch 1045, Loss: 0.000649498229904566, Final Batch Loss: 6.603138899663463e-05\n",
      "Epoch 1046, Loss: 0.006305583519861102, Final Batch Loss: 0.00570871913805604\n",
      "Epoch 1047, Loss: 0.002373480863752775, Final Batch Loss: 0.002201343420892954\n",
      "Epoch 1048, Loss: 0.001506416705524316, Final Batch Loss: 3.408104748814367e-05\n",
      "Epoch 1049, Loss: 0.0005330665062501794, Final Batch Loss: 2.230679638159927e-05\n",
      "Epoch 1050, Loss: 0.0016225336730713025, Final Batch Loss: 0.0015113167464733124\n",
      "Epoch 1051, Loss: 0.00017397591727785766, Final Batch Loss: 4.889955744147301e-05\n",
      "Epoch 1052, Loss: 0.0005119780253153294, Final Batch Loss: 8.164625614881516e-05\n",
      "Epoch 1053, Loss: 0.0012218989431858063, Final Batch Loss: 0.0009615406743250787\n",
      "Epoch 1054, Loss: 0.0003400227433303371, Final Batch Loss: 8.458334195893258e-05\n",
      "Epoch 1055, Loss: 0.011284510139375925, Final Batch Loss: 0.00020848726853728294\n",
      "Epoch 1056, Loss: 0.0004130568850087002, Final Batch Loss: 7.712484512012452e-05\n",
      "Epoch 1057, Loss: 0.00040703683043830097, Final Batch Loss: 0.00021653615112882107\n",
      "Epoch 1058, Loss: 0.00026167347095906734, Final Batch Loss: 0.00010370754171162844\n",
      "Epoch 1059, Loss: 0.002413840622466523, Final Batch Loss: 8.616166451247409e-05\n",
      "Epoch 1060, Loss: 0.001189791684737429, Final Batch Loss: 0.0004329433722887188\n",
      "Epoch 1061, Loss: 0.0033527432242408395, Final Batch Loss: 0.0028182929381728172\n",
      "Epoch 1062, Loss: 0.0013799005537293851, Final Batch Loss: 0.0009622871875762939\n",
      "Epoch 1063, Loss: 0.00023128533939598128, Final Batch Loss: 0.00013723688607569784\n",
      "Epoch 1064, Loss: 0.0010074028105009347, Final Batch Loss: 0.00020628023776225746\n",
      "Epoch 1065, Loss: 0.00015165906006586738, Final Batch Loss: 5.1069011533400044e-05\n",
      "Epoch 1066, Loss: 0.0036429934843908995, Final Batch Loss: 0.0033366726711392403\n",
      "Epoch 1067, Loss: 0.001983076515898574, Final Batch Loss: 5.258335295366123e-05\n",
      "Epoch 1068, Loss: 0.0002860951644834131, Final Batch Loss: 6.271452002692968e-05\n",
      "Epoch 1069, Loss: 0.0031973155710147694, Final Batch Loss: 0.0030882260762155056\n",
      "Epoch 1070, Loss: 0.0007550863520009443, Final Batch Loss: 6.093403499107808e-05\n",
      "Epoch 1071, Loss: 0.0006810730483266525, Final Batch Loss: 0.00011126754543511197\n",
      "Epoch 1072, Loss: 0.0008341086213476956, Final Batch Loss: 0.0005377376219257712\n",
      "Epoch 1073, Loss: 0.0007240019185701385, Final Batch Loss: 0.0005402968381531537\n",
      "Epoch 1074, Loss: 0.0007332325403694995, Final Batch Loss: 4.381238977657631e-05\n",
      "Epoch 1075, Loss: 0.002595617901533842, Final Batch Loss: 0.0007565830601379275\n",
      "Epoch 1076, Loss: 0.00389880062721204, Final Batch Loss: 0.003734041703864932\n",
      "Epoch 1077, Loss: 0.0007100621151039377, Final Batch Loss: 0.0005859783850610256\n",
      "Epoch 1078, Loss: 0.0016487706889165565, Final Batch Loss: 0.00016278021212201566\n",
      "Epoch 1079, Loss: 0.000298982864478603, Final Batch Loss: 0.00017178764392156154\n",
      "Epoch 1080, Loss: 0.00023783559117873665, Final Batch Loss: 0.00021479252609424293\n",
      "Epoch 1081, Loss: 0.0005574512179009616, Final Batch Loss: 0.00035424664383754134\n",
      "Epoch 1082, Loss: 0.0005447412877401803, Final Batch Loss: 4.0011309465626255e-05\n",
      "Epoch 1083, Loss: 0.0003955869578931015, Final Batch Loss: 0.00034174747997894883\n",
      "Epoch 1084, Loss: 0.0011507811432238668, Final Batch Loss: 0.0001615906076040119\n",
      "Epoch 1085, Loss: 0.0008096460369415581, Final Batch Loss: 3.6534154787659645e-05\n",
      "Epoch 1086, Loss: 0.0017792478756746277, Final Batch Loss: 4.6990797272883356e-05\n",
      "Epoch 1087, Loss: 0.0023911411026347196, Final Batch Loss: 1.6550728105357848e-05\n",
      "Epoch 1088, Loss: 0.0002898451202781871, Final Batch Loss: 0.0002455592912156135\n",
      "Epoch 1089, Loss: 0.0005022168770665303, Final Batch Loss: 9.068702638614923e-05\n",
      "Epoch 1090, Loss: 0.0003499079030007124, Final Batch Loss: 0.00018271124281454831\n",
      "Epoch 1091, Loss: 0.00041511241033731494, Final Batch Loss: 1.5677442206651904e-05\n",
      "Epoch 1092, Loss: 0.0029559580725617707, Final Batch Loss: 0.0028600022196769714\n",
      "Epoch 1093, Loss: 0.000379468547180295, Final Batch Loss: 0.00015168602112680674\n",
      "Epoch 1094, Loss: 0.0006229711580090225, Final Batch Loss: 0.00029430488939397037\n",
      "Epoch 1095, Loss: 0.016206298139877617, Final Batch Loss: 0.015180706977844238\n",
      "Epoch 1096, Loss: 0.001323579424933996, Final Batch Loss: 0.00010069805284729227\n",
      "Epoch 1097, Loss: 0.002151085383957252, Final Batch Loss: 0.0019852323457598686\n",
      "Epoch 1098, Loss: 0.0010091139120049775, Final Batch Loss: 0.0002634124830365181\n",
      "Epoch 1099, Loss: 0.0013288612863107119, Final Batch Loss: 3.897509668604471e-05\n",
      "Epoch 1100, Loss: 0.0031666288632550277, Final Batch Loss: 4.781815368914977e-05\n",
      "Epoch 1101, Loss: 0.00036008057941216975, Final Batch Loss: 6.792591011617333e-05\n",
      "Epoch 1102, Loss: 8.360629476555914e-05, Final Batch Loss: 3.3873268421302782e-06\n",
      "Epoch 1103, Loss: 0.001309683924773708, Final Batch Loss: 0.0001731129887048155\n",
      "Epoch 1104, Loss: 0.0005156485931365751, Final Batch Loss: 6.773575296392664e-05\n",
      "Epoch 1105, Loss: 0.0002306848473381251, Final Batch Loss: 0.00011643068137345836\n",
      "Epoch 1106, Loss: 0.0005387019191402942, Final Batch Loss: 0.00011322810314595699\n",
      "Epoch 1107, Loss: 0.0006742066325386986, Final Batch Loss: 0.00016725003661122173\n",
      "Epoch 1108, Loss: 0.00021799595924676396, Final Batch Loss: 0.00016430906543973833\n",
      "Epoch 1109, Loss: 0.0009579615361872129, Final Batch Loss: 0.0001136016144300811\n",
      "Epoch 1110, Loss: 0.0005981777430861257, Final Batch Loss: 0.0004860471235588193\n",
      "Epoch 1111, Loss: 0.0004141741883358918, Final Batch Loss: 7.081735384417698e-05\n",
      "Epoch 1112, Loss: 0.00041174140642397106, Final Batch Loss: 0.00022156337217893451\n",
      "Epoch 1113, Loss: 0.0023504892433265923, Final Batch Loss: 0.0023283648770302534\n",
      "Epoch 1114, Loss: 0.004035555000882596, Final Batch Loss: 0.00038006616523489356\n",
      "Epoch 1115, Loss: 0.0008225115379900672, Final Batch Loss: 1.034673914546147e-05\n",
      "Epoch 1116, Loss: 0.003074768523219973, Final Batch Loss: 0.0022493908181786537\n",
      "Epoch 1117, Loss: 0.0005985111420159228, Final Batch Loss: 7.829152309568599e-05\n",
      "Epoch 1118, Loss: 0.001071862869139295, Final Batch Loss: 0.0010400657774880528\n",
      "Epoch 1119, Loss: 0.0001724321991787292, Final Batch Loss: 8.036720100790262e-05\n",
      "Epoch 1120, Loss: 0.0024433263315586373, Final Batch Loss: 4.027101385872811e-05\n",
      "Epoch 1121, Loss: 0.00048436695942655206, Final Batch Loss: 0.0001434487639926374\n",
      "Epoch 1122, Loss: 0.005016078124754131, Final Batch Loss: 0.001762285246513784\n",
      "Epoch 1123, Loss: 0.00039619400922674686, Final Batch Loss: 0.00019230376346968114\n",
      "Epoch 1124, Loss: 0.00030301899823825806, Final Batch Loss: 0.00014769851986784488\n",
      "Epoch 1125, Loss: 0.004232458268234041, Final Batch Loss: 0.004116527270525694\n",
      "Epoch 1126, Loss: 0.0025436803516640794, Final Batch Loss: 3.195226236130111e-05\n",
      "Epoch 1127, Loss: 0.0024455578823108226, Final Batch Loss: 0.0022962770890444517\n",
      "Epoch 1128, Loss: 0.003211202099919319, Final Batch Loss: 0.001229981193318963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1129, Loss: 0.0010367544600740075, Final Batch Loss: 0.00010492996079847217\n",
      "Epoch 1130, Loss: 0.0007251024944707751, Final Batch Loss: 0.00033147618523798883\n",
      "Epoch 1131, Loss: 0.002745581034105271, Final Batch Loss: 0.002115718787536025\n",
      "Epoch 1132, Loss: 0.00044854070438304916, Final Batch Loss: 0.0003542813064996153\n",
      "Epoch 1133, Loss: 0.0004526397751760669, Final Batch Loss: 6.653287709923461e-05\n",
      "Epoch 1134, Loss: 0.0005416399799287319, Final Batch Loss: 0.0003483999753370881\n",
      "Epoch 1135, Loss: 0.0008142990409396589, Final Batch Loss: 0.0005092817591503263\n",
      "Epoch 1136, Loss: 0.005100367809063755, Final Batch Loss: 0.004940281622111797\n",
      "Epoch 1137, Loss: 0.0002840583911165595, Final Batch Loss: 0.00013514213787857443\n",
      "Epoch 1138, Loss: 0.0011342818033881485, Final Batch Loss: 0.00021473650122061372\n",
      "Epoch 1139, Loss: 0.0006537435110658407, Final Batch Loss: 0.0004676151729654521\n",
      "Epoch 1140, Loss: 0.0005313102155923843, Final Batch Loss: 0.00015836322563700378\n",
      "Epoch 1141, Loss: 0.000331686493154848, Final Batch Loss: 5.6995926570380107e-05\n",
      "Epoch 1142, Loss: 0.0006348481547320262, Final Batch Loss: 0.0005299236509017646\n",
      "Epoch 1143, Loss: 0.00010720205682446249, Final Batch Loss: 4.160124444752e-05\n",
      "Epoch 1144, Loss: 0.00048791468725539744, Final Batch Loss: 0.0003686822601594031\n",
      "Epoch 1145, Loss: 0.0009102737094508484, Final Batch Loss: 0.00010253059735987335\n",
      "Epoch 1146, Loss: 0.0003803322615567595, Final Batch Loss: 0.000240366964135319\n",
      "Epoch 1147, Loss: 0.000283329798548948, Final Batch Loss: 4.243932926328853e-05\n",
      "Epoch 1148, Loss: 0.003917148405889748, Final Batch Loss: 0.0038580852560698986\n",
      "Epoch 1149, Loss: 0.0015780751418787986, Final Batch Loss: 0.0013745826436206698\n",
      "Epoch 1150, Loss: 0.001497392153396504, Final Batch Loss: 4.294906466384418e-05\n",
      "Epoch 1151, Loss: 0.0003922518153558485, Final Batch Loss: 1.711030927253887e-05\n",
      "Epoch 1152, Loss: 9.173018952424172e-05, Final Batch Loss: 7.6828378951177e-05\n",
      "Epoch 1153, Loss: 0.00015820654516573995, Final Batch Loss: 8.857002831064165e-05\n",
      "Epoch 1154, Loss: 0.0013470990561472718, Final Batch Loss: 2.9365157388383523e-05\n",
      "Epoch 1155, Loss: 0.0003381436990821385, Final Batch Loss: 5.3465491873794235e-06\n",
      "Epoch 1156, Loss: 0.0050253508816240355, Final Batch Loss: 9.85645892797038e-05\n",
      "Epoch 1157, Loss: 0.02871841480373405, Final Batch Loss: 0.028285888954997063\n",
      "Epoch 1158, Loss: 9.329986278316937e-05, Final Batch Loss: 3.9020869735395536e-05\n",
      "Epoch 1159, Loss: 0.001051053790433798, Final Batch Loss: 6.261122325668111e-05\n",
      "Epoch 1160, Loss: 0.0004986156563973054, Final Batch Loss: 0.00024114643747452646\n",
      "Epoch 1161, Loss: 0.0006219763163244352, Final Batch Loss: 0.00046217310591600835\n",
      "Epoch 1162, Loss: 0.0006068935035727918, Final Batch Loss: 4.760845331475139e-05\n",
      "Epoch 1163, Loss: 0.0005646019271807745, Final Batch Loss: 0.00046827743062749505\n",
      "Epoch 1164, Loss: 0.003801785525865853, Final Batch Loss: 0.0028900541365146637\n",
      "Epoch 1165, Loss: 0.02726779691874981, Final Batch Loss: 0.002077065408229828\n",
      "Epoch 1166, Loss: 0.0008588709752075374, Final Batch Loss: 0.00012695358600467443\n",
      "Epoch 1167, Loss: 0.0003827006003120914, Final Batch Loss: 0.00014817687042523175\n",
      "Epoch 1168, Loss: 7.621825716341846e-05, Final Batch Loss: 1.4393739547813311e-05\n",
      "Epoch 1169, Loss: 0.019372260747331893, Final Batch Loss: 3.938990630558692e-05\n",
      "Epoch 1170, Loss: 0.0006447037012549117, Final Batch Loss: 0.00018868230108637363\n",
      "Epoch 1171, Loss: 0.0002105355124513153, Final Batch Loss: 4.461690332391299e-05\n",
      "Epoch 1172, Loss: 0.00020560466509778053, Final Batch Loss: 4.935172910336405e-05\n",
      "Epoch 1173, Loss: 0.001285318867303431, Final Batch Loss: 0.00017945189028978348\n",
      "Epoch 1174, Loss: 0.0012411536517902277, Final Batch Loss: 9.831177158048376e-05\n",
      "Epoch 1175, Loss: 0.00025394149270141497, Final Batch Loss: 0.00011439908848842606\n",
      "Epoch 1176, Loss: 0.00044668476039078087, Final Batch Loss: 0.00024159166787285358\n",
      "Epoch 1177, Loss: 0.0011315871961414814, Final Batch Loss: 0.0008718891767784953\n",
      "Epoch 1178, Loss: 0.0001270536486117635, Final Batch Loss: 6.70888475724496e-05\n",
      "Epoch 1179, Loss: 0.000804059105576016, Final Batch Loss: 0.00014542062126565725\n",
      "Epoch 1180, Loss: 0.0037008795188739896, Final Batch Loss: 0.0021519188303500414\n",
      "Epoch 1181, Loss: 0.00028430166275938973, Final Batch Loss: 0.0002017217339016497\n",
      "Epoch 1182, Loss: 0.005618516239337623, Final Batch Loss: 0.003990374971181154\n",
      "Epoch 1183, Loss: 0.00013366210259846412, Final Batch Loss: 5.545954991248436e-05\n",
      "Epoch 1184, Loss: 0.0004958952195011079, Final Batch Loss: 0.00017221851157955825\n",
      "Epoch 1185, Loss: 0.0003035437475773506, Final Batch Loss: 0.0002305878297192976\n",
      "Epoch 1186, Loss: 0.0014456638018600643, Final Batch Loss: 0.001035398105159402\n",
      "Epoch 1187, Loss: 0.00026752873964142054, Final Batch Loss: 0.00013533420860767365\n",
      "Epoch 1188, Loss: 0.0004654526892409194, Final Batch Loss: 4.7475903556915e-05\n",
      "Epoch 1189, Loss: 0.0005924980359850451, Final Batch Loss: 0.00021283059322740883\n",
      "Epoch 1190, Loss: 0.0026271985261701047, Final Batch Loss: 7.539399666711688e-05\n",
      "Epoch 1191, Loss: 0.0009577620949130505, Final Batch Loss: 4.396072472445667e-05\n",
      "Epoch 1192, Loss: 0.0006901277556607965, Final Batch Loss: 4.544147304841317e-05\n",
      "Epoch 1193, Loss: 0.0007287419284693897, Final Batch Loss: 0.00019674835493788123\n",
      "Epoch 1194, Loss: 0.00030598033481510356, Final Batch Loss: 0.0001049879429046996\n",
      "Epoch 1195, Loss: 0.0022046936355764046, Final Batch Loss: 8.568262273911387e-05\n",
      "Epoch 1196, Loss: 0.001230704307090491, Final Batch Loss: 0.0007117982604540884\n",
      "Epoch 1197, Loss: 0.0037260022945702076, Final Batch Loss: 0.0014424973633140326\n",
      "Epoch 1198, Loss: 0.00042363873035355937, Final Batch Loss: 2.6477295250515454e-05\n",
      "Epoch 1199, Loss: 0.00026287772561772726, Final Batch Loss: 0.00022971136786509305\n",
      "Epoch 1200, Loss: 0.00044735589472111315, Final Batch Loss: 0.00030769596924073994\n",
      "Epoch 1201, Loss: 0.001148024275607895, Final Batch Loss: 5.862168472958729e-05\n",
      "Epoch 1202, Loss: 0.0036321193765616044, Final Batch Loss: 0.0035131394397467375\n",
      "Epoch 1203, Loss: 0.003343734599184245, Final Batch Loss: 0.00034292921191081405\n",
      "Epoch 1204, Loss: 0.00021595788712147623, Final Batch Loss: 4.823030030820519e-05\n",
      "Epoch 1205, Loss: 0.0005710592376999557, Final Batch Loss: 0.00011635787086561322\n",
      "Epoch 1206, Loss: 0.0004841342815780081, Final Batch Loss: 7.525477121816948e-05\n",
      "Epoch 1207, Loss: 0.0003535071446094662, Final Batch Loss: 0.00015131974942050874\n",
      "Epoch 1208, Loss: 0.00016847657298058039, Final Batch Loss: 0.00015392240311484784\n",
      "Epoch 1209, Loss: 0.0003624731325544417, Final Batch Loss: 0.00012724078260362148\n",
      "Epoch 1210, Loss: 0.00010795818980113836, Final Batch Loss: 1.4277528862294275e-05\n",
      "Epoch 1211, Loss: 0.0014508854364976287, Final Batch Loss: 0.00046816724352538586\n",
      "Epoch 1212, Loss: 0.00044085796253057197, Final Batch Loss: 9.50697940425016e-05\n",
      "Epoch 1213, Loss: 0.0016554023386561312, Final Batch Loss: 0.0015365037834271789\n",
      "Epoch 1214, Loss: 0.00079067048500292, Final Batch Loss: 0.0004842224589083344\n",
      "Epoch 1215, Loss: 0.0001237952965311706, Final Batch Loss: 7.383830234175548e-05\n",
      "Epoch 1216, Loss: 0.0049658152856864035, Final Batch Loss: 0.00043705623829737306\n",
      "Epoch 1217, Loss: 0.0004160346506978385, Final Batch Loss: 2.0753905118908733e-05\n",
      "Epoch 1218, Loss: 0.003949764650315046, Final Batch Loss: 0.00099640479311347\n",
      "Epoch 1219, Loss: 0.00024342068354599178, Final Batch Loss: 9.688801947049797e-05\n",
      "Epoch 1220, Loss: 0.00045027864689473063, Final Batch Loss: 0.00038202101131901145\n",
      "Epoch 1221, Loss: 0.0003268430446041748, Final Batch Loss: 0.00026002974482253194\n",
      "Epoch 1222, Loss: 0.0003115087456535548, Final Batch Loss: 8.734948642086238e-05\n",
      "Epoch 1223, Loss: 0.0012430873393896036, Final Batch Loss: 0.000106745857920032\n",
      "Epoch 1224, Loss: 8.790185347606894e-05, Final Batch Loss: 2.0352605133666657e-05\n",
      "Epoch 1225, Loss: 0.00020161249994998798, Final Batch Loss: 6.911028322065249e-05\n",
      "Epoch 1226, Loss: 0.00020023254910483956, Final Batch Loss: 8.959027763921767e-05\n",
      "Epoch 1227, Loss: 0.0005998591659590602, Final Batch Loss: 0.0003638609196059406\n",
      "Epoch 1228, Loss: 0.000270628348516766, Final Batch Loss: 0.0002017147053265944\n",
      "Epoch 1229, Loss: 0.0007183945417637005, Final Batch Loss: 0.0005432908656075597\n",
      "Epoch 1230, Loss: 0.0021450144704431295, Final Batch Loss: 0.0019855087157338858\n",
      "Epoch 1231, Loss: 0.0004605798458214849, Final Batch Loss: 0.00042980146827176213\n",
      "Epoch 1232, Loss: 0.0017243846605197177, Final Batch Loss: 1.131236149376491e-05\n",
      "Epoch 1233, Loss: 0.0002156016998924315, Final Batch Loss: 0.00014896158245392144\n",
      "Epoch 1234, Loss: 0.0031030138597998302, Final Batch Loss: 0.0030657146126031876\n",
      "Epoch 1235, Loss: 0.001323555363342166, Final Batch Loss: 0.0003224654356017709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1236, Loss: 0.0014373350131791085, Final Batch Loss: 5.427419091574848e-05\n",
      "Epoch 1237, Loss: 0.00022313510635285638, Final Batch Loss: 3.295208080089651e-05\n",
      "Epoch 1238, Loss: 0.00013304668755154125, Final Batch Loss: 5.156742190592922e-05\n",
      "Epoch 1239, Loss: 0.00021538107830565423, Final Batch Loss: 0.00013135427434463054\n",
      "Epoch 1240, Loss: 0.00109741358392057, Final Batch Loss: 0.0010609980672597885\n",
      "Epoch 1241, Loss: 0.00035856982685800176, Final Batch Loss: 1.0105328328791074e-05\n",
      "Epoch 1242, Loss: 0.0005045469588367268, Final Batch Loss: 0.00035694913822226226\n",
      "Epoch 1243, Loss: 0.0008096560777630657, Final Batch Loss: 0.0005686500808224082\n",
      "Epoch 1244, Loss: 1.5321141745516798e-05, Final Batch Loss: 6.132866019470384e-06\n",
      "Epoch 1245, Loss: 0.00014813664893154055, Final Batch Loss: 6.564264913322404e-05\n",
      "Epoch 1246, Loss: 0.00018558899137133267, Final Batch Loss: 2.2771308067603968e-05\n",
      "Epoch 1247, Loss: 0.0002840318193193525, Final Batch Loss: 0.0001393485872540623\n",
      "Epoch 1248, Loss: 0.0018765481836453546, Final Batch Loss: 3.4498651075409725e-05\n",
      "Epoch 1249, Loss: 0.0032106967410072684, Final Batch Loss: 0.0016431760741397738\n",
      "Epoch 1250, Loss: 0.00012170956688350998, Final Batch Loss: 3.757702870643698e-05\n",
      "Epoch 1251, Loss: 0.0011152884326293133, Final Batch Loss: 5.790506111225113e-05\n",
      "Epoch 1252, Loss: 0.0007689970952924341, Final Batch Loss: 0.0002943154249805957\n",
      "Epoch 1253, Loss: 8.693148993188515e-05, Final Batch Loss: 3.052552347071469e-05\n",
      "Epoch 1254, Loss: 0.00023308139407163253, Final Batch Loss: 9.783433597476687e-06\n",
      "Epoch 1255, Loss: 0.00018827099120244384, Final Batch Loss: 0.0001286901970161125\n",
      "Epoch 1256, Loss: 0.0012336551153566688, Final Batch Loss: 0.00034637769567780197\n",
      "Epoch 1257, Loss: 0.0014210471999831498, Final Batch Loss: 0.0007860425394028425\n",
      "Epoch 1258, Loss: 0.00037023284676251933, Final Batch Loss: 0.0003336503286845982\n",
      "Epoch 1259, Loss: 0.0002734928493737243, Final Batch Loss: 8.19009801489301e-05\n",
      "Epoch 1260, Loss: 0.0004988997825421393, Final Batch Loss: 0.00025610291049815714\n",
      "Epoch 1261, Loss: 0.0006334547651931643, Final Batch Loss: 0.0002655800781212747\n",
      "Epoch 1262, Loss: 0.001251811467227526, Final Batch Loss: 0.00014743681822437793\n",
      "Epoch 1263, Loss: 0.00015121211254154332, Final Batch Loss: 2.228732410003431e-05\n",
      "Epoch 1264, Loss: 0.0006227119156392291, Final Batch Loss: 0.000159208444529213\n",
      "Epoch 1265, Loss: 0.002253554390335921, Final Batch Loss: 6.728954758727923e-05\n",
      "Epoch 1266, Loss: 0.00033339544461341575, Final Batch Loss: 0.00028193325852043927\n",
      "Epoch 1267, Loss: 0.0006235297478269786, Final Batch Loss: 0.00045537418918684125\n",
      "Epoch 1268, Loss: 0.00014699813618790358, Final Batch Loss: 7.754429680062458e-05\n",
      "Epoch 1269, Loss: 0.001331059102085419, Final Batch Loss: 6.604690861422569e-05\n",
      "Epoch 1270, Loss: 6.179405136208516e-05, Final Batch Loss: 2.426831088087056e-05\n",
      "Epoch 1271, Loss: 6.110874710429925e-05, Final Batch Loss: 3.578720861696638e-05\n",
      "Epoch 1272, Loss: 0.00259354507579701, Final Batch Loss: 8.351455471711233e-05\n",
      "Epoch 1273, Loss: 0.000250330476774252, Final Batch Loss: 0.0002228517405455932\n",
      "Epoch 1274, Loss: 0.0001600747200427577, Final Batch Loss: 0.0001179643368232064\n",
      "Epoch 1275, Loss: 0.0004560615197988227, Final Batch Loss: 0.0002719298645388335\n",
      "Epoch 1276, Loss: 0.00035999284591525793, Final Batch Loss: 0.00016243656864389777\n",
      "Epoch 1277, Loss: 0.00014878448928357102, Final Batch Loss: 0.00010822869808180258\n",
      "Epoch 1278, Loss: 0.0002602635395305697, Final Batch Loss: 3.401363574084826e-05\n",
      "Epoch 1279, Loss: 0.00017896515964821447, Final Batch Loss: 1.6362248061341234e-05\n",
      "Epoch 1280, Loss: 3.974601804657141e-05, Final Batch Loss: 9.28315694181947e-06\n",
      "Epoch 1281, Loss: 0.0003539225526765222, Final Batch Loss: 2.2813366740592755e-05\n",
      "Epoch 1282, Loss: 0.00023680539743509144, Final Batch Loss: 0.00016620304086245596\n",
      "Epoch 1283, Loss: 0.0006889535579830408, Final Batch Loss: 0.00017598184058442712\n",
      "Epoch 1284, Loss: 0.00018839752874555415, Final Batch Loss: 6.616284281335538e-06\n",
      "Epoch 1285, Loss: 9.243392196367495e-05, Final Batch Loss: 5.9342517488403246e-05\n",
      "Epoch 1286, Loss: 0.007010564906522632, Final Batch Loss: 0.001673719147220254\n",
      "Epoch 1287, Loss: 0.00030903025981388055, Final Batch Loss: 0.00027753488393500447\n",
      "Epoch 1288, Loss: 0.0008564546296838671, Final Batch Loss: 0.00011413768515922129\n",
      "Epoch 1289, Loss: 7.117545283108484e-05, Final Batch Loss: 2.5247145458706655e-05\n",
      "Epoch 1290, Loss: 0.0011598820419749245, Final Batch Loss: 0.0010591690661385655\n",
      "Epoch 1291, Loss: 0.001251093293831218, Final Batch Loss: 0.0011914132628589869\n",
      "Epoch 1292, Loss: 0.0007418483146466315, Final Batch Loss: 0.0005138700944371521\n",
      "Epoch 1293, Loss: 0.0008342562068719417, Final Batch Loss: 0.0005142857553437352\n",
      "Epoch 1294, Loss: 0.0002638307232700754, Final Batch Loss: 0.00020523140847217292\n",
      "Epoch 1295, Loss: 0.005495679914020002, Final Batch Loss: 0.004431071225553751\n",
      "Epoch 1296, Loss: 0.0011206078488612548, Final Batch Loss: 0.0009589366381987929\n",
      "Epoch 1297, Loss: 0.00018329818703932688, Final Batch Loss: 2.159552968805656e-05\n",
      "Epoch 1298, Loss: 9.320540266344324e-05, Final Batch Loss: 1.5812081983312964e-05\n",
      "Epoch 1299, Loss: 0.0019243155984440818, Final Batch Loss: 3.224100510124117e-05\n",
      "Epoch 1300, Loss: 0.0001994958656723611, Final Batch Loss: 6.689444853691384e-05\n",
      "Epoch 1301, Loss: 0.00011502471170388162, Final Batch Loss: 2.0969448087271303e-05\n",
      "Epoch 1302, Loss: 0.00011186450683453586, Final Batch Loss: 1.157744372903835e-05\n",
      "Epoch 1303, Loss: 0.00042774577741511166, Final Batch Loss: 0.000359889556420967\n",
      "Epoch 1304, Loss: 0.0006738538795616478, Final Batch Loss: 0.0002721333294175565\n",
      "Epoch 1305, Loss: 0.001285416847167653, Final Batch Loss: 0.0012606657110154629\n",
      "Epoch 1306, Loss: 0.00033500324934720993, Final Batch Loss: 0.0002605541085358709\n",
      "Epoch 1307, Loss: 0.0019753230444621295, Final Batch Loss: 0.00012499195872806013\n",
      "Epoch 1308, Loss: 0.0003039788134628907, Final Batch Loss: 0.0001463299267925322\n",
      "Epoch 1309, Loss: 0.0011554700759006664, Final Batch Loss: 8.742771751713008e-05\n",
      "Epoch 1310, Loss: 0.00033388591691618785, Final Batch Loss: 0.00010315572581021115\n",
      "Epoch 1311, Loss: 0.00019184545817552134, Final Batch Loss: 8.898172382032499e-05\n",
      "Epoch 1312, Loss: 6.681250852125231e-05, Final Batch Loss: 5.1278173486934975e-05\n",
      "Epoch 1313, Loss: 0.00039556001138407737, Final Batch Loss: 0.00018786231521517038\n",
      "Epoch 1314, Loss: 0.00025915869082382414, Final Batch Loss: 2.4562536054872908e-05\n",
      "Epoch 1315, Loss: 0.0008206755974242697, Final Batch Loss: 2.5380950319231488e-05\n",
      "Epoch 1316, Loss: 0.0021575908904196694, Final Batch Loss: 0.0001590587926330045\n",
      "Epoch 1317, Loss: 0.001172314296127297, Final Batch Loss: 8.490298932883888e-05\n",
      "Epoch 1318, Loss: 0.00015844134395592846, Final Batch Loss: 3.8855690945638344e-05\n",
      "Epoch 1319, Loss: 8.780978168942966e-05, Final Batch Loss: 3.6722351069329306e-05\n",
      "Epoch 1320, Loss: 0.001826968444220256, Final Batch Loss: 2.5869398086797446e-05\n",
      "Epoch 1321, Loss: 0.00010808646402438171, Final Batch Loss: 3.598961848183535e-05\n",
      "Epoch 1322, Loss: 0.0032481476591783576, Final Batch Loss: 0.0032052265014499426\n",
      "Epoch 1323, Loss: 0.00028870211099274457, Final Batch Loss: 0.0001253965892829001\n",
      "Epoch 1324, Loss: 0.0005537025790545158, Final Batch Loss: 7.216285303002223e-05\n",
      "Epoch 1325, Loss: 0.00017910718452185392, Final Batch Loss: 0.00010339525033487007\n",
      "Epoch 1326, Loss: 0.0019856643048115075, Final Batch Loss: 0.0013859604950994253\n",
      "Epoch 1327, Loss: 0.00014052078040549532, Final Batch Loss: 7.720874418737367e-05\n",
      "Epoch 1328, Loss: 7.349773113674019e-05, Final Batch Loss: 1.2917023923364468e-05\n",
      "Epoch 1329, Loss: 0.0010526975020184182, Final Batch Loss: 8.928609167924151e-05\n",
      "Epoch 1330, Loss: 0.00035798640601569787, Final Batch Loss: 9.709236474009231e-05\n",
      "Epoch 1331, Loss: 9.206766480929218e-05, Final Batch Loss: 5.0901940994663164e-05\n",
      "Epoch 1332, Loss: 0.00012874271487817168, Final Batch Loss: 6.290886085480452e-05\n",
      "Epoch 1333, Loss: 5.7199983530153986e-05, Final Batch Loss: 1.2357540072116535e-05\n",
      "Epoch 1334, Loss: 0.00015744777738291305, Final Batch Loss: 0.00013504433445632458\n",
      "Epoch 1335, Loss: 0.0008499952382408082, Final Batch Loss: 0.0005795672186650336\n",
      "Epoch 1336, Loss: 0.0004396151198307052, Final Batch Loss: 0.000158427152200602\n",
      "Epoch 1337, Loss: 0.0060255927965044975, Final Batch Loss: 0.004765842109918594\n",
      "Epoch 1338, Loss: 0.0003937903238693252, Final Batch Loss: 0.0003216196200810373\n",
      "Epoch 1339, Loss: 0.00023966075241332874, Final Batch Loss: 5.8925528719555587e-05\n",
      "Epoch 1340, Loss: 0.00023721758861938724, Final Batch Loss: 1.201779468829045e-05\n",
      "Epoch 1341, Loss: 6.965717147977557e-05, Final Batch Loss: 8.071865522651933e-06\n",
      "Epoch 1342, Loss: 0.005727400453906739, Final Batch Loss: 3.3751512091839686e-05\n",
      "Epoch 1343, Loss: 0.00387063117523212, Final Batch Loss: 0.00012860105198342353\n",
      "Epoch 1344, Loss: 0.00043677502253558487, Final Batch Loss: 0.00032311450922861695\n",
      "Epoch 1345, Loss: 0.00037006840648246, Final Batch Loss: 0.00032435241155326366\n",
      "Epoch 1346, Loss: 0.0006045227928552777, Final Batch Loss: 0.0003099283785559237\n",
      "Epoch 1347, Loss: 0.0005580511206062511, Final Batch Loss: 0.0002081663260469213\n",
      "Epoch 1348, Loss: 0.00014364506932906806, Final Batch Loss: 3.318488597869873e-05\n",
      "Epoch 1349, Loss: 0.00011418497524573468, Final Batch Loss: 3.456874765106477e-05\n",
      "Epoch 1350, Loss: 0.0010901866844506003, Final Batch Loss: 0.0010113157331943512\n",
      "Epoch 1351, Loss: 0.0003429560274526011, Final Batch Loss: 4.749493018607609e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1352, Loss: 4.875751619692892e-05, Final Batch Loss: 2.5998702767537907e-05\n",
      "Epoch 1353, Loss: 0.000647323908196995, Final Batch Loss: 5.15852625539992e-05\n",
      "Epoch 1354, Loss: 7.82879378675716e-05, Final Batch Loss: 2.0527009837678634e-05\n",
      "Epoch 1355, Loss: 0.0001235519866895629, Final Batch Loss: 9.566620428813621e-05\n",
      "Epoch 1356, Loss: 0.0006179472366056871, Final Batch Loss: 0.0006020392756909132\n",
      "Epoch 1357, Loss: 0.00038064963518991135, Final Batch Loss: 0.0003246619598940015\n",
      "Epoch 1358, Loss: 0.001556927298224764, Final Batch Loss: 3.605425081332214e-05\n",
      "Epoch 1359, Loss: 0.0005364036587707233, Final Batch Loss: 3.79353114112746e-05\n",
      "Epoch 1360, Loss: 0.0015103741025086492, Final Batch Loss: 0.00047852503485046327\n",
      "Epoch 1361, Loss: 0.00019811035599559546, Final Batch Loss: 3.1764357117936015e-05\n",
      "Epoch 1362, Loss: 0.0005560354911722243, Final Batch Loss: 4.31152293458581e-05\n",
      "Epoch 1363, Loss: 0.0015815955921425484, Final Batch Loss: 8.142479782691225e-05\n",
      "Epoch 1364, Loss: 0.00011749246004910674, Final Batch Loss: 9.63605270953849e-05\n",
      "Epoch 1365, Loss: 0.0055841131616034545, Final Batch Loss: 7.002041820669547e-05\n",
      "Epoch 1366, Loss: 0.0003122726920992136, Final Batch Loss: 0.0002484349242877215\n",
      "Epoch 1367, Loss: 8.61544904182665e-05, Final Batch Loss: 2.9572791390819475e-05\n",
      "Epoch 1368, Loss: 0.0003268210571150121, Final Batch Loss: 3.942026978620561e-06\n",
      "Epoch 1369, Loss: 0.0011696925594151253, Final Batch Loss: 1.752255229803268e-05\n",
      "Epoch 1370, Loss: 0.0010822710173670202, Final Batch Loss: 0.0002035086799878627\n",
      "Epoch 1371, Loss: 0.0003706516872625798, Final Batch Loss: 0.0002153152454411611\n",
      "Epoch 1372, Loss: 0.003673241299111396, Final Batch Loss: 0.0027307108975946903\n",
      "Epoch 1373, Loss: 8.139969759213272e-05, Final Batch Loss: 1.5680869182688184e-05\n",
      "Epoch 1374, Loss: 0.0002507683420844842, Final Batch Loss: 0.00019919246551580727\n",
      "Epoch 1375, Loss: 0.004401543916173978, Final Batch Loss: 1.2318876542849466e-05\n",
      "Epoch 1376, Loss: 0.005917734699323773, Final Batch Loss: 0.0008480942342430353\n",
      "Epoch 1377, Loss: 0.0015521473251283169, Final Batch Loss: 0.0004927919944748282\n",
      "Epoch 1378, Loss: 0.000512835283188906, Final Batch Loss: 1.3742367627855856e-05\n",
      "Epoch 1379, Loss: 0.00025332405493827537, Final Batch Loss: 0.00011830747098429129\n",
      "Epoch 1380, Loss: 0.00010010082041844726, Final Batch Loss: 4.037731559947133e-05\n",
      "Epoch 1381, Loss: 0.00011878717896252056, Final Batch Loss: 5.818922090838896e-06\n",
      "Epoch 1382, Loss: 0.0001533683571324218, Final Batch Loss: 3.198186823283322e-05\n",
      "Epoch 1383, Loss: 5.6088795645337086e-05, Final Batch Loss: 9.63863840297563e-06\n",
      "Epoch 1384, Loss: 0.0005182878558116499, Final Batch Loss: 1.3752174709225073e-05\n",
      "Epoch 1385, Loss: 0.002959018042020034, Final Batch Loss: 0.00290126190520823\n",
      "Epoch 1386, Loss: 0.0001865405065473169, Final Batch Loss: 6.438625860027969e-05\n",
      "Epoch 1387, Loss: 6.386764107446652e-05, Final Batch Loss: 4.39077994087711e-05\n",
      "Epoch 1388, Loss: 0.0018958832952193916, Final Batch Loss: 0.0006631987052969635\n",
      "Epoch 1389, Loss: 0.000176750858372543, Final Batch Loss: 5.861297540832311e-05\n",
      "Epoch 1390, Loss: 0.000228142824198585, Final Batch Loss: 0.00013802191824652255\n",
      "Epoch 1391, Loss: 9.746450359671144e-05, Final Batch Loss: 8.6946702140267e-06\n",
      "Epoch 1392, Loss: 6.045387272024527e-05, Final Batch Loss: 1.0110052244272083e-05\n",
      "Epoch 1393, Loss: 0.00011631883353402372, Final Batch Loss: 2.5738945623743348e-05\n",
      "Epoch 1394, Loss: 0.0035597857931861654, Final Batch Loss: 7.677952817175537e-05\n",
      "Epoch 1395, Loss: 0.0012217789917485788, Final Batch Loss: 6.322802801150829e-05\n",
      "Epoch 1396, Loss: 0.00020932350889779627, Final Batch Loss: 9.776470687938854e-05\n",
      "Epoch 1397, Loss: 0.012152106726716738, Final Batch Loss: 0.01203115377575159\n",
      "Epoch 1398, Loss: 0.00011959294715779833, Final Batch Loss: 8.6520092736464e-05\n",
      "Epoch 1399, Loss: 0.0012030216639686842, Final Batch Loss: 8.302438800456002e-06\n",
      "Epoch 1400, Loss: 0.0034774549421854317, Final Batch Loss: 0.0033453337382525206\n",
      "Epoch 1401, Loss: 0.00039109545468818396, Final Batch Loss: 0.0002182369353249669\n",
      "Epoch 1402, Loss: 0.0001921924176713219, Final Batch Loss: 0.00016596776549704373\n",
      "Epoch 1403, Loss: 0.0014720357139594853, Final Batch Loss: 0.0014025457203388214\n",
      "Epoch 1404, Loss: 4.805860407941509e-05, Final Batch Loss: 1.4533075955114327e-05\n",
      "Epoch 1405, Loss: 0.0004956433931511128, Final Batch Loss: 2.4863033104338683e-05\n",
      "Epoch 1406, Loss: 0.0016033104329835624, Final Batch Loss: 0.001224920735694468\n",
      "Epoch 1407, Loss: 9.791403863346204e-05, Final Batch Loss: 1.3567965652327985e-05\n",
      "Epoch 1408, Loss: 0.00012238037925271783, Final Batch Loss: 9.431350190425292e-05\n",
      "Epoch 1409, Loss: 0.0023532488994533196, Final Batch Loss: 5.610335210803896e-05\n",
      "Epoch 1410, Loss: 0.0001431089658581186, Final Batch Loss: 3.44516993209254e-05\n",
      "Epoch 1411, Loss: 0.0010814389233928523, Final Batch Loss: 1.4241856661101338e-05\n",
      "Epoch 1412, Loss: 0.0005989334231344401, Final Batch Loss: 2.628999027365353e-06\n",
      "Epoch 1413, Loss: 0.0014865715056657791, Final Batch Loss: 0.001155821606516838\n",
      "Epoch 1414, Loss: 0.005107931114253006, Final Batch Loss: 1.0706737157306634e-05\n",
      "Epoch 1415, Loss: 0.00027483141457196325, Final Batch Loss: 9.994988795369864e-05\n",
      "Epoch 1416, Loss: 0.0005858869117219001, Final Batch Loss: 0.000320867111440748\n",
      "Epoch 1417, Loss: 0.0003924425991499447, Final Batch Loss: 1.3302808838489e-05\n",
      "Epoch 1418, Loss: 0.0008166969346348196, Final Batch Loss: 3.800165723077953e-05\n",
      "Epoch 1419, Loss: 0.00013481723726727068, Final Batch Loss: 5.210749804973602e-05\n",
      "Epoch 1420, Loss: 0.0014138926635496318, Final Batch Loss: 0.00018823269056156278\n",
      "Epoch 1421, Loss: 0.00012679859401032445, Final Batch Loss: 5.221089395490708e-06\n",
      "Epoch 1422, Loss: 0.0003911608764610719, Final Batch Loss: 0.0003656197222881019\n",
      "Epoch 1423, Loss: 0.0012646433169720694, Final Batch Loss: 0.001148540759459138\n",
      "Epoch 1424, Loss: 1.794412264644052e-05, Final Batch Loss: 5.75704734728788e-06\n",
      "Epoch 1425, Loss: 7.374068081844598e-05, Final Batch Loss: 3.974570063292049e-05\n",
      "Epoch 1426, Loss: 0.0024974531697807834, Final Batch Loss: 6.504419434349984e-05\n",
      "Epoch 1427, Loss: 0.0019683237969729817, Final Batch Loss: 1.5321847968152724e-05\n",
      "Epoch 1428, Loss: 0.00019649484602268785, Final Batch Loss: 7.244310108944774e-05\n",
      "Epoch 1429, Loss: 0.003362669362104498, Final Batch Loss: 0.003227143781259656\n",
      "Epoch 1430, Loss: 0.0007790844347255188, Final Batch Loss: 1.4317959539766889e-05\n",
      "Epoch 1431, Loss: 0.00012159175821579993, Final Batch Loss: 3.255549381719902e-05\n",
      "Epoch 1432, Loss: 0.006514861750474665, Final Batch Loss: 0.00010873753490159288\n",
      "Epoch 1433, Loss: 0.0008277858833025675, Final Batch Loss: 0.0007747578201815486\n",
      "Epoch 1434, Loss: 0.001908054982777685, Final Batch Loss: 0.0012605524389073253\n",
      "Epoch 1435, Loss: 0.0001949012621480506, Final Batch Loss: 2.6740843168227002e-05\n",
      "Epoch 1436, Loss: 0.0005208731708989944, Final Batch Loss: 0.0004899191553704441\n",
      "Epoch 1437, Loss: 0.0001443122800992569, Final Batch Loss: 2.4515653421985917e-05\n",
      "Epoch 1438, Loss: 0.0036412344925338402, Final Batch Loss: 0.0035435843747109175\n",
      "Epoch 1439, Loss: 0.0018639500485733151, Final Batch Loss: 0.0016941198846325278\n",
      "Epoch 1440, Loss: 0.0010505862810532562, Final Batch Loss: 0.0010271471692249179\n",
      "Epoch 1441, Loss: 0.0010698875671550923, Final Batch Loss: 4.5397578105621506e-06\n",
      "Epoch 1442, Loss: 0.0010498324045329355, Final Batch Loss: 0.0009750379831530154\n",
      "Epoch 1443, Loss: 0.0013916688112658449, Final Batch Loss: 5.957263783784583e-05\n",
      "Epoch 1444, Loss: 0.0007068561717460398, Final Batch Loss: 3.847843981930055e-05\n",
      "Epoch 1445, Loss: 0.0010205126163782552, Final Batch Loss: 0.00016389148368034512\n",
      "Epoch 1446, Loss: 0.00164944349671714, Final Batch Loss: 0.0013733437517657876\n",
      "Epoch 1447, Loss: 0.00010391055911895819, Final Batch Loss: 6.62275415379554e-05\n",
      "Epoch 1448, Loss: 5.7546015341358725e-05, Final Batch Loss: 1.0162469152419362e-05\n",
      "Epoch 1449, Loss: 0.00035409080737736076, Final Batch Loss: 0.00012800097465515137\n",
      "Epoch 1450, Loss: 2.866921295208158e-05, Final Batch Loss: 9.140226211457048e-06\n",
      "Epoch 1451, Loss: 0.0007048879137983022, Final Batch Loss: 3.655566160887247e-06\n",
      "Epoch 1452, Loss: 0.0014455726304731797, Final Batch Loss: 0.0014091532211750746\n",
      "Epoch 1453, Loss: 0.00020314416906330734, Final Batch Loss: 0.00012065391638316214\n",
      "Epoch 1454, Loss: 0.005862099846126512, Final Batch Loss: 0.0056220791302621365\n",
      "Epoch 1455, Loss: 0.0004169829626334831, Final Batch Loss: 0.0002824328257702291\n",
      "Epoch 1456, Loss: 0.002407297088211635, Final Batch Loss: 5.144538954482414e-05\n",
      "Epoch 1457, Loss: 6.481619129772298e-05, Final Batch Loss: 2.5166169507429004e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1458, Loss: 0.0024522287749277893, Final Batch Loss: 3.273142283433117e-05\n",
      "Epoch 1459, Loss: 4.2256657252437435e-05, Final Batch Loss: 1.937009255925659e-05\n",
      "Epoch 1460, Loss: 3.445457878115121e-05, Final Batch Loss: 2.2499150873045437e-05\n",
      "Epoch 1461, Loss: 0.005468371789902449, Final Batch Loss: 0.004558039363473654\n",
      "Epoch 1462, Loss: 0.00015867896036070306, Final Batch Loss: 0.00013522262452170253\n",
      "Epoch 1463, Loss: 0.00335418080794625, Final Batch Loss: 0.0030532677192240953\n",
      "Epoch 1464, Loss: 0.0013263730215840042, Final Batch Loss: 0.0001912526204250753\n",
      "Epoch 1465, Loss: 0.0005875883653061464, Final Batch Loss: 0.00016314063395839185\n",
      "Epoch 1466, Loss: 8.596415955253178e-05, Final Batch Loss: 7.329405343625695e-05\n",
      "Epoch 1467, Loss: 0.00010206937474777078, Final Batch Loss: 1.7805508605306386e-06\n",
      "Epoch 1468, Loss: 0.0002094559231409221, Final Batch Loss: 1.0458860742801335e-05\n",
      "Epoch 1469, Loss: 0.0007778735598549247, Final Batch Loss: 5.1727984100580215e-05\n",
      "Epoch 1470, Loss: 3.488492620817851e-05, Final Batch Loss: 1.6844423953443766e-05\n",
      "Epoch 1471, Loss: 0.002497868175851181, Final Batch Loss: 0.0023694902192801237\n",
      "Epoch 1472, Loss: 0.00018375759373157052, Final Batch Loss: 1.4758576980966609e-05\n",
      "Epoch 1473, Loss: 0.011431727973103989, Final Batch Loss: 0.011396506801247597\n",
      "Epoch 1474, Loss: 6.996271986281499e-05, Final Batch Loss: 5.5436092225136235e-05\n",
      "Epoch 1475, Loss: 6.151158049760852e-05, Final Batch Loss: 2.1440793716465123e-05\n",
      "Epoch 1476, Loss: 0.0010861326300073415, Final Batch Loss: 0.00025479114265181124\n",
      "Epoch 1477, Loss: 7.30899100744864e-05, Final Batch Loss: 2.6193223675363697e-05\n",
      "Epoch 1478, Loss: 0.0003420681314310059, Final Batch Loss: 0.00021783271222375333\n",
      "Epoch 1479, Loss: 0.0002946211752714589, Final Batch Loss: 5.0976057536900043e-05\n",
      "Epoch 1480, Loss: 0.00018426571477903053, Final Batch Loss: 1.6862126358319074e-05\n",
      "Epoch 1481, Loss: 0.0010253959626425058, Final Batch Loss: 0.0006823587464168668\n",
      "Epoch 1482, Loss: 0.004644550266675651, Final Batch Loss: 0.0008828415302559733\n",
      "Epoch 1483, Loss: 0.0004188237071502954, Final Batch Loss: 0.00011682233889587224\n",
      "Epoch 1484, Loss: 0.00014446819477598183, Final Batch Loss: 1.4952496712794527e-05\n",
      "Epoch 1485, Loss: 0.0012651420329348184, Final Batch Loss: 7.253888907143846e-05\n",
      "Epoch 1486, Loss: 0.00026744502065412235, Final Batch Loss: 1.9105382307316177e-05\n",
      "Epoch 1487, Loss: 0.0006414488107111538, Final Batch Loss: 2.610390401969198e-05\n",
      "Epoch 1488, Loss: 0.0003568690372048877, Final Batch Loss: 0.00011864136467920616\n",
      "Epoch 1489, Loss: 0.0005566039435507264, Final Batch Loss: 4.8429934395244345e-05\n",
      "Epoch 1490, Loss: 0.00013218654930824414, Final Batch Loss: 0.00010446708620293066\n",
      "Epoch 1491, Loss: 0.00039079165435396135, Final Batch Loss: 0.0001764076587278396\n",
      "Epoch 1492, Loss: 0.0009309246252087178, Final Batch Loss: 3.0361365134012885e-05\n",
      "Epoch 1493, Loss: 0.0004189897808828391, Final Batch Loss: 0.0003872041997965425\n",
      "Epoch 1494, Loss: 0.00013430819126369897, Final Batch Loss: 2.201614734076429e-05\n",
      "Epoch 1495, Loss: 0.0008676498400745913, Final Batch Loss: 7.080762588884681e-05\n",
      "Epoch 1496, Loss: 0.00034154260538343806, Final Batch Loss: 1.643419273023028e-05\n",
      "Epoch 1497, Loss: 5.331846477929503e-05, Final Batch Loss: 2.636202952999156e-05\n",
      "Epoch 1498, Loss: 2.3690636226092465e-05, Final Batch Loss: 4.2543470044620335e-06\n",
      "Epoch 1499, Loss: 0.007873677203861007, Final Batch Loss: 8.735361006984022e-06\n",
      "Epoch 1500, Loss: 0.00013131600553606404, Final Batch Loss: 1.0969985851261299e-05\n",
      "Epoch 1501, Loss: 0.002006404029089026, Final Batch Loss: 0.00022285226441454142\n",
      "Epoch 1502, Loss: 0.0002821185562424944, Final Batch Loss: 1.0808108527271543e-05\n",
      "Epoch 1503, Loss: 0.0010378669567217003, Final Batch Loss: 9.792539458430838e-06\n",
      "Epoch 1504, Loss: 0.00016035057706176303, Final Batch Loss: 1.969020740943961e-05\n",
      "Epoch 1505, Loss: 0.00010960478175547905, Final Batch Loss: 5.111261998536065e-05\n",
      "Epoch 1506, Loss: 2.025000321737025e-05, Final Batch Loss: 5.670506652677432e-06\n",
      "Epoch 1507, Loss: 0.00025251209444832057, Final Batch Loss: 0.0001640219852561131\n",
      "Epoch 1508, Loss: 0.0006878055864945054, Final Batch Loss: 0.00030150116072036326\n",
      "Epoch 1509, Loss: 0.00040280459506902844, Final Batch Loss: 0.00026942059048451483\n",
      "Epoch 1510, Loss: 9.999584108300041e-05, Final Batch Loss: 8.422471000812948e-05\n",
      "Epoch 1511, Loss: 0.00016710958880139515, Final Batch Loss: 0.00012188446999061853\n",
      "Epoch 1512, Loss: 8.241043360612821e-05, Final Batch Loss: 5.67508177482523e-05\n",
      "Epoch 1513, Loss: 0.0034332562927374966, Final Batch Loss: 1.120439173973864e-05\n",
      "Epoch 1514, Loss: 0.0025941708881873637, Final Batch Loss: 0.0025283037684857845\n",
      "Epoch 1515, Loss: 0.0001640301306906622, Final Batch Loss: 0.0001170463947346434\n",
      "Epoch 1516, Loss: 4.1347418118675705e-05, Final Batch Loss: 7.675857887079474e-06\n",
      "Epoch 1517, Loss: 0.00015116240683710203, Final Batch Loss: 6.495216075563803e-05\n",
      "Epoch 1518, Loss: 0.000677641284710262, Final Batch Loss: 0.0006536510773003101\n",
      "Epoch 1519, Loss: 0.0004921531362924725, Final Batch Loss: 0.00045545242028310895\n",
      "Epoch 1520, Loss: 9.298210170527454e-05, Final Batch Loss: 2.0195066099404357e-05\n",
      "Epoch 1521, Loss: 0.0001940245638252236, Final Batch Loss: 6.001503061270341e-05\n",
      "Epoch 1522, Loss: 0.001556714589241892, Final Batch Loss: 0.0009546981891617179\n",
      "Epoch 1523, Loss: 9.535007848171517e-05, Final Batch Loss: 4.419026299729012e-05\n",
      "Epoch 1524, Loss: 0.00014578573609469458, Final Batch Loss: 3.392563667148352e-05\n",
      "Epoch 1525, Loss: 8.039517342695035e-05, Final Batch Loss: 4.798009103978984e-05\n",
      "Epoch 1526, Loss: 0.001636844186577946, Final Batch Loss: 0.0001628106110729277\n",
      "Epoch 1527, Loss: 0.0003592040957300924, Final Batch Loss: 0.0002758129558060318\n",
      "Epoch 1528, Loss: 9.405573837284464e-05, Final Batch Loss: 8.280044858111069e-05\n",
      "Epoch 1529, Loss: 0.0006289601951721124, Final Batch Loss: 0.0005096755339764059\n",
      "Epoch 1530, Loss: 0.0003068136065849103, Final Batch Loss: 1.874936424428597e-05\n",
      "Epoch 1531, Loss: 0.0004675700474763289, Final Batch Loss: 0.0003668943827506155\n",
      "Epoch 1532, Loss: 7.087828453222755e-05, Final Batch Loss: 2.792875784507487e-05\n",
      "Epoch 1533, Loss: 0.00013791338369628647, Final Batch Loss: 7.951800398586784e-06\n",
      "Epoch 1534, Loss: 0.0022042535711079836, Final Batch Loss: 4.161451943218708e-05\n",
      "Epoch 1535, Loss: 0.00019229323515901342, Final Batch Loss: 8.403699757764116e-05\n",
      "Epoch 1536, Loss: 0.000527226562553551, Final Batch Loss: 4.329950752435252e-05\n",
      "Epoch 1537, Loss: 0.0007079896022332832, Final Batch Loss: 0.00021073447715025395\n",
      "Epoch 1538, Loss: 0.00045662363118026406, Final Batch Loss: 0.00023328352835960686\n",
      "Epoch 1539, Loss: 3.135199676762568e-05, Final Batch Loss: 1.0654962352418806e-05\n",
      "Epoch 1540, Loss: 0.00039933380321599543, Final Batch Loss: 0.00034494599094614387\n",
      "Epoch 1541, Loss: 0.00011709124555636663, Final Batch Loss: 2.0494970158324577e-05\n",
      "Epoch 1542, Loss: 3.958815523219528e-05, Final Batch Loss: 3.113825005129911e-05\n",
      "Epoch 1543, Loss: 0.00017123983707278967, Final Batch Loss: 6.15545068285428e-05\n",
      "Epoch 1544, Loss: 0.0006947921210667118, Final Batch Loss: 0.0005157841951586306\n",
      "Epoch 1545, Loss: 0.0012364737303869333, Final Batch Loss: 2.8615988412639126e-05\n",
      "Epoch 1546, Loss: 0.00029718218320340384, Final Batch Loss: 0.00027086908812634647\n",
      "Epoch 1547, Loss: 0.00021362266397773055, Final Batch Loss: 9.882244739856105e-06\n",
      "Epoch 1548, Loss: 0.00011008602268702816, Final Batch Loss: 8.067665476119146e-05\n",
      "Epoch 1549, Loss: 8.075827827269677e-05, Final Batch Loss: 5.5077209253795445e-05\n",
      "Epoch 1550, Loss: 0.0006731782341375947, Final Batch Loss: 0.00023804951342754066\n",
      "Epoch 1551, Loss: 0.00016176854114746675, Final Batch Loss: 3.6944889870937914e-05\n",
      "Epoch 1552, Loss: 0.0002474708703630313, Final Batch Loss: 6.634053988818778e-06\n",
      "Epoch 1553, Loss: 9.103458796744235e-05, Final Batch Loss: 4.820884714717977e-05\n",
      "Epoch 1554, Loss: 0.00025712771457619965, Final Batch Loss: 0.00021095022384542972\n",
      "Epoch 1555, Loss: 6.822402974648867e-05, Final Batch Loss: 1.3899918485549279e-05\n",
      "Epoch 1556, Loss: 0.0006512093787023332, Final Batch Loss: 5.775055251433514e-05\n",
      "Epoch 1557, Loss: 0.0002372769140492892, Final Batch Loss: 2.4165294234990142e-05\n",
      "Epoch 1558, Loss: 0.0002265012517455034, Final Batch Loss: 0.00010972691961796954\n",
      "Epoch 1559, Loss: 0.0007829894420865458, Final Batch Loss: 0.0007508746930398047\n",
      "Epoch 1560, Loss: 0.0008120047568809241, Final Batch Loss: 0.000559976848307997\n",
      "Epoch 1561, Loss: 5.750510172219947e-05, Final Batch Loss: 4.716416879091412e-05\n",
      "Epoch 1562, Loss: 0.0020032934517075773, Final Batch Loss: 5.76857928535901e-06\n",
      "Epoch 1563, Loss: 0.00013774731996818446, Final Batch Loss: 2.2035685105947778e-05\n",
      "Epoch 1564, Loss: 0.004667801636969671, Final Batch Loss: 0.0046529644168913364\n",
      "Epoch 1565, Loss: 0.0001373700961266877, Final Batch Loss: 0.0001198804602609016\n",
      "Epoch 1566, Loss: 0.0002441895703668706, Final Batch Loss: 0.00016105044051073492\n",
      "Epoch 1567, Loss: 0.005454319762066007, Final Batch Loss: 0.004830250516533852\n",
      "Epoch 1568, Loss: 1.3275643595989095e-05, Final Batch Loss: 6.585908522538375e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1569, Loss: 0.0002804707401082851, Final Batch Loss: 3.581582132028416e-05\n",
      "Epoch 1570, Loss: 0.00020346012297522975, Final Batch Loss: 1.3468498764268588e-05\n",
      "Epoch 1571, Loss: 0.00018494059986551292, Final Batch Loss: 1.8636030290508643e-05\n",
      "Epoch 1572, Loss: 0.0002946089498436777, Final Batch Loss: 5.355932444217615e-06\n",
      "Epoch 1573, Loss: 0.00015941515448503196, Final Batch Loss: 3.644730895757675e-05\n",
      "Epoch 1574, Loss: 0.00047933846508385614, Final Batch Loss: 8.933054778026417e-05\n",
      "Epoch 1575, Loss: 0.00032285739871440455, Final Batch Loss: 0.00022622779943048954\n",
      "Epoch 1576, Loss: 9.08932361198822e-05, Final Batch Loss: 1.755961602611933e-05\n",
      "Epoch 1577, Loss: 0.0002156538248527795, Final Batch Loss: 9.761576075106859e-05\n",
      "Epoch 1578, Loss: 0.0006336635269690305, Final Batch Loss: 9.783569839783013e-05\n",
      "Epoch 1579, Loss: 6.237965089894715e-05, Final Batch Loss: 4.550743597064866e-06\n",
      "Epoch 1580, Loss: 7.699829984630924e-05, Final Batch Loss: 5.276947558741085e-05\n",
      "Epoch 1581, Loss: 0.001151468441094039, Final Batch Loss: 0.001091980841010809\n",
      "Epoch 1582, Loss: 0.0016527466141269542, Final Batch Loss: 9.135146683547646e-06\n",
      "Epoch 1583, Loss: 0.01490075212859665, Final Batch Loss: 3.39660509780515e-05\n",
      "Epoch 1584, Loss: 0.0005320819091139128, Final Batch Loss: 1.825081380957272e-05\n",
      "Epoch 1585, Loss: 0.0004975400806870311, Final Batch Loss: 0.0002747154503595084\n",
      "Epoch 1586, Loss: 0.0022406541975215077, Final Batch Loss: 0.0015551031101495028\n",
      "Epoch 1587, Loss: 0.00018045318574877456, Final Batch Loss: 0.00011348941916367039\n",
      "Epoch 1588, Loss: 0.00017938730343303178, Final Batch Loss: 0.00016165706620085984\n",
      "Epoch 1589, Loss: 0.0037473972133739153, Final Batch Loss: 0.0037242418620735407\n",
      "Epoch 1590, Loss: 0.000544137563338154, Final Batch Loss: 0.0005184172769077122\n",
      "Epoch 1591, Loss: 9.439182031201199e-05, Final Batch Loss: 1.9002953195013106e-05\n",
      "Epoch 1592, Loss: 4.562569210975198e-05, Final Batch Loss: 3.145256050629541e-05\n",
      "Epoch 1593, Loss: 0.000411959204939194, Final Batch Loss: 0.00014156785618979484\n",
      "Epoch 1594, Loss: 0.002078180870739743, Final Batch Loss: 2.7504953322932124e-05\n",
      "Epoch 1595, Loss: 0.0002869224772439338, Final Batch Loss: 2.3021922970656306e-05\n",
      "Epoch 1596, Loss: 0.0006847007225587731, Final Batch Loss: 1.5643765436834656e-05\n",
      "Epoch 1597, Loss: 0.0020492915937211365, Final Batch Loss: 0.00022084181546233594\n",
      "Epoch 1598, Loss: 0.0008394905016757548, Final Batch Loss: 0.0003882861929014325\n",
      "Epoch 1599, Loss: 0.00034743057040032, Final Batch Loss: 0.00027666293317452073\n",
      "Epoch 1600, Loss: 0.00010913478854490677, Final Batch Loss: 9.924606274580583e-05\n",
      "Epoch 1601, Loss: 3.117558026133338e-05, Final Batch Loss: 9.06472541828407e-06\n",
      "Epoch 1602, Loss: 0.0001614335915292031, Final Batch Loss: 1.4087446288613137e-05\n",
      "Epoch 1603, Loss: 0.00013871449118596502, Final Batch Loss: 9.098673763219267e-05\n",
      "Epoch 1604, Loss: 0.0012919857108499855, Final Batch Loss: 0.00021536750136874616\n",
      "Epoch 1605, Loss: 0.00012492533096519765, Final Batch Loss: 1.3301343642524444e-05\n",
      "Epoch 1606, Loss: 0.000860584179918078, Final Batch Loss: 5.507412879524054e-06\n",
      "Epoch 1607, Loss: 0.0012322218935878482, Final Batch Loss: 0.0011904066195711493\n",
      "Epoch 1608, Loss: 0.0002590715484984685, Final Batch Loss: 4.582242763717659e-05\n",
      "Epoch 1609, Loss: 3.640856357378652e-05, Final Batch Loss: 2.6506650101509877e-05\n",
      "Epoch 1610, Loss: 0.0011935222428292036, Final Batch Loss: 0.0005414965562522411\n",
      "Epoch 1611, Loss: 0.00018377749620412942, Final Batch Loss: 2.365948421356734e-05\n",
      "Epoch 1612, Loss: 4.458899456949439e-05, Final Batch Loss: 1.0663532520993613e-05\n",
      "Epoch 1613, Loss: 0.0007440326880896464, Final Batch Loss: 7.905009260866791e-05\n",
      "Epoch 1614, Loss: 0.0001954784311237745, Final Batch Loss: 9.789307659957558e-05\n",
      "Epoch 1615, Loss: 0.0030389282619580626, Final Batch Loss: 0.0014547493774443865\n",
      "Epoch 1616, Loss: 0.0005388701829360798, Final Batch Loss: 0.00020622399460989982\n",
      "Epoch 1617, Loss: 0.0016124930698424578, Final Batch Loss: 0.0008471246692351997\n",
      "Epoch 1618, Loss: 9.173035368803539e-05, Final Batch Loss: 8.736485324334353e-05\n",
      "Epoch 1619, Loss: 0.0003074264677707106, Final Batch Loss: 0.00011156110849697143\n",
      "Epoch 1620, Loss: 4.1139856875815894e-05, Final Batch Loss: 8.218167749873828e-06\n",
      "Epoch 1621, Loss: 0.00014853294123895466, Final Batch Loss: 2.0007966668345034e-05\n",
      "Epoch 1622, Loss: 0.000308398601191584, Final Batch Loss: 7.379856106126681e-05\n",
      "Epoch 1623, Loss: 0.0031968690291250823, Final Batch Loss: 1.4427101632463746e-05\n",
      "Epoch 1624, Loss: 6.416099404304987e-05, Final Batch Loss: 1.1988288861175533e-05\n",
      "Epoch 1625, Loss: 0.0004405604322528234, Final Batch Loss: 0.0004257532418705523\n",
      "Epoch 1626, Loss: 6.877810574223986e-05, Final Batch Loss: 1.024655193759827e-05\n",
      "Epoch 1627, Loss: 2.9206553335825447e-05, Final Batch Loss: 1.6148063878063112e-05\n",
      "Epoch 1628, Loss: 0.003831466501651448, Final Batch Loss: 0.0038224663585424423\n",
      "Epoch 1629, Loss: 0.00022526101747644134, Final Batch Loss: 4.953242387273349e-05\n",
      "Epoch 1630, Loss: 1.4129053852229845e-05, Final Batch Loss: 3.5258926800452173e-07\n",
      "Epoch 1631, Loss: 9.414412852493115e-05, Final Batch Loss: 5.3424155339598656e-05\n",
      "Epoch 1632, Loss: 0.00013256948659545742, Final Batch Loss: 1.0394342098152265e-05\n",
      "Epoch 1633, Loss: 4.553181042865617e-05, Final Batch Loss: 5.298547876009252e-06\n",
      "Epoch 1634, Loss: 8.157905185157688e-06, Final Batch Loss: 1.1417215262099489e-07\n",
      "Epoch 1635, Loss: 0.00028020170429954305, Final Batch Loss: 7.85440715844743e-05\n",
      "Epoch 1636, Loss: 0.0032230504148174077, Final Batch Loss: 8.618624997325242e-05\n",
      "Epoch 1637, Loss: 7.157386062317528e-05, Final Batch Loss: 3.0432736821239814e-05\n",
      "Epoch 1638, Loss: 0.00127286376664415, Final Batch Loss: 0.0006892341189086437\n",
      "Epoch 1639, Loss: 0.0006194963352754712, Final Batch Loss: 0.00023942487314343452\n",
      "Epoch 1640, Loss: 6.916724487382453e-05, Final Batch Loss: 4.143071055295877e-05\n",
      "Epoch 1641, Loss: 0.0014020068338140845, Final Batch Loss: 0.0010117220226675272\n",
      "Epoch 1642, Loss: 9.640354983275756e-05, Final Batch Loss: 6.855092942714691e-05\n",
      "Epoch 1643, Loss: 7.503014899157279e-05, Final Batch Loss: 1.2390603387757437e-06\n",
      "Epoch 1644, Loss: 0.005686091026291251, Final Batch Loss: 0.005074146203696728\n",
      "Epoch 1645, Loss: 0.0005174066754989326, Final Batch Loss: 0.00038039530045352876\n",
      "Epoch 1646, Loss: 0.0007526025392508018, Final Batch Loss: 8.029232958506327e-06\n",
      "Epoch 1647, Loss: 0.0002847825307981111, Final Batch Loss: 0.00020625432080123574\n",
      "Epoch 1648, Loss: 8.107168468995951e-05, Final Batch Loss: 5.426711868494749e-05\n",
      "Epoch 1649, Loss: 0.00034125942329410464, Final Batch Loss: 0.00016937864711508155\n",
      "Epoch 1650, Loss: 0.0006431526417145506, Final Batch Loss: 7.504249515477568e-05\n",
      "Epoch 1651, Loss: 0.0003848232445307076, Final Batch Loss: 6.753284833393991e-05\n",
      "Epoch 1652, Loss: 0.0001891635274660075, Final Batch Loss: 8.074226570897736e-06\n",
      "Epoch 1653, Loss: 0.00032956490031210706, Final Batch Loss: 8.722178608877584e-05\n",
      "Epoch 1654, Loss: 0.00024954839682322927, Final Batch Loss: 3.7488080124603584e-05\n",
      "Epoch 1655, Loss: 2.196653986175079e-05, Final Batch Loss: 1.3511928045772947e-05\n",
      "Epoch 1656, Loss: 4.0754358678896097e-05, Final Batch Loss: 1.1803124380094232e-06\n",
      "Epoch 1657, Loss: 0.00015020302089396864, Final Batch Loss: 6.769236642867327e-05\n",
      "Epoch 1658, Loss: 3.6957304473617114e-05, Final Batch Loss: 1.0092726370203309e-05\n",
      "Epoch 1659, Loss: 0.00013725991993851494, Final Batch Loss: 0.0001125883572967723\n",
      "Epoch 1660, Loss: 0.00011995116028629127, Final Batch Loss: 6.826004664617358e-06\n",
      "Epoch 1661, Loss: 0.0001337763378614909, Final Batch Loss: 0.00012181117199361324\n",
      "Epoch 1662, Loss: 0.00014442479005083442, Final Batch Loss: 3.876175469486043e-05\n",
      "Epoch 1663, Loss: 1.3522385870601283e-05, Final Batch Loss: 9.169394616037607e-06\n",
      "Epoch 1664, Loss: 6.962361658224836e-05, Final Batch Loss: 5.475054058479145e-05\n",
      "Epoch 1665, Loss: 0.0010201978730037808, Final Batch Loss: 0.0009180198539979756\n",
      "Epoch 1666, Loss: 0.0006520107708638534, Final Batch Loss: 4.0959377656690776e-05\n",
      "Epoch 1667, Loss: 0.00010820141142175999, Final Batch Loss: 2.5333594749099575e-05\n",
      "Epoch 1668, Loss: 3.7116260500624776e-05, Final Batch Loss: 1.9956631149398163e-05\n",
      "Epoch 1669, Loss: 0.001230933726674266, Final Batch Loss: 0.001225171028636396\n",
      "Epoch 1670, Loss: 0.00032670250766386744, Final Batch Loss: 1.5268471543095075e-05\n",
      "Epoch 1671, Loss: 0.00038853968726471066, Final Batch Loss: 0.00023456003691535443\n",
      "Epoch 1672, Loss: 0.0021281091612763703, Final Batch Loss: 0.0017623472958803177\n",
      "Epoch 1673, Loss: 0.001101566687225386, Final Batch Loss: 9.813569477046258e-07\n",
      "Epoch 1674, Loss: 6.77271145832492e-05, Final Batch Loss: 2.142628909496125e-05\n",
      "Epoch 1675, Loss: 9.693665924714878e-05, Final Batch Loss: 8.55268444865942e-06\n",
      "Epoch 1676, Loss: 0.017313515963905957, Final Batch Loss: 2.2117244952823967e-05\n",
      "Epoch 1677, Loss: 2.176886027882574e-05, Final Batch Loss: 1.2157058336015325e-05\n",
      "Epoch 1678, Loss: 0.0011519499821588397, Final Batch Loss: 0.0005179453291930258\n",
      "Epoch 1679, Loss: 0.00014063539492781274, Final Batch Loss: 0.00011096963135059923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1680, Loss: 0.003265453298809007, Final Batch Loss: 0.0028982844669371843\n",
      "Epoch 1681, Loss: 0.0003660668517113663, Final Batch Loss: 4.049094422953203e-05\n",
      "Epoch 1682, Loss: 6.737121839250904e-05, Final Batch Loss: 2.217853943875525e-05\n",
      "Epoch 1683, Loss: 9.918456089508254e-05, Final Batch Loss: 2.477554698998574e-05\n",
      "Epoch 1684, Loss: 7.907539838925004e-05, Final Batch Loss: 2.385217885603197e-05\n",
      "Epoch 1685, Loss: 0.0004085620603291318, Final Batch Loss: 0.0002136134571628645\n",
      "Epoch 1686, Loss: 0.0009776809019967914, Final Batch Loss: 2.972286893054843e-05\n",
      "Epoch 1687, Loss: 0.005373209855861205, Final Batch Loss: 0.005363133270293474\n",
      "Epoch 1688, Loss: 0.003078389605434495, Final Batch Loss: 0.0030485414899885654\n",
      "Epoch 1689, Loss: 0.0003266745916334912, Final Batch Loss: 0.00014104280853644013\n",
      "Epoch 1690, Loss: 0.00022053857537684962, Final Batch Loss: 7.265122985700145e-05\n",
      "Epoch 1691, Loss: 6.551946717081591e-05, Final Batch Loss: 2.7821832190966234e-05\n",
      "Epoch 1692, Loss: 1.4966933122195769e-05, Final Batch Loss: 1.1186082701897249e-05\n",
      "Epoch 1693, Loss: 0.0015121580800041556, Final Batch Loss: 0.0014759150799363852\n",
      "Epoch 1694, Loss: 9.77873114607064e-05, Final Batch Loss: 2.9022825401625596e-05\n",
      "Epoch 1695, Loss: 0.0007072811567923054, Final Batch Loss: 0.0006242541130632162\n",
      "Epoch 1696, Loss: 0.0012049200540786842, Final Batch Loss: 2.0443281755433418e-05\n",
      "Epoch 1697, Loss: 0.00038274878170341253, Final Batch Loss: 0.0003005098842550069\n",
      "Epoch 1698, Loss: 5.7427375850238604e-05, Final Batch Loss: 5.0910657591884956e-05\n",
      "Epoch 1699, Loss: 3.4300666811759584e-05, Final Batch Loss: 2.1213969375821762e-05\n",
      "Epoch 1700, Loss: 0.00012843407603213564, Final Batch Loss: 6.89057560521178e-05\n",
      "Epoch 1701, Loss: 0.0007949311984702945, Final Batch Loss: 0.000510861340444535\n",
      "Epoch 1702, Loss: 2.2862132937007118e-05, Final Batch Loss: 8.231845640693791e-06\n",
      "Epoch 1703, Loss: 0.00010577718967397232, Final Batch Loss: 1.6586929632467218e-05\n",
      "Epoch 1704, Loss: 2.5143552193185315e-05, Final Batch Loss: 1.4413039934879635e-05\n",
      "Epoch 1705, Loss: 7.445359960911446e-05, Final Batch Loss: 5.759719442721689e-06\n",
      "Epoch 1706, Loss: 2.7720810976461507e-05, Final Batch Loss: 2.050479088211432e-05\n",
      "Epoch 1707, Loss: 6.0985188611084595e-05, Final Batch Loss: 3.9662831113673747e-05\n",
      "Epoch 1708, Loss: 0.00024964668409666047, Final Batch Loss: 3.0328148568514735e-05\n",
      "Epoch 1709, Loss: 0.00012393955694278702, Final Batch Loss: 6.187129474710673e-05\n",
      "Epoch 1710, Loss: 0.0009160224481092882, Final Batch Loss: 5.579368917096872e-06\n",
      "Epoch 1711, Loss: 0.00016794487123661384, Final Batch Loss: 1.9098031316389097e-06\n",
      "Epoch 1712, Loss: 0.0012827996270061703, Final Batch Loss: 1.7004656911012717e-05\n",
      "Epoch 1713, Loss: 0.00064361546174041, Final Batch Loss: 4.864701986662112e-05\n",
      "Epoch 1714, Loss: 0.0004351957577455323, Final Batch Loss: 5.058805618318729e-05\n",
      "Epoch 1715, Loss: 0.00015457687186426483, Final Batch Loss: 4.4571741455001757e-05\n",
      "Epoch 1716, Loss: 0.00023903974943095818, Final Batch Loss: 9.686350676929578e-05\n",
      "Epoch 1717, Loss: 5.021155479312256e-05, Final Batch Loss: 3.8196989748939814e-07\n",
      "Epoch 1718, Loss: 0.00014946926376069314, Final Batch Loss: 6.1712721617368516e-06\n",
      "Epoch 1719, Loss: 0.00011484473361633718, Final Batch Loss: 6.378890248015523e-05\n",
      "Epoch 1720, Loss: 0.00048658926971256733, Final Batch Loss: 0.00038675390533171594\n",
      "Epoch 1721, Loss: 0.001605392106284853, Final Batch Loss: 0.0015358610544353724\n",
      "Epoch 1722, Loss: 5.19355817232281e-05, Final Batch Loss: 1.8422877474222332e-05\n",
      "Epoch 1723, Loss: 0.0010201076947851107, Final Batch Loss: 0.0008427980355918407\n",
      "Epoch 1724, Loss: 0.00013174478408473078, Final Batch Loss: 1.5324296327889897e-05\n",
      "Epoch 1725, Loss: 0.00014329982150229625, Final Batch Loss: 5.9374255215516314e-05\n",
      "Epoch 1726, Loss: 0.0005168784018678707, Final Batch Loss: 1.1417218956921715e-05\n",
      "Epoch 1727, Loss: 2.169783692806959e-05, Final Batch Loss: 6.696238415315747e-06\n",
      "Epoch 1728, Loss: 0.00013300276441441383, Final Batch Loss: 0.00011726710363291204\n",
      "Epoch 1729, Loss: 0.0006976688309805468, Final Batch Loss: 0.000593643169850111\n",
      "Epoch 1730, Loss: 0.0001347248562524328, Final Batch Loss: 2.0062509065610357e-05\n",
      "Epoch 1731, Loss: 0.0007329310683417134, Final Batch Loss: 9.516445425106212e-05\n",
      "Epoch 1732, Loss: 5.0333517719991505e-05, Final Batch Loss: 1.793386763893068e-05\n",
      "Epoch 1733, Loss: 0.00034759552818286465, Final Batch Loss: 0.00033821354736573994\n",
      "Epoch 1734, Loss: 0.00012744481637128047, Final Batch Loss: 3.2780385481601115e-06\n",
      "Epoch 1735, Loss: 0.00041380752008990385, Final Batch Loss: 0.00036507585900835693\n",
      "Epoch 1736, Loss: 0.0003203358987775573, Final Batch Loss: 4.191320385871222e-06\n",
      "Epoch 1737, Loss: 0.00019110881839878857, Final Batch Loss: 0.00011215378617634997\n",
      "Epoch 1738, Loss: 0.0002063147803710308, Final Batch Loss: 2.413423135294579e-05\n",
      "Epoch 1739, Loss: 0.000443670270669827, Final Batch Loss: 0.0004411284171510488\n",
      "Epoch 1740, Loss: 0.0006938140832062345, Final Batch Loss: 3.6100052966503426e-05\n",
      "Epoch 1741, Loss: 3.983372857874201e-05, Final Batch Loss: 3.2192945127462735e-06\n",
      "Epoch 1742, Loss: 0.00017376811229041778, Final Batch Loss: 5.280611730995588e-05\n",
      "Epoch 1743, Loss: 6.466583363362588e-05, Final Batch Loss: 1.765715569490567e-05\n",
      "Epoch 1744, Loss: 1.1909866771020461e-05, Final Batch Loss: 6.726015726599144e-06\n",
      "Epoch 1745, Loss: 5.384182804846205e-05, Final Batch Loss: 1.6254452930297703e-05\n",
      "Epoch 1746, Loss: 0.007242509385832818, Final Batch Loss: 0.0072196973487734795\n",
      "Epoch 1747, Loss: 0.000707905294120792, Final Batch Loss: 2.884384457502165e-06\n",
      "Epoch 1748, Loss: 0.007457039435394108, Final Batch Loss: 0.00020198116544634104\n",
      "Epoch 1749, Loss: 0.00025331526558147743, Final Batch Loss: 0.00010256582027068362\n",
      "Epoch 1750, Loss: 0.0005076966481283307, Final Batch Loss: 0.0001349020458292216\n",
      "Epoch 1751, Loss: 0.00015507910802625702, Final Batch Loss: 5.687967586709419e-06\n",
      "Epoch 1752, Loss: 0.00011143809933855664, Final Batch Loss: 7.246670065796934e-06\n",
      "Epoch 1753, Loss: 4.2783112803590484e-05, Final Batch Loss: 2.6759164029499516e-05\n",
      "Epoch 1754, Loss: 0.0013324225728865713, Final Batch Loss: 0.0009136688895523548\n",
      "Epoch 1755, Loss: 0.0012266846024431288, Final Batch Loss: 0.0005426371353678405\n",
      "Epoch 1756, Loss: 0.0001563743244332727, Final Batch Loss: 2.9061364330118522e-05\n",
      "Epoch 1757, Loss: 0.0002493497959221713, Final Batch Loss: 0.00013381817552726716\n",
      "Epoch 1758, Loss: 0.000673192206704698, Final Batch Loss: 1.1461847861937713e-05\n",
      "Epoch 1759, Loss: 3.4772212529787794e-05, Final Batch Loss: 1.528014399809763e-05\n",
      "Epoch 1760, Loss: 0.00044856543354399037, Final Batch Loss: 0.0004260788264218718\n",
      "Epoch 1761, Loss: 0.00024679040018327214, Final Batch Loss: 1.3347768117455416e-06\n",
      "Epoch 1762, Loss: 0.0009504914414719678, Final Batch Loss: 3.459942672634497e-05\n",
      "Epoch 1763, Loss: 0.00021261930487526115, Final Batch Loss: 2.338609738217201e-05\n",
      "Epoch 1764, Loss: 9.80498061835533e-05, Final Batch Loss: 2.8056134397047572e-05\n",
      "Epoch 1765, Loss: 0.00020189181668683887, Final Batch Loss: 3.500444290693849e-05\n",
      "Epoch 1766, Loss: 7.017120015007094e-05, Final Batch Loss: 1.9819658518827055e-06\n",
      "Epoch 1767, Loss: 0.0002330601928406395, Final Batch Loss: 0.0001476789329899475\n",
      "Epoch 1768, Loss: 8.772111777943792e-05, Final Batch Loss: 7.5348989412304945e-06\n",
      "Epoch 1769, Loss: 0.00034432296342856716, Final Batch Loss: 2.679801946214866e-05\n",
      "Epoch 1770, Loss: 0.00013105609559715958, Final Batch Loss: 0.0001222587306983769\n",
      "Epoch 1771, Loss: 0.00017058762023225427, Final Batch Loss: 7.690182246733457e-05\n",
      "Epoch 1772, Loss: 0.00010309165918442886, Final Batch Loss: 5.656720531987958e-06\n",
      "Epoch 1773, Loss: 0.006206080463016406, Final Batch Loss: 7.814043783582747e-05\n",
      "Epoch 1774, Loss: 0.00029956537764519453, Final Batch Loss: 0.0001843276695581153\n",
      "Epoch 1775, Loss: 4.3504151108209044e-05, Final Batch Loss: 2.486021003278438e-05\n",
      "Epoch 1776, Loss: 0.00011889901361428201, Final Batch Loss: 6.177804607432336e-05\n",
      "Epoch 1777, Loss: 0.00026507397706154734, Final Batch Loss: 0.00017325746011920273\n",
      "Epoch 1778, Loss: 0.0005037865557824261, Final Batch Loss: 8.808583515929058e-05\n",
      "Epoch 1779, Loss: 0.00033287661426584236, Final Batch Loss: 3.5669869248522446e-05\n",
      "Epoch 1780, Loss: 0.0008073759090621024, Final Batch Loss: 0.0003248967113904655\n",
      "Epoch 1781, Loss: 0.00018436732898408081, Final Batch Loss: 0.00016298380796797574\n",
      "Epoch 1782, Loss: 4.033778532175347e-05, Final Batch Loss: 1.937140586960595e-05\n",
      "Epoch 1783, Loss: 0.0012306862627156079, Final Batch Loss: 0.00044003583025187254\n",
      "Epoch 1784, Loss: 0.002455738591379486, Final Batch Loss: 0.0023030228912830353\n",
      "Epoch 1785, Loss: 3.9580967495567165e-05, Final Batch Loss: 1.821050864236895e-05\n",
      "Epoch 1786, Loss: 0.00017720689356792718, Final Batch Loss: 4.669591726269573e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1787, Loss: 0.0011783341687987559, Final Batch Loss: 6.112344999564812e-05\n",
      "Epoch 1788, Loss: 0.00020389943529153243, Final Batch Loss: 0.00017291141557507217\n",
      "Epoch 1789, Loss: 1.1655632988549769e-05, Final Batch Loss: 6.105827651481377e-06\n",
      "Epoch 1790, Loss: 0.00011659308620437514, Final Batch Loss: 2.236309774161782e-05\n",
      "Epoch 1791, Loss: 4.0054344935924746e-05, Final Batch Loss: 1.283513120142743e-05\n",
      "Epoch 1792, Loss: 0.00026822752988664433, Final Batch Loss: 0.00024636503076180816\n",
      "Epoch 1793, Loss: 0.0006650502546108328, Final Batch Loss: 6.69817891321145e-05\n",
      "Epoch 1794, Loss: 0.00035118732193950564, Final Batch Loss: 0.00010578332876320928\n",
      "Epoch 1795, Loss: 0.0005142816517036408, Final Batch Loss: 0.00041160700493492186\n",
      "Epoch 1796, Loss: 0.0010013503479058272, Final Batch Loss: 0.000987931853160262\n",
      "Epoch 1797, Loss: 5.2010112995048985e-05, Final Batch Loss: 2.582066008471884e-05\n",
      "Epoch 1798, Loss: 5.02708289786824e-05, Final Batch Loss: 1.1510100193845574e-05\n",
      "Epoch 1799, Loss: 5.20539288118016e-05, Final Batch Loss: 1.5598190657328814e-05\n",
      "Epoch 1800, Loss: 6.522207740999875e-05, Final Batch Loss: 6.104497151682153e-05\n",
      "Epoch 1801, Loss: 0.0005734399483117159, Final Batch Loss: 1.9081226128037088e-06\n",
      "Epoch 1802, Loss: 0.0013660097120009596, Final Batch Loss: 0.0013452976709231734\n",
      "Epoch 1803, Loss: 0.0007326151392135216, Final Batch Loss: 2.6843774776352802e-06\n",
      "Epoch 1804, Loss: 0.001059814661857672, Final Batch Loss: 0.0010248428443446755\n",
      "Epoch 1805, Loss: 0.00012888432320323773, Final Batch Loss: 1.0695544915506616e-05\n",
      "Epoch 1806, Loss: 0.0003432309167692438, Final Batch Loss: 0.00027693991432897747\n",
      "Epoch 1807, Loss: 7.317340555346163e-05, Final Batch Loss: 7.041906792437658e-05\n",
      "Epoch 1808, Loss: 0.0002162284145015292, Final Batch Loss: 8.197307033697143e-05\n",
      "Epoch 1809, Loss: 0.0007919541385490447, Final Batch Loss: 0.0006729894084855914\n",
      "Epoch 1810, Loss: 0.00043502006883500144, Final Batch Loss: 4.919635102851316e-05\n",
      "Epoch 1811, Loss: 9.689240005172906e-05, Final Batch Loss: 7.438044576701941e-06\n",
      "Epoch 1812, Loss: 0.0008146010477503296, Final Batch Loss: 1.8771297618513927e-05\n",
      "Epoch 1813, Loss: 0.00024310056687681936, Final Batch Loss: 0.00020878860959783196\n",
      "Epoch 1814, Loss: 0.016579564193307306, Final Batch Loss: 1.3238732208264992e-06\n",
      "Epoch 1815, Loss: 0.0005614432329821284, Final Batch Loss: 0.0005521036800928414\n",
      "Epoch 1816, Loss: 2.420415444248647e-05, Final Batch Loss: 2.923804686361109e-06\n",
      "Epoch 1817, Loss: 7.791207826812752e-05, Final Batch Loss: 3.9216036384459585e-05\n",
      "Epoch 1818, Loss: 0.00026654613202481414, Final Batch Loss: 3.958829893235816e-06\n",
      "Epoch 1819, Loss: 0.0005684304705937393, Final Batch Loss: 1.2932061508763582e-05\n",
      "Epoch 1820, Loss: 0.00012287567733437754, Final Batch Loss: 4.032904325868003e-05\n",
      "Epoch 1821, Loss: 0.003402373054996133, Final Batch Loss: 0.002305119065567851\n",
      "Epoch 1822, Loss: 0.0001378877968818415, Final Batch Loss: 2.6764140784507617e-05\n",
      "Epoch 1823, Loss: 0.021493464228115045, Final Batch Loss: 0.02145126461982727\n",
      "Epoch 1824, Loss: 9.432877413928509e-05, Final Batch Loss: 7.911171269370243e-05\n",
      "Epoch 1825, Loss: 0.0007504106524720555, Final Batch Loss: 6.613545338041149e-06\n",
      "Epoch 1826, Loss: 0.0014576088869944215, Final Batch Loss: 0.0005872062174603343\n",
      "Epoch 1827, Loss: 5.209754453971982e-05, Final Batch Loss: 3.4067590604536235e-05\n",
      "Epoch 1828, Loss: 0.001117077545131906, Final Batch Loss: 0.00109194777905941\n",
      "Epoch 1829, Loss: 0.0001999989544856362, Final Batch Loss: 0.00011462028487585485\n",
      "Epoch 1830, Loss: 7.471636126865633e-05, Final Batch Loss: 4.1257568227592856e-05\n",
      "Epoch 1831, Loss: 0.0001966520503628999, Final Batch Loss: 6.42593513475731e-05\n",
      "Epoch 1832, Loss: 3.70215238945093e-05, Final Batch Loss: 8.717601303942502e-06\n",
      "Epoch 1833, Loss: 6.591210876649711e-05, Final Batch Loss: 4.430319677339867e-05\n",
      "Epoch 1834, Loss: 0.00022444502246798947, Final Batch Loss: 0.00016033023712225258\n",
      "Epoch 1835, Loss: 0.0012081096647307277, Final Batch Loss: 0.0007173854392021894\n",
      "Epoch 1836, Loss: 0.0001705824543023482, Final Batch Loss: 7.899814954726025e-05\n",
      "Epoch 1837, Loss: 0.0010129642751053325, Final Batch Loss: 7.338107934629079e-06\n",
      "Epoch 1838, Loss: 5.456240614876151e-05, Final Batch Loss: 4.948731293552555e-05\n",
      "Epoch 1839, Loss: 0.0007059322815621272, Final Batch Loss: 0.0005007302388548851\n",
      "Epoch 1840, Loss: 6.456601113313809e-05, Final Batch Loss: 1.3209417375037447e-05\n",
      "Epoch 1841, Loss: 0.0001922221781569533, Final Batch Loss: 0.0001257969270227477\n",
      "Epoch 1842, Loss: 0.0003735720622444205, Final Batch Loss: 3.803792651524418e-06\n",
      "Epoch 1843, Loss: 0.0001404113572789356, Final Batch Loss: 3.4437005524523556e-05\n",
      "Epoch 1844, Loss: 0.00012703326501650736, Final Batch Loss: 3.272183676017448e-05\n",
      "Epoch 1845, Loss: 0.00041702766884554876, Final Batch Loss: 0.0004028339753858745\n",
      "Epoch 1846, Loss: 0.00031582271549268626, Final Batch Loss: 5.165827678865753e-05\n",
      "Epoch 1847, Loss: 6.391344362555174e-05, Final Batch Loss: 2.8039215749231516e-07\n",
      "Epoch 1848, Loss: 7.794561724949745e-05, Final Batch Loss: 5.293979938869597e-06\n",
      "Epoch 1849, Loss: 3.660505717562046e-05, Final Batch Loss: 1.8082200767821632e-05\n",
      "Epoch 1850, Loss: 0.0001131619319494348, Final Batch Loss: 3.3877742680488154e-05\n",
      "Epoch 1851, Loss: 0.0003369337118783733, Final Batch Loss: 0.0003066208737436682\n",
      "Epoch 1852, Loss: 0.00046624577953480184, Final Batch Loss: 0.0001962816168088466\n",
      "Epoch 1853, Loss: 0.002746651938650757, Final Batch Loss: 0.00016273959772661328\n",
      "Epoch 1854, Loss: 5.443251757242251e-05, Final Batch Loss: 3.638999260147102e-05\n",
      "Epoch 1855, Loss: 0.00033017212444974575, Final Batch Loss: 1.0171026588068344e-05\n",
      "Epoch 1856, Loss: 8.037063071242301e-05, Final Batch Loss: 6.675066106254235e-05\n",
      "Epoch 1857, Loss: 0.000578603036046843, Final Batch Loss: 2.7481726647238247e-05\n",
      "Epoch 1858, Loss: 4.336518941272516e-05, Final Batch Loss: 2.5657818696345203e-05\n",
      "Epoch 1859, Loss: 0.005785837154689943, Final Batch Loss: 5.5210515711223707e-05\n",
      "Epoch 1860, Loss: 3.203005235263845e-05, Final Batch Loss: 9.354203029943164e-06\n",
      "Epoch 1861, Loss: 5.4223137340159155e-05, Final Batch Loss: 1.6969623175100423e-05\n",
      "Epoch 1862, Loss: 0.00013901459533371963, Final Batch Loss: 4.303759851609357e-05\n",
      "Epoch 1863, Loss: 0.0004367020483186934, Final Batch Loss: 0.0004224170988891274\n",
      "Epoch 1864, Loss: 0.0043206708069192246, Final Batch Loss: 0.004167448729276657\n",
      "Epoch 1865, Loss: 0.00026704936499299947, Final Batch Loss: 0.00025315157836303115\n",
      "Epoch 1866, Loss: 0.0001968231845239643, Final Batch Loss: 0.0001459526247344911\n",
      "Epoch 1867, Loss: 7.704869494773448e-05, Final Batch Loss: 1.6384783521061763e-05\n",
      "Epoch 1868, Loss: 0.015930346911773086, Final Batch Loss: 0.013341676443815231\n",
      "Epoch 1869, Loss: 1.8457351870893035e-05, Final Batch Loss: 1.0410969480290078e-05\n",
      "Epoch 1870, Loss: 1.2892259292129893e-05, Final Batch Loss: 3.25117252941709e-06\n",
      "Epoch 1871, Loss: 0.00013154474800103344, Final Batch Loss: 3.6527486372506246e-05\n",
      "Epoch 1872, Loss: 0.00011865966735058464, Final Batch Loss: 4.32071065006312e-05\n",
      "Epoch 1873, Loss: 9.845791282714345e-05, Final Batch Loss: 3.613313674577512e-05\n",
      "Epoch 1874, Loss: 0.00012675296966335736, Final Batch Loss: 5.433180558611639e-05\n",
      "Epoch 1875, Loss: 0.0013741237635258585, Final Batch Loss: 0.0010769566288217902\n",
      "Epoch 1876, Loss: 0.00012087107461411506, Final Batch Loss: 5.684379721060395e-05\n",
      "Epoch 1877, Loss: 4.751457618112909e-05, Final Batch Loss: 3.992984056822024e-05\n",
      "Epoch 1878, Loss: 0.0002815579791786149, Final Batch Loss: 0.0001778961013769731\n",
      "Epoch 1879, Loss: 0.00017653781833359972, Final Batch Loss: 3.172182914568111e-05\n",
      "Epoch 1880, Loss: 3.7298992538126186e-05, Final Batch Loss: 1.1434858606662601e-05\n",
      "Epoch 1881, Loss: 9.298481927544344e-05, Final Batch Loss: 2.1331015886971727e-06\n",
      "Epoch 1882, Loss: 0.0001310910338361282, Final Batch Loss: 1.5878013073233888e-05\n",
      "Epoch 1883, Loss: 0.0004353404237917857, Final Batch Loss: 1.3931772627984174e-05\n",
      "Epoch 1884, Loss: 0.0022720164588463376, Final Batch Loss: 0.002261360874399543\n",
      "Epoch 1885, Loss: 0.0005220116581767797, Final Batch Loss: 0.00025303676375187933\n",
      "Epoch 1886, Loss: 0.0011883798792950984, Final Batch Loss: 0.0011858191573992372\n",
      "Epoch 1887, Loss: 0.00015468969286303036, Final Batch Loss: 5.9987734857713804e-05\n",
      "Epoch 1888, Loss: 0.001904593199469673, Final Batch Loss: 0.0018981945468112826\n",
      "Epoch 1889, Loss: 0.0006942760555830318, Final Batch Loss: 1.3805158232571557e-05\n",
      "Epoch 1890, Loss: 0.00036828930024057627, Final Batch Loss: 3.945565549656749e-05\n",
      "Epoch 1891, Loss: 0.004574490121740382, Final Batch Loss: 9.23316620173864e-05\n",
      "Epoch 1892, Loss: 0.00010627400843077339, Final Batch Loss: 5.0042806833516806e-05\n",
      "Epoch 1893, Loss: 0.00021329813898773864, Final Batch Loss: 0.00020923760894220322\n",
      "Epoch 1894, Loss: 0.0011598714281717548, Final Batch Loss: 0.001144101144745946\n",
      "Epoch 1895, Loss: 1.3799418638882344e-05, Final Batch Loss: 3.6597878079192014e-06\n",
      "Epoch 1896, Loss: 0.009048829015227966, Final Batch Loss: 0.0002318901679245755\n",
      "Epoch 1897, Loss: 0.00014065011055208743, Final Batch Loss: 4.835802246816456e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1898, Loss: 0.00022506988170789555, Final Batch Loss: 3.676454798551276e-05\n",
      "Epoch 1899, Loss: 0.0007990176727616927, Final Batch Loss: 1.6002164556994103e-05\n",
      "Epoch 1900, Loss: 3.3806489227572456e-05, Final Batch Loss: 8.258275556727313e-06\n",
      "Epoch 1901, Loss: 4.251535028743092e-05, Final Batch Loss: 1.715796497592237e-05\n",
      "Epoch 1902, Loss: 0.0010380223684478551, Final Batch Loss: 0.0009747705771587789\n",
      "Epoch 1903, Loss: 0.00020559853874146938, Final Batch Loss: 0.00013984819815959781\n",
      "Epoch 1904, Loss: 6.163726425256755e-06, Final Batch Loss: 3.1397246402775636e-07\n",
      "Epoch 1905, Loss: 0.0006729230008204468, Final Batch Loss: 0.0006127041997388005\n",
      "Epoch 1906, Loss: 3.488360152914538e-05, Final Batch Loss: 2.8406528144842014e-05\n",
      "Epoch 1907, Loss: 0.000481030432638363, Final Batch Loss: 0.0004600532993208617\n",
      "Epoch 1908, Loss: 0.0006581236120837275, Final Batch Loss: 0.0006480723968707025\n",
      "Epoch 1909, Loss: 8.640442683827132e-05, Final Batch Loss: 3.313815614092164e-05\n",
      "Epoch 1910, Loss: 0.00012675318953370152, Final Batch Loss: 2.0054701508342987e-06\n",
      "Epoch 1911, Loss: 0.00035693392521807255, Final Batch Loss: 1.6025234117478249e-06\n",
      "Epoch 1912, Loss: 0.00040041811371338554, Final Batch Loss: 4.520774382399395e-06\n",
      "Epoch 1913, Loss: 6.951218551876082e-05, Final Batch Loss: 6.645734538324177e-05\n",
      "Epoch 1914, Loss: 9.402579962625168e-05, Final Batch Loss: 2.6590034394757822e-05\n",
      "Epoch 1915, Loss: 0.0025844942647381686, Final Batch Loss: 0.0025179563090205193\n",
      "Epoch 1916, Loss: 9.796827771424432e-05, Final Batch Loss: 4.778110906045185e-06\n",
      "Epoch 1917, Loss: 0.0001456391764804721, Final Batch Loss: 2.6505091227591038e-05\n",
      "Epoch 1918, Loss: 0.00018218010154669173, Final Batch Loss: 0.00014547065075021237\n",
      "Epoch 1919, Loss: 0.0010762312158476561, Final Batch Loss: 2.632426912896335e-05\n",
      "Epoch 1920, Loss: 2.663672603375744e-05, Final Batch Loss: 1.6893598512979224e-05\n",
      "Epoch 1921, Loss: 0.0010967472408083268, Final Batch Loss: 7.553499017376453e-06\n",
      "Epoch 1922, Loss: 3.16150171784102e-05, Final Batch Loss: 1.1977263966400642e-05\n",
      "Epoch 1923, Loss: 0.0007082217180141015, Final Batch Loss: 2.381109334237408e-05\n",
      "Epoch 1924, Loss: 0.00012422298880210292, Final Batch Loss: 1.1668859087876626e-06\n",
      "Epoch 1925, Loss: 4.197914563519589e-05, Final Batch Loss: 3.9865990402176976e-05\n",
      "Epoch 1926, Loss: 0.0014257992670536623, Final Batch Loss: 1.151294509327272e-05\n",
      "Epoch 1927, Loss: 8.183888621715596e-05, Final Batch Loss: 7.480149179173168e-06\n",
      "Epoch 1928, Loss: 2.3814342057448812e-05, Final Batch Loss: 2.0150675482000224e-05\n",
      "Epoch 1929, Loss: 0.0011648974032141268, Final Batch Loss: 0.0006875791004858911\n",
      "Epoch 1930, Loss: 0.00034848095674533397, Final Batch Loss: 0.00018806607113219798\n",
      "Epoch 1931, Loss: 6.172525900183246e-05, Final Batch Loss: 5.1622420869534835e-05\n",
      "Epoch 1932, Loss: 5.100925682199886e-05, Final Batch Loss: 5.718596185033675e-06\n",
      "Epoch 1933, Loss: 0.00015548263399978168, Final Batch Loss: 2.1772782929474488e-05\n",
      "Epoch 1934, Loss: 0.0005163902393405806, Final Batch Loss: 9.855581311057904e-07\n",
      "Epoch 1935, Loss: 0.00026337484905525343, Final Batch Loss: 0.00025349773932248354\n",
      "Epoch 1936, Loss: 0.0001061096518242266, Final Batch Loss: 3.2900450605666265e-05\n",
      "Epoch 1937, Loss: 4.763219521919382e-05, Final Batch Loss: 4.4104657717980444e-05\n",
      "Epoch 1938, Loss: 3.435327380429953e-05, Final Batch Loss: 1.7072630726033822e-05\n",
      "Epoch 1939, Loss: 0.00022753866414859658, Final Batch Loss: 1.472994244977599e-05\n",
      "Epoch 1940, Loss: 0.000312198608298786, Final Batch Loss: 6.208782724570483e-05\n",
      "Epoch 1941, Loss: 0.00017057062723324634, Final Batch Loss: 3.378375913598575e-05\n",
      "Epoch 1942, Loss: 9.336531002190895e-05, Final Batch Loss: 8.072610944509506e-05\n",
      "Epoch 1943, Loss: 0.0007924009405542165, Final Batch Loss: 0.0002605557383503765\n",
      "Epoch 1944, Loss: 4.4018839616910554e-05, Final Batch Loss: 2.1871748685953207e-05\n",
      "Epoch 1945, Loss: 3.4457811125321314e-05, Final Batch Loss: 5.15404281031806e-06\n",
      "Epoch 1946, Loss: 0.00010071361975860782, Final Batch Loss: 8.977572724688798e-05\n",
      "Epoch 1947, Loss: 0.0001532220030640019, Final Batch Loss: 2.2935839297133498e-05\n",
      "Epoch 1948, Loss: 0.0006577008098247461, Final Batch Loss: 0.0005546991596929729\n",
      "Epoch 1949, Loss: 0.00012363658561298507, Final Batch Loss: 0.000117949974082876\n",
      "Epoch 1950, Loss: 4.231029288348509e-05, Final Batch Loss: 1.3060490346106235e-05\n",
      "Epoch 1951, Loss: 9.734529703564476e-05, Final Batch Loss: 2.6065374186146073e-05\n",
      "Epoch 1952, Loss: 0.00014772814392927103, Final Batch Loss: 8.777046605246142e-05\n",
      "Epoch 1953, Loss: 0.0009388098242197884, Final Batch Loss: 0.0009116489673033357\n",
      "Epoch 1954, Loss: 0.0003206702967872843, Final Batch Loss: 0.00018362169794272631\n",
      "Epoch 1955, Loss: 0.005064388096798211, Final Batch Loss: 0.0047216578386723995\n",
      "Epoch 1956, Loss: 3.16515443046228e-05, Final Batch Loss: 7.425195690302644e-06\n",
      "Epoch 1957, Loss: 0.0002653973533597309, Final Batch Loss: 0.00022223677660804242\n",
      "Epoch 1958, Loss: 0.000330654154822696, Final Batch Loss: 0.0002653145929798484\n",
      "Epoch 1959, Loss: 7.50209092075238e-05, Final Batch Loss: 8.06892967375461e-06\n",
      "Epoch 1960, Loss: 0.0007128898723749444, Final Batch Loss: 0.0006890101358294487\n",
      "Epoch 1961, Loss: 0.0005426658608485013, Final Batch Loss: 0.000378707074560225\n",
      "Epoch 1962, Loss: 0.00011964647546847118, Final Batch Loss: 0.00011689580423990265\n",
      "Epoch 1963, Loss: 8.158806394931162e-05, Final Batch Loss: 1.1128432561235968e-05\n",
      "Epoch 1964, Loss: 7.325049864448374e-06, Final Batch Loss: 3.961789388995385e-06\n",
      "Epoch 1965, Loss: 4.349641119461012e-05, Final Batch Loss: 1.5664789998481865e-06\n",
      "Epoch 1966, Loss: 2.65343123828643e-05, Final Batch Loss: 8.921432709030341e-06\n",
      "Epoch 1967, Loss: 0.0004358526930445805, Final Batch Loss: 2.1050902432762086e-05\n",
      "Epoch 1968, Loss: 0.00031719756680104183, Final Batch Loss: 7.75542594055878e-06\n",
      "Epoch 1969, Loss: 0.003412192928863078, Final Batch Loss: 2.149733973055845e-06\n",
      "Epoch 1970, Loss: 8.665071391078527e-05, Final Batch Loss: 1.451454863854451e-06\n",
      "Epoch 1971, Loss: 0.000217774162592832, Final Batch Loss: 6.717157521052286e-05\n",
      "Epoch 1972, Loss: 0.00012662354720305302, Final Batch Loss: 2.9111965886841062e-06\n",
      "Epoch 1973, Loss: 4.934400385536719e-05, Final Batch Loss: 3.211691728211008e-05\n",
      "Epoch 1974, Loss: 9.107838695854298e-05, Final Batch Loss: 5.2085101742704865e-06\n",
      "Epoch 1975, Loss: 0.00010374903649790213, Final Batch Loss: 7.821308099664748e-05\n",
      "Epoch 1976, Loss: 0.0020870252010354307, Final Batch Loss: 0.0020427408162504435\n",
      "Epoch 1977, Loss: 6.592437762265035e-05, Final Batch Loss: 3.4853399029088905e-06\n",
      "Epoch 1978, Loss: 3.3841022741398774e-05, Final Batch Loss: 1.2018685083603486e-05\n",
      "Epoch 1979, Loss: 8.149780796884443e-05, Final Batch Loss: 2.691365352802677e-06\n",
      "Epoch 1980, Loss: 1.8859092392631283e-05, Final Batch Loss: 1.7000485968310386e-05\n",
      "Epoch 1981, Loss: 0.00014065817595110275, Final Batch Loss: 0.0001003975557978265\n",
      "Epoch 1982, Loss: 7.001319772825809e-06, Final Batch Loss: 2.0724410205730237e-06\n",
      "Epoch 1983, Loss: 0.00011544421613507438, Final Batch Loss: 0.00010737862612586468\n",
      "Epoch 1984, Loss: 0.0002159625328204129, Final Batch Loss: 0.00016896877787075937\n",
      "Epoch 1985, Loss: 7.963803000166081e-05, Final Batch Loss: 3.367149838595651e-05\n",
      "Epoch 1986, Loss: 0.00031055291765369475, Final Batch Loss: 7.064511009957641e-05\n",
      "Epoch 1987, Loss: 5.271441114018671e-05, Final Batch Loss: 3.936981738661416e-05\n",
      "Epoch 1988, Loss: 0.0017275212476306478, Final Batch Loss: 9.580343430570792e-06\n",
      "Epoch 1989, Loss: 4.8579855047137244e-05, Final Batch Loss: 7.372618256340502e-06\n",
      "Epoch 1990, Loss: 0.000331105591612868, Final Batch Loss: 9.555606811773032e-05\n",
      "Epoch 1991, Loss: 2.958568529720651e-05, Final Batch Loss: 1.4396928236237727e-06\n",
      "Epoch 1992, Loss: 5.316954957379494e-05, Final Batch Loss: 5.065146979177371e-05\n",
      "Epoch 1993, Loss: 8.275865548057482e-05, Final Batch Loss: 3.6852721677860245e-05\n",
      "Epoch 1994, Loss: 4.473078115552198e-05, Final Batch Loss: 9.020737707032822e-06\n",
      "Epoch 1995, Loss: 0.00024229943437603652, Final Batch Loss: 0.0002394402545178309\n",
      "Epoch 1996, Loss: 3.6686631574411876e-05, Final Batch Loss: 9.431470971321687e-06\n",
      "Epoch 1997, Loss: 0.00027418781974120066, Final Batch Loss: 3.7394762330222875e-05\n",
      "Epoch 1998, Loss: 0.00012133738891861867, Final Batch Loss: 0.00011370228457963094\n",
      "Epoch 1999, Loss: 8.915156286093406e-05, Final Batch Loss: 6.995074363658205e-05\n",
      "Epoch 2000, Loss: 0.0017065053834812716, Final Batch Loss: 0.00018424222071189433\n",
      "Epoch 2001, Loss: 0.00015324911510106176, Final Batch Loss: 6.24368985882029e-05\n",
      "Epoch 2002, Loss: 0.0001290347245230805, Final Batch Loss: 5.852612594026141e-05\n",
      "Epoch 2003, Loss: 0.0003362935567565728, Final Batch Loss: 4.2557967390166596e-05\n",
      "Epoch 2004, Loss: 8.500357103002898e-05, Final Batch Loss: 1.939128878802876e-06\n",
      "Epoch 2005, Loss: 0.0021055981051176786, Final Batch Loss: 0.0005379524081945419\n",
      "Epoch 2006, Loss: 4.443415519972405e-06, Final Batch Loss: 3.8532837720595126e-07\n",
      "Epoch 2007, Loss: 5.668927678925684e-05, Final Batch Loss: 9.128324563789647e-06\n",
      "Epoch 2008, Loss: 2.1314985588105628e-05, Final Batch Loss: 1.7301683328696527e-05\n",
      "Epoch 2009, Loss: 7.420917472700239e-05, Final Batch Loss: 2.8311646929068957e-06\n",
      "Epoch 2010, Loss: 0.002835849851180683, Final Batch Loss: 0.0028309945482760668\n",
      "Epoch 2011, Loss: 0.0014113122451817617, Final Batch Loss: 7.596668729092926e-05\n",
      "Epoch 2012, Loss: 0.001925424236105755, Final Batch Loss: 0.00019807930220849812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2013, Loss: 0.0002819106418883166, Final Batch Loss: 2.715675464060041e-06\n",
      "Epoch 2014, Loss: 2.7846523266816803e-05, Final Batch Loss: 1.4816724842603435e-06\n",
      "Epoch 2015, Loss: 0.0008713955412531504, Final Batch Loss: 0.0008604914764873683\n",
      "Epoch 2016, Loss: 5.958319889032282e-05, Final Batch Loss: 9.214807505486533e-06\n",
      "Epoch 2017, Loss: 6.926116157046636e-06, Final Batch Loss: 1.9173655800841516e-06\n",
      "Epoch 2018, Loss: 0.00020764367218362167, Final Batch Loss: 9.173667058348656e-05\n",
      "Epoch 2019, Loss: 2.7231406420469284e-05, Final Batch Loss: 4.060924766235985e-06\n",
      "Epoch 2020, Loss: 0.0003759400133276358, Final Batch Loss: 0.00034852197859436274\n",
      "Epoch 2021, Loss: 1.168777771454188e-05, Final Batch Loss: 9.916979252011515e-06\n",
      "Epoch 2022, Loss: 4.37990206592076e-05, Final Batch Loss: 3.9388571167364717e-05\n",
      "Epoch 2023, Loss: 7.723198928033526e-05, Final Batch Loss: 1.5186071777861798e-06\n",
      "Epoch 2024, Loss: 0.0001189054182759719, Final Batch Loss: 0.00011293080024188384\n",
      "Epoch 2025, Loss: 9.576996762916679e-05, Final Batch Loss: 1.3921330719313119e-05\n",
      "Epoch 2026, Loss: 6.703574172206572e-06, Final Batch Loss: 1.2793741461791797e-06\n",
      "Epoch 2027, Loss: 0.00030338335045598797, Final Batch Loss: 5.632043666992104e-06\n",
      "Epoch 2028, Loss: 0.0006834848786638759, Final Batch Loss: 2.2110648387752008e-06\n",
      "Epoch 2029, Loss: 4.6150580601533875e-05, Final Batch Loss: 2.162416603823658e-05\n",
      "Epoch 2030, Loss: 0.00037780545244459063, Final Batch Loss: 0.00031815256807021797\n",
      "Epoch 2031, Loss: 0.0001923264846936945, Final Batch Loss: 0.00018863932928070426\n",
      "Epoch 2032, Loss: 0.0005127089971210808, Final Batch Loss: 0.0002682125777937472\n",
      "Epoch 2033, Loss: 0.00011299260950181633, Final Batch Loss: 2.976836549350992e-05\n",
      "Epoch 2034, Loss: 2.2127032025309745e-05, Final Batch Loss: 1.1021538739441894e-05\n",
      "Epoch 2035, Loss: 0.03323614665896457, Final Batch Loss: 0.0332132987678051\n",
      "Epoch 2036, Loss: 0.00012155342756159371, Final Batch Loss: 0.00011914998322026804\n",
      "Epoch 2037, Loss: 0.00010992259194608778, Final Batch Loss: 5.654364940710366e-06\n",
      "Epoch 2038, Loss: 0.017840343116404256, Final Batch Loss: 0.017808707430958748\n",
      "Epoch 2039, Loss: 0.0005282376032482716, Final Batch Loss: 5.0650514822336845e-06\n",
      "Epoch 2040, Loss: 0.000599126738961786, Final Batch Loss: 0.0004056676698382944\n",
      "Epoch 2041, Loss: 4.696670134762826e-05, Final Batch Loss: 1.260026920135715e-06\n",
      "Epoch 2042, Loss: 7.091154293448199e-05, Final Batch Loss: 6.2200975662563e-05\n",
      "Epoch 2043, Loss: 0.0011489590742712608, Final Batch Loss: 1.4493392882286571e-05\n",
      "Epoch 2044, Loss: 3.2667287086951546e-05, Final Batch Loss: 1.5687362974858843e-05\n",
      "Epoch 2045, Loss: 0.0003248286448069848, Final Batch Loss: 0.0002507475146558136\n",
      "Epoch 2046, Loss: 0.00013095577560306992, Final Batch Loss: 0.00011326425010338426\n",
      "Epoch 2047, Loss: 0.010127694862603676, Final Batch Loss: 0.010094517841935158\n",
      "Epoch 2048, Loss: 0.00038084990228526294, Final Batch Loss: 0.0001984906557481736\n",
      "Epoch 2049, Loss: 6.932555334060453e-05, Final Batch Loss: 2.120198041666299e-05\n",
      "Epoch 2050, Loss: 0.0008236370485974476, Final Batch Loss: 0.0007622767006978393\n",
      "Epoch 2051, Loss: 0.00033166050707222894, Final Batch Loss: 0.0002839627268258482\n",
      "Epoch 2052, Loss: 0.002389357610809384, Final Batch Loss: 3.468496652203612e-05\n",
      "Epoch 2053, Loss: 0.0001379214481858071, Final Batch Loss: 3.679291330627166e-05\n",
      "Epoch 2054, Loss: 5.663746765094402e-05, Final Batch Loss: 1.7561853837833041e-06\n",
      "Epoch 2055, Loss: 4.235549931763671e-05, Final Batch Loss: 2.5543196898070164e-05\n",
      "Epoch 2056, Loss: 0.0010085885041917209, Final Batch Loss: 0.0009512911783531308\n",
      "Epoch 2057, Loss: 0.00035637806649901904, Final Batch Loss: 0.00030071911169216037\n",
      "Epoch 2058, Loss: 0.00038082727769506164, Final Batch Loss: 1.0549923899816349e-05\n",
      "Epoch 2059, Loss: 0.0001998057559831068, Final Batch Loss: 7.675947563257068e-05\n",
      "Epoch 2060, Loss: 0.0005064083306933753, Final Batch Loss: 0.00047580909449607134\n",
      "Epoch 2061, Loss: 7.373295193247031e-05, Final Batch Loss: 2.9388729672064073e-05\n",
      "Epoch 2062, Loss: 0.0002630459412102937, Final Batch Loss: 5.769447852799203e-06\n",
      "Epoch 2063, Loss: 9.17190991458483e-05, Final Batch Loss: 5.6442004279233515e-05\n",
      "Epoch 2064, Loss: 0.0005063409844296984, Final Batch Loss: 5.689757381333038e-05\n",
      "Epoch 2065, Loss: 0.00028190103876113426, Final Batch Loss: 0.00025538154295645654\n",
      "Epoch 2066, Loss: 0.00017643802129896358, Final Batch Loss: 0.00015118428564164788\n",
      "Epoch 2067, Loss: 0.00010460783232701942, Final Batch Loss: 5.8849775086855516e-05\n",
      "Epoch 2068, Loss: 0.0001520251862530131, Final Batch Loss: 1.9758099369937554e-05\n",
      "Epoch 2069, Loss: 4.419873778260808e-05, Final Batch Loss: 1.1534522172951256e-06\n",
      "Epoch 2070, Loss: 0.00038488082645926625, Final Batch Loss: 0.0001741567102726549\n",
      "Epoch 2071, Loss: 0.00036349149922898505, Final Batch Loss: 0.00034714440698735416\n",
      "Epoch 2072, Loss: 0.0002680901234271005, Final Batch Loss: 0.00021235823805909604\n",
      "Epoch 2073, Loss: 9.193202822643798e-05, Final Batch Loss: 2.6557636374491267e-05\n",
      "Epoch 2074, Loss: 0.00013136325105733704, Final Batch Loss: 0.00010247546015307307\n",
      "Epoch 2075, Loss: 0.00018497064229450189, Final Batch Loss: 1.4247470971895382e-05\n",
      "Epoch 2076, Loss: 4.900078783975914e-05, Final Batch Loss: 1.3161414244677871e-05\n",
      "Epoch 2077, Loss: 9.689124681244721e-05, Final Batch Loss: 3.94624339605798e-06\n",
      "Epoch 2078, Loss: 8.1582590155449e-05, Final Batch Loss: 7.548256689915434e-05\n",
      "Epoch 2079, Loss: 9.090037019632291e-05, Final Batch Loss: 7.073694723658264e-05\n",
      "Epoch 2080, Loss: 0.00013249106268631294, Final Batch Loss: 2.4566557840444148e-05\n",
      "Epoch 2081, Loss: 5.608820811175974e-05, Final Batch Loss: 3.975154868385289e-06\n",
      "Epoch 2082, Loss: 6.598841355298646e-05, Final Batch Loss: 2.821554517140612e-05\n",
      "Epoch 2083, Loss: 7.585500043205684e-06, Final Batch Loss: 4.869172244070796e-06\n",
      "Epoch 2084, Loss: 0.0002923324645962566, Final Batch Loss: 9.736123320180923e-05\n",
      "Epoch 2085, Loss: 2.6773085210152203e-05, Final Batch Loss: 7.070723313518101e-06\n",
      "Epoch 2086, Loss: 4.0850280129234307e-05, Final Batch Loss: 3.191388168488629e-05\n",
      "Epoch 2087, Loss: 2.118811835316592e-05, Final Batch Loss: 3.2856282814464066e-06\n",
      "Epoch 2088, Loss: 0.0004962810417055152, Final Batch Loss: 0.00042912777280434966\n",
      "Epoch 2089, Loss: 0.00030479760998503025, Final Batch Loss: 1.292831228738578e-07\n",
      "Epoch 2090, Loss: 4.668991095968522e-05, Final Batch Loss: 4.187549711787142e-05\n",
      "Epoch 2091, Loss: 0.012709057562233284, Final Batch Loss: 0.012707659043371677\n",
      "Epoch 2092, Loss: 2.3630441660316137e-05, Final Batch Loss: 1.1811565627795062e-06\n",
      "Epoch 2093, Loss: 8.49801695608221e-05, Final Batch Loss: 6.228988809198199e-07\n",
      "Epoch 2094, Loss: 0.00011988222104264423, Final Batch Loss: 0.00011014306073775515\n",
      "Epoch 2095, Loss: 0.0006096674246691691, Final Batch Loss: 0.0006042898749001324\n",
      "Epoch 2096, Loss: 0.00019349832655279897, Final Batch Loss: 2.1534429833991453e-05\n",
      "Epoch 2097, Loss: 0.0004063531268911902, Final Batch Loss: 0.0003819216217380017\n",
      "Epoch 2098, Loss: 0.00014041419490240514, Final Batch Loss: 3.557159652700648e-05\n",
      "Epoch 2099, Loss: 0.00027803370539913885, Final Batch Loss: 0.0002518180408515036\n",
      "Epoch 2100, Loss: 0.00022282966529019177, Final Batch Loss: 0.0001447762770112604\n",
      "Epoch 2101, Loss: 0.002044742652515197, Final Batch Loss: 3.4265269732713932e-06\n",
      "Epoch 2102, Loss: 1.0622334684740053e-05, Final Batch Loss: 2.779389888019068e-06\n",
      "Epoch 2103, Loss: 6.578060697393084e-05, Final Batch Loss: 3.2937225569185102e-06\n",
      "Epoch 2104, Loss: 0.0001812305890780408, Final Batch Loss: 0.00014013836334925145\n",
      "Epoch 2105, Loss: 3.830917421510094e-05, Final Batch Loss: 3.1449806556338444e-05\n",
      "Epoch 2106, Loss: 0.00011904925304406788, Final Batch Loss: 9.65835788520053e-05\n",
      "Epoch 2107, Loss: 9.62331032496877e-05, Final Batch Loss: 5.106428579892963e-05\n",
      "Epoch 2108, Loss: 0.0014044230338186026, Final Batch Loss: 0.0007614789647050202\n",
      "Epoch 2109, Loss: 0.0009202403734889231, Final Batch Loss: 4.534681465884205e-06\n",
      "Epoch 2110, Loss: 0.00015050575893837959, Final Batch Loss: 5.81819040235132e-06\n",
      "Epoch 2111, Loss: 0.00012073708126081328, Final Batch Loss: 3.256100853832322e-06\n",
      "Epoch 2112, Loss: 5.704022441932466e-05, Final Batch Loss: 3.719398591783829e-06\n",
      "Epoch 2113, Loss: 4.432796595210675e-05, Final Batch Loss: 2.5893779820762575e-05\n",
      "Epoch 2114, Loss: 1.9534200362159027e-05, Final Batch Loss: 5.800870326311269e-07\n",
      "Epoch 2115, Loss: 0.00027925139147555456, Final Batch Loss: 6.60675359540619e-05\n",
      "Epoch 2116, Loss: 0.004459792253328487, Final Batch Loss: 0.004185606259852648\n",
      "Epoch 2117, Loss: 0.002095185416692402, Final Batch Loss: 0.001976212253794074\n",
      "Epoch 2118, Loss: 0.00013666284576174803, Final Batch Loss: 3.670651858556084e-05\n",
      "Epoch 2119, Loss: 0.0001668921031523496, Final Batch Loss: 0.00011073114728787914\n",
      "Epoch 2120, Loss: 0.00015170012920862064, Final Batch Loss: 1.250384229933843e-05\n",
      "Epoch 2121, Loss: 0.0009030466317199171, Final Batch Loss: 0.0008722392958588898\n",
      "Epoch 2122, Loss: 0.0008637272840132937, Final Batch Loss: 0.0007307457271963358\n",
      "Epoch 2123, Loss: 0.0007848364875826519, Final Batch Loss: 0.0007529583526775241\n",
      "Epoch 2124, Loss: 3.238834301555471e-05, Final Batch Loss: 2.0373897768877214e-06\n",
      "Epoch 2125, Loss: 0.00010550674051046371, Final Batch Loss: 9.059465082827955e-05\n",
      "Epoch 2126, Loss: 0.000303348930174252, Final Batch Loss: 2.446764483465813e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2127, Loss: 4.419485162543424e-05, Final Batch Loss: 3.4313281958020525e-06\n",
      "Epoch 2128, Loss: 0.00028893847775179893, Final Batch Loss: 0.0002227443183073774\n",
      "Epoch 2129, Loss: 0.00027151515632795054, Final Batch Loss: 5.355882876756368e-06\n",
      "Epoch 2130, Loss: 4.708381629825453e-05, Final Batch Loss: 4.608247763826512e-05\n",
      "Epoch 2131, Loss: 0.0004164561250945553, Final Batch Loss: 0.0001246406027348712\n",
      "Epoch 2132, Loss: 0.00015265834372257814, Final Batch Loss: 0.00010829966777237132\n",
      "Epoch 2133, Loss: 0.0004922470998280915, Final Batch Loss: 8.086370144155808e-06\n",
      "Epoch 2134, Loss: 2.590869007690344e-05, Final Batch Loss: 1.8084581824950874e-05\n",
      "Epoch 2135, Loss: 0.0008651951571891914, Final Batch Loss: 0.0008634457481093705\n",
      "Epoch 2136, Loss: 0.00013005218124817475, Final Batch Loss: 7.5042021308036055e-06\n",
      "Epoch 2137, Loss: 0.0032922470127232373, Final Batch Loss: 5.84946246817708e-06\n",
      "Epoch 2138, Loss: 0.005960593285635696, Final Batch Loss: 0.005935189314186573\n",
      "Epoch 2139, Loss: 3.0080496799200773e-05, Final Batch Loss: 1.349480589851737e-05\n",
      "Epoch 2140, Loss: 0.0002686859806999564, Final Batch Loss: 0.00013679280527867377\n",
      "Epoch 2141, Loss: 0.0004820214307983406, Final Batch Loss: 6.505056080641225e-05\n",
      "Epoch 2142, Loss: 0.001505085874669021, Final Batch Loss: 2.1095063857501373e-05\n",
      "Epoch 2143, Loss: 3.5263580684841145e-05, Final Batch Loss: 6.580782610399183e-06\n",
      "Epoch 2144, Loss: 5.244987278274493e-05, Final Batch Loss: 7.376024768745992e-06\n",
      "Epoch 2145, Loss: 0.00437174309627153, Final Batch Loss: 0.004236542619764805\n",
      "Epoch 2146, Loss: 2.8291495084431517e-06, Final Batch Loss: 3.626637692377699e-07\n",
      "Epoch 2147, Loss: 0.003621045521867927, Final Batch Loss: 5.208656511968002e-05\n",
      "Epoch 2148, Loss: 8.321771019836888e-05, Final Batch Loss: 3.595728048821911e-05\n",
      "Epoch 2149, Loss: 0.00026800484829436755, Final Batch Loss: 0.0002549240889493376\n",
      "Epoch 2150, Loss: 8.68504612299148e-05, Final Batch Loss: 4.249197809258476e-05\n",
      "Epoch 2151, Loss: 9.654139648773707e-05, Final Batch Loss: 4.251997233950533e-05\n",
      "Epoch 2152, Loss: 5.367343328543939e-05, Final Batch Loss: 3.8992136978777125e-05\n",
      "Epoch 2153, Loss: 0.00012216083450766746, Final Batch Loss: 1.4538223695126362e-05\n",
      "Epoch 2154, Loss: 0.00022574801550945267, Final Batch Loss: 7.941612420836464e-05\n",
      "Epoch 2155, Loss: 2.4487875180057017e-05, Final Batch Loss: 7.047437520668609e-06\n",
      "Epoch 2156, Loss: 1.2884725947515108e-05, Final Batch Loss: 1.0686635505408049e-06\n",
      "Epoch 2157, Loss: 0.00013329686316865264, Final Batch Loss: 6.839730303909164e-06\n",
      "Epoch 2158, Loss: 0.004076269523920928, Final Batch Loss: 4.542128863249673e-06\n",
      "Epoch 2159, Loss: 0.0002734104564297013, Final Batch Loss: 0.0002479588147252798\n",
      "Epoch 2160, Loss: 0.00010091097601616639, Final Batch Loss: 9.444701572647318e-05\n",
      "Epoch 2161, Loss: 0.0001426387498213444, Final Batch Loss: 5.431777753983624e-05\n",
      "Epoch 2162, Loss: 5.064770220997161e-06, Final Batch Loss: 2.3990446607058402e-06\n",
      "Epoch 2163, Loss: 0.00018729964267549803, Final Batch Loss: 8.005742529348936e-06\n",
      "Epoch 2164, Loss: 0.0029130519251339138, Final Batch Loss: 0.0004992810427211225\n",
      "Epoch 2165, Loss: 0.00010934170313703362, Final Batch Loss: 0.00010128489520866424\n",
      "Epoch 2166, Loss: 9.4108243501978e-05, Final Batch Loss: 8.290475670946762e-05\n",
      "Epoch 2167, Loss: 0.0007656338530068751, Final Batch Loss: 5.2532264817273244e-05\n",
      "Epoch 2168, Loss: 0.0004101733784409589, Final Batch Loss: 1.4698975974170025e-05\n",
      "Epoch 2169, Loss: 0.01902501069707796, Final Batch Loss: 0.00022326939506456256\n",
      "Epoch 2170, Loss: 0.0006851640646345913, Final Batch Loss: 0.00018237490439787507\n",
      "Epoch 2171, Loss: 0.0040502741176169366, Final Batch Loss: 3.672271850518882e-05\n",
      "Epoch 2172, Loss: 0.0005046717096774955, Final Batch Loss: 0.0004968897555954754\n",
      "Epoch 2173, Loss: 1.4026605526851199e-05, Final Batch Loss: 1.533729914626747e-06\n",
      "Epoch 2174, Loss: 0.013596298500488047, Final Batch Loss: 7.233708311105147e-05\n",
      "Epoch 2175, Loss: 0.00016693305997250718, Final Batch Loss: 3.5164198379789013e-06\n",
      "Epoch 2176, Loss: 7.970274600666016e-05, Final Batch Loss: 1.6563593817409128e-05\n",
      "Epoch 2177, Loss: 0.00012797027687838636, Final Batch Loss: 8.579585824008973e-07\n",
      "Epoch 2178, Loss: 9.359899263472471e-05, Final Batch Loss: 9.167983080260456e-05\n",
      "Epoch 2179, Loss: 0.003524170668242732, Final Batch Loss: 3.3660271583357826e-05\n",
      "Epoch 2180, Loss: 0.0005306212497089291, Final Batch Loss: 1.7401916920789517e-05\n",
      "Epoch 2181, Loss: 2.600039715616731e-05, Final Batch Loss: 2.317530925211031e-05\n",
      "Epoch 2182, Loss: 0.0006771015378035372, Final Batch Loss: 0.0006637304904870689\n",
      "Epoch 2183, Loss: 0.00027246864465269027, Final Batch Loss: 0.0002704321523196995\n",
      "Epoch 2184, Loss: 0.0007533129210059997, Final Batch Loss: 0.0007170055760070682\n",
      "Epoch 2185, Loss: 0.00013138039321347605, Final Batch Loss: 0.00012004833115497604\n",
      "Epoch 2186, Loss: 0.00038070499431341887, Final Batch Loss: 9.315123315900564e-05\n",
      "Epoch 2187, Loss: 0.00026428659566590795, Final Batch Loss: 0.000257794075878337\n",
      "Epoch 2188, Loss: 6.357181518978905e-05, Final Batch Loss: 4.368493682704866e-05\n",
      "Epoch 2189, Loss: 7.4394960392965e-05, Final Batch Loss: 5.7734385336516425e-05\n",
      "Epoch 2190, Loss: 8.015561616048217e-05, Final Batch Loss: 4.243707735440694e-05\n",
      "Epoch 2191, Loss: 0.00010406948490526702, Final Batch Loss: 3.7346260342019377e-06\n",
      "Epoch 2192, Loss: 0.00014595478478440782, Final Batch Loss: 1.502651775808772e-05\n",
      "Epoch 2193, Loss: 0.00043066420016657503, Final Batch Loss: 0.0004284065216779709\n",
      "Epoch 2194, Loss: 0.0002469496612320654, Final Batch Loss: 0.00010075330646941438\n",
      "Epoch 2195, Loss: 0.00013447380842990242, Final Batch Loss: 7.945969264255837e-05\n",
      "Epoch 2196, Loss: 0.0010075055324705318, Final Batch Loss: 8.998556586448103e-05\n",
      "Epoch 2197, Loss: 0.0007279850833583623, Final Batch Loss: 0.0002881510881707072\n",
      "Epoch 2198, Loss: 0.0003770032162719872, Final Batch Loss: 0.0003566829254850745\n",
      "Epoch 2199, Loss: 1.727804647089215e-05, Final Batch Loss: 6.3182596932165325e-06\n",
      "Epoch 2200, Loss: 0.00015995028661563993, Final Batch Loss: 3.061530878767371e-05\n",
      "Epoch 2201, Loss: 6.407455748558277e-05, Final Batch Loss: 9.849424714047927e-06\n",
      "Epoch 2202, Loss: 0.00021206167366472073, Final Batch Loss: 5.1773666200460866e-05\n",
      "Epoch 2203, Loss: 0.0004013330544694327, Final Batch Loss: 0.0002899257524404675\n",
      "Epoch 2204, Loss: 0.00035452956217341125, Final Batch Loss: 0.00010141247184947133\n",
      "Epoch 2205, Loss: 0.0007279521473719797, Final Batch Loss: 5.8442624322196934e-06\n",
      "Epoch 2206, Loss: 0.00754490163490118, Final Batch Loss: 2.9428809284581803e-05\n",
      "Epoch 2207, Loss: 0.00023187341503216885, Final Batch Loss: 0.00018274638568982482\n",
      "Epoch 2208, Loss: 0.00040294142127095256, Final Batch Loss: 2.1307141651050188e-05\n",
      "Epoch 2209, Loss: 0.0007703535466134781, Final Batch Loss: 0.000744046235922724\n",
      "Epoch 2210, Loss: 0.0002591715056041721, Final Batch Loss: 5.1916231313953176e-05\n",
      "Epoch 2211, Loss: 0.0008788663471932523, Final Batch Loss: 0.0008313005091622472\n",
      "Epoch 2212, Loss: 0.0004487867117859423, Final Batch Loss: 0.00013234122889116406\n",
      "Epoch 2213, Loss: 0.000126260729302885, Final Batch Loss: 4.4027288822690025e-05\n",
      "Epoch 2214, Loss: 3.587586888897931e-05, Final Batch Loss: 2.7965479603153653e-05\n",
      "Epoch 2215, Loss: 0.0010843319032574072, Final Batch Loss: 0.0008721917984075844\n",
      "Epoch 2216, Loss: 4.161930201007635e-05, Final Batch Loss: 3.935298536816845e-06\n",
      "Epoch 2217, Loss: 0.0001120982469728915, Final Batch Loss: 0.00010011236008722335\n",
      "Epoch 2218, Loss: 5.308032450557221e-05, Final Batch Loss: 1.0708188710850663e-05\n",
      "Epoch 2219, Loss: 0.0009111611325351987, Final Batch Loss: 0.0008827458368614316\n",
      "Epoch 2220, Loss: 0.0003002626053785207, Final Batch Loss: 0.0002717401075642556\n",
      "Epoch 2221, Loss: 3.533058952598367e-05, Final Batch Loss: 1.1130849088658579e-05\n",
      "Epoch 2222, Loss: 2.9776215228594083e-05, Final Batch Loss: 1.3549368986787158e-06\n",
      "Epoch 2223, Loss: 0.00013825840869685635, Final Batch Loss: 7.46341684134677e-05\n",
      "Epoch 2224, Loss: 0.00010881157868425362, Final Batch Loss: 3.5775457945419475e-05\n",
      "Epoch 2225, Loss: 3.083464707742678e-05, Final Batch Loss: 1.6711175703676417e-05\n",
      "Epoch 2226, Loss: 0.0003007603663718328, Final Batch Loss: 0.00023897246865089983\n",
      "Epoch 2227, Loss: 9.552157462167088e-05, Final Batch Loss: 8.465837163385004e-05\n",
      "Epoch 2228, Loss: 0.0003292278288427042, Final Batch Loss: 0.0003056078858207911\n",
      "Epoch 2229, Loss: 1.9658225937746465e-05, Final Batch Loss: 1.425603659299668e-05\n",
      "Epoch 2230, Loss: 0.00039253728346011485, Final Batch Loss: 2.99691919281031e-06\n",
      "Epoch 2231, Loss: 0.00023934600540087558, Final Batch Loss: 0.0001958247448783368\n",
      "Epoch 2232, Loss: 6.917517202964518e-05, Final Batch Loss: 5.646683712257072e-05\n",
      "Epoch 2233, Loss: 0.00011830946095869876, Final Batch Loss: 2.438772571622394e-05\n",
      "Epoch 2234, Loss: 0.00014536908565787598, Final Batch Loss: 3.680621739476919e-05\n",
      "Epoch 2235, Loss: 7.994616134965327e-05, Final Batch Loss: 6.106056389398873e-05\n",
      "Epoch 2236, Loss: 1.7119433778134407e-05, Final Batch Loss: 4.153506324655609e-06\n",
      "Epoch 2237, Loss: 0.0002035117504419759, Final Batch Loss: 0.00018928424105979502\n",
      "Epoch 2238, Loss: 0.008953112846938893, Final Batch Loss: 0.00045663557830266654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2239, Loss: 0.00013570963028541883, Final Batch Loss: 4.160229309491115e-06\n",
      "Epoch 2240, Loss: 5.538492314371979e-05, Final Batch Loss: 8.619080290372949e-06\n",
      "Epoch 2241, Loss: 0.00015486205393244745, Final Batch Loss: 8.699488716956694e-06\n",
      "Epoch 2242, Loss: 0.00015702450036769733, Final Batch Loss: 7.48138118069619e-05\n",
      "Epoch 2243, Loss: 0.0008032592486415524, Final Batch Loss: 0.0007732680533081293\n",
      "Epoch 2244, Loss: 0.0009495653284830041, Final Batch Loss: 8.297066233353689e-05\n",
      "Epoch 2245, Loss: 1.789953421393875e-05, Final Batch Loss: 7.643792741873767e-06\n",
      "Epoch 2246, Loss: 0.00020493566012191877, Final Batch Loss: 3.3317967336188303e-06\n",
      "Epoch 2247, Loss: 0.010283324227202684, Final Batch Loss: 8.164095925167203e-05\n",
      "Epoch 2248, Loss: 0.0006051648961147293, Final Batch Loss: 3.555549483280629e-05\n",
      "Epoch 2249, Loss: 6.892790861456888e-05, Final Batch Loss: 6.11877185292542e-05\n",
      "Epoch 2250, Loss: 0.00011144585005240515, Final Batch Loss: 5.4796408221591264e-05\n",
      "Epoch 2251, Loss: 0.0001230537709488999, Final Batch Loss: 4.4929674913873896e-05\n",
      "Epoch 2252, Loss: 0.00032520458353246795, Final Batch Loss: 1.5108887055248488e-05\n",
      "Epoch 2253, Loss: 0.001453634860808961, Final Batch Loss: 0.0013952150475233793\n",
      "Epoch 2254, Loss: 6.66215182718588e-05, Final Batch Loss: 1.749969851516653e-05\n",
      "Epoch 2255, Loss: 0.0003944181498809485, Final Batch Loss: 0.0003821800637524575\n",
      "Epoch 2256, Loss: 3.1540775125904474e-05, Final Batch Loss: 1.0737997399701271e-05\n",
      "Epoch 2257, Loss: 0.00020838815908064134, Final Batch Loss: 0.00015620171325281262\n",
      "Epoch 2258, Loss: 0.00018420486594550312, Final Batch Loss: 7.264537998707965e-05\n",
      "Epoch 2259, Loss: 5.9869091273867525e-05, Final Batch Loss: 5.2919604058843106e-05\n",
      "Epoch 2260, Loss: 0.0007892334833741188, Final Batch Loss: 0.0006038664141669869\n",
      "Epoch 2261, Loss: 0.0006240432048798539, Final Batch Loss: 0.0005268885870464146\n",
      "Epoch 2262, Loss: 0.001851877721492201, Final Batch Loss: 0.0013154589105397463\n",
      "Epoch 2263, Loss: 0.0004466254176804796, Final Batch Loss: 0.0002786197583191097\n",
      "Epoch 2264, Loss: 0.00036057678516954184, Final Batch Loss: 0.00015840274863876402\n",
      "Epoch 2265, Loss: 8.99073165783193e-05, Final Batch Loss: 5.970560232526623e-05\n",
      "Epoch 2266, Loss: 0.0002552089499658905, Final Batch Loss: 0.00011792250006692484\n",
      "Epoch 2267, Loss: 0.0011431904786149971, Final Batch Loss: 0.0010740543948486447\n",
      "Epoch 2268, Loss: 0.0001504724714322947, Final Batch Loss: 0.00011013971379725263\n",
      "Epoch 2269, Loss: 0.0001514941477580578, Final Batch Loss: 1.4872880456096027e-05\n",
      "Epoch 2270, Loss: 0.00027757786301663145, Final Batch Loss: 0.0001685653260210529\n",
      "Epoch 2271, Loss: 5.8115421779803e-05, Final Batch Loss: 3.780199767788872e-05\n",
      "Epoch 2272, Loss: 0.00020015188783872873, Final Batch Loss: 2.1372761693783104e-05\n",
      "Epoch 2273, Loss: 2.0503239738900447e-05, Final Batch Loss: 1.802858241717331e-05\n",
      "Epoch 2274, Loss: 7.622937539508712e-05, Final Batch Loss: 6.699161758660921e-07\n",
      "Epoch 2275, Loss: 0.00022890013769938378, Final Batch Loss: 0.0002207141078542918\n",
      "Epoch 2276, Loss: 0.00020790770940948278, Final Batch Loss: 0.00014305902004707605\n",
      "Epoch 2277, Loss: 0.00027849818519598557, Final Batch Loss: 5.095725441606191e-07\n",
      "Epoch 2278, Loss: 6.10374404459435e-05, Final Batch Loss: 5.7618788559921086e-05\n",
      "Epoch 2279, Loss: 0.0002842216199496761, Final Batch Loss: 9.429070632904768e-05\n",
      "Epoch 2280, Loss: 0.0006908671621204121, Final Batch Loss: 0.0006734469789080322\n",
      "Epoch 2281, Loss: 6.750983266101684e-05, Final Batch Loss: 1.0661040505510755e-05\n",
      "Epoch 2282, Loss: 0.00014819673015153967, Final Batch Loss: 0.00012745868298225105\n",
      "Epoch 2283, Loss: 0.00030266534304246306, Final Batch Loss: 0.00012735341442748904\n",
      "Epoch 2284, Loss: 0.0005909004485147307, Final Batch Loss: 1.2792961570085026e-05\n",
      "Epoch 2285, Loss: 0.000700772969139507, Final Batch Loss: 0.0006584582151845098\n",
      "Epoch 2286, Loss: 0.0003174410157953389, Final Batch Loss: 3.8679463614244014e-05\n",
      "Epoch 2287, Loss: 5.990697354718577e-05, Final Batch Loss: 4.6424152969848365e-05\n",
      "Epoch 2288, Loss: 0.00019806448108283803, Final Batch Loss: 6.411676440620795e-05\n",
      "Epoch 2289, Loss: 0.00038296461116260616, Final Batch Loss: 8.285157491627615e-06\n",
      "Epoch 2290, Loss: 5.687282646249514e-05, Final Batch Loss: 4.589468517224304e-06\n",
      "Epoch 2291, Loss: 0.00047599690878996626, Final Batch Loss: 0.00045820148079656065\n",
      "Epoch 2292, Loss: 0.00010188279702560976, Final Batch Loss: 3.691290476126596e-05\n",
      "Epoch 2293, Loss: 1.4105278751230799e-05, Final Batch Loss: 6.227752237464301e-06\n",
      "Epoch 2294, Loss: 1.6174192296602996e-05, Final Batch Loss: 7.2397792791889515e-06\n",
      "Epoch 2295, Loss: 6.267348362598568e-05, Final Batch Loss: 2.850997043424286e-05\n",
      "Epoch 2296, Loss: 3.469426337687764e-05, Final Batch Loss: 8.093844371614978e-06\n",
      "Epoch 2297, Loss: 0.0002730711130425334, Final Batch Loss: 0.00013206532457843423\n",
      "Epoch 2298, Loss: 0.0067322804061404895, Final Batch Loss: 2.017295264522545e-05\n",
      "Epoch 2299, Loss: 0.00016580235569563229, Final Batch Loss: 2.2655194698018022e-05\n",
      "Epoch 2300, Loss: 0.0005981722424621694, Final Batch Loss: 0.0005063353455625474\n",
      "Epoch 2301, Loss: 3.78066283701628e-05, Final Batch Loss: 3.933247626264347e-06\n",
      "Epoch 2302, Loss: 0.0007936927177070174, Final Batch Loss: 9.970452083507553e-06\n",
      "Epoch 2303, Loss: 2.4583966023783432e-05, Final Batch Loss: 2.9128536880307365e-06\n",
      "Epoch 2304, Loss: 2.7164952598468517e-05, Final Batch Loss: 2.481145565980114e-05\n",
      "Epoch 2305, Loss: 2.4917121891121496e-05, Final Batch Loss: 3.0512467219523387e-06\n",
      "Epoch 2306, Loss: 0.00042120837315451354, Final Batch Loss: 0.00039633308188058436\n",
      "Epoch 2307, Loss: 4.648626418202184e-05, Final Batch Loss: 4.452800931176171e-05\n",
      "Epoch 2308, Loss: 0.0005599712940238533, Final Batch Loss: 7.651197847735602e-06\n",
      "Epoch 2309, Loss: 6.246971861401107e-05, Final Batch Loss: 4.539571818895638e-05\n",
      "Epoch 2310, Loss: 0.0002044534678589116, Final Batch Loss: 3.2090658805827843e-06\n",
      "Epoch 2311, Loss: 0.00021573703043031855, Final Batch Loss: 5.7117699725495186e-06\n",
      "Epoch 2312, Loss: 4.8720992481321446e-05, Final Batch Loss: 5.196468464419013e-07\n",
      "Epoch 2313, Loss: 0.00012016045548080001, Final Batch Loss: 3.914234184776433e-06\n",
      "Epoch 2314, Loss: 0.00036956771509721875, Final Batch Loss: 0.0001310560473939404\n",
      "Epoch 2315, Loss: 8.046699986152817e-05, Final Batch Loss: 5.372027226258069e-05\n",
      "Epoch 2316, Loss: 0.0007593233967781998, Final Batch Loss: 0.0007339899311773479\n",
      "Epoch 2317, Loss: 2.714171341722249e-05, Final Batch Loss: 2.204007250838913e-05\n",
      "Epoch 2318, Loss: 4.4765559323423076e-05, Final Batch Loss: 1.1431869097577874e-05\n",
      "Epoch 2319, Loss: 6.846224039236404e-06, Final Batch Loss: 8.722217330614512e-07\n",
      "Epoch 2320, Loss: 0.0005640493691316806, Final Batch Loss: 5.78370745643042e-05\n",
      "Epoch 2321, Loss: 3.6788643228646833e-05, Final Batch Loss: 3.48876383213792e-05\n",
      "Epoch 2322, Loss: 0.00016812285502965096, Final Batch Loss: 7.118887879187241e-07\n",
      "Epoch 2323, Loss: 0.0004336431229603477, Final Batch Loss: 6.527885125251487e-05\n",
      "Epoch 2324, Loss: 6.330908036034089e-05, Final Batch Loss: 8.556222383049317e-06\n",
      "Epoch 2325, Loss: 0.0008121631981339306, Final Batch Loss: 0.0005294140428304672\n",
      "Epoch 2326, Loss: 0.000153437809785828, Final Batch Loss: 0.00010038412438007072\n",
      "Epoch 2327, Loss: 0.0006336951264529489, Final Batch Loss: 0.0006308414740487933\n",
      "Epoch 2328, Loss: 9.879991466732463e-06, Final Batch Loss: 3.4107420106010977e-06\n",
      "Epoch 2329, Loss: 0.00022280578809841245, Final Batch Loss: 8.394879387196852e-07\n",
      "Epoch 2330, Loss: 9.497081464360235e-06, Final Batch Loss: 4.1494599827274214e-06\n",
      "Epoch 2331, Loss: 1.4836245327387587e-05, Final Batch Loss: 3.010226691912976e-06\n",
      "Epoch 2332, Loss: 1.689080545475008e-05, Final Batch Loss: 7.055316018522717e-06\n",
      "Epoch 2333, Loss: 1.2988885032427788e-05, Final Batch Loss: 1.7108606016336125e-06\n",
      "Epoch 2334, Loss: 0.00010798501170938835, Final Batch Loss: 5.098175097373314e-05\n",
      "Epoch 2335, Loss: 0.0002350461327296216, Final Batch Loss: 3.623210432124324e-05\n",
      "Epoch 2336, Loss: 0.005042844873969443, Final Batch Loss: 0.004907697439193726\n",
      "Epoch 2337, Loss: 0.0009353767345601227, Final Batch Loss: 0.0009214627207256854\n",
      "Epoch 2338, Loss: 1.0070574717246927e-05, Final Batch Loss: 1.9945555322919972e-06\n",
      "Epoch 2339, Loss: 6.953963111300254e-05, Final Batch Loss: 1.9282388166175224e-06\n",
      "Epoch 2340, Loss: 7.012311471044086e-05, Final Batch Loss: 6.13396186963655e-05\n",
      "Epoch 2341, Loss: 6.889005089760758e-05, Final Batch Loss: 3.53121395164635e-05\n",
      "Epoch 2342, Loss: 0.00014043686314835213, Final Batch Loss: 4.97439359605778e-05\n",
      "Epoch 2343, Loss: 0.0029819752016919665, Final Batch Loss: 0.0029432291630655527\n",
      "Epoch 2344, Loss: 1.4072722933633486e-05, Final Batch Loss: 6.014369773765793e-06\n",
      "Epoch 2345, Loss: 0.0049687568680383265, Final Batch Loss: 0.004578786436468363\n",
      "Epoch 2346, Loss: 0.0006248761528695468, Final Batch Loss: 0.000574206467717886\n",
      "Epoch 2347, Loss: 0.00029784722846670775, Final Batch Loss: 1.103573140426306e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2348, Loss: 0.0013330326255527325, Final Batch Loss: 6.9519810494966805e-06\n",
      "Epoch 2349, Loss: 0.00020688957738457248, Final Batch Loss: 8.798357885098085e-05\n",
      "Epoch 2350, Loss: 0.0002737274917308241, Final Batch Loss: 0.0001419599720975384\n",
      "Epoch 2351, Loss: 0.0027196334303880576, Final Batch Loss: 3.725165515788831e-05\n",
      "Epoch 2352, Loss: 0.013452633866108954, Final Batch Loss: 0.012157682329416275\n",
      "Epoch 2353, Loss: 0.01755310510225172, Final Batch Loss: 5.82550592298503e-06\n",
      "Epoch 2354, Loss: 4.0700300814933144e-05, Final Batch Loss: 2.870161370083224e-05\n",
      "Epoch 2355, Loss: 8.023420377867296e-05, Final Batch Loss: 1.5493074897676706e-05\n",
      "Epoch 2356, Loss: 3.764002167372382e-05, Final Batch Loss: 4.904229626845336e-06\n",
      "Epoch 2357, Loss: 6.0014635323568655e-05, Final Batch Loss: 1.7217583945239312e-06\n",
      "Epoch 2358, Loss: 4.308405050323927e-05, Final Batch Loss: 3.5634533560369164e-05\n",
      "Epoch 2359, Loss: 0.03553940612891893, Final Batch Loss: 1.4415719306271058e-05\n",
      "Epoch 2360, Loss: 0.000423065746872453, Final Batch Loss: 3.218768324586563e-05\n",
      "Epoch 2361, Loss: 1.5850401268835412e-05, Final Batch Loss: 1.2318841982050799e-05\n",
      "Epoch 2362, Loss: 0.06536430164123885, Final Batch Loss: 0.06507433950901031\n",
      "Epoch 2363, Loss: 0.0041636734968051314, Final Batch Loss: 0.0015944192418828607\n",
      "Epoch 2364, Loss: 0.0016141409323608968, Final Batch Loss: 0.0016003147466108203\n",
      "Epoch 2365, Loss: 6.616794235014822e-05, Final Batch Loss: 1.9665390937007032e-05\n",
      "Epoch 2366, Loss: 0.000614025688264519, Final Batch Loss: 0.0005691508995369077\n",
      "Epoch 2367, Loss: 0.0008549782724003308, Final Batch Loss: 0.00010720994760049507\n",
      "Epoch 2368, Loss: 0.009651858825236559, Final Batch Loss: 0.006894726771861315\n",
      "Epoch 2369, Loss: 0.0021059868377051316, Final Batch Loss: 8.462057303404436e-05\n",
      "Epoch 2370, Loss: 0.0022972145743551664, Final Batch Loss: 3.920087328879163e-05\n",
      "Epoch 2371, Loss: 0.0011937359377043322, Final Batch Loss: 1.8448408809490502e-05\n",
      "Epoch 2372, Loss: 0.0009915631817420945, Final Batch Loss: 0.00017711320833768696\n",
      "Epoch 2373, Loss: 0.003647244710009545, Final Batch Loss: 0.0026712478138506413\n",
      "Epoch 2374, Loss: 0.04579995688982308, Final Batch Loss: 0.0025906239170581102\n",
      "Epoch 2375, Loss: 0.000745082987123169, Final Batch Loss: 0.000240168024902232\n",
      "Epoch 2376, Loss: 0.00039685268711764365, Final Batch Loss: 0.0002131224173353985\n",
      "Epoch 2377, Loss: 0.0003235723706893623, Final Batch Loss: 0.0001003044453682378\n",
      "Epoch 2378, Loss: 0.006751564571459312, Final Batch Loss: 0.0066861375235021114\n",
      "Epoch 2379, Loss: 0.0002767989626590861, Final Batch Loss: 0.00024652405409142375\n",
      "Epoch 2380, Loss: 0.0005684578864020295, Final Batch Loss: 0.0004738580319099128\n",
      "Epoch 2381, Loss: 0.00026911638997262344, Final Batch Loss: 7.657430978724733e-05\n",
      "Epoch 2382, Loss: 8.971272109192796e-05, Final Batch Loss: 3.810984708252363e-05\n",
      "Epoch 2383, Loss: 3.583594661904499e-05, Final Batch Loss: 1.7004138499032706e-05\n",
      "Epoch 2384, Loss: 0.00039261297206394374, Final Batch Loss: 0.00031946817762218416\n",
      "Epoch 2385, Loss: 0.00018995730351889506, Final Batch Loss: 9.215750469593331e-05\n",
      "Epoch 2386, Loss: 0.0001608923230378423, Final Batch Loss: 0.00010970124276354909\n",
      "Epoch 2387, Loss: 0.0005668542798957787, Final Batch Loss: 0.00048082921421155334\n",
      "Epoch 2388, Loss: 0.00032003687374526635, Final Batch Loss: 8.978909318102524e-05\n",
      "Epoch 2389, Loss: 0.0013762023281742586, Final Batch Loss: 1.8522840036894195e-05\n",
      "Epoch 2390, Loss: 0.0003550062156136846, Final Batch Loss: 0.0003274662885814905\n",
      "Epoch 2391, Loss: 0.0006000992725603282, Final Batch Loss: 0.00045953691005706787\n",
      "Epoch 2392, Loss: 7.892757184890797e-05, Final Batch Loss: 8.641653948870953e-06\n",
      "Epoch 2393, Loss: 7.105563236109447e-05, Final Batch Loss: 1.9604865883593448e-05\n",
      "Epoch 2394, Loss: 0.0001831252229749225, Final Batch Loss: 6.674607720924541e-05\n",
      "Epoch 2395, Loss: 0.00019409324158914387, Final Batch Loss: 0.00014693403500132263\n",
      "Epoch 2396, Loss: 0.0006301137291302439, Final Batch Loss: 1.8877526599681005e-05\n",
      "Epoch 2397, Loss: 0.00034641687670955434, Final Batch Loss: 0.0002475348301231861\n",
      "Epoch 2398, Loss: 5.730007069359999e-05, Final Batch Loss: 2.2699114197166637e-06\n",
      "Epoch 2399, Loss: 0.00038910772127564996, Final Batch Loss: 0.00014282965275924653\n",
      "Epoch 2400, Loss: 0.00016661010295138112, Final Batch Loss: 4.60427099824301e-06\n",
      "Epoch 2401, Loss: 0.0002604516521387268, Final Batch Loss: 0.00020127443713136017\n",
      "Epoch 2402, Loss: 3.870322234433843e-05, Final Batch Loss: 2.600243351480458e-05\n",
      "Epoch 2403, Loss: 5.339263771020342e-05, Final Batch Loss: 3.94784910895396e-05\n",
      "Epoch 2404, Loss: 0.0005624974437523633, Final Batch Loss: 0.00035245504113845527\n",
      "Epoch 2405, Loss: 0.00011423891191952862, Final Batch Loss: 4.8236808652291074e-05\n",
      "Epoch 2406, Loss: 2.747898315647035e-05, Final Batch Loss: 5.853389211551985e-06\n",
      "Epoch 2407, Loss: 0.0005537806719075888, Final Batch Loss: 0.0001695262617431581\n",
      "Epoch 2408, Loss: 9.470679651712999e-05, Final Batch Loss: 5.149520802660845e-05\n",
      "Epoch 2409, Loss: 0.0003072243453061674, Final Batch Loss: 0.00026637004339136183\n",
      "Epoch 2410, Loss: 0.00012404467088344973, Final Batch Loss: 2.7092120944871567e-05\n",
      "Epoch 2411, Loss: 0.0006223505624802783, Final Batch Loss: 0.00043568480759859085\n",
      "Epoch 2412, Loss: 0.004235062625411956, Final Batch Loss: 3.8522930481121875e-06\n",
      "Epoch 2413, Loss: 0.0001481043618696276, Final Batch Loss: 0.00011012346658390015\n",
      "Epoch 2414, Loss: 3.508520512696123e-05, Final Batch Loss: 9.121352377405856e-06\n",
      "Epoch 2415, Loss: 0.0007432346465066075, Final Batch Loss: 0.0005329298437573016\n",
      "Epoch 2416, Loss: 0.0001316059278906323, Final Batch Loss: 3.4892909752670676e-05\n",
      "Epoch 2417, Loss: 0.0004661360726458952, Final Batch Loss: 0.00014717217709403485\n",
      "Epoch 2418, Loss: 0.00039586143338965485, Final Batch Loss: 9.367541679239366e-06\n",
      "Epoch 2419, Loss: 0.0004939538812323008, Final Batch Loss: 1.3991844753036276e-05\n",
      "Epoch 2420, Loss: 0.0003126576848444529, Final Batch Loss: 0.000219916517380625\n",
      "Epoch 2421, Loss: 0.0001539390068501234, Final Batch Loss: 4.977438220521435e-05\n",
      "Epoch 2422, Loss: 0.00032272791213472374, Final Batch Loss: 2.1090923837618902e-05\n",
      "Epoch 2423, Loss: 0.0015414540384881548, Final Batch Loss: 1.5123091543500777e-05\n",
      "Epoch 2424, Loss: 0.00034095953560608905, Final Batch Loss: 1.8470729628461413e-05\n",
      "Epoch 2425, Loss: 6.644651784881717e-05, Final Batch Loss: 5.4760006605647504e-05\n",
      "Epoch 2426, Loss: 0.00020330670304247178, Final Batch Loss: 0.00018157868180423975\n",
      "Epoch 2427, Loss: 1.6949922837738995e-05, Final Batch Loss: 2.8331771773082437e-06\n",
      "Epoch 2428, Loss: 0.000208330731766182, Final Batch Loss: 5.929539838689379e-06\n",
      "Epoch 2429, Loss: 0.0004298179046600126, Final Batch Loss: 0.0003740203392226249\n",
      "Epoch 2430, Loss: 4.087195156898815e-05, Final Batch Loss: 1.9382368918741122e-05\n",
      "Epoch 2431, Loss: 0.00023518785747000948, Final Batch Loss: 0.00015290812007151544\n",
      "Epoch 2432, Loss: 0.0003464067049208097, Final Batch Loss: 4.417663876665756e-05\n",
      "Epoch 2433, Loss: 3.9012024899420794e-05, Final Batch Loss: 2.6795467420015484e-05\n",
      "Epoch 2434, Loss: 0.006531021343107568, Final Batch Loss: 0.006476284004747868\n",
      "Epoch 2435, Loss: 4.6000710426596925e-05, Final Batch Loss: 2.8883969207527116e-05\n",
      "Epoch 2436, Loss: 0.00013495602979674004, Final Batch Loss: 5.5030675866873935e-05\n",
      "Epoch 2437, Loss: 6.0756185121135786e-05, Final Batch Loss: 8.457773219561204e-06\n",
      "Epoch 2438, Loss: 0.0001529814544483088, Final Batch Loss: 3.614875458879396e-05\n",
      "Epoch 2439, Loss: 5.3393745474750176e-05, Final Batch Loss: 1.3044355000602081e-05\n",
      "Epoch 2440, Loss: 0.00011798922605521511, Final Batch Loss: 9.280326776206493e-05\n",
      "Epoch 2441, Loss: 0.00012110693114664173, Final Batch Loss: 1.0023787581303623e-05\n",
      "Epoch 2442, Loss: 7.362443011516007e-05, Final Batch Loss: 6.948514965188224e-06\n",
      "Epoch 2443, Loss: 8.892077221389627e-05, Final Batch Loss: 1.271571727556875e-05\n",
      "Epoch 2444, Loss: 0.00029191292424002313, Final Batch Loss: 5.359519946068758e-06\n",
      "Epoch 2445, Loss: 0.0006249397624742414, Final Batch Loss: 6.037902039679466e-06\n",
      "Epoch 2446, Loss: 0.00048588294521323405, Final Batch Loss: 5.674280328094028e-05\n",
      "Epoch 2447, Loss: 0.00011298975368845277, Final Batch Loss: 2.96969483315479e-05\n",
      "Epoch 2448, Loss: 3.83142578357365e-05, Final Batch Loss: 1.558472831675317e-05\n",
      "Epoch 2449, Loss: 0.0007188356976257637, Final Batch Loss: 0.0005103796720504761\n",
      "Epoch 2450, Loss: 0.00022297882424027193, Final Batch Loss: 0.00020063311967533082\n",
      "Epoch 2451, Loss: 0.0001667291835474316, Final Batch Loss: 2.5995865144068375e-05\n",
      "Epoch 2452, Loss: 0.010573883029792341, Final Batch Loss: 2.5189901862177067e-05\n",
      "Epoch 2453, Loss: 0.0010228926767013036, Final Batch Loss: 0.0009611050481908023\n",
      "Epoch 2454, Loss: 0.00014622372691519558, Final Batch Loss: 8.457760122837499e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2455, Loss: 0.00016170641538337804, Final Batch Loss: 0.00010822981857927516\n",
      "Epoch 2456, Loss: 0.001290799569687806, Final Batch Loss: 0.001208471949212253\n",
      "Epoch 2457, Loss: 0.00037089947727508843, Final Batch Loss: 4.6513479901477695e-05\n",
      "Epoch 2458, Loss: 0.00027063540619565174, Final Batch Loss: 5.721249181078747e-05\n",
      "Epoch 2459, Loss: 0.00010785364611365367, Final Batch Loss: 8.184237231034786e-05\n",
      "Epoch 2460, Loss: 9.578255912856548e-05, Final Batch Loss: 7.391119197563967e-06\n",
      "Epoch 2461, Loss: 5.368380880099721e-05, Final Batch Loss: 3.9124293834902346e-05\n",
      "Epoch 2462, Loss: 1.912618608912453e-05, Final Batch Loss: 4.5659407987841405e-06\n",
      "Epoch 2463, Loss: 0.006929475086508319, Final Batch Loss: 0.00025873977574519813\n",
      "Epoch 2464, Loss: 0.00015213503320410382, Final Batch Loss: 0.00013716939429286867\n",
      "Epoch 2465, Loss: 0.0001767138867307949, Final Batch Loss: 2.633370286275749e-06\n",
      "Epoch 2466, Loss: 0.0001983934507734375, Final Batch Loss: 3.6245783121557906e-06\n",
      "Epoch 2467, Loss: 4.7711393563076854e-05, Final Batch Loss: 5.611957021756098e-06\n",
      "Epoch 2468, Loss: 0.0017585786918061785, Final Batch Loss: 2.6862762751989067e-06\n",
      "Epoch 2469, Loss: 0.0006613157347601373, Final Batch Loss: 0.0006426876643672585\n",
      "Epoch 2470, Loss: 0.00023718753072898835, Final Batch Loss: 2.8307680622674525e-05\n",
      "Epoch 2471, Loss: 2.72876386588905e-05, Final Batch Loss: 1.2257315574970562e-05\n",
      "Epoch 2472, Loss: 0.000191017412362271, Final Batch Loss: 4.8596066335448995e-06\n",
      "Epoch 2473, Loss: 8.387936122744577e-05, Final Batch Loss: 1.5097580217116047e-05\n",
      "Epoch 2474, Loss: 0.0009375729714520276, Final Batch Loss: 0.0005817043711431324\n",
      "Epoch 2475, Loss: 0.0001934091269504279, Final Batch Loss: 0.00010502960503799841\n",
      "Epoch 2476, Loss: 1.3381889630181831e-05, Final Batch Loss: 2.252271997349453e-06\n",
      "Epoch 2477, Loss: 0.00026230311777908355, Final Batch Loss: 1.9300554413348436e-05\n",
      "Epoch 2478, Loss: 5.45879483979661e-05, Final Batch Loss: 1.1710257240338251e-05\n",
      "Epoch 2479, Loss: 0.0001137886501965113, Final Batch Loss: 2.066419256152585e-05\n",
      "Epoch 2480, Loss: 0.005446305400255369, Final Batch Loss: 3.3037173125194386e-05\n",
      "Epoch 2481, Loss: 3.2072346584754996e-05, Final Batch Loss: 2.5702414859551936e-05\n",
      "Epoch 2482, Loss: 4.821450238523539e-05, Final Batch Loss: 5.455132850329392e-06\n",
      "Epoch 2483, Loss: 0.0003478457518895084, Final Batch Loss: 0.00034673712798394263\n",
      "Epoch 2484, Loss: 0.0008447850545962865, Final Batch Loss: 0.0008375195320695639\n",
      "Epoch 2485, Loss: 0.00032435670800623484, Final Batch Loss: 0.0002923926804214716\n",
      "Epoch 2486, Loss: 0.00013229982141638175, Final Batch Loss: 3.92565198126249e-05\n",
      "Epoch 2487, Loss: 0.0010265796081512235, Final Batch Loss: 4.5191227400209755e-05\n",
      "Epoch 2488, Loss: 0.00037820154102519155, Final Batch Loss: 0.00034940463956445456\n",
      "Epoch 2489, Loss: 7.441814727826568e-05, Final Batch Loss: 1.8980520053446526e-06\n",
      "Epoch 2490, Loss: 1.306201943407359e-05, Final Batch Loss: 2.0701365883724065e-06\n",
      "Epoch 2491, Loss: 0.0007529057620558888, Final Batch Loss: 6.991586997173727e-05\n",
      "Epoch 2492, Loss: 0.00017010857118293643, Final Batch Loss: 3.219778591301292e-05\n",
      "Epoch 2493, Loss: 0.0001252460288014845, Final Batch Loss: 3.1444005799130537e-06\n",
      "Epoch 2494, Loss: 0.0005383537386478565, Final Batch Loss: 5.423778475233121e-06\n",
      "Epoch 2495, Loss: 0.00021918444326729514, Final Batch Loss: 4.0941089537227526e-05\n",
      "Epoch 2496, Loss: 0.000598778869061789, Final Batch Loss: 1.2268233149370644e-05\n",
      "Epoch 2497, Loss: 4.79332866234472e-05, Final Batch Loss: 2.6420902941026725e-05\n",
      "Epoch 2498, Loss: 0.00016877740927156992, Final Batch Loss: 0.00012194146256661043\n",
      "Epoch 2499, Loss: 0.00020143668371019885, Final Batch Loss: 8.030141179915518e-05\n",
      "Epoch 2500, Loss: 5.7159763855452184e-05, Final Batch Loss: 4.5034990762360394e-05\n",
      "Epoch 2501, Loss: 3.668061253847554e-05, Final Batch Loss: 1.4284521967056207e-05\n",
      "Epoch 2502, Loss: 9.824491280596703e-05, Final Batch Loss: 2.9177397664170712e-05\n",
      "Epoch 2503, Loss: 0.00016002417032723315, Final Batch Loss: 0.00012494628026615828\n",
      "Epoch 2504, Loss: 6.410520654753782e-05, Final Batch Loss: 6.050065712770447e-05\n",
      "Epoch 2505, Loss: 0.00043998593173455447, Final Batch Loss: 0.00027121248422190547\n",
      "Epoch 2506, Loss: 4.068677708346513e-05, Final Batch Loss: 5.524063908524113e-06\n",
      "Epoch 2507, Loss: 0.00237275667313952, Final Batch Loss: 0.0022726699244230986\n",
      "Epoch 2508, Loss: 0.00022569295106222853, Final Batch Loss: 1.3993507309351116e-05\n",
      "Epoch 2509, Loss: 0.00012687905109487474, Final Batch Loss: 0.0001155057834694162\n",
      "Epoch 2510, Loss: 0.00022831618116470054, Final Batch Loss: 0.0001418526517227292\n",
      "Epoch 2511, Loss: 0.00015242474728438538, Final Batch Loss: 3.0328241336974315e-05\n",
      "Epoch 2512, Loss: 0.00020287522283979342, Final Batch Loss: 5.036056336393813e-06\n",
      "Epoch 2513, Loss: 3.550313886080403e-05, Final Batch Loss: 3.067716534133069e-05\n",
      "Epoch 2514, Loss: 2.5832597202679608e-05, Final Batch Loss: 1.1893138434970751e-05\n",
      "Epoch 2515, Loss: 0.00014653995094704442, Final Batch Loss: 9.517269063508138e-06\n",
      "Epoch 2516, Loss: 6.26589771854924e-05, Final Batch Loss: 4.391159018268809e-05\n",
      "Epoch 2517, Loss: 0.005957935679475668, Final Batch Loss: 1.1643616062428919e-06\n",
      "Epoch 2518, Loss: 2.107492309733061e-05, Final Batch Loss: 1.0324631148250774e-05\n",
      "Epoch 2519, Loss: 0.00015381467164843343, Final Batch Loss: 0.00010360142186982557\n",
      "Epoch 2520, Loss: 0.03976885800511809, Final Batch Loss: 0.039647798985242844\n",
      "Epoch 2521, Loss: 1.70153439285059e-05, Final Batch Loss: 1.2652836630877573e-05\n",
      "Epoch 2522, Loss: 0.00020609977946151048, Final Batch Loss: 5.641618918161839e-05\n",
      "Epoch 2523, Loss: 6.729339656885713e-05, Final Batch Loss: 3.9549726352561265e-05\n",
      "Epoch 2524, Loss: 0.00013825691712554544, Final Batch Loss: 3.815341187873855e-05\n",
      "Epoch 2525, Loss: 0.00046480515447910875, Final Batch Loss: 0.00011177775741089135\n",
      "Epoch 2526, Loss: 0.00014039808411325794, Final Batch Loss: 2.617972313601058e-05\n",
      "Epoch 2527, Loss: 0.0005390610313042998, Final Batch Loss: 0.0003045998455490917\n",
      "Epoch 2528, Loss: 0.000361392434570007, Final Batch Loss: 0.0001803881023079157\n",
      "Epoch 2529, Loss: 0.00016192009172755206, Final Batch Loss: 9.620413266020478e-07\n",
      "Epoch 2530, Loss: 0.0008815747423795983, Final Batch Loss: 0.00024219775514211506\n",
      "Epoch 2531, Loss: 0.00018914843212769483, Final Batch Loss: 6.841965387138771e-06\n",
      "Epoch 2532, Loss: 0.00015762867406010628, Final Batch Loss: 0.0001186163499369286\n",
      "Epoch 2533, Loss: 0.001593428572959965, Final Batch Loss: 3.626770558184944e-05\n",
      "Epoch 2534, Loss: 0.0004186784353805706, Final Batch Loss: 0.0002155566617147997\n",
      "Epoch 2535, Loss: 0.00035503163235262036, Final Batch Loss: 8.466123836115003e-05\n",
      "Epoch 2536, Loss: 0.02573067472258117, Final Batch Loss: 6.909445801284164e-05\n",
      "Epoch 2537, Loss: 0.0054536840034415945, Final Batch Loss: 0.005345498211681843\n",
      "Epoch 2538, Loss: 1.1684839591907803e-05, Final Batch Loss: 7.2097941483662e-06\n",
      "Epoch 2539, Loss: 0.00043445917253848165, Final Batch Loss: 0.00028642124379985034\n",
      "Epoch 2540, Loss: 0.00017687953368294984, Final Batch Loss: 0.00012297336070332676\n",
      "Epoch 2541, Loss: 0.0001058483650240305, Final Batch Loss: 0.00010440408368594944\n",
      "Epoch 2542, Loss: 0.0006435595132643357, Final Batch Loss: 6.344950816128403e-05\n",
      "Epoch 2543, Loss: 0.00021827167984156404, Final Batch Loss: 1.4322644346975721e-05\n",
      "Epoch 2544, Loss: 0.002995786159317504, Final Batch Loss: 6.579929049621569e-06\n",
      "Epoch 2545, Loss: 1.784823962225346e-05, Final Batch Loss: 5.725817572965752e-06\n",
      "Epoch 2546, Loss: 8.845179036143236e-05, Final Batch Loss: 8.078618702711537e-05\n",
      "Epoch 2547, Loss: 4.244047386237071e-05, Final Batch Loss: 6.83605549056665e-06\n",
      "Epoch 2548, Loss: 0.00018386303599982057, Final Batch Loss: 1.2195125236758031e-05\n",
      "Epoch 2549, Loss: 0.0029387602116912603, Final Batch Loss: 0.0022907950915396214\n",
      "Epoch 2550, Loss: 6.522467265313026e-05, Final Batch Loss: 3.818458571913652e-05\n",
      "Epoch 2551, Loss: 3.429638491070364e-05, Final Batch Loss: 2.438974115648307e-05\n",
      "Epoch 2552, Loss: 0.0005758427869295701, Final Batch Loss: 0.00033356164931319654\n",
      "Epoch 2553, Loss: 6.136802949185949e-05, Final Batch Loss: 3.203770756954327e-05\n",
      "Epoch 2554, Loss: 0.0009636539762141183, Final Batch Loss: 0.0008035310311242938\n",
      "Epoch 2555, Loss: 0.00027857505119754933, Final Batch Loss: 0.00026633095694705844\n",
      "Epoch 2556, Loss: 0.0002217638975707814, Final Batch Loss: 3.681665111798793e-05\n",
      "Epoch 2557, Loss: 0.0001126723836932797, Final Batch Loss: 7.614013884449378e-05\n",
      "Epoch 2558, Loss: 2.588199322417495e-05, Final Batch Loss: 2.0703340851468965e-05\n",
      "Epoch 2559, Loss: 0.00024054254026850685, Final Batch Loss: 0.0001366540527669713\n",
      "Epoch 2560, Loss: 0.0004487818805500865, Final Batch Loss: 0.0003252991591580212\n",
      "Epoch 2561, Loss: 3.8042870755816693e-05, Final Batch Loss: 3.614898741943762e-05\n",
      "Epoch 2562, Loss: 0.0003601845746743493, Final Batch Loss: 4.503054515225813e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2563, Loss: 0.0002680233992577996, Final Batch Loss: 0.0002627194335218519\n",
      "Epoch 2564, Loss: 8.760988202993758e-05, Final Batch Loss: 2.1392337657744065e-05\n",
      "Epoch 2565, Loss: 0.00020647261226258706, Final Batch Loss: 0.00018357647059019655\n",
      "Epoch 2566, Loss: 2.4402825602010125e-05, Final Batch Loss: 1.9359784346306697e-05\n",
      "Epoch 2567, Loss: 7.304862629098352e-05, Final Batch Loss: 6.195214155013673e-06\n",
      "Epoch 2568, Loss: 0.0007864657090976834, Final Batch Loss: 0.0003824079467449337\n",
      "Epoch 2569, Loss: 0.0021857729998373543, Final Batch Loss: 0.002178990049287677\n",
      "Epoch 2570, Loss: 1.1208984687982593e-05, Final Batch Loss: 5.388129920902429e-06\n",
      "Epoch 2571, Loss: 2.6881215489993338e-05, Final Batch Loss: 1.384499864798272e-05\n",
      "Epoch 2572, Loss: 5.016392606194131e-05, Final Batch Loss: 8.410221198573709e-06\n",
      "Epoch 2573, Loss: 2.6444794457347598e-05, Final Batch Loss: 1.5184965377557091e-05\n",
      "Epoch 2574, Loss: 7.321290468098596e-05, Final Batch Loss: 5.565774699789472e-05\n",
      "Epoch 2575, Loss: 0.0031008835539978463, Final Batch Loss: 0.0030619704630225897\n",
      "Epoch 2576, Loss: 8.006820098671596e-05, Final Batch Loss: 2.225911339337472e-05\n",
      "Epoch 2577, Loss: 0.0003776559060497675, Final Batch Loss: 2.744759331108071e-05\n",
      "Epoch 2578, Loss: 5.529440704776789e-05, Final Batch Loss: 4.852206984651275e-05\n",
      "Epoch 2579, Loss: 0.00045949817467771936, Final Batch Loss: 0.0004308193165343255\n",
      "Epoch 2580, Loss: 0.00013324868814379442, Final Batch Loss: 0.00011075761722167954\n",
      "Epoch 2581, Loss: 0.0003663352254079655, Final Batch Loss: 3.06931760860607e-05\n",
      "Epoch 2582, Loss: 3.8305712450892315e-05, Final Batch Loss: 3.7716711176472018e-06\n",
      "Epoch 2583, Loss: 1.7862740151031176e-05, Final Batch Loss: 1.4725584151165094e-05\n",
      "Epoch 2584, Loss: 0.00023972611961653456, Final Batch Loss: 4.376835568109527e-05\n",
      "Epoch 2585, Loss: 0.0015848417697270634, Final Batch Loss: 1.8907145204138942e-05\n",
      "Epoch 2586, Loss: 9.875514933810337e-05, Final Batch Loss: 8.889609307516366e-05\n",
      "Epoch 2587, Loss: 3.180057842655515e-05, Final Batch Loss: 2.2027249997336185e-06\n",
      "Epoch 2588, Loss: 3.89527758670738e-05, Final Batch Loss: 1.8437576727592386e-05\n",
      "Epoch 2589, Loss: 3.962964183301665e-05, Final Batch Loss: 1.185038490802981e-05\n",
      "Epoch 2590, Loss: 0.000987217123110895, Final Batch Loss: 1.6581851014052518e-05\n",
      "Epoch 2591, Loss: 0.0004012508870800957, Final Batch Loss: 3.879379073623568e-05\n",
      "Epoch 2592, Loss: 0.00017298490456596483, Final Batch Loss: 0.0001446661917725578\n",
      "Epoch 2593, Loss: 4.0562541471445e-05, Final Batch Loss: 2.8899845347041264e-05\n",
      "Epoch 2594, Loss: 0.013414082121471438, Final Batch Loss: 4.03263084081118e-06\n",
      "Epoch 2595, Loss: 0.00018818584067048505, Final Batch Loss: 8.906259608920664e-05\n",
      "Epoch 2596, Loss: 0.0006274750448937993, Final Batch Loss: 0.0005847418797202408\n",
      "Epoch 2597, Loss: 0.00010641597873473074, Final Batch Loss: 7.648016617167741e-05\n",
      "Epoch 2598, Loss: 0.0002237147946289042, Final Batch Loss: 1.537943353469018e-05\n",
      "Epoch 2599, Loss: 0.00028284384745802527, Final Batch Loss: 1.565541538184334e-06\n",
      "Epoch 2600, Loss: 2.4189413352360134e-05, Final Batch Loss: 3.5574805679061683e-06\n",
      "Epoch 2601, Loss: 0.00015541152561127092, Final Batch Loss: 5.475517809827579e-06\n",
      "Epoch 2602, Loss: 0.00016577015776420012, Final Batch Loss: 0.0001401407498633489\n",
      "Epoch 2603, Loss: 2.269487822559313e-05, Final Batch Loss: 1.5451149010914378e-05\n",
      "Epoch 2604, Loss: 5.986959513393231e-05, Final Batch Loss: 2.946504537248984e-06\n",
      "Epoch 2605, Loss: 7.26798261894146e-05, Final Batch Loss: 5.518073157873005e-05\n",
      "Epoch 2606, Loss: 0.0005477323720697314, Final Batch Loss: 0.0002697049349080771\n",
      "Epoch 2607, Loss: 0.00012153279385529459, Final Batch Loss: 3.390273923287168e-05\n",
      "Epoch 2608, Loss: 0.0002392567002971191, Final Batch Loss: 3.528166053001769e-05\n",
      "Epoch 2609, Loss: 0.00027242405394645175, Final Batch Loss: 0.00026204256573691964\n",
      "Epoch 2610, Loss: 2.3919792511151172e-05, Final Batch Loss: 7.977278073667549e-06\n",
      "Epoch 2611, Loss: 0.0004278373780834954, Final Batch Loss: 3.842952355626039e-05\n",
      "Epoch 2612, Loss: 4.292261746741133e-05, Final Batch Loss: 3.235909389331937e-05\n",
      "Epoch 2613, Loss: 0.00020363067596917972, Final Batch Loss: 0.00014729776012245566\n",
      "Epoch 2614, Loss: 0.0010664971632650122, Final Batch Loss: 0.0009261562954634428\n",
      "Epoch 2615, Loss: 0.0028555576100188773, Final Batch Loss: 4.841935515287332e-05\n",
      "Epoch 2616, Loss: 0.00020320280964369886, Final Batch Loss: 0.00016382421017624438\n",
      "Epoch 2617, Loss: 5.8529919897409854e-05, Final Batch Loss: 4.808603534911526e-06\n",
      "Epoch 2618, Loss: 0.0008104799489956349, Final Batch Loss: 0.0003095062274951488\n",
      "Epoch 2619, Loss: 0.0008148434717440978, Final Batch Loss: 0.0007399578462354839\n",
      "Epoch 2620, Loss: 8.778257415542612e-05, Final Batch Loss: 7.346382517425809e-06\n",
      "Epoch 2621, Loss: 0.00012802552055291017, Final Batch Loss: 7.349754469032632e-06\n",
      "Epoch 2622, Loss: 0.0006389007394318469, Final Batch Loss: 3.4555741876829416e-05\n",
      "Epoch 2623, Loss: 0.00032242470115306787, Final Batch Loss: 5.106681419420056e-05\n",
      "Epoch 2624, Loss: 0.00028814192774007097, Final Batch Loss: 0.000271069526206702\n",
      "Epoch 2625, Loss: 4.5235006837174296e-05, Final Batch Loss: 3.592394932638854e-05\n",
      "Epoch 2626, Loss: 5.04048202856211e-05, Final Batch Loss: 3.175063102389686e-05\n",
      "Epoch 2627, Loss: 0.0007658344475203194, Final Batch Loss: 0.0007340384181588888\n",
      "Epoch 2628, Loss: 0.00012355940270936117, Final Batch Loss: 8.779347263043746e-05\n",
      "Epoch 2629, Loss: 0.000531754812982399, Final Batch Loss: 0.0004396782023832202\n",
      "Epoch 2630, Loss: 4.167366569163278e-05, Final Batch Loss: 1.9168008293490857e-05\n",
      "Epoch 2631, Loss: 0.00035231304354965687, Final Batch Loss: 0.00013337668497115374\n",
      "Epoch 2632, Loss: 0.00010368322546128184, Final Batch Loss: 7.04571939422749e-05\n",
      "Epoch 2633, Loss: 6.268197375902673e-05, Final Batch Loss: 5.551673530135304e-05\n",
      "Epoch 2634, Loss: 1.0045458566310117e-05, Final Batch Loss: 5.693306320608826e-06\n",
      "Epoch 2635, Loss: 0.008507530776796557, Final Batch Loss: 3.109326598860207e-06\n",
      "Epoch 2636, Loss: 0.0002343570304219611, Final Batch Loss: 0.00021249751443974674\n",
      "Epoch 2637, Loss: 0.00010066101822303608, Final Batch Loss: 3.378446854185313e-05\n",
      "Epoch 2638, Loss: 7.361624034274428e-05, Final Batch Loss: 3.1252786811819533e-06\n",
      "Epoch 2639, Loss: 0.00011732603707059752, Final Batch Loss: 2.9171174901421182e-05\n",
      "Epoch 2640, Loss: 6.481499440269545e-05, Final Batch Loss: 4.035804886370897e-05\n",
      "Epoch 2641, Loss: 3.6477971661952324e-05, Final Batch Loss: 1.7236374333151616e-05\n",
      "Epoch 2642, Loss: 3.4515159370585025e-06, Final Batch Loss: 3.3831580026344454e-07\n",
      "Epoch 2643, Loss: 0.0002534016311983578, Final Batch Loss: 6.718475924571976e-05\n",
      "Epoch 2644, Loss: 0.00010142301653104369, Final Batch Loss: 2.5324750822619535e-05\n",
      "Epoch 2645, Loss: 4.6647637645946816e-05, Final Batch Loss: 8.323491783812642e-06\n",
      "Epoch 2646, Loss: 0.00032731657302065287, Final Batch Loss: 2.18824661715189e-05\n",
      "Epoch 2647, Loss: 0.00020733638848469127, Final Batch Loss: 5.773823431809433e-06\n",
      "Epoch 2648, Loss: 4.0401202568318695e-05, Final Batch Loss: 2.3435992261511274e-05\n",
      "Epoch 2649, Loss: 0.0002287022871314548, Final Batch Loss: 6.254563777474687e-05\n",
      "Epoch 2650, Loss: 0.00019410328422964085, Final Batch Loss: 0.0001782189356163144\n",
      "Epoch 2651, Loss: 2.9231336384327733e-05, Final Batch Loss: 3.3157941743411357e-06\n",
      "Epoch 2652, Loss: 7.56162844481878e-05, Final Batch Loss: 5.754038647864945e-05\n",
      "Epoch 2653, Loss: 0.00033553611137904227, Final Batch Loss: 0.0002519266854505986\n",
      "Epoch 2654, Loss: 4.0081178667605855e-05, Final Batch Loss: 3.068503428949043e-05\n",
      "Epoch 2655, Loss: 3.115451727353502e-05, Final Batch Loss: 1.8980668755830266e-05\n",
      "Epoch 2656, Loss: 2.5428154913242906e-05, Final Batch Loss: 8.7547923612874e-06\n",
      "Epoch 2657, Loss: 0.0008888537413440645, Final Batch Loss: 0.000310884031932801\n",
      "Epoch 2658, Loss: 0.00022760701267543482, Final Batch Loss: 0.00022125322720967233\n",
      "Epoch 2659, Loss: 0.011290267575532198, Final Batch Loss: 0.002799451816827059\n",
      "Epoch 2660, Loss: 0.0006381229113685549, Final Batch Loss: 0.0006290577002801001\n",
      "Epoch 2661, Loss: 2.7392987249186262e-05, Final Batch Loss: 1.4007268873683643e-05\n",
      "Epoch 2662, Loss: 0.00016113165293063503, Final Batch Loss: 0.00014060795365367085\n",
      "Epoch 2663, Loss: 2.7529269686965563e-05, Final Batch Loss: 7.177660563684185e-07\n",
      "Epoch 2664, Loss: 6.529426900669932e-05, Final Batch Loss: 1.8371578335063532e-05\n",
      "Epoch 2665, Loss: 1.962688929779688e-05, Final Batch Loss: 1.1736994565580972e-05\n",
      "Epoch 2666, Loss: 1.9085605345026124e-05, Final Batch Loss: 8.90167666511843e-06\n",
      "Epoch 2667, Loss: 0.00013501584544428624, Final Batch Loss: 4.233187428326346e-05\n",
      "Epoch 2668, Loss: 0.00012015707534374087, Final Batch Loss: 6.51119398753508e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2669, Loss: 0.00030396249348996207, Final Batch Loss: 1.8620099581312388e-05\n",
      "Epoch 2670, Loss: 0.001579172363562975, Final Batch Loss: 0.0015496989944949746\n",
      "Epoch 2671, Loss: 0.0009712156897876412, Final Batch Loss: 0.0004775483103003353\n",
      "Epoch 2672, Loss: 5.445529495773371e-05, Final Batch Loss: 2.8065815058653243e-05\n",
      "Epoch 2673, Loss: 0.00011581633043533657, Final Batch Loss: 1.847910061769653e-05\n",
      "Epoch 2674, Loss: 0.0001266388499061577, Final Batch Loss: 4.1503131797071546e-05\n",
      "Epoch 2675, Loss: 0.00077790193608962, Final Batch Loss: 0.00019425104255788028\n",
      "Epoch 2676, Loss: 0.0008761409990256652, Final Batch Loss: 0.0006990014808252454\n",
      "Epoch 2677, Loss: 4.999103839509189e-05, Final Batch Loss: 6.616606697207317e-06\n",
      "Epoch 2678, Loss: 0.00012163968676759396, Final Batch Loss: 9.741930989548564e-05\n",
      "Epoch 2679, Loss: 0.00016685823356965557, Final Batch Loss: 3.407774056540802e-05\n",
      "Epoch 2680, Loss: 4.367311339592561e-05, Final Batch Loss: 1.5301959138014354e-05\n",
      "Epoch 2681, Loss: 0.00011708740203175694, Final Batch Loss: 6.887396739330143e-05\n",
      "Epoch 2682, Loss: 9.485461123404093e-05, Final Batch Loss: 5.9152807807549834e-05\n",
      "Epoch 2683, Loss: 0.0012229236417624634, Final Batch Loss: 3.8092501199571416e-05\n",
      "Epoch 2684, Loss: 0.00010161141108255833, Final Batch Loss: 5.0732465751934797e-05\n",
      "Epoch 2685, Loss: 4.284976967028342e-06, Final Batch Loss: 1.9500944290484767e-06\n",
      "Epoch 2686, Loss: 8.271780507129733e-05, Final Batch Loss: 5.129677902004914e-06\n",
      "Epoch 2687, Loss: 5.108815548737766e-05, Final Batch Loss: 4.3238895159447566e-05\n",
      "Epoch 2688, Loss: 8.294487270177342e-05, Final Batch Loss: 4.4769334635930136e-05\n",
      "Epoch 2689, Loss: 0.0003060638300667051, Final Batch Loss: 3.29042122757528e-05\n",
      "Epoch 2690, Loss: 0.0005695822983398102, Final Batch Loss: 0.0004975175252184272\n",
      "Epoch 2691, Loss: 0.00011831687129415513, Final Batch Loss: 2.728985919020488e-06\n",
      "Epoch 2692, Loss: 4.3551433918764815e-05, Final Batch Loss: 2.603836401249282e-05\n",
      "Epoch 2693, Loss: 8.886431260179961e-06, Final Batch Loss: 2.4981341084640007e-06\n",
      "Epoch 2694, Loss: 0.00046358829354176123, Final Batch Loss: 0.0004611823824234307\n",
      "Epoch 2695, Loss: 4.85698296870396e-05, Final Batch Loss: 7.044604444672586e-06\n",
      "Epoch 2696, Loss: 3.359861375429318e-05, Final Batch Loss: 2.729349580476992e-05\n",
      "Epoch 2697, Loss: 0.00047072634333744645, Final Batch Loss: 0.00039117562118917704\n",
      "Epoch 2698, Loss: 7.657931701032794e-05, Final Batch Loss: 5.7720185395737644e-06\n",
      "Epoch 2699, Loss: 0.00021026339891250245, Final Batch Loss: 1.6709218471078202e-05\n",
      "Epoch 2700, Loss: 6.138383332654485e-05, Final Batch Loss: 5.5485765187768266e-05\n",
      "Epoch 2701, Loss: 0.0001388995224260725, Final Batch Loss: 8.218463335651904e-06\n",
      "Epoch 2702, Loss: 9.753299036674434e-05, Final Batch Loss: 1.3874800970370416e-05\n",
      "Epoch 2703, Loss: 9.124626785705914e-06, Final Batch Loss: 3.572622290448635e-06\n",
      "Epoch 2704, Loss: 8.550155371267465e-06, Final Batch Loss: 5.111478913022438e-06\n",
      "Epoch 2705, Loss: 7.990775645794201e-05, Final Batch Loss: 2.711561819523922e-07\n",
      "Epoch 2706, Loss: 0.0005195845442358404, Final Batch Loss: 0.00030880520353093743\n",
      "Epoch 2707, Loss: 0.00011252329932176508, Final Batch Loss: 8.648683433420956e-05\n",
      "Epoch 2708, Loss: 5.11591197209782e-05, Final Batch Loss: 4.757321221404709e-05\n",
      "Epoch 2709, Loss: 0.010625484820195652, Final Batch Loss: 8.218472089538409e-07\n",
      "Epoch 2710, Loss: 8.474750643472362e-06, Final Batch Loss: 1.6042248489611666e-06\n",
      "Epoch 2711, Loss: 8.925278234528378e-05, Final Batch Loss: 4.4211858039489016e-05\n",
      "Epoch 2712, Loss: 5.205001434660517e-05, Final Batch Loss: 1.938749846885912e-05\n",
      "Epoch 2713, Loss: 0.00016517783660674468, Final Batch Loss: 2.7111855160910636e-05\n",
      "Epoch 2714, Loss: 0.00023800453345756978, Final Batch Loss: 7.139645458664745e-05\n",
      "Epoch 2715, Loss: 1.2355065450719849e-05, Final Batch Loss: 1.1601742926359293e-06\n",
      "Epoch 2716, Loss: 6.708962700940901e-05, Final Batch Loss: 1.4996098798292223e-05\n",
      "Epoch 2717, Loss: 0.000954342212935444, Final Batch Loss: 0.0009265908156521618\n",
      "Epoch 2718, Loss: 8.22168249214883e-06, Final Batch Loss: 4.2280562411178835e-06\n",
      "Epoch 2719, Loss: 1.4985867437644629e-05, Final Batch Loss: 9.140730981016532e-06\n",
      "Epoch 2720, Loss: 0.00010761740759335225, Final Batch Loss: 0.00010059007763629779\n",
      "Epoch 2721, Loss: 5.849371552812954e-05, Final Batch Loss: 9.905892284223228e-07\n",
      "Epoch 2722, Loss: 2.4142593019860215e-05, Final Batch Loss: 2.0775948996742954e-06\n",
      "Epoch 2723, Loss: 0.0001208941441745992, Final Batch Loss: 0.00011744729272322729\n",
      "Epoch 2724, Loss: 0.00011966199053858873, Final Batch Loss: 1.1517919119796716e-05\n",
      "Epoch 2725, Loss: 0.00010350383308832534, Final Batch Loss: 8.93946344149299e-06\n",
      "Epoch 2726, Loss: 0.00012124117347411811, Final Batch Loss: 8.092353527899832e-05\n",
      "Epoch 2727, Loss: 0.00010448898956383346, Final Batch Loss: 1.001951295620529e-05\n",
      "Epoch 2728, Loss: 5.4117851504997816e-05, Final Batch Loss: 4.392228584038094e-05\n",
      "Epoch 2729, Loss: 0.0033799531443037267, Final Batch Loss: 2.8524586923595052e-06\n",
      "Epoch 2730, Loss: 0.001524131468613632, Final Batch Loss: 0.0014771491987630725\n",
      "Epoch 2731, Loss: 9.55742734731757e-06, Final Batch Loss: 3.7053214327897877e-06\n",
      "Epoch 2732, Loss: 0.00015223930586216738, Final Batch Loss: 0.00014967839524615556\n",
      "Epoch 2733, Loss: 0.00010847940029634628, Final Batch Loss: 2.8059732358087786e-05\n",
      "Epoch 2734, Loss: 0.0003480844834484742, Final Batch Loss: 1.039762810250977e-05\n",
      "Epoch 2735, Loss: 1.8387661839369684e-05, Final Batch Loss: 1.1895638635905925e-05\n",
      "Epoch 2736, Loss: 3.739786370715592e-05, Final Batch Loss: 9.037892596097663e-06\n",
      "Epoch 2737, Loss: 7.354369336098898e-05, Final Batch Loss: 4.639013059204444e-05\n",
      "Epoch 2738, Loss: 6.652592401223956e-05, Final Batch Loss: 1.0059701708087232e-05\n",
      "Epoch 2739, Loss: 0.00014970869597163983, Final Batch Loss: 5.341136784409173e-05\n",
      "Epoch 2740, Loss: 1.3832275726599619e-05, Final Batch Loss: 6.80228504279512e-06\n",
      "Epoch 2741, Loss: 5.359281203709543e-05, Final Batch Loss: 2.6475845515960827e-05\n",
      "Epoch 2742, Loss: 9.976764431485208e-06, Final Batch Loss: 7.67584606364835e-06\n",
      "Epoch 2743, Loss: 0.00011953535431530327, Final Batch Loss: 6.070894960430451e-05\n",
      "Epoch 2744, Loss: 4.445773083716631e-05, Final Batch Loss: 8.125174645101652e-06\n",
      "Epoch 2745, Loss: 2.8755142466252437e-05, Final Batch Loss: 3.62706077794428e-06\n",
      "Epoch 2746, Loss: 4.2363200918771327e-05, Final Batch Loss: 1.5529525626334362e-05\n",
      "Epoch 2747, Loss: 2.5123290924966568e-05, Final Batch Loss: 7.091050520102726e-06\n",
      "Epoch 2748, Loss: 0.002438451383454776, Final Batch Loss: 0.0024373780470341444\n",
      "Epoch 2749, Loss: 9.534945456834976e-05, Final Batch Loss: 1.1912883564946242e-05\n",
      "Epoch 2750, Loss: 0.00025070908122870605, Final Batch Loss: 1.7202297385665588e-05\n",
      "Epoch 2751, Loss: 7.465562930519809e-06, Final Batch Loss: 4.467325197765604e-06\n",
      "Epoch 2752, Loss: 5.465102549351286e-05, Final Batch Loss: 1.2400631021591835e-05\n",
      "Epoch 2753, Loss: 0.0002163720564567484, Final Batch Loss: 4.0921739127952605e-05\n",
      "Epoch 2754, Loss: 0.0004317119737606845, Final Batch Loss: 7.439447472279426e-06\n",
      "Epoch 2755, Loss: 0.0003076634784520138, Final Batch Loss: 0.00027215652517043054\n",
      "Epoch 2756, Loss: 0.0005839312725584023, Final Batch Loss: 9.380693518323824e-05\n",
      "Epoch 2757, Loss: 7.00572700225166e-05, Final Batch Loss: 6.539402238558978e-05\n",
      "Epoch 2758, Loss: 5.298370388118201e-05, Final Batch Loss: 4.6327120799105614e-05\n",
      "Epoch 2759, Loss: 0.0001111148449126631, Final Batch Loss: 0.00010749080684036016\n",
      "Epoch 2760, Loss: 0.00023236464733145112, Final Batch Loss: 6.48083755550033e-07\n",
      "Epoch 2761, Loss: 5.9109353060193826e-05, Final Batch Loss: 4.4226108002476394e-05\n",
      "Epoch 2762, Loss: 0.00047717391680635046, Final Batch Loss: 0.00046557627501897514\n",
      "Epoch 2763, Loss: 3.936146640626248e-05, Final Batch Loss: 2.319316081411671e-05\n",
      "Epoch 2764, Loss: 4.405325796597026e-06, Final Batch Loss: 7.102111680978851e-07\n",
      "Epoch 2765, Loss: 6.037402454239782e-05, Final Batch Loss: 1.0238070899504237e-05\n",
      "Epoch 2766, Loss: 4.869667645834852e-05, Final Batch Loss: 3.0483441150863655e-05\n",
      "Epoch 2767, Loss: 6.0840971855213866e-05, Final Batch Loss: 4.1077062633121386e-05\n",
      "Epoch 2768, Loss: 0.0011582962761167437, Final Batch Loss: 0.0011317981407046318\n",
      "Epoch 2769, Loss: 3.5596709778928926e-05, Final Batch Loss: 8.856625868247647e-07\n",
      "Epoch 2770, Loss: 5.554850076805451e-05, Final Batch Loss: 5.99147324464866e-06\n",
      "Epoch 2771, Loss: 0.0024053689812717494, Final Batch Loss: 5.9785812482004985e-05\n",
      "Epoch 2772, Loss: 0.00011720836323547701, Final Batch Loss: 0.00011460077803349122\n",
      "Epoch 2773, Loss: 2.6913450767551694e-05, Final Batch Loss: 6.883729497531021e-07\n",
      "Epoch 2774, Loss: 1.622613990548416e-05, Final Batch Loss: 2.5201247808581684e-06\n",
      "Epoch 2775, Loss: 0.0003336549744972217, Final Batch Loss: 1.7150488247352769e-06\n",
      "Epoch 2776, Loss: 5.289954401632713e-06, Final Batch Loss: 4.1585035432945006e-06\n",
      "Epoch 2777, Loss: 0.003798787613050081, Final Batch Loss: 0.00017202961316797882\n",
      "Epoch 2778, Loss: 0.00011115238885395229, Final Batch Loss: 3.6642333725467324e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2779, Loss: 0.0004514307074714452, Final Batch Loss: 0.0002924312721006572\n",
      "Epoch 2780, Loss: 0.0004106978431082098, Final Batch Loss: 4.232320861774497e-06\n",
      "Epoch 2781, Loss: 0.00012150344264227897, Final Batch Loss: 4.985932901035994e-05\n",
      "Epoch 2782, Loss: 0.00042718807299024775, Final Batch Loss: 0.0004197873058728874\n",
      "Epoch 2783, Loss: 0.0009829405462369323, Final Batch Loss: 0.0005098058609291911\n",
      "Epoch 2784, Loss: 0.001575222215251415, Final Batch Loss: 6.851250873296522e-06\n",
      "Epoch 2785, Loss: 0.0005026740545872599, Final Batch Loss: 0.00033920383430086076\n",
      "Epoch 2786, Loss: 4.153290728936554e-05, Final Batch Loss: 3.815296440734528e-05\n",
      "Epoch 2787, Loss: 0.00011195644765393808, Final Batch Loss: 8.938463724916801e-05\n",
      "Epoch 2788, Loss: 1.4202807506080717e-05, Final Batch Loss: 1.9265953596914187e-06\n",
      "Epoch 2789, Loss: 4.036173231725115e-05, Final Batch Loss: 1.2056460036546923e-05\n",
      "Epoch 2790, Loss: 0.00047012057666506735, Final Batch Loss: 3.558962362149032e-06\n",
      "Epoch 2791, Loss: 0.00025206118903042807, Final Batch Loss: 0.00024982207105495036\n",
      "Epoch 2792, Loss: 4.456284113985021e-05, Final Batch Loss: 1.972212703549303e-05\n",
      "Epoch 2793, Loss: 0.0006151386769488454, Final Batch Loss: 0.000544288894161582\n",
      "Epoch 2794, Loss: 5.014051112084417e-05, Final Batch Loss: 4.94821051688632e-06\n",
      "Epoch 2795, Loss: 0.007077603440848179, Final Batch Loss: 0.00695708068087697\n",
      "Epoch 2796, Loss: 1.7257380022783764e-05, Final Batch Loss: 1.0822793228726368e-05\n",
      "Epoch 2797, Loss: 2.794669671857264e-05, Final Batch Loss: 1.0822992408066057e-05\n",
      "Epoch 2798, Loss: 4.989259650756139e-05, Final Batch Loss: 3.502137042232789e-05\n",
      "Epoch 2799, Loss: 0.0005034782516304404, Final Batch Loss: 0.00026569669716991484\n",
      "Epoch 2800, Loss: 0.021531385369598866, Final Batch Loss: 0.014552532695233822\n",
      "Epoch 2801, Loss: 3.3181619983224664e-05, Final Batch Loss: 2.4496626792824827e-05\n",
      "Epoch 2802, Loss: 0.00023848940691095777, Final Batch Loss: 0.00018594993161968887\n",
      "Epoch 2803, Loss: 0.0008351336946361698, Final Batch Loss: 0.0008143811719492078\n",
      "Epoch 2804, Loss: 2.0383341393426235e-05, Final Batch Loss: 1.2222780014781165e-06\n",
      "Epoch 2805, Loss: 4.534197614702862e-05, Final Batch Loss: 2.4891915018088184e-05\n",
      "Epoch 2806, Loss: 2.885105732275406e-05, Final Batch Loss: 5.209310074860696e-06\n",
      "Epoch 2807, Loss: 1.8088144997818745e-05, Final Batch Loss: 3.179876102876733e-06\n",
      "Epoch 2808, Loss: 1.0006810725826654e-05, Final Batch Loss: 7.05412230672664e-06\n",
      "Epoch 2809, Loss: 8.783318162386422e-05, Final Batch Loss: 8.549106860300526e-05\n",
      "Epoch 2810, Loss: 6.35324977338314e-05, Final Batch Loss: 3.1873612897470593e-05\n",
      "Epoch 2811, Loss: 0.0002024929090111982, Final Batch Loss: 5.062613854533993e-05\n",
      "Epoch 2812, Loss: 0.0004775090746989008, Final Batch Loss: 0.000426201761001721\n",
      "Epoch 2813, Loss: 0.00040435876144329086, Final Batch Loss: 0.00032840759376995265\n",
      "Epoch 2814, Loss: 3.757821104954928e-05, Final Batch Loss: 1.691931174718775e-05\n",
      "Epoch 2815, Loss: 1.0810604408106883e-05, Final Batch Loss: 9.047823368746322e-06\n",
      "Epoch 2816, Loss: 2.6755935323308222e-05, Final Batch Loss: 2.216167740698438e-05\n",
      "Epoch 2817, Loss: 0.00023590592627442675, Final Batch Loss: 0.0002281752385897562\n",
      "Epoch 2818, Loss: 0.0003639528149506077, Final Batch Loss: 0.00032868131529539824\n",
      "Epoch 2819, Loss: 2.2012168301444035e-05, Final Batch Loss: 8.223291843023617e-06\n",
      "Epoch 2820, Loss: 8.062163828981284e-06, Final Batch Loss: 1.7200576394316158e-06\n",
      "Epoch 2821, Loss: 0.00014939244647393934, Final Batch Loss: 4.569983502733521e-05\n",
      "Epoch 2822, Loss: 4.021280619781464e-05, Final Batch Loss: 1.9054850781685673e-05\n",
      "Epoch 2823, Loss: 0.000186705630767392, Final Batch Loss: 0.00015555329446215183\n",
      "Epoch 2824, Loss: 0.0007389498350676149, Final Batch Loss: 0.000555235892534256\n",
      "Epoch 2825, Loss: 0.0023730268512736075, Final Batch Loss: 0.0022519659250974655\n",
      "Epoch 2826, Loss: 0.00041941713061532937, Final Batch Loss: 3.220550934202038e-05\n",
      "Epoch 2827, Loss: 0.0007915172391221859, Final Batch Loss: 1.6668556781951338e-05\n",
      "Epoch 2828, Loss: 1.923889431054704e-05, Final Batch Loss: 9.709548066894058e-06\n",
      "Epoch 2829, Loss: 0.009033478031597042, Final Batch Loss: 0.009030499495565891\n",
      "Epoch 2830, Loss: 0.00013649920947500505, Final Batch Loss: 2.1067175111966208e-05\n",
      "Epoch 2831, Loss: 7.80722739364137e-05, Final Batch Loss: 1.383001381327631e-05\n",
      "Epoch 2832, Loss: 1.2611551937879995e-05, Final Batch Loss: 7.318990355997812e-06\n",
      "Epoch 2833, Loss: 2.078799661830999e-05, Final Batch Loss: 9.404915545019321e-06\n",
      "Epoch 2834, Loss: 0.0004296784463804215, Final Batch Loss: 0.00025464396458119154\n",
      "Epoch 2835, Loss: 0.0002694340037123766, Final Batch Loss: 1.3475069863488898e-05\n",
      "Epoch 2836, Loss: 8.661347374072648e-05, Final Batch Loss: 6.230083727132296e-06\n",
      "Epoch 2837, Loss: 0.0003734051679202821, Final Batch Loss: 3.895250483765267e-05\n",
      "Epoch 2838, Loss: 2.3262099603016395e-05, Final Batch Loss: 1.9982526282547042e-05\n",
      "Epoch 2839, Loss: 0.0001391050245729275, Final Batch Loss: 5.6914708693511784e-05\n",
      "Epoch 2840, Loss: 2.0906205350001983e-05, Final Batch Loss: 1.1769624279622803e-06\n",
      "Epoch 2841, Loss: 1.3793825701213791e-05, Final Batch Loss: 1.7771324110071873e-06\n",
      "Epoch 2842, Loss: 2.275491942782537e-05, Final Batch Loss: 6.170872893562773e-06\n",
      "Epoch 2843, Loss: 4.1104501178779174e-05, Final Batch Loss: 2.99760140478611e-05\n",
      "Epoch 2844, Loss: 1.8294779238203773e-05, Final Batch Loss: 2.524099272704916e-06\n",
      "Epoch 2845, Loss: 2.621385283418931e-05, Final Batch Loss: 1.700090797385201e-05\n",
      "Epoch 2846, Loss: 0.00039239854231709614, Final Batch Loss: 0.00029939430532976985\n",
      "Epoch 2847, Loss: 0.0008712553244549781, Final Batch Loss: 0.00013140428927727044\n",
      "Epoch 2848, Loss: 3.237885630369419e-05, Final Batch Loss: 3.9605811252840795e-06\n",
      "Epoch 2849, Loss: 0.00016149930888786912, Final Batch Loss: 0.00010078446211991832\n",
      "Epoch 2850, Loss: 0.0003186445392202586, Final Batch Loss: 7.108491263352334e-05\n",
      "Epoch 2851, Loss: 7.490477582905442e-05, Final Batch Loss: 4.046348840347491e-05\n",
      "Epoch 2852, Loss: 0.0005529187728825491, Final Batch Loss: 5.9031368436990306e-05\n",
      "Epoch 2853, Loss: 0.0007196022534117219, Final Batch Loss: 0.0007046666578389704\n",
      "Epoch 2854, Loss: 0.0036082733950024704, Final Batch Loss: 2.284121364937164e-06\n",
      "Epoch 2855, Loss: 1.1473049880805775e-05, Final Batch Loss: 2.6695004180510296e-06\n",
      "Epoch 2856, Loss: 4.6041313908062875e-05, Final Batch Loss: 8.100680133793503e-06\n",
      "Epoch 2857, Loss: 6.420576255550259e-06, Final Batch Loss: 1.8955076939164428e-06\n",
      "Epoch 2858, Loss: 0.00021914039496095938, Final Batch Loss: 1.1425476031945436e-06\n",
      "Epoch 2859, Loss: 0.00019477840015724723, Final Batch Loss: 5.607833486465097e-07\n",
      "Epoch 2860, Loss: 1.953157652678783e-05, Final Batch Loss: 2.7080182007921394e-06\n",
      "Epoch 2861, Loss: 7.667277532164007e-05, Final Batch Loss: 6.159937038319185e-05\n",
      "Epoch 2862, Loss: 0.01060635127214482, Final Batch Loss: 0.010553540661931038\n",
      "Epoch 2863, Loss: 3.825068324658787e-05, Final Batch Loss: 8.0703093772172e-06\n",
      "Epoch 2864, Loss: 4.5292623212844774e-05, Final Batch Loss: 1.1081118600486661e-06\n",
      "Epoch 2865, Loss: 0.0004210795468679862, Final Batch Loss: 0.00039487413596361876\n",
      "Epoch 2866, Loss: 0.00019516734209901188, Final Batch Loss: 0.00017401142395101488\n",
      "Epoch 2867, Loss: 9.183877568830212e-05, Final Batch Loss: 8.935611549532041e-05\n",
      "Epoch 2868, Loss: 4.7436882596230134e-05, Final Batch Loss: 3.199096317985095e-05\n",
      "Epoch 2869, Loss: 0.00015530905966443243, Final Batch Loss: 1.4936628758732695e-05\n",
      "Epoch 2870, Loss: 0.0001705865106487181, Final Batch Loss: 5.312999201123603e-05\n",
      "Epoch 2871, Loss: 3.2353977985621896e-05, Final Batch Loss: 2.4073582608252764e-05\n",
      "Epoch 2872, Loss: 0.00015480140700674383, Final Batch Loss: 1.2698345926764887e-05\n",
      "Epoch 2873, Loss: 0.00030108030478004366, Final Batch Loss: 0.0001789242960512638\n",
      "Epoch 2874, Loss: 0.00011780121894844342, Final Batch Loss: 1.4277373338700272e-05\n",
      "Epoch 2875, Loss: 5.797728863399243e-05, Final Batch Loss: 4.747837920149323e-06\n",
      "Epoch 2876, Loss: 1.0593965726002352e-05, Final Batch Loss: 2.328676146134967e-06\n",
      "Epoch 2877, Loss: 0.00036946922773495317, Final Batch Loss: 7.423970964737236e-05\n",
      "Epoch 2878, Loss: 7.867145632189931e-05, Final Batch Loss: 4.3735972212743945e-06\n",
      "Epoch 2879, Loss: 4.536420965450816e-05, Final Batch Loss: 2.509902697056532e-05\n",
      "Epoch 2880, Loss: 5.654547166500379e-05, Final Batch Loss: 3.1145427215051313e-07\n",
      "Epoch 2881, Loss: 5.362623596738558e-05, Final Batch Loss: 2.7653233701130375e-05\n",
      "Epoch 2882, Loss: 4.430311764735961e-05, Final Batch Loss: 1.4732519957760815e-05\n",
      "Epoch 2883, Loss: 1.6807132851681672e-05, Final Batch Loss: 5.818828867631964e-06\n",
      "Epoch 2884, Loss: 7.451475312336697e-06, Final Batch Loss: 3.463909933998366e-06\n",
      "Epoch 2885, Loss: 0.0004778741131303832, Final Batch Loss: 0.0003539348836056888\n",
      "Epoch 2886, Loss: 0.00019108734704786912, Final Batch Loss: 4.09883723477833e-05\n",
      "Epoch 2887, Loss: 0.0023137484640756156, Final Batch Loss: 4.668417022912763e-05\n",
      "Epoch 2888, Loss: 0.0072360604208370205, Final Batch Loss: 0.007175725884735584\n",
      "Epoch 2889, Loss: 0.000908254980458878, Final Batch Loss: 1.241905556526035e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2890, Loss: 0.000623938432909199, Final Batch Loss: 2.1721740267821588e-05\n",
      "Epoch 2891, Loss: 0.00011503541827551089, Final Batch Loss: 4.554662518785335e-05\n",
      "Epoch 2892, Loss: 0.000173411492141895, Final Batch Loss: 6.243622920010239e-05\n",
      "Epoch 2893, Loss: 4.418818025442306e-05, Final Batch Loss: 3.756800288101658e-05\n",
      "Epoch 2894, Loss: 0.0003990275436080992, Final Batch Loss: 0.0002646897337399423\n",
      "Epoch 2895, Loss: 0.0007500691790482961, Final Batch Loss: 0.0006671315059065819\n",
      "Epoch 2896, Loss: 6.564074919879204e-05, Final Batch Loss: 1.031626288749976e-05\n",
      "Epoch 2897, Loss: 0.00027616232546279207, Final Batch Loss: 2.3508247977588326e-05\n",
      "Epoch 2898, Loss: 0.00018068350982503034, Final Batch Loss: 0.0001417393796145916\n",
      "Epoch 2899, Loss: 0.00012635045459319372, Final Batch Loss: 2.7960068109678105e-06\n",
      "Epoch 2900, Loss: 0.0005162104669125256, Final Batch Loss: 0.0005128530319780111\n",
      "Epoch 2901, Loss: 0.0003591937966120895, Final Batch Loss: 3.126961746602319e-05\n",
      "Epoch 2902, Loss: 4.1900892938429024e-05, Final Batch Loss: 1.2853585758421104e-05\n",
      "Epoch 2903, Loss: 2.4618420866318047e-05, Final Batch Loss: 2.0203902749926783e-05\n",
      "Epoch 2904, Loss: 0.00018170117982663214, Final Batch Loss: 0.00010605296847643331\n",
      "Epoch 2905, Loss: 0.0006439975841203704, Final Batch Loss: 0.0005175357800908387\n",
      "Epoch 2906, Loss: 6.467661069109454e-05, Final Batch Loss: 5.776301259174943e-05\n",
      "Epoch 2907, Loss: 0.0016623298233753303, Final Batch Loss: 0.001634369371458888\n",
      "Epoch 2908, Loss: 6.118556120782159e-05, Final Batch Loss: 4.619553510565311e-05\n",
      "Epoch 2909, Loss: 9.118049820244778e-05, Final Batch Loss: 6.836162356194109e-05\n",
      "Epoch 2910, Loss: 6.54284049232956e-05, Final Batch Loss: 1.3659664546139538e-05\n",
      "Epoch 2911, Loss: 0.00010123196989297867, Final Batch Loss: 7.491311407648027e-06\n",
      "Epoch 2912, Loss: 7.07124563632533e-05, Final Batch Loss: 3.549587563611567e-05\n",
      "Epoch 2913, Loss: 6.127863434812753e-05, Final Batch Loss: 5.106729076942429e-05\n",
      "Epoch 2914, Loss: 5.354215602437762e-05, Final Batch Loss: 5.19563072884921e-05\n",
      "Epoch 2915, Loss: 3.734223355422728e-05, Final Batch Loss: 2.5306371753686108e-05\n",
      "Epoch 2916, Loss: 1.8627640429258463e-05, Final Batch Loss: 2.909465592892957e-06\n",
      "Epoch 2917, Loss: 0.00010174610906688031, Final Batch Loss: 8.091086783679202e-05\n",
      "Epoch 2918, Loss: 1.65016367645876e-05, Final Batch Loss: 9.863404557108879e-06\n",
      "Epoch 2919, Loss: 0.00048062992573250085, Final Batch Loss: 7.805872883182019e-05\n",
      "Epoch 2920, Loss: 4.216365960019175e-05, Final Batch Loss: 2.6109632017323747e-05\n",
      "Epoch 2921, Loss: 6.778068382118363e-05, Final Batch Loss: 3.907884092768654e-05\n",
      "Epoch 2922, Loss: 0.00030234292626118986, Final Batch Loss: 3.5825023587676696e-06\n",
      "Epoch 2923, Loss: 8.105273809633218e-05, Final Batch Loss: 4.345698107499629e-05\n",
      "Epoch 2924, Loss: 0.00017848531570052728, Final Batch Loss: 0.00016114517347887158\n",
      "Epoch 2925, Loss: 0.0004290690994821489, Final Batch Loss: 0.0001546726271044463\n",
      "Epoch 2926, Loss: 0.00016839379168231972, Final Batch Loss: 2.9311577236512676e-05\n",
      "Epoch 2927, Loss: 3.972102194893523e-05, Final Batch Loss: 3.935799668397522e-06\n",
      "Epoch 2928, Loss: 2.9361363431235077e-05, Final Batch Loss: 5.004040303902002e-06\n",
      "Epoch 2929, Loss: 0.0005355683142624912, Final Batch Loss: 0.0005215902929194272\n",
      "Epoch 2930, Loss: 2.7564142328628805e-05, Final Batch Loss: 1.0442759048601147e-05\n",
      "Epoch 2931, Loss: 2.7391137336962856e-05, Final Batch Loss: 5.8363875723443925e-06\n",
      "Epoch 2932, Loss: 7.770682896079961e-05, Final Batch Loss: 6.928423681529239e-05\n",
      "Epoch 2933, Loss: 4.729597640107386e-05, Final Batch Loss: 2.0630819562938996e-05\n",
      "Epoch 2934, Loss: 0.00018793814842865686, Final Batch Loss: 5.049517767474754e-06\n",
      "Epoch 2935, Loss: 0.0001345056534773903, Final Batch Loss: 0.00010803627083078027\n",
      "Epoch 2936, Loss: 0.000933533170609735, Final Batch Loss: 7.930594438221306e-05\n",
      "Epoch 2937, Loss: 3.372118499100907e-05, Final Batch Loss: 2.1073734387755394e-05\n",
      "Epoch 2938, Loss: 0.00012483997488743626, Final Batch Loss: 3.4941545891342685e-05\n",
      "Epoch 2939, Loss: 3.0436466659011785e-05, Final Batch Loss: 2.4428254619124345e-06\n",
      "Epoch 2940, Loss: 0.0004182881639280822, Final Batch Loss: 2.7587808290263638e-05\n",
      "Epoch 2941, Loss: 0.0002687561864149757, Final Batch Loss: 0.00011139413254568353\n",
      "Epoch 2942, Loss: 8.213400860768161e-05, Final Batch Loss: 5.492920081451302e-06\n",
      "Epoch 2943, Loss: 3.086715969402576e-05, Final Batch Loss: 7.5473953984328546e-06\n",
      "Epoch 2944, Loss: 0.0015234305337799015, Final Batch Loss: 1.2496910130721517e-05\n",
      "Epoch 2945, Loss: 9.649318326410139e-05, Final Batch Loss: 1.0835800821951125e-05\n",
      "Epoch 2946, Loss: 0.0004670425259973854, Final Batch Loss: 0.00030892863287590444\n",
      "Epoch 2947, Loss: 6.506436693598516e-05, Final Batch Loss: 3.904145705746487e-05\n",
      "Epoch 2948, Loss: 1.1017009910574416e-05, Final Batch Loss: 6.3776742535992526e-06\n",
      "Epoch 2949, Loss: 1.5058741837492562e-05, Final Batch Loss: 2.49711024480348e-06\n",
      "Epoch 2950, Loss: 0.010764449265934672, Final Batch Loss: 0.01075736153870821\n",
      "Epoch 2951, Loss: 1.6388928543165093e-05, Final Batch Loss: 1.1966657439188566e-05\n",
      "Epoch 2952, Loss: 0.00022330318427066231, Final Batch Loss: 0.00022213213378563523\n",
      "Epoch 2953, Loss: 4.806113042832294e-05, Final Batch Loss: 4.523844108916819e-05\n",
      "Epoch 2954, Loss: 3.928417845600052e-05, Final Batch Loss: 2.5968660338548943e-05\n",
      "Epoch 2955, Loss: 0.00011542933498276398, Final Batch Loss: 4.158556112088263e-05\n",
      "Epoch 2956, Loss: 0.0047741870380377804, Final Batch Loss: 5.423075890576001e-07\n",
      "Epoch 2957, Loss: 0.0001283255041926168, Final Batch Loss: 0.00010712441144278273\n",
      "Epoch 2958, Loss: 4.371857312435168e-05, Final Batch Loss: 5.436875198938651e-06\n",
      "Epoch 2959, Loss: 4.971886136218018e-05, Final Batch Loss: 8.134649647217884e-07\n",
      "Epoch 2960, Loss: 2.871400442927552e-05, Final Batch Loss: 1.7259151263715466e-06\n",
      "Epoch 2961, Loss: 0.00011441098308750952, Final Batch Loss: 2.4695675620023394e-06\n",
      "Epoch 2962, Loss: 0.00016034104669415683, Final Batch Loss: 2.042402456936543e-06\n",
      "Epoch 2963, Loss: 4.660219474317273e-05, Final Batch Loss: 3.593504516175017e-05\n",
      "Epoch 2964, Loss: 1.633039937587455e-05, Final Batch Loss: 9.04609350982355e-06\n",
      "Epoch 2965, Loss: 6.242983545234893e-05, Final Batch Loss: 4.448549952940084e-05\n",
      "Epoch 2966, Loss: 0.00041004527747645625, Final Batch Loss: 6.6917114054376725e-06\n",
      "Epoch 2967, Loss: 0.005997085441777017, Final Batch Loss: 0.005955562926828861\n",
      "Epoch 2968, Loss: 0.00207466348001617, Final Batch Loss: 0.002041324507445097\n",
      "Epoch 2969, Loss: 9.39264446060406e-05, Final Batch Loss: 2.6734540369943716e-05\n",
      "Epoch 2970, Loss: 1.5462007468158845e-05, Final Batch Loss: 8.304798029712401e-06\n",
      "Epoch 2971, Loss: 0.00017588167975191027, Final Batch Loss: 0.00010389904491603374\n",
      "Epoch 2972, Loss: 3.7727410926891025e-05, Final Batch Loss: 2.4867984393495135e-05\n",
      "Epoch 2973, Loss: 1.0165334288103622e-05, Final Batch Loss: 7.157383606681833e-06\n",
      "Epoch 2974, Loss: 0.00013876827870262787, Final Batch Loss: 4.659462865674868e-05\n",
      "Epoch 2975, Loss: 8.98449870874174e-05, Final Batch Loss: 6.215948087628931e-05\n",
      "Epoch 2976, Loss: 7.153430033213226e-05, Final Batch Loss: 5.400247573561501e-06\n",
      "Epoch 2977, Loss: 3.970377383666346e-05, Final Batch Loss: 2.7921194487134926e-05\n",
      "Epoch 2978, Loss: 8.37737525216653e-06, Final Batch Loss: 1.986205916182371e-06\n",
      "Epoch 2979, Loss: 3.9245451262104325e-05, Final Batch Loss: 2.6912184694083408e-06\n",
      "Epoch 2980, Loss: 0.00024199876861530356, Final Batch Loss: 1.7151844076579437e-05\n",
      "Epoch 2981, Loss: 0.0001287630848310073, Final Batch Loss: 1.4254500456445385e-05\n",
      "Epoch 2982, Loss: 0.00021035027884863666, Final Batch Loss: 1.994559625018155e-06\n",
      "Epoch 2983, Loss: 7.820364407962188e-05, Final Batch Loss: 1.4911136531736702e-05\n",
      "Epoch 2984, Loss: 0.0002662831866473425, Final Batch Loss: 1.9463845092104748e-05\n",
      "Epoch 2985, Loss: 5.76203347009141e-05, Final Batch Loss: 1.5730463928775862e-05\n",
      "Epoch 2986, Loss: 0.00031487720843870193, Final Batch Loss: 9.207925177179277e-05\n",
      "Epoch 2987, Loss: 7.18117971700849e-05, Final Batch Loss: 1.709568277874496e-05\n",
      "Epoch 2988, Loss: 0.00014691076285089366, Final Batch Loss: 0.00010313888924429193\n",
      "Epoch 2989, Loss: 0.0006445687758969143, Final Batch Loss: 6.110990943852812e-05\n",
      "Epoch 2990, Loss: 0.0002397708658463671, Final Batch Loss: 0.00023609861091244966\n",
      "Epoch 2991, Loss: 0.00012661343680520076, Final Batch Loss: 0.00010843727795872837\n",
      "Epoch 2992, Loss: 6.456529354181839e-05, Final Batch Loss: 1.4092877790972125e-05\n",
      "Epoch 2993, Loss: 1.0802982160385e-05, Final Batch Loss: 8.778027222433593e-06\n",
      "Epoch 2994, Loss: 0.00016398614570789505, Final Batch Loss: 6.177100658533163e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2995, Loss: 0.0016251015185844153, Final Batch Loss: 0.0012552411062642932\n",
      "Epoch 2996, Loss: 5.358816179068526e-05, Final Batch Loss: 6.269233381317463e-06\n",
      "Epoch 2997, Loss: 2.401013489361503e-06, Final Batch Loss: 1.2113524689993937e-06\n",
      "Epoch 2998, Loss: 6.277718557612388e-05, Final Batch Loss: 5.536845128517598e-05\n",
      "Epoch 2999, Loss: 0.00021999791351845488, Final Batch Loss: 0.0002112795045832172\n",
      "Epoch 3000, Loss: 3.311962882435182e-05, Final Batch Loss: 2.042548294411972e-05\n",
      "Epoch 3001, Loss: 0.004100900105186156, Final Batch Loss: 0.00408944021910429\n",
      "Epoch 3002, Loss: 9.64802075031912e-05, Final Batch Loss: 7.600952812936157e-05\n",
      "Epoch 3003, Loss: 4.048102164233569e-05, Final Batch Loss: 3.344121796544641e-05\n",
      "Epoch 3004, Loss: 0.00032856635516509414, Final Batch Loss: 3.197620389983058e-05\n",
      "Epoch 3005, Loss: 0.00031265679353964515, Final Batch Loss: 0.0002904934517573565\n",
      "Epoch 3006, Loss: 6.232447776710615e-05, Final Batch Loss: 2.212394610978663e-05\n",
      "Epoch 3007, Loss: 2.1531951460929122e-05, Final Batch Loss: 1.2554865861602593e-05\n",
      "Epoch 3008, Loss: 0.00018674158309295308, Final Batch Loss: 0.00017513475904706866\n",
      "Epoch 3009, Loss: 0.0006146781051938888, Final Batch Loss: 2.0638366549974307e-05\n",
      "Epoch 3010, Loss: 0.000335126144818787, Final Batch Loss: 0.00033023179275915027\n",
      "Epoch 3011, Loss: 3.4476505334168905e-05, Final Batch Loss: 3.2713055588828865e-06\n",
      "Epoch 3012, Loss: 0.00020786202367162332, Final Batch Loss: 8.56899205246009e-05\n",
      "Epoch 3013, Loss: 0.00014778701370232739, Final Batch Loss: 2.7473444788483903e-05\n",
      "Epoch 3014, Loss: 0.00013712384316022508, Final Batch Loss: 0.00010905265662586316\n",
      "Epoch 3015, Loss: 9.751994139151066e-05, Final Batch Loss: 2.2245271793508437e-06\n",
      "Epoch 3016, Loss: 1.8889198145188857e-05, Final Batch Loss: 8.483714736939874e-06\n",
      "Epoch 3017, Loss: 2.0858675725321518e-05, Final Batch Loss: 1.6082336514955387e-05\n",
      "Epoch 3018, Loss: 0.0045771938621328445, Final Batch Loss: 2.4590162865933962e-05\n",
      "Epoch 3019, Loss: 8.984989290183876e-05, Final Batch Loss: 1.7972941350308247e-05\n",
      "Epoch 3020, Loss: 9.503324918114231e-06, Final Batch Loss: 4.877485935139703e-07\n",
      "Epoch 3021, Loss: 0.0010158700388274156, Final Batch Loss: 0.0008956462843343616\n",
      "Epoch 3022, Loss: 3.675137850223109e-05, Final Batch Loss: 5.152356607140973e-06\n",
      "Epoch 3023, Loss: 3.215839205950033e-05, Final Batch Loss: 2.6759717002278194e-05\n",
      "Epoch 3024, Loss: 7.877518055465771e-05, Final Batch Loss: 5.56545546714915e-06\n",
      "Epoch 3025, Loss: 0.001680683151789708, Final Batch Loss: 2.5767873012227938e-05\n",
      "Epoch 3026, Loss: 0.0003888009746901844, Final Batch Loss: 5.087281920168607e-07\n",
      "Epoch 3027, Loss: 0.0010454454513819655, Final Batch Loss: 2.679636781977024e-05\n",
      "Epoch 3028, Loss: 6.280400157265831e-05, Final Batch Loss: 1.5518287909799255e-05\n",
      "Epoch 3029, Loss: 3.279729719452007e-05, Final Batch Loss: 3.1307288736570626e-05\n",
      "Epoch 3030, Loss: 1.4400845429918263e-05, Final Batch Loss: 7.245382221299224e-06\n",
      "Epoch 3031, Loss: 1.2470770798245212e-05, Final Batch Loss: 3.931919763999758e-06\n",
      "Epoch 3032, Loss: 0.00012731944843835663, Final Batch Loss: 8.994435120257549e-06\n",
      "Epoch 3033, Loss: 1.1305352245472022e-06, Final Batch Loss: 2.384156800872006e-07\n",
      "Epoch 3034, Loss: 0.00016965246391009714, Final Batch Loss: 3.0049784527363954e-06\n",
      "Epoch 3035, Loss: 0.00012049900215060916, Final Batch Loss: 1.193275056721177e-05\n",
      "Epoch 3036, Loss: 0.00016674365861035767, Final Batch Loss: 1.0266808203596156e-06\n",
      "Epoch 3037, Loss: 4.644183468371921e-05, Final Batch Loss: 2.6753125439427095e-06\n",
      "Epoch 3038, Loss: 0.0002599262006697245, Final Batch Loss: 0.00021031868527643383\n",
      "Epoch 3039, Loss: 3.2280172320042766e-05, Final Batch Loss: 6.136695560599037e-07\n",
      "Epoch 3040, Loss: 0.00013817668514093384, Final Batch Loss: 0.0001226116146426648\n",
      "Epoch 3041, Loss: 0.00017042280524037778, Final Batch Loss: 0.00012294376210775226\n",
      "Epoch 3042, Loss: 3.572755315417453e-05, Final Batch Loss: 7.597410558446427e-07\n",
      "Epoch 3043, Loss: 1.9012586108146934e-05, Final Batch Loss: 5.288761713018175e-07\n",
      "Epoch 3044, Loss: 1.3458719422487775e-05, Final Batch Loss: 2.87673583443393e-06\n",
      "Epoch 3045, Loss: 2.9448087843775284e-05, Final Batch Loss: 8.599098691774998e-06\n",
      "Epoch 3046, Loss: 2.0401820165716344e-05, Final Batch Loss: 4.32392198490561e-06\n",
      "Epoch 3047, Loss: 1.1508911029523006e-05, Final Batch Loss: 3.9957158151082695e-06\n",
      "Epoch 3048, Loss: 1.5100706377779716e-05, Final Batch Loss: 2.629197524584015e-06\n",
      "Epoch 3049, Loss: 0.00021241800277493894, Final Batch Loss: 8.898600935935974e-05\n",
      "Epoch 3050, Loss: 2.7030944238504162e-05, Final Batch Loss: 7.041718617983861e-06\n",
      "Epoch 3051, Loss: 4.923419146507513e-05, Final Batch Loss: 2.0116063751629554e-05\n",
      "Epoch 3052, Loss: 2.1753872715635225e-05, Final Batch Loss: 1.690916542429477e-05\n",
      "Epoch 3053, Loss: 6.386567747540539e-06, Final Batch Loss: 9.73793248704169e-07\n",
      "Epoch 3054, Loss: 8.148872620949987e-05, Final Batch Loss: 5.620298907160759e-05\n",
      "Epoch 3055, Loss: 0.000190390448551625, Final Batch Loss: 0.00017149487393908203\n",
      "Epoch 3056, Loss: 6.53022098049405e-05, Final Batch Loss: 5.288018655846827e-05\n",
      "Epoch 3057, Loss: 7.070587912494375e-05, Final Batch Loss: 2.8657743769144872e-06\n",
      "Epoch 3058, Loss: 2.6394037377031054e-05, Final Batch Loss: 7.827599802112672e-06\n",
      "Epoch 3059, Loss: 0.00026254812291881535, Final Batch Loss: 0.00023814791347831488\n",
      "Epoch 3060, Loss: 0.0006584205802937504, Final Batch Loss: 0.0006053577526472509\n",
      "Epoch 3061, Loss: 0.00010962951228066231, Final Batch Loss: 6.22780817138846e-06\n",
      "Epoch 3062, Loss: 0.00047177171290968545, Final Batch Loss: 0.0004288145573809743\n",
      "Epoch 3063, Loss: 0.0002766437391983345, Final Batch Loss: 0.00024247672990895808\n",
      "Epoch 3064, Loss: 0.00032823486253619194, Final Batch Loss: 0.00018606205412652344\n",
      "Epoch 3065, Loss: 2.7594804123509675e-05, Final Batch Loss: 7.471029675798491e-06\n",
      "Epoch 3066, Loss: 9.770344604476122e-06, Final Batch Loss: 6.258706434891792e-06\n",
      "Epoch 3067, Loss: 0.00014221237870515324, Final Batch Loss: 0.00011242983600823209\n",
      "Epoch 3068, Loss: 2.0920339238728047e-05, Final Batch Loss: 3.5416217087913537e-06\n",
      "Epoch 3069, Loss: 0.0005826098185934825, Final Batch Loss: 0.0005608831415884197\n",
      "Epoch 3070, Loss: 0.0003901294459183191, Final Batch Loss: 0.00038895130273886025\n",
      "Epoch 3071, Loss: 0.005768725658526819, Final Batch Loss: 0.005759245716035366\n",
      "Epoch 3072, Loss: 9.42198712436948e-05, Final Batch Loss: 3.314402056275867e-05\n",
      "Epoch 3073, Loss: 1.5277040120054153e-05, Final Batch Loss: 2.757556330834632e-06\n",
      "Epoch 3074, Loss: 0.0015299600963771809, Final Batch Loss: 0.0014961444539949298\n",
      "Epoch 3075, Loss: 2.947363827843219e-05, Final Batch Loss: 1.4313592146208975e-05\n",
      "Epoch 3076, Loss: 0.0002798787108986289, Final Batch Loss: 2.05238120543072e-06\n",
      "Epoch 3077, Loss: 1.2688630249613198e-05, Final Batch Loss: 5.771715223090723e-06\n",
      "Epoch 3078, Loss: 2.2805893479471706e-05, Final Batch Loss: 7.731442224212515e-07\n",
      "Epoch 3079, Loss: 3.507980909489561e-05, Final Batch Loss: 2.626693094498478e-05\n",
      "Epoch 3080, Loss: 4.522869289758091e-05, Final Batch Loss: 2.4528615085728234e-06\n",
      "Epoch 3081, Loss: 2.8014479539706372e-05, Final Batch Loss: 7.925111276563257e-06\n",
      "Epoch 3082, Loss: 6.123155344539555e-05, Final Batch Loss: 9.198666703014169e-06\n",
      "Epoch 3083, Loss: 6.871770801808452e-05, Final Batch Loss: 5.450758908409625e-05\n",
      "Epoch 3084, Loss: 0.0025850021047517657, Final Batch Loss: 0.0023860603105276823\n",
      "Epoch 3085, Loss: 4.5625092070622486e-05, Final Batch Loss: 4.3133280996698886e-05\n",
      "Epoch 3086, Loss: 0.0004442837816895917, Final Batch Loss: 0.0002099120756611228\n",
      "Epoch 3087, Loss: 4.3493407929418026e-05, Final Batch Loss: 3.191471250829636e-06\n",
      "Epoch 3088, Loss: 0.0005071781554306654, Final Batch Loss: 1.9097562926617684e-06\n",
      "Epoch 3089, Loss: 3.788383855862776e-05, Final Batch Loss: 2.3885117116151378e-05\n",
      "Epoch 3090, Loss: 4.088256707746041e-05, Final Batch Loss: 3.786097977354075e-07\n",
      "Epoch 3091, Loss: 6.481119908130495e-05, Final Batch Loss: 7.667676072742324e-06\n",
      "Epoch 3092, Loss: 1.8845796375899226e-05, Final Batch Loss: 3.0964204142946983e-06\n",
      "Epoch 3093, Loss: 1.3771805015494465e-05, Final Batch Loss: 1.0777303941722494e-05\n",
      "Epoch 3094, Loss: 0.00013178339759178925, Final Batch Loss: 0.00011841879313578829\n",
      "Epoch 3095, Loss: 7.21047144907061e-05, Final Batch Loss: 4.236437234794721e-06\n",
      "Epoch 3096, Loss: 5.68838618164591e-05, Final Batch Loss: 2.765150838968111e-06\n",
      "Epoch 3097, Loss: 0.00012345572031335905, Final Batch Loss: 7.868017564760521e-05\n",
      "Epoch 3098, Loss: 4.6087313421594445e-05, Final Batch Loss: 1.601722942723427e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3099, Loss: 2.6015399271273054e-05, Final Batch Loss: 1.0690084309317172e-05\n",
      "Epoch 3100, Loss: 1.929763220687164e-05, Final Batch Loss: 4.175208232481964e-06\n",
      "Epoch 3101, Loss: 6.0475227883216576e-06, Final Batch Loss: 4.7687058213341516e-06\n",
      "Epoch 3102, Loss: 6.447666737585678e-05, Final Batch Loss: 4.482042186282342e-06\n",
      "Epoch 3103, Loss: 1.95824759430252e-05, Final Batch Loss: 1.4456099052040372e-05\n",
      "Epoch 3104, Loss: 7.144642131606815e-05, Final Batch Loss: 5.8938439906341955e-05\n",
      "Epoch 3105, Loss: 2.183567130487063e-05, Final Batch Loss: 1.4812656445428729e-05\n",
      "Epoch 3106, Loss: 0.00010906424358836375, Final Batch Loss: 3.086918513872661e-05\n",
      "Epoch 3107, Loss: 0.0003291965986136347, Final Batch Loss: 3.060523886233568e-05\n",
      "Epoch 3108, Loss: 0.0009619676879992767, Final Batch Loss: 7.433120572386542e-06\n",
      "Epoch 3109, Loss: 6.822521936555859e-05, Final Batch Loss: 5.408869401435368e-05\n",
      "Epoch 3110, Loss: 0.0003076628563576378, Final Batch Loss: 0.00019070696725975722\n",
      "Epoch 3111, Loss: 4.4781538235838525e-05, Final Batch Loss: 1.1681489922921173e-05\n",
      "Epoch 3112, Loss: 1.9001133296114858e-05, Final Batch Loss: 1.281152344745351e-05\n",
      "Epoch 3113, Loss: 1.8256414477946237e-05, Final Batch Loss: 5.898013114347123e-06\n",
      "Epoch 3114, Loss: 3.6751542893398437e-06, Final Batch Loss: 1.592437570252514e-06\n",
      "Epoch 3115, Loss: 2.5478875159024028e-05, Final Batch Loss: 2.384153413004242e-05\n",
      "Epoch 3116, Loss: 8.733829872653587e-06, Final Batch Loss: 4.248772256687516e-06\n",
      "Epoch 3117, Loss: 0.00022220178334464435, Final Batch Loss: 3.913785349141108e-06\n",
      "Epoch 3118, Loss: 5.942263851466123e-05, Final Batch Loss: 2.8850763555965386e-05\n",
      "Epoch 3119, Loss: 7.032969406850498e-06, Final Batch Loss: 2.19108770238563e-07\n",
      "Epoch 3120, Loss: 7.560910262327525e-07, Final Batch Loss: 2.7115714829051285e-07\n",
      "Epoch 3121, Loss: 3.728477838649269e-05, Final Batch Loss: 1.4682367464047275e-06\n",
      "Epoch 3122, Loss: 6.056264544440637e-05, Final Batch Loss: 1.6075363191703218e-06\n",
      "Epoch 3123, Loss: 2.73602781817317e-05, Final Batch Loss: 9.506080459686927e-06\n",
      "Epoch 3124, Loss: 6.442231097025797e-05, Final Batch Loss: 4.967821587342769e-05\n",
      "Epoch 3125, Loss: 1.1705531761663224e-06, Final Batch Loss: 2.0735576811148348e-07\n",
      "Epoch 3126, Loss: 0.0002603728978556319, Final Batch Loss: 2.922567318819347e-06\n",
      "Epoch 3127, Loss: 0.00015554150741081685, Final Batch Loss: 7.023385114734992e-05\n",
      "Epoch 3128, Loss: 6.907780877440928e-05, Final Batch Loss: 2.5604637698961596e-07\n",
      "Epoch 3129, Loss: 4.223305222694762e-05, Final Batch Loss: 2.363662133575417e-05\n",
      "Epoch 3130, Loss: 0.0011238709303142969, Final Batch Loss: 3.204026506864466e-05\n",
      "Epoch 3131, Loss: 4.9329248895446653e-05, Final Batch Loss: 4.783688564202748e-05\n",
      "Epoch 3132, Loss: 0.00015954985428834334, Final Batch Loss: 2.174350811401382e-05\n",
      "Epoch 3133, Loss: 2.716441144912096e-06, Final Batch Loss: 1.6688558162059053e-06\n",
      "Epoch 3134, Loss: 2.8972496693313587e-05, Final Batch Loss: 7.773055585857946e-06\n",
      "Epoch 3135, Loss: 4.7611227273591794e-05, Final Batch Loss: 3.363599898875691e-05\n",
      "Epoch 3136, Loss: 2.3110858649033617e-06, Final Batch Loss: 2.795514149056544e-07\n",
      "Epoch 3137, Loss: 4.671152055379935e-06, Final Batch Loss: 1.986970801226562e-06\n",
      "Epoch 3138, Loss: 1.0214275789621752e-06, Final Batch Loss: 4.6591816271757125e-07\n",
      "Epoch 3139, Loss: 8.693235486134654e-06, Final Batch Loss: 3.5339544410817325e-06\n",
      "Epoch 3140, Loss: 0.004029105124573107, Final Batch Loss: 0.0040094587020576\n",
      "Epoch 3141, Loss: 2.0549892127519342e-05, Final Batch Loss: 3.106136716723995e-07\n",
      "Epoch 3142, Loss: 3.9880312215245795e-05, Final Batch Loss: 7.650839506823104e-06\n",
      "Epoch 3143, Loss: 6.565715921169613e-05, Final Batch Loss: 1.6168944057426415e-05\n",
      "Epoch 3144, Loss: 0.0007935075136629166, Final Batch Loss: 1.9894812794518657e-05\n",
      "Epoch 3145, Loss: 7.367975376837421e-05, Final Batch Loss: 6.509344530059025e-05\n",
      "Epoch 3146, Loss: 0.017568085046150372, Final Batch Loss: 9.283126928494312e-06\n",
      "Epoch 3147, Loss: 0.0010917598847299814, Final Batch Loss: 0.0007241890416480601\n",
      "Epoch 3148, Loss: 0.00015631891824341437, Final Batch Loss: 2.480523335179896e-06\n",
      "Epoch 3149, Loss: 0.0001815786934002972, Final Batch Loss: 0.0001805883803172037\n",
      "Epoch 3150, Loss: 6.456977826019283e-05, Final Batch Loss: 5.8799178077606484e-06\n",
      "Epoch 3151, Loss: 0.0017126216844189912, Final Batch Loss: 0.0016511745052412152\n",
      "Epoch 3152, Loss: 2.296622710673546e-05, Final Batch Loss: 2.0070690425200155e-06\n",
      "Epoch 3153, Loss: 2.7538446374819614e-05, Final Batch Loss: 1.2897682609036565e-05\n",
      "Epoch 3154, Loss: 0.00023014890120975906, Final Batch Loss: 1.1445518794062082e-05\n",
      "Epoch 3155, Loss: 0.0027897398176719435, Final Batch Loss: 4.2247884266544133e-05\n",
      "Epoch 3156, Loss: 0.00010736099648056552, Final Batch Loss: 1.3587312423624098e-05\n",
      "Epoch 3157, Loss: 0.00017426365229766816, Final Batch Loss: 0.00016270202468149364\n",
      "Epoch 3158, Loss: 0.00037950463593006134, Final Batch Loss: 0.00016915000742301345\n",
      "Epoch 3159, Loss: 0.009064500220119953, Final Batch Loss: 0.007904060184955597\n",
      "Epoch 3160, Loss: 0.0028131951316936465, Final Batch Loss: 3.824030955001945e-06\n",
      "Epoch 3161, Loss: 5.3980867960490286e-05, Final Batch Loss: 3.788328103837557e-05\n",
      "Epoch 3162, Loss: 3.7239882885842235e-05, Final Batch Loss: 6.841876256657997e-07\n",
      "Epoch 3163, Loss: 2.506417661152227e-05, Final Batch Loss: 1.3473778608386056e-06\n",
      "Epoch 3164, Loss: 0.00012675194159328385, Final Batch Loss: 1.5815763845239417e-06\n",
      "Epoch 3165, Loss: 0.0013005850723857293, Final Batch Loss: 1.1219142834306695e-05\n",
      "Epoch 3166, Loss: 5.0555413281472283e-05, Final Batch Loss: 4.866243034484796e-05\n",
      "Epoch 3167, Loss: 5.3827549891138915e-05, Final Batch Loss: 4.2387295252410695e-05\n",
      "Epoch 3168, Loss: 0.00019744722521863878, Final Batch Loss: 8.592884114477783e-05\n",
      "Epoch 3169, Loss: 1.1750978956115432e-05, Final Batch Loss: 5.676104592566844e-06\n",
      "Epoch 3170, Loss: 5.0430355258868076e-05, Final Batch Loss: 2.2020853066351265e-05\n",
      "Epoch 3171, Loss: 7.055514333842439e-05, Final Batch Loss: 4.705689661932411e-06\n",
      "Epoch 3172, Loss: 7.113252104318235e-05, Final Batch Loss: 9.803205102798529e-06\n",
      "Epoch 3173, Loss: 2.1390854101355217e-06, Final Batch Loss: 3.257241871779115e-07\n",
      "Epoch 3174, Loss: 0.0007775236749694159, Final Batch Loss: 0.0007717660046182573\n",
      "Epoch 3175, Loss: 0.000256677642937575, Final Batch Loss: 0.000244659575400874\n",
      "Epoch 3176, Loss: 0.00011709181580954464, Final Batch Loss: 1.3586545719590504e-05\n",
      "Epoch 3177, Loss: 9.399302712154167e-06, Final Batch Loss: 9.97303345684486e-07\n",
      "Epoch 3178, Loss: 0.00015270635549313738, Final Batch Loss: 2.4890155145840254e-06\n",
      "Epoch 3179, Loss: 8.273903222288936e-05, Final Batch Loss: 3.921815368812531e-05\n",
      "Epoch 3180, Loss: 1.4663564513739402e-05, Final Batch Loss: 4.331783998168248e-07\n",
      "Epoch 3181, Loss: 0.00019382247296562127, Final Batch Loss: 0.0001910269056679681\n",
      "Epoch 3182, Loss: 6.34800162515603e-05, Final Batch Loss: 4.4642594730248675e-05\n",
      "Epoch 3183, Loss: 3.141094020975288e-05, Final Batch Loss: 8.093518772511743e-06\n",
      "Epoch 3184, Loss: 0.0002992775280290516, Final Batch Loss: 0.00027757446514442563\n",
      "Epoch 3185, Loss: 5.259989939077059e-05, Final Batch Loss: 5.196857819100842e-05\n",
      "Epoch 3186, Loss: 0.0004873672514804639, Final Batch Loss: 0.0004557041684165597\n",
      "Epoch 3187, Loss: 6.20897117187269e-06, Final Batch Loss: 1.7402057892468292e-06\n",
      "Epoch 3188, Loss: 5.747244244957983e-06, Final Batch Loss: 1.2894296332888189e-06\n",
      "Epoch 3189, Loss: 2.2425747147281072e-05, Final Batch Loss: 1.9852193418046227e-06\n",
      "Epoch 3190, Loss: 4.456144597497769e-05, Final Batch Loss: 2.1227609977358952e-05\n",
      "Epoch 3191, Loss: 2.622692159093276e-05, Final Batch Loss: 2.2600690499530174e-05\n",
      "Epoch 3192, Loss: 1.4677495528303552e-05, Final Batch Loss: 4.72828651254531e-06\n",
      "Epoch 3193, Loss: 0.0006149565974737925, Final Batch Loss: 0.0006075552082620561\n",
      "Epoch 3194, Loss: 0.00011520635644046706, Final Batch Loss: 6.341674179566326e-06\n",
      "Epoch 3195, Loss: 0.00016305682311212877, Final Batch Loss: 2.2010435714037158e-06\n",
      "Epoch 3196, Loss: 2.2125081159174442e-05, Final Batch Loss: 1.1436228305683471e-05\n",
      "Epoch 3197, Loss: 3.893110260833055e-05, Final Batch Loss: 4.545083356788382e-06\n",
      "Epoch 3198, Loss: 2.9466590376614477e-06, Final Batch Loss: 1.787996325219865e-06\n",
      "Epoch 3199, Loss: 0.001998808525968343, Final Batch Loss: 0.00016577885253354907\n",
      "Epoch 3200, Loss: 9.813402493819012e-05, Final Batch Loss: 5.2947484618925955e-06\n",
      "Epoch 3201, Loss: 5.791126523035928e-05, Final Batch Loss: 4.9401655815017875e-06\n",
      "Epoch 3202, Loss: 0.0007131658639991656, Final Batch Loss: 5.755219899583608e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3203, Loss: 0.0002186020319641102, Final Batch Loss: 4.676352909882553e-05\n",
      "Epoch 3204, Loss: 5.95442145367997e-06, Final Batch Loss: 4.806707693205681e-06\n",
      "Epoch 3205, Loss: 7.536787239814657e-05, Final Batch Loss: 7.4971147114411e-05\n",
      "Epoch 3206, Loss: 0.004931351178328214, Final Batch Loss: 0.00493091344833374\n",
      "Epoch 3207, Loss: 1.3923366850576713e-06, Final Batch Loss: 4.5920131697130273e-07\n",
      "Epoch 3208, Loss: 4.61348463431932e-05, Final Batch Loss: 7.392929546767846e-06\n",
      "Epoch 3209, Loss: 7.27958140487317e-05, Final Batch Loss: 4.942668601870537e-05\n",
      "Epoch 3210, Loss: 7.232930465761456e-05, Final Batch Loss: 6.796383968321607e-05\n",
      "Epoch 3211, Loss: 7.313147352761007e-05, Final Batch Loss: 1.547983174532419e-06\n",
      "Epoch 3212, Loss: 2.0752318619088328e-05, Final Batch Loss: 1.1610151204877184e-06\n",
      "Epoch 3213, Loss: 2.0500857772276504e-05, Final Batch Loss: 3.3552983040863182e-06\n",
      "Epoch 3214, Loss: 0.00012401006824802607, Final Batch Loss: 6.471830420196056e-05\n",
      "Epoch 3215, Loss: 5.6483535445295274e-05, Final Batch Loss: 2.4733268219279125e-05\n",
      "Epoch 3216, Loss: 0.00013702159048989415, Final Batch Loss: 3.279755765106529e-05\n",
      "Epoch 3217, Loss: 2.1406679479696322e-05, Final Batch Loss: 1.0359773114032578e-05\n",
      "Epoch 3218, Loss: 0.0003973614329879638, Final Batch Loss: 2.9513576009776443e-06\n",
      "Epoch 3219, Loss: 1.1895067189016117e-05, Final Batch Loss: 1.0966697118419688e-05\n",
      "Epoch 3220, Loss: 6.840819378339802e-05, Final Batch Loss: 2.1657947399944533e-06\n",
      "Epoch 3221, Loss: 5.864715694769984e-05, Final Batch Loss: 1.2497245734266471e-05\n",
      "Epoch 3222, Loss: 9.32154853217071e-06, Final Batch Loss: 1.8745486158877611e-06\n",
      "Epoch 3223, Loss: 0.0002025155772571452, Final Batch Loss: 0.00011983389413217083\n",
      "Epoch 3224, Loss: 0.00108907038338657, Final Batch Loss: 0.0010769657092168927\n",
      "Epoch 3225, Loss: 2.6139461624552496e-05, Final Batch Loss: 1.247408908966463e-05\n",
      "Epoch 3226, Loss: 1.623009239892781e-06, Final Batch Loss: 2.845893334324501e-07\n",
      "Epoch 3227, Loss: 3.2845960959093645e-05, Final Batch Loss: 8.493852874380536e-06\n",
      "Epoch 3228, Loss: 0.0003417016487219371, Final Batch Loss: 0.0002284515940118581\n",
      "Epoch 3229, Loss: 6.233601254734822e-06, Final Batch Loss: 5.346225407265592e-06\n",
      "Epoch 3230, Loss: 0.00025892831217788626, Final Batch Loss: 0.0002395256160525605\n",
      "Epoch 3231, Loss: 8.583469374912056e-05, Final Batch Loss: 8.555383828934282e-05\n",
      "Epoch 3232, Loss: 0.0004300600921851583, Final Batch Loss: 0.00032381576602347195\n",
      "Epoch 3233, Loss: 0.00045260538354341406, Final Batch Loss: 0.0004315851256251335\n",
      "Epoch 3234, Loss: 6.38687106402358e-06, Final Batch Loss: 1.2130076356697828e-06\n",
      "Epoch 3235, Loss: 7.742473655980575e-06, Final Batch Loss: 7.02150646247901e-06\n",
      "Epoch 3236, Loss: 1.9710440255948924e-05, Final Batch Loss: 2.6198470095550874e-06\n",
      "Epoch 3237, Loss: 0.000139518235300784, Final Batch Loss: 2.324435808986891e-05\n",
      "Epoch 3238, Loss: 4.445232480065897e-05, Final Batch Loss: 1.544031147204805e-05\n",
      "Epoch 3239, Loss: 3.717943218362052e-05, Final Batch Loss: 2.459309689584188e-05\n",
      "Epoch 3240, Loss: 0.0008364939640159719, Final Batch Loss: 0.000772729457821697\n",
      "Epoch 3241, Loss: 0.010051029501482844, Final Batch Loss: 0.009983092546463013\n",
      "Epoch 3242, Loss: 4.488286933224117e-06, Final Batch Loss: 2.3506046886723198e-08\n",
      "Epoch 3243, Loss: 6.489829593192553e-05, Final Batch Loss: 1.081235495803412e-06\n",
      "Epoch 3244, Loss: 0.0008521463507236149, Final Batch Loss: 1.804921225811995e-07\n",
      "Epoch 3245, Loss: 1.7366185602440964e-05, Final Batch Loss: 9.199167834594846e-06\n",
      "Epoch 3246, Loss: 0.00030224212241591886, Final Batch Loss: 0.00022112725127954036\n",
      "Epoch 3247, Loss: 1.3178178846828814e-05, Final Batch Loss: 1.2350889846857172e-05\n",
      "Epoch 3248, Loss: 1.3357897387322737e-05, Final Batch Loss: 1.0404764907434583e-05\n",
      "Epoch 3249, Loss: 6.14935670455452e-05, Final Batch Loss: 1.1206604540348053e-05\n",
      "Epoch 3250, Loss: 0.00020448967677566543, Final Batch Loss: 0.00020331525593064725\n",
      "Epoch 3251, Loss: 0.00021859391017642338, Final Batch Loss: 0.00019314415112603456\n",
      "Epoch 3252, Loss: 0.00015944854567351285, Final Batch Loss: 2.026122274401132e-05\n",
      "Epoch 3253, Loss: 1.064714660969912e-05, Final Batch Loss: 4.901140982838115e-06\n",
      "Epoch 3254, Loss: 5.209573510001064e-05, Final Batch Loss: 5.751013759436319e-06\n",
      "Epoch 3255, Loss: 0.00011731318591046147, Final Batch Loss: 0.000106960185803473\n",
      "Epoch 3256, Loss: 3.9309175008384045e-06, Final Batch Loss: 1.0930141343123978e-06\n",
      "Epoch 3257, Loss: 0.00012789123138645664, Final Batch Loss: 1.1631986126303673e-05\n",
      "Epoch 3258, Loss: 7.113847004802665e-06, Final Batch Loss: 3.0034589144634083e-06\n",
      "Epoch 3259, Loss: 0.00010659212421160191, Final Batch Loss: 9.255149052478373e-05\n",
      "Epoch 3260, Loss: 0.00010248522914935165, Final Batch Loss: 4.7263631586247357e-07\n",
      "Epoch 3261, Loss: 3.1274564662453486e-06, Final Batch Loss: 1.7771030798030552e-06\n",
      "Epoch 3262, Loss: 1.0409532478661276e-05, Final Batch Loss: 6.1476007431338076e-06\n",
      "Epoch 3263, Loss: 2.439303943901905e-05, Final Batch Loss: 2.1854320948477834e-05\n",
      "Epoch 3264, Loss: 0.0003112994891125709, Final Batch Loss: 0.00024142027541529387\n",
      "Epoch 3265, Loss: 8.680915925651789e-05, Final Batch Loss: 5.834990588482469e-06\n",
      "Epoch 3266, Loss: 5.7641650300865876e-05, Final Batch Loss: 2.956444177470985e-06\n",
      "Epoch 3267, Loss: 6.50251223532905e-06, Final Batch Loss: 2.913050707320508e-07\n",
      "Epoch 3268, Loss: 0.00013462330207403284, Final Batch Loss: 0.00011929582251468673\n",
      "Epoch 3269, Loss: 0.0002961361600455348, Final Batch Loss: 9.821955018196604e-07\n",
      "Epoch 3270, Loss: 0.00022163158428156748, Final Batch Loss: 6.0407859564293176e-05\n",
      "Epoch 3271, Loss: 2.1761838922884635e-05, Final Batch Loss: 8.159867661561293e-07\n",
      "Epoch 3272, Loss: 1.5096032370820467e-06, Final Batch Loss: 9.889032526189112e-07\n",
      "Epoch 3273, Loss: 1.4511728068100638e-05, Final Batch Loss: 1.3142303032509517e-05\n",
      "Epoch 3274, Loss: 0.005442932048026705, Final Batch Loss: 0.0054275840520858765\n",
      "Epoch 3275, Loss: 2.5358868469993467e-05, Final Batch Loss: 3.643406216724543e-07\n",
      "Epoch 3276, Loss: 1.7616433979128487e-05, Final Batch Loss: 1.2057267667842098e-05\n",
      "Epoch 3277, Loss: 4.999454972676176e-06, Final Batch Loss: 1.8970284827446449e-06\n",
      "Epoch 3278, Loss: 3.365329757798463e-05, Final Batch Loss: 2.684471837710589e-06\n",
      "Epoch 3279, Loss: 1.7416068203601753e-05, Final Batch Loss: 5.20392086400534e-06\n",
      "Epoch 3280, Loss: 0.0008104170483420603, Final Batch Loss: 0.0007557828794233501\n",
      "Epoch 3281, Loss: 2.224231866421178e-05, Final Batch Loss: 3.189559720340185e-06\n",
      "Epoch 3282, Loss: 6.957695836717903e-05, Final Batch Loss: 6.732381734764203e-05\n",
      "Epoch 3283, Loss: 2.7701848011929542e-05, Final Batch Loss: 1.5395191439893097e-05\n",
      "Epoch 3284, Loss: 0.00012173803406767547, Final Batch Loss: 6.583775393664837e-05\n",
      "Epoch 3285, Loss: 8.512012573191896e-05, Final Batch Loss: 5.185502232052386e-06\n",
      "Epoch 3286, Loss: 2.4274087763842545e-05, Final Batch Loss: 9.250995844922727e-07\n",
      "Epoch 3287, Loss: 7.945330617076252e-05, Final Batch Loss: 4.201590854790993e-06\n",
      "Epoch 3288, Loss: 1.1516891390783712e-05, Final Batch Loss: 4.197426733298926e-06\n",
      "Epoch 3289, Loss: 0.0005286094975929245, Final Batch Loss: 0.0005284330691210926\n",
      "Epoch 3290, Loss: 6.040164748810639e-06, Final Batch Loss: 5.120895139043569e-07\n",
      "Epoch 3291, Loss: 0.00023255652558873408, Final Batch Loss: 0.00021796810324303806\n",
      "Epoch 3292, Loss: 2.9931853987363866e-05, Final Batch Loss: 6.411633421521401e-06\n",
      "Epoch 3293, Loss: 0.00012741847513098037, Final Batch Loss: 0.00012256603804416955\n",
      "Epoch 3294, Loss: 0.0004713418800292857, Final Batch Loss: 5.968811365164584e-07\n",
      "Epoch 3295, Loss: 1.8193094092566753e-05, Final Batch Loss: 1.2042624803143553e-05\n",
      "Epoch 3296, Loss: 0.0001649101973271172, Final Batch Loss: 0.00016040388436522335\n",
      "Epoch 3297, Loss: 1.8647196895926754e-05, Final Batch Loss: 3.85329087748687e-07\n",
      "Epoch 3298, Loss: 1.8222501921627554e-05, Final Batch Loss: 1.649357727728784e-05\n",
      "Epoch 3299, Loss: 3.102389973719255e-05, Final Batch Loss: 1.4521979210257996e-06\n",
      "Epoch 3300, Loss: 9.076245623873547e-05, Final Batch Loss: 2.4016968382056803e-05\n",
      "Epoch 3301, Loss: 1.2016169421258382e-05, Final Batch Loss: 9.003944796859287e-06\n",
      "Epoch 3302, Loss: 9.113188571063802e-05, Final Batch Loss: 1.671339850872755e-05\n",
      "Epoch 3303, Loss: 0.00021418890855784412, Final Batch Loss: 4.5832234718545806e-06\n",
      "Epoch 3304, Loss: 6.225329798326129e-05, Final Batch Loss: 1.2288329344301019e-05\n",
      "Epoch 3305, Loss: 3.946889933104103e-06, Final Batch Loss: 1.0661418627933017e-06\n",
      "Epoch 3306, Loss: 1.852752620834508e-05, Final Batch Loss: 1.2349897588137537e-05\n",
      "Epoch 3307, Loss: 0.0002829261284205131, Final Batch Loss: 0.0002649380767252296\n",
      "Epoch 3308, Loss: 6.667800334980711e-05, Final Batch Loss: 4.0771257772576064e-05\n",
      "Epoch 3309, Loss: 2.642261364371734e-06, Final Batch Loss: 2.3170159124674683e-07\n",
      "Epoch 3310, Loss: 3.706557140503719e-05, Final Batch Loss: 2.953059038190986e-06\n",
      "Epoch 3311, Loss: 0.00010940623724309262, Final Batch Loss: 9.257548663299531e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3312, Loss: 0.00010201646000496112, Final Batch Loss: 5.63861831324175e-05\n",
      "Epoch 3313, Loss: 0.0009173906178148172, Final Batch Loss: 3.014330559381051e-06\n",
      "Epoch 3314, Loss: 2.2312031433102675e-05, Final Batch Loss: 1.7424272300559096e-05\n",
      "Epoch 3315, Loss: 2.903379231611325e-05, Final Batch Loss: 2.5406197892152704e-05\n",
      "Epoch 3316, Loss: 0.00013960941578261554, Final Batch Loss: 8.64839821588248e-05\n",
      "Epoch 3317, Loss: 0.001673010061495006, Final Batch Loss: 2.780812792479992e-06\n",
      "Epoch 3318, Loss: 4.1419329136260785e-05, Final Batch Loss: 3.4565036912681535e-05\n",
      "Epoch 3319, Loss: 0.00016065766612882726, Final Batch Loss: 0.00013677777315024287\n",
      "Epoch 3320, Loss: 2.9938593399947422e-05, Final Batch Loss: 4.5164375706008286e-07\n",
      "Epoch 3321, Loss: 0.00016354281979147345, Final Batch Loss: 4.788955266121775e-05\n",
      "Epoch 3322, Loss: 5.124200015416136e-06, Final Batch Loss: 2.185088760597864e-06\n",
      "Epoch 3323, Loss: 9.885396366371424e-06, Final Batch Loss: 3.576244580472121e-07\n",
      "Epoch 3324, Loss: 3.336101565309946e-05, Final Batch Loss: 3.235352414776571e-05\n",
      "Epoch 3325, Loss: 0.0006042639724910259, Final Batch Loss: 0.000337466160999611\n",
      "Epoch 3326, Loss: 8.24171149531594e-05, Final Batch Loss: 2.4345553129023756e-08\n",
      "Epoch 3327, Loss: 0.00010382000618847087, Final Batch Loss: 4.355898272478953e-05\n",
      "Epoch 3328, Loss: 0.0006519593153342385, Final Batch Loss: 1.32640749939128e-07\n",
      "Epoch 3329, Loss: 0.00011028189510398079, Final Batch Loss: 5.009498636354692e-06\n",
      "Epoch 3330, Loss: 2.689696020752308e-05, Final Batch Loss: 4.035706751892576e-06\n",
      "Epoch 3331, Loss: 0.00021552843278982436, Final Batch Loss: 3.542681668022851e-07\n",
      "Epoch 3332, Loss: 1.3305113725436968e-05, Final Batch Loss: 2.094383717121673e-06\n",
      "Epoch 3333, Loss: 0.00011043250924558379, Final Batch Loss: 9.67202868196182e-05\n",
      "Epoch 3334, Loss: 1.4476880096481182e-05, Final Batch Loss: 2.32277307077311e-06\n",
      "Epoch 3335, Loss: 2.0739990304718958e-05, Final Batch Loss: 3.830813966487767e-06\n",
      "Epoch 3336, Loss: 3.900115530086623e-06, Final Batch Loss: 1.8861679791370989e-06\n",
      "Epoch 3337, Loss: 6.457180097640958e-05, Final Batch Loss: 2.634484008012805e-05\n",
      "Epoch 3338, Loss: 6.53100069030188e-05, Final Batch Loss: 4.535273546935059e-05\n",
      "Epoch 3339, Loss: 4.3645292066685215e-05, Final Batch Loss: 1.302853092965961e-06\n",
      "Epoch 3340, Loss: 5.924759420850023e-06, Final Batch Loss: 4.398078544909367e-06\n",
      "Epoch 3341, Loss: 2.9572576750069857e-05, Final Batch Loss: 1.0536015906836838e-05\n",
      "Epoch 3342, Loss: 4.143108753851266e-06, Final Batch Loss: 1.5185789834504249e-06\n",
      "Epoch 3343, Loss: 2.8057727831765078e-05, Final Batch Loss: 8.829594662529416e-06\n",
      "Epoch 3344, Loss: 8.017720415409713e-05, Final Batch Loss: 7.737980922684073e-05\n",
      "Epoch 3345, Loss: 0.000189125103133847, Final Batch Loss: 0.00017426186241209507\n",
      "Epoch 3346, Loss: 1.930265443661483e-05, Final Batch Loss: 2.701398443605285e-06\n",
      "Epoch 3347, Loss: 8.840684586175485e-05, Final Batch Loss: 9.05451724975137e-06\n",
      "Epoch 3348, Loss: 7.961157007230213e-05, Final Batch Loss: 7.34169443603605e-05\n",
      "Epoch 3349, Loss: 1.728815425394714e-05, Final Batch Loss: 1.6588184735155664e-05\n",
      "Epoch 3350, Loss: 5.251537811545859e-05, Final Batch Loss: 9.251060646420228e-07\n",
      "Epoch 3351, Loss: 0.0003169775418427889, Final Batch Loss: 1.3640395081893075e-05\n",
      "Epoch 3352, Loss: 8.589760909671895e-05, Final Batch Loss: 5.62242312298622e-05\n",
      "Epoch 3353, Loss: 4.962735511071514e-05, Final Batch Loss: 3.40858859999571e-05\n",
      "Epoch 3354, Loss: 4.438874839252094e-05, Final Batch Loss: 3.495318742352538e-05\n",
      "Epoch 3355, Loss: 0.00012084720765415113, Final Batch Loss: 9.974653949029744e-05\n",
      "Epoch 3356, Loss: 0.0004176588317932328, Final Batch Loss: 0.0004073593008797616\n",
      "Epoch 3357, Loss: 4.6772607674938627e-05, Final Batch Loss: 1.3756465705228038e-05\n",
      "Epoch 3358, Loss: 8.220776408052188e-06, Final Batch Loss: 5.0419889703334775e-06\n",
      "Epoch 3359, Loss: 3.4233763926749816e-05, Final Batch Loss: 2.7188691092305817e-05\n",
      "Epoch 3360, Loss: 0.0005090843898187813, Final Batch Loss: 1.1702196616170113e-06\n",
      "Epoch 3361, Loss: 6.658279176008364e-06, Final Batch Loss: 2.745158553807414e-07\n",
      "Epoch 3362, Loss: 3.4996194699488115e-05, Final Batch Loss: 6.361972737067845e-06\n",
      "Epoch 3363, Loss: 9.30883533811766e-06, Final Batch Loss: 9.654258548152939e-08\n",
      "Epoch 3364, Loss: 9.099676844925852e-06, Final Batch Loss: 5.90874333283864e-06\n",
      "Epoch 3365, Loss: 4.156171200975223e-06, Final Batch Loss: 3.7021692378402804e-07\n",
      "Epoch 3366, Loss: 5.551692538574571e-06, Final Batch Loss: 4.608818926499225e-07\n",
      "Epoch 3367, Loss: 4.758761315315496e-05, Final Batch Loss: 3.7729842006228864e-05\n",
      "Epoch 3368, Loss: 1.9859635813190835e-05, Final Batch Loss: 6.965981356188422e-06\n",
      "Epoch 3369, Loss: 1.6827971194288693e-05, Final Batch Loss: 7.310085493372753e-06\n",
      "Epoch 3370, Loss: 6.183251571201254e-06, Final Batch Loss: 4.2389706322865095e-06\n",
      "Epoch 3371, Loss: 2.290409065608401e-05, Final Batch Loss: 8.188652827811893e-06\n",
      "Epoch 3372, Loss: 0.00021679246492567472, Final Batch Loss: 0.00017939966346602887\n",
      "Epoch 3373, Loss: 1.7034560414685984e-05, Final Batch Loss: 1.542198697279673e-05\n",
      "Epoch 3374, Loss: 1.381011998091708e-06, Final Batch Loss: 8.159757385328703e-07\n",
      "Epoch 3375, Loss: 0.0002931015842477791, Final Batch Loss: 0.0002817047934513539\n",
      "Epoch 3376, Loss: 3.731851393240504e-05, Final Batch Loss: 1.4051192920305766e-05\n",
      "Epoch 3377, Loss: 0.00017437826453203797, Final Batch Loss: 1.3515953867226926e-07\n",
      "Epoch 3378, Loss: 4.6860183829267044e-05, Final Batch Loss: 1.0675020348571707e-05\n",
      "Epoch 3379, Loss: 0.00010833807027665898, Final Batch Loss: 8.845890988595784e-05\n",
      "Epoch 3380, Loss: 0.0006793671491323039, Final Batch Loss: 0.0004415334842633456\n",
      "Epoch 3381, Loss: 8.768800171310431e-06, Final Batch Loss: 6.64182698528748e-06\n",
      "Epoch 3382, Loss: 2.4187277176679345e-05, Final Batch Loss: 6.417365966626676e-06\n",
      "Epoch 3383, Loss: 9.333700063507422e-06, Final Batch Loss: 6.589941676793387e-07\n",
      "Epoch 3384, Loss: 0.0005385490949265659, Final Batch Loss: 0.000352665112586692\n",
      "Epoch 3385, Loss: 3.0259254799602786e-05, Final Batch Loss: 2.812043203448411e-05\n",
      "Epoch 3386, Loss: 1.697314218063184e-05, Final Batch Loss: 1.6401430912083015e-05\n",
      "Epoch 3387, Loss: 1.7682240013527917e-05, Final Batch Loss: 5.582774520007661e-06\n",
      "Epoch 3388, Loss: 0.00012927806164952926, Final Batch Loss: 0.00011266060755588114\n",
      "Epoch 3389, Loss: 4.464138783077942e-05, Final Batch Loss: 9.76588580670068e-06\n",
      "Epoch 3390, Loss: 4.210173028695863e-05, Final Batch Loss: 2.109958222717978e-05\n",
      "Epoch 3391, Loss: 6.179258321026282e-06, Final Batch Loss: 7.261513701450895e-07\n",
      "Epoch 3392, Loss: 0.00021060274593764916, Final Batch Loss: 0.00014805948012508452\n",
      "Epoch 3393, Loss: 0.00039596380236162076, Final Batch Loss: 1.2382123486531782e-06\n",
      "Epoch 3394, Loss: 0.0005363901468626864, Final Batch Loss: 3.4442959986336064e-06\n",
      "Epoch 3395, Loss: 0.00011843758750273992, Final Batch Loss: 1.7712160342853167e-06\n",
      "Epoch 3396, Loss: 0.0008685900261866664, Final Batch Loss: 9.225928465639299e-07\n",
      "Epoch 3397, Loss: 0.0002803736933856271, Final Batch Loss: 1.4269309758674353e-05\n",
      "Epoch 3398, Loss: 1.0470501365489326e-05, Final Batch Loss: 5.304558726493269e-06\n",
      "Epoch 3399, Loss: 1.4675543752673548e-05, Final Batch Loss: 8.650640666019171e-06\n",
      "Epoch 3400, Loss: 2.137678961844358e-06, Final Batch Loss: 8.478829158775625e-07\n",
      "Epoch 3401, Loss: 0.00010138397806258581, Final Batch Loss: 7.076803285599453e-07\n",
      "Epoch 3402, Loss: 3.4963606822202564e-05, Final Batch Loss: 3.461486130618141e-06\n",
      "Epoch 3403, Loss: 0.00019783699463005178, Final Batch Loss: 8.597762644058093e-06\n",
      "Epoch 3404, Loss: 3.543373259162763e-05, Final Batch Loss: 2.9990869734319858e-05\n",
      "Epoch 3405, Loss: 2.025905268965289e-05, Final Batch Loss: 8.331579010700807e-06\n",
      "Epoch 3406, Loss: 3.7768182664876804e-05, Final Batch Loss: 2.7175312425242737e-05\n",
      "Epoch 3407, Loss: 1.2519007185574083e-05, Final Batch Loss: 1.206840624945471e-05\n",
      "Epoch 3408, Loss: 9.193992809741758e-05, Final Batch Loss: 3.320927862660028e-05\n",
      "Epoch 3409, Loss: 1.4291293268797745e-06, Final Batch Loss: 9.704160675028106e-07\n",
      "Epoch 3410, Loss: 3.7387755583040416e-05, Final Batch Loss: 2.3209036953630857e-05\n",
      "Epoch 3411, Loss: 2.0155531387899828e-05, Final Batch Loss: 1.6687855577401933e-06\n",
      "Epoch 3412, Loss: 0.0016266008183265512, Final Batch Loss: 0.0016246745362877846\n",
      "Epoch 3413, Loss: 1.9509808680595597e-05, Final Batch Loss: 5.649758350045886e-07\n",
      "Epoch 3414, Loss: 1.400635437676101e-05, Final Batch Loss: 2.1858836589672137e-06\n",
      "Epoch 3415, Loss: 1.7544397451274563e-05, Final Batch Loss: 1.2327816875767894e-05\n",
      "Epoch 3416, Loss: 2.3986207011716942e-06, Final Batch Loss: 7.807361868117368e-08\n",
      "Epoch 3417, Loss: 2.595938144622778e-05, Final Batch Loss: 3.064139946218347e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3418, Loss: 1.6432954453193815e-05, Final Batch Loss: 4.226613327773521e-06\n",
      "Epoch 3419, Loss: 1.332549146582096e-06, Final Batch Loss: 3.870027569519152e-07\n",
      "Epoch 3420, Loss: 0.0005138242622706457, Final Batch Loss: 5.468994459079113e-06\n",
      "Epoch 3421, Loss: 7.751628572805203e-06, Final Batch Loss: 5.043194050813327e-06\n",
      "Epoch 3422, Loss: 4.7060132601473015e-05, Final Batch Loss: 3.2444910175399855e-05\n",
      "Epoch 3423, Loss: 3.977718068881586e-05, Final Batch Loss: 1.0073989642478409e-07\n",
      "Epoch 3424, Loss: 0.0002284752500969489, Final Batch Loss: 1.0661655380772572e-07\n",
      "Epoch 3425, Loss: 1.991921521948825e-06, Final Batch Loss: 9.553140216667089e-07\n",
      "Epoch 3426, Loss: 0.00014338978780870093, Final Batch Loss: 0.0001364640484098345\n",
      "Epoch 3427, Loss: 2.040266984693062e-06, Final Batch Loss: 7.303653859480619e-08\n",
      "Epoch 3428, Loss: 0.002182099835522422, Final Batch Loss: 0.00218040868639946\n",
      "Epoch 3429, Loss: 4.411518830238492e-06, Final Batch Loss: 2.1817770630150335e-06\n",
      "Epoch 3430, Loss: 9.136575317825191e-05, Final Batch Loss: 2.0745635993080214e-05\n",
      "Epoch 3431, Loss: 1.2382554075429653e-05, Final Batch Loss: 1.2042572961945552e-05\n",
      "Epoch 3432, Loss: 1.261692915477397e-05, Final Batch Loss: 6.514458732453932e-07\n",
      "Epoch 3433, Loss: 1.3329826742847217e-05, Final Batch Loss: 9.320864592154976e-06\n",
      "Epoch 3434, Loss: 2.1626555053444463e-06, Final Batch Loss: 1.0316985026292969e-06\n",
      "Epoch 3435, Loss: 6.922309728452092e-05, Final Batch Loss: 1.6553243540329277e-06\n",
      "Epoch 3436, Loss: 4.76945089644687e-07, Final Batch Loss: 7.975255300607387e-08\n",
      "Epoch 3437, Loss: 0.0005413887469103429, Final Batch Loss: 7.236288865897222e-07\n",
      "Epoch 3438, Loss: 3.716131118380872e-06, Final Batch Loss: 1.3372820149015752e-06\n",
      "Epoch 3439, Loss: 0.0010697534474957138, Final Batch Loss: 0.0010680955601856112\n",
      "Epoch 3440, Loss: 2.679511476344487e-05, Final Batch Loss: 2.568693389548571e-06\n",
      "Epoch 3441, Loss: 1.808827626348375e-05, Final Batch Loss: 1.443932688971472e-07\n",
      "Epoch 3442, Loss: 0.00017356557509629056, Final Batch Loss: 3.7608690035995096e-05\n",
      "Epoch 3443, Loss: 5.074627097201301e-06, Final Batch Loss: 4.689354682341218e-06\n",
      "Epoch 3444, Loss: 4.971868202119367e-05, Final Batch Loss: 4.278331107343547e-05\n",
      "Epoch 3445, Loss: 2.397542539256392e-05, Final Batch Loss: 1.366380547551671e-05\n",
      "Epoch 3446, Loss: 2.858258230986621e-06, Final Batch Loss: 5.960456306297601e-08\n",
      "Epoch 3447, Loss: 9.053451816498637e-05, Final Batch Loss: 2.5352659349664464e-07\n",
      "Epoch 3448, Loss: 1.7797999134927522e-05, Final Batch Loss: 6.597979336220305e-06\n",
      "Epoch 3449, Loss: 2.0068082903890172e-05, Final Batch Loss: 4.225285465508932e-06\n",
      "Epoch 3450, Loss: 2.4762321260141107e-06, Final Batch Loss: 1.7881326641600026e-07\n",
      "Epoch 3451, Loss: 0.00019917322725859776, Final Batch Loss: 0.0001989185984712094\n",
      "Epoch 3452, Loss: 5.081683298158168e-06, Final Batch Loss: 9.737804020915064e-07\n",
      "Epoch 3453, Loss: 6.12947528679797e-05, Final Batch Loss: 5.8856341638602316e-05\n",
      "Epoch 3454, Loss: 4.83970758864416e-05, Final Batch Loss: 4.8009893362177536e-05\n",
      "Epoch 3455, Loss: 0.00010215656584477983, Final Batch Loss: 3.0700855859322473e-05\n",
      "Epoch 3456, Loss: 1.7257475803944544e-06, Final Batch Loss: 3.912055319688079e-07\n",
      "Epoch 3457, Loss: 1.6358085339618356e-05, Final Batch Loss: 6.212307113173665e-08\n",
      "Epoch 3458, Loss: 1.1083950312240631e-05, Final Batch Loss: 7.79849142418243e-06\n",
      "Epoch 3459, Loss: 3.0240451422969272e-06, Final Batch Loss: 2.901021389334346e-06\n",
      "Epoch 3460, Loss: 0.00011274191820120905, Final Batch Loss: 9.820594277698547e-05\n",
      "Epoch 3461, Loss: 3.358948697496089e-05, Final Batch Loss: 2.6568219254841097e-05\n",
      "Epoch 3462, Loss: 6.795295939809876e-05, Final Batch Loss: 6.083782864152454e-05\n",
      "Epoch 3463, Loss: 6.331201529974351e-05, Final Batch Loss: 1.3286892681207974e-05\n",
      "Epoch 3464, Loss: 5.1579745559138246e-05, Final Batch Loss: 2.5260145775973797e-05\n",
      "Epoch 3465, Loss: 1.7966395944313263e-05, Final Batch Loss: 1.4297859706857707e-05\n",
      "Epoch 3466, Loss: 3.5098172702419106e-05, Final Batch Loss: 2.839534317899961e-05\n",
      "Epoch 3467, Loss: 0.0053234552038929905, Final Batch Loss: 0.00532279908657074\n",
      "Epoch 3468, Loss: 1.566808055031288e-05, Final Batch Loss: 1.317099076914019e-06\n",
      "Epoch 3469, Loss: 1.6046729797380976e-05, Final Batch Loss: 1.2341616638877895e-05\n",
      "Epoch 3470, Loss: 9.96235699517456e-05, Final Batch Loss: 4.2058815097334445e-07\n",
      "Epoch 3471, Loss: 6.992692408402945e-05, Final Batch Loss: 7.740110277154599e-07\n",
      "Epoch 3472, Loss: 0.00020371004575281404, Final Batch Loss: 4.0239636291516945e-05\n",
      "Epoch 3473, Loss: 0.0002960347040925626, Final Batch Loss: 0.00029465099214576185\n",
      "Epoch 3474, Loss: 8.84865080763575e-07, Final Batch Loss: 8.14314446984099e-08\n",
      "Epoch 3475, Loss: 1.3178730739582534e-05, Final Batch Loss: 5.649760055348452e-07\n",
      "Epoch 3476, Loss: 1.1310308366319077e-05, Final Batch Loss: 5.129218720867357e-07\n",
      "Epoch 3477, Loss: 8.921392395677685e-05, Final Batch Loss: 4.021155746158911e-07\n",
      "Epoch 3478, Loss: 3.369223099980445e-05, Final Batch Loss: 3.313195702503435e-05\n",
      "Epoch 3479, Loss: 1.7361255231662653e-05, Final Batch Loss: 1.4080545952310786e-05\n",
      "Epoch 3480, Loss: 1.0514090263313847e-05, Final Batch Loss: 6.588954420294613e-06\n",
      "Epoch 3481, Loss: 0.00025071986078728514, Final Batch Loss: 3.172166771037155e-06\n",
      "Epoch 3482, Loss: 3.094834119110601e-05, Final Batch Loss: 2.2029611500329338e-05\n",
      "Epoch 3483, Loss: 2.55440872933832e-05, Final Batch Loss: 8.285959665954579e-06\n",
      "Epoch 3484, Loss: 1.994494823520654e-06, Final Batch Loss: 1.4127614349490614e-06\n",
      "Epoch 3485, Loss: 6.368110952692518e-05, Final Batch Loss: 4.8691067178197045e-08\n",
      "Epoch 3486, Loss: 1.3251366169697576e-05, Final Batch Loss: 8.453618534076668e-07\n",
      "Epoch 3487, Loss: 0.0002153579325749888, Final Batch Loss: 0.00020504998974502087\n",
      "Epoch 3488, Loss: 1.2294966438730626e-05, Final Batch Loss: 1.1606912266870495e-05\n",
      "Epoch 3489, Loss: 0.003207737802540578, Final Batch Loss: 1.4271495274442714e-07\n",
      "Epoch 3490, Loss: 5.9266055814077845e-06, Final Batch Loss: 1.988659050766728e-06\n",
      "Epoch 3491, Loss: 1.5294122137188282e-05, Final Batch Loss: 2.5185058483145895e-09\n",
      "Epoch 3492, Loss: 6.645183020737022e-05, Final Batch Loss: 6.482304888777435e-05\n",
      "Epoch 3493, Loss: 7.301154073502403e-05, Final Batch Loss: 2.1092129827593453e-05\n",
      "Epoch 3494, Loss: 2.6035557425529987e-06, Final Batch Loss: 1.7309758959527244e-06\n",
      "Epoch 3495, Loss: 1.0221202558113873e-05, Final Batch Loss: 9.511186931376869e-07\n",
      "Epoch 3496, Loss: 8.966027451151604e-06, Final Batch Loss: 7.765187888253422e-07\n",
      "Epoch 3497, Loss: 0.00012445631671198498, Final Batch Loss: 0.00012318271910771728\n",
      "Epoch 3498, Loss: 2.814476829371415e-06, Final Batch Loss: 1.5362094245574553e-06\n",
      "Epoch 3499, Loss: 5.4381956260840525e-05, Final Batch Loss: 1.6351671092706965e-06\n",
      "Epoch 3500, Loss: 4.29320944022038e-05, Final Batch Loss: 1.4740661754331086e-05\n",
      "Epoch 3501, Loss: 3.4291559796173487e-06, Final Batch Loss: 2.770354790015972e-08\n",
      "Epoch 3502, Loss: 1.272158078791108e-05, Final Batch Loss: 6.959452093724394e-06\n",
      "Epoch 3503, Loss: 0.00012570493800012628, Final Batch Loss: 6.631992619077209e-06\n",
      "Epoch 3504, Loss: 6.807910176576115e-05, Final Batch Loss: 6.494681292679161e-05\n",
      "Epoch 3505, Loss: 6.318279031347629e-05, Final Batch Loss: 6.20298451394774e-05\n",
      "Epoch 3506, Loss: 0.00017425521946279332, Final Batch Loss: 0.00010304395982529968\n",
      "Epoch 3507, Loss: 3.813589080436941e-05, Final Batch Loss: 1.7476771745350561e-06\n",
      "Epoch 3508, Loss: 3.7640329537680373e-06, Final Batch Loss: 3.14416274704854e-06\n",
      "Epoch 3509, Loss: 3.8068114633915684e-05, Final Batch Loss: 3.987576633335266e-07\n",
      "Epoch 3510, Loss: 1.6290347900849156e-05, Final Batch Loss: 1.5513121979893185e-05\n",
      "Epoch 3511, Loss: 3.906310401191604e-05, Final Batch Loss: 2.358984403372233e-07\n",
      "Epoch 3512, Loss: 0.00016889951530174585, Final Batch Loss: 0.00016410576063208282\n",
      "Epoch 3513, Loss: 0.019296525308163837, Final Batch Loss: 0.000146877282531932\n",
      "Epoch 3514, Loss: 0.000550139088474566, Final Batch Loss: 1.5614629944593617e-07\n",
      "Epoch 3515, Loss: 2.4432358713966096e-06, Final Batch Loss: 2.147123723261757e-06\n",
      "Epoch 3516, Loss: 0.00010446800752106356, Final Batch Loss: 9.608580148778856e-05\n",
      "Epoch 3517, Loss: 6.4710727656347444e-06, Final Batch Loss: 2.3889449494163273e-06\n",
      "Epoch 3518, Loss: 7.259628432620957e-06, Final Batch Loss: 5.62451873520331e-07\n",
      "Epoch 3519, Loss: 1.5080648267939978e-06, Final Batch Loss: 5.406245122685505e-07\n",
      "Epoch 3520, Loss: 1.8453483789926395e-05, Final Batch Loss: 8.158063792507164e-06\n",
      "Epoch 3521, Loss: 4.061618895434549e-06, Final Batch Loss: 1.51110000956578e-07\n",
      "Epoch 3522, Loss: 0.00014122990789644518, Final Batch Loss: 0.00014108495088294148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3523, Loss: 1.9527832591847982e-05, Final Batch Loss: 5.53169047634583e-06\n",
      "Epoch 3524, Loss: 1.5879577404120937e-05, Final Batch Loss: 7.076750989654101e-07\n",
      "Epoch 3525, Loss: 5.356428664526902e-05, Final Batch Loss: 9.758085070643574e-06\n",
      "Epoch 3526, Loss: 6.519652515635244e-07, Final Batch Loss: 5.389550210566085e-07\n",
      "Epoch 3527, Loss: 0.00027699802012648433, Final Batch Loss: 0.00020264583872631192\n",
      "Epoch 3528, Loss: 0.00011710633589245845, Final Batch Loss: 2.8295691663515754e-05\n",
      "Epoch 3529, Loss: 4.4904327296535484e-05, Final Batch Loss: 4.8637284635333344e-06\n",
      "Epoch 3530, Loss: 0.001591264946227966, Final Batch Loss: 3.746688207684201e-06\n",
      "Epoch 3531, Loss: 4.159176978646428e-05, Final Batch Loss: 6.989196208451176e-06\n",
      "Epoch 3532, Loss: 0.0022404767078114673, Final Batch Loss: 6.060516170691699e-05\n",
      "Epoch 3533, Loss: 8.12138347328073e-06, Final Batch Loss: 7.630725121998694e-06\n",
      "Epoch 3534, Loss: 1.1030335713257955e-05, Final Batch Loss: 6.422027354346937e-07\n",
      "Epoch 3535, Loss: 3.4945800280183903e-06, Final Batch Loss: 2.056578068732051e-06\n",
      "Epoch 3536, Loss: 0.0004417172792727797, Final Batch Loss: 3.2851573905645637e-06\n",
      "Epoch 3537, Loss: 1.0488216389603622e-05, Final Batch Loss: 9.372010936203878e-06\n",
      "Epoch 3538, Loss: 0.0005091393642544517, Final Batch Loss: 4.684362977513956e-07\n",
      "Epoch 3539, Loss: 0.0001020545678329654, Final Batch Loss: 6.364686123561114e-05\n",
      "Epoch 3540, Loss: 9.323398109017944e-05, Final Batch Loss: 5.725290179725562e-07\n",
      "Epoch 3541, Loss: 7.201069365692092e-06, Final Batch Loss: 1.434660589438863e-06\n",
      "Epoch 3542, Loss: 2.835548821167322e-05, Final Batch Loss: 5.076367415313143e-06\n",
      "Epoch 3543, Loss: 1.7855075327588565e-05, Final Batch Loss: 1.7158436094177887e-05\n",
      "Epoch 3544, Loss: 1.7162477888632566e-05, Final Batch Loss: 8.043853085837327e-06\n",
      "Epoch 3545, Loss: 7.40520323461169e-06, Final Batch Loss: 5.666580022989365e-07\n",
      "Epoch 3546, Loss: 7.65544032788057e-06, Final Batch Loss: 4.424097426181106e-07\n",
      "Epoch 3547, Loss: 3.189896534649961e-05, Final Batch Loss: 3.072557888117444e-07\n",
      "Epoch 3548, Loss: 6.0676204157061875e-05, Final Batch Loss: 1.1529849871294573e-05\n",
      "Epoch 3549, Loss: 5.060663283984468e-07, Final Batch Loss: 1.637025093259581e-07\n",
      "Epoch 3550, Loss: 4.670224188885186e-05, Final Batch Loss: 4.019116749987006e-05\n",
      "Epoch 3551, Loss: 0.0003353945135131653, Final Batch Loss: 0.0003328393795527518\n",
      "Epoch 3552, Loss: 4.791952733285143e-06, Final Batch Loss: 3.91983985537081e-06\n",
      "Epoch 3553, Loss: 5.634340413962491e-05, Final Batch Loss: 2.4826957087498158e-05\n",
      "Epoch 3554, Loss: 0.00011664776775432983, Final Batch Loss: 0.0001071867736754939\n",
      "Epoch 3555, Loss: 3.1990035274986894e-05, Final Batch Loss: 9.822156954442107e-08\n",
      "Epoch 3556, Loss: 1.4931899386283476e-05, Final Batch Loss: 3.674126674013678e-06\n",
      "Epoch 3557, Loss: 7.790321326694993e-06, Final Batch Loss: 3.861703845586817e-08\n",
      "Epoch 3558, Loss: 2.6360464801200578e-05, Final Batch Loss: 2.561899418651592e-05\n",
      "Epoch 3559, Loss: 0.009133013400514756, Final Batch Loss: 5.233536739979172e-06\n",
      "Epoch 3560, Loss: 4.575835419018404e-06, Final Batch Loss: 2.2564308892469853e-06\n",
      "Epoch 3561, Loss: 9.171175179290003e-07, Final Batch Loss: 3.668597514661087e-07\n",
      "Epoch 3562, Loss: 1.7109425698436098e-05, Final Batch Loss: 1.1661751159408595e-05\n",
      "Epoch 3563, Loss: 7.786345489080304e-05, Final Batch Loss: 7.761073356959969e-05\n",
      "Epoch 3564, Loss: 1.350551701762015e-05, Final Batch Loss: 6.256860160647193e-06\n",
      "Epoch 3565, Loss: 0.0021857944020666764, Final Batch Loss: 0.002182380063459277\n",
      "Epoch 3566, Loss: 3.4862759967779766e-06, Final Batch Loss: 5.624655941005585e-08\n",
      "Epoch 3567, Loss: 4.2887747895292705e-06, Final Batch Loss: 1.8669404653337551e-06\n",
      "Epoch 3568, Loss: 4.183102385013626e-05, Final Batch Loss: 1.1761195537474123e-06\n",
      "Epoch 3569, Loss: 0.00012452724058675813, Final Batch Loss: 1.0166198080696631e-05\n",
      "Epoch 3570, Loss: 3.942790499422699e-06, Final Batch Loss: 1.101356019717059e-06\n",
      "Epoch 3571, Loss: 0.0001825040435505798, Final Batch Loss: 1.8280805306858383e-05\n",
      "Epoch 3572, Loss: 0.001125504422816448, Final Batch Loss: 0.0011038401862606406\n",
      "Epoch 3573, Loss: 1.6301591927003756e-05, Final Batch Loss: 1.487210192863131e-05\n",
      "Epoch 3574, Loss: 0.00019694252091539965, Final Batch Loss: 1.4103277408139547e-06\n",
      "Epoch 3575, Loss: 1.803549184842268e-05, Final Batch Loss: 1.2398750186548568e-06\n",
      "Epoch 3576, Loss: 9.709155867199115e-05, Final Batch Loss: 9.663332457421347e-05\n",
      "Epoch 3577, Loss: 0.017488500066974666, Final Batch Loss: 0.017450561746954918\n",
      "Epoch 3578, Loss: 2.4557495876820212e-06, Final Batch Loss: 2.361336100875633e-06\n",
      "Epoch 3579, Loss: 1.2360380367226753e-05, Final Batch Loss: 6.799891139053216e-07\n",
      "Epoch 3580, Loss: 0.0006714992359775351, Final Batch Loss: 0.0006615475285798311\n",
      "Epoch 3581, Loss: 3.0499161809416364e-05, Final Batch Loss: 2.023180485366538e-07\n",
      "Epoch 3582, Loss: 3.986146657553036e-05, Final Batch Loss: 2.6948036975227296e-05\n",
      "Epoch 3583, Loss: 1.76230068973382e-05, Final Batch Loss: 5.0086364353774115e-06\n",
      "Epoch 3584, Loss: 6.0805657540186075e-06, Final Batch Loss: 2.3646873614779906e-06\n",
      "Epoch 3585, Loss: 0.00020845181708750715, Final Batch Loss: 0.0002081051643472165\n",
      "Epoch 3586, Loss: 8.709732537681703e-05, Final Batch Loss: 8.256547880591825e-05\n",
      "Epoch 3587, Loss: 1.139637930691606e-05, Final Batch Loss: 5.784045811196847e-07\n",
      "Epoch 3588, Loss: 2.516187691981031e-05, Final Batch Loss: 2.2943009753362276e-05\n",
      "Epoch 3589, Loss: 6.991884765739087e-05, Final Batch Loss: 2.2372665625880472e-05\n",
      "Epoch 3590, Loss: 2.3306856220983718e-05, Final Batch Loss: 7.05180553950413e-08\n",
      "Epoch 3591, Loss: 0.0002156699844135801, Final Batch Loss: 1.2676097185249091e-06\n",
      "Epoch 3592, Loss: 3.523059476151502e-05, Final Batch Loss: 3.1649014431422984e-07\n",
      "Epoch 3593, Loss: 0.009303150310188357, Final Batch Loss: 0.009291337803006172\n",
      "Epoch 3594, Loss: 0.0002701703624552465, Final Batch Loss: 8.651083589938935e-06\n",
      "Epoch 3595, Loss: 9.251309165847488e-05, Final Batch Loss: 6.895410479046404e-05\n",
      "Epoch 3596, Loss: 5.197938889978104e-06, Final Batch Loss: 1.9668250388349406e-06\n",
      "Epoch 3597, Loss: 0.00028356055190670304, Final Batch Loss: 0.0002352663577767089\n",
      "Epoch 3598, Loss: 0.0004797613013280966, Final Batch Loss: 9.318443261463472e-08\n",
      "Epoch 3599, Loss: 8.245478056778666e-05, Final Batch Loss: 1.2296104614506476e-05\n",
      "Epoch 3600, Loss: 0.0007202864508144557, Final Batch Loss: 7.270823698490858e-05\n",
      "Epoch 3601, Loss: 6.638296690653078e-05, Final Batch Loss: 2.8338741685729474e-05\n",
      "Epoch 3602, Loss: 5.183384155316162e-05, Final Batch Loss: 4.763539891428081e-06\n",
      "Epoch 3603, Loss: 0.00010563564183030394, Final Batch Loss: 2.774279437289806e-06\n",
      "Epoch 3604, Loss: 9.79949636530364e-05, Final Batch Loss: 2.5105082386289723e-05\n",
      "Epoch 3605, Loss: 3.216366485503386e-05, Final Batch Loss: 2.5190869564539753e-05\n",
      "Epoch 3606, Loss: 0.0001824352530093165, Final Batch Loss: 1.4719773389515467e-05\n",
      "Epoch 3607, Loss: 6.469527488661697e-05, Final Batch Loss: 1.1567381989152636e-05\n",
      "Epoch 3608, Loss: 0.00029768737931590294, Final Batch Loss: 1.2126677574997302e-05\n",
      "Epoch 3609, Loss: 3.056462037420715e-05, Final Batch Loss: 2.762500571407145e-06\n",
      "Epoch 3610, Loss: 0.0001431546498906755, Final Batch Loss: 1.767834078236774e-06\n",
      "Epoch 3611, Loss: 0.00012879584187430737, Final Batch Loss: 0.00012730156595353037\n",
      "Epoch 3612, Loss: 0.0004998597778467229, Final Batch Loss: 2.849332486221101e-05\n",
      "Epoch 3613, Loss: 0.000252473461387126, Final Batch Loss: 5.297210918797646e-07\n",
      "Epoch 3614, Loss: 5.0417642341926694e-05, Final Batch Loss: 2.9578752219094895e-05\n",
      "Epoch 3615, Loss: 6.041429378456087e-05, Final Batch Loss: 4.115116553293774e-06\n",
      "Epoch 3616, Loss: 7.670017907912552e-06, Final Batch Loss: 6.247741112019867e-06\n",
      "Epoch 3617, Loss: 0.00027001557100447826, Final Batch Loss: 2.8791280783480033e-05\n",
      "Epoch 3618, Loss: 0.0004627207599696703, Final Batch Loss: 9.08159781829454e-05\n",
      "Epoch 3619, Loss: 3.070411031558251e-05, Final Batch Loss: 3.0119532311800867e-05\n",
      "Epoch 3620, Loss: 6.947312976990361e-05, Final Batch Loss: 2.3096747099771164e-05\n",
      "Epoch 3621, Loss: 1.7144562434623367e-05, Final Batch Loss: 2.380711293881177e-06\n",
      "Epoch 3622, Loss: 0.0001026126501528779, Final Batch Loss: 1.9473935026326217e-05\n",
      "Epoch 3623, Loss: 9.165934429233857e-07, Final Batch Loss: 1.0409799955368726e-07\n",
      "Epoch 3624, Loss: 2.8960337203898234e-06, Final Batch Loss: 1.9667177184601314e-06\n",
      "Epoch 3625, Loss: 0.0001195052100229077, Final Batch Loss: 1.8916158296633512e-05\n",
      "Epoch 3626, Loss: 7.575203414234011e-05, Final Batch Loss: 8.898711456595265e-08\n",
      "Epoch 3627, Loss: 4.382192537377705e-05, Final Batch Loss: 1.1206579983991105e-06\n",
      "Epoch 3628, Loss: 0.0003561070370778907, Final Batch Loss: 1.9961258658440784e-05\n",
      "Epoch 3629, Loss: 0.00010842967094504274, Final Batch Loss: 5.9990259615005925e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3630, Loss: 0.01028498493542429, Final Batch Loss: 0.00015386145969387144\n",
      "Epoch 3631, Loss: 0.002667499051312916, Final Batch Loss: 9.928368672262877e-05\n",
      "Epoch 3632, Loss: 4.6049696265981765e-05, Final Batch Loss: 5.113518000143813e-06\n",
      "Epoch 3633, Loss: 2.239049626950873e-05, Final Batch Loss: 9.919630429067183e-06\n",
      "Epoch 3634, Loss: 3.043792685275548e-05, Final Batch Loss: 6.6615234572964255e-06\n",
      "Epoch 3635, Loss: 0.0005884734473511344, Final Batch Loss: 0.0005744724767282605\n",
      "Epoch 3636, Loss: 9.546086744194326e-06, Final Batch Loss: 1.6915367950787186e-06\n",
      "Epoch 3637, Loss: 2.0904575080749055e-05, Final Batch Loss: 1.149218746832048e-06\n",
      "Epoch 3638, Loss: 0.0004981960246652761, Final Batch Loss: 3.945624769130518e-07\n",
      "Epoch 3639, Loss: 0.00035940235102316365, Final Batch Loss: 4.366510984255001e-05\n",
      "Epoch 3640, Loss: 1.7231879155588103e-05, Final Batch Loss: 2.2286581042862963e-06\n",
      "Epoch 3641, Loss: 0.00028066728896192217, Final Batch Loss: 3.73229318029189e-06\n",
      "Epoch 3642, Loss: 5.47737517990754e-05, Final Batch Loss: 1.4850026673229877e-05\n",
      "Epoch 3643, Loss: 0.00043896044473967777, Final Batch Loss: 0.00043743036803789437\n",
      "Epoch 3644, Loss: 3.9349880353256594e-05, Final Batch Loss: 1.2822291864722501e-05\n",
      "Epoch 3645, Loss: 7.553145042038523e-05, Final Batch Loss: 4.4314558181213215e-05\n",
      "Epoch 3646, Loss: 6.567070977325784e-05, Final Batch Loss: 1.0072192708321381e-05\n",
      "Epoch 3647, Loss: 3.825559878123386e-05, Final Batch Loss: 5.725339065065782e-07\n",
      "Epoch 3648, Loss: 4.411734698805958e-05, Final Batch Loss: 3.4304412110941485e-05\n",
      "Epoch 3649, Loss: 5.245223178462766e-06, Final Batch Loss: 4.1103921830654144e-06\n",
      "Epoch 3650, Loss: 0.00010875636053242488, Final Batch Loss: 7.724370334472042e-06\n",
      "Epoch 3651, Loss: 0.00010801867756526917, Final Batch Loss: 9.265544213121757e-05\n",
      "Epoch 3652, Loss: 0.00029356170671235304, Final Batch Loss: 1.923490890476387e-05\n",
      "Epoch 3653, Loss: 0.00033729130842630184, Final Batch Loss: 2.7535458002603264e-07\n",
      "Epoch 3654, Loss: 2.9097205811012827e-05, Final Batch Loss: 1.782153162821487e-06\n",
      "Epoch 3655, Loss: 9.480393782723695e-05, Final Batch Loss: 3.814207229879685e-05\n",
      "Epoch 3656, Loss: 7.594300299729184e-07, Final Batch Loss: 3.6098548150675924e-08\n",
      "Epoch 3657, Loss: 0.002695113347726874, Final Batch Loss: 0.0026779575273394585\n",
      "Epoch 3658, Loss: 8.68824190547457e-05, Final Batch Loss: 2.282529567310121e-05\n",
      "Epoch 3659, Loss: 2.0245224163772946e-06, Final Batch Loss: 1.318822455687041e-06\n",
      "Epoch 3660, Loss: 2.753865908289299e-05, Final Batch Loss: 1.0543734560997109e-06\n",
      "Epoch 3661, Loss: 1.9434114619798493e-05, Final Batch Loss: 7.486392860300839e-06\n",
      "Epoch 3662, Loss: 1.3830560078531562e-05, Final Batch Loss: 1.2096504178771283e-05\n",
      "Epoch 3663, Loss: 8.423356484854594e-05, Final Batch Loss: 1.8773636838886887e-05\n",
      "Epoch 3664, Loss: 0.0001567198115139945, Final Batch Loss: 0.00015626729873474687\n",
      "Epoch 3665, Loss: 2.429296989703289e-05, Final Batch Loss: 2.2746657123207115e-05\n",
      "Epoch 3666, Loss: 1.2922141195303993e-05, Final Batch Loss: 5.783083452115534e-06\n",
      "Epoch 3667, Loss: 8.868642237302993e-05, Final Batch Loss: 8.807560516288504e-05\n",
      "Epoch 3668, Loss: 2.9013638140895637e-06, Final Batch Loss: 1.6268209037662018e-06\n",
      "Epoch 3669, Loss: 2.8735468731611036e-05, Final Batch Loss: 2.2423437258112244e-05\n",
      "Epoch 3670, Loss: 9.803229659155477e-06, Final Batch Loss: 2.631694314914057e-06\n",
      "Epoch 3671, Loss: 0.00024690704503882444, Final Batch Loss: 0.00024294966715388\n",
      "Epoch 3672, Loss: 7.829392700386961e-06, Final Batch Loss: 7.656192906324577e-07\n",
      "Epoch 3673, Loss: 2.2682297185383504e-05, Final Batch Loss: 6.970563390495954e-06\n",
      "Epoch 3674, Loss: 8.535575148016505e-06, Final Batch Loss: 1.646997702664521e-06\n",
      "Epoch 3675, Loss: 2.5207707949448377e-05, Final Batch Loss: 1.9655752112157643e-05\n",
      "Epoch 3676, Loss: 1.4077488231123425e-05, Final Batch Loss: 3.9732776713208295e-06\n",
      "Epoch 3677, Loss: 2.9046931558696087e-05, Final Batch Loss: 1.4713837117596995e-05\n",
      "Epoch 3678, Loss: 7.821331882951199e-05, Final Batch Loss: 3.25953942592605e-06\n",
      "Epoch 3679, Loss: 0.0003602047167987621, Final Batch Loss: 7.298711807379732e-06\n",
      "Epoch 3680, Loss: 1.3624117656263479e-05, Final Batch Loss: 3.9288332231990353e-07\n",
      "Epoch 3681, Loss: 1.7163190477731405e-05, Final Batch Loss: 6.7411933741823304e-06\n",
      "Epoch 3682, Loss: 0.00017991979757425725, Final Batch Loss: 0.00017310127441305667\n",
      "Epoch 3683, Loss: 3.2924617698881775e-05, Final Batch Loss: 4.7347202780656517e-07\n",
      "Epoch 3684, Loss: 0.00014608445917474455, Final Batch Loss: 5.305564172886079e-06\n",
      "Epoch 3685, Loss: 1.0445516949175726e-05, Final Batch Loss: 3.710523230893159e-07\n",
      "Epoch 3686, Loss: 4.87393393768798e-05, Final Batch Loss: 1.3213378906584694e-06\n",
      "Epoch 3687, Loss: 7.440783275569629e-05, Final Batch Loss: 6.699168011436996e-07\n",
      "Epoch 3688, Loss: 1.939063713507494e-05, Final Batch Loss: 9.777087143447716e-06\n",
      "Epoch 3689, Loss: 0.00012280377268325537, Final Batch Loss: 7.565964187961072e-05\n",
      "Epoch 3690, Loss: 2.3069527287589153e-05, Final Batch Loss: 4.598010036716005e-06\n",
      "Epoch 3691, Loss: 9.965699064196087e-06, Final Batch Loss: 7.6546339187189e-06\n",
      "Epoch 3692, Loss: 1.952833167706558e-05, Final Batch Loss: 7.689666290389141e-07\n",
      "Epoch 3693, Loss: 7.569387344119605e-05, Final Batch Loss: 7.002517668297514e-05\n",
      "Epoch 3694, Loss: 0.0001469344788347371, Final Batch Loss: 7.727707998128608e-05\n",
      "Epoch 3695, Loss: 1.4677805779683695e-05, Final Batch Loss: 1.3773783393844496e-05\n",
      "Epoch 3696, Loss: 2.1170573859308206e-05, Final Batch Loss: 1.0887798680414562e-06\n",
      "Epoch 3697, Loss: 0.0005656327984979725, Final Batch Loss: 0.0005548892659135163\n",
      "Epoch 3698, Loss: 1.3413101669357275e-06, Final Batch Loss: 8.13461440429819e-07\n",
      "Epoch 3699, Loss: 0.0001669469206717622, Final Batch Loss: 0.00016517704352736473\n",
      "Epoch 3700, Loss: 0.00039282074453694804, Final Batch Loss: 7.664496024517575e-07\n",
      "Epoch 3701, Loss: 4.912440414273078e-05, Final Batch Loss: 8.143011314132309e-07\n",
      "Epoch 3702, Loss: 6.348180466630993e-05, Final Batch Loss: 1.0997462851491946e-07\n",
      "Epoch 3703, Loss: 4.39660743722925e-06, Final Batch Loss: 1.0149369700229727e-06\n",
      "Epoch 3704, Loss: 2.653653882589424e-05, Final Batch Loss: 5.51048378838459e-06\n",
      "Epoch 3705, Loss: 7.74115719650581e-05, Final Batch Loss: 7.627721788594499e-05\n",
      "Epoch 3706, Loss: 0.004166478060597001, Final Batch Loss: 6.3523207245452795e-06\n",
      "Epoch 3707, Loss: 2.1709917518819566e-05, Final Batch Loss: 2.0076424334547482e-05\n",
      "Epoch 3708, Loss: 5.169660653336905e-06, Final Batch Loss: 2.6199029434792465e-06\n",
      "Epoch 3709, Loss: 0.00012535212090369896, Final Batch Loss: 2.59277521763579e-06\n",
      "Epoch 3710, Loss: 1.5199220115391654e-05, Final Batch Loss: 2.9137420369806932e-06\n",
      "Epoch 3711, Loss: 0.00033047812394215725, Final Batch Loss: 0.0002812936145346612\n",
      "Epoch 3712, Loss: 1.8765264030662365e-05, Final Batch Loss: 9.72964789980324e-06\n",
      "Epoch 3713, Loss: 1.4493521121039521e-05, Final Batch Loss: 5.477454578795005e-06\n",
      "Epoch 3714, Loss: 0.00012301444803597406, Final Batch Loss: 4.195491783320904e-06\n",
      "Epoch 3715, Loss: 1.872874736363883e-05, Final Batch Loss: 1.169451843452407e-05\n",
      "Epoch 3716, Loss: 0.00041336718277307227, Final Batch Loss: 0.0003896287817042321\n",
      "Epoch 3717, Loss: 1.7500435660622315e-05, Final Batch Loss: 3.2114826353790704e-06\n",
      "Epoch 3718, Loss: 0.00019903197289750096, Final Batch Loss: 3.8961593418207485e-06\n",
      "Epoch 3719, Loss: 6.853265495010419e-05, Final Batch Loss: 5.7255201681982726e-05\n",
      "Epoch 3720, Loss: 0.0006834314590378199, Final Batch Loss: 0.0006669563590548933\n",
      "Epoch 3721, Loss: 0.00019624731794465333, Final Batch Loss: 0.0001030309431371279\n",
      "Epoch 3722, Loss: 2.13844041354605e-05, Final Batch Loss: 1.2184689694549888e-05\n",
      "Epoch 3723, Loss: 3.4819839129340835e-05, Final Batch Loss: 3.338850729051046e-05\n",
      "Epoch 3724, Loss: 0.001751645962940529, Final Batch Loss: 0.0004880117776338011\n",
      "Epoch 3725, Loss: 0.00013155638953321613, Final Batch Loss: 3.8849222619319335e-05\n",
      "Epoch 3726, Loss: 2.5554825882068144e-06, Final Batch Loss: 1.066164898588795e-07\n",
      "Epoch 3727, Loss: 0.0001036911071423674, Final Batch Loss: 2.650710848683957e-05\n",
      "Epoch 3728, Loss: 7.900214677647455e-05, Final Batch Loss: 1.3620966456073802e-05\n",
      "Epoch 3729, Loss: 0.0017360163474222645, Final Batch Loss: 0.00013665527512785047\n",
      "Epoch 3730, Loss: 1.2827390605707478e-05, Final Batch Loss: 1.2336729014350567e-05\n",
      "Epoch 3731, Loss: 1.0245417115584132e-05, Final Batch Loss: 1.9164010609529214e-06\n",
      "Epoch 3732, Loss: 2.724845126067521e-05, Final Batch Loss: 9.178554137179162e-06\n",
      "Epoch 3733, Loss: 0.018547383895565872, Final Batch Loss: 0.018532684072852135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3734, Loss: 9.527732345304685e-06, Final Batch Loss: 4.448703293746803e-06\n",
      "Epoch 3735, Loss: 1.0142037581317709e-05, Final Batch Loss: 3.7044299006083747e-06\n",
      "Epoch 3736, Loss: 7.382707963188295e-06, Final Batch Loss: 2.4612688775960123e-06\n",
      "Epoch 3737, Loss: 3.2388460482479786e-06, Final Batch Loss: 1.0241900838536822e-07\n",
      "Epoch 3738, Loss: 8.984813412382664e-06, Final Batch Loss: 3.693805439297648e-08\n",
      "Epoch 3739, Loss: 2.515675441827625e-05, Final Batch Loss: 4.450055712368339e-06\n",
      "Epoch 3740, Loss: 0.0018202939531875018, Final Batch Loss: 0.0018177024321630597\n",
      "Epoch 3741, Loss: 4.7738387820572825e-06, Final Batch Loss: 4.2068882066814695e-06\n",
      "Epoch 3742, Loss: 1.5834692810301476e-06, Final Batch Loss: 1.5252953744493425e-06\n",
      "Epoch 3743, Loss: 1.91948782912732e-06, Final Batch Loss: 6.564739010173071e-07\n",
      "Epoch 3744, Loss: 3.331430639263999e-05, Final Batch Loss: 1.8367056782153668e-06\n",
      "Epoch 3745, Loss: 0.0004449026893098562, Final Batch Loss: 1.5512633808612009e-06\n",
      "Epoch 3746, Loss: 1.1704239796017646e-05, Final Batch Loss: 2.7657094960886752e-06\n",
      "Epoch 3747, Loss: 1.4235356047720416e-05, Final Batch Loss: 1.173599866888253e-05\n",
      "Epoch 3748, Loss: 0.0001913743466275264, Final Batch Loss: 1.1383375522200367e-06\n",
      "Epoch 3749, Loss: 0.0069502977361253215, Final Batch Loss: 5.842824748469866e-07\n",
      "Epoch 3750, Loss: 0.0017431124563245248, Final Batch Loss: 3.5420509902905906e-06\n",
      "Epoch 3751, Loss: 9.8211634508516e-05, Final Batch Loss: 1.3834452374794637e-06\n",
      "Epoch 3752, Loss: 0.003881967667439312, Final Batch Loss: 1.3026915439695586e-05\n",
      "Epoch 3753, Loss: 2.1952687973225693e-05, Final Batch Loss: 2.1024325178586878e-05\n",
      "Epoch 3754, Loss: 1.1583299908579647e-05, Final Batch Loss: 1.0789868611027487e-05\n",
      "Epoch 3755, Loss: 9.05053690303248e-06, Final Batch Loss: 8.177944437193219e-06\n",
      "Epoch 3756, Loss: 4.862514424530673e-05, Final Batch Loss: 4.4194046495249495e-05\n",
      "Epoch 3757, Loss: 5.2790754466514045e-05, Final Batch Loss: 1.771284928508976e-06\n",
      "Epoch 3758, Loss: 1.3718470199819421e-06, Final Batch Loss: 6.976154622861941e-07\n",
      "Epoch 3759, Loss: 3.000664537466946e-05, Final Batch Loss: 2.7629963369690813e-05\n",
      "Epoch 3760, Loss: 3.466934231255436e-05, Final Batch Loss: 1.3164802112441976e-05\n",
      "Epoch 3761, Loss: 0.0008632290409877896, Final Batch Loss: 0.0005687918164767325\n",
      "Epoch 3762, Loss: 4.38738476304934e-06, Final Batch Loss: 8.310933594657399e-07\n",
      "Epoch 3763, Loss: 6.618798988711205e-05, Final Batch Loss: 5.8730565797304735e-05\n",
      "Epoch 3764, Loss: 0.009811562920617689, Final Batch Loss: 0.009810547344386578\n",
      "Epoch 3765, Loss: 3.25699993481976e-05, Final Batch Loss: 2.782519004540518e-05\n",
      "Epoch 3766, Loss: 1.087629732410278e-05, Final Batch Loss: 1.492583010076487e-06\n",
      "Epoch 3767, Loss: 0.005607347520253825, Final Batch Loss: 1.2550076462503057e-06\n",
      "Epoch 3768, Loss: 5.406323725765105e-05, Final Batch Loss: 4.867390453000553e-05\n",
      "Epoch 3769, Loss: 9.733543537038258e-05, Final Batch Loss: 9.719095396576449e-05\n",
      "Epoch 3770, Loss: 1.829406392062083e-05, Final Batch Loss: 5.975144631520379e-06\n",
      "Epoch 3771, Loss: 1.7513284774395288e-05, Final Batch Loss: 1.3702321666642092e-05\n",
      "Epoch 3772, Loss: 5.3497317367146024e-05, Final Batch Loss: 6.07760966886417e-06\n",
      "Epoch 3773, Loss: 0.00032322075276169926, Final Batch Loss: 1.0111878509633243e-05\n",
      "Epoch 3774, Loss: 0.00012173975028417772, Final Batch Loss: 0.00011095032095909119\n",
      "Epoch 3775, Loss: 2.5868961529340595e-05, Final Batch Loss: 9.518525985185988e-06\n",
      "Epoch 3776, Loss: 0.00014824207499941622, Final Batch Loss: 8.680046335030056e-07\n",
      "Epoch 3777, Loss: 6.919140162153781e-06, Final Batch Loss: 4.12190786391875e-07\n",
      "Epoch 3778, Loss: 0.00012166388341938728, Final Batch Loss: 0.00011588335473788902\n",
      "Epoch 3779, Loss: 0.00010879641195060685, Final Batch Loss: 3.3027165045496076e-05\n",
      "Epoch 3780, Loss: 2.1116443932100992e-05, Final Batch Loss: 1.2088788992059563e-07\n",
      "Epoch 3781, Loss: 7.608512350998353e-05, Final Batch Loss: 5.807967681903392e-05\n",
      "Epoch 3782, Loss: 3.83229678391217e-06, Final Batch Loss: 9.48618549045932e-07\n",
      "Epoch 3783, Loss: 9.094540018850239e-06, Final Batch Loss: 4.8369765863753855e-06\n",
      "Epoch 3784, Loss: 0.0003312968256068416, Final Batch Loss: 7.01765893609263e-05\n",
      "Epoch 3785, Loss: 2.9310910576896276e-05, Final Batch Loss: 4.872733370575588e-06\n",
      "Epoch 3786, Loss: 0.00017096370083891088, Final Batch Loss: 0.00015652336878702044\n",
      "Epoch 3787, Loss: 1.9185519477105117e-05, Final Batch Loss: 3.0150802103889873e-06\n",
      "Epoch 3788, Loss: 0.001260827630176209, Final Batch Loss: 0.00013735830725636333\n",
      "Epoch 3789, Loss: 1.0909260197422554e-06, Final Batch Loss: 2.4933112285907555e-07\n",
      "Epoch 3790, Loss: 2.50874236371601e-05, Final Batch Loss: 1.4304060641734395e-05\n",
      "Epoch 3791, Loss: 3.9838092561694793e-05, Final Batch Loss: 2.6139870897168294e-05\n",
      "Epoch 3792, Loss: 7.806949179212097e-05, Final Batch Loss: 2.7284784664516337e-05\n",
      "Epoch 3793, Loss: 0.00011620489431152237, Final Batch Loss: 4.224021267873468e-06\n",
      "Epoch 3794, Loss: 1.2177529981727275e-05, Final Batch Loss: 5.993995841890865e-07\n",
      "Epoch 3795, Loss: 0.00032166710388992215, Final Batch Loss: 1.4172940609569196e-05\n",
      "Epoch 3796, Loss: 8.14328768683481e-06, Final Batch Loss: 1.9885223991877865e-06\n",
      "Epoch 3797, Loss: 3.106878352809872e-06, Final Batch Loss: 2.1346515950426692e-06\n",
      "Epoch 3798, Loss: 3.622681333581568e-05, Final Batch Loss: 3.881973043462494e-06\n",
      "Epoch 3799, Loss: 0.00023557718668598682, Final Batch Loss: 0.00019086241081822664\n",
      "Epoch 3800, Loss: 0.0013053173970547505, Final Batch Loss: 0.0012843264266848564\n",
      "Epoch 3801, Loss: 4.438388987182407e-05, Final Batch Loss: 3.1376614060718566e-05\n",
      "Epoch 3802, Loss: 4.967348286299966e-05, Final Batch Loss: 3.693829057738185e-06\n",
      "Epoch 3803, Loss: 3.89927918149624e-05, Final Batch Loss: 1.8020808056462556e-05\n",
      "Epoch 3804, Loss: 3.8030191035431926e-05, Final Batch Loss: 2.4998382741614478e-06\n",
      "Epoch 3805, Loss: 2.4570113055233378e-05, Final Batch Loss: 1.1486825314932503e-05\n",
      "Epoch 3806, Loss: 1.1721257763497306e-05, Final Batch Loss: 1.1513835488585755e-05\n",
      "Epoch 3807, Loss: 1.1045991413993761e-05, Final Batch Loss: 4.195047949906439e-06\n",
      "Epoch 3808, Loss: 1.1550525158554592e-05, Final Batch Loss: 3.6266166603127203e-07\n",
      "Epoch 3809, Loss: 1.3910749203205341e-05, Final Batch Loss: 6.4059358919621445e-06\n",
      "Epoch 3810, Loss: 6.531732287839986e-05, Final Batch Loss: 4.5332490117289126e-07\n",
      "Epoch 3811, Loss: 0.0003031914652638079, Final Batch Loss: 0.0003001742879860103\n",
      "Epoch 3812, Loss: 4.43944355339454e-05, Final Batch Loss: 1.58665059757368e-07\n",
      "Epoch 3813, Loss: 0.00012746785796480253, Final Batch Loss: 6.647255941061303e-05\n",
      "Epoch 3814, Loss: 5.694852063697908e-06, Final Batch Loss: 1.5026995470179827e-07\n",
      "Epoch 3815, Loss: 1.0160472641018714e-06, Final Batch Loss: 6.715995937156549e-08\n",
      "Epoch 3816, Loss: 0.0002468513266649097, Final Batch Loss: 7.813549018464983e-05\n",
      "Epoch 3817, Loss: 7.038365674816305e-05, Final Batch Loss: 5.010305358155165e-06\n",
      "Epoch 3818, Loss: 1.4795524734267929e-06, Final Batch Loss: 1.0493740632000481e-07\n",
      "Epoch 3819, Loss: 3.848549521734412e-05, Final Batch Loss: 9.318454630147244e-08\n",
      "Epoch 3820, Loss: 1.6696640614100033e-05, Final Batch Loss: 1.5979017916833982e-05\n",
      "Epoch 3821, Loss: 5.99022479264022e-06, Final Batch Loss: 5.336016783985542e-06\n",
      "Epoch 3822, Loss: 1.9225990513405122e-05, Final Batch Loss: 1.0972090649374877e-06\n",
      "Epoch 3823, Loss: 0.005489494600624312, Final Batch Loss: 0.0054016439244151115\n",
      "Epoch 3824, Loss: 0.0003535854339133948, Final Batch Loss: 0.00012858711124863476\n",
      "Epoch 3825, Loss: 0.005992665978283185, Final Batch Loss: 0.0059886835515499115\n",
      "Epoch 3826, Loss: 5.684461484634085e-06, Final Batch Loss: 3.66498875337129e-06\n",
      "Epoch 3827, Loss: 0.006219085285010806, Final Batch Loss: 0.006210625637322664\n",
      "Epoch 3828, Loss: 0.0007418606692226604, Final Batch Loss: 4.075323522556573e-05\n",
      "Epoch 3829, Loss: 7.310056389542297e-05, Final Batch Loss: 6.619358464377001e-05\n",
      "Epoch 3830, Loss: 1.982315507120802e-05, Final Batch Loss: 5.202000011195196e-06\n",
      "Epoch 3831, Loss: 8.584195529692806e-05, Final Batch Loss: 1.479871934861876e-05\n",
      "Epoch 3832, Loss: 4.907088714389829e-05, Final Batch Loss: 4.367950532468967e-05\n",
      "Epoch 3833, Loss: 8.40904685901478e-05, Final Batch Loss: 4.349897426436655e-05\n",
      "Epoch 3834, Loss: 3.5360156289243605e-05, Final Batch Loss: 2.0420658984221518e-05\n",
      "Epoch 3835, Loss: 7.632244273736433e-05, Final Batch Loss: 2.880170768548851e-06\n",
      "Epoch 3836, Loss: 6.871198092994746e-05, Final Batch Loss: 2.0170698917354457e-05\n",
      "Epoch 3837, Loss: 2.456143715789949e-05, Final Batch Loss: 2.148934072465636e-05\n",
      "Epoch 3838, Loss: 2.5319616270280676e-05, Final Batch Loss: 2.42687428908539e-06\n",
      "Epoch 3839, Loss: 0.0012629904667846859, Final Batch Loss: 7.715210085734725e-05\n",
      "Epoch 3840, Loss: 4.9292471430817386e-05, Final Batch Loss: 4.247133983881213e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3841, Loss: 2.1766080863017123e-05, Final Batch Loss: 1.3231779121269938e-05\n",
      "Epoch 3842, Loss: 2.3736363800708205e-05, Final Batch Loss: 1.5306044588214718e-05\n",
      "Epoch 3843, Loss: 4.0992234517034376e-05, Final Batch Loss: 3.71865535271354e-05\n",
      "Epoch 3844, Loss: 0.0004599820531439036, Final Batch Loss: 0.0003075777494814247\n",
      "Epoch 3845, Loss: 2.0050987217246075e-06, Final Batch Loss: 1.8434514004184166e-06\n",
      "Epoch 3846, Loss: 0.00023893877732916735, Final Batch Loss: 0.00018548796651884913\n",
      "Epoch 3847, Loss: 6.708830596835469e-06, Final Batch Loss: 3.311198042865726e-06\n",
      "Epoch 3848, Loss: 1.3360352056679403e-05, Final Batch Loss: 2.9214464802862494e-07\n",
      "Epoch 3849, Loss: 0.0001940764823302743, Final Batch Loss: 1.0628301424731035e-05\n",
      "Epoch 3850, Loss: 1.5098356129783497e-06, Final Batch Loss: 1.804921225811995e-07\n",
      "Epoch 3851, Loss: 3.769162049138686e-05, Final Batch Loss: 2.9931265089544468e-05\n",
      "Epoch 3852, Loss: 0.00010071743781736586, Final Batch Loss: 2.486808989488054e-05\n",
      "Epoch 3853, Loss: 1.7186639524879865e-05, Final Batch Loss: 1.4306609955383465e-05\n",
      "Epoch 3854, Loss: 3.411193756619468e-05, Final Batch Loss: 1.1590631402214058e-05\n",
      "Epoch 3855, Loss: 8.920163963921368e-06, Final Batch Loss: 1.6344115465471987e-06\n",
      "Epoch 3856, Loss: 1.701562678135815e-05, Final Batch Loss: 1.4594868844142184e-05\n",
      "Epoch 3857, Loss: 8.860992784320842e-05, Final Batch Loss: 1.1221634849789552e-05\n",
      "Epoch 3858, Loss: 1.1667577155094477e-05, Final Batch Loss: 9.266927918361034e-06\n",
      "Epoch 3859, Loss: 5.4401596116804285e-05, Final Batch Loss: 5.8345535762782674e-06\n",
      "Epoch 3860, Loss: 6.203681687111384e-05, Final Batch Loss: 5.551155481953174e-05\n",
      "Epoch 3861, Loss: 6.979124805184256e-06, Final Batch Loss: 6.085569566494087e-06\n",
      "Epoch 3862, Loss: 0.00016592710016993806, Final Batch Loss: 7.651766645722091e-05\n",
      "Epoch 3863, Loss: 0.00015461698785657063, Final Batch Loss: 7.216856465674937e-05\n",
      "Epoch 3864, Loss: 5.341953794868459e-07, Final Batch Loss: 3.2152715334632376e-07\n",
      "Epoch 3865, Loss: 9.797309394343756e-05, Final Batch Loss: 1.4784545783186331e-05\n",
      "Epoch 3866, Loss: 1.718668323746897e-05, Final Batch Loss: 8.436819030066545e-07\n",
      "Epoch 3867, Loss: 0.00016771883383626118, Final Batch Loss: 1.6095531464088708e-05\n",
      "Epoch 3868, Loss: 4.088157766091172e-06, Final Batch Loss: 3.2068646760308184e-07\n",
      "Epoch 3869, Loss: 6.526942479467834e-05, Final Batch Loss: 6.150432000140427e-06\n",
      "Epoch 3870, Loss: 3.9223423755174736e-05, Final Batch Loss: 1.9777312445512507e-06\n",
      "Epoch 3871, Loss: 0.0002577239338279469, Final Batch Loss: 0.0002536674728617072\n",
      "Epoch 3872, Loss: 3.095171518907591e-05, Final Batch Loss: 2.9001077564316802e-05\n",
      "Epoch 3873, Loss: 2.4893964678085467e-05, Final Batch Loss: 1.5118672536118538e-06\n",
      "Epoch 3874, Loss: 5.1955795242975e-05, Final Batch Loss: 6.239702088350896e-06\n",
      "Epoch 3875, Loss: 3.214087882952299e-05, Final Batch Loss: 2.404898259555921e-05\n",
      "Epoch 3876, Loss: 4.6268634562807165e-05, Final Batch Loss: 5.456759311073256e-08\n",
      "Epoch 3877, Loss: 4.0103104765876196e-05, Final Batch Loss: 5.010149834561162e-06\n",
      "Epoch 3878, Loss: 2.0406211547197017e-06, Final Batch Loss: 8.495616725667787e-07\n",
      "Epoch 3879, Loss: 3.4897720979643054e-05, Final Batch Loss: 2.0970479454263113e-05\n",
      "Epoch 3880, Loss: 4.559168155537918e-05, Final Batch Loss: 8.686645742272958e-06\n",
      "Epoch 3881, Loss: 2.396036677509983e-06, Final Batch Loss: 1.9726098798855674e-06\n",
      "Epoch 3882, Loss: 0.009465258743148297, Final Batch Loss: 0.0007797593134455383\n",
      "Epoch 3883, Loss: 4.597524275595788e-05, Final Batch Loss: 3.0587849323637784e-05\n",
      "Epoch 3884, Loss: 0.00025567538978066295, Final Batch Loss: 3.5448421840555966e-05\n",
      "Epoch 3885, Loss: 8.635030098957941e-05, Final Batch Loss: 8.154936949722469e-06\n",
      "Epoch 3886, Loss: 3.6145235185358615e-05, Final Batch Loss: 3.559640026651323e-05\n",
      "Epoch 3887, Loss: 0.00048804006473801564, Final Batch Loss: 1.9226046788389795e-05\n",
      "Epoch 3888, Loss: 2.4485208086844068e-05, Final Batch Loss: 2.2041978809284046e-05\n",
      "Epoch 3889, Loss: 5.2150246119708754e-05, Final Batch Loss: 2.7030064302380197e-05\n",
      "Epoch 3890, Loss: 3.6717328839586116e-05, Final Batch Loss: 1.2403792425175197e-05\n",
      "Epoch 3891, Loss: 1.1588273650886549e-05, Final Batch Loss: 1.252505740012566e-06\n",
      "Epoch 3892, Loss: 8.958470971265342e-06, Final Batch Loss: 6.089978342060931e-06\n",
      "Epoch 3893, Loss: 1.5090240253812226e-05, Final Batch Loss: 1.205475768983888e-06\n",
      "Epoch 3894, Loss: 9.353886127883015e-07, Final Batch Loss: 1.410358265729883e-07\n",
      "Epoch 3895, Loss: 3.0388843015316525e-06, Final Batch Loss: 1.3171486443752656e-06\n",
      "Epoch 3896, Loss: 1.1865994792970014e-05, Final Batch Loss: 1.8778503090288723e-06\n",
      "Epoch 3897, Loss: 4.4897924453835e-06, Final Batch Loss: 2.8991830731683876e-06\n",
      "Epoch 3898, Loss: 0.0001184533248306252, Final Batch Loss: 1.8540995370130986e-05\n",
      "Epoch 3899, Loss: 0.0010994683107128367, Final Batch Loss: 0.00011725454533006996\n",
      "Epoch 3900, Loss: 3.1618032124924866e-05, Final Batch Loss: 3.8029062920941215e-07\n",
      "Epoch 3901, Loss: 0.00027954077086178586, Final Batch Loss: 0.00020870279695373029\n",
      "Epoch 3902, Loss: 0.003542391683367896, Final Batch Loss: 8.85721055965405e-06\n",
      "Epoch 3903, Loss: 0.00017938415658136364, Final Batch Loss: 2.7356136342859827e-05\n",
      "Epoch 3904, Loss: 1.1207583838768187e-05, Final Batch Loss: 2.0927470814058324e-06\n",
      "Epoch 3905, Loss: 0.0002416678125882754, Final Batch Loss: 1.628399513720069e-05\n",
      "Epoch 3906, Loss: 0.011566054075956345, Final Batch Loss: 0.004428423009812832\n",
      "Epoch 3907, Loss: 4.9022982238966506e-05, Final Batch Loss: 1.0293532795913052e-05\n",
      "Epoch 3908, Loss: 0.0002612692690036056, Final Batch Loss: 2.2118540528026642e-06\n",
      "Epoch 3909, Loss: 0.00020424687954800902, Final Batch Loss: 0.00019227623124606907\n",
      "Epoch 3910, Loss: 0.0008463683479931206, Final Batch Loss: 0.0002768915437627584\n",
      "Epoch 3911, Loss: 7.830506592654274e-05, Final Batch Loss: 7.230930350488052e-05\n",
      "Epoch 3912, Loss: 3.2408374863734934e-06, Final Batch Loss: 1.1080953754571965e-06\n",
      "Epoch 3913, Loss: 1.6391587678299402e-06, Final Batch Loss: 5.129190867592115e-07\n",
      "Epoch 3914, Loss: 0.0008618125575594604, Final Batch Loss: 0.000830212258733809\n",
      "Epoch 3915, Loss: 9.457103260501754e-06, Final Batch Loss: 5.289392447593855e-06\n",
      "Epoch 3916, Loss: 1.930604241806577e-06, Final Batch Loss: 5.473446549331129e-07\n",
      "Epoch 3917, Loss: 0.0004039510040456662, Final Batch Loss: 2.56859293585876e-05\n",
      "Epoch 3918, Loss: 3.390708620543137e-05, Final Batch Loss: 1.259245863138858e-07\n",
      "Epoch 3919, Loss: 0.007192757234065539, Final Batch Loss: 0.007191771175712347\n",
      "Epoch 3920, Loss: 4.687593275320978e-05, Final Batch Loss: 4.629611430573277e-05\n",
      "Epoch 3921, Loss: 1.2368245734251104e-05, Final Batch Loss: 4.013582838524599e-06\n",
      "Epoch 3922, Loss: 5.445859187602764e-06, Final Batch Loss: 3.421622750465758e-06\n",
      "Epoch 3923, Loss: 1.2971444846243685e-05, Final Batch Loss: 1.2203749065520242e-05\n",
      "Epoch 3924, Loss: 6.08486783448825e-06, Final Batch Loss: 7.479597456949705e-07\n",
      "Epoch 3925, Loss: 0.00012035085019590497, Final Batch Loss: 1.3012250121846591e-07\n",
      "Epoch 3926, Loss: 1.6210230569413397e-05, Final Batch Loss: 7.659356015210506e-06\n",
      "Epoch 3927, Loss: 0.006005108429235406, Final Batch Loss: 0.00012441266153473407\n",
      "Epoch 3928, Loss: 0.0001389714452670887, Final Batch Loss: 1.971142046386376e-05\n",
      "Epoch 3929, Loss: 3.4166537375313055e-05, Final Batch Loss: 1.7301218804277596e-06\n",
      "Epoch 3930, Loss: 6.606245005968958e-05, Final Batch Loss: 3.499493686831556e-05\n",
      "Epoch 3931, Loss: 3.029637218787684e-05, Final Batch Loss: 3.2752864171925467e-06\n",
      "Epoch 3932, Loss: 1.7674865148364916e-05, Final Batch Loss: 1.4444616681430489e-05\n",
      "Epoch 3933, Loss: 2.7569271196625778e-05, Final Batch Loss: 1.707469209577539e-06\n",
      "Epoch 3934, Loss: 3.133449695269519e-06, Final Batch Loss: 1.9986057395726675e-06\n",
      "Epoch 3935, Loss: 5.65573691346799e-06, Final Batch Loss: 1.1492570592963602e-06\n",
      "Epoch 3936, Loss: 6.5591124212005525e-06, Final Batch Loss: 5.018606771045597e-06\n",
      "Epoch 3937, Loss: 8.890039623565826e-06, Final Batch Loss: 3.853273824461212e-07\n",
      "Epoch 3938, Loss: 2.263310943817487e-05, Final Batch Loss: 6.3320139815914445e-06\n",
      "Epoch 3939, Loss: 3.366664532222785e-05, Final Batch Loss: 2.5655219360487536e-05\n",
      "Epoch 3940, Loss: 1.2095720876459382e-05, Final Batch Loss: 2.934698159151594e-06\n",
      "Epoch 3941, Loss: 2.2186914748090203e-05, Final Batch Loss: 1.6151232102856738e-06\n",
      "Epoch 3942, Loss: 7.412258128169924e-05, Final Batch Loss: 1.5357763913925737e-05\n",
      "Epoch 3943, Loss: 3.141553588648094e-05, Final Batch Loss: 4.730788532469887e-06\n",
      "Epoch 3944, Loss: 0.00027148561230205814, Final Batch Loss: 0.0002680781180970371\n",
      "Epoch 3945, Loss: 0.008617836231678666, Final Batch Loss: 0.008613565005362034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3946, Loss: 1.8661317881196737e-05, Final Batch Loss: 1.3891394701204263e-05\n",
      "Epoch 3947, Loss: 1.3980068160890369e-05, Final Batch Loss: 7.355516117968364e-06\n",
      "Epoch 3948, Loss: 5.694117635357543e-05, Final Batch Loss: 1.4254342204367276e-06\n",
      "Epoch 3949, Loss: 1.0798599760164507e-05, Final Batch Loss: 8.159958269970957e-06\n",
      "Epoch 3950, Loss: 1.3514516012946842e-05, Final Batch Loss: 6.2946442085376475e-06\n",
      "Epoch 3951, Loss: 5.64430030181029e-05, Final Batch Loss: 1.0695094943002914e-06\n",
      "Epoch 3952, Loss: 0.00014657804052831125, Final Batch Loss: 3.1313169301938615e-07\n",
      "Epoch 3953, Loss: 1.944714313140139e-05, Final Batch Loss: 5.576046532951295e-06\n",
      "Epoch 3954, Loss: 1.137572053266922e-05, Final Batch Loss: 6.014585324010113e-06\n",
      "Epoch 3955, Loss: 0.0003266177494651856, Final Batch Loss: 1.603342184353096e-06\n",
      "Epoch 3956, Loss: 1.4886863027641084e-05, Final Batch Loss: 3.5533330446924083e-06\n",
      "Epoch 3957, Loss: 0.000200189632778347, Final Batch Loss: 0.0001850308763096109\n",
      "Epoch 3958, Loss: 2.2399054614652414e-05, Final Batch Loss: 7.877007192291785e-06\n",
      "Epoch 3959, Loss: 1.1136875514239364e-05, Final Batch Loss: 1.518591602689412e-06\n",
      "Epoch 3960, Loss: 0.0025728506734594703, Final Batch Loss: 0.002513000974431634\n",
      "Epoch 3961, Loss: 0.00010828010636032559, Final Batch Loss: 7.253760122694075e-05\n",
      "Epoch 3962, Loss: 3.2503193096999894e-06, Final Batch Loss: 8.126131660901592e-07\n",
      "Epoch 3963, Loss: 0.0010975494096783223, Final Batch Loss: 6.18705598753877e-07\n",
      "Epoch 3964, Loss: 3.317672508273972e-05, Final Batch Loss: 4.958005774824414e-06\n",
      "Epoch 3965, Loss: 0.001990803226362914, Final Batch Loss: 0.0003987871459685266\n",
      "Epoch 3966, Loss: 0.00034382721059955657, Final Batch Loss: 0.0003311983891762793\n",
      "Epoch 3967, Loss: 0.002029446797678247, Final Batch Loss: 1.830272958613932e-05\n",
      "Epoch 3968, Loss: 1.2433151709956292e-05, Final Batch Loss: 1.8333847719986807e-06\n",
      "Epoch 3969, Loss: 2.2710845769324806e-05, Final Batch Loss: 1.6221154510276392e-05\n",
      "Epoch 3970, Loss: 5.726207746192813e-05, Final Batch Loss: 5.535755917662755e-06\n",
      "Epoch 3971, Loss: 2.8723928835461265e-06, Final Batch Loss: 7.345478252318571e-07\n",
      "Epoch 3972, Loss: 0.00047051828005351126, Final Batch Loss: 0.0002871217729989439\n",
      "Epoch 3973, Loss: 3.286923060841218e-06, Final Batch Loss: 1.372545398226066e-06\n",
      "Epoch 3974, Loss: 1.0470119264027744e-05, Final Batch Loss: 8.571930266043637e-06\n",
      "Epoch 3975, Loss: 0.00376714368667308, Final Batch Loss: 3.827487489616033e-06\n",
      "Epoch 3976, Loss: 7.878257611082518e-05, Final Batch Loss: 6.6550987867231015e-06\n",
      "Epoch 3977, Loss: 0.02100882502782042, Final Batch Loss: 6.1561404436361045e-06\n",
      "Epoch 3978, Loss: 3.0171368052833714e-06, Final Batch Loss: 1.1366705621185247e-06\n",
      "Epoch 3979, Loss: 0.00015931105735944584, Final Batch Loss: 8.344479283550754e-05\n",
      "Epoch 3980, Loss: 5.818522004119586e-05, Final Batch Loss: 4.015637387055904e-05\n",
      "Epoch 3981, Loss: 0.00013649619859279483, Final Batch Loss: 6.503095846710494e-06\n",
      "Epoch 3982, Loss: 7.173607446020469e-05, Final Batch Loss: 3.772015043068677e-05\n",
      "Epoch 3983, Loss: 1.2916037121613044e-05, Final Batch Loss: 7.560185622423887e-06\n",
      "Epoch 3984, Loss: 0.005469738103784039, Final Batch Loss: 0.005446406546980143\n",
      "Epoch 3985, Loss: 7.425281546602491e-05, Final Batch Loss: 5.388979479903355e-05\n",
      "Epoch 3986, Loss: 0.00033609881211305037, Final Batch Loss: 0.0002309056872036308\n",
      "Epoch 3987, Loss: 2.3629414954484673e-05, Final Batch Loss: 1.894289380288683e-05\n",
      "Epoch 3988, Loss: 9.720497109810822e-05, Final Batch Loss: 5.9432659327285364e-05\n",
      "Epoch 3989, Loss: 2.73196612852189e-05, Final Batch Loss: 1.0166088486585068e-06\n",
      "Epoch 3990, Loss: 3.257113530708011e-05, Final Batch Loss: 6.2958461057860404e-06\n",
      "Epoch 3991, Loss: 0.0001323448082075629, Final Batch Loss: 4.642831754608778e-06\n",
      "Epoch 3992, Loss: 1.6447057305413182e-05, Final Batch Loss: 1.2952932593179867e-05\n",
      "Epoch 3993, Loss: 5.1388994961598655e-06, Final Batch Loss: 4.001670731668128e-06\n",
      "Epoch 3994, Loss: 0.0011268517046119086, Final Batch Loss: 0.001108932076022029\n",
      "Epoch 3995, Loss: 0.00017669964290689677, Final Batch Loss: 7.503143569920212e-05\n",
      "Epoch 3996, Loss: 3.00377269013552e-05, Final Batch Loss: 4.432176865520887e-06\n",
      "Epoch 3997, Loss: 0.00012688647620962001, Final Batch Loss: 3.9718146581435576e-05\n",
      "Epoch 3998, Loss: 0.0012823383385693887, Final Batch Loss: 0.0012663766974583268\n",
      "Epoch 3999, Loss: 1.3540618112983793e-05, Final Batch Loss: 5.607826665254834e-07\n",
      "Epoch 4000, Loss: 0.000666560728859622, Final Batch Loss: 6.385951564880088e-05\n",
      "Epoch 4001, Loss: 0.00023894559126347303, Final Batch Loss: 7.304508471861482e-05\n",
      "Epoch 4002, Loss: 1.8881111259361205e-05, Final Batch Loss: 1.1895457419086597e-06\n",
      "Epoch 4003, Loss: 0.00015006127085825938, Final Batch Loss: 5.028561531617015e-07\n",
      "Epoch 4004, Loss: 0.0006336250808089972, Final Batch Loss: 0.0004306525515858084\n",
      "Epoch 4005, Loss: 6.201431551744463e-05, Final Batch Loss: 5.1225048082415015e-05\n",
      "Epoch 4006, Loss: 0.0003875993668600586, Final Batch Loss: 0.00038728275103494525\n",
      "Epoch 4007, Loss: 0.00031389459036290646, Final Batch Loss: 0.0002301089552929625\n",
      "Epoch 4008, Loss: 6.035742444510106e-05, Final Batch Loss: 3.691882739076391e-05\n",
      "Epoch 4009, Loss: 3.4528241030784557e-06, Final Batch Loss: 3.1905653941066703e-06\n",
      "Epoch 4010, Loss: 4.110839540771849e-06, Final Batch Loss: 1.2339725117271882e-06\n",
      "Epoch 4011, Loss: 0.0042528100906338295, Final Batch Loss: 8.890068556866026e-07\n",
      "Epoch 4012, Loss: 0.00016732348501591332, Final Batch Loss: 1.2398571698213345e-06\n",
      "Epoch 4013, Loss: 2.725326896779734e-05, Final Batch Loss: 7.060153848215123e-07\n",
      "Epoch 4014, Loss: 8.617237256203225e-06, Final Batch Loss: 8.067932867561467e-06\n",
      "Epoch 4015, Loss: 8.177218478522263e-05, Final Batch Loss: 4.366886423667893e-05\n",
      "Epoch 4016, Loss: 0.0006706920539727435, Final Batch Loss: 0.0006141058984212577\n",
      "Epoch 4017, Loss: 0.0002293358338647522, Final Batch Loss: 0.0001503558160038665\n",
      "Epoch 4018, Loss: 0.0006832051813034923, Final Batch Loss: 2.4460978238494135e-06\n",
      "Epoch 4019, Loss: 2.4691281396371778e-05, Final Batch Loss: 8.479512871417683e-06\n",
      "Epoch 4020, Loss: 8.338158977494459e-05, Final Batch Loss: 6.306723207671894e-06\n",
      "Epoch 4021, Loss: 2.6162895132131325e-05, Final Batch Loss: 2.6074203560710885e-05\n",
      "Epoch 4022, Loss: 8.906553557608277e-05, Final Batch Loss: 4.316006015869789e-05\n",
      "Epoch 4023, Loss: 0.0022639213584625395, Final Batch Loss: 1.673241968092043e-05\n",
      "Epoch 4024, Loss: 8.47702062856115e-06, Final Batch Loss: 1.3641345049109077e-06\n",
      "Epoch 4025, Loss: 8.687841545906849e-05, Final Batch Loss: 5.605634578387253e-05\n",
      "Epoch 4026, Loss: 2.075236091059196e-05, Final Batch Loss: 5.423081574917887e-07\n",
      "Epoch 4027, Loss: 3.7699298445659224e-05, Final Batch Loss: 1.1495533726701979e-05\n",
      "Epoch 4028, Loss: 3.1138036774791544e-05, Final Batch Loss: 6.482333901658421e-06\n",
      "Epoch 4029, Loss: 4.817134220047592e-05, Final Batch Loss: 4.7655412345193326e-05\n",
      "Epoch 4030, Loss: 0.00010387546717538498, Final Batch Loss: 6.69937435304746e-05\n",
      "Epoch 4031, Loss: 7.236839542201778e-05, Final Batch Loss: 1.8367175016464898e-06\n",
      "Epoch 4032, Loss: 3.1318584660766646e-05, Final Batch Loss: 1.5801873814780265e-05\n",
      "Epoch 4033, Loss: 6.318840064523101e-06, Final Batch Loss: 1.5755946378703811e-06\n",
      "Epoch 4034, Loss: 9.60600812049961e-06, Final Batch Loss: 1.6402306073359796e-06\n",
      "Epoch 4035, Loss: 0.0001010986848086759, Final Batch Loss: 9.549425885779783e-05\n",
      "Epoch 4036, Loss: 9.326410736321122e-05, Final Batch Loss: 7.341559921769658e-06\n",
      "Epoch 4037, Loss: 2.501351127648377e-05, Final Batch Loss: 2.204021620855201e-05\n",
      "Epoch 4038, Loss: 0.0003188199084434018, Final Batch Loss: 3.045123321498977e-06\n",
      "Epoch 4039, Loss: 5.818094678033958e-06, Final Batch Loss: 4.287596766516799e-06\n",
      "Epoch 4040, Loss: 0.0001167424705954545, Final Batch Loss: 1.1920917586394353e-07\n",
      "Epoch 4041, Loss: 1.2511755357991206e-05, Final Batch Loss: 3.945219305023784e-06\n",
      "Epoch 4042, Loss: 0.00022577271147383726, Final Batch Loss: 5.838324341311818e-06\n",
      "Epoch 4043, Loss: 4.792060508407303e-06, Final Batch Loss: 2.5911315333360108e-06\n",
      "Epoch 4044, Loss: 1.3806803167426551e-06, Final Batch Loss: 4.432519062902429e-07\n",
      "Epoch 4045, Loss: 9.898040815414788e-06, Final Batch Loss: 9.491305718256626e-06\n",
      "Epoch 4046, Loss: 0.0005858847289346159, Final Batch Loss: 0.00012261330266483128\n",
      "Epoch 4047, Loss: 1.7216561957411614e-05, Final Batch Loss: 2.023189722422103e-07\n",
      "Epoch 4048, Loss: 3.0940921185163006e-05, Final Batch Loss: 7.47155510794073e-08\n",
      "Epoch 4049, Loss: 0.00020205859436828177, Final Batch Loss: 2.5747371182660572e-05\n",
      "Epoch 4050, Loss: 0.00029343565984163433, Final Batch Loss: 0.00013630581088364124\n",
      "Epoch 4051, Loss: 1.5003734461060958e-05, Final Batch Loss: 9.075593879970256e-06\n",
      "Epoch 4052, Loss: 3.654958436527522e-05, Final Batch Loss: 2.2794143660576083e-05\n",
      "Epoch 4053, Loss: 0.00011263031410635449, Final Batch Loss: 3.837903932435438e-06\n",
      "Epoch 4054, Loss: 7.2518453180236975e-06, Final Batch Loss: 3.819598532572854e-06\n",
      "Epoch 4055, Loss: 1.1720264637915534e-05, Final Batch Loss: 1.0412910341983661e-05\n",
      "Epoch 4056, Loss: 0.00035710680659661875, Final Batch Loss: 6.799947271929341e-08\n",
      "Epoch 4057, Loss: 7.507474265366909e-06, Final Batch Loss: 2.9991695100761717e-06\n",
      "Epoch 4058, Loss: 3.938152079996371e-06, Final Batch Loss: 1.0074021616901518e-08\n",
      "Epoch 4059, Loss: 0.0008930986441555433, Final Batch Loss: 0.0007860000478103757\n",
      "Epoch 4060, Loss: 2.1554447357630124e-05, Final Batch Loss: 4.7542630454699975e-06\n",
      "Epoch 4061, Loss: 1.4427984979192843e-05, Final Batch Loss: 1.110931953007821e-05\n",
      "Epoch 4062, Loss: 1.0009649940911913e-05, Final Batch Loss: 6.875660801597405e-06\n",
      "Epoch 4063, Loss: 6.7657756517292e-05, Final Batch Loss: 1.2113468983443454e-06\n",
      "Epoch 4064, Loss: 5.104469892103225e-06, Final Batch Loss: 4.2018732528958935e-06\n",
      "Epoch 4065, Loss: 0.00014313821429823292, Final Batch Loss: 7.563229701190721e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4066, Loss: 3.753063516853672e-06, Final Batch Loss: 9.906100473244805e-08\n",
      "Epoch 4067, Loss: 9.59970543590316e-06, Final Batch Loss: 5.87202885071747e-06\n",
      "Epoch 4068, Loss: 1.3254722489364212e-05, Final Batch Loss: 7.414093488478102e-06\n",
      "Epoch 4069, Loss: 2.96384409921302e-05, Final Batch Loss: 2.6077706934302114e-05\n",
      "Epoch 4070, Loss: 2.5790754762056167e-05, Final Batch Loss: 2.044857637883979e-06\n",
      "Epoch 4071, Loss: 1.7971386682802404e-05, Final Batch Loss: 1.676034662523307e-05\n",
      "Epoch 4072, Loss: 1.0061949524242664e-05, Final Batch Loss: 4.333196557126939e-06\n",
      "Epoch 4073, Loss: 2.805100848490838e-05, Final Batch Loss: 2.6080830139108002e-05\n",
      "Epoch 4074, Loss: 5.059378736405051e-06, Final Batch Loss: 1.4966847174946452e-06\n",
      "Epoch 4075, Loss: 4.0857261410565116e-05, Final Batch Loss: 1.857957431639079e-05\n",
      "Epoch 4076, Loss: 9.66617608355591e-06, Final Batch Loss: 3.4943095670314506e-06\n",
      "Epoch 4077, Loss: 0.003783525168273627, Final Batch Loss: 2.977173153340118e-06\n",
      "Epoch 4078, Loss: 2.745985619867497e-05, Final Batch Loss: 1.6789925894045155e-07\n",
      "Epoch 4079, Loss: 2.6012066030034475e-06, Final Batch Loss: 1.41875176495887e-07\n",
      "Epoch 4080, Loss: 3.886593746926792e-05, Final Batch Loss: 2.0399799893766613e-07\n",
      "Epoch 4081, Loss: 0.0001924484317896713, Final Batch Loss: 0.00019023058121092618\n",
      "Epoch 4082, Loss: 2.6042407171189552e-05, Final Batch Loss: 4.241231636115117e-06\n",
      "Epoch 4083, Loss: 2.4546754048060393e-05, Final Batch Loss: 1.9479684851830825e-05\n",
      "Epoch 4084, Loss: 1.9697909237947897e-05, Final Batch Loss: 3.56740770257602e-06\n",
      "Epoch 4085, Loss: 0.0072737286689061875, Final Batch Loss: 0.007270505651831627\n",
      "Epoch 4086, Loss: 1.2062105383847666e-05, Final Batch Loss: 1.5706356180089642e-06\n",
      "Epoch 4087, Loss: 0.0001170411105704261, Final Batch Loss: 0.00010115214536199346\n",
      "Epoch 4088, Loss: 0.0006600320375582669, Final Batch Loss: 0.0006216958281584084\n",
      "Epoch 4089, Loss: 9.971491363103269e-05, Final Batch Loss: 9.726707503432408e-05\n",
      "Epoch 4090, Loss: 9.501764907327015e-06, Final Batch Loss: 4.293854544812348e-06\n",
      "Epoch 4091, Loss: 2.002701990022615e-06, Final Batch Loss: 1.3179796951590106e-06\n",
      "Epoch 4092, Loss: 2.3006699620964355e-05, Final Batch Loss: 3.4626334581844276e-06\n",
      "Epoch 4093, Loss: 0.0008258993267133974, Final Batch Loss: 2.014795370541833e-07\n",
      "Epoch 4094, Loss: 1.393145304717791e-05, Final Batch Loss: 7.47155510794073e-08\n",
      "Epoch 4095, Loss: 3.2932486249137582e-06, Final Batch Loss: 2.787132018511329e-07\n",
      "Epoch 4096, Loss: 0.00011996093053312507, Final Batch Loss: 2.9258821086841635e-05\n",
      "Epoch 4097, Loss: 0.00018883214943343773, Final Batch Loss: 0.0001701989385765046\n",
      "Epoch 4098, Loss: 1.6229792549893318e-05, Final Batch Loss: 1.0921518196482793e-06\n",
      "Epoch 4099, Loss: 5.3835200787943904e-05, Final Batch Loss: 3.024442094101687e-06\n",
      "Epoch 4100, Loss: 8.752865596761694e-05, Final Batch Loss: 7.848708628444001e-05\n",
      "Epoch 4101, Loss: 6.589323947991943e-05, Final Batch Loss: 5.199056613491848e-05\n",
      "Epoch 4102, Loss: 0.00018593303775560344, Final Batch Loss: 8.332747711392585e-06\n",
      "Epoch 4103, Loss: 0.0002708727690219348, Final Batch Loss: 7.504851851081185e-07\n",
      "Epoch 4104, Loss: 6.578582542715594e-06, Final Batch Loss: 1.9491781131364405e-06\n",
      "Epoch 4105, Loss: 3.771890806092415e-05, Final Batch Loss: 2.291843520652037e-05\n",
      "Epoch 4106, Loss: 0.00019036388709992025, Final Batch Loss: 0.0001886178506538272\n",
      "Epoch 4107, Loss: 2.6328082583404466e-05, Final Batch Loss: 2.572298762970604e-05\n",
      "Epoch 4108, Loss: 3.81137574549939e-05, Final Batch Loss: 3.1386247428599745e-05\n",
      "Epoch 4109, Loss: 8.357156002603006e-05, Final Batch Loss: 6.951736577320844e-05\n",
      "Epoch 4110, Loss: 4.049713766107743e-06, Final Batch Loss: 1.3296493079906213e-06\n",
      "Epoch 4111, Loss: 0.00011520422117428097, Final Batch Loss: 3.712656280185911e-06\n",
      "Epoch 4112, Loss: 3.398224771444802e-05, Final Batch Loss: 2.640409547893796e-05\n",
      "Epoch 4113, Loss: 3.712365646890703e-05, Final Batch Loss: 1.880470819060065e-07\n",
      "Epoch 4114, Loss: 5.917209455219563e-05, Final Batch Loss: 4.5761975343339145e-05\n",
      "Epoch 4115, Loss: 0.00010374538896940066, Final Batch Loss: 0.0001036094909068197\n",
      "Epoch 4116, Loss: 8.645930620332365e-05, Final Batch Loss: 8.366367546841502e-05\n",
      "Epoch 4117, Loss: 0.0003944003492506454, Final Batch Loss: 1.549854096083436e-05\n",
      "Epoch 4118, Loss: 2.7820441118819872e-05, Final Batch Loss: 5.86603209740133e-06\n",
      "Epoch 4119, Loss: 9.828490078689356e-06, Final Batch Loss: 5.859639031768893e-07\n",
      "Epoch 4120, Loss: 2.4822082764330844e-05, Final Batch Loss: 2.4523107640561648e-05\n",
      "Epoch 4121, Loss: 4.253237234763674e-05, Final Batch Loss: 1.6622102805285977e-07\n",
      "Epoch 4122, Loss: 7.719935751993035e-06, Final Batch Loss: 8.40298639559478e-07\n",
      "Epoch 4123, Loss: 6.3103624370342e-05, Final Batch Loss: 1.0828887297975598e-06\n",
      "Epoch 4124, Loss: 1.4065590221434832e-05, Final Batch Loss: 9.621149729355238e-06\n",
      "Epoch 4125, Loss: 0.00013749827513720447, Final Batch Loss: 4.877441028838803e-07\n",
      "Epoch 4126, Loss: 9.013881538066926e-06, Final Batch Loss: 8.377888320865168e-07\n",
      "Epoch 4127, Loss: 4.99025009048637e-05, Final Batch Loss: 3.1016130378702655e-05\n",
      "Epoch 4128, Loss: 0.0002510535341571085, Final Batch Loss: 0.00022001728939358145\n",
      "Epoch 4129, Loss: 4.693578193837311e-05, Final Batch Loss: 2.0339339243946597e-06\n",
      "Epoch 4130, Loss: 2.5654315322753973e-05, Final Batch Loss: 1.6942254660534672e-05\n",
      "Epoch 4131, Loss: 3.818561935986509e-06, Final Batch Loss: 1.7712045519147068e-06\n",
      "Epoch 4132, Loss: 0.0027314888720866293, Final Batch Loss: 0.00041155130020342767\n",
      "Epoch 4133, Loss: 7.323005434045626e-06, Final Batch Loss: 1.1374437463018694e-06\n",
      "Epoch 4134, Loss: 5.6838550790416775e-06, Final Batch Loss: 4.80187509310781e-07\n",
      "Epoch 4135, Loss: 1.0965075944113778e-05, Final Batch Loss: 4.67137033410836e-06\n",
      "Epoch 4136, Loss: 2.416524353066052e-06, Final Batch Loss: 1.1324386832711753e-06\n",
      "Epoch 4137, Loss: 0.0001646830132813193, Final Batch Loss: 2.2290747438091785e-05\n",
      "Epoch 4138, Loss: 0.00016047754206738318, Final Batch Loss: 7.601756351505173e-06\n",
      "Epoch 4139, Loss: 6.415066309273243e-06, Final Batch Loss: 6.363352440530434e-07\n",
      "Epoch 4140, Loss: 1.0965951787511585e-05, Final Batch Loss: 3.1315807973442134e-06\n",
      "Epoch 4141, Loss: 7.161894563978422e-05, Final Batch Loss: 6.602308712899685e-05\n",
      "Epoch 4142, Loss: 1.3990338771918687e-06, Final Batch Loss: 2.275015873465236e-07\n",
      "Epoch 4143, Loss: 2.8828495146626665e-06, Final Batch Loss: 1.970205403267755e-06\n",
      "Epoch 4144, Loss: 0.010198451142059639, Final Batch Loss: 0.00987041462212801\n",
      "Epoch 4145, Loss: 8.178328698704718e-06, Final Batch Loss: 4.747811999550322e-06\n",
      "Epoch 4146, Loss: 1.8096534830647215e-06, Final Batch Loss: 1.276038545938718e-07\n",
      "Epoch 4147, Loss: 5.2496741211882636e-05, Final Batch Loss: 6.883909264843169e-08\n",
      "Epoch 4148, Loss: 3.298031151643954e-05, Final Batch Loss: 2.851925091817975e-05\n",
      "Epoch 4149, Loss: 1.8310123834908154e-06, Final Batch Loss: 1.4791115745538264e-06\n",
      "Epoch 4150, Loss: 1.6931000573094934e-05, Final Batch Loss: 6.982273589528631e-06\n",
      "Epoch 4151, Loss: 0.0069443225002032705, Final Batch Loss: 0.006899012252688408\n",
      "Epoch 4152, Loss: 4.143110828636054e-06, Final Batch Loss: 3.987609318301111e-07\n",
      "Epoch 4153, Loss: 9.577673676375298e-06, Final Batch Loss: 9.528559530735947e-06\n",
      "Epoch 4154, Loss: 1.1117883104816428e-05, Final Batch Loss: 3.802387482210179e-06\n",
      "Epoch 4155, Loss: 2.388665689068148e-05, Final Batch Loss: 2.2532503862748854e-05\n",
      "Epoch 4156, Loss: 6.181290601148248e-06, Final Batch Loss: 2.0231745168075577e-07\n",
      "Epoch 4157, Loss: 3.2777133185390994e-07, Final Batch Loss: 5.1209482876402035e-08\n",
      "Epoch 4158, Loss: 2.6722845177573618e-05, Final Batch Loss: 2.0389268684084527e-05\n",
      "Epoch 4159, Loss: 8.716528782315436e-06, Final Batch Loss: 7.004781309660757e-06\n",
      "Epoch 4160, Loss: 4.098520730622113e-05, Final Batch Loss: 3.321903204778209e-05\n",
      "Epoch 4161, Loss: 0.0001462306852886286, Final Batch Loss: 0.00014607905177399516\n",
      "Epoch 4162, Loss: 4.523963525571162e-06, Final Batch Loss: 1.1072500001318986e-06\n",
      "Epoch 4163, Loss: 6.5283963976980885e-06, Final Batch Loss: 6.505999863293255e-07\n",
      "Epoch 4164, Loss: 5.8089273977657285e-05, Final Batch Loss: 5.731444980483502e-05\n",
      "Epoch 4165, Loss: 9.714607742239423e-06, Final Batch Loss: 8.646854610105947e-08\n",
      "Epoch 4166, Loss: 6.633494677998897e-07, Final Batch Loss: 6.094669515732676e-07\n",
      "Epoch 4167, Loss: 0.00013508575284504332, Final Batch Loss: 0.00011226551578147337\n",
      "Epoch 4168, Loss: 6.217181089596124e-05, Final Batch Loss: 5.208968104852829e-06\n",
      "Epoch 4169, Loss: 4.060394985572202e-06, Final Batch Loss: 2.1851365090697072e-06\n",
      "Epoch 4170, Loss: 1.2921686902700458e-05, Final Batch Loss: 6.5700860432116315e-06\n",
      "Epoch 4171, Loss: 0.00010104226657858817, Final Batch Loss: 9.853765368461609e-05\n",
      "Epoch 4172, Loss: 1.774371776264161e-05, Final Batch Loss: 1.390072429785505e-05\n",
      "Epoch 4173, Loss: 0.0014825508405920118, Final Batch Loss: 1.1026946594938636e-05\n",
      "Epoch 4174, Loss: 8.066557757047121e-05, Final Batch Loss: 8.030032768147066e-05\n",
      "Epoch 4175, Loss: 1.779359217835008e-05, Final Batch Loss: 5.130349109094823e-06\n",
      "Epoch 4176, Loss: 0.004957061463073842, Final Batch Loss: 2.749000714175054e-06\n",
      "Epoch 4177, Loss: 1.0812971886764444e-06, Final Batch Loss: 3.19010560190236e-08\n",
      "Epoch 4178, Loss: 0.000155662746692542, Final Batch Loss: 4.3775893573183566e-05\n",
      "Epoch 4179, Loss: 5.94106921880666e-07, Final Batch Loss: 2.1407134909168235e-07\n",
      "Epoch 4180, Loss: 3.4446692893652653e-06, Final Batch Loss: 3.0484309263556497e-06\n",
      "Epoch 4181, Loss: 3.6499086490948685e-06, Final Batch Loss: 1.2583604984683916e-06\n",
      "Epoch 4182, Loss: 4.33472418421843e-05, Final Batch Loss: 4.1554852714398294e-07\n",
      "Epoch 4183, Loss: 3.3731827898009215e-05, Final Batch Loss: 1.2846675417677034e-05\n",
      "Epoch 4184, Loss: 3.779190137720434e-06, Final Batch Loss: 1.471559926358168e-06\n",
      "Epoch 4185, Loss: 1.8125383348888136e-05, Final Batch Loss: 1.7884105545817874e-05\n",
      "Epoch 4186, Loss: 4.881917946164549e-05, Final Batch Loss: 1.1920881348714829e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4187, Loss: 7.631533264884638e-06, Final Batch Loss: 7.089854534569895e-06\n",
      "Epoch 4188, Loss: 1.7725037992022408e-05, Final Batch Loss: 1.4950049944673083e-06\n",
      "Epoch 4189, Loss: 7.231723066070117e-05, Final Batch Loss: 1.4736797311343253e-05\n",
      "Epoch 4190, Loss: 3.706271786541038e-05, Final Batch Loss: 3.6055698728887364e-05\n",
      "Epoch 4191, Loss: 9.097535803448409e-05, Final Batch Loss: 8.277447341242805e-05\n",
      "Epoch 4192, Loss: 2.657564289165748e-05, Final Batch Loss: 2.5483239369350486e-05\n",
      "Epoch 4193, Loss: 0.0001695590426606941, Final Batch Loss: 1.2804225661966484e-05\n",
      "Epoch 4194, Loss: 4.1730198745426605e-05, Final Batch Loss: 2.7306621177558554e-06\n",
      "Epoch 4195, Loss: 1.981896815550499e-06, Final Batch Loss: 4.6088163685453765e-07\n",
      "Epoch 4196, Loss: 0.000103653091173328, Final Batch Loss: 9.065536869456992e-05\n",
      "Epoch 4197, Loss: 2.086944266466162e-05, Final Batch Loss: 1.7291885114900651e-06\n",
      "Epoch 4198, Loss: 1.8073488377012836e-06, Final Batch Loss: 2.4009585786188836e-07\n",
      "Epoch 4199, Loss: 5.665943319854705e-06, Final Batch Loss: 5.128085831529461e-06\n",
      "Epoch 4200, Loss: 7.277207259903662e-05, Final Batch Loss: 2.14400643017143e-05\n",
      "Epoch 4201, Loss: 4.841120357923501e-06, Final Batch Loss: 3.244826302761794e-06\n",
      "Epoch 4202, Loss: 6.674938504147576e-06, Final Batch Loss: 4.36074969911715e-06\n",
      "Epoch 4203, Loss: 1.4445951137531665e-05, Final Batch Loss: 1.1333236216160003e-07\n",
      "Epoch 4204, Loss: 2.460043064989037e-05, Final Batch Loss: 1.0913525194666818e-08\n",
      "Epoch 4205, Loss: 8.376140976906754e-05, Final Batch Loss: 7.450315752066672e-05\n",
      "Epoch 4206, Loss: 0.00013410775136435404, Final Batch Loss: 3.813332295976579e-05\n",
      "Epoch 4207, Loss: 0.0007161371412394146, Final Batch Loss: 0.0007160541717894375\n",
      "Epoch 4208, Loss: 1.223411459250201e-06, Final Batch Loss: 7.966488624333579e-07\n",
      "Epoch 4209, Loss: 5.416581825556932e-05, Final Batch Loss: 4.254884333931841e-05\n",
      "Epoch 4210, Loss: 0.00021053534840120847, Final Batch Loss: 1.0618965688991011e-06\n",
      "Epoch 4211, Loss: 6.8866232908249e-05, Final Batch Loss: 6.852911610621959e-05\n",
      "Epoch 4212, Loss: 0.006557624243896498, Final Batch Loss: 0.006555440369993448\n",
      "Epoch 4213, Loss: 1.5658071788493544e-05, Final Batch Loss: 4.032545803056564e-06\n",
      "Epoch 4214, Loss: 1.984212765648863e-06, Final Batch Loss: 9.234475584207757e-08\n",
      "Epoch 4215, Loss: 0.0002422229708827217, Final Batch Loss: 0.00023724597122054547\n",
      "Epoch 4216, Loss: 1.5864818010413728e-06, Final Batch Loss: 3.106138706243655e-07\n",
      "Epoch 4217, Loss: 0.0004337401969678467, Final Batch Loss: 3.2123843993758783e-06\n",
      "Epoch 4218, Loss: 3.03513309063419e-06, Final Batch Loss: 2.469617129463586e-06\n",
      "Epoch 4219, Loss: 2.8031862484567682e-06, Final Batch Loss: 1.2188611435703933e-06\n",
      "Epoch 4220, Loss: 0.002211982606240781, Final Batch Loss: 0.002203855197876692\n",
      "Epoch 4221, Loss: 1.1905352572227912e-05, Final Batch Loss: 5.4567486529322196e-08\n",
      "Epoch 4222, Loss: 7.60341425518618e-05, Final Batch Loss: 2.9885981689403707e-07\n",
      "Epoch 4223, Loss: 0.00018395793449599296, Final Batch Loss: 2.417224459350109e-05\n",
      "Epoch 4224, Loss: 2.000915947064641e-05, Final Batch Loss: 9.62854301178595e-07\n",
      "Epoch 4225, Loss: 5.3548206324194325e-05, Final Batch Loss: 5.075128501630388e-05\n",
      "Epoch 4226, Loss: 3.2496188282493677e-06, Final Batch Loss: 2.912026047852123e-06\n",
      "Epoch 4227, Loss: 2.766463865100377e-06, Final Batch Loss: 6.111383186180319e-07\n",
      "Epoch 4228, Loss: 0.00022862335026729852, Final Batch Loss: 0.00019061272905673832\n",
      "Epoch 4229, Loss: 2.6435725999363058e-06, Final Batch Loss: 6.942419190636429e-07\n",
      "Epoch 4230, Loss: 8.672103604112635e-06, Final Batch Loss: 1.3221708741184557e-06\n",
      "Epoch 4231, Loss: 3.5588413282994225e-06, Final Batch Loss: 3.3414057725167368e-06\n",
      "Epoch 4232, Loss: 5.130277330067656e-06, Final Batch Loss: 1.1501158780902188e-07\n",
      "Epoch 4233, Loss: 0.00011937654517168994, Final Batch Loss: 2.1605551410175394e-06\n",
      "Epoch 4234, Loss: 1.7091383824663353e-05, Final Batch Loss: 1.372764654661296e-05\n",
      "Epoch 4235, Loss: 1.5352898117271252e-05, Final Batch Loss: 1.1343524420226458e-05\n",
      "Epoch 4236, Loss: 1.1052713460912855e-05, Final Batch Loss: 4.214225270970928e-07\n",
      "Epoch 4237, Loss: 7.282291699084453e-05, Final Batch Loss: 4.300790897104889e-05\n",
      "Epoch 4238, Loss: 2.0920436782034812e-05, Final Batch Loss: 6.531053713842994e-06\n",
      "Epoch 4239, Loss: 5.402011953492547e-05, Final Batch Loss: 5.88480872920627e-07\n",
      "Epoch 4240, Loss: 3.4314847852101593e-06, Final Batch Loss: 2.2750275263661024e-07\n",
      "Epoch 4241, Loss: 7.527421047370808e-06, Final Batch Loss: 2.8962264764231804e-07\n",
      "Epoch 4242, Loss: 3.163971260988774e-06, Final Batch Loss: 3.4419546324215844e-08\n",
      "Epoch 4243, Loss: 5.016963950765785e-05, Final Batch Loss: 2.5867811928037554e-05\n",
      "Epoch 4244, Loss: 4.101645707521584e-07, Final Batch Loss: 3.441956764049792e-08\n",
      "Epoch 4245, Loss: 2.2433285039369366e-05, Final Batch Loss: 6.774623670935398e-07\n",
      "Epoch 4246, Loss: 6.630692553244444e-06, Final Batch Loss: 5.732424142479431e-06\n",
      "Epoch 4247, Loss: 1.0137207453908559e-05, Final Batch Loss: 2.6024324029094714e-07\n",
      "Epoch 4248, Loss: 0.0002640284084236555, Final Batch Loss: 6.422061460398254e-07\n",
      "Epoch 4249, Loss: 7.910761695484325e-06, Final Batch Loss: 3.928807643660548e-07\n",
      "Epoch 4250, Loss: 4.224391005891448e-06, Final Batch Loss: 4.6003358988855325e-07\n",
      "Epoch 4251, Loss: 1.1612594960297429e-05, Final Batch Loss: 3.1984581028154935e-07\n",
      "Epoch 4252, Loss: 1.9855530126733356e-06, Final Batch Loss: 3.9120538986026077e-07\n",
      "Epoch 4253, Loss: 5.986584369566117e-06, Final Batch Loss: 1.0728614370236755e-06\n",
      "Epoch 4254, Loss: 5.3552038025372894e-05, Final Batch Loss: 4.756545240525156e-05\n",
      "Epoch 4255, Loss: 0.0001917210311148665, Final Batch Loss: 7.81274775363272e-06\n",
      "Epoch 4256, Loss: 7.381262889794016e-07, Final Batch Loss: 2.980171984745539e-07\n",
      "Epoch 4257, Loss: 5.507432979356963e-05, Final Batch Loss: 1.0005633157561533e-05\n",
      "Epoch 4258, Loss: 7.104088354026317e-06, Final Batch Loss: 2.8171364192530746e-06\n",
      "Epoch 4259, Loss: 2.4807171030261088e-05, Final Batch Loss: 1.577115835971199e-05\n",
      "Epoch 4260, Loss: 5.927231313762604e-06, Final Batch Loss: 3.4782683542289305e-06\n",
      "Epoch 4261, Loss: 0.006565571143710258, Final Batch Loss: 0.006563480012118816\n",
      "Epoch 4262, Loss: 5.210428440705073e-06, Final Batch Loss: 5.0125418056268245e-06\n",
      "Epoch 4263, Loss: 2.0270808818168007e-06, Final Batch Loss: 1.3833669072482735e-06\n",
      "Epoch 4264, Loss: 4.722696735370846e-05, Final Batch Loss: 2.7021631012758007e-06\n",
      "Epoch 4265, Loss: 1.2826732017856557e-05, Final Batch Loss: 6.27937879471574e-07\n",
      "Epoch 4266, Loss: 7.774947852112746e-05, Final Batch Loss: 5.683247650267731e-07\n",
      "Epoch 4267, Loss: 0.00015420497584273107, Final Batch Loss: 0.00013842216867487878\n",
      "Epoch 4268, Loss: 3.8032547706734476e-05, Final Batch Loss: 7.71481097672222e-07\n",
      "Epoch 4269, Loss: 0.0004485081972234184, Final Batch Loss: 0.00042440270772203803\n",
      "Epoch 4270, Loss: 7.153532533266116e-05, Final Batch Loss: 1.3676019079866819e-05\n",
      "Epoch 4271, Loss: 1.1682111107802484e-05, Final Batch Loss: 7.742733032500837e-06\n",
      "Epoch 4272, Loss: 8.522152454304432e-05, Final Batch Loss: 1.2844354557728366e-07\n",
      "Epoch 4273, Loss: 0.0002918739992310293, Final Batch Loss: 6.3921979744918644e-06\n",
      "Epoch 4274, Loss: 9.372907584292989e-06, Final Batch Loss: 8.327737305080518e-06\n",
      "Epoch 4275, Loss: 5.85227923011189e-07, Final Batch Loss: 3.038976785774139e-07\n",
      "Epoch 4276, Loss: 3.1718447900175306e-05, Final Batch Loss: 4.7012036930027534e-08\n",
      "Epoch 4277, Loss: 2.8966222203052894e-06, Final Batch Loss: 2.0893619421258336e-06\n",
      "Epoch 4278, Loss: 6.412904610897385e-06, Final Batch Loss: 7.093696581250697e-07\n",
      "Epoch 4279, Loss: 1.136681771640724e-05, Final Batch Loss: 1.0831819054146763e-05\n",
      "Epoch 4280, Loss: 2.4817086796247168e-05, Final Batch Loss: 1.3339008546608966e-06\n",
      "Epoch 4281, Loss: 0.00016110992555695702, Final Batch Loss: 0.0001576817303430289\n",
      "Epoch 4282, Loss: 0.001098444858826042, Final Batch Loss: 2.305895350218634e-06\n",
      "Epoch 4283, Loss: 3.985663147432206e-05, Final Batch Loss: 3.2404363992100116e-07\n",
      "Epoch 4284, Loss: 2.421496537863277e-05, Final Batch Loss: 2.2276508389040828e-05\n",
      "Epoch 4285, Loss: 4.1993975173681974e-05, Final Batch Loss: 1.717176564852707e-05\n",
      "Epoch 4286, Loss: 0.000299692661883455, Final Batch Loss: 5.438733296614373e-06\n",
      "Epoch 4287, Loss: 2.3382320364362386e-05, Final Batch Loss: 1.7377635685988935e-07\n",
      "Epoch 4288, Loss: 1.5716482494099182e-05, Final Batch Loss: 1.2383071407384705e-05\n",
      "Epoch 4289, Loss: 2.738966372817231e-06, Final Batch Loss: 6.413737310140277e-07\n",
      "Epoch 4290, Loss: 0.00981545532954442, Final Batch Loss: 7.924707006168319e-07\n",
      "Epoch 4291, Loss: 0.0001852834609223919, Final Batch Loss: 3.828097021596477e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4292, Loss: 3.0496744798824693e-05, Final Batch Loss: 7.387599509911524e-08\n",
      "Epoch 4293, Loss: 2.9379860279732384e-05, Final Batch Loss: 1.7352498616673984e-05\n",
      "Epoch 4294, Loss: 4.6338278480106965e-05, Final Batch Loss: 4.623536369763315e-06\n",
      "Epoch 4295, Loss: 6.463644649556954e-05, Final Batch Loss: 6.048327486496419e-05\n",
      "Epoch 4296, Loss: 3.3745438486221246e-05, Final Batch Loss: 1.537996831757482e-05\n",
      "Epoch 4297, Loss: 1.4724638191410122e-05, Final Batch Loss: 4.4744311367139744e-07\n",
      "Epoch 4298, Loss: 0.00011859529786306666, Final Batch Loss: 6.847815711807925e-06\n",
      "Epoch 4299, Loss: 2.7858960152116197e-05, Final Batch Loss: 3.282408442828455e-07\n",
      "Epoch 4300, Loss: 2.802052722472581e-05, Final Batch Loss: 2.3758104362059385e-05\n",
      "Epoch 4301, Loss: 7.98742377128292e-07, Final Batch Loss: 2.0987383209103427e-07\n",
      "Epoch 4302, Loss: 3.208375164831523e-05, Final Batch Loss: 2.6599505872582085e-05\n",
      "Epoch 4303, Loss: 9.645806585467653e-06, Final Batch Loss: 5.055685505794827e-06\n",
      "Epoch 4304, Loss: 1.2471067975639016e-05, Final Batch Loss: 9.460129149374552e-06\n",
      "Epoch 4305, Loss: 3.0503460095587798e-06, Final Batch Loss: 3.794476981511252e-07\n",
      "Epoch 4306, Loss: 2.5469373099440418e-06, Final Batch Loss: 1.754507820805884e-06\n",
      "Epoch 4307, Loss: 0.0003147811694361735, Final Batch Loss: 0.0002775020548142493\n",
      "Epoch 4308, Loss: 0.00011246470330661396, Final Batch Loss: 0.00010877916065510362\n",
      "Epoch 4309, Loss: 9.322989353677258e-05, Final Batch Loss: 2.8112190193496644e-06\n",
      "Epoch 4310, Loss: 2.1802696892336826e-06, Final Batch Loss: 3.0557646368833957e-07\n",
      "Epoch 4311, Loss: 8.742610447143306e-05, Final Batch Loss: 2.904657208091521e-07\n",
      "Epoch 4312, Loss: 2.2446852227631098e-05, Final Batch Loss: 1.544676990761218e-07\n",
      "Epoch 4313, Loss: 1.2486294053815072e-05, Final Batch Loss: 4.542797341855476e-06\n",
      "Epoch 4314, Loss: 3.4377454767309246e-06, Final Batch Loss: 2.2538265511684585e-06\n",
      "Epoch 4315, Loss: 0.0004178459632839804, Final Batch Loss: 1.6100814264063956e-06\n",
      "Epoch 4316, Loss: 7.463975919108634e-06, Final Batch Loss: 4.533279138740909e-07\n",
      "Epoch 4317, Loss: 1.5097447459311297e-05, Final Batch Loss: 2.3673786131439556e-07\n",
      "Epoch 4318, Loss: 2.2440124780587212e-07, Final Batch Loss: 6.799956508984906e-08\n",
      "Epoch 4319, Loss: 2.5064227713755827e-05, Final Batch Loss: 2.4852513888617977e-05\n",
      "Epoch 4320, Loss: 7.275967561781727e-07, Final Batch Loss: 3.895232509876223e-07\n",
      "Epoch 4321, Loss: 2.5746778192115016e-05, Final Batch Loss: 2.1285595721565187e-05\n",
      "Epoch 4322, Loss: 5.8634004574287246e-05, Final Batch Loss: 5.8367455494590104e-05\n",
      "Epoch 4323, Loss: 1.8900166196544887e-06, Final Batch Loss: 1.5285839936041157e-06\n",
      "Epoch 4324, Loss: 3.6572438872894963e-06, Final Batch Loss: 5.037002637209298e-08\n",
      "Epoch 4325, Loss: 1.2805767026335957e-05, Final Batch Loss: 1.511102531992492e-08\n",
      "Epoch 4326, Loss: 9.609185417502886e-05, Final Batch Loss: 1.394975606672233e-05\n",
      "Epoch 4327, Loss: 2.0916530729664373e-06, Final Batch Loss: 4.037927965327981e-07\n",
      "Epoch 4328, Loss: 4.909076686487879e-06, Final Batch Loss: 1.0997418797842329e-07\n",
      "Epoch 4329, Loss: 5.551162416850275e-06, Final Batch Loss: 4.366777830000501e-06\n",
      "Epoch 4330, Loss: 1.4299816939455923e-05, Final Batch Loss: 8.042152330745012e-06\n",
      "Epoch 4331, Loss: 0.00018489962894818746, Final Batch Loss: 0.0001459318882552907\n",
      "Epoch 4332, Loss: 7.297563115571393e-06, Final Batch Loss: 2.0415932340256404e-06\n",
      "Epoch 4333, Loss: 0.0003459907602518797, Final Batch Loss: 3.782546264119446e-05\n",
      "Epoch 4334, Loss: 0.00010450648755977454, Final Batch Loss: 2.018811073867255e-06\n",
      "Epoch 4335, Loss: 3.5194619584899556e-05, Final Batch Loss: 2.946630672795436e-07\n",
      "Epoch 4336, Loss: 1.8485573576754177e-05, Final Batch Loss: 2.8291023568272067e-07\n",
      "Epoch 4337, Loss: 0.0006632146541960537, Final Batch Loss: 0.0005924056749790907\n",
      "Epoch 4338, Loss: 5.841717847943073e-05, Final Batch Loss: 8.213150977098849e-06\n",
      "Epoch 4339, Loss: 1.991158137570892e-05, Final Batch Loss: 1.8319100490771234e-05\n",
      "Epoch 4340, Loss: 9.602158627330937e-06, Final Batch Loss: 6.489299835266138e-07\n",
      "Epoch 4341, Loss: 8.039941576498677e-06, Final Batch Loss: 7.084411663527135e-06\n",
      "Epoch 4342, Loss: 5.4850678282036824e-05, Final Batch Loss: 4.827039106203301e-07\n",
      "Epoch 4343, Loss: 2.6798459657584317e-05, Final Batch Loss: 1.5335797797888517e-05\n",
      "Epoch 4344, Loss: 1.710483225281223e-06, Final Batch Loss: 6.883903580501283e-08\n",
      "Epoch 4345, Loss: 5.724075890611857e-05, Final Batch Loss: 7.93144863564521e-06\n",
      "Epoch 4346, Loss: 1.3100431317525363e-05, Final Batch Loss: 3.7693422427764744e-07\n",
      "Epoch 4347, Loss: 0.0002489521784809767, Final Batch Loss: 2.576117367425468e-06\n",
      "Epoch 4348, Loss: 0.0007472367537957325, Final Batch Loss: 0.0007418268942274153\n",
      "Epoch 4349, Loss: 3.111570754299464e-05, Final Batch Loss: 2.9424050808302127e-05\n",
      "Epoch 4350, Loss: 1.789166481103166e-05, Final Batch Loss: 1.5888328562141396e-05\n",
      "Epoch 4351, Loss: 0.00023455445796116692, Final Batch Loss: 1.2373728850434418e-06\n",
      "Epoch 4352, Loss: 2.0269298374842037e-05, Final Batch Loss: 1.9513561710482463e-05\n",
      "Epoch 4353, Loss: 4.094503310625441e-06, Final Batch Loss: 1.646147438805201e-06\n",
      "Epoch 4354, Loss: 3.529028731463768e-07, Final Batch Loss: 2.6611894554662285e-07\n",
      "Epoch 4355, Loss: 1.4418749287870014e-05, Final Batch Loss: 5.775500085292151e-06\n",
      "Epoch 4356, Loss: 0.0027128427518476883, Final Batch Loss: 1.3431962031518196e-07\n",
      "Epoch 4357, Loss: 1.2131015694194502e-06, Final Batch Loss: 1.1836917224172794e-07\n",
      "Epoch 4358, Loss: 2.1480618137559304e-06, Final Batch Loss: 3.4419546324215844e-08\n",
      "Epoch 4359, Loss: 3.155743434035685e-05, Final Batch Loss: 1.5508770957239904e-05\n",
      "Epoch 4360, Loss: 3.705268767362213e-07, Final Batch Loss: 2.03158521117075e-07\n",
      "Epoch 4361, Loss: 0.00026867384440265596, Final Batch Loss: 6.287982978392392e-05\n",
      "Epoch 4362, Loss: 2.7452098265712266e-06, Final Batch Loss: 5.406319587564212e-07\n",
      "Epoch 4363, Loss: 2.416142379502162e-07, Final Batch Loss: 9.570307923922883e-08\n",
      "Epoch 4364, Loss: 1.0963727845592075e-05, Final Batch Loss: 9.680175935500301e-06\n",
      "Epoch 4365, Loss: 1.4446102909460024e-05, Final Batch Loss: 3.979149596489151e-07\n",
      "Epoch 4366, Loss: 3.158769388278415e-07, Final Batch Loss: 2.54365062346551e-07\n",
      "Epoch 4367, Loss: 6.408897388610058e-05, Final Batch Loss: 5.910913023399189e-05\n",
      "Epoch 4368, Loss: 2.8148274537898033e-06, Final Batch Loss: 2.6321999939682428e-06\n",
      "Epoch 4369, Loss: 6.361658856235408e-05, Final Batch Loss: 1.956021549176512e-07\n",
      "Epoch 4370, Loss: 1.1940911008423427e-05, Final Batch Loss: 7.862403435865417e-06\n",
      "Epoch 4371, Loss: 6.9745700272960676e-06, Final Batch Loss: 2.879476994621655e-07\n",
      "Epoch 4372, Loss: 0.00021727244893554598, Final Batch Loss: 0.00018033997912425548\n",
      "Epoch 4373, Loss: 0.00012464282553992234, Final Batch Loss: 7.97026077634655e-05\n",
      "Epoch 4374, Loss: 9.939001586189988e-07, Final Batch Loss: 3.7021638377154886e-07\n",
      "Epoch 4375, Loss: 2.433698796266981e-05, Final Batch Loss: 5.607755610981258e-07\n",
      "Epoch 4376, Loss: 0.00011541050702668088, Final Batch Loss: 2.9382539068478764e-08\n",
      "Epoch 4377, Loss: 7.169587092903384e-07, Final Batch Loss: 4.64237359665276e-07\n",
      "Epoch 4378, Loss: 3.8064927139203064e-05, Final Batch Loss: 2.0276611394365318e-05\n",
      "Epoch 4379, Loss: 6.019176097993295e-06, Final Batch Loss: 2.2498498708500847e-07\n",
      "Epoch 4380, Loss: 1.4171054544931394e-05, Final Batch Loss: 2.6103709842573153e-06\n",
      "Epoch 4381, Loss: 0.0004884249756287318, Final Batch Loss: 3.243468745495193e-05\n",
      "Epoch 4382, Loss: 4.027971158393484e-06, Final Batch Loss: 2.1565224415098783e-06\n",
      "Epoch 4383, Loss: 2.6689600645113387e-06, Final Batch Loss: 1.0745187637439813e-06\n",
      "Epoch 4384, Loss: 5.0748637249853346e-05, Final Batch Loss: 4.7066332626855e-05\n",
      "Epoch 4385, Loss: 4.594312486005947e-07, Final Batch Loss: 1.59504594421378e-07\n",
      "Epoch 4386, Loss: 2.338566537218867e-05, Final Batch Loss: 1.4208759239409119e-05\n",
      "Epoch 4387, Loss: 5.054217217548285e-05, Final Batch Loss: 2.0605953977792524e-05\n",
      "Epoch 4388, Loss: 3.171734249463043e-06, Final Batch Loss: 2.3454372239939403e-06\n",
      "Epoch 4389, Loss: 0.00014027191036802833, Final Batch Loss: 0.00013997913629282266\n",
      "Epoch 4390, Loss: 4.482050826482009e-05, Final Batch Loss: 3.79717348550912e-05\n",
      "Epoch 4391, Loss: 7.021166581466787e-07, Final Batch Loss: 6.329755137812754e-07\n",
      "Epoch 4392, Loss: 2.9043981157883536e-06, Final Batch Loss: 1.5370009123216732e-06\n",
      "Epoch 4393, Loss: 2.5357258891745005e-05, Final Batch Loss: 1.7974418369703926e-05\n",
      "Epoch 4394, Loss: 2.1629925640809233e-05, Final Batch Loss: 1.9744193195947446e-05\n",
      "Epoch 4395, Loss: 1.2994549479117268e-05, Final Batch Loss: 1.2188771506771445e-05\n",
      "Epoch 4396, Loss: 4.245009563419444e-06, Final Batch Loss: 1.0736597459981567e-06\n",
      "Epoch 4397, Loss: 6.908454622589488e-06, Final Batch Loss: 6.551787919306662e-06\n",
      "Epoch 4398, Loss: 1.494107345934026e-05, Final Batch Loss: 8.631764103483874e-06\n",
      "Epoch 4399, Loss: 3.8568645095438114e-06, Final Batch Loss: 1.3481779888024903e-06\n",
      "Epoch 4400, Loss: 6.015652616042644e-06, Final Batch Loss: 3.43441251970944e-06\n",
      "Epoch 4401, Loss: 0.00011201444931074889, Final Batch Loss: 3.022205063984984e-08\n",
      "Epoch 4402, Loss: 4.684041236657777e-06, Final Batch Loss: 4.701205824630961e-08\n",
      "Epoch 4403, Loss: 0.0010928008762220998, Final Batch Loss: 2.585641141195083e-07\n",
      "Epoch 4404, Loss: 0.002214341624494409, Final Batch Loss: 0.0021712277084589005\n",
      "Epoch 4405, Loss: 2.9011082084196005e-05, Final Batch Loss: 4.365400485539794e-08\n",
      "Epoch 4406, Loss: 3.4172306641266914e-05, Final Batch Loss: 3.0457622415269725e-05\n",
      "Epoch 4407, Loss: 8.297644853882957e-06, Final Batch Loss: 5.171968950890005e-06\n",
      "Epoch 4408, Loss: 3.7166786910347582e-06, Final Batch Loss: 4.692732886724116e-07\n",
      "Epoch 4409, Loss: 2.1707539872295456e-06, Final Batch Loss: 1.1408303635107586e-06\n",
      "Epoch 4410, Loss: 6.048881573406106e-06, Final Batch Loss: 1.2357164678178378e-06\n",
      "Epoch 4411, Loss: 2.314476023457246e-05, Final Batch Loss: 1.5749717931612395e-05\n",
      "Epoch 4412, Loss: 5.301839109961293e-06, Final Batch Loss: 2.23629081119725e-06\n",
      "Epoch 4413, Loss: 4.330390744655688e-06, Final Batch Loss: 9.234506848088131e-08\n",
      "Epoch 4414, Loss: 7.109157644435982e-05, Final Batch Loss: 2.8710832111755735e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4415, Loss: 6.98755138728302e-05, Final Batch Loss: 5.4126936447573826e-05\n",
      "Epoch 4416, Loss: 5.130984209245071e-05, Final Batch Loss: 2.415208291495219e-05\n",
      "Epoch 4417, Loss: 3.350195811435697e-05, Final Batch Loss: 4.866799372393871e-06\n",
      "Epoch 4418, Loss: 2.763594591570495e-05, Final Batch Loss: 5.960453464126658e-08\n",
      "Epoch 4419, Loss: 1.5849232568143634e-05, Final Batch Loss: 5.8595787777449e-07\n",
      "Epoch 4420, Loss: 1.2310622480526945e-05, Final Batch Loss: 1.1395605724828783e-05\n",
      "Epoch 4421, Loss: 0.004821601625621952, Final Batch Loss: 1.34140634600044e-06\n",
      "Epoch 4422, Loss: 4.527050396063714e-05, Final Batch Loss: 2.155758465960389e-06\n",
      "Epoch 4423, Loss: 0.0003552659477463749, Final Batch Loss: 3.4892877920356113e-06\n",
      "Epoch 4424, Loss: 4.7605487907276256e-07, Final Batch Loss: 1.8804806245498185e-07\n",
      "Epoch 4425, Loss: 9.071850217878819e-05, Final Batch Loss: 4.330269803176634e-05\n",
      "Epoch 4426, Loss: 0.006998365161052789, Final Batch Loss: 5.0201761041535065e-06\n",
      "Epoch 4427, Loss: 1.6274809695460135e-06, Final Batch Loss: 8.159528874784883e-07\n",
      "Epoch 4428, Loss: 6.165817649161909e-05, Final Batch Loss: 6.23744199401699e-07\n",
      "Epoch 4429, Loss: 0.00035363576850500067, Final Batch Loss: 3.6433581840356055e-07\n",
      "Epoch 4430, Loss: 0.003119955580586975, Final Batch Loss: 0.0031062113121151924\n",
      "Epoch 4431, Loss: 8.922708047975902e-06, Final Batch Loss: 2.2900737803865923e-06\n",
      "Epoch 4432, Loss: 5.420161073743657e-05, Final Batch Loss: 5.0747628847602755e-05\n",
      "Epoch 4433, Loss: 8.993344408736448e-06, Final Batch Loss: 1.082071094060666e-06\n",
      "Epoch 4434, Loss: 0.00012632336984097492, Final Batch Loss: 1.7044452761183493e-05\n",
      "Epoch 4435, Loss: 3.261455162828497e-06, Final Batch Loss: 2.6635118501872057e-06\n",
      "Epoch 4436, Loss: 0.0002214744949924352, Final Batch Loss: 5.6388294069620315e-06\n",
      "Epoch 4437, Loss: 5.724386301153572e-05, Final Batch Loss: 1.596687980054412e-06\n",
      "Epoch 4438, Loss: 5.295219216350233e-05, Final Batch Loss: 7.266345164680388e-06\n",
      "Epoch 4439, Loss: 3.931091487174854e-05, Final Batch Loss: 7.689668564125896e-07\n",
      "Epoch 4440, Loss: 0.0012737969332192733, Final Batch Loss: 4.567943960864795e-06\n",
      "Epoch 4441, Loss: 1.3619824130728375e-05, Final Batch Loss: 4.737419658340514e-06\n",
      "Epoch 4442, Loss: 2.944328889498138e-05, Final Batch Loss: 2.3890943339210935e-05\n",
      "Epoch 4443, Loss: 1.1766765965148807e-05, Final Batch Loss: 4.8263905227940995e-06\n",
      "Epoch 4444, Loss: 0.0008813179993012454, Final Batch Loss: 0.0008729383116587996\n",
      "Epoch 4445, Loss: 0.00029444697429426014, Final Batch Loss: 0.0002639286103658378\n",
      "Epoch 4446, Loss: 1.1845592780446168e-05, Final Batch Loss: 4.709038421424339e-06\n",
      "Epoch 4447, Loss: 5.318649471064418e-06, Final Batch Loss: 4.645372428058181e-06\n",
      "Epoch 4448, Loss: 1.5583141021124902e-05, Final Batch Loss: 1.4444055523199495e-05\n",
      "Epoch 4449, Loss: 7.838070314392098e-05, Final Batch Loss: 7.2617141995579e-05\n",
      "Epoch 4450, Loss: 7.022870079254062e-06, Final Batch Loss: 6.426379968615947e-06\n",
      "Epoch 4451, Loss: 4.0787473835735e-05, Final Batch Loss: 1.8115622424375033e-06\n",
      "Epoch 4452, Loss: 6.817921757829026e-06, Final Batch Loss: 3.949769961764105e-06\n",
      "Epoch 4453, Loss: 1.1674851521092933e-05, Final Batch Loss: 8.956678357208148e-06\n",
      "Epoch 4454, Loss: 5.538365121537936e-05, Final Batch Loss: 4.980152880307287e-05\n",
      "Epoch 4455, Loss: 2.8124436539656017e-06, Final Batch Loss: 8.042291028687032e-07\n",
      "Epoch 4456, Loss: 0.0006102226179791614, Final Batch Loss: 0.00055989547399804\n",
      "Epoch 4457, Loss: 4.609816096490249e-05, Final Batch Loss: 2.2713635189575143e-05\n",
      "Epoch 4458, Loss: 1.279571279155789e-05, Final Batch Loss: 5.7176944210368674e-06\n",
      "Epoch 4459, Loss: 4.131005141516653e-06, Final Batch Loss: 3.824401574092917e-06\n",
      "Epoch 4460, Loss: 1.133301381628371e-06, Final Batch Loss: 1.6202265840092878e-07\n",
      "Epoch 4461, Loss: 6.303102054516785e-05, Final Batch Loss: 2.7011759812012315e-05\n",
      "Epoch 4462, Loss: 6.330519772745902e-05, Final Batch Loss: 7.630406798853073e-06\n",
      "Epoch 4463, Loss: 5.4067813834990375e-06, Final Batch Loss: 6.480768206529319e-07\n",
      "Epoch 4464, Loss: 0.003374646323209163, Final Batch Loss: 3.749192546820268e-05\n",
      "Epoch 4465, Loss: 3.2203631747051986e-05, Final Batch Loss: 3.170154013787396e-05\n",
      "Epoch 4466, Loss: 1.4783015558350598e-05, Final Batch Loss: 3.360958089615451e-06\n",
      "Epoch 4467, Loss: 0.00011964366967731621, Final Batch Loss: 0.00010141678649233654\n",
      "Epoch 4468, Loss: 5.189146918382903e-06, Final Batch Loss: 9.192007155434112e-07\n",
      "Epoch 4469, Loss: 2.560530265327543e-05, Final Batch Loss: 1.0084389941766858e-05\n",
      "Epoch 4470, Loss: 2.7873276621903642e-05, Final Batch Loss: 2.4744892925809836e-06\n",
      "Epoch 4471, Loss: 4.491317241672732e-06, Final Batch Loss: 4.284371698304312e-06\n",
      "Epoch 4472, Loss: 1.3161649121684604e-06, Final Batch Loss: 2.795517275444581e-07\n",
      "Epoch 4473, Loss: 3.3157036227748904e-06, Final Batch Loss: 8.64654509769025e-07\n",
      "Epoch 4474, Loss: 2.1040244803316455e-05, Final Batch Loss: 8.310706220981956e-07\n",
      "Epoch 4475, Loss: 0.00017129873197063716, Final Batch Loss: 0.00017033079348038882\n",
      "Epoch 4476, Loss: 6.950976739972248e-06, Final Batch Loss: 1.2147327197453706e-06\n",
      "Epoch 4477, Loss: 2.967481668747496e-05, Final Batch Loss: 1.1775326129281893e-05\n",
      "Epoch 4478, Loss: 0.00021057157670156812, Final Batch Loss: 0.0002096470125252381\n",
      "Epoch 4479, Loss: 0.00015917324662950705, Final Batch Loss: 0.0001579173986101523\n",
      "Epoch 4480, Loss: 2.0300762813008078e-05, Final Batch Loss: 2.014792386262343e-07\n",
      "Epoch 4481, Loss: 1.3458189357606898e-05, Final Batch Loss: 9.041211228577595e-07\n",
      "Epoch 4482, Loss: 1.362227590107068e-05, Final Batch Loss: 2.231308599220938e-06\n",
      "Epoch 4483, Loss: 8.965982283370977e-05, Final Batch Loss: 8.746186358621344e-05\n",
      "Epoch 4484, Loss: 0.00018887187918892323, Final Batch Loss: 1.3348046934424929e-07\n",
      "Epoch 4485, Loss: 5.353797632778878e-06, Final Batch Loss: 2.0758875507453922e-06\n",
      "Epoch 4486, Loss: 7.405029737128643e-05, Final Batch Loss: 2.133881025656592e-06\n",
      "Epoch 4487, Loss: 0.006137796279290342, Final Batch Loss: 0.0061358180828392506\n",
      "Epoch 4488, Loss: 8.990743367576215e-06, Final Batch Loss: 8.636457096145023e-06\n",
      "Epoch 4489, Loss: 5.070351676295104e-06, Final Batch Loss: 1.8132283230443136e-06\n",
      "Epoch 4490, Loss: 1.6141262790370092e-05, Final Batch Loss: 1.6301302139254403e-06\n",
      "Epoch 4491, Loss: 0.0003431819597210506, Final Batch Loss: 0.0003430436772760004\n",
      "Epoch 4492, Loss: 5.2291959946160205e-05, Final Batch Loss: 2.7776735805673525e-05\n",
      "Epoch 4493, Loss: 0.0025842400869464655, Final Batch Loss: 8.730353897590248e-07\n",
      "Epoch 4494, Loss: 4.365752522517141e-05, Final Batch Loss: 1.0510381116546341e-06\n",
      "Epoch 4495, Loss: 2.2476250705949496e-05, Final Batch Loss: 1.4038625522516668e-05\n",
      "Epoch 4496, Loss: 1.2218955191656278e-05, Final Batch Loss: 1.157571477961028e-05\n",
      "Epoch 4497, Loss: 6.238686330561904e-05, Final Batch Loss: 1.3095574331600801e-06\n",
      "Epoch 4498, Loss: 6.125135399770443e-05, Final Batch Loss: 6.338049729492923e-07\n",
      "Epoch 4499, Loss: 1.24924640658719e-05, Final Batch Loss: 1.1505465408845339e-05\n",
      "Epoch 4500, Loss: 7.277583029008383e-05, Final Batch Loss: 1.6025584272938431e-06\n",
      "Epoch 4501, Loss: 2.7336350910900364e-05, Final Batch Loss: 2.683043021534104e-05\n",
      "Epoch 4502, Loss: 2.228241226021055e-05, Final Batch Loss: 1.5697836488470784e-06\n",
      "Epoch 4503, Loss: 0.00015983350203896407, Final Batch Loss: 0.00013273590593598783\n",
      "Epoch 4504, Loss: 5.981411504762946e-06, Final Batch Loss: 2.805475787681644e-06\n",
      "Epoch 4505, Loss: 5.687816724275763e-07, Final Batch Loss: 1.863686520664487e-07\n",
      "Epoch 4506, Loss: 0.03671708826811937, Final Batch Loss: 1.0443189921716112e-06\n",
      "Epoch 4507, Loss: 0.0005119132125344095, Final Batch Loss: 1.3515963814825227e-07\n",
      "Epoch 4508, Loss: 0.00016792248061392456, Final Batch Loss: 0.00012084496847819537\n",
      "Epoch 4509, Loss: 3.023606399210621e-05, Final Batch Loss: 2.9517495931941085e-05\n",
      "Epoch 4510, Loss: 8.620487642474473e-05, Final Batch Loss: 8.235961286118254e-05\n",
      "Epoch 4511, Loss: 0.00029711582601521513, Final Batch Loss: 1.2424561646184884e-07\n",
      "Epoch 4512, Loss: 3.564596977412293e-05, Final Batch Loss: 3.341990304761566e-05\n",
      "Epoch 4513, Loss: 0.010556592395005282, Final Batch Loss: 1.3213357306085527e-06\n",
      "Epoch 4514, Loss: 5.7478774238006736e-06, Final Batch Loss: 3.844884872705734e-07\n",
      "Epoch 4515, Loss: 0.0006641335476160748, Final Batch Loss: 0.000636350130662322\n",
      "Epoch 4516, Loss: 0.0002617562931845896, Final Batch Loss: 0.00020513102936092764\n",
      "Epoch 4517, Loss: 5.613382882074802e-06, Final Batch Loss: 1.6957039861154044e-06\n",
      "Epoch 4518, Loss: 0.0002295841641171137, Final Batch Loss: 5.174029865884222e-06\n",
      "Epoch 4519, Loss: 7.029927837720606e-05, Final Batch Loss: 2.0339739421615377e-06\n",
      "Epoch 4520, Loss: 5.332251748768613e-05, Final Batch Loss: 1.695743776508607e-05\n",
      "Epoch 4521, Loss: 0.002901383224525489, Final Batch Loss: 0.0028127282857894897\n",
      "Epoch 4522, Loss: 1.0385956329628243e-05, Final Batch Loss: 1.701501560091856e-06\n",
      "Epoch 4523, Loss: 0.00038550548742932733, Final Batch Loss: 1.7689968444756232e-05\n",
      "Epoch 4524, Loss: 0.0003643148811534047, Final Batch Loss: 0.00018279842333868146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4525, Loss: 0.0003262799000367522, Final Batch Loss: 0.00021882280998397619\n",
      "Epoch 4526, Loss: 0.00013984606630401686, Final Batch Loss: 0.0001211322596645914\n",
      "Epoch 4527, Loss: 0.00010399298298580106, Final Batch Loss: 7.880081102484837e-05\n",
      "Epoch 4528, Loss: 0.00037747318856418133, Final Batch Loss: 0.0001725962501950562\n",
      "Epoch 4529, Loss: 1.9114573660772294e-05, Final Batch Loss: 5.210802555666305e-06\n",
      "Epoch 4530, Loss: 2.9828728656866588e-05, Final Batch Loss: 1.4529550753650256e-05\n",
      "Epoch 4531, Loss: 0.00022925576001853187, Final Batch Loss: 1.657141069699719e-06\n",
      "Epoch 4532, Loss: 4.1812998006207636e-05, Final Batch Loss: 6.269388450164115e-06\n",
      "Epoch 4533, Loss: 0.00029086956919854856, Final Batch Loss: 0.0002856931241694838\n",
      "Epoch 4534, Loss: 3.302094114587817e-05, Final Batch Loss: 2.9962100597913377e-05\n",
      "Epoch 4535, Loss: 6.716001053064247e-06, Final Batch Loss: 9.124994448939105e-07\n",
      "Epoch 4536, Loss: 3.2056786494649714e-05, Final Batch Loss: 2.688314998522401e-05\n",
      "Epoch 4537, Loss: 7.658064191673475e-07, Final Batch Loss: 2.20788137994532e-07\n",
      "Epoch 4538, Loss: 0.00017317476323341907, Final Batch Loss: 0.00017252676479984075\n",
      "Epoch 4539, Loss: 6.482566959675751e-06, Final Batch Loss: 1.2105258520023199e-06\n",
      "Epoch 4540, Loss: 0.00028655457572313026, Final Batch Loss: 0.00025597994681447744\n",
      "Epoch 4541, Loss: 0.00012250581130501814, Final Batch Loss: 2.7535497792996466e-07\n",
      "Epoch 4542, Loss: 3.840833096546703e-05, Final Batch Loss: 5.462078206619481e-06\n",
      "Epoch 4543, Loss: 0.0015889072892605327, Final Batch Loss: 0.0015720169758424163\n",
      "Epoch 4544, Loss: 8.59460374158516e-05, Final Batch Loss: 1.4002102943777572e-06\n",
      "Epoch 4545, Loss: 6.365372337313602e-05, Final Batch Loss: 5.273687747830991e-06\n",
      "Epoch 4546, Loss: 4.27781460530241e-05, Final Batch Loss: 3.982561793236528e-06\n",
      "Epoch 4547, Loss: 5.59973877898301e-05, Final Batch Loss: 3.290833774372004e-07\n",
      "Epoch 4548, Loss: 5.141522478879779e-06, Final Batch Loss: 1.3599833437183406e-07\n",
      "Epoch 4549, Loss: 6.744572374373092e-06, Final Batch Loss: 3.139899263260304e-06\n",
      "Epoch 4550, Loss: 3.0982836847215367e-06, Final Batch Loss: 5.003275305170973e-07\n",
      "Epoch 4551, Loss: 3.4204450457764324e-05, Final Batch Loss: 4.278604137653019e-06\n",
      "Epoch 4552, Loss: 8.172996899702412e-05, Final Batch Loss: 1.970201310541597e-06\n",
      "Epoch 4553, Loss: 5.6418688473058864e-05, Final Batch Loss: 2.2499451006297022e-05\n",
      "Epoch 4554, Loss: 0.00015922344846330816, Final Batch Loss: 0.00015725141565781087\n",
      "Epoch 4555, Loss: 2.8781090577467694e-05, Final Batch Loss: 3.6647450087912148e-06\n",
      "Epoch 4556, Loss: 1.4554428375390671e-05, Final Batch Loss: 1.4461922546615824e-05\n",
      "Epoch 4557, Loss: 6.471528422480333e-06, Final Batch Loss: 3.048569169550319e-06\n",
      "Epoch 4558, Loss: 0.0002957818505819887, Final Batch Loss: 0.00025392131647095084\n",
      "Epoch 4559, Loss: 0.0001953213281922217, Final Batch Loss: 2.0666698219429236e-06\n",
      "Epoch 4560, Loss: 2.6450702989677666e-05, Final Batch Loss: 6.312123787211021e-06\n",
      "Epoch 4561, Loss: 2.8321359650362865e-05, Final Batch Loss: 2.937238832600997e-06\n",
      "Epoch 4562, Loss: 4.143161095271353e-05, Final Batch Loss: 1.4506194929708727e-05\n",
      "Epoch 4563, Loss: 0.00022773028410938423, Final Batch Loss: 1.1123187277917168e-06\n",
      "Epoch 4564, Loss: 9.552377122190592e-06, Final Batch Loss: 4.4660984599431686e-07\n",
      "Epoch 4565, Loss: 2.605045722248178e-06, Final Batch Loss: 2.299873813171871e-06\n",
      "Epoch 4566, Loss: 0.0003953855792246941, Final Batch Loss: 5.725322012040124e-07\n",
      "Epoch 4567, Loss: 5.244391968517448e-05, Final Batch Loss: 7.065256340865744e-06\n",
      "Epoch 4568, Loss: 0.00013837184906151379, Final Batch Loss: 0.00013469037367030978\n",
      "Epoch 4569, Loss: 1.164009017884382e-05, Final Batch Loss: 7.795688361511566e-06\n",
      "Epoch 4570, Loss: 3.9011295370983134e-05, Final Batch Loss: 1.2172756669315277e-07\n",
      "Epoch 4571, Loss: 0.0011695536031766096, Final Batch Loss: 0.001160835032351315\n",
      "Epoch 4572, Loss: 4.9135382596432464e-05, Final Batch Loss: 6.664370175712975e-06\n",
      "Epoch 4573, Loss: 7.4764700173091114e-06, Final Batch Loss: 7.185125923570013e-06\n",
      "Epoch 4574, Loss: 0.00020027156101320998, Final Batch Loss: 0.0002000660460907966\n",
      "Epoch 4575, Loss: 6.751363912371744e-07, Final Batch Loss: 4.0715596583140723e-07\n",
      "Epoch 4576, Loss: 1.1515186315591563e-05, Final Batch Loss: 9.968395715986844e-06\n",
      "Epoch 4577, Loss: 1.3308507050169283e-05, Final Batch Loss: 1.1099189578089863e-05\n",
      "Epoch 4578, Loss: 6.492998682006146e-05, Final Batch Loss: 6.798752565373434e-06\n",
      "Epoch 4579, Loss: 2.2380716018233215e-06, Final Batch Loss: 9.788194574866793e-07\n",
      "Epoch 4580, Loss: 3.0594641430070624e-05, Final Batch Loss: 2.395986120973248e-05\n",
      "Epoch 4581, Loss: 3.5585566138252034e-06, Final Batch Loss: 1.6856586171343224e-06\n",
      "Epoch 4582, Loss: 5.860144256075728e-06, Final Batch Loss: 3.191129962942796e-06\n",
      "Epoch 4583, Loss: 2.3054282962675643e-06, Final Batch Loss: 1.9308544096929836e-08\n",
      "Epoch 4584, Loss: 1.2111664091207786e-05, Final Batch Loss: 1.0391363503003959e-05\n",
      "Epoch 4585, Loss: 1.681878256931668e-05, Final Batch Loss: 3.362825736985542e-06\n",
      "Epoch 4586, Loss: 3.775219738599844e-05, Final Batch Loss: 2.871536707971245e-06\n",
      "Epoch 4587, Loss: 0.000543401970389823, Final Batch Loss: 0.0005367730045691133\n",
      "Epoch 4588, Loss: 0.0001444005611119792, Final Batch Loss: 6.118832970969379e-06\n",
      "Epoch 4589, Loss: 0.0004700470913121535, Final Batch Loss: 5.793760010419646e-06\n",
      "Epoch 4590, Loss: 3.9169867704913486e-05, Final Batch Loss: 1.0073317753267474e-06\n",
      "Epoch 4591, Loss: 9.004864864436968e-06, Final Batch Loss: 8.16612555354368e-06\n",
      "Epoch 4592, Loss: 8.629086551081855e-05, Final Batch Loss: 7.27464139345102e-05\n",
      "Epoch 4593, Loss: 0.0008180930993830771, Final Batch Loss: 0.0008170841610990465\n",
      "Epoch 4594, Loss: 2.0345616576378234e-05, Final Batch Loss: 5.082200004835613e-06\n",
      "Epoch 4595, Loss: 8.1109223515341e-06, Final Batch Loss: 3.8532874668817385e-07\n",
      "Epoch 4596, Loss: 6.523767933686031e-05, Final Batch Loss: 2.0582983779604547e-06\n",
      "Epoch 4597, Loss: 9.074276249521063e-06, Final Batch Loss: 1.0023297818406718e-06\n",
      "Epoch 4598, Loss: 0.0003958469008011889, Final Batch Loss: 0.0003927878278773278\n",
      "Epoch 4599, Loss: 5.8060642572854704e-05, Final Batch Loss: 5.742599387303926e-05\n",
      "Epoch 4600, Loss: 6.6811628130381e-05, Final Batch Loss: 3.686117270262912e-05\n",
      "Epoch 4601, Loss: 7.778524388868391e-05, Final Batch Loss: 7.714295497862622e-05\n",
      "Epoch 4602, Loss: 3.1134384698816575e-05, Final Batch Loss: 2.0678013243013993e-05\n",
      "Epoch 4603, Loss: 8.797890700407152e-07, Final Batch Loss: 2.6947873266180977e-07\n",
      "Epoch 4604, Loss: 1.1268758726146189e-05, Final Batch Loss: 2.848179292413988e-06\n",
      "Epoch 4605, Loss: 1.0580375260360597e-06, Final Batch Loss: 1.1585063930397155e-07\n",
      "Epoch 4606, Loss: 6.4624150581948925e-06, Final Batch Loss: 5.299953954818193e-06\n",
      "Epoch 4607, Loss: 3.637611754925274e-06, Final Batch Loss: 3.49742322214297e-06\n",
      "Epoch 4608, Loss: 2.334668852199684e-05, Final Batch Loss: 4.228082161716884e-06\n",
      "Epoch 4609, Loss: 1.2885859291600354e-05, Final Batch Loss: 1.3549307595894788e-06\n",
      "Epoch 4610, Loss: 2.4079549802991096e-05, Final Batch Loss: 5.315398993843701e-06\n",
      "Epoch 4611, Loss: 6.662440046056872e-05, Final Batch Loss: 1.3570747796620708e-05\n",
      "Epoch 4612, Loss: 8.569167462724181e-06, Final Batch Loss: 1.821711208549459e-07\n",
      "Epoch 4613, Loss: 0.0019552724697859958, Final Batch Loss: 0.00022803254250902683\n",
      "Epoch 4614, Loss: 1.4586322322429623e-05, Final Batch Loss: 1.2219592463225126e-05\n",
      "Epoch 4615, Loss: 6.526332981593441e-06, Final Batch Loss: 1.9593003344198223e-06\n",
      "Epoch 4616, Loss: 7.287164748959185e-06, Final Batch Loss: 5.525942469830625e-06\n",
      "Epoch 4617, Loss: 0.0014101837023190456, Final Batch Loss: 1.549485205032397e-05\n",
      "Epoch 4618, Loss: 0.00019833682745229453, Final Batch Loss: 0.00017684235353954136\n",
      "Epoch 4619, Loss: 1.0627684673636395e-05, Final Batch Loss: 1.3195866586102056e-06\n",
      "Epoch 4620, Loss: 6.221695821295725e-05, Final Batch Loss: 5.355522080208175e-05\n",
      "Epoch 4621, Loss: 2.1918205916904299e-07, Final Batch Loss: 3.274056226132416e-08\n",
      "Epoch 4622, Loss: 2.2983062763159978e-05, Final Batch Loss: 2.18657692130364e-06\n",
      "Epoch 4623, Loss: 1.3309271253092447e-05, Final Batch Loss: 9.113940905081108e-06\n",
      "Epoch 4624, Loss: 2.3550714161046926e-06, Final Batch Loss: 3.3159645340674615e-07\n",
      "Epoch 4625, Loss: 6.26278222171095e-06, Final Batch Loss: 1.4439168580793194e-06\n",
      "Epoch 4626, Loss: 3.5574863943566015e-05, Final Batch Loss: 5.42299460448703e-07\n",
      "Epoch 4627, Loss: 6.574316830665339e-05, Final Batch Loss: 5.136747859069146e-05\n",
      "Epoch 4628, Loss: 0.0001935692648658005, Final Batch Loss: 0.00019179319497197866\n",
      "Epoch 4629, Loss: 9.107480650527577e-06, Final Batch Loss: 8.726493433641735e-06\n",
      "Epoch 4630, Loss: 4.1739773379845246e-05, Final Batch Loss: 8.562908249132306e-08\n",
      "Epoch 4631, Loss: 9.628204415434993e-05, Final Batch Loss: 9.604744263924658e-05\n",
      "Epoch 4632, Loss: 1.9200457046508745e-06, Final Batch Loss: 7.051808381675073e-08\n",
      "Epoch 4633, Loss: 8.01800473482217e-06, Final Batch Loss: 7.340449428738793e-06\n",
      "Epoch 4634, Loss: 1.2375614005577518e-05, Final Batch Loss: 4.83546045870753e-07\n",
      "Epoch 4635, Loss: 2.4550497897735113e-05, Final Batch Loss: 3.114527373782039e-07\n",
      "Epoch 4636, Loss: 1.968460423995566e-06, Final Batch Loss: 5.104029696667567e-07\n",
      "Epoch 4637, Loss: 2.7291028459330846e-06, Final Batch Loss: 2.3376269382424653e-06\n",
      "Epoch 4638, Loss: 1.6622659302356624e-06, Final Batch Loss: 1.3313477893461823e-06\n",
      "Epoch 4639, Loss: 1.6767283952390244e-06, Final Batch Loss: 1.5613351251886343e-06\n",
      "Epoch 4640, Loss: 0.00011624549870248302, Final Batch Loss: 6.875224698887905e-06\n",
      "Epoch 4641, Loss: 4.692770403380564e-07, Final Batch Loss: 4.0967245240608463e-07\n",
      "Epoch 4642, Loss: 0.001745440466038417, Final Batch Loss: 0.0017110833432525396\n",
      "Epoch 4643, Loss: 7.543147848565468e-07, Final Batch Loss: 1.762953338868556e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4644, Loss: 1.3449215998662112e-05, Final Batch Loss: 9.77146896730119e-07\n",
      "Epoch 4645, Loss: 2.0748327500541563e-07, Final Batch Loss: 6.967854204731339e-08\n",
      "Epoch 4646, Loss: 7.252981731653563e-06, Final Batch Loss: 4.457228897081222e-06\n",
      "Epoch 4647, Loss: 5.60742068955733e-06, Final Batch Loss: 3.2481298148923088e-06\n",
      "Epoch 4648, Loss: 0.00023381049390991393, Final Batch Loss: 3.4962110930791823e-06\n",
      "Epoch 4649, Loss: 0.00016515876382072747, Final Batch Loss: 0.00016377509746234864\n",
      "Epoch 4650, Loss: 1.7770468730304856e-05, Final Batch Loss: 1.1444238225521985e-05\n",
      "Epoch 4651, Loss: 7.01729106822313e-07, Final Batch Loss: 3.097733838330896e-07\n",
      "Epoch 4652, Loss: 1.8876015019486658e-05, Final Batch Loss: 5.005478669772856e-06\n",
      "Epoch 4653, Loss: 2.5334339738947165e-05, Final Batch Loss: 2.4577149815740995e-05\n",
      "Epoch 4654, Loss: 1.7683495116216363e-05, Final Batch Loss: 1.5044140127429273e-05\n",
      "Epoch 4655, Loss: 4.856471923631034e-05, Final Batch Loss: 1.7828801901487168e-06\n",
      "Epoch 4656, Loss: 1.8617269432752437e-06, Final Batch Loss: 1.133325184810019e-07\n",
      "Epoch 4657, Loss: 5.356695510272402e-06, Final Batch Loss: 4.462245215108851e-06\n",
      "Epoch 4658, Loss: 2.2860306700067667e-05, Final Batch Loss: 2.5856482466224406e-07\n",
      "Epoch 4659, Loss: 1.3732414004152815e-05, Final Batch Loss: 2.484893002474564e-07\n",
      "Epoch 4660, Loss: 1.9296201799079427e-05, Final Batch Loss: 1.829876418923959e-05\n",
      "Epoch 4661, Loss: 0.005171157877839505, Final Batch Loss: 0.005168422590941191\n",
      "Epoch 4662, Loss: 1.800513933858383e-05, Final Batch Loss: 7.521776410612802e-07\n",
      "Epoch 4663, Loss: 0.00011009722499011332, Final Batch Loss: 0.00010975485929520801\n",
      "Epoch 4664, Loss: 1.2108243652164674e-06, Final Batch Loss: 9.654249311097374e-08\n",
      "Epoch 4665, Loss: 7.525528781116009e-05, Final Batch Loss: 2.1632669813698158e-05\n",
      "Epoch 4666, Loss: 1.4966228718549246e-05, Final Batch Loss: 1.1559248378034681e-05\n",
      "Epoch 4667, Loss: 8.056654678512132e-06, Final Batch Loss: 4.15119848184986e-06\n",
      "Epoch 4668, Loss: 7.355804905273544e-05, Final Batch Loss: 1.5656062259949977e-06\n",
      "Epoch 4669, Loss: 2.7977852852245633e-06, Final Batch Loss: 1.2424602857663558e-07\n",
      "Epoch 4670, Loss: 3.4396960472804494e-05, Final Batch Loss: 5.35740218765568e-06\n",
      "Epoch 4671, Loss: 0.0001244627697190026, Final Batch Loss: 2.829097240919509e-07\n",
      "Epoch 4672, Loss: 4.973178045020177e-05, Final Batch Loss: 1.0375541705798241e-06\n",
      "Epoch 4673, Loss: 0.00034999092349607963, Final Batch Loss: 0.0003447921189945191\n",
      "Epoch 4674, Loss: 1.8749957462205202e-05, Final Batch Loss: 1.986836878131726e-06\n",
      "Epoch 4675, Loss: 4.889541997954439e-07, Final Batch Loss: 9.318453919604508e-08\n",
      "Epoch 4676, Loss: 9.349866900265624e-06, Final Batch Loss: 7.815458047844004e-06\n",
      "Epoch 4677, Loss: 6.75609535392141e-05, Final Batch Loss: 6.041358210495673e-05\n",
      "Epoch 4678, Loss: 3.677248105304898e-05, Final Batch Loss: 3.126481533399783e-05\n",
      "Epoch 4679, Loss: 1.5299282040359685e-05, Final Batch Loss: 2.2488125068775844e-06\n",
      "Epoch 4680, Loss: 3.3972049777730717e-06, Final Batch Loss: 8.696850954947877e-07\n",
      "Epoch 4681, Loss: 1.671410558401476e-06, Final Batch Loss: 1.3171245427656686e-06\n",
      "Epoch 4682, Loss: 3.170105884464647e-06, Final Batch Loss: 2.2498559815176122e-07\n",
      "Epoch 4683, Loss: 2.124473951425898e-06, Final Batch Loss: 5.028553573538375e-07\n",
      "Epoch 4684, Loss: 0.00011950613679800881, Final Batch Loss: 0.00010925081733148545\n",
      "Epoch 4685, Loss: 1.1137535011584987e-05, Final Batch Loss: 5.473468718264485e-07\n",
      "Epoch 4686, Loss: 0.0030250731074374926, Final Batch Loss: 5.472466455103131e-06\n",
      "Epoch 4687, Loss: 2.5745313223524136e-06, Final Batch Loss: 1.8769400185192353e-06\n",
      "Epoch 4688, Loss: 4.632602212950587e-06, Final Batch Loss: 2.115290271831327e-06\n",
      "Epoch 4689, Loss: 0.0003398592947405632, Final Batch Loss: 0.00033847891609184444\n",
      "Epoch 4690, Loss: 6.894683565406012e-06, Final Batch Loss: 1.9392405192775186e-07\n",
      "Epoch 4691, Loss: 2.083812864839274e-05, Final Batch Loss: 1.8576951333670877e-05\n",
      "Epoch 4692, Loss: 2.4046950557021773e-05, Final Batch Loss: 9.804805358726298e-07\n",
      "Epoch 4693, Loss: 2.1311303157744987e-06, Final Batch Loss: 5.69167298181128e-07\n",
      "Epoch 4694, Loss: 6.348248916765442e-06, Final Batch Loss: 3.2980872219923185e-06\n",
      "Epoch 4695, Loss: 0.033923540263486984, Final Batch Loss: 0.033923421055078506\n",
      "Epoch 4696, Loss: 6.776382093676148e-05, Final Batch Loss: 6.747629231540486e-05\n",
      "Epoch 4697, Loss: 6.305343873691527e-07, Final Batch Loss: 4.054691089550033e-07\n",
      "Epoch 4698, Loss: 6.934692351023841e-06, Final Batch Loss: 6.220528803169145e-07\n",
      "Epoch 4699, Loss: 0.0038463035095901432, Final Batch Loss: 2.443507355565089e-06\n",
      "Epoch 4700, Loss: 2.7570096885476403e-06, Final Batch Loss: 4.197509451131509e-09\n",
      "Epoch 4701, Loss: 2.336891036236466e-07, Final Batch Loss: 1.8552877634192555e-07\n",
      "Epoch 4702, Loss: 9.88289320957847e-06, Final Batch Loss: 5.423071343102492e-07\n",
      "Epoch 4703, Loss: 0.0013479617409757338, Final Batch Loss: 0.0013228084426373243\n",
      "Epoch 4704, Loss: 3.744976311281789e-06, Final Batch Loss: 7.546791493950877e-07\n",
      "Epoch 4705, Loss: 3.2123413120643818e-06, Final Batch Loss: 3.000150400112034e-06\n",
      "Epoch 4706, Loss: 1.7095351211082743e-05, Final Batch Loss: 7.462871849384101e-07\n",
      "Epoch 4707, Loss: 1.1609361464937074e-06, Final Batch Loss: 8.395019679419136e-10\n",
      "Epoch 4708, Loss: 7.919921620214154e-05, Final Batch Loss: 7.756107515888289e-05\n",
      "Epoch 4709, Loss: 2.1905842686464894e-06, Final Batch Loss: 9.099902626985568e-07\n",
      "Epoch 4710, Loss: 0.0006241985023436314, Final Batch Loss: 1.1249300513327398e-07\n",
      "Epoch 4711, Loss: 4.634199149222695e-05, Final Batch Loss: 6.401917289622361e-06\n",
      "Epoch 4712, Loss: 7.238015768962214e-07, Final Batch Loss: 3.928831802113564e-07\n",
      "Epoch 4713, Loss: 0.0008856992083132731, Final Batch Loss: 5.037011252539969e-09\n",
      "Epoch 4714, Loss: 1.5031593250114383e-06, Final Batch Loss: 1.0921386319751036e-06\n",
      "Epoch 4715, Loss: 0.0002771705658233259, Final Batch Loss: 0.0002399441582383588\n",
      "Epoch 4716, Loss: 1.1096360395868032e-05, Final Batch Loss: 1.0697258403524756e-05\n",
      "Epoch 4717, Loss: 1.604983276592975e-05, Final Batch Loss: 1.5311748938984238e-05\n",
      "Epoch 4718, Loss: 0.00024295100627824695, Final Batch Loss: 7.303641069711375e-08\n",
      "Epoch 4719, Loss: 6.858203425963438e-05, Final Batch Loss: 4.315007799959858e-07\n",
      "Epoch 4720, Loss: 1.3215391646781427e-05, Final Batch Loss: 4.12190985343841e-07\n",
      "Epoch 4721, Loss: 6.838003719167318e-05, Final Batch Loss: 4.787534635397606e-06\n",
      "Epoch 4722, Loss: 2.0326676803961163e-06, Final Batch Loss: 1.4404603234652313e-06\n",
      "Epoch 4723, Loss: 1.4175368733049254e-05, Final Batch Loss: 1.3934090929978993e-05\n",
      "Epoch 4724, Loss: 2.2186298338056076e-05, Final Batch Loss: 5.717231942981016e-06\n",
      "Epoch 4725, Loss: 2.5723539209820956e-07, Final Batch Loss: 1.5614646997619275e-07\n",
      "Epoch 4726, Loss: 3.7619188617554755e-06, Final Batch Loss: 2.694783063361683e-07\n",
      "Epoch 4727, Loss: 7.880599692811074e-07, Final Batch Loss: 1.846902897284508e-08\n",
      "Epoch 4728, Loss: 0.008093902705979872, Final Batch Loss: 5.204740887165826e-07\n",
      "Epoch 4729, Loss: 3.309365906645212e-06, Final Batch Loss: 5.876513498037639e-09\n",
      "Epoch 4730, Loss: 4.0609668531033094e-05, Final Batch Loss: 3.687330536195077e-05\n",
      "Epoch 4731, Loss: 0.0011329409571771976, Final Batch Loss: 2.50801895163022e-06\n",
      "Epoch 4732, Loss: 0.00016115265134430956, Final Batch Loss: 0.00014893876505084336\n",
      "Epoch 4733, Loss: 9.253310457779662e-05, Final Batch Loss: 9.206344111589715e-05\n",
      "Epoch 4734, Loss: 0.00019302650980534963, Final Batch Loss: 0.00019031422561965883\n",
      "Epoch 4735, Loss: 2.5840571424851078e-06, Final Batch Loss: 1.0703250836741063e-06\n",
      "Epoch 4736, Loss: 6.653537332113046e-05, Final Batch Loss: 1.6738127897042432e-06\n",
      "Epoch 4737, Loss: 5.479150786413811e-06, Final Batch Loss: 2.0774698441528017e-06\n",
      "Epoch 4738, Loss: 4.4060474010620965e-05, Final Batch Loss: 4.0313843783224e-05\n",
      "Epoch 4739, Loss: 1.146029198650922e-06, Final Batch Loss: 9.990019833594488e-08\n",
      "Epoch 4740, Loss: 6.4720964161324446e-06, Final Batch Loss: 1.4943067583317315e-07\n",
      "Epoch 4741, Loss: 1.784413649374983e-05, Final Batch Loss: 9.225637427334732e-07\n",
      "Epoch 4742, Loss: 2.168357912069041e-05, Final Batch Loss: 2.0609391867765225e-05\n",
      "Epoch 4743, Loss: 1.1848830126837129e-05, Final Batch Loss: 2.3787838472344447e-06\n",
      "Epoch 4744, Loss: 7.024652461495862e-05, Final Batch Loss: 6.856071559013799e-05\n",
      "Epoch 4745, Loss: 2.6486689534976904e-06, Final Batch Loss: 4.7179338480418664e-07\n",
      "Epoch 4746, Loss: 1.9125751826720716e-07, Final Batch Loss: 2.7703540794732362e-08\n",
      "Epoch 4747, Loss: 3.158568404160178e-06, Final Batch Loss: 8.671742648402869e-07\n",
      "Epoch 4748, Loss: 4.578471566674125e-05, Final Batch Loss: 3.2979435218294384e-06\n",
      "Epoch 4749, Loss: 1.8092540926772926e-05, Final Batch Loss: 1.8182155372414854e-06\n",
      "Epoch 4750, Loss: 1.0332686770198052e-05, Final Batch Loss: 6.603714155062335e-06\n",
      "Epoch 4751, Loss: 1.906957635355866e-06, Final Batch Loss: 3.1732972161080397e-07\n",
      "Epoch 4752, Loss: 3.265082213488313e-05, Final Batch Loss: 9.906088394018298e-08\n",
      "Epoch 4753, Loss: 4.139598422625568e-05, Final Batch Loss: 1.33386674860958e-06\n",
      "Epoch 4754, Loss: 0.0004533068381533667, Final Batch Loss: 0.00045271700946614146\n",
      "Epoch 4755, Loss: 0.0012458892285849288, Final Batch Loss: 0.001244409242644906\n",
      "Epoch 4756, Loss: 1.6946375751558662e-06, Final Batch Loss: 9.738195672071015e-08\n",
      "Epoch 4757, Loss: 6.837850764895848e-05, Final Batch Loss: 6.705545820295811e-05\n",
      "Epoch 4758, Loss: 2.7612073285609995e-06, Final Batch Loss: 2.6864030999718125e-08\n",
      "Epoch 4759, Loss: 2.3139228346735763e-06, Final Batch Loss: 1.742704739626788e-06\n",
      "Epoch 4760, Loss: 0.00013616848082165234, Final Batch Loss: 3.2868691050680354e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4761, Loss: 1.625583126951824e-05, Final Batch Loss: 1.4487874977930915e-05\n",
      "Epoch 4762, Loss: 1.7258540196962713e-05, Final Batch Loss: 1.5394205547636375e-05\n",
      "Epoch 4763, Loss: 1.0828076995039737e-05, Final Batch Loss: 4.667504640565312e-07\n",
      "Epoch 4764, Loss: 6.824332032806524e-06, Final Batch Loss: 1.712577812895688e-07\n",
      "Epoch 4765, Loss: 1.8122840060641465e-05, Final Batch Loss: 1.0543402595430962e-06\n",
      "Epoch 4766, Loss: 8.552567578590242e-07, Final Batch Loss: 5.372794475988485e-08\n",
      "Epoch 4767, Loss: 1.3666032003811779e-06, Final Batch Loss: 1.1634728025455843e-06\n",
      "Epoch 4768, Loss: 3.568199815617845e-07, Final Batch Loss: 2.8291040621297725e-07\n",
      "Epoch 4769, Loss: 0.0002412969986380631, Final Batch Loss: 0.00023994618095457554\n",
      "Epoch 4770, Loss: 3.257720118199359e-05, Final Batch Loss: 3.170129639329389e-05\n",
      "Epoch 4771, Loss: 4.3110958512171393e-05, Final Batch Loss: 3.3580078717676543e-09\n",
      "Epoch 4772, Loss: 0.0005034205673837278, Final Batch Loss: 5.892564786336152e-06\n",
      "Epoch 4773, Loss: 1.6174098618648713e-05, Final Batch Loss: 1.3218670574133284e-05\n",
      "Epoch 4774, Loss: 1.5232911607654387e-06, Final Batch Loss: 1.2348074278634158e-06\n",
      "Epoch 4775, Loss: 8.431664355157409e-06, Final Batch Loss: 5.21738138559158e-06\n",
      "Epoch 4776, Loss: 0.00011996565788052749, Final Batch Loss: 0.0001199127291329205\n",
      "Epoch 4777, Loss: 0.00045747729018330574, Final Batch Loss: 0.00036819788510911167\n",
      "Epoch 4778, Loss: 1.7269023146582185e-05, Final Batch Loss: 1.6585285266046412e-05\n",
      "Epoch 4779, Loss: 2.4860489702405175e-06, Final Batch Loss: 1.5210200672299834e-06\n",
      "Epoch 4780, Loss: 0.0001378545612169546, Final Batch Loss: 1.0726919754233677e-05\n",
      "Epoch 4781, Loss: 0.0001986333227250725, Final Batch Loss: 5.422389949671924e-05\n",
      "Epoch 4782, Loss: 8.714954435617983e-05, Final Batch Loss: 1.514331756879983e-06\n",
      "Epoch 4783, Loss: 1.0149700301553821e-05, Final Batch Loss: 5.556039923249045e-06\n",
      "Epoch 4784, Loss: 5.451746710605221e-05, Final Batch Loss: 4.4889220589539036e-05\n",
      "Epoch 4785, Loss: 9.152438451565104e-06, Final Batch Loss: 5.178351329959696e-06\n",
      "Epoch 4786, Loss: 2.9891050303376687e-05, Final Batch Loss: 1.8324093389310292e-06\n",
      "Epoch 4787, Loss: 3.2312671464751475e-05, Final Batch Loss: 1.3507069525076076e-06\n",
      "Epoch 4788, Loss: 2.121027893053906e-05, Final Batch Loss: 5.859531597707246e-07\n",
      "Epoch 4789, Loss: 7.236466262838803e-05, Final Batch Loss: 2.8482045308919623e-05\n",
      "Epoch 4790, Loss: 4.930364093524986e-05, Final Batch Loss: 9.57827523961896e-07\n",
      "Epoch 4791, Loss: 6.9783547473889485e-06, Final Batch Loss: 6.175387170515023e-06\n",
      "Epoch 4792, Loss: 1.0822519925568486e-05, Final Batch Loss: 9.847914952842984e-06\n",
      "Epoch 4793, Loss: 1.3455727838618259e-06, Final Batch Loss: 1.4355411792621453e-07\n",
      "Epoch 4794, Loss: 1.4965187347115716e-06, Final Batch Loss: 1.1021811587852426e-06\n",
      "Epoch 4795, Loss: 6.233846931991138e-07, Final Batch Loss: 4.0547220692133124e-07\n",
      "Epoch 4796, Loss: 2.3402728288601793e-05, Final Batch Loss: 3.9539543195132865e-07\n",
      "Epoch 4797, Loss: 7.309013653866714e-06, Final Batch Loss: 1.9885742403857876e-06\n",
      "Epoch 4798, Loss: 3.29635369666903e-06, Final Batch Loss: 3.154256773996167e-06\n",
      "Epoch 4799, Loss: 1.79694478674719e-06, Final Batch Loss: 8.142775982378225e-07\n",
      "Epoch 4800, Loss: 4.137554753924633e-06, Final Batch Loss: 4.726310294245195e-07\n",
      "Epoch 4801, Loss: 2.2731357937288976e-05, Final Batch Loss: 9.570282344384395e-08\n",
      "Epoch 4802, Loss: 7.301408686544164e-07, Final Batch Loss: 7.144052460716921e-07\n",
      "Epoch 4803, Loss: 0.00025771979287725344, Final Batch Loss: 8.311051402642988e-08\n",
      "Epoch 4804, Loss: 0.00011105365058483585, Final Batch Loss: 2.7199359919904964e-07\n",
      "Epoch 4805, Loss: 0.0002570198630564846, Final Batch Loss: 0.0002047249727183953\n",
      "Epoch 4806, Loss: 8.417617209488526e-06, Final Batch Loss: 4.903537501377286e-06\n",
      "Epoch 4807, Loss: 0.00010307491527328239, Final Batch Loss: 1.396026959810115e-06\n",
      "Epoch 4808, Loss: 3.722830470564986e-07, Final Batch Loss: 3.945655890902344e-08\n",
      "Epoch 4809, Loss: 1.3858172565051063e-06, Final Batch Loss: 1.1273754125795676e-06\n",
      "Epoch 4810, Loss: 1.3673758303411887e-05, Final Batch Loss: 9.869711902865674e-06\n",
      "Epoch 4811, Loss: 1.931142108446693e-05, Final Batch Loss: 2.6108139650204976e-07\n",
      "Epoch 4812, Loss: 5.295999784493688e-06, Final Batch Loss: 5.008471816836391e-06\n",
      "Epoch 4813, Loss: 3.370017338966136e-06, Final Batch Loss: 3.72730937669985e-07\n",
      "Epoch 4814, Loss: 1.0150912203243934e-05, Final Batch Loss: 2.0541529011097737e-06\n",
      "Epoch 4815, Loss: 2.362988510640207e-06, Final Batch Loss: 3.5006800658266e-07\n",
      "Epoch 4816, Loss: 3.185115460269117e-07, Final Batch Loss: 1.7629524506901362e-08\n",
      "Epoch 4817, Loss: 7.506659756018053e-07, Final Batch Loss: 2.4429377276646846e-07\n",
      "Epoch 4818, Loss: 3.641845091806317e-05, Final Batch Loss: 3.389640187378973e-05\n",
      "Epoch 4819, Loss: 6.580443125514535e-06, Final Batch Loss: 6.558508630405413e-06\n",
      "Epoch 4820, Loss: 9.900011377794726e-06, Final Batch Loss: 9.425095413462259e-06\n",
      "Epoch 4821, Loss: 1.717543547385958e-07, Final Batch Loss: 5.5407017640618506e-08\n",
      "Epoch 4822, Loss: 1.6283560633212346e-07, Final Batch Loss: 1.930853166243196e-08\n",
      "Epoch 4823, Loss: 3.2351407753594685e-05, Final Batch Loss: 2.0896948626614176e-05\n",
      "Epoch 4824, Loss: 2.837405077116273e-06, Final Batch Loss: 1.4161232684273273e-06\n",
      "Epoch 4825, Loss: 3.0629999514530937e-06, Final Batch Loss: 5.3055811122249e-07\n",
      "Epoch 4826, Loss: 2.4726334487468193e-05, Final Batch Loss: 3.0641447779089503e-07\n",
      "Epoch 4827, Loss: 1.1390085262519278e-05, Final Batch Loss: 4.5247833213579725e-07\n",
      "Epoch 4828, Loss: 9.495377639723301e-07, Final Batch Loss: 2.0903513586745248e-07\n",
      "Epoch 4829, Loss: 1.6693523612332228e-06, Final Batch Loss: 5.792556478922961e-08\n",
      "Epoch 4830, Loss: 1.4706690393273547e-06, Final Batch Loss: 1.6790039358838271e-09\n",
      "Epoch 4831, Loss: 2.4773636368990992e-06, Final Batch Loss: 1.5957153891577036e-06\n",
      "Epoch 4832, Loss: 3.4957748198394256e-06, Final Batch Loss: 6.908865657351271e-07\n",
      "Epoch 4833, Loss: 2.959275832381536e-06, Final Batch Loss: 2.377084911131533e-06\n",
      "Epoch 4834, Loss: 0.00560693309466842, Final Batch Loss: 0.005605575628578663\n",
      "Epoch 4835, Loss: 8.287958280561725e-06, Final Batch Loss: 6.839985417173011e-06\n",
      "Epoch 4836, Loss: 6.782486195788806e-06, Final Batch Loss: 5.979515208309749e-06\n",
      "Epoch 4837, Loss: 0.0017672315793433313, Final Batch Loss: 5.037005479380241e-08\n",
      "Epoch 4838, Loss: 9.797765230246114e-07, Final Batch Loss: 8.805948255030671e-07\n",
      "Epoch 4839, Loss: 3.43572644823098e-06, Final Batch Loss: 7.555507153256258e-08\n",
      "Epoch 4840, Loss: 9.57274960455834e-05, Final Batch Loss: 8.552276995033026e-05\n",
      "Epoch 4841, Loss: 2.2845981675345683e-06, Final Batch Loss: 6.573080781890894e-07\n",
      "Epoch 4842, Loss: 3.7029647046438185e-06, Final Batch Loss: 2.8280121568968752e-06\n",
      "Epoch 4843, Loss: 3.054682838410372e-05, Final Batch Loss: 1.0988378562615253e-06\n",
      "Epoch 4844, Loss: 2.460946845417311e-05, Final Batch Loss: 3.6769299072147987e-07\n",
      "Epoch 4845, Loss: 4.1273476199421566e-05, Final Batch Loss: 2.829412005667109e-05\n",
      "Epoch 4846, Loss: 8.463623771604034e-06, Final Batch Loss: 5.989429610053776e-06\n",
      "Epoch 4847, Loss: 3.9058841139194556e-05, Final Batch Loss: 8.036533472477458e-06\n",
      "Epoch 4848, Loss: 7.440316500151312e-05, Final Batch Loss: 7.413232378894463e-05\n",
      "Epoch 4849, Loss: 0.00017671953537501395, Final Batch Loss: 0.0001315061963396147\n",
      "Epoch 4850, Loss: 3.957236799578823e-06, Final Batch Loss: 8.134501285894657e-07\n",
      "Epoch 4851, Loss: 9.088025720416226e-06, Final Batch Loss: 1.8384976385732443e-07\n",
      "Epoch 4852, Loss: 9.270249792336926e-05, Final Batch Loss: 9.259187208954245e-05\n",
      "Epoch 4853, Loss: 0.0008098753239522694, Final Batch Loss: 1.0157940266708465e-07\n",
      "Epoch 4854, Loss: 3.282251100245048e-05, Final Batch Loss: 3.621984888013685e-06\n",
      "Epoch 4855, Loss: 0.0021292026472110592, Final Batch Loss: 3.2716748137318064e-06\n",
      "Epoch 4856, Loss: 6.049163303600835e-07, Final Batch Loss: 7.135739821251263e-08\n",
      "Epoch 4857, Loss: 0.00017619576374272583, Final Batch Loss: 0.0001613143685972318\n",
      "Epoch 4858, Loss: 7.662622010684572e-06, Final Batch Loss: 6.8639401433756575e-06\n",
      "Epoch 4859, Loss: 0.008411147049628198, Final Batch Loss: 0.007739502936601639\n",
      "Epoch 4860, Loss: 6.08102729984239e-05, Final Batch Loss: 4.7430353333766107e-07\n",
      "Epoch 4861, Loss: 1.846973173158517e-05, Final Batch Loss: 3.6098573019671676e-08\n",
      "Epoch 4862, Loss: 0.004307057429059569, Final Batch Loss: 0.004305735230445862\n",
      "Epoch 4863, Loss: 5.784718098311714e-06, Final Batch Loss: 7.093547651493282e-07\n",
      "Epoch 4864, Loss: 3.783066858886741e-06, Final Batch Loss: 4.121836809645174e-07\n",
      "Epoch 4865, Loss: 1.403768430918717e-05, Final Batch Loss: 1.5588058204230038e-06\n",
      "Epoch 4866, Loss: 5.003395433789137e-05, Final Batch Loss: 1.8301086868177663e-07\n",
      "Epoch 4867, Loss: 1.6895105545700062e-05, Final Batch Loss: 1.0561341696302406e-05\n",
      "Epoch 4868, Loss: 1.7274660649491125e-05, Final Batch Loss: 1.501613405707758e-05\n",
      "Epoch 4869, Loss: 7.486410936508037e-06, Final Batch Loss: 1.5302483689083601e-06\n",
      "Epoch 4870, Loss: 3.274898608651711e-05, Final Batch Loss: 3.9949145502760075e-06\n",
      "Epoch 4871, Loss: 0.00041827128711702244, Final Batch Loss: 0.00041507722926326096\n",
      "Epoch 4872, Loss: 0.00025207280850736424, Final Batch Loss: 1.344076736131683e-05\n",
      "Epoch 4873, Loss: 7.68183564048286e-06, Final Batch Loss: 1.435542884564711e-07\n",
      "Epoch 4874, Loss: 3.662192830233835e-05, Final Batch Loss: 1.2511041859397665e-05\n",
      "Epoch 4875, Loss: 2.7120976938022068e-05, Final Batch Loss: 3.96639870814397e-06\n",
      "Epoch 4876, Loss: 4.807786467608821e-06, Final Batch Loss: 3.425121803957154e-07\n",
      "Epoch 4877, Loss: 3.768063470488414e-05, Final Batch Loss: 2.8570540962391533e-05\n",
      "Epoch 4878, Loss: 4.897275061921391e-06, Final Batch Loss: 3.153602847305592e-06\n",
      "Epoch 4879, Loss: 3.245380769811845e-05, Final Batch Loss: 8.143154417439291e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4880, Loss: 3.1066866768014734e-05, Final Batch Loss: 2.6660284220270114e-06\n",
      "Epoch 4881, Loss: 2.2462982940396614e-07, Final Batch Loss: 6.632052418353851e-08\n",
      "Epoch 4882, Loss: 1.5195502783171833e-05, Final Batch Loss: 8.38532650959678e-06\n",
      "Epoch 4883, Loss: 6.478162038803248e-06, Final Batch Loss: 4.029606159861032e-08\n",
      "Epoch 4884, Loss: 2.219167015482526e-06, Final Batch Loss: 1.5764164800202707e-06\n",
      "Epoch 4885, Loss: 6.54673447542109e-06, Final Batch Loss: 6.448983185691759e-06\n",
      "Epoch 4886, Loss: 0.0001957249103305969, Final Batch Loss: 1.5111030648995438e-08\n",
      "Epoch 4887, Loss: 4.605397577961412e-06, Final Batch Loss: 2.8794346462746034e-07\n",
      "Epoch 4888, Loss: 4.091419327778567e-06, Final Batch Loss: 2.936096962002921e-06\n",
      "Epoch 4889, Loss: 1.2377506720895326e-05, Final Batch Loss: 9.292994604948035e-07\n",
      "Epoch 4890, Loss: 1.4574646126419566e-05, Final Batch Loss: 3.861704200858185e-08\n",
      "Epoch 4891, Loss: 7.135627038223902e-05, Final Batch Loss: 8.89821421878878e-07\n",
      "Epoch 4892, Loss: 0.0001004947189358063, Final Batch Loss: 4.864010406890884e-05\n",
      "Epoch 4893, Loss: 1.7887464309751522e-05, Final Batch Loss: 6.499783012259286e-06\n",
      "Epoch 4894, Loss: 1.4822597336205945e-06, Final Batch Loss: 9.41060250170267e-07\n",
      "Epoch 4895, Loss: 7.539690841440461e-06, Final Batch Loss: 4.03149715566542e-06\n",
      "Epoch 4896, Loss: 7.195070566012873e-06, Final Batch Loss: 5.682626579073258e-06\n",
      "Epoch 4897, Loss: 1.4534522961184848e-05, Final Batch Loss: 5.237445293460041e-06\n",
      "Epoch 4898, Loss: 8.700424587004818e-05, Final Batch Loss: 5.5746830184943974e-05\n",
      "Epoch 4899, Loss: 1.4113848578745092e-06, Final Batch Loss: 8.797439363661397e-07\n",
      "Epoch 4900, Loss: 1.7722424274779769e-06, Final Batch Loss: 1.3674203955815756e-06\n",
      "Epoch 4901, Loss: 6.02006010126388e-05, Final Batch Loss: 6.0099511756561697e-05\n",
      "Epoch 4902, Loss: 0.0003165349698974751, Final Batch Loss: 0.0003098627203144133\n",
      "Epoch 4903, Loss: 1.654273390272465e-06, Final Batch Loss: 1.4816614566370845e-06\n",
      "Epoch 4904, Loss: 4.990684146832791e-05, Final Batch Loss: 4.8822155804373324e-05\n",
      "Epoch 4905, Loss: 0.0012751901194860693, Final Batch Loss: 0.0012403529835864902\n",
      "Epoch 4906, Loss: 2.2437791926677164e-06, Final Batch Loss: 6.741024094480963e-07\n",
      "Epoch 4907, Loss: 6.51925302008749e-06, Final Batch Loss: 4.928694124828326e-06\n",
      "Epoch 4908, Loss: 1.9170956875314005e-05, Final Batch Loss: 1.2707372661679983e-05\n",
      "Epoch 4909, Loss: 7.882884318632932e-07, Final Batch Loss: 5.708517392122303e-07\n",
      "Epoch 4910, Loss: 9.494924412578598e-05, Final Batch Loss: 1.9308540544216157e-08\n",
      "Epoch 4911, Loss: 4.5445706291502574e-06, Final Batch Loss: 2.5878011911117937e-06\n",
      "Epoch 4912, Loss: 2.536610654857441e-07, Final Batch Loss: 1.7629540494112916e-08\n",
      "Epoch 4913, Loss: 3.105864323060814e-06, Final Batch Loss: 2.3872876226960216e-06\n",
      "Epoch 4914, Loss: 1.997253525587439e-05, Final Batch Loss: 1.7225411284016445e-05\n",
      "Epoch 4915, Loss: 6.411762214497685e-07, Final Batch Loss: 7.471557950111674e-08\n",
      "Epoch 4916, Loss: 7.518697486830206e-07, Final Batch Loss: 4.4240465513212257e-07\n",
      "Epoch 4917, Loss: 1.3566390180130838e-06, Final Batch Loss: 5.003278715776105e-07\n",
      "Epoch 4918, Loss: 3.0445063998740807e-06, Final Batch Loss: 2.8070437565475004e-06\n",
      "Epoch 4919, Loss: 1.7201955380130585e-06, Final Batch Loss: 4.617254134586801e-08\n",
      "Epoch 4920, Loss: 0.00018141422521011918, Final Batch Loss: 0.00018105327035300434\n",
      "Epoch 4921, Loss: 1.757824941783781e-05, Final Batch Loss: 1.2592527909305318e-08\n",
      "Epoch 4922, Loss: 2.435862063521199e-05, Final Batch Loss: 1.8485085320207872e-06\n",
      "Epoch 4923, Loss: 0.01888490523924702, Final Batch Loss: 2.416278948658146e-05\n",
      "Epoch 4924, Loss: 2.365375536328429e-06, Final Batch Loss: 1.5530636687799415e-07\n",
      "Epoch 4925, Loss: 2.9077183398840134e-06, Final Batch Loss: 4.12184249398706e-07\n",
      "Epoch 4926, Loss: 1.6500030426414014e-06, Final Batch Loss: 4.5416359739647305e-07\n",
      "Epoch 4927, Loss: 9.774267823559057e-06, Final Batch Loss: 9.030426554090809e-06\n",
      "Epoch 4928, Loss: 3.766944655581028e-05, Final Batch Loss: 6.369542916218052e-06\n",
      "Epoch 4929, Loss: 4.610651984648939e-07, Final Batch Loss: 2.5268894887631177e-07\n",
      "Epoch 4930, Loss: 2.929898869297176e-06, Final Batch Loss: 1.465702553105075e-06\n",
      "Epoch 4931, Loss: 7.783887241430421e-07, Final Batch Loss: 1.737760300102309e-07\n",
      "Epoch 4932, Loss: 0.0002090606685669627, Final Batch Loss: 0.00018853778601624072\n",
      "Epoch 4933, Loss: 2.8282767061682534e-05, Final Batch Loss: 2.420042847006698e-06\n",
      "Epoch 4934, Loss: 3.7027891721663764e-06, Final Batch Loss: 2.6962150059262058e-06\n",
      "Epoch 4935, Loss: 3.132857710852477e-05, Final Batch Loss: 9.502917350800999e-07\n",
      "Epoch 4936, Loss: 9.208507071889471e-05, Final Batch Loss: 1.77562815224519e-05\n",
      "Epoch 4937, Loss: 0.00010157894030271564, Final Batch Loss: 2.5464805730734952e-05\n",
      "Epoch 4938, Loss: 0.00011427468962210696, Final Batch Loss: 8.433443144895136e-05\n",
      "Epoch 4939, Loss: 0.00019556459301384166, Final Batch Loss: 3.741621185326949e-05\n",
      "Epoch 4940, Loss: 5.589085070312194e-06, Final Batch Loss: 9.234465636609457e-08\n",
      "Epoch 4941, Loss: 3.57816788891796e-05, Final Batch Loss: 1.2168031389592215e-05\n",
      "Epoch 4942, Loss: 1.0974260476359632e-05, Final Batch Loss: 9.549610695103183e-06\n",
      "Epoch 4943, Loss: 4.231271532262326e-06, Final Batch Loss: 2.72030456471839e-06\n",
      "Epoch 4944, Loss: 3.7705378417740576e-05, Final Batch Loss: 1.632455678191036e-05\n",
      "Epoch 4945, Loss: 6.734337746649999e-05, Final Batch Loss: 6.725230196025223e-05\n",
      "Epoch 4946, Loss: 9.41425099654225e-07, Final Batch Loss: 5.456652729662892e-07\n",
      "Epoch 4947, Loss: 6.656237246716046e-06, Final Batch Loss: 6.065950401534792e-06\n",
      "Epoch 4948, Loss: 0.00011537993850652128, Final Batch Loss: 3.3249452826566994e-06\n",
      "Epoch 4949, Loss: 4.064350969201769e-05, Final Batch Loss: 3.518370431265794e-05\n",
      "Epoch 4950, Loss: 2.5925693080353085e-05, Final Batch Loss: 1.5619714758940972e-05\n",
      "Epoch 4951, Loss: 7.16808826837223e-05, Final Batch Loss: 4.000633998657577e-05\n",
      "Epoch 4952, Loss: 6.527455639115942e-06, Final Batch Loss: 5.536623575608246e-06\n",
      "Epoch 4953, Loss: 1.776099935568709e-06, Final Batch Loss: 1.3321712231118e-06\n",
      "Epoch 4954, Loss: 0.000406831130021601, Final Batch Loss: 0.0003814726951532066\n",
      "Epoch 4955, Loss: 4.321817323216237e-05, Final Batch Loss: 3.5758595913648605e-05\n",
      "Epoch 4956, Loss: 4.76805449522999e-06, Final Batch Loss: 1.242454885641564e-07\n",
      "Epoch 4957, Loss: 2.9258898393891286e-05, Final Batch Loss: 2.7253583539277315e-05\n",
      "Epoch 4958, Loss: 3.743916259679736e-06, Final Batch Loss: 8.478942703504799e-08\n",
      "Epoch 4959, Loss: 4.544776828652175e-06, Final Batch Loss: 1.9308544096929836e-08\n",
      "Epoch 4960, Loss: 1.4834563444310334e-05, Final Batch Loss: 3.962536538892891e-06\n",
      "Epoch 4961, Loss: 3.154923701842449e-06, Final Batch Loss: 2.0987540594319398e-08\n",
      "Epoch 4962, Loss: 2.6912546218227362e-06, Final Batch Loss: 4.869064014201285e-07\n",
      "Epoch 4963, Loss: 8.147960056703596e-05, Final Batch Loss: 7.798118895152584e-05\n",
      "Epoch 4964, Loss: 3.5146612731296045e-07, Final Batch Loss: 6.632058102695737e-08\n",
      "Epoch 4965, Loss: 0.0023293721314985305, Final Batch Loss: 0.0001682280853856355\n",
      "Epoch 4966, Loss: 4.9851733933792275e-05, Final Batch Loss: 2.661191729202983e-07\n",
      "Epoch 4967, Loss: 9.961942072322927e-05, Final Batch Loss: 8.780911571193428e-07\n",
      "Epoch 4968, Loss: 5.04956437907822e-06, Final Batch Loss: 3.7020986383140553e-06\n",
      "Epoch 4969, Loss: 3.6018664445691684e-05, Final Batch Loss: 3.461351661826484e-05\n",
      "Epoch 4970, Loss: 0.00014626550273533212, Final Batch Loss: 1.0412329174869228e-05\n",
      "Epoch 4971, Loss: 1.9182644450665975e-06, Final Batch Loss: 6.027531185281987e-07\n",
      "Epoch 4972, Loss: 1.4812491826887708e-05, Final Batch Loss: 2.4115806809277274e-06\n",
      "Epoch 4973, Loss: 9.687570548067015e-05, Final Batch Loss: 7.060122015900561e-07\n",
      "Epoch 4974, Loss: 1.2228501153899174e-06, Final Batch Loss: 8.395018902263018e-09\n",
      "Epoch 4975, Loss: 7.809281186155204e-07, Final Batch Loss: 1.7965258791718952e-07\n",
      "Epoch 4976, Loss: 0.0009464777358516585, Final Batch Loss: 6.1677237681578845e-06\n",
      "Epoch 4977, Loss: 0.0001237456284570726, Final Batch Loss: 8.209875659304089e-07\n",
      "Epoch 4978, Loss: 3.9138201941568695e-06, Final Batch Loss: 6.304522344180441e-07\n",
      "Epoch 4979, Loss: 4.622638425644254e-05, Final Batch Loss: 3.865817234327551e-06\n",
      "Epoch 4980, Loss: 3.447853345051044e-07, Final Batch Loss: 2.2414586453578522e-07\n",
      "Epoch 4981, Loss: 2.5145357994915685e-05, Final Batch Loss: 5.628674898616737e-06\n",
      "Epoch 4982, Loss: 1.8153490088934632e-06, Final Batch Loss: 1.510182642050495e-06\n",
      "Epoch 4983, Loss: 1.0690854423955898e-05, Final Batch Loss: 1.4833219665888464e-06\n",
      "Epoch 4984, Loss: 7.347347855102271e-05, Final Batch Loss: 6.479848525486887e-05\n",
      "Epoch 4985, Loss: 0.0004631416263407573, Final Batch Loss: 9.150559776571754e-08\n",
      "Epoch 4986, Loss: 8.50717884190999e-05, Final Batch Loss: 8.435846393695101e-05\n",
      "Epoch 4987, Loss: 4.592758419263987e-05, Final Batch Loss: 3.7777549977136005e-08\n",
      "Epoch 4988, Loss: 2.392823091668106e-06, Final Batch Loss: 1.8669002201932017e-06\n",
      "Epoch 4989, Loss: 0.00011646372428231189, Final Batch Loss: 7.362132805610599e-07\n",
      "Epoch 4990, Loss: 3.3343468601287896e-05, Final Batch Loss: 3.282706893514842e-05\n",
      "Epoch 4991, Loss: 1.4154663404042367e-05, Final Batch Loss: 1.9357612472958863e-06\n",
      "Epoch 4992, Loss: 0.00016366120689781383, Final Batch Loss: 0.00015991172404028475\n",
      "Epoch 4993, Loss: 1.052316201821668e-05, Final Batch Loss: 9.47846274357289e-06\n",
      "Epoch 4994, Loss: 6.702404974134879e-06, Final Batch Loss: 5.540705672046897e-08\n",
      "Epoch 4995, Loss: 4.754479192570216e-06, Final Batch Loss: 4.547056505543878e-06\n",
      "Epoch 4996, Loss: 0.0015583793674238677, Final Batch Loss: 3.811246358509379e-07\n",
      "Epoch 4997, Loss: 4.4101477669755695e-06, Final Batch Loss: 3.009380179719301e-06\n",
      "Epoch 4998, Loss: 0.0030986593734780854, Final Batch Loss: 3.7105533579051553e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4999, Loss: 7.953507520142011e-05, Final Batch Loss: 4.429512046044692e-06\n",
      "Epoch 5000, Loss: 1.959079847324574e-05, Final Batch Loss: 3.5930199260292284e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  0  0]\n",
      " [ 0 22  0]\n",
      " [ 0  0 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        26\n",
      "           1    1.00000   1.00000   1.00000        22\n",
      "           2    1.00000   1.00000   1.00000        50\n",
      "\n",
      "    accuracy                        1.00000        98\n",
      "   macro avg    1.00000   1.00000   1.00000        98\n",
      "weighted avg    1.00000   1.00000   1.00000        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=106, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=46, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 106)\n",
    "load_model(gen, \"cGAN_UCI_Group_4_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 3)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0  0]\n",
      " [ 0 35  0]\n",
      " [ 0  0 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        29\n",
      "           1    1.00000   1.00000   1.00000        35\n",
      "           2    1.00000   1.00000   1.00000        34\n",
      "\n",
      "    accuracy                        1.00000        98\n",
      "   macro avg    1.00000   1.00000   1.00000        98\n",
      "weighted avg    1.00000   1.00000   1.00000        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [19, 21, 22]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 19:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 21:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.270096182823181, Final Batch Loss: 1.1665412187576294\n",
      "Epoch 2, Loss: 2.2482686042785645, Final Batch Loss: 1.1237142086029053\n",
      "Epoch 3, Loss: 2.240135908126831, Final Batch Loss: 1.10916268825531\n",
      "Epoch 4, Loss: 2.2325645685195923, Final Batch Loss: 1.1011220216751099\n",
      "Epoch 5, Loss: 2.2406163215637207, Final Batch Loss: 1.1276978254318237\n",
      "Epoch 6, Loss: 2.230108141899109, Final Batch Loss: 1.1111730337142944\n",
      "Epoch 7, Loss: 2.228450655937195, Final Batch Loss: 1.1145827770233154\n",
      "Epoch 8, Loss: 2.2274733781814575, Final Batch Loss: 1.1136747598648071\n",
      "Epoch 9, Loss: 2.227184295654297, Final Batch Loss: 1.1220953464508057\n",
      "Epoch 10, Loss: 2.2175889015197754, Final Batch Loss: 1.1107454299926758\n",
      "Epoch 11, Loss: 2.215391755104065, Final Batch Loss: 1.10914945602417\n",
      "Epoch 12, Loss: 2.206649899482727, Final Batch Loss: 1.1027253866195679\n",
      "Epoch 13, Loss: 2.2122647762298584, Final Batch Loss: 1.1220409870147705\n",
      "Epoch 14, Loss: 2.2014150619506836, Final Batch Loss: 1.0990831851959229\n",
      "Epoch 15, Loss: 2.2008553743362427, Final Batch Loss: 1.1081286668777466\n",
      "Epoch 16, Loss: 2.18865430355072, Final Batch Loss: 1.099706768989563\n",
      "Epoch 17, Loss: 2.1836670637130737, Final Batch Loss: 1.0928184986114502\n",
      "Epoch 18, Loss: 2.1787291765213013, Final Batch Loss: 1.08742094039917\n",
      "Epoch 19, Loss: 2.1629369258880615, Final Batch Loss: 1.0668537616729736\n",
      "Epoch 20, Loss: 2.1661912202835083, Final Batch Loss: 1.091905951499939\n",
      "Epoch 21, Loss: 2.1522955894470215, Final Batch Loss: 1.0740079879760742\n",
      "Epoch 22, Loss: 2.1465461254119873, Final Batch Loss: 1.0666909217834473\n",
      "Epoch 23, Loss: 2.140283226966858, Final Batch Loss: 1.0679585933685303\n",
      "Epoch 24, Loss: 2.1268415451049805, Final Batch Loss: 1.0609359741210938\n",
      "Epoch 25, Loss: 2.1347936391830444, Final Batch Loss: 1.0777400732040405\n",
      "Epoch 26, Loss: 2.1219252347946167, Final Batch Loss: 1.0685789585113525\n",
      "Epoch 27, Loss: 2.0925700664520264, Final Batch Loss: 1.0348894596099854\n",
      "Epoch 28, Loss: 2.101924419403076, Final Batch Loss: 1.0613702535629272\n",
      "Epoch 29, Loss: 2.083238363265991, Final Batch Loss: 1.0517657995224\n",
      "Epoch 30, Loss: 2.074134349822998, Final Batch Loss: 1.0293759107589722\n",
      "Epoch 31, Loss: 2.051305055618286, Final Batch Loss: 0.9964325428009033\n",
      "Epoch 32, Loss: 2.044482707977295, Final Batch Loss: 1.0129997730255127\n",
      "Epoch 33, Loss: 2.0494816303253174, Final Batch Loss: 1.0251126289367676\n",
      "Epoch 34, Loss: 2.0291436910629272, Final Batch Loss: 1.0079641342163086\n",
      "Epoch 35, Loss: 2.0172238945961, Final Batch Loss: 1.0253663063049316\n",
      "Epoch 36, Loss: 2.001479208469391, Final Batch Loss: 1.0181190967559814\n",
      "Epoch 37, Loss: 1.949423611164093, Final Batch Loss: 0.9590765833854675\n",
      "Epoch 38, Loss: 1.9587087035179138, Final Batch Loss: 1.0061101913452148\n",
      "Epoch 39, Loss: 1.9581785798072815, Final Batch Loss: 0.9760497212409973\n",
      "Epoch 40, Loss: 1.9207422137260437, Final Batch Loss: 0.9805672764778137\n",
      "Epoch 41, Loss: 1.847938358783722, Final Batch Loss: 0.9061341881752014\n",
      "Epoch 42, Loss: 1.8714189529418945, Final Batch Loss: 0.9120725393295288\n",
      "Epoch 43, Loss: 1.8511613011360168, Final Batch Loss: 0.9216273427009583\n",
      "Epoch 44, Loss: 1.8223493099212646, Final Batch Loss: 0.9047951698303223\n",
      "Epoch 45, Loss: 1.8189043998718262, Final Batch Loss: 0.923169732093811\n",
      "Epoch 46, Loss: 1.7785956859588623, Final Batch Loss: 0.864077091217041\n",
      "Epoch 47, Loss: 1.709532618522644, Final Batch Loss: 0.8398098349571228\n",
      "Epoch 48, Loss: 1.7408615946769714, Final Batch Loss: 0.8736189603805542\n",
      "Epoch 49, Loss: 1.7721084356307983, Final Batch Loss: 0.9191650748252869\n",
      "Epoch 50, Loss: 1.6738983392715454, Final Batch Loss: 0.7982474565505981\n",
      "Epoch 51, Loss: 1.6748602390289307, Final Batch Loss: 0.8373907208442688\n",
      "Epoch 52, Loss: 1.6404075026512146, Final Batch Loss: 0.8507019281387329\n",
      "Epoch 53, Loss: 1.6164653897285461, Final Batch Loss: 0.8108377456665039\n",
      "Epoch 54, Loss: 1.6180757284164429, Final Batch Loss: 0.8127410411834717\n",
      "Epoch 55, Loss: 1.5957509875297546, Final Batch Loss: 0.7611851692199707\n",
      "Epoch 56, Loss: 1.6017324924468994, Final Batch Loss: 0.8284559845924377\n",
      "Epoch 57, Loss: 1.5090230703353882, Final Batch Loss: 0.7255290150642395\n",
      "Epoch 58, Loss: 1.563010811805725, Final Batch Loss: 0.809420645236969\n",
      "Epoch 59, Loss: 1.5235639810562134, Final Batch Loss: 0.7533851861953735\n",
      "Epoch 60, Loss: 1.4891744256019592, Final Batch Loss: 0.7639984488487244\n",
      "Epoch 61, Loss: 1.4477723836898804, Final Batch Loss: 0.7141240835189819\n",
      "Epoch 62, Loss: 1.5029066801071167, Final Batch Loss: 0.72733074426651\n",
      "Epoch 63, Loss: 1.422675609588623, Final Batch Loss: 0.7001838684082031\n",
      "Epoch 64, Loss: 1.386420488357544, Final Batch Loss: 0.7106676697731018\n",
      "Epoch 65, Loss: 1.3750710487365723, Final Batch Loss: 0.6932184100151062\n",
      "Epoch 66, Loss: 1.4074842929840088, Final Batch Loss: 0.6621155142784119\n",
      "Epoch 67, Loss: 1.375414490699768, Final Batch Loss: 0.6858423948287964\n",
      "Epoch 68, Loss: 1.383986473083496, Final Batch Loss: 0.7273499369621277\n",
      "Epoch 69, Loss: 1.3660091757774353, Final Batch Loss: 0.7368515729904175\n",
      "Epoch 70, Loss: 1.3318137526512146, Final Batch Loss: 0.6674519777297974\n",
      "Epoch 71, Loss: 1.378028392791748, Final Batch Loss: 0.7080914974212646\n",
      "Epoch 72, Loss: 1.3068828582763672, Final Batch Loss: 0.64299476146698\n",
      "Epoch 73, Loss: 1.2027862071990967, Final Batch Loss: 0.5514359474182129\n",
      "Epoch 74, Loss: 1.2729116082191467, Final Batch Loss: 0.6500018835067749\n",
      "Epoch 75, Loss: 1.2768940329551697, Final Batch Loss: 0.6737082600593567\n",
      "Epoch 76, Loss: 1.2348674535751343, Final Batch Loss: 0.6085031032562256\n",
      "Epoch 77, Loss: 1.210289180278778, Final Batch Loss: 0.624868631362915\n",
      "Epoch 78, Loss: 1.1970557570457458, Final Batch Loss: 0.593903660774231\n",
      "Epoch 79, Loss: 1.2010801434516907, Final Batch Loss: 0.6125099062919617\n",
      "Epoch 80, Loss: 1.1386972069740295, Final Batch Loss: 0.5215878486633301\n",
      "Epoch 81, Loss: 1.0998560190200806, Final Batch Loss: 0.5186189413070679\n",
      "Epoch 82, Loss: 1.1157228350639343, Final Batch Loss: 0.5281134843826294\n",
      "Epoch 83, Loss: 1.1466143727302551, Final Batch Loss: 0.5758668184280396\n",
      "Epoch 84, Loss: 1.1531673073768616, Final Batch Loss: 0.5824916362762451\n",
      "Epoch 85, Loss: 1.0817105770111084, Final Batch Loss: 0.5397993326187134\n",
      "Epoch 86, Loss: 1.069715827703476, Final Batch Loss: 0.49034538865089417\n",
      "Epoch 87, Loss: 1.0677756071090698, Final Batch Loss: 0.4877609610557556\n",
      "Epoch 88, Loss: 1.0134862065315247, Final Batch Loss: 0.5243157148361206\n",
      "Epoch 89, Loss: 1.0850982069969177, Final Batch Loss: 0.5407085418701172\n",
      "Epoch 90, Loss: 1.0133553445339203, Final Batch Loss: 0.47716769576072693\n",
      "Epoch 91, Loss: 1.0128090977668762, Final Batch Loss: 0.5278840661048889\n",
      "Epoch 92, Loss: 1.0060362219810486, Final Batch Loss: 0.4928458333015442\n",
      "Epoch 93, Loss: 1.0466456413269043, Final Batch Loss: 0.5450132489204407\n",
      "Epoch 94, Loss: 1.0042781233787537, Final Batch Loss: 0.5355619788169861\n",
      "Epoch 95, Loss: 0.9833627641201019, Final Batch Loss: 0.4698544442653656\n",
      "Epoch 96, Loss: 0.9665990471839905, Final Batch Loss: 0.47383913397789\n",
      "Epoch 97, Loss: 1.0139914751052856, Final Batch Loss: 0.5336694717407227\n",
      "Epoch 98, Loss: 0.9750596284866333, Final Batch Loss: 0.4840013086795807\n",
      "Epoch 99, Loss: 0.8913415372371674, Final Batch Loss: 0.41491928696632385\n",
      "Epoch 100, Loss: 0.9588310420513153, Final Batch Loss: 0.4968508183956146\n",
      "Epoch 101, Loss: 0.9366314113140106, Final Batch Loss: 0.5029944181442261\n",
      "Epoch 102, Loss: 0.9347064793109894, Final Batch Loss: 0.5311794281005859\n",
      "Epoch 103, Loss: 0.9422344267368317, Final Batch Loss: 0.46555575728416443\n",
      "Epoch 104, Loss: 0.9088398516178131, Final Batch Loss: 0.45194920897483826\n",
      "Epoch 105, Loss: 0.8460134565830231, Final Batch Loss: 0.40483900904655457\n",
      "Epoch 106, Loss: 0.9173233509063721, Final Batch Loss: 0.5081800818443298\n",
      "Epoch 107, Loss: 0.8562237918376923, Final Batch Loss: 0.4036813974380493\n",
      "Epoch 108, Loss: 0.8359604477882385, Final Batch Loss: 0.4027339220046997\n",
      "Epoch 109, Loss: 0.8930284976959229, Final Batch Loss: 0.4970830976963043\n",
      "Epoch 110, Loss: 0.8499632477760315, Final Batch Loss: 0.4019993245601654\n",
      "Epoch 111, Loss: 0.8124583661556244, Final Batch Loss: 0.38710713386535645\n",
      "Epoch 112, Loss: 0.8447693884372711, Final Batch Loss: 0.4299258291721344\n",
      "Epoch 113, Loss: 0.8915575444698334, Final Batch Loss: 0.4742347300052643\n",
      "Epoch 114, Loss: 0.805700808763504, Final Batch Loss: 0.3245934844017029\n",
      "Epoch 115, Loss: 0.8161095976829529, Final Batch Loss: 0.3835390508174896\n",
      "Epoch 116, Loss: 0.8346992135047913, Final Batch Loss: 0.45360007882118225\n",
      "Epoch 117, Loss: 0.7992608845233917, Final Batch Loss: 0.4132935702800751\n",
      "Epoch 118, Loss: 0.7735002636909485, Final Batch Loss: 0.398305743932724\n",
      "Epoch 119, Loss: 0.7894983887672424, Final Batch Loss: 0.41879814863204956\n",
      "Epoch 120, Loss: 0.7674751877784729, Final Batch Loss: 0.40505513548851013\n",
      "Epoch 121, Loss: 0.7995678782463074, Final Batch Loss: 0.4129822552204132\n",
      "Epoch 122, Loss: 0.7174429595470428, Final Batch Loss: 0.3413753807544708\n",
      "Epoch 123, Loss: 0.8137474060058594, Final Batch Loss: 0.38198208808898926\n",
      "Epoch 124, Loss: 0.7702175974845886, Final Batch Loss: 0.3489589989185333\n",
      "Epoch 125, Loss: 0.7885861396789551, Final Batch Loss: 0.4305606782436371\n",
      "Epoch 126, Loss: 0.7447910606861115, Final Batch Loss: 0.3570069372653961\n",
      "Epoch 127, Loss: 0.7585337162017822, Final Batch Loss: 0.37386220693588257\n",
      "Epoch 128, Loss: 0.700465589761734, Final Batch Loss: 0.33419930934906006\n",
      "Epoch 129, Loss: 0.7529422044754028, Final Batch Loss: 0.4167492687702179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, Loss: 0.7388501167297363, Final Batch Loss: 0.4291132092475891\n",
      "Epoch 131, Loss: 0.7698154151439667, Final Batch Loss: 0.3844447731971741\n",
      "Epoch 132, Loss: 0.6773208677768707, Final Batch Loss: 0.3309447169303894\n",
      "Epoch 133, Loss: 0.7033226490020752, Final Batch Loss: 0.3487284481525421\n",
      "Epoch 134, Loss: 0.6538839638233185, Final Batch Loss: 0.32534587383270264\n",
      "Epoch 135, Loss: 0.7119013071060181, Final Batch Loss: 0.37369370460510254\n",
      "Epoch 136, Loss: 0.714559406042099, Final Batch Loss: 0.3756294548511505\n",
      "Epoch 137, Loss: 0.7037670016288757, Final Batch Loss: 0.3615438640117645\n",
      "Epoch 138, Loss: 0.6591955125331879, Final Batch Loss: 0.31368136405944824\n",
      "Epoch 139, Loss: 0.6977545619010925, Final Batch Loss: 0.3410018980503082\n",
      "Epoch 140, Loss: 0.6447707712650299, Final Batch Loss: 0.3697665333747864\n",
      "Epoch 141, Loss: 0.6207889914512634, Final Batch Loss: 0.2618025839328766\n",
      "Epoch 142, Loss: 0.6109337210655212, Final Batch Loss: 0.28306183218955994\n",
      "Epoch 143, Loss: 0.6477198898792267, Final Batch Loss: 0.28241634368896484\n",
      "Epoch 144, Loss: 0.6372728645801544, Final Batch Loss: 0.3028140068054199\n",
      "Epoch 145, Loss: 0.6775124371051788, Final Batch Loss: 0.3504432141780853\n",
      "Epoch 146, Loss: 0.6407118737697601, Final Batch Loss: 0.33912336826324463\n",
      "Epoch 147, Loss: 0.6256051659584045, Final Batch Loss: 0.29867637157440186\n",
      "Epoch 148, Loss: 0.6376424431800842, Final Batch Loss: 0.29319167137145996\n",
      "Epoch 149, Loss: 0.6683922111988068, Final Batch Loss: 0.332070916891098\n",
      "Epoch 150, Loss: 0.6614881157875061, Final Batch Loss: 0.3288920223712921\n",
      "Epoch 151, Loss: 0.66238734126091, Final Batch Loss: 0.344354510307312\n",
      "Epoch 152, Loss: 0.594825029373169, Final Batch Loss: 0.29715245962142944\n",
      "Epoch 153, Loss: 0.5919154584407806, Final Batch Loss: 0.25932711362838745\n",
      "Epoch 154, Loss: 0.6099207401275635, Final Batch Loss: 0.3066553771495819\n",
      "Epoch 155, Loss: 0.5899433195590973, Final Batch Loss: 0.2975976765155792\n",
      "Epoch 156, Loss: 0.6419692635536194, Final Batch Loss: 0.33543410897254944\n",
      "Epoch 157, Loss: 0.5877947509288788, Final Batch Loss: 0.2766675353050232\n",
      "Epoch 158, Loss: 0.6159453392028809, Final Batch Loss: 0.2698076367378235\n",
      "Epoch 159, Loss: 0.6021234393119812, Final Batch Loss: 0.26912179589271545\n",
      "Epoch 160, Loss: 0.5585149526596069, Final Batch Loss: 0.2665046453475952\n",
      "Epoch 161, Loss: 0.608478233218193, Final Batch Loss: 0.2439887672662735\n",
      "Epoch 162, Loss: 0.548476979136467, Final Batch Loss: 0.239608034491539\n",
      "Epoch 163, Loss: 0.6411737203598022, Final Batch Loss: 0.31913405656814575\n",
      "Epoch 164, Loss: 0.6000270247459412, Final Batch Loss: 0.29476937651634216\n",
      "Epoch 165, Loss: 0.5885848999023438, Final Batch Loss: 0.24848386645317078\n",
      "Epoch 166, Loss: 0.5882643461227417, Final Batch Loss: 0.3045232892036438\n",
      "Epoch 167, Loss: 0.5801744759082794, Final Batch Loss: 0.31106215715408325\n",
      "Epoch 168, Loss: 0.5702375024557114, Final Batch Loss: 0.23407571017742157\n",
      "Epoch 169, Loss: 0.5629535019397736, Final Batch Loss: 0.2691512703895569\n",
      "Epoch 170, Loss: 0.5714194774627686, Final Batch Loss: 0.2584642171859741\n",
      "Epoch 171, Loss: 0.5417015850543976, Final Batch Loss: 0.24430358409881592\n",
      "Epoch 172, Loss: 0.5557796210050583, Final Batch Loss: 0.232533797621727\n",
      "Epoch 173, Loss: 0.5640865862369537, Final Batch Loss: 0.2652375400066376\n",
      "Epoch 174, Loss: 0.5197246968746185, Final Batch Loss: 0.20844846963882446\n",
      "Epoch 175, Loss: 0.5977524220943451, Final Batch Loss: 0.29376015067100525\n",
      "Epoch 176, Loss: 0.5768333822488785, Final Batch Loss: 0.33404162526130676\n",
      "Epoch 177, Loss: 0.5567000806331635, Final Batch Loss: 0.30015304684638977\n",
      "Epoch 178, Loss: 0.5748410522937775, Final Batch Loss: 0.30142197012901306\n",
      "Epoch 179, Loss: 0.5131200402975082, Final Batch Loss: 0.2309427410364151\n",
      "Epoch 180, Loss: 0.5701357871294022, Final Batch Loss: 0.24904866516590118\n",
      "Epoch 181, Loss: 0.6021831035614014, Final Batch Loss: 0.3183431923389435\n",
      "Epoch 182, Loss: 0.558999627828598, Final Batch Loss: 0.2861904203891754\n",
      "Epoch 183, Loss: 0.5332533419132233, Final Batch Loss: 0.25617918372154236\n",
      "Epoch 184, Loss: 0.5788041055202484, Final Batch Loss: 0.2955208718776703\n",
      "Epoch 185, Loss: 0.5135548561811447, Final Batch Loss: 0.2640813887119293\n",
      "Epoch 186, Loss: 0.5666005462408066, Final Batch Loss: 0.33295080065727234\n",
      "Epoch 187, Loss: 0.5450087934732437, Final Batch Loss: 0.2103608399629593\n",
      "Epoch 188, Loss: 0.5959455668926239, Final Batch Loss: 0.3449839949607849\n",
      "Epoch 189, Loss: 0.5031439363956451, Final Batch Loss: 0.23140117526054382\n",
      "Epoch 190, Loss: 0.5187129974365234, Final Batch Loss: 0.22385475039482117\n",
      "Epoch 191, Loss: 0.4718059152364731, Final Batch Loss: 0.21928752958774567\n",
      "Epoch 192, Loss: 0.5319913029670715, Final Batch Loss: 0.26192528009414673\n",
      "Epoch 193, Loss: 0.5440042018890381, Final Batch Loss: 0.24047088623046875\n",
      "Epoch 194, Loss: 0.5006211251020432, Final Batch Loss: 0.21265091001987457\n",
      "Epoch 195, Loss: 0.521294116973877, Final Batch Loss: 0.26176777482032776\n",
      "Epoch 196, Loss: 0.5439316034317017, Final Batch Loss: 0.2854633927345276\n",
      "Epoch 197, Loss: 0.5470092743635178, Final Batch Loss: 0.322912335395813\n",
      "Epoch 198, Loss: 0.5392127633094788, Final Batch Loss: 0.2626572847366333\n",
      "Epoch 199, Loss: 0.4925650507211685, Final Batch Loss: 0.24307173490524292\n",
      "Epoch 200, Loss: 0.5268554091453552, Final Batch Loss: 0.25695493817329407\n",
      "Epoch 201, Loss: 0.4805312156677246, Final Batch Loss: 0.2370849996805191\n",
      "Epoch 202, Loss: 0.5303713381290436, Final Batch Loss: 0.2780440151691437\n",
      "Epoch 203, Loss: 0.4598076045513153, Final Batch Loss: 0.19748204946517944\n",
      "Epoch 204, Loss: 0.5655488222837448, Final Batch Loss: 0.3359559178352356\n",
      "Epoch 205, Loss: 0.5491154789924622, Final Batch Loss: 0.28227144479751587\n",
      "Epoch 206, Loss: 0.5048931539058685, Final Batch Loss: 0.25655537843704224\n",
      "Epoch 207, Loss: 0.5123989582061768, Final Batch Loss: 0.27940091490745544\n",
      "Epoch 208, Loss: 0.5601523816585541, Final Batch Loss: 0.30227670073509216\n",
      "Epoch 209, Loss: 0.49449044466018677, Final Batch Loss: 0.2417411506175995\n",
      "Epoch 210, Loss: 0.5081895589828491, Final Batch Loss: 0.27053242921829224\n",
      "Epoch 211, Loss: 0.4980447143316269, Final Batch Loss: 0.270855575799942\n",
      "Epoch 212, Loss: 0.49421729147434235, Final Batch Loss: 0.24367021024227142\n",
      "Epoch 213, Loss: 0.536488264799118, Final Batch Loss: 0.27712589502334595\n",
      "Epoch 214, Loss: 0.5258698761463165, Final Batch Loss: 0.2651429772377014\n",
      "Epoch 215, Loss: 0.5005325675010681, Final Batch Loss: 0.23050501942634583\n",
      "Epoch 216, Loss: 0.4908408969640732, Final Batch Loss: 0.2703970670700073\n",
      "Epoch 217, Loss: 0.49986521899700165, Final Batch Loss: 0.2583298087120056\n",
      "Epoch 218, Loss: 0.48253145813941956, Final Batch Loss: 0.2387802004814148\n",
      "Epoch 219, Loss: 0.5040955543518066, Final Batch Loss: 0.2921350598335266\n",
      "Epoch 220, Loss: 0.5333958566188812, Final Batch Loss: 0.269563227891922\n",
      "Epoch 221, Loss: 0.4876747727394104, Final Batch Loss: 0.21782952547073364\n",
      "Epoch 222, Loss: 0.4396367520093918, Final Batch Loss: 0.19364692270755768\n",
      "Epoch 223, Loss: 0.471004456281662, Final Batch Loss: 0.2593936324119568\n",
      "Epoch 224, Loss: 0.45293013751506805, Final Batch Loss: 0.18615089356899261\n",
      "Epoch 225, Loss: 0.49137361347675323, Final Batch Loss: 0.2606315314769745\n",
      "Epoch 226, Loss: 0.4494294971227646, Final Batch Loss: 0.2154451161623001\n",
      "Epoch 227, Loss: 0.4371069222688675, Final Batch Loss: 0.2010110467672348\n",
      "Epoch 228, Loss: 0.4333917051553726, Final Batch Loss: 0.1988794505596161\n",
      "Epoch 229, Loss: 0.4968773126602173, Final Batch Loss: 0.2996370792388916\n",
      "Epoch 230, Loss: 0.4264669567346573, Final Batch Loss: 0.19169552624225616\n",
      "Epoch 231, Loss: 0.4850600063800812, Final Batch Loss: 0.2531531751155853\n",
      "Epoch 232, Loss: 0.4084133803844452, Final Batch Loss: 0.17288610339164734\n",
      "Epoch 233, Loss: 0.45016662776470184, Final Batch Loss: 0.17077596485614777\n",
      "Epoch 234, Loss: 0.4423897862434387, Final Batch Loss: 0.2029188573360443\n",
      "Epoch 235, Loss: 0.4632851928472519, Final Batch Loss: 0.21328943967819214\n",
      "Epoch 236, Loss: 0.39578279852867126, Final Batch Loss: 0.23095625638961792\n",
      "Epoch 237, Loss: 0.45920343697071075, Final Batch Loss: 0.20129196345806122\n",
      "Epoch 238, Loss: 0.4244251102209091, Final Batch Loss: 0.22380763292312622\n",
      "Epoch 239, Loss: 0.44338417053222656, Final Batch Loss: 0.22339794039726257\n",
      "Epoch 240, Loss: 0.49765293300151825, Final Batch Loss: 0.283465176820755\n",
      "Epoch 241, Loss: 0.40710337460041046, Final Batch Loss: 0.19849997758865356\n",
      "Epoch 242, Loss: 0.4319329112768173, Final Batch Loss: 0.1940629482269287\n",
      "Epoch 243, Loss: 0.3966236263513565, Final Batch Loss: 0.1809612512588501\n",
      "Epoch 244, Loss: 0.43967264890670776, Final Batch Loss: 0.19919957220554352\n",
      "Epoch 245, Loss: 0.39285965263843536, Final Batch Loss: 0.16336528956890106\n",
      "Epoch 246, Loss: 0.4528779834508896, Final Batch Loss: 0.24307245016098022\n",
      "Epoch 247, Loss: 0.4690074622631073, Final Batch Loss: 0.23863717913627625\n",
      "Epoch 248, Loss: 0.4193268120288849, Final Batch Loss: 0.19410233199596405\n",
      "Epoch 249, Loss: 0.4217895120382309, Final Batch Loss: 0.22082175314426422\n",
      "Epoch 250, Loss: 0.42214930057525635, Final Batch Loss: 0.24906830489635468\n",
      "Epoch 251, Loss: 0.4536544382572174, Final Batch Loss: 0.2271585315465927\n",
      "Epoch 252, Loss: 0.4346100091934204, Final Batch Loss: 0.18122825026512146\n",
      "Epoch 253, Loss: 0.4019147455692291, Final Batch Loss: 0.2054315060377121\n",
      "Epoch 254, Loss: 0.5078515708446503, Final Batch Loss: 0.31123146414756775\n",
      "Epoch 255, Loss: 0.38634489476680756, Final Batch Loss: 0.21622055768966675\n",
      "Epoch 256, Loss: 0.4135414659976959, Final Batch Loss: 0.2007550150156021\n",
      "Epoch 257, Loss: 0.401859313249588, Final Batch Loss: 0.19309532642364502\n",
      "Epoch 258, Loss: 0.4174288809299469, Final Batch Loss: 0.19110184907913208\n",
      "Epoch 259, Loss: 0.4166344851255417, Final Batch Loss: 0.1826861947774887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260, Loss: 0.4164801388978958, Final Batch Loss: 0.19164787232875824\n",
      "Epoch 261, Loss: 0.40455567836761475, Final Batch Loss: 0.22333009541034698\n",
      "Epoch 262, Loss: 0.4280407428741455, Final Batch Loss: 0.20310181379318237\n",
      "Epoch 263, Loss: 0.4024953097105026, Final Batch Loss: 0.1784840226173401\n",
      "Epoch 264, Loss: 0.38248685002326965, Final Batch Loss: 0.19443757832050323\n",
      "Epoch 265, Loss: 0.40297017991542816, Final Batch Loss: 0.2203422635793686\n",
      "Epoch 266, Loss: 0.43131062388420105, Final Batch Loss: 0.2378314882516861\n",
      "Epoch 267, Loss: 0.3521045446395874, Final Batch Loss: 0.16527538001537323\n",
      "Epoch 268, Loss: 0.42452412843704224, Final Batch Loss: 0.20869959890842438\n",
      "Epoch 269, Loss: 0.3580933064222336, Final Batch Loss: 0.1901894211769104\n",
      "Epoch 270, Loss: 0.4804292917251587, Final Batch Loss: 0.2783002257347107\n",
      "Epoch 271, Loss: 0.4230298697948456, Final Batch Loss: 0.2054441273212433\n",
      "Epoch 272, Loss: 0.4432087540626526, Final Batch Loss: 0.2317705899477005\n",
      "Epoch 273, Loss: 0.4291476607322693, Final Batch Loss: 0.242245152592659\n",
      "Epoch 274, Loss: 0.40301513671875, Final Batch Loss: 0.19222718477249146\n",
      "Epoch 275, Loss: 0.3735325038433075, Final Batch Loss: 0.19942030310630798\n",
      "Epoch 276, Loss: 0.43637262284755707, Final Batch Loss: 0.23897399008274078\n",
      "Epoch 277, Loss: 0.4320026785135269, Final Batch Loss: 0.21345022320747375\n",
      "Epoch 278, Loss: 0.41347019374370575, Final Batch Loss: 0.19198666512966156\n",
      "Epoch 279, Loss: 0.45135413110256195, Final Batch Loss: 0.22177600860595703\n",
      "Epoch 280, Loss: 0.42608125507831573, Final Batch Loss: 0.24175864458084106\n",
      "Epoch 281, Loss: 0.36080993711948395, Final Batch Loss: 0.1794510930776596\n",
      "Epoch 282, Loss: 0.4488362520933151, Final Batch Loss: 0.25886693596839905\n",
      "Epoch 283, Loss: 0.39332060515880585, Final Batch Loss: 0.21727821230888367\n",
      "Epoch 284, Loss: 0.43073268234729767, Final Batch Loss: 0.25874853134155273\n",
      "Epoch 285, Loss: 0.3945561796426773, Final Batch Loss: 0.18386508524417877\n",
      "Epoch 286, Loss: 0.40805062651634216, Final Batch Loss: 0.23473408818244934\n",
      "Epoch 287, Loss: 0.401462197303772, Final Batch Loss: 0.19159583747386932\n",
      "Epoch 288, Loss: 0.4253019541501999, Final Batch Loss: 0.212186798453331\n",
      "Epoch 289, Loss: 0.3806355893611908, Final Batch Loss: 0.179165318608284\n",
      "Epoch 290, Loss: 0.44850262999534607, Final Batch Loss: 0.23288094997406006\n",
      "Epoch 291, Loss: 0.4361707866191864, Final Batch Loss: 0.17867174744606018\n",
      "Epoch 292, Loss: 0.36713357269763947, Final Batch Loss: 0.1928066909313202\n",
      "Epoch 293, Loss: 0.3435572236776352, Final Batch Loss: 0.18889851868152618\n",
      "Epoch 294, Loss: 0.37238530814647675, Final Batch Loss: 0.19413533806800842\n",
      "Epoch 295, Loss: 0.3739236891269684, Final Batch Loss: 0.22498029470443726\n",
      "Epoch 296, Loss: 0.3737134337425232, Final Batch Loss: 0.16101627051830292\n",
      "Epoch 297, Loss: 0.3915465623140335, Final Batch Loss: 0.1783139556646347\n",
      "Epoch 298, Loss: 0.442292258143425, Final Batch Loss: 0.23026704788208008\n",
      "Epoch 299, Loss: 0.36916783452033997, Final Batch Loss: 0.16612596809864044\n",
      "Epoch 300, Loss: 0.38604892790317535, Final Batch Loss: 0.23201651871204376\n",
      "Epoch 301, Loss: 0.3650268465280533, Final Batch Loss: 0.18485839664936066\n",
      "Epoch 302, Loss: 0.4024715721607208, Final Batch Loss: 0.1921503096818924\n",
      "Epoch 303, Loss: 0.34760741889476776, Final Batch Loss: 0.13634593784809113\n",
      "Epoch 304, Loss: 0.3637056350708008, Final Batch Loss: 0.20735587179660797\n",
      "Epoch 305, Loss: 0.3657646179199219, Final Batch Loss: 0.18679426610469818\n",
      "Epoch 306, Loss: 0.3921522796154022, Final Batch Loss: 0.21081256866455078\n",
      "Epoch 307, Loss: 0.33978191018104553, Final Batch Loss: 0.12909378111362457\n",
      "Epoch 308, Loss: 0.3354868143796921, Final Batch Loss: 0.14640675485134125\n",
      "Epoch 309, Loss: 0.3582853078842163, Final Batch Loss: 0.1829361915588379\n",
      "Epoch 310, Loss: 0.3346446454524994, Final Batch Loss: 0.1560366004705429\n",
      "Epoch 311, Loss: 0.36374814808368683, Final Batch Loss: 0.18591271340847015\n",
      "Epoch 312, Loss: 0.33875036239624023, Final Batch Loss: 0.15750689804553986\n",
      "Epoch 313, Loss: 0.32372941076755524, Final Batch Loss: 0.17420487105846405\n",
      "Epoch 314, Loss: 0.3913307338953018, Final Batch Loss: 0.2118159532546997\n",
      "Epoch 315, Loss: 0.3501623868942261, Final Batch Loss: 0.1464153230190277\n",
      "Epoch 316, Loss: 0.3171352744102478, Final Batch Loss: 0.15894679725170135\n",
      "Epoch 317, Loss: 0.3228919506072998, Final Batch Loss: 0.1378156542778015\n",
      "Epoch 318, Loss: 0.35589440166950226, Final Batch Loss: 0.17435748875141144\n",
      "Epoch 319, Loss: 0.36901211738586426, Final Batch Loss: 0.17566272616386414\n",
      "Epoch 320, Loss: 0.4136515259742737, Final Batch Loss: 0.22307489812374115\n",
      "Epoch 321, Loss: 0.3443542420864105, Final Batch Loss: 0.1795569360256195\n",
      "Epoch 322, Loss: 0.3733968138694763, Final Batch Loss: 0.1706063449382782\n",
      "Epoch 323, Loss: 0.3253258019685745, Final Batch Loss: 0.1323232501745224\n",
      "Epoch 324, Loss: 0.317413866519928, Final Batch Loss: 0.14745216071605682\n",
      "Epoch 325, Loss: 0.2903212308883667, Final Batch Loss: 0.1383615881204605\n",
      "Epoch 326, Loss: 0.3273804038763046, Final Batch Loss: 0.17566727101802826\n",
      "Epoch 327, Loss: 0.33803606033325195, Final Batch Loss: 0.1843477487564087\n",
      "Epoch 328, Loss: 0.3935209959745407, Final Batch Loss: 0.23649922013282776\n",
      "Epoch 329, Loss: 0.3357242941856384, Final Batch Loss: 0.17444708943367004\n",
      "Epoch 330, Loss: 0.42643260955810547, Final Batch Loss: 0.25799360871315\n",
      "Epoch 331, Loss: 0.3662446588277817, Final Batch Loss: 0.2352585643529892\n",
      "Epoch 332, Loss: 0.34756022691726685, Final Batch Loss: 0.1884138286113739\n",
      "Epoch 333, Loss: 0.314069002866745, Final Batch Loss: 0.18159206211566925\n",
      "Epoch 334, Loss: 0.33594807982444763, Final Batch Loss: 0.15640808641910553\n",
      "Epoch 335, Loss: 0.3144615441560745, Final Batch Loss: 0.15727244317531586\n",
      "Epoch 336, Loss: 0.37038300931453705, Final Batch Loss: 0.21555736660957336\n",
      "Epoch 337, Loss: 0.3673771023750305, Final Batch Loss: 0.21684229373931885\n",
      "Epoch 338, Loss: 0.33204515278339386, Final Batch Loss: 0.1450306624174118\n",
      "Epoch 339, Loss: 0.3273250162601471, Final Batch Loss: 0.17711128294467926\n",
      "Epoch 340, Loss: 0.31775645911693573, Final Batch Loss: 0.1643323302268982\n",
      "Epoch 341, Loss: 0.37692251801490784, Final Batch Loss: 0.20856055617332458\n",
      "Epoch 342, Loss: 0.3304692208766937, Final Batch Loss: 0.15490707755088806\n",
      "Epoch 343, Loss: 0.31408096849918365, Final Batch Loss: 0.16980718076229095\n",
      "Epoch 344, Loss: 0.31506671011447906, Final Batch Loss: 0.16750092804431915\n",
      "Epoch 345, Loss: 0.34526611864566803, Final Batch Loss: 0.19717101752758026\n",
      "Epoch 346, Loss: 0.31682783365249634, Final Batch Loss: 0.14622762799263\n",
      "Epoch 347, Loss: 0.328667089343071, Final Batch Loss: 0.1682138741016388\n",
      "Epoch 348, Loss: 0.32538364827632904, Final Batch Loss: 0.15742063522338867\n",
      "Epoch 349, Loss: 0.3401341438293457, Final Batch Loss: 0.17951086163520813\n",
      "Epoch 350, Loss: 0.3570116460323334, Final Batch Loss: 0.19577431678771973\n",
      "Epoch 351, Loss: 0.30993710458278656, Final Batch Loss: 0.16744281351566315\n",
      "Epoch 352, Loss: 0.3399554193019867, Final Batch Loss: 0.1701422482728958\n",
      "Epoch 353, Loss: 0.29837556183338165, Final Batch Loss: 0.1475888043642044\n",
      "Epoch 354, Loss: 0.35150039196014404, Final Batch Loss: 0.1968197375535965\n",
      "Epoch 355, Loss: 0.281060591340065, Final Batch Loss: 0.14608730375766754\n",
      "Epoch 356, Loss: 0.28534114360809326, Final Batch Loss: 0.13144904375076294\n",
      "Epoch 357, Loss: 0.3003006875514984, Final Batch Loss: 0.1435042768716812\n",
      "Epoch 358, Loss: 0.3534332513809204, Final Batch Loss: 0.19054369628429413\n",
      "Epoch 359, Loss: 0.30502980947494507, Final Batch Loss: 0.14782586693763733\n",
      "Epoch 360, Loss: 0.3075687289237976, Final Batch Loss: 0.18291164934635162\n",
      "Epoch 361, Loss: 0.287582203745842, Final Batch Loss: 0.14452961087226868\n",
      "Epoch 362, Loss: 0.3010620176792145, Final Batch Loss: 0.1572393923997879\n",
      "Epoch 363, Loss: 0.25345540046691895, Final Batch Loss: 0.13448768854141235\n",
      "Epoch 364, Loss: 0.3074573576450348, Final Batch Loss: 0.16230548918247223\n",
      "Epoch 365, Loss: 0.29134324193000793, Final Batch Loss: 0.1426474004983902\n",
      "Epoch 366, Loss: 0.2757975310087204, Final Batch Loss: 0.12181133031845093\n",
      "Epoch 367, Loss: 0.35650278627872467, Final Batch Loss: 0.19993096590042114\n",
      "Epoch 368, Loss: 0.31695786118507385, Final Batch Loss: 0.15504275262355804\n",
      "Epoch 369, Loss: 0.3057568818330765, Final Batch Loss: 0.13995027542114258\n",
      "Epoch 370, Loss: 0.3365563750267029, Final Batch Loss: 0.18705637753009796\n",
      "Epoch 371, Loss: 0.33943358063697815, Final Batch Loss: 0.13462373614311218\n",
      "Epoch 372, Loss: 0.3166409432888031, Final Batch Loss: 0.12476243078708649\n",
      "Epoch 373, Loss: 0.2962329238653183, Final Batch Loss: 0.1398790031671524\n",
      "Epoch 374, Loss: 0.3061414510011673, Final Batch Loss: 0.17580418288707733\n",
      "Epoch 375, Loss: 0.3471439480781555, Final Batch Loss: 0.20144592225551605\n",
      "Epoch 376, Loss: 0.34729570150375366, Final Batch Loss: 0.1974223256111145\n",
      "Epoch 377, Loss: 0.31264111399650574, Final Batch Loss: 0.17530353367328644\n",
      "Epoch 378, Loss: 0.26908545196056366, Final Batch Loss: 0.14268945157527924\n",
      "Epoch 379, Loss: 0.30929918587207794, Final Batch Loss: 0.165659561753273\n",
      "Epoch 380, Loss: 0.30011987686157227, Final Batch Loss: 0.12162300944328308\n",
      "Epoch 381, Loss: 0.2903253734111786, Final Batch Loss: 0.1262778341770172\n",
      "Epoch 382, Loss: 0.32689057290554047, Final Batch Loss: 0.1774134784936905\n",
      "Epoch 383, Loss: 0.31689564883708954, Final Batch Loss: 0.15610936284065247\n",
      "Epoch 384, Loss: 0.3146866261959076, Final Batch Loss: 0.1614496409893036\n",
      "Epoch 385, Loss: 0.3800013065338135, Final Batch Loss: 0.21747958660125732\n",
      "Epoch 386, Loss: 0.30386778712272644, Final Batch Loss: 0.15246497094631195\n",
      "Epoch 387, Loss: 0.3121573179960251, Final Batch Loss: 0.13597695529460907\n",
      "Epoch 388, Loss: 0.28698669373989105, Final Batch Loss: 0.1637503057718277\n",
      "Epoch 389, Loss: 0.25451647490262985, Final Batch Loss: 0.10827622562646866\n",
      "Epoch 390, Loss: 0.29494331777095795, Final Batch Loss: 0.15235422551631927\n",
      "Epoch 391, Loss: 0.32791242003440857, Final Batch Loss: 0.1669333577156067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392, Loss: 0.29403547942638397, Final Batch Loss: 0.16178838908672333\n",
      "Epoch 393, Loss: 0.2766808867454529, Final Batch Loss: 0.14345033466815948\n",
      "Epoch 394, Loss: 0.29942066967487335, Final Batch Loss: 0.14692063629627228\n",
      "Epoch 395, Loss: 0.31003211438655853, Final Batch Loss: 0.1749178022146225\n",
      "Epoch 396, Loss: 0.28902754187583923, Final Batch Loss: 0.12590500712394714\n",
      "Epoch 397, Loss: 0.34934772551059723, Final Batch Loss: 0.18061837553977966\n",
      "Epoch 398, Loss: 0.24779823422431946, Final Batch Loss: 0.13507768511772156\n",
      "Epoch 399, Loss: 0.311222180724144, Final Batch Loss: 0.16047292947769165\n",
      "Epoch 400, Loss: 0.3135984092950821, Final Batch Loss: 0.153055801987648\n",
      "Epoch 401, Loss: 0.29196786880493164, Final Batch Loss: 0.1571747362613678\n",
      "Epoch 402, Loss: 0.327828973531723, Final Batch Loss: 0.1602034717798233\n",
      "Epoch 403, Loss: 0.30118972063064575, Final Batch Loss: 0.16279159486293793\n",
      "Epoch 404, Loss: 0.282759353518486, Final Batch Loss: 0.1658594310283661\n",
      "Epoch 405, Loss: 0.27292153239250183, Final Batch Loss: 0.15032298862934113\n",
      "Epoch 406, Loss: 0.2707881033420563, Final Batch Loss: 0.13706780970096588\n",
      "Epoch 407, Loss: 0.2752825990319252, Final Batch Loss: 0.105953149497509\n",
      "Epoch 408, Loss: 0.329604834318161, Final Batch Loss: 0.180593341588974\n",
      "Epoch 409, Loss: 0.31088024377822876, Final Batch Loss: 0.17037756741046906\n",
      "Epoch 410, Loss: 0.3034808784723282, Final Batch Loss: 0.15955066680908203\n",
      "Epoch 411, Loss: 0.2542402073740959, Final Batch Loss: 0.09718377143144608\n",
      "Epoch 412, Loss: 0.2698699086904526, Final Batch Loss: 0.13468486070632935\n",
      "Epoch 413, Loss: 0.2773941308259964, Final Batch Loss: 0.1262839138507843\n",
      "Epoch 414, Loss: 0.32412944734096527, Final Batch Loss: 0.1646365225315094\n",
      "Epoch 415, Loss: 0.3456079661846161, Final Batch Loss: 0.21676738560199738\n",
      "Epoch 416, Loss: 0.2936934530735016, Final Batch Loss: 0.14338462054729462\n",
      "Epoch 417, Loss: 0.23848288506269455, Final Batch Loss: 0.12545952200889587\n",
      "Epoch 418, Loss: 0.30367182195186615, Final Batch Loss: 0.19093617796897888\n",
      "Epoch 419, Loss: 0.2834087312221527, Final Batch Loss: 0.15274810791015625\n",
      "Epoch 420, Loss: 0.27972761541604996, Final Batch Loss: 0.08601183444261551\n",
      "Epoch 421, Loss: 0.3161240816116333, Final Batch Loss: 0.1742139458656311\n",
      "Epoch 422, Loss: 0.2978062927722931, Final Batch Loss: 0.13511738181114197\n",
      "Epoch 423, Loss: 0.2719794064760208, Final Batch Loss: 0.14374656975269318\n",
      "Epoch 424, Loss: 0.24511314183473587, Final Batch Loss: 0.12462504208087921\n",
      "Epoch 425, Loss: 0.25833529233932495, Final Batch Loss: 0.13696156442165375\n",
      "Epoch 426, Loss: 0.2712031304836273, Final Batch Loss: 0.16647905111312866\n",
      "Epoch 427, Loss: 0.2436942234635353, Final Batch Loss: 0.10611607879400253\n",
      "Epoch 428, Loss: 0.26050520688295364, Final Batch Loss: 0.08951950818300247\n",
      "Epoch 429, Loss: 0.26835867762565613, Final Batch Loss: 0.11099590361118317\n",
      "Epoch 430, Loss: 0.23510544747114182, Final Batch Loss: 0.11251040548086166\n",
      "Epoch 431, Loss: 0.26337265223264694, Final Batch Loss: 0.15032517910003662\n",
      "Epoch 432, Loss: 0.22703537344932556, Final Batch Loss: 0.11188632994890213\n",
      "Epoch 433, Loss: 0.27561140060424805, Final Batch Loss: 0.12986941635608673\n",
      "Epoch 434, Loss: 0.21609093993902206, Final Batch Loss: 0.07027506083250046\n",
      "Epoch 435, Loss: 0.2893701046705246, Final Batch Loss: 0.13386432826519012\n",
      "Epoch 436, Loss: 0.25659559667110443, Final Batch Loss: 0.12873303890228271\n",
      "Epoch 437, Loss: 0.29888054728507996, Final Batch Loss: 0.15425364673137665\n",
      "Epoch 438, Loss: 0.2492353469133377, Final Batch Loss: 0.10793441534042358\n",
      "Epoch 439, Loss: 0.25300613045692444, Final Batch Loss: 0.11911256611347198\n",
      "Epoch 440, Loss: 0.23733431845903397, Final Batch Loss: 0.09648280590772629\n",
      "Epoch 441, Loss: 0.24510421603918076, Final Batch Loss: 0.1134006604552269\n",
      "Epoch 442, Loss: 0.22880425304174423, Final Batch Loss: 0.10363835841417313\n",
      "Epoch 443, Loss: 0.24840933084487915, Final Batch Loss: 0.09762182831764221\n",
      "Epoch 444, Loss: 0.25110213458538055, Final Batch Loss: 0.1279047280550003\n",
      "Epoch 445, Loss: 0.2408084198832512, Final Batch Loss: 0.12898053228855133\n",
      "Epoch 446, Loss: 0.26018644869327545, Final Batch Loss: 0.1561518758535385\n",
      "Epoch 447, Loss: 0.27312060445547104, Final Batch Loss: 0.11769858747720718\n",
      "Epoch 448, Loss: 0.24439602345228195, Final Batch Loss: 0.12082710862159729\n",
      "Epoch 449, Loss: 0.24685419350862503, Final Batch Loss: 0.1308695673942566\n",
      "Epoch 450, Loss: 0.27065958827733994, Final Batch Loss: 0.12213293462991714\n",
      "Epoch 451, Loss: 0.23843227326869965, Final Batch Loss: 0.12538741528987885\n",
      "Epoch 452, Loss: 0.20871331542730331, Final Batch Loss: 0.09564894437789917\n",
      "Epoch 453, Loss: 0.23907515406608582, Final Batch Loss: 0.1028662621974945\n",
      "Epoch 454, Loss: 0.2381814643740654, Final Batch Loss: 0.1257389783859253\n",
      "Epoch 455, Loss: 0.33556585758924484, Final Batch Loss: 0.2126150280237198\n",
      "Epoch 456, Loss: 0.21391838043928146, Final Batch Loss: 0.0820508822798729\n",
      "Epoch 457, Loss: 0.2216024175286293, Final Batch Loss: 0.10748639702796936\n",
      "Epoch 458, Loss: 0.27605435252189636, Final Batch Loss: 0.15161395072937012\n",
      "Epoch 459, Loss: 0.2752804458141327, Final Batch Loss: 0.12537401914596558\n",
      "Epoch 460, Loss: 0.26056939363479614, Final Batch Loss: 0.13824959099292755\n",
      "Epoch 461, Loss: 0.25329241901636124, Final Batch Loss: 0.1424182951450348\n",
      "Epoch 462, Loss: 0.23751380294561386, Final Batch Loss: 0.13206183910369873\n",
      "Epoch 463, Loss: 0.22620002180337906, Final Batch Loss: 0.10641489923000336\n",
      "Epoch 464, Loss: 0.2364705577492714, Final Batch Loss: 0.14230291545391083\n",
      "Epoch 465, Loss: 0.3021944612264633, Final Batch Loss: 0.14426445960998535\n",
      "Epoch 466, Loss: 0.26501142233610153, Final Batch Loss: 0.15367986261844635\n",
      "Epoch 467, Loss: 0.2389764040708542, Final Batch Loss: 0.10849584639072418\n",
      "Epoch 468, Loss: 0.2516416907310486, Final Batch Loss: 0.10157735645771027\n",
      "Epoch 469, Loss: 0.25027307868003845, Final Batch Loss: 0.11920398473739624\n",
      "Epoch 470, Loss: 0.20632877945899963, Final Batch Loss: 0.11259226500988007\n",
      "Epoch 471, Loss: 0.21666640788316727, Final Batch Loss: 0.105623759329319\n",
      "Epoch 472, Loss: 0.225636325776577, Final Batch Loss: 0.09174676984548569\n",
      "Epoch 473, Loss: 0.24747614562511444, Final Batch Loss: 0.11452935636043549\n",
      "Epoch 474, Loss: 0.256240576505661, Final Batch Loss: 0.1367076188325882\n",
      "Epoch 475, Loss: 0.3353879749774933, Final Batch Loss: 0.23108790814876556\n",
      "Epoch 476, Loss: 0.23880263417959213, Final Batch Loss: 0.13732518255710602\n",
      "Epoch 477, Loss: 0.2612358182668686, Final Batch Loss: 0.15232937037944794\n",
      "Epoch 478, Loss: 0.31164010614156723, Final Batch Loss: 0.1973443478345871\n",
      "Epoch 479, Loss: 0.25449082255363464, Final Batch Loss: 0.13591966032981873\n",
      "Epoch 480, Loss: 0.2575065717101097, Final Batch Loss: 0.1365506500005722\n",
      "Epoch 481, Loss: 0.24816084653139114, Final Batch Loss: 0.11772450059652328\n",
      "Epoch 482, Loss: 0.2962116599082947, Final Batch Loss: 0.1558150202035904\n",
      "Epoch 483, Loss: 0.2735641747713089, Final Batch Loss: 0.12223105132579803\n",
      "Epoch 484, Loss: 0.2888851761817932, Final Batch Loss: 0.14637000858783722\n",
      "Epoch 485, Loss: 0.22591248899698257, Final Batch Loss: 0.0981491282582283\n",
      "Epoch 486, Loss: 0.3092081993818283, Final Batch Loss: 0.17197397351264954\n",
      "Epoch 487, Loss: 0.2821029722690582, Final Batch Loss: 0.16289377212524414\n",
      "Epoch 488, Loss: 0.2422664910554886, Final Batch Loss: 0.1393299698829651\n",
      "Epoch 489, Loss: 0.22723063081502914, Final Batch Loss: 0.09432011097669601\n",
      "Epoch 490, Loss: 0.2517666295170784, Final Batch Loss: 0.1273384690284729\n",
      "Epoch 491, Loss: 0.25847340375185013, Final Batch Loss: 0.15281915664672852\n",
      "Epoch 492, Loss: 0.19764840602874756, Final Batch Loss: 0.07793259620666504\n",
      "Epoch 493, Loss: 0.24718493223190308, Final Batch Loss: 0.09269846975803375\n",
      "Epoch 494, Loss: 0.22569894790649414, Final Batch Loss: 0.10638678073883057\n",
      "Epoch 495, Loss: 0.19876951724290848, Final Batch Loss: 0.08658013492822647\n",
      "Epoch 496, Loss: 0.2240251526236534, Final Batch Loss: 0.12779775261878967\n",
      "Epoch 497, Loss: 0.24677101522684097, Final Batch Loss: 0.14012913405895233\n",
      "Epoch 498, Loss: 0.24276378005743027, Final Batch Loss: 0.11304519325494766\n",
      "Epoch 499, Loss: 0.20870498567819595, Final Batch Loss: 0.08819027990102768\n",
      "Epoch 500, Loss: 0.27324751764535904, Final Batch Loss: 0.17397427558898926\n",
      "Epoch 501, Loss: 0.19830332696437836, Final Batch Loss: 0.07913954555988312\n",
      "Epoch 502, Loss: 0.21010950952768326, Final Batch Loss: 0.08380752056837082\n",
      "Epoch 503, Loss: 0.2198699712753296, Final Batch Loss: 0.10857672989368439\n",
      "Epoch 504, Loss: 0.20160840451717377, Final Batch Loss: 0.12785111367702484\n",
      "Epoch 505, Loss: 0.21520308405160904, Final Batch Loss: 0.08230068534612656\n",
      "Epoch 506, Loss: 0.21718289703130722, Final Batch Loss: 0.09063980728387833\n",
      "Epoch 507, Loss: 0.217646062374115, Final Batch Loss: 0.11511486023664474\n",
      "Epoch 508, Loss: 0.21394269913434982, Final Batch Loss: 0.10547075420618057\n",
      "Epoch 509, Loss: 0.212824247777462, Final Batch Loss: 0.07902919501066208\n",
      "Epoch 510, Loss: 0.20085033029317856, Final Batch Loss: 0.06721947342157364\n",
      "Epoch 511, Loss: 0.21887855976819992, Final Batch Loss: 0.09539752453565598\n",
      "Epoch 512, Loss: 0.21934302896261215, Final Batch Loss: 0.11673110723495483\n",
      "Epoch 513, Loss: 0.2379692792892456, Final Batch Loss: 0.13490629196166992\n",
      "Epoch 514, Loss: 0.21504080295562744, Final Batch Loss: 0.12250980734825134\n",
      "Epoch 515, Loss: 0.25773755460977554, Final Batch Loss: 0.11136242002248764\n",
      "Epoch 516, Loss: 0.21331427991390228, Final Batch Loss: 0.10895813256502151\n",
      "Epoch 517, Loss: 0.23511545360088348, Final Batch Loss: 0.11161535978317261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518, Loss: 0.22712332010269165, Final Batch Loss: 0.12189975380897522\n",
      "Epoch 519, Loss: 0.2122897356748581, Final Batch Loss: 0.11719666421413422\n",
      "Epoch 520, Loss: 0.17107245326042175, Final Batch Loss: 0.08427691459655762\n",
      "Epoch 521, Loss: 0.1936802938580513, Final Batch Loss: 0.08332784473896027\n",
      "Epoch 522, Loss: 0.19032813608646393, Final Batch Loss: 0.08398868888616562\n",
      "Epoch 523, Loss: 0.23952516168355942, Final Batch Loss: 0.1342056542634964\n",
      "Epoch 524, Loss: 0.2690296843647957, Final Batch Loss: 0.1531086415052414\n",
      "Epoch 525, Loss: 0.23276326805353165, Final Batch Loss: 0.11748871207237244\n",
      "Epoch 526, Loss: 0.17583569884300232, Final Batch Loss: 0.09035779535770416\n",
      "Epoch 527, Loss: 0.23026137799024582, Final Batch Loss: 0.11178406327962875\n",
      "Epoch 528, Loss: 0.2391563355922699, Final Batch Loss: 0.135599747300148\n",
      "Epoch 529, Loss: 0.20430483669042587, Final Batch Loss: 0.06676071137189865\n",
      "Epoch 530, Loss: 0.25442908704280853, Final Batch Loss: 0.12730029225349426\n",
      "Epoch 531, Loss: 0.2171066254377365, Final Batch Loss: 0.11244597285985947\n",
      "Epoch 532, Loss: 0.2169414684176445, Final Batch Loss: 0.09928526729345322\n",
      "Epoch 533, Loss: 0.19281039386987686, Final Batch Loss: 0.09398075193166733\n",
      "Epoch 534, Loss: 0.24584538489580154, Final Batch Loss: 0.1054743155837059\n",
      "Epoch 535, Loss: 0.19775500148534775, Final Batch Loss: 0.09084317088127136\n",
      "Epoch 536, Loss: 0.22189468145370483, Final Batch Loss: 0.1093236654996872\n",
      "Epoch 537, Loss: 0.18758435547351837, Final Batch Loss: 0.08526688069105148\n",
      "Epoch 538, Loss: 0.21067918837070465, Final Batch Loss: 0.09462964534759521\n",
      "Epoch 539, Loss: 0.2224280759692192, Final Batch Loss: 0.10126683115959167\n",
      "Epoch 540, Loss: 0.2154013067483902, Final Batch Loss: 0.129306823015213\n",
      "Epoch 541, Loss: 0.23134639859199524, Final Batch Loss: 0.1316974014043808\n",
      "Epoch 542, Loss: 0.20250391215085983, Final Batch Loss: 0.1024354100227356\n",
      "Epoch 543, Loss: 0.17217324674129486, Final Batch Loss: 0.08747901022434235\n",
      "Epoch 544, Loss: 0.18908283859491348, Final Batch Loss: 0.0801066979765892\n",
      "Epoch 545, Loss: 0.19154971092939377, Final Batch Loss: 0.09014121443033218\n",
      "Epoch 546, Loss: 0.18963883817195892, Final Batch Loss: 0.07250625640153885\n",
      "Epoch 547, Loss: 0.18987087160348892, Final Batch Loss: 0.10964150726795197\n",
      "Epoch 548, Loss: 0.19509241729974747, Final Batch Loss: 0.0870581567287445\n",
      "Epoch 549, Loss: 0.1922019049525261, Final Batch Loss: 0.08924323320388794\n",
      "Epoch 550, Loss: 0.20291100442409515, Final Batch Loss: 0.1094515323638916\n",
      "Epoch 551, Loss: 0.21798092126846313, Final Batch Loss: 0.11267416924238205\n",
      "Epoch 552, Loss: 0.18279077857732773, Final Batch Loss: 0.08826711028814316\n",
      "Epoch 553, Loss: 0.22470322996377945, Final Batch Loss: 0.10893584787845612\n",
      "Epoch 554, Loss: 0.16461849957704544, Final Batch Loss: 0.06653459370136261\n",
      "Epoch 555, Loss: 0.21080776304006577, Final Batch Loss: 0.12216190248727798\n",
      "Epoch 556, Loss: 0.20046459883451462, Final Batch Loss: 0.10433885455131531\n",
      "Epoch 557, Loss: 0.18991892784833908, Final Batch Loss: 0.08326545357704163\n",
      "Epoch 558, Loss: 0.2285686433315277, Final Batch Loss: 0.13621892035007477\n",
      "Epoch 559, Loss: 0.22193968296051025, Final Batch Loss: 0.15043805539608002\n",
      "Epoch 560, Loss: 0.19475314766168594, Final Batch Loss: 0.08764375001192093\n",
      "Epoch 561, Loss: 0.18186448514461517, Final Batch Loss: 0.0820220410823822\n",
      "Epoch 562, Loss: 0.25035499781370163, Final Batch Loss: 0.18630576133728027\n",
      "Epoch 563, Loss: 0.1698288694024086, Final Batch Loss: 0.09235228598117828\n",
      "Epoch 564, Loss: 0.2177983671426773, Final Batch Loss: 0.12888087332248688\n",
      "Epoch 565, Loss: 0.182326078414917, Final Batch Loss: 0.08872281014919281\n",
      "Epoch 566, Loss: 0.20566140860319138, Final Batch Loss: 0.1179092675447464\n",
      "Epoch 567, Loss: 0.15916937589645386, Final Batch Loss: 0.0691935196518898\n",
      "Epoch 568, Loss: 0.16116755083203316, Final Batch Loss: 0.05725570395588875\n",
      "Epoch 569, Loss: 0.24316954612731934, Final Batch Loss: 0.1396823674440384\n",
      "Epoch 570, Loss: 0.18110007047653198, Final Batch Loss: 0.09899946302175522\n",
      "Epoch 571, Loss: 0.1749129220843315, Final Batch Loss: 0.07434201240539551\n",
      "Epoch 572, Loss: 0.1751709282398224, Final Batch Loss: 0.09314104169607162\n",
      "Epoch 573, Loss: 0.17923342436552048, Final Batch Loss: 0.06575233489274979\n",
      "Epoch 574, Loss: 0.1637841835618019, Final Batch Loss: 0.0678633376955986\n",
      "Epoch 575, Loss: 0.1960754692554474, Final Batch Loss: 0.1026245653629303\n",
      "Epoch 576, Loss: 0.20530721172690392, Final Batch Loss: 0.14561867713928223\n",
      "Epoch 577, Loss: 0.18709155917167664, Final Batch Loss: 0.09406907856464386\n",
      "Epoch 578, Loss: 0.22536081820726395, Final Batch Loss: 0.13237610459327698\n",
      "Epoch 579, Loss: 0.2221713811159134, Final Batch Loss: 0.13001748919487\n",
      "Epoch 580, Loss: 0.19183512032032013, Final Batch Loss: 0.07316882908344269\n",
      "Epoch 581, Loss: 0.18692873418331146, Final Batch Loss: 0.08258040994405746\n",
      "Epoch 582, Loss: 0.2025444135069847, Final Batch Loss: 0.09310010820627213\n",
      "Epoch 583, Loss: 0.209438756108284, Final Batch Loss: 0.1363382637500763\n",
      "Epoch 584, Loss: 0.1760263592004776, Final Batch Loss: 0.07302994281053543\n",
      "Epoch 585, Loss: 0.19567763805389404, Final Batch Loss: 0.09011632204055786\n",
      "Epoch 586, Loss: 0.18228726089000702, Final Batch Loss: 0.07130224257707596\n",
      "Epoch 587, Loss: 0.13963723927736282, Final Batch Loss: 0.05567243695259094\n",
      "Epoch 588, Loss: 0.17695149779319763, Final Batch Loss: 0.10070783644914627\n",
      "Epoch 589, Loss: 0.21068931370973587, Final Batch Loss: 0.12617546319961548\n",
      "Epoch 590, Loss: 0.1502295434474945, Final Batch Loss: 0.07925480604171753\n",
      "Epoch 591, Loss: 0.1734979897737503, Final Batch Loss: 0.11077874153852463\n",
      "Epoch 592, Loss: 0.16122128069400787, Final Batch Loss: 0.07516233623027802\n",
      "Epoch 593, Loss: 0.15612144023180008, Final Batch Loss: 0.08204037696123123\n",
      "Epoch 594, Loss: 0.1885378211736679, Final Batch Loss: 0.08339137583971024\n",
      "Epoch 595, Loss: 0.14851519465446472, Final Batch Loss: 0.08045346289873123\n",
      "Epoch 596, Loss: 0.14692707732319832, Final Batch Loss: 0.057537924498319626\n",
      "Epoch 597, Loss: 0.1474766954779625, Final Batch Loss: 0.06609335541725159\n",
      "Epoch 598, Loss: 0.17698099836707115, Final Batch Loss: 0.11549069732427597\n",
      "Epoch 599, Loss: 0.23140829056501389, Final Batch Loss: 0.12595035135746002\n",
      "Epoch 600, Loss: 0.13759301230311394, Final Batch Loss: 0.052256662398576736\n",
      "Epoch 601, Loss: 0.1681336909532547, Final Batch Loss: 0.1136760339140892\n",
      "Epoch 602, Loss: 0.17226459830999374, Final Batch Loss: 0.06992802023887634\n",
      "Epoch 603, Loss: 0.16543646156787872, Final Batch Loss: 0.09199873358011246\n",
      "Epoch 604, Loss: 0.18060890585184097, Final Batch Loss: 0.10629117488861084\n",
      "Epoch 605, Loss: 0.16041279584169388, Final Batch Loss: 0.08938945084810257\n",
      "Epoch 606, Loss: 0.21286460757255554, Final Batch Loss: 0.12770941853523254\n",
      "Epoch 607, Loss: 0.12869051843881607, Final Batch Loss: 0.057313449680805206\n",
      "Epoch 608, Loss: 0.13665173947811127, Final Batch Loss: 0.05770016461610794\n",
      "Epoch 609, Loss: 0.18169502168893814, Final Batch Loss: 0.07593832910060883\n",
      "Epoch 610, Loss: 0.16773535311222076, Final Batch Loss: 0.07136940211057663\n",
      "Epoch 611, Loss: 0.1195952482521534, Final Batch Loss: 0.04775822535157204\n",
      "Epoch 612, Loss: 0.20533856749534607, Final Batch Loss: 0.1124192401766777\n",
      "Epoch 613, Loss: 0.1585434526205063, Final Batch Loss: 0.09288323670625687\n",
      "Epoch 614, Loss: 0.13265061005949974, Final Batch Loss: 0.08006519079208374\n",
      "Epoch 615, Loss: 0.1548849642276764, Final Batch Loss: 0.0871339961886406\n",
      "Epoch 616, Loss: 0.1410585343837738, Final Batch Loss: 0.04881887882947922\n",
      "Epoch 617, Loss: 0.15101654082536697, Final Batch Loss: 0.07584769278764725\n",
      "Epoch 618, Loss: 0.15705015510320663, Final Batch Loss: 0.06410045921802521\n",
      "Epoch 619, Loss: 0.20114821940660477, Final Batch Loss: 0.1295001208782196\n",
      "Epoch 620, Loss: 0.1734081208705902, Final Batch Loss: 0.10904479026794434\n",
      "Epoch 621, Loss: 0.17602024972438812, Final Batch Loss: 0.07860416173934937\n",
      "Epoch 622, Loss: 0.10257995501160622, Final Batch Loss: 0.04921296238899231\n",
      "Epoch 623, Loss: 0.17732959985733032, Final Batch Loss: 0.10928796231746674\n",
      "Epoch 624, Loss: 0.13247521221637726, Final Batch Loss: 0.058931201696395874\n",
      "Epoch 625, Loss: 0.13580610416829586, Final Batch Loss: 0.02761307917535305\n",
      "Epoch 626, Loss: 0.18265239894390106, Final Batch Loss: 0.09997764974832535\n",
      "Epoch 627, Loss: 0.13833699002861977, Final Batch Loss: 0.08659429848194122\n",
      "Epoch 628, Loss: 0.14633939415216446, Final Batch Loss: 0.08818881213665009\n",
      "Epoch 629, Loss: 0.15182508900761604, Final Batch Loss: 0.10198638588190079\n",
      "Epoch 630, Loss: 0.12655500322580338, Final Batch Loss: 0.06681998074054718\n",
      "Epoch 631, Loss: 0.17385344207286835, Final Batch Loss: 0.08881785720586777\n",
      "Epoch 632, Loss: 0.1810305342078209, Final Batch Loss: 0.09263817965984344\n",
      "Epoch 633, Loss: 0.14151562750339508, Final Batch Loss: 0.06915140151977539\n",
      "Epoch 634, Loss: 0.163149893283844, Final Batch Loss: 0.07255250960588455\n",
      "Epoch 635, Loss: 0.11326760053634644, Final Batch Loss: 0.055629026144742966\n",
      "Epoch 636, Loss: 0.18144868314266205, Final Batch Loss: 0.0808820053935051\n",
      "Epoch 637, Loss: 0.125586099922657, Final Batch Loss: 0.05999373644590378\n",
      "Epoch 638, Loss: 0.1334034651517868, Final Batch Loss: 0.07402361929416656\n",
      "Epoch 639, Loss: 0.10626386478543282, Final Batch Loss: 0.044455740600824356\n",
      "Epoch 640, Loss: 0.18025615811347961, Final Batch Loss: 0.08067081868648529\n",
      "Epoch 641, Loss: 0.1602080538868904, Final Batch Loss: 0.11001632362604141\n",
      "Epoch 642, Loss: 0.10515505447983742, Final Batch Loss: 0.0430617518723011\n",
      "Epoch 643, Loss: 0.1693132370710373, Final Batch Loss: 0.09267686307430267\n",
      "Epoch 644, Loss: 0.15435223653912544, Final Batch Loss: 0.06188076362013817\n",
      "Epoch 645, Loss: 0.14958657324314117, Final Batch Loss: 0.030404575169086456\n",
      "Epoch 646, Loss: 0.23049835115671158, Final Batch Loss: 0.1557990461587906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 647, Loss: 0.1568886786699295, Final Batch Loss: 0.07997528463602066\n",
      "Epoch 648, Loss: 0.1743086576461792, Final Batch Loss: 0.08291113376617432\n",
      "Epoch 649, Loss: 0.12243359163403511, Final Batch Loss: 0.06251045316457748\n",
      "Epoch 650, Loss: 0.18433725088834763, Final Batch Loss: 0.10133393108844757\n",
      "Epoch 651, Loss: 0.18962756544351578, Final Batch Loss: 0.10087655484676361\n",
      "Epoch 652, Loss: 0.14521266520023346, Final Batch Loss: 0.07658332586288452\n",
      "Epoch 653, Loss: 0.13196415826678276, Final Batch Loss: 0.08908043056726456\n",
      "Epoch 654, Loss: 0.14426643401384354, Final Batch Loss: 0.06486213207244873\n",
      "Epoch 655, Loss: 0.13179807737469673, Final Batch Loss: 0.05400604382157326\n",
      "Epoch 656, Loss: 0.156871248036623, Final Batch Loss: 0.10803954303264618\n",
      "Epoch 657, Loss: 0.13341466337442398, Final Batch Loss: 0.06642467528581619\n",
      "Epoch 658, Loss: 0.11763147637248039, Final Batch Loss: 0.04616386815905571\n",
      "Epoch 659, Loss: 0.197151780128479, Final Batch Loss: 0.088363878428936\n",
      "Epoch 660, Loss: 0.17416933178901672, Final Batch Loss: 0.07450084388256073\n",
      "Epoch 661, Loss: 0.20061571896076202, Final Batch Loss: 0.11982320249080658\n",
      "Epoch 662, Loss: 0.14241645485162735, Final Batch Loss: 0.07541607320308685\n",
      "Epoch 663, Loss: 0.14577799290418625, Final Batch Loss: 0.07794006168842316\n",
      "Epoch 664, Loss: 0.13070211559534073, Final Batch Loss: 0.06476569175720215\n",
      "Epoch 665, Loss: 0.14847949892282486, Final Batch Loss: 0.06896781176328659\n",
      "Epoch 666, Loss: 0.17523453384637833, Final Batch Loss: 0.07893670350313187\n",
      "Epoch 667, Loss: 0.12019854038953781, Final Batch Loss: 0.053988732397556305\n",
      "Epoch 668, Loss: 0.1192673109471798, Final Batch Loss: 0.04896700009703636\n",
      "Epoch 669, Loss: 0.10659539699554443, Final Batch Loss: 0.03938659280538559\n",
      "Epoch 670, Loss: 0.18849296122789383, Final Batch Loss: 0.11355610936880112\n",
      "Epoch 671, Loss: 0.13583053275942802, Final Batch Loss: 0.06006217375397682\n",
      "Epoch 672, Loss: 0.23122991621494293, Final Batch Loss: 0.11726171523332596\n",
      "Epoch 673, Loss: 0.18068575114011765, Final Batch Loss: 0.08849328756332397\n",
      "Epoch 674, Loss: 0.1645250916481018, Final Batch Loss: 0.0765918493270874\n",
      "Epoch 675, Loss: 0.19118261709809303, Final Batch Loss: 0.12994764745235443\n",
      "Epoch 676, Loss: 0.17733826488256454, Final Batch Loss: 0.09463287144899368\n",
      "Epoch 677, Loss: 0.1606900990009308, Final Batch Loss: 0.07306922972202301\n",
      "Epoch 678, Loss: 0.1326197236776352, Final Batch Loss: 0.07301629334688187\n",
      "Epoch 679, Loss: 0.13792625814676285, Final Batch Loss: 0.06772025674581528\n",
      "Epoch 680, Loss: 0.14891430735588074, Final Batch Loss: 0.11139362305402756\n",
      "Epoch 681, Loss: 0.14808784425258636, Final Batch Loss: 0.063707135617733\n",
      "Epoch 682, Loss: 0.12120694294571877, Final Batch Loss: 0.0495699979364872\n",
      "Epoch 683, Loss: 0.11222628131508827, Final Batch Loss: 0.04321296140551567\n",
      "Epoch 684, Loss: 0.11019734665751457, Final Batch Loss: 0.051991887390613556\n",
      "Epoch 685, Loss: 0.11215216666460037, Final Batch Loss: 0.04384692758321762\n",
      "Epoch 686, Loss: 0.12632306665182114, Final Batch Loss: 0.06259304285049438\n",
      "Epoch 687, Loss: 0.10687917843461037, Final Batch Loss: 0.05199108272790909\n",
      "Epoch 688, Loss: 0.13645971193909645, Final Batch Loss: 0.07925169169902802\n",
      "Epoch 689, Loss: 0.13756904751062393, Final Batch Loss: 0.06453604996204376\n",
      "Epoch 690, Loss: 0.1248379722237587, Final Batch Loss: 0.04603192210197449\n",
      "Epoch 691, Loss: 0.15318729728460312, Final Batch Loss: 0.07863834500312805\n",
      "Epoch 692, Loss: 0.13333741948008537, Final Batch Loss: 0.07124578952789307\n",
      "Epoch 693, Loss: 0.13292765244841576, Final Batch Loss: 0.062480274587869644\n",
      "Epoch 694, Loss: 0.10870485380291939, Final Batch Loss: 0.05284131318330765\n",
      "Epoch 695, Loss: 0.13469933345913887, Final Batch Loss: 0.09256938844919205\n",
      "Epoch 696, Loss: 0.11548551544547081, Final Batch Loss: 0.06989607959985733\n",
      "Epoch 697, Loss: 0.13474244624376297, Final Batch Loss: 0.07162117958068848\n",
      "Epoch 698, Loss: 0.10617387294769287, Final Batch Loss: 0.06675585359334946\n",
      "Epoch 699, Loss: 0.16081806272268295, Final Batch Loss: 0.06344695389270782\n",
      "Epoch 700, Loss: 0.13696956634521484, Final Batch Loss: 0.06651192903518677\n",
      "Epoch 701, Loss: 0.1503516137599945, Final Batch Loss: 0.07575948536396027\n",
      "Epoch 702, Loss: 0.10910648107528687, Final Batch Loss: 0.05017319321632385\n",
      "Epoch 703, Loss: 0.13746154308319092, Final Batch Loss: 0.07355157285928726\n",
      "Epoch 704, Loss: 0.12103313952684402, Final Batch Loss: 0.05519593507051468\n",
      "Epoch 705, Loss: 0.12909231707453728, Final Batch Loss: 0.07680181413888931\n",
      "Epoch 706, Loss: 0.11176278814673424, Final Batch Loss: 0.04326549544930458\n",
      "Epoch 707, Loss: 0.15147440135478973, Final Batch Loss: 0.0781276598572731\n",
      "Epoch 708, Loss: 0.1451999768614769, Final Batch Loss: 0.041970089077949524\n",
      "Epoch 709, Loss: 0.13710162416100502, Final Batch Loss: 0.054761070758104324\n",
      "Epoch 710, Loss: 0.12719912827014923, Final Batch Loss: 0.06703127920627594\n",
      "Epoch 711, Loss: 0.11612503603100777, Final Batch Loss: 0.07812348008155823\n",
      "Epoch 712, Loss: 0.1448015160858631, Final Batch Loss: 0.09648669511079788\n",
      "Epoch 713, Loss: 0.1667209044098854, Final Batch Loss: 0.08619450777769089\n",
      "Epoch 714, Loss: 0.12871826440095901, Final Batch Loss: 0.05415260046720505\n",
      "Epoch 715, Loss: 0.15381088107824326, Final Batch Loss: 0.07064549624919891\n",
      "Epoch 716, Loss: 0.14083672314882278, Final Batch Loss: 0.07173558324575424\n",
      "Epoch 717, Loss: 0.1291227973997593, Final Batch Loss: 0.06713712960481644\n",
      "Epoch 718, Loss: 0.11145999282598495, Final Batch Loss: 0.05312558636069298\n",
      "Epoch 719, Loss: 0.10205232352018356, Final Batch Loss: 0.042711883783340454\n",
      "Epoch 720, Loss: 0.17790234833955765, Final Batch Loss: 0.12523388862609863\n",
      "Epoch 721, Loss: 0.13244498148560524, Final Batch Loss: 0.05707303062081337\n",
      "Epoch 722, Loss: 0.11478135734796524, Final Batch Loss: 0.052069954574108124\n",
      "Epoch 723, Loss: 0.09268804639577866, Final Batch Loss: 0.053996577858924866\n",
      "Epoch 724, Loss: 0.10851020365953445, Final Batch Loss: 0.050293680280447006\n",
      "Epoch 725, Loss: 0.1067935898900032, Final Batch Loss: 0.05623474717140198\n",
      "Epoch 726, Loss: 0.1482444629073143, Final Batch Loss: 0.088737852871418\n",
      "Epoch 727, Loss: 0.15042448788881302, Final Batch Loss: 0.0672420859336853\n",
      "Epoch 728, Loss: 0.14112439006567, Final Batch Loss: 0.0681595727801323\n",
      "Epoch 729, Loss: 0.16538927890360355, Final Batch Loss: 0.1371878832578659\n",
      "Epoch 730, Loss: 0.13819728791713715, Final Batch Loss: 0.07146354764699936\n",
      "Epoch 731, Loss: 0.17313824594020844, Final Batch Loss: 0.09575899690389633\n",
      "Epoch 732, Loss: 0.10218632966279984, Final Batch Loss: 0.018685072660446167\n",
      "Epoch 733, Loss: 0.10108117386698723, Final Batch Loss: 0.03563672676682472\n",
      "Epoch 734, Loss: 0.10133742541074753, Final Batch Loss: 0.03979232534766197\n",
      "Epoch 735, Loss: 0.1282251738011837, Final Batch Loss: 0.0463421605527401\n",
      "Epoch 736, Loss: 0.11471910402178764, Final Batch Loss: 0.05394686758518219\n",
      "Epoch 737, Loss: 0.10425993427634239, Final Batch Loss: 0.042505860328674316\n",
      "Epoch 738, Loss: 0.1182139664888382, Final Batch Loss: 0.06545298546552658\n",
      "Epoch 739, Loss: 0.19987747073173523, Final Batch Loss: 0.12713438272476196\n",
      "Epoch 740, Loss: 0.1242382638156414, Final Batch Loss: 0.04028640314936638\n",
      "Epoch 741, Loss: 0.14901922643184662, Final Batch Loss: 0.09484023600816727\n",
      "Epoch 742, Loss: 0.11891267448663712, Final Batch Loss: 0.046613454818725586\n",
      "Epoch 743, Loss: 0.10790621489286423, Final Batch Loss: 0.070272296667099\n",
      "Epoch 744, Loss: 0.12274553999304771, Final Batch Loss: 0.05593434348702431\n",
      "Epoch 745, Loss: 0.11127391830086708, Final Batch Loss: 0.043470095843076706\n",
      "Epoch 746, Loss: 0.10605153441429138, Final Batch Loss: 0.04800185188651085\n",
      "Epoch 747, Loss: 0.09733575209975243, Final Batch Loss: 0.04994513839483261\n",
      "Epoch 748, Loss: 0.11547373235225677, Final Batch Loss: 0.059116143733263016\n",
      "Epoch 749, Loss: 0.08929752558469772, Final Batch Loss: 0.05074898898601532\n",
      "Epoch 750, Loss: 0.17219164222478867, Final Batch Loss: 0.0726974606513977\n",
      "Epoch 751, Loss: 0.1277117319405079, Final Batch Loss: 0.06061122938990593\n",
      "Epoch 752, Loss: 0.09763938188552856, Final Batch Loss: 0.044020794332027435\n",
      "Epoch 753, Loss: 0.12124500423669815, Final Batch Loss: 0.08386446535587311\n",
      "Epoch 754, Loss: 0.14526768028736115, Final Batch Loss: 0.07589622586965561\n",
      "Epoch 755, Loss: 0.09354451671242714, Final Batch Loss: 0.052178531885147095\n",
      "Epoch 756, Loss: 0.1122642531991005, Final Batch Loss: 0.07490231096744537\n",
      "Epoch 757, Loss: 0.07446092739701271, Final Batch Loss: 0.025900360196828842\n",
      "Epoch 758, Loss: 0.09727266430854797, Final Batch Loss: 0.029039524495601654\n",
      "Epoch 759, Loss: 0.12628967314958572, Final Batch Loss: 0.06321030855178833\n",
      "Epoch 760, Loss: 0.09126117080450058, Final Batch Loss: 0.04368756711483002\n",
      "Epoch 761, Loss: 0.08698586747050285, Final Batch Loss: 0.04142214357852936\n",
      "Epoch 762, Loss: 0.10599297285079956, Final Batch Loss: 0.05686498060822487\n",
      "Epoch 763, Loss: 0.19940050691366196, Final Batch Loss: 0.10968197882175446\n",
      "Epoch 764, Loss: 0.14157341420650482, Final Batch Loss: 0.07335047423839569\n",
      "Epoch 765, Loss: 0.13705088570713997, Final Batch Loss: 0.09835271537303925\n",
      "Epoch 766, Loss: 0.09325997903943062, Final Batch Loss: 0.024978164583444595\n",
      "Epoch 767, Loss: 0.09133337065577507, Final Batch Loss: 0.038831938058137894\n",
      "Epoch 768, Loss: 0.14491762220859528, Final Batch Loss: 0.07545297592878342\n",
      "Epoch 769, Loss: 0.09667845070362091, Final Batch Loss: 0.029880017042160034\n",
      "Epoch 770, Loss: 0.12494846805930138, Final Batch Loss: 0.06104044243693352\n",
      "Epoch 771, Loss: 0.10493514314293861, Final Batch Loss: 0.06837731599807739\n",
      "Epoch 772, Loss: 0.08612086623907089, Final Batch Loss: 0.04557471722364426\n",
      "Epoch 773, Loss: 0.12620003521442413, Final Batch Loss: 0.06385380774736404\n",
      "Epoch 774, Loss: 0.15361186116933823, Final Batch Loss: 0.08249311149120331\n",
      "Epoch 775, Loss: 0.10353245958685875, Final Batch Loss: 0.03324897214770317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 776, Loss: 0.09110846742987633, Final Batch Loss: 0.05513140931725502\n",
      "Epoch 777, Loss: 0.13844333961606026, Final Batch Loss: 0.05630382522940636\n",
      "Epoch 778, Loss: 0.11104381084442139, Final Batch Loss: 0.039915747940540314\n",
      "Epoch 779, Loss: 0.11223975569009781, Final Batch Loss: 0.04294510930776596\n",
      "Epoch 780, Loss: 0.1242426373064518, Final Batch Loss: 0.05170624330639839\n",
      "Epoch 781, Loss: 0.11074528098106384, Final Batch Loss: 0.045245952904224396\n",
      "Epoch 782, Loss: 0.11046964302659035, Final Batch Loss: 0.02318701520562172\n",
      "Epoch 783, Loss: 0.11136423796415329, Final Batch Loss: 0.048382848501205444\n",
      "Epoch 784, Loss: 0.09742869436740875, Final Batch Loss: 0.05223322659730911\n",
      "Epoch 785, Loss: 0.11802402511239052, Final Batch Loss: 0.064963199198246\n",
      "Epoch 786, Loss: 0.0853000283241272, Final Batch Loss: 0.050442278385162354\n",
      "Epoch 787, Loss: 0.08182007074356079, Final Batch Loss: 0.03575548902153969\n",
      "Epoch 788, Loss: 0.057222189381718636, Final Batch Loss: 0.0313161164522171\n",
      "Epoch 789, Loss: 0.09946854412555695, Final Batch Loss: 0.05292663350701332\n",
      "Epoch 790, Loss: 0.09470343589782715, Final Batch Loss: 0.05981670320034027\n",
      "Epoch 791, Loss: 0.12557947263121605, Final Batch Loss: 0.08713828772306442\n",
      "Epoch 792, Loss: 0.09335034713149071, Final Batch Loss: 0.05303836986422539\n",
      "Epoch 793, Loss: 0.14222883433103561, Final Batch Loss: 0.07786059379577637\n",
      "Epoch 794, Loss: 0.08973857387900352, Final Batch Loss: 0.02648111805319786\n",
      "Epoch 795, Loss: 0.2433052435517311, Final Batch Loss: 0.1536492556333542\n",
      "Epoch 796, Loss: 0.08408376201987267, Final Batch Loss: 0.03631091117858887\n",
      "Epoch 797, Loss: 0.08786791935563087, Final Batch Loss: 0.03363631293177605\n",
      "Epoch 798, Loss: 0.10567924752831459, Final Batch Loss: 0.062502421438694\n",
      "Epoch 799, Loss: 0.09933946840465069, Final Batch Loss: 0.07281902432441711\n",
      "Epoch 800, Loss: 0.11125901341438293, Final Batch Loss: 0.023849695920944214\n",
      "Epoch 801, Loss: 0.12524161115288734, Final Batch Loss: 0.0874154269695282\n",
      "Epoch 802, Loss: 0.17155898362398148, Final Batch Loss: 0.09144679456949234\n",
      "Epoch 803, Loss: 0.10595719888806343, Final Batch Loss: 0.06851176172494888\n",
      "Epoch 804, Loss: 0.11083756014704704, Final Batch Loss: 0.042551230639219284\n",
      "Epoch 805, Loss: 0.15176984667778015, Final Batch Loss: 0.09216189384460449\n",
      "Epoch 806, Loss: 0.21348179876804352, Final Batch Loss: 0.15538406372070312\n",
      "Epoch 807, Loss: 0.10770736634731293, Final Batch Loss: 0.04352413862943649\n",
      "Epoch 808, Loss: 0.1758209988474846, Final Batch Loss: 0.11308407038450241\n",
      "Epoch 809, Loss: 0.11836664006114006, Final Batch Loss: 0.04709697887301445\n",
      "Epoch 810, Loss: 0.11108729988336563, Final Batch Loss: 0.04367394745349884\n",
      "Epoch 811, Loss: 0.1051531508564949, Final Batch Loss: 0.0436568446457386\n",
      "Epoch 812, Loss: 0.06747036427259445, Final Batch Loss: 0.04111555963754654\n",
      "Epoch 813, Loss: 0.12722114473581314, Final Batch Loss: 0.08148343116044998\n",
      "Epoch 814, Loss: 0.09788554906845093, Final Batch Loss: 0.05279136076569557\n",
      "Epoch 815, Loss: 0.09447405859827995, Final Batch Loss: 0.03151572123169899\n",
      "Epoch 816, Loss: 0.0848408155143261, Final Batch Loss: 0.03432167321443558\n",
      "Epoch 817, Loss: 0.1972457766532898, Final Batch Loss: 0.07971058785915375\n",
      "Epoch 818, Loss: 0.1102127693593502, Final Batch Loss: 0.0775485709309578\n",
      "Epoch 819, Loss: 0.115184236317873, Final Batch Loss: 0.07982642948627472\n",
      "Epoch 820, Loss: 0.18318933248519897, Final Batch Loss: 0.12172897905111313\n",
      "Epoch 821, Loss: 0.1331503614783287, Final Batch Loss: 0.06777150928974152\n",
      "Epoch 822, Loss: 0.12613985687494278, Final Batch Loss: 0.07673502713441849\n",
      "Epoch 823, Loss: 0.13893652707338333, Final Batch Loss: 0.07420863211154938\n",
      "Epoch 824, Loss: 0.14860009402036667, Final Batch Loss: 0.03509952872991562\n",
      "Epoch 825, Loss: 0.09401868097484112, Final Batch Loss: 0.030855095013976097\n",
      "Epoch 826, Loss: 0.12335516884922981, Final Batch Loss: 0.07814773917198181\n",
      "Epoch 827, Loss: 0.13841595500707626, Final Batch Loss: 0.06204599142074585\n",
      "Epoch 828, Loss: 0.1100093349814415, Final Batch Loss: 0.05170196667313576\n",
      "Epoch 829, Loss: 0.11033013090491295, Final Batch Loss: 0.04542744532227516\n",
      "Epoch 830, Loss: 0.10629122331738472, Final Batch Loss: 0.05462328717112541\n",
      "Epoch 831, Loss: 0.08547650277614594, Final Batch Loss: 0.048751551657915115\n",
      "Epoch 832, Loss: 0.08923991769552231, Final Batch Loss: 0.04735701158642769\n",
      "Epoch 833, Loss: 0.13379313796758652, Final Batch Loss: 0.09072104096412659\n",
      "Epoch 834, Loss: 0.1051245890557766, Final Batch Loss: 0.05463296175003052\n",
      "Epoch 835, Loss: 0.07827262952923775, Final Batch Loss: 0.03657897934317589\n",
      "Epoch 836, Loss: 0.09678908810019493, Final Batch Loss: 0.028141897171735764\n",
      "Epoch 837, Loss: 0.1395057775080204, Final Batch Loss: 0.08825121819972992\n",
      "Epoch 838, Loss: 0.07046585530042648, Final Batch Loss: 0.03294811770319939\n",
      "Epoch 839, Loss: 0.11129973828792572, Final Batch Loss: 0.07671492546796799\n",
      "Epoch 840, Loss: 0.09458281472325325, Final Batch Loss: 0.0486462339758873\n",
      "Epoch 841, Loss: 0.08745476603507996, Final Batch Loss: 0.0311584509909153\n",
      "Epoch 842, Loss: 0.09632210806012154, Final Batch Loss: 0.06153034791350365\n",
      "Epoch 843, Loss: 0.1074746884405613, Final Batch Loss: 0.03321107104420662\n",
      "Epoch 844, Loss: 0.10726002603769302, Final Batch Loss: 0.05754707753658295\n",
      "Epoch 845, Loss: 0.10931313037872314, Final Batch Loss: 0.041426174342632294\n",
      "Epoch 846, Loss: 0.10033548250794411, Final Batch Loss: 0.0500217005610466\n",
      "Epoch 847, Loss: 0.07551327347755432, Final Batch Loss: 0.03436277434229851\n",
      "Epoch 848, Loss: 0.09669171273708344, Final Batch Loss: 0.031632669270038605\n",
      "Epoch 849, Loss: 0.08761545643210411, Final Batch Loss: 0.03933580964803696\n",
      "Epoch 850, Loss: 0.08705868385732174, Final Batch Loss: 0.0302406158298254\n",
      "Epoch 851, Loss: 0.05968824401497841, Final Batch Loss: 0.0249159038066864\n",
      "Epoch 852, Loss: 0.10784484446048737, Final Batch Loss: 0.027576953172683716\n",
      "Epoch 853, Loss: 0.10271073505282402, Final Batch Loss: 0.042285703122615814\n",
      "Epoch 854, Loss: 0.07595987431704998, Final Batch Loss: 0.052612125873565674\n",
      "Epoch 855, Loss: 0.1469360813498497, Final Batch Loss: 0.0544222891330719\n",
      "Epoch 856, Loss: 0.16206572949886322, Final Batch Loss: 0.09045032411813736\n",
      "Epoch 857, Loss: 0.13380028307437897, Final Batch Loss: 0.062154971063137054\n",
      "Epoch 858, Loss: 0.09188881888985634, Final Batch Loss: 0.046780604869127274\n",
      "Epoch 859, Loss: 0.1139192134141922, Final Batch Loss: 0.07002296298742294\n",
      "Epoch 860, Loss: 0.08864285424351692, Final Batch Loss: 0.0415542870759964\n",
      "Epoch 861, Loss: 0.11790886148810387, Final Batch Loss: 0.05996667966246605\n",
      "Epoch 862, Loss: 0.07279859855771065, Final Batch Loss: 0.03924708440899849\n",
      "Epoch 863, Loss: 0.09631788358092308, Final Batch Loss: 0.059297334402799606\n",
      "Epoch 864, Loss: 0.1033702865242958, Final Batch Loss: 0.0456337034702301\n",
      "Epoch 865, Loss: 0.0850733146071434, Final Batch Loss: 0.05422878637909889\n",
      "Epoch 866, Loss: 0.09947583451867104, Final Batch Loss: 0.05926937982439995\n",
      "Epoch 867, Loss: 0.055116383358836174, Final Batch Loss: 0.02235175482928753\n",
      "Epoch 868, Loss: 0.08395049534738064, Final Batch Loss: 0.028742292895913124\n",
      "Epoch 869, Loss: 0.07197804562747478, Final Batch Loss: 0.044438403099775314\n",
      "Epoch 870, Loss: 0.09490689635276794, Final Batch Loss: 0.06361927837133408\n",
      "Epoch 871, Loss: 0.07561750710010529, Final Batch Loss: 0.029988285154104233\n",
      "Epoch 872, Loss: 0.09557531028985977, Final Batch Loss: 0.046745412051677704\n",
      "Epoch 873, Loss: 0.08821921795606613, Final Batch Loss: 0.03842610865831375\n",
      "Epoch 874, Loss: 0.0841387826949358, Final Batch Loss: 0.0561191700398922\n",
      "Epoch 875, Loss: 0.08675810135900974, Final Batch Loss: 0.026994457468390465\n",
      "Epoch 876, Loss: 0.1071881651878357, Final Batch Loss: 0.05914107710123062\n",
      "Epoch 877, Loss: 0.06580022722482681, Final Batch Loss: 0.020542386919260025\n",
      "Epoch 878, Loss: 0.10028183832764626, Final Batch Loss: 0.046107836067676544\n",
      "Epoch 879, Loss: 0.0685153529047966, Final Batch Loss: 0.032302647829055786\n",
      "Epoch 880, Loss: 0.09142741560935974, Final Batch Loss: 0.031075812876224518\n",
      "Epoch 881, Loss: 0.05986788868904114, Final Batch Loss: 0.02802015095949173\n",
      "Epoch 882, Loss: 0.10725260153412819, Final Batch Loss: 0.03538898751139641\n",
      "Epoch 883, Loss: 0.053949497640132904, Final Batch Loss: 0.03357459977269173\n",
      "Epoch 884, Loss: 0.09862849302589893, Final Batch Loss: 0.0701148733496666\n",
      "Epoch 885, Loss: 0.09444034472107887, Final Batch Loss: 0.05382581427693367\n",
      "Epoch 886, Loss: 0.07037461176514626, Final Batch Loss: 0.03955577313899994\n",
      "Epoch 887, Loss: 0.06962400302290916, Final Batch Loss: 0.03908945247530937\n",
      "Epoch 888, Loss: 0.12618395313620567, Final Batch Loss: 0.04862029477953911\n",
      "Epoch 889, Loss: 0.10602669417858124, Final Batch Loss: 0.045910097658634186\n",
      "Epoch 890, Loss: 0.08142506331205368, Final Batch Loss: 0.04403778538107872\n",
      "Epoch 891, Loss: 0.07456554286181927, Final Batch Loss: 0.01939903013408184\n",
      "Epoch 892, Loss: 0.07290010899305344, Final Batch Loss: 0.03429673984646797\n",
      "Epoch 893, Loss: 0.04787677712738514, Final Batch Loss: 0.024709533900022507\n",
      "Epoch 894, Loss: 0.07580425031483173, Final Batch Loss: 0.025024289265275\n",
      "Epoch 895, Loss: 0.05247296579182148, Final Batch Loss: 0.012622380629181862\n",
      "Epoch 896, Loss: 0.082290543243289, Final Batch Loss: 0.05217282846570015\n",
      "Epoch 897, Loss: 0.1106950119137764, Final Batch Loss: 0.04300703853368759\n",
      "Epoch 898, Loss: 0.08255093172192574, Final Batch Loss: 0.044975265860557556\n",
      "Epoch 899, Loss: 0.09527052193880081, Final Batch Loss: 0.058527108281850815\n",
      "Epoch 900, Loss: 0.13041413575410843, Final Batch Loss: 0.048216529190540314\n",
      "Epoch 901, Loss: 0.0775588471442461, Final Batch Loss: 0.030269937589764595\n",
      "Epoch 902, Loss: 0.07494936883449554, Final Batch Loss: 0.036662496626377106\n",
      "Epoch 903, Loss: 0.09381083026528358, Final Batch Loss: 0.045405492186546326\n",
      "Epoch 904, Loss: 0.14920135587453842, Final Batch Loss: 0.11100506037473679\n",
      "Epoch 905, Loss: 0.07725358381867409, Final Batch Loss: 0.037797801196575165\n",
      "Epoch 906, Loss: 0.11434090510010719, Final Batch Loss: 0.06116720661520958\n",
      "Epoch 907, Loss: 0.09744005650281906, Final Batch Loss: 0.03802095726132393\n",
      "Epoch 908, Loss: 0.11319739371538162, Final Batch Loss: 0.06232133507728577\n",
      "Epoch 909, Loss: 0.1446404978632927, Final Batch Loss: 0.04814421385526657\n",
      "Epoch 910, Loss: 0.09362288936972618, Final Batch Loss: 0.04697728157043457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911, Loss: 0.12304459512233734, Final Batch Loss: 0.07475559413433075\n",
      "Epoch 912, Loss: 0.1016041673719883, Final Batch Loss: 0.04655933007597923\n",
      "Epoch 913, Loss: 0.10984019190073013, Final Batch Loss: 0.06511788815259933\n",
      "Epoch 914, Loss: 0.07831765525043011, Final Batch Loss: 0.02186770550906658\n",
      "Epoch 915, Loss: 0.07427515834569931, Final Batch Loss: 0.03908708319067955\n",
      "Epoch 916, Loss: 0.068028399720788, Final Batch Loss: 0.030025461688637733\n",
      "Epoch 917, Loss: 0.127704668790102, Final Batch Loss: 0.07858835160732269\n",
      "Epoch 918, Loss: 0.10828055813908577, Final Batch Loss: 0.043067362159490585\n",
      "Epoch 919, Loss: 0.09781491570174694, Final Batch Loss: 0.02733629010617733\n",
      "Epoch 920, Loss: 0.11272638663649559, Final Batch Loss: 0.02905235067009926\n",
      "Epoch 921, Loss: 0.11651775613427162, Final Batch Loss: 0.05340367183089256\n",
      "Epoch 922, Loss: 0.07424116879701614, Final Batch Loss: 0.02899390459060669\n",
      "Epoch 923, Loss: 0.09897218272089958, Final Batch Loss: 0.06108484044671059\n",
      "Epoch 924, Loss: 0.06536087207496166, Final Batch Loss: 0.013930005952715874\n",
      "Epoch 925, Loss: 0.09479084238409996, Final Batch Loss: 0.04874451830983162\n",
      "Epoch 926, Loss: 0.10851209983229637, Final Batch Loss: 0.06570810079574585\n",
      "Epoch 927, Loss: 0.12623700127005577, Final Batch Loss: 0.0868983268737793\n",
      "Epoch 928, Loss: 0.12680338695645332, Final Batch Loss: 0.0915207713842392\n",
      "Epoch 929, Loss: 0.10353288054466248, Final Batch Loss: 0.04202684387564659\n",
      "Epoch 930, Loss: 0.09752426669001579, Final Batch Loss: 0.03973037376999855\n",
      "Epoch 931, Loss: 0.12251962348818779, Final Batch Loss: 0.037566039711236954\n",
      "Epoch 932, Loss: 0.0804978534579277, Final Batch Loss: 0.04176919534802437\n",
      "Epoch 933, Loss: 0.12916091457009315, Final Batch Loss: 0.07470789551734924\n",
      "Epoch 934, Loss: 0.0619039349257946, Final Batch Loss: 0.02393864467740059\n",
      "Epoch 935, Loss: 0.09592849388718605, Final Batch Loss: 0.06897444278001785\n",
      "Epoch 936, Loss: 0.08351486921310425, Final Batch Loss: 0.03203018009662628\n",
      "Epoch 937, Loss: 0.10349280014634132, Final Batch Loss: 0.03403094783425331\n",
      "Epoch 938, Loss: 0.11346342787146568, Final Batch Loss: 0.05656364560127258\n",
      "Epoch 939, Loss: 0.11163734644651413, Final Batch Loss: 0.057556070387363434\n",
      "Epoch 940, Loss: 0.08246023766696453, Final Batch Loss: 0.053389061242341995\n",
      "Epoch 941, Loss: 0.056269810535013676, Final Batch Loss: 0.010803678072988987\n",
      "Epoch 942, Loss: 0.08284617215394974, Final Batch Loss: 0.032874345779418945\n",
      "Epoch 943, Loss: 0.08182839304208755, Final Batch Loss: 0.04318505525588989\n",
      "Epoch 944, Loss: 0.12463758885860443, Final Batch Loss: 0.047503761947155\n",
      "Epoch 945, Loss: 0.04190303012728691, Final Batch Loss: 0.015565801411867142\n",
      "Epoch 946, Loss: 0.08974569290876389, Final Batch Loss: 0.03934754058718681\n",
      "Epoch 947, Loss: 0.0716397650539875, Final Batch Loss: 0.03504692018032074\n",
      "Epoch 948, Loss: 0.09351183474063873, Final Batch Loss: 0.04270064830780029\n",
      "Epoch 949, Loss: 0.07694016583263874, Final Batch Loss: 0.0488947331905365\n",
      "Epoch 950, Loss: 0.09673362225294113, Final Batch Loss: 0.06836128979921341\n",
      "Epoch 951, Loss: 0.08355783298611641, Final Batch Loss: 0.03006862848997116\n",
      "Epoch 952, Loss: 0.07047819159924984, Final Batch Loss: 0.039427079260349274\n",
      "Epoch 953, Loss: 0.08866948448121548, Final Batch Loss: 0.061504706740379333\n",
      "Epoch 954, Loss: 0.0723852813243866, Final Batch Loss: 0.034794628620147705\n",
      "Epoch 955, Loss: 0.10724612325429916, Final Batch Loss: 0.04353693872690201\n",
      "Epoch 956, Loss: 0.060591692104935646, Final Batch Loss: 0.029007697477936745\n",
      "Epoch 957, Loss: 0.058796992525458336, Final Batch Loss: 0.036680035293102264\n",
      "Epoch 958, Loss: 0.10925266891717911, Final Batch Loss: 0.06122932210564613\n",
      "Epoch 959, Loss: 0.13228845596313477, Final Batch Loss: 0.09056146442890167\n",
      "Epoch 960, Loss: 0.12665480747818947, Final Batch Loss: 0.07313835620880127\n",
      "Epoch 961, Loss: 0.049146274104714394, Final Batch Loss: 0.023078955709934235\n",
      "Epoch 962, Loss: 0.11635971814393997, Final Batch Loss: 0.07902157306671143\n",
      "Epoch 963, Loss: 0.080018550157547, Final Batch Loss: 0.04053634777665138\n",
      "Epoch 964, Loss: 0.12150346487760544, Final Batch Loss: 0.05712958425283432\n",
      "Epoch 965, Loss: 0.11583986133337021, Final Batch Loss: 0.08272591978311539\n",
      "Epoch 966, Loss: 0.104904405772686, Final Batch Loss: 0.0646098181605339\n",
      "Epoch 967, Loss: 0.11111342906951904, Final Batch Loss: 0.05456661805510521\n",
      "Epoch 968, Loss: 0.12986129149794579, Final Batch Loss: 0.08997213840484619\n",
      "Epoch 969, Loss: 0.10932283662259579, Final Batch Loss: 0.031097298488020897\n",
      "Epoch 970, Loss: 0.13914106786251068, Final Batch Loss: 0.07539903372526169\n",
      "Epoch 971, Loss: 0.12166709080338478, Final Batch Loss: 0.07082564383745193\n",
      "Epoch 972, Loss: 0.1303909532725811, Final Batch Loss: 0.0961921215057373\n",
      "Epoch 973, Loss: 0.12305906787514687, Final Batch Loss: 0.06290524452924728\n",
      "Epoch 974, Loss: 0.12416380271315575, Final Batch Loss: 0.07108377665281296\n",
      "Epoch 975, Loss: 0.1299676038324833, Final Batch Loss: 0.05839439108967781\n",
      "Epoch 976, Loss: 0.16704392060637474, Final Batch Loss: 0.12561844289302826\n",
      "Epoch 977, Loss: 0.1826806515455246, Final Batch Loss: 0.09384628385305405\n",
      "Epoch 978, Loss: 0.11683544889092445, Final Batch Loss: 0.0770278051495552\n",
      "Epoch 979, Loss: 0.07127246260643005, Final Batch Loss: 0.05031481757760048\n",
      "Epoch 980, Loss: 0.16258013993501663, Final Batch Loss: 0.07830101251602173\n",
      "Epoch 981, Loss: 0.07644053921103477, Final Batch Loss: 0.039009418338537216\n",
      "Epoch 982, Loss: 0.11216366663575172, Final Batch Loss: 0.05841657519340515\n",
      "Epoch 983, Loss: 0.09091838076710701, Final Batch Loss: 0.06055011227726936\n",
      "Epoch 984, Loss: 0.0926140733063221, Final Batch Loss: 0.05918187275528908\n",
      "Epoch 985, Loss: 0.07763530500233173, Final Batch Loss: 0.02385607175529003\n",
      "Epoch 986, Loss: 0.1319168657064438, Final Batch Loss: 0.07079240679740906\n",
      "Epoch 987, Loss: 0.13320688903331757, Final Batch Loss: 0.07056237757205963\n",
      "Epoch 988, Loss: 0.1069899220019579, Final Batch Loss: 0.029097342863678932\n",
      "Epoch 989, Loss: 0.10357010364532471, Final Batch Loss: 0.0404585599899292\n",
      "Epoch 990, Loss: 0.1646033227443695, Final Batch Loss: 0.11390354484319687\n",
      "Epoch 991, Loss: 0.07865843176841736, Final Batch Loss: 0.0450001135468483\n",
      "Epoch 992, Loss: 0.08199165761470795, Final Batch Loss: 0.04096941649913788\n",
      "Epoch 993, Loss: 0.06117675080895424, Final Batch Loss: 0.029372207820415497\n",
      "Epoch 994, Loss: 0.09942066669464111, Final Batch Loss: 0.05321992561221123\n",
      "Epoch 995, Loss: 0.08681415393948555, Final Batch Loss: 0.05541500076651573\n",
      "Epoch 996, Loss: 0.08308247476816177, Final Batch Loss: 0.05482129380106926\n",
      "Epoch 997, Loss: 0.06101304665207863, Final Batch Loss: 0.026800088584423065\n",
      "Epoch 998, Loss: 0.06853319332003593, Final Batch Loss: 0.02843451499938965\n",
      "Epoch 999, Loss: 0.13110095262527466, Final Batch Loss: 0.06757728010416031\n",
      "Epoch 1000, Loss: 0.088449502363801, Final Batch Loss: 0.0670238509774208\n",
      "Epoch 1001, Loss: 0.09595016948878765, Final Batch Loss: 0.027093766257166862\n",
      "Epoch 1002, Loss: 0.07248377986252308, Final Batch Loss: 0.027748337015509605\n",
      "Epoch 1003, Loss: 0.05424189195036888, Final Batch Loss: 0.030315561220049858\n",
      "Epoch 1004, Loss: 0.05570535361766815, Final Batch Loss: 0.019875574856996536\n",
      "Epoch 1005, Loss: 0.09498319029808044, Final Batch Loss: 0.03763439506292343\n",
      "Epoch 1006, Loss: 0.1827046275138855, Final Batch Loss: 0.07976318895816803\n",
      "Epoch 1007, Loss: 0.06910976395010948, Final Batch Loss: 0.03921971470117569\n",
      "Epoch 1008, Loss: 0.05917800962924957, Final Batch Loss: 0.03269870951771736\n",
      "Epoch 1009, Loss: 0.05708924122154713, Final Batch Loss: 0.029067762196063995\n",
      "Epoch 1010, Loss: 0.06584317050874233, Final Batch Loss: 0.036333225667476654\n",
      "Epoch 1011, Loss: 0.1226070299744606, Final Batch Loss: 0.07245778292417526\n",
      "Epoch 1012, Loss: 0.06076960265636444, Final Batch Loss: 0.0413346029818058\n",
      "Epoch 1013, Loss: 0.08266768231987953, Final Batch Loss: 0.038391657173633575\n",
      "Epoch 1014, Loss: 0.09832376800477505, Final Batch Loss: 0.07588169723749161\n",
      "Epoch 1015, Loss: 0.09192321076989174, Final Batch Loss: 0.04512946680188179\n",
      "Epoch 1016, Loss: 0.08786879107356071, Final Batch Loss: 0.032884322106838226\n",
      "Epoch 1017, Loss: 0.08510300703346729, Final Batch Loss: 0.05398942530155182\n",
      "Epoch 1018, Loss: 0.06180160492658615, Final Batch Loss: 0.029892750084400177\n",
      "Epoch 1019, Loss: 0.18632763624191284, Final Batch Loss: 0.0727567970752716\n",
      "Epoch 1020, Loss: 0.0858776830136776, Final Batch Loss: 0.05040218308568001\n",
      "Epoch 1021, Loss: 0.10705117881298065, Final Batch Loss: 0.041142359375953674\n",
      "Epoch 1022, Loss: 0.10887249000370502, Final Batch Loss: 0.029842907562851906\n",
      "Epoch 1023, Loss: 0.0659963134676218, Final Batch Loss: 0.03940819576382637\n",
      "Epoch 1024, Loss: 0.06007205508649349, Final Batch Loss: 0.016661791130900383\n",
      "Epoch 1025, Loss: 0.06991229765117168, Final Batch Loss: 0.046508293598890305\n",
      "Epoch 1026, Loss: 0.08132856152951717, Final Batch Loss: 0.01735936664044857\n",
      "Epoch 1027, Loss: 0.106611467897892, Final Batch Loss: 0.048687662929296494\n",
      "Epoch 1028, Loss: 0.04932633135467768, Final Batch Loss: 0.013802514411509037\n",
      "Epoch 1029, Loss: 0.06490248162299395, Final Batch Loss: 0.01334496308118105\n",
      "Epoch 1030, Loss: 0.08541115000844002, Final Batch Loss: 0.05406845733523369\n",
      "Epoch 1031, Loss: 0.08731718733906746, Final Batch Loss: 0.041934337466955185\n",
      "Epoch 1032, Loss: 0.06265392899513245, Final Batch Loss: 0.023398663848638535\n",
      "Epoch 1033, Loss: 0.07804444618523121, Final Batch Loss: 0.0303263571113348\n",
      "Epoch 1034, Loss: 0.10272739455103874, Final Batch Loss: 0.03904026374220848\n",
      "Epoch 1035, Loss: 0.09661700204014778, Final Batch Loss: 0.04542671889066696\n",
      "Epoch 1036, Loss: 0.10124621726572514, Final Batch Loss: 0.07343106716871262\n",
      "Epoch 1037, Loss: 0.07277443632483482, Final Batch Loss: 0.036582328379154205\n",
      "Epoch 1038, Loss: 0.05466157756745815, Final Batch Loss: 0.031686436384916306\n",
      "Epoch 1039, Loss: 0.07943097874522209, Final Batch Loss: 0.03793342784047127\n",
      "Epoch 1040, Loss: 0.08951818011701107, Final Batch Loss: 0.02863732911646366\n",
      "Epoch 1041, Loss: 0.06430675089359283, Final Batch Loss: 0.023036178201436996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1042, Loss: 0.036969611421227455, Final Batch Loss: 0.015424611046910286\n",
      "Epoch 1043, Loss: 0.09828401356935501, Final Batch Loss: 0.04393019527196884\n",
      "Epoch 1044, Loss: 0.05818159878253937, Final Batch Loss: 0.024492066353559494\n",
      "Epoch 1045, Loss: 0.08665088191628456, Final Batch Loss: 0.04034423828125\n",
      "Epoch 1046, Loss: 0.08000562340021133, Final Batch Loss: 0.05119019001722336\n",
      "Epoch 1047, Loss: 0.09111537784337997, Final Batch Loss: 0.06004459783434868\n",
      "Epoch 1048, Loss: 0.073133185505867, Final Batch Loss: 0.048736367374658585\n",
      "Epoch 1049, Loss: 0.05585429072380066, Final Batch Loss: 0.029629331082105637\n",
      "Epoch 1050, Loss: 0.05222478322684765, Final Batch Loss: 0.020402291789650917\n",
      "Epoch 1051, Loss: 0.08873182535171509, Final Batch Loss: 0.03472649306058884\n",
      "Epoch 1052, Loss: 0.08054488897323608, Final Batch Loss: 0.03953900188207626\n",
      "Epoch 1053, Loss: 0.07683926820755005, Final Batch Loss: 0.050653133541345596\n",
      "Epoch 1054, Loss: 0.06315204128623009, Final Batch Loss: 0.027987804263830185\n",
      "Epoch 1055, Loss: 0.0894184447824955, Final Batch Loss: 0.03073647990822792\n",
      "Epoch 1056, Loss: 0.07474066875874996, Final Batch Loss: 0.023480819538235664\n",
      "Epoch 1057, Loss: 0.05356640927493572, Final Batch Loss: 0.035514723509550095\n",
      "Epoch 1058, Loss: 0.05981111526489258, Final Batch Loss: 0.01638859510421753\n",
      "Epoch 1059, Loss: 0.054773442447185516, Final Batch Loss: 0.02551494911313057\n",
      "Epoch 1060, Loss: 0.05783567391335964, Final Batch Loss: 0.026022987440228462\n",
      "Epoch 1061, Loss: 0.055226054042577744, Final Batch Loss: 0.024154912680387497\n",
      "Epoch 1062, Loss: 0.04899601265788078, Final Batch Loss: 0.02222931571304798\n",
      "Epoch 1063, Loss: 0.05944513715803623, Final Batch Loss: 0.02194720320403576\n",
      "Epoch 1064, Loss: 0.087339723482728, Final Batch Loss: 0.06810429692268372\n",
      "Epoch 1065, Loss: 0.10781774669885635, Final Batch Loss: 0.045021720230579376\n",
      "Epoch 1066, Loss: 0.04334234073758125, Final Batch Loss: 0.015288298949599266\n",
      "Epoch 1067, Loss: 0.07787895575165749, Final Batch Loss: 0.06043555215001106\n",
      "Epoch 1068, Loss: 0.08102524280548096, Final Batch Loss: 0.031440556049346924\n",
      "Epoch 1069, Loss: 0.10057925060391426, Final Batch Loss: 0.06375104933977127\n",
      "Epoch 1070, Loss: 0.07190312631428242, Final Batch Loss: 0.02595321647822857\n",
      "Epoch 1071, Loss: 0.06010906212031841, Final Batch Loss: 0.030341671779751778\n",
      "Epoch 1072, Loss: 0.10528591647744179, Final Batch Loss: 0.07358623296022415\n",
      "Epoch 1073, Loss: 0.055199408903717995, Final Batch Loss: 0.020882951095700264\n",
      "Epoch 1074, Loss: 0.056378076784312725, Final Batch Loss: 0.012824120931327343\n",
      "Epoch 1075, Loss: 0.10749080032110214, Final Batch Loss: 0.07887474447488785\n",
      "Epoch 1076, Loss: 0.0899747870862484, Final Batch Loss: 0.03689182177186012\n",
      "Epoch 1077, Loss: 0.08065248653292656, Final Batch Loss: 0.034822411835193634\n",
      "Epoch 1078, Loss: 0.12522006034851074, Final Batch Loss: 0.06316449493169785\n",
      "Epoch 1079, Loss: 0.05349756218492985, Final Batch Loss: 0.025502298027276993\n",
      "Epoch 1080, Loss: 0.05343305040150881, Final Batch Loss: 0.015120801515877247\n",
      "Epoch 1081, Loss: 0.09417150542140007, Final Batch Loss: 0.053841300308704376\n",
      "Epoch 1082, Loss: 0.0757428016513586, Final Batch Loss: 0.030665820464491844\n",
      "Epoch 1083, Loss: 0.12867701426148415, Final Batch Loss: 0.05245224013924599\n",
      "Epoch 1084, Loss: 0.04830141831189394, Final Batch Loss: 0.012887825258076191\n",
      "Epoch 1085, Loss: 0.046533651649951935, Final Batch Loss: 0.022448809817433357\n",
      "Epoch 1086, Loss: 0.08378945104777813, Final Batch Loss: 0.05306629464030266\n",
      "Epoch 1087, Loss: 0.09125372394919395, Final Batch Loss: 0.06974751502275467\n",
      "Epoch 1088, Loss: 0.048502180725336075, Final Batch Loss: 0.027230875566601753\n",
      "Epoch 1089, Loss: 0.061229366809129715, Final Batch Loss: 0.023065738379955292\n",
      "Epoch 1090, Loss: 0.04032845050096512, Final Batch Loss: 0.017582278698682785\n",
      "Epoch 1091, Loss: 0.05658365972340107, Final Batch Loss: 0.03230840340256691\n",
      "Epoch 1092, Loss: 0.0888481605798006, Final Batch Loss: 0.0631476566195488\n",
      "Epoch 1093, Loss: 0.1125979470089078, Final Batch Loss: 0.014603537507355213\n",
      "Epoch 1094, Loss: 0.08437976241111755, Final Batch Loss: 0.03824296593666077\n",
      "Epoch 1095, Loss: 0.0763290636241436, Final Batch Loss: 0.048025041818618774\n",
      "Epoch 1096, Loss: 0.07638286054134369, Final Batch Loss: 0.04492302983999252\n",
      "Epoch 1097, Loss: 0.050062088295817375, Final Batch Loss: 0.0187689121812582\n",
      "Epoch 1098, Loss: 0.09631398692727089, Final Batch Loss: 0.053519826382398605\n",
      "Epoch 1099, Loss: 0.06903361901640892, Final Batch Loss: 0.017944954335689545\n",
      "Epoch 1100, Loss: 0.06811727583408356, Final Batch Loss: 0.033151350915431976\n",
      "Epoch 1101, Loss: 0.09730158746242523, Final Batch Loss: 0.06718339025974274\n",
      "Epoch 1102, Loss: 0.07591917365789413, Final Batch Loss: 0.04453272745013237\n",
      "Epoch 1103, Loss: 0.0373678682371974, Final Batch Loss: 0.0109620476141572\n",
      "Epoch 1104, Loss: 0.06920931674540043, Final Batch Loss: 0.01561695896089077\n",
      "Epoch 1105, Loss: 0.06575426645576954, Final Batch Loss: 0.02592226304113865\n",
      "Epoch 1106, Loss: 0.04339854419231415, Final Batch Loss: 0.024181513115763664\n",
      "Epoch 1107, Loss: 0.051055943593382835, Final Batch Loss: 0.017151331529021263\n",
      "Epoch 1108, Loss: 0.052563946694135666, Final Batch Loss: 0.015493832528591156\n",
      "Epoch 1109, Loss: 0.0962819829583168, Final Batch Loss: 0.054997220635414124\n",
      "Epoch 1110, Loss: 0.0720959696918726, Final Batch Loss: 0.026339301839470863\n",
      "Epoch 1111, Loss: 0.056202298030257225, Final Batch Loss: 0.02333255670964718\n",
      "Epoch 1112, Loss: 0.07105717435479164, Final Batch Loss: 0.03889108821749687\n",
      "Epoch 1113, Loss: 0.06588679179549217, Final Batch Loss: 0.03209212049841881\n",
      "Epoch 1114, Loss: 0.0637421477586031, Final Batch Loss: 0.0385323129594326\n",
      "Epoch 1115, Loss: 0.09792054072022438, Final Batch Loss: 0.06523513793945312\n",
      "Epoch 1116, Loss: 0.07287968322634697, Final Batch Loss: 0.022849909961223602\n",
      "Epoch 1117, Loss: 0.08416014537215233, Final Batch Loss: 0.05430840700864792\n",
      "Epoch 1118, Loss: 0.11321454122662544, Final Batch Loss: 0.07392387837171555\n",
      "Epoch 1119, Loss: 0.10324662178754807, Final Batch Loss: 0.03797711431980133\n",
      "Epoch 1120, Loss: 0.07843881100416183, Final Batch Loss: 0.03676324337720871\n",
      "Epoch 1121, Loss: 0.08487583324313164, Final Batch Loss: 0.02940443530678749\n",
      "Epoch 1122, Loss: 0.07455431297421455, Final Batch Loss: 0.03647680953145027\n",
      "Epoch 1123, Loss: 0.13700733333826065, Final Batch Loss: 0.09049789607524872\n",
      "Epoch 1124, Loss: 0.08105912432074547, Final Batch Loss: 0.031877126544713974\n",
      "Epoch 1125, Loss: 0.09674441441893578, Final Batch Loss: 0.0516425184905529\n",
      "Epoch 1126, Loss: 0.0841386653482914, Final Batch Loss: 0.0371791310608387\n",
      "Epoch 1127, Loss: 0.12464889138936996, Final Batch Loss: 0.08753254264593124\n",
      "Epoch 1128, Loss: 0.07537876442074776, Final Batch Loss: 0.022924959659576416\n",
      "Epoch 1129, Loss: 0.07369767129421234, Final Batch Loss: 0.044507771730422974\n",
      "Epoch 1130, Loss: 0.07640447467565536, Final Batch Loss: 0.04319199547171593\n",
      "Epoch 1131, Loss: 0.07119700685143471, Final Batch Loss: 0.022399481385946274\n",
      "Epoch 1132, Loss: 0.07516557350754738, Final Batch Loss: 0.032297585159540176\n",
      "Epoch 1133, Loss: 0.053927358239889145, Final Batch Loss: 0.02730838768184185\n",
      "Epoch 1134, Loss: 0.07786905765533447, Final Batch Loss: 0.03791007027029991\n",
      "Epoch 1135, Loss: 0.06671229377388954, Final Batch Loss: 0.023104242980480194\n",
      "Epoch 1136, Loss: 0.06801077350974083, Final Batch Loss: 0.027864061295986176\n",
      "Epoch 1137, Loss: 0.051736755296587944, Final Batch Loss: 0.016910186037421227\n",
      "Epoch 1138, Loss: 0.08146703615784645, Final Batch Loss: 0.05749114975333214\n",
      "Epoch 1139, Loss: 0.05452887341380119, Final Batch Loss: 0.03415004163980484\n",
      "Epoch 1140, Loss: 0.04161384887993336, Final Batch Loss: 0.02299848012626171\n",
      "Epoch 1141, Loss: 0.04705817997455597, Final Batch Loss: 0.01563732698559761\n",
      "Epoch 1142, Loss: 0.0666777677834034, Final Batch Loss: 0.028931140899658203\n",
      "Epoch 1143, Loss: 0.03844329435378313, Final Batch Loss: 0.0057962993159890175\n",
      "Epoch 1144, Loss: 0.05393759720027447, Final Batch Loss: 0.015726933255791664\n",
      "Epoch 1145, Loss: 0.05706528201699257, Final Batch Loss: 0.029094796627759933\n",
      "Epoch 1146, Loss: 0.09021840244531631, Final Batch Loss: 0.053013838827610016\n",
      "Epoch 1147, Loss: 0.04561482556164265, Final Batch Loss: 0.01838688552379608\n",
      "Epoch 1148, Loss: 0.07068632170557976, Final Batch Loss: 0.05242728441953659\n",
      "Epoch 1149, Loss: 0.05519748292863369, Final Batch Loss: 0.028490418568253517\n",
      "Epoch 1150, Loss: 0.040470357052981853, Final Batch Loss: 0.01506930310279131\n",
      "Epoch 1151, Loss: 0.09419752471148968, Final Batch Loss: 0.0773962140083313\n",
      "Epoch 1152, Loss: 0.04352645017206669, Final Batch Loss: 0.016972307115793228\n",
      "Epoch 1153, Loss: 0.1213237252086401, Final Batch Loss: 0.09817303717136383\n",
      "Epoch 1154, Loss: 0.07036363705992699, Final Batch Loss: 0.03466774523258209\n",
      "Epoch 1155, Loss: 0.07776438817381859, Final Batch Loss: 0.02694718912243843\n",
      "Epoch 1156, Loss: 0.061136605218052864, Final Batch Loss: 0.03233397379517555\n",
      "Epoch 1157, Loss: 0.0684789065271616, Final Batch Loss: 0.043949998915195465\n",
      "Epoch 1158, Loss: 0.06693047657608986, Final Batch Loss: 0.026562005281448364\n",
      "Epoch 1159, Loss: 0.08549916185438633, Final Batch Loss: 0.02746526710689068\n",
      "Epoch 1160, Loss: 0.06467641703784466, Final Batch Loss: 0.03744090348482132\n",
      "Epoch 1161, Loss: 0.0545097254216671, Final Batch Loss: 0.027119949460029602\n",
      "Epoch 1162, Loss: 0.04320818372070789, Final Batch Loss: 0.021849920973181725\n",
      "Epoch 1163, Loss: 0.11794534139335155, Final Batch Loss: 0.0948847234249115\n",
      "Epoch 1164, Loss: 0.07858527824282646, Final Batch Loss: 0.04128912091255188\n",
      "Epoch 1165, Loss: 0.10051416233181953, Final Batch Loss: 0.039728425443172455\n",
      "Epoch 1166, Loss: 0.06673664879053831, Final Batch Loss: 0.05283726006746292\n",
      "Epoch 1167, Loss: 0.16948563791811466, Final Batch Loss: 0.15090595185756683\n",
      "Epoch 1168, Loss: 0.06740535423159599, Final Batch Loss: 0.041949376463890076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1169, Loss: 0.13939252495765686, Final Batch Loss: 0.07174407690763474\n",
      "Epoch 1170, Loss: 0.12216850370168686, Final Batch Loss: 0.06592966616153717\n",
      "Epoch 1171, Loss: 0.06791406124830246, Final Batch Loss: 0.03397074714303017\n",
      "Epoch 1172, Loss: 0.0696855578571558, Final Batch Loss: 0.02888551540672779\n",
      "Epoch 1173, Loss: 0.08153103291988373, Final Batch Loss: 0.05228094756603241\n",
      "Epoch 1174, Loss: 0.09926486387848854, Final Batch Loss: 0.04174100235104561\n",
      "Epoch 1175, Loss: 0.04312039352953434, Final Batch Loss: 0.015640975907444954\n",
      "Epoch 1176, Loss: 0.05559684336185455, Final Batch Loss: 0.03300432488322258\n",
      "Epoch 1177, Loss: 0.0645713098347187, Final Batch Loss: 0.04703482612967491\n",
      "Epoch 1178, Loss: 0.055130915716290474, Final Batch Loss: 0.015751944854855537\n",
      "Epoch 1179, Loss: 0.03787834569811821, Final Batch Loss: 0.016411179676651955\n",
      "Epoch 1180, Loss: 0.06786760501563549, Final Batch Loss: 0.03050110675394535\n",
      "Epoch 1181, Loss: 0.05480003170669079, Final Batch Loss: 0.030667677521705627\n",
      "Epoch 1182, Loss: 0.09749065712094307, Final Batch Loss: 0.03889046236872673\n",
      "Epoch 1183, Loss: 0.08954156562685966, Final Batch Loss: 0.03386373072862625\n",
      "Epoch 1184, Loss: 0.08323579281568527, Final Batch Loss: 0.01092258095741272\n",
      "Epoch 1185, Loss: 0.04499388672411442, Final Batch Loss: 0.018742062151432037\n",
      "Epoch 1186, Loss: 0.08984760753810406, Final Batch Loss: 0.02358405850827694\n",
      "Epoch 1187, Loss: 0.08972173929214478, Final Batch Loss: 0.03450654447078705\n",
      "Epoch 1188, Loss: 0.08199177123606205, Final Batch Loss: 0.030027883127331734\n",
      "Epoch 1189, Loss: 0.04620972461998463, Final Batch Loss: 0.019582614302635193\n",
      "Epoch 1190, Loss: 0.07200264185667038, Final Batch Loss: 0.046107202768325806\n",
      "Epoch 1191, Loss: 0.07532183919101954, Final Batch Loss: 0.015170671977102757\n",
      "Epoch 1192, Loss: 0.08054032549262047, Final Batch Loss: 0.04414980113506317\n",
      "Epoch 1193, Loss: 0.06984966062009335, Final Batch Loss: 0.026153316721320152\n",
      "Epoch 1194, Loss: 0.044008372351527214, Final Batch Loss: 0.011436792090535164\n",
      "Epoch 1195, Loss: 0.051351841539144516, Final Batch Loss: 0.03268260508775711\n",
      "Epoch 1196, Loss: 0.045411924831569195, Final Batch Loss: 0.030426736921072006\n",
      "Epoch 1197, Loss: 0.10481425747275352, Final Batch Loss: 0.06920679658651352\n",
      "Epoch 1198, Loss: 0.08151045627892017, Final Batch Loss: 0.05805337801575661\n",
      "Epoch 1199, Loss: 0.09592364728450775, Final Batch Loss: 0.0729060247540474\n",
      "Epoch 1200, Loss: 0.06380978040397167, Final Batch Loss: 0.02554798312485218\n",
      "Epoch 1201, Loss: 0.10787947103381157, Final Batch Loss: 0.07313745468854904\n",
      "Epoch 1202, Loss: 0.05641227774322033, Final Batch Loss: 0.02069406397640705\n",
      "Epoch 1203, Loss: 0.04624592512845993, Final Batch Loss: 0.018950948491692543\n",
      "Epoch 1204, Loss: 0.0692271888256073, Final Batch Loss: 0.04297615960240364\n",
      "Epoch 1205, Loss: 0.0697706826031208, Final Batch Loss: 0.032113827764987946\n",
      "Epoch 1206, Loss: 0.03797846473753452, Final Batch Loss: 0.021052910014986992\n",
      "Epoch 1207, Loss: 0.05490263178944588, Final Batch Loss: 0.021464388817548752\n",
      "Epoch 1208, Loss: 0.050492821261286736, Final Batch Loss: 0.031894292682409286\n",
      "Epoch 1209, Loss: 0.045833227224648, Final Batch Loss: 0.011371851898729801\n",
      "Epoch 1210, Loss: 0.05838062986731529, Final Batch Loss: 0.027140870690345764\n",
      "Epoch 1211, Loss: 0.05322639364749193, Final Batch Loss: 0.014893663115799427\n",
      "Epoch 1212, Loss: 0.06389294750988483, Final Batch Loss: 0.039232540875673294\n",
      "Epoch 1213, Loss: 0.11269605532288551, Final Batch Loss: 0.06167362630367279\n",
      "Epoch 1214, Loss: 0.09237432852387428, Final Batch Loss: 0.05866714194417\n",
      "Epoch 1215, Loss: 0.046777612529695034, Final Batch Loss: 0.008978660218417645\n",
      "Epoch 1216, Loss: 0.0887690857052803, Final Batch Loss: 0.04635915532708168\n",
      "Epoch 1217, Loss: 0.030954464338719845, Final Batch Loss: 0.016036273911595345\n",
      "Epoch 1218, Loss: 0.08853877894580364, Final Batch Loss: 0.019384106621146202\n",
      "Epoch 1219, Loss: 0.06442780792713165, Final Batch Loss: 0.02481832727789879\n",
      "Epoch 1220, Loss: 0.07033282145857811, Final Batch Loss: 0.038048155605793\n",
      "Epoch 1221, Loss: 0.08214354142546654, Final Batch Loss: 0.011336933821439743\n",
      "Epoch 1222, Loss: 0.06284437887370586, Final Batch Loss: 0.03174588829278946\n",
      "Epoch 1223, Loss: 0.07690677046775818, Final Batch Loss: 0.02976135164499283\n",
      "Epoch 1224, Loss: 0.0761333592236042, Final Batch Loss: 0.03804408758878708\n",
      "Epoch 1225, Loss: 0.03976914472877979, Final Batch Loss: 0.018903642892837524\n",
      "Epoch 1226, Loss: 0.04748921096324921, Final Batch Loss: 0.032799266278743744\n",
      "Epoch 1227, Loss: 0.08594978414475918, Final Batch Loss: 0.055398888885974884\n",
      "Epoch 1228, Loss: 0.03512994386255741, Final Batch Loss: 0.010940099135041237\n",
      "Epoch 1229, Loss: 0.051945277489721775, Final Batch Loss: 0.012972556985914707\n",
      "Epoch 1230, Loss: 0.053207943215966225, Final Batch Loss: 0.02163115330040455\n",
      "Epoch 1231, Loss: 0.11841065809130669, Final Batch Loss: 0.039190035313367844\n",
      "Epoch 1232, Loss: 0.0341483186930418, Final Batch Loss: 0.009915364906191826\n",
      "Epoch 1233, Loss: 0.08324640803039074, Final Batch Loss: 0.057048846036195755\n",
      "Epoch 1234, Loss: 0.033016618341207504, Final Batch Loss: 0.012537041679024696\n",
      "Epoch 1235, Loss: 0.08240929245948792, Final Batch Loss: 0.04649921879172325\n",
      "Epoch 1236, Loss: 0.026681456249207258, Final Batch Loss: 0.005013240035623312\n",
      "Epoch 1237, Loss: 0.052117591723799706, Final Batch Loss: 0.019761135801672935\n",
      "Epoch 1238, Loss: 0.07093766890466213, Final Batch Loss: 0.04459400102496147\n",
      "Epoch 1239, Loss: 0.13063380122184753, Final Batch Loss: 0.0911073163151741\n",
      "Epoch 1240, Loss: 0.07283230684697628, Final Batch Loss: 0.043272968381643295\n",
      "Epoch 1241, Loss: 0.04910466447472572, Final Batch Loss: 0.014130249619483948\n",
      "Epoch 1242, Loss: 0.1074223481118679, Final Batch Loss: 0.0377647764980793\n",
      "Epoch 1243, Loss: 0.06007389351725578, Final Batch Loss: 0.032001204788684845\n",
      "Epoch 1244, Loss: 0.08296449668705463, Final Batch Loss: 0.059813130646944046\n",
      "Epoch 1245, Loss: 0.05303244665265083, Final Batch Loss: 0.020408079028129578\n",
      "Epoch 1246, Loss: 0.06354006752371788, Final Batch Loss: 0.030386488884687424\n",
      "Epoch 1247, Loss: 0.06425106525421143, Final Batch Loss: 0.02460799366235733\n",
      "Epoch 1248, Loss: 0.07582932524383068, Final Batch Loss: 0.04770774766802788\n",
      "Epoch 1249, Loss: 0.0638381876051426, Final Batch Loss: 0.025378596037626266\n",
      "Epoch 1250, Loss: 0.0835910402238369, Final Batch Loss: 0.0670156329870224\n",
      "Epoch 1251, Loss: 0.1041252538561821, Final Batch Loss: 0.036568984389305115\n",
      "Epoch 1252, Loss: 0.09306799992918968, Final Batch Loss: 0.06040361523628235\n",
      "Epoch 1253, Loss: 0.0752875879406929, Final Batch Loss: 0.03725903853774071\n",
      "Epoch 1254, Loss: 0.055378908291459084, Final Batch Loss: 0.030852576717734337\n",
      "Epoch 1255, Loss: 0.09638403356075287, Final Batch Loss: 0.036616552621126175\n",
      "Epoch 1256, Loss: 0.05832756496965885, Final Batch Loss: 0.028934640809893608\n",
      "Epoch 1257, Loss: 0.07618989422917366, Final Batch Loss: 0.04005566984415054\n",
      "Epoch 1258, Loss: 0.11713973060250282, Final Batch Loss: 0.06743388622999191\n",
      "Epoch 1259, Loss: 0.06361031904816628, Final Batch Loss: 0.02362026274204254\n",
      "Epoch 1260, Loss: 0.09186465293169022, Final Batch Loss: 0.05245356261730194\n",
      "Epoch 1261, Loss: 0.06776154786348343, Final Batch Loss: 0.04569672793149948\n",
      "Epoch 1262, Loss: 0.07390076667070389, Final Batch Loss: 0.03758379444479942\n",
      "Epoch 1263, Loss: 0.08666297048330307, Final Batch Loss: 0.02341703325510025\n",
      "Epoch 1264, Loss: 0.1649773120880127, Final Batch Loss: 0.09978537261486053\n",
      "Epoch 1265, Loss: 0.09101300314068794, Final Batch Loss: 0.06572367250919342\n",
      "Epoch 1266, Loss: 0.08575105294585228, Final Batch Loss: 0.044918082654476166\n",
      "Epoch 1267, Loss: 0.14784356951713562, Final Batch Loss: 0.038367778062820435\n",
      "Epoch 1268, Loss: 0.07157486490905285, Final Batch Loss: 0.020815672352910042\n",
      "Epoch 1269, Loss: 0.057879332453012466, Final Batch Loss: 0.021088983863592148\n",
      "Epoch 1270, Loss: 0.07772497460246086, Final Batch Loss: 0.04958366975188255\n",
      "Epoch 1271, Loss: 0.05899049527943134, Final Batch Loss: 0.03536878526210785\n",
      "Epoch 1272, Loss: 0.08422206714749336, Final Batch Loss: 0.047142188996076584\n",
      "Epoch 1273, Loss: 0.03841255605220795, Final Batch Loss: 0.014930330216884613\n",
      "Epoch 1274, Loss: 0.08613102324306965, Final Batch Loss: 0.06560738384723663\n",
      "Epoch 1275, Loss: 0.07694776728749275, Final Batch Loss: 0.059028949588537216\n",
      "Epoch 1276, Loss: 0.04902595281600952, Final Batch Loss: 0.027678873389959335\n",
      "Epoch 1277, Loss: 0.041851187124848366, Final Batch Loss: 0.019968505948781967\n",
      "Epoch 1278, Loss: 0.06073426827788353, Final Batch Loss: 0.04004690796136856\n",
      "Epoch 1279, Loss: 0.08407231234014034, Final Batch Loss: 0.06236154958605766\n",
      "Epoch 1280, Loss: 0.08874816820025444, Final Batch Loss: 0.04636397585272789\n",
      "Epoch 1281, Loss: 0.049694955348968506, Final Batch Loss: 0.02284124121069908\n",
      "Epoch 1282, Loss: 0.06618664227426052, Final Batch Loss: 0.024993104860186577\n",
      "Epoch 1283, Loss: 0.04172299988567829, Final Batch Loss: 0.01980937458574772\n",
      "Epoch 1284, Loss: 0.11907075345516205, Final Batch Loss: 0.0639176294207573\n",
      "Epoch 1285, Loss: 0.08059458620846272, Final Batch Loss: 0.023606257513165474\n",
      "Epoch 1286, Loss: 0.06282339058816433, Final Batch Loss: 0.03416646271944046\n",
      "Epoch 1287, Loss: 0.031226512975990772, Final Batch Loss: 0.008250056765973568\n",
      "Epoch 1288, Loss: 0.05337277241051197, Final Batch Loss: 0.02992384508252144\n",
      "Epoch 1289, Loss: 0.04854042362421751, Final Batch Loss: 0.010126962326467037\n",
      "Epoch 1290, Loss: 0.08580767549574375, Final Batch Loss: 0.062231048941612244\n",
      "Epoch 1291, Loss: 0.04474513977766037, Final Batch Loss: 0.02076527290046215\n",
      "Epoch 1292, Loss: 0.04289071448147297, Final Batch Loss: 0.016355756670236588\n",
      "Epoch 1293, Loss: 0.02661652397364378, Final Batch Loss: 0.01675071381032467\n",
      "Epoch 1294, Loss: 0.04709717072546482, Final Batch Loss: 0.013895420357584953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1295, Loss: 0.03491000458598137, Final Batch Loss: 0.018774347379803658\n",
      "Epoch 1296, Loss: 0.03348990809172392, Final Batch Loss: 0.010531227104365826\n",
      "Epoch 1297, Loss: 0.09866736643016338, Final Batch Loss: 0.07863468676805496\n",
      "Epoch 1298, Loss: 0.08418960124254227, Final Batch Loss: 0.03605525940656662\n",
      "Epoch 1299, Loss: 0.0920589379966259, Final Batch Loss: 0.06734004616737366\n",
      "Epoch 1300, Loss: 0.07565817981958389, Final Batch Loss: 0.05046143755316734\n",
      "Epoch 1301, Loss: 0.16096492856740952, Final Batch Loss: 0.09184644371271133\n",
      "Epoch 1302, Loss: 0.1201716735959053, Final Batch Loss: 0.03942936658859253\n",
      "Epoch 1303, Loss: 0.2254462167620659, Final Batch Loss: 0.17505186796188354\n",
      "Epoch 1304, Loss: 0.08679540082812309, Final Batch Loss: 0.02385057881474495\n",
      "Epoch 1305, Loss: 0.21474214643239975, Final Batch Loss: 0.09434408694505692\n",
      "Epoch 1306, Loss: 0.12908116728067398, Final Batch Loss: 0.03566563129425049\n",
      "Epoch 1307, Loss: 0.07577916607260704, Final Batch Loss: 0.044323697686195374\n",
      "Epoch 1308, Loss: 0.08273613825440407, Final Batch Loss: 0.0424991250038147\n",
      "Epoch 1309, Loss: 0.12113358080387115, Final Batch Loss: 0.09136609733104706\n",
      "Epoch 1310, Loss: 0.11270647495985031, Final Batch Loss: 0.06624354422092438\n",
      "Epoch 1311, Loss: 0.07745537906885147, Final Batch Loss: 0.04512188956141472\n",
      "Epoch 1312, Loss: 0.07301821932196617, Final Batch Loss: 0.01642686501145363\n",
      "Epoch 1313, Loss: 0.11215893179178238, Final Batch Loss: 0.06277218461036682\n",
      "Epoch 1314, Loss: 0.046572135761380196, Final Batch Loss: 0.025385547429323196\n",
      "Epoch 1315, Loss: 0.08739582449197769, Final Batch Loss: 0.04811171442270279\n",
      "Epoch 1316, Loss: 0.05493754614144564, Final Batch Loss: 0.014260542578995228\n",
      "Epoch 1317, Loss: 0.10409120842814445, Final Batch Loss: 0.05868277698755264\n",
      "Epoch 1318, Loss: 0.05574699863791466, Final Batch Loss: 0.030146410688757896\n",
      "Epoch 1319, Loss: 0.06425627134740353, Final Batch Loss: 0.03626561164855957\n",
      "Epoch 1320, Loss: 0.05083771236240864, Final Batch Loss: 0.030153337866067886\n",
      "Epoch 1321, Loss: 0.03895081952214241, Final Batch Loss: 0.009994281455874443\n",
      "Epoch 1322, Loss: 0.0726760495454073, Final Batch Loss: 0.04219278320670128\n",
      "Epoch 1323, Loss: 0.12147745117545128, Final Batch Loss: 0.07753275334835052\n",
      "Epoch 1324, Loss: 0.06484153494238853, Final Batch Loss: 0.020700424909591675\n",
      "Epoch 1325, Loss: 0.0586374644190073, Final Batch Loss: 0.03538388013839722\n",
      "Epoch 1326, Loss: 0.07065366394817829, Final Batch Loss: 0.024097247049212456\n",
      "Epoch 1327, Loss: 0.07010875921696424, Final Batch Loss: 0.05541764199733734\n",
      "Epoch 1328, Loss: 0.06796837039291859, Final Batch Loss: 0.02564352937042713\n",
      "Epoch 1329, Loss: 0.0707215741276741, Final Batch Loss: 0.036724500358104706\n",
      "Epoch 1330, Loss: 0.05444891843944788, Final Batch Loss: 0.045700233429670334\n",
      "Epoch 1331, Loss: 0.0799860805273056, Final Batch Loss: 0.03610549122095108\n",
      "Epoch 1332, Loss: 0.059561945497989655, Final Batch Loss: 0.028482001274824142\n",
      "Epoch 1333, Loss: 0.07992921769618988, Final Batch Loss: 0.021701142191886902\n",
      "Epoch 1334, Loss: 0.04951627552509308, Final Batch Loss: 0.02418995276093483\n",
      "Epoch 1335, Loss: 0.08788189478218555, Final Batch Loss: 0.0605047307908535\n",
      "Epoch 1336, Loss: 0.08267928473651409, Final Batch Loss: 0.02023433707654476\n",
      "Epoch 1337, Loss: 0.0640344675630331, Final Batch Loss: 0.04265880212187767\n",
      "Epoch 1338, Loss: 0.08154765516519547, Final Batch Loss: 0.04852321743965149\n",
      "Epoch 1339, Loss: 0.07385081425309181, Final Batch Loss: 0.048746317625045776\n",
      "Epoch 1340, Loss: 0.12198473885655403, Final Batch Loss: 0.08927103132009506\n",
      "Epoch 1341, Loss: 0.058836257085204124, Final Batch Loss: 0.03725669905543327\n",
      "Epoch 1342, Loss: 0.1072264313697815, Final Batch Loss: 0.07844264060258865\n",
      "Epoch 1343, Loss: 0.04304848238825798, Final Batch Loss: 0.01694772019982338\n",
      "Epoch 1344, Loss: 0.04403965827077627, Final Batch Loss: 0.011710072867572308\n",
      "Epoch 1345, Loss: 0.0739922970533371, Final Batch Loss: 0.03294937685132027\n",
      "Epoch 1346, Loss: 0.09438749589025974, Final Batch Loss: 0.07015254348516464\n",
      "Epoch 1347, Loss: 0.08875448629260063, Final Batch Loss: 0.048795316368341446\n",
      "Epoch 1348, Loss: 0.07673531398177147, Final Batch Loss: 0.04045870527625084\n",
      "Epoch 1349, Loss: 0.08209237921983004, Final Batch Loss: 0.06937001645565033\n",
      "Epoch 1350, Loss: 0.12387122958898544, Final Batch Loss: 0.07922076433897018\n",
      "Epoch 1351, Loss: 0.07592491805553436, Final Batch Loss: 0.030784815549850464\n",
      "Epoch 1352, Loss: 0.10442657768726349, Final Batch Loss: 0.06754674762487411\n",
      "Epoch 1353, Loss: 0.08358498476445675, Final Batch Loss: 0.05549545958638191\n",
      "Epoch 1354, Loss: 0.13848745077848434, Final Batch Loss: 0.08808127790689468\n",
      "Epoch 1355, Loss: 0.10670712403953075, Final Batch Loss: 0.08840833604335785\n",
      "Epoch 1356, Loss: 0.14935355633497238, Final Batch Loss: 0.10272982716560364\n",
      "Epoch 1357, Loss: 0.05471152812242508, Final Batch Loss: 0.02002011239528656\n",
      "Epoch 1358, Loss: 0.048844246193766594, Final Batch Loss: 0.021754618734121323\n",
      "Epoch 1359, Loss: 0.061431704089045525, Final Batch Loss: 0.036687221378088\n",
      "Epoch 1360, Loss: 0.10683321580290794, Final Batch Loss: 0.02904805913567543\n",
      "Epoch 1361, Loss: 0.07995922118425369, Final Batch Loss: 0.044788625091314316\n",
      "Epoch 1362, Loss: 0.060656407848000526, Final Batch Loss: 0.02530289627611637\n",
      "Epoch 1363, Loss: 0.07008802518248558, Final Batch Loss: 0.02360057458281517\n",
      "Epoch 1364, Loss: 0.06764036789536476, Final Batch Loss: 0.0319015234708786\n",
      "Epoch 1365, Loss: 0.04652337543666363, Final Batch Loss: 0.02570332959294319\n",
      "Epoch 1366, Loss: 0.07266148738563061, Final Batch Loss: 0.04805929586291313\n",
      "Epoch 1367, Loss: 0.04131197463721037, Final Batch Loss: 0.032706934958696365\n",
      "Epoch 1368, Loss: 0.1312067061662674, Final Batch Loss: 0.06625812500715256\n",
      "Epoch 1369, Loss: 0.10236913338303566, Final Batch Loss: 0.07635865360498428\n",
      "Epoch 1370, Loss: 0.10139946267008781, Final Batch Loss: 0.05559815838932991\n",
      "Epoch 1371, Loss: 0.08708038739860058, Final Batch Loss: 0.06293730437755585\n",
      "Epoch 1372, Loss: 0.04731521476060152, Final Batch Loss: 0.012973234988749027\n",
      "Epoch 1373, Loss: 0.047865139320492744, Final Batch Loss: 0.02098279632627964\n",
      "Epoch 1374, Loss: 0.05361712537705898, Final Batch Loss: 0.02490268275141716\n",
      "Epoch 1375, Loss: 0.07262993976473808, Final Batch Loss: 0.037834107875823975\n",
      "Epoch 1376, Loss: 0.09953785687685013, Final Batch Loss: 0.03227926790714264\n",
      "Epoch 1377, Loss: 0.07562250830233097, Final Batch Loss: 0.021083889529109\n",
      "Epoch 1378, Loss: 0.08296814933419228, Final Batch Loss: 0.022220760583877563\n",
      "Epoch 1379, Loss: 0.055037752725183964, Final Batch Loss: 0.011499685235321522\n",
      "Epoch 1380, Loss: 0.05948867276310921, Final Batch Loss: 0.02452543005347252\n",
      "Epoch 1381, Loss: 0.08742741122841835, Final Batch Loss: 0.07453850656747818\n",
      "Epoch 1382, Loss: 0.059991275891661644, Final Batch Loss: 0.020852217450737953\n",
      "Epoch 1383, Loss: 0.0632590539753437, Final Batch Loss: 0.020534411072731018\n",
      "Epoch 1384, Loss: 0.05413847044110298, Final Batch Loss: 0.03247496485710144\n",
      "Epoch 1385, Loss: 0.06933380290865898, Final Batch Loss: 0.04610101878643036\n",
      "Epoch 1386, Loss: 0.05647085700184107, Final Batch Loss: 0.011817757971584797\n",
      "Epoch 1387, Loss: 0.05080038867890835, Final Batch Loss: 0.02060699090361595\n",
      "Epoch 1388, Loss: 0.12179647013545036, Final Batch Loss: 0.06782182306051254\n",
      "Epoch 1389, Loss: 0.11929397284984589, Final Batch Loss: 0.021394193172454834\n",
      "Epoch 1390, Loss: 0.11784075945615768, Final Batch Loss: 0.047500960528850555\n",
      "Epoch 1391, Loss: 0.04911816865205765, Final Batch Loss: 0.018434664234519005\n",
      "Epoch 1392, Loss: 0.042492857202887535, Final Batch Loss: 0.023298511281609535\n",
      "Epoch 1393, Loss: 0.03557468205690384, Final Batch Loss: 0.01701226457953453\n",
      "Epoch 1394, Loss: 0.0636295024305582, Final Batch Loss: 0.04488614201545715\n",
      "Epoch 1395, Loss: 0.043470367789268494, Final Batch Loss: 0.030643127858638763\n",
      "Epoch 1396, Loss: 0.07907542586326599, Final Batch Loss: 0.059087157249450684\n",
      "Epoch 1397, Loss: 0.05496334470808506, Final Batch Loss: 0.03095628134906292\n",
      "Epoch 1398, Loss: 0.03349361661821604, Final Batch Loss: 0.01888507977128029\n",
      "Epoch 1399, Loss: 0.05606970749795437, Final Batch Loss: 0.029256679117679596\n",
      "Epoch 1400, Loss: 0.06382516585290432, Final Batch Loss: 0.016430655494332314\n",
      "Epoch 1401, Loss: 0.04505937360227108, Final Batch Loss: 0.012090807780623436\n",
      "Epoch 1402, Loss: 0.04144897311925888, Final Batch Loss: 0.010116945952177048\n",
      "Epoch 1403, Loss: 0.05872086063027382, Final Batch Loss: 0.01576213911175728\n",
      "Epoch 1404, Loss: 0.03126771654933691, Final Batch Loss: 0.013714668340981007\n",
      "Epoch 1405, Loss: 0.09420621022582054, Final Batch Loss: 0.07606877386569977\n",
      "Epoch 1406, Loss: 0.04749852605164051, Final Batch Loss: 0.0269213505089283\n",
      "Epoch 1407, Loss: 0.05380592122673988, Final Batch Loss: 0.04189032316207886\n",
      "Epoch 1408, Loss: 0.05634929984807968, Final Batch Loss: 0.038795534521341324\n",
      "Epoch 1409, Loss: 0.07676501199603081, Final Batch Loss: 0.04482128098607063\n",
      "Epoch 1410, Loss: 0.043526045978069305, Final Batch Loss: 0.024477578699588776\n",
      "Epoch 1411, Loss: 0.055583725683391094, Final Batch Loss: 0.04875227063894272\n",
      "Epoch 1412, Loss: 0.04048702213913202, Final Batch Loss: 0.009628449566662312\n",
      "Epoch 1413, Loss: 0.04415084049105644, Final Batch Loss: 0.02347041666507721\n",
      "Epoch 1414, Loss: 0.07231879234313965, Final Batch Loss: 0.03052765503525734\n",
      "Epoch 1415, Loss: 0.05016162618994713, Final Batch Loss: 0.01239197701215744\n",
      "Epoch 1416, Loss: 0.05435858108103275, Final Batch Loss: 0.024644292891025543\n",
      "Epoch 1417, Loss: 0.053918915800750256, Final Batch Loss: 0.007272525690495968\n",
      "Epoch 1418, Loss: 0.08469946123659611, Final Batch Loss: 0.05547904968261719\n",
      "Epoch 1419, Loss: 0.05363412108272314, Final Batch Loss: 0.013322408311069012\n",
      "Epoch 1420, Loss: 0.039820197969675064, Final Batch Loss: 0.01649760827422142\n",
      "Epoch 1421, Loss: 0.08759886398911476, Final Batch Loss: 0.0366559736430645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1422, Loss: 0.08807343989610672, Final Batch Loss: 0.06600417196750641\n",
      "Epoch 1423, Loss: 0.056670138612389565, Final Batch Loss: 0.021360399201512337\n",
      "Epoch 1424, Loss: 0.06395412236452103, Final Batch Loss: 0.03860801085829735\n",
      "Epoch 1425, Loss: 0.04580017738044262, Final Batch Loss: 0.016192089766263962\n",
      "Epoch 1426, Loss: 0.037615202367305756, Final Batch Loss: 0.02226545289158821\n",
      "Epoch 1427, Loss: 0.10432740487158298, Final Batch Loss: 0.07557865232229233\n",
      "Epoch 1428, Loss: 0.030600826255977154, Final Batch Loss: 0.013785052113234997\n",
      "Epoch 1429, Loss: 0.05546725168824196, Final Batch Loss: 0.013649716973304749\n",
      "Epoch 1430, Loss: 0.06184397265315056, Final Batch Loss: 0.03727776184678078\n",
      "Epoch 1431, Loss: 0.04738238733261824, Final Batch Loss: 0.03322373330593109\n",
      "Epoch 1432, Loss: 0.04803348146378994, Final Batch Loss: 0.032208848744630814\n",
      "Epoch 1433, Loss: 0.06538781709969044, Final Batch Loss: 0.028876008465886116\n",
      "Epoch 1434, Loss: 0.06596811022609472, Final Batch Loss: 0.015361468307673931\n",
      "Epoch 1435, Loss: 0.07427719235420227, Final Batch Loss: 0.020634613931179047\n",
      "Epoch 1436, Loss: 0.053001439198851585, Final Batch Loss: 0.01584104262292385\n",
      "Epoch 1437, Loss: 0.048993756994605064, Final Batch Loss: 0.02358105219900608\n",
      "Epoch 1438, Loss: 0.04776310920715332, Final Batch Loss: 0.024590151384472847\n",
      "Epoch 1439, Loss: 0.05318505875766277, Final Batch Loss: 0.022048912942409515\n",
      "Epoch 1440, Loss: 0.040293073281645775, Final Batch Loss: 0.0215171966701746\n",
      "Epoch 1441, Loss: 0.07337315380573273, Final Batch Loss: 0.0422520786523819\n",
      "Epoch 1442, Loss: 0.05644909292459488, Final Batch Loss: 0.03938271477818489\n",
      "Epoch 1443, Loss: 0.10249153524637222, Final Batch Loss: 0.04313678294420242\n",
      "Epoch 1444, Loss: 0.039400266483426094, Final Batch Loss: 0.031085601076483727\n",
      "Epoch 1445, Loss: 0.030771106481552124, Final Batch Loss: 0.008955234661698341\n",
      "Epoch 1446, Loss: 0.055397551506757736, Final Batch Loss: 0.03622497245669365\n",
      "Epoch 1447, Loss: 0.05193784274160862, Final Batch Loss: 0.017716264352202415\n",
      "Epoch 1448, Loss: 0.031389386393129826, Final Batch Loss: 0.007242473773658276\n",
      "Epoch 1449, Loss: 0.030214915983378887, Final Batch Loss: 0.009768770076334476\n",
      "Epoch 1450, Loss: 0.09109039604663849, Final Batch Loss: 0.05481826514005661\n",
      "Epoch 1451, Loss: 0.0240615401417017, Final Batch Loss: 0.011012058705091476\n",
      "Epoch 1452, Loss: 0.033708252012729645, Final Batch Loss: 0.01703777350485325\n",
      "Epoch 1453, Loss: 0.06732315942645073, Final Batch Loss: 0.03696010634303093\n",
      "Epoch 1454, Loss: 0.06894881278276443, Final Batch Loss: 0.04340445622801781\n",
      "Epoch 1455, Loss: 0.03696565143764019, Final Batch Loss: 0.01625419408082962\n",
      "Epoch 1456, Loss: 0.06523236073553562, Final Batch Loss: 0.035722047090530396\n",
      "Epoch 1457, Loss: 0.09948760643601418, Final Batch Loss: 0.0819457471370697\n",
      "Epoch 1458, Loss: 0.0879320539534092, Final Batch Loss: 0.038553640246391296\n",
      "Epoch 1459, Loss: 0.05699900630861521, Final Batch Loss: 0.014497973956167698\n",
      "Epoch 1460, Loss: 0.08915162831544876, Final Batch Loss: 0.03809788450598717\n",
      "Epoch 1461, Loss: 0.08758218586444855, Final Batch Loss: 0.03632569685578346\n",
      "Epoch 1462, Loss: 0.06756146624684334, Final Batch Loss: 0.029930975288152695\n",
      "Epoch 1463, Loss: 0.06303547788411379, Final Batch Loss: 0.04958508163690567\n",
      "Epoch 1464, Loss: 0.05272781662642956, Final Batch Loss: 0.02545144408941269\n",
      "Epoch 1465, Loss: 0.08219996839761734, Final Batch Loss: 0.048382002860307693\n",
      "Epoch 1466, Loss: 0.06526018306612968, Final Batch Loss: 0.04362326115369797\n",
      "Epoch 1467, Loss: 0.04027179814875126, Final Batch Loss: 0.01682439260184765\n",
      "Epoch 1468, Loss: 0.05583246611058712, Final Batch Loss: 0.026468124240636826\n",
      "Epoch 1469, Loss: 0.05879366025328636, Final Batch Loss: 0.03543607145547867\n",
      "Epoch 1470, Loss: 0.09304357320070267, Final Batch Loss: 0.05346308648586273\n",
      "Epoch 1471, Loss: 0.04063283372670412, Final Batch Loss: 0.00802664551883936\n",
      "Epoch 1472, Loss: 0.08396098762750626, Final Batch Loss: 0.026503056287765503\n",
      "Epoch 1473, Loss: 0.05664878897368908, Final Batch Loss: 0.020550215616822243\n",
      "Epoch 1474, Loss: 0.10195505619049072, Final Batch Loss: 0.059360940009355545\n",
      "Epoch 1475, Loss: 0.06038310378789902, Final Batch Loss: 0.021702859550714493\n",
      "Epoch 1476, Loss: 0.07739043608307838, Final Batch Loss: 0.03519851341843605\n",
      "Epoch 1477, Loss: 0.10652603209018707, Final Batch Loss: 0.012609109282493591\n",
      "Epoch 1478, Loss: 0.08274791017174721, Final Batch Loss: 0.034619733691215515\n",
      "Epoch 1479, Loss: 0.0703051257878542, Final Batch Loss: 0.04728502780199051\n",
      "Epoch 1480, Loss: 0.08203336596488953, Final Batch Loss: 0.04202273115515709\n",
      "Epoch 1481, Loss: 0.06987282820045948, Final Batch Loss: 0.028680583462119102\n",
      "Epoch 1482, Loss: 0.09081345424056053, Final Batch Loss: 0.03389867767691612\n",
      "Epoch 1483, Loss: 0.0756855383515358, Final Batch Loss: 0.032477326691150665\n",
      "Epoch 1484, Loss: 0.04901251755654812, Final Batch Loss: 0.03490602970123291\n",
      "Epoch 1485, Loss: 0.06224016472697258, Final Batch Loss: 0.022816840559244156\n",
      "Epoch 1486, Loss: 0.06518218293786049, Final Batch Loss: 0.02070477232336998\n",
      "Epoch 1487, Loss: 0.07715535908937454, Final Batch Loss: 0.04460108280181885\n",
      "Epoch 1488, Loss: 0.09505229070782661, Final Batch Loss: 0.062248364090919495\n",
      "Epoch 1489, Loss: 0.041367413476109505, Final Batch Loss: 0.015139494091272354\n",
      "Epoch 1490, Loss: 0.04673699662089348, Final Batch Loss: 0.016890874132514\n",
      "Epoch 1491, Loss: 0.04920613951981068, Final Batch Loss: 0.011845814064145088\n",
      "Epoch 1492, Loss: 0.054810330271720886, Final Batch Loss: 0.023955482989549637\n",
      "Epoch 1493, Loss: 0.05749776214361191, Final Batch Loss: 0.03923758491873741\n",
      "Epoch 1494, Loss: 0.033763050101697445, Final Batch Loss: 0.012894363142549992\n",
      "Epoch 1495, Loss: 0.06290614791214466, Final Batch Loss: 0.019117364659905434\n",
      "Epoch 1496, Loss: 0.07472633011639118, Final Batch Loss: 0.020075509324669838\n",
      "Epoch 1497, Loss: 0.07609789073467255, Final Batch Loss: 0.04681052640080452\n",
      "Epoch 1498, Loss: 0.05292769707739353, Final Batch Loss: 0.03991934284567833\n",
      "Epoch 1499, Loss: 0.04899146221578121, Final Batch Loss: 0.02966279350221157\n",
      "Epoch 1500, Loss: 0.04318403638899326, Final Batch Loss: 0.0254446379840374\n",
      "Epoch 1501, Loss: 0.06037832237780094, Final Batch Loss: 0.03727104514837265\n",
      "Epoch 1502, Loss: 0.0656373631209135, Final Batch Loss: 0.0258882287889719\n",
      "Epoch 1503, Loss: 0.04819265007972717, Final Batch Loss: 0.014609560370445251\n",
      "Epoch 1504, Loss: 0.06596679054200649, Final Batch Loss: 0.010137056931853294\n",
      "Epoch 1505, Loss: 0.03789592441171408, Final Batch Loss: 0.011004782281816006\n",
      "Epoch 1506, Loss: 0.08575817197561264, Final Batch Loss: 0.05336073413491249\n",
      "Epoch 1507, Loss: 0.053807079792022705, Final Batch Loss: 0.0331285335123539\n",
      "Epoch 1508, Loss: 0.07919671013951302, Final Batch Loss: 0.0236981064081192\n",
      "Epoch 1509, Loss: 0.06389935687184334, Final Batch Loss: 0.02810896560549736\n",
      "Epoch 1510, Loss: 0.029425681568682194, Final Batch Loss: 0.01612413115799427\n",
      "Epoch 1511, Loss: 0.03497329447418451, Final Batch Loss: 0.008866106159985065\n",
      "Epoch 1512, Loss: 0.029807704500854015, Final Batch Loss: 0.015488794073462486\n",
      "Epoch 1513, Loss: 0.03471179213374853, Final Batch Loss: 0.014409278519451618\n",
      "Epoch 1514, Loss: 0.042100757360458374, Final Batch Loss: 0.024330414831638336\n",
      "Epoch 1515, Loss: 0.042885894887149334, Final Batch Loss: 0.01274616178125143\n",
      "Epoch 1516, Loss: 0.045539068058133125, Final Batch Loss: 0.023003382608294487\n",
      "Epoch 1517, Loss: 0.03959850315004587, Final Batch Loss: 0.014321661554276943\n",
      "Epoch 1518, Loss: 0.049688260070979595, Final Batch Loss: 0.011566395871341228\n",
      "Epoch 1519, Loss: 0.04027007520198822, Final Batch Loss: 0.01902458816766739\n",
      "Epoch 1520, Loss: 0.04963158816099167, Final Batch Loss: 0.023203227669000626\n",
      "Epoch 1521, Loss: 0.05040151812136173, Final Batch Loss: 0.016779346391558647\n",
      "Epoch 1522, Loss: 0.03857826255261898, Final Batch Loss: 0.02275318279862404\n",
      "Epoch 1523, Loss: 0.025318091735243797, Final Batch Loss: 0.014567331410944462\n",
      "Epoch 1524, Loss: 0.051050640642642975, Final Batch Loss: 0.01021961122751236\n",
      "Epoch 1525, Loss: 0.028518575243651867, Final Batch Loss: 0.009814462624490261\n",
      "Epoch 1526, Loss: 0.06025503762066364, Final Batch Loss: 0.02847573719918728\n",
      "Epoch 1527, Loss: 0.05863543972373009, Final Batch Loss: 0.018306251615285873\n",
      "Epoch 1528, Loss: 0.0366384033113718, Final Batch Loss: 0.008444877341389656\n",
      "Epoch 1529, Loss: 0.07030346989631653, Final Batch Loss: 0.03018162027001381\n",
      "Epoch 1530, Loss: 0.026381853967905045, Final Batch Loss: 0.010409528389573097\n",
      "Epoch 1531, Loss: 0.04819742124527693, Final Batch Loss: 0.011483835987746716\n",
      "Epoch 1532, Loss: 0.08336720429360867, Final Batch Loss: 0.013148760423064232\n",
      "Epoch 1533, Loss: 0.05547373741865158, Final Batch Loss: 0.029041018337011337\n",
      "Epoch 1534, Loss: 0.04312027618288994, Final Batch Loss: 0.005862884223461151\n",
      "Epoch 1535, Loss: 0.05455861985683441, Final Batch Loss: 0.02487441897392273\n",
      "Epoch 1536, Loss: 0.05618305504322052, Final Batch Loss: 0.03439963608980179\n",
      "Epoch 1537, Loss: 0.04112331382930279, Final Batch Loss: 0.01769903674721718\n",
      "Epoch 1538, Loss: 0.0718359500169754, Final Batch Loss: 0.03851892426609993\n",
      "Epoch 1539, Loss: 0.03754298482090235, Final Batch Loss: 0.011164885945618153\n",
      "Epoch 1540, Loss: 0.14289066195487976, Final Batch Loss: 0.07476408779621124\n",
      "Epoch 1541, Loss: 0.07255406863987446, Final Batch Loss: 0.053099509328603745\n",
      "Epoch 1542, Loss: 0.03508489020168781, Final Batch Loss: 0.01734468713402748\n",
      "Epoch 1543, Loss: 0.07964122761040926, Final Batch Loss: 0.07042138278484344\n",
      "Epoch 1544, Loss: 0.06683846563100815, Final Batch Loss: 0.03537798672914505\n",
      "Epoch 1545, Loss: 0.09321928583085537, Final Batch Loss: 0.06505163013935089\n",
      "Epoch 1546, Loss: 0.057563863694667816, Final Batch Loss: 0.022470273077487946\n",
      "Epoch 1547, Loss: 0.08994089905172586, Final Batch Loss: 0.07540424913167953\n",
      "Epoch 1548, Loss: 0.06611534114927053, Final Batch Loss: 0.051865771412849426\n",
      "Epoch 1549, Loss: 0.05827118828892708, Final Batch Loss: 0.0358896479010582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1550, Loss: 0.05100904684513807, Final Batch Loss: 0.03548441082239151\n",
      "Epoch 1551, Loss: 0.032489401288330555, Final Batch Loss: 0.017551211640238762\n",
      "Epoch 1552, Loss: 0.04811795614659786, Final Batch Loss: 0.02386862225830555\n",
      "Epoch 1553, Loss: 0.07773822732269764, Final Batch Loss: 0.031052375212311745\n",
      "Epoch 1554, Loss: 0.052648844197392464, Final Batch Loss: 0.03045995719730854\n",
      "Epoch 1555, Loss: 0.06953502539545298, Final Batch Loss: 0.012802326120436192\n",
      "Epoch 1556, Loss: 0.028630287386476994, Final Batch Loss: 0.014430895447731018\n",
      "Epoch 1557, Loss: 0.04160115588456392, Final Batch Loss: 0.014651970006525517\n",
      "Epoch 1558, Loss: 0.0453423410654068, Final Batch Loss: 0.016514135524630547\n",
      "Epoch 1559, Loss: 0.04114973172545433, Final Batch Loss: 0.01876564882695675\n",
      "Epoch 1560, Loss: 0.05417502112686634, Final Batch Loss: 0.033566735684871674\n",
      "Epoch 1561, Loss: 0.03541858494281769, Final Batch Loss: 0.010501762852072716\n",
      "Epoch 1562, Loss: 0.04886435903608799, Final Batch Loss: 0.01965232938528061\n",
      "Epoch 1563, Loss: 0.03137896955013275, Final Batch Loss: 0.015211563557386398\n",
      "Epoch 1564, Loss: 0.03971005789935589, Final Batch Loss: 0.0156520064920187\n",
      "Epoch 1565, Loss: 0.03528480976819992, Final Batch Loss: 0.013243526220321655\n",
      "Epoch 1566, Loss: 0.04272478073835373, Final Batch Loss: 0.018476281315088272\n",
      "Epoch 1567, Loss: 0.06132417544722557, Final Batch Loss: 0.04671887680888176\n",
      "Epoch 1568, Loss: 0.08975411206483841, Final Batch Loss: 0.04135281965136528\n",
      "Epoch 1569, Loss: 0.05907876417040825, Final Batch Loss: 0.03518202528357506\n",
      "Epoch 1570, Loss: 0.06251062406226993, Final Batch Loss: 0.007428515236824751\n",
      "Epoch 1571, Loss: 0.05659043602645397, Final Batch Loss: 0.02688951976597309\n",
      "Epoch 1572, Loss: 0.04032190516591072, Final Batch Loss: 0.009834922850131989\n",
      "Epoch 1573, Loss: 0.12647540867328644, Final Batch Loss: 0.07678573578596115\n",
      "Epoch 1574, Loss: 0.07166821137070656, Final Batch Loss: 0.031071841716766357\n",
      "Epoch 1575, Loss: 0.049301937222480774, Final Batch Loss: 0.024243678897619247\n",
      "Epoch 1576, Loss: 0.02468506433069706, Final Batch Loss: 0.004788972437381744\n",
      "Epoch 1577, Loss: 0.04540389962494373, Final Batch Loss: 0.01954479143023491\n",
      "Epoch 1578, Loss: 0.04682548716664314, Final Batch Loss: 0.0174307469278574\n",
      "Epoch 1579, Loss: 0.0317672323435545, Final Batch Loss: 0.009611202403903008\n",
      "Epoch 1580, Loss: 0.05156331695616245, Final Batch Loss: 0.015953989699482918\n",
      "Epoch 1581, Loss: 0.022748890332877636, Final Batch Loss: 0.009524669498205185\n",
      "Epoch 1582, Loss: 0.03828557766973972, Final Batch Loss: 0.01585153117775917\n",
      "Epoch 1583, Loss: 0.11352294310927391, Final Batch Loss: 0.04865514859557152\n",
      "Epoch 1584, Loss: 0.03676320239901543, Final Batch Loss: 0.013031616806983948\n",
      "Epoch 1585, Loss: 0.04598872642964125, Final Batch Loss: 0.01392346527427435\n",
      "Epoch 1586, Loss: 0.034848716109991074, Final Batch Loss: 0.016726745292544365\n",
      "Epoch 1587, Loss: 0.024303107522428036, Final Batch Loss: 0.008552453480660915\n",
      "Epoch 1588, Loss: 0.037010541651397943, Final Batch Loss: 0.004644969943910837\n",
      "Epoch 1589, Loss: 0.04277191497385502, Final Batch Loss: 0.012418292462825775\n",
      "Epoch 1590, Loss: 0.06649134214967489, Final Batch Loss: 0.054323580116033554\n",
      "Epoch 1591, Loss: 0.04247261490672827, Final Batch Loss: 0.028952941298484802\n",
      "Epoch 1592, Loss: 0.042870113626122475, Final Batch Loss: 0.01581745222210884\n",
      "Epoch 1593, Loss: 0.026280242018401623, Final Batch Loss: 0.012469383887946606\n",
      "Epoch 1594, Loss: 0.04994011204689741, Final Batch Loss: 0.03808913007378578\n",
      "Epoch 1595, Loss: 0.03379793465137482, Final Batch Loss: 0.019927503541111946\n",
      "Epoch 1596, Loss: 0.0382215715944767, Final Batch Loss: 0.033984120935201645\n",
      "Epoch 1597, Loss: 0.03096632845699787, Final Batch Loss: 0.013051768764853477\n",
      "Epoch 1598, Loss: 0.03250750992447138, Final Batch Loss: 0.009899850003421307\n",
      "Epoch 1599, Loss: 0.04789578169584274, Final Batch Loss: 0.017831725999712944\n",
      "Epoch 1600, Loss: 0.028519771993160248, Final Batch Loss: 0.012187261134386063\n",
      "Epoch 1601, Loss: 0.0873771570622921, Final Batch Loss: 0.03553561866283417\n",
      "Epoch 1602, Loss: 0.08952969312667847, Final Batch Loss: 0.022436052560806274\n",
      "Epoch 1603, Loss: 0.031198828481137753, Final Batch Loss: 0.0075725382193923\n",
      "Epoch 1604, Loss: 0.06359297037124634, Final Batch Loss: 0.02700941264629364\n",
      "Epoch 1605, Loss: 0.0559553150087595, Final Batch Loss: 0.024919835850596428\n",
      "Epoch 1606, Loss: 0.03770136274397373, Final Batch Loss: 0.025203628465533257\n",
      "Epoch 1607, Loss: 0.056895457208156586, Final Batch Loss: 0.03968958184123039\n",
      "Epoch 1608, Loss: 0.04848898947238922, Final Batch Loss: 0.03160931542515755\n",
      "Epoch 1609, Loss: 0.06499405205249786, Final Batch Loss: 0.012451183050870895\n",
      "Epoch 1610, Loss: 0.0714455209672451, Final Batch Loss: 0.024308625608682632\n",
      "Epoch 1611, Loss: 0.03598151355981827, Final Batch Loss: 0.011071788147091866\n",
      "Epoch 1612, Loss: 0.051189716905355453, Final Batch Loss: 0.009207505732774734\n",
      "Epoch 1613, Loss: 0.07065759412944317, Final Batch Loss: 0.06019478291273117\n",
      "Epoch 1614, Loss: 0.05333113670349121, Final Batch Loss: 0.022464996203780174\n",
      "Epoch 1615, Loss: 0.04464911622926593, Final Batch Loss: 0.005282867234200239\n",
      "Epoch 1616, Loss: 0.1073918342590332, Final Batch Loss: 0.037781357765197754\n",
      "Epoch 1617, Loss: 0.06076014041900635, Final Batch Loss: 0.031152114272117615\n",
      "Epoch 1618, Loss: 0.06389491260051727, Final Batch Loss: 0.04124287888407707\n",
      "Epoch 1619, Loss: 0.0395907424390316, Final Batch Loss: 0.00666533038020134\n",
      "Epoch 1620, Loss: 0.07999540492892265, Final Batch Loss: 0.024338528513908386\n",
      "Epoch 1621, Loss: 0.05035433731973171, Final Batch Loss: 0.02366996370255947\n",
      "Epoch 1622, Loss: 0.05803992599248886, Final Batch Loss: 0.013348985463380814\n",
      "Epoch 1623, Loss: 0.15271853283047676, Final Batch Loss: 0.13429512083530426\n",
      "Epoch 1624, Loss: 0.06562756188213825, Final Batch Loss: 0.03619268909096718\n",
      "Epoch 1625, Loss: 0.09506399370729923, Final Batch Loss: 0.06912994384765625\n",
      "Epoch 1626, Loss: 0.13197290524840355, Final Batch Loss: 0.1108447015285492\n",
      "Epoch 1627, Loss: 0.0809575505554676, Final Batch Loss: 0.04975414648652077\n",
      "Epoch 1628, Loss: 0.1267632693052292, Final Batch Loss: 0.07385633885860443\n",
      "Epoch 1629, Loss: 0.12078531458973885, Final Batch Loss: 0.02417244389653206\n",
      "Epoch 1630, Loss: 0.14935271441936493, Final Batch Loss: 0.095244862139225\n",
      "Epoch 1631, Loss: 0.1294003278017044, Final Batch Loss: 0.06647179275751114\n",
      "Epoch 1632, Loss: 0.07023175060749054, Final Batch Loss: 0.024025943130254745\n",
      "Epoch 1633, Loss: 0.1259821355342865, Final Batch Loss: 0.08940260112285614\n",
      "Epoch 1634, Loss: 0.06948842108249664, Final Batch Loss: 0.032467201352119446\n",
      "Epoch 1635, Loss: 0.03769233264029026, Final Batch Loss: 0.024112191051244736\n",
      "Epoch 1636, Loss: 0.10878288000822067, Final Batch Loss: 0.07290269434452057\n",
      "Epoch 1637, Loss: 0.06057040952146053, Final Batch Loss: 0.03172104060649872\n",
      "Epoch 1638, Loss: 0.0732378177344799, Final Batch Loss: 0.04600884020328522\n",
      "Epoch 1639, Loss: 0.11550798080861568, Final Batch Loss: 0.08757715672254562\n",
      "Epoch 1640, Loss: 0.026456686668097973, Final Batch Loss: 0.011203592643141747\n",
      "Epoch 1641, Loss: 0.09491386637091637, Final Batch Loss: 0.02773727849125862\n",
      "Epoch 1642, Loss: 0.06288069114089012, Final Batch Loss: 0.03383557125926018\n",
      "Epoch 1643, Loss: 0.05839692987501621, Final Batch Loss: 0.02633626200258732\n",
      "Epoch 1644, Loss: 0.046616628766059875, Final Batch Loss: 0.019764494150877\n",
      "Epoch 1645, Loss: 0.10201545432209969, Final Batch Loss: 0.072213314473629\n",
      "Epoch 1646, Loss: 0.04606945812702179, Final Batch Loss: 0.027979690581560135\n",
      "Epoch 1647, Loss: 0.029944713227450848, Final Batch Loss: 0.015980057418346405\n",
      "Epoch 1648, Loss: 0.044934213161468506, Final Batch Loss: 0.01585446670651436\n",
      "Epoch 1649, Loss: 0.0761374682188034, Final Batch Loss: 0.03770533576607704\n",
      "Epoch 1650, Loss: 0.05044956132769585, Final Batch Loss: 0.016343839466571808\n",
      "Epoch 1651, Loss: 0.05600984767079353, Final Batch Loss: 0.010280497372150421\n",
      "Epoch 1652, Loss: 0.03866386413574219, Final Batch Loss: 0.020137881860136986\n",
      "Epoch 1653, Loss: 0.03758411202579737, Final Batch Loss: 0.014715113677084446\n",
      "Epoch 1654, Loss: 0.051080742850899696, Final Batch Loss: 0.03193835914134979\n",
      "Epoch 1655, Loss: 0.07732724025845528, Final Batch Loss: 0.021147243678569794\n",
      "Epoch 1656, Loss: 0.03524821810424328, Final Batch Loss: 0.01881677284836769\n",
      "Epoch 1657, Loss: 0.058755092322826385, Final Batch Loss: 0.021084126085042953\n",
      "Epoch 1658, Loss: 0.046182870864868164, Final Batch Loss: 0.027328314259648323\n",
      "Epoch 1659, Loss: 0.056980255991220474, Final Batch Loss: 0.034938108175992966\n",
      "Epoch 1660, Loss: 0.04750667605549097, Final Batch Loss: 0.013975043781101704\n",
      "Epoch 1661, Loss: 0.029904124327003956, Final Batch Loss: 0.00859240535646677\n",
      "Epoch 1662, Loss: 0.08767119795084, Final Batch Loss: 0.029670264571905136\n",
      "Epoch 1663, Loss: 0.03834517579525709, Final Batch Loss: 0.01519311498850584\n",
      "Epoch 1664, Loss: 0.07614994794130325, Final Batch Loss: 0.017956357449293137\n",
      "Epoch 1665, Loss: 0.03990303725004196, Final Batch Loss: 0.01310194656252861\n",
      "Epoch 1666, Loss: 0.03635210730135441, Final Batch Loss: 0.005301589146256447\n",
      "Epoch 1667, Loss: 0.047309933230280876, Final Batch Loss: 0.011430324986577034\n",
      "Epoch 1668, Loss: 0.036328328773379326, Final Batch Loss: 0.015257103368639946\n",
      "Epoch 1669, Loss: 0.0528254508972168, Final Batch Loss: 0.030193405225872993\n",
      "Epoch 1670, Loss: 0.02331776637583971, Final Batch Loss: 0.008398155681788921\n",
      "Epoch 1671, Loss: 0.05347125977277756, Final Batch Loss: 0.023736776784062386\n",
      "Epoch 1672, Loss: 0.031496934592723846, Final Batch Loss: 0.011075370013713837\n",
      "Epoch 1673, Loss: 0.03979894518852234, Final Batch Loss: 0.01433161087334156\n",
      "Epoch 1674, Loss: 0.026564668864011765, Final Batch Loss: 0.013918871060013771\n",
      "Epoch 1675, Loss: 0.06298152543604374, Final Batch Loss: 0.03179943189024925\n",
      "Epoch 1676, Loss: 0.07349205017089844, Final Batch Loss: 0.045033156871795654\n",
      "Epoch 1677, Loss: 0.03931809589266777, Final Batch Loss: 0.011351138353347778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1678, Loss: 0.07724480517208576, Final Batch Loss: 0.05138101801276207\n",
      "Epoch 1679, Loss: 0.0638126153498888, Final Batch Loss: 0.03846706822514534\n",
      "Epoch 1680, Loss: 0.03648807667195797, Final Batch Loss: 0.02158692479133606\n",
      "Epoch 1681, Loss: 0.04260633885860443, Final Batch Loss: 0.02006283402442932\n",
      "Epoch 1682, Loss: 0.029246719554066658, Final Batch Loss: 0.00954383984208107\n",
      "Epoch 1683, Loss: 0.09061992540955544, Final Batch Loss: 0.020854253321886063\n",
      "Epoch 1684, Loss: 0.06133566237986088, Final Batch Loss: 0.019855445250868797\n",
      "Epoch 1685, Loss: 0.14596417546272278, Final Batch Loss: 0.0804249569773674\n",
      "Epoch 1686, Loss: 0.06382477097213268, Final Batch Loss: 0.0260248314589262\n",
      "Epoch 1687, Loss: 0.1323096603155136, Final Batch Loss: 0.0986393615603447\n",
      "Epoch 1688, Loss: 0.03449672879651189, Final Batch Loss: 0.006501298863440752\n",
      "Epoch 1689, Loss: 0.03898620046675205, Final Batch Loss: 0.013250086456537247\n",
      "Epoch 1690, Loss: 0.06394873932003975, Final Batch Loss: 0.019437070935964584\n",
      "Epoch 1691, Loss: 0.04870842024683952, Final Batch Loss: 0.026873260736465454\n",
      "Epoch 1692, Loss: 0.04814131837338209, Final Batch Loss: 0.00982902105897665\n",
      "Epoch 1693, Loss: 0.08345971629023552, Final Batch Loss: 0.055954404175281525\n",
      "Epoch 1694, Loss: 0.02474843244999647, Final Batch Loss: 0.012875629588961601\n",
      "Epoch 1695, Loss: 0.05050722602754831, Final Batch Loss: 0.012206130661070347\n",
      "Epoch 1696, Loss: 0.036361332051455975, Final Batch Loss: 0.015433368273079395\n",
      "Epoch 1697, Loss: 0.024525480344891548, Final Batch Loss: 0.006450161337852478\n",
      "Epoch 1698, Loss: 0.051405927166342735, Final Batch Loss: 0.02484297938644886\n",
      "Epoch 1699, Loss: 0.05045187473297119, Final Batch Loss: 0.016984649002552032\n",
      "Epoch 1700, Loss: 0.033790964633226395, Final Batch Loss: 0.015654543414711952\n",
      "Epoch 1701, Loss: 0.048939524218440056, Final Batch Loss: 0.0266916211694479\n",
      "Epoch 1702, Loss: 0.024854444433003664, Final Batch Loss: 0.004652176517993212\n",
      "Epoch 1703, Loss: 0.04144321847707033, Final Batch Loss: 0.007786010392010212\n",
      "Epoch 1704, Loss: 0.043090594466775656, Final Batch Loss: 0.004821834620088339\n",
      "Epoch 1705, Loss: 0.045239425264298916, Final Batch Loss: 0.03810535743832588\n",
      "Epoch 1706, Loss: 0.04973232001066208, Final Batch Loss: 0.028805503621697426\n",
      "Epoch 1707, Loss: 0.03773640003055334, Final Batch Loss: 0.0245366208255291\n",
      "Epoch 1708, Loss: 0.08180928789079189, Final Batch Loss: 0.07089625298976898\n",
      "Epoch 1709, Loss: 0.021288171410560608, Final Batch Loss: 0.004397239536046982\n",
      "Epoch 1710, Loss: 0.07390723749995232, Final Batch Loss: 0.041797198355197906\n",
      "Epoch 1711, Loss: 0.07371686398983002, Final Batch Loss: 0.04128730297088623\n",
      "Epoch 1712, Loss: 0.06736951926723123, Final Batch Loss: 0.006043823901563883\n",
      "Epoch 1713, Loss: 0.0476644653826952, Final Batch Loss: 0.027693649753928185\n",
      "Epoch 1714, Loss: 0.04395001754164696, Final Batch Loss: 0.008826401084661484\n",
      "Epoch 1715, Loss: 0.02097296016290784, Final Batch Loss: 0.015362517908215523\n",
      "Epoch 1716, Loss: 0.03658530209213495, Final Batch Loss: 0.02578156441450119\n",
      "Epoch 1717, Loss: 0.02796867210417986, Final Batch Loss: 0.007936120964586735\n",
      "Epoch 1718, Loss: 0.04001933895051479, Final Batch Loss: 0.02170603722333908\n",
      "Epoch 1719, Loss: 0.0330986687913537, Final Batch Loss: 0.023860733956098557\n",
      "Epoch 1720, Loss: 0.11001286935061216, Final Batch Loss: 0.1027064397931099\n",
      "Epoch 1721, Loss: 0.014430290553718805, Final Batch Loss: 0.007917138747870922\n",
      "Epoch 1722, Loss: 0.042556725442409515, Final Batch Loss: 0.03274537995457649\n",
      "Epoch 1723, Loss: 0.050901249051094055, Final Batch Loss: 0.03245127946138382\n",
      "Epoch 1724, Loss: 0.09837090969085693, Final Batch Loss: 0.06809862703084946\n",
      "Epoch 1725, Loss: 0.11293944530189037, Final Batch Loss: 0.018938204273581505\n",
      "Epoch 1726, Loss: 0.033920045010745525, Final Batch Loss: 0.011421521194279194\n",
      "Epoch 1727, Loss: 0.04768022149801254, Final Batch Loss: 0.026496317237615585\n",
      "Epoch 1728, Loss: 0.11747458204627037, Final Batch Loss: 0.0680130273103714\n",
      "Epoch 1729, Loss: 0.04599779658019543, Final Batch Loss: 0.015825539827346802\n",
      "Epoch 1730, Loss: 0.0447307825088501, Final Batch Loss: 0.011254079639911652\n",
      "Epoch 1731, Loss: 0.06486905366182327, Final Batch Loss: 0.023990750312805176\n",
      "Epoch 1732, Loss: 0.06328202597796917, Final Batch Loss: 0.03544440120458603\n",
      "Epoch 1733, Loss: 0.036328570917248726, Final Batch Loss: 0.024094343185424805\n",
      "Epoch 1734, Loss: 0.027754388749599457, Final Batch Loss: 0.013490041717886925\n",
      "Epoch 1735, Loss: 0.058758363127708435, Final Batch Loss: 0.027143798768520355\n",
      "Epoch 1736, Loss: 0.0454061534255743, Final Batch Loss: 0.03000219725072384\n",
      "Epoch 1737, Loss: 0.0765155553817749, Final Batch Loss: 0.022254616022109985\n",
      "Epoch 1738, Loss: 0.02201036736369133, Final Batch Loss: 0.007289213128387928\n",
      "Epoch 1739, Loss: 0.0647581871598959, Final Batch Loss: 0.023287246003746986\n",
      "Epoch 1740, Loss: 0.1304982453584671, Final Batch Loss: 0.05366814136505127\n",
      "Epoch 1741, Loss: 0.06344043370336294, Final Batch Loss: 0.05325717478990555\n",
      "Epoch 1742, Loss: 0.042190056294202805, Final Batch Loss: 0.02833079919219017\n",
      "Epoch 1743, Loss: 0.04067225847393274, Final Batch Loss: 0.026142651215195656\n",
      "Epoch 1744, Loss: 0.05019321758300066, Final Batch Loss: 0.012778461910784245\n",
      "Epoch 1745, Loss: 0.02803792990744114, Final Batch Loss: 0.01357458159327507\n",
      "Epoch 1746, Loss: 0.06113442964851856, Final Batch Loss: 0.029836567118763924\n",
      "Epoch 1747, Loss: 0.03241976397112012, Final Batch Loss: 0.006276108790189028\n",
      "Epoch 1748, Loss: 0.029119045473635197, Final Batch Loss: 0.01616274006664753\n",
      "Epoch 1749, Loss: 0.052049191668629646, Final Batch Loss: 0.021837759763002396\n",
      "Epoch 1750, Loss: 0.13318048976361752, Final Batch Loss: 0.11419592052698135\n",
      "Epoch 1751, Loss: 0.04875401267781854, Final Batch Loss: 0.0061436728574335575\n",
      "Epoch 1752, Loss: 0.05879815295338631, Final Batch Loss: 0.011411041021347046\n",
      "Epoch 1753, Loss: 0.06228718161582947, Final Batch Loss: 0.027632370591163635\n",
      "Epoch 1754, Loss: 0.03520985506474972, Final Batch Loss: 0.017851337790489197\n",
      "Epoch 1755, Loss: 0.09635160304605961, Final Batch Loss: 0.08075745403766632\n",
      "Epoch 1756, Loss: 0.031494420021772385, Final Batch Loss: 0.016420481726527214\n",
      "Epoch 1757, Loss: 0.025782721117138863, Final Batch Loss: 0.006806585937738419\n",
      "Epoch 1758, Loss: 0.04811752215027809, Final Batch Loss: 0.0227502528578043\n",
      "Epoch 1759, Loss: 0.04220935329794884, Final Batch Loss: 0.026021387428045273\n",
      "Epoch 1760, Loss: 0.045387000776827335, Final Batch Loss: 0.031614795327186584\n",
      "Epoch 1761, Loss: 0.023414979688823223, Final Batch Loss: 0.010936126112937927\n",
      "Epoch 1762, Loss: 0.0676545761525631, Final Batch Loss: 0.045958977192640305\n",
      "Epoch 1763, Loss: 0.04875906929373741, Final Batch Loss: 0.038738913834095\n",
      "Epoch 1764, Loss: 0.02513548731803894, Final Batch Loss: 0.007412707433104515\n",
      "Epoch 1765, Loss: 0.06189780309796333, Final Batch Loss: 0.008091267198324203\n",
      "Epoch 1766, Loss: 0.03007745649665594, Final Batch Loss: 0.01003748644143343\n",
      "Epoch 1767, Loss: 0.0459342896938324, Final Batch Loss: 0.030405450612306595\n",
      "Epoch 1768, Loss: 0.04647205676883459, Final Batch Loss: 0.0149817680940032\n",
      "Epoch 1769, Loss: 0.03496083617210388, Final Batch Loss: 0.020727965980768204\n",
      "Epoch 1770, Loss: 0.05055235978215933, Final Batch Loss: 0.03589566797018051\n",
      "Epoch 1771, Loss: 0.03719017282128334, Final Batch Loss: 0.016502466052770615\n",
      "Epoch 1772, Loss: 0.07590142451226711, Final Batch Loss: 0.06396688520908356\n",
      "Epoch 1773, Loss: 0.047691233456134796, Final Batch Loss: 0.031099820509552956\n",
      "Epoch 1774, Loss: 0.03625194076448679, Final Batch Loss: 0.009222972206771374\n",
      "Epoch 1775, Loss: 0.024435775820165873, Final Batch Loss: 0.019281979650259018\n",
      "Epoch 1776, Loss: 0.049831731244921684, Final Batch Loss: 0.026571979746222496\n",
      "Epoch 1777, Loss: 0.04236238542944193, Final Batch Loss: 0.010959827341139317\n",
      "Epoch 1778, Loss: 0.03204427286982536, Final Batch Loss: 0.020751187577843666\n",
      "Epoch 1779, Loss: 0.03331170231103897, Final Batch Loss: 0.007509224116802216\n",
      "Epoch 1780, Loss: 0.041438388638198376, Final Batch Loss: 0.027662033215165138\n",
      "Epoch 1781, Loss: 0.059607069939374924, Final Batch Loss: 0.03758089616894722\n",
      "Epoch 1782, Loss: 0.04677430912852287, Final Batch Loss: 0.023402445018291473\n",
      "Epoch 1783, Loss: 0.02551333513110876, Final Batch Loss: 0.009504652582108974\n",
      "Epoch 1784, Loss: 0.04720723442733288, Final Batch Loss: 0.031054751947522163\n",
      "Epoch 1785, Loss: 0.039467993192374706, Final Batch Loss: 0.011299590580165386\n",
      "Epoch 1786, Loss: 0.032452610321342945, Final Batch Loss: 0.019431516528129578\n",
      "Epoch 1787, Loss: 0.03740598168224096, Final Batch Loss: 0.023932045325636864\n",
      "Epoch 1788, Loss: 0.06604729406535625, Final Batch Loss: 0.04042370617389679\n",
      "Epoch 1789, Loss: 0.06408457458019257, Final Batch Loss: 0.026977278292179108\n",
      "Epoch 1790, Loss: 0.04027284495532513, Final Batch Loss: 0.020790627226233482\n",
      "Epoch 1791, Loss: 0.028745408169925213, Final Batch Loss: 0.011150137521326542\n",
      "Epoch 1792, Loss: 0.035785214975476265, Final Batch Loss: 0.017855416983366013\n",
      "Epoch 1793, Loss: 0.06236024759709835, Final Batch Loss: 0.0370296835899353\n",
      "Epoch 1794, Loss: 0.056473324075341225, Final Batch Loss: 0.009126672521233559\n",
      "Epoch 1795, Loss: 0.04472866468131542, Final Batch Loss: 0.02353244088590145\n",
      "Epoch 1796, Loss: 0.014943125192075968, Final Batch Loss: 0.00613549305126071\n",
      "Epoch 1797, Loss: 0.09165462665259838, Final Batch Loss: 0.06262454390525818\n",
      "Epoch 1798, Loss: 0.01913238875567913, Final Batch Loss: 0.008859843015670776\n",
      "Epoch 1799, Loss: 0.021471411921083927, Final Batch Loss: 0.009434845298528671\n",
      "Epoch 1800, Loss: 0.12214282713830471, Final Batch Loss: 0.020460350438952446\n",
      "Epoch 1801, Loss: 0.039902061223983765, Final Batch Loss: 0.028316522017121315\n",
      "Epoch 1802, Loss: 0.02587009873241186, Final Batch Loss: 0.007084387354552746\n",
      "Epoch 1803, Loss: 0.01245314977131784, Final Batch Loss: 0.0035419741179794073\n",
      "Epoch 1804, Loss: 0.06680348329246044, Final Batch Loss: 0.036573246121406555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1805, Loss: 0.03308425843715668, Final Batch Loss: 0.02050396054983139\n",
      "Epoch 1806, Loss: 0.05018460284918547, Final Batch Loss: 0.037839896976947784\n",
      "Epoch 1807, Loss: 0.017070865258574486, Final Batch Loss: 0.008063814602792263\n",
      "Epoch 1808, Loss: 0.057255854830145836, Final Batch Loss: 0.03050128184258938\n",
      "Epoch 1809, Loss: 0.023776818998157978, Final Batch Loss: 0.0135306715965271\n",
      "Epoch 1810, Loss: 0.026222489774227142, Final Batch Loss: 0.007391402497887611\n",
      "Epoch 1811, Loss: 0.026771613396704197, Final Batch Loss: 0.012921152636408806\n",
      "Epoch 1812, Loss: 0.02672057505697012, Final Batch Loss: 0.010545811615884304\n",
      "Epoch 1813, Loss: 0.04681028891354799, Final Batch Loss: 0.03620496019721031\n",
      "Epoch 1814, Loss: 0.03942084312438965, Final Batch Loss: 0.017896801233291626\n",
      "Epoch 1815, Loss: 0.01233203848823905, Final Batch Loss: 0.006365349516272545\n",
      "Epoch 1816, Loss: 0.048416540026664734, Final Batch Loss: 0.029350223019719124\n",
      "Epoch 1817, Loss: 0.053820830304175615, Final Batch Loss: 0.048447005450725555\n",
      "Epoch 1818, Loss: 0.035053526517003775, Final Batch Loss: 0.006955205928534269\n",
      "Epoch 1819, Loss: 0.02165419515222311, Final Batch Loss: 0.011861159466207027\n",
      "Epoch 1820, Loss: 0.04837152361869812, Final Batch Loss: 0.011875953525304794\n",
      "Epoch 1821, Loss: 0.0422354806214571, Final Batch Loss: 0.02211950346827507\n",
      "Epoch 1822, Loss: 0.016094190068542957, Final Batch Loss: 0.008164324797689915\n",
      "Epoch 1823, Loss: 0.03371206857264042, Final Batch Loss: 0.014562712982296944\n",
      "Epoch 1824, Loss: 0.015015002340078354, Final Batch Loss: 0.008316452614963055\n",
      "Epoch 1825, Loss: 0.022041639778763056, Final Batch Loss: 0.002453871536999941\n",
      "Epoch 1826, Loss: 0.03234597761183977, Final Batch Loss: 0.010097767226397991\n",
      "Epoch 1827, Loss: 0.036625285632908344, Final Batch Loss: 0.009964444674551487\n",
      "Epoch 1828, Loss: 0.046353742480278015, Final Batch Loss: 0.0234941765666008\n",
      "Epoch 1829, Loss: 0.03511952701956034, Final Batch Loss: 0.01099806372076273\n",
      "Epoch 1830, Loss: 0.11299994960427284, Final Batch Loss: 0.09442167729139328\n",
      "Epoch 1831, Loss: 0.015107087325304747, Final Batch Loss: 0.007409864105284214\n",
      "Epoch 1832, Loss: 0.023470446467399597, Final Batch Loss: 0.012679127976298332\n",
      "Epoch 1833, Loss: 0.03152396623045206, Final Batch Loss: 0.015915846452116966\n",
      "Epoch 1834, Loss: 0.09236866515129805, Final Batch Loss: 0.0851641371846199\n",
      "Epoch 1835, Loss: 0.060188394505530596, Final Batch Loss: 0.054788071662187576\n",
      "Epoch 1836, Loss: 0.03921546787023544, Final Batch Loss: 0.012565823271870613\n",
      "Epoch 1837, Loss: 0.06323790550231934, Final Batch Loss: 0.03869478404521942\n",
      "Epoch 1838, Loss: 0.0136454151943326, Final Batch Loss: 0.006865326780825853\n",
      "Epoch 1839, Loss: 0.0568966306746006, Final Batch Loss: 0.004316370934247971\n",
      "Epoch 1840, Loss: 0.1526200845837593, Final Batch Loss: 0.06968583911657333\n",
      "Epoch 1841, Loss: 0.020843012258410454, Final Batch Loss: 0.008838046342134476\n",
      "Epoch 1842, Loss: 0.13455260545015335, Final Batch Loss: 0.0943753719329834\n",
      "Epoch 1843, Loss: 0.04112294502556324, Final Batch Loss: 0.020985765382647514\n",
      "Epoch 1844, Loss: 0.01813338603824377, Final Batch Loss: 0.004775595851242542\n",
      "Epoch 1845, Loss: 0.03777454048395157, Final Batch Loss: 0.02037014439702034\n",
      "Epoch 1846, Loss: 0.04601097293198109, Final Batch Loss: 0.021216601133346558\n",
      "Epoch 1847, Loss: 0.03286704607307911, Final Batch Loss: 0.016221798956394196\n",
      "Epoch 1848, Loss: 0.03255472984164953, Final Batch Loss: 0.013582623563706875\n",
      "Epoch 1849, Loss: 0.023556330241262913, Final Batch Loss: 0.01056710910052061\n",
      "Epoch 1850, Loss: 0.03970387764275074, Final Batch Loss: 0.035437628626823425\n",
      "Epoch 1851, Loss: 0.03761718049645424, Final Batch Loss: 0.01514418050646782\n",
      "Epoch 1852, Loss: 0.043620962649583817, Final Batch Loss: 0.03456360846757889\n",
      "Epoch 1853, Loss: 0.014318228932097554, Final Batch Loss: 0.010489536449313164\n",
      "Epoch 1854, Loss: 0.03467820584774017, Final Batch Loss: 0.007379734888672829\n",
      "Epoch 1855, Loss: 0.061110541224479675, Final Batch Loss: 0.03946604207158089\n",
      "Epoch 1856, Loss: 0.03680079244077206, Final Batch Loss: 0.015444822609424591\n",
      "Epoch 1857, Loss: 0.03774401172995567, Final Batch Loss: 0.008985646069049835\n",
      "Epoch 1858, Loss: 0.03059758199378848, Final Batch Loss: 0.024100787937641144\n",
      "Epoch 1859, Loss: 0.03974572801962495, Final Batch Loss: 0.03394095227122307\n",
      "Epoch 1860, Loss: 0.08801476331427693, Final Batch Loss: 0.0068981763906776905\n",
      "Epoch 1861, Loss: 0.09755341801792383, Final Batch Loss: 0.08315645903348923\n",
      "Epoch 1862, Loss: 0.03211487038061023, Final Batch Loss: 0.007041600998491049\n",
      "Epoch 1863, Loss: 0.054463814944028854, Final Batch Loss: 0.03540555015206337\n",
      "Epoch 1864, Loss: 0.13406988233327866, Final Batch Loss: 0.1211380586028099\n",
      "Epoch 1865, Loss: 0.06050894781947136, Final Batch Loss: 0.02773967757821083\n",
      "Epoch 1866, Loss: 0.10057283751666546, Final Batch Loss: 0.09005792438983917\n",
      "Epoch 1867, Loss: 0.026425769552588463, Final Batch Loss: 0.011544313281774521\n",
      "Epoch 1868, Loss: 0.036887853406369686, Final Batch Loss: 0.012537269853055477\n",
      "Epoch 1869, Loss: 0.04504949785768986, Final Batch Loss: 0.02213003672659397\n",
      "Epoch 1870, Loss: 0.03061624336987734, Final Batch Loss: 0.013622959144413471\n",
      "Epoch 1871, Loss: 0.030207878910005093, Final Batch Loss: 0.012432091869413853\n",
      "Epoch 1872, Loss: 0.06705557368695736, Final Batch Loss: 0.030400319024920464\n",
      "Epoch 1873, Loss: 0.03557879198342562, Final Batch Loss: 0.027225704863667488\n",
      "Epoch 1874, Loss: 0.06445912830531597, Final Batch Loss: 0.048215847462415695\n",
      "Epoch 1875, Loss: 0.05263521056622267, Final Batch Loss: 0.012238848023116589\n",
      "Epoch 1876, Loss: 0.042294252663850784, Final Batch Loss: 0.010656088590621948\n",
      "Epoch 1877, Loss: 0.02756685926578939, Final Batch Loss: 0.002140801167115569\n",
      "Epoch 1878, Loss: 0.0259772976860404, Final Batch Loss: 0.010856607928872108\n",
      "Epoch 1879, Loss: 0.04150205757468939, Final Batch Loss: 0.031083550304174423\n",
      "Epoch 1880, Loss: 0.04186388850212097, Final Batch Loss: 0.029288966208696365\n",
      "Epoch 1881, Loss: 0.024454781785607338, Final Batch Loss: 0.011555579490959644\n",
      "Epoch 1882, Loss: 0.04720786865800619, Final Batch Loss: 0.033301062881946564\n",
      "Epoch 1883, Loss: 0.06438429281115532, Final Batch Loss: 0.04362424835562706\n",
      "Epoch 1884, Loss: 0.036332312040030956, Final Batch Loss: 0.02493184618651867\n",
      "Epoch 1885, Loss: 0.05734340846538544, Final Batch Loss: 0.013732604682445526\n",
      "Epoch 1886, Loss: 0.036205233074724674, Final Batch Loss: 0.009350419975817204\n",
      "Epoch 1887, Loss: 0.028445452451705933, Final Batch Loss: 0.012570073828101158\n",
      "Epoch 1888, Loss: 0.03447636775672436, Final Batch Loss: 0.029016038402915\n",
      "Epoch 1889, Loss: 0.031587899662554264, Final Batch Loss: 0.010439208708703518\n",
      "Epoch 1890, Loss: 0.041314342990517616, Final Batch Loss: 0.01648673601448536\n",
      "Epoch 1891, Loss: 0.10586722008883953, Final Batch Loss: 0.08831086754798889\n",
      "Epoch 1892, Loss: 0.025680325459688902, Final Batch Loss: 0.018883761018514633\n",
      "Epoch 1893, Loss: 0.0400840537622571, Final Batch Loss: 0.008613531477749348\n",
      "Epoch 1894, Loss: 0.02030603028833866, Final Batch Loss: 0.008197220973670483\n",
      "Epoch 1895, Loss: 0.04348207637667656, Final Batch Loss: 0.012392278760671616\n",
      "Epoch 1896, Loss: 0.037984950467944145, Final Batch Loss: 0.020850826054811478\n",
      "Epoch 1897, Loss: 0.035525212064385414, Final Batch Loss: 0.027621787041425705\n",
      "Epoch 1898, Loss: 0.015914898831397295, Final Batch Loss: 0.004292130004614592\n",
      "Epoch 1899, Loss: 0.035015237517654896, Final Batch Loss: 0.013755307532846928\n",
      "Epoch 1900, Loss: 0.019944225903600454, Final Batch Loss: 0.005493687000125647\n",
      "Epoch 1901, Loss: 0.03537808731198311, Final Batch Loss: 0.010173248127102852\n",
      "Epoch 1902, Loss: 0.043510209769010544, Final Batch Loss: 0.031882308423519135\n",
      "Epoch 1903, Loss: 0.03252753219567239, Final Batch Loss: 0.003022873541340232\n",
      "Epoch 1904, Loss: 0.021956074982881546, Final Batch Loss: 0.01112015638500452\n",
      "Epoch 1905, Loss: 0.024930131621658802, Final Batch Loss: 0.011284392327070236\n",
      "Epoch 1906, Loss: 0.04220065660774708, Final Batch Loss: 0.03345971927046776\n",
      "Epoch 1907, Loss: 0.030371252447366714, Final Batch Loss: 0.014029610902071\n",
      "Epoch 1908, Loss: 0.054377414751797915, Final Batch Loss: 0.04822024703025818\n",
      "Epoch 1909, Loss: 0.06134026497602463, Final Batch Loss: 0.04680376872420311\n",
      "Epoch 1910, Loss: 0.026544620282948017, Final Batch Loss: 0.007930300198495388\n",
      "Epoch 1911, Loss: 0.025578325614333153, Final Batch Loss: 0.010830914601683617\n",
      "Epoch 1912, Loss: 0.019668156281113625, Final Batch Loss: 0.009985593147575855\n",
      "Epoch 1913, Loss: 0.032213219441473484, Final Batch Loss: 0.021655377000570297\n",
      "Epoch 1914, Loss: 0.03083182405680418, Final Batch Loss: 0.010294918902218342\n",
      "Epoch 1915, Loss: 0.022207431495189667, Final Batch Loss: 0.005413683131337166\n",
      "Epoch 1916, Loss: 0.03501126170158386, Final Batch Loss: 0.024839943274855614\n",
      "Epoch 1917, Loss: 0.047484397888183594, Final Batch Loss: 0.02778787724673748\n",
      "Epoch 1918, Loss: 0.012124843429774046, Final Batch Loss: 0.005172294098883867\n",
      "Epoch 1919, Loss: 0.016007605474442244, Final Batch Loss: 0.00439005671069026\n",
      "Epoch 1920, Loss: 0.029228586703538895, Final Batch Loss: 0.021333549171686172\n",
      "Epoch 1921, Loss: 0.020858032628893852, Final Batch Loss: 0.016471173614263535\n",
      "Epoch 1922, Loss: 0.045521512161940336, Final Batch Loss: 0.039533376693725586\n",
      "Epoch 1923, Loss: 0.016698691993951797, Final Batch Loss: 0.009544347412884235\n",
      "Epoch 1924, Loss: 0.030927822459489107, Final Batch Loss: 0.007112754974514246\n",
      "Epoch 1925, Loss: 0.01944711245596409, Final Batch Loss: 0.009248564019799232\n",
      "Epoch 1926, Loss: 0.01024184888228774, Final Batch Loss: 0.003394868690520525\n",
      "Epoch 1927, Loss: 0.042861687019467354, Final Batch Loss: 0.024300016462802887\n",
      "Epoch 1928, Loss: 0.0637529119849205, Final Batch Loss: 0.05308891087770462\n",
      "Epoch 1929, Loss: 0.03627728298306465, Final Batch Loss: 0.028071701526641846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1930, Loss: 0.017063826322555542, Final Batch Loss: 0.004544692113995552\n",
      "Epoch 1931, Loss: 0.01671824138611555, Final Batch Loss: 0.009251800365746021\n",
      "Epoch 1932, Loss: 0.04294165410101414, Final Batch Loss: 0.01912059634923935\n",
      "Epoch 1933, Loss: 0.055569928139448166, Final Batch Loss: 0.020963173359632492\n",
      "Epoch 1934, Loss: 0.043357206508517265, Final Batch Loss: 0.023615291342139244\n",
      "Epoch 1935, Loss: 0.028515512123703957, Final Batch Loss: 0.011055754497647285\n",
      "Epoch 1936, Loss: 0.0399318328127265, Final Batch Loss: 0.03326868638396263\n",
      "Epoch 1937, Loss: 0.019321265863254666, Final Batch Loss: 0.003497318597510457\n",
      "Epoch 1938, Loss: 0.014640833716839552, Final Batch Loss: 0.004759210627526045\n",
      "Epoch 1939, Loss: 0.045185090973973274, Final Batch Loss: 0.019757166504859924\n",
      "Epoch 1940, Loss: 0.028097287751734257, Final Batch Loss: 0.016154250130057335\n",
      "Epoch 1941, Loss: 0.028483630623668432, Final Batch Loss: 0.006819094996899366\n",
      "Epoch 1942, Loss: 0.0382719449698925, Final Batch Loss: 0.01815887913107872\n",
      "Epoch 1943, Loss: 0.024463619105517864, Final Batch Loss: 0.009850677102804184\n",
      "Epoch 1944, Loss: 0.06119971536099911, Final Batch Loss: 0.01459445245563984\n",
      "Epoch 1945, Loss: 0.028447403572499752, Final Batch Loss: 0.01835266500711441\n",
      "Epoch 1946, Loss: 0.026342386845499277, Final Batch Loss: 0.006645070854574442\n",
      "Epoch 1947, Loss: 0.042041150853037834, Final Batch Loss: 0.021319251507520676\n",
      "Epoch 1948, Loss: 0.02583531104028225, Final Batch Loss: 0.014423246495425701\n",
      "Epoch 1949, Loss: 0.049634771421551704, Final Batch Loss: 0.03284752741456032\n",
      "Epoch 1950, Loss: 0.019136516842991114, Final Batch Loss: 0.0060975938104093075\n",
      "Epoch 1951, Loss: 0.02814868465065956, Final Batch Loss: 0.017804425209760666\n",
      "Epoch 1952, Loss: 0.02435792190954089, Final Batch Loss: 0.02066303975880146\n",
      "Epoch 1953, Loss: 0.011427840683609247, Final Batch Loss: 0.004854355938732624\n",
      "Epoch 1954, Loss: 0.0807039774954319, Final Batch Loss: 0.07128509134054184\n",
      "Epoch 1955, Loss: 0.018415706930682063, Final Batch Loss: 0.0027798216324299574\n",
      "Epoch 1956, Loss: 0.07533072866499424, Final Batch Loss: 0.05334583297371864\n",
      "Epoch 1957, Loss: 0.03706394322216511, Final Batch Loss: 0.010378478094935417\n",
      "Epoch 1958, Loss: 0.009306569583714008, Final Batch Loss: 0.003998901229351759\n",
      "Epoch 1959, Loss: 0.06944960355758667, Final Batch Loss: 0.020834509283304214\n",
      "Epoch 1960, Loss: 0.030836821533739567, Final Batch Loss: 0.009091242216527462\n",
      "Epoch 1961, Loss: 0.018969353288412094, Final Batch Loss: 0.008049816824495792\n",
      "Epoch 1962, Loss: 0.027471652254462242, Final Batch Loss: 0.008667057380080223\n",
      "Epoch 1963, Loss: 0.03862006030976772, Final Batch Loss: 0.017493221908807755\n",
      "Epoch 1964, Loss: 0.0335174473002553, Final Batch Loss: 0.00918030645698309\n",
      "Epoch 1965, Loss: 0.021007006987929344, Final Batch Loss: 0.012445983476936817\n",
      "Epoch 1966, Loss: 0.019717864925041795, Final Batch Loss: 0.0038195534143596888\n",
      "Epoch 1967, Loss: 0.025362763088196516, Final Batch Loss: 0.019144969061017036\n",
      "Epoch 1968, Loss: 0.0223434348590672, Final Batch Loss: 0.005659629125148058\n",
      "Epoch 1969, Loss: 0.03503597807139158, Final Batch Loss: 0.019459117203950882\n",
      "Epoch 1970, Loss: 0.045270214322954416, Final Batch Loss: 0.04074520617723465\n",
      "Epoch 1971, Loss: 0.03544571250677109, Final Batch Loss: 0.018540117889642715\n",
      "Epoch 1972, Loss: 0.04487447813153267, Final Batch Loss: 0.004618749022483826\n",
      "Epoch 1973, Loss: 0.016782631166279316, Final Batch Loss: 0.009295442141592503\n",
      "Epoch 1974, Loss: 0.02191053982824087, Final Batch Loss: 0.008419987745583057\n",
      "Epoch 1975, Loss: 0.07640968635678291, Final Batch Loss: 0.048850156366825104\n",
      "Epoch 1976, Loss: 0.03903379198163748, Final Batch Loss: 0.02701108530163765\n",
      "Epoch 1977, Loss: 0.04664825089275837, Final Batch Loss: 0.028580406680703163\n",
      "Epoch 1978, Loss: 0.02627316117286682, Final Batch Loss: 0.006181836128234863\n",
      "Epoch 1979, Loss: 0.04564470797777176, Final Batch Loss: 0.04109771177172661\n",
      "Epoch 1980, Loss: 0.02098729833960533, Final Batch Loss: 0.016753006726503372\n",
      "Epoch 1981, Loss: 0.03960692789405584, Final Batch Loss: 0.006941555999219418\n",
      "Epoch 1982, Loss: 0.04573039570823312, Final Batch Loss: 0.007158490363508463\n",
      "Epoch 1983, Loss: 0.059907104820013046, Final Batch Loss: 0.05043238773941994\n",
      "Epoch 1984, Loss: 0.03201417904347181, Final Batch Loss: 0.016740664839744568\n",
      "Epoch 1985, Loss: 0.04435655102133751, Final Batch Loss: 0.02312597818672657\n",
      "Epoch 1986, Loss: 0.01897854800336063, Final Batch Loss: 0.0028336334507912397\n",
      "Epoch 1987, Loss: 0.03514782525599003, Final Batch Loss: 0.018881218507885933\n",
      "Epoch 1988, Loss: 0.017163851764053106, Final Batch Loss: 0.012061940506100655\n",
      "Epoch 1989, Loss: 0.01915333839133382, Final Batch Loss: 0.007228693459182978\n",
      "Epoch 1990, Loss: 0.03744297847151756, Final Batch Loss: 0.019694186747074127\n",
      "Epoch 1991, Loss: 0.025468037463724613, Final Batch Loss: 0.003990828059613705\n",
      "Epoch 1992, Loss: 0.10869482904672623, Final Batch Loss: 0.10193713009357452\n",
      "Epoch 1993, Loss: 0.00994612812064588, Final Batch Loss: 0.0015878367703408003\n",
      "Epoch 1994, Loss: 0.02196156093850732, Final Batch Loss: 0.006190531421452761\n",
      "Epoch 1995, Loss: 0.02881079539656639, Final Batch Loss: 0.01601499319076538\n",
      "Epoch 1996, Loss: 0.045402093324810266, Final Batch Loss: 0.03969131410121918\n",
      "Epoch 1997, Loss: 0.1554223969578743, Final Batch Loss: 0.14197330176830292\n",
      "Epoch 1998, Loss: 0.07329436391592026, Final Batch Loss: 0.040701575577259064\n",
      "Epoch 1999, Loss: 0.0254936208948493, Final Batch Loss: 0.007842878811061382\n",
      "Epoch 2000, Loss: 0.018042595824226737, Final Batch Loss: 0.0032166566234081984\n",
      "Epoch 2001, Loss: 0.027454656548798084, Final Batch Loss: 0.01589217782020569\n",
      "Epoch 2002, Loss: 0.045265368185937405, Final Batch Loss: 0.013445734046399593\n",
      "Epoch 2003, Loss: 0.030336139257997274, Final Batch Loss: 0.007524529006332159\n",
      "Epoch 2004, Loss: 0.061246221885085106, Final Batch Loss: 0.03900456801056862\n",
      "Epoch 2005, Loss: 0.06830648705363274, Final Batch Loss: 0.037116046994924545\n",
      "Epoch 2006, Loss: 0.02541246358305216, Final Batch Loss: 0.009950371459126472\n",
      "Epoch 2007, Loss: 0.02601698972284794, Final Batch Loss: 0.01821098104119301\n",
      "Epoch 2008, Loss: 0.06489291833713651, Final Batch Loss: 0.059356916695833206\n",
      "Epoch 2009, Loss: 0.0640697458293289, Final Batch Loss: 0.0038699449505656958\n",
      "Epoch 2010, Loss: 0.0490932185202837, Final Batch Loss: 0.03158671781420708\n",
      "Epoch 2011, Loss: 0.02029431425035, Final Batch Loss: 0.008074332028627396\n",
      "Epoch 2012, Loss: 0.05360516160726547, Final Batch Loss: 0.029000988230109215\n",
      "Epoch 2013, Loss: 0.019368980079889297, Final Batch Loss: 0.014095057733356953\n",
      "Epoch 2014, Loss: 0.02744507696479559, Final Batch Loss: 0.004571693949401379\n",
      "Epoch 2015, Loss: 0.07898997981101274, Final Batch Loss: 0.06556562334299088\n",
      "Epoch 2016, Loss: 0.01476642838679254, Final Batch Loss: 0.011100434698164463\n",
      "Epoch 2017, Loss: 0.07846640981733799, Final Batch Loss: 0.050294507294893265\n",
      "Epoch 2018, Loss: 0.02876744419336319, Final Batch Loss: 0.008587773889303207\n",
      "Epoch 2019, Loss: 0.09103057906031609, Final Batch Loss: 0.07283780723810196\n",
      "Epoch 2020, Loss: 0.04781407583504915, Final Batch Loss: 0.009883866645395756\n",
      "Epoch 2021, Loss: 0.016466020606458187, Final Batch Loss: 0.006824401207268238\n",
      "Epoch 2022, Loss: 0.09098184108734131, Final Batch Loss: 0.05347801372408867\n",
      "Epoch 2023, Loss: 0.05625450052320957, Final Batch Loss: 0.02361953817307949\n",
      "Epoch 2024, Loss: 0.01839043037034571, Final Batch Loss: 0.0028131233993917704\n",
      "Epoch 2025, Loss: 0.054492032155394554, Final Batch Loss: 0.021224914118647575\n",
      "Epoch 2026, Loss: 0.04748493432998657, Final Batch Loss: 0.021246444433927536\n",
      "Epoch 2027, Loss: 0.026494807563722134, Final Batch Loss: 0.014888077042996883\n",
      "Epoch 2028, Loss: 0.026351495645940304, Final Batch Loss: 0.004205177538096905\n",
      "Epoch 2029, Loss: 0.06245747301727533, Final Batch Loss: 0.012089801020920277\n",
      "Epoch 2030, Loss: 0.046294206753373146, Final Batch Loss: 0.028951318934559822\n",
      "Epoch 2031, Loss: 0.06091745384037495, Final Batch Loss: 0.04860943555831909\n",
      "Epoch 2032, Loss: 0.060668520629405975, Final Batch Loss: 0.019941236823797226\n",
      "Epoch 2033, Loss: 0.09217658825218678, Final Batch Loss: 0.06180036440491676\n",
      "Epoch 2034, Loss: 0.02495709666982293, Final Batch Loss: 0.01933303475379944\n",
      "Epoch 2035, Loss: 0.03292979393154383, Final Batch Loss: 0.014424140565097332\n",
      "Epoch 2036, Loss: 0.029422370716929436, Final Batch Loss: 0.01463162899017334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2037, Loss: 0.04018551670014858, Final Batch Loss: 0.02043183334171772\n",
      "Epoch 2038, Loss: 0.024649305269122124, Final Batch Loss: 0.011054356582462788\n",
      "Epoch 2039, Loss: 0.028471045196056366, Final Batch Loss: 0.01583872176706791\n",
      "Epoch 2040, Loss: 0.037876333110034466, Final Batch Loss: 0.009192961268126965\n",
      "Epoch 2041, Loss: 0.014856026042252779, Final Batch Loss: 0.00760918203741312\n",
      "Epoch 2042, Loss: 0.023424499668180943, Final Batch Loss: 0.013011484406888485\n",
      "Epoch 2043, Loss: 0.04503835737705231, Final Batch Loss: 0.024597058072686195\n",
      "Epoch 2044, Loss: 0.04649621620774269, Final Batch Loss: 0.022939985617995262\n",
      "Epoch 2045, Loss: 0.029638931155204773, Final Batch Loss: 0.01539601944386959\n",
      "Epoch 2046, Loss: 0.017291363328695297, Final Batch Loss: 0.0045229848474264145\n",
      "Epoch 2047, Loss: 0.029287834651768208, Final Batch Loss: 0.02310762368142605\n",
      "Epoch 2048, Loss: 0.06245319079607725, Final Batch Loss: 0.05051257088780403\n",
      "Epoch 2049, Loss: 0.020517200231552124, Final Batch Loss: 0.008883359842002392\n",
      "Epoch 2050, Loss: 0.024731295183300972, Final Batch Loss: 0.016733819618821144\n",
      "Epoch 2051, Loss: 0.042149536311626434, Final Batch Loss: 0.017972679808735847\n",
      "Epoch 2052, Loss: 0.02285714726895094, Final Batch Loss: 0.008987939916551113\n",
      "Epoch 2053, Loss: 0.012158704921603203, Final Batch Loss: 0.00485640624538064\n",
      "Epoch 2054, Loss: 0.021460439544171095, Final Batch Loss: 0.014718101359903812\n",
      "Epoch 2055, Loss: 0.0312997791916132, Final Batch Loss: 0.017861466854810715\n",
      "Epoch 2056, Loss: 0.032388826832175255, Final Batch Loss: 0.02217032201588154\n",
      "Epoch 2057, Loss: 0.03140736371278763, Final Batch Loss: 0.021909838542342186\n",
      "Epoch 2058, Loss: 0.027398865669965744, Final Batch Loss: 0.005582498386502266\n",
      "Epoch 2059, Loss: 0.014253690605983138, Final Batch Loss: 0.0030834923963993788\n",
      "Epoch 2060, Loss: 0.039034321904182434, Final Batch Loss: 0.01744926907122135\n",
      "Epoch 2061, Loss: 0.037906890735030174, Final Batch Loss: 0.003300124779343605\n",
      "Epoch 2062, Loss: 0.01884491555392742, Final Batch Loss: 0.008858500979840755\n",
      "Epoch 2063, Loss: 0.02782846475020051, Final Batch Loss: 0.004009981174021959\n",
      "Epoch 2064, Loss: 0.05362425744533539, Final Batch Loss: 0.007765725255012512\n",
      "Epoch 2065, Loss: 0.027475768700242043, Final Batch Loss: 0.017319535836577415\n",
      "Epoch 2066, Loss: 0.019101853482425213, Final Batch Loss: 0.00963712390512228\n",
      "Epoch 2067, Loss: 0.03794975113123655, Final Batch Loss: 0.02289222553372383\n",
      "Epoch 2068, Loss: 0.01069690566509962, Final Batch Loss: 0.006626778282225132\n",
      "Epoch 2069, Loss: 0.015625099651515484, Final Batch Loss: 0.00495077483355999\n",
      "Epoch 2070, Loss: 0.027622951893135905, Final Batch Loss: 0.0033670503180474043\n",
      "Epoch 2071, Loss: 0.016745537985116243, Final Batch Loss: 0.006980253849178553\n",
      "Epoch 2072, Loss: 0.04328756593167782, Final Batch Loss: 0.017789339646697044\n",
      "Epoch 2073, Loss: 0.013489014469087124, Final Batch Loss: 0.0062600914388895035\n",
      "Epoch 2074, Loss: 0.022729048505425453, Final Batch Loss: 0.014931499026715755\n",
      "Epoch 2075, Loss: 0.04485185071825981, Final Batch Loss: 0.018824126571416855\n",
      "Epoch 2076, Loss: 0.0581457894295454, Final Batch Loss: 0.029141342267394066\n",
      "Epoch 2077, Loss: 0.023063047789037228, Final Batch Loss: 0.011977276764810085\n",
      "Epoch 2078, Loss: 0.05873005464673042, Final Batch Loss: 0.041139762848615646\n",
      "Epoch 2079, Loss: 0.027260986622422934, Final Batch Loss: 0.003941675182431936\n",
      "Epoch 2080, Loss: 0.062246209010481834, Final Batch Loss: 0.020461170002818108\n",
      "Epoch 2081, Loss: 0.11888113431632519, Final Batch Loss: 0.0950997993350029\n",
      "Epoch 2082, Loss: 0.024259301833808422, Final Batch Loss: 0.008850479498505592\n",
      "Epoch 2083, Loss: 0.049886807799339294, Final Batch Loss: 0.031356487423181534\n",
      "Epoch 2084, Loss: 0.045459610410034657, Final Batch Loss: 0.033204708248376846\n",
      "Epoch 2085, Loss: 0.03004283830523491, Final Batch Loss: 0.02183031104505062\n",
      "Epoch 2086, Loss: 0.020622994285076857, Final Batch Loss: 0.013819735497236252\n",
      "Epoch 2087, Loss: 0.025777884759008884, Final Batch Loss: 0.009235969744622707\n",
      "Epoch 2088, Loss: 0.045652913860976696, Final Batch Loss: 0.03384159132838249\n",
      "Epoch 2089, Loss: 0.020434550940990448, Final Batch Loss: 0.009386525489389896\n",
      "Epoch 2090, Loss: 0.03295578341931105, Final Batch Loss: 0.028126057237386703\n",
      "Epoch 2091, Loss: 0.017921466380357742, Final Batch Loss: 0.005243499763309956\n",
      "Epoch 2092, Loss: 0.0609572040848434, Final Batch Loss: 0.005169443320482969\n",
      "Epoch 2093, Loss: 0.02539463574066758, Final Batch Loss: 0.006445797625929117\n",
      "Epoch 2094, Loss: 0.04614744894206524, Final Batch Loss: 0.0295411366969347\n",
      "Epoch 2095, Loss: 0.052333781495690346, Final Batch Loss: 0.03590391203761101\n",
      "Epoch 2096, Loss: 0.054666683077812195, Final Batch Loss: 0.037864137440919876\n",
      "Epoch 2097, Loss: 0.013520321808755398, Final Batch Loss: 0.004110937938094139\n",
      "Epoch 2098, Loss: 0.039630856830626726, Final Batch Loss: 0.03378641605377197\n",
      "Epoch 2099, Loss: 0.07530964724719524, Final Batch Loss: 0.0272109005600214\n",
      "Epoch 2100, Loss: 0.019982059486210346, Final Batch Loss: 0.013988110236823559\n",
      "Epoch 2101, Loss: 0.012079565785825253, Final Batch Loss: 0.006326745729893446\n",
      "Epoch 2102, Loss: 0.03384915366768837, Final Batch Loss: 0.01588178612291813\n",
      "Epoch 2103, Loss: 0.019321586471050978, Final Batch Loss: 0.01192744355648756\n",
      "Epoch 2104, Loss: 0.06669471971690655, Final Batch Loss: 0.03881505876779556\n",
      "Epoch 2105, Loss: 0.036306499037891626, Final Batch Loss: 0.007186560425907373\n",
      "Epoch 2106, Loss: 0.037198045291006565, Final Batch Loss: 0.008827089332044125\n",
      "Epoch 2107, Loss: 0.041609239764511585, Final Batch Loss: 0.028317555785179138\n",
      "Epoch 2108, Loss: 0.06061677448451519, Final Batch Loss: 0.05088817700743675\n",
      "Epoch 2109, Loss: 0.03539513424038887, Final Batch Loss: 0.010045427829027176\n",
      "Epoch 2110, Loss: 0.018942986149340868, Final Batch Loss: 0.004569055046886206\n",
      "Epoch 2111, Loss: 0.018656293861567974, Final Batch Loss: 0.009090673178434372\n",
      "Epoch 2112, Loss: 0.05371978785842657, Final Batch Loss: 0.04362459480762482\n",
      "Epoch 2113, Loss: 0.03097831178456545, Final Batch Loss: 0.01320998091250658\n",
      "Epoch 2114, Loss: 0.03098869789391756, Final Batch Loss: 0.00489539559930563\n",
      "Epoch 2115, Loss: 0.04039699770510197, Final Batch Loss: 0.016185792163014412\n",
      "Epoch 2116, Loss: 0.013598504941910505, Final Batch Loss: 0.006591083016246557\n",
      "Epoch 2117, Loss: 0.05566026456654072, Final Batch Loss: 0.03306272253394127\n",
      "Epoch 2118, Loss: 0.0998656302690506, Final Batch Loss: 0.03919614478945732\n",
      "Epoch 2119, Loss: 0.021160071133635938, Final Batch Loss: 0.0010237855603918433\n",
      "Epoch 2120, Loss: 0.1709727644920349, Final Batch Loss: 0.08886992186307907\n",
      "Epoch 2121, Loss: 0.06395372934639454, Final Batch Loss: 0.02537520043551922\n",
      "Epoch 2122, Loss: 0.0311970179900527, Final Batch Loss: 0.011233632452785969\n",
      "Epoch 2123, Loss: 0.07019934430718422, Final Batch Loss: 0.01679297164082527\n",
      "Epoch 2124, Loss: 0.0364557895809412, Final Batch Loss: 0.021664852276444435\n",
      "Epoch 2125, Loss: 0.02440200001001358, Final Batch Loss: 0.009390605613589287\n",
      "Epoch 2126, Loss: 0.02822269219905138, Final Batch Loss: 0.023455070331692696\n",
      "Epoch 2127, Loss: 0.03191836643964052, Final Batch Loss: 0.010783656500279903\n",
      "Epoch 2128, Loss: 0.015450913459062576, Final Batch Loss: 0.010133018717169762\n",
      "Epoch 2129, Loss: 0.017325887456536293, Final Batch Loss: 0.012599261477589607\n",
      "Epoch 2130, Loss: 0.016524878796190023, Final Batch Loss: 0.011159863322973251\n",
      "Epoch 2131, Loss: 0.04162040539085865, Final Batch Loss: 0.018374696373939514\n",
      "Epoch 2132, Loss: 0.013940746430307627, Final Batch Loss: 0.007522529922425747\n",
      "Epoch 2133, Loss: 0.006671241484582424, Final Batch Loss: 0.0015736641362309456\n",
      "Epoch 2134, Loss: 0.027415005024522543, Final Batch Loss: 0.00561935780569911\n",
      "Epoch 2135, Loss: 0.0106516950763762, Final Batch Loss: 0.0036520883440971375\n",
      "Epoch 2136, Loss: 0.017076113261282444, Final Batch Loss: 0.009907731786370277\n",
      "Epoch 2137, Loss: 0.007533221272751689, Final Batch Loss: 0.0038665952160954475\n",
      "Epoch 2138, Loss: 0.03412075759842992, Final Batch Loss: 0.02762598544359207\n",
      "Epoch 2139, Loss: 0.046345144510269165, Final Batch Loss: 0.007236003875732422\n",
      "Epoch 2140, Loss: 0.019701810088008642, Final Batch Loss: 0.013968382962048054\n",
      "Epoch 2141, Loss: 0.03966515325009823, Final Batch Loss: 0.018651681020855904\n",
      "Epoch 2142, Loss: 0.009926199680194259, Final Batch Loss: 0.003701399313285947\n",
      "Epoch 2143, Loss: 0.03438181756064296, Final Batch Loss: 0.007251666393131018\n",
      "Epoch 2144, Loss: 0.040241539478302, Final Batch Loss: 0.01942543499171734\n",
      "Epoch 2145, Loss: 0.04285613726824522, Final Batch Loss: 0.033727485686540604\n",
      "Epoch 2146, Loss: 0.01900319056585431, Final Batch Loss: 0.012994213961064816\n",
      "Epoch 2147, Loss: 0.029064572416245937, Final Batch Loss: 0.01438121683895588\n",
      "Epoch 2148, Loss: 0.02491777716204524, Final Batch Loss: 0.0021814382635056973\n",
      "Epoch 2149, Loss: 0.016256543807685375, Final Batch Loss: 0.008040809072554111\n",
      "Epoch 2150, Loss: 0.015871359268203378, Final Batch Loss: 0.002262706169858575\n",
      "Epoch 2151, Loss: 0.013078342657536268, Final Batch Loss: 0.008396673016250134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2152, Loss: 0.0374513128772378, Final Batch Loss: 0.008246554993093014\n",
      "Epoch 2153, Loss: 0.022822847589850426, Final Batch Loss: 0.015598203055560589\n",
      "Epoch 2154, Loss: 0.016055119689553976, Final Batch Loss: 0.004289702977985144\n",
      "Epoch 2155, Loss: 0.016850538086146116, Final Batch Loss: 0.0073411003686487675\n",
      "Epoch 2156, Loss: 0.04696916462853551, Final Batch Loss: 0.005000379402190447\n",
      "Epoch 2157, Loss: 0.06047352682799101, Final Batch Loss: 0.05359198525547981\n",
      "Epoch 2158, Loss: 0.033538924530148506, Final Batch Loss: 0.01618449203670025\n",
      "Epoch 2159, Loss: 0.025276789907366037, Final Batch Loss: 0.007271854672580957\n",
      "Epoch 2160, Loss: 0.014612866099923849, Final Batch Loss: 0.010561729781329632\n",
      "Epoch 2161, Loss: 0.016631033271551132, Final Batch Loss: 0.006361865438520908\n",
      "Epoch 2162, Loss: 0.029548280872404575, Final Batch Loss: 0.015623698942363262\n",
      "Epoch 2163, Loss: 0.02075614593923092, Final Batch Loss: 0.00824764370918274\n",
      "Epoch 2164, Loss: 0.00864502927288413, Final Batch Loss: 0.004083399195224047\n",
      "Epoch 2165, Loss: 0.03184756636619568, Final Batch Loss: 0.021054426208138466\n",
      "Epoch 2166, Loss: 0.019193473737686872, Final Batch Loss: 0.007007039617747068\n",
      "Epoch 2167, Loss: 0.012087367475032806, Final Batch Loss: 0.008124254643917084\n",
      "Epoch 2168, Loss: 0.024115036241710186, Final Batch Loss: 0.007030493579804897\n",
      "Epoch 2169, Loss: 0.022993783466517925, Final Batch Loss: 0.011843805201351643\n",
      "Epoch 2170, Loss: 0.043433234095573425, Final Batch Loss: 0.016759252175688744\n",
      "Epoch 2171, Loss: 0.032396203838288784, Final Batch Loss: 0.02413761429488659\n",
      "Epoch 2172, Loss: 0.03166580758988857, Final Batch Loss: 0.013945555314421654\n",
      "Epoch 2173, Loss: 0.008280407404527068, Final Batch Loss: 0.005106298718601465\n",
      "Epoch 2174, Loss: 0.03181886952370405, Final Batch Loss: 0.013765078969299793\n",
      "Epoch 2175, Loss: 0.02020704746246338, Final Batch Loss: 0.01405092142522335\n",
      "Epoch 2176, Loss: 0.03177123051136732, Final Batch Loss: 0.015410189516842365\n",
      "Epoch 2177, Loss: 0.01144848670810461, Final Batch Loss: 0.003673077095299959\n",
      "Epoch 2178, Loss: 0.010862319031730294, Final Batch Loss: 0.002990249777212739\n",
      "Epoch 2179, Loss: 0.019741772674024105, Final Batch Loss: 0.008907751180231571\n",
      "Epoch 2180, Loss: 0.028356189839541912, Final Batch Loss: 0.007000933401286602\n",
      "Epoch 2181, Loss: 0.0510155139490962, Final Batch Loss: 0.040229033678770065\n",
      "Epoch 2182, Loss: 0.03380458243191242, Final Batch Loss: 0.011920405551791191\n",
      "Epoch 2183, Loss: 0.007465263595804572, Final Batch Loss: 0.0026123293209820986\n",
      "Epoch 2184, Loss: 0.02216058550402522, Final Batch Loss: 0.003411292564123869\n",
      "Epoch 2185, Loss: 0.06758972071111202, Final Batch Loss: 0.030612627044320107\n",
      "Epoch 2186, Loss: 0.02722541894763708, Final Batch Loss: 0.0173010416328907\n",
      "Epoch 2187, Loss: 0.008810177678242326, Final Batch Loss: 0.0028902494814246893\n",
      "Epoch 2188, Loss: 0.03443218395113945, Final Batch Loss: 0.0062300097197294235\n",
      "Epoch 2189, Loss: 0.014775778166949749, Final Batch Loss: 0.005987844429910183\n",
      "Epoch 2190, Loss: 0.03519706521183252, Final Batch Loss: 0.020107265561819077\n",
      "Epoch 2191, Loss: 0.016307521611452103, Final Batch Loss: 0.007645811885595322\n",
      "Epoch 2192, Loss: 0.019927711226046085, Final Batch Loss: 0.00820537656545639\n",
      "Epoch 2193, Loss: 0.03122222563251853, Final Batch Loss: 0.00758941238746047\n",
      "Epoch 2194, Loss: 0.018577557988464832, Final Batch Loss: 0.008525136858224869\n",
      "Epoch 2195, Loss: 0.015975415357388556, Final Batch Loss: 0.0015756149077787995\n",
      "Epoch 2196, Loss: 0.03419690625742078, Final Batch Loss: 0.005228559020906687\n",
      "Epoch 2197, Loss: 0.02796829864382744, Final Batch Loss: 0.012671561911702156\n",
      "Epoch 2198, Loss: 0.020055448170751333, Final Batch Loss: 0.013173192739486694\n",
      "Epoch 2199, Loss: 0.03947596065700054, Final Batch Loss: 0.012055689468979836\n",
      "Epoch 2200, Loss: 0.059385028667747974, Final Batch Loss: 0.010241095907986164\n",
      "Epoch 2201, Loss: 0.12536060344427824, Final Batch Loss: 0.11523821949958801\n",
      "Epoch 2202, Loss: 0.031036341562867165, Final Batch Loss: 0.011118430644273758\n",
      "Epoch 2203, Loss: 0.08345842361450195, Final Batch Loss: 0.041295330971479416\n",
      "Epoch 2204, Loss: 0.016124510439112782, Final Batch Loss: 0.002766155870631337\n",
      "Epoch 2205, Loss: 0.14101998135447502, Final Batch Loss: 0.08921384066343307\n",
      "Epoch 2206, Loss: 0.022995130391791463, Final Batch Loss: 0.0030898910481482744\n",
      "Epoch 2207, Loss: 0.0454011270776391, Final Batch Loss: 0.03224559500813484\n",
      "Epoch 2208, Loss: 0.013595129130408168, Final Batch Loss: 0.002116596093401313\n",
      "Epoch 2209, Loss: 0.016829635947942734, Final Batch Loss: 0.01012306660413742\n",
      "Epoch 2210, Loss: 0.023556469939649105, Final Batch Loss: 0.008574266918003559\n",
      "Epoch 2211, Loss: 0.009526481619104743, Final Batch Loss: 0.002410108456388116\n",
      "Epoch 2212, Loss: 0.026383999967947602, Final Batch Loss: 0.022757645696401596\n",
      "Epoch 2213, Loss: 0.057812441140413284, Final Batch Loss: 0.03025890700519085\n",
      "Epoch 2214, Loss: 0.03847475349903107, Final Batch Loss: 0.025459492579102516\n",
      "Epoch 2215, Loss: 0.031706832349300385, Final Batch Loss: 0.016954196617007256\n",
      "Epoch 2216, Loss: 0.022874473128467798, Final Batch Loss: 0.020265119150280952\n",
      "Epoch 2217, Loss: 0.010495130438357592, Final Batch Loss: 0.005085688550025225\n",
      "Epoch 2218, Loss: 0.04976662993431091, Final Batch Loss: 0.033803898841142654\n",
      "Epoch 2219, Loss: 0.020656029228121042, Final Batch Loss: 0.0030019902624189854\n",
      "Epoch 2220, Loss: 0.07825553044676781, Final Batch Loss: 0.03582696244120598\n",
      "Epoch 2221, Loss: 0.03661729395389557, Final Batch Loss: 0.015986500307917595\n",
      "Epoch 2222, Loss: 0.03367116767913103, Final Batch Loss: 0.01995125040411949\n",
      "Epoch 2223, Loss: 0.04454214125871658, Final Batch Loss: 0.017420625314116478\n",
      "Epoch 2224, Loss: 0.024778629653155804, Final Batch Loss: 0.014727341942489147\n",
      "Epoch 2225, Loss: 0.017632292117923498, Final Batch Loss: 0.010528100654482841\n",
      "Epoch 2226, Loss: 0.017799434019252658, Final Batch Loss: 0.015414200723171234\n",
      "Epoch 2227, Loss: 0.04423602111637592, Final Batch Loss: 0.020022327080368996\n",
      "Epoch 2228, Loss: 0.03542135562747717, Final Batch Loss: 0.012921608053147793\n",
      "Epoch 2229, Loss: 0.020291799679398537, Final Batch Loss: 0.008466391824185848\n",
      "Epoch 2230, Loss: 0.023072550538927317, Final Batch Loss: 0.00694022374227643\n",
      "Epoch 2231, Loss: 0.009804160101339221, Final Batch Loss: 0.0036460182163864374\n",
      "Epoch 2232, Loss: 0.050378354266285896, Final Batch Loss: 0.013334831222891808\n",
      "Epoch 2233, Loss: 0.020783151499927044, Final Batch Loss: 0.012271175161004066\n",
      "Epoch 2234, Loss: 0.030263256281614304, Final Batch Loss: 0.004037277773022652\n",
      "Epoch 2235, Loss: 0.0445177280344069, Final Batch Loss: 0.0058490135706961155\n",
      "Epoch 2236, Loss: 0.02098307851701975, Final Batch Loss: 0.0167770367115736\n",
      "Epoch 2237, Loss: 0.012351490091532469, Final Batch Loss: 0.004444492515176535\n",
      "Epoch 2238, Loss: 0.010964990127831697, Final Batch Loss: 0.004341376479715109\n",
      "Epoch 2239, Loss: 0.0758549626916647, Final Batch Loss: 0.062253355979919434\n",
      "Epoch 2240, Loss: 0.014622958144173026, Final Batch Loss: 0.002701797289773822\n",
      "Epoch 2241, Loss: 0.0367891862988472, Final Batch Loss: 0.005657972767949104\n",
      "Epoch 2242, Loss: 0.014230722561478615, Final Batch Loss: 0.010184443555772305\n",
      "Epoch 2243, Loss: 0.015176782850176096, Final Batch Loss: 0.01067032665014267\n",
      "Epoch 2244, Loss: 0.014018386136740446, Final Batch Loss: 0.011261341162025928\n",
      "Epoch 2245, Loss: 0.02490366157144308, Final Batch Loss: 0.009630095213651657\n",
      "Epoch 2246, Loss: 0.022720722015947104, Final Batch Loss: 0.00495409918949008\n",
      "Epoch 2247, Loss: 0.05223968531936407, Final Batch Loss: 0.039406146854162216\n",
      "Epoch 2248, Loss: 0.013557114638388157, Final Batch Loss: 0.009466612711548805\n",
      "Epoch 2249, Loss: 0.02611946500837803, Final Batch Loss: 0.008684670552611351\n",
      "Epoch 2250, Loss: 0.015062557999044657, Final Batch Loss: 0.0037381774745881557\n",
      "Epoch 2251, Loss: 0.011754408711567521, Final Batch Loss: 0.002453784691169858\n",
      "Epoch 2252, Loss: 0.01289966981858015, Final Batch Loss: 0.007504008244723082\n",
      "Epoch 2253, Loss: 0.01116243633441627, Final Batch Loss: 0.0035247558262199163\n",
      "Epoch 2254, Loss: 0.07914851419627666, Final Batch Loss: 0.01641678623855114\n",
      "Epoch 2255, Loss: 0.014094353886321187, Final Batch Loss: 0.00352478981949389\n",
      "Epoch 2256, Loss: 0.060139354318380356, Final Batch Loss: 0.0418986901640892\n",
      "Epoch 2257, Loss: 0.037507384084165096, Final Batch Loss: 0.010748346336185932\n",
      "Epoch 2258, Loss: 0.030748365446925163, Final Batch Loss: 0.017463382333517075\n",
      "Epoch 2259, Loss: 0.010350930970162153, Final Batch Loss: 0.005170358344912529\n",
      "Epoch 2260, Loss: 0.024008676409721375, Final Batch Loss: 0.010928024537861347\n",
      "Epoch 2261, Loss: 0.033398523926734924, Final Batch Loss: 0.010014547035098076\n",
      "Epoch 2262, Loss: 0.011503855232149363, Final Batch Loss: 0.006664075423032045\n",
      "Epoch 2263, Loss: 0.047954285982996225, Final Batch Loss: 0.04358365386724472\n",
      "Epoch 2264, Loss: 0.011337292846292257, Final Batch Loss: 0.0040567610412836075\n",
      "Epoch 2265, Loss: 0.025579582899808884, Final Batch Loss: 0.011358091607689857\n",
      "Epoch 2266, Loss: 0.019442802760750055, Final Batch Loss: 0.00466327415779233\n",
      "Epoch 2267, Loss: 0.02877753460779786, Final Batch Loss: 0.021277746185660362\n",
      "Epoch 2268, Loss: 0.031494808383286, Final Batch Loss: 0.021410446614027023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2269, Loss: 0.010975174140185118, Final Batch Loss: 0.005554203875362873\n",
      "Epoch 2270, Loss: 0.052486483473330736, Final Batch Loss: 0.04809970408678055\n",
      "Epoch 2271, Loss: 0.018510660622268915, Final Batch Loss: 0.004726236220449209\n",
      "Epoch 2272, Loss: 0.011022686026990414, Final Batch Loss: 0.006397689692676067\n",
      "Epoch 2273, Loss: 0.015147545840591192, Final Batch Loss: 0.008286946453154087\n",
      "Epoch 2274, Loss: 0.08006920292973518, Final Batch Loss: 0.03167540207505226\n",
      "Epoch 2275, Loss: 0.00937805906869471, Final Batch Loss: 0.0035105834249407053\n",
      "Epoch 2276, Loss: 0.034573988523334265, Final Batch Loss: 0.02843713015317917\n",
      "Epoch 2277, Loss: 0.047284092754125595, Final Batch Loss: 0.013424042612314224\n",
      "Epoch 2278, Loss: 0.04067242005839944, Final Batch Loss: 0.034150995314121246\n",
      "Epoch 2279, Loss: 0.014848825056105852, Final Batch Loss: 0.004995038267225027\n",
      "Epoch 2280, Loss: 0.06425752490758896, Final Batch Loss: 0.04525820165872574\n",
      "Epoch 2281, Loss: 0.020627831108868122, Final Batch Loss: 0.010632330551743507\n",
      "Epoch 2282, Loss: 0.09078026004135609, Final Batch Loss: 0.07042711973190308\n",
      "Epoch 2283, Loss: 0.03564358875155449, Final Batch Loss: 0.02654448337852955\n",
      "Epoch 2284, Loss: 0.041524192318320274, Final Batch Loss: 0.023577503859996796\n",
      "Epoch 2285, Loss: 0.06143402960151434, Final Batch Loss: 0.012312526814639568\n",
      "Epoch 2286, Loss: 0.044243252370506525, Final Batch Loss: 0.03796840459108353\n",
      "Epoch 2287, Loss: 0.022913681343197823, Final Batch Loss: 0.00722920149564743\n",
      "Epoch 2288, Loss: 0.056736208498477936, Final Batch Loss: 0.029318341985344887\n",
      "Epoch 2289, Loss: 0.032487278804183006, Final Batch Loss: 0.019279375672340393\n",
      "Epoch 2290, Loss: 0.08825105801224709, Final Batch Loss: 0.06808048486709595\n",
      "Epoch 2291, Loss: 0.05217675678431988, Final Batch Loss: 0.04652462154626846\n",
      "Epoch 2292, Loss: 0.09564275480806828, Final Batch Loss: 0.02584169991314411\n",
      "Epoch 2293, Loss: 0.04015798028558493, Final Batch Loss: 0.013748998753726482\n",
      "Epoch 2294, Loss: 0.10479284822940826, Final Batch Loss: 0.009223252534866333\n",
      "Epoch 2295, Loss: 0.04992864280939102, Final Batch Loss: 0.03340975567698479\n",
      "Epoch 2296, Loss: 0.07824140973389149, Final Batch Loss: 0.05821947380900383\n",
      "Epoch 2297, Loss: 0.01086533535271883, Final Batch Loss: 0.0026426538825035095\n",
      "Epoch 2298, Loss: 0.031627777963876724, Final Batch Loss: 0.003906795755028725\n",
      "Epoch 2299, Loss: 0.05631556548178196, Final Batch Loss: 0.030169373378157616\n",
      "Epoch 2300, Loss: 0.04679357632994652, Final Batch Loss: 0.02881428226828575\n",
      "Epoch 2301, Loss: 0.06385809555649757, Final Batch Loss: 0.03748544678092003\n",
      "Epoch 2302, Loss: 0.03636029874905944, Final Batch Loss: 0.02919922024011612\n",
      "Epoch 2303, Loss: 0.03005054872483015, Final Batch Loss: 0.01972397416830063\n",
      "Epoch 2304, Loss: 0.023229215294122696, Final Batch Loss: 0.011130200698971748\n",
      "Epoch 2305, Loss: 0.06467080488801003, Final Batch Loss: 0.04876379668712616\n",
      "Epoch 2306, Loss: 0.021568284835666418, Final Batch Loss: 0.0058105397038161755\n",
      "Epoch 2307, Loss: 0.0599622200243175, Final Batch Loss: 0.007723729591816664\n",
      "Epoch 2308, Loss: 0.05093809589743614, Final Batch Loss: 0.024299917742609978\n",
      "Epoch 2309, Loss: 0.016212746035307646, Final Batch Loss: 0.009778923355042934\n",
      "Epoch 2310, Loss: 0.026901210192590952, Final Batch Loss: 0.02140248380601406\n",
      "Epoch 2311, Loss: 0.021271084435284138, Final Batch Loss: 0.01350056380033493\n",
      "Epoch 2312, Loss: 0.017617661971598864, Final Batch Loss: 0.011869874782860279\n",
      "Epoch 2313, Loss: 0.03362725581973791, Final Batch Loss: 0.019108319655060768\n",
      "Epoch 2314, Loss: 0.015189225552603602, Final Batch Loss: 0.0032323969062417746\n",
      "Epoch 2315, Loss: 0.0328282187692821, Final Batch Loss: 0.004213992040604353\n",
      "Epoch 2316, Loss: 0.01875669788569212, Final Batch Loss: 0.005229657515883446\n",
      "Epoch 2317, Loss: 0.018038437701761723, Final Batch Loss: 0.006317242980003357\n",
      "Epoch 2318, Loss: 0.029029258526861668, Final Batch Loss: 0.01789235696196556\n",
      "Epoch 2319, Loss: 0.03695604484528303, Final Batch Loss: 0.02519248239696026\n",
      "Epoch 2320, Loss: 0.03963027894496918, Final Batch Loss: 0.022547101601958275\n",
      "Epoch 2321, Loss: 0.027851399965584278, Final Batch Loss: 0.025332169607281685\n",
      "Epoch 2322, Loss: 0.030490143690258265, Final Batch Loss: 0.007023271638900042\n",
      "Epoch 2323, Loss: 0.028541321400552988, Final Batch Loss: 0.00719976844266057\n",
      "Epoch 2324, Loss: 0.05327685549855232, Final Batch Loss: 0.04786960035562515\n",
      "Epoch 2325, Loss: 0.01859035389497876, Final Batch Loss: 0.015261868014931679\n",
      "Epoch 2326, Loss: 0.01708688773214817, Final Batch Loss: 0.007676694542169571\n",
      "Epoch 2327, Loss: 0.017102813348174095, Final Batch Loss: 0.003978217951953411\n",
      "Epoch 2328, Loss: 0.06024954840540886, Final Batch Loss: 0.017103925347328186\n",
      "Epoch 2329, Loss: 0.05054288264364004, Final Batch Loss: 0.04141746833920479\n",
      "Epoch 2330, Loss: 0.03378554806113243, Final Batch Loss: 0.017446430400013924\n",
      "Epoch 2331, Loss: 0.032180100213736296, Final Batch Loss: 0.006545157637447119\n",
      "Epoch 2332, Loss: 0.03078291192650795, Final Batch Loss: 0.01790711097419262\n",
      "Epoch 2333, Loss: 0.02401040680706501, Final Batch Loss: 0.017411960288882256\n",
      "Epoch 2334, Loss: 0.01452617533504963, Final Batch Loss: 0.009745942428708076\n",
      "Epoch 2335, Loss: 0.03195730270817876, Final Batch Loss: 0.0031813294626772404\n",
      "Epoch 2336, Loss: 0.010550808976404369, Final Batch Loss: 0.0015425327001139522\n",
      "Epoch 2337, Loss: 0.017749390564858913, Final Batch Loss: 0.012363889254629612\n",
      "Epoch 2338, Loss: 0.014394701924175024, Final Batch Loss: 0.005382101517170668\n",
      "Epoch 2339, Loss: 0.03964108042418957, Final Batch Loss: 0.01998518966138363\n",
      "Epoch 2340, Loss: 0.0265928590670228, Final Batch Loss: 0.0025790976360440254\n",
      "Epoch 2341, Loss: 0.00996055779978633, Final Batch Loss: 0.004157038871198893\n",
      "Epoch 2342, Loss: 0.01026073144748807, Final Batch Loss: 0.006514363922178745\n",
      "Epoch 2343, Loss: 0.02215035818517208, Final Batch Loss: 0.008001506328582764\n",
      "Epoch 2344, Loss: 0.07193330302834511, Final Batch Loss: 0.043794646859169006\n",
      "Epoch 2345, Loss: 0.0170885999687016, Final Batch Loss: 0.013147189281880856\n",
      "Epoch 2346, Loss: 0.013022666797041893, Final Batch Loss: 0.002651570364832878\n",
      "Epoch 2347, Loss: 0.022952246479690075, Final Batch Loss: 0.01872105523943901\n",
      "Epoch 2348, Loss: 0.021411877125501633, Final Batch Loss: 0.0050453487783670425\n",
      "Epoch 2349, Loss: 0.005935513647273183, Final Batch Loss: 0.0038513108156621456\n",
      "Epoch 2350, Loss: 0.012065107934176922, Final Batch Loss: 0.004127632826566696\n",
      "Epoch 2351, Loss: 0.024414375890046358, Final Batch Loss: 0.0033586756326258183\n",
      "Epoch 2352, Loss: 0.009840775514021516, Final Batch Loss: 0.0033426585141569376\n",
      "Epoch 2353, Loss: 0.03401852771639824, Final Batch Loss: 0.023525914177298546\n",
      "Epoch 2354, Loss: 0.020999695640057325, Final Batch Loss: 0.00753795588389039\n",
      "Epoch 2355, Loss: 0.013145111734047532, Final Batch Loss: 0.0034722343552857637\n",
      "Epoch 2356, Loss: 0.011282760999165475, Final Batch Loss: 0.0015761893009766936\n",
      "Epoch 2357, Loss: 0.020327128469944, Final Batch Loss: 0.004237139597535133\n",
      "Epoch 2358, Loss: 0.040806028293445706, Final Batch Loss: 0.038570668548345566\n",
      "Epoch 2359, Loss: 0.016010604100301862, Final Batch Loss: 0.0033793554175645113\n",
      "Epoch 2360, Loss: 0.011475896695628762, Final Batch Loss: 0.007845288142561913\n",
      "Epoch 2361, Loss: 0.026840688660740852, Final Batch Loss: 0.008919550105929375\n",
      "Epoch 2362, Loss: 0.058070491068065166, Final Batch Loss: 0.05240951105952263\n",
      "Epoch 2363, Loss: 0.013454532949253917, Final Batch Loss: 0.0020152179058641195\n",
      "Epoch 2364, Loss: 0.06177487410604954, Final Batch Loss: 0.039864081889390945\n",
      "Epoch 2365, Loss: 0.01722302846610546, Final Batch Loss: 0.004627079702913761\n",
      "Epoch 2366, Loss: 0.027950672432780266, Final Batch Loss: 0.016796786338090897\n",
      "Epoch 2367, Loss: 0.02025321125984192, Final Batch Loss: 0.010211044922471046\n",
      "Epoch 2368, Loss: 0.06185872573405504, Final Batch Loss: 0.04840807244181633\n",
      "Epoch 2369, Loss: 0.05546654760837555, Final Batch Loss: 0.018897607922554016\n",
      "Epoch 2370, Loss: 0.03875353094190359, Final Batch Loss: 0.01414994616061449\n",
      "Epoch 2371, Loss: 0.0329512907192111, Final Batch Loss: 0.02412272058427334\n",
      "Epoch 2372, Loss: 0.033262562938034534, Final Batch Loss: 0.007530936039984226\n",
      "Epoch 2373, Loss: 0.015274668578058481, Final Batch Loss: 0.010518599301576614\n",
      "Epoch 2374, Loss: 0.04970675893127918, Final Batch Loss: 0.024015998467803\n",
      "Epoch 2375, Loss: 0.05156508460640907, Final Batch Loss: 0.02716938592493534\n",
      "Epoch 2376, Loss: 0.011272506322711706, Final Batch Loss: 0.007209385745227337\n",
      "Epoch 2377, Loss: 0.04539312073029578, Final Batch Loss: 0.04317483305931091\n",
      "Epoch 2378, Loss: 0.036985998041927814, Final Batch Loss: 0.02707262523472309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2379, Loss: 0.017463432624936104, Final Batch Loss: 0.011144575662910938\n",
      "Epoch 2380, Loss: 0.021956516429781914, Final Batch Loss: 0.014174246229231358\n",
      "Epoch 2381, Loss: 0.016825631726533175, Final Batch Loss: 0.007685614284127951\n",
      "Epoch 2382, Loss: 0.061237895861268044, Final Batch Loss: 0.04343481361865997\n",
      "Epoch 2383, Loss: 0.006612594006583095, Final Batch Loss: 0.0024619975592941046\n",
      "Epoch 2384, Loss: 0.05870302952826023, Final Batch Loss: 0.015959342941641808\n",
      "Epoch 2385, Loss: 0.09819887951016426, Final Batch Loss: 0.04712695628404617\n",
      "Epoch 2386, Loss: 0.022590793669223785, Final Batch Loss: 0.007821117527782917\n",
      "Epoch 2387, Loss: 0.02307665697298944, Final Batch Loss: 0.0034474486019462347\n",
      "Epoch 2388, Loss: 0.024624917656183243, Final Batch Loss: 0.0055022090673446655\n",
      "Epoch 2389, Loss: 0.06727562472224236, Final Batch Loss: 0.04820402339100838\n",
      "Epoch 2390, Loss: 0.025451624765992165, Final Batch Loss: 0.007989739999175072\n",
      "Epoch 2391, Loss: 0.03490362875163555, Final Batch Loss: 0.015026003122329712\n",
      "Epoch 2392, Loss: 0.03629152476787567, Final Batch Loss: 0.01705213636159897\n",
      "Epoch 2393, Loss: 0.07739542238414288, Final Batch Loss: 0.06630192697048187\n",
      "Epoch 2394, Loss: 0.0760148074477911, Final Batch Loss: 0.024052979424595833\n",
      "Epoch 2395, Loss: 0.031543818302452564, Final Batch Loss: 0.012442057020962238\n",
      "Epoch 2396, Loss: 0.04625344276428223, Final Batch Loss: 0.026383694261312485\n",
      "Epoch 2397, Loss: 0.025368710979819298, Final Batch Loss: 0.013478334993124008\n",
      "Epoch 2398, Loss: 0.029181906022131443, Final Batch Loss: 0.021782202646136284\n",
      "Epoch 2399, Loss: 0.014403844950720668, Final Batch Loss: 0.0027417379897087812\n",
      "Epoch 2400, Loss: 0.04740863759070635, Final Batch Loss: 0.011844721622765064\n",
      "Epoch 2401, Loss: 0.010523732984438539, Final Batch Loss: 0.006622014567255974\n",
      "Epoch 2402, Loss: 0.01772424206137657, Final Batch Loss: 0.009569910354912281\n",
      "Epoch 2403, Loss: 0.013976719696074724, Final Batch Loss: 0.008694149553775787\n",
      "Epoch 2404, Loss: 0.054894812405109406, Final Batch Loss: 0.029044369235634804\n",
      "Epoch 2405, Loss: 0.032095142640173435, Final Batch Loss: 0.002077699638903141\n",
      "Epoch 2406, Loss: 0.03292526979930699, Final Batch Loss: 0.0038866002578288317\n",
      "Epoch 2407, Loss: 0.2131861373782158, Final Batch Loss: 0.09123605489730835\n",
      "Epoch 2408, Loss: 0.05258583975955844, Final Batch Loss: 0.04749470204114914\n",
      "Epoch 2409, Loss: 0.047803630121052265, Final Batch Loss: 0.035814158618450165\n",
      "Epoch 2410, Loss: 0.016350951977074146, Final Batch Loss: 0.008151805959641933\n",
      "Epoch 2411, Loss: 0.06750928238034248, Final Batch Loss: 0.036654163151979446\n",
      "Epoch 2412, Loss: 0.04658655449748039, Final Batch Loss: 0.006628762930631638\n",
      "Epoch 2413, Loss: 0.025484933517873287, Final Batch Loss: 0.01801963336765766\n",
      "Epoch 2414, Loss: 0.009668412385508418, Final Batch Loss: 0.0029262362513691187\n",
      "Epoch 2415, Loss: 0.023757676128298044, Final Batch Loss: 0.01744966208934784\n",
      "Epoch 2416, Loss: 0.024936573579907417, Final Batch Loss: 0.004553196951746941\n",
      "Epoch 2417, Loss: 0.032235232181847095, Final Batch Loss: 0.022269362583756447\n",
      "Epoch 2418, Loss: 0.061147965490818024, Final Batch Loss: 0.027733221650123596\n",
      "Epoch 2419, Loss: 0.023412077222019434, Final Batch Loss: 0.016163023188710213\n",
      "Epoch 2420, Loss: 0.014473187271505594, Final Batch Loss: 0.005776621866971254\n",
      "Epoch 2421, Loss: 0.019530443474650383, Final Batch Loss: 0.004991724155843258\n",
      "Epoch 2422, Loss: 0.03525978699326515, Final Batch Loss: 0.016300734132528305\n",
      "Epoch 2423, Loss: 0.020994434133172035, Final Batch Loss: 0.00789127591997385\n",
      "Epoch 2424, Loss: 0.01707549672573805, Final Batch Loss: 0.011545693501830101\n",
      "Epoch 2425, Loss: 0.05139956343919039, Final Batch Loss: 0.04788343608379364\n",
      "Epoch 2426, Loss: 0.014021300710737705, Final Batch Loss: 0.006730099208652973\n",
      "Epoch 2427, Loss: 0.036860459484159946, Final Batch Loss: 0.009792094118893147\n",
      "Epoch 2428, Loss: 0.011333931237459183, Final Batch Loss: 0.004979022778570652\n",
      "Epoch 2429, Loss: 0.0319658846128732, Final Batch Loss: 0.030068987980484962\n",
      "Epoch 2430, Loss: 0.014100077096372843, Final Batch Loss: 0.004103779327124357\n",
      "Epoch 2431, Loss: 0.023495587054640055, Final Batch Loss: 0.017582407221198082\n",
      "Epoch 2432, Loss: 0.01679390762001276, Final Batch Loss: 0.006556978449225426\n",
      "Epoch 2433, Loss: 0.032964673824608326, Final Batch Loss: 0.006667931564152241\n",
      "Epoch 2434, Loss: 0.01461910642683506, Final Batch Loss: 0.009345872327685356\n",
      "Epoch 2435, Loss: 0.02533292700536549, Final Batch Loss: 0.003626025514677167\n",
      "Epoch 2436, Loss: 0.050630818121135235, Final Batch Loss: 0.03752569481730461\n",
      "Epoch 2437, Loss: 0.043286471627652645, Final Batch Loss: 0.03187250345945358\n",
      "Epoch 2438, Loss: 0.06870710104703903, Final Batch Loss: 0.013222716748714447\n",
      "Epoch 2439, Loss: 0.010180470766499639, Final Batch Loss: 0.0011084864381700754\n",
      "Epoch 2440, Loss: 0.03742877533659339, Final Batch Loss: 0.00609356677159667\n",
      "Epoch 2441, Loss: 0.013549760449677706, Final Batch Loss: 0.006672124844044447\n",
      "Epoch 2442, Loss: 0.03287585126236081, Final Batch Loss: 0.02840409427881241\n",
      "Epoch 2443, Loss: 0.0324459308758378, Final Batch Loss: 0.02965310961008072\n",
      "Epoch 2444, Loss: 0.007068818202242255, Final Batch Loss: 0.0032476470805704594\n",
      "Epoch 2445, Loss: 0.05662471428513527, Final Batch Loss: 0.009232472628355026\n",
      "Epoch 2446, Loss: 0.045115360990166664, Final Batch Loss: 0.017167897894978523\n",
      "Epoch 2447, Loss: 0.0196802644059062, Final Batch Loss: 0.009481322951614857\n",
      "Epoch 2448, Loss: 0.021455041598528624, Final Batch Loss: 0.004667564760893583\n",
      "Epoch 2449, Loss: 0.03475751914083958, Final Batch Loss: 0.02286716364324093\n",
      "Epoch 2450, Loss: 0.0483859833329916, Final Batch Loss: 0.03617055341601372\n",
      "Epoch 2451, Loss: 0.035421902779489756, Final Batch Loss: 0.0066725038923323154\n",
      "Epoch 2452, Loss: 0.05759037844836712, Final Batch Loss: 0.027042312547564507\n",
      "Epoch 2453, Loss: 0.009101139847189188, Final Batch Loss: 0.006809732411056757\n",
      "Epoch 2454, Loss: 0.008702946826815605, Final Batch Loss: 0.0021144570782780647\n",
      "Epoch 2455, Loss: 0.025597105734050274, Final Batch Loss: 0.016829704865813255\n",
      "Epoch 2456, Loss: 0.01568063860759139, Final Batch Loss: 0.0033000768162310123\n",
      "Epoch 2457, Loss: 0.012182087637484074, Final Batch Loss: 0.004019140265882015\n",
      "Epoch 2458, Loss: 0.026575825177133083, Final Batch Loss: 0.00436497014015913\n",
      "Epoch 2459, Loss: 0.007513732183724642, Final Batch Loss: 0.0022111674770712852\n",
      "Epoch 2460, Loss: 0.021634580567479134, Final Batch Loss: 0.012765229679644108\n",
      "Epoch 2461, Loss: 0.025679863058030605, Final Batch Loss: 0.011263645254075527\n",
      "Epoch 2462, Loss: 0.013631715439260006, Final Batch Loss: 0.004988926462829113\n",
      "Epoch 2463, Loss: 0.1127544641494751, Final Batch Loss: 0.057884879410266876\n",
      "Epoch 2464, Loss: 0.017259632237255573, Final Batch Loss: 0.0063895490020513535\n",
      "Epoch 2465, Loss: 0.009388364152982831, Final Batch Loss: 0.006494877859950066\n",
      "Epoch 2466, Loss: 0.03971325233578682, Final Batch Loss: 0.01670335978269577\n",
      "Epoch 2467, Loss: 0.023987015476450324, Final Batch Loss: 0.0027871557977050543\n",
      "Epoch 2468, Loss: 0.026062306948006153, Final Batch Loss: 0.0031798547133803368\n",
      "Epoch 2469, Loss: 0.021689295768737793, Final Batch Loss: 0.01481548324227333\n",
      "Epoch 2470, Loss: 0.015160733950324357, Final Batch Loss: 0.0018691831501200795\n",
      "Epoch 2471, Loss: 0.028488321928307414, Final Batch Loss: 0.024829259142279625\n",
      "Epoch 2472, Loss: 0.07272410299628973, Final Batch Loss: 0.06642334163188934\n",
      "Epoch 2473, Loss: 0.013881410006433725, Final Batch Loss: 0.0038166376762092113\n",
      "Epoch 2474, Loss: 0.03310404811054468, Final Batch Loss: 0.02811393141746521\n",
      "Epoch 2475, Loss: 0.019194215768948197, Final Batch Loss: 0.0022938495967537165\n",
      "Epoch 2476, Loss: 0.011967066675424576, Final Batch Loss: 0.004380446393042803\n",
      "Epoch 2477, Loss: 0.06658183597028255, Final Batch Loss: 0.052688371390104294\n",
      "Epoch 2478, Loss: 0.021288271062076092, Final Batch Loss: 0.017064528539776802\n",
      "Epoch 2479, Loss: 0.023120295256376266, Final Batch Loss: 0.011686965823173523\n",
      "Epoch 2480, Loss: 0.060972114093601704, Final Batch Loss: 0.007926740683615208\n",
      "Epoch 2481, Loss: 0.021332587581127882, Final Batch Loss: 0.016683630645275116\n",
      "Epoch 2482, Loss: 0.09666556864976883, Final Batch Loss: 0.059293705970048904\n",
      "Epoch 2483, Loss: 0.05325099779292941, Final Batch Loss: 0.0023275348357856274\n",
      "Epoch 2484, Loss: 0.028385920450091362, Final Batch Loss: 0.018332617357373238\n",
      "Epoch 2485, Loss: 0.019944938365370035, Final Batch Loss: 0.016984308138489723\n",
      "Epoch 2486, Loss: 0.03466126788407564, Final Batch Loss: 0.01921064592897892\n",
      "Epoch 2487, Loss: 0.03573047090321779, Final Batch Loss: 0.014852653257548809\n",
      "Epoch 2488, Loss: 0.05997901828959584, Final Batch Loss: 0.0058418517000973225\n",
      "Epoch 2489, Loss: 0.037827720399945974, Final Batch Loss: 0.0061630732379853725\n",
      "Epoch 2490, Loss: 0.02800978720188141, Final Batch Loss: 0.011858997866511345\n",
      "Epoch 2491, Loss: 0.04615017119795084, Final Batch Loss: 0.011012506671249866\n",
      "Epoch 2492, Loss: 0.03449650900438428, Final Batch Loss: 0.007166661787778139\n",
      "Epoch 2493, Loss: 0.024115909822285175, Final Batch Loss: 0.010783466510474682\n",
      "Epoch 2494, Loss: 0.012682252563536167, Final Batch Loss: 0.006855090148746967\n",
      "Epoch 2495, Loss: 0.027857919223606586, Final Batch Loss: 0.011925063095986843\n",
      "Epoch 2496, Loss: 0.027945395559072495, Final Batch Loss: 0.021404309198260307\n",
      "Epoch 2497, Loss: 0.05117589421570301, Final Batch Loss: 0.005653267726302147\n",
      "Epoch 2498, Loss: 0.021902645006775856, Final Batch Loss: 0.010310644283890724\n",
      "Epoch 2499, Loss: 0.017471569124609232, Final Batch Loss: 0.006885212380439043\n",
      "Epoch 2500, Loss: 0.03409997886046767, Final Batch Loss: 0.02856515161693096\n",
      "Epoch 2501, Loss: 0.019839650951325893, Final Batch Loss: 0.0020462041720747948\n",
      "Epoch 2502, Loss: 0.04225240321829915, Final Batch Loss: 0.005707156378775835\n",
      "Epoch 2503, Loss: 0.01566648343577981, Final Batch Loss: 0.005281270015984774\n",
      "Epoch 2504, Loss: 0.06060001044534147, Final Batch Loss: 0.003585668047890067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2505, Loss: 0.012612826656550169, Final Batch Loss: 0.006737428717315197\n",
      "Epoch 2506, Loss: 0.03156810300424695, Final Batch Loss: 0.004602218512445688\n",
      "Epoch 2507, Loss: 0.009720270289108157, Final Batch Loss: 0.006305314600467682\n",
      "Epoch 2508, Loss: 0.009220498846843839, Final Batch Loss: 0.0034545359667390585\n",
      "Epoch 2509, Loss: 0.007752405246719718, Final Batch Loss: 0.003689615288749337\n",
      "Epoch 2510, Loss: 0.01172056794166565, Final Batch Loss: 0.0039453632198274136\n",
      "Epoch 2511, Loss: 0.00803254870697856, Final Batch Loss: 0.0016529317945241928\n",
      "Epoch 2512, Loss: 0.015450005419552326, Final Batch Loss: 0.007185406982898712\n",
      "Epoch 2513, Loss: 0.019707696046680212, Final Batch Loss: 0.014079838991165161\n",
      "Epoch 2514, Loss: 0.009989401791244745, Final Batch Loss: 0.0032578641548752785\n",
      "Epoch 2515, Loss: 0.01841607131063938, Final Batch Loss: 0.009400946088135242\n",
      "Epoch 2516, Loss: 0.007731877267360687, Final Batch Loss: 0.004821253474801779\n",
      "Epoch 2517, Loss: 0.015565556474030018, Final Batch Loss: 0.00418431032449007\n",
      "Epoch 2518, Loss: 0.028493459802120924, Final Batch Loss: 0.003969981800764799\n",
      "Epoch 2519, Loss: 0.007693031802773476, Final Batch Loss: 0.004530217498540878\n",
      "Epoch 2520, Loss: 0.014817154733464122, Final Batch Loss: 0.011516881175339222\n",
      "Epoch 2521, Loss: 0.00991661031730473, Final Batch Loss: 0.002300570486113429\n",
      "Epoch 2522, Loss: 0.006719903787598014, Final Batch Loss: 0.002798092318698764\n",
      "Epoch 2523, Loss: 0.022781560197472572, Final Batch Loss: 0.011385161429643631\n",
      "Epoch 2524, Loss: 0.039256028831005096, Final Batch Loss: 0.02934197708964348\n",
      "Epoch 2525, Loss: 0.017918451223522425, Final Batch Loss: 0.0035114469937980175\n",
      "Epoch 2526, Loss: 0.029683338478207588, Final Batch Loss: 0.004958810284733772\n",
      "Epoch 2527, Loss: 0.04644428752362728, Final Batch Loss: 0.02633199840784073\n",
      "Epoch 2528, Loss: 0.010415238793939352, Final Batch Loss: 0.0039346362464129925\n",
      "Epoch 2529, Loss: 0.02475870866328478, Final Batch Loss: 0.012635326944291592\n",
      "Epoch 2530, Loss: 0.03818147722631693, Final Batch Loss: 0.003889859654009342\n",
      "Epoch 2531, Loss: 0.03930195257999003, Final Batch Loss: 0.03703179210424423\n",
      "Epoch 2532, Loss: 0.005525338463485241, Final Batch Loss: 0.003914935514330864\n",
      "Epoch 2533, Loss: 0.08067534328438342, Final Batch Loss: 0.001736941048875451\n",
      "Epoch 2534, Loss: 0.038828106597065926, Final Batch Loss: 0.02876199223101139\n",
      "Epoch 2535, Loss: 0.03964027762413025, Final Batch Loss: 0.02533523552119732\n",
      "Epoch 2536, Loss: 0.032992216874845326, Final Batch Loss: 0.0018722425447776914\n",
      "Epoch 2537, Loss: 0.045302554965019226, Final Batch Loss: 0.021394118666648865\n",
      "Epoch 2538, Loss: 0.03167346306145191, Final Batch Loss: 0.010870620608329773\n",
      "Epoch 2539, Loss: 0.022934873588383198, Final Batch Loss: 0.008086471818387508\n",
      "Epoch 2540, Loss: 0.03569561638869345, Final Batch Loss: 0.033268850296735764\n",
      "Epoch 2541, Loss: 0.009002746315672994, Final Batch Loss: 0.0037365311291068792\n",
      "Epoch 2542, Loss: 0.027154206298291683, Final Batch Loss: 0.014624718576669693\n",
      "Epoch 2543, Loss: 0.03962143324315548, Final Batch Loss: 0.01694757118821144\n",
      "Epoch 2544, Loss: 0.01689642108976841, Final Batch Loss: 0.0040138596668839455\n",
      "Epoch 2545, Loss: 0.03488634945824742, Final Batch Loss: 0.006645298097282648\n",
      "Epoch 2546, Loss: 0.038253829814493656, Final Batch Loss: 0.030634218826889992\n",
      "Epoch 2547, Loss: 0.032446309458464384, Final Batch Loss: 0.0026997081004083157\n",
      "Epoch 2548, Loss: 0.0537288635969162, Final Batch Loss: 0.04537944868206978\n",
      "Epoch 2549, Loss: 0.021176708862185478, Final Batch Loss: 0.01699218526482582\n",
      "Epoch 2550, Loss: 0.010424210224300623, Final Batch Loss: 0.006554961204528809\n",
      "Epoch 2551, Loss: 0.04785626009106636, Final Batch Loss: 0.025681298226118088\n",
      "Epoch 2552, Loss: 0.04168422892689705, Final Batch Loss: 0.025248300284147263\n",
      "Epoch 2553, Loss: 0.02428288571536541, Final Batch Loss: 0.013997065834701061\n",
      "Epoch 2554, Loss: 0.0665265480056405, Final Batch Loss: 0.005296708084642887\n",
      "Epoch 2555, Loss: 0.05550849251449108, Final Batch Loss: 0.05007552355527878\n",
      "Epoch 2556, Loss: 0.027043542359024286, Final Batch Loss: 0.002820985857397318\n",
      "Epoch 2557, Loss: 0.02939210645854473, Final Batch Loss: 0.005389504134654999\n",
      "Epoch 2558, Loss: 0.02144236769527197, Final Batch Loss: 0.009881364181637764\n",
      "Epoch 2559, Loss: 0.03749697108287364, Final Batch Loss: 0.0018611607374623418\n",
      "Epoch 2560, Loss: 0.023198456037789583, Final Batch Loss: 0.004421344492584467\n",
      "Epoch 2561, Loss: 0.05032234778627753, Final Batch Loss: 0.006568626966327429\n",
      "Epoch 2562, Loss: 0.036533088888973, Final Batch Loss: 0.00469159847125411\n",
      "Epoch 2563, Loss: 0.043273529037833214, Final Batch Loss: 0.012441758066415787\n",
      "Epoch 2564, Loss: 0.04657245799899101, Final Batch Loss: 0.02139100804924965\n",
      "Epoch 2565, Loss: 0.04534647800028324, Final Batch Loss: 0.02927858754992485\n",
      "Epoch 2566, Loss: 0.009650107705965638, Final Batch Loss: 0.0010696707759052515\n",
      "Epoch 2567, Loss: 0.08081999234855175, Final Batch Loss: 0.06277038902044296\n",
      "Epoch 2568, Loss: 0.0092713781632483, Final Batch Loss: 0.003983830101788044\n",
      "Epoch 2569, Loss: 0.029617149149999022, Final Batch Loss: 0.003114385297521949\n",
      "Epoch 2570, Loss: 0.09123377501964569, Final Batch Loss: 0.052898138761520386\n",
      "Epoch 2571, Loss: 0.01724039320833981, Final Batch Loss: 0.0012720779050141573\n",
      "Epoch 2572, Loss: 0.08293258305639029, Final Batch Loss: 0.06819494813680649\n",
      "Epoch 2573, Loss: 0.03349559288471937, Final Batch Loss: 0.007537740282714367\n",
      "Epoch 2574, Loss: 0.03631461039185524, Final Batch Loss: 0.01662633568048477\n",
      "Epoch 2575, Loss: 0.039502326399087906, Final Batch Loss: 0.0242843646556139\n",
      "Epoch 2576, Loss: 0.0233834576793015, Final Batch Loss: 0.018459072336554527\n",
      "Epoch 2577, Loss: 0.008735588984563947, Final Batch Loss: 0.003339578630402684\n",
      "Epoch 2578, Loss: 0.015483427094295621, Final Batch Loss: 0.0033527298364788294\n",
      "Epoch 2579, Loss: 0.0710387909784913, Final Batch Loss: 0.062139034271240234\n",
      "Epoch 2580, Loss: 0.024411598220467567, Final Batch Loss: 0.015999410301446915\n",
      "Epoch 2581, Loss: 0.007027208339422941, Final Batch Loss: 0.0044242627918720245\n",
      "Epoch 2582, Loss: 0.012634600512683392, Final Batch Loss: 0.002788814716041088\n",
      "Epoch 2583, Loss: 0.03278152830898762, Final Batch Loss: 0.01690433919429779\n",
      "Epoch 2584, Loss: 0.02280469983816147, Final Batch Loss: 0.008221732452511787\n",
      "Epoch 2585, Loss: 0.017325797118246555, Final Batch Loss: 0.007275981828570366\n",
      "Epoch 2586, Loss: 0.040055462159216404, Final Batch Loss: 0.006151926703751087\n",
      "Epoch 2587, Loss: 0.031627682503312826, Final Batch Loss: 0.004694489296525717\n",
      "Epoch 2588, Loss: 0.0156090771779418, Final Batch Loss: 0.005913479253649712\n",
      "Epoch 2589, Loss: 0.01146182045340538, Final Batch Loss: 0.005204642191529274\n",
      "Epoch 2590, Loss: 0.023292752914130688, Final Batch Loss: 0.006917585618793964\n",
      "Epoch 2591, Loss: 0.022554548922926188, Final Batch Loss: 0.007347904611378908\n",
      "Epoch 2592, Loss: 0.01646469347178936, Final Batch Loss: 0.00954038929194212\n",
      "Epoch 2593, Loss: 0.030369832646101713, Final Batch Loss: 0.0052035837434232235\n",
      "Epoch 2594, Loss: 0.016849486622959375, Final Batch Loss: 0.004635463934391737\n",
      "Epoch 2595, Loss: 0.048773405607789755, Final Batch Loss: 0.04173332825303078\n",
      "Epoch 2596, Loss: 0.021531744860112667, Final Batch Loss: 0.005725824274122715\n",
      "Epoch 2597, Loss: 0.02807975560426712, Final Batch Loss: 0.012166917324066162\n",
      "Epoch 2598, Loss: 0.031863235868513584, Final Batch Loss: 0.0101681062951684\n",
      "Epoch 2599, Loss: 0.020039675757288933, Final Batch Loss: 0.010067790746688843\n",
      "Epoch 2600, Loss: 0.005865488899871707, Final Batch Loss: 0.0022880553733557463\n",
      "Epoch 2601, Loss: 0.03413473255932331, Final Batch Loss: 0.019217053428292274\n",
      "Epoch 2602, Loss: 0.006825250573456287, Final Batch Loss: 0.003601881442591548\n",
      "Epoch 2603, Loss: 0.04355230194050819, Final Batch Loss: 0.042726654559373856\n",
      "Epoch 2604, Loss: 0.004846043535508215, Final Batch Loss: 0.0015918916324153543\n",
      "Epoch 2605, Loss: 0.00886392779648304, Final Batch Loss: 0.0031279418617486954\n",
      "Epoch 2606, Loss: 0.031728964764624834, Final Batch Loss: 0.003724489826709032\n",
      "Epoch 2607, Loss: 0.025588276330381632, Final Batch Loss: 0.004658993799239397\n",
      "Epoch 2608, Loss: 0.017019788501784205, Final Batch Loss: 0.003799308789893985\n",
      "Epoch 2609, Loss: 0.09122516214847565, Final Batch Loss: 0.04266062751412392\n",
      "Epoch 2610, Loss: 0.02721013780683279, Final Batch Loss: 0.010491994209587574\n",
      "Epoch 2611, Loss: 0.05383322760462761, Final Batch Loss: 0.050867486745119095\n",
      "Epoch 2612, Loss: 0.0678340457379818, Final Batch Loss: 0.03963090479373932\n",
      "Epoch 2613, Loss: 0.011491573881357908, Final Batch Loss: 0.00793399941176176\n",
      "Epoch 2614, Loss: 0.012342116795480251, Final Batch Loss: 0.008210535161197186\n",
      "Epoch 2615, Loss: 0.016411511693149805, Final Batch Loss: 0.011464565061032772\n",
      "Epoch 2616, Loss: 0.006560387555509806, Final Batch Loss: 0.0034088268876075745\n",
      "Epoch 2617, Loss: 0.05056952312588692, Final Batch Loss: 0.034210529178380966\n",
      "Epoch 2618, Loss: 0.013383219949901104, Final Batch Loss: 0.004236623644828796\n",
      "Epoch 2619, Loss: 0.03107154043391347, Final Batch Loss: 0.026654519140720367\n",
      "Epoch 2620, Loss: 0.030743949115276337, Final Batch Loss: 0.005704045295715332\n",
      "Epoch 2621, Loss: 0.00970108131878078, Final Batch Loss: 0.003005043836310506\n",
      "Epoch 2622, Loss: 0.0396698834374547, Final Batch Loss: 0.026262564584612846\n",
      "Epoch 2623, Loss: 0.034084502607584, Final Batch Loss: 0.014276707544922829\n",
      "Epoch 2624, Loss: 0.025934739504009485, Final Batch Loss: 0.018883295357227325\n",
      "Epoch 2625, Loss: 0.009294445859268308, Final Batch Loss: 0.003695497987791896\n",
      "Epoch 2626, Loss: 0.04230242781341076, Final Batch Loss: 0.024448074400424957\n",
      "Epoch 2627, Loss: 0.017504501156508923, Final Batch Loss: 0.009406299330294132\n",
      "Epoch 2628, Loss: 0.01152620604261756, Final Batch Loss: 0.0053861322812736034\n",
      "Epoch 2629, Loss: 0.007821314502507448, Final Batch Loss: 0.004390540067106485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2630, Loss: 0.03940563974902034, Final Batch Loss: 0.007246806751936674\n",
      "Epoch 2631, Loss: 0.019659125711768866, Final Batch Loss: 0.006598927546292543\n",
      "Epoch 2632, Loss: 0.041142948903143406, Final Batch Loss: 0.011435004882514477\n",
      "Epoch 2633, Loss: 0.012948627700097859, Final Batch Loss: 0.0010438273893669248\n",
      "Epoch 2634, Loss: 0.03181646764278412, Final Batch Loss: 0.024031829088926315\n",
      "Epoch 2635, Loss: 0.013749619480222464, Final Batch Loss: 0.0035001770593225956\n",
      "Epoch 2636, Loss: 0.04441283643245697, Final Batch Loss: 0.02662394754588604\n",
      "Epoch 2637, Loss: 0.010772064793854952, Final Batch Loss: 0.006859698332846165\n",
      "Epoch 2638, Loss: 0.012237350456416607, Final Batch Loss: 0.004838769789785147\n",
      "Epoch 2639, Loss: 0.019988241605460644, Final Batch Loss: 0.01087579783052206\n",
      "Epoch 2640, Loss: 0.014662823639810085, Final Batch Loss: 0.009011637419462204\n",
      "Epoch 2641, Loss: 0.019391456618905067, Final Batch Loss: 0.016357555985450745\n",
      "Epoch 2642, Loss: 0.02410085592418909, Final Batch Loss: 0.015348948538303375\n",
      "Epoch 2643, Loss: 0.009748303797096014, Final Batch Loss: 0.0048612020909786224\n",
      "Epoch 2644, Loss: 0.006257112603634596, Final Batch Loss: 0.004859170876443386\n",
      "Epoch 2645, Loss: 0.027534413151443005, Final Batch Loss: 0.009729263372719288\n",
      "Epoch 2646, Loss: 0.01841785293072462, Final Batch Loss: 0.011015186086297035\n",
      "Epoch 2647, Loss: 0.034504128620028496, Final Batch Loss: 0.016871245577931404\n",
      "Epoch 2648, Loss: 0.030323242768645287, Final Batch Loss: 0.026136739179491997\n",
      "Epoch 2649, Loss: 0.06765027344226837, Final Batch Loss: 0.03569560497999191\n",
      "Epoch 2650, Loss: 0.01943059917539358, Final Batch Loss: 0.004231476224958897\n",
      "Epoch 2651, Loss: 0.016327575780451298, Final Batch Loss: 0.003408682532608509\n",
      "Epoch 2652, Loss: 0.024922631215304136, Final Batch Loss: 0.002094691153615713\n",
      "Epoch 2653, Loss: 0.02485471311956644, Final Batch Loss: 0.008086836896836758\n",
      "Epoch 2654, Loss: 0.013918759068474174, Final Batch Loss: 0.003655877662822604\n",
      "Epoch 2655, Loss: 0.021059862338006496, Final Batch Loss: 0.011868923902511597\n",
      "Epoch 2656, Loss: 0.014208382461220026, Final Batch Loss: 0.0040677390061318874\n",
      "Epoch 2657, Loss: 0.052554779686033726, Final Batch Loss: 0.01081321481615305\n",
      "Epoch 2658, Loss: 0.020372258499264717, Final Batch Loss: 0.009941915050148964\n",
      "Epoch 2659, Loss: 0.023428944870829582, Final Batch Loss: 0.013018663972616196\n",
      "Epoch 2660, Loss: 0.01289741462096572, Final Batch Loss: 0.0040357294492423534\n",
      "Epoch 2661, Loss: 0.03918902948498726, Final Batch Loss: 0.018565740436315536\n",
      "Epoch 2662, Loss: 0.017493016668595374, Final Batch Loss: 0.0006468925857916474\n",
      "Epoch 2663, Loss: 0.008548140292987227, Final Batch Loss: 0.001956515247002244\n",
      "Epoch 2664, Loss: 0.023702892009168863, Final Batch Loss: 0.0051033333875238895\n",
      "Epoch 2665, Loss: 0.035844044759869576, Final Batch Loss: 0.03131609410047531\n",
      "Epoch 2666, Loss: 0.04714900627732277, Final Batch Loss: 0.025159742683172226\n",
      "Epoch 2667, Loss: 0.02158473408780992, Final Batch Loss: 0.0026367807295173407\n",
      "Epoch 2668, Loss: 0.05293800309300423, Final Batch Loss: 0.0024022385478019714\n",
      "Epoch 2669, Loss: 0.019249812001362443, Final Batch Loss: 0.002506686607375741\n",
      "Epoch 2670, Loss: 0.009348133113235235, Final Batch Loss: 0.0018602865748107433\n",
      "Epoch 2671, Loss: 0.05348007194697857, Final Batch Loss: 0.03431696444749832\n",
      "Epoch 2672, Loss: 0.013975087087601423, Final Batch Loss: 0.0030635283328592777\n",
      "Epoch 2673, Loss: 0.01818708493374288, Final Batch Loss: 0.0027190984692424536\n",
      "Epoch 2674, Loss: 0.008956919773481786, Final Batch Loss: 0.0015097766881808639\n",
      "Epoch 2675, Loss: 0.024020183365792036, Final Batch Loss: 0.021852070465683937\n",
      "Epoch 2676, Loss: 0.026682069059461355, Final Batch Loss: 0.02071855030953884\n",
      "Epoch 2677, Loss: 0.03735193517059088, Final Batch Loss: 0.007451959885656834\n",
      "Epoch 2678, Loss: 0.01716018607839942, Final Batch Loss: 0.0034753172658383846\n",
      "Epoch 2679, Loss: 0.030669264495372772, Final Batch Loss: 0.018231049180030823\n",
      "Epoch 2680, Loss: 0.005525231943465769, Final Batch Loss: 0.001921427552588284\n",
      "Epoch 2681, Loss: 0.010328763164579868, Final Batch Loss: 0.0072452351450920105\n",
      "Epoch 2682, Loss: 0.027253930922597647, Final Batch Loss: 0.004330269526690245\n",
      "Epoch 2683, Loss: 0.01227654842659831, Final Batch Loss: 0.007590319961309433\n",
      "Epoch 2684, Loss: 0.03083578567020595, Final Batch Loss: 0.002955761505290866\n",
      "Epoch 2685, Loss: 0.05730770342051983, Final Batch Loss: 0.03092007152736187\n",
      "Epoch 2686, Loss: 0.009552823845297098, Final Batch Loss: 0.004482471849769354\n",
      "Epoch 2687, Loss: 0.004348497488535941, Final Batch Loss: 0.001408322132192552\n",
      "Epoch 2688, Loss: 0.01988514931872487, Final Batch Loss: 0.007802565116435289\n",
      "Epoch 2689, Loss: 0.030627496540546417, Final Batch Loss: 0.0248107872903347\n",
      "Epoch 2690, Loss: 0.006561785121448338, Final Batch Loss: 0.0018224326195195317\n",
      "Epoch 2691, Loss: 0.022925067227333784, Final Batch Loss: 0.0059202141128480434\n",
      "Epoch 2692, Loss: 0.016462383791804314, Final Batch Loss: 0.011264447122812271\n",
      "Epoch 2693, Loss: 0.017734488006681204, Final Batch Loss: 0.007425507064908743\n",
      "Epoch 2694, Loss: 0.032266030088067055, Final Batch Loss: 0.027696769684553146\n",
      "Epoch 2695, Loss: 0.03763258922845125, Final Batch Loss: 0.011510969139635563\n",
      "Epoch 2696, Loss: 0.056554657872766256, Final Batch Loss: 0.004676458891481161\n",
      "Epoch 2697, Loss: 0.04938875325024128, Final Batch Loss: 0.02819521352648735\n",
      "Epoch 2698, Loss: 0.0329273147508502, Final Batch Loss: 0.013609564863145351\n",
      "Epoch 2699, Loss: 0.050327176693826914, Final Batch Loss: 0.005630227271467447\n",
      "Epoch 2700, Loss: 0.05012224242091179, Final Batch Loss: 0.017522186040878296\n",
      "Epoch 2701, Loss: 0.015931198140606284, Final Batch Loss: 0.002507859608158469\n",
      "Epoch 2702, Loss: 0.0358298122882843, Final Batch Loss: 0.007880033925175667\n",
      "Epoch 2703, Loss: 0.07142691779881716, Final Batch Loss: 0.008268353529274464\n",
      "Epoch 2704, Loss: 0.03108382597565651, Final Batch Loss: 0.010559268295764923\n",
      "Epoch 2705, Loss: 0.03679820895195007, Final Batch Loss: 0.01639108546078205\n",
      "Epoch 2706, Loss: 0.015988732688128948, Final Batch Loss: 0.0039792051538825035\n",
      "Epoch 2707, Loss: 0.02047680877149105, Final Batch Loss: 0.004731152206659317\n",
      "Epoch 2708, Loss: 0.0547508392482996, Final Batch Loss: 0.02022826485335827\n",
      "Epoch 2709, Loss: 0.037228659726679325, Final Batch Loss: 0.007480167783796787\n",
      "Epoch 2710, Loss: 0.02047700434923172, Final Batch Loss: 0.012657183222472668\n",
      "Epoch 2711, Loss: 0.04621244082227349, Final Batch Loss: 0.04164931923151016\n",
      "Epoch 2712, Loss: 0.044026248157024384, Final Batch Loss: 0.025078192353248596\n",
      "Epoch 2713, Loss: 0.04532458167523146, Final Batch Loss: 0.039784327149391174\n",
      "Epoch 2714, Loss: 0.02047874452546239, Final Batch Loss: 0.01610230654478073\n",
      "Epoch 2715, Loss: 0.027912266552448273, Final Batch Loss: 0.019207919016480446\n",
      "Epoch 2716, Loss: 0.0119867785833776, Final Batch Loss: 0.0049168020486831665\n",
      "Epoch 2717, Loss: 0.05427265167236328, Final Batch Loss: 0.017298806458711624\n",
      "Epoch 2718, Loss: 0.07182072848081589, Final Batch Loss: 0.007933981716632843\n",
      "Epoch 2719, Loss: 0.13592299073934555, Final Batch Loss: 0.013118565082550049\n",
      "Epoch 2720, Loss: 0.045820124447345734, Final Batch Loss: 0.019071707502007484\n",
      "Epoch 2721, Loss: 0.0182800879701972, Final Batch Loss: 0.007367431186139584\n",
      "Epoch 2722, Loss: 0.00821549678221345, Final Batch Loss: 0.004304797388613224\n",
      "Epoch 2723, Loss: 0.03658159915357828, Final Batch Loss: 0.004282833077013493\n",
      "Epoch 2724, Loss: 0.02734432159923017, Final Batch Loss: 0.0025210061576217413\n",
      "Epoch 2725, Loss: 0.021732767578214407, Final Batch Loss: 0.00433776481077075\n",
      "Epoch 2726, Loss: 0.022641289979219437, Final Batch Loss: 0.01904403418302536\n",
      "Epoch 2727, Loss: 0.010478624608367682, Final Batch Loss: 0.004935104865580797\n",
      "Epoch 2728, Loss: 0.013572856783866882, Final Batch Loss: 0.0032283999025821686\n",
      "Epoch 2729, Loss: 0.02567896107211709, Final Batch Loss: 0.022952774539589882\n",
      "Epoch 2730, Loss: 0.00860490882769227, Final Batch Loss: 0.006009511649608612\n",
      "Epoch 2731, Loss: 0.02707984484732151, Final Batch Loss: 0.017870305106043816\n",
      "Epoch 2732, Loss: 0.012278193375095725, Final Batch Loss: 0.00841254461556673\n",
      "Epoch 2733, Loss: 0.06591210560873151, Final Batch Loss: 0.007200941909104586\n",
      "Epoch 2734, Loss: 0.007812555879354477, Final Batch Loss: 0.005328231491148472\n",
      "Epoch 2735, Loss: 0.025438027689233422, Final Batch Loss: 0.022159524261951447\n",
      "Epoch 2736, Loss: 0.04450358543545008, Final Batch Loss: 0.03494032844901085\n",
      "Epoch 2737, Loss: 0.026585277169942856, Final Batch Loss: 0.017538364976644516\n",
      "Epoch 2738, Loss: 0.02908679167740047, Final Batch Loss: 0.02539319172501564\n",
      "Epoch 2739, Loss: 0.09538296889513731, Final Batch Loss: 0.08986837416887283\n",
      "Epoch 2740, Loss: 0.033237628638744354, Final Batch Loss: 0.01734090968966484\n",
      "Epoch 2741, Loss: 0.014115219470113516, Final Batch Loss: 0.00835835374891758\n",
      "Epoch 2742, Loss: 0.027792768669314682, Final Batch Loss: 0.0019077417673543096\n",
      "Epoch 2743, Loss: 0.018709552939981222, Final Batch Loss: 0.0023276000283658504\n",
      "Epoch 2744, Loss: 0.03360598161816597, Final Batch Loss: 0.016915811225771904\n",
      "Epoch 2745, Loss: 0.01566234673373401, Final Batch Loss: 0.002550400560721755\n",
      "Epoch 2746, Loss: 0.011705925222486258, Final Batch Loss: 0.0055715241469442844\n",
      "Epoch 2747, Loss: 0.036466569639742374, Final Batch Loss: 0.03174722567200661\n",
      "Epoch 2748, Loss: 0.0511788260191679, Final Batch Loss: 0.020548015832901\n",
      "Epoch 2749, Loss: 0.023032085970044136, Final Batch Loss: 0.013389677740633488\n",
      "Epoch 2750, Loss: 0.012138243531808257, Final Batch Loss: 0.002927719382569194\n",
      "Epoch 2751, Loss: 0.02687461907044053, Final Batch Loss: 0.006597491446882486\n",
      "Epoch 2752, Loss: 0.017698339885100722, Final Batch Loss: 0.0038347558584064245\n",
      "Epoch 2753, Loss: 0.025481967953965068, Final Batch Loss: 0.002117271302267909\n",
      "Epoch 2754, Loss: 0.02421592315658927, Final Batch Loss: 0.007052240427583456\n",
      "Epoch 2755, Loss: 0.022774940822273493, Final Batch Loss: 0.003942925948649645\n",
      "Epoch 2756, Loss: 0.018635242246091366, Final Batch Loss: 0.010727820917963982\n",
      "Epoch 2757, Loss: 0.014899166068062186, Final Batch Loss: 0.011745205149054527\n",
      "Epoch 2758, Loss: 0.018662426620721817, Final Batch Loss: 0.00844926480203867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2759, Loss: 0.008003869093954563, Final Batch Loss: 0.0030262665823101997\n",
      "Epoch 2760, Loss: 0.015829491894692183, Final Batch Loss: 0.004545301664620638\n",
      "Epoch 2761, Loss: 0.020273033995181322, Final Batch Loss: 0.01708373986184597\n",
      "Epoch 2762, Loss: 0.012101001106202602, Final Batch Loss: 0.006067492533475161\n",
      "Epoch 2763, Loss: 0.008969528833404183, Final Batch Loss: 0.00689922459423542\n",
      "Epoch 2764, Loss: 0.06783907115459442, Final Batch Loss: 0.03644738346338272\n",
      "Epoch 2765, Loss: 0.005160602740943432, Final Batch Loss: 0.0019644685089588165\n",
      "Epoch 2766, Loss: 0.014488032087683678, Final Batch Loss: 0.010163647122681141\n",
      "Epoch 2767, Loss: 0.015406307065859437, Final Batch Loss: 0.003208319889381528\n",
      "Epoch 2768, Loss: 0.04559721611440182, Final Batch Loss: 0.03512725606560707\n",
      "Epoch 2769, Loss: 0.0207297308370471, Final Batch Loss: 0.007372940890491009\n",
      "Epoch 2770, Loss: 0.020633612759411335, Final Batch Loss: 0.013794736936688423\n",
      "Epoch 2771, Loss: 0.03160524368286133, Final Batch Loss: 0.024343861266970634\n",
      "Epoch 2772, Loss: 0.016776608768850565, Final Batch Loss: 0.012104974128305912\n",
      "Epoch 2773, Loss: 0.015670881257392466, Final Batch Loss: 0.0018141638720408082\n",
      "Epoch 2774, Loss: 0.03155502490699291, Final Batch Loss: 0.012628050521016121\n",
      "Epoch 2775, Loss: 0.08393319696187973, Final Batch Loss: 0.04060056060552597\n",
      "Epoch 2776, Loss: 0.02258704137057066, Final Batch Loss: 0.01579788513481617\n",
      "Epoch 2777, Loss: 0.026163054397329688, Final Batch Loss: 0.022562218829989433\n",
      "Epoch 2778, Loss: 0.03288822062313557, Final Batch Loss: 0.022983307018876076\n",
      "Epoch 2779, Loss: 0.0716811753809452, Final Batch Loss: 0.030688557773828506\n",
      "Epoch 2780, Loss: 0.024834411800839007, Final Batch Loss: 0.023285560309886932\n",
      "Epoch 2781, Loss: 0.025508438237011433, Final Batch Loss: 0.007591203786432743\n",
      "Epoch 2782, Loss: 0.07675911672413349, Final Batch Loss: 0.018566081300377846\n",
      "Epoch 2783, Loss: 0.008028830867260695, Final Batch Loss: 0.003556332550942898\n",
      "Epoch 2784, Loss: 0.021065585780888796, Final Batch Loss: 0.018372833728790283\n",
      "Epoch 2785, Loss: 0.016743116779252887, Final Batch Loss: 0.0035829150583595037\n",
      "Epoch 2786, Loss: 0.010804619989357889, Final Batch Loss: 0.001423946931026876\n",
      "Epoch 2787, Loss: 0.019990697968751192, Final Batch Loss: 0.002484722528606653\n",
      "Epoch 2788, Loss: 0.028862855629995465, Final Batch Loss: 0.02629389613866806\n",
      "Epoch 2789, Loss: 0.010455260053277016, Final Batch Loss: 0.006231303326785564\n",
      "Epoch 2790, Loss: 0.06827472150325775, Final Batch Loss: 0.053098488599061966\n",
      "Epoch 2791, Loss: 0.029138924088329077, Final Batch Loss: 0.0031647025607526302\n",
      "Epoch 2792, Loss: 0.006213329790625721, Final Batch Loss: 0.0008411990129388869\n",
      "Epoch 2793, Loss: 0.03179271682165563, Final Batch Loss: 0.0296309906989336\n",
      "Epoch 2794, Loss: 0.012538944836705923, Final Batch Loss: 0.003103038761764765\n",
      "Epoch 2795, Loss: 0.010511578875593841, Final Batch Loss: 0.0008379713399335742\n",
      "Epoch 2796, Loss: 0.020289654843509197, Final Batch Loss: 0.010694165714085102\n",
      "Epoch 2797, Loss: 0.03102569840848446, Final Batch Loss: 0.023088717833161354\n",
      "Epoch 2798, Loss: 0.009391188621520996, Final Batch Loss: 0.0017805290408432484\n",
      "Epoch 2799, Loss: 0.06153326667845249, Final Batch Loss: 0.02708064578473568\n",
      "Epoch 2800, Loss: 0.011179519351571798, Final Batch Loss: 0.005580107215791941\n",
      "Epoch 2801, Loss: 0.0038484776159748435, Final Batch Loss: 0.0012797698145732284\n",
      "Epoch 2802, Loss: 0.023254007333889604, Final Batch Loss: 0.020226966589689255\n",
      "Epoch 2803, Loss: 0.031484696082770824, Final Batch Loss: 0.02320610173046589\n",
      "Epoch 2804, Loss: 0.008032499114051461, Final Batch Loss: 0.002000987296923995\n",
      "Epoch 2805, Loss: 0.012903157155960798, Final Batch Loss: 0.009436992928385735\n",
      "Epoch 2806, Loss: 0.012221070472151041, Final Batch Loss: 0.004288385156542063\n",
      "Epoch 2807, Loss: 0.025603692280128598, Final Batch Loss: 0.022929998114705086\n",
      "Epoch 2808, Loss: 0.02276410534977913, Final Batch Loss: 0.003278292715549469\n",
      "Epoch 2809, Loss: 0.010388824390247464, Final Batch Loss: 0.0035498926881700754\n",
      "Epoch 2810, Loss: 0.03588577592745423, Final Batch Loss: 0.003783895168453455\n",
      "Epoch 2811, Loss: 0.013542344560846686, Final Batch Loss: 0.0017943957354873419\n",
      "Epoch 2812, Loss: 0.032638268545269966, Final Batch Loss: 0.018394919112324715\n",
      "Epoch 2813, Loss: 0.006250299047678709, Final Batch Loss: 0.003930878825485706\n",
      "Epoch 2814, Loss: 0.024422859773039818, Final Batch Loss: 0.007553892210125923\n",
      "Epoch 2815, Loss: 0.04622367396950722, Final Batch Loss: 0.025501081719994545\n",
      "Epoch 2816, Loss: 0.021353975171223283, Final Batch Loss: 0.0016215222422033548\n",
      "Epoch 2817, Loss: 0.1117142029106617, Final Batch Loss: 0.08322825282812119\n",
      "Epoch 2818, Loss: 0.023334776982665062, Final Batch Loss: 0.016919679939746857\n",
      "Epoch 2819, Loss: 0.017648568842560053, Final Batch Loss: 0.006297289859503508\n",
      "Epoch 2820, Loss: 0.009470354416407645, Final Batch Loss: 0.0009571282425895333\n",
      "Epoch 2821, Loss: 0.01630951603874564, Final Batch Loss: 0.0040332055650651455\n",
      "Epoch 2822, Loss: 0.011145684402436018, Final Batch Loss: 0.005345836281776428\n",
      "Epoch 2823, Loss: 0.012117997044697404, Final Batch Loss: 0.008389083668589592\n",
      "Epoch 2824, Loss: 0.007218855665996671, Final Batch Loss: 0.003723738482221961\n",
      "Epoch 2825, Loss: 0.011450352612882853, Final Batch Loss: 0.0041063325479626656\n",
      "Epoch 2826, Loss: 0.016314689069986343, Final Batch Loss: 0.004183060489594936\n",
      "Epoch 2827, Loss: 0.034351582638919353, Final Batch Loss: 0.009001991711556911\n",
      "Epoch 2828, Loss: 0.007479408988729119, Final Batch Loss: 0.0023992785718292\n",
      "Epoch 2829, Loss: 0.011430688202381134, Final Batch Loss: 0.0020564422011375427\n",
      "Epoch 2830, Loss: 0.005036456044763327, Final Batch Loss: 0.0021149078384041786\n",
      "Epoch 2831, Loss: 0.014627916039898992, Final Batch Loss: 0.003347876714542508\n",
      "Epoch 2832, Loss: 0.010185081278905272, Final Batch Loss: 0.008196054957807064\n",
      "Epoch 2833, Loss: 0.013884416432119906, Final Batch Loss: 0.0016643140697851777\n",
      "Epoch 2834, Loss: 0.005556821124628186, Final Batch Loss: 0.002294883830472827\n",
      "Epoch 2835, Loss: 0.01188134215772152, Final Batch Loss: 0.00562420254573226\n",
      "Epoch 2836, Loss: 0.014097967417910695, Final Batch Loss: 0.0015681118238717318\n",
      "Epoch 2837, Loss: 0.006962525541894138, Final Batch Loss: 0.0011988024925813079\n",
      "Epoch 2838, Loss: 0.043864072766155005, Final Batch Loss: 0.004247584845870733\n",
      "Epoch 2839, Loss: 0.038426860235631466, Final Batch Loss: 0.008056179620325565\n",
      "Epoch 2840, Loss: 0.025070223840884864, Final Batch Loss: 0.001545684295706451\n",
      "Epoch 2841, Loss: 0.020567392464727163, Final Batch Loss: 0.005128620658069849\n",
      "Epoch 2842, Loss: 0.04490266367793083, Final Batch Loss: 0.007167398929595947\n",
      "Epoch 2843, Loss: 0.00764509430155158, Final Batch Loss: 0.00463545136153698\n",
      "Epoch 2844, Loss: 0.007680166512727737, Final Batch Loss: 0.002351516392081976\n",
      "Epoch 2845, Loss: 0.02883967198431492, Final Batch Loss: 0.01996241882443428\n",
      "Epoch 2846, Loss: 0.02881144918501377, Final Batch Loss: 0.012668758630752563\n",
      "Epoch 2847, Loss: 0.025065811350941658, Final Batch Loss: 0.014240889810025692\n",
      "Epoch 2848, Loss: 0.042658469174057245, Final Batch Loss: 0.007407201919704676\n",
      "Epoch 2849, Loss: 0.007246782770380378, Final Batch Loss: 0.0023703116457909346\n",
      "Epoch 2850, Loss: 0.01769788423553109, Final Batch Loss: 0.003698561806231737\n",
      "Epoch 2851, Loss: 0.008390156785026193, Final Batch Loss: 0.003802522784098983\n",
      "Epoch 2852, Loss: 0.008021206129342318, Final Batch Loss: 0.005154782440513372\n",
      "Epoch 2853, Loss: 0.014845435041934252, Final Batch Loss: 0.010920796543359756\n",
      "Epoch 2854, Loss: 0.010908062569797039, Final Batch Loss: 0.007913783192634583\n",
      "Epoch 2855, Loss: 0.05886005703359842, Final Batch Loss: 0.010401391424238682\n",
      "Epoch 2856, Loss: 0.012760798446834087, Final Batch Loss: 0.002700384706258774\n",
      "Epoch 2857, Loss: 0.012832654407247901, Final Batch Loss: 0.0010396891739219427\n",
      "Epoch 2858, Loss: 0.006462537217885256, Final Batch Loss: 0.003238992067053914\n",
      "Epoch 2859, Loss: 0.01277474733069539, Final Batch Loss: 0.004873993340879679\n",
      "Epoch 2860, Loss: 0.024657635018229485, Final Batch Loss: 0.009376810863614082\n",
      "Epoch 2861, Loss: 0.015913208248093724, Final Batch Loss: 0.012097046710550785\n",
      "Epoch 2862, Loss: 0.00438022508751601, Final Batch Loss: 0.0032809125259518623\n",
      "Epoch 2863, Loss: 0.020751143689267337, Final Batch Loss: 0.019408857449889183\n",
      "Epoch 2864, Loss: 0.008901193970814347, Final Batch Loss: 0.00318101211450994\n",
      "Epoch 2865, Loss: 0.054080139845609665, Final Batch Loss: 0.028019020333886147\n",
      "Epoch 2866, Loss: 0.07603867538273335, Final Batch Loss: 0.0718725174665451\n",
      "Epoch 2867, Loss: 0.036273516016080976, Final Batch Loss: 0.003028488950803876\n",
      "Epoch 2868, Loss: 0.12603489123284817, Final Batch Loss: 0.09734301269054413\n",
      "Epoch 2869, Loss: 0.033362445421516895, Final Batch Loss: 0.02323020063340664\n",
      "Epoch 2870, Loss: 0.031499577686190605, Final Batch Loss: 0.008092159405350685\n",
      "Epoch 2871, Loss: 0.06344149145297706, Final Batch Loss: 0.059889644384384155\n",
      "Epoch 2872, Loss: 0.08474379777908325, Final Batch Loss: 0.016268223524093628\n",
      "Epoch 2873, Loss: 0.05952410772442818, Final Batch Loss: 0.009614553302526474\n",
      "Epoch 2874, Loss: 0.019757930655032396, Final Batch Loss: 0.012471772730350494\n",
      "Epoch 2875, Loss: 0.033754367381334305, Final Batch Loss: 0.010478781536221504\n",
      "Epoch 2876, Loss: 0.026532934047281742, Final Batch Loss: 0.008845464326441288\n",
      "Epoch 2877, Loss: 0.04567977786064148, Final Batch Loss: 0.028330154716968536\n",
      "Epoch 2878, Loss: 0.019709656480699778, Final Batch Loss: 0.005881670396775007\n",
      "Epoch 2879, Loss: 0.04445159342139959, Final Batch Loss: 0.030940381810069084\n",
      "Epoch 2880, Loss: 0.03857089672237635, Final Batch Loss: 0.015253503806889057\n",
      "Epoch 2881, Loss: 0.016892888816073537, Final Batch Loss: 0.003627502592280507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2882, Loss: 0.014343986520543694, Final Batch Loss: 0.0022025725338608027\n",
      "Epoch 2883, Loss: 0.032545086462050676, Final Batch Loss: 0.02596364915370941\n",
      "Epoch 2884, Loss: 0.03446229360997677, Final Batch Loss: 0.007971514016389847\n",
      "Epoch 2885, Loss: 0.01763118989765644, Final Batch Loss: 0.00980028323829174\n",
      "Epoch 2886, Loss: 0.02856859378516674, Final Batch Loss: 0.008647896349430084\n",
      "Epoch 2887, Loss: 0.017340255435556173, Final Batch Loss: 0.002462428528815508\n",
      "Epoch 2888, Loss: 0.030767299234867096, Final Batch Loss: 0.026705069467425346\n",
      "Epoch 2889, Loss: 0.010796211659908295, Final Batch Loss: 0.006281536538153887\n",
      "Epoch 2890, Loss: 0.022938508540391922, Final Batch Loss: 0.0030541326850652695\n",
      "Epoch 2891, Loss: 0.03421897441148758, Final Batch Loss: 0.02032979018986225\n",
      "Epoch 2892, Loss: 0.014498271979391575, Final Batch Loss: 0.0056870244443416595\n",
      "Epoch 2893, Loss: 0.019681906327605247, Final Batch Loss: 0.003507247194647789\n",
      "Epoch 2894, Loss: 0.03281782753765583, Final Batch Loss: 0.020089320838451385\n",
      "Epoch 2895, Loss: 0.028872249647974968, Final Batch Loss: 0.014741036109626293\n",
      "Epoch 2896, Loss: 0.01891276892274618, Final Batch Loss: 0.011493291705846786\n",
      "Epoch 2897, Loss: 0.019911709241569042, Final Batch Loss: 0.0029392605647444725\n",
      "Epoch 2898, Loss: 0.026230227202177048, Final Batch Loss: 0.021754903718829155\n",
      "Epoch 2899, Loss: 0.05780152603983879, Final Batch Loss: 0.048147015273571014\n",
      "Epoch 2900, Loss: 0.009187485091388226, Final Batch Loss: 0.005898542236536741\n",
      "Epoch 2901, Loss: 0.015839001163840294, Final Batch Loss: 0.01245829090476036\n",
      "Epoch 2902, Loss: 0.009367970982566476, Final Batch Loss: 0.003161464584991336\n",
      "Epoch 2903, Loss: 0.008107342990115285, Final Batch Loss: 0.0015769267920404673\n",
      "Epoch 2904, Loss: 0.017211600206792355, Final Batch Loss: 0.003966746851801872\n",
      "Epoch 2905, Loss: 0.008574201259762049, Final Batch Loss: 0.0032526571303606033\n",
      "Epoch 2906, Loss: 0.03795705852098763, Final Batch Loss: 0.0025347594637423754\n",
      "Epoch 2907, Loss: 0.059309618547558784, Final Batch Loss: 0.030411025509238243\n",
      "Epoch 2908, Loss: 0.01008288306184113, Final Batch Loss: 0.00627270620316267\n",
      "Epoch 2909, Loss: 0.03456989862024784, Final Batch Loss: 0.020147575065493584\n",
      "Epoch 2910, Loss: 0.0042557576089166105, Final Batch Loss: 0.0007708412013016641\n",
      "Epoch 2911, Loss: 0.05001921206712723, Final Batch Loss: 0.02663237974047661\n",
      "Epoch 2912, Loss: 0.003864591824822128, Final Batch Loss: 0.0005278232274577022\n",
      "Epoch 2913, Loss: 0.013180164154618979, Final Batch Loss: 0.009279834106564522\n",
      "Epoch 2914, Loss: 0.005911154439672828, Final Batch Loss: 0.0020683349575847387\n",
      "Epoch 2915, Loss: 0.019632309675216675, Final Batch Loss: 0.011878606863319874\n",
      "Epoch 2916, Loss: 0.025812495732679963, Final Batch Loss: 0.00285497703589499\n",
      "Epoch 2917, Loss: 0.008262948598712683, Final Batch Loss: 0.0038690180517733097\n",
      "Epoch 2918, Loss: 0.04275081120431423, Final Batch Loss: 0.006212951615452766\n",
      "Epoch 2919, Loss: 0.008926864014938474, Final Batch Loss: 0.0025149413850158453\n",
      "Epoch 2920, Loss: 0.011970608495175838, Final Batch Loss: 0.0038792407140135765\n",
      "Epoch 2921, Loss: 0.01577742025256157, Final Batch Loss: 0.00563565269112587\n",
      "Epoch 2922, Loss: 0.026685898192226887, Final Batch Loss: 0.01711897924542427\n",
      "Epoch 2923, Loss: 0.014450208749622107, Final Batch Loss: 0.004691976588219404\n",
      "Epoch 2924, Loss: 0.018699832260608673, Final Batch Loss: 0.013793284073472023\n",
      "Epoch 2925, Loss: 0.0966646671295166, Final Batch Loss: 0.047318235039711\n",
      "Epoch 2926, Loss: 0.022749260999262333, Final Batch Loss: 0.006606879644095898\n",
      "Epoch 2927, Loss: 0.05516641680151224, Final Batch Loss: 0.01518202293664217\n",
      "Epoch 2928, Loss: 0.011301749385893345, Final Batch Loss: 0.0014945603907108307\n",
      "Epoch 2929, Loss: 0.008479403331875801, Final Batch Loss: 0.0028866049833595753\n",
      "Epoch 2930, Loss: 0.013578196987509727, Final Batch Loss: 0.004633050411939621\n",
      "Epoch 2931, Loss: 0.019068812020123005, Final Batch Loss: 0.012818573974072933\n",
      "Epoch 2932, Loss: 0.00954363914206624, Final Batch Loss: 0.0028869975358247757\n",
      "Epoch 2933, Loss: 0.007193617755547166, Final Batch Loss: 0.002562218578532338\n",
      "Epoch 2934, Loss: 0.01967326831072569, Final Batch Loss: 0.007966559380292892\n",
      "Epoch 2935, Loss: 0.014955159742385149, Final Batch Loss: 0.0035884766839444637\n",
      "Epoch 2936, Loss: 0.016151358373463154, Final Batch Loss: 0.007661931216716766\n",
      "Epoch 2937, Loss: 0.021527467295527458, Final Batch Loss: 0.002578500658273697\n",
      "Epoch 2938, Loss: 0.012569957878440619, Final Batch Loss: 0.007501307409256697\n",
      "Epoch 2939, Loss: 0.026421590242534876, Final Batch Loss: 0.002164002973586321\n",
      "Epoch 2940, Loss: 0.008650645380839705, Final Batch Loss: 0.004942877683788538\n",
      "Epoch 2941, Loss: 0.01625152351334691, Final Batch Loss: 0.009597133845090866\n",
      "Epoch 2942, Loss: 0.012372100492939353, Final Batch Loss: 0.008652160875499249\n",
      "Epoch 2943, Loss: 0.047280734637752175, Final Batch Loss: 0.04354175552725792\n",
      "Epoch 2944, Loss: 0.008552505169063807, Final Batch Loss: 0.0053147971630096436\n",
      "Epoch 2945, Loss: 0.018526682630181313, Final Batch Loss: 0.008560962043702602\n",
      "Epoch 2946, Loss: 0.004962429404258728, Final Batch Loss: 0.002854706486687064\n",
      "Epoch 2947, Loss: 0.004551312536932528, Final Batch Loss: 0.0032765623182058334\n",
      "Epoch 2948, Loss: 0.04472000105306506, Final Batch Loss: 0.04210658743977547\n",
      "Epoch 2949, Loss: 0.02630306174978614, Final Batch Loss: 0.004015143495053053\n",
      "Epoch 2950, Loss: 0.0189222760964185, Final Batch Loss: 0.0031529006082564592\n",
      "Epoch 2951, Loss: 0.0735553172416985, Final Batch Loss: 0.06604862958192825\n",
      "Epoch 2952, Loss: 0.016688529402017593, Final Batch Loss: 0.010818843729794025\n",
      "Epoch 2953, Loss: 0.009321130346506834, Final Batch Loss: 0.005384672898799181\n",
      "Epoch 2954, Loss: 0.015384271275252104, Final Batch Loss: 0.013235785067081451\n",
      "Epoch 2955, Loss: 0.07611127197742462, Final Batch Loss: 0.05341317504644394\n",
      "Epoch 2956, Loss: 0.005905450903810561, Final Batch Loss: 0.0017581862630322576\n",
      "Epoch 2957, Loss: 0.05410951003432274, Final Batch Loss: 0.018149085342884064\n",
      "Epoch 2958, Loss: 0.019031337229534984, Final Batch Loss: 0.0021005950402468443\n",
      "Epoch 2959, Loss: 0.029854142107069492, Final Batch Loss: 0.01650139130651951\n",
      "Epoch 2960, Loss: 0.019007395952939987, Final Batch Loss: 0.014234257861971855\n",
      "Epoch 2961, Loss: 0.0657360628247261, Final Batch Loss: 0.011894676834344864\n",
      "Epoch 2962, Loss: 0.01712698396295309, Final Batch Loss: 0.01043209433555603\n",
      "Epoch 2963, Loss: 0.019650224596261978, Final Batch Loss: 0.014669589698314667\n",
      "Epoch 2964, Loss: 0.014575111214071512, Final Batch Loss: 0.002787800971418619\n",
      "Epoch 2965, Loss: 0.012620570603758097, Final Batch Loss: 0.006850474514067173\n",
      "Epoch 2966, Loss: 0.035656369058415294, Final Batch Loss: 0.002111802576109767\n",
      "Epoch 2967, Loss: 0.011992658022791147, Final Batch Loss: 0.007620007265359163\n",
      "Epoch 2968, Loss: 0.011950240470468998, Final Batch Loss: 0.004751312546432018\n",
      "Epoch 2969, Loss: 0.041655564680695534, Final Batch Loss: 0.037491101771593094\n",
      "Epoch 2970, Loss: 0.025255756452679634, Final Batch Loss: 0.004728903993964195\n",
      "Epoch 2971, Loss: 0.09034277871251106, Final Batch Loss: 0.038201671093702316\n",
      "Epoch 2972, Loss: 0.01463473029434681, Final Batch Loss: 0.002462848089635372\n",
      "Epoch 2973, Loss: 0.1060167271643877, Final Batch Loss: 0.08937696367502213\n",
      "Epoch 2974, Loss: 0.056790685281157494, Final Batch Loss: 0.0091079231351614\n",
      "Epoch 2975, Loss: 0.10151565261185169, Final Batch Loss: 0.07434315979480743\n",
      "Epoch 2976, Loss: 0.023103246930986643, Final Batch Loss: 0.019025936722755432\n",
      "Epoch 2977, Loss: 0.031955648213624954, Final Batch Loss: 0.01672389544546604\n",
      "Epoch 2978, Loss: 0.08737331535667181, Final Batch Loss: 0.004485062323510647\n",
      "Epoch 2979, Loss: 0.029560082126408815, Final Batch Loss: 0.006577289197593927\n",
      "Epoch 2980, Loss: 0.036844913847744465, Final Batch Loss: 0.02219076082110405\n",
      "Epoch 2981, Loss: 0.03202701918780804, Final Batch Loss: 0.021969392895698547\n",
      "Epoch 2982, Loss: 0.02866996917873621, Final Batch Loss: 0.011589168570935726\n",
      "Epoch 2983, Loss: 0.03205035300925374, Final Batch Loss: 0.02734224498271942\n",
      "Epoch 2984, Loss: 0.02181933308020234, Final Batch Loss: 0.007647993508726358\n",
      "Epoch 2985, Loss: 0.017830276396125555, Final Batch Loss: 0.01391451247036457\n",
      "Epoch 2986, Loss: 0.03030087985098362, Final Batch Loss: 0.011751437559723854\n",
      "Epoch 2987, Loss: 0.03334544226527214, Final Batch Loss: 0.01686120592057705\n",
      "Epoch 2988, Loss: 0.013480153400450945, Final Batch Loss: 0.0044952393509447575\n",
      "Epoch 2989, Loss: 0.04500911384820938, Final Batch Loss: 0.012912675738334656\n",
      "Epoch 2990, Loss: 0.07002697698771954, Final Batch Loss: 0.02188391424715519\n",
      "Epoch 2991, Loss: 0.027368595823645592, Final Batch Loss: 0.010848157107830048\n",
      "Epoch 2992, Loss: 0.01830537710338831, Final Batch Loss: 0.010313400067389011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2993, Loss: 0.04576086066663265, Final Batch Loss: 0.04144832491874695\n",
      "Epoch 2994, Loss: 0.03400409407913685, Final Batch Loss: 0.0248069167137146\n",
      "Epoch 2995, Loss: 0.0420284615829587, Final Batch Loss: 0.03770720958709717\n",
      "Epoch 2996, Loss: 0.054773688316345215, Final Batch Loss: 0.017547018826007843\n",
      "Epoch 2997, Loss: 0.006743288598954678, Final Batch Loss: 0.0028481727931648493\n",
      "Epoch 2998, Loss: 0.04334883950650692, Final Batch Loss: 0.02429741621017456\n",
      "Epoch 2999, Loss: 0.015820054803043604, Final Batch Loss: 0.009428146295249462\n",
      "Epoch 3000, Loss: 0.058935679495334625, Final Batch Loss: 0.04281720146536827\n",
      "Epoch 3001, Loss: 0.02135244384407997, Final Batch Loss: 0.014852572232484818\n",
      "Epoch 3002, Loss: 0.022539339028298855, Final Batch Loss: 0.01207851804792881\n",
      "Epoch 3003, Loss: 0.0178376417607069, Final Batch Loss: 0.006547779776155949\n",
      "Epoch 3004, Loss: 0.01924127829261124, Final Batch Loss: 0.01683816686272621\n",
      "Epoch 3005, Loss: 0.06865860987454653, Final Batch Loss: 0.06459620594978333\n",
      "Epoch 3006, Loss: 0.017009173054248095, Final Batch Loss: 0.005388529505580664\n",
      "Epoch 3007, Loss: 0.04801519960165024, Final Batch Loss: 0.0322134867310524\n",
      "Epoch 3008, Loss: 0.01457672519609332, Final Batch Loss: 0.006528310943394899\n",
      "Epoch 3009, Loss: 0.00782831571996212, Final Batch Loss: 0.004381805192679167\n",
      "Epoch 3010, Loss: 0.01560372207313776, Final Batch Loss: 0.007831182330846786\n",
      "Epoch 3011, Loss: 0.014410810079425573, Final Batch Loss: 0.005931707564741373\n",
      "Epoch 3012, Loss: 0.0295514112804085, Final Batch Loss: 0.0021435918752104044\n",
      "Epoch 3013, Loss: 0.01815983187407255, Final Batch Loss: 0.005004307255148888\n",
      "Epoch 3014, Loss: 0.01422443799674511, Final Batch Loss: 0.008384943939745426\n",
      "Epoch 3015, Loss: 0.03597797453403473, Final Batch Loss: 0.015674514696002007\n",
      "Epoch 3016, Loss: 0.005738741368986666, Final Batch Loss: 0.0017803326481953263\n",
      "Epoch 3017, Loss: 0.02098389994353056, Final Batch Loss: 0.016567392274737358\n",
      "Epoch 3018, Loss: 0.04155373992398381, Final Batch Loss: 0.03684847801923752\n",
      "Epoch 3019, Loss: 0.04709787666797638, Final Batch Loss: 0.008416026830673218\n",
      "Epoch 3020, Loss: 0.01904993038624525, Final Batch Loss: 0.01673799566924572\n",
      "Epoch 3021, Loss: 0.01685447059571743, Final Batch Loss: 0.004671239294111729\n",
      "Epoch 3022, Loss: 0.05060331290587783, Final Batch Loss: 0.042949579656124115\n",
      "Epoch 3023, Loss: 0.01979372650384903, Final Batch Loss: 0.004335791803896427\n",
      "Epoch 3024, Loss: 0.012651933124288917, Final Batch Loss: 0.003336516907438636\n",
      "Epoch 3025, Loss: 0.019340745639055967, Final Batch Loss: 0.003998474683612585\n",
      "Epoch 3026, Loss: 0.019811874255537987, Final Batch Loss: 0.005796017125248909\n",
      "Epoch 3027, Loss: 0.008650215342640877, Final Batch Loss: 0.006481832824647427\n",
      "Epoch 3028, Loss: 0.05945751257240772, Final Batch Loss: 0.025240356102585793\n",
      "Epoch 3029, Loss: 0.025271636433899403, Final Batch Loss: 0.003346492536365986\n",
      "Epoch 3030, Loss: 0.030272318981587887, Final Batch Loss: 0.008376448415219784\n",
      "Epoch 3031, Loss: 0.10601925756782293, Final Batch Loss: 0.09180807322263718\n",
      "Epoch 3032, Loss: 0.020597062073647976, Final Batch Loss: 0.012378765270113945\n",
      "Epoch 3033, Loss: 0.014916676096618176, Final Batch Loss: 0.011554285883903503\n",
      "Epoch 3034, Loss: 0.016430382151156664, Final Batch Loss: 0.010795927606523037\n",
      "Epoch 3035, Loss: 0.03433865960687399, Final Batch Loss: 0.023940525949001312\n",
      "Epoch 3036, Loss: 0.008715334348380566, Final Batch Loss: 0.00475711515173316\n",
      "Epoch 3037, Loss: 0.013449828373268247, Final Batch Loss: 0.002093713032081723\n",
      "Epoch 3038, Loss: 0.01296257320791483, Final Batch Loss: 0.005585335195064545\n",
      "Epoch 3039, Loss: 0.03959493152797222, Final Batch Loss: 0.016169078648090363\n",
      "Epoch 3040, Loss: 0.012347874697297812, Final Batch Loss: 0.004692418966442347\n",
      "Epoch 3041, Loss: 0.01837005582638085, Final Batch Loss: 0.014920439571142197\n",
      "Epoch 3042, Loss: 0.01709788106381893, Final Batch Loss: 0.007448732852935791\n",
      "Epoch 3043, Loss: 0.020746042486280203, Final Batch Loss: 0.01632808893918991\n",
      "Epoch 3044, Loss: 0.019029165152460337, Final Batch Loss: 0.014799839816987514\n",
      "Epoch 3045, Loss: 0.12462291494011879, Final Batch Loss: 0.044157933443784714\n",
      "Epoch 3046, Loss: 0.012713209260255098, Final Batch Loss: 0.00391335180029273\n",
      "Epoch 3047, Loss: 0.10345995984971523, Final Batch Loss: 0.07760003954172134\n",
      "Epoch 3048, Loss: 0.014140363200567663, Final Batch Loss: 0.0014914119383320212\n",
      "Epoch 3049, Loss: 0.020277272909879684, Final Batch Loss: 0.005720401182770729\n",
      "Epoch 3050, Loss: 0.17861147597432137, Final Batch Loss: 0.15309585630893707\n",
      "Epoch 3051, Loss: 0.057531123980879784, Final Batch Loss: 0.04694126546382904\n",
      "Epoch 3052, Loss: 0.04031578078866005, Final Batch Loss: 0.01703052408993244\n",
      "Epoch 3053, Loss: 0.09987271204590797, Final Batch Loss: 0.03136691078543663\n",
      "Epoch 3054, Loss: 0.028822546359151602, Final Batch Loss: 0.02459368295967579\n",
      "Epoch 3055, Loss: 0.044402992352843285, Final Batch Loss: 0.024244913831353188\n",
      "Epoch 3056, Loss: 0.023762214928865433, Final Batch Loss: 0.004126271232962608\n",
      "Epoch 3057, Loss: 0.03142787702381611, Final Batch Loss: 0.020125605165958405\n",
      "Epoch 3058, Loss: 0.04494123626500368, Final Batch Loss: 0.03416609764099121\n",
      "Epoch 3059, Loss: 0.026069927494972944, Final Batch Loss: 0.02011076733469963\n",
      "Epoch 3060, Loss: 0.03649787697941065, Final Batch Loss: 0.02336251735687256\n",
      "Epoch 3061, Loss: 0.03461372945457697, Final Batch Loss: 0.007397814653813839\n",
      "Epoch 3062, Loss: 0.015777915716171265, Final Batch Loss: 0.0062667978927493095\n",
      "Epoch 3063, Loss: 0.03804352134466171, Final Batch Loss: 0.026718713343143463\n",
      "Epoch 3064, Loss: 0.071785232052207, Final Batch Loss: 0.0262600090354681\n",
      "Epoch 3065, Loss: 0.0494075883179903, Final Batch Loss: 0.030902734026312828\n",
      "Epoch 3066, Loss: 0.0330203752964735, Final Batch Loss: 0.009425736963748932\n",
      "Epoch 3067, Loss: 0.014988630078732967, Final Batch Loss: 0.007374646607786417\n",
      "Epoch 3068, Loss: 0.020083855371922255, Final Batch Loss: 0.01269401516765356\n",
      "Epoch 3069, Loss: 0.025423567974939942, Final Batch Loss: 0.0031247029546648264\n",
      "Epoch 3070, Loss: 0.04337400570511818, Final Batch Loss: 0.016349509358406067\n",
      "Epoch 3071, Loss: 0.027716686483472586, Final Batch Loss: 0.004787481855601072\n",
      "Epoch 3072, Loss: 0.017349855042994022, Final Batch Loss: 0.011633172631263733\n",
      "Epoch 3073, Loss: 0.025460246950387955, Final Batch Loss: 0.018516182899475098\n",
      "Epoch 3074, Loss: 0.02535763941705227, Final Batch Loss: 0.020521435886621475\n",
      "Epoch 3075, Loss: 0.014743562322109938, Final Batch Loss: 0.008102809078991413\n",
      "Epoch 3076, Loss: 0.04213441722095013, Final Batch Loss: 0.03553330898284912\n",
      "Epoch 3077, Loss: 0.02207267750054598, Final Batch Loss: 0.009331777691841125\n",
      "Epoch 3078, Loss: 0.011769407894462347, Final Batch Loss: 0.004742923192679882\n",
      "Epoch 3079, Loss: 0.016107575967907906, Final Batch Loss: 0.005588574334979057\n",
      "Epoch 3080, Loss: 0.021717418218031526, Final Batch Loss: 0.0038333518896251917\n",
      "Epoch 3081, Loss: 0.014910509577021003, Final Batch Loss: 0.0011684929486364126\n",
      "Epoch 3082, Loss: 0.036640703678131104, Final Batch Loss: 0.011366313323378563\n",
      "Epoch 3083, Loss: 0.06313045509159565, Final Batch Loss: 0.03986867889761925\n",
      "Epoch 3084, Loss: 0.05304508190602064, Final Batch Loss: 0.009101360104978085\n",
      "Epoch 3085, Loss: 0.023458472918719053, Final Batch Loss: 0.006158267613500357\n",
      "Epoch 3086, Loss: 0.09921128675341606, Final Batch Loss: 0.06960117071866989\n",
      "Epoch 3087, Loss: 0.033406694419682026, Final Batch Loss: 0.021487312391400337\n",
      "Epoch 3088, Loss: 0.05330045893788338, Final Batch Loss: 0.01630997285246849\n",
      "Epoch 3089, Loss: 0.0030766131822019815, Final Batch Loss: 0.0009987521916627884\n",
      "Epoch 3090, Loss: 0.031727357069030404, Final Batch Loss: 0.028625404462218285\n",
      "Epoch 3091, Loss: 0.02219987101852894, Final Batch Loss: 0.008847675286233425\n",
      "Epoch 3092, Loss: 0.015419241972267628, Final Batch Loss: 0.01089091319590807\n",
      "Epoch 3093, Loss: 0.010151574620977044, Final Batch Loss: 0.0073997159488499165\n",
      "Epoch 3094, Loss: 0.03990377765148878, Final Batch Loss: 0.005204363726079464\n",
      "Epoch 3095, Loss: 0.05041786143556237, Final Batch Loss: 0.0024498500861227512\n",
      "Epoch 3096, Loss: 0.04881918616592884, Final Batch Loss: 0.022530393674969673\n",
      "Epoch 3097, Loss: 0.007090224651619792, Final Batch Loss: 0.004120149649679661\n",
      "Epoch 3098, Loss: 0.031317693181335926, Final Batch Loss: 0.004845327697694302\n",
      "Epoch 3099, Loss: 0.0145785016939044, Final Batch Loss: 0.0097428597509861\n",
      "Epoch 3100, Loss: 0.010065272450447083, Final Batch Loss: 0.006452252622693777\n",
      "Epoch 3101, Loss: 0.017014367505908012, Final Batch Loss: 0.007226690649986267\n",
      "Epoch 3102, Loss: 0.025931490119546652, Final Batch Loss: 0.020129989832639694\n",
      "Epoch 3103, Loss: 0.026119946036487818, Final Batch Loss: 0.021108431741595268\n",
      "Epoch 3104, Loss: 0.01107350131496787, Final Batch Loss: 0.005927139427512884\n",
      "Epoch 3105, Loss: 0.09957981389015913, Final Batch Loss: 0.09412761777639389\n",
      "Epoch 3106, Loss: 0.022821451537311077, Final Batch Loss: 0.010981988161802292\n",
      "Epoch 3107, Loss: 0.03182703210040927, Final Batch Loss: 0.02480193041265011\n",
      "Epoch 3108, Loss: 0.037410146091133356, Final Batch Loss: 0.0024569169618189335\n",
      "Epoch 3109, Loss: 0.02933104895055294, Final Batch Loss: 0.02496533840894699\n",
      "Epoch 3110, Loss: 0.015309033216908574, Final Batch Loss: 0.0037408333737403154\n",
      "Epoch 3111, Loss: 0.06661547161638737, Final Batch Loss: 0.021486962214112282\n",
      "Epoch 3112, Loss: 0.013748459983617067, Final Batch Loss: 0.008547446690499783\n",
      "Epoch 3113, Loss: 0.022282618563622236, Final Batch Loss: 0.007053370121866465\n",
      "Epoch 3114, Loss: 0.016485046595335007, Final Batch Loss: 0.008797939866781235\n",
      "Epoch 3115, Loss: 0.10124858282506466, Final Batch Loss: 0.08204872906208038\n",
      "Epoch 3116, Loss: 0.009046440478414297, Final Batch Loss: 0.0030242642387747765\n",
      "Epoch 3117, Loss: 0.04309248994104564, Final Batch Loss: 0.03942655399441719\n",
      "Epoch 3118, Loss: 0.03892494924366474, Final Batch Loss: 0.02822655439376831\n",
      "Epoch 3119, Loss: 0.016018738970160484, Final Batch Loss: 0.010970639064908028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3120, Loss: 0.020697918720543385, Final Batch Loss: 0.012490426190197468\n",
      "Epoch 3121, Loss: 0.03705034498125315, Final Batch Loss: 0.00839314516633749\n",
      "Epoch 3122, Loss: 0.011082445504143834, Final Batch Loss: 0.0035201895516365767\n",
      "Epoch 3123, Loss: 0.033441110514104366, Final Batch Loss: 0.01422457117587328\n",
      "Epoch 3124, Loss: 0.03778393939137459, Final Batch Loss: 0.012911802157759666\n",
      "Epoch 3125, Loss: 0.04097597533836961, Final Batch Loss: 0.03794850409030914\n",
      "Epoch 3126, Loss: 0.0913756862282753, Final Batch Loss: 0.06509627401828766\n",
      "Epoch 3127, Loss: 0.0457866033539176, Final Batch Loss: 0.010762698017060757\n",
      "Epoch 3128, Loss: 0.06098584085702896, Final Batch Loss: 0.049207936972379684\n",
      "Epoch 3129, Loss: 0.010852582287043333, Final Batch Loss: 0.003233585972338915\n",
      "Epoch 3130, Loss: 0.05126052163541317, Final Batch Loss: 0.01781178079545498\n",
      "Epoch 3131, Loss: 0.04208545573055744, Final Batch Loss: 0.01765117421746254\n",
      "Epoch 3132, Loss: 0.014692336320877075, Final Batch Loss: 0.00976881105452776\n",
      "Epoch 3133, Loss: 0.04390731826424599, Final Batch Loss: 0.036287397146224976\n",
      "Epoch 3134, Loss: 0.018185642082244158, Final Batch Loss: 0.01251661591231823\n",
      "Epoch 3135, Loss: 0.041356828063726425, Final Batch Loss: 0.022625282406806946\n",
      "Epoch 3136, Loss: 0.015641381964087486, Final Batch Loss: 0.00805454608052969\n",
      "Epoch 3137, Loss: 0.028583459090441465, Final Batch Loss: 0.025589898228645325\n",
      "Epoch 3138, Loss: 0.0200115074403584, Final Batch Loss: 0.004269041586667299\n",
      "Epoch 3139, Loss: 0.021443921141326427, Final Batch Loss: 0.004121185280382633\n",
      "Epoch 3140, Loss: 0.01253262022510171, Final Batch Loss: 0.008106783963739872\n",
      "Epoch 3141, Loss: 0.00956888182554394, Final Batch Loss: 0.0011688197264447808\n",
      "Epoch 3142, Loss: 0.03517534118145704, Final Batch Loss: 0.011121581308543682\n",
      "Epoch 3143, Loss: 0.016781423706561327, Final Batch Loss: 0.0055511160753667355\n",
      "Epoch 3144, Loss: 0.023576833307743073, Final Batch Loss: 0.014001468196511269\n",
      "Epoch 3145, Loss: 0.01581622613593936, Final Batch Loss: 0.005140680354088545\n",
      "Epoch 3146, Loss: 0.016828464344143867, Final Batch Loss: 0.002839094027876854\n",
      "Epoch 3147, Loss: 0.004103219253011048, Final Batch Loss: 0.0010857462184503675\n",
      "Epoch 3148, Loss: 0.01436328492127359, Final Batch Loss: 0.0023807191755622625\n",
      "Epoch 3149, Loss: 0.03728288831189275, Final Batch Loss: 0.007381186354905367\n",
      "Epoch 3150, Loss: 0.012387137860059738, Final Batch Loss: 0.0040160976350307465\n",
      "Epoch 3151, Loss: 0.009354287292808294, Final Batch Loss: 0.002684367820620537\n",
      "Epoch 3152, Loss: 0.022662094794213772, Final Batch Loss: 0.010361392050981522\n",
      "Epoch 3153, Loss: 0.023014213889837265, Final Batch Loss: 0.014565949328243732\n",
      "Epoch 3154, Loss: 0.005787454312667251, Final Batch Loss: 0.0023777401074767113\n",
      "Epoch 3155, Loss: 0.024337549228221178, Final Batch Loss: 0.005420919973403215\n",
      "Epoch 3156, Loss: 0.016244600992649794, Final Batch Loss: 0.01016183476895094\n",
      "Epoch 3157, Loss: 0.047975781839340925, Final Batch Loss: 0.005078181158751249\n",
      "Epoch 3158, Loss: 0.008091244497336447, Final Batch Loss: 0.0015204172814264894\n",
      "Epoch 3159, Loss: 0.020265288185328245, Final Batch Loss: 0.014346622861921787\n",
      "Epoch 3160, Loss: 0.014242730103433132, Final Batch Loss: 0.005777130834758282\n",
      "Epoch 3161, Loss: 0.015500760171562433, Final Batch Loss: 0.004742028657346964\n",
      "Epoch 3162, Loss: 0.013540975749492645, Final Batch Loss: 0.00697790551930666\n",
      "Epoch 3163, Loss: 0.011737963883206248, Final Batch Loss: 0.008034356869757175\n",
      "Epoch 3164, Loss: 0.03825360257178545, Final Batch Loss: 0.012297951616346836\n",
      "Epoch 3165, Loss: 0.043113577645272017, Final Batch Loss: 0.03901224583387375\n",
      "Epoch 3166, Loss: 0.027921639382839203, Final Batch Loss: 0.008515354245901108\n",
      "Epoch 3167, Loss: 0.013991336803883314, Final Batch Loss: 0.00787845253944397\n",
      "Epoch 3168, Loss: 0.018097544088959694, Final Batch Loss: 0.003271144814789295\n",
      "Epoch 3169, Loss: 0.01879328559152782, Final Batch Loss: 0.015018471516668797\n",
      "Epoch 3170, Loss: 0.016176413744688034, Final Batch Loss: 0.005317408591508865\n",
      "Epoch 3171, Loss: 0.022283908911049366, Final Batch Loss: 0.008714978583157063\n",
      "Epoch 3172, Loss: 0.011933193076401949, Final Batch Loss: 0.002587434370070696\n",
      "Epoch 3173, Loss: 0.012132256757467985, Final Batch Loss: 0.006641695275902748\n",
      "Epoch 3174, Loss: 0.004423163831233978, Final Batch Loss: 0.0012895804829895496\n",
      "Epoch 3175, Loss: 0.016822202713228762, Final Batch Loss: 0.0018748227739706635\n",
      "Epoch 3176, Loss: 0.05443206802010536, Final Batch Loss: 0.023244526237249374\n",
      "Epoch 3177, Loss: 0.005176272010430694, Final Batch Loss: 0.002743789926171303\n",
      "Epoch 3178, Loss: 0.009634579764679074, Final Batch Loss: 0.006842614617198706\n",
      "Epoch 3179, Loss: 0.003630696446634829, Final Batch Loss: 0.0015535062411800027\n",
      "Epoch 3180, Loss: 0.0030749422730877995, Final Batch Loss: 0.0014523965073749423\n",
      "Epoch 3181, Loss: 0.01034764968790114, Final Batch Loss: 0.008602854795753956\n",
      "Epoch 3182, Loss: 0.006433428730815649, Final Batch Loss: 0.0015921900048851967\n",
      "Epoch 3183, Loss: 0.04031726089306176, Final Batch Loss: 0.0030429076869040728\n",
      "Epoch 3184, Loss: 0.032560097984969616, Final Batch Loss: 0.014941087923943996\n",
      "Epoch 3185, Loss: 0.021975334733724594, Final Batch Loss: 0.002177441492676735\n",
      "Epoch 3186, Loss: 0.01402597175911069, Final Batch Loss: 0.0013556075282394886\n",
      "Epoch 3187, Loss: 0.015334276715293527, Final Batch Loss: 0.003743225010111928\n",
      "Epoch 3188, Loss: 0.004249088000506163, Final Batch Loss: 0.0009839455597102642\n",
      "Epoch 3189, Loss: 0.027687092311680317, Final Batch Loss: 0.0013280166313052177\n",
      "Epoch 3190, Loss: 0.005434372695162892, Final Batch Loss: 0.002201617695391178\n",
      "Epoch 3191, Loss: 0.03084003319963813, Final Batch Loss: 0.002687597181648016\n",
      "Epoch 3192, Loss: 0.025869186036288738, Final Batch Loss: 0.0034660520032048225\n",
      "Epoch 3193, Loss: 0.09843255952000618, Final Batch Loss: 0.07775183022022247\n",
      "Epoch 3194, Loss: 0.02183277066797018, Final Batch Loss: 0.015299255959689617\n",
      "Epoch 3195, Loss: 0.04980312939733267, Final Batch Loss: 0.007864768616855145\n",
      "Epoch 3196, Loss: 0.011587352957576513, Final Batch Loss: 0.004512345418334007\n",
      "Epoch 3197, Loss: 0.031238283962011337, Final Batch Loss: 0.005071144551038742\n",
      "Epoch 3198, Loss: 0.021276075392961502, Final Batch Loss: 0.002107687294483185\n",
      "Epoch 3199, Loss: 0.006569030229002237, Final Batch Loss: 0.004405172076076269\n",
      "Epoch 3200, Loss: 0.004756635520607233, Final Batch Loss: 0.0019617683719843626\n",
      "Epoch 3201, Loss: 0.022285164333879948, Final Batch Loss: 0.009034235961735249\n",
      "Epoch 3202, Loss: 0.007959063397720456, Final Batch Loss: 0.002241789596155286\n",
      "Epoch 3203, Loss: 0.004932807758450508, Final Batch Loss: 0.003467224771156907\n",
      "Epoch 3204, Loss: 0.020006290636956692, Final Batch Loss: 0.01584772579371929\n",
      "Epoch 3205, Loss: 0.0073230419075116515, Final Batch Loss: 0.005380870308727026\n",
      "Epoch 3206, Loss: 0.06619034986943007, Final Batch Loss: 0.058782853186130524\n",
      "Epoch 3207, Loss: 0.04917443357408047, Final Batch Loss: 0.012668902054429054\n",
      "Epoch 3208, Loss: 0.009081502445042133, Final Batch Loss: 0.00537079619243741\n",
      "Epoch 3209, Loss: 0.015058323740959167, Final Batch Loss: 0.011155306361615658\n",
      "Epoch 3210, Loss: 0.03700934490188956, Final Batch Loss: 0.0022882609628140926\n",
      "Epoch 3211, Loss: 0.015374782029539347, Final Batch Loss: 0.0035198298282921314\n",
      "Epoch 3212, Loss: 0.030933642061427236, Final Batch Loss: 0.0035874147433787584\n",
      "Epoch 3213, Loss: 0.10586764174513519, Final Batch Loss: 0.10205817222595215\n",
      "Epoch 3214, Loss: 0.016589230159297585, Final Batch Loss: 0.0027232880238443613\n",
      "Epoch 3215, Loss: 0.016397328348830342, Final Batch Loss: 0.012642947025597095\n",
      "Epoch 3216, Loss: 0.011310424888506532, Final Batch Loss: 0.002997203031554818\n",
      "Epoch 3217, Loss: 0.02021344006061554, Final Batch Loss: 0.005753980949521065\n",
      "Epoch 3218, Loss: 0.031095949467271566, Final Batch Loss: 0.024433938786387444\n",
      "Epoch 3219, Loss: 0.01240119943395257, Final Batch Loss: 0.002677318174391985\n",
      "Epoch 3220, Loss: 0.01552895549684763, Final Batch Loss: 0.009688785299658775\n",
      "Epoch 3221, Loss: 0.049599110847339034, Final Batch Loss: 0.04680372402071953\n",
      "Epoch 3222, Loss: 0.01841314323246479, Final Batch Loss: 0.0051816729828715324\n",
      "Epoch 3223, Loss: 0.020178220234811306, Final Batch Loss: 0.016470441594719887\n",
      "Epoch 3224, Loss: 0.005134434439241886, Final Batch Loss: 0.002262469846755266\n",
      "Epoch 3225, Loss: 0.028199708089232445, Final Batch Loss: 0.011720353737473488\n",
      "Epoch 3226, Loss: 0.014184510335326195, Final Batch Loss: 0.004377069883048534\n",
      "Epoch 3227, Loss: 0.021709559485316277, Final Batch Loss: 0.017170589417219162\n",
      "Epoch 3228, Loss: 0.01018789829686284, Final Batch Loss: 0.0030433046631515026\n",
      "Epoch 3229, Loss: 0.006018457235768437, Final Batch Loss: 0.0038820093031972647\n",
      "Epoch 3230, Loss: 0.010680435923859477, Final Batch Loss: 0.007015257142484188\n",
      "Epoch 3231, Loss: 0.022465050220489502, Final Batch Loss: 0.010587241500616074\n",
      "Epoch 3232, Loss: 0.008336034137755632, Final Batch Loss: 0.002231589052826166\n",
      "Epoch 3233, Loss: 0.05176033824682236, Final Batch Loss: 0.043265290558338165\n",
      "Epoch 3234, Loss: 0.016606376506388187, Final Batch Loss: 0.007952415384352207\n",
      "Epoch 3235, Loss: 0.00748853012919426, Final Batch Loss: 0.001630662940442562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3236, Loss: 0.00497186480788514, Final Batch Loss: 0.0009678310598246753\n",
      "Epoch 3237, Loss: 0.016243742313235998, Final Batch Loss: 0.0015151011757552624\n",
      "Epoch 3238, Loss: 0.009657264919951558, Final Batch Loss: 0.00630791625007987\n",
      "Epoch 3239, Loss: 0.050209423527121544, Final Batch Loss: 0.019128398969769478\n",
      "Epoch 3240, Loss: 0.007105532335117459, Final Batch Loss: 0.003921411000192165\n",
      "Epoch 3241, Loss: 0.0248861035797745, Final Batch Loss: 0.0030146578792482615\n",
      "Epoch 3242, Loss: 0.005557885626330972, Final Batch Loss: 0.0017591335345059633\n",
      "Epoch 3243, Loss: 0.0034087912063114345, Final Batch Loss: 0.0025283878203481436\n",
      "Epoch 3244, Loss: 0.010616439394652843, Final Batch Loss: 0.006825692020356655\n",
      "Epoch 3245, Loss: 0.015452860156074166, Final Batch Loss: 0.0024304159451276064\n",
      "Epoch 3246, Loss: 0.0068366373889148235, Final Batch Loss: 0.0049425698816776276\n",
      "Epoch 3247, Loss: 0.026837418787181377, Final Batch Loss: 0.016452422365546227\n",
      "Epoch 3248, Loss: 0.005129165714606643, Final Batch Loss: 0.0012315670028328896\n",
      "Epoch 3249, Loss: 0.004320417705457658, Final Batch Loss: 0.000678756448905915\n",
      "Epoch 3250, Loss: 0.025053430115804076, Final Batch Loss: 0.00322741805575788\n",
      "Epoch 3251, Loss: 0.017436448484659195, Final Batch Loss: 0.012277704663574696\n",
      "Epoch 3252, Loss: 0.0048094617668539286, Final Batch Loss: 0.0030975905247032642\n",
      "Epoch 3253, Loss: 0.0029120291583240032, Final Batch Loss: 0.0007791754323989153\n",
      "Epoch 3254, Loss: 0.0043466887436807156, Final Batch Loss: 0.0013949384447187185\n",
      "Epoch 3255, Loss: 0.02271257061511278, Final Batch Loss: 0.01108884159475565\n",
      "Epoch 3256, Loss: 0.013578413520008326, Final Batch Loss: 0.004170446190983057\n",
      "Epoch 3257, Loss: 0.04415652411989868, Final Batch Loss: 0.041560668498277664\n",
      "Epoch 3258, Loss: 0.004987593973055482, Final Batch Loss: 0.0016455133445560932\n",
      "Epoch 3259, Loss: 0.04094934347085655, Final Batch Loss: 0.03749270737171173\n",
      "Epoch 3260, Loss: 0.006038978579454124, Final Batch Loss: 0.00098011817317456\n",
      "Epoch 3261, Loss: 0.005303216865286231, Final Batch Loss: 0.002566090552136302\n",
      "Epoch 3262, Loss: 0.026820221915841103, Final Batch Loss: 0.015768902376294136\n",
      "Epoch 3263, Loss: 0.00737114273943007, Final Batch Loss: 0.005815637297928333\n",
      "Epoch 3264, Loss: 0.011402973905205727, Final Batch Loss: 0.0016787834465503693\n",
      "Epoch 3265, Loss: 0.009932713583111763, Final Batch Loss: 0.004280594643205404\n",
      "Epoch 3266, Loss: 0.0100888900924474, Final Batch Loss: 0.0038390017580240965\n",
      "Epoch 3267, Loss: 0.03516142722219229, Final Batch Loss: 0.0010373694822192192\n",
      "Epoch 3268, Loss: 0.005886196391656995, Final Batch Loss: 0.004357706289738417\n",
      "Epoch 3269, Loss: 0.017436117166653275, Final Batch Loss: 0.014027991332113743\n",
      "Epoch 3270, Loss: 0.025808098260313272, Final Batch Loss: 0.021938355639576912\n",
      "Epoch 3271, Loss: 0.0264020764734596, Final Batch Loss: 0.023602958768606186\n",
      "Epoch 3272, Loss: 0.004950848640874028, Final Batch Loss: 0.0029254446271806955\n",
      "Epoch 3273, Loss: 0.010258814319968224, Final Batch Loss: 0.0024899477139115334\n",
      "Epoch 3274, Loss: 0.019464966841042042, Final Batch Loss: 0.014261237345635891\n",
      "Epoch 3275, Loss: 0.011617100215516984, Final Batch Loss: 0.0012276567285880446\n",
      "Epoch 3276, Loss: 0.03869978804141283, Final Batch Loss: 0.03377016261219978\n",
      "Epoch 3277, Loss: 0.005626792553812265, Final Batch Loss: 0.0021708293352276087\n",
      "Epoch 3278, Loss: 0.04712433088570833, Final Batch Loss: 0.043154276907444\n",
      "Epoch 3279, Loss: 0.03459129482507706, Final Batch Loss: 0.025411784648895264\n",
      "Epoch 3280, Loss: 0.015115485992282629, Final Batch Loss: 0.006335792597383261\n",
      "Epoch 3281, Loss: 0.11040908843278885, Final Batch Loss: 0.07161244004964828\n",
      "Epoch 3282, Loss: 0.019960132893174887, Final Batch Loss: 0.006570037920027971\n",
      "Epoch 3283, Loss: 0.01827678270637989, Final Batch Loss: 0.013349506072700024\n",
      "Epoch 3284, Loss: 0.0405349750071764, Final Batch Loss: 0.009728282690048218\n",
      "Epoch 3285, Loss: 0.01915979478508234, Final Batch Loss: 0.00948580726981163\n",
      "Epoch 3286, Loss: 0.009491167729720473, Final Batch Loss: 0.0068229204043745995\n",
      "Epoch 3287, Loss: 0.030319955199956894, Final Batch Loss: 0.016370650380849838\n",
      "Epoch 3288, Loss: 0.02088666253257543, Final Batch Loss: 0.0013652826892212033\n",
      "Epoch 3289, Loss: 0.010032456833869219, Final Batch Loss: 0.005603651516139507\n",
      "Epoch 3290, Loss: 0.008532001986168325, Final Batch Loss: 0.0018219210905954242\n",
      "Epoch 3291, Loss: 0.012531699147075415, Final Batch Loss: 0.0037015979178249836\n",
      "Epoch 3292, Loss: 0.007109335623681545, Final Batch Loss: 0.005682323127985001\n",
      "Epoch 3293, Loss: 0.017299872590228915, Final Batch Loss: 0.01587214693427086\n",
      "Epoch 3294, Loss: 0.009005662519484758, Final Batch Loss: 0.00767001137137413\n",
      "Epoch 3295, Loss: 0.004605672787874937, Final Batch Loss: 0.0024677959736436605\n",
      "Epoch 3296, Loss: 0.004062510677613318, Final Batch Loss: 0.003134828759357333\n",
      "Epoch 3297, Loss: 0.021570486016571522, Final Batch Loss: 0.01618688739836216\n",
      "Epoch 3298, Loss: 0.01860359823331237, Final Batch Loss: 0.002384799998253584\n",
      "Epoch 3299, Loss: 0.015233861282467842, Final Batch Loss: 0.004225204698741436\n",
      "Epoch 3300, Loss: 0.013125305180437863, Final Batch Loss: 0.0019265637965872884\n",
      "Epoch 3301, Loss: 0.027820096351206303, Final Batch Loss: 0.004472428001463413\n",
      "Epoch 3302, Loss: 0.004809967591427267, Final Batch Loss: 0.0031152444425970316\n",
      "Epoch 3303, Loss: 0.010999873979017138, Final Batch Loss: 0.0038753089029341936\n",
      "Epoch 3304, Loss: 0.07105040363967419, Final Batch Loss: 0.04610990732908249\n",
      "Epoch 3305, Loss: 0.01567597547546029, Final Batch Loss: 0.0040857563726603985\n",
      "Epoch 3306, Loss: 0.019619695376604795, Final Batch Loss: 0.002152475994080305\n",
      "Epoch 3307, Loss: 0.042828863486647606, Final Batch Loss: 0.03810781612992287\n",
      "Epoch 3308, Loss: 0.03395718592219055, Final Batch Loss: 0.031138654798269272\n",
      "Epoch 3309, Loss: 0.0027816176880151033, Final Batch Loss: 0.0017357042524963617\n",
      "Epoch 3310, Loss: 0.006944852182641625, Final Batch Loss: 0.002531429985538125\n",
      "Epoch 3311, Loss: 0.024483785033226013, Final Batch Loss: 0.004441192373633385\n",
      "Epoch 3312, Loss: 0.06534911110065877, Final Batch Loss: 0.0631105974316597\n",
      "Epoch 3313, Loss: 0.024460166692733765, Final Batch Loss: 0.0057888273149728775\n",
      "Epoch 3314, Loss: 0.011704756179824471, Final Batch Loss: 0.001014963025227189\n",
      "Epoch 3315, Loss: 0.038034725352190435, Final Batch Loss: 0.0012440452119335532\n",
      "Epoch 3316, Loss: 0.00653628318104893, Final Batch Loss: 0.004664026200771332\n",
      "Epoch 3317, Loss: 0.004828208824619651, Final Batch Loss: 0.004210755694657564\n",
      "Epoch 3318, Loss: 0.052485955879092216, Final Batch Loss: 0.03599295765161514\n",
      "Epoch 3319, Loss: 0.014329294906929135, Final Batch Loss: 0.012770041823387146\n",
      "Epoch 3320, Loss: 0.009714824613183737, Final Batch Loss: 0.0066032554022967815\n",
      "Epoch 3321, Loss: 0.016255549853667617, Final Batch Loss: 0.0037043082993477583\n",
      "Epoch 3322, Loss: 0.012675332138314843, Final Batch Loss: 0.010638672858476639\n",
      "Epoch 3323, Loss: 0.01758881181012839, Final Batch Loss: 0.016305293887853622\n",
      "Epoch 3324, Loss: 0.015344391576945782, Final Batch Loss: 0.003363541327416897\n",
      "Epoch 3325, Loss: 0.02158910222351551, Final Batch Loss: 0.002892095595598221\n",
      "Epoch 3326, Loss: 0.0058296427596360445, Final Batch Loss: 0.003608043771237135\n",
      "Epoch 3327, Loss: 0.07676069624722004, Final Batch Loss: 0.05128822848200798\n",
      "Epoch 3328, Loss: 0.005478957900777459, Final Batch Loss: 0.0026139698456972837\n",
      "Epoch 3329, Loss: 0.035115606151521206, Final Batch Loss: 0.011707800440490246\n",
      "Epoch 3330, Loss: 0.06287888064980507, Final Batch Loss: 0.023445401340723038\n",
      "Epoch 3331, Loss: 0.03166421968489885, Final Batch Loss: 0.021521927788853645\n",
      "Epoch 3332, Loss: 0.034789311699569225, Final Batch Loss: 0.019872555509209633\n",
      "Epoch 3333, Loss: 0.13017192110419273, Final Batch Loss: 0.09842066466808319\n",
      "Epoch 3334, Loss: 0.006750003667548299, Final Batch Loss: 0.0022687639575451612\n",
      "Epoch 3335, Loss: 0.09010942094027996, Final Batch Loss: 0.06816092878580093\n",
      "Epoch 3336, Loss: 0.03603390767239034, Final Batch Loss: 0.03226814419031143\n",
      "Epoch 3337, Loss: 0.1962055191397667, Final Batch Loss: 0.0637427344918251\n",
      "Epoch 3338, Loss: 0.06623762892559171, Final Batch Loss: 0.06268007308244705\n",
      "Epoch 3339, Loss: 0.04765794053673744, Final Batch Loss: 0.024394609034061432\n",
      "Epoch 3340, Loss: 0.03284472646191716, Final Batch Loss: 0.0029371497221291065\n",
      "Epoch 3341, Loss: 0.00939839449711144, Final Batch Loss: 0.0032764982897788286\n",
      "Epoch 3342, Loss: 0.02030203677713871, Final Batch Loss: 0.013932955451309681\n",
      "Epoch 3343, Loss: 0.07179648405872285, Final Batch Loss: 0.06825494021177292\n",
      "Epoch 3344, Loss: 0.033147935289889574, Final Batch Loss: 0.02535802125930786\n",
      "Epoch 3345, Loss: 0.017866824753582478, Final Batch Loss: 0.002781802788376808\n",
      "Epoch 3346, Loss: 0.06188669567927718, Final Batch Loss: 0.057701971381902695\n",
      "Epoch 3347, Loss: 0.04180106520652771, Final Batch Loss: 0.016960442066192627\n",
      "Epoch 3348, Loss: 0.11686012893915176, Final Batch Loss: 0.08620493113994598\n",
      "Epoch 3349, Loss: 0.06244858168065548, Final Batch Loss: 0.016793938353657722\n",
      "Epoch 3350, Loss: 0.11403781175613403, Final Batch Loss: 0.03544609993696213\n",
      "Epoch 3351, Loss: 0.07698984071612358, Final Batch Loss: 0.04451308399438858\n",
      "Epoch 3352, Loss: 0.08242584392428398, Final Batch Loss: 0.03871338814496994\n",
      "Epoch 3353, Loss: 0.03811672888696194, Final Batch Loss: 0.026530137285590172\n",
      "Epoch 3354, Loss: 0.11748592928051949, Final Batch Loss: 0.06737760454416275\n",
      "Epoch 3355, Loss: 0.07156741805374622, Final Batch Loss: 0.024144241586327553\n",
      "Epoch 3356, Loss: 0.04691035486757755, Final Batch Loss: 0.017090771347284317\n",
      "Epoch 3357, Loss: 0.12676073238253593, Final Batch Loss: 0.0846790224313736\n",
      "Epoch 3358, Loss: 0.01997172273695469, Final Batch Loss: 0.00459684431552887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3359, Loss: 0.03227331303060055, Final Batch Loss: 0.02031991071999073\n",
      "Epoch 3360, Loss: 0.10895761102437973, Final Batch Loss: 0.06164869666099548\n",
      "Epoch 3361, Loss: 0.049708799459040165, Final Batch Loss: 0.04462486505508423\n",
      "Epoch 3362, Loss: 0.06673520430922508, Final Batch Loss: 0.023091405630111694\n",
      "Epoch 3363, Loss: 0.07653313502669334, Final Batch Loss: 0.043003249913454056\n",
      "Epoch 3364, Loss: 0.05492098815739155, Final Batch Loss: 0.03827444091439247\n",
      "Epoch 3365, Loss: 0.0666604544967413, Final Batch Loss: 0.053928226232528687\n",
      "Epoch 3366, Loss: 0.027923717047087848, Final Batch Loss: 0.001939457724802196\n",
      "Epoch 3367, Loss: 0.010573149658739567, Final Batch Loss: 0.0062303245067596436\n",
      "Epoch 3368, Loss: 0.02956701023504138, Final Batch Loss: 0.025210628286004066\n",
      "Epoch 3369, Loss: 0.012166002299636602, Final Batch Loss: 0.004066892433911562\n",
      "Epoch 3370, Loss: 0.028355466201901436, Final Batch Loss: 0.015206422656774521\n",
      "Epoch 3371, Loss: 0.02193030482158065, Final Batch Loss: 0.004145029466599226\n",
      "Epoch 3372, Loss: 0.02799313748255372, Final Batch Loss: 0.0055219572968780994\n",
      "Epoch 3373, Loss: 0.014585701981559396, Final Batch Loss: 0.0033689283300191164\n",
      "Epoch 3374, Loss: 0.004204723751172423, Final Batch Loss: 0.0021633985452353954\n",
      "Epoch 3375, Loss: 0.015863072592765093, Final Batch Loss: 0.0033325827680528164\n",
      "Epoch 3376, Loss: 0.018888451624661684, Final Batch Loss: 0.015787217766046524\n",
      "Epoch 3377, Loss: 0.015031400136649609, Final Batch Loss: 0.007608469109982252\n",
      "Epoch 3378, Loss: 0.0101220877841115, Final Batch Loss: 0.005918024107813835\n",
      "Epoch 3379, Loss: 0.031830222345888615, Final Batch Loss: 0.014202314428985119\n",
      "Epoch 3380, Loss: 0.008218921953812242, Final Batch Loss: 0.005004406441003084\n",
      "Epoch 3381, Loss: 0.038455617148429155, Final Batch Loss: 0.004649181384593248\n",
      "Epoch 3382, Loss: 0.014066227711737156, Final Batch Loss: 0.0029245279729366302\n",
      "Epoch 3383, Loss: 0.012551448307931423, Final Batch Loss: 0.0014534629881381989\n",
      "Epoch 3384, Loss: 0.03621814027428627, Final Batch Loss: 0.028350021690130234\n",
      "Epoch 3385, Loss: 0.013215857557952404, Final Batch Loss: 0.005817241035401821\n",
      "Epoch 3386, Loss: 0.02045113407075405, Final Batch Loss: 0.008178997784852982\n",
      "Epoch 3387, Loss: 0.02367941802367568, Final Batch Loss: 0.017256783321499825\n",
      "Epoch 3388, Loss: 0.0044199025724083185, Final Batch Loss: 0.0021386118605732918\n",
      "Epoch 3389, Loss: 0.009256127290427685, Final Batch Loss: 0.002908627036958933\n",
      "Epoch 3390, Loss: 0.01704089972190559, Final Batch Loss: 0.01348209846764803\n",
      "Epoch 3391, Loss: 0.02017114032059908, Final Batch Loss: 0.006392939016222954\n",
      "Epoch 3392, Loss: 0.04633124405518174, Final Batch Loss: 0.004412023816257715\n",
      "Epoch 3393, Loss: 0.03474890347570181, Final Batch Loss: 0.02517678029835224\n",
      "Epoch 3394, Loss: 0.03177895280532539, Final Batch Loss: 0.029719239100813866\n",
      "Epoch 3395, Loss: 0.014757787808775902, Final Batch Loss: 0.010984450578689575\n",
      "Epoch 3396, Loss: 0.020062671974301338, Final Batch Loss: 0.0037215687334537506\n",
      "Epoch 3397, Loss: 0.047288347501307726, Final Batch Loss: 0.04128725454211235\n",
      "Epoch 3398, Loss: 0.014863189775496721, Final Batch Loss: 0.009136893786489964\n",
      "Epoch 3399, Loss: 0.00854774285107851, Final Batch Loss: 0.005404206924140453\n",
      "Epoch 3400, Loss: 0.018316361354663968, Final Batch Loss: 0.0023631539661437273\n",
      "Epoch 3401, Loss: 0.027634909376502037, Final Batch Loss: 0.02034992352128029\n",
      "Epoch 3402, Loss: 0.0129897422157228, Final Batch Loss: 0.0053079500794410706\n",
      "Epoch 3403, Loss: 0.04753788094967604, Final Batch Loss: 0.045208640396595\n",
      "Epoch 3404, Loss: 0.03234979463741183, Final Batch Loss: 0.026210976764559746\n",
      "Epoch 3405, Loss: 0.0066666987258940935, Final Batch Loss: 0.0016558372881263494\n",
      "Epoch 3406, Loss: 0.01009319955483079, Final Batch Loss: 0.005853930953890085\n",
      "Epoch 3407, Loss: 0.022070191334933043, Final Batch Loss: 0.004932265263050795\n",
      "Epoch 3408, Loss: 0.021083654835820198, Final Batch Loss: 0.015181588008999825\n",
      "Epoch 3409, Loss: 0.005177677725441754, Final Batch Loss: 0.001789368106983602\n",
      "Epoch 3410, Loss: 0.006688976660370827, Final Batch Loss: 0.0038835653103888035\n",
      "Epoch 3411, Loss: 0.010082408785820007, Final Batch Loss: 0.004937378689646721\n",
      "Epoch 3412, Loss: 0.045968819642439485, Final Batch Loss: 0.0029771255794912577\n",
      "Epoch 3413, Loss: 0.017309891991317272, Final Batch Loss: 0.015189921483397484\n",
      "Epoch 3414, Loss: 0.008024056209251285, Final Batch Loss: 0.0034612773451954126\n",
      "Epoch 3415, Loss: 0.020634060725569725, Final Batch Loss: 0.0036367103457450867\n",
      "Epoch 3416, Loss: 0.013492553494870663, Final Batch Loss: 0.004168538376688957\n",
      "Epoch 3417, Loss: 0.012080562766641378, Final Batch Loss: 0.004838466178625822\n",
      "Epoch 3418, Loss: 0.018206293927505612, Final Batch Loss: 0.0032193309161812067\n",
      "Epoch 3419, Loss: 0.008347965660504997, Final Batch Loss: 0.0018455124227330089\n",
      "Epoch 3420, Loss: 0.01031731441617012, Final Batch Loss: 0.0015066443011164665\n",
      "Epoch 3421, Loss: 0.007299146149307489, Final Batch Loss: 0.00348706915974617\n",
      "Epoch 3422, Loss: 0.016220177756622434, Final Batch Loss: 0.0015272379387170076\n",
      "Epoch 3423, Loss: 0.016962632013019174, Final Batch Loss: 0.000544115377124399\n",
      "Epoch 3424, Loss: 0.017517134314402938, Final Batch Loss: 0.0035910361912101507\n",
      "Epoch 3425, Loss: 0.02286434080451727, Final Batch Loss: 0.004078465513885021\n",
      "Epoch 3426, Loss: 0.0346243754029274, Final Batch Loss: 0.016436543315649033\n",
      "Epoch 3427, Loss: 0.013543695211410522, Final Batch Loss: 0.0022595208138227463\n",
      "Epoch 3428, Loss: 0.01822739141061902, Final Batch Loss: 0.006791448686271906\n",
      "Epoch 3429, Loss: 0.03329976508393884, Final Batch Loss: 0.028798609972000122\n",
      "Epoch 3430, Loss: 0.022630202118307352, Final Batch Loss: 0.0027788938023149967\n",
      "Epoch 3431, Loss: 0.010908159893006086, Final Batch Loss: 0.006892804987728596\n",
      "Epoch 3432, Loss: 0.02652290347032249, Final Batch Loss: 0.003169401315972209\n",
      "Epoch 3433, Loss: 0.03954608552157879, Final Batch Loss: 0.025660715997219086\n",
      "Epoch 3434, Loss: 0.047416944056749344, Final Batch Loss: 0.024418024346232414\n",
      "Epoch 3435, Loss: 0.0052182532381266356, Final Batch Loss: 0.002722286619246006\n",
      "Epoch 3436, Loss: 0.02256641094572842, Final Batch Loss: 0.0028359454590827227\n",
      "Epoch 3437, Loss: 0.012331198202446103, Final Batch Loss: 0.00850970484316349\n",
      "Epoch 3438, Loss: 0.02020314463879913, Final Batch Loss: 0.0014822141965851188\n",
      "Epoch 3439, Loss: 0.05573166813701391, Final Batch Loss: 0.04827360808849335\n",
      "Epoch 3440, Loss: 0.003298984607681632, Final Batch Loss: 0.0015471293590962887\n",
      "Epoch 3441, Loss: 0.04347658529877663, Final Batch Loss: 0.02156558260321617\n",
      "Epoch 3442, Loss: 0.008787752594798803, Final Batch Loss: 0.006398548372089863\n",
      "Epoch 3443, Loss: 0.02555758785456419, Final Batch Loss: 0.01296289637684822\n",
      "Epoch 3444, Loss: 0.01307924510911107, Final Batch Loss: 0.009484215639531612\n",
      "Epoch 3445, Loss: 0.05040857940912247, Final Batch Loss: 0.017946232110261917\n",
      "Epoch 3446, Loss: 0.03376423544250429, Final Batch Loss: 0.03127724304795265\n",
      "Epoch 3447, Loss: 0.03932855976745486, Final Batch Loss: 0.00737063167616725\n",
      "Epoch 3448, Loss: 0.02871984988451004, Final Batch Loss: 0.02421705238521099\n",
      "Epoch 3449, Loss: 0.01983574591577053, Final Batch Loss: 0.010336542502045631\n",
      "Epoch 3450, Loss: 0.028252664022147655, Final Batch Loss: 0.007526890374720097\n",
      "Epoch 3451, Loss: 0.09799886867403984, Final Batch Loss: 0.03709433600306511\n",
      "Epoch 3452, Loss: 0.008316573686897755, Final Batch Loss: 0.003634300082921982\n",
      "Epoch 3453, Loss: 0.032310381066054106, Final Batch Loss: 0.004320088308304548\n",
      "Epoch 3454, Loss: 0.027298856526613235, Final Batch Loss: 0.00807913951575756\n",
      "Epoch 3455, Loss: 0.020143813453614712, Final Batch Loss: 0.004546787589788437\n",
      "Epoch 3456, Loss: 0.01574290730059147, Final Batch Loss: 0.005526168271899223\n",
      "Epoch 3457, Loss: 0.05682940408587456, Final Batch Loss: 0.012928135693073273\n",
      "Epoch 3458, Loss: 0.008490509120747447, Final Batch Loss: 0.0017958518583327532\n",
      "Epoch 3459, Loss: 0.0040949160465970635, Final Batch Loss: 0.001812671427614987\n",
      "Epoch 3460, Loss: 0.021641834639012814, Final Batch Loss: 0.014972852542996407\n",
      "Epoch 3461, Loss: 0.06187852472066879, Final Batch Loss: 0.023852545768022537\n",
      "Epoch 3462, Loss: 0.056586865335702896, Final Batch Loss: 0.015445876866579056\n",
      "Epoch 3463, Loss: 0.0052762862760573626, Final Batch Loss: 0.001835935516282916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3464, Loss: 0.00854831375181675, Final Batch Loss: 0.004965299274772406\n",
      "Epoch 3465, Loss: 0.041200379841029644, Final Batch Loss: 0.03740817680954933\n",
      "Epoch 3466, Loss: 0.0385844511911273, Final Batch Loss: 0.0119435740634799\n",
      "Epoch 3467, Loss: 0.03438308835029602, Final Batch Loss: 0.007290659472346306\n",
      "Epoch 3468, Loss: 0.06740189623087645, Final Batch Loss: 0.05590277165174484\n",
      "Epoch 3469, Loss: 0.03724617604166269, Final Batch Loss: 0.0051687369123101234\n",
      "Epoch 3470, Loss: 0.028436111053451896, Final Batch Loss: 0.0016136167105287313\n",
      "Epoch 3471, Loss: 0.018994536949321628, Final Batch Loss: 0.0027282170485705137\n",
      "Epoch 3472, Loss: 0.013637679629027843, Final Batch Loss: 0.0051971906796097755\n",
      "Epoch 3473, Loss: 0.029691137373447418, Final Batch Loss: 0.0038385391235351562\n",
      "Epoch 3474, Loss: 0.017070507630705833, Final Batch Loss: 0.0034150630235671997\n",
      "Epoch 3475, Loss: 0.01935343723744154, Final Batch Loss: 0.011364616453647614\n",
      "Epoch 3476, Loss: 0.02059970423579216, Final Batch Loss: 0.004625165835022926\n",
      "Epoch 3477, Loss: 0.013257371494546533, Final Batch Loss: 0.0024074160028249025\n",
      "Epoch 3478, Loss: 0.07179832272231579, Final Batch Loss: 0.05595920607447624\n",
      "Epoch 3479, Loss: 0.005902394186705351, Final Batch Loss: 0.002379681682214141\n",
      "Epoch 3480, Loss: 0.009255979675799608, Final Batch Loss: 0.005221228115260601\n",
      "Epoch 3481, Loss: 0.012318533845245838, Final Batch Loss: 0.004511710721999407\n",
      "Epoch 3482, Loss: 0.02201932156458497, Final Batch Loss: 0.005070606712251902\n",
      "Epoch 3483, Loss: 0.01557292533107102, Final Batch Loss: 0.002801035763695836\n",
      "Epoch 3484, Loss: 0.00780448317527771, Final Batch Loss: 0.004084422718733549\n",
      "Epoch 3485, Loss: 0.022799053229391575, Final Batch Loss: 0.0029992377385497093\n",
      "Epoch 3486, Loss: 0.01312070433050394, Final Batch Loss: 0.007171494886279106\n",
      "Epoch 3487, Loss: 0.045119300018996, Final Batch Loss: 0.005869850050657988\n",
      "Epoch 3488, Loss: 0.011179781111422926, Final Batch Loss: 0.0008361614891327918\n",
      "Epoch 3489, Loss: 0.011687865713611245, Final Batch Loss: 0.009242723695933819\n",
      "Epoch 3490, Loss: 0.017232720274478197, Final Batch Loss: 0.013115172274410725\n",
      "Epoch 3491, Loss: 0.012568510137498379, Final Batch Loss: 0.007898160256445408\n",
      "Epoch 3492, Loss: 0.006595405284315348, Final Batch Loss: 0.003382657188922167\n",
      "Epoch 3493, Loss: 0.017677770112641156, Final Batch Loss: 0.0016440442996099591\n",
      "Epoch 3494, Loss: 0.02950876858085394, Final Batch Loss: 0.02095617912709713\n",
      "Epoch 3495, Loss: 0.00868150289170444, Final Batch Loss: 0.005812827032059431\n",
      "Epoch 3496, Loss: 0.01058541052043438, Final Batch Loss: 0.0019968505948781967\n",
      "Epoch 3497, Loss: 0.0032602917635813355, Final Batch Loss: 0.001594597240909934\n",
      "Epoch 3498, Loss: 0.015149165876209736, Final Batch Loss: 0.006343185901641846\n",
      "Epoch 3499, Loss: 0.0066271943505853415, Final Batch Loss: 0.002575784223154187\n",
      "Epoch 3500, Loss: 0.02927473932504654, Final Batch Loss: 0.021832015365362167\n",
      "Epoch 3501, Loss: 0.025121109560132027, Final Batch Loss: 0.007682783529162407\n",
      "Epoch 3502, Loss: 0.031388742849230766, Final Batch Loss: 0.011656492948532104\n",
      "Epoch 3503, Loss: 0.02173053752630949, Final Batch Loss: 0.011715351603925228\n",
      "Epoch 3504, Loss: 0.020089974394068122, Final Batch Loss: 0.0018844769801944494\n",
      "Epoch 3505, Loss: 0.014107691589742899, Final Batch Loss: 0.004489006008952856\n",
      "Epoch 3506, Loss: 0.003586183360312134, Final Batch Loss: 0.002892415737733245\n",
      "Epoch 3507, Loss: 0.01605328358709812, Final Batch Loss: 0.002575695514678955\n",
      "Epoch 3508, Loss: 0.024806595407426357, Final Batch Loss: 0.0053340597078204155\n",
      "Epoch 3509, Loss: 0.019472358631901443, Final Batch Loss: 0.0016847065417096019\n",
      "Epoch 3510, Loss: 0.08996344171464443, Final Batch Loss: 0.0704294815659523\n",
      "Epoch 3511, Loss: 0.026867630425840616, Final Batch Loss: 0.02370874397456646\n",
      "Epoch 3512, Loss: 0.043175897328183055, Final Batch Loss: 0.0029748480301350355\n",
      "Epoch 3513, Loss: 0.017070227535441518, Final Batch Loss: 0.0037641285452991724\n",
      "Epoch 3514, Loss: 0.04121286980807781, Final Batch Loss: 0.02458294853568077\n",
      "Epoch 3515, Loss: 0.049337527714669704, Final Batch Loss: 0.03977812081575394\n",
      "Epoch 3516, Loss: 0.012786552193574607, Final Batch Loss: 0.001711624558083713\n",
      "Epoch 3517, Loss: 0.0071201694663614035, Final Batch Loss: 0.0026743190828710794\n",
      "Epoch 3518, Loss: 0.022211905336007476, Final Batch Loss: 0.018924318253993988\n",
      "Epoch 3519, Loss: 0.006127868313342333, Final Batch Loss: 0.004197521600872278\n",
      "Epoch 3520, Loss: 0.014391034841537476, Final Batch Loss: 0.004940608516335487\n",
      "Epoch 3521, Loss: 0.01966292643919587, Final Batch Loss: 0.01248250249773264\n",
      "Epoch 3522, Loss: 0.009618401294574142, Final Batch Loss: 0.007345559541136026\n",
      "Epoch 3523, Loss: 0.006158722098916769, Final Batch Loss: 0.0020240177400410175\n",
      "Epoch 3524, Loss: 0.020796271041035652, Final Batch Loss: 0.01552667748183012\n",
      "Epoch 3525, Loss: 0.017140078358352184, Final Batch Loss: 0.011631941422820091\n",
      "Epoch 3526, Loss: 0.03842142038047314, Final Batch Loss: 0.023298438638448715\n",
      "Epoch 3527, Loss: 0.005520609149243683, Final Batch Loss: 0.004597237799316645\n",
      "Epoch 3528, Loss: 0.005207843263633549, Final Batch Loss: 0.0008357224287465215\n",
      "Epoch 3529, Loss: 0.020303087309002876, Final Batch Loss: 0.006645503453910351\n",
      "Epoch 3530, Loss: 0.008321811677888036, Final Batch Loss: 0.004486490972340107\n",
      "Epoch 3531, Loss: 0.018435629783198237, Final Batch Loss: 0.015714900568127632\n",
      "Epoch 3532, Loss: 0.006635282014030963, Final Batch Loss: 0.0008413985488004982\n",
      "Epoch 3533, Loss: 0.0032729716040194035, Final Batch Loss: 0.001982638146728277\n",
      "Epoch 3534, Loss: 0.007573792245239019, Final Batch Loss: 0.0009604874067008495\n",
      "Epoch 3535, Loss: 0.003964720119256526, Final Batch Loss: 0.0008660883759148419\n",
      "Epoch 3536, Loss: 0.027496744762174785, Final Batch Loss: 0.0012965676141902804\n",
      "Epoch 3537, Loss: 0.004465434700250626, Final Batch Loss: 0.001350445905700326\n",
      "Epoch 3538, Loss: 0.03000240959227085, Final Batch Loss: 0.0033871959894895554\n",
      "Epoch 3539, Loss: 0.018183660344220698, Final Batch Loss: 0.0011292757699266076\n",
      "Epoch 3540, Loss: 0.017879021354019642, Final Batch Loss: 0.009476696141064167\n",
      "Epoch 3541, Loss: 0.013365855440497398, Final Batch Loss: 0.007646192330867052\n",
      "Epoch 3542, Loss: 0.011303250212222338, Final Batch Loss: 0.004040592350065708\n",
      "Epoch 3543, Loss: 0.0037082229973748326, Final Batch Loss: 0.0005076484521850944\n",
      "Epoch 3544, Loss: 0.021481928881257772, Final Batch Loss: 0.003937469329684973\n",
      "Epoch 3545, Loss: 0.006712006637826562, Final Batch Loss: 0.0043288362212479115\n",
      "Epoch 3546, Loss: 0.015451338607817888, Final Batch Loss: 0.006817581597715616\n",
      "Epoch 3547, Loss: 0.016270307824015617, Final Batch Loss: 0.00805773213505745\n",
      "Epoch 3548, Loss: 0.05318027175962925, Final Batch Loss: 0.0212851669639349\n",
      "Epoch 3549, Loss: 0.07967755012214184, Final Batch Loss: 0.0030740033835172653\n",
      "Epoch 3550, Loss: 0.03467143792659044, Final Batch Loss: 0.027041908353567123\n",
      "Epoch 3551, Loss: 0.004315345082432032, Final Batch Loss: 0.0012616640888154507\n",
      "Epoch 3552, Loss: 0.06508278287947178, Final Batch Loss: 0.055719468742609024\n",
      "Epoch 3553, Loss: 0.009587015956640244, Final Batch Loss: 0.005198161583393812\n",
      "Epoch 3554, Loss: 0.007792567368596792, Final Batch Loss: 0.003424802329391241\n",
      "Epoch 3555, Loss: 0.01465804222971201, Final Batch Loss: 0.0104935672134161\n",
      "Epoch 3556, Loss: 0.023466063663363457, Final Batch Loss: 0.0177605003118515\n",
      "Epoch 3557, Loss: 0.007220635539852083, Final Batch Loss: 0.000980319338850677\n",
      "Epoch 3558, Loss: 0.05033167637884617, Final Batch Loss: 0.025440802797675133\n",
      "Epoch 3559, Loss: 0.007110694365110248, Final Batch Loss: 0.00031916325679048896\n",
      "Epoch 3560, Loss: 0.003699449705891311, Final Batch Loss: 0.0018807973247021437\n",
      "Epoch 3561, Loss: 0.026494215708225965, Final Batch Loss: 0.00759101239964366\n",
      "Epoch 3562, Loss: 0.019462200347334146, Final Batch Loss: 0.007623836863785982\n",
      "Epoch 3563, Loss: 0.011132905259728432, Final Batch Loss: 0.006810371298342943\n",
      "Epoch 3564, Loss: 0.012168839108198881, Final Batch Loss: 0.004929772578179836\n",
      "Epoch 3565, Loss: 0.008379948558285832, Final Batch Loss: 0.005611693952232599\n",
      "Epoch 3566, Loss: 0.020280618919059634, Final Batch Loss: 0.018431086093187332\n",
      "Epoch 3567, Loss: 0.0057352709118276834, Final Batch Loss: 0.0007146538700908422\n",
      "Epoch 3568, Loss: 0.012132855132222176, Final Batch Loss: 0.008044563233852386\n",
      "Epoch 3569, Loss: 0.01929095620289445, Final Batch Loss: 0.0034020603634417057\n",
      "Epoch 3570, Loss: 0.002531186444684863, Final Batch Loss: 0.0005883274134248495\n",
      "Epoch 3571, Loss: 0.021069488720968366, Final Batch Loss: 0.018406955525279045\n",
      "Epoch 3572, Loss: 0.021371218143031, Final Batch Loss: 0.0016219026874750853\n",
      "Epoch 3573, Loss: 0.008383318316191435, Final Batch Loss: 0.006003314163535833\n",
      "Epoch 3574, Loss: 0.010018247179687023, Final Batch Loss: 0.004232416395097971\n",
      "Epoch 3575, Loss: 0.004292037570849061, Final Batch Loss: 0.003163575194776058\n",
      "Epoch 3576, Loss: 0.05284801637753844, Final Batch Loss: 0.047201596200466156\n",
      "Epoch 3577, Loss: 0.030856546480208635, Final Batch Loss: 0.027982177212834358\n",
      "Epoch 3578, Loss: 0.016258482821285725, Final Batch Loss: 0.01025552861392498\n",
      "Epoch 3579, Loss: 0.015473222883883864, Final Batch Loss: 0.0006469018408097327\n",
      "Epoch 3580, Loss: 0.0030541244777850807, Final Batch Loss: 0.0006594196311198175\n",
      "Epoch 3581, Loss: 0.019525833893567324, Final Batch Loss: 0.0053252880461514\n",
      "Epoch 3582, Loss: 0.024037111783400178, Final Batch Loss: 0.02049500308930874\n",
      "Epoch 3583, Loss: 0.043072164291515946, Final Batch Loss: 0.002283811802044511\n",
      "Epoch 3584, Loss: 0.04751192778348923, Final Batch Loss: 0.017389535903930664\n",
      "Epoch 3585, Loss: 0.045080749318003654, Final Batch Loss: 0.025922780856490135\n",
      "Epoch 3586, Loss: 0.05544053763151169, Final Batch Loss: 0.014796394854784012\n",
      "Epoch 3587, Loss: 0.028949737548828125, Final Batch Loss: 0.02008507400751114\n",
      "Epoch 3588, Loss: 0.04375988245010376, Final Batch Loss: 0.03833454102277756\n",
      "Epoch 3589, Loss: 0.040901968255639076, Final Batch Loss: 0.011006319895386696\n",
      "Epoch 3590, Loss: 0.010514537570998073, Final Batch Loss: 0.007865680381655693\n",
      "Epoch 3591, Loss: 0.06873113662004471, Final Batch Loss: 0.048251088708639145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3592, Loss: 0.011742931790649891, Final Batch Loss: 0.006700845435261726\n",
      "Epoch 3593, Loss: 0.03326640836894512, Final Batch Loss: 0.015860872343182564\n",
      "Epoch 3594, Loss: 0.01670217514038086, Final Batch Loss: 0.006683629937469959\n",
      "Epoch 3595, Loss: 0.016421493608504534, Final Batch Loss: 0.005298727657645941\n",
      "Epoch 3596, Loss: 0.03447448322549462, Final Batch Loss: 0.002928475383669138\n",
      "Epoch 3597, Loss: 0.04261258617043495, Final Batch Loss: 0.03264012932777405\n",
      "Epoch 3598, Loss: 0.020071423612535, Final Batch Loss: 0.015599566511809826\n",
      "Epoch 3599, Loss: 0.031683310866355896, Final Batch Loss: 0.01696975715458393\n",
      "Epoch 3600, Loss: 0.032617973163723946, Final Batch Loss: 0.001788971945643425\n",
      "Epoch 3601, Loss: 0.018040045630186796, Final Batch Loss: 0.004105366300791502\n",
      "Epoch 3602, Loss: 0.04808558709919453, Final Batch Loss: 0.02110625058412552\n",
      "Epoch 3603, Loss: 0.012246175669133663, Final Batch Loss: 0.005306089296936989\n",
      "Epoch 3604, Loss: 0.007868212182074785, Final Batch Loss: 0.0037494772113859653\n",
      "Epoch 3605, Loss: 0.024554476607590914, Final Batch Loss: 0.0015113470144569874\n",
      "Epoch 3606, Loss: 0.03244942892342806, Final Batch Loss: 0.02325337752699852\n",
      "Epoch 3607, Loss: 0.08824209868907928, Final Batch Loss: 0.07211610674858093\n",
      "Epoch 3608, Loss: 0.007676106528379023, Final Batch Loss: 0.006700458470731974\n",
      "Epoch 3609, Loss: 0.004484283272176981, Final Batch Loss: 0.0015056503470987082\n",
      "Epoch 3610, Loss: 0.008486802922561765, Final Batch Loss: 0.006215822417289019\n",
      "Epoch 3611, Loss: 0.008566031930968165, Final Batch Loss: 0.0020917218644171953\n",
      "Epoch 3612, Loss: 0.010325844399631023, Final Batch Loss: 0.002144377678632736\n",
      "Epoch 3613, Loss: 0.009363951161503792, Final Batch Loss: 0.0051804520189762115\n",
      "Epoch 3614, Loss: 0.01280818716622889, Final Batch Loss: 0.002768634120002389\n",
      "Epoch 3615, Loss: 0.029092295095324516, Final Batch Loss: 0.00862346775829792\n",
      "Epoch 3616, Loss: 0.023375587537884712, Final Batch Loss: 0.011058359406888485\n",
      "Epoch 3617, Loss: 0.00806054484564811, Final Batch Loss: 0.0016726834001019597\n",
      "Epoch 3618, Loss: 0.016160330735147, Final Batch Loss: 0.00598473846912384\n",
      "Epoch 3619, Loss: 0.025873832404613495, Final Batch Loss: 0.009483112022280693\n",
      "Epoch 3620, Loss: 0.002882727887481451, Final Batch Loss: 0.0016100408975034952\n",
      "Epoch 3621, Loss: 0.016674076789058745, Final Batch Loss: 0.0011682097101584077\n",
      "Epoch 3622, Loss: 0.01435966556891799, Final Batch Loss: 0.001043692696839571\n",
      "Epoch 3623, Loss: 0.00796407531015575, Final Batch Loss: 0.005262883845716715\n",
      "Epoch 3624, Loss: 0.004046884016133845, Final Batch Loss: 0.001901206444017589\n",
      "Epoch 3625, Loss: 0.005304942140355706, Final Batch Loss: 0.00293258810415864\n",
      "Epoch 3626, Loss: 0.016894128173589706, Final Batch Loss: 0.005374978296458721\n",
      "Epoch 3627, Loss: 0.04272365942597389, Final Batch Loss: 0.03518414497375488\n",
      "Epoch 3628, Loss: 0.035091583617031574, Final Batch Loss: 0.025779062882065773\n",
      "Epoch 3629, Loss: 0.018859450006857514, Final Batch Loss: 0.0022174271289259195\n",
      "Epoch 3630, Loss: 0.008166978135704994, Final Batch Loss: 0.0023932987824082375\n",
      "Epoch 3631, Loss: 0.05183841660618782, Final Batch Loss: 0.04667655751109123\n",
      "Epoch 3632, Loss: 0.011946541722863913, Final Batch Loss: 0.004729988053441048\n",
      "Epoch 3633, Loss: 0.027384256944060326, Final Batch Loss: 0.011146334931254387\n",
      "Epoch 3634, Loss: 0.011961722280830145, Final Batch Loss: 0.003707967232912779\n",
      "Epoch 3635, Loss: 0.01404930092394352, Final Batch Loss: 0.00937389861792326\n",
      "Epoch 3636, Loss: 0.11174668837338686, Final Batch Loss: 0.1008489578962326\n",
      "Epoch 3637, Loss: 0.011132982792332768, Final Batch Loss: 0.008750036358833313\n",
      "Epoch 3638, Loss: 0.02301650063600391, Final Batch Loss: 0.0016882059862837195\n",
      "Epoch 3639, Loss: 0.019675455056130886, Final Batch Loss: 0.009899388067424297\n",
      "Epoch 3640, Loss: 0.016015803441405296, Final Batch Loss: 0.00977719109505415\n",
      "Epoch 3641, Loss: 0.014201735146343708, Final Batch Loss: 0.0031401291489601135\n",
      "Epoch 3642, Loss: 0.008219412993639708, Final Batch Loss: 0.002448692452162504\n",
      "Epoch 3643, Loss: 0.018364728428423405, Final Batch Loss: 0.014354182407259941\n",
      "Epoch 3644, Loss: 0.00934300315566361, Final Batch Loss: 0.007112480234354734\n",
      "Epoch 3645, Loss: 0.013622247613966465, Final Batch Loss: 0.01211399957537651\n",
      "Epoch 3646, Loss: 0.01585927838459611, Final Batch Loss: 0.006497849244624376\n",
      "Epoch 3647, Loss: 0.013676698785275221, Final Batch Loss: 0.006988099776208401\n",
      "Epoch 3648, Loss: 0.004772719577886164, Final Batch Loss: 0.0014376869658008218\n",
      "Epoch 3649, Loss: 0.009067024569958448, Final Batch Loss: 0.0025730840861797333\n",
      "Epoch 3650, Loss: 0.01130613824352622, Final Batch Loss: 0.004812745843082666\n",
      "Epoch 3651, Loss: 0.010689669288694859, Final Batch Loss: 0.0066661830060184\n",
      "Epoch 3652, Loss: 0.030948968953453004, Final Batch Loss: 0.030381152406334877\n",
      "Epoch 3653, Loss: 0.01753337448462844, Final Batch Loss: 0.005692444276064634\n",
      "Epoch 3654, Loss: 0.02866219519637525, Final Batch Loss: 0.0038390604313462973\n",
      "Epoch 3655, Loss: 0.016068004304543138, Final Batch Loss: 0.0027847897727042437\n",
      "Epoch 3656, Loss: 0.004735609516501427, Final Batch Loss: 0.00270988536067307\n",
      "Epoch 3657, Loss: 0.006895932601764798, Final Batch Loss: 0.0047269342467188835\n",
      "Epoch 3658, Loss: 0.04080404620617628, Final Batch Loss: 0.03397217020392418\n",
      "Epoch 3659, Loss: 0.04399302741512656, Final Batch Loss: 0.03671449422836304\n",
      "Epoch 3660, Loss: 0.008890920085832477, Final Batch Loss: 0.006380158010870218\n",
      "Epoch 3661, Loss: 0.031940827146172523, Final Batch Loss: 0.016824785619974136\n",
      "Epoch 3662, Loss: 0.016427885042503476, Final Batch Loss: 0.014736009761691093\n",
      "Epoch 3663, Loss: 0.006374241434969008, Final Batch Loss: 0.0011562478030100465\n",
      "Epoch 3664, Loss: 0.003781219245865941, Final Batch Loss: 0.003240469377487898\n",
      "Epoch 3665, Loss: 0.011119268368929625, Final Batch Loss: 0.00905456393957138\n",
      "Epoch 3666, Loss: 0.01428962592035532, Final Batch Loss: 0.009027439169585705\n",
      "Epoch 3667, Loss: 0.013342670165002346, Final Batch Loss: 0.0022647716104984283\n",
      "Epoch 3668, Loss: 0.010955061530694366, Final Batch Loss: 0.008244103752076626\n",
      "Epoch 3669, Loss: 0.006300184060819447, Final Batch Loss: 0.001709680655039847\n",
      "Epoch 3670, Loss: 0.0948583073914051, Final Batch Loss: 0.08830112963914871\n",
      "Epoch 3671, Loss: 0.031044545583426952, Final Batch Loss: 0.023506054654717445\n",
      "Epoch 3672, Loss: 0.014244477380998433, Final Batch Loss: 0.0018821220146492124\n",
      "Epoch 3673, Loss: 0.014633256709203124, Final Batch Loss: 0.01224206481128931\n",
      "Epoch 3674, Loss: 0.02230202406644821, Final Batch Loss: 0.00601019524037838\n",
      "Epoch 3675, Loss: 0.025502751814201474, Final Batch Loss: 0.02170952595770359\n",
      "Epoch 3676, Loss: 0.023640309926122427, Final Batch Loss: 0.0047704610042274\n",
      "Epoch 3677, Loss: 0.02405920485034585, Final Batch Loss: 0.021618353202939034\n",
      "Epoch 3678, Loss: 0.00507873494643718, Final Batch Loss: 0.001813795999623835\n",
      "Epoch 3679, Loss: 0.0060670822858810425, Final Batch Loss: 0.002045862842351198\n",
      "Epoch 3680, Loss: 0.07625268772244453, Final Batch Loss: 0.03568641096353531\n",
      "Epoch 3681, Loss: 0.014691873919218779, Final Batch Loss: 0.007134831510484219\n",
      "Epoch 3682, Loss: 0.006198712275363505, Final Batch Loss: 0.0016374728875234723\n",
      "Epoch 3683, Loss: 0.07803309336304665, Final Batch Loss: 0.057215865701436996\n",
      "Epoch 3684, Loss: 0.008680371334776282, Final Batch Loss: 0.004901984240859747\n",
      "Epoch 3685, Loss: 0.045978398993611336, Final Batch Loss: 0.034555912017822266\n",
      "Epoch 3686, Loss: 0.039669119752943516, Final Batch Loss: 0.03495960682630539\n",
      "Epoch 3687, Loss: 0.021484597586095333, Final Batch Loss: 0.009903662838041782\n",
      "Epoch 3688, Loss: 0.010731125832535326, Final Batch Loss: 0.0012745779240503907\n",
      "Epoch 3689, Loss: 0.12930695340037346, Final Batch Loss: 0.076592817902565\n",
      "Epoch 3690, Loss: 0.033634673221968114, Final Batch Loss: 0.001819989993236959\n",
      "Epoch 3691, Loss: 0.010817844653502107, Final Batch Loss: 0.002699402393773198\n",
      "Epoch 3692, Loss: 0.06461665406823158, Final Batch Loss: 0.02157306671142578\n",
      "Epoch 3693, Loss: 0.07695744652301073, Final Batch Loss: 0.07077332586050034\n",
      "Epoch 3694, Loss: 0.013306951615959406, Final Batch Loss: 0.00113209942355752\n",
      "Epoch 3695, Loss: 0.05197580438107252, Final Batch Loss: 0.042885612696409225\n",
      "Epoch 3696, Loss: 0.02490707580000162, Final Batch Loss: 0.017091726884245872\n",
      "Epoch 3697, Loss: 0.04397202841937542, Final Batch Loss: 0.03367075324058533\n",
      "Epoch 3698, Loss: 0.08158405311405659, Final Batch Loss: 0.024675389751791954\n",
      "Epoch 3699, Loss: 0.02443827409297228, Final Batch Loss: 0.01811523362994194\n",
      "Epoch 3700, Loss: 0.034940747544169426, Final Batch Loss: 0.011346565559506416\n",
      "Epoch 3701, Loss: 0.027545411605387926, Final Batch Loss: 0.023267148062586784\n",
      "Epoch 3702, Loss: 0.01208073040470481, Final Batch Loss: 0.008518281392753124\n",
      "Epoch 3703, Loss: 0.04790761461481452, Final Batch Loss: 0.0415278896689415\n",
      "Epoch 3704, Loss: 0.025130084832198918, Final Batch Loss: 0.0008748351829126477\n",
      "Epoch 3705, Loss: 0.009218083694577217, Final Batch Loss: 0.004212033469229937\n",
      "Epoch 3706, Loss: 0.041155476588755846, Final Batch Loss: 0.03886666148900986\n",
      "Epoch 3707, Loss: 0.020922750933095813, Final Batch Loss: 0.0020144737791270018\n",
      "Epoch 3708, Loss: 0.01903247833251953, Final Batch Loss: 0.00577804259955883\n",
      "Epoch 3709, Loss: 0.04472998529672623, Final Batch Loss: 0.02304433286190033\n",
      "Epoch 3710, Loss: 0.005467317532747984, Final Batch Loss: 0.002721918746829033\n",
      "Epoch 3711, Loss: 0.10789606906473637, Final Batch Loss: 0.09223785996437073\n",
      "Epoch 3712, Loss: 0.014994631055742502, Final Batch Loss: 0.0054696607403457165\n",
      "Epoch 3713, Loss: 0.04200297221541405, Final Batch Loss: 0.019727978855371475\n",
      "Epoch 3714, Loss: 0.034505982883274555, Final Batch Loss: 0.010988614521920681\n",
      "Epoch 3715, Loss: 0.13364493008702993, Final Batch Loss: 0.1269439309835434\n",
      "Epoch 3716, Loss: 0.05496780201792717, Final Batch Loss: 0.022873852401971817\n",
      "Epoch 3717, Loss: 0.06360764242708683, Final Batch Loss: 0.054888561367988586\n",
      "Epoch 3718, Loss: 0.03522925544530153, Final Batch Loss: 0.02214537002146244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3719, Loss: 0.01845715893432498, Final Batch Loss: 0.0064555383287370205\n",
      "Epoch 3720, Loss: 0.029478424228727818, Final Batch Loss: 0.008530915714800358\n",
      "Epoch 3721, Loss: 0.06147238612174988, Final Batch Loss: 0.017846811562776566\n",
      "Epoch 3722, Loss: 0.03949179779738188, Final Batch Loss: 0.025534844025969505\n",
      "Epoch 3723, Loss: 0.06476416252553463, Final Batch Loss: 0.05073262378573418\n",
      "Epoch 3724, Loss: 0.02741800807416439, Final Batch Loss: 0.012893550097942352\n",
      "Epoch 3725, Loss: 0.030805944465100765, Final Batch Loss: 0.015518002212047577\n",
      "Epoch 3726, Loss: 0.019375605508685112, Final Batch Loss: 0.010083161294460297\n",
      "Epoch 3727, Loss: 0.008952673990279436, Final Batch Loss: 0.0019737505353987217\n",
      "Epoch 3728, Loss: 0.03238788712769747, Final Batch Loss: 0.00924441497772932\n",
      "Epoch 3729, Loss: 0.018642306327819824, Final Batch Loss: 0.0017950665205717087\n",
      "Epoch 3730, Loss: 0.052308764308691025, Final Batch Loss: 0.0362316370010376\n",
      "Epoch 3731, Loss: 0.02529094833880663, Final Batch Loss: 0.00850351806730032\n",
      "Epoch 3732, Loss: 0.04625883139669895, Final Batch Loss: 0.04049595817923546\n",
      "Epoch 3733, Loss: 0.12318480014801025, Final Batch Loss: 0.06247108057141304\n",
      "Epoch 3734, Loss: 0.06563487462699413, Final Batch Loss: 0.016844501718878746\n",
      "Epoch 3735, Loss: 0.00817817635834217, Final Batch Loss: 0.002400733530521393\n",
      "Epoch 3736, Loss: 0.008746903389692307, Final Batch Loss: 0.005536526441574097\n",
      "Epoch 3737, Loss: 0.05227456288412213, Final Batch Loss: 0.0021422659046947956\n",
      "Epoch 3738, Loss: 0.06956808106042445, Final Batch Loss: 0.0013755692634731531\n",
      "Epoch 3739, Loss: 0.01284877024590969, Final Batch Loss: 0.00544271245598793\n",
      "Epoch 3740, Loss: 0.01667173346504569, Final Batch Loss: 0.011593026109039783\n",
      "Epoch 3741, Loss: 0.020020379684865475, Final Batch Loss: 0.0042826151475310326\n",
      "Epoch 3742, Loss: 0.07886128779500723, Final Batch Loss: 0.00494957622140646\n",
      "Epoch 3743, Loss: 0.011679141782224178, Final Batch Loss: 0.007549545262008905\n",
      "Epoch 3744, Loss: 0.03189011476933956, Final Batch Loss: 0.005250252783298492\n",
      "Epoch 3745, Loss: 0.048528824001550674, Final Batch Loss: 0.03435700014233589\n",
      "Epoch 3746, Loss: 0.016922518145292997, Final Batch Loss: 0.004049171227961779\n",
      "Epoch 3747, Loss: 0.02447621524333954, Final Batch Loss: 0.015290517359972\n",
      "Epoch 3748, Loss: 0.008390253875404596, Final Batch Loss: 0.0026778187602758408\n",
      "Epoch 3749, Loss: 0.005997315980494022, Final Batch Loss: 0.0020571500062942505\n",
      "Epoch 3750, Loss: 0.024524568580091, Final Batch Loss: 0.010234491899609566\n",
      "Epoch 3751, Loss: 0.011613206006586552, Final Batch Loss: 0.005795217119157314\n",
      "Epoch 3752, Loss: 0.02031836938112974, Final Batch Loss: 0.0081627881154418\n",
      "Epoch 3753, Loss: 0.007537727244198322, Final Batch Loss: 0.004155297297984362\n",
      "Epoch 3754, Loss: 0.009457903914153576, Final Batch Loss: 0.0038824379444122314\n",
      "Epoch 3755, Loss: 0.008367423666641116, Final Batch Loss: 0.002862029941752553\n",
      "Epoch 3756, Loss: 0.017565482761710882, Final Batch Loss: 0.012004030868411064\n",
      "Epoch 3757, Loss: 0.03842174494639039, Final Batch Loss: 0.03138352185487747\n",
      "Epoch 3758, Loss: 0.01359829364810139, Final Batch Loss: 0.011661866679787636\n",
      "Epoch 3759, Loss: 0.012694507138803601, Final Batch Loss: 0.003206313820555806\n",
      "Epoch 3760, Loss: 0.054087521973997355, Final Batch Loss: 0.04831625893712044\n",
      "Epoch 3761, Loss: 0.021633245050907135, Final Batch Loss: 0.012795254588127136\n",
      "Epoch 3762, Loss: 0.006360635627061129, Final Batch Loss: 0.002386422362178564\n",
      "Epoch 3763, Loss: 0.016372165642678738, Final Batch Loss: 0.00963537022471428\n",
      "Epoch 3764, Loss: 0.028352290391921997, Final Batch Loss: 0.009431129321455956\n",
      "Epoch 3765, Loss: 0.03404185175895691, Final Batch Loss: 0.018922798335552216\n",
      "Epoch 3766, Loss: 0.043902721256017685, Final Batch Loss: 0.013822628185153008\n",
      "Epoch 3767, Loss: 0.06560861319303513, Final Batch Loss: 0.010173726826906204\n",
      "Epoch 3768, Loss: 0.026801991276443005, Final Batch Loss: 0.010651354677975178\n",
      "Epoch 3769, Loss: 0.0546732060611248, Final Batch Loss: 0.04665267467498779\n",
      "Epoch 3770, Loss: 0.01688631367869675, Final Batch Loss: 0.014982008375227451\n",
      "Epoch 3771, Loss: 0.018665071111172438, Final Batch Loss: 0.014115439727902412\n",
      "Epoch 3772, Loss: 0.024779343511909246, Final Batch Loss: 0.019328204914927483\n",
      "Epoch 3773, Loss: 0.033940067514777184, Final Batch Loss: 0.008898312225937843\n",
      "Epoch 3774, Loss: 0.010803431272506714, Final Batch Loss: 0.005835567135363817\n",
      "Epoch 3775, Loss: 0.004308812320232391, Final Batch Loss: 0.002976125106215477\n",
      "Epoch 3776, Loss: 0.02772076055407524, Final Batch Loss: 0.017653679475188255\n",
      "Epoch 3777, Loss: 0.010121935745701194, Final Batch Loss: 0.002796780550852418\n",
      "Epoch 3778, Loss: 0.013972084503620863, Final Batch Loss: 0.011159919202327728\n",
      "Epoch 3779, Loss: 0.029230246786028147, Final Batch Loss: 0.00232906686142087\n",
      "Epoch 3780, Loss: 0.01796249346807599, Final Batch Loss: 0.005729284603148699\n",
      "Epoch 3781, Loss: 0.05949206184595823, Final Batch Loss: 0.049783408641815186\n",
      "Epoch 3782, Loss: 0.04511906951665878, Final Batch Loss: 0.03730721399188042\n",
      "Epoch 3783, Loss: 0.030657796189188957, Final Batch Loss: 0.012986961752176285\n",
      "Epoch 3784, Loss: 0.018820935860276222, Final Batch Loss: 0.00641260202974081\n",
      "Epoch 3785, Loss: 0.01191003480926156, Final Batch Loss: 0.008102287538349628\n",
      "Epoch 3786, Loss: 0.0022613892797380686, Final Batch Loss: 0.0012218361953273416\n",
      "Epoch 3787, Loss: 0.011369897983968258, Final Batch Loss: 0.0013997005298733711\n",
      "Epoch 3788, Loss: 0.028365309350192547, Final Batch Loss: 0.015171433798968792\n",
      "Epoch 3789, Loss: 0.005965964985080063, Final Batch Loss: 0.004309592302888632\n",
      "Epoch 3790, Loss: 0.04903516173362732, Final Batch Loss: 0.012984782457351685\n",
      "Epoch 3791, Loss: 0.012047698255628347, Final Batch Loss: 0.008459431119263172\n",
      "Epoch 3792, Loss: 0.03147617541253567, Final Batch Loss: 0.01163877360522747\n",
      "Epoch 3793, Loss: 0.0069378933403640985, Final Batch Loss: 0.002759957918897271\n",
      "Epoch 3794, Loss: 0.007232156582176685, Final Batch Loss: 0.002660028636455536\n",
      "Epoch 3795, Loss: 0.06589399930089712, Final Batch Loss: 0.004210035316646099\n",
      "Epoch 3796, Loss: 0.006334693403914571, Final Batch Loss: 0.002365680178627372\n",
      "Epoch 3797, Loss: 0.04023907380178571, Final Batch Loss: 0.03506435081362724\n",
      "Epoch 3798, Loss: 0.018198691308498383, Final Batch Loss: 0.012231473810970783\n",
      "Epoch 3799, Loss: 0.018416587729007006, Final Batch Loss: 0.004703613463789225\n",
      "Epoch 3800, Loss: 0.05541444011032581, Final Batch Loss: 0.028392624109983444\n",
      "Epoch 3801, Loss: 0.021954245865345, Final Batch Loss: 0.015632009133696556\n",
      "Epoch 3802, Loss: 0.07091926317662, Final Batch Loss: 0.06104186549782753\n",
      "Epoch 3803, Loss: 0.051482684910297394, Final Batch Loss: 0.011399131268262863\n",
      "Epoch 3804, Loss: 0.018799352925270796, Final Batch Loss: 0.003983741160482168\n",
      "Epoch 3805, Loss: 0.018410699442029, Final Batch Loss: 0.014855339191854\n",
      "Epoch 3806, Loss: 0.01966386055573821, Final Batch Loss: 0.014651481993496418\n",
      "Epoch 3807, Loss: 0.06928628450259566, Final Batch Loss: 0.06404104828834534\n",
      "Epoch 3808, Loss: 0.02109913807362318, Final Batch Loss: 0.00918630976229906\n",
      "Epoch 3809, Loss: 0.06444895267486572, Final Batch Loss: 0.046860821545124054\n",
      "Epoch 3810, Loss: 0.007737261243164539, Final Batch Loss: 0.0026360834017395973\n",
      "Epoch 3811, Loss: 0.012747925706207752, Final Batch Loss: 0.0026259003207087517\n",
      "Epoch 3812, Loss: 0.012819263152778149, Final Batch Loss: 0.005725988652557135\n",
      "Epoch 3813, Loss: 0.012514732778072357, Final Batch Loss: 0.006272756028920412\n",
      "Epoch 3814, Loss: 0.07267986284568906, Final Batch Loss: 0.0021162782795727253\n",
      "Epoch 3815, Loss: 0.039119540713727474, Final Batch Loss: 0.03202015534043312\n",
      "Epoch 3816, Loss: 0.010012980550527573, Final Batch Loss: 0.0022057117894291878\n",
      "Epoch 3817, Loss: 0.058254556730389595, Final Batch Loss: 0.041987642645835876\n",
      "Epoch 3818, Loss: 0.04130670498125255, Final Batch Loss: 0.003235050244256854\n",
      "Epoch 3819, Loss: 0.017422708217054605, Final Batch Loss: 0.003099047113209963\n",
      "Epoch 3820, Loss: 0.011195545084774494, Final Batch Loss: 0.004895927384495735\n",
      "Epoch 3821, Loss: 0.03885889891535044, Final Batch Loss: 0.02587028592824936\n",
      "Epoch 3822, Loss: 0.005175526952371001, Final Batch Loss: 0.002748887287452817\n",
      "Epoch 3823, Loss: 0.06161518208682537, Final Batch Loss: 0.011546710506081581\n",
      "Epoch 3824, Loss: 0.06641930341720581, Final Batch Loss: 0.03429416939616203\n",
      "Epoch 3825, Loss: 0.02367148594930768, Final Batch Loss: 0.016305958852171898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3826, Loss: 0.006673693191260099, Final Batch Loss: 0.0046015274710953236\n",
      "Epoch 3827, Loss: 0.021887792507186532, Final Batch Loss: 0.018857700750231743\n",
      "Epoch 3828, Loss: 0.03628313820809126, Final Batch Loss: 0.02743370831012726\n",
      "Epoch 3829, Loss: 0.027111941017210484, Final Batch Loss: 0.013816011138260365\n",
      "Epoch 3830, Loss: 0.015540521126240492, Final Batch Loss: 0.00949034746736288\n",
      "Epoch 3831, Loss: 0.02686174912378192, Final Batch Loss: 0.02170182392001152\n",
      "Epoch 3832, Loss: 0.03667327202856541, Final Batch Loss: 0.02389497123658657\n",
      "Epoch 3833, Loss: 0.009453601203858852, Final Batch Loss: 0.0044373078271746635\n",
      "Epoch 3834, Loss: 0.032318936195224524, Final Batch Loss: 0.0032072062604129314\n",
      "Epoch 3835, Loss: 0.017602241598069668, Final Batch Loss: 0.013431692495942116\n",
      "Epoch 3836, Loss: 0.012359043816104531, Final Batch Loss: 0.0097251171246171\n",
      "Epoch 3837, Loss: 0.01067602401599288, Final Batch Loss: 0.004340361338108778\n",
      "Epoch 3838, Loss: 0.01468935189768672, Final Batch Loss: 0.006236557383090258\n",
      "Epoch 3839, Loss: 0.006329585565254092, Final Batch Loss: 0.0008896088693290949\n",
      "Epoch 3840, Loss: 0.008277934743091464, Final Batch Loss: 0.005214189179241657\n",
      "Epoch 3841, Loss: 0.004147095489315689, Final Batch Loss: 0.0022169542498886585\n",
      "Epoch 3842, Loss: 0.009613184491172433, Final Batch Loss: 0.002941122045740485\n",
      "Epoch 3843, Loss: 0.026255431585013866, Final Batch Loss: 0.011837177909910679\n",
      "Epoch 3844, Loss: 0.012593354796990752, Final Batch Loss: 0.0006917424034327269\n",
      "Epoch 3845, Loss: 0.02663096832111478, Final Batch Loss: 0.005706977564841509\n",
      "Epoch 3846, Loss: 0.00856015901081264, Final Batch Loss: 0.005440418608486652\n",
      "Epoch 3847, Loss: 0.02030443213880062, Final Batch Loss: 0.011836526915431023\n",
      "Epoch 3848, Loss: 0.005209285067394376, Final Batch Loss: 0.0023822160437703133\n",
      "Epoch 3849, Loss: 0.19091293029487133, Final Batch Loss: 0.17463544011116028\n",
      "Epoch 3850, Loss: 0.07249783910810947, Final Batch Loss: 0.01815578155219555\n",
      "Epoch 3851, Loss: 0.006461586803197861, Final Batch Loss: 0.004910603165626526\n",
      "Epoch 3852, Loss: 0.03646411094814539, Final Batch Loss: 0.010397727601230145\n",
      "Epoch 3853, Loss: 0.015606173779815435, Final Batch Loss: 0.003997307736426592\n",
      "Epoch 3854, Loss: 0.060042550787329674, Final Batch Loss: 0.019175512716174126\n",
      "Epoch 3855, Loss: 0.050186049193143845, Final Batch Loss: 0.0055430009961128235\n",
      "Epoch 3856, Loss: 0.04633155185729265, Final Batch Loss: 0.03404148295521736\n",
      "Epoch 3857, Loss: 0.03861243277788162, Final Batch Loss: 0.02035735733807087\n",
      "Epoch 3858, Loss: 0.02668629866093397, Final Batch Loss: 0.02049250155687332\n",
      "Epoch 3859, Loss: 0.007469490170478821, Final Batch Loss: 0.002087643835693598\n",
      "Epoch 3860, Loss: 0.022074367618188262, Final Batch Loss: 0.020048080012202263\n",
      "Epoch 3861, Loss: 0.05094062304124236, Final Batch Loss: 0.044074561446905136\n",
      "Epoch 3862, Loss: 0.03899980615824461, Final Batch Loss: 0.025789067149162292\n",
      "Epoch 3863, Loss: 0.06499866582453251, Final Batch Loss: 0.06164964661002159\n",
      "Epoch 3864, Loss: 0.03322290722280741, Final Batch Loss: 0.004063847474753857\n",
      "Epoch 3865, Loss: 0.03233667928725481, Final Batch Loss: 0.01133344043046236\n",
      "Epoch 3866, Loss: 0.0342554310336709, Final Batch Loss: 0.01871551014482975\n",
      "Epoch 3867, Loss: 0.006492826389148831, Final Batch Loss: 0.0042689042165875435\n",
      "Epoch 3868, Loss: 0.05834119953215122, Final Batch Loss: 0.030460132285952568\n",
      "Epoch 3869, Loss: 0.038948611356318, Final Batch Loss: 0.03399132192134857\n",
      "Epoch 3870, Loss: 0.06117221061140299, Final Batch Loss: 0.007920720614492893\n",
      "Epoch 3871, Loss: 0.01658775471150875, Final Batch Loss: 0.0058137644082307816\n",
      "Epoch 3872, Loss: 0.0169291733764112, Final Batch Loss: 0.0036680311895906925\n",
      "Epoch 3873, Loss: 0.01721305400133133, Final Batch Loss: 0.008102071471512318\n",
      "Epoch 3874, Loss: 0.023236487992107868, Final Batch Loss: 0.013027224689722061\n",
      "Epoch 3875, Loss: 0.011505528236739337, Final Batch Loss: 0.0016619822708889842\n",
      "Epoch 3876, Loss: 0.015934039372950792, Final Batch Loss: 0.00529742194339633\n",
      "Epoch 3877, Loss: 0.05676843412220478, Final Batch Loss: 0.0042376164346933365\n",
      "Epoch 3878, Loss: 0.014214228373020887, Final Batch Loss: 0.008526094257831573\n",
      "Epoch 3879, Loss: 0.01378280739299953, Final Batch Loss: 0.0025264795403927565\n",
      "Epoch 3880, Loss: 0.0086956478189677, Final Batch Loss: 0.002528706332668662\n",
      "Epoch 3881, Loss: 0.005350302555598319, Final Batch Loss: 0.0018949260702356696\n",
      "Epoch 3882, Loss: 0.021996094845235348, Final Batch Loss: 0.014274572022259235\n",
      "Epoch 3883, Loss: 0.007913820096291602, Final Batch Loss: 0.006119424942880869\n",
      "Epoch 3884, Loss: 0.008258708287030458, Final Batch Loss: 0.003782260697335005\n",
      "Epoch 3885, Loss: 0.003310726140625775, Final Batch Loss: 0.001194089069031179\n",
      "Epoch 3886, Loss: 0.028810583520680666, Final Batch Loss: 0.021020062267780304\n",
      "Epoch 3887, Loss: 0.03862422425299883, Final Batch Loss: 0.028895320370793343\n",
      "Epoch 3888, Loss: 0.008156244293786585, Final Batch Loss: 0.0019003032939508557\n",
      "Epoch 3889, Loss: 0.017440526513382792, Final Batch Loss: 0.014307091012597084\n",
      "Epoch 3890, Loss: 0.03808585740625858, Final Batch Loss: 0.019837962463498116\n",
      "Epoch 3891, Loss: 0.06533659994602203, Final Batch Loss: 0.023474954068660736\n",
      "Epoch 3892, Loss: 0.06170689349528402, Final Batch Loss: 0.05990953743457794\n",
      "Epoch 3893, Loss: 0.02429470157949254, Final Batch Loss: 0.0007821015897206962\n",
      "Epoch 3894, Loss: 0.02001123782247305, Final Batch Loss: 0.007979780435562134\n",
      "Epoch 3895, Loss: 0.01450410345569253, Final Batch Loss: 0.007126988843083382\n",
      "Epoch 3896, Loss: 0.04117145808413625, Final Batch Loss: 0.03621630370616913\n",
      "Epoch 3897, Loss: 0.013106034835800529, Final Batch Loss: 0.002966466126963496\n",
      "Epoch 3898, Loss: 0.03944530338048935, Final Batch Loss: 0.009103290736675262\n",
      "Epoch 3899, Loss: 0.015780092449858785, Final Batch Loss: 0.0036323044914752245\n",
      "Epoch 3900, Loss: 0.0035103282425552607, Final Batch Loss: 0.0019343314925208688\n",
      "Epoch 3901, Loss: 0.02454299433156848, Final Batch Loss: 0.004097617696970701\n",
      "Epoch 3902, Loss: 0.008407858666032553, Final Batch Loss: 0.0044840252958238125\n",
      "Epoch 3903, Loss: 0.011015229392796755, Final Batch Loss: 0.005806456785649061\n",
      "Epoch 3904, Loss: 0.01106976717710495, Final Batch Loss: 0.007195257116109133\n",
      "Epoch 3905, Loss: 0.008037000661715865, Final Batch Loss: 0.006137358956038952\n",
      "Epoch 3906, Loss: 0.021144164726138115, Final Batch Loss: 0.0089639313519001\n",
      "Epoch 3907, Loss: 0.01992590120062232, Final Batch Loss: 0.007314735557883978\n",
      "Epoch 3908, Loss: 0.007568346802145243, Final Batch Loss: 0.004426806699484587\n",
      "Epoch 3909, Loss: 0.003123698988929391, Final Batch Loss: 0.0014025918208062649\n",
      "Epoch 3910, Loss: 0.03328073304146528, Final Batch Loss: 0.020953599363565445\n",
      "Epoch 3911, Loss: 0.005173130193725228, Final Batch Loss: 0.003528977045789361\n",
      "Epoch 3912, Loss: 0.0037453272379934788, Final Batch Loss: 0.002205156022682786\n",
      "Epoch 3913, Loss: 0.00435504864435643, Final Batch Loss: 0.0028006122447550297\n",
      "Epoch 3914, Loss: 0.017881672363728285, Final Batch Loss: 0.005782948341220617\n",
      "Epoch 3915, Loss: 0.01560124265961349, Final Batch Loss: 0.002709038322791457\n",
      "Epoch 3916, Loss: 0.029630941338837147, Final Batch Loss: 0.010155289433896542\n",
      "Epoch 3917, Loss: 0.006899142637848854, Final Batch Loss: 0.0018376605585217476\n",
      "Epoch 3918, Loss: 0.016187386121600866, Final Batch Loss: 0.01423373818397522\n",
      "Epoch 3919, Loss: 0.023312999866902828, Final Batch Loss: 0.005528203211724758\n",
      "Epoch 3920, Loss: 0.017948291264474392, Final Batch Loss: 0.013231574557721615\n",
      "Epoch 3921, Loss: 0.0430447943508625, Final Batch Loss: 0.029291730374097824\n",
      "Epoch 3922, Loss: 0.005861389683559537, Final Batch Loss: 0.003325387369841337\n",
      "Epoch 3923, Loss: 0.004772595129907131, Final Batch Loss: 0.0022827482316643\n",
      "Epoch 3924, Loss: 0.005672643193975091, Final Batch Loss: 0.002915180753916502\n",
      "Epoch 3925, Loss: 0.06395288277417421, Final Batch Loss: 0.05219351500272751\n",
      "Epoch 3926, Loss: 0.022362384479492903, Final Batch Loss: 0.0024213544093072414\n",
      "Epoch 3927, Loss: 0.028010990004986525, Final Batch Loss: 0.02257109433412552\n",
      "Epoch 3928, Loss: 0.006353545002639294, Final Batch Loss: 0.0019847159273922443\n",
      "Epoch 3929, Loss: 0.01610922161489725, Final Batch Loss: 0.011929020285606384\n",
      "Epoch 3930, Loss: 0.014039789326488972, Final Batch Loss: 0.009864690713584423\n",
      "Epoch 3931, Loss: 0.021843875059857965, Final Batch Loss: 0.002276974031701684\n",
      "Epoch 3932, Loss: 0.006418808945454657, Final Batch Loss: 0.0013893601717427373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3933, Loss: 0.015332440380007029, Final Batch Loss: 0.0054469178430736065\n",
      "Epoch 3934, Loss: 0.008570208912715316, Final Batch Loss: 0.00580236129462719\n",
      "Epoch 3935, Loss: 0.004016342689283192, Final Batch Loss: 0.0017736525041982532\n",
      "Epoch 3936, Loss: 0.03019819315522909, Final Batch Loss: 0.017888400703668594\n",
      "Epoch 3937, Loss: 0.012378356768749654, Final Batch Loss: 0.0014499485259875655\n",
      "Epoch 3938, Loss: 0.034751662984490395, Final Batch Loss: 0.029063522815704346\n",
      "Epoch 3939, Loss: 0.07782908296212554, Final Batch Loss: 0.07367555052042007\n",
      "Epoch 3940, Loss: 0.015815842431038618, Final Batch Loss: 0.003615065012127161\n",
      "Epoch 3941, Loss: 0.009948671329766512, Final Batch Loss: 0.004665466491132975\n",
      "Epoch 3942, Loss: 0.028224602807313204, Final Batch Loss: 0.023676922544836998\n",
      "Epoch 3943, Loss: 0.07363981194794178, Final Batch Loss: 0.061005786061286926\n",
      "Epoch 3944, Loss: 0.03930692397989333, Final Batch Loss: 0.0013407173100858927\n",
      "Epoch 3945, Loss: 0.03985023032873869, Final Batch Loss: 0.012018687091767788\n",
      "Epoch 3946, Loss: 0.006562234018929303, Final Batch Loss: 0.0006530858809128404\n",
      "Epoch 3947, Loss: 0.018794473260641098, Final Batch Loss: 0.009598950855433941\n",
      "Epoch 3948, Loss: 0.04927508719265461, Final Batch Loss: 0.03126956894993782\n",
      "Epoch 3949, Loss: 0.04301044903695583, Final Batch Loss: 0.03764987736940384\n",
      "Epoch 3950, Loss: 0.019129089079797268, Final Batch Loss: 0.007699653506278992\n",
      "Epoch 3951, Loss: 0.011636593379080296, Final Batch Loss: 0.005027266684919596\n",
      "Epoch 3952, Loss: 0.09641550108790398, Final Batch Loss: 0.08306100964546204\n",
      "Epoch 3953, Loss: 0.05427099950611591, Final Batch Loss: 0.02850627899169922\n",
      "Epoch 3954, Loss: 0.01158945239149034, Final Batch Loss: 0.009285780601203442\n",
      "Epoch 3955, Loss: 0.0765522439032793, Final Batch Loss: 0.05260065197944641\n",
      "Epoch 3956, Loss: 0.045798445120453835, Final Batch Loss: 0.02545851469039917\n",
      "Epoch 3957, Loss: 0.058139050379395485, Final Batch Loss: 0.03480049967765808\n",
      "Epoch 3958, Loss: 0.09846390411257744, Final Batch Loss: 0.03942467272281647\n",
      "Epoch 3959, Loss: 0.04894382460042834, Final Batch Loss: 0.04251076653599739\n",
      "Epoch 3960, Loss: 0.10299279540777206, Final Batch Loss: 0.03807096183300018\n",
      "Epoch 3961, Loss: 0.022134221624583006, Final Batch Loss: 0.018400605767965317\n",
      "Epoch 3962, Loss: 0.034108336083590984, Final Batch Loss: 0.025040768086910248\n",
      "Epoch 3963, Loss: 0.09056282788515091, Final Batch Loss: 0.0786433145403862\n",
      "Epoch 3964, Loss: 0.017405882943421602, Final Batch Loss: 0.003586385864764452\n",
      "Epoch 3965, Loss: 0.03747927211225033, Final Batch Loss: 0.014634383842349052\n",
      "Epoch 3966, Loss: 0.03215904254466295, Final Batch Loss: 0.008049714379012585\n",
      "Epoch 3967, Loss: 0.04731647437438369, Final Batch Loss: 0.04274106025695801\n",
      "Epoch 3968, Loss: 0.05465436913073063, Final Batch Loss: 0.032816994935274124\n",
      "Epoch 3969, Loss: 0.061917105689644814, Final Batch Loss: 0.04282908886671066\n",
      "Epoch 3970, Loss: 0.03064404521137476, Final Batch Loss: 0.004416518844664097\n",
      "Epoch 3971, Loss: 0.03388690669089556, Final Batch Loss: 0.019260060042142868\n",
      "Epoch 3972, Loss: 0.027811573818325996, Final Batch Loss: 0.01264031883329153\n",
      "Epoch 3973, Loss: 0.013976186513900757, Final Batch Loss: 0.005618847906589508\n",
      "Epoch 3974, Loss: 0.016597627196460962, Final Batch Loss: 0.010227846913039684\n",
      "Epoch 3975, Loss: 0.013492285972461104, Final Batch Loss: 0.01129730325192213\n",
      "Epoch 3976, Loss: 0.026889737229794264, Final Batch Loss: 0.02033558301627636\n",
      "Epoch 3977, Loss: 0.06026935391128063, Final Batch Loss: 0.025595543906092644\n",
      "Epoch 3978, Loss: 0.06193365901708603, Final Batch Loss: 0.035169411450624466\n",
      "Epoch 3979, Loss: 0.012418024707585573, Final Batch Loss: 0.007107969839125872\n",
      "Epoch 3980, Loss: 0.03472525905817747, Final Batch Loss: 0.012199214659631252\n",
      "Epoch 3981, Loss: 0.008982803206890821, Final Batch Loss: 0.005038105882704258\n",
      "Epoch 3982, Loss: 0.015739583875983953, Final Batch Loss: 0.004524648655205965\n",
      "Epoch 3983, Loss: 0.009732764214277267, Final Batch Loss: 0.005057395435869694\n",
      "Epoch 3984, Loss: 0.026637068949639797, Final Batch Loss: 0.014171217568218708\n",
      "Epoch 3985, Loss: 0.020065007265657187, Final Batch Loss: 0.012385645881295204\n",
      "Epoch 3986, Loss: 0.013492105761542916, Final Batch Loss: 0.002363333711400628\n",
      "Epoch 3987, Loss: 0.02762837102636695, Final Batch Loss: 0.020946618169546127\n",
      "Epoch 3988, Loss: 0.015954019967466593, Final Batch Loss: 0.004140238743275404\n",
      "Epoch 3989, Loss: 0.024958827067166567, Final Batch Loss: 0.006937532220035791\n",
      "Epoch 3990, Loss: 0.038339510560035706, Final Batch Loss: 0.019682681187987328\n",
      "Epoch 3991, Loss: 0.012137152720242739, Final Batch Loss: 0.005209472496062517\n",
      "Epoch 3992, Loss: 0.03860056586563587, Final Batch Loss: 0.01005568727850914\n",
      "Epoch 3993, Loss: 0.008286102442070842, Final Batch Loss: 0.004956334829330444\n",
      "Epoch 3994, Loss: 0.0267667043954134, Final Batch Loss: 0.004353636875748634\n",
      "Epoch 3995, Loss: 0.021610814379528165, Final Batch Loss: 0.0029148117173463106\n",
      "Epoch 3996, Loss: 0.04723308514803648, Final Batch Loss: 0.03777513653039932\n",
      "Epoch 3997, Loss: 0.01414853218011558, Final Batch Loss: 0.010316410101950169\n",
      "Epoch 3998, Loss: 0.027651648269966245, Final Batch Loss: 0.0019571047741919756\n",
      "Epoch 3999, Loss: 0.01165550947189331, Final Batch Loss: 0.006529339589178562\n",
      "Epoch 4000, Loss: 0.015136911999434233, Final Batch Loss: 0.0024633235298097134\n",
      "Epoch 4001, Loss: 0.03099918970838189, Final Batch Loss: 0.025148313492536545\n",
      "Epoch 4002, Loss: 0.06760796811431646, Final Batch Loss: 0.06434129923582077\n",
      "Epoch 4003, Loss: 0.034568235743790865, Final Batch Loss: 0.0053461589850485325\n",
      "Epoch 4004, Loss: 0.023179504089057446, Final Batch Loss: 0.015399374067783356\n",
      "Epoch 4005, Loss: 0.023388415575027466, Final Batch Loss: 0.01705547794699669\n",
      "Epoch 4006, Loss: 0.033346583135426044, Final Batch Loss: 0.005422334186732769\n",
      "Epoch 4007, Loss: 0.02764727547764778, Final Batch Loss: 0.008085101842880249\n",
      "Epoch 4008, Loss: 0.029788421001285315, Final Batch Loss: 0.0037087718956172466\n",
      "Epoch 4009, Loss: 0.017487042816355824, Final Batch Loss: 0.0035331344697624445\n",
      "Epoch 4010, Loss: 0.03157847095280886, Final Batch Loss: 0.020177336409687996\n",
      "Epoch 4011, Loss: 0.0147253661416471, Final Batch Loss: 0.008156964555382729\n",
      "Epoch 4012, Loss: 0.03806186048313975, Final Batch Loss: 0.032337628304958344\n",
      "Epoch 4013, Loss: 0.02419834118336439, Final Batch Loss: 0.015327698551118374\n",
      "Epoch 4014, Loss: 0.034214104525744915, Final Batch Loss: 0.010166921652853489\n",
      "Epoch 4015, Loss: 0.03769669868052006, Final Batch Loss: 0.019609801471233368\n",
      "Epoch 4016, Loss: 0.009359627729281783, Final Batch Loss: 0.003742248984053731\n",
      "Epoch 4017, Loss: 0.042263681534677744, Final Batch Loss: 0.005214931908994913\n",
      "Epoch 4018, Loss: 0.019073901930823922, Final Batch Loss: 0.003615292953327298\n",
      "Epoch 4019, Loss: 0.09787609428167343, Final Batch Loss: 0.054783135652542114\n",
      "Epoch 4020, Loss: 0.02105611131992191, Final Batch Loss: 0.00086871103849262\n",
      "Epoch 4021, Loss: 0.014924189075827599, Final Batch Loss: 0.0077341762371361256\n",
      "Epoch 4022, Loss: 0.00816224969457835, Final Batch Loss: 0.0015582939377054572\n",
      "Epoch 4023, Loss: 0.018396622501313686, Final Batch Loss: 0.015757843852043152\n",
      "Epoch 4024, Loss: 0.014249409548938274, Final Batch Loss: 0.007046095095574856\n",
      "Epoch 4025, Loss: 0.009359650313854218, Final Batch Loss: 0.003721189219504595\n",
      "Epoch 4026, Loss: 0.021067859372124076, Final Batch Loss: 0.0028558222111314535\n",
      "Epoch 4027, Loss: 0.04248046688735485, Final Batch Loss: 0.023534981533885002\n",
      "Epoch 4028, Loss: 0.01695393433328718, Final Batch Loss: 0.00190558226313442\n",
      "Epoch 4029, Loss: 0.02643386321142316, Final Batch Loss: 0.004019052255898714\n",
      "Epoch 4030, Loss: 0.0048084898153319955, Final Batch Loss: 0.0019137485651299357\n",
      "Epoch 4031, Loss: 0.013177799293771386, Final Batch Loss: 0.009886128827929497\n",
      "Epoch 4032, Loss: 0.009756926214322448, Final Batch Loss: 0.002533239545300603\n",
      "Epoch 4033, Loss: 0.006321980385109782, Final Batch Loss: 0.0026473412290215492\n",
      "Epoch 4034, Loss: 0.01662618317641318, Final Batch Loss: 0.0026227787602692842\n",
      "Epoch 4035, Loss: 0.026213026605546474, Final Batch Loss: 0.008139572106301785\n",
      "Epoch 4036, Loss: 0.04377857281360775, Final Batch Loss: 0.04242003709077835\n",
      "Epoch 4037, Loss: 0.01719668321311474, Final Batch Loss: 0.005710415542125702\n",
      "Epoch 4038, Loss: 0.009969741106033325, Final Batch Loss: 0.004660287406295538\n",
      "Epoch 4039, Loss: 0.05474972911179066, Final Batch Loss: 0.03437785804271698\n",
      "Epoch 4040, Loss: 0.011369308922439814, Final Batch Loss: 0.0064025684259831905\n",
      "Epoch 4041, Loss: 0.05236541945487261, Final Batch Loss: 0.00745305884629488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4042, Loss: 0.010606514755636454, Final Batch Loss: 0.006436755880713463\n",
      "Epoch 4043, Loss: 0.010503138415515423, Final Batch Loss: 0.004484633915126324\n",
      "Epoch 4044, Loss: 0.04326580837368965, Final Batch Loss: 0.026448087766766548\n",
      "Epoch 4045, Loss: 0.014459448866546154, Final Batch Loss: 0.0015798872336745262\n",
      "Epoch 4046, Loss: 0.015198786510154605, Final Batch Loss: 0.002672725124284625\n",
      "Epoch 4047, Loss: 0.012703413609415293, Final Batch Loss: 0.003497492056339979\n",
      "Epoch 4048, Loss: 0.011091073043644428, Final Batch Loss: 0.0056413570418953896\n",
      "Epoch 4049, Loss: 0.005988226737827063, Final Batch Loss: 0.004213729873299599\n",
      "Epoch 4050, Loss: 0.004114774870686233, Final Batch Loss: 0.0016223577549681067\n",
      "Epoch 4051, Loss: 0.01250859908759594, Final Batch Loss: 0.005321066360920668\n",
      "Epoch 4052, Loss: 0.012122733984142542, Final Batch Loss: 0.007890000008046627\n",
      "Epoch 4053, Loss: 0.012004290008917451, Final Batch Loss: 0.0034307187888771296\n",
      "Epoch 4054, Loss: 0.009722711285576224, Final Batch Loss: 0.0008023025002330542\n",
      "Epoch 4055, Loss: 0.01327230385504663, Final Batch Loss: 0.0025083969812840223\n",
      "Epoch 4056, Loss: 0.007102898089215159, Final Batch Loss: 0.004545435309410095\n",
      "Epoch 4057, Loss: 0.10275426227599382, Final Batch Loss: 0.09042678028345108\n",
      "Epoch 4058, Loss: 0.007286040345206857, Final Batch Loss: 0.004053681157529354\n",
      "Epoch 4059, Loss: 0.016816614661365747, Final Batch Loss: 0.0047243633307516575\n",
      "Epoch 4060, Loss: 0.02850325033068657, Final Batch Loss: 0.010850004851818085\n",
      "Epoch 4061, Loss: 0.010322927962988615, Final Batch Loss: 0.004622201435267925\n",
      "Epoch 4062, Loss: 0.0815780945122242, Final Batch Loss: 0.024774011224508286\n",
      "Epoch 4063, Loss: 0.03665035357698798, Final Batch Loss: 0.004304730799049139\n",
      "Epoch 4064, Loss: 0.03508696798235178, Final Batch Loss: 0.012372304685413837\n",
      "Epoch 4065, Loss: 0.034541680477559566, Final Batch Loss: 0.00930649321526289\n",
      "Epoch 4066, Loss: 0.15680840611457825, Final Batch Loss: 0.12875322997570038\n",
      "Epoch 4067, Loss: 0.023916713427752256, Final Batch Loss: 0.01752416603267193\n",
      "Epoch 4068, Loss: 0.09693738631904125, Final Batch Loss: 0.016238344833254814\n",
      "Epoch 4069, Loss: 0.04178907675668597, Final Batch Loss: 0.003924268763512373\n",
      "Epoch 4070, Loss: 0.07572087878361344, Final Batch Loss: 0.007103922311216593\n",
      "Epoch 4071, Loss: 0.04778806306421757, Final Batch Loss: 0.02430819347500801\n",
      "Epoch 4072, Loss: 0.03223144821822643, Final Batch Loss: 0.0030602775514125824\n",
      "Epoch 4073, Loss: 0.013934673741459846, Final Batch Loss: 0.008129347115755081\n",
      "Epoch 4074, Loss: 0.036611054092645645, Final Batch Loss: 0.030872395262122154\n",
      "Epoch 4075, Loss: 0.0288092028349638, Final Batch Loss: 0.009995661675930023\n",
      "Epoch 4076, Loss: 0.022732156328856945, Final Batch Loss: 0.013170076534152031\n",
      "Epoch 4077, Loss: 0.03067426197230816, Final Batch Loss: 0.012865681201219559\n",
      "Epoch 4078, Loss: 0.022010660264641047, Final Batch Loss: 0.018142450600862503\n",
      "Epoch 4079, Loss: 0.04939829185605049, Final Batch Loss: 0.03525402769446373\n",
      "Epoch 4080, Loss: 0.016817745752632618, Final Batch Loss: 0.011633090674877167\n",
      "Epoch 4081, Loss: 0.010408658534288406, Final Batch Loss: 0.002426830120384693\n",
      "Epoch 4082, Loss: 0.03917212877422571, Final Batch Loss: 0.028220849111676216\n",
      "Epoch 4083, Loss: 0.00888055027462542, Final Batch Loss: 0.0036116635892540216\n",
      "Epoch 4084, Loss: 0.025097238831222057, Final Batch Loss: 0.012619941495358944\n",
      "Epoch 4085, Loss: 0.03624744899570942, Final Batch Loss: 0.012110020965337753\n",
      "Epoch 4086, Loss: 0.06188316270709038, Final Batch Loss: 0.04150257259607315\n",
      "Epoch 4087, Loss: 0.09370224550366402, Final Batch Loss: 0.07344603538513184\n",
      "Epoch 4088, Loss: 0.016473467461764812, Final Batch Loss: 0.0036158468574285507\n",
      "Epoch 4089, Loss: 0.1105116899125278, Final Batch Loss: 0.10444889962673187\n",
      "Epoch 4090, Loss: 0.023336971178650856, Final Batch Loss: 0.01684018224477768\n",
      "Epoch 4091, Loss: 0.009418062400072813, Final Batch Loss: 0.004370365757495165\n",
      "Epoch 4092, Loss: 0.031572370789945126, Final Batch Loss: 0.019746500998735428\n",
      "Epoch 4093, Loss: 0.06839107722043991, Final Batch Loss: 0.04051680862903595\n",
      "Epoch 4094, Loss: 0.015892883762717247, Final Batch Loss: 0.007801327854394913\n",
      "Epoch 4095, Loss: 0.023621761705726385, Final Batch Loss: 0.00675623444840312\n",
      "Epoch 4096, Loss: 0.04253480164334178, Final Batch Loss: 0.03852881118655205\n",
      "Epoch 4097, Loss: 0.013595649506896734, Final Batch Loss: 0.0067838821560144424\n",
      "Epoch 4098, Loss: 0.017486732453107834, Final Batch Loss: 0.009872449561953545\n",
      "Epoch 4099, Loss: 0.005920534487813711, Final Batch Loss: 0.002302787732332945\n",
      "Epoch 4100, Loss: 0.01577496761456132, Final Batch Loss: 0.010750385001301765\n",
      "Epoch 4101, Loss: 0.03805307485163212, Final Batch Loss: 0.0013936962932348251\n",
      "Epoch 4102, Loss: 0.012354035279713571, Final Batch Loss: 0.0009792366763576865\n",
      "Epoch 4103, Loss: 0.01909874053671956, Final Batch Loss: 0.011595849879086018\n",
      "Epoch 4104, Loss: 0.03128410875797272, Final Batch Loss: 0.026623839512467384\n",
      "Epoch 4105, Loss: 0.012789931613951921, Final Batch Loss: 0.005595081951469183\n",
      "Epoch 4106, Loss: 0.024264175444841385, Final Batch Loss: 0.022446276620030403\n",
      "Epoch 4107, Loss: 0.019512854050844908, Final Batch Loss: 0.01477830857038498\n",
      "Epoch 4108, Loss: 0.007844079285860062, Final Batch Loss: 0.0016199415549635887\n",
      "Epoch 4109, Loss: 0.016410067910328507, Final Batch Loss: 0.003187412628903985\n",
      "Epoch 4110, Loss: 0.055914231576025486, Final Batch Loss: 0.0025433944538235664\n",
      "Epoch 4111, Loss: 0.011738134548068047, Final Batch Loss: 0.006888264324516058\n",
      "Epoch 4112, Loss: 0.020128188654780388, Final Batch Loss: 0.015923049300909042\n",
      "Epoch 4113, Loss: 0.007263978943228722, Final Batch Loss: 0.0041475254110991955\n",
      "Epoch 4114, Loss: 0.019508723635226488, Final Batch Loss: 0.006323855835944414\n",
      "Epoch 4115, Loss: 0.01609776448458433, Final Batch Loss: 0.011500736698508263\n",
      "Epoch 4116, Loss: 0.009964582975953817, Final Batch Loss: 0.0019362508319318295\n",
      "Epoch 4117, Loss: 0.013496122788637877, Final Batch Loss: 0.00930606760084629\n",
      "Epoch 4118, Loss: 0.020296172704547644, Final Batch Loss: 0.005044389050453901\n",
      "Epoch 4119, Loss: 0.023052808828651905, Final Batch Loss: 0.014196682721376419\n",
      "Epoch 4120, Loss: 0.019119417294859886, Final Batch Loss: 0.011469317600131035\n",
      "Epoch 4121, Loss: 0.02011572616174817, Final Batch Loss: 0.016920873895287514\n",
      "Epoch 4122, Loss: 0.006665727589279413, Final Batch Loss: 0.004254132974892855\n",
      "Epoch 4123, Loss: 0.0059629641473293304, Final Batch Loss: 0.003223699750378728\n",
      "Epoch 4124, Loss: 0.008833915460854769, Final Batch Loss: 0.004155283328145742\n",
      "Epoch 4125, Loss: 0.00459983223117888, Final Batch Loss: 0.0021561181638389826\n",
      "Epoch 4126, Loss: 0.0062844647327438, Final Batch Loss: 0.0019357517594471574\n",
      "Epoch 4127, Loss: 0.021259925328195095, Final Batch Loss: 0.01527956873178482\n",
      "Epoch 4128, Loss: 0.005182486027479172, Final Batch Loss: 0.0032903370447456837\n",
      "Epoch 4129, Loss: 0.005661835661157966, Final Batch Loss: 0.0013343493919819593\n",
      "Epoch 4130, Loss: 0.011093805078417063, Final Batch Loss: 0.002969196531921625\n",
      "Epoch 4131, Loss: 0.007705589756369591, Final Batch Loss: 0.0024375845678150654\n",
      "Epoch 4132, Loss: 0.007951438368763775, Final Batch Loss: 0.0009677083580754697\n",
      "Epoch 4133, Loss: 0.008911887416616082, Final Batch Loss: 0.0014044300187379122\n",
      "Epoch 4134, Loss: 0.024898001924157143, Final Batch Loss: 0.012758954428136349\n",
      "Epoch 4135, Loss: 0.01387485204031691, Final Batch Loss: 0.000921030470635742\n",
      "Epoch 4136, Loss: 0.009409745107404888, Final Batch Loss: 0.007638244424015284\n",
      "Epoch 4137, Loss: 0.020044933073222637, Final Batch Loss: 0.010792280547320843\n",
      "Epoch 4138, Loss: 0.016246251296252012, Final Batch Loss: 0.009496071375906467\n",
      "Epoch 4139, Loss: 0.0818703577388078, Final Batch Loss: 0.07992877066135406\n",
      "Epoch 4140, Loss: 0.018265417777001858, Final Batch Loss: 0.007053579203784466\n",
      "Epoch 4141, Loss: 0.023930177092552185, Final Batch Loss: 0.014575736597180367\n",
      "Epoch 4142, Loss: 0.009271139395423234, Final Batch Loss: 0.008105005137622356\n",
      "Epoch 4143, Loss: 0.0065627803560346365, Final Batch Loss: 0.0013983247336000204\n",
      "Epoch 4144, Loss: 0.007425328250974417, Final Batch Loss: 0.0025433097034692764\n",
      "Epoch 4145, Loss: 0.04269389994442463, Final Batch Loss: 0.006434476003050804\n",
      "Epoch 4146, Loss: 0.03311736590694636, Final Batch Loss: 0.03137011453509331\n",
      "Epoch 4147, Loss: 0.020609166007488966, Final Batch Loss: 0.015063691884279251\n",
      "Epoch 4148, Loss: 0.007631097570993006, Final Batch Loss: 0.0008896152721717954\n",
      "Epoch 4149, Loss: 0.022351853782311082, Final Batch Loss: 0.0026266819331794977\n",
      "Epoch 4150, Loss: 0.007835598080419004, Final Batch Loss: 0.0017712981207296252\n",
      "Epoch 4151, Loss: 0.01929416856728494, Final Batch Loss: 0.0032240895088762045\n",
      "Epoch 4152, Loss: 0.014968894887715578, Final Batch Loss: 0.004024585243314505\n",
      "Epoch 4153, Loss: 0.0156399377156049, Final Batch Loss: 0.013257046230137348\n",
      "Epoch 4154, Loss: 0.025131340604275465, Final Batch Loss: 0.003562105353921652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4155, Loss: 0.030721463728696108, Final Batch Loss: 0.023641437292099\n",
      "Epoch 4156, Loss: 0.027084033004939556, Final Batch Loss: 0.001849253661930561\n",
      "Epoch 4157, Loss: 0.002867699251510203, Final Batch Loss: 0.0011660994496196508\n",
      "Epoch 4158, Loss: 0.01148882694542408, Final Batch Loss: 0.0048174867406487465\n",
      "Epoch 4159, Loss: 0.06934008002281189, Final Batch Loss: 0.048420924693346024\n",
      "Epoch 4160, Loss: 0.035019632894545794, Final Batch Loss: 0.0071828835643827915\n",
      "Epoch 4161, Loss: 0.010618177708238363, Final Batch Loss: 0.004145505838096142\n",
      "Epoch 4162, Loss: 0.024777330458164215, Final Batch Loss: 0.008314080536365509\n",
      "Epoch 4163, Loss: 0.027696363627910614, Final Batch Loss: 0.010975545272231102\n",
      "Epoch 4164, Loss: 0.044463906437158585, Final Batch Loss: 0.02609812282025814\n",
      "Epoch 4165, Loss: 0.009998646564781666, Final Batch Loss: 0.004340712446719408\n",
      "Epoch 4166, Loss: 0.07167519442737103, Final Batch Loss: 0.027639323845505714\n",
      "Epoch 4167, Loss: 0.016130382660776377, Final Batch Loss: 0.006572060752660036\n",
      "Epoch 4168, Loss: 0.09506088774651289, Final Batch Loss: 0.08729570358991623\n",
      "Epoch 4169, Loss: 0.03331119101494551, Final Batch Loss: 0.02081422135233879\n",
      "Epoch 4170, Loss: 0.06397052574902773, Final Batch Loss: 0.04924905300140381\n",
      "Epoch 4171, Loss: 0.030198668129742146, Final Batch Loss: 0.005100752227008343\n",
      "Epoch 4172, Loss: 0.01792310015298426, Final Batch Loss: 0.003435566322878003\n",
      "Epoch 4173, Loss: 0.020057127345353365, Final Batch Loss: 0.006736201699823141\n",
      "Epoch 4174, Loss: 0.0802520364522934, Final Batch Loss: 0.052313707768917084\n",
      "Epoch 4175, Loss: 0.01274456875398755, Final Batch Loss: 0.0061811418272554874\n",
      "Epoch 4176, Loss: 0.01925637573003769, Final Batch Loss: 0.005675389431416988\n",
      "Epoch 4177, Loss: 0.018443153239786625, Final Batch Loss: 0.015324261970818043\n",
      "Epoch 4178, Loss: 0.07672717422246933, Final Batch Loss: 0.03079816699028015\n",
      "Epoch 4179, Loss: 0.02064899541437626, Final Batch Loss: 0.011085942387580872\n",
      "Epoch 4180, Loss: 0.03870096057653427, Final Batch Loss: 0.013471867889165878\n",
      "Epoch 4181, Loss: 0.030337633565068245, Final Batch Loss: 0.017229655757546425\n",
      "Epoch 4182, Loss: 0.018031494691967964, Final Batch Loss: 0.00876107532531023\n",
      "Epoch 4183, Loss: 0.015252323355525732, Final Batch Loss: 0.009221355430781841\n",
      "Epoch 4184, Loss: 0.011312393471598625, Final Batch Loss: 0.006233634427189827\n",
      "Epoch 4185, Loss: 0.007393874228000641, Final Batch Loss: 0.0036341585218906403\n",
      "Epoch 4186, Loss: 0.07823366019874811, Final Batch Loss: 0.07016926258802414\n",
      "Epoch 4187, Loss: 0.025925442576408386, Final Batch Loss: 0.009703299030661583\n",
      "Epoch 4188, Loss: 0.025706599932163954, Final Batch Loss: 0.02008759416639805\n",
      "Epoch 4189, Loss: 0.006142881000414491, Final Batch Loss: 0.0011329373810440302\n",
      "Epoch 4190, Loss: 0.04292283393442631, Final Batch Loss: 0.033933088183403015\n",
      "Epoch 4191, Loss: 0.025944348890334368, Final Batch Loss: 0.021039484068751335\n",
      "Epoch 4192, Loss: 0.00839659501798451, Final Batch Loss: 0.00629974901676178\n",
      "Epoch 4193, Loss: 0.011999861802905798, Final Batch Loss: 0.0025365245528519154\n",
      "Epoch 4194, Loss: 0.024251660448499024, Final Batch Loss: 0.022705839946866035\n",
      "Epoch 4195, Loss: 0.024223158601671457, Final Batch Loss: 0.019079409539699554\n",
      "Epoch 4196, Loss: 0.0058603554498404264, Final Batch Loss: 0.0027540926821529865\n",
      "Epoch 4197, Loss: 0.017521820031106472, Final Batch Loss: 0.005713623948395252\n",
      "Epoch 4198, Loss: 0.05113261006772518, Final Batch Loss: 0.03986084461212158\n",
      "Epoch 4199, Loss: 0.003820882353466004, Final Batch Loss: 0.0008763016085140407\n",
      "Epoch 4200, Loss: 0.014970325632020831, Final Batch Loss: 0.011167364194989204\n",
      "Epoch 4201, Loss: 0.034884946420788765, Final Batch Loss: 0.029117658734321594\n",
      "Epoch 4202, Loss: 0.01803406747058034, Final Batch Loss: 0.0064407228492200375\n",
      "Epoch 4203, Loss: 0.0179480534279719, Final Batch Loss: 0.0010177750373259187\n",
      "Epoch 4204, Loss: 0.00856249826028943, Final Batch Loss: 0.0022538057528436184\n",
      "Epoch 4205, Loss: 0.02929658815264702, Final Batch Loss: 0.01588479056954384\n",
      "Epoch 4206, Loss: 0.03280818648636341, Final Batch Loss: 0.008977949619293213\n",
      "Epoch 4207, Loss: 0.026335239876061678, Final Batch Loss: 0.022146185860037804\n",
      "Epoch 4208, Loss: 0.04544870578683913, Final Batch Loss: 0.04298529773950577\n",
      "Epoch 4209, Loss: 0.0604359433054924, Final Batch Loss: 0.03158516436815262\n",
      "Epoch 4210, Loss: 0.021032239077612758, Final Batch Loss: 0.0020746297668665648\n",
      "Epoch 4211, Loss: 0.01637841935735196, Final Batch Loss: 0.01468755304813385\n",
      "Epoch 4212, Loss: 0.038516804575920105, Final Batch Loss: 0.02349243313074112\n",
      "Epoch 4213, Loss: 0.02716358844190836, Final Batch Loss: 0.015916263684630394\n",
      "Epoch 4214, Loss: 0.013865325599908829, Final Batch Loss: 0.009344375692307949\n",
      "Epoch 4215, Loss: 0.030477448366582394, Final Batch Loss: 0.01668892800807953\n",
      "Epoch 4216, Loss: 0.024955722503364086, Final Batch Loss: 0.008853624574840069\n",
      "Epoch 4217, Loss: 0.008460992714390159, Final Batch Loss: 0.0030593418050557375\n",
      "Epoch 4218, Loss: 0.01361374044790864, Final Batch Loss: 0.004365043248981237\n",
      "Epoch 4219, Loss: 0.010120628168806434, Final Batch Loss: 0.006308380514383316\n",
      "Epoch 4220, Loss: 0.02923721633851528, Final Batch Loss: 0.007940839976072311\n",
      "Epoch 4221, Loss: 0.012525316094979644, Final Batch Loss: 0.0011761512141674757\n",
      "Epoch 4222, Loss: 0.0045359262730926275, Final Batch Loss: 0.002765580778941512\n",
      "Epoch 4223, Loss: 0.034535134211182594, Final Batch Loss: 0.01217000000178814\n",
      "Epoch 4224, Loss: 0.005523264640942216, Final Batch Loss: 0.002808293327689171\n",
      "Epoch 4225, Loss: 0.003424219787120819, Final Batch Loss: 0.0020404430106282234\n",
      "Epoch 4226, Loss: 0.020041562151163816, Final Batch Loss: 0.0013805232010781765\n",
      "Epoch 4227, Loss: 0.051762224175035954, Final Batch Loss: 0.044017449021339417\n",
      "Epoch 4228, Loss: 0.04459203872829676, Final Batch Loss: 0.004096255637705326\n",
      "Epoch 4229, Loss: 0.00506294472143054, Final Batch Loss: 0.0022741295397281647\n",
      "Epoch 4230, Loss: 0.02568607171997428, Final Batch Loss: 0.004868490155786276\n",
      "Epoch 4231, Loss: 0.0118682881584391, Final Batch Loss: 0.0016870381077751517\n",
      "Epoch 4232, Loss: 0.026855209842324257, Final Batch Loss: 0.013471665792167187\n",
      "Epoch 4233, Loss: 0.0035149247851222754, Final Batch Loss: 0.001381849404424429\n",
      "Epoch 4234, Loss: 0.014583575772121549, Final Batch Loss: 0.002819634275510907\n",
      "Epoch 4235, Loss: 0.037051488645374775, Final Batch Loss: 0.0316673219203949\n",
      "Epoch 4236, Loss: 0.021253900602459908, Final Batch Loss: 0.011646189726889133\n",
      "Epoch 4237, Loss: 0.00414353352971375, Final Batch Loss: 0.0015175756998360157\n",
      "Epoch 4238, Loss: 0.025365297216922045, Final Batch Loss: 0.01970241777598858\n",
      "Epoch 4239, Loss: 0.009327324805781245, Final Batch Loss: 0.007794067729264498\n",
      "Epoch 4240, Loss: 0.018220964819192886, Final Batch Loss: 0.01565822958946228\n",
      "Epoch 4241, Loss: 0.017624518368393183, Final Batch Loss: 0.007103005889803171\n",
      "Epoch 4242, Loss: 0.020312984939664602, Final Batch Loss: 0.0022112871520221233\n",
      "Epoch 4243, Loss: 0.06713950634002686, Final Batch Loss: 0.06156165152788162\n",
      "Epoch 4244, Loss: 0.04242718731984496, Final Batch Loss: 0.03489788994193077\n",
      "Epoch 4245, Loss: 0.032909583766013384, Final Batch Loss: 0.028240317478775978\n",
      "Epoch 4246, Loss: 0.005535479635000229, Final Batch Loss: 0.0005126525647938251\n",
      "Epoch 4247, Loss: 0.01681916182860732, Final Batch Loss: 0.0033763679675757885\n",
      "Epoch 4248, Loss: 0.026871362468227744, Final Batch Loss: 0.02572055719792843\n",
      "Epoch 4249, Loss: 0.02295411517843604, Final Batch Loss: 0.005055203568190336\n",
      "Epoch 4250, Loss: 0.003366486809682101, Final Batch Loss: 0.0006422576843760908\n",
      "Epoch 4251, Loss: 0.02878848323598504, Final Batch Loss: 0.00402792589738965\n",
      "Epoch 4252, Loss: 0.04821864143013954, Final Batch Loss: 0.025789201259613037\n",
      "Epoch 4253, Loss: 0.009650301653891802, Final Batch Loss: 0.002545600291341543\n",
      "Epoch 4254, Loss: 0.005779852392151952, Final Batch Loss: 0.0033717018086463213\n",
      "Epoch 4255, Loss: 0.003819590900093317, Final Batch Loss: 0.001068479847162962\n",
      "Epoch 4256, Loss: 0.008408562745898962, Final Batch Loss: 0.0020564207807183266\n",
      "Epoch 4257, Loss: 0.004797478439286351, Final Batch Loss: 0.002117353957146406\n",
      "Epoch 4258, Loss: 0.015418829396367073, Final Batch Loss: 0.009690377861261368\n",
      "Epoch 4259, Loss: 0.007170079508796334, Final Batch Loss: 0.0016334147658199072\n",
      "Epoch 4260, Loss: 0.008745775558054447, Final Batch Loss: 0.004286420065909624\n",
      "Epoch 4261, Loss: 0.0038356593577191234, Final Batch Loss: 0.0015559090534225106\n",
      "Epoch 4262, Loss: 0.017210111254826188, Final Batch Loss: 0.014181464910507202\n",
      "Epoch 4263, Loss: 0.017368053551763296, Final Batch Loss: 0.013881911523640156\n",
      "Epoch 4264, Loss: 0.02532300795428455, Final Batch Loss: 0.0038762285839766264\n",
      "Epoch 4265, Loss: 0.026707038283348083, Final Batch Loss: 0.018775559961795807\n",
      "Epoch 4266, Loss: 0.01639470923691988, Final Batch Loss: 0.006662607192993164\n",
      "Epoch 4267, Loss: 0.011993218795396388, Final Batch Loss: 0.010534693486988544\n",
      "Epoch 4268, Loss: 0.004532891325652599, Final Batch Loss: 0.001499814447015524\n",
      "Epoch 4269, Loss: 0.023120357654988766, Final Batch Loss: 0.019824806600809097\n",
      "Epoch 4270, Loss: 0.015653495909646153, Final Batch Loss: 0.011863426305353642\n",
      "Epoch 4271, Loss: 0.014486593892797828, Final Batch Loss: 0.00300407106988132\n",
      "Epoch 4272, Loss: 0.012556765228509903, Final Batch Loss: 0.003735083155333996\n",
      "Epoch 4273, Loss: 0.0082254852168262, Final Batch Loss: 0.0032479367218911648\n",
      "Epoch 4274, Loss: 0.014683639630675316, Final Batch Loss: 0.00814519077539444\n",
      "Epoch 4275, Loss: 0.021964764455333352, Final Batch Loss: 0.002432175213471055\n",
      "Epoch 4276, Loss: 0.018423436675220728, Final Batch Loss: 0.0035658827982842922\n",
      "Epoch 4277, Loss: 0.02960036601871252, Final Batch Loss: 0.021846476942300797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4278, Loss: 0.006007895921356976, Final Batch Loss: 0.0013740403810516\n",
      "Epoch 4279, Loss: 0.01829176489263773, Final Batch Loss: 0.01567681133747101\n",
      "Epoch 4280, Loss: 0.006185735808685422, Final Batch Loss: 0.0023680077865719795\n",
      "Epoch 4281, Loss: 0.06119863362982869, Final Batch Loss: 0.055923942476511\n",
      "Epoch 4282, Loss: 0.014953044708818197, Final Batch Loss: 0.0009551090188324451\n",
      "Epoch 4283, Loss: 0.013150187209248543, Final Batch Loss: 0.008541778661310673\n",
      "Epoch 4284, Loss: 0.006148100597783923, Final Batch Loss: 0.001755282049998641\n",
      "Epoch 4285, Loss: 0.007827535504475236, Final Batch Loss: 0.00353217008523643\n",
      "Epoch 4286, Loss: 0.02199325547553599, Final Batch Loss: 0.018149182200431824\n",
      "Epoch 4287, Loss: 0.02047957992181182, Final Batch Loss: 0.016031155362725258\n",
      "Epoch 4288, Loss: 0.005416844505816698, Final Batch Loss: 0.0034520700573921204\n",
      "Epoch 4289, Loss: 0.02952410187572241, Final Batch Loss: 0.008862142451107502\n",
      "Epoch 4290, Loss: 0.007377173751592636, Final Batch Loss: 0.0033525116741657257\n",
      "Epoch 4291, Loss: 0.008445309707894921, Final Batch Loss: 0.0038399973418563604\n",
      "Epoch 4292, Loss: 0.004158841271419078, Final Batch Loss: 0.0009457686101086438\n",
      "Epoch 4293, Loss: 0.020282321609556675, Final Batch Loss: 0.006489256396889687\n",
      "Epoch 4294, Loss: 0.013611441478133202, Final Batch Loss: 0.001412494108080864\n",
      "Epoch 4295, Loss: 0.012684512417763472, Final Batch Loss: 0.005822521168738604\n",
      "Epoch 4296, Loss: 0.007560801110230386, Final Batch Loss: 0.0010372329270467162\n",
      "Epoch 4297, Loss: 0.013053562957793474, Final Batch Loss: 0.006215446628630161\n",
      "Epoch 4298, Loss: 0.010112229501828551, Final Batch Loss: 0.003442284418269992\n",
      "Epoch 4299, Loss: 0.006840176181867719, Final Batch Loss: 0.0022413197439163923\n",
      "Epoch 4300, Loss: 0.02954204846173525, Final Batch Loss: 0.023216476663947105\n",
      "Epoch 4301, Loss: 0.002559479500632733, Final Batch Loss: 0.0016073473962023854\n",
      "Epoch 4302, Loss: 0.006771137588657439, Final Batch Loss: 0.005147211719304323\n",
      "Epoch 4303, Loss: 0.018947768956422806, Final Batch Loss: 0.006596830673515797\n",
      "Epoch 4304, Loss: 0.006561266258358955, Final Batch Loss: 0.002570193726569414\n",
      "Epoch 4305, Loss: 0.016793619142845273, Final Batch Loss: 0.0032589382026344538\n",
      "Epoch 4306, Loss: 0.02331695007160306, Final Batch Loss: 0.005890785250812769\n",
      "Epoch 4307, Loss: 0.00484154827427119, Final Batch Loss: 0.0017233536345884204\n",
      "Epoch 4308, Loss: 0.005442917929030955, Final Batch Loss: 0.001098545384593308\n",
      "Epoch 4309, Loss: 0.007154525490477681, Final Batch Loss: 0.0035347132943570614\n",
      "Epoch 4310, Loss: 0.06905414164066315, Final Batch Loss: 0.030911985784769058\n",
      "Epoch 4311, Loss: 0.007697160355746746, Final Batch Loss: 0.0057313209399580956\n",
      "Epoch 4312, Loss: 0.021434163209050894, Final Batch Loss: 0.003772502299398184\n",
      "Epoch 4313, Loss: 0.007148489123210311, Final Batch Loss: 0.003262832062318921\n",
      "Epoch 4314, Loss: 0.005429102689959109, Final Batch Loss: 0.0012922427849844098\n",
      "Epoch 4315, Loss: 0.012120237457565963, Final Batch Loss: 0.0012841400457546115\n",
      "Epoch 4316, Loss: 0.020905792247503996, Final Batch Loss: 0.005883036646991968\n",
      "Epoch 4317, Loss: 0.007169501739554107, Final Batch Loss: 0.0015012620715424418\n",
      "Epoch 4318, Loss: 0.016090283170342445, Final Batch Loss: 0.0017894254997372627\n",
      "Epoch 4319, Loss: 0.06331010162830353, Final Batch Loss: 0.038747746497392654\n",
      "Epoch 4320, Loss: 0.024412035010755062, Final Batch Loss: 0.008312513120472431\n",
      "Epoch 4321, Loss: 0.003551604168023914, Final Batch Loss: 0.002674558199942112\n",
      "Epoch 4322, Loss: 0.053640138008631766, Final Batch Loss: 0.0017080489778891206\n",
      "Epoch 4323, Loss: 0.05691948579624295, Final Batch Loss: 0.05048670619726181\n",
      "Epoch 4324, Loss: 0.020131000317633152, Final Batch Loss: 0.0095616290345788\n",
      "Epoch 4325, Loss: 0.0059628349263221025, Final Batch Loss: 0.003507267450913787\n",
      "Epoch 4326, Loss: 0.01740547176450491, Final Batch Loss: 0.0063053155317902565\n",
      "Epoch 4327, Loss: 0.053187266224995255, Final Batch Loss: 0.05091556906700134\n",
      "Epoch 4328, Loss: 0.022756125777959824, Final Batch Loss: 0.0055897049605846405\n",
      "Epoch 4329, Loss: 0.020689825527369976, Final Batch Loss: 0.00468513835221529\n",
      "Epoch 4330, Loss: 0.03575680684298277, Final Batch Loss: 0.004074684344232082\n",
      "Epoch 4331, Loss: 0.013985179830342531, Final Batch Loss: 0.0040069217793643475\n",
      "Epoch 4332, Loss: 0.07738704606890678, Final Batch Loss: 0.04443555325269699\n",
      "Epoch 4333, Loss: 0.06618501618504524, Final Batch Loss: 0.014632973819971085\n",
      "Epoch 4334, Loss: 0.09282968752086163, Final Batch Loss: 0.0684586614370346\n",
      "Epoch 4335, Loss: 0.009548780508339405, Final Batch Loss: 0.005377087742090225\n",
      "Epoch 4336, Loss: 0.04936359450221062, Final Batch Loss: 0.004416577517986298\n",
      "Epoch 4337, Loss: 0.00695874507073313, Final Batch Loss: 0.006032047793269157\n",
      "Epoch 4338, Loss: 0.004841941874474287, Final Batch Loss: 0.0012098345905542374\n",
      "Epoch 4339, Loss: 0.036857093218714, Final Batch Loss: 0.03146441653370857\n",
      "Epoch 4340, Loss: 0.018504658713936806, Final Batch Loss: 0.010735505260527134\n",
      "Epoch 4341, Loss: 0.015394304413348436, Final Batch Loss: 0.007187436800450087\n",
      "Epoch 4342, Loss: 0.06394678447395563, Final Batch Loss: 0.050847381353378296\n",
      "Epoch 4343, Loss: 0.00837350357323885, Final Batch Loss: 0.002488037571310997\n",
      "Epoch 4344, Loss: 0.008441565092653036, Final Batch Loss: 0.00555379269644618\n",
      "Epoch 4345, Loss: 0.14504938945174217, Final Batch Loss: 0.11735037714242935\n",
      "Epoch 4346, Loss: 0.03819929342716932, Final Batch Loss: 0.010280667804181576\n",
      "Epoch 4347, Loss: 0.09892469272017479, Final Batch Loss: 0.0747048556804657\n",
      "Epoch 4348, Loss: 0.021553585305809975, Final Batch Loss: 0.004978027194738388\n",
      "Epoch 4349, Loss: 0.04144584946334362, Final Batch Loss: 0.02694837562739849\n",
      "Epoch 4350, Loss: 0.10129567701369524, Final Batch Loss: 0.010939565487205982\n",
      "Epoch 4351, Loss: 0.039731147699058056, Final Batch Loss: 0.01351278554648161\n",
      "Epoch 4352, Loss: 0.1216789036989212, Final Batch Loss: 0.04283899813890457\n",
      "Epoch 4353, Loss: 0.029111329466104507, Final Batch Loss: 0.005181171000003815\n",
      "Epoch 4354, Loss: 0.04533145157620311, Final Batch Loss: 0.03788949176669121\n",
      "Epoch 4355, Loss: 0.0775703713297844, Final Batch Loss: 0.04024651646614075\n",
      "Epoch 4356, Loss: 0.06302587129175663, Final Batch Loss: 0.04219474270939827\n",
      "Epoch 4357, Loss: 0.02537033800035715, Final Batch Loss: 0.01837298274040222\n",
      "Epoch 4358, Loss: 0.12483165040612221, Final Batch Loss: 0.10313338786363602\n",
      "Epoch 4359, Loss: 0.014088054187595844, Final Batch Loss: 0.004456653259694576\n",
      "Epoch 4360, Loss: 0.03327781520783901, Final Batch Loss: 0.0036402978003025055\n",
      "Epoch 4361, Loss: 0.09566750004887581, Final Batch Loss: 0.05501142516732216\n",
      "Epoch 4362, Loss: 0.048280505230650306, Final Batch Loss: 0.0031907164957374334\n",
      "Epoch 4363, Loss: 0.0410519614815712, Final Batch Loss: 0.011139124631881714\n",
      "Epoch 4364, Loss: 0.09710686840116978, Final Batch Loss: 0.06595965474843979\n",
      "Epoch 4365, Loss: 0.03379988297820091, Final Batch Loss: 0.011072568595409393\n",
      "Epoch 4366, Loss: 0.03840695880353451, Final Batch Loss: 0.016381213441491127\n",
      "Epoch 4367, Loss: 0.028874565847218037, Final Batch Loss: 0.011627155356109142\n",
      "Epoch 4368, Loss: 0.046588411554694176, Final Batch Loss: 0.026042306795716286\n",
      "Epoch 4369, Loss: 0.012187619227916002, Final Batch Loss: 0.004264525603502989\n",
      "Epoch 4370, Loss: 0.022517656907439232, Final Batch Loss: 0.011197976768016815\n",
      "Epoch 4371, Loss: 0.043086797930300236, Final Batch Loss: 0.030156059190630913\n",
      "Epoch 4372, Loss: 0.04253399698063731, Final Batch Loss: 0.007212940137833357\n",
      "Epoch 4373, Loss: 0.03687699604779482, Final Batch Loss: 0.03238710016012192\n",
      "Epoch 4374, Loss: 0.08925709803588688, Final Batch Loss: 0.08543834835290909\n",
      "Epoch 4375, Loss: 0.021248050034046173, Final Batch Loss: 0.008036710321903229\n",
      "Epoch 4376, Loss: 0.021456239745020866, Final Batch Loss: 0.00858013704419136\n",
      "Epoch 4377, Loss: 0.05222267843782902, Final Batch Loss: 0.00708768330514431\n",
      "Epoch 4378, Loss: 0.031172165647149086, Final Batch Loss: 0.018881112337112427\n",
      "Epoch 4379, Loss: 0.02315689343959093, Final Batch Loss: 0.004625326953828335\n",
      "Epoch 4380, Loss: 0.030323829501867294, Final Batch Loss: 0.02009446546435356\n",
      "Epoch 4381, Loss: 0.028639731463044882, Final Batch Loss: 0.022474976256489754\n",
      "Epoch 4382, Loss: 0.028477719519287348, Final Batch Loss: 0.006251095328480005\n",
      "Epoch 4383, Loss: 0.010498953284695745, Final Batch Loss: 0.0027738495264202356\n",
      "Epoch 4384, Loss: 0.016081126872450113, Final Batch Loss: 0.007066953461617231\n",
      "Epoch 4385, Loss: 0.016933617647737265, Final Batch Loss: 0.004465748090296984\n",
      "Epoch 4386, Loss: 0.033786995336413383, Final Batch Loss: 0.014589376747608185\n",
      "Epoch 4387, Loss: 0.03266163426451385, Final Batch Loss: 0.0020635954570025206\n",
      "Epoch 4388, Loss: 0.016083281487226486, Final Batch Loss: 0.01084656547755003\n",
      "Epoch 4389, Loss: 0.00876459851861, Final Batch Loss: 0.003406250849366188\n",
      "Epoch 4390, Loss: 0.011391445761546493, Final Batch Loss: 0.008632457815110683\n",
      "Epoch 4391, Loss: 0.01069202646613121, Final Batch Loss: 0.004861241672188044\n",
      "Epoch 4392, Loss: 0.028200070839375257, Final Batch Loss: 0.022043902426958084\n",
      "Epoch 4393, Loss: 0.01676601846702397, Final Batch Loss: 0.0038128646556288004\n",
      "Epoch 4394, Loss: 0.004451193381100893, Final Batch Loss: 0.00192745472304523\n",
      "Epoch 4395, Loss: 0.02585599571466446, Final Batch Loss: 0.00507584773004055\n",
      "Epoch 4396, Loss: 0.012122990097850561, Final Batch Loss: 0.0018486869521439075\n",
      "Epoch 4397, Loss: 0.03708280576393008, Final Batch Loss: 0.030519908294081688\n",
      "Epoch 4398, Loss: 0.01887599006295204, Final Batch Loss: 0.01078102272003889\n",
      "Epoch 4399, Loss: 0.025710750836879015, Final Batch Loss: 0.004912779200822115\n",
      "Epoch 4400, Loss: 0.06534063257277012, Final Batch Loss: 0.04043901339173317\n",
      "Epoch 4401, Loss: 0.03579617477953434, Final Batch Loss: 0.009091228246688843\n",
      "Epoch 4402, Loss: 0.008238072274252772, Final Batch Loss: 0.006065904162824154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4403, Loss: 0.01149969082325697, Final Batch Loss: 0.007007327396422625\n",
      "Epoch 4404, Loss: 0.012178189121186733, Final Batch Loss: 0.003714778460562229\n",
      "Epoch 4405, Loss: 0.030795984901487827, Final Batch Loss: 0.007142749615013599\n",
      "Epoch 4406, Loss: 0.03565146587789059, Final Batch Loss: 0.027834635227918625\n",
      "Epoch 4407, Loss: 0.007015509065240622, Final Batch Loss: 0.0027935700491070747\n",
      "Epoch 4408, Loss: 0.003693463862873614, Final Batch Loss: 0.0019395537674427032\n",
      "Epoch 4409, Loss: 0.022943899035453796, Final Batch Loss: 0.011474544182419777\n",
      "Epoch 4410, Loss: 0.0316466037184, Final Batch Loss: 0.024601731449365616\n",
      "Epoch 4411, Loss: 0.024828817695379257, Final Batch Loss: 0.013612187467515469\n",
      "Epoch 4412, Loss: 0.01303121680393815, Final Batch Loss: 0.00873642135411501\n",
      "Epoch 4413, Loss: 0.034058492397889495, Final Batch Loss: 0.0007953343447297812\n",
      "Epoch 4414, Loss: 0.051343954633921385, Final Batch Loss: 0.047066494822502136\n",
      "Epoch 4415, Loss: 0.04930758848786354, Final Batch Loss: 0.02041342668235302\n",
      "Epoch 4416, Loss: 0.02084473567083478, Final Batch Loss: 0.013447142206132412\n",
      "Epoch 4417, Loss: 0.009694502223283052, Final Batch Loss: 0.003869950771331787\n",
      "Epoch 4418, Loss: 0.025545756798237562, Final Batch Loss: 0.020581576973199844\n",
      "Epoch 4419, Loss: 0.03166026808321476, Final Batch Loss: 0.024209842085838318\n",
      "Epoch 4420, Loss: 0.01162984617985785, Final Batch Loss: 0.0037832532543689013\n",
      "Epoch 4421, Loss: 0.03345249220728874, Final Batch Loss: 0.01601373217999935\n",
      "Epoch 4422, Loss: 0.010429833550006151, Final Batch Loss: 0.006013927981257439\n",
      "Epoch 4423, Loss: 0.009584127925336361, Final Batch Loss: 0.005433667451143265\n",
      "Epoch 4424, Loss: 0.05792024452239275, Final Batch Loss: 0.048590343445539474\n",
      "Epoch 4425, Loss: 0.00830576615408063, Final Batch Loss: 0.002752319909632206\n",
      "Epoch 4426, Loss: 0.06945997104048729, Final Batch Loss: 0.03177105262875557\n",
      "Epoch 4427, Loss: 0.04040156304836273, Final Batch Loss: 0.03201260045170784\n",
      "Epoch 4428, Loss: 0.04918636754155159, Final Batch Loss: 0.01987840048968792\n",
      "Epoch 4429, Loss: 0.029745090752840042, Final Batch Loss: 0.004870250821113586\n",
      "Epoch 4430, Loss: 0.008797499584034085, Final Batch Loss: 0.006671006325632334\n",
      "Epoch 4431, Loss: 0.012365298345685005, Final Batch Loss: 0.004832171835005283\n",
      "Epoch 4432, Loss: 0.039592403918504715, Final Batch Loss: 0.03481746092438698\n",
      "Epoch 4433, Loss: 0.007042147917672992, Final Batch Loss: 0.004944224376231432\n",
      "Epoch 4434, Loss: 0.009944986319169402, Final Batch Loss: 0.007531917653977871\n",
      "Epoch 4435, Loss: 0.0202622190117836, Final Batch Loss: 0.0028257016092538834\n",
      "Epoch 4436, Loss: 0.024086672579869628, Final Batch Loss: 0.0037341301795095205\n",
      "Epoch 4437, Loss: 0.03746214509010315, Final Batch Loss: 0.017877323552966118\n",
      "Epoch 4438, Loss: 0.023504585027694702, Final Batch Loss: 0.019296569749712944\n",
      "Epoch 4439, Loss: 0.031755562871694565, Final Batch Loss: 0.015279918909072876\n",
      "Epoch 4440, Loss: 0.033074963837862015, Final Batch Loss: 0.018885893747210503\n",
      "Epoch 4441, Loss: 0.04513502772897482, Final Batch Loss: 0.035753726959228516\n",
      "Epoch 4442, Loss: 0.016229465138167143, Final Batch Loss: 0.013440459966659546\n",
      "Epoch 4443, Loss: 0.046508040046319366, Final Batch Loss: 0.04284977540373802\n",
      "Epoch 4444, Loss: 0.06148087978363037, Final Batch Loss: 0.028797313570976257\n",
      "Epoch 4445, Loss: 0.026667382568120956, Final Batch Loss: 0.01988350786268711\n",
      "Epoch 4446, Loss: 0.015807786490768194, Final Batch Loss: 0.010340472683310509\n",
      "Epoch 4447, Loss: 0.03204250708222389, Final Batch Loss: 0.017981134355068207\n",
      "Epoch 4448, Loss: 0.02374350745230913, Final Batch Loss: 0.004136635921895504\n",
      "Epoch 4449, Loss: 0.010362738743424416, Final Batch Loss: 0.005438737105578184\n",
      "Epoch 4450, Loss: 0.09260004851967096, Final Batch Loss: 0.08173809200525284\n",
      "Epoch 4451, Loss: 0.019559799693524837, Final Batch Loss: 0.013551333919167519\n",
      "Epoch 4452, Loss: 0.009169676341116428, Final Batch Loss: 0.0024309083819389343\n",
      "Epoch 4453, Loss: 0.017836886923760176, Final Batch Loss: 0.010401027277112007\n",
      "Epoch 4454, Loss: 0.033561116084456444, Final Batch Loss: 0.011753879487514496\n",
      "Epoch 4455, Loss: 0.008299225941300392, Final Batch Loss: 0.0052958764135837555\n",
      "Epoch 4456, Loss: 0.023760915733873844, Final Batch Loss: 0.01235518604516983\n",
      "Epoch 4457, Loss: 0.01140693761408329, Final Batch Loss: 0.0058342646807432175\n",
      "Epoch 4458, Loss: 0.04082372097764164, Final Batch Loss: 0.0019008038798347116\n",
      "Epoch 4459, Loss: 0.017589214257895947, Final Batch Loss: 0.005720062181353569\n",
      "Epoch 4460, Loss: 0.032310412265360355, Final Batch Loss: 0.014326122589409351\n",
      "Epoch 4461, Loss: 0.03293987992219627, Final Batch Loss: 0.0028217535000294447\n",
      "Epoch 4462, Loss: 0.0777191836386919, Final Batch Loss: 0.02342689223587513\n",
      "Epoch 4463, Loss: 0.013542975299060345, Final Batch Loss: 0.00602198950946331\n",
      "Epoch 4464, Loss: 0.039233120158314705, Final Batch Loss: 0.017343375831842422\n",
      "Epoch 4465, Loss: 0.009463059715926647, Final Batch Loss: 0.003693725448101759\n",
      "Epoch 4466, Loss: 0.012966551817953587, Final Batch Loss: 0.004750799387693405\n",
      "Epoch 4467, Loss: 0.02345607033930719, Final Batch Loss: 0.001113945385441184\n",
      "Epoch 4468, Loss: 0.012946880655363202, Final Batch Loss: 0.010238653048872948\n",
      "Epoch 4469, Loss: 0.016150497714988887, Final Batch Loss: 0.0017947478918358684\n",
      "Epoch 4470, Loss: 0.042568313889205456, Final Batch Loss: 0.012799066491425037\n",
      "Epoch 4471, Loss: 0.043079810217022896, Final Batch Loss: 0.029053201898932457\n",
      "Epoch 4472, Loss: 0.053167641162872314, Final Batch Loss: 0.04898381605744362\n",
      "Epoch 4473, Loss: 0.10940965078771114, Final Batch Loss: 0.020329048857092857\n",
      "Epoch 4474, Loss: 0.003733754623681307, Final Batch Loss: 0.0028502827044576406\n",
      "Epoch 4475, Loss: 0.03492696676403284, Final Batch Loss: 0.014672699384391308\n",
      "Epoch 4476, Loss: 0.024252191185951233, Final Batch Loss: 0.02045321837067604\n",
      "Epoch 4477, Loss: 0.023952655494213104, Final Batch Loss: 0.009547377936542034\n",
      "Epoch 4478, Loss: 0.021636218763887882, Final Batch Loss: 0.009651035070419312\n",
      "Epoch 4479, Loss: 0.0929819829761982, Final Batch Loss: 0.03964050114154816\n",
      "Epoch 4480, Loss: 0.021383734419941902, Final Batch Loss: 0.01495964266359806\n",
      "Epoch 4481, Loss: 0.012117117876186967, Final Batch Loss: 0.003084916854277253\n",
      "Epoch 4482, Loss: 0.013393034576438367, Final Batch Loss: 0.0015207541873678565\n",
      "Epoch 4483, Loss: 0.028029642766341567, Final Batch Loss: 0.024547848850488663\n",
      "Epoch 4484, Loss: 0.019608488772064447, Final Batch Loss: 0.005014336202293634\n",
      "Epoch 4485, Loss: 0.011538401246070862, Final Batch Loss: 0.006850614212453365\n",
      "Epoch 4486, Loss: 0.018685971619561315, Final Batch Loss: 0.0033199398312717676\n",
      "Epoch 4487, Loss: 0.0033658057218417525, Final Batch Loss: 0.0012822839198634028\n",
      "Epoch 4488, Loss: 0.023141703684814274, Final Batch Loss: 0.0012496832059696317\n",
      "Epoch 4489, Loss: 0.010999505640938878, Final Batch Loss: 0.008828887715935707\n",
      "Epoch 4490, Loss: 0.0056502255611121655, Final Batch Loss: 0.0026357953902333975\n",
      "Epoch 4491, Loss: 0.009272848721593618, Final Batch Loss: 0.004240581765770912\n",
      "Epoch 4492, Loss: 0.012386056972900406, Final Batch Loss: 0.00045271628187038004\n",
      "Epoch 4493, Loss: 0.01082273293286562, Final Batch Loss: 0.003872182220220566\n",
      "Epoch 4494, Loss: 0.030301795806735754, Final Batch Loss: 0.006414869334548712\n",
      "Epoch 4495, Loss: 0.002765019075013697, Final Batch Loss: 0.0013067236868664622\n",
      "Epoch 4496, Loss: 0.011579521466046572, Final Batch Loss: 0.0015765936113893986\n",
      "Epoch 4497, Loss: 0.004871491109952331, Final Batch Loss: 0.0018530490342527628\n",
      "Epoch 4498, Loss: 0.04252473788801581, Final Batch Loss: 0.040610603988170624\n",
      "Epoch 4499, Loss: 0.014214984606951475, Final Batch Loss: 0.008446838706731796\n",
      "Epoch 4500, Loss: 0.015821891371160746, Final Batch Loss: 0.009291226044297218\n",
      "Epoch 4501, Loss: 0.004438774194568396, Final Batch Loss: 0.0014823612291365862\n",
      "Epoch 4502, Loss: 0.0030697507318109274, Final Batch Loss: 0.0019574882462620735\n",
      "Epoch 4503, Loss: 0.062165399082005024, Final Batch Loss: 0.05130534991621971\n",
      "Epoch 4504, Loss: 0.008539343252778053, Final Batch Loss: 0.006430264562368393\n",
      "Epoch 4505, Loss: 0.0028664059937000275, Final Batch Loss: 0.0015166153898462653\n",
      "Epoch 4506, Loss: 0.013129795901477337, Final Batch Loss: 0.006176971830427647\n",
      "Epoch 4507, Loss: 0.0444489661604166, Final Batch Loss: 0.010309139266610146\n",
      "Epoch 4508, Loss: 0.007886465638875961, Final Batch Loss: 0.0018358356319367886\n",
      "Epoch 4509, Loss: 0.004868537769652903, Final Batch Loss: 0.003188219852745533\n",
      "Epoch 4510, Loss: 0.021188723854720592, Final Batch Loss: 0.011512511409819126\n",
      "Epoch 4511, Loss: 0.004143743542954326, Final Batch Loss: 0.0024959982838481665\n",
      "Epoch 4512, Loss: 0.0375800144392997, Final Batch Loss: 0.002959010424092412\n",
      "Epoch 4513, Loss: 0.007483890512958169, Final Batch Loss: 0.0030783892143517733\n",
      "Epoch 4514, Loss: 0.01637039426714182, Final Batch Loss: 0.010776004754006863\n",
      "Epoch 4515, Loss: 0.004583673435263336, Final Batch Loss: 0.002892991527915001\n",
      "Epoch 4516, Loss: 0.019770374055951834, Final Batch Loss: 0.014469245448708534\n",
      "Epoch 4517, Loss: 0.006885781738674268, Final Batch Loss: 0.00042490134364925325\n",
      "Epoch 4518, Loss: 0.0067057255655527115, Final Batch Loss: 0.0047074612230062485\n",
      "Epoch 4519, Loss: 0.04271068051457405, Final Batch Loss: 0.027885757386684418\n",
      "Epoch 4520, Loss: 0.0320073077455163, Final Batch Loss: 0.0030805720016360283\n",
      "Epoch 4521, Loss: 0.03231788636185229, Final Batch Loss: 0.0025614036712795496\n",
      "Epoch 4522, Loss: 0.009696637513116002, Final Batch Loss: 0.0026455826591700315\n",
      "Epoch 4523, Loss: 0.02087887842208147, Final Batch Loss: 0.00747358612716198\n",
      "Epoch 4524, Loss: 0.010587552562355995, Final Batch Loss: 0.003320559859275818\n",
      "Epoch 4525, Loss: 0.004219793365336955, Final Batch Loss: 0.0014468234730884433\n",
      "Epoch 4526, Loss: 0.006501552648842335, Final Batch Loss: 0.004538136534392834\n",
      "Epoch 4527, Loss: 0.007454267702996731, Final Batch Loss: 0.005074113141745329\n",
      "Epoch 4528, Loss: 0.08515334269031882, Final Batch Loss: 0.08170969784259796\n",
      "Epoch 4529, Loss: 0.012527371291071177, Final Batch Loss: 0.008477500639855862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4530, Loss: 0.025084972381591797, Final Batch Loss: 0.008668838068842888\n",
      "Epoch 4531, Loss: 0.011857143137603998, Final Batch Loss: 0.004271642304956913\n",
      "Epoch 4532, Loss: 0.07186935073696077, Final Batch Loss: 0.06883908808231354\n",
      "Epoch 4533, Loss: 0.017683879006654024, Final Batch Loss: 0.007389746140688658\n",
      "Epoch 4534, Loss: 0.008667581249028444, Final Batch Loss: 0.0013600261881947517\n",
      "Epoch 4535, Loss: 0.06084615644067526, Final Batch Loss: 0.012945245020091534\n",
      "Epoch 4536, Loss: 0.028226609341800213, Final Batch Loss: 0.008683149702847004\n",
      "Epoch 4537, Loss: 0.007110061589628458, Final Batch Loss: 0.004155824892222881\n",
      "Epoch 4538, Loss: 0.020929466001689434, Final Batch Loss: 0.011896824464201927\n",
      "Epoch 4539, Loss: 0.010378815000876784, Final Batch Loss: 0.003899653209373355\n",
      "Epoch 4540, Loss: 0.008747512241825461, Final Batch Loss: 0.004928079899400473\n",
      "Epoch 4541, Loss: 0.02248840592801571, Final Batch Loss: 0.0032997746020555496\n",
      "Epoch 4542, Loss: 0.025521895848214626, Final Batch Loss: 0.017063826322555542\n",
      "Epoch 4543, Loss: 0.005837158067151904, Final Batch Loss: 0.0019236488733440638\n",
      "Epoch 4544, Loss: 0.007768178591504693, Final Batch Loss: 0.002350908936932683\n",
      "Epoch 4545, Loss: 0.005685098702087998, Final Batch Loss: 0.0036528711207211018\n",
      "Epoch 4546, Loss: 0.006169873988255858, Final Batch Loss: 0.00234863325022161\n",
      "Epoch 4547, Loss: 0.013985404279083014, Final Batch Loss: 0.00955596100538969\n",
      "Epoch 4548, Loss: 0.007014012313447893, Final Batch Loss: 0.005513485055416822\n",
      "Epoch 4549, Loss: 0.013775288127362728, Final Batch Loss: 0.0025527840480208397\n",
      "Epoch 4550, Loss: 0.035062738228589296, Final Batch Loss: 0.03197793662548065\n",
      "Epoch 4551, Loss: 0.006119402591139078, Final Batch Loss: 0.0016622710973024368\n",
      "Epoch 4552, Loss: 0.028727352619171143, Final Batch Loss: 0.00800585001707077\n",
      "Epoch 4553, Loss: 0.013143457006663084, Final Batch Loss: 0.010574117302894592\n",
      "Epoch 4554, Loss: 0.00364113028626889, Final Batch Loss: 0.0007369468221440911\n",
      "Epoch 4555, Loss: 0.02387800021097064, Final Batch Loss: 0.021477947011590004\n",
      "Epoch 4556, Loss: 0.04069921188056469, Final Batch Loss: 0.021164722740650177\n",
      "Epoch 4557, Loss: 0.011359946336597204, Final Batch Loss: 0.006914400029927492\n",
      "Epoch 4558, Loss: 0.012516008224338293, Final Batch Loss: 0.0021517924033105373\n",
      "Epoch 4559, Loss: 0.00808574608527124, Final Batch Loss: 0.002300800057128072\n",
      "Epoch 4560, Loss: 0.010166690684854984, Final Batch Loss: 0.004546690732240677\n",
      "Epoch 4561, Loss: 0.003021357813850045, Final Batch Loss: 0.0015862660948187113\n",
      "Epoch 4562, Loss: 0.01108262233901769, Final Batch Loss: 0.00928743276745081\n",
      "Epoch 4563, Loss: 0.018379082903265953, Final Batch Loss: 0.011058303527534008\n",
      "Epoch 4564, Loss: 0.03129144851118326, Final Batch Loss: 0.012532499618828297\n",
      "Epoch 4565, Loss: 0.00811041402630508, Final Batch Loss: 0.002258982742205262\n",
      "Epoch 4566, Loss: 0.02272297814488411, Final Batch Loss: 0.009675188921391964\n",
      "Epoch 4567, Loss: 0.008833118190523237, Final Batch Loss: 0.0009226048714481294\n",
      "Epoch 4568, Loss: 0.01661861501634121, Final Batch Loss: 0.012441989034414291\n",
      "Epoch 4569, Loss: 0.009232549462467432, Final Batch Loss: 0.007063784170895815\n",
      "Epoch 4570, Loss: 0.015355569776147604, Final Batch Loss: 0.0033378140069544315\n",
      "Epoch 4571, Loss: 0.012886402197182178, Final Batch Loss: 0.005967968609184027\n",
      "Epoch 4572, Loss: 0.056541018187999725, Final Batch Loss: 0.022556651383638382\n",
      "Epoch 4573, Loss: 0.0218505235388875, Final Batch Loss: 0.014500971883535385\n",
      "Epoch 4574, Loss: 0.03557208436541259, Final Batch Loss: 0.0013192470651119947\n",
      "Epoch 4575, Loss: 0.016344422474503517, Final Batch Loss: 0.013679184019565582\n",
      "Epoch 4576, Loss: 0.008967967936769128, Final Batch Loss: 0.003340100636705756\n",
      "Epoch 4577, Loss: 0.025095959194004536, Final Batch Loss: 0.014197943732142448\n",
      "Epoch 4578, Loss: 0.020098441746085882, Final Batch Loss: 0.004071944858878851\n",
      "Epoch 4579, Loss: 0.04047120548784733, Final Batch Loss: 0.01587422378361225\n",
      "Epoch 4580, Loss: 0.038722907193005085, Final Batch Loss: 0.014732572250068188\n",
      "Epoch 4581, Loss: 0.011452450416982174, Final Batch Loss: 0.004244386684149504\n",
      "Epoch 4582, Loss: 0.006004723021760583, Final Batch Loss: 0.0019331041257828474\n",
      "Epoch 4583, Loss: 0.051249352283775806, Final Batch Loss: 0.04189082235097885\n",
      "Epoch 4584, Loss: 0.012735235970467329, Final Batch Loss: 0.0064749810844659805\n",
      "Epoch 4585, Loss: 0.03096825524698943, Final Batch Loss: 0.0010029681725427508\n",
      "Epoch 4586, Loss: 0.06760768033564091, Final Batch Loss: 0.041515935212373734\n",
      "Epoch 4587, Loss: 0.00908412178978324, Final Batch Loss: 0.0018443679437041283\n",
      "Epoch 4588, Loss: 0.07291483134031296, Final Batch Loss: 0.037295304238796234\n",
      "Epoch 4589, Loss: 0.008949591661803424, Final Batch Loss: 0.0007886289386078715\n",
      "Epoch 4590, Loss: 0.02204016875475645, Final Batch Loss: 0.011352808214724064\n",
      "Epoch 4591, Loss: 0.05045553809031844, Final Batch Loss: 0.005707708653062582\n",
      "Epoch 4592, Loss: 0.0034626113483682275, Final Batch Loss: 0.0016641634283587337\n",
      "Epoch 4593, Loss: 0.013901434140279889, Final Batch Loss: 0.0017069356981664896\n",
      "Epoch 4594, Loss: 0.016487376764416695, Final Batch Loss: 0.006995813921093941\n",
      "Epoch 4595, Loss: 0.005560709512792528, Final Batch Loss: 0.0006312847835943103\n",
      "Epoch 4596, Loss: 0.010502572171390057, Final Batch Loss: 0.006578311789780855\n",
      "Epoch 4597, Loss: 0.010442267172038555, Final Batch Loss: 0.003963793627917767\n",
      "Epoch 4598, Loss: 0.008213777793571353, Final Batch Loss: 0.005459578242152929\n",
      "Epoch 4599, Loss: 0.0309662614017725, Final Batch Loss: 0.012996142730116844\n",
      "Epoch 4600, Loss: 0.03753078356385231, Final Batch Loss: 0.01842295192182064\n",
      "Epoch 4601, Loss: 0.01582902343943715, Final Batch Loss: 0.00840763095766306\n",
      "Epoch 4602, Loss: 0.006955297198146582, Final Batch Loss: 0.004647088702768087\n",
      "Epoch 4603, Loss: 0.011915820417925715, Final Batch Loss: 0.0011034791823476553\n",
      "Epoch 4604, Loss: 0.012549543753266335, Final Batch Loss: 0.002980419434607029\n",
      "Epoch 4605, Loss: 0.013461663154885173, Final Batch Loss: 0.011126632802188396\n",
      "Epoch 4606, Loss: 0.013311644492205232, Final Batch Loss: 0.0006085964269004762\n",
      "Epoch 4607, Loss: 0.01019671862013638, Final Batch Loss: 0.003870344953611493\n",
      "Epoch 4608, Loss: 0.011699674651026726, Final Batch Loss: 0.0067529221996665\n",
      "Epoch 4609, Loss: 0.005467182258144021, Final Batch Loss: 0.0022234010975807905\n",
      "Epoch 4610, Loss: 0.018702443689107895, Final Batch Loss: 0.009464532136917114\n",
      "Epoch 4611, Loss: 0.005336896516382694, Final Batch Loss: 0.002598580438643694\n",
      "Epoch 4612, Loss: 0.005900929449126124, Final Batch Loss: 0.0004893320146948099\n",
      "Epoch 4613, Loss: 0.015465914737433195, Final Batch Loss: 0.009802834130823612\n",
      "Epoch 4614, Loss: 0.0234167343005538, Final Batch Loss: 0.004562790505588055\n",
      "Epoch 4615, Loss: 0.022489371011033654, Final Batch Loss: 0.02018049545586109\n",
      "Epoch 4616, Loss: 0.009174339706078172, Final Batch Loss: 0.0012937469873577356\n",
      "Epoch 4617, Loss: 0.025945832021534443, Final Batch Loss: 0.017535587772727013\n",
      "Epoch 4618, Loss: 0.04634066391736269, Final Batch Loss: 0.011381641961634159\n",
      "Epoch 4619, Loss: 0.030107038794085383, Final Batch Loss: 0.02808455564081669\n",
      "Epoch 4620, Loss: 0.010161365615203977, Final Batch Loss: 0.002123989397659898\n",
      "Epoch 4621, Loss: 0.03836733475327492, Final Batch Loss: 0.032348718494176865\n",
      "Epoch 4622, Loss: 0.03832276910543442, Final Batch Loss: 0.02196003869175911\n",
      "Epoch 4623, Loss: 0.007964867632836103, Final Batch Loss: 0.002124394290149212\n",
      "Epoch 4624, Loss: 0.0028101353091187775, Final Batch Loss: 0.00066454365151003\n",
      "Epoch 4625, Loss: 0.006924006389454007, Final Batch Loss: 0.002152603818103671\n",
      "Epoch 4626, Loss: 0.013427936239168048, Final Batch Loss: 0.010347801260650158\n",
      "Epoch 4627, Loss: 0.01792625244706869, Final Batch Loss: 0.008660675957798958\n",
      "Epoch 4628, Loss: 0.009076944552361965, Final Batch Loss: 0.0063506439328193665\n",
      "Epoch 4629, Loss: 0.010021105408668518, Final Batch Loss: 0.006548140663653612\n",
      "Epoch 4630, Loss: 0.0039626468205824494, Final Batch Loss: 0.0020551008637994528\n",
      "Epoch 4631, Loss: 0.014608690747991204, Final Batch Loss: 0.0032008395064622164\n",
      "Epoch 4632, Loss: 0.019081149715930223, Final Batch Loss: 0.012308127246797085\n",
      "Epoch 4633, Loss: 0.04016462434083223, Final Batch Loss: 0.008195490576326847\n",
      "Epoch 4634, Loss: 0.003484678571112454, Final Batch Loss: 0.0014104974688962102\n",
      "Epoch 4635, Loss: 0.007112725870683789, Final Batch Loss: 0.001966379815712571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4636, Loss: 0.020007938146591187, Final Batch Loss: 0.011586233973503113\n",
      "Epoch 4637, Loss: 0.023648980306461453, Final Batch Loss: 0.0034337800461798906\n",
      "Epoch 4638, Loss: 0.006847867276519537, Final Batch Loss: 0.002671070396900177\n",
      "Epoch 4639, Loss: 0.021540808491408825, Final Batch Loss: 0.013105571269989014\n",
      "Epoch 4640, Loss: 0.005846044747158885, Final Batch Loss: 0.0027375260833650827\n",
      "Epoch 4641, Loss: 0.009204180096276104, Final Batch Loss: 0.007959497161209583\n",
      "Epoch 4642, Loss: 0.059740811586380005, Final Batch Loss: 0.0206771157681942\n",
      "Epoch 4643, Loss: 0.052603997057303786, Final Batch Loss: 0.050108689814805984\n",
      "Epoch 4644, Loss: 0.01444883900694549, Final Batch Loss: 0.010935347527265549\n",
      "Epoch 4645, Loss: 0.006343226181343198, Final Batch Loss: 0.004584937822073698\n",
      "Epoch 4646, Loss: 0.01729780063033104, Final Batch Loss: 0.010329785756766796\n",
      "Epoch 4647, Loss: 0.030948501080274582, Final Batch Loss: 0.012072199955582619\n",
      "Epoch 4648, Loss: 0.041549666319042444, Final Batch Loss: 0.03977070748806\n",
      "Epoch 4649, Loss: 0.022681737318634987, Final Batch Loss: 0.007394807413220406\n",
      "Epoch 4650, Loss: 0.016774810384958982, Final Batch Loss: 0.007597646210342646\n",
      "Epoch 4651, Loss: 0.006044551497325301, Final Batch Loss: 0.002746495185419917\n",
      "Epoch 4652, Loss: 0.012174923904240131, Final Batch Loss: 0.0072575462982058525\n",
      "Epoch 4653, Loss: 0.02475921157747507, Final Batch Loss: 0.015510648488998413\n",
      "Epoch 4654, Loss: 0.005406405893154442, Final Batch Loss: 0.0013182974653318524\n",
      "Epoch 4655, Loss: 0.02795924129895866, Final Batch Loss: 0.0017028066795319319\n",
      "Epoch 4656, Loss: 0.014312481740489602, Final Batch Loss: 0.003708885284140706\n",
      "Epoch 4657, Loss: 0.02381722116842866, Final Batch Loss: 0.0029898141510784626\n",
      "Epoch 4658, Loss: 0.011910501634702086, Final Batch Loss: 0.008550181984901428\n",
      "Epoch 4659, Loss: 0.02077971096150577, Final Batch Loss: 0.0030721973162144423\n",
      "Epoch 4660, Loss: 0.020904036704450846, Final Batch Loss: 0.005445831920951605\n",
      "Epoch 4661, Loss: 0.006927557289600372, Final Batch Loss: 0.002118936274200678\n",
      "Epoch 4662, Loss: 0.02118096430785954, Final Batch Loss: 0.0025011610705405474\n",
      "Epoch 4663, Loss: 0.0029661828884854913, Final Batch Loss: 0.0011504041031002998\n",
      "Epoch 4664, Loss: 0.008150601526722312, Final Batch Loss: 0.0025529798585921526\n",
      "Epoch 4665, Loss: 0.0037388326600193977, Final Batch Loss: 0.002368928398936987\n",
      "Epoch 4666, Loss: 0.0065536650363355875, Final Batch Loss: 0.002823058282956481\n",
      "Epoch 4667, Loss: 0.004303521243855357, Final Batch Loss: 0.002927053952589631\n",
      "Epoch 4668, Loss: 0.0062241083942353725, Final Batch Loss: 0.004217596724629402\n",
      "Epoch 4669, Loss: 0.028745861491188407, Final Batch Loss: 0.002658849349245429\n",
      "Epoch 4670, Loss: 0.013584390515461564, Final Batch Loss: 0.0037289292085915804\n",
      "Epoch 4671, Loss: 0.006258216861169785, Final Batch Loss: 0.0005473617347888649\n",
      "Epoch 4672, Loss: 0.013022495899349451, Final Batch Loss: 0.005744634196162224\n",
      "Epoch 4673, Loss: 0.002469550003297627, Final Batch Loss: 0.0007609134772792459\n",
      "Epoch 4674, Loss: 0.0018822873826138675, Final Batch Loss: 0.0006807405152358115\n",
      "Epoch 4675, Loss: 0.012406273977831006, Final Batch Loss: 0.009724956005811691\n",
      "Epoch 4676, Loss: 0.03941280208528042, Final Batch Loss: 0.03829769417643547\n",
      "Epoch 4677, Loss: 0.004299604333937168, Final Batch Loss: 0.002869332442060113\n",
      "Epoch 4678, Loss: 0.004588474053889513, Final Batch Loss: 0.0019234775099903345\n",
      "Epoch 4679, Loss: 0.02519065234810114, Final Batch Loss: 0.023108573630452156\n",
      "Epoch 4680, Loss: 0.009155354462563992, Final Batch Loss: 0.0029147728346288204\n",
      "Epoch 4681, Loss: 0.020250975154340267, Final Batch Loss: 0.013925965875387192\n",
      "Epoch 4682, Loss: 0.03039953112602234, Final Batch Loss: 0.022909794002771378\n",
      "Epoch 4683, Loss: 0.006522348150610924, Final Batch Loss: 0.004411662463098764\n",
      "Epoch 4684, Loss: 0.008672325406223536, Final Batch Loss: 0.005085724871605635\n",
      "Epoch 4685, Loss: 0.006719645578414202, Final Batch Loss: 0.004615561570972204\n",
      "Epoch 4686, Loss: 0.008415521122515202, Final Batch Loss: 0.0027571506798267365\n",
      "Epoch 4687, Loss: 0.012987576890736818, Final Batch Loss: 0.010065567679703236\n",
      "Epoch 4688, Loss: 0.012459809891879559, Final Batch Loss: 0.0063027795404195786\n",
      "Epoch 4689, Loss: 0.0170609587803483, Final Batch Loss: 0.0152455298230052\n",
      "Epoch 4690, Loss: 0.011322489706799388, Final Batch Loss: 0.0021337110083550215\n",
      "Epoch 4691, Loss: 0.05032895575277507, Final Batch Loss: 0.04705284908413887\n",
      "Epoch 4692, Loss: 0.011312094517052174, Final Batch Loss: 0.002103629522025585\n",
      "Epoch 4693, Loss: 0.005347675993107259, Final Batch Loss: 0.0011854962212964892\n",
      "Epoch 4694, Loss: 0.00653158692875877, Final Batch Loss: 0.0006775516667403281\n",
      "Epoch 4695, Loss: 0.004582651425153017, Final Batch Loss: 0.0017770843114703894\n",
      "Epoch 4696, Loss: 0.020609881728887558, Final Batch Loss: 0.011899466626346111\n",
      "Epoch 4697, Loss: 0.026504586450755596, Final Batch Loss: 0.01841539703309536\n",
      "Epoch 4698, Loss: 0.03076300211250782, Final Batch Loss: 0.01198912039399147\n",
      "Epoch 4699, Loss: 0.04155227914452553, Final Batch Loss: 0.02706490457057953\n",
      "Epoch 4700, Loss: 0.01047993404790759, Final Batch Loss: 0.008229752071201801\n",
      "Epoch 4701, Loss: 0.02316612098366022, Final Batch Loss: 0.01918373815715313\n",
      "Epoch 4702, Loss: 0.045217487029731274, Final Batch Loss: 0.03959618881344795\n",
      "Epoch 4703, Loss: 0.03782192803919315, Final Batch Loss: 0.004462061449885368\n",
      "Epoch 4704, Loss: 0.030417259666137397, Final Batch Loss: 0.0018312073079869151\n",
      "Epoch 4705, Loss: 0.012304964940994978, Final Batch Loss: 0.002829252276569605\n",
      "Epoch 4706, Loss: 0.009808656992390752, Final Batch Loss: 0.0032439178321510553\n",
      "Epoch 4707, Loss: 0.00574947870336473, Final Batch Loss: 0.0020175818353891373\n",
      "Epoch 4708, Loss: 0.0177899650298059, Final Batch Loss: 0.015001420862972736\n",
      "Epoch 4709, Loss: 0.04222476156428456, Final Batch Loss: 0.0029006716795265675\n",
      "Epoch 4710, Loss: 0.018014407600276172, Final Batch Loss: 0.0013914023293182254\n",
      "Epoch 4711, Loss: 0.038357171695679426, Final Batch Loss: 0.03359527513384819\n",
      "Epoch 4712, Loss: 0.012446013279259205, Final Batch Loss: 0.0009634103626012802\n",
      "Epoch 4713, Loss: 0.026576890086289495, Final Batch Loss: 0.000965429877396673\n",
      "Epoch 4714, Loss: 0.011638135649263859, Final Batch Loss: 0.002376176416873932\n",
      "Epoch 4715, Loss: 0.1088460348546505, Final Batch Loss: 0.06889665871858597\n",
      "Epoch 4716, Loss: 0.05555533990263939, Final Batch Loss: 0.014734283089637756\n",
      "Epoch 4717, Loss: 0.03542036935687065, Final Batch Loss: 0.025858936831355095\n",
      "Epoch 4718, Loss: 0.0063888245495036244, Final Batch Loss: 0.0017778478795662522\n",
      "Epoch 4719, Loss: 0.031009528785943985, Final Batch Loss: 0.006686585023999214\n",
      "Epoch 4720, Loss: 0.01905198348686099, Final Batch Loss: 0.0073012481443583965\n",
      "Epoch 4721, Loss: 0.06857768632471561, Final Batch Loss: 0.02959430404007435\n",
      "Epoch 4722, Loss: 0.02204993972554803, Final Batch Loss: 0.01999935321509838\n",
      "Epoch 4723, Loss: 0.0427262969315052, Final Batch Loss: 0.008137039840221405\n",
      "Epoch 4724, Loss: 0.0634391400963068, Final Batch Loss: 0.0513199120759964\n",
      "Epoch 4725, Loss: 0.023629716597497463, Final Batch Loss: 0.004843332804739475\n",
      "Epoch 4726, Loss: 0.015436726622283459, Final Batch Loss: 0.0085788294672966\n",
      "Epoch 4727, Loss: 0.03600003058090806, Final Batch Loss: 0.032620757818222046\n",
      "Epoch 4728, Loss: 0.008385908440686762, Final Batch Loss: 0.0012659310596063733\n",
      "Epoch 4729, Loss: 0.02134901937097311, Final Batch Loss: 0.007763137109577656\n",
      "Epoch 4730, Loss: 0.031413462944328785, Final Batch Loss: 0.00534569937735796\n",
      "Epoch 4731, Loss: 0.009241046383976936, Final Batch Loss: 0.004961170256137848\n",
      "Epoch 4732, Loss: 0.018682223744690418, Final Batch Loss: 0.0041145021095871925\n",
      "Epoch 4733, Loss: 0.057804391952231526, Final Batch Loss: 0.05564887821674347\n",
      "Epoch 4734, Loss: 0.02597480604890734, Final Batch Loss: 0.024062231183052063\n",
      "Epoch 4735, Loss: 0.03311464563012123, Final Batch Loss: 0.019910871982574463\n",
      "Epoch 4736, Loss: 0.01017301483079791, Final Batch Loss: 0.0058179995976388454\n",
      "Epoch 4737, Loss: 0.010756964678876102, Final Batch Loss: 0.001757497782818973\n",
      "Epoch 4738, Loss: 0.03454067092388868, Final Batch Loss: 0.029202384874224663\n",
      "Epoch 4739, Loss: 0.02475594461429864, Final Batch Loss: 0.023111604154109955\n",
      "Epoch 4740, Loss: 0.028027627617120743, Final Batch Loss: 0.00955892913043499\n",
      "Epoch 4741, Loss: 0.016130901174619794, Final Batch Loss: 0.0023314182180911303\n",
      "Epoch 4742, Loss: 0.014381245709955692, Final Batch Loss: 0.005945957265794277\n",
      "Epoch 4743, Loss: 0.014820515410974622, Final Batch Loss: 0.0010335969273000956\n",
      "Epoch 4744, Loss: 0.005734828417189419, Final Batch Loss: 0.004500926472246647\n",
      "Epoch 4745, Loss: 0.01727164094336331, Final Batch Loss: 0.0021710351575165987\n",
      "Epoch 4746, Loss: 0.087774419458583, Final Batch Loss: 0.08577803522348404\n",
      "Epoch 4747, Loss: 0.018710652133449912, Final Batch Loss: 0.0036591782700270414\n",
      "Epoch 4748, Loss: 0.006952172494493425, Final Batch Loss: 0.0019407285144552588\n",
      "Epoch 4749, Loss: 0.04111797176301479, Final Batch Loss: 0.02496519312262535\n",
      "Epoch 4750, Loss: 0.0672929622232914, Final Batch Loss: 0.0472428984940052\n",
      "Epoch 4751, Loss: 0.06867989711463451, Final Batch Loss: 0.023889930918812752\n",
      "Epoch 4752, Loss: 0.016156518133357167, Final Batch Loss: 0.014302230440080166\n",
      "Epoch 4753, Loss: 0.012091718846932054, Final Batch Loss: 0.001877309987321496\n",
      "Epoch 4754, Loss: 0.010482545010745525, Final Batch Loss: 0.001269032247364521\n",
      "Epoch 4755, Loss: 0.08620196091942489, Final Batch Loss: 0.08385328948497772\n",
      "Epoch 4756, Loss: 0.01901419088244438, Final Batch Loss: 0.014540021307766438\n",
      "Epoch 4757, Loss: 0.01906434167176485, Final Batch Loss: 0.010621475987136364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4758, Loss: 0.004701707977801561, Final Batch Loss: 0.0019177959766238928\n",
      "Epoch 4759, Loss: 0.006978976773098111, Final Batch Loss: 0.005080223549157381\n",
      "Epoch 4760, Loss: 0.022251573391258717, Final Batch Loss: 0.009685438126325607\n",
      "Epoch 4761, Loss: 0.02118811011314392, Final Batch Loss: 0.002005636692047119\n",
      "Epoch 4762, Loss: 0.011191463330760598, Final Batch Loss: 0.007343009114265442\n",
      "Epoch 4763, Loss: 0.024136709980666637, Final Batch Loss: 0.004278651438653469\n",
      "Epoch 4764, Loss: 0.026221216772682965, Final Batch Loss: 0.0015578950988128781\n",
      "Epoch 4765, Loss: 0.008802372321952134, Final Batch Loss: 0.0007952938904054463\n",
      "Epoch 4766, Loss: 0.06472305534407496, Final Batch Loss: 0.004693056922405958\n",
      "Epoch 4767, Loss: 0.09225944057106972, Final Batch Loss: 0.049842510372400284\n",
      "Epoch 4768, Loss: 0.015412418637424707, Final Batch Loss: 0.004521663766354322\n",
      "Epoch 4769, Loss: 0.01562781515531242, Final Batch Loss: 0.0013790854718536139\n",
      "Epoch 4770, Loss: 0.00754098454490304, Final Batch Loss: 0.0026633664965629578\n",
      "Epoch 4771, Loss: 0.009881885256618261, Final Batch Loss: 0.0024183043278753757\n",
      "Epoch 4772, Loss: 0.008639812236651778, Final Batch Loss: 0.0035290869418531656\n",
      "Epoch 4773, Loss: 0.03356462670490146, Final Batch Loss: 0.00415606377646327\n",
      "Epoch 4774, Loss: 0.009784482419490814, Final Batch Loss: 0.004153307061642408\n",
      "Epoch 4775, Loss: 0.04229602124541998, Final Batch Loss: 0.005801177583634853\n",
      "Epoch 4776, Loss: 0.009873801609501243, Final Batch Loss: 0.006615076679736376\n",
      "Epoch 4777, Loss: 0.04893335700035095, Final Batch Loss: 0.04052549973130226\n",
      "Epoch 4778, Loss: 0.008026438765227795, Final Batch Loss: 0.00442701019346714\n",
      "Epoch 4779, Loss: 0.039410349912941456, Final Batch Loss: 0.006230716593563557\n",
      "Epoch 4780, Loss: 0.007717853179201484, Final Batch Loss: 0.001373486826196313\n",
      "Epoch 4781, Loss: 0.025298723950982094, Final Batch Loss: 0.020200330764055252\n",
      "Epoch 4782, Loss: 0.012152432929724455, Final Batch Loss: 0.01038285531103611\n",
      "Epoch 4783, Loss: 0.014704110217280686, Final Batch Loss: 0.013251529075205326\n",
      "Epoch 4784, Loss: 0.0042390774469822645, Final Batch Loss: 0.0020660569425672293\n",
      "Epoch 4785, Loss: 0.009060661657713354, Final Batch Loss: 0.007924766279757023\n",
      "Epoch 4786, Loss: 0.0435919682495296, Final Batch Loss: 0.003914206754416227\n",
      "Epoch 4787, Loss: 0.03711777785792947, Final Batch Loss: 0.003292588982731104\n",
      "Epoch 4788, Loss: 0.004320625215768814, Final Batch Loss: 0.0010438752360641956\n",
      "Epoch 4789, Loss: 0.011158489040099084, Final Batch Loss: 0.001931039965711534\n",
      "Epoch 4790, Loss: 0.015466879587620497, Final Batch Loss: 0.006697056349366903\n",
      "Epoch 4791, Loss: 0.016407922375947237, Final Batch Loss: 0.0014849244616925716\n",
      "Epoch 4792, Loss: 0.009595006704330444, Final Batch Loss: 0.004185103345662355\n",
      "Epoch 4793, Loss: 0.013007221976295114, Final Batch Loss: 0.0024260294158011675\n",
      "Epoch 4794, Loss: 0.010510436724871397, Final Batch Loss: 0.0012052846141159534\n",
      "Epoch 4795, Loss: 0.03413461218588054, Final Batch Loss: 0.031188784167170525\n",
      "Epoch 4796, Loss: 0.008359614061191678, Final Batch Loss: 0.0031922294292598963\n",
      "Epoch 4797, Loss: 0.008594053331762552, Final Batch Loss: 0.0013752314262092113\n",
      "Epoch 4798, Loss: 0.05821837671101093, Final Batch Loss: 0.03647448495030403\n",
      "Epoch 4799, Loss: 0.007176526472903788, Final Batch Loss: 0.0016384540358558297\n",
      "Epoch 4800, Loss: 0.004860301734879613, Final Batch Loss: 0.0023972715716809034\n",
      "Epoch 4801, Loss: 0.0067236318718642, Final Batch Loss: 0.0035111538600176573\n",
      "Epoch 4802, Loss: 0.009116474393522367, Final Batch Loss: 0.0002707334642764181\n",
      "Epoch 4803, Loss: 0.02474442298989743, Final Batch Loss: 0.001591000589542091\n",
      "Epoch 4804, Loss: 0.022162269800901413, Final Batch Loss: 0.01625937409698963\n",
      "Epoch 4805, Loss: 0.02669512154534459, Final Batch Loss: 0.025469815358519554\n",
      "Epoch 4806, Loss: 0.013957498595118523, Final Batch Loss: 0.00977869052439928\n",
      "Epoch 4807, Loss: 0.007591957459226251, Final Batch Loss: 0.001994589576497674\n",
      "Epoch 4808, Loss: 0.02154640667140484, Final Batch Loss: 0.006394336931407452\n",
      "Epoch 4809, Loss: 0.042583770118653774, Final Batch Loss: 0.03321162983775139\n",
      "Epoch 4810, Loss: 0.012183154234662652, Final Batch Loss: 0.002102628583088517\n",
      "Epoch 4811, Loss: 0.016391879878938198, Final Batch Loss: 0.008274092338979244\n",
      "Epoch 4812, Loss: 0.08272649347782135, Final Batch Loss: 0.06566861271858215\n",
      "Epoch 4813, Loss: 0.00843721441924572, Final Batch Loss: 0.006209584418684244\n",
      "Epoch 4814, Loss: 0.18090204149484634, Final Batch Loss: 0.09942197799682617\n",
      "Epoch 4815, Loss: 0.03134841984137893, Final Batch Loss: 0.0019956021569669247\n",
      "Epoch 4816, Loss: 0.127005934715271, Final Batch Loss: 0.08011196553707123\n",
      "Epoch 4817, Loss: 0.00781545671634376, Final Batch Loss: 0.0019538390915840864\n",
      "Epoch 4818, Loss: 0.017758482601493597, Final Batch Loss: 0.012320269830524921\n",
      "Epoch 4819, Loss: 0.024249149253591895, Final Batch Loss: 0.0014857219066470861\n",
      "Epoch 4820, Loss: 0.0257379449903965, Final Batch Loss: 0.01787148043513298\n",
      "Epoch 4821, Loss: 0.025070181116461754, Final Batch Loss: 0.004750097170472145\n",
      "Epoch 4822, Loss: 0.019468944519758224, Final Batch Loss: 0.007817492820322514\n",
      "Epoch 4823, Loss: 0.03968940768390894, Final Batch Loss: 0.026973925530910492\n",
      "Epoch 4824, Loss: 0.031240602023899555, Final Batch Loss: 0.021956361830234528\n",
      "Epoch 4825, Loss: 0.018709285650402308, Final Batch Loss: 0.002893144730478525\n",
      "Epoch 4826, Loss: 0.03378976508975029, Final Batch Loss: 0.02081148698925972\n",
      "Epoch 4827, Loss: 0.022001336328685284, Final Batch Loss: 0.01680690422654152\n",
      "Epoch 4828, Loss: 0.06412237323820591, Final Batch Loss: 0.03673182800412178\n",
      "Epoch 4829, Loss: 0.03733963333070278, Final Batch Loss: 0.03053670935332775\n",
      "Epoch 4830, Loss: 0.014317367691546679, Final Batch Loss: 0.009025821462273598\n",
      "Epoch 4831, Loss: 0.01804437581449747, Final Batch Loss: 0.008616103790700436\n",
      "Epoch 4832, Loss: 0.011430155951529741, Final Batch Loss: 0.005791822914034128\n",
      "Epoch 4833, Loss: 0.02273266389966011, Final Batch Loss: 0.0038354303687810898\n",
      "Epoch 4834, Loss: 0.011032437905669212, Final Batch Loss: 0.003551214002072811\n",
      "Epoch 4835, Loss: 0.08663362637162209, Final Batch Loss: 0.040097422897815704\n",
      "Epoch 4836, Loss: 0.018840271048247814, Final Batch Loss: 0.0031310608610510826\n",
      "Epoch 4837, Loss: 0.010823940392583609, Final Batch Loss: 0.005322003737092018\n",
      "Epoch 4838, Loss: 0.033351427875459194, Final Batch Loss: 0.009079049341380596\n",
      "Epoch 4839, Loss: 0.027540625538676977, Final Batch Loss: 0.006403728853911161\n",
      "Epoch 4840, Loss: 0.009280731668695807, Final Batch Loss: 0.002947387518361211\n",
      "Epoch 4841, Loss: 0.028680900111794472, Final Batch Loss: 0.0183724258095026\n",
      "Epoch 4842, Loss: 0.026659524999558926, Final Batch Loss: 0.002828315831720829\n",
      "Epoch 4843, Loss: 0.08216384053230286, Final Batch Loss: 0.05476095899939537\n",
      "Epoch 4844, Loss: 0.08691040799021721, Final Batch Loss: 0.04494966194033623\n",
      "Epoch 4845, Loss: 0.03324838378466666, Final Batch Loss: 0.030046015977859497\n",
      "Epoch 4846, Loss: 0.06573212333023548, Final Batch Loss: 0.020089691504836082\n",
      "Epoch 4847, Loss: 0.015216173604130745, Final Batch Loss: 0.004926432855427265\n",
      "Epoch 4848, Loss: 0.008879713714122772, Final Batch Loss: 0.00396799435839057\n",
      "Epoch 4849, Loss: 0.05250182934105396, Final Batch Loss: 0.028687573969364166\n",
      "Epoch 4850, Loss: 0.07545726839452982, Final Batch Loss: 0.06170723959803581\n",
      "Epoch 4851, Loss: 0.06592852156609297, Final Batch Loss: 0.012665252201259136\n",
      "Epoch 4852, Loss: 0.01495787175372243, Final Batch Loss: 0.008821917697787285\n",
      "Epoch 4853, Loss: 0.024633734952658415, Final Batch Loss: 0.007494512479752302\n",
      "Epoch 4854, Loss: 0.0731801688671112, Final Batch Loss: 0.04958827793598175\n",
      "Epoch 4855, Loss: 0.032132328022271395, Final Batch Loss: 0.006938945967704058\n",
      "Epoch 4856, Loss: 0.04087959695607424, Final Batch Loss: 0.027362262830138206\n",
      "Epoch 4857, Loss: 0.05464346706867218, Final Batch Loss: 0.028393466025590897\n",
      "Epoch 4858, Loss: 0.045711858198046684, Final Batch Loss: 0.024478796869516373\n",
      "Epoch 4859, Loss: 0.03599811065942049, Final Batch Loss: 0.008367831818759441\n",
      "Epoch 4860, Loss: 0.02969954814761877, Final Batch Loss: 0.019224314019083977\n",
      "Epoch 4861, Loss: 0.07128113764338195, Final Batch Loss: 0.0016877304296940565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4862, Loss: 0.016244729049503803, Final Batch Loss: 0.007596238516271114\n",
      "Epoch 4863, Loss: 0.04433456528931856, Final Batch Loss: 0.0308554545044899\n",
      "Epoch 4864, Loss: 0.015158727299422026, Final Batch Loss: 0.01045982725918293\n",
      "Epoch 4865, Loss: 0.014957851031795144, Final Batch Loss: 0.0033519614953547716\n",
      "Epoch 4866, Loss: 0.028806244488805532, Final Batch Loss: 0.005825288128107786\n",
      "Epoch 4867, Loss: 0.04915686044842005, Final Batch Loss: 0.010366496630012989\n",
      "Epoch 4868, Loss: 0.023621912114322186, Final Batch Loss: 0.008178194053471088\n",
      "Epoch 4869, Loss: 0.011600707424804568, Final Batch Loss: 0.008945947512984276\n",
      "Epoch 4870, Loss: 0.011358925607055426, Final Batch Loss: 0.005365427117794752\n",
      "Epoch 4871, Loss: 0.03298854664899409, Final Batch Loss: 0.003693331265822053\n",
      "Epoch 4872, Loss: 0.037916405126452446, Final Batch Loss: 0.022668709978461266\n",
      "Epoch 4873, Loss: 0.0714238379150629, Final Batch Loss: 0.05460754409432411\n",
      "Epoch 4874, Loss: 0.03637258801609278, Final Batch Loss: 0.01393911149352789\n",
      "Epoch 4875, Loss: 0.008351019117981195, Final Batch Loss: 0.0015071132220327854\n",
      "Epoch 4876, Loss: 0.013105018995702267, Final Batch Loss: 0.00607135659083724\n",
      "Epoch 4877, Loss: 0.016905630473047495, Final Batch Loss: 0.004245015326887369\n",
      "Epoch 4878, Loss: 0.059717681258916855, Final Batch Loss: 0.04119578376412392\n",
      "Epoch 4879, Loss: 0.009292018599808216, Final Batch Loss: 0.005672919098287821\n",
      "Epoch 4880, Loss: 0.014935692539438605, Final Batch Loss: 0.011135652661323547\n",
      "Epoch 4881, Loss: 0.008895786246284842, Final Batch Loss: 0.002356510376557708\n",
      "Epoch 4882, Loss: 0.013602565275505185, Final Batch Loss: 0.0026619744021445513\n",
      "Epoch 4883, Loss: 0.0035062452079728246, Final Batch Loss: 0.000985184102319181\n",
      "Epoch 4884, Loss: 0.021613152464851737, Final Batch Loss: 0.018006620928645134\n",
      "Epoch 4885, Loss: 0.008709608344361186, Final Batch Loss: 0.005433287471532822\n",
      "Epoch 4886, Loss: 0.013311682734638453, Final Batch Loss: 0.0028597223572432995\n",
      "Epoch 4887, Loss: 0.010471310000866652, Final Batch Loss: 0.00617603724822402\n",
      "Epoch 4888, Loss: 0.025165198370814323, Final Batch Loss: 0.007110586389899254\n",
      "Epoch 4889, Loss: 0.0033621726324781775, Final Batch Loss: 0.001688447897322476\n",
      "Epoch 4890, Loss: 0.008368386421352625, Final Batch Loss: 0.006257998291403055\n",
      "Epoch 4891, Loss: 0.028124846518039703, Final Batch Loss: 0.01737554557621479\n",
      "Epoch 4892, Loss: 0.012332622427493334, Final Batch Loss: 0.005326795857399702\n",
      "Epoch 4893, Loss: 0.02893322939053178, Final Batch Loss: 0.023574965074658394\n",
      "Epoch 4894, Loss: 0.03416412370279431, Final Batch Loss: 0.028645971789956093\n",
      "Epoch 4895, Loss: 0.005548658431507647, Final Batch Loss: 0.001160642714239657\n",
      "Epoch 4896, Loss: 0.027874778024852276, Final Batch Loss: 0.018388401716947556\n",
      "Epoch 4897, Loss: 0.016351935919374228, Final Batch Loss: 0.008837703615427017\n",
      "Epoch 4898, Loss: 0.05317867128178477, Final Batch Loss: 0.05066683515906334\n",
      "Epoch 4899, Loss: 0.014007137855514884, Final Batch Loss: 0.0031895253341645002\n",
      "Epoch 4900, Loss: 0.010897858766838908, Final Batch Loss: 0.0014342020731419325\n",
      "Epoch 4901, Loss: 0.03852114640176296, Final Batch Loss: 0.03431888669729233\n",
      "Epoch 4902, Loss: 0.009081281954422593, Final Batch Loss: 0.005871511064469814\n",
      "Epoch 4903, Loss: 0.018718191189691424, Final Batch Loss: 0.0023356310557574034\n",
      "Epoch 4904, Loss: 0.03426645137369633, Final Batch Loss: 0.03188272938132286\n",
      "Epoch 4905, Loss: 0.023814450949430466, Final Batch Loss: 0.006063137203454971\n",
      "Epoch 4906, Loss: 0.024787195958197117, Final Batch Loss: 0.00679944921284914\n",
      "Epoch 4907, Loss: 0.036582114174962044, Final Batch Loss: 0.029309947043657303\n",
      "Epoch 4908, Loss: 0.02781092608347535, Final Batch Loss: 0.004668739158660173\n",
      "Epoch 4909, Loss: 0.020897192880511284, Final Batch Loss: 0.0019891969859600067\n",
      "Epoch 4910, Loss: 0.008465328719466925, Final Batch Loss: 0.004091245122253895\n",
      "Epoch 4911, Loss: 0.007308211177587509, Final Batch Loss: 0.0016592894680798054\n",
      "Epoch 4912, Loss: 0.021597733721137047, Final Batch Loss: 0.015014583244919777\n",
      "Epoch 4913, Loss: 0.06913140276446939, Final Batch Loss: 0.06377092003822327\n",
      "Epoch 4914, Loss: 0.015562210697680712, Final Batch Loss: 0.003813748713582754\n",
      "Epoch 4915, Loss: 0.0048282823991030455, Final Batch Loss: 0.0024003377184271812\n",
      "Epoch 4916, Loss: 0.007413908140733838, Final Batch Loss: 0.003576158545911312\n",
      "Epoch 4917, Loss: 0.03476507915183902, Final Batch Loss: 0.005340383853763342\n",
      "Epoch 4918, Loss: 0.02423345996066928, Final Batch Loss: 0.0026151048950850964\n",
      "Epoch 4919, Loss: 0.015502297086641192, Final Batch Loss: 0.013887318782508373\n",
      "Epoch 4920, Loss: 0.00902513973414898, Final Batch Loss: 0.0022900905460119247\n",
      "Epoch 4921, Loss: 0.03319409675896168, Final Batch Loss: 0.030005455017089844\n",
      "Epoch 4922, Loss: 0.019091042107902467, Final Batch Loss: 0.0015752393519505858\n",
      "Epoch 4923, Loss: 0.01025072019547224, Final Batch Loss: 0.006904476322233677\n",
      "Epoch 4924, Loss: 0.015782716684043407, Final Batch Loss: 0.00687741581350565\n",
      "Epoch 4925, Loss: 0.03302320768125355, Final Batch Loss: 0.030046366155147552\n",
      "Epoch 4926, Loss: 0.002219185815192759, Final Batch Loss: 0.0011909141903743148\n",
      "Epoch 4927, Loss: 0.01795121468603611, Final Batch Loss: 0.013189711607992649\n",
      "Epoch 4928, Loss: 0.018632862018421292, Final Batch Loss: 0.001988836796954274\n",
      "Epoch 4929, Loss: 0.0096553775947541, Final Batch Loss: 0.0027250193525105715\n",
      "Epoch 4930, Loss: 0.006480685900896788, Final Batch Loss: 0.003841391298919916\n",
      "Epoch 4931, Loss: 0.020468512549996376, Final Batch Loss: 0.013009273447096348\n",
      "Epoch 4932, Loss: 0.015813983976840973, Final Batch Loss: 0.010258866474032402\n",
      "Epoch 4933, Loss: 0.05097880493849516, Final Batch Loss: 0.04630836099386215\n",
      "Epoch 4934, Loss: 0.018915676046162844, Final Batch Loss: 0.0020425808615982533\n",
      "Epoch 4935, Loss: 0.014156661927700043, Final Batch Loss: 0.009401070885360241\n",
      "Epoch 4936, Loss: 0.022361794370226562, Final Batch Loss: 0.0016369445947930217\n",
      "Epoch 4937, Loss: 0.009054283844307065, Final Batch Loss: 0.00764700910076499\n",
      "Epoch 4938, Loss: 0.008234343200456351, Final Batch Loss: 0.0006828789482824504\n",
      "Epoch 4939, Loss: 0.006332146702334285, Final Batch Loss: 0.0017573817167431116\n",
      "Epoch 4940, Loss: 0.0031015874701552093, Final Batch Loss: 0.0009701940580271184\n",
      "Epoch 4941, Loss: 0.017888642847537994, Final Batch Loss: 0.004160539247095585\n",
      "Epoch 4942, Loss: 0.04023830872029066, Final Batch Loss: 0.027321308851242065\n",
      "Epoch 4943, Loss: 0.0450405552983284, Final Batch Loss: 0.023704245686531067\n",
      "Epoch 4944, Loss: 0.017841594759374857, Final Batch Loss: 0.005114443134516478\n",
      "Epoch 4945, Loss: 0.00608887686394155, Final Batch Loss: 0.0044181738048791885\n",
      "Epoch 4946, Loss: 0.004375760443508625, Final Batch Loss: 0.002164556412026286\n",
      "Epoch 4947, Loss: 0.018433852586895227, Final Batch Loss: 0.0027884715236723423\n",
      "Epoch 4948, Loss: 0.021277734078466892, Final Batch Loss: 0.008487049490213394\n",
      "Epoch 4949, Loss: 0.04232844337821007, Final Batch Loss: 0.0194175336509943\n",
      "Epoch 4950, Loss: 0.017842345172539353, Final Batch Loss: 0.01687011495232582\n",
      "Epoch 4951, Loss: 0.00560958287678659, Final Batch Loss: 0.0030309271533042192\n",
      "Epoch 4952, Loss: 0.02238118159584701, Final Batch Loss: 0.0024727031122893095\n",
      "Epoch 4953, Loss: 0.005853215232491493, Final Batch Loss: 0.0021145581267774105\n",
      "Epoch 4954, Loss: 0.009012023219838738, Final Batch Loss: 0.002391731133684516\n",
      "Epoch 4955, Loss: 0.0318625564686954, Final Batch Loss: 0.0256065484136343\n",
      "Epoch 4956, Loss: 0.030642488040030003, Final Batch Loss: 0.027418531477451324\n",
      "Epoch 4957, Loss: 0.017723094671964645, Final Batch Loss: 0.012989474460482597\n",
      "Epoch 4958, Loss: 0.013460319954901934, Final Batch Loss: 0.0034260121174156666\n",
      "Epoch 4959, Loss: 0.018180507700890303, Final Batch Loss: 0.006911942269653082\n",
      "Epoch 4960, Loss: 0.003198574762791395, Final Batch Loss: 0.001465111505240202\n",
      "Epoch 4961, Loss: 0.008593664970248938, Final Batch Loss: 0.004460886120796204\n",
      "Epoch 4962, Loss: 0.04865417256951332, Final Batch Loss: 0.04493776708841324\n",
      "Epoch 4963, Loss: 0.030649091582745314, Final Batch Loss: 0.026044053956866264\n",
      "Epoch 4964, Loss: 0.009176702937111259, Final Batch Loss: 0.00264273420907557\n",
      "Epoch 4965, Loss: 0.010204764956142753, Final Batch Loss: 0.000586317793931812\n",
      "Epoch 4966, Loss: 0.0067246288526803255, Final Batch Loss: 0.002748955739662051\n",
      "Epoch 4967, Loss: 0.019691577879711986, Final Batch Loss: 0.0022068496327847242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4968, Loss: 0.004954255651682615, Final Batch Loss: 0.002383920829743147\n",
      "Epoch 4969, Loss: 0.01335341646336019, Final Batch Loss: 0.009517869912087917\n",
      "Epoch 4970, Loss: 0.03003902267664671, Final Batch Loss: 0.01770259626209736\n",
      "Epoch 4971, Loss: 0.0064284291584044695, Final Batch Loss: 0.0024709540884941816\n",
      "Epoch 4972, Loss: 0.011616265401244164, Final Batch Loss: 0.005677294451743364\n",
      "Epoch 4973, Loss: 0.0036007246235385537, Final Batch Loss: 0.002196867950260639\n",
      "Epoch 4974, Loss: 0.027657060883939266, Final Batch Loss: 0.00972015131264925\n",
      "Epoch 4975, Loss: 0.1287003622855991, Final Batch Loss: 0.1253066509962082\n",
      "Epoch 4976, Loss: 0.020393821876496077, Final Batch Loss: 0.014614471234381199\n",
      "Epoch 4977, Loss: 0.034222675720229745, Final Batch Loss: 0.03196163475513458\n",
      "Epoch 4978, Loss: 0.04183564893901348, Final Batch Loss: 0.0226623322814703\n",
      "Epoch 4979, Loss: 0.03334359638392925, Final Batch Loss: 0.006735626608133316\n",
      "Epoch 4980, Loss: 0.024334612535312772, Final Batch Loss: 0.0030758411157876253\n",
      "Epoch 4981, Loss: 0.02761106425896287, Final Batch Loss: 0.022235648706555367\n",
      "Epoch 4982, Loss: 0.025781174656003714, Final Batch Loss: 0.01901198923587799\n",
      "Epoch 4983, Loss: 0.007433925988152623, Final Batch Loss: 0.004259995184838772\n",
      "Epoch 4984, Loss: 0.028281685430556536, Final Batch Loss: 0.021474411711096764\n",
      "Epoch 4985, Loss: 0.10066181421279907, Final Batch Loss: 0.05869334191083908\n",
      "Epoch 4986, Loss: 0.007188780000433326, Final Batch Loss: 0.002347401110455394\n",
      "Epoch 4987, Loss: 0.023060140432789922, Final Batch Loss: 0.021059131249785423\n",
      "Epoch 4988, Loss: 0.03338065161369741, Final Batch Loss: 0.0017311887349933386\n",
      "Epoch 4989, Loss: 0.006120918085798621, Final Batch Loss: 0.003954178653657436\n",
      "Epoch 4990, Loss: 0.03212465415708721, Final Batch Loss: 0.002223540795966983\n",
      "Epoch 4991, Loss: 0.007735108956694603, Final Batch Loss: 0.0034641604870557785\n",
      "Epoch 4992, Loss: 0.009354020148748532, Final Batch Loss: 0.00046574664884246886\n",
      "Epoch 4993, Loss: 0.022531529888510704, Final Batch Loss: 0.0017480794340372086\n",
      "Epoch 4994, Loss: 0.03205157467164099, Final Batch Loss: 0.0038972387555986643\n",
      "Epoch 4995, Loss: 0.012610195437446237, Final Batch Loss: 0.009217813611030579\n",
      "Epoch 4996, Loss: 0.005320850759744644, Final Batch Loss: 0.001370824407786131\n",
      "Epoch 4997, Loss: 0.004161287797614932, Final Batch Loss: 0.0009984795469790697\n",
      "Epoch 4998, Loss: 0.030092037748545408, Final Batch Loss: 0.0020449734292924404\n",
      "Epoch 4999, Loss: 0.022753419121727347, Final Batch Loss: 0.001043118303641677\n",
      "Epoch 5000, Loss: 0.006420814199373126, Final Batch Loss: 0.003365227021276951\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0  0]\n",
      " [ 0 36  0]\n",
      " [ 0  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        33\n",
      "           1    1.00000   1.00000   1.00000        36\n",
      "           2    1.00000   1.00000   1.00000        29\n",
      "\n",
      "    accuracy                        1.00000        98\n",
      "   macro avg    1.00000   1.00000   1.00000        98\n",
      "weighted avg    1.00000   1.00000   1.00000        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  0  0]\n",
      " [ 0 28  0]\n",
      " [ 0  0 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        39\n",
      "           1    1.00000   1.00000   1.00000        28\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "\n",
      "    accuracy                        1.00000        98\n",
      "   macro avg    1.00000   1.00000   1.00000        98\n",
      "weighted avg    1.00000   1.00000   1.00000        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
