{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 9)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [19, 21, 22]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.394202470779419, Final Batch Loss: 2.205573797225952\n",
      "Epoch 2, Loss: 4.357257843017578, Final Batch Loss: 2.185246706008911\n",
      "Epoch 3, Loss: 4.31178879737854, Final Batch Loss: 2.131004810333252\n",
      "Epoch 4, Loss: 4.278748989105225, Final Batch Loss: 2.1249706745147705\n",
      "Epoch 5, Loss: 4.256714105606079, Final Batch Loss: 2.1188578605651855\n",
      "Epoch 6, Loss: 4.230982065200806, Final Batch Loss: 2.115166187286377\n",
      "Epoch 7, Loss: 4.189702272415161, Final Batch Loss: 2.07887601852417\n",
      "Epoch 8, Loss: 4.163536787033081, Final Batch Loss: 2.0880982875823975\n",
      "Epoch 9, Loss: 4.124236583709717, Final Batch Loss: 2.0564160346984863\n",
      "Epoch 10, Loss: 4.080570459365845, Final Batch Loss: 2.031066656112671\n",
      "Epoch 11, Loss: 4.032838582992554, Final Batch Loss: 2.0110371112823486\n",
      "Epoch 12, Loss: 3.9785076379776, Final Batch Loss: 1.9885205030441284\n",
      "Epoch 13, Loss: 3.9191973209381104, Final Batch Loss: 1.9540659189224243\n",
      "Epoch 14, Loss: 3.883513927459717, Final Batch Loss: 1.9488691091537476\n",
      "Epoch 15, Loss: 3.787271499633789, Final Batch Loss: 1.8830478191375732\n",
      "Epoch 16, Loss: 3.70695698261261, Final Batch Loss: 1.8421581983566284\n",
      "Epoch 17, Loss: 3.6359612941741943, Final Batch Loss: 1.8065118789672852\n",
      "Epoch 18, Loss: 3.556957721710205, Final Batch Loss: 1.770291805267334\n",
      "Epoch 19, Loss: 3.458395004272461, Final Batch Loss: 1.720072865486145\n",
      "Epoch 20, Loss: 3.380788207054138, Final Batch Loss: 1.711216926574707\n",
      "Epoch 21, Loss: 3.2933294773101807, Final Batch Loss: 1.6328845024108887\n",
      "Epoch 22, Loss: 3.151829957962036, Final Batch Loss: 1.5655195713043213\n",
      "Epoch 23, Loss: 3.0538103580474854, Final Batch Loss: 1.5071762800216675\n",
      "Epoch 24, Loss: 2.936624765396118, Final Batch Loss: 1.4830032587051392\n",
      "Epoch 25, Loss: 2.8676189184188843, Final Batch Loss: 1.4303780794143677\n",
      "Epoch 26, Loss: 2.676722764968872, Final Batch Loss: 1.2787810564041138\n",
      "Epoch 27, Loss: 2.647429585456848, Final Batch Loss: 1.317949891090393\n",
      "Epoch 28, Loss: 2.567017078399658, Final Batch Loss: 1.3243945837020874\n",
      "Epoch 29, Loss: 2.391766667366028, Final Batch Loss: 1.0790164470672607\n",
      "Epoch 30, Loss: 2.372666835784912, Final Batch Loss: 1.1675244569778442\n",
      "Epoch 31, Loss: 2.3448076248168945, Final Batch Loss: 1.1589120626449585\n",
      "Epoch 32, Loss: 2.20865261554718, Final Batch Loss: 1.150381326675415\n",
      "Epoch 33, Loss: 2.197977662086487, Final Batch Loss: 1.0691814422607422\n",
      "Epoch 34, Loss: 2.1287171840667725, Final Batch Loss: 1.078843116760254\n",
      "Epoch 35, Loss: 2.095638871192932, Final Batch Loss: 1.068250060081482\n",
      "Epoch 36, Loss: 2.0715389251708984, Final Batch Loss: 1.0737172365188599\n",
      "Epoch 37, Loss: 1.9953481554985046, Final Batch Loss: 1.0097280740737915\n",
      "Epoch 38, Loss: 1.9459072947502136, Final Batch Loss: 0.8885888457298279\n",
      "Epoch 39, Loss: 1.9733101725578308, Final Batch Loss: 1.061696171760559\n",
      "Epoch 40, Loss: 1.9056507349014282, Final Batch Loss: 1.034896731376648\n",
      "Epoch 41, Loss: 1.8534926772117615, Final Batch Loss: 0.9283359050750732\n",
      "Epoch 42, Loss: 1.8109440803527832, Final Batch Loss: 0.8702367544174194\n",
      "Epoch 43, Loss: 1.781413495540619, Final Batch Loss: 0.889822781085968\n",
      "Epoch 44, Loss: 1.7384364008903503, Final Batch Loss: 0.8778275847434998\n",
      "Epoch 45, Loss: 1.6693271398544312, Final Batch Loss: 0.8011773228645325\n",
      "Epoch 46, Loss: 1.6659398674964905, Final Batch Loss: 0.8424397706985474\n",
      "Epoch 47, Loss: 1.6189799904823303, Final Batch Loss: 0.7829426527023315\n",
      "Epoch 48, Loss: 1.5989863276481628, Final Batch Loss: 0.837931215763092\n",
      "Epoch 49, Loss: 1.5630349516868591, Final Batch Loss: 0.7621126174926758\n",
      "Epoch 50, Loss: 1.4846003651618958, Final Batch Loss: 0.7340841293334961\n",
      "Epoch 51, Loss: 1.499222457408905, Final Batch Loss: 0.7218718528747559\n",
      "Epoch 52, Loss: 1.3856953978538513, Final Batch Loss: 0.6853517889976501\n",
      "Epoch 53, Loss: 1.353302776813507, Final Batch Loss: 0.6745278239250183\n",
      "Epoch 54, Loss: 1.2523745894432068, Final Batch Loss: 0.6396843194961548\n",
      "Epoch 55, Loss: 1.211192548274994, Final Batch Loss: 0.5813366770744324\n",
      "Epoch 56, Loss: 1.1098324656486511, Final Batch Loss: 0.5506047606468201\n",
      "Epoch 57, Loss: 1.0805695950984955, Final Batch Loss: 0.4908318817615509\n",
      "Epoch 58, Loss: 1.1345764994621277, Final Batch Loss: 0.5914097428321838\n",
      "Epoch 59, Loss: 0.9913963079452515, Final Batch Loss: 0.5214982628822327\n",
      "Epoch 60, Loss: 0.8948651850223541, Final Batch Loss: 0.39981088042259216\n",
      "Epoch 61, Loss: 0.7957322895526886, Final Batch Loss: 0.3774469494819641\n",
      "Epoch 62, Loss: 0.769858717918396, Final Batch Loss: 0.3337196707725525\n",
      "Epoch 63, Loss: 0.7326000332832336, Final Batch Loss: 0.33605140447616577\n",
      "Epoch 64, Loss: 0.6956856548786163, Final Batch Loss: 0.34490445256233215\n",
      "Epoch 65, Loss: 0.6194575130939484, Final Batch Loss: 0.32355213165283203\n",
      "Epoch 66, Loss: 0.5664072632789612, Final Batch Loss: 0.28235289454460144\n",
      "Epoch 67, Loss: 0.4953896552324295, Final Batch Loss: 0.22594629228115082\n",
      "Epoch 68, Loss: 0.43359218537807465, Final Batch Loss: 0.18095983564853668\n",
      "Epoch 69, Loss: 0.5044891387224197, Final Batch Loss: 0.2918129563331604\n",
      "Epoch 70, Loss: 0.44549234211444855, Final Batch Loss: 0.19691939651966095\n",
      "Epoch 71, Loss: 0.41026681661605835, Final Batch Loss: 0.21015414595603943\n",
      "Epoch 72, Loss: 0.40130575001239777, Final Batch Loss: 0.2068045437335968\n",
      "Epoch 73, Loss: 0.31179700791835785, Final Batch Loss: 0.15661482512950897\n",
      "Epoch 74, Loss: 0.341852143406868, Final Batch Loss: 0.1749952733516693\n",
      "Epoch 75, Loss: 0.31530793011188507, Final Batch Loss: 0.15020506083965302\n",
      "Epoch 76, Loss: 0.22872889786958694, Final Batch Loss: 0.08826503902673721\n",
      "Epoch 77, Loss: 0.23641009628772736, Final Batch Loss: 0.11677989363670349\n",
      "Epoch 78, Loss: 0.2390468418598175, Final Batch Loss: 0.103570356965065\n",
      "Epoch 79, Loss: 0.21847838163375854, Final Batch Loss: 0.1108628585934639\n",
      "Epoch 80, Loss: 0.2595621272921562, Final Batch Loss: 0.11378461867570877\n",
      "Epoch 81, Loss: 0.2459951564669609, Final Batch Loss: 0.11749353259801865\n",
      "Epoch 82, Loss: 0.22939985245466232, Final Batch Loss: 0.06860580295324326\n",
      "Epoch 83, Loss: 0.1976274847984314, Final Batch Loss: 0.1226888969540596\n",
      "Epoch 84, Loss: 0.16053763031959534, Final Batch Loss: 0.0703452080488205\n",
      "Epoch 85, Loss: 0.2071869745850563, Final Batch Loss: 0.10823190957307816\n",
      "Epoch 86, Loss: 0.15510481595993042, Final Batch Loss: 0.08616122603416443\n",
      "Epoch 87, Loss: 0.199729822576046, Final Batch Loss: 0.1331125795841217\n",
      "Epoch 88, Loss: 0.19507002085447311, Final Batch Loss: 0.11327047646045685\n",
      "Epoch 89, Loss: 0.18184471875429153, Final Batch Loss: 0.09315593540668488\n",
      "Epoch 90, Loss: 0.198609359562397, Final Batch Loss: 0.12670068442821503\n",
      "Epoch 91, Loss: 0.20082106441259384, Final Batch Loss: 0.06988485902547836\n",
      "Epoch 92, Loss: 0.17606514692306519, Final Batch Loss: 0.0919518917798996\n",
      "Epoch 93, Loss: 0.14124076813459396, Final Batch Loss: 0.0635504424571991\n",
      "Epoch 94, Loss: 0.12727060914039612, Final Batch Loss: 0.04449411481618881\n",
      "Epoch 95, Loss: 0.1164882630109787, Final Batch Loss: 0.054536063224077225\n",
      "Epoch 96, Loss: 0.11304168775677681, Final Batch Loss: 0.04074424132704735\n",
      "Epoch 97, Loss: 0.08768879808485508, Final Batch Loss: 0.0570867694914341\n",
      "Epoch 98, Loss: 0.12777189165353775, Final Batch Loss: 0.07436720281839371\n",
      "Epoch 99, Loss: 0.11633235588669777, Final Batch Loss: 0.050872694700956345\n",
      "Epoch 100, Loss: 0.11895545944571495, Final Batch Loss: 0.053607720881700516\n",
      "Epoch 101, Loss: 0.14163204282522202, Final Batch Loss: 0.08331254869699478\n",
      "Epoch 102, Loss: 0.13171488046646118, Final Batch Loss: 0.04514888674020767\n",
      "Epoch 103, Loss: 0.13939359039068222, Final Batch Loss: 0.07392285764217377\n",
      "Epoch 104, Loss: 0.11405101418495178, Final Batch Loss: 0.06827883422374725\n",
      "Epoch 105, Loss: 0.08266747556626797, Final Batch Loss: 0.025075385347008705\n",
      "Epoch 106, Loss: 0.09119816869497299, Final Batch Loss: 0.045865997672080994\n",
      "Epoch 107, Loss: 0.12019113078713417, Final Batch Loss: 0.06175479665398598\n",
      "Epoch 108, Loss: 0.09541492909193039, Final Batch Loss: 0.047715067863464355\n",
      "Epoch 109, Loss: 0.09343180805444717, Final Batch Loss: 0.048550333827733994\n",
      "Epoch 110, Loss: 0.13013342395424843, Final Batch Loss: 0.048842187970876694\n",
      "Epoch 111, Loss: 0.11430708691477776, Final Batch Loss: 0.05678114295005798\n",
      "Epoch 112, Loss: 0.0622295867651701, Final Batch Loss: 0.02670847438275814\n",
      "Epoch 113, Loss: 0.10039284452795982, Final Batch Loss: 0.06365036964416504\n",
      "Epoch 114, Loss: 0.1035398580133915, Final Batch Loss: 0.033251482993364334\n",
      "Epoch 115, Loss: 0.07869546860456467, Final Batch Loss: 0.023766111582517624\n",
      "Epoch 116, Loss: 0.09444641694426537, Final Batch Loss: 0.03713186830282211\n",
      "Epoch 117, Loss: 0.11568064242601395, Final Batch Loss: 0.0661250650882721\n",
      "Epoch 118, Loss: 0.09413179382681847, Final Batch Loss: 0.06081153824925423\n",
      "Epoch 119, Loss: 0.06704405322670937, Final Batch Loss: 0.03896613046526909\n",
      "Epoch 120, Loss: 0.08208164572715759, Final Batch Loss: 0.04591922461986542\n",
      "Epoch 121, Loss: 0.05384966731071472, Final Batch Loss: 0.014556016772985458\n",
      "Epoch 122, Loss: 0.097965769469738, Final Batch Loss: 0.05990372225642204\n",
      "Epoch 123, Loss: 0.0839868038892746, Final Batch Loss: 0.037016693502664566\n",
      "Epoch 124, Loss: 0.0971132442355156, Final Batch Loss: 0.05636465176939964\n",
      "Epoch 125, Loss: 0.07431741803884506, Final Batch Loss: 0.03869147598743439\n",
      "Epoch 126, Loss: 0.08803462982177734, Final Batch Loss: 0.03229596093297005\n",
      "Epoch 127, Loss: 0.07275235280394554, Final Batch Loss: 0.05462232604622841\n",
      "Epoch 128, Loss: 0.03246618527919054, Final Batch Loss: 0.012433777563273907\n",
      "Epoch 129, Loss: 0.05446404032409191, Final Batch Loss: 0.0165878739207983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, Loss: 0.1098032183945179, Final Batch Loss: 0.04960012435913086\n",
      "Epoch 131, Loss: 0.1265045702457428, Final Batch Loss: 0.07487109303474426\n",
      "Epoch 132, Loss: 0.07904789969325066, Final Batch Loss: 0.032236214727163315\n",
      "Epoch 133, Loss: 0.047276370227336884, Final Batch Loss: 0.02345481514930725\n",
      "Epoch 134, Loss: 0.1188819408416748, Final Batch Loss: 0.06434695422649384\n",
      "Epoch 135, Loss: 0.04550938308238983, Final Batch Loss: 0.028971903026103973\n",
      "Epoch 136, Loss: 0.08053876832127571, Final Batch Loss: 0.03945222869515419\n",
      "Epoch 137, Loss: 0.06890263222157955, Final Batch Loss: 0.042814429849386215\n",
      "Epoch 138, Loss: 0.07337878085672855, Final Batch Loss: 0.023004045709967613\n",
      "Epoch 139, Loss: 0.10244689881801605, Final Batch Loss: 0.07500224560499191\n",
      "Epoch 140, Loss: 0.06244495324790478, Final Batch Loss: 0.020848741754889488\n",
      "Epoch 141, Loss: 0.05512069258838892, Final Batch Loss: 0.015411262400448322\n",
      "Epoch 142, Loss: 0.05992949567735195, Final Batch Loss: 0.023579945787787437\n",
      "Epoch 143, Loss: 0.07563957571983337, Final Batch Loss: 0.035180240869522095\n",
      "Epoch 144, Loss: 0.03269331622868776, Final Batch Loss: 0.014211985282599926\n",
      "Epoch 145, Loss: 0.04212474077939987, Final Batch Loss: 0.011654354631900787\n",
      "Epoch 146, Loss: 0.04141484014689922, Final Batch Loss: 0.014077870175242424\n",
      "Epoch 147, Loss: 0.05042845197021961, Final Batch Loss: 0.025712717324495316\n",
      "Epoch 148, Loss: 0.05129949375987053, Final Batch Loss: 0.021953795105218887\n",
      "Epoch 149, Loss: 0.05255182832479477, Final Batch Loss: 0.026395991444587708\n",
      "Epoch 150, Loss: 0.05265782726928592, Final Batch Loss: 0.007589619141072035\n",
      "Epoch 151, Loss: 0.03232382517307997, Final Batch Loss: 0.019252965226769447\n",
      "Epoch 152, Loss: 0.0812593325972557, Final Batch Loss: 0.05336432904005051\n",
      "Epoch 153, Loss: 0.06945158913731575, Final Batch Loss: 0.0357775054872036\n",
      "Epoch 154, Loss: 0.05767584592103958, Final Batch Loss: 0.02360270917415619\n",
      "Epoch 155, Loss: 0.08052824810147285, Final Batch Loss: 0.052292805165052414\n",
      "Epoch 156, Loss: 0.03786083869636059, Final Batch Loss: 0.01772378385066986\n",
      "Epoch 157, Loss: 0.03139114752411842, Final Batch Loss: 0.021746153011918068\n",
      "Epoch 158, Loss: 0.051999177783727646, Final Batch Loss: 0.027701659128069878\n",
      "Epoch 159, Loss: 0.06792737357318401, Final Batch Loss: 0.04027203470468521\n",
      "Epoch 160, Loss: 0.06358962692320347, Final Batch Loss: 0.04106540232896805\n",
      "Epoch 161, Loss: 0.09875292517244816, Final Batch Loss: 0.07670684903860092\n",
      "Epoch 162, Loss: 0.04565208964049816, Final Batch Loss: 0.021393360570073128\n",
      "Epoch 163, Loss: 0.038478706032037735, Final Batch Loss: 0.01694069616496563\n",
      "Epoch 164, Loss: 0.04584369622170925, Final Batch Loss: 0.025301819667220116\n",
      "Epoch 165, Loss: 0.0802830420434475, Final Batch Loss: 0.04839654639363289\n",
      "Epoch 166, Loss: 0.052258191630244255, Final Batch Loss: 0.018949689343571663\n",
      "Epoch 167, Loss: 0.022917063906788826, Final Batch Loss: 0.008951567113399506\n",
      "Epoch 168, Loss: 0.04837401211261749, Final Batch Loss: 0.016933079808950424\n",
      "Epoch 169, Loss: 0.09924619272351265, Final Batch Loss: 0.08117058128118515\n",
      "Epoch 170, Loss: 0.06650439649820328, Final Batch Loss: 0.04093790799379349\n",
      "Epoch 171, Loss: 0.07941553462296724, Final Batch Loss: 0.014273774810135365\n",
      "Epoch 172, Loss: 0.04546811245381832, Final Batch Loss: 0.03563283011317253\n",
      "Epoch 173, Loss: 0.039497523568570614, Final Batch Loss: 0.02858833596110344\n",
      "Epoch 174, Loss: 0.02457650937139988, Final Batch Loss: 0.009197468869388103\n",
      "Epoch 175, Loss: 0.05717666819691658, Final Batch Loss: 0.03192747011780739\n",
      "Epoch 176, Loss: 0.05089031904935837, Final Batch Loss: 0.02620440535247326\n",
      "Epoch 177, Loss: 0.059106526896357536, Final Batch Loss: 0.031986117362976074\n",
      "Epoch 178, Loss: 0.04317741096019745, Final Batch Loss: 0.01649331860244274\n",
      "Epoch 179, Loss: 0.041121432557702065, Final Batch Loss: 0.022145600989460945\n",
      "Epoch 180, Loss: 0.04640051908791065, Final Batch Loss: 0.024254506453871727\n",
      "Epoch 181, Loss: 0.04413599707186222, Final Batch Loss: 0.019062800332903862\n",
      "Epoch 182, Loss: 0.042041487991809845, Final Batch Loss: 0.018811918795108795\n",
      "Epoch 183, Loss: 0.03329129330813885, Final Batch Loss: 0.01606588624417782\n",
      "Epoch 184, Loss: 0.024792387150228024, Final Batch Loss: 0.004655751399695873\n",
      "Epoch 185, Loss: 0.0279812291264534, Final Batch Loss: 0.01628449186682701\n",
      "Epoch 186, Loss: 0.03940933756530285, Final Batch Loss: 0.017596354708075523\n",
      "Epoch 187, Loss: 0.03338162135332823, Final Batch Loss: 0.019603358581662178\n",
      "Epoch 188, Loss: 0.034304048866033554, Final Batch Loss: 0.004557348787784576\n",
      "Epoch 189, Loss: 0.04722440429031849, Final Batch Loss: 0.020633874461054802\n",
      "Epoch 190, Loss: 0.06973236799240112, Final Batch Loss: 0.02244492620229721\n",
      "Epoch 191, Loss: 0.0790113303810358, Final Batch Loss: 0.027824563905596733\n",
      "Epoch 192, Loss: 0.02492333482950926, Final Batch Loss: 0.006176804192364216\n",
      "Epoch 193, Loss: 0.08661036938428879, Final Batch Loss: 0.06078433245420456\n",
      "Epoch 194, Loss: 0.04400116764008999, Final Batch Loss: 0.016366932541131973\n",
      "Epoch 195, Loss: 0.051090861670672894, Final Batch Loss: 0.00841990765184164\n",
      "Epoch 196, Loss: 0.07528946176171303, Final Batch Loss: 0.03280524164438248\n",
      "Epoch 197, Loss: 0.030433078296482563, Final Batch Loss: 0.017666203901171684\n",
      "Epoch 198, Loss: 0.03452644031494856, Final Batch Loss: 0.008280343376100063\n",
      "Epoch 199, Loss: 0.037053363397717476, Final Batch Loss: 0.013798316940665245\n",
      "Epoch 200, Loss: 0.029260203707963228, Final Batch Loss: 0.007333061192184687\n",
      "Epoch 201, Loss: 0.018654095474630594, Final Batch Loss: 0.011495694518089294\n",
      "Epoch 202, Loss: 0.04377229558303952, Final Batch Loss: 0.006766085047274828\n",
      "Epoch 203, Loss: 0.027931787073612213, Final Batch Loss: 0.012202547863125801\n",
      "Epoch 204, Loss: 0.02909125853329897, Final Batch Loss: 0.012702367268502712\n",
      "Epoch 205, Loss: 0.023786865174770355, Final Batch Loss: 0.007082240656018257\n",
      "Epoch 206, Loss: 0.04122909903526306, Final Batch Loss: 0.011232325807213783\n",
      "Epoch 207, Loss: 0.046419478952884674, Final Batch Loss: 0.022011619061231613\n",
      "Epoch 208, Loss: 0.02804207894951105, Final Batch Loss: 0.01695030741393566\n",
      "Epoch 209, Loss: 0.04021734558045864, Final Batch Loss: 0.019516058266162872\n",
      "Epoch 210, Loss: 0.022585736587643623, Final Batch Loss: 0.012649094685912132\n",
      "Epoch 211, Loss: 0.037797922268509865, Final Batch Loss: 0.02008180320262909\n",
      "Epoch 212, Loss: 0.057449134066700935, Final Batch Loss: 0.015766674652695656\n",
      "Epoch 213, Loss: 0.1083054356276989, Final Batch Loss: 0.07940924167633057\n",
      "Epoch 214, Loss: 0.015302269021049142, Final Batch Loss: 0.003812384093180299\n",
      "Epoch 215, Loss: 0.029502596706151962, Final Batch Loss: 0.016842342913150787\n",
      "Epoch 216, Loss: 0.03961849957704544, Final Batch Loss: 0.030758092179894447\n",
      "Epoch 217, Loss: 0.04144579218700528, Final Batch Loss: 0.03526325151324272\n",
      "Epoch 218, Loss: 0.04423512518405914, Final Batch Loss: 0.010622892528772354\n",
      "Epoch 219, Loss: 0.031946935690939426, Final Batch Loss: 0.00904171634465456\n",
      "Epoch 220, Loss: 0.05630291625857353, Final Batch Loss: 0.023953400552272797\n",
      "Epoch 221, Loss: 0.03614694019779563, Final Batch Loss: 0.006624575238674879\n",
      "Epoch 222, Loss: 0.05042610503733158, Final Batch Loss: 0.024961359798908234\n",
      "Epoch 223, Loss: 0.04308669827878475, Final Batch Loss: 0.006819428876042366\n",
      "Epoch 224, Loss: 0.03611071640625596, Final Batch Loss: 0.004596265498548746\n",
      "Epoch 225, Loss: 0.008403373416513205, Final Batch Loss: 0.0035620625130832195\n",
      "Epoch 226, Loss: 0.0522721353918314, Final Batch Loss: 0.01487455703318119\n",
      "Epoch 227, Loss: 0.05835539475083351, Final Batch Loss: 0.05147319287061691\n",
      "Epoch 228, Loss: 0.043644314631819725, Final Batch Loss: 0.016350427642464638\n",
      "Epoch 229, Loss: 0.021980997640639544, Final Batch Loss: 0.016542743891477585\n",
      "Epoch 230, Loss: 0.01823248900473118, Final Batch Loss: 0.007093676365911961\n",
      "Epoch 231, Loss: 0.04370715469121933, Final Batch Loss: 0.023480892181396484\n",
      "Epoch 232, Loss: 0.02221167739480734, Final Batch Loss: 0.007552050985395908\n",
      "Epoch 233, Loss: 0.019594497978687286, Final Batch Loss: 0.007537868805229664\n",
      "Epoch 234, Loss: 0.02449077507480979, Final Batch Loss: 0.019491208717226982\n",
      "Epoch 235, Loss: 0.017385255079716444, Final Batch Loss: 0.00676922919228673\n",
      "Epoch 236, Loss: 0.025415447540581226, Final Batch Loss: 0.008943931199610233\n",
      "Epoch 237, Loss: 0.03241018485277891, Final Batch Loss: 0.01841663382947445\n",
      "Epoch 238, Loss: 0.04031800664961338, Final Batch Loss: 0.014053784310817719\n",
      "Epoch 239, Loss: 0.0290455911308527, Final Batch Loss: 0.010205511003732681\n",
      "Epoch 240, Loss: 0.01740201935172081, Final Batch Loss: 0.008644117042422295\n",
      "Epoch 241, Loss: 0.020440160762518644, Final Batch Loss: 0.01316525787115097\n",
      "Epoch 242, Loss: 0.01836421899497509, Final Batch Loss: 0.010148651897907257\n",
      "Epoch 243, Loss: 0.04222686402499676, Final Batch Loss: 0.021183712407946587\n",
      "Epoch 244, Loss: 0.08241567201912403, Final Batch Loss: 0.053262338042259216\n",
      "Epoch 245, Loss: 0.03584357397630811, Final Batch Loss: 0.031082089990377426\n",
      "Epoch 246, Loss: 0.022506716661155224, Final Batch Loss: 0.00935456808656454\n",
      "Epoch 247, Loss: 0.014907658565789461, Final Batch Loss: 0.009270885959267616\n",
      "Epoch 248, Loss: 0.024662278592586517, Final Batch Loss: 0.014058554545044899\n",
      "Epoch 249, Loss: 0.015851079486310482, Final Batch Loss: 0.009846661239862442\n",
      "Epoch 250, Loss: 0.01730383187532425, Final Batch Loss: 0.00808656495064497\n",
      "Epoch 251, Loss: 0.024341280106455088, Final Batch Loss: 0.005222611594945192\n",
      "Epoch 252, Loss: 0.03354371199384332, Final Batch Loss: 0.0077072870917618275\n",
      "Epoch 253, Loss: 0.048956725746393204, Final Batch Loss: 0.029274342581629753\n",
      "Epoch 254, Loss: 0.036824483424425125, Final Batch Loss: 0.021750973537564278\n",
      "Epoch 255, Loss: 0.022335307905450463, Final Batch Loss: 0.019259121268987656\n",
      "Epoch 256, Loss: 0.013766350224614143, Final Batch Loss: 0.004120527766644955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257, Loss: 0.011567656649276614, Final Batch Loss: 0.007751177530735731\n",
      "Epoch 258, Loss: 0.060400331392884254, Final Batch Loss: 0.018324779346585274\n",
      "Epoch 259, Loss: 0.02870552521198988, Final Batch Loss: 0.01722678542137146\n",
      "Epoch 260, Loss: 0.0322924992069602, Final Batch Loss: 0.017613403499126434\n",
      "Epoch 261, Loss: 0.02268095314502716, Final Batch Loss: 0.011525110341608524\n",
      "Epoch 262, Loss: 0.0180012877099216, Final Batch Loss: 0.004985131788998842\n",
      "Epoch 263, Loss: 0.018116498365998268, Final Batch Loss: 0.00627164077013731\n",
      "Epoch 264, Loss: 0.017782661132514477, Final Batch Loss: 0.005512449890375137\n",
      "Epoch 265, Loss: 0.03614566707983613, Final Batch Loss: 0.00609084265306592\n",
      "Epoch 266, Loss: 0.011831269599497318, Final Batch Loss: 0.0067364489659667015\n",
      "Epoch 267, Loss: 0.04213560838252306, Final Batch Loss: 0.006118767894804478\n",
      "Epoch 268, Loss: 0.04558846610598266, Final Batch Loss: 0.04197871312499046\n",
      "Epoch 269, Loss: 0.01287505985237658, Final Batch Loss: 0.0030611457768827677\n",
      "Epoch 270, Loss: 0.02028034534305334, Final Batch Loss: 0.004241674207150936\n",
      "Epoch 271, Loss: 0.01519955275580287, Final Batch Loss: 0.007476187776774168\n",
      "Epoch 272, Loss: 0.04726813733577728, Final Batch Loss: 0.024343546479940414\n",
      "Epoch 273, Loss: 0.05812512617558241, Final Batch Loss: 0.04529367387294769\n",
      "Epoch 274, Loss: 0.029012564569711685, Final Batch Loss: 0.017960116267204285\n",
      "Epoch 275, Loss: 0.007837657118216157, Final Batch Loss: 0.004802503157407045\n",
      "Epoch 276, Loss: 0.018450215458869934, Final Batch Loss: 0.00565033033490181\n",
      "Epoch 277, Loss: 0.01782857161015272, Final Batch Loss: 0.00580477062612772\n",
      "Epoch 278, Loss: 0.022609887178987265, Final Batch Loss: 0.005697024520486593\n",
      "Epoch 279, Loss: 0.005935478140600026, Final Batch Loss: 0.0017900035018101335\n",
      "Epoch 280, Loss: 0.02134046144783497, Final Batch Loss: 0.010874707251787186\n",
      "Epoch 281, Loss: 0.012266811216250062, Final Batch Loss: 0.0020493457559496164\n",
      "Epoch 282, Loss: 0.010854997206479311, Final Batch Loss: 0.005222152918577194\n",
      "Epoch 283, Loss: 0.03714694269001484, Final Batch Loss: 0.01568870060145855\n",
      "Epoch 284, Loss: 0.03579965652897954, Final Batch Loss: 0.0073751830495893955\n",
      "Epoch 285, Loss: 0.02420994359999895, Final Batch Loss: 0.02026483789086342\n",
      "Epoch 286, Loss: 0.00908229174092412, Final Batch Loss: 0.004361032508313656\n",
      "Epoch 287, Loss: 0.03028692025691271, Final Batch Loss: 0.014296452514827251\n",
      "Epoch 288, Loss: 0.018145968206226826, Final Batch Loss: 0.009263959713280201\n",
      "Epoch 289, Loss: 0.007321150740608573, Final Batch Loss: 0.003908585757017136\n",
      "Epoch 290, Loss: 0.022418266627937555, Final Batch Loss: 0.01746360771358013\n",
      "Epoch 291, Loss: 0.010073513956740499, Final Batch Loss: 0.007304168306291103\n",
      "Epoch 292, Loss: 0.036125048995018005, Final Batch Loss: 0.007636222988367081\n",
      "Epoch 293, Loss: 0.02585042268037796, Final Batch Loss: 0.017741184681653976\n",
      "Epoch 294, Loss: 0.026405985467135906, Final Batch Loss: 0.004830346442759037\n",
      "Epoch 295, Loss: 0.013643633108586073, Final Batch Loss: 0.004301130305975676\n",
      "Epoch 296, Loss: 0.00814202451147139, Final Batch Loss: 0.0030587336514145136\n",
      "Epoch 297, Loss: 0.007530586561188102, Final Batch Loss: 0.004447947256267071\n",
      "Epoch 298, Loss: 0.01951397769153118, Final Batch Loss: 0.004537477158010006\n",
      "Epoch 299, Loss: 0.011177844367921352, Final Batch Loss: 0.009039949625730515\n",
      "Epoch 300, Loss: 0.011226921807974577, Final Batch Loss: 0.008880757726728916\n",
      "Epoch 301, Loss: 0.01813282212242484, Final Batch Loss: 0.010872938670217991\n",
      "Epoch 302, Loss: 0.015394544461742043, Final Batch Loss: 0.0029601820278912783\n",
      "Epoch 303, Loss: 0.02581989113241434, Final Batch Loss: 0.017736606299877167\n",
      "Epoch 304, Loss: 0.006714800605550408, Final Batch Loss: 0.0034065896179527044\n",
      "Epoch 305, Loss: 0.01901961211115122, Final Batch Loss: 0.014312597922980785\n",
      "Epoch 306, Loss: 0.010834827553480864, Final Batch Loss: 0.003210841678082943\n",
      "Epoch 307, Loss: 0.05045810900628567, Final Batch Loss: 0.034523386508226395\n",
      "Epoch 308, Loss: 0.015215490013360977, Final Batch Loss: 0.01172142755240202\n",
      "Epoch 309, Loss: 0.035433356650173664, Final Batch Loss: 0.015614059753715992\n",
      "Epoch 310, Loss: 0.013412674656137824, Final Batch Loss: 0.003435323713347316\n",
      "Epoch 311, Loss: 0.010437697172164917, Final Batch Loss: 0.003511738032102585\n",
      "Epoch 312, Loss: 0.03059054957702756, Final Batch Loss: 0.005869370419532061\n",
      "Epoch 313, Loss: 0.01776305539533496, Final Batch Loss: 0.00580641021952033\n",
      "Epoch 314, Loss: 0.005217742174863815, Final Batch Loss: 0.002765638055279851\n",
      "Epoch 315, Loss: 0.008977211080491543, Final Batch Loss: 0.004383082501590252\n",
      "Epoch 316, Loss: 0.027480196091346443, Final Batch Loss: 0.02567070722579956\n",
      "Epoch 317, Loss: 0.015359927900135517, Final Batch Loss: 0.006533035077154636\n",
      "Epoch 318, Loss: 0.038364509120583534, Final Batch Loss: 0.034330062568187714\n",
      "Epoch 319, Loss: 0.06557251885533333, Final Batch Loss: 0.057779647409915924\n",
      "Epoch 320, Loss: 0.03691305313259363, Final Batch Loss: 0.021333584561944008\n",
      "Epoch 321, Loss: 0.01725054462440312, Final Batch Loss: 0.003285113023594022\n",
      "Epoch 322, Loss: 0.014612349448725581, Final Batch Loss: 0.011669806204736233\n",
      "Epoch 323, Loss: 0.010748413391411304, Final Batch Loss: 0.002616509795188904\n",
      "Epoch 324, Loss: 0.019913251511752605, Final Batch Loss: 0.01078661996871233\n",
      "Epoch 325, Loss: 0.013259404571726918, Final Batch Loss: 0.009773354046046734\n",
      "Epoch 326, Loss: 0.00756469345651567, Final Batch Loss: 0.006175004877150059\n",
      "Epoch 327, Loss: 0.029073534067720175, Final Batch Loss: 0.007029322441667318\n",
      "Epoch 328, Loss: 0.029832840198650956, Final Batch Loss: 0.027906587347388268\n",
      "Epoch 329, Loss: 0.018494691234081984, Final Batch Loss: 0.0044674077071249485\n",
      "Epoch 330, Loss: 0.013790139928460121, Final Batch Loss: 0.00819666963070631\n",
      "Epoch 331, Loss: 0.019902776926755905, Final Batch Loss: 0.009359857998788357\n",
      "Epoch 332, Loss: 0.017528468742966652, Final Batch Loss: 0.006924770772457123\n",
      "Epoch 333, Loss: 0.01679749321192503, Final Batch Loss: 0.008106130175292492\n",
      "Epoch 334, Loss: 0.016819446813315153, Final Batch Loss: 0.009331107139587402\n",
      "Epoch 335, Loss: 0.017911076545715332, Final Batch Loss: 0.0071513717994093895\n",
      "Epoch 336, Loss: 0.020242436788976192, Final Batch Loss: 0.014757802709937096\n",
      "Epoch 337, Loss: 0.00439633778296411, Final Batch Loss: 0.0019337129779160023\n",
      "Epoch 338, Loss: 0.011306954082101583, Final Batch Loss: 0.00484746228903532\n",
      "Epoch 339, Loss: 0.014954438898712397, Final Batch Loss: 0.008361478336155415\n",
      "Epoch 340, Loss: 0.01406373642385006, Final Batch Loss: 0.003205512650310993\n",
      "Epoch 341, Loss: 0.04176600789651275, Final Batch Loss: 0.037416938692331314\n",
      "Epoch 342, Loss: 0.01124726003035903, Final Batch Loss: 0.003980327397584915\n",
      "Epoch 343, Loss: 0.01107892137952149, Final Batch Loss: 0.003450684016570449\n",
      "Epoch 344, Loss: 0.007892320398241282, Final Batch Loss: 0.004567721392959356\n",
      "Epoch 345, Loss: 0.0098908725194633, Final Batch Loss: 0.004946656990796328\n",
      "Epoch 346, Loss: 0.016750937094911933, Final Batch Loss: 0.0024251833092421293\n",
      "Epoch 347, Loss: 0.02089475328102708, Final Batch Loss: 0.017404044046998024\n",
      "Epoch 348, Loss: 0.05768197402358055, Final Batch Loss: 0.04258100688457489\n",
      "Epoch 349, Loss: 0.008020861889235675, Final Batch Loss: 0.0016927652759477496\n",
      "Epoch 350, Loss: 0.013574416749179363, Final Batch Loss: 0.008750036358833313\n",
      "Epoch 351, Loss: 0.009965451376046985, Final Batch Loss: 0.0009046149789355695\n",
      "Epoch 352, Loss: 0.011283692438155413, Final Batch Loss: 0.0029919291846454144\n",
      "Epoch 353, Loss: 0.016363029601052403, Final Batch Loss: 0.012561210431158543\n",
      "Epoch 354, Loss: 0.009395461063832045, Final Batch Loss: 0.004779765848070383\n",
      "Epoch 355, Loss: 0.015704368241131306, Final Batch Loss: 0.006389777176082134\n",
      "Epoch 356, Loss: 0.028438159730285406, Final Batch Loss: 0.007213919889181852\n",
      "Epoch 357, Loss: 0.021768858190625906, Final Batch Loss: 0.015202457085251808\n",
      "Epoch 358, Loss: 0.011911570327356458, Final Batch Loss: 0.002690438413992524\n",
      "Epoch 359, Loss: 0.008991616312414408, Final Batch Loss: 0.005914115346968174\n",
      "Epoch 360, Loss: 0.01568477274850011, Final Batch Loss: 0.012224634177982807\n",
      "Epoch 361, Loss: 0.01088532223366201, Final Batch Loss: 0.001064587151631713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362, Loss: 0.009088707389310002, Final Batch Loss: 0.0023962499108165503\n",
      "Epoch 363, Loss: 0.005967638338916004, Final Batch Loss: 0.0017195370746776462\n",
      "Epoch 364, Loss: 0.015136037487536669, Final Batch Loss: 0.004591015633195639\n",
      "Epoch 365, Loss: 0.009314037160947919, Final Batch Loss: 0.006375693716108799\n",
      "Epoch 366, Loss: 0.014097403734922409, Final Batch Loss: 0.00947711244225502\n",
      "Epoch 367, Loss: 0.005953631130978465, Final Batch Loss: 0.002852301113307476\n",
      "Epoch 368, Loss: 0.0026856407057493925, Final Batch Loss: 0.0006278723012655973\n",
      "Epoch 369, Loss: 0.011024062521755695, Final Batch Loss: 0.006196879781782627\n",
      "Epoch 370, Loss: 0.02291608415544033, Final Batch Loss: 0.0025977138429880142\n",
      "Epoch 371, Loss: 0.009291529655456543, Final Batch Loss: 0.003284310922026634\n",
      "Epoch 372, Loss: 0.010458546690642834, Final Batch Loss: 0.005413669627159834\n",
      "Epoch 373, Loss: 0.019371615606360137, Final Batch Loss: 0.0016887950478121638\n",
      "Epoch 374, Loss: 0.006983060739003122, Final Batch Loss: 0.0018801576225087047\n",
      "Epoch 375, Loss: 0.03747984650544822, Final Batch Loss: 0.03562748432159424\n",
      "Epoch 376, Loss: 0.006162740872241557, Final Batch Loss: 0.001526457373984158\n",
      "Epoch 377, Loss: 0.012478024698793888, Final Batch Loss: 0.0026467526331543922\n",
      "Epoch 378, Loss: 0.007121543516404927, Final Batch Loss: 0.001839541015215218\n",
      "Epoch 379, Loss: 0.008420345489867032, Final Batch Loss: 0.0009705155389383435\n",
      "Epoch 380, Loss: 0.03429201082326472, Final Batch Loss: 0.0021853430662304163\n",
      "Epoch 381, Loss: 0.01442319096531719, Final Batch Loss: 0.0018103051697835326\n",
      "Epoch 382, Loss: 0.009066029451787472, Final Batch Loss: 0.0035625742748379707\n",
      "Epoch 383, Loss: 0.011739563662558794, Final Batch Loss: 0.0063409870490431786\n",
      "Epoch 384, Loss: 0.015421767253428698, Final Batch Loss: 0.0049389130435884\n",
      "Epoch 385, Loss: 0.006143047008663416, Final Batch Loss: 0.0026573780924081802\n",
      "Epoch 386, Loss: 0.02291502384468913, Final Batch Loss: 0.006889247801154852\n",
      "Epoch 387, Loss: 0.02561367501039058, Final Batch Loss: 0.024142025038599968\n",
      "Epoch 388, Loss: 0.011356656206771731, Final Batch Loss: 0.0030987716745585203\n",
      "Epoch 389, Loss: 0.008127004839479923, Final Batch Loss: 0.006611619610339403\n",
      "Epoch 390, Loss: 0.008802738622762263, Final Batch Loss: 0.007725487928837538\n",
      "Epoch 391, Loss: 0.009493147488683462, Final Batch Loss: 0.006568228825926781\n",
      "Epoch 392, Loss: 0.006203342578373849, Final Batch Loss: 0.000598595361225307\n",
      "Epoch 393, Loss: 0.01584383985027671, Final Batch Loss: 0.00988080631941557\n",
      "Epoch 394, Loss: 0.03244968503713608, Final Batch Loss: 0.027095096185803413\n",
      "Epoch 395, Loss: 0.005240135593339801, Final Batch Loss: 0.0029194282833486795\n",
      "Epoch 396, Loss: 0.013199710752815008, Final Batch Loss: 0.007910069078207016\n",
      "Epoch 397, Loss: 0.017000167863443494, Final Batch Loss: 0.003279156284406781\n",
      "Epoch 398, Loss: 0.01921801140997559, Final Batch Loss: 0.001766421482898295\n",
      "Epoch 399, Loss: 0.005713168415240943, Final Batch Loss: 0.004032803699374199\n",
      "Epoch 400, Loss: 0.005189112853258848, Final Batch Loss: 0.002484063385054469\n",
      "Epoch 401, Loss: 0.004532821476459503, Final Batch Loss: 0.0035551798064261675\n",
      "Epoch 402, Loss: 0.021837725769728422, Final Batch Loss: 0.002928019966930151\n",
      "Epoch 403, Loss: 0.021589063806459308, Final Batch Loss: 0.019489333033561707\n",
      "Epoch 404, Loss: 0.00954487081617117, Final Batch Loss: 0.004102450329810381\n",
      "Epoch 405, Loss: 0.01612885110080242, Final Batch Loss: 0.014256623573601246\n",
      "Epoch 406, Loss: 0.02740951720625162, Final Batch Loss: 0.02047726698219776\n",
      "Epoch 407, Loss: 0.006738592172041535, Final Batch Loss: 0.0031987337861210108\n",
      "Epoch 408, Loss: 0.004024540714453906, Final Batch Loss: 0.0007368442020379007\n",
      "Epoch 409, Loss: 0.004017531522549689, Final Batch Loss: 0.0015601395862177014\n",
      "Epoch 410, Loss: 0.0033386488212272525, Final Batch Loss: 0.0011140293208882213\n",
      "Epoch 411, Loss: 0.00868606346193701, Final Batch Loss: 0.0016900693299248815\n",
      "Epoch 412, Loss: 0.006379836471751332, Final Batch Loss: 0.004274945706129074\n",
      "Epoch 413, Loss: 0.014193010050803423, Final Batch Loss: 0.009805245324969292\n",
      "Epoch 414, Loss: 0.0036556858103722334, Final Batch Loss: 0.0014795982278883457\n",
      "Epoch 415, Loss: 0.006876655388623476, Final Batch Loss: 0.00345006980933249\n",
      "Epoch 416, Loss: 0.02481718931812793, Final Batch Loss: 0.023767922073602676\n",
      "Epoch 417, Loss: 0.0045944401063025, Final Batch Loss: 0.0014228497166186571\n",
      "Epoch 418, Loss: 0.006616877508349717, Final Batch Loss: 0.001365427509881556\n",
      "Epoch 419, Loss: 0.0037394837709143758, Final Batch Loss: 0.0020775143057107925\n",
      "Epoch 420, Loss: 0.008425751235336065, Final Batch Loss: 0.005039643030613661\n",
      "Epoch 421, Loss: 0.006773008033633232, Final Batch Loss: 0.0037745351437479258\n",
      "Epoch 422, Loss: 0.004505867254920304, Final Batch Loss: 0.001759470789693296\n",
      "Epoch 423, Loss: 0.006734755821526051, Final Batch Loss: 0.002304124180227518\n",
      "Epoch 424, Loss: 0.05121250788215548, Final Batch Loss: 0.04963577166199684\n",
      "Epoch 425, Loss: 0.0016509609413333237, Final Batch Loss: 0.0008440627134405077\n",
      "Epoch 426, Loss: 0.009079597657546401, Final Batch Loss: 0.005443907342851162\n",
      "Epoch 427, Loss: 0.03414528211578727, Final Batch Loss: 0.0270292479544878\n",
      "Epoch 428, Loss: 0.007977006724104285, Final Batch Loss: 0.0038583127316087484\n",
      "Epoch 429, Loss: 0.003602670505642891, Final Batch Loss: 0.0010709306225180626\n",
      "Epoch 430, Loss: 0.007600190700031817, Final Batch Loss: 0.0011203178437426686\n",
      "Epoch 431, Loss: 0.005287369596771896, Final Batch Loss: 0.0014814963797107339\n",
      "Epoch 432, Loss: 0.019403564510867, Final Batch Loss: 0.0022860735189169645\n",
      "Epoch 433, Loss: 0.016885135672055185, Final Batch Loss: 0.000626461929641664\n",
      "Epoch 434, Loss: 0.018721965490840375, Final Batch Loss: 0.0013372668763622642\n",
      "Epoch 435, Loss: 0.015047985594719648, Final Batch Loss: 0.003114167135208845\n",
      "Epoch 436, Loss: 0.009174203965812922, Final Batch Loss: 0.0042730108834803104\n",
      "Epoch 437, Loss: 0.00800958659965545, Final Batch Loss: 0.0010778765426948667\n",
      "Epoch 438, Loss: 0.014170383801683784, Final Batch Loss: 0.001284948317334056\n",
      "Epoch 439, Loss: 0.027733655646443367, Final Batch Loss: 0.013992096297442913\n",
      "Epoch 440, Loss: 0.003987335076089948, Final Batch Loss: 0.0007077080081216991\n",
      "Epoch 441, Loss: 0.006922656204551458, Final Batch Loss: 0.004973884671926498\n",
      "Epoch 442, Loss: 0.00443624728359282, Final Batch Loss: 0.0014171050861477852\n",
      "Epoch 443, Loss: 0.006361549720168114, Final Batch Loss: 0.0034862812608480453\n",
      "Epoch 444, Loss: 0.038878570310771465, Final Batch Loss: 0.009907268919050694\n",
      "Epoch 445, Loss: 0.011262059211730957, Final Batch Loss: 0.00804678350687027\n",
      "Epoch 446, Loss: 0.011246425099670887, Final Batch Loss: 0.010140831582248211\n",
      "Epoch 447, Loss: 0.023135860916227102, Final Batch Loss: 0.003851465415209532\n",
      "Epoch 448, Loss: 0.0250333733856678, Final Batch Loss: 0.014614442363381386\n",
      "Epoch 449, Loss: 0.005610594293102622, Final Batch Loss: 0.0018853626679629087\n",
      "Epoch 450, Loss: 0.009015262825414538, Final Batch Loss: 0.005808068439364433\n",
      "Epoch 451, Loss: 0.027774095768108964, Final Batch Loss: 0.024309886619448662\n",
      "Epoch 452, Loss: 0.02660827524960041, Final Batch Loss: 0.011938671581447124\n",
      "Epoch 453, Loss: 0.015399682335555553, Final Batch Loss: 0.012621902860701084\n",
      "Epoch 454, Loss: 0.02852387260645628, Final Batch Loss: 0.027338845655322075\n",
      "Epoch 455, Loss: 0.0023635823163203895, Final Batch Loss: 0.0004894392914138734\n",
      "Epoch 456, Loss: 0.007519798004068434, Final Batch Loss: 0.0008076700614765286\n",
      "Epoch 457, Loss: 0.003315880778245628, Final Batch Loss: 0.001698264037258923\n",
      "Epoch 458, Loss: 0.004532892140559852, Final Batch Loss: 0.002991648158058524\n",
      "Epoch 459, Loss: 0.01001460081897676, Final Batch Loss: 0.0019856065046042204\n",
      "Epoch 460, Loss: 0.013870825059711933, Final Batch Loss: 0.008702670224010944\n",
      "Epoch 461, Loss: 0.02471807226538658, Final Batch Loss: 0.015308022499084473\n",
      "Epoch 462, Loss: 0.012051444733515382, Final Batch Loss: 0.0017995007801800966\n",
      "Epoch 463, Loss: 0.007603178033605218, Final Batch Loss: 0.005832765717059374\n",
      "Epoch 464, Loss: 0.01520674442872405, Final Batch Loss: 0.011200040578842163\n",
      "Epoch 465, Loss: 0.006396663375198841, Final Batch Loss: 0.003962683491408825\n",
      "Epoch 466, Loss: 0.011296683456748724, Final Batch Loss: 0.00240864185616374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467, Loss: 0.004217986366711557, Final Batch Loss: 0.003112215781584382\n",
      "Epoch 468, Loss: 0.01878479332663119, Final Batch Loss: 0.016708016395568848\n",
      "Epoch 469, Loss: 0.025175344198942184, Final Batch Loss: 0.0226021409034729\n",
      "Epoch 470, Loss: 0.011971228406764567, Final Batch Loss: 0.010360176675021648\n",
      "Epoch 471, Loss: 0.003507327288389206, Final Batch Loss: 0.0029457747004926205\n",
      "Epoch 472, Loss: 0.004711348039563745, Final Batch Loss: 0.0038505864795297384\n",
      "Epoch 473, Loss: 0.015303196618333459, Final Batch Loss: 0.011462495662271976\n",
      "Epoch 474, Loss: 0.0037154193269088864, Final Batch Loss: 0.00189090589992702\n",
      "Epoch 475, Loss: 0.008087932073976845, Final Batch Loss: 0.00729938643053174\n",
      "Epoch 476, Loss: 0.011424772092141211, Final Batch Loss: 0.001717709586955607\n",
      "Epoch 477, Loss: 0.00734198372811079, Final Batch Loss: 0.004129830282181501\n",
      "Epoch 478, Loss: 0.012635677587240934, Final Batch Loss: 0.0024630590341985226\n",
      "Epoch 479, Loss: 0.00371823541354388, Final Batch Loss: 0.0014922035625204444\n",
      "Epoch 480, Loss: 0.012083248468115926, Final Batch Loss: 0.0035038443747907877\n",
      "Epoch 481, Loss: 0.004943883744999766, Final Batch Loss: 0.0025814403779804707\n",
      "Epoch 482, Loss: 0.018703432520851493, Final Batch Loss: 0.0026647483464330435\n",
      "Epoch 483, Loss: 0.0027636759623419493, Final Batch Loss: 0.000451393163530156\n",
      "Epoch 484, Loss: 0.0094436637009494, Final Batch Loss: 0.0006982923368923366\n",
      "Epoch 485, Loss: 0.01161893317475915, Final Batch Loss: 0.009583653882145882\n",
      "Epoch 486, Loss: 0.025493226945400238, Final Batch Loss: 0.004571104422211647\n",
      "Epoch 487, Loss: 0.005020977696403861, Final Batch Loss: 0.0034124564845114946\n",
      "Epoch 488, Loss: 0.005713056772947311, Final Batch Loss: 0.0024901528377085924\n",
      "Epoch 489, Loss: 0.002641718427184969, Final Batch Loss: 0.0017677572323009372\n",
      "Epoch 490, Loss: 0.007647141348570585, Final Batch Loss: 0.006397678051143885\n",
      "Epoch 491, Loss: 0.014132986776530743, Final Batch Loss: 0.011876985430717468\n",
      "Epoch 492, Loss: 0.005840533645823598, Final Batch Loss: 0.003549512941390276\n",
      "Epoch 493, Loss: 0.0037618661881424487, Final Batch Loss: 0.0005421438836492598\n",
      "Epoch 494, Loss: 0.008440275676548481, Final Batch Loss: 0.0043464708141982555\n",
      "Epoch 495, Loss: 0.0065646665170788765, Final Batch Loss: 0.00372323184274137\n",
      "Epoch 496, Loss: 0.004799226997420192, Final Batch Loss: 0.0014796832110732794\n",
      "Epoch 497, Loss: 0.00687135593034327, Final Batch Loss: 0.002779813716188073\n",
      "Epoch 498, Loss: 0.005888243671506643, Final Batch Loss: 0.0028759704437106848\n",
      "Epoch 499, Loss: 0.028622728306800127, Final Batch Loss: 0.021133244037628174\n",
      "Epoch 500, Loss: 0.0038628512993454933, Final Batch Loss: 0.0020506454166024923\n",
      "Epoch 501, Loss: 0.01357919629663229, Final Batch Loss: 0.007224688306450844\n",
      "Epoch 502, Loss: 0.024741354282014072, Final Batch Loss: 0.0012731206370517612\n",
      "Epoch 503, Loss: 0.008160312427207828, Final Batch Loss: 0.005409584380686283\n",
      "Epoch 504, Loss: 0.0010886911186389625, Final Batch Loss: 0.000711460888851434\n",
      "Epoch 505, Loss: 0.007000117911957204, Final Batch Loss: 0.0011878696968778968\n",
      "Epoch 506, Loss: 0.0037969613331370056, Final Batch Loss: 0.0007022527861408889\n",
      "Epoch 507, Loss: 0.045477199368178844, Final Batch Loss: 0.03717102110385895\n",
      "Epoch 508, Loss: 0.017110790126025677, Final Batch Loss: 0.008465946651995182\n",
      "Epoch 509, Loss: 0.003927057608962059, Final Batch Loss: 0.0024056604597717524\n",
      "Epoch 510, Loss: 0.008793344255536795, Final Batch Loss: 0.0026840814389288425\n",
      "Epoch 511, Loss: 0.03455119580030441, Final Batch Loss: 0.018895041197538376\n",
      "Epoch 512, Loss: 0.0020705456845462322, Final Batch Loss: 0.0010132601018995047\n",
      "Epoch 513, Loss: 0.03405989846214652, Final Batch Loss: 0.0031547932885587215\n",
      "Epoch 514, Loss: 0.014875940047204494, Final Batch Loss: 0.012542407028377056\n",
      "Epoch 515, Loss: 0.004504173179157078, Final Batch Loss: 0.0030680964700877666\n",
      "Epoch 516, Loss: 0.00799782807007432, Final Batch Loss: 0.0011422266252338886\n",
      "Epoch 517, Loss: 0.0032310589449480176, Final Batch Loss: 0.00127326266374439\n",
      "Epoch 518, Loss: 0.007919729454442859, Final Batch Loss: 0.00462440587580204\n",
      "Epoch 519, Loss: 0.0209821438184008, Final Batch Loss: 0.019798988476395607\n",
      "Epoch 520, Loss: 0.0063066346338018775, Final Batch Loss: 0.001213153707794845\n",
      "Epoch 521, Loss: 0.0023059379309415817, Final Batch Loss: 0.0017613550880923867\n",
      "Epoch 522, Loss: 0.013843966647982597, Final Batch Loss: 0.009442700073122978\n",
      "Epoch 523, Loss: 0.008703959989361465, Final Batch Loss: 0.0014479042729362845\n",
      "Epoch 524, Loss: 0.005937756504863501, Final Batch Loss: 0.0016935430467128754\n",
      "Epoch 525, Loss: 0.0017202585004270077, Final Batch Loss: 0.0011856530327349901\n",
      "Epoch 526, Loss: 0.01477187336422503, Final Batch Loss: 0.0019047644454985857\n",
      "Epoch 527, Loss: 0.00497207255102694, Final Batch Loss: 0.003004153026267886\n",
      "Epoch 528, Loss: 0.001751119620166719, Final Batch Loss: 0.00027134991250932217\n",
      "Epoch 529, Loss: 0.0025413688854314387, Final Batch Loss: 0.0007332314853556454\n",
      "Epoch 530, Loss: 0.0019994589092675596, Final Batch Loss: 0.00029894060571677983\n",
      "Epoch 531, Loss: 0.006573757389560342, Final Batch Loss: 0.002037027617916465\n",
      "Epoch 532, Loss: 0.006238368747290224, Final Batch Loss: 0.000646681000944227\n",
      "Epoch 533, Loss: 0.020798013545572758, Final Batch Loss: 0.001523173414170742\n",
      "Epoch 534, Loss: 0.006012603524141014, Final Batch Loss: 0.0047454508021473885\n",
      "Epoch 535, Loss: 0.009226975962519646, Final Batch Loss: 0.004643571563065052\n",
      "Epoch 536, Loss: 0.004700054414570332, Final Batch Loss: 0.002413301495835185\n",
      "Epoch 537, Loss: 0.0028171519516035914, Final Batch Loss: 0.0017767470562830567\n",
      "Epoch 538, Loss: 0.01476628752425313, Final Batch Loss: 0.002083826344460249\n",
      "Epoch 539, Loss: 0.006112435832619667, Final Batch Loss: 0.002990442095324397\n",
      "Epoch 540, Loss: 0.02109858742915094, Final Batch Loss: 0.002687446540221572\n",
      "Epoch 541, Loss: 0.0025132816517725587, Final Batch Loss: 0.0013107996201142669\n",
      "Epoch 542, Loss: 0.012582806870341301, Final Batch Loss: 0.001779761165380478\n",
      "Epoch 543, Loss: 0.04000116465613246, Final Batch Loss: 0.0377487950026989\n",
      "Epoch 544, Loss: 0.008820594230201095, Final Batch Loss: 0.0007260292186401784\n",
      "Epoch 545, Loss: 0.006156603340059519, Final Batch Loss: 0.0008415845222771168\n",
      "Epoch 546, Loss: 0.0029675088590011, Final Batch Loss: 0.0018615210428833961\n",
      "Epoch 547, Loss: 0.010440612211823463, Final Batch Loss: 0.007033789064735174\n",
      "Epoch 548, Loss: 0.013832096243277192, Final Batch Loss: 0.0009646501857787371\n",
      "Epoch 549, Loss: 0.007075438741594553, Final Batch Loss: 0.00469194957986474\n",
      "Epoch 550, Loss: 0.005153719335794449, Final Batch Loss: 0.002426323015242815\n",
      "Epoch 551, Loss: 0.0038559233071282506, Final Batch Loss: 0.0022680636029690504\n",
      "Epoch 552, Loss: 0.005022280034609139, Final Batch Loss: 0.00327321863733232\n",
      "Epoch 553, Loss: 0.005108102224767208, Final Batch Loss: 0.0012549103703349829\n",
      "Epoch 554, Loss: 0.011743803508579731, Final Batch Loss: 0.0016976632177829742\n",
      "Epoch 555, Loss: 0.001669078308623284, Final Batch Loss: 0.0009598527103662491\n",
      "Epoch 556, Loss: 0.012557194102555513, Final Batch Loss: 0.010992628522217274\n",
      "Epoch 557, Loss: 0.006414043513359502, Final Batch Loss: 0.00036123234895057976\n",
      "Epoch 558, Loss: 0.01577127631753683, Final Batch Loss: 0.0014515835791826248\n",
      "Epoch 559, Loss: 0.00204697233857587, Final Batch Loss: 0.0003927050274796784\n",
      "Epoch 560, Loss: 0.002039208950009197, Final Batch Loss: 0.0007458164473064244\n",
      "Epoch 561, Loss: 0.005368056241422892, Final Batch Loss: 0.003488534828647971\n",
      "Epoch 562, Loss: 0.00557030230993405, Final Batch Loss: 0.004845001269131899\n",
      "Epoch 563, Loss: 0.004428159212693572, Final Batch Loss: 0.0026104215066879988\n",
      "Epoch 564, Loss: 0.0075608023325912654, Final Batch Loss: 0.0009312892216257751\n",
      "Epoch 565, Loss: 0.004406764579471201, Final Batch Loss: 0.000731331470888108\n",
      "Epoch 566, Loss: 0.008803011965937912, Final Batch Loss: 0.0011471324833109975\n",
      "Epoch 567, Loss: 0.0025523941731080413, Final Batch Loss: 0.0010599740780889988\n",
      "Epoch 568, Loss: 0.0052187187829986215, Final Batch Loss: 0.0019191064639016986\n",
      "Epoch 569, Loss: 0.005369000369682908, Final Batch Loss: 0.004222586750984192\n",
      "Epoch 570, Loss: 0.003805952495895326, Final Batch Loss: 0.0005429469747468829\n",
      "Epoch 571, Loss: 0.002161010808777064, Final Batch Loss: 0.0007934728055261075\n",
      "Epoch 572, Loss: 0.002606073336210102, Final Batch Loss: 0.0008318743784911931\n",
      "Epoch 573, Loss: 0.002941373852081597, Final Batch Loss: 0.0015269964933395386\n",
      "Epoch 574, Loss: 0.0065161146922037005, Final Batch Loss: 0.0013107553822919726\n",
      "Epoch 575, Loss: 0.005590655375272036, Final Batch Loss: 0.0007941932417452335\n",
      "Epoch 576, Loss: 0.011094529065303504, Final Batch Loss: 0.001379244844429195\n",
      "Epoch 577, Loss: 0.00738620397169143, Final Batch Loss: 0.0006585131632164121\n",
      "Epoch 578, Loss: 0.0018898203852586448, Final Batch Loss: 0.0012179581681266427\n",
      "Epoch 579, Loss: 0.0019501043716445565, Final Batch Loss: 0.0011331784771755338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580, Loss: 0.004388656350784004, Final Batch Loss: 0.0016621918184682727\n",
      "Epoch 581, Loss: 0.0015421955613419414, Final Batch Loss: 0.0010440237820148468\n",
      "Epoch 582, Loss: 0.002359005738981068, Final Batch Loss: 0.0007417742162942886\n",
      "Epoch 583, Loss: 0.007094330387189984, Final Batch Loss: 0.00475237425416708\n",
      "Epoch 584, Loss: 0.008557084249332547, Final Batch Loss: 0.0009567972738295794\n",
      "Epoch 585, Loss: 0.00334239867515862, Final Batch Loss: 0.0020771888084709644\n",
      "Epoch 586, Loss: 0.0265135777881369, Final Batch Loss: 0.0014159263810142875\n",
      "Epoch 587, Loss: 0.011487910058349371, Final Batch Loss: 0.01056916918605566\n",
      "Epoch 588, Loss: 0.011598987621255219, Final Batch Loss: 0.010275756008923054\n",
      "Epoch 589, Loss: 0.009434072067961097, Final Batch Loss: 0.0014371115248650312\n",
      "Epoch 590, Loss: 0.02666447265073657, Final Batch Loss: 0.003504668828099966\n",
      "Epoch 591, Loss: 0.009118913440033793, Final Batch Loss: 0.0024781154934316874\n",
      "Epoch 592, Loss: 0.0037740871775895357, Final Batch Loss: 0.0027835166547447443\n",
      "Epoch 593, Loss: 0.004432976478710771, Final Batch Loss: 0.00389959872700274\n",
      "Epoch 594, Loss: 0.003023626864887774, Final Batch Loss: 0.0009496646234765649\n",
      "Epoch 595, Loss: 0.0026953816413879395, Final Batch Loss: 0.001516579883173108\n",
      "Epoch 596, Loss: 0.03164711152203381, Final Batch Loss: 0.029116401448845863\n",
      "Epoch 597, Loss: 0.009737426531501114, Final Batch Loss: 0.0011926592560485005\n",
      "Epoch 598, Loss: 0.00427708396455273, Final Batch Loss: 0.003453637706115842\n",
      "Epoch 599, Loss: 0.004248528508469462, Final Batch Loss: 0.001912575215101242\n",
      "Epoch 600, Loss: 0.0034932035487145185, Final Batch Loss: 0.0009538773447275162\n",
      "Epoch 601, Loss: 0.0036820336245000362, Final Batch Loss: 0.0003059899900108576\n",
      "Epoch 602, Loss: 0.012373554054647684, Final Batch Loss: 0.010534039698541164\n",
      "Epoch 603, Loss: 0.0022349569480866194, Final Batch Loss: 0.0012043722672387958\n",
      "Epoch 604, Loss: 0.002747800899669528, Final Batch Loss: 0.0015005884924903512\n",
      "Epoch 605, Loss: 0.002153272391296923, Final Batch Loss: 0.0009841404389590025\n",
      "Epoch 606, Loss: 0.010291581740602851, Final Batch Loss: 0.0016176241915673018\n",
      "Epoch 607, Loss: 0.005328932078555226, Final Batch Loss: 0.003237491473555565\n",
      "Epoch 608, Loss: 0.001749163493514061, Final Batch Loss: 0.0004937457852065563\n",
      "Epoch 609, Loss: 0.0139026939868927, Final Batch Loss: 0.006241391412913799\n",
      "Epoch 610, Loss: 0.002291332872118801, Final Batch Loss: 0.0015960212331265211\n",
      "Epoch 611, Loss: 0.001644710369873792, Final Batch Loss: 0.000546052644494921\n",
      "Epoch 612, Loss: 0.012556854984723032, Final Batch Loss: 0.010732561349868774\n",
      "Epoch 613, Loss: 0.0018413982761558145, Final Batch Loss: 0.0004588272131513804\n",
      "Epoch 614, Loss: 0.002487742807716131, Final Batch Loss: 0.0013220591936260462\n",
      "Epoch 615, Loss: 0.015193600673228502, Final Batch Loss: 0.011957340873777866\n",
      "Epoch 616, Loss: 0.00807565584545955, Final Batch Loss: 0.0008350442512892187\n",
      "Epoch 617, Loss: 0.004414774244651198, Final Batch Loss: 0.0022341276053339243\n",
      "Epoch 618, Loss: 0.0016762531013228, Final Batch Loss: 0.0005967055330984294\n",
      "Epoch 619, Loss: 0.004777849069796503, Final Batch Loss: 0.0034380070865154266\n",
      "Epoch 620, Loss: 0.03367113787680864, Final Batch Loss: 0.0137879503890872\n",
      "Epoch 621, Loss: 0.004419923556270078, Final Batch Loss: 0.000372575392248109\n",
      "Epoch 622, Loss: 0.004729532287456095, Final Batch Loss: 0.0017845191759988666\n",
      "Epoch 623, Loss: 0.014594420092180371, Final Batch Loss: 0.0024612166453152895\n",
      "Epoch 624, Loss: 0.005649570608511567, Final Batch Loss: 0.0013388192746788263\n",
      "Epoch 625, Loss: 0.006824215699452907, Final Batch Loss: 0.006098561454564333\n",
      "Epoch 626, Loss: 0.025289899669587612, Final Batch Loss: 0.01352204941213131\n",
      "Epoch 627, Loss: 0.0034240041859447956, Final Batch Loss: 0.0012240710202604532\n",
      "Epoch 628, Loss: 0.010440940619446337, Final Batch Loss: 0.0009384570876136422\n",
      "Epoch 629, Loss: 0.0014660866581834853, Final Batch Loss: 0.0010410783579573035\n",
      "Epoch 630, Loss: 0.005439566884888336, Final Batch Loss: 0.0003902814059983939\n",
      "Epoch 631, Loss: 0.009938196162693202, Final Batch Loss: 0.008828992955386639\n",
      "Epoch 632, Loss: 0.012530194595456123, Final Batch Loss: 0.011040274053812027\n",
      "Epoch 633, Loss: 0.019433649256825447, Final Batch Loss: 0.005777444690465927\n",
      "Epoch 634, Loss: 0.00740953377680853, Final Batch Loss: 0.0008179809083230793\n",
      "Epoch 635, Loss: 0.011094510671682656, Final Batch Loss: 0.009434164501726627\n",
      "Epoch 636, Loss: 0.0022808773210272193, Final Batch Loss: 0.0011489834869280457\n",
      "Epoch 637, Loss: 0.0025476603186689317, Final Batch Loss: 0.0008942194399423897\n",
      "Epoch 638, Loss: 0.0015202636132016778, Final Batch Loss: 0.0006480125593952835\n",
      "Epoch 639, Loss: 0.005225933069596067, Final Batch Loss: 0.004800987895578146\n",
      "Epoch 640, Loss: 0.0008650032395962626, Final Batch Loss: 0.0004865172377321869\n",
      "Epoch 641, Loss: 0.0021952161914668977, Final Batch Loss: 0.0005606936174444854\n",
      "Epoch 642, Loss: 0.0036913526710122824, Final Batch Loss: 0.002490136306732893\n",
      "Epoch 643, Loss: 0.01229199138469994, Final Batch Loss: 0.00954642053693533\n",
      "Epoch 644, Loss: 0.008208812272641808, Final Batch Loss: 0.00048580538714304566\n",
      "Epoch 645, Loss: 0.005020514130592346, Final Batch Loss: 0.003464208682999015\n",
      "Epoch 646, Loss: 0.0016157995560206473, Final Batch Loss: 0.0006150395493023098\n",
      "Epoch 647, Loss: 0.004650939314160496, Final Batch Loss: 0.0006598127656616271\n",
      "Epoch 648, Loss: 0.010594146209768951, Final Batch Loss: 0.009857986122369766\n",
      "Epoch 649, Loss: 0.004294264945201576, Final Batch Loss: 0.00371382269077003\n",
      "Epoch 650, Loss: 0.010065955808386207, Final Batch Loss: 0.006751103326678276\n",
      "Epoch 651, Loss: 0.02015261398628354, Final Batch Loss: 0.015971189364790916\n",
      "Epoch 652, Loss: 0.002095213276334107, Final Batch Loss: 0.0010456250747665763\n",
      "Epoch 653, Loss: 0.006228207144886255, Final Batch Loss: 0.0023843140807002783\n",
      "Epoch 654, Loss: 0.013058604905381799, Final Batch Loss: 0.0027591923717409372\n",
      "Epoch 655, Loss: 0.014186665997840464, Final Batch Loss: 0.013172532431781292\n",
      "Epoch 656, Loss: 0.012145360233262181, Final Batch Loss: 0.01008466724306345\n",
      "Epoch 657, Loss: 0.01502571371383965, Final Batch Loss: 0.0016041325870901346\n",
      "Epoch 658, Loss: 0.01664553675800562, Final Batch Loss: 0.016276594251394272\n",
      "Epoch 659, Loss: 0.0026444856193847954, Final Batch Loss: 0.0009312669862993062\n",
      "Epoch 660, Loss: 0.0017225858173333108, Final Batch Loss: 0.0005356950568966568\n",
      "Epoch 661, Loss: 0.0099800368770957, Final Batch Loss: 0.005677216686308384\n",
      "Epoch 662, Loss: 0.001865991624072194, Final Batch Loss: 0.0002990399952977896\n",
      "Epoch 663, Loss: 0.008622124150861055, Final Batch Loss: 0.007821116596460342\n",
      "Epoch 664, Loss: 0.009018111129989848, Final Batch Loss: 0.00019681462435983121\n",
      "Epoch 665, Loss: 0.008734646253287792, Final Batch Loss: 0.006723711267113686\n",
      "Epoch 666, Loss: 0.006613093661144376, Final Batch Loss: 0.006117687094956636\n",
      "Epoch 667, Loss: 0.002493147796485573, Final Batch Loss: 0.0006895209080539644\n",
      "Epoch 668, Loss: 0.010154068237170577, Final Batch Loss: 0.0003291273023933172\n",
      "Epoch 669, Loss: 0.0014556223759427667, Final Batch Loss: 0.0005303148063831031\n",
      "Epoch 670, Loss: 0.010102050146088004, Final Batch Loss: 0.00181297748349607\n",
      "Epoch 671, Loss: 0.0016326656332239509, Final Batch Loss: 0.0007285288302227855\n",
      "Epoch 672, Loss: 0.0025866393698379397, Final Batch Loss: 0.0017635286785662174\n",
      "Epoch 673, Loss: 0.001369643141515553, Final Batch Loss: 0.0005494237411767244\n",
      "Epoch 674, Loss: 0.00242769654141739, Final Batch Loss: 0.0006160629563964903\n",
      "Epoch 675, Loss: 0.004970070149283856, Final Batch Loss: 0.004054688382893801\n",
      "Epoch 676, Loss: 0.0016854607965797186, Final Batch Loss: 0.0008040727116167545\n",
      "Epoch 677, Loss: 0.007650086539797485, Final Batch Loss: 0.0067916810512542725\n",
      "Epoch 678, Loss: 0.0017955497023649514, Final Batch Loss: 0.0011712261475622654\n",
      "Epoch 679, Loss: 0.001391418045386672, Final Batch Loss: 0.0005294780130498111\n",
      "Epoch 680, Loss: 0.005084751755930483, Final Batch Loss: 0.0034608757123351097\n",
      "Epoch 681, Loss: 0.009891829104162753, Final Batch Loss: 0.0013847477966919541\n",
      "Epoch 682, Loss: 0.003997925552539527, Final Batch Loss: 0.003124639857560396\n",
      "Epoch 683, Loss: 0.0017040203092619777, Final Batch Loss: 0.0008688000380061567\n",
      "Epoch 684, Loss: 0.004098127901670523, Final Batch Loss: 0.00019405510101933032\n",
      "Epoch 685, Loss: 0.003621269323048182, Final Batch Loss: 0.00023159019474405795\n",
      "Epoch 686, Loss: 0.002901881409343332, Final Batch Loss: 0.0022757963743060827\n",
      "Epoch 687, Loss: 0.005166776943951845, Final Batch Loss: 0.00268168980255723\n",
      "Epoch 688, Loss: 0.002131076471414417, Final Batch Loss: 0.001432071323506534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689, Loss: 0.0037267754087224603, Final Batch Loss: 0.0005416221683844924\n",
      "Epoch 690, Loss: 0.021828321740031242, Final Batch Loss: 0.013354547321796417\n",
      "Epoch 691, Loss: 0.0013691711355932057, Final Batch Loss: 0.0009482309687882662\n",
      "Epoch 692, Loss: 0.0034934879513457417, Final Batch Loss: 0.0018017255933955312\n",
      "Epoch 693, Loss: 0.0014930444885976613, Final Batch Loss: 0.000729071325622499\n",
      "Epoch 694, Loss: 0.0026829588459804654, Final Batch Loss: 0.0020658683497458696\n",
      "Epoch 695, Loss: 0.00837153458269313, Final Batch Loss: 0.0007394294370897114\n",
      "Epoch 696, Loss: 0.012792421039193869, Final Batch Loss: 0.0025411932729184628\n",
      "Epoch 697, Loss: 0.014661540742963552, Final Batch Loss: 0.011912871152162552\n",
      "Epoch 698, Loss: 0.009819772094488144, Final Batch Loss: 0.00868215225636959\n",
      "Epoch 699, Loss: 0.013577397039625794, Final Batch Loss: 0.012859568931162357\n",
      "Epoch 700, Loss: 0.007740309549262747, Final Batch Loss: 0.0003867904597427696\n",
      "Epoch 701, Loss: 0.005531414411962032, Final Batch Loss: 0.004309261217713356\n",
      "Epoch 702, Loss: 0.0020043281838297844, Final Batch Loss: 0.0013821604661643505\n",
      "Epoch 703, Loss: 0.0016608393925707787, Final Batch Loss: 0.0004836468433495611\n",
      "Epoch 704, Loss: 0.004576626815833151, Final Batch Loss: 0.0009355883812531829\n",
      "Epoch 705, Loss: 0.012969780655112118, Final Batch Loss: 0.012668740935623646\n",
      "Epoch 706, Loss: 0.0014276590081863105, Final Batch Loss: 0.0008264963398687541\n",
      "Epoch 707, Loss: 0.0021088122157379985, Final Batch Loss: 0.0010292218066751957\n",
      "Epoch 708, Loss: 0.016737900441512465, Final Batch Loss: 0.0019588505383580923\n",
      "Epoch 709, Loss: 0.001115409133490175, Final Batch Loss: 0.0004982444806955755\n",
      "Epoch 710, Loss: 0.0027670346898958087, Final Batch Loss: 0.001519030425697565\n",
      "Epoch 711, Loss: 0.0015806570299901068, Final Batch Loss: 0.000964005128480494\n",
      "Epoch 712, Loss: 0.013280236162245274, Final Batch Loss: 0.005077646113932133\n",
      "Epoch 713, Loss: 0.0030121852178126574, Final Batch Loss: 0.0015030186623334885\n",
      "Epoch 714, Loss: 0.0011468908633105457, Final Batch Loss: 0.0005288430256769061\n",
      "Epoch 715, Loss: 0.0014008849975652993, Final Batch Loss: 0.0006426515174098313\n",
      "Epoch 716, Loss: 0.002482365700416267, Final Batch Loss: 0.0010246564634144306\n",
      "Epoch 717, Loss: 0.0021862421417608857, Final Batch Loss: 0.0009565748041495681\n",
      "Epoch 718, Loss: 0.014264678582549095, Final Batch Loss: 0.010513472370803356\n",
      "Epoch 719, Loss: 0.004578564956318587, Final Batch Loss: 0.00037397322012111545\n",
      "Epoch 720, Loss: 0.0032807154348120093, Final Batch Loss: 0.0013919691555202007\n",
      "Epoch 721, Loss: 0.0026345073711127043, Final Batch Loss: 0.0007701994618400931\n",
      "Epoch 722, Loss: 0.002079512400086969, Final Batch Loss: 0.0014296481385827065\n",
      "Epoch 723, Loss: 0.006045604823157191, Final Batch Loss: 0.004377291072160006\n",
      "Epoch 724, Loss: 0.0014614293177146465, Final Batch Loss: 0.001239711418747902\n",
      "Epoch 725, Loss: 0.001009201048873365, Final Batch Loss: 0.0006713785696774721\n",
      "Epoch 726, Loss: 0.006125555140897632, Final Batch Loss: 0.0011775593739002943\n",
      "Epoch 727, Loss: 0.0022526801330968738, Final Batch Loss: 0.001828037085942924\n",
      "Epoch 728, Loss: 0.003217934223357588, Final Batch Loss: 0.0026901925448328257\n",
      "Epoch 729, Loss: 0.006894321239087731, Final Batch Loss: 0.006402940023690462\n",
      "Epoch 730, Loss: 0.0031295153312385082, Final Batch Loss: 0.001897658221423626\n",
      "Epoch 731, Loss: 0.001800599944544956, Final Batch Loss: 0.00029720188467763364\n",
      "Epoch 732, Loss: 0.005434543127194047, Final Batch Loss: 0.0019926659297198057\n",
      "Epoch 733, Loss: 0.0013870290713384748, Final Batch Loss: 0.0007382769254036248\n",
      "Epoch 734, Loss: 0.0019099251076113433, Final Batch Loss: 0.00018722502863965929\n",
      "Epoch 735, Loss: 0.0020263841142877936, Final Batch Loss: 0.0006626383401453495\n",
      "Epoch 736, Loss: 0.0022009343083482236, Final Batch Loss: 0.0019275982631370425\n",
      "Epoch 737, Loss: 0.0007932621520012617, Final Batch Loss: 0.0005850831512361765\n",
      "Epoch 738, Loss: 0.0034316094242967665, Final Batch Loss: 0.0027910922653973103\n",
      "Epoch 739, Loss: 0.005003330297768116, Final Batch Loss: 0.0021773020271211863\n",
      "Epoch 740, Loss: 0.001393028738675639, Final Batch Loss: 0.0009403701988048851\n",
      "Epoch 741, Loss: 0.002923503634519875, Final Batch Loss: 0.0015100670279935002\n",
      "Epoch 742, Loss: 0.019376332871615887, Final Batch Loss: 0.00870395265519619\n",
      "Epoch 743, Loss: 0.010718496167100966, Final Batch Loss: 0.0013812171528115869\n",
      "Epoch 744, Loss: 0.006258930778130889, Final Batch Loss: 0.005091357510536909\n",
      "Epoch 745, Loss: 0.002431784727377817, Final Batch Loss: 0.002107493346557021\n",
      "Epoch 746, Loss: 0.0008041172986850142, Final Batch Loss: 0.00013200531248003244\n",
      "Epoch 747, Loss: 0.005835759569890797, Final Batch Loss: 0.0016011592233553529\n",
      "Epoch 748, Loss: 0.00803951092530042, Final Batch Loss: 0.0006457694107666612\n",
      "Epoch 749, Loss: 0.0010069319687318057, Final Batch Loss: 0.0006134163122624159\n",
      "Epoch 750, Loss: 0.016809742199257016, Final Batch Loss: 0.015663856640458107\n",
      "Epoch 751, Loss: 0.007638118840986863, Final Batch Loss: 0.0071970620192587376\n",
      "Epoch 752, Loss: 0.008499244984705001, Final Batch Loss: 0.00830249022692442\n",
      "Epoch 753, Loss: 0.0009178710752166808, Final Batch Loss: 0.00036728556733578444\n",
      "Epoch 754, Loss: 0.00845147273503244, Final Batch Loss: 0.001138634281232953\n",
      "Epoch 755, Loss: 0.0023756243172101676, Final Batch Loss: 0.0008384299580939114\n",
      "Epoch 756, Loss: 0.0026223912136629224, Final Batch Loss: 0.0010610823519527912\n",
      "Epoch 757, Loss: 0.0015658662596251816, Final Batch Loss: 0.0012455605901777744\n",
      "Epoch 758, Loss: 0.00477570213843137, Final Batch Loss: 0.0030864716973155737\n",
      "Epoch 759, Loss: 0.0011779916821978986, Final Batch Loss: 0.00020132429199293256\n",
      "Epoch 760, Loss: 0.004535017185844481, Final Batch Loss: 0.003712946781888604\n",
      "Epoch 761, Loss: 0.004571794357616454, Final Batch Loss: 0.0005610676598735154\n",
      "Epoch 762, Loss: 0.0014602213050238788, Final Batch Loss: 0.0006106296204961836\n",
      "Epoch 763, Loss: 0.0006526136712636799, Final Batch Loss: 0.00037639279616996646\n",
      "Epoch 764, Loss: 0.0010815713903866708, Final Batch Loss: 0.0007437082822434604\n",
      "Epoch 765, Loss: 0.001085424650227651, Final Batch Loss: 0.0003831906651612371\n",
      "Epoch 766, Loss: 0.018921216018497944, Final Batch Loss: 0.010830323211848736\n",
      "Epoch 767, Loss: 0.003894472843967378, Final Batch Loss: 0.003315697656944394\n",
      "Epoch 768, Loss: 0.005551801325054839, Final Batch Loss: 0.0004123847757000476\n",
      "Epoch 769, Loss: 0.001499974518083036, Final Batch Loss: 0.0006764287245459855\n",
      "Epoch 770, Loss: 0.012672212440520525, Final Batch Loss: 0.008738500066101551\n",
      "Epoch 771, Loss: 0.0007123293617041782, Final Batch Loss: 0.00016439725004602224\n",
      "Epoch 772, Loss: 0.013046966632828116, Final Batch Loss: 0.011410187929868698\n",
      "Epoch 773, Loss: 0.0016556345508433878, Final Batch Loss: 0.0009641199139878154\n",
      "Epoch 774, Loss: 0.002840286586433649, Final Batch Loss: 0.002494622953236103\n",
      "Epoch 775, Loss: 0.0044281716691330075, Final Batch Loss: 0.0014097014209255576\n",
      "Epoch 776, Loss: 0.015180223737843335, Final Batch Loss: 0.000299459439702332\n",
      "Epoch 777, Loss: 0.0060647299396805465, Final Batch Loss: 0.0007659994880668819\n",
      "Epoch 778, Loss: 0.005134815437486395, Final Batch Loss: 0.004764208570122719\n",
      "Epoch 779, Loss: 0.00817745304084383, Final Batch Loss: 0.0003195724857505411\n",
      "Epoch 780, Loss: 0.003302649944089353, Final Batch Loss: 0.003021473065018654\n",
      "Epoch 781, Loss: 0.0008776146860327572, Final Batch Loss: 0.0001578468072693795\n",
      "Epoch 782, Loss: 0.017230330617167056, Final Batch Loss: 0.016475006937980652\n",
      "Epoch 783, Loss: 0.0008268063247669488, Final Batch Loss: 0.0004581314860843122\n",
      "Epoch 784, Loss: 0.0018570130923762918, Final Batch Loss: 0.0007239629048854113\n",
      "Epoch 785, Loss: 0.014303565956652164, Final Batch Loss: 0.011961853131651878\n",
      "Epoch 786, Loss: 0.01018458693579305, Final Batch Loss: 0.00016978471830952913\n",
      "Epoch 787, Loss: 0.005241159116849303, Final Batch Loss: 0.0025805109180510044\n",
      "Epoch 788, Loss: 0.00968276895582676, Final Batch Loss: 0.008066198788583279\n",
      "Epoch 789, Loss: 0.015124363679205999, Final Batch Loss: 0.014790499582886696\n",
      "Epoch 790, Loss: 0.002456349495332688, Final Batch Loss: 0.0015673682792112231\n",
      "Epoch 791, Loss: 0.008310278411954641, Final Batch Loss: 0.0029484936967492104\n",
      "Epoch 792, Loss: 0.005856342730112374, Final Batch Loss: 0.0006606305250898004\n",
      "Epoch 793, Loss: 0.0018171999254263937, Final Batch Loss: 0.001114761340431869\n",
      "Epoch 794, Loss: 0.002082261664327234, Final Batch Loss: 0.0017996318638324738\n",
      "Epoch 795, Loss: 0.004999685217626393, Final Batch Loss: 0.0030695933382958174\n",
      "Epoch 796, Loss: 0.0010304809402441606, Final Batch Loss: 0.0002096044918289408\n",
      "Epoch 797, Loss: 0.0007320672157220542, Final Batch Loss: 0.0003757531230803579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798, Loss: 0.0017313486314378679, Final Batch Loss: 0.0007932625012472272\n",
      "Epoch 799, Loss: 0.01804797980003059, Final Batch Loss: 0.0021138701122254133\n",
      "Epoch 800, Loss: 0.00088433941709809, Final Batch Loss: 0.0004934463649988174\n",
      "Epoch 801, Loss: 0.002007657283684239, Final Batch Loss: 0.0018416574457660317\n",
      "Epoch 802, Loss: 0.0011632352252490819, Final Batch Loss: 0.00030860939295962453\n",
      "Epoch 803, Loss: 0.001089598998078145, Final Batch Loss: 0.00019075094314757735\n",
      "Epoch 804, Loss: 0.00251593574648723, Final Batch Loss: 0.0006928707589395344\n",
      "Epoch 805, Loss: 0.0021781448158435524, Final Batch Loss: 0.0008933813660405576\n",
      "Epoch 806, Loss: 0.00828446273226291, Final Batch Loss: 0.000597211648710072\n",
      "Epoch 807, Loss: 0.004624417633749545, Final Batch Loss: 0.004355563782155514\n",
      "Epoch 808, Loss: 0.0009839127014856786, Final Batch Loss: 0.00034694591886363924\n",
      "Epoch 809, Loss: 0.006149625405669212, Final Batch Loss: 0.005035429261624813\n",
      "Epoch 810, Loss: 0.0013218662497820333, Final Batch Loss: 0.00021357550576794893\n",
      "Epoch 811, Loss: 0.0017678199365036562, Final Batch Loss: 0.00023588638578075916\n",
      "Epoch 812, Loss: 0.002862107940018177, Final Batch Loss: 0.0015716934576630592\n",
      "Epoch 813, Loss: 0.00046226519043557346, Final Batch Loss: 0.00016821714234538376\n",
      "Epoch 814, Loss: 0.001293287961743772, Final Batch Loss: 0.0005755915190093219\n",
      "Epoch 815, Loss: 0.0003791443450609222, Final Batch Loss: 0.00026668451027944684\n",
      "Epoch 816, Loss: 0.0016470914270030335, Final Batch Loss: 0.00017132826906163245\n",
      "Epoch 817, Loss: 0.006235850043594837, Final Batch Loss: 0.003854211885482073\n",
      "Epoch 818, Loss: 0.000980138749582693, Final Batch Loss: 0.0006801138515584171\n",
      "Epoch 819, Loss: 0.0015021231956779957, Final Batch Loss: 0.0010848226957023144\n",
      "Epoch 820, Loss: 0.008439297555014491, Final Batch Loss: 0.0011605818290263414\n",
      "Epoch 821, Loss: 0.004827706899959594, Final Batch Loss: 0.0039310818538069725\n",
      "Epoch 822, Loss: 0.0016169778537005186, Final Batch Loss: 0.0006842022994533181\n",
      "Epoch 823, Loss: 0.0008562565344618633, Final Batch Loss: 0.00014141436258796602\n",
      "Epoch 824, Loss: 0.0014465933199971914, Final Batch Loss: 0.0010116779012605548\n",
      "Epoch 825, Loss: 0.004094773321412504, Final Batch Loss: 0.00089701556134969\n",
      "Epoch 826, Loss: 0.002740984840784222, Final Batch Loss: 0.0009525659843347967\n",
      "Epoch 827, Loss: 0.0020173346856608987, Final Batch Loss: 0.0009089232189580798\n",
      "Epoch 828, Loss: 0.0006159171171020716, Final Batch Loss: 0.00015317107317969203\n",
      "Epoch 829, Loss: 0.0010933764860965312, Final Batch Loss: 0.0004365973873063922\n",
      "Epoch 830, Loss: 0.002118366421200335, Final Batch Loss: 0.0006911042146384716\n",
      "Epoch 831, Loss: 0.002197160676587373, Final Batch Loss: 0.0016672357451170683\n",
      "Epoch 832, Loss: 0.010656651138560846, Final Batch Loss: 0.010197757743299007\n",
      "Epoch 833, Loss: 0.008930480340495706, Final Batch Loss: 0.001479970058426261\n",
      "Epoch 834, Loss: 0.021499257010873407, Final Batch Loss: 0.020947568118572235\n",
      "Epoch 835, Loss: 0.001555065915454179, Final Batch Loss: 0.0008681727922521532\n",
      "Epoch 836, Loss: 0.012109384493669495, Final Batch Loss: 0.011645408347249031\n",
      "Epoch 837, Loss: 0.0012158503523096442, Final Batch Loss: 0.0004087794222868979\n",
      "Epoch 838, Loss: 0.0013833549164701253, Final Batch Loss: 0.00047625458682887256\n",
      "Epoch 839, Loss: 0.004275611718185246, Final Batch Loss: 0.0010510397842153907\n",
      "Epoch 840, Loss: 0.01632821641396731, Final Batch Loss: 0.01583600975573063\n",
      "Epoch 841, Loss: 0.016315284185111523, Final Batch Loss: 0.015135811641812325\n",
      "Epoch 842, Loss: 0.00783941713598324, Final Batch Loss: 6.634048622800037e-05\n",
      "Epoch 843, Loss: 0.01458886219188571, Final Batch Loss: 0.013896038755774498\n",
      "Epoch 844, Loss: 0.012321827351115644, Final Batch Loss: 0.0007948115235194564\n",
      "Epoch 845, Loss: 0.0015525839698966593, Final Batch Loss: 0.0004809027013834566\n",
      "Epoch 846, Loss: 0.0007631666958332062, Final Batch Loss: 0.0004907660186290741\n",
      "Epoch 847, Loss: 0.0038379495963454247, Final Batch Loss: 0.0030916498508304358\n",
      "Epoch 848, Loss: 0.0026088746963068843, Final Batch Loss: 0.001306535443291068\n",
      "Epoch 849, Loss: 0.00193967972882092, Final Batch Loss: 0.001415930804796517\n",
      "Epoch 850, Loss: 0.023557323147542775, Final Batch Loss: 0.02193905971944332\n",
      "Epoch 851, Loss: 0.0020995333325117826, Final Batch Loss: 0.0005613350076600909\n",
      "Epoch 852, Loss: 0.003200878738425672, Final Batch Loss: 0.001660971436649561\n",
      "Epoch 853, Loss: 0.0013928358675912023, Final Batch Loss: 0.0006629267008975148\n",
      "Epoch 854, Loss: 0.0009375655208714306, Final Batch Loss: 0.0006616426398977637\n",
      "Epoch 855, Loss: 0.000309924827888608, Final Batch Loss: 0.00015768666344229132\n",
      "Epoch 856, Loss: 0.0019860596512444317, Final Batch Loss: 0.0013624263228848577\n",
      "Epoch 857, Loss: 0.0007221307896543294, Final Batch Loss: 0.0003638559428509325\n",
      "Epoch 858, Loss: 0.002592551347333938, Final Batch Loss: 0.0005216079880483449\n",
      "Epoch 859, Loss: 0.0072654662653803825, Final Batch Loss: 0.0003091045655310154\n",
      "Epoch 860, Loss: 0.024201231964980252, Final Batch Loss: 0.00015577203885186464\n",
      "Epoch 861, Loss: 0.0013560811057686806, Final Batch Loss: 0.0007275737589225173\n",
      "Epoch 862, Loss: 0.001068595563992858, Final Batch Loss: 0.00027843628777191043\n",
      "Epoch 863, Loss: 0.00309982115868479, Final Batch Loss: 0.0020364585798233747\n",
      "Epoch 864, Loss: 0.0017969393520615995, Final Batch Loss: 0.0012152879498898983\n",
      "Epoch 865, Loss: 0.0014952682540751994, Final Batch Loss: 0.0006497928989119828\n",
      "Epoch 866, Loss: 0.0015021830622572452, Final Batch Loss: 0.0011206242488697171\n",
      "Epoch 867, Loss: 0.001968080992810428, Final Batch Loss: 0.0004970120498910546\n",
      "Epoch 868, Loss: 0.0016897009336389601, Final Batch Loss: 0.0005584972095675766\n",
      "Epoch 869, Loss: 0.015511020319536328, Final Batch Loss: 0.013662360608577728\n",
      "Epoch 870, Loss: 0.0010968709830194712, Final Batch Loss: 0.0005373989115469158\n",
      "Epoch 871, Loss: 0.0014248492079786956, Final Batch Loss: 0.00042045029113069177\n",
      "Epoch 872, Loss: 0.0013342188904061913, Final Batch Loss: 0.0009203930967487395\n",
      "Epoch 873, Loss: 0.001231080386787653, Final Batch Loss: 0.0007831669645383954\n",
      "Epoch 874, Loss: 0.01543351955479011, Final Batch Loss: 0.0009476174018345773\n",
      "Epoch 875, Loss: 0.0009199869818985462, Final Batch Loss: 0.00041594478534534574\n",
      "Epoch 876, Loss: 0.001479961327277124, Final Batch Loss: 0.0003436356782913208\n",
      "Epoch 877, Loss: 0.000841050103190355, Final Batch Loss: 0.00021017219114582986\n",
      "Epoch 878, Loss: 0.0009749388555064797, Final Batch Loss: 0.0005649085505865514\n",
      "Epoch 879, Loss: 0.003249892732128501, Final Batch Loss: 0.001866856124252081\n",
      "Epoch 880, Loss: 0.0026832044823095202, Final Batch Loss: 0.0016806909115985036\n",
      "Epoch 881, Loss: 0.001776011529727839, Final Batch Loss: 0.0015384984435513616\n",
      "Epoch 882, Loss: 0.006500889576273039, Final Batch Loss: 0.00616033049300313\n",
      "Epoch 883, Loss: 0.0009420318529009819, Final Batch Loss: 0.0002706766244955361\n",
      "Epoch 884, Loss: 0.0024582751793786883, Final Batch Loss: 0.0009989052778109908\n",
      "Epoch 885, Loss: 0.0008838017238304019, Final Batch Loss: 0.0007019530748948455\n",
      "Epoch 886, Loss: 0.018559033516794443, Final Batch Loss: 0.0030550998635590076\n",
      "Epoch 887, Loss: 0.019174266373738647, Final Batch Loss: 0.018165819346904755\n",
      "Epoch 888, Loss: 0.0006660507206106558, Final Batch Loss: 0.00021056189143564552\n",
      "Epoch 889, Loss: 0.0071577500202693045, Final Batch Loss: 0.0005945661687292159\n",
      "Epoch 890, Loss: 0.013892540242522955, Final Batch Loss: 0.0007248544134199619\n",
      "Epoch 891, Loss: 0.0023029183503240347, Final Batch Loss: 0.001904654665850103\n",
      "Epoch 892, Loss: 0.0009479131258558482, Final Batch Loss: 0.0004500104987528175\n",
      "Epoch 893, Loss: 0.0006549298414029181, Final Batch Loss: 0.00038517932989634573\n",
      "Epoch 894, Loss: 0.0013786816562060267, Final Batch Loss: 0.0003982682537753135\n",
      "Epoch 895, Loss: 0.009972669242415577, Final Batch Loss: 0.0004726136685349047\n",
      "Epoch 896, Loss: 0.0021751078020315617, Final Batch Loss: 0.0018480027792975307\n",
      "Epoch 897, Loss: 0.0018171322881244123, Final Batch Loss: 0.0005039796815253794\n",
      "Epoch 898, Loss: 0.0038535238127224147, Final Batch Loss: 0.0005060473340563476\n",
      "Epoch 899, Loss: 0.0013547171256504953, Final Batch Loss: 0.00029389577684924006\n",
      "Epoch 900, Loss: 0.009681201030616648, Final Batch Loss: 0.009478934109210968\n",
      "Epoch 901, Loss: 0.003950142883695662, Final Batch Loss: 0.003421888453885913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902, Loss: 0.0014405753463506699, Final Batch Loss: 0.00024524505715817213\n",
      "Epoch 903, Loss: 0.007598868105560541, Final Batch Loss: 0.0010361834429204464\n",
      "Epoch 904, Loss: 0.0009142165945377201, Final Batch Loss: 0.00043503177585080266\n",
      "Epoch 905, Loss: 0.0015805911971256137, Final Batch Loss: 0.0006332396878860891\n",
      "Epoch 906, Loss: 0.0035903205280192196, Final Batch Loss: 0.0004425484803505242\n",
      "Epoch 907, Loss: 0.0008906558796297759, Final Batch Loss: 0.00032001189538277686\n",
      "Epoch 908, Loss: 0.0017681856988929212, Final Batch Loss: 0.0005065115983597934\n",
      "Epoch 909, Loss: 0.0022157577623147517, Final Batch Loss: 0.0004465868987608701\n",
      "Epoch 910, Loss: 0.0019992066954728216, Final Batch Loss: 0.0004312870732974261\n",
      "Epoch 911, Loss: 0.0014086414448684081, Final Batch Loss: 0.0011859360383823514\n",
      "Epoch 912, Loss: 0.00047046465624589473, Final Batch Loss: 0.0002448181330692023\n",
      "Epoch 913, Loss: 0.001761295658070594, Final Batch Loss: 0.0007384359487332404\n",
      "Epoch 914, Loss: 0.0005484211433213204, Final Batch Loss: 0.00026185749447904527\n",
      "Epoch 915, Loss: 0.0007232882344396785, Final Batch Loss: 0.00013889560068491846\n",
      "Epoch 916, Loss: 0.0013579874066635966, Final Batch Loss: 0.00039628520607948303\n",
      "Epoch 917, Loss: 0.0007015242299530655, Final Batch Loss: 0.00025323135196231306\n",
      "Epoch 918, Loss: 0.0006892146193422377, Final Batch Loss: 0.0002463251003064215\n",
      "Epoch 919, Loss: 0.0015198239125311375, Final Batch Loss: 0.001086253672838211\n",
      "Epoch 920, Loss: 0.0015818415267858654, Final Batch Loss: 0.0003111019323114306\n",
      "Epoch 921, Loss: 0.0012893181410618126, Final Batch Loss: 0.0005243030609562993\n",
      "Epoch 922, Loss: 0.020635133609175682, Final Batch Loss: 0.010885973460972309\n",
      "Epoch 923, Loss: 0.006681433602352627, Final Batch Loss: 0.0002400751254754141\n",
      "Epoch 924, Loss: 0.0006764702848158777, Final Batch Loss: 0.00013170531019568443\n",
      "Epoch 925, Loss: 0.014794585527852178, Final Batch Loss: 0.000544355483725667\n",
      "Epoch 926, Loss: 0.0006718391232425347, Final Batch Loss: 0.00012220728967804462\n",
      "Epoch 927, Loss: 0.0015786025032866746, Final Batch Loss: 0.001355172018520534\n",
      "Epoch 928, Loss: 0.0009795209334697574, Final Batch Loss: 0.00036370664020068944\n",
      "Epoch 929, Loss: 0.0009171668207272887, Final Batch Loss: 0.00022856728173792362\n",
      "Epoch 930, Loss: 0.0046613824961241335, Final Batch Loss: 0.0002465353754814714\n",
      "Epoch 931, Loss: 0.003066218108870089, Final Batch Loss: 0.0017028403235599399\n",
      "Epoch 932, Loss: 0.0053224165458232164, Final Batch Loss: 0.004728176165372133\n",
      "Epoch 933, Loss: 0.000348507659509778, Final Batch Loss: 0.00014760125486645848\n",
      "Epoch 934, Loss: 0.007510002644266933, Final Batch Loss: 0.00046700233360752463\n",
      "Epoch 935, Loss: 0.0005794348398922011, Final Batch Loss: 0.00021395385556388646\n",
      "Epoch 936, Loss: 0.0015023380692582577, Final Batch Loss: 0.0001971439633052796\n",
      "Epoch 937, Loss: 0.0007483833469450474, Final Batch Loss: 0.0003418493433855474\n",
      "Epoch 938, Loss: 0.0010207861487288028, Final Batch Loss: 0.0005800540675409138\n",
      "Epoch 939, Loss: 0.0005404120602179319, Final Batch Loss: 0.0002175944100599736\n",
      "Epoch 940, Loss: 0.0007460688939318061, Final Batch Loss: 0.0004398410383146256\n",
      "Epoch 941, Loss: 0.01170116220600903, Final Batch Loss: 0.010211094282567501\n",
      "Epoch 942, Loss: 0.0033877569367177784, Final Batch Loss: 0.003054684493690729\n",
      "Epoch 943, Loss: 0.0006153826543595642, Final Batch Loss: 0.00033839643583633006\n",
      "Epoch 944, Loss: 0.0007066169928293675, Final Batch Loss: 0.00015647176769562066\n",
      "Epoch 945, Loss: 0.009927563834935427, Final Batch Loss: 0.009664678946137428\n",
      "Epoch 946, Loss: 0.0051365295657888055, Final Batch Loss: 0.0011515963124111295\n",
      "Epoch 947, Loss: 0.00047689504572190344, Final Batch Loss: 0.00027223050710745156\n",
      "Epoch 948, Loss: 0.0006432884547393769, Final Batch Loss: 0.00029326367075555027\n",
      "Epoch 949, Loss: 0.010683920452720486, Final Batch Loss: 0.010452216491103172\n",
      "Epoch 950, Loss: 0.017558831721544266, Final Batch Loss: 0.01631324738264084\n",
      "Epoch 951, Loss: 0.01572426175698638, Final Batch Loss: 0.009123150259256363\n",
      "Epoch 952, Loss: 0.0010563800751697272, Final Batch Loss: 0.0006851715152151883\n",
      "Epoch 953, Loss: 0.0010598582157399505, Final Batch Loss: 0.00039926785393618047\n",
      "Epoch 954, Loss: 0.012770416855346411, Final Batch Loss: 0.00018360622925683856\n",
      "Epoch 955, Loss: 0.0006767923186998814, Final Batch Loss: 0.0003862505254801363\n",
      "Epoch 956, Loss: 0.003076390450587496, Final Batch Loss: 0.00043528000242076814\n",
      "Epoch 957, Loss: 0.0018577222945168614, Final Batch Loss: 0.0008842535899020731\n",
      "Epoch 958, Loss: 0.006398193654604256, Final Batch Loss: 0.0003286759601905942\n",
      "Epoch 959, Loss: 0.002503810857888311, Final Batch Loss: 0.0019431592663750052\n",
      "Epoch 960, Loss: 0.000580029038246721, Final Batch Loss: 0.00022819259902462363\n",
      "Epoch 961, Loss: 0.0004106961641809903, Final Batch Loss: 9.485499322181568e-05\n",
      "Epoch 962, Loss: 0.0010917510953731835, Final Batch Loss: 0.00028333027148619294\n",
      "Epoch 963, Loss: 0.0007290918729268014, Final Batch Loss: 0.00045946601312607527\n",
      "Epoch 964, Loss: 0.0014177254197420552, Final Batch Loss: 0.00022595359769184142\n",
      "Epoch 965, Loss: 0.0009623785153962672, Final Batch Loss: 0.0003684709081426263\n",
      "Epoch 966, Loss: 0.0016789831133792177, Final Batch Loss: 0.00021430793276522309\n",
      "Epoch 967, Loss: 0.000436118571087718, Final Batch Loss: 0.0001845196238718927\n",
      "Epoch 968, Loss: 0.003059625974856317, Final Batch Loss: 0.0015810400946065784\n",
      "Epoch 969, Loss: 0.001918263384141028, Final Batch Loss: 0.0010103760287165642\n",
      "Epoch 970, Loss: 0.0030464858864434063, Final Batch Loss: 0.0005492792115546763\n",
      "Epoch 971, Loss: 0.001297746493946761, Final Batch Loss: 0.0006952877738513052\n",
      "Epoch 972, Loss: 0.0006122577178757638, Final Batch Loss: 0.00033094495302066207\n",
      "Epoch 973, Loss: 0.0010124529362656176, Final Batch Loss: 0.0004273581434972584\n",
      "Epoch 974, Loss: 0.0012489949585869908, Final Batch Loss: 0.0006944186752662063\n",
      "Epoch 975, Loss: 0.012034372659400105, Final Batch Loss: 0.011234313249588013\n",
      "Epoch 976, Loss: 0.0069865434197708964, Final Batch Loss: 0.0015465536853298545\n",
      "Epoch 977, Loss: 0.0050298720598220825, Final Batch Loss: 0.003841609926894307\n",
      "Epoch 978, Loss: 0.0007815456774551421, Final Batch Loss: 0.00027036716346628964\n",
      "Epoch 979, Loss: 0.0015207490068860352, Final Batch Loss: 0.0009172234567813575\n",
      "Epoch 980, Loss: 0.0017765697266440839, Final Batch Loss: 0.00023429605062119663\n",
      "Epoch 981, Loss: 0.0009993715502787381, Final Batch Loss: 0.0007525387336499989\n",
      "Epoch 982, Loss: 0.0010555648914305493, Final Batch Loss: 0.0008595777908340096\n",
      "Epoch 983, Loss: 0.000959259326918982, Final Batch Loss: 0.0007329244981519878\n",
      "Epoch 984, Loss: 0.0010661380365490913, Final Batch Loss: 0.0003499542362987995\n",
      "Epoch 985, Loss: 0.009640800126362592, Final Batch Loss: 0.008969304151833057\n",
      "Epoch 986, Loss: 0.00045545565080828965, Final Batch Loss: 0.00015204682131297886\n",
      "Epoch 987, Loss: 0.0011045711289625615, Final Batch Loss: 0.0007778106373734772\n",
      "Epoch 988, Loss: 0.0006410012283595279, Final Batch Loss: 0.00020346352539490908\n",
      "Epoch 989, Loss: 0.0030171251855790615, Final Batch Loss: 0.0005054816137999296\n",
      "Epoch 990, Loss: 0.002977819473017007, Final Batch Loss: 0.0027078608982264996\n",
      "Epoch 991, Loss: 0.0012805603619199246, Final Batch Loss: 0.001107143354602158\n",
      "Epoch 992, Loss: 0.007702607428655028, Final Batch Loss: 0.0002738491166383028\n",
      "Epoch 993, Loss: 0.0030511527584167197, Final Batch Loss: 0.002864277921617031\n",
      "Epoch 994, Loss: 0.014354052109410986, Final Batch Loss: 0.014052481390535831\n",
      "Epoch 995, Loss: 0.00027814958593808115, Final Batch Loss: 0.0001260218268726021\n",
      "Epoch 996, Loss: 0.0006996069205342792, Final Batch Loss: 0.00011532610369613394\n",
      "Epoch 997, Loss: 0.0012182830250822008, Final Batch Loss: 0.0005673982668668032\n",
      "Epoch 998, Loss: 0.0007811603136360645, Final Batch Loss: 0.0005365682300180197\n",
      "Epoch 999, Loss: 0.0007699673005845398, Final Batch Loss: 0.00025432617985643446\n",
      "Epoch 1000, Loss: 0.0008988541376311332, Final Batch Loss: 0.0002973689988721162\n",
      "Epoch 1001, Loss: 0.0010257740650558844, Final Batch Loss: 0.0008314953302033246\n",
      "Epoch 1002, Loss: 0.010361341235693544, Final Batch Loss: 0.00046997092431411147\n",
      "Epoch 1003, Loss: 0.003429823729675263, Final Batch Loss: 0.0004934884491376579\n",
      "Epoch 1004, Loss: 0.0013644956925418228, Final Batch Loss: 0.00024844062863849103\n",
      "Epoch 1005, Loss: 0.0012593455903697759, Final Batch Loss: 0.00036054124939255416\n",
      "Epoch 1006, Loss: 0.0012004274758510292, Final Batch Loss: 0.00016436033183708787\n",
      "Epoch 1007, Loss: 0.0005209952068980783, Final Batch Loss: 0.00036310384166426957\n",
      "Epoch 1008, Loss: 0.0011122841679025441, Final Batch Loss: 0.0010297015542164445\n",
      "Epoch 1009, Loss: 0.0032135173678398132, Final Batch Loss: 0.0028946332167834044\n",
      "Epoch 1010, Loss: 0.000898159749340266, Final Batch Loss: 0.00028075918089598417\n",
      "Epoch 1011, Loss: 0.0006679825892206281, Final Batch Loss: 0.00035857947659678757\n",
      "Epoch 1012, Loss: 0.00038332425174303353, Final Batch Loss: 0.00016269739717245102\n",
      "Epoch 1013, Loss: 0.000788477118476294, Final Batch Loss: 0.0005760248750448227\n",
      "Epoch 1014, Loss: 0.002289424679474905, Final Batch Loss: 0.0004172345215920359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1015, Loss: 0.0008224176417570561, Final Batch Loss: 0.00038780953036621213\n",
      "Epoch 1016, Loss: 0.0008652442484162748, Final Batch Loss: 0.0006700529484078288\n",
      "Epoch 1017, Loss: 0.003527931577991694, Final Batch Loss: 0.0030243752989917994\n",
      "Epoch 1018, Loss: 0.0008152922673616558, Final Batch Loss: 0.0004949527210555971\n",
      "Epoch 1019, Loss: 0.002311432996066287, Final Batch Loss: 0.00028730116900987923\n",
      "Epoch 1020, Loss: 0.008838291629217565, Final Batch Loss: 0.0006649357965216041\n",
      "Epoch 1021, Loss: 0.0006333584315143526, Final Batch Loss: 0.0002957459073513746\n",
      "Epoch 1022, Loss: 0.010508020350243896, Final Batch Loss: 0.009599928744137287\n",
      "Epoch 1023, Loss: 0.009701158982352354, Final Batch Loss: 0.009474338963627815\n",
      "Epoch 1024, Loss: 0.0002522219074307941, Final Batch Loss: 8.287415403174236e-05\n",
      "Epoch 1025, Loss: 0.0007027962419670075, Final Batch Loss: 0.00026649728533811867\n",
      "Epoch 1026, Loss: 0.0011895520146936178, Final Batch Loss: 0.0004825043142773211\n",
      "Epoch 1027, Loss: 0.0003745257999980822, Final Batch Loss: 0.00022103777155280113\n",
      "Epoch 1028, Loss: 0.0006579195178346708, Final Batch Loss: 0.00018934936088044196\n",
      "Epoch 1029, Loss: 0.008078291721176356, Final Batch Loss: 0.0001399327884428203\n",
      "Epoch 1030, Loss: 0.0010295008833054453, Final Batch Loss: 0.0006522023468278348\n",
      "Epoch 1031, Loss: 0.0010572243918431923, Final Batch Loss: 0.00015408369654323906\n",
      "Epoch 1032, Loss: 0.0012807573075406253, Final Batch Loss: 0.0011307189706712961\n",
      "Epoch 1033, Loss: 0.0032099780219141394, Final Batch Loss: 0.0030862586572766304\n",
      "Epoch 1034, Loss: 0.0011462689726613462, Final Batch Loss: 0.00040904164779931307\n",
      "Epoch 1035, Loss: 0.00032258008286589757, Final Batch Loss: 0.00021344514971133322\n",
      "Epoch 1036, Loss: 0.0006282404792727903, Final Batch Loss: 0.00039874992216937244\n",
      "Epoch 1037, Loss: 0.00042506339377723634, Final Batch Loss: 0.00019091997819487005\n",
      "Epoch 1038, Loss: 0.015431657047884073, Final Batch Loss: 0.01536544319242239\n",
      "Epoch 1039, Loss: 0.000599600956775248, Final Batch Loss: 0.00046532967826351523\n",
      "Epoch 1040, Loss: 0.01712603105988819, Final Batch Loss: 0.016957314684987068\n",
      "Epoch 1041, Loss: 0.005741565692005679, Final Batch Loss: 0.00033675480517558753\n",
      "Epoch 1042, Loss: 0.0006237515481188893, Final Batch Loss: 0.00023514535860158503\n",
      "Epoch 1043, Loss: 0.0005275022267596796, Final Batch Loss: 0.0003246779670007527\n",
      "Epoch 1044, Loss: 0.0010992896859534085, Final Batch Loss: 0.0008604757604189217\n",
      "Epoch 1045, Loss: 0.001493343967013061, Final Batch Loss: 0.00035986024886369705\n",
      "Epoch 1046, Loss: 0.001224561536218971, Final Batch Loss: 0.0008572745136916637\n",
      "Epoch 1047, Loss: 0.0058146900264546275, Final Batch Loss: 0.005230803042650223\n",
      "Epoch 1048, Loss: 0.005604117322945967, Final Batch Loss: 0.00037465585046447814\n",
      "Epoch 1049, Loss: 0.0006049723306205124, Final Batch Loss: 0.00026731236721388996\n",
      "Epoch 1050, Loss: 0.005836339812958613, Final Batch Loss: 0.00031298413523472846\n",
      "Epoch 1051, Loss: 0.019279916305094957, Final Batch Loss: 0.0007315916009247303\n",
      "Epoch 1052, Loss: 0.0009672502346802503, Final Batch Loss: 0.0007243965519592166\n",
      "Epoch 1053, Loss: 0.0065221351105719805, Final Batch Loss: 0.0025521048810333014\n",
      "Epoch 1054, Loss: 0.006686674838420004, Final Batch Loss: 0.00017345364904031157\n",
      "Epoch 1055, Loss: 0.0009994367719627917, Final Batch Loss: 0.0006589966942556202\n",
      "Epoch 1056, Loss: 0.0018673179292818531, Final Batch Loss: 0.00024113791005220264\n",
      "Epoch 1057, Loss: 0.0019667348242364824, Final Batch Loss: 0.0009432547376491129\n",
      "Epoch 1058, Loss: 0.0024247338296845555, Final Batch Loss: 0.0004422791535034776\n",
      "Epoch 1059, Loss: 0.0012704100809060037, Final Batch Loss: 0.0006386330351233482\n",
      "Epoch 1060, Loss: 0.0009986524528358132, Final Batch Loss: 0.0004701844591181725\n",
      "Epoch 1061, Loss: 0.0060380388458725065, Final Batch Loss: 0.005872158799320459\n",
      "Epoch 1062, Loss: 0.0006875412218505517, Final Batch Loss: 0.0005482856067828834\n",
      "Epoch 1063, Loss: 0.0005160034488653764, Final Batch Loss: 0.00016479640908073634\n",
      "Epoch 1064, Loss: 0.00048598795547150075, Final Batch Loss: 0.00023009919095784426\n",
      "Epoch 1065, Loss: 0.014717604324687272, Final Batch Loss: 0.0005694574792869389\n",
      "Epoch 1066, Loss: 0.0003381846327101812, Final Batch Loss: 0.00011915515642613173\n",
      "Epoch 1067, Loss: 0.0006347540256683715, Final Batch Loss: 0.0005565062165260315\n",
      "Epoch 1068, Loss: 0.00023667670029681176, Final Batch Loss: 0.0001244664890691638\n",
      "Epoch 1069, Loss: 0.012688300805166364, Final Batch Loss: 0.0005262589547783136\n",
      "Epoch 1070, Loss: 0.006181222212035209, Final Batch Loss: 0.0006913769175298512\n",
      "Epoch 1071, Loss: 0.004412081092596054, Final Batch Loss: 7.549626752734184e-05\n",
      "Epoch 1072, Loss: 0.0005994499369990081, Final Batch Loss: 0.00024506752379238605\n",
      "Epoch 1073, Loss: 0.001736442543915473, Final Batch Loss: 0.00017566453607287258\n",
      "Epoch 1074, Loss: 0.00035631414357339963, Final Batch Loss: 0.0002538147091399878\n",
      "Epoch 1075, Loss: 0.0005852130707353354, Final Batch Loss: 0.00042080035200342536\n",
      "Epoch 1076, Loss: 0.0009668121347203851, Final Batch Loss: 0.0007184865535236895\n",
      "Epoch 1077, Loss: 0.0008899877138901502, Final Batch Loss: 0.00031257039518095553\n",
      "Epoch 1078, Loss: 0.0004993690963601694, Final Batch Loss: 0.0003118599415756762\n",
      "Epoch 1079, Loss: 0.0014820948708802462, Final Batch Loss: 0.0011551688658073545\n",
      "Epoch 1080, Loss: 0.000560569649678655, Final Batch Loss: 8.570485806558281e-05\n",
      "Epoch 1081, Loss: 0.0022415852290578187, Final Batch Loss: 0.0003200923674739897\n",
      "Epoch 1082, Loss: 0.0006267211865633726, Final Batch Loss: 0.00029392490978352726\n",
      "Epoch 1083, Loss: 0.0010430910770082846, Final Batch Loss: 0.0008523922297172248\n",
      "Epoch 1084, Loss: 0.002226010838057846, Final Batch Loss: 0.0009103528573177755\n",
      "Epoch 1085, Loss: 0.00044793038978241384, Final Batch Loss: 0.00022756968974135816\n",
      "Epoch 1086, Loss: 0.0010481446515768766, Final Batch Loss: 0.000323105719871819\n",
      "Epoch 1087, Loss: 0.0003320978066767566, Final Batch Loss: 0.00012078132567694411\n",
      "Epoch 1088, Loss: 0.0007184066198533401, Final Batch Loss: 0.0005966592580080032\n",
      "Epoch 1089, Loss: 0.0006828092009527609, Final Batch Loss: 0.0004419068282004446\n",
      "Epoch 1090, Loss: 0.0005981746871839277, Final Batch Loss: 6.329057941911742e-05\n",
      "Epoch 1091, Loss: 0.0006307289950200357, Final Batch Loss: 9.576706361258402e-05\n",
      "Epoch 1092, Loss: 0.0003862084777210839, Final Batch Loss: 0.00010949993884423748\n",
      "Epoch 1093, Loss: 0.0003832172369584441, Final Batch Loss: 0.00016883843636605889\n",
      "Epoch 1094, Loss: 0.0004706902618636377, Final Batch Loss: 0.0001169729875982739\n",
      "Epoch 1095, Loss: 0.000500412323162891, Final Batch Loss: 0.00032060270314104855\n",
      "Epoch 1096, Loss: 0.0011416204943088815, Final Batch Loss: 0.00018909403297584504\n",
      "Epoch 1097, Loss: 0.0012096051941625774, Final Batch Loss: 0.0009862345177680254\n",
      "Epoch 1098, Loss: 0.0005285181978251785, Final Batch Loss: 0.00035603719879873097\n",
      "Epoch 1099, Loss: 0.0006081110332161188, Final Batch Loss: 0.0003532874397933483\n",
      "Epoch 1100, Loss: 0.0012434626114554703, Final Batch Loss: 0.0007496055332012475\n",
      "Epoch 1101, Loss: 0.0008382065134355798, Final Batch Loss: 0.00020308421517256647\n",
      "Epoch 1102, Loss: 0.00030246722599258646, Final Batch Loss: 7.779645238770172e-05\n",
      "Epoch 1103, Loss: 0.0006293111364357173, Final Batch Loss: 0.00031862492323853076\n",
      "Epoch 1104, Loss: 0.002626186527777463, Final Batch Loss: 0.0001710644573904574\n",
      "Epoch 1105, Loss: 0.0006934518314665183, Final Batch Loss: 0.0004730959190055728\n",
      "Epoch 1106, Loss: 0.0022362056333804503, Final Batch Loss: 0.0020113037899136543\n",
      "Epoch 1107, Loss: 0.0006746430735802278, Final Batch Loss: 0.000545208458788693\n",
      "Epoch 1108, Loss: 0.0022753807133994997, Final Batch Loss: 0.0005670287064276636\n",
      "Epoch 1109, Loss: 0.017661135701928288, Final Batch Loss: 0.017082633450627327\n",
      "Epoch 1110, Loss: 0.0005380684597184882, Final Batch Loss: 0.000234062215895392\n",
      "Epoch 1111, Loss: 0.0002668483939487487, Final Batch Loss: 8.547281322535127e-05\n",
      "Epoch 1112, Loss: 0.017884905450046062, Final Batch Loss: 0.001141396351158619\n",
      "Epoch 1113, Loss: 0.011433581123128533, Final Batch Loss: 0.010553214699029922\n",
      "Epoch 1114, Loss: 0.0006805098091717809, Final Batch Loss: 0.0003224058891646564\n",
      "Epoch 1115, Loss: 0.0005893139204999898, Final Batch Loss: 4.094891846762039e-05\n",
      "Epoch 1116, Loss: 0.0007111542945494875, Final Batch Loss: 0.0001494008902227506\n",
      "Epoch 1117, Loss: 0.0009572415729053319, Final Batch Loss: 0.0004780753224622458\n",
      "Epoch 1118, Loss: 0.0003092276310781017, Final Batch Loss: 0.00011939303658436984\n",
      "Epoch 1119, Loss: 0.00042262263013981283, Final Batch Loss: 0.0002925685257650912\n",
      "Epoch 1120, Loss: 0.0006146354135125875, Final Batch Loss: 0.00027321616653352976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1121, Loss: 0.0028073593857698143, Final Batch Loss: 0.0026686808560043573\n",
      "Epoch 1122, Loss: 0.002706999657675624, Final Batch Loss: 0.0015930193476378918\n",
      "Epoch 1123, Loss: 0.0020775803131982684, Final Batch Loss: 0.00016780232544988394\n",
      "Epoch 1124, Loss: 0.00047626806917833164, Final Batch Loss: 0.00037680036621168256\n",
      "Epoch 1125, Loss: 0.019589164716308005, Final Batch Loss: 0.019472045823931694\n",
      "Epoch 1126, Loss: 0.0006320489628706127, Final Batch Loss: 0.00013765544281341136\n",
      "Epoch 1127, Loss: 0.0008017512445803732, Final Batch Loss: 0.0006195887108333409\n",
      "Epoch 1128, Loss: 0.0009096401190618053, Final Batch Loss: 0.0006665350520052016\n",
      "Epoch 1129, Loss: 0.0006202599033713341, Final Batch Loss: 0.0003160022897645831\n",
      "Epoch 1130, Loss: 0.0004376303986646235, Final Batch Loss: 0.00013463746290653944\n",
      "Epoch 1131, Loss: 0.009169254859443754, Final Batch Loss: 0.008891597390174866\n",
      "Epoch 1132, Loss: 0.007363763899775222, Final Batch Loss: 0.0003553193819243461\n",
      "Epoch 1133, Loss: 0.020410391967743635, Final Batch Loss: 0.0133854104205966\n",
      "Epoch 1134, Loss: 0.0016348764766007662, Final Batch Loss: 0.0006688988651148975\n",
      "Epoch 1135, Loss: 0.008429894580331165, Final Batch Loss: 4.6951121476013213e-05\n",
      "Epoch 1136, Loss: 0.0006329127645585686, Final Batch Loss: 0.00035123113775625825\n",
      "Epoch 1137, Loss: 0.0005215603887336329, Final Batch Loss: 0.0001618792157387361\n",
      "Epoch 1138, Loss: 0.0008875839412212372, Final Batch Loss: 0.00039525481406599283\n",
      "Epoch 1139, Loss: 0.0009214806195814162, Final Batch Loss: 0.0005939254187978804\n",
      "Epoch 1140, Loss: 0.0004833821876673028, Final Batch Loss: 0.00013854574353899807\n",
      "Epoch 1141, Loss: 0.0017596133257029578, Final Batch Loss: 0.00024370946630369872\n",
      "Epoch 1142, Loss: 0.000718841387424618, Final Batch Loss: 0.0003895116678904742\n",
      "Epoch 1143, Loss: 0.007083976932335645, Final Batch Loss: 0.0005451145698316395\n",
      "Epoch 1144, Loss: 0.0009337620576843619, Final Batch Loss: 0.0006765500293113291\n",
      "Epoch 1145, Loss: 0.0012482966994866729, Final Batch Loss: 0.000685316976159811\n",
      "Epoch 1146, Loss: 0.0011011913884431124, Final Batch Loss: 0.0005566825275309384\n",
      "Epoch 1147, Loss: 0.0006203182419994846, Final Batch Loss: 0.0004338556027505547\n",
      "Epoch 1148, Loss: 0.0017135317903012037, Final Batch Loss: 0.001444543246179819\n",
      "Epoch 1149, Loss: 0.010717012628447264, Final Batch Loss: 0.0004494941676966846\n",
      "Epoch 1150, Loss: 0.0005156112310942262, Final Batch Loss: 0.0003237389319110662\n",
      "Epoch 1151, Loss: 0.00018559345699031837, Final Batch Loss: 0.00012869171041529626\n",
      "Epoch 1152, Loss: 0.0018159430183004588, Final Batch Loss: 0.0003683323448058218\n",
      "Epoch 1153, Loss: 0.0011448372097220272, Final Batch Loss: 0.0003757448575925082\n",
      "Epoch 1154, Loss: 0.0007624576974194497, Final Batch Loss: 0.0006338770617730916\n",
      "Epoch 1155, Loss: 0.0008476676011923701, Final Batch Loss: 0.0002698339812923223\n",
      "Epoch 1156, Loss: 0.0006347335438476875, Final Batch Loss: 0.0004876537132076919\n",
      "Epoch 1157, Loss: 0.0003114789942628704, Final Batch Loss: 9.17911747819744e-05\n",
      "Epoch 1158, Loss: 0.0019193384796380997, Final Batch Loss: 0.0010423281928524375\n",
      "Epoch 1159, Loss: 0.00022653723135590553, Final Batch Loss: 7.111034938134253e-05\n",
      "Epoch 1160, Loss: 0.0006755718641215935, Final Batch Loss: 0.0001418079627910629\n",
      "Epoch 1161, Loss: 0.00043872515379916877, Final Batch Loss: 0.00027633790159597993\n",
      "Epoch 1162, Loss: 0.0018905022297985852, Final Batch Loss: 0.0014206551713868976\n",
      "Epoch 1163, Loss: 0.009662154072429985, Final Batch Loss: 0.008932782337069511\n",
      "Epoch 1164, Loss: 0.00020248682994861156, Final Batch Loss: 0.0001171541734947823\n",
      "Epoch 1165, Loss: 0.0005733944854000583, Final Batch Loss: 0.00015227955009322613\n",
      "Epoch 1166, Loss: 0.007642422468052246, Final Batch Loss: 0.00021101640595588833\n",
      "Epoch 1167, Loss: 0.0073817486118059605, Final Batch Loss: 0.00011561039718799293\n",
      "Epoch 1168, Loss: 0.0009569031826686114, Final Batch Loss: 0.0005856638308614492\n",
      "Epoch 1169, Loss: 0.0019264246802777052, Final Batch Loss: 0.0012832542415708303\n",
      "Epoch 1170, Loss: 0.0006629348208662122, Final Batch Loss: 0.0003243240644223988\n",
      "Epoch 1171, Loss: 0.0009533642587484792, Final Batch Loss: 0.00015018846897874027\n",
      "Epoch 1172, Loss: 0.0010914587182924151, Final Batch Loss: 0.0009075119742192328\n",
      "Epoch 1173, Loss: 0.02741177094867453, Final Batch Loss: 0.027093669399619102\n",
      "Epoch 1174, Loss: 0.0010471736022736877, Final Batch Loss: 0.0003111021069344133\n",
      "Epoch 1175, Loss: 0.0013343542232178152, Final Batch Loss: 0.0007966993725858629\n",
      "Epoch 1176, Loss: 0.00019353155221324414, Final Batch Loss: 0.00011931392509723082\n",
      "Epoch 1177, Loss: 0.0011592633672989905, Final Batch Loss: 0.0006026114569976926\n",
      "Epoch 1178, Loss: 0.014143413747660816, Final Batch Loss: 0.00037089630495756865\n",
      "Epoch 1179, Loss: 0.018602239550091326, Final Batch Loss: 0.017366116866469383\n",
      "Epoch 1180, Loss: 0.007711020298302174, Final Batch Loss: 0.001957508735358715\n",
      "Epoch 1181, Loss: 0.010072563833091408, Final Batch Loss: 0.00016467651585116982\n",
      "Epoch 1182, Loss: 0.008078264378127642, Final Batch Loss: 6.995939475018531e-05\n",
      "Epoch 1183, Loss: 0.00043077087320853025, Final Batch Loss: 0.00028732698410749435\n",
      "Epoch 1184, Loss: 0.0005342653603293002, Final Batch Loss: 0.00010676239617168903\n",
      "Epoch 1185, Loss: 0.0010653814824763685, Final Batch Loss: 0.0003007130871992558\n",
      "Epoch 1186, Loss: 0.005010283210140187, Final Batch Loss: 0.00010786450729938224\n",
      "Epoch 1187, Loss: 0.0009180494089378044, Final Batch Loss: 0.0007131024613045156\n",
      "Epoch 1188, Loss: 0.0038530356105184183, Final Batch Loss: 0.0036822070833295584\n",
      "Epoch 1189, Loss: 0.0009528903901809826, Final Batch Loss: 0.0008564993622712791\n",
      "Epoch 1190, Loss: 0.0009383541182614863, Final Batch Loss: 0.0008382555097341537\n",
      "Epoch 1191, Loss: 0.023111633665394038, Final Batch Loss: 0.022919170558452606\n",
      "Epoch 1192, Loss: 0.0011965601588599384, Final Batch Loss: 0.00037369306664913893\n",
      "Epoch 1193, Loss: 0.01853604707866907, Final Batch Loss: 0.008624397218227386\n",
      "Epoch 1194, Loss: 0.0005226217326708138, Final Batch Loss: 0.0002168540668208152\n",
      "Epoch 1195, Loss: 0.038983557373285294, Final Batch Loss: 0.03838389739394188\n",
      "Epoch 1196, Loss: 0.0005680779286194593, Final Batch Loss: 0.00038309628143906593\n",
      "Epoch 1197, Loss: 0.00047099012590479106, Final Batch Loss: 7.368381193373352e-05\n",
      "Epoch 1198, Loss: 0.009718497094581835, Final Batch Loss: 8.650477684568614e-05\n",
      "Epoch 1199, Loss: 0.0012006863253191113, Final Batch Loss: 0.00020744430366903543\n",
      "Epoch 1200, Loss: 0.00024738243519095704, Final Batch Loss: 0.00012787914602085948\n",
      "Epoch 1201, Loss: 0.002771978673990816, Final Batch Loss: 0.0022322421427816153\n",
      "Epoch 1202, Loss: 0.015882982726907358, Final Batch Loss: 0.015566241927444935\n",
      "Epoch 1203, Loss: 0.0010519483184907585, Final Batch Loss: 0.0003306881117168814\n",
      "Epoch 1204, Loss: 0.00037929636891931295, Final Batch Loss: 0.00023206727928481996\n",
      "Epoch 1205, Loss: 0.0005723147187381983, Final Batch Loss: 0.00017236662097275257\n",
      "Epoch 1206, Loss: 0.0004133821785217151, Final Batch Loss: 0.00011773848382290453\n",
      "Epoch 1207, Loss: 0.0008495274960296229, Final Batch Loss: 0.00012731827155221254\n",
      "Epoch 1208, Loss: 0.001162754138931632, Final Batch Loss: 0.0006177755421958864\n",
      "Epoch 1209, Loss: 0.0005422075410024263, Final Batch Loss: 0.00010013388964580372\n",
      "Epoch 1210, Loss: 0.0008548760379198939, Final Batch Loss: 0.0007071425206959248\n",
      "Epoch 1211, Loss: 0.0005556184041779488, Final Batch Loss: 5.456837243400514e-05\n",
      "Epoch 1212, Loss: 0.0003185338428011164, Final Batch Loss: 0.00010917113104369491\n",
      "Epoch 1213, Loss: 0.0021349124290281907, Final Batch Loss: 0.00021669584384653717\n",
      "Epoch 1214, Loss: 0.0012303618714213371, Final Batch Loss: 0.000694153131917119\n",
      "Epoch 1215, Loss: 0.0011899553355760872, Final Batch Loss: 0.0010364061454311013\n",
      "Epoch 1216, Loss: 0.0007357590147876181, Final Batch Loss: 8.504416473442689e-05\n",
      "Epoch 1217, Loss: 0.002640184888150543, Final Batch Loss: 0.002152978675439954\n",
      "Epoch 1218, Loss: 0.0002899455212173052, Final Batch Loss: 9.929066436598077e-05\n",
      "Epoch 1219, Loss: 0.0011167833872605115, Final Batch Loss: 0.00025633766199462116\n",
      "Epoch 1220, Loss: 0.0005448730516945943, Final Batch Loss: 0.00010069845302496105\n",
      "Epoch 1221, Loss: 0.00031636519997846335, Final Batch Loss: 0.00016483766376040876\n",
      "Epoch 1222, Loss: 0.0029104743152856827, Final Batch Loss: 0.0008690368849784136\n",
      "Epoch 1223, Loss: 0.0008410658920183778, Final Batch Loss: 0.0005174094694666564\n",
      "Epoch 1224, Loss: 0.003030178355402313, Final Batch Loss: 0.0028275391086935997\n",
      "Epoch 1225, Loss: 0.0013424072822090238, Final Batch Loss: 0.0011822707019746304\n",
      "Epoch 1226, Loss: 0.0005457888328237459, Final Batch Loss: 0.00019284286827314645\n",
      "Epoch 1227, Loss: 0.00035904039395973086, Final Batch Loss: 8.049607276916504e-05\n",
      "Epoch 1228, Loss: 0.01960617318400182, Final Batch Loss: 0.01920083723962307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1229, Loss: 0.0008607413183199242, Final Batch Loss: 0.00021111844398546964\n",
      "Epoch 1230, Loss: 0.006951449176995084, Final Batch Loss: 0.006688060238957405\n",
      "Epoch 1231, Loss: 0.0006302278416114859, Final Batch Loss: 0.00011215468839509413\n",
      "Epoch 1232, Loss: 0.020808046974707395, Final Batch Loss: 0.02009616233408451\n",
      "Epoch 1233, Loss: 0.000535064929863438, Final Batch Loss: 0.00024026341270655394\n",
      "Epoch 1234, Loss: 0.0009518324222881347, Final Batch Loss: 0.0003780947590712458\n",
      "Epoch 1235, Loss: 0.023968906607478857, Final Batch Loss: 0.017450235784053802\n",
      "Epoch 1236, Loss: 0.0007002800339250825, Final Batch Loss: 4.656201781472191e-05\n",
      "Epoch 1237, Loss: 0.00036067939072381705, Final Batch Loss: 0.00027982983738183975\n",
      "Epoch 1238, Loss: 0.0006291423924267292, Final Batch Loss: 0.00035123468842357397\n",
      "Epoch 1239, Loss: 0.0036886483430862427, Final Batch Loss: 0.0010027321986854076\n",
      "Epoch 1240, Loss: 0.0018276518094353378, Final Batch Loss: 0.0012656727340072393\n",
      "Epoch 1241, Loss: 0.013031281385337934, Final Batch Loss: 0.0001363538613077253\n",
      "Epoch 1242, Loss: 0.011257861100602895, Final Batch Loss: 0.010498173534870148\n",
      "Epoch 1243, Loss: 0.00250049120222684, Final Batch Loss: 0.002346083987504244\n",
      "Epoch 1244, Loss: 0.0014584091841243207, Final Batch Loss: 0.0009436255786567926\n",
      "Epoch 1245, Loss: 0.0005806645203847438, Final Batch Loss: 0.00024600213509984314\n",
      "Epoch 1246, Loss: 0.001007415063213557, Final Batch Loss: 0.0004088835557922721\n",
      "Epoch 1247, Loss: 0.002885880385292694, Final Batch Loss: 0.00031246544676832855\n",
      "Epoch 1248, Loss: 0.0029590815538540483, Final Batch Loss: 0.002766704885289073\n",
      "Epoch 1249, Loss: 0.0006746851286152378, Final Batch Loss: 0.00023156146926339716\n",
      "Epoch 1250, Loss: 0.0005041545155108906, Final Batch Loss: 9.3482703960035e-05\n",
      "Epoch 1251, Loss: 0.002911831485107541, Final Batch Loss: 0.0018838662654161453\n",
      "Epoch 1252, Loss: 0.0011141508584842086, Final Batch Loss: 0.0004279323620721698\n",
      "Epoch 1253, Loss: 0.0016092578298412263, Final Batch Loss: 0.0007435375591740012\n",
      "Epoch 1254, Loss: 0.004559789667837322, Final Batch Loss: 0.0036569631192833185\n",
      "Epoch 1255, Loss: 0.010140606900677085, Final Batch Loss: 0.009481340646743774\n",
      "Epoch 1256, Loss: 0.0006723406258970499, Final Batch Loss: 0.0003078796435147524\n",
      "Epoch 1257, Loss: 0.008514749817550182, Final Batch Loss: 0.008333164267241955\n",
      "Epoch 1258, Loss: 0.002322417334653437, Final Batch Loss: 0.00046042364556342363\n",
      "Epoch 1259, Loss: 0.0008250911778304726, Final Batch Loss: 0.00034300549305044115\n",
      "Epoch 1260, Loss: 0.0038782191113568842, Final Batch Loss: 0.0002975161769427359\n",
      "Epoch 1261, Loss: 0.0009346794686280191, Final Batch Loss: 0.0006351282354444265\n",
      "Epoch 1262, Loss: 0.019343734660651535, Final Batch Loss: 0.00025606987765058875\n",
      "Epoch 1263, Loss: 0.007553266124887159, Final Batch Loss: 5.864095510332845e-05\n",
      "Epoch 1264, Loss: 0.0011394964676583186, Final Batch Loss: 0.0009274647454731166\n",
      "Epoch 1265, Loss: 0.0009130039397859946, Final Batch Loss: 0.0007443919312208891\n",
      "Epoch 1266, Loss: 0.004815125932509545, Final Batch Loss: 6.441688310587779e-05\n",
      "Epoch 1267, Loss: 0.005929848994128406, Final Batch Loss: 0.0010421386687085032\n",
      "Epoch 1268, Loss: 0.007094455613696482, Final Batch Loss: 6.726683204760775e-05\n",
      "Epoch 1269, Loss: 0.0008973454241640866, Final Batch Loss: 0.00031837745336815715\n",
      "Epoch 1270, Loss: 0.004218531656078994, Final Batch Loss: 0.00028820789884775877\n",
      "Epoch 1271, Loss: 0.001132722565671429, Final Batch Loss: 0.0007244960870593786\n",
      "Epoch 1272, Loss: 0.00043489248491823673, Final Batch Loss: 0.00015962956240400672\n",
      "Epoch 1273, Loss: 0.0002414427581243217, Final Batch Loss: 0.00010534054308664054\n",
      "Epoch 1274, Loss: 0.0005772972363047302, Final Batch Loss: 0.00012620212510228157\n",
      "Epoch 1275, Loss: 0.000547935844224412, Final Batch Loss: 0.00011273322888882831\n",
      "Epoch 1276, Loss: 0.0012932778772665188, Final Batch Loss: 0.00018505605112295598\n",
      "Epoch 1277, Loss: 0.003757683327421546, Final Batch Loss: 0.003132748417556286\n",
      "Epoch 1278, Loss: 0.0011586291948333383, Final Batch Loss: 0.0005935050430707633\n",
      "Epoch 1279, Loss: 0.0013475557061610743, Final Batch Loss: 0.001176510937511921\n",
      "Epoch 1280, Loss: 0.000717807502951473, Final Batch Loss: 0.00036154649569652975\n",
      "Epoch 1281, Loss: 0.005634832588839345, Final Batch Loss: 0.00020457331265788525\n",
      "Epoch 1282, Loss: 0.002087868837406859, Final Batch Loss: 0.0017260535387322307\n",
      "Epoch 1283, Loss: 0.00029429867572616786, Final Batch Loss: 0.0001145581336459145\n",
      "Epoch 1284, Loss: 0.0007803437983966433, Final Batch Loss: 0.00010430948896100745\n",
      "Epoch 1285, Loss: 0.0019731520224013366, Final Batch Loss: 0.0019050379050895572\n",
      "Epoch 1286, Loss: 0.0031897688095341437, Final Batch Loss: 0.00309628713876009\n",
      "Epoch 1287, Loss: 0.0006611004209844396, Final Batch Loss: 0.0004324873734731227\n",
      "Epoch 1288, Loss: 0.0003158693216391839, Final Batch Loss: 0.00011769367119995877\n",
      "Epoch 1289, Loss: 0.0001950469013536349, Final Batch Loss: 8.062119013629854e-05\n",
      "Epoch 1290, Loss: 0.0018144337518606335, Final Batch Loss: 0.0016419966705143452\n",
      "Epoch 1291, Loss: 0.00814747717231512, Final Batch Loss: 0.0008332598954439163\n",
      "Epoch 1292, Loss: 0.00043428802746348083, Final Batch Loss: 0.00014871652820147574\n",
      "Epoch 1293, Loss: 0.0003589251573430374, Final Batch Loss: 0.0002169082872569561\n",
      "Epoch 1294, Loss: 0.01056516597600421, Final Batch Loss: 0.00010833105625351891\n",
      "Epoch 1295, Loss: 0.0001437407045159489, Final Batch Loss: 5.5258700740523636e-05\n",
      "Epoch 1296, Loss: 0.01680436881724745, Final Batch Loss: 0.0008235272252932191\n",
      "Epoch 1297, Loss: 0.03532065637409687, Final Batch Loss: 0.01008429192006588\n",
      "Epoch 1298, Loss: 0.000885387125890702, Final Batch Loss: 0.0005889137974008918\n",
      "Epoch 1299, Loss: 0.0009358754323329777, Final Batch Loss: 0.0005650800885632634\n",
      "Epoch 1300, Loss: 0.0018774346099235117, Final Batch Loss: 0.0015708965947851539\n",
      "Epoch 1301, Loss: 0.0009919135482050478, Final Batch Loss: 0.0006321960245259106\n",
      "Epoch 1302, Loss: 0.0006056629063095897, Final Batch Loss: 0.0003466460620984435\n",
      "Epoch 1303, Loss: 0.0007772611279506236, Final Batch Loss: 0.00022738162078894675\n",
      "Epoch 1304, Loss: 0.00045350623258855194, Final Batch Loss: 0.0002651810646057129\n",
      "Epoch 1305, Loss: 0.0002344085878576152, Final Batch Loss: 0.00013531019794754684\n",
      "Epoch 1306, Loss: 0.0008362930384464562, Final Batch Loss: 0.0005225226050242782\n",
      "Epoch 1307, Loss: 0.021507406898308545, Final Batch Loss: 0.0005349296261556447\n",
      "Epoch 1308, Loss: 0.005209047580137849, Final Batch Loss: 0.0022317045368254185\n",
      "Epoch 1309, Loss: 0.009674256143625826, Final Batch Loss: 0.008895115926861763\n",
      "Epoch 1310, Loss: 0.0017023119144141674, Final Batch Loss: 0.0004224792355671525\n",
      "Epoch 1311, Loss: 0.0006743343401467428, Final Batch Loss: 0.00016480129852425307\n",
      "Epoch 1312, Loss: 0.0007151356840040535, Final Batch Loss: 0.00022893131244927645\n",
      "Epoch 1313, Loss: 0.009278667974285781, Final Batch Loss: 0.000382145750336349\n",
      "Epoch 1314, Loss: 0.00029768169042654335, Final Batch Loss: 0.00016848018276505172\n",
      "Epoch 1315, Loss: 0.0004948660061927512, Final Batch Loss: 0.00018620949413161725\n",
      "Epoch 1316, Loss: 0.00026514077035244554, Final Batch Loss: 0.0001732226664898917\n",
      "Epoch 1317, Loss: 0.0010197179071838036, Final Batch Loss: 6.127999222371727e-05\n",
      "Epoch 1318, Loss: 0.000441074778791517, Final Batch Loss: 0.00011391393491066992\n",
      "Epoch 1319, Loss: 0.0028136028558947146, Final Batch Loss: 0.001976501662284136\n",
      "Epoch 1320, Loss: 0.0007102162926457822, Final Batch Loss: 0.00015352544141933322\n",
      "Epoch 1321, Loss: 0.002433458692394197, Final Batch Loss: 0.0017783098155632615\n",
      "Epoch 1322, Loss: 0.0006177249451866373, Final Batch Loss: 0.00019854311540257186\n",
      "Epoch 1323, Loss: 0.0009453151142224669, Final Batch Loss: 0.0002934611984528601\n",
      "Epoch 1324, Loss: 0.00040248197910841554, Final Batch Loss: 0.0001802450860850513\n",
      "Epoch 1325, Loss: 0.0010653907665982842, Final Batch Loss: 0.0004988968139514327\n",
      "Epoch 1326, Loss: 0.0014155490789562464, Final Batch Loss: 0.0007938233902677894\n",
      "Epoch 1327, Loss: 0.010137922508874908, Final Batch Loss: 0.009846572764217854\n",
      "Epoch 1328, Loss: 0.00030150470047374256, Final Batch Loss: 3.225765613024123e-05\n",
      "Epoch 1329, Loss: 0.00019355157564859837, Final Batch Loss: 0.0001243886654265225\n",
      "Epoch 1330, Loss: 0.0009224984241882339, Final Batch Loss: 0.000700382050126791\n",
      "Epoch 1331, Loss: 0.00042064019362442195, Final Batch Loss: 0.00012500901357270777\n",
      "Epoch 1332, Loss: 0.011147033132147044, Final Batch Loss: 0.010407496243715286\n",
      "Epoch 1333, Loss: 0.0006271896709222347, Final Batch Loss: 0.00040337402606382966\n",
      "Epoch 1334, Loss: 0.00023088099624146707, Final Batch Loss: 4.512508530751802e-05\n",
      "Epoch 1335, Loss: 0.0012785676517523825, Final Batch Loss: 0.0004605822032317519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1336, Loss: 0.00016326887271134183, Final Batch Loss: 7.295440445886925e-05\n",
      "Epoch 1337, Loss: 0.0003644250609795563, Final Batch Loss: 0.00010766245395643637\n",
      "Epoch 1338, Loss: 0.0009757686493685469, Final Batch Loss: 7.773567631375045e-05\n",
      "Epoch 1339, Loss: 0.0003468957438599318, Final Batch Loss: 0.00014692592958454043\n",
      "Epoch 1340, Loss: 0.0007550865993835032, Final Batch Loss: 3.890757216140628e-05\n",
      "Epoch 1341, Loss: 0.0007747358322376385, Final Batch Loss: 0.0006280451780185103\n",
      "Epoch 1342, Loss: 0.00017338029283564538, Final Batch Loss: 9.978646994568408e-05\n",
      "Epoch 1343, Loss: 0.0008066550944931805, Final Batch Loss: 0.00019307940965518355\n",
      "Epoch 1344, Loss: 0.001685238181380555, Final Batch Loss: 0.0014250683598220348\n",
      "Epoch 1345, Loss: 0.00027264659001957625, Final Batch Loss: 0.00016659620450809598\n",
      "Epoch 1346, Loss: 0.0005743602087022737, Final Batch Loss: 0.00012491676898207515\n",
      "Epoch 1347, Loss: 0.009590263565769419, Final Batch Loss: 0.00921687576919794\n",
      "Epoch 1348, Loss: 0.0003460601583356038, Final Batch Loss: 0.00013386680802796036\n",
      "Epoch 1349, Loss: 0.0005778697959613055, Final Batch Loss: 0.0002870106545742601\n",
      "Epoch 1350, Loss: 0.0007071736472425982, Final Batch Loss: 9.637947368901223e-05\n",
      "Epoch 1351, Loss: 0.00031652397592552006, Final Batch Loss: 0.00025122545775957406\n",
      "Epoch 1352, Loss: 0.0014283452183008194, Final Batch Loss: 0.0004270961508154869\n",
      "Epoch 1353, Loss: 0.001410574885085225, Final Batch Loss: 0.0005403809482231736\n",
      "Epoch 1354, Loss: 0.016840194977703504, Final Batch Loss: 0.00015929124492686242\n",
      "Epoch 1355, Loss: 0.008863552240654826, Final Batch Loss: 0.0005030545871704817\n",
      "Epoch 1356, Loss: 0.00040673016337677836, Final Batch Loss: 0.0002732088905759156\n",
      "Epoch 1357, Loss: 0.0003532448681653477, Final Batch Loss: 0.0002786370168905705\n",
      "Epoch 1358, Loss: 0.0006943975313333794, Final Batch Loss: 0.00012244678509887308\n",
      "Epoch 1359, Loss: 0.00041901940130628645, Final Batch Loss: 0.0001437008031643927\n",
      "Epoch 1360, Loss: 0.0003750697214854881, Final Batch Loss: 0.0001407473610015586\n",
      "Epoch 1361, Loss: 0.006264515919610858, Final Batch Loss: 0.00010830978862941265\n",
      "Epoch 1362, Loss: 0.0005399617512011901, Final Batch Loss: 0.0003516283759381622\n",
      "Epoch 1363, Loss: 0.0011148318299092352, Final Batch Loss: 0.00013929751003161073\n",
      "Epoch 1364, Loss: 0.0006623195295105688, Final Batch Loss: 5.655857239617035e-05\n",
      "Epoch 1365, Loss: 0.00038558799133170396, Final Batch Loss: 0.00020198256243020296\n",
      "Epoch 1366, Loss: 0.00028246418514754623, Final Batch Loss: 0.0001428864779882133\n",
      "Epoch 1367, Loss: 0.004230892382111051, Final Batch Loss: 2.4292248781421222e-05\n",
      "Epoch 1368, Loss: 0.00141199555946514, Final Batch Loss: 0.0005532642244361341\n",
      "Epoch 1369, Loss: 0.0003375800733920187, Final Batch Loss: 0.00013587232388090342\n",
      "Epoch 1370, Loss: 0.000549229618627578, Final Batch Loss: 0.00012126308865845203\n",
      "Epoch 1371, Loss: 0.0004993662005290389, Final Batch Loss: 0.00032296087010763586\n",
      "Epoch 1372, Loss: 0.006867394156870432, Final Batch Loss: 0.00017679839220363647\n",
      "Epoch 1373, Loss: 0.000983764388365671, Final Batch Loss: 0.0005623560282401741\n",
      "Epoch 1374, Loss: 0.0005654553242493421, Final Batch Loss: 0.00012124120257794857\n",
      "Epoch 1375, Loss: 0.0004223280993755907, Final Batch Loss: 0.00025888922391459346\n",
      "Epoch 1376, Loss: 0.00020874990877928212, Final Batch Loss: 6.422070873668417e-05\n",
      "Epoch 1377, Loss: 0.0174108034116216, Final Batch Loss: 0.00031214189948514104\n",
      "Epoch 1378, Loss: 0.0006622075889026746, Final Batch Loss: 0.00047277778503485024\n",
      "Epoch 1379, Loss: 0.0008415578486165032, Final Batch Loss: 0.00023345525551121682\n",
      "Epoch 1380, Loss: 0.00033076795807573944, Final Batch Loss: 0.00023338770552072674\n",
      "Epoch 1381, Loss: 0.0003314918139949441, Final Batch Loss: 0.0001419815089320764\n",
      "Epoch 1382, Loss: 0.006149166147224605, Final Batch Loss: 0.00036521756555885077\n",
      "Epoch 1383, Loss: 0.0009828006150200963, Final Batch Loss: 0.00018954375991597772\n",
      "Epoch 1384, Loss: 0.005110828147735447, Final Batch Loss: 0.00093221286078915\n",
      "Epoch 1385, Loss: 0.00047322762839030474, Final Batch Loss: 0.00024958772701211274\n",
      "Epoch 1386, Loss: 0.0023290677927434444, Final Batch Loss: 0.0020532701164484024\n",
      "Epoch 1387, Loss: 0.00029916736821178347, Final Batch Loss: 6.064859917387366e-05\n",
      "Epoch 1388, Loss: 0.00036698393523693085, Final Batch Loss: 0.000174554850673303\n",
      "Epoch 1389, Loss: 0.0006783273420296609, Final Batch Loss: 0.0004182692791800946\n",
      "Epoch 1390, Loss: 0.0008206109050661325, Final Batch Loss: 0.0004968070425093174\n",
      "Epoch 1391, Loss: 0.014068860778934322, Final Batch Loss: 0.00013643897545989603\n",
      "Epoch 1392, Loss: 0.000709544590790756, Final Batch Loss: 0.00013325650070328265\n",
      "Epoch 1393, Loss: 0.0023026695125736296, Final Batch Loss: 0.0006160776247270405\n",
      "Epoch 1394, Loss: 0.0004181573312962428, Final Batch Loss: 0.00022911332780495286\n",
      "Epoch 1395, Loss: 0.0010076661419589072, Final Batch Loss: 0.00029075596830807626\n",
      "Epoch 1396, Loss: 0.00040152833207685035, Final Batch Loss: 2.5599858417990617e-05\n",
      "Epoch 1397, Loss: 0.0005616081471089274, Final Batch Loss: 0.0002868810552172363\n",
      "Epoch 1398, Loss: 0.004143675963860005, Final Batch Loss: 0.0038601781707257032\n",
      "Epoch 1399, Loss: 0.0011733031715266407, Final Batch Loss: 0.0009203560766763985\n",
      "Epoch 1400, Loss: 0.0005957652974757366, Final Batch Loss: 9.153386781690642e-05\n",
      "Epoch 1401, Loss: 0.000999582713120617, Final Batch Loss: 0.00013475278683472425\n",
      "Epoch 1402, Loss: 0.0005923274293309078, Final Batch Loss: 0.0001680337154539302\n",
      "Epoch 1403, Loss: 0.013035219861194491, Final Batch Loss: 0.01267658919095993\n",
      "Epoch 1404, Loss: 0.000495727377710864, Final Batch Loss: 0.00022955102031119168\n",
      "Epoch 1405, Loss: 0.0003946109500247985, Final Batch Loss: 0.00019564214744605124\n",
      "Epoch 1406, Loss: 0.007290654699318111, Final Batch Loss: 0.0007642473792657256\n",
      "Epoch 1407, Loss: 0.014553721994161606, Final Batch Loss: 0.009552894160151482\n",
      "Epoch 1408, Loss: 0.00047226018796209246, Final Batch Loss: 0.0002879986714106053\n",
      "Epoch 1409, Loss: 0.002133930684067309, Final Batch Loss: 0.00015930936206132174\n",
      "Epoch 1410, Loss: 0.0006767026061424986, Final Batch Loss: 0.0005532992072403431\n",
      "Epoch 1411, Loss: 0.0007482383225578815, Final Batch Loss: 0.0003804906737059355\n",
      "Epoch 1412, Loss: 0.023888540803454816, Final Batch Loss: 0.0007556987693533301\n",
      "Epoch 1413, Loss: 0.0015507854986935854, Final Batch Loss: 0.0009150387486442924\n",
      "Epoch 1414, Loss: 0.0005789054848719388, Final Batch Loss: 0.00039734464371576905\n",
      "Epoch 1415, Loss: 0.0006797169626224786, Final Batch Loss: 0.00026681358576752245\n",
      "Epoch 1416, Loss: 0.0007156314750318415, Final Batch Loss: 9.814213990466669e-05\n",
      "Epoch 1417, Loss: 0.0024866040621418506, Final Batch Loss: 0.00026476269704289734\n",
      "Epoch 1418, Loss: 0.00040082148916553706, Final Batch Loss: 0.00019795293337665498\n",
      "Epoch 1419, Loss: 0.002205349795985967, Final Batch Loss: 0.0009160909685306251\n",
      "Epoch 1420, Loss: 0.00033883971627801657, Final Batch Loss: 0.00020406156545504928\n",
      "Epoch 1421, Loss: 0.0010020949121098965, Final Batch Loss: 0.00017279534949921072\n",
      "Epoch 1422, Loss: 0.0012692991294898093, Final Batch Loss: 0.0006573243299499154\n",
      "Epoch 1423, Loss: 0.0006861172878416255, Final Batch Loss: 0.00017348224355373532\n",
      "Epoch 1424, Loss: 0.0002111634603352286, Final Batch Loss: 9.92157292785123e-05\n",
      "Epoch 1425, Loss: 0.00022091662685852498, Final Batch Loss: 0.00012359324318822473\n",
      "Epoch 1426, Loss: 0.001410218137607444, Final Batch Loss: 7.882627687649801e-05\n",
      "Epoch 1427, Loss: 0.00046011335507500917, Final Batch Loss: 0.0001445075758965686\n",
      "Epoch 1428, Loss: 0.000510186109750066, Final Batch Loss: 0.00010809765808517113\n",
      "Epoch 1429, Loss: 0.000745178280340042, Final Batch Loss: 6.689779547741637e-05\n",
      "Epoch 1430, Loss: 0.0007078754642861895, Final Batch Loss: 8.177255949703977e-05\n",
      "Epoch 1431, Loss: 0.00030546738707926124, Final Batch Loss: 0.00013230412150733173\n",
      "Epoch 1432, Loss: 0.001430834294296801, Final Batch Loss: 0.0004883535439148545\n",
      "Epoch 1433, Loss: 0.0005038616363890469, Final Batch Loss: 0.00012561387848109007\n",
      "Epoch 1434, Loss: 0.007142409915104508, Final Batch Loss: 0.0010720973368734121\n",
      "Epoch 1435, Loss: 0.004342237254604697, Final Batch Loss: 0.004192851018160582\n",
      "Epoch 1436, Loss: 0.0003202962689101696, Final Batch Loss: 0.00012844798038713634\n",
      "Epoch 1437, Loss: 0.0075355264998506755, Final Batch Loss: 0.00020893660257570446\n",
      "Epoch 1438, Loss: 0.0001861713535618037, Final Batch Loss: 6.56094925943762e-05\n",
      "Epoch 1439, Loss: 0.00031816260889172554, Final Batch Loss: 0.0001286372571485117\n",
      "Epoch 1440, Loss: 0.0004886946553597227, Final Batch Loss: 0.00018046276818495244\n",
      "Epoch 1441, Loss: 0.0004174643036094494, Final Batch Loss: 8.673541742609814e-05\n",
      "Epoch 1442, Loss: 0.0005690782709280029, Final Batch Loss: 0.00013602471153717488\n",
      "Epoch 1443, Loss: 0.0013117337803123519, Final Batch Loss: 0.001238741329871118\n",
      "Epoch 1444, Loss: 0.010362535671447404, Final Batch Loss: 0.010294685140252113\n",
      "Epoch 1445, Loss: 0.0007497719925595447, Final Batch Loss: 0.00020166572357993573\n",
      "Epoch 1446, Loss: 0.0006109797323006205, Final Batch Loss: 8.932599303079769e-05\n",
      "Epoch 1447, Loss: 0.0009330521279480308, Final Batch Loss: 0.0005455046193674207\n",
      "Epoch 1448, Loss: 0.0004889576957793906, Final Batch Loss: 0.0002313457225682214\n",
      "Epoch 1449, Loss: 0.0003340103285154328, Final Batch Loss: 0.00010504380043130368\n",
      "Epoch 1450, Loss: 0.0009815843804972246, Final Batch Loss: 0.0008998608682304621\n",
      "Epoch 1451, Loss: 0.00017563974688528106, Final Batch Loss: 5.9796970163006335e-05\n",
      "Epoch 1452, Loss: 0.005054848144936841, Final Batch Loss: 0.004981649573892355\n",
      "Epoch 1453, Loss: 0.00018842391727957875, Final Batch Loss: 0.00010134064359590411\n",
      "Epoch 1454, Loss: 0.0006330367687041871, Final Batch Loss: 3.777216625167057e-05\n",
      "Epoch 1455, Loss: 0.005736561324738432, Final Batch Loss: 6.765436410205439e-05\n",
      "Epoch 1456, Loss: 0.0005534820520551875, Final Batch Loss: 0.0002037027879850939\n",
      "Epoch 1457, Loss: 0.00034553350997157395, Final Batch Loss: 0.00017639898578636348\n",
      "Epoch 1458, Loss: 0.0004637525125872344, Final Batch Loss: 0.00030466701718978584\n",
      "Epoch 1459, Loss: 0.00032520144304726273, Final Batch Loss: 0.00020203535677865148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1460, Loss: 0.00017374054004903883, Final Batch Loss: 0.00010947487317025661\n",
      "Epoch 1461, Loss: 0.007720679997873958, Final Batch Loss: 0.007638133596628904\n",
      "Epoch 1462, Loss: 0.000647653971100226, Final Batch Loss: 0.0005558850825764239\n",
      "Epoch 1463, Loss: 0.00304077792679891, Final Batch Loss: 0.0024206882808357477\n",
      "Epoch 1464, Loss: 0.0005762339569628239, Final Batch Loss: 0.0004528356366790831\n",
      "Epoch 1465, Loss: 0.0005067783931735903, Final Batch Loss: 0.000152778928168118\n",
      "Epoch 1466, Loss: 0.0002579410320322495, Final Batch Loss: 3.664620089693926e-05\n",
      "Epoch 1467, Loss: 0.0003942844778066501, Final Batch Loss: 0.00020328789833001792\n",
      "Epoch 1468, Loss: 0.004000606015324593, Final Batch Loss: 0.0019979774951934814\n",
      "Epoch 1469, Loss: 0.0004897487524431199, Final Batch Loss: 0.00022141390945762396\n",
      "Epoch 1470, Loss: 0.0008309822442242876, Final Batch Loss: 0.0006331750191748142\n",
      "Epoch 1471, Loss: 0.0008328535259352066, Final Batch Loss: 0.0007308131898753345\n",
      "Epoch 1472, Loss: 0.001387151722155977, Final Batch Loss: 8.409802831010893e-05\n",
      "Epoch 1473, Loss: 0.0016453161952085793, Final Batch Loss: 0.0008635340491309762\n",
      "Epoch 1474, Loss: 0.0003700937086250633, Final Batch Loss: 0.00020054521155543625\n",
      "Epoch 1475, Loss: 0.0006378661055350676, Final Batch Loss: 0.000513944192789495\n",
      "Epoch 1476, Loss: 0.00026095522480318323, Final Batch Loss: 9.128962847171351e-05\n",
      "Epoch 1477, Loss: 0.0005656340799760073, Final Batch Loss: 0.00026575184892863035\n",
      "Epoch 1478, Loss: 0.0036360297235660255, Final Batch Loss: 0.0007877761381678283\n",
      "Epoch 1479, Loss: 0.00561523565556854, Final Batch Loss: 0.0052953981794416904\n",
      "Epoch 1480, Loss: 0.010362647091824329, Final Batch Loss: 4.799532689503394e-05\n",
      "Epoch 1481, Loss: 0.0001701175278867595, Final Batch Loss: 6.83669131831266e-05\n",
      "Epoch 1482, Loss: 0.0020630965154850855, Final Batch Loss: 0.0020140409469604492\n",
      "Epoch 1483, Loss: 0.009340817050542682, Final Batch Loss: 0.008871166966855526\n",
      "Epoch 1484, Loss: 0.0007652777931070887, Final Batch Loss: 6.271039455896243e-05\n",
      "Epoch 1485, Loss: 0.00042462591954972595, Final Batch Loss: 0.0001358890294795856\n",
      "Epoch 1486, Loss: 0.0002910080147557892, Final Batch Loss: 8.360554784303531e-05\n",
      "Epoch 1487, Loss: 0.001241872123500798, Final Batch Loss: 8.371848525712267e-05\n",
      "Epoch 1488, Loss: 0.000574420831981115, Final Batch Loss: 0.0003321773838251829\n",
      "Epoch 1489, Loss: 0.00025499926414340734, Final Batch Loss: 0.00019875456928275526\n",
      "Epoch 1490, Loss: 0.00039426409057341516, Final Batch Loss: 0.00022591487504541874\n",
      "Epoch 1491, Loss: 0.0002455323265166953, Final Batch Loss: 0.0001586458965903148\n",
      "Epoch 1492, Loss: 0.00039482458669226617, Final Batch Loss: 0.0003142667992506176\n",
      "Epoch 1493, Loss: 0.006458422722062096, Final Batch Loss: 7.851989357732236e-05\n",
      "Epoch 1494, Loss: 0.0012501905875978991, Final Batch Loss: 0.00020734003919642419\n",
      "Epoch 1495, Loss: 0.0002393274953647051, Final Batch Loss: 5.944483928033151e-05\n",
      "Epoch 1496, Loss: 0.01092919969232753, Final Batch Loss: 0.010262373834848404\n",
      "Epoch 1497, Loss: 0.00022998406348051503, Final Batch Loss: 6.221916555659845e-05\n",
      "Epoch 1498, Loss: 0.0005009145606891252, Final Batch Loss: 0.00010119367652805522\n",
      "Epoch 1499, Loss: 0.0008777344046393409, Final Batch Loss: 0.0006728043081238866\n",
      "Epoch 1500, Loss: 0.0002571391887613572, Final Batch Loss: 5.804023385280743e-05\n",
      "Epoch 1501, Loss: 0.008686186687555164, Final Batch Loss: 8.438894292339683e-05\n",
      "Epoch 1502, Loss: 0.00013884458894608542, Final Batch Loss: 7.019656186457723e-05\n",
      "Epoch 1503, Loss: 0.0003221418082830496, Final Batch Loss: 8.174916001735255e-05\n",
      "Epoch 1504, Loss: 0.000492232727992814, Final Batch Loss: 0.00011298481695121154\n",
      "Epoch 1505, Loss: 0.028348269217531197, Final Batch Loss: 5.599511496257037e-05\n",
      "Epoch 1506, Loss: 0.0007359389564953744, Final Batch Loss: 0.00013376015704125166\n",
      "Epoch 1507, Loss: 0.0003248927168897353, Final Batch Loss: 4.910240386379883e-05\n",
      "Epoch 1508, Loss: 0.00020476763893384486, Final Batch Loss: 0.00010136247146874666\n",
      "Epoch 1509, Loss: 0.00032323875348083675, Final Batch Loss: 8.045406138990074e-05\n",
      "Epoch 1510, Loss: 0.00046727590961381793, Final Batch Loss: 0.0003266010608058423\n",
      "Epoch 1511, Loss: 0.0021505385520868003, Final Batch Loss: 0.0006247636047191918\n",
      "Epoch 1512, Loss: 0.00032655934046488255, Final Batch Loss: 0.00017154095985461026\n",
      "Epoch 1513, Loss: 0.00039458725950680673, Final Batch Loss: 0.00027223158394917846\n",
      "Epoch 1514, Loss: 0.007259654448716901, Final Batch Loss: 6.864882016088814e-05\n",
      "Epoch 1515, Loss: 0.0005642823234666139, Final Batch Loss: 0.000437039794633165\n",
      "Epoch 1516, Loss: 0.00022355475812219083, Final Batch Loss: 0.00010673102951841429\n",
      "Epoch 1517, Loss: 0.006851640027889516, Final Batch Loss: 9.201789362123236e-05\n",
      "Epoch 1518, Loss: 0.00022282058489508927, Final Batch Loss: 0.00010680610284907743\n",
      "Epoch 1519, Loss: 0.0004946340050082654, Final Batch Loss: 0.00024039321579039097\n",
      "Epoch 1520, Loss: 0.0008243755873991176, Final Batch Loss: 0.00024093569663818926\n",
      "Epoch 1521, Loss: 0.00033510365392430685, Final Batch Loss: 0.0002784764510579407\n",
      "Epoch 1522, Loss: 0.005927177291596308, Final Batch Loss: 0.005629612132906914\n",
      "Epoch 1523, Loss: 0.0018073224928230047, Final Batch Loss: 0.0007853164570406079\n",
      "Epoch 1524, Loss: 0.0007239588885568082, Final Batch Loss: 0.00037689594319090247\n",
      "Epoch 1525, Loss: 0.0011179702123627067, Final Batch Loss: 0.0005941948038525879\n",
      "Epoch 1526, Loss: 0.00018292502500116825, Final Batch Loss: 9.116641012951732e-05\n",
      "Epoch 1527, Loss: 0.0016266444436041638, Final Batch Loss: 0.0014856895431876183\n",
      "Epoch 1528, Loss: 0.0006064659391995519, Final Batch Loss: 0.00027886172756552696\n",
      "Epoch 1529, Loss: 0.0014849851722829044, Final Batch Loss: 0.0005533056100830436\n",
      "Epoch 1530, Loss: 0.00022964976960793138, Final Batch Loss: 4.299846477806568e-05\n",
      "Epoch 1531, Loss: 0.006680172657070216, Final Batch Loss: 8.050843462115154e-05\n",
      "Epoch 1532, Loss: 0.0009701922826934606, Final Batch Loss: 7.35249777790159e-05\n",
      "Epoch 1533, Loss: 0.0008994361996883526, Final Batch Loss: 0.0006653486052528024\n",
      "Epoch 1534, Loss: 0.008267639044788666, Final Batch Loss: 9.476470586378127e-05\n",
      "Epoch 1535, Loss: 0.0010485221864655614, Final Batch Loss: 0.0007635278743691742\n",
      "Epoch 1536, Loss: 0.0007475387756130658, Final Batch Loss: 0.0006845606840215623\n",
      "Epoch 1537, Loss: 0.00024043404846452177, Final Batch Loss: 9.069508814718574e-05\n",
      "Epoch 1538, Loss: 0.015046809472551104, Final Batch Loss: 0.014975194819271564\n",
      "Epoch 1539, Loss: 0.008458934527880047, Final Batch Loss: 0.00839349627494812\n",
      "Epoch 1540, Loss: 0.0005503773863893002, Final Batch Loss: 0.00027322297682985663\n",
      "Epoch 1541, Loss: 0.0005462398112285882, Final Batch Loss: 0.00038123669219203293\n",
      "Epoch 1542, Loss: 0.01795865182793932, Final Batch Loss: 0.017847316339612007\n",
      "Epoch 1543, Loss: 0.0013316731347003952, Final Batch Loss: 0.0011104550212621689\n",
      "Epoch 1544, Loss: 0.0003101961192442104, Final Batch Loss: 0.00016249630425591022\n",
      "Epoch 1545, Loss: 0.008158508120686747, Final Batch Loss: 7.586590072605759e-05\n",
      "Epoch 1546, Loss: 0.0007478307379642501, Final Batch Loss: 0.00019888144743163139\n",
      "Epoch 1547, Loss: 0.0003154175210511312, Final Batch Loss: 0.00012293708277866244\n",
      "Epoch 1548, Loss: 0.0023583519650856033, Final Batch Loss: 0.00016206166765186936\n",
      "Epoch 1549, Loss: 0.006801287949201651, Final Batch Loss: 0.0001607470476301387\n",
      "Epoch 1550, Loss: 0.001754717086441815, Final Batch Loss: 0.0004993353504687548\n",
      "Epoch 1551, Loss: 0.0008719590550754219, Final Batch Loss: 0.0004051357100252062\n",
      "Epoch 1552, Loss: 0.00021940786973573267, Final Batch Loss: 7.140895468182862e-05\n",
      "Epoch 1553, Loss: 0.00074751689680852, Final Batch Loss: 0.0006239780923351645\n",
      "Epoch 1554, Loss: 0.00016952068108366802, Final Batch Loss: 6.536723958561197e-05\n",
      "Epoch 1555, Loss: 0.00703974993666634, Final Batch Loss: 0.006708981469273567\n",
      "Epoch 1556, Loss: 0.0003385483578313142, Final Batch Loss: 0.0001460565545130521\n",
      "Epoch 1557, Loss: 0.006908502953592688, Final Batch Loss: 0.006530179176479578\n",
      "Epoch 1558, Loss: 0.0006166254024719819, Final Batch Loss: 6.441200093831867e-05\n",
      "Epoch 1559, Loss: 0.012857229507062584, Final Batch Loss: 0.0004870901466347277\n",
      "Epoch 1560, Loss: 0.0003453227109275758, Final Batch Loss: 0.000107472253148444\n",
      "Epoch 1561, Loss: 0.00045341678196564317, Final Batch Loss: 0.0002956730895675719\n",
      "Epoch 1562, Loss: 0.00018060676666209474, Final Batch Loss: 6.528069206979126e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1563, Loss: 0.0005498328100657091, Final Batch Loss: 0.000225532116019167\n",
      "Epoch 1564, Loss: 0.00024753920297371224, Final Batch Loss: 8.845209231367335e-05\n",
      "Epoch 1565, Loss: 0.0008679506427142769, Final Batch Loss: 8.388046990148723e-05\n",
      "Epoch 1566, Loss: 0.00038602053245995194, Final Batch Loss: 0.00022239248210098594\n",
      "Epoch 1567, Loss: 0.00165658094920218, Final Batch Loss: 0.0008716793381609023\n",
      "Epoch 1568, Loss: 0.0033152604373754, Final Batch Loss: 9.454441169509664e-05\n",
      "Epoch 1569, Loss: 0.0001488323978264816, Final Batch Loss: 5.4284500947687775e-05\n",
      "Epoch 1570, Loss: 0.0010911658609984443, Final Batch Loss: 0.0009556742152199149\n",
      "Epoch 1571, Loss: 0.00038009744457667693, Final Batch Loss: 0.00010210071195615456\n",
      "Epoch 1572, Loss: 0.0005537003380595706, Final Batch Loss: 0.00045382152893580496\n",
      "Epoch 1573, Loss: 0.00043780334817711264, Final Batch Loss: 0.00022174438345246017\n",
      "Epoch 1574, Loss: 0.00045633044646820053, Final Batch Loss: 6.490991654573008e-05\n",
      "Epoch 1575, Loss: 0.0024566976353526115, Final Batch Loss: 0.0018634351436048746\n",
      "Epoch 1576, Loss: 0.00019791265003732406, Final Batch Loss: 0.00014301080955192447\n",
      "Epoch 1577, Loss: 0.006822620751336217, Final Batch Loss: 0.0003837414551526308\n",
      "Epoch 1578, Loss: 0.0009051637462107465, Final Batch Loss: 0.00022271308989729732\n",
      "Epoch 1579, Loss: 0.00019184619304724038, Final Batch Loss: 6.269737787079066e-05\n",
      "Epoch 1580, Loss: 0.00013527561532100663, Final Batch Loss: 3.8158497773110867e-05\n",
      "Epoch 1581, Loss: 0.00024937371199484915, Final Batch Loss: 0.00013346078048925847\n",
      "Epoch 1582, Loss: 0.0026836475008167326, Final Batch Loss: 0.0009516665595583618\n",
      "Epoch 1583, Loss: 0.00016876623703865334, Final Batch Loss: 8.384620741708204e-05\n",
      "Epoch 1584, Loss: 0.0005061188858235255, Final Batch Loss: 6.230770668480545e-05\n",
      "Epoch 1585, Loss: 0.000292867909593042, Final Batch Loss: 0.0001111794772441499\n",
      "Epoch 1586, Loss: 0.00018255896429764107, Final Batch Loss: 2.8036469302605838e-05\n",
      "Epoch 1587, Loss: 0.0002575837788754143, Final Batch Loss: 0.00018036001711152494\n",
      "Epoch 1588, Loss: 0.00027974930708296597, Final Batch Loss: 0.00020525671425275505\n",
      "Epoch 1589, Loss: 0.005295333499816479, Final Batch Loss: 5.917581802350469e-05\n",
      "Epoch 1590, Loss: 0.00043630742584355175, Final Batch Loss: 0.00012901495210826397\n",
      "Epoch 1591, Loss: 0.0012253407039679587, Final Batch Loss: 6.858020788058639e-05\n",
      "Epoch 1592, Loss: 0.0006350324911181815, Final Batch Loss: 8.520315896021202e-05\n",
      "Epoch 1593, Loss: 0.0006362645799526945, Final Batch Loss: 4.50121151516214e-05\n",
      "Epoch 1594, Loss: 0.00026170496857957914, Final Batch Loss: 0.0001629409089218825\n",
      "Epoch 1595, Loss: 0.0001325010962318629, Final Batch Loss: 4.7198249376378953e-05\n",
      "Epoch 1596, Loss: 0.0003096739383181557, Final Batch Loss: 0.00011060469842050225\n",
      "Epoch 1597, Loss: 0.00025846563221421093, Final Batch Loss: 0.00010627282608766109\n",
      "Epoch 1598, Loss: 0.0005639418468490476, Final Batch Loss: 2.333930206077639e-05\n",
      "Epoch 1599, Loss: 0.00037630870792781934, Final Batch Loss: 0.0002748443803284317\n",
      "Epoch 1600, Loss: 0.0037026427562523168, Final Batch Loss: 0.0036711108405143023\n",
      "Epoch 1601, Loss: 0.001229927031090483, Final Batch Loss: 0.00014941077097319067\n",
      "Epoch 1602, Loss: 0.0003862021112581715, Final Batch Loss: 0.00020564647275023162\n",
      "Epoch 1603, Loss: 0.0032480478985235095, Final Batch Loss: 0.0018722830573096871\n",
      "Epoch 1604, Loss: 0.014400592917809263, Final Batch Loss: 0.014357971027493477\n",
      "Epoch 1605, Loss: 0.0006014205919200322, Final Batch Loss: 2.9426015316857956e-05\n",
      "Epoch 1606, Loss: 0.0002978260235977359, Final Batch Loss: 8.990802598418668e-05\n",
      "Epoch 1607, Loss: 0.00033477041870355606, Final Batch Loss: 0.0001308029459323734\n",
      "Epoch 1608, Loss: 0.0009551557595841587, Final Batch Loss: 0.0005578728741966188\n",
      "Epoch 1609, Loss: 0.0048309192061424255, Final Batch Loss: 0.0004229918122291565\n",
      "Epoch 1610, Loss: 0.00040562660433351994, Final Batch Loss: 0.0001077710185199976\n",
      "Epoch 1611, Loss: 0.0043676408677129075, Final Batch Loss: 8.201102900784463e-05\n",
      "Epoch 1612, Loss: 0.0003875774491461925, Final Batch Loss: 6.259531801333651e-05\n",
      "Epoch 1613, Loss: 0.00016555851107113995, Final Batch Loss: 4.045969762955792e-05\n",
      "Epoch 1614, Loss: 0.0003138082756777294, Final Batch Loss: 0.00024052195658441633\n",
      "Epoch 1615, Loss: 0.00923856512963539, Final Batch Loss: 6.633137672906741e-05\n",
      "Epoch 1616, Loss: 0.00023593508012709208, Final Batch Loss: 4.337096834206022e-05\n",
      "Epoch 1617, Loss: 0.00024704658426344395, Final Batch Loss: 0.00012288018479011953\n",
      "Epoch 1618, Loss: 0.00018878383707487956, Final Batch Loss: 0.0001118231302825734\n",
      "Epoch 1619, Loss: 0.0003510953101795167, Final Batch Loss: 5.3780386224389076e-05\n",
      "Epoch 1620, Loss: 9.213084922521375e-05, Final Batch Loss: 4.298401472624391e-05\n",
      "Epoch 1621, Loss: 0.005203726293984801, Final Batch Loss: 0.00013121176743879914\n",
      "Epoch 1622, Loss: 0.0017478546287748031, Final Batch Loss: 0.0016808329382911325\n",
      "Epoch 1623, Loss: 0.00042050585034303367, Final Batch Loss: 0.00012953186524100602\n",
      "Epoch 1624, Loss: 0.00022061102208681405, Final Batch Loss: 0.00011865323904203251\n",
      "Epoch 1625, Loss: 0.0002522933209547773, Final Batch Loss: 0.00016516263713128865\n",
      "Epoch 1626, Loss: 0.0020999543485231698, Final Batch Loss: 0.00016078940825536847\n",
      "Epoch 1627, Loss: 0.0011112177016912028, Final Batch Loss: 0.0009855454554781318\n",
      "Epoch 1628, Loss: 0.0003512571711326018, Final Batch Loss: 0.00023080500250216573\n",
      "Epoch 1629, Loss: 0.0010006103657360654, Final Batch Loss: 0.0009467178606428206\n",
      "Epoch 1630, Loss: 0.005672691728250356, Final Batch Loss: 3.892822496709414e-05\n",
      "Epoch 1631, Loss: 0.00031339631823357195, Final Batch Loss: 0.00017296017904300243\n",
      "Epoch 1632, Loss: 6.722229773004074e-05, Final Batch Loss: 4.0162594814319164e-05\n",
      "Epoch 1633, Loss: 0.00023519538808614016, Final Batch Loss: 9.644098463468254e-05\n",
      "Epoch 1634, Loss: 0.0002441447286400944, Final Batch Loss: 0.00010394328273832798\n",
      "Epoch 1635, Loss: 0.007309841679671081, Final Batch Loss: 0.007265869993716478\n",
      "Epoch 1636, Loss: 0.0006915002813911997, Final Batch Loss: 0.00011754084698623046\n",
      "Epoch 1637, Loss: 0.00017648381253820844, Final Batch Loss: 6.0728041717084125e-05\n",
      "Epoch 1638, Loss: 0.00015397241077153012, Final Batch Loss: 3.1982541258912534e-05\n",
      "Epoch 1639, Loss: 0.0002805743642966263, Final Batch Loss: 0.0001638948597246781\n",
      "Epoch 1640, Loss: 0.00033144126791739836, Final Batch Loss: 0.0002532852813601494\n",
      "Epoch 1641, Loss: 0.00031358270098280627, Final Batch Loss: 2.8085503799957223e-05\n",
      "Epoch 1642, Loss: 0.00015905185136944056, Final Batch Loss: 0.00011110198101960123\n",
      "Epoch 1643, Loss: 0.0001039033813867718, Final Batch Loss: 5.143717862665653e-05\n",
      "Epoch 1644, Loss: 0.00039103536983020604, Final Batch Loss: 3.5911856684833765e-05\n",
      "Epoch 1645, Loss: 0.0005518237303476781, Final Batch Loss: 0.0001556533097755164\n",
      "Epoch 1646, Loss: 0.00015487468772334978, Final Batch Loss: 6.931900861673057e-05\n",
      "Epoch 1647, Loss: 0.00024037078765104525, Final Batch Loss: 2.9646220355061814e-05\n",
      "Epoch 1648, Loss: 0.00022842314137960784, Final Batch Loss: 4.4784272176912054e-05\n",
      "Epoch 1649, Loss: 0.0005569279164774343, Final Batch Loss: 0.00038995800423435867\n",
      "Epoch 1650, Loss: 0.0006272832542890683, Final Batch Loss: 6.006153125781566e-05\n",
      "Epoch 1651, Loss: 0.0003142484674754087, Final Batch Loss: 5.0061997171724215e-05\n",
      "Epoch 1652, Loss: 0.0006833063380327076, Final Batch Loss: 0.0005912438500672579\n",
      "Epoch 1653, Loss: 0.00023664297623327002, Final Batch Loss: 0.00011578586418181658\n",
      "Epoch 1654, Loss: 0.000100673390988959, Final Batch Loss: 2.8971455321880057e-05\n",
      "Epoch 1655, Loss: 0.00011782460569520481, Final Batch Loss: 3.055899651371874e-05\n",
      "Epoch 1656, Loss: 0.0004797896726813633, Final Batch Loss: 4.796444045496173e-05\n",
      "Epoch 1657, Loss: 9.563540152157657e-05, Final Batch Loss: 5.468671952257864e-05\n",
      "Epoch 1658, Loss: 0.002266454554046504, Final Batch Loss: 0.002133365487679839\n",
      "Epoch 1659, Loss: 0.0001734944962663576, Final Batch Loss: 8.39100539451465e-05\n",
      "Epoch 1660, Loss: 0.0003105253963440191, Final Batch Loss: 5.589642023551278e-05\n",
      "Epoch 1661, Loss: 0.0013013408752158284, Final Batch Loss: 0.0003622281947173178\n",
      "Epoch 1662, Loss: 0.007946937519591302, Final Batch Loss: 0.00053785479394719\n",
      "Epoch 1663, Loss: 0.0006859194545540959, Final Batch Loss: 0.0002858492371160537\n",
      "Epoch 1664, Loss: 0.0002753202788881026, Final Batch Loss: 0.00011898433876922354\n",
      "Epoch 1665, Loss: 0.01077094508218579, Final Batch Loss: 0.010625532828271389\n",
      "Epoch 1666, Loss: 0.0004329266885179095, Final Batch Loss: 4.320090374676511e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1667, Loss: 0.0003154271253151819, Final Batch Loss: 0.0001532190799480304\n",
      "Epoch 1668, Loss: 0.006153188442112878, Final Batch Loss: 0.00013322781887836754\n",
      "Epoch 1669, Loss: 0.005600741133093834, Final Batch Loss: 0.0008465927094221115\n",
      "Epoch 1670, Loss: 0.00020977102758479305, Final Batch Loss: 3.699068111018278e-05\n",
      "Epoch 1671, Loss: 0.00037444687040988356, Final Batch Loss: 0.0001506521803094074\n",
      "Epoch 1672, Loss: 0.0002769827115116641, Final Batch Loss: 0.00017080575344152749\n",
      "Epoch 1673, Loss: 0.0001316718407906592, Final Batch Loss: 4.1087434510700405e-05\n",
      "Epoch 1674, Loss: 0.0025250659782614093, Final Batch Loss: 0.002471332671120763\n",
      "Epoch 1675, Loss: 0.0005395499574660789, Final Batch Loss: 4.6950455725891516e-05\n",
      "Epoch 1676, Loss: 0.00021900607680436224, Final Batch Loss: 7.048645056784153e-05\n",
      "Epoch 1677, Loss: 0.0002957982578664087, Final Batch Loss: 0.00010441263293614611\n",
      "Epoch 1678, Loss: 0.0001808550350688165, Final Batch Loss: 2.967457658087369e-05\n",
      "Epoch 1679, Loss: 0.00046007414493942633, Final Batch Loss: 0.0003837094991467893\n",
      "Epoch 1680, Loss: 0.001184371387353167, Final Batch Loss: 0.0009976942092180252\n",
      "Epoch 1681, Loss: 0.0013097398914396763, Final Batch Loss: 0.0005212817341089249\n",
      "Epoch 1682, Loss: 0.00023657624115003273, Final Batch Loss: 0.00011651876411633566\n",
      "Epoch 1683, Loss: 0.0051185870106564835, Final Batch Loss: 0.0001462022337364033\n",
      "Epoch 1684, Loss: 0.00025844939227681607, Final Batch Loss: 0.0001849635154940188\n",
      "Epoch 1685, Loss: 0.0005518720136024058, Final Batch Loss: 0.00034141200012527406\n",
      "Epoch 1686, Loss: 0.0027036004466935992, Final Batch Loss: 0.002229689620435238\n",
      "Epoch 1687, Loss: 0.00017848166316980496, Final Batch Loss: 0.00012595510634128004\n",
      "Epoch 1688, Loss: 0.00047031333815539256, Final Batch Loss: 0.0004025830130558461\n",
      "Epoch 1689, Loss: 0.0009561739425407723, Final Batch Loss: 0.0008020130917429924\n",
      "Epoch 1690, Loss: 0.00013592980030807666, Final Batch Loss: 4.0463895857101306e-05\n",
      "Epoch 1691, Loss: 0.027601147017776384, Final Batch Loss: 0.027579326182603836\n",
      "Epoch 1692, Loss: 0.002055311248113867, Final Batch Loss: 2.6543297281023115e-05\n",
      "Epoch 1693, Loss: 0.0006465941260103136, Final Batch Loss: 0.0004284145834390074\n",
      "Epoch 1694, Loss: 0.0006434050083043985, Final Batch Loss: 9.483523172093555e-05\n",
      "Epoch 1695, Loss: 0.0006365430599544197, Final Batch Loss: 0.0003444254689384252\n",
      "Epoch 1696, Loss: 0.0006088856607675552, Final Batch Loss: 0.00038311153184622526\n",
      "Epoch 1697, Loss: 0.000298682447464671, Final Batch Loss: 0.00023337914899457246\n",
      "Epoch 1698, Loss: 0.0002822407695930451, Final Batch Loss: 0.0001568856241647154\n",
      "Epoch 1699, Loss: 7.02113211445976e-05, Final Batch Loss: 2.8248072339920327e-05\n",
      "Epoch 1700, Loss: 0.007462724941433407, Final Batch Loss: 7.489546260330826e-05\n",
      "Epoch 1701, Loss: 0.00039807683788239956, Final Batch Loss: 0.00013977510388940573\n",
      "Epoch 1702, Loss: 9.702973693492822e-05, Final Batch Loss: 6.232711166376248e-05\n",
      "Epoch 1703, Loss: 0.00023379254707833752, Final Batch Loss: 0.0001180297476821579\n",
      "Epoch 1704, Loss: 0.0003101272595813498, Final Batch Loss: 0.0001548416039440781\n",
      "Epoch 1705, Loss: 0.002652892449987121, Final Batch Loss: 0.00019471075211185962\n",
      "Epoch 1706, Loss: 0.000330115930410102, Final Batch Loss: 0.00018293590983375907\n",
      "Epoch 1707, Loss: 0.00017157659749500453, Final Batch Loss: 7.705351163167506e-05\n",
      "Epoch 1708, Loss: 0.0002377838027314283, Final Batch Loss: 5.1873452321160585e-05\n",
      "Epoch 1709, Loss: 0.00226755830408365, Final Batch Loss: 2.8906333682243712e-05\n",
      "Epoch 1710, Loss: 0.0006226986661204137, Final Batch Loss: 0.0005087509634904563\n",
      "Epoch 1711, Loss: 0.0002821668967953883, Final Batch Loss: 3.2466450647916645e-05\n",
      "Epoch 1712, Loss: 0.0003707096475409344, Final Batch Loss: 2.6888083084486425e-05\n",
      "Epoch 1713, Loss: 0.00036397356598172337, Final Batch Loss: 0.0002517937682569027\n",
      "Epoch 1714, Loss: 0.00036939359779353254, Final Batch Loss: 3.7348141631809995e-05\n",
      "Epoch 1715, Loss: 0.000135006797790993, Final Batch Loss: 7.559121149824932e-05\n",
      "Epoch 1716, Loss: 0.0004157094517722726, Final Batch Loss: 5.553045775741339e-05\n",
      "Epoch 1717, Loss: 0.00040691075992072, Final Batch Loss: 0.00011713477579178289\n",
      "Epoch 1718, Loss: 0.00041944861004594713, Final Batch Loss: 0.00010314873361494392\n",
      "Epoch 1719, Loss: 0.0005021146062063053, Final Batch Loss: 2.44712718995288e-05\n",
      "Epoch 1720, Loss: 0.0004508567799348384, Final Batch Loss: 0.00039799613296054304\n",
      "Epoch 1721, Loss: 0.006105916394517408, Final Batch Loss: 2.4314789698109962e-05\n",
      "Epoch 1722, Loss: 0.00013298912381287664, Final Batch Loss: 6.62585225654766e-05\n",
      "Epoch 1723, Loss: 0.00022686880402034149, Final Batch Loss: 7.743598689557984e-05\n",
      "Epoch 1724, Loss: 0.00015149626051425003, Final Batch Loss: 3.917102367267944e-05\n",
      "Epoch 1725, Loss: 0.00014602641749661416, Final Batch Loss: 6.786185986129567e-05\n",
      "Epoch 1726, Loss: 0.0005476379446918145, Final Batch Loss: 0.00010715045209508389\n",
      "Epoch 1727, Loss: 0.00037178979255259037, Final Batch Loss: 0.00016802821482997388\n",
      "Epoch 1728, Loss: 0.0001310904190177098, Final Batch Loss: 7.932466542115435e-05\n",
      "Epoch 1729, Loss: 0.00014479688252322376, Final Batch Loss: 6.302216206677258e-05\n",
      "Epoch 1730, Loss: 0.00024356594076380134, Final Batch Loss: 0.000128173764096573\n",
      "Epoch 1731, Loss: 0.0001731458614813164, Final Batch Loss: 9.156091255135834e-05\n",
      "Epoch 1732, Loss: 0.00021948881476419047, Final Batch Loss: 0.00015762691327836365\n",
      "Epoch 1733, Loss: 0.00034565241367090493, Final Batch Loss: 0.00014688017836306244\n",
      "Epoch 1734, Loss: 0.00018884411110775545, Final Batch Loss: 0.00012748643348459154\n",
      "Epoch 1735, Loss: 0.0001819364151742775, Final Batch Loss: 0.00012909408542327583\n",
      "Epoch 1736, Loss: 0.00021561256289714947, Final Batch Loss: 0.00011206107592443004\n",
      "Epoch 1737, Loss: 0.002317542937817052, Final Batch Loss: 0.00019970795256085694\n",
      "Epoch 1738, Loss: 9.44641578826122e-05, Final Batch Loss: 4.024568625027314e-05\n",
      "Epoch 1739, Loss: 0.00043582443322520703, Final Batch Loss: 0.00013800883607473224\n",
      "Epoch 1740, Loss: 0.0007913886365713552, Final Batch Loss: 0.0006023051682859659\n",
      "Epoch 1741, Loss: 0.0004994714472559281, Final Batch Loss: 9.4437891675625e-05\n",
      "Epoch 1742, Loss: 0.0003325533034512773, Final Batch Loss: 0.0001911660801852122\n",
      "Epoch 1743, Loss: 0.0007521597071900032, Final Batch Loss: 0.0006804625736549497\n",
      "Epoch 1744, Loss: 0.00015974689449649304, Final Batch Loss: 6.721276440657675e-05\n",
      "Epoch 1745, Loss: 0.00015354630158981308, Final Batch Loss: 3.738108352990821e-05\n",
      "Epoch 1746, Loss: 0.0009910898479574826, Final Batch Loss: 0.0009327223524451256\n",
      "Epoch 1747, Loss: 0.00023385473468806595, Final Batch Loss: 0.0001237456890521571\n",
      "Epoch 1748, Loss: 0.018338961388508324, Final Batch Loss: 0.018245775252580643\n",
      "Epoch 1749, Loss: 0.0006500203198811505, Final Batch Loss: 4.805002026841976e-05\n",
      "Epoch 1750, Loss: 0.00048605664051137865, Final Batch Loss: 9.519766899757087e-05\n",
      "Epoch 1751, Loss: 0.00846371655279654, Final Batch Loss: 5.004969352739863e-05\n",
      "Epoch 1752, Loss: 0.004136277129873633, Final Batch Loss: 0.0006589118856936693\n",
      "Epoch 1753, Loss: 0.003568150852515828, Final Batch Loss: 0.00011910689499927685\n",
      "Epoch 1754, Loss: 0.004885429989371914, Final Batch Loss: 0.004790418781340122\n",
      "Epoch 1755, Loss: 6.878183739900123e-05, Final Batch Loss: 2.1237143300822936e-05\n",
      "Epoch 1756, Loss: 0.0003793104478972964, Final Batch Loss: 0.0002962459984701127\n",
      "Epoch 1757, Loss: 0.000363327628292609, Final Batch Loss: 0.0002781724033411592\n",
      "Epoch 1758, Loss: 0.008413180003117304, Final Batch Loss: 0.008356827311217785\n",
      "Epoch 1759, Loss: 0.0006447581181419082, Final Batch Loss: 9.010622306959704e-05\n",
      "Epoch 1760, Loss: 0.0010530218496569432, Final Batch Loss: 7.78401517891325e-05\n",
      "Epoch 1761, Loss: 0.000528914672031533, Final Batch Loss: 9.638981282478198e-05\n",
      "Epoch 1762, Loss: 0.0005567643456743099, Final Batch Loss: 0.0004955141921527684\n",
      "Epoch 1763, Loss: 0.03554363745934097, Final Batch Loss: 0.03542511165142059\n",
      "Epoch 1764, Loss: 0.00031283325370168313, Final Batch Loss: 0.00022024322242941707\n",
      "Epoch 1765, Loss: 0.00042559433495625854, Final Batch Loss: 0.00021446967730298638\n",
      "Epoch 1766, Loss: 0.003501603991026059, Final Batch Loss: 6.217244663275778e-05\n",
      "Epoch 1767, Loss: 0.0013213938800618052, Final Batch Loss: 0.0007845761138014495\n",
      "Epoch 1768, Loss: 0.008555612905183807, Final Batch Loss: 0.0003752349002752453\n",
      "Epoch 1769, Loss: 0.010399190228781663, Final Batch Loss: 0.0001381723996018991\n",
      "Epoch 1770, Loss: 0.008901020395569503, Final Batch Loss: 0.008737923577427864\n",
      "Epoch 1771, Loss: 8.645122215966694e-05, Final Batch Loss: 3.308970190118998e-05\n",
      "Epoch 1772, Loss: 0.00175716815283522, Final Batch Loss: 0.00027955492259934545\n",
      "Epoch 1773, Loss: 0.0003970890975324437, Final Batch Loss: 0.00025659138918854296\n",
      "Epoch 1774, Loss: 0.00016148843133123592, Final Batch Loss: 7.93669096310623e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1775, Loss: 0.00033307738340226933, Final Batch Loss: 0.00021174187713768333\n",
      "Epoch 1776, Loss: 0.0003355765438755043, Final Batch Loss: 0.0002735158777795732\n",
      "Epoch 1777, Loss: 0.0014298159840109292, Final Batch Loss: 5.483380300574936e-05\n",
      "Epoch 1778, Loss: 0.0001485921020503156, Final Batch Loss: 6.929144001333043e-05\n",
      "Epoch 1779, Loss: 0.0013503172740456648, Final Batch Loss: 0.0012384564615786076\n",
      "Epoch 1780, Loss: 0.00011482737318146974, Final Batch Loss: 5.249743117019534e-05\n",
      "Epoch 1781, Loss: 0.000590337673202157, Final Batch Loss: 0.00025872798869386315\n",
      "Epoch 1782, Loss: 0.0005036285219830461, Final Batch Loss: 0.00045043430873192847\n",
      "Epoch 1783, Loss: 0.0003386382813914679, Final Batch Loss: 0.00023521283583249897\n",
      "Epoch 1784, Loss: 0.000237975920754252, Final Batch Loss: 5.5035543482517824e-05\n",
      "Epoch 1785, Loss: 0.003949788799218368, Final Batch Loss: 0.00010156741336686537\n",
      "Epoch 1786, Loss: 0.0003836354298982769, Final Batch Loss: 7.362032192759216e-05\n",
      "Epoch 1787, Loss: 0.0010515285830479115, Final Batch Loss: 0.0002705650113057345\n",
      "Epoch 1788, Loss: 0.00026230557705275714, Final Batch Loss: 8.08244658401236e-05\n",
      "Epoch 1789, Loss: 0.0009001634025480598, Final Batch Loss: 0.00022517729667015374\n",
      "Epoch 1790, Loss: 0.00026769889518618584, Final Batch Loss: 0.00011027044092770666\n",
      "Epoch 1791, Loss: 0.00010081329673994333, Final Batch Loss: 7.015590381342918e-05\n",
      "Epoch 1792, Loss: 0.00026908546715276316, Final Batch Loss: 0.00022177411301527172\n",
      "Epoch 1793, Loss: 0.00018844188889488578, Final Batch Loss: 6.770889012841508e-05\n",
      "Epoch 1794, Loss: 0.0007597138392156921, Final Batch Loss: 6.785472942283377e-05\n",
      "Epoch 1795, Loss: 0.0012082500325050205, Final Batch Loss: 0.0007836475851945579\n",
      "Epoch 1796, Loss: 0.0001695565297268331, Final Batch Loss: 6.495617708424106e-05\n",
      "Epoch 1797, Loss: 0.00022518175683217123, Final Batch Loss: 7.916261529317126e-05\n",
      "Epoch 1798, Loss: 0.00024726567789912224, Final Batch Loss: 0.0001380370231345296\n",
      "Epoch 1799, Loss: 0.0007799603481544182, Final Batch Loss: 0.0006678074132651091\n",
      "Epoch 1800, Loss: 9.086035788641311e-05, Final Batch Loss: 6.524097261717543e-05\n",
      "Epoch 1801, Loss: 0.0001914217609737534, Final Batch Loss: 5.840820449520834e-05\n",
      "Epoch 1802, Loss: 0.005425838355222368, Final Batch Loss: 1.772686118783895e-05\n",
      "Epoch 1803, Loss: 0.002022584725636989, Final Batch Loss: 0.0008549081976525486\n",
      "Epoch 1804, Loss: 0.009025346240377985, Final Batch Loss: 0.00884331576526165\n",
      "Epoch 1805, Loss: 0.0006144638609839603, Final Batch Loss: 0.0004229379410389811\n",
      "Epoch 1806, Loss: 0.00023157714895205572, Final Batch Loss: 0.00019311066716909409\n",
      "Epoch 1807, Loss: 0.000331671217281837, Final Batch Loss: 5.133156810188666e-05\n",
      "Epoch 1808, Loss: 0.0007565712148789316, Final Batch Loss: 0.0005589179927483201\n",
      "Epoch 1809, Loss: 0.00015326853463193402, Final Batch Loss: 6.990417750785127e-05\n",
      "Epoch 1810, Loss: 0.00012899606736027636, Final Batch Loss: 9.674446482677013e-05\n",
      "Epoch 1811, Loss: 0.0004973828908987343, Final Batch Loss: 0.0002512826176825911\n",
      "Epoch 1812, Loss: 0.0005716141495213378, Final Batch Loss: 3.131853372906335e-05\n",
      "Epoch 1813, Loss: 0.0001453816657885909, Final Batch Loss: 6.487619975814596e-05\n",
      "Epoch 1814, Loss: 0.006392882074578665, Final Batch Loss: 7.314734102692455e-05\n",
      "Epoch 1815, Loss: 0.004525380732957274, Final Batch Loss: 0.0002263300702907145\n",
      "Epoch 1816, Loss: 0.00033533183159306645, Final Batch Loss: 0.00010653666686266661\n",
      "Epoch 1817, Loss: 0.0006835076201241463, Final Batch Loss: 0.000610155111644417\n",
      "Epoch 1818, Loss: 0.0010375008496339433, Final Batch Loss: 7.5871757871937e-05\n",
      "Epoch 1819, Loss: 8.801174408290535e-05, Final Batch Loss: 1.7325306544080377e-05\n",
      "Epoch 1820, Loss: 0.000126007402286632, Final Batch Loss: 4.159332820563577e-05\n",
      "Epoch 1821, Loss: 0.00039236627344507724, Final Batch Loss: 6.157239840831608e-05\n",
      "Epoch 1822, Loss: 0.005745088521507569, Final Batch Loss: 3.321266558486968e-05\n",
      "Epoch 1823, Loss: 0.0021298446808941662, Final Batch Loss: 0.0015674493042752147\n",
      "Epoch 1824, Loss: 0.00036500307760434225, Final Batch Loss: 0.00027951266383752227\n",
      "Epoch 1825, Loss: 0.0004329339135438204, Final Batch Loss: 0.0001277472183573991\n",
      "Epoch 1826, Loss: 0.0003162480497849174, Final Batch Loss: 0.00020743077038787305\n",
      "Epoch 1827, Loss: 0.0025486533268122002, Final Batch Loss: 9.287909779231995e-05\n",
      "Epoch 1828, Loss: 0.00026221467123832554, Final Batch Loss: 6.953197589609772e-05\n",
      "Epoch 1829, Loss: 0.010096473095472902, Final Batch Loss: 0.009950471110641956\n",
      "Epoch 1830, Loss: 0.0051564539317041636, Final Batch Loss: 0.001043499680235982\n",
      "Epoch 1831, Loss: 0.0003205998982593883, Final Batch Loss: 3.10931536660064e-05\n",
      "Epoch 1832, Loss: 0.0009669455466791987, Final Batch Loss: 0.0008019780507311225\n",
      "Epoch 1833, Loss: 0.000164390352438204, Final Batch Loss: 9.783803398022428e-05\n",
      "Epoch 1834, Loss: 0.0005227723013376817, Final Batch Loss: 0.00015100576274562627\n",
      "Epoch 1835, Loss: 0.01867991907056421, Final Batch Loss: 0.0005711469566449523\n",
      "Epoch 1836, Loss: 0.01647704979404807, Final Batch Loss: 0.01050683856010437\n",
      "Epoch 1837, Loss: 0.00013878412210033275, Final Batch Loss: 5.797659468953498e-05\n",
      "Epoch 1838, Loss: 0.0005008780717616901, Final Batch Loss: 0.00030862761195749044\n",
      "Epoch 1839, Loss: 0.00022539260680787265, Final Batch Loss: 0.00010429557005409151\n",
      "Epoch 1840, Loss: 0.0026528380112722516, Final Batch Loss: 0.002065749140456319\n",
      "Epoch 1841, Loss: 0.0014662970643257722, Final Batch Loss: 0.0013763351598754525\n",
      "Epoch 1842, Loss: 0.0007502000225940719, Final Batch Loss: 0.0005588678177446127\n",
      "Epoch 1843, Loss: 0.0014187034175847657, Final Batch Loss: 0.0013579970691353083\n",
      "Epoch 1844, Loss: 0.0016611068131169304, Final Batch Loss: 0.00014805652608629316\n",
      "Epoch 1845, Loss: 0.00024324423429789022, Final Batch Loss: 0.00011901830293936655\n",
      "Epoch 1846, Loss: 0.0017024164844769984, Final Batch Loss: 0.00012540086754597723\n",
      "Epoch 1847, Loss: 0.0006882973248139024, Final Batch Loss: 0.00048730935668572783\n",
      "Epoch 1848, Loss: 0.001747465881635435, Final Batch Loss: 0.001646468066610396\n",
      "Epoch 1849, Loss: 0.00030807169241597876, Final Batch Loss: 7.727974298177287e-05\n",
      "Epoch 1850, Loss: 0.0003905546909663826, Final Batch Loss: 0.00019250300829298794\n",
      "Epoch 1851, Loss: 0.00019066620734520257, Final Batch Loss: 0.0001113164980779402\n",
      "Epoch 1852, Loss: 0.008187050902051851, Final Batch Loss: 0.0078033823519945145\n",
      "Epoch 1853, Loss: 0.0008820348884910345, Final Batch Loss: 0.0003310813335701823\n",
      "Epoch 1854, Loss: 0.0006253946194192395, Final Batch Loss: 9.438853885512799e-05\n",
      "Epoch 1855, Loss: 0.009416484565008432, Final Batch Loss: 0.008819113485515118\n",
      "Epoch 1856, Loss: 0.005290787579724565, Final Batch Loss: 0.00019489965052343905\n",
      "Epoch 1857, Loss: 0.00041849142871797085, Final Batch Loss: 6.573632708750665e-05\n",
      "Epoch 1858, Loss: 0.0007537381607107818, Final Batch Loss: 0.0005658665322698653\n",
      "Epoch 1859, Loss: 0.0004553808248601854, Final Batch Loss: 0.0001323096512351185\n",
      "Epoch 1860, Loss: 0.0004689525376306847, Final Batch Loss: 0.00029334911960177124\n",
      "Epoch 1861, Loss: 0.0005943596916040406, Final Batch Loss: 0.00037540175253525376\n",
      "Epoch 1862, Loss: 0.0007013072390691377, Final Batch Loss: 0.0005913189961574972\n",
      "Epoch 1863, Loss: 0.010837301146239042, Final Batch Loss: 0.0059098415076732635\n",
      "Epoch 1864, Loss: 0.001010942374705337, Final Batch Loss: 0.00014698632003273815\n",
      "Epoch 1865, Loss: 0.0012837508984375745, Final Batch Loss: 0.0010310314828529954\n",
      "Epoch 1866, Loss: 0.0064264734101016074, Final Batch Loss: 0.006144002079963684\n",
      "Epoch 1867, Loss: 0.0011424948606872931, Final Batch Loss: 0.00012022630835417658\n",
      "Epoch 1868, Loss: 0.001485291330027394, Final Batch Loss: 0.0012864901218563318\n",
      "Epoch 1869, Loss: 0.006909811636433005, Final Batch Loss: 0.001437554368749261\n",
      "Epoch 1870, Loss: 0.0004726037004729733, Final Batch Loss: 0.00028748196200467646\n",
      "Epoch 1871, Loss: 0.00037460634484887123, Final Batch Loss: 0.00014629420184064656\n",
      "Epoch 1872, Loss: 0.0002969365414173808, Final Batch Loss: 3.783261854550801e-05\n",
      "Epoch 1873, Loss: 0.0010331064549973235, Final Batch Loss: 0.0008964581647887826\n",
      "Epoch 1874, Loss: 0.0007158880325732753, Final Batch Loss: 0.0005150812212377787\n",
      "Epoch 1875, Loss: 0.00017696859140414745, Final Batch Loss: 5.1653929403983057e-05\n",
      "Epoch 1876, Loss: 0.0037954764266032726, Final Batch Loss: 3.015928086824715e-05\n",
      "Epoch 1877, Loss: 0.00034016502468148246, Final Batch Loss: 6.187038525240496e-05\n",
      "Epoch 1878, Loss: 0.0002808523495332338, Final Batch Loss: 7.736552652204409e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1879, Loss: 0.0002850995952030644, Final Batch Loss: 4.8108864575624466e-05\n",
      "Epoch 1880, Loss: 0.0001500533035141416, Final Batch Loss: 6.739296804880723e-05\n",
      "Epoch 1881, Loss: 0.0002888325252570212, Final Batch Loss: 0.00017399144417140633\n",
      "Epoch 1882, Loss: 0.00041829921246971935, Final Batch Loss: 0.00010463227226864547\n",
      "Epoch 1883, Loss: 0.00032551392359891906, Final Batch Loss: 6.0865313571412116e-05\n",
      "Epoch 1884, Loss: 0.018451646144967526, Final Batch Loss: 0.018296802416443825\n",
      "Epoch 1885, Loss: 0.002647620625793934, Final Batch Loss: 0.002342506079003215\n",
      "Epoch 1886, Loss: 0.0003968406526837498, Final Batch Loss: 0.00027836821391247213\n",
      "Epoch 1887, Loss: 0.0011451672471594065, Final Batch Loss: 0.0008526879246346653\n",
      "Epoch 1888, Loss: 0.0003397493128431961, Final Batch Loss: 8.14634986454621e-05\n",
      "Epoch 1889, Loss: 0.00023197509290184826, Final Batch Loss: 8.421367965638638e-05\n",
      "Epoch 1890, Loss: 0.0012579635949805379, Final Batch Loss: 0.0008747214451432228\n",
      "Epoch 1891, Loss: 0.0005382666568038985, Final Batch Loss: 0.00014464989362750202\n",
      "Epoch 1892, Loss: 0.000559332431294024, Final Batch Loss: 0.00045527637121267617\n",
      "Epoch 1893, Loss: 0.00029755206196568906, Final Batch Loss: 0.00010408702655695379\n",
      "Epoch 1894, Loss: 0.0005146141047589481, Final Batch Loss: 0.0002007259172387421\n",
      "Epoch 1895, Loss: 0.0005940879054833204, Final Batch Loss: 0.0003178622864652425\n",
      "Epoch 1896, Loss: 0.0005225284112384543, Final Batch Loss: 0.00031109945848584175\n",
      "Epoch 1897, Loss: 0.0003405203315196559, Final Batch Loss: 0.00013904545630794019\n",
      "Epoch 1898, Loss: 0.0022175407866598107, Final Batch Loss: 6.170667620608583e-05\n",
      "Epoch 1899, Loss: 0.003103689450654201, Final Batch Loss: 0.0029810594860464334\n",
      "Epoch 1900, Loss: 0.00043391513827373274, Final Batch Loss: 0.0003875070542562753\n",
      "Epoch 1901, Loss: 0.00029455619369400665, Final Batch Loss: 7.021276542218402e-05\n",
      "Epoch 1902, Loss: 0.00021177316011744551, Final Batch Loss: 0.00016118353232741356\n",
      "Epoch 1903, Loss: 0.0002718571267905645, Final Batch Loss: 0.00017103907885029912\n",
      "Epoch 1904, Loss: 0.008580977999372408, Final Batch Loss: 0.008503356948494911\n",
      "Epoch 1905, Loss: 0.0001940699185070116, Final Batch Loss: 5.538792538573034e-05\n",
      "Epoch 1906, Loss: 0.0002632789401104674, Final Batch Loss: 7.120984082575887e-05\n",
      "Epoch 1907, Loss: 0.01009594788774848, Final Batch Loss: 0.006517680361866951\n",
      "Epoch 1908, Loss: 0.00018721545711741783, Final Batch Loss: 3.653150997706689e-05\n",
      "Epoch 1909, Loss: 0.0008774367743171751, Final Batch Loss: 3.228621790185571e-05\n",
      "Epoch 1910, Loss: 0.00018110796736436896, Final Batch Loss: 3.7166271795285866e-05\n",
      "Epoch 1911, Loss: 0.00016357221829821356, Final Batch Loss: 0.00011972377251368016\n",
      "Epoch 1912, Loss: 0.002007251081522554, Final Batch Loss: 0.001893559005111456\n",
      "Epoch 1913, Loss: 0.00047731898666825145, Final Batch Loss: 0.0003072319086641073\n",
      "Epoch 1914, Loss: 6.45950003672624e-05, Final Batch Loss: 4.43018798250705e-05\n",
      "Epoch 1915, Loss: 0.00022856319992570207, Final Batch Loss: 3.1754789233673364e-05\n",
      "Epoch 1916, Loss: 0.010465781670063734, Final Batch Loss: 0.006248533725738525\n",
      "Epoch 1917, Loss: 0.0018657611799426377, Final Batch Loss: 0.0001979459193535149\n",
      "Epoch 1918, Loss: 0.0021031216165283695, Final Batch Loss: 7.509383431170136e-05\n",
      "Epoch 1919, Loss: 0.00022063732467358932, Final Batch Loss: 0.00012867615441791713\n",
      "Epoch 1920, Loss: 0.0003383214061614126, Final Batch Loss: 5.571125075221062e-05\n",
      "Epoch 1921, Loss: 0.00035592680433182977, Final Batch Loss: 5.5521490139653906e-05\n",
      "Epoch 1922, Loss: 0.00020424290414666757, Final Batch Loss: 9.211413271259516e-05\n",
      "Epoch 1923, Loss: 0.0006750520260538906, Final Batch Loss: 0.000257014820817858\n",
      "Epoch 1924, Loss: 0.0008832511666696519, Final Batch Loss: 0.0003126358787994832\n",
      "Epoch 1925, Loss: 0.00018122714391211048, Final Batch Loss: 6.655591278104112e-05\n",
      "Epoch 1926, Loss: 0.007943142612930387, Final Batch Loss: 5.4837611969560385e-05\n",
      "Epoch 1927, Loss: 0.0011263793712714687, Final Batch Loss: 0.0009561197948642075\n",
      "Epoch 1928, Loss: 0.0002809423822327517, Final Batch Loss: 0.0001856604212662205\n",
      "Epoch 1929, Loss: 0.0003947771474486217, Final Batch Loss: 0.00012408041220624\n",
      "Epoch 1930, Loss: 0.0002568188283476047, Final Batch Loss: 0.00014770023699384183\n",
      "Epoch 1931, Loss: 0.0002216488792328164, Final Batch Loss: 9.729912562761456e-05\n",
      "Epoch 1932, Loss: 0.0006041577507858165, Final Batch Loss: 0.0001031498031807132\n",
      "Epoch 1933, Loss: 0.000418733230617363, Final Batch Loss: 6.658765050815418e-05\n",
      "Epoch 1934, Loss: 0.00016927568867686205, Final Batch Loss: 0.00012868554040323943\n",
      "Epoch 1935, Loss: 0.0006785109217162244, Final Batch Loss: 0.0005748088005930185\n",
      "Epoch 1936, Loss: 0.004158552103035618, Final Batch Loss: 7.10490348865278e-05\n",
      "Epoch 1937, Loss: 0.0010784981132019311, Final Batch Loss: 0.0009181477362290025\n",
      "Epoch 1938, Loss: 0.0008000460366019979, Final Batch Loss: 0.00019005117064807564\n",
      "Epoch 1939, Loss: 0.00041317085560876876, Final Batch Loss: 0.00016792853421065956\n",
      "Epoch 1940, Loss: 0.0003240709993406199, Final Batch Loss: 9.911183587973937e-05\n",
      "Epoch 1941, Loss: 0.00021549414304899983, Final Batch Loss: 0.00015995118883438408\n",
      "Epoch 1942, Loss: 0.01318592888128478, Final Batch Loss: 7.999346416909248e-05\n",
      "Epoch 1943, Loss: 0.00016130655421875417, Final Batch Loss: 8.555374370189384e-05\n",
      "Epoch 1944, Loss: 0.0033313521853415295, Final Batch Loss: 7.377767178695649e-05\n",
      "Epoch 1945, Loss: 0.00044939953659195453, Final Batch Loss: 5.299314216244966e-05\n",
      "Epoch 1946, Loss: 0.0003602262804633938, Final Batch Loss: 0.00027846236480399966\n",
      "Epoch 1947, Loss: 0.00038172183667484205, Final Batch Loss: 2.913565367634874e-05\n",
      "Epoch 1948, Loss: 0.0006190206186147407, Final Batch Loss: 0.0005968392943032086\n",
      "Epoch 1949, Loss: 0.0020578552648657933, Final Batch Loss: 0.0018815299263224006\n",
      "Epoch 1950, Loss: 0.0004114473231311422, Final Batch Loss: 3.75763738702517e-05\n",
      "Epoch 1951, Loss: 0.0039024263387545943, Final Batch Loss: 0.003473927965387702\n",
      "Epoch 1952, Loss: 0.000259088643360883, Final Batch Loss: 8.969377086032182e-05\n",
      "Epoch 1953, Loss: 0.00011040459867217578, Final Batch Loss: 6.402599683497101e-05\n",
      "Epoch 1954, Loss: 0.0002847508148988709, Final Batch Loss: 0.00020216568373143673\n",
      "Epoch 1955, Loss: 0.003955295611376641, Final Batch Loss: 5.5693391914246604e-05\n",
      "Epoch 1956, Loss: 0.0009847799738054164, Final Batch Loss: 4.5919565309304744e-05\n",
      "Epoch 1957, Loss: 9.178864456771407e-05, Final Batch Loss: 1.64173779921839e-05\n",
      "Epoch 1958, Loss: 0.0003573876674636267, Final Batch Loss: 8.812869054963812e-05\n",
      "Epoch 1959, Loss: 0.0005027780134696513, Final Batch Loss: 0.000225274998228997\n",
      "Epoch 1960, Loss: 0.0007749410578981042, Final Batch Loss: 0.0007033808506093919\n",
      "Epoch 1961, Loss: 0.00022223514679353684, Final Batch Loss: 0.00014084725989960134\n",
      "Epoch 1962, Loss: 0.004477215057704598, Final Batch Loss: 0.00025133375311270356\n",
      "Epoch 1963, Loss: 0.0008996893302537501, Final Batch Loss: 0.00025461503537371755\n",
      "Epoch 1964, Loss: 0.00024756342099863105, Final Batch Loss: 0.00020004906400572509\n",
      "Epoch 1965, Loss: 0.0002697292875382118, Final Batch Loss: 9.424848394701257e-05\n",
      "Epoch 1966, Loss: 0.0003812725772149861, Final Batch Loss: 0.0002283066714880988\n",
      "Epoch 1967, Loss: 0.0027344199879735243, Final Batch Loss: 3.8862093788338825e-05\n",
      "Epoch 1968, Loss: 0.0001967468488146551, Final Batch Loss: 0.00011217536666663364\n",
      "Epoch 1969, Loss: 0.0004269296769052744, Final Batch Loss: 0.0001291667576879263\n",
      "Epoch 1970, Loss: 0.0004329610164859332, Final Batch Loss: 4.995533527107909e-05\n",
      "Epoch 1971, Loss: 0.0002303965484315995, Final Batch Loss: 5.0026985263684765e-05\n",
      "Epoch 1972, Loss: 0.0003608330116549041, Final Batch Loss: 0.0003135354781989008\n",
      "Epoch 1973, Loss: 0.00019960243662353605, Final Batch Loss: 0.00014187202032189816\n",
      "Epoch 1974, Loss: 0.00027497571863932535, Final Batch Loss: 0.00016818969743326306\n",
      "Epoch 1975, Loss: 0.00028108486731071025, Final Batch Loss: 0.00012088153744116426\n",
      "Epoch 1976, Loss: 0.00024444783775834367, Final Batch Loss: 0.00019091636931989342\n",
      "Epoch 1977, Loss: 0.0002500855589460116, Final Batch Loss: 5.6112079619197175e-05\n",
      "Epoch 1978, Loss: 0.00041836753371171653, Final Batch Loss: 2.7045432943850756e-05\n",
      "Epoch 1979, Loss: 0.0007808219597791322, Final Batch Loss: 7.229561015265062e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1980, Loss: 0.0004512190935201943, Final Batch Loss: 0.00031800029682926834\n",
      "Epoch 1981, Loss: 0.0001323675605817698, Final Batch Loss: 7.394828571705148e-05\n",
      "Epoch 1982, Loss: 0.0014092106794123538, Final Batch Loss: 3.151066630380228e-05\n",
      "Epoch 1983, Loss: 0.00011420825467212126, Final Batch Loss: 6.644756649620831e-05\n",
      "Epoch 1984, Loss: 0.0030345498489623424, Final Batch Loss: 4.176105358055793e-05\n",
      "Epoch 1985, Loss: 0.000936497759539634, Final Batch Loss: 0.00027090084040537477\n",
      "Epoch 1986, Loss: 5.8758980230777524e-05, Final Batch Loss: 2.7684951419360004e-05\n",
      "Epoch 1987, Loss: 7.443472713930532e-05, Final Batch Loss: 4.1992585465777665e-05\n",
      "Epoch 1988, Loss: 0.00010239877155981958, Final Batch Loss: 5.2074821724090725e-05\n",
      "Epoch 1989, Loss: 0.00016698366744094528, Final Batch Loss: 3.078337249462493e-05\n",
      "Epoch 1990, Loss: 0.000325433153193444, Final Batch Loss: 1.9896426238119602e-05\n",
      "Epoch 1991, Loss: 0.004731933295261115, Final Batch Loss: 0.0002887460286729038\n",
      "Epoch 1992, Loss: 0.0005287852873152588, Final Batch Loss: 4.978102879249491e-05\n",
      "Epoch 1993, Loss: 0.0006206932303030044, Final Batch Loss: 0.0001474547607358545\n",
      "Epoch 1994, Loss: 0.0002768878111965023, Final Batch Loss: 0.00012175708980066702\n",
      "Epoch 1995, Loss: 0.0002578314524726011, Final Batch Loss: 0.00010457149619469419\n",
      "Epoch 1996, Loss: 8.371659350814298e-05, Final Batch Loss: 5.313480505719781e-05\n",
      "Epoch 1997, Loss: 0.0001302401469729375, Final Batch Loss: 5.73816905671265e-05\n",
      "Epoch 1998, Loss: 0.0007810953684384003, Final Batch Loss: 0.0005728303804062307\n",
      "Epoch 1999, Loss: 0.00032533642297494225, Final Batch Loss: 0.00026966750738210976\n",
      "Epoch 2000, Loss: 8.077646270976402e-05, Final Batch Loss: 4.914324017590843e-05\n",
      "Epoch 2001, Loss: 0.00018311744133825414, Final Batch Loss: 5.6254368246300146e-05\n",
      "Epoch 2002, Loss: 0.0011042521946365014, Final Batch Loss: 0.0009518243605270982\n",
      "Epoch 2003, Loss: 0.0008795659741736017, Final Batch Loss: 0.0008173672831617296\n",
      "Epoch 2004, Loss: 0.0005106751050334424, Final Batch Loss: 8.072916534729302e-05\n",
      "Epoch 2005, Loss: 0.0001753174074110575, Final Batch Loss: 0.0001253959198947996\n",
      "Epoch 2006, Loss: 0.0001733938988763839, Final Batch Loss: 7.198963430710137e-05\n",
      "Epoch 2007, Loss: 0.00020092789782211185, Final Batch Loss: 7.525701948907226e-05\n",
      "Epoch 2008, Loss: 0.0002694592039915733, Final Batch Loss: 0.0001684746821410954\n",
      "Epoch 2009, Loss: 0.0053225365045364015, Final Batch Loss: 0.005232350435107946\n",
      "Epoch 2010, Loss: 0.006343690576613881, Final Batch Loss: 2.8259019018150866e-05\n",
      "Epoch 2011, Loss: 0.00023827219411032274, Final Batch Loss: 0.00017045727872755378\n",
      "Epoch 2012, Loss: 0.004158727009780705, Final Batch Loss: 0.0008749560220167041\n",
      "Epoch 2013, Loss: 0.0006900761945871636, Final Batch Loss: 0.0006039578001946211\n",
      "Epoch 2014, Loss: 0.005597795228823088, Final Batch Loss: 2.663150371517986e-05\n",
      "Epoch 2015, Loss: 0.00017406215192750096, Final Batch Loss: 8.113755757221952e-05\n",
      "Epoch 2016, Loss: 0.00011188376083737239, Final Batch Loss: 7.492767326766625e-05\n",
      "Epoch 2017, Loss: 0.004472948770853691, Final Batch Loss: 0.00024184274661820382\n",
      "Epoch 2018, Loss: 0.004834706662222743, Final Batch Loss: 0.00010951212607324123\n",
      "Epoch 2019, Loss: 0.002128536405507475, Final Batch Loss: 0.0015229970449581742\n",
      "Epoch 2020, Loss: 0.0002564463866292499, Final Batch Loss: 0.00011946664744755253\n",
      "Epoch 2021, Loss: 0.0001576502345415065, Final Batch Loss: 0.00013594486517831683\n",
      "Epoch 2022, Loss: 0.0014076822080824059, Final Batch Loss: 0.0013843737542629242\n",
      "Epoch 2023, Loss: 0.00013890707123209722, Final Batch Loss: 0.0001060297290678136\n",
      "Epoch 2024, Loss: 0.0005406740092439577, Final Batch Loss: 0.00018784885469358414\n",
      "Epoch 2025, Loss: 0.0004165922582615167, Final Batch Loss: 0.00024934677639976144\n",
      "Epoch 2026, Loss: 7.446938116117963e-05, Final Batch Loss: 5.457396127894754e-06\n",
      "Epoch 2027, Loss: 0.0005559633136726916, Final Batch Loss: 0.00013692665379494429\n",
      "Epoch 2028, Loss: 0.010846474939171458, Final Batch Loss: 2.630128074088134e-05\n",
      "Epoch 2029, Loss: 0.00013842181215295568, Final Batch Loss: 5.6710159697104245e-05\n",
      "Epoch 2030, Loss: 0.0002188136350014247, Final Batch Loss: 8.419689402217045e-05\n",
      "Epoch 2031, Loss: 0.0003320731848361902, Final Batch Loss: 0.0002141716831829399\n",
      "Epoch 2032, Loss: 0.0002518265973776579, Final Batch Loss: 7.134120096452534e-05\n",
      "Epoch 2033, Loss: 0.026129778460017405, Final Batch Loss: 0.026006367057561874\n",
      "Epoch 2034, Loss: 0.001277590730751399, Final Batch Loss: 5.0093956815544516e-05\n",
      "Epoch 2035, Loss: 0.000141407479532063, Final Batch Loss: 8.184568287106231e-05\n",
      "Epoch 2036, Loss: 0.0002824914990924299, Final Batch Loss: 0.0002194924745708704\n",
      "Epoch 2037, Loss: 0.00017476521679782309, Final Batch Loss: 0.00012405499001033604\n",
      "Epoch 2038, Loss: 0.002125463855918497, Final Batch Loss: 0.00143455620855093\n",
      "Epoch 2039, Loss: 9.701363342173863e-05, Final Batch Loss: 2.3107540982891805e-05\n",
      "Epoch 2040, Loss: 0.0014078732492635027, Final Batch Loss: 9.494113328400999e-05\n",
      "Epoch 2041, Loss: 0.0009717831053421833, Final Batch Loss: 8.111613715300336e-05\n",
      "Epoch 2042, Loss: 0.0003909880615537986, Final Batch Loss: 0.0002659916353877634\n",
      "Epoch 2043, Loss: 0.001289689156692475, Final Batch Loss: 0.0010185795836150646\n",
      "Epoch 2044, Loss: 0.0001294147950829938, Final Batch Loss: 5.617211718345061e-05\n",
      "Epoch 2045, Loss: 0.0039162242246675305, Final Batch Loss: 0.00010560033115325496\n",
      "Epoch 2046, Loss: 0.00463965762173757, Final Batch Loss: 2.6297231670469046e-05\n",
      "Epoch 2047, Loss: 0.0006853355444036424, Final Batch Loss: 0.0006186198443174362\n",
      "Epoch 2048, Loss: 0.003980548519393778, Final Batch Loss: 1.876608257589396e-05\n",
      "Epoch 2049, Loss: 8.965198321675416e-05, Final Batch Loss: 6.793654029024765e-05\n",
      "Epoch 2050, Loss: 9.838984806265216e-05, Final Batch Loss: 1.0734902389231138e-05\n",
      "Epoch 2051, Loss: 0.0002849851953214966, Final Batch Loss: 0.00021602664492093027\n",
      "Epoch 2052, Loss: 0.00025075586745515466, Final Batch Loss: 3.9973630919121206e-05\n",
      "Epoch 2053, Loss: 0.0002327594193047844, Final Batch Loss: 9.047249477589503e-05\n",
      "Epoch 2054, Loss: 0.00012805833102902398, Final Batch Loss: 6.111788388807327e-05\n",
      "Epoch 2055, Loss: 0.00011909503155038692, Final Batch Loss: 3.5621549614006653e-05\n",
      "Epoch 2056, Loss: 0.00039782515159458853, Final Batch Loss: 0.0003543788334354758\n",
      "Epoch 2057, Loss: 0.00021777489746455103, Final Batch Loss: 6.150201079435647e-05\n",
      "Epoch 2058, Loss: 0.0004626887239282951, Final Batch Loss: 7.246980385389179e-05\n",
      "Epoch 2059, Loss: 0.0005501953564817086, Final Batch Loss: 0.0004521670925896615\n",
      "Epoch 2060, Loss: 0.000962465419434011, Final Batch Loss: 0.0009119305177591741\n",
      "Epoch 2061, Loss: 0.00011382637239876203, Final Batch Loss: 2.5872224796330556e-05\n",
      "Epoch 2062, Loss: 0.0002660384780028835, Final Batch Loss: 8.697449811734259e-05\n",
      "Epoch 2063, Loss: 0.0007328973115363624, Final Batch Loss: 0.0006996836746111512\n",
      "Epoch 2064, Loss: 0.0002830296289175749, Final Batch Loss: 0.00013712490908801556\n",
      "Epoch 2065, Loss: 7.403313247777987e-05, Final Batch Loss: 1.8039258065982722e-05\n",
      "Epoch 2066, Loss: 0.000853098725201562, Final Batch Loss: 2.4957204004749656e-05\n",
      "Epoch 2067, Loss: 0.0003464269611868076, Final Batch Loss: 0.0002985161554533988\n",
      "Epoch 2068, Loss: 0.00025025688955793157, Final Batch Loss: 5.757630424341187e-05\n",
      "Epoch 2069, Loss: 0.00013515782848116942, Final Batch Loss: 2.151339504052885e-05\n",
      "Epoch 2070, Loss: 0.00015144801727728918, Final Batch Loss: 8.352706936420873e-05\n",
      "Epoch 2071, Loss: 0.0002968168191728182, Final Batch Loss: 3.108228702330962e-05\n",
      "Epoch 2072, Loss: 7.867861859267578e-05, Final Batch Loss: 4.430822082213126e-05\n",
      "Epoch 2073, Loss: 0.0005270145484246314, Final Batch Loss: 0.00041299016447737813\n",
      "Epoch 2074, Loss: 0.00028164218383608386, Final Batch Loss: 2.354921161895618e-05\n",
      "Epoch 2075, Loss: 0.0012919496657559648, Final Batch Loss: 4.576497303787619e-05\n",
      "Epoch 2076, Loss: 7.674355947528966e-05, Final Batch Loss: 4.065583198098466e-05\n",
      "Epoch 2077, Loss: 0.00013915407180320472, Final Batch Loss: 7.147050928324461e-05\n",
      "Epoch 2078, Loss: 7.332336645049509e-05, Final Batch Loss: 5.410237281466834e-05\n",
      "Epoch 2079, Loss: 0.015583803236950189, Final Batch Loss: 0.014717758633196354\n",
      "Epoch 2080, Loss: 0.00045557179328170605, Final Batch Loss: 4.5155862608226016e-05\n",
      "Epoch 2081, Loss: 0.00020682026661233976, Final Batch Loss: 6.818661495344713e-05\n",
      "Epoch 2082, Loss: 0.0001877901522675529, Final Batch Loss: 0.0001379929599352181\n",
      "Epoch 2083, Loss: 0.00022257982345763594, Final Batch Loss: 0.00014629759243689477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2084, Loss: 8.451530447928235e-05, Final Batch Loss: 4.552075552055612e-05\n",
      "Epoch 2085, Loss: 0.0005329640462150564, Final Batch Loss: 0.0005107795004732907\n",
      "Epoch 2086, Loss: 8.774616071605124e-05, Final Batch Loss: 1.8435774109093472e-05\n",
      "Epoch 2087, Loss: 0.0004637480014935136, Final Batch Loss: 0.0002535539388190955\n",
      "Epoch 2088, Loss: 0.00027829640384879895, Final Batch Loss: 4.494480162975378e-05\n",
      "Epoch 2089, Loss: 0.006602856403333135, Final Batch Loss: 2.0234918338246644e-05\n",
      "Epoch 2090, Loss: 7.249305235745851e-05, Final Batch Loss: 2.7851454433402978e-05\n",
      "Epoch 2091, Loss: 0.00010045355884358287, Final Batch Loss: 6.950433453312144e-05\n",
      "Epoch 2092, Loss: 0.014381317283550743, Final Batch Loss: 0.014315302483737469\n",
      "Epoch 2093, Loss: 0.0001499797945143655, Final Batch Loss: 6.623343506362289e-05\n",
      "Epoch 2094, Loss: 0.00010938361992884893, Final Batch Loss: 2.819772817019839e-05\n",
      "Epoch 2095, Loss: 0.0001539984586997889, Final Batch Loss: 8.942142449086532e-05\n",
      "Epoch 2096, Loss: 0.0003687100288516376, Final Batch Loss: 3.603822915465571e-05\n",
      "Epoch 2097, Loss: 0.0003865109247271903, Final Batch Loss: 4.316544072935358e-05\n",
      "Epoch 2098, Loss: 7.801227184245363e-05, Final Batch Loss: 2.0820552890654653e-05\n",
      "Epoch 2099, Loss: 0.0003295126880402677, Final Batch Loss: 0.00010673335782485083\n",
      "Epoch 2100, Loss: 0.0002069184702122584, Final Batch Loss: 6.491194653790444e-05\n",
      "Epoch 2101, Loss: 9.695790049590869e-05, Final Batch Loss: 1.0224032848782372e-05\n",
      "Epoch 2102, Loss: 0.00012098262959625572, Final Batch Loss: 8.913921192288399e-06\n",
      "Epoch 2103, Loss: 0.0068102289660600945, Final Batch Loss: 0.00013222980487626046\n",
      "Epoch 2104, Loss: 0.00027702152146957815, Final Batch Loss: 0.00015015326789580286\n",
      "Epoch 2105, Loss: 0.00025271154299844056, Final Batch Loss: 1.1369396816007793e-05\n",
      "Epoch 2106, Loss: 0.00022140148212201893, Final Batch Loss: 0.00012226698163431138\n",
      "Epoch 2107, Loss: 0.0001967654279724229, Final Batch Loss: 2.9204285965533927e-05\n",
      "Epoch 2108, Loss: 9.470505210629199e-05, Final Batch Loss: 1.6347812561434694e-05\n",
      "Epoch 2109, Loss: 6.234570901142433e-05, Final Batch Loss: 8.896968211047351e-06\n",
      "Epoch 2110, Loss: 0.0009036271658260375, Final Batch Loss: 0.0008624566835351288\n",
      "Epoch 2111, Loss: 0.00016665286784700584, Final Batch Loss: 1.8273638488608412e-05\n",
      "Epoch 2112, Loss: 0.0001534870534669608, Final Batch Loss: 7.543224637629464e-05\n",
      "Epoch 2113, Loss: 0.0002842637914000079, Final Batch Loss: 0.00010961186490021646\n",
      "Epoch 2114, Loss: 0.00011454737705207663, Final Batch Loss: 9.944751946022734e-05\n",
      "Epoch 2115, Loss: 0.00019016396981896833, Final Batch Loss: 9.627404506318271e-05\n",
      "Epoch 2116, Loss: 0.0005914804823987652, Final Batch Loss: 4.057198020746e-05\n",
      "Epoch 2117, Loss: 0.0002014218898693798, Final Batch Loss: 5.672320185112767e-06\n",
      "Epoch 2118, Loss: 6.703089275106322e-05, Final Batch Loss: 4.596421786118299e-05\n",
      "Epoch 2119, Loss: 7.447310144925723e-05, Final Batch Loss: 7.87083354225615e-06\n",
      "Epoch 2120, Loss: 7.156642823247239e-05, Final Batch Loss: 4.504297248786315e-05\n",
      "Epoch 2121, Loss: 0.004625563080480788, Final Batch Loss: 0.00010635055514285341\n",
      "Epoch 2122, Loss: 9.75786242634058e-05, Final Batch Loss: 3.51950729964301e-05\n",
      "Epoch 2123, Loss: 0.00011335293902448029, Final Batch Loss: 7.20762409400777e-06\n",
      "Epoch 2124, Loss: 0.00014681133689009584, Final Batch Loss: 4.766691927216016e-05\n",
      "Epoch 2125, Loss: 0.0002714799775276333, Final Batch Loss: 8.071488991845399e-05\n",
      "Epoch 2126, Loss: 8.144051389535889e-05, Final Batch Loss: 3.541629484971054e-05\n",
      "Epoch 2127, Loss: 0.00012036115731461905, Final Batch Loss: 3.4156040783273056e-05\n",
      "Epoch 2128, Loss: 0.01583610090892762, Final Batch Loss: 0.01469713170081377\n",
      "Epoch 2129, Loss: 0.006223797478014603, Final Batch Loss: 0.00014170646318234503\n",
      "Epoch 2130, Loss: 0.0004084928659722209, Final Batch Loss: 0.0002626814821269363\n",
      "Epoch 2131, Loss: 0.00012005242751911283, Final Batch Loss: 7.962883682921529e-05\n",
      "Epoch 2132, Loss: 0.00946969585493207, Final Batch Loss: 0.005552737042307854\n",
      "Epoch 2133, Loss: 0.0009692913190519903, Final Batch Loss: 0.0009092522668652236\n",
      "Epoch 2134, Loss: 0.0002599304643808864, Final Batch Loss: 9.627945109969005e-05\n",
      "Epoch 2135, Loss: 9.797737948247232e-05, Final Batch Loss: 2.3458724172087386e-05\n",
      "Epoch 2136, Loss: 0.0003776910525630228, Final Batch Loss: 0.00026147140306420624\n",
      "Epoch 2137, Loss: 0.0009209021882270463, Final Batch Loss: 9.137270535575226e-05\n",
      "Epoch 2138, Loss: 6.430687608371954e-05, Final Batch Loss: 2.762377516773995e-05\n",
      "Epoch 2139, Loss: 0.00026329196043661796, Final Batch Loss: 0.0002325824898434803\n",
      "Epoch 2140, Loss: 0.00025869147066259757, Final Batch Loss: 0.00011933096538996324\n",
      "Epoch 2141, Loss: 0.00032622260187054053, Final Batch Loss: 0.00023668023641221225\n",
      "Epoch 2142, Loss: 0.00022589422223973088, Final Batch Loss: 3.2421517971670255e-05\n",
      "Epoch 2143, Loss: 0.006334992707706988, Final Batch Loss: 0.006071529351174831\n",
      "Epoch 2144, Loss: 0.00014024153642822057, Final Batch Loss: 5.1480681577231735e-05\n",
      "Epoch 2145, Loss: 0.00024288697022711858, Final Batch Loss: 0.00012584209616761655\n",
      "Epoch 2146, Loss: 0.0005416044514277019, Final Batch Loss: 0.00045206848881207407\n",
      "Epoch 2147, Loss: 0.00010156546704820357, Final Batch Loss: 7.618511881446466e-05\n",
      "Epoch 2148, Loss: 0.003335650049848482, Final Batch Loss: 0.00014332446153275669\n",
      "Epoch 2149, Loss: 0.00041403775685466826, Final Batch Loss: 0.00025819436996243894\n",
      "Epoch 2150, Loss: 0.00048317696928279474, Final Batch Loss: 0.00039583988836966455\n",
      "Epoch 2151, Loss: 4.9418137678003404e-05, Final Batch Loss: 1.1613480637606699e-05\n",
      "Epoch 2152, Loss: 7.192531120381318e-05, Final Batch Loss: 3.127363379462622e-05\n",
      "Epoch 2153, Loss: 8.152160626195837e-05, Final Batch Loss: 2.511583261366468e-05\n",
      "Epoch 2154, Loss: 6.898870014993008e-05, Final Batch Loss: 2.3594018784933724e-05\n",
      "Epoch 2155, Loss: 8.568960038246587e-05, Final Batch Loss: 4.5559718273580074e-05\n",
      "Epoch 2156, Loss: 4.001634988526348e-05, Final Batch Loss: 1.5508741853409447e-05\n",
      "Epoch 2157, Loss: 0.0001367216209473554, Final Batch Loss: 3.8251728256000206e-05\n",
      "Epoch 2158, Loss: 0.0002203848744102288, Final Batch Loss: 4.432058267411776e-05\n",
      "Epoch 2159, Loss: 0.0005608534229395445, Final Batch Loss: 3.6299312341725454e-05\n",
      "Epoch 2160, Loss: 0.00022212091425899416, Final Batch Loss: 0.00015888740017544478\n",
      "Epoch 2161, Loss: 0.0006343706227198709, Final Batch Loss: 3.4028100344585255e-05\n",
      "Epoch 2162, Loss: 0.02057659025012981, Final Batch Loss: 0.020452573895454407\n",
      "Epoch 2163, Loss: 5.1260998588986695e-05, Final Batch Loss: 1.3296292308950797e-05\n",
      "Epoch 2164, Loss: 0.00022040849216864444, Final Batch Loss: 0.0001624038995942101\n",
      "Epoch 2165, Loss: 0.000478437781566754, Final Batch Loss: 0.00029583077412098646\n",
      "Epoch 2166, Loss: 0.00013785259943688288, Final Batch Loss: 6.879065767861903e-05\n",
      "Epoch 2167, Loss: 0.00040369699127040803, Final Batch Loss: 7.453587022610009e-05\n",
      "Epoch 2168, Loss: 0.0008680589744471945, Final Batch Loss: 0.00010039358312496915\n",
      "Epoch 2169, Loss: 0.00014264815399656072, Final Batch Loss: 2.297888568136841e-05\n",
      "Epoch 2170, Loss: 0.00031911877158563584, Final Batch Loss: 0.0001603719574632123\n",
      "Epoch 2171, Loss: 0.003533743780280929, Final Batch Loss: 8.110701310215518e-05\n",
      "Epoch 2172, Loss: 0.00022081970382714644, Final Batch Loss: 0.000119048694614321\n",
      "Epoch 2173, Loss: 0.004027092654723674, Final Batch Loss: 0.003098695306107402\n",
      "Epoch 2174, Loss: 0.000277821411145851, Final Batch Loss: 4.8932270146906376e-05\n",
      "Epoch 2175, Loss: 7.457298488589004e-05, Final Batch Loss: 3.276118513895199e-05\n",
      "Epoch 2176, Loss: 0.0016316341643687338, Final Batch Loss: 0.0012650368735194206\n",
      "Epoch 2177, Loss: 0.0025717298049130477, Final Batch Loss: 0.00011336091120028868\n",
      "Epoch 2178, Loss: 0.00020928969752276316, Final Batch Loss: 8.548214827897027e-05\n",
      "Epoch 2179, Loss: 6.355551704473328e-05, Final Batch Loss: 1.7933087292476557e-05\n",
      "Epoch 2180, Loss: 0.0003051178209716454, Final Batch Loss: 0.000139108975417912\n",
      "Epoch 2181, Loss: 0.003251278860261664, Final Batch Loss: 0.003122664988040924\n",
      "Epoch 2182, Loss: 0.00028949569241376594, Final Batch Loss: 0.0002060556726064533\n",
      "Epoch 2183, Loss: 0.00018933095270767808, Final Batch Loss: 8.56233382364735e-05\n",
      "Epoch 2184, Loss: 0.0005039096577093005, Final Batch Loss: 0.00043904237099923193\n",
      "Epoch 2185, Loss: 0.00024613259301986545, Final Batch Loss: 0.00012313027400523424\n",
      "Epoch 2186, Loss: 0.003790183167438954, Final Batch Loss: 0.00026564759900793433\n",
      "Epoch 2187, Loss: 0.0002109241540892981, Final Batch Loss: 0.00015276139311026782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2188, Loss: 0.0002069416623271536, Final Batch Loss: 0.00016192274051718414\n",
      "Epoch 2189, Loss: 0.0003515710704959929, Final Batch Loss: 0.00010364540503360331\n",
      "Epoch 2190, Loss: 0.00030348139262059703, Final Batch Loss: 1.790805981727317e-05\n",
      "Epoch 2191, Loss: 7.704272138653323e-05, Final Batch Loss: 1.623873322387226e-05\n",
      "Epoch 2192, Loss: 0.00014623296010540798, Final Batch Loss: 6.3805200625211e-05\n",
      "Epoch 2193, Loss: 0.003603797231335193, Final Batch Loss: 0.0034785026218742132\n",
      "Epoch 2194, Loss: 0.00022166300186654553, Final Batch Loss: 8.777362381806597e-05\n",
      "Epoch 2195, Loss: 7.791915777488612e-05, Final Batch Loss: 3.465798363322392e-05\n",
      "Epoch 2196, Loss: 0.00011779408669099212, Final Batch Loss: 7.50917024561204e-05\n",
      "Epoch 2197, Loss: 0.0002367267916270066, Final Batch Loss: 4.993463880964555e-05\n",
      "Epoch 2198, Loss: 0.00041104639240074903, Final Batch Loss: 0.00013897819735575467\n",
      "Epoch 2199, Loss: 0.007134620216675103, Final Batch Loss: 0.007046491373330355\n",
      "Epoch 2200, Loss: 0.0007491177202609833, Final Batch Loss: 1.4419518265640363e-05\n",
      "Epoch 2201, Loss: 0.0003050352315767668, Final Batch Loss: 0.0002233255945611745\n",
      "Epoch 2202, Loss: 9.280783342546783e-05, Final Batch Loss: 5.913382119615562e-05\n",
      "Epoch 2203, Loss: 0.00015606582564942073, Final Batch Loss: 0.00014421393279917538\n",
      "Epoch 2204, Loss: 0.0003302555705886334, Final Batch Loss: 0.00016504641098435968\n",
      "Epoch 2205, Loss: 0.00019547624833649024, Final Batch Loss: 0.00011987400648649782\n",
      "Epoch 2206, Loss: 0.0003660420188680291, Final Batch Loss: 0.0002211754908785224\n",
      "Epoch 2207, Loss: 0.00016220437464653514, Final Batch Loss: 2.502534698578529e-05\n",
      "Epoch 2208, Loss: 0.0002768814083538018, Final Batch Loss: 0.00018500750593375415\n",
      "Epoch 2209, Loss: 0.00013411962208920158, Final Batch Loss: 3.607842882047407e-05\n",
      "Epoch 2210, Loss: 0.00014932176236470696, Final Batch Loss: 2.3337610400631092e-05\n",
      "Epoch 2211, Loss: 8.235915083787404e-05, Final Batch Loss: 4.135394192417152e-05\n",
      "Epoch 2212, Loss: 0.0002907778034568764, Final Batch Loss: 0.00020652709645219147\n",
      "Epoch 2213, Loss: 0.0012871152139268816, Final Batch Loss: 0.00023841060465201735\n",
      "Epoch 2214, Loss: 0.00011525521767907776, Final Batch Loss: 3.391147401998751e-05\n",
      "Epoch 2215, Loss: 0.00048008783778641373, Final Batch Loss: 0.000434274465078488\n",
      "Epoch 2216, Loss: 0.00016838376905070618, Final Batch Loss: 7.188646850408986e-05\n",
      "Epoch 2217, Loss: 0.00025283423929067794, Final Batch Loss: 2.6946896468871273e-05\n",
      "Epoch 2218, Loss: 0.00027950730873271823, Final Batch Loss: 0.00024596319417469203\n",
      "Epoch 2219, Loss: 0.000164966237207409, Final Batch Loss: 3.641531657194719e-05\n",
      "Epoch 2220, Loss: 0.00040203004027716815, Final Batch Loss: 5.406324635259807e-05\n",
      "Epoch 2221, Loss: 0.00013644826321979053, Final Batch Loss: 4.455804810277186e-05\n",
      "Epoch 2222, Loss: 4.833272032556124e-05, Final Batch Loss: 1.4119184925220907e-05\n",
      "Epoch 2223, Loss: 0.0013597737124655396, Final Batch Loss: 0.0012289868900552392\n",
      "Epoch 2224, Loss: 7.339561125263572e-05, Final Batch Loss: 4.192701817373745e-05\n",
      "Epoch 2225, Loss: 0.0004413329006638378, Final Batch Loss: 0.00020947163284290582\n",
      "Epoch 2226, Loss: 0.0003611112115322612, Final Batch Loss: 9.359357500215992e-05\n",
      "Epoch 2227, Loss: 5.570111989072757e-05, Final Batch Loss: 1.1020573765563313e-05\n",
      "Epoch 2228, Loss: 0.00012355457147350535, Final Batch Loss: 5.528535257326439e-05\n",
      "Epoch 2229, Loss: 4.1222680010832846e-05, Final Batch Loss: 2.02351529878797e-05\n",
      "Epoch 2230, Loss: 0.000329102658724878, Final Batch Loss: 0.00023522600531578064\n",
      "Epoch 2231, Loss: 0.0001197787369164871, Final Batch Loss: 9.571890404913574e-05\n",
      "Epoch 2232, Loss: 0.0013993624597787857, Final Batch Loss: 3.99112468585372e-05\n",
      "Epoch 2233, Loss: 0.0001822978192649316, Final Batch Loss: 0.00013982928066980094\n",
      "Epoch 2234, Loss: 9.20055535971187e-05, Final Batch Loss: 5.707994569092989e-05\n",
      "Epoch 2235, Loss: 6.901033157191705e-05, Final Batch Loss: 2.8939432013430633e-05\n",
      "Epoch 2236, Loss: 0.00018950941739603877, Final Batch Loss: 0.00011268354865023866\n",
      "Epoch 2237, Loss: 5.4422398534370586e-05, Final Batch Loss: 3.777468009502627e-05\n",
      "Epoch 2238, Loss: 7.527275010943413e-05, Final Batch Loss: 4.4203628931427374e-05\n",
      "Epoch 2239, Loss: 0.000299588282359764, Final Batch Loss: 0.00025798080605454743\n",
      "Epoch 2240, Loss: 0.0007985451957210898, Final Batch Loss: 8.099403930827975e-05\n",
      "Epoch 2241, Loss: 0.0060291124136711005, Final Batch Loss: 3.75217387045268e-05\n",
      "Epoch 2242, Loss: 8.169011198333465e-05, Final Batch Loss: 2.8680613468168303e-05\n",
      "Epoch 2243, Loss: 0.000599194121605251, Final Batch Loss: 0.0005513724754564464\n",
      "Epoch 2244, Loss: 0.001087778377950599, Final Batch Loss: 0.0010750340297818184\n",
      "Epoch 2245, Loss: 4.7599542540410766e-05, Final Batch Loss: 6.639306320721516e-06\n",
      "Epoch 2246, Loss: 0.001301062264246866, Final Batch Loss: 0.0012267278507351875\n",
      "Epoch 2247, Loss: 0.0026714173509390093, Final Batch Loss: 8.618695574114099e-05\n",
      "Epoch 2248, Loss: 7.019496842985973e-05, Final Batch Loss: 3.9468304748879746e-05\n",
      "Epoch 2249, Loss: 0.00020217293695168337, Final Batch Loss: 1.4971264135965612e-05\n",
      "Epoch 2250, Loss: 0.0012501968594733626, Final Batch Loss: 6.299107917584479e-05\n",
      "Epoch 2251, Loss: 9.721248170535546e-05, Final Batch Loss: 9.449320714338683e-06\n",
      "Epoch 2252, Loss: 0.006241285796477314, Final Batch Loss: 0.006234658416360617\n",
      "Epoch 2253, Loss: 0.0009750877361511812, Final Batch Loss: 8.068628085311502e-05\n",
      "Epoch 2254, Loss: 0.00020715422942885198, Final Batch Loss: 3.174158700858243e-05\n",
      "Epoch 2255, Loss: 0.00019054380391025916, Final Batch Loss: 6.316332292044535e-05\n",
      "Epoch 2256, Loss: 0.0006348061724565923, Final Batch Loss: 0.00037536415038630366\n",
      "Epoch 2257, Loss: 0.00014884248230373487, Final Batch Loss: 6.863789167255163e-05\n",
      "Epoch 2258, Loss: 0.02822162252414273, Final Batch Loss: 3.529381501721218e-05\n",
      "Epoch 2259, Loss: 0.00038347456938936375, Final Batch Loss: 0.0003618989430833608\n",
      "Epoch 2260, Loss: 5.182369477552129e-05, Final Batch Loss: 1.1065249964303803e-05\n",
      "Epoch 2261, Loss: 0.00011800206266343594, Final Batch Loss: 7.446403469657525e-05\n",
      "Epoch 2262, Loss: 0.00019393336697248742, Final Batch Loss: 0.00015369130414910614\n",
      "Epoch 2263, Loss: 0.0003029647850780748, Final Batch Loss: 6.244333781069145e-05\n",
      "Epoch 2264, Loss: 0.00012079303996870294, Final Batch Loss: 6.961847248021513e-05\n",
      "Epoch 2265, Loss: 0.00045527404290623963, Final Batch Loss: 0.00020347133977338672\n",
      "Epoch 2266, Loss: 0.000129072837808053, Final Batch Loss: 8.742847057874314e-06\n",
      "Epoch 2267, Loss: 0.004376143719127867, Final Batch Loss: 8.987778710434213e-05\n",
      "Epoch 2268, Loss: 0.02096457215520786, Final Batch Loss: 3.755832585738972e-05\n",
      "Epoch 2269, Loss: 0.0008767155231907964, Final Batch Loss: 0.00015472481027245522\n",
      "Epoch 2270, Loss: 0.00014501104669761844, Final Batch Loss: 0.00011770157288992777\n",
      "Epoch 2271, Loss: 0.0002138044374078163, Final Batch Loss: 1.0539662071096245e-05\n",
      "Epoch 2272, Loss: 0.0014169110668262874, Final Batch Loss: 7.073905635479605e-06\n",
      "Epoch 2273, Loss: 7.220514453365467e-05, Final Batch Loss: 2.292622230015695e-05\n",
      "Epoch 2274, Loss: 0.0014623287279391661, Final Batch Loss: 0.0001720822328934446\n",
      "Epoch 2275, Loss: 0.00010876974192797206, Final Batch Loss: 6.494297122117132e-05\n",
      "Epoch 2276, Loss: 8.9676780589798e-05, Final Batch Loss: 9.296526513935532e-06\n",
      "Epoch 2277, Loss: 4.640631050278898e-05, Final Batch Loss: 4.683393854065798e-06\n",
      "Epoch 2278, Loss: 6.505979763460346e-05, Final Batch Loss: 1.9304072338854894e-05\n",
      "Epoch 2279, Loss: 0.00012862559015047736, Final Batch Loss: 7.601285324199125e-05\n",
      "Epoch 2280, Loss: 0.0013861721381545067, Final Batch Loss: 0.0006363583961501718\n",
      "Epoch 2281, Loss: 0.0004305705861042952, Final Batch Loss: 3.031765481864568e-05\n",
      "Epoch 2282, Loss: 0.00013812822726322338, Final Batch Loss: 3.855134855257347e-05\n",
      "Epoch 2283, Loss: 0.0002762191816145787, Final Batch Loss: 2.4220958948717453e-05\n",
      "Epoch 2284, Loss: 0.0003986778319813311, Final Batch Loss: 0.00022282647842075676\n",
      "Epoch 2285, Loss: 6.535150168929249e-05, Final Batch Loss: 3.88099106203299e-05\n",
      "Epoch 2286, Loss: 0.00033739066111593274, Final Batch Loss: 4.101598278793972e-06\n",
      "Epoch 2287, Loss: 0.05068290900089778, Final Batch Loss: 0.0503586009144783\n",
      "Epoch 2288, Loss: 0.0001112201089199516, Final Batch Loss: 1.2254243301867973e-05\n",
      "Epoch 2289, Loss: 9.699928341433406e-05, Final Batch Loss: 6.512931577162817e-05\n",
      "Epoch 2290, Loss: 4.4703425373882055e-05, Final Batch Loss: 2.5781364456634037e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2291, Loss: 0.0007262556609930471, Final Batch Loss: 0.000664814084302634\n",
      "Epoch 2292, Loss: 0.0001893780081445584, Final Batch Loss: 1.0530546205700375e-05\n",
      "Epoch 2293, Loss: 0.0001310043880948797, Final Batch Loss: 3.854868555208668e-05\n",
      "Epoch 2294, Loss: 0.00019318636623211205, Final Batch Loss: 7.979256770340726e-05\n",
      "Epoch 2295, Loss: 0.003221109524019994, Final Batch Loss: 0.00016494306328240782\n",
      "Epoch 2296, Loss: 0.002307805058080703, Final Batch Loss: 0.0005079313996247947\n",
      "Epoch 2297, Loss: 6.796632442274131e-05, Final Batch Loss: 3.6344994441606104e-05\n",
      "Epoch 2298, Loss: 0.00027269905694993213, Final Batch Loss: 0.00010462814680067822\n",
      "Epoch 2299, Loss: 0.0008051818876992911, Final Batch Loss: 0.0005432433681562543\n",
      "Epoch 2300, Loss: 0.00015516841085627675, Final Batch Loss: 5.2328992751426995e-05\n",
      "Epoch 2301, Loss: 0.00024421820853604004, Final Batch Loss: 9.112603584071621e-05\n",
      "Epoch 2302, Loss: 0.00032222605659626424, Final Batch Loss: 4.5276014134287834e-05\n",
      "Epoch 2303, Loss: 9.335549839306623e-05, Final Batch Loss: 3.472483149380423e-05\n",
      "Epoch 2304, Loss: 0.0001245395942532923, Final Batch Loss: 8.341037028003484e-05\n",
      "Epoch 2305, Loss: 0.00023893563411547802, Final Batch Loss: 5.4923537391005084e-05\n",
      "Epoch 2306, Loss: 0.00015690036889282055, Final Batch Loss: 0.00013092665176372975\n",
      "Epoch 2307, Loss: 0.0001030153962346958, Final Batch Loss: 8.36394538055174e-05\n",
      "Epoch 2308, Loss: 6.298546759353485e-05, Final Batch Loss: 3.7085213989485055e-05\n",
      "Epoch 2309, Loss: 0.0004656760356738232, Final Batch Loss: 0.00011048005399061367\n",
      "Epoch 2310, Loss: 0.00016957327534328215, Final Batch Loss: 3.4766821045195684e-05\n",
      "Epoch 2311, Loss: 0.00012662225708481856, Final Batch Loss: 3.303822086309083e-05\n",
      "Epoch 2312, Loss: 0.00030398480885196477, Final Batch Loss: 0.00019231683108955622\n",
      "Epoch 2313, Loss: 0.00010225956430076621, Final Batch Loss: 2.2796284611104056e-05\n",
      "Epoch 2314, Loss: 8.241537852882175e-05, Final Batch Loss: 1.09485436041723e-05\n",
      "Epoch 2315, Loss: 0.0001229010449605994, Final Batch Loss: 3.4775577660184354e-05\n",
      "Epoch 2316, Loss: 0.000772448256611824, Final Batch Loss: 0.0001429012045264244\n",
      "Epoch 2317, Loss: 6.77019233989995e-05, Final Batch Loss: 3.3582229661988094e-05\n",
      "Epoch 2318, Loss: 0.0003008506610058248, Final Batch Loss: 0.00013832049444317818\n",
      "Epoch 2319, Loss: 0.0006744266283931211, Final Batch Loss: 0.0005453135818243027\n",
      "Epoch 2320, Loss: 0.0006301528537733248, Final Batch Loss: 1.3431161278276704e-05\n",
      "Epoch 2321, Loss: 0.0006824223091825843, Final Batch Loss: 0.0001746747875586152\n",
      "Epoch 2322, Loss: 0.0034779694833559915, Final Batch Loss: 0.00010295123502146453\n",
      "Epoch 2323, Loss: 0.000347358549333876, Final Batch Loss: 5.413064718595706e-05\n",
      "Epoch 2324, Loss: 0.0001684969975030981, Final Batch Loss: 3.105750511167571e-05\n",
      "Epoch 2325, Loss: 0.00036437153903534636, Final Batch Loss: 0.000298178696539253\n",
      "Epoch 2326, Loss: 2.2187388822203502e-05, Final Batch Loss: 9.857506483967882e-06\n",
      "Epoch 2327, Loss: 0.00038642456638626754, Final Batch Loss: 0.00012661851360462606\n",
      "Epoch 2328, Loss: 0.00023917209182400256, Final Batch Loss: 0.0001276881230296567\n",
      "Epoch 2329, Loss: 0.00019964543753303587, Final Batch Loss: 0.0001391259575029835\n",
      "Epoch 2330, Loss: 0.006841565482318401, Final Batch Loss: 0.002534512896090746\n",
      "Epoch 2331, Loss: 0.00012836697669627029, Final Batch Loss: 6.2305985011335e-06\n",
      "Epoch 2332, Loss: 0.007306150288059143, Final Batch Loss: 0.007274741772562265\n",
      "Epoch 2333, Loss: 0.0029665661677427124, Final Batch Loss: 0.0029485770501196384\n",
      "Epoch 2334, Loss: 0.00017089854190999176, Final Batch Loss: 2.959171797556337e-05\n",
      "Epoch 2335, Loss: 0.00017989744446822442, Final Batch Loss: 3.3288280974375084e-05\n",
      "Epoch 2336, Loss: 0.00013032646529609337, Final Batch Loss: 8.302677451865748e-05\n",
      "Epoch 2337, Loss: 0.00013672486966243014, Final Batch Loss: 9.905164915835485e-05\n",
      "Epoch 2338, Loss: 0.00024101437156787142, Final Batch Loss: 7.22792829037644e-05\n",
      "Epoch 2339, Loss: 9.818864964472596e-05, Final Batch Loss: 8.472855552099645e-05\n",
      "Epoch 2340, Loss: 8.03087577878614e-05, Final Batch Loss: 1.3963243873149622e-05\n",
      "Epoch 2341, Loss: 0.0003994286525994539, Final Batch Loss: 8.642362081445754e-05\n",
      "Epoch 2342, Loss: 0.00015573066048091277, Final Batch Loss: 0.00012239979696460068\n",
      "Epoch 2343, Loss: 0.00016620269161649048, Final Batch Loss: 8.307419921038672e-05\n",
      "Epoch 2344, Loss: 0.000173876564076636, Final Batch Loss: 3.58766337740235e-05\n",
      "Epoch 2345, Loss: 0.000165248588018585, Final Batch Loss: 6.047489296179265e-05\n",
      "Epoch 2346, Loss: 0.00015585754954372533, Final Batch Loss: 9.967314690584317e-05\n",
      "Epoch 2347, Loss: 8.91819490789203e-05, Final Batch Loss: 2.154581125068944e-05\n",
      "Epoch 2348, Loss: 0.0016790988847787958, Final Batch Loss: 0.0016297235852107406\n",
      "Epoch 2349, Loss: 0.0007591320754727349, Final Batch Loss: 0.0006347017479129136\n",
      "Epoch 2350, Loss: 0.00022180982341524214, Final Batch Loss: 0.00012807807070203125\n",
      "Epoch 2351, Loss: 0.0010433256884425646, Final Batch Loss: 2.3788355974829756e-05\n",
      "Epoch 2352, Loss: 0.00012610306657734327, Final Batch Loss: 4.702587102656253e-05\n",
      "Epoch 2353, Loss: 0.0001686167342995759, Final Batch Loss: 0.00013221112021710724\n",
      "Epoch 2354, Loss: 0.0004003614667453803, Final Batch Loss: 0.00031729473266750574\n",
      "Epoch 2355, Loss: 0.0017386027611792088, Final Batch Loss: 8.940743282437325e-05\n",
      "Epoch 2356, Loss: 0.00013619025412481278, Final Batch Loss: 7.934882887639105e-05\n",
      "Epoch 2357, Loss: 0.00017138760449597612, Final Batch Loss: 6.971116090426221e-05\n",
      "Epoch 2358, Loss: 0.0006532836941914866, Final Batch Loss: 0.0006371933850459754\n",
      "Epoch 2359, Loss: 0.0001914059103000909, Final Batch Loss: 7.721481961198151e-05\n",
      "Epoch 2360, Loss: 0.00015046910266391933, Final Batch Loss: 4.915385943604633e-05\n",
      "Epoch 2361, Loss: 0.00021029434719821438, Final Batch Loss: 0.0001463942462578416\n",
      "Epoch 2362, Loss: 0.0006865585492050741, Final Batch Loss: 2.6176396204391494e-05\n",
      "Epoch 2363, Loss: 0.0002022140979534015, Final Batch Loss: 0.0001002434000838548\n",
      "Epoch 2364, Loss: 0.00012756523938151076, Final Batch Loss: 6.830137135693803e-05\n",
      "Epoch 2365, Loss: 5.865680032002274e-05, Final Batch Loss: 4.1043327655643225e-05\n",
      "Epoch 2366, Loss: 0.00014211384041118436, Final Batch Loss: 0.00011084231664426625\n",
      "Epoch 2367, Loss: 0.00043934659333899617, Final Batch Loss: 9.250070434063673e-05\n",
      "Epoch 2368, Loss: 0.0008343800291186199, Final Batch Loss: 0.0006903908797539771\n",
      "Epoch 2369, Loss: 0.00550080167613487, Final Batch Loss: 1.1192937563464511e-05\n",
      "Epoch 2370, Loss: 0.00018187292880611494, Final Batch Loss: 0.00010376761929364875\n",
      "Epoch 2371, Loss: 8.966912901087198e-05, Final Batch Loss: 2.642962681420613e-05\n",
      "Epoch 2372, Loss: 0.0001726117479847744, Final Batch Loss: 8.36766412248835e-05\n",
      "Epoch 2373, Loss: 3.170314289491216e-05, Final Batch Loss: 1.9501133010635385e-06\n",
      "Epoch 2374, Loss: 0.0014186914359015645, Final Batch Loss: 1.5788786186021753e-05\n",
      "Epoch 2375, Loss: 6.057111568225082e-05, Final Batch Loss: 1.5968491425155662e-05\n",
      "Epoch 2376, Loss: 0.0001868537365226075, Final Batch Loss: 8.091764902928844e-05\n",
      "Epoch 2377, Loss: 0.00019120836805086583, Final Batch Loss: 0.00012113103730371222\n",
      "Epoch 2378, Loss: 0.00010444019244459923, Final Batch Loss: 8.334103040397167e-05\n",
      "Epoch 2379, Loss: 7.871345951571129e-05, Final Batch Loss: 3.674421532195993e-05\n",
      "Epoch 2380, Loss: 0.00031229965316015296, Final Batch Loss: 0.00028844765620306134\n",
      "Epoch 2381, Loss: 6.035593833075836e-05, Final Batch Loss: 2.007189323194325e-05\n",
      "Epoch 2382, Loss: 0.001883958924736362, Final Batch Loss: 0.0018586445366963744\n",
      "Epoch 2383, Loss: 0.0008616288173470821, Final Batch Loss: 4.840337624045787e-06\n",
      "Epoch 2384, Loss: 0.00013318253331817687, Final Batch Loss: 1.3164877600502223e-05\n",
      "Epoch 2385, Loss: 0.00016052823775680736, Final Batch Loss: 0.00011882233229698613\n",
      "Epoch 2386, Loss: 0.00038596729064011015, Final Batch Loss: 0.00035558032686822116\n",
      "Epoch 2387, Loss: 0.0016703507071724744, Final Batch Loss: 0.0016555589390918612\n",
      "Epoch 2388, Loss: 3.845152605208568e-05, Final Batch Loss: 3.379379995749332e-05\n",
      "Epoch 2389, Loss: 0.0002903332788264379, Final Batch Loss: 4.178153176326305e-05\n",
      "Epoch 2390, Loss: 0.0003030350708286278, Final Batch Loss: 0.00019807842909358442\n",
      "Epoch 2391, Loss: 0.00021124054183019325, Final Batch Loss: 7.609763270011172e-05\n",
      "Epoch 2392, Loss: 7.396467117359862e-05, Final Batch Loss: 1.6230886103585362e-05\n",
      "Epoch 2393, Loss: 8.196129601856228e-05, Final Batch Loss: 2.435813621559646e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2394, Loss: 3.8436988688772544e-05, Final Batch Loss: 2.8485987058957107e-05\n",
      "Epoch 2395, Loss: 0.0025782830416574143, Final Batch Loss: 0.002531403210014105\n",
      "Epoch 2396, Loss: 0.0004977679245712352, Final Batch Loss: 1.5038142919365782e-05\n",
      "Epoch 2397, Loss: 4.642505336960312e-05, Final Batch Loss: 2.0498107915045694e-05\n",
      "Epoch 2398, Loss: 0.00012830071500502527, Final Batch Loss: 8.726196392672136e-05\n",
      "Epoch 2399, Loss: 0.0002662233237060718, Final Batch Loss: 7.768290379317477e-05\n",
      "Epoch 2400, Loss: 0.0009324743114120793, Final Batch Loss: 9.512627002550289e-06\n",
      "Epoch 2401, Loss: 4.8798148782225326e-05, Final Batch Loss: 1.9724313460756093e-05\n",
      "Epoch 2402, Loss: 5.6423905334668234e-05, Final Batch Loss: 2.8855318305431865e-05\n",
      "Epoch 2403, Loss: 0.00039748837298247963, Final Batch Loss: 0.00037673479528166354\n",
      "Epoch 2404, Loss: 0.0017150304811366368, Final Batch Loss: 0.001663680886849761\n",
      "Epoch 2405, Loss: 5.485723704623524e-05, Final Batch Loss: 4.5833738113287836e-05\n",
      "Epoch 2406, Loss: 0.0002725722576997214, Final Batch Loss: 0.0002694512368179858\n",
      "Epoch 2407, Loss: 0.00012184011575300246, Final Batch Loss: 7.930221181595698e-05\n",
      "Epoch 2408, Loss: 0.0012611372258106712, Final Batch Loss: 5.418612636276521e-05\n",
      "Epoch 2409, Loss: 7.214429206214845e-05, Final Batch Loss: 2.2752432414563373e-05\n",
      "Epoch 2410, Loss: 1.2330429854046088e-05, Final Batch Loss: 4.42802320321789e-06\n",
      "Epoch 2411, Loss: 0.031580682061758125, Final Batch Loss: 0.0315590463578701\n",
      "Epoch 2412, Loss: 0.001662160619162023, Final Batch Loss: 0.0005079497350379825\n",
      "Epoch 2413, Loss: 0.00014706902584293857, Final Batch Loss: 0.00011854423064505681\n",
      "Epoch 2414, Loss: 0.00022449116295319982, Final Batch Loss: 0.00017700326861813664\n",
      "Epoch 2415, Loss: 0.00015386418817797676, Final Batch Loss: 8.444388367934152e-05\n",
      "Epoch 2416, Loss: 0.0037683674599975348, Final Batch Loss: 0.0003361511044204235\n",
      "Epoch 2417, Loss: 0.00010168514018005226, Final Batch Loss: 8.4757361037191e-05\n",
      "Epoch 2418, Loss: 0.0002386794876656495, Final Batch Loss: 3.0140690796542913e-05\n",
      "Epoch 2419, Loss: 0.00011913598245882895, Final Batch Loss: 2.0386598407640122e-05\n",
      "Epoch 2420, Loss: 0.01679151994176209, Final Batch Loss: 0.016600020229816437\n",
      "Epoch 2421, Loss: 0.0009603675571270287, Final Batch Loss: 0.00029413524316623807\n",
      "Epoch 2422, Loss: 0.00013970059080747887, Final Batch Loss: 4.0249855373986065e-05\n",
      "Epoch 2423, Loss: 0.00011482236368465237, Final Batch Loss: 3.0751016311114654e-05\n",
      "Epoch 2424, Loss: 7.114648178685457e-05, Final Batch Loss: 1.837672243709676e-05\n",
      "Epoch 2425, Loss: 0.0007833234376448672, Final Batch Loss: 3.056846253457479e-05\n",
      "Epoch 2426, Loss: 0.0001126548886531964, Final Batch Loss: 6.0547125031007454e-05\n",
      "Epoch 2427, Loss: 9.514670637145173e-05, Final Batch Loss: 8.05087765911594e-05\n",
      "Epoch 2428, Loss: 0.000824348593596369, Final Batch Loss: 0.0003173430450260639\n",
      "Epoch 2429, Loss: 0.00038609436069236835, Final Batch Loss: 5.526998393179383e-06\n",
      "Epoch 2430, Loss: 0.0027007920434698462, Final Batch Loss: 0.002099900273606181\n",
      "Epoch 2431, Loss: 0.0007458840918843634, Final Batch Loss: 0.000668505032081157\n",
      "Epoch 2432, Loss: 5.8672716477303766e-05, Final Batch Loss: 4.5162381866248325e-05\n",
      "Epoch 2433, Loss: 0.0004146056453464553, Final Batch Loss: 0.00018864854064304382\n",
      "Epoch 2434, Loss: 6.689219662803225e-05, Final Batch Loss: 4.3985121010337025e-05\n",
      "Epoch 2435, Loss: 4.914147484669229e-05, Final Batch Loss: 1.1397983143979218e-05\n",
      "Epoch 2436, Loss: 6.712571121170186e-05, Final Batch Loss: 3.742866465472616e-05\n",
      "Epoch 2437, Loss: 3.699163698911434e-05, Final Batch Loss: 2.9245053156046197e-05\n",
      "Epoch 2438, Loss: 0.0004945796390529722, Final Batch Loss: 5.3447321988642216e-05\n",
      "Epoch 2439, Loss: 0.0003917459071089979, Final Batch Loss: 0.00037709635216742754\n",
      "Epoch 2440, Loss: 4.2376213968964294e-05, Final Batch Loss: 2.6797946702572517e-05\n",
      "Epoch 2441, Loss: 0.00010186028885073029, Final Batch Loss: 6.696430500596762e-05\n",
      "Epoch 2442, Loss: 4.252242615621071e-05, Final Batch Loss: 1.946050178958103e-05\n",
      "Epoch 2443, Loss: 3.701630521391053e-05, Final Batch Loss: 2.4959072106867097e-05\n",
      "Epoch 2444, Loss: 0.00021506333905563224, Final Batch Loss: 0.00020519690588116646\n",
      "Epoch 2445, Loss: 0.00010617728457873454, Final Batch Loss: 1.018384409690043e-05\n",
      "Epoch 2446, Loss: 0.00041119912202702835, Final Batch Loss: 0.0003924496122635901\n",
      "Epoch 2447, Loss: 0.0001431921664334368, Final Batch Loss: 4.491416984819807e-05\n",
      "Epoch 2448, Loss: 0.0011433576291892678, Final Batch Loss: 5.848860018886626e-05\n",
      "Epoch 2449, Loss: 0.0001161484069598373, Final Batch Loss: 0.00010114214092027396\n",
      "Epoch 2450, Loss: 0.00018755932251224294, Final Batch Loss: 4.3035099224653095e-05\n",
      "Epoch 2451, Loss: 3.299007221357897e-05, Final Batch Loss: 1.0343714166083373e-05\n",
      "Epoch 2452, Loss: 0.00017262915207538754, Final Batch Loss: 0.00016427475202362984\n",
      "Epoch 2453, Loss: 5.753712093792274e-05, Final Batch Loss: 5.24640126968734e-05\n",
      "Epoch 2454, Loss: 0.0012113369593862444, Final Batch Loss: 0.0010064179077744484\n",
      "Epoch 2455, Loss: 0.0001232539871125482, Final Batch Loss: 4.3723332055378705e-05\n",
      "Epoch 2456, Loss: 0.0001986458707960992, Final Batch Loss: 2.083576646327856e-06\n",
      "Epoch 2457, Loss: 0.0015371602630693815, Final Batch Loss: 0.001524338498711586\n",
      "Epoch 2458, Loss: 0.004912749049253762, Final Batch Loss: 0.0018002827418968081\n",
      "Epoch 2459, Loss: 0.0004433646017787396, Final Batch Loss: 0.0004357239813543856\n",
      "Epoch 2460, Loss: 0.0001831424060583231, Final Batch Loss: 3.7775653254357167e-06\n",
      "Epoch 2461, Loss: 4.511977476795437e-05, Final Batch Loss: 1.257900021300884e-05\n",
      "Epoch 2462, Loss: 0.009100387938815402, Final Batch Loss: 0.009053532965481281\n",
      "Epoch 2463, Loss: 6.600271990464535e-05, Final Batch Loss: 5.437897925730795e-05\n",
      "Epoch 2464, Loss: 9.967346340999939e-05, Final Batch Loss: 6.412788934540004e-05\n",
      "Epoch 2465, Loss: 0.00618523329603704, Final Batch Loss: 4.7745938900334295e-06\n",
      "Epoch 2466, Loss: 0.0001375508691126015, Final Batch Loss: 7.970236765686423e-05\n",
      "Epoch 2467, Loss: 8.581930887885392e-05, Final Batch Loss: 6.860866415081546e-05\n",
      "Epoch 2468, Loss: 0.0009275035408791155, Final Batch Loss: 0.00015250287833623588\n",
      "Epoch 2469, Loss: 0.0003967733646277338, Final Batch Loss: 0.00015765606076456606\n",
      "Epoch 2470, Loss: 6.647048212471418e-05, Final Batch Loss: 3.129246397293173e-05\n",
      "Epoch 2471, Loss: 0.00013585914348368533, Final Batch Loss: 1.3652886991621926e-05\n",
      "Epoch 2472, Loss: 3.865697271976387e-05, Final Batch Loss: 9.771662917046342e-06\n",
      "Epoch 2473, Loss: 0.00011411324157961644, Final Batch Loss: 6.75536211929284e-05\n",
      "Epoch 2474, Loss: 0.0001107890466300887, Final Batch Loss: 1.2286011951800901e-05\n",
      "Epoch 2475, Loss: 2.70846985586104e-05, Final Batch Loss: 1.3533610399463214e-05\n",
      "Epoch 2476, Loss: 0.00018720793013926595, Final Batch Loss: 0.00015433115186169744\n",
      "Epoch 2477, Loss: 0.00010954648860206362, Final Batch Loss: 1.4510636901832186e-05\n",
      "Epoch 2478, Loss: 0.004506439552642405, Final Batch Loss: 0.00025324441958218813\n",
      "Epoch 2479, Loss: 0.004033129254821688, Final Batch Loss: 2.4362525437027216e-05\n",
      "Epoch 2480, Loss: 0.0006367673558997922, Final Batch Loss: 0.0006064713816158473\n",
      "Epoch 2481, Loss: 0.00015635772433597594, Final Batch Loss: 1.9665603758767247e-05\n",
      "Epoch 2482, Loss: 0.0002514363768568728, Final Batch Loss: 9.820145351113752e-06\n",
      "Epoch 2483, Loss: 0.00017348725305055268, Final Batch Loss: 2.9105493013048545e-05\n",
      "Epoch 2484, Loss: 0.0005831476519233547, Final Batch Loss: 0.0004698217089753598\n",
      "Epoch 2485, Loss: 0.0001502716913819313, Final Batch Loss: 0.0001134308404289186\n",
      "Epoch 2486, Loss: 6.307282637862954e-05, Final Batch Loss: 1.2783786587533541e-05\n",
      "Epoch 2487, Loss: 0.0005239150632405654, Final Batch Loss: 0.00017550897609908134\n",
      "Epoch 2488, Loss: 0.00011173726670676842, Final Batch Loss: 3.2208241464104503e-05\n",
      "Epoch 2489, Loss: 0.0007491820142604411, Final Batch Loss: 5.806097760796547e-05\n",
      "Epoch 2490, Loss: 0.0005534441006602719, Final Batch Loss: 0.0003619637282099575\n",
      "Epoch 2491, Loss: 0.0028444872332329396, Final Batch Loss: 2.1144431229913607e-05\n",
      "Epoch 2492, Loss: 0.00015302238170988858, Final Batch Loss: 0.00012894210522063076\n",
      "Epoch 2493, Loss: 0.00020060783390363213, Final Batch Loss: 0.00018324599659536034\n",
      "Epoch 2494, Loss: 0.00032725685741752386, Final Batch Loss: 2.906724694184959e-05\n",
      "Epoch 2495, Loss: 0.00013470163685269654, Final Batch Loss: 5.258782039163634e-05\n",
      "Epoch 2496, Loss: 5.114533178129932e-05, Final Batch Loss: 4.555734449240845e-06\n",
      "Epoch 2497, Loss: 5.5084170526242815e-05, Final Batch Loss: 3.871973240165971e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2498, Loss: 0.000363349899998866, Final Batch Loss: 0.00013814300473313779\n",
      "Epoch 2499, Loss: 0.00019699292079167208, Final Batch Loss: 0.00018233724404126406\n",
      "Epoch 2500, Loss: 3.946049946534913e-05, Final Batch Loss: 8.398184945690446e-06\n",
      "Epoch 2501, Loss: 0.0004371345530671533, Final Batch Loss: 0.0003772959753405303\n",
      "Epoch 2502, Loss: 7.673539312236244e-05, Final Batch Loss: 8.844975127431098e-06\n",
      "Epoch 2503, Loss: 0.01714484692456608, Final Batch Loss: 3.342711352161132e-06\n",
      "Epoch 2504, Loss: 0.0006563403694599401, Final Batch Loss: 3.61131205863785e-05\n",
      "Epoch 2505, Loss: 0.00019835124840028584, Final Batch Loss: 4.9320398829877377e-05\n",
      "Epoch 2506, Loss: 8.592326412326656e-05, Final Batch Loss: 5.312871508067474e-06\n",
      "Epoch 2507, Loss: 0.0018025744357146323, Final Batch Loss: 0.000521711481269449\n",
      "Epoch 2508, Loss: 1.9732101463887375e-05, Final Batch Loss: 8.543565854779445e-06\n",
      "Epoch 2509, Loss: 6.0716201915056445e-05, Final Batch Loss: 1.0568963261903264e-05\n",
      "Epoch 2510, Loss: 9.174192018690519e-05, Final Batch Loss: 1.4901164831826463e-05\n",
      "Epoch 2511, Loss: 4.240048838255461e-05, Final Batch Loss: 2.765511817415245e-05\n",
      "Epoch 2512, Loss: 6.601796485483646e-05, Final Batch Loss: 4.517683191807009e-05\n",
      "Epoch 2513, Loss: 3.5353527891857084e-05, Final Batch Loss: 2.17341093957657e-05\n",
      "Epoch 2514, Loss: 0.00014344011924549704, Final Batch Loss: 1.4833100976829883e-05\n",
      "Epoch 2515, Loss: 0.00012368957322905771, Final Batch Loss: 8.879276720108464e-05\n",
      "Epoch 2516, Loss: 0.00027149595553055406, Final Batch Loss: 0.00021170808759052306\n",
      "Epoch 2517, Loss: 0.00014654201913799625, Final Batch Loss: 7.048465704428963e-06\n",
      "Epoch 2518, Loss: 0.0009963413249352016, Final Batch Loss: 0.0008983847219496965\n",
      "Epoch 2519, Loss: 3.3891352359205484e-05, Final Batch Loss: 2.593292811070569e-05\n",
      "Epoch 2520, Loss: 0.00021701970035792328, Final Batch Loss: 4.008466567029245e-05\n",
      "Epoch 2521, Loss: 5.829446126881521e-05, Final Batch Loss: 1.788130794011522e-05\n",
      "Epoch 2522, Loss: 0.002609621464216616, Final Batch Loss: 0.0025151886511594057\n",
      "Epoch 2523, Loss: 0.0004515868167800363, Final Batch Loss: 0.00042048952309414744\n",
      "Epoch 2524, Loss: 6.263906470849179e-05, Final Batch Loss: 4.683419319917448e-05\n",
      "Epoch 2525, Loss: 6.782093078072648e-05, Final Batch Loss: 1.0755784387583844e-05\n",
      "Epoch 2526, Loss: 0.0001605580182513222, Final Batch Loss: 8.34819657029584e-05\n",
      "Epoch 2527, Loss: 0.0004023903456982225, Final Batch Loss: 0.00028732180362567306\n",
      "Epoch 2528, Loss: 0.00015754100195408682, Final Batch Loss: 3.791810286202235e-06\n",
      "Epoch 2529, Loss: 8.65118909132434e-05, Final Batch Loss: 1.0858884706976824e-05\n",
      "Epoch 2530, Loss: 3.8211175706237555e-05, Final Batch Loss: 1.0647041563061066e-05\n",
      "Epoch 2531, Loss: 0.00034537412284407765, Final Batch Loss: 0.00016098689229693264\n",
      "Epoch 2532, Loss: 0.03663527965545654, Final Batch Loss: 0.009400039911270142\n",
      "Epoch 2533, Loss: 2.959931043733377e-05, Final Batch Loss: 1.0119389116880484e-05\n",
      "Epoch 2534, Loss: 0.0006344989596982487, Final Batch Loss: 0.0005919802933931351\n",
      "Epoch 2535, Loss: 5.157593750482192e-05, Final Batch Loss: 1.4148706213745754e-05\n",
      "Epoch 2536, Loss: 0.003849757486023009, Final Batch Loss: 0.003434337442740798\n",
      "Epoch 2537, Loss: 0.0031589274294674397, Final Batch Loss: 0.0007310893852263689\n",
      "Epoch 2538, Loss: 0.00018185149201599415, Final Batch Loss: 0.00015305195120163262\n",
      "Epoch 2539, Loss: 0.0011835518344014417, Final Batch Loss: 0.0011447961442172527\n",
      "Epoch 2540, Loss: 4.682328835770022e-05, Final Batch Loss: 3.3778032957343385e-05\n",
      "Epoch 2541, Loss: 2.6900194825429935e-05, Final Batch Loss: 1.381534730171552e-05\n",
      "Epoch 2542, Loss: 0.00022957655164645985, Final Batch Loss: 7.584255217807367e-05\n",
      "Epoch 2543, Loss: 0.00010004790965467691, Final Batch Loss: 6.145001680124551e-05\n",
      "Epoch 2544, Loss: 0.0030451088377958513, Final Batch Loss: 9.616574061510619e-06\n",
      "Epoch 2545, Loss: 0.00018292245658813044, Final Batch Loss: 0.00012283219257369637\n",
      "Epoch 2546, Loss: 0.00011388825259928126, Final Batch Loss: 1.1067657396779396e-05\n",
      "Epoch 2547, Loss: 9.692107960290741e-05, Final Batch Loss: 1.9109711502096616e-05\n",
      "Epoch 2548, Loss: 0.00018800695215759333, Final Batch Loss: 2.925260014308151e-05\n",
      "Epoch 2549, Loss: 0.0001631468676350778, Final Batch Loss: 1.0200388715020381e-05\n",
      "Epoch 2550, Loss: 0.00010365347679908155, Final Batch Loss: 1.5158841961238068e-05\n",
      "Epoch 2551, Loss: 0.007710435311309993, Final Batch Loss: 0.0009896972915157676\n",
      "Epoch 2552, Loss: 0.00012059251457685605, Final Batch Loss: 4.8921589041128755e-05\n",
      "Epoch 2553, Loss: 0.0004489384009502828, Final Batch Loss: 0.00010611792095005512\n",
      "Epoch 2554, Loss: 0.00014839119830867276, Final Batch Loss: 3.632277366705239e-05\n",
      "Epoch 2555, Loss: 0.0003420094508328475, Final Batch Loss: 0.00024233873409684747\n",
      "Epoch 2556, Loss: 0.00026423740928294137, Final Batch Loss: 0.00011754254956031218\n",
      "Epoch 2557, Loss: 9.666075493441895e-05, Final Batch Loss: 4.282455120119266e-05\n",
      "Epoch 2558, Loss: 6.084217602619901e-05, Final Batch Loss: 1.7785143427317962e-05\n",
      "Epoch 2559, Loss: 9.30931910261279e-05, Final Batch Loss: 3.02582611766411e-05\n",
      "Epoch 2560, Loss: 0.0002616644705994986, Final Batch Loss: 0.00010228814062429592\n",
      "Epoch 2561, Loss: 0.0005066945668659173, Final Batch Loss: 3.21667394018732e-05\n",
      "Epoch 2562, Loss: 0.0001011188196571311, Final Batch Loss: 2.131969631591346e-05\n",
      "Epoch 2563, Loss: 0.0008568038465455174, Final Batch Loss: 0.0007989631849341094\n",
      "Epoch 2564, Loss: 0.0002456893416820094, Final Batch Loss: 2.5477100280113518e-05\n",
      "Epoch 2565, Loss: 0.00011879737576236948, Final Batch Loss: 5.295962910167873e-05\n",
      "Epoch 2566, Loss: 0.0016704866866348311, Final Batch Loss: 0.0015001124702394009\n",
      "Epoch 2567, Loss: 6.513528569485061e-05, Final Batch Loss: 1.5973088011378422e-05\n",
      "Epoch 2568, Loss: 0.0013509630334738176, Final Batch Loss: 1.6547401173738763e-05\n",
      "Epoch 2569, Loss: 7.417308006552048e-05, Final Batch Loss: 3.874654430546798e-05\n",
      "Epoch 2570, Loss: 8.237143333644781e-05, Final Batch Loss: 3.690246330734226e-06\n",
      "Epoch 2571, Loss: 0.00014941229164833203, Final Batch Loss: 1.931188307935372e-05\n",
      "Epoch 2572, Loss: 4.716545845440123e-05, Final Batch Loss: 2.7794420020654798e-05\n",
      "Epoch 2573, Loss: 0.00033109508513007313, Final Batch Loss: 0.00018054994870908558\n",
      "Epoch 2574, Loss: 0.00021399243996711448, Final Batch Loss: 0.00011613308015512303\n",
      "Epoch 2575, Loss: 0.00028499904146883637, Final Batch Loss: 8.860384696163237e-05\n",
      "Epoch 2576, Loss: 0.005538832614547573, Final Batch Loss: 3.0602546758018434e-05\n",
      "Epoch 2577, Loss: 7.128349261620315e-05, Final Batch Loss: 8.654457815282512e-06\n",
      "Epoch 2578, Loss: 7.294475290109403e-05, Final Batch Loss: 4.131368768867105e-05\n",
      "Epoch 2579, Loss: 3.73714847228257e-05, Final Batch Loss: 1.661567875999026e-05\n",
      "Epoch 2580, Loss: 2.0050909370183945e-05, Final Batch Loss: 9.372613931191154e-06\n",
      "Epoch 2581, Loss: 9.861468788585626e-05, Final Batch Loss: 3.984408613177948e-05\n",
      "Epoch 2582, Loss: 0.0002594755933387205, Final Batch Loss: 0.0001334340195171535\n",
      "Epoch 2583, Loss: 0.00026983093084709253, Final Batch Loss: 0.0002571064978837967\n",
      "Epoch 2584, Loss: 0.00016597969170106808, Final Batch Loss: 1.0180862773268018e-05\n",
      "Epoch 2585, Loss: 9.251118945030612e-05, Final Batch Loss: 7.0580576903012116e-06\n",
      "Epoch 2586, Loss: 0.0002911785968535696, Final Batch Loss: 1.2479443284973968e-05\n",
      "Epoch 2587, Loss: 8.36742328829132e-05, Final Batch Loss: 7.550770533271134e-06\n",
      "Epoch 2588, Loss: 0.0004950016973452875, Final Batch Loss: 0.0004791191313415766\n",
      "Epoch 2589, Loss: 0.0003312161297799321, Final Batch Loss: 0.0003139260516036302\n",
      "Epoch 2590, Loss: 0.0001703345842543058, Final Batch Loss: 0.0001243697915924713\n",
      "Epoch 2591, Loss: 4.425292354426347e-05, Final Batch Loss: 1.3734446838498116e-05\n",
      "Epoch 2592, Loss: 0.00020778653833986027, Final Batch Loss: 9.393816981173586e-06\n",
      "Epoch 2593, Loss: 0.00026401849754620343, Final Batch Loss: 0.00024157062580343336\n",
      "Epoch 2594, Loss: 3.0193248676368967e-05, Final Batch Loss: 3.198270860593766e-06\n",
      "Epoch 2595, Loss: 5.919938666920643e-05, Final Batch Loss: 9.786113878362812e-06\n",
      "Epoch 2596, Loss: 0.02078967198031023, Final Batch Loss: 0.02056627906858921\n",
      "Epoch 2597, Loss: 0.00020189334463793784, Final Batch Loss: 0.0001470933057134971\n",
      "Epoch 2598, Loss: 3.2809776939757285e-05, Final Batch Loss: 3.500302454995108e-06\n",
      "Epoch 2599, Loss: 0.0008698580495547503, Final Batch Loss: 0.0007354593253694475\n",
      "Epoch 2600, Loss: 4.4092690586694516e-05, Final Batch Loss: 2.298362051078584e-05\n",
      "Epoch 2601, Loss: 0.0007646581216249615, Final Batch Loss: 0.0004886150127276778\n",
      "Epoch 2602, Loss: 1.9922725186916068e-05, Final Batch Loss: 8.440407327725552e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2603, Loss: 0.008301399291667622, Final Batch Loss: 8.759705087868497e-05\n",
      "Epoch 2604, Loss: 2.0915698314638576e-05, Final Batch Loss: 6.527484856633237e-06\n",
      "Epoch 2605, Loss: 9.157086606137455e-05, Final Batch Loss: 4.758627255796455e-05\n",
      "Epoch 2606, Loss: 0.0014379220592672937, Final Batch Loss: 7.34206332708709e-05\n",
      "Epoch 2607, Loss: 0.000683137781379628, Final Batch Loss: 0.000656574557069689\n",
      "Epoch 2608, Loss: 0.0008019928727662773, Final Batch Loss: 1.4114289115241263e-05\n",
      "Epoch 2609, Loss: 4.8810577936819755e-05, Final Batch Loss: 7.816104698576964e-06\n",
      "Epoch 2610, Loss: 0.0027761618548538536, Final Batch Loss: 0.0026885722763836384\n",
      "Epoch 2611, Loss: 6.292137823038502e-05, Final Batch Loss: 8.185702426999342e-06\n",
      "Epoch 2612, Loss: 0.00020550777753669536, Final Batch Loss: 1.0985312655975576e-05\n",
      "Epoch 2613, Loss: 0.0004915587196592242, Final Batch Loss: 0.0004267669573891908\n",
      "Epoch 2614, Loss: 0.00014786396059207618, Final Batch Loss: 3.077316068811342e-05\n",
      "Epoch 2615, Loss: 7.44690878491383e-05, Final Batch Loss: 4.023107612738386e-05\n",
      "Epoch 2616, Loss: 0.00015437813272001222, Final Batch Loss: 1.8494036339689046e-05\n",
      "Epoch 2617, Loss: 0.00021349288726923987, Final Batch Loss: 0.00018533621914684772\n",
      "Epoch 2618, Loss: 0.00020641911396523938, Final Batch Loss: 8.241243631346151e-05\n",
      "Epoch 2619, Loss: 0.0010175638744840398, Final Batch Loss: 0.00023423887614626437\n",
      "Epoch 2620, Loss: 0.0001780531765689375, Final Batch Loss: 2.642964136612136e-05\n",
      "Epoch 2621, Loss: 0.0021881750726606697, Final Batch Loss: 0.00012507670908235013\n",
      "Epoch 2622, Loss: 0.00020565761951729655, Final Batch Loss: 0.0001347247016383335\n",
      "Epoch 2623, Loss: 0.0011106120073236525, Final Batch Loss: 0.00018131593242287636\n",
      "Epoch 2624, Loss: 0.00019991684166598134, Final Batch Loss: 0.000150930107338354\n",
      "Epoch 2625, Loss: 0.00010914195809164084, Final Batch Loss: 5.489811155712232e-05\n",
      "Epoch 2626, Loss: 0.00018654566520126536, Final Batch Loss: 0.00011658536095637828\n",
      "Epoch 2627, Loss: 0.00018636946333572268, Final Batch Loss: 3.9679784094914794e-05\n",
      "Epoch 2628, Loss: 0.0003341328556416556, Final Batch Loss: 0.00024339690571650863\n",
      "Epoch 2629, Loss: 0.00028542491781990975, Final Batch Loss: 7.071052095852792e-05\n",
      "Epoch 2630, Loss: 0.00014504976570606232, Final Batch Loss: 0.0001060571739799343\n",
      "Epoch 2631, Loss: 0.00020881226373603567, Final Batch Loss: 0.0001471324940212071\n",
      "Epoch 2632, Loss: 0.0010294130042893812, Final Batch Loss: 0.0009930416708812118\n",
      "Epoch 2633, Loss: 9.958730242942693e-05, Final Batch Loss: 9.060869342647493e-05\n",
      "Epoch 2634, Loss: 0.0002470159233780578, Final Batch Loss: 0.0001411704288329929\n",
      "Epoch 2635, Loss: 0.001801376827643253, Final Batch Loss: 0.0017007279675453901\n",
      "Epoch 2636, Loss: 0.00010317908163415268, Final Batch Loss: 4.426038503879681e-05\n",
      "Epoch 2637, Loss: 0.000720488213119097, Final Batch Loss: 1.5885292668826878e-05\n",
      "Epoch 2638, Loss: 0.00010647901217453182, Final Batch Loss: 7.148084841901436e-05\n",
      "Epoch 2639, Loss: 0.0011948095489060506, Final Batch Loss: 0.0010411253897473216\n",
      "Epoch 2640, Loss: 3.8392538954212796e-05, Final Batch Loss: 1.0850938451767433e-05\n",
      "Epoch 2641, Loss: 4.356713816378033e-05, Final Batch Loss: 7.806817848177161e-06\n",
      "Epoch 2642, Loss: 0.0001813986491470132, Final Batch Loss: 3.6256406019674614e-05\n",
      "Epoch 2643, Loss: 0.00016343026800313964, Final Batch Loss: 7.109712896635756e-05\n",
      "Epoch 2644, Loss: 0.0004563841866911389, Final Batch Loss: 0.0004405178769957274\n",
      "Epoch 2645, Loss: 0.00022603918478125706, Final Batch Loss: 9.647587285144255e-05\n",
      "Epoch 2646, Loss: 3.83617089028121e-05, Final Batch Loss: 1.4494261449726764e-05\n",
      "Epoch 2647, Loss: 6.770276013412513e-05, Final Batch Loss: 7.344675395870581e-06\n",
      "Epoch 2648, Loss: 5.397729910328053e-05, Final Batch Loss: 2.4293954993481748e-05\n",
      "Epoch 2649, Loss: 0.00012262804739293642, Final Batch Loss: 3.192242365912534e-05\n",
      "Epoch 2650, Loss: 0.0004800119895662647, Final Batch Loss: 0.0004207806778140366\n",
      "Epoch 2651, Loss: 0.00012042324487993028, Final Batch Loss: 2.5165221813949756e-05\n",
      "Epoch 2652, Loss: 0.00014597582048736513, Final Batch Loss: 0.00010911605932051316\n",
      "Epoch 2653, Loss: 0.007147796030039899, Final Batch Loss: 0.00019425810023676604\n",
      "Epoch 2654, Loss: 0.00021550533710978925, Final Batch Loss: 0.00017807332915253937\n",
      "Epoch 2655, Loss: 0.00015618195902789012, Final Batch Loss: 7.089915015967563e-05\n",
      "Epoch 2656, Loss: 0.0002649268317327369, Final Batch Loss: 1.7310860130237415e-05\n",
      "Epoch 2657, Loss: 5.367806261347141e-05, Final Batch Loss: 3.123824353679083e-05\n",
      "Epoch 2658, Loss: 0.0003524793755786959, Final Batch Loss: 5.6837601732695475e-05\n",
      "Epoch 2659, Loss: 0.00016669284013914876, Final Batch Loss: 3.8484835386043414e-05\n",
      "Epoch 2660, Loss: 0.00011488273230497725, Final Batch Loss: 5.845634950674139e-05\n",
      "Epoch 2661, Loss: 0.00013625887550006155, Final Batch Loss: 1.1673744666040875e-05\n",
      "Epoch 2662, Loss: 0.00013395036330621224, Final Batch Loss: 0.00011604069732129574\n",
      "Epoch 2663, Loss: 0.0001823317725211382, Final Batch Loss: 7.496811304008588e-05\n",
      "Epoch 2664, Loss: 0.00020696645151474513, Final Batch Loss: 2.0413808670127764e-05\n",
      "Epoch 2665, Loss: 0.0001189935501315631, Final Batch Loss: 3.3011929190251976e-05\n",
      "Epoch 2666, Loss: 0.00015181007074716035, Final Batch Loss: 0.00014151052164379507\n",
      "Epoch 2667, Loss: 1.711874210741371e-05, Final Batch Loss: 8.987877663457766e-06\n",
      "Epoch 2668, Loss: 0.00013194536222727038, Final Batch Loss: 2.6356985472375527e-05\n",
      "Epoch 2669, Loss: 0.0001694469465292059, Final Batch Loss: 2.6144385628867894e-05\n",
      "Epoch 2670, Loss: 4.025583439215552e-05, Final Batch Loss: 1.5604029613314196e-05\n",
      "Epoch 2671, Loss: 0.00032291234674630687, Final Batch Loss: 0.00020479189697653055\n",
      "Epoch 2672, Loss: 0.0001446244405087782, Final Batch Loss: 0.00012476480333134532\n",
      "Epoch 2673, Loss: 0.0002548049087636173, Final Batch Loss: 3.651459701359272e-05\n",
      "Epoch 2674, Loss: 7.228671529446729e-05, Final Batch Loss: 2.9912589525338262e-05\n",
      "Epoch 2675, Loss: 0.0001936854860105086, Final Batch Loss: 3.846230174531229e-05\n",
      "Epoch 2676, Loss: 0.0003473474134807475, Final Batch Loss: 0.0002709318359848112\n",
      "Epoch 2677, Loss: 0.00020798153127543628, Final Batch Loss: 6.075222336221486e-05\n",
      "Epoch 2678, Loss: 0.00043438118882477283, Final Batch Loss: 0.00029947838629595935\n",
      "Epoch 2679, Loss: 0.00018756956887955312, Final Batch Loss: 1.0384954293840565e-05\n",
      "Epoch 2680, Loss: 0.0059989684814354405, Final Batch Loss: 0.005755974445492029\n",
      "Epoch 2681, Loss: 7.966819794091862e-05, Final Batch Loss: 4.972082388121635e-05\n",
      "Epoch 2682, Loss: 0.002681981786736287, Final Batch Loss: 0.002488151891157031\n",
      "Epoch 2683, Loss: 0.0007459892804035917, Final Batch Loss: 0.000706900202203542\n",
      "Epoch 2684, Loss: 0.0004363211937743472, Final Batch Loss: 0.00040668793371878564\n",
      "Epoch 2685, Loss: 0.0001004497244139202, Final Batch Loss: 2.1277366613503546e-05\n",
      "Epoch 2686, Loss: 0.00016458106165373465, Final Batch Loss: 7.373461812676396e-06\n",
      "Epoch 2687, Loss: 5.311699533194769e-05, Final Batch Loss: 2.9731761969742365e-05\n",
      "Epoch 2688, Loss: 0.006663931873845286, Final Batch Loss: 0.006657393649220467\n",
      "Epoch 2689, Loss: 3.856795410683844e-05, Final Batch Loss: 2.2416172214434482e-05\n",
      "Epoch 2690, Loss: 4.610861105902586e-05, Final Batch Loss: 2.2566255211131647e-05\n",
      "Epoch 2691, Loss: 2.5821198505582288e-05, Final Batch Loss: 1.4581155483028851e-05\n",
      "Epoch 2692, Loss: 0.00015274122029040882, Final Batch Loss: 0.00014939076208975166\n",
      "Epoch 2693, Loss: 8.308363612741232e-05, Final Batch Loss: 1.5862628060858697e-05\n",
      "Epoch 2694, Loss: 0.00027921692526433617, Final Batch Loss: 0.0002629276132211089\n",
      "Epoch 2695, Loss: 0.00011577328768908046, Final Batch Loss: 7.177372026490048e-05\n",
      "Epoch 2696, Loss: 0.00015855239144002553, Final Batch Loss: 0.0001372640545014292\n",
      "Epoch 2697, Loss: 6.49307021376444e-05, Final Batch Loss: 3.840927820419893e-05\n",
      "Epoch 2698, Loss: 6.194218804012053e-05, Final Batch Loss: 3.528539673425257e-05\n",
      "Epoch 2699, Loss: 0.00016729642811696976, Final Batch Loss: 1.8533726688474417e-05\n",
      "Epoch 2700, Loss: 0.015944112034048885, Final Batch Loss: 0.015759006142616272\n",
      "Epoch 2701, Loss: 0.00013674087676918134, Final Batch Loss: 3.606322570703924e-05\n",
      "Epoch 2702, Loss: 0.00045085576130077243, Final Batch Loss: 0.00032995876972563565\n",
      "Epoch 2703, Loss: 0.0002101457421304076, Final Batch Loss: 1.440173127775779e-05\n",
      "Epoch 2704, Loss: 0.001006730497465469, Final Batch Loss: 0.0009047713247127831\n",
      "Epoch 2705, Loss: 0.00011537188038346358, Final Batch Loss: 3.244147592340596e-05\n",
      "Epoch 2706, Loss: 0.001920885915751569, Final Batch Loss: 0.00014009005099069327\n",
      "Epoch 2707, Loss: 9.006022082758136e-05, Final Batch Loss: 4.228818215779029e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2708, Loss: 0.0004513676640272024, Final Batch Loss: 8.513011380273383e-06\n",
      "Epoch 2709, Loss: 0.00025813026149990037, Final Batch Loss: 4.245463787810877e-05\n",
      "Epoch 2710, Loss: 7.051366719679208e-05, Final Batch Loss: 1.4204139915818814e-05\n",
      "Epoch 2711, Loss: 0.0010617127009027172, Final Batch Loss: 1.889579652925022e-05\n",
      "Epoch 2712, Loss: 8.044934293138795e-05, Final Batch Loss: 4.770564555656165e-05\n",
      "Epoch 2713, Loss: 0.00010038908067144803, Final Batch Loss: 6.148956799734151e-06\n",
      "Epoch 2714, Loss: 0.003154602423819597, Final Batch Loss: 0.0031379323918372393\n",
      "Epoch 2715, Loss: 0.0005804559332318604, Final Batch Loss: 2.543948357924819e-05\n",
      "Epoch 2716, Loss: 4.734550566354301e-05, Final Batch Loss: 1.1112448191852309e-05\n",
      "Epoch 2717, Loss: 6.561628106283024e-05, Final Batch Loss: 2.249802855658345e-05\n",
      "Epoch 2718, Loss: 0.00016207655062316917, Final Batch Loss: 3.1833780667511746e-05\n",
      "Epoch 2719, Loss: 5.948922444076743e-05, Final Batch Loss: 3.3948406780837104e-05\n",
      "Epoch 2720, Loss: 4.73457075713668e-05, Final Batch Loss: 1.7998809198616073e-05\n",
      "Epoch 2721, Loss: 7.600727985845879e-05, Final Batch Loss: 3.057081266888417e-05\n",
      "Epoch 2722, Loss: 9.021077858051285e-05, Final Batch Loss: 1.3988319551572204e-05\n",
      "Epoch 2723, Loss: 0.00019976799376308918, Final Batch Loss: 1.1118390830233693e-05\n",
      "Epoch 2724, Loss: 0.00017693345762381796, Final Batch Loss: 1.8992819605045952e-05\n",
      "Epoch 2725, Loss: 0.00012841150601161644, Final Batch Loss: 6.446247425628826e-05\n",
      "Epoch 2726, Loss: 0.00014348911645356566, Final Batch Loss: 0.00011134750820929185\n",
      "Epoch 2727, Loss: 0.00010128874419024214, Final Batch Loss: 5.6668330216780305e-05\n",
      "Epoch 2728, Loss: 6.738857427990297e-05, Final Batch Loss: 1.0921184184553567e-05\n",
      "Epoch 2729, Loss: 0.00032990839827107266, Final Batch Loss: 2.5441440811846405e-05\n",
      "Epoch 2730, Loss: 0.001792908205970889, Final Batch Loss: 0.0017481936374679208\n",
      "Epoch 2731, Loss: 0.010431509828777052, Final Batch Loss: 0.010367891751229763\n",
      "Epoch 2732, Loss: 0.0003903317956428509, Final Batch Loss: 2.370039510424249e-05\n",
      "Epoch 2733, Loss: 0.0001730258809402585, Final Batch Loss: 2.9282353352755308e-05\n",
      "Epoch 2734, Loss: 3.143966296192957e-05, Final Batch Loss: 9.066231541510206e-06\n",
      "Epoch 2735, Loss: 0.0008971472198027186, Final Batch Loss: 7.085059041855857e-05\n",
      "Epoch 2736, Loss: 2.4816981294861762e-05, Final Batch Loss: 3.99903501602239e-06\n",
      "Epoch 2737, Loss: 3.143178855680162e-05, Final Batch Loss: 8.900929060473572e-06\n",
      "Epoch 2738, Loss: 9.09140635485528e-05, Final Batch Loss: 7.162752444855869e-05\n",
      "Epoch 2739, Loss: 6.063976252335124e-05, Final Batch Loss: 3.587337414501235e-05\n",
      "Epoch 2740, Loss: 1.693056310614338e-05, Final Batch Loss: 1.1105526027677115e-05\n",
      "Epoch 2741, Loss: 3.714645572472364e-05, Final Batch Loss: 2.0824587409151718e-05\n",
      "Epoch 2742, Loss: 7.151048794185044e-05, Final Batch Loss: 5.894920468563214e-05\n",
      "Epoch 2743, Loss: 0.00034411339765938465, Final Batch Loss: 0.0003223881940357387\n",
      "Epoch 2744, Loss: 9.644761576055316e-06, Final Batch Loss: 3.536571966833435e-06\n",
      "Epoch 2745, Loss: 2.9101081508997595e-05, Final Batch Loss: 4.058799731865292e-06\n",
      "Epoch 2746, Loss: 5.0494453716964927e-05, Final Batch Loss: 7.631801963725593e-06\n",
      "Epoch 2747, Loss: 0.00010725081301643513, Final Batch Loss: 4.594192796503194e-05\n",
      "Epoch 2748, Loss: 0.00016448173118988052, Final Batch Loss: 1.617249654373154e-05\n",
      "Epoch 2749, Loss: 0.005657612200593576, Final Batch Loss: 0.0002871852775570005\n",
      "Epoch 2750, Loss: 5.515674092748668e-05, Final Batch Loss: 4.008314135717228e-05\n",
      "Epoch 2751, Loss: 5.1863610906366375e-05, Final Batch Loss: 3.6760204693564447e-06\n",
      "Epoch 2752, Loss: 2.2819035621068906e-05, Final Batch Loss: 8.450447239738423e-06\n",
      "Epoch 2753, Loss: 0.001790902009815909, Final Batch Loss: 0.0016655146609991789\n",
      "Epoch 2754, Loss: 0.00043636955160764046, Final Batch Loss: 0.0004017575120087713\n",
      "Epoch 2755, Loss: 1.2363053428998683e-05, Final Batch Loss: 4.167163751844782e-06\n",
      "Epoch 2756, Loss: 2.0677551219705492e-05, Final Batch Loss: 1.0706455213949084e-05\n",
      "Epoch 2757, Loss: 0.0007736642210147693, Final Batch Loss: 6.098248377384152e-06\n",
      "Epoch 2758, Loss: 2.6001206606451888e-05, Final Batch Loss: 1.8907881894847378e-05\n",
      "Epoch 2759, Loss: 3.260698508711357e-05, Final Batch Loss: 3.6952908430976095e-06\n",
      "Epoch 2760, Loss: 0.00026773121771839214, Final Batch Loss: 6.23426149104489e-06\n",
      "Epoch 2761, Loss: 0.0001762487936503021, Final Batch Loss: 2.818293978634756e-05\n",
      "Epoch 2762, Loss: 5.483975746756187e-05, Final Batch Loss: 7.008303327893373e-06\n",
      "Epoch 2763, Loss: 0.0002640671996232413, Final Batch Loss: 6.821730949013727e-06\n",
      "Epoch 2764, Loss: 0.00023941104154800996, Final Batch Loss: 5.8611905842553824e-05\n",
      "Epoch 2765, Loss: 3.348136306158267e-05, Final Batch Loss: 1.3002065315959044e-05\n",
      "Epoch 2766, Loss: 0.0007836463578314579, Final Batch Loss: 2.154900812456617e-06\n",
      "Epoch 2767, Loss: 0.0038839850003569154, Final Batch Loss: 8.899382009985857e-06\n",
      "Epoch 2768, Loss: 6.909780495334417e-05, Final Batch Loss: 3.360448681632988e-05\n",
      "Epoch 2769, Loss: 0.0041148240270558745, Final Batch Loss: 0.00011789254494942725\n",
      "Epoch 2770, Loss: 0.0004910118113912176, Final Batch Loss: 0.0004456095630303025\n",
      "Epoch 2771, Loss: 0.0006308486044872552, Final Batch Loss: 0.0004835787694901228\n",
      "Epoch 2772, Loss: 0.00016672623678459786, Final Batch Loss: 2.443165794829838e-05\n",
      "Epoch 2773, Loss: 0.00019292519573355094, Final Batch Loss: 1.6940954083111137e-05\n",
      "Epoch 2774, Loss: 4.412204589243629e-05, Final Batch Loss: 3.987438049080083e-06\n",
      "Epoch 2775, Loss: 7.403476320178015e-05, Final Batch Loss: 6.307513831416145e-05\n",
      "Epoch 2776, Loss: 2.367628530919319e-05, Final Batch Loss: 4.655556949728634e-06\n",
      "Epoch 2777, Loss: 5.713042446586769e-05, Final Batch Loss: 5.194054028834216e-05\n",
      "Epoch 2778, Loss: 0.00014290584658738226, Final Batch Loss: 0.00011425976845202968\n",
      "Epoch 2779, Loss: 3.649583231890574e-05, Final Batch Loss: 1.5280415027518757e-05\n",
      "Epoch 2780, Loss: 0.00028285247390158474, Final Batch Loss: 2.6224792236462235e-05\n",
      "Epoch 2781, Loss: 0.0001635597272979794, Final Batch Loss: 0.0001444267836632207\n",
      "Epoch 2782, Loss: 2.480345301592024e-05, Final Batch Loss: 9.757969564816449e-06\n",
      "Epoch 2783, Loss: 0.0012038284821755951, Final Batch Loss: 1.577042530698236e-05\n",
      "Epoch 2784, Loss: 0.0008600590517744422, Final Batch Loss: 7.773691322654486e-06\n",
      "Epoch 2785, Loss: 5.361263538361527e-05, Final Batch Loss: 2.2367548808688298e-05\n",
      "Epoch 2786, Loss: 3.816787057075999e-05, Final Batch Loss: 3.900143838109216e-06\n",
      "Epoch 2787, Loss: 0.0023079887687345035, Final Batch Loss: 2.271758421557024e-05\n",
      "Epoch 2788, Loss: 9.29753059608629e-05, Final Batch Loss: 6.44606989226304e-05\n",
      "Epoch 2789, Loss: 3.823429869953543e-05, Final Batch Loss: 2.447889346512966e-05\n",
      "Epoch 2790, Loss: 3.240214073230163e-05, Final Batch Loss: 4.56251882496872e-06\n",
      "Epoch 2791, Loss: 0.00015490015175601002, Final Batch Loss: 0.00013333123933989555\n",
      "Epoch 2792, Loss: 5.7216603636334185e-05, Final Batch Loss: 1.1710916623997036e-05\n",
      "Epoch 2793, Loss: 0.00021252097212709486, Final Batch Loss: 0.00015661361976526678\n",
      "Epoch 2794, Loss: 0.00010712953371694311, Final Batch Loss: 3.6712597648147494e-05\n",
      "Epoch 2795, Loss: 0.0006051967284292914, Final Batch Loss: 0.0005703503848053515\n",
      "Epoch 2796, Loss: 3.2542235203436576e-05, Final Batch Loss: 7.82494134909939e-06\n",
      "Epoch 2797, Loss: 0.00013244674937595846, Final Batch Loss: 8.038889973249752e-06\n",
      "Epoch 2798, Loss: 2.414143455098383e-05, Final Batch Loss: 1.1385700418031774e-05\n",
      "Epoch 2799, Loss: 2.4518201826140285e-05, Final Batch Loss: 1.7747697711456567e-05\n",
      "Epoch 2800, Loss: 3.555259218046558e-05, Final Batch Loss: 2.873727680707816e-05\n",
      "Epoch 2801, Loss: 0.0007698436711507384, Final Batch Loss: 4.712099689641036e-05\n",
      "Epoch 2802, Loss: 0.0019074840965913609, Final Batch Loss: 0.0018639644840732217\n",
      "Epoch 2803, Loss: 0.00036324844040791504, Final Batch Loss: 0.000359197030775249\n",
      "Epoch 2804, Loss: 3.7374607018136885e-05, Final Batch Loss: 2.7717038392438553e-05\n",
      "Epoch 2805, Loss: 0.0005499841645359993, Final Batch Loss: 0.00037523318314924836\n",
      "Epoch 2806, Loss: 0.0001666617681621574, Final Batch Loss: 9.14102784008719e-05\n",
      "Epoch 2807, Loss: 4.70849554403685e-05, Final Batch Loss: 2.5418234145035967e-05\n",
      "Epoch 2808, Loss: 0.0008317781903315336, Final Batch Loss: 0.00023734060232527554\n",
      "Epoch 2809, Loss: 2.4787897928035818e-05, Final Batch Loss: 1.6502875951118767e-05\n",
      "Epoch 2810, Loss: 5.0277545597054996e-05, Final Batch Loss: 3.1409927032655105e-05\n",
      "Epoch 2811, Loss: 0.0004778593865921721, Final Batch Loss: 0.0002806792326737195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2812, Loss: 0.00011290167822153307, Final Batch Loss: 6.632487929891795e-05\n",
      "Epoch 2813, Loss: 0.0003394049017515499, Final Batch Loss: 0.00031723256688565016\n",
      "Epoch 2814, Loss: 5.612044333247468e-05, Final Batch Loss: 3.7658675864804536e-05\n",
      "Epoch 2815, Loss: 0.0004156985451118089, Final Batch Loss: 0.00034257027436979115\n",
      "Epoch 2816, Loss: 3.5550958273233846e-05, Final Batch Loss: 2.9072611141600646e-05\n",
      "Epoch 2817, Loss: 3.877062408719212e-05, Final Batch Loss: 8.849901860230602e-06\n",
      "Epoch 2818, Loss: 5.590932687482564e-05, Final Batch Loss: 4.11161090596579e-05\n",
      "Epoch 2819, Loss: 0.00023199349197966512, Final Batch Loss: 1.1214424375793897e-05\n",
      "Epoch 2820, Loss: 0.0002699714823393151, Final Batch Loss: 0.0001359428424621001\n",
      "Epoch 2821, Loss: 0.00022533546507474966, Final Batch Loss: 0.00017903295520227402\n",
      "Epoch 2822, Loss: 1.4286364148574648e-05, Final Batch Loss: 6.870355264254613e-06\n",
      "Epoch 2823, Loss: 0.00017277947881666478, Final Batch Loss: 0.00015681475633755326\n",
      "Epoch 2824, Loss: 0.00015506579438806511, Final Batch Loss: 0.0001325553748756647\n",
      "Epoch 2825, Loss: 2.4838851459207945e-05, Final Batch Loss: 1.627730489417445e-05\n",
      "Epoch 2826, Loss: 0.00011272272240603343, Final Batch Loss: 1.628462632652372e-05\n",
      "Epoch 2827, Loss: 0.0001235696345247561, Final Batch Loss: 1.6732128642615862e-05\n",
      "Epoch 2828, Loss: 0.0003397627151571214, Final Batch Loss: 5.380759830586612e-05\n",
      "Epoch 2829, Loss: 0.00020506979672063608, Final Batch Loss: 9.702913303044625e-06\n",
      "Epoch 2830, Loss: 7.609953127030167e-05, Final Batch Loss: 5.55047108719009e-06\n",
      "Epoch 2831, Loss: 9.26804136724968e-06, Final Batch Loss: 2.8298225061007543e-06\n",
      "Epoch 2832, Loss: 0.0003273777501817676, Final Batch Loss: 8.969592272478621e-06\n",
      "Epoch 2833, Loss: 2.3146597754930553e-05, Final Batch Loss: 1.8922158915302134e-06\n",
      "Epoch 2834, Loss: 0.00017544778893352486, Final Batch Loss: 0.0001315267145400867\n",
      "Epoch 2835, Loss: 4.7671730499132536e-05, Final Batch Loss: 1.528531538497191e-05\n",
      "Epoch 2836, Loss: 7.192832072178135e-05, Final Batch Loss: 8.968193469627295e-06\n",
      "Epoch 2837, Loss: 0.0015262695924320724, Final Batch Loss: 4.208320387988351e-05\n",
      "Epoch 2838, Loss: 4.112948772672098e-05, Final Batch Loss: 1.402782800141722e-05\n",
      "Epoch 2839, Loss: 0.00011512736818986014, Final Batch Loss: 4.73211330245249e-05\n",
      "Epoch 2840, Loss: 0.0026387988473288715, Final Batch Loss: 0.00012548657832667232\n",
      "Epoch 2841, Loss: 0.000958098222326953, Final Batch Loss: 0.0008866713615134358\n",
      "Epoch 2842, Loss: 1.231231226483942e-05, Final Batch Loss: 6.834174655523384e-06\n",
      "Epoch 2843, Loss: 2.2841993086331058e-05, Final Batch Loss: 6.5281865317956544e-06\n",
      "Epoch 2844, Loss: 2.4745663267822238e-05, Final Batch Loss: 2.7602113732427824e-06\n",
      "Epoch 2845, Loss: 1.598959033799474e-05, Final Batch Loss: 5.6670110097911675e-06\n",
      "Epoch 2846, Loss: 2.9681745218113065e-05, Final Batch Loss: 9.794626748771407e-06\n",
      "Epoch 2847, Loss: 0.0013827545844833367, Final Batch Loss: 1.2388853065203875e-05\n",
      "Epoch 2848, Loss: 6.953665888431715e-05, Final Batch Loss: 6.286855204962194e-05\n",
      "Epoch 2849, Loss: 0.000527358082763385, Final Batch Loss: 6.840234709670767e-05\n",
      "Epoch 2850, Loss: 7.102824929461349e-05, Final Batch Loss: 6.186609243741259e-05\n",
      "Epoch 2851, Loss: 0.00012760713070747443, Final Batch Loss: 9.52594491536729e-05\n",
      "Epoch 2852, Loss: 0.0015983303196662746, Final Batch Loss: 0.001592168235220015\n",
      "Epoch 2853, Loss: 1.9212764073017752e-05, Final Batch Loss: 1.5631905625923537e-05\n",
      "Epoch 2854, Loss: 4.0545691717852606e-05, Final Batch Loss: 3.391966311028227e-05\n",
      "Epoch 2855, Loss: 5.911521884627291e-05, Final Batch Loss: 7.6228120633459184e-06\n",
      "Epoch 2856, Loss: 5.242356564849615e-05, Final Batch Loss: 1.787195651559159e-05\n",
      "Epoch 2857, Loss: 4.249090125085786e-05, Final Batch Loss: 1.7577214748598635e-05\n",
      "Epoch 2858, Loss: 0.00023075160015650908, Final Batch Loss: 0.00022536175674758852\n",
      "Epoch 2859, Loss: 0.0002290484007971827, Final Batch Loss: 1.2103093467885628e-05\n",
      "Epoch 2860, Loss: 0.0001351834143861197, Final Batch Loss: 0.00010655399091774598\n",
      "Epoch 2861, Loss: 9.810355891204381e-06, Final Batch Loss: 8.152435839292593e-06\n",
      "Epoch 2862, Loss: 2.446678263368085e-05, Final Batch Loss: 1.7142741853604093e-05\n",
      "Epoch 2863, Loss: 2.2062107291276334e-05, Final Batch Loss: 7.228157755889697e-06\n",
      "Epoch 2864, Loss: 1.872426310001174e-05, Final Batch Loss: 7.402060873573646e-06\n",
      "Epoch 2865, Loss: 4.886765509581892e-05, Final Batch Loss: 3.8470574509119615e-05\n",
      "Epoch 2866, Loss: 2.234378371213097e-05, Final Batch Loss: 6.761334589100443e-06\n",
      "Epoch 2867, Loss: 4.80536837130785e-05, Final Batch Loss: 3.1490861147176474e-05\n",
      "Epoch 2868, Loss: 9.478192805545405e-05, Final Batch Loss: 7.638896204298362e-05\n",
      "Epoch 2869, Loss: 3.2916322197706904e-05, Final Batch Loss: 2.291004784638062e-05\n",
      "Epoch 2870, Loss: 1.8420949345454574e-05, Final Batch Loss: 1.0604811905068345e-05\n",
      "Epoch 2871, Loss: 1.4132060641713906e-05, Final Batch Loss: 5.970277925371192e-06\n",
      "Epoch 2872, Loss: 5.924130709900055e-05, Final Batch Loss: 2.5415263735339977e-05\n",
      "Epoch 2873, Loss: 0.00017675201706879307, Final Batch Loss: 1.5655810784664936e-05\n",
      "Epoch 2874, Loss: 3.475264657026855e-05, Final Batch Loss: 9.866394066193607e-06\n",
      "Epoch 2875, Loss: 2.6581627480481984e-05, Final Batch Loss: 1.9408240405027755e-05\n",
      "Epoch 2876, Loss: 0.0001394677065036376, Final Batch Loss: 1.1680848729156423e-05\n",
      "Epoch 2877, Loss: 4.781584266311256e-05, Final Batch Loss: 4.275860919733532e-05\n",
      "Epoch 2878, Loss: 0.00022112673161700513, Final Batch Loss: 0.00021963521430734545\n",
      "Epoch 2879, Loss: 1.6771060018072603e-05, Final Batch Loss: 5.2890050028508995e-06\n",
      "Epoch 2880, Loss: 0.00010002675844589248, Final Batch Loss: 1.9493920262902975e-05\n",
      "Epoch 2881, Loss: 0.0001388985383528052, Final Batch Loss: 6.60271143715363e-06\n",
      "Epoch 2882, Loss: 0.00019163070919603342, Final Batch Loss: 1.942550625244621e-06\n",
      "Epoch 2883, Loss: 5.184477981856617e-05, Final Batch Loss: 4.828865348827094e-05\n",
      "Epoch 2884, Loss: 4.101803824596573e-05, Final Batch Loss: 3.680507870740257e-05\n",
      "Epoch 2885, Loss: 3.0203813821572112e-05, Final Batch Loss: 2.5035820726770908e-05\n",
      "Epoch 2886, Loss: 0.0002937138779088855, Final Batch Loss: 2.070097252726555e-06\n",
      "Epoch 2887, Loss: 5.900355790799949e-05, Final Batch Loss: 3.5174914955860004e-05\n",
      "Epoch 2888, Loss: 0.00036866340360575123, Final Batch Loss: 0.00035431660944595933\n",
      "Epoch 2889, Loss: 0.00013272084288473707, Final Batch Loss: 0.00010519670468056574\n",
      "Epoch 2890, Loss: 5.7425031627644785e-05, Final Batch Loss: 2.8613298127311282e-05\n",
      "Epoch 2891, Loss: 9.91697143035708e-05, Final Batch Loss: 7.928956620162353e-05\n",
      "Epoch 2892, Loss: 0.00014708059461554512, Final Batch Loss: 7.174625352490693e-06\n",
      "Epoch 2893, Loss: 0.0029427944391500205, Final Batch Loss: 0.000458750146208331\n",
      "Epoch 2894, Loss: 0.00011583369496293017, Final Batch Loss: 0.00010909538104897365\n",
      "Epoch 2895, Loss: 0.00015463638555957004, Final Batch Loss: 0.00013505533570423722\n",
      "Epoch 2896, Loss: 7.909065539024596e-05, Final Batch Loss: 2.4570902041887166e-06\n",
      "Epoch 2897, Loss: 1.2739281828544335e-05, Final Batch Loss: 3.8337243495334405e-06\n",
      "Epoch 2898, Loss: 9.504359513812233e-05, Final Batch Loss: 9.23169318411965e-06\n",
      "Epoch 2899, Loss: 2.9717763936787378e-05, Final Batch Loss: 1.770090966601856e-05\n",
      "Epoch 2900, Loss: 9.695238077256363e-06, Final Batch Loss: 5.801288352813572e-06\n",
      "Epoch 2901, Loss: 0.00010897296260736766, Final Batch Loss: 0.00010166445281356573\n",
      "Epoch 2902, Loss: 0.0032326021464541554, Final Batch Loss: 0.0022046214435249567\n",
      "Epoch 2903, Loss: 7.022318641247693e-05, Final Batch Loss: 6.0588365158764645e-05\n",
      "Epoch 2904, Loss: 9.204447633237578e-05, Final Batch Loss: 7.68942991271615e-05\n",
      "Epoch 2905, Loss: 9.172523732559057e-05, Final Batch Loss: 9.769156349648256e-06\n",
      "Epoch 2906, Loss: 1.9795372281805612e-05, Final Batch Loss: 1.1693958185787778e-05\n",
      "Epoch 2907, Loss: 0.00013389742161962204, Final Batch Loss: 0.00011233443365199491\n",
      "Epoch 2908, Loss: 0.003064397210437164, Final Batch Loss: 0.0030544933397322893\n",
      "Epoch 2909, Loss: 5.992805199639406e-06, Final Batch Loss: 2.217028395534726e-06\n",
      "Epoch 2910, Loss: 7.239200749609154e-05, Final Batch Loss: 1.8107657524524257e-06\n",
      "Epoch 2911, Loss: 0.000167055862448251, Final Batch Loss: 3.7112397421878995e-06\n",
      "Epoch 2912, Loss: 6.3796323047427e-05, Final Batch Loss: 5.5911295930854976e-05\n",
      "Epoch 2913, Loss: 9.376585057907505e-05, Final Batch Loss: 8.066993905231357e-05\n",
      "Epoch 2914, Loss: 0.000158202090233317, Final Batch Loss: 2.260696192024625e-06\n",
      "Epoch 2915, Loss: 0.00019677492105074634, Final Batch Loss: 2.424372496534488e-06\n",
      "Epoch 2916, Loss: 0.0010100585664076789, Final Batch Loss: 0.0010042376816272736\n",
      "Epoch 2917, Loss: 6.723126193719509e-05, Final Batch Loss: 2.6744621663965518e-06\n",
      "Epoch 2918, Loss: 0.001561327873787377, Final Batch Loss: 9.647481056163087e-05\n",
      "Epoch 2919, Loss: 1.875586895039305e-05, Final Batch Loss: 9.098543159780093e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2920, Loss: 3.451238262641709e-05, Final Batch Loss: 1.3507042240235023e-05\n",
      "Epoch 2921, Loss: 0.00023005449838819914, Final Batch Loss: 0.00019621058891061693\n",
      "Epoch 2922, Loss: 9.739675442688167e-05, Final Batch Loss: 1.470732968300581e-06\n",
      "Epoch 2923, Loss: 8.050413453020155e-05, Final Batch Loss: 3.4298169339308515e-05\n",
      "Epoch 2924, Loss: 0.0012218699412187561, Final Batch Loss: 0.001175127224996686\n",
      "Epoch 2925, Loss: 8.334629092132673e-05, Final Batch Loss: 4.759478542837314e-05\n",
      "Epoch 2926, Loss: 4.896169866697164e-05, Final Batch Loss: 4.451373570191208e-06\n",
      "Epoch 2927, Loss: 0.00021352918065531412, Final Batch Loss: 7.935138455650304e-06\n",
      "Epoch 2928, Loss: 3.775500681513222e-05, Final Batch Loss: 1.2881783732154872e-05\n",
      "Epoch 2929, Loss: 0.005075059805676574, Final Batch Loss: 0.005050348117947578\n",
      "Epoch 2930, Loss: 0.00011507461977089406, Final Batch Loss: 1.908129434013972e-06\n",
      "Epoch 2931, Loss: 0.00828325249244699, Final Batch Loss: 2.582222123237443e-06\n",
      "Epoch 2932, Loss: 7.630601612618193e-05, Final Batch Loss: 4.574027843773365e-05\n",
      "Epoch 2933, Loss: 2.1538499822781887e-05, Final Batch Loss: 1.3570529517892282e-05\n",
      "Epoch 2934, Loss: 2.4740711523918435e-05, Final Batch Loss: 9.805959052755497e-06\n",
      "Epoch 2935, Loss: 0.0018714486213866621, Final Batch Loss: 0.0015734131447970867\n",
      "Epoch 2936, Loss: 2.8004134946968406e-05, Final Batch Loss: 1.6463913198094815e-05\n",
      "Epoch 2937, Loss: 2.0945343749190215e-05, Final Batch Loss: 6.138141543488018e-06\n",
      "Epoch 2938, Loss: 0.00019352934941707645, Final Batch Loss: 0.0001715672406135127\n",
      "Epoch 2939, Loss: 2.6862439881369937e-05, Final Batch Loss: 9.822874744713772e-06\n",
      "Epoch 2940, Loss: 1.7857844341051532e-05, Final Batch Loss: 4.533076662482927e-06\n",
      "Epoch 2941, Loss: 5.910438449063804e-05, Final Batch Loss: 4.69643491669558e-05\n",
      "Epoch 2942, Loss: 3.621437826950569e-05, Final Batch Loss: 1.5828549294383265e-05\n",
      "Epoch 2943, Loss: 3.1714479064248735e-05, Final Batch Loss: 4.333115157351131e-06\n",
      "Epoch 2944, Loss: 0.00020944668358424678, Final Batch Loss: 3.424437454668805e-05\n",
      "Epoch 2945, Loss: 5.751011303800624e-05, Final Batch Loss: 3.064314660150558e-05\n",
      "Epoch 2946, Loss: 6.280914567469154e-05, Final Batch Loss: 2.4743660105741583e-05\n",
      "Epoch 2947, Loss: 0.0005721531269955449, Final Batch Loss: 6.537144508911297e-05\n",
      "Epoch 2948, Loss: 4.831055503018433e-05, Final Batch Loss: 4.286216608306859e-06\n",
      "Epoch 2949, Loss: 0.00013877284800400957, Final Batch Loss: 8.289357356261462e-05\n",
      "Epoch 2950, Loss: 0.0012848680562456138, Final Batch Loss: 0.001248275046236813\n",
      "Epoch 2951, Loss: 0.0001951759795701946, Final Batch Loss: 1.3923013284511399e-05\n",
      "Epoch 2952, Loss: 6.288293661782518e-05, Final Batch Loss: 2.4971406674012542e-05\n",
      "Epoch 2953, Loss: 0.009342760069557698, Final Batch Loss: 0.009331019595265388\n",
      "Epoch 2954, Loss: 0.005003342746931594, Final Batch Loss: 8.27828116598539e-05\n",
      "Epoch 2955, Loss: 0.024874234959952446, Final Batch Loss: 6.925702564331004e-06\n",
      "Epoch 2956, Loss: 0.015207916958388523, Final Batch Loss: 2.7315219995216466e-05\n",
      "Epoch 2957, Loss: 9.229726583726006e-05, Final Batch Loss: 9.015476280183066e-06\n",
      "Epoch 2958, Loss: 2.807615555866505e-05, Final Batch Loss: 5.309895186655922e-06\n",
      "Epoch 2959, Loss: 2.574223572082701e-05, Final Batch Loss: 4.193168479105225e-06\n",
      "Epoch 2960, Loss: 0.0003059544596908381, Final Batch Loss: 0.00029933868790976703\n",
      "Epoch 2961, Loss: 3.8601920095970854e-05, Final Batch Loss: 2.012929144257214e-05\n",
      "Epoch 2962, Loss: 0.00011013334733434021, Final Batch Loss: 8.477921801386401e-05\n",
      "Epoch 2963, Loss: 0.0011656970618787454, Final Batch Loss: 0.0011358127230778337\n",
      "Epoch 2964, Loss: 5.377831621444784e-05, Final Batch Loss: 7.612215995322913e-06\n",
      "Epoch 2965, Loss: 6.799559105274966e-05, Final Batch Loss: 1.1888226254086476e-05\n",
      "Epoch 2966, Loss: 2.8536073841678444e-05, Final Batch Loss: 5.795492143079173e-06\n",
      "Epoch 2967, Loss: 0.0003430590759307961, Final Batch Loss: 0.0003355035150889307\n",
      "Epoch 2968, Loss: 6.655987453996204e-05, Final Batch Loss: 4.751999949803576e-05\n",
      "Epoch 2969, Loss: 0.00014782042899241787, Final Batch Loss: 0.0001407671661581844\n",
      "Epoch 2970, Loss: 0.00014467539290308196, Final Batch Loss: 1.8762264062388567e-06\n",
      "Epoch 2971, Loss: 0.0032134159991983324, Final Batch Loss: 0.0003256904019508511\n",
      "Epoch 2972, Loss: 4.8987642458087066e-05, Final Batch Loss: 4.1032021727005485e-06\n",
      "Epoch 2973, Loss: 4.812076349480776e-05, Final Batch Loss: 3.379020927241072e-05\n",
      "Epoch 2974, Loss: 0.0004843471688218415, Final Batch Loss: 7.019742042757571e-05\n",
      "Epoch 2975, Loss: 3.183684384566732e-05, Final Batch Loss: 2.007880902965553e-05\n",
      "Epoch 2976, Loss: 4.088513355782197e-05, Final Batch Loss: 3.795463635469787e-05\n",
      "Epoch 2977, Loss: 7.383339698208147e-05, Final Batch Loss: 6.373715677909786e-06\n",
      "Epoch 2978, Loss: 4.8647713811078575e-05, Final Batch Loss: 5.7730676417122595e-06\n",
      "Epoch 2979, Loss: 0.00022957899091125, Final Batch Loss: 1.4096514860284515e-05\n",
      "Epoch 2980, Loss: 7.455183549609501e-05, Final Batch Loss: 6.69878936605528e-05\n",
      "Epoch 2981, Loss: 2.930203208961757e-05, Final Batch Loss: 2.0493876945693046e-05\n",
      "Epoch 2982, Loss: 2.3469007828680333e-05, Final Batch Loss: 1.135408274421934e-05\n",
      "Epoch 2983, Loss: 0.00042684717209340306, Final Batch Loss: 8.145060746755917e-06\n",
      "Epoch 2984, Loss: 0.00013429966566036455, Final Batch Loss: 5.04603267472703e-05\n",
      "Epoch 2985, Loss: 0.0007987736898940057, Final Batch Loss: 1.4792458387091756e-05\n",
      "Epoch 2986, Loss: 2.664767271198798e-05, Final Batch Loss: 4.6888362703612074e-06\n",
      "Epoch 2987, Loss: 1.9395184608583804e-05, Final Batch Loss: 8.774903108133003e-06\n",
      "Epoch 2988, Loss: 1.4295237633632496e-05, Final Batch Loss: 3.996467967226636e-06\n",
      "Epoch 2989, Loss: 0.00013366764687816612, Final Batch Loss: 0.00010955842299154028\n",
      "Epoch 2990, Loss: 0.002909643026214326, Final Batch Loss: 0.002858267165720463\n",
      "Epoch 2991, Loss: 0.00154667170590983, Final Batch Loss: 1.1582252227526624e-05\n",
      "Epoch 2992, Loss: 6.833966472186148e-05, Final Batch Loss: 5.0363338232273236e-05\n",
      "Epoch 2993, Loss: 0.0012442711085896008, Final Batch Loss: 2.270814002258703e-05\n",
      "Epoch 2994, Loss: 1.6846146081661573e-05, Final Batch Loss: 1.0994315744028427e-05\n",
      "Epoch 2995, Loss: 0.0001967429998330772, Final Batch Loss: 6.454453978221864e-05\n",
      "Epoch 2996, Loss: 0.00026488997173146345, Final Batch Loss: 2.0200390281388536e-05\n",
      "Epoch 2997, Loss: 0.0003030158313777065, Final Batch Loss: 2.0583151126629673e-05\n",
      "Epoch 2998, Loss: 8.740213888813742e-05, Final Batch Loss: 6.508100341307e-05\n",
      "Epoch 2999, Loss: 0.00017740820521794376, Final Batch Loss: 7.193157671281369e-06\n",
      "Epoch 3000, Loss: 8.961793400885654e-05, Final Batch Loss: 3.897498118021758e-06\n",
      "Epoch 3001, Loss: 4.371804152469849e-05, Final Batch Loss: 1.2664807400142308e-05\n",
      "Epoch 3002, Loss: 0.00012849181075580418, Final Batch Loss: 3.155553713440895e-05\n",
      "Epoch 3003, Loss: 6.497632284663268e-05, Final Batch Loss: 2.3664892978558782e-06\n",
      "Epoch 3004, Loss: 0.0003421057226660196, Final Batch Loss: 3.165667658322491e-05\n",
      "Epoch 3005, Loss: 3.935077620553784e-05, Final Batch Loss: 3.0038796467124484e-05\n",
      "Epoch 3006, Loss: 5.616922589979367e-05, Final Batch Loss: 1.1821307452919427e-05\n",
      "Epoch 3007, Loss: 6.589610165974591e-05, Final Batch Loss: 2.4760922315181233e-05\n",
      "Epoch 3008, Loss: 0.000400976583478041, Final Batch Loss: 4.498586349654943e-05\n",
      "Epoch 3009, Loss: 2.323525814063032e-05, Final Batch Loss: 4.7319849727500696e-06\n",
      "Epoch 3010, Loss: 0.00012261589472473133, Final Batch Loss: 0.00010590622696327046\n",
      "Epoch 3011, Loss: 0.0004967998493157211, Final Batch Loss: 7.989317055034917e-06\n",
      "Epoch 3012, Loss: 0.0004810884674952831, Final Batch Loss: 0.0004535024636425078\n",
      "Epoch 3013, Loss: 0.0004925459561491152, Final Batch Loss: 0.0004788074584212154\n",
      "Epoch 3014, Loss: 5.8783726672118064e-05, Final Batch Loss: 1.3456718988891225e-05\n",
      "Epoch 3015, Loss: 0.010765105293103261, Final Batch Loss: 0.010724680498242378\n",
      "Epoch 3016, Loss: 0.0002982132655233727, Final Batch Loss: 4.186172191111837e-06\n",
      "Epoch 3017, Loss: 4.503057334659388e-05, Final Batch Loss: 3.853020098176785e-05\n",
      "Epoch 3018, Loss: 6.0981406932114623e-05, Final Batch Loss: 4.9469283112557605e-05\n",
      "Epoch 3019, Loss: 2.934020403699833e-05, Final Batch Loss: 6.612768174818484e-06\n",
      "Epoch 3020, Loss: 0.0007373688549705548, Final Batch Loss: 0.0007076906622387469\n",
      "Epoch 3021, Loss: 5.52518577023875e-05, Final Batch Loss: 3.901961463270709e-05\n",
      "Epoch 3022, Loss: 0.00010381627612332522, Final Batch Loss: 0.00010000943439081311\n",
      "Epoch 3023, Loss: 0.00011396293302823324, Final Batch Loss: 9.055603004526347e-05\n",
      "Epoch 3024, Loss: 0.00012654471129280864, Final Batch Loss: 6.155770734039834e-06\n",
      "Epoch 3025, Loss: 2.69652236966067e-05, Final Batch Loss: 1.3356197086977772e-05\n",
      "Epoch 3026, Loss: 7.559712867077906e-05, Final Batch Loss: 1.930283360707108e-05\n",
      "Epoch 3027, Loss: 0.00034176231292804005, Final Batch Loss: 8.641732165415306e-06\n",
      "Epoch 3028, Loss: 2.4960624614323024e-05, Final Batch Loss: 1.6191675968002528e-05\n",
      "Epoch 3029, Loss: 0.00023763876106386306, Final Batch Loss: 7.753657882858533e-06\n",
      "Epoch 3030, Loss: 0.0007761090200801846, Final Batch Loss: 1.913800588226877e-05\n",
      "Epoch 3031, Loss: 3.268823365942808e-05, Final Batch Loss: 1.0725077117967885e-05\n",
      "Epoch 3032, Loss: 0.00011889647794305347, Final Batch Loss: 6.846895848866552e-05\n",
      "Epoch 3033, Loss: 9.181324912788114e-06, Final Batch Loss: 5.862210855411831e-06\n",
      "Epoch 3034, Loss: 4.571973659039941e-05, Final Batch Loss: 2.805232179525774e-05\n",
      "Epoch 3035, Loss: 6.299725646385923e-05, Final Batch Loss: 2.1087580535095185e-06\n",
      "Epoch 3036, Loss: 1.795014236449788e-05, Final Batch Loss: 1.505188492956222e-06\n",
      "Epoch 3037, Loss: 2.3930716452014167e-05, Final Batch Loss: 8.37213792692637e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3038, Loss: 7.00034015608253e-05, Final Batch Loss: 5.821114973514341e-05\n",
      "Epoch 3039, Loss: 3.9033539906085934e-05, Final Batch Loss: 1.4591402759833727e-05\n",
      "Epoch 3040, Loss: 6.286385359999258e-05, Final Batch Loss: 3.297207149444148e-05\n",
      "Epoch 3041, Loss: 0.001487716544943396, Final Batch Loss: 0.00010417062003398314\n",
      "Epoch 3042, Loss: 7.07562703610165e-05, Final Batch Loss: 1.9488301404635422e-05\n",
      "Epoch 3043, Loss: 0.00023026759299682453, Final Batch Loss: 0.00014426324923988432\n",
      "Epoch 3044, Loss: 0.00014217483112588525, Final Batch Loss: 7.71784907556139e-05\n",
      "Epoch 3045, Loss: 6.425742139981594e-05, Final Batch Loss: 4.888540206593461e-05\n",
      "Epoch 3046, Loss: 5.5020200306898914e-05, Final Batch Loss: 2.75193560810294e-05\n",
      "Epoch 3047, Loss: 0.0002293899524374865, Final Batch Loss: 0.00010913427104242146\n",
      "Epoch 3048, Loss: 4.1091599541687174e-05, Final Batch Loss: 4.311437351134373e-06\n",
      "Epoch 3049, Loss: 0.00018989037016581278, Final Batch Loss: 0.00016683602007105947\n",
      "Epoch 3050, Loss: 8.508935388817918e-05, Final Batch Loss: 6.318849773379043e-05\n",
      "Epoch 3051, Loss: 0.00017127156479546102, Final Batch Loss: 1.4683774679724593e-05\n",
      "Epoch 3052, Loss: 5.863392289029434e-05, Final Batch Loss: 4.239198824507184e-05\n",
      "Epoch 3053, Loss: 6.369478614942636e-05, Final Batch Loss: 2.090632369800005e-05\n",
      "Epoch 3054, Loss: 0.00030619563767686486, Final Batch Loss: 0.000290128868073225\n",
      "Epoch 3055, Loss: 0.010747528780484572, Final Batch Loss: 7.411479600705206e-05\n",
      "Epoch 3056, Loss: 6.685012340312824e-05, Final Batch Loss: 4.49490689788945e-05\n",
      "Epoch 3057, Loss: 0.0001695214377832599, Final Batch Loss: 2.4345376004930586e-05\n",
      "Epoch 3058, Loss: 0.00032433465821668506, Final Batch Loss: 0.0002874959900509566\n",
      "Epoch 3059, Loss: 0.00010380227649875451, Final Batch Loss: 1.9531225916580297e-05\n",
      "Epoch 3060, Loss: 6.255334210436558e-05, Final Batch Loss: 1.120785509556299e-05\n",
      "Epoch 3061, Loss: 0.00019878515013260767, Final Batch Loss: 6.246849807212129e-05\n",
      "Epoch 3062, Loss: 7.824473686923739e-05, Final Batch Loss: 2.2323480152408592e-05\n",
      "Epoch 3063, Loss: 0.00020784695880138315, Final Batch Loss: 0.0001735042897053063\n",
      "Epoch 3064, Loss: 5.392733328335453e-05, Final Batch Loss: 3.403203663765453e-05\n",
      "Epoch 3065, Loss: 0.0034931686477648327, Final Batch Loss: 2.9315264328033663e-05\n",
      "Epoch 3066, Loss: 7.612706986037665e-05, Final Batch Loss: 7.224107775982702e-06\n",
      "Epoch 3067, Loss: 5.211722418607678e-05, Final Batch Loss: 3.539165481925011e-05\n",
      "Epoch 3068, Loss: 1.7724469898894313e-05, Final Batch Loss: 3.4870070066972403e-06\n",
      "Epoch 3069, Loss: 7.019093936833087e-05, Final Batch Loss: 4.813937266590074e-05\n",
      "Epoch 3070, Loss: 0.00022289560729404911, Final Batch Loss: 6.986963126109913e-05\n",
      "Epoch 3071, Loss: 0.00020205754117341712, Final Batch Loss: 2.3575332306791097e-05\n",
      "Epoch 3072, Loss: 3.516568995109992e-05, Final Batch Loss: 4.220220034767408e-06\n",
      "Epoch 3073, Loss: 0.0006079363629396539, Final Batch Loss: 3.919617665815167e-05\n",
      "Epoch 3074, Loss: 0.0008901500841602683, Final Batch Loss: 6.161979399621487e-05\n",
      "Epoch 3075, Loss: 9.236781261279248e-05, Final Batch Loss: 3.5904664400732145e-05\n",
      "Epoch 3076, Loss: 9.307459185947664e-05, Final Batch Loss: 7.645305595360696e-05\n",
      "Epoch 3077, Loss: 0.0004868488176725805, Final Batch Loss: 0.0001754136465024203\n",
      "Epoch 3078, Loss: 5.092313404020388e-05, Final Batch Loss: 2.1626266970997676e-05\n",
      "Epoch 3079, Loss: 4.3582464968494605e-05, Final Batch Loss: 3.145557639072649e-05\n",
      "Epoch 3080, Loss: 0.0003858862692140974, Final Batch Loss: 0.0002892023476306349\n",
      "Epoch 3081, Loss: 5.847732154506957e-05, Final Batch Loss: 1.1439838090154808e-05\n",
      "Epoch 3082, Loss: 1.1548389466042863e-05, Final Batch Loss: 6.850547833892051e-06\n",
      "Epoch 3083, Loss: 0.00018769930466078222, Final Batch Loss: 4.3434847611933947e-05\n",
      "Epoch 3084, Loss: 2.061531995423138e-05, Final Batch Loss: 1.2009133570245467e-05\n",
      "Epoch 3085, Loss: 0.00014263410957937595, Final Batch Loss: 2.130464963556733e-05\n",
      "Epoch 3086, Loss: 4.0917162550613284e-05, Final Batch Loss: 4.741988959722221e-06\n",
      "Epoch 3087, Loss: 0.0002325393543287646, Final Batch Loss: 3.514083437039517e-05\n",
      "Epoch 3088, Loss: 1.8568198356661014e-05, Final Batch Loss: 6.059152838133741e-06\n",
      "Epoch 3089, Loss: 0.0004491913514357293, Final Batch Loss: 1.7785068848752417e-05\n",
      "Epoch 3090, Loss: 0.0001517013915872667, Final Batch Loss: 0.00010401498002465814\n",
      "Epoch 3091, Loss: 0.0001783412808435969, Final Batch Loss: 7.660827395739034e-05\n",
      "Epoch 3092, Loss: 5.24353908986086e-05, Final Batch Loss: 1.3524981113732792e-05\n",
      "Epoch 3093, Loss: 8.149373024934903e-05, Final Batch Loss: 9.646602848079056e-06\n",
      "Epoch 3094, Loss: 1.9560246073524468e-05, Final Batch Loss: 5.970781785435975e-06\n",
      "Epoch 3095, Loss: 0.00019272989629826043, Final Batch Loss: 2.4318122086697258e-05\n",
      "Epoch 3096, Loss: 0.00015566006186418235, Final Batch Loss: 0.0001466921530663967\n",
      "Epoch 3097, Loss: 1.0401938652648823e-05, Final Batch Loss: 8.571237231080886e-07\n",
      "Epoch 3098, Loss: 5.803350722999312e-05, Final Batch Loss: 4.193986387690529e-05\n",
      "Epoch 3099, Loss: 0.00010361361637478694, Final Batch Loss: 3.8063706597313285e-05\n",
      "Epoch 3100, Loss: 2.3838608285586815e-05, Final Batch Loss: 8.964801963884383e-06\n",
      "Epoch 3101, Loss: 5.1825200898747426e-05, Final Batch Loss: 3.758581806323491e-05\n",
      "Epoch 3102, Loss: 3.662460221676156e-05, Final Batch Loss: 2.8671431209659204e-05\n",
      "Epoch 3103, Loss: 0.00038262315501924604, Final Batch Loss: 0.0003363253199495375\n",
      "Epoch 3104, Loss: 5.70869269722607e-05, Final Batch Loss: 3.790198388742283e-05\n",
      "Epoch 3105, Loss: 2.028503513429314e-05, Final Batch Loss: 8.093389624264091e-06\n",
      "Epoch 3106, Loss: 4.163525773037691e-05, Final Batch Loss: 2.533028782636393e-05\n",
      "Epoch 3107, Loss: 0.00016200999743887223, Final Batch Loss: 5.1708058890653774e-05\n",
      "Epoch 3108, Loss: 2.7762996978708543e-05, Final Batch Loss: 7.640655894647352e-06\n",
      "Epoch 3109, Loss: 0.01712677502337101, Final Batch Loss: 0.01712278090417385\n",
      "Epoch 3110, Loss: 4.4304862967692316e-05, Final Batch Loss: 1.4869294318486936e-05\n",
      "Epoch 3111, Loss: 0.0003534010174917057, Final Batch Loss: 0.00025911745615303516\n",
      "Epoch 3112, Loss: 1.095144818918925e-05, Final Batch Loss: 1.234057549481804e-06\n",
      "Epoch 3113, Loss: 6.989530265855137e-05, Final Batch Loss: 2.6267052817274816e-05\n",
      "Epoch 3114, Loss: 0.0001658338837842166, Final Batch Loss: 5.584700829786016e-06\n",
      "Epoch 3115, Loss: 6.37591106169566e-05, Final Batch Loss: 7.31614227333921e-06\n",
      "Epoch 3116, Loss: 8.414794865529984e-05, Final Batch Loss: 4.2380714148748666e-05\n",
      "Epoch 3117, Loss: 4.1466817037871806e-05, Final Batch Loss: 4.712513600679813e-06\n",
      "Epoch 3118, Loss: 6.944557026145048e-05, Final Batch Loss: 8.597580745117739e-06\n",
      "Epoch 3119, Loss: 0.0001355552376480773, Final Batch Loss: 8.190702646970749e-05\n",
      "Epoch 3120, Loss: 7.944166100060102e-05, Final Batch Loss: 6.743169797118753e-05\n",
      "Epoch 3121, Loss: 2.0346649762359448e-05, Final Batch Loss: 9.445634532312397e-06\n",
      "Epoch 3122, Loss: 0.0030810966636636294, Final Batch Loss: 4.466120299184695e-05\n",
      "Epoch 3123, Loss: 3.177265080012148e-05, Final Batch Loss: 9.685955774330068e-06\n",
      "Epoch 3124, Loss: 0.00026863859966397285, Final Batch Loss: 9.354746725875884e-05\n",
      "Epoch 3125, Loss: 4.371011436887784e-05, Final Batch Loss: 6.196088179422077e-06\n",
      "Epoch 3126, Loss: 0.00036625175198423676, Final Batch Loss: 0.0003190484712831676\n",
      "Epoch 3127, Loss: 0.00023634925491933245, Final Batch Loss: 1.8341657778364606e-05\n",
      "Epoch 3128, Loss: 0.00018566848302725703, Final Batch Loss: 0.0001591233885847032\n",
      "Epoch 3129, Loss: 0.00037645911652361974, Final Batch Loss: 0.00033826869912445545\n",
      "Epoch 3130, Loss: 4.7084048674150836e-05, Final Batch Loss: 3.7435427657328546e-05\n",
      "Epoch 3131, Loss: 0.0001665093659539707, Final Batch Loss: 0.00010988939175149426\n",
      "Epoch 3132, Loss: 0.0002801968985295389, Final Batch Loss: 0.0002576024562586099\n",
      "Epoch 3133, Loss: 0.00011545755296538118, Final Batch Loss: 2.5343355446239002e-05\n",
      "Epoch 3134, Loss: 4.849202923651319e-05, Final Batch Loss: 3.069788363063708e-05\n",
      "Epoch 3135, Loss: 0.0001097253061743686, Final Batch Loss: 8.485725993523374e-05\n",
      "Epoch 3136, Loss: 6.367250534822233e-05, Final Batch Loss: 3.963424751418643e-05\n",
      "Epoch 3137, Loss: 8.683031774125993e-05, Final Batch Loss: 6.421060243155807e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3138, Loss: 6.599856715183705e-05, Final Batch Loss: 2.465967190801166e-05\n",
      "Epoch 3139, Loss: 4.436167728272267e-05, Final Batch Loss: 2.5751620341907255e-05\n",
      "Epoch 3140, Loss: 6.259143265197054e-05, Final Batch Loss: 2.4615146685391665e-05\n",
      "Epoch 3141, Loss: 3.331905736558838e-05, Final Batch Loss: 1.3317866432771552e-05\n",
      "Epoch 3142, Loss: 0.00016874176071723923, Final Batch Loss: 5.361752846511081e-05\n",
      "Epoch 3143, Loss: 0.0001679822089499794, Final Batch Loss: 9.40141617320478e-05\n",
      "Epoch 3144, Loss: 5.416928661361453e-05, Final Batch Loss: 5.932085059612291e-06\n",
      "Epoch 3145, Loss: 0.0002250063553219661, Final Batch Loss: 0.00014851179730612785\n",
      "Epoch 3146, Loss: 9.516155841993168e-05, Final Batch Loss: 5.8483674365561455e-05\n",
      "Epoch 3147, Loss: 4.7242726395779755e-05, Final Batch Loss: 4.3394433305365965e-05\n",
      "Epoch 3148, Loss: 8.250303653767332e-05, Final Batch Loss: 1.6987149138003588e-05\n",
      "Epoch 3149, Loss: 0.0003038225768250413, Final Batch Loss: 7.48344391467981e-05\n",
      "Epoch 3150, Loss: 0.00011675377209030557, Final Batch Loss: 1.1994396118097939e-05\n",
      "Epoch 3151, Loss: 6.548896817548666e-05, Final Batch Loss: 4.2332620068918914e-05\n",
      "Epoch 3152, Loss: 3.394631028186268e-05, Final Batch Loss: 1.6949223891060683e-06\n",
      "Epoch 3153, Loss: 6.077407124394085e-05, Final Batch Loss: 4.93332372570876e-05\n",
      "Epoch 3154, Loss: 3.746378934010863e-05, Final Batch Loss: 1.6249174223048612e-05\n",
      "Epoch 3155, Loss: 7.628269031556556e-05, Final Batch Loss: 4.325463123677764e-06\n",
      "Epoch 3156, Loss: 0.0001176045168449491, Final Batch Loss: 3.4139281979150837e-06\n",
      "Epoch 3157, Loss: 2.145251983165508e-05, Final Batch Loss: 1.752139905875083e-05\n",
      "Epoch 3158, Loss: 0.0012369719079288188, Final Batch Loss: 5.02032671647612e-05\n",
      "Epoch 3159, Loss: 7.235137672978453e-05, Final Batch Loss: 4.679548510466702e-05\n",
      "Epoch 3160, Loss: 3.124884096905589e-05, Final Batch Loss: 1.6046258679125458e-05\n",
      "Epoch 3161, Loss: 0.00016637394764984492, Final Batch Loss: 2.279843647556845e-05\n",
      "Epoch 3162, Loss: 0.0006136064062047808, Final Batch Loss: 4.096642896911362e-06\n",
      "Epoch 3163, Loss: 7.200384789030068e-05, Final Batch Loss: 2.8926853701705113e-05\n",
      "Epoch 3164, Loss: 0.00019641620747279376, Final Batch Loss: 0.0001515307667432353\n",
      "Epoch 3165, Loss: 1.3819363289258035e-05, Final Batch Loss: 9.939618621501722e-07\n",
      "Epoch 3166, Loss: 0.0014051178432055167, Final Batch Loss: 1.4972333701734897e-05\n",
      "Epoch 3167, Loss: 0.003170772804878652, Final Batch Loss: 0.0016688477480784059\n",
      "Epoch 3168, Loss: 9.847164437815081e-05, Final Batch Loss: 7.59344402467832e-05\n",
      "Epoch 3169, Loss: 5.96114023210248e-05, Final Batch Loss: 1.496658478572499e-05\n",
      "Epoch 3170, Loss: 1.9527397853380535e-05, Final Batch Loss: 8.36788967717439e-06\n",
      "Epoch 3171, Loss: 7.084539538482204e-05, Final Batch Loss: 3.37029377988074e-05\n",
      "Epoch 3172, Loss: 1.9100647932646098e-05, Final Batch Loss: 6.7489477260096464e-06\n",
      "Epoch 3173, Loss: 1.2904639334010426e-05, Final Batch Loss: 9.673723980085924e-06\n",
      "Epoch 3174, Loss: 7.158384687500075e-05, Final Batch Loss: 3.0685067031299695e-05\n",
      "Epoch 3175, Loss: 3.304260371805867e-05, Final Batch Loss: 2.274575672345236e-05\n",
      "Epoch 3176, Loss: 0.00011537596037669573, Final Batch Loss: 9.283072722610086e-05\n",
      "Epoch 3177, Loss: 0.0001297219205298461, Final Batch Loss: 6.0729340475518256e-05\n",
      "Epoch 3178, Loss: 3.4975552807736676e-05, Final Batch Loss: 8.0740546763991e-06\n",
      "Epoch 3179, Loss: 5.261018486635294e-05, Final Batch Loss: 1.5377308955066837e-05\n",
      "Epoch 3180, Loss: 0.00014566923346137628, Final Batch Loss: 0.00012520082236733288\n",
      "Epoch 3181, Loss: 8.909161761039286e-05, Final Batch Loss: 4.204853667033603e-06\n",
      "Epoch 3182, Loss: 0.00014428851409320487, Final Batch Loss: 0.0001324903714703396\n",
      "Epoch 3183, Loss: 0.000253288570092991, Final Batch Loss: 0.00023885705741122365\n",
      "Epoch 3184, Loss: 1.2868428711954039e-05, Final Batch Loss: 4.712585905508604e-06\n",
      "Epoch 3185, Loss: 2.836027579178335e-05, Final Batch Loss: 1.3985736586619169e-05\n",
      "Epoch 3186, Loss: 2.130566053892835e-05, Final Batch Loss: 1.4063110029383097e-05\n",
      "Epoch 3187, Loss: 4.7506475311820395e-05, Final Batch Loss: 9.723460607347079e-06\n",
      "Epoch 3188, Loss: 6.889828182465862e-05, Final Batch Loss: 1.9688230167957954e-05\n",
      "Epoch 3189, Loss: 5.147762567503378e-05, Final Batch Loss: 1.7171663785120472e-05\n",
      "Epoch 3190, Loss: 8.773739500611555e-05, Final Batch Loss: 2.6601874196785502e-05\n",
      "Epoch 3191, Loss: 3.084601394220954e-05, Final Batch Loss: 1.4874906810291577e-05\n",
      "Epoch 3192, Loss: 5.332797627488617e-05, Final Batch Loss: 3.5741544706979766e-05\n",
      "Epoch 3193, Loss: 3.844294110422197e-05, Final Batch Loss: 2.339628508707392e-06\n",
      "Epoch 3194, Loss: 5.94899265706772e-05, Final Batch Loss: 2.437873808958102e-05\n",
      "Epoch 3195, Loss: 0.0006791685300413519, Final Batch Loss: 0.0001598829694557935\n",
      "Epoch 3196, Loss: 3.0476119718514383e-05, Final Batch Loss: 8.976145181804895e-06\n",
      "Epoch 3197, Loss: 0.00033394921774743125, Final Batch Loss: 3.084303898504004e-05\n",
      "Epoch 3198, Loss: 2.0921891518810298e-05, Final Batch Loss: 8.229934792325366e-06\n",
      "Epoch 3199, Loss: 2.094317142109503e-05, Final Batch Loss: 5.5907335081428755e-06\n",
      "Epoch 3200, Loss: 9.096189933188725e-05, Final Batch Loss: 7.565258420072496e-05\n",
      "Epoch 3201, Loss: 0.0038949274849073845, Final Batch Loss: 8.70068743097363e-06\n",
      "Epoch 3202, Loss: 0.00012924030852445867, Final Batch Loss: 2.6318053642171435e-05\n",
      "Epoch 3203, Loss: 4.33889617852401e-05, Final Batch Loss: 1.09822976810392e-05\n",
      "Epoch 3204, Loss: 2.1543468392337672e-05, Final Batch Loss: 1.401051486027427e-05\n",
      "Epoch 3205, Loss: 9.292146273764956e-05, Final Batch Loss: 2.6779205200000433e-06\n",
      "Epoch 3206, Loss: 3.691953997986275e-05, Final Batch Loss: 4.135773906455142e-06\n",
      "Epoch 3207, Loss: 0.0006562773323821602, Final Batch Loss: 0.0006348041933961213\n",
      "Epoch 3208, Loss: 4.2346229747636244e-05, Final Batch Loss: 1.058881389326416e-05\n",
      "Epoch 3209, Loss: 3.589586412999779e-05, Final Batch Loss: 3.182836371706799e-05\n",
      "Epoch 3210, Loss: 0.00010460083422003663, Final Batch Loss: 6.707573447783943e-07\n",
      "Epoch 3211, Loss: 0.00022908623941475525, Final Batch Loss: 0.00014668535732198507\n",
      "Epoch 3212, Loss: 2.4967181161628105e-05, Final Batch Loss: 2.0471290554269217e-05\n",
      "Epoch 3213, Loss: 2.569207936176099e-05, Final Batch Loss: 6.949394446564838e-06\n",
      "Epoch 3214, Loss: 2.4569820197939407e-05, Final Batch Loss: 1.989330121432431e-05\n",
      "Epoch 3215, Loss: 8.077597885858268e-05, Final Batch Loss: 1.900475035654381e-05\n",
      "Epoch 3216, Loss: 3.6991496017435566e-05, Final Batch Loss: 1.4905668649589643e-05\n",
      "Epoch 3217, Loss: 0.0001179825540020829, Final Batch Loss: 9.059130388777703e-05\n",
      "Epoch 3218, Loss: 0.00023082836560206488, Final Batch Loss: 1.883653021650389e-05\n",
      "Epoch 3219, Loss: 2.924891214206582e-05, Final Batch Loss: 6.152670721348841e-06\n",
      "Epoch 3220, Loss: 1.8970563587572542e-05, Final Batch Loss: 2.307682052560267e-06\n",
      "Epoch 3221, Loss: 0.00014546888269251212, Final Batch Loss: 3.810547786997631e-05\n",
      "Epoch 3222, Loss: 6.933636791472964e-05, Final Batch Loss: 1.1291183454886777e-06\n",
      "Epoch 3223, Loss: 0.00029235306283226237, Final Batch Loss: 0.0002611640084069222\n",
      "Epoch 3224, Loss: 0.00011143763367726933, Final Batch Loss: 4.359861122793518e-06\n",
      "Epoch 3225, Loss: 1.6026071989472257e-05, Final Batch Loss: 7.0251940087473486e-06\n",
      "Epoch 3226, Loss: 1.5479447938560043e-05, Final Batch Loss: 7.983259820321109e-06\n",
      "Epoch 3227, Loss: 0.0012663151137530804, Final Batch Loss: 0.001119342865422368\n",
      "Epoch 3228, Loss: 2.630912513268413e-05, Final Batch Loss: 8.445255843980704e-06\n",
      "Epoch 3229, Loss: 3.897380020134733e-05, Final Batch Loss: 3.159298648824915e-05\n",
      "Epoch 3230, Loss: 7.700170726820943e-06, Final Batch Loss: 3.0983949272922473e-06\n",
      "Epoch 3231, Loss: 0.00010482889410923235, Final Batch Loss: 5.7521756389178336e-05\n",
      "Epoch 3232, Loss: 6.398063487722538e-05, Final Batch Loss: 1.0528921848163009e-05\n",
      "Epoch 3233, Loss: 4.56707439298043e-05, Final Batch Loss: 3.875706170219928e-05\n",
      "Epoch 3234, Loss: 1.7673316961008823e-05, Final Batch Loss: 5.452892310131574e-06\n",
      "Epoch 3235, Loss: 0.00010605179704725742, Final Batch Loss: 6.34718599030748e-05\n",
      "Epoch 3236, Loss: 3.583265424822457e-05, Final Batch Loss: 6.76071249472443e-06\n",
      "Epoch 3237, Loss: 2.0122663045185618e-05, Final Batch Loss: 3.7826321204192936e-06\n",
      "Epoch 3238, Loss: 0.0003759599554769011, Final Batch Loss: 9.318379170508706e-07\n",
      "Epoch 3239, Loss: 6.547127168232691e-05, Final Batch Loss: 5.8733916375786066e-05\n",
      "Epoch 3240, Loss: 1.976062549147173e-05, Final Batch Loss: 7.111233117029769e-06\n",
      "Epoch 3241, Loss: 7.958145943121053e-05, Final Batch Loss: 7.020923658274114e-05\n",
      "Epoch 3242, Loss: 0.00011296079355815891, Final Batch Loss: 0.00010144624684471637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3243, Loss: 3.255056708439952e-05, Final Batch Loss: 8.604553840996232e-06\n",
      "Epoch 3244, Loss: 0.012971489755727816, Final Batch Loss: 0.012954923324286938\n",
      "Epoch 3245, Loss: 3.946600918425247e-05, Final Batch Loss: 3.0796960345469415e-05\n",
      "Epoch 3246, Loss: 3.100668345723534e-05, Final Batch Loss: 1.90733317140257e-05\n",
      "Epoch 3247, Loss: 7.565802593489934e-05, Final Batch Loss: 3.659172989500803e-06\n",
      "Epoch 3248, Loss: 0.00011402171685404028, Final Batch Loss: 0.00010783953621285036\n",
      "Epoch 3249, Loss: 0.0002690969777177088, Final Batch Loss: 8.428554428974167e-05\n",
      "Epoch 3250, Loss: 0.0004196352238068357, Final Batch Loss: 0.00014323175128083676\n",
      "Epoch 3251, Loss: 6.954700279493409e-05, Final Batch Loss: 2.5965002805605764e-06\n",
      "Epoch 3252, Loss: 0.0008004089904716238, Final Batch Loss: 9.886651241686195e-05\n",
      "Epoch 3253, Loss: 0.0002509835940145422, Final Batch Loss: 0.00021330450545065105\n",
      "Epoch 3254, Loss: 0.0005451980687212199, Final Batch Loss: 0.0004496639594435692\n",
      "Epoch 3255, Loss: 0.00013570216879088548, Final Batch Loss: 0.00012917017738800496\n",
      "Epoch 3256, Loss: 0.00012703044740192126, Final Batch Loss: 9.34068339120131e-06\n",
      "Epoch 3257, Loss: 0.00012388790855766274, Final Batch Loss: 3.356472370796837e-05\n",
      "Epoch 3258, Loss: 8.705896289029624e-05, Final Batch Loss: 7.275212556123734e-05\n",
      "Epoch 3259, Loss: 3.59333171218168e-05, Final Batch Loss: 1.960653935384471e-05\n",
      "Epoch 3260, Loss: 0.0002793313487927662, Final Batch Loss: 2.207764373451937e-05\n",
      "Epoch 3261, Loss: 1.1933316841350461e-05, Final Batch Loss: 1.1870321259266348e-06\n",
      "Epoch 3262, Loss: 0.02420602273195982, Final Batch Loss: 0.02029609866440296\n",
      "Epoch 3263, Loss: 3.008434305229457e-05, Final Batch Loss: 1.5221893590933178e-05\n",
      "Epoch 3264, Loss: 1.8486828139430145e-05, Final Batch Loss: 1.0879671208385844e-05\n",
      "Epoch 3265, Loss: 1.1612030448304722e-05, Final Batch Loss: 6.557802862516837e-06\n",
      "Epoch 3266, Loss: 6.167334868223406e-05, Final Batch Loss: 5.15830579388421e-05\n",
      "Epoch 3267, Loss: 4.415784314915072e-05, Final Batch Loss: 3.7731570046162233e-06\n",
      "Epoch 3268, Loss: 3.61173279088689e-05, Final Batch Loss: 1.5987001461326145e-05\n",
      "Epoch 3269, Loss: 0.0006892634551149968, Final Batch Loss: 6.129848316049902e-06\n",
      "Epoch 3270, Loss: 4.3131438360433094e-05, Final Batch Loss: 3.524937346810475e-05\n",
      "Epoch 3271, Loss: 1.0801350526890019e-05, Final Batch Loss: 2.3681218408455607e-06\n",
      "Epoch 3272, Loss: 1.6889552625798387e-05, Final Batch Loss: 2.540204604883911e-06\n",
      "Epoch 3273, Loss: 0.002836097453837283, Final Batch Loss: 5.040290125180036e-05\n",
      "Epoch 3274, Loss: 4.559443004836794e-05, Final Batch Loss: 2.129956010321621e-05\n",
      "Epoch 3275, Loss: 4.211123587083421e-05, Final Batch Loss: 3.6236626328900456e-05\n",
      "Epoch 3276, Loss: 7.5412112892081495e-06, Final Batch Loss: 1.163525212177774e-06\n",
      "Epoch 3277, Loss: 0.001122971203585621, Final Batch Loss: 0.0010554082691669464\n",
      "Epoch 3278, Loss: 2.3917018552310765e-05, Final Batch Loss: 1.2267571946722455e-05\n",
      "Epoch 3279, Loss: 0.0008411034941673279, Final Batch Loss: 0.0005729853291995823\n",
      "Epoch 3280, Loss: 0.0003150407919747522, Final Batch Loss: 0.0003010548243764788\n",
      "Epoch 3281, Loss: 4.436480537606258e-05, Final Batch Loss: 1.6360348809030256e-06\n",
      "Epoch 3282, Loss: 1.7485459920862922e-05, Final Batch Loss: 1.3433051208266988e-05\n",
      "Epoch 3283, Loss: 0.0002899305982282385, Final Batch Loss: 0.00023802278155926615\n",
      "Epoch 3284, Loss: 6.152239984658081e-05, Final Batch Loss: 1.4174447642290033e-05\n",
      "Epoch 3285, Loss: 2.558888672865578e-05, Final Batch Loss: 2.200013113906607e-05\n",
      "Epoch 3286, Loss: 1.2322605925874086e-05, Final Batch Loss: 2.4854539333318826e-06\n",
      "Epoch 3287, Loss: 3.0181913871274446e-05, Final Batch Loss: 2.2908927803655388e-06\n",
      "Epoch 3288, Loss: 0.00017747563072134653, Final Batch Loss: 0.00017647907952778041\n",
      "Epoch 3289, Loss: 9.315012357546948e-05, Final Batch Loss: 7.020022894721478e-05\n",
      "Epoch 3290, Loss: 7.473366463273123e-05, Final Batch Loss: 3.0011044600541936e-06\n",
      "Epoch 3291, Loss: 5.4467443533212645e-06, Final Batch Loss: 2.0491661416599527e-06\n",
      "Epoch 3292, Loss: 3.0409103601414245e-05, Final Batch Loss: 9.601834790373687e-06\n",
      "Epoch 3293, Loss: 1.0427749202790437e-05, Final Batch Loss: 2.1717246454500128e-06\n",
      "Epoch 3294, Loss: 6.265446472752956e-06, Final Batch Loss: 2.3528421024821e-06\n",
      "Epoch 3295, Loss: 3.758368984563276e-05, Final Batch Loss: 1.3900518752052449e-05\n",
      "Epoch 3296, Loss: 2.912786203523865e-05, Final Batch Loss: 1.10245173345902e-05\n",
      "Epoch 3297, Loss: 8.357421620530658e-06, Final Batch Loss: 4.883426754531683e-06\n",
      "Epoch 3298, Loss: 3.89484175684629e-05, Final Batch Loss: 3.4450378734618425e-05\n",
      "Epoch 3299, Loss: 2.1991921585140517e-05, Final Batch Loss: 3.243213996029226e-06\n",
      "Epoch 3300, Loss: 0.0009621454023545084, Final Batch Loss: 0.0009570164838805795\n",
      "Epoch 3301, Loss: 9.708163247523771e-06, Final Batch Loss: 8.353543307748623e-06\n",
      "Epoch 3302, Loss: 6.960945688661013e-05, Final Batch Loss: 2.1180087514949264e-06\n",
      "Epoch 3303, Loss: 1.8421823597236653e-05, Final Batch Loss: 1.482934476371156e-05\n",
      "Epoch 3304, Loss: 6.803592555115756e-06, Final Batch Loss: 1.7200810589201865e-06\n",
      "Epoch 3305, Loss: 8.067758813012915e-06, Final Batch Loss: 1.6277618897220236e-06\n",
      "Epoch 3306, Loss: 2.8575071155501064e-05, Final Batch Loss: 8.077749043877702e-06\n",
      "Epoch 3307, Loss: 0.0001948817975971906, Final Batch Loss: 0.00019021327898371965\n",
      "Epoch 3308, Loss: 6.282619051489746e-05, Final Batch Loss: 1.2936618986714166e-05\n",
      "Epoch 3309, Loss: 0.00016469741240143776, Final Batch Loss: 7.54279171815142e-05\n",
      "Epoch 3310, Loss: 0.00014140820292141143, Final Batch Loss: 4.85229406876897e-07\n",
      "Epoch 3311, Loss: 3.387599554116605e-05, Final Batch Loss: 2.596613012428861e-05\n",
      "Epoch 3312, Loss: 9.74835916167649e-06, Final Batch Loss: 6.426178060792154e-06\n",
      "Epoch 3313, Loss: 0.0009061818172995117, Final Batch Loss: 0.0008918337407521904\n",
      "Epoch 3314, Loss: 0.00019675948715303093, Final Batch Loss: 3.3986871130764484e-05\n",
      "Epoch 3315, Loss: 5.2332637778818025e-06, Final Batch Loss: 3.853250518659479e-07\n",
      "Epoch 3316, Loss: 9.185173075820785e-05, Final Batch Loss: 2.9791734050377272e-05\n",
      "Epoch 3317, Loss: 2.7363917070033494e-05, Final Batch Loss: 8.893718586477917e-06\n",
      "Epoch 3318, Loss: 6.680307706119493e-06, Final Batch Loss: 2.601341748231789e-06\n",
      "Epoch 3319, Loss: 4.474232355278218e-05, Final Batch Loss: 1.2826695638068486e-05\n",
      "Epoch 3320, Loss: 7.2398213433189085e-06, Final Batch Loss: 4.3488926166901365e-06\n",
      "Epoch 3321, Loss: 0.0006825456866863533, Final Batch Loss: 0.0006769741303287446\n",
      "Epoch 3322, Loss: 6.220862542249961e-05, Final Batch Loss: 1.0098910934175365e-06\n",
      "Epoch 3323, Loss: 2.656841570569668e-05, Final Batch Loss: 5.084928488940932e-06\n",
      "Epoch 3324, Loss: 2.2910410280019278e-05, Final Batch Loss: 6.247405053727562e-06\n",
      "Epoch 3325, Loss: 6.071062216506107e-06, Final Batch Loss: 4.814178737433394e-06\n",
      "Epoch 3326, Loss: 4.373558567749569e-05, Final Batch Loss: 3.384912633919157e-05\n",
      "Epoch 3327, Loss: 1.214727853948716e-05, Final Batch Loss: 7.570368779852288e-06\n",
      "Epoch 3328, Loss: 1.952796390014555e-05, Final Batch Loss: 1.783337393135298e-05\n",
      "Epoch 3329, Loss: 1.907498472064617e-05, Final Batch Loss: 7.250858743645949e-06\n",
      "Epoch 3330, Loss: 1.0740714969870169e-05, Final Batch Loss: 4.9861187108035665e-06\n",
      "Epoch 3331, Loss: 4.533357969194185e-05, Final Batch Loss: 1.4262093827710487e-05\n",
      "Epoch 3332, Loss: 5.742260441365943e-06, Final Batch Loss: 2.9550358249252895e-07\n",
      "Epoch 3333, Loss: 6.659680138909607e-06, Final Batch Loss: 4.348112270236015e-06\n",
      "Epoch 3334, Loss: 0.000390659580261854, Final Batch Loss: 0.0003795315860770643\n",
      "Epoch 3335, Loss: 6.309319530828361e-06, Final Batch Loss: 5.649760055348452e-07\n",
      "Epoch 3336, Loss: 1.4138493497739546e-05, Final Batch Loss: 2.7097203201265074e-06\n",
      "Epoch 3337, Loss: 0.0010165684542471354, Final Batch Loss: 1.3221905419413815e-06\n",
      "Epoch 3338, Loss: 0.00018023834218183765, Final Batch Loss: 1.359707039227942e-05\n",
      "Epoch 3339, Loss: 2.55998502325383e-05, Final Batch Loss: 3.923437361663673e-06\n",
      "Epoch 3340, Loss: 8.165755048139545e-05, Final Batch Loss: 1.017457407215261e-06\n",
      "Epoch 3341, Loss: 1.4469908819592092e-05, Final Batch Loss: 5.233066076471005e-06\n",
      "Epoch 3342, Loss: 2.118087707003724e-06, Final Batch Loss: 1.2373899380691e-06\n",
      "Epoch 3343, Loss: 0.00017599390866962494, Final Batch Loss: 8.497740964230616e-06\n",
      "Epoch 3344, Loss: 0.00010098687562276609, Final Batch Loss: 6.34351308690384e-05\n",
      "Epoch 3345, Loss: 0.00010164685954805464, Final Batch Loss: 7.805244240444154e-05\n",
      "Epoch 3346, Loss: 2.598391438368708e-05, Final Batch Loss: 4.531233571469784e-06\n",
      "Epoch 3347, Loss: 5.232667319887696e-06, Final Batch Loss: 5.397951667873713e-07\n",
      "Epoch 3348, Loss: 5.56165571197198e-06, Final Batch Loss: 4.383417035569437e-06\n",
      "Epoch 3349, Loss: 3.437550412854762e-05, Final Batch Loss: 3.088134326389991e-05\n",
      "Epoch 3350, Loss: 4.699086247228479e-06, Final Batch Loss: 4.591974800405296e-07\n",
      "Epoch 3351, Loss: 1.1652551023644264e-05, Final Batch Loss: 4.625629514976026e-07\n",
      "Epoch 3352, Loss: 2.463232522131875e-05, Final Batch Loss: 1.7495043721282855e-05\n",
      "Epoch 3353, Loss: 5.311057907420036e-05, Final Batch Loss: 4.956312841386534e-05\n",
      "Epoch 3354, Loss: 3.9994284179556416e-05, Final Batch Loss: 3.489055234240368e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3355, Loss: 2.5029805783560732e-06, Final Batch Loss: 1.1735891121134046e-06\n",
      "Epoch 3356, Loss: 0.00013167162614990957, Final Batch Loss: 0.00012843951117247343\n",
      "Epoch 3357, Loss: 2.547631129345973e-05, Final Batch Loss: 2.167924503737595e-05\n",
      "Epoch 3358, Loss: 0.0018781482121994486, Final Batch Loss: 0.001864163437858224\n",
      "Epoch 3359, Loss: 0.00010486131668585585, Final Batch Loss: 9.216192120220512e-05\n",
      "Epoch 3360, Loss: 3.993572136096191e-05, Final Batch Loss: 2.456193760735914e-05\n",
      "Epoch 3361, Loss: 6.304752514552092e-05, Final Batch Loss: 5.7962111895903945e-05\n",
      "Epoch 3362, Loss: 4.945046566717792e-05, Final Batch Loss: 5.185620466363616e-06\n",
      "Epoch 3363, Loss: 1.902835015243909e-05, Final Batch Loss: 1.728317693050485e-05\n",
      "Epoch 3364, Loss: 0.0002929412094090367, Final Batch Loss: 1.8290922525920905e-05\n",
      "Epoch 3365, Loss: 2.4190100248233648e-05, Final Batch Loss: 1.931308906932827e-05\n",
      "Epoch 3366, Loss: 6.136718639027094e-05, Final Batch Loss: 1.1164213901793119e-05\n",
      "Epoch 3367, Loss: 1.855538130257628e-05, Final Batch Loss: 1.2117747246520594e-05\n",
      "Epoch 3368, Loss: 6.9109946707612835e-06, Final Batch Loss: 2.169961589970626e-06\n",
      "Epoch 3369, Loss: 6.267699791351333e-05, Final Batch Loss: 5.3518160711973906e-05\n",
      "Epoch 3370, Loss: 0.0002901430743804667, Final Batch Loss: 5.598162897513248e-05\n",
      "Epoch 3371, Loss: 0.00047479379281867296, Final Batch Loss: 8.005196286831051e-05\n",
      "Epoch 3372, Loss: 0.0017627715849357628, Final Batch Loss: 0.0017608223715797067\n",
      "Epoch 3373, Loss: 1.8683077541936655e-05, Final Batch Loss: 1.2608377801370807e-05\n",
      "Epoch 3374, Loss: 0.0001045193821482826, Final Batch Loss: 8.494378562318161e-05\n",
      "Epoch 3375, Loss: 0.00021034356132076937, Final Batch Loss: 0.00020800628408323973\n",
      "Epoch 3376, Loss: 3.834203107544454e-05, Final Batch Loss: 1.1053499292756896e-05\n",
      "Epoch 3377, Loss: 4.3933225043701896e-05, Final Batch Loss: 4.5920367597318545e-07\n",
      "Epoch 3378, Loss: 7.686873686907347e-05, Final Batch Loss: 1.687833537289407e-05\n",
      "Epoch 3379, Loss: 3.829940760624595e-05, Final Batch Loss: 8.571161743020639e-06\n",
      "Epoch 3380, Loss: 7.609027534272172e-05, Final Batch Loss: 7.117390487110242e-05\n",
      "Epoch 3381, Loss: 4.07290053772158e-06, Final Batch Loss: 3.1468982797377976e-06\n",
      "Epoch 3382, Loss: 0.0011466356436358183, Final Batch Loss: 1.0560404007264879e-05\n",
      "Epoch 3383, Loss: 1.0941260825347854e-05, Final Batch Loss: 1.0257007488689851e-05\n",
      "Epoch 3384, Loss: 0.00017235856512343162, Final Batch Loss: 2.8365234356897417e-06\n",
      "Epoch 3385, Loss: 0.0004942749656038359, Final Batch Loss: 0.00017455768829677254\n",
      "Epoch 3386, Loss: 1.887594953586813e-05, Final Batch Loss: 1.636788874748163e-05\n",
      "Epoch 3387, Loss: 2.835120540112257e-05, Final Batch Loss: 3.3704654924804345e-06\n",
      "Epoch 3388, Loss: 8.576139111937664e-05, Final Batch Loss: 2.3116651846066816e-06\n",
      "Epoch 3389, Loss: 4.4617877165364916e-05, Final Batch Loss: 2.8465390187193407e-06\n",
      "Epoch 3390, Loss: 2.1976562493364327e-05, Final Batch Loss: 7.681328497710638e-06\n",
      "Epoch 3391, Loss: 1.9450005083854194e-05, Final Batch Loss: 1.8029568309430033e-05\n",
      "Epoch 3392, Loss: 1.0145094165636692e-05, Final Batch Loss: 6.651959211012581e-06\n",
      "Epoch 3393, Loss: 0.0027906789182452485, Final Batch Loss: 0.0026356056332588196\n",
      "Epoch 3394, Loss: 4.006990229754592e-05, Final Batch Loss: 2.108619355567498e-06\n",
      "Epoch 3395, Loss: 0.0001144005473179277, Final Batch Loss: 8.08536569820717e-05\n",
      "Epoch 3396, Loss: 5.9249214245937765e-06, Final Batch Loss: 1.3934777598478831e-06\n",
      "Epoch 3397, Loss: 1.2129326933063567e-05, Final Batch Loss: 1.1878200893988833e-06\n",
      "Epoch 3398, Loss: 5.0743403448905156e-05, Final Batch Loss: 4.9408299673814327e-05\n",
      "Epoch 3399, Loss: 0.0003406459200050449, Final Batch Loss: 1.0291571015841328e-05\n",
      "Epoch 3400, Loss: 1.4607662706112023e-05, Final Batch Loss: 5.273131137073506e-06\n",
      "Epoch 3401, Loss: 0.004595904072630219, Final Batch Loss: 0.00012158269237261266\n",
      "Epoch 3402, Loss: 1.133645628215163e-05, Final Batch Loss: 7.369122613454238e-06\n",
      "Epoch 3403, Loss: 3.3493020964669995e-05, Final Batch Loss: 1.6276184396701865e-05\n",
      "Epoch 3404, Loss: 6.895507976878434e-05, Final Batch Loss: 3.125683360849507e-05\n",
      "Epoch 3405, Loss: 2.522109934943728e-05, Final Batch Loss: 1.862198405433446e-05\n",
      "Epoch 3406, Loss: 0.0002003252129725297, Final Batch Loss: 7.541236300312448e-06\n",
      "Epoch 3407, Loss: 1.992395255001611e-05, Final Batch Loss: 5.972464805381605e-06\n",
      "Epoch 3408, Loss: 7.078694898154936e-05, Final Batch Loss: 7.140313300624257e-06\n",
      "Epoch 3409, Loss: 0.00174591265295021, Final Batch Loss: 1.3235198821348604e-05\n",
      "Epoch 3410, Loss: 6.444267455663066e-05, Final Batch Loss: 2.3456943381461315e-05\n",
      "Epoch 3411, Loss: 1.1484828291941085e-05, Final Batch Loss: 9.0799258032348e-06\n",
      "Epoch 3412, Loss: 1.957455424417276e-05, Final Batch Loss: 2.464585122652352e-06\n",
      "Epoch 3413, Loss: 1.3267708709463477e-05, Final Batch Loss: 4.691532012657262e-06\n",
      "Epoch 3414, Loss: 3.7843135942239314e-05, Final Batch Loss: 1.58333896251861e-05\n",
      "Epoch 3415, Loss: 1.889066606963752e-05, Final Batch Loss: 8.509286089974921e-06\n",
      "Epoch 3416, Loss: 7.914085983884434e-05, Final Batch Loss: 1.6915579408305348e-06\n",
      "Epoch 3417, Loss: 1.6668094758642837e-05, Final Batch Loss: 4.569740667648148e-06\n",
      "Epoch 3418, Loss: 0.0006580665811384279, Final Batch Loss: 5.162890488463745e-07\n",
      "Epoch 3419, Loss: 1.561933606808452e-05, Final Batch Loss: 1.6814543641885393e-06\n",
      "Epoch 3420, Loss: 5.060882767793373e-05, Final Batch Loss: 4.572881880449131e-05\n",
      "Epoch 3421, Loss: 5.799692053187755e-05, Final Batch Loss: 6.6230245465703774e-06\n",
      "Epoch 3422, Loss: 4.6070476855675224e-05, Final Batch Loss: 6.205195859365631e-06\n",
      "Epoch 3423, Loss: 1.9359769794391468e-05, Final Batch Loss: 3.944649506593123e-06\n",
      "Epoch 3424, Loss: 0.0045095919008417695, Final Batch Loss: 0.004507078323513269\n",
      "Epoch 3425, Loss: 8.803473974694498e-05, Final Batch Loss: 2.9384384106379002e-05\n",
      "Epoch 3426, Loss: 1.3940517874289071e-05, Final Batch Loss: 5.3248081712808926e-06\n",
      "Epoch 3427, Loss: 1.7423912140657194e-05, Final Batch Loss: 1.4235029084375128e-05\n",
      "Epoch 3428, Loss: 8.45924591885705e-06, Final Batch Loss: 3.6514436487777857e-06\n",
      "Epoch 3429, Loss: 2.827658590831561e-05, Final Batch Loss: 5.852408321516123e-06\n",
      "Epoch 3430, Loss: 5.3547138577414444e-05, Final Batch Loss: 3.751521489903098e-06\n",
      "Epoch 3431, Loss: 0.00011294420255580917, Final Batch Loss: 7.071309664752334e-05\n",
      "Epoch 3432, Loss: 5.171761154088017e-05, Final Batch Loss: 2.8834576824010583e-06\n",
      "Epoch 3433, Loss: 1.560434634484409e-05, Final Batch Loss: 1.9232304566685343e-06\n",
      "Epoch 3434, Loss: 5.582663220593531e-06, Final Batch Loss: 3.794136546275695e-06\n",
      "Epoch 3435, Loss: 0.007860742443881463, Final Batch Loss: 0.007817904464900494\n",
      "Epoch 3436, Loss: 3.5250453947810456e-05, Final Batch Loss: 3.26789086102508e-06\n",
      "Epoch 3437, Loss: 1.913490132210427e-05, Final Batch Loss: 1.1787837138399482e-05\n",
      "Epoch 3438, Loss: 1.9577936200221302e-05, Final Batch Loss: 1.3182474503992125e-05\n",
      "Epoch 3439, Loss: 0.006251377508306177, Final Batch Loss: 0.006230466067790985\n",
      "Epoch 3440, Loss: 1.531116498654228e-05, Final Batch Loss: 4.801885893357394e-07\n",
      "Epoch 3441, Loss: 0.00032741911854827777, Final Batch Loss: 3.507472138153389e-05\n",
      "Epoch 3442, Loss: 0.0001337392423010897, Final Batch Loss: 0.00012192085705464706\n",
      "Epoch 3443, Loss: 0.00011518003748278716, Final Batch Loss: 3.845356786769116e-06\n",
      "Epoch 3444, Loss: 7.119994916138239e-05, Final Batch Loss: 3.063152689719573e-05\n",
      "Epoch 3445, Loss: 0.00046349050535354763, Final Batch Loss: 0.00013986196427140385\n",
      "Epoch 3446, Loss: 1.0936587386822794e-05, Final Batch Loss: 2.9859456844860688e-06\n",
      "Epoch 3447, Loss: 3.782059320656117e-05, Final Batch Loss: 2.4526234483346343e-05\n",
      "Epoch 3448, Loss: 0.0001444238587282598, Final Batch Loss: 0.00011263530905125663\n",
      "Epoch 3449, Loss: 0.0002017857468672446, Final Batch Loss: 5.5756818255758844e-06\n",
      "Epoch 3450, Loss: 1.4205722436599899e-05, Final Batch Loss: 5.130379577167332e-06\n",
      "Epoch 3451, Loss: 0.0001339260852546431, Final Batch Loss: 1.638633693801239e-05\n",
      "Epoch 3452, Loss: 5.996876643621363e-05, Final Batch Loss: 3.961620677728206e-06\n",
      "Epoch 3453, Loss: 8.64644389366731e-05, Final Batch Loss: 2.000470703933388e-05\n",
      "Epoch 3454, Loss: 1.5448654380634252e-05, Final Batch Loss: 1.430092834198149e-05\n",
      "Epoch 3455, Loss: 2.935650627478026e-05, Final Batch Loss: 1.7126922102761455e-05\n",
      "Epoch 3456, Loss: 3.108498731307918e-05, Final Batch Loss: 8.803389391687233e-06\n",
      "Epoch 3457, Loss: 1.247760246769758e-05, Final Batch Loss: 2.2656986402580515e-06\n",
      "Epoch 3458, Loss: 3.352108637955098e-05, Final Batch Loss: 3.744759169421741e-06\n",
      "Epoch 3459, Loss: 1.0632366183926933e-05, Final Batch Loss: 2.9287177767400863e-06\n",
      "Epoch 3460, Loss: 5.128966040501837e-05, Final Batch Loss: 7.875625669839792e-06\n",
      "Epoch 3461, Loss: 3.403035907467711e-05, Final Batch Loss: 3.128923344775103e-05\n",
      "Epoch 3462, Loss: 1.408152024851006e-05, Final Batch Loss: 1.1631136658252217e-05\n",
      "Epoch 3463, Loss: 4.805581033906492e-05, Final Batch Loss: 3.2804148304421687e-06\n",
      "Epoch 3464, Loss: 9.598462384019513e-06, Final Batch Loss: 6.059711722627981e-06\n",
      "Epoch 3465, Loss: 5.131948819325771e-05, Final Batch Loss: 3.3131058444269e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3466, Loss: 2.0332194367256307e-05, Final Batch Loss: 1.7980838720177417e-06\n",
      "Epoch 3467, Loss: 5.9296720110069145e-05, Final Batch Loss: 5.698557652067393e-05\n",
      "Epoch 3468, Loss: 1.843364407250192e-05, Final Batch Loss: 6.7882638177252375e-06\n",
      "Epoch 3469, Loss: 9.701702674647095e-05, Final Batch Loss: 1.2175693882454652e-05\n",
      "Epoch 3470, Loss: 2.623451109684538e-05, Final Batch Loss: 1.1060805263696238e-05\n",
      "Epoch 3471, Loss: 0.00020279940713407996, Final Batch Loss: 2.198592710556113e-06\n",
      "Epoch 3472, Loss: 1.607104445611185e-05, Final Batch Loss: 2.3287232124857837e-06\n",
      "Epoch 3473, Loss: 0.015235632670737687, Final Batch Loss: 7.726264811935835e-06\n",
      "Epoch 3474, Loss: 1.0823703860296519e-05, Final Batch Loss: 8.12974940345157e-06\n",
      "Epoch 3475, Loss: 0.0001214569524563558, Final Batch Loss: 6.971774837438716e-06\n",
      "Epoch 3476, Loss: 2.450292777211871e-05, Final Batch Loss: 6.254676918615587e-06\n",
      "Epoch 3477, Loss: 0.00020486111679929309, Final Batch Loss: 3.2429259590571746e-05\n",
      "Epoch 3478, Loss: 2.5465068574703764e-05, Final Batch Loss: 7.030414963082876e-06\n",
      "Epoch 3479, Loss: 9.242423766409047e-05, Final Batch Loss: 7.426299271173775e-05\n",
      "Epoch 3480, Loss: 9.316491286881501e-05, Final Batch Loss: 7.714880666753743e-06\n",
      "Epoch 3481, Loss: 3.520433142512047e-05, Final Batch Loss: 2.8264655611565104e-06\n",
      "Epoch 3482, Loss: 4.412410635268316e-05, Final Batch Loss: 2.7301872250973247e-05\n",
      "Epoch 3483, Loss: 0.00021770323655800894, Final Batch Loss: 0.00016859782044775784\n",
      "Epoch 3484, Loss: 3.59802033926826e-05, Final Batch Loss: 8.996061296784319e-06\n",
      "Epoch 3485, Loss: 0.00022478544269688427, Final Batch Loss: 0.00012027326738461852\n",
      "Epoch 3486, Loss: 5.015719125367468e-05, Final Batch Loss: 3.619753260863945e-05\n",
      "Epoch 3487, Loss: 0.00019670413530548103, Final Batch Loss: 0.0001757469290168956\n",
      "Epoch 3488, Loss: 0.00014928109521861188, Final Batch Loss: 4.2824973206734285e-05\n",
      "Epoch 3489, Loss: 0.000241959798586322, Final Batch Loss: 2.5317738618468866e-05\n",
      "Epoch 3490, Loss: 9.489713647781173e-05, Final Batch Loss: 1.4809303138463292e-05\n",
      "Epoch 3491, Loss: 5.487023918249179e-05, Final Batch Loss: 3.1795480026630685e-05\n",
      "Epoch 3492, Loss: 2.9807231840095483e-05, Final Batch Loss: 2.0672965547419153e-05\n",
      "Epoch 3493, Loss: 0.0012688540009548888, Final Batch Loss: 4.3078180169686675e-06\n",
      "Epoch 3494, Loss: 0.00012460691141313873, Final Batch Loss: 5.5812088248785585e-06\n",
      "Epoch 3495, Loss: 3.3728493690432515e-05, Final Batch Loss: 1.3705955097975675e-05\n",
      "Epoch 3496, Loss: 5.944222812104272e-05, Final Batch Loss: 1.1952201930398587e-05\n",
      "Epoch 3497, Loss: 7.492951385756896e-05, Final Batch Loss: 2.577063924036338e-06\n",
      "Epoch 3498, Loss: 6.017971827532165e-05, Final Batch Loss: 3.999959517386742e-05\n",
      "Epoch 3499, Loss: 1.9665145373437554e-05, Final Batch Loss: 3.1900890462566167e-07\n",
      "Epoch 3500, Loss: 4.790827051692759e-05, Final Batch Loss: 5.7359143283974845e-06\n",
      "Epoch 3501, Loss: 6.60494167732395e-05, Final Batch Loss: 2.947335588032729e-06\n",
      "Epoch 3502, Loss: 3.8915465665922966e-05, Final Batch Loss: 7.653309694433119e-06\n",
      "Epoch 3503, Loss: 8.010292822291376e-05, Final Batch Loss: 7.069752609822899e-05\n",
      "Epoch 3504, Loss: 2.630910512380069e-05, Final Batch Loss: 1.3477105312631465e-05\n",
      "Epoch 3505, Loss: 5.952829451416619e-05, Final Batch Loss: 4.4871070713270456e-05\n",
      "Epoch 3506, Loss: 0.00010118614318344044, Final Batch Loss: 1.4439004189625848e-05\n",
      "Epoch 3507, Loss: 1.1234057637921069e-05, Final Batch Loss: 7.11308530298993e-06\n",
      "Epoch 3508, Loss: 0.009935920003044885, Final Batch Loss: 0.00985401775687933\n",
      "Epoch 3509, Loss: 5.023119456382119e-06, Final Batch Loss: 2.00635827241058e-06\n",
      "Epoch 3510, Loss: 5.830811801388336e-05, Final Batch Loss: 5.59850777790416e-05\n",
      "Epoch 3511, Loss: 6.880011937937525e-06, Final Batch Loss: 7.312002026083064e-07\n",
      "Epoch 3512, Loss: 5.125163806951605e-05, Final Batch Loss: 2.685819345060736e-05\n",
      "Epoch 3513, Loss: 1.713467008812586e-05, Final Batch Loss: 1.0701125574996695e-05\n",
      "Epoch 3514, Loss: 4.6735030537092825e-05, Final Batch Loss: 4.5456192310666665e-05\n",
      "Epoch 3515, Loss: 1.4272686257754685e-05, Final Batch Loss: 5.5040022743924055e-06\n",
      "Epoch 3516, Loss: 3.468093564151786e-05, Final Batch Loss: 3.0503289963235147e-05\n",
      "Epoch 3517, Loss: 4.279503218640457e-05, Final Batch Loss: 2.553682406869484e-06\n",
      "Epoch 3518, Loss: 0.0002905342098529218, Final Batch Loss: 3.5726825444726273e-06\n",
      "Epoch 3519, Loss: 6.1019446548016276e-05, Final Batch Loss: 1.1729759535228368e-05\n",
      "Epoch 3520, Loss: 6.923516230017412e-05, Final Batch Loss: 4.80372182209976e-05\n",
      "Epoch 3521, Loss: 2.758483333309414e-05, Final Batch Loss: 1.0216263945039827e-05\n",
      "Epoch 3522, Loss: 2.6123958832613425e-05, Final Batch Loss: 4.322746917750919e-06\n",
      "Epoch 3523, Loss: 6.556079597430653e-06, Final Batch Loss: 2.305130465174443e-06\n",
      "Epoch 3524, Loss: 0.00010389304588898085, Final Batch Loss: 5.83519104111474e-05\n",
      "Epoch 3525, Loss: 6.311297283900785e-06, Final Batch Loss: 1.9601918666012352e-06\n",
      "Epoch 3526, Loss: 1.6184115111173014e-05, Final Batch Loss: 1.9684664493979653e-06\n",
      "Epoch 3527, Loss: 2.456365473335609e-05, Final Batch Loss: 6.357000529533252e-06\n",
      "Epoch 3528, Loss: 0.00060974872621955, Final Batch Loss: 3.825427938863868e-06\n",
      "Epoch 3529, Loss: 0.00010415516953798942, Final Batch Loss: 2.80956483038608e-05\n",
      "Epoch 3530, Loss: 1.617302450540592e-05, Final Batch Loss: 1.1747785720217507e-05\n",
      "Epoch 3531, Loss: 0.00019450875515758526, Final Batch Loss: 1.5502837413805537e-05\n",
      "Epoch 3532, Loss: 6.25309330644086e-05, Final Batch Loss: 2.179812508984469e-05\n",
      "Epoch 3533, Loss: 5.394518530010828e-05, Final Batch Loss: 4.991564492229372e-05\n",
      "Epoch 3534, Loss: 1.5453171954504796e-05, Final Batch Loss: 1.0938349532807479e-06\n",
      "Epoch 3535, Loss: 1.714260633889353e-05, Final Batch Loss: 2.5963181542465463e-06\n",
      "Epoch 3536, Loss: 2.0083141862414777e-05, Final Batch Loss: 1.3905908417655155e-05\n",
      "Epoch 3537, Loss: 3.7313849134079646e-05, Final Batch Loss: 3.290910171926953e-05\n",
      "Epoch 3538, Loss: 0.001191126684716437, Final Batch Loss: 8.42528315843083e-05\n",
      "Epoch 3539, Loss: 0.00012088342919014394, Final Batch Loss: 0.00010765687329694629\n",
      "Epoch 3540, Loss: 4.203464868623996e-06, Final Batch Loss: 9.049745131051168e-07\n",
      "Epoch 3541, Loss: 4.149101869188598e-06, Final Batch Loss: 3.0271205559984082e-06\n",
      "Epoch 3542, Loss: 6.274794441196718e-05, Final Batch Loss: 5.785122630186379e-05\n",
      "Epoch 3543, Loss: 5.472687917063013e-05, Final Batch Loss: 1.687600524746813e-05\n",
      "Epoch 3544, Loss: 0.0001659174295127741, Final Batch Loss: 1.342012456007069e-05\n",
      "Epoch 3545, Loss: 4.76055884064408e-05, Final Batch Loss: 3.125158400507644e-05\n",
      "Epoch 3546, Loss: 2.8630061251533334e-05, Final Batch Loss: 3.12355336973269e-06\n",
      "Epoch 3547, Loss: 1.368428365822183e-05, Final Batch Loss: 9.45104784477735e-06\n",
      "Epoch 3548, Loss: 7.129307778086513e-05, Final Batch Loss: 2.5566227122908458e-05\n",
      "Epoch 3549, Loss: 1.009191942102916e-05, Final Batch Loss: 3.8052482977946056e-06\n",
      "Epoch 3550, Loss: 1.2526984846772393e-05, Final Batch Loss: 6.110048616392305e-06\n",
      "Epoch 3551, Loss: 0.00012379256440908648, Final Batch Loss: 8.401727245654911e-05\n",
      "Epoch 3552, Loss: 0.0003420446391828591, Final Batch Loss: 2.3626615075045265e-05\n",
      "Epoch 3553, Loss: 9.087457783607533e-06, Final Batch Loss: 1.0208145795331802e-06\n",
      "Epoch 3554, Loss: 0.0001515835137979593, Final Batch Loss: 5.039535244577564e-05\n",
      "Epoch 3555, Loss: 5.634358558381791e-05, Final Batch Loss: 6.6181414695165586e-06\n",
      "Epoch 3556, Loss: 3.5642315083350695e-05, Final Batch Loss: 3.402110087336041e-05\n",
      "Epoch 3557, Loss: 0.00010849198224605061, Final Batch Loss: 4.0078219171846285e-05\n",
      "Epoch 3558, Loss: 6.885168886583415e-06, Final Batch Loss: 2.9354625894484343e-06\n",
      "Epoch 3559, Loss: 3.1884202144283336e-05, Final Batch Loss: 1.475701265007956e-05\n",
      "Epoch 3560, Loss: 0.0011680524075927678, Final Batch Loss: 0.0011580800637602806\n",
      "Epoch 3561, Loss: 2.209111221418425e-05, Final Batch Loss: 1.8384660052106483e-06\n",
      "Epoch 3562, Loss: 3.2187554097617976e-06, Final Batch Loss: 1.7234482356798253e-06\n",
      "Epoch 3563, Loss: 0.00016524639522685902, Final Batch Loss: 1.0410451977804769e-05\n",
      "Epoch 3564, Loss: 0.00024095496701193042, Final Batch Loss: 0.00018700996588449925\n",
      "Epoch 3565, Loss: 5.552393531615962e-06, Final Batch Loss: 3.056290097447345e-06\n",
      "Epoch 3566, Loss: 2.9644470487255603e-05, Final Batch Loss: 1.4501801160804462e-05\n",
      "Epoch 3567, Loss: 4.116126729059033e-05, Final Batch Loss: 2.2856125724501908e-05\n",
      "Epoch 3568, Loss: 2.0302340089983772e-05, Final Batch Loss: 1.3010833754378837e-05\n",
      "Epoch 3569, Loss: 0.00025538037880323827, Final Batch Loss: 0.00017145888705272228\n",
      "Epoch 3570, Loss: 5.659276894220966e-06, Final Batch Loss: 4.64792674392811e-06\n",
      "Epoch 3571, Loss: 0.0014334377319755731, Final Batch Loss: 0.0014256094582378864\n",
      "Epoch 3572, Loss: 2.6402456569485366e-05, Final Batch Loss: 2.1058474885649048e-05\n",
      "Epoch 3573, Loss: 5.316538999977638e-05, Final Batch Loss: 2.155662969016703e-06\n",
      "Epoch 3574, Loss: 6.144247720385465e-06, Final Batch Loss: 9.259577495868143e-07\n",
      "Epoch 3575, Loss: 1.8916794488177402e-05, Final Batch Loss: 1.2307663382671308e-05\n",
      "Epoch 3576, Loss: 0.001884687429992482, Final Batch Loss: 0.0018298357026651502\n",
      "Epoch 3577, Loss: 6.935722467460437e-05, Final Batch Loss: 4.913042175758164e-06\n",
      "Epoch 3578, Loss: 0.0008284468622150598, Final Batch Loss: 2.447033693897538e-06\n",
      "Epoch 3579, Loss: 2.0667497665272094e-05, Final Batch Loss: 8.32553268992342e-06\n",
      "Epoch 3580, Loss: 5.353781148187409e-06, Final Batch Loss: 1.4816247357885004e-06\n",
      "Epoch 3581, Loss: 7.629217975591018e-06, Final Batch Loss: 6.359972303471295e-06\n",
      "Epoch 3582, Loss: 9.361510751659807e-05, Final Batch Loss: 9.124254574999213e-05\n",
      "Epoch 3583, Loss: 3.2517048282443284e-05, Final Batch Loss: 3.198681952198967e-05\n",
      "Epoch 3584, Loss: 1.674813449881185e-05, Final Batch Loss: 1.6178799342014827e-05\n",
      "Epoch 3585, Loss: 0.0002613117098917428, Final Batch Loss: 4.6996860874060076e-06\n",
      "Epoch 3586, Loss: 0.00020852575050867017, Final Batch Loss: 1.8627537201609812e-06\n",
      "Epoch 3587, Loss: 6.396983621925756e-06, Final Batch Loss: 4.515095952228876e-06\n",
      "Epoch 3588, Loss: 3.946658216591459e-05, Final Batch Loss: 1.2671334843616933e-05\n",
      "Epoch 3589, Loss: 8.184972102753818e-06, Final Batch Loss: 2.3629563656868413e-06\n",
      "Epoch 3590, Loss: 1.5586557765345788e-05, Final Batch Loss: 5.856452389707556e-06\n",
      "Epoch 3591, Loss: 3.4019767326753936e-05, Final Batch Loss: 3.5943173770647263e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3592, Loss: 1.3666204267792637e-05, Final Batch Loss: 6.734291673637927e-06\n",
      "Epoch 3593, Loss: 0.0004594142055793782, Final Batch Loss: 5.52329311176436e-06\n",
      "Epoch 3594, Loss: 4.117088155908277e-05, Final Batch Loss: 1.3478115761245135e-05\n",
      "Epoch 3595, Loss: 2.0530518668238074e-05, Final Batch Loss: 9.590749868948478e-06\n",
      "Epoch 3596, Loss: 3.242190734908945e-05, Final Batch Loss: 3.076026769122109e-05\n",
      "Epoch 3597, Loss: 0.002319761098988238, Final Batch Loss: 0.0023036242928355932\n",
      "Epoch 3598, Loss: 4.477374261568912e-06, Final Batch Loss: 3.822688086074777e-06\n",
      "Epoch 3599, Loss: 2.0176552084194554e-05, Final Batch Loss: 1.830844848882407e-05\n",
      "Epoch 3600, Loss: 7.458308118657442e-06, Final Batch Loss: 4.598155101120938e-06\n",
      "Epoch 3601, Loss: 2.175422378059011e-05, Final Batch Loss: 1.310568222834263e-05\n",
      "Epoch 3602, Loss: 0.0032765047944849357, Final Batch Loss: 0.00012733972107525915\n",
      "Epoch 3603, Loss: 1.5303804360655704e-05, Final Batch Loss: 2.8626877224269265e-07\n",
      "Epoch 3604, Loss: 5.260802822704136e-06, Final Batch Loss: 3.769885097426595e-06\n",
      "Epoch 3605, Loss: 9.711488473840291e-05, Final Batch Loss: 6.546551048813853e-06\n",
      "Epoch 3606, Loss: 0.0001320487094744749, Final Batch Loss: 3.6855958569503855e-06\n",
      "Epoch 3607, Loss: 1.1399011555113248e-05, Final Batch Loss: 8.076944141066633e-06\n",
      "Epoch 3608, Loss: 1.419378031641827e-05, Final Batch Loss: 5.110096481075743e-06\n",
      "Epoch 3609, Loss: 0.0002642252020450542, Final Batch Loss: 0.00025816666311584413\n",
      "Epoch 3610, Loss: 1.248174442025629e-06, Final Batch Loss: 7.093681233527604e-07\n",
      "Epoch 3611, Loss: 5.33023439857061e-05, Final Batch Loss: 9.069018233276438e-06\n",
      "Epoch 3612, Loss: 1.941659002113738e-05, Final Batch Loss: 1.5222262845782097e-05\n",
      "Epoch 3613, Loss: 3.0559681817976525e-05, Final Batch Loss: 8.033689482545014e-07\n",
      "Epoch 3614, Loss: 0.00010799901065183803, Final Batch Loss: 0.00010742681479314342\n",
      "Epoch 3615, Loss: 7.305978579097427e-05, Final Batch Loss: 6.563570786966011e-05\n",
      "Epoch 3616, Loss: 0.00010246189935969596, Final Batch Loss: 3.1025790576677537e-06\n",
      "Epoch 3617, Loss: 2.758069422270637e-05, Final Batch Loss: 1.9027818780159578e-05\n",
      "Epoch 3618, Loss: 5.149871981302567e-06, Final Batch Loss: 3.7895470086368732e-06\n",
      "Epoch 3619, Loss: 7.0038659032434225e-06, Final Batch Loss: 4.604768037097529e-06\n",
      "Epoch 3620, Loss: 1.8883393408941629e-06, Final Batch Loss: 4.407348228596675e-07\n",
      "Epoch 3621, Loss: 1.1924634833349046e-05, Final Batch Loss: 3.7609393643833755e-07\n",
      "Epoch 3622, Loss: 1.4672580618935172e-05, Final Batch Loss: 1.224259722221177e-05\n",
      "Epoch 3623, Loss: 6.615904464979394e-05, Final Batch Loss: 4.978199967808905e-07\n",
      "Epoch 3624, Loss: 1.7540791759529384e-05, Final Batch Loss: 4.311339125706581e-06\n",
      "Epoch 3625, Loss: 5.295084918088833e-06, Final Batch Loss: 3.685385649987438e-07\n",
      "Epoch 3626, Loss: 8.409753627347527e-05, Final Batch Loss: 7.940082286950201e-05\n",
      "Epoch 3627, Loss: 1.870504843282106e-05, Final Batch Loss: 1.5943733160384e-05\n",
      "Epoch 3628, Loss: 0.00010023037179962557, Final Batch Loss: 9.798083192436025e-05\n",
      "Epoch 3629, Loss: 4.992451493990302e-06, Final Batch Loss: 3.483891930500249e-07\n",
      "Epoch 3630, Loss: 0.004152186564169824, Final Batch Loss: 0.0024512414820492268\n",
      "Epoch 3631, Loss: 0.00024685225707798963, Final Batch Loss: 1.525583411421394e-05\n",
      "Epoch 3632, Loss: 5.872871179235517e-05, Final Batch Loss: 5.773310112999752e-05\n",
      "Epoch 3633, Loss: 2.6442563012096798e-05, Final Batch Loss: 2.0983316062483937e-05\n",
      "Epoch 3634, Loss: 0.00023629014356174594, Final Batch Loss: 1.423759727003926e-06\n",
      "Epoch 3635, Loss: 0.0002399804798187688, Final Batch Loss: 0.00016754471289459616\n",
      "Epoch 3636, Loss: 9.639301424613222e-06, Final Batch Loss: 8.637966857349966e-06\n",
      "Epoch 3637, Loss: 5.845391933689825e-05, Final Batch Loss: 1.0870629921555519e-05\n",
      "Epoch 3638, Loss: 2.3651708858096754e-07, Final Batch Loss: 8.059198108867349e-08\n",
      "Epoch 3639, Loss: 0.0025836376606207523, Final Batch Loss: 6.380158197316632e-07\n",
      "Epoch 3640, Loss: 2.3279312813428987e-05, Final Batch Loss: 2.2767202608520165e-05\n",
      "Epoch 3641, Loss: 0.00011018452096323017, Final Batch Loss: 0.00010823767661349848\n",
      "Epoch 3642, Loss: 9.37385311772232e-06, Final Batch Loss: 4.354435532150092e-06\n",
      "Epoch 3643, Loss: 2.6154593797400594e-06, Final Batch Loss: 1.0862889894269756e-06\n",
      "Epoch 3644, Loss: 0.00013220881737652235, Final Batch Loss: 7.550071313744411e-05\n",
      "Epoch 3645, Loss: 8.04251021691016e-06, Final Batch Loss: 5.742876965086907e-06\n",
      "Epoch 3646, Loss: 1.6197442676002538e-06, Final Batch Loss: 1.2239720490470063e-06\n",
      "Epoch 3647, Loss: 1.976639305212302e-05, Final Batch Loss: 6.1474329413613304e-06\n",
      "Epoch 3648, Loss: 2.1609984742099186e-05, Final Batch Loss: 4.173248726146994e-06\n",
      "Epoch 3649, Loss: 2.415209223727288e-06, Final Batch Loss: 1.1945556934733759e-06\n",
      "Epoch 3650, Loss: 3.716125593200559e-05, Final Batch Loss: 8.965135748439934e-06\n",
      "Epoch 3651, Loss: 2.044830338832071e-06, Final Batch Loss: 1.8107048163074069e-06\n",
      "Epoch 3652, Loss: 2.0269998003641376e-05, Final Batch Loss: 4.815314696315909e-06\n",
      "Epoch 3653, Loss: 0.0001417522580595687, Final Batch Loss: 9.208041592501104e-05\n",
      "Epoch 3654, Loss: 7.617098640366748e-05, Final Batch Loss: 7.345989433815703e-05\n",
      "Epoch 3655, Loss: 1.2588311847139266e-05, Final Batch Loss: 1.39518692776619e-06\n",
      "Epoch 3656, Loss: 4.887016439170111e-05, Final Batch Loss: 2.30530586122768e-05\n",
      "Epoch 3657, Loss: 8.390249689682605e-06, Final Batch Loss: 2.434545365304075e-07\n",
      "Epoch 3658, Loss: 7.288396545845899e-06, Final Batch Loss: 3.012589559148182e-06\n",
      "Epoch 3659, Loss: 2.30589585044072e-05, Final Batch Loss: 6.96309234626824e-06\n",
      "Epoch 3660, Loss: 3.647883158919285e-05, Final Batch Loss: 5.287678050081013e-06\n",
      "Epoch 3661, Loss: 1.3240241287348908e-05, Final Batch Loss: 6.287821179284947e-07\n",
      "Epoch 3662, Loss: 1.2558420962704986e-05, Final Batch Loss: 1.1725886906788219e-05\n",
      "Epoch 3663, Loss: 6.103522355260793e-05, Final Batch Loss: 5.649590821121819e-05\n",
      "Epoch 3664, Loss: 1.5519349744863575e-05, Final Batch Loss: 9.304510967922397e-06\n",
      "Epoch 3665, Loss: 2.464107240029989e-06, Final Batch Loss: 8.419876280640892e-07\n",
      "Epoch 3666, Loss: 3.748840663320152e-05, Final Batch Loss: 2.7255629902356304e-05\n",
      "Epoch 3667, Loss: 3.219818722755008e-06, Final Batch Loss: 1.2415854371283785e-06\n",
      "Epoch 3668, Loss: 8.99495853445842e-06, Final Batch Loss: 4.041350166517077e-06\n",
      "Epoch 3669, Loss: 1.814933375499095e-05, Final Batch Loss: 4.4744911065208726e-07\n",
      "Epoch 3670, Loss: 5.511066547114751e-05, Final Batch Loss: 3.0177884582371917e-06\n",
      "Epoch 3671, Loss: 1.0725495712904376e-05, Final Batch Loss: 2.049107251878013e-06\n",
      "Epoch 3672, Loss: 0.000722958953701891, Final Batch Loss: 3.977121377829462e-05\n",
      "Epoch 3673, Loss: 1.7504135712442803e-05, Final Batch Loss: 1.4021520655660424e-05\n",
      "Epoch 3674, Loss: 0.000326662484120277, Final Batch Loss: 9.486361562949241e-08\n",
      "Epoch 3675, Loss: 3.706240590872767e-06, Final Batch Loss: 2.110371724484139e-06\n",
      "Epoch 3676, Loss: 2.9361156521190424e-05, Final Batch Loss: 2.271500306960661e-06\n",
      "Epoch 3677, Loss: 5.5723381592542864e-05, Final Batch Loss: 1.1207030183868483e-06\n",
      "Epoch 3678, Loss: 4.007607526546053e-05, Final Batch Loss: 3.6126973554928554e-06\n",
      "Epoch 3679, Loss: 1.376469882075071e-06, Final Batch Loss: 1.200484263108592e-07\n",
      "Epoch 3680, Loss: 2.2699344413013023e-06, Final Batch Loss: 5.062086643192742e-07\n",
      "Epoch 3681, Loss: 1.3509538121070364e-05, Final Batch Loss: 2.4990106339828344e-06\n",
      "Epoch 3682, Loss: 9.008560937218135e-06, Final Batch Loss: 1.6101012079161592e-06\n",
      "Epoch 3683, Loss: 0.00047840391562203877, Final Batch Loss: 0.00045854743802919984\n",
      "Epoch 3684, Loss: 2.4106674345603096e-06, Final Batch Loss: 1.7149998257082189e-06\n",
      "Epoch 3685, Loss: 4.271824423085491e-06, Final Batch Loss: 7.085210427248967e-07\n",
      "Epoch 3686, Loss: 0.00023988755555137686, Final Batch Loss: 0.00023931059695314616\n",
      "Epoch 3687, Loss: 3.2728713676988264e-05, Final Batch Loss: 2.9643390007549897e-05\n",
      "Epoch 3688, Loss: 2.0101571180930478e-06, Final Batch Loss: 2.39257587963948e-07\n",
      "Epoch 3689, Loss: 1.3454649376853922e-06, Final Batch Loss: 8.915210401028162e-07\n",
      "Epoch 3690, Loss: 4.613519422491663e-06, Final Batch Loss: 2.8617203042813344e-06\n",
      "Epoch 3691, Loss: 3.366571334595392e-06, Final Batch Loss: 2.1575131370354939e-07\n",
      "Epoch 3692, Loss: 0.002761598057759329, Final Batch Loss: 8.932181572163245e-07\n",
      "Epoch 3693, Loss: 2.960095002890739e-06, Final Batch Loss: 1.3842567341271206e-06\n",
      "Epoch 3694, Loss: 1.829665673369618e-05, Final Batch Loss: 1.0241895154194935e-07\n",
      "Epoch 3695, Loss: 4.199890099698678e-06, Final Batch Loss: 1.8644823285285383e-06\n",
      "Epoch 3696, Loss: 4.004656148026697e-06, Final Batch Loss: 1.5185958091024077e-06\n",
      "Epoch 3697, Loss: 2.662735369085567e-06, Final Batch Loss: 1.2919666687594145e-06\n",
      "Epoch 3698, Loss: 7.658491767870146e-06, Final Batch Loss: 4.552902737486875e-06\n",
      "Epoch 3699, Loss: 3.4002769666585664e-06, Final Batch Loss: 2.6769293981487863e-06\n",
      "Epoch 3700, Loss: 1.4394450317922747e-05, Final Batch Loss: 8.53446817927761e-06\n",
      "Epoch 3701, Loss: 2.2659280830339412e-05, Final Batch Loss: 1.0728115285019157e-06\n",
      "Epoch 3702, Loss: 3.826274394214124e-05, Final Batch Loss: 1.5093900174178998e-06\n",
      "Epoch 3703, Loss: 3.970248539530985e-05, Final Batch Loss: 3.080934618537867e-07\n",
      "Epoch 3704, Loss: 6.318875421129633e-06, Final Batch Loss: 4.494126642384799e-06\n",
      "Epoch 3705, Loss: 0.001062685543729458, Final Batch Loss: 7.939212082419544e-06\n",
      "Epoch 3706, Loss: 1.8309928819348897e-05, Final Batch Loss: 1.808963315852452e-05\n",
      "Epoch 3707, Loss: 8.306261179313879e-06, Final Batch Loss: 6.2441054069495294e-06\n",
      "Epoch 3708, Loss: 7.758572564853239e-06, Final Batch Loss: 1.5773214272485347e-06\n",
      "Epoch 3709, Loss: 4.317158243338781e-06, Final Batch Loss: 3.5523512451618444e-06\n",
      "Epoch 3710, Loss: 0.00020914795481985493, Final Batch Loss: 5.16287627760903e-07\n",
      "Epoch 3711, Loss: 0.0017792866565287113, Final Batch Loss: 0.0008658170700073242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3712, Loss: 0.00010274473947902152, Final Batch Loss: 3.541452088029473e-06\n",
      "Epoch 3713, Loss: 1.6899230388389697e-06, Final Batch Loss: 1.3599533303931821e-06\n",
      "Epoch 3714, Loss: 0.0001231290475516289, Final Batch Loss: 0.00011634017573669553\n",
      "Epoch 3715, Loss: 4.493608298616891e-05, Final Batch Loss: 4.253585575497709e-05\n",
      "Epoch 3716, Loss: 2.0460875873595796e-06, Final Batch Loss: 3.5678655763149436e-07\n",
      "Epoch 3717, Loss: 0.0001589313251315616, Final Batch Loss: 5.3797775763086975e-06\n",
      "Epoch 3718, Loss: 4.8068226760733523e-05, Final Batch Loss: 3.492163386908942e-06\n",
      "Epoch 3719, Loss: 0.0005237595954667995, Final Batch Loss: 0.0005223768530413508\n",
      "Epoch 3720, Loss: 8.541013357898919e-06, Final Batch Loss: 3.4350000532867853e-06\n",
      "Epoch 3721, Loss: 4.5077051254338585e-05, Final Batch Loss: 1.5871208233875223e-05\n",
      "Epoch 3722, Loss: 6.245625627343543e-05, Final Batch Loss: 4.856856321566738e-05\n",
      "Epoch 3723, Loss: 5.9819087027790374e-05, Final Batch Loss: 5.771798896603286e-05\n",
      "Epoch 3724, Loss: 9.775963917491026e-06, Final Batch Loss: 8.619191248726565e-06\n",
      "Epoch 3725, Loss: 0.00018187856403528713, Final Batch Loss: 0.000173053631442599\n",
      "Epoch 3726, Loss: 0.00010508716832191567, Final Batch Loss: 3.706914412759943e-06\n",
      "Epoch 3727, Loss: 1.2054009516759834e-05, Final Batch Loss: 6.455699121943326e-07\n",
      "Epoch 3728, Loss: 4.860607623413671e-05, Final Batch Loss: 2.463051350787282e-05\n",
      "Epoch 3729, Loss: 3.149105214106385e-05, Final Batch Loss: 1.979229818971362e-05\n",
      "Epoch 3730, Loss: 8.943782859205385e-06, Final Batch Loss: 3.6800390716962283e-06\n",
      "Epoch 3731, Loss: 1.0654732705006609e-05, Final Batch Loss: 2.039853370661149e-06\n",
      "Epoch 3732, Loss: 7.635786005266709e-05, Final Batch Loss: 4.996526513423305e-06\n",
      "Epoch 3733, Loss: 8.534259222869878e-06, Final Batch Loss: 1.5135576632019365e-06\n",
      "Epoch 3734, Loss: 0.00010356982693338068, Final Batch Loss: 9.831380884861574e-05\n",
      "Epoch 3735, Loss: 2.6230250568914926e-05, Final Batch Loss: 4.861346951656742e-06\n",
      "Epoch 3736, Loss: 9.873146439076663e-06, Final Batch Loss: 9.29903853830183e-06\n",
      "Epoch 3737, Loss: 1.676225565461209e-05, Final Batch Loss: 8.827081728668418e-06\n",
      "Epoch 3738, Loss: 0.00876893381064292, Final Batch Loss: 0.00012019927089568228\n",
      "Epoch 3739, Loss: 5.491761157827568e-06, Final Batch Loss: 3.253775958000915e-06\n",
      "Epoch 3740, Loss: 1.3392573237069882e-05, Final Batch Loss: 6.179522642923985e-06\n",
      "Epoch 3741, Loss: 0.010169953774209262, Final Batch Loss: 4.877480819232005e-07\n",
      "Epoch 3742, Loss: 6.829880885561579e-05, Final Batch Loss: 4.1775770114327315e-06\n",
      "Epoch 3743, Loss: 4.917707792628789e-05, Final Batch Loss: 4.952348717779387e-06\n",
      "Epoch 3744, Loss: 8.050767974054907e-06, Final Batch Loss: 4.752857876155758e-06\n",
      "Epoch 3745, Loss: 9.580734064229546e-05, Final Batch Loss: 9.492377284914255e-05\n",
      "Epoch 3746, Loss: 1.9513891857059207e-05, Final Batch Loss: 2.417755240458064e-07\n",
      "Epoch 3747, Loss: 0.00044705923664878355, Final Batch Loss: 0.0004410715773701668\n",
      "Epoch 3748, Loss: 0.019190877964319952, Final Batch Loss: 0.019186217337846756\n",
      "Epoch 3749, Loss: 1.3382205224843347e-05, Final Batch Loss: 1.0950519936159253e-05\n",
      "Epoch 3750, Loss: 1.5095239632501034e-05, Final Batch Loss: 1.2665876056416892e-05\n",
      "Epoch 3751, Loss: 1.96872348396937e-05, Final Batch Loss: 1.1828393553514616e-06\n",
      "Epoch 3752, Loss: 8.92165262484923e-05, Final Batch Loss: 1.8071383237838745e-05\n",
      "Epoch 3753, Loss: 0.0007091146458151343, Final Batch Loss: 4.782158157468075e-06\n",
      "Epoch 3754, Loss: 5.807512570754625e-05, Final Batch Loss: 8.11243080534041e-06\n",
      "Epoch 3755, Loss: 0.0023191014042822644, Final Batch Loss: 0.0001709413918433711\n",
      "Epoch 3756, Loss: 0.010055476916022599, Final Batch Loss: 0.009016282856464386\n",
      "Epoch 3757, Loss: 2.0481051137721806e-05, Final Batch Loss: 1.7175351558762486e-06\n",
      "Epoch 3758, Loss: 4.5305047251531505e-06, Final Batch Loss: 3.5797042983176652e-06\n",
      "Epoch 3759, Loss: 0.007648454936315829, Final Batch Loss: 0.007641626987606287\n",
      "Epoch 3760, Loss: 1.669539778959006e-05, Final Batch Loss: 8.596352927270345e-06\n",
      "Epoch 3761, Loss: 0.002793084377856303, Final Batch Loss: 7.597398621328466e-07\n",
      "Epoch 3762, Loss: 1.5040525795484427e-05, Final Batch Loss: 8.994536074169446e-06\n",
      "Epoch 3763, Loss: 0.00011921836630790494, Final Batch Loss: 6.289945304160938e-06\n",
      "Epoch 3764, Loss: 2.4810602781144553e-05, Final Batch Loss: 8.562803941458696e-07\n",
      "Epoch 3765, Loss: 0.06208683013164773, Final Batch Loss: 0.06207975745201111\n",
      "Epoch 3766, Loss: 0.000543967345947749, Final Batch Loss: 0.0005421768873929977\n",
      "Epoch 3767, Loss: 8.140381487464765e-05, Final Batch Loss: 7.531432493124157e-05\n",
      "Epoch 3768, Loss: 3.6922354411217384e-05, Final Batch Loss: 2.01565617317101e-05\n",
      "Epoch 3769, Loss: 0.0007737026680842973, Final Batch Loss: 3.2032236049417406e-05\n",
      "Epoch 3770, Loss: 2.187108543694194e-05, Final Batch Loss: 1.8937329514301382e-05\n",
      "Epoch 3771, Loss: 5.435432649392169e-05, Final Batch Loss: 2.9337730666156858e-05\n",
      "Epoch 3772, Loss: 0.00012773378693964332, Final Batch Loss: 0.00010852479317691177\n",
      "Epoch 3773, Loss: 0.0021162243356229737, Final Batch Loss: 0.002085366053506732\n",
      "Epoch 3774, Loss: 0.0061267740675248206, Final Batch Loss: 0.0006475225673057139\n",
      "Epoch 3775, Loss: 0.00011849965449073352, Final Batch Loss: 8.000042726052925e-06\n",
      "Epoch 3776, Loss: 2.618528833409073e-05, Final Batch Loss: 1.0648010174918454e-05\n",
      "Epoch 3777, Loss: 0.0002836388775904197, Final Batch Loss: 0.00026488586445339024\n",
      "Epoch 3778, Loss: 3.689729419420473e-05, Final Batch Loss: 1.6190400856430642e-05\n",
      "Epoch 3779, Loss: 2.516850145184435e-05, Final Batch Loss: 1.0430469956190791e-05\n",
      "Epoch 3780, Loss: 0.03545401315750496, Final Batch Loss: 0.03544575721025467\n",
      "Epoch 3781, Loss: 0.00016939243914748658, Final Batch Loss: 2.364508418395417e-06\n",
      "Epoch 3782, Loss: 4.160823095844535e-05, Final Batch Loss: 3.9098351408028975e-05\n",
      "Epoch 3783, Loss: 3.054792068724055e-05, Final Batch Loss: 9.865658284979872e-06\n",
      "Epoch 3784, Loss: 0.00012479643373808358, Final Batch Loss: 8.225690180552192e-06\n",
      "Epoch 3785, Loss: 0.0005020473026888794, Final Batch Loss: 0.0004924254608340561\n",
      "Epoch 3786, Loss: 4.484391683945432e-05, Final Batch Loss: 1.5193143553915434e-05\n",
      "Epoch 3787, Loss: 1.5868041145949974e-05, Final Batch Loss: 3.2503637612535385e-06\n",
      "Epoch 3788, Loss: 0.0022494404101962573, Final Batch Loss: 6.469664185715374e-06\n",
      "Epoch 3789, Loss: 1.6655898434692062e-05, Final Batch Loss: 7.259851372509729e-06\n",
      "Epoch 3790, Loss: 7.155584899010137e-05, Final Batch Loss: 1.0905059752985835e-05\n",
      "Epoch 3791, Loss: 1.3550003359341645e-05, Final Batch Loss: 1.2560592949739657e-05\n",
      "Epoch 3792, Loss: 1.8011864995060023e-05, Final Batch Loss: 8.036511644604616e-06\n",
      "Epoch 3793, Loss: 0.0010348455671191914, Final Batch Loss: 1.4159913916955702e-05\n",
      "Epoch 3794, Loss: 1.0102260603161994e-05, Final Batch Loss: 4.100304067833349e-06\n",
      "Epoch 3795, Loss: 2.747546432146919e-05, Final Batch Loss: 2.0392231817822903e-05\n",
      "Epoch 3796, Loss: 0.001027518856972165, Final Batch Loss: 1.4633146747655701e-05\n",
      "Epoch 3797, Loss: 2.9668018214579206e-05, Final Batch Loss: 1.8726332200458273e-05\n",
      "Epoch 3798, Loss: 0.008280910839175704, Final Batch Loss: 2.7383759970689425e-06\n",
      "Epoch 3799, Loss: 2.8336455670796568e-05, Final Batch Loss: 2.1923848180449568e-05\n",
      "Epoch 3800, Loss: 1.60505628628016e-05, Final Batch Loss: 4.874581918556942e-06\n",
      "Epoch 3801, Loss: 0.0002893645478252438, Final Batch Loss: 0.00028017364093102515\n",
      "Epoch 3802, Loss: 4.361443643574603e-05, Final Batch Loss: 2.0004852558486164e-05\n",
      "Epoch 3803, Loss: 0.00018808746472132043, Final Batch Loss: 2.8155795916973148e-06\n",
      "Epoch 3804, Loss: 0.0054811426907690475, Final Batch Loss: 0.005466442089527845\n",
      "Epoch 3805, Loss: 5.665221397066489e-05, Final Batch Loss: 1.2000571587122977e-05\n",
      "Epoch 3806, Loss: 2.28002572839614e-05, Final Batch Loss: 1.1274918506387621e-05\n",
      "Epoch 3807, Loss: 1.789172165445052e-05, Final Batch Loss: 4.2976244003511965e-06\n",
      "Epoch 3808, Loss: 0.0002899135943152942, Final Batch Loss: 4.622247797669843e-05\n",
      "Epoch 3809, Loss: 6.982294598856242e-05, Final Batch Loss: 6.185314123285934e-05\n",
      "Epoch 3810, Loss: 4.8596184569760226e-05, Final Batch Loss: 6.9858997449046e-06\n",
      "Epoch 3811, Loss: 0.00017542304703965783, Final Batch Loss: 7.309807551791891e-05\n",
      "Epoch 3812, Loss: 4.907154288957827e-05, Final Batch Loss: 1.2393611541483551e-05\n",
      "Epoch 3813, Loss: 0.00010884336734306999, Final Batch Loss: 8.105282176984474e-06\n",
      "Epoch 3814, Loss: 6.609236015719944e-05, Final Batch Loss: 6.171064160298556e-05\n",
      "Epoch 3815, Loss: 1.0487603276487789e-05, Final Batch Loss: 1.606783143870416e-06\n",
      "Epoch 3816, Loss: 7.49017381167505e-05, Final Batch Loss: 5.744726877310313e-05\n",
      "Epoch 3817, Loss: 2.5628030471125385e-05, Final Batch Loss: 1.8726126654655673e-05\n",
      "Epoch 3818, Loss: 0.00020271627727197483, Final Batch Loss: 9.808198228711262e-05\n",
      "Epoch 3819, Loss: 1.5193704712146427e-05, Final Batch Loss: 3.350744918861892e-06\n",
      "Epoch 3820, Loss: 0.0001732687242110842, Final Batch Loss: 0.00016932166181504726\n",
      "Epoch 3821, Loss: 0.0001234987903444562, Final Batch Loss: 0.00010978955106111243\n",
      "Epoch 3822, Loss: 2.6302508558728732e-05, Final Batch Loss: 7.999009540071711e-06\n",
      "Epoch 3823, Loss: 9.163849426840898e-05, Final Batch Loss: 8.654488920001313e-05\n",
      "Epoch 3824, Loss: 0.04498505291894617, Final Batch Loss: 5.655711447616341e-06\n",
      "Epoch 3825, Loss: 0.0038479368877233355, Final Batch Loss: 8.27854728413513e-06\n",
      "Epoch 3826, Loss: 5.4097023166832514e-05, Final Batch Loss: 2.8226862923474982e-05\n",
      "Epoch 3827, Loss: 0.0002048459864454344, Final Batch Loss: 0.00012467488704714924\n",
      "Epoch 3828, Loss: 4.7524240471830126e-05, Final Batch Loss: 8.989066373032983e-06\n",
      "Epoch 3829, Loss: 4.4673809497908223e-05, Final Batch Loss: 3.552920315996744e-05\n",
      "Epoch 3830, Loss: 2.792029067677504e-05, Final Batch Loss: 2.064227601294988e-06\n",
      "Epoch 3831, Loss: 1.549359967611963e-05, Final Batch Loss: 1.8316623027203605e-06\n",
      "Epoch 3832, Loss: 6.746131475665607e-05, Final Batch Loss: 3.517707227729261e-05\n",
      "Epoch 3833, Loss: 0.0001201712220790796, Final Batch Loss: 4.0892395190894604e-05\n",
      "Epoch 3834, Loss: 3.108829855591466e-05, Final Batch Loss: 3.495287955956883e-06\n",
      "Epoch 3835, Loss: 0.0003983087226515636, Final Batch Loss: 0.0002478134701959789\n",
      "Epoch 3836, Loss: 0.0001910000737552764, Final Batch Loss: 0.00016135723853949457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3837, Loss: 1.4060446574148955e-05, Final Batch Loss: 4.277199423086131e-06\n",
      "Epoch 3838, Loss: 9.618198600946926e-05, Final Batch Loss: 2.316149402759038e-05\n",
      "Epoch 3839, Loss: 0.00029239542527648155, Final Batch Loss: 0.00028083514189347625\n",
      "Epoch 3840, Loss: 1.4715315955982078e-05, Final Batch Loss: 6.302371730271261e-06\n",
      "Epoch 3841, Loss: 0.00014609844220103696, Final Batch Loss: 8.305034134536982e-05\n",
      "Epoch 3842, Loss: 0.0005536922253668308, Final Batch Loss: 0.0002686707302927971\n",
      "Epoch 3843, Loss: 1.4247678336687386e-05, Final Batch Loss: 4.7832490963628516e-06\n",
      "Epoch 3844, Loss: 6.540549475175794e-05, Final Batch Loss: 5.709880861104466e-05\n",
      "Epoch 3845, Loss: 4.5408556616166607e-05, Final Batch Loss: 1.7078486052923836e-05\n",
      "Epoch 3846, Loss: 2.3716258965578163e-05, Final Batch Loss: 1.776078534021508e-05\n",
      "Epoch 3847, Loss: 0.00012883171075372957, Final Batch Loss: 4.804590207641013e-05\n",
      "Epoch 3848, Loss: 2.9378465569607215e-05, Final Batch Loss: 2.927230980276363e-06\n",
      "Epoch 3849, Loss: 6.354798097163439e-05, Final Batch Loss: 3.9317746995948255e-05\n",
      "Epoch 3850, Loss: 0.0002726280317801866, Final Batch Loss: 1.1526189155119937e-05\n",
      "Epoch 3851, Loss: 0.00010300818394171074, Final Batch Loss: 6.668737478321418e-05\n",
      "Epoch 3852, Loss: 4.8500177399546374e-05, Final Batch Loss: 1.471171071898425e-05\n",
      "Epoch 3853, Loss: 9.197939743899042e-05, Final Batch Loss: 5.106500793772284e-06\n",
      "Epoch 3854, Loss: 7.763406301819487e-06, Final Batch Loss: 5.132331352797337e-06\n",
      "Epoch 3855, Loss: 0.0002253424536320381, Final Batch Loss: 0.00011304228246444836\n",
      "Epoch 3856, Loss: 0.000719043736353342, Final Batch Loss: 9.223488632414956e-06\n",
      "Epoch 3857, Loss: 0.00028112461950513534, Final Batch Loss: 0.0002407743304502219\n",
      "Epoch 3858, Loss: 3.9764684061083244e-05, Final Batch Loss: 4.318528681324096e-06\n",
      "Epoch 3859, Loss: 0.00011425492630223744, Final Batch Loss: 2.2416377760237083e-05\n",
      "Epoch 3860, Loss: 0.002383993713010568, Final Batch Loss: 7.464690861525014e-05\n",
      "Epoch 3861, Loss: 2.2147704385133693e-05, Final Batch Loss: 1.799239544197917e-05\n",
      "Epoch 3862, Loss: 0.0001212857312111737, Final Batch Loss: 2.172571612391039e-06\n",
      "Epoch 3863, Loss: 7.2597184953338e-05, Final Batch Loss: 6.0510723415063694e-05\n",
      "Epoch 3864, Loss: 1.1692410680552712e-05, Final Batch Loss: 5.8221366998623125e-06\n",
      "Epoch 3865, Loss: 0.010218563719035956, Final Batch Loss: 0.010217200964689255\n",
      "Epoch 3866, Loss: 1.131921453634277e-05, Final Batch Loss: 4.352020368969534e-06\n",
      "Epoch 3867, Loss: 0.004941575647990248, Final Batch Loss: 3.6456153793551493e-06\n",
      "Epoch 3868, Loss: 0.00021982840553391725, Final Batch Loss: 0.00018514970724936575\n",
      "Epoch 3869, Loss: 2.6293805149180116e-05, Final Batch Loss: 2.3516346118412912e-05\n",
      "Epoch 3870, Loss: 5.891577893635258e-05, Final Batch Loss: 1.9710285414475948e-05\n",
      "Epoch 3871, Loss: 1.7001115793391364e-05, Final Batch Loss: 5.073756710771704e-06\n",
      "Epoch 3872, Loss: 4.997028190700803e-05, Final Batch Loss: 2.089694135065656e-05\n",
      "Epoch 3873, Loss: 0.00012302699519750604, Final Batch Loss: 2.5981969429267338e-06\n",
      "Epoch 3874, Loss: 0.0005449374853014888, Final Batch Loss: 5.719933596992632e-06\n",
      "Epoch 3875, Loss: 7.787742742948467e-05, Final Batch Loss: 8.706404514668975e-06\n",
      "Epoch 3876, Loss: 6.59566535432532e-05, Final Batch Loss: 5.9858462009287905e-06\n",
      "Epoch 3877, Loss: 0.00010244429881822725, Final Batch Loss: 3.3896810691658175e-06\n",
      "Epoch 3878, Loss: 0.0005507977239176398, Final Batch Loss: 0.000542929396033287\n",
      "Epoch 3879, Loss: 0.0003028960127267055, Final Batch Loss: 0.0002534262603148818\n",
      "Epoch 3880, Loss: 0.00011147709301440045, Final Batch Loss: 6.114562711445615e-05\n",
      "Epoch 3881, Loss: 0.0009201787243000581, Final Batch Loss: 1.0393217053206172e-05\n",
      "Epoch 3882, Loss: 0.0005050500276411185, Final Batch Loss: 0.00047494444879703224\n",
      "Epoch 3883, Loss: 0.00010179767377849203, Final Batch Loss: 8.470052853226662e-05\n",
      "Epoch 3884, Loss: 0.0011032563452317845, Final Batch Loss: 2.5892029952956364e-05\n",
      "Epoch 3885, Loss: 3.178889619448455e-05, Final Batch Loss: 2.0391627913340926e-05\n",
      "Epoch 3886, Loss: 8.196054113795981e-05, Final Batch Loss: 6.915151607245207e-05\n",
      "Epoch 3887, Loss: 3.0081652766966727e-05, Final Batch Loss: 1.0776074304885697e-05\n",
      "Epoch 3888, Loss: 9.825871075008763e-06, Final Batch Loss: 5.83747896598652e-06\n",
      "Epoch 3889, Loss: 2.0258194354028092e-05, Final Batch Loss: 3.5548639516491676e-06\n",
      "Epoch 3890, Loss: 4.5644655074283946e-05, Final Batch Loss: 3.96264877053909e-05\n",
      "Epoch 3891, Loss: 4.660159356717486e-05, Final Batch Loss: 3.5879220376955345e-05\n",
      "Epoch 3892, Loss: 4.3621098484436516e-05, Final Batch Loss: 1.1156987056892831e-05\n",
      "Epoch 3893, Loss: 2.4351900719921105e-05, Final Batch Loss: 1.463487478758907e-05\n",
      "Epoch 3894, Loss: 0.0003212240026186919, Final Batch Loss: 5.5561449698871e-06\n",
      "Epoch 3895, Loss: 0.0002568193426668586, Final Batch Loss: 0.00025266839656978846\n",
      "Epoch 3896, Loss: 0.00018761540559353307, Final Batch Loss: 0.00012413885269779712\n",
      "Epoch 3897, Loss: 0.00038792546729382593, Final Batch Loss: 1.602636075404007e-05\n",
      "Epoch 3898, Loss: 4.7000548875075765e-05, Final Batch Loss: 1.7277927327086218e-05\n",
      "Epoch 3899, Loss: 8.211020121962065e-05, Final Batch Loss: 6.785516598029062e-05\n",
      "Epoch 3900, Loss: 4.641227496904321e-05, Final Batch Loss: 2.4087536075967364e-05\n",
      "Epoch 3901, Loss: 4.370974693301832e-06, Final Batch Loss: 1.46910883813689e-06\n",
      "Epoch 3902, Loss: 1.7392659628967522e-05, Final Batch Loss: 4.966212600265862e-06\n",
      "Epoch 3903, Loss: 6.960050995985512e-05, Final Batch Loss: 6.780812691431493e-05\n",
      "Epoch 3904, Loss: 2.518523069738876e-05, Final Batch Loss: 1.763048567227088e-05\n",
      "Epoch 3905, Loss: 0.00013433563071885146, Final Batch Loss: 8.483462443109602e-05\n",
      "Epoch 3906, Loss: 0.00020621903968276456, Final Batch Loss: 9.999187022913247e-05\n",
      "Epoch 3907, Loss: 3.4068771128659137e-05, Final Batch Loss: 1.794777563191019e-05\n",
      "Epoch 3908, Loss: 3.967734119214583e-05, Final Batch Loss: 1.6750582290114835e-05\n",
      "Epoch 3909, Loss: 0.00011111695403087651, Final Batch Loss: 0.00010300864960299805\n",
      "Epoch 3910, Loss: 6.950327679078327e-05, Final Batch Loss: 7.487925358873326e-06\n",
      "Epoch 3911, Loss: 4.2247038436471485e-05, Final Batch Loss: 1.6819734810269438e-05\n",
      "Epoch 3912, Loss: 1.9422160505655484e-05, Final Batch Loss: 8.504023867317301e-07\n",
      "Epoch 3913, Loss: 5.481275366037153e-05, Final Batch Loss: 3.849897984764539e-05\n",
      "Epoch 3914, Loss: 8.844893363857409e-05, Final Batch Loss: 4.709289896709379e-06\n",
      "Epoch 3915, Loss: 4.528106910584029e-05, Final Batch Loss: 2.6633571906131692e-05\n",
      "Epoch 3916, Loss: 0.00015358804375864565, Final Batch Loss: 6.322324043139815e-05\n",
      "Epoch 3917, Loss: 7.195808666438097e-05, Final Batch Loss: 1.5104099475138355e-05\n",
      "Epoch 3918, Loss: 9.642929944675416e-05, Final Batch Loss: 7.452600402757525e-05\n",
      "Epoch 3919, Loss: 3.4305920962651726e-05, Final Batch Loss: 1.499074187449878e-05\n",
      "Epoch 3920, Loss: 0.00021534221741603687, Final Batch Loss: 6.796600791858509e-05\n",
      "Epoch 3921, Loss: 2.0690655219368637e-05, Final Batch Loss: 1.1568688023544382e-05\n",
      "Epoch 3922, Loss: 8.822691142995609e-05, Final Batch Loss: 8.599204011261463e-05\n",
      "Epoch 3923, Loss: 5.971278437755245e-05, Final Batch Loss: 5.722521382267587e-05\n",
      "Epoch 3924, Loss: 0.00039888741594040766, Final Batch Loss: 4.687528416980058e-06\n",
      "Epoch 3925, Loss: 6.502593714685645e-05, Final Batch Loss: 2.3683007384533994e-05\n",
      "Epoch 3926, Loss: 6.024684989824891e-05, Final Batch Loss: 2.0284642232581973e-05\n",
      "Epoch 3927, Loss: 0.004633068246221228, Final Batch Loss: 1.3713864063902292e-05\n",
      "Epoch 3928, Loss: 2.5475379970885115e-05, Final Batch Loss: 3.5213438422943e-06\n",
      "Epoch 3929, Loss: 0.00017959118849830702, Final Batch Loss: 1.1144547897856683e-05\n",
      "Epoch 3930, Loss: 2.1949567781121004e-05, Final Batch Loss: 4.86030967294937e-06\n",
      "Epoch 3931, Loss: 9.320696335635148e-06, Final Batch Loss: 5.173380941414507e-06\n",
      "Epoch 3932, Loss: 6.268966899369843e-05, Final Batch Loss: 2.122533624060452e-05\n",
      "Epoch 3933, Loss: 5.293225513014477e-05, Final Batch Loss: 3.237518831156194e-05\n",
      "Epoch 3934, Loss: 0.00011849485599668697, Final Batch Loss: 4.084219108335674e-05\n",
      "Epoch 3935, Loss: 9.610702545614913e-05, Final Batch Loss: 8.29172131489031e-05\n",
      "Epoch 3936, Loss: 4.413005808601156e-05, Final Batch Loss: 3.3133255783468485e-06\n",
      "Epoch 3937, Loss: 0.005532623104954837, Final Batch Loss: 1.7952475900528952e-05\n",
      "Epoch 3938, Loss: 4.11456576330238e-05, Final Batch Loss: 1.4109543371887412e-05\n",
      "Epoch 3939, Loss: 0.00013014669821131974, Final Batch Loss: 0.00010077960905618966\n",
      "Epoch 3940, Loss: 0.0001370964091620408, Final Batch Loss: 8.178592543117702e-05\n",
      "Epoch 3941, Loss: 2.3735845388728194e-05, Final Batch Loss: 7.920592906884849e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3942, Loss: 4.4309372242423706e-05, Final Batch Loss: 2.2333444576361217e-05\n",
      "Epoch 3943, Loss: 6.400271377060562e-05, Final Batch Loss: 4.3299864046275616e-05\n",
      "Epoch 3944, Loss: 0.00017120180291385623, Final Batch Loss: 0.00015710476145613939\n",
      "Epoch 3945, Loss: 0.0003278342410339974, Final Batch Loss: 0.00022504024673253298\n",
      "Epoch 3946, Loss: 0.0001713157123504061, Final Batch Loss: 3.6743310829479015e-06\n",
      "Epoch 3947, Loss: 0.0001998467942030402, Final Batch Loss: 0.00019300341955386102\n",
      "Epoch 3948, Loss: 3.924739758076612e-05, Final Batch Loss: 2.74580015684478e-05\n",
      "Epoch 3949, Loss: 0.00026787542265083175, Final Batch Loss: 0.00024482302251271904\n",
      "Epoch 3950, Loss: 1.0782362096506404e-05, Final Batch Loss: 1.9282456378277857e-06\n",
      "Epoch 3951, Loss: 1.4825226571701933e-05, Final Batch Loss: 5.4925594668020494e-06\n",
      "Epoch 3952, Loss: 7.100859511410818e-05, Final Batch Loss: 5.124156450619921e-05\n",
      "Epoch 3953, Loss: 1.1147650866405456e-05, Final Batch Loss: 3.163110477544251e-06\n",
      "Epoch 3954, Loss: 1.91650042324909e-05, Final Batch Loss: 9.704420335765462e-06\n",
      "Epoch 3955, Loss: 3.895472036674619e-05, Final Batch Loss: 1.1716128938132897e-05\n",
      "Epoch 3956, Loss: 0.0002405505611022818, Final Batch Loss: 0.0002291188866365701\n",
      "Epoch 3957, Loss: 1.4783892765990458e-05, Final Batch Loss: 2.8239919629413635e-06\n",
      "Epoch 3958, Loss: 0.00011532129883562448, Final Batch Loss: 5.363258424040396e-06\n",
      "Epoch 3959, Loss: 0.00857430971609574, Final Batch Loss: 0.008566205389797688\n",
      "Epoch 3960, Loss: 0.0001276223592867609, Final Batch Loss: 5.2985164074925706e-05\n",
      "Epoch 3961, Loss: 2.4202405256801285e-05, Final Batch Loss: 1.6255587979685515e-05\n",
      "Epoch 3962, Loss: 7.441921115969308e-05, Final Batch Loss: 5.397571294452064e-05\n",
      "Epoch 3963, Loss: 5.8239993450115435e-05, Final Batch Loss: 1.6522137229912914e-05\n",
      "Epoch 3964, Loss: 2.287555548718956e-05, Final Batch Loss: 1.9386327039683238e-05\n",
      "Epoch 3965, Loss: 2.553701870056102e-05, Final Batch Loss: 1.1058288691856433e-05\n",
      "Epoch 3966, Loss: 0.0002200126946263481, Final Batch Loss: 0.00016882929776329547\n",
      "Epoch 3967, Loss: 0.004447264764166903, Final Batch Loss: 9.45774809224531e-06\n",
      "Epoch 3968, Loss: 8.35971841297578e-05, Final Batch Loss: 6.37125558569096e-05\n",
      "Epoch 3969, Loss: 3.222944724257104e-05, Final Batch Loss: 2.1368821762735024e-05\n",
      "Epoch 3970, Loss: 4.97739965794608e-05, Final Batch Loss: 1.0294257663190365e-05\n",
      "Epoch 3971, Loss: 0.00010611645848257467, Final Batch Loss: 4.2041807319037616e-05\n",
      "Epoch 3972, Loss: 0.0078502506694349, Final Batch Loss: 0.0078119863756000996\n",
      "Epoch 3973, Loss: 3.2970545362331904e-05, Final Batch Loss: 8.250462997239083e-06\n",
      "Epoch 3974, Loss: 0.00015294142713173642, Final Batch Loss: 4.178667495580157e-06\n",
      "Epoch 3975, Loss: 4.720956803794252e-05, Final Batch Loss: 3.297413968539331e-06\n",
      "Epoch 3976, Loss: 6.6333549284536275e-06, Final Batch Loss: 1.1442210734458058e-06\n",
      "Epoch 3977, Loss: 2.431463417451596e-05, Final Batch Loss: 7.241765160870273e-06\n",
      "Epoch 3978, Loss: 0.001903569150954354, Final Batch Loss: 0.001901537412777543\n",
      "Epoch 3979, Loss: 3.223708381483448e-05, Final Batch Loss: 5.462689387059072e-06\n",
      "Epoch 3980, Loss: 3.136907616863027e-05, Final Batch Loss: 3.592851498979144e-06\n",
      "Epoch 3981, Loss: 0.00026329867978347465, Final Batch Loss: 1.583870471222326e-05\n",
      "Epoch 3982, Loss: 2.665021747816354e-05, Final Batch Loss: 1.8217584511148743e-05\n",
      "Epoch 3983, Loss: 3.300026492070174e-05, Final Batch Loss: 1.1785717106249649e-05\n",
      "Epoch 3984, Loss: 0.00010316314183000941, Final Batch Loss: 2.3114249415812083e-05\n",
      "Epoch 3985, Loss: 0.0002092596096190391, Final Batch Loss: 2.101091195072513e-05\n",
      "Epoch 3986, Loss: 0.00016511169178556884, Final Batch Loss: 1.5113358131202403e-05\n",
      "Epoch 3987, Loss: 4.784433986060321e-05, Final Batch Loss: 2.552859041315969e-05\n",
      "Epoch 3988, Loss: 0.0012023705421597697, Final Batch Loss: 0.00114992237649858\n",
      "Epoch 3989, Loss: 0.00021514595982807805, Final Batch Loss: 2.3580764718644787e-06\n",
      "Epoch 3990, Loss: 0.0033407682276447304, Final Batch Loss: 1.4252560504246503e-05\n",
      "Epoch 3991, Loss: 7.403108793369029e-05, Final Batch Loss: 1.720745967759285e-05\n",
      "Epoch 3992, Loss: 0.0004444870023689873, Final Batch Loss: 5.557001259148819e-06\n",
      "Epoch 3993, Loss: 2.9690241717617027e-05, Final Batch Loss: 1.6010308172553778e-05\n",
      "Epoch 3994, Loss: 2.1554857084993273e-05, Final Batch Loss: 4.337811333243735e-06\n",
      "Epoch 3995, Loss: 2.2695897769153817e-05, Final Batch Loss: 5.118904937262414e-06\n",
      "Epoch 3996, Loss: 6.58887111057993e-05, Final Batch Loss: 5.3743086027679965e-05\n",
      "Epoch 3997, Loss: 0.00021546122479776386, Final Batch Loss: 5.5174841691041365e-06\n",
      "Epoch 3998, Loss: 7.559690857306123e-06, Final Batch Loss: 5.951858838670887e-06\n",
      "Epoch 3999, Loss: 0.00010457702137500746, Final Batch Loss: 4.348296897660475e-06\n",
      "Epoch 4000, Loss: 4.061945037392434e-05, Final Batch Loss: 2.239613968413323e-05\n",
      "Epoch 4001, Loss: 1.2187394986540312e-05, Final Batch Loss: 6.930366453161696e-06\n",
      "Epoch 4002, Loss: 1.4499390999844763e-05, Final Batch Loss: 4.062930202053394e-06\n",
      "Epoch 4003, Loss: 1.1069006632169476e-05, Final Batch Loss: 2.315205620107008e-06\n",
      "Epoch 4004, Loss: 3.173325058014598e-05, Final Batch Loss: 1.5790346878929995e-05\n",
      "Epoch 4005, Loss: 9.564272113493644e-05, Final Batch Loss: 2.6766170776681975e-05\n",
      "Epoch 4006, Loss: 7.494102783311973e-05, Final Batch Loss: 4.308512416173471e-06\n",
      "Epoch 4007, Loss: 4.137870109843789e-05, Final Batch Loss: 3.357593959663063e-05\n",
      "Epoch 4008, Loss: 2.8508886316558346e-05, Final Batch Loss: 1.0637704690452665e-05\n",
      "Epoch 4009, Loss: 3.603945879149251e-05, Final Batch Loss: 1.700316533970181e-05\n",
      "Epoch 4010, Loss: 0.0001766704226611182, Final Batch Loss: 5.691311525879428e-05\n",
      "Epoch 4011, Loss: 1.754556615196634e-05, Final Batch Loss: 9.260757906304207e-06\n",
      "Epoch 4012, Loss: 7.797574289725162e-05, Final Batch Loss: 1.694046295597218e-05\n",
      "Epoch 4013, Loss: 0.0001624819815333467, Final Batch Loss: 5.904389763600193e-05\n",
      "Epoch 4014, Loss: 0.0001470537572458852, Final Batch Loss: 0.000133724111947231\n",
      "Epoch 4015, Loss: 0.00011571152208489366, Final Batch Loss: 9.648079139878973e-05\n",
      "Epoch 4016, Loss: 2.4334381123480853e-05, Final Batch Loss: 1.1247738257225137e-05\n",
      "Epoch 4017, Loss: 1.8695270227908622e-05, Final Batch Loss: 1.001969758362975e-05\n",
      "Epoch 4018, Loss: 0.0005821717750222888, Final Batch Loss: 0.0005662869662046432\n",
      "Epoch 4019, Loss: 0.00019091326248599216, Final Batch Loss: 0.0001763914478942752\n",
      "Epoch 4020, Loss: 0.0039538587916467804, Final Batch Loss: 4.077195262652822e-05\n",
      "Epoch 4021, Loss: 2.880775571156846e-05, Final Batch Loss: 1.1274281632722705e-06\n",
      "Epoch 4022, Loss: 9.972798079616041e-05, Final Batch Loss: 9.469486394664273e-05\n",
      "Epoch 4023, Loss: 0.00011799676576629281, Final Batch Loss: 6.503313488792628e-05\n",
      "Epoch 4024, Loss: 0.00034775394760799827, Final Batch Loss: 1.0104636203323025e-05\n",
      "Epoch 4025, Loss: 0.00034823819441953674, Final Batch Loss: 0.00028584414394572377\n",
      "Epoch 4026, Loss: 3.290645508968737e-05, Final Batch Loss: 2.842525464075152e-05\n",
      "Epoch 4027, Loss: 0.0001071922411028936, Final Batch Loss: 2.3614370547875296e-06\n",
      "Epoch 4028, Loss: 0.00029803206416545436, Final Batch Loss: 0.00011083453864557669\n",
      "Epoch 4029, Loss: 0.004308965837481082, Final Batch Loss: 1.2762693586410023e-05\n",
      "Epoch 4030, Loss: 2.8057330382580403e-05, Final Batch Loss: 9.686856174084824e-06\n",
      "Epoch 4031, Loss: 2.971900084958179e-05, Final Batch Loss: 9.437290827918332e-06\n",
      "Epoch 4032, Loss: 6.868497439427301e-05, Final Batch Loss: 4.639634062186815e-05\n",
      "Epoch 4033, Loss: 1.17996969493106e-05, Final Batch Loss: 3.3289188650087453e-06\n",
      "Epoch 4034, Loss: 1.967642947420245e-05, Final Batch Loss: 1.4250405911298003e-05\n",
      "Epoch 4035, Loss: 0.0003708885997184552, Final Batch Loss: 0.00028867446235381067\n",
      "Epoch 4036, Loss: 0.00031471460533794016, Final Batch Loss: 0.0002987869374919683\n",
      "Epoch 4037, Loss: 0.00014641884263255633, Final Batch Loss: 2.7574173145694658e-05\n",
      "Epoch 4038, Loss: 5.67843671888113e-05, Final Batch Loss: 4.570918099489063e-05\n",
      "Epoch 4039, Loss: 2.7465705443319166e-05, Final Batch Loss: 5.896221864531981e-06\n",
      "Epoch 4040, Loss: 0.00013643149213748984, Final Batch Loss: 5.068341488367878e-05\n",
      "Epoch 4041, Loss: 6.325525282591116e-05, Final Batch Loss: 1.9068595065618865e-05\n",
      "Epoch 4042, Loss: 7.584335617139004e-05, Final Batch Loss: 3.163156725349836e-05\n",
      "Epoch 4043, Loss: 8.816422450763639e-05, Final Batch Loss: 4.320476364227943e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4044, Loss: 4.154976522841025e-05, Final Batch Loss: 3.116235893685371e-05\n",
      "Epoch 4045, Loss: 0.0001462421532778535, Final Batch Loss: 0.00012619570770766586\n",
      "Epoch 4046, Loss: 3.623077463998925e-05, Final Batch Loss: 1.0884550647460856e-05\n",
      "Epoch 4047, Loss: 3.002997073053848e-05, Final Batch Loss: 2.3854940081946552e-05\n",
      "Epoch 4048, Loss: 1.6851440705067944e-05, Final Batch Loss: 5.261550541035831e-06\n",
      "Epoch 4049, Loss: 2.9968865419505164e-05, Final Batch Loss: 9.991133993025869e-06\n",
      "Epoch 4050, Loss: 3.639822443801677e-05, Final Batch Loss: 2.1692812879336998e-05\n",
      "Epoch 4051, Loss: 0.007995595219426832, Final Batch Loss: 0.00799376517534256\n",
      "Epoch 4052, Loss: 4.3419682697276585e-05, Final Batch Loss: 9.850040441961028e-06\n",
      "Epoch 4053, Loss: 7.72211269577383e-05, Final Batch Loss: 1.4685049791296478e-05\n",
      "Epoch 4054, Loss: 4.85537734675745e-05, Final Batch Loss: 3.5760626815317664e-06\n",
      "Epoch 4055, Loss: 7.245065989991417e-05, Final Batch Loss: 5.7289402320748195e-05\n",
      "Epoch 4056, Loss: 1.0788080999191152e-05, Final Batch Loss: 6.266091986617539e-06\n",
      "Epoch 4057, Loss: 8.407094128415338e-06, Final Batch Loss: 3.5324794680491323e-06\n",
      "Epoch 4058, Loss: 6.601762834179681e-05, Final Batch Loss: 3.9502894651377574e-05\n",
      "Epoch 4059, Loss: 1.2504875485319644e-05, Final Batch Loss: 7.988290235516615e-06\n",
      "Epoch 4060, Loss: 4.401724254421424e-05, Final Batch Loss: 1.9026432710234076e-05\n",
      "Epoch 4061, Loss: 2.9798859941365663e-05, Final Batch Loss: 1.0007789569499437e-05\n",
      "Epoch 4062, Loss: 4.807751793123316e-05, Final Batch Loss: 3.248412031098269e-05\n",
      "Epoch 4063, Loss: 0.0012353944621281698, Final Batch Loss: 3.0650131520815194e-05\n",
      "Epoch 4064, Loss: 6.818678775744047e-05, Final Batch Loss: 1.3080543794785626e-05\n",
      "Epoch 4065, Loss: 3.095919191764551e-05, Final Batch Loss: 6.121151727711549e-06\n",
      "Epoch 4066, Loss: 6.21992330707144e-05, Final Batch Loss: 3.626476973295212e-05\n",
      "Epoch 4067, Loss: 4.780074323207373e-05, Final Batch Loss: 6.922819920873735e-06\n",
      "Epoch 4068, Loss: 0.00014302815543487668, Final Batch Loss: 0.00010697770630940795\n",
      "Epoch 4069, Loss: 0.00032103397461469285, Final Batch Loss: 4.3849762732861564e-05\n",
      "Epoch 4070, Loss: 0.00014398791063285898, Final Batch Loss: 0.0001256945397472009\n",
      "Epoch 4071, Loss: 0.00013047200263827108, Final Batch Loss: 4.6512341214111075e-05\n",
      "Epoch 4072, Loss: 0.0001469874223403167, Final Batch Loss: 0.00010301895963493735\n",
      "Epoch 4073, Loss: 0.0006803663027312723, Final Batch Loss: 9.999731446441729e-06\n",
      "Epoch 4074, Loss: 4.752793711304548e-05, Final Batch Loss: 4.265944517101161e-05\n",
      "Epoch 4075, Loss: 9.941268217517063e-06, Final Batch Loss: 5.050053005106747e-06\n",
      "Epoch 4076, Loss: 0.0004506341829255689, Final Batch Loss: 3.107621523668058e-05\n",
      "Epoch 4077, Loss: 0.00020555235278152395, Final Batch Loss: 0.00017990372725762427\n",
      "Epoch 4078, Loss: 0.00020617056725313887, Final Batch Loss: 0.00019776444241870195\n",
      "Epoch 4079, Loss: 0.00019271145174570847, Final Batch Loss: 0.0001791020476957783\n",
      "Epoch 4080, Loss: 1.7907306755660102e-05, Final Batch Loss: 8.445545972790569e-06\n",
      "Epoch 4081, Loss: 7.873272261349484e-05, Final Batch Loss: 1.8884915334638208e-05\n",
      "Epoch 4082, Loss: 0.0001594696523170569, Final Batch Loss: 1.1285709661024157e-05\n",
      "Epoch 4083, Loss: 0.0005370040944399079, Final Batch Loss: 0.0005188388749957085\n",
      "Epoch 4084, Loss: 0.00029247319253045134, Final Batch Loss: 0.00025599251966923475\n",
      "Epoch 4085, Loss: 4.2843748815357685e-05, Final Batch Loss: 2.4444532755296677e-05\n",
      "Epoch 4086, Loss: 8.486146907671355e-05, Final Batch Loss: 5.367555786506273e-05\n",
      "Epoch 4087, Loss: 0.00011617218024184695, Final Batch Loss: 7.651679879927542e-06\n",
      "Epoch 4088, Loss: 2.8132437364547513e-05, Final Batch Loss: 1.7927675799001008e-05\n",
      "Epoch 4089, Loss: 5.9685968608391704e-05, Final Batch Loss: 5.595652328338474e-05\n",
      "Epoch 4090, Loss: 6.894721855132957e-05, Final Batch Loss: 6.313849007710814e-05\n",
      "Epoch 4091, Loss: 1.6209907471420593e-05, Final Batch Loss: 1.3177874279790558e-05\n",
      "Epoch 4092, Loss: 0.00023032252465782221, Final Batch Loss: 2.756709545792546e-05\n",
      "Epoch 4093, Loss: 9.795370533538517e-05, Final Batch Loss: 2.706492341530975e-05\n",
      "Epoch 4094, Loss: 5.8803881984204054e-05, Final Batch Loss: 3.8432735891547054e-05\n",
      "Epoch 4095, Loss: 0.000141319542308338, Final Batch Loss: 7.08936495357193e-05\n",
      "Epoch 4096, Loss: 5.478463936015032e-05, Final Batch Loss: 4.5053817302687094e-05\n",
      "Epoch 4097, Loss: 3.657187335193157e-05, Final Batch Loss: 2.4212133212131448e-05\n",
      "Epoch 4098, Loss: 0.00018722679487837013, Final Batch Loss: 9.838511687121354e-06\n",
      "Epoch 4099, Loss: 8.284588511742186e-05, Final Batch Loss: 2.400453195150476e-05\n",
      "Epoch 4100, Loss: 1.844397547756671e-05, Final Batch Loss: 5.388934823713498e-06\n",
      "Epoch 4101, Loss: 1.7856851627584547e-05, Final Batch Loss: 8.865512427291833e-06\n",
      "Epoch 4102, Loss: 0.00014696877406095155, Final Batch Loss: 2.2158088540891185e-05\n",
      "Epoch 4103, Loss: 7.49377541069407e-05, Final Batch Loss: 4.632315904018469e-05\n",
      "Epoch 4104, Loss: 8.896164672478335e-06, Final Batch Loss: 5.270555902825436e-06\n",
      "Epoch 4105, Loss: 5.550174137169961e-05, Final Batch Loss: 5.0422793719917536e-05\n",
      "Epoch 4106, Loss: 0.00016146859343280084, Final Batch Loss: 9.877960110316053e-06\n",
      "Epoch 4107, Loss: 0.0009901721678033937, Final Batch Loss: 1.0078791092382744e-05\n",
      "Epoch 4108, Loss: 4.0248287518807047e-05, Final Batch Loss: 5.188086333873798e-07\n",
      "Epoch 4109, Loss: 3.4285929359612055e-05, Final Batch Loss: 6.593496436835267e-06\n",
      "Epoch 4110, Loss: 1.924477714965178e-06, Final Batch Loss: 1.0728656434366712e-06\n",
      "Epoch 4111, Loss: 3.69493973266799e-05, Final Batch Loss: 1.9308421542518772e-05\n",
      "Epoch 4112, Loss: 1.5304056887543993e-05, Final Batch Loss: 5.355493613024009e-06\n",
      "Epoch 4113, Loss: 0.0012444847961887717, Final Batch Loss: 0.0011140720453113317\n",
      "Epoch 4114, Loss: 1.888442420749925e-05, Final Batch Loss: 7.151316822273657e-06\n",
      "Epoch 4115, Loss: 2.3549263630684436e-05, Final Batch Loss: 3.9120567407735507e-07\n",
      "Epoch 4116, Loss: 1.8132189325115178e-05, Final Batch Loss: 1.338728816335788e-05\n",
      "Epoch 4117, Loss: 2.2233664594750735e-05, Final Batch Loss: 2.6166314910369692e-06\n",
      "Epoch 4118, Loss: 7.242443462018855e-05, Final Batch Loss: 4.495738903642632e-05\n",
      "Epoch 4119, Loss: 0.00260230243748083, Final Batch Loss: 0.002588405041024089\n",
      "Epoch 4120, Loss: 1.736760350468103e-05, Final Batch Loss: 1.0077114893647376e-05\n",
      "Epoch 4121, Loss: 5.907648665015586e-05, Final Batch Loss: 2.7711674192687497e-05\n",
      "Epoch 4122, Loss: 5.9519232308957726e-05, Final Batch Loss: 3.8080332160461694e-05\n",
      "Epoch 4123, Loss: 0.00033894636453624116, Final Batch Loss: 2.9238408387755044e-06\n",
      "Epoch 4124, Loss: 0.00011506870578159578, Final Batch Loss: 6.927894719410688e-05\n",
      "Epoch 4125, Loss: 4.6968618107712246e-05, Final Batch Loss: 1.0686505902413046e-06\n",
      "Epoch 4126, Loss: 6.089526777941501e-06, Final Batch Loss: 3.849424956570147e-06\n",
      "Epoch 4127, Loss: 0.0005946868668615934, Final Batch Loss: 1.2549314305942971e-05\n",
      "Epoch 4128, Loss: 2.01093999976365e-05, Final Batch Loss: 1.4657153997177375e-06\n",
      "Epoch 4129, Loss: 3.5142412798450096e-05, Final Batch Loss: 5.730720204155659e-06\n",
      "Epoch 4130, Loss: 0.0002846033785317559, Final Batch Loss: 0.0002513572108000517\n",
      "Epoch 4131, Loss: 1.203371971314482e-05, Final Batch Loss: 1.9055712527915603e-06\n",
      "Epoch 4132, Loss: 9.997879715228919e-05, Final Batch Loss: 6.513133484986611e-06\n",
      "Epoch 4133, Loss: 7.15274472895544e-05, Final Batch Loss: 3.4140070056309924e-05\n",
      "Epoch 4134, Loss: 1.699681070022052e-05, Final Batch Loss: 9.744644557940774e-06\n",
      "Epoch 4135, Loss: 0.00016524329475942068, Final Batch Loss: 4.145977072766982e-05\n",
      "Epoch 4136, Loss: 1.3721444247494219e-05, Final Batch Loss: 7.711621037742589e-06\n",
      "Epoch 4137, Loss: 5.918990166264848e-05, Final Batch Loss: 1.3943473504696158e-06\n",
      "Epoch 4138, Loss: 4.220858818371198e-05, Final Batch Loss: 5.343017164705088e-06\n",
      "Epoch 4139, Loss: 7.206140526250238e-05, Final Batch Loss: 3.830843525065575e-06\n",
      "Epoch 4140, Loss: 2.007565944950329e-05, Final Batch Loss: 1.2208859516249504e-05\n",
      "Epoch 4141, Loss: 1.5022326010694087e-05, Final Batch Loss: 1.0904960845437017e-06\n",
      "Epoch 4142, Loss: 0.00013819981177221052, Final Batch Loss: 0.00012134695134591311\n",
      "Epoch 4143, Loss: 0.00022881344193592668, Final Batch Loss: 0.00016320013673976064\n",
      "Epoch 4144, Loss: 0.0002928596909441694, Final Batch Loss: 9.49464720179094e-07\n",
      "Epoch 4145, Loss: 0.0002772352090687491, Final Batch Loss: 2.0301587937865406e-05\n",
      "Epoch 4146, Loss: 3.714453714565025e-05, Final Batch Loss: 3.2496050152985845e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4147, Loss: 4.8180688281718176e-05, Final Batch Loss: 9.043214049597736e-06\n",
      "Epoch 4148, Loss: 4.763884362546378e-06, Final Batch Loss: 2.6649840947357006e-06\n",
      "Epoch 4149, Loss: 2.0726995899167378e-05, Final Batch Loss: 1.2830544619646389e-05\n",
      "Epoch 4150, Loss: 2.8268626010685693e-05, Final Batch Loss: 7.071887921483722e-06\n",
      "Epoch 4151, Loss: 9.434069215785712e-05, Final Batch Loss: 3.5991077311336994e-05\n",
      "Epoch 4152, Loss: 0.0004403588818604476, Final Batch Loss: 0.00043806599569506943\n",
      "Epoch 4153, Loss: 0.001680939101788681, Final Batch Loss: 4.0167120459955186e-05\n",
      "Epoch 4154, Loss: 8.389134336539428e-06, Final Batch Loss: 7.26812641005381e-06\n",
      "Epoch 4155, Loss: 3.295028955108137e-05, Final Batch Loss: 2.8245527573744766e-05\n",
      "Epoch 4156, Loss: 0.0004957635901519097, Final Batch Loss: 0.0004525100812315941\n",
      "Epoch 4157, Loss: 0.00011447594715718878, Final Batch Loss: 7.142512004065793e-06\n",
      "Epoch 4158, Loss: 4.0559677700002794e-05, Final Batch Loss: 5.389567832025932e-07\n",
      "Epoch 4159, Loss: 7.140823072404601e-05, Final Batch Loss: 3.232720700907521e-05\n",
      "Epoch 4160, Loss: 1.7475234699304565e-05, Final Batch Loss: 2.085238293147995e-06\n",
      "Epoch 4161, Loss: 1.0114524002347025e-05, Final Batch Loss: 9.154222425422631e-06\n",
      "Epoch 4162, Loss: 3.83459359909466e-06, Final Batch Loss: 1.156802454715944e-06\n",
      "Epoch 4163, Loss: 6.90117190060846e-06, Final Batch Loss: 4.7688463382655755e-06\n",
      "Epoch 4164, Loss: 4.139567136007827e-05, Final Batch Loss: 1.9188892110832967e-05\n",
      "Epoch 4165, Loss: 9.47677722251683e-06, Final Batch Loss: 1.4262975582823856e-06\n",
      "Epoch 4166, Loss: 9.249280537915183e-06, Final Batch Loss: 3.563347945600981e-06\n",
      "Epoch 4167, Loss: 2.6422274459037e-05, Final Batch Loss: 1.3312836017576046e-05\n",
      "Epoch 4168, Loss: 0.0005743423716921825, Final Batch Loss: 0.0005595340626314282\n",
      "Epoch 4169, Loss: 1.6364151179004693e-05, Final Batch Loss: 9.720457455841824e-06\n",
      "Epoch 4170, Loss: 9.617654040994239e-05, Final Batch Loss: 9.458830754738301e-05\n",
      "Epoch 4171, Loss: 1.1431969141995069e-05, Final Batch Loss: 4.290966899134219e-06\n",
      "Epoch 4172, Loss: 1.6565937585255597e-05, Final Batch Loss: 5.561189027503133e-06\n",
      "Epoch 4173, Loss: 7.432148322550347e-05, Final Batch Loss: 8.641843123768922e-06\n",
      "Epoch 4174, Loss: 4.911372002425196e-06, Final Batch Loss: 1.526171104160312e-06\n",
      "Epoch 4175, Loss: 1.044727764565323e-05, Final Batch Loss: 7.429716788465157e-06\n",
      "Epoch 4176, Loss: 0.001063171713212796, Final Batch Loss: 0.001049974700435996\n",
      "Epoch 4177, Loss: 6.689080237265443e-05, Final Batch Loss: 1.2908639291708823e-05\n",
      "Epoch 4178, Loss: 3.539734098012559e-05, Final Batch Loss: 3.164172812830657e-05\n",
      "Epoch 4179, Loss: 2.2799741145718144e-05, Final Batch Loss: 1.6814797163533513e-06\n",
      "Epoch 4180, Loss: 9.469350970903179e-06, Final Batch Loss: 6.239476988412207e-06\n",
      "Epoch 4181, Loss: 5.069109874966671e-05, Final Batch Loss: 4.7000656195450574e-05\n",
      "Epoch 4182, Loss: 0.0007592798829136882, Final Batch Loss: 0.0007435794686898589\n",
      "Epoch 4183, Loss: 3.418155483814189e-05, Final Batch Loss: 5.4440506573882885e-06\n",
      "Epoch 4184, Loss: 1.30831467686221e-05, Final Batch Loss: 7.466687748092227e-06\n",
      "Epoch 4185, Loss: 6.643828328378731e-06, Final Batch Loss: 4.464311132323928e-06\n",
      "Epoch 4186, Loss: 4.121015626878943e-05, Final Batch Loss: 4.538926077657379e-06\n",
      "Epoch 4187, Loss: 2.6361163691035472e-05, Final Batch Loss: 1.769420487107709e-05\n",
      "Epoch 4188, Loss: 6.305412171059288e-06, Final Batch Loss: 4.219888069201261e-06\n",
      "Epoch 4189, Loss: 2.214348023699131e-05, Final Batch Loss: 1.177003559860168e-05\n",
      "Epoch 4190, Loss: 3.413931972318096e-05, Final Batch Loss: 2.9647335395566188e-06\n",
      "Epoch 4191, Loss: 1.819047156459419e-05, Final Batch Loss: 1.0432736416987609e-05\n",
      "Epoch 4192, Loss: 2.6172498110099696e-05, Final Batch Loss: 2.5233566702809185e-06\n",
      "Epoch 4193, Loss: 0.00013686989950656425, Final Batch Loss: 0.00011993402586085722\n",
      "Epoch 4194, Loss: 0.0001139105406764429, Final Batch Loss: 9.538890299154446e-05\n",
      "Epoch 4195, Loss: 5.9975349131491384e-06, Final Batch Loss: 4.637631263904041e-06\n",
      "Epoch 4196, Loss: 7.54892948862107e-06, Final Batch Loss: 3.7649481328116963e-06\n",
      "Epoch 4197, Loss: 8.662092204758665e-05, Final Batch Loss: 1.1045142855437007e-05\n",
      "Epoch 4198, Loss: 0.00012238044018886285, Final Batch Loss: 0.00011404891120037064\n",
      "Epoch 4199, Loss: 6.40284256405721e-05, Final Batch Loss: 5.702782073058188e-05\n",
      "Epoch 4200, Loss: 4.0264527342515066e-05, Final Batch Loss: 1.4787559848628007e-05\n",
      "Epoch 4201, Loss: 2.2997423911874648e-05, Final Batch Loss: 9.749378477863502e-06\n",
      "Epoch 4202, Loss: 6.4090979776665336e-06, Final Batch Loss: 4.169508883933304e-06\n",
      "Epoch 4203, Loss: 5.580394281423651e-05, Final Batch Loss: 3.7615958717651665e-05\n",
      "Epoch 4204, Loss: 0.0031559816529806994, Final Batch Loss: 3.358578851475613e-06\n",
      "Epoch 4205, Loss: 2.686262041606824e-05, Final Batch Loss: 1.9868777599185705e-05\n",
      "Epoch 4206, Loss: 1.3002685363971977e-05, Final Batch Loss: 1.8593480035633547e-06\n",
      "Epoch 4207, Loss: 8.007188625924755e-05, Final Batch Loss: 5.468297240440734e-05\n",
      "Epoch 4208, Loss: 7.807291467543109e-05, Final Batch Loss: 6.8291096795292106e-06\n",
      "Epoch 4209, Loss: 3.656278204289265e-05, Final Batch Loss: 7.831318725948222e-06\n",
      "Epoch 4210, Loss: 2.7913610551877355e-06, Final Batch Loss: 6.447273221965588e-07\n",
      "Epoch 4211, Loss: 8.355422713179905e-05, Final Batch Loss: 3.24045942079465e-07\n",
      "Epoch 4212, Loss: 0.0006926328933332115, Final Batch Loss: 0.00027858122484758496\n",
      "Epoch 4213, Loss: 7.324755711124453e-05, Final Batch Loss: 2.5351225758640794e-06\n",
      "Epoch 4214, Loss: 7.17120710760355e-05, Final Batch Loss: 6.376516103046015e-05\n",
      "Epoch 4215, Loss: 4.1882188668296294e-05, Final Batch Loss: 5.078958906779008e-07\n",
      "Epoch 4216, Loss: 6.080095755578441e-05, Final Batch Loss: 5.389518378251523e-07\n",
      "Epoch 4217, Loss: 0.00022826464191894047, Final Batch Loss: 0.0002022620610659942\n",
      "Epoch 4218, Loss: 0.00010153645871469053, Final Batch Loss: 7.039311640255619e-06\n",
      "Epoch 4219, Loss: 2.5666185933914676e-05, Final Batch Loss: 2.463671626173891e-05\n",
      "Epoch 4220, Loss: 5.6872823279263685e-05, Final Batch Loss: 5.0281942094443366e-05\n",
      "Epoch 4221, Loss: 2.0780095383088337e-05, Final Batch Loss: 2.5948033908207435e-06\n",
      "Epoch 4222, Loss: 8.195496320695383e-05, Final Batch Loss: 6.911507807672024e-05\n",
      "Epoch 4223, Loss: 2.7487987608765252e-05, Final Batch Loss: 7.628746971022338e-06\n",
      "Epoch 4224, Loss: 4.631358751794323e-05, Final Batch Loss: 2.4228082111221738e-05\n",
      "Epoch 4225, Loss: 0.00011205157716176473, Final Batch Loss: 7.622937118867412e-05\n",
      "Epoch 4226, Loss: 2.260238215967547e-05, Final Batch Loss: 1.8199687474407256e-05\n",
      "Epoch 4227, Loss: 4.474244178709341e-05, Final Batch Loss: 3.0150898965075612e-05\n",
      "Epoch 4228, Loss: 3.717391336977016e-05, Final Batch Loss: 1.5861549400142394e-05\n",
      "Epoch 4229, Loss: 0.00013557484498960548, Final Batch Loss: 2.9557472771557514e-06\n",
      "Epoch 4230, Loss: 2.5621088070693077e-05, Final Batch Loss: 2.1750568066636333e-06\n",
      "Epoch 4231, Loss: 1.4459446674663923e-05, Final Batch Loss: 1.1629758773779031e-05\n",
      "Epoch 4232, Loss: 2.7021143068850506e-05, Final Batch Loss: 1.1404782526369672e-05\n",
      "Epoch 4233, Loss: 1.009472725854721e-05, Final Batch Loss: 3.021103566425154e-06\n",
      "Epoch 4234, Loss: 5.1792100066450075e-06, Final Batch Loss: 3.8545922507182695e-06\n",
      "Epoch 4235, Loss: 0.00016041869912442053, Final Batch Loss: 1.0583317816781346e-05\n",
      "Epoch 4236, Loss: 4.4795091525884345e-05, Final Batch Loss: 2.2742644432582892e-05\n",
      "Epoch 4237, Loss: 3.1020234018797055e-05, Final Batch Loss: 9.437486369279213e-06\n",
      "Epoch 4238, Loss: 7.51492561903433e-05, Final Batch Loss: 5.791626790596638e-06\n",
      "Epoch 4239, Loss: 1.1484518836368807e-05, Final Batch Loss: 7.151204044930637e-06\n",
      "Epoch 4240, Loss: 9.183643896903959e-06, Final Batch Loss: 2.5242727588192793e-06\n",
      "Epoch 4241, Loss: 2.4130877392281036e-05, Final Batch Loss: 2.3789942133589648e-05\n",
      "Epoch 4242, Loss: 8.709209851076594e-06, Final Batch Loss: 3.771940100705251e-06\n",
      "Epoch 4243, Loss: 0.00010056197788799182, Final Batch Loss: 6.953196134418249e-06\n",
      "Epoch 4244, Loss: 2.484578499206691e-05, Final Batch Loss: 2.2487449314212427e-05\n",
      "Epoch 4245, Loss: 2.9586290395400283e-06, Final Batch Loss: 4.138655924634804e-07\n",
      "Epoch 4246, Loss: 3.0500314096570946e-05, Final Batch Loss: 3.306338840047829e-06\n",
      "Epoch 4247, Loss: 4.696109226642875e-05, Final Batch Loss: 3.620013012550771e-05\n",
      "Epoch 4248, Loss: 1.0175649549637455e-05, Final Batch Loss: 7.900285709183663e-06\n",
      "Epoch 4249, Loss: 0.0005546879337998689, Final Batch Loss: 0.000539592991117388\n",
      "Epoch 4250, Loss: 0.00018541495171575662, Final Batch Loss: 1.6503539654877386e-06\n",
      "Epoch 4251, Loss: 8.611245539213996e-05, Final Batch Loss: 1.0323068636353128e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4252, Loss: 2.344816266486305e-06, Final Batch Loss: 1.0602602742437739e-06\n",
      "Epoch 4253, Loss: 2.9953716875752434e-05, Final Batch Loss: 1.7735430446919054e-05\n",
      "Epoch 4254, Loss: 4.3600455683190376e-05, Final Batch Loss: 3.1518680771114305e-05\n",
      "Epoch 4255, Loss: 4.9961831336986506e-05, Final Batch Loss: 2.425260845484445e-06\n",
      "Epoch 4256, Loss: 0.00024121013848343864, Final Batch Loss: 8.820376388030127e-05\n",
      "Epoch 4257, Loss: 4.034776065964252e-05, Final Batch Loss: 1.022546348394826e-05\n",
      "Epoch 4258, Loss: 3.0309083626889333e-05, Final Batch Loss: 1.583239168212458e-06\n",
      "Epoch 4259, Loss: 3.517862751323264e-05, Final Batch Loss: 2.640753154992126e-05\n",
      "Epoch 4260, Loss: 5.978948684060015e-05, Final Batch Loss: 4.166455619269982e-05\n",
      "Epoch 4261, Loss: 2.272567871841602e-05, Final Batch Loss: 1.497173525422113e-05\n",
      "Epoch 4262, Loss: 2.581217785291301e-06, Final Batch Loss: 3.1733063110550574e-07\n",
      "Epoch 4263, Loss: 4.658771672438888e-06, Final Batch Loss: 1.0166069159822655e-06\n",
      "Epoch 4264, Loss: 4.1965108721342403e-05, Final Batch Loss: 3.104648203589022e-05\n",
      "Epoch 4265, Loss: 1.2119112284381117e-05, Final Batch Loss: 1.0757311429188121e-05\n",
      "Epoch 4266, Loss: 2.8393437787599396e-05, Final Batch Loss: 5.792092451883946e-06\n",
      "Epoch 4267, Loss: 2.5448755991419603e-05, Final Batch Loss: 2.379563193244394e-05\n",
      "Epoch 4268, Loss: 2.825971387210302e-05, Final Batch Loss: 1.781225910235662e-05\n",
      "Epoch 4269, Loss: 0.0005621170048470958, Final Batch Loss: 8.001027708814945e-06\n",
      "Epoch 4270, Loss: 4.174920604782528e-06, Final Batch Loss: 2.703023483263678e-06\n",
      "Epoch 4271, Loss: 3.290523545729229e-05, Final Batch Loss: 6.477143870142754e-06\n",
      "Epoch 4272, Loss: 1.1271412859059637e-05, Final Batch Loss: 4.869438271271065e-06\n",
      "Epoch 4273, Loss: 4.556417934509227e-05, Final Batch Loss: 3.1504578146268614e-06\n",
      "Epoch 4274, Loss: 2.6938618702843087e-05, Final Batch Loss: 5.6781977946229745e-06\n",
      "Epoch 4275, Loss: 5.688736791853444e-06, Final Batch Loss: 1.2743505521939369e-06\n",
      "Epoch 4276, Loss: 1.0330604254704667e-05, Final Batch Loss: 4.8048741518869065e-06\n",
      "Epoch 4277, Loss: 9.779149308997148e-06, Final Batch Loss: 7.960543371154927e-06\n",
      "Epoch 4278, Loss: 3.1721306186227594e-05, Final Batch Loss: 1.1483029993542004e-05\n",
      "Epoch 4279, Loss: 0.000135713287818362, Final Batch Loss: 0.00011432095925556496\n",
      "Epoch 4280, Loss: 7.545320931967581e-05, Final Batch Loss: 4.788999831362162e-06\n",
      "Epoch 4281, Loss: 4.351489133114228e-05, Final Batch Loss: 1.0325628863938618e-05\n",
      "Epoch 4282, Loss: 9.211883678972299e-06, Final Batch Loss: 8.810868166619912e-06\n",
      "Epoch 4283, Loss: 3.937931251130067e-05, Final Batch Loss: 3.314155765110627e-05\n",
      "Epoch 4284, Loss: 9.970955261451309e-06, Final Batch Loss: 6.85583609083551e-06\n",
      "Epoch 4285, Loss: 2.0169970866845688e-05, Final Batch Loss: 1.8257946067024022e-05\n",
      "Epoch 4286, Loss: 0.005271087500432259, Final Batch Loss: 1.5824168713152176e-06\n",
      "Epoch 4287, Loss: 9.561650358591578e-06, Final Batch Loss: 8.296673513541464e-06\n",
      "Epoch 4288, Loss: 5.5601690291950945e-06, Final Batch Loss: 1.997841536649503e-06\n",
      "Epoch 4289, Loss: 0.0002432175970170647, Final Batch Loss: 0.0002091124770231545\n",
      "Epoch 4290, Loss: 7.823744590496062e-05, Final Batch Loss: 2.378013505222043e-06\n",
      "Epoch 4291, Loss: 4.2546786062303e-05, Final Batch Loss: 2.8370785003062338e-05\n",
      "Epoch 4292, Loss: 5.293639151204843e-05, Final Batch Loss: 2.9007615012233146e-05\n",
      "Epoch 4293, Loss: 1.1935472230106825e-05, Final Batch Loss: 7.650600309716538e-06\n",
      "Epoch 4294, Loss: 8.95585890248185e-06, Final Batch Loss: 3.5743446460401174e-06\n",
      "Epoch 4295, Loss: 1.5233451904350659e-05, Final Batch Loss: 1.161343516287161e-05\n",
      "Epoch 4296, Loss: 0.00027062423851020867, Final Batch Loss: 9.12768973648781e-06\n",
      "Epoch 4297, Loss: 2.6049144139506097e-06, Final Batch Loss: 9.351884386887832e-07\n",
      "Epoch 4298, Loss: 0.00011078040938627964, Final Batch Loss: 0.00010742084123194218\n",
      "Epoch 4299, Loss: 3.6503395222098334e-06, Final Batch Loss: 1.697371999398456e-06\n",
      "Epoch 4300, Loss: 1.059953547155601e-05, Final Batch Loss: 4.307279141357867e-06\n",
      "Epoch 4301, Loss: 1.5112045275600394e-05, Final Batch Loss: 8.955369594332296e-06\n",
      "Epoch 4302, Loss: 1.3191217703933944e-05, Final Batch Loss: 9.915167538565584e-06\n",
      "Epoch 4303, Loss: 4.2955367121066956e-05, Final Batch Loss: 4.1412855352973565e-05\n",
      "Epoch 4304, Loss: 9.393188872763858e-05, Final Batch Loss: 9.265018888982013e-05\n",
      "Epoch 4305, Loss: 0.000221878801312414, Final Batch Loss: 0.00019512859580572695\n",
      "Epoch 4306, Loss: 9.191697108690278e-05, Final Batch Loss: 8.636925485916436e-05\n",
      "Epoch 4307, Loss: 0.00014019587365510233, Final Batch Loss: 5.540653091884451e-07\n",
      "Epoch 4308, Loss: 8.603951584973402e-06, Final Batch Loss: 7.530277912337624e-07\n",
      "Epoch 4309, Loss: 2.0378766407702642e-05, Final Batch Loss: 8.05059812591935e-07\n",
      "Epoch 4310, Loss: 1.1534920076883282e-05, Final Batch Loss: 2.0079348814761033e-06\n",
      "Epoch 4311, Loss: 7.842569175409153e-06, Final Batch Loss: 6.051844593457645e-06\n",
      "Epoch 4312, Loss: 9.654344466980547e-06, Final Batch Loss: 6.5056801759055816e-06\n",
      "Epoch 4313, Loss: 6.316468216027715e-05, Final Batch Loss: 5.6043559197860304e-06\n",
      "Epoch 4314, Loss: 3.6591691241483204e-05, Final Batch Loss: 1.3357073839870282e-05\n",
      "Epoch 4315, Loss: 0.007237389282181539, Final Batch Loss: 5.05993966726237e-06\n",
      "Epoch 4316, Loss: 2.5662955977168167e-05, Final Batch Loss: 5.567790594795952e-06\n",
      "Epoch 4317, Loss: 1.342473160548252e-05, Final Batch Loss: 6.9583652475557756e-06\n",
      "Epoch 4318, Loss: 2.211559421994025e-05, Final Batch Loss: 1.8695054677664302e-06\n",
      "Epoch 4319, Loss: 5.513755695574218e-06, Final Batch Loss: 2.7325129394739633e-06\n",
      "Epoch 4320, Loss: 2.7744767976400908e-05, Final Batch Loss: 1.1672821528918575e-05\n",
      "Epoch 4321, Loss: 1.0041983841801994e-05, Final Batch Loss: 3.7205222724878695e-06\n",
      "Epoch 4322, Loss: 5.099170130051789e-05, Final Batch Loss: 4.8671066906536e-05\n",
      "Epoch 4323, Loss: 0.00033020407136064023, Final Batch Loss: 0.0001948520221048966\n",
      "Epoch 4324, Loss: 2.8222314995218767e-05, Final Batch Loss: 7.475638540199725e-06\n",
      "Epoch 4325, Loss: 0.00012958830848219804, Final Batch Loss: 0.00011193635873496532\n",
      "Epoch 4326, Loss: 0.07140762576455018, Final Batch Loss: 0.07135274261236191\n",
      "Epoch 4327, Loss: 7.240401464514434e-05, Final Batch Loss: 4.214142609271221e-05\n",
      "Epoch 4328, Loss: 0.0001390416618960444, Final Batch Loss: 0.00010226732410956174\n",
      "Epoch 4329, Loss: 1.5560799056402175e-05, Final Batch Loss: 1.0256720997858793e-05\n",
      "Epoch 4330, Loss: 5.711579797207378e-05, Final Batch Loss: 5.600289296125993e-05\n",
      "Epoch 4331, Loss: 1.9532504438757314e-05, Final Batch Loss: 1.697967672953382e-05\n",
      "Epoch 4332, Loss: 2.3712776965112425e-05, Final Batch Loss: 1.2451026123017073e-05\n",
      "Epoch 4333, Loss: 4.362911477073794e-05, Final Batch Loss: 9.03836826182669e-06\n",
      "Epoch 4334, Loss: 0.00017323791689705104, Final Batch Loss: 9.19368612812832e-05\n",
      "Epoch 4335, Loss: 0.00010356057464377955, Final Batch Loss: 5.0062171794706956e-05\n",
      "Epoch 4336, Loss: 0.00037479965249076486, Final Batch Loss: 6.67037966195494e-05\n",
      "Epoch 4337, Loss: 2.380055229878053e-05, Final Batch Loss: 2.597269485704601e-06\n",
      "Epoch 4338, Loss: 0.0001720626960377558, Final Batch Loss: 1.2617142601811793e-05\n",
      "Epoch 4339, Loss: 3.4641154343262315e-05, Final Batch Loss: 6.31666807748843e-06\n",
      "Epoch 4340, Loss: 0.00011600733705563471, Final Batch Loss: 3.2342148188035935e-05\n",
      "Epoch 4341, Loss: 0.0006564293289557099, Final Batch Loss: 0.0001542294630780816\n",
      "Epoch 4342, Loss: 3.311794625915354e-05, Final Batch Loss: 2.262250018247869e-05\n",
      "Epoch 4343, Loss: 0.003282677564129699, Final Batch Loss: 4.659471596824005e-05\n",
      "Epoch 4344, Loss: 0.00020825807223445736, Final Batch Loss: 9.28950248635374e-06\n",
      "Epoch 4345, Loss: 0.00010659066265361616, Final Batch Loss: 9.443966700928286e-05\n",
      "Epoch 4346, Loss: 0.00011844984328490682, Final Batch Loss: 8.968004112830386e-05\n",
      "Epoch 4347, Loss: 0.013171875694297341, Final Batch Loss: 5.017810963181546e-06\n",
      "Epoch 4348, Loss: 6.96662700647721e-05, Final Batch Loss: 2.7193773348699324e-05\n",
      "Epoch 4349, Loss: 1.4194896721164696e-05, Final Batch Loss: 7.59309523346019e-06\n",
      "Epoch 4350, Loss: 0.000263071243352897, Final Batch Loss: 0.00025027524679899216\n",
      "Epoch 4351, Loss: 0.0002569737480371259, Final Batch Loss: 2.2728076146449894e-05\n",
      "Epoch 4352, Loss: 7.168399179136031e-06, Final Batch Loss: 1.9878518742189044e-06\n",
      "Epoch 4353, Loss: 4.5873376620875206e-05, Final Batch Loss: 1.3194700841268059e-05\n",
      "Epoch 4354, Loss: 8.978442929219455e-05, Final Batch Loss: 5.191784293856472e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4355, Loss: 9.440552821615711e-05, Final Batch Loss: 5.4345993703464046e-05\n",
      "Epoch 4356, Loss: 0.00022143852402223274, Final Batch Loss: 0.0001959937799256295\n",
      "Epoch 4357, Loss: 3.654960255516926e-05, Final Batch Loss: 1.3483661859936547e-05\n",
      "Epoch 4358, Loss: 4.8128187700058334e-05, Final Batch Loss: 3.265022314735688e-05\n",
      "Epoch 4359, Loss: 4.997245059712441e-05, Final Batch Loss: 5.643438726110617e-06\n",
      "Epoch 4360, Loss: 3.825557223535725e-05, Final Batch Loss: 6.281183686951408e-06\n",
      "Epoch 4361, Loss: 0.003975795385485981, Final Batch Loss: 5.517880344996229e-05\n",
      "Epoch 4362, Loss: 0.0002776816108962521, Final Batch Loss: 7.556912896689028e-05\n",
      "Epoch 4363, Loss: 7.391768849629443e-05, Final Batch Loss: 1.6868574675754644e-05\n",
      "Epoch 4364, Loss: 0.00011637835746114433, Final Batch Loss: 1.9484261883917497e-06\n",
      "Epoch 4365, Loss: 4.488042395678349e-05, Final Batch Loss: 2.5309480406576768e-05\n",
      "Epoch 4366, Loss: 0.0003690678331622621, Final Batch Loss: 1.0914407539530657e-05\n",
      "Epoch 4367, Loss: 0.00044850293488707393, Final Batch Loss: 0.0003243677201680839\n",
      "Epoch 4368, Loss: 4.4395021177479066e-05, Final Batch Loss: 3.2877695048227906e-05\n",
      "Epoch 4369, Loss: 0.0002496206434443593, Final Batch Loss: 0.00015536944556515664\n",
      "Epoch 4370, Loss: 2.335467070224695e-05, Final Batch Loss: 9.07629873836413e-06\n",
      "Epoch 4371, Loss: 0.00020246503117959946, Final Batch Loss: 0.0001599529932718724\n",
      "Epoch 4372, Loss: 6.372860116243828e-05, Final Batch Loss: 4.054118107887916e-05\n",
      "Epoch 4373, Loss: 6.493717273770017e-05, Final Batch Loss: 5.567988864640938e-06\n",
      "Epoch 4374, Loss: 3.314104105811566e-05, Final Batch Loss: 1.6056736058089882e-05\n",
      "Epoch 4375, Loss: 0.00034742623938655015, Final Batch Loss: 0.0003287798899691552\n",
      "Epoch 4376, Loss: 0.00033782787795644253, Final Batch Loss: 0.00017497598310001194\n",
      "Epoch 4377, Loss: 2.125576247635763e-05, Final Batch Loss: 1.2077279279765207e-05\n",
      "Epoch 4378, Loss: 1.9941264326917008e-05, Final Batch Loss: 1.3662698620464653e-05\n",
      "Epoch 4379, Loss: 3.063154781557387e-05, Final Batch Loss: 1.7562291759531945e-05\n",
      "Epoch 4380, Loss: 2.4353004846489057e-05, Final Batch Loss: 5.979140041745268e-06\n",
      "Epoch 4381, Loss: 0.00010689928967622109, Final Batch Loss: 8.886808791430667e-05\n",
      "Epoch 4382, Loss: 0.0003018122042703908, Final Batch Loss: 0.00028390312218107283\n",
      "Epoch 4383, Loss: 0.015416197074955562, Final Batch Loss: 0.01535800937563181\n",
      "Epoch 4384, Loss: 4.18638437622576e-05, Final Batch Loss: 3.2951051252894104e-05\n",
      "Epoch 4385, Loss: 0.00012448184043023502, Final Batch Loss: 0.00010930062853731215\n",
      "Epoch 4386, Loss: 0.0001919370533869369, Final Batch Loss: 2.1226745957392268e-05\n",
      "Epoch 4387, Loss: 0.00014660810029454296, Final Batch Loss: 0.00014015493798069656\n",
      "Epoch 4388, Loss: 2.8612521418835968e-05, Final Batch Loss: 2.0028946892125532e-05\n",
      "Epoch 4389, Loss: 7.773653487674892e-05, Final Batch Loss: 1.3093515008222312e-05\n",
      "Epoch 4390, Loss: 6.250462320167571e-05, Final Batch Loss: 1.1348714906489477e-05\n",
      "Epoch 4391, Loss: 1.897446873044828e-05, Final Batch Loss: 7.78981666371692e-06\n",
      "Epoch 4392, Loss: 2.618592998260283e-05, Final Batch Loss: 2.881594355130801e-06\n",
      "Epoch 4393, Loss: 3.5496450152550096e-05, Final Batch Loss: 4.852296910939913e-07\n",
      "Epoch 4394, Loss: 5.340362918104802e-06, Final Batch Loss: 3.7664267438231036e-06\n",
      "Epoch 4395, Loss: 0.00013135806057107402, Final Batch Loss: 0.00011985456512775272\n",
      "Epoch 4396, Loss: 5.373593239710317e-05, Final Batch Loss: 4.782804171554744e-05\n",
      "Epoch 4397, Loss: 0.0002537109778586455, Final Batch Loss: 0.00025039384490810335\n",
      "Epoch 4398, Loss: 0.01002225152842584, Final Batch Loss: 0.009969398379325867\n",
      "Epoch 4399, Loss: 0.0004250820056768134, Final Batch Loss: 3.4863987821154296e-05\n",
      "Epoch 4400, Loss: 0.013193245573347667, Final Batch Loss: 0.0131524121388793\n",
      "Epoch 4401, Loss: 0.00021437020404846407, Final Batch Loss: 0.00015619181795045733\n",
      "Epoch 4402, Loss: 0.0013223737478256226, Final Batch Loss: 1.2211385183036327e-05\n",
      "Epoch 4403, Loss: 0.00036622146944864653, Final Batch Loss: 3.7995483580743894e-05\n",
      "Epoch 4404, Loss: 0.0001397203031956451, Final Batch Loss: 0.0001176246878458187\n",
      "Epoch 4405, Loss: 3.3703110148053383e-05, Final Batch Loss: 2.433499957987806e-06\n",
      "Epoch 4406, Loss: 9.500621672486886e-05, Final Batch Loss: 1.1686439393088222e-05\n",
      "Epoch 4407, Loss: 5.3319690323405666e-05, Final Batch Loss: 4.965268453815952e-05\n",
      "Epoch 4408, Loss: 0.00031142900115810335, Final Batch Loss: 0.0002483170828782022\n",
      "Epoch 4409, Loss: 3.143347475997871e-05, Final Batch Loss: 2.8136782930232584e-05\n",
      "Epoch 4410, Loss: 9.307410437031649e-05, Final Batch Loss: 7.723590533714741e-05\n",
      "Epoch 4411, Loss: 4.048442809789776e-05, Final Batch Loss: 8.143028367157967e-07\n",
      "Epoch 4412, Loss: 6.473809298768174e-05, Final Batch Loss: 3.0155717468005605e-05\n",
      "Epoch 4413, Loss: 9.493873585597612e-05, Final Batch Loss: 2.9782338970107958e-05\n",
      "Epoch 4414, Loss: 3.273340689702309e-05, Final Batch Loss: 3.080940950894728e-05\n",
      "Epoch 4415, Loss: 4.346471541794017e-05, Final Batch Loss: 7.384398486465216e-06\n",
      "Epoch 4416, Loss: 3.25183918903349e-05, Final Batch Loss: 1.1647822248050943e-05\n",
      "Epoch 4417, Loss: 0.00016106457769637927, Final Batch Loss: 6.732065230607986e-05\n",
      "Epoch 4418, Loss: 5.6343295000260696e-05, Final Batch Loss: 2.0182738808216527e-05\n",
      "Epoch 4419, Loss: 8.489252650178969e-05, Final Batch Loss: 2.792857412714511e-05\n",
      "Epoch 4420, Loss: 0.00016787169624876697, Final Batch Loss: 0.000157341972226277\n",
      "Epoch 4421, Loss: 2.5855542617136962e-05, Final Batch Loss: 3.7078477816976374e-06\n",
      "Epoch 4422, Loss: 0.00045245938235893846, Final Batch Loss: 0.0004337294667493552\n",
      "Epoch 4423, Loss: 0.00013640098222822417, Final Batch Loss: 1.2111429896322079e-05\n",
      "Epoch 4424, Loss: 1.5483799529647513e-05, Final Batch Loss: 1.6445252413177514e-06\n",
      "Epoch 4425, Loss: 3.8626672903774306e-05, Final Batch Loss: 7.549035217380151e-06\n",
      "Epoch 4426, Loss: 2.7016930289391894e-05, Final Batch Loss: 1.7363174265483394e-05\n",
      "Epoch 4427, Loss: 0.00035712965473067015, Final Batch Loss: 0.0003118189924862236\n",
      "Epoch 4428, Loss: 7.448496216966305e-05, Final Batch Loss: 2.9907636417192407e-05\n",
      "Epoch 4429, Loss: 5.244174553808989e-05, Final Batch Loss: 4.488787817535922e-05\n",
      "Epoch 4430, Loss: 0.0001449825067538768, Final Batch Loss: 9.658622002461925e-05\n",
      "Epoch 4431, Loss: 0.03105320966551517, Final Batch Loss: 1.1613580682023894e-05\n",
      "Epoch 4432, Loss: 0.0006052479075151496, Final Batch Loss: 7.986433774931356e-05\n",
      "Epoch 4433, Loss: 0.00040798635745886713, Final Batch Loss: 0.0003540505131240934\n",
      "Epoch 4434, Loss: 4.095137683179928e-05, Final Batch Loss: 2.9795064619975165e-05\n",
      "Epoch 4435, Loss: 0.0001181174156954512, Final Batch Loss: 5.6088974815793335e-05\n",
      "Epoch 4436, Loss: 4.1111257814918645e-05, Final Batch Loss: 2.602545100671705e-05\n",
      "Epoch 4437, Loss: 0.000151685233504395, Final Batch Loss: 0.00013936744653619826\n",
      "Epoch 4438, Loss: 7.529227696068119e-05, Final Batch Loss: 2.5733983420650475e-05\n",
      "Epoch 4439, Loss: 0.00027867423432326177, Final Batch Loss: 1.0152632057724986e-05\n",
      "Epoch 4440, Loss: 0.00010952573938993737, Final Batch Loss: 4.1508297726977617e-05\n",
      "Epoch 4441, Loss: 0.0003018977149622515, Final Batch Loss: 0.00020587584003806114\n",
      "Epoch 4442, Loss: 0.00010723077502916567, Final Batch Loss: 7.013628055574372e-05\n",
      "Epoch 4443, Loss: 9.810799201659393e-05, Final Batch Loss: 2.9723034458584152e-05\n",
      "Epoch 4444, Loss: 9.173782746074721e-05, Final Batch Loss: 1.7297097656410187e-05\n",
      "Epoch 4445, Loss: 0.00044235675886739045, Final Batch Loss: 0.00029071225435473025\n",
      "Epoch 4446, Loss: 0.00023832309580029687, Final Batch Loss: 1.0524897334107663e-05\n",
      "Epoch 4447, Loss: 4.6734219722566195e-05, Final Batch Loss: 1.8370070392847992e-05\n",
      "Epoch 4448, Loss: 0.00019959191558882594, Final Batch Loss: 0.00018172917771153152\n",
      "Epoch 4449, Loss: 4.2723073420347646e-05, Final Batch Loss: 2.1242985894787125e-05\n",
      "Epoch 4450, Loss: 3.390782330825459e-05, Final Batch Loss: 1.7913653209689073e-05\n",
      "Epoch 4451, Loss: 2.246230997116072e-05, Final Batch Loss: 1.0207320883637294e-05\n",
      "Epoch 4452, Loss: 0.0003065064884140156, Final Batch Loss: 7.423728675348684e-05\n",
      "Epoch 4453, Loss: 7.060887855914189e-05, Final Batch Loss: 8.826204975775909e-06\n",
      "Epoch 4454, Loss: 0.0007202308333944529, Final Batch Loss: 0.0004832110716961324\n",
      "Epoch 4455, Loss: 5.9882347159145866e-05, Final Batch Loss: 7.794163138896693e-06\n",
      "Epoch 4456, Loss: 0.00036436800110095646, Final Batch Loss: 0.00035824289079755545\n",
      "Epoch 4457, Loss: 6.158529140520841e-05, Final Batch Loss: 2.4036828108364716e-05\n",
      "Epoch 4458, Loss: 5.533818512049038e-05, Final Batch Loss: 2.0015779227833264e-05\n",
      "Epoch 4459, Loss: 0.00013201368710724637, Final Batch Loss: 9.645111276768148e-05\n",
      "Epoch 4460, Loss: 5.5302596592810005e-05, Final Batch Loss: 2.906824738602154e-05\n",
      "Epoch 4461, Loss: 5.475057514559012e-05, Final Batch Loss: 3.520896643749438e-05\n",
      "Epoch 4462, Loss: 3.976690732088173e-05, Final Batch Loss: 1.0067110451927874e-05\n",
      "Epoch 4463, Loss: 2.1951932922092965e-05, Final Batch Loss: 6.330064479698194e-06\n",
      "Epoch 4464, Loss: 8.895795690477826e-05, Final Batch Loss: 4.256322426954284e-05\n",
      "Epoch 4465, Loss: 5.082488860352896e-05, Final Batch Loss: 2.7187119485461153e-05\n",
      "Epoch 4466, Loss: 8.366742986254394e-05, Final Batch Loss: 6.550659600179642e-05\n",
      "Epoch 4467, Loss: 5.8980171615985455e-05, Final Batch Loss: 5.28147984368843e-06\n",
      "Epoch 4468, Loss: 4.32666665801662e-05, Final Batch Loss: 1.5201673704723362e-05\n",
      "Epoch 4469, Loss: 5.6907958423835225e-05, Final Batch Loss: 1.810824869608041e-05\n",
      "Epoch 4470, Loss: 0.00042975936958100647, Final Batch Loss: 5.499769758898765e-05\n",
      "Epoch 4471, Loss: 0.0003804323605436366, Final Batch Loss: 1.5463265299331397e-06\n",
      "Epoch 4472, Loss: 1.7189434402098414e-05, Final Batch Loss: 9.466765732213389e-06\n",
      "Epoch 4473, Loss: 0.00038519976442330517, Final Batch Loss: 5.0316393753746524e-05\n",
      "Epoch 4474, Loss: 1.3695429515792057e-05, Final Batch Loss: 3.482872671156656e-06\n",
      "Epoch 4475, Loss: 4.903305489278864e-05, Final Batch Loss: 2.521612259442918e-06\n",
      "Epoch 4476, Loss: 2.777008512566681e-05, Final Batch Loss: 7.012782134552253e-06\n",
      "Epoch 4477, Loss: 0.0004203584758215584, Final Batch Loss: 6.302679685177281e-05\n",
      "Epoch 4478, Loss: 0.00015958603125909576, Final Batch Loss: 6.539173227793071e-06\n",
      "Epoch 4479, Loss: 4.8540565330768004e-05, Final Batch Loss: 3.548635504557751e-05\n",
      "Epoch 4480, Loss: 3.5775827200268395e-05, Final Batch Loss: 1.9079978301306255e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4481, Loss: 3.750622818188276e-05, Final Batch Loss: 2.993911948578898e-05\n",
      "Epoch 4482, Loss: 5.248095840215683e-05, Final Batch Loss: 8.972405339591205e-06\n",
      "Epoch 4483, Loss: 2.542944412198267e-05, Final Batch Loss: 2.618280177557608e-06\n",
      "Epoch 4484, Loss: 1.9624931155703962e-05, Final Batch Loss: 1.4147342881187797e-05\n",
      "Epoch 4485, Loss: 0.00016883824764590827, Final Batch Loss: 2.0122538444411475e-06\n",
      "Epoch 4486, Loss: 0.0004063180263074173, Final Batch Loss: 7.034805548755685e-06\n",
      "Epoch 4487, Loss: 3.382364957360551e-05, Final Batch Loss: 6.1395421653287485e-06\n",
      "Epoch 4488, Loss: 5.1444592372718034e-05, Final Batch Loss: 2.3614225028723013e-06\n",
      "Epoch 4489, Loss: 1.3787410580334836e-05, Final Batch Loss: 1.8737293885351392e-06\n",
      "Epoch 4490, Loss: 5.9424477512948215e-05, Final Batch Loss: 4.332981916377321e-05\n",
      "Epoch 4491, Loss: 4.2568108256091364e-05, Final Batch Loss: 2.8918317184434272e-05\n",
      "Epoch 4492, Loss: 3.731547622010112e-05, Final Batch Loss: 1.706212970020715e-05\n",
      "Epoch 4493, Loss: 0.00035197537908970844, Final Batch Loss: 0.0003411377256270498\n",
      "Epoch 4494, Loss: 6.625560490647331e-05, Final Batch Loss: 1.358119334327057e-05\n",
      "Epoch 4495, Loss: 0.0003516495562507771, Final Batch Loss: 0.00023925252025946975\n",
      "Epoch 4496, Loss: 5.955352753517218e-05, Final Batch Loss: 3.7319281545933336e-05\n",
      "Epoch 4497, Loss: 4.949296453560237e-05, Final Batch Loss: 4.042551518068649e-05\n",
      "Epoch 4498, Loss: 0.00015162537420110311, Final Batch Loss: 3.026593003596645e-05\n",
      "Epoch 4499, Loss: 8.362992866750574e-05, Final Batch Loss: 7.132144673960283e-05\n",
      "Epoch 4500, Loss: 5.7140834542224184e-05, Final Batch Loss: 2.9735892894677818e-05\n",
      "Epoch 4501, Loss: 1.0329505812478601e-05, Final Batch Loss: 1.8628131783771096e-06\n",
      "Epoch 4502, Loss: 0.00022203945445653517, Final Batch Loss: 0.00020446680719032884\n",
      "Epoch 4503, Loss: 0.00028172219390398823, Final Batch Loss: 0.00022502962383441627\n",
      "Epoch 4504, Loss: 1.8421100321575068e-05, Final Batch Loss: 8.16810097603593e-06\n",
      "Epoch 4505, Loss: 0.00024193237368308473, Final Batch Loss: 0.00022429590171668679\n",
      "Epoch 4506, Loss: 2.3024558458928368e-05, Final Batch Loss: 3.4208185297757154e-06\n",
      "Epoch 4507, Loss: 3.436668521317188e-05, Final Batch Loss: 7.93577783042565e-06\n",
      "Epoch 4508, Loss: 8.018248990993015e-05, Final Batch Loss: 2.5752251531230286e-05\n",
      "Epoch 4509, Loss: 2.3902643079054542e-05, Final Batch Loss: 7.558017387054861e-06\n",
      "Epoch 4510, Loss: 0.0001400340515829157, Final Batch Loss: 4.1059302020585164e-05\n",
      "Epoch 4511, Loss: 4.934851676807739e-05, Final Batch Loss: 1.921601506182924e-05\n",
      "Epoch 4512, Loss: 2.238305796709028e-05, Final Batch Loss: 1.4892716535541695e-05\n",
      "Epoch 4513, Loss: 5.22270629517152e-05, Final Batch Loss: 4.63838005089201e-05\n",
      "Epoch 4514, Loss: 1.535612364023109e-05, Final Batch Loss: 8.845044249028433e-06\n",
      "Epoch 4515, Loss: 4.187041304248851e-05, Final Batch Loss: 2.8065242076991126e-05\n",
      "Epoch 4516, Loss: 0.00027921701257582754, Final Batch Loss: 0.00023908527509775013\n",
      "Epoch 4517, Loss: 0.000221783178858459, Final Batch Loss: 0.0001869102707132697\n",
      "Epoch 4518, Loss: 0.0013509314935618022, Final Batch Loss: 4.545455794868758e-06\n",
      "Epoch 4519, Loss: 6.264694638957735e-05, Final Batch Loss: 2.213982770626899e-05\n",
      "Epoch 4520, Loss: 4.731325157081301e-05, Final Batch Loss: 3.2368936899729306e-06\n",
      "Epoch 4521, Loss: 7.755667184028425e-05, Final Batch Loss: 1.8149353309127036e-06\n",
      "Epoch 4522, Loss: 4.5424043491948396e-05, Final Batch Loss: 2.5583096430636942e-05\n",
      "Epoch 4523, Loss: 0.003532097165589221, Final Batch Loss: 1.35791051434353e-05\n",
      "Epoch 4524, Loss: 0.00015793551983733778, Final Batch Loss: 0.00015041349979583174\n",
      "Epoch 4525, Loss: 0.00034373054586467333, Final Batch Loss: 0.00028957281028851867\n",
      "Epoch 4526, Loss: 2.4164142359950347e-05, Final Batch Loss: 1.3121166375640314e-06\n",
      "Epoch 4527, Loss: 0.00018799931899593503, Final Batch Loss: 3.571968818505411e-06\n",
      "Epoch 4528, Loss: 1.0141568736798945e-05, Final Batch Loss: 2.736664328040206e-06\n",
      "Epoch 4529, Loss: 4.5788476199959405e-05, Final Batch Loss: 2.394885268586222e-05\n",
      "Epoch 4530, Loss: 0.00011359931704646442, Final Batch Loss: 9.378155664307997e-05\n",
      "Epoch 4531, Loss: 3.852428744721692e-05, Final Batch Loss: 9.290708476328291e-06\n",
      "Epoch 4532, Loss: 7.146841835492523e-05, Final Batch Loss: 7.781815838825423e-06\n",
      "Epoch 4533, Loss: 0.0002589361356513109, Final Batch Loss: 0.00022338121198117733\n",
      "Epoch 4534, Loss: 6.053881861589616e-05, Final Batch Loss: 4.976859418093227e-05\n",
      "Epoch 4535, Loss: 8.80692527971405e-06, Final Batch Loss: 3.294051339253201e-06\n",
      "Epoch 4536, Loss: 0.0001740849438647274, Final Batch Loss: 0.00012396721285767853\n",
      "Epoch 4537, Loss: 0.00011197044022992486, Final Batch Loss: 0.00010294892126694322\n",
      "Epoch 4538, Loss: 0.0001325941066170344, Final Batch Loss: 2.8295851734583266e-05\n",
      "Epoch 4539, Loss: 3.305359132355079e-05, Final Batch Loss: 1.970416087715421e-05\n",
      "Epoch 4540, Loss: 0.0002978091888508061, Final Batch Loss: 0.00027385252178646624\n",
      "Epoch 4541, Loss: 4.0782913856673986e-05, Final Batch Loss: 2.0690053133876063e-05\n",
      "Epoch 4542, Loss: 1.736144895403413e-05, Final Batch Loss: 2.562731424404774e-06\n",
      "Epoch 4543, Loss: 1.663064267631853e-05, Final Batch Loss: 1.227833672601264e-05\n",
      "Epoch 4544, Loss: 4.775056186190341e-05, Final Batch Loss: 2.1297122657415457e-05\n",
      "Epoch 4545, Loss: 0.00012993428617846803, Final Batch Loss: 0.00012583128409460187\n",
      "Epoch 4546, Loss: 2.312213700861321e-05, Final Batch Loss: 1.576363320054952e-05\n",
      "Epoch 4547, Loss: 3.1556283829559106e-05, Final Batch Loss: 4.707601874542888e-06\n",
      "Epoch 4548, Loss: 4.248098412062973e-05, Final Batch Loss: 2.790296457533259e-05\n",
      "Epoch 4549, Loss: 0.00012436047381925164, Final Batch Loss: 0.000120316501124762\n",
      "Epoch 4550, Loss: 8.145984611473978e-05, Final Batch Loss: 4.36317604908254e-05\n",
      "Epoch 4551, Loss: 0.0010187190782744437, Final Batch Loss: 0.0008983065490610898\n",
      "Epoch 4552, Loss: 8.460199751425534e-06, Final Batch Loss: 4.26250153395813e-06\n",
      "Epoch 4553, Loss: 0.00014507711603073403, Final Batch Loss: 8.811997395241633e-05\n",
      "Epoch 4554, Loss: 2.1577136976702604e-05, Final Batch Loss: 1.6919735571718775e-05\n",
      "Epoch 4555, Loss: 5.604069338005502e-05, Final Batch Loss: 2.0273439076845534e-05\n",
      "Epoch 4556, Loss: 0.0002386491614743136, Final Batch Loss: 7.184559217421338e-05\n",
      "Epoch 4557, Loss: 2.6182735837210203e-05, Final Batch Loss: 1.9474944565445185e-05\n",
      "Epoch 4558, Loss: 0.0013749335194006562, Final Batch Loss: 0.0008497911621816456\n",
      "Epoch 4559, Loss: 1.3821247080159083e-05, Final Batch Loss: 1.690705971668649e-06\n",
      "Epoch 4560, Loss: 6.884801223350223e-05, Final Batch Loss: 9.894540198729374e-06\n",
      "Epoch 4561, Loss: 1.7863113043858903e-05, Final Batch Loss: 6.0714396568073425e-06\n",
      "Epoch 4562, Loss: 1.5390153748739976e-05, Final Batch Loss: 3.7162317312322557e-06\n",
      "Epoch 4563, Loss: 0.0001334511580353137, Final Batch Loss: 7.936789188534021e-05\n",
      "Epoch 4564, Loss: 1.4576562534784898e-05, Final Batch Loss: 7.642718628630973e-06\n",
      "Epoch 4565, Loss: 0.00018427617578709032, Final Batch Loss: 0.0001564059784868732\n",
      "Epoch 4566, Loss: 5.162560046301223e-05, Final Batch Loss: 2.5193707188009284e-05\n",
      "Epoch 4567, Loss: 0.00016280887484754203, Final Batch Loss: 4.287091542209964e-06\n",
      "Epoch 4568, Loss: 0.0006613219047721941, Final Batch Loss: 3.083573028561659e-05\n",
      "Epoch 4569, Loss: 4.112849546800135e-05, Final Batch Loss: 5.561279067478608e-06\n",
      "Epoch 4570, Loss: 0.0002015525460592471, Final Batch Loss: 9.426379256183282e-05\n",
      "Epoch 4571, Loss: 3.189577273587929e-05, Final Batch Loss: 2.1834437575307675e-05\n",
      "Epoch 4572, Loss: 0.00024335567286470905, Final Batch Loss: 3.475073754088953e-05\n",
      "Epoch 4573, Loss: 7.138444743759464e-05, Final Batch Loss: 2.5103092411882244e-05\n",
      "Epoch 4574, Loss: 8.359067214769311e-05, Final Batch Loss: 4.1636816604295745e-05\n",
      "Epoch 4575, Loss: 1.9132477063976694e-05, Final Batch Loss: 8.316554158227518e-06\n",
      "Epoch 4576, Loss: 0.030373156012501568, Final Batch Loss: 0.03034931793808937\n",
      "Epoch 4577, Loss: 0.0003413281319808448, Final Batch Loss: 0.0003163485962431878\n",
      "Epoch 4578, Loss: 5.624115055979928e-05, Final Batch Loss: 5.00768146594055e-05\n",
      "Epoch 4579, Loss: 0.00020102382404729724, Final Batch Loss: 0.00016800480079837143\n",
      "Epoch 4580, Loss: 8.563327719457448e-05, Final Batch Loss: 4.9651538574835286e-05\n",
      "Epoch 4581, Loss: 2.580352702352684e-05, Final Batch Loss: 8.719922334421426e-06\n",
      "Epoch 4582, Loss: 3.225478394597303e-05, Final Batch Loss: 2.5161210942314938e-05\n",
      "Epoch 4583, Loss: 0.00013653547284775414, Final Batch Loss: 0.0001179633618448861\n",
      "Epoch 4584, Loss: 5.2954588682041503e-05, Final Batch Loss: 2.836599924194161e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4585, Loss: 0.0005124849849380553, Final Batch Loss: 4.936239565722644e-05\n",
      "Epoch 4586, Loss: 0.00015936267300276086, Final Batch Loss: 9.161573689198121e-05\n",
      "Epoch 4587, Loss: 0.00027848841637023725, Final Batch Loss: 0.0002593313984107226\n",
      "Epoch 4588, Loss: 0.00010405341163277626, Final Batch Loss: 8.396476187044755e-05\n",
      "Epoch 4589, Loss: 0.00022126010662759654, Final Batch Loss: 1.857684037531726e-05\n",
      "Epoch 4590, Loss: 0.00019170437462889822, Final Batch Loss: 7.680432645429391e-06\n",
      "Epoch 4591, Loss: 0.0004952515701006632, Final Batch Loss: 2.94144956569653e-05\n",
      "Epoch 4592, Loss: 5.125539064465556e-05, Final Batch Loss: 3.9200902392622083e-05\n",
      "Epoch 4593, Loss: 0.000131418630189728, Final Batch Loss: 4.483872908167541e-05\n",
      "Epoch 4594, Loss: 0.00047289239591918886, Final Batch Loss: 0.00045310327550396323\n",
      "Epoch 4595, Loss: 8.760347554925829e-05, Final Batch Loss: 3.860594006255269e-05\n",
      "Epoch 4596, Loss: 0.00016311773651978, Final Batch Loss: 0.00012258662900421768\n",
      "Epoch 4597, Loss: 0.00011508115858305246, Final Batch Loss: 3.983092028647661e-05\n",
      "Epoch 4598, Loss: 0.00011545889174158219, Final Batch Loss: 9.575314470566809e-05\n",
      "Epoch 4599, Loss: 0.00020879224302916555, Final Batch Loss: 8.73722729011206e-06\n",
      "Epoch 4600, Loss: 0.0003327853810333181, Final Batch Loss: 4.0450326196150854e-05\n",
      "Epoch 4601, Loss: 0.00031887373188510537, Final Batch Loss: 0.00019850778335239738\n",
      "Epoch 4602, Loss: 0.0001140761787610245, Final Batch Loss: 8.725740372028667e-06\n",
      "Epoch 4603, Loss: 0.0022090826169005595, Final Batch Loss: 0.0021904483437538147\n",
      "Epoch 4604, Loss: 8.638998133392306e-05, Final Batch Loss: 9.974112799682189e-06\n",
      "Epoch 4605, Loss: 0.0007208236056612805, Final Batch Loss: 0.00016329642676282674\n",
      "Epoch 4606, Loss: 7.17410530342022e-05, Final Batch Loss: 5.826348933624104e-05\n",
      "Epoch 4607, Loss: 0.00015146239820751362, Final Batch Loss: 5.471022814163007e-05\n",
      "Epoch 4608, Loss: 0.00010010781079472508, Final Batch Loss: 7.02174220350571e-05\n",
      "Epoch 4609, Loss: 7.130471021810081e-05, Final Batch Loss: 3.0193858037819155e-05\n",
      "Epoch 4610, Loss: 7.68222744227387e-05, Final Batch Loss: 3.543412094586529e-05\n",
      "Epoch 4611, Loss: 1.8771444047160912e-05, Final Batch Loss: 7.98794917500345e-06\n",
      "Epoch 4612, Loss: 3.0369212254299782e-05, Final Batch Loss: 1.9530449208104983e-05\n",
      "Epoch 4613, Loss: 3.400679270271212e-05, Final Batch Loss: 1.833727401390206e-05\n",
      "Epoch 4614, Loss: 3.847014522762038e-05, Final Batch Loss: 2.129466702172067e-05\n",
      "Epoch 4615, Loss: 0.00018646755461304565, Final Batch Loss: 0.00018061132868751884\n",
      "Epoch 4616, Loss: 0.00011829930735984817, Final Batch Loss: 5.6323318858630955e-05\n",
      "Epoch 4617, Loss: 6.746300687154871e-05, Final Batch Loss: 6.0322385252220556e-05\n",
      "Epoch 4618, Loss: 5.869660708412994e-05, Final Batch Loss: 2.1336980353225954e-05\n",
      "Epoch 4619, Loss: 0.0001593927590874955, Final Batch Loss: 6.537855369970202e-05\n",
      "Epoch 4620, Loss: 6.423323429771699e-05, Final Batch Loss: 1.2958735169377178e-05\n",
      "Epoch 4621, Loss: 4.2331538679718506e-05, Final Batch Loss: 3.851441579172388e-05\n",
      "Epoch 4622, Loss: 0.00010481952631380409, Final Batch Loss: 5.982537550153211e-05\n",
      "Epoch 4623, Loss: 2.647140354383737e-05, Final Batch Loss: 9.333341949968599e-06\n",
      "Epoch 4624, Loss: 2.0746462269016774e-05, Final Batch Loss: 7.1658491833659355e-06\n",
      "Epoch 4625, Loss: 8.487798186251894e-05, Final Batch Loss: 2.7627491363091394e-05\n",
      "Epoch 4626, Loss: 0.00010955147808999754, Final Batch Loss: 6.214284076122567e-05\n",
      "Epoch 4627, Loss: 0.0001041393079503905, Final Batch Loss: 5.2000053983647376e-05\n",
      "Epoch 4628, Loss: 0.00023970302572706714, Final Batch Loss: 0.00020777499594260007\n",
      "Epoch 4629, Loss: 0.00010997182835126296, Final Batch Loss: 7.714353705523536e-05\n",
      "Epoch 4630, Loss: 0.0001075171385309659, Final Batch Loss: 6.752577610313892e-05\n",
      "Epoch 4631, Loss: 1.3318798210093519e-05, Final Batch Loss: 7.306094630621374e-06\n",
      "Epoch 4632, Loss: 1.2421703104337212e-05, Final Batch Loss: 2.6560446713119745e-06\n",
      "Epoch 4633, Loss: 0.00018978232765221037, Final Batch Loss: 3.107266456936486e-05\n",
      "Epoch 4634, Loss: 9.715903797768988e-05, Final Batch Loss: 5.934984437772073e-05\n",
      "Epoch 4635, Loss: 0.00013955560643807985, Final Batch Loss: 0.00011543453729245812\n",
      "Epoch 4636, Loss: 6.407868022506591e-05, Final Batch Loss: 3.668266799650155e-05\n",
      "Epoch 4637, Loss: 9.045403930940665e-05, Final Batch Loss: 4.927222107653506e-05\n",
      "Epoch 4638, Loss: 3.0035851523280144e-05, Final Batch Loss: 1.376047839585226e-05\n",
      "Epoch 4639, Loss: 6.099206075305119e-05, Final Batch Loss: 4.08625892305281e-05\n",
      "Epoch 4640, Loss: 7.740019282209687e-05, Final Batch Loss: 2.824814146151766e-06\n",
      "Epoch 4641, Loss: 9.639975542086177e-05, Final Batch Loss: 2.8381557058310136e-05\n",
      "Epoch 4642, Loss: 6.489888983196579e-05, Final Batch Loss: 3.259870209149085e-05\n",
      "Epoch 4643, Loss: 0.0002252926460641902, Final Batch Loss: 0.000193049170775339\n",
      "Epoch 4644, Loss: 0.00015392789737234125, Final Batch Loss: 1.4504280443361495e-05\n",
      "Epoch 4645, Loss: 0.00027178354503121227, Final Batch Loss: 0.0001796837750589475\n",
      "Epoch 4646, Loss: 1.4757112694496755e-05, Final Batch Loss: 4.375963726488408e-06\n",
      "Epoch 4647, Loss: 5.489611157827312e-05, Final Batch Loss: 4.355580313131213e-05\n",
      "Epoch 4648, Loss: 7.41092771932017e-05, Final Batch Loss: 4.883015208179131e-06\n",
      "Epoch 4649, Loss: 4.242000068188645e-05, Final Batch Loss: 2.3887992938398384e-05\n",
      "Epoch 4650, Loss: 8.79622018601367e-05, Final Batch Loss: 3.4426191177772125e-06\n",
      "Epoch 4651, Loss: 2.8881039270345354e-05, Final Batch Loss: 6.46088528810651e-06\n",
      "Epoch 4652, Loss: 0.0001755372213665396, Final Batch Loss: 0.00010049979027826339\n",
      "Epoch 4653, Loss: 3.080269289057469e-05, Final Batch Loss: 9.066913662536535e-06\n",
      "Epoch 4654, Loss: 1.2349762528174324e-05, Final Batch Loss: 2.3211682673718315e-06\n",
      "Epoch 4655, Loss: 7.944266690174118e-05, Final Batch Loss: 4.2461473640287295e-05\n",
      "Epoch 4656, Loss: 3.443658169999253e-05, Final Batch Loss: 2.181232594011817e-05\n",
      "Epoch 4657, Loss: 7.496551415897557e-05, Final Batch Loss: 4.376778178993845e-06\n",
      "Epoch 4658, Loss: 0.00012837698523071595, Final Batch Loss: 5.290882472763769e-05\n",
      "Epoch 4659, Loss: 0.00026822113431990147, Final Batch Loss: 0.00018467943300493062\n",
      "Epoch 4660, Loss: 3.400991863600211e-05, Final Batch Loss: 9.222659173246939e-06\n",
      "Epoch 4661, Loss: 0.0041555302414053585, Final Batch Loss: 3.413820741116069e-05\n",
      "Epoch 4662, Loss: 7.509712031605886e-05, Final Batch Loss: 6.991195550654083e-05\n",
      "Epoch 4663, Loss: 4.3130351059517125e-05, Final Batch Loss: 1.8913037820311729e-06\n",
      "Epoch 4664, Loss: 5.847272404935211e-05, Final Batch Loss: 5.056100053479895e-05\n",
      "Epoch 4665, Loss: 0.0002477340240147896, Final Batch Loss: 3.4502292692195624e-05\n",
      "Epoch 4666, Loss: 8.251938425019034e-06, Final Batch Loss: 2.292605358888977e-06\n",
      "Epoch 4667, Loss: 4.0603172237752005e-06, Final Batch Loss: 2.631752295201295e-06\n",
      "Epoch 4668, Loss: 0.00032023749372456223, Final Batch Loss: 8.939967665355653e-05\n",
      "Epoch 4669, Loss: 1.1806582733697724e-05, Final Batch Loss: 3.7630916267517023e-06\n",
      "Epoch 4670, Loss: 9.386131569044665e-05, Final Batch Loss: 3.807453322224319e-05\n",
      "Epoch 4671, Loss: 0.00012297751709411386, Final Batch Loss: 1.7965039660339244e-05\n",
      "Epoch 4672, Loss: 2.0320202565926593e-05, Final Batch Loss: 1.1249516319367103e-05\n",
      "Epoch 4673, Loss: 7.13207118678838e-05, Final Batch Loss: 4.731609806185588e-05\n",
      "Epoch 4674, Loss: 2.899453102145344e-05, Final Batch Loss: 7.502632797695696e-06\n",
      "Epoch 4675, Loss: 0.00010407213449070696, Final Batch Loss: 7.45875331631396e-06\n",
      "Epoch 4676, Loss: 6.0310806475172285e-05, Final Batch Loss: 1.111238179873908e-05\n",
      "Epoch 4677, Loss: 3.9179014493129216e-05, Final Batch Loss: 1.647655517444946e-05\n",
      "Epoch 4678, Loss: 1.9892734485438268e-05, Final Batch Loss: 1.8388374883215874e-05\n",
      "Epoch 4679, Loss: 6.450008004321717e-05, Final Batch Loss: 4.166781218373217e-05\n",
      "Epoch 4680, Loss: 9.356014015793335e-05, Final Batch Loss: 8.553912266506813e-06\n",
      "Epoch 4681, Loss: 3.291493658252875e-05, Final Batch Loss: 2.7883099392056465e-05\n",
      "Epoch 4682, Loss: 0.00015451292347279377, Final Batch Loss: 2.173187749576755e-05\n",
      "Epoch 4683, Loss: 2.439230684103677e-05, Final Batch Loss: 1.270482698600972e-05\n",
      "Epoch 4684, Loss: 0.00026771077637022245, Final Batch Loss: 0.0002631666138768196\n",
      "Epoch 4685, Loss: 0.00019349697868165094, Final Batch Loss: 0.0001661172864260152\n",
      "Epoch 4686, Loss: 2.9706575332966167e-05, Final Batch Loss: 4.436261406226549e-06\n",
      "Epoch 4687, Loss: 8.959707884059753e-06, Final Batch Loss: 3.866957285936223e-06\n",
      "Epoch 4688, Loss: 1.4668639323645039e-05, Final Batch Loss: 1.0575031410553493e-05\n",
      "Epoch 4689, Loss: 4.24622458012891e-05, Final Batch Loss: 6.194569323270116e-06\n",
      "Epoch 4690, Loss: 7.87598892202368e-05, Final Batch Loss: 6.64984472678043e-05\n",
      "Epoch 4691, Loss: 9.033861033458379e-06, Final Batch Loss: 9.485904683970148e-07\n",
      "Epoch 4692, Loss: 2.0979171495127957e-05, Final Batch Loss: 8.137719305523206e-06\n",
      "Epoch 4693, Loss: 3.519645360938739e-05, Final Batch Loss: 9.190174750983715e-06\n",
      "Epoch 4694, Loss: 4.2260366683422035e-05, Final Batch Loss: 6.438900186367391e-07\n",
      "Epoch 4695, Loss: 6.719574685121188e-06, Final Batch Loss: 2.033216333074961e-06\n",
      "Epoch 4696, Loss: 6.6514916397864e-05, Final Batch Loss: 5.363950549508445e-05\n",
      "Epoch 4697, Loss: 0.00012213287845952436, Final Batch Loss: 6.599388143513352e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4698, Loss: 7.908591396699194e-05, Final Batch Loss: 5.5331816838588566e-05\n",
      "Epoch 4699, Loss: 4.1686945223773364e-05, Final Batch Loss: 1.36589269459364e-05\n",
      "Epoch 4700, Loss: 0.0002298382764820417, Final Batch Loss: 5.951545517746126e-06\n",
      "Epoch 4701, Loss: 3.343206026329426e-05, Final Batch Loss: 8.82993026607437e-06\n",
      "Epoch 4702, Loss: 8.414204057771713e-05, Final Batch Loss: 6.440462311729789e-05\n",
      "Epoch 4703, Loss: 1.2391903965180973e-05, Final Batch Loss: 2.4738869797147345e-06\n",
      "Epoch 4704, Loss: 5.7939006183005404e-05, Final Batch Loss: 7.166268005676102e-06\n",
      "Epoch 4705, Loss: 9.970246355806012e-05, Final Batch Loss: 7.450005068676546e-05\n",
      "Epoch 4706, Loss: 0.00026684862314141355, Final Batch Loss: 4.693632581620477e-05\n",
      "Epoch 4707, Loss: 2.066684373858152e-05, Final Batch Loss: 8.100660124910064e-06\n",
      "Epoch 4708, Loss: 0.00019373158102098387, Final Batch Loss: 0.00018573414126876742\n",
      "Epoch 4709, Loss: 4.0760126012173714e-05, Final Batch Loss: 3.5612978535937145e-05\n",
      "Epoch 4710, Loss: 2.5764666133909486e-05, Final Batch Loss: 2.031053554674145e-05\n",
      "Epoch 4711, Loss: 1.383890662509657e-05, Final Batch Loss: 1.1544994777068496e-05\n",
      "Epoch 4712, Loss: 8.645445177535294e-06, Final Batch Loss: 6.512215350085171e-06\n",
      "Epoch 4713, Loss: 5.870550739928149e-05, Final Batch Loss: 2.091807618853636e-05\n",
      "Epoch 4714, Loss: 9.410179336555302e-05, Final Batch Loss: 5.4096413805382326e-05\n",
      "Epoch 4715, Loss: 0.00013587331250164425, Final Batch Loss: 0.00013435987057164311\n",
      "Epoch 4716, Loss: 4.8371859520557337e-05, Final Batch Loss: 3.2602711144136265e-05\n",
      "Epoch 4717, Loss: 5.179538970878639e-05, Final Batch Loss: 4.701189482148038e-07\n",
      "Epoch 4718, Loss: 8.259628998530388e-06, Final Batch Loss: 6.575486622750759e-06\n",
      "Epoch 4719, Loss: 3.5472110539558344e-05, Final Batch Loss: 2.521723035897594e-05\n",
      "Epoch 4720, Loss: 0.00035803255832433933, Final Batch Loss: 8.478354175167624e-06\n",
      "Epoch 4721, Loss: 8.443501656074659e-06, Final Batch Loss: 2.3066352241585264e-06\n",
      "Epoch 4722, Loss: 0.0003297872108305455, Final Batch Loss: 3.93950267607579e-06\n",
      "Epoch 4723, Loss: 3.487229059828678e-05, Final Batch Loss: 2.046636836894322e-06\n",
      "Epoch 4724, Loss: 0.0003170665413563256, Final Batch Loss: 0.00030728208366781473\n",
      "Epoch 4725, Loss: 3.865987287099415e-05, Final Batch Loss: 1.6167866760952165e-06\n",
      "Epoch 4726, Loss: 0.00010852192372112768, Final Batch Loss: 9.761167166288942e-05\n",
      "Epoch 4727, Loss: 2.8069448489986826e-05, Final Batch Loss: 1.9529727069311775e-05\n",
      "Epoch 4728, Loss: 7.408146484522149e-05, Final Batch Loss: 2.7775007765740156e-05\n",
      "Epoch 4729, Loss: 0.00047391502516802575, Final Batch Loss: 1.1987947345915018e-06\n",
      "Epoch 4730, Loss: 5.667185178026557e-06, Final Batch Loss: 2.4175678845494986e-06\n",
      "Epoch 4731, Loss: 4.069767828696058e-05, Final Batch Loss: 6.887609288241947e-06\n",
      "Epoch 4732, Loss: 7.705689142767369e-06, Final Batch Loss: 7.060064604047511e-07\n",
      "Epoch 4733, Loss: 7.155814364523394e-05, Final Batch Loss: 6.289219163591042e-05\n",
      "Epoch 4734, Loss: 7.78770800025086e-06, Final Batch Loss: 3.842237674689386e-06\n",
      "Epoch 4735, Loss: 3.1177725077213836e-05, Final Batch Loss: 1.9089504803559976e-06\n",
      "Epoch 4736, Loss: 0.00010139197001990397, Final Batch Loss: 8.478589006699622e-05\n",
      "Epoch 4737, Loss: 6.844198833277915e-05, Final Batch Loss: 5.201612657401711e-05\n",
      "Epoch 4738, Loss: 8.806521009319113e-06, Final Batch Loss: 7.807223028066801e-07\n",
      "Epoch 4739, Loss: 1.525100742583163e-05, Final Batch Loss: 9.628993211663328e-07\n",
      "Epoch 4740, Loss: 3.306982125650393e-05, Final Batch Loss: 5.260209036350716e-06\n",
      "Epoch 4741, Loss: 0.006099006618569547, Final Batch Loss: 2.879175553971436e-06\n",
      "Epoch 4742, Loss: 3.6339382859296165e-05, Final Batch Loss: 2.8167663913336582e-05\n",
      "Epoch 4743, Loss: 0.0001363149860935664, Final Batch Loss: 1.9768415313592413e-06\n",
      "Epoch 4744, Loss: 2.0250230306828598e-05, Final Batch Loss: 7.958366836646746e-07\n",
      "Epoch 4745, Loss: 3.371959746800712e-05, Final Batch Loss: 5.130475528858369e-06\n",
      "Epoch 4746, Loss: 3.400061268621357e-05, Final Batch Loss: 2.7742780730477534e-05\n",
      "Epoch 4747, Loss: 0.0003226681913020002, Final Batch Loss: 0.00031894087442196906\n",
      "Epoch 4748, Loss: 0.000163836230058223, Final Batch Loss: 4.923097731079906e-05\n",
      "Epoch 4749, Loss: 8.053625037973688e-06, Final Batch Loss: 6.339914762065746e-06\n",
      "Epoch 4750, Loss: 1.7619136087887455e-05, Final Batch Loss: 2.7441774363978766e-06\n",
      "Epoch 4751, Loss: 7.137204465834657e-05, Final Batch Loss: 6.363349530147389e-05\n",
      "Epoch 4752, Loss: 0.00018763116213449393, Final Batch Loss: 0.00018429789633955806\n",
      "Epoch 4753, Loss: 0.0002490741153451381, Final Batch Loss: 2.2897102098795585e-05\n",
      "Epoch 4754, Loss: 4.580575614454574e-05, Final Batch Loss: 4.715382146969205e-06\n",
      "Epoch 4755, Loss: 3.004707377840532e-05, Final Batch Loss: 8.306865311169531e-06\n",
      "Epoch 4756, Loss: 2.7435745323600713e-05, Final Batch Loss: 7.923818884592038e-06\n",
      "Epoch 4757, Loss: 2.0480831722125004e-05, Final Batch Loss: 1.905514727695845e-05\n",
      "Epoch 4758, Loss: 0.0005429875552636076, Final Batch Loss: 1.2357002106000436e-06\n",
      "Epoch 4759, Loss: 4.803985143553291e-05, Final Batch Loss: 4.6307104639708996e-05\n",
      "Epoch 4760, Loss: 1.687525627858122e-05, Final Batch Loss: 1.0607078365865164e-05\n",
      "Epoch 4761, Loss: 2.1852034478797577e-05, Final Batch Loss: 9.472911187913269e-06\n",
      "Epoch 4762, Loss: 1.2987218269699952e-05, Final Batch Loss: 6.501757525256835e-06\n",
      "Epoch 4763, Loss: 5.6493856391170993e-05, Final Batch Loss: 6.238122296053916e-06\n",
      "Epoch 4764, Loss: 0.007567071581433993, Final Batch Loss: 0.007547633722424507\n",
      "Epoch 4765, Loss: 7.807927886460675e-06, Final Batch Loss: 5.682886694557965e-06\n",
      "Epoch 4766, Loss: 0.0001142828928095696, Final Batch Loss: 2.0710153876279946e-06\n",
      "Epoch 4767, Loss: 1.1799982075899607e-05, Final Batch Loss: 9.066402526514139e-07\n",
      "Epoch 4768, Loss: 1.578256751599838e-05, Final Batch Loss: 1.9224157767894212e-06\n",
      "Epoch 4769, Loss: 8.340770000359043e-05, Final Batch Loss: 3.861768709612079e-05\n",
      "Epoch 4770, Loss: 0.0002095667805406265, Final Batch Loss: 2.1095838746987283e-06\n",
      "Epoch 4771, Loss: 0.00046624342758150306, Final Batch Loss: 0.0004371637769509107\n",
      "Epoch 4772, Loss: 8.000702405297488e-05, Final Batch Loss: 7.621597615070641e-05\n",
      "Epoch 4773, Loss: 0.0002550615117797861, Final Batch Loss: 1.1307947715977207e-06\n",
      "Epoch 4774, Loss: 7.373520702458336e-06, Final Batch Loss: 4.409031589602819e-06\n",
      "Epoch 4775, Loss: 3.3729973210938624e-05, Final Batch Loss: 3.48536536876054e-06\n",
      "Epoch 4776, Loss: 3.7473670090548694e-05, Final Batch Loss: 1.619429349375423e-05\n",
      "Epoch 4777, Loss: 0.00015038917990750633, Final Batch Loss: 5.082631469122134e-05\n",
      "Epoch 4778, Loss: 7.452169302268885e-05, Final Batch Loss: 3.833849768852815e-05\n",
      "Epoch 4779, Loss: 2.0515765299933264e-05, Final Batch Loss: 1.3591087736131158e-05\n",
      "Epoch 4780, Loss: 8.719624020159245e-05, Final Batch Loss: 6.963280611671507e-06\n",
      "Epoch 4781, Loss: 0.00010610694243951002, Final Batch Loss: 1.4386933798959944e-05\n",
      "Epoch 4782, Loss: 0.00012600969057530165, Final Batch Loss: 5.934372893534601e-05\n",
      "Epoch 4783, Loss: 1.564549711474683e-05, Final Batch Loss: 8.575872925575823e-06\n",
      "Epoch 4784, Loss: 0.00015846061796764843, Final Batch Loss: 1.0091735020978376e-05\n",
      "Epoch 4785, Loss: 3.394087434571702e-05, Final Batch Loss: 2.6213156161247753e-05\n",
      "Epoch 4786, Loss: 1.6809939097583992e-05, Final Batch Loss: 9.69145094131818e-06\n",
      "Epoch 4787, Loss: 8.767613735471969e-06, Final Batch Loss: 9.326561212219531e-07\n",
      "Epoch 4788, Loss: 2.5519183054711903e-05, Final Batch Loss: 6.283830316533567e-06\n",
      "Epoch 4789, Loss: 0.00010831374493136536, Final Batch Loss: 8.650132804177701e-05\n",
      "Epoch 4790, Loss: 0.00016232522466452792, Final Batch Loss: 1.1718781024683267e-05\n",
      "Epoch 4791, Loss: 9.8275827440375e-06, Final Batch Loss: 4.1819071157078724e-06\n",
      "Epoch 4792, Loss: 1.548784985061502e-05, Final Batch Loss: 8.574408639105968e-06\n",
      "Epoch 4793, Loss: 0.00010318891008864739, Final Batch Loss: 9.580642654327676e-05\n",
      "Epoch 4794, Loss: 3.045230005227495e-05, Final Batch Loss: 1.6742702428018674e-05\n",
      "Epoch 4795, Loss: 1.3970131590212986e-05, Final Batch Loss: 1.690691647127096e-06\n",
      "Epoch 4796, Loss: 1.613940617062326e-05, Final Batch Loss: 1.2824464647565037e-05\n",
      "Epoch 4797, Loss: 2.9532470762205776e-05, Final Batch Loss: 1.1001767234120052e-05\n",
      "Epoch 4798, Loss: 1.1263358373980736e-05, Final Batch Loss: 4.118169727007626e-06\n",
      "Epoch 4799, Loss: 2.952649583676248e-05, Final Batch Loss: 4.509547125053359e-06\n",
      "Epoch 4800, Loss: 4.7268226353480713e-05, Final Batch Loss: 4.467929102247581e-05\n",
      "Epoch 4801, Loss: 0.0006139478500699624, Final Batch Loss: 0.00018359198293183\n",
      "Epoch 4802, Loss: 0.0006430934670333954, Final Batch Loss: 0.0006402183789759874\n",
      "Epoch 4803, Loss: 0.001003695055260323, Final Batch Loss: 0.0007999249501153827\n",
      "Epoch 4804, Loss: 6.108866909926292e-05, Final Batch Loss: 3.2734707929193974e-05\n",
      "Epoch 4805, Loss: 0.00019967537809861824, Final Batch Loss: 0.00013464140647556633\n",
      "Epoch 4806, Loss: 1.687511894488125e-05, Final Batch Loss: 1.0059364285552874e-05\n",
      "Epoch 4807, Loss: 3.771971285004838e-05, Final Batch Loss: 1.562267129884276e-06\n",
      "Epoch 4808, Loss: 5.4639302788928035e-05, Final Batch Loss: 1.9383667222427903e-06\n",
      "Epoch 4809, Loss: 1.2880873782705748e-05, Final Batch Loss: 6.060683517716825e-06\n",
      "Epoch 4810, Loss: 2.1661392111127498e-05, Final Batch Loss: 1.7528664102428593e-05\n",
      "Epoch 4811, Loss: 3.060280391764536e-05, Final Batch Loss: 1.2785446870111628e-06\n",
      "Epoch 4812, Loss: 4.425713234468276e-05, Final Batch Loss: 4.3371215724619105e-05\n",
      "Epoch 4813, Loss: 1.6906960809137672e-05, Final Batch Loss: 4.103601895621978e-06\n",
      "Epoch 4814, Loss: 2.2719053959008306e-05, Final Batch Loss: 1.1408610589569435e-06\n",
      "Epoch 4815, Loss: 2.583053628768539e-05, Final Batch Loss: 1.379842433379963e-05\n",
      "Epoch 4816, Loss: 5.407877551988349e-06, Final Batch Loss: 3.3561757390998537e-06\n",
      "Epoch 4817, Loss: 0.0029265470293466933, Final Batch Loss: 4.390505637275055e-05\n",
      "Epoch 4818, Loss: 8.707958841114305e-05, Final Batch Loss: 3.376306631253101e-05\n",
      "Epoch 4819, Loss: 1.4635186744271778e-05, Final Batch Loss: 1.7301517800660804e-06\n",
      "Epoch 4820, Loss: 2.8463392709454638e-05, Final Batch Loss: 2.5219753297278658e-05\n",
      "Epoch 4821, Loss: 3.195673752998118e-05, Final Batch Loss: 3.705769358930411e-06\n",
      "Epoch 4822, Loss: 2.435380201859516e-05, Final Batch Loss: 4.6574264160881285e-06\n",
      "Epoch 4823, Loss: 1.6877536836545914e-05, Final Batch Loss: 7.789802111801691e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4824, Loss: 2.014672281802632e-05, Final Batch Loss: 1.3055443560006097e-05\n",
      "Epoch 4825, Loss: 2.0662340602939366e-05, Final Batch Loss: 1.7966947780223563e-05\n",
      "Epoch 4826, Loss: 0.0061000881032668985, Final Batch Loss: 0.006091856397688389\n",
      "Epoch 4827, Loss: 0.0026374322405899875, Final Batch Loss: 5.5308737501036376e-05\n",
      "Epoch 4828, Loss: 2.1680663849110715e-05, Final Batch Loss: 1.0076949365611654e-05\n",
      "Epoch 4829, Loss: 7.179993735917378e-05, Final Batch Loss: 2.0166246031294577e-05\n",
      "Epoch 4830, Loss: 4.405151867103996e-05, Final Batch Loss: 1.3522655535780359e-05\n",
      "Epoch 4831, Loss: 4.575911361826002e-06, Final Batch Loss: 2.5595174975023838e-06\n",
      "Epoch 4832, Loss: 4.554599308903562e-05, Final Batch Loss: 3.2973803172353655e-05\n",
      "Epoch 4833, Loss: 0.002138729349098867, Final Batch Loss: 0.0021159269381314516\n",
      "Epoch 4834, Loss: 0.00023299525491893291, Final Batch Loss: 8.826333214528859e-05\n",
      "Epoch 4835, Loss: 5.7379805070922885e-05, Final Batch Loss: 9.964777518689516e-07\n",
      "Epoch 4836, Loss: 0.0063881825444696005, Final Batch Loss: 0.006372355856001377\n",
      "Epoch 4837, Loss: 0.0010209718893747777, Final Batch Loss: 0.00021712665329687297\n",
      "Epoch 4838, Loss: 1.9483379674056778e-05, Final Batch Loss: 1.4239062693377491e-05\n",
      "Epoch 4839, Loss: 0.00013780065182800172, Final Batch Loss: 9.006277650769334e-06\n",
      "Epoch 4840, Loss: 2.8231882197360392e-05, Final Batch Loss: 2.593853605503682e-05\n",
      "Epoch 4841, Loss: 1.7096069768740563e-05, Final Batch Loss: 4.7943481149559375e-06\n",
      "Epoch 4842, Loss: 5.799551036034245e-05, Final Batch Loss: 2.8877911972813308e-05\n",
      "Epoch 4843, Loss: 1.5497174445044948e-05, Final Batch Loss: 5.617003353108885e-06\n",
      "Epoch 4844, Loss: 3.0956273803894874e-05, Final Batch Loss: 1.2383095054246951e-05\n",
      "Epoch 4845, Loss: 3.0776353469263995e-05, Final Batch Loss: 7.3591495493019465e-06\n",
      "Epoch 4846, Loss: 5.529835107154213e-05, Final Batch Loss: 4.242527938913554e-05\n",
      "Epoch 4847, Loss: 0.00010118493446498178, Final Batch Loss: 2.682211561477743e-05\n",
      "Epoch 4848, Loss: 0.00010163722436118405, Final Batch Loss: 7.667465979466215e-05\n",
      "Epoch 4849, Loss: 4.5556451368611306e-05, Final Batch Loss: 3.0500519642373547e-05\n",
      "Epoch 4850, Loss: 0.0011961510572291445, Final Batch Loss: 0.0011782838264480233\n",
      "Epoch 4851, Loss: 5.897089886275353e-05, Final Batch Loss: 9.458662134420592e-06\n",
      "Epoch 4852, Loss: 1.235919944519992e-05, Final Batch Loss: 8.712388080311939e-06\n",
      "Epoch 4853, Loss: 6.127704182290472e-06, Final Batch Loss: 2.016437065321952e-06\n",
      "Epoch 4854, Loss: 1.622699573999853e-05, Final Batch Loss: 7.627452305314364e-06\n",
      "Epoch 4855, Loss: 2.039569744738401e-05, Final Batch Loss: 6.750946795364143e-06\n",
      "Epoch 4856, Loss: 0.00018957640531880315, Final Batch Loss: 2.563838461355772e-05\n",
      "Epoch 4857, Loss: 1.7558572835696395e-06, Final Batch Loss: 8.226991781157267e-07\n",
      "Epoch 4858, Loss: 5.449486889119726e-05, Final Batch Loss: 1.5066170817590319e-05\n",
      "Epoch 4859, Loss: 1.9382322761885007e-05, Final Batch Loss: 1.835620241763536e-05\n",
      "Epoch 4860, Loss: 0.0020560531659157277, Final Batch Loss: 1.6680235148669453e-06\n",
      "Epoch 4861, Loss: 2.979489227072918e-05, Final Batch Loss: 2.7269456040812656e-05\n",
      "Epoch 4862, Loss: 7.273554729181342e-06, Final Batch Loss: 3.453494173299987e-06\n",
      "Epoch 4863, Loss: 1.0589473731670296e-05, Final Batch Loss: 2.1028895389463287e-06\n",
      "Epoch 4864, Loss: 4.816821399344917e-05, Final Batch Loss: 1.905590920614486e-06\n",
      "Epoch 4865, Loss: 4.232841729390202e-05, Final Batch Loss: 1.1836956218758132e-05\n",
      "Epoch 4866, Loss: 1.8387072486802936e-06, Final Batch Loss: 8.059131459958735e-07\n",
      "Epoch 4867, Loss: 7.21693522791611e-05, Final Batch Loss: 1.044981945597101e-05\n",
      "Epoch 4868, Loss: 1.5681561308156233e-05, Final Batch Loss: 7.776584425300825e-06\n",
      "Epoch 4869, Loss: 0.00026176664414379047, Final Batch Loss: 0.00025312721845693886\n",
      "Epoch 4870, Loss: 6.677789315290283e-05, Final Batch Loss: 1.582476579642389e-05\n",
      "Epoch 4871, Loss: 1.9106117747469398e-05, Final Batch Loss: 1.1005691931131878e-06\n",
      "Epoch 4872, Loss: 1.6525998262295616e-05, Final Batch Loss: 1.3813240002491511e-05\n",
      "Epoch 4873, Loss: 7.525064938818105e-05, Final Batch Loss: 5.262019840301946e-06\n",
      "Epoch 4874, Loss: 7.398117486445699e-05, Final Batch Loss: 1.8753094991552643e-05\n",
      "Epoch 4875, Loss: 3.847458265227033e-05, Final Batch Loss: 1.4099784493737388e-05\n",
      "Epoch 4876, Loss: 0.00011350203749316279, Final Batch Loss: 9.110839528148063e-06\n",
      "Epoch 4877, Loss: 3.7043687370896805e-05, Final Batch Loss: 3.148982796119526e-05\n",
      "Epoch 4878, Loss: 0.00017702134209685028, Final Batch Loss: 2.270561526529491e-05\n",
      "Epoch 4879, Loss: 2.125288892784738e-05, Final Batch Loss: 4.260099103703396e-06\n",
      "Epoch 4880, Loss: 0.0005513651340152137, Final Batch Loss: 7.378102600341663e-05\n",
      "Epoch 4881, Loss: 7.341799846471986e-05, Final Batch Loss: 6.662702071480453e-05\n",
      "Epoch 4882, Loss: 0.03375690569373546, Final Batch Loss: 0.033723387867212296\n",
      "Epoch 4883, Loss: 5.602868441201281e-06, Final Batch Loss: 2.3974705527507467e-06\n",
      "Epoch 4884, Loss: 0.0004589950106037577, Final Batch Loss: 0.00045608318760059774\n",
      "Epoch 4885, Loss: 7.635993256371876e-06, Final Batch Loss: 8.806281357465195e-07\n",
      "Epoch 4886, Loss: 0.0001049180661993887, Final Batch Loss: 2.8381416541378712e-06\n",
      "Epoch 4887, Loss: 0.0001943341133028298, Final Batch Loss: 5.179692834644811e-07\n",
      "Epoch 4888, Loss: 5.6433540521538816e-05, Final Batch Loss: 9.083401891984977e-06\n",
      "Epoch 4889, Loss: 6.128191853349563e-05, Final Batch Loss: 3.294867929071188e-05\n",
      "Epoch 4890, Loss: 7.496023044950562e-05, Final Batch Loss: 9.613596375857014e-06\n",
      "Epoch 4891, Loss: 9.943859510030961e-06, Final Batch Loss: 4.5248376068229845e-07\n",
      "Epoch 4892, Loss: 3.0025754085727385e-05, Final Batch Loss: 2.8529466362670064e-05\n",
      "Epoch 4893, Loss: 0.0004954227715643356, Final Batch Loss: 1.2287398931221105e-05\n",
      "Epoch 4894, Loss: 3.081633440160658e-05, Final Batch Loss: 1.4887571524013765e-05\n",
      "Epoch 4895, Loss: 9.895829634842812e-06, Final Batch Loss: 3.595303269321448e-06\n",
      "Epoch 4896, Loss: 1.2016357231914299e-05, Final Batch Loss: 4.285926024749642e-06\n",
      "Epoch 4897, Loss: 1.1799643743870547e-05, Final Batch Loss: 9.004776984511409e-06\n",
      "Epoch 4898, Loss: 1.571013308421243e-05, Final Batch Loss: 8.105825145321433e-06\n",
      "Epoch 4899, Loss: 0.00033874675864353776, Final Batch Loss: 0.00020021441741846502\n",
      "Epoch 4900, Loss: 0.00016814076025184477, Final Batch Loss: 0.00016315669927280396\n",
      "Epoch 4901, Loss: 0.00015010141032689717, Final Batch Loss: 0.00013830678653903306\n",
      "Epoch 4902, Loss: 0.00031324181509262417, Final Batch Loss: 2.0606117686838843e-05\n",
      "Epoch 4903, Loss: 0.000205512164029642, Final Batch Loss: 4.898194674751721e-06\n",
      "Epoch 4904, Loss: 6.445239978347672e-05, Final Batch Loss: 3.1839981602388434e-06\n",
      "Epoch 4905, Loss: 0.0002561679698374064, Final Batch Loss: 2.619939095893642e-06\n",
      "Epoch 4906, Loss: 2.0590010876730958e-05, Final Batch Loss: 1.1618361668297439e-06\n",
      "Epoch 4907, Loss: 9.397243729836191e-06, Final Batch Loss: 1.2055077149852877e-06\n",
      "Epoch 4908, Loss: 1.1137926321680425e-05, Final Batch Loss: 6.2368512772081885e-06\n",
      "Epoch 4909, Loss: 1.649064779485343e-05, Final Batch Loss: 1.0432720955577679e-05\n",
      "Epoch 4910, Loss: 2.949807731056353e-05, Final Batch Loss: 3.418815140321385e-06\n",
      "Epoch 4911, Loss: 1.4387555324901768e-06, Final Batch Loss: 7.068496188367135e-07\n",
      "Epoch 4912, Loss: 3.202028619853081e-05, Final Batch Loss: 1.4779569937672932e-05\n",
      "Epoch 4913, Loss: 3.356385809638596e-05, Final Batch Loss: 3.000190417878912e-06\n",
      "Epoch 4914, Loss: 4.0808577978168614e-05, Final Batch Loss: 6.504089469672181e-06\n",
      "Epoch 4915, Loss: 2.4753732759563718e-05, Final Batch Loss: 1.2374694961181376e-05\n",
      "Epoch 4916, Loss: 1.1503335940687975e-05, Final Batch Loss: 1.4758121551494696e-06\n",
      "Epoch 4917, Loss: 4.288195452772925e-05, Final Batch Loss: 1.387633915328479e-06\n",
      "Epoch 4918, Loss: 5.0362656111246906e-05, Final Batch Loss: 1.9515502572176047e-05\n",
      "Epoch 4919, Loss: 0.0001099279379559448, Final Batch Loss: 8.87987480382435e-05\n",
      "Epoch 4920, Loss: 0.00012194695545986178, Final Batch Loss: 5.001798399462132e-06\n",
      "Epoch 4921, Loss: 5.4539179927814985e-06, Final Batch Loss: 1.986187953662011e-06\n",
      "Epoch 4922, Loss: 3.455576461419696e-06, Final Batch Loss: 1.1912311492778827e-06\n",
      "Epoch 4923, Loss: 6.530711743835127e-06, Final Batch Loss: 2.951449687316199e-06\n",
      "Epoch 4924, Loss: 2.97242895612726e-05, Final Batch Loss: 1.3954073438071646e-05\n",
      "Epoch 4925, Loss: 1.9036940784644685e-05, Final Batch Loss: 1.1585013908188557e-06\n",
      "Epoch 4926, Loss: 1.1909745353477774e-05, Final Batch Loss: 9.462881280342117e-06\n",
      "Epoch 4927, Loss: 3.5819983850160497e-06, Final Batch Loss: 7.194447562142159e-07\n",
      "Epoch 4928, Loss: 8.619753771199612e-06, Final Batch Loss: 2.4243563530035317e-06\n",
      "Epoch 4929, Loss: 4.8799646719999146e-05, Final Batch Loss: 1.023026470647892e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4930, Loss: 0.000141919382258493, Final Batch Loss: 8.986923603515606e-06\n",
      "Epoch 4931, Loss: 3.674149593280163e-05, Final Batch Loss: 1.935733416758012e-05\n",
      "Epoch 4932, Loss: 2.0981462057534372e-05, Final Batch Loss: 1.3430041690298822e-05\n",
      "Epoch 4933, Loss: 9.581137874192791e-06, Final Batch Loss: 4.9926711653824896e-06\n",
      "Epoch 4934, Loss: 1.6496298144375032e-05, Final Batch Loss: 9.284609632231877e-07\n",
      "Epoch 4935, Loss: 5.7947317145590205e-05, Final Batch Loss: 4.5782864617649466e-05\n",
      "Epoch 4936, Loss: 2.742214121553843e-05, Final Batch Loss: 9.066417305803043e-07\n",
      "Epoch 4937, Loss: 7.387654022750212e-06, Final Batch Loss: 4.105366770090768e-06\n",
      "Epoch 4938, Loss: 0.0005621577670353872, Final Batch Loss: 1.5765485841257032e-06\n",
      "Epoch 4939, Loss: 8.53370911499951e-05, Final Batch Loss: 3.3362419344484806e-05\n",
      "Epoch 4940, Loss: 6.759591815352906e-05, Final Batch Loss: 5.716898158425465e-05\n",
      "Epoch 4941, Loss: 2.704341187609316e-05, Final Batch Loss: 2.6546078515821137e-05\n",
      "Epoch 4942, Loss: 1.5428516348947596e-05, Final Batch Loss: 1.0065424476124463e-06\n",
      "Epoch 4943, Loss: 7.992924111022148e-05, Final Batch Loss: 5.7994773669634014e-05\n",
      "Epoch 4944, Loss: 5.663125875798869e-06, Final Batch Loss: 3.169593128404813e-06\n",
      "Epoch 4945, Loss: 2.900006165873492e-05, Final Batch Loss: 7.778092367516365e-06\n",
      "Epoch 4946, Loss: 8.169032014393451e-06, Final Batch Loss: 7.085324682520877e-07\n",
      "Epoch 4947, Loss: 0.0010276052280460135, Final Batch Loss: 0.0010179297532886267\n",
      "Epoch 4948, Loss: 2.5438799866606132e-06, Final Batch Loss: 1.037611013998685e-06\n",
      "Epoch 4949, Loss: 1.987910223988365e-06, Final Batch Loss: 2.2750433004148363e-07\n",
      "Epoch 4950, Loss: 1.433451961929677e-05, Final Batch Loss: 4.9422842494095676e-06\n",
      "Epoch 4951, Loss: 2.2153486497700214e-05, Final Batch Loss: 9.553447853249963e-06\n",
      "Epoch 4952, Loss: 2.4618861971248407e-06, Final Batch Loss: 1.8014732177107362e-06\n",
      "Epoch 4953, Loss: 7.215314440145448e-06, Final Batch Loss: 5.519761089090025e-06\n",
      "Epoch 4954, Loss: 0.0009921751734509598, Final Batch Loss: 0.0009320228127762675\n",
      "Epoch 4955, Loss: 5.295822234074876e-06, Final Batch Loss: 4.273499143891968e-06\n",
      "Epoch 4956, Loss: 8.921864036892657e-06, Final Batch Loss: 8.158939635904972e-06\n",
      "Epoch 4957, Loss: 1.693835929472698e-05, Final Batch Loss: 6.282347385422327e-06\n",
      "Epoch 4958, Loss: 7.815606295480393e-05, Final Batch Loss: 6.122056947788224e-05\n",
      "Epoch 4959, Loss: 1.7227146599907428e-05, Final Batch Loss: 7.219298822747078e-06\n",
      "Epoch 4960, Loss: 3.0216502182156546e-05, Final Batch Loss: 2.3564763978356495e-05\n",
      "Epoch 4961, Loss: 0.00019794051445387595, Final Batch Loss: 3.188071104887058e-06\n",
      "Epoch 4962, Loss: 1.0636682418407872e-05, Final Batch Loss: 4.211522991681704e-06\n",
      "Epoch 4963, Loss: 5.7116609468721435e-06, Final Batch Loss: 1.435521539860929e-06\n",
      "Epoch 4964, Loss: 5.518651846614375e-06, Final Batch Loss: 1.0686670748327742e-06\n",
      "Epoch 4965, Loss: 9.609837206880911e-06, Final Batch Loss: 3.4246797895320924e-06\n",
      "Epoch 4966, Loss: 5.432192722309992e-06, Final Batch Loss: 5.137686116540863e-07\n",
      "Epoch 4967, Loss: 0.004248698473929835, Final Batch Loss: 7.0466185206896625e-06\n",
      "Epoch 4968, Loss: 4.641151406303834e-06, Final Batch Loss: 4.381753569759894e-06\n",
      "Epoch 4969, Loss: 6.539382184200804e-06, Final Batch Loss: 3.873027253575856e-06\n",
      "Epoch 4970, Loss: 3.4003645396296633e-05, Final Batch Loss: 2.7284871976007707e-05\n",
      "Epoch 4971, Loss: 3.449527616794512e-05, Final Batch Loss: 2.030706355071743e-06\n",
      "Epoch 4972, Loss: 0.0007883230796323915, Final Batch Loss: 0.000781091395765543\n",
      "Epoch 4973, Loss: 6.42321128907497e-06, Final Batch Loss: 3.1790384582564e-06\n",
      "Epoch 4974, Loss: 7.871116395108402e-05, Final Batch Loss: 3.1383646273752674e-05\n",
      "Epoch 4975, Loss: 2.0152614069957053e-05, Final Batch Loss: 1.25305023175315e-05\n",
      "Epoch 4976, Loss: 3.0419590302699362e-05, Final Batch Loss: 2.7459462216938846e-05\n",
      "Epoch 4977, Loss: 2.522491013223771e-05, Final Batch Loss: 1.6247744497377425e-05\n",
      "Epoch 4978, Loss: 3.566639725249843e-05, Final Batch Loss: 4.659671049012104e-06\n",
      "Epoch 4979, Loss: 2.4858663891791366e-05, Final Batch Loss: 1.0251254025206435e-05\n",
      "Epoch 4980, Loss: 0.0001545658287795959, Final Batch Loss: 1.2095128113287501e-05\n",
      "Epoch 4981, Loss: 2.4950625629571732e-05, Final Batch Loss: 2.3597121980856173e-06\n",
      "Epoch 4982, Loss: 0.00010027698590420187, Final Batch Loss: 7.984395779203624e-06\n",
      "Epoch 4983, Loss: 7.410282159980852e-05, Final Batch Loss: 2.0305178622948006e-06\n",
      "Epoch 4984, Loss: 3.4566832255222835e-05, Final Batch Loss: 1.0427924280520529e-05\n",
      "Epoch 4985, Loss: 4.341229015381032e-06, Final Batch Loss: 3.651778399671457e-07\n",
      "Epoch 4986, Loss: 1.8341974737268174e-05, Final Batch Loss: 1.2426155990397092e-05\n",
      "Epoch 4987, Loss: 1.940177082815353e-05, Final Batch Loss: 1.753130527504254e-05\n",
      "Epoch 4988, Loss: 2.0419552470229974e-05, Final Batch Loss: 1.9413924746913835e-05\n",
      "Epoch 4989, Loss: 3.7915448046987876e-05, Final Batch Loss: 2.8763655791408382e-05\n",
      "Epoch 4990, Loss: 6.929173480330064e-06, Final Batch Loss: 6.35649666946847e-06\n",
      "Epoch 4991, Loss: 2.1474651930475375e-05, Final Batch Loss: 4.575507318804739e-06\n",
      "Epoch 4992, Loss: 9.579019661032362e-06, Final Batch Loss: 6.172846951812971e-06\n",
      "Epoch 4993, Loss: 5.956133350082382e-06, Final Batch Loss: 1.4815972235737718e-06\n",
      "Epoch 4994, Loss: 5.941577001067344e-06, Final Batch Loss: 3.576136805349961e-06\n",
      "Epoch 4995, Loss: 0.0001094029439627775, Final Batch Loss: 9.978674643207341e-05\n",
      "Epoch 4996, Loss: 2.9767505566269392e-05, Final Batch Loss: 3.4844692891056184e-06\n",
      "Epoch 4997, Loss: 9.911509323501377e-06, Final Batch Loss: 2.39325549955538e-06\n",
      "Epoch 4998, Loss: 1.8663546370589756e-06, Final Batch Loss: 5.465085450850893e-07\n",
      "Epoch 4999, Loss: 2.832006248354446e-05, Final Batch Loss: 1.4269691746449098e-05\n",
      "Epoch 5000, Loss: 2.700725218574007e-06, Final Batch Loss: 1.2592479947670654e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  0  0]\n",
      " [ 0 30  0]\n",
      " [ 0  0 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        34\n",
      "           1    1.00000   1.00000   1.00000        30\n",
      "           2    1.00000   1.00000   1.00000        34\n",
      "\n",
      "    accuracy                        1.00000        98\n",
      "   macro avg    1.00000   1.00000   1.00000        98\n",
      "weighted avg    1.00000   1.00000   1.00000        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Group 4_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 3) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 0 30  0]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    1.00000   1.00000   1.00000        30\n",
      "         1.0    1.00000   1.00000   1.00000        30\n",
      "         2.0    1.00000   1.00000   1.00000        30\n",
      "\n",
      "    accuracy                        1.00000        90\n",
      "   macro avg    1.00000   1.00000   1.00000        90\n",
      "weighted avg    1.00000   1.00000   1.00000        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [19, 21, 22]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 19:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 21:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.490448951721191, Final Batch Loss: 2.2609307765960693\n",
      "Epoch 2, Loss: 4.453925132751465, Final Batch Loss: 2.2258682250976562\n",
      "Epoch 3, Loss: 4.426087856292725, Final Batch Loss: 2.193281888961792\n",
      "Epoch 4, Loss: 4.432168960571289, Final Batch Loss: 2.232943058013916\n",
      "Epoch 5, Loss: 4.405224800109863, Final Batch Loss: 2.2142016887664795\n",
      "Epoch 6, Loss: 4.381544589996338, Final Batch Loss: 2.202669382095337\n",
      "Epoch 7, Loss: 4.360584497451782, Final Batch Loss: 2.1844677925109863\n",
      "Epoch 8, Loss: 4.324115991592407, Final Batch Loss: 2.1617870330810547\n",
      "Epoch 9, Loss: 4.314440965652466, Final Batch Loss: 2.1624839305877686\n",
      "Epoch 10, Loss: 4.286506414413452, Final Batch Loss: 2.1452231407165527\n",
      "Epoch 11, Loss: 4.250180721282959, Final Batch Loss: 2.1201748847961426\n",
      "Epoch 12, Loss: 4.226307153701782, Final Batch Loss: 2.1160619258880615\n",
      "Epoch 13, Loss: 4.1874401569366455, Final Batch Loss: 2.0950639247894287\n",
      "Epoch 14, Loss: 4.156593322753906, Final Batch Loss: 2.0765533447265625\n",
      "Epoch 15, Loss: 4.109440088272095, Final Batch Loss: 2.0495147705078125\n",
      "Epoch 16, Loss: 4.058212757110596, Final Batch Loss: 2.0298588275909424\n",
      "Epoch 17, Loss: 4.001740455627441, Final Batch Loss: 1.9850287437438965\n",
      "Epoch 18, Loss: 3.9654645919799805, Final Batch Loss: 1.9789749383926392\n",
      "Epoch 19, Loss: 3.913256525993347, Final Batch Loss: 1.9680627584457397\n",
      "Epoch 20, Loss: 3.8226341009140015, Final Batch Loss: 1.9170171022415161\n",
      "Epoch 21, Loss: 3.7789226770401, Final Batch Loss: 1.883265733718872\n",
      "Epoch 22, Loss: 3.688945174217224, Final Batch Loss: 1.8251396417617798\n",
      "Epoch 23, Loss: 3.601121187210083, Final Batch Loss: 1.7633202075958252\n",
      "Epoch 24, Loss: 3.5097051858901978, Final Batch Loss: 1.7358044385910034\n",
      "Epoch 25, Loss: 3.451794385910034, Final Batch Loss: 1.7263723611831665\n",
      "Epoch 26, Loss: 3.3506518602371216, Final Batch Loss: 1.6896048784255981\n",
      "Epoch 27, Loss: 3.2412511110305786, Final Batch Loss: 1.6099627017974854\n",
      "Epoch 28, Loss: 3.1659865379333496, Final Batch Loss: 1.5549942255020142\n",
      "Epoch 29, Loss: 3.086631417274475, Final Batch Loss: 1.5216596126556396\n",
      "Epoch 30, Loss: 3.020560145378113, Final Batch Loss: 1.5072849988937378\n",
      "Epoch 31, Loss: 2.9378418922424316, Final Batch Loss: 1.4735771417617798\n",
      "Epoch 32, Loss: 2.962080240249634, Final Batch Loss: 1.4874447584152222\n",
      "Epoch 33, Loss: 2.8330613374710083, Final Batch Loss: 1.4222079515457153\n",
      "Epoch 34, Loss: 2.8006871938705444, Final Batch Loss: 1.3903462886810303\n",
      "Epoch 35, Loss: 2.7308976650238037, Final Batch Loss: 1.3612717390060425\n",
      "Epoch 36, Loss: 2.737584710121155, Final Batch Loss: 1.3436001539230347\n",
      "Epoch 37, Loss: 2.694225311279297, Final Batch Loss: 1.3675097227096558\n",
      "Epoch 38, Loss: 2.6050665378570557, Final Batch Loss: 1.315940260887146\n",
      "Epoch 39, Loss: 2.567733407020569, Final Batch Loss: 1.2590943574905396\n",
      "Epoch 40, Loss: 2.5378613471984863, Final Batch Loss: 1.2774525880813599\n",
      "Epoch 41, Loss: 2.527194857597351, Final Batch Loss: 1.2692015171051025\n",
      "Epoch 42, Loss: 2.495372772216797, Final Batch Loss: 1.220357060432434\n",
      "Epoch 43, Loss: 2.469407796859741, Final Batch Loss: 1.2011373043060303\n",
      "Epoch 44, Loss: 2.5110208988189697, Final Batch Loss: 1.2355434894561768\n",
      "Epoch 45, Loss: 2.549406051635742, Final Batch Loss: 1.267335295677185\n",
      "Epoch 46, Loss: 2.4510854482650757, Final Batch Loss: 1.2200610637664795\n",
      "Epoch 47, Loss: 2.4397722482681274, Final Batch Loss: 1.192500352859497\n",
      "Epoch 48, Loss: 2.44023060798645, Final Batch Loss: 1.2179378271102905\n",
      "Epoch 49, Loss: 2.440705418586731, Final Batch Loss: 1.1860027313232422\n",
      "Epoch 50, Loss: 2.473419189453125, Final Batch Loss: 1.2459968328475952\n",
      "Epoch 51, Loss: 2.440391778945923, Final Batch Loss: 1.225103497505188\n",
      "Epoch 52, Loss: 2.4356294870376587, Final Batch Loss: 1.2161791324615479\n",
      "Epoch 53, Loss: 2.437300682067871, Final Batch Loss: 1.204077124595642\n",
      "Epoch 54, Loss: 2.391081690788269, Final Batch Loss: 1.2055822610855103\n",
      "Epoch 55, Loss: 2.352970242500305, Final Batch Loss: 1.1578726768493652\n",
      "Epoch 56, Loss: 2.4480730295181274, Final Batch Loss: 1.1992002725601196\n",
      "Epoch 57, Loss: 2.349874973297119, Final Batch Loss: 1.1647189855575562\n",
      "Epoch 58, Loss: 2.4763076305389404, Final Batch Loss: 1.2845667600631714\n",
      "Epoch 59, Loss: 2.3778395652770996, Final Batch Loss: 1.2028636932373047\n",
      "Epoch 60, Loss: 2.3287694454193115, Final Batch Loss: 1.1676733493804932\n",
      "Epoch 61, Loss: 2.411773681640625, Final Batch Loss: 1.2156901359558105\n",
      "Epoch 62, Loss: 2.3593450784683228, Final Batch Loss: 1.194506287574768\n",
      "Epoch 63, Loss: 2.403204321861267, Final Batch Loss: 1.1993814706802368\n",
      "Epoch 64, Loss: 2.3510148525238037, Final Batch Loss: 1.185987949371338\n",
      "Epoch 65, Loss: 2.3774715662002563, Final Batch Loss: 1.1939570903778076\n",
      "Epoch 66, Loss: 2.4094552993774414, Final Batch Loss: 1.255250096321106\n",
      "Epoch 67, Loss: 2.3779661655426025, Final Batch Loss: 1.1936116218566895\n",
      "Epoch 68, Loss: 2.332033395767212, Final Batch Loss: 1.159164547920227\n",
      "Epoch 69, Loss: 2.403891444206238, Final Batch Loss: 1.2106850147247314\n",
      "Epoch 70, Loss: 2.3440349102020264, Final Batch Loss: 1.1400736570358276\n",
      "Epoch 71, Loss: 2.295549511909485, Final Batch Loss: 1.1381046772003174\n",
      "Epoch 72, Loss: 2.360265612602234, Final Batch Loss: 1.152600646018982\n",
      "Epoch 73, Loss: 2.2965415716171265, Final Batch Loss: 1.150693655014038\n",
      "Epoch 74, Loss: 2.369669198989868, Final Batch Loss: 1.2066676616668701\n",
      "Epoch 75, Loss: 2.3280885219573975, Final Batch Loss: 1.1756454706192017\n",
      "Epoch 76, Loss: 2.3376753330230713, Final Batch Loss: 1.1673911809921265\n",
      "Epoch 77, Loss: 2.330722212791443, Final Batch Loss: 1.1740057468414307\n",
      "Epoch 78, Loss: 2.284333825111389, Final Batch Loss: 1.1007555723190308\n",
      "Epoch 79, Loss: 2.293255925178528, Final Batch Loss: 1.1426669359207153\n",
      "Epoch 80, Loss: 2.347551941871643, Final Batch Loss: 1.1653283834457397\n",
      "Epoch 81, Loss: 2.3104653358459473, Final Batch Loss: 1.1800456047058105\n",
      "Epoch 82, Loss: 2.2462825775146484, Final Batch Loss: 1.135793924331665\n",
      "Epoch 83, Loss: 2.3191665410995483, Final Batch Loss: 1.1568411588668823\n",
      "Epoch 84, Loss: 2.350603699684143, Final Batch Loss: 1.1913511753082275\n",
      "Epoch 85, Loss: 2.284470319747925, Final Batch Loss: 1.1383802890777588\n",
      "Epoch 86, Loss: 2.2321064472198486, Final Batch Loss: 1.097747564315796\n",
      "Epoch 87, Loss: 2.2651087045669556, Final Batch Loss: 1.133095622062683\n",
      "Epoch 88, Loss: 2.2703750133514404, Final Batch Loss: 1.126747727394104\n",
      "Epoch 89, Loss: 2.240718126296997, Final Batch Loss: 1.085807204246521\n",
      "Epoch 90, Loss: 2.2298907041549683, Final Batch Loss: 1.1299861669540405\n",
      "Epoch 91, Loss: 2.261466383934021, Final Batch Loss: 1.132273554801941\n",
      "Epoch 92, Loss: 2.2683002948760986, Final Batch Loss: 1.1356419324874878\n",
      "Epoch 93, Loss: 2.3116899728775024, Final Batch Loss: 1.1959071159362793\n",
      "Epoch 94, Loss: 2.2632076740264893, Final Batch Loss: 1.1462135314941406\n",
      "Epoch 95, Loss: 2.257251024246216, Final Batch Loss: 1.0969090461730957\n",
      "Epoch 96, Loss: 2.2753649950027466, Final Batch Loss: 1.1440855264663696\n",
      "Epoch 97, Loss: 2.2123934030532837, Final Batch Loss: 1.075860857963562\n",
      "Epoch 98, Loss: 2.278770685195923, Final Batch Loss: 1.1357100009918213\n",
      "Epoch 99, Loss: 2.269175171852112, Final Batch Loss: 1.1443123817443848\n",
      "Epoch 100, Loss: 2.2498217821121216, Final Batch Loss: 1.131417155265808\n",
      "Epoch 101, Loss: 2.20678174495697, Final Batch Loss: 1.1017234325408936\n",
      "Epoch 102, Loss: 2.288452625274658, Final Batch Loss: 1.1578513383865356\n",
      "Epoch 103, Loss: 2.234246015548706, Final Batch Loss: 1.1228373050689697\n",
      "Epoch 104, Loss: 2.218440890312195, Final Batch Loss: 1.1137601137161255\n",
      "Epoch 105, Loss: 2.278692126274109, Final Batch Loss: 1.1110317707061768\n",
      "Epoch 106, Loss: 2.2340359687805176, Final Batch Loss: 1.1111557483673096\n",
      "Epoch 107, Loss: 2.239283323287964, Final Batch Loss: 1.1555836200714111\n",
      "Epoch 108, Loss: 2.173895835876465, Final Batch Loss: 1.0912284851074219\n",
      "Epoch 109, Loss: 2.216553211212158, Final Batch Loss: 1.1315076351165771\n",
      "Epoch 110, Loss: 2.1823768615722656, Final Batch Loss: 1.0624752044677734\n",
      "Epoch 111, Loss: 2.180993914604187, Final Batch Loss: 1.0964422225952148\n",
      "Epoch 112, Loss: 2.2134785652160645, Final Batch Loss: 1.1130478382110596\n",
      "Epoch 113, Loss: 2.1451520919799805, Final Batch Loss: 1.0672624111175537\n",
      "Epoch 114, Loss: 2.189993381500244, Final Batch Loss: 1.0795130729675293\n",
      "Epoch 115, Loss: 2.1943109035491943, Final Batch Loss: 1.128144383430481\n",
      "Epoch 116, Loss: 2.218575358390808, Final Batch Loss: 1.1157091856002808\n",
      "Epoch 117, Loss: 2.1919854879379272, Final Batch Loss: 1.1019939184188843\n",
      "Epoch 118, Loss: 2.1995514631271362, Final Batch Loss: 1.1119729280471802\n",
      "Epoch 119, Loss: 2.171230435371399, Final Batch Loss: 1.0674738883972168\n",
      "Epoch 120, Loss: 2.1518341302871704, Final Batch Loss: 1.0525413751602173\n",
      "Epoch 121, Loss: 2.169781804084778, Final Batch Loss: 1.09214448928833\n",
      "Epoch 122, Loss: 2.1657049655914307, Final Batch Loss: 1.1192610263824463\n",
      "Epoch 123, Loss: 2.108186364173889, Final Batch Loss: 1.0334668159484863\n",
      "Epoch 124, Loss: 2.139651298522949, Final Batch Loss: 1.0644232034683228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125, Loss: 2.10856831073761, Final Batch Loss: 1.0456103086471558\n",
      "Epoch 126, Loss: 2.143097758293152, Final Batch Loss: 1.097213625907898\n",
      "Epoch 127, Loss: 2.0853224992752075, Final Batch Loss: 1.0528019666671753\n",
      "Epoch 128, Loss: 2.111033797264099, Final Batch Loss: 1.042366862297058\n",
      "Epoch 129, Loss: 2.0551239252090454, Final Batch Loss: 1.0018256902694702\n",
      "Epoch 130, Loss: 2.061598002910614, Final Batch Loss: 0.998433530330658\n",
      "Epoch 131, Loss: 2.033028244972229, Final Batch Loss: 0.9979596138000488\n",
      "Epoch 132, Loss: 1.9880186319351196, Final Batch Loss: 0.991489589214325\n",
      "Epoch 133, Loss: 2.042285680770874, Final Batch Loss: 1.026776671409607\n",
      "Epoch 134, Loss: 2.0273963809013367, Final Batch Loss: 0.9972973465919495\n",
      "Epoch 135, Loss: 2.034497916698456, Final Batch Loss: 0.9974667429924011\n",
      "Epoch 136, Loss: 2.021562099456787, Final Batch Loss: 1.0137988328933716\n",
      "Epoch 137, Loss: 1.9342378973960876, Final Batch Loss: 0.959611177444458\n",
      "Epoch 138, Loss: 1.9990623593330383, Final Batch Loss: 0.9500452876091003\n",
      "Epoch 139, Loss: 2.003694236278534, Final Batch Loss: 0.9775407910346985\n",
      "Epoch 140, Loss: 1.9435937404632568, Final Batch Loss: 0.9287261962890625\n",
      "Epoch 141, Loss: 1.9486716985702515, Final Batch Loss: 0.9659992456436157\n",
      "Epoch 142, Loss: 1.875588595867157, Final Batch Loss: 0.9288637638092041\n",
      "Epoch 143, Loss: 1.9649747014045715, Final Batch Loss: 0.9714093208312988\n",
      "Epoch 144, Loss: 1.9777504801750183, Final Batch Loss: 0.9722009301185608\n",
      "Epoch 145, Loss: 1.9407762289047241, Final Batch Loss: 1.009732723236084\n",
      "Epoch 146, Loss: 1.9506002068519592, Final Batch Loss: 0.9565525054931641\n",
      "Epoch 147, Loss: 1.9267525672912598, Final Batch Loss: 0.9267044067382812\n",
      "Epoch 148, Loss: 1.9011706113815308, Final Batch Loss: 0.9357818961143494\n",
      "Epoch 149, Loss: 1.876332700252533, Final Batch Loss: 0.9313706755638123\n",
      "Epoch 150, Loss: 1.8493792414665222, Final Batch Loss: 0.8995053172111511\n",
      "Epoch 151, Loss: 1.8685678839683533, Final Batch Loss: 0.9521394968032837\n",
      "Epoch 152, Loss: 1.8632858991622925, Final Batch Loss: 0.9303840398788452\n",
      "Epoch 153, Loss: 1.8164138793945312, Final Batch Loss: 0.8774527907371521\n",
      "Epoch 154, Loss: 1.8349971771240234, Final Batch Loss: 0.870632529258728\n",
      "Epoch 155, Loss: 1.8403828740119934, Final Batch Loss: 0.9529527425765991\n",
      "Epoch 156, Loss: 1.8838589787483215, Final Batch Loss: 0.9170751571655273\n",
      "Epoch 157, Loss: 1.8729876279830933, Final Batch Loss: 0.97020024061203\n",
      "Epoch 158, Loss: 1.7878295183181763, Final Batch Loss: 0.8480463624000549\n",
      "Epoch 159, Loss: 1.8470160365104675, Final Batch Loss: 0.9073977470397949\n",
      "Epoch 160, Loss: 1.7526429891586304, Final Batch Loss: 0.8879014253616333\n",
      "Epoch 161, Loss: 1.8054205179214478, Final Batch Loss: 0.8972448706626892\n",
      "Epoch 162, Loss: 1.7565721273422241, Final Batch Loss: 0.8398090600967407\n",
      "Epoch 163, Loss: 1.786133885383606, Final Batch Loss: 0.9008530378341675\n",
      "Epoch 164, Loss: 1.7972187995910645, Final Batch Loss: 0.9068753719329834\n",
      "Epoch 165, Loss: 1.7545475959777832, Final Batch Loss: 0.8279776573181152\n",
      "Epoch 166, Loss: 1.7160853147506714, Final Batch Loss: 0.8635544776916504\n",
      "Epoch 167, Loss: 1.7186630964279175, Final Batch Loss: 0.8724511861801147\n",
      "Epoch 168, Loss: 1.6288564801216125, Final Batch Loss: 0.8081384897232056\n",
      "Epoch 169, Loss: 1.6697872877120972, Final Batch Loss: 0.8333749175071716\n",
      "Epoch 170, Loss: 1.6397894620895386, Final Batch Loss: 0.8028643131256104\n",
      "Epoch 171, Loss: 1.6380439400672913, Final Batch Loss: 0.7733624577522278\n",
      "Epoch 172, Loss: 1.6413632035255432, Final Batch Loss: 0.8190123438835144\n",
      "Epoch 173, Loss: 1.5907897353172302, Final Batch Loss: 0.7919510006904602\n",
      "Epoch 174, Loss: 1.5613659024238586, Final Batch Loss: 0.8084741830825806\n",
      "Epoch 175, Loss: 1.544666826725006, Final Batch Loss: 0.7235499620437622\n",
      "Epoch 176, Loss: 1.6122222542762756, Final Batch Loss: 0.8198887705802917\n",
      "Epoch 177, Loss: 1.5977747440338135, Final Batch Loss: 0.8236359357833862\n",
      "Epoch 178, Loss: 1.4623461961746216, Final Batch Loss: 0.7091323733329773\n",
      "Epoch 179, Loss: 1.5678076148033142, Final Batch Loss: 0.8512533903121948\n",
      "Epoch 180, Loss: 1.5315696001052856, Final Batch Loss: 0.7785649299621582\n",
      "Epoch 181, Loss: 1.433587372303009, Final Batch Loss: 0.6779304146766663\n",
      "Epoch 182, Loss: 1.5104560852050781, Final Batch Loss: 0.7665344476699829\n",
      "Epoch 183, Loss: 1.5050743222236633, Final Batch Loss: 0.7232247591018677\n",
      "Epoch 184, Loss: 1.4809573888778687, Final Batch Loss: 0.7391216158866882\n",
      "Epoch 185, Loss: 1.4552817940711975, Final Batch Loss: 0.760558545589447\n",
      "Epoch 186, Loss: 1.3803935050964355, Final Batch Loss: 0.7466217279434204\n",
      "Epoch 187, Loss: 1.3977385759353638, Final Batch Loss: 0.6843432784080505\n",
      "Epoch 188, Loss: 1.340910017490387, Final Batch Loss: 0.6353484392166138\n",
      "Epoch 189, Loss: 1.4033063054084778, Final Batch Loss: 0.6952346563339233\n",
      "Epoch 190, Loss: 1.3260045647621155, Final Batch Loss: 0.6098132729530334\n",
      "Epoch 191, Loss: 1.3557565212249756, Final Batch Loss: 0.6735917329788208\n",
      "Epoch 192, Loss: 1.37229984998703, Final Batch Loss: 0.6965076327323914\n",
      "Epoch 193, Loss: 1.3732599020004272, Final Batch Loss: 0.7023395895957947\n",
      "Epoch 194, Loss: 1.2897437810897827, Final Batch Loss: 0.6116857528686523\n",
      "Epoch 195, Loss: 1.2511221170425415, Final Batch Loss: 0.5970580577850342\n",
      "Epoch 196, Loss: 1.3430770635604858, Final Batch Loss: 0.6771786212921143\n",
      "Epoch 197, Loss: 1.3172565698623657, Final Batch Loss: 0.6703678965568542\n",
      "Epoch 198, Loss: 1.2573199272155762, Final Batch Loss: 0.5895138382911682\n",
      "Epoch 199, Loss: 1.2835785746574402, Final Batch Loss: 0.6519237160682678\n",
      "Epoch 200, Loss: 1.278328776359558, Final Batch Loss: 0.6344232559204102\n",
      "Epoch 201, Loss: 1.3259831666946411, Final Batch Loss: 0.6709176301956177\n",
      "Epoch 202, Loss: 1.2488721013069153, Final Batch Loss: 0.6295103430747986\n",
      "Epoch 203, Loss: 1.242588996887207, Final Batch Loss: 0.6493125557899475\n",
      "Epoch 204, Loss: 1.2371804118156433, Final Batch Loss: 0.6557252407073975\n",
      "Epoch 205, Loss: 1.2517554759979248, Final Batch Loss: 0.612199068069458\n",
      "Epoch 206, Loss: 1.1826509833335876, Final Batch Loss: 0.5778071284294128\n",
      "Epoch 207, Loss: 1.1804144382476807, Final Batch Loss: 0.6087331771850586\n",
      "Epoch 208, Loss: 1.1806432008743286, Final Batch Loss: 0.5951594710350037\n",
      "Epoch 209, Loss: 1.20832097530365, Final Batch Loss: 0.6445348858833313\n",
      "Epoch 210, Loss: 1.2019931077957153, Final Batch Loss: 0.6290873289108276\n",
      "Epoch 211, Loss: 1.160903513431549, Final Batch Loss: 0.582630455493927\n",
      "Epoch 212, Loss: 1.1197116374969482, Final Batch Loss: 0.5209776163101196\n",
      "Epoch 213, Loss: 1.204314410686493, Final Batch Loss: 0.6606171727180481\n",
      "Epoch 214, Loss: 1.1846699118614197, Final Batch Loss: 0.6270599961280823\n",
      "Epoch 215, Loss: 1.1668097972869873, Final Batch Loss: 0.6166701912879944\n",
      "Epoch 216, Loss: 1.1784095764160156, Final Batch Loss: 0.5692326426506042\n",
      "Epoch 217, Loss: 1.1278437376022339, Final Batch Loss: 0.535297691822052\n",
      "Epoch 218, Loss: 1.1676800847053528, Final Batch Loss: 0.6225175261497498\n",
      "Epoch 219, Loss: 1.1356077194213867, Final Batch Loss: 0.5495028495788574\n",
      "Epoch 220, Loss: 1.1356391906738281, Final Batch Loss: 0.5731365084648132\n",
      "Epoch 221, Loss: 1.1519216895103455, Final Batch Loss: 0.5897248387336731\n",
      "Epoch 222, Loss: 1.1021537780761719, Final Batch Loss: 0.544567346572876\n",
      "Epoch 223, Loss: 1.0519742369651794, Final Batch Loss: 0.5144274830818176\n",
      "Epoch 224, Loss: 1.1119497418403625, Final Batch Loss: 0.5854328870773315\n",
      "Epoch 225, Loss: 1.0196449756622314, Final Batch Loss: 0.47927266359329224\n",
      "Epoch 226, Loss: 1.0909647345542908, Final Batch Loss: 0.5432062745094299\n",
      "Epoch 227, Loss: 1.070618987083435, Final Batch Loss: 0.5139882564544678\n",
      "Epoch 228, Loss: 1.0864214897155762, Final Batch Loss: 0.5445377230644226\n",
      "Epoch 229, Loss: 1.0817517638206482, Final Batch Loss: 0.5789671540260315\n",
      "Epoch 230, Loss: 1.0687180757522583, Final Batch Loss: 0.5073413252830505\n",
      "Epoch 231, Loss: 0.9936226308345795, Final Batch Loss: 0.46008536219596863\n",
      "Epoch 232, Loss: 1.0540763139724731, Final Batch Loss: 0.5250361561775208\n",
      "Epoch 233, Loss: 1.0140652060508728, Final Batch Loss: 0.48571115732192993\n",
      "Epoch 234, Loss: 1.0260487794876099, Final Batch Loss: 0.5260287523269653\n",
      "Epoch 235, Loss: 1.0286881923675537, Final Batch Loss: 0.5172420144081116\n",
      "Epoch 236, Loss: 1.014305740594864, Final Batch Loss: 0.5359411835670471\n",
      "Epoch 237, Loss: 0.9811951518058777, Final Batch Loss: 0.4604067802429199\n",
      "Epoch 238, Loss: 1.1024123430252075, Final Batch Loss: 0.555440366268158\n",
      "Epoch 239, Loss: 0.9958731234073639, Final Batch Loss: 0.48455891013145447\n",
      "Epoch 240, Loss: 0.9985575377941132, Final Batch Loss: 0.5247462391853333\n",
      "Epoch 241, Loss: 1.0066710114479065, Final Batch Loss: 0.5058155059814453\n",
      "Epoch 242, Loss: 1.0003311038017273, Final Batch Loss: 0.521722674369812\n",
      "Epoch 243, Loss: 0.9360426962375641, Final Batch Loss: 0.4386026859283447\n",
      "Epoch 244, Loss: 0.9941447675228119, Final Batch Loss: 0.5000607967376709\n",
      "Epoch 245, Loss: 0.9956347346305847, Final Batch Loss: 0.5068259239196777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246, Loss: 0.982771098613739, Final Batch Loss: 0.49187782406806946\n",
      "Epoch 247, Loss: 0.9212613999843597, Final Batch Loss: 0.4311314821243286\n",
      "Epoch 248, Loss: 0.9595068395137787, Final Batch Loss: 0.465606153011322\n",
      "Epoch 249, Loss: 0.9231176972389221, Final Batch Loss: 0.4350234568119049\n",
      "Epoch 250, Loss: 0.9206679463386536, Final Batch Loss: 0.43333545327186584\n",
      "Epoch 251, Loss: 0.9221158623695374, Final Batch Loss: 0.4789859652519226\n",
      "Epoch 252, Loss: 0.917269378900528, Final Batch Loss: 0.4708465337753296\n",
      "Epoch 253, Loss: 0.9034165143966675, Final Batch Loss: 0.4358398914337158\n",
      "Epoch 254, Loss: 0.9198233485221863, Final Batch Loss: 0.4506840109825134\n",
      "Epoch 255, Loss: 0.9826922118663788, Final Batch Loss: 0.4794650971889496\n",
      "Epoch 256, Loss: 0.895156979560852, Final Batch Loss: 0.4523399770259857\n",
      "Epoch 257, Loss: 0.9081664681434631, Final Batch Loss: 0.45670419931411743\n",
      "Epoch 258, Loss: 0.8691001534461975, Final Batch Loss: 0.4469645619392395\n",
      "Epoch 259, Loss: 0.8712625205516815, Final Batch Loss: 0.41619792580604553\n",
      "Epoch 260, Loss: 0.8275972902774811, Final Batch Loss: 0.4203435480594635\n",
      "Epoch 261, Loss: 0.9193601906299591, Final Batch Loss: 0.47863221168518066\n",
      "Epoch 262, Loss: 0.8777846693992615, Final Batch Loss: 0.43989941477775574\n",
      "Epoch 263, Loss: 0.8597220480442047, Final Batch Loss: 0.4335012435913086\n",
      "Epoch 264, Loss: 0.8194614946842194, Final Batch Loss: 0.39079079031944275\n",
      "Epoch 265, Loss: 0.8050625920295715, Final Batch Loss: 0.39606747031211853\n",
      "Epoch 266, Loss: 0.8102928698062897, Final Batch Loss: 0.4301305115222931\n",
      "Epoch 267, Loss: 0.8680374920368195, Final Batch Loss: 0.416677862405777\n",
      "Epoch 268, Loss: 0.8209937512874603, Final Batch Loss: 0.3912947177886963\n",
      "Epoch 269, Loss: 0.8785590529441833, Final Batch Loss: 0.4460228681564331\n",
      "Epoch 270, Loss: 0.7939574718475342, Final Batch Loss: 0.4016449451446533\n",
      "Epoch 271, Loss: 0.8600004315376282, Final Batch Loss: 0.40953049063682556\n",
      "Epoch 272, Loss: 0.7642245590686798, Final Batch Loss: 0.3552147150039673\n",
      "Epoch 273, Loss: 0.7994058728218079, Final Batch Loss: 0.4025363028049469\n",
      "Epoch 274, Loss: 0.8603491485118866, Final Batch Loss: 0.3888905346393585\n",
      "Epoch 275, Loss: 0.7705718874931335, Final Batch Loss: 0.3562365770339966\n",
      "Epoch 276, Loss: 0.7714270949363708, Final Batch Loss: 0.34510087966918945\n",
      "Epoch 277, Loss: 0.7691608965396881, Final Batch Loss: 0.38310104608535767\n",
      "Epoch 278, Loss: 0.7960188090801239, Final Batch Loss: 0.41551417112350464\n",
      "Epoch 279, Loss: 0.8416224718093872, Final Batch Loss: 0.47699588537216187\n",
      "Epoch 280, Loss: 0.7659418284893036, Final Batch Loss: 0.3909777104854584\n",
      "Epoch 281, Loss: 0.8753639161586761, Final Batch Loss: 0.5175426006317139\n",
      "Epoch 282, Loss: 0.7028033137321472, Final Batch Loss: 0.37204283475875854\n",
      "Epoch 283, Loss: 0.7677509486675262, Final Batch Loss: 0.3791154623031616\n",
      "Epoch 284, Loss: 0.8268674910068512, Final Batch Loss: 0.44612178206443787\n",
      "Epoch 285, Loss: 0.7411646544933319, Final Batch Loss: 0.3757917881011963\n",
      "Epoch 286, Loss: 0.7744410932064056, Final Batch Loss: 0.41817015409469604\n",
      "Epoch 287, Loss: 0.7126549184322357, Final Batch Loss: 0.3132345676422119\n",
      "Epoch 288, Loss: 0.7511544227600098, Final Batch Loss: 0.37567800283432007\n",
      "Epoch 289, Loss: 0.7388170659542084, Final Batch Loss: 0.3776707053184509\n",
      "Epoch 290, Loss: 0.7732597589492798, Final Batch Loss: 0.4060095548629761\n",
      "Epoch 291, Loss: 0.7623479068279266, Final Batch Loss: 0.3563896715641022\n",
      "Epoch 292, Loss: 0.7843349874019623, Final Batch Loss: 0.4427289366722107\n",
      "Epoch 293, Loss: 0.7709163427352905, Final Batch Loss: 0.3540833294391632\n",
      "Epoch 294, Loss: 0.7816781401634216, Final Batch Loss: 0.431716650724411\n",
      "Epoch 295, Loss: 0.7257916331291199, Final Batch Loss: 0.33373355865478516\n",
      "Epoch 296, Loss: 0.7378178834915161, Final Batch Loss: 0.37882721424102783\n",
      "Epoch 297, Loss: 0.7381553649902344, Final Batch Loss: 0.3879222571849823\n",
      "Epoch 298, Loss: 0.7082934379577637, Final Batch Loss: 0.37000975012779236\n",
      "Epoch 299, Loss: 0.7461018860340118, Final Batch Loss: 0.3551209270954132\n",
      "Epoch 300, Loss: 0.7335678339004517, Final Batch Loss: 0.36281436681747437\n",
      "Epoch 301, Loss: 0.7017067670822144, Final Batch Loss: 0.3403222858905792\n",
      "Epoch 302, Loss: 0.7172620296478271, Final Batch Loss: 0.3494121730327606\n",
      "Epoch 303, Loss: 0.7645917236804962, Final Batch Loss: 0.3957025110721588\n",
      "Epoch 304, Loss: 0.7238045930862427, Final Batch Loss: 0.3409869074821472\n",
      "Epoch 305, Loss: 0.7425886988639832, Final Batch Loss: 0.35992708802223206\n",
      "Epoch 306, Loss: 0.6822096109390259, Final Batch Loss: 0.37185192108154297\n",
      "Epoch 307, Loss: 0.652902364730835, Final Batch Loss: 0.3053037226200104\n",
      "Epoch 308, Loss: 0.8013176620006561, Final Batch Loss: 0.46730872988700867\n",
      "Epoch 309, Loss: 0.6979442834854126, Final Batch Loss: 0.3562481701374054\n",
      "Epoch 310, Loss: 0.6581215262413025, Final Batch Loss: 0.3516565263271332\n",
      "Epoch 311, Loss: 0.6725730895996094, Final Batch Loss: 0.3802413046360016\n",
      "Epoch 312, Loss: 0.7048748135566711, Final Batch Loss: 0.31316906213760376\n",
      "Epoch 313, Loss: 0.647750198841095, Final Batch Loss: 0.3292485773563385\n",
      "Epoch 314, Loss: 0.6885225176811218, Final Batch Loss: 0.36215147376060486\n",
      "Epoch 315, Loss: 0.6390518844127655, Final Batch Loss: 0.31153184175491333\n",
      "Epoch 316, Loss: 0.690344363451004, Final Batch Loss: 0.3452704846858978\n",
      "Epoch 317, Loss: 0.7328111827373505, Final Batch Loss: 0.3854270577430725\n",
      "Epoch 318, Loss: 0.6519714891910553, Final Batch Loss: 0.3120368719100952\n",
      "Epoch 319, Loss: 0.7185165286064148, Final Batch Loss: 0.4018612504005432\n",
      "Epoch 320, Loss: 0.7404043078422546, Final Batch Loss: 0.39372819662094116\n",
      "Epoch 321, Loss: 0.6435866951942444, Final Batch Loss: 0.32583150267601013\n",
      "Epoch 322, Loss: 0.6913188099861145, Final Batch Loss: 0.34104594588279724\n",
      "Epoch 323, Loss: 0.6491670310497284, Final Batch Loss: 0.31187209486961365\n",
      "Epoch 324, Loss: 0.6469740867614746, Final Batch Loss: 0.3011311888694763\n",
      "Epoch 325, Loss: 0.6262242197990417, Final Batch Loss: 0.313403844833374\n",
      "Epoch 326, Loss: 0.657356858253479, Final Batch Loss: 0.36762213706970215\n",
      "Epoch 327, Loss: 0.7537121474742889, Final Batch Loss: 0.4629654288291931\n",
      "Epoch 328, Loss: 0.6472145915031433, Final Batch Loss: 0.3218232989311218\n",
      "Epoch 329, Loss: 0.6879220008850098, Final Batch Loss: 0.36285218596458435\n",
      "Epoch 330, Loss: 0.6290622651576996, Final Batch Loss: 0.31994175910949707\n",
      "Epoch 331, Loss: 0.6766285002231598, Final Batch Loss: 0.381107896566391\n",
      "Epoch 332, Loss: 0.6682803332805634, Final Batch Loss: 0.33600300550460815\n",
      "Epoch 333, Loss: 0.6170349717140198, Final Batch Loss: 0.24662074446678162\n",
      "Epoch 334, Loss: 0.7174535095691681, Final Batch Loss: 0.39878740906715393\n",
      "Epoch 335, Loss: 0.5942418575286865, Final Batch Loss: 0.28431206941604614\n",
      "Epoch 336, Loss: 0.6464115083217621, Final Batch Loss: 0.2926434576511383\n",
      "Epoch 337, Loss: 0.6339814960956573, Final Batch Loss: 0.30412155389785767\n",
      "Epoch 338, Loss: 0.6569907069206238, Final Batch Loss: 0.3283681571483612\n",
      "Epoch 339, Loss: 0.5558699071407318, Final Batch Loss: 0.2613097131252289\n",
      "Epoch 340, Loss: 0.6413616836071014, Final Batch Loss: 0.3651483952999115\n",
      "Epoch 341, Loss: 0.6089485436677933, Final Batch Loss: 0.24655897915363312\n",
      "Epoch 342, Loss: 0.6121927797794342, Final Batch Loss: 0.2784120738506317\n",
      "Epoch 343, Loss: 0.6135762333869934, Final Batch Loss: 0.3348727226257324\n",
      "Epoch 344, Loss: 0.6218689680099487, Final Batch Loss: 0.29882171750068665\n",
      "Epoch 345, Loss: 0.6226443946361542, Final Batch Loss: 0.28727495670318604\n",
      "Epoch 346, Loss: 0.6193424165248871, Final Batch Loss: 0.3021218478679657\n",
      "Epoch 347, Loss: 0.6188074052333832, Final Batch Loss: 0.29260626435279846\n",
      "Epoch 348, Loss: 0.6237369477748871, Final Batch Loss: 0.30311504006385803\n",
      "Epoch 349, Loss: 0.6028592884540558, Final Batch Loss: 0.30076122283935547\n",
      "Epoch 350, Loss: 0.5402119159698486, Final Batch Loss: 0.26181089878082275\n",
      "Epoch 351, Loss: 0.5224746316671371, Final Batch Loss: 0.23916776478290558\n",
      "Epoch 352, Loss: 0.6124725639820099, Final Batch Loss: 0.3217286169528961\n",
      "Epoch 353, Loss: 0.6709046959877014, Final Batch Loss: 0.36314937472343445\n",
      "Epoch 354, Loss: 0.5817780494689941, Final Batch Loss: 0.28495609760284424\n",
      "Epoch 355, Loss: 0.6435585618019104, Final Batch Loss: 0.319877564907074\n",
      "Epoch 356, Loss: 0.5707103908061981, Final Batch Loss: 0.2937410771846771\n",
      "Epoch 357, Loss: 0.587306559085846, Final Batch Loss: 0.2764827013015747\n",
      "Epoch 358, Loss: 0.582071378827095, Final Batch Loss: 0.33730795979499817\n",
      "Epoch 359, Loss: 0.5733562707901001, Final Batch Loss: 0.2821836471557617\n",
      "Epoch 360, Loss: 0.5785741806030273, Final Batch Loss: 0.2631154954433441\n",
      "Epoch 361, Loss: 0.6183737367391586, Final Batch Loss: 0.3770250380039215\n",
      "Epoch 362, Loss: 0.5136981904506683, Final Batch Loss: 0.2690052390098572\n",
      "Epoch 363, Loss: 0.5625907182693481, Final Batch Loss: 0.25689151883125305\n",
      "Epoch 364, Loss: 0.5204271972179413, Final Batch Loss: 0.2451286017894745\n",
      "Epoch 365, Loss: 0.6640913784503937, Final Batch Loss: 0.39363574981689453\n",
      "Epoch 366, Loss: 0.5647629648447037, Final Batch Loss: 0.3205548822879791\n",
      "Epoch 367, Loss: 0.5381559282541275, Final Batch Loss: 0.22585450112819672\n",
      "Epoch 368, Loss: 0.5101264268159866, Final Batch Loss: 0.231826052069664\n",
      "Epoch 369, Loss: 0.5697886943817139, Final Batch Loss: 0.3096063733100891\n",
      "Epoch 370, Loss: 0.5039068311452866, Final Batch Loss: 0.2637902796268463\n",
      "Epoch 371, Loss: 0.5909398198127747, Final Batch Loss: 0.2983558177947998\n",
      "Epoch 372, Loss: 0.55992791056633, Final Batch Loss: 0.28042489290237427\n",
      "Epoch 373, Loss: 0.5087479501962662, Final Batch Loss: 0.21963955461978912\n",
      "Epoch 374, Loss: 0.5492660105228424, Final Batch Loss: 0.26632097363471985\n",
      "Epoch 375, Loss: 0.5257140696048737, Final Batch Loss: 0.27285584807395935\n",
      "Epoch 376, Loss: 0.5056748986244202, Final Batch Loss: 0.22398826479911804\n",
      "Epoch 377, Loss: 0.5401816964149475, Final Batch Loss: 0.2689172029495239\n",
      "Epoch 378, Loss: 0.5488182008266449, Final Batch Loss: 0.2677571177482605\n",
      "Epoch 379, Loss: 0.5472313165664673, Final Batch Loss: 0.2861849367618561\n",
      "Epoch 380, Loss: 0.5215795934200287, Final Batch Loss: 0.2501649558544159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381, Loss: 0.48822708427906036, Final Batch Loss: 0.25192463397979736\n",
      "Epoch 382, Loss: 0.5691094398498535, Final Batch Loss: 0.3040641248226166\n",
      "Epoch 383, Loss: 0.519255205988884, Final Batch Loss: 0.2716001272201538\n",
      "Epoch 384, Loss: 0.5594711303710938, Final Batch Loss: 0.33699750900268555\n",
      "Epoch 385, Loss: 0.5043693631887436, Final Batch Loss: 0.2347538322210312\n",
      "Epoch 386, Loss: 0.5664767771959305, Final Batch Loss: 0.3181142508983612\n",
      "Epoch 387, Loss: 0.5060154497623444, Final Batch Loss: 0.2672952711582184\n",
      "Epoch 388, Loss: 0.5511579215526581, Final Batch Loss: 0.28488683700561523\n",
      "Epoch 389, Loss: 0.4684332311153412, Final Batch Loss: 0.22162199020385742\n",
      "Epoch 390, Loss: 0.4946771562099457, Final Batch Loss: 0.20956626534461975\n",
      "Epoch 391, Loss: 0.4809414744377136, Final Batch Loss: 0.15409404039382935\n",
      "Epoch 392, Loss: 0.4763984978199005, Final Batch Loss: 0.20497378706932068\n",
      "Epoch 393, Loss: 0.5120288133621216, Final Batch Loss: 0.24081668257713318\n",
      "Epoch 394, Loss: 0.4219951182603836, Final Batch Loss: 0.2031080424785614\n",
      "Epoch 395, Loss: 0.4380440413951874, Final Batch Loss: 0.2240402102470398\n",
      "Epoch 396, Loss: 0.4742104858160019, Final Batch Loss: 0.23864267766475677\n",
      "Epoch 397, Loss: 0.4482802450656891, Final Batch Loss: 0.19793912768363953\n",
      "Epoch 398, Loss: 0.4621848165988922, Final Batch Loss: 0.2671324908733368\n",
      "Epoch 399, Loss: 0.471864253282547, Final Batch Loss: 0.24633020162582397\n",
      "Epoch 400, Loss: 0.46850305795669556, Final Batch Loss: 0.21854162216186523\n",
      "Epoch 401, Loss: 0.41880202293395996, Final Batch Loss: 0.15378528833389282\n",
      "Epoch 402, Loss: 0.5187634825706482, Final Batch Loss: 0.28124234080314636\n",
      "Epoch 403, Loss: 0.42867541313171387, Final Batch Loss: 0.19591176509857178\n",
      "Epoch 404, Loss: 0.49201521277427673, Final Batch Loss: 0.2807234227657318\n",
      "Epoch 405, Loss: 0.4636436551809311, Final Batch Loss: 0.2559957504272461\n",
      "Epoch 406, Loss: 0.5418652594089508, Final Batch Loss: 0.2995668351650238\n",
      "Epoch 407, Loss: 0.46820980310440063, Final Batch Loss: 0.25275367498397827\n",
      "Epoch 408, Loss: 0.4843301922082901, Final Batch Loss: 0.26555320620536804\n",
      "Epoch 409, Loss: 0.5382156074047089, Final Batch Loss: 0.3043130934238434\n",
      "Epoch 410, Loss: 0.4766604006290436, Final Batch Loss: 0.27005767822265625\n",
      "Epoch 411, Loss: 0.41077829897403717, Final Batch Loss: 0.1832975149154663\n",
      "Epoch 412, Loss: 0.5242521017789841, Final Batch Loss: 0.23667998611927032\n",
      "Epoch 413, Loss: 0.40724557638168335, Final Batch Loss: 0.191719651222229\n",
      "Epoch 414, Loss: 0.3824072778224945, Final Batch Loss: 0.16012825071811676\n",
      "Epoch 415, Loss: 0.4424739181995392, Final Batch Loss: 0.2105901539325714\n",
      "Epoch 416, Loss: 0.5129124224185944, Final Batch Loss: 0.2792293429374695\n",
      "Epoch 417, Loss: 0.4340924173593521, Final Batch Loss: 0.2169242948293686\n",
      "Epoch 418, Loss: 0.4934787005186081, Final Batch Loss: 0.23615719377994537\n",
      "Epoch 419, Loss: 0.3920142203569412, Final Batch Loss: 0.16424117982387543\n",
      "Epoch 420, Loss: 0.509723350405693, Final Batch Loss: 0.3129625916481018\n",
      "Epoch 421, Loss: 0.4478522390127182, Final Batch Loss: 0.2056877315044403\n",
      "Epoch 422, Loss: 0.4513509273529053, Final Batch Loss: 0.2238040268421173\n",
      "Epoch 423, Loss: 0.49972952902317047, Final Batch Loss: 0.27844664454460144\n",
      "Epoch 424, Loss: 0.47880077362060547, Final Batch Loss: 0.25588375329971313\n",
      "Epoch 425, Loss: 0.432109534740448, Final Batch Loss: 0.22076603770256042\n",
      "Epoch 426, Loss: 0.4946061223745346, Final Batch Loss: 0.27497220039367676\n",
      "Epoch 427, Loss: 0.4164331704378128, Final Batch Loss: 0.21588176488876343\n",
      "Epoch 428, Loss: 0.5035011172294617, Final Batch Loss: 0.2719140648841858\n",
      "Epoch 429, Loss: 0.39460641145706177, Final Batch Loss: 0.18635830283164978\n",
      "Epoch 430, Loss: 0.4570389837026596, Final Batch Loss: 0.20050592720508575\n",
      "Epoch 431, Loss: 0.47324706614017487, Final Batch Loss: 0.20718149840831757\n",
      "Epoch 432, Loss: 0.5341211557388306, Final Batch Loss: 0.3130030930042267\n",
      "Epoch 433, Loss: 0.42435891926288605, Final Batch Loss: 0.15783588588237762\n",
      "Epoch 434, Loss: 0.48881272971630096, Final Batch Loss: 0.2782900929450989\n",
      "Epoch 435, Loss: 0.4013432264328003, Final Batch Loss: 0.1972346156835556\n",
      "Epoch 436, Loss: 0.4468441903591156, Final Batch Loss: 0.18023496866226196\n",
      "Epoch 437, Loss: 0.4270373284816742, Final Batch Loss: 0.20564347505569458\n",
      "Epoch 438, Loss: 0.4293573647737503, Final Batch Loss: 0.20944999158382416\n",
      "Epoch 439, Loss: 0.4309137314558029, Final Batch Loss: 0.19725583493709564\n",
      "Epoch 440, Loss: 0.4054550975561142, Final Batch Loss: 0.19500517845153809\n",
      "Epoch 441, Loss: 0.3986295610666275, Final Batch Loss: 0.17409242689609528\n",
      "Epoch 442, Loss: 0.4365905821323395, Final Batch Loss: 0.2250593602657318\n",
      "Epoch 443, Loss: 0.43490850925445557, Final Batch Loss: 0.23125983774662018\n",
      "Epoch 444, Loss: 0.37508420646190643, Final Batch Loss: 0.17204703390598297\n",
      "Epoch 445, Loss: 0.43072840571403503, Final Batch Loss: 0.2518187463283539\n",
      "Epoch 446, Loss: 0.41685473918914795, Final Batch Loss: 0.20974741876125336\n",
      "Epoch 447, Loss: 0.4974130541086197, Final Batch Loss: 0.2687971293926239\n",
      "Epoch 448, Loss: 0.3631300628185272, Final Batch Loss: 0.15602655708789825\n",
      "Epoch 449, Loss: 0.4969114363193512, Final Batch Loss: 0.20689105987548828\n",
      "Epoch 450, Loss: 0.4179941564798355, Final Batch Loss: 0.22430016100406647\n",
      "Epoch 451, Loss: 0.4011402428150177, Final Batch Loss: 0.22325187921524048\n",
      "Epoch 452, Loss: 0.4183885008096695, Final Batch Loss: 0.20668736100196838\n",
      "Epoch 453, Loss: 0.39285145699977875, Final Batch Loss: 0.230251744389534\n",
      "Epoch 454, Loss: 0.4189702570438385, Final Batch Loss: 0.21040090918540955\n",
      "Epoch 455, Loss: 0.3519032895565033, Final Batch Loss: 0.17374853789806366\n",
      "Epoch 456, Loss: 0.3962164372205734, Final Batch Loss: 0.16581860184669495\n",
      "Epoch 457, Loss: 0.38076552748680115, Final Batch Loss: 0.20894674956798553\n",
      "Epoch 458, Loss: 0.3567638695240021, Final Batch Loss: 0.19939211010932922\n",
      "Epoch 459, Loss: 0.38755565136671066, Final Batch Loss: 0.12139003723859787\n",
      "Epoch 460, Loss: 0.42073316872119904, Final Batch Loss: 0.2143668234348297\n",
      "Epoch 461, Loss: 0.4009335786104202, Final Batch Loss: 0.2216583639383316\n",
      "Epoch 462, Loss: 0.39540861546993256, Final Batch Loss: 0.18845537304878235\n",
      "Epoch 463, Loss: 0.38855020701885223, Final Batch Loss: 0.1948319524526596\n",
      "Epoch 464, Loss: 0.41824254393577576, Final Batch Loss: 0.20312851667404175\n",
      "Epoch 465, Loss: 0.37124399840831757, Final Batch Loss: 0.21356792747974396\n",
      "Epoch 466, Loss: 0.3685746043920517, Final Batch Loss: 0.133367657661438\n",
      "Epoch 467, Loss: 0.4156666249036789, Final Batch Loss: 0.18794459104537964\n",
      "Epoch 468, Loss: 0.3998165428638458, Final Batch Loss: 0.17917534708976746\n",
      "Epoch 469, Loss: 0.3834383338689804, Final Batch Loss: 0.17083978652954102\n",
      "Epoch 470, Loss: 0.3561023026704788, Final Batch Loss: 0.1795211136341095\n",
      "Epoch 471, Loss: 0.3849644511938095, Final Batch Loss: 0.17625750601291656\n",
      "Epoch 472, Loss: 0.3846726268529892, Final Batch Loss: 0.1535104215145111\n",
      "Epoch 473, Loss: 0.3375962972640991, Final Batch Loss: 0.18724176287651062\n",
      "Epoch 474, Loss: 0.37768179178237915, Final Batch Loss: 0.20179681479930878\n",
      "Epoch 475, Loss: 0.36081038415431976, Final Batch Loss: 0.2029017060995102\n",
      "Epoch 476, Loss: 0.33131037652492523, Final Batch Loss: 0.16086766123771667\n",
      "Epoch 477, Loss: 0.3699144721031189, Final Batch Loss: 0.17072415351867676\n",
      "Epoch 478, Loss: 0.33926232159137726, Final Batch Loss: 0.14196613430976868\n",
      "Epoch 479, Loss: 0.38568371534347534, Final Batch Loss: 0.19703063368797302\n",
      "Epoch 480, Loss: 0.41686587035655975, Final Batch Loss: 0.2511623501777649\n",
      "Epoch 481, Loss: 0.4107408970594406, Final Batch Loss: 0.22377946972846985\n",
      "Epoch 482, Loss: 0.35606637597084045, Final Batch Loss: 0.18737488985061646\n",
      "Epoch 483, Loss: 0.361626461148262, Final Batch Loss: 0.16965463757514954\n",
      "Epoch 484, Loss: 0.3625623285770416, Final Batch Loss: 0.15255391597747803\n",
      "Epoch 485, Loss: 0.43159119784832, Final Batch Loss: 0.24013538658618927\n",
      "Epoch 486, Loss: 0.38783620297908783, Final Batch Loss: 0.20284010469913483\n",
      "Epoch 487, Loss: 0.3392408788204193, Final Batch Loss: 0.1529550701379776\n",
      "Epoch 488, Loss: 0.32834120839834213, Final Batch Loss: 0.12111193686723709\n",
      "Epoch 489, Loss: 0.38994498550891876, Final Batch Loss: 0.19364890456199646\n",
      "Epoch 490, Loss: 0.3352653533220291, Final Batch Loss: 0.15586909651756287\n",
      "Epoch 491, Loss: 0.4092756360769272, Final Batch Loss: 0.243483766913414\n",
      "Epoch 492, Loss: 0.3884955793619156, Final Batch Loss: 0.17804943025112152\n",
      "Epoch 493, Loss: 0.3529713749885559, Final Batch Loss: 0.1931242197751999\n",
      "Epoch 494, Loss: 0.3675452023744583, Final Batch Loss: 0.20793652534484863\n",
      "Epoch 495, Loss: 0.4137149006128311, Final Batch Loss: 0.2410706728696823\n",
      "Epoch 496, Loss: 0.42679712176322937, Final Batch Loss: 0.2594110369682312\n",
      "Epoch 497, Loss: 0.39831510186195374, Final Batch Loss: 0.21540701389312744\n",
      "Epoch 498, Loss: 0.3927190601825714, Final Batch Loss: 0.21792913973331451\n",
      "Epoch 499, Loss: 0.45497751235961914, Final Batch Loss: 0.2627542316913605\n",
      "Epoch 500, Loss: 0.37543024122714996, Final Batch Loss: 0.17093338072299957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501, Loss: 0.34051595628261566, Final Batch Loss: 0.15880835056304932\n",
      "Epoch 502, Loss: 0.3460211306810379, Final Batch Loss: 0.15395186841487885\n",
      "Epoch 503, Loss: 0.33691129088401794, Final Batch Loss: 0.1654767394065857\n",
      "Epoch 504, Loss: 0.36352385580539703, Final Batch Loss: 0.20496974885463715\n",
      "Epoch 505, Loss: 0.34043246507644653, Final Batch Loss: 0.16870316863059998\n",
      "Epoch 506, Loss: 0.39422713220119476, Final Batch Loss: 0.20164619386196136\n",
      "Epoch 507, Loss: 0.33910132944583893, Final Batch Loss: 0.18396033346652985\n",
      "Epoch 508, Loss: 0.3477455973625183, Final Batch Loss: 0.17897501587867737\n",
      "Epoch 509, Loss: 0.37061940133571625, Final Batch Loss: 0.22714222967624664\n",
      "Epoch 510, Loss: 0.41776856780052185, Final Batch Loss: 0.26378315687179565\n",
      "Epoch 511, Loss: 0.38013362884521484, Final Batch Loss: 0.1974351853132248\n",
      "Epoch 512, Loss: 0.5051225423812866, Final Batch Loss: 0.3068047761917114\n",
      "Epoch 513, Loss: 0.31010785698890686, Final Batch Loss: 0.1787334680557251\n",
      "Epoch 514, Loss: 0.3007994592189789, Final Batch Loss: 0.13852140307426453\n",
      "Epoch 515, Loss: 0.3717253804206848, Final Batch Loss: 0.2453211098909378\n",
      "Epoch 516, Loss: 0.30521272122859955, Final Batch Loss: 0.14807359874248505\n",
      "Epoch 517, Loss: 0.3358524292707443, Final Batch Loss: 0.14568984508514404\n",
      "Epoch 518, Loss: 0.38769564032554626, Final Batch Loss: 0.21467150747776031\n",
      "Epoch 519, Loss: 0.33935506641864777, Final Batch Loss: 0.17527079582214355\n",
      "Epoch 520, Loss: 0.392450749874115, Final Batch Loss: 0.1906924545764923\n",
      "Epoch 521, Loss: 0.32575085759162903, Final Batch Loss: 0.15835638344287872\n",
      "Epoch 522, Loss: 0.31867876648902893, Final Batch Loss: 0.1517205685377121\n",
      "Epoch 523, Loss: 0.44913753867149353, Final Batch Loss: 0.2953489124774933\n",
      "Epoch 524, Loss: 0.31789731979370117, Final Batch Loss: 0.17988865077495575\n",
      "Epoch 525, Loss: 0.3261953294277191, Final Batch Loss: 0.1560896784067154\n",
      "Epoch 526, Loss: 0.3278450220823288, Final Batch Loss: 0.11265517771244049\n",
      "Epoch 527, Loss: 0.36856555938720703, Final Batch Loss: 0.18938568234443665\n",
      "Epoch 528, Loss: 0.34782563149929047, Final Batch Loss: 0.17901140451431274\n",
      "Epoch 529, Loss: 0.3150360584259033, Final Batch Loss: 0.15638144314289093\n",
      "Epoch 530, Loss: 0.34921038150787354, Final Batch Loss: 0.16217373311519623\n",
      "Epoch 531, Loss: 0.35459430515766144, Final Batch Loss: 0.1590624749660492\n",
      "Epoch 532, Loss: 0.36846792697906494, Final Batch Loss: 0.17803819477558136\n",
      "Epoch 533, Loss: 0.3494876027107239, Final Batch Loss: 0.11135110259056091\n",
      "Epoch 534, Loss: 0.3209197074174881, Final Batch Loss: 0.17094090580940247\n",
      "Epoch 535, Loss: 0.28441590815782547, Final Batch Loss: 0.11498434096574783\n",
      "Epoch 536, Loss: 0.4003491699695587, Final Batch Loss: 0.20993849635124207\n",
      "Epoch 537, Loss: 0.34913308918476105, Final Batch Loss: 0.1539832502603531\n",
      "Epoch 538, Loss: 0.39039212465286255, Final Batch Loss: 0.21620473265647888\n",
      "Epoch 539, Loss: 0.3439919203519821, Final Batch Loss: 0.1852198988199234\n",
      "Epoch 540, Loss: 0.3625362068414688, Final Batch Loss: 0.18845076858997345\n",
      "Epoch 541, Loss: 0.40126416087150574, Final Batch Loss: 0.22824743390083313\n",
      "Epoch 542, Loss: 0.33392827212810516, Final Batch Loss: 0.14249669015407562\n",
      "Epoch 543, Loss: 0.36012357473373413, Final Batch Loss: 0.17343056201934814\n",
      "Epoch 544, Loss: 0.37659604847431183, Final Batch Loss: 0.1548096239566803\n",
      "Epoch 545, Loss: 0.33631591498851776, Final Batch Loss: 0.1398342102766037\n",
      "Epoch 546, Loss: 0.3699645698070526, Final Batch Loss: 0.1773882806301117\n",
      "Epoch 547, Loss: 0.29338547587394714, Final Batch Loss: 0.1379423886537552\n",
      "Epoch 548, Loss: 0.38665270805358887, Final Batch Loss: 0.19644059240818024\n",
      "Epoch 549, Loss: 0.27676665782928467, Final Batch Loss: 0.1276763379573822\n",
      "Epoch 550, Loss: 0.30054871737957, Final Batch Loss: 0.11971378326416016\n",
      "Epoch 551, Loss: 0.3104150593280792, Final Batch Loss: 0.16373777389526367\n",
      "Epoch 552, Loss: 0.3003937900066376, Final Batch Loss: 0.13497617840766907\n",
      "Epoch 553, Loss: 0.3754805475473404, Final Batch Loss: 0.19332636892795563\n",
      "Epoch 554, Loss: 0.3115270584821701, Final Batch Loss: 0.18272551894187927\n",
      "Epoch 555, Loss: 0.3555544316768646, Final Batch Loss: 0.19844987988471985\n",
      "Epoch 556, Loss: 0.2945253551006317, Final Batch Loss: 0.12684978544712067\n",
      "Epoch 557, Loss: 0.3135295808315277, Final Batch Loss: 0.1495000272989273\n",
      "Epoch 558, Loss: 0.32619620859622955, Final Batch Loss: 0.2003180831670761\n",
      "Epoch 559, Loss: 0.27984167635440826, Final Batch Loss: 0.12874065339565277\n",
      "Epoch 560, Loss: 0.2913687229156494, Final Batch Loss: 0.1354198157787323\n",
      "Epoch 561, Loss: 0.33389027416706085, Final Batch Loss: 0.16416434943675995\n",
      "Epoch 562, Loss: 0.31786462664604187, Final Batch Loss: 0.14338527619838715\n",
      "Epoch 563, Loss: 0.28528452664613724, Final Batch Loss: 0.09733173996210098\n",
      "Epoch 564, Loss: 0.3541271835565567, Final Batch Loss: 0.1621355265378952\n",
      "Epoch 565, Loss: 0.2983156442642212, Final Batch Loss: 0.16979414224624634\n",
      "Epoch 566, Loss: 0.2743927463889122, Final Batch Loss: 0.11761198192834854\n",
      "Epoch 567, Loss: 0.36739344894886017, Final Batch Loss: 0.20203663408756256\n",
      "Epoch 568, Loss: 0.25898557901382446, Final Batch Loss: 0.1288854330778122\n",
      "Epoch 569, Loss: 0.3405972421169281, Final Batch Loss: 0.1919749677181244\n",
      "Epoch 570, Loss: 0.2798096388578415, Final Batch Loss: 0.1452321857213974\n",
      "Epoch 571, Loss: 0.2935681492090225, Final Batch Loss: 0.147664874792099\n",
      "Epoch 572, Loss: 0.2965351641178131, Final Batch Loss: 0.13515552878379822\n",
      "Epoch 573, Loss: 0.3138056695461273, Final Batch Loss: 0.13851994276046753\n",
      "Epoch 574, Loss: 0.34914420545101166, Final Batch Loss: 0.18552766740322113\n",
      "Epoch 575, Loss: 0.32141461968421936, Final Batch Loss: 0.16176791489124298\n",
      "Epoch 576, Loss: 0.34111255407333374, Final Batch Loss: 0.20455482602119446\n",
      "Epoch 577, Loss: 0.28287212550640106, Final Batch Loss: 0.14238674938678741\n",
      "Epoch 578, Loss: 0.2876121550798416, Final Batch Loss: 0.17358171939849854\n",
      "Epoch 579, Loss: 0.3425539880990982, Final Batch Loss: 0.19645632803440094\n",
      "Epoch 580, Loss: 0.32618245482444763, Final Batch Loss: 0.17239025235176086\n",
      "Epoch 581, Loss: 0.2832387164235115, Final Batch Loss: 0.16108806431293488\n",
      "Epoch 582, Loss: 0.2752677798271179, Final Batch Loss: 0.1114177256822586\n",
      "Epoch 583, Loss: 0.3124852478504181, Final Batch Loss: 0.14952483773231506\n",
      "Epoch 584, Loss: 0.2269507348537445, Final Batch Loss: 0.0988387018442154\n",
      "Epoch 585, Loss: 0.31311872601509094, Final Batch Loss: 0.13418759405612946\n",
      "Epoch 586, Loss: 0.3056296929717064, Final Batch Loss: 0.18317697942256927\n",
      "Epoch 587, Loss: 0.34061621129512787, Final Batch Loss: 0.1748153120279312\n",
      "Epoch 588, Loss: 0.2953183874487877, Final Batch Loss: 0.17897813022136688\n",
      "Epoch 589, Loss: 0.2975138947367668, Final Batch Loss: 0.11213686317205429\n",
      "Epoch 590, Loss: 0.3140004873275757, Final Batch Loss: 0.12801094353199005\n",
      "Epoch 591, Loss: 0.286749929189682, Final Batch Loss: 0.11363044381141663\n",
      "Epoch 592, Loss: 0.3510490208864212, Final Batch Loss: 0.2003193348646164\n",
      "Epoch 593, Loss: 0.32425758242607117, Final Batch Loss: 0.1705644428730011\n",
      "Epoch 594, Loss: 0.2720896303653717, Final Batch Loss: 0.10325510799884796\n",
      "Epoch 595, Loss: 0.303109772503376, Final Batch Loss: 0.11182750016450882\n",
      "Epoch 596, Loss: 0.2604001984000206, Final Batch Loss: 0.12117543071508408\n",
      "Epoch 597, Loss: 0.3196772485971451, Final Batch Loss: 0.16343696415424347\n",
      "Epoch 598, Loss: 0.3092890828847885, Final Batch Loss: 0.1780051440000534\n",
      "Epoch 599, Loss: 0.359540730714798, Final Batch Loss: 0.1645338088274002\n",
      "Epoch 600, Loss: 0.30984145402908325, Final Batch Loss: 0.14922665059566498\n",
      "Epoch 601, Loss: 0.26240256428718567, Final Batch Loss: 0.14029623568058014\n",
      "Epoch 602, Loss: 0.2993145287036896, Final Batch Loss: 0.13852477073669434\n",
      "Epoch 603, Loss: 0.2586619555950165, Final Batch Loss: 0.10807238519191742\n",
      "Epoch 604, Loss: 0.26324793696403503, Final Batch Loss: 0.13183817267417908\n",
      "Epoch 605, Loss: 0.3126010447740555, Final Batch Loss: 0.1290159374475479\n",
      "Epoch 606, Loss: 0.2825957089662552, Final Batch Loss: 0.13921095430850983\n",
      "Epoch 607, Loss: 0.28888319432735443, Final Batch Loss: 0.1316794753074646\n",
      "Epoch 608, Loss: 0.3064880669116974, Final Batch Loss: 0.1653291881084442\n",
      "Epoch 609, Loss: 0.28107406198978424, Final Batch Loss: 0.14314693212509155\n",
      "Epoch 610, Loss: 0.2905000001192093, Final Batch Loss: 0.15138237178325653\n",
      "Epoch 611, Loss: 0.2990207225084305, Final Batch Loss: 0.14611651003360748\n",
      "Epoch 612, Loss: 0.269203782081604, Final Batch Loss: 0.12184876203536987\n",
      "Epoch 613, Loss: 0.30194510519504547, Final Batch Loss: 0.14391472935676575\n",
      "Epoch 614, Loss: 0.3153121769428253, Final Batch Loss: 0.16634012758731842\n",
      "Epoch 615, Loss: 0.25830161571502686, Final Batch Loss: 0.12808983027935028\n",
      "Epoch 616, Loss: 0.2504947781562805, Final Batch Loss: 0.11195015907287598\n",
      "Epoch 617, Loss: 0.28753790259361267, Final Batch Loss: 0.16963985562324524\n",
      "Epoch 618, Loss: 0.2914903536438942, Final Batch Loss: 0.12418224662542343\n",
      "Epoch 619, Loss: 0.3007918447256088, Final Batch Loss: 0.16377869248390198\n",
      "Epoch 620, Loss: 0.2909202575683594, Final Batch Loss: 0.1752585917711258\n",
      "Epoch 621, Loss: 0.2966670021414757, Final Batch Loss: 0.1843588650226593\n",
      "Epoch 622, Loss: 0.3310665637254715, Final Batch Loss: 0.1557604819536209\n",
      "Epoch 623, Loss: 0.23767172545194626, Final Batch Loss: 0.08834045380353928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624, Loss: 0.30455004423856735, Final Batch Loss: 0.20931018888950348\n",
      "Epoch 625, Loss: 0.28106050938367844, Final Batch Loss: 0.17219002544879913\n",
      "Epoch 626, Loss: 0.40957364439964294, Final Batch Loss: 0.22951658070087433\n",
      "Epoch 627, Loss: 0.31116145104169846, Final Batch Loss: 0.12180838733911514\n",
      "Epoch 628, Loss: 0.3195890188217163, Final Batch Loss: 0.18444529175758362\n",
      "Epoch 629, Loss: 0.3197125047445297, Final Batch Loss: 0.14395080506801605\n",
      "Epoch 630, Loss: 0.28470084071159363, Final Batch Loss: 0.15392564237117767\n",
      "Epoch 631, Loss: 0.325519323348999, Final Batch Loss: 0.16829383373260498\n",
      "Epoch 632, Loss: 0.2932065725326538, Final Batch Loss: 0.14999288320541382\n",
      "Epoch 633, Loss: 0.24834511429071426, Final Batch Loss: 0.11269605904817581\n",
      "Epoch 634, Loss: 0.29809989035129547, Final Batch Loss: 0.15608036518096924\n",
      "Epoch 635, Loss: 0.25396086275577545, Final Batch Loss: 0.12607140839099884\n",
      "Epoch 636, Loss: 0.26121821254491806, Final Batch Loss: 0.1017889603972435\n",
      "Epoch 637, Loss: 0.2527680993080139, Final Batch Loss: 0.11869321763515472\n",
      "Epoch 638, Loss: 0.238814078271389, Final Batch Loss: 0.07494383305311203\n",
      "Epoch 639, Loss: 0.3041071891784668, Final Batch Loss: 0.12694992125034332\n",
      "Epoch 640, Loss: 0.2782299667596817, Final Batch Loss: 0.13148629665374756\n",
      "Epoch 641, Loss: 0.23894842714071274, Final Batch Loss: 0.10361767560243607\n",
      "Epoch 642, Loss: 0.2648031860589981, Final Batch Loss: 0.12600703537464142\n",
      "Epoch 643, Loss: 0.25300023704767227, Final Batch Loss: 0.12403497844934464\n",
      "Epoch 644, Loss: 0.23508501052856445, Final Batch Loss: 0.08393283188343048\n",
      "Epoch 645, Loss: 0.26835887134075165, Final Batch Loss: 0.14195294678211212\n",
      "Epoch 646, Loss: 0.2675364166498184, Final Batch Loss: 0.08774703741073608\n",
      "Epoch 647, Loss: 0.22000663727521896, Final Batch Loss: 0.09929878264665604\n",
      "Epoch 648, Loss: 0.2751843258738518, Final Batch Loss: 0.16104401648044586\n",
      "Epoch 649, Loss: 0.2736087888479233, Final Batch Loss: 0.12806233763694763\n",
      "Epoch 650, Loss: 0.2952738106250763, Final Batch Loss: 0.16155698895454407\n",
      "Epoch 651, Loss: 0.2564666047692299, Final Batch Loss: 0.13197872042655945\n",
      "Epoch 652, Loss: 0.2699311152100563, Final Batch Loss: 0.14976634085178375\n",
      "Epoch 653, Loss: 0.2623312622308731, Final Batch Loss: 0.12782001495361328\n",
      "Epoch 654, Loss: 0.26764483749866486, Final Batch Loss: 0.1441386640071869\n",
      "Epoch 655, Loss: 0.26131388545036316, Final Batch Loss: 0.14484082162380219\n",
      "Epoch 656, Loss: 0.2125249058008194, Final Batch Loss: 0.09942159056663513\n",
      "Epoch 657, Loss: 0.2989504188299179, Final Batch Loss: 0.14649416506290436\n",
      "Epoch 658, Loss: 0.2711695358157158, Final Batch Loss: 0.11967719346284866\n",
      "Epoch 659, Loss: 0.288407102227211, Final Batch Loss: 0.17013350129127502\n",
      "Epoch 660, Loss: 0.24768786132335663, Final Batch Loss: 0.11808639764785767\n",
      "Epoch 661, Loss: 0.229280024766922, Final Batch Loss: 0.08744180202484131\n",
      "Epoch 662, Loss: 0.27238015830516815, Final Batch Loss: 0.13341352343559265\n",
      "Epoch 663, Loss: 0.30504027009010315, Final Batch Loss: 0.135715514421463\n",
      "Epoch 664, Loss: 0.2669576406478882, Final Batch Loss: 0.11940804123878479\n",
      "Epoch 665, Loss: 0.28003741055727005, Final Batch Loss: 0.10375791043043137\n",
      "Epoch 666, Loss: 0.21066045761108398, Final Batch Loss: 0.08584373444318771\n",
      "Epoch 667, Loss: 0.2586124762892723, Final Batch Loss: 0.1472095549106598\n",
      "Epoch 668, Loss: 0.2744978964328766, Final Batch Loss: 0.12435206770896912\n",
      "Epoch 669, Loss: 0.2757323831319809, Final Batch Loss: 0.15540049970149994\n",
      "Epoch 670, Loss: 0.25658971071243286, Final Batch Loss: 0.15936405956745148\n",
      "Epoch 671, Loss: 0.27974338829517365, Final Batch Loss: 0.16395790874958038\n",
      "Epoch 672, Loss: 0.2600972354412079, Final Batch Loss: 0.10716034471988678\n",
      "Epoch 673, Loss: 0.21687732636928558, Final Batch Loss: 0.1106608584523201\n",
      "Epoch 674, Loss: 0.22535759955644608, Final Batch Loss: 0.11616171151399612\n",
      "Epoch 675, Loss: 0.24475087225437164, Final Batch Loss: 0.10536141693592072\n",
      "Epoch 676, Loss: 0.21061129122972488, Final Batch Loss: 0.08555734902620316\n",
      "Epoch 677, Loss: 0.2236778810620308, Final Batch Loss: 0.09617716819047928\n",
      "Epoch 678, Loss: 0.2628752589225769, Final Batch Loss: 0.12690795958042145\n",
      "Epoch 679, Loss: 0.2483673319220543, Final Batch Loss: 0.12567885220050812\n",
      "Epoch 680, Loss: 0.24504511803388596, Final Batch Loss: 0.11957328766584396\n",
      "Epoch 681, Loss: 0.2426760271191597, Final Batch Loss: 0.13700777292251587\n",
      "Epoch 682, Loss: 0.27166101336479187, Final Batch Loss: 0.1192748099565506\n",
      "Epoch 683, Loss: 0.278731107711792, Final Batch Loss: 0.12670642137527466\n",
      "Epoch 684, Loss: 0.2686782628297806, Final Batch Loss: 0.11656039953231812\n",
      "Epoch 685, Loss: 0.25342757254838943, Final Batch Loss: 0.11697433143854141\n",
      "Epoch 686, Loss: 0.23359063267707825, Final Batch Loss: 0.1190185695886612\n",
      "Epoch 687, Loss: 0.24626628309488297, Final Batch Loss: 0.14413060247898102\n",
      "Epoch 688, Loss: 0.2467549666762352, Final Batch Loss: 0.09703557938337326\n",
      "Epoch 689, Loss: 0.20569787174463272, Final Batch Loss: 0.11533445864915848\n",
      "Epoch 690, Loss: 0.17301202565431595, Final Batch Loss: 0.07253558933734894\n",
      "Epoch 691, Loss: 0.24164564162492752, Final Batch Loss: 0.14376237988471985\n",
      "Epoch 692, Loss: 0.26620839536190033, Final Batch Loss: 0.1388169527053833\n",
      "Epoch 693, Loss: 0.2082776576280594, Final Batch Loss: 0.12636233866214752\n",
      "Epoch 694, Loss: 0.3192901834845543, Final Batch Loss: 0.19821405410766602\n",
      "Epoch 695, Loss: 0.22318940609693527, Final Batch Loss: 0.11546690762042999\n",
      "Epoch 696, Loss: 0.2036338374018669, Final Batch Loss: 0.08976048231124878\n",
      "Epoch 697, Loss: 0.2201259657740593, Final Batch Loss: 0.09787045419216156\n",
      "Epoch 698, Loss: 0.22030182927846909, Final Batch Loss: 0.09907069802284241\n",
      "Epoch 699, Loss: 0.20738577842712402, Final Batch Loss: 0.1287301778793335\n",
      "Epoch 700, Loss: 0.2728499621152878, Final Batch Loss: 0.12897075712680817\n",
      "Epoch 701, Loss: 0.29519638419151306, Final Batch Loss: 0.11740873754024506\n",
      "Epoch 702, Loss: 0.2118908017873764, Final Batch Loss: 0.11250036209821701\n",
      "Epoch 703, Loss: 0.2289707064628601, Final Batch Loss: 0.11490579694509506\n",
      "Epoch 704, Loss: 0.20915117114782333, Final Batch Loss: 0.1144198551774025\n",
      "Epoch 705, Loss: 0.20549088716506958, Final Batch Loss: 0.09790662676095963\n",
      "Epoch 706, Loss: 0.2532161697745323, Final Batch Loss: 0.15907303988933563\n",
      "Epoch 707, Loss: 0.2971946448087692, Final Batch Loss: 0.1838613748550415\n",
      "Epoch 708, Loss: 0.22141753882169724, Final Batch Loss: 0.1092306599020958\n",
      "Epoch 709, Loss: 0.2194831594824791, Final Batch Loss: 0.12790095806121826\n",
      "Epoch 710, Loss: 0.2504836171865463, Final Batch Loss: 0.16080082952976227\n",
      "Epoch 711, Loss: 0.23305755108594894, Final Batch Loss: 0.11198066920042038\n",
      "Epoch 712, Loss: 0.2106981724500656, Final Batch Loss: 0.10413677990436554\n",
      "Epoch 713, Loss: 0.1909114494919777, Final Batch Loss: 0.09711857885122299\n",
      "Epoch 714, Loss: 0.22238333523273468, Final Batch Loss: 0.08435903489589691\n",
      "Epoch 715, Loss: 0.2130502238869667, Final Batch Loss: 0.09372931718826294\n",
      "Epoch 716, Loss: 0.2738599479198456, Final Batch Loss: 0.11666828393936157\n",
      "Epoch 717, Loss: 0.25775931030511856, Final Batch Loss: 0.11924832314252853\n",
      "Epoch 718, Loss: 0.21953969448804855, Final Batch Loss: 0.09504328668117523\n",
      "Epoch 719, Loss: 0.2554984465241432, Final Batch Loss: 0.16443562507629395\n",
      "Epoch 720, Loss: 0.19546562433242798, Final Batch Loss: 0.0951462835073471\n",
      "Epoch 721, Loss: 0.20970618724822998, Final Batch Loss: 0.10149212926626205\n",
      "Epoch 722, Loss: 0.36404210329055786, Final Batch Loss: 0.17197099328041077\n",
      "Epoch 723, Loss: 0.21446499973535538, Final Batch Loss: 0.11868779361248016\n",
      "Epoch 724, Loss: 0.21367165446281433, Final Batch Loss: 0.1190393716096878\n",
      "Epoch 725, Loss: 0.27715858072042465, Final Batch Loss: 0.17981164157390594\n",
      "Epoch 726, Loss: 0.27143919467926025, Final Batch Loss: 0.15020540356636047\n",
      "Epoch 727, Loss: 0.1822938174009323, Final Batch Loss: 0.0726846233010292\n",
      "Epoch 728, Loss: 0.2512862980365753, Final Batch Loss: 0.12115707993507385\n",
      "Epoch 729, Loss: 0.23319710046052933, Final Batch Loss: 0.11432686448097229\n",
      "Epoch 730, Loss: 0.19592096656560898, Final Batch Loss: 0.08080465346574783\n",
      "Epoch 731, Loss: 0.19014080613851547, Final Batch Loss: 0.09337183088064194\n",
      "Epoch 732, Loss: 0.2485448345541954, Final Batch Loss: 0.13916371762752533\n",
      "Epoch 733, Loss: 0.23286554962396622, Final Batch Loss: 0.13201536238193512\n",
      "Epoch 734, Loss: 0.18145250529050827, Final Batch Loss: 0.09582781791687012\n",
      "Epoch 735, Loss: 0.25004467368125916, Final Batch Loss: 0.0941266417503357\n",
      "Epoch 736, Loss: 0.1981436386704445, Final Batch Loss: 0.0999203696846962\n",
      "Epoch 737, Loss: 0.22483737766742706, Final Batch Loss: 0.09071578085422516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 738, Loss: 0.23925987631082535, Final Batch Loss: 0.11860835552215576\n",
      "Epoch 739, Loss: 0.2577665224671364, Final Batch Loss: 0.13683728873729706\n",
      "Epoch 740, Loss: 0.22670496255159378, Final Batch Loss: 0.09594655781984329\n",
      "Epoch 741, Loss: 0.2105681076645851, Final Batch Loss: 0.09357330948114395\n",
      "Epoch 742, Loss: 0.1669798046350479, Final Batch Loss: 0.06479697674512863\n",
      "Epoch 743, Loss: 0.2105696126818657, Final Batch Loss: 0.06288846582174301\n",
      "Epoch 744, Loss: 0.2077384740114212, Final Batch Loss: 0.09495449811220169\n",
      "Epoch 745, Loss: 0.23950239270925522, Final Batch Loss: 0.10867028683423996\n",
      "Epoch 746, Loss: 0.26777488738298416, Final Batch Loss: 0.08607055991888046\n",
      "Epoch 747, Loss: 0.24017999321222305, Final Batch Loss: 0.11170274764299393\n",
      "Epoch 748, Loss: 0.22445563971996307, Final Batch Loss: 0.12185931205749512\n",
      "Epoch 749, Loss: 0.20232176035642624, Final Batch Loss: 0.10621204227209091\n",
      "Epoch 750, Loss: 0.21274445950984955, Final Batch Loss: 0.11021401733160019\n",
      "Epoch 751, Loss: 0.2652367725968361, Final Batch Loss: 0.15850014984607697\n",
      "Epoch 752, Loss: 0.2001992166042328, Final Batch Loss: 0.11992502957582474\n",
      "Epoch 753, Loss: 0.19766371697187424, Final Batch Loss: 0.07381673902273178\n",
      "Epoch 754, Loss: 0.18270068615674973, Final Batch Loss: 0.08722721040248871\n",
      "Epoch 755, Loss: 0.1953275501728058, Final Batch Loss: 0.10730664432048798\n",
      "Epoch 756, Loss: 0.27155572175979614, Final Batch Loss: 0.13830937445163727\n",
      "Epoch 757, Loss: 0.2410786896944046, Final Batch Loss: 0.1625232696533203\n",
      "Epoch 758, Loss: 0.2628294602036476, Final Batch Loss: 0.15001963078975677\n",
      "Epoch 759, Loss: 0.19142117351293564, Final Batch Loss: 0.08707156777381897\n",
      "Epoch 760, Loss: 0.18437719345092773, Final Batch Loss: 0.06788560003042221\n",
      "Epoch 761, Loss: 0.20032820105552673, Final Batch Loss: 0.09177177399396896\n",
      "Epoch 762, Loss: 0.20677358657121658, Final Batch Loss: 0.09648460149765015\n",
      "Epoch 763, Loss: 0.2072710394859314, Final Batch Loss: 0.08025659620761871\n",
      "Epoch 764, Loss: 0.17207422107458115, Final Batch Loss: 0.07211995869874954\n",
      "Epoch 765, Loss: 0.21102650463581085, Final Batch Loss: 0.09734707325696945\n",
      "Epoch 766, Loss: 0.2326982617378235, Final Batch Loss: 0.08407603204250336\n",
      "Epoch 767, Loss: 0.19831828027963638, Final Batch Loss: 0.08655967563390732\n",
      "Epoch 768, Loss: 0.1897822469472885, Final Batch Loss: 0.08068178594112396\n",
      "Epoch 769, Loss: 0.2193896621465683, Final Batch Loss: 0.09738317131996155\n",
      "Epoch 770, Loss: 0.16455954313278198, Final Batch Loss: 0.07883134484291077\n",
      "Epoch 771, Loss: 0.1692306399345398, Final Batch Loss: 0.06751665472984314\n",
      "Epoch 772, Loss: 0.19566237181425095, Final Batch Loss: 0.11040450632572174\n",
      "Epoch 773, Loss: 0.1981033757328987, Final Batch Loss: 0.11521289497613907\n",
      "Epoch 774, Loss: 0.20750264823436737, Final Batch Loss: 0.09949101507663727\n",
      "Epoch 775, Loss: 0.19563089311122894, Final Batch Loss: 0.08588289469480515\n",
      "Epoch 776, Loss: 0.19044506549835205, Final Batch Loss: 0.08471713960170746\n",
      "Epoch 777, Loss: 0.21424339711666107, Final Batch Loss: 0.09521707147359848\n",
      "Epoch 778, Loss: 0.18998819589614868, Final Batch Loss: 0.10053207725286484\n",
      "Epoch 779, Loss: 0.18019970506429672, Final Batch Loss: 0.06923765689134598\n",
      "Epoch 780, Loss: 0.23690928518772125, Final Batch Loss: 0.13750097155570984\n",
      "Epoch 781, Loss: 0.1869777962565422, Final Batch Loss: 0.08218677341938019\n",
      "Epoch 782, Loss: 0.1840110868215561, Final Batch Loss: 0.08825420588254929\n",
      "Epoch 783, Loss: 0.14602673053741455, Final Batch Loss: 0.05485379695892334\n",
      "Epoch 784, Loss: 0.16595517098903656, Final Batch Loss: 0.08855944871902466\n",
      "Epoch 785, Loss: 0.18671173602342606, Final Batch Loss: 0.06713591516017914\n",
      "Epoch 786, Loss: 0.1881990283727646, Final Batch Loss: 0.10606622695922852\n",
      "Epoch 787, Loss: 0.21337299048900604, Final Batch Loss: 0.11657275259494781\n",
      "Epoch 788, Loss: 0.1666831560432911, Final Batch Loss: 0.04823138192296028\n",
      "Epoch 789, Loss: 0.16280518472194672, Final Batch Loss: 0.07511599361896515\n",
      "Epoch 790, Loss: 0.1981455534696579, Final Batch Loss: 0.0935187041759491\n",
      "Epoch 791, Loss: 0.18330248445272446, Final Batch Loss: 0.08383757621049881\n",
      "Epoch 792, Loss: 0.18734043091535568, Final Batch Loss: 0.098722904920578\n",
      "Epoch 793, Loss: 0.1571841798722744, Final Batch Loss: 0.06160908564925194\n",
      "Epoch 794, Loss: 0.20763642340898514, Final Batch Loss: 0.11968731135129929\n",
      "Epoch 795, Loss: 0.1693512760102749, Final Batch Loss: 0.05002197250723839\n",
      "Epoch 796, Loss: 0.17175066098570824, Final Batch Loss: 0.06151224300265312\n",
      "Epoch 797, Loss: 0.1685185730457306, Final Batch Loss: 0.08521420508623123\n",
      "Epoch 798, Loss: 0.16734641790390015, Final Batch Loss: 0.09298144280910492\n",
      "Epoch 799, Loss: 0.15284467488527298, Final Batch Loss: 0.06749222427606583\n",
      "Epoch 800, Loss: 0.2057703137397766, Final Batch Loss: 0.11479474604129791\n",
      "Epoch 801, Loss: 0.18240905553102493, Final Batch Loss: 0.09516643732786179\n",
      "Epoch 802, Loss: 0.15590541809797287, Final Batch Loss: 0.07697581499814987\n",
      "Epoch 803, Loss: 0.22235623747110367, Final Batch Loss: 0.09882988035678864\n",
      "Epoch 804, Loss: 0.1622304990887642, Final Batch Loss: 0.07465487718582153\n",
      "Epoch 805, Loss: 0.20536769181489944, Final Batch Loss: 0.10774858295917511\n",
      "Epoch 806, Loss: 0.19710873812437057, Final Batch Loss: 0.13658808171749115\n",
      "Epoch 807, Loss: 0.17724477499723434, Final Batch Loss: 0.08747231960296631\n",
      "Epoch 808, Loss: 0.1665414497256279, Final Batch Loss: 0.06073427200317383\n",
      "Epoch 809, Loss: 0.2076265886425972, Final Batch Loss: 0.06712480634450912\n",
      "Epoch 810, Loss: 0.19605442136526108, Final Batch Loss: 0.12129494547843933\n",
      "Epoch 811, Loss: 0.22964028269052505, Final Batch Loss: 0.13447481393814087\n",
      "Epoch 812, Loss: 0.16963481903076172, Final Batch Loss: 0.08628524094820023\n",
      "Epoch 813, Loss: 0.1416228637099266, Final Batch Loss: 0.07159879058599472\n",
      "Epoch 814, Loss: 0.17507115751504898, Final Batch Loss: 0.09782275557518005\n",
      "Epoch 815, Loss: 0.2236410155892372, Final Batch Loss: 0.11537235975265503\n",
      "Epoch 816, Loss: 0.1686873733997345, Final Batch Loss: 0.08980151265859604\n",
      "Epoch 817, Loss: 0.13514494150877, Final Batch Loss: 0.0728968009352684\n",
      "Epoch 818, Loss: 0.21864400058984756, Final Batch Loss: 0.153025284409523\n",
      "Epoch 819, Loss: 0.27428585290908813, Final Batch Loss: 0.1485886126756668\n",
      "Epoch 820, Loss: 0.23603415489196777, Final Batch Loss: 0.14851920306682587\n",
      "Epoch 821, Loss: 0.15816610306501389, Final Batch Loss: 0.07574107497930527\n",
      "Epoch 822, Loss: 0.229507215321064, Final Batch Loss: 0.14365985989570618\n",
      "Epoch 823, Loss: 0.20793258398771286, Final Batch Loss: 0.10262124985456467\n",
      "Epoch 824, Loss: 0.16636594384908676, Final Batch Loss: 0.09438003599643707\n",
      "Epoch 825, Loss: 0.1747574582695961, Final Batch Loss: 0.06777873635292053\n",
      "Epoch 826, Loss: 0.1819860339164734, Final Batch Loss: 0.0842665284872055\n",
      "Epoch 827, Loss: 0.18856478482484818, Final Batch Loss: 0.08942621201276779\n",
      "Epoch 828, Loss: 0.1339319385588169, Final Batch Loss: 0.0393989272415638\n",
      "Epoch 829, Loss: 0.1264958381652832, Final Batch Loss: 0.06079661101102829\n",
      "Epoch 830, Loss: 0.18866106867790222, Final Batch Loss: 0.11229007691144943\n",
      "Epoch 831, Loss: 0.1674206554889679, Final Batch Loss: 0.08434564620256424\n",
      "Epoch 832, Loss: 0.19398066401481628, Final Batch Loss: 0.13092072308063507\n",
      "Epoch 833, Loss: 0.14118298888206482, Final Batch Loss: 0.06835587322711945\n",
      "Epoch 834, Loss: 0.1903463453054428, Final Batch Loss: 0.06998394429683685\n",
      "Epoch 835, Loss: 0.16321153193712234, Final Batch Loss: 0.08539280295372009\n",
      "Epoch 836, Loss: 0.12433161586523056, Final Batch Loss: 0.06759494543075562\n",
      "Epoch 837, Loss: 0.12697375938296318, Final Batch Loss: 0.06639128178358078\n",
      "Epoch 838, Loss: 0.14524096250534058, Final Batch Loss: 0.035797081887722015\n",
      "Epoch 839, Loss: 0.14750288426876068, Final Batch Loss: 0.08521287143230438\n",
      "Epoch 840, Loss: 0.26799238473176956, Final Batch Loss: 0.0882938876748085\n",
      "Epoch 841, Loss: 0.1459895223379135, Final Batch Loss: 0.07654531300067902\n",
      "Epoch 842, Loss: 0.13027379661798477, Final Batch Loss: 0.05627860128879547\n",
      "Epoch 843, Loss: 0.1288500465452671, Final Batch Loss: 0.06692560762166977\n",
      "Epoch 844, Loss: 0.18715400993824005, Final Batch Loss: 0.10903441160917282\n",
      "Epoch 845, Loss: 0.1885814517736435, Final Batch Loss: 0.09122933447360992\n",
      "Epoch 846, Loss: 0.15482547134160995, Final Batch Loss: 0.0732208713889122\n",
      "Epoch 847, Loss: 0.15536008030176163, Final Batch Loss: 0.09427329152822495\n",
      "Epoch 848, Loss: 0.20331424474716187, Final Batch Loss: 0.0791262611746788\n",
      "Epoch 849, Loss: 0.177930049598217, Final Batch Loss: 0.11243972927331924\n",
      "Epoch 850, Loss: 0.12869830429553986, Final Batch Loss: 0.07759550958871841\n",
      "Epoch 851, Loss: 0.13342861458659172, Final Batch Loss: 0.061501938849687576\n",
      "Epoch 852, Loss: 0.16006940975785255, Final Batch Loss: 0.053846877068281174\n",
      "Epoch 853, Loss: 0.15725154429674149, Final Batch Loss: 0.09253780543804169\n",
      "Epoch 854, Loss: 0.142516128718853, Final Batch Loss: 0.0664614588022232\n",
      "Epoch 855, Loss: 0.12040857598185539, Final Batch Loss: 0.049314361065626144\n",
      "Epoch 856, Loss: 0.20277557522058487, Final Batch Loss: 0.08500272780656815\n",
      "Epoch 857, Loss: 0.12629950046539307, Final Batch Loss: 0.05393451452255249\n",
      "Epoch 858, Loss: 0.1425042264163494, Final Batch Loss: 0.05750490352511406\n",
      "Epoch 859, Loss: 0.16591214388608932, Final Batch Loss: 0.06209734082221985\n",
      "Epoch 860, Loss: 0.16052614897489548, Final Batch Loss: 0.08619780838489532\n",
      "Epoch 861, Loss: 0.11554770544171333, Final Batch Loss: 0.047455307096242905\n",
      "Epoch 862, Loss: 0.1594773754477501, Final Batch Loss: 0.050899483263492584\n",
      "Epoch 863, Loss: 0.22984344512224197, Final Batch Loss: 0.16166356205940247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 864, Loss: 0.14076654240489006, Final Batch Loss: 0.07915734499692917\n",
      "Epoch 865, Loss: 0.12929491326212883, Final Batch Loss: 0.06807557493448257\n",
      "Epoch 866, Loss: 0.1466805748641491, Final Batch Loss: 0.09399097412824631\n",
      "Epoch 867, Loss: 0.11489102616906166, Final Batch Loss: 0.05541672557592392\n",
      "Epoch 868, Loss: 0.13900228217244148, Final Batch Loss: 0.07769671082496643\n",
      "Epoch 869, Loss: 0.3274536803364754, Final Batch Loss: 0.26891082525253296\n",
      "Epoch 870, Loss: 0.07060353271663189, Final Batch Loss: 0.017984537407755852\n",
      "Epoch 871, Loss: 0.17238808423280716, Final Batch Loss: 0.09989480674266815\n",
      "Epoch 872, Loss: 0.11555220186710358, Final Batch Loss: 0.05294075608253479\n",
      "Epoch 873, Loss: 0.14169831573963165, Final Batch Loss: 0.08732765913009644\n",
      "Epoch 874, Loss: 0.10417268425226212, Final Batch Loss: 0.05104338005185127\n",
      "Epoch 875, Loss: 0.12521230801939964, Final Batch Loss: 0.06361643970012665\n",
      "Epoch 876, Loss: 0.1438833251595497, Final Batch Loss: 0.07262085378170013\n",
      "Epoch 877, Loss: 0.15623727068305016, Final Batch Loss: 0.046258699148893356\n",
      "Epoch 878, Loss: 0.1441131755709648, Final Batch Loss: 0.05212954431772232\n",
      "Epoch 879, Loss: 0.18162016570568085, Final Batch Loss: 0.11270233243703842\n",
      "Epoch 880, Loss: 0.15869899094104767, Final Batch Loss: 0.07996666431427002\n",
      "Epoch 881, Loss: 0.17571351677179337, Final Batch Loss: 0.08181753754615784\n",
      "Epoch 882, Loss: 0.18656174093484879, Final Batch Loss: 0.07570024579763412\n",
      "Epoch 883, Loss: 0.11175291240215302, Final Batch Loss: 0.04878764599561691\n",
      "Epoch 884, Loss: 0.19760270416736603, Final Batch Loss: 0.1300515979528427\n",
      "Epoch 885, Loss: 0.14725640416145325, Final Batch Loss: 0.08833528310060501\n",
      "Epoch 886, Loss: 0.1398349516093731, Final Batch Loss: 0.08422141522169113\n",
      "Epoch 887, Loss: 0.15380311757326126, Final Batch Loss: 0.0717359185218811\n",
      "Epoch 888, Loss: 0.1572437286376953, Final Batch Loss: 0.08478529751300812\n",
      "Epoch 889, Loss: 0.10028156079351902, Final Batch Loss: 0.029963912442326546\n",
      "Epoch 890, Loss: 0.14208199083805084, Final Batch Loss: 0.0725986585021019\n",
      "Epoch 891, Loss: 0.12659191712737083, Final Batch Loss: 0.06084335222840309\n",
      "Epoch 892, Loss: 0.1815715804696083, Final Batch Loss: 0.06705541163682938\n",
      "Epoch 893, Loss: 0.11545313149690628, Final Batch Loss: 0.04488050192594528\n",
      "Epoch 894, Loss: 0.16449977457523346, Final Batch Loss: 0.05729469656944275\n",
      "Epoch 895, Loss: 0.15884268283843994, Final Batch Loss: 0.08845187723636627\n",
      "Epoch 896, Loss: 0.17044324427843094, Final Batch Loss: 0.08652208000421524\n",
      "Epoch 897, Loss: 0.12604548782110214, Final Batch Loss: 0.07873136550188065\n",
      "Epoch 898, Loss: 0.1390945240855217, Final Batch Loss: 0.07351027429103851\n",
      "Epoch 899, Loss: 0.13451890274882317, Final Batch Loss: 0.08401857316493988\n",
      "Epoch 900, Loss: 0.12615671008825302, Final Batch Loss: 0.07330963015556335\n",
      "Epoch 901, Loss: 0.11993659287691116, Final Batch Loss: 0.04850855469703674\n",
      "Epoch 902, Loss: 0.1880868747830391, Final Batch Loss: 0.13861781358718872\n",
      "Epoch 903, Loss: 0.12085208296775818, Final Batch Loss: 0.04120311141014099\n",
      "Epoch 904, Loss: 0.14916037023067474, Final Batch Loss: 0.05312260240316391\n",
      "Epoch 905, Loss: 0.10234906151890755, Final Batch Loss: 0.06397665292024612\n",
      "Epoch 906, Loss: 0.17410210520029068, Final Batch Loss: 0.10607289522886276\n",
      "Epoch 907, Loss: 0.12208472564816475, Final Batch Loss: 0.06397584825754166\n",
      "Epoch 908, Loss: 0.16284462064504623, Final Batch Loss: 0.08366101235151291\n",
      "Epoch 909, Loss: 0.11926821619272232, Final Batch Loss: 0.0792120173573494\n",
      "Epoch 910, Loss: 0.15108110010623932, Final Batch Loss: 0.08529866486787796\n",
      "Epoch 911, Loss: 0.13149799406528473, Final Batch Loss: 0.06228508800268173\n",
      "Epoch 912, Loss: 0.12823281809687614, Final Batch Loss: 0.044664207845926285\n",
      "Epoch 913, Loss: 0.13373610749840736, Final Batch Loss: 0.062116775661706924\n",
      "Epoch 914, Loss: 0.11197375506162643, Final Batch Loss: 0.07440890371799469\n",
      "Epoch 915, Loss: 0.14712709188461304, Final Batch Loss: 0.06568674743175507\n",
      "Epoch 916, Loss: 0.12110655382275581, Final Batch Loss: 0.07358355075120926\n",
      "Epoch 917, Loss: 0.16502808779478073, Final Batch Loss: 0.11396072059869766\n",
      "Epoch 918, Loss: 0.09842084720730782, Final Batch Loss: 0.03859228268265724\n",
      "Epoch 919, Loss: 0.12453754246234894, Final Batch Loss: 0.056488633155822754\n",
      "Epoch 920, Loss: 0.14372894167900085, Final Batch Loss: 0.09072631597518921\n",
      "Epoch 921, Loss: 0.1122182346880436, Final Batch Loss: 0.036310549825429916\n",
      "Epoch 922, Loss: 0.13823722675442696, Final Batch Loss: 0.08976701647043228\n",
      "Epoch 923, Loss: 0.10059269890189171, Final Batch Loss: 0.05313852056860924\n",
      "Epoch 924, Loss: 0.11957137659192085, Final Batch Loss: 0.037935394793748856\n",
      "Epoch 925, Loss: 0.12199066951870918, Final Batch Loss: 0.0444607250392437\n",
      "Epoch 926, Loss: 0.09571361541748047, Final Batch Loss: 0.04721006378531456\n",
      "Epoch 927, Loss: 0.1863054782152176, Final Batch Loss: 0.09804586321115494\n",
      "Epoch 928, Loss: 0.10701268166303635, Final Batch Loss: 0.04516535624861717\n",
      "Epoch 929, Loss: 0.16225023567676544, Final Batch Loss: 0.07649040967226028\n",
      "Epoch 930, Loss: 0.143680140376091, Final Batch Loss: 0.07278914004564285\n",
      "Epoch 931, Loss: 0.21202197670936584, Final Batch Loss: 0.09183873981237411\n",
      "Epoch 932, Loss: 0.13440120220184326, Final Batch Loss: 0.07179206609725952\n",
      "Epoch 933, Loss: 0.14675544202327728, Final Batch Loss: 0.09119848161935806\n",
      "Epoch 934, Loss: 0.15169372409582138, Final Batch Loss: 0.0657288208603859\n",
      "Epoch 935, Loss: 0.10034392029047012, Final Batch Loss: 0.06414645165205002\n",
      "Epoch 936, Loss: 0.11844278499484062, Final Batch Loss: 0.054043982177972794\n",
      "Epoch 937, Loss: 0.1696379855275154, Final Batch Loss: 0.10002706199884415\n",
      "Epoch 938, Loss: 0.11731909215450287, Final Batch Loss: 0.0628475695848465\n",
      "Epoch 939, Loss: 0.19836411625146866, Final Batch Loss: 0.08621075004339218\n",
      "Epoch 940, Loss: 0.1279069408774376, Final Batch Loss: 0.05919305235147476\n",
      "Epoch 941, Loss: 0.11358679831027985, Final Batch Loss: 0.05601280555129051\n",
      "Epoch 942, Loss: 0.11506025120615959, Final Batch Loss: 0.046472202986478806\n",
      "Epoch 943, Loss: 0.13950756192207336, Final Batch Loss: 0.07408110052347183\n",
      "Epoch 944, Loss: 0.11632034555077553, Final Batch Loss: 0.06480415165424347\n",
      "Epoch 945, Loss: 0.07774509489536285, Final Batch Loss: 0.026801660656929016\n",
      "Epoch 946, Loss: 0.12225989252328873, Final Batch Loss: 0.05111739784479141\n",
      "Epoch 947, Loss: 0.10818085074424744, Final Batch Loss: 0.044666096568107605\n",
      "Epoch 948, Loss: 0.1298447772860527, Final Batch Loss: 0.07429615408182144\n",
      "Epoch 949, Loss: 0.10663672164082527, Final Batch Loss: 0.0658925473690033\n",
      "Epoch 950, Loss: 0.10807591676712036, Final Batch Loss: 0.034530363976955414\n",
      "Epoch 951, Loss: 0.11359356343746185, Final Batch Loss: 0.06259426474571228\n",
      "Epoch 952, Loss: 0.08616399019956589, Final Batch Loss: 0.05466969311237335\n",
      "Epoch 953, Loss: 0.11883550137281418, Final Batch Loss: 0.038324207067489624\n",
      "Epoch 954, Loss: 0.09076050668954849, Final Batch Loss: 0.05638442933559418\n",
      "Epoch 955, Loss: 0.09274023398756981, Final Batch Loss: 0.0479658767580986\n",
      "Epoch 956, Loss: 0.10018961131572723, Final Batch Loss: 0.062209419906139374\n",
      "Epoch 957, Loss: 0.09101035073399544, Final Batch Loss: 0.02139938995242119\n",
      "Epoch 958, Loss: 0.12900907546281815, Final Batch Loss: 0.06828150898218155\n",
      "Epoch 959, Loss: 0.10076617449522018, Final Batch Loss: 0.05128924921154976\n",
      "Epoch 960, Loss: 0.13606898859143257, Final Batch Loss: 0.060462791472673416\n",
      "Epoch 961, Loss: 0.12759238854050636, Final Batch Loss: 0.07206112146377563\n",
      "Epoch 962, Loss: 0.13523438572883606, Final Batch Loss: 0.08819092810153961\n",
      "Epoch 963, Loss: 0.15230094641447067, Final Batch Loss: 0.08425098657608032\n",
      "Epoch 964, Loss: 0.1384854055941105, Final Batch Loss: 0.09015347808599472\n",
      "Epoch 965, Loss: 0.18160178139805794, Final Batch Loss: 0.12885412573814392\n",
      "Epoch 966, Loss: 0.10725235939025879, Final Batch Loss: 0.03857390582561493\n",
      "Epoch 967, Loss: 0.11651814356446266, Final Batch Loss: 0.05756666883826256\n",
      "Epoch 968, Loss: 0.12205589935183525, Final Batch Loss: 0.0919702872633934\n",
      "Epoch 969, Loss: 0.08646117523312569, Final Batch Loss: 0.04013469070196152\n",
      "Epoch 970, Loss: 0.11522103473544121, Final Batch Loss: 0.0383589081466198\n",
      "Epoch 971, Loss: 0.14582017436623573, Final Batch Loss: 0.09825383126735687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972, Loss: 0.08491279184818268, Final Batch Loss: 0.028708960860967636\n",
      "Epoch 973, Loss: 0.17600345984101295, Final Batch Loss: 0.129990816116333\n",
      "Epoch 974, Loss: 0.10825258865952492, Final Batch Loss: 0.05969226732850075\n",
      "Epoch 975, Loss: 0.19669291377067566, Final Batch Loss: 0.09199048578739166\n",
      "Epoch 976, Loss: 0.15662959218025208, Final Batch Loss: 0.07573728263378143\n",
      "Epoch 977, Loss: 0.16647538542747498, Final Batch Loss: 0.07294802367687225\n",
      "Epoch 978, Loss: 0.11411975882947445, Final Batch Loss: 0.026125101372599602\n",
      "Epoch 979, Loss: 0.09992799907922745, Final Batch Loss: 0.06239647418260574\n",
      "Epoch 980, Loss: 0.20345064252614975, Final Batch Loss: 0.1004481092095375\n",
      "Epoch 981, Loss: 0.08026513457298279, Final Batch Loss: 0.040417399257421494\n",
      "Epoch 982, Loss: 0.11963267996907234, Final Batch Loss: 0.04025602713227272\n",
      "Epoch 983, Loss: 0.14065337553620338, Final Batch Loss: 0.09604421257972717\n",
      "Epoch 984, Loss: 0.11773886159062386, Final Batch Loss: 0.026675578206777573\n",
      "Epoch 985, Loss: 0.17415767163038254, Final Batch Loss: 0.11197870224714279\n",
      "Epoch 986, Loss: 0.13321112096309662, Final Batch Loss: 0.041483134031295776\n",
      "Epoch 987, Loss: 0.137364000082016, Final Batch Loss: 0.0653475672006607\n",
      "Epoch 988, Loss: 0.16029267758131027, Final Batch Loss: 0.11387185752391815\n",
      "Epoch 989, Loss: 0.10761076211929321, Final Batch Loss: 0.026141226291656494\n",
      "Epoch 990, Loss: 0.0864969752728939, Final Batch Loss: 0.029199909418821335\n",
      "Epoch 991, Loss: 0.13789066299796104, Final Batch Loss: 0.06238292530179024\n",
      "Epoch 992, Loss: 0.16673048585653305, Final Batch Loss: 0.060813501477241516\n",
      "Epoch 993, Loss: 0.12454383820295334, Final Batch Loss: 0.0665116161108017\n",
      "Epoch 994, Loss: 0.10010755620896816, Final Batch Loss: 0.01711363159120083\n",
      "Epoch 995, Loss: 0.1962905079126358, Final Batch Loss: 0.09684530645608902\n",
      "Epoch 996, Loss: 0.10737162455916405, Final Batch Loss: 0.05160091444849968\n",
      "Epoch 997, Loss: 0.12655546516180038, Final Batch Loss: 0.07275678962469101\n",
      "Epoch 998, Loss: 0.11260179802775383, Final Batch Loss: 0.052340880036354065\n",
      "Epoch 999, Loss: 0.0813415851444006, Final Batch Loss: 0.02903314121067524\n",
      "Epoch 1000, Loss: 0.13355783373117447, Final Batch Loss: 0.05027899146080017\n",
      "Epoch 1001, Loss: 0.09944995120167732, Final Batch Loss: 0.05058542266488075\n",
      "Epoch 1002, Loss: 0.11966174468398094, Final Batch Loss: 0.06762853264808655\n",
      "Epoch 1003, Loss: 0.0937098991125822, Final Batch Loss: 0.02150384895503521\n",
      "Epoch 1004, Loss: 0.10430917888879776, Final Batch Loss: 0.05570808798074722\n",
      "Epoch 1005, Loss: 0.16885226964950562, Final Batch Loss: 0.0665917843580246\n",
      "Epoch 1006, Loss: 0.0855584517121315, Final Batch Loss: 0.023508571088314056\n",
      "Epoch 1007, Loss: 0.10800892114639282, Final Batch Loss: 0.07455135881900787\n",
      "Epoch 1008, Loss: 0.062429029494524, Final Batch Loss: 0.0309084914624691\n",
      "Epoch 1009, Loss: 0.08086424134671688, Final Batch Loss: 0.027337895706295967\n",
      "Epoch 1010, Loss: 0.08602569624781609, Final Batch Loss: 0.026413947343826294\n",
      "Epoch 1011, Loss: 0.09452774003148079, Final Batch Loss: 0.04399105906486511\n",
      "Epoch 1012, Loss: 0.1019560694694519, Final Batch Loss: 0.039894022047519684\n",
      "Epoch 1013, Loss: 0.11539457738399506, Final Batch Loss: 0.07109379768371582\n",
      "Epoch 1014, Loss: 0.0566047765314579, Final Batch Loss: 0.03410409018397331\n",
      "Epoch 1015, Loss: 0.10214840620756149, Final Batch Loss: 0.048090677708387375\n",
      "Epoch 1016, Loss: 0.09785584360361099, Final Batch Loss: 0.0646752119064331\n",
      "Epoch 1017, Loss: 0.18353306129574776, Final Batch Loss: 0.14438745379447937\n",
      "Epoch 1018, Loss: 0.12522361427545547, Final Batch Loss: 0.08120296895503998\n",
      "Epoch 1019, Loss: 0.06071615405380726, Final Batch Loss: 0.028132209554314613\n",
      "Epoch 1020, Loss: 0.08526943810284138, Final Batch Loss: 0.06139878183603287\n",
      "Epoch 1021, Loss: 0.12747999653220177, Final Batch Loss: 0.07779980450868607\n",
      "Epoch 1022, Loss: 0.09426021575927734, Final Batch Loss: 0.051051944494247437\n",
      "Epoch 1023, Loss: 0.10078887268900871, Final Batch Loss: 0.058846693485975266\n",
      "Epoch 1024, Loss: 0.09979420527815819, Final Batch Loss: 0.06119125708937645\n",
      "Epoch 1025, Loss: 0.0636719036847353, Final Batch Loss: 0.021441055461764336\n",
      "Epoch 1026, Loss: 0.07668295502662659, Final Batch Loss: 0.04089227691292763\n",
      "Epoch 1027, Loss: 0.10778219625353813, Final Batch Loss: 0.06525956839323044\n",
      "Epoch 1028, Loss: 0.05388936772942543, Final Batch Loss: 0.025001080706715584\n",
      "Epoch 1029, Loss: 0.1788778007030487, Final Batch Loss: 0.10535788536071777\n",
      "Epoch 1030, Loss: 0.07451651059091091, Final Batch Loss: 0.027384305372834206\n",
      "Epoch 1031, Loss: 0.08446159958839417, Final Batch Loss: 0.036971598863601685\n",
      "Epoch 1032, Loss: 0.16632605344057083, Final Batch Loss: 0.08260998129844666\n",
      "Epoch 1033, Loss: 0.092845369130373, Final Batch Loss: 0.05396128073334694\n",
      "Epoch 1034, Loss: 0.10040692985057831, Final Batch Loss: 0.06261500716209412\n",
      "Epoch 1035, Loss: 0.1063939668238163, Final Batch Loss: 0.03856354579329491\n",
      "Epoch 1036, Loss: 0.14141403511166573, Final Batch Loss: 0.09666439890861511\n",
      "Epoch 1037, Loss: 0.09983072429895401, Final Batch Loss: 0.045140624046325684\n",
      "Epoch 1038, Loss: 0.0643012560904026, Final Batch Loss: 0.03109961748123169\n",
      "Epoch 1039, Loss: 0.08536379225552082, Final Batch Loss: 0.031002944335341454\n",
      "Epoch 1040, Loss: 0.11862589418888092, Final Batch Loss: 0.03590870648622513\n",
      "Epoch 1041, Loss: 0.07477999478578568, Final Batch Loss: 0.03991531953215599\n",
      "Epoch 1042, Loss: 0.14938640594482422, Final Batch Loss: 0.07955261319875717\n",
      "Epoch 1043, Loss: 0.10319081135094166, Final Batch Loss: 0.018923500552773476\n",
      "Epoch 1044, Loss: 0.11870970577001572, Final Batch Loss: 0.06578384339809418\n",
      "Epoch 1045, Loss: 0.0788872092962265, Final Batch Loss: 0.03938068449497223\n",
      "Epoch 1046, Loss: 0.07925954461097717, Final Batch Loss: 0.035773150622844696\n",
      "Epoch 1047, Loss: 0.19428112357854843, Final Batch Loss: 0.10439260303974152\n",
      "Epoch 1048, Loss: 0.18205756694078445, Final Batch Loss: 0.0843987762928009\n",
      "Epoch 1049, Loss: 0.15026307851076126, Final Batch Loss: 0.0960761159658432\n",
      "Epoch 1050, Loss: 0.07833781838417053, Final Batch Loss: 0.039687786251306534\n",
      "Epoch 1051, Loss: 0.1228121966123581, Final Batch Loss: 0.08190778642892838\n",
      "Epoch 1052, Loss: 0.09384213760495186, Final Batch Loss: 0.036051541566848755\n",
      "Epoch 1053, Loss: 0.066683329641819, Final Batch Loss: 0.04038114473223686\n",
      "Epoch 1054, Loss: 0.06028822809457779, Final Batch Loss: 0.026218701153993607\n",
      "Epoch 1055, Loss: 0.09310660138726234, Final Batch Loss: 0.03686387091875076\n",
      "Epoch 1056, Loss: 0.0705632884055376, Final Batch Loss: 0.028130577877163887\n",
      "Epoch 1057, Loss: 0.052110455930233, Final Batch Loss: 0.02363879419863224\n",
      "Epoch 1058, Loss: 0.09429934248328209, Final Batch Loss: 0.04830199107527733\n",
      "Epoch 1059, Loss: 0.0957308653742075, Final Batch Loss: 0.06792517006397247\n",
      "Epoch 1060, Loss: 0.09208273328840733, Final Batch Loss: 0.02392963506281376\n",
      "Epoch 1061, Loss: 0.05811062268912792, Final Batch Loss: 0.023043351247906685\n",
      "Epoch 1062, Loss: 0.059929974377155304, Final Batch Loss: 0.021186448633670807\n",
      "Epoch 1063, Loss: 0.07222978956997395, Final Batch Loss: 0.04909911006689072\n",
      "Epoch 1064, Loss: 0.08854715153574944, Final Batch Loss: 0.043480224907398224\n",
      "Epoch 1065, Loss: 0.0748785026371479, Final Batch Loss: 0.036443669348955154\n",
      "Epoch 1066, Loss: 0.08153180405497551, Final Batch Loss: 0.04633441939949989\n",
      "Epoch 1067, Loss: 0.12637973949313164, Final Batch Loss: 0.09596424549818039\n",
      "Epoch 1068, Loss: 0.08815986290574074, Final Batch Loss: 0.06526827067136765\n",
      "Epoch 1069, Loss: 0.1060677319765091, Final Batch Loss: 0.06605631858110428\n",
      "Epoch 1070, Loss: 0.13467744924128056, Final Batch Loss: 0.10525861382484436\n",
      "Epoch 1071, Loss: 0.08055887930095196, Final Batch Loss: 0.02408951334655285\n",
      "Epoch 1072, Loss: 0.07892917655408382, Final Batch Loss: 0.016365250572562218\n",
      "Epoch 1073, Loss: 0.13828382641077042, Final Batch Loss: 0.09801460802555084\n",
      "Epoch 1074, Loss: 0.12021525204181671, Final Batch Loss: 0.03659992665052414\n",
      "Epoch 1075, Loss: 0.06611307337880135, Final Batch Loss: 0.017203055322170258\n",
      "Epoch 1076, Loss: 0.1047136876732111, Final Batch Loss: 0.07902588695287704\n",
      "Epoch 1077, Loss: 0.06250558234751225, Final Batch Loss: 0.040365781635046005\n",
      "Epoch 1078, Loss: 0.11002308502793312, Final Batch Loss: 0.06577962636947632\n",
      "Epoch 1079, Loss: 0.08618075400590897, Final Batch Loss: 0.04630443826317787\n",
      "Epoch 1080, Loss: 0.06530174985527992, Final Batch Loss: 0.04093317314982414\n",
      "Epoch 1081, Loss: 0.40001988783478737, Final Batch Loss: 0.37427154183387756\n",
      "Epoch 1082, Loss: 0.12000644207000732, Final Batch Loss: 0.07000382989645004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1083, Loss: 0.08581743575632572, Final Batch Loss: 0.05693233385682106\n",
      "Epoch 1084, Loss: 0.09884211048483849, Final Batch Loss: 0.04892871901392937\n",
      "Epoch 1085, Loss: 0.10205026715993881, Final Batch Loss: 0.035662807524204254\n",
      "Epoch 1086, Loss: 0.04012260399758816, Final Batch Loss: 0.018815191462635994\n",
      "Epoch 1087, Loss: 0.08516060933470726, Final Batch Loss: 0.0471925251185894\n",
      "Epoch 1088, Loss: 0.05438561551272869, Final Batch Loss: 0.0342392772436142\n",
      "Epoch 1089, Loss: 0.04347592778503895, Final Batch Loss: 0.0158913005143404\n",
      "Epoch 1090, Loss: 0.1450222060084343, Final Batch Loss: 0.12096806615591049\n",
      "Epoch 1091, Loss: 0.055520081892609596, Final Batch Loss: 0.028358731418848038\n",
      "Epoch 1092, Loss: 0.05385730229318142, Final Batch Loss: 0.027620431035757065\n",
      "Epoch 1093, Loss: 0.056181494146585464, Final Batch Loss: 0.03725714236497879\n",
      "Epoch 1094, Loss: 0.06285925768315792, Final Batch Loss: 0.04270503669977188\n",
      "Epoch 1095, Loss: 0.051387690007686615, Final Batch Loss: 0.027279989793896675\n",
      "Epoch 1096, Loss: 0.06251364387571812, Final Batch Loss: 0.03587990626692772\n",
      "Epoch 1097, Loss: 0.09940608963370323, Final Batch Loss: 0.030566077679395676\n",
      "Epoch 1098, Loss: 0.05012752488255501, Final Batch Loss: 0.028856690973043442\n",
      "Epoch 1099, Loss: 0.11785690858960152, Final Batch Loss: 0.056281447410583496\n",
      "Epoch 1100, Loss: 0.06456533819437027, Final Batch Loss: 0.01919863000512123\n",
      "Epoch 1101, Loss: 0.04667372815310955, Final Batch Loss: 0.0248301699757576\n",
      "Epoch 1102, Loss: 0.048506107181310654, Final Batch Loss: 0.018303969874978065\n",
      "Epoch 1103, Loss: 0.07845993712544441, Final Batch Loss: 0.043008413165807724\n",
      "Epoch 1104, Loss: 0.05846800468862057, Final Batch Loss: 0.0439586341381073\n",
      "Epoch 1105, Loss: 0.08215796202421188, Final Batch Loss: 0.043688077479600906\n",
      "Epoch 1106, Loss: 0.08968141116201878, Final Batch Loss: 0.05999667942523956\n",
      "Epoch 1107, Loss: 0.14092322811484337, Final Batch Loss: 0.1093466579914093\n",
      "Epoch 1108, Loss: 0.057786108925938606, Final Batch Loss: 0.03518831729888916\n",
      "Epoch 1109, Loss: 0.040143621154129505, Final Batch Loss: 0.013026312924921513\n",
      "Epoch 1110, Loss: 0.07913062535226345, Final Batch Loss: 0.010756922885775566\n",
      "Epoch 1111, Loss: 0.08945485949516296, Final Batch Loss: 0.04812083765864372\n",
      "Epoch 1112, Loss: 0.08705724589526653, Final Batch Loss: 0.06544286757707596\n",
      "Epoch 1113, Loss: 0.08534660935401917, Final Batch Loss: 0.041347093880176544\n",
      "Epoch 1114, Loss: 0.06600969657301903, Final Batch Loss: 0.03271199390292168\n",
      "Epoch 1115, Loss: 0.09447875618934631, Final Batch Loss: 0.036720018833875656\n",
      "Epoch 1116, Loss: 0.05681269429624081, Final Batch Loss: 0.018194766715168953\n",
      "Epoch 1117, Loss: 0.09442297741770744, Final Batch Loss: 0.05096186324954033\n",
      "Epoch 1118, Loss: 0.1633966788649559, Final Batch Loss: 0.05367458611726761\n",
      "Epoch 1119, Loss: 0.09576317295432091, Final Batch Loss: 0.06067709997296333\n",
      "Epoch 1120, Loss: 0.06891580671072006, Final Batch Loss: 0.032437484711408615\n",
      "Epoch 1121, Loss: 0.0830235630273819, Final Batch Loss: 0.04143821820616722\n",
      "Epoch 1122, Loss: 0.054193777963519096, Final Batch Loss: 0.01408284343779087\n",
      "Epoch 1123, Loss: 0.061872584745287895, Final Batch Loss: 0.040527526289224625\n",
      "Epoch 1124, Loss: 0.12993261590600014, Final Batch Loss: 0.05023642256855965\n",
      "Epoch 1125, Loss: 0.12848959863185883, Final Batch Loss: 0.048319220542907715\n",
      "Epoch 1126, Loss: 0.08398327231407166, Final Batch Loss: 0.042302899062633514\n",
      "Epoch 1127, Loss: 0.05860479548573494, Final Batch Loss: 0.010709688067436218\n",
      "Epoch 1128, Loss: 0.05179477296769619, Final Batch Loss: 0.019630374386906624\n",
      "Epoch 1129, Loss: 0.09668572805821896, Final Batch Loss: 0.02829967997968197\n",
      "Epoch 1130, Loss: 0.06057252362370491, Final Batch Loss: 0.03367337957024574\n",
      "Epoch 1131, Loss: 0.11041144654154778, Final Batch Loss: 0.07210810482501984\n",
      "Epoch 1132, Loss: 0.05337942764163017, Final Batch Loss: 0.026809344068169594\n",
      "Epoch 1133, Loss: 0.056024154648184776, Final Batch Loss: 0.03538336604833603\n",
      "Epoch 1134, Loss: 0.0699712298810482, Final Batch Loss: 0.037795331329107285\n",
      "Epoch 1135, Loss: 0.07736008986830711, Final Batch Loss: 0.030140630900859833\n",
      "Epoch 1136, Loss: 0.0795832946896553, Final Batch Loss: 0.029097624123096466\n",
      "Epoch 1137, Loss: 0.0674324743449688, Final Batch Loss: 0.03425733745098114\n",
      "Epoch 1138, Loss: 0.08120630122721195, Final Batch Loss: 0.057459507137537\n",
      "Epoch 1139, Loss: 0.0885750874876976, Final Batch Loss: 0.05186481773853302\n",
      "Epoch 1140, Loss: 0.10970129445195198, Final Batch Loss: 0.04494344815611839\n",
      "Epoch 1141, Loss: 0.11782591044902802, Final Batch Loss: 0.05905218422412872\n",
      "Epoch 1142, Loss: 0.0633356086909771, Final Batch Loss: 0.02562534436583519\n",
      "Epoch 1143, Loss: 0.06087173707783222, Final Batch Loss: 0.04038585349917412\n",
      "Epoch 1144, Loss: 0.06686697527766228, Final Batch Loss: 0.02233133092522621\n",
      "Epoch 1145, Loss: 0.08268764987587929, Final Batch Loss: 0.049473561346530914\n",
      "Epoch 1146, Loss: 0.057139188051223755, Final Batch Loss: 0.016222655773162842\n",
      "Epoch 1147, Loss: 0.06758535839617252, Final Batch Loss: 0.026006599888205528\n",
      "Epoch 1148, Loss: 0.052124571055173874, Final Batch Loss: 0.025048917159438133\n",
      "Epoch 1149, Loss: 0.045373640954494476, Final Batch Loss: 0.023815570399165154\n",
      "Epoch 1150, Loss: 0.09156912937760353, Final Batch Loss: 0.044465791434049606\n",
      "Epoch 1151, Loss: 0.04011245630681515, Final Batch Loss: 0.017327003180980682\n",
      "Epoch 1152, Loss: 0.1046220175921917, Final Batch Loss: 0.06372883915901184\n",
      "Epoch 1153, Loss: 0.09230608865618706, Final Batch Loss: 0.04736765846610069\n",
      "Epoch 1154, Loss: 0.10722062736749649, Final Batch Loss: 0.07135158777236938\n",
      "Epoch 1155, Loss: 0.09750550240278244, Final Batch Loss: 0.07812085747718811\n",
      "Epoch 1156, Loss: 0.061534399166703224, Final Batch Loss: 0.017230046913027763\n",
      "Epoch 1157, Loss: 0.09434382990002632, Final Batch Loss: 0.03322726488113403\n",
      "Epoch 1158, Loss: 0.09990603476762772, Final Batch Loss: 0.060965828597545624\n",
      "Epoch 1159, Loss: 0.12122764438390732, Final Batch Loss: 0.08891212940216064\n",
      "Epoch 1160, Loss: 0.05744679644703865, Final Batch Loss: 0.027635367587208748\n",
      "Epoch 1161, Loss: 0.1144295409321785, Final Batch Loss: 0.044721923768520355\n",
      "Epoch 1162, Loss: 0.07424298115074635, Final Batch Loss: 0.03056498058140278\n",
      "Epoch 1163, Loss: 0.08657369017601013, Final Batch Loss: 0.03321431204676628\n",
      "Epoch 1164, Loss: 0.039674634113907814, Final Batch Loss: 0.01034018024802208\n",
      "Epoch 1165, Loss: 0.0726934066042304, Final Batch Loss: 0.012276041321456432\n",
      "Epoch 1166, Loss: 0.08926765620708466, Final Batch Loss: 0.048603035509586334\n",
      "Epoch 1167, Loss: 0.07149947062134743, Final Batch Loss: 0.02779444307088852\n",
      "Epoch 1168, Loss: 0.044693129137158394, Final Batch Loss: 0.020913491025567055\n",
      "Epoch 1169, Loss: 0.07149399071931839, Final Batch Loss: 0.03060188516974449\n",
      "Epoch 1170, Loss: 0.07123405858874321, Final Batch Loss: 0.028846029192209244\n",
      "Epoch 1171, Loss: 0.1180083304643631, Final Batch Loss: 0.08277669548988342\n",
      "Epoch 1172, Loss: 0.07429237477481365, Final Batch Loss: 0.013313369825482368\n",
      "Epoch 1173, Loss: 0.17700383067131042, Final Batch Loss: 0.0974489077925682\n",
      "Epoch 1174, Loss: 0.04172654449939728, Final Batch Loss: 0.015247706323862076\n",
      "Epoch 1175, Loss: 0.07569554727524519, Final Batch Loss: 0.009467626921832561\n",
      "Epoch 1176, Loss: 0.12531578913331032, Final Batch Loss: 0.05867348983883858\n",
      "Epoch 1177, Loss: 0.07059339061379433, Final Batch Loss: 0.010739032179117203\n",
      "Epoch 1178, Loss: 0.07498525455594063, Final Batch Loss: 0.030436892062425613\n",
      "Epoch 1179, Loss: 0.06484823115170002, Final Batch Loss: 0.04685264080762863\n",
      "Epoch 1180, Loss: 0.05272892490029335, Final Batch Loss: 0.02101823315024376\n",
      "Epoch 1181, Loss: 0.162068210542202, Final Batch Loss: 0.12923210859298706\n",
      "Epoch 1182, Loss: 0.11066332086920738, Final Batch Loss: 0.06857705861330032\n",
      "Epoch 1183, Loss: 0.10955153405666351, Final Batch Loss: 0.0632106140255928\n",
      "Epoch 1184, Loss: 0.0633953595533967, Final Batch Loss: 0.010977503843605518\n",
      "Epoch 1185, Loss: 0.0444322032853961, Final Batch Loss: 0.01244258414953947\n",
      "Epoch 1186, Loss: 0.09249090030789375, Final Batch Loss: 0.02362717315554619\n",
      "Epoch 1187, Loss: 0.06521563977003098, Final Batch Loss: 0.0356077179312706\n",
      "Epoch 1188, Loss: 0.0912952646613121, Final Batch Loss: 0.05639421567320824\n",
      "Epoch 1189, Loss: 0.09296581521630287, Final Batch Loss: 0.03885359317064285\n",
      "Epoch 1190, Loss: 0.07713907770812511, Final Batch Loss: 0.058140914887189865\n",
      "Epoch 1191, Loss: 0.10759008675813675, Final Batch Loss: 0.07905193418264389\n",
      "Epoch 1192, Loss: 0.09276922792196274, Final Batch Loss: 0.05103470757603645\n",
      "Epoch 1193, Loss: 0.07066604308784008, Final Batch Loss: 0.02645082212984562\n",
      "Epoch 1194, Loss: 0.08931319881230593, Final Batch Loss: 0.0155193405225873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1195, Loss: 0.049745350144803524, Final Batch Loss: 0.014658051542937756\n",
      "Epoch 1196, Loss: 0.09773816168308258, Final Batch Loss: 0.05823346972465515\n",
      "Epoch 1197, Loss: 0.07347052730619907, Final Batch Loss: 0.047493595629930496\n",
      "Epoch 1198, Loss: 0.06256993301212788, Final Batch Loss: 0.02874644286930561\n",
      "Epoch 1199, Loss: 0.08965489082038403, Final Batch Loss: 0.030476482585072517\n",
      "Epoch 1200, Loss: 0.07847404852509499, Final Batch Loss: 0.04059745743870735\n",
      "Epoch 1201, Loss: 0.041107138618826866, Final Batch Loss: 0.02476360835134983\n",
      "Epoch 1202, Loss: 0.05510452389717102, Final Batch Loss: 0.037082962691783905\n",
      "Epoch 1203, Loss: 0.0549502968788147, Final Batch Loss: 0.02503930777311325\n",
      "Epoch 1204, Loss: 0.06362238712608814, Final Batch Loss: 0.037598975002765656\n",
      "Epoch 1205, Loss: 0.06605160050094128, Final Batch Loss: 0.048491593450307846\n",
      "Epoch 1206, Loss: 0.03482345212250948, Final Batch Loss: 0.02063167281448841\n",
      "Epoch 1207, Loss: 0.10545630566775799, Final Batch Loss: 0.080466628074646\n",
      "Epoch 1208, Loss: 0.05024102330207825, Final Batch Loss: 0.025060730054974556\n",
      "Epoch 1209, Loss: 0.0756828784942627, Final Batch Loss: 0.03717877343297005\n",
      "Epoch 1210, Loss: 0.07871637120842934, Final Batch Loss: 0.050964709371328354\n",
      "Epoch 1211, Loss: 0.05113024450838566, Final Batch Loss: 0.032447874546051025\n",
      "Epoch 1212, Loss: 0.06246369518339634, Final Batch Loss: 0.012566497549414635\n",
      "Epoch 1213, Loss: 0.06306946463882923, Final Batch Loss: 0.030880091711878777\n",
      "Epoch 1214, Loss: 0.05025072582066059, Final Batch Loss: 0.025929616764187813\n",
      "Epoch 1215, Loss: 0.060162896290421486, Final Batch Loss: 0.031027622520923615\n",
      "Epoch 1216, Loss: 0.03681509010493755, Final Batch Loss: 0.012407565489411354\n",
      "Epoch 1217, Loss: 0.06179593689739704, Final Batch Loss: 0.04335483908653259\n",
      "Epoch 1218, Loss: 0.09115897864103317, Final Batch Loss: 0.060536231845617294\n",
      "Epoch 1219, Loss: 0.050049079582095146, Final Batch Loss: 0.02863834984600544\n",
      "Epoch 1220, Loss: 0.13490769267082214, Final Batch Loss: 0.07364228367805481\n",
      "Epoch 1221, Loss: 0.040550483390688896, Final Batch Loss: 0.016964245587587357\n",
      "Epoch 1222, Loss: 0.04525798559188843, Final Batch Loss: 0.014054737985134125\n",
      "Epoch 1223, Loss: 0.13665711134672165, Final Batch Loss: 0.11503399908542633\n",
      "Epoch 1224, Loss: 0.11038047075271606, Final Batch Loss: 0.048715148121118546\n",
      "Epoch 1225, Loss: 0.06545630842447281, Final Batch Loss: 0.04388740286231041\n",
      "Epoch 1226, Loss: 0.061833590269088745, Final Batch Loss: 0.02412547543644905\n",
      "Epoch 1227, Loss: 0.06822173483669758, Final Batch Loss: 0.020408237352967262\n",
      "Epoch 1228, Loss: 0.06818049401044846, Final Batch Loss: 0.03430124372243881\n",
      "Epoch 1229, Loss: 0.053189126774668694, Final Batch Loss: 0.02174130268394947\n",
      "Epoch 1230, Loss: 0.10313199833035469, Final Batch Loss: 0.0828620120882988\n",
      "Epoch 1231, Loss: 0.07324200123548508, Final Batch Loss: 0.04205022752285004\n",
      "Epoch 1232, Loss: 0.07781236246228218, Final Batch Loss: 0.03767315670847893\n",
      "Epoch 1233, Loss: 0.0512659028172493, Final Batch Loss: 0.01578541472554207\n",
      "Epoch 1234, Loss: 0.1149443443864584, Final Batch Loss: 0.08973056077957153\n",
      "Epoch 1235, Loss: 0.09915584698319435, Final Batch Loss: 0.06031326577067375\n",
      "Epoch 1236, Loss: 0.06876800209283829, Final Batch Loss: 0.031323328614234924\n",
      "Epoch 1237, Loss: 0.07806449756026268, Final Batch Loss: 0.013238716870546341\n",
      "Epoch 1238, Loss: 0.054208675399422646, Final Batch Loss: 0.031129151582717896\n",
      "Epoch 1239, Loss: 0.057557662948966026, Final Batch Loss: 0.020266590639948845\n",
      "Epoch 1240, Loss: 0.04855239950120449, Final Batch Loss: 0.0342571884393692\n",
      "Epoch 1241, Loss: 0.08729343116283417, Final Batch Loss: 0.05913068726658821\n",
      "Epoch 1242, Loss: 0.05931486748158932, Final Batch Loss: 0.04523612931370735\n",
      "Epoch 1243, Loss: 0.06682181358337402, Final Batch Loss: 0.029066260904073715\n",
      "Epoch 1244, Loss: 0.09173225611448288, Final Batch Loss: 0.03305375576019287\n",
      "Epoch 1245, Loss: 0.058683594688773155, Final Batch Loss: 0.033530883491039276\n",
      "Epoch 1246, Loss: 0.028618973679840565, Final Batch Loss: 0.020945435389876366\n",
      "Epoch 1247, Loss: 0.06550285033881664, Final Batch Loss: 0.019520321860909462\n",
      "Epoch 1248, Loss: 0.05277344584465027, Final Batch Loss: 0.01903519406914711\n",
      "Epoch 1249, Loss: 0.0627073384821415, Final Batch Loss: 0.024951975792646408\n",
      "Epoch 1250, Loss: 0.049709077924489975, Final Batch Loss: 0.015787966549396515\n",
      "Epoch 1251, Loss: 0.05173436179757118, Final Batch Loss: 0.013770248740911484\n",
      "Epoch 1252, Loss: 0.048382218927145004, Final Batch Loss: 0.025881757959723473\n",
      "Epoch 1253, Loss: 0.06798865646123886, Final Batch Loss: 0.03442338854074478\n",
      "Epoch 1254, Loss: 0.08633969724178314, Final Batch Loss: 0.05357340723276138\n",
      "Epoch 1255, Loss: 0.09430855512619019, Final Batch Loss: 0.05827895551919937\n",
      "Epoch 1256, Loss: 0.06959251128137112, Final Batch Loss: 0.048031363636255264\n",
      "Epoch 1257, Loss: 0.10647263377904892, Final Batch Loss: 0.038602642714977264\n",
      "Epoch 1258, Loss: 0.05017080903053284, Final Batch Loss: 0.027168668806552887\n",
      "Epoch 1259, Loss: 0.069980937987566, Final Batch Loss: 0.04228238761425018\n",
      "Epoch 1260, Loss: 0.06443381868302822, Final Batch Loss: 0.024540653452277184\n",
      "Epoch 1261, Loss: 0.09904641658067703, Final Batch Loss: 0.05928916484117508\n",
      "Epoch 1262, Loss: 0.052201710641384125, Final Batch Loss: 0.019090812653303146\n",
      "Epoch 1263, Loss: 0.16795969754457474, Final Batch Loss: 0.12991982698440552\n",
      "Epoch 1264, Loss: 0.05534423980861902, Final Batch Loss: 0.012270216830074787\n",
      "Epoch 1265, Loss: 0.03929859399795532, Final Batch Loss: 0.02212401293218136\n",
      "Epoch 1266, Loss: 0.08152295835316181, Final Batch Loss: 0.05695028603076935\n",
      "Epoch 1267, Loss: 0.054473232477903366, Final Batch Loss: 0.02502981387078762\n",
      "Epoch 1268, Loss: 0.03995653986930847, Final Batch Loss: 0.0173506997525692\n",
      "Epoch 1269, Loss: 0.08989227190613747, Final Batch Loss: 0.051070552319288254\n",
      "Epoch 1270, Loss: 0.0706993043422699, Final Batch Loss: 0.025147750973701477\n",
      "Epoch 1271, Loss: 0.040461271069943905, Final Batch Loss: 0.013141981326043606\n",
      "Epoch 1272, Loss: 0.049377087503671646, Final Batch Loss: 0.0328311026096344\n",
      "Epoch 1273, Loss: 0.09140997938811779, Final Batch Loss: 0.07356595993041992\n",
      "Epoch 1274, Loss: 0.05150666646659374, Final Batch Loss: 0.023201577365398407\n",
      "Epoch 1275, Loss: 0.1486882735043764, Final Batch Loss: 0.025140533223748207\n",
      "Epoch 1276, Loss: 0.10421653091907501, Final Batch Loss: 0.06454403698444366\n",
      "Epoch 1277, Loss: 0.049923576414585114, Final Batch Loss: 0.02320137992501259\n",
      "Epoch 1278, Loss: 0.054085610434412956, Final Batch Loss: 0.010558461770415306\n",
      "Epoch 1279, Loss: 0.06549282744526863, Final Batch Loss: 0.049570001661777496\n",
      "Epoch 1280, Loss: 0.058654673397541046, Final Batch Loss: 0.026195064187049866\n",
      "Epoch 1281, Loss: 0.02840949036180973, Final Batch Loss: 0.0189814530313015\n",
      "Epoch 1282, Loss: 0.04732697922736406, Final Batch Loss: 0.01245968509465456\n",
      "Epoch 1283, Loss: 0.06949803791940212, Final Batch Loss: 0.05197369307279587\n",
      "Epoch 1284, Loss: 0.0990774817764759, Final Batch Loss: 0.060868069529533386\n",
      "Epoch 1285, Loss: 0.06056215614080429, Final Batch Loss: 0.018607497215270996\n",
      "Epoch 1286, Loss: 0.04981072433292866, Final Batch Loss: 0.019079433754086494\n",
      "Epoch 1287, Loss: 0.02100671548396349, Final Batch Loss: 0.00951180700212717\n",
      "Epoch 1288, Loss: 0.044285387732088566, Final Batch Loss: 0.013582908548414707\n",
      "Epoch 1289, Loss: 0.09031658247113228, Final Batch Loss: 0.05889526382088661\n",
      "Epoch 1290, Loss: 0.044359996914863586, Final Batch Loss: 0.02829986810684204\n",
      "Epoch 1291, Loss: 0.027249599806964397, Final Batch Loss: 0.014585275202989578\n",
      "Epoch 1292, Loss: 0.07109688967466354, Final Batch Loss: 0.03713395074009895\n",
      "Epoch 1293, Loss: 0.08225096762180328, Final Batch Loss: 0.042019329965114594\n",
      "Epoch 1294, Loss: 0.03276786021888256, Final Batch Loss: 0.013017525896430016\n",
      "Epoch 1295, Loss: 0.07811529189348221, Final Batch Loss: 0.03601066395640373\n",
      "Epoch 1296, Loss: 0.06601856555789709, Final Batch Loss: 0.011090564541518688\n",
      "Epoch 1297, Loss: 0.028095969930291176, Final Batch Loss: 0.012093685567378998\n",
      "Epoch 1298, Loss: 0.048727985471487045, Final Batch Loss: 0.03043687902390957\n",
      "Epoch 1299, Loss: 0.08965037763118744, Final Batch Loss: 0.04825950786471367\n",
      "Epoch 1300, Loss: 0.05449089966714382, Final Batch Loss: 0.021958479657769203\n",
      "Epoch 1301, Loss: 0.05546529404819012, Final Batch Loss: 0.020980307832360268\n",
      "Epoch 1302, Loss: 0.04133987799286842, Final Batch Loss: 0.009576957672834396\n",
      "Epoch 1303, Loss: 0.038844574242830276, Final Batch Loss: 0.02247512899339199\n",
      "Epoch 1304, Loss: 0.04347139410674572, Final Batch Loss: 0.018746841698884964\n",
      "Epoch 1305, Loss: 0.058612996246665716, Final Batch Loss: 0.050840824842453\n",
      "Epoch 1306, Loss: 0.09535909071564674, Final Batch Loss: 0.07165201008319855\n",
      "Epoch 1307, Loss: 0.0346907889470458, Final Batch Loss: 0.013439211063086987\n",
      "Epoch 1308, Loss: 0.07657677680253983, Final Batch Loss: 0.02212999016046524\n",
      "Epoch 1309, Loss: 0.062439773231744766, Final Batch Loss: 0.025612734258174896\n",
      "Epoch 1310, Loss: 0.0773718380369246, Final Batch Loss: 0.06956077367067337\n",
      "Epoch 1311, Loss: 0.055295078083872795, Final Batch Loss: 0.019641442224383354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1312, Loss: 0.047015607357025146, Final Batch Loss: 0.022122902795672417\n",
      "Epoch 1313, Loss: 0.0434185154736042, Final Batch Loss: 0.018139217048883438\n",
      "Epoch 1314, Loss: 0.06516388058662415, Final Batch Loss: 0.04686231166124344\n",
      "Epoch 1315, Loss: 0.022121482994407415, Final Batch Loss: 0.0067260307259857655\n",
      "Epoch 1316, Loss: 0.039993308018893, Final Batch Loss: 0.006489865016192198\n",
      "Epoch 1317, Loss: 0.1130291516892612, Final Batch Loss: 0.1058117002248764\n",
      "Epoch 1318, Loss: 0.04030311852693558, Final Batch Loss: 0.014349900186061859\n",
      "Epoch 1319, Loss: 0.03048677183687687, Final Batch Loss: 0.007930630818009377\n",
      "Epoch 1320, Loss: 0.06104289926588535, Final Batch Loss: 0.04166710376739502\n",
      "Epoch 1321, Loss: 0.04228639043867588, Final Batch Loss: 0.014262961223721504\n",
      "Epoch 1322, Loss: 0.06552561186254025, Final Batch Loss: 0.034801583737134933\n",
      "Epoch 1323, Loss: 0.045399196445941925, Final Batch Loss: 0.0224783793091774\n",
      "Epoch 1324, Loss: 0.04807361774146557, Final Batch Loss: 0.01737167313694954\n",
      "Epoch 1325, Loss: 0.12612787261605263, Final Batch Loss: 0.08820421993732452\n",
      "Epoch 1326, Loss: 0.12148347869515419, Final Batch Loss: 0.08963729441165924\n",
      "Epoch 1327, Loss: 0.022243262268602848, Final Batch Loss: 0.005871905945241451\n",
      "Epoch 1328, Loss: 0.07450933381915092, Final Batch Loss: 0.04797619953751564\n",
      "Epoch 1329, Loss: 0.07252212800085545, Final Batch Loss: 0.022634970024228096\n",
      "Epoch 1330, Loss: 0.03726073168218136, Final Batch Loss: 0.010631591081619263\n",
      "Epoch 1331, Loss: 0.04737376607954502, Final Batch Loss: 0.028888439759612083\n",
      "Epoch 1332, Loss: 0.07524122297763824, Final Batch Loss: 0.03343259543180466\n",
      "Epoch 1333, Loss: 0.06726246699690819, Final Batch Loss: 0.0395234040915966\n",
      "Epoch 1334, Loss: 0.03625371307134628, Final Batch Loss: 0.017277367413043976\n",
      "Epoch 1335, Loss: 0.06352351233363152, Final Batch Loss: 0.03068770095705986\n",
      "Epoch 1336, Loss: 0.061115507036447525, Final Batch Loss: 0.028705250471830368\n",
      "Epoch 1337, Loss: 0.0794463474303484, Final Batch Loss: 0.05579926446080208\n",
      "Epoch 1338, Loss: 0.07216081768274307, Final Batch Loss: 0.03781462833285332\n",
      "Epoch 1339, Loss: 0.037111908197402954, Final Batch Loss: 0.018396781757473946\n",
      "Epoch 1340, Loss: 0.059420984238386154, Final Batch Loss: 0.026506390422582626\n",
      "Epoch 1341, Loss: 0.05295184440910816, Final Batch Loss: 0.035279277712106705\n",
      "Epoch 1342, Loss: 0.13243931904435158, Final Batch Loss: 0.09753904491662979\n",
      "Epoch 1343, Loss: 0.062183963134884834, Final Batch Loss: 0.029100267216563225\n",
      "Epoch 1344, Loss: 0.055033416487276554, Final Batch Loss: 0.015352108515799046\n",
      "Epoch 1345, Loss: 0.06372186914086342, Final Batch Loss: 0.0327620729804039\n",
      "Epoch 1346, Loss: 0.05453832261264324, Final Batch Loss: 0.01525125838816166\n",
      "Epoch 1347, Loss: 0.1416676752269268, Final Batch Loss: 0.047293294221162796\n",
      "Epoch 1348, Loss: 0.03464661445468664, Final Batch Loss: 0.024348735809326172\n",
      "Epoch 1349, Loss: 0.07612685859203339, Final Batch Loss: 0.025520220398902893\n",
      "Epoch 1350, Loss: 0.04020207189023495, Final Batch Loss: 0.020298203453421593\n",
      "Epoch 1351, Loss: 0.04714675061404705, Final Batch Loss: 0.011802254244685173\n",
      "Epoch 1352, Loss: 0.05489576980471611, Final Batch Loss: 0.030344799160957336\n",
      "Epoch 1353, Loss: 0.09307639673352242, Final Batch Loss: 0.05087536200881004\n",
      "Epoch 1354, Loss: 0.061288473196327686, Final Batch Loss: 0.01349892932921648\n",
      "Epoch 1355, Loss: 0.07591986563056707, Final Batch Loss: 0.015375993214547634\n",
      "Epoch 1356, Loss: 0.04108923673629761, Final Batch Loss: 0.019559340551495552\n",
      "Epoch 1357, Loss: 0.026580355130136013, Final Batch Loss: 0.011168299242854118\n",
      "Epoch 1358, Loss: 0.10120711848139763, Final Batch Loss: 0.05975963547825813\n",
      "Epoch 1359, Loss: 0.032648803666234016, Final Batch Loss: 0.017930686473846436\n",
      "Epoch 1360, Loss: 0.037737175822257996, Final Batch Loss: 0.010699763894081116\n",
      "Epoch 1361, Loss: 0.07662960886955261, Final Batch Loss: 0.022363875061273575\n",
      "Epoch 1362, Loss: 0.059989859350025654, Final Batch Loss: 0.01285566482692957\n",
      "Epoch 1363, Loss: 0.075094323605299, Final Batch Loss: 0.033456169068813324\n",
      "Epoch 1364, Loss: 0.06703872606158257, Final Batch Loss: 0.0315265879034996\n",
      "Epoch 1365, Loss: 0.03814841993153095, Final Batch Loss: 0.020605197176337242\n",
      "Epoch 1366, Loss: 0.0504447054117918, Final Batch Loss: 0.018867431208491325\n",
      "Epoch 1367, Loss: 0.02866778802126646, Final Batch Loss: 0.01911454275250435\n",
      "Epoch 1368, Loss: 0.04257568344473839, Final Batch Loss: 0.02603212743997574\n",
      "Epoch 1369, Loss: 0.060660095885396004, Final Batch Loss: 0.018417825922369957\n",
      "Epoch 1370, Loss: 0.04053475894033909, Final Batch Loss: 0.008535435423254967\n",
      "Epoch 1371, Loss: 0.030427999794483185, Final Batch Loss: 0.016701512038707733\n",
      "Epoch 1372, Loss: 0.02167270751670003, Final Batch Loss: 0.004456151742488146\n",
      "Epoch 1373, Loss: 0.04136575944721699, Final Batch Loss: 0.029255041852593422\n",
      "Epoch 1374, Loss: 0.026226916816085577, Final Batch Loss: 0.003407649230211973\n",
      "Epoch 1375, Loss: 0.03358984086662531, Final Batch Loss: 0.011346575804054737\n",
      "Epoch 1376, Loss: 0.03124959021806717, Final Batch Loss: 0.01524997130036354\n",
      "Epoch 1377, Loss: 0.030370798893272877, Final Batch Loss: 0.01715017855167389\n",
      "Epoch 1378, Loss: 0.09328744374215603, Final Batch Loss: 0.012577814981341362\n",
      "Epoch 1379, Loss: 0.062059708405286074, Final Batch Loss: 0.005262304563075304\n",
      "Epoch 1380, Loss: 0.046911949291825294, Final Batch Loss: 0.03169795125722885\n",
      "Epoch 1381, Loss: 0.0602850541472435, Final Batch Loss: 0.034873116761446\n",
      "Epoch 1382, Loss: 0.08420722559094429, Final Batch Loss: 0.03692052885890007\n",
      "Epoch 1383, Loss: 0.03348256181925535, Final Batch Loss: 0.014753573574125767\n",
      "Epoch 1384, Loss: 0.0522717647254467, Final Batch Loss: 0.03791584447026253\n",
      "Epoch 1385, Loss: 0.0287575526162982, Final Batch Loss: 0.014081090688705444\n",
      "Epoch 1386, Loss: 0.04215991869568825, Final Batch Loss: 0.01904899626970291\n",
      "Epoch 1387, Loss: 0.03195934556424618, Final Batch Loss: 0.01360144279897213\n",
      "Epoch 1388, Loss: 0.024742395617067814, Final Batch Loss: 0.016366418451070786\n",
      "Epoch 1389, Loss: 0.0442676842212677, Final Batch Loss: 0.023881983011960983\n",
      "Epoch 1390, Loss: 0.1117235142737627, Final Batch Loss: 0.09495177865028381\n",
      "Epoch 1391, Loss: 0.0411448460072279, Final Batch Loss: 0.012522412464022636\n",
      "Epoch 1392, Loss: 0.09135115146636963, Final Batch Loss: 0.07487892359495163\n",
      "Epoch 1393, Loss: 0.0424291230738163, Final Batch Loss: 0.020273970440030098\n",
      "Epoch 1394, Loss: 0.03155519533902407, Final Batch Loss: 0.016001898795366287\n",
      "Epoch 1395, Loss: 0.08055511489510536, Final Batch Loss: 0.037048280239105225\n",
      "Epoch 1396, Loss: 0.029876746702939272, Final Batch Loss: 0.006309416610747576\n",
      "Epoch 1397, Loss: 0.0710152629762888, Final Batch Loss: 0.05370159074664116\n",
      "Epoch 1398, Loss: 0.07550732977688313, Final Batch Loss: 0.046398915350437164\n",
      "Epoch 1399, Loss: 0.04265453480184078, Final Batch Loss: 0.030264176428318024\n",
      "Epoch 1400, Loss: 0.04143261816352606, Final Batch Loss: 0.011836244724690914\n",
      "Epoch 1401, Loss: 0.02647505607455969, Final Batch Loss: 0.009789320640265942\n",
      "Epoch 1402, Loss: 0.035427914932370186, Final Batch Loss: 0.019003968685865402\n",
      "Epoch 1403, Loss: 0.029875006526708603, Final Batch Loss: 0.016921391710639\n",
      "Epoch 1404, Loss: 0.05612807348370552, Final Batch Loss: 0.011129260063171387\n",
      "Epoch 1405, Loss: 0.039999520406126976, Final Batch Loss: 0.027144985273480415\n",
      "Epoch 1406, Loss: 0.039736172184348106, Final Batch Loss: 0.019098008051514626\n",
      "Epoch 1407, Loss: 0.05298953130841255, Final Batch Loss: 0.02478213422000408\n",
      "Epoch 1408, Loss: 0.06648283079266548, Final Batch Loss: 0.02261997014284134\n",
      "Epoch 1409, Loss: 0.042994916439056396, Final Batch Loss: 0.025926237925887108\n",
      "Epoch 1410, Loss: 0.044836584478616714, Final Batch Loss: 0.02027694135904312\n",
      "Epoch 1411, Loss: 0.07941699400544167, Final Batch Loss: 0.0619000568985939\n",
      "Epoch 1412, Loss: 0.08272046223282814, Final Batch Loss: 0.017666596919298172\n",
      "Epoch 1413, Loss: 0.09360500611364841, Final Batch Loss: 0.06253036111593246\n",
      "Epoch 1414, Loss: 0.03931328095495701, Final Batch Loss: 0.022605029866099358\n",
      "Epoch 1415, Loss: 0.06352319940924644, Final Batch Loss: 0.013697255402803421\n",
      "Epoch 1416, Loss: 0.03723926329985261, Final Batch Loss: 0.00708360830321908\n",
      "Epoch 1417, Loss: 0.03685576654970646, Final Batch Loss: 0.017090272158384323\n",
      "Epoch 1418, Loss: 0.049754463136196136, Final Batch Loss: 0.01598655804991722\n",
      "Epoch 1419, Loss: 0.04534461721777916, Final Batch Loss: 0.02284233085811138\n",
      "Epoch 1420, Loss: 0.028403427451848984, Final Batch Loss: 0.011609643697738647\n",
      "Epoch 1421, Loss: 0.03085778560489416, Final Batch Loss: 0.013838508166372776\n",
      "Epoch 1422, Loss: 0.03683703765273094, Final Batch Loss: 0.02071860060095787\n",
      "Epoch 1423, Loss: 0.06732266768813133, Final Batch Loss: 0.04694082960486412\n",
      "Epoch 1424, Loss: 0.035672263242304325, Final Batch Loss: 0.010617061518132687\n",
      "Epoch 1425, Loss: 0.0546959089115262, Final Batch Loss: 0.04246494546532631\n",
      "Epoch 1426, Loss: 0.11288399808108807, Final Batch Loss: 0.08378876745700836\n",
      "Epoch 1427, Loss: 0.06472090631723404, Final Batch Loss: 0.0170283280313015\n",
      "Epoch 1428, Loss: 0.07679959200322628, Final Batch Loss: 0.05614132434129715\n",
      "Epoch 1429, Loss: 0.10033384710550308, Final Batch Loss: 0.02320065349340439\n",
      "Epoch 1430, Loss: 0.0659265574067831, Final Batch Loss: 0.02679862640798092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1431, Loss: 0.058162789791822433, Final Batch Loss: 0.019918065518140793\n",
      "Epoch 1432, Loss: 0.06458194367587566, Final Batch Loss: 0.01767946220934391\n",
      "Epoch 1433, Loss: 0.05433295667171478, Final Batch Loss: 0.03622042387723923\n",
      "Epoch 1434, Loss: 0.065240278840065, Final Batch Loss: 0.033746980130672455\n",
      "Epoch 1435, Loss: 0.041822684928774834, Final Batch Loss: 0.02200176939368248\n",
      "Epoch 1436, Loss: 0.02512406837195158, Final Batch Loss: 0.015863293781876564\n",
      "Epoch 1437, Loss: 0.08567545562982559, Final Batch Loss: 0.05000707507133484\n",
      "Epoch 1438, Loss: 0.028224101290106773, Final Batch Loss: 0.017307797446846962\n",
      "Epoch 1439, Loss: 0.03805334493517876, Final Batch Loss: 0.015834053978323936\n",
      "Epoch 1440, Loss: 0.04677275475114584, Final Batch Loss: 0.011685132049024105\n",
      "Epoch 1441, Loss: 0.04844851605594158, Final Batch Loss: 0.03469373658299446\n",
      "Epoch 1442, Loss: 0.0425941301509738, Final Batch Loss: 0.029636692255735397\n",
      "Epoch 1443, Loss: 0.05377011373639107, Final Batch Loss: 0.02150178700685501\n",
      "Epoch 1444, Loss: 0.04223626013845205, Final Batch Loss: 0.02816089056432247\n",
      "Epoch 1445, Loss: 0.032178351655602455, Final Batch Loss: 0.013852780684828758\n",
      "Epoch 1446, Loss: 0.013031627284362912, Final Batch Loss: 0.003802964696660638\n",
      "Epoch 1447, Loss: 0.036546953953802586, Final Batch Loss: 0.013491262681782246\n",
      "Epoch 1448, Loss: 0.03369550779461861, Final Batch Loss: 0.01682755909860134\n",
      "Epoch 1449, Loss: 0.03712747059762478, Final Batch Loss: 0.024075748398900032\n",
      "Epoch 1450, Loss: 0.01835907227359712, Final Batch Loss: 0.003425424685701728\n",
      "Epoch 1451, Loss: 0.03167601767927408, Final Batch Loss: 0.006225996650755405\n",
      "Epoch 1452, Loss: 0.11314331740140915, Final Batch Loss: 0.08038748800754547\n",
      "Epoch 1453, Loss: 0.018518284894526005, Final Batch Loss: 0.004728161729872227\n",
      "Epoch 1454, Loss: 0.08032223861664534, Final Batch Loss: 0.06746861338615417\n",
      "Epoch 1455, Loss: 0.023507970850914717, Final Batch Loss: 0.006734806578606367\n",
      "Epoch 1456, Loss: 0.04148006346076727, Final Batch Loss: 0.011977213434875011\n",
      "Epoch 1457, Loss: 0.03732446115463972, Final Batch Loss: 0.00677254144102335\n",
      "Epoch 1458, Loss: 0.06991072557866573, Final Batch Loss: 0.030229924246668816\n",
      "Epoch 1459, Loss: 0.03170226980000734, Final Batch Loss: 0.0111520541831851\n",
      "Epoch 1460, Loss: 0.02916241902858019, Final Batch Loss: 0.01217487920075655\n",
      "Epoch 1461, Loss: 0.048816198483109474, Final Batch Loss: 0.01880740188062191\n",
      "Epoch 1462, Loss: 0.05898144841194153, Final Batch Loss: 0.042795613408088684\n",
      "Epoch 1463, Loss: 0.04291388392448425, Final Batch Loss: 0.017863376066088676\n",
      "Epoch 1464, Loss: 0.04011109936982393, Final Batch Loss: 0.013031347654759884\n",
      "Epoch 1465, Loss: 0.043822260573506355, Final Batch Loss: 0.026667790487408638\n",
      "Epoch 1466, Loss: 0.04460029862821102, Final Batch Loss: 0.029268436133861542\n",
      "Epoch 1467, Loss: 0.034406477585434914, Final Batch Loss: 0.017548412084579468\n",
      "Epoch 1468, Loss: 0.024738592095673084, Final Batch Loss: 0.011799297295510769\n",
      "Epoch 1469, Loss: 0.08644034340977669, Final Batch Loss: 0.029606308788061142\n",
      "Epoch 1470, Loss: 0.052875151857733727, Final Batch Loss: 0.04421817511320114\n",
      "Epoch 1471, Loss: 0.09119362197816372, Final Batch Loss: 0.07646777480840683\n",
      "Epoch 1472, Loss: 0.0667966939508915, Final Batch Loss: 0.02345564216375351\n",
      "Epoch 1473, Loss: 0.12512708082795143, Final Batch Loss: 0.06614703685045242\n",
      "Epoch 1474, Loss: 0.050640545785427094, Final Batch Loss: 0.028602445498108864\n",
      "Epoch 1475, Loss: 0.08371675759553909, Final Batch Loss: 0.06624512374401093\n",
      "Epoch 1476, Loss: 0.05871664918959141, Final Batch Loss: 0.030510040000081062\n",
      "Epoch 1477, Loss: 0.19610045105218887, Final Batch Loss: 0.10964895039796829\n",
      "Epoch 1478, Loss: 0.07590872794389725, Final Batch Loss: 0.04046778380870819\n",
      "Epoch 1479, Loss: 0.16179008409380913, Final Batch Loss: 0.11337856203317642\n",
      "Epoch 1480, Loss: 0.12459931895136833, Final Batch Loss: 0.051690731197595596\n",
      "Epoch 1481, Loss: 0.03893755003809929, Final Batch Loss: 0.018732773140072823\n",
      "Epoch 1482, Loss: 0.1128917746245861, Final Batch Loss: 0.07572078704833984\n",
      "Epoch 1483, Loss: 0.04108978621661663, Final Batch Loss: 0.027943776920437813\n",
      "Epoch 1484, Loss: 0.08672502823174, Final Batch Loss: 0.030433764681220055\n",
      "Epoch 1485, Loss: 0.10364287719130516, Final Batch Loss: 0.01925421878695488\n",
      "Epoch 1486, Loss: 0.03308989852666855, Final Batch Loss: 0.015949122607707977\n",
      "Epoch 1487, Loss: 0.04891580156981945, Final Batch Loss: 0.019176531583070755\n",
      "Epoch 1488, Loss: 0.05019317753612995, Final Batch Loss: 0.018246492370963097\n",
      "Epoch 1489, Loss: 0.08661891147494316, Final Batch Loss: 0.020784180611371994\n",
      "Epoch 1490, Loss: 0.049198852851986885, Final Batch Loss: 0.029437119141221046\n",
      "Epoch 1491, Loss: 0.07074552029371262, Final Batch Loss: 0.015885598957538605\n",
      "Epoch 1492, Loss: 0.11533217504620552, Final Batch Loss: 0.05273137614130974\n",
      "Epoch 1493, Loss: 0.05950495786964893, Final Batch Loss: 0.022367505356669426\n",
      "Epoch 1494, Loss: 0.060971133410930634, Final Batch Loss: 0.016879603266716003\n",
      "Epoch 1495, Loss: 0.10795381292700768, Final Batch Loss: 0.07789145410060883\n",
      "Epoch 1496, Loss: 0.036091163754463196, Final Batch Loss: 0.017645535990595818\n",
      "Epoch 1497, Loss: 0.07410419546067715, Final Batch Loss: 0.028662996366620064\n",
      "Epoch 1498, Loss: 0.04712018836289644, Final Batch Loss: 0.014707659371197224\n",
      "Epoch 1499, Loss: 0.03721692133694887, Final Batch Loss: 0.028687376528978348\n",
      "Epoch 1500, Loss: 0.07941674906760454, Final Batch Loss: 0.009413537569344044\n",
      "Epoch 1501, Loss: 0.019950141198933125, Final Batch Loss: 0.004905855283141136\n",
      "Epoch 1502, Loss: 0.03174755722284317, Final Batch Loss: 0.023524999618530273\n",
      "Epoch 1503, Loss: 0.011692820582538843, Final Batch Loss: 0.005569506902247667\n",
      "Epoch 1504, Loss: 0.023652055766433477, Final Batch Loss: 0.00703673018142581\n",
      "Epoch 1505, Loss: 0.057169634848833084, Final Batch Loss: 0.024781692773103714\n",
      "Epoch 1506, Loss: 0.06653984449803829, Final Batch Loss: 0.039864204823970795\n",
      "Epoch 1507, Loss: 0.03459032857790589, Final Batch Loss: 0.007649621460586786\n",
      "Epoch 1508, Loss: 0.029583679512143135, Final Batch Loss: 0.015942607074975967\n",
      "Epoch 1509, Loss: 0.017466526478528976, Final Batch Loss: 0.00639698002487421\n",
      "Epoch 1510, Loss: 0.0520426370203495, Final Batch Loss: 0.021883992478251457\n",
      "Epoch 1511, Loss: 0.04575375001877546, Final Batch Loss: 0.034343309700489044\n",
      "Epoch 1512, Loss: 0.06473616138100624, Final Batch Loss: 0.026742350310087204\n",
      "Epoch 1513, Loss: 0.028263567946851254, Final Batch Loss: 0.008707775734364986\n",
      "Epoch 1514, Loss: 0.057236199267208576, Final Batch Loss: 0.046679820865392685\n",
      "Epoch 1515, Loss: 0.02744904113933444, Final Batch Loss: 0.0067878603003919125\n",
      "Epoch 1516, Loss: 0.04672743007540703, Final Batch Loss: 0.02646857127547264\n",
      "Epoch 1517, Loss: 0.06757303792983294, Final Batch Loss: 0.015220035798847675\n",
      "Epoch 1518, Loss: 0.05432073771953583, Final Batch Loss: 0.04058877006173134\n",
      "Epoch 1519, Loss: 0.06566983368247747, Final Batch Loss: 0.00788890477269888\n",
      "Epoch 1520, Loss: 0.04485717602074146, Final Batch Loss: 0.016765885055065155\n",
      "Epoch 1521, Loss: 0.08117807283997536, Final Batch Loss: 0.02901523932814598\n",
      "Epoch 1522, Loss: 0.07046796102076769, Final Batch Loss: 0.05768159404397011\n",
      "Epoch 1523, Loss: 0.058698615059256554, Final Batch Loss: 0.043523456901311874\n",
      "Epoch 1524, Loss: 0.09710223600268364, Final Batch Loss: 0.051362115889787674\n",
      "Epoch 1525, Loss: 0.048618040047585964, Final Batch Loss: 0.033067960292100906\n",
      "Epoch 1526, Loss: 0.06405936367809772, Final Batch Loss: 0.04689960554242134\n",
      "Epoch 1527, Loss: 0.032046967186033726, Final Batch Loss: 0.011083577759563923\n",
      "Epoch 1528, Loss: 0.09889151528477669, Final Batch Loss: 0.06745042651891708\n",
      "Epoch 1529, Loss: 0.033651670441031456, Final Batch Loss: 0.011324547231197357\n",
      "Epoch 1530, Loss: 0.05008495505899191, Final Batch Loss: 0.035361193120479584\n",
      "Epoch 1531, Loss: 0.06597024947404861, Final Batch Loss: 0.044522177428007126\n",
      "Epoch 1532, Loss: 0.09329783916473389, Final Batch Loss: 0.05192257836461067\n",
      "Epoch 1533, Loss: 0.13744840025901794, Final Batch Loss: 0.06500308215618134\n",
      "Epoch 1534, Loss: 0.016546329949051142, Final Batch Loss: 0.009896262548863888\n",
      "Epoch 1535, Loss: 0.08127252757549286, Final Batch Loss: 0.05386563017964363\n",
      "Epoch 1536, Loss: 0.1038644053041935, Final Batch Loss: 0.016697216778993607\n",
      "Epoch 1537, Loss: 0.1602667197585106, Final Batch Loss: 0.06896385550498962\n",
      "Epoch 1538, Loss: 0.03673934796825051, Final Batch Loss: 0.007353030610829592\n",
      "Epoch 1539, Loss: 0.07509087771177292, Final Batch Loss: 0.02805357053875923\n",
      "Epoch 1540, Loss: 0.09637673199176788, Final Batch Loss: 0.040649235248565674\n",
      "Epoch 1541, Loss: 0.07756992056965828, Final Batch Loss: 0.028301168233156204\n",
      "Epoch 1542, Loss: 0.0370964203029871, Final Batch Loss: 0.02837156318128109\n",
      "Epoch 1543, Loss: 0.05402306094765663, Final Batch Loss: 0.01910485327243805\n",
      "Epoch 1544, Loss: 0.05873064324259758, Final Batch Loss: 0.024468250572681427\n",
      "Epoch 1545, Loss: 0.04295111820101738, Final Batch Loss: 0.010168559849262238\n",
      "Epoch 1546, Loss: 0.1045362651348114, Final Batch Loss: 0.0434022918343544\n",
      "Epoch 1547, Loss: 0.09504761919379234, Final Batch Loss: 0.040365416556596756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1548, Loss: 0.02798607526347041, Final Batch Loss: 0.005400545429438353\n",
      "Epoch 1549, Loss: 0.05827119015157223, Final Batch Loss: 0.04012693464756012\n",
      "Epoch 1550, Loss: 0.05479059927165508, Final Batch Loss: 0.0272783525288105\n",
      "Epoch 1551, Loss: 0.050070054829120636, Final Batch Loss: 0.03172934055328369\n",
      "Epoch 1552, Loss: 0.08584803342819214, Final Batch Loss: 0.06483962386846542\n",
      "Epoch 1553, Loss: 0.09329728409647942, Final Batch Loss: 0.047506798058748245\n",
      "Epoch 1554, Loss: 0.06600762344896793, Final Batch Loss: 0.016986889764666557\n",
      "Epoch 1555, Loss: 0.06574320420622826, Final Batch Loss: 0.054493360221385956\n",
      "Epoch 1556, Loss: 0.0683572106063366, Final Batch Loss: 0.02607283741235733\n",
      "Epoch 1557, Loss: 0.06806921772658825, Final Batch Loss: 0.027589356526732445\n",
      "Epoch 1558, Loss: 0.045584168285131454, Final Batch Loss: 0.026722362264990807\n",
      "Epoch 1559, Loss: 0.05265355110168457, Final Batch Loss: 0.01840883120894432\n",
      "Epoch 1560, Loss: 0.04478207044303417, Final Batch Loss: 0.02259148098528385\n",
      "Epoch 1561, Loss: 0.08342818729579449, Final Batch Loss: 0.030401552096009254\n",
      "Epoch 1562, Loss: 0.12704753316938877, Final Batch Loss: 0.09588973969221115\n",
      "Epoch 1563, Loss: 0.035881539806723595, Final Batch Loss: 0.007106201723217964\n",
      "Epoch 1564, Loss: 0.08129821717739105, Final Batch Loss: 0.04243062064051628\n",
      "Epoch 1565, Loss: 0.08715655282139778, Final Batch Loss: 0.04615192487835884\n",
      "Epoch 1566, Loss: 0.06602975726127625, Final Batch Loss: 0.0462944433093071\n",
      "Epoch 1567, Loss: 0.06320145726203918, Final Batch Loss: 0.043138280510902405\n",
      "Epoch 1568, Loss: 0.05055322125554085, Final Batch Loss: 0.018589463084936142\n",
      "Epoch 1569, Loss: 0.08922215178608894, Final Batch Loss: 0.04077601432800293\n",
      "Epoch 1570, Loss: 0.02465908881276846, Final Batch Loss: 0.01088839303702116\n",
      "Epoch 1571, Loss: 0.0605982868000865, Final Batch Loss: 0.048271045088768005\n",
      "Epoch 1572, Loss: 0.0879088006913662, Final Batch Loss: 0.0481109656393528\n",
      "Epoch 1573, Loss: 0.02137074153870344, Final Batch Loss: 0.01286143809556961\n",
      "Epoch 1574, Loss: 0.24308978766202927, Final Batch Loss: 0.12336963415145874\n",
      "Epoch 1575, Loss: 0.02788055967539549, Final Batch Loss: 0.016740381717681885\n",
      "Epoch 1576, Loss: 0.07625895366072655, Final Batch Loss: 0.04967251420021057\n",
      "Epoch 1577, Loss: 0.02100226003676653, Final Batch Loss: 0.007976263761520386\n",
      "Epoch 1578, Loss: 0.02278689108788967, Final Batch Loss: 0.011456300504505634\n",
      "Epoch 1579, Loss: 0.09668062254786491, Final Batch Loss: 0.036731164902448654\n",
      "Epoch 1580, Loss: 0.05864753760397434, Final Batch Loss: 0.026927275583148003\n",
      "Epoch 1581, Loss: 0.022821629885584116, Final Batch Loss: 0.007362506818026304\n",
      "Epoch 1582, Loss: 0.03569911140948534, Final Batch Loss: 0.021480407565832138\n",
      "Epoch 1583, Loss: 0.04437506012618542, Final Batch Loss: 0.017051387578248978\n",
      "Epoch 1584, Loss: 0.04660583287477493, Final Batch Loss: 0.01667083241045475\n",
      "Epoch 1585, Loss: 0.020755082834511995, Final Batch Loss: 0.006569922436028719\n",
      "Epoch 1586, Loss: 0.03332887962460518, Final Batch Loss: 0.016661398112773895\n",
      "Epoch 1587, Loss: 0.04719935171306133, Final Batch Loss: 0.02676563151180744\n",
      "Epoch 1588, Loss: 0.02295329002663493, Final Batch Loss: 0.004066317807883024\n",
      "Epoch 1589, Loss: 0.03872480429708958, Final Batch Loss: 0.020561721175909042\n",
      "Epoch 1590, Loss: 0.02198099996894598, Final Batch Loss: 0.011959847062826157\n",
      "Epoch 1591, Loss: 0.04545962996780872, Final Batch Loss: 0.018771778792142868\n",
      "Epoch 1592, Loss: 0.03376216907054186, Final Batch Loss: 0.022739367559552193\n",
      "Epoch 1593, Loss: 0.03359422832727432, Final Batch Loss: 0.012094490230083466\n",
      "Epoch 1594, Loss: 0.04344593081623316, Final Batch Loss: 0.005294331349432468\n",
      "Epoch 1595, Loss: 0.022283980390056968, Final Batch Loss: 0.02004300244152546\n",
      "Epoch 1596, Loss: 0.01636896561831236, Final Batch Loss: 0.007277626544237137\n",
      "Epoch 1597, Loss: 0.027345022186636925, Final Batch Loss: 0.017776580527424812\n",
      "Epoch 1598, Loss: 0.025904216803610325, Final Batch Loss: 0.01662851870059967\n",
      "Epoch 1599, Loss: 0.033091760240495205, Final Batch Loss: 0.0074512893334031105\n",
      "Epoch 1600, Loss: 0.03537206910550594, Final Batch Loss: 0.016196269541978836\n",
      "Epoch 1601, Loss: 0.07135343737900257, Final Batch Loss: 0.04390837624669075\n",
      "Epoch 1602, Loss: 0.027906392700970173, Final Batch Loss: 0.01199557539075613\n",
      "Epoch 1603, Loss: 0.03124262485653162, Final Batch Loss: 0.006188991479575634\n",
      "Epoch 1604, Loss: 0.09661846980452538, Final Batch Loss: 0.0288715623319149\n",
      "Epoch 1605, Loss: 0.023118871729820967, Final Batch Loss: 0.006409341003745794\n",
      "Epoch 1606, Loss: 0.04315424710512161, Final Batch Loss: 0.0360221229493618\n",
      "Epoch 1607, Loss: 0.03624462150037289, Final Batch Loss: 0.011172957718372345\n",
      "Epoch 1608, Loss: 0.032191391102969646, Final Batch Loss: 0.006968180648982525\n",
      "Epoch 1609, Loss: 0.035753482952713966, Final Batch Loss: 0.02550794743001461\n",
      "Epoch 1610, Loss: 0.035278924740850925, Final Batch Loss: 0.008398757316172123\n",
      "Epoch 1611, Loss: 0.029404030181467533, Final Batch Loss: 0.015115903690457344\n",
      "Epoch 1612, Loss: 0.02590567199513316, Final Batch Loss: 0.006926750298589468\n",
      "Epoch 1613, Loss: 0.12550027295947075, Final Batch Loss: 0.10996031761169434\n",
      "Epoch 1614, Loss: 0.06257233023643494, Final Batch Loss: 0.047534532845020294\n",
      "Epoch 1615, Loss: 0.03878334444016218, Final Batch Loss: 0.012445195578038692\n",
      "Epoch 1616, Loss: 0.03605103865265846, Final Batch Loss: 0.02191763184964657\n",
      "Epoch 1617, Loss: 0.0732980384491384, Final Batch Loss: 0.003405527677386999\n",
      "Epoch 1618, Loss: 0.0242008320055902, Final Batch Loss: 0.002360002603381872\n",
      "Epoch 1619, Loss: 0.028926948085427284, Final Batch Loss: 0.00894935056567192\n",
      "Epoch 1620, Loss: 0.053801738657057285, Final Batch Loss: 0.042872410267591476\n",
      "Epoch 1621, Loss: 0.022102409042418003, Final Batch Loss: 0.0037659229710698128\n",
      "Epoch 1622, Loss: 0.0540138790383935, Final Batch Loss: 0.015035429038107395\n",
      "Epoch 1623, Loss: 0.0275162598118186, Final Batch Loss: 0.007393096573650837\n",
      "Epoch 1624, Loss: 0.0432857908308506, Final Batch Loss: 0.008097577840089798\n",
      "Epoch 1625, Loss: 0.0841653048992157, Final Batch Loss: 0.0481475368142128\n",
      "Epoch 1626, Loss: 0.03233512304723263, Final Batch Loss: 0.024035902693867683\n",
      "Epoch 1627, Loss: 0.04653584957122803, Final Batch Loss: 0.029397597536444664\n",
      "Epoch 1628, Loss: 0.06570589356124401, Final Batch Loss: 0.04336835443973541\n",
      "Epoch 1629, Loss: 0.08215180458500981, Final Batch Loss: 0.07718917727470398\n",
      "Epoch 1630, Loss: 0.025511298794299364, Final Batch Loss: 0.0029107374139130116\n",
      "Epoch 1631, Loss: 0.02533658780157566, Final Batch Loss: 0.016452308744192123\n",
      "Epoch 1632, Loss: 0.03625222481787205, Final Batch Loss: 0.005972951650619507\n",
      "Epoch 1633, Loss: 0.04863707162439823, Final Batch Loss: 0.023049503564834595\n",
      "Epoch 1634, Loss: 0.041646577417850494, Final Batch Loss: 0.014506682753562927\n",
      "Epoch 1635, Loss: 0.032658365555107594, Final Batch Loss: 0.023613767698407173\n",
      "Epoch 1636, Loss: 0.06191075127571821, Final Batch Loss: 0.049722567200660706\n",
      "Epoch 1637, Loss: 0.04411139991134405, Final Batch Loss: 0.02945159189403057\n",
      "Epoch 1638, Loss: 0.041335685178637505, Final Batch Loss: 0.018166564404964447\n",
      "Epoch 1639, Loss: 0.0671500600874424, Final Batch Loss: 0.009051699191331863\n",
      "Epoch 1640, Loss: 0.03775087837129831, Final Batch Loss: 0.009925189428031445\n",
      "Epoch 1641, Loss: 0.03884055558592081, Final Batch Loss: 0.026640761643648148\n",
      "Epoch 1642, Loss: 0.010753627866506577, Final Batch Loss: 0.005811422131955624\n",
      "Epoch 1643, Loss: 0.03656190633773804, Final Batch Loss: 0.01431177370250225\n",
      "Epoch 1644, Loss: 0.027943553868681192, Final Batch Loss: 0.020782051607966423\n",
      "Epoch 1645, Loss: 0.048626476898789406, Final Batch Loss: 0.032586246728897095\n",
      "Epoch 1646, Loss: 0.044624429661780596, Final Batch Loss: 0.006828308571130037\n",
      "Epoch 1647, Loss: 0.026052829809486866, Final Batch Loss: 0.015001852996647358\n",
      "Epoch 1648, Loss: 0.028798935003578663, Final Batch Loss: 0.014924421906471252\n",
      "Epoch 1649, Loss: 0.041910468600690365, Final Batch Loss: 0.012187381274998188\n",
      "Epoch 1650, Loss: 0.037482055835425854, Final Batch Loss: 0.028182050213217735\n",
      "Epoch 1651, Loss: 0.027651755139231682, Final Batch Loss: 0.009400833398103714\n",
      "Epoch 1652, Loss: 0.0777962002903223, Final Batch Loss: 0.027902113273739815\n",
      "Epoch 1653, Loss: 0.05079025402665138, Final Batch Loss: 0.02407199889421463\n",
      "Epoch 1654, Loss: 0.020697726868093014, Final Batch Loss: 0.007837959565222263\n",
      "Epoch 1655, Loss: 0.026230706833302975, Final Batch Loss: 0.016057802364230156\n",
      "Epoch 1656, Loss: 0.0265535656362772, Final Batch Loss: 0.008882710710167885\n",
      "Epoch 1657, Loss: 0.027600347995758057, Final Batch Loss: 0.01185668632388115\n",
      "Epoch 1658, Loss: 0.04530000081285834, Final Batch Loss: 0.007328090723603964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1659, Loss: 0.01681535132229328, Final Batch Loss: 0.005444289185106754\n",
      "Epoch 1660, Loss: 0.034798952750861645, Final Batch Loss: 0.006523198448121548\n",
      "Epoch 1661, Loss: 0.19435972394421697, Final Batch Loss: 0.006258119363337755\n",
      "Epoch 1662, Loss: 0.07760685216635466, Final Batch Loss: 0.011391575448215008\n",
      "Epoch 1663, Loss: 0.037357356399297714, Final Batch Loss: 0.018344666808843613\n",
      "Epoch 1664, Loss: 0.028312379494309425, Final Batch Loss: 0.0060379114001989365\n",
      "Epoch 1665, Loss: 0.0332746731583029, Final Batch Loss: 0.003156371647492051\n",
      "Epoch 1666, Loss: 0.0313710393384099, Final Batch Loss: 0.02443365566432476\n",
      "Epoch 1667, Loss: 0.023518365807831287, Final Batch Loss: 0.012299920432269573\n",
      "Epoch 1668, Loss: 0.08103754557669163, Final Batch Loss: 0.06910081207752228\n",
      "Epoch 1669, Loss: 0.05058910883963108, Final Batch Loss: 0.034300316125154495\n",
      "Epoch 1670, Loss: 0.04343365132808685, Final Batch Loss: 0.019994230940937996\n",
      "Epoch 1671, Loss: 0.018666177988052368, Final Batch Loss: 0.012293566018342972\n",
      "Epoch 1672, Loss: 0.21647972986102104, Final Batch Loss: 0.17693346738815308\n",
      "Epoch 1673, Loss: 0.06168402545154095, Final Batch Loss: 0.012314485386013985\n",
      "Epoch 1674, Loss: 0.06367740407586098, Final Batch Loss: 0.03817128762602806\n",
      "Epoch 1675, Loss: 0.04470554389990866, Final Batch Loss: 0.0032218920532613993\n",
      "Epoch 1676, Loss: 0.03053261525928974, Final Batch Loss: 0.014770980924367905\n",
      "Epoch 1677, Loss: 0.029366349801421165, Final Batch Loss: 0.021213455125689507\n",
      "Epoch 1678, Loss: 0.05025325529277325, Final Batch Loss: 0.021625356748700142\n",
      "Epoch 1679, Loss: 0.036866693291813135, Final Batch Loss: 0.00656483368948102\n",
      "Epoch 1680, Loss: 0.027182764373719692, Final Batch Loss: 0.010045773349702358\n",
      "Epoch 1681, Loss: 0.029249639250338078, Final Batch Loss: 0.011209973134100437\n",
      "Epoch 1682, Loss: 0.041751325130462646, Final Batch Loss: 0.017111768946051598\n",
      "Epoch 1683, Loss: 0.07547722198069096, Final Batch Loss: 0.061465855687856674\n",
      "Epoch 1684, Loss: 0.03879770450294018, Final Batch Loss: 0.029810233041644096\n",
      "Epoch 1685, Loss: 0.01768453512340784, Final Batch Loss: 0.012966210022568703\n",
      "Epoch 1686, Loss: 0.0167596279643476, Final Batch Loss: 0.006562833208590746\n",
      "Epoch 1687, Loss: 0.0677755419164896, Final Batch Loss: 0.04839905723929405\n",
      "Epoch 1688, Loss: 0.036053527146577835, Final Batch Loss: 0.030519522726535797\n",
      "Epoch 1689, Loss: 0.06146799121052027, Final Batch Loss: 0.009625219739973545\n",
      "Epoch 1690, Loss: 0.0716887041926384, Final Batch Loss: 0.042809367179870605\n",
      "Epoch 1691, Loss: 0.13206852227449417, Final Batch Loss: 0.07604272663593292\n",
      "Epoch 1692, Loss: 0.06185941398143768, Final Batch Loss: 0.02292916178703308\n",
      "Epoch 1693, Loss: 0.09298158064484596, Final Batch Loss: 0.0496583916246891\n",
      "Epoch 1694, Loss: 0.057374048978090286, Final Batch Loss: 0.008962348103523254\n",
      "Epoch 1695, Loss: 0.06723052822053432, Final Batch Loss: 0.04962747171521187\n",
      "Epoch 1696, Loss: 0.07816801778972149, Final Batch Loss: 0.05089526250958443\n",
      "Epoch 1697, Loss: 0.03481393679976463, Final Batch Loss: 0.012897660955786705\n",
      "Epoch 1698, Loss: 0.06773808691650629, Final Batch Loss: 0.05432381108403206\n",
      "Epoch 1699, Loss: 0.0743167195469141, Final Batch Loss: 0.017292147502303123\n",
      "Epoch 1700, Loss: 0.07147794682532549, Final Batch Loss: 0.01174588967114687\n",
      "Epoch 1701, Loss: 0.05062739551067352, Final Batch Loss: 0.029528813436627388\n",
      "Epoch 1702, Loss: 0.07421442493796349, Final Batch Loss: 0.04694709554314613\n",
      "Epoch 1703, Loss: 0.07178599946200848, Final Batch Loss: 0.047612614929676056\n",
      "Epoch 1704, Loss: 0.024037793278694153, Final Batch Loss: 0.011576143093407154\n",
      "Epoch 1705, Loss: 0.04815680719912052, Final Batch Loss: 0.025058554485440254\n",
      "Epoch 1706, Loss: 0.07760066725313663, Final Batch Loss: 0.04843645915389061\n",
      "Epoch 1707, Loss: 0.09939510934054852, Final Batch Loss: 0.06906656920909882\n",
      "Epoch 1708, Loss: 0.048339562490582466, Final Batch Loss: 0.03464728593826294\n",
      "Epoch 1709, Loss: 0.028581652790308, Final Batch Loss: 0.017633449286222458\n",
      "Epoch 1710, Loss: 0.02649808209389448, Final Batch Loss: 0.01274428516626358\n",
      "Epoch 1711, Loss: 0.04398866556584835, Final Batch Loss: 0.029171252623200417\n",
      "Epoch 1712, Loss: 0.02426327019929886, Final Batch Loss: 0.012198067270219326\n",
      "Epoch 1713, Loss: 0.03810683265328407, Final Batch Loss: 0.013807931914925575\n",
      "Epoch 1714, Loss: 0.03235462587326765, Final Batch Loss: 0.018169866874814034\n",
      "Epoch 1715, Loss: 0.040476574562489986, Final Batch Loss: 0.005203641019761562\n",
      "Epoch 1716, Loss: 0.02615988440811634, Final Batch Loss: 0.016303343698382378\n",
      "Epoch 1717, Loss: 0.03851178288459778, Final Batch Loss: 0.029582705348730087\n",
      "Epoch 1718, Loss: 0.022185184061527252, Final Batch Loss: 0.010584629140794277\n",
      "Epoch 1719, Loss: 0.03137604147195816, Final Batch Loss: 0.011066492646932602\n",
      "Epoch 1720, Loss: 0.0546104721724987, Final Batch Loss: 0.041769642382860184\n",
      "Epoch 1721, Loss: 0.03696089470759034, Final Batch Loss: 0.004428619984537363\n",
      "Epoch 1722, Loss: 0.15770523995161057, Final Batch Loss: 0.03801879286766052\n",
      "Epoch 1723, Loss: 0.01681598462164402, Final Batch Loss: 0.007947539910674095\n",
      "Epoch 1724, Loss: 0.028372270986437798, Final Batch Loss: 0.013518206775188446\n",
      "Epoch 1725, Loss: 0.02523530088365078, Final Batch Loss: 0.01535750087350607\n",
      "Epoch 1726, Loss: 0.028139641508460045, Final Batch Loss: 0.019225796684622765\n",
      "Epoch 1727, Loss: 0.04803227912634611, Final Batch Loss: 0.04006720334291458\n",
      "Epoch 1728, Loss: 0.06801233068108559, Final Batch Loss: 0.029299188405275345\n",
      "Epoch 1729, Loss: 0.03536470979452133, Final Batch Loss: 0.014702919870615005\n",
      "Epoch 1730, Loss: 0.025229474529623985, Final Batch Loss: 0.018881142139434814\n",
      "Epoch 1731, Loss: 0.014452222036197782, Final Batch Loss: 0.011978362686932087\n",
      "Epoch 1732, Loss: 0.0432041697204113, Final Batch Loss: 0.02133929543197155\n",
      "Epoch 1733, Loss: 0.012899775989353657, Final Batch Loss: 0.0032586446031928062\n",
      "Epoch 1734, Loss: 0.027603971771895885, Final Batch Loss: 0.0062123192474246025\n",
      "Epoch 1735, Loss: 0.021421595476567745, Final Batch Loss: 0.008517764508724213\n",
      "Epoch 1736, Loss: 0.032214172184467316, Final Batch Loss: 0.011345699429512024\n",
      "Epoch 1737, Loss: 0.024066285230219364, Final Batch Loss: 0.007505170069634914\n",
      "Epoch 1738, Loss: 0.02453853003680706, Final Batch Loss: 0.014077599160373211\n",
      "Epoch 1739, Loss: 0.04331888863816857, Final Batch Loss: 0.00543909752741456\n",
      "Epoch 1740, Loss: 0.021963294595479965, Final Batch Loss: 0.006283629685640335\n",
      "Epoch 1741, Loss: 0.041842732578516006, Final Batch Loss: 0.020318808034062386\n",
      "Epoch 1742, Loss: 0.03785392362624407, Final Batch Loss: 0.009637217037379742\n",
      "Epoch 1743, Loss: 0.026202939450740814, Final Batch Loss: 0.004769615828990936\n",
      "Epoch 1744, Loss: 0.04978295415639877, Final Batch Loss: 0.01331191137433052\n",
      "Epoch 1745, Loss: 0.03405757714062929, Final Batch Loss: 0.02631593495607376\n",
      "Epoch 1746, Loss: 0.01874702423810959, Final Batch Loss: 0.006953381933271885\n",
      "Epoch 1747, Loss: 0.062120381742715836, Final Batch Loss: 0.03618913143873215\n",
      "Epoch 1748, Loss: 0.04801993817090988, Final Batch Loss: 0.017152080312371254\n",
      "Epoch 1749, Loss: 0.050086067989468575, Final Batch Loss: 0.021368922665715218\n",
      "Epoch 1750, Loss: 0.03565273154526949, Final Batch Loss: 0.009661463089287281\n",
      "Epoch 1751, Loss: 0.03834829106926918, Final Batch Loss: 0.0172464307397604\n",
      "Epoch 1752, Loss: 0.025019017048180103, Final Batch Loss: 0.015598230063915253\n",
      "Epoch 1753, Loss: 0.02256137691438198, Final Batch Loss: 0.012629508040845394\n",
      "Epoch 1754, Loss: 0.03876599110662937, Final Batch Loss: 0.02136019617319107\n",
      "Epoch 1755, Loss: 0.030448385514318943, Final Batch Loss: 0.02181510254740715\n",
      "Epoch 1756, Loss: 0.00665636919438839, Final Batch Loss: 0.0025903191417455673\n",
      "Epoch 1757, Loss: 0.01624853489920497, Final Batch Loss: 0.007254670839756727\n",
      "Epoch 1758, Loss: 0.05568189360201359, Final Batch Loss: 0.009781105443835258\n",
      "Epoch 1759, Loss: 0.027001990005373955, Final Batch Loss: 0.006333408877253532\n",
      "Epoch 1760, Loss: 0.02262380626052618, Final Batch Loss: 0.013742859475314617\n",
      "Epoch 1761, Loss: 0.030471662059426308, Final Batch Loss: 0.021915897727012634\n",
      "Epoch 1762, Loss: 0.021012181416153908, Final Batch Loss: 0.007122626528143883\n",
      "Epoch 1763, Loss: 0.01969789434224367, Final Batch Loss: 0.014789457432925701\n",
      "Epoch 1764, Loss: 0.018376801162958145, Final Batch Loss: 0.006199901923537254\n",
      "Epoch 1765, Loss: 0.014236332383006811, Final Batch Loss: 0.008480412885546684\n",
      "Epoch 1766, Loss: 0.11796312686055899, Final Batch Loss: 0.11005502194166183\n",
      "Epoch 1767, Loss: 0.05815725587308407, Final Batch Loss: 0.04046187922358513\n",
      "Epoch 1768, Loss: 0.025762722827494144, Final Batch Loss: 0.005051993764936924\n",
      "Epoch 1769, Loss: 0.03237947914749384, Final Batch Loss: 0.012404718436300755\n",
      "Epoch 1770, Loss: 0.02376924967393279, Final Batch Loss: 0.007096422370523214\n",
      "Epoch 1771, Loss: 0.06926134554669261, Final Batch Loss: 0.003622713964432478\n",
      "Epoch 1772, Loss: 0.013028757879510522, Final Batch Loss: 0.002191345440223813\n",
      "Epoch 1773, Loss: 0.026719662360846996, Final Batch Loss: 0.008738498203456402\n",
      "Epoch 1774, Loss: 0.05969303520396352, Final Batch Loss: 0.05225098878145218\n",
      "Epoch 1775, Loss: 0.027417150791734457, Final Batch Loss: 0.023176411166787148\n",
      "Epoch 1776, Loss: 0.05238662380725145, Final Batch Loss: 0.04368744418025017\n",
      "Epoch 1777, Loss: 0.026651863008737564, Final Batch Loss: 0.009517861530184746\n",
      "Epoch 1778, Loss: 0.06308230571448803, Final Batch Loss: 0.018287846818566322\n",
      "Epoch 1779, Loss: 0.018985969945788383, Final Batch Loss: 0.00901604164391756\n",
      "Epoch 1780, Loss: 0.04589338228106499, Final Batch Loss: 0.027766305953264236\n",
      "Epoch 1781, Loss: 0.016605202574282885, Final Batch Loss: 0.003191856201738119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1782, Loss: 0.028784429654479027, Final Batch Loss: 0.009470086544752121\n",
      "Epoch 1783, Loss: 0.08689575362950563, Final Batch Loss: 0.0744393914937973\n",
      "Epoch 1784, Loss: 0.028327197767794132, Final Batch Loss: 0.021344909444451332\n",
      "Epoch 1785, Loss: 0.022968952311202884, Final Batch Loss: 0.003694991348311305\n",
      "Epoch 1786, Loss: 0.10242436779662967, Final Batch Loss: 0.09533928334712982\n",
      "Epoch 1787, Loss: 0.018941225949674845, Final Batch Loss: 0.014412782154977322\n",
      "Epoch 1788, Loss: 0.03688537236303091, Final Batch Loss: 0.013205516152083874\n",
      "Epoch 1789, Loss: 0.0692341960966587, Final Batch Loss: 0.04165199398994446\n",
      "Epoch 1790, Loss: 0.036113361828029156, Final Batch Loss: 0.005604536272585392\n",
      "Epoch 1791, Loss: 0.029279188252985477, Final Batch Loss: 0.016794823110103607\n",
      "Epoch 1792, Loss: 0.04481541411951184, Final Batch Loss: 0.003930081147700548\n",
      "Epoch 1793, Loss: 0.12510431930422783, Final Batch Loss: 0.07852073758840561\n",
      "Epoch 1794, Loss: 0.09050212986767292, Final Batch Loss: 0.0241962019354105\n",
      "Epoch 1795, Loss: 0.1261066272854805, Final Batch Loss: 0.07000575214624405\n",
      "Epoch 1796, Loss: 0.03869161568582058, Final Batch Loss: 0.0068420302122831345\n",
      "Epoch 1797, Loss: 0.045470286160707474, Final Batch Loss: 0.028022995218634605\n",
      "Epoch 1798, Loss: 0.03401896357536316, Final Batch Loss: 0.021788792684674263\n",
      "Epoch 1799, Loss: 0.19318158691748977, Final Batch Loss: 0.007441771682351828\n",
      "Epoch 1800, Loss: 0.05167824774980545, Final Batch Loss: 0.01935086026787758\n",
      "Epoch 1801, Loss: 0.03001247253268957, Final Batch Loss: 0.020207703113555908\n",
      "Epoch 1802, Loss: 0.04925721511244774, Final Batch Loss: 0.01845925860106945\n",
      "Epoch 1803, Loss: 0.02879930566996336, Final Batch Loss: 0.013569465838372707\n",
      "Epoch 1804, Loss: 0.14392115082591772, Final Batch Loss: 0.009486331604421139\n",
      "Epoch 1805, Loss: 0.027865727432072163, Final Batch Loss: 0.01785087399184704\n",
      "Epoch 1806, Loss: 0.022222346626222134, Final Batch Loss: 0.00789683498442173\n",
      "Epoch 1807, Loss: 0.02857913449406624, Final Batch Loss: 0.010227454826235771\n",
      "Epoch 1808, Loss: 0.04377797432243824, Final Batch Loss: 0.007019074633717537\n",
      "Epoch 1809, Loss: 0.03112364187836647, Final Batch Loss: 0.006516173481941223\n",
      "Epoch 1810, Loss: 0.0089707151055336, Final Batch Loss: 0.003236818127334118\n",
      "Epoch 1811, Loss: 0.012896012049168348, Final Batch Loss: 0.010619337670505047\n",
      "Epoch 1812, Loss: 0.012185601983219385, Final Batch Loss: 0.004348649177700281\n",
      "Epoch 1813, Loss: 0.021506882272660732, Final Batch Loss: 0.005992230959236622\n",
      "Epoch 1814, Loss: 0.023918644059449434, Final Batch Loss: 0.004028706345707178\n",
      "Epoch 1815, Loss: 0.0380436135455966, Final Batch Loss: 0.02522672899067402\n",
      "Epoch 1816, Loss: 0.01746561739128083, Final Batch Loss: 0.0015734507469460368\n",
      "Epoch 1817, Loss: 0.012734141200780869, Final Batch Loss: 0.004880284890532494\n",
      "Epoch 1818, Loss: 0.014624716714024544, Final Batch Loss: 0.0048911962658166885\n",
      "Epoch 1819, Loss: 0.014694695360958576, Final Batch Loss: 0.006165429018437862\n",
      "Epoch 1820, Loss: 0.025705776177346706, Final Batch Loss: 0.01834457367658615\n",
      "Epoch 1821, Loss: 0.01747018750756979, Final Batch Loss: 0.008171400055289268\n",
      "Epoch 1822, Loss: 0.019721731077879667, Final Batch Loss: 0.002216226886957884\n",
      "Epoch 1823, Loss: 0.017576821614056826, Final Batch Loss: 0.012761088088154793\n",
      "Epoch 1824, Loss: 0.055118344724178314, Final Batch Loss: 0.040001463145017624\n",
      "Epoch 1825, Loss: 0.03220335626974702, Final Batch Loss: 0.028948314487934113\n",
      "Epoch 1826, Loss: 0.041768865659832954, Final Batch Loss: 0.019995901733636856\n",
      "Epoch 1827, Loss: 0.01778804138302803, Final Batch Loss: 0.01110642496496439\n",
      "Epoch 1828, Loss: 0.029082488268613815, Final Batch Loss: 0.019184742122888565\n",
      "Epoch 1829, Loss: 0.025770295411348343, Final Batch Loss: 0.019337112084031105\n",
      "Epoch 1830, Loss: 0.07412407360970974, Final Batch Loss: 0.0216535571962595\n",
      "Epoch 1831, Loss: 0.07473015505820513, Final Batch Loss: 0.01169047225266695\n",
      "Epoch 1832, Loss: 0.027340693399310112, Final Batch Loss: 0.011721362359821796\n",
      "Epoch 1833, Loss: 0.09381582867354155, Final Batch Loss: 0.008172313682734966\n",
      "Epoch 1834, Loss: 0.020469640381634235, Final Batch Loss: 0.006957933306694031\n",
      "Epoch 1835, Loss: 0.06384316645562649, Final Batch Loss: 0.041135821491479874\n",
      "Epoch 1836, Loss: 0.051275862380862236, Final Batch Loss: 0.01758412830531597\n",
      "Epoch 1837, Loss: 0.06844117864966393, Final Batch Loss: 0.04979678615927696\n",
      "Epoch 1838, Loss: 0.07813171669840813, Final Batch Loss: 0.05356922745704651\n",
      "Epoch 1839, Loss: 0.1466530878096819, Final Batch Loss: 0.12825655937194824\n",
      "Epoch 1840, Loss: 0.05341478809714317, Final Batch Loss: 0.013471748679876328\n",
      "Epoch 1841, Loss: 0.06000989489257336, Final Batch Loss: 0.019683143123984337\n",
      "Epoch 1842, Loss: 0.09587856382131577, Final Batch Loss: 0.06477068364620209\n",
      "Epoch 1843, Loss: 0.03328724019229412, Final Batch Loss: 0.020761029794812202\n",
      "Epoch 1844, Loss: 0.05163923464715481, Final Batch Loss: 0.023129282519221306\n",
      "Epoch 1845, Loss: 0.023204948753118515, Final Batch Loss: 0.009930052794516087\n",
      "Epoch 1846, Loss: 0.04218843672424555, Final Batch Loss: 0.009942927397787571\n",
      "Epoch 1847, Loss: 0.04216205142438412, Final Batch Loss: 0.018756376579403877\n",
      "Epoch 1848, Loss: 0.040625226218253374, Final Batch Loss: 0.007427398581057787\n",
      "Epoch 1849, Loss: 0.05108172632753849, Final Batch Loss: 0.03153073415160179\n",
      "Epoch 1850, Loss: 0.03326859883964062, Final Batch Loss: 0.009478926658630371\n",
      "Epoch 1851, Loss: 0.029405957087874413, Final Batch Loss: 0.01860884018242359\n",
      "Epoch 1852, Loss: 0.05975740775465965, Final Batch Loss: 0.01091298833489418\n",
      "Epoch 1853, Loss: 0.21724314708262682, Final Batch Loss: 0.20214101672172546\n",
      "Epoch 1854, Loss: 0.032764704897999763, Final Batch Loss: 0.012740511447191238\n",
      "Epoch 1855, Loss: 0.01782174129039049, Final Batch Loss: 0.008139724843204021\n",
      "Epoch 1856, Loss: 0.05330870486795902, Final Batch Loss: 0.033430490642786026\n",
      "Epoch 1857, Loss: 0.012742561288177967, Final Batch Loss: 0.006905311718583107\n",
      "Epoch 1858, Loss: 0.029183602891862392, Final Batch Loss: 0.01843724027276039\n",
      "Epoch 1859, Loss: 0.04196447413414717, Final Batch Loss: 0.012828267179429531\n",
      "Epoch 1860, Loss: 0.03929650876671076, Final Batch Loss: 0.02838299050927162\n",
      "Epoch 1861, Loss: 0.030959177762269974, Final Batch Loss: 0.011572476476430893\n",
      "Epoch 1862, Loss: 0.0494327787309885, Final Batch Loss: 0.018803900107741356\n",
      "Epoch 1863, Loss: 0.0439443476498127, Final Batch Loss: 0.020873960107564926\n",
      "Epoch 1864, Loss: 0.03756223525851965, Final Batch Loss: 0.010125559754669666\n",
      "Epoch 1865, Loss: 0.045104410499334335, Final Batch Loss: 0.0342520996928215\n",
      "Epoch 1866, Loss: 0.037927569821476936, Final Batch Loss: 0.010026486590504646\n",
      "Epoch 1867, Loss: 0.01582432072609663, Final Batch Loss: 0.00676397979259491\n",
      "Epoch 1868, Loss: 0.022193887270987034, Final Batch Loss: 0.011895813047885895\n",
      "Epoch 1869, Loss: 0.019683909602463245, Final Batch Loss: 0.008748109452426434\n",
      "Epoch 1870, Loss: 0.05071752518415451, Final Batch Loss: 0.014741774648427963\n",
      "Epoch 1871, Loss: 0.044411005452275276, Final Batch Loss: 0.03025711141526699\n",
      "Epoch 1872, Loss: 0.021509001031517982, Final Batch Loss: 0.009377510286867619\n",
      "Epoch 1873, Loss: 0.0391016099601984, Final Batch Loss: 0.030583297833800316\n",
      "Epoch 1874, Loss: 0.048585282638669014, Final Batch Loss: 0.02034740522503853\n",
      "Epoch 1875, Loss: 0.00894478103145957, Final Batch Loss: 0.004075576085597277\n",
      "Epoch 1876, Loss: 0.03261794615536928, Final Batch Loss: 0.015570747666060925\n",
      "Epoch 1877, Loss: 0.0638494361191988, Final Batch Loss: 0.011823808774352074\n",
      "Epoch 1878, Loss: 0.016096399165689945, Final Batch Loss: 0.007369942031800747\n",
      "Epoch 1879, Loss: 0.03127273265272379, Final Batch Loss: 0.024939492344856262\n",
      "Epoch 1880, Loss: 0.05991368182003498, Final Batch Loss: 0.00797964446246624\n",
      "Epoch 1881, Loss: 0.04007619060575962, Final Batch Loss: 0.019671877846121788\n",
      "Epoch 1882, Loss: 0.023954506032168865, Final Batch Loss: 0.013861838728189468\n",
      "Epoch 1883, Loss: 0.05462676286697388, Final Batch Loss: 0.029614118859171867\n",
      "Epoch 1884, Loss: 0.030325723811984062, Final Batch Loss: 0.024266570806503296\n",
      "Epoch 1885, Loss: 0.050418466329574585, Final Batch Loss: 0.04089194908738136\n",
      "Epoch 1886, Loss: 0.05433359555900097, Final Batch Loss: 0.04347195103764534\n",
      "Epoch 1887, Loss: 0.06236385926604271, Final Batch Loss: 0.03839423134922981\n",
      "Epoch 1888, Loss: 0.040709951892495155, Final Batch Loss: 0.009185029193758965\n",
      "Epoch 1889, Loss: 0.006619381136260927, Final Batch Loss: 0.005187897477298975\n",
      "Epoch 1890, Loss: 0.09987241867929697, Final Batch Loss: 0.09007428586483002\n",
      "Epoch 1891, Loss: 0.0370879415422678, Final Batch Loss: 0.025178540498018265\n",
      "Epoch 1892, Loss: 0.054045118391513824, Final Batch Loss: 0.023237477988004684\n",
      "Epoch 1893, Loss: 0.01653222693130374, Final Batch Loss: 0.005899089854210615\n",
      "Epoch 1894, Loss: 0.03201812785118818, Final Batch Loss: 0.004824287258088589\n",
      "Epoch 1895, Loss: 0.03494451940059662, Final Batch Loss: 0.024641215801239014\n",
      "Epoch 1896, Loss: 0.03552012797445059, Final Batch Loss: 0.027297914028167725\n",
      "Epoch 1897, Loss: 0.040624141693115234, Final Batch Loss: 0.01196778193116188\n",
      "Epoch 1898, Loss: 0.06529192999005318, Final Batch Loss: 0.03198970481753349\n",
      "Epoch 1899, Loss: 0.01140726706944406, Final Batch Loss: 0.003011303720995784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1900, Loss: 0.03316822648048401, Final Batch Loss: 0.010985443368554115\n",
      "Epoch 1901, Loss: 0.030433001928031445, Final Batch Loss: 0.01286351028829813\n",
      "Epoch 1902, Loss: 0.04316743090748787, Final Batch Loss: 0.03184007480740547\n",
      "Epoch 1903, Loss: 0.03770487941801548, Final Batch Loss: 0.006532685831189156\n",
      "Epoch 1904, Loss: 0.03466344624757767, Final Batch Loss: 0.018133394420146942\n",
      "Epoch 1905, Loss: 0.040781174786388874, Final Batch Loss: 0.0057648541405797005\n",
      "Epoch 1906, Loss: 0.046491644345223904, Final Batch Loss: 0.010499159805476665\n",
      "Epoch 1907, Loss: 0.00976605643518269, Final Batch Loss: 0.0021903093438595533\n",
      "Epoch 1908, Loss: 0.04223870858550072, Final Batch Loss: 0.007093019783496857\n",
      "Epoch 1909, Loss: 0.05557750537991524, Final Batch Loss: 0.03693787753582001\n",
      "Epoch 1910, Loss: 0.016480586025863886, Final Batch Loss: 0.0062302895821630955\n",
      "Epoch 1911, Loss: 0.027532010339200497, Final Batch Loss: 0.01280379667878151\n",
      "Epoch 1912, Loss: 0.06394650787115097, Final Batch Loss: 0.03506658971309662\n",
      "Epoch 1913, Loss: 0.0109492102637887, Final Batch Loss: 0.00489179790019989\n",
      "Epoch 1914, Loss: 0.042284825816750526, Final Batch Loss: 0.02547195740044117\n",
      "Epoch 1915, Loss: 0.07764411414973438, Final Batch Loss: 0.07434848695993423\n",
      "Epoch 1916, Loss: 0.06489625596441329, Final Batch Loss: 0.0021579342428594828\n",
      "Epoch 1917, Loss: 0.01950447726994753, Final Batch Loss: 0.007933015935122967\n",
      "Epoch 1918, Loss: 0.07044446095824242, Final Batch Loss: 0.0462881475687027\n",
      "Epoch 1919, Loss: 0.020546928979456425, Final Batch Loss: 0.010967884212732315\n",
      "Epoch 1920, Loss: 0.012482409365475178, Final Batch Loss: 0.00856172014027834\n",
      "Epoch 1921, Loss: 0.035354867577552795, Final Batch Loss: 0.014458352699875832\n",
      "Epoch 1922, Loss: 0.023038027808070183, Final Batch Loss: 0.009377414360642433\n",
      "Epoch 1923, Loss: 0.00891566788777709, Final Batch Loss: 0.004847658332437277\n",
      "Epoch 1924, Loss: 0.015401067212224007, Final Batch Loss: 0.005737221799790859\n",
      "Epoch 1925, Loss: 0.021333540789783, Final Batch Loss: 0.011531222611665726\n",
      "Epoch 1926, Loss: 0.020587672479450703, Final Batch Loss: 0.005142436362802982\n",
      "Epoch 1927, Loss: 0.024218945764005184, Final Batch Loss: 0.004602205939590931\n",
      "Epoch 1928, Loss: 0.030542828142642975, Final Batch Loss: 0.010202039033174515\n",
      "Epoch 1929, Loss: 0.02471447316929698, Final Batch Loss: 0.02003391459584236\n",
      "Epoch 1930, Loss: 0.018076996318995953, Final Batch Loss: 0.0051788464188575745\n",
      "Epoch 1931, Loss: 0.017943715676665306, Final Batch Loss: 0.009117317385971546\n",
      "Epoch 1932, Loss: 0.017951275687664747, Final Batch Loss: 0.011731314472854137\n",
      "Epoch 1933, Loss: 0.025807682424783707, Final Batch Loss: 0.01870317943394184\n",
      "Epoch 1934, Loss: 0.0067003583535552025, Final Batch Loss: 0.0022835643030703068\n",
      "Epoch 1935, Loss: 0.015357628464698792, Final Batch Loss: 0.009818890132009983\n",
      "Epoch 1936, Loss: 0.023221636191010475, Final Batch Loss: 0.010010618716478348\n",
      "Epoch 1937, Loss: 0.01086825504899025, Final Batch Loss: 0.003436055965721607\n",
      "Epoch 1938, Loss: 0.01788425538688898, Final Batch Loss: 0.0059066517278552055\n",
      "Epoch 1939, Loss: 0.04108109092339873, Final Batch Loss: 0.00494523486122489\n",
      "Epoch 1940, Loss: 0.013126351870596409, Final Batch Loss: 0.005900138523429632\n",
      "Epoch 1941, Loss: 0.03594289952889085, Final Batch Loss: 0.0071753994561731815\n",
      "Epoch 1942, Loss: 0.03640699852257967, Final Batch Loss: 0.007789791561663151\n",
      "Epoch 1943, Loss: 0.020754060707986355, Final Batch Loss: 0.007324696518480778\n",
      "Epoch 1944, Loss: 0.04661352187395096, Final Batch Loss: 0.020537547767162323\n",
      "Epoch 1945, Loss: 0.04882614687085152, Final Batch Loss: 0.03889216482639313\n",
      "Epoch 1946, Loss: 0.03314646380022168, Final Batch Loss: 0.026719585061073303\n",
      "Epoch 1947, Loss: 0.022124849259853363, Final Batch Loss: 0.00454886257648468\n",
      "Epoch 1948, Loss: 0.058312488719820976, Final Batch Loss: 0.01793491654098034\n",
      "Epoch 1949, Loss: 0.04266706679482013, Final Batch Loss: 0.0009505172492936254\n",
      "Epoch 1950, Loss: 0.028655377216637135, Final Batch Loss: 0.0043931929394602776\n",
      "Epoch 1951, Loss: 0.04610927402973175, Final Batch Loss: 0.018382877111434937\n",
      "Epoch 1952, Loss: 0.03223961591720581, Final Batch Loss: 0.026711173355579376\n",
      "Epoch 1953, Loss: 0.03871779050678015, Final Batch Loss: 0.011540464125573635\n",
      "Epoch 1954, Loss: 0.15318666771054268, Final Batch Loss: 0.049952808767557144\n",
      "Epoch 1955, Loss: 0.025621936656534672, Final Batch Loss: 0.011143523268401623\n",
      "Epoch 1956, Loss: 0.016250527929514647, Final Batch Loss: 0.009904715232551098\n",
      "Epoch 1957, Loss: 0.03384396992623806, Final Batch Loss: 0.0174869392067194\n",
      "Epoch 1958, Loss: 0.01564088766463101, Final Batch Loss: 0.0032659631688147783\n",
      "Epoch 1959, Loss: 0.07515899091959, Final Batch Loss: 0.05442724749445915\n",
      "Epoch 1960, Loss: 0.019451770465821028, Final Batch Loss: 0.007018555421382189\n",
      "Epoch 1961, Loss: 0.03166711796075106, Final Batch Loss: 0.021058175712823868\n",
      "Epoch 1962, Loss: 0.06688687577843666, Final Batch Loss: 0.033315662294626236\n",
      "Epoch 1963, Loss: 0.0233768904581666, Final Batch Loss: 0.01586560159921646\n",
      "Epoch 1964, Loss: 0.02308097667992115, Final Batch Loss: 0.010780462995171547\n",
      "Epoch 1965, Loss: 0.02938327845185995, Final Batch Loss: 0.02027023211121559\n",
      "Epoch 1966, Loss: 0.015886629233136773, Final Batch Loss: 0.0024528515059500933\n",
      "Epoch 1967, Loss: 0.046901749446988106, Final Batch Loss: 0.02863672748208046\n",
      "Epoch 1968, Loss: 0.02179170399904251, Final Batch Loss: 0.009733371436595917\n",
      "Epoch 1969, Loss: 0.01688782498240471, Final Batch Loss: 0.012004259042441845\n",
      "Epoch 1970, Loss: 0.00993496016599238, Final Batch Loss: 0.0038754057604819536\n",
      "Epoch 1971, Loss: 0.07225293386727571, Final Batch Loss: 0.06122278794646263\n",
      "Epoch 1972, Loss: 0.013916331809014082, Final Batch Loss: 0.0020741489715874195\n",
      "Epoch 1973, Loss: 0.02565168309956789, Final Batch Loss: 0.011140303686261177\n",
      "Epoch 1974, Loss: 0.030454302206635475, Final Batch Loss: 0.007890867069363594\n",
      "Epoch 1975, Loss: 0.01951671252027154, Final Batch Loss: 0.0047029550187289715\n",
      "Epoch 1976, Loss: 0.016735625453293324, Final Batch Loss: 0.008036608807742596\n",
      "Epoch 1977, Loss: 0.03290094435214996, Final Batch Loss: 0.012451032176613808\n",
      "Epoch 1978, Loss: 0.04452127730473876, Final Batch Loss: 0.038631148636341095\n",
      "Epoch 1979, Loss: 0.03605133923701942, Final Batch Loss: 0.032290808856487274\n",
      "Epoch 1980, Loss: 0.010085051413625479, Final Batch Loss: 0.006643771659582853\n",
      "Epoch 1981, Loss: 0.05542621109634638, Final Batch Loss: 0.044383253902196884\n",
      "Epoch 1982, Loss: 0.02295741531997919, Final Batch Loss: 0.006776398979127407\n",
      "Epoch 1983, Loss: 0.020692105405032635, Final Batch Loss: 0.01309176255017519\n",
      "Epoch 1984, Loss: 0.041046781931072474, Final Batch Loss: 0.03377794846892357\n",
      "Epoch 1985, Loss: 0.015855703502893448, Final Batch Loss: 0.011383972130715847\n",
      "Epoch 1986, Loss: 0.030768383760005236, Final Batch Loss: 0.023261936381459236\n",
      "Epoch 1987, Loss: 0.023331426084041595, Final Batch Loss: 0.012490320950746536\n",
      "Epoch 1988, Loss: 0.05576847307384014, Final Batch Loss: 0.04500294476747513\n",
      "Epoch 1989, Loss: 0.012935237027704716, Final Batch Loss: 0.0015165787190198898\n",
      "Epoch 1990, Loss: 0.030562957748770714, Final Batch Loss: 0.00794956274330616\n",
      "Epoch 1991, Loss: 0.05674750730395317, Final Batch Loss: 0.016513865441083908\n",
      "Epoch 1992, Loss: 0.049323512241244316, Final Batch Loss: 0.03038410097360611\n",
      "Epoch 1993, Loss: 0.030804615933448076, Final Batch Loss: 0.003088500816375017\n",
      "Epoch 1994, Loss: 0.0406255591660738, Final Batch Loss: 0.025723695755004883\n",
      "Epoch 1995, Loss: 0.05322021909523755, Final Batch Loss: 0.05134056136012077\n",
      "Epoch 1996, Loss: 0.015077876159921288, Final Batch Loss: 0.0017230745870620012\n",
      "Epoch 1997, Loss: 0.036875998601317406, Final Batch Loss: 0.013544345274567604\n",
      "Epoch 1998, Loss: 0.10418031178414822, Final Batch Loss: 0.08126663416624069\n",
      "Epoch 1999, Loss: 0.027395239798352122, Final Batch Loss: 0.002158651826903224\n",
      "Epoch 2000, Loss: 0.05525738140568137, Final Batch Loss: 0.005921536590903997\n",
      "Epoch 2001, Loss: 0.045054830610752106, Final Batch Loss: 0.032923705875873566\n",
      "Epoch 2002, Loss: 0.035990296863019466, Final Batch Loss: 0.005975018255412579\n",
      "Epoch 2003, Loss: 0.013513969955965877, Final Batch Loss: 0.00250940746627748\n",
      "Epoch 2004, Loss: 0.058344325982034206, Final Batch Loss: 0.05106900632381439\n",
      "Epoch 2005, Loss: 0.007444670656695962, Final Batch Loss: 0.003394103841856122\n",
      "Epoch 2006, Loss: 0.010305101983249187, Final Batch Loss: 0.003461104352027178\n",
      "Epoch 2007, Loss: 0.03150760941207409, Final Batch Loss: 0.002021120861172676\n",
      "Epoch 2008, Loss: 0.03786515537649393, Final Batch Loss: 0.004107520915567875\n",
      "Epoch 2009, Loss: 0.06861826311796904, Final Batch Loss: 0.006252775900065899\n",
      "Epoch 2010, Loss: 0.02938014129176736, Final Batch Loss: 0.023284923285245895\n",
      "Epoch 2011, Loss: 0.02556280337739736, Final Batch Loss: 0.00144708261359483\n",
      "Epoch 2012, Loss: 0.050802621990442276, Final Batch Loss: 0.024956533685326576\n",
      "Epoch 2013, Loss: 0.021624519489705563, Final Batch Loss: 0.007885261438786983\n",
      "Epoch 2014, Loss: 0.013096301816403866, Final Batch Loss: 0.004050721414387226\n",
      "Epoch 2015, Loss: 0.055223270785063505, Final Batch Loss: 0.04774037376046181\n",
      "Epoch 2016, Loss: 0.03532673977315426, Final Batch Loss: 0.02036239393055439\n",
      "Epoch 2017, Loss: 0.04178351047448814, Final Batch Loss: 0.0028102833312004805\n",
      "Epoch 2018, Loss: 0.05874382331967354, Final Batch Loss: 0.03097684308886528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2019, Loss: 0.0284507405012846, Final Batch Loss: 0.022204391658306122\n",
      "Epoch 2020, Loss: 0.015937259420752525, Final Batch Loss: 0.007947164587676525\n",
      "Epoch 2021, Loss: 0.025428359396755695, Final Batch Loss: 0.01621248386800289\n",
      "Epoch 2022, Loss: 0.04787582717835903, Final Batch Loss: 0.01772020012140274\n",
      "Epoch 2023, Loss: 0.025607880204916, Final Batch Loss: 0.009459920227527618\n",
      "Epoch 2024, Loss: 0.03298963978886604, Final Batch Loss: 0.006119752302765846\n",
      "Epoch 2025, Loss: 0.04796924255788326, Final Batch Loss: 0.038818370550870895\n",
      "Epoch 2026, Loss: 0.007364198565483093, Final Batch Loss: 0.0019577499479055405\n",
      "Epoch 2027, Loss: 0.014160786755383015, Final Batch Loss: 0.004278869368135929\n",
      "Epoch 2028, Loss: 0.11218883097171783, Final Batch Loss: 0.06260168552398682\n",
      "Epoch 2029, Loss: 0.015371181070804596, Final Batch Loss: 0.0054399603977799416\n",
      "Epoch 2030, Loss: 0.050689032301306725, Final Batch Loss: 0.04716532304883003\n",
      "Epoch 2031, Loss: 0.030895239673554897, Final Batch Loss: 0.01570364274084568\n",
      "Epoch 2032, Loss: 0.01800601393915713, Final Batch Loss: 0.0011398142669349909\n",
      "Epoch 2033, Loss: 0.08140888717025518, Final Batch Loss: 0.07044452428817749\n",
      "Epoch 2034, Loss: 0.053645599633455276, Final Batch Loss: 0.041715048253536224\n",
      "Epoch 2035, Loss: 0.05221382575109601, Final Batch Loss: 0.04789912328124046\n",
      "Epoch 2036, Loss: 0.033530132845044136, Final Batch Loss: 0.016263840720057487\n",
      "Epoch 2037, Loss: 0.06571635603904724, Final Batch Loss: 0.04908391088247299\n",
      "Epoch 2038, Loss: 0.019474944099783897, Final Batch Loss: 0.011224991641938686\n",
      "Epoch 2039, Loss: 0.07968860119581223, Final Batch Loss: 0.05125845968723297\n",
      "Epoch 2040, Loss: 0.058547353371977806, Final Batch Loss: 0.020451342687010765\n",
      "Epoch 2041, Loss: 0.032181672751903534, Final Batch Loss: 0.010566404089331627\n",
      "Epoch 2042, Loss: 0.11130185052752495, Final Batch Loss: 0.06471258401870728\n",
      "Epoch 2043, Loss: 0.07709473837167025, Final Batch Loss: 0.009567511267960072\n",
      "Epoch 2044, Loss: 0.06524459179490805, Final Batch Loss: 0.05791669338941574\n",
      "Epoch 2045, Loss: 0.07286724913865328, Final Batch Loss: 0.014423263259232044\n",
      "Epoch 2046, Loss: 0.048645904287695885, Final Batch Loss: 0.01636245660483837\n",
      "Epoch 2047, Loss: 0.06998569145798683, Final Batch Loss: 0.0256483294069767\n",
      "Epoch 2048, Loss: 0.043595146387815475, Final Batch Loss: 0.02493642270565033\n",
      "Epoch 2049, Loss: 0.06674223579466343, Final Batch Loss: 0.025991356000304222\n",
      "Epoch 2050, Loss: 0.08117969240993261, Final Batch Loss: 0.06558427959680557\n",
      "Epoch 2051, Loss: 0.04103456065058708, Final Batch Loss: 0.0288064144551754\n",
      "Epoch 2052, Loss: 0.08460823819041252, Final Batch Loss: 0.06604069471359253\n",
      "Epoch 2053, Loss: 0.02712724171578884, Final Batch Loss: 0.018491080030798912\n",
      "Epoch 2054, Loss: 0.03990386985242367, Final Batch Loss: 0.015878135338425636\n",
      "Epoch 2055, Loss: 0.032688709907233715, Final Batch Loss: 0.017838237807154655\n",
      "Epoch 2056, Loss: 0.023694393690675497, Final Batch Loss: 0.007329586427658796\n",
      "Epoch 2057, Loss: 0.02158400695770979, Final Batch Loss: 0.01285103801637888\n",
      "Epoch 2058, Loss: 0.029187587089836597, Final Batch Loss: 0.01605033501982689\n",
      "Epoch 2059, Loss: 0.03155984356999397, Final Batch Loss: 0.020666049793362617\n",
      "Epoch 2060, Loss: 0.02243679389357567, Final Batch Loss: 0.002868957817554474\n",
      "Epoch 2061, Loss: 0.04606574960052967, Final Batch Loss: 0.018937833607196808\n",
      "Epoch 2062, Loss: 0.02287111710757017, Final Batch Loss: 0.01060620229691267\n",
      "Epoch 2063, Loss: 0.01980492379516363, Final Batch Loss: 0.008237803354859352\n",
      "Epoch 2064, Loss: 0.040562557987868786, Final Batch Loss: 0.027512069791555405\n",
      "Epoch 2065, Loss: 0.07734152115881443, Final Batch Loss: 0.016478070989251137\n",
      "Epoch 2066, Loss: 0.04620359465479851, Final Batch Loss: 0.01015196368098259\n",
      "Epoch 2067, Loss: 0.03794505726546049, Final Batch Loss: 0.014960483647882938\n",
      "Epoch 2068, Loss: 0.06933697685599327, Final Batch Loss: 0.05963984504342079\n",
      "Epoch 2069, Loss: 0.054162753745913506, Final Batch Loss: 0.0204812902957201\n",
      "Epoch 2070, Loss: 0.029601131565868855, Final Batch Loss: 0.020778272300958633\n",
      "Epoch 2071, Loss: 0.03858121857047081, Final Batch Loss: 0.009584985673427582\n",
      "Epoch 2072, Loss: 0.03846100717782974, Final Batch Loss: 0.03048553690314293\n",
      "Epoch 2073, Loss: 0.02505642455071211, Final Batch Loss: 0.00611045490950346\n",
      "Epoch 2074, Loss: 0.030479256063699722, Final Batch Loss: 0.01768477074801922\n",
      "Epoch 2075, Loss: 0.08097428642213345, Final Batch Loss: 0.01995067112147808\n",
      "Epoch 2076, Loss: 0.025441321544349194, Final Batch Loss: 0.009551935829222202\n",
      "Epoch 2077, Loss: 0.02767095621675253, Final Batch Loss: 0.012783324345946312\n",
      "Epoch 2078, Loss: 0.05565640889108181, Final Batch Loss: 0.041945695877075195\n",
      "Epoch 2079, Loss: 0.015840676613152027, Final Batch Loss: 0.009841087274253368\n",
      "Epoch 2080, Loss: 0.03490993846207857, Final Batch Loss: 0.006616939790546894\n",
      "Epoch 2081, Loss: 0.058142961002886295, Final Batch Loss: 0.04340801015496254\n",
      "Epoch 2082, Loss: 0.10568565083667636, Final Batch Loss: 0.09914456307888031\n",
      "Epoch 2083, Loss: 0.015999602619558573, Final Batch Loss: 0.004748270381242037\n",
      "Epoch 2084, Loss: 0.06963589787483215, Final Batch Loss: 0.03236747533082962\n",
      "Epoch 2085, Loss: 0.0363704776391387, Final Batch Loss: 0.025147898122668266\n",
      "Epoch 2086, Loss: 0.07530360016971827, Final Batch Loss: 0.0648106187582016\n",
      "Epoch 2087, Loss: 0.013350522611290216, Final Batch Loss: 0.007318240590393543\n",
      "Epoch 2088, Loss: 0.04772016126662493, Final Batch Loss: 0.03706766664981842\n",
      "Epoch 2089, Loss: 0.08859367948025465, Final Batch Loss: 0.0056993393227458\n",
      "Epoch 2090, Loss: 0.015036399010568857, Final Batch Loss: 0.009196766652166843\n",
      "Epoch 2091, Loss: 0.04960463475435972, Final Batch Loss: 0.0147017827257514\n",
      "Epoch 2092, Loss: 0.03468531742691994, Final Batch Loss: 0.02976967580616474\n",
      "Epoch 2093, Loss: 0.026140323840081692, Final Batch Loss: 0.012798146344721317\n",
      "Epoch 2094, Loss: 0.030131332576274872, Final Batch Loss: 0.01248442754149437\n",
      "Epoch 2095, Loss: 0.028825705870985985, Final Batch Loss: 0.01583973690867424\n",
      "Epoch 2096, Loss: 0.024272999726235867, Final Batch Loss: 0.015717871487140656\n",
      "Epoch 2097, Loss: 0.05169670656323433, Final Batch Loss: 0.003760218620300293\n",
      "Epoch 2098, Loss: 0.04705810593441129, Final Batch Loss: 0.0053133112378418446\n",
      "Epoch 2099, Loss: 0.020458608865737915, Final Batch Loss: 0.004015982151031494\n",
      "Epoch 2100, Loss: 0.03126554284244776, Final Batch Loss: 0.00658856425434351\n",
      "Epoch 2101, Loss: 0.04015709459781647, Final Batch Loss: 0.016606176272034645\n",
      "Epoch 2102, Loss: 0.022692936938256025, Final Batch Loss: 0.005661295261234045\n",
      "Epoch 2103, Loss: 0.017282947897911072, Final Batch Loss: 0.007191919721662998\n",
      "Epoch 2104, Loss: 0.038781557232141495, Final Batch Loss: 0.015588229522109032\n",
      "Epoch 2105, Loss: 0.010157619835808873, Final Batch Loss: 0.006401107180863619\n",
      "Epoch 2106, Loss: 0.011403643060475588, Final Batch Loss: 0.0068045551888644695\n",
      "Epoch 2107, Loss: 0.03299990575760603, Final Batch Loss: 0.013307933695614338\n",
      "Epoch 2108, Loss: 0.05005909176543355, Final Batch Loss: 0.046231091022491455\n",
      "Epoch 2109, Loss: 0.021517706103622913, Final Batch Loss: 0.015922026708722115\n",
      "Epoch 2110, Loss: 0.05946969985961914, Final Batch Loss: 0.03983749449253082\n",
      "Epoch 2111, Loss: 0.017937240190804005, Final Batch Loss: 0.009749040007591248\n",
      "Epoch 2112, Loss: 0.012730082497000694, Final Batch Loss: 0.009204443544149399\n",
      "Epoch 2113, Loss: 0.02923648152500391, Final Batch Loss: 0.009542605839669704\n",
      "Epoch 2114, Loss: 0.017112496308982372, Final Batch Loss: 0.01094802375882864\n",
      "Epoch 2115, Loss: 0.028170921839773655, Final Batch Loss: 0.019853806123137474\n",
      "Epoch 2116, Loss: 0.018107567448168993, Final Batch Loss: 0.012128743343055248\n",
      "Epoch 2117, Loss: 0.041232598945498466, Final Batch Loss: 0.02243909426033497\n",
      "Epoch 2118, Loss: 0.04825636325404048, Final Batch Loss: 0.040807366371154785\n",
      "Epoch 2119, Loss: 0.044962624087929726, Final Batch Loss: 0.019513417035341263\n",
      "Epoch 2120, Loss: 0.06751231290400028, Final Batch Loss: 0.027305813506245613\n",
      "Epoch 2121, Loss: 0.04366497602313757, Final Batch Loss: 0.0016892356798052788\n",
      "Epoch 2122, Loss: 0.021166174672544003, Final Batch Loss: 0.014954834245145321\n",
      "Epoch 2123, Loss: 0.023491259664297104, Final Batch Loss: 0.005297916010022163\n",
      "Epoch 2124, Loss: 0.032311840914189816, Final Batch Loss: 0.008191420696675777\n",
      "Epoch 2125, Loss: 0.01399808470159769, Final Batch Loss: 0.003942934796214104\n",
      "Epoch 2126, Loss: 0.030400135554373264, Final Batch Loss: 0.012953574769198895\n",
      "Epoch 2127, Loss: 0.05346323596313596, Final Batch Loss: 0.0022630286403000355\n",
      "Epoch 2128, Loss: 0.03479099413380027, Final Batch Loss: 0.005222569685429335\n",
      "Epoch 2129, Loss: 0.06705761142075062, Final Batch Loss: 0.015765896067023277\n",
      "Epoch 2130, Loss: 0.02687282022088766, Final Batch Loss: 0.008909224532544613\n",
      "Epoch 2131, Loss: 0.018515216186642647, Final Batch Loss: 0.013199139386415482\n",
      "Epoch 2132, Loss: 0.020443267188966274, Final Batch Loss: 0.014881701208651066\n",
      "Epoch 2133, Loss: 0.03403555788099766, Final Batch Loss: 0.015711061656475067\n",
      "Epoch 2134, Loss: 0.01556869875639677, Final Batch Loss: 0.008734511211514473\n",
      "Epoch 2135, Loss: 0.0566105842590332, Final Batch Loss: 0.009237628430128098\n",
      "Epoch 2136, Loss: 0.014051975682377815, Final Batch Loss: 0.009342707693576813\n",
      "Epoch 2137, Loss: 0.013540588319301605, Final Batch Loss: 0.009604356251657009\n",
      "Epoch 2138, Loss: 0.03980202600359917, Final Batch Loss: 0.012155191972851753\n",
      "Epoch 2139, Loss: 0.027660603169351816, Final Batch Loss: 0.021491309627890587\n",
      "Epoch 2140, Loss: 0.017705049365758896, Final Batch Loss: 0.0066886181011796\n",
      "Epoch 2141, Loss: 0.030610315036028624, Final Batch Loss: 0.005011941771954298\n",
      "Epoch 2142, Loss: 0.011468194425106049, Final Batch Loss: 0.005448419600725174\n",
      "Epoch 2143, Loss: 0.025926433969289064, Final Batch Loss: 0.022235777229070663\n",
      "Epoch 2144, Loss: 0.08038498647511005, Final Batch Loss: 0.07228994369506836\n",
      "Epoch 2145, Loss: 0.015188735909759998, Final Batch Loss: 0.006163269281387329\n",
      "Epoch 2146, Loss: 0.017290416173636913, Final Batch Loss: 0.009049353189766407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2147, Loss: 0.014271585270762444, Final Batch Loss: 0.004875083453953266\n",
      "Epoch 2148, Loss: 0.0486700851470232, Final Batch Loss: 0.03719307854771614\n",
      "Epoch 2149, Loss: 0.036192118655890226, Final Batch Loss: 0.004717882256954908\n",
      "Epoch 2150, Loss: 0.020587323233485222, Final Batch Loss: 0.00821656547486782\n",
      "Epoch 2151, Loss: 0.03537319228053093, Final Batch Loss: 0.026870697736740112\n",
      "Epoch 2152, Loss: 0.0060571604408323765, Final Batch Loss: 0.003712406847625971\n",
      "Epoch 2153, Loss: 0.03702344186604023, Final Batch Loss: 0.01933659240603447\n",
      "Epoch 2154, Loss: 0.010118005331605673, Final Batch Loss: 0.00451565021649003\n",
      "Epoch 2155, Loss: 0.035856613889336586, Final Batch Loss: 0.019140759482979774\n",
      "Epoch 2156, Loss: 0.08431276679039001, Final Batch Loss: 0.04695630073547363\n",
      "Epoch 2157, Loss: 0.024005189072340727, Final Batch Loss: 0.016302520409226418\n",
      "Epoch 2158, Loss: 0.01643111417070031, Final Batch Loss: 0.012398992665112019\n",
      "Epoch 2159, Loss: 0.014571959851309657, Final Batch Loss: 0.01281209196895361\n",
      "Epoch 2160, Loss: 0.03640747629106045, Final Batch Loss: 0.013924028724431992\n",
      "Epoch 2161, Loss: 0.01757140690460801, Final Batch Loss: 0.006196531932801008\n",
      "Epoch 2162, Loss: 0.017040207283571362, Final Batch Loss: 0.002020688960328698\n",
      "Epoch 2163, Loss: 0.022259941790252924, Final Batch Loss: 0.0072119892574846745\n",
      "Epoch 2164, Loss: 0.052675706800073385, Final Batch Loss: 0.00426834961399436\n",
      "Epoch 2165, Loss: 0.04351788735948503, Final Batch Loss: 0.04031173512339592\n",
      "Epoch 2166, Loss: 0.01542355166748166, Final Batch Loss: 0.009833674877882004\n",
      "Epoch 2167, Loss: 0.007652631029486656, Final Batch Loss: 0.003855458926409483\n",
      "Epoch 2168, Loss: 0.06936675868928432, Final Batch Loss: 0.024985110387206078\n",
      "Epoch 2169, Loss: 0.013623822946101427, Final Batch Loss: 0.011658736504614353\n",
      "Epoch 2170, Loss: 0.0473674014210701, Final Batch Loss: 0.030355926603078842\n",
      "Epoch 2171, Loss: 0.017142565920948982, Final Batch Loss: 0.00824226625263691\n",
      "Epoch 2172, Loss: 0.04970096983015537, Final Batch Loss: 0.01589246653020382\n",
      "Epoch 2173, Loss: 0.04933198355138302, Final Batch Loss: 0.008215395733714104\n",
      "Epoch 2174, Loss: 0.011363124940544367, Final Batch Loss: 0.0032007615081965923\n",
      "Epoch 2175, Loss: 0.011027536354959011, Final Batch Loss: 0.004949921742081642\n",
      "Epoch 2176, Loss: 0.05279724672436714, Final Batch Loss: 0.006097782403230667\n",
      "Epoch 2177, Loss: 0.015508446842432022, Final Batch Loss: 0.005462859757244587\n",
      "Epoch 2178, Loss: 0.009889595210552216, Final Batch Loss: 0.004547037649899721\n",
      "Epoch 2179, Loss: 0.009114038664847612, Final Batch Loss: 0.0067531391978263855\n",
      "Epoch 2180, Loss: 0.006134734256193042, Final Batch Loss: 0.0024048148188740015\n",
      "Epoch 2181, Loss: 0.030264954082667828, Final Batch Loss: 0.003898351453244686\n",
      "Epoch 2182, Loss: 0.011603195685893297, Final Batch Loss: 0.003630054648965597\n",
      "Epoch 2183, Loss: 0.012744087725877762, Final Batch Loss: 0.00782226212322712\n",
      "Epoch 2184, Loss: 0.008626020047813654, Final Batch Loss: 0.004449629224836826\n",
      "Epoch 2185, Loss: 0.0054225672502070665, Final Batch Loss: 0.002272354206070304\n",
      "Epoch 2186, Loss: 0.013218856882303953, Final Batch Loss: 0.003752694930881262\n",
      "Epoch 2187, Loss: 0.038965363055467606, Final Batch Loss: 0.00922919437289238\n",
      "Epoch 2188, Loss: 0.1794787049293518, Final Batch Loss: 0.04209335148334503\n",
      "Epoch 2189, Loss: 0.012607801705598831, Final Batch Loss: 0.0061838384717702866\n",
      "Epoch 2190, Loss: 0.007488907780498266, Final Batch Loss: 0.003813635790720582\n",
      "Epoch 2191, Loss: 0.0559341125190258, Final Batch Loss: 0.0288764089345932\n",
      "Epoch 2192, Loss: 0.04153232462704182, Final Batch Loss: 0.01607373356819153\n",
      "Epoch 2193, Loss: 0.09328413289040327, Final Batch Loss: 0.0815400704741478\n",
      "Epoch 2194, Loss: 0.03455102629959583, Final Batch Loss: 0.02714996412396431\n",
      "Epoch 2195, Loss: 0.0304288980551064, Final Batch Loss: 0.024261366575956345\n",
      "Epoch 2196, Loss: 0.07127674482762814, Final Batch Loss: 0.04950661212205887\n",
      "Epoch 2197, Loss: 0.0694217486307025, Final Batch Loss: 0.005163694731891155\n",
      "Epoch 2198, Loss: 0.06962687335908413, Final Batch Loss: 0.011478034779429436\n",
      "Epoch 2199, Loss: 0.025144072948023677, Final Batch Loss: 0.002626158995553851\n",
      "Epoch 2200, Loss: 0.026557758450508118, Final Batch Loss: 0.01844842918217182\n",
      "Epoch 2201, Loss: 0.028552953153848648, Final Batch Loss: 0.015117494389414787\n",
      "Epoch 2202, Loss: 0.02968158107250929, Final Batch Loss: 0.0196677315980196\n",
      "Epoch 2203, Loss: 0.04948183801025152, Final Batch Loss: 0.038114018738269806\n",
      "Epoch 2204, Loss: 0.04082122910767794, Final Batch Loss: 0.03168216720223427\n",
      "Epoch 2205, Loss: 0.010134661570191383, Final Batch Loss: 0.007950959727168083\n",
      "Epoch 2206, Loss: 0.18961694091558456, Final Batch Loss: 0.12240830063819885\n",
      "Epoch 2207, Loss: 0.05109893251210451, Final Batch Loss: 0.039730895310640335\n",
      "Epoch 2208, Loss: 0.24435981549322605, Final Batch Loss: 0.21974393725395203\n",
      "Epoch 2209, Loss: 0.027134004049003124, Final Batch Loss: 0.015210789628326893\n",
      "Epoch 2210, Loss: 0.02559658605605364, Final Batch Loss: 0.015838874503970146\n",
      "Epoch 2211, Loss: 0.04795314744114876, Final Batch Loss: 0.012813426554203033\n",
      "Epoch 2212, Loss: 0.051859404891729355, Final Batch Loss: 0.019707344472408295\n",
      "Epoch 2213, Loss: 0.03962016524747014, Final Batch Loss: 0.0030480590648949146\n",
      "Epoch 2214, Loss: 0.023846462136134505, Final Batch Loss: 0.0024427955504506826\n",
      "Epoch 2215, Loss: 0.05283421138301492, Final Batch Loss: 0.0033750073052942753\n",
      "Epoch 2216, Loss: 0.014630036428570747, Final Batch Loss: 0.004134410060942173\n",
      "Epoch 2217, Loss: 0.03578421752899885, Final Batch Loss: 0.020463382825255394\n",
      "Epoch 2218, Loss: 0.03316908422857523, Final Batch Loss: 0.004566916264593601\n",
      "Epoch 2219, Loss: 0.059393045492470264, Final Batch Loss: 0.00675704050809145\n",
      "Epoch 2220, Loss: 0.01922102179378271, Final Batch Loss: 0.009667790494859219\n",
      "Epoch 2221, Loss: 0.06614761706441641, Final Batch Loss: 0.013512159697711468\n",
      "Epoch 2222, Loss: 0.048152157105505466, Final Batch Loss: 0.011673209257423878\n",
      "Epoch 2223, Loss: 0.018863866571336985, Final Batch Loss: 0.011520089581608772\n",
      "Epoch 2224, Loss: 0.11361043713986874, Final Batch Loss: 0.0851677879691124\n",
      "Epoch 2225, Loss: 0.02915577730163932, Final Batch Loss: 0.006372376810759306\n",
      "Epoch 2226, Loss: 0.027872759383171797, Final Batch Loss: 0.02302083931863308\n",
      "Epoch 2227, Loss: 0.04498274810612202, Final Batch Loss: 0.038463082164525986\n",
      "Epoch 2228, Loss: 0.020133893936872482, Final Batch Loss: 0.01174484845250845\n",
      "Epoch 2229, Loss: 0.11516540218144655, Final Batch Loss: 0.10608621686697006\n",
      "Epoch 2230, Loss: 0.024687490426003933, Final Batch Loss: 0.012180566787719727\n",
      "Epoch 2231, Loss: 0.020186586305499077, Final Batch Loss: 0.012373030185699463\n",
      "Epoch 2232, Loss: 0.024114140309393406, Final Batch Loss: 0.007504592649638653\n",
      "Epoch 2233, Loss: 0.032764857634902, Final Batch Loss: 0.017969073727726936\n",
      "Epoch 2234, Loss: 0.04295525047928095, Final Batch Loss: 0.04012927785515785\n",
      "Epoch 2235, Loss: 0.01873940695077181, Final Batch Loss: 0.008417156524956226\n",
      "Epoch 2236, Loss: 0.006771982181817293, Final Batch Loss: 0.004354372154921293\n",
      "Epoch 2237, Loss: 0.040770494379103184, Final Batch Loss: 0.026219448074698448\n",
      "Epoch 2238, Loss: 0.011313613969832659, Final Batch Loss: 0.004103096667677164\n",
      "Epoch 2239, Loss: 0.014622397720813751, Final Batch Loss: 0.0076434980146586895\n",
      "Epoch 2240, Loss: 0.009000264341011643, Final Batch Loss: 0.0063504609279334545\n",
      "Epoch 2241, Loss: 0.01106452033855021, Final Batch Loss: 0.00870038103312254\n",
      "Epoch 2242, Loss: 0.13922253251075745, Final Batch Loss: 0.024308383464813232\n",
      "Epoch 2243, Loss: 0.011327153537422419, Final Batch Loss: 0.005455282051116228\n",
      "Epoch 2244, Loss: 0.015854128869250417, Final Batch Loss: 0.0022201056126505136\n",
      "Epoch 2245, Loss: 0.029564151307567954, Final Batch Loss: 0.026120664551854134\n",
      "Epoch 2246, Loss: 0.10088130459189415, Final Batch Loss: 0.08288770914077759\n",
      "Epoch 2247, Loss: 0.027296677231788635, Final Batch Loss: 0.015030568465590477\n",
      "Epoch 2248, Loss: 0.05072200112044811, Final Batch Loss: 0.021840140223503113\n",
      "Epoch 2249, Loss: 0.031713759526610374, Final Batch Loss: 0.0049438513815402985\n",
      "Epoch 2250, Loss: 0.010903350543230772, Final Batch Loss: 0.0043207318522036076\n",
      "Epoch 2251, Loss: 0.016433632466942072, Final Batch Loss: 0.003766376059502363\n",
      "Epoch 2252, Loss: 0.01965121296234429, Final Batch Loss: 0.0026573457289487123\n",
      "Epoch 2253, Loss: 0.05978842917829752, Final Batch Loss: 0.011194177903234959\n",
      "Epoch 2254, Loss: 0.014482737984508276, Final Batch Loss: 0.010735206305980682\n",
      "Epoch 2255, Loss: 0.02032649889588356, Final Batch Loss: 0.005684071220457554\n",
      "Epoch 2256, Loss: 0.017719066701829433, Final Batch Loss: 0.009182645939290524\n",
      "Epoch 2257, Loss: 0.04098434653133154, Final Batch Loss: 0.029875479638576508\n",
      "Epoch 2258, Loss: 0.021435588598251343, Final Batch Loss: 0.008195506408810616\n",
      "Epoch 2259, Loss: 0.04187015164643526, Final Batch Loss: 0.01019964087754488\n",
      "Epoch 2260, Loss: 0.01695502595975995, Final Batch Loss: 0.004838220309466124\n",
      "Epoch 2261, Loss: 0.0486703971400857, Final Batch Loss: 0.010160540230572224\n",
      "Epoch 2262, Loss: 0.023267017677426338, Final Batch Loss: 0.0113434549421072\n",
      "Epoch 2263, Loss: 0.02073004050180316, Final Batch Loss: 0.012984075583517551\n",
      "Epoch 2264, Loss: 0.014617946464568377, Final Batch Loss: 0.00991940125823021\n",
      "Epoch 2265, Loss: 0.03668480692431331, Final Batch Loss: 0.03251243382692337\n",
      "Epoch 2266, Loss: 0.011658093426376581, Final Batch Loss: 0.0033303131349384785\n",
      "Epoch 2267, Loss: 0.01725076581351459, Final Batch Loss: 0.014075370505452156\n",
      "Epoch 2268, Loss: 0.015416983049362898, Final Batch Loss: 0.011056195944547653\n",
      "Epoch 2269, Loss: 0.026272693648934364, Final Batch Loss: 0.011175164021551609\n",
      "Epoch 2270, Loss: 0.026494660414755344, Final Batch Loss: 0.015583216212689877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2271, Loss: 0.03243208862841129, Final Batch Loss: 0.004399687051773071\n",
      "Epoch 2272, Loss: 0.008515960071235895, Final Batch Loss: 0.004106258507817984\n",
      "Epoch 2273, Loss: 0.005507678491994739, Final Batch Loss: 0.0020602482836693525\n",
      "Epoch 2274, Loss: 0.014659688575193286, Final Batch Loss: 0.003471838077530265\n",
      "Epoch 2275, Loss: 0.10941917821764946, Final Batch Loss: 0.07377471029758453\n",
      "Epoch 2276, Loss: 0.05322407092899084, Final Batch Loss: 0.0040358370169997215\n",
      "Epoch 2277, Loss: 0.040747469291090965, Final Batch Loss: 0.014834152534604073\n",
      "Epoch 2278, Loss: 0.019771067425608635, Final Batch Loss: 0.009539663791656494\n",
      "Epoch 2279, Loss: 0.023437735624611378, Final Batch Loss: 0.0075552696362137794\n",
      "Epoch 2280, Loss: 0.07843462377786636, Final Batch Loss: 0.039756350219249725\n",
      "Epoch 2281, Loss: 0.043585434556007385, Final Batch Loss: 0.015891503542661667\n",
      "Epoch 2282, Loss: 0.03914947924204171, Final Batch Loss: 0.0020280976314097643\n",
      "Epoch 2283, Loss: 0.011626264080405235, Final Batch Loss: 0.005454406142234802\n",
      "Epoch 2284, Loss: 0.015497284475713968, Final Batch Loss: 0.006177040282636881\n",
      "Epoch 2285, Loss: 0.02037227153778076, Final Batch Loss: 0.010197192430496216\n",
      "Epoch 2286, Loss: 0.020255940034985542, Final Batch Loss: 0.007356193847954273\n",
      "Epoch 2287, Loss: 0.029504576697945595, Final Batch Loss: 0.01266508363187313\n",
      "Epoch 2288, Loss: 0.025928191374987364, Final Batch Loss: 0.018706193193793297\n",
      "Epoch 2289, Loss: 0.012465644162148237, Final Batch Loss: 0.004331317264586687\n",
      "Epoch 2290, Loss: 0.029117457568645477, Final Batch Loss: 0.01591862179338932\n",
      "Epoch 2291, Loss: 0.016094877384603024, Final Batch Loss: 0.003786236047744751\n",
      "Epoch 2292, Loss: 0.018194228410720825, Final Batch Loss: 0.004949980415403843\n",
      "Epoch 2293, Loss: 0.023084894753992558, Final Batch Loss: 0.017003251239657402\n",
      "Epoch 2294, Loss: 0.035936794243752956, Final Batch Loss: 0.007458346895873547\n",
      "Epoch 2295, Loss: 0.032467583660036325, Final Batch Loss: 0.005044710356742144\n",
      "Epoch 2296, Loss: 0.015301637817174196, Final Batch Loss: 0.009535052813589573\n",
      "Epoch 2297, Loss: 0.008427547989413142, Final Batch Loss: 0.0023329018149524927\n",
      "Epoch 2298, Loss: 0.01881427224725485, Final Batch Loss: 0.010053576901555061\n",
      "Epoch 2299, Loss: 0.015360395656898618, Final Batch Loss: 0.001720907399430871\n",
      "Epoch 2300, Loss: 0.014069966971874237, Final Batch Loss: 0.006862714886665344\n",
      "Epoch 2301, Loss: 0.020156231708824635, Final Batch Loss: 0.015089877881109715\n",
      "Epoch 2302, Loss: 0.11135046556591988, Final Batch Loss: 0.07600699365139008\n",
      "Epoch 2303, Loss: 0.08382914401590824, Final Batch Loss: 0.07310628145933151\n",
      "Epoch 2304, Loss: 0.09397041681222618, Final Batch Loss: 0.0032453674357384443\n",
      "Epoch 2305, Loss: 0.038436533883214, Final Batch Loss: 0.026583345606923103\n",
      "Epoch 2306, Loss: 0.03547621984034777, Final Batch Loss: 0.02682202309370041\n",
      "Epoch 2307, Loss: 0.04004940018057823, Final Batch Loss: 0.012722590938210487\n",
      "Epoch 2308, Loss: 0.029733311384916306, Final Batch Loss: 0.009816017001867294\n",
      "Epoch 2309, Loss: 0.08171362616121769, Final Batch Loss: 0.03055758588016033\n",
      "Epoch 2310, Loss: 0.059655312448740005, Final Batch Loss: 0.03257003799080849\n",
      "Epoch 2311, Loss: 0.02650634292513132, Final Batch Loss: 0.009030736051499844\n",
      "Epoch 2312, Loss: 0.026098341681063175, Final Batch Loss: 0.0174443107098341\n",
      "Epoch 2313, Loss: 0.04982187319546938, Final Batch Loss: 0.03800920769572258\n",
      "Epoch 2314, Loss: 0.06925442442297935, Final Batch Loss: 0.05976590886712074\n",
      "Epoch 2315, Loss: 0.03281929111108184, Final Batch Loss: 0.007645524572581053\n",
      "Epoch 2316, Loss: 0.027178763411939144, Final Batch Loss: 0.004301597364246845\n",
      "Epoch 2317, Loss: 0.07511873356997967, Final Batch Loss: 0.01967920921742916\n",
      "Epoch 2318, Loss: 0.03214931860566139, Final Batch Loss: 0.026689069345593452\n",
      "Epoch 2319, Loss: 0.025127788074314594, Final Batch Loss: 0.008198359049856663\n",
      "Epoch 2320, Loss: 0.040161837823688984, Final Batch Loss: 0.03736050799489021\n",
      "Epoch 2321, Loss: 0.01581344660371542, Final Batch Loss: 0.004569274373352528\n",
      "Epoch 2322, Loss: 0.04950305912643671, Final Batch Loss: 0.03908825293183327\n",
      "Epoch 2323, Loss: 0.03409661678597331, Final Batch Loss: 0.00631593307480216\n",
      "Epoch 2324, Loss: 0.03668336849659681, Final Batch Loss: 0.03307201340794563\n",
      "Epoch 2325, Loss: 0.012747701490297914, Final Batch Loss: 0.003734668018296361\n",
      "Epoch 2326, Loss: 0.05858331359922886, Final Batch Loss: 0.04821131378412247\n",
      "Epoch 2327, Loss: 0.029336819425225258, Final Batch Loss: 0.02132370136678219\n",
      "Epoch 2328, Loss: 0.011734278872609138, Final Batch Loss: 0.0055312542244791985\n",
      "Epoch 2329, Loss: 0.010437042452394962, Final Batch Loss: 0.0038900449872016907\n",
      "Epoch 2330, Loss: 0.03158396761864424, Final Batch Loss: 0.0072134388610720634\n",
      "Epoch 2331, Loss: 0.057017224840819836, Final Batch Loss: 0.047439251095056534\n",
      "Epoch 2332, Loss: 0.032001408748328686, Final Batch Loss: 0.011019536294043064\n",
      "Epoch 2333, Loss: 0.013241108390502632, Final Batch Loss: 0.0013444869546219707\n",
      "Epoch 2334, Loss: 0.012950058095157146, Final Batch Loss: 0.0028765862807631493\n",
      "Epoch 2335, Loss: 0.008993407944217324, Final Batch Loss: 0.002744851866737008\n",
      "Epoch 2336, Loss: 0.020483065396547318, Final Batch Loss: 0.00807131640613079\n",
      "Epoch 2337, Loss: 0.03372072312049568, Final Batch Loss: 0.003109334735199809\n",
      "Epoch 2338, Loss: 0.019941823557019234, Final Batch Loss: 0.00904359295964241\n",
      "Epoch 2339, Loss: 0.0068069444969296455, Final Batch Loss: 0.001507916022092104\n",
      "Epoch 2340, Loss: 0.03720416850410402, Final Batch Loss: 0.0038066317792981863\n",
      "Epoch 2341, Loss: 0.016683710739016533, Final Batch Loss: 0.008029746823012829\n",
      "Epoch 2342, Loss: 0.011464460752904415, Final Batch Loss: 0.006590236909687519\n",
      "Epoch 2343, Loss: 0.03612767392769456, Final Batch Loss: 0.007082961965352297\n",
      "Epoch 2344, Loss: 0.021689340006560087, Final Batch Loss: 0.007799672428518534\n",
      "Epoch 2345, Loss: 0.05300522781908512, Final Batch Loss: 0.029933886602520943\n",
      "Epoch 2346, Loss: 0.06513931415975094, Final Batch Loss: 0.04029957205057144\n",
      "Epoch 2347, Loss: 0.03804633393883705, Final Batch Loss: 0.027856925502419472\n",
      "Epoch 2348, Loss: 0.04662456177175045, Final Batch Loss: 0.01574684865772724\n",
      "Epoch 2349, Loss: 0.04724201373755932, Final Batch Loss: 0.03150268271565437\n",
      "Epoch 2350, Loss: 0.040749967098236084, Final Batch Loss: 0.021507006138563156\n",
      "Epoch 2351, Loss: 0.053057110868394375, Final Batch Loss: 0.03794549033045769\n",
      "Epoch 2352, Loss: 0.03962022066116333, Final Batch Loss: 0.029881121590733528\n",
      "Epoch 2353, Loss: 0.020782112376764417, Final Batch Loss: 0.0037017364520579576\n",
      "Epoch 2354, Loss: 0.03085231687873602, Final Batch Loss: 0.010281744413077831\n",
      "Epoch 2355, Loss: 0.05195716582238674, Final Batch Loss: 0.03588312864303589\n",
      "Epoch 2356, Loss: 0.02011732943356037, Final Batch Loss: 0.011042443104088306\n",
      "Epoch 2357, Loss: 0.009898339165374637, Final Batch Loss: 0.0015603990759700537\n",
      "Epoch 2358, Loss: 0.020782385487109423, Final Batch Loss: 0.006027068477123976\n",
      "Epoch 2359, Loss: 0.019999164156615734, Final Batch Loss: 0.006891836412250996\n",
      "Epoch 2360, Loss: 0.053039200603961945, Final Batch Loss: 0.036683473736047745\n",
      "Epoch 2361, Loss: 0.022144899237900972, Final Batch Loss: 0.006646294612437487\n",
      "Epoch 2362, Loss: 0.01569845201447606, Final Batch Loss: 0.0056586903519928455\n",
      "Epoch 2363, Loss: 0.0398401936981827, Final Batch Loss: 0.0030720627401024103\n",
      "Epoch 2364, Loss: 0.018351304344832897, Final Batch Loss: 0.006606806069612503\n",
      "Epoch 2365, Loss: 0.02489834208972752, Final Batch Loss: 0.021332379430532455\n",
      "Epoch 2366, Loss: 0.025428735185414553, Final Batch Loss: 0.019984567537903786\n",
      "Epoch 2367, Loss: 0.007753078592941165, Final Batch Loss: 0.0049273730255663395\n",
      "Epoch 2368, Loss: 0.03458970319479704, Final Batch Loss: 0.02068563923239708\n",
      "Epoch 2369, Loss: 0.011228265706449747, Final Batch Loss: 0.004034840036183596\n",
      "Epoch 2370, Loss: 0.02077419264242053, Final Batch Loss: 0.007640657480806112\n",
      "Epoch 2371, Loss: 0.045617906376719475, Final Batch Loss: 0.013305464759469032\n",
      "Epoch 2372, Loss: 0.030057920841500163, Final Batch Loss: 0.0023006058763712645\n",
      "Epoch 2373, Loss: 0.015878534875810146, Final Batch Loss: 0.004743823781609535\n",
      "Epoch 2374, Loss: 0.04839903488755226, Final Batch Loss: 0.03796444460749626\n",
      "Epoch 2375, Loss: 0.026017255149781704, Final Batch Loss: 0.009359343908727169\n",
      "Epoch 2376, Loss: 0.047343287616968155, Final Batch Loss: 0.009915217757225037\n",
      "Epoch 2377, Loss: 0.034910351037979126, Final Batch Loss: 0.03050927072763443\n",
      "Epoch 2378, Loss: 0.011517437174916267, Final Batch Loss: 0.0041937981732189655\n",
      "Epoch 2379, Loss: 0.01809066254645586, Final Batch Loss: 0.01217170525342226\n",
      "Epoch 2380, Loss: 0.06334676872938871, Final Batch Loss: 0.054184891283512115\n",
      "Epoch 2381, Loss: 0.01284292945638299, Final Batch Loss: 0.005962153431028128\n",
      "Epoch 2382, Loss: 0.03529879450798035, Final Batch Loss: 0.03133111447095871\n",
      "Epoch 2383, Loss: 0.009307614993304014, Final Batch Loss: 0.005194601137191057\n",
      "Epoch 2384, Loss: 0.012970211915671825, Final Batch Loss: 0.005051653832197189\n",
      "Epoch 2385, Loss: 0.008723825216293335, Final Batch Loss: 0.0021629012189805508\n",
      "Epoch 2386, Loss: 0.014007248915731907, Final Batch Loss: 0.007572551723569632\n",
      "Epoch 2387, Loss: 0.05334648583084345, Final Batch Loss: 0.009746436960995197\n",
      "Epoch 2388, Loss: 0.008974086144007742, Final Batch Loss: 0.0019297675462439656\n",
      "Epoch 2389, Loss: 0.04561551404185593, Final Batch Loss: 0.003732160897925496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2390, Loss: 0.0147999357432127, Final Batch Loss: 0.010970587842166424\n",
      "Epoch 2391, Loss: 0.12567902356386185, Final Batch Loss: 0.11245311051607132\n",
      "Epoch 2392, Loss: 0.03370524477213621, Final Batch Loss: 0.014255479909479618\n",
      "Epoch 2393, Loss: 0.01199912279844284, Final Batch Loss: 0.007127024699002504\n",
      "Epoch 2394, Loss: 0.024584560305811465, Final Batch Loss: 0.001807641820050776\n",
      "Epoch 2395, Loss: 0.028414489701390266, Final Batch Loss: 0.010971209034323692\n",
      "Epoch 2396, Loss: 0.01572953024879098, Final Batch Loss: 0.004942378494888544\n",
      "Epoch 2397, Loss: 0.014369498006999493, Final Batch Loss: 0.009400849230587482\n",
      "Epoch 2398, Loss: 0.028226539492607117, Final Batch Loss: 0.008339488878846169\n",
      "Epoch 2399, Loss: 0.029278175439685583, Final Batch Loss: 0.004994246643036604\n",
      "Epoch 2400, Loss: 0.036518506705760956, Final Batch Loss: 0.01181795448064804\n",
      "Epoch 2401, Loss: 0.026864144019782543, Final Batch Loss: 0.008270503021776676\n",
      "Epoch 2402, Loss: 0.007520237704738975, Final Batch Loss: 0.0025763281155377626\n",
      "Epoch 2403, Loss: 0.02514342311769724, Final Batch Loss: 0.0216623917222023\n",
      "Epoch 2404, Loss: 0.026601085904985666, Final Batch Loss: 0.021131182089447975\n",
      "Epoch 2405, Loss: 0.04642191529273987, Final Batch Loss: 0.01785028912127018\n",
      "Epoch 2406, Loss: 0.016911957878619432, Final Batch Loss: 0.012114744633436203\n",
      "Epoch 2407, Loss: 0.021961908787488937, Final Batch Loss: 0.012612825259566307\n",
      "Epoch 2408, Loss: 0.08175269700586796, Final Batch Loss: 0.0593886524438858\n",
      "Epoch 2409, Loss: 0.022790118586272, Final Batch Loss: 0.01681196503341198\n",
      "Epoch 2410, Loss: 0.01179240585770458, Final Batch Loss: 0.0018434444209560752\n",
      "Epoch 2411, Loss: 0.02382748667150736, Final Batch Loss: 0.007920782081782818\n",
      "Epoch 2412, Loss: 0.011416974943131208, Final Batch Loss: 0.0053873201832175255\n",
      "Epoch 2413, Loss: 0.011899556498974562, Final Batch Loss: 0.004304546397179365\n",
      "Epoch 2414, Loss: 0.033680148888379335, Final Batch Loss: 0.026154451072216034\n",
      "Epoch 2415, Loss: 0.044899238273501396, Final Batch Loss: 0.02820095233619213\n",
      "Epoch 2416, Loss: 0.044568958692252636, Final Batch Loss: 0.013640736229717731\n",
      "Epoch 2417, Loss: 0.028886819258332253, Final Batch Loss: 0.01722990907728672\n",
      "Epoch 2418, Loss: 0.03797059739008546, Final Batch Loss: 0.00687434384599328\n",
      "Epoch 2419, Loss: 0.01458209054544568, Final Batch Loss: 0.007338419556617737\n",
      "Epoch 2420, Loss: 0.018252046313136816, Final Batch Loss: 0.01061947364360094\n",
      "Epoch 2421, Loss: 0.013442542403936386, Final Batch Loss: 0.0036848271265625954\n",
      "Epoch 2422, Loss: 0.007712831720709801, Final Batch Loss: 0.002539968118071556\n",
      "Epoch 2423, Loss: 0.012967342045158148, Final Batch Loss: 0.00531991058960557\n",
      "Epoch 2424, Loss: 0.030681231059134007, Final Batch Loss: 0.02313975803554058\n",
      "Epoch 2425, Loss: 0.027318090200424194, Final Batch Loss: 0.02173537202179432\n",
      "Epoch 2426, Loss: 0.03289711009711027, Final Batch Loss: 0.025112658739089966\n",
      "Epoch 2427, Loss: 0.03310126485303044, Final Batch Loss: 0.02885596454143524\n",
      "Epoch 2428, Loss: 0.04157560504972935, Final Batch Loss: 0.03169434145092964\n",
      "Epoch 2429, Loss: 0.01773105375468731, Final Batch Loss: 0.009233967401087284\n",
      "Epoch 2430, Loss: 0.014617964625358582, Final Batch Loss: 0.002859720028936863\n",
      "Epoch 2431, Loss: 0.011921587865799665, Final Batch Loss: 0.002730123233050108\n",
      "Epoch 2432, Loss: 0.016076629981398582, Final Batch Loss: 0.006827824749052525\n",
      "Epoch 2433, Loss: 0.01360088400542736, Final Batch Loss: 0.005137089639902115\n",
      "Epoch 2434, Loss: 0.010613450373057276, Final Batch Loss: 0.0007946226396597922\n",
      "Epoch 2435, Loss: 0.02475735265761614, Final Batch Loss: 0.01233979407697916\n",
      "Epoch 2436, Loss: 0.02008029166609049, Final Batch Loss: 0.0020996006205677986\n",
      "Epoch 2437, Loss: 0.011881134007126093, Final Batch Loss: 0.006476634182035923\n",
      "Epoch 2438, Loss: 0.032981302589178085, Final Batch Loss: 0.005526360124349594\n",
      "Epoch 2439, Loss: 0.013443907955661416, Final Batch Loss: 0.010305685922503471\n",
      "Epoch 2440, Loss: 0.03236816264688969, Final Batch Loss: 0.02404104918241501\n",
      "Epoch 2441, Loss: 0.03504552226513624, Final Batch Loss: 0.006063818000257015\n",
      "Epoch 2442, Loss: 0.012704253196716309, Final Batch Loss: 0.004999780561774969\n",
      "Epoch 2443, Loss: 0.03598345536738634, Final Batch Loss: 0.03042597882449627\n",
      "Epoch 2444, Loss: 0.013162666698917747, Final Batch Loss: 0.0038214342202991247\n",
      "Epoch 2445, Loss: 0.023052816279232502, Final Batch Loss: 0.00972660630941391\n",
      "Epoch 2446, Loss: 0.01471036160364747, Final Batch Loss: 0.011582293547689915\n",
      "Epoch 2447, Loss: 0.010032163467258215, Final Batch Loss: 0.005416792817413807\n",
      "Epoch 2448, Loss: 0.06345614418387413, Final Batch Loss: 0.00993417575955391\n",
      "Epoch 2449, Loss: 0.010657518170773983, Final Batch Loss: 0.00509611377492547\n",
      "Epoch 2450, Loss: 0.007891176734119654, Final Batch Loss: 0.0030463477596640587\n",
      "Epoch 2451, Loss: 0.026912150904536247, Final Batch Loss: 0.02126052975654602\n",
      "Epoch 2452, Loss: 0.014555970206856728, Final Batch Loss: 0.012515232898294926\n",
      "Epoch 2453, Loss: 0.05902295093983412, Final Batch Loss: 0.010345502756536007\n",
      "Epoch 2454, Loss: 0.00376615475397557, Final Batch Loss: 0.001659887726418674\n",
      "Epoch 2455, Loss: 0.0311289606615901, Final Batch Loss: 0.022476673126220703\n",
      "Epoch 2456, Loss: 0.03984028147533536, Final Batch Loss: 0.00742957042530179\n",
      "Epoch 2457, Loss: 0.02051455993205309, Final Batch Loss: 0.0024694139137864113\n",
      "Epoch 2458, Loss: 0.021055012475699186, Final Batch Loss: 0.005597406532615423\n",
      "Epoch 2459, Loss: 0.031773694790899754, Final Batch Loss: 0.020222006365656853\n",
      "Epoch 2460, Loss: 0.029399000108242035, Final Batch Loss: 0.025592250749468803\n",
      "Epoch 2461, Loss: 0.00997269933577627, Final Batch Loss: 0.0019003370543941855\n",
      "Epoch 2462, Loss: 0.02836271934211254, Final Batch Loss: 0.008641364052891731\n",
      "Epoch 2463, Loss: 0.10601956397294998, Final Batch Loss: 0.0882464125752449\n",
      "Epoch 2464, Loss: 0.04803792294114828, Final Batch Loss: 0.04058137908577919\n",
      "Epoch 2465, Loss: 0.01603957242332399, Final Batch Loss: 0.012510399334132671\n",
      "Epoch 2466, Loss: 0.043500445783138275, Final Batch Loss: 0.01890065334737301\n",
      "Epoch 2467, Loss: 0.03793611051514745, Final Batch Loss: 0.03373032063245773\n",
      "Epoch 2468, Loss: 0.009625910548493266, Final Batch Loss: 0.0064919437281787395\n",
      "Epoch 2469, Loss: 0.03697924315929413, Final Batch Loss: 0.013887139037251472\n",
      "Epoch 2470, Loss: 0.06305203214287758, Final Batch Loss: 0.035865478217601776\n",
      "Epoch 2471, Loss: 0.015571569092571735, Final Batch Loss: 0.006988141685724258\n",
      "Epoch 2472, Loss: 0.02755195426288992, Final Batch Loss: 0.025853827595710754\n",
      "Epoch 2473, Loss: 0.009654111927375197, Final Batch Loss: 0.0033970277290791273\n",
      "Epoch 2474, Loss: 0.028462867252528667, Final Batch Loss: 0.01994638703763485\n",
      "Epoch 2475, Loss: 0.0337476022541523, Final Batch Loss: 0.01916390471160412\n",
      "Epoch 2476, Loss: 0.023080222774297, Final Batch Loss: 0.00760691100731492\n",
      "Epoch 2477, Loss: 0.022089872043579817, Final Batch Loss: 0.0174618661403656\n",
      "Epoch 2478, Loss: 0.01366990152746439, Final Batch Loss: 0.010783810168504715\n",
      "Epoch 2479, Loss: 0.023071611300110817, Final Batch Loss: 0.01229765173047781\n",
      "Epoch 2480, Loss: 0.022549117915332317, Final Batch Loss: 0.014410527423024178\n",
      "Epoch 2481, Loss: 0.10076439939439297, Final Batch Loss: 0.07911200076341629\n",
      "Epoch 2482, Loss: 0.09192913770675659, Final Batch Loss: 0.019421279430389404\n",
      "Epoch 2483, Loss: 0.04482258856296539, Final Batch Loss: 0.03430747240781784\n",
      "Epoch 2484, Loss: 0.13225561380386353, Final Batch Loss: 0.06913340091705322\n",
      "Epoch 2485, Loss: 0.03032589890062809, Final Batch Loss: 0.02444985695183277\n",
      "Epoch 2486, Loss: 0.035328395664691925, Final Batch Loss: 0.004371426999568939\n",
      "Epoch 2487, Loss: 0.10922742821276188, Final Batch Loss: 0.018250035122036934\n",
      "Epoch 2488, Loss: 0.010484294965863228, Final Batch Loss: 0.004398795776069164\n",
      "Epoch 2489, Loss: 0.011988814221695065, Final Batch Loss: 0.0027710648719221354\n",
      "Epoch 2490, Loss: 0.028868423774838448, Final Batch Loss: 0.019126662984490395\n",
      "Epoch 2491, Loss: 0.033856303663924336, Final Batch Loss: 0.0029433269519358873\n",
      "Epoch 2492, Loss: 0.007126587210223079, Final Batch Loss: 0.0029208750929683447\n",
      "Epoch 2493, Loss: 0.009758967440575361, Final Batch Loss: 0.004516622517257929\n",
      "Epoch 2494, Loss: 0.02389577217400074, Final Batch Loss: 0.006810074672102928\n",
      "Epoch 2495, Loss: 0.013607178814709187, Final Batch Loss: 0.00638077175244689\n",
      "Epoch 2496, Loss: 0.008471179520711303, Final Batch Loss: 0.0021445804741233587\n",
      "Epoch 2497, Loss: 0.05175882740877569, Final Batch Loss: 0.049224983900785446\n",
      "Epoch 2498, Loss: 0.02788866125047207, Final Batch Loss: 0.0051783062517642975\n",
      "Epoch 2499, Loss: 0.02643879526294768, Final Batch Loss: 0.0028084462974220514\n",
      "Epoch 2500, Loss: 0.007858246332034469, Final Batch Loss: 0.0036687494721263647\n",
      "Epoch 2501, Loss: 0.014957291074097157, Final Batch Loss: 0.004391388967633247\n",
      "Epoch 2502, Loss: 0.0599192432127893, Final Batch Loss: 0.05387108027935028\n",
      "Epoch 2503, Loss: 0.02347547560930252, Final Batch Loss: 0.015529627911746502\n",
      "Epoch 2504, Loss: 0.014373700600117445, Final Batch Loss: 0.011129754595458508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2505, Loss: 0.012732044328004122, Final Batch Loss: 0.00688982056453824\n",
      "Epoch 2506, Loss: 0.021656843833625317, Final Batch Loss: 0.006409413181245327\n",
      "Epoch 2507, Loss: 0.019598249113187194, Final Batch Loss: 0.002381860977038741\n",
      "Epoch 2508, Loss: 0.013586128130555153, Final Batch Loss: 0.007911942899227142\n",
      "Epoch 2509, Loss: 0.01806980837136507, Final Batch Loss: 0.010329523123800755\n",
      "Epoch 2510, Loss: 0.01340219983831048, Final Batch Loss: 0.008367237634956837\n",
      "Epoch 2511, Loss: 0.013949922285974026, Final Batch Loss: 0.004540774039924145\n",
      "Epoch 2512, Loss: 0.009398692985996604, Final Batch Loss: 0.0020774255972355604\n",
      "Epoch 2513, Loss: 0.02316646184772253, Final Batch Loss: 0.01331097912043333\n",
      "Epoch 2514, Loss: 0.01973926369100809, Final Batch Loss: 0.01169665902853012\n",
      "Epoch 2515, Loss: 0.04420952033251524, Final Batch Loss: 0.014149465598165989\n",
      "Epoch 2516, Loss: 0.010747155407443643, Final Batch Loss: 0.0069245845079422\n",
      "Epoch 2517, Loss: 0.011559085454791784, Final Batch Loss: 0.004968083463609219\n",
      "Epoch 2518, Loss: 0.036902250023558736, Final Batch Loss: 0.0010572683531790972\n",
      "Epoch 2519, Loss: 0.005501041887328029, Final Batch Loss: 0.0020274377893656492\n",
      "Epoch 2520, Loss: 0.0050953770987689495, Final Batch Loss: 0.004009755328297615\n",
      "Epoch 2521, Loss: 0.010934769175946712, Final Batch Loss: 0.007113601081073284\n",
      "Epoch 2522, Loss: 0.02135471533983946, Final Batch Loss: 0.016042763367295265\n",
      "Epoch 2523, Loss: 0.006432211026549339, Final Batch Loss: 0.0020980355329811573\n",
      "Epoch 2524, Loss: 0.016287641134113073, Final Batch Loss: 0.007448377553373575\n",
      "Epoch 2525, Loss: 0.010775804985314608, Final Batch Loss: 0.004273177590221167\n",
      "Epoch 2526, Loss: 0.019150828011333942, Final Batch Loss: 0.009477599523961544\n",
      "Epoch 2527, Loss: 0.031114349141716957, Final Batch Loss: 0.00234096497297287\n",
      "Epoch 2528, Loss: 0.009305422427132726, Final Batch Loss: 0.0032283219043165445\n",
      "Epoch 2529, Loss: 0.03009058814495802, Final Batch Loss: 0.013499937020242214\n",
      "Epoch 2530, Loss: 0.04652819503098726, Final Batch Loss: 0.008766834624111652\n",
      "Epoch 2531, Loss: 0.010211371816694736, Final Batch Loss: 0.005546271800994873\n",
      "Epoch 2532, Loss: 0.01901082508265972, Final Batch Loss: 0.0076800743117928505\n",
      "Epoch 2533, Loss: 0.020396963227540255, Final Batch Loss: 0.004250541795045137\n",
      "Epoch 2534, Loss: 0.015052030328661203, Final Batch Loss: 0.003926408011466265\n",
      "Epoch 2535, Loss: 0.04995928145945072, Final Batch Loss: 0.035129938274621964\n",
      "Epoch 2536, Loss: 0.013818229548633099, Final Batch Loss: 0.006112236063927412\n",
      "Epoch 2537, Loss: 0.026092074811458588, Final Batch Loss: 0.017522767186164856\n",
      "Epoch 2538, Loss: 0.016874887514859438, Final Batch Loss: 0.013247677125036716\n",
      "Epoch 2539, Loss: 0.006074902135878801, Final Batch Loss: 0.0015644729137420654\n",
      "Epoch 2540, Loss: 0.0059080650098621845, Final Batch Loss: 0.003828955814242363\n",
      "Epoch 2541, Loss: 0.007315872004255652, Final Batch Loss: 0.0028517975006252527\n",
      "Epoch 2542, Loss: 0.0193092692643404, Final Batch Loss: 0.00829606968909502\n",
      "Epoch 2543, Loss: 0.04086111672222614, Final Batch Loss: 0.023423651233315468\n",
      "Epoch 2544, Loss: 0.013817899394780397, Final Batch Loss: 0.008615533821284771\n",
      "Epoch 2545, Loss: 0.022569251246750355, Final Batch Loss: 0.009626002050936222\n",
      "Epoch 2546, Loss: 0.046662211418151855, Final Batch Loss: 0.016361629590392113\n",
      "Epoch 2547, Loss: 0.011856835626531392, Final Batch Loss: 0.0009562431951053441\n",
      "Epoch 2548, Loss: 0.018872611224651337, Final Batch Loss: 0.013098585419356823\n",
      "Epoch 2549, Loss: 0.008107764413580298, Final Batch Loss: 0.002196680987253785\n",
      "Epoch 2550, Loss: 0.03423845674842596, Final Batch Loss: 0.0058157360181212425\n",
      "Epoch 2551, Loss: 0.04113733256235719, Final Batch Loss: 0.03391404449939728\n",
      "Epoch 2552, Loss: 0.009034860413521528, Final Batch Loss: 0.005420975387096405\n",
      "Epoch 2553, Loss: 0.03186783380806446, Final Batch Loss: 0.01272117905318737\n",
      "Epoch 2554, Loss: 0.013430499704554677, Final Batch Loss: 0.009994727559387684\n",
      "Epoch 2555, Loss: 0.01865917257964611, Final Batch Loss: 0.009623369202017784\n",
      "Epoch 2556, Loss: 0.015545941423624754, Final Batch Loss: 0.0034361588768661022\n",
      "Epoch 2557, Loss: 0.013819566927850246, Final Batch Loss: 0.009277964010834694\n",
      "Epoch 2558, Loss: 0.018849358893930912, Final Batch Loss: 0.009063614532351494\n",
      "Epoch 2559, Loss: 0.022704074159264565, Final Batch Loss: 0.007878818549215794\n",
      "Epoch 2560, Loss: 0.019001281121745706, Final Batch Loss: 0.0160377137362957\n",
      "Epoch 2561, Loss: 0.011766045819967985, Final Batch Loss: 0.0026403102092444897\n",
      "Epoch 2562, Loss: 0.006592901656404138, Final Batch Loss: 0.0006368069443851709\n",
      "Epoch 2563, Loss: 0.013487261021509767, Final Batch Loss: 0.010449840687215328\n",
      "Epoch 2564, Loss: 0.005428062053397298, Final Batch Loss: 0.0010769127402454615\n",
      "Epoch 2565, Loss: 0.029238090617582202, Final Batch Loss: 0.003258551238104701\n",
      "Epoch 2566, Loss: 0.022038888186216354, Final Batch Loss: 0.008409892208874226\n",
      "Epoch 2567, Loss: 0.009933301713317633, Final Batch Loss: 0.0033479169942438602\n",
      "Epoch 2568, Loss: 0.03580874111503363, Final Batch Loss: 0.03157367929816246\n",
      "Epoch 2569, Loss: 0.05447971820831299, Final Batch Loss: 0.023475198075175285\n",
      "Epoch 2570, Loss: 0.049878613790497184, Final Batch Loss: 0.046392571181058884\n",
      "Epoch 2571, Loss: 0.025928030256181955, Final Batch Loss: 0.01845148392021656\n",
      "Epoch 2572, Loss: 0.025013803504407406, Final Batch Loss: 0.008399545215070248\n",
      "Epoch 2573, Loss: 0.03543247561901808, Final Batch Loss: 0.013748339377343655\n",
      "Epoch 2574, Loss: 0.013754622312262654, Final Batch Loss: 0.011217830702662468\n",
      "Epoch 2575, Loss: 0.007587719243019819, Final Batch Loss: 0.002943130210042\n",
      "Epoch 2576, Loss: 0.015748805832117796, Final Batch Loss: 0.01182420365512371\n",
      "Epoch 2577, Loss: 0.0211506187915802, Final Batch Loss: 0.0025937482714653015\n",
      "Epoch 2578, Loss: 0.018338990630581975, Final Batch Loss: 0.001972672762349248\n",
      "Epoch 2579, Loss: 0.009587886277586222, Final Batch Loss: 0.00445354450494051\n",
      "Epoch 2580, Loss: 0.020993925631046295, Final Batch Loss: 0.009950891137123108\n",
      "Epoch 2581, Loss: 0.014408609131351113, Final Batch Loss: 0.0008853098843246698\n",
      "Epoch 2582, Loss: 0.010314706712961197, Final Batch Loss: 0.0035067349672317505\n",
      "Epoch 2583, Loss: 0.07364922482520342, Final Batch Loss: 0.07142041623592377\n",
      "Epoch 2584, Loss: 0.020454457961022854, Final Batch Loss: 0.014425462111830711\n",
      "Epoch 2585, Loss: 0.003275041584856808, Final Batch Loss: 0.0019229443278163671\n",
      "Epoch 2586, Loss: 0.022861335426568985, Final Batch Loss: 0.0061017367988824844\n",
      "Epoch 2587, Loss: 0.032563548535108566, Final Batch Loss: 0.026767056435346603\n",
      "Epoch 2588, Loss: 0.08539831405505538, Final Batch Loss: 0.0052370852790772915\n",
      "Epoch 2589, Loss: 0.03779206518083811, Final Batch Loss: 0.02388771064579487\n",
      "Epoch 2590, Loss: 0.02447786438278854, Final Batch Loss: 0.002943648723885417\n",
      "Epoch 2591, Loss: 0.05105938948690891, Final Batch Loss: 0.04066513851284981\n",
      "Epoch 2592, Loss: 0.022508571855723858, Final Batch Loss: 0.005548122338950634\n",
      "Epoch 2593, Loss: 0.012915147002786398, Final Batch Loss: 0.006235339213162661\n",
      "Epoch 2594, Loss: 0.02223917469382286, Final Batch Loss: 0.010765611194074154\n",
      "Epoch 2595, Loss: 0.03248776216059923, Final Batch Loss: 0.0025793490931391716\n",
      "Epoch 2596, Loss: 0.021333722630515695, Final Batch Loss: 0.0032105802092701197\n",
      "Epoch 2597, Loss: 0.011464572045952082, Final Batch Loss: 0.005278258118778467\n",
      "Epoch 2598, Loss: 0.00967810582369566, Final Batch Loss: 0.005584608297795057\n",
      "Epoch 2599, Loss: 0.02752812672406435, Final Batch Loss: 0.02091406099498272\n",
      "Epoch 2600, Loss: 0.004662963096052408, Final Batch Loss: 0.0020574647933244705\n",
      "Epoch 2601, Loss: 0.07942145131528378, Final Batch Loss: 0.062272533774375916\n",
      "Epoch 2602, Loss: 0.019608106464147568, Final Batch Loss: 0.00830544251948595\n",
      "Epoch 2603, Loss: 0.01447766087949276, Final Batch Loss: 0.008211079984903336\n",
      "Epoch 2604, Loss: 0.0454226927831769, Final Batch Loss: 0.031086266040802002\n",
      "Epoch 2605, Loss: 0.018631968647241592, Final Batch Loss: 0.005057409405708313\n",
      "Epoch 2606, Loss: 0.02405979298055172, Final Batch Loss: 0.004962887614965439\n",
      "Epoch 2607, Loss: 0.01686491072177887, Final Batch Loss: 0.010869666002690792\n",
      "Epoch 2608, Loss: 0.04491775529459119, Final Batch Loss: 0.03993484005331993\n",
      "Epoch 2609, Loss: 0.03199105150997639, Final Batch Loss: 0.01593921147286892\n",
      "Epoch 2610, Loss: 0.019210193771868944, Final Batch Loss: 0.012597726657986641\n",
      "Epoch 2611, Loss: 0.004120140569284558, Final Batch Loss: 0.0023376771714538336\n",
      "Epoch 2612, Loss: 0.011876672273501754, Final Batch Loss: 0.008888350799679756\n",
      "Epoch 2613, Loss: 0.1087300144135952, Final Batch Loss: 0.0870388075709343\n",
      "Epoch 2614, Loss: 0.014190712245181203, Final Batch Loss: 0.0028123839292675257\n",
      "Epoch 2615, Loss: 0.027880797162652016, Final Batch Loss: 0.012640433385968208\n",
      "Epoch 2616, Loss: 0.05708526074886322, Final Batch Loss: 0.02204091101884842\n",
      "Epoch 2617, Loss: 0.03219412500038743, Final Batch Loss: 0.024692310020327568\n",
      "Epoch 2618, Loss: 0.05185870360583067, Final Batch Loss: 0.047720570117235184\n",
      "Epoch 2619, Loss: 0.004160287091508508, Final Batch Loss: 0.001314898720011115\n",
      "Epoch 2620, Loss: 0.01422578888013959, Final Batch Loss: 0.007308787666261196\n",
      "Epoch 2621, Loss: 0.0136045110411942, Final Batch Loss: 0.006180743221193552\n",
      "Epoch 2622, Loss: 0.023288699332624674, Final Batch Loss: 0.006981434766203165\n",
      "Epoch 2623, Loss: 0.04958488489501178, Final Batch Loss: 0.0459730327129364\n",
      "Epoch 2624, Loss: 0.013092413078993559, Final Batch Loss: 0.006518832873553038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2625, Loss: 0.010432925657369196, Final Batch Loss: 0.008705978281795979\n",
      "Epoch 2626, Loss: 0.012311451137065887, Final Batch Loss: 0.005508102010935545\n",
      "Epoch 2627, Loss: 0.01122189499437809, Final Batch Loss: 0.004174003377556801\n",
      "Epoch 2628, Loss: 0.014686649665236473, Final Batch Loss: 0.009464230388402939\n",
      "Epoch 2629, Loss: 0.018816904281266034, Final Batch Loss: 0.01739722304046154\n",
      "Epoch 2630, Loss: 0.012860994786024094, Final Batch Loss: 0.004811843857169151\n",
      "Epoch 2631, Loss: 0.010868685320019722, Final Batch Loss: 0.004195151384919882\n",
      "Epoch 2632, Loss: 0.0947740375995636, Final Batch Loss: 0.060401998460292816\n",
      "Epoch 2633, Loss: 0.045735147781670094, Final Batch Loss: 0.004800525493919849\n",
      "Epoch 2634, Loss: 0.006935100071132183, Final Batch Loss: 0.002257240004837513\n",
      "Epoch 2635, Loss: 0.047811852768063545, Final Batch Loss: 0.022068526595830917\n",
      "Epoch 2636, Loss: 0.04973808862268925, Final Batch Loss: 0.015878358855843544\n",
      "Epoch 2637, Loss: 0.12639134004712105, Final Batch Loss: 0.08245618641376495\n",
      "Epoch 2638, Loss: 0.02273860201239586, Final Batch Loss: 0.012945085763931274\n",
      "Epoch 2639, Loss: 0.03471168875694275, Final Batch Loss: 0.014110429212450981\n",
      "Epoch 2640, Loss: 0.029866171069443226, Final Batch Loss: 0.008968834765255451\n",
      "Epoch 2641, Loss: 0.049225786700844765, Final Batch Loss: 0.00338776595890522\n",
      "Epoch 2642, Loss: 0.028018471784889698, Final Batch Loss: 0.009209412150084972\n",
      "Epoch 2643, Loss: 0.0579125601798296, Final Batch Loss: 0.009386109188199043\n",
      "Epoch 2644, Loss: 0.04763501603156328, Final Batch Loss: 0.003942397423088551\n",
      "Epoch 2645, Loss: 0.030696512665599585, Final Batch Loss: 0.023656686767935753\n",
      "Epoch 2646, Loss: 0.009266152745112777, Final Batch Loss: 0.003779256483539939\n",
      "Epoch 2647, Loss: 0.024092999286949635, Final Batch Loss: 0.01549589168280363\n",
      "Epoch 2648, Loss: 0.046581835485994816, Final Batch Loss: 0.035736702382564545\n",
      "Epoch 2649, Loss: 0.044021522626280785, Final Batch Loss: 0.021895907819271088\n",
      "Epoch 2650, Loss: 0.029399557039141655, Final Batch Loss: 0.017505956813693047\n",
      "Epoch 2651, Loss: 0.013957611750811338, Final Batch Loss: 0.005252039525657892\n",
      "Epoch 2652, Loss: 0.0650563184171915, Final Batch Loss: 0.05568331480026245\n",
      "Epoch 2653, Loss: 0.016938897781074047, Final Batch Loss: 0.006484770216047764\n",
      "Epoch 2654, Loss: 0.02974813710898161, Final Batch Loss: 0.024117622524499893\n",
      "Epoch 2655, Loss: 0.03364876308478415, Final Batch Loss: 0.03021758422255516\n",
      "Epoch 2656, Loss: 0.04057416971772909, Final Batch Loss: 0.002552102319896221\n",
      "Epoch 2657, Loss: 0.01543621951714158, Final Batch Loss: 0.010932458564639091\n",
      "Epoch 2658, Loss: 0.03979193326085806, Final Batch Loss: 0.008023946546018124\n",
      "Epoch 2659, Loss: 0.013538388651795685, Final Batch Loss: 0.0012202850775793195\n",
      "Epoch 2660, Loss: 0.09349249675869942, Final Batch Loss: 0.06519059836864471\n",
      "Epoch 2661, Loss: 0.010665601585060358, Final Batch Loss: 0.004329952877014875\n",
      "Epoch 2662, Loss: 0.03959296038374305, Final Batch Loss: 0.03624312952160835\n",
      "Epoch 2663, Loss: 0.033533915877342224, Final Batch Loss: 0.01938606984913349\n",
      "Epoch 2664, Loss: 0.012320657726377249, Final Batch Loss: 0.003852210473269224\n",
      "Epoch 2665, Loss: 0.012496537994593382, Final Batch Loss: 0.005865247920155525\n",
      "Epoch 2666, Loss: 0.008531559724360704, Final Batch Loss: 0.00461318576708436\n",
      "Epoch 2667, Loss: 0.016199483594391495, Final Batch Loss: 0.0008983510197140276\n",
      "Epoch 2668, Loss: 0.02861060155555606, Final Batch Loss: 0.0074738371185958385\n",
      "Epoch 2669, Loss: 0.009794807061553001, Final Batch Loss: 0.005564513150602579\n",
      "Epoch 2670, Loss: 0.0123559539206326, Final Batch Loss: 0.006074085831642151\n",
      "Epoch 2671, Loss: 0.008567446377128363, Final Batch Loss: 0.004919546190649271\n",
      "Epoch 2672, Loss: 0.01817002147436142, Final Batch Loss: 0.0036320891231298447\n",
      "Epoch 2673, Loss: 0.010661275824531913, Final Batch Loss: 0.003703442169353366\n",
      "Epoch 2674, Loss: 0.024045684840530157, Final Batch Loss: 0.004781122785061598\n",
      "Epoch 2675, Loss: 0.02115695783868432, Final Batch Loss: 0.0005396776832640171\n",
      "Epoch 2676, Loss: 0.03397759888321161, Final Batch Loss: 0.023850930854678154\n",
      "Epoch 2677, Loss: 0.007038747193291783, Final Batch Loss: 0.003609740873798728\n",
      "Epoch 2678, Loss: 0.02694083470851183, Final Batch Loss: 0.015349065884947777\n",
      "Epoch 2679, Loss: 0.035438343649730086, Final Batch Loss: 0.003825701540336013\n",
      "Epoch 2680, Loss: 0.03361274488270283, Final Batch Loss: 0.016246723011136055\n",
      "Epoch 2681, Loss: 0.01705838553607464, Final Batch Loss: 0.011277278885245323\n",
      "Epoch 2682, Loss: 0.04440522752702236, Final Batch Loss: 0.03552907332777977\n",
      "Epoch 2683, Loss: 0.020671135745942593, Final Batch Loss: 0.014658682979643345\n",
      "Epoch 2684, Loss: 0.040310803800821304, Final Batch Loss: 0.03544723987579346\n",
      "Epoch 2685, Loss: 0.04280336084775627, Final Batch Loss: 0.039755892008543015\n",
      "Epoch 2686, Loss: 0.21712432382628322, Final Batch Loss: 0.0022505181841552258\n",
      "Epoch 2687, Loss: 0.007259652717038989, Final Batch Loss: 0.0031793147791177034\n",
      "Epoch 2688, Loss: 0.00821058638393879, Final Batch Loss: 0.0021470533683896065\n",
      "Epoch 2689, Loss: 0.014251673594117165, Final Batch Loss: 0.0075914072804152966\n",
      "Epoch 2690, Loss: 0.030926394276320934, Final Batch Loss: 0.026396896690130234\n",
      "Epoch 2691, Loss: 0.011433335021138191, Final Batch Loss: 0.006038948893547058\n",
      "Epoch 2692, Loss: 0.012206625193357468, Final Batch Loss: 0.004526094999164343\n",
      "Epoch 2693, Loss: 0.04925886355340481, Final Batch Loss: 0.022250305861234665\n",
      "Epoch 2694, Loss: 0.03639337234199047, Final Batch Loss: 0.0209333635866642\n",
      "Epoch 2695, Loss: 0.019318619277328253, Final Batch Loss: 0.004084871616214514\n",
      "Epoch 2696, Loss: 0.0143366907723248, Final Batch Loss: 0.007055066991597414\n",
      "Epoch 2697, Loss: 0.007511401083320379, Final Batch Loss: 0.0026604216545820236\n",
      "Epoch 2698, Loss: 0.05287565104663372, Final Batch Loss: 0.02650398015975952\n",
      "Epoch 2699, Loss: 0.04167161323130131, Final Batch Loss: 0.03748268634080887\n",
      "Epoch 2700, Loss: 0.01873596152290702, Final Batch Loss: 0.012452016584575176\n",
      "Epoch 2701, Loss: 0.015370688866823912, Final Batch Loss: 0.011608715169131756\n",
      "Epoch 2702, Loss: 0.0943231675773859, Final Batch Loss: 0.007348442450165749\n",
      "Epoch 2703, Loss: 0.007000662968493998, Final Batch Loss: 0.0014822353841736913\n",
      "Epoch 2704, Loss: 0.013710667379200459, Final Batch Loss: 0.007005779072642326\n",
      "Epoch 2705, Loss: 0.014581979718059301, Final Batch Loss: 0.010415893979370594\n",
      "Epoch 2706, Loss: 0.007121637929230928, Final Batch Loss: 0.0011950964108109474\n",
      "Epoch 2707, Loss: 0.02649065852165222, Final Batch Loss: 0.022420689463615417\n",
      "Epoch 2708, Loss: 0.007931388914585114, Final Batch Loss: 0.004400100093334913\n",
      "Epoch 2709, Loss: 0.0074413621332496405, Final Batch Loss: 0.003390564816072583\n",
      "Epoch 2710, Loss: 0.006848095916211605, Final Batch Loss: 0.004365184344351292\n",
      "Epoch 2711, Loss: 0.014365237206220627, Final Batch Loss: 0.0019707772880792618\n",
      "Epoch 2712, Loss: 0.024341529700905085, Final Batch Loss: 0.018891964107751846\n",
      "Epoch 2713, Loss: 0.007952310843393207, Final Batch Loss: 0.003052721032872796\n",
      "Epoch 2714, Loss: 0.054000118747353554, Final Batch Loss: 0.03435104712843895\n",
      "Epoch 2715, Loss: 0.04296880215406418, Final Batch Loss: 0.01616872102022171\n",
      "Epoch 2716, Loss: 0.013279583305120468, Final Batch Loss: 0.011127997189760208\n",
      "Epoch 2717, Loss: 0.005670812213793397, Final Batch Loss: 0.0037281664554029703\n",
      "Epoch 2718, Loss: 0.01633112784475088, Final Batch Loss: 0.008638451807200909\n",
      "Epoch 2719, Loss: 0.015469613950699568, Final Batch Loss: 0.008840481750667095\n",
      "Epoch 2720, Loss: 0.016666875686496496, Final Batch Loss: 0.009877138771116734\n",
      "Epoch 2721, Loss: 0.04755238629877567, Final Batch Loss: 0.026312105357646942\n",
      "Epoch 2722, Loss: 0.01800460647791624, Final Batch Loss: 0.009584682062268257\n",
      "Epoch 2723, Loss: 0.005788031267002225, Final Batch Loss: 0.003095576772466302\n",
      "Epoch 2724, Loss: 0.008168522967025638, Final Batch Loss: 0.0013592795003205538\n",
      "Epoch 2725, Loss: 0.03388539655134082, Final Batch Loss: 0.026917047798633575\n",
      "Epoch 2726, Loss: 0.011007931549102068, Final Batch Loss: 0.003954536747187376\n",
      "Epoch 2727, Loss: 0.0107118827290833, Final Batch Loss: 0.0061753313057124615\n",
      "Epoch 2728, Loss: 0.0177871014457196, Final Batch Loss: 0.0013189006131142378\n",
      "Epoch 2729, Loss: 0.032984474673867226, Final Batch Loss: 0.016044769436120987\n",
      "Epoch 2730, Loss: 0.005614043795503676, Final Batch Loss: 0.003972404636442661\n",
      "Epoch 2731, Loss: 0.01709271175786853, Final Batch Loss: 0.006197192240506411\n",
      "Epoch 2732, Loss: 0.021631654351949692, Final Batch Loss: 0.012091748416423798\n",
      "Epoch 2733, Loss: 0.007725591538473964, Final Batch Loss: 0.0035950050223618746\n",
      "Epoch 2734, Loss: 0.01451918063685298, Final Batch Loss: 0.003081296104937792\n",
      "Epoch 2735, Loss: 0.013448245823383331, Final Batch Loss: 0.008593383245170116\n",
      "Epoch 2736, Loss: 0.023690523114055395, Final Batch Loss: 0.016345994547009468\n",
      "Epoch 2737, Loss: 0.0073484559543430805, Final Batch Loss: 0.003806191496551037\n",
      "Epoch 2738, Loss: 0.007407749304547906, Final Batch Loss: 0.004840222653001547\n",
      "Epoch 2739, Loss: 0.01580191170796752, Final Batch Loss: 0.01098485104739666\n",
      "Epoch 2740, Loss: 0.017912120558321476, Final Batch Loss: 0.010779629461467266\n",
      "Epoch 2741, Loss: 0.00938287505414337, Final Batch Loss: 0.001415249309502542\n",
      "Epoch 2742, Loss: 0.02673686621710658, Final Batch Loss: 0.020475374534726143\n",
      "Epoch 2743, Loss: 0.020030622370541096, Final Batch Loss: 0.01736530475318432\n",
      "Epoch 2744, Loss: 0.02249725442379713, Final Batch Loss: 0.00490031111985445\n",
      "Epoch 2745, Loss: 0.012005242519080639, Final Batch Loss: 0.008810426108539104\n",
      "Epoch 2746, Loss: 0.029847090132534504, Final Batch Loss: 0.010337104089558125\n",
      "Epoch 2747, Loss: 0.022907258244231343, Final Batch Loss: 0.0012959514278918505\n",
      "Epoch 2748, Loss: 0.025524399243295193, Final Batch Loss: 0.021217916160821915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2749, Loss: 0.015725772362202406, Final Batch Loss: 0.005942684132605791\n",
      "Epoch 2750, Loss: 0.015655001625418663, Final Batch Loss: 0.010441882535815239\n",
      "Epoch 2751, Loss: 0.03420581389218569, Final Batch Loss: 0.012665054760873318\n",
      "Epoch 2752, Loss: 0.010422191116958857, Final Batch Loss: 0.005766595713794231\n",
      "Epoch 2753, Loss: 0.012751749134622514, Final Batch Loss: 0.001465118839405477\n",
      "Epoch 2754, Loss: 0.007475533406250179, Final Batch Loss: 0.001716604339890182\n",
      "Epoch 2755, Loss: 0.007827376131899655, Final Batch Loss: 0.001432168879546225\n",
      "Epoch 2756, Loss: 0.013447986217215657, Final Batch Loss: 0.010114948265254498\n",
      "Epoch 2757, Loss: 0.01302933506667614, Final Batch Loss: 0.007883003912866116\n",
      "Epoch 2758, Loss: 0.007055080961436033, Final Batch Loss: 0.003930449951440096\n",
      "Epoch 2759, Loss: 0.024112473241984844, Final Batch Loss: 0.008326546289026737\n",
      "Epoch 2760, Loss: 0.007111225568223745, Final Batch Loss: 0.000583882734645158\n",
      "Epoch 2761, Loss: 0.0158037762157619, Final Batch Loss: 0.009155812673270702\n",
      "Epoch 2762, Loss: 0.020704145543277264, Final Batch Loss: 0.01226762868463993\n",
      "Epoch 2763, Loss: 0.012708878144621849, Final Batch Loss: 0.0036567114293575287\n",
      "Epoch 2764, Loss: 0.010549478698521852, Final Batch Loss: 0.008561723865568638\n",
      "Epoch 2765, Loss: 0.031677368097007275, Final Batch Loss: 0.008307608775794506\n",
      "Epoch 2766, Loss: 0.05984835949493572, Final Batch Loss: 0.0009020219440571964\n",
      "Epoch 2767, Loss: 0.05551018472760916, Final Batch Loss: 0.05075283721089363\n",
      "Epoch 2768, Loss: 0.03967977501451969, Final Batch Loss: 0.03078930452466011\n",
      "Epoch 2769, Loss: 0.04029796365648508, Final Batch Loss: 0.030029062181711197\n",
      "Epoch 2770, Loss: 0.034360908437520266, Final Batch Loss: 0.02770877815783024\n",
      "Epoch 2771, Loss: 0.014448158908635378, Final Batch Loss: 0.002473072614520788\n",
      "Epoch 2772, Loss: 0.024706133641302586, Final Batch Loss: 0.008411665447056293\n",
      "Epoch 2773, Loss: 0.011067091021686792, Final Batch Loss: 0.004931693896651268\n",
      "Epoch 2774, Loss: 0.02139789203647524, Final Batch Loss: 0.019906489178538322\n",
      "Epoch 2775, Loss: 0.03844450879842043, Final Batch Loss: 0.02867860160768032\n",
      "Epoch 2776, Loss: 0.017146431375294924, Final Batch Loss: 0.007502646651118994\n",
      "Epoch 2777, Loss: 0.020939368288964033, Final Batch Loss: 0.017004501074552536\n",
      "Epoch 2778, Loss: 0.006072797521483153, Final Batch Loss: 0.0007273426163010299\n",
      "Epoch 2779, Loss: 0.04231962002813816, Final Batch Loss: 0.023155033588409424\n",
      "Epoch 2780, Loss: 0.04596375348046422, Final Batch Loss: 0.0025690910406410694\n",
      "Epoch 2781, Loss: 0.015716640511527658, Final Batch Loss: 0.012522236444056034\n",
      "Epoch 2782, Loss: 0.026050470769405365, Final Batch Loss: 0.010381670668721199\n",
      "Epoch 2783, Loss: 0.02918232697993517, Final Batch Loss: 0.010589745827019215\n",
      "Epoch 2784, Loss: 0.022634408553130925, Final Batch Loss: 0.0008081953274086118\n",
      "Epoch 2785, Loss: 0.017085177823901176, Final Batch Loss: 0.011929645203053951\n",
      "Epoch 2786, Loss: 0.02456167060881853, Final Batch Loss: 0.01493278332054615\n",
      "Epoch 2787, Loss: 0.02726897201500833, Final Batch Loss: 0.024417376145720482\n",
      "Epoch 2788, Loss: 0.021937602199614048, Final Batch Loss: 0.01003285963088274\n",
      "Epoch 2789, Loss: 0.015051042195409536, Final Batch Loss: 0.006910448428243399\n",
      "Epoch 2790, Loss: 0.007806881098076701, Final Batch Loss: 0.00443789828568697\n",
      "Epoch 2791, Loss: 0.007429100573062897, Final Batch Loss: 0.0035048644058406353\n",
      "Epoch 2792, Loss: 0.022500216029584408, Final Batch Loss: 0.016666095703840256\n",
      "Epoch 2793, Loss: 0.029971204232424498, Final Batch Loss: 0.005377491470426321\n",
      "Epoch 2794, Loss: 0.01516669662669301, Final Batch Loss: 0.00612622732296586\n",
      "Epoch 2795, Loss: 0.012696249643340707, Final Batch Loss: 0.0019565916154533625\n",
      "Epoch 2796, Loss: 0.012260715942829847, Final Batch Loss: 0.007333064451813698\n",
      "Epoch 2797, Loss: 0.005714827682822943, Final Batch Loss: 0.0031064492650330067\n",
      "Epoch 2798, Loss: 0.011507243849337101, Final Batch Loss: 0.007603362202644348\n",
      "Epoch 2799, Loss: 0.007309806300327182, Final Batch Loss: 0.006287654396146536\n",
      "Epoch 2800, Loss: 0.017188270576298237, Final Batch Loss: 0.010519636794924736\n",
      "Epoch 2801, Loss: 0.044563112780451775, Final Batch Loss: 0.037327639758586884\n",
      "Epoch 2802, Loss: 0.01704504434019327, Final Batch Loss: 0.007965805940330029\n",
      "Epoch 2803, Loss: 0.006323755718767643, Final Batch Loss: 0.0026961916591972113\n",
      "Epoch 2804, Loss: 0.015945980791002512, Final Batch Loss: 0.002953858580440283\n",
      "Epoch 2805, Loss: 0.025665227323770523, Final Batch Loss: 0.008786261081695557\n",
      "Epoch 2806, Loss: 0.008307215059176087, Final Batch Loss: 0.002804803429171443\n",
      "Epoch 2807, Loss: 0.017687483690679073, Final Batch Loss: 0.0065498072654008865\n",
      "Epoch 2808, Loss: 0.04924122616648674, Final Batch Loss: 0.03253576532006264\n",
      "Epoch 2809, Loss: 0.012367628049105406, Final Batch Loss: 0.005766335409134626\n",
      "Epoch 2810, Loss: 0.03788955323398113, Final Batch Loss: 0.029773984104394913\n",
      "Epoch 2811, Loss: 0.018892448395490646, Final Batch Loss: 0.00862917210906744\n",
      "Epoch 2812, Loss: 0.02344982884824276, Final Batch Loss: 0.01390986517071724\n",
      "Epoch 2813, Loss: 0.009125863667577505, Final Batch Loss: 0.006168016232550144\n",
      "Epoch 2814, Loss: 0.0031412699026986957, Final Batch Loss: 0.0008222261676564813\n",
      "Epoch 2815, Loss: 0.03034533793106675, Final Batch Loss: 0.0025968109257519245\n",
      "Epoch 2816, Loss: 0.015618513338267803, Final Batch Loss: 0.0042908089235424995\n",
      "Epoch 2817, Loss: 0.017513016471639276, Final Batch Loss: 0.0027045488823205233\n",
      "Epoch 2818, Loss: 0.02322064433246851, Final Batch Loss: 0.02199934609234333\n",
      "Epoch 2819, Loss: 0.03072778508067131, Final Batch Loss: 0.019600167870521545\n",
      "Epoch 2820, Loss: 0.007565802661702037, Final Batch Loss: 0.004704431630671024\n",
      "Epoch 2821, Loss: 0.008713641203939915, Final Batch Loss: 0.0041442373767495155\n",
      "Epoch 2822, Loss: 0.013054834213107824, Final Batch Loss: 0.00907234288752079\n",
      "Epoch 2823, Loss: 0.0495733474381268, Final Batch Loss: 0.00769335450604558\n",
      "Epoch 2824, Loss: 0.009499673964455724, Final Batch Loss: 0.003083840711042285\n",
      "Epoch 2825, Loss: 0.01406551362015307, Final Batch Loss: 0.00270166271366179\n",
      "Epoch 2826, Loss: 0.01151265762746334, Final Batch Loss: 0.0035510454326868057\n",
      "Epoch 2827, Loss: 0.006049660500138998, Final Batch Loss: 0.0013870312832295895\n",
      "Epoch 2828, Loss: 0.023587566567584872, Final Batch Loss: 0.021215330809354782\n",
      "Epoch 2829, Loss: 0.017103947699069977, Final Batch Loss: 0.009022064507007599\n",
      "Epoch 2830, Loss: 0.005690631805919111, Final Batch Loss: 0.004536033608019352\n",
      "Epoch 2831, Loss: 0.053293167147785425, Final Batch Loss: 0.0035022185184061527\n",
      "Epoch 2832, Loss: 0.004903041524812579, Final Batch Loss: 0.0028971792198717594\n",
      "Epoch 2833, Loss: 0.004927980131469667, Final Batch Loss: 0.0031583872623741627\n",
      "Epoch 2834, Loss: 0.022928867489099503, Final Batch Loss: 0.01164498645812273\n",
      "Epoch 2835, Loss: 0.0076133981929160655, Final Batch Loss: 0.000508948287460953\n",
      "Epoch 2836, Loss: 0.024885122198611498, Final Batch Loss: 0.006831368897110224\n",
      "Epoch 2837, Loss: 0.008538851514458656, Final Batch Loss: 0.0025986102409660816\n",
      "Epoch 2838, Loss: 0.0413376996293664, Final Batch Loss: 0.013314788229763508\n",
      "Epoch 2839, Loss: 0.05647579487413168, Final Batch Loss: 0.05345289781689644\n",
      "Epoch 2840, Loss: 0.008688073372468352, Final Batch Loss: 0.006022621411830187\n",
      "Epoch 2841, Loss: 0.03083751304075122, Final Batch Loss: 0.026400813832879066\n",
      "Epoch 2842, Loss: 0.010928085539489985, Final Batch Loss: 0.006618709769099951\n",
      "Epoch 2843, Loss: 0.01190895913168788, Final Batch Loss: 0.004634538199752569\n",
      "Epoch 2844, Loss: 0.008649396477267146, Final Batch Loss: 0.0019249061588197947\n",
      "Epoch 2845, Loss: 0.007417032727971673, Final Batch Loss: 0.002472811611369252\n",
      "Epoch 2846, Loss: 0.00585167552344501, Final Batch Loss: 0.0028255698271095753\n",
      "Epoch 2847, Loss: 0.0024663337972015142, Final Batch Loss: 0.0009303914848715067\n",
      "Epoch 2848, Loss: 0.008104408392682672, Final Batch Loss: 0.0020045877899974585\n",
      "Epoch 2849, Loss: 0.004343901993706822, Final Batch Loss: 0.0025587172713130713\n",
      "Epoch 2850, Loss: 0.018453889526426792, Final Batch Loss: 0.01012622844427824\n",
      "Epoch 2851, Loss: 0.05689081735908985, Final Batch Loss: 0.027274539694190025\n",
      "Epoch 2852, Loss: 0.18168979207985103, Final Batch Loss: 0.0024829439353197813\n",
      "Epoch 2853, Loss: 0.028783179819583893, Final Batch Loss: 0.01532826293259859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Loss: 0.006365508306771517, Final Batch Loss: 0.0024541672319173813\n",
      "Epoch 2855, Loss: 0.030949834268540144, Final Batch Loss: 0.023558784276247025\n",
      "Epoch 2856, Loss: 0.029540501534938812, Final Batch Loss: 0.026143047958612442\n",
      "Epoch 2857, Loss: 0.021301566623151302, Final Batch Loss: 0.011577972210943699\n",
      "Epoch 2858, Loss: 0.021553320810198784, Final Batch Loss: 0.00431429035961628\n",
      "Epoch 2859, Loss: 0.05468215420842171, Final Batch Loss: 0.02452302910387516\n",
      "Epoch 2860, Loss: 0.03699971316382289, Final Batch Loss: 0.030499128624796867\n",
      "Epoch 2861, Loss: 0.011177780106663704, Final Batch Loss: 0.006650473456829786\n",
      "Epoch 2862, Loss: 0.009831911884248257, Final Batch Loss: 0.004152687732130289\n",
      "Epoch 2863, Loss: 0.03204337973147631, Final Batch Loss: 0.013624078594148159\n",
      "Epoch 2864, Loss: 0.02354526915587485, Final Batch Loss: 0.019752908498048782\n",
      "Epoch 2865, Loss: 0.026743308641016483, Final Batch Loss: 0.017353881150484085\n",
      "Epoch 2866, Loss: 0.02976135816425085, Final Batch Loss: 0.008808054961264133\n",
      "Epoch 2867, Loss: 0.02632542746141553, Final Batch Loss: 0.021180784329771996\n",
      "Epoch 2868, Loss: 0.02439313940703869, Final Batch Loss: 0.004949929192662239\n",
      "Epoch 2869, Loss: 0.06525487080216408, Final Batch Loss: 0.06082576513290405\n",
      "Epoch 2870, Loss: 0.034501451067626476, Final Batch Loss: 0.024559499695897102\n",
      "Epoch 2871, Loss: 0.021907974034547806, Final Batch Loss: 0.008885295130312443\n",
      "Epoch 2872, Loss: 0.01613690424710512, Final Batch Loss: 0.007653055712580681\n",
      "Epoch 2873, Loss: 0.017170313745737076, Final Batch Loss: 0.005377775989472866\n",
      "Epoch 2874, Loss: 0.041471051517874, Final Batch Loss: 0.034177593886852264\n",
      "Epoch 2875, Loss: 0.014985124114900827, Final Batch Loss: 0.00964027177542448\n",
      "Epoch 2876, Loss: 0.07095514982938766, Final Batch Loss: 0.05148568004369736\n",
      "Epoch 2877, Loss: 0.011972042731940746, Final Batch Loss: 0.006645797286182642\n",
      "Epoch 2878, Loss: 0.14705537632107735, Final Batch Loss: 0.09396474808454514\n",
      "Epoch 2879, Loss: 0.07113965600728989, Final Batch Loss: 0.0397004671394825\n",
      "Epoch 2880, Loss: 0.010871668811887503, Final Batch Loss: 0.004371685907244682\n",
      "Epoch 2881, Loss: 0.045465363189578056, Final Batch Loss: 0.028403621166944504\n",
      "Epoch 2882, Loss: 0.03694100771099329, Final Batch Loss: 0.009739688597619534\n",
      "Epoch 2883, Loss: 0.033617544919252396, Final Batch Loss: 0.022460944950580597\n",
      "Epoch 2884, Loss: 0.043370723724365234, Final Batch Loss: 0.015310036018490791\n",
      "Epoch 2885, Loss: 0.024081458337605, Final Batch Loss: 0.019336197525262833\n",
      "Epoch 2886, Loss: 0.06833262601867318, Final Batch Loss: 0.007207261864095926\n",
      "Epoch 2887, Loss: 0.02586871525272727, Final Batch Loss: 0.0050768363289535046\n",
      "Epoch 2888, Loss: 0.05021392134949565, Final Batch Loss: 0.0440036877989769\n",
      "Epoch 2889, Loss: 0.06370296515524387, Final Batch Loss: 0.039564743638038635\n",
      "Epoch 2890, Loss: 0.04683506453875452, Final Batch Loss: 0.0017629783833399415\n",
      "Epoch 2891, Loss: 0.12211917340755463, Final Batch Loss: 0.06067308783531189\n",
      "Epoch 2892, Loss: 0.020536702126264572, Final Batch Loss: 0.008078642189502716\n",
      "Epoch 2893, Loss: 0.01930537587031722, Final Batch Loss: 0.015138521790504456\n",
      "Epoch 2894, Loss: 0.04040439426898956, Final Batch Loss: 0.008098594844341278\n",
      "Epoch 2895, Loss: 0.04049103707075119, Final Batch Loss: 0.021030567586421967\n",
      "Epoch 2896, Loss: 0.011646638624370098, Final Batch Loss: 0.006557682994753122\n",
      "Epoch 2897, Loss: 0.028010380687192082, Final Batch Loss: 0.002186593832448125\n",
      "Epoch 2898, Loss: 0.08245784603059292, Final Batch Loss: 0.022770041599869728\n",
      "Epoch 2899, Loss: 0.030042927712202072, Final Batch Loss: 0.007861802354454994\n",
      "Epoch 2900, Loss: 0.03399439435452223, Final Batch Loss: 0.025513440370559692\n",
      "Epoch 2901, Loss: 0.0407792825717479, Final Batch Loss: 0.00309922662563622\n",
      "Epoch 2902, Loss: 0.026819422375410795, Final Batch Loss: 0.023013761267066002\n",
      "Epoch 2903, Loss: 0.027356595965102315, Final Batch Loss: 0.0027233317960053682\n",
      "Epoch 2904, Loss: 0.016476182267069817, Final Batch Loss: 0.009187718853354454\n",
      "Epoch 2905, Loss: 0.006128360517323017, Final Batch Loss: 0.002884211717173457\n",
      "Epoch 2906, Loss: 0.06658101733773947, Final Batch Loss: 0.014569311402738094\n",
      "Epoch 2907, Loss: 0.010077425045892596, Final Batch Loss: 0.003790086368098855\n",
      "Epoch 2908, Loss: 0.044145090505480766, Final Batch Loss: 0.01999766193330288\n",
      "Epoch 2909, Loss: 0.08090635482221842, Final Batch Loss: 0.07369265705347061\n",
      "Epoch 2910, Loss: 0.039981963112950325, Final Batch Loss: 0.010394921526312828\n",
      "Epoch 2911, Loss: 0.016379544511437416, Final Batch Loss: 0.008641761727631092\n",
      "Epoch 2912, Loss: 0.03854162618517876, Final Batch Loss: 0.007567994296550751\n",
      "Epoch 2913, Loss: 0.018239098135381937, Final Batch Loss: 0.004935286473482847\n",
      "Epoch 2914, Loss: 0.019957000389695168, Final Batch Loss: 0.00697733461856842\n",
      "Epoch 2915, Loss: 0.03392312675714493, Final Batch Loss: 0.010673647746443748\n",
      "Epoch 2916, Loss: 0.0500403456389904, Final Batch Loss: 0.034958988428115845\n",
      "Epoch 2917, Loss: 0.009919583913870156, Final Batch Loss: 0.0015313859330490232\n",
      "Epoch 2918, Loss: 0.03130882140249014, Final Batch Loss: 0.007171127013862133\n",
      "Epoch 2919, Loss: 0.08762431517243385, Final Batch Loss: 0.03981802985072136\n",
      "Epoch 2920, Loss: 0.027053910307586193, Final Batch Loss: 0.015627402812242508\n",
      "Epoch 2921, Loss: 0.035252819769084454, Final Batch Loss: 0.009819368831813335\n",
      "Epoch 2922, Loss: 0.0400371877476573, Final Batch Loss: 0.034220777451992035\n",
      "Epoch 2923, Loss: 0.06725209439173341, Final Batch Loss: 0.00530799338594079\n",
      "Epoch 2924, Loss: 0.04416920989751816, Final Batch Loss: 0.024648964405059814\n",
      "Epoch 2925, Loss: 0.03046624641865492, Final Batch Loss: 0.011561878956854343\n",
      "Epoch 2926, Loss: 0.007701303111389279, Final Batch Loss: 0.0021489050704985857\n",
      "Epoch 2927, Loss: 0.022861781530082226, Final Batch Loss: 0.01343043614178896\n",
      "Epoch 2928, Loss: 0.06077709095552564, Final Batch Loss: 0.05796632543206215\n",
      "Epoch 2929, Loss: 0.04660618398338556, Final Batch Loss: 0.011186995543539524\n",
      "Epoch 2930, Loss: 0.05172981880605221, Final Batch Loss: 0.023832056671380997\n",
      "Epoch 2931, Loss: 0.02961034420877695, Final Batch Loss: 0.005681700073182583\n",
      "Epoch 2932, Loss: 0.037395235151052475, Final Batch Loss: 0.01721060276031494\n",
      "Epoch 2933, Loss: 0.04274775553494692, Final Batch Loss: 0.01172309648245573\n",
      "Epoch 2934, Loss: 0.05176651105284691, Final Batch Loss: 0.02927660010755062\n",
      "Epoch 2935, Loss: 0.02099798060953617, Final Batch Loss: 0.0065533993765711784\n",
      "Epoch 2936, Loss: 0.03195857163518667, Final Batch Loss: 0.010390200652182102\n",
      "Epoch 2937, Loss: 0.019155459478497505, Final Batch Loss: 0.01106266863644123\n",
      "Epoch 2938, Loss: 0.1206795172765851, Final Batch Loss: 0.11469320952892303\n",
      "Epoch 2939, Loss: 0.03156312834471464, Final Batch Loss: 0.007408098317682743\n",
      "Epoch 2940, Loss: 0.05192989716306329, Final Batch Loss: 0.046169035136699677\n",
      "Epoch 2941, Loss: 0.06636142870411277, Final Batch Loss: 0.0046165152452886105\n",
      "Epoch 2942, Loss: 0.030281946063041687, Final Batch Loss: 0.010089630261063576\n",
      "Epoch 2943, Loss: 0.06186726689338684, Final Batch Loss: 0.02783576026558876\n",
      "Epoch 2944, Loss: 0.044245912693440914, Final Batch Loss: 0.036605365574359894\n",
      "Epoch 2945, Loss: 0.028882427141070366, Final Batch Loss: 0.011158762499690056\n",
      "Epoch 2946, Loss: 0.032215334475040436, Final Batch Loss: 0.017481502145528793\n",
      "Epoch 2947, Loss: 0.10441870428621769, Final Batch Loss: 0.026066096499562263\n",
      "Epoch 2948, Loss: 0.04476754041388631, Final Batch Loss: 0.003947005141526461\n",
      "Epoch 2949, Loss: 0.01960424706339836, Final Batch Loss: 0.006916997954249382\n",
      "Epoch 2950, Loss: 0.048705048859119415, Final Batch Loss: 0.03940414637327194\n",
      "Epoch 2951, Loss: 0.046581169590353966, Final Batch Loss: 0.030937964096665382\n",
      "Epoch 2952, Loss: 0.009368774713948369, Final Batch Loss: 0.006705611478537321\n",
      "Epoch 2953, Loss: 0.057080257683992386, Final Batch Loss: 0.047151386737823486\n",
      "Epoch 2954, Loss: 0.030269773676991463, Final Batch Loss: 0.0035676956176757812\n",
      "Epoch 2955, Loss: 0.02458646334707737, Final Batch Loss: 0.01694885641336441\n",
      "Epoch 2956, Loss: 0.015613727271556854, Final Batch Loss: 0.01036893017590046\n",
      "Epoch 2957, Loss: 0.021129156928509474, Final Batch Loss: 0.0032102162949740887\n",
      "Epoch 2958, Loss: 0.0702016488648951, Final Batch Loss: 0.06751222163438797\n",
      "Epoch 2959, Loss: 0.04622053075581789, Final Batch Loss: 0.009860341437160969\n",
      "Epoch 2960, Loss: 0.03455170523375273, Final Batch Loss: 0.01992310769855976\n",
      "Epoch 2961, Loss: 0.024849737994372845, Final Batch Loss: 0.015278774313628674\n",
      "Epoch 2962, Loss: 0.016944630071520805, Final Batch Loss: 0.005536660552024841\n",
      "Epoch 2963, Loss: 0.02252284763380885, Final Batch Loss: 0.017382973805069923\n",
      "Epoch 2964, Loss: 0.04009264428168535, Final Batch Loss: 0.004094772972166538\n",
      "Epoch 2965, Loss: 0.04360414668917656, Final Batch Loss: 0.027592403814196587\n",
      "Epoch 2966, Loss: 0.046694522723555565, Final Batch Loss: 0.01864614337682724\n",
      "Epoch 2967, Loss: 0.011802286375313997, Final Batch Loss: 0.005771597381681204\n",
      "Epoch 2968, Loss: 0.04803110845386982, Final Batch Loss: 0.0257076695561409\n",
      "Epoch 2969, Loss: 0.08423997834324837, Final Batch Loss: 0.054220594465732574\n",
      "Epoch 2970, Loss: 0.017571761272847652, Final Batch Loss: 0.009198090992867947\n",
      "Epoch 2971, Loss: 0.019047857262194157, Final Batch Loss: 0.00286745373159647\n",
      "Epoch 2972, Loss: 0.04617086239159107, Final Batch Loss: 0.031504493206739426\n",
      "Epoch 2973, Loss: 0.020070225466042757, Final Batch Loss: 0.00692133279517293\n",
      "Epoch 2974, Loss: 0.037723975256085396, Final Batch Loss: 0.01576012186706066\n",
      "Epoch 2975, Loss: 0.02621324360370636, Final Batch Loss: 0.011102431453764439\n",
      "Epoch 2976, Loss: 0.08636892214417458, Final Batch Loss: 0.032222144305706024\n",
      "Epoch 2977, Loss: 0.0436050221323967, Final Batch Loss: 0.024965275079011917\n",
      "Epoch 2978, Loss: 0.08231922797858715, Final Batch Loss: 0.07221681624650955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2979, Loss: 0.08296849206089973, Final Batch Loss: 0.07232474535703659\n",
      "Epoch 2980, Loss: 0.12945858389139175, Final Batch Loss: 0.04929972440004349\n",
      "Epoch 2981, Loss: 0.11901223286986351, Final Batch Loss: 0.08415508270263672\n",
      "Epoch 2982, Loss: 0.0708109624683857, Final Batch Loss: 0.03626696765422821\n",
      "Epoch 2983, Loss: 0.030322629027068615, Final Batch Loss: 0.013469993136823177\n",
      "Epoch 2984, Loss: 0.015101355966180563, Final Batch Loss: 0.004172453191131353\n",
      "Epoch 2985, Loss: 0.04205389739945531, Final Batch Loss: 0.03467163071036339\n",
      "Epoch 2986, Loss: 0.03718954510986805, Final Batch Loss: 0.02134830504655838\n",
      "Epoch 2987, Loss: 0.08089518547058105, Final Batch Loss: 0.06779728829860687\n",
      "Epoch 2988, Loss: 0.018494002288207412, Final Batch Loss: 0.0038411689456552267\n",
      "Epoch 2989, Loss: 0.017437496222555637, Final Batch Loss: 0.00894775241613388\n",
      "Epoch 2990, Loss: 0.048098220489919186, Final Batch Loss: 0.035812798887491226\n",
      "Epoch 2991, Loss: 0.024244675412774086, Final Batch Loss: 0.010430550202727318\n",
      "Epoch 2992, Loss: 0.029122899752110243, Final Batch Loss: 0.02190663293004036\n",
      "Epoch 2993, Loss: 0.012286831624805927, Final Batch Loss: 0.004310512915253639\n",
      "Epoch 2994, Loss: 0.037211122224107385, Final Batch Loss: 0.03346729278564453\n",
      "Epoch 2995, Loss: 0.08544336631894112, Final Batch Loss: 0.03210372477769852\n",
      "Epoch 2996, Loss: 0.07771573448553681, Final Batch Loss: 0.07094552367925644\n",
      "Epoch 2997, Loss: 0.038275593891739845, Final Batch Loss: 0.01847688853740692\n",
      "Epoch 2998, Loss: 0.02675822377204895, Final Batch Loss: 0.018027622252702713\n",
      "Epoch 2999, Loss: 0.05609416915103793, Final Batch Loss: 0.048954252153635025\n",
      "Epoch 3000, Loss: 0.01443308312445879, Final Batch Loss: 0.006906571332365274\n",
      "Epoch 3001, Loss: 0.08483289368450642, Final Batch Loss: 0.057590365409851074\n",
      "Epoch 3002, Loss: 0.0501857646740973, Final Batch Loss: 0.044813163578510284\n",
      "Epoch 3003, Loss: 0.05754139460623264, Final Batch Loss: 0.03321973979473114\n",
      "Epoch 3004, Loss: 0.04989215359091759, Final Batch Loss: 0.024793270975351334\n",
      "Epoch 3005, Loss: 0.010933509562164545, Final Batch Loss: 0.004070605151355267\n",
      "Epoch 3006, Loss: 0.00813309452496469, Final Batch Loss: 0.002301506930962205\n",
      "Epoch 3007, Loss: 0.04734128434211016, Final Batch Loss: 0.03530426695942879\n",
      "Epoch 3008, Loss: 0.049902068451046944, Final Batch Loss: 0.0071814823895692825\n",
      "Epoch 3009, Loss: 0.014552149455994368, Final Batch Loss: 0.00772914569824934\n",
      "Epoch 3010, Loss: 0.046504292637109756, Final Batch Loss: 0.03457446023821831\n",
      "Epoch 3011, Loss: 0.025935033103451133, Final Batch Loss: 0.0034694296773523092\n",
      "Epoch 3012, Loss: 0.07369349151849747, Final Batch Loss: 0.03706684336066246\n",
      "Epoch 3013, Loss: 0.029358217492699623, Final Batch Loss: 0.008759820833802223\n",
      "Epoch 3014, Loss: 0.027937553822994232, Final Batch Loss: 0.01850341632962227\n",
      "Epoch 3015, Loss: 0.021867552772164345, Final Batch Loss: 0.008947840891778469\n",
      "Epoch 3016, Loss: 0.05438877083361149, Final Batch Loss: 0.021099606528878212\n",
      "Epoch 3017, Loss: 0.03286911081522703, Final Batch Loss: 0.018795840442180634\n",
      "Epoch 3018, Loss: 0.11305373534560204, Final Batch Loss: 0.05511198937892914\n",
      "Epoch 3019, Loss: 0.012480264529585838, Final Batch Loss: 0.0036917496472597122\n",
      "Epoch 3020, Loss: 0.03669635974802077, Final Batch Loss: 0.0013510289136320353\n",
      "Epoch 3021, Loss: 0.012793115573003888, Final Batch Loss: 0.008892464451491833\n",
      "Epoch 3022, Loss: 0.004829591605812311, Final Batch Loss: 0.0015148371458053589\n",
      "Epoch 3023, Loss: 0.01360336598008871, Final Batch Loss: 0.005882365629076958\n",
      "Epoch 3024, Loss: 0.027580599300563335, Final Batch Loss: 0.012704632245004177\n",
      "Epoch 3025, Loss: 0.055587561801075935, Final Batch Loss: 0.03537854179739952\n",
      "Epoch 3026, Loss: 0.06782274227589369, Final Batch Loss: 0.06360975652933121\n",
      "Epoch 3027, Loss: 0.014687188202515244, Final Batch Loss: 0.01086749043315649\n",
      "Epoch 3028, Loss: 0.03788631595671177, Final Batch Loss: 0.006913192570209503\n",
      "Epoch 3029, Loss: 0.04267683997750282, Final Batch Loss: 0.025191230699419975\n",
      "Epoch 3030, Loss: 0.037155899219214916, Final Batch Loss: 0.005693691782653332\n",
      "Epoch 3031, Loss: 0.03670291230082512, Final Batch Loss: 0.016037246212363243\n",
      "Epoch 3032, Loss: 0.02408737037330866, Final Batch Loss: 0.013452073559165001\n",
      "Epoch 3033, Loss: 0.018450682517141104, Final Batch Loss: 0.013161878101527691\n",
      "Epoch 3034, Loss: 0.03237363789230585, Final Batch Loss: 0.009555377997457981\n",
      "Epoch 3035, Loss: 0.013739385176450014, Final Batch Loss: 0.0049961223267018795\n",
      "Epoch 3036, Loss: 0.04349437216296792, Final Batch Loss: 0.004715906921774149\n",
      "Epoch 3037, Loss: 0.009757502470165491, Final Batch Loss: 0.004207015503197908\n",
      "Epoch 3038, Loss: 0.05825331062078476, Final Batch Loss: 0.0012845024466514587\n",
      "Epoch 3039, Loss: 0.022437925916165113, Final Batch Loss: 0.0039695012383162975\n",
      "Epoch 3040, Loss: 0.026809750124812126, Final Batch Loss: 0.016028743237257004\n",
      "Epoch 3041, Loss: 0.03739551454782486, Final Batch Loss: 0.023883190006017685\n",
      "Epoch 3042, Loss: 0.005021790973842144, Final Batch Loss: 0.0021691834554076195\n",
      "Epoch 3043, Loss: 0.010280127171427011, Final Batch Loss: 0.004983838647603989\n",
      "Epoch 3044, Loss: 0.014721357263624668, Final Batch Loss: 0.004416674375534058\n",
      "Epoch 3045, Loss: 0.05863192514516413, Final Batch Loss: 0.05513939633965492\n",
      "Epoch 3046, Loss: 0.041636254638433456, Final Batch Loss: 0.026751460507512093\n",
      "Epoch 3047, Loss: 0.015608259942382574, Final Batch Loss: 0.011036700569093227\n",
      "Epoch 3048, Loss: 0.024937439244240522, Final Batch Loss: 0.004735527094453573\n",
      "Epoch 3049, Loss: 0.06150802131742239, Final Batch Loss: 0.010875619016587734\n",
      "Epoch 3050, Loss: 0.03873972687870264, Final Batch Loss: 0.006189913488924503\n",
      "Epoch 3051, Loss: 0.01748963398858905, Final Batch Loss: 0.010319347493350506\n",
      "Epoch 3052, Loss: 0.062198830768465996, Final Batch Loss: 0.03588470444083214\n",
      "Epoch 3053, Loss: 0.019488335121423006, Final Batch Loss: 0.014358648099005222\n",
      "Epoch 3054, Loss: 0.053793749772012234, Final Batch Loss: 0.043080128729343414\n",
      "Epoch 3055, Loss: 0.014332750346511602, Final Batch Loss: 0.006077112164348364\n",
      "Epoch 3056, Loss: 0.04070248547941446, Final Batch Loss: 0.005277981050312519\n",
      "Epoch 3057, Loss: 0.03870456060394645, Final Batch Loss: 0.0054841130040585995\n",
      "Epoch 3058, Loss: 0.006786639103665948, Final Batch Loss: 0.002383632818236947\n",
      "Epoch 3059, Loss: 0.011372406035661697, Final Batch Loss: 0.005895417183637619\n",
      "Epoch 3060, Loss: 0.011460069799795747, Final Batch Loss: 0.0037869152147322893\n",
      "Epoch 3061, Loss: 0.005294736358337104, Final Batch Loss: 0.0008876322535797954\n",
      "Epoch 3062, Loss: 0.06567342299968004, Final Batch Loss: 0.005809460766613483\n",
      "Epoch 3063, Loss: 0.04951113648712635, Final Batch Loss: 0.037477873265743256\n",
      "Epoch 3064, Loss: 0.014188751578330994, Final Batch Loss: 0.00909703504294157\n",
      "Epoch 3065, Loss: 0.009142672875896096, Final Batch Loss: 0.0034239154774695635\n",
      "Epoch 3066, Loss: 0.029478524811565876, Final Batch Loss: 0.00975359883159399\n",
      "Epoch 3067, Loss: 0.0381728820502758, Final Batch Loss: 0.024403996765613556\n",
      "Epoch 3068, Loss: 0.019354232819750905, Final Batch Loss: 0.001463213237002492\n",
      "Epoch 3069, Loss: 0.018310973420739174, Final Batch Loss: 0.003271453082561493\n",
      "Epoch 3070, Loss: 0.01685910183005035, Final Batch Loss: 0.0023109938483685255\n",
      "Epoch 3071, Loss: 0.033649838995188475, Final Batch Loss: 0.007550505455583334\n",
      "Epoch 3072, Loss: 0.010760062374174595, Final Batch Loss: 0.006063198670744896\n",
      "Epoch 3073, Loss: 0.00559856544714421, Final Batch Loss: 0.004451611544936895\n",
      "Epoch 3074, Loss: 0.013397693634033203, Final Batch Loss: 0.005891432054340839\n",
      "Epoch 3075, Loss: 0.017479588743299246, Final Batch Loss: 0.00435861898586154\n",
      "Epoch 3076, Loss: 0.00916564860381186, Final Batch Loss: 0.0023958010133355856\n",
      "Epoch 3077, Loss: 0.01232330035418272, Final Batch Loss: 0.007478612475097179\n",
      "Epoch 3078, Loss: 0.009919550735503435, Final Batch Loss: 0.0049307625740766525\n",
      "Epoch 3079, Loss: 0.011322405422106385, Final Batch Loss: 0.008001910522580147\n",
      "Epoch 3080, Loss: 0.014788074884563684, Final Batch Loss: 0.0060204374603927135\n",
      "Epoch 3081, Loss: 0.05174623429775238, Final Batch Loss: 0.04611564055085182\n",
      "Epoch 3082, Loss: 0.01988632942084223, Final Batch Loss: 0.001897593610920012\n",
      "Epoch 3083, Loss: 0.01862144353799522, Final Batch Loss: 0.01480039767920971\n",
      "Epoch 3084, Loss: 0.011315631680190563, Final Batch Loss: 0.004775886423885822\n",
      "Epoch 3085, Loss: 0.019392103422433138, Final Batch Loss: 0.014584541320800781\n",
      "Epoch 3086, Loss: 0.006146332481876016, Final Batch Loss: 0.002853569108992815\n",
      "Epoch 3087, Loss: 0.030789409967837855, Final Batch Loss: 0.0004496418114285916\n",
      "Epoch 3088, Loss: 0.01039822306483984, Final Batch Loss: 0.005116966087371111\n",
      "Epoch 3089, Loss: 0.021796259563416243, Final Batch Loss: 0.007095288019627333\n",
      "Epoch 3090, Loss: 0.06433140183798969, Final Batch Loss: 0.06108776107430458\n",
      "Epoch 3091, Loss: 0.025812389503698796, Final Batch Loss: 0.000853050674777478\n",
      "Epoch 3092, Loss: 0.0301331696100533, Final Batch Loss: 0.022363193333148956\n",
      "Epoch 3093, Loss: 0.03302582981996238, Final Batch Loss: 0.029792949557304382\n",
      "Epoch 3094, Loss: 0.05438132677227259, Final Batch Loss: 0.006817632354795933\n",
      "Epoch 3095, Loss: 0.06956769339740276, Final Batch Loss: 0.012956308200955391\n",
      "Epoch 3096, Loss: 0.13968657329678535, Final Batch Loss: 0.06247767433524132\n",
      "Epoch 3097, Loss: 0.033495753072202206, Final Batch Loss: 0.005684630014002323\n",
      "Epoch 3098, Loss: 0.013638949953019619, Final Batch Loss: 0.005442481487989426\n",
      "Epoch 3099, Loss: 0.019043415319174528, Final Batch Loss: 0.014704331755638123\n",
      "Epoch 3100, Loss: 0.026250015944242477, Final Batch Loss: 0.01276038121432066\n",
      "Epoch 3101, Loss: 0.00522598740644753, Final Batch Loss: 0.0032492673490196466\n",
      "Epoch 3102, Loss: 0.014068947872146964, Final Batch Loss: 0.011692997999489307\n",
      "Epoch 3103, Loss: 0.010476029943674803, Final Batch Loss: 0.0022095092572271824\n",
      "Epoch 3104, Loss: 0.013052141293883324, Final Batch Loss: 0.0022141840308904648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3105, Loss: 0.023016632068902254, Final Batch Loss: 0.020008498802781105\n",
      "Epoch 3106, Loss: 0.020921033108606935, Final Batch Loss: 0.0032078514341264963\n",
      "Epoch 3107, Loss: 0.05876220669597387, Final Batch Loss: 0.04723726585507393\n",
      "Epoch 3108, Loss: 0.01113569876179099, Final Batch Loss: 0.004316949751228094\n",
      "Epoch 3109, Loss: 0.029986058827489614, Final Batch Loss: 0.003975329454988241\n",
      "Epoch 3110, Loss: 0.046531167812645435, Final Batch Loss: 0.03224172070622444\n",
      "Epoch 3111, Loss: 0.06303316354751587, Final Batch Loss: 0.028378017246723175\n",
      "Epoch 3112, Loss: 0.10319739580154419, Final Batch Loss: 0.058421120047569275\n",
      "Epoch 3113, Loss: 0.037658583372831345, Final Batch Loss: 0.028187133371829987\n",
      "Epoch 3114, Loss: 0.035808075219392776, Final Batch Loss: 0.015224358066916466\n",
      "Epoch 3115, Loss: 0.021153248380869627, Final Batch Loss: 0.017137648537755013\n",
      "Epoch 3116, Loss: 0.025768852792680264, Final Batch Loss: 0.02053704857826233\n",
      "Epoch 3117, Loss: 0.011894817929714918, Final Batch Loss: 0.008060703985393047\n",
      "Epoch 3118, Loss: 0.0739343878813088, Final Batch Loss: 0.0009598401375114918\n",
      "Epoch 3119, Loss: 0.01848745159804821, Final Batch Loss: 0.01262244675308466\n",
      "Epoch 3120, Loss: 0.01847686991095543, Final Batch Loss: 0.00436552707105875\n",
      "Epoch 3121, Loss: 0.017281016800552607, Final Batch Loss: 0.006516305264085531\n",
      "Epoch 3122, Loss: 0.01806520693935454, Final Batch Loss: 0.01427154615521431\n",
      "Epoch 3123, Loss: 0.01366634201258421, Final Batch Loss: 0.010522284545004368\n",
      "Epoch 3124, Loss: 0.011874182149767876, Final Batch Loss: 0.007808977272361517\n",
      "Epoch 3125, Loss: 0.0276276096701622, Final Batch Loss: 0.014577487483620644\n",
      "Epoch 3126, Loss: 0.020418351516127586, Final Batch Loss: 0.0055358391255140305\n",
      "Epoch 3127, Loss: 0.029076813254505396, Final Batch Loss: 0.021734068170189857\n",
      "Epoch 3128, Loss: 0.029590096324682236, Final Batch Loss: 0.015906060114502907\n",
      "Epoch 3129, Loss: 0.07293000724166632, Final Batch Loss: 0.0609896145761013\n",
      "Epoch 3130, Loss: 0.006321351043879986, Final Batch Loss: 0.00172044662758708\n",
      "Epoch 3131, Loss: 0.0647703493013978, Final Batch Loss: 0.004802894778549671\n",
      "Epoch 3132, Loss: 0.04176019877195358, Final Batch Loss: 0.016045089811086655\n",
      "Epoch 3133, Loss: 0.008030138444155455, Final Batch Loss: 0.003796100616455078\n",
      "Epoch 3134, Loss: 0.027264965698122978, Final Batch Loss: 0.015658879652619362\n",
      "Epoch 3135, Loss: 0.01651718281209469, Final Batch Loss: 0.010396689176559448\n",
      "Epoch 3136, Loss: 0.006819998612627387, Final Batch Loss: 0.0030665139202028513\n",
      "Epoch 3137, Loss: 0.00813937047496438, Final Batch Loss: 0.0019917525351047516\n",
      "Epoch 3138, Loss: 0.03600136190652847, Final Batch Loss: 0.021778536960482597\n",
      "Epoch 3139, Loss: 0.006844118004664779, Final Batch Loss: 0.003138213185593486\n",
      "Epoch 3140, Loss: 0.03431084239855409, Final Batch Loss: 0.028782840818166733\n",
      "Epoch 3141, Loss: 0.024465187918394804, Final Batch Loss: 0.02026664838194847\n",
      "Epoch 3142, Loss: 0.026406663469970226, Final Batch Loss: 0.009473063983023167\n",
      "Epoch 3143, Loss: 0.008882542490027845, Final Batch Loss: 0.001413483521901071\n",
      "Epoch 3144, Loss: 0.014970445539802313, Final Batch Loss: 0.009076758287847042\n",
      "Epoch 3145, Loss: 0.014569104416295886, Final Batch Loss: 0.011921835131943226\n",
      "Epoch 3146, Loss: 0.014580047689378262, Final Batch Loss: 0.01252688653767109\n",
      "Epoch 3147, Loss: 0.006843809504061937, Final Batch Loss: 0.002624841872602701\n",
      "Epoch 3148, Loss: 0.007859379053115845, Final Batch Loss: 0.005291496869176626\n",
      "Epoch 3149, Loss: 0.027167008258402348, Final Batch Loss: 0.018792245537042618\n",
      "Epoch 3150, Loss: 0.008469341788440943, Final Batch Loss: 0.00223609060049057\n",
      "Epoch 3151, Loss: 0.00977579434402287, Final Batch Loss: 0.001632496016100049\n",
      "Epoch 3152, Loss: 0.013487081974744797, Final Batch Loss: 0.007769718766212463\n",
      "Epoch 3153, Loss: 0.021459142677485943, Final Batch Loss: 0.0036337198689579964\n",
      "Epoch 3154, Loss: 0.0054481616243720055, Final Batch Loss: 0.0034035048447549343\n",
      "Epoch 3155, Loss: 0.027933851815760136, Final Batch Loss: 0.008535741828382015\n",
      "Epoch 3156, Loss: 0.007063568569719791, Final Batch Loss: 0.0023618568666279316\n",
      "Epoch 3157, Loss: 0.00318639149190858, Final Batch Loss: 0.0006563657079823315\n",
      "Epoch 3158, Loss: 0.006331333424896002, Final Batch Loss: 0.0032367617823183537\n",
      "Epoch 3159, Loss: 0.02005992829799652, Final Batch Loss: 0.015782075002789497\n",
      "Epoch 3160, Loss: 0.01416350295767188, Final Batch Loss: 0.009088519960641861\n",
      "Epoch 3161, Loss: 0.011855955934152007, Final Batch Loss: 0.00801775697618723\n",
      "Epoch 3162, Loss: 0.01475511770695448, Final Batch Loss: 0.004584489390254021\n",
      "Epoch 3163, Loss: 0.004187779035419226, Final Batch Loss: 0.0022365597542375326\n",
      "Epoch 3164, Loss: 0.0180726726539433, Final Batch Loss: 0.006598408799618483\n",
      "Epoch 3165, Loss: 0.018177601043134928, Final Batch Loss: 0.004682859871536493\n",
      "Epoch 3166, Loss: 0.03140858840197325, Final Batch Loss: 0.005465769208967686\n",
      "Epoch 3167, Loss: 0.023885974194854498, Final Batch Loss: 0.0025540622882544994\n",
      "Epoch 3168, Loss: 0.027676054975017905, Final Batch Loss: 0.02482234127819538\n",
      "Epoch 3169, Loss: 0.02550383470952511, Final Batch Loss: 0.005073413252830505\n",
      "Epoch 3170, Loss: 0.007692289538681507, Final Batch Loss: 0.0034665041603147984\n",
      "Epoch 3171, Loss: 0.04432841017842293, Final Batch Loss: 0.03668820858001709\n",
      "Epoch 3172, Loss: 0.026796913938596845, Final Batch Loss: 0.02297867275774479\n",
      "Epoch 3173, Loss: 0.0033222436904907227, Final Batch Loss: 0.0021095864940434694\n",
      "Epoch 3174, Loss: 0.04935337649658322, Final Batch Loss: 0.044074174016714096\n",
      "Epoch 3175, Loss: 0.01070404564961791, Final Batch Loss: 0.008479764685034752\n",
      "Epoch 3176, Loss: 0.15536954626441002, Final Batch Loss: 0.14751069247722626\n",
      "Epoch 3177, Loss: 0.026649704203009605, Final Batch Loss: 0.01133884396404028\n",
      "Epoch 3178, Loss: 0.005073315813206136, Final Batch Loss: 0.0011346688261255622\n",
      "Epoch 3179, Loss: 0.009943041484802961, Final Batch Loss: 0.0036823032423853874\n",
      "Epoch 3180, Loss: 0.009475324302911758, Final Batch Loss: 0.002412649802863598\n",
      "Epoch 3181, Loss: 0.006991710979491472, Final Batch Loss: 0.0030192341655492783\n",
      "Epoch 3182, Loss: 0.02163446880877018, Final Batch Loss: 0.015451446175575256\n",
      "Epoch 3183, Loss: 0.012408732902258635, Final Batch Loss: 0.0039956350810825825\n",
      "Epoch 3184, Loss: 0.021813266910612583, Final Batch Loss: 0.010615156963467598\n",
      "Epoch 3185, Loss: 0.010592499282211065, Final Batch Loss: 0.008020006120204926\n",
      "Epoch 3186, Loss: 0.006014847895130515, Final Batch Loss: 0.003100444795563817\n",
      "Epoch 3187, Loss: 0.011095028836280107, Final Batch Loss: 0.004884782247245312\n",
      "Epoch 3188, Loss: 0.007465633505489677, Final Batch Loss: 0.0008669746457599103\n",
      "Epoch 3189, Loss: 0.02288307575508952, Final Batch Loss: 0.00406475318595767\n",
      "Epoch 3190, Loss: 0.013965169433504343, Final Batch Loss: 0.011817061342298985\n",
      "Epoch 3191, Loss: 0.005199253908358514, Final Batch Loss: 0.0034091791603714228\n",
      "Epoch 3192, Loss: 0.01640544389374554, Final Batch Loss: 0.013710660859942436\n",
      "Epoch 3193, Loss: 0.04043101891875267, Final Batch Loss: 0.0314892940223217\n",
      "Epoch 3194, Loss: 0.013746079755946994, Final Batch Loss: 0.0030497971456497908\n",
      "Epoch 3195, Loss: 0.013001565588638186, Final Batch Loss: 0.002011375268921256\n",
      "Epoch 3196, Loss: 0.007392596337012947, Final Batch Loss: 0.0016342968447133899\n",
      "Epoch 3197, Loss: 0.012133456766605377, Final Batch Loss: 0.004136416129767895\n",
      "Epoch 3198, Loss: 0.007825470995157957, Final Batch Loss: 0.005506806541234255\n",
      "Epoch 3199, Loss: 0.007478767540305853, Final Batch Loss: 0.0031437347643077374\n",
      "Epoch 3200, Loss: 0.010304968105629086, Final Batch Loss: 0.0026739684399217367\n",
      "Epoch 3201, Loss: 0.015438027679920197, Final Batch Loss: 0.0033876271918416023\n",
      "Epoch 3202, Loss: 0.02374043659074232, Final Batch Loss: 0.0007210631738416851\n",
      "Epoch 3203, Loss: 0.0541445454582572, Final Batch Loss: 0.040306221693754196\n",
      "Epoch 3204, Loss: 0.02642897004261613, Final Batch Loss: 0.019185755401849747\n",
      "Epoch 3205, Loss: 0.01502535818144679, Final Batch Loss: 0.010591156780719757\n",
      "Epoch 3206, Loss: 0.07113115570973605, Final Batch Loss: 0.06973591446876526\n",
      "Epoch 3207, Loss: 0.022522523067891598, Final Batch Loss: 0.005931186489760876\n",
      "Epoch 3208, Loss: 0.006777859525755048, Final Batch Loss: 0.0024695980828255415\n",
      "Epoch 3209, Loss: 0.010359444189816713, Final Batch Loss: 0.005122524220496416\n",
      "Epoch 3210, Loss: 0.005442178575322032, Final Batch Loss: 0.0025656954385340214\n",
      "Epoch 3211, Loss: 0.006686248118057847, Final Batch Loss: 0.0033795286435633898\n",
      "Epoch 3212, Loss: 0.00828124606050551, Final Batch Loss: 0.006442734505981207\n",
      "Epoch 3213, Loss: 0.01894746092148125, Final Batch Loss: 0.015161020681262016\n",
      "Epoch 3214, Loss: 0.020924140699207783, Final Batch Loss: 0.00422720517963171\n",
      "Epoch 3215, Loss: 0.00860802480019629, Final Batch Loss: 0.003524219384416938\n",
      "Epoch 3216, Loss: 0.011572485091164708, Final Batch Loss: 0.008840842172503471\n",
      "Epoch 3217, Loss: 0.029320260509848595, Final Batch Loss: 0.005620589479804039\n",
      "Epoch 3218, Loss: 0.010083888308145106, Final Batch Loss: 0.0012513488763943315\n",
      "Epoch 3219, Loss: 0.015130579238757491, Final Batch Loss: 0.0023215615656226873\n",
      "Epoch 3220, Loss: 0.013630537316203117, Final Batch Loss: 0.00955978687852621\n",
      "Epoch 3221, Loss: 0.005975742475129664, Final Batch Loss: 0.004113622009754181\n",
      "Epoch 3222, Loss: 0.010576744563877583, Final Batch Loss: 0.008086212910711765\n",
      "Epoch 3223, Loss: 0.006902890163473785, Final Batch Loss: 0.0009406994795426726\n",
      "Epoch 3224, Loss: 0.015485109761357307, Final Batch Loss: 0.007061797194182873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3225, Loss: 0.006976307136937976, Final Batch Loss: 0.004091605544090271\n",
      "Epoch 3226, Loss: 0.023601236287504435, Final Batch Loss: 0.017247941344976425\n",
      "Epoch 3227, Loss: 0.007673779036849737, Final Batch Loss: 0.005454431753605604\n",
      "Epoch 3228, Loss: 0.011702001793310046, Final Batch Loss: 0.003460168605670333\n",
      "Epoch 3229, Loss: 0.03413777519017458, Final Batch Loss: 0.024326059967279434\n",
      "Epoch 3230, Loss: 0.011059419717639685, Final Batch Loss: 0.008419760502874851\n",
      "Epoch 3231, Loss: 0.016087989322841167, Final Batch Loss: 0.006138807162642479\n",
      "Epoch 3232, Loss: 0.010976462159305811, Final Batch Loss: 0.006702772807329893\n",
      "Epoch 3233, Loss: 0.04941196087747812, Final Batch Loss: 0.04259730130434036\n",
      "Epoch 3234, Loss: 0.015528036281466484, Final Batch Loss: 0.009701558388769627\n",
      "Epoch 3235, Loss: 0.03355518775060773, Final Batch Loss: 0.007699398789554834\n",
      "Epoch 3236, Loss: 0.0035415675956755877, Final Batch Loss: 0.0018213354051113129\n",
      "Epoch 3237, Loss: 0.08027087897062302, Final Batch Loss: 0.008132398128509521\n",
      "Epoch 3238, Loss: 0.02056297194212675, Final Batch Loss: 0.002327120862901211\n",
      "Epoch 3239, Loss: 0.006161410128697753, Final Batch Loss: 0.004436470102518797\n",
      "Epoch 3240, Loss: 0.024674969725310802, Final Batch Loss: 0.008097889833152294\n",
      "Epoch 3241, Loss: 0.014263638237025589, Final Batch Loss: 0.0008723968057893217\n",
      "Epoch 3242, Loss: 0.02613257337361574, Final Batch Loss: 0.024217935279011726\n",
      "Epoch 3243, Loss: 0.009617979638278484, Final Batch Loss: 0.003258942160755396\n",
      "Epoch 3244, Loss: 0.017682644072920084, Final Batch Loss: 0.01564895547926426\n",
      "Epoch 3245, Loss: 0.008091840893030167, Final Batch Loss: 0.0046913037076592445\n",
      "Epoch 3246, Loss: 0.019127281848341227, Final Batch Loss: 0.004435840528458357\n",
      "Epoch 3247, Loss: 0.017218382097780704, Final Batch Loss: 0.011569633148610592\n",
      "Epoch 3248, Loss: 0.013210128992795944, Final Batch Loss: 0.00610885675996542\n",
      "Epoch 3249, Loss: 0.012337503489106894, Final Batch Loss: 0.006308454088866711\n",
      "Epoch 3250, Loss: 0.014482874423265457, Final Batch Loss: 0.0063721369951963425\n",
      "Epoch 3251, Loss: 0.007115518907085061, Final Batch Loss: 0.0041925860568881035\n",
      "Epoch 3252, Loss: 0.019696680828928947, Final Batch Loss: 0.014895309694111347\n",
      "Epoch 3253, Loss: 0.01333205762784928, Final Batch Loss: 0.0010227457387372851\n",
      "Epoch 3254, Loss: 0.0032113947672769427, Final Batch Loss: 0.0005680486792698503\n",
      "Epoch 3255, Loss: 0.009540772996842861, Final Batch Loss: 0.004743343219161034\n",
      "Epoch 3256, Loss: 0.007578420219942927, Final Batch Loss: 0.006312511395663023\n",
      "Epoch 3257, Loss: 0.03775729797780514, Final Batch Loss: 0.033754877746105194\n",
      "Epoch 3258, Loss: 0.014834126457571983, Final Batch Loss: 0.0016623418778181076\n",
      "Epoch 3259, Loss: 0.011761919595301151, Final Batch Loss: 0.006540631875395775\n",
      "Epoch 3260, Loss: 0.04490909818559885, Final Batch Loss: 0.038777224719524384\n",
      "Epoch 3261, Loss: 0.009308481472544372, Final Batch Loss: 0.0015369657194241881\n",
      "Epoch 3262, Loss: 0.009146595606580377, Final Batch Loss: 0.005713684484362602\n",
      "Epoch 3263, Loss: 0.011627190513536334, Final Batch Loss: 0.008456092327833176\n",
      "Epoch 3264, Loss: 0.07476458698511124, Final Batch Loss: 0.03134625032544136\n",
      "Epoch 3265, Loss: 0.03808746254071593, Final Batch Loss: 0.006343720015138388\n",
      "Epoch 3266, Loss: 0.0046605311799794436, Final Batch Loss: 0.0016106986440718174\n",
      "Epoch 3267, Loss: 0.012797253206372261, Final Batch Loss: 0.0036519374698400497\n",
      "Epoch 3268, Loss: 0.012274033855646849, Final Batch Loss: 0.005412542726844549\n",
      "Epoch 3269, Loss: 0.014144925400614738, Final Batch Loss: 0.00560334324836731\n",
      "Epoch 3270, Loss: 0.04424054455012083, Final Batch Loss: 0.034604158252477646\n",
      "Epoch 3271, Loss: 0.031458109617233276, Final Batch Loss: 0.009935539215803146\n",
      "Epoch 3272, Loss: 0.037500739737879485, Final Batch Loss: 0.0007122016395442188\n",
      "Epoch 3273, Loss: 0.059339048340916634, Final Batch Loss: 0.0304014440625906\n",
      "Epoch 3274, Loss: 0.0353262685239315, Final Batch Loss: 0.010616971179842949\n",
      "Epoch 3275, Loss: 0.034405552665703, Final Batch Loss: 0.001698293606750667\n",
      "Epoch 3276, Loss: 0.05910496413707733, Final Batch Loss: 0.02056024596095085\n",
      "Epoch 3277, Loss: 0.0055857321713119745, Final Batch Loss: 0.0026882945094257593\n",
      "Epoch 3278, Loss: 0.03285006573423743, Final Batch Loss: 0.005915639456361532\n",
      "Epoch 3279, Loss: 0.0723047899082303, Final Batch Loss: 0.00609117466956377\n",
      "Epoch 3280, Loss: 0.05004122853279114, Final Batch Loss: 0.012794945389032364\n",
      "Epoch 3281, Loss: 0.033718316815793514, Final Batch Loss: 0.009981603361666203\n",
      "Epoch 3282, Loss: 0.061057474464178085, Final Batch Loss: 0.038390759378671646\n",
      "Epoch 3283, Loss: 0.0223878666292876, Final Batch Loss: 0.019329344853758812\n",
      "Epoch 3284, Loss: 0.014944208320230246, Final Batch Loss: 0.009502717293798923\n",
      "Epoch 3285, Loss: 0.07919885590672493, Final Batch Loss: 0.04648661985993385\n",
      "Epoch 3286, Loss: 0.02385028824210167, Final Batch Loss: 0.01588078774511814\n",
      "Epoch 3287, Loss: 0.022647729143500328, Final Batch Loss: 0.01300861593335867\n",
      "Epoch 3288, Loss: 0.010092431446537375, Final Batch Loss: 0.003210613736882806\n",
      "Epoch 3289, Loss: 0.010039834422059357, Final Batch Loss: 0.008149378001689911\n",
      "Epoch 3290, Loss: 0.007151996484026313, Final Batch Loss: 0.00453073438256979\n",
      "Epoch 3291, Loss: 0.03986095264554024, Final Batch Loss: 0.035213544964790344\n",
      "Epoch 3292, Loss: 0.007708783959969878, Final Batch Loss: 0.003518854035064578\n",
      "Epoch 3293, Loss: 0.027913661673665047, Final Batch Loss: 0.011255325749516487\n",
      "Epoch 3294, Loss: 0.01922555547207594, Final Batch Loss: 0.01163168903440237\n",
      "Epoch 3295, Loss: 0.008177390554919839, Final Batch Loss: 0.004403167404234409\n",
      "Epoch 3296, Loss: 0.01963061816059053, Final Batch Loss: 0.002222619717940688\n",
      "Epoch 3297, Loss: 0.012989297043532133, Final Batch Loss: 0.00930177140980959\n",
      "Epoch 3298, Loss: 0.008434575516730547, Final Batch Loss: 0.002597896382212639\n",
      "Epoch 3299, Loss: 0.014182768762111664, Final Batch Loss: 0.0008890330791473389\n",
      "Epoch 3300, Loss: 0.01919420249760151, Final Batch Loss: 0.012999683618545532\n",
      "Epoch 3301, Loss: 0.02444587741047144, Final Batch Loss: 0.014705881476402283\n",
      "Epoch 3302, Loss: 0.0366460217628628, Final Batch Loss: 0.003791539231315255\n",
      "Epoch 3303, Loss: 0.023438016418367624, Final Batch Loss: 0.007560445461422205\n",
      "Epoch 3304, Loss: 0.0052317967638373375, Final Batch Loss: 0.004549684468656778\n",
      "Epoch 3305, Loss: 0.004328065901063383, Final Batch Loss: 0.0013006288791075349\n",
      "Epoch 3306, Loss: 0.021706589497625828, Final Batch Loss: 0.013434669934213161\n",
      "Epoch 3307, Loss: 0.0076296181650832295, Final Batch Loss: 0.0017938512610271573\n",
      "Epoch 3308, Loss: 0.0279446872882545, Final Batch Loss: 0.0074431500397622585\n",
      "Epoch 3309, Loss: 0.024052602238953114, Final Batch Loss: 0.007120235823094845\n",
      "Epoch 3310, Loss: 0.11353664100170135, Final Batch Loss: 0.07855602353811264\n",
      "Epoch 3311, Loss: 0.03473407635465264, Final Batch Loss: 0.0039772395975887775\n",
      "Epoch 3312, Loss: 0.07538894796743989, Final Batch Loss: 0.005769456271082163\n",
      "Epoch 3313, Loss: 0.053804561495780945, Final Batch Loss: 0.0063800811767578125\n",
      "Epoch 3314, Loss: 0.006264654221013188, Final Batch Loss: 0.002483625430613756\n",
      "Epoch 3315, Loss: 0.01214059442281723, Final Batch Loss: 0.004201970063149929\n",
      "Epoch 3316, Loss: 0.008400277933105826, Final Batch Loss: 0.004889608360826969\n",
      "Epoch 3317, Loss: 0.024588195839896798, Final Batch Loss: 0.002661492908373475\n",
      "Epoch 3318, Loss: 0.09455590322613716, Final Batch Loss: 0.05876621603965759\n",
      "Epoch 3319, Loss: 0.04407853935845196, Final Batch Loss: 0.04070034250617027\n",
      "Epoch 3320, Loss: 0.019545921124517918, Final Batch Loss: 0.004159777425229549\n",
      "Epoch 3321, Loss: 0.0042919800616800785, Final Batch Loss: 0.0017175679095089436\n",
      "Epoch 3322, Loss: 0.014690090902149677, Final Batch Loss: 0.00878245010972023\n",
      "Epoch 3323, Loss: 0.08634621230885386, Final Batch Loss: 0.08430912345647812\n",
      "Epoch 3324, Loss: 0.020227824337780476, Final Batch Loss: 0.002957555465400219\n",
      "Epoch 3325, Loss: 0.0082205570070073, Final Batch Loss: 0.0013367970241233706\n",
      "Epoch 3326, Loss: 0.018356026615947485, Final Batch Loss: 0.00226266635581851\n",
      "Epoch 3327, Loss: 0.016440693754702806, Final Batch Loss: 0.0091535784304142\n",
      "Epoch 3328, Loss: 0.014234606176614761, Final Batch Loss: 0.007320166565477848\n",
      "Epoch 3329, Loss: 0.00676199299050495, Final Batch Loss: 0.0009752569603733718\n",
      "Epoch 3330, Loss: 0.03897092957049608, Final Batch Loss: 0.027752509340643883\n",
      "Epoch 3331, Loss: 0.045544739812612534, Final Batch Loss: 0.0026314333081245422\n",
      "Epoch 3332, Loss: 0.02404666319489479, Final Batch Loss: 0.011792813427746296\n",
      "Epoch 3333, Loss: 0.02898510592058301, Final Batch Loss: 0.005244192201644182\n",
      "Epoch 3334, Loss: 0.018251231871545315, Final Batch Loss: 0.004736640490591526\n",
      "Epoch 3335, Loss: 0.015075202798470855, Final Batch Loss: 0.0016592114698141813\n",
      "Epoch 3336, Loss: 0.020807304535992444, Final Batch Loss: 0.0012875489192083478\n",
      "Epoch 3337, Loss: 0.005646007601171732, Final Batch Loss: 0.0032409599516540766\n",
      "Epoch 3338, Loss: 0.05959645635448396, Final Batch Loss: 0.05785015970468521\n",
      "Epoch 3339, Loss: 0.009564118925482035, Final Batch Loss: 0.006269969046115875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3340, Loss: 0.007684219162911177, Final Batch Loss: 0.004625589586794376\n",
      "Epoch 3341, Loss: 0.011066286824643612, Final Batch Loss: 0.0023012692108750343\n",
      "Epoch 3342, Loss: 0.013770560268312693, Final Batch Loss: 0.0102362260222435\n",
      "Epoch 3343, Loss: 0.006569348508492112, Final Batch Loss: 0.002409851411357522\n",
      "Epoch 3344, Loss: 0.025399137753993273, Final Batch Loss: 0.02259734459221363\n",
      "Epoch 3345, Loss: 0.032217071391642094, Final Batch Loss: 0.010734417475759983\n",
      "Epoch 3346, Loss: 0.012765589635819197, Final Batch Loss: 0.00646128598600626\n",
      "Epoch 3347, Loss: 0.038686713203787804, Final Batch Loss: 0.010035200044512749\n",
      "Epoch 3348, Loss: 0.0180823034606874, Final Batch Loss: 0.004227772820740938\n",
      "Epoch 3349, Loss: 0.022120949812233448, Final Batch Loss: 0.010595262050628662\n",
      "Epoch 3350, Loss: 0.02501419559121132, Final Batch Loss: 0.008922932669520378\n",
      "Epoch 3351, Loss: 0.014863896649330854, Final Batch Loss: 0.0040893531404435635\n",
      "Epoch 3352, Loss: 0.057624468579888344, Final Batch Loss: 0.040888987481594086\n",
      "Epoch 3353, Loss: 0.012047536205500364, Final Batch Loss: 0.004269054159522057\n",
      "Epoch 3354, Loss: 0.005684506613761187, Final Batch Loss: 0.002869765041396022\n",
      "Epoch 3355, Loss: 0.01220526359975338, Final Batch Loss: 0.008250297978520393\n",
      "Epoch 3356, Loss: 0.0201967665925622, Final Batch Loss: 0.0067174555733799934\n",
      "Epoch 3357, Loss: 0.024448486976325512, Final Batch Loss: 0.008870325051248074\n",
      "Epoch 3358, Loss: 0.023268220596946776, Final Batch Loss: 0.0018951218808069825\n",
      "Epoch 3359, Loss: 0.005086441524326801, Final Batch Loss: 0.0029209465719759464\n",
      "Epoch 3360, Loss: 0.007793293567374349, Final Batch Loss: 0.0012990084942430258\n",
      "Epoch 3361, Loss: 0.008671840652823448, Final Batch Loss: 0.0014658449217677116\n",
      "Epoch 3362, Loss: 0.027145170839503407, Final Batch Loss: 0.0016045898664742708\n",
      "Epoch 3363, Loss: 0.015481406822800636, Final Batch Loss: 0.010044317692518234\n",
      "Epoch 3364, Loss: 0.10472273081541061, Final Batch Loss: 0.06832475960254669\n",
      "Epoch 3365, Loss: 0.007961700903251767, Final Batch Loss: 0.0030908251646906137\n",
      "Epoch 3366, Loss: 0.01785436552017927, Final Batch Loss: 0.009027267806231976\n",
      "Epoch 3367, Loss: 0.006815238855779171, Final Batch Loss: 0.0009541562758386135\n",
      "Epoch 3368, Loss: 0.020674361439887434, Final Batch Loss: 0.0008906596922315657\n",
      "Epoch 3369, Loss: 0.007547152461484075, Final Batch Loss: 0.002489259699359536\n",
      "Epoch 3370, Loss: 0.014351835008710623, Final Batch Loss: 0.006011527497321367\n",
      "Epoch 3371, Loss: 0.011735823354683816, Final Batch Loss: 0.0016112768789753318\n",
      "Epoch 3372, Loss: 0.012349184602499008, Final Batch Loss: 0.003200788050889969\n",
      "Epoch 3373, Loss: 0.006898336345329881, Final Batch Loss: 0.005149284843355417\n",
      "Epoch 3374, Loss: 0.013282171683385968, Final Batch Loss: 0.0025851784739643335\n",
      "Epoch 3375, Loss: 0.023061987943947315, Final Batch Loss: 0.006781966425478458\n",
      "Epoch 3376, Loss: 0.009072857908904552, Final Batch Loss: 0.00568758137524128\n",
      "Epoch 3377, Loss: 0.015869088005274534, Final Batch Loss: 0.010089470073580742\n",
      "Epoch 3378, Loss: 0.01491113705560565, Final Batch Loss: 0.004864186514168978\n",
      "Epoch 3379, Loss: 0.03531387308612466, Final Batch Loss: 0.0040054419077932835\n",
      "Epoch 3380, Loss: 0.005976318847388029, Final Batch Loss: 0.004651397932320833\n",
      "Epoch 3381, Loss: 0.04939120355993509, Final Batch Loss: 0.04195744916796684\n",
      "Epoch 3382, Loss: 0.010312253376469016, Final Batch Loss: 0.006610651966184378\n",
      "Epoch 3383, Loss: 0.005636273301206529, Final Batch Loss: 0.0016249333275482059\n",
      "Epoch 3384, Loss: 0.015844011213630438, Final Batch Loss: 0.003117096144706011\n",
      "Epoch 3385, Loss: 0.014702366199344397, Final Batch Loss: 0.007912060245871544\n",
      "Epoch 3386, Loss: 0.0497032580897212, Final Batch Loss: 0.0038073277100920677\n",
      "Epoch 3387, Loss: 0.005433267098851502, Final Batch Loss: 0.0017347530229017138\n",
      "Epoch 3388, Loss: 0.014714595628902316, Final Batch Loss: 0.0027089861687272787\n",
      "Epoch 3389, Loss: 0.004861220484599471, Final Batch Loss: 0.0026400929782539606\n",
      "Epoch 3390, Loss: 0.04339172784239054, Final Batch Loss: 0.0004209587350487709\n",
      "Epoch 3391, Loss: 0.012784673366695642, Final Batch Loss: 0.0047598169185221195\n",
      "Epoch 3392, Loss: 0.011168068740516901, Final Batch Loss: 0.00456802174448967\n",
      "Epoch 3393, Loss: 0.006959032500162721, Final Batch Loss: 0.002043944550678134\n",
      "Epoch 3394, Loss: 0.00500765978358686, Final Batch Loss: 0.00209855567663908\n",
      "Epoch 3395, Loss: 0.003799398080445826, Final Batch Loss: 0.0015588764799758792\n",
      "Epoch 3396, Loss: 0.0033303402015008032, Final Batch Loss: 0.0005757851176895201\n",
      "Epoch 3397, Loss: 0.03880128194577992, Final Batch Loss: 0.0011946104932576418\n",
      "Epoch 3398, Loss: 0.02839017938822508, Final Batch Loss: 0.024074755609035492\n",
      "Epoch 3399, Loss: 0.007493332959711552, Final Batch Loss: 0.003533379640430212\n",
      "Epoch 3400, Loss: 0.01409714575856924, Final Batch Loss: 0.010054838843643665\n",
      "Epoch 3401, Loss: 0.00900063943117857, Final Batch Loss: 0.0022009112872183323\n",
      "Epoch 3402, Loss: 0.019912376534193754, Final Batch Loss: 0.016690006479620934\n",
      "Epoch 3403, Loss: 0.008436197647824883, Final Batch Loss: 0.004573578014969826\n",
      "Epoch 3404, Loss: 0.01801272016018629, Final Batch Loss: 0.009838295169174671\n",
      "Epoch 3405, Loss: 0.00796721177175641, Final Batch Loss: 0.001098310574889183\n",
      "Epoch 3406, Loss: 0.021816034452058375, Final Batch Loss: 0.0006041998276486993\n",
      "Epoch 3407, Loss: 0.02581009635468945, Final Batch Loss: 0.000700298638548702\n",
      "Epoch 3408, Loss: 0.007789937895722687, Final Batch Loss: 0.0019115201430395246\n",
      "Epoch 3409, Loss: 0.008072592318058014, Final Batch Loss: 0.0013990914449095726\n",
      "Epoch 3410, Loss: 0.025211956584826112, Final Batch Loss: 0.02311919443309307\n",
      "Epoch 3411, Loss: 0.03075175266712904, Final Batch Loss: 0.004363424144685268\n",
      "Epoch 3412, Loss: 0.009140010457485914, Final Batch Loss: 0.004191090352833271\n",
      "Epoch 3413, Loss: 0.030304024228826165, Final Batch Loss: 0.003218898782506585\n",
      "Epoch 3414, Loss: 0.1009359685704112, Final Batch Loss: 0.014964709989726543\n",
      "Epoch 3415, Loss: 0.05127361952327192, Final Batch Loss: 0.0036246830131858587\n",
      "Epoch 3416, Loss: 0.012307980563491583, Final Batch Loss: 0.00727098761126399\n",
      "Epoch 3417, Loss: 0.018935298547148705, Final Batch Loss: 0.009818796068429947\n",
      "Epoch 3418, Loss: 0.13912677019834518, Final Batch Loss: 0.12132594734430313\n",
      "Epoch 3419, Loss: 0.025421462953090668, Final Batch Loss: 0.01317709218710661\n",
      "Epoch 3420, Loss: 0.06577027030289173, Final Batch Loss: 0.049861107021570206\n",
      "Epoch 3421, Loss: 0.05486796796321869, Final Batch Loss: 0.018269658088684082\n",
      "Epoch 3422, Loss: 0.014563317410647869, Final Batch Loss: 0.010039597749710083\n",
      "Epoch 3423, Loss: 0.010955512057989836, Final Batch Loss: 0.005565456580370665\n",
      "Epoch 3424, Loss: 0.02561672730371356, Final Batch Loss: 0.02169131301343441\n",
      "Epoch 3425, Loss: 0.023902966640889645, Final Batch Loss: 0.012256698682904243\n",
      "Epoch 3426, Loss: 0.06568263564258814, Final Batch Loss: 0.015402239747345448\n",
      "Epoch 3427, Loss: 0.11554823070764542, Final Batch Loss: 0.04061085730791092\n",
      "Epoch 3428, Loss: 0.02090241201221943, Final Batch Loss: 0.001962488517165184\n",
      "Epoch 3429, Loss: 0.016461982391774654, Final Batch Loss: 0.012320993468165398\n",
      "Epoch 3430, Loss: 0.014028789009898901, Final Batch Loss: 0.007189477793872356\n",
      "Epoch 3431, Loss: 0.017595716286450624, Final Batch Loss: 0.006857364904135466\n",
      "Epoch 3432, Loss: 0.07632742589339614, Final Batch Loss: 0.06868519634008408\n",
      "Epoch 3433, Loss: 0.02940894430503249, Final Batch Loss: 0.027208900079131126\n",
      "Epoch 3434, Loss: 0.028960649855434895, Final Batch Loss: 0.011807483620941639\n",
      "Epoch 3435, Loss: 0.02057277923449874, Final Batch Loss: 0.013926293700933456\n",
      "Epoch 3436, Loss: 0.04520407319068909, Final Batch Loss: 0.024129115045070648\n",
      "Epoch 3437, Loss: 0.008842818439006805, Final Batch Loss: 0.003972525242716074\n",
      "Epoch 3438, Loss: 0.010395669844001532, Final Batch Loss: 0.0033738366328179836\n",
      "Epoch 3439, Loss: 0.005939572351053357, Final Batch Loss: 0.002244585892185569\n",
      "Epoch 3440, Loss: 0.01634773425757885, Final Batch Loss: 0.01080418936908245\n",
      "Epoch 3441, Loss: 0.06033776141703129, Final Batch Loss: 0.05550980567932129\n",
      "Epoch 3442, Loss: 0.02270686300471425, Final Batch Loss: 0.005711922887712717\n",
      "Epoch 3443, Loss: 0.025346871931105852, Final Batch Loss: 0.01969856582581997\n",
      "Epoch 3444, Loss: 0.03612990444526076, Final Batch Loss: 0.005719614680856466\n",
      "Epoch 3445, Loss: 0.014079809421673417, Final Batch Loss: 0.002029931405559182\n",
      "Epoch 3446, Loss: 0.05060736695304513, Final Batch Loss: 0.006241349969059229\n",
      "Epoch 3447, Loss: 0.006119700614362955, Final Batch Loss: 0.003967976197600365\n",
      "Epoch 3448, Loss: 0.00949822785332799, Final Batch Loss: 0.0030727600678801537\n",
      "Epoch 3449, Loss: 0.0381294199032709, Final Batch Loss: 0.03663196042180061\n",
      "Epoch 3450, Loss: 0.017822545487433672, Final Batch Loss: 0.0038837227039039135\n",
      "Epoch 3451, Loss: 0.06699564307928085, Final Batch Loss: 0.059148143976926804\n",
      "Epoch 3452, Loss: 0.02050239033997059, Final Batch Loss: 0.013347892090678215\n",
      "Epoch 3453, Loss: 0.007058789720758796, Final Batch Loss: 0.0032631850335747004\n",
      "Epoch 3454, Loss: 0.005233616568148136, Final Batch Loss: 0.00255081569775939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3455, Loss: 0.013260603416711092, Final Batch Loss: 0.01129404827952385\n",
      "Epoch 3456, Loss: 0.0187633135356009, Final Batch Loss: 0.014645452611148357\n",
      "Epoch 3457, Loss: 0.03763448866084218, Final Batch Loss: 0.006368730682879686\n",
      "Epoch 3458, Loss: 0.009166646283119917, Final Batch Loss: 0.00524690980091691\n",
      "Epoch 3459, Loss: 0.010341341840103269, Final Batch Loss: 0.002526273252442479\n",
      "Epoch 3460, Loss: 0.016007807571440935, Final Batch Loss: 0.009260301478207111\n",
      "Epoch 3461, Loss: 0.018230118905194104, Final Batch Loss: 0.0006289734737947583\n",
      "Epoch 3462, Loss: 0.023096939083188772, Final Batch Loss: 0.007392318453639746\n",
      "Epoch 3463, Loss: 0.01901493314653635, Final Batch Loss: 0.011841027066111565\n",
      "Epoch 3464, Loss: 0.016033050371333957, Final Batch Loss: 0.012301425449550152\n",
      "Epoch 3465, Loss: 0.011050236877053976, Final Batch Loss: 0.003073470201343298\n",
      "Epoch 3466, Loss: 0.024439562112092972, Final Batch Loss: 0.018610801547765732\n",
      "Epoch 3467, Loss: 0.014799445867538452, Final Batch Loss: 0.012818804942071438\n",
      "Epoch 3468, Loss: 0.023601477965712547, Final Batch Loss: 0.0049611665308475494\n",
      "Epoch 3469, Loss: 0.0096275006653741, Final Batch Loss: 0.001214962569065392\n",
      "Epoch 3470, Loss: 0.005441695800982416, Final Batch Loss: 0.0011084688594564795\n",
      "Epoch 3471, Loss: 0.02308903355151415, Final Batch Loss: 0.013659616932272911\n",
      "Epoch 3472, Loss: 0.038154893554747105, Final Batch Loss: 0.009450261481106281\n",
      "Epoch 3473, Loss: 0.01301626767963171, Final Batch Loss: 0.005442920606583357\n",
      "Epoch 3474, Loss: 0.0289667546749115, Final Batch Loss: 0.015567438676953316\n",
      "Epoch 3475, Loss: 0.04649388883262873, Final Batch Loss: 0.044726088643074036\n",
      "Epoch 3476, Loss: 0.035470700124278665, Final Batch Loss: 0.031780097633600235\n",
      "Epoch 3477, Loss: 0.011481075081974268, Final Batch Loss: 0.007427022326737642\n",
      "Epoch 3478, Loss: 0.04004852729849517, Final Batch Loss: 0.03730574622750282\n",
      "Epoch 3479, Loss: 0.03158209566026926, Final Batch Loss: 0.023147469386458397\n",
      "Epoch 3480, Loss: 0.023091886192560196, Final Batch Loss: 0.009272312745451927\n",
      "Epoch 3481, Loss: 0.006635461235418916, Final Batch Loss: 0.0033596863504499197\n",
      "Epoch 3482, Loss: 0.01571786357089877, Final Batch Loss: 0.0062392656691372395\n",
      "Epoch 3483, Loss: 0.008989130961708724, Final Batch Loss: 0.0018027046462520957\n",
      "Epoch 3484, Loss: 0.0036994032561779022, Final Batch Loss: 0.0013620390091091394\n",
      "Epoch 3485, Loss: 0.011857541278004646, Final Batch Loss: 0.00768894050270319\n",
      "Epoch 3486, Loss: 0.03389959526248276, Final Batch Loss: 0.001967569114640355\n",
      "Epoch 3487, Loss: 0.02161921188235283, Final Batch Loss: 0.008917825296521187\n",
      "Epoch 3488, Loss: 0.013349521672353148, Final Batch Loss: 0.011240765452384949\n",
      "Epoch 3489, Loss: 0.01296851271763444, Final Batch Loss: 0.0061280494555830956\n",
      "Epoch 3490, Loss: 0.009186944924294949, Final Batch Loss: 0.0031885425560176373\n",
      "Epoch 3491, Loss: 0.0177918984554708, Final Batch Loss: 0.007134516257792711\n",
      "Epoch 3492, Loss: 0.0108911560382694, Final Batch Loss: 0.0030338752549141645\n",
      "Epoch 3493, Loss: 0.004875502781942487, Final Batch Loss: 0.0022087953984737396\n",
      "Epoch 3494, Loss: 0.03947030729614198, Final Batch Loss: 0.03649766743183136\n",
      "Epoch 3495, Loss: 0.02028450951911509, Final Batch Loss: 0.01751965843141079\n",
      "Epoch 3496, Loss: 0.017608087975531816, Final Batch Loss: 0.004780690651386976\n",
      "Epoch 3497, Loss: 0.0031853566179051995, Final Batch Loss: 0.0016953966114670038\n",
      "Epoch 3498, Loss: 0.025305972434580326, Final Batch Loss: 0.015862474218010902\n",
      "Epoch 3499, Loss: 0.00874122092500329, Final Batch Loss: 0.00460463110357523\n",
      "Epoch 3500, Loss: 0.010880951536819339, Final Batch Loss: 0.0012451510410755873\n",
      "Epoch 3501, Loss: 0.004557396052405238, Final Batch Loss: 0.0009706425480544567\n",
      "Epoch 3502, Loss: 0.012582896859385073, Final Batch Loss: 0.0013681730488315225\n",
      "Epoch 3503, Loss: 0.0113211051793769, Final Batch Loss: 0.0012108908267691731\n",
      "Epoch 3504, Loss: 0.004785729222930968, Final Batch Loss: 0.0029477968346327543\n",
      "Epoch 3505, Loss: 0.029657745733857155, Final Batch Loss: 0.01205582357943058\n",
      "Epoch 3506, Loss: 0.006408703280612826, Final Batch Loss: 0.004263709299266338\n",
      "Epoch 3507, Loss: 0.03007574751973152, Final Batch Loss: 0.01227232813835144\n",
      "Epoch 3508, Loss: 0.007702400209382176, Final Batch Loss: 0.00399581715464592\n",
      "Epoch 3509, Loss: 0.021535255014896393, Final Batch Loss: 0.002559855580329895\n",
      "Epoch 3510, Loss: 0.005640539573505521, Final Batch Loss: 0.0025879384484142065\n",
      "Epoch 3511, Loss: 0.02709946036338806, Final Batch Loss: 0.010978497564792633\n",
      "Epoch 3512, Loss: 0.020761841908097267, Final Batch Loss: 0.012335503473877907\n",
      "Epoch 3513, Loss: 0.008292357320897281, Final Batch Loss: 0.0072980765253305435\n",
      "Epoch 3514, Loss: 0.02797520416788757, Final Batch Loss: 0.02622910402715206\n",
      "Epoch 3515, Loss: 0.010185262421146035, Final Batch Loss: 0.003694332903251052\n",
      "Epoch 3516, Loss: 0.032040967140346766, Final Batch Loss: 0.005260870326310396\n",
      "Epoch 3517, Loss: 0.005542581086046994, Final Batch Loss: 0.004206688608974218\n",
      "Epoch 3518, Loss: 0.011852675350382924, Final Batch Loss: 0.0010422917548567057\n",
      "Epoch 3519, Loss: 0.038847846910357475, Final Batch Loss: 0.0034818705171346664\n",
      "Epoch 3520, Loss: 0.01068220753222704, Final Batch Loss: 0.008106959983706474\n",
      "Epoch 3521, Loss: 0.004824555246159434, Final Batch Loss: 0.0026051492895931005\n",
      "Epoch 3522, Loss: 0.017516073770821095, Final Batch Loss: 0.005600961856544018\n",
      "Epoch 3523, Loss: 0.02060614782385528, Final Batch Loss: 0.018334686756134033\n",
      "Epoch 3524, Loss: 0.010270991828292608, Final Batch Loss: 0.004205124452710152\n",
      "Epoch 3525, Loss: 0.05650508287362754, Final Batch Loss: 0.054593637585639954\n",
      "Epoch 3526, Loss: 0.05385623639449477, Final Batch Loss: 0.007354834582656622\n",
      "Epoch 3527, Loss: 0.02046594233252108, Final Batch Loss: 0.016709743067622185\n",
      "Epoch 3528, Loss: 0.007570320973172784, Final Batch Loss: 0.0036113166715949774\n",
      "Epoch 3529, Loss: 0.0983332209289074, Final Batch Loss: 0.02290598675608635\n",
      "Epoch 3530, Loss: 0.012238797498866916, Final Batch Loss: 0.0033651001285761595\n",
      "Epoch 3531, Loss: 0.008495245594531298, Final Batch Loss: 0.002208313439041376\n",
      "Epoch 3532, Loss: 0.11178743466734886, Final Batch Loss: 0.055277422070503235\n",
      "Epoch 3533, Loss: 0.04066900163888931, Final Batch Loss: 0.03573964536190033\n",
      "Epoch 3534, Loss: 0.0049842470325529575, Final Batch Loss: 0.0004326780326664448\n",
      "Epoch 3535, Loss: 0.030797948129475117, Final Batch Loss: 0.024301614612340927\n",
      "Epoch 3536, Loss: 0.12887063063681126, Final Batch Loss: 0.12514041364192963\n",
      "Epoch 3537, Loss: 0.08076734468340874, Final Batch Loss: 0.047181520611047745\n",
      "Epoch 3538, Loss: 0.0760316257365048, Final Batch Loss: 0.06860394030809402\n",
      "Epoch 3539, Loss: 0.05197435477748513, Final Batch Loss: 0.007416764739900827\n",
      "Epoch 3540, Loss: 0.038018486462533474, Final Batch Loss: 0.031068015843629837\n",
      "Epoch 3541, Loss: 0.0881060753017664, Final Batch Loss: 0.060218315571546555\n",
      "Epoch 3542, Loss: 0.11394746787846088, Final Batch Loss: 0.01838485337793827\n",
      "Epoch 3543, Loss: 0.014532981440424919, Final Batch Loss: 0.007434309460222721\n",
      "Epoch 3544, Loss: 0.08082140237092972, Final Batch Loss: 0.0424564965069294\n",
      "Epoch 3545, Loss: 0.048655545338988304, Final Batch Loss: 0.011365639045834541\n",
      "Epoch 3546, Loss: 0.07187627092935145, Final Batch Loss: 0.0016602559480816126\n",
      "Epoch 3547, Loss: 0.03984936513006687, Final Batch Loss: 0.0350947380065918\n",
      "Epoch 3548, Loss: 0.05271556321531534, Final Batch Loss: 0.0066153304651379585\n",
      "Epoch 3549, Loss: 0.05404791980981827, Final Batch Loss: 0.016986854374408722\n",
      "Epoch 3550, Loss: 0.048433903604745865, Final Batch Loss: 0.03378214314579964\n",
      "Epoch 3551, Loss: 0.009027738589793444, Final Batch Loss: 0.007056527771055698\n",
      "Epoch 3552, Loss: 0.0257877497933805, Final Batch Loss: 0.003987306263297796\n",
      "Epoch 3553, Loss: 0.033145285211503506, Final Batch Loss: 0.012731659226119518\n",
      "Epoch 3554, Loss: 0.049311624839901924, Final Batch Loss: 0.017393669113516808\n",
      "Epoch 3555, Loss: 0.021066826535388827, Final Batch Loss: 0.0035739827435463667\n",
      "Epoch 3556, Loss: 0.025239691138267517, Final Batch Loss: 0.010944538749754429\n",
      "Epoch 3557, Loss: 0.0319045502692461, Final Batch Loss: 0.011623049154877663\n",
      "Epoch 3558, Loss: 0.012772585730999708, Final Batch Loss: 0.002598088700324297\n",
      "Epoch 3559, Loss: 0.012455043382942677, Final Batch Loss: 0.0062212590128183365\n",
      "Epoch 3560, Loss: 0.04602510901167989, Final Batch Loss: 0.0064773824997246265\n",
      "Epoch 3561, Loss: 0.07436633110046387, Final Batch Loss: 0.03897501900792122\n",
      "Epoch 3562, Loss: 0.0060683697229251266, Final Batch Loss: 0.000821636407636106\n",
      "Epoch 3563, Loss: 0.012824378907680511, Final Batch Loss: 0.008126881904900074\n",
      "Epoch 3564, Loss: 0.01997665362432599, Final Batch Loss: 0.016033470630645752\n",
      "Epoch 3565, Loss: 0.016580368857830763, Final Batch Loss: 0.00599345238879323\n",
      "Epoch 3566, Loss: 0.016120267566293478, Final Batch Loss: 0.0072624715976417065\n",
      "Epoch 3567, Loss: 0.024650935549288988, Final Batch Loss: 0.0047151935286819935\n",
      "Epoch 3568, Loss: 0.03045782959088683, Final Batch Loss: 0.002247545402497053\n",
      "Epoch 3569, Loss: 0.03871842660009861, Final Batch Loss: 0.019334252923727036\n",
      "Epoch 3570, Loss: 0.015119365882128477, Final Batch Loss: 0.008902712725102901\n",
      "Epoch 3571, Loss: 0.020629307720810175, Final Batch Loss: 0.007597006391733885\n",
      "Epoch 3572, Loss: 0.0500478558242321, Final Batch Loss: 0.02754536084830761\n",
      "Epoch 3573, Loss: 0.07746005430817604, Final Batch Loss: 0.042946573346853256\n",
      "Epoch 3574, Loss: 0.011305497959256172, Final Batch Loss: 0.0021518608555197716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3575, Loss: 0.07651745341718197, Final Batch Loss: 0.06478431820869446\n",
      "Epoch 3576, Loss: 0.025098437443375587, Final Batch Loss: 0.01529195811599493\n",
      "Epoch 3577, Loss: 0.015146953985095024, Final Batch Loss: 0.003878749907016754\n",
      "Epoch 3578, Loss: 0.013326691696420312, Final Batch Loss: 0.0037424510810524225\n",
      "Epoch 3579, Loss: 0.025110159069299698, Final Batch Loss: 0.006484769284725189\n",
      "Epoch 3580, Loss: 0.03377527557313442, Final Batch Loss: 0.017956966534256935\n",
      "Epoch 3581, Loss: 0.01657696720212698, Final Batch Loss: 0.007187828421592712\n",
      "Epoch 3582, Loss: 0.026193965459242463, Final Batch Loss: 0.003843538695946336\n",
      "Epoch 3583, Loss: 0.03338728891685605, Final Batch Loss: 0.006660322193056345\n",
      "Epoch 3584, Loss: 0.008943571476265788, Final Batch Loss: 0.002746652578935027\n",
      "Epoch 3585, Loss: 0.012569021433591843, Final Batch Loss: 0.007443873677402735\n",
      "Epoch 3586, Loss: 0.008361252024769783, Final Batch Loss: 0.0028132274746894836\n",
      "Epoch 3587, Loss: 0.006407710257917643, Final Batch Loss: 0.001961523201316595\n",
      "Epoch 3588, Loss: 0.016179651487618685, Final Batch Loss: 0.0022409246303141117\n",
      "Epoch 3589, Loss: 0.056241387501358986, Final Batch Loss: 0.05393190309405327\n",
      "Epoch 3590, Loss: 0.013619087403640151, Final Batch Loss: 0.002587123541161418\n",
      "Epoch 3591, Loss: 0.02703358663711697, Final Batch Loss: 0.025700494647026062\n",
      "Epoch 3592, Loss: 0.02954815188422799, Final Batch Loss: 0.005456211511045694\n",
      "Epoch 3593, Loss: 0.017751745879650116, Final Batch Loss: 0.004365000873804092\n",
      "Epoch 3594, Loss: 0.012992313830181956, Final Batch Loss: 0.00942725408822298\n",
      "Epoch 3595, Loss: 0.011430887039750814, Final Batch Loss: 0.007356421090662479\n",
      "Epoch 3596, Loss: 0.012578401248902082, Final Batch Loss: 0.003003911580890417\n",
      "Epoch 3597, Loss: 0.0067088427022099495, Final Batch Loss: 0.004442655481398106\n",
      "Epoch 3598, Loss: 0.017326679080724716, Final Batch Loss: 0.015120836906135082\n",
      "Epoch 3599, Loss: 0.04176537902094424, Final Batch Loss: 0.03929811343550682\n",
      "Epoch 3600, Loss: 0.028190613025799394, Final Batch Loss: 0.0030074717942625284\n",
      "Epoch 3601, Loss: 0.016141611617058516, Final Batch Loss: 0.00859612412750721\n",
      "Epoch 3602, Loss: 0.005947604542598128, Final Batch Loss: 0.0029167726170271635\n",
      "Epoch 3603, Loss: 0.01407524780370295, Final Batch Loss: 0.012255577370524406\n",
      "Epoch 3604, Loss: 0.033347765915095806, Final Batch Loss: 0.007428533397614956\n",
      "Epoch 3605, Loss: 0.017018207581713796, Final Batch Loss: 0.002475790912285447\n",
      "Epoch 3606, Loss: 0.029734761454164982, Final Batch Loss: 0.01502774003893137\n",
      "Epoch 3607, Loss: 0.018848260398954153, Final Batch Loss: 0.005977401044219732\n",
      "Epoch 3608, Loss: 0.01693951478227973, Final Batch Loss: 0.011766944080591202\n",
      "Epoch 3609, Loss: 0.009151550417300314, Final Batch Loss: 0.0007612755871377885\n",
      "Epoch 3610, Loss: 0.027039099019020796, Final Batch Loss: 0.02062826044857502\n",
      "Epoch 3611, Loss: 0.007945901365019381, Final Batch Loss: 0.00033717521000653505\n",
      "Epoch 3612, Loss: 0.0370815796777606, Final Batch Loss: 0.008025185205042362\n",
      "Epoch 3613, Loss: 0.014915156876668334, Final Batch Loss: 0.01152759324759245\n",
      "Epoch 3614, Loss: 0.01949821226298809, Final Batch Loss: 0.009498614817857742\n",
      "Epoch 3615, Loss: 0.00955884251743555, Final Batch Loss: 0.004243715666234493\n",
      "Epoch 3616, Loss: 0.0400503845885396, Final Batch Loss: 0.026926441118121147\n",
      "Epoch 3617, Loss: 0.026000981219112873, Final Batch Loss: 0.004645277746021748\n",
      "Epoch 3618, Loss: 0.01779770408757031, Final Batch Loss: 0.0030518595594912767\n",
      "Epoch 3619, Loss: 0.02825835533440113, Final Batch Loss: 0.015768753364682198\n",
      "Epoch 3620, Loss: 0.0125142487231642, Final Batch Loss: 0.003829485969617963\n",
      "Epoch 3621, Loss: 0.013917805626988411, Final Batch Loss: 0.002280222252011299\n",
      "Epoch 3622, Loss: 0.03154847864061594, Final Batch Loss: 0.012825808487832546\n",
      "Epoch 3623, Loss: 0.006251004058867693, Final Batch Loss: 0.003205255139619112\n",
      "Epoch 3624, Loss: 0.009895712602883577, Final Batch Loss: 0.004968893714249134\n",
      "Epoch 3625, Loss: 0.018886669306084514, Final Batch Loss: 0.0012026436161249876\n",
      "Epoch 3626, Loss: 0.014621289679780602, Final Batch Loss: 0.012009087018668652\n",
      "Epoch 3627, Loss: 0.07136999070644379, Final Batch Loss: 0.05752822011709213\n",
      "Epoch 3628, Loss: 0.007408296689391136, Final Batch Loss: 0.003281733952462673\n",
      "Epoch 3629, Loss: 0.007581465877592564, Final Batch Loss: 0.004885504953563213\n",
      "Epoch 3630, Loss: 0.012803928926587105, Final Batch Loss: 0.010821150615811348\n",
      "Epoch 3631, Loss: 0.02781419176608324, Final Batch Loss: 0.015088215470314026\n",
      "Epoch 3632, Loss: 0.04625258408486843, Final Batch Loss: 0.03839221969246864\n",
      "Epoch 3633, Loss: 0.009398901602253318, Final Batch Loss: 0.005912446416914463\n",
      "Epoch 3634, Loss: 0.0075452260207384825, Final Batch Loss: 0.004508209880441427\n",
      "Epoch 3635, Loss: 0.009562452090904117, Final Batch Loss: 0.0024769564624875784\n",
      "Epoch 3636, Loss: 0.006083925254642963, Final Batch Loss: 0.0032810806296765804\n",
      "Epoch 3637, Loss: 0.0272720605134964, Final Batch Loss: 0.017417652532458305\n",
      "Epoch 3638, Loss: 0.032457937370054424, Final Batch Loss: 0.030551426112651825\n",
      "Epoch 3639, Loss: 0.006682980747427791, Final Batch Loss: 0.005900866352021694\n",
      "Epoch 3640, Loss: 0.0042693037539720535, Final Batch Loss: 0.0019387947395443916\n",
      "Epoch 3641, Loss: 0.015850522788241506, Final Batch Loss: 0.00348838628269732\n",
      "Epoch 3642, Loss: 0.03260266687721014, Final Batch Loss: 0.024048270657658577\n",
      "Epoch 3643, Loss: 0.048557023517787457, Final Batch Loss: 0.007009982131421566\n",
      "Epoch 3644, Loss: 0.0273176790215075, Final Batch Loss: 0.024705884978175163\n",
      "Epoch 3645, Loss: 0.015118781942874193, Final Batch Loss: 0.005006824154406786\n",
      "Epoch 3646, Loss: 0.023832181002944708, Final Batch Loss: 0.006243057083338499\n",
      "Epoch 3647, Loss: 0.046478234231472015, Final Batch Loss: 0.028338532894849777\n",
      "Epoch 3648, Loss: 0.020999109838157892, Final Batch Loss: 0.0049927630461752415\n",
      "Epoch 3649, Loss: 0.004454504000023007, Final Batch Loss: 0.0025715476367622614\n",
      "Epoch 3650, Loss: 0.01190820150077343, Final Batch Loss: 0.0038272570818662643\n",
      "Epoch 3651, Loss: 0.021912694443017244, Final Batch Loss: 0.017009394243359566\n",
      "Epoch 3652, Loss: 0.019097867887467146, Final Batch Loss: 0.002020243089646101\n",
      "Epoch 3653, Loss: 0.03341980930417776, Final Batch Loss: 0.003985493443906307\n",
      "Epoch 3654, Loss: 0.006205618614330888, Final Batch Loss: 0.0033573422115296125\n",
      "Epoch 3655, Loss: 0.022736668586730957, Final Batch Loss: 0.011193792335689068\n",
      "Epoch 3656, Loss: 0.021080817095935345, Final Batch Loss: 0.018718140199780464\n",
      "Epoch 3657, Loss: 0.05281103681772947, Final Batch Loss: 0.0371960885822773\n",
      "Epoch 3658, Loss: 0.014421854168176651, Final Batch Loss: 0.009855853393673897\n",
      "Epoch 3659, Loss: 0.006745792692527175, Final Batch Loss: 0.004142991732805967\n",
      "Epoch 3660, Loss: 0.03453710360918194, Final Batch Loss: 0.0013317173579707742\n",
      "Epoch 3661, Loss: 0.009438434150069952, Final Batch Loss: 0.005677216686308384\n",
      "Epoch 3662, Loss: 0.031694434001110494, Final Batch Loss: 0.0011943815043196082\n",
      "Epoch 3663, Loss: 0.012997915968298912, Final Batch Loss: 0.007328036706894636\n",
      "Epoch 3664, Loss: 0.009484728099778295, Final Batch Loss: 0.005633895751088858\n",
      "Epoch 3665, Loss: 0.05838926136493683, Final Batch Loss: 0.03576259687542915\n",
      "Epoch 3666, Loss: 0.03514793247450143, Final Batch Loss: 0.0014609891222789884\n",
      "Epoch 3667, Loss: 0.007612245623022318, Final Batch Loss: 0.0040902444161474705\n",
      "Epoch 3668, Loss: 0.00958922691643238, Final Batch Loss: 0.004017540253698826\n",
      "Epoch 3669, Loss: 0.018437801161780953, Final Batch Loss: 0.015720462426543236\n",
      "Epoch 3670, Loss: 0.01604520110413432, Final Batch Loss: 0.004571716766804457\n",
      "Epoch 3671, Loss: 0.006884052534587681, Final Batch Loss: 0.0011270238319411874\n",
      "Epoch 3672, Loss: 0.009939300594851375, Final Batch Loss: 0.006210805382579565\n",
      "Epoch 3673, Loss: 0.010577255161479115, Final Batch Loss: 0.007560422644019127\n",
      "Epoch 3674, Loss: 0.014293472981080413, Final Batch Loss: 0.003860636381432414\n",
      "Epoch 3675, Loss: 0.04459351859986782, Final Batch Loss: 0.008052511140704155\n",
      "Epoch 3676, Loss: 0.004566922318190336, Final Batch Loss: 0.0028494643047451973\n",
      "Epoch 3677, Loss: 0.006831471575424075, Final Batch Loss: 0.004741526208817959\n",
      "Epoch 3678, Loss: 0.016840672120451927, Final Batch Loss: 0.008923356421291828\n",
      "Epoch 3679, Loss: 0.009231326403096318, Final Batch Loss: 0.007276992779225111\n",
      "Epoch 3680, Loss: 0.010272265179082751, Final Batch Loss: 0.006583840120583773\n",
      "Epoch 3681, Loss: 0.015605483204126358, Final Batch Loss: 0.007986954413354397\n",
      "Epoch 3682, Loss: 0.0171079293359071, Final Batch Loss: 0.014769106172025204\n",
      "Epoch 3683, Loss: 0.0060798353515565395, Final Batch Loss: 0.002184443175792694\n",
      "Epoch 3684, Loss: 0.01179070258513093, Final Batch Loss: 0.003465434070676565\n",
      "Epoch 3685, Loss: 0.017800410045310855, Final Batch Loss: 0.0005919493269175291\n",
      "Epoch 3686, Loss: 0.025640943087637424, Final Batch Loss: 0.012673689052462578\n",
      "Epoch 3687, Loss: 0.04406428337097168, Final Batch Loss: 0.025065068155527115\n",
      "Epoch 3688, Loss: 0.00934678316116333, Final Batch Loss: 0.0053411489352583885\n",
      "Epoch 3689, Loss: 0.015657483134418726, Final Batch Loss: 0.005895893555134535\n",
      "Epoch 3690, Loss: 0.010042148875072598, Final Batch Loss: 0.006981982383877039\n",
      "Epoch 3691, Loss: 0.023725210689008236, Final Batch Loss: 0.008649686351418495\n",
      "Epoch 3692, Loss: 0.017903366358950734, Final Batch Loss: 0.014299152418971062\n",
      "Epoch 3693, Loss: 0.009145128889940679, Final Batch Loss: 0.0015223178779706359\n",
      "Epoch 3694, Loss: 0.006128942593932152, Final Batch Loss: 0.0005186991766095161\n",
      "Epoch 3695, Loss: 0.01125340349972248, Final Batch Loss: 0.005323478952050209\n",
      "Epoch 3696, Loss: 0.005284253624267876, Final Batch Loss: 0.0010620775865390897\n",
      "Epoch 3697, Loss: 0.0037371155340224504, Final Batch Loss: 0.001544091384857893\n",
      "Epoch 3698, Loss: 0.0031967234099283814, Final Batch Loss: 0.0017552973004058003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3699, Loss: 0.0038037231424823403, Final Batch Loss: 0.0015049698995426297\n",
      "Epoch 3700, Loss: 0.00649760034866631, Final Batch Loss: 0.003825669176876545\n",
      "Epoch 3701, Loss: 0.018277657218277454, Final Batch Loss: 0.006952584721148014\n",
      "Epoch 3702, Loss: 0.007207342190667987, Final Batch Loss: 0.004724584985524416\n",
      "Epoch 3703, Loss: 0.01459820056334138, Final Batch Loss: 0.006828699726611376\n",
      "Epoch 3704, Loss: 0.017011865973472595, Final Batch Loss: 0.00888238288462162\n",
      "Epoch 3705, Loss: 0.0034657581709325314, Final Batch Loss: 0.001795925316400826\n",
      "Epoch 3706, Loss: 0.018818710930645466, Final Batch Loss: 0.012297973036766052\n",
      "Epoch 3707, Loss: 0.0038376249140128493, Final Batch Loss: 0.0026207834016531706\n",
      "Epoch 3708, Loss: 0.002778227557428181, Final Batch Loss: 0.0010629649041220546\n",
      "Epoch 3709, Loss: 0.009265174390748143, Final Batch Loss: 0.00591416098177433\n",
      "Epoch 3710, Loss: 0.038247922784648836, Final Batch Loss: 0.03655194118618965\n",
      "Epoch 3711, Loss: 0.00624117418192327, Final Batch Loss: 0.0013397790025919676\n",
      "Epoch 3712, Loss: 0.006368848844431341, Final Batch Loss: 0.0044288355857133865\n",
      "Epoch 3713, Loss: 0.03284394834190607, Final Batch Loss: 0.02385043166577816\n",
      "Epoch 3714, Loss: 0.007914629764854908, Final Batch Loss: 0.0034820144064724445\n",
      "Epoch 3715, Loss: 0.014228246407583356, Final Batch Loss: 0.010940790176391602\n",
      "Epoch 3716, Loss: 0.006539793219417334, Final Batch Loss: 0.002941657556220889\n",
      "Epoch 3717, Loss: 0.04433911060914397, Final Batch Loss: 0.04296277090907097\n",
      "Epoch 3718, Loss: 0.006402146304026246, Final Batch Loss: 0.002235777908936143\n",
      "Epoch 3719, Loss: 0.028915083035826683, Final Batch Loss: 0.0014983154833316803\n",
      "Epoch 3720, Loss: 0.003819705918431282, Final Batch Loss: 0.002678561955690384\n",
      "Epoch 3721, Loss: 0.021415541414171457, Final Batch Loss: 0.00780335022136569\n",
      "Epoch 3722, Loss: 0.04768826253712177, Final Batch Loss: 0.016266951337456703\n",
      "Epoch 3723, Loss: 0.007123228861019015, Final Batch Loss: 0.0025917261373251677\n",
      "Epoch 3724, Loss: 0.0038309660740196705, Final Batch Loss: 0.0025091629941016436\n",
      "Epoch 3725, Loss: 0.031207064166665077, Final Batch Loss: 0.02809731848537922\n",
      "Epoch 3726, Loss: 0.023880098946392536, Final Batch Loss: 0.004564107395708561\n",
      "Epoch 3727, Loss: 0.008174130111001432, Final Batch Loss: 0.0010915942257270217\n",
      "Epoch 3728, Loss: 0.028263751417398453, Final Batch Loss: 0.024907024577260017\n",
      "Epoch 3729, Loss: 0.02877430513035506, Final Batch Loss: 0.0015179523034021258\n",
      "Epoch 3730, Loss: 0.03152109566144645, Final Batch Loss: 0.0035692851524800062\n",
      "Epoch 3731, Loss: 0.016596578992903233, Final Batch Loss: 0.008648538962006569\n",
      "Epoch 3732, Loss: 0.041832192335277796, Final Batch Loss: 0.0060081989504396915\n",
      "Epoch 3733, Loss: 0.023885113187134266, Final Batch Loss: 0.002733140252530575\n",
      "Epoch 3734, Loss: 0.04204564169049263, Final Batch Loss: 0.018719935789704323\n",
      "Epoch 3735, Loss: 0.0095824277959764, Final Batch Loss: 0.0022555384784936905\n",
      "Epoch 3736, Loss: 0.016250983346253633, Final Batch Loss: 0.012938802130520344\n",
      "Epoch 3737, Loss: 0.01536793215200305, Final Batch Loss: 0.005624900106340647\n",
      "Epoch 3738, Loss: 0.04609806556254625, Final Batch Loss: 0.040713001042604446\n",
      "Epoch 3739, Loss: 0.04883541539311409, Final Batch Loss: 0.023113982751965523\n",
      "Epoch 3740, Loss: 0.033867171267047524, Final Batch Loss: 0.003885906422510743\n",
      "Epoch 3741, Loss: 0.01803828403353691, Final Batch Loss: 0.013005884364247322\n",
      "Epoch 3742, Loss: 0.05289141461253166, Final Batch Loss: 0.01087835431098938\n",
      "Epoch 3743, Loss: 0.018603767966851592, Final Batch Loss: 0.002453902503475547\n",
      "Epoch 3744, Loss: 0.029830717016011477, Final Batch Loss: 0.004331347066909075\n",
      "Epoch 3745, Loss: 0.016293621622025967, Final Batch Loss: 0.008213303051888943\n",
      "Epoch 3746, Loss: 0.010897169820964336, Final Batch Loss: 0.006949631031602621\n",
      "Epoch 3747, Loss: 0.021823596209287643, Final Batch Loss: 0.011052297428250313\n",
      "Epoch 3748, Loss: 0.021812690421938896, Final Batch Loss: 0.01947762444615364\n",
      "Epoch 3749, Loss: 0.01656481483951211, Final Batch Loss: 0.01441193651407957\n",
      "Epoch 3750, Loss: 0.026501805521547794, Final Batch Loss: 0.015459401533007622\n",
      "Epoch 3751, Loss: 0.02099202759563923, Final Batch Loss: 0.0026661772280931473\n",
      "Epoch 3752, Loss: 0.008631018688902259, Final Batch Loss: 0.0021450871136039495\n",
      "Epoch 3753, Loss: 0.010031459853053093, Final Batch Loss: 0.004715456627309322\n",
      "Epoch 3754, Loss: 0.008819396374747157, Final Batch Loss: 0.003271965542808175\n",
      "Epoch 3755, Loss: 0.01133122923783958, Final Batch Loss: 0.0015255610924214125\n",
      "Epoch 3756, Loss: 0.04222921235486865, Final Batch Loss: 0.006757672410458326\n",
      "Epoch 3757, Loss: 0.009711180347949266, Final Batch Loss: 0.0022557126358151436\n",
      "Epoch 3758, Loss: 0.0929911402054131, Final Batch Loss: 0.08755429089069366\n",
      "Epoch 3759, Loss: 0.017392156063579023, Final Batch Loss: 0.0019257677486166358\n",
      "Epoch 3760, Loss: 0.009957837639376521, Final Batch Loss: 0.006262269336730242\n",
      "Epoch 3761, Loss: 0.02179034100845456, Final Batch Loss: 0.015681711956858635\n",
      "Epoch 3762, Loss: 0.0958270626142621, Final Batch Loss: 0.086526058614254\n",
      "Epoch 3763, Loss: 0.009580142330378294, Final Batch Loss: 0.007018680218607187\n",
      "Epoch 3764, Loss: 0.01773173827677965, Final Batch Loss: 0.0140389334410429\n",
      "Epoch 3765, Loss: 0.01943172700703144, Final Batch Loss: 0.014809942804276943\n",
      "Epoch 3766, Loss: 0.013708550948649645, Final Batch Loss: 0.012175078503787518\n",
      "Epoch 3767, Loss: 0.007514834986068308, Final Batch Loss: 0.005759764462709427\n",
      "Epoch 3768, Loss: 0.011151603190228343, Final Batch Loss: 0.0030524746980518103\n",
      "Epoch 3769, Loss: 0.013667535968124866, Final Batch Loss: 0.004295531660318375\n",
      "Epoch 3770, Loss: 0.021065381821244955, Final Batch Loss: 0.014787586405873299\n",
      "Epoch 3771, Loss: 0.03582430025562644, Final Batch Loss: 0.0007962523959577084\n",
      "Epoch 3772, Loss: 0.10778087936341763, Final Batch Loss: 0.08237537741661072\n",
      "Epoch 3773, Loss: 0.002877117251046002, Final Batch Loss: 0.0017794070299714804\n",
      "Epoch 3774, Loss: 0.002615981036797166, Final Batch Loss: 0.0005406865384429693\n",
      "Epoch 3775, Loss: 0.03720499179325998, Final Batch Loss: 0.0012187657412141562\n",
      "Epoch 3776, Loss: 0.006170575157739222, Final Batch Loss: 0.0019302672008052468\n",
      "Epoch 3777, Loss: 0.01652660290710628, Final Batch Loss: 0.0033192008268088102\n",
      "Epoch 3778, Loss: 0.036091596353799105, Final Batch Loss: 0.031345874071121216\n",
      "Epoch 3779, Loss: 0.0695010656490922, Final Batch Loss: 0.058894675225019455\n",
      "Epoch 3780, Loss: 0.026542001869529486, Final Batch Loss: 0.0067870463244616985\n",
      "Epoch 3781, Loss: 0.006625388457905501, Final Batch Loss: 0.0009655204485170543\n",
      "Epoch 3782, Loss: 0.033378107473254204, Final Batch Loss: 0.028340518474578857\n",
      "Epoch 3783, Loss: 0.02588078659027815, Final Batch Loss: 0.00580825749784708\n",
      "Epoch 3784, Loss: 0.0064628764521330595, Final Batch Loss: 0.0009658976923674345\n",
      "Epoch 3785, Loss: 0.023446307401172817, Final Batch Loss: 0.0011107203317806125\n",
      "Epoch 3786, Loss: 0.07878448627889156, Final Batch Loss: 0.07432252913713455\n",
      "Epoch 3787, Loss: 0.007120630121789873, Final Batch Loss: 0.005266224499791861\n",
      "Epoch 3788, Loss: 0.09898896515369415, Final Batch Loss: 0.07131695747375488\n",
      "Epoch 3789, Loss: 0.05850810371339321, Final Batch Loss: 0.02382819913327694\n",
      "Epoch 3790, Loss: 0.03225350962020457, Final Batch Loss: 0.030371803790330887\n",
      "Epoch 3791, Loss: 0.012690090574324131, Final Batch Loss: 0.0050819567404687405\n",
      "Epoch 3792, Loss: 0.012846961384639144, Final Batch Loss: 0.00913340225815773\n",
      "Epoch 3793, Loss: 0.018863119184970856, Final Batch Loss: 0.010202452540397644\n",
      "Epoch 3794, Loss: 0.05691776145249605, Final Batch Loss: 0.044759031385183334\n",
      "Epoch 3795, Loss: 0.010669415351003408, Final Batch Loss: 0.008886839263141155\n",
      "Epoch 3796, Loss: 0.01690625213086605, Final Batch Loss: 0.009656978771090508\n",
      "Epoch 3797, Loss: 0.014720043167471886, Final Batch Loss: 0.00848448183387518\n",
      "Epoch 3798, Loss: 0.03337888978421688, Final Batch Loss: 0.012768266722559929\n",
      "Epoch 3799, Loss: 0.031728227622807026, Final Batch Loss: 0.008927450515329838\n",
      "Epoch 3800, Loss: 0.037997917272150517, Final Batch Loss: 0.025163497775793076\n",
      "Epoch 3801, Loss: 0.03847985528409481, Final Batch Loss: 0.035652920603752136\n",
      "Epoch 3802, Loss: 0.010517102433368564, Final Batch Loss: 0.0030908735934644938\n",
      "Epoch 3803, Loss: 0.034288154216483235, Final Batch Loss: 0.03152273967862129\n",
      "Epoch 3804, Loss: 0.00661746715195477, Final Batch Loss: 0.00103483977727592\n",
      "Epoch 3805, Loss: 0.036395659553818405, Final Batch Loss: 0.0009493211982771754\n",
      "Epoch 3806, Loss: 0.045189425349235535, Final Batch Loss: 0.01771416887640953\n",
      "Epoch 3807, Loss: 0.07050343323498964, Final Batch Loss: 0.058518677949905396\n",
      "Epoch 3808, Loss: 0.026579844765365124, Final Batch Loss: 0.023150302469730377\n",
      "Epoch 3809, Loss: 0.016746452660299838, Final Batch Loss: 0.0014282806077972054\n",
      "Epoch 3810, Loss: 0.0072756793815642595, Final Batch Loss: 0.00292223715223372\n",
      "Epoch 3811, Loss: 0.009937532478943467, Final Batch Loss: 0.0066085741855204105\n",
      "Epoch 3812, Loss: 0.011350070824846625, Final Batch Loss: 0.0034054915886372328\n",
      "Epoch 3813, Loss: 0.03778428863734007, Final Batch Loss: 0.024974672123789787\n",
      "Epoch 3814, Loss: 0.01722056372091174, Final Batch Loss: 0.0029594716615974903\n",
      "Epoch 3815, Loss: 0.013094056863337755, Final Batch Loss: 0.00288976589217782\n",
      "Epoch 3816, Loss: 0.016396422870457172, Final Batch Loss: 0.011673007160425186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3817, Loss: 0.09803780168294907, Final Batch Loss: 0.03601750731468201\n",
      "Epoch 3818, Loss: 0.011844697874039412, Final Batch Loss: 0.0037998943589627743\n",
      "Epoch 3819, Loss: 0.01810656115412712, Final Batch Loss: 0.009671385399997234\n",
      "Epoch 3820, Loss: 0.010077138897031546, Final Batch Loss: 0.0022057383321225643\n",
      "Epoch 3821, Loss: 0.07262120395898819, Final Batch Loss: 0.03586377575993538\n",
      "Epoch 3822, Loss: 0.012556233443319798, Final Batch Loss: 0.0043554967269301414\n",
      "Epoch 3823, Loss: 0.010552824358455837, Final Batch Loss: 0.001652626204304397\n",
      "Epoch 3824, Loss: 0.005914326990023255, Final Batch Loss: 0.0026346074882894754\n",
      "Epoch 3825, Loss: 0.008903803769499063, Final Batch Loss: 0.0044131213799119\n",
      "Epoch 3826, Loss: 0.08592996699735522, Final Batch Loss: 0.08137550204992294\n",
      "Epoch 3827, Loss: 0.020823235157877207, Final Batch Loss: 0.014303993433713913\n",
      "Epoch 3828, Loss: 0.014401813503354788, Final Batch Loss: 0.0010142247192561626\n",
      "Epoch 3829, Loss: 0.010565048549324274, Final Batch Loss: 0.008330474607646465\n",
      "Epoch 3830, Loss: 0.006509194150567055, Final Batch Loss: 0.0017367438413202763\n",
      "Epoch 3831, Loss: 0.061826495453715324, Final Batch Loss: 0.008021334186196327\n",
      "Epoch 3832, Loss: 0.027064916677773, Final Batch Loss: 0.023747069761157036\n",
      "Epoch 3833, Loss: 0.01194728771224618, Final Batch Loss: 0.003951530437916517\n",
      "Epoch 3834, Loss: 0.014881211798638105, Final Batch Loss: 0.00716785155236721\n",
      "Epoch 3835, Loss: 0.0875607393682003, Final Batch Loss: 0.06683772057294846\n",
      "Epoch 3836, Loss: 0.015642633195966482, Final Batch Loss: 0.007681409362703562\n",
      "Epoch 3837, Loss: 0.05431919125840068, Final Batch Loss: 0.04786285385489464\n",
      "Epoch 3838, Loss: 0.0065884513314813375, Final Batch Loss: 0.002835725201293826\n",
      "Epoch 3839, Loss: 0.008361618965864182, Final Batch Loss: 0.0036411285400390625\n",
      "Epoch 3840, Loss: 0.0062169721350073814, Final Batch Loss: 0.0029997797682881355\n",
      "Epoch 3841, Loss: 0.026740781497210264, Final Batch Loss: 0.004448953550308943\n",
      "Epoch 3842, Loss: 0.03109526669140905, Final Batch Loss: 0.001443492597900331\n",
      "Epoch 3843, Loss: 0.030325918458402157, Final Batch Loss: 0.026875445619225502\n",
      "Epoch 3844, Loss: 0.009852106217294931, Final Batch Loss: 0.008401797153055668\n",
      "Epoch 3845, Loss: 0.012336368439719081, Final Batch Loss: 0.003578101983293891\n",
      "Epoch 3846, Loss: 0.03062080405652523, Final Batch Loss: 0.02644476108253002\n",
      "Epoch 3847, Loss: 0.0052006320329383016, Final Batch Loss: 0.0018117051804438233\n",
      "Epoch 3848, Loss: 0.03438596613705158, Final Batch Loss: 0.0036829207092523575\n",
      "Epoch 3849, Loss: 0.008974001044407487, Final Batch Loss: 0.0030902328435331583\n",
      "Epoch 3850, Loss: 0.005173434969037771, Final Batch Loss: 0.0024646339006721973\n",
      "Epoch 3851, Loss: 0.007737242733128369, Final Batch Loss: 0.0016760594444349408\n",
      "Epoch 3852, Loss: 0.013110005762428045, Final Batch Loss: 0.004092442337423563\n",
      "Epoch 3853, Loss: 0.016747097484767437, Final Batch Loss: 0.011771071702241898\n",
      "Epoch 3854, Loss: 0.005076638306491077, Final Batch Loss: 0.0013803908368572593\n",
      "Epoch 3855, Loss: 0.015422504395246506, Final Batch Loss: 0.006241075694561005\n",
      "Epoch 3856, Loss: 0.013027545996010303, Final Batch Loss: 0.003498583100736141\n",
      "Epoch 3857, Loss: 0.008710821159183979, Final Batch Loss: 0.0056161778047680855\n",
      "Epoch 3858, Loss: 0.007198813604190946, Final Batch Loss: 0.0030715700704604387\n",
      "Epoch 3859, Loss: 0.00864772079512477, Final Batch Loss: 0.001287282444536686\n",
      "Epoch 3860, Loss: 0.003595037676859647, Final Batch Loss: 0.00085509690688923\n",
      "Epoch 3861, Loss: 0.01607884280383587, Final Batch Loss: 0.00631655752658844\n",
      "Epoch 3862, Loss: 0.017078165896236897, Final Batch Loss: 0.012056952342391014\n",
      "Epoch 3863, Loss: 0.020360907539725304, Final Batch Loss: 0.01225330587476492\n",
      "Epoch 3864, Loss: 0.005412214784882963, Final Batch Loss: 0.0038082567043602467\n",
      "Epoch 3865, Loss: 0.014612602069973946, Final Batch Loss: 0.002646317705512047\n",
      "Epoch 3866, Loss: 0.027529444778338075, Final Batch Loss: 0.025380559265613556\n",
      "Epoch 3867, Loss: 0.014587538316845894, Final Batch Loss: 0.004096079617738724\n",
      "Epoch 3868, Loss: 0.07456708024255931, Final Batch Loss: 0.07289750874042511\n",
      "Epoch 3869, Loss: 0.00514580961316824, Final Batch Loss: 0.0016817734576761723\n",
      "Epoch 3870, Loss: 0.023899300023913383, Final Batch Loss: 0.012904773466289043\n",
      "Epoch 3871, Loss: 0.01812542788684368, Final Batch Loss: 0.015180935151875019\n",
      "Epoch 3872, Loss: 0.029663095367141068, Final Batch Loss: 0.001017879811115563\n",
      "Epoch 3873, Loss: 0.009176271967589855, Final Batch Loss: 0.00698267063125968\n",
      "Epoch 3874, Loss: 0.009765471098944545, Final Batch Loss: 0.0018656214233487844\n",
      "Epoch 3875, Loss: 0.006409123074263334, Final Batch Loss: 0.004417082294821739\n",
      "Epoch 3876, Loss: 0.008805791614577174, Final Batch Loss: 0.002809267258271575\n",
      "Epoch 3877, Loss: 0.029601281974464655, Final Batch Loss: 0.004599495325237513\n",
      "Epoch 3878, Loss: 0.003057141089811921, Final Batch Loss: 0.0016302971635013819\n",
      "Epoch 3879, Loss: 0.009214865509420633, Final Batch Loss: 0.0020864768885076046\n",
      "Epoch 3880, Loss: 0.003338900860399008, Final Batch Loss: 0.0019009466050192714\n",
      "Epoch 3881, Loss: 0.023370721726678312, Final Batch Loss: 0.001772052957676351\n",
      "Epoch 3882, Loss: 0.01825694367289543, Final Batch Loss: 0.0118764853104949\n",
      "Epoch 3883, Loss: 0.0179945039562881, Final Batch Loss: 0.0040085348300635815\n",
      "Epoch 3884, Loss: 0.002694098628126085, Final Batch Loss: 0.001409028540365398\n",
      "Epoch 3885, Loss: 0.007529669092036784, Final Batch Loss: 0.0017479272792115808\n",
      "Epoch 3886, Loss: 0.0030584632768295705, Final Batch Loss: 0.0005634999251924455\n",
      "Epoch 3887, Loss: 0.01417254761327058, Final Batch Loss: 0.0010739053832367063\n",
      "Epoch 3888, Loss: 0.009865725762210786, Final Batch Loss: 0.008724899031221867\n",
      "Epoch 3889, Loss: 0.01035327184945345, Final Batch Loss: 0.002642023842781782\n",
      "Epoch 3890, Loss: 0.04200211935676634, Final Batch Loss: 0.04048999026417732\n",
      "Epoch 3891, Loss: 0.010523481760174036, Final Batch Loss: 0.003935113549232483\n",
      "Epoch 3892, Loss: 0.012414807453751564, Final Batch Loss: 0.006682244595140219\n",
      "Epoch 3893, Loss: 0.0051978398114442825, Final Batch Loss: 0.0018417874816805124\n",
      "Epoch 3894, Loss: 0.031763500766828656, Final Batch Loss: 0.0029161416459828615\n",
      "Epoch 3895, Loss: 0.009931295062415302, Final Batch Loss: 0.0008000143570825458\n",
      "Epoch 3896, Loss: 0.04693663213402033, Final Batch Loss: 0.039217758923769\n",
      "Epoch 3897, Loss: 0.005663746618665755, Final Batch Loss: 0.00434497743844986\n",
      "Epoch 3898, Loss: 0.0084116174839437, Final Batch Loss: 0.001966436393558979\n",
      "Epoch 3899, Loss: 0.020987720927223563, Final Batch Loss: 0.017941759899258614\n",
      "Epoch 3900, Loss: 0.013112594140693545, Final Batch Loss: 0.0033184445928782225\n",
      "Epoch 3901, Loss: 0.03263079992029816, Final Batch Loss: 0.0005648048827424645\n",
      "Epoch 3902, Loss: 0.005829624366015196, Final Batch Loss: 0.0025340665597468615\n",
      "Epoch 3903, Loss: 0.010148993926122785, Final Batch Loss: 0.007723950780928135\n",
      "Epoch 3904, Loss: 0.05936815426684916, Final Batch Loss: 0.0030215776059776545\n",
      "Epoch 3905, Loss: 0.02302867011167109, Final Batch Loss: 0.0037889538798481226\n",
      "Epoch 3906, Loss: 0.007908235304057598, Final Batch Loss: 0.002225036732852459\n",
      "Epoch 3907, Loss: 0.011085350764915347, Final Batch Loss: 0.002168829319998622\n",
      "Epoch 3908, Loss: 0.03131276834756136, Final Batch Loss: 0.011819773353636265\n",
      "Epoch 3909, Loss: 0.009866922395303845, Final Batch Loss: 0.0022776455152779818\n",
      "Epoch 3910, Loss: 0.004554336774162948, Final Batch Loss: 0.0028778796549886465\n",
      "Epoch 3911, Loss: 0.05133016221225262, Final Batch Loss: 0.03217431530356407\n",
      "Epoch 3912, Loss: 0.036052885465323925, Final Batch Loss: 0.02184602990746498\n",
      "Epoch 3913, Loss: 0.0408819995354861, Final Batch Loss: 0.001603294862434268\n",
      "Epoch 3914, Loss: 0.023483733646571636, Final Batch Loss: 0.01917971484363079\n",
      "Epoch 3915, Loss: 0.11146967299282551, Final Batch Loss: 0.10459472984075546\n",
      "Epoch 3916, Loss: 0.011479569016955793, Final Batch Loss: 0.0012981531908735633\n",
      "Epoch 3917, Loss: 0.023050101939588785, Final Batch Loss: 0.0040427339263260365\n",
      "Epoch 3918, Loss: 0.008906719507649541, Final Batch Loss: 0.005939807277172804\n",
      "Epoch 3919, Loss: 0.011740770656615496, Final Batch Loss: 0.004175344482064247\n",
      "Epoch 3920, Loss: 0.008557523600757122, Final Batch Loss: 0.004265099298208952\n",
      "Epoch 3921, Loss: 0.014063270296901464, Final Batch Loss: 0.0031405710615217686\n",
      "Epoch 3922, Loss: 0.028119610156863928, Final Batch Loss: 0.021644478663802147\n",
      "Epoch 3923, Loss: 0.024177493527531624, Final Batch Loss: 0.014095036312937737\n",
      "Epoch 3924, Loss: 0.03676930209621787, Final Batch Loss: 0.004300845321267843\n",
      "Epoch 3925, Loss: 0.005429419979918748, Final Batch Loss: 0.00028302130522206426\n",
      "Epoch 3926, Loss: 0.004910475807264447, Final Batch Loss: 0.0013551062438637018\n",
      "Epoch 3927, Loss: 0.015735584194771945, Final Batch Loss: 0.00156637083273381\n",
      "Epoch 3928, Loss: 0.027230792678892612, Final Batch Loss: 0.01933928020298481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3929, Loss: 0.01067544799298048, Final Batch Loss: 0.0019934820011258125\n",
      "Epoch 3930, Loss: 0.015751471742987633, Final Batch Loss: 0.013539777137339115\n",
      "Epoch 3931, Loss: 0.004961975326295942, Final Batch Loss: 0.004123019520193338\n",
      "Epoch 3932, Loss: 0.04509865678846836, Final Batch Loss: 0.015657758340239525\n",
      "Epoch 3933, Loss: 0.02232705755159259, Final Batch Loss: 0.019362101331353188\n",
      "Epoch 3934, Loss: 0.0038110868190415204, Final Batch Loss: 0.0008303684298880398\n",
      "Epoch 3935, Loss: 0.029315360356122255, Final Batch Loss: 0.0013249856419861317\n",
      "Epoch 3936, Loss: 0.0473560793325305, Final Batch Loss: 0.0036706579849123955\n",
      "Epoch 3937, Loss: 0.021895420271903276, Final Batch Loss: 0.014158705249428749\n",
      "Epoch 3938, Loss: 0.021028883755207062, Final Batch Loss: 0.005188044160604477\n",
      "Epoch 3939, Loss: 0.018808786757290363, Final Batch Loss: 0.00840570218861103\n",
      "Epoch 3940, Loss: 0.013927930500358343, Final Batch Loss: 0.0066353022120893\n",
      "Epoch 3941, Loss: 0.008184315403923392, Final Batch Loss: 0.0044182115234434605\n",
      "Epoch 3942, Loss: 0.008444770239293575, Final Batch Loss: 0.004543872084468603\n",
      "Epoch 3943, Loss: 0.017598729813471437, Final Batch Loss: 0.015284568071365356\n",
      "Epoch 3944, Loss: 0.06977752223610878, Final Batch Loss: 0.018877767026424408\n",
      "Epoch 3945, Loss: 0.026534115429967642, Final Batch Loss: 0.020742136985063553\n",
      "Epoch 3946, Loss: 0.004546276526525617, Final Batch Loss: 0.000735709210857749\n",
      "Epoch 3947, Loss: 0.09981397166848183, Final Batch Loss: 0.0835154727101326\n",
      "Epoch 3948, Loss: 0.030878634192049503, Final Batch Loss: 0.005291380919516087\n",
      "Epoch 3949, Loss: 0.03705388540402055, Final Batch Loss: 0.02972576394677162\n",
      "Epoch 3950, Loss: 0.07108384184539318, Final Batch Loss: 0.04165647178888321\n",
      "Epoch 3951, Loss: 0.013746822020038962, Final Batch Loss: 0.010029638186097145\n",
      "Epoch 3952, Loss: 0.05647687241435051, Final Batch Loss: 0.014826055616140366\n",
      "Epoch 3953, Loss: 0.01141479448415339, Final Batch Loss: 0.008765519596636295\n",
      "Epoch 3954, Loss: 0.055500255431979895, Final Batch Loss: 0.005432394798845053\n",
      "Epoch 3955, Loss: 0.01772087044082582, Final Batch Loss: 0.0009935495909303427\n",
      "Epoch 3956, Loss: 0.02988620474934578, Final Batch Loss: 0.005759038031101227\n",
      "Epoch 3957, Loss: 0.12685741111636162, Final Batch Loss: 0.08518964052200317\n",
      "Epoch 3958, Loss: 0.007836545119062066, Final Batch Loss: 0.0018098137807101011\n",
      "Epoch 3959, Loss: 0.011730194091796875, Final Batch Loss: 0.006110678892582655\n",
      "Epoch 3960, Loss: 0.022021883632987738, Final Batch Loss: 0.01667015627026558\n",
      "Epoch 3961, Loss: 0.10922390129417181, Final Batch Loss: 0.008801660500466824\n",
      "Epoch 3962, Loss: 0.045649005100131035, Final Batch Loss: 0.042616814374923706\n",
      "Epoch 3963, Loss: 0.11170366406440735, Final Batch Loss: 0.07615529745817184\n",
      "Epoch 3964, Loss: 0.06050471402704716, Final Batch Loss: 0.04443167895078659\n",
      "Epoch 3965, Loss: 0.007360405987128615, Final Batch Loss: 0.002751615596935153\n",
      "Epoch 3966, Loss: 0.007867711130529642, Final Batch Loss: 0.004901345353573561\n",
      "Epoch 3967, Loss: 0.05325029091909528, Final Batch Loss: 0.005726177711039782\n",
      "Epoch 3968, Loss: 0.021791180595755577, Final Batch Loss: 0.007339434698224068\n",
      "Epoch 3969, Loss: 0.00863624014891684, Final Batch Loss: 0.003397130174562335\n",
      "Epoch 3970, Loss: 0.06356948800384998, Final Batch Loss: 0.04335371032357216\n",
      "Epoch 3971, Loss: 0.03789263125509024, Final Batch Loss: 0.027589639648795128\n",
      "Epoch 3972, Loss: 0.03420750983059406, Final Batch Loss: 0.016451671719551086\n",
      "Epoch 3973, Loss: 0.0064426688477396965, Final Batch Loss: 0.002106587402522564\n",
      "Epoch 3974, Loss: 0.007582369260489941, Final Batch Loss: 0.0024735406041145325\n",
      "Epoch 3975, Loss: 0.026118451729416847, Final Batch Loss: 0.008612342178821564\n",
      "Epoch 3976, Loss: 0.028380293399095535, Final Batch Loss: 0.00257294625043869\n",
      "Epoch 3977, Loss: 0.015942301251925528, Final Batch Loss: 0.001289315172471106\n",
      "Epoch 3978, Loss: 0.013664765981957316, Final Batch Loss: 0.0015691581647843122\n",
      "Epoch 3979, Loss: 0.009183450136333704, Final Batch Loss: 0.0032075471244752407\n",
      "Epoch 3980, Loss: 0.046244366094470024, Final Batch Loss: 0.021495485678315163\n",
      "Epoch 3981, Loss: 0.02148889284580946, Final Batch Loss: 0.013094713911414146\n",
      "Epoch 3982, Loss: 0.019030787283554673, Final Batch Loss: 0.002053650328889489\n",
      "Epoch 3983, Loss: 0.02663891203701496, Final Batch Loss: 0.013380643911659718\n",
      "Epoch 3984, Loss: 0.009338230360299349, Final Batch Loss: 0.004284524358808994\n",
      "Epoch 3985, Loss: 0.03341238107532263, Final Batch Loss: 0.025650059804320335\n",
      "Epoch 3986, Loss: 0.020750995725393295, Final Batch Loss: 0.004402687773108482\n",
      "Epoch 3987, Loss: 0.0283752316609025, Final Batch Loss: 0.005639529787003994\n",
      "Epoch 3988, Loss: 0.02879756037145853, Final Batch Loss: 0.01884336955845356\n",
      "Epoch 3989, Loss: 0.036228436045348644, Final Batch Loss: 0.02779567427933216\n",
      "Epoch 3990, Loss: 0.0448556337505579, Final Batch Loss: 0.03313210979104042\n",
      "Epoch 3991, Loss: 0.004624042892828584, Final Batch Loss: 0.0015477968845516443\n",
      "Epoch 3992, Loss: 0.0069642874877899885, Final Batch Loss: 0.0032114950008690357\n",
      "Epoch 3993, Loss: 0.0034372556256130338, Final Batch Loss: 0.0017917148070409894\n",
      "Epoch 3994, Loss: 0.03252779319882393, Final Batch Loss: 0.022552229464054108\n",
      "Epoch 3995, Loss: 0.015515363309532404, Final Batch Loss: 0.007704257965087891\n",
      "Epoch 3996, Loss: 0.031318707624450326, Final Batch Loss: 0.002390470588579774\n",
      "Epoch 3997, Loss: 0.006437907228246331, Final Batch Loss: 0.0034134809393435717\n",
      "Epoch 3998, Loss: 0.003839693730697036, Final Batch Loss: 0.0021205830853432417\n",
      "Epoch 3999, Loss: 0.007818613667041063, Final Batch Loss: 0.003136755432933569\n",
      "Epoch 4000, Loss: 0.005771007155999541, Final Batch Loss: 0.0025786433834582567\n",
      "Epoch 4001, Loss: 0.0465778021607548, Final Batch Loss: 0.001872083405032754\n",
      "Epoch 4002, Loss: 0.013689454179257154, Final Batch Loss: 0.006456622388213873\n",
      "Epoch 4003, Loss: 0.0051115044625476, Final Batch Loss: 0.0013164366828277707\n",
      "Epoch 4004, Loss: 0.016137811820954084, Final Batch Loss: 0.006136530544608831\n",
      "Epoch 4005, Loss: 0.010026823496446013, Final Batch Loss: 0.002564451890066266\n",
      "Epoch 4006, Loss: 0.004262636066414416, Final Batch Loss: 0.0018209802219644189\n",
      "Epoch 4007, Loss: 0.004524585325270891, Final Batch Loss: 0.0012412548530846834\n",
      "Epoch 4008, Loss: 0.03189311898313463, Final Batch Loss: 0.002444242825731635\n",
      "Epoch 4009, Loss: 0.014058633707463741, Final Batch Loss: 0.0120738185942173\n",
      "Epoch 4010, Loss: 0.01449810154736042, Final Batch Loss: 0.005051353946328163\n",
      "Epoch 4011, Loss: 0.016442116582766175, Final Batch Loss: 0.015200629830360413\n",
      "Epoch 4012, Loss: 0.03324256418272853, Final Batch Loss: 0.025952184572815895\n",
      "Epoch 4013, Loss: 0.007184230023995042, Final Batch Loss: 0.0030729586724191904\n",
      "Epoch 4014, Loss: 0.00783602544106543, Final Batch Loss: 0.004968938883394003\n",
      "Epoch 4015, Loss: 0.01733197597786784, Final Batch Loss: 0.0057848370634019375\n",
      "Epoch 4016, Loss: 0.015900665894150734, Final Batch Loss: 0.01209242269396782\n",
      "Epoch 4017, Loss: 0.004895021906122565, Final Batch Loss: 0.00260771531611681\n",
      "Epoch 4018, Loss: 0.011592564173042774, Final Batch Loss: 0.007938127033412457\n",
      "Epoch 4019, Loss: 0.010327017866075039, Final Batch Loss: 0.002285979688167572\n",
      "Epoch 4020, Loss: 0.004654383286833763, Final Batch Loss: 0.0032065361738204956\n",
      "Epoch 4021, Loss: 0.021351526491343975, Final Batch Loss: 0.008718120865523815\n",
      "Epoch 4022, Loss: 0.008593476377427578, Final Batch Loss: 0.004997767508029938\n",
      "Epoch 4023, Loss: 0.011307540582492948, Final Batch Loss: 0.0037263354752212763\n",
      "Epoch 4024, Loss: 0.008827480021864176, Final Batch Loss: 0.005628413055092096\n",
      "Epoch 4025, Loss: 0.019380776560865343, Final Batch Loss: 0.0016545116668567061\n",
      "Epoch 4026, Loss: 0.023668858222663403, Final Batch Loss: 0.0017449865117669106\n",
      "Epoch 4027, Loss: 0.005221210420131683, Final Batch Loss: 0.0016442060004919767\n",
      "Epoch 4028, Loss: 0.010250800754874945, Final Batch Loss: 0.0043181548826396465\n",
      "Epoch 4029, Loss: 0.011890335474163294, Final Batch Loss: 0.004057599697262049\n",
      "Epoch 4030, Loss: 0.022556413896381855, Final Batch Loss: 0.01441956777125597\n",
      "Epoch 4031, Loss: 0.006501637864857912, Final Batch Loss: 0.003594889072701335\n",
      "Epoch 4032, Loss: 0.032303910702466965, Final Batch Loss: 0.013659024611115456\n",
      "Epoch 4033, Loss: 0.026892371475696564, Final Batch Loss: 0.006733650341629982\n",
      "Epoch 4034, Loss: 0.02622126112692058, Final Batch Loss: 0.024232136085629463\n",
      "Epoch 4035, Loss: 0.02484965743497014, Final Batch Loss: 0.02034861035645008\n",
      "Epoch 4036, Loss: 0.01105379220098257, Final Batch Loss: 0.007928291335701942\n",
      "Epoch 4037, Loss: 0.0055991633562371135, Final Batch Loss: 0.0005387727869674563\n",
      "Epoch 4038, Loss: 0.031213628128170967, Final Batch Loss: 0.010837273672223091\n",
      "Epoch 4039, Loss: 0.010853892657905817, Final Batch Loss: 0.005533096380531788\n",
      "Epoch 4040, Loss: 0.007901757722720504, Final Batch Loss: 0.0016865411307662725\n",
      "Epoch 4041, Loss: 0.015520716086030006, Final Batch Loss: 0.004804887808859348\n",
      "Epoch 4042, Loss: 0.01175932539626956, Final Batch Loss: 0.0027809743769466877\n",
      "Epoch 4043, Loss: 0.005918828945141286, Final Batch Loss: 0.0009354061330668628\n",
      "Epoch 4044, Loss: 0.005878971773199737, Final Batch Loss: 0.004895505495369434\n",
      "Epoch 4045, Loss: 0.006251993007026613, Final Batch Loss: 0.004863815847784281\n",
      "Epoch 4046, Loss: 0.008259067079052329, Final Batch Loss: 0.005100983660668135\n",
      "Epoch 4047, Loss: 0.01651990390382707, Final Batch Loss: 0.012689433060586452\n",
      "Epoch 4048, Loss: 0.012098770122975111, Final Batch Loss: 0.005246642976999283\n",
      "Epoch 4049, Loss: 0.01097877835854888, Final Batch Loss: 0.00813231524080038\n",
      "Epoch 4050, Loss: 0.00721731293015182, Final Batch Loss: 0.0017177148256450891\n",
      "Epoch 4051, Loss: 0.0030458627734333277, Final Batch Loss: 0.001967564458027482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4052, Loss: 0.0070678910706192255, Final Batch Loss: 0.003024609060958028\n",
      "Epoch 4053, Loss: 0.00645333924330771, Final Batch Loss: 0.004554827231913805\n",
      "Epoch 4054, Loss: 0.003116183157544583, Final Batch Loss: 0.0006175529561005533\n",
      "Epoch 4055, Loss: 0.005182960769161582, Final Batch Loss: 0.0014161290600895882\n",
      "Epoch 4056, Loss: 0.08533785352483392, Final Batch Loss: 0.08069717139005661\n",
      "Epoch 4057, Loss: 0.03668279154226184, Final Batch Loss: 0.0025847661308944225\n",
      "Epoch 4058, Loss: 0.007664602715522051, Final Batch Loss: 0.005040947813540697\n",
      "Epoch 4059, Loss: 0.005822604289278388, Final Batch Loss: 0.004480092320591211\n",
      "Epoch 4060, Loss: 0.00820516503881663, Final Batch Loss: 0.0014146094908937812\n",
      "Epoch 4061, Loss: 0.002005285699851811, Final Batch Loss: 0.00040105346124619246\n",
      "Epoch 4062, Loss: 0.008839344140142202, Final Batch Loss: 0.0011631511151790619\n",
      "Epoch 4063, Loss: 0.001816136878915131, Final Batch Loss: 0.00032781693153083324\n",
      "Epoch 4064, Loss: 0.020896723493933678, Final Batch Loss: 0.010554150678217411\n",
      "Epoch 4065, Loss: 0.009292163420468569, Final Batch Loss: 0.001297523733228445\n",
      "Epoch 4066, Loss: 0.0070026537869125605, Final Batch Loss: 0.0020223662722855806\n",
      "Epoch 4067, Loss: 0.029243362601846457, Final Batch Loss: 0.0033977380953729153\n",
      "Epoch 4068, Loss: 0.006149674882180989, Final Batch Loss: 0.0014993675285950303\n",
      "Epoch 4069, Loss: 0.0037536444142460823, Final Batch Loss: 0.0014512513298541307\n",
      "Epoch 4070, Loss: 0.003508563619107008, Final Batch Loss: 0.002577437786385417\n",
      "Epoch 4071, Loss: 0.025036657112650573, Final Batch Loss: 0.0019078607438132167\n",
      "Epoch 4072, Loss: 0.024551957845687866, Final Batch Loss: 0.016537196934223175\n",
      "Epoch 4073, Loss: 0.005496991565451026, Final Batch Loss: 0.0031548705883324146\n",
      "Epoch 4074, Loss: 0.02347043389454484, Final Batch Loss: 0.004792241845279932\n",
      "Epoch 4075, Loss: 0.005145280156284571, Final Batch Loss: 0.0030220793560147285\n",
      "Epoch 4076, Loss: 0.006478469935245812, Final Batch Loss: 0.004660836420953274\n",
      "Epoch 4077, Loss: 0.03968710359185934, Final Batch Loss: 0.004309493117034435\n",
      "Epoch 4078, Loss: 0.020337065681815147, Final Batch Loss: 0.01743929833173752\n",
      "Epoch 4079, Loss: 0.02289358782581985, Final Batch Loss: 0.0029564339201897383\n",
      "Epoch 4080, Loss: 0.012452757102437317, Final Batch Loss: 0.0015751823084428906\n",
      "Epoch 4081, Loss: 0.008506262442097068, Final Batch Loss: 0.0047427332028746605\n",
      "Epoch 4082, Loss: 0.012859603157266974, Final Batch Loss: 0.008976004086434841\n",
      "Epoch 4083, Loss: 0.023495430359616876, Final Batch Loss: 0.021277248859405518\n",
      "Epoch 4084, Loss: 0.0069133678916841745, Final Batch Loss: 0.003958180081099272\n",
      "Epoch 4085, Loss: 0.036849514581263065, Final Batch Loss: 0.008975912816822529\n",
      "Epoch 4086, Loss: 0.027713436167687178, Final Batch Loss: 0.006849426310509443\n",
      "Epoch 4087, Loss: 0.009017510456033051, Final Batch Loss: 0.001651118160225451\n",
      "Epoch 4088, Loss: 0.01176078338176012, Final Batch Loss: 0.008503692224621773\n",
      "Epoch 4089, Loss: 0.010761576937511563, Final Batch Loss: 0.008136951364576817\n",
      "Epoch 4090, Loss: 0.007975349901244044, Final Batch Loss: 0.003275914816185832\n",
      "Epoch 4091, Loss: 0.0036594259436242282, Final Batch Loss: 0.0029329664539545774\n",
      "Epoch 4092, Loss: 0.04042637534439564, Final Batch Loss: 0.038254763931035995\n",
      "Epoch 4093, Loss: 0.00854653981514275, Final Batch Loss: 0.0048426114954054356\n",
      "Epoch 4094, Loss: 0.0855458676815033, Final Batch Loss: 0.037254996597766876\n",
      "Epoch 4095, Loss: 0.007271229289472103, Final Batch Loss: 0.00225371727719903\n",
      "Epoch 4096, Loss: 0.01812241622246802, Final Batch Loss: 0.0009709449950605631\n",
      "Epoch 4097, Loss: 0.01541468407958746, Final Batch Loss: 0.005449822172522545\n",
      "Epoch 4098, Loss: 0.019640602869912982, Final Batch Loss: 0.0026057518552988768\n",
      "Epoch 4099, Loss: 0.029195244424045086, Final Batch Loss: 0.011048194952309132\n",
      "Epoch 4100, Loss: 0.003053923253901303, Final Batch Loss: 0.0011466146679595113\n",
      "Epoch 4101, Loss: 0.0034088791289832443, Final Batch Loss: 0.0004830154066439718\n",
      "Epoch 4102, Loss: 0.017274876590818167, Final Batch Loss: 0.014583487063646317\n",
      "Epoch 4103, Loss: 0.006115430733188987, Final Batch Loss: 0.0006899486761540174\n",
      "Epoch 4104, Loss: 0.003627330530434847, Final Batch Loss: 0.0010042316280305386\n",
      "Epoch 4105, Loss: 0.022748047951608896, Final Batch Loss: 0.020698700100183487\n",
      "Epoch 4106, Loss: 0.0183050031773746, Final Batch Loss: 0.013029186986386776\n",
      "Epoch 4107, Loss: 0.010901368455961347, Final Batch Loss: 0.0010593247134238482\n",
      "Epoch 4108, Loss: 0.022379117319360375, Final Batch Loss: 0.01879511959850788\n",
      "Epoch 4109, Loss: 0.009291149908676744, Final Batch Loss: 0.006547861732542515\n",
      "Epoch 4110, Loss: 0.015003031585365534, Final Batch Loss: 0.00808203686028719\n",
      "Epoch 4111, Loss: 0.005681345239281654, Final Batch Loss: 0.0036835174541920424\n",
      "Epoch 4112, Loss: 0.02741146134212613, Final Batch Loss: 0.007590743247419596\n",
      "Epoch 4113, Loss: 0.013425201177597046, Final Batch Loss: 0.007641063537448645\n",
      "Epoch 4114, Loss: 0.017377678537741303, Final Batch Loss: 0.0013655072543770075\n",
      "Epoch 4115, Loss: 0.007928129751235247, Final Batch Loss: 0.0050613717176020145\n",
      "Epoch 4116, Loss: 0.012717913836240768, Final Batch Loss: 0.008748342283070087\n",
      "Epoch 4117, Loss: 0.03620150173082948, Final Batch Loss: 0.0018448256887495518\n",
      "Epoch 4118, Loss: 0.007858611643314362, Final Batch Loss: 0.0014929063618183136\n",
      "Epoch 4119, Loss: 0.0023770263069309294, Final Batch Loss: 0.0018734476761892438\n",
      "Epoch 4120, Loss: 0.014994026627391577, Final Batch Loss: 0.008083750493824482\n",
      "Epoch 4121, Loss: 0.013517524115741253, Final Batch Loss: 0.0046683140099048615\n",
      "Epoch 4122, Loss: 0.01726944837719202, Final Batch Loss: 0.008901973254978657\n",
      "Epoch 4123, Loss: 0.0059578558430075645, Final Batch Loss: 0.002926797606050968\n",
      "Epoch 4124, Loss: 0.03094162931665778, Final Batch Loss: 0.005475259851664305\n",
      "Epoch 4125, Loss: 0.0021994001581333578, Final Batch Loss: 0.0012515574926510453\n",
      "Epoch 4126, Loss: 0.005266556516289711, Final Batch Loss: 0.0009813406504690647\n",
      "Epoch 4127, Loss: 0.022570534143596888, Final Batch Loss: 0.018741128966212273\n",
      "Epoch 4128, Loss: 0.004293768433853984, Final Batch Loss: 0.0029477502685040236\n",
      "Epoch 4129, Loss: 0.019102033227682114, Final Batch Loss: 0.009822242893278599\n",
      "Epoch 4130, Loss: 0.009632603265345097, Final Batch Loss: 0.0030769482254981995\n",
      "Epoch 4131, Loss: 0.006551268743351102, Final Batch Loss: 0.002776001114398241\n",
      "Epoch 4132, Loss: 0.005917369853705168, Final Batch Loss: 0.0045577967539429665\n",
      "Epoch 4133, Loss: 0.04016794636845589, Final Batch Loss: 0.028196275234222412\n",
      "Epoch 4134, Loss: 0.009077657712623477, Final Batch Loss: 0.002700116252526641\n",
      "Epoch 4135, Loss: 0.01354352617636323, Final Batch Loss: 0.004026126582175493\n",
      "Epoch 4136, Loss: 0.00223270314745605, Final Batch Loss: 0.0009684177348390222\n",
      "Epoch 4137, Loss: 0.013188911136239767, Final Batch Loss: 0.00037140073254704475\n",
      "Epoch 4138, Loss: 0.010257050395011902, Final Batch Loss: 0.00225057452917099\n",
      "Epoch 4139, Loss: 0.002836763858795166, Final Batch Loss: 0.001846969942562282\n",
      "Epoch 4140, Loss: 0.008996555960038677, Final Batch Loss: 0.0004154633788857609\n",
      "Epoch 4141, Loss: 0.0022000975150149316, Final Batch Loss: 0.0019276610109955072\n",
      "Epoch 4142, Loss: 0.007102088304236531, Final Batch Loss: 0.005026856902986765\n",
      "Epoch 4143, Loss: 0.005314175970852375, Final Batch Loss: 0.0014743716455996037\n",
      "Epoch 4144, Loss: 0.004996640142053366, Final Batch Loss: 0.0029300369787961245\n",
      "Epoch 4145, Loss: 0.0030596982687711716, Final Batch Loss: 0.0006818126421421766\n",
      "Epoch 4146, Loss: 0.0035604287404567003, Final Batch Loss: 0.0014331040438264608\n",
      "Epoch 4147, Loss: 0.0024606618244433776, Final Batch Loss: 0.00011174475366715342\n",
      "Epoch 4148, Loss: 0.00368821615120396, Final Batch Loss: 0.0006302219699136913\n",
      "Epoch 4149, Loss: 0.012104911496862769, Final Batch Loss: 0.00905989296734333\n",
      "Epoch 4150, Loss: 0.0029513477929867804, Final Batch Loss: 0.0007109325961209834\n",
      "Epoch 4151, Loss: 0.005076433066278696, Final Batch Loss: 0.0001735319383442402\n",
      "Epoch 4152, Loss: 0.005675832508131862, Final Batch Loss: 0.0035163164138793945\n",
      "Epoch 4153, Loss: 0.014850839041173458, Final Batch Loss: 0.011149858124554157\n",
      "Epoch 4154, Loss: 0.007889730186434463, Final Batch Loss: 0.00034357167896814644\n",
      "Epoch 4155, Loss: 0.0024369967286475003, Final Batch Loss: 0.0015401440905407071\n",
      "Epoch 4156, Loss: 0.014389708172529936, Final Batch Loss: 0.012797688134014606\n",
      "Epoch 4157, Loss: 0.014235607348382473, Final Batch Loss: 0.009082063101232052\n",
      "Epoch 4158, Loss: 0.0020352486753836274, Final Batch Loss: 0.001142706605605781\n",
      "Epoch 4159, Loss: 0.007328754058107734, Final Batch Loss: 0.006464942824095488\n",
      "Epoch 4160, Loss: 0.002340233768336475, Final Batch Loss: 0.0012773770140483975\n",
      "Epoch 4161, Loss: 0.01135164953302592, Final Batch Loss: 0.009729037061333656\n",
      "Epoch 4162, Loss: 0.001206400484079495, Final Batch Loss: 0.0004776798014063388\n",
      "Epoch 4163, Loss: 0.0033615058637224138, Final Batch Loss: 0.0025072721764445305\n",
      "Epoch 4164, Loss: 0.013219191692769527, Final Batch Loss: 0.008920136839151382\n",
      "Epoch 4165, Loss: 0.05438460153527558, Final Batch Loss: 0.051981791853904724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4166, Loss: 0.015476100612431765, Final Batch Loss: 0.003586897160857916\n",
      "Epoch 4167, Loss: 0.0049206880503334105, Final Batch Loss: 0.004073105752468109\n",
      "Epoch 4168, Loss: 0.009744805051013827, Final Batch Loss: 0.002892141928896308\n",
      "Epoch 4169, Loss: 0.019085057079792023, Final Batch Loss: 0.00637821014970541\n",
      "Epoch 4170, Loss: 0.013866878580302, Final Batch Loss: 0.0027594626881182194\n",
      "Epoch 4171, Loss: 0.012887797318398952, Final Batch Loss: 0.005714091472327709\n",
      "Epoch 4172, Loss: 0.013872029259800911, Final Batch Loss: 0.009592466987669468\n",
      "Epoch 4173, Loss: 0.010419053956866264, Final Batch Loss: 0.004160122014582157\n",
      "Epoch 4174, Loss: 0.01163989375345409, Final Batch Loss: 0.0031390886288136244\n",
      "Epoch 4175, Loss: 0.012240133015438914, Final Batch Loss: 0.010042375884950161\n",
      "Epoch 4176, Loss: 0.0076067801273893565, Final Batch Loss: 0.00038291930104605854\n",
      "Epoch 4177, Loss: 0.01028024172410369, Final Batch Loss: 0.0005319691263139248\n",
      "Epoch 4178, Loss: 0.007223069202154875, Final Batch Loss: 0.0046087391674518585\n",
      "Epoch 4179, Loss: 0.0093241510912776, Final Batch Loss: 0.0032735601998865604\n",
      "Epoch 4180, Loss: 0.015915232739644125, Final Batch Loss: 0.000443126104073599\n",
      "Epoch 4181, Loss: 0.024182138382457197, Final Batch Loss: 0.0010779270669445395\n",
      "Epoch 4182, Loss: 0.006038377992808819, Final Batch Loss: 0.0015944945625960827\n",
      "Epoch 4183, Loss: 0.04446349758654833, Final Batch Loss: 0.04158811271190643\n",
      "Epoch 4184, Loss: 0.0032527497969567776, Final Batch Loss: 0.002052444266155362\n",
      "Epoch 4185, Loss: 0.0018251423025503755, Final Batch Loss: 0.0008226502686738968\n",
      "Epoch 4186, Loss: 0.0132110781269148, Final Batch Loss: 0.0007335861446335912\n",
      "Epoch 4187, Loss: 0.0021684382227249444, Final Batch Loss: 0.0015843921573832631\n",
      "Epoch 4188, Loss: 0.004390738205984235, Final Batch Loss: 0.0030289413407444954\n",
      "Epoch 4189, Loss: 0.0020970076438970864, Final Batch Loss: 0.0013770173536613584\n",
      "Epoch 4190, Loss: 0.002364042855333537, Final Batch Loss: 0.0018066688207909465\n",
      "Epoch 4191, Loss: 0.013719166163355112, Final Batch Loss: 0.003759282175451517\n",
      "Epoch 4192, Loss: 0.01665442599914968, Final Batch Loss: 0.014970965683460236\n",
      "Epoch 4193, Loss: 0.007293350761756301, Final Batch Loss: 0.0037565184757113457\n",
      "Epoch 4194, Loss: 0.0030507983174175024, Final Batch Loss: 0.0006529125384986401\n",
      "Epoch 4195, Loss: 0.002026247908361256, Final Batch Loss: 0.000594210927374661\n",
      "Epoch 4196, Loss: 0.03071496053598821, Final Batch Loss: 0.02703511156141758\n",
      "Epoch 4197, Loss: 0.008341390290297568, Final Batch Loss: 0.001475985744036734\n",
      "Epoch 4198, Loss: 0.0038593566860072315, Final Batch Loss: 0.00023022218374535441\n",
      "Epoch 4199, Loss: 0.009404803247889504, Final Batch Loss: 0.0003162497596349567\n",
      "Epoch 4200, Loss: 0.012746070977300406, Final Batch Loss: 0.004544564988464117\n",
      "Epoch 4201, Loss: 0.0037999588530510664, Final Batch Loss: 0.0023687349166721106\n",
      "Epoch 4202, Loss: 0.0073718426283448935, Final Batch Loss: 0.0029360393527895212\n",
      "Epoch 4203, Loss: 0.008591271587647498, Final Batch Loss: 0.0018272452289238572\n",
      "Epoch 4204, Loss: 0.005667310208082199, Final Batch Loss: 0.00167500926181674\n",
      "Epoch 4205, Loss: 0.006516022840514779, Final Batch Loss: 0.0028232079930603504\n",
      "Epoch 4206, Loss: 0.008404722670093179, Final Batch Loss: 0.005563755519688129\n",
      "Epoch 4207, Loss: 0.006478495895862579, Final Batch Loss: 0.0013684742152690887\n",
      "Epoch 4208, Loss: 0.01466784079093486, Final Batch Loss: 0.013480608351528645\n",
      "Epoch 4209, Loss: 0.01049639517441392, Final Batch Loss: 0.006680973339825869\n",
      "Epoch 4210, Loss: 0.0030210662516765296, Final Batch Loss: 0.0007882285281084478\n",
      "Epoch 4211, Loss: 0.0021026028553023934, Final Batch Loss: 0.0007389952661469579\n",
      "Epoch 4212, Loss: 0.00739797530695796, Final Batch Loss: 0.004683089908212423\n",
      "Epoch 4213, Loss: 0.007214624900370836, Final Batch Loss: 0.0012165210209786892\n",
      "Epoch 4214, Loss: 0.02003801497630775, Final Batch Loss: 0.0031181115191429853\n",
      "Epoch 4215, Loss: 0.0027807075530290604, Final Batch Loss: 0.00020556640811264515\n",
      "Epoch 4216, Loss: 0.007496320642530918, Final Batch Loss: 0.0023181717842817307\n",
      "Epoch 4217, Loss: 0.034539492102339864, Final Batch Loss: 0.032246243208646774\n",
      "Epoch 4218, Loss: 0.0023298144224099815, Final Batch Loss: 0.0006314291968010366\n",
      "Epoch 4219, Loss: 0.03752022888511419, Final Batch Loss: 0.023276133462786674\n",
      "Epoch 4220, Loss: 0.01896043319720775, Final Batch Loss: 0.01776777394115925\n",
      "Epoch 4221, Loss: 0.021506631281226873, Final Batch Loss: 0.0027991789393126965\n",
      "Epoch 4222, Loss: 0.0027289942954666913, Final Batch Loss: 0.0006276919157244265\n",
      "Epoch 4223, Loss: 0.006279804976657033, Final Batch Loss: 0.0011157814878970385\n",
      "Epoch 4224, Loss: 0.03563281614333391, Final Batch Loss: 0.010188649408519268\n",
      "Epoch 4225, Loss: 0.0008502596465405077, Final Batch Loss: 0.00012571437400765717\n",
      "Epoch 4226, Loss: 0.00394041498657316, Final Batch Loss: 0.0018399028340354562\n",
      "Epoch 4227, Loss: 0.014465834246948361, Final Batch Loss: 0.0007462624926120043\n",
      "Epoch 4228, Loss: 0.019619689788669348, Final Batch Loss: 0.013902413658797741\n",
      "Epoch 4229, Loss: 0.017058872967027128, Final Batch Loss: 0.001171580865047872\n",
      "Epoch 4230, Loss: 0.049857212230563164, Final Batch Loss: 0.02433309331536293\n",
      "Epoch 4231, Loss: 0.0043290245812386274, Final Batch Loss: 0.0031542060896754265\n",
      "Epoch 4232, Loss: 0.009616011753678322, Final Batch Loss: 0.006315924227237701\n",
      "Epoch 4233, Loss: 0.017653264105319977, Final Batch Loss: 0.0022807633504271507\n",
      "Epoch 4234, Loss: 0.006566757103428245, Final Batch Loss: 0.0020036182831972837\n",
      "Epoch 4235, Loss: 0.030184517381712794, Final Batch Loss: 0.027582861483097076\n",
      "Epoch 4236, Loss: 0.031090041156858206, Final Batch Loss: 0.004398468416184187\n",
      "Epoch 4237, Loss: 0.015164693351835012, Final Batch Loss: 0.0022260905243456364\n",
      "Epoch 4238, Loss: 0.00850759248714894, Final Batch Loss: 0.006657775025814772\n",
      "Epoch 4239, Loss: 0.0034251661272719502, Final Batch Loss: 0.001954365288838744\n",
      "Epoch 4240, Loss: 0.009414662141352892, Final Batch Loss: 0.0010962947271764278\n",
      "Epoch 4241, Loss: 0.013227305375039577, Final Batch Loss: 0.005449202377349138\n",
      "Epoch 4242, Loss: 0.07654903456568718, Final Batch Loss: 0.0324566550552845\n",
      "Epoch 4243, Loss: 0.06787693034857512, Final Batch Loss: 0.006128768436610699\n",
      "Epoch 4244, Loss: 0.012549101607874036, Final Batch Loss: 0.003714547725394368\n",
      "Epoch 4245, Loss: 0.009689254919067025, Final Batch Loss: 0.007689673453569412\n",
      "Epoch 4246, Loss: 0.003788157133385539, Final Batch Loss: 0.001939374953508377\n",
      "Epoch 4247, Loss: 0.004778467526193708, Final Batch Loss: 0.004171909298747778\n",
      "Epoch 4248, Loss: 0.026271480601280928, Final Batch Loss: 0.006314258556813002\n",
      "Epoch 4249, Loss: 0.004888091469183564, Final Batch Loss: 0.0014211460947990417\n",
      "Epoch 4250, Loss: 0.0021896235994063318, Final Batch Loss: 0.001344630611129105\n",
      "Epoch 4251, Loss: 0.1132965951692313, Final Batch Loss: 0.0018664493691176176\n",
      "Epoch 4252, Loss: 0.004642908810637891, Final Batch Loss: 0.0035496505443006754\n",
      "Epoch 4253, Loss: 0.012136202305555344, Final Batch Loss: 0.0030896440148353577\n",
      "Epoch 4254, Loss: 0.005238028767053038, Final Batch Loss: 0.004380479920655489\n",
      "Epoch 4255, Loss: 0.009139768895693123, Final Batch Loss: 0.008005807176232338\n",
      "Epoch 4256, Loss: 0.010584215284325182, Final Batch Loss: 0.009375153109431267\n",
      "Epoch 4257, Loss: 0.002951713395304978, Final Batch Loss: 0.0012538585579022765\n",
      "Epoch 4258, Loss: 0.004636753816157579, Final Batch Loss: 0.002466754289343953\n",
      "Epoch 4259, Loss: 0.002895686135161668, Final Batch Loss: 0.0006976868608035147\n",
      "Epoch 4260, Loss: 0.007459488697350025, Final Batch Loss: 0.005498644430190325\n",
      "Epoch 4261, Loss: 0.0025067239766940475, Final Batch Loss: 0.001110757584683597\n",
      "Epoch 4262, Loss: 0.012259972630999982, Final Batch Loss: 0.010736537165939808\n",
      "Epoch 4263, Loss: 0.006103628198616207, Final Batch Loss: 0.0014006550190970302\n",
      "Epoch 4264, Loss: 0.0042386169952806085, Final Batch Loss: 0.0038003812078386545\n",
      "Epoch 4265, Loss: 0.004630743525922298, Final Batch Loss: 0.001056378474459052\n",
      "Epoch 4266, Loss: 0.06181960855610669, Final Batch Loss: 0.002608808921650052\n",
      "Epoch 4267, Loss: 0.037634676322340965, Final Batch Loss: 0.022693239152431488\n",
      "Epoch 4268, Loss: 0.01718287682160735, Final Batch Loss: 0.004700378980487585\n",
      "Epoch 4269, Loss: 0.03499041707254946, Final Batch Loss: 0.03317419812083244\n",
      "Epoch 4270, Loss: 0.009039182681590319, Final Batch Loss: 0.00220310827717185\n",
      "Epoch 4271, Loss: 0.006316610611975193, Final Batch Loss: 0.0010950122959911823\n",
      "Epoch 4272, Loss: 0.0049035807605832815, Final Batch Loss: 0.0030328056309372187\n",
      "Epoch 4273, Loss: 0.007659337017685175, Final Batch Loss: 0.0020705792121589184\n",
      "Epoch 4274, Loss: 0.0030875203665345907, Final Batch Loss: 0.0017537366366013885\n",
      "Epoch 4275, Loss: 0.008878775872290134, Final Batch Loss: 0.006733606569468975\n",
      "Epoch 4276, Loss: 0.0030277561745606363, Final Batch Loss: 0.0005411558668129146\n",
      "Epoch 4277, Loss: 0.003248158987844363, Final Batch Loss: 0.0003231364826206118\n",
      "Epoch 4278, Loss: 0.0021753052133135498, Final Batch Loss: 0.00056646071607247\n",
      "Epoch 4279, Loss: 0.048667834722436965, Final Batch Loss: 0.04717374965548515\n",
      "Epoch 4280, Loss: 0.001165030524134636, Final Batch Loss: 0.0007510896539315581\n",
      "Epoch 4281, Loss: 0.0024010438355617225, Final Batch Loss: 0.0005169221549294889\n",
      "Epoch 4282, Loss: 0.006095793913118541, Final Batch Loss: 0.0017591648502275348\n",
      "Epoch 4283, Loss: 0.015521961497142911, Final Batch Loss: 0.0005742425564676523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4284, Loss: 0.008667225716635585, Final Batch Loss: 0.00552005460485816\n",
      "Epoch 4285, Loss: 0.004397520329803228, Final Batch Loss: 0.0022416594438254833\n",
      "Epoch 4286, Loss: 0.010763079422758892, Final Batch Loss: 0.00035220806603319943\n",
      "Epoch 4287, Loss: 0.004393081413581967, Final Batch Loss: 0.0019094855524599552\n",
      "Epoch 4288, Loss: 0.006760668475180864, Final Batch Loss: 0.005357226822525263\n",
      "Epoch 4289, Loss: 0.010505266254767776, Final Batch Loss: 0.007859067060053349\n",
      "Epoch 4290, Loss: 0.006956817116588354, Final Batch Loss: 0.0049531590193510056\n",
      "Epoch 4291, Loss: 0.004529483732767403, Final Batch Loss: 0.0012235016329213977\n",
      "Epoch 4292, Loss: 0.005838459590449929, Final Batch Loss: 0.0022246837615966797\n",
      "Epoch 4293, Loss: 0.011744930176064372, Final Batch Loss: 0.002269517397508025\n",
      "Epoch 4294, Loss: 0.007093640859238803, Final Batch Loss: 0.005152851343154907\n",
      "Epoch 4295, Loss: 0.010502016521058977, Final Batch Loss: 0.0011616492411121726\n",
      "Epoch 4296, Loss: 0.016139423241838813, Final Batch Loss: 0.0023363425862044096\n",
      "Epoch 4297, Loss: 0.009123236406594515, Final Batch Loss: 0.006531162653118372\n",
      "Epoch 4298, Loss: 0.00444361031986773, Final Batch Loss: 0.002799014560878277\n",
      "Epoch 4299, Loss: 0.000927387794945389, Final Batch Loss: 0.0004039880004711449\n",
      "Epoch 4300, Loss: 0.006729935063049197, Final Batch Loss: 0.004137474112212658\n",
      "Epoch 4301, Loss: 0.031188634980935603, Final Batch Loss: 0.030272170901298523\n",
      "Epoch 4302, Loss: 0.011850163107737899, Final Batch Loss: 0.01064249873161316\n",
      "Epoch 4303, Loss: 0.004170654341578484, Final Batch Loss: 0.002372334012761712\n",
      "Epoch 4304, Loss: 0.0116850322810933, Final Batch Loss: 0.009933898225426674\n",
      "Epoch 4305, Loss: 0.0073334561893716455, Final Batch Loss: 0.0012924271868541837\n",
      "Epoch 4306, Loss: 0.006446904793847352, Final Batch Loss: 0.005834734998643398\n",
      "Epoch 4307, Loss: 0.005646402016282082, Final Batch Loss: 0.003138133091852069\n",
      "Epoch 4308, Loss: 0.007123492789105512, Final Batch Loss: 0.006885357666760683\n",
      "Epoch 4309, Loss: 0.0031965032685548067, Final Batch Loss: 0.001262082252651453\n",
      "Epoch 4310, Loss: 0.013555568875744939, Final Batch Loss: 0.010638232342898846\n",
      "Epoch 4311, Loss: 0.0010960367508232594, Final Batch Loss: 0.00019936077296733856\n",
      "Epoch 4312, Loss: 0.0025017302250489593, Final Batch Loss: 0.001839782577008009\n",
      "Epoch 4313, Loss: 0.03995359409600496, Final Batch Loss: 0.01309195440262556\n",
      "Epoch 4314, Loss: 0.012100664898753166, Final Batch Loss: 0.008141794241964817\n",
      "Epoch 4315, Loss: 0.041536558885127306, Final Batch Loss: 0.007145092356950045\n",
      "Epoch 4316, Loss: 0.003548310836777091, Final Batch Loss: 0.0010525293182581663\n",
      "Epoch 4317, Loss: 0.0026614482048898935, Final Batch Loss: 0.0014810013817623258\n",
      "Epoch 4318, Loss: 0.011427665478549898, Final Batch Loss: 0.00981163140386343\n",
      "Epoch 4319, Loss: 0.010921122506260872, Final Batch Loss: 0.004707972053438425\n",
      "Epoch 4320, Loss: 0.002250230376375839, Final Batch Loss: 0.0002538093540351838\n",
      "Epoch 4321, Loss: 0.10665281454566866, Final Batch Loss: 0.0009127740049734712\n",
      "Epoch 4322, Loss: 0.007776812883093953, Final Batch Loss: 0.0069032772444188595\n",
      "Epoch 4323, Loss: 0.0025424088817089796, Final Batch Loss: 0.0012768314918503165\n",
      "Epoch 4324, Loss: 0.0017878944636322558, Final Batch Loss: 0.0008105921442620456\n",
      "Epoch 4325, Loss: 0.005238569690845907, Final Batch Loss: 0.001162333763204515\n",
      "Epoch 4326, Loss: 0.010825524106621742, Final Batch Loss: 0.006730592809617519\n",
      "Epoch 4327, Loss: 0.028984363249037415, Final Batch Loss: 0.0007100487709976733\n",
      "Epoch 4328, Loss: 0.0027560272137634456, Final Batch Loss: 0.000869917159434408\n",
      "Epoch 4329, Loss: 0.023724950850009918, Final Batch Loss: 0.021181104704737663\n",
      "Epoch 4330, Loss: 0.003283114929217845, Final Batch Loss: 0.0005230957758612931\n",
      "Epoch 4331, Loss: 0.022879648488014936, Final Batch Loss: 0.01785406284034252\n",
      "Epoch 4332, Loss: 0.002636793433339335, Final Batch Loss: 0.00018100453598890454\n",
      "Epoch 4333, Loss: 0.038094097282737494, Final Batch Loss: 0.03525193780660629\n",
      "Epoch 4334, Loss: 0.003428418072871864, Final Batch Loss: 0.0009986829245463014\n",
      "Epoch 4335, Loss: 0.016040225513279438, Final Batch Loss: 0.005173224024474621\n",
      "Epoch 4336, Loss: 0.002373964962316677, Final Batch Loss: 0.00019906085799448192\n",
      "Epoch 4337, Loss: 0.007710830366704613, Final Batch Loss: 0.006770214065909386\n",
      "Epoch 4338, Loss: 0.08562726341187954, Final Batch Loss: 0.06795243918895721\n",
      "Epoch 4339, Loss: 0.025937921309377998, Final Batch Loss: 0.025197576731443405\n",
      "Epoch 4340, Loss: 0.006675907177850604, Final Batch Loss: 0.0029196098912507296\n",
      "Epoch 4341, Loss: 0.06115565006621182, Final Batch Loss: 0.05904039740562439\n",
      "Epoch 4342, Loss: 0.008172616362571716, Final Batch Loss: 0.005695072468370199\n",
      "Epoch 4343, Loss: 0.022537423064932227, Final Batch Loss: 0.019581368193030357\n",
      "Epoch 4344, Loss: 0.03415295749437064, Final Batch Loss: 0.032670650631189346\n",
      "Epoch 4345, Loss: 0.008707716478966177, Final Batch Loss: 0.0016205402789637446\n",
      "Epoch 4346, Loss: 0.013827927177771926, Final Batch Loss: 0.011768932454288006\n",
      "Epoch 4347, Loss: 0.007766323396936059, Final Batch Loss: 0.002974645933136344\n",
      "Epoch 4348, Loss: 0.018196111952420324, Final Batch Loss: 0.017697203904390335\n",
      "Epoch 4349, Loss: 0.0017815001774579287, Final Batch Loss: 0.0006513502448797226\n",
      "Epoch 4350, Loss: 0.004932316252961755, Final Batch Loss: 0.0005113326478749514\n",
      "Epoch 4351, Loss: 0.001643902069190517, Final Batch Loss: 0.0012529934756457806\n",
      "Epoch 4352, Loss: 0.006570759695023298, Final Batch Loss: 0.0036849412135779858\n",
      "Epoch 4353, Loss: 0.004175689478870481, Final Batch Loss: 0.0008713746792636812\n",
      "Epoch 4354, Loss: 0.0034899053862318397, Final Batch Loss: 0.0005256192525848746\n",
      "Epoch 4355, Loss: 0.0035036824992857873, Final Batch Loss: 0.0006743361591361463\n",
      "Epoch 4356, Loss: 0.008928148541599512, Final Batch Loss: 0.00604837853461504\n",
      "Epoch 4357, Loss: 0.00596487321308814, Final Batch Loss: 0.0004297120904084295\n",
      "Epoch 4358, Loss: 0.06186450051609427, Final Batch Loss: 0.060281720012426376\n",
      "Epoch 4359, Loss: 0.005999695451464504, Final Batch Loss: 0.00512477895244956\n",
      "Epoch 4360, Loss: 0.006414417875930667, Final Batch Loss: 0.0025661103427410126\n",
      "Epoch 4361, Loss: 0.010841751703992486, Final Batch Loss: 0.0019942924845963717\n",
      "Epoch 4362, Loss: 0.010048972209915519, Final Batch Loss: 0.008124122396111488\n",
      "Epoch 4363, Loss: 0.015078656142577529, Final Batch Loss: 0.001467356225475669\n",
      "Epoch 4364, Loss: 0.0023441138910129666, Final Batch Loss: 0.0011083449935540557\n",
      "Epoch 4365, Loss: 0.004076034529134631, Final Batch Loss: 0.003002326702699065\n",
      "Epoch 4366, Loss: 0.005518580204807222, Final Batch Loss: 0.0014469994930550456\n",
      "Epoch 4367, Loss: 0.0031566727557219565, Final Batch Loss: 0.0023937630467116833\n",
      "Epoch 4368, Loss: 0.04870409797877073, Final Batch Loss: 0.03590666875243187\n",
      "Epoch 4369, Loss: 0.006260065478272736, Final Batch Loss: 0.0012345426948741078\n",
      "Epoch 4370, Loss: 0.0044214769441168755, Final Batch Loss: 0.00047556005301885307\n",
      "Epoch 4371, Loss: 0.03303330880589783, Final Batch Loss: 0.03171642869710922\n",
      "Epoch 4372, Loss: 0.0016291873180307448, Final Batch Loss: 0.0008080957923084497\n",
      "Epoch 4373, Loss: 0.005700538284145296, Final Batch Loss: 0.0006817512912675738\n",
      "Epoch 4374, Loss: 0.011884609004482627, Final Batch Loss: 0.002783603733405471\n",
      "Epoch 4375, Loss: 0.017006132751703262, Final Batch Loss: 0.00737917423248291\n",
      "Epoch 4376, Loss: 0.014794807881116867, Final Batch Loss: 0.007602127734571695\n",
      "Epoch 4377, Loss: 0.0027821658295579255, Final Batch Loss: 0.0005325598758645356\n",
      "Epoch 4378, Loss: 0.015753104351460934, Final Batch Loss: 0.005876606330275536\n",
      "Epoch 4379, Loss: 0.0050875169690698385, Final Batch Loss: 0.0030266984831541777\n",
      "Epoch 4380, Loss: 0.0009018272103276104, Final Batch Loss: 0.00038255119579844177\n",
      "Epoch 4381, Loss: 0.011697601235937327, Final Batch Loss: 0.000766008801292628\n",
      "Epoch 4382, Loss: 0.007868336047977209, Final Batch Loss: 0.00407605292275548\n",
      "Epoch 4383, Loss: 0.003919036709703505, Final Batch Loss: 0.0018730830634012818\n",
      "Epoch 4384, Loss: 0.002932410396169871, Final Batch Loss: 0.0007479360210709274\n",
      "Epoch 4385, Loss: 0.0030540688894689083, Final Batch Loss: 0.0028152542654424906\n",
      "Epoch 4386, Loss: 0.004839224391616881, Final Batch Loss: 0.003523493418470025\n",
      "Epoch 4387, Loss: 0.008996725548058748, Final Batch Loss: 0.0024763490073382854\n",
      "Epoch 4388, Loss: 0.004078739497344941, Final Batch Loss: 0.00029977638041600585\n",
      "Epoch 4389, Loss: 0.00729148113168776, Final Batch Loss: 0.002043342450633645\n",
      "Epoch 4390, Loss: 0.015570804942399263, Final Batch Loss: 0.0022629783488810062\n",
      "Epoch 4391, Loss: 0.0019260156550444663, Final Batch Loss: 0.0011867715511471033\n",
      "Epoch 4392, Loss: 0.0032809959957376122, Final Batch Loss: 0.0014711912954226136\n",
      "Epoch 4393, Loss: 0.003577008959837258, Final Batch Loss: 0.0030785787384957075\n",
      "Epoch 4394, Loss: 0.002001476881559938, Final Batch Loss: 0.0015021634753793478\n",
      "Epoch 4395, Loss: 0.0028084944933652878, Final Batch Loss: 0.001411585370078683\n",
      "Epoch 4396, Loss: 0.003670586389489472, Final Batch Loss: 0.0019171854946762323\n",
      "Epoch 4397, Loss: 0.11529692658223212, Final Batch Loss: 0.11257143318653107\n",
      "Epoch 4398, Loss: 0.005735282087698579, Final Batch Loss: 0.0015225207898765802\n",
      "Epoch 4399, Loss: 0.011507087154313922, Final Batch Loss: 0.0009469285141676664\n",
      "Epoch 4400, Loss: 0.0050677338149398565, Final Batch Loss: 0.0009760314133018255\n",
      "Epoch 4401, Loss: 0.019098308868706226, Final Batch Loss: 0.01754806376993656\n",
      "Epoch 4402, Loss: 0.00562547380104661, Final Batch Loss: 0.0011417469941079617\n",
      "Epoch 4403, Loss: 0.0032301985193043947, Final Batch Loss: 0.0022955192252993584\n",
      "Epoch 4404, Loss: 0.007569904206320643, Final Batch Loss: 0.0030234602745622396\n",
      "Epoch 4405, Loss: 0.016080624423921108, Final Batch Loss: 0.011221379041671753\n",
      "Epoch 4406, Loss: 0.016691527562215924, Final Batch Loss: 0.013701365329325199\n",
      "Epoch 4407, Loss: 0.03639449691399932, Final Batch Loss: 0.006201868411153555\n",
      "Epoch 4408, Loss: 0.02333638130221516, Final Batch Loss: 0.02246791683137417\n",
      "Epoch 4409, Loss: 0.11710414849221706, Final Batch Loss: 0.10397754609584808\n",
      "Epoch 4410, Loss: 0.018891162239015102, Final Batch Loss: 0.014496937394142151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4411, Loss: 0.0032031715381890535, Final Batch Loss: 0.0013280232669785619\n",
      "Epoch 4412, Loss: 0.0284543689340353, Final Batch Loss: 0.012872694991528988\n",
      "Epoch 4413, Loss: 0.07003562059253454, Final Batch Loss: 0.0068520670756697655\n",
      "Epoch 4414, Loss: 0.010278644040226936, Final Batch Loss: 0.002108488231897354\n",
      "Epoch 4415, Loss: 0.02842688385862857, Final Batch Loss: 0.0267751794308424\n",
      "Epoch 4416, Loss: 0.01033895241562277, Final Batch Loss: 0.0018832717323675752\n",
      "Epoch 4417, Loss: 0.01858702627941966, Final Batch Loss: 0.013100615702569485\n",
      "Epoch 4418, Loss: 0.0655510276556015, Final Batch Loss: 0.03163966163992882\n",
      "Epoch 4419, Loss: 0.011124542681500316, Final Batch Loss: 0.003029848216101527\n",
      "Epoch 4420, Loss: 0.005370003753341734, Final Batch Loss: 0.0011575251119211316\n",
      "Epoch 4421, Loss: 0.012170304078608751, Final Batch Loss: 0.00456384988501668\n",
      "Epoch 4422, Loss: 0.04658704763278365, Final Batch Loss: 0.0022109313867986202\n",
      "Epoch 4423, Loss: 0.015940990764647722, Final Batch Loss: 0.00891951285302639\n",
      "Epoch 4424, Loss: 0.01666624890640378, Final Batch Loss: 0.0017363750375807285\n",
      "Epoch 4425, Loss: 0.07365586049854755, Final Batch Loss: 0.044716086238622665\n",
      "Epoch 4426, Loss: 0.05730636790394783, Final Batch Loss: 0.018456075340509415\n",
      "Epoch 4427, Loss: 0.018781021935865283, Final Batch Loss: 0.01610245741903782\n",
      "Epoch 4428, Loss: 0.021833512000739574, Final Batch Loss: 0.004123038612306118\n",
      "Epoch 4429, Loss: 0.012962591368705034, Final Batch Loss: 0.007082792464643717\n",
      "Epoch 4430, Loss: 0.0066047554719261825, Final Batch Loss: 0.0006976832519285381\n",
      "Epoch 4431, Loss: 0.009470727061852813, Final Batch Loss: 0.0013769713696092367\n",
      "Epoch 4432, Loss: 0.08103641867637634, Final Batch Loss: 0.06221931800246239\n",
      "Epoch 4433, Loss: 0.023268824443221092, Final Batch Loss: 0.007985019125044346\n",
      "Epoch 4434, Loss: 0.020314844325184822, Final Batch Loss: 0.011033628135919571\n",
      "Epoch 4435, Loss: 0.004253722378052771, Final Batch Loss: 0.0017782029462978244\n",
      "Epoch 4436, Loss: 0.015442616073414683, Final Batch Loss: 0.0034224882256239653\n",
      "Epoch 4437, Loss: 0.005397126544266939, Final Batch Loss: 0.0016730274073779583\n",
      "Epoch 4438, Loss: 0.00913178944028914, Final Batch Loss: 0.006237958557903767\n",
      "Epoch 4439, Loss: 0.004439546260982752, Final Batch Loss: 0.0037046384532004595\n",
      "Epoch 4440, Loss: 0.005213294643908739, Final Batch Loss: 0.0004926947876811028\n",
      "Epoch 4441, Loss: 0.007251107366755605, Final Batch Loss: 0.004241021815687418\n",
      "Epoch 4442, Loss: 0.002762765099760145, Final Batch Loss: 0.0009233257151208818\n",
      "Epoch 4443, Loss: 0.0031965269008651376, Final Batch Loss: 0.0012388104805722833\n",
      "Epoch 4444, Loss: 0.007828003726899624, Final Batch Loss: 0.002571124117821455\n",
      "Epoch 4445, Loss: 0.00456761458190158, Final Batch Loss: 0.0009397750836797059\n",
      "Epoch 4446, Loss: 0.0257937703281641, Final Batch Loss: 0.0003327932208776474\n",
      "Epoch 4447, Loss: 0.026630351436324418, Final Batch Loss: 0.02595560811460018\n",
      "Epoch 4448, Loss: 0.021674233488738537, Final Batch Loss: 0.0004518507048487663\n",
      "Epoch 4449, Loss: 0.0021221116185188293, Final Batch Loss: 0.001017546164803207\n",
      "Epoch 4450, Loss: 0.0403530178591609, Final Batch Loss: 0.006777863018214703\n",
      "Epoch 4451, Loss: 0.008629654766991735, Final Batch Loss: 0.0016143487300723791\n",
      "Epoch 4452, Loss: 0.04272827785462141, Final Batch Loss: 0.00998112466186285\n",
      "Epoch 4453, Loss: 0.043060663156211376, Final Batch Loss: 0.013262872584164143\n",
      "Epoch 4454, Loss: 0.13114667683839798, Final Batch Loss: 0.10826917737722397\n",
      "Epoch 4455, Loss: 0.042111776769161224, Final Batch Loss: 0.03400684893131256\n",
      "Epoch 4456, Loss: 0.02064117230474949, Final Batch Loss: 0.008295531384646893\n",
      "Epoch 4457, Loss: 0.051708769984543324, Final Batch Loss: 0.049008212983608246\n",
      "Epoch 4458, Loss: 0.017508380580693483, Final Batch Loss: 0.012264574877917767\n",
      "Epoch 4459, Loss: 0.016071666963398457, Final Batch Loss: 0.005187755450606346\n",
      "Epoch 4460, Loss: 0.023796151392161846, Final Batch Loss: 0.01067365426570177\n",
      "Epoch 4461, Loss: 0.015013466589152813, Final Batch Loss: 0.003973015584051609\n",
      "Epoch 4462, Loss: 0.006030012737028301, Final Batch Loss: 0.0011182677699252963\n",
      "Epoch 4463, Loss: 0.004992066940758377, Final Batch Loss: 0.0009487923816777766\n",
      "Epoch 4464, Loss: 0.030258568469434977, Final Batch Loss: 0.025257723405957222\n",
      "Epoch 4465, Loss: 0.0066148143960163, Final Batch Loss: 0.0017047253204509616\n",
      "Epoch 4466, Loss: 0.010388848255388439, Final Batch Loss: 0.0014118709368631244\n",
      "Epoch 4467, Loss: 0.005109829129651189, Final Batch Loss: 0.002022228203713894\n",
      "Epoch 4468, Loss: 0.027728289365768433, Final Batch Loss: 0.021413423120975494\n",
      "Epoch 4469, Loss: 0.04581331927329302, Final Batch Loss: 0.04054025560617447\n",
      "Epoch 4470, Loss: 0.014025291195139289, Final Batch Loss: 0.010450673289597034\n",
      "Epoch 4471, Loss: 0.027708956273272634, Final Batch Loss: 0.0030329127330332994\n",
      "Epoch 4472, Loss: 0.014714138116687536, Final Batch Loss: 0.0014800899662077427\n",
      "Epoch 4473, Loss: 0.00572801404632628, Final Batch Loss: 0.0018340651877224445\n",
      "Epoch 4474, Loss: 0.03468055743724108, Final Batch Loss: 0.028106756508350372\n",
      "Epoch 4475, Loss: 0.01122106472030282, Final Batch Loss: 0.007231917232275009\n",
      "Epoch 4476, Loss: 0.004744947422295809, Final Batch Loss: 0.0027245902456343174\n",
      "Epoch 4477, Loss: 0.018654731567949057, Final Batch Loss: 0.011501363478600979\n",
      "Epoch 4478, Loss: 0.016889757942408323, Final Batch Loss: 0.0036663846112787724\n",
      "Epoch 4479, Loss: 0.008465675404295325, Final Batch Loss: 0.0030193428974598646\n",
      "Epoch 4480, Loss: 0.01267614762764424, Final Batch Loss: 0.011188860982656479\n",
      "Epoch 4481, Loss: 0.05276954988949001, Final Batch Loss: 0.050557319074869156\n",
      "Epoch 4482, Loss: 0.010733782779425383, Final Batch Loss: 0.006931540090590715\n",
      "Epoch 4483, Loss: 0.007551656803116202, Final Batch Loss: 0.005254390183836222\n",
      "Epoch 4484, Loss: 0.00787118193693459, Final Batch Loss: 0.0019481673371046782\n",
      "Epoch 4485, Loss: 0.02135354094207287, Final Batch Loss: 0.016630705446004868\n",
      "Epoch 4486, Loss: 0.011675884190481156, Final Batch Loss: 0.0007388267549686134\n",
      "Epoch 4487, Loss: 0.028457865118980408, Final Batch Loss: 0.008644720539450645\n",
      "Epoch 4488, Loss: 0.0029873300809413195, Final Batch Loss: 0.00150206102989614\n",
      "Epoch 4489, Loss: 0.007781569263897836, Final Batch Loss: 0.0019016506848856807\n",
      "Epoch 4490, Loss: 0.017921053804457188, Final Batch Loss: 0.01270956639200449\n",
      "Epoch 4491, Loss: 0.02802110370248556, Final Batch Loss: 0.003071642480790615\n",
      "Epoch 4492, Loss: 0.0077662651892751455, Final Batch Loss: 0.0012551357503980398\n",
      "Epoch 4493, Loss: 0.0420795981772244, Final Batch Loss: 0.0373852401971817\n",
      "Epoch 4494, Loss: 0.006232054554857314, Final Batch Loss: 0.004888476803898811\n",
      "Epoch 4495, Loss: 0.005445280112326145, Final Batch Loss: 0.0015793752390891314\n",
      "Epoch 4496, Loss: 0.08507704548537731, Final Batch Loss: 0.05973122641444206\n",
      "Epoch 4497, Loss: 0.03545195609331131, Final Batch Loss: 0.02496616542339325\n",
      "Epoch 4498, Loss: 0.02442845841869712, Final Batch Loss: 0.0015365811996161938\n",
      "Epoch 4499, Loss: 0.01644715527072549, Final Batch Loss: 0.01002154778689146\n",
      "Epoch 4500, Loss: 0.03254688601009548, Final Batch Loss: 0.03080231323838234\n",
      "Epoch 4501, Loss: 0.03410595189779997, Final Batch Loss: 0.01373042818158865\n",
      "Epoch 4502, Loss: 0.05244830250740051, Final Batch Loss: 0.027409512549638748\n",
      "Epoch 4503, Loss: 0.056248744018375874, Final Batch Loss: 0.011324864812195301\n",
      "Epoch 4504, Loss: 0.04247210919857025, Final Batch Loss: 0.009754598140716553\n",
      "Epoch 4505, Loss: 0.03844496142119169, Final Batch Loss: 0.0035102246329188347\n",
      "Epoch 4506, Loss: 0.1337331347167492, Final Batch Loss: 0.09848921000957489\n",
      "Epoch 4507, Loss: 0.0720756989903748, Final Batch Loss: 0.005002577323466539\n",
      "Epoch 4508, Loss: 0.11506651900708675, Final Batch Loss: 0.09701579809188843\n",
      "Epoch 4509, Loss: 0.028172688093036413, Final Batch Loss: 0.02195723168551922\n",
      "Epoch 4510, Loss: 0.041067469865083694, Final Batch Loss: 0.019495299085974693\n",
      "Epoch 4511, Loss: 0.07586034201085567, Final Batch Loss: 0.02344011329114437\n",
      "Epoch 4512, Loss: 0.03546574153006077, Final Batch Loss: 0.003942342475056648\n",
      "Epoch 4513, Loss: 0.011880680453032255, Final Batch Loss: 0.005723918788135052\n",
      "Epoch 4514, Loss: 0.01698796171694994, Final Batch Loss: 0.011231939308345318\n",
      "Epoch 4515, Loss: 0.04748018644750118, Final Batch Loss: 0.03955277428030968\n",
      "Epoch 4516, Loss: 0.011323563288897276, Final Batch Loss: 0.005798571277409792\n",
      "Epoch 4517, Loss: 0.03603064361959696, Final Batch Loss: 0.009394842199981213\n",
      "Epoch 4518, Loss: 0.004840707988478243, Final Batch Loss: 0.0012699732324108481\n",
      "Epoch 4519, Loss: 0.01024021441116929, Final Batch Loss: 0.0030559981241822243\n",
      "Epoch 4520, Loss: 0.024406117852777243, Final Batch Loss: 0.003122327383607626\n",
      "Epoch 4521, Loss: 0.013245349517092109, Final Batch Loss: 0.0023653411772102118\n",
      "Epoch 4522, Loss: 0.005299713462591171, Final Batch Loss: 0.003061003517359495\n",
      "Epoch 4523, Loss: 0.003775246615987271, Final Batch Loss: 0.0006824919837526977\n",
      "Epoch 4524, Loss: 0.006137563148513436, Final Batch Loss: 0.003015820635482669\n",
      "Epoch 4525, Loss: 0.06108121760189533, Final Batch Loss: 0.03171014040708542\n",
      "Epoch 4526, Loss: 0.018900180235505104, Final Batch Loss: 0.0014826860278844833\n",
      "Epoch 4527, Loss: 0.01474944967776537, Final Batch Loss: 0.009527389891445637\n",
      "Epoch 4528, Loss: 0.03590833768248558, Final Batch Loss: 0.013507531955838203\n",
      "Epoch 4529, Loss: 0.018938370048999786, Final Batch Loss: 0.01195510197430849\n",
      "Epoch 4530, Loss: 0.04778778925538063, Final Batch Loss: 0.018337378278374672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4531, Loss: 0.01748606376349926, Final Batch Loss: 0.007176501676440239\n",
      "Epoch 4532, Loss: 0.004881663480773568, Final Batch Loss: 0.0024835532531142235\n",
      "Epoch 4533, Loss: 0.04461692040786147, Final Batch Loss: 0.04110445827245712\n",
      "Epoch 4534, Loss: 0.008604092989116907, Final Batch Loss: 0.0026612957008183002\n",
      "Epoch 4535, Loss: 0.004622237524017692, Final Batch Loss: 0.0021402486599981785\n",
      "Epoch 4536, Loss: 0.009539829101413488, Final Batch Loss: 0.0034803971648216248\n",
      "Epoch 4537, Loss: 0.01622437231708318, Final Batch Loss: 0.0008603903697803617\n",
      "Epoch 4538, Loss: 0.039689112454652786, Final Batch Loss: 0.004518579691648483\n",
      "Epoch 4539, Loss: 0.005718751810491085, Final Batch Loss: 0.004142699763178825\n",
      "Epoch 4540, Loss: 0.019206359051167965, Final Batch Loss: 0.010618920437991619\n",
      "Epoch 4541, Loss: 0.03705666586756706, Final Batch Loss: 0.033453989773988724\n",
      "Epoch 4542, Loss: 0.021917168982326984, Final Batch Loss: 0.005903800018131733\n",
      "Epoch 4543, Loss: 0.05788034154102206, Final Batch Loss: 0.004332836251705885\n",
      "Epoch 4544, Loss: 0.02072143298573792, Final Batch Loss: 0.002017974155023694\n",
      "Epoch 4545, Loss: 0.0060572088696062565, Final Batch Loss: 0.00101918401196599\n",
      "Epoch 4546, Loss: 0.01359796104952693, Final Batch Loss: 0.0036483625881373882\n",
      "Epoch 4547, Loss: 0.007127081044018269, Final Batch Loss: 0.0011584158055484295\n",
      "Epoch 4548, Loss: 0.02220083848806098, Final Batch Loss: 0.0009123541531153023\n",
      "Epoch 4549, Loss: 0.0042769203428179026, Final Batch Loss: 0.0023168381303548813\n",
      "Epoch 4550, Loss: 0.07216967944987118, Final Batch Loss: 0.07000374794006348\n",
      "Epoch 4551, Loss: 0.04977266397327185, Final Batch Loss: 0.0103007135912776\n",
      "Epoch 4552, Loss: 0.09365862235426903, Final Batch Loss: 0.021593917161226273\n",
      "Epoch 4553, Loss: 0.041006687097251415, Final Batch Loss: 0.014087324030697346\n",
      "Epoch 4554, Loss: 0.013871670700609684, Final Batch Loss: 0.01137424074113369\n",
      "Epoch 4555, Loss: 0.013556029880419374, Final Batch Loss: 0.002683117287233472\n",
      "Epoch 4556, Loss: 0.0599934384226799, Final Batch Loss: 0.04540768265724182\n",
      "Epoch 4557, Loss: 0.07221545558422804, Final Batch Loss: 0.06311091780662537\n",
      "Epoch 4558, Loss: 0.00433095486368984, Final Batch Loss: 0.0017768429825082421\n",
      "Epoch 4559, Loss: 0.011538881342858076, Final Batch Loss: 0.004755801986902952\n",
      "Epoch 4560, Loss: 0.05993332900106907, Final Batch Loss: 0.03600476309657097\n",
      "Epoch 4561, Loss: 0.06703494396060705, Final Batch Loss: 0.05575176700949669\n",
      "Epoch 4562, Loss: 0.0070703725796192884, Final Batch Loss: 0.003914329223334789\n",
      "Epoch 4563, Loss: 0.022170251235365868, Final Batch Loss: 0.009206321090459824\n",
      "Epoch 4564, Loss: 0.011520277010276914, Final Batch Loss: 0.007960143499076366\n",
      "Epoch 4565, Loss: 0.048187135718762875, Final Batch Loss: 0.04003660008311272\n",
      "Epoch 4566, Loss: 0.006914784898981452, Final Batch Loss: 0.003379687899723649\n",
      "Epoch 4567, Loss: 0.036963794846087694, Final Batch Loss: 0.0022149202413856983\n",
      "Epoch 4568, Loss: 0.0040188736747950315, Final Batch Loss: 0.0028649033047258854\n",
      "Epoch 4569, Loss: 0.007052387576550245, Final Batch Loss: 0.003095458261668682\n",
      "Epoch 4570, Loss: 0.013845238485373557, Final Batch Loss: 0.0010003201896324754\n",
      "Epoch 4571, Loss: 0.006951543502509594, Final Batch Loss: 0.0017978865653276443\n",
      "Epoch 4572, Loss: 0.006500550080090761, Final Batch Loss: 0.004315695259720087\n",
      "Epoch 4573, Loss: 0.02038502914365381, Final Batch Loss: 0.018579691648483276\n",
      "Epoch 4574, Loss: 0.015336694894358516, Final Batch Loss: 0.002223922638222575\n",
      "Epoch 4575, Loss: 0.0048360446235165, Final Batch Loss: 0.0029708619695156813\n",
      "Epoch 4576, Loss: 0.0020554677466861904, Final Batch Loss: 0.0008700829348526895\n",
      "Epoch 4577, Loss: 0.025495989248156548, Final Batch Loss: 0.023398831486701965\n",
      "Epoch 4578, Loss: 0.01179515733383596, Final Batch Loss: 0.007985315285623074\n",
      "Epoch 4579, Loss: 0.06154860742390156, Final Batch Loss: 0.04419117420911789\n",
      "Epoch 4580, Loss: 0.009957964066416025, Final Batch Loss: 0.001972330268472433\n",
      "Epoch 4581, Loss: 0.07840776816010475, Final Batch Loss: 0.07395230233669281\n",
      "Epoch 4582, Loss: 0.006592421792447567, Final Batch Loss: 0.004451203625649214\n",
      "Epoch 4583, Loss: 0.008947013644501567, Final Batch Loss: 0.0027616212610155344\n",
      "Epoch 4584, Loss: 0.013329651672393084, Final Batch Loss: 0.0037878616712987423\n",
      "Epoch 4585, Loss: 0.004454100911971182, Final Batch Loss: 0.0006125764339230955\n",
      "Epoch 4586, Loss: 0.003308977233245969, Final Batch Loss: 0.0013032543938606977\n",
      "Epoch 4587, Loss: 0.013953085988759995, Final Batch Loss: 0.004854094237089157\n",
      "Epoch 4588, Loss: 0.01762390206567943, Final Batch Loss: 0.013941571116447449\n",
      "Epoch 4589, Loss: 0.003853519563563168, Final Batch Loss: 0.0011186673073098063\n",
      "Epoch 4590, Loss: 0.0019526666728779674, Final Batch Loss: 0.0007500211941078305\n",
      "Epoch 4591, Loss: 0.004517261986620724, Final Batch Loss: 0.0019235556246712804\n",
      "Epoch 4592, Loss: 0.014741315506398678, Final Batch Loss: 0.0069549488835036755\n",
      "Epoch 4593, Loss: 0.003833264228887856, Final Batch Loss: 0.0010943309171125293\n",
      "Epoch 4594, Loss: 0.011618469608947635, Final Batch Loss: 0.0023085407447069883\n",
      "Epoch 4595, Loss: 0.003283599391579628, Final Batch Loss: 0.0009348040912300348\n",
      "Epoch 4596, Loss: 0.0020690109813585877, Final Batch Loss: 0.0010500573553144932\n",
      "Epoch 4597, Loss: 0.0036642593331635, Final Batch Loss: 0.0024228591937571764\n",
      "Epoch 4598, Loss: 0.0023240570444613695, Final Batch Loss: 0.0009400693234056234\n",
      "Epoch 4599, Loss: 0.006497128983028233, Final Batch Loss: 0.0005965555319562554\n",
      "Epoch 4600, Loss: 0.008092162781395018, Final Batch Loss: 0.006376130506396294\n",
      "Epoch 4601, Loss: 0.005754083918873221, Final Batch Loss: 0.0004954287433065474\n",
      "Epoch 4602, Loss: 0.0018781180260702968, Final Batch Loss: 0.0008573068771511316\n",
      "Epoch 4603, Loss: 0.005714245373383164, Final Batch Loss: 0.0006204207893460989\n",
      "Epoch 4604, Loss: 0.009885669394861907, Final Batch Loss: 0.0005289052496664226\n",
      "Epoch 4605, Loss: 0.004070917493663728, Final Batch Loss: 0.0011931477347388864\n",
      "Epoch 4606, Loss: 0.006413226044969633, Final Batch Loss: 0.0004256530955899507\n",
      "Epoch 4607, Loss: 0.005093286163173616, Final Batch Loss: 0.001855782582424581\n",
      "Epoch 4608, Loss: 0.004214377957396209, Final Batch Loss: 0.0013572474708780646\n",
      "Epoch 4609, Loss: 0.003432742552831769, Final Batch Loss: 0.0009167864918708801\n",
      "Epoch 4610, Loss: 0.02379650855436921, Final Batch Loss: 0.004960228223353624\n",
      "Epoch 4611, Loss: 0.011540168430656195, Final Batch Loss: 0.002119146753102541\n",
      "Epoch 4612, Loss: 0.0035425019450485706, Final Batch Loss: 0.00242829043418169\n",
      "Epoch 4613, Loss: 0.002765342651400715, Final Batch Loss: 0.00039207242662087083\n",
      "Epoch 4614, Loss: 0.0088579673320055, Final Batch Loss: 0.006936424411833286\n",
      "Epoch 4615, Loss: 0.002196588844526559, Final Batch Loss: 0.0005946277524344623\n",
      "Epoch 4616, Loss: 0.017256644554436207, Final Batch Loss: 0.009813073091208935\n",
      "Epoch 4617, Loss: 0.0021660426864400506, Final Batch Loss: 0.0013118911301717162\n",
      "Epoch 4618, Loss: 0.009151154197752476, Final Batch Loss: 0.004033282399177551\n",
      "Epoch 4619, Loss: 0.009916513634379953, Final Batch Loss: 0.00038556515937671065\n",
      "Epoch 4620, Loss: 0.00670740578789264, Final Batch Loss: 0.0019160794327035546\n",
      "Epoch 4621, Loss: 0.003696156316436827, Final Batch Loss: 0.0016533093294128776\n",
      "Epoch 4622, Loss: 0.00716003030538559, Final Batch Loss: 0.0021658954210579395\n",
      "Epoch 4623, Loss: 0.025318273808807135, Final Batch Loss: 0.0013421433977782726\n",
      "Epoch 4624, Loss: 0.0032776323496364057, Final Batch Loss: 0.00018533499678596854\n",
      "Epoch 4625, Loss: 0.0035834259469993412, Final Batch Loss: 0.0026147780008614063\n",
      "Epoch 4626, Loss: 0.00915371673181653, Final Batch Loss: 0.004788163583725691\n",
      "Epoch 4627, Loss: 0.006814110558480024, Final Batch Loss: 0.0041063884273171425\n",
      "Epoch 4628, Loss: 0.05273511726409197, Final Batch Loss: 0.007121146656572819\n",
      "Epoch 4629, Loss: 0.00498331431299448, Final Batch Loss: 0.0021493348758667707\n",
      "Epoch 4630, Loss: 0.016731901559978724, Final Batch Loss: 0.013051665388047695\n",
      "Epoch 4631, Loss: 0.009277119766920805, Final Batch Loss: 0.00428154319524765\n",
      "Epoch 4632, Loss: 0.009520081803202629, Final Batch Loss: 0.0011991336941719055\n",
      "Epoch 4633, Loss: 0.01813472481444478, Final Batch Loss: 0.016053372994065285\n",
      "Epoch 4634, Loss: 0.004387550347018987, Final Batch Loss: 0.000940063560847193\n",
      "Epoch 4635, Loss: 0.0056272535584867, Final Batch Loss: 0.003738712752237916\n",
      "Epoch 4636, Loss: 0.006918167695403099, Final Batch Loss: 0.0009413775987923145\n",
      "Epoch 4637, Loss: 0.032125599682331085, Final Batch Loss: 0.01720087043941021\n",
      "Epoch 4638, Loss: 0.007919462397694588, Final Batch Loss: 0.006986841559410095\n",
      "Epoch 4639, Loss: 0.004265131487045437, Final Batch Loss: 0.0009052311652339995\n",
      "Epoch 4640, Loss: 0.010051670833490789, Final Batch Loss: 0.0019098216434940696\n",
      "Epoch 4641, Loss: 0.012795116286724806, Final Batch Loss: 0.008581863716244698\n",
      "Epoch 4642, Loss: 0.008055338286794722, Final Batch Loss: 0.0016010241815820336\n",
      "Epoch 4643, Loss: 0.004964707186445594, Final Batch Loss: 0.0010240913834422827\n",
      "Epoch 4644, Loss: 0.030911736364942044, Final Batch Loss: 0.0008789898711256683\n",
      "Epoch 4645, Loss: 0.05590192228555679, Final Batch Loss: 0.04022311791777611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4646, Loss: 0.0037948533426970243, Final Batch Loss: 0.0024493972305208445\n",
      "Epoch 4647, Loss: 0.017035709810443223, Final Batch Loss: 0.015119334682822227\n",
      "Epoch 4648, Loss: 0.0236552432179451, Final Batch Loss: 0.005109289661049843\n",
      "Epoch 4649, Loss: 0.0435425853356719, Final Batch Loss: 0.03609233349561691\n",
      "Epoch 4650, Loss: 0.028107217513024807, Final Batch Loss: 0.015580250881612301\n",
      "Epoch 4651, Loss: 0.022288869600743055, Final Batch Loss: 0.02068328857421875\n",
      "Epoch 4652, Loss: 0.011252034921199083, Final Batch Loss: 0.003984373994171619\n",
      "Epoch 4653, Loss: 0.0059987930580973625, Final Batch Loss: 0.0013304892927408218\n",
      "Epoch 4654, Loss: 0.013138176407665014, Final Batch Loss: 0.009003613144159317\n",
      "Epoch 4655, Loss: 0.036182392737828195, Final Batch Loss: 0.0017372820293530822\n",
      "Epoch 4656, Loss: 0.014990067342296243, Final Batch Loss: 0.011564758606255054\n",
      "Epoch 4657, Loss: 0.005850752990227193, Final Batch Loss: 0.005116068292409182\n",
      "Epoch 4658, Loss: 0.012498883996158838, Final Batch Loss: 0.005145820323377848\n",
      "Epoch 4659, Loss: 0.010687198024243116, Final Batch Loss: 0.004490741062909365\n",
      "Epoch 4660, Loss: 0.008332978002727032, Final Batch Loss: 0.004268185701221228\n",
      "Epoch 4661, Loss: 0.018366889795288444, Final Batch Loss: 0.0012442057486623526\n",
      "Epoch 4662, Loss: 0.013233703561127186, Final Batch Loss: 0.006607083138078451\n",
      "Epoch 4663, Loss: 0.005154015263542533, Final Batch Loss: 0.0014943829737603664\n",
      "Epoch 4664, Loss: 0.021596482256427407, Final Batch Loss: 0.018016915768384933\n",
      "Epoch 4665, Loss: 0.008587463409639895, Final Batch Loss: 0.000979592208750546\n",
      "Epoch 4666, Loss: 0.0022280484554357827, Final Batch Loss: 0.0008796480833552778\n",
      "Epoch 4667, Loss: 0.002226330805569887, Final Batch Loss: 0.0007862432394176722\n",
      "Epoch 4668, Loss: 0.00490005558822304, Final Batch Loss: 0.003056027926504612\n",
      "Epoch 4669, Loss: 0.007618761621415615, Final Batch Loss: 0.0021556150168180466\n",
      "Epoch 4670, Loss: 0.009479344356805086, Final Batch Loss: 0.004167848266661167\n",
      "Epoch 4671, Loss: 0.020331221050582826, Final Batch Loss: 0.019039753824472427\n",
      "Epoch 4672, Loss: 0.025148754939436913, Final Batch Loss: 0.01371253002434969\n",
      "Epoch 4673, Loss: 0.0075081560062244534, Final Batch Loss: 0.001474593416787684\n",
      "Epoch 4674, Loss: 0.018598351976834238, Final Batch Loss: 0.01764189638197422\n",
      "Epoch 4675, Loss: 0.010365590918809175, Final Batch Loss: 0.007367487531155348\n",
      "Epoch 4676, Loss: 0.012832745094783604, Final Batch Loss: 0.010907460935413837\n",
      "Epoch 4677, Loss: 0.05046144628431648, Final Batch Loss: 0.04884781315922737\n",
      "Epoch 4678, Loss: 0.006265158299356699, Final Batch Loss: 0.004966806620359421\n",
      "Epoch 4679, Loss: 0.06347906473092735, Final Batch Loss: 0.061197809875011444\n",
      "Epoch 4680, Loss: 0.0061713982140645385, Final Batch Loss: 0.0011216177372261882\n",
      "Epoch 4681, Loss: 0.005307733081281185, Final Batch Loss: 0.0029319727327674627\n",
      "Epoch 4682, Loss: 0.029531240463256836, Final Batch Loss: 0.027969053015112877\n",
      "Epoch 4683, Loss: 0.04343566088937223, Final Batch Loss: 0.0025806555058807135\n",
      "Epoch 4684, Loss: 0.01327302074059844, Final Batch Loss: 0.0034379721619188786\n",
      "Epoch 4685, Loss: 0.027007238939404488, Final Batch Loss: 0.0023707766085863113\n",
      "Epoch 4686, Loss: 0.015662440098822117, Final Batch Loss: 0.005478900857269764\n",
      "Epoch 4687, Loss: 0.014743846841156483, Final Batch Loss: 0.005066707730293274\n",
      "Epoch 4688, Loss: 0.012750864494591951, Final Batch Loss: 0.006545324344187975\n",
      "Epoch 4689, Loss: 0.04027171339839697, Final Batch Loss: 0.031124655157327652\n",
      "Epoch 4690, Loss: 0.006610335491131991, Final Batch Loss: 0.0006818544934503734\n",
      "Epoch 4691, Loss: 0.01133037218824029, Final Batch Loss: 0.003293281886726618\n",
      "Epoch 4692, Loss: 0.018087330274283886, Final Batch Loss: 0.007794021628797054\n",
      "Epoch 4693, Loss: 0.020495441276580095, Final Batch Loss: 0.005877186078578234\n",
      "Epoch 4694, Loss: 0.010221605829428881, Final Batch Loss: 0.0007593647460453212\n",
      "Epoch 4695, Loss: 0.020784649532288313, Final Batch Loss: 0.013904905878007412\n",
      "Epoch 4696, Loss: 0.0023670666851103306, Final Batch Loss: 0.0005601331358775496\n",
      "Epoch 4697, Loss: 0.05133776040747762, Final Batch Loss: 0.0007340353913605213\n",
      "Epoch 4698, Loss: 0.007247720146551728, Final Batch Loss: 0.003895958885550499\n",
      "Epoch 4699, Loss: 0.013381440658122301, Final Batch Loss: 0.005835145711898804\n",
      "Epoch 4700, Loss: 0.010020404355600476, Final Batch Loss: 0.0027658629696816206\n",
      "Epoch 4701, Loss: 0.00922624277882278, Final Batch Loss: 0.006084104534238577\n",
      "Epoch 4702, Loss: 0.02936451241839677, Final Batch Loss: 0.0011316455202177167\n",
      "Epoch 4703, Loss: 0.013466974953189492, Final Batch Loss: 0.0036494790110737085\n",
      "Epoch 4704, Loss: 0.005582618759945035, Final Batch Loss: 0.0025720668490976095\n",
      "Epoch 4705, Loss: 0.004079054342582822, Final Batch Loss: 0.0020777385216206312\n",
      "Epoch 4706, Loss: 0.003610231331549585, Final Batch Loss: 0.0015239814529195428\n",
      "Epoch 4707, Loss: 0.02692586020566523, Final Batch Loss: 0.0035639351699501276\n",
      "Epoch 4708, Loss: 0.007276298681972548, Final Batch Loss: 0.0067953490652143955\n",
      "Epoch 4709, Loss: 0.0051965254824608564, Final Batch Loss: 0.0011646540369838476\n",
      "Epoch 4710, Loss: 0.005842815851792693, Final Batch Loss: 0.0019836323335766792\n",
      "Epoch 4711, Loss: 0.0063787654507905245, Final Batch Loss: 0.0014202406164258718\n",
      "Epoch 4712, Loss: 0.07441002561245114, Final Batch Loss: 0.07298419624567032\n",
      "Epoch 4713, Loss: 0.024712861981242895, Final Batch Loss: 0.0044590565375983715\n",
      "Epoch 4714, Loss: 0.005608816049061716, Final Batch Loss: 0.003837988479062915\n",
      "Epoch 4715, Loss: 0.013709057122468948, Final Batch Loss: 0.0026171505451202393\n",
      "Epoch 4716, Loss: 0.03631394449621439, Final Batch Loss: 0.012502997182309628\n",
      "Epoch 4717, Loss: 0.006606585578992963, Final Batch Loss: 0.002149983076378703\n",
      "Epoch 4718, Loss: 0.003885993850417435, Final Batch Loss: 0.001530034583993256\n",
      "Epoch 4719, Loss: 0.018823277903720737, Final Batch Loss: 0.016595831140875816\n",
      "Epoch 4720, Loss: 0.006487054051831365, Final Batch Loss: 0.0011667667422443628\n",
      "Epoch 4721, Loss: 0.02282557636499405, Final Batch Loss: 0.008582498878240585\n",
      "Epoch 4722, Loss: 0.024841365637257695, Final Batch Loss: 0.0021668088156729937\n",
      "Epoch 4723, Loss: 0.03827211633324623, Final Batch Loss: 0.020137304440140724\n",
      "Epoch 4724, Loss: 0.03708051214925945, Final Batch Loss: 0.0013927228283137083\n",
      "Epoch 4725, Loss: 0.028714746236801147, Final Batch Loss: 0.004146728664636612\n",
      "Epoch 4726, Loss: 0.033784490544348955, Final Batch Loss: 0.029079223051667213\n",
      "Epoch 4727, Loss: 0.03963407874107361, Final Batch Loss: 0.012877698987722397\n",
      "Epoch 4728, Loss: 0.006957358680665493, Final Batch Loss: 0.004299114923924208\n",
      "Epoch 4729, Loss: 0.005967763951048255, Final Batch Loss: 0.0032870082650333643\n",
      "Epoch 4730, Loss: 0.012642784742638469, Final Batch Loss: 0.0025089967530220747\n",
      "Epoch 4731, Loss: 0.012819086667150259, Final Batch Loss: 0.010326369665563107\n",
      "Epoch 4732, Loss: 0.07076020911335945, Final Batch Loss: 0.05364570394158363\n",
      "Epoch 4733, Loss: 0.017219281755387783, Final Batch Loss: 0.004826093092560768\n",
      "Epoch 4734, Loss: 0.03593514650128782, Final Batch Loss: 0.03291488438844681\n",
      "Epoch 4735, Loss: 0.0441830987110734, Final Batch Loss: 0.007094052620232105\n",
      "Epoch 4736, Loss: 0.0043000951409339905, Final Batch Loss: 0.0006336309015750885\n",
      "Epoch 4737, Loss: 0.010446884669363499, Final Batch Loss: 0.005410950165241957\n",
      "Epoch 4738, Loss: 0.008548094891011715, Final Batch Loss: 0.003397350199520588\n",
      "Epoch 4739, Loss: 0.057744179270230234, Final Batch Loss: 0.056205086410045624\n",
      "Epoch 4740, Loss: 0.01122973975725472, Final Batch Loss: 0.003893565619364381\n",
      "Epoch 4741, Loss: 0.015833355952054262, Final Batch Loss: 0.010785279795527458\n",
      "Epoch 4742, Loss: 0.016507417429238558, Final Batch Loss: 0.011007954366505146\n",
      "Epoch 4743, Loss: 0.020414076279848814, Final Batch Loss: 0.004889232572168112\n",
      "Epoch 4744, Loss: 0.013875634176656604, Final Batch Loss: 0.0026625588070601225\n",
      "Epoch 4745, Loss: 0.028802286833524704, Final Batch Loss: 0.027070751413702965\n",
      "Epoch 4746, Loss: 0.02526020840741694, Final Batch Loss: 0.02222817949950695\n",
      "Epoch 4747, Loss: 0.0055034474935382605, Final Batch Loss: 0.0020622177980840206\n",
      "Epoch 4748, Loss: 0.006615186342969537, Final Batch Loss: 0.002465261844918132\n",
      "Epoch 4749, Loss: 0.01146063907071948, Final Batch Loss: 0.005345032084733248\n",
      "Epoch 4750, Loss: 0.0033047374454326928, Final Batch Loss: 0.0027764062397181988\n",
      "Epoch 4751, Loss: 0.005069375038146973, Final Batch Loss: 0.002179408445954323\n",
      "Epoch 4752, Loss: 0.0241003455594182, Final Batch Loss: 0.006002909503877163\n",
      "Epoch 4753, Loss: 0.015434701461344957, Final Batch Loss: 0.002416562754660845\n",
      "Epoch 4754, Loss: 0.03392867534421384, Final Batch Loss: 0.0034229529555886984\n",
      "Epoch 4755, Loss: 0.00924963247962296, Final Batch Loss: 0.008503884077072144\n",
      "Epoch 4756, Loss: 0.010122008621692657, Final Batch Loss: 0.0075963325798511505\n",
      "Epoch 4757, Loss: 0.0016490731504745781, Final Batch Loss: 0.0013204084243625402\n",
      "Epoch 4758, Loss: 0.0044681120198220015, Final Batch Loss: 0.002261015586555004\n",
      "Epoch 4759, Loss: 0.008807291276752949, Final Batch Loss: 0.004130465444177389\n",
      "Epoch 4760, Loss: 0.013290070230141282, Final Batch Loss: 0.002268474781885743\n",
      "Epoch 4761, Loss: 0.0011915932700503618, Final Batch Loss: 0.00030255623278208077\n",
      "Epoch 4762, Loss: 0.006384366657584906, Final Batch Loss: 0.005215570330619812\n",
      "Epoch 4763, Loss: 0.005688755016308278, Final Batch Loss: 0.0005869531887583435\n",
      "Epoch 4764, Loss: 0.002042271022219211, Final Batch Loss: 0.0011073657078668475\n",
      "Epoch 4765, Loss: 0.0028323319857008755, Final Batch Loss: 0.0006199898780323565\n",
      "Epoch 4766, Loss: 0.009503032080829144, Final Batch Loss: 0.005709586199373007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4767, Loss: 0.0019538178748916835, Final Batch Loss: 0.0015104615595191717\n",
      "Epoch 4768, Loss: 0.010897204279899597, Final Batch Loss: 0.0044848439283668995\n",
      "Epoch 4769, Loss: 0.009163354290649295, Final Batch Loss: 0.008062239736318588\n",
      "Epoch 4770, Loss: 0.009895581286400557, Final Batch Loss: 0.0028182221576571465\n",
      "Epoch 4771, Loss: 0.0031831968808546662, Final Batch Loss: 0.0008750230772420764\n",
      "Epoch 4772, Loss: 0.0013107569830026478, Final Batch Loss: 0.0002987537009175867\n",
      "Epoch 4773, Loss: 0.11828217841684818, Final Batch Loss: 0.10321039706468582\n",
      "Epoch 4774, Loss: 0.008216549642384052, Final Batch Loss: 0.0048722438514232635\n",
      "Epoch 4775, Loss: 0.02728241798467934, Final Batch Loss: 0.0014979050029069185\n",
      "Epoch 4776, Loss: 0.008586012991145253, Final Batch Loss: 0.007966839708387852\n",
      "Epoch 4777, Loss: 0.02308202674612403, Final Batch Loss: 0.0166931115090847\n",
      "Epoch 4778, Loss: 0.0055364149156957865, Final Batch Loss: 0.004026119597256184\n",
      "Epoch 4779, Loss: 0.014396645943634212, Final Batch Loss: 0.013116108253598213\n",
      "Epoch 4780, Loss: 0.009436058229766786, Final Batch Loss: 0.0017140739364549518\n",
      "Epoch 4781, Loss: 0.014823144767433405, Final Batch Loss: 0.005510768387466669\n",
      "Epoch 4782, Loss: 0.004571086959913373, Final Batch Loss: 0.002004926558583975\n",
      "Epoch 4783, Loss: 0.032065546489320695, Final Batch Loss: 0.0011740404879674315\n",
      "Epoch 4784, Loss: 0.006644636858254671, Final Batch Loss: 0.004666128195822239\n",
      "Epoch 4785, Loss: 0.006443161983042955, Final Batch Loss: 0.003132428275421262\n",
      "Epoch 4786, Loss: 0.00541126006282866, Final Batch Loss: 0.0030275890603661537\n",
      "Epoch 4787, Loss: 0.016972241923213005, Final Batch Loss: 0.014961366541683674\n",
      "Epoch 4788, Loss: 0.007480596425011754, Final Batch Loss: 0.006585110444575548\n",
      "Epoch 4789, Loss: 0.0031484683277085423, Final Batch Loss: 0.00031080807093530893\n",
      "Epoch 4790, Loss: 0.038511971855768934, Final Batch Loss: 0.00036406415165401995\n",
      "Epoch 4791, Loss: 0.0017682475736364722, Final Batch Loss: 0.0007642294513061643\n",
      "Epoch 4792, Loss: 0.008422301150858402, Final Batch Loss: 0.001107487827539444\n",
      "Epoch 4793, Loss: 0.0036866883747279644, Final Batch Loss: 0.0022843212354928255\n",
      "Epoch 4794, Loss: 0.0036105369217693806, Final Batch Loss: 0.0009908727370202541\n",
      "Epoch 4795, Loss: 0.008822108851745725, Final Batch Loss: 0.006512428168207407\n",
      "Epoch 4796, Loss: 0.0019856528524542227, Final Batch Loss: 0.00015730947779957205\n",
      "Epoch 4797, Loss: 0.0054166296031326056, Final Batch Loss: 0.0032282930333167315\n",
      "Epoch 4798, Loss: 0.003249487082939595, Final Batch Loss: 0.0006660937215201557\n",
      "Epoch 4799, Loss: 0.007902757031843066, Final Batch Loss: 0.007111223880201578\n",
      "Epoch 4800, Loss: 0.011613239767029881, Final Batch Loss: 0.0012026627082377672\n",
      "Epoch 4801, Loss: 0.036417052149772644, Final Batch Loss: 0.01568559929728508\n",
      "Epoch 4802, Loss: 0.0035117861116304994, Final Batch Loss: 0.0006791955092921853\n",
      "Epoch 4803, Loss: 0.012454725801944733, Final Batch Loss: 0.009650406427681446\n",
      "Epoch 4804, Loss: 0.008367830654606223, Final Batch Loss: 0.0012845483142882586\n",
      "Epoch 4805, Loss: 0.027098622173070908, Final Batch Loss: 0.007376296445727348\n",
      "Epoch 4806, Loss: 0.016362940659746528, Final Batch Loss: 0.013723734766244888\n",
      "Epoch 4807, Loss: 0.008132147137075663, Final Batch Loss: 0.0031782197766005993\n",
      "Epoch 4808, Loss: 0.005567686748690903, Final Batch Loss: 0.0018332147737964988\n",
      "Epoch 4809, Loss: 0.008600373519584537, Final Batch Loss: 0.006021162960678339\n",
      "Epoch 4810, Loss: 0.0023950848262757063, Final Batch Loss: 0.001308027538470924\n",
      "Epoch 4811, Loss: 0.014438921120017767, Final Batch Loss: 0.002954037394374609\n",
      "Epoch 4812, Loss: 0.01256138039752841, Final Batch Loss: 0.005544664338231087\n",
      "Epoch 4813, Loss: 0.012993556796573102, Final Batch Loss: 0.0008644586196169257\n",
      "Epoch 4814, Loss: 0.002982519567012787, Final Batch Loss: 0.0015654891030862927\n",
      "Epoch 4815, Loss: 0.003341632429510355, Final Batch Loss: 0.0018725743284448981\n",
      "Epoch 4816, Loss: 0.03068041056394577, Final Batch Loss: 0.028734855353832245\n",
      "Epoch 4817, Loss: 0.006312010926194489, Final Batch Loss: 0.0010419335449114442\n",
      "Epoch 4818, Loss: 0.007116838591173291, Final Batch Loss: 0.004252222832292318\n",
      "Epoch 4819, Loss: 0.024640457471832633, Final Batch Loss: 0.02326609380543232\n",
      "Epoch 4820, Loss: 0.004856388317421079, Final Batch Loss: 0.0014836164191365242\n",
      "Epoch 4821, Loss: 0.002482337295077741, Final Batch Loss: 0.0007932304870337248\n",
      "Epoch 4822, Loss: 0.0318275960162282, Final Batch Loss: 0.015510265715420246\n",
      "Epoch 4823, Loss: 0.001623470918275416, Final Batch Loss: 0.0007606509607285261\n",
      "Epoch 4824, Loss: 0.005194838624447584, Final Batch Loss: 0.0026956808287650347\n",
      "Epoch 4825, Loss: 0.029085603076964617, Final Batch Loss: 0.006415607873350382\n",
      "Epoch 4826, Loss: 0.04411644930951297, Final Batch Loss: 0.041567835956811905\n",
      "Epoch 4827, Loss: 0.020367540884763002, Final Batch Loss: 0.013196800835430622\n",
      "Epoch 4828, Loss: 0.004648330854251981, Final Batch Loss: 0.0019779864232987165\n",
      "Epoch 4829, Loss: 0.021563966292887926, Final Batch Loss: 0.005752124357968569\n",
      "Epoch 4830, Loss: 0.030987433856353164, Final Batch Loss: 0.02930643782019615\n",
      "Epoch 4831, Loss: 0.009702706942334771, Final Batch Loss: 0.007172473706305027\n",
      "Epoch 4832, Loss: 0.003310338594019413, Final Batch Loss: 0.0013735519023612142\n",
      "Epoch 4833, Loss: 0.0033750133588910103, Final Batch Loss: 0.002045926172286272\n",
      "Epoch 4834, Loss: 0.011153476778417826, Final Batch Loss: 0.007644686847925186\n",
      "Epoch 4835, Loss: 0.011133622378110886, Final Batch Loss: 0.010436596348881721\n",
      "Epoch 4836, Loss: 0.0027775034541264176, Final Batch Loss: 0.0014680627500638366\n",
      "Epoch 4837, Loss: 0.011618590448051691, Final Batch Loss: 0.009558843448758125\n",
      "Epoch 4838, Loss: 0.025186152197420597, Final Batch Loss: 0.02186599187552929\n",
      "Epoch 4839, Loss: 0.008574743056669831, Final Batch Loss: 0.006692760623991489\n",
      "Epoch 4840, Loss: 0.0039609207306057215, Final Batch Loss: 0.0011679194867610931\n",
      "Epoch 4841, Loss: 0.014880284201353788, Final Batch Loss: 0.004979001823812723\n",
      "Epoch 4842, Loss: 0.011112680309452116, Final Batch Loss: 0.00047194643411785364\n",
      "Epoch 4843, Loss: 0.001941109832841903, Final Batch Loss: 0.0006254711770452559\n",
      "Epoch 4844, Loss: 0.0054040235409047455, Final Batch Loss: 0.0003595837333705276\n",
      "Epoch 4845, Loss: 0.004569790093228221, Final Batch Loss: 0.0033968063071370125\n",
      "Epoch 4846, Loss: 0.010516590438783169, Final Batch Loss: 0.0010069534182548523\n",
      "Epoch 4847, Loss: 0.04787968541495502, Final Batch Loss: 0.04681670293211937\n",
      "Epoch 4848, Loss: 0.03509305161423981, Final Batch Loss: 0.0011483703274279833\n",
      "Epoch 4849, Loss: 0.0016272487700916827, Final Batch Loss: 0.0011200420558452606\n",
      "Epoch 4850, Loss: 0.00867860997095704, Final Batch Loss: 0.004310029558837414\n",
      "Epoch 4851, Loss: 0.007369582599494606, Final Batch Loss: 0.0007087267586030066\n",
      "Epoch 4852, Loss: 0.00781672797165811, Final Batch Loss: 0.003866529790684581\n",
      "Epoch 4853, Loss: 0.007278915960341692, Final Batch Loss: 0.0033394978381693363\n",
      "Epoch 4854, Loss: 0.002447671489790082, Final Batch Loss: 0.001265784609131515\n",
      "Epoch 4855, Loss: 0.0021541506284847856, Final Batch Loss: 0.001122971880249679\n",
      "Epoch 4856, Loss: 0.007422405993565917, Final Batch Loss: 0.0022691639605909586\n",
      "Epoch 4857, Loss: 0.001651621307246387, Final Batch Loss: 0.0007091448060236871\n",
      "Epoch 4858, Loss: 0.009115757886320353, Final Batch Loss: 0.003983814734965563\n",
      "Epoch 4859, Loss: 0.003079630376305431, Final Batch Loss: 0.0009649169514887035\n",
      "Epoch 4860, Loss: 0.011194151127710938, Final Batch Loss: 0.0014474776107817888\n",
      "Epoch 4861, Loss: 0.0026613870868459344, Final Batch Loss: 0.0016749793430790305\n",
      "Epoch 4862, Loss: 0.00230491190450266, Final Batch Loss: 0.00018563569756224751\n",
      "Epoch 4863, Loss: 0.00275873439386487, Final Batch Loss: 0.001111457939259708\n",
      "Epoch 4864, Loss: 0.028051249566487968, Final Batch Loss: 0.0005175693659111857\n",
      "Epoch 4865, Loss: 0.003951501217670739, Final Batch Loss: 0.0023910508025437593\n",
      "Epoch 4866, Loss: 0.005086974706500769, Final Batch Loss: 0.001393403159454465\n",
      "Epoch 4867, Loss: 0.005967608653008938, Final Batch Loss: 0.0011591603979468346\n",
      "Epoch 4868, Loss: 0.005769877112470567, Final Batch Loss: 0.0014137051766738296\n",
      "Epoch 4869, Loss: 0.0023597456747666, Final Batch Loss: 0.0016689655603840947\n",
      "Epoch 4870, Loss: 0.001976868137717247, Final Batch Loss: 0.0015195045853033662\n",
      "Epoch 4871, Loss: 0.010807945538545027, Final Batch Loss: 0.0003901591117028147\n",
      "Epoch 4872, Loss: 0.010961657157167792, Final Batch Loss: 0.00848890095949173\n",
      "Epoch 4873, Loss: 0.01728265022393316, Final Batch Loss: 0.0011715240543708205\n",
      "Epoch 4874, Loss: 0.019353412091732025, Final Batch Loss: 0.0016013924032449722\n",
      "Epoch 4875, Loss: 0.0035811912384815514, Final Batch Loss: 0.00020972691709175706\n",
      "Epoch 4876, Loss: 0.01619257451966405, Final Batch Loss: 0.003946197684854269\n",
      "Epoch 4877, Loss: 0.004762477008625865, Final Batch Loss: 0.0007454680744558573\n",
      "Epoch 4878, Loss: 0.017459188704378903, Final Batch Loss: 0.01593971811234951\n",
      "Epoch 4879, Loss: 0.0006972311239223927, Final Batch Loss: 0.0004739492724183947\n",
      "Epoch 4880, Loss: 0.0015486229676753283, Final Batch Loss: 0.00043982930947095156\n",
      "Epoch 4881, Loss: 0.066410947823897, Final Batch Loss: 0.06450925767421722\n",
      "Epoch 4882, Loss: 0.017632239498198032, Final Batch Loss: 0.01679937168955803\n",
      "Epoch 4883, Loss: 0.007728316122666001, Final Batch Loss: 0.00461246632039547\n",
      "Epoch 4884, Loss: 0.0017213669489137828, Final Batch Loss: 0.0008359093335457146\n",
      "Epoch 4885, Loss: 0.006235576816834509, Final Batch Loss: 0.000787947908975184\n",
      "Epoch 4886, Loss: 0.0008781037613516673, Final Batch Loss: 0.0006420519785024226\n",
      "Epoch 4887, Loss: 0.06899320217780769, Final Batch Loss: 0.002565509406849742\n",
      "Epoch 4888, Loss: 0.004560102010145783, Final Batch Loss: 0.002175664994865656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4889, Loss: 0.008576403371989727, Final Batch Loss: 0.0013237940147519112\n",
      "Epoch 4890, Loss: 0.003494165779557079, Final Batch Loss: 0.002890188479796052\n",
      "Epoch 4891, Loss: 0.00959385751048103, Final Batch Loss: 0.0007167906151153147\n",
      "Epoch 4892, Loss: 0.012575300876051188, Final Batch Loss: 0.007847931236028671\n",
      "Epoch 4893, Loss: 0.006836742861196399, Final Batch Loss: 0.001043224474415183\n",
      "Epoch 4894, Loss: 0.007125553674995899, Final Batch Loss: 0.002054283395409584\n",
      "Epoch 4895, Loss: 0.00153343565762043, Final Batch Loss: 0.0005692271515727043\n",
      "Epoch 4896, Loss: 0.005207288428209722, Final Batch Loss: 0.003789047012105584\n",
      "Epoch 4897, Loss: 0.016430257819592953, Final Batch Loss: 0.009304007515311241\n",
      "Epoch 4898, Loss: 0.0030558271682821214, Final Batch Loss: 0.0007011435809545219\n",
      "Epoch 4899, Loss: 0.0016584807308390737, Final Batch Loss: 0.001094361417926848\n",
      "Epoch 4900, Loss: 0.004697410273365676, Final Batch Loss: 0.00405940180644393\n",
      "Epoch 4901, Loss: 0.011648380779661238, Final Batch Loss: 0.0006544670322909951\n",
      "Epoch 4902, Loss: 0.006277924054302275, Final Batch Loss: 0.005102731287479401\n",
      "Epoch 4903, Loss: 0.0033749606227502227, Final Batch Loss: 0.0012308593140915036\n",
      "Epoch 4904, Loss: 0.008005845826119184, Final Batch Loss: 0.0046725040301680565\n",
      "Epoch 4905, Loss: 0.006724255392327905, Final Batch Loss: 0.0026691306848078966\n",
      "Epoch 4906, Loss: 0.0014239369193091989, Final Batch Loss: 0.0008739940240047872\n",
      "Epoch 4907, Loss: 0.0025596226332709193, Final Batch Loss: 0.0010368614457547665\n",
      "Epoch 4908, Loss: 0.010367363574914634, Final Batch Loss: 0.009745592251420021\n",
      "Epoch 4909, Loss: 0.012563072144985199, Final Batch Loss: 0.010133619420230389\n",
      "Epoch 4910, Loss: 0.0013027381501160562, Final Batch Loss: 0.0005528246983885765\n",
      "Epoch 4911, Loss: 0.004109851783141494, Final Batch Loss: 0.0003658789210021496\n",
      "Epoch 4912, Loss: 0.0012884406023658812, Final Batch Loss: 0.000442543241661042\n",
      "Epoch 4913, Loss: 0.0012541275355033576, Final Batch Loss: 0.00027874490479007363\n",
      "Epoch 4914, Loss: 0.005620203097350895, Final Batch Loss: 0.004516723565757275\n",
      "Epoch 4915, Loss: 0.0049671027809381485, Final Batch Loss: 0.0035215511452406645\n",
      "Epoch 4916, Loss: 0.005470305452035973, Final Batch Loss: 3.162562279612757e-05\n",
      "Epoch 4917, Loss: 0.0043967715464532375, Final Batch Loss: 0.0028365054167807102\n",
      "Epoch 4918, Loss: 0.002323366585187614, Final Batch Loss: 0.00116220791824162\n",
      "Epoch 4919, Loss: 0.0025779882562346756, Final Batch Loss: 0.00040479941526427865\n",
      "Epoch 4920, Loss: 0.002712528730626218, Final Batch Loss: 0.00016641737602185458\n",
      "Epoch 4921, Loss: 0.0020224039908498526, Final Batch Loss: 0.0011781019857153296\n",
      "Epoch 4922, Loss: 0.007386960962321609, Final Batch Loss: 0.0002813920727930963\n",
      "Epoch 4923, Loss: 0.0013490308774635196, Final Batch Loss: 0.0003470479277893901\n",
      "Epoch 4924, Loss: 0.05632888153195381, Final Batch Loss: 0.003211989998817444\n",
      "Epoch 4925, Loss: 0.0054024511482566595, Final Batch Loss: 0.005183806177228689\n",
      "Epoch 4926, Loss: 0.0010730113426689059, Final Batch Loss: 0.0006217085756361485\n",
      "Epoch 4927, Loss: 0.010441537713631988, Final Batch Loss: 0.0030760865192860365\n",
      "Epoch 4928, Loss: 0.0009348927196697332, Final Batch Loss: 0.00010180843673879281\n",
      "Epoch 4929, Loss: 0.003184050030540675, Final Batch Loss: 0.0005431223544292152\n",
      "Epoch 4930, Loss: 0.005213326890952885, Final Batch Loss: 0.0012897310080006719\n",
      "Epoch 4931, Loss: 0.0008783448429312557, Final Batch Loss: 0.00043915718561038375\n",
      "Epoch 4932, Loss: 0.006401845486834645, Final Batch Loss: 0.0039797755889594555\n",
      "Epoch 4933, Loss: 0.02139600832015276, Final Batch Loss: 0.001470879651606083\n",
      "Epoch 4934, Loss: 0.017522495938465, Final Batch Loss: 0.0017731382977217436\n",
      "Epoch 4935, Loss: 0.0021660421625711024, Final Batch Loss: 0.001195163931697607\n",
      "Epoch 4936, Loss: 0.0016518791380804032, Final Batch Loss: 0.0011824035318568349\n",
      "Epoch 4937, Loss: 0.01124339527450502, Final Batch Loss: 0.008304246701300144\n",
      "Epoch 4938, Loss: 0.0022451089462265372, Final Batch Loss: 0.0010240875417366624\n",
      "Epoch 4939, Loss: 0.007710436126217246, Final Batch Loss: 0.007153105456382036\n",
      "Epoch 4940, Loss: 0.005274035967886448, Final Batch Loss: 0.003944541793316603\n",
      "Epoch 4941, Loss: 0.006588339398149401, Final Batch Loss: 0.0008438681834377348\n",
      "Epoch 4942, Loss: 0.028418714471627027, Final Batch Loss: 0.02756003849208355\n",
      "Epoch 4943, Loss: 0.004785807337611914, Final Batch Loss: 0.0020793110597878695\n",
      "Epoch 4944, Loss: 0.014947240706533194, Final Batch Loss: 0.00026223016902804375\n",
      "Epoch 4945, Loss: 0.03234001121018082, Final Batch Loss: 0.030827991664409637\n",
      "Epoch 4946, Loss: 0.011086030048318207, Final Batch Loss: 0.0005208906950429082\n",
      "Epoch 4947, Loss: 0.002924022206570953, Final Batch Loss: 0.002091068308800459\n",
      "Epoch 4948, Loss: 0.030121966381557286, Final Batch Loss: 0.0016533724265173078\n",
      "Epoch 4949, Loss: 0.006542731425724924, Final Batch Loss: 0.0013562574749812484\n",
      "Epoch 4950, Loss: 0.008524877019226551, Final Batch Loss: 0.007448600139468908\n",
      "Epoch 4951, Loss: 0.022341378033161163, Final Batch Loss: 0.008054938167333603\n",
      "Epoch 4952, Loss: 0.006569483899511397, Final Batch Loss: 0.0012206585379317403\n",
      "Epoch 4953, Loss: 0.00409768708050251, Final Batch Loss: 0.0015892540104687214\n",
      "Epoch 4954, Loss: 0.00177317438647151, Final Batch Loss: 0.0009466632036492229\n",
      "Epoch 4955, Loss: 0.002410971326753497, Final Batch Loss: 0.0006222698139026761\n",
      "Epoch 4956, Loss: 0.008432312635704875, Final Batch Loss: 0.0036164831835776567\n",
      "Epoch 4957, Loss: 0.018153220647946, Final Batch Loss: 0.0017729683313518763\n",
      "Epoch 4958, Loss: 0.0010125019471161067, Final Batch Loss: 0.000555950216948986\n",
      "Epoch 4959, Loss: 0.004957236000336707, Final Batch Loss: 0.0009823344880715013\n",
      "Epoch 4960, Loss: 0.003342278068885207, Final Batch Loss: 0.0027229886036366224\n",
      "Epoch 4961, Loss: 0.002554304664954543, Final Batch Loss: 0.0008107743924483657\n",
      "Epoch 4962, Loss: 0.0032933405018411577, Final Batch Loss: 0.0006789129110984504\n",
      "Epoch 4963, Loss: 0.0036909665213897824, Final Batch Loss: 0.0013760743895545602\n",
      "Epoch 4964, Loss: 0.005902985809370875, Final Batch Loss: 0.002853548154234886\n",
      "Epoch 4965, Loss: 0.01781701378058642, Final Batch Loss: 0.01745074801146984\n",
      "Epoch 4966, Loss: 0.0019997385679744184, Final Batch Loss: 0.0009555864962749183\n",
      "Epoch 4967, Loss: 0.003384531009942293, Final Batch Loss: 0.0007177763618528843\n",
      "Epoch 4968, Loss: 0.007219850551337004, Final Batch Loss: 0.0055520846508443356\n",
      "Epoch 4969, Loss: 0.013550977571867406, Final Batch Loss: 0.0010125202825292945\n",
      "Epoch 4970, Loss: 0.004877877770923078, Final Batch Loss: 0.0037686878349632025\n",
      "Epoch 4971, Loss: 0.010469602304510772, Final Batch Loss: 0.0003352992935106158\n",
      "Epoch 4972, Loss: 0.002222627226728946, Final Batch Loss: 0.0007454243605025113\n",
      "Epoch 4973, Loss: 0.0014766743843210861, Final Batch Loss: 0.0012401618296280503\n",
      "Epoch 4974, Loss: 0.0012120735482312739, Final Batch Loss: 0.00032040884252637625\n",
      "Epoch 4975, Loss: 0.031007084529846907, Final Batch Loss: 0.028848493471741676\n",
      "Epoch 4976, Loss: 0.0010681151470635086, Final Batch Loss: 0.00035005700192414224\n",
      "Epoch 4977, Loss: 0.0039633907726965845, Final Batch Loss: 0.0006663386593572795\n",
      "Epoch 4978, Loss: 0.004534174571745098, Final Batch Loss: 0.0008107729954645038\n",
      "Epoch 4979, Loss: 0.01590926095377654, Final Batch Loss: 0.01484724972397089\n",
      "Epoch 4980, Loss: 0.004655022727092728, Final Batch Loss: 0.0003313986526336521\n",
      "Epoch 4981, Loss: 0.014678921550512314, Final Batch Loss: 0.004330924712121487\n",
      "Epoch 4982, Loss: 0.004217526991851628, Final Batch Loss: 0.0004185055149719119\n",
      "Epoch 4983, Loss: 0.009431993355974555, Final Batch Loss: 0.005936841946095228\n",
      "Epoch 4984, Loss: 0.0014727155212312937, Final Batch Loss: 0.0008056586957536638\n",
      "Epoch 4985, Loss: 0.004868077172432095, Final Batch Loss: 0.004395398311316967\n",
      "Epoch 4986, Loss: 0.00353771896334365, Final Batch Loss: 0.0006085406639613211\n",
      "Epoch 4987, Loss: 0.012426343047991395, Final Batch Loss: 0.0011344209779053926\n",
      "Epoch 4988, Loss: 0.02443851064890623, Final Batch Loss: 0.0029759882017970085\n",
      "Epoch 4989, Loss: 0.004423196311108768, Final Batch Loss: 0.0003463801695033908\n",
      "Epoch 4990, Loss: 0.007955025415867567, Final Batch Loss: 0.005323505960404873\n",
      "Epoch 4991, Loss: 0.015138061717152596, Final Batch Loss: 0.0007254257798194885\n",
      "Epoch 4992, Loss: 0.0032711169915273786, Final Batch Loss: 0.0016940610948950052\n",
      "Epoch 4993, Loss: 0.005397528118919581, Final Batch Loss: 0.004545159172266722\n",
      "Epoch 4994, Loss: 0.004508593876380473, Final Batch Loss: 0.0038521059323102236\n",
      "Epoch 4995, Loss: 0.013013475574553013, Final Batch Loss: 0.006615102291107178\n",
      "Epoch 4996, Loss: 0.03898040915373713, Final Batch Loss: 0.03806377202272415\n",
      "Epoch 4997, Loss: 0.07888927805470303, Final Batch Loss: 0.0004887257819063962\n",
      "Epoch 4998, Loss: 0.003277731520938687, Final Batch Loss: 0.00023898125800769776\n",
      "Epoch 4999, Loss: 0.0013214382051955909, Final Batch Loss: 0.0003465661720838398\n",
      "Epoch 5000, Loss: 0.02591466950252652, Final Batch Loss: 0.006226996425539255\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0  0]\n",
      " [ 0 43  0]\n",
      " [ 0  1 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        29\n",
      "           1    0.97727   1.00000   0.98851        43\n",
      "           2    1.00000   0.96154   0.98039        26\n",
      "\n",
      "    accuracy                        0.98980        98\n",
      "   macro avg    0.99242   0.98718   0.98963        98\n",
      "weighted avg    0.99003   0.98980   0.98975        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  3  1]\n",
      " [ 0 30  0]\n",
      " [ 2  7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92857   0.86667   0.89655        30\n",
      "           1    0.75000   1.00000   0.85714        30\n",
      "           2    0.95455   0.70000   0.80769        30\n",
      "\n",
      "    accuracy                        0.85556        90\n",
      "   macro avg    0.87771   0.85556   0.85380        90\n",
      "weighted avg    0.87771   0.85556   0.85380        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
