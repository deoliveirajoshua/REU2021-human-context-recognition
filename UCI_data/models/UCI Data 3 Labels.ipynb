{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['58 tGravityAcc-energy()-Y', '59 tGravityAcc-energy()-Z', '104 tBodyAccJerk-entropy()-Y', '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y', '132 tBodyGyro-max()-Z', '134 tBodyGyro-min()-Y','138 tBodyGyro-energy()-Y', '141 tBodyGyro-iqr()-Y',\n",
    " '167 tBodyGyroJerk-mad()-X','168 tBodyGyroJerk-mad()-Y','177 tBodyGyroJerk-energy()-X', '181 tBodyGyroJerk-iqr()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8', '484 fBodyGyro-bandsEnergy()-17,32','487 fBodyGyro-bandsEnergy()-1,24']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X', '7 tBodyAcc-mad()-X', '10 tBodyAcc-max()-X', '17 tBodyAcc-energy()-X', '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()', '215 tGravityAccMag-std()', '217 tGravityAccMag-max()', '269 fBodyAcc-std()-X', '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X', '286 fBodyAcc-iqr()-Y', '303 fBodyAcc-bandsEnergy()-1,8', '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '368 fBodyAccJerk-entropy()-Y', '390 fBodyAccJerk-bandsEnergy()-1,16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>58 tGravityAcc-energy()-Y</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>104 tBodyAccJerk-entropy()-Y</th>\n",
       "      <th>125 tBodyGyro-std()-Y</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>132 tBodyGyro-max()-Z</th>\n",
       "      <th>134 tBodyGyro-min()-Y</th>\n",
       "      <th>138 tBodyGyro-energy()-Y</th>\n",
       "      <th>141 tBodyGyro-iqr()-Y</th>\n",
       "      <th>167 tBodyGyroJerk-mad()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>217 tGravityAccMag-max()</th>\n",
       "      <th>269 fBodyAcc-std()-X</th>\n",
       "      <th>275 fBodyAcc-max()-X</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>286 fBodyAcc-iqr()-Y</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>368 fBodyAccJerk-entropy()-Y</th>\n",
       "      <th>390 fBodyAccJerk-bandsEnergy()-1,16</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.970905</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.793046</td>\n",
       "      <td>-0.976623</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>-0.747566</td>\n",
       "      <td>0.914895</td>\n",
       "      <td>-0.999354</td>\n",
       "      <td>-0.978614</td>\n",
       "      <td>-0.992165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946305</td>\n",
       "      <td>-0.995422</td>\n",
       "      <td>-0.993756</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.989709</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.970583</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.655362</td>\n",
       "      <td>-0.989046</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>-0.745870</td>\n",
       "      <td>0.908110</td>\n",
       "      <td>-0.999897</td>\n",
       "      <td>-0.989345</td>\n",
       "      <td>-0.989876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978711</td>\n",
       "      <td>-0.998680</td>\n",
       "      <td>-0.999372</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.980784</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999987</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.970368</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.673274</td>\n",
       "      <td>-0.993552</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>-0.743277</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>-0.995144</td>\n",
       "      <td>-0.987868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986496</td>\n",
       "      <td>-0.996313</td>\n",
       "      <td>-0.998158</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.977242</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.969400</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.754968</td>\n",
       "      <td>-0.992407</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>-0.743277</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>-0.999902</td>\n",
       "      <td>-0.994165</td>\n",
       "      <td>-0.991241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986496</td>\n",
       "      <td>-0.996312</td>\n",
       "      <td>-0.997404</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.991902</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999978</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.967051</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.746258</td>\n",
       "      <td>-0.992378</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>-0.749780</td>\n",
       "      <td>0.911184</td>\n",
       "      <td>-0.999952</td>\n",
       "      <td>-0.993337</td>\n",
       "      <td>-0.992882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.990962</td>\n",
       "      <td>-0.998606</td>\n",
       "      <td>-0.999277</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.988180</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.918375</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>0.605462</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.065142</td>\n",
       "      <td>-0.015472</td>\n",
       "      <td>0.396623</td>\n",
       "      <td>-0.419947</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>-0.533656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.221989</td>\n",
       "      <td>-0.318185</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>0.455341</td>\n",
       "      <td>-0.775736</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.902880</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>0.608132</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>-0.223612</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>-0.405579</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>-0.609540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069568</td>\n",
       "      <td>-0.267430</td>\n",
       "      <td>-0.332146</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.547702</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>0.357697</td>\n",
       "      <td>-0.780751</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.907561</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.497936</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>-0.176254</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>-0.305023</td>\n",
       "      <td>0.073383</td>\n",
       "      <td>-0.662918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083233</td>\n",
       "      <td>-0.173212</td>\n",
       "      <td>-0.160368</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.588790</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>0.422191</td>\n",
       "      <td>-0.783616</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.910648</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.501824</td>\n",
       "      <td>0.190360</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>-0.176254</td>\n",
       "      <td>0.473542</td>\n",
       "      <td>-0.298515</td>\n",
       "      <td>0.042519</td>\n",
       "      <td>-0.645452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098052</td>\n",
       "      <td>-0.158192</td>\n",
       "      <td>-0.147421</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.548936</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>0.346965</td>\n",
       "      <td>-0.821137</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.910579</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>0.505438</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>-0.262266</td>\n",
       "      <td>0.452599</td>\n",
       "      <td>-0.474331</td>\n",
       "      <td>-0.370964</td>\n",
       "      <td>-0.688840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051914</td>\n",
       "      <td>-0.270794</td>\n",
       "      <td>-0.417612</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.409732</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>0.340934</td>\n",
       "      <td>-0.825848</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      58 tGravityAcc-energy()-Y  59 tGravityAcc-energy()-Z  \\\n",
       "0                     -0.970905                  -0.975510   \n",
       "1                     -0.970583                  -0.978500   \n",
       "2                     -0.970368                  -0.981672   \n",
       "3                     -0.969400                  -0.982420   \n",
       "4                     -0.967051                  -0.984363   \n",
       "...                         ...                        ...   \n",
       "7347                  -0.918375                  -0.995193   \n",
       "7348                  -0.902880                  -0.995151   \n",
       "7349                  -0.907561                  -0.995450   \n",
       "7350                  -0.910648                  -0.998824   \n",
       "7351                  -0.910579                  -0.998144   \n",
       "\n",
       "      104 tBodyAccJerk-entropy()-Y  125 tBodyGyro-std()-Y  \\\n",
       "0                        -0.793046              -0.976623   \n",
       "1                        -0.655362              -0.989046   \n",
       "2                        -0.673274              -0.993552   \n",
       "3                        -0.754968              -0.992407   \n",
       "4                        -0.746258              -0.992378   \n",
       "...                            ...                    ...   \n",
       "7347                      0.605462               0.084878   \n",
       "7348                      0.608132               0.098249   \n",
       "7349                      0.497936               0.185902   \n",
       "7350                      0.501824               0.190360   \n",
       "7351                      0.505438               0.022216   \n",
       "\n",
       "      128 tBodyGyro-mad()-Y  132 tBodyGyro-max()-Z  134 tBodyGyro-min()-Y  \\\n",
       "0                 -0.976353              -0.747566               0.914895   \n",
       "1                 -0.989038              -0.745870               0.908110   \n",
       "2                 -0.994122              -0.743277               0.905753   \n",
       "3                 -0.993142              -0.743277               0.905753   \n",
       "4                 -0.992542              -0.749780               0.911184   \n",
       "...                     ...                    ...                    ...   \n",
       "7347               0.065142              -0.015472               0.396623   \n",
       "7348               0.091791              -0.223612               0.373761   \n",
       "7349               0.170686              -0.176254               0.373761   \n",
       "7350               0.178939              -0.176254               0.473542   \n",
       "7351              -0.073681              -0.262266               0.452599   \n",
       "\n",
       "      138 tBodyGyro-energy()-Y  141 tBodyGyro-iqr()-Y  \\\n",
       "0                    -0.999354              -0.978614   \n",
       "1                    -0.999897              -0.989345   \n",
       "2                    -0.999828              -0.995144   \n",
       "3                    -0.999902              -0.994165   \n",
       "4                    -0.999952              -0.993337   \n",
       "...                        ...                    ...   \n",
       "7347                 -0.419947               0.019043   \n",
       "7348                 -0.405579               0.023374   \n",
       "7349                 -0.305023               0.073383   \n",
       "7350                 -0.298515               0.042519   \n",
       "7351                 -0.474331              -0.370964   \n",
       "\n",
       "      167 tBodyGyroJerk-mad()-X  ...  217 tGravityAccMag-max()  \\\n",
       "0                     -0.992165  ...                 -0.946305   \n",
       "1                     -0.989876  ...                 -0.978711   \n",
       "2                     -0.987868  ...                 -0.986496   \n",
       "3                     -0.991241  ...                 -0.986496   \n",
       "4                     -0.992882  ...                 -0.990962   \n",
       "...                         ...  ...                       ...   \n",
       "7347                  -0.533656  ...                  0.000026   \n",
       "7348                  -0.609540  ...                 -0.069568   \n",
       "7349                  -0.662918  ...                 -0.083233   \n",
       "7350                  -0.645452  ...                 -0.098052   \n",
       "7351                  -0.688840  ...                 -0.051914   \n",
       "\n",
       "      269 fBodyAcc-std()-X  275 fBodyAcc-max()-X  282 fBodyAcc-energy()-X  \\\n",
       "0                -0.995422             -0.993756                -0.999968   \n",
       "1                -0.998680             -0.999372                -0.999991   \n",
       "2                -0.996313             -0.998158                -0.999969   \n",
       "3                -0.996312             -0.997404                -0.999975   \n",
       "4                -0.998606             -0.999277                -0.999990   \n",
       "...                    ...                   ...                      ...   \n",
       "7347             -0.221989             -0.318185                -0.674230   \n",
       "7348             -0.267430             -0.332146                -0.705580   \n",
       "7349             -0.173212             -0.160368                -0.692379   \n",
       "7350             -0.158192             -0.147421                -0.693098   \n",
       "7351             -0.270794             -0.417612                -0.731037   \n",
       "\n",
       "      286 fBodyAcc-iqr()-Y  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                -0.989709                       -0.999963   \n",
       "1                -0.980784                       -0.999996   \n",
       "2                -0.977242                       -0.999989   \n",
       "3                -0.991902                       -0.999989   \n",
       "4                -0.988180                       -0.999994   \n",
       "...                    ...                             ...   \n",
       "7347             -0.395202                       -0.684177   \n",
       "7348             -0.547702                       -0.726986   \n",
       "7349             -0.588790                       -0.655263   \n",
       "7350             -0.548936                       -0.643425   \n",
       "7351             -0.409732                       -0.709495   \n",
       "\n",
       "      315 fBodyAcc-bandsEnergy()-1,24  368 fBodyAccJerk-entropy()-Y  \\\n",
       "0                           -0.999971                     -1.000000   \n",
       "1                           -0.999992                     -1.000000   \n",
       "2                           -0.999972                     -1.000000   \n",
       "3                           -0.999977                     -1.000000   \n",
       "4                           -0.999991                     -1.000000   \n",
       "...                               ...                           ...   \n",
       "7347                        -0.668164                      0.455341   \n",
       "7348                        -0.705435                      0.357697   \n",
       "7349                        -0.684729                      0.422191   \n",
       "7350                        -0.685088                      0.346965   \n",
       "7351                        -0.727441                      0.340934   \n",
       "\n",
       "      390 fBodyAccJerk-bandsEnergy()-1,16  Activity  \n",
       "0                               -0.999982         5  \n",
       "1                               -0.999987         5  \n",
       "2                               -0.999963         5  \n",
       "3                               -0.999978         5  \n",
       "4                               -0.999988         5  \n",
       "...                                   ...       ...  \n",
       "7347                            -0.775736         2  \n",
       "7348                            -0.780751         2  \n",
       "7349                            -0.783616         2  \n",
       "7350                            -0.821137         2  \n",
       "7351                            -0.825848         2  \n",
       "\n",
       "[7352 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "# X_train_1 = train_data.loc[:,'1 tBodyAcc-mean()-X':'40 tBodyAcc-correlation()-Y,Z']\n",
    "# X_train_2 = train_data.loc[:,'81 tBodyAccJerk-mean()-X':'160 tBodyGyro-correlation()-Y,Z']\n",
    "X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train = pd.concat([X_train, y_train], axis = 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[(X_train['Activity'] == 1) | (X_train['Activity'] == 3) | (X_train['Activity'] == 4)]\n",
    "X_train = X_train.iloc[:,:-1].values\n",
    "\n",
    "y_train = y_train[(y_train['Activity'] == 1) | (y_train['Activity'] == 3) | (y_train['Activity'] == 4)]\n",
    "y_train = y_train.values\n",
    "y_train = y_train.flatten()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_subjects = pd.read_csv('UCI/subject_train.txt', header = None)\n",
    "# train_subjects.columns = ['Subject']\n",
    "# train_subjects = train_subjects.values\n",
    "# train_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>58 tGravityAcc-energy()-Y</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>104 tBodyAccJerk-entropy()-Y</th>\n",
       "      <th>125 tBodyGyro-std()-Y</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>132 tBodyGyro-max()-Z</th>\n",
       "      <th>134 tBodyGyro-min()-Y</th>\n",
       "      <th>138 tBodyGyro-energy()-Y</th>\n",
       "      <th>141 tBodyGyro-iqr()-Y</th>\n",
       "      <th>167 tBodyGyroJerk-mad()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>217 tGravityAccMag-max()</th>\n",
       "      <th>269 fBodyAcc-std()-X</th>\n",
       "      <th>275 fBodyAcc-max()-X</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>286 fBodyAcc-iqr()-Y</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>368 fBodyAccJerk-entropy()-Y</th>\n",
       "      <th>390 fBodyAccJerk-bandsEnergy()-1,16</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.864621</td>\n",
       "      <td>-0.967795</td>\n",
       "      <td>-0.310263</td>\n",
       "      <td>-0.816164</td>\n",
       "      <td>-0.857801</td>\n",
       "      <td>-0.648679</td>\n",
       "      <td>0.825257</td>\n",
       "      <td>-0.982900</td>\n",
       "      <td>-0.906104</td>\n",
       "      <td>-0.910363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760796</td>\n",
       "      <td>-0.948290</td>\n",
       "      <td>-0.968424</td>\n",
       "      <td>-0.997844</td>\n",
       "      <td>-0.933812</td>\n",
       "      <td>-0.998506</td>\n",
       "      <td>-0.998020</td>\n",
       "      <td>-0.672172</td>\n",
       "      <td>-0.998040</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.858163</td>\n",
       "      <td>-0.957240</td>\n",
       "      <td>-0.655751</td>\n",
       "      <td>-0.929599</td>\n",
       "      <td>-0.950025</td>\n",
       "      <td>-0.703212</td>\n",
       "      <td>0.870780</td>\n",
       "      <td>-0.995194</td>\n",
       "      <td>-0.960685</td>\n",
       "      <td>-0.968614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.937608</td>\n",
       "      <td>-0.984350</td>\n",
       "      <td>-0.993051</td>\n",
       "      <td>-0.999592</td>\n",
       "      <td>-0.971002</td>\n",
       "      <td>-0.999850</td>\n",
       "      <td>-0.999687</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999641</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.859947</td>\n",
       "      <td>-0.960965</td>\n",
       "      <td>-0.674949</td>\n",
       "      <td>-0.978511</td>\n",
       "      <td>-0.980558</td>\n",
       "      <td>-0.715170</td>\n",
       "      <td>0.892714</td>\n",
       "      <td>-0.998265</td>\n",
       "      <td>-0.986199</td>\n",
       "      <td>-0.983723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969212</td>\n",
       "      <td>-0.994754</td>\n",
       "      <td>-0.995082</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.969352</td>\n",
       "      <td>-0.999976</td>\n",
       "      <td>-0.999958</td>\n",
       "      <td>-0.939120</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.853713</td>\n",
       "      <td>-0.962713</td>\n",
       "      <td>-0.614042</td>\n",
       "      <td>-0.975134</td>\n",
       "      <td>-0.973915</td>\n",
       "      <td>-0.715170</td>\n",
       "      <td>0.894620</td>\n",
       "      <td>-0.999174</td>\n",
       "      <td>-0.971681</td>\n",
       "      <td>-0.983995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969212</td>\n",
       "      <td>-0.995594</td>\n",
       "      <td>-0.997495</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.962432</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999966</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.843378</td>\n",
       "      <td>-0.965137</td>\n",
       "      <td>-0.637935</td>\n",
       "      <td>-0.977951</td>\n",
       "      <td>-0.979507</td>\n",
       "      <td>-0.731706</td>\n",
       "      <td>0.899262</td>\n",
       "      <td>-0.999686</td>\n",
       "      <td>-0.981584</td>\n",
       "      <td>-0.988244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.975954</td>\n",
       "      <td>-0.994504</td>\n",
       "      <td>-0.995932</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.978862</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>-0.999957</td>\n",
       "      <td>-0.939120</td>\n",
       "      <td>-0.999955</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>-0.870515</td>\n",
       "      <td>-0.888599</td>\n",
       "      <td>0.525215</td>\n",
       "      <td>-0.526855</td>\n",
       "      <td>-0.575937</td>\n",
       "      <td>-0.311752</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>-0.887282</td>\n",
       "      <td>-0.669323</td>\n",
       "      <td>-0.652975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>-0.269827</td>\n",
       "      <td>-0.381610</td>\n",
       "      <td>-0.744467</td>\n",
       "      <td>-0.477903</td>\n",
       "      <td>-0.734651</td>\n",
       "      <td>-0.739414</td>\n",
       "      <td>0.277066</td>\n",
       "      <td>-0.792017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>-0.872342</td>\n",
       "      <td>-0.891822</td>\n",
       "      <td>0.464601</td>\n",
       "      <td>-0.518149</td>\n",
       "      <td>-0.571732</td>\n",
       "      <td>-0.266502</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>-0.884727</td>\n",
       "      <td>-0.674429</td>\n",
       "      <td>-0.626430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>-0.328225</td>\n",
       "      <td>-0.540880</td>\n",
       "      <td>-0.756815</td>\n",
       "      <td>-0.528280</td>\n",
       "      <td>-0.747251</td>\n",
       "      <td>-0.753166</td>\n",
       "      <td>0.394316</td>\n",
       "      <td>-0.807522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>-0.871197</td>\n",
       "      <td>-0.893504</td>\n",
       "      <td>0.530407</td>\n",
       "      <td>-0.557059</td>\n",
       "      <td>-0.576087</td>\n",
       "      <td>-0.266502</td>\n",
       "      <td>0.656046</td>\n",
       "      <td>-0.898203</td>\n",
       "      <td>-0.599423</td>\n",
       "      <td>-0.653267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117645</td>\n",
       "      <td>-0.316973</td>\n",
       "      <td>-0.340887</td>\n",
       "      <td>-0.773399</td>\n",
       "      <td>-0.563036</td>\n",
       "      <td>-0.762837</td>\n",
       "      <td>-0.769811</td>\n",
       "      <td>0.351133</td>\n",
       "      <td>-0.830224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>-0.884788</td>\n",
       "      <td>-0.885275</td>\n",
       "      <td>0.446009</td>\n",
       "      <td>-0.555166</td>\n",
       "      <td>-0.580453</td>\n",
       "      <td>-0.314949</td>\n",
       "      <td>0.566648</td>\n",
       "      <td>-0.896625</td>\n",
       "      <td>-0.597778</td>\n",
       "      <td>-0.716997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204541</td>\n",
       "      <td>-0.302423</td>\n",
       "      <td>-0.310583</td>\n",
       "      <td>-0.768993</td>\n",
       "      <td>-0.741144</td>\n",
       "      <td>-0.751525</td>\n",
       "      <td>-0.765049</td>\n",
       "      <td>0.182878</td>\n",
       "      <td>-0.838522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>-0.885692</td>\n",
       "      <td>-0.884370</td>\n",
       "      <td>0.526791</td>\n",
       "      <td>-0.508557</td>\n",
       "      <td>-0.544531</td>\n",
       "      <td>-0.264569</td>\n",
       "      <td>0.566648</td>\n",
       "      <td>-0.880072</td>\n",
       "      <td>-0.585541</td>\n",
       "      <td>-0.694131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267262</td>\n",
       "      <td>-0.303854</td>\n",
       "      <td>-0.413622</td>\n",
       "      <td>-0.773668</td>\n",
       "      <td>-0.611778</td>\n",
       "      <td>-0.755378</td>\n",
       "      <td>-0.768236</td>\n",
       "      <td>0.151049</td>\n",
       "      <td>-0.832593</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2947 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      58 tGravityAcc-energy()-Y  59 tGravityAcc-energy()-Z  \\\n",
       "0                     -0.864621                  -0.967795   \n",
       "1                     -0.858163                  -0.957240   \n",
       "2                     -0.859947                  -0.960965   \n",
       "3                     -0.853713                  -0.962713   \n",
       "4                     -0.843378                  -0.965137   \n",
       "...                         ...                        ...   \n",
       "2942                  -0.870515                  -0.888599   \n",
       "2943                  -0.872342                  -0.891822   \n",
       "2944                  -0.871197                  -0.893504   \n",
       "2945                  -0.884788                  -0.885275   \n",
       "2946                  -0.885692                  -0.884370   \n",
       "\n",
       "      104 tBodyAccJerk-entropy()-Y  125 tBodyGyro-std()-Y  \\\n",
       "0                        -0.310263              -0.816164   \n",
       "1                        -0.655751              -0.929599   \n",
       "2                        -0.674949              -0.978511   \n",
       "3                        -0.614042              -0.975134   \n",
       "4                        -0.637935              -0.977951   \n",
       "...                            ...                    ...   \n",
       "2942                      0.525215              -0.526855   \n",
       "2943                      0.464601              -0.518149   \n",
       "2944                      0.530407              -0.557059   \n",
       "2945                      0.446009              -0.555166   \n",
       "2946                      0.526791              -0.508557   \n",
       "\n",
       "      128 tBodyGyro-mad()-Y  132 tBodyGyro-max()-Z  134 tBodyGyro-min()-Y  \\\n",
       "0                 -0.857801              -0.648679               0.825257   \n",
       "1                 -0.950025              -0.703212               0.870780   \n",
       "2                 -0.980558              -0.715170               0.892714   \n",
       "3                 -0.973915              -0.715170               0.894620   \n",
       "4                 -0.979507              -0.731706               0.899262   \n",
       "...                     ...                    ...                    ...   \n",
       "2942              -0.575937              -0.311752               0.485194   \n",
       "2943              -0.571732              -0.266502               0.485194   \n",
       "2944              -0.576087              -0.266502               0.656046   \n",
       "2945              -0.580453              -0.314949               0.566648   \n",
       "2946              -0.544531              -0.264569               0.566648   \n",
       "\n",
       "      138 tBodyGyro-energy()-Y  141 tBodyGyro-iqr()-Y  \\\n",
       "0                    -0.982900              -0.906104   \n",
       "1                    -0.995194              -0.960685   \n",
       "2                    -0.998265              -0.986199   \n",
       "3                    -0.999174              -0.971681   \n",
       "4                    -0.999686              -0.981584   \n",
       "...                        ...                    ...   \n",
       "2942                 -0.887282              -0.669323   \n",
       "2943                 -0.884727              -0.674429   \n",
       "2944                 -0.898203              -0.599423   \n",
       "2945                 -0.896625              -0.597778   \n",
       "2946                 -0.880072              -0.585541   \n",
       "\n",
       "      167 tBodyGyroJerk-mad()-X  ...  217 tGravityAccMag-max()  \\\n",
       "0                     -0.910363  ...                 -0.760796   \n",
       "1                     -0.968614  ...                 -0.937608   \n",
       "2                     -0.983723  ...                 -0.969212   \n",
       "3                     -0.983995  ...                 -0.969212   \n",
       "4                     -0.988244  ...                 -0.975954   \n",
       "...                         ...  ...                       ...   \n",
       "2942                  -0.652975  ...                 -0.053767   \n",
       "2943                  -0.626430  ...                 -0.053767   \n",
       "2944                  -0.653267  ...                 -0.117645   \n",
       "2945                  -0.716997  ...                 -0.204541   \n",
       "2946                  -0.694131  ...                 -0.267262   \n",
       "\n",
       "      269 fBodyAcc-std()-X  275 fBodyAcc-max()-X  282 fBodyAcc-energy()-X  \\\n",
       "0                -0.948290             -0.968424                -0.997844   \n",
       "1                -0.984350             -0.993051                -0.999592   \n",
       "2                -0.994754             -0.995082                -0.999954   \n",
       "3                -0.995594             -0.997495                -0.999963   \n",
       "4                -0.994504             -0.995932                -0.999954   \n",
       "...                    ...                   ...                      ...   \n",
       "2942             -0.269827             -0.381610                -0.744467   \n",
       "2943             -0.328225             -0.540880                -0.756815   \n",
       "2944             -0.316973             -0.340887                -0.773399   \n",
       "2945             -0.302423             -0.310583                -0.768993   \n",
       "2946             -0.303854             -0.413622                -0.773668   \n",
       "\n",
       "      286 fBodyAcc-iqr()-Y  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                -0.933812                       -0.998506   \n",
       "1                -0.971002                       -0.999850   \n",
       "2                -0.969352                       -0.999976   \n",
       "3                -0.962432                       -0.999983   \n",
       "4                -0.978862                       -0.999961   \n",
       "...                    ...                             ...   \n",
       "2942             -0.477903                       -0.734651   \n",
       "2943             -0.528280                       -0.747251   \n",
       "2944             -0.563036                       -0.762837   \n",
       "2945             -0.741144                       -0.751525   \n",
       "2946             -0.611778                       -0.755378   \n",
       "\n",
       "      315 fBodyAcc-bandsEnergy()-1,24  368 fBodyAccJerk-entropy()-Y  \\\n",
       "0                           -0.998020                     -0.672172   \n",
       "1                           -0.999687                     -1.000000   \n",
       "2                           -0.999958                     -0.939120   \n",
       "3                           -0.999966                     -1.000000   \n",
       "4                           -0.999957                     -0.939120   \n",
       "...                               ...                           ...   \n",
       "2942                        -0.739414                      0.277066   \n",
       "2943                        -0.753166                      0.394316   \n",
       "2944                        -0.769811                      0.351133   \n",
       "2945                        -0.765049                      0.182878   \n",
       "2946                        -0.768236                      0.151049   \n",
       "\n",
       "      390 fBodyAccJerk-bandsEnergy()-1,16  Activity  \n",
       "0                               -0.998040         5  \n",
       "1                               -0.999641         5  \n",
       "2                               -0.999954         5  \n",
       "3                               -0.999949         5  \n",
       "4                               -0.999955         5  \n",
       "...                                   ...       ...  \n",
       "2942                            -0.792017         2  \n",
       "2943                            -0.807522         2  \n",
       "2944                            -0.830224         2  \n",
       "2945                            -0.838522         2  \n",
       "2946                            -0.832593         2  \n",
       "\n",
       "[2947 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "test_column_names = test_names.values.tolist()\n",
    "test_column_names = [k for row in test_column_names for k in row]\n",
    "\n",
    "test_data = pd.read_csv('../data/X_test.txt', delim_whitespace = True, header = None)\n",
    "test_data.columns = test_column_names\n",
    "\n",
    "y_test = pd.read_csv('../data/y_test.txt', header = None)\n",
    "y_test.columns = ['Activity']\n",
    "\n",
    "X_test_1 = test_data[sub_features]\n",
    "X_test_2 = test_data[act_features]\n",
    "\n",
    "# X_test_1 = test_data.loc[:,'1 tBodyAcc-mean()-X':'40 tBodyAcc-correlation()-Y,Z']\n",
    "# X_test_2 = test_data.loc[:,'81 tBodyAccJerk-mean()-X':'160 tBodyGyro-correlation()-Y,Z']\n",
    "X_test = pd.concat([X_test_1, X_test_2], axis = 1)\n",
    "\n",
    "X_test = pd.concat([X_test, y_test], axis = 1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[(X_test['Activity'] == 1) | (X_test['Activity'] == 3) | (X_test['Activity'] == 4)]\n",
    "X_test = X_test.iloc[:,:-1].values\n",
    "\n",
    "y_test = y_test[(y_test['Activity'] == 1) | (y_test['Activity'] == 3) | (y_test['Activity'] == 4)]\n",
    "y_test = y_test.values\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2\n",
    "        \n",
    "for k in range(len(y_test)):\n",
    "    if y_test[k] == 1:\n",
    "        y_test[k] = 0\n",
    "    elif y_test[k] == 3:\n",
    "        y_test[k] = 1\n",
    "    else:\n",
    "        y_test[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_subjects = pd.read_csv('UCI/subject_test.txt', header = None)\n",
    "# test_subjects.columns = ['Subject']\n",
    "# test_subjects = test_subjects.values\n",
    "# test_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classifier_block(input_dim, output_dim):\n",
    "#     return nn.Sequential(\n",
    "#         nn.Linear(input_dim, output_dim),\n",
    "#         nn.Dropout(0.1),\n",
    "#         nn.LeakyReLU(0.05)\n",
    "#     )\n",
    "\n",
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self, feature_dim = 40):\n",
    "#         super(Classifier, self).__init__()\n",
    "#         self.network = nn.Sequential(\n",
    "#             classifier_block(feature_dim, 30),\n",
    "#             classifier_block(30, 25),\n",
    "#             classifier_block(25, 20),\n",
    "#             classifier_block(20, 10),\n",
    "#             nn.Linear(10, 3)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = 32):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 15.49111545085907, Final Batch Loss: 1.0942786931991577\n",
      "Epoch 2, Loss: 14.977617263793945, Final Batch Loss: 1.0439417362213135\n",
      "Epoch 3, Loss: 14.06204229593277, Final Batch Loss: 0.9392672777175903\n",
      "Epoch 4, Loss: 12.378333926200867, Final Batch Loss: 0.8268043398857117\n",
      "Epoch 5, Loss: 10.223864614963531, Final Batch Loss: 0.6607250571250916\n",
      "Epoch 6, Loss: 8.367107689380646, Final Batch Loss: 0.563985288143158\n",
      "Epoch 7, Loss: 6.9367241859436035, Final Batch Loss: 0.4394117295742035\n",
      "Epoch 8, Loss: 5.496841549873352, Final Batch Loss: 0.34278517961502075\n",
      "Epoch 9, Loss: 4.3299214243888855, Final Batch Loss: 0.2802843451499939\n",
      "Epoch 10, Loss: 3.7736791223287582, Final Batch Loss: 0.2529258131980896\n",
      "Epoch 11, Loss: 3.2999210506677628, Final Batch Loss: 0.1857481449842453\n",
      "Epoch 12, Loss: 3.159610077738762, Final Batch Loss: 0.2248685657978058\n",
      "Epoch 13, Loss: 2.772458851337433, Final Batch Loss: 0.1913353055715561\n",
      "Epoch 14, Loss: 2.7356227934360504, Final Batch Loss: 0.2107221782207489\n",
      "Epoch 15, Loss: 2.825294554233551, Final Batch Loss: 0.2400708645582199\n",
      "Epoch 16, Loss: 2.6267816573381424, Final Batch Loss: 0.18493284285068512\n",
      "Epoch 17, Loss: 2.394633963704109, Final Batch Loss: 0.15346117317676544\n",
      "Epoch 18, Loss: 2.489172250032425, Final Batch Loss: 0.18535824120044708\n",
      "Epoch 19, Loss: 2.28411166369915, Final Batch Loss: 0.16522446274757385\n",
      "Epoch 20, Loss: 2.1744316667318344, Final Batch Loss: 0.0866989940404892\n",
      "Epoch 21, Loss: 2.114920452237129, Final Batch Loss: 0.1342833936214447\n",
      "Epoch 22, Loss: 1.9380510970950127, Final Batch Loss: 0.13818810880184174\n",
      "Epoch 23, Loss: 1.92693392932415, Final Batch Loss: 0.15806394815444946\n",
      "Epoch 24, Loss: 1.82452642172575, Final Batch Loss: 0.15503744781017303\n",
      "Epoch 25, Loss: 1.7611888200044632, Final Batch Loss: 0.13620354235172272\n",
      "Epoch 26, Loss: 1.649647980928421, Final Batch Loss: 0.10493692755699158\n",
      "Epoch 27, Loss: 1.6297951340675354, Final Batch Loss: 0.2025487869977951\n",
      "Epoch 28, Loss: 1.49998127669096, Final Batch Loss: 0.12218302488327026\n",
      "Epoch 29, Loss: 1.4339841827750206, Final Batch Loss: 0.09220118820667267\n",
      "Epoch 30, Loss: 1.4295711480081081, Final Batch Loss: 0.10514035075902939\n",
      "Epoch 31, Loss: 1.4605863764882088, Final Batch Loss: 0.07728438824415207\n",
      "Epoch 32, Loss: 1.3479964062571526, Final Batch Loss: 0.08417229354381561\n",
      "Epoch 33, Loss: 1.2965639159083366, Final Batch Loss: 0.0900774672627449\n",
      "Epoch 34, Loss: 1.1445410586893559, Final Batch Loss: 0.06998142600059509\n",
      "Epoch 35, Loss: 1.2360284700989723, Final Batch Loss: 0.08869536221027374\n",
      "Epoch 36, Loss: 1.120387677103281, Final Batch Loss: 0.048748284578323364\n",
      "Epoch 37, Loss: 1.1032157018780708, Final Batch Loss: 0.10957106947898865\n",
      "Epoch 38, Loss: 1.0934293270111084, Final Batch Loss: 0.06619906425476074\n",
      "Epoch 39, Loss: 1.1266684867441654, Final Batch Loss: 0.07144881784915924\n",
      "Epoch 40, Loss: 1.0689388662576675, Final Batch Loss: 0.05034349486231804\n",
      "Epoch 41, Loss: 0.9672975614666939, Final Batch Loss: 0.06858863681554794\n",
      "Epoch 42, Loss: 0.9691450819373131, Final Batch Loss: 0.07260462641716003\n",
      "Epoch 43, Loss: 0.9518784061074257, Final Batch Loss: 0.08089296519756317\n",
      "Epoch 44, Loss: 0.8717359602451324, Final Batch Loss: 0.04894545301795006\n",
      "Epoch 45, Loss: 0.7999573685228825, Final Batch Loss: 0.03470781818032265\n",
      "Epoch 46, Loss: 0.7989166937768459, Final Batch Loss: 0.06675136834383011\n",
      "Epoch 47, Loss: 0.7710904143750668, Final Batch Loss: 0.06774134933948517\n",
      "Epoch 48, Loss: 0.7352793198078871, Final Batch Loss: 0.055800966918468475\n",
      "Epoch 49, Loss: 0.7326979525387287, Final Batch Loss: 0.02251531183719635\n",
      "Epoch 50, Loss: 0.737059323117137, Final Batch Loss: 0.04824090749025345\n",
      "Epoch 51, Loss: 0.6990681383758783, Final Batch Loss: 0.08620209246873856\n",
      "Epoch 52, Loss: 0.6972494907677174, Final Batch Loss: 0.03974604979157448\n",
      "Epoch 53, Loss: 0.6762856245040894, Final Batch Loss: 0.0534839853644371\n",
      "Epoch 54, Loss: 0.6506681609898806, Final Batch Loss: 0.03340092673897743\n",
      "Epoch 55, Loss: 0.681400952860713, Final Batch Loss: 0.040912237018346786\n",
      "Epoch 56, Loss: 0.5977449417114258, Final Batch Loss: 0.045545920729637146\n",
      "Epoch 57, Loss: 0.6704724263399839, Final Batch Loss: 0.0544729083776474\n",
      "Epoch 58, Loss: 0.5749819800257683, Final Batch Loss: 0.038780853152275085\n",
      "Epoch 59, Loss: 0.6100059673190117, Final Batch Loss: 0.06197507306933403\n",
      "Epoch 60, Loss: 0.57705850712955, Final Batch Loss: 0.042028266936540604\n",
      "Epoch 61, Loss: 0.4603022411465645, Final Batch Loss: 0.023091597482562065\n",
      "Epoch 62, Loss: 0.5617719572037458, Final Batch Loss: 0.03375997394323349\n",
      "Epoch 63, Loss: 0.45190595742315054, Final Batch Loss: 0.014645381830632687\n",
      "Epoch 64, Loss: 0.45760810375213623, Final Batch Loss: 0.03528568893671036\n",
      "Epoch 65, Loss: 0.4954170659184456, Final Batch Loss: 0.03319348767399788\n",
      "Epoch 66, Loss: 0.42677484452724457, Final Batch Loss: 0.016852987930178642\n",
      "Epoch 67, Loss: 0.5698488913476467, Final Batch Loss: 0.032393306493759155\n",
      "Epoch 68, Loss: 0.42276853788644075, Final Batch Loss: 0.05063532292842865\n",
      "Epoch 69, Loss: 0.5440547997131944, Final Batch Loss: 0.08861532062292099\n",
      "Epoch 70, Loss: 0.4576247502118349, Final Batch Loss: 0.0411795899271965\n",
      "Epoch 71, Loss: 0.4958665268495679, Final Batch Loss: 0.049481917172670364\n",
      "Epoch 72, Loss: 0.4557288270443678, Final Batch Loss: 0.025963854044675827\n",
      "Epoch 73, Loss: 0.4619829133152962, Final Batch Loss: 0.07931137084960938\n",
      "Epoch 74, Loss: 0.4530670754611492, Final Batch Loss: 0.022269530221819878\n",
      "Epoch 75, Loss: 0.439803846180439, Final Batch Loss: 0.03270038962364197\n",
      "Epoch 76, Loss: 0.4283698843792081, Final Batch Loss: 0.027796490117907524\n",
      "Epoch 77, Loss: 0.3859680173918605, Final Batch Loss: 0.027045954018831253\n",
      "Epoch 78, Loss: 0.40314116794615984, Final Batch Loss: 0.03444000333547592\n",
      "Epoch 79, Loss: 0.2965150335803628, Final Batch Loss: 0.004883055575191975\n",
      "Epoch 80, Loss: 0.35485861636698246, Final Batch Loss: 0.0181060042232275\n",
      "Epoch 81, Loss: 0.3145269965752959, Final Batch Loss: 0.03494730219244957\n",
      "Epoch 82, Loss: 0.43071828689426184, Final Batch Loss: 0.029443897306919098\n",
      "Epoch 83, Loss: 0.36990169528871775, Final Batch Loss: 0.031447552144527435\n",
      "Epoch 84, Loss: 0.3384916945360601, Final Batch Loss: 0.01809876225888729\n",
      "Epoch 85, Loss: 0.35888450033962727, Final Batch Loss: 0.024016838520765305\n",
      "Epoch 86, Loss: 0.321448075119406, Final Batch Loss: 0.010816698893904686\n",
      "Epoch 87, Loss: 0.3067681510001421, Final Batch Loss: 0.023063603788614273\n",
      "Epoch 88, Loss: 0.34410896990448236, Final Batch Loss: 0.019634203985333443\n",
      "Epoch 89, Loss: 0.3396513881161809, Final Batch Loss: 0.02592586539685726\n",
      "Epoch 90, Loss: 0.3591111283749342, Final Batch Loss: 0.022730929777026176\n",
      "Epoch 91, Loss: 0.3381187398917973, Final Batch Loss: 0.0065950374118983746\n",
      "Epoch 92, Loss: 0.3355562281794846, Final Batch Loss: 0.019395459443330765\n",
      "Epoch 93, Loss: 0.3753106836229563, Final Batch Loss: 0.018073970451951027\n",
      "Epoch 94, Loss: 0.31781561113893986, Final Batch Loss: 0.02220863848924637\n",
      "Epoch 95, Loss: 0.28650037245824933, Final Batch Loss: 0.006641294341534376\n",
      "Epoch 96, Loss: 0.30539380107074976, Final Batch Loss: 0.02451268956065178\n",
      "Epoch 97, Loss: 0.3194721844047308, Final Batch Loss: 0.034778010100126266\n",
      "Epoch 98, Loss: 0.30195803940296173, Final Batch Loss: 0.019925421103835106\n",
      "Epoch 99, Loss: 0.23652067966759205, Final Batch Loss: 0.018489914014935493\n",
      "Epoch 100, Loss: 0.3107393654063344, Final Batch Loss: 0.05124492198228836\n",
      "Epoch 101, Loss: 0.27672012569382787, Final Batch Loss: 0.02182094193994999\n",
      "Epoch 102, Loss: 0.31347957951948047, Final Batch Loss: 0.022789079695940018\n",
      "Epoch 103, Loss: 0.3329755822196603, Final Batch Loss: 0.014059305191040039\n",
      "Epoch 104, Loss: 0.3047467144206166, Final Batch Loss: 0.015425984747707844\n",
      "Epoch 105, Loss: 0.262194468639791, Final Batch Loss: 0.03725062310695648\n",
      "Epoch 106, Loss: 0.25197675498202443, Final Batch Loss: 0.007389327976852655\n",
      "Epoch 107, Loss: 0.2578904000110924, Final Batch Loss: 0.026270531117916107\n",
      "Epoch 108, Loss: 0.33784716483205557, Final Batch Loss: 0.03446079418063164\n",
      "Epoch 109, Loss: 0.2662068558856845, Final Batch Loss: 0.02114778757095337\n",
      "Epoch 110, Loss: 0.25208003586158156, Final Batch Loss: 0.03223155811429024\n",
      "Epoch 111, Loss: 0.27883119438774884, Final Batch Loss: 0.01938076689839363\n",
      "Epoch 112, Loss: 0.24000740982592106, Final Batch Loss: 0.026682676747441292\n",
      "Epoch 113, Loss: 0.27820771001279354, Final Batch Loss: 0.007187423296272755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114, Loss: 0.20941796759143472, Final Batch Loss: 0.032485079020261765\n",
      "Epoch 115, Loss: 0.2731242240406573, Final Batch Loss: 0.029203854501247406\n",
      "Epoch 116, Loss: 0.22193051734939218, Final Batch Loss: 0.010781534016132355\n",
      "Epoch 117, Loss: 0.30825682496652007, Final Batch Loss: 0.01786636747419834\n",
      "Epoch 118, Loss: 0.25848590722307563, Final Batch Loss: 0.02871589921414852\n",
      "Epoch 119, Loss: 0.22442215541377664, Final Batch Loss: 0.011673386208713055\n",
      "Epoch 120, Loss: 0.21874369261786342, Final Batch Loss: 0.01702038384974003\n",
      "Epoch 121, Loss: 0.20040297228842974, Final Batch Loss: 0.01786881498992443\n",
      "Epoch 122, Loss: 0.24816236551851034, Final Batch Loss: 0.0388057716190815\n",
      "Epoch 123, Loss: 0.20212000608444214, Final Batch Loss: 0.00920083187520504\n",
      "Epoch 124, Loss: 0.21114989835768938, Final Batch Loss: 0.009739654138684273\n",
      "Epoch 125, Loss: 0.2566900020465255, Final Batch Loss: 0.031059613451361656\n",
      "Epoch 126, Loss: 0.2290896037593484, Final Batch Loss: 0.02726666070520878\n",
      "Epoch 127, Loss: 0.2463005349272862, Final Batch Loss: 0.01936538703739643\n",
      "Epoch 128, Loss: 0.18153118481859565, Final Batch Loss: 0.006071238778531551\n",
      "Epoch 129, Loss: 0.25974037777632475, Final Batch Loss: 0.021243751049041748\n",
      "Epoch 130, Loss: 0.19618641305714846, Final Batch Loss: 0.00792704802006483\n",
      "Epoch 131, Loss: 0.25842735590413213, Final Batch Loss: 0.023127088323235512\n",
      "Epoch 132, Loss: 0.16819728026166558, Final Batch Loss: 0.0050333342514932156\n",
      "Epoch 133, Loss: 0.23357996973209083, Final Batch Loss: 0.006606725510209799\n",
      "Epoch 134, Loss: 0.20395957946311682, Final Batch Loss: 0.0018421559361740947\n",
      "Epoch 135, Loss: 0.21135820308700204, Final Batch Loss: 0.010999484919011593\n",
      "Epoch 136, Loss: 0.1661331932991743, Final Batch Loss: 0.02662397362291813\n",
      "Epoch 137, Loss: 0.21817838144488633, Final Batch Loss: 0.004599846433848143\n",
      "Epoch 138, Loss: 0.21522228443063796, Final Batch Loss: 0.018305843695998192\n",
      "Epoch 139, Loss: 0.1721582529717125, Final Batch Loss: 0.012238588184118271\n",
      "Epoch 140, Loss: 0.1777659107465297, Final Batch Loss: 0.008459785021841526\n",
      "Epoch 141, Loss: 0.19661983172409236, Final Batch Loss: 0.005532378330826759\n",
      "Epoch 142, Loss: 0.20922530023381114, Final Batch Loss: 0.005650193430483341\n",
      "Epoch 143, Loss: 0.1937607581494376, Final Batch Loss: 0.010040231049060822\n",
      "Epoch 144, Loss: 0.23132382472977042, Final Batch Loss: 0.015018420293927193\n",
      "Epoch 145, Loss: 0.18516688444651663, Final Batch Loss: 0.022079352289438248\n",
      "Epoch 146, Loss: 0.17500622768420726, Final Batch Loss: 0.0013847603695467114\n",
      "Epoch 147, Loss: 0.1481820496264845, Final Batch Loss: 0.01824023574590683\n",
      "Epoch 148, Loss: 0.17447238601744175, Final Batch Loss: 0.020986108109354973\n",
      "Epoch 149, Loss: 0.18377010012045503, Final Batch Loss: 0.03297970071434975\n",
      "Epoch 150, Loss: 0.23274001432582736, Final Batch Loss: 0.007616414222866297\n",
      "Epoch 151, Loss: 0.16195962531492114, Final Batch Loss: 0.006167880725115538\n",
      "Epoch 152, Loss: 0.1157025289721787, Final Batch Loss: 0.004549342207610607\n",
      "Epoch 153, Loss: 0.15096517093479633, Final Batch Loss: 0.005423578433692455\n",
      "Epoch 154, Loss: 0.151838265825063, Final Batch Loss: 0.0023079686798155308\n",
      "Epoch 155, Loss: 0.19517874717712402, Final Batch Loss: 0.01220652088522911\n",
      "Epoch 156, Loss: 0.20761587098240852, Final Batch Loss: 0.005172108765691519\n",
      "Epoch 157, Loss: 0.1751449399162084, Final Batch Loss: 0.016145573928952217\n",
      "Epoch 158, Loss: 0.1565472676884383, Final Batch Loss: 0.020865175873041153\n",
      "Epoch 159, Loss: 0.158704788191244, Final Batch Loss: 0.015389470383524895\n",
      "Epoch 160, Loss: 0.15115830767899752, Final Batch Loss: 0.009434754028916359\n",
      "Epoch 161, Loss: 0.13984773377887905, Final Batch Loss: 0.003768054535612464\n",
      "Epoch 162, Loss: 0.1715074694948271, Final Batch Loss: 0.01699697971343994\n",
      "Epoch 163, Loss: 0.21701005136128515, Final Batch Loss: 0.026763563975691795\n",
      "Epoch 164, Loss: 0.17401788220740855, Final Batch Loss: 0.019606938585639\n",
      "Epoch 165, Loss: 0.16838889999780804, Final Batch Loss: 0.006839567795395851\n",
      "Epoch 166, Loss: 0.16611796314828098, Final Batch Loss: 0.016079043969511986\n",
      "Epoch 167, Loss: 0.15063086443115026, Final Batch Loss: 0.0017807325348258018\n",
      "Epoch 168, Loss: 0.1946109221316874, Final Batch Loss: 0.013076122850179672\n",
      "Epoch 169, Loss: 0.2308414385188371, Final Batch Loss: 0.01312894094735384\n",
      "Epoch 170, Loss: 0.16569204279221594, Final Batch Loss: 0.005167843773961067\n",
      "Epoch 171, Loss: 0.16108624427579343, Final Batch Loss: 0.025552911683917046\n",
      "Epoch 172, Loss: 0.11047313548624516, Final Batch Loss: 0.025449756532907486\n",
      "Epoch 173, Loss: 0.19547181320376694, Final Batch Loss: 0.010933644138276577\n",
      "Epoch 174, Loss: 0.14391950448043644, Final Batch Loss: 0.012108375318348408\n",
      "Epoch 175, Loss: 0.11671597859822214, Final Batch Loss: 0.009555126540362835\n",
      "Epoch 176, Loss: 0.1628625609446317, Final Batch Loss: 0.012497100979089737\n",
      "Epoch 177, Loss: 0.11090187635272741, Final Batch Loss: 0.003679695539176464\n",
      "Epoch 178, Loss: 0.1629734804155305, Final Batch Loss: 0.0032487227581441402\n",
      "Epoch 179, Loss: 0.10962684382684529, Final Batch Loss: 0.008180911652743816\n",
      "Epoch 180, Loss: 0.1423931607278064, Final Batch Loss: 0.006350850686430931\n",
      "Epoch 181, Loss: 0.1929302014177665, Final Batch Loss: 0.006810393650084734\n",
      "Epoch 182, Loss: 0.14189921552315354, Final Batch Loss: 0.016117580235004425\n",
      "Epoch 183, Loss: 0.11263171839527786, Final Batch Loss: 0.0027743210084736347\n",
      "Epoch 184, Loss: 0.14025556074921042, Final Batch Loss: 0.04540323093533516\n",
      "Epoch 185, Loss: 0.17115319427102804, Final Batch Loss: 0.028077034279704094\n",
      "Epoch 186, Loss: 0.14194249047432095, Final Batch Loss: 0.0035820319317281246\n",
      "Epoch 187, Loss: 0.11131767625920475, Final Batch Loss: 0.005905775353312492\n",
      "Epoch 188, Loss: 0.09451613062992692, Final Batch Loss: 0.0022407332435250282\n",
      "Epoch 189, Loss: 0.14632059482391924, Final Batch Loss: 0.0019148779101669788\n",
      "Epoch 190, Loss: 0.25828790036030114, Final Batch Loss: 0.015719164162874222\n",
      "Epoch 191, Loss: 0.15409557102248073, Final Batch Loss: 0.0023130113258957863\n",
      "Epoch 192, Loss: 0.1639195648021996, Final Batch Loss: 0.026873759925365448\n",
      "Epoch 193, Loss: 0.10817176313139498, Final Batch Loss: 0.008765033446252346\n",
      "Epoch 194, Loss: 0.14061352296266705, Final Batch Loss: 0.03541123494505882\n",
      "Epoch 195, Loss: 0.14446463156491518, Final Batch Loss: 0.0025551237631589174\n",
      "Epoch 196, Loss: 0.10416019288823009, Final Batch Loss: 0.013734548352658749\n",
      "Epoch 197, Loss: 0.1497569135390222, Final Batch Loss: 0.0017850870499387383\n",
      "Epoch 198, Loss: 0.15375813539139926, Final Batch Loss: 0.003119174623861909\n",
      "Epoch 199, Loss: 0.1266325922915712, Final Batch Loss: 0.009368466213345528\n",
      "Epoch 200, Loss: 0.10883511556312442, Final Batch Loss: 0.001826440799050033\n",
      "Epoch 201, Loss: 0.11641572543885559, Final Batch Loss: 0.0026784222573041916\n",
      "Epoch 202, Loss: 0.11434941296465695, Final Batch Loss: 0.002322813728824258\n",
      "Epoch 203, Loss: 0.0991067141876556, Final Batch Loss: 0.012171031907200813\n",
      "Epoch 204, Loss: 0.1770862740231678, Final Batch Loss: 0.002363275969401002\n",
      "Epoch 205, Loss: 0.1117114822845906, Final Batch Loss: 0.006076404824852943\n",
      "Epoch 206, Loss: 0.13570085645187646, Final Batch Loss: 0.002827755408361554\n",
      "Epoch 207, Loss: 0.12685921392403543, Final Batch Loss: 0.0026693278923630714\n",
      "Epoch 208, Loss: 0.12070091546047479, Final Batch Loss: 0.00685215974226594\n",
      "Epoch 209, Loss: 0.12619474914390594, Final Batch Loss: 0.0071776253171265125\n",
      "Epoch 210, Loss: 0.13179467606823891, Final Batch Loss: 0.05463738739490509\n",
      "Epoch 211, Loss: 0.0987098659388721, Final Batch Loss: 0.017557669430971146\n",
      "Epoch 212, Loss: 0.17093333567027003, Final Batch Loss: 0.006507680751383305\n",
      "Epoch 213, Loss: 0.11740350525360554, Final Batch Loss: 0.00941932201385498\n",
      "Epoch 214, Loss: 0.1089805046794936, Final Batch Loss: 0.025858119130134583\n",
      "Epoch 215, Loss: 0.10756626760121435, Final Batch Loss: 0.008772294968366623\n",
      "Epoch 216, Loss: 0.07595502526964992, Final Batch Loss: 0.0025434335693717003\n",
      "Epoch 217, Loss: 0.11977255018427968, Final Batch Loss: 0.02158363163471222\n",
      "Epoch 218, Loss: 0.09314822958549485, Final Batch Loss: 0.0012875176034867764\n",
      "Epoch 219, Loss: 0.10265156073728576, Final Batch Loss: 0.009898053482174873\n",
      "Epoch 220, Loss: 0.11442204017657787, Final Batch Loss: 0.001049260376021266\n",
      "Epoch 221, Loss: 0.06311620003543794, Final Batch Loss: 0.006480433978140354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222, Loss: 0.08234269503736869, Final Batch Loss: 0.0024732116144150496\n",
      "Epoch 223, Loss: 0.10968392531503923, Final Batch Loss: 0.00915074534714222\n",
      "Epoch 224, Loss: 0.10924226220231503, Final Batch Loss: 0.008832182735204697\n",
      "Epoch 225, Loss: 0.11615275649819523, Final Batch Loss: 0.016156842932105064\n",
      "Epoch 226, Loss: 0.145761001505889, Final Batch Loss: 0.0016199852107092738\n",
      "Epoch 227, Loss: 0.09747849917039275, Final Batch Loss: 0.00593899330124259\n",
      "Epoch 228, Loss: 0.08535840309923515, Final Batch Loss: 0.009505276568233967\n",
      "Epoch 229, Loss: 0.12727688602171838, Final Batch Loss: 0.005706693511456251\n",
      "Epoch 230, Loss: 0.07988512396696024, Final Batch Loss: 0.0011171529768034816\n",
      "Epoch 231, Loss: 0.09365874365903437, Final Batch Loss: 0.005663557443767786\n",
      "Epoch 232, Loss: 0.08649299095850438, Final Batch Loss: 0.001680266228504479\n",
      "Epoch 233, Loss: 0.0995978283463046, Final Batch Loss: 0.001931473845615983\n",
      "Epoch 234, Loss: 0.12748163688229397, Final Batch Loss: 0.038265518844127655\n",
      "Epoch 235, Loss: 0.1019950658082962, Final Batch Loss: 0.0020009279251098633\n",
      "Epoch 236, Loss: 0.10230923377093859, Final Batch Loss: 0.010572360828518867\n",
      "Epoch 237, Loss: 0.10129161982331425, Final Batch Loss: 0.002457285998389125\n",
      "Epoch 238, Loss: 0.067715281737037, Final Batch Loss: 0.0029004730749875307\n",
      "Epoch 239, Loss: 0.11389865481760353, Final Batch Loss: 0.009088306687772274\n",
      "Epoch 240, Loss: 0.11573201010469347, Final Batch Loss: 0.008018279448151588\n",
      "Epoch 241, Loss: 0.08019912656163797, Final Batch Loss: 0.0125938281416893\n",
      "Epoch 242, Loss: 0.11221189761999995, Final Batch Loss: 0.007763677276670933\n",
      "Epoch 243, Loss: 0.05608411875437014, Final Batch Loss: 0.0020715815480798483\n",
      "Epoch 244, Loss: 0.15390031650895253, Final Batch Loss: 0.0012377442326396704\n",
      "Epoch 245, Loss: 0.06330716086085886, Final Batch Loss: 0.001183304120786488\n",
      "Epoch 246, Loss: 0.08450174960307777, Final Batch Loss: 0.007438473869115114\n",
      "Epoch 247, Loss: 0.09658636304084212, Final Batch Loss: 0.010395390912890434\n",
      "Epoch 248, Loss: 0.05044773255940527, Final Batch Loss: 0.002073498209938407\n",
      "Epoch 249, Loss: 0.15276117052417248, Final Batch Loss: 0.021370353177189827\n",
      "Epoch 250, Loss: 0.06516325491247699, Final Batch Loss: 0.004312226083129644\n",
      "Epoch 251, Loss: 0.08145489715388976, Final Batch Loss: 0.023395003750920296\n",
      "Epoch 252, Loss: 0.12890409189276397, Final Batch Loss: 0.016828706488013268\n",
      "Epoch 253, Loss: 0.06176552816759795, Final Batch Loss: 0.003090954152867198\n",
      "Epoch 254, Loss: 0.11712874157819897, Final Batch Loss: 0.0013054690789431334\n",
      "Epoch 255, Loss: 0.10426236141938716, Final Batch Loss: 0.01047173049300909\n",
      "Epoch 256, Loss: 0.12560096045490354, Final Batch Loss: 0.0022041352931410074\n",
      "Epoch 257, Loss: 0.07322717556962743, Final Batch Loss: 0.00117736856918782\n",
      "Epoch 258, Loss: 0.07677208402310498, Final Batch Loss: 0.002478135982528329\n",
      "Epoch 259, Loss: 0.13315662136301398, Final Batch Loss: 0.02342723123729229\n",
      "Epoch 260, Loss: 0.07459947059396654, Final Batch Loss: 0.0010189521126449108\n",
      "Epoch 261, Loss: 0.10888214752776548, Final Batch Loss: 0.004305425100028515\n",
      "Epoch 262, Loss: 0.07089173144777305, Final Batch Loss: 0.0010574511252343655\n",
      "Epoch 263, Loss: 0.07833478279644623, Final Batch Loss: 0.002241957001388073\n",
      "Epoch 264, Loss: 0.08541756571503356, Final Batch Loss: 0.01570979319512844\n",
      "Epoch 265, Loss: 0.1045638361829333, Final Batch Loss: 0.005465691443532705\n",
      "Epoch 266, Loss: 0.10706732753897086, Final Batch Loss: 0.012087611481547356\n",
      "Epoch 267, Loss: 0.10143052984494716, Final Batch Loss: 0.0025431837420910597\n",
      "Epoch 268, Loss: 0.09003602981101722, Final Batch Loss: 0.004710929002612829\n",
      "Epoch 269, Loss: 0.08102011808659881, Final Batch Loss: 0.0038299555890262127\n",
      "Epoch 270, Loss: 0.055633584677707404, Final Batch Loss: 0.010689198970794678\n",
      "Epoch 271, Loss: 0.06982049271755386, Final Batch Loss: 0.0034178514033555984\n",
      "Epoch 272, Loss: 0.08729466830845922, Final Batch Loss: 0.003955957014113665\n",
      "Epoch 273, Loss: 0.09937815347802825, Final Batch Loss: 0.005071092396974564\n",
      "Epoch 274, Loss: 0.09361352148698643, Final Batch Loss: 0.002408391097560525\n",
      "Epoch 275, Loss: 0.11840602394659072, Final Batch Loss: 0.000826806528493762\n",
      "Epoch 276, Loss: 0.10438592778518796, Final Batch Loss: 0.015466387383639812\n",
      "Epoch 277, Loss: 0.10961235570721328, Final Batch Loss: 0.0032531938049942255\n",
      "Epoch 278, Loss: 0.1628851814311929, Final Batch Loss: 0.0056853145360946655\n",
      "Epoch 279, Loss: 0.057866099232342094, Final Batch Loss: 0.005873731337487698\n",
      "Epoch 280, Loss: 0.08230215022922494, Final Batch Loss: 0.013214553706347942\n",
      "Epoch 281, Loss: 0.11805206234566867, Final Batch Loss: 0.016289623454213142\n",
      "Epoch 282, Loss: 0.0736154590267688, Final Batch Loss: 0.0032917680218815804\n",
      "Epoch 283, Loss: 0.09942032673279755, Final Batch Loss: 0.006807506550103426\n",
      "Epoch 284, Loss: 0.13588764646556228, Final Batch Loss: 0.007322010118514299\n",
      "Epoch 285, Loss: 0.136511214368511, Final Batch Loss: 0.02079903520643711\n",
      "Epoch 286, Loss: 0.12551356066251174, Final Batch Loss: 0.003415030427277088\n",
      "Epoch 287, Loss: 0.12683818762889132, Final Batch Loss: 0.0008771787979640067\n",
      "Epoch 288, Loss: 0.08694214548449963, Final Batch Loss: 0.00178895378485322\n",
      "Epoch 289, Loss: 0.06404779362492263, Final Batch Loss: 0.0065469094552099705\n",
      "Epoch 290, Loss: 0.07745454751420766, Final Batch Loss: 0.0015214397571980953\n",
      "Epoch 291, Loss: 0.11825001880060881, Final Batch Loss: 0.02158677764236927\n",
      "Epoch 292, Loss: 0.10328339756233618, Final Batch Loss: 0.022966545075178146\n",
      "Epoch 293, Loss: 0.12022685806732625, Final Batch Loss: 0.018427936360239983\n",
      "Epoch 294, Loss: 0.07188478205353022, Final Batch Loss: 0.0028287263121455908\n",
      "Epoch 295, Loss: 0.08922963088843971, Final Batch Loss: 0.005350032355636358\n",
      "Epoch 296, Loss: 0.04864565428579226, Final Batch Loss: 0.0009778810199350119\n",
      "Epoch 297, Loss: 0.07786779443267733, Final Batch Loss: 0.012521354481577873\n",
      "Epoch 298, Loss: 0.06624555734742898, Final Batch Loss: 0.0008094750228337944\n",
      "Epoch 299, Loss: 0.0680701197416056, Final Batch Loss: 0.002265256829559803\n",
      "Epoch 300, Loss: 0.06880755050224252, Final Batch Loss: 0.0012147004017606378\n",
      "Epoch 301, Loss: 0.06128909683320671, Final Batch Loss: 0.004219927825033665\n",
      "Epoch 302, Loss: 0.08839709180756472, Final Batch Loss: 0.004473008681088686\n",
      "Epoch 303, Loss: 0.0849543365475256, Final Batch Loss: 0.0005738895270042121\n",
      "Epoch 304, Loss: 0.06282538633968215, Final Batch Loss: 0.0053550503216683865\n",
      "Epoch 305, Loss: 0.09294112777570263, Final Batch Loss: 0.0074279215186834335\n",
      "Epoch 306, Loss: 0.08364970039110631, Final Batch Loss: 0.003175194375216961\n",
      "Epoch 307, Loss: 0.0861211493902374, Final Batch Loss: 0.0014691108372062445\n",
      "Epoch 308, Loss: 0.06335444957949221, Final Batch Loss: 0.0011215381091460586\n",
      "Epoch 309, Loss: 0.054119896434713155, Final Batch Loss: 0.010815522633492947\n",
      "Epoch 310, Loss: 0.12212924764025956, Final Batch Loss: 0.007760366424918175\n",
      "Epoch 311, Loss: 0.07133325736504048, Final Batch Loss: 0.0012222705408930779\n",
      "Epoch 312, Loss: 0.0975234194775112, Final Batch Loss: 0.011281585320830345\n",
      "Epoch 313, Loss: 0.06957715388853103, Final Batch Loss: 0.0038973300252109766\n",
      "Epoch 314, Loss: 0.06251550087472424, Final Batch Loss: 0.0021507046185433865\n",
      "Epoch 315, Loss: 0.05309977242723107, Final Batch Loss: 0.008727220818400383\n",
      "Epoch 316, Loss: 0.07610692852176726, Final Batch Loss: 0.00542310019955039\n",
      "Epoch 317, Loss: 0.06205913415760733, Final Batch Loss: 0.00351694761775434\n",
      "Epoch 318, Loss: 0.05341285915346816, Final Batch Loss: 0.0023013537283986807\n",
      "Epoch 319, Loss: 0.11736981058493257, Final Batch Loss: 0.002467499114573002\n",
      "Epoch 320, Loss: 0.12041676137596369, Final Batch Loss: 0.016022969037294388\n",
      "Epoch 321, Loss: 0.05977489578071982, Final Batch Loss: 0.002609074115753174\n",
      "Epoch 322, Loss: 0.05586841865442693, Final Batch Loss: 0.0012180182384327054\n",
      "Epoch 323, Loss: 0.04554233778617345, Final Batch Loss: 0.00038569114985875785\n",
      "Epoch 324, Loss: 0.10522791954281274, Final Batch Loss: 0.0001635272492421791\n",
      "Epoch 325, Loss: 0.06900805918849073, Final Batch Loss: 0.003325555706396699\n",
      "Epoch 326, Loss: 0.10012572249979712, Final Batch Loss: 0.0008193455287255347\n",
      "Epoch 327, Loss: 0.088767203502357, Final Batch Loss: 0.004174301866441965\n",
      "Epoch 328, Loss: 0.05320888961432502, Final Batch Loss: 0.0025410412345081568\n",
      "Epoch 329, Loss: 0.13413210335420445, Final Batch Loss: 0.033441733568906784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330, Loss: 0.07935752898629289, Final Batch Loss: 0.0002135794929927215\n",
      "Epoch 331, Loss: 0.0444299018708989, Final Batch Loss: 0.004995835945010185\n",
      "Epoch 332, Loss: 0.03284010791685432, Final Batch Loss: 0.0015828890027478337\n",
      "Epoch 333, Loss: 0.05215449960087426, Final Batch Loss: 0.0004967048880644143\n",
      "Epoch 334, Loss: 0.06685728547745384, Final Batch Loss: 0.0017320753540843725\n",
      "Epoch 335, Loss: 0.04298288837890141, Final Batch Loss: 0.0013664839789271355\n",
      "Epoch 336, Loss: 0.08140442831791006, Final Batch Loss: 0.014844280667603016\n",
      "Epoch 337, Loss: 0.05308910779422149, Final Batch Loss: 0.0007271856302395463\n",
      "Epoch 338, Loss: 0.0791268482862506, Final Batch Loss: 0.005367590114474297\n",
      "Epoch 339, Loss: 0.045571789058158174, Final Batch Loss: 0.00034064328065142035\n",
      "Epoch 340, Loss: 0.035020122304558754, Final Batch Loss: 0.00027675722958520055\n",
      "Epoch 341, Loss: 0.06508000157191418, Final Batch Loss: 0.0017494068015366793\n",
      "Epoch 342, Loss: 0.06906142487423494, Final Batch Loss: 0.003773735836148262\n",
      "Epoch 343, Loss: 0.03457382223859895, Final Batch Loss: 0.00027420208789408207\n",
      "Epoch 344, Loss: 0.0458059402735671, Final Batch Loss: 0.005126635544002056\n",
      "Epoch 345, Loss: 0.03013421647483483, Final Batch Loss: 0.0012137454468756914\n",
      "Epoch 346, Loss: 0.037597102171275765, Final Batch Loss: 0.0014049093006178737\n",
      "Epoch 347, Loss: 0.046163447899743915, Final Batch Loss: 0.0005935329827480018\n",
      "Epoch 348, Loss: 0.057901647058315575, Final Batch Loss: 0.005339596886187792\n",
      "Epoch 349, Loss: 0.04770073766121641, Final Batch Loss: 0.0007331414963118732\n",
      "Epoch 350, Loss: 0.07052887079771608, Final Batch Loss: 0.000721491000149399\n",
      "Epoch 351, Loss: 0.05966032430296764, Final Batch Loss: 0.0007506532710976899\n",
      "Epoch 352, Loss: 0.07094813679577783, Final Batch Loss: 0.018619224429130554\n",
      "Epoch 353, Loss: 0.059339644969441, Final Batch Loss: 0.0028311703354120255\n",
      "Epoch 354, Loss: 0.07429289822175633, Final Batch Loss: 0.01137041300535202\n",
      "Epoch 355, Loss: 0.10125726065598428, Final Batch Loss: 0.013707008212804794\n",
      "Epoch 356, Loss: 0.11464789949241094, Final Batch Loss: 0.0022477509919553995\n",
      "Epoch 357, Loss: 0.09010653861332685, Final Batch Loss: 0.02325069159269333\n",
      "Epoch 358, Loss: 0.07495961204404011, Final Batch Loss: 0.0016606641001999378\n",
      "Epoch 359, Loss: 0.05230296909576282, Final Batch Loss: 0.0044279214926064014\n",
      "Epoch 360, Loss: 0.050560494273668155, Final Batch Loss: 0.000496524793561548\n",
      "Epoch 361, Loss: 0.07060568372253329, Final Batch Loss: 0.0018971982644870877\n",
      "Epoch 362, Loss: 0.03520995395956561, Final Batch Loss: 0.003072981256991625\n",
      "Epoch 363, Loss: 0.04903728383942507, Final Batch Loss: 0.0003319619281683117\n",
      "Epoch 364, Loss: 0.06868929203483276, Final Batch Loss: 0.00041474748286418617\n",
      "Epoch 365, Loss: 0.052867084959871136, Final Batch Loss: 0.0007350569940172136\n",
      "Epoch 366, Loss: 0.08826443084399216, Final Batch Loss: 0.005189595278352499\n",
      "Epoch 367, Loss: 0.021506146993488073, Final Batch Loss: 0.00035483771353028715\n",
      "Epoch 368, Loss: 0.022525054635480046, Final Batch Loss: 0.002959717297926545\n",
      "Epoch 369, Loss: 0.06457782271900214, Final Batch Loss: 0.008108849637210369\n",
      "Epoch 370, Loss: 0.06824013241566718, Final Batch Loss: 0.0002625918132252991\n",
      "Epoch 371, Loss: 0.049665003636619076, Final Batch Loss: 0.00026333858841098845\n",
      "Epoch 372, Loss: 0.055183375254273415, Final Batch Loss: 0.015918271616101265\n",
      "Epoch 373, Loss: 0.04620240768417716, Final Batch Loss: 0.0004894750309176743\n",
      "Epoch 374, Loss: 0.07040386719745584, Final Batch Loss: 0.0004565390117932111\n",
      "Epoch 375, Loss: 0.03848789798212238, Final Batch Loss: 0.010707574896514416\n",
      "Epoch 376, Loss: 0.0658317431807518, Final Batch Loss: 0.0011834012111648917\n",
      "Epoch 377, Loss: 0.10210875580378342, Final Batch Loss: 9.390061313752085e-05\n",
      "Epoch 378, Loss: 0.03621882056177128, Final Batch Loss: 0.0003264507104177028\n",
      "Epoch 379, Loss: 0.049407019367208704, Final Batch Loss: 0.0016641204711049795\n",
      "Epoch 380, Loss: 0.0403845016262494, Final Batch Loss: 0.0026901152450591326\n",
      "Epoch 381, Loss: 0.09180393714632373, Final Batch Loss: 0.0014803047524765134\n",
      "Epoch 382, Loss: 0.03444689995376393, Final Batch Loss: 0.001429980737157166\n",
      "Epoch 383, Loss: 0.03564607283624355, Final Batch Loss: 0.004464110359549522\n",
      "Epoch 384, Loss: 0.05109733194694854, Final Batch Loss: 0.009266678243875504\n",
      "Epoch 385, Loss: 0.13226583536015823, Final Batch Loss: 0.005347768776118755\n",
      "Epoch 386, Loss: 0.05698659730842337, Final Batch Loss: 0.0019878572784364223\n",
      "Epoch 387, Loss: 0.031796722672879696, Final Batch Loss: 0.0026767542585730553\n",
      "Epoch 388, Loss: 0.0387604914867552, Final Batch Loss: 0.0017701408360153437\n",
      "Epoch 389, Loss: 0.0743312549602706, Final Batch Loss: 0.002568579278886318\n",
      "Epoch 390, Loss: 0.06459792199893855, Final Batch Loss: 0.0031328992918133736\n",
      "Epoch 391, Loss: 0.04998485912074102, Final Batch Loss: 0.0044462126679718494\n",
      "Epoch 392, Loss: 0.08905410155421123, Final Batch Loss: 0.01736092008650303\n",
      "Epoch 393, Loss: 0.06741174083435908, Final Batch Loss: 0.0021248848643153906\n",
      "Epoch 394, Loss: 0.06509614705282729, Final Batch Loss: 0.0034194216132164\n",
      "Epoch 395, Loss: 0.039806153858080506, Final Batch Loss: 0.003131638281047344\n",
      "Epoch 396, Loss: 0.05418924485275056, Final Batch Loss: 0.0006719521479681134\n",
      "Epoch 397, Loss: 0.05328816472319886, Final Batch Loss: 0.0021701890509575605\n",
      "Epoch 398, Loss: 0.03876399341970682, Final Batch Loss: 0.0006429075729101896\n",
      "Epoch 399, Loss: 0.0410464777960442, Final Batch Loss: 0.014049844816327095\n",
      "Epoch 400, Loss: 0.05882273131283, Final Batch Loss: 0.0018626712262630463\n",
      "Epoch 401, Loss: 0.03368175672949292, Final Batch Loss: 0.0006322931731119752\n",
      "Epoch 402, Loss: 0.040066086905426346, Final Batch Loss: 0.00022430589888244867\n",
      "Epoch 403, Loss: 0.055027363676344976, Final Batch Loss: 0.001218548626638949\n",
      "Epoch 404, Loss: 0.04765966103877872, Final Batch Loss: 0.00380989839322865\n",
      "Epoch 405, Loss: 0.03305781976087019, Final Batch Loss: 0.0018252249574288726\n",
      "Epoch 406, Loss: 0.02908018126618117, Final Batch Loss: 0.00021513855608645827\n",
      "Epoch 407, Loss: 0.08254650670278352, Final Batch Loss: 0.005944398231804371\n",
      "Epoch 408, Loss: 0.03657114070665557, Final Batch Loss: 0.02138388715684414\n",
      "Epoch 409, Loss: 0.06185599582386203, Final Batch Loss: 0.00026194678503088653\n",
      "Epoch 410, Loss: 0.0880508403206477, Final Batch Loss: 0.004959139507263899\n",
      "Epoch 411, Loss: 0.0590551718196366, Final Batch Loss: 0.003838805016130209\n",
      "Epoch 412, Loss: 0.04378059643204324, Final Batch Loss: 0.019093384966254234\n",
      "Epoch 413, Loss: 0.024252291361335665, Final Batch Loss: 0.0037721428088843822\n",
      "Epoch 414, Loss: 0.07297819458472077, Final Batch Loss: 0.001007718499749899\n",
      "Epoch 415, Loss: 0.041374570660991594, Final Batch Loss: 0.007814975455403328\n",
      "Epoch 416, Loss: 0.024569609988247976, Final Batch Loss: 0.0055086310021579266\n",
      "Epoch 417, Loss: 0.07738795300247148, Final Batch Loss: 0.0025745658203959465\n",
      "Epoch 418, Loss: 0.07206485743517987, Final Batch Loss: 0.03633878007531166\n",
      "Epoch 419, Loss: 0.05079597112489864, Final Batch Loss: 0.023361019790172577\n",
      "Epoch 420, Loss: 0.05445439790491946, Final Batch Loss: 0.014631753787398338\n",
      "Epoch 421, Loss: 0.10837769755744375, Final Batch Loss: 0.0012156303273513913\n",
      "Epoch 422, Loss: 0.048253852350171655, Final Batch Loss: 0.0006273469189181924\n",
      "Epoch 423, Loss: 0.04957207996631041, Final Batch Loss: 0.0028031794354319572\n",
      "Epoch 424, Loss: 0.03116839364520274, Final Batch Loss: 0.0016601425595581532\n",
      "Epoch 425, Loss: 0.08966323177446611, Final Batch Loss: 0.047061141580343246\n",
      "Epoch 426, Loss: 0.028279876132728532, Final Batch Loss: 0.0006418471457436681\n",
      "Epoch 427, Loss: 0.04301428435428534, Final Batch Loss: 0.01946401409804821\n",
      "Epoch 428, Loss: 0.048097516017151065, Final Batch Loss: 0.0064578065648674965\n",
      "Epoch 429, Loss: 0.045527218775532674, Final Batch Loss: 0.0013042575446888804\n",
      "Epoch 430, Loss: 0.019667892978759483, Final Batch Loss: 0.004853007849305868\n",
      "Epoch 431, Loss: 0.05692026358155999, Final Batch Loss: 0.03270351141691208\n",
      "Epoch 432, Loss: 0.07977125839533983, Final Batch Loss: 0.015863796696066856\n",
      "Epoch 433, Loss: 0.11964659346267581, Final Batch Loss: 0.0010152742033824325\n",
      "Epoch 434, Loss: 0.07342796784359962, Final Batch Loss: 0.010040619410574436\n",
      "Epoch 435, Loss: 0.09930815317784436, Final Batch Loss: 0.005670816637575626\n",
      "Epoch 436, Loss: 0.021923709311522543, Final Batch Loss: 0.0002910794282797724\n",
      "Epoch 437, Loss: 0.02469998868764378, Final Batch Loss: 0.0024460013955831528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438, Loss: 0.04739735493785702, Final Batch Loss: 0.002444410463795066\n",
      "Epoch 439, Loss: 0.02442103819339536, Final Batch Loss: 0.00834850687533617\n",
      "Epoch 440, Loss: 0.05259926576400176, Final Batch Loss: 0.0002900052350014448\n",
      "Epoch 441, Loss: 0.07063536340137944, Final Batch Loss: 0.0011252184631302953\n",
      "Epoch 442, Loss: 0.05961434036726132, Final Batch Loss: 0.010708203539252281\n",
      "Epoch 443, Loss: 0.047995442495448515, Final Batch Loss: 0.001899524824693799\n",
      "Epoch 444, Loss: 0.043225542962318286, Final Batch Loss: 0.005935748107731342\n",
      "Epoch 445, Loss: 0.01762445631902665, Final Batch Loss: 0.00015714910114184022\n",
      "Epoch 446, Loss: 0.059610497293761, Final Batch Loss: 0.0006880350993014872\n",
      "Epoch 447, Loss: 0.0512479407916544, Final Batch Loss: 0.0059030852280557156\n",
      "Epoch 448, Loss: 0.04293199769745115, Final Batch Loss: 0.00017647299682721496\n",
      "Epoch 449, Loss: 0.042737345458590426, Final Batch Loss: 0.0006375137018039823\n",
      "Epoch 450, Loss: 0.019596323232690338, Final Batch Loss: 0.007542971987277269\n",
      "Epoch 451, Loss: 0.05664274041191675, Final Batch Loss: 0.007424931973218918\n",
      "Epoch 452, Loss: 0.03586956991057377, Final Batch Loss: 0.0018925027688965201\n",
      "Epoch 453, Loss: 0.015363692946266383, Final Batch Loss: 0.00033645928488112986\n",
      "Epoch 454, Loss: 0.0262128452595789, Final Batch Loss: 0.002799547743052244\n",
      "Epoch 455, Loss: 0.026625431375578046, Final Batch Loss: 0.0019977877382189035\n",
      "Epoch 456, Loss: 0.036129292158875614, Final Batch Loss: 0.0019296723185107112\n",
      "Epoch 457, Loss: 0.048722897554398514, Final Batch Loss: 0.00849470030516386\n",
      "Epoch 458, Loss: 0.043229652859736234, Final Batch Loss: 0.00032291392562910914\n",
      "Epoch 459, Loss: 0.01384966519617592, Final Batch Loss: 0.004103782121092081\n",
      "Epoch 460, Loss: 0.010523458884563297, Final Batch Loss: 0.0011540001723915339\n",
      "Epoch 461, Loss: 0.020770738821738632, Final Batch Loss: 0.001137971063144505\n",
      "Epoch 462, Loss: 0.030206426410586573, Final Batch Loss: 0.00024896589457057416\n",
      "Epoch 463, Loss: 0.024587392865214497, Final Batch Loss: 0.0020286357030272484\n",
      "Epoch 464, Loss: 0.0468465558369644, Final Batch Loss: 0.0007145160925574601\n",
      "Epoch 465, Loss: 0.05519654713134514, Final Batch Loss: 0.005790032912045717\n",
      "Epoch 466, Loss: 0.035218587225244846, Final Batch Loss: 0.0007602872792631388\n",
      "Epoch 467, Loss: 0.013373236171901226, Final Batch Loss: 7.058290066197515e-05\n",
      "Epoch 468, Loss: 0.02528156510379631, Final Batch Loss: 0.0005523102008737624\n",
      "Epoch 469, Loss: 0.06824010285345139, Final Batch Loss: 0.0008618663996458054\n",
      "Epoch 470, Loss: 0.17562624800484627, Final Batch Loss: 0.00341700273565948\n",
      "Epoch 471, Loss: 0.08501224531210028, Final Batch Loss: 0.0007929436396807432\n",
      "Epoch 472, Loss: 0.07005000182107324, Final Batch Loss: 0.00011847116547869518\n",
      "Epoch 473, Loss: 0.04843703951337375, Final Batch Loss: 0.005500291474163532\n",
      "Epoch 474, Loss: 0.03224458706972655, Final Batch Loss: 0.0008548254263587296\n",
      "Epoch 475, Loss: 0.05297918542055413, Final Batch Loss: 0.00017675981507636607\n",
      "Epoch 476, Loss: 0.06235939460748341, Final Batch Loss: 0.0002810088626574725\n",
      "Epoch 477, Loss: 0.0383896458952222, Final Batch Loss: 0.0029243805911391973\n",
      "Epoch 478, Loss: 0.04311558434710605, Final Batch Loss: 0.0007917726179584861\n",
      "Epoch 479, Loss: 0.024928787461249158, Final Batch Loss: 0.006908840499818325\n",
      "Epoch 480, Loss: 0.05494654869835358, Final Batch Loss: 0.005228490103036165\n",
      "Epoch 481, Loss: 0.05381386060616933, Final Batch Loss: 0.001520407386124134\n",
      "Epoch 482, Loss: 0.049414283072110265, Final Batch Loss: 0.01062669139355421\n",
      "Epoch 483, Loss: 0.07210856332676485, Final Batch Loss: 0.0012978542363271117\n",
      "Epoch 484, Loss: 0.08635148231405765, Final Batch Loss: 0.0014580984134227037\n",
      "Epoch 485, Loss: 0.08075592044770019, Final Batch Loss: 0.010300622321665287\n",
      "Epoch 486, Loss: 0.051327308086911216, Final Batch Loss: 0.0010264425072818995\n",
      "Epoch 487, Loss: 0.07055585453053936, Final Batch Loss: 0.00016992920427583158\n",
      "Epoch 488, Loss: 0.059085232598590665, Final Batch Loss: 0.0014725958462804556\n",
      "Epoch 489, Loss: 0.03236722675501369, Final Batch Loss: 0.0001926964905578643\n",
      "Epoch 490, Loss: 0.024903149402234703, Final Batch Loss: 0.0013504402013495564\n",
      "Epoch 491, Loss: 0.019204073323635384, Final Batch Loss: 0.002137040486559272\n",
      "Epoch 492, Loss: 0.03293715040490497, Final Batch Loss: 0.0005511566996574402\n",
      "Epoch 493, Loss: 0.04747929121367633, Final Batch Loss: 0.006976278964430094\n",
      "Epoch 494, Loss: 0.0945995525107719, Final Batch Loss: 0.009451181627810001\n",
      "Epoch 495, Loss: 0.10422142737661488, Final Batch Loss: 0.007894541136920452\n",
      "Epoch 496, Loss: 0.034569354669656605, Final Batch Loss: 0.0008553015650250018\n",
      "Epoch 497, Loss: 0.03886988355952781, Final Batch Loss: 0.0010280878050252795\n",
      "Epoch 498, Loss: 0.04790072140167467, Final Batch Loss: 0.0007733934908173978\n",
      "Epoch 499, Loss: 0.03982708273542812, Final Batch Loss: 0.010233502835035324\n",
      "Epoch 500, Loss: 0.05409239608707139, Final Batch Loss: 0.0003758265229407698\n",
      "Epoch 501, Loss: 0.06561658697319217, Final Batch Loss: 0.0007711135549470782\n",
      "Epoch 502, Loss: 0.08857285115664126, Final Batch Loss: 0.005970703437924385\n",
      "Epoch 503, Loss: 0.05277963203843683, Final Batch Loss: 0.003720880253240466\n",
      "Epoch 504, Loss: 0.0526223951310385, Final Batch Loss: 0.014095659367740154\n",
      "Epoch 505, Loss: 0.04564833464974072, Final Batch Loss: 0.007944583892822266\n",
      "Epoch 506, Loss: 0.018564537735073827, Final Batch Loss: 0.0004701381840277463\n",
      "Epoch 507, Loss: 0.06317564308847068, Final Batch Loss: 9.139732719631866e-05\n",
      "Epoch 508, Loss: 0.0192196452699136, Final Batch Loss: 0.0003106235235463828\n",
      "Epoch 509, Loss: 0.018405697381240316, Final Batch Loss: 0.0017192824743688107\n",
      "Epoch 510, Loss: 0.020204395361361094, Final Batch Loss: 0.00023036656784825027\n",
      "Epoch 511, Loss: 0.022009376974892803, Final Batch Loss: 0.0003007089253515005\n",
      "Epoch 512, Loss: 0.06448636501590954, Final Batch Loss: 9.97540118987672e-05\n",
      "Epoch 513, Loss: 0.0188279380381573, Final Batch Loss: 0.0006510830717161298\n",
      "Epoch 514, Loss: 0.046138546349538956, Final Batch Loss: 0.0022022207267582417\n",
      "Epoch 515, Loss: 0.019303810164274182, Final Batch Loss: 0.0011475593782961369\n",
      "Epoch 516, Loss: 0.027751270274166018, Final Batch Loss: 0.000968797248788178\n",
      "Epoch 517, Loss: 0.018064669900923036, Final Batch Loss: 0.0029854862950742245\n",
      "Epoch 518, Loss: 0.011110016122984234, Final Batch Loss: 8.71151132741943e-05\n",
      "Epoch 519, Loss: 0.013580204955360387, Final Batch Loss: 8.856575732352212e-05\n",
      "Epoch 520, Loss: 0.0370824178608018, Final Batch Loss: 0.000996622839011252\n",
      "Epoch 521, Loss: 0.011050048782635713, Final Batch Loss: 0.00011259254097240046\n",
      "Epoch 522, Loss: 0.04427530508110067, Final Batch Loss: 0.0004422834899742156\n",
      "Epoch 523, Loss: 0.03374649893885362, Final Batch Loss: 0.0024159846361726522\n",
      "Epoch 524, Loss: 0.04035154574376065, Final Batch Loss: 0.01050245389342308\n",
      "Epoch 525, Loss: 0.04849923749497975, Final Batch Loss: 0.0018343657720834017\n",
      "Epoch 526, Loss: 0.017793841019738466, Final Batch Loss: 0.009755504317581654\n",
      "Epoch 527, Loss: 0.07065774703369243, Final Batch Loss: 0.0022319317795336246\n",
      "Epoch 528, Loss: 0.05445223965216428, Final Batch Loss: 0.0116333132609725\n",
      "Epoch 529, Loss: 0.060899154683283996, Final Batch Loss: 0.013941126875579357\n",
      "Epoch 530, Loss: 0.05660194823576603, Final Batch Loss: 0.00035703499452210963\n",
      "Epoch 531, Loss: 0.03781880436872598, Final Batch Loss: 0.00018482330779079348\n",
      "Epoch 532, Loss: 0.049670093692839146, Final Batch Loss: 0.005839120130985975\n",
      "Epoch 533, Loss: 0.02647105886717327, Final Batch Loss: 0.0004570208548102528\n",
      "Epoch 534, Loss: 0.05715424023219384, Final Batch Loss: 0.0001599399111000821\n",
      "Epoch 535, Loss: 0.026222965112538077, Final Batch Loss: 0.00031877009314484894\n",
      "Epoch 536, Loss: 0.030616390838986263, Final Batch Loss: 0.00020406093972269446\n",
      "Epoch 537, Loss: 0.020942869334248826, Final Batch Loss: 0.00015793390048202127\n",
      "Epoch 538, Loss: 0.0964863012341084, Final Batch Loss: 0.01604774035513401\n",
      "Epoch 539, Loss: 0.030390674521186156, Final Batch Loss: 0.00938674621284008\n",
      "Epoch 540, Loss: 0.02161332290415885, Final Batch Loss: 0.0002843124093487859\n",
      "Epoch 541, Loss: 0.03927209827816114, Final Batch Loss: 0.010569585487246513\n",
      "Epoch 542, Loss: 0.01796530709543731, Final Batch Loss: 0.0005665861535817385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 543, Loss: 0.04205699192243628, Final Batch Loss: 0.0003812316572293639\n",
      "Epoch 544, Loss: 0.032712597647332586, Final Batch Loss: 0.017535025253891945\n",
      "Epoch 545, Loss: 0.02779903325426858, Final Batch Loss: 0.0007656820234842598\n",
      "Epoch 546, Loss: 0.017250683573365677, Final Batch Loss: 0.001044676173478365\n",
      "Epoch 547, Loss: 0.03573871900152881, Final Batch Loss: 0.0025580781511962414\n",
      "Epoch 548, Loss: 0.07436433078692062, Final Batch Loss: 0.00024784242850728333\n",
      "Epoch 549, Loss: 0.04566047327534761, Final Batch Loss: 0.002079182304441929\n",
      "Epoch 550, Loss: 0.014539405732648447, Final Batch Loss: 0.0006557831657119095\n",
      "Epoch 551, Loss: 0.007649774233868811, Final Batch Loss: 0.0005581008153967559\n",
      "Epoch 552, Loss: 0.01254552762111416, Final Batch Loss: 0.00039323815144598484\n",
      "Epoch 553, Loss: 0.019957661726948572, Final Batch Loss: 0.00020527678134385496\n",
      "Epoch 554, Loss: 0.011827892831206555, Final Batch Loss: 0.0003824012237600982\n",
      "Epoch 555, Loss: 0.015312518622522475, Final Batch Loss: 0.00044960170635022223\n",
      "Epoch 556, Loss: 0.048187674139626324, Final Batch Loss: 0.0003498075529932976\n",
      "Epoch 557, Loss: 0.08822417776536895, Final Batch Loss: 0.009949145838618279\n",
      "Epoch 558, Loss: 0.046047054151131306, Final Batch Loss: 2.8959635528735816e-05\n",
      "Epoch 559, Loss: 0.028187231124320533, Final Batch Loss: 0.01949591189622879\n",
      "Epoch 560, Loss: 0.08737782062235055, Final Batch Loss: 0.004489390179514885\n",
      "Epoch 561, Loss: 0.02551606119959615, Final Batch Loss: 0.0008449674933217466\n",
      "Epoch 562, Loss: 0.03075664827338187, Final Batch Loss: 0.002914429409429431\n",
      "Epoch 563, Loss: 0.052920526592060924, Final Batch Loss: 0.02667500637471676\n",
      "Epoch 564, Loss: 0.03705293146413169, Final Batch Loss: 6.40653888694942e-05\n",
      "Epoch 565, Loss: 0.056026971666142344, Final Batch Loss: 0.0005346717080101371\n",
      "Epoch 566, Loss: 0.050775803421856835, Final Batch Loss: 0.000440700794570148\n",
      "Epoch 567, Loss: 0.07101589965532185, Final Batch Loss: 0.021323414519429207\n",
      "Epoch 568, Loss: 0.12095466746541206, Final Batch Loss: 0.00071960553759709\n",
      "Epoch 569, Loss: 0.08229732831387082, Final Batch Loss: 0.0019916193559765816\n",
      "Epoch 570, Loss: 0.031878287001745775, Final Batch Loss: 0.00019648170564323664\n",
      "Epoch 571, Loss: 0.046885845658835024, Final Batch Loss: 0.0019300950225442648\n",
      "Epoch 572, Loss: 0.058246551649062894, Final Batch Loss: 0.005909903906285763\n",
      "Epoch 573, Loss: 0.04010409185138997, Final Batch Loss: 0.009749534539878368\n",
      "Epoch 574, Loss: 0.018802729166054633, Final Batch Loss: 0.00018920587899629027\n",
      "Epoch 575, Loss: 0.013330160225450527, Final Batch Loss: 0.00023765703372191638\n",
      "Epoch 576, Loss: 0.03518045786768198, Final Batch Loss: 0.002117086900398135\n",
      "Epoch 577, Loss: 0.0772045535959478, Final Batch Loss: 0.00014734573778696358\n",
      "Epoch 578, Loss: 0.0180438306852011, Final Batch Loss: 0.0021320427767932415\n",
      "Epoch 579, Loss: 0.01880569693457801, Final Batch Loss: 0.00013822178880218416\n",
      "Epoch 580, Loss: 0.011607184213062283, Final Batch Loss: 0.0007266671163961291\n",
      "Epoch 581, Loss: 0.026222424421575852, Final Batch Loss: 0.0001233908988069743\n",
      "Epoch 582, Loss: 0.019512082522851415, Final Batch Loss: 0.0001504987449152395\n",
      "Epoch 583, Loss: 0.03322685952298343, Final Batch Loss: 0.0016415065620094538\n",
      "Epoch 584, Loss: 0.04765263810986653, Final Batch Loss: 0.0018492296803742647\n",
      "Epoch 585, Loss: 0.032752040890045464, Final Batch Loss: 0.00010168607695959508\n",
      "Epoch 586, Loss: 0.026820497841981705, Final Batch Loss: 0.00026470961165614426\n",
      "Epoch 587, Loss: 0.019196685316273943, Final Batch Loss: 0.00033243882353417575\n",
      "Epoch 588, Loss: 0.05064179042528849, Final Batch Loss: 0.006877710111439228\n",
      "Epoch 589, Loss: 0.042478824594581965, Final Batch Loss: 0.003370666643604636\n",
      "Epoch 590, Loss: 0.06924217083724216, Final Batch Loss: 0.00013243308058008552\n",
      "Epoch 591, Loss: 0.02930634858785197, Final Batch Loss: 0.0064130923710763454\n",
      "Epoch 592, Loss: 0.05700048061044072, Final Batch Loss: 0.0145369041711092\n",
      "Epoch 593, Loss: 0.04573525349405827, Final Batch Loss: 0.006227994803339243\n",
      "Epoch 594, Loss: 0.0316592348026461, Final Batch Loss: 0.0016096992185339332\n",
      "Epoch 595, Loss: 0.02427767388871871, Final Batch Loss: 0.0008310756529681385\n",
      "Epoch 596, Loss: 0.04805860166379716, Final Batch Loss: 0.002138381591066718\n",
      "Epoch 597, Loss: 0.1352791607459949, Final Batch Loss: 0.0006654707249253988\n",
      "Epoch 598, Loss: 0.08663633270771243, Final Batch Loss: 0.001811077119782567\n",
      "Epoch 599, Loss: 0.11702244443586096, Final Batch Loss: 0.0007123289396986365\n",
      "Epoch 600, Loss: 0.055214213687577285, Final Batch Loss: 0.005507347639650106\n",
      "Epoch 601, Loss: 0.05118473805487156, Final Batch Loss: 0.007719726301729679\n",
      "Epoch 602, Loss: 0.04432497193920426, Final Batch Loss: 0.00030847699963487685\n",
      "Epoch 603, Loss: 0.02628959527646657, Final Batch Loss: 0.001314583234488964\n",
      "Epoch 604, Loss: 0.016016451569157653, Final Batch Loss: 0.0026071181055158377\n",
      "Epoch 605, Loss: 0.02416188169445377, Final Batch Loss: 0.0014530798653140664\n",
      "Epoch 606, Loss: 0.013495876657543704, Final Batch Loss: 0.0001498100027674809\n",
      "Epoch 607, Loss: 0.029737237786321202, Final Batch Loss: 0.000580992316827178\n",
      "Epoch 608, Loss: 0.02075905467791017, Final Batch Loss: 0.002356517594307661\n",
      "Epoch 609, Loss: 0.08100963105243864, Final Batch Loss: 0.0009209890849888325\n",
      "Epoch 610, Loss: 0.1257122631650418, Final Batch Loss: 0.0009627446415834129\n",
      "Epoch 611, Loss: 0.016559453535592183, Final Batch Loss: 0.00031910190591588616\n",
      "Epoch 612, Loss: 0.012410377807100303, Final Batch Loss: 0.001384433824568987\n",
      "Epoch 613, Loss: 0.0385767954721814, Final Batch Loss: 0.0008499643299728632\n",
      "Epoch 614, Loss: 0.04010198394826148, Final Batch Loss: 0.0008044918649829924\n",
      "Epoch 615, Loss: 0.026694774664065335, Final Batch Loss: 0.0028894920833408833\n",
      "Epoch 616, Loss: 0.008100941369775683, Final Batch Loss: 0.0010427641682326794\n",
      "Epoch 617, Loss: 0.014336381602333859, Final Batch Loss: 0.0009189219563268125\n",
      "Epoch 618, Loss: 0.04264251675340347, Final Batch Loss: 0.004278392996639013\n",
      "Epoch 619, Loss: 0.0463439409431885, Final Batch Loss: 0.000574182893615216\n",
      "Epoch 620, Loss: 0.047374943605973385, Final Batch Loss: 0.03576478362083435\n",
      "Epoch 621, Loss: 0.024578513082815334, Final Batch Loss: 0.0002726290258578956\n",
      "Epoch 622, Loss: 0.03343681244041363, Final Batch Loss: 0.00949717964977026\n",
      "Epoch 623, Loss: 0.03122366105526453, Final Batch Loss: 0.0008338195621035993\n",
      "Epoch 624, Loss: 0.013444573240121827, Final Batch Loss: 0.0021003952715545893\n",
      "Epoch 625, Loss: 0.0180318789643934, Final Batch Loss: 0.00017924579151440412\n",
      "Epoch 626, Loss: 0.01883949025068432, Final Batch Loss: 0.0001462938671465963\n",
      "Epoch 627, Loss: 0.017369523993693292, Final Batch Loss: 0.000348650966770947\n",
      "Epoch 628, Loss: 0.07121841630578274, Final Batch Loss: 0.00020723151101265103\n",
      "Epoch 629, Loss: 0.03510170887602726, Final Batch Loss: 0.0013081851648166776\n",
      "Epoch 630, Loss: 0.010994996744557284, Final Batch Loss: 0.0009427835466340184\n",
      "Epoch 631, Loss: 0.02724738631877699, Final Batch Loss: 0.00029456644551828504\n",
      "Epoch 632, Loss: 0.05426351107598748, Final Batch Loss: 0.0017027632566168904\n",
      "Epoch 633, Loss: 0.024681721233719145, Final Batch Loss: 0.00032961589749902487\n",
      "Epoch 634, Loss: 0.06770253803915693, Final Batch Loss: 0.013558345846831799\n",
      "Epoch 635, Loss: 0.021407631691545248, Final Batch Loss: 0.00046583512448705733\n",
      "Epoch 636, Loss: 0.036339034770207945, Final Batch Loss: 0.0014705732464790344\n",
      "Epoch 637, Loss: 0.0536861078653601, Final Batch Loss: 0.027555307373404503\n",
      "Epoch 638, Loss: 0.013731766637647524, Final Batch Loss: 0.00045531318755820394\n",
      "Epoch 639, Loss: 0.031446152439457364, Final Batch Loss: 0.0012772001791745424\n",
      "Epoch 640, Loss: 0.012587680561409798, Final Batch Loss: 0.00036644653300754726\n",
      "Epoch 641, Loss: 0.01796817341892165, Final Batch Loss: 0.0017841600347310305\n",
      "Epoch 642, Loss: 0.011048805914469995, Final Batch Loss: 0.001156219863332808\n",
      "Epoch 643, Loss: 0.007311951419978868, Final Batch Loss: 0.0002076415257761255\n",
      "Epoch 644, Loss: 0.010191352863330394, Final Batch Loss: 0.00037709821481257677\n",
      "Epoch 645, Loss: 0.006175903205075883, Final Batch Loss: 0.0019538968335837126\n",
      "Epoch 646, Loss: 0.005208897688135039, Final Batch Loss: 0.00011322233331156895\n",
      "Epoch 647, Loss: 0.03049982027732767, Final Batch Loss: 0.00013587642752099782\n",
      "Epoch 648, Loss: 0.0102371173161373, Final Batch Loss: 0.001257139490917325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649, Loss: 0.06438786913713557, Final Batch Loss: 0.031495507806539536\n",
      "Epoch 650, Loss: 0.04428243847360136, Final Batch Loss: 0.0014205685583874583\n",
      "Epoch 651, Loss: 0.086729178117821, Final Batch Loss: 0.00032545963767915964\n",
      "Epoch 652, Loss: 0.07847676717210561, Final Batch Loss: 0.007275697309523821\n",
      "Epoch 653, Loss: 0.048851804007426836, Final Batch Loss: 0.00017314132128376514\n",
      "Epoch 654, Loss: 0.015090768563823076, Final Batch Loss: 0.008341064676642418\n",
      "Epoch 655, Loss: 0.05377677566866623, Final Batch Loss: 0.0007980118389241397\n",
      "Epoch 656, Loss: 0.008387960468098754, Final Batch Loss: 0.00028165284311398864\n",
      "Epoch 657, Loss: 0.012844300847064005, Final Batch Loss: 0.0007035901071503758\n",
      "Epoch 658, Loss: 0.024421638230705867, Final Batch Loss: 0.0005987610784359276\n",
      "Epoch 659, Loss: 0.018252615627716295, Final Batch Loss: 0.0002282315690536052\n",
      "Epoch 660, Loss: 0.015514839804382063, Final Batch Loss: 0.004047750495374203\n",
      "Epoch 661, Loss: 0.030240845509979408, Final Batch Loss: 0.00022916610760148615\n",
      "Epoch 662, Loss: 0.039288745319936424, Final Batch Loss: 0.0006883611786179245\n",
      "Epoch 663, Loss: 0.0165383518251474, Final Batch Loss: 0.0006420311983674765\n",
      "Epoch 664, Loss: 0.020341024704976007, Final Batch Loss: 4.044363595312461e-05\n",
      "Epoch 665, Loss: 0.06915371897048317, Final Batch Loss: 0.03127340227365494\n",
      "Epoch 666, Loss: 0.03874559293035418, Final Batch Loss: 0.0003140996559523046\n",
      "Epoch 667, Loss: 0.056631441053468734, Final Batch Loss: 0.00010809703962877393\n",
      "Epoch 668, Loss: 0.03259189540403895, Final Batch Loss: 0.008835205808281898\n",
      "Epoch 669, Loss: 0.03540312957557035, Final Batch Loss: 5.3895459132036194e-05\n",
      "Epoch 670, Loss: 0.012819126015529037, Final Batch Loss: 0.0003366918535903096\n",
      "Epoch 671, Loss: 0.03924466179887531, Final Batch Loss: 0.0003927920770365745\n",
      "Epoch 672, Loss: 0.014349916749779368, Final Batch Loss: 0.0006448259227909148\n",
      "Epoch 673, Loss: 0.013596123313618591, Final Batch Loss: 0.0011702841147780418\n",
      "Epoch 674, Loss: 0.0073682214751897845, Final Batch Loss: 0.0001394134305883199\n",
      "Epoch 675, Loss: 0.02409259692649357, Final Batch Loss: 0.0020308787934482098\n",
      "Epoch 676, Loss: 0.03122563991928473, Final Batch Loss: 0.0006012640660628676\n",
      "Epoch 677, Loss: 0.03436725235951599, Final Batch Loss: 0.0006357235251925886\n",
      "Epoch 678, Loss: 0.04919081552361604, Final Batch Loss: 0.000439940340584144\n",
      "Epoch 679, Loss: 0.018976031249621883, Final Batch Loss: 0.00030157281435094774\n",
      "Epoch 680, Loss: 0.042788091268448625, Final Batch Loss: 0.0005553420633077621\n",
      "Epoch 681, Loss: 0.020816024582018144, Final Batch Loss: 0.0003995525185018778\n",
      "Epoch 682, Loss: 0.015793247766850982, Final Batch Loss: 0.0001956439227797091\n",
      "Epoch 683, Loss: 0.021294125384883955, Final Batch Loss: 0.00026144017465412617\n",
      "Epoch 684, Loss: 0.009519937859295169, Final Batch Loss: 0.0004792747786268592\n",
      "Epoch 685, Loss: 0.026952188256473164, Final Batch Loss: 0.00016280818090308458\n",
      "Epoch 686, Loss: 0.031135997556702932, Final Batch Loss: 3.614018714870326e-05\n",
      "Epoch 687, Loss: 0.027948427574301604, Final Batch Loss: 0.002424523700028658\n",
      "Epoch 688, Loss: 0.06529988500551553, Final Batch Loss: 8.047894516494125e-05\n",
      "Epoch 689, Loss: 0.006851716250821482, Final Batch Loss: 9.256770863430575e-05\n",
      "Epoch 690, Loss: 0.04774172131874366, Final Batch Loss: 0.0011363397352397442\n",
      "Epoch 691, Loss: 0.054820171630126424, Final Batch Loss: 0.0010589930461719632\n",
      "Epoch 692, Loss: 0.03444435284473002, Final Batch Loss: 0.00016203195264097303\n",
      "Epoch 693, Loss: 0.021787298654089682, Final Batch Loss: 0.0005090951453894377\n",
      "Epoch 694, Loss: 0.021038962702732533, Final Batch Loss: 0.0001631227059988305\n",
      "Epoch 695, Loss: 0.009562400169670582, Final Batch Loss: 0.0019998308271169662\n",
      "Epoch 696, Loss: 0.019119208114716457, Final Batch Loss: 0.0002178233553422615\n",
      "Epoch 697, Loss: 0.036217562621459365, Final Batch Loss: 0.00040196545887738466\n",
      "Epoch 698, Loss: 0.017794741885154508, Final Batch Loss: 0.008798876777291298\n",
      "Epoch 699, Loss: 0.009703942618216388, Final Batch Loss: 0.002021497581154108\n",
      "Epoch 700, Loss: 0.010015286193265638, Final Batch Loss: 0.0015128052327781916\n",
      "Epoch 701, Loss: 0.07925089622222004, Final Batch Loss: 0.0004908611299470067\n",
      "Epoch 702, Loss: 0.01388620791840367, Final Batch Loss: 0.0007056025206111372\n",
      "Epoch 703, Loss: 0.011297497389023192, Final Batch Loss: 0.0002709418477024883\n",
      "Epoch 704, Loss: 0.01918859219404112, Final Batch Loss: 0.00022745311434846371\n",
      "Epoch 705, Loss: 0.02638412015949143, Final Batch Loss: 0.00024136988213285804\n",
      "Epoch 706, Loss: 0.04007370036561042, Final Batch Loss: 0.0009486495982855558\n",
      "Epoch 707, Loss: 0.0317588589132356, Final Batch Loss: 0.015917424112558365\n",
      "Epoch 708, Loss: 0.09702296457908233, Final Batch Loss: 0.0001879968331195414\n",
      "Epoch 709, Loss: 0.04336824710480869, Final Batch Loss: 0.006956649012863636\n",
      "Epoch 710, Loss: 0.02040701099031139, Final Batch Loss: 0.0007473971345461905\n",
      "Epoch 711, Loss: 0.008088742972176988, Final Batch Loss: 0.001495036412961781\n",
      "Epoch 712, Loss: 0.033657189982477576, Final Batch Loss: 0.0020621169824153185\n",
      "Epoch 713, Loss: 0.02552418175037019, Final Batch Loss: 0.00017018697690218687\n",
      "Epoch 714, Loss: 0.026601485820719972, Final Batch Loss: 0.010687356814742088\n",
      "Epoch 715, Loss: 0.023191026361018885, Final Batch Loss: 0.0001667225151322782\n",
      "Epoch 716, Loss: 0.022496511512144934, Final Batch Loss: 0.0014997996622696519\n",
      "Epoch 717, Loss: 0.014312212681033998, Final Batch Loss: 0.00023317342856898904\n",
      "Epoch 718, Loss: 0.01673491358087631, Final Batch Loss: 0.00044558660010807216\n",
      "Epoch 719, Loss: 0.07240539755730424, Final Batch Loss: 0.00026912835892289877\n",
      "Epoch 720, Loss: 0.01803453333559446, Final Batch Loss: 0.009137636050581932\n",
      "Epoch 721, Loss: 0.012117252939788159, Final Batch Loss: 0.0005658500012941658\n",
      "Epoch 722, Loss: 0.03248635918862419, Final Batch Loss: 0.00014016464410815388\n",
      "Epoch 723, Loss: 0.0223811986434157, Final Batch Loss: 0.0009967118967324495\n",
      "Epoch 724, Loss: 0.009172464022412896, Final Batch Loss: 2.5850869860732928e-05\n",
      "Epoch 725, Loss: 0.04327863675280241, Final Batch Loss: 0.02736845053732395\n",
      "Epoch 726, Loss: 0.055212753835803596, Final Batch Loss: 0.001002154080197215\n",
      "Epoch 727, Loss: 0.02570668564294465, Final Batch Loss: 0.0004269317432772368\n",
      "Epoch 728, Loss: 0.015334579122281866, Final Batch Loss: 0.00010288986231898889\n",
      "Epoch 729, Loss: 0.013447592085867655, Final Batch Loss: 0.0004082338127773255\n",
      "Epoch 730, Loss: 0.02452186775553855, Final Batch Loss: 0.0008905645809136331\n",
      "Epoch 731, Loss: 0.03435656654619379, Final Batch Loss: 0.018272943794727325\n",
      "Epoch 732, Loss: 0.018195867854956305, Final Batch Loss: 0.0015898705460131168\n",
      "Epoch 733, Loss: 0.027518320028320886, Final Batch Loss: 0.0006354975048452616\n",
      "Epoch 734, Loss: 0.034830777876777574, Final Batch Loss: 9.826319001149386e-05\n",
      "Epoch 735, Loss: 0.04278071073349565, Final Batch Loss: 0.002853960497304797\n",
      "Epoch 736, Loss: 0.015830819014809094, Final Batch Loss: 0.0002863762783817947\n",
      "Epoch 737, Loss: 0.00952921257703565, Final Batch Loss: 0.0003757009981200099\n",
      "Epoch 738, Loss: 0.016152972290001344, Final Batch Loss: 0.00012685811088886112\n",
      "Epoch 739, Loss: 0.008947550628363388, Final Batch Loss: 0.00015433736552949995\n",
      "Epoch 740, Loss: 0.020927847608618322, Final Batch Loss: 0.00011399966024328023\n",
      "Epoch 741, Loss: 0.028107180985898594, Final Batch Loss: 4.1893727029673755e-05\n",
      "Epoch 742, Loss: 0.00780104651403235, Final Batch Loss: 0.0023054953198879957\n",
      "Epoch 743, Loss: 0.015810783703273046, Final Batch Loss: 0.00038794841384515166\n",
      "Epoch 744, Loss: 0.07388621870268253, Final Batch Loss: 0.0019330168142914772\n",
      "Epoch 745, Loss: 0.03462274516823527, Final Batch Loss: 8.527194950147532e-06\n",
      "Epoch 746, Loss: 0.05160510302812327, Final Batch Loss: 0.00015823707508388907\n",
      "Epoch 747, Loss: 0.014339657864184119, Final Batch Loss: 0.0003430790384300053\n",
      "Epoch 748, Loss: 0.05541067786543863, Final Batch Loss: 0.0007395421271212399\n",
      "Epoch 749, Loss: 0.019053288357099518, Final Batch Loss: 0.00032188501791097224\n",
      "Epoch 750, Loss: 0.01021991509696818, Final Batch Loss: 0.0002756797184702009\n",
      "Epoch 751, Loss: 0.02125710286782123, Final Batch Loss: 6.697133358102292e-05\n",
      "Epoch 752, Loss: 0.008725444715310005, Final Batch Loss: 7.074540189933032e-05\n",
      "Epoch 753, Loss: 0.028805007961636875, Final Batch Loss: 0.013724999502301216\n",
      "Epoch 754, Loss: 0.13667906621776638, Final Batch Loss: 0.000893181364517659\n",
      "Epoch 755, Loss: 0.05483362017548643, Final Batch Loss: 0.0009615742019377649\n",
      "Epoch 756, Loss: 0.052814957343798596, Final Batch Loss: 0.00018441634892951697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757, Loss: 0.019989994500065222, Final Batch Loss: 0.0008196838898584247\n",
      "Epoch 758, Loss: 0.01827109430450946, Final Batch Loss: 0.0001892488799057901\n",
      "Epoch 759, Loss: 0.014835057416348718, Final Batch Loss: 6.314827624009922e-05\n",
      "Epoch 760, Loss: 0.03603623454546323, Final Batch Loss: 0.00032123998971655965\n",
      "Epoch 761, Loss: 0.03420378705050098, Final Batch Loss: 9.862755541689694e-05\n",
      "Epoch 762, Loss: 0.034002888092800276, Final Batch Loss: 0.0017680658493191004\n",
      "Epoch 763, Loss: 0.012034998573653866, Final Batch Loss: 9.050251537701115e-05\n",
      "Epoch 764, Loss: 0.033268256462179124, Final Batch Loss: 0.0012136072618886828\n",
      "Epoch 765, Loss: 0.03579754533711821, Final Batch Loss: 0.00016398871957790107\n",
      "Epoch 766, Loss: 0.03002484262106009, Final Batch Loss: 0.0003239736251998693\n",
      "Epoch 767, Loss: 0.031461841805139557, Final Batch Loss: 0.008878466673195362\n",
      "Epoch 768, Loss: 0.13494526442082133, Final Batch Loss: 0.0002809297584462911\n",
      "Epoch 769, Loss: 0.07733674949849956, Final Batch Loss: 0.011713857762515545\n",
      "Epoch 770, Loss: 0.12085083220154047, Final Batch Loss: 0.001940085319802165\n",
      "Epoch 771, Loss: 0.05700310967222322, Final Batch Loss: 0.012837518006563187\n",
      "Epoch 772, Loss: 0.048752933711512014, Final Batch Loss: 0.005687745753675699\n",
      "Epoch 773, Loss: 0.03999613109044731, Final Batch Loss: 0.0014560635900124907\n",
      "Epoch 774, Loss: 0.05544706215732731, Final Batch Loss: 0.011412509717047215\n",
      "Epoch 775, Loss: 0.013795396545901895, Final Batch Loss: 0.0004566532443277538\n",
      "Epoch 776, Loss: 0.046322841342771426, Final Batch Loss: 0.00024701730581000447\n",
      "Epoch 777, Loss: 0.09288579400163144, Final Batch Loss: 0.005249992944300175\n",
      "Epoch 778, Loss: 0.04304484187741764, Final Batch Loss: 0.0015477000270038843\n",
      "Epoch 779, Loss: 0.03445336617005523, Final Batch Loss: 0.0005029072635807097\n",
      "Epoch 780, Loss: 0.019331454037455842, Final Batch Loss: 0.004028727766126394\n",
      "Epoch 781, Loss: 0.017729828075971454, Final Batch Loss: 0.00017444504192098975\n",
      "Epoch 782, Loss: 0.023517649999121204, Final Batch Loss: 0.0006346192676573992\n",
      "Epoch 783, Loss: 0.00569032025305205, Final Batch Loss: 9.001833677757531e-05\n",
      "Epoch 784, Loss: 0.005046942205808591, Final Batch Loss: 4.904151865048334e-05\n",
      "Epoch 785, Loss: 0.036963067561373464, Final Batch Loss: 0.0072035095654428005\n",
      "Epoch 786, Loss: 0.038379181671189144, Final Batch Loss: 0.016074104234576225\n",
      "Epoch 787, Loss: 0.027419948572060093, Final Batch Loss: 0.0017970589688047767\n",
      "Epoch 788, Loss: 0.010163783656025771, Final Batch Loss: 0.00013632130867335945\n",
      "Epoch 789, Loss: 0.00824850609205896, Final Batch Loss: 0.0003176978207193315\n",
      "Epoch 790, Loss: 0.014788107400818262, Final Batch Loss: 0.002268731826916337\n",
      "Epoch 791, Loss: 0.03156098418185138, Final Batch Loss: 4.313796307542361e-05\n",
      "Epoch 792, Loss: 0.015978250186890364, Final Batch Loss: 0.00018290028674528003\n",
      "Epoch 793, Loss: 0.01816283671723795, Final Batch Loss: 0.0019352925010025501\n",
      "Epoch 794, Loss: 0.029169070032367017, Final Batch Loss: 0.01451729703694582\n",
      "Epoch 795, Loss: 0.08863158142776228, Final Batch Loss: 0.0003229263820685446\n",
      "Epoch 796, Loss: 0.04148532084218459, Final Batch Loss: 0.027102526277303696\n",
      "Epoch 797, Loss: 0.05005231124960119, Final Batch Loss: 0.0003576129674911499\n",
      "Epoch 798, Loss: 0.014191240232321434, Final Batch Loss: 0.0018601970514282584\n",
      "Epoch 799, Loss: 0.0142706034675939, Final Batch Loss: 0.0012140178587287664\n",
      "Epoch 800, Loss: 0.020664550494984724, Final Batch Loss: 0.0010113741736859083\n",
      "Epoch 801, Loss: 0.009275386309127498, Final Batch Loss: 0.0004453426809050143\n",
      "Epoch 802, Loss: 0.036269658703531604, Final Batch Loss: 0.001615542103536427\n",
      "Epoch 803, Loss: 0.0630741195527662, Final Batch Loss: 7.243787695188075e-05\n",
      "Epoch 804, Loss: 0.05212763822055422, Final Batch Loss: 0.008128480985760689\n",
      "Epoch 805, Loss: 0.006176895025419071, Final Batch Loss: 0.00017437321366742253\n",
      "Epoch 806, Loss: 0.013806295581161976, Final Batch Loss: 9.81455814326182e-05\n",
      "Epoch 807, Loss: 0.013836009791702963, Final Batch Loss: 0.0003087600052822381\n",
      "Epoch 808, Loss: 0.008864727293257602, Final Batch Loss: 0.0012923387112095952\n",
      "Epoch 809, Loss: 0.0062864241808711085, Final Batch Loss: 9.710437734611332e-05\n",
      "Epoch 810, Loss: 0.012643536072573625, Final Batch Loss: 0.0005321440985426307\n",
      "Epoch 811, Loss: 0.021564560644037556, Final Batch Loss: 0.0001324953482253477\n",
      "Epoch 812, Loss: 0.003841095587631571, Final Batch Loss: 0.0005430933088064194\n",
      "Epoch 813, Loss: 0.04351512228822685, Final Batch Loss: 0.00010304261377314106\n",
      "Epoch 814, Loss: 0.06384456307205255, Final Batch Loss: 0.008109685964882374\n",
      "Epoch 815, Loss: 0.10232647080192692, Final Batch Loss: 0.005822543986141682\n",
      "Epoch 816, Loss: 0.02364869614757481, Final Batch Loss: 0.0004006312519777566\n",
      "Epoch 817, Loss: 0.02802481006074231, Final Batch Loss: 0.000507280754391104\n",
      "Epoch 818, Loss: 0.006994456525717396, Final Batch Loss: 0.00015018413250800222\n",
      "Epoch 819, Loss: 0.025121192025835626, Final Batch Loss: 0.013116258196532726\n",
      "Epoch 820, Loss: 0.012589924495841842, Final Batch Loss: 0.0004876577004324645\n",
      "Epoch 821, Loss: 0.02396593993762508, Final Batch Loss: 0.00015536817954853177\n",
      "Epoch 822, Loss: 0.007473554771422641, Final Batch Loss: 0.0004522560629993677\n",
      "Epoch 823, Loss: 0.008090146540780552, Final Batch Loss: 3.518292214721441e-05\n",
      "Epoch 824, Loss: 0.020001664730443736, Final Batch Loss: 6.271235906751826e-05\n",
      "Epoch 825, Loss: 0.017204232441144995, Final Batch Loss: 8.76920748851262e-05\n",
      "Epoch 826, Loss: 0.03266965798320598, Final Batch Loss: 5.9253692597849295e-05\n",
      "Epoch 827, Loss: 0.044644648623943795, Final Batch Loss: 3.636780456872657e-05\n",
      "Epoch 828, Loss: 0.008038711137487553, Final Batch Loss: 0.0009760746033862233\n",
      "Epoch 829, Loss: 0.014225771104975138, Final Batch Loss: 7.433669088641182e-05\n",
      "Epoch 830, Loss: 0.017574697954842122, Final Batch Loss: 0.0005889473832212389\n",
      "Epoch 831, Loss: 0.011796303104347317, Final Batch Loss: 0.00014848590944893658\n",
      "Epoch 832, Loss: 0.009610686578525929, Final Batch Loss: 0.00351295480504632\n",
      "Epoch 833, Loss: 0.008313805861689616, Final Batch Loss: 0.0002631078823469579\n",
      "Epoch 834, Loss: 0.02792510842482443, Final Batch Loss: 3.3446769521106035e-05\n",
      "Epoch 835, Loss: 0.006259765382310434, Final Batch Loss: 3.745173307834193e-05\n",
      "Epoch 836, Loss: 0.019106170248051058, Final Batch Loss: 0.0004992084577679634\n",
      "Epoch 837, Loss: 0.004812170245713787, Final Batch Loss: 2.1359828679123893e-05\n",
      "Epoch 838, Loss: 0.012778687188983895, Final Batch Loss: 0.0003474916738923639\n",
      "Epoch 839, Loss: 0.0052799693221459165, Final Batch Loss: 0.0009646948892623186\n",
      "Epoch 840, Loss: 0.004611571141140303, Final Batch Loss: 4.8259822506224737e-05\n",
      "Epoch 841, Loss: 0.02061558735476865, Final Batch Loss: 0.014615202322602272\n",
      "Epoch 842, Loss: 0.029311736866475258, Final Batch Loss: 7.652975182281807e-05\n",
      "Epoch 843, Loss: 0.03255510273447726, Final Batch Loss: 0.00014064244169276208\n",
      "Epoch 844, Loss: 0.03265312155599531, Final Batch Loss: 0.0008414495969191194\n",
      "Epoch 845, Loss: 0.05870431299263146, Final Batch Loss: 0.006066311150789261\n",
      "Epoch 846, Loss: 0.06998764106538147, Final Batch Loss: 0.0012629278935492039\n",
      "Epoch 847, Loss: 0.014602902228944004, Final Batch Loss: 0.001302728895097971\n",
      "Epoch 848, Loss: 0.009454428378376178, Final Batch Loss: 0.00013055946328677237\n",
      "Epoch 849, Loss: 0.004496647306950763, Final Batch Loss: 0.0003855043323710561\n",
      "Epoch 850, Loss: 0.03921538444410544, Final Batch Loss: 0.0018145771464332938\n",
      "Epoch 851, Loss: 0.005948522004473489, Final Batch Loss: 0.0008335051243193448\n",
      "Epoch 852, Loss: 0.026271634760632878, Final Batch Loss: 0.0011023215483874083\n",
      "Epoch 853, Loss: 0.0904122003212251, Final Batch Loss: 0.01973302848637104\n",
      "Epoch 854, Loss: 0.08040808299119817, Final Batch Loss: 0.004720459226518869\n",
      "Epoch 855, Loss: 0.07310873043752508, Final Batch Loss: 0.0008543152362108231\n",
      "Epoch 856, Loss: 0.025545716995111434, Final Batch Loss: 0.010251549072563648\n",
      "Epoch 857, Loss: 0.025337822480651084, Final Batch Loss: 0.0005930984625592828\n",
      "Epoch 858, Loss: 0.020259602837541024, Final Batch Loss: 6.653358286712319e-05\n",
      "Epoch 859, Loss: 0.02057875141781551, Final Batch Loss: 0.0009286561398766935\n",
      "Epoch 860, Loss: 0.05151564214975224, Final Batch Loss: 0.00015538017032667994\n",
      "Epoch 861, Loss: 0.013441494855214842, Final Batch Loss: 0.0006349348113872111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862, Loss: 0.1482174263583147, Final Batch Loss: 0.00030784140108153224\n",
      "Epoch 863, Loss: 0.01475046256382484, Final Batch Loss: 9.464895265409723e-05\n",
      "Epoch 864, Loss: 0.03465605130622862, Final Batch Loss: 0.0006316303042694926\n",
      "Epoch 865, Loss: 0.004847209111176198, Final Batch Loss: 0.0005261222831904888\n",
      "Epoch 866, Loss: 0.027937680308241397, Final Batch Loss: 0.0012289879377931356\n",
      "Epoch 867, Loss: 0.01956069354491774, Final Batch Loss: 0.00961651187390089\n",
      "Epoch 868, Loss: 0.06310955788285355, Final Batch Loss: 0.0006241953233256936\n",
      "Epoch 869, Loss: 0.021431481407489628, Final Batch Loss: 0.007558375597000122\n",
      "Epoch 870, Loss: 0.01018948491946503, Final Batch Loss: 0.0009765899740159512\n",
      "Epoch 871, Loss: 0.01107818350646994, Final Batch Loss: 0.00019514378800522536\n",
      "Epoch 872, Loss: 0.02121402793818561, Final Batch Loss: 0.009719155728816986\n",
      "Epoch 873, Loss: 0.03421559332218749, Final Batch Loss: 0.022276923060417175\n",
      "Epoch 874, Loss: 0.03617016281532415, Final Batch Loss: 0.00036909428308717906\n",
      "Epoch 875, Loss: 0.058872360314126126, Final Batch Loss: 0.00022368787904269993\n",
      "Epoch 876, Loss: 0.0729637683252804, Final Batch Loss: 0.006326168309897184\n",
      "Epoch 877, Loss: 0.0606672286594403, Final Batch Loss: 0.0049867709167301655\n",
      "Epoch 878, Loss: 0.01636309081368381, Final Batch Loss: 0.0008615077240392566\n",
      "Epoch 879, Loss: 0.016468193622131366, Final Batch Loss: 0.00043202718370594084\n",
      "Epoch 880, Loss: 0.03257493716046156, Final Batch Loss: 0.0005020826356485486\n",
      "Epoch 881, Loss: 0.004386913429698325, Final Batch Loss: 0.0002202283649239689\n",
      "Epoch 882, Loss: 0.013123089302098379, Final Batch Loss: 0.00017266810755245388\n",
      "Epoch 883, Loss: 0.007655325016457937, Final Batch Loss: 0.0002898331149481237\n",
      "Epoch 884, Loss: 0.009621126773708966, Final Batch Loss: 0.000404759484808892\n",
      "Epoch 885, Loss: 0.02119855542332516, Final Batch Loss: 0.015828674659132957\n",
      "Epoch 886, Loss: 0.030197488522389904, Final Batch Loss: 0.0001257544063264504\n",
      "Epoch 887, Loss: 0.014232521643862128, Final Batch Loss: 0.0013591243186965585\n",
      "Epoch 888, Loss: 0.005417379681603052, Final Batch Loss: 0.00023826697724871337\n",
      "Epoch 889, Loss: 0.015357187632616842, Final Batch Loss: 0.00015846500173211098\n",
      "Epoch 890, Loss: 0.009214404210069915, Final Batch Loss: 9.747677540872246e-05\n",
      "Epoch 891, Loss: 0.03446078719571233, Final Batch Loss: 0.0016345828771591187\n",
      "Epoch 892, Loss: 0.06402717747550923, Final Batch Loss: 0.0002075764787150547\n",
      "Epoch 893, Loss: 0.03215745497800526, Final Batch Loss: 0.00015571278345305473\n",
      "Epoch 894, Loss: 0.014800741384533467, Final Batch Loss: 0.00025444067432545125\n",
      "Epoch 895, Loss: 0.018863697503547883, Final Batch Loss: 0.00010528506390983239\n",
      "Epoch 896, Loss: 0.025426105015867506, Final Batch Loss: 0.00018114113481715322\n",
      "Epoch 897, Loss: 0.007410844871628797, Final Batch Loss: 0.00021860901324544102\n",
      "Epoch 898, Loss: 0.02015307793408283, Final Batch Loss: 0.00014781008940190077\n",
      "Epoch 899, Loss: 0.0317308325884369, Final Batch Loss: 0.00016326768673025072\n",
      "Epoch 900, Loss: 0.012704166965704644, Final Batch Loss: 0.0001584790152264759\n",
      "Epoch 901, Loss: 0.009423534029338043, Final Batch Loss: 0.00028344261227175593\n",
      "Epoch 902, Loss: 0.03468963332124986, Final Batch Loss: 0.0006504225893877447\n",
      "Epoch 903, Loss: 0.007131513160857139, Final Batch Loss: 0.0014464008854702115\n",
      "Epoch 904, Loss: 0.022628902977885446, Final Batch Loss: 0.0002343408268643543\n",
      "Epoch 905, Loss: 0.026278435972926673, Final Batch Loss: 0.0009103582124225795\n",
      "Epoch 906, Loss: 0.013020891710766591, Final Batch Loss: 9.837457037065178e-05\n",
      "Epoch 907, Loss: 0.04032978594477754, Final Batch Loss: 0.0008307170937769115\n",
      "Epoch 908, Loss: 0.030550884068361484, Final Batch Loss: 0.018710849806666374\n",
      "Epoch 909, Loss: 0.011433614177803975, Final Batch Loss: 0.0009522855398245156\n",
      "Epoch 910, Loss: 0.018896915527875535, Final Batch Loss: 0.0037929012905806303\n",
      "Epoch 911, Loss: 0.011108623608379276, Final Batch Loss: 0.00020354421576485038\n",
      "Epoch 912, Loss: 0.04814431085833348, Final Batch Loss: 0.00020954936917405576\n",
      "Epoch 913, Loss: 0.019150361855281517, Final Batch Loss: 0.00033864559372887015\n",
      "Epoch 914, Loss: 0.04744143201969564, Final Batch Loss: 0.0001870547712314874\n",
      "Epoch 915, Loss: 0.0142602927153348, Final Batch Loss: 0.0003928513906430453\n",
      "Epoch 916, Loss: 0.024897502291423734, Final Batch Loss: 8.148545020958409e-05\n",
      "Epoch 917, Loss: 0.025126785380052752, Final Batch Loss: 0.0010993860196322203\n",
      "Epoch 918, Loss: 0.050634517370781396, Final Batch Loss: 0.000399377488065511\n",
      "Epoch 919, Loss: 0.017813917685998604, Final Batch Loss: 6.91028981236741e-05\n",
      "Epoch 920, Loss: 0.009965197124984115, Final Batch Loss: 0.00014892783656250685\n",
      "Epoch 921, Loss: 0.07703809630766045, Final Batch Loss: 0.00034078946919180453\n",
      "Epoch 922, Loss: 0.03733315845602192, Final Batch Loss: 0.0001360279566142708\n",
      "Epoch 923, Loss: 0.013098528586851899, Final Batch Loss: 0.00010709706839406863\n",
      "Epoch 924, Loss: 0.042470370048249606, Final Batch Loss: 0.0008349589770659804\n",
      "Epoch 925, Loss: 0.006435415634769015, Final Batch Loss: 9.192040306515992e-05\n",
      "Epoch 926, Loss: 0.0052021472656633705, Final Batch Loss: 0.0002094325900543481\n",
      "Epoch 927, Loss: 0.0076601154232776025, Final Batch Loss: 2.857503386621829e-05\n",
      "Epoch 928, Loss: 0.011657098889372719, Final Batch Loss: 9.590539775672369e-06\n",
      "Epoch 929, Loss: 0.004541962334769778, Final Batch Loss: 8.526677993359044e-05\n",
      "Epoch 930, Loss: 0.006082145897380542, Final Batch Loss: 0.0005517942481674254\n",
      "Epoch 931, Loss: 0.003642405798927939, Final Batch Loss: 0.0004854162398260087\n",
      "Epoch 932, Loss: 0.011569131740543526, Final Batch Loss: 0.0006194243906065822\n",
      "Epoch 933, Loss: 0.026854156729314127, Final Batch Loss: 8.678477024659514e-05\n",
      "Epoch 934, Loss: 0.02346128557837801, Final Batch Loss: 0.00028074911097064614\n",
      "Epoch 935, Loss: 0.04767432657899917, Final Batch Loss: 0.00042532934457995\n",
      "Epoch 936, Loss: 0.03609665605472401, Final Batch Loss: 0.0002973601222038269\n",
      "Epoch 937, Loss: 0.023289147233299445, Final Batch Loss: 0.0009851710638031363\n",
      "Epoch 938, Loss: 0.007029041316855, Final Batch Loss: 0.0001221541315317154\n",
      "Epoch 939, Loss: 0.030018885729077738, Final Batch Loss: 0.0041516246274113655\n",
      "Epoch 940, Loss: 0.01961588379344903, Final Batch Loss: 0.01394029799848795\n",
      "Epoch 941, Loss: 0.016382676956709474, Final Batch Loss: 0.001576577895320952\n",
      "Epoch 942, Loss: 0.04437371710901061, Final Batch Loss: 0.00032804906368255615\n",
      "Epoch 943, Loss: 0.036684382994280895, Final Batch Loss: 0.0002975909155793488\n",
      "Epoch 944, Loss: 0.013002052222873317, Final Batch Loss: 0.0005452499608509243\n",
      "Epoch 945, Loss: 0.012931606022902997, Final Batch Loss: 0.006205226294696331\n",
      "Epoch 946, Loss: 0.02771247862256132, Final Batch Loss: 0.0004047867259941995\n",
      "Epoch 947, Loss: 0.007164760958403349, Final Batch Loss: 3.79413650080096e-05\n",
      "Epoch 948, Loss: 0.023747189776258892, Final Batch Loss: 1.9203927877242677e-05\n",
      "Epoch 949, Loss: 0.02731572113225411, Final Batch Loss: 0.00029348742100410163\n",
      "Epoch 950, Loss: 0.007869897572163609, Final Batch Loss: 3.6085093597648665e-05\n",
      "Epoch 951, Loss: 0.02186860377605626, Final Batch Loss: 0.00036946043837815523\n",
      "Epoch 952, Loss: 0.00451314332713082, Final Batch Loss: 7.241083221742883e-05\n",
      "Epoch 953, Loss: 0.01984058504604036, Final Batch Loss: 8.017306390684098e-05\n",
      "Epoch 954, Loss: 0.006572785172465956, Final Batch Loss: 0.0004633368516806513\n",
      "Epoch 955, Loss: 0.033313447904220084, Final Batch Loss: 0.0007971078739501536\n",
      "Epoch 956, Loss: 0.026592948343022726, Final Batch Loss: 0.00011955529771512374\n",
      "Epoch 957, Loss: 0.004399169432872441, Final Batch Loss: 0.00015245199028868228\n",
      "Epoch 958, Loss: 0.041539673919032793, Final Batch Loss: 0.0007038642070256174\n",
      "Epoch 959, Loss: 0.012458412980777211, Final Batch Loss: 0.007510419934988022\n",
      "Epoch 960, Loss: 0.029192398749728454, Final Batch Loss: 0.0011873604962602258\n",
      "Epoch 961, Loss: 0.018065927863062825, Final Batch Loss: 7.54642896936275e-05\n",
      "Epoch 962, Loss: 0.07978540536714718, Final Batch Loss: 0.0001769781665643677\n",
      "Epoch 963, Loss: 0.021054632001323625, Final Batch Loss: 0.00037804999738000333\n",
      "Epoch 964, Loss: 0.06118425255044713, Final Batch Loss: 0.0008141351281665266\n",
      "Epoch 965, Loss: 0.044298708642600104, Final Batch Loss: 0.001074002357199788\n",
      "Epoch 966, Loss: 0.009959196278941818, Final Batch Loss: 9.046420018421486e-05\n",
      "Epoch 967, Loss: 0.017756569392076926, Final Batch Loss: 0.0013316902332007885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968, Loss: 0.011287312918284442, Final Batch Loss: 6.179790943861008e-05\n",
      "Epoch 969, Loss: 0.03376999974352657, Final Batch Loss: 0.0013397068250924349\n",
      "Epoch 970, Loss: 0.10139005963719683, Final Batch Loss: 0.0004028395633213222\n",
      "Epoch 971, Loss: 0.02809750798769528, Final Batch Loss: 0.0006947555812075734\n",
      "Epoch 972, Loss: 0.008234305878431769, Final Batch Loss: 0.00037247425643727183\n",
      "Epoch 973, Loss: 0.016598927482846193, Final Batch Loss: 0.0002069048205157742\n",
      "Epoch 974, Loss: 0.007029913602309534, Final Batch Loss: 0.00015293032629415393\n",
      "Epoch 975, Loss: 0.02266763413717854, Final Batch Loss: 0.001375838415697217\n",
      "Epoch 976, Loss: 0.007316655392060056, Final Batch Loss: 4.123096005059779e-05\n",
      "Epoch 977, Loss: 0.06631999601086136, Final Batch Loss: 0.02506987936794758\n",
      "Epoch 978, Loss: 0.005126721094711684, Final Batch Loss: 0.00029017613269388676\n",
      "Epoch 979, Loss: 0.010663175649824552, Final Batch Loss: 0.00010171560279559344\n",
      "Epoch 980, Loss: 0.019066713357460685, Final Batch Loss: 0.0005014374037273228\n",
      "Epoch 981, Loss: 0.0461398549414298, Final Batch Loss: 7.004251528996974e-05\n",
      "Epoch 982, Loss: 0.013623099184769671, Final Batch Loss: 0.00011636276030912995\n",
      "Epoch 983, Loss: 0.013015121941862162, Final Batch Loss: 0.0004802678886335343\n",
      "Epoch 984, Loss: 0.00496485278927139, Final Batch Loss: 4.986798012396321e-05\n",
      "Epoch 985, Loss: 0.00660415527454461, Final Batch Loss: 0.00010774872498586774\n",
      "Epoch 986, Loss: 0.011292430722278368, Final Batch Loss: 0.00011374150199117139\n",
      "Epoch 987, Loss: 0.008312297821248649, Final Batch Loss: 0.0007022934150882065\n",
      "Epoch 988, Loss: 0.007474925727365189, Final Batch Loss: 3.357654713909142e-05\n",
      "Epoch 989, Loss: 0.03648858396536525, Final Batch Loss: 0.00014986435417085886\n",
      "Epoch 990, Loss: 0.008728496406547492, Final Batch Loss: 0.0004026225069537759\n",
      "Epoch 991, Loss: 0.004290931105060736, Final Batch Loss: 0.0006527749355882406\n",
      "Epoch 992, Loss: 0.01831479988140927, Final Batch Loss: 0.00033950930810533464\n",
      "Epoch 993, Loss: 0.01925914805906359, Final Batch Loss: 0.0004295736434869468\n",
      "Epoch 994, Loss: 0.021758768772997428, Final Batch Loss: 0.0003441162989474833\n",
      "Epoch 995, Loss: 0.026911991682936787, Final Batch Loss: 3.694647966767661e-05\n",
      "Epoch 996, Loss: 0.012440247599442955, Final Batch Loss: 0.0002685020153876394\n",
      "Epoch 997, Loss: 0.00454908105530194, Final Batch Loss: 0.00043580704368650913\n",
      "Epoch 998, Loss: 0.00827263735118322, Final Batch Loss: 0.0027593171689659357\n",
      "Epoch 999, Loss: 0.016420498201114242, Final Batch Loss: 0.0006781031261198223\n",
      "Epoch 1000, Loss: 0.04636806190501375, Final Batch Loss: 0.033958714455366135\n",
      "Epoch 1001, Loss: 0.05118123544525588, Final Batch Loss: 0.0004177515802439302\n",
      "Epoch 1002, Loss: 0.06393419791129418, Final Batch Loss: 0.0018975044367834926\n",
      "Epoch 1003, Loss: 0.08066020699880028, Final Batch Loss: 2.4126091375364922e-05\n",
      "Epoch 1004, Loss: 0.01725536282901885, Final Batch Loss: 0.0045242952182888985\n",
      "Epoch 1005, Loss: 0.04111015033413423, Final Batch Loss: 0.006179289426654577\n",
      "Epoch 1006, Loss: 0.09770797554756427, Final Batch Loss: 0.00017756903253030032\n",
      "Epoch 1007, Loss: 0.028762948779331055, Final Batch Loss: 0.0009106327779591084\n",
      "Epoch 1008, Loss: 0.027340110513250693, Final Batch Loss: 7.09260712028481e-05\n",
      "Epoch 1009, Loss: 0.04687578330049291, Final Batch Loss: 0.0001991492317756638\n",
      "Epoch 1010, Loss: 0.024562355516536627, Final Batch Loss: 0.00010904256487265229\n",
      "Epoch 1011, Loss: 0.06300551915774122, Final Batch Loss: 0.0002352624578634277\n",
      "Epoch 1012, Loss: 0.023596886778250337, Final Batch Loss: 0.00030468852492049336\n",
      "Epoch 1013, Loss: 0.006234404436327168, Final Batch Loss: 0.0006285043200477958\n",
      "Epoch 1014, Loss: 0.009839882606684114, Final Batch Loss: 0.0004912684671580791\n",
      "Epoch 1015, Loss: 0.00971886322076898, Final Batch Loss: 0.00014416339399758726\n",
      "Epoch 1016, Loss: 0.011178964648934198, Final Batch Loss: 8.569374040234834e-05\n",
      "Epoch 1017, Loss: 0.02620921679044841, Final Batch Loss: 0.00015186356904450804\n",
      "Epoch 1018, Loss: 0.022607804647122975, Final Batch Loss: 2.3132211936172098e-05\n",
      "Epoch 1019, Loss: 0.030660716649435926, Final Batch Loss: 0.0005409806617535651\n",
      "Epoch 1020, Loss: 0.04841096989548532, Final Batch Loss: 0.0005166560295037925\n",
      "Epoch 1021, Loss: 0.009628987791074906, Final Batch Loss: 0.00018167312373407185\n",
      "Epoch 1022, Loss: 0.00889236842340324, Final Batch Loss: 0.00020487603615038097\n",
      "Epoch 1023, Loss: 0.023924462468130514, Final Batch Loss: 0.0009436533437110484\n",
      "Epoch 1024, Loss: 0.009210939446347766, Final Batch Loss: 0.0009190737619064748\n",
      "Epoch 1025, Loss: 0.010797017290315125, Final Batch Loss: 0.00020809324632864445\n",
      "Epoch 1026, Loss: 0.013534003141103312, Final Batch Loss: 0.00022864398488309234\n",
      "Epoch 1027, Loss: 0.010573269571978017, Final Batch Loss: 0.0001138918159995228\n",
      "Epoch 1028, Loss: 0.005637543566990644, Final Batch Loss: 9.179837798001245e-05\n",
      "Epoch 1029, Loss: 0.0059732258996518794, Final Batch Loss: 8.208649524021894e-05\n",
      "Epoch 1030, Loss: 0.006423273936889018, Final Batch Loss: 0.00010984607797581702\n",
      "Epoch 1031, Loss: 0.07627308857627213, Final Batch Loss: 0.011156989261507988\n",
      "Epoch 1032, Loss: 0.011222564218769548, Final Batch Loss: 8.745020750211552e-05\n",
      "Epoch 1033, Loss: 0.00838457607824239, Final Batch Loss: 0.00022235076176002622\n",
      "Epoch 1034, Loss: 0.02804240246587142, Final Batch Loss: 0.001417552470229566\n",
      "Epoch 1035, Loss: 0.01724284554074984, Final Batch Loss: 0.0006274129264056683\n",
      "Epoch 1036, Loss: 0.026252391984598944, Final Batch Loss: 0.004325837828218937\n",
      "Epoch 1037, Loss: 0.02756694340678223, Final Batch Loss: 5.9302950830897316e-05\n",
      "Epoch 1038, Loss: 0.007527449030021671, Final Batch Loss: 0.0006271791062317789\n",
      "Epoch 1039, Loss: 0.039217725632624933, Final Batch Loss: 0.006593767087906599\n",
      "Epoch 1040, Loss: 0.025170080785756, Final Batch Loss: 0.00016089492419268936\n",
      "Epoch 1041, Loss: 0.008316263691995118, Final Batch Loss: 0.000420729978941381\n",
      "Epoch 1042, Loss: 0.024925666100898525, Final Batch Loss: 7.693524821661413e-05\n",
      "Epoch 1043, Loss: 0.007071051556522434, Final Batch Loss: 0.0001137147264671512\n",
      "Epoch 1044, Loss: 0.008285541502118576, Final Batch Loss: 2.056648736470379e-05\n",
      "Epoch 1045, Loss: 0.008985746988400933, Final Batch Loss: 0.00047271695802919567\n",
      "Epoch 1046, Loss: 0.004316619779274333, Final Batch Loss: 5.1540439017117023e-05\n",
      "Epoch 1047, Loss: 0.006167315703351051, Final Batch Loss: 0.000403361686039716\n",
      "Epoch 1048, Loss: 0.0042781170068337815, Final Batch Loss: 5.5133150453912094e-05\n",
      "Epoch 1049, Loss: 0.01761290997183096, Final Batch Loss: 0.000430684449383989\n",
      "Epoch 1050, Loss: 0.03892765723321645, Final Batch Loss: 0.00011445947166066617\n",
      "Epoch 1051, Loss: 0.013984153859382786, Final Batch Loss: 0.00010727487824624404\n",
      "Epoch 1052, Loss: 0.017577241835169843, Final Batch Loss: 3.6378231015987694e-05\n",
      "Epoch 1053, Loss: 0.010061298478831304, Final Batch Loss: 0.00022818367870058864\n",
      "Epoch 1054, Loss: 0.03941120160743594, Final Batch Loss: 6.761624536011368e-05\n",
      "Epoch 1055, Loss: 0.0114353714416211, Final Batch Loss: 0.00024704611860215664\n",
      "Epoch 1056, Loss: 0.007674488806515001, Final Batch Loss: 0.0016948272241279483\n",
      "Epoch 1057, Loss: 0.02185692601960909, Final Batch Loss: 0.00023463596880901605\n",
      "Epoch 1058, Loss: 0.01065688473136106, Final Batch Loss: 0.001276615890674293\n",
      "Epoch 1059, Loss: 0.014169360017604049, Final Batch Loss: 0.0006163711659610271\n",
      "Epoch 1060, Loss: 0.007109494390533655, Final Batch Loss: 1.904828241094947e-05\n",
      "Epoch 1061, Loss: 0.05840002945296874, Final Batch Loss: 3.766734880628064e-05\n",
      "Epoch 1062, Loss: 0.021494342781807063, Final Batch Loss: 0.0011953915236517787\n",
      "Epoch 1063, Loss: 0.0853095588083761, Final Batch Loss: 0.000245240778895095\n",
      "Epoch 1064, Loss: 0.13338474332158512, Final Batch Loss: 0.006238841917365789\n",
      "Epoch 1065, Loss: 0.02170761195884552, Final Batch Loss: 0.001217150827869773\n",
      "Epoch 1066, Loss: 0.027943879569647834, Final Batch Loss: 0.0001627349847694859\n",
      "Epoch 1067, Loss: 0.022726103306922596, Final Batch Loss: 0.005410792771726847\n",
      "Epoch 1068, Loss: 0.03640772728249431, Final Batch Loss: 0.0004803796182386577\n",
      "Epoch 1069, Loss: 0.0515001519524958, Final Batch Loss: 0.006324210669845343\n",
      "Epoch 1070, Loss: 0.027942277629335877, Final Batch Loss: 0.0015057133277878165\n",
      "Epoch 1071, Loss: 0.013269011862576008, Final Batch Loss: 0.0005781381041742861\n",
      "Epoch 1072, Loss: 0.007743342432149802, Final Batch Loss: 0.0001506580738350749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1073, Loss: 0.0072813842289178865, Final Batch Loss: 0.00010611475590849295\n",
      "Epoch 1074, Loss: 0.003487658999802079, Final Batch Loss: 8.032157347770408e-05\n",
      "Epoch 1075, Loss: 0.09836137185993721, Final Batch Loss: 0.0002903523272834718\n",
      "Epoch 1076, Loss: 0.013860382092389045, Final Batch Loss: 0.00032690053922124207\n",
      "Epoch 1077, Loss: 0.003243681456297054, Final Batch Loss: 0.0002461140393279493\n",
      "Epoch 1078, Loss: 0.0047541836761411105, Final Batch Loss: 6.968967227294343e-06\n",
      "Epoch 1079, Loss: 0.004906412598757015, Final Batch Loss: 0.0004645639273803681\n",
      "Epoch 1080, Loss: 0.009814435807129485, Final Batch Loss: 0.00010886685777222738\n",
      "Epoch 1081, Loss: 0.04889692710003146, Final Batch Loss: 0.00047718329005874693\n",
      "Epoch 1082, Loss: 0.00658401185501134, Final Batch Loss: 0.0019274960504844785\n",
      "Epoch 1083, Loss: 0.013721054390771315, Final Batch Loss: 8.768473344389349e-05\n",
      "Epoch 1084, Loss: 0.0064875937496253755, Final Batch Loss: 0.0005518363905139267\n",
      "Epoch 1085, Loss: 0.008199602169042919, Final Batch Loss: 3.1073061109054834e-05\n",
      "Epoch 1086, Loss: 0.014259484927606536, Final Batch Loss: 0.0006893780664540827\n",
      "Epoch 1087, Loss: 0.031494570976065006, Final Batch Loss: 0.0002874617057386786\n",
      "Epoch 1088, Loss: 0.004178689653144829, Final Batch Loss: 0.00017949639004655182\n",
      "Epoch 1089, Loss: 0.006000223458613618, Final Batch Loss: 5.397673521656543e-05\n",
      "Epoch 1090, Loss: 0.009627458555769408, Final Batch Loss: 0.0052014924585819244\n",
      "Epoch 1091, Loss: 0.010077803546664654, Final Batch Loss: 0.00014447540161199868\n",
      "Epoch 1092, Loss: 0.009871970658423379, Final Batch Loss: 0.00015004539454821497\n",
      "Epoch 1093, Loss: 0.08130747048062403, Final Batch Loss: 4.2698197830759455e-06\n",
      "Epoch 1094, Loss: 0.05192824062760337, Final Batch Loss: 0.009419804438948631\n",
      "Epoch 1095, Loss: 0.02172352544948808, Final Batch Loss: 0.007137613371014595\n",
      "Epoch 1096, Loss: 0.009278304525651038, Final Batch Loss: 0.0001490483118686825\n",
      "Epoch 1097, Loss: 0.006917538084962871, Final Batch Loss: 0.00022703036665916443\n",
      "Epoch 1098, Loss: 0.007462450124876341, Final Batch Loss: 0.00020748972019646317\n",
      "Epoch 1099, Loss: 0.005171532520762412, Final Batch Loss: 9.148688695859164e-05\n",
      "Epoch 1100, Loss: 0.03981855101665133, Final Batch Loss: 0.0003778123646043241\n",
      "Epoch 1101, Loss: 0.008198208735848311, Final Batch Loss: 0.0002518245892133564\n",
      "Epoch 1102, Loss: 0.026877120981225744, Final Batch Loss: 0.0005288457032293081\n",
      "Epoch 1103, Loss: 0.008325807120854734, Final Batch Loss: 0.0015561615582555532\n",
      "Epoch 1104, Loss: 0.0028216210375830997, Final Batch Loss: 8.275718573713675e-05\n",
      "Epoch 1105, Loss: 0.023249692811987188, Final Batch Loss: 0.0006545427604578435\n",
      "Epoch 1106, Loss: 0.007900733284259331, Final Batch Loss: 8.198010618798435e-05\n",
      "Epoch 1107, Loss: 0.0021812967679579742, Final Batch Loss: 0.00019399216398596764\n",
      "Epoch 1108, Loss: 0.004938752521411516, Final Batch Loss: 9.238853090209886e-05\n",
      "Epoch 1109, Loss: 0.005011549635128176, Final Batch Loss: 0.00038021543878130615\n",
      "Epoch 1110, Loss: 0.016647877357172547, Final Batch Loss: 0.00015699848881922662\n",
      "Epoch 1111, Loss: 0.01651411343846121, Final Batch Loss: 0.0001392360863974318\n",
      "Epoch 1112, Loss: 0.0026513877146499, Final Batch Loss: 2.5079176339204423e-05\n",
      "Epoch 1113, Loss: 0.003022740042069927, Final Batch Loss: 6.668736023129895e-05\n",
      "Epoch 1114, Loss: 0.0026880120367422933, Final Batch Loss: 7.259147241711617e-05\n",
      "Epoch 1115, Loss: 0.02816495024944743, Final Batch Loss: 0.0001940498623298481\n",
      "Epoch 1116, Loss: 0.007972312787387636, Final Batch Loss: 0.000627597444690764\n",
      "Epoch 1117, Loss: 0.009300768011598848, Final Batch Loss: 6.98351432220079e-05\n",
      "Epoch 1118, Loss: 0.018699626647503464, Final Batch Loss: 0.0007075902540236712\n",
      "Epoch 1119, Loss: 0.04277466224175441, Final Batch Loss: 0.00014351301069837064\n",
      "Epoch 1120, Loss: 0.010925945833150763, Final Batch Loss: 0.0007976132910698652\n",
      "Epoch 1121, Loss: 0.008983172640000703, Final Batch Loss: 0.00015850707131903619\n",
      "Epoch 1122, Loss: 0.0015841050317249028, Final Batch Loss: 0.00025015854043886065\n",
      "Epoch 1123, Loss: 0.0022354242028086446, Final Batch Loss: 0.00030141076422296464\n",
      "Epoch 1124, Loss: 0.02903138883630163, Final Batch Loss: 2.2579890355700627e-05\n",
      "Epoch 1125, Loss: 0.004666957596782595, Final Batch Loss: 0.00040151880239136517\n",
      "Epoch 1126, Loss: 0.0028330820405244594, Final Batch Loss: 0.0006405356107279658\n",
      "Epoch 1127, Loss: 0.008322132008856897, Final Batch Loss: 0.005897447466850281\n",
      "Epoch 1128, Loss: 0.06108399118420493, Final Batch Loss: 0.009251796640455723\n",
      "Epoch 1129, Loss: 0.02899137760323356, Final Batch Loss: 0.00026315150898881257\n",
      "Epoch 1130, Loss: 0.05886346334409609, Final Batch Loss: 0.007754933554679155\n",
      "Epoch 1131, Loss: 0.016354962596778932, Final Batch Loss: 0.00017469395243097097\n",
      "Epoch 1132, Loss: 0.04538948083973082, Final Batch Loss: 0.011998944915831089\n",
      "Epoch 1133, Loss: 0.023215746663481696, Final Batch Loss: 0.00010287003533449024\n",
      "Epoch 1134, Loss: 0.03575180293410085, Final Batch Loss: 0.0010151563910767436\n",
      "Epoch 1135, Loss: 0.016713393677491695, Final Batch Loss: 0.0016356970882043242\n",
      "Epoch 1136, Loss: 0.034772787759720813, Final Batch Loss: 0.0005382304079830647\n",
      "Epoch 1137, Loss: 0.028492384941273485, Final Batch Loss: 0.0005768603296019137\n",
      "Epoch 1138, Loss: 0.023510384238761617, Final Batch Loss: 0.00011663908662740141\n",
      "Epoch 1139, Loss: 0.04318972395049059, Final Batch Loss: 0.0037982934154570103\n",
      "Epoch 1140, Loss: 0.011313097271340666, Final Batch Loss: 0.0001640005939407274\n",
      "Epoch 1141, Loss: 0.00895150315045612, Final Batch Loss: 0.0005629265797324479\n",
      "Epoch 1142, Loss: 0.007401413182378747, Final Batch Loss: 0.0002703903301153332\n",
      "Epoch 1143, Loss: 0.009090667183045298, Final Batch Loss: 0.005295093171298504\n",
      "Epoch 1144, Loss: 0.01926482929411577, Final Batch Loss: 0.0033357120119035244\n",
      "Epoch 1145, Loss: 0.025297285668784752, Final Batch Loss: 0.00011823054956039414\n",
      "Epoch 1146, Loss: 0.02392808268632507, Final Batch Loss: 0.00021037209080532193\n",
      "Epoch 1147, Loss: 0.007924332207039697, Final Batch Loss: 0.0007112728198990226\n",
      "Epoch 1148, Loss: 0.003993289915342757, Final Batch Loss: 0.00013352895621210337\n",
      "Epoch 1149, Loss: 0.02243975201054127, Final Batch Loss: 0.00021889887284487486\n",
      "Epoch 1150, Loss: 0.01078699995559873, Final Batch Loss: 0.00028748493059538305\n",
      "Epoch 1151, Loss: 0.021995321387294098, Final Batch Loss: 0.0006506568752229214\n",
      "Epoch 1152, Loss: 0.01131737250216247, Final Batch Loss: 2.7901689463760704e-05\n",
      "Epoch 1153, Loss: 0.03657408623257652, Final Batch Loss: 0.00014360423665493727\n",
      "Epoch 1154, Loss: 0.03872117587889079, Final Batch Loss: 0.0008760119671933353\n",
      "Epoch 1155, Loss: 0.005275224380966392, Final Batch Loss: 2.837802458088845e-05\n",
      "Epoch 1156, Loss: 0.0060299994656816125, Final Batch Loss: 0.0001548507425468415\n",
      "Epoch 1157, Loss: 0.038503259283515945, Final Batch Loss: 0.002142867539077997\n",
      "Epoch 1158, Loss: 0.010581077489405288, Final Batch Loss: 0.0010453640716150403\n",
      "Epoch 1159, Loss: 0.02632945765799377, Final Batch Loss: 0.00311059202067554\n",
      "Epoch 1160, Loss: 0.03997366478142794, Final Batch Loss: 0.0002747961843851954\n",
      "Epoch 1161, Loss: 0.028254991466383217, Final Batch Loss: 9.27735964069143e-05\n",
      "Epoch 1162, Loss: 0.0029102761054673465, Final Batch Loss: 4.518580681178719e-05\n",
      "Epoch 1163, Loss: 0.011663021045023925, Final Batch Loss: 0.000564614194445312\n",
      "Epoch 1164, Loss: 0.005528927651539561, Final Batch Loss: 4.871706914855167e-05\n",
      "Epoch 1165, Loss: 0.034245631059093284, Final Batch Loss: 0.02877422235906124\n",
      "Epoch 1166, Loss: 0.02822004304107395, Final Batch Loss: 3.722568362718448e-05\n",
      "Epoch 1167, Loss: 0.039330698251433205, Final Batch Loss: 0.0007038518670015037\n",
      "Epoch 1168, Loss: 0.060111890573352866, Final Batch Loss: 0.008594500832259655\n",
      "Epoch 1169, Loss: 0.04722887551179156, Final Batch Loss: 0.0011303636711090803\n",
      "Epoch 1170, Loss: 0.006901488204675843, Final Batch Loss: 0.00040338668623007834\n",
      "Epoch 1171, Loss: 0.00876720602173009, Final Batch Loss: 5.8829347835853696e-05\n",
      "Epoch 1172, Loss: 0.014389436233614106, Final Batch Loss: 0.00058377516688779\n",
      "Epoch 1173, Loss: 0.0038975097322691, Final Batch Loss: 0.0011159884743392467\n",
      "Epoch 1174, Loss: 0.0035237784086348256, Final Batch Loss: 0.0001277964620385319\n",
      "Epoch 1175, Loss: 0.01697236115251144, Final Batch Loss: 7.306512998184189e-05\n",
      "Epoch 1176, Loss: 0.019982354850071715, Final Batch Loss: 0.00039794915937818587\n",
      "Epoch 1177, Loss: 0.015816799877939047, Final Batch Loss: 0.00019397384312469512\n",
      "Epoch 1178, Loss: 0.0032137783709913492, Final Batch Loss: 6.332126940833405e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1179, Loss: 0.008522816264303401, Final Batch Loss: 8.946284651756287e-06\n",
      "Epoch 1180, Loss: 0.026504981482503354, Final Batch Loss: 2.078277975670062e-05\n",
      "Epoch 1181, Loss: 0.007217959729132417, Final Batch Loss: 5.989618330204394e-06\n",
      "Epoch 1182, Loss: 0.017359455374389654, Final Batch Loss: 0.00010851103434106335\n",
      "Epoch 1183, Loss: 0.008429091456491733, Final Batch Loss: 4.431134948390536e-05\n",
      "Epoch 1184, Loss: 0.11808591932685886, Final Batch Loss: 0.00010671180643839762\n",
      "Epoch 1185, Loss: 0.07517460288727307, Final Batch Loss: 2.6293564587831497e-05\n",
      "Epoch 1186, Loss: 0.024196339192712912, Final Batch Loss: 0.0028334392700344324\n",
      "Epoch 1187, Loss: 0.005542498944123508, Final Batch Loss: 0.00012544913624878973\n",
      "Epoch 1188, Loss: 0.010064085239719134, Final Batch Loss: 0.00016209606837946922\n",
      "Epoch 1189, Loss: 0.007500041439925553, Final Batch Loss: 0.000128592160763219\n",
      "Epoch 1190, Loss: 0.008091177385722403, Final Batch Loss: 0.0006479814765043557\n",
      "Epoch 1191, Loss: 0.003111925650955527, Final Batch Loss: 0.00017951840709429234\n",
      "Epoch 1192, Loss: 0.013415713132417295, Final Batch Loss: 0.00031964044319465756\n",
      "Epoch 1193, Loss: 0.0034071907348334207, Final Batch Loss: 0.0004127334104850888\n",
      "Epoch 1194, Loss: 0.0018889076113737246, Final Batch Loss: 0.0004614305216819048\n",
      "Epoch 1195, Loss: 0.0023733921952953096, Final Batch Loss: 5.107825018058065e-06\n",
      "Epoch 1196, Loss: 0.002776471283596038, Final Batch Loss: 3.004620157298632e-05\n",
      "Epoch 1197, Loss: 0.01838772687506207, Final Batch Loss: 0.0001495186152169481\n",
      "Epoch 1198, Loss: 0.008387776455265339, Final Batch Loss: 0.0017278745071962476\n",
      "Epoch 1199, Loss: 0.016048142485942662, Final Batch Loss: 0.00017492331971880049\n",
      "Epoch 1200, Loss: 0.10435497464550281, Final Batch Loss: 0.0284904595464468\n",
      "Epoch 1201, Loss: 0.06612269314064179, Final Batch Loss: 0.008765378966927528\n",
      "Epoch 1202, Loss: 0.022935363558644895, Final Batch Loss: 0.0011271759867668152\n",
      "Epoch 1203, Loss: 0.007273180381162092, Final Batch Loss: 0.0005320386844687164\n",
      "Epoch 1204, Loss: 0.008078717042735661, Final Batch Loss: 7.415049913106486e-05\n",
      "Epoch 1205, Loss: 0.010170142824790673, Final Batch Loss: 0.00036176637513563037\n",
      "Epoch 1206, Loss: 0.036928485121279664, Final Batch Loss: 0.0002967045293189585\n",
      "Epoch 1207, Loss: 0.02022613844837906, Final Batch Loss: 0.00026017468189820647\n",
      "Epoch 1208, Loss: 0.012111487907532137, Final Batch Loss: 0.0011929802130907774\n",
      "Epoch 1209, Loss: 0.03384367762555485, Final Batch Loss: 0.00021483100135810673\n",
      "Epoch 1210, Loss: 0.006929823302925797, Final Batch Loss: 0.00010741343430709094\n",
      "Epoch 1211, Loss: 0.008914803838706575, Final Batch Loss: 0.0007682139985263348\n",
      "Epoch 1212, Loss: 0.0041220226248697145, Final Batch Loss: 0.0018180193146690726\n",
      "Epoch 1213, Loss: 0.020725098307593726, Final Batch Loss: 0.00025973247829824686\n",
      "Epoch 1214, Loss: 0.011610189863858977, Final Batch Loss: 0.000863191788084805\n",
      "Epoch 1215, Loss: 0.016745751974667655, Final Batch Loss: 0.00019049995171371847\n",
      "Epoch 1216, Loss: 0.003739440031495178, Final Batch Loss: 9.149357356363907e-05\n",
      "Epoch 1217, Loss: 0.008057623695094662, Final Batch Loss: 0.00021137813746463507\n",
      "Epoch 1218, Loss: 0.009622700752515811, Final Batch Loss: 7.883860962465405e-05\n",
      "Epoch 1219, Loss: 0.019389993068216427, Final Batch Loss: 1.5074957445904147e-05\n",
      "Epoch 1220, Loss: 0.027020546484891383, Final Batch Loss: 1.1796219951065723e-05\n",
      "Epoch 1221, Loss: 0.05287524104460317, Final Batch Loss: 6.051488526281901e-06\n",
      "Epoch 1222, Loss: 0.016454788739793003, Final Batch Loss: 0.0007740736473351717\n",
      "Epoch 1223, Loss: 0.008766965904214885, Final Batch Loss: 0.00022947046090848744\n",
      "Epoch 1224, Loss: 0.03608534314116696, Final Batch Loss: 0.0007289722561836243\n",
      "Epoch 1225, Loss: 0.014641047001987317, Final Batch Loss: 7.99331464804709e-05\n",
      "Epoch 1226, Loss: 0.05479838661267422, Final Batch Loss: 0.0008674292475916445\n",
      "Epoch 1227, Loss: 0.05851635808903666, Final Batch Loss: 0.00010392971307737753\n",
      "Epoch 1228, Loss: 0.03263963219797006, Final Batch Loss: 0.0018465806497260928\n",
      "Epoch 1229, Loss: 0.06169893329115439, Final Batch Loss: 0.0004903973313048482\n",
      "Epoch 1230, Loss: 0.028371892745781224, Final Batch Loss: 0.0016540184151381254\n",
      "Epoch 1231, Loss: 0.02974637378792977, Final Batch Loss: 0.00017710462270770222\n",
      "Epoch 1232, Loss: 0.02404225855570985, Final Batch Loss: 0.004005480092018843\n",
      "Epoch 1233, Loss: 0.008372367779429624, Final Batch Loss: 0.0001958249631570652\n",
      "Epoch 1234, Loss: 0.009152407099463744, Final Batch Loss: 0.00039417538209818304\n",
      "Epoch 1235, Loss: 0.004542343209323008, Final Batch Loss: 6.476893759099767e-05\n",
      "Epoch 1236, Loss: 0.0050352052026028105, Final Batch Loss: 0.0001573377230670303\n",
      "Epoch 1237, Loss: 0.003395793720301299, Final Batch Loss: 7.593256304971874e-05\n",
      "Epoch 1238, Loss: 0.0008996476772153983, Final Batch Loss: 4.041004285681993e-05\n",
      "Epoch 1239, Loss: 0.014000190571096027, Final Batch Loss: 0.003474190831184387\n",
      "Epoch 1240, Loss: 0.021131194199597303, Final Batch Loss: 0.004952133633196354\n",
      "Epoch 1241, Loss: 0.022819059721086887, Final Batch Loss: 8.803134733170737e-06\n",
      "Epoch 1242, Loss: 0.03368861230046605, Final Batch Loss: 0.0005194764817133546\n",
      "Epoch 1243, Loss: 0.013193021894039703, Final Batch Loss: 6.16597753833048e-05\n",
      "Epoch 1244, Loss: 0.007617683512307849, Final Batch Loss: 2.900877734646201e-05\n",
      "Epoch 1245, Loss: 0.0034141256360271655, Final Batch Loss: 0.000899566279258579\n",
      "Epoch 1246, Loss: 0.022655481434640024, Final Batch Loss: 0.00020659825531765819\n",
      "Epoch 1247, Loss: 0.025927242671968997, Final Batch Loss: 0.00011757821630453691\n",
      "Epoch 1248, Loss: 0.014160612425257568, Final Batch Loss: 8.767058898229152e-05\n",
      "Epoch 1249, Loss: 0.004433782445630641, Final Batch Loss: 4.429133332450874e-05\n",
      "Epoch 1250, Loss: 0.0020868119781880523, Final Batch Loss: 6.230620783753693e-05\n",
      "Epoch 1251, Loss: 0.0031852214960963465, Final Batch Loss: 0.00013026366650592536\n",
      "Epoch 1252, Loss: 0.0031750819907756522, Final Batch Loss: 0.00019713006622623652\n",
      "Epoch 1253, Loss: 0.01773167800911324, Final Batch Loss: 1.0106768058903981e-05\n",
      "Epoch 1254, Loss: 0.03390192860570096, Final Batch Loss: 0.027507228776812553\n",
      "Epoch 1255, Loss: 0.013281153340358287, Final Batch Loss: 0.0005085629527457058\n",
      "Epoch 1256, Loss: 0.03065466728367028, Final Batch Loss: 0.002426550490781665\n",
      "Epoch 1257, Loss: 0.033400180464468576, Final Batch Loss: 1.1803258530562744e-05\n",
      "Epoch 1258, Loss: 0.020365185362607008, Final Batch Loss: 0.0008654314442537725\n",
      "Epoch 1259, Loss: 0.01901759898464661, Final Batch Loss: 0.0067171258851885796\n",
      "Epoch 1260, Loss: 0.044418754820071626, Final Batch Loss: 8.557351247873157e-05\n",
      "Epoch 1261, Loss: 0.013947744510005577, Final Batch Loss: 2.360669350309763e-05\n",
      "Epoch 1262, Loss: 0.02392225369658263, Final Batch Loss: 0.0001181935440399684\n",
      "Epoch 1263, Loss: 0.019628810216090642, Final Batch Loss: 0.003029389539733529\n",
      "Epoch 1264, Loss: 0.03292944282247845, Final Batch Loss: 0.00011986098252236843\n",
      "Epoch 1265, Loss: 0.016347535191016505, Final Batch Loss: 0.004302934743463993\n",
      "Epoch 1266, Loss: 0.027297247725073248, Final Batch Loss: 0.000645574415102601\n",
      "Epoch 1267, Loss: 0.012317924654325907, Final Batch Loss: 0.0018056193366646767\n",
      "Epoch 1268, Loss: 0.004246195018822618, Final Batch Loss: 0.0003266746352892369\n",
      "Epoch 1269, Loss: 0.005814616967654729, Final Batch Loss: 7.879306212998927e-05\n",
      "Epoch 1270, Loss: 0.014833955403446453, Final Batch Loss: 0.010212885215878487\n",
      "Epoch 1271, Loss: 0.002142587407661267, Final Batch Loss: 0.0006242786184884608\n",
      "Epoch 1272, Loss: 0.0014485488997593166, Final Batch Loss: 3.1723753636470065e-05\n",
      "Epoch 1273, Loss: 0.0043485546793817775, Final Batch Loss: 4.207167512504384e-05\n",
      "Epoch 1274, Loss: 0.008862310728318334, Final Batch Loss: 0.00018646346870809793\n",
      "Epoch 1275, Loss: 0.007242957542075601, Final Batch Loss: 4.4485819671535864e-05\n",
      "Epoch 1276, Loss: 0.0054465493603856885, Final Batch Loss: 1.1038360753445886e-05\n",
      "Epoch 1277, Loss: 0.017790881720429752, Final Batch Loss: 1.569225059938617e-05\n",
      "Epoch 1278, Loss: 0.0022179048992256867, Final Batch Loss: 4.5144653995521367e-05\n",
      "Epoch 1279, Loss: 0.0033754304413378122, Final Batch Loss: 8.062098459049594e-06\n",
      "Epoch 1280, Loss: 0.0051544563609695615, Final Batch Loss: 2.8815454697905807e-06\n",
      "Epoch 1281, Loss: 0.0021836892324245127, Final Batch Loss: 1.1727441233233549e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1282, Loss: 0.012154081332937494, Final Batch Loss: 9.368500286655035e-06\n",
      "Epoch 1283, Loss: 0.011609165580466652, Final Batch Loss: 0.0035906105767935514\n",
      "Epoch 1284, Loss: 0.011982659397290263, Final Batch Loss: 0.00022868784435559064\n",
      "Epoch 1285, Loss: 0.01402801520544017, Final Batch Loss: 2.568276431702543e-05\n",
      "Epoch 1286, Loss: 0.006268468682719686, Final Batch Loss: 0.00012876403343398124\n",
      "Epoch 1287, Loss: 0.007722551776396358, Final Batch Loss: 0.004594847559928894\n",
      "Epoch 1288, Loss: 0.019403912398047396, Final Batch Loss: 7.268365152413025e-05\n",
      "Epoch 1289, Loss: 0.027596086344601645, Final Batch Loss: 1.1603176062635612e-05\n",
      "Epoch 1290, Loss: 0.006684689395115129, Final Batch Loss: 0.00018955925770569593\n",
      "Epoch 1291, Loss: 0.01334116084035486, Final Batch Loss: 0.00019395427079871297\n",
      "Epoch 1292, Loss: 0.010498961541543395, Final Batch Loss: 3.1514013244304806e-05\n",
      "Epoch 1293, Loss: 0.003591786751712789, Final Batch Loss: 1.287786835746374e-05\n",
      "Epoch 1294, Loss: 0.015200170877506025, Final Batch Loss: 6.613185541937128e-05\n",
      "Epoch 1295, Loss: 0.016880466811926453, Final Batch Loss: 8.822215932013933e-06\n",
      "Epoch 1296, Loss: 0.010929384153314459, Final Batch Loss: 0.002028763061389327\n",
      "Epoch 1297, Loss: 0.005829852512761136, Final Batch Loss: 1.0259880582452752e-05\n",
      "Epoch 1298, Loss: 0.007781080068525625, Final Batch Loss: 7.987409480847418e-05\n",
      "Epoch 1299, Loss: 0.003180520315368085, Final Batch Loss: 0.001226656837388873\n",
      "Epoch 1300, Loss: 0.003830168157492153, Final Batch Loss: 7.573471521027386e-05\n",
      "Epoch 1301, Loss: 0.001675994028119021, Final Batch Loss: 7.455455488525331e-05\n",
      "Epoch 1302, Loss: 0.008741889845623518, Final Batch Loss: 0.0010444608051329851\n",
      "Epoch 1303, Loss: 0.002005146430747118, Final Batch Loss: 1.706645889498759e-05\n",
      "Epoch 1304, Loss: 0.001778700159775326, Final Batch Loss: 0.0008314576116390526\n",
      "Epoch 1305, Loss: 0.002727988035985618, Final Batch Loss: 0.00011088057362940162\n",
      "Epoch 1306, Loss: 0.026932864272964707, Final Batch Loss: 0.0006077484576962888\n",
      "Epoch 1307, Loss: 0.0018764470023597823, Final Batch Loss: 2.286739800183568e-05\n",
      "Epoch 1308, Loss: 0.03759656822512625, Final Batch Loss: 0.021292321383953094\n",
      "Epoch 1309, Loss: 0.03654294478837983, Final Batch Loss: 0.000175431850948371\n",
      "Epoch 1310, Loss: 0.035261715838714736, Final Batch Loss: 1.430194970453158e-05\n",
      "Epoch 1311, Loss: 0.06680671758840617, Final Batch Loss: 0.0019236051011830568\n",
      "Epoch 1312, Loss: 0.06559760344316601, Final Batch Loss: 0.014797627925872803\n",
      "Epoch 1313, Loss: 0.1048337892825657, Final Batch Loss: 0.00020332068379502743\n",
      "Epoch 1314, Loss: 0.016002114310140314, Final Batch Loss: 0.00011588184133870527\n",
      "Epoch 1315, Loss: 0.016256579511718883, Final Batch Loss: 0.0012461546575650573\n",
      "Epoch 1316, Loss: 0.009434446728846524, Final Batch Loss: 0.00046305274008773267\n",
      "Epoch 1317, Loss: 0.025435561708945897, Final Batch Loss: 0.01610678806900978\n",
      "Epoch 1318, Loss: 0.014857297244816436, Final Batch Loss: 0.0001102483001886867\n",
      "Epoch 1319, Loss: 0.10895307815189881, Final Batch Loss: 3.1317122193286195e-05\n",
      "Epoch 1320, Loss: 0.018299390883839806, Final Batch Loss: 5.119643174111843e-05\n",
      "Epoch 1321, Loss: 0.023438032294961886, Final Batch Loss: 0.0008247107616625726\n",
      "Epoch 1322, Loss: 0.008942832727370842, Final Batch Loss: 0.001370300306007266\n",
      "Epoch 1323, Loss: 0.05331952999222267, Final Batch Loss: 0.047571226954460144\n",
      "Epoch 1324, Loss: 0.012739391493141738, Final Batch Loss: 4.6606735850218683e-05\n",
      "Epoch 1325, Loss: 0.00423363245499786, Final Batch Loss: 0.00016028553363867104\n",
      "Epoch 1326, Loss: 0.009054586309503065, Final Batch Loss: 0.003335690125823021\n",
      "Epoch 1327, Loss: 0.0012161870745330816, Final Batch Loss: 3.526783984852955e-05\n",
      "Epoch 1328, Loss: 0.005525808164293267, Final Batch Loss: 1.965874071174767e-05\n",
      "Epoch 1329, Loss: 0.014238717178614024, Final Batch Loss: 3.968616510974243e-05\n",
      "Epoch 1330, Loss: 0.021707912948841113, Final Batch Loss: 0.0015551341930404305\n",
      "Epoch 1331, Loss: 0.014245699362845698, Final Batch Loss: 0.0003622280200943351\n",
      "Epoch 1332, Loss: 0.01992962045369495, Final Batch Loss: 0.00013086279795970768\n",
      "Epoch 1333, Loss: 0.004570539964333875, Final Batch Loss: 5.7334873417858034e-05\n",
      "Epoch 1334, Loss: 0.0011449192716099788, Final Batch Loss: 2.3027601855574176e-05\n",
      "Epoch 1335, Loss: 0.03763095360045554, Final Batch Loss: 0.00010927658149739727\n",
      "Epoch 1336, Loss: 0.004497786670981441, Final Batch Loss: 2.6038349460577592e-05\n",
      "Epoch 1337, Loss: 0.019810287295513263, Final Batch Loss: 0.00037703680573031306\n",
      "Epoch 1338, Loss: 0.003043442415219033, Final Batch Loss: 0.00019573089957702905\n",
      "Epoch 1339, Loss: 0.011108998759482347, Final Batch Loss: 5.1966006139991805e-05\n",
      "Epoch 1340, Loss: 0.010972056717037049, Final Batch Loss: 0.0007185476715676486\n",
      "Epoch 1341, Loss: 0.016505714125742088, Final Batch Loss: 5.9412595874164253e-05\n",
      "Epoch 1342, Loss: 0.02264965420908993, Final Batch Loss: 0.00015259537030942738\n",
      "Epoch 1343, Loss: 0.004902229615254328, Final Batch Loss: 9.283445979235694e-05\n",
      "Epoch 1344, Loss: 0.007293065448720881, Final Batch Loss: 7.483013905584812e-05\n",
      "Epoch 1345, Loss: 0.0012428940840436553, Final Batch Loss: 4.43740573246032e-05\n",
      "Epoch 1346, Loss: 0.0016407493295673703, Final Batch Loss: 0.0005595540278591216\n",
      "Epoch 1347, Loss: 0.013676666006858795, Final Batch Loss: 9.598575707059354e-05\n",
      "Epoch 1348, Loss: 0.01312116103417793, Final Batch Loss: 9.109297388931736e-05\n",
      "Epoch 1349, Loss: 0.002858472264961165, Final Batch Loss: 0.0006653348682448268\n",
      "Epoch 1350, Loss: 0.011320396716655523, Final Batch Loss: 0.00017628980276640505\n",
      "Epoch 1351, Loss: 0.04818525722657796, Final Batch Loss: 0.005317054223269224\n",
      "Epoch 1352, Loss: 0.0017075922801268462, Final Batch Loss: 0.0001057681001839228\n",
      "Epoch 1353, Loss: 0.015070870905901756, Final Batch Loss: 0.00010665770241757855\n",
      "Epoch 1354, Loss: 0.01272443726338679, Final Batch Loss: 6.414662493625656e-06\n",
      "Epoch 1355, Loss: 0.006101144449530693, Final Batch Loss: 0.00030030333437025547\n",
      "Epoch 1356, Loss: 0.00961283055585227, Final Batch Loss: 3.132332494715229e-05\n",
      "Epoch 1357, Loss: 0.02251772708405042, Final Batch Loss: 6.086698340368457e-05\n",
      "Epoch 1358, Loss: 0.010417361237159639, Final Batch Loss: 3.0132890969980508e-05\n",
      "Epoch 1359, Loss: 0.0069368937802209985, Final Batch Loss: 0.00033077012631110847\n",
      "Epoch 1360, Loss: 0.0018926851980722859, Final Batch Loss: 0.0005230871611274779\n",
      "Epoch 1361, Loss: 0.013809859759930987, Final Batch Loss: 0.0002541619760449976\n",
      "Epoch 1362, Loss: 0.016132407917211822, Final Batch Loss: 5.155191320227459e-05\n",
      "Epoch 1363, Loss: 0.023994529397896258, Final Batch Loss: 8.997061377158388e-05\n",
      "Epoch 1364, Loss: 0.028890652321933885, Final Batch Loss: 0.0011578563135117292\n",
      "Epoch 1365, Loss: 0.03474399362130498, Final Batch Loss: 1.189497379527893e-05\n",
      "Epoch 1366, Loss: 0.004499629402744176, Final Batch Loss: 3.3554646506672725e-05\n",
      "Epoch 1367, Loss: 0.007716619058555807, Final Batch Loss: 3.8486425182782114e-05\n",
      "Epoch 1368, Loss: 0.007034057816781569, Final Batch Loss: 7.404352800222114e-05\n",
      "Epoch 1369, Loss: 0.01711397744838905, Final Batch Loss: 0.005938979331403971\n",
      "Epoch 1370, Loss: 0.0064648674851923715, Final Batch Loss: 0.00012908839562442154\n",
      "Epoch 1371, Loss: 0.023052086966799834, Final Batch Loss: 0.008852286264300346\n",
      "Epoch 1372, Loss: 0.010818262720022176, Final Batch Loss: 3.8468861021101475e-05\n",
      "Epoch 1373, Loss: 0.017038093119481346, Final Batch Loss: 4.549419827526435e-06\n",
      "Epoch 1374, Loss: 0.011554044833246735, Final Batch Loss: 0.0003222156083211303\n",
      "Epoch 1375, Loss: 0.007928690401058702, Final Batch Loss: 1.4952840501791798e-05\n",
      "Epoch 1376, Loss: 0.0036262779212847818, Final Batch Loss: 6.717074938933365e-06\n",
      "Epoch 1377, Loss: 0.0010243755110650454, Final Batch Loss: 2.806441216307576e-06\n",
      "Epoch 1378, Loss: 0.001710281601845054, Final Batch Loss: 0.00023540235997643322\n",
      "Epoch 1379, Loss: 0.025636561251303647, Final Batch Loss: 1.0324386494175997e-05\n",
      "Epoch 1380, Loss: 0.010372733972872084, Final Batch Loss: 5.8546032960293815e-05\n",
      "Epoch 1381, Loss: 0.10272049288937524, Final Batch Loss: 0.0009598824544809759\n",
      "Epoch 1382, Loss: 0.04255015450507926, Final Batch Loss: 2.1104764527990483e-05\n",
      "Epoch 1383, Loss: 0.04453094571363181, Final Batch Loss: 0.00018506644119042903\n",
      "Epoch 1384, Loss: 0.00975520250358386, Final Batch Loss: 0.00011654995614662766\n",
      "Epoch 1385, Loss: 0.003092794007898192, Final Batch Loss: 0.00042819729424081743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1386, Loss: 0.015614880254361196, Final Batch Loss: 0.0002875408681575209\n",
      "Epoch 1387, Loss: 0.011293648205082718, Final Batch Loss: 0.0007189004099927843\n",
      "Epoch 1388, Loss: 0.002445021804305725, Final Batch Loss: 6.645232497248799e-05\n",
      "Epoch 1389, Loss: 0.0020160783733444987, Final Batch Loss: 3.728965384652838e-05\n",
      "Epoch 1390, Loss: 0.014451277883381408, Final Batch Loss: 7.735741382930428e-05\n",
      "Epoch 1391, Loss: 0.0023938361725868162, Final Batch Loss: 1.9426097424002364e-05\n",
      "Epoch 1392, Loss: 0.002581468345852045, Final Batch Loss: 1.1329891094646882e-05\n",
      "Epoch 1393, Loss: 0.004357343506853795, Final Batch Loss: 1.1927917512366548e-05\n",
      "Epoch 1394, Loss: 0.0029078330826450838, Final Batch Loss: 2.025912908720784e-05\n",
      "Epoch 1395, Loss: 0.010242926193768653, Final Batch Loss: 5.193366087041795e-05\n",
      "Epoch 1396, Loss: 0.005173522342602155, Final Batch Loss: 4.045282912557013e-05\n",
      "Epoch 1397, Loss: 0.005508894351805793, Final Batch Loss: 4.276209801901132e-05\n",
      "Epoch 1398, Loss: 0.0010133684194215675, Final Batch Loss: 6.459614724008134e-06\n",
      "Epoch 1399, Loss: 0.028045763214322506, Final Batch Loss: 1.3091755135974381e-05\n",
      "Epoch 1400, Loss: 0.01759277551263949, Final Batch Loss: 0.00010307877528248355\n",
      "Epoch 1401, Loss: 0.02109331864721753, Final Batch Loss: 0.000330098788253963\n",
      "Epoch 1402, Loss: 0.028575477237609448, Final Batch Loss: 9.873671660898253e-05\n",
      "Epoch 1403, Loss: 0.006862512078896543, Final Batch Loss: 0.005532464012503624\n",
      "Epoch 1404, Loss: 0.03683194463701511, Final Batch Loss: 1.9119928765576333e-05\n",
      "Epoch 1405, Loss: 0.014846393278276082, Final Batch Loss: 8.843882824294269e-05\n",
      "Epoch 1406, Loss: 0.018394310899566335, Final Batch Loss: 1.47178925544722e-05\n",
      "Epoch 1407, Loss: 0.07107205454303767, Final Batch Loss: 8.676358993398026e-05\n",
      "Epoch 1408, Loss: 0.022016403469024226, Final Batch Loss: 0.00019486108794808388\n",
      "Epoch 1409, Loss: 0.03594920803516288, Final Batch Loss: 0.00011111262574559078\n",
      "Epoch 1410, Loss: 0.07268595205277961, Final Batch Loss: 0.0650225281715393\n",
      "Epoch 1411, Loss: 0.11124228809967462, Final Batch Loss: 0.006248357705771923\n",
      "Epoch 1412, Loss: 0.06768455371638993, Final Batch Loss: 0.0001381525507895276\n",
      "Epoch 1413, Loss: 0.0237138752854662, Final Batch Loss: 0.00032708756043575704\n",
      "Epoch 1414, Loss: 0.014729457745488617, Final Batch Loss: 0.00027554554981179535\n",
      "Epoch 1415, Loss: 0.01313233047403628, Final Batch Loss: 0.00017432804452255368\n",
      "Epoch 1416, Loss: 0.019930191663206642, Final Batch Loss: 0.0010625033173710108\n",
      "Epoch 1417, Loss: 0.004881000968453009, Final Batch Loss: 0.0001197566743940115\n",
      "Epoch 1418, Loss: 0.0036968972763133934, Final Batch Loss: 5.795823017251678e-05\n",
      "Epoch 1419, Loss: 0.021676893091353122, Final Batch Loss: 0.007482269313186407\n",
      "Epoch 1420, Loss: 0.0042054327932419255, Final Batch Loss: 1.614182474440895e-05\n",
      "Epoch 1421, Loss: 0.09446968260454014, Final Batch Loss: 2.0160372514510527e-05\n",
      "Epoch 1422, Loss: 0.004120303121453617, Final Batch Loss: 0.00031673855846747756\n",
      "Epoch 1423, Loss: 0.046873971303284634, Final Batch Loss: 0.00042243246571160853\n",
      "Epoch 1424, Loss: 0.01664109524608648, Final Batch Loss: 0.002816423075273633\n",
      "Epoch 1425, Loss: 0.015401637507238775, Final Batch Loss: 0.011254580691456795\n",
      "Epoch 1426, Loss: 0.015151613471971359, Final Batch Loss: 0.00014908841694705188\n",
      "Epoch 1427, Loss: 0.028893486449305783, Final Batch Loss: 0.007331605535000563\n",
      "Epoch 1428, Loss: 0.0366535920984461, Final Batch Loss: 6.33265808573924e-05\n",
      "Epoch 1429, Loss: 0.09274315260563526, Final Batch Loss: 0.006928218528628349\n",
      "Epoch 1430, Loss: 0.02639407306924113, Final Batch Loss: 0.00014139749691821635\n",
      "Epoch 1431, Loss: 0.025848095941910287, Final Batch Loss: 0.008279549889266491\n",
      "Epoch 1432, Loss: 0.03815264304103039, Final Batch Loss: 0.00779946381226182\n",
      "Epoch 1433, Loss: 0.004552705355308717, Final Batch Loss: 0.0010540077928453684\n",
      "Epoch 1434, Loss: 0.010814042318088468, Final Batch Loss: 0.00010899313201662153\n",
      "Epoch 1435, Loss: 0.0229685877193333, Final Batch Loss: 0.00415783142670989\n",
      "Epoch 1436, Loss: 0.0223192742014362, Final Batch Loss: 4.999265001970343e-05\n",
      "Epoch 1437, Loss: 0.009572322622261709, Final Batch Loss: 4.0374619857175276e-05\n",
      "Epoch 1438, Loss: 0.022790412318499875, Final Batch Loss: 0.00039850271423347294\n",
      "Epoch 1439, Loss: 0.008095601029708632, Final Batch Loss: 0.00020083047274965793\n",
      "Epoch 1440, Loss: 0.006871125598991057, Final Batch Loss: 0.0003071370883844793\n",
      "Epoch 1441, Loss: 0.005965303118500742, Final Batch Loss: 6.173957808641717e-05\n",
      "Epoch 1442, Loss: 0.011175518604432, Final Batch Loss: 0.0007311315275728703\n",
      "Epoch 1443, Loss: 0.007637470680492697, Final Batch Loss: 0.0016527270199730992\n",
      "Epoch 1444, Loss: 0.014812790318501357, Final Batch Loss: 0.00014597384142689407\n",
      "Epoch 1445, Loss: 0.008265826275419386, Final Batch Loss: 2.7380103347240947e-05\n",
      "Epoch 1446, Loss: 0.014352930484164972, Final Batch Loss: 0.00023107667220756412\n",
      "Epoch 1447, Loss: 0.012321185722612427, Final Batch Loss: 5.4998829000396654e-05\n",
      "Epoch 1448, Loss: 0.001730079793560435, Final Batch Loss: 7.096045010257512e-05\n",
      "Epoch 1449, Loss: 0.031630206176032516, Final Batch Loss: 5.336094545782544e-06\n",
      "Epoch 1450, Loss: 0.0022554631905222777, Final Batch Loss: 5.32528902112972e-05\n",
      "Epoch 1451, Loss: 0.04711074474562338, Final Batch Loss: 1.6887741367099807e-05\n",
      "Epoch 1452, Loss: 0.025737564930750523, Final Batch Loss: 0.0033358472865074873\n",
      "Epoch 1453, Loss: 0.008381572324651643, Final Batch Loss: 0.00030814509955234826\n",
      "Epoch 1454, Loss: 0.005736144971251633, Final Batch Loss: 3.332112555654021e-06\n",
      "Epoch 1455, Loss: 0.0180047380454198, Final Batch Loss: 0.0002766552788671106\n",
      "Epoch 1456, Loss: 0.016664900619161926, Final Batch Loss: 5.9810419770656154e-05\n",
      "Epoch 1457, Loss: 0.03836622581547999, Final Batch Loss: 0.0034103342331945896\n",
      "Epoch 1458, Loss: 0.032549145599205076, Final Batch Loss: 0.0012266337871551514\n",
      "Epoch 1459, Loss: 0.020794667179870885, Final Batch Loss: 0.0014144907472655177\n",
      "Epoch 1460, Loss: 0.0060830756556242704, Final Batch Loss: 3.704372647916898e-05\n",
      "Epoch 1461, Loss: 0.018868059238229762, Final Batch Loss: 0.00013297358236741275\n",
      "Epoch 1462, Loss: 0.06486180402407626, Final Batch Loss: 2.268752177769784e-05\n",
      "Epoch 1463, Loss: 0.043500137733644806, Final Batch Loss: 0.0006405748426914215\n",
      "Epoch 1464, Loss: 0.011482797586722882, Final Batch Loss: 0.00045101239811629057\n",
      "Epoch 1465, Loss: 0.018005650767008774, Final Batch Loss: 4.555354098556563e-05\n",
      "Epoch 1466, Loss: 0.01498126250498899, Final Batch Loss: 6.551574188051745e-05\n",
      "Epoch 1467, Loss: 0.023479270570533117, Final Batch Loss: 0.002827319549396634\n",
      "Epoch 1468, Loss: 0.03117697551533638, Final Batch Loss: 5.679674359271303e-05\n",
      "Epoch 1469, Loss: 0.006922556844074279, Final Batch Loss: 0.002689713379368186\n",
      "Epoch 1470, Loss: 0.018364572630162, Final Batch Loss: 0.0003394263912923634\n",
      "Epoch 1471, Loss: 0.005050080582805094, Final Batch Loss: 0.0023603581357747316\n",
      "Epoch 1472, Loss: 0.0350600497204141, Final Batch Loss: 0.0027519965078681707\n",
      "Epoch 1473, Loss: 0.0019850493340527464, Final Batch Loss: 0.0001369642122881487\n",
      "Epoch 1474, Loss: 0.0126942454944583, Final Batch Loss: 9.22096205613343e-06\n",
      "Epoch 1475, Loss: 0.04138502489513485, Final Batch Loss: 0.0003061204624827951\n",
      "Epoch 1476, Loss: 0.013410604844466434, Final Batch Loss: 0.00025495124282315373\n",
      "Epoch 1477, Loss: 0.018277909490279853, Final Batch Loss: 0.00012935869744978845\n",
      "Epoch 1478, Loss: 0.04221211709045747, Final Batch Loss: 8.821721712592989e-05\n",
      "Epoch 1479, Loss: 0.016912793180381414, Final Batch Loss: 0.0001873914443422109\n",
      "Epoch 1480, Loss: 0.04362658076570369, Final Batch Loss: 6.447042687796056e-05\n",
      "Epoch 1481, Loss: 0.021598930448817555, Final Batch Loss: 0.007864880375564098\n",
      "Epoch 1482, Loss: 0.00794357539689372, Final Batch Loss: 0.00010276915418216959\n",
      "Epoch 1483, Loss: 0.019882570071786176, Final Batch Loss: 0.00012228322157170624\n",
      "Epoch 1484, Loss: 0.00757226338100736, Final Batch Loss: 0.000503379269503057\n",
      "Epoch 1485, Loss: 0.010444232880217896, Final Batch Loss: 0.00011647556675598025\n",
      "Epoch 1486, Loss: 0.02720601200053352, Final Batch Loss: 0.00044485050602816045\n",
      "Epoch 1487, Loss: 0.011935063448618166, Final Batch Loss: 0.002571295015513897\n",
      "Epoch 1488, Loss: 0.005277881795336725, Final Batch Loss: 9.796120866667479e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1489, Loss: 0.02508033897538553, Final Batch Loss: 9.558186866343021e-05\n",
      "Epoch 1490, Loss: 0.0061498940631281585, Final Batch Loss: 0.0008521442650817335\n",
      "Epoch 1491, Loss: 0.05079269465022662, Final Batch Loss: 0.00060610834043473\n",
      "Epoch 1492, Loss: 0.016777313965576468, Final Batch Loss: 2.8808604838559404e-05\n",
      "Epoch 1493, Loss: 0.039189125773191336, Final Batch Loss: 2.9360116968746297e-05\n",
      "Epoch 1494, Loss: 0.010183434438658878, Final Batch Loss: 2.1587473383988254e-05\n",
      "Epoch 1495, Loss: 0.004371463680399756, Final Batch Loss: 2.5409421141375788e-05\n",
      "Epoch 1496, Loss: 0.019475445924399537, Final Batch Loss: 0.0020402646623551846\n",
      "Epoch 1497, Loss: 0.018783123105095, Final Batch Loss: 0.0013313778908923268\n",
      "Epoch 1498, Loss: 0.003178968013571648, Final Batch Loss: 0.00010375926649430767\n",
      "Epoch 1499, Loss: 0.06435605810111156, Final Batch Loss: 4.779436130775139e-05\n",
      "Epoch 1500, Loss: 0.05916988382159616, Final Batch Loss: 0.0015954143600538373\n",
      "Epoch 1501, Loss: 0.018832734294846887, Final Batch Loss: 0.0003547511878423393\n",
      "Epoch 1502, Loss: 0.05070590893046756, Final Batch Loss: 2.3363871150650084e-05\n",
      "Epoch 1503, Loss: 0.09248009047223604, Final Batch Loss: 0.000662033271510154\n",
      "Epoch 1504, Loss: 0.02212572952885239, Final Batch Loss: 0.0006216869805939496\n",
      "Epoch 1505, Loss: 0.029247662409034092, Final Batch Loss: 0.0004942532395943999\n",
      "Epoch 1506, Loss: 0.04795567353903607, Final Batch Loss: 4.867847383138724e-05\n",
      "Epoch 1507, Loss: 0.014724056993145496, Final Batch Loss: 8.473241905448958e-05\n",
      "Epoch 1508, Loss: 0.02899680488371814, Final Batch Loss: 9.642416989663616e-05\n",
      "Epoch 1509, Loss: 0.008814999448077288, Final Batch Loss: 0.0002541437279433012\n",
      "Epoch 1510, Loss: 0.004473088698432548, Final Batch Loss: 3.5183318686904386e-05\n",
      "Epoch 1511, Loss: 0.015562503034743713, Final Batch Loss: 0.00013395982387010008\n",
      "Epoch 1512, Loss: 0.008127765702738543, Final Batch Loss: 8.823350799502805e-05\n",
      "Epoch 1513, Loss: 0.004167941568084643, Final Batch Loss: 0.00036036066012457013\n",
      "Epoch 1514, Loss: 0.012335495970546617, Final Batch Loss: 3.8503672840306535e-05\n",
      "Epoch 1515, Loss: 0.010022335023677442, Final Batch Loss: 0.0006865166942588985\n",
      "Epoch 1516, Loss: 0.0037602850734401727, Final Batch Loss: 0.00011338179319864139\n",
      "Epoch 1517, Loss: 0.01938652193894086, Final Batch Loss: 0.00011054248898290098\n",
      "Epoch 1518, Loss: 0.02772420144174248, Final Batch Loss: 0.00029760616598650813\n",
      "Epoch 1519, Loss: 0.022740375461580697, Final Batch Loss: 7.481229840777814e-05\n",
      "Epoch 1520, Loss: 0.006696414640828152, Final Batch Loss: 4.5680590119445696e-05\n",
      "Epoch 1521, Loss: 0.010685653867767542, Final Batch Loss: 7.332712993957102e-05\n",
      "Epoch 1522, Loss: 0.014375813530932646, Final Batch Loss: 0.0007022215868346393\n",
      "Epoch 1523, Loss: 0.0033451244180469075, Final Batch Loss: 0.00024006608873605728\n",
      "Epoch 1524, Loss: 0.0038430051508839824, Final Batch Loss: 0.001290458021685481\n",
      "Epoch 1525, Loss: 0.016492097175614617, Final Batch Loss: 0.0008311237907037139\n",
      "Epoch 1526, Loss: 0.016864180839093024, Final Batch Loss: 0.0012330565368756652\n",
      "Epoch 1527, Loss: 0.0052667386717075715, Final Batch Loss: 7.663405267521739e-05\n",
      "Epoch 1528, Loss: 0.004555952549935682, Final Batch Loss: 4.725933831650764e-05\n",
      "Epoch 1529, Loss: 0.009776385102668428, Final Batch Loss: 6.903335815877654e-06\n",
      "Epoch 1530, Loss: 0.007503619111048465, Final Batch Loss: 0.0002359861391596496\n",
      "Epoch 1531, Loss: 0.008545585800447952, Final Batch Loss: 0.0004903116496279836\n",
      "Epoch 1532, Loss: 0.04106304428523799, Final Batch Loss: 0.0015601664781570435\n",
      "Epoch 1533, Loss: 0.032099264913995285, Final Batch Loss: 0.0077060856856405735\n",
      "Epoch 1534, Loss: 0.014491446941974573, Final Batch Loss: 1.2537355360109359e-05\n",
      "Epoch 1535, Loss: 0.03762324555827945, Final Batch Loss: 2.7265232347417623e-05\n",
      "Epoch 1536, Loss: 0.00574484048775048, Final Batch Loss: 0.00038182182470336556\n",
      "Epoch 1537, Loss: 0.013627475745124684, Final Batch Loss: 0.00015613710274919868\n",
      "Epoch 1538, Loss: 0.012518700707914832, Final Batch Loss: 1.558981603011489e-05\n",
      "Epoch 1539, Loss: 0.0025750742406671634, Final Batch Loss: 1.659831468714401e-05\n",
      "Epoch 1540, Loss: 0.011403830236304202, Final Batch Loss: 5.450351636682171e-06\n",
      "Epoch 1541, Loss: 0.00944497241107456, Final Batch Loss: 0.001191972172819078\n",
      "Epoch 1542, Loss: 0.01300235498638358, Final Batch Loss: 0.00012008623161818832\n",
      "Epoch 1543, Loss: 0.00576605604692304, Final Batch Loss: 7.087978156050667e-05\n",
      "Epoch 1544, Loss: 0.00412861891754801, Final Batch Loss: 2.4085438781185076e-05\n",
      "Epoch 1545, Loss: 0.04821862390599563, Final Batch Loss: 8.168913336703554e-05\n",
      "Epoch 1546, Loss: 0.0028020263703183446, Final Batch Loss: 0.00021377441589720547\n",
      "Epoch 1547, Loss: 0.004301019847389398, Final Batch Loss: 2.6900947887043003e-06\n",
      "Epoch 1548, Loss: 0.0018552244209786295, Final Batch Loss: 3.403134542168118e-05\n",
      "Epoch 1549, Loss: 0.0037488846937776543, Final Batch Loss: 7.048077532090247e-05\n",
      "Epoch 1550, Loss: 0.005725492397687049, Final Batch Loss: 0.0005068760365247726\n",
      "Epoch 1551, Loss: 0.00408932083109903, Final Batch Loss: 6.174822920002043e-05\n",
      "Epoch 1552, Loss: 0.00881850649966509, Final Batch Loss: 1.0474479495314881e-05\n",
      "Epoch 1553, Loss: 0.0016675162742103566, Final Batch Loss: 1.1106913007097319e-05\n",
      "Epoch 1554, Loss: 0.006283510504999867, Final Batch Loss: 1.9421362594584934e-05\n",
      "Epoch 1555, Loss: 0.0012074521964677842, Final Batch Loss: 1.5506569980061613e-05\n",
      "Epoch 1556, Loss: 0.031248200912614266, Final Batch Loss: 9.247394336853176e-05\n",
      "Epoch 1557, Loss: 0.005546431309539912, Final Batch Loss: 0.001279314630664885\n",
      "Epoch 1558, Loss: 0.0035900786124329898, Final Batch Loss: 0.00015188528050202876\n",
      "Epoch 1559, Loss: 0.04015937564554406, Final Batch Loss: 0.0006093451520428061\n",
      "Epoch 1560, Loss: 0.043583804326772224, Final Batch Loss: 0.00046946966904215515\n",
      "Epoch 1561, Loss: 0.02798911950594629, Final Batch Loss: 0.00027056317776441574\n",
      "Epoch 1562, Loss: 0.015013896643722546, Final Batch Loss: 0.0008877243380993605\n",
      "Epoch 1563, Loss: 0.009157985370620736, Final Batch Loss: 1.356605025648605e-05\n",
      "Epoch 1564, Loss: 0.005708227570721647, Final Batch Loss: 3.9575457776663825e-05\n",
      "Epoch 1565, Loss: 0.005042545304604573, Final Batch Loss: 0.0006515029817819595\n",
      "Epoch 1566, Loss: 0.0059126963969902135, Final Batch Loss: 0.00013979220238979906\n",
      "Epoch 1567, Loss: 0.004015967135273968, Final Batch Loss: 5.499335748027079e-05\n",
      "Epoch 1568, Loss: 0.003390143809156143, Final Batch Loss: 6.353820936055854e-05\n",
      "Epoch 1569, Loss: 0.0019744781379813503, Final Batch Loss: 1.9840957975247875e-05\n",
      "Epoch 1570, Loss: 0.01893720470252447, Final Batch Loss: 7.85720330895856e-05\n",
      "Epoch 1571, Loss: 0.01706333216020539, Final Batch Loss: 0.00044701428851112723\n",
      "Epoch 1572, Loss: 0.018176698439219763, Final Batch Loss: 0.009938854724168777\n",
      "Epoch 1573, Loss: 0.036997867368654624, Final Batch Loss: 0.0016577148344367743\n",
      "Epoch 1574, Loss: 0.030541971003913204, Final Batch Loss: 0.0004963534884154797\n",
      "Epoch 1575, Loss: 0.020348388011370844, Final Batch Loss: 3.933138941647485e-05\n",
      "Epoch 1576, Loss: 0.020266251707653282, Final Batch Loss: 4.253781298757531e-05\n",
      "Epoch 1577, Loss: 0.025867497563012876, Final Batch Loss: 8.999841520562768e-05\n",
      "Epoch 1578, Loss: 0.01795506187772844, Final Batch Loss: 0.0001292599190492183\n",
      "Epoch 1579, Loss: 0.015703989383837325, Final Batch Loss: 0.003880369011312723\n",
      "Epoch 1580, Loss: 0.1487225795717677, Final Batch Loss: 0.0006420781137421727\n",
      "Epoch 1581, Loss: 0.013765627256361768, Final Batch Loss: 0.00018978783919010311\n",
      "Epoch 1582, Loss: 0.014357696563820355, Final Batch Loss: 0.0006582736968994141\n",
      "Epoch 1583, Loss: 0.010228760054815211, Final Batch Loss: 3.9144797483459115e-05\n",
      "Epoch 1584, Loss: 0.005021281071094563, Final Batch Loss: 2.389977998973336e-05\n",
      "Epoch 1585, Loss: 0.010820803727256134, Final Batch Loss: 4.831141632166691e-05\n",
      "Epoch 1586, Loss: 0.009410478033260006, Final Batch Loss: 0.00010440032929182053\n",
      "Epoch 1587, Loss: 0.037855114536796464, Final Batch Loss: 0.0025799525901675224\n",
      "Epoch 1588, Loss: 0.008574478581067524, Final Batch Loss: 0.00336445146240294\n",
      "Epoch 1589, Loss: 0.012803978179192654, Final Batch Loss: 0.005927761550992727\n",
      "Epoch 1590, Loss: 0.02006741032289483, Final Batch Loss: 0.000546521448995918\n",
      "Epoch 1591, Loss: 0.022118970217889, Final Batch Loss: 2.6372430511401035e-05\n",
      "Epoch 1592, Loss: 0.020940875429005246, Final Batch Loss: 0.0010951056610792875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1593, Loss: 0.015231573703204049, Final Batch Loss: 3.680923691717908e-05\n",
      "Epoch 1594, Loss: 0.022980600129812956, Final Batch Loss: 1.9758022972382605e-05\n",
      "Epoch 1595, Loss: 0.02477574638396618, Final Batch Loss: 0.0019625204149633646\n",
      "Epoch 1596, Loss: 0.01318356941192178, Final Batch Loss: 0.00011769294360419735\n",
      "Epoch 1597, Loss: 0.015541022024308404, Final Batch Loss: 5.0139777158619836e-05\n",
      "Epoch 1598, Loss: 0.00913790906270151, Final Batch Loss: 0.0028176051564514637\n",
      "Epoch 1599, Loss: 0.020526341598042563, Final Batch Loss: 2.4493435830663657e-06\n",
      "Epoch 1600, Loss: 0.026444065795431015, Final Batch Loss: 2.854870672308607e-06\n",
      "Epoch 1601, Loss: 0.027340104857103142, Final Batch Loss: 0.003123038914054632\n",
      "Epoch 1602, Loss: 0.005497147531968949, Final Batch Loss: 3.71734713553451e-05\n",
      "Epoch 1603, Loss: 0.0026810834281150164, Final Batch Loss: 0.000499528890941292\n",
      "Epoch 1604, Loss: 0.004165698509950744, Final Batch Loss: 4.127203737880336e-06\n",
      "Epoch 1605, Loss: 0.0067268506033997255, Final Batch Loss: 0.00021346707944758236\n",
      "Epoch 1606, Loss: 0.009167996615815355, Final Batch Loss: 0.00460733100771904\n",
      "Epoch 1607, Loss: 0.013137679610508712, Final Batch Loss: 0.00015752139734104276\n",
      "Epoch 1608, Loss: 0.07134500378197117, Final Batch Loss: 0.023165276274085045\n",
      "Epoch 1609, Loss: 0.017388639827458974, Final Batch Loss: 2.231695907539688e-05\n",
      "Epoch 1610, Loss: 0.002612084201956577, Final Batch Loss: 2.035527904808987e-05\n",
      "Epoch 1611, Loss: 0.027845080652696197, Final Batch Loss: 2.247265183541458e-05\n",
      "Epoch 1612, Loss: 0.03391010011000617, Final Batch Loss: 0.000726064492482692\n",
      "Epoch 1613, Loss: 0.02657080822973512, Final Batch Loss: 0.003623650874942541\n",
      "Epoch 1614, Loss: 0.038648660854960326, Final Batch Loss: 0.0001744985784171149\n",
      "Epoch 1615, Loss: 0.008981647104519652, Final Batch Loss: 0.0001753975811880082\n",
      "Epoch 1616, Loss: 0.012159997324488359, Final Batch Loss: 0.0003683998656924814\n",
      "Epoch 1617, Loss: 0.004529711213308474, Final Batch Loss: 8.242329386121128e-06\n",
      "Epoch 1618, Loss: 0.00782374063055613, Final Batch Loss: 0.00043753033969551325\n",
      "Epoch 1619, Loss: 0.007893400366810965, Final Batch Loss: 1.2537630027509294e-05\n",
      "Epoch 1620, Loss: 0.009862619688078667, Final Batch Loss: 7.618649533469579e-07\n",
      "Epoch 1621, Loss: 0.014039257296644791, Final Batch Loss: 0.00023562485876027495\n",
      "Epoch 1622, Loss: 0.01606706942538949, Final Batch Loss: 4.617105150828138e-05\n",
      "Epoch 1623, Loss: 0.008672352709254483, Final Batch Loss: 0.0008239783346652985\n",
      "Epoch 1624, Loss: 0.016553476315522175, Final Batch Loss: 0.00013798463623970747\n",
      "Epoch 1625, Loss: 0.009797921762583428, Final Batch Loss: 8.581317524658516e-05\n",
      "Epoch 1626, Loss: 0.01702820640457503, Final Batch Loss: 8.133313531288877e-05\n",
      "Epoch 1627, Loss: 0.05530720116439625, Final Batch Loss: 1.0395589924883097e-05\n",
      "Epoch 1628, Loss: 0.010735117710282793, Final Batch Loss: 6.052307435311377e-05\n",
      "Epoch 1629, Loss: 0.009887186672131065, Final Batch Loss: 0.00030408668681047857\n",
      "Epoch 1630, Loss: 0.006681002666596214, Final Batch Loss: 5.220157981966622e-05\n",
      "Epoch 1631, Loss: 0.008893075362720992, Final Batch Loss: 0.0016075462335720658\n",
      "Epoch 1632, Loss: 0.009528558985039126, Final Batch Loss: 2.8947641112608835e-05\n",
      "Epoch 1633, Loss: 0.0013959496282041073, Final Batch Loss: 6.790706538595259e-05\n",
      "Epoch 1634, Loss: 0.05996521245469921, Final Batch Loss: 3.723008558154106e-05\n",
      "Epoch 1635, Loss: 0.013408853920282127, Final Batch Loss: 8.56522165122442e-05\n",
      "Epoch 1636, Loss: 0.0043316760588822945, Final Batch Loss: 0.0017657605931162834\n",
      "Epoch 1637, Loss: 0.016682776007655775, Final Batch Loss: 0.01401591394096613\n",
      "Epoch 1638, Loss: 0.003183075952620129, Final Batch Loss: 2.0137060346314684e-05\n",
      "Epoch 1639, Loss: 0.004873742750078236, Final Batch Loss: 4.445210379344644e-06\n",
      "Epoch 1640, Loss: 0.015938900211040163, Final Batch Loss: 0.0002524541050661355\n",
      "Epoch 1641, Loss: 0.018326001318200724, Final Batch Loss: 0.00017626614135224372\n",
      "Epoch 1642, Loss: 0.03191996365421801, Final Batch Loss: 7.466429087799042e-05\n",
      "Epoch 1643, Loss: 0.032598300585959805, Final Batch Loss: 0.00026564011932350695\n",
      "Epoch 1644, Loss: 0.010402416986835306, Final Batch Loss: 0.003170584561303258\n",
      "Epoch 1645, Loss: 0.012958352959685726, Final Batch Loss: 0.00010033792932517827\n",
      "Epoch 1646, Loss: 0.009521997624688083, Final Batch Loss: 0.0017735621659085155\n",
      "Epoch 1647, Loss: 0.004964118408224749, Final Batch Loss: 4.704037110059289e-06\n",
      "Epoch 1648, Loss: 0.06063882017042488, Final Batch Loss: 4.832589183934033e-05\n",
      "Epoch 1649, Loss: 0.01635681553489121, Final Batch Loss: 0.00013117864727973938\n",
      "Epoch 1650, Loss: 0.04352305573229387, Final Batch Loss: 0.0005987381446175277\n",
      "Epoch 1651, Loss: 0.019742148947898386, Final Batch Loss: 2.547657277318649e-05\n",
      "Epoch 1652, Loss: 0.004196781892460422, Final Batch Loss: 4.912811709800735e-05\n",
      "Epoch 1653, Loss: 0.04812177239728044, Final Batch Loss: 0.00022355727560352534\n",
      "Epoch 1654, Loss: 0.012974263994692592, Final Batch Loss: 1.4915262909198646e-05\n",
      "Epoch 1655, Loss: 0.030941937628085725, Final Batch Loss: 0.0015603969804942608\n",
      "Epoch 1656, Loss: 0.015216937626064464, Final Batch Loss: 0.0007086447440087795\n",
      "Epoch 1657, Loss: 0.007250648306126095, Final Batch Loss: 0.00011038238881155849\n",
      "Epoch 1658, Loss: 0.0018396141476841876, Final Batch Loss: 2.8751299396390095e-05\n",
      "Epoch 1659, Loss: 0.014726273006090196, Final Batch Loss: 0.003228417132049799\n",
      "Epoch 1660, Loss: 0.013680958854820346, Final Batch Loss: 0.0030497279949486256\n",
      "Epoch 1661, Loss: 0.008926462475301378, Final Batch Loss: 1.523417540738592e-05\n",
      "Epoch 1662, Loss: 0.0034831796697289974, Final Batch Loss: 0.0003006190818268806\n",
      "Epoch 1663, Loss: 0.009254397709810291, Final Batch Loss: 0.00036020667175762355\n",
      "Epoch 1664, Loss: 0.01813869686156977, Final Batch Loss: 0.00012804337893612683\n",
      "Epoch 1665, Loss: 0.0017734942446168134, Final Batch Loss: 3.153928628307767e-05\n",
      "Epoch 1666, Loss: 0.0016806473277029, Final Batch Loss: 4.74612306788913e-06\n",
      "Epoch 1667, Loss: 0.0014293430003817775, Final Batch Loss: 8.763706318859477e-06\n",
      "Epoch 1668, Loss: 0.003925645567960601, Final Batch Loss: 6.762325210729614e-05\n",
      "Epoch 1669, Loss: 0.0037339179498303565, Final Batch Loss: 0.00013734743697568774\n",
      "Epoch 1670, Loss: 0.0055620372627345205, Final Batch Loss: 2.0715549453598214e-06\n",
      "Epoch 1671, Loss: 0.004216683703589297, Final Batch Loss: 2.481609726601164e-06\n",
      "Epoch 1672, Loss: 0.004441334347575321, Final Batch Loss: 3.153957368340343e-05\n",
      "Epoch 1673, Loss: 0.0015882200923442724, Final Batch Loss: 1.785709355317522e-05\n",
      "Epoch 1674, Loss: 0.0010120587139681447, Final Batch Loss: 7.641437696292996e-05\n",
      "Epoch 1675, Loss: 0.0007090482445164525, Final Batch Loss: 4.399098543217406e-06\n",
      "Epoch 1676, Loss: 0.001275676825116534, Final Batch Loss: 2.137789488187991e-05\n",
      "Epoch 1677, Loss: 0.004243826274205276, Final Batch Loss: 0.0011416581692174077\n",
      "Epoch 1678, Loss: 0.001248416962198462, Final Batch Loss: 0.00011570873903110623\n",
      "Epoch 1679, Loss: 0.023609651214371752, Final Batch Loss: 0.0001859492767835036\n",
      "Epoch 1680, Loss: 0.003216920189515804, Final Batch Loss: 0.00011921089026145637\n",
      "Epoch 1681, Loss: 0.006394843911948556, Final Batch Loss: 2.0015533664263785e-05\n",
      "Epoch 1682, Loss: 0.038028153250706964, Final Batch Loss: 0.00015405773592647165\n",
      "Epoch 1683, Loss: 0.06191377515642671, Final Batch Loss: 0.00024180291802622378\n",
      "Epoch 1684, Loss: 0.039355651882942766, Final Batch Loss: 0.00046262977411970496\n",
      "Epoch 1685, Loss: 0.016783833816589322, Final Batch Loss: 0.005363996606320143\n",
      "Epoch 1686, Loss: 0.007733599759376375, Final Batch Loss: 3.947385266656056e-05\n",
      "Epoch 1687, Loss: 0.006934987870408804, Final Batch Loss: 0.0015129592502489686\n",
      "Epoch 1688, Loss: 0.016704803620541497, Final Batch Loss: 7.140225079638185e-06\n",
      "Epoch 1689, Loss: 0.0022366083994711516, Final Batch Loss: 0.00024899595882743597\n",
      "Epoch 1690, Loss: 0.020970586745534092, Final Batch Loss: 4.193860513623804e-05\n",
      "Epoch 1691, Loss: 0.005853810534517834, Final Batch Loss: 0.002531568519771099\n",
      "Epoch 1692, Loss: 0.04649746031827817, Final Batch Loss: 0.0002437896910123527\n",
      "Epoch 1693, Loss: 0.03239730200402846, Final Batch Loss: 0.0025382181629538536\n",
      "Epoch 1694, Loss: 0.02792220473929774, Final Batch Loss: 0.00041390364640392363\n",
      "Epoch 1695, Loss: 0.008006706017113174, Final Batch Loss: 6.46563057671301e-05\n",
      "Epoch 1696, Loss: 0.009228969878677162, Final Batch Loss: 0.0010481845820322633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1697, Loss: 0.005590378857050382, Final Batch Loss: 6.575406587217003e-05\n",
      "Epoch 1698, Loss: 0.00799895134923645, Final Batch Loss: 0.0001143647896242328\n",
      "Epoch 1699, Loss: 0.0027731302034226246, Final Batch Loss: 7.92871924204519e-06\n",
      "Epoch 1700, Loss: 0.045751411314995494, Final Batch Loss: 8.694565622135997e-05\n",
      "Epoch 1701, Loss: 0.009415317985258298, Final Batch Loss: 1.1147631084895693e-05\n",
      "Epoch 1702, Loss: 0.0039783828433428425, Final Batch Loss: 7.909311534604058e-05\n",
      "Epoch 1703, Loss: 0.005638499311316991, Final Batch Loss: 0.00010331488738302141\n",
      "Epoch 1704, Loss: 0.008749618745468979, Final Batch Loss: 3.1354535167338327e-05\n",
      "Epoch 1705, Loss: 0.03334988377764603, Final Batch Loss: 4.36617701780051e-05\n",
      "Epoch 1706, Loss: 0.007022428063919506, Final Batch Loss: 0.002833558712154627\n",
      "Epoch 1707, Loss: 0.02365850949445303, Final Batch Loss: 0.0054010446183383465\n",
      "Epoch 1708, Loss: 0.06675857438676758, Final Batch Loss: 0.0016730937641113997\n",
      "Epoch 1709, Loss: 0.021980135444664484, Final Batch Loss: 0.00023489062732551247\n",
      "Epoch 1710, Loss: 0.008023930642593768, Final Batch Loss: 0.0006446387269534171\n",
      "Epoch 1711, Loss: 0.021865639464522246, Final Batch Loss: 9.74558643065393e-05\n",
      "Epoch 1712, Loss: 0.0052018673850398045, Final Batch Loss: 0.0005392075981944799\n",
      "Epoch 1713, Loss: 0.014483810798992636, Final Batch Loss: 0.0008198742871172726\n",
      "Epoch 1714, Loss: 0.010192625880335981, Final Batch Loss: 0.00015811259800102562\n",
      "Epoch 1715, Loss: 0.013875249947886914, Final Batch Loss: 4.843588612857275e-05\n",
      "Epoch 1716, Loss: 0.018872126383939758, Final Batch Loss: 0.014044470153748989\n",
      "Epoch 1717, Loss: 0.0200073697087646, Final Batch Loss: 0.0009048950741998851\n",
      "Epoch 1718, Loss: 0.03489043170247896, Final Batch Loss: 3.127391391899437e-05\n",
      "Epoch 1719, Loss: 0.06340654155883385, Final Batch Loss: 0.001261721015907824\n",
      "Epoch 1720, Loss: 0.044011064113874454, Final Batch Loss: 0.016978440806269646\n",
      "Epoch 1721, Loss: 0.021884176287130686, Final Batch Loss: 0.0003630937135312706\n",
      "Epoch 1722, Loss: 0.03704977486086136, Final Batch Loss: 0.0033021073322743177\n",
      "Epoch 1723, Loss: 0.01160312821957632, Final Batch Loss: 0.00013911699352320284\n",
      "Epoch 1724, Loss: 0.004275463001249591, Final Batch Loss: 4.275510218576528e-05\n",
      "Epoch 1725, Loss: 0.001731794224724581, Final Batch Loss: 6.507253419840708e-05\n",
      "Epoch 1726, Loss: 0.0032660156966812792, Final Batch Loss: 1.254045946552651e-05\n",
      "Epoch 1727, Loss: 0.002080997574921639, Final Batch Loss: 3.834615563391708e-05\n",
      "Epoch 1728, Loss: 0.005581063590852864, Final Batch Loss: 0.0001472024741815403\n",
      "Epoch 1729, Loss: 0.005483424516569357, Final Batch Loss: 1.7257800209335983e-05\n",
      "Epoch 1730, Loss: 0.003112209371465724, Final Batch Loss: 0.0015935440314933658\n",
      "Epoch 1731, Loss: 0.0005126336127432296, Final Batch Loss: 2.1321309759514406e-05\n",
      "Epoch 1732, Loss: 0.03451805139638964, Final Batch Loss: 0.00032446408295072615\n",
      "Epoch 1733, Loss: 0.008208811696022167, Final Batch Loss: 4.5384542318060994e-05\n",
      "Epoch 1734, Loss: 0.01674596597389666, Final Batch Loss: 1.3473365470417775e-05\n",
      "Epoch 1735, Loss: 0.11697096145417163, Final Batch Loss: 0.00016894552391022444\n",
      "Epoch 1736, Loss: 0.038097907234259765, Final Batch Loss: 0.00013631940237246454\n",
      "Epoch 1737, Loss: 0.006740415859894711, Final Batch Loss: 1.4372099030879326e-05\n",
      "Epoch 1738, Loss: 0.030056910998609965, Final Batch Loss: 0.0007909854175522923\n",
      "Epoch 1739, Loss: 0.025899057862261543, Final Batch Loss: 0.0006574311410076916\n",
      "Epoch 1740, Loss: 0.021888276060053613, Final Batch Loss: 0.00030829900060780346\n",
      "Epoch 1741, Loss: 0.00786335477278044, Final Batch Loss: 0.0006189087289385498\n",
      "Epoch 1742, Loss: 0.009071995904378127, Final Batch Loss: 0.00025352093507535756\n",
      "Epoch 1743, Loss: 0.003447709137617494, Final Batch Loss: 2.5324139642179944e-05\n",
      "Epoch 1744, Loss: 0.05995991950658208, Final Batch Loss: 0.028302080929279327\n",
      "Epoch 1745, Loss: 0.006325758615275845, Final Batch Loss: 0.00018103804904967546\n",
      "Epoch 1746, Loss: 0.007470781358279055, Final Batch Loss: 8.710827387403697e-05\n",
      "Epoch 1747, Loss: 0.013841257721196598, Final Batch Loss: 0.003074293490499258\n",
      "Epoch 1748, Loss: 0.0034178816525809452, Final Batch Loss: 9.600459634384606e-06\n",
      "Epoch 1749, Loss: 0.0041163488658639835, Final Batch Loss: 0.00015403481665998697\n",
      "Epoch 1750, Loss: 0.014325350298349804, Final Batch Loss: 8.460907702101395e-05\n",
      "Epoch 1751, Loss: 0.008657431432766316, Final Batch Loss: 2.0952653358108364e-05\n",
      "Epoch 1752, Loss: 0.00984602502467169, Final Batch Loss: 9.16158314794302e-05\n",
      "Epoch 1753, Loss: 0.0027567150591494283, Final Batch Loss: 0.0001679322449490428\n",
      "Epoch 1754, Loss: 0.0035690667538403886, Final Batch Loss: 1.5297200661734678e-05\n",
      "Epoch 1755, Loss: 0.002493190732138828, Final Batch Loss: 0.00023101913393475115\n",
      "Epoch 1756, Loss: 0.006294660230423688, Final Batch Loss: 0.00010198416566709056\n",
      "Epoch 1757, Loss: 0.007583236279742778, Final Batch Loss: 0.0002727848768699914\n",
      "Epoch 1758, Loss: 0.0010574239909146854, Final Batch Loss: 0.00033333819010294974\n",
      "Epoch 1759, Loss: 0.00245902526376085, Final Batch Loss: 8.55201233207481e-06\n",
      "Epoch 1760, Loss: 0.0022238161909626797, Final Batch Loss: 0.0004266966425348073\n",
      "Epoch 1761, Loss: 0.019052974403166445, Final Batch Loss: 2.0806586690014228e-05\n",
      "Epoch 1762, Loss: 0.0012651272072616848, Final Batch Loss: 5.7383335843042005e-06\n",
      "Epoch 1763, Loss: 0.009139266075635533, Final Batch Loss: 0.000545698101632297\n",
      "Epoch 1764, Loss: 0.004281396930991832, Final Batch Loss: 0.0001960227091331035\n",
      "Epoch 1765, Loss: 0.004435548953324542, Final Batch Loss: 6.425840638257796e-06\n",
      "Epoch 1766, Loss: 0.0028078290888515767, Final Batch Loss: 3.637000190792605e-05\n",
      "Epoch 1767, Loss: 0.0022047754357572558, Final Batch Loss: 1.2553691703942604e-05\n",
      "Epoch 1768, Loss: 0.0016869228028326688, Final Batch Loss: 6.465239857789129e-05\n",
      "Epoch 1769, Loss: 0.0018405857479137921, Final Batch Loss: 7.15656133252196e-05\n",
      "Epoch 1770, Loss: 0.0008152139483854626, Final Batch Loss: 7.193656529125292e-06\n",
      "Epoch 1771, Loss: 0.004034883239910414, Final Batch Loss: 4.5809283619746566e-05\n",
      "Epoch 1772, Loss: 0.0007451486576428579, Final Batch Loss: 4.999460361432284e-05\n",
      "Epoch 1773, Loss: 0.027355135250672902, Final Batch Loss: 5.006436913390644e-05\n",
      "Epoch 1774, Loss: 0.013448280271290969, Final Batch Loss: 8.80373681866331e-06\n",
      "Epoch 1775, Loss: 0.041364759954376495, Final Batch Loss: 0.004844167735427618\n",
      "Epoch 1776, Loss: 0.016423306070009858, Final Batch Loss: 0.00021817786910105497\n",
      "Epoch 1777, Loss: 0.07010747215917945, Final Batch Loss: 0.0016650049947202206\n",
      "Epoch 1778, Loss: 0.04032030330745329, Final Batch Loss: 0.0002480158000253141\n",
      "Epoch 1779, Loss: 0.023839043211182798, Final Batch Loss: 3.8690744986524805e-05\n",
      "Epoch 1780, Loss: 0.0062735608053117176, Final Batch Loss: 3.161649874527939e-05\n",
      "Epoch 1781, Loss: 0.06977900403489912, Final Batch Loss: 8.867617907526437e-06\n",
      "Epoch 1782, Loss: 0.005903440749989386, Final Batch Loss: 1.5498844732064754e-05\n",
      "Epoch 1783, Loss: 0.004201364445179934, Final Batch Loss: 8.696681470610201e-05\n",
      "Epoch 1784, Loss: 0.012505946708188276, Final Batch Loss: 9.480983135290444e-05\n",
      "Epoch 1785, Loss: 0.013509688253179775, Final Batch Loss: 7.792916585458443e-05\n",
      "Epoch 1786, Loss: 0.010297605517735064, Final Batch Loss: 0.008369451388716698\n",
      "Epoch 1787, Loss: 0.01004340314352703, Final Batch Loss: 0.0001535650371806696\n",
      "Epoch 1788, Loss: 0.0036274415213028988, Final Batch Loss: 1.848774445534218e-05\n",
      "Epoch 1789, Loss: 0.0085311612847363, Final Batch Loss: 0.0007476512691937387\n",
      "Epoch 1790, Loss: 0.01034451129334002, Final Batch Loss: 5.782788502983749e-05\n",
      "Epoch 1791, Loss: 0.0014917948064976372, Final Batch Loss: 5.152507219463587e-05\n",
      "Epoch 1792, Loss: 0.0073169239822163945, Final Batch Loss: 8.337564941029996e-05\n",
      "Epoch 1793, Loss: 0.006694477197697779, Final Batch Loss: 0.00012152831186540425\n",
      "Epoch 1794, Loss: 0.04570119080381119, Final Batch Loss: 0.00018361146794632077\n",
      "Epoch 1795, Loss: 0.04871617750768564, Final Batch Loss: 0.00019871386757586151\n",
      "Epoch 1796, Loss: 0.013505810868082335, Final Batch Loss: 0.00017345871310681105\n",
      "Epoch 1797, Loss: 0.0022431689469613048, Final Batch Loss: 0.0001530612207716331\n",
      "Epoch 1798, Loss: 0.004865707092449156, Final Batch Loss: 6.4386513258796185e-06\n",
      "Epoch 1799, Loss: 0.01697447919809747, Final Batch Loss: 0.00011282591731287539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1800, Loss: 0.003143003105833486, Final Batch Loss: 0.0003262671525590122\n",
      "Epoch 1801, Loss: 0.008941676549056865, Final Batch Loss: 0.0003704050031956285\n",
      "Epoch 1802, Loss: 0.0018831245799901808, Final Batch Loss: 1.8596500012790784e-05\n",
      "Epoch 1803, Loss: 0.01764706035692143, Final Batch Loss: 0.007708519231528044\n",
      "Epoch 1804, Loss: 0.005846449391583519, Final Batch Loss: 0.00014576155808754265\n",
      "Epoch 1805, Loss: 0.01841160235380812, Final Batch Loss: 0.00015830021584406495\n",
      "Epoch 1806, Loss: 0.05161451547883189, Final Batch Loss: 0.00011248169903410599\n",
      "Epoch 1807, Loss: 0.010724029520133627, Final Batch Loss: 8.86369525687769e-05\n",
      "Epoch 1808, Loss: 0.010752009063253354, Final Batch Loss: 0.00022696054656989872\n",
      "Epoch 1809, Loss: 0.03976287263503764, Final Batch Loss: 0.017447752878069878\n",
      "Epoch 1810, Loss: 0.008206862062706932, Final Batch Loss: 0.00011037207150366157\n",
      "Epoch 1811, Loss: 0.007347719544441134, Final Batch Loss: 0.00029749434906989336\n",
      "Epoch 1812, Loss: 0.05077219805752975, Final Batch Loss: 0.00037966188392601907\n",
      "Epoch 1813, Loss: 0.0036776653414563043, Final Batch Loss: 0.0012765671126544476\n",
      "Epoch 1814, Loss: 0.014911361402482726, Final Batch Loss: 0.0008183510508388281\n",
      "Epoch 1815, Loss: 0.008419912221143022, Final Batch Loss: 4.323666144046001e-05\n",
      "Epoch 1816, Loss: 0.007803689476077125, Final Batch Loss: 1.306859303440433e-05\n",
      "Epoch 1817, Loss: 0.010339004957131692, Final Batch Loss: 0.00023909792071208358\n",
      "Epoch 1818, Loss: 0.0016829686519486131, Final Batch Loss: 1.489340138505213e-05\n",
      "Epoch 1819, Loss: 0.004610350506482064, Final Batch Loss: 9.028807653521653e-06\n",
      "Epoch 1820, Loss: 0.0026657159796741325, Final Batch Loss: 3.320596078992821e-05\n",
      "Epoch 1821, Loss: 0.024124610537228364, Final Batch Loss: 1.0067999937746208e-05\n",
      "Epoch 1822, Loss: 0.013895497719204286, Final Batch Loss: 0.009834049269557\n",
      "Epoch 1823, Loss: 0.004894661788512167, Final Batch Loss: 3.014376670762431e-05\n",
      "Epoch 1824, Loss: 0.002145701047879811, Final Batch Loss: 2.366506123507861e-05\n",
      "Epoch 1825, Loss: 0.005241446636773617, Final Batch Loss: 6.37530829408206e-05\n",
      "Epoch 1826, Loss: 0.029842584724974586, Final Batch Loss: 1.938224522746168e-05\n",
      "Epoch 1827, Loss: 0.016093734778223734, Final Batch Loss: 8.887526519174571e-07\n",
      "Epoch 1828, Loss: 0.011517010820739415, Final Batch Loss: 1.7851183429229422e-06\n",
      "Epoch 1829, Loss: 0.009063148864697723, Final Batch Loss: 1.0727299013524316e-05\n",
      "Epoch 1830, Loss: 0.004002528992486987, Final Batch Loss: 0.00012117358710383996\n",
      "Epoch 1831, Loss: 0.004116575729085525, Final Batch Loss: 0.00018368594464845955\n",
      "Epoch 1832, Loss: 0.001412467915315574, Final Batch Loss: 1.4299571375886444e-06\n",
      "Epoch 1833, Loss: 0.017044429533598304, Final Batch Loss: 0.00021927074703853577\n",
      "Epoch 1834, Loss: 0.005540445195947541, Final Batch Loss: 0.0001104688344639726\n",
      "Epoch 1835, Loss: 0.0016506590952758415, Final Batch Loss: 3.165242014802061e-05\n",
      "Epoch 1836, Loss: 0.0019083592524111737, Final Batch Loss: 2.4581053367001005e-05\n",
      "Epoch 1837, Loss: 0.003470868623480783, Final Batch Loss: 5.60105727345217e-05\n",
      "Epoch 1838, Loss: 0.006720187088376406, Final Batch Loss: 0.0016214001225307584\n",
      "Epoch 1839, Loss: 0.003312201244170865, Final Batch Loss: 0.0002825790143106133\n",
      "Epoch 1840, Loss: 0.005178979905394954, Final Batch Loss: 0.00042563737952150404\n",
      "Epoch 1841, Loss: 0.00563522632319291, Final Batch Loss: 0.0003434245300013572\n",
      "Epoch 1842, Loss: 0.010447127744100726, Final Batch Loss: 7.304197424673475e-06\n",
      "Epoch 1843, Loss: 0.019729678880139545, Final Batch Loss: 1.691246870905161e-05\n",
      "Epoch 1844, Loss: 0.011137395773857861, Final Batch Loss: 0.00011629746586550027\n",
      "Epoch 1845, Loss: 0.001925968784462384, Final Batch Loss: 0.00019009163952432573\n",
      "Epoch 1846, Loss: 0.0013955291130400838, Final Batch Loss: 6.665637920377776e-05\n",
      "Epoch 1847, Loss: 0.005243424507170857, Final Batch Loss: 1.9742006770684384e-05\n",
      "Epoch 1848, Loss: 0.004821896247449331, Final Batch Loss: 0.0002563897578511387\n",
      "Epoch 1849, Loss: 0.0031972963021758005, Final Batch Loss: 0.000799908593762666\n",
      "Epoch 1850, Loss: 0.0009688345375025165, Final Batch Loss: 1.6135007854245487e-06\n",
      "Epoch 1851, Loss: 0.013205766696955834, Final Batch Loss: 0.0019470934057608247\n",
      "Epoch 1852, Loss: 0.001609771879316213, Final Batch Loss: 3.056862624362111e-06\n",
      "Epoch 1853, Loss: 0.0029189513479650486, Final Batch Loss: 3.617973925429396e-05\n",
      "Epoch 1854, Loss: 0.0013408128220362414, Final Batch Loss: 8.039169188123196e-05\n",
      "Epoch 1855, Loss: 0.011654444429041178, Final Batch Loss: 1.0976197700074408e-05\n",
      "Epoch 1856, Loss: 0.018727077392213687, Final Batch Loss: 1.1851904673676472e-05\n",
      "Epoch 1857, Loss: 0.02890375400602352, Final Batch Loss: 0.00022154921316541731\n",
      "Epoch 1858, Loss: 0.01586947138935102, Final Batch Loss: 1.2122629868827062e-06\n",
      "Epoch 1859, Loss: 0.00386946008529776, Final Batch Loss: 0.000145528421853669\n",
      "Epoch 1860, Loss: 0.014321897817353602, Final Batch Loss: 3.7608617276418954e-05\n",
      "Epoch 1861, Loss: 0.009375932022521738, Final Batch Loss: 3.7547310057561845e-05\n",
      "Epoch 1862, Loss: 0.006911948498782294, Final Batch Loss: 2.2812520910520107e-05\n",
      "Epoch 1863, Loss: 0.0315613848592875, Final Batch Loss: 0.0001592231128597632\n",
      "Epoch 1864, Loss: 0.0019344182815075328, Final Batch Loss: 4.179646566626616e-05\n",
      "Epoch 1865, Loss: 0.007315621031011688, Final Batch Loss: 0.0032975736539810896\n",
      "Epoch 1866, Loss: 0.0026018841604127374, Final Batch Loss: 1.1265188732068054e-05\n",
      "Epoch 1867, Loss: 0.0026321462601117673, Final Batch Loss: 0.00023221939045470208\n",
      "Epoch 1868, Loss: 0.0018586310968657926, Final Batch Loss: 0.00011365422687958926\n",
      "Epoch 1869, Loss: 0.002362807016879742, Final Batch Loss: 0.0007098641945049167\n",
      "Epoch 1870, Loss: 0.01544960181490751, Final Batch Loss: 3.7975075883878162e-06\n",
      "Epoch 1871, Loss: 0.005748260773543734, Final Batch Loss: 1.0296264008502476e-05\n",
      "Epoch 1872, Loss: 0.002652281275757673, Final Batch Loss: 1.9329650967847556e-05\n",
      "Epoch 1873, Loss: 0.034454321669727506, Final Batch Loss: 1.1320556950522587e-05\n",
      "Epoch 1874, Loss: 0.019915626329293445, Final Batch Loss: 0.008666944690048695\n",
      "Epoch 1875, Loss: 0.07283164393248853, Final Batch Loss: 0.0001221988641191274\n",
      "Epoch 1876, Loss: 0.15901712126651546, Final Batch Loss: 0.04880096763372421\n",
      "Epoch 1877, Loss: 0.05669709790845445, Final Batch Loss: 0.004213572014123201\n",
      "Epoch 1878, Loss: 0.02190218190662563, Final Batch Loss: 0.0002699741453398019\n",
      "Epoch 1879, Loss: 0.017809253851737594, Final Batch Loss: 0.00026040535885840654\n",
      "Epoch 1880, Loss: 0.01885822725307662, Final Batch Loss: 6.904757174197584e-05\n",
      "Epoch 1881, Loss: 0.009366867219796404, Final Batch Loss: 6.469139771070331e-05\n",
      "Epoch 1882, Loss: 0.010241975700409967, Final Batch Loss: 0.0016399184241890907\n",
      "Epoch 1883, Loss: 0.007367534755758243, Final Batch Loss: 5.4595562687609345e-05\n",
      "Epoch 1884, Loss: 0.006742994623891718, Final Batch Loss: 0.0003930308448616415\n",
      "Epoch 1885, Loss: 0.0049427242838646634, Final Batch Loss: 0.00011697771697072312\n",
      "Epoch 1886, Loss: 0.012073086311829684, Final Batch Loss: 0.00055995600996539\n",
      "Epoch 1887, Loss: 0.004253774746644012, Final Batch Loss: 2.780998102025478e-06\n",
      "Epoch 1888, Loss: 0.003586561153497314, Final Batch Loss: 0.00015318006626330316\n",
      "Epoch 1889, Loss: 0.020072083207196556, Final Batch Loss: 4.562672256724909e-05\n",
      "Epoch 1890, Loss: 0.012382048282233882, Final Batch Loss: 0.0017618936253711581\n",
      "Epoch 1891, Loss: 0.004895638270681957, Final Batch Loss: 0.00025187135906890035\n",
      "Epoch 1892, Loss: 0.046309310808283044, Final Batch Loss: 5.356623660190962e-05\n",
      "Epoch 1893, Loss: 0.009324346717221488, Final Batch Loss: 6.47999404463917e-05\n",
      "Epoch 1894, Loss: 0.013438712271636177, Final Batch Loss: 0.0011365528916940093\n",
      "Epoch 1895, Loss: 0.01994435330016131, Final Batch Loss: 4.381682083476335e-05\n",
      "Epoch 1896, Loss: 0.011303829585813219, Final Batch Loss: 0.00020095882064197212\n",
      "Epoch 1897, Loss: 0.014679599607916316, Final Batch Loss: 0.002818083856254816\n",
      "Epoch 1898, Loss: 0.037276029641361674, Final Batch Loss: 0.0008256967412307858\n",
      "Epoch 1899, Loss: 0.009788859111722559, Final Batch Loss: 0.0002010353491641581\n",
      "Epoch 1900, Loss: 0.011810107420387794, Final Batch Loss: 0.0004424536891747266\n",
      "Epoch 1901, Loss: 0.01291713767022884, Final Batch Loss: 0.00017297336307819933\n",
      "Epoch 1902, Loss: 0.005217213296418777, Final Batch Loss: 1.9955063180532306e-05\n",
      "Epoch 1903, Loss: 0.002817822316501406, Final Batch Loss: 5.569175482378341e-05\n",
      "Epoch 1904, Loss: 0.006036851786120678, Final Batch Loss: 4.460683703655377e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1905, Loss: 0.001962348165079675, Final Batch Loss: 0.0005096772219985723\n",
      "Epoch 1906, Loss: 0.005447397921670927, Final Batch Loss: 7.256534445332363e-05\n",
      "Epoch 1907, Loss: 0.009917140287143411, Final Batch Loss: 1.3140126611688174e-05\n",
      "Epoch 1908, Loss: 0.005793763863948698, Final Batch Loss: 4.925742541672662e-05\n",
      "Epoch 1909, Loss: 0.005013551617139456, Final Batch Loss: 0.00032761841430328786\n",
      "Epoch 1910, Loss: 0.004718319287349004, Final Batch Loss: 0.0006229520076885819\n",
      "Epoch 1911, Loss: 0.0015808972402737709, Final Batch Loss: 5.2996096201241016e-05\n",
      "Epoch 1912, Loss: 0.005501229470837643, Final Batch Loss: 0.00013124225370120257\n",
      "Epoch 1913, Loss: 0.0019263073695583444, Final Batch Loss: 0.00029755276045762\n",
      "Epoch 1914, Loss: 0.0016861757662809396, Final Batch Loss: 1.2646464710996952e-06\n",
      "Epoch 1915, Loss: 0.006724434655097866, Final Batch Loss: 3.962988193961792e-05\n",
      "Epoch 1916, Loss: 0.002639649127559096, Final Batch Loss: 0.00022348816855810583\n",
      "Epoch 1917, Loss: 0.002013218007391515, Final Batch Loss: 4.777920139531489e-07\n",
      "Epoch 1918, Loss: 0.0025822147958933783, Final Batch Loss: 1.5446530596818775e-05\n",
      "Epoch 1919, Loss: 0.0028043339418672986, Final Batch Loss: 0.00015725736739113927\n",
      "Epoch 1920, Loss: 0.0016157398177938376, Final Batch Loss: 3.7558191252173856e-05\n",
      "Epoch 1921, Loss: 0.0007978570215527725, Final Batch Loss: 0.00015717830683570355\n",
      "Epoch 1922, Loss: 0.0003045753315973343, Final Batch Loss: 1.0626686162140686e-05\n",
      "Epoch 1923, Loss: 0.0010296756916829963, Final Batch Loss: 6.015057806507684e-06\n",
      "Epoch 1924, Loss: 0.007221545788524963, Final Batch Loss: 0.0014446863206103444\n",
      "Epoch 1925, Loss: 0.0010584826194417474, Final Batch Loss: 6.051672244211659e-06\n",
      "Epoch 1926, Loss: 0.0012583107618127087, Final Batch Loss: 1.7438619579479564e-06\n",
      "Epoch 1927, Loss: 0.007017241783614736, Final Batch Loss: 5.2675204642582685e-05\n",
      "Epoch 1928, Loss: 0.0005926741878283792, Final Batch Loss: 3.1396841222885996e-05\n",
      "Epoch 1929, Loss: 0.0035142837315333963, Final Batch Loss: 2.2600292140850797e-05\n",
      "Epoch 1930, Loss: 0.00033263007895811825, Final Batch Loss: 3.5561442928155884e-06\n",
      "Epoch 1931, Loss: 0.00306731864111498, Final Batch Loss: 2.218734698544722e-05\n",
      "Epoch 1932, Loss: 0.01271214046357727, Final Batch Loss: 1.1987417565251235e-05\n",
      "Epoch 1933, Loss: 0.037501587876363374, Final Batch Loss: 1.8654233144843602e-06\n",
      "Epoch 1934, Loss: 0.02316055737833267, Final Batch Loss: 6.371327617671341e-05\n",
      "Epoch 1935, Loss: 0.0075564813546407095, Final Batch Loss: 0.0009673105669207871\n",
      "Epoch 1936, Loss: 0.004437920825694164, Final Batch Loss: 0.00012514082482084632\n",
      "Epoch 1937, Loss: 0.005580455309427634, Final Batch Loss: 1.1813006494776346e-05\n",
      "Epoch 1938, Loss: 0.00339519263479815, Final Batch Loss: 0.00030614944989793\n",
      "Epoch 1939, Loss: 0.00572536504364507, Final Batch Loss: 1.3138066606188659e-05\n",
      "Epoch 1940, Loss: 0.01231346256827237, Final Batch Loss: 1.0036686035164166e-05\n",
      "Epoch 1941, Loss: 0.0031926426022437226, Final Batch Loss: 0.00013519806088879704\n",
      "Epoch 1942, Loss: 0.0026962792320546214, Final Batch Loss: 6.81639767208253e-06\n",
      "Epoch 1943, Loss: 0.0027480491606866053, Final Batch Loss: 0.00024266760738100857\n",
      "Epoch 1944, Loss: 0.0021729590358745554, Final Batch Loss: 5.8287547290092334e-05\n",
      "Epoch 1945, Loss: 0.000491366502501478, Final Batch Loss: 6.398702680598944e-05\n",
      "Epoch 1946, Loss: 0.0064757878235468525, Final Batch Loss: 6.488780491054058e-05\n",
      "Epoch 1947, Loss: 0.004010775587630633, Final Batch Loss: 4.995930794393644e-05\n",
      "Epoch 1948, Loss: 0.012887463972674595, Final Batch Loss: 0.00011889853340107948\n",
      "Epoch 1949, Loss: 0.0014282487787227183, Final Batch Loss: 0.0002864484558813274\n",
      "Epoch 1950, Loss: 0.0028377761116189504, Final Batch Loss: 7.882284080551472e-06\n",
      "Epoch 1951, Loss: 0.004779662506862792, Final Batch Loss: 3.660730044430238e-06\n",
      "Epoch 1952, Loss: 0.0007259320682351245, Final Batch Loss: 2.4187831513700075e-05\n",
      "Epoch 1953, Loss: 0.004307477678281657, Final Batch Loss: 4.390637332107872e-05\n",
      "Epoch 1954, Loss: 0.004860468834976928, Final Batch Loss: 0.00028788993950001895\n",
      "Epoch 1955, Loss: 0.006659406353492159, Final Batch Loss: 8.734023140277714e-05\n",
      "Epoch 1956, Loss: 0.005147293934555819, Final Batch Loss: 9.792506170924753e-05\n",
      "Epoch 1957, Loss: 0.001127280571040501, Final Batch Loss: 1.454309585824376e-05\n",
      "Epoch 1958, Loss: 0.01748712675376396, Final Batch Loss: 2.102783946611453e-05\n",
      "Epoch 1959, Loss: 0.003442733607471382, Final Batch Loss: 0.0013109705178067088\n",
      "Epoch 1960, Loss: 0.008385595833033221, Final Batch Loss: 0.00012417352991178632\n",
      "Epoch 1961, Loss: 0.00031903487001727626, Final Batch Loss: 8.973506737675052e-06\n",
      "Epoch 1962, Loss: 0.0016958915496161353, Final Batch Loss: 1.4289475984696764e-06\n",
      "Epoch 1963, Loss: 0.0008372580230116, Final Batch Loss: 2.0086506538063986e-06\n",
      "Epoch 1964, Loss: 0.0023743453380120627, Final Batch Loss: 1.922877345350571e-06\n",
      "Epoch 1965, Loss: 0.059107421957605766, Final Batch Loss: 1.7585694877197966e-05\n",
      "Epoch 1966, Loss: 0.09747430530842394, Final Batch Loss: 0.0007650222978554666\n",
      "Epoch 1967, Loss: 0.06450722970225797, Final Batch Loss: 0.000544929236639291\n",
      "Epoch 1968, Loss: 0.01089823780006327, Final Batch Loss: 5.239157303549291e-07\n",
      "Epoch 1969, Loss: 0.0551811877653563, Final Batch Loss: 0.0003465615736786276\n",
      "Epoch 1970, Loss: 0.004485314083467529, Final Batch Loss: 0.00043236554483883083\n",
      "Epoch 1971, Loss: 0.05841449530589671, Final Batch Loss: 0.00032572131021879613\n",
      "Epoch 1972, Loss: 0.008814834711301955, Final Batch Loss: 4.947259367327206e-05\n",
      "Epoch 1973, Loss: 0.037089258830746985, Final Batch Loss: 3.638366615632549e-05\n",
      "Epoch 1974, Loss: 0.002654407648151391, Final Batch Loss: 5.4332911531673744e-05\n",
      "Epoch 1975, Loss: 0.01426904252366512, Final Batch Loss: 2.8100905183237046e-05\n",
      "Epoch 1976, Loss: 0.021011365239928637, Final Batch Loss: 4.641621126211248e-05\n",
      "Epoch 1977, Loss: 0.002427857236853015, Final Batch Loss: 0.00015555767458863556\n",
      "Epoch 1978, Loss: 0.008384329818227343, Final Batch Loss: 2.5361625830555568e-06\n",
      "Epoch 1979, Loss: 0.0276401389764942, Final Batch Loss: 0.00011460721725597978\n",
      "Epoch 1980, Loss: 0.002595573879261792, Final Batch Loss: 0.00036799092777073383\n",
      "Epoch 1981, Loss: 0.0022669570464586286, Final Batch Loss: 3.55623742507305e-05\n",
      "Epoch 1982, Loss: 0.0014774805222259602, Final Batch Loss: 3.40713177138241e-06\n",
      "Epoch 1983, Loss: 0.006161535168757837, Final Batch Loss: 4.720933429780416e-05\n",
      "Epoch 1984, Loss: 0.0017912285277361661, Final Batch Loss: 2.245115638288553e-06\n",
      "Epoch 1985, Loss: 0.0020904111324853147, Final Batch Loss: 3.0725659598829225e-05\n",
      "Epoch 1986, Loss: 0.003507886995066656, Final Batch Loss: 1.1026094398403075e-05\n",
      "Epoch 1987, Loss: 0.005617975357836258, Final Batch Loss: 9.564864740241319e-05\n",
      "Epoch 1988, Loss: 0.014279315243584279, Final Batch Loss: 0.0004614125064108521\n",
      "Epoch 1989, Loss: 0.03727516929234298, Final Batch Loss: 0.0004686821484938264\n",
      "Epoch 1990, Loss: 0.004996211019488328, Final Batch Loss: 5.488068927661516e-05\n",
      "Epoch 1991, Loss: 0.00455805918193164, Final Batch Loss: 0.0028913395944982767\n",
      "Epoch 1992, Loss: 0.0011268989039763255, Final Batch Loss: 5.696390417142538e-06\n",
      "Epoch 1993, Loss: 0.004072499992219036, Final Batch Loss: 0.002589619252830744\n",
      "Epoch 1994, Loss: 0.022968661384311417, Final Batch Loss: 0.0004953189636580646\n",
      "Epoch 1995, Loss: 0.022876037429682583, Final Batch Loss: 3.086240030825138e-05\n",
      "Epoch 1996, Loss: 0.0036567691983009354, Final Batch Loss: 1.712938137643505e-05\n",
      "Epoch 1997, Loss: 0.004905971285893429, Final Batch Loss: 1.4207938647814444e-06\n",
      "Epoch 1998, Loss: 0.004258220801375501, Final Batch Loss: 0.003181236097589135\n",
      "Epoch 1999, Loss: 0.0012794861625025078, Final Batch Loss: 6.179050251375884e-05\n",
      "Epoch 2000, Loss: 0.0019355179292688263, Final Batch Loss: 0.00022495369194075465\n",
      "Epoch 2001, Loss: 0.0029615288972308917, Final Batch Loss: 9.297362339566462e-06\n",
      "Epoch 2002, Loss: 0.001316968178798561, Final Batch Loss: 5.240969767328352e-05\n",
      "Epoch 2003, Loss: 0.0025334891130057713, Final Batch Loss: 0.00011017080396413803\n",
      "Epoch 2004, Loss: 0.002161738631684784, Final Batch Loss: 6.348575698211789e-05\n",
      "Epoch 2005, Loss: 0.001709534441033611, Final Batch Loss: 7.089584869390819e-06\n",
      "Epoch 2006, Loss: 0.010745436942670494, Final Batch Loss: 8.665043424116448e-05\n",
      "Epoch 2007, Loss: 0.0018747197389075154, Final Batch Loss: 0.00010358762665418908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2008, Loss: 0.006956754105885921, Final Batch Loss: 0.00031610639416612685\n",
      "Epoch 2009, Loss: 0.0009453667334469174, Final Batch Loss: 1.6348090866813436e-05\n",
      "Epoch 2010, Loss: 0.0016560771691729315, Final Batch Loss: 3.312049375381321e-05\n",
      "Epoch 2011, Loss: 0.001688400746573393, Final Batch Loss: 1.7945345462067053e-05\n",
      "Epoch 2012, Loss: 0.01880493862995536, Final Batch Loss: 0.00021938577992841601\n",
      "Epoch 2013, Loss: 0.007192074079739541, Final Batch Loss: 1.2203596270410344e-05\n",
      "Epoch 2014, Loss: 0.00562404188463006, Final Batch Loss: 5.326653081283439e-06\n",
      "Epoch 2015, Loss: 0.002942486959454982, Final Batch Loss: 1.9881234038621187e-05\n",
      "Epoch 2016, Loss: 0.0017914937249940976, Final Batch Loss: 5.800936560262926e-05\n",
      "Epoch 2017, Loss: 0.00033834664577625517, Final Batch Loss: 1.827201595006045e-05\n",
      "Epoch 2018, Loss: 0.001154934187525214, Final Batch Loss: 3.2174990337807685e-05\n",
      "Epoch 2019, Loss: 0.0007608778053054266, Final Batch Loss: 0.00018370160250924528\n",
      "Epoch 2020, Loss: 0.0016835212161367963, Final Batch Loss: 0.0005146561306901276\n",
      "Epoch 2021, Loss: 0.0014442190276895417, Final Batch Loss: 0.0010027987882494926\n",
      "Epoch 2022, Loss: 0.0016067868764650939, Final Batch Loss: 2.7061886953561043e-07\n",
      "Epoch 2023, Loss: 0.0011023594395282998, Final Batch Loss: 2.176221642002929e-05\n",
      "Epoch 2024, Loss: 0.000522613505438585, Final Batch Loss: 4.806895594811067e-05\n",
      "Epoch 2025, Loss: 0.04360832381706814, Final Batch Loss: 8.065604788498604e-07\n",
      "Epoch 2026, Loss: 0.022546297085227707, Final Batch Loss: 0.0017419473733752966\n",
      "Epoch 2027, Loss: 0.01746766672715694, Final Batch Loss: 0.007809470873326063\n",
      "Epoch 2028, Loss: 0.030791531496106472, Final Batch Loss: 0.0001889287232188508\n",
      "Epoch 2029, Loss: 0.011129912320598123, Final Batch Loss: 6.061344492991338e-07\n",
      "Epoch 2030, Loss: 0.03804741617022955, Final Batch Loss: 0.0015269677387550473\n",
      "Epoch 2031, Loss: 0.00647365601224692, Final Batch Loss: 0.001592799206264317\n",
      "Epoch 2032, Loss: 0.013765452939878742, Final Batch Loss: 0.002295001409947872\n",
      "Epoch 2033, Loss: 0.006456757635987742, Final Batch Loss: 0.0007709790370427072\n",
      "Epoch 2034, Loss: 0.003824136960474789, Final Batch Loss: 2.4671169285284122e-06\n",
      "Epoch 2035, Loss: 0.0030801940904439107, Final Batch Loss: 0.0002460993127897382\n",
      "Epoch 2036, Loss: 0.0008689742801379907, Final Batch Loss: 9.956729627447203e-06\n",
      "Epoch 2037, Loss: 0.001781419950475538, Final Batch Loss: 3.450442454777658e-05\n",
      "Epoch 2038, Loss: 0.03402561568964302, Final Batch Loss: 0.0335225947201252\n",
      "Epoch 2039, Loss: 0.0018519074492360232, Final Batch Loss: 9.413095540367067e-05\n",
      "Epoch 2040, Loss: 0.0021996357118041487, Final Batch Loss: 2.8472544727264903e-05\n",
      "Epoch 2041, Loss: 0.0024855580934470822, Final Batch Loss: 0.0008798596099950373\n",
      "Epoch 2042, Loss: 0.03291254723262682, Final Batch Loss: 7.511864532716572e-05\n",
      "Epoch 2043, Loss: 0.08462072038668111, Final Batch Loss: 6.01385499976459e-06\n",
      "Epoch 2044, Loss: 0.12245208566400834, Final Batch Loss: 0.03504369780421257\n",
      "Epoch 2045, Loss: 0.139352139813127, Final Batch Loss: 0.00011616160918492824\n",
      "Epoch 2046, Loss: 0.025955107863410376, Final Batch Loss: 0.0025711541529744864\n",
      "Epoch 2047, Loss: 0.0734810877693235, Final Batch Loss: 9.527133806841448e-05\n",
      "Epoch 2048, Loss: 0.020920111259329133, Final Batch Loss: 0.00022965969401411712\n",
      "Epoch 2049, Loss: 0.013038292017881759, Final Batch Loss: 0.0005790286813862622\n",
      "Epoch 2050, Loss: 0.0070563032568315975, Final Batch Loss: 7.85526935942471e-05\n",
      "Epoch 2051, Loss: 0.007406413915305166, Final Batch Loss: 0.00011358795745763928\n",
      "Epoch 2052, Loss: 0.008916782424421399, Final Batch Loss: 9.63982311077416e-05\n",
      "Epoch 2053, Loss: 0.005329795776560786, Final Batch Loss: 0.002811047714203596\n",
      "Epoch 2054, Loss: 0.008378279486350948, Final Batch Loss: 0.005820866674184799\n",
      "Epoch 2055, Loss: 0.004692783762948238, Final Batch Loss: 0.00011737149907276034\n",
      "Epoch 2056, Loss: 0.020976690554107336, Final Batch Loss: 0.000150018124259077\n",
      "Epoch 2057, Loss: 0.006712038302794099, Final Batch Loss: 0.0002995769027620554\n",
      "Epoch 2058, Loss: 0.01756424807899748, Final Batch Loss: 2.2918151444173418e-05\n",
      "Epoch 2059, Loss: 0.005636552004943951, Final Batch Loss: 0.0001232300855917856\n",
      "Epoch 2060, Loss: 0.008156012059316708, Final Batch Loss: 0.00015938891738187522\n",
      "Epoch 2061, Loss: 0.02036431863598409, Final Batch Loss: 1.6750822396716103e-05\n",
      "Epoch 2062, Loss: 0.003708565708848255, Final Batch Loss: 2.1023683075327426e-05\n",
      "Epoch 2063, Loss: 0.001988009518754552, Final Batch Loss: 0.0005949889891780913\n",
      "Epoch 2064, Loss: 0.01137220374403114, Final Batch Loss: 0.009026915766298771\n",
      "Epoch 2065, Loss: 0.0014202758129613358, Final Batch Loss: 0.000160583556862548\n",
      "Epoch 2066, Loss: 0.00911823936746714, Final Batch Loss: 4.400971010909416e-05\n",
      "Epoch 2067, Loss: 0.01260542920044827, Final Batch Loss: 0.0007773196557536721\n",
      "Epoch 2068, Loss: 0.06098750335877412, Final Batch Loss: 0.00936419889330864\n",
      "Epoch 2069, Loss: 0.08450518171594013, Final Batch Loss: 0.00819624774158001\n",
      "Epoch 2070, Loss: 0.12237470576292253, Final Batch Loss: 0.000670043402351439\n",
      "Epoch 2071, Loss: 0.1908213292772416, Final Batch Loss: 0.031021850183606148\n",
      "Epoch 2072, Loss: 0.040548589306126814, Final Batch Loss: 0.0016876173904165626\n",
      "Epoch 2073, Loss: 0.042601577457389794, Final Batch Loss: 0.0003662701928988099\n",
      "Epoch 2074, Loss: 0.027174743430805393, Final Batch Loss: 0.00437587033957243\n",
      "Epoch 2075, Loss: 0.01494985096360324, Final Batch Loss: 0.0003291892644483596\n",
      "Epoch 2076, Loss: 0.02840130010008579, Final Batch Loss: 9.186353418044746e-05\n",
      "Epoch 2077, Loss: 0.02588429019670002, Final Batch Loss: 0.0003343940479680896\n",
      "Epoch 2078, Loss: 0.06982970303215552, Final Batch Loss: 0.001660766894929111\n",
      "Epoch 2079, Loss: 0.02022494531411212, Final Batch Loss: 0.00043089332757517695\n",
      "Epoch 2080, Loss: 0.02947130469692638, Final Batch Loss: 0.0028648427687585354\n",
      "Epoch 2081, Loss: 0.00942111938547896, Final Batch Loss: 0.00018389291653875262\n",
      "Epoch 2082, Loss: 0.010241072452117805, Final Batch Loss: 0.00019270200573373586\n",
      "Epoch 2083, Loss: 0.013796272553918243, Final Batch Loss: 0.0038768986705690622\n",
      "Epoch 2084, Loss: 0.005922515545535134, Final Batch Loss: 8.627876377431676e-05\n",
      "Epoch 2085, Loss: 0.00505121876267367, Final Batch Loss: 0.00021496502449736\n",
      "Epoch 2086, Loss: 0.00425668153047809, Final Batch Loss: 6.18672784185037e-05\n",
      "Epoch 2087, Loss: 0.03661786442535231, Final Batch Loss: 4.0306247683474794e-05\n",
      "Epoch 2088, Loss: 0.008314560927829007, Final Batch Loss: 0.0004699895216617733\n",
      "Epoch 2089, Loss: 0.006664428246949683, Final Batch Loss: 0.00019132763554807752\n",
      "Epoch 2090, Loss: 0.00855761973252811, Final Batch Loss: 0.0002201324823545292\n",
      "Epoch 2091, Loss: 0.004036011817333929, Final Batch Loss: 2.5806397388805635e-05\n",
      "Epoch 2092, Loss: 0.008300477333250456, Final Batch Loss: 6.216754263732582e-05\n",
      "Epoch 2093, Loss: 0.008131531878007081, Final Batch Loss: 3.769199611269869e-05\n",
      "Epoch 2094, Loss: 0.0018975017592310905, Final Batch Loss: 7.604567508678883e-05\n",
      "Epoch 2095, Loss: 0.003966065218264703, Final Batch Loss: 1.1855092452606186e-05\n",
      "Epoch 2096, Loss: 0.0027285138817205734, Final Batch Loss: 1.7195117834489793e-05\n",
      "Epoch 2097, Loss: 0.014108456971371197, Final Batch Loss: 0.00013005724758841097\n",
      "Epoch 2098, Loss: 0.0028686022978945402, Final Batch Loss: 0.0002146325132343918\n",
      "Epoch 2099, Loss: 0.003946170238123159, Final Batch Loss: 2.820214103849139e-05\n",
      "Epoch 2100, Loss: 0.0041197463147000235, Final Batch Loss: 4.2308879528718535e-06\n",
      "Epoch 2101, Loss: 0.0041805614082477405, Final Batch Loss: 0.0013543894747272134\n",
      "Epoch 2102, Loss: 0.00812632974157168, Final Batch Loss: 1.0602037946227938e-05\n",
      "Epoch 2103, Loss: 0.007226382691442268, Final Batch Loss: 6.914945697644725e-05\n",
      "Epoch 2104, Loss: 0.0013899216301069828, Final Batch Loss: 0.00029601651476696134\n",
      "Epoch 2105, Loss: 0.009696872977656312, Final Batch Loss: 0.00048573993262834847\n",
      "Epoch 2106, Loss: 0.0414146800629851, Final Batch Loss: 0.03983289748430252\n",
      "Epoch 2107, Loss: 0.003710027533088578, Final Batch Loss: 3.496446515782736e-05\n",
      "Epoch 2108, Loss: 0.0039000677097646985, Final Batch Loss: 9.675071851233952e-06\n",
      "Epoch 2109, Loss: 0.0008627340794191696, Final Batch Loss: 5.2531038818415254e-05\n",
      "Epoch 2110, Loss: 0.0028875792771430042, Final Batch Loss: 2.2121877918834798e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2111, Loss: 0.007554377165206461, Final Batch Loss: 2.33719329116866e-05\n",
      "Epoch 2112, Loss: 0.006189260027895216, Final Batch Loss: 3.231466325814836e-05\n",
      "Epoch 2113, Loss: 0.002854280335668591, Final Batch Loss: 4.813779014511965e-06\n",
      "Epoch 2114, Loss: 0.002413544324781469, Final Batch Loss: 4.6935532736824825e-05\n",
      "Epoch 2115, Loss: 0.005166146420719997, Final Batch Loss: 0.00053957145428285\n",
      "Epoch 2116, Loss: 0.0019572357555261988, Final Batch Loss: 1.0107824891747441e-05\n",
      "Epoch 2117, Loss: 0.0013487983278537286, Final Batch Loss: 4.059273123857565e-05\n",
      "Epoch 2118, Loss: 0.00425627365211767, Final Batch Loss: 8.658759725221898e-06\n",
      "Epoch 2119, Loss: 0.003985806755054, Final Batch Loss: 2.6060492018586956e-05\n",
      "Epoch 2120, Loss: 0.0015901304607268685, Final Batch Loss: 0.0005184222245588899\n",
      "Epoch 2121, Loss: 0.0008310928321861866, Final Batch Loss: 1.073161001841072e-05\n",
      "Epoch 2122, Loss: 0.0030292062937746778, Final Batch Loss: 0.0017847015988081694\n",
      "Epoch 2123, Loss: 0.003000970922698798, Final Batch Loss: 0.00020150870841462165\n",
      "Epoch 2124, Loss: 0.001043180746762573, Final Batch Loss: 3.3999215247604297e-06\n",
      "Epoch 2125, Loss: 0.0020111154801725206, Final Batch Loss: 0.00034710828913375735\n",
      "Epoch 2126, Loss: 0.003354871468673082, Final Batch Loss: 5.142447480466217e-05\n",
      "Epoch 2127, Loss: 0.0033822119039541576, Final Batch Loss: 0.00037791801150888205\n",
      "Epoch 2128, Loss: 0.029193697766800142, Final Batch Loss: 0.0003923111653421074\n",
      "Epoch 2129, Loss: 0.03609006146052707, Final Batch Loss: 1.4268770428316202e-05\n",
      "Epoch 2130, Loss: 0.01879347655994934, Final Batch Loss: 3.0034436349524185e-05\n",
      "Epoch 2131, Loss: 0.004074802437571634, Final Batch Loss: 0.0015252036973834038\n",
      "Epoch 2132, Loss: 0.005687414078238362, Final Batch Loss: 2.4253333322121762e-05\n",
      "Epoch 2133, Loss: 0.03733058151556179, Final Batch Loss: 0.00020094048522878438\n",
      "Epoch 2134, Loss: 0.003749168442652717, Final Batch Loss: 3.5050736187258735e-05\n",
      "Epoch 2135, Loss: 0.007015196187921902, Final Batch Loss: 0.00016682884597685188\n",
      "Epoch 2136, Loss: 0.001029082555533023, Final Batch Loss: 2.2222335246624425e-05\n",
      "Epoch 2137, Loss: 0.002072429129611919, Final Batch Loss: 6.716650386806577e-05\n",
      "Epoch 2138, Loss: 0.003325129159975404, Final Batch Loss: 6.671185838058591e-05\n",
      "Epoch 2139, Loss: 0.008916179229345289, Final Batch Loss: 3.414517777855508e-05\n",
      "Epoch 2140, Loss: 0.004893753482065222, Final Batch Loss: 5.0468879635445774e-05\n",
      "Epoch 2141, Loss: 0.0042703270514721225, Final Batch Loss: 3.669635043479502e-05\n",
      "Epoch 2142, Loss: 0.0007589768664502117, Final Batch Loss: 4.677693868870847e-05\n",
      "Epoch 2143, Loss: 0.005591702842821178, Final Batch Loss: 2.9636832550750114e-05\n",
      "Epoch 2144, Loss: 0.003896557862503869, Final Batch Loss: 0.000268187461188063\n",
      "Epoch 2145, Loss: 0.016093392394850525, Final Batch Loss: 0.00020937503722961992\n",
      "Epoch 2146, Loss: 0.054229387982559274, Final Batch Loss: 0.00022977104526944458\n",
      "Epoch 2147, Loss: 0.004892639319450609, Final Batch Loss: 0.0016936104511842132\n",
      "Epoch 2148, Loss: 0.0081901047028623, Final Batch Loss: 0.00030675652669742703\n",
      "Epoch 2149, Loss: 0.019490896141178382, Final Batch Loss: 0.0011701909825205803\n",
      "Epoch 2150, Loss: 0.01228847024458446, Final Batch Loss: 8.222927135648206e-05\n",
      "Epoch 2151, Loss: 0.0027890828179124583, Final Batch Loss: 0.00010437655873829499\n",
      "Epoch 2152, Loss: 0.017734783619062, Final Batch Loss: 0.005291237961500883\n",
      "Epoch 2153, Loss: 0.006202968582329049, Final Batch Loss: 0.00010157324140891433\n",
      "Epoch 2154, Loss: 0.0015216415140457684, Final Batch Loss: 2.2308118786895648e-05\n",
      "Epoch 2155, Loss: 0.012173643163237102, Final Batch Loss: 4.504165190155618e-05\n",
      "Epoch 2156, Loss: 0.00468870817746847, Final Batch Loss: 1.3132503227097914e-05\n",
      "Epoch 2157, Loss: 0.0018463324581716734, Final Batch Loss: 0.0001258414122276008\n",
      "Epoch 2158, Loss: 0.003109012894128682, Final Batch Loss: 4.468304541660473e-05\n",
      "Epoch 2159, Loss: 0.046644428172612606, Final Batch Loss: 0.003383974777534604\n",
      "Epoch 2160, Loss: 0.015178196534179733, Final Batch Loss: 0.00014157187251839787\n",
      "Epoch 2161, Loss: 0.002810115582178696, Final Batch Loss: 2.6911608074442483e-05\n",
      "Epoch 2162, Loss: 0.009640758876230393, Final Batch Loss: 0.0003225185500923544\n",
      "Epoch 2163, Loss: 0.0011598346964092343, Final Batch Loss: 6.696594937238842e-05\n",
      "Epoch 2164, Loss: 0.004516736895368467, Final Batch Loss: 0.000515341991558671\n",
      "Epoch 2165, Loss: 0.001893655527055671, Final Batch Loss: 0.00011908241140190512\n",
      "Epoch 2166, Loss: 0.0009170414396066917, Final Batch Loss: 2.5331015422125347e-05\n",
      "Epoch 2167, Loss: 0.0045521997503783496, Final Batch Loss: 2.206776298407931e-05\n",
      "Epoch 2168, Loss: 0.002837576289266508, Final Batch Loss: 4.316128251957707e-05\n",
      "Epoch 2169, Loss: 0.006952865163952993, Final Batch Loss: 2.0446800590434577e-06\n",
      "Epoch 2170, Loss: 0.014138654808903084, Final Batch Loss: 0.00016969424905255437\n",
      "Epoch 2171, Loss: 0.0032535917052882724, Final Batch Loss: 4.135167728236411e-06\n",
      "Epoch 2172, Loss: 0.0008963122513705457, Final Batch Loss: 3.0437508030445315e-05\n",
      "Epoch 2173, Loss: 0.00283345919160638, Final Batch Loss: 0.00015088576765265316\n",
      "Epoch 2174, Loss: 0.002403367836450343, Final Batch Loss: 0.0008805062971077859\n",
      "Epoch 2175, Loss: 0.0015375025352568628, Final Batch Loss: 1.395354729538667e-06\n",
      "Epoch 2176, Loss: 0.0557071682037531, Final Batch Loss: 2.973731398014934e-06\n",
      "Epoch 2177, Loss: 0.04963520291130408, Final Batch Loss: 3.83586848329287e-05\n",
      "Epoch 2178, Loss: 0.007868928893003613, Final Batch Loss: 0.0005401002708822489\n",
      "Epoch 2179, Loss: 0.01256266799828154, Final Batch Loss: 0.00016201061953324825\n",
      "Epoch 2180, Loss: 0.029183428489886865, Final Batch Loss: 0.000787627708632499\n",
      "Epoch 2181, Loss: 0.004531836966634728, Final Batch Loss: 0.00046642214874736965\n",
      "Epoch 2182, Loss: 0.021191234369325684, Final Batch Loss: 3.490827657515183e-05\n",
      "Epoch 2183, Loss: 0.01783028080069471, Final Batch Loss: 1.4047095646674279e-05\n",
      "Epoch 2184, Loss: 0.002988237479257805, Final Batch Loss: 3.0714261811226606e-05\n",
      "Epoch 2185, Loss: 0.0015894294622285088, Final Batch Loss: 7.422993803629652e-05\n",
      "Epoch 2186, Loss: 0.000982550468734189, Final Batch Loss: 1.2270704246475361e-05\n",
      "Epoch 2187, Loss: 0.0011290303658597622, Final Batch Loss: 0.0006240371149033308\n",
      "Epoch 2188, Loss: 0.02706367881614824, Final Batch Loss: 0.02610650099813938\n",
      "Epoch 2189, Loss: 0.004389616385026329, Final Batch Loss: 0.0001895332825370133\n",
      "Epoch 2190, Loss: 0.0013964996296635945, Final Batch Loss: 0.00024557276628911495\n",
      "Epoch 2191, Loss: 0.0012720807910682197, Final Batch Loss: 3.961950642406009e-05\n",
      "Epoch 2192, Loss: 0.003275747794873496, Final Batch Loss: 0.0005467217997647822\n",
      "Epoch 2193, Loss: 0.0028851491067598545, Final Batch Loss: 1.549883199913893e-05\n",
      "Epoch 2194, Loss: 0.0033003811267917627, Final Batch Loss: 6.224070239113644e-05\n",
      "Epoch 2195, Loss: 0.004121055122141115, Final Batch Loss: 0.0035639882553368807\n",
      "Epoch 2196, Loss: 0.02093738587154803, Final Batch Loss: 0.019921334460377693\n",
      "Epoch 2197, Loss: 0.00540203825039498, Final Batch Loss: 0.0011372590670362115\n",
      "Epoch 2198, Loss: 0.009738009111060819, Final Batch Loss: 0.00012182931823190302\n",
      "Epoch 2199, Loss: 0.006577829396974266, Final Batch Loss: 0.0006540394388139248\n",
      "Epoch 2200, Loss: 0.034154958187627926, Final Batch Loss: 0.0031363379675894976\n",
      "Epoch 2201, Loss: 0.0071761271628929535, Final Batch Loss: 0.001045631943270564\n",
      "Epoch 2202, Loss: 0.0012170413822332193, Final Batch Loss: 8.357031038030982e-05\n",
      "Epoch 2203, Loss: 0.0034885778782154375, Final Batch Loss: 4.250393612892367e-05\n",
      "Epoch 2204, Loss: 0.0022371962136276125, Final Batch Loss: 4.574963440973079e-06\n",
      "Epoch 2205, Loss: 0.002500157181202667, Final Batch Loss: 4.452884604688734e-05\n",
      "Epoch 2206, Loss: 0.001884409418209998, Final Batch Loss: 5.645951205224264e-06\n",
      "Epoch 2207, Loss: 0.0007982251754583558, Final Batch Loss: 2.875233803933952e-06\n",
      "Epoch 2208, Loss: 0.0017097126166163434, Final Batch Loss: 0.00018225505482405424\n",
      "Epoch 2209, Loss: 0.0024976452575629082, Final Batch Loss: 3.7142749533813912e-06\n",
      "Epoch 2210, Loss: 0.0005312788650826406, Final Batch Loss: 1.7262816982110962e-05\n",
      "Epoch 2211, Loss: 0.012079362325721377, Final Batch Loss: 0.009758717380464077\n",
      "Epoch 2212, Loss: 0.012695008083937864, Final Batch Loss: 0.0068312291987240314\n",
      "Epoch 2213, Loss: 0.0027109850152555737, Final Batch Loss: 0.0002643641200847924\n",
      "Epoch 2214, Loss: 0.005801596515539131, Final Batch Loss: 0.00026614053058438003\n",
      "Epoch 2215, Loss: 0.0009910806938933092, Final Batch Loss: 3.421116707613692e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2216, Loss: 0.001436065417692589, Final Batch Loss: 1.4890797501720954e-05\n",
      "Epoch 2217, Loss: 0.0022471546640190354, Final Batch Loss: 0.0008875525090843439\n",
      "Epoch 2218, Loss: 0.0006603317306144163, Final Batch Loss: 6.313579433481209e-06\n",
      "Epoch 2219, Loss: 0.003561438838687536, Final Batch Loss: 3.1002044124761596e-05\n",
      "Epoch 2220, Loss: 0.0007105920124104159, Final Batch Loss: 6.912584649398923e-05\n",
      "Epoch 2221, Loss: 0.003295284008743238, Final Batch Loss: 1.1788409210566897e-05\n",
      "Epoch 2222, Loss: 0.000646113195784892, Final Batch Loss: 1.903833617689088e-05\n",
      "Epoch 2223, Loss: 0.00307977707984719, Final Batch Loss: 0.00010844405915122479\n",
      "Epoch 2224, Loss: 0.0025869323692404578, Final Batch Loss: 4.23737546952907e-05\n",
      "Epoch 2225, Loss: 0.001307470836536595, Final Batch Loss: 3.781235500355251e-05\n",
      "Epoch 2226, Loss: 0.002725570992993198, Final Batch Loss: 0.00019688303291331977\n",
      "Epoch 2227, Loss: 0.05256442043094012, Final Batch Loss: 7.923347584437579e-05\n",
      "Epoch 2228, Loss: 0.013492525791662047, Final Batch Loss: 0.0007109621074050665\n",
      "Epoch 2229, Loss: 0.02806423738502417, Final Batch Loss: 0.00034622193197719753\n",
      "Epoch 2230, Loss: 0.008412251690060657, Final Batch Loss: 1.4727621419297066e-05\n",
      "Epoch 2231, Loss: 0.0053425148939822975, Final Batch Loss: 0.0002129497443092987\n",
      "Epoch 2232, Loss: 0.027423669995187083, Final Batch Loss: 8.076513950072695e-06\n",
      "Epoch 2233, Loss: 0.006908698876941344, Final Batch Loss: 9.827891335589811e-05\n",
      "Epoch 2234, Loss: 0.011508190888889658, Final Batch Loss: 6.386497261701152e-05\n",
      "Epoch 2235, Loss: 0.014677787139589782, Final Batch Loss: 1.1697687114065047e-05\n",
      "Epoch 2236, Loss: 0.0029743052211870236, Final Batch Loss: 0.0002132477966370061\n",
      "Epoch 2237, Loss: 0.003411425636841159, Final Batch Loss: 0.000115140741399955\n",
      "Epoch 2238, Loss: 0.0034694690230026026, Final Batch Loss: 2.0179466446279548e-05\n",
      "Epoch 2239, Loss: 0.028641824885653477, Final Batch Loss: 0.00011442612594692037\n",
      "Epoch 2240, Loss: 0.015943572172545828, Final Batch Loss: 5.334380330168642e-05\n",
      "Epoch 2241, Loss: 0.008104881951680909, Final Batch Loss: 0.0005338155897334218\n",
      "Epoch 2242, Loss: 0.03381133762695754, Final Batch Loss: 5.8329089370090514e-05\n",
      "Epoch 2243, Loss: 0.04599574658493566, Final Batch Loss: 0.0024249358102679253\n",
      "Epoch 2244, Loss: 0.0030374349780686316, Final Batch Loss: 0.00021076125267427415\n",
      "Epoch 2245, Loss: 0.0032266290354527882, Final Batch Loss: 0.00015892910596448928\n",
      "Epoch 2246, Loss: 0.006464773388870526, Final Batch Loss: 1.7923661289387383e-05\n",
      "Epoch 2247, Loss: 0.008729582880505404, Final Batch Loss: 0.0004235898668412119\n",
      "Epoch 2248, Loss: 0.005659434634253557, Final Batch Loss: 3.609904524637386e-05\n",
      "Epoch 2249, Loss: 0.0013970116815471556, Final Batch Loss: 6.032081364537589e-05\n",
      "Epoch 2250, Loss: 0.0019917230168857714, Final Batch Loss: 2.9990912935318192e-06\n",
      "Epoch 2251, Loss: 0.0007858704234422476, Final Batch Loss: 7.236801138787996e-06\n",
      "Epoch 2252, Loss: 0.0010412051583443827, Final Batch Loss: 1.0812711479957215e-05\n",
      "Epoch 2253, Loss: 0.0037995387731299957, Final Batch Loss: 0.0005068890750408173\n",
      "Epoch 2254, Loss: 0.017702192345936396, Final Batch Loss: 1.6556246919208206e-05\n",
      "Epoch 2255, Loss: 0.006271627641808664, Final Batch Loss: 2.6098143734998303e-06\n",
      "Epoch 2256, Loss: 0.016489033887864935, Final Batch Loss: 0.00018044908938463777\n",
      "Epoch 2257, Loss: 0.0021230080571967846, Final Batch Loss: 0.000363592233043164\n",
      "Epoch 2258, Loss: 0.002717328624385118, Final Batch Loss: 0.00025141151854768395\n",
      "Epoch 2259, Loss: 0.0014083620831115695, Final Batch Loss: 3.07379086734727e-05\n",
      "Epoch 2260, Loss: 0.003915041487061899, Final Batch Loss: 1.5544123016297817e-05\n",
      "Epoch 2261, Loss: 0.0007124704920897784, Final Batch Loss: 2.1329260562197305e-05\n",
      "Epoch 2262, Loss: 0.0007063676066536573, Final Batch Loss: 2.3344640794675797e-05\n",
      "Epoch 2263, Loss: 0.024521432619508232, Final Batch Loss: 4.621444895747118e-05\n",
      "Epoch 2264, Loss: 0.006742836141256703, Final Batch Loss: 6.3562060859112535e-06\n",
      "Epoch 2265, Loss: 0.004569476452161325, Final Batch Loss: 0.00032655042014084756\n",
      "Epoch 2266, Loss: 0.016069331644189333, Final Batch Loss: 1.1588930419748067e-06\n",
      "Epoch 2267, Loss: 0.0016867269296199083, Final Batch Loss: 4.206495941616595e-05\n",
      "Epoch 2268, Loss: 0.06659879232392996, Final Batch Loss: 0.005416324362158775\n",
      "Epoch 2269, Loss: 0.009340989576685388, Final Batch Loss: 4.0519687900086865e-05\n",
      "Epoch 2270, Loss: 0.022783086015010667, Final Batch Loss: 2.04229331757233e-06\n",
      "Epoch 2271, Loss: 0.039664997363217935, Final Batch Loss: 6.07085496540094e-07\n",
      "Epoch 2272, Loss: 0.028568950688168115, Final Batch Loss: 0.022613883018493652\n",
      "Epoch 2273, Loss: 0.00972484524390893, Final Batch Loss: 0.0017312114359810948\n",
      "Epoch 2274, Loss: 0.018661975679606257, Final Batch Loss: 0.01538195088505745\n",
      "Epoch 2275, Loss: 0.004214898186774008, Final Batch Loss: 0.0003218564379494637\n",
      "Epoch 2276, Loss: 0.04214425457575999, Final Batch Loss: 5.001994577469304e-05\n",
      "Epoch 2277, Loss: 0.01809189740652073, Final Batch Loss: 8.148167398758233e-05\n",
      "Epoch 2278, Loss: 0.004088131321623223, Final Batch Loss: 0.0016517031472176313\n",
      "Epoch 2279, Loss: 0.007194747664470924, Final Batch Loss: 3.2636671676300466e-05\n",
      "Epoch 2280, Loss: 0.0026300140143575845, Final Batch Loss: 4.8464135034009814e-05\n",
      "Epoch 2281, Loss: 0.011289235997537617, Final Batch Loss: 7.782782631693408e-06\n",
      "Epoch 2282, Loss: 0.03823840714630933, Final Batch Loss: 0.01013245154172182\n",
      "Epoch 2283, Loss: 0.0549339559429427, Final Batch Loss: 0.002229968085885048\n",
      "Epoch 2284, Loss: 0.007655740146219614, Final Batch Loss: 0.00018047969206236303\n",
      "Epoch 2285, Loss: 0.002186324796639383, Final Batch Loss: 3.629576167440973e-05\n",
      "Epoch 2286, Loss: 0.0024306583623001643, Final Batch Loss: 8.127996261464432e-05\n",
      "Epoch 2287, Loss: 0.0011796555687624277, Final Batch Loss: 8.551536302547902e-05\n",
      "Epoch 2288, Loss: 0.0038292892645586107, Final Batch Loss: 7.665553857805207e-05\n",
      "Epoch 2289, Loss: 0.005817189156914537, Final Batch Loss: 0.003245601197704673\n",
      "Epoch 2290, Loss: 0.015266663029763095, Final Batch Loss: 0.0019274565856903791\n",
      "Epoch 2291, Loss: 0.0008192003845124418, Final Batch Loss: 5.260348189040087e-05\n",
      "Epoch 2292, Loss: 0.00873238270787624, Final Batch Loss: 3.740496686077677e-05\n",
      "Epoch 2293, Loss: 0.0052302360209068866, Final Batch Loss: 0.00017589972412679344\n",
      "Epoch 2294, Loss: 0.03792696027153397, Final Batch Loss: 2.3133791273721727e-06\n",
      "Epoch 2295, Loss: 0.11709722382511245, Final Batch Loss: 3.4735770896077156e-05\n",
      "Epoch 2296, Loss: 0.01812756476147115, Final Batch Loss: 0.0001086044212570414\n",
      "Epoch 2297, Loss: 0.05957787075294618, Final Batch Loss: 0.0007698761764913797\n",
      "Epoch 2298, Loss: 0.010552549616022588, Final Batch Loss: 0.0005050903419032693\n",
      "Epoch 2299, Loss: 0.0026705052709985466, Final Batch Loss: 3.2412823202321306e-05\n",
      "Epoch 2300, Loss: 0.044808852042478975, Final Batch Loss: 4.206484300084412e-05\n",
      "Epoch 2301, Loss: 0.008803077224001754, Final Batch Loss: 7.144055416574702e-05\n",
      "Epoch 2302, Loss: 0.008605562743468909, Final Batch Loss: 1.8223141523776576e-05\n",
      "Epoch 2303, Loss: 0.0077317492659858544, Final Batch Loss: 1.222622722707456e-05\n",
      "Epoch 2304, Loss: 0.00475814941637509, Final Batch Loss: 4.432236892171204e-05\n",
      "Epoch 2305, Loss: 0.0037957425251988752, Final Batch Loss: 4.463177174329758e-05\n",
      "Epoch 2306, Loss: 0.0032119377865456045, Final Batch Loss: 8.70763324201107e-05\n",
      "Epoch 2307, Loss: 0.004993143943011091, Final Batch Loss: 9.29959333006991e-06\n",
      "Epoch 2308, Loss: 0.0025229952066183614, Final Batch Loss: 0.00014486353029496968\n",
      "Epoch 2309, Loss: 0.015178498269051488, Final Batch Loss: 0.003158329054713249\n",
      "Epoch 2310, Loss: 0.002229144037301012, Final Batch Loss: 7.16308131814003e-05\n",
      "Epoch 2311, Loss: 0.008247543598372431, Final Batch Loss: 0.0003979208995588124\n",
      "Epoch 2312, Loss: 0.002394687967353093, Final Batch Loss: 7.86741202318808e-06\n",
      "Epoch 2313, Loss: 0.001520199104106723, Final Batch Loss: 4.4158132368465886e-05\n",
      "Epoch 2314, Loss: 0.002602156847842707, Final Batch Loss: 2.3090340619091876e-05\n",
      "Epoch 2315, Loss: 0.000987368425171553, Final Batch Loss: 1.4399923884411692e-06\n",
      "Epoch 2316, Loss: 0.0017390321399943787, Final Batch Loss: 0.0003954259736929089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2317, Loss: 0.0006726654468138804, Final Batch Loss: 1.985965354833752e-05\n",
      "Epoch 2318, Loss: 0.017120146144407045, Final Batch Loss: 0.0003090169047936797\n",
      "Epoch 2319, Loss: 0.0019579300901568786, Final Batch Loss: 9.519430932414252e-06\n",
      "Epoch 2320, Loss: 0.014141149599709024, Final Batch Loss: 7.693354746152181e-06\n",
      "Epoch 2321, Loss: 0.042131740619879565, Final Batch Loss: 0.003822099883109331\n",
      "Epoch 2322, Loss: 0.013336872067156946, Final Batch Loss: 1.651561979088001e-05\n",
      "Epoch 2323, Loss: 0.021664432590796423, Final Batch Loss: 0.0021497441921383142\n",
      "Epoch 2324, Loss: 0.004574265295559599, Final Batch Loss: 3.88934749935288e-05\n",
      "Epoch 2325, Loss: 0.006125461661213194, Final Batch Loss: 0.00015264471585396677\n",
      "Epoch 2326, Loss: 0.04143962831813042, Final Batch Loss: 5.2733706979779527e-05\n",
      "Epoch 2327, Loss: 0.0031299138126996695, Final Batch Loss: 3.7700057873735204e-05\n",
      "Epoch 2328, Loss: 0.003950198884922429, Final Batch Loss: 0.00013970962027087808\n",
      "Epoch 2329, Loss: 0.007097473713656655, Final Batch Loss: 2.4386590666836128e-05\n",
      "Epoch 2330, Loss: 0.005513883736057323, Final Batch Loss: 1.5579154933220707e-05\n",
      "Epoch 2331, Loss: 0.011550031355909596, Final Batch Loss: 4.251001519151032e-05\n",
      "Epoch 2332, Loss: 0.0020757436861913448, Final Batch Loss: 1.152779168478446e-05\n",
      "Epoch 2333, Loss: 0.0013478335618515302, Final Batch Loss: 5.498668542713858e-05\n",
      "Epoch 2334, Loss: 0.0013795569143439934, Final Batch Loss: 0.00017638446297496557\n",
      "Epoch 2335, Loss: 0.0007466047181878821, Final Batch Loss: 0.00023660261649638414\n",
      "Epoch 2336, Loss: 0.004086446575456648, Final Batch Loss: 3.841467696474865e-05\n",
      "Epoch 2337, Loss: 0.0008383018041513424, Final Batch Loss: 2.331727955606766e-05\n",
      "Epoch 2338, Loss: 0.0009710318727229605, Final Batch Loss: 7.166042632889003e-05\n",
      "Epoch 2339, Loss: 0.0012212420490982367, Final Batch Loss: 9.357820817967877e-05\n",
      "Epoch 2340, Loss: 0.002397857326968733, Final Batch Loss: 4.7671842366980854e-06\n",
      "Epoch 2341, Loss: 0.002608117247405062, Final Batch Loss: 3.5747038054978475e-05\n",
      "Epoch 2342, Loss: 0.0016059620115242978, Final Batch Loss: 2.0942179617122747e-05\n",
      "Epoch 2343, Loss: 0.0033631243054514925, Final Batch Loss: 0.0001686474570306018\n",
      "Epoch 2344, Loss: 0.002036485552252998, Final Batch Loss: 0.00022857713338453323\n",
      "Epoch 2345, Loss: 0.0009947455778274161, Final Batch Loss: 6.791380292270333e-05\n",
      "Epoch 2346, Loss: 0.0009107086452786461, Final Batch Loss: 4.258577973814681e-05\n",
      "Epoch 2347, Loss: 0.0312743336960466, Final Batch Loss: 0.00048727175453677773\n",
      "Epoch 2348, Loss: 0.10330059759326105, Final Batch Loss: 0.005060478579252958\n",
      "Epoch 2349, Loss: 0.12299650797285722, Final Batch Loss: 5.750232594436966e-05\n",
      "Epoch 2350, Loss: 0.07395157332848612, Final Batch Loss: 0.009616314433515072\n",
      "Epoch 2351, Loss: 0.09142950905152247, Final Batch Loss: 3.931473838747479e-05\n",
      "Epoch 2352, Loss: 0.027059579151682556, Final Batch Loss: 0.00627621915191412\n",
      "Epoch 2353, Loss: 0.050107930812373525, Final Batch Loss: 0.0008477198425680399\n",
      "Epoch 2354, Loss: 0.008338895000633784, Final Batch Loss: 0.0001244939921889454\n",
      "Epoch 2355, Loss: 0.010851996134078945, Final Batch Loss: 2.1311470845830627e-05\n",
      "Epoch 2356, Loss: 0.008381532865314512, Final Batch Loss: 0.00046997572644613683\n",
      "Epoch 2357, Loss: 0.004956756132742157, Final Batch Loss: 0.0001776421268004924\n",
      "Epoch 2358, Loss: 0.005860596194906975, Final Batch Loss: 0.0007899272022768855\n",
      "Epoch 2359, Loss: 0.007732448673777981, Final Batch Loss: 0.00048329224227927625\n",
      "Epoch 2360, Loss: 0.010067848998005502, Final Batch Loss: 3.3757143683033064e-05\n",
      "Epoch 2361, Loss: 0.03679741900032241, Final Batch Loss: 0.01989143155515194\n",
      "Epoch 2362, Loss: 0.014204225521098124, Final Batch Loss: 0.002087078522890806\n",
      "Epoch 2363, Loss: 0.011795823184002074, Final Batch Loss: 4.116246782359667e-05\n",
      "Epoch 2364, Loss: 0.027178655875104596, Final Batch Loss: 0.0002483910939190537\n",
      "Epoch 2365, Loss: 0.002494124628356076, Final Batch Loss: 2.1368088710005395e-05\n",
      "Epoch 2366, Loss: 0.014742075796675636, Final Batch Loss: 0.0011063202982768416\n",
      "Epoch 2367, Loss: 0.009727710787046817, Final Batch Loss: 7.297407137230039e-05\n",
      "Epoch 2368, Loss: 0.009905280536258942, Final Batch Loss: 8.431629976257682e-05\n",
      "Epoch 2369, Loss: 0.003822501557351643, Final Batch Loss: 0.00031458184821531177\n",
      "Epoch 2370, Loss: 0.02679451377252917, Final Batch Loss: 2.1865257622266654e-06\n",
      "Epoch 2371, Loss: 0.004203645191410033, Final Batch Loss: 0.0002462797856424004\n",
      "Epoch 2372, Loss: 0.004037436555336171, Final Batch Loss: 4.313273529987782e-05\n",
      "Epoch 2373, Loss: 0.00792689775244071, Final Batch Loss: 0.0001291095104534179\n",
      "Epoch 2374, Loss: 0.034306088101402565, Final Batch Loss: 0.0001523158571217209\n",
      "Epoch 2375, Loss: 0.006620881025810377, Final Batch Loss: 0.00014214488328434527\n",
      "Epoch 2376, Loss: 0.0078230979743239, Final Batch Loss: 0.00031996608595363796\n",
      "Epoch 2377, Loss: 0.0530541596817784, Final Batch Loss: 0.0005988999619148672\n",
      "Epoch 2378, Loss: 0.007304767605546658, Final Batch Loss: 3.012524757650681e-05\n",
      "Epoch 2379, Loss: 0.005345567491303882, Final Batch Loss: 8.1174530350836e-06\n",
      "Epoch 2380, Loss: 0.0032566605677857297, Final Batch Loss: 0.00011232359247514978\n",
      "Epoch 2381, Loss: 0.003010409796388558, Final Batch Loss: 1.2360444088699296e-05\n",
      "Epoch 2382, Loss: 0.003784444103075657, Final Batch Loss: 0.00013194294297136366\n",
      "Epoch 2383, Loss: 0.000949207735800428, Final Batch Loss: 0.0002326412359252572\n",
      "Epoch 2384, Loss: 0.0011869447958474666, Final Batch Loss: 0.00012294047337491065\n",
      "Epoch 2385, Loss: 0.017816393468137903, Final Batch Loss: 3.0136009172565537e-06\n",
      "Epoch 2386, Loss: 0.0033255740763706854, Final Batch Loss: 0.0003054131520912051\n",
      "Epoch 2387, Loss: 0.04848387907622964, Final Batch Loss: 0.0022803342435508966\n",
      "Epoch 2388, Loss: 0.004667859546316322, Final Batch Loss: 0.0005394526524469256\n",
      "Epoch 2389, Loss: 0.008819930166282575, Final Batch Loss: 9.899840370053425e-05\n",
      "Epoch 2390, Loss: 0.004984581670328225, Final Batch Loss: 6.030097574694082e-05\n",
      "Epoch 2391, Loss: 0.0019849129330395954, Final Batch Loss: 0.0007125937263481319\n",
      "Epoch 2392, Loss: 0.003341743306691569, Final Batch Loss: 0.00011839516082545742\n",
      "Epoch 2393, Loss: 0.004128625524572271, Final Batch Loss: 0.0002482801501173526\n",
      "Epoch 2394, Loss: 0.0017286311733641924, Final Batch Loss: 4.676572643802501e-05\n",
      "Epoch 2395, Loss: 0.0017492881879661581, Final Batch Loss: 0.0005815398180857301\n",
      "Epoch 2396, Loss: 0.023736846962037816, Final Batch Loss: 0.0006388447945937514\n",
      "Epoch 2397, Loss: 0.028406268028447812, Final Batch Loss: 0.0008736145682632923\n",
      "Epoch 2398, Loss: 0.04026871000405663, Final Batch Loss: 0.010607448406517506\n",
      "Epoch 2399, Loss: 0.00751566656617797, Final Batch Loss: 1.98649795493111e-05\n",
      "Epoch 2400, Loss: 0.005642680913297227, Final Batch Loss: 0.00016545370453968644\n",
      "Epoch 2401, Loss: 0.005852280605722626, Final Batch Loss: 8.357065235031769e-05\n",
      "Epoch 2402, Loss: 0.015575670835460187, Final Batch Loss: 0.00013537921768147498\n",
      "Epoch 2403, Loss: 0.004748151867090655, Final Batch Loss: 1.617949783394579e-05\n",
      "Epoch 2404, Loss: 0.0030898393160896376, Final Batch Loss: 7.164812268456444e-05\n",
      "Epoch 2405, Loss: 0.010878821531150606, Final Batch Loss: 0.006743068806827068\n",
      "Epoch 2406, Loss: 0.006963171853271888, Final Batch Loss: 0.0009018983691930771\n",
      "Epoch 2407, Loss: 0.0025084963048129794, Final Batch Loss: 5.971143036731519e-05\n",
      "Epoch 2408, Loss: 0.024456029020484493, Final Batch Loss: 8.86817360878922e-07\n",
      "Epoch 2409, Loss: 0.004306981184527103, Final Batch Loss: 5.518060061149299e-05\n",
      "Epoch 2410, Loss: 0.003089160509262001, Final Batch Loss: 7.370208913926035e-05\n",
      "Epoch 2411, Loss: 0.01828024176438703, Final Batch Loss: 0.0024848743341863155\n",
      "Epoch 2412, Loss: 0.01981328422061779, Final Batch Loss: 0.0001410813129041344\n",
      "Epoch 2413, Loss: 0.04049401531665353, Final Batch Loss: 5.9635218349285424e-05\n",
      "Epoch 2414, Loss: 0.045623383967658526, Final Batch Loss: 0.032005421817302704\n",
      "Epoch 2415, Loss: 0.05079299802764581, Final Batch Loss: 0.00011365114187356085\n",
      "Epoch 2416, Loss: 0.0008999076900408909, Final Batch Loss: 1.7030373783200048e-05\n",
      "Epoch 2417, Loss: 0.02411677433389059, Final Batch Loss: 4.8209574742941186e-05\n",
      "Epoch 2418, Loss: 0.02329682851450343, Final Batch Loss: 0.0001532487804070115\n",
      "Epoch 2419, Loss: 0.002739096933964902, Final Batch Loss: 0.00035744375782087445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2420, Loss: 0.003526534636307588, Final Batch Loss: 0.001604248071089387\n",
      "Epoch 2421, Loss: 0.01565462320269262, Final Batch Loss: 1.7744099750416353e-05\n",
      "Epoch 2422, Loss: 0.01797818402701523, Final Batch Loss: 0.004322543740272522\n",
      "Epoch 2423, Loss: 0.014060646297366475, Final Batch Loss: 0.00014940409164410084\n",
      "Epoch 2424, Loss: 0.002882443578528182, Final Batch Loss: 4.811920462088892e-06\n",
      "Epoch 2425, Loss: 0.0019085020344391523, Final Batch Loss: 4.880877531832084e-05\n",
      "Epoch 2426, Loss: 0.0021253492541291052, Final Batch Loss: 3.63178041880019e-05\n",
      "Epoch 2427, Loss: 0.002486624991433928, Final Batch Loss: 0.0001319627626799047\n",
      "Epoch 2428, Loss: 0.0024043655031960043, Final Batch Loss: 0.0017540904227644205\n",
      "Epoch 2429, Loss: 0.04196280194901192, Final Batch Loss: 5.231602699495852e-05\n",
      "Epoch 2430, Loss: 0.003523813572655854, Final Batch Loss: 2.1352427665988216e-06\n",
      "Epoch 2431, Loss: 0.007117216430742701, Final Batch Loss: 0.0005145865143276751\n",
      "Epoch 2432, Loss: 0.0011572601400047233, Final Batch Loss: 5.2433483688218985e-06\n",
      "Epoch 2433, Loss: 0.0018975748116645264, Final Batch Loss: 9.613361180527136e-05\n",
      "Epoch 2434, Loss: 0.002430901295156218, Final Batch Loss: 3.465393547230633e-06\n",
      "Epoch 2435, Loss: 0.0017686764152529122, Final Batch Loss: 4.390530739328824e-05\n",
      "Epoch 2436, Loss: 0.0006472513186963624, Final Batch Loss: 5.255103678791784e-05\n",
      "Epoch 2437, Loss: 0.001363436836982146, Final Batch Loss: 2.0359513655421324e-05\n",
      "Epoch 2438, Loss: 0.004478803685458388, Final Batch Loss: 1.4564619732482242e-07\n",
      "Epoch 2439, Loss: 0.0007728028981262014, Final Batch Loss: 1.5479990906897e-05\n",
      "Epoch 2440, Loss: 0.0013161800277998736, Final Batch Loss: 7.426624506479129e-05\n",
      "Epoch 2441, Loss: 0.0028239075013516413, Final Batch Loss: 4.967890163243283e-06\n",
      "Epoch 2442, Loss: 0.0019572545784285467, Final Batch Loss: 3.1539029805571772e-06\n",
      "Epoch 2443, Loss: 0.0010320077776668768, Final Batch Loss: 3.1428728107130155e-05\n",
      "Epoch 2444, Loss: 0.05342398893185418, Final Batch Loss: 0.00015329485177062452\n",
      "Epoch 2445, Loss: 0.0013602705173525464, Final Batch Loss: 2.105172461597249e-05\n",
      "Epoch 2446, Loss: 0.000844551572185992, Final Batch Loss: 7.407902739942074e-05\n",
      "Epoch 2447, Loss: 0.004514469824243861, Final Batch Loss: 0.0008082137210294604\n",
      "Epoch 2448, Loss: 0.0013200741669834315, Final Batch Loss: 0.0001801299658836797\n",
      "Epoch 2449, Loss: 0.0010377382735669016, Final Batch Loss: 1.5936859199428e-05\n",
      "Epoch 2450, Loss: 0.04235333194287705, Final Batch Loss: 1.4921899492037483e-05\n",
      "Epoch 2451, Loss: 0.0026920012563778073, Final Batch Loss: 5.876083832845325e-06\n",
      "Epoch 2452, Loss: 0.0009072847349216318, Final Batch Loss: 2.390058034507092e-05\n",
      "Epoch 2453, Loss: 0.00931703154128627, Final Batch Loss: 9.122888877755031e-05\n",
      "Epoch 2454, Loss: 0.0086361920825766, Final Batch Loss: 9.580011101206765e-05\n",
      "Epoch 2455, Loss: 0.0746613473124853, Final Batch Loss: 0.002679638797417283\n",
      "Epoch 2456, Loss: 0.02239302951439015, Final Batch Loss: 4.291725872462848e-06\n",
      "Epoch 2457, Loss: 0.010041907362392521, Final Batch Loss: 0.0003351959749124944\n",
      "Epoch 2458, Loss: 0.003457362026779265, Final Batch Loss: 0.0022481288760900497\n",
      "Epoch 2459, Loss: 0.0011300622682028916, Final Batch Loss: 3.890021616825834e-06\n",
      "Epoch 2460, Loss: 0.0009316294707844008, Final Batch Loss: 1.696947219897993e-05\n",
      "Epoch 2461, Loss: 0.0018666858601363856, Final Batch Loss: 1.9083029201283352e-07\n",
      "Epoch 2462, Loss: 0.003642462547759351, Final Batch Loss: 6.417479744413868e-05\n",
      "Epoch 2463, Loss: 0.0007023457653758669, Final Batch Loss: 1.7912285557031282e-06\n",
      "Epoch 2464, Loss: 0.004342747254895585, Final Batch Loss: 0.001483964268118143\n",
      "Epoch 2465, Loss: 0.0021292200752327517, Final Batch Loss: 0.0013534550089389086\n",
      "Epoch 2466, Loss: 0.0013782019780137489, Final Batch Loss: 0.00018985506903845817\n",
      "Epoch 2467, Loss: 0.010259399684400705, Final Batch Loss: 4.4520056690089405e-05\n",
      "Epoch 2468, Loss: 0.0375141222482398, Final Batch Loss: 0.00013480322377290577\n",
      "Epoch 2469, Loss: 0.07736704410990569, Final Batch Loss: 0.0007651900523342192\n",
      "Epoch 2470, Loss: 0.013931352097642957, Final Batch Loss: 9.596127347322181e-05\n",
      "Epoch 2471, Loss: 0.04746655095169672, Final Batch Loss: 0.0002108027838403359\n",
      "Epoch 2472, Loss: 0.02457675487949018, Final Batch Loss: 0.014972344972193241\n",
      "Epoch 2473, Loss: 0.0035817866591969505, Final Batch Loss: 0.0005240979371592402\n",
      "Epoch 2474, Loss: 0.006323043700831477, Final Batch Loss: 0.0037296204827725887\n",
      "Epoch 2475, Loss: 0.004532502117626791, Final Batch Loss: 0.0006972301052883267\n",
      "Epoch 2476, Loss: 0.012979774144696421, Final Batch Loss: 0.0003636864712461829\n",
      "Epoch 2477, Loss: 0.026516397278555814, Final Batch Loss: 0.002624243963509798\n",
      "Epoch 2478, Loss: 0.018432431261317106, Final Batch Loss: 3.559315882739611e-05\n",
      "Epoch 2479, Loss: 0.009328157498202927, Final Batch Loss: 2.592434611869976e-05\n",
      "Epoch 2480, Loss: 0.046770642802584916, Final Batch Loss: 0.004436105489730835\n",
      "Epoch 2481, Loss: 0.024914520061429357, Final Batch Loss: 0.0012354598147794604\n",
      "Epoch 2482, Loss: 0.009808561964746332, Final Batch Loss: 0.00015174764848779887\n",
      "Epoch 2483, Loss: 0.008831697663481464, Final Batch Loss: 0.00018476779223419726\n",
      "Epoch 2484, Loss: 0.004656817421164305, Final Batch Loss: 0.0002417982032056898\n",
      "Epoch 2485, Loss: 0.005691957857834495, Final Batch Loss: 0.0014227669453248382\n",
      "Epoch 2486, Loss: 0.011522727212650352, Final Batch Loss: 0.001586693455465138\n",
      "Epoch 2487, Loss: 0.0079874496695993, Final Batch Loss: 2.0653676983783953e-05\n",
      "Epoch 2488, Loss: 0.00510207682964392, Final Batch Loss: 0.00021647903486154974\n",
      "Epoch 2489, Loss: 0.013421045821814914, Final Batch Loss: 0.001584901474416256\n",
      "Epoch 2490, Loss: 0.08791684740572236, Final Batch Loss: 0.0002465677971486002\n",
      "Epoch 2491, Loss: 0.014587189521989785, Final Batch Loss: 0.00014255566929932684\n",
      "Epoch 2492, Loss: 0.003545413067058689, Final Batch Loss: 2.399665754637681e-05\n",
      "Epoch 2493, Loss: 0.044906167799126706, Final Batch Loss: 0.00018604795332066715\n",
      "Epoch 2494, Loss: 0.009015091758556082, Final Batch Loss: 0.00327164214104414\n",
      "Epoch 2495, Loss: 0.018461162823768973, Final Batch Loss: 7.034103327896446e-05\n",
      "Epoch 2496, Loss: 0.0060816547311333125, Final Batch Loss: 0.004843889269977808\n",
      "Epoch 2497, Loss: 0.014611842643716955, Final Batch Loss: 0.001965775853022933\n",
      "Epoch 2498, Loss: 0.00588023050022457, Final Batch Loss: 2.376398515480105e-05\n",
      "Epoch 2499, Loss: 0.010199112910413533, Final Batch Loss: 5.4523334256373346e-05\n",
      "Epoch 2500, Loss: 0.003033317987501505, Final Batch Loss: 1.4574750821338966e-05\n",
      "Epoch 2501, Loss: 0.011401263849847965, Final Batch Loss: 0.0006004438037052751\n",
      "Epoch 2502, Loss: 0.0387231079639605, Final Batch Loss: 0.00011713839194271713\n",
      "Epoch 2503, Loss: 0.0054031116796977585, Final Batch Loss: 9.480398875894025e-05\n",
      "Epoch 2504, Loss: 0.005639541090204148, Final Batch Loss: 0.0015578860184177756\n",
      "Epoch 2505, Loss: 0.007628871339875332, Final Batch Loss: 2.4104547264869325e-05\n",
      "Epoch 2506, Loss: 0.0025724506203914643, Final Batch Loss: 5.853267794009298e-05\n",
      "Epoch 2507, Loss: 0.025379140952281887, Final Batch Loss: 2.956127718789503e-05\n",
      "Epoch 2508, Loss: 0.005399713099905057, Final Batch Loss: 0.0007513653836213052\n",
      "Epoch 2509, Loss: 0.005432087314147793, Final Batch Loss: 0.00010792886314447969\n",
      "Epoch 2510, Loss: 0.004945484771269548, Final Batch Loss: 1.6709180272300728e-05\n",
      "Epoch 2511, Loss: 0.04612990510213422, Final Batch Loss: 0.0016418531304225326\n",
      "Epoch 2512, Loss: 0.00902072402095655, Final Batch Loss: 0.0003249177825637162\n",
      "Epoch 2513, Loss: 0.0037023484601377277, Final Batch Loss: 4.9463393224868923e-05\n",
      "Epoch 2514, Loss: 0.05044146194086352, Final Batch Loss: 7.797931903041899e-05\n",
      "Epoch 2515, Loss: 0.00719519126778323, Final Batch Loss: 0.00015785329742357135\n",
      "Epoch 2516, Loss: 0.0072794373336364515, Final Batch Loss: 3.8093341572675854e-05\n",
      "Epoch 2517, Loss: 0.01356740020946745, Final Batch Loss: 0.0014149617636576295\n",
      "Epoch 2518, Loss: 0.0230801198035806, Final Batch Loss: 0.003646272700279951\n",
      "Epoch 2519, Loss: 0.009598383672710042, Final Batch Loss: 0.00045975708053447306\n",
      "Epoch 2520, Loss: 0.0602797851743162, Final Batch Loss: 8.698764759174082e-06\n",
      "Epoch 2521, Loss: 0.004651371345744337, Final Batch Loss: 0.00010996674245689064\n",
      "Epoch 2522, Loss: 0.011015947138730553, Final Batch Loss: 6.615624442929402e-05\n",
      "Epoch 2523, Loss: 0.0033355845107507776, Final Batch Loss: 1.2448540473997127e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2524, Loss: 0.011461115081147, Final Batch Loss: 8.69492123456439e-06\n",
      "Epoch 2525, Loss: 0.004542423099337611, Final Batch Loss: 5.5327265727100894e-05\n",
      "Epoch 2526, Loss: 0.0016891626983124297, Final Batch Loss: 2.341453728149645e-05\n",
      "Epoch 2527, Loss: 0.0033534053254697938, Final Batch Loss: 2.4859313271008432e-05\n",
      "Epoch 2528, Loss: 0.004983463724784087, Final Batch Loss: 8.213281398639083e-05\n",
      "Epoch 2529, Loss: 0.0027678869778355875, Final Batch Loss: 4.325282134232111e-05\n",
      "Epoch 2530, Loss: 0.002626566889375681, Final Batch Loss: 0.00020078975649084896\n",
      "Epoch 2531, Loss: 0.013610520099518908, Final Batch Loss: 7.12089313310571e-05\n",
      "Epoch 2532, Loss: 0.00154204685577497, Final Batch Loss: 0.00012792374764103442\n",
      "Epoch 2533, Loss: 0.0026170631667525868, Final Batch Loss: 4.3985244701616466e-05\n",
      "Epoch 2534, Loss: 0.00275179055006447, Final Batch Loss: 2.8750787350872997e-06\n",
      "Epoch 2535, Loss: 0.0012824413859107153, Final Batch Loss: 5.353771939553553e-06\n",
      "Epoch 2536, Loss: 0.009907661079523677, Final Batch Loss: 0.000983391422778368\n",
      "Epoch 2537, Loss: 0.0046575341989409935, Final Batch Loss: 7.152487523853779e-05\n",
      "Epoch 2538, Loss: 0.008512806416320018, Final Batch Loss: 9.739573215483688e-06\n",
      "Epoch 2539, Loss: 0.027627551803334427, Final Batch Loss: 6.59265151625732e-06\n",
      "Epoch 2540, Loss: 0.016473381052492186, Final Batch Loss: 0.00014524755533784628\n",
      "Epoch 2541, Loss: 0.01342017764090997, Final Batch Loss: 0.0019068275578320026\n",
      "Epoch 2542, Loss: 0.053798250978616124, Final Batch Loss: 0.009178252890706062\n",
      "Epoch 2543, Loss: 0.020187558301017816, Final Batch Loss: 1.6386518836952746e-05\n",
      "Epoch 2544, Loss: 0.04665052594145891, Final Batch Loss: 7.061879387038061e-06\n",
      "Epoch 2545, Loss: 0.01064925552236673, Final Batch Loss: 0.0016996086342260242\n",
      "Epoch 2546, Loss: 0.01714858097329852, Final Batch Loss: 0.0007659007096663117\n",
      "Epoch 2547, Loss: 0.010525473382585915, Final Batch Loss: 0.0004802919283974916\n",
      "Epoch 2548, Loss: 0.01005787920075818, Final Batch Loss: 0.0003648678830359131\n",
      "Epoch 2549, Loss: 0.0025312242469226476, Final Batch Loss: 7.48874808778055e-05\n",
      "Epoch 2550, Loss: 0.0049967372015089495, Final Batch Loss: 0.0005402224487625062\n",
      "Epoch 2551, Loss: 0.006922432964984182, Final Batch Loss: 0.00019805823103524745\n",
      "Epoch 2552, Loss: 0.001620827508304501, Final Batch Loss: 4.730560249299742e-05\n",
      "Epoch 2553, Loss: 0.002655560428820536, Final Batch Loss: 2.056722587440163e-05\n",
      "Epoch 2554, Loss: 0.008008991680981126, Final Batch Loss: 1.8003720470005646e-05\n",
      "Epoch 2555, Loss: 0.03127391437556071, Final Batch Loss: 6.91581517457962e-05\n",
      "Epoch 2556, Loss: 0.00467384889702771, Final Batch Loss: 0.00020582527213264257\n",
      "Epoch 2557, Loss: 0.004526920650732791, Final Batch Loss: 0.0007133270846679807\n",
      "Epoch 2558, Loss: 0.0039184086001569085, Final Batch Loss: 0.00021139002637937665\n",
      "Epoch 2559, Loss: 0.010907854293691344, Final Batch Loss: 4.4369560782797635e-05\n",
      "Epoch 2560, Loss: 0.051088134970086685, Final Batch Loss: 8.779176823736634e-06\n",
      "Epoch 2561, Loss: 0.006688184077574988, Final Batch Loss: 1.9344988686498255e-05\n",
      "Epoch 2562, Loss: 0.01587447739439085, Final Batch Loss: 0.012638249434530735\n",
      "Epoch 2563, Loss: 0.013388862803367374, Final Batch Loss: 0.001355188200250268\n",
      "Epoch 2564, Loss: 0.008150982902407122, Final Batch Loss: 2.6836985853151418e-05\n",
      "Epoch 2565, Loss: 0.005005908776183787, Final Batch Loss: 0.00016035250155255198\n",
      "Epoch 2566, Loss: 0.0024083777252599248, Final Batch Loss: 2.4292692614835687e-05\n",
      "Epoch 2567, Loss: 0.002750741853560612, Final Batch Loss: 1.77822894329438e-05\n",
      "Epoch 2568, Loss: 0.040416003450445714, Final Batch Loss: 4.7727568016853184e-05\n",
      "Epoch 2569, Loss: 0.020433359281923913, Final Batch Loss: 0.004394956398755312\n",
      "Epoch 2570, Loss: 0.005295412149735057, Final Batch Loss: 3.9590180676896125e-05\n",
      "Epoch 2571, Loss: 0.045478679695406754, Final Batch Loss: 0.00010314672545064241\n",
      "Epoch 2572, Loss: 0.0016998491616959654, Final Batch Loss: 4.475871173781343e-05\n",
      "Epoch 2573, Loss: 0.0034478773027331044, Final Batch Loss: 0.00010523285163799301\n",
      "Epoch 2574, Loss: 0.0018892764201154932, Final Batch Loss: 5.070682163932361e-06\n",
      "Epoch 2575, Loss: 0.003354787719217711, Final Batch Loss: 5.8595182053977624e-05\n",
      "Epoch 2576, Loss: 0.019046169442844985, Final Batch Loss: 0.0010884158546105027\n",
      "Epoch 2577, Loss: 0.020133143319981173, Final Batch Loss: 1.3995023437018972e-05\n",
      "Epoch 2578, Loss: 0.01276311803576391, Final Batch Loss: 9.836931894824374e-06\n",
      "Epoch 2579, Loss: 0.011561593382793944, Final Batch Loss: 2.8648522857110947e-05\n",
      "Epoch 2580, Loss: 0.0009204989028148702, Final Batch Loss: 4.7359637392219156e-05\n",
      "Epoch 2581, Loss: 0.001528815939082051, Final Batch Loss: 0.00011290117254247889\n",
      "Epoch 2582, Loss: 0.002080828223313347, Final Batch Loss: 0.0001675495586823672\n",
      "Epoch 2583, Loss: 0.0009123501025669611, Final Batch Loss: 1.4517639101541135e-05\n",
      "Epoch 2584, Loss: 0.005361857785828761, Final Batch Loss: 1.6712607248337008e-05\n",
      "Epoch 2585, Loss: 0.04608339065657674, Final Batch Loss: 0.017277251929044724\n",
      "Epoch 2586, Loss: 0.004115204914796777, Final Batch Loss: 0.00026743681519292295\n",
      "Epoch 2587, Loss: 0.02783940698168408, Final Batch Loss: 7.888078107498586e-05\n",
      "Epoch 2588, Loss: 0.00772530590813858, Final Batch Loss: 0.00015306206478271633\n",
      "Epoch 2589, Loss: 0.0022515105392812984, Final Batch Loss: 7.995374471647665e-05\n",
      "Epoch 2590, Loss: 0.0009780683406006574, Final Batch Loss: 4.056068792124279e-05\n",
      "Epoch 2591, Loss: 0.0024138804865287966, Final Batch Loss: 1.0266131539538037e-05\n",
      "Epoch 2592, Loss: 0.0009965630948727267, Final Batch Loss: 2.6115005312021822e-05\n",
      "Epoch 2593, Loss: 0.009768877544729548, Final Batch Loss: 7.921037467895076e-05\n",
      "Epoch 2594, Loss: 0.0014924364800208423, Final Batch Loss: 4.95077529194532e-06\n",
      "Epoch 2595, Loss: 0.0004705619708147424, Final Batch Loss: 6.435103568946943e-05\n",
      "Epoch 2596, Loss: 0.0007578716888474446, Final Batch Loss: 2.1466188627528027e-05\n",
      "Epoch 2597, Loss: 0.0007989344694578904, Final Batch Loss: 0.00011288413224974647\n",
      "Epoch 2598, Loss: 0.0014425691942960839, Final Batch Loss: 8.862231334205717e-05\n",
      "Epoch 2599, Loss: 0.003816629872289923, Final Batch Loss: 0.00015640656056348234\n",
      "Epoch 2600, Loss: 0.0014015314277600055, Final Batch Loss: 1.081532587932088e-07\n",
      "Epoch 2601, Loss: 0.016735488106405683, Final Batch Loss: 0.015817778185009956\n",
      "Epoch 2602, Loss: 0.015962566642201637, Final Batch Loss: 1.7424959878553636e-05\n",
      "Epoch 2603, Loss: 0.014171297666052851, Final Batch Loss: 0.0005849056760780513\n",
      "Epoch 2604, Loss: 0.003401675615350541, Final Batch Loss: 5.373502972361166e-06\n",
      "Epoch 2605, Loss: 0.002200321130658267, Final Batch Loss: 3.8346235669450834e-05\n",
      "Epoch 2606, Loss: 0.002949050707684364, Final Batch Loss: 7.939093848108314e-06\n",
      "Epoch 2607, Loss: 0.0008843483326472779, Final Batch Loss: 9.520449384581298e-05\n",
      "Epoch 2608, Loss: 0.0021964568259136286, Final Batch Loss: 1.677075124462135e-05\n",
      "Epoch 2609, Loss: 0.0016710360989691253, Final Batch Loss: 5.2633600716944784e-05\n",
      "Epoch 2610, Loss: 0.0013841335318147685, Final Batch Loss: 5.422329195425846e-05\n",
      "Epoch 2611, Loss: 0.0013241510603165807, Final Batch Loss: 0.0005030965548940003\n",
      "Epoch 2612, Loss: 0.006289453507292819, Final Batch Loss: 0.004802498035132885\n",
      "Epoch 2613, Loss: 0.0012698453147095279, Final Batch Loss: 0.00034722863347269595\n",
      "Epoch 2614, Loss: 0.003661722159904457, Final Batch Loss: 3.1217899959301576e-05\n",
      "Epoch 2615, Loss: 0.0016904613626138598, Final Batch Loss: 4.8246211008518e-06\n",
      "Epoch 2616, Loss: 0.0006718274598256357, Final Batch Loss: 2.802531298584654e-06\n",
      "Epoch 2617, Loss: 0.002268969401029608, Final Batch Loss: 0.0008171671652235091\n",
      "Epoch 2618, Loss: 0.0010299121882439977, Final Batch Loss: 0.0007234404911287129\n",
      "Epoch 2619, Loss: 0.0008509950916959497, Final Batch Loss: 6.096775450714631e-06\n",
      "Epoch 2620, Loss: 0.0005571472238443675, Final Batch Loss: 3.408743941690773e-05\n",
      "Epoch 2621, Loss: 0.001208318210615289, Final Batch Loss: 4.869878921454074e-06\n",
      "Epoch 2622, Loss: 0.01687113120851791, Final Batch Loss: 4.283745056454791e-06\n",
      "Epoch 2623, Loss: 0.00971356448167171, Final Batch Loss: 2.022444641625043e-05\n",
      "Epoch 2624, Loss: 0.004786770799000806, Final Batch Loss: 0.00015069152868818492\n",
      "Epoch 2625, Loss: 0.00169642427135841, Final Batch Loss: 0.0008450556779280305\n",
      "Epoch 2626, Loss: 0.002567198555766481, Final Batch Loss: 0.0002663050836417824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2627, Loss: 0.015742422907578657, Final Batch Loss: 5.39954453415703e-05\n",
      "Epoch 2628, Loss: 0.017636838471844385, Final Batch Loss: 4.73951058665989e-06\n",
      "Epoch 2629, Loss: 0.019026272720793713, Final Batch Loss: 2.5732537324074656e-05\n",
      "Epoch 2630, Loss: 0.08025242102530683, Final Batch Loss: 0.0006008869386278093\n",
      "Epoch 2631, Loss: 0.019654745628031378, Final Batch Loss: 0.0012016833061352372\n",
      "Epoch 2632, Loss: 0.02334913544837036, Final Batch Loss: 0.0051802461966872215\n",
      "Epoch 2633, Loss: 0.019150864368384646, Final Batch Loss: 2.1461408323375508e-05\n",
      "Epoch 2634, Loss: 0.007084793725880445, Final Batch Loss: 1.0460647899890319e-05\n",
      "Epoch 2635, Loss: 0.004737591211551262, Final Batch Loss: 0.0009812244679778814\n",
      "Epoch 2636, Loss: 0.011622730114638102, Final Batch Loss: 0.00013965570542495698\n",
      "Epoch 2637, Loss: 0.0021106762628733122, Final Batch Loss: 0.0017076312797144055\n",
      "Epoch 2638, Loss: 0.0015538890210109457, Final Batch Loss: 3.7054043787065893e-05\n",
      "Epoch 2639, Loss: 0.006489444760632068, Final Batch Loss: 1.4695101526740473e-05\n",
      "Epoch 2640, Loss: 0.0020735556066426852, Final Batch Loss: 0.0012458141427487135\n",
      "Epoch 2641, Loss: 0.0016338590532427588, Final Batch Loss: 0.00015612579591106623\n",
      "Epoch 2642, Loss: 0.0012805759230332114, Final Batch Loss: 6.887983090564376e-07\n",
      "Epoch 2643, Loss: 0.001477092491086296, Final Batch Loss: 9.747357125888811e-07\n",
      "Epoch 2644, Loss: 0.010134361536643155, Final Batch Loss: 9.277764183934778e-05\n",
      "Epoch 2645, Loss: 0.006426817374631355, Final Batch Loss: 4.533950050245039e-05\n",
      "Epoch 2646, Loss: 0.003929455991283248, Final Batch Loss: 6.078108344809152e-05\n",
      "Epoch 2647, Loss: 0.023503365138935806, Final Batch Loss: 7.468871626770124e-05\n",
      "Epoch 2648, Loss: 0.023114454428650788, Final Batch Loss: 0.0005257706507109106\n",
      "Epoch 2649, Loss: 0.02542914132624219, Final Batch Loss: 0.00012659515778068453\n",
      "Epoch 2650, Loss: 0.004173686880221794, Final Batch Loss: 2.1877451217733324e-05\n",
      "Epoch 2651, Loss: 0.004462130413685372, Final Batch Loss: 3.75530325982254e-05\n",
      "Epoch 2652, Loss: 0.03606151030089677, Final Batch Loss: 0.0014077808009460568\n",
      "Epoch 2653, Loss: 0.0024345035803889914, Final Batch Loss: 4.091116352356039e-06\n",
      "Epoch 2654, Loss: 0.0018544031572673703, Final Batch Loss: 0.00015039915160741657\n",
      "Epoch 2655, Loss: 0.0033684882836269026, Final Batch Loss: 0.0001288555358769372\n",
      "Epoch 2656, Loss: 0.0011534142965956562, Final Batch Loss: 0.0003951139224227518\n",
      "Epoch 2657, Loss: 0.0017769460046395125, Final Batch Loss: 1.5650063005523407e-06\n",
      "Epoch 2658, Loss: 0.0017144098868016044, Final Batch Loss: 6.526465313072549e-06\n",
      "Epoch 2659, Loss: 0.014431064587824949, Final Batch Loss: 1.6123252862598747e-05\n",
      "Epoch 2660, Loss: 0.018783702713335515, Final Batch Loss: 6.80343437124975e-05\n",
      "Epoch 2661, Loss: 0.0077275287089833, Final Batch Loss: 2.3052584765537176e-06\n",
      "Epoch 2662, Loss: 0.03525182484736433, Final Batch Loss: 0.004996873904019594\n",
      "Epoch 2663, Loss: 0.004915103640087182, Final Batch Loss: 5.3518397180596367e-05\n",
      "Epoch 2664, Loss: 0.0025877071514059935, Final Batch Loss: 4.786544650414726e-06\n",
      "Epoch 2665, Loss: 0.0011075279022634277, Final Batch Loss: 7.218004157039104e-06\n",
      "Epoch 2666, Loss: 0.004676108982494043, Final Batch Loss: 4.759805506182602e-06\n",
      "Epoch 2667, Loss: 0.010980275828842423, Final Batch Loss: 5.894553396501578e-06\n",
      "Epoch 2668, Loss: 0.0006916062179698201, Final Batch Loss: 7.865262887207791e-05\n",
      "Epoch 2669, Loss: 0.0031832188615226187, Final Batch Loss: 0.00010208140884060413\n",
      "Epoch 2670, Loss: 0.01836095915587066, Final Batch Loss: 5.77584296479472e-06\n",
      "Epoch 2671, Loss: 0.004381060420200811, Final Batch Loss: 0.00014454642951022834\n",
      "Epoch 2672, Loss: 0.01788454698134956, Final Batch Loss: 0.00016513807349838316\n",
      "Epoch 2673, Loss: 0.018431964423143654, Final Batch Loss: 1.649525438551791e-05\n",
      "Epoch 2674, Loss: 0.02009291792910517, Final Batch Loss: 2.955029412987642e-05\n",
      "Epoch 2675, Loss: 0.026679489607886353, Final Batch Loss: 1.0643047971825581e-05\n",
      "Epoch 2676, Loss: 0.0237100073095462, Final Batch Loss: 0.0019170817686244845\n",
      "Epoch 2677, Loss: 0.0072705595921434, Final Batch Loss: 7.348747021751478e-05\n",
      "Epoch 2678, Loss: 0.04142819723415414, Final Batch Loss: 0.003965935669839382\n",
      "Epoch 2679, Loss: 0.00670722818995273, Final Batch Loss: 1.2802593118976802e-05\n",
      "Epoch 2680, Loss: 0.007879116902586247, Final Batch Loss: 5.48152002011193e-06\n",
      "Epoch 2681, Loss: 0.005276414160107379, Final Batch Loss: 0.00023478148796129972\n",
      "Epoch 2682, Loss: 0.017088598912778252, Final Batch Loss: 5.7669374655233696e-05\n",
      "Epoch 2683, Loss: 0.0057291857590371364, Final Batch Loss: 3.666237535071559e-05\n",
      "Epoch 2684, Loss: 0.0007319195465242956, Final Batch Loss: 4.19738280470483e-05\n",
      "Epoch 2685, Loss: 0.0037669421017199056, Final Batch Loss: 6.5744357016228605e-06\n",
      "Epoch 2686, Loss: 0.002634170763030852, Final Batch Loss: 6.835687963757664e-05\n",
      "Epoch 2687, Loss: 0.013317740393631539, Final Batch Loss: 7.870364061091095e-05\n",
      "Epoch 2688, Loss: 0.003706300520207151, Final Batch Loss: 2.7084046450909227e-05\n",
      "Epoch 2689, Loss: 0.0025154014954296144, Final Batch Loss: 4.349192386143841e-05\n",
      "Epoch 2690, Loss: 0.0011803685558788857, Final Batch Loss: 4.990712841390632e-05\n",
      "Epoch 2691, Loss: 0.0019089782531409583, Final Batch Loss: 0.00010829710663529113\n",
      "Epoch 2692, Loss: 0.003085323800860351, Final Batch Loss: 2.8263446438359097e-05\n",
      "Epoch 2693, Loss: 0.0019416240729697165, Final Batch Loss: 1.0715271855588071e-05\n",
      "Epoch 2694, Loss: 0.007402050606287958, Final Batch Loss: 5.106582830194384e-05\n",
      "Epoch 2695, Loss: 0.001091235546482494, Final Batch Loss: 8.0248893937096e-05\n",
      "Epoch 2696, Loss: 0.0030977948908912367, Final Batch Loss: 0.00039037453825585544\n",
      "Epoch 2697, Loss: 0.0015249112366291229, Final Batch Loss: 3.2960538192128297e-06\n",
      "Epoch 2698, Loss: 0.001907460146867379, Final Batch Loss: 2.14755618799245e-06\n",
      "Epoch 2699, Loss: 0.0016834718979907848, Final Batch Loss: 1.4394780691873166e-06\n",
      "Epoch 2700, Loss: 0.0004785396529314312, Final Batch Loss: 5.033672096033115e-06\n",
      "Epoch 2701, Loss: 0.0004845032763114432, Final Batch Loss: 8.053342753555626e-06\n",
      "Epoch 2702, Loss: 0.0021519370673104277, Final Batch Loss: 0.0002188828366342932\n",
      "Epoch 2703, Loss: 0.00043166411296624574, Final Batch Loss: 5.583424353972077e-06\n",
      "Epoch 2704, Loss: 0.2079598294913012, Final Batch Loss: 8.54343488754239e-06\n",
      "Epoch 2705, Loss: 0.005938803329627262, Final Batch Loss: 1.3541311091103125e-05\n",
      "Epoch 2706, Loss: 0.0013332025737327058, Final Batch Loss: 7.261340942932293e-05\n",
      "Epoch 2707, Loss: 0.00807097258802969, Final Batch Loss: 1.883799268398434e-05\n",
      "Epoch 2708, Loss: 0.003953214187049525, Final Batch Loss: 0.0010083954548463225\n",
      "Epoch 2709, Loss: 0.002738227819918393, Final Batch Loss: 3.10442665067967e-05\n",
      "Epoch 2710, Loss: 0.002978763132205131, Final Batch Loss: 1.919572241604328e-05\n",
      "Epoch 2711, Loss: 0.0015726534359146171, Final Batch Loss: 0.0004217747482471168\n",
      "Epoch 2712, Loss: 0.0033176395071450315, Final Batch Loss: 3.7458306906046346e-05\n",
      "Epoch 2713, Loss: 0.0033625378534907213, Final Batch Loss: 0.0007588841835968196\n",
      "Epoch 2714, Loss: 0.002469593472824272, Final Batch Loss: 0.00014802461373619735\n",
      "Epoch 2715, Loss: 0.0006772425740564358, Final Batch Loss: 1.9519215129548684e-05\n",
      "Epoch 2716, Loss: 0.01740749345600534, Final Batch Loss: 5.893296474823728e-05\n",
      "Epoch 2717, Loss: 0.005324014371581143, Final Batch Loss: 9.453475286136381e-06\n",
      "Epoch 2718, Loss: 0.0013520087748588594, Final Batch Loss: 0.00029957108199596405\n",
      "Epoch 2719, Loss: 0.0034390576594205413, Final Batch Loss: 1.2979578059457708e-05\n",
      "Epoch 2720, Loss: 0.0006619199425585975, Final Batch Loss: 5.866067294846289e-05\n",
      "Epoch 2721, Loss: 0.0018013262426848087, Final Batch Loss: 4.837867527385242e-05\n",
      "Epoch 2722, Loss: 0.001030508605168734, Final Batch Loss: 1.6937269720074255e-06\n",
      "Epoch 2723, Loss: 0.0020264739641788765, Final Batch Loss: 2.902177584473975e-05\n",
      "Epoch 2724, Loss: 0.002504504260855356, Final Batch Loss: 1.6809641238069162e-05\n",
      "Epoch 2725, Loss: 0.0003288237919605308, Final Batch Loss: 8.945506124291569e-05\n",
      "Epoch 2726, Loss: 0.0008079247593286709, Final Batch Loss: 5.456329745356925e-06\n",
      "Epoch 2727, Loss: 0.0013663690584309052, Final Batch Loss: 0.00014844107499811798\n",
      "Epoch 2728, Loss: 0.0004279149100483437, Final Batch Loss: 0.0001136638384195976\n",
      "Epoch 2729, Loss: 0.00021132773460408316, Final Batch Loss: 2.03438030439429e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2730, Loss: 0.0006041246925860833, Final Batch Loss: 1.337626372333034e-06\n",
      "Epoch 2731, Loss: 0.02113911556648418, Final Batch Loss: 5.857513770024525e-06\n",
      "Epoch 2732, Loss: 0.008014867231509015, Final Batch Loss: 2.8001793907606043e-05\n",
      "Epoch 2733, Loss: 0.0099540326659735, Final Batch Loss: 0.0006008566124364734\n",
      "Epoch 2734, Loss: 0.0025961337584305966, Final Batch Loss: 1.896256799227558e-05\n",
      "Epoch 2735, Loss: 0.002742086161788393, Final Batch Loss: 2.12613645089732e-06\n",
      "Epoch 2736, Loss: 0.0017239534726343209, Final Batch Loss: 2.6885527404374443e-06\n",
      "Epoch 2737, Loss: 0.0019079793161154157, Final Batch Loss: 1.552474600430287e-06\n",
      "Epoch 2738, Loss: 0.0004766865780538865, Final Batch Loss: 6.66623018332757e-05\n",
      "Epoch 2739, Loss: 0.00786326104366708, Final Batch Loss: 3.6557660223479616e-06\n",
      "Epoch 2740, Loss: 0.00980010134639997, Final Batch Loss: 3.301309698144905e-05\n",
      "Epoch 2741, Loss: 0.0006349589165211, Final Batch Loss: 8.627154602436349e-05\n",
      "Epoch 2742, Loss: 0.0005112153255595331, Final Batch Loss: 6.145254701550584e-06\n",
      "Epoch 2743, Loss: 0.0012752417031265395, Final Batch Loss: 2.690660494408803e-06\n",
      "Epoch 2744, Loss: 0.0006464091487714541, Final Batch Loss: 7.858620847400744e-06\n",
      "Epoch 2745, Loss: 0.001061589076925884, Final Batch Loss: 6.379013029800262e-06\n",
      "Epoch 2746, Loss: 0.012584544143493304, Final Batch Loss: 3.77813449858877e-07\n",
      "Epoch 2747, Loss: 0.0018533649689800313, Final Batch Loss: 1.1367694696673425e-06\n",
      "Epoch 2748, Loss: 0.0009752018489734837, Final Batch Loss: 3.0175186111591756e-05\n",
      "Epoch 2749, Loss: 0.0023072108345445486, Final Batch Loss: 4.2616473365342245e-05\n",
      "Epoch 2750, Loss: 0.000341775845271286, Final Batch Loss: 4.965372681908775e-07\n",
      "Epoch 2751, Loss: 0.001515482466317053, Final Batch Loss: 0.0002737144532147795\n",
      "Epoch 2752, Loss: 0.0004670019419563687, Final Batch Loss: 1.3351492270885501e-05\n",
      "Epoch 2753, Loss: 0.00022751843914647907, Final Batch Loss: 3.2263060347759165e-06\n",
      "Epoch 2754, Loss: 0.00032064268475551216, Final Batch Loss: 4.9592749746807385e-06\n",
      "Epoch 2755, Loss: 0.02723035341563218, Final Batch Loss: 2.472969572409056e-05\n",
      "Epoch 2756, Loss: 0.11225011706210353, Final Batch Loss: 0.0006375984521582723\n",
      "Epoch 2757, Loss: 0.040068713344567186, Final Batch Loss: 0.0002457665395922959\n",
      "Epoch 2758, Loss: 0.048235238002689584, Final Batch Loss: 0.00013939343625679612\n",
      "Epoch 2759, Loss: 0.06529353577025176, Final Batch Loss: 7.300671131815761e-05\n",
      "Epoch 2760, Loss: 0.037661902664694935, Final Batch Loss: 8.941722626332194e-05\n",
      "Epoch 2761, Loss: 0.004235292824887438, Final Batch Loss: 6.431345536839217e-05\n",
      "Epoch 2762, Loss: 0.015935037790768547, Final Batch Loss: 0.0002841937239281833\n",
      "Epoch 2763, Loss: 0.02354567276029229, Final Batch Loss: 0.0006683470564894378\n",
      "Epoch 2764, Loss: 0.00796292354061734, Final Batch Loss: 0.000392597314203158\n",
      "Epoch 2765, Loss: 0.01011241604010138, Final Batch Loss: 0.000127800929476507\n",
      "Epoch 2766, Loss: 0.011287231427559163, Final Batch Loss: 4.6820940042380244e-05\n",
      "Epoch 2767, Loss: 0.0188345443293656, Final Batch Loss: 2.140549804607872e-05\n",
      "Epoch 2768, Loss: 0.0024549063359700085, Final Batch Loss: 0.0002903057320509106\n",
      "Epoch 2769, Loss: 0.031207314788844087, Final Batch Loss: 0.012042542919516563\n",
      "Epoch 2770, Loss: 0.015135411142068733, Final Batch Loss: 0.0001034112719935365\n",
      "Epoch 2771, Loss: 0.015081224949881289, Final Batch Loss: 0.0005499505205079913\n",
      "Epoch 2772, Loss: 0.010810792510710598, Final Batch Loss: 0.00033528797212056816\n",
      "Epoch 2773, Loss: 0.015438766395163839, Final Batch Loss: 0.00017044342530425638\n",
      "Epoch 2774, Loss: 0.007278544396058351, Final Batch Loss: 0.0005982819711789489\n",
      "Epoch 2775, Loss: 0.008132481171742256, Final Batch Loss: 0.00046934557030908763\n",
      "Epoch 2776, Loss: 0.0033509179038446746, Final Batch Loss: 0.0004566205316223204\n",
      "Epoch 2777, Loss: 0.004308545631829475, Final Batch Loss: 0.0002363620005780831\n",
      "Epoch 2778, Loss: 0.012699193408707288, Final Batch Loss: 0.00010480071068741381\n",
      "Epoch 2779, Loss: 0.0025199537731168675, Final Batch Loss: 3.172389915562235e-05\n",
      "Epoch 2780, Loss: 0.00529597899401324, Final Batch Loss: 0.00033456188975833356\n",
      "Epoch 2781, Loss: 0.003761260510714237, Final Batch Loss: 4.6689615373907145e-06\n",
      "Epoch 2782, Loss: 0.0060034566467948025, Final Batch Loss: 7.298395939869806e-05\n",
      "Epoch 2783, Loss: 0.003170312606926018, Final Batch Loss: 3.726800423464738e-05\n",
      "Epoch 2784, Loss: 0.009001085447835067, Final Batch Loss: 1.4678515981358942e-05\n",
      "Epoch 2785, Loss: 0.003537039248385554, Final Batch Loss: 4.566075858747354e-06\n",
      "Epoch 2786, Loss: 0.001314271614774043, Final Batch Loss: 7.808759255567566e-05\n",
      "Epoch 2787, Loss: 0.029504680068043854, Final Batch Loss: 6.990206020418555e-05\n",
      "Epoch 2788, Loss: 0.005977079415060871, Final Batch Loss: 0.00022804229229222983\n",
      "Epoch 2789, Loss: 0.0023803751978448418, Final Batch Loss: 6.664900138275698e-05\n",
      "Epoch 2790, Loss: 0.008066707910330706, Final Batch Loss: 2.3529044483439066e-05\n",
      "Epoch 2791, Loss: 0.0011029655686343176, Final Batch Loss: 8.358158083865419e-05\n",
      "Epoch 2792, Loss: 0.0021328680387568966, Final Batch Loss: 0.00017124302394222468\n",
      "Epoch 2793, Loss: 0.002472260637546242, Final Batch Loss: 1.7982882127398625e-05\n",
      "Epoch 2794, Loss: 0.0020864344182882633, Final Batch Loss: 0.00033850292675197124\n",
      "Epoch 2795, Loss: 0.002302418778640458, Final Batch Loss: 6.223122454684926e-06\n",
      "Epoch 2796, Loss: 0.0027334835309034133, Final Batch Loss: 1.4002351235831156e-05\n",
      "Epoch 2797, Loss: 0.004258225441049035, Final Batch Loss: 3.060401286347769e-05\n",
      "Epoch 2798, Loss: 0.001716959546911312, Final Batch Loss: 9.860403224593028e-05\n",
      "Epoch 2799, Loss: 0.023610849355009123, Final Batch Loss: 2.165552905353252e-05\n",
      "Epoch 2800, Loss: 0.00393291080263225, Final Batch Loss: 1.0386283975094557e-05\n",
      "Epoch 2801, Loss: 0.0007659622227151885, Final Batch Loss: 6.373753080879396e-07\n",
      "Epoch 2802, Loss: 0.00299314818221319, Final Batch Loss: 1.8436179743730463e-05\n",
      "Epoch 2803, Loss: 0.0013345154494004419, Final Batch Loss: 1.5477386114071123e-05\n",
      "Epoch 2804, Loss: 0.000319272149340577, Final Batch Loss: 2.7067853807238862e-05\n",
      "Epoch 2805, Loss: 0.0008108859097291088, Final Batch Loss: 2.355669266762561e-06\n",
      "Epoch 2806, Loss: 0.0007181206825066511, Final Batch Loss: 4.3549431438805186e-07\n",
      "Epoch 2807, Loss: 0.001317009822514592, Final Batch Loss: 3.452183591434732e-05\n",
      "Epoch 2808, Loss: 0.003910189849818835, Final Batch Loss: 2.2114300008979626e-06\n",
      "Epoch 2809, Loss: 0.0011650641098128744, Final Batch Loss: 9.959114777302602e-07\n",
      "Epoch 2810, Loss: 0.00015681796298849804, Final Batch Loss: 2.4844701329129748e-05\n",
      "Epoch 2811, Loss: 0.0009324111071578045, Final Batch Loss: 2.8738837499986403e-05\n",
      "Epoch 2812, Loss: 0.015785561900202083, Final Batch Loss: 5.5149597756098956e-05\n",
      "Epoch 2813, Loss: 0.012255635333971782, Final Batch Loss: 0.0024427594617009163\n",
      "Epoch 2814, Loss: 0.0026950481458243303, Final Batch Loss: 4.866661038249731e-05\n",
      "Epoch 2815, Loss: 0.014314171672339171, Final Batch Loss: 1.2669634088524617e-06\n",
      "Epoch 2816, Loss: 0.00372423235523911, Final Batch Loss: 9.304875129600987e-05\n",
      "Epoch 2817, Loss: 0.0006956223558916008, Final Batch Loss: 0.0001253059454029426\n",
      "Epoch 2818, Loss: 0.017902250589571622, Final Batch Loss: 1.7460598655816284e-06\n",
      "Epoch 2819, Loss: 0.04870533653651421, Final Batch Loss: 0.00028878101147711277\n",
      "Epoch 2820, Loss: 0.005376427777036952, Final Batch Loss: 0.0024693466257303953\n",
      "Epoch 2821, Loss: 0.004305368792529407, Final Batch Loss: 1.1287700544926338e-05\n",
      "Epoch 2822, Loss: 0.015152812659152914, Final Batch Loss: 0.004170436877757311\n",
      "Epoch 2823, Loss: 0.020606939886874898, Final Batch Loss: 7.619985353812808e-06\n",
      "Epoch 2824, Loss: 0.006679892050442504, Final Batch Loss: 3.3621852253418183e-06\n",
      "Epoch 2825, Loss: 0.007269528111692125, Final Batch Loss: 6.679506623186171e-05\n",
      "Epoch 2826, Loss: 0.004233872907917657, Final Batch Loss: 3.1221854442264885e-05\n",
      "Epoch 2827, Loss: 0.003318499524084473, Final Batch Loss: 2.5305530471086968e-06\n",
      "Epoch 2828, Loss: 0.00041273086566206985, Final Batch Loss: 2.748104088823311e-05\n",
      "Epoch 2829, Loss: 0.001113707172407885, Final Batch Loss: 1.0267424841003958e-05\n",
      "Epoch 2830, Loss: 0.0013188915567639015, Final Batch Loss: 1.0972046766255517e-05\n",
      "Epoch 2831, Loss: 0.0005758400147897191, Final Batch Loss: 2.989853328472236e-06\n",
      "Epoch 2832, Loss: 0.0013851767251935598, Final Batch Loss: 1.344839574812795e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2833, Loss: 0.0025827096311275, Final Batch Loss: 0.00019129179418087006\n",
      "Epoch 2834, Loss: 0.01979188778662433, Final Batch Loss: 0.0005222491454333067\n",
      "Epoch 2835, Loss: 0.016391635517862824, Final Batch Loss: 4.983599865227006e-06\n",
      "Epoch 2836, Loss: 0.07989532254384812, Final Batch Loss: 0.0024212223943322897\n",
      "Epoch 2837, Loss: 0.02626268309063562, Final Batch Loss: 1.0258097972837277e-05\n",
      "Epoch 2838, Loss: 0.003975810865085805, Final Batch Loss: 0.0001171029798570089\n",
      "Epoch 2839, Loss: 0.007123216426407453, Final Batch Loss: 1.4174038369674236e-06\n",
      "Epoch 2840, Loss: 0.0035941195312716445, Final Batch Loss: 0.0008859735098667443\n",
      "Epoch 2841, Loss: 0.002770870025756267, Final Batch Loss: 2.5258168534492142e-05\n",
      "Epoch 2842, Loss: 0.0022182940992649947, Final Batch Loss: 0.00033232319401577115\n",
      "Epoch 2843, Loss: 0.0008269730526535568, Final Batch Loss: 3.45945663866587e-05\n",
      "Epoch 2844, Loss: 0.00028786580011797014, Final Batch Loss: 3.614687500430591e-07\n",
      "Epoch 2845, Loss: 0.0005362028102808836, Final Batch Loss: 2.271488483529538e-05\n",
      "Epoch 2846, Loss: 0.0019189926816238767, Final Batch Loss: 6.973915151320398e-05\n",
      "Epoch 2847, Loss: 0.00043000724991770767, Final Batch Loss: 1.3587693956651492e-06\n",
      "Epoch 2848, Loss: 0.0010364626567138657, Final Batch Loss: 2.66683832705894e-06\n",
      "Epoch 2849, Loss: 0.00017127197656918725, Final Batch Loss: 2.184588447562419e-05\n",
      "Epoch 2850, Loss: 0.0011223938878544004, Final Batch Loss: 2.790915687000961e-06\n",
      "Epoch 2851, Loss: 0.004585056240117069, Final Batch Loss: 6.047154965926893e-05\n",
      "Epoch 2852, Loss: 0.003488724348812866, Final Batch Loss: 1.648443503654562e-05\n",
      "Epoch 2853, Loss: 0.007240986197530219, Final Batch Loss: 0.00010522423690417781\n",
      "Epoch 2854, Loss: 0.0012328671274985936, Final Batch Loss: 3.443417654125369e-06\n",
      "Epoch 2855, Loss: 0.0010164984852849557, Final Batch Loss: 3.0483852242468856e-06\n",
      "Epoch 2856, Loss: 0.0013508470287888485, Final Batch Loss: 3.436196857364848e-05\n",
      "Epoch 2857, Loss: 0.003917243458118946, Final Batch Loss: 0.002474534325301647\n",
      "Epoch 2858, Loss: 0.0035411417400155187, Final Batch Loss: 4.550673111225478e-06\n",
      "Epoch 2859, Loss: 0.03342022591999694, Final Batch Loss: 9.017559932544827e-06\n",
      "Epoch 2860, Loss: 0.0012298437399635986, Final Batch Loss: 4.647937385016121e-05\n",
      "Epoch 2861, Loss: 0.0025267877621786283, Final Batch Loss: 0.001478710793890059\n",
      "Epoch 2862, Loss: 0.004920276132793333, Final Batch Loss: 8.301095704155159e-07\n",
      "Epoch 2863, Loss: 0.024276379771208667, Final Batch Loss: 0.008716413751244545\n",
      "Epoch 2864, Loss: 0.020030254526545832, Final Batch Loss: 0.017973344773054123\n",
      "Epoch 2865, Loss: 0.05252020813134095, Final Batch Loss: 4.2600109736667946e-05\n",
      "Epoch 2866, Loss: 0.002344736162740446, Final Batch Loss: 8.144342245941516e-06\n",
      "Epoch 2867, Loss: 0.010112177588780469, Final Batch Loss: 0.00014031180762685835\n",
      "Epoch 2868, Loss: 0.009532731121453253, Final Batch Loss: 1.030468411045149e-05\n",
      "Epoch 2869, Loss: 0.055756473167733134, Final Batch Loss: 2.97060796583537e-06\n",
      "Epoch 2870, Loss: 0.0718687618393119, Final Batch Loss: 4.950953211846354e-07\n",
      "Epoch 2871, Loss: 0.06203326994193503, Final Batch Loss: 0.005880798678845167\n",
      "Epoch 2872, Loss: 0.013970165038699633, Final Batch Loss: 0.0030873885843902826\n",
      "Epoch 2873, Loss: 0.014402409562535468, Final Batch Loss: 0.00010247618774883449\n",
      "Epoch 2874, Loss: 0.034285239175915194, Final Batch Loss: 1.3800546184938867e-05\n",
      "Epoch 2875, Loss: 0.02806523940034822, Final Batch Loss: 2.8250022296560928e-05\n",
      "Epoch 2876, Loss: 0.008272229436443013, Final Batch Loss: 2.784579191938974e-05\n",
      "Epoch 2877, Loss: 0.0010029083259723848, Final Batch Loss: 4.6041954192332923e-05\n",
      "Epoch 2878, Loss: 0.00895381456530231, Final Batch Loss: 3.477199425105937e-05\n",
      "Epoch 2879, Loss: 0.008903950905732927, Final Batch Loss: 0.00032171126804314554\n",
      "Epoch 2880, Loss: 0.005024911674809118, Final Batch Loss: 0.0001205132357426919\n",
      "Epoch 2881, Loss: 0.002464154073095415, Final Batch Loss: 0.0013837232254445553\n",
      "Epoch 2882, Loss: 0.003279778264413835, Final Batch Loss: 3.2699449548090342e-06\n",
      "Epoch 2883, Loss: 0.017509185297512886, Final Batch Loss: 5.352830157789867e-06\n",
      "Epoch 2884, Loss: 0.0028974358488085272, Final Batch Loss: 0.00026231646188534796\n",
      "Epoch 2885, Loss: 0.025082108329115727, Final Batch Loss: 7.133464532671496e-05\n",
      "Epoch 2886, Loss: 0.017661055498138012, Final Batch Loss: 0.00031253794440999627\n",
      "Epoch 2887, Loss: 0.0038005516962584807, Final Batch Loss: 1.6951185898506083e-05\n",
      "Epoch 2888, Loss: 0.0016868760983470565, Final Batch Loss: 0.00014898406516294926\n",
      "Epoch 2889, Loss: 0.011263646464385602, Final Batch Loss: 0.00032960748649202287\n",
      "Epoch 2890, Loss: 0.002185105854550784, Final Batch Loss: 0.00017149531049653888\n",
      "Epoch 2891, Loss: 0.015152019934703276, Final Batch Loss: 2.1846335584996268e-05\n",
      "Epoch 2892, Loss: 0.01086836672766367, Final Batch Loss: 9.224261884810403e-05\n",
      "Epoch 2893, Loss: 0.0030952459756008466, Final Batch Loss: 0.00022023111523594707\n",
      "Epoch 2894, Loss: 0.0011420180435379734, Final Batch Loss: 6.966719956835732e-05\n",
      "Epoch 2895, Loss: 0.0014112638227743446, Final Batch Loss: 6.573093560291454e-05\n",
      "Epoch 2896, Loss: 0.0032394219556408643, Final Batch Loss: 0.0007087966077961028\n",
      "Epoch 2897, Loss: 0.0066918927695951425, Final Batch Loss: 0.00011536249803612009\n",
      "Epoch 2898, Loss: 0.019030751906029764, Final Batch Loss: 0.01773804798722267\n",
      "Epoch 2899, Loss: 0.020132401560658764, Final Batch Loss: 2.404506813036278e-05\n",
      "Epoch 2900, Loss: 0.006493456939097086, Final Batch Loss: 2.8048359581589466e-06\n",
      "Epoch 2901, Loss: 0.0041634399922259036, Final Batch Loss: 7.848963286960497e-05\n",
      "Epoch 2902, Loss: 0.031972539321714066, Final Batch Loss: 4.469619398150826e-06\n",
      "Epoch 2903, Loss: 0.0016800339553810772, Final Batch Loss: 3.661746814032085e-05\n",
      "Epoch 2904, Loss: 0.0015778751394464052, Final Batch Loss: 9.071721251530107e-06\n",
      "Epoch 2905, Loss: 0.014844895110400103, Final Batch Loss: 0.00015950610395520926\n",
      "Epoch 2906, Loss: 0.0026759764632515726, Final Batch Loss: 1.8005095625994727e-05\n",
      "Epoch 2907, Loss: 0.0031460063047461517, Final Batch Loss: 3.365206111993757e-06\n",
      "Epoch 2908, Loss: 0.0010776594392609695, Final Batch Loss: 3.157347236992791e-05\n",
      "Epoch 2909, Loss: 0.001961599715741613, Final Batch Loss: 2.111826461259625e-06\n",
      "Epoch 2910, Loss: 0.003117377626892903, Final Batch Loss: 3.285529601271264e-05\n",
      "Epoch 2911, Loss: 0.001018881173877162, Final Batch Loss: 1.9914634322049096e-05\n",
      "Epoch 2912, Loss: 0.0013023613215636942, Final Batch Loss: 5.3337607823777944e-05\n",
      "Epoch 2913, Loss: 0.0007966774759324835, Final Batch Loss: 1.2728717592835892e-05\n",
      "Epoch 2914, Loss: 0.0004687196231998314, Final Batch Loss: 0.00021429899788927287\n",
      "Epoch 2915, Loss: 0.00046950439502779773, Final Batch Loss: 3.598421699280152e-06\n",
      "Epoch 2916, Loss: 0.001622354204300791, Final Batch Loss: 1.853970024967566e-05\n",
      "Epoch 2917, Loss: 0.0005716443946539584, Final Batch Loss: 2.869229774660198e-06\n",
      "Epoch 2918, Loss: 0.00465145657665289, Final Batch Loss: 3.040521733055357e-06\n",
      "Epoch 2919, Loss: 0.0007102878237219556, Final Batch Loss: 6.150513218017295e-05\n",
      "Epoch 2920, Loss: 0.0018523138568298236, Final Batch Loss: 5.597760264208773e-06\n",
      "Epoch 2921, Loss: 0.001498600893683033, Final Batch Loss: 4.9734160711523145e-05\n",
      "Epoch 2922, Loss: 0.008588899542473882, Final Batch Loss: 3.945619027945213e-05\n",
      "Epoch 2923, Loss: 0.0005316450682357754, Final Batch Loss: 0.0001015710731735453\n",
      "Epoch 2924, Loss: 0.004505874789174413, Final Batch Loss: 4.47118100055377e-06\n",
      "Epoch 2925, Loss: 0.0009967249643523246, Final Batch Loss: 4.078875281265937e-05\n",
      "Epoch 2926, Loss: 0.012075830940375454, Final Batch Loss: 1.1233354598516598e-05\n",
      "Epoch 2927, Loss: 0.003344637262443939, Final Batch Loss: 0.00022281974088400602\n",
      "Epoch 2928, Loss: 0.0008552392127967323, Final Batch Loss: 0.00026602079742588103\n",
      "Epoch 2929, Loss: 0.00033083552955304185, Final Batch Loss: 3.4854081150115235e-06\n",
      "Epoch 2930, Loss: 0.0007178390499120724, Final Batch Loss: 3.1513111480308e-06\n",
      "Epoch 2931, Loss: 0.003476798194355979, Final Batch Loss: 6.123767661847523e-07\n",
      "Epoch 2932, Loss: 0.003109798904119998, Final Batch Loss: 8.574629646318499e-06\n",
      "Epoch 2933, Loss: 0.0017994019792695326, Final Batch Loss: 1.0505435966479126e-05\n",
      "Epoch 2934, Loss: 0.0005524167464159291, Final Batch Loss: 7.999107765499502e-06\n",
      "Epoch 2935, Loss: 0.01981685203543293, Final Batch Loss: 5.917021326240501e-07\n",
      "Epoch 2936, Loss: 0.007952633622835492, Final Batch Loss: 0.00012925313785672188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2937, Loss: 0.0060891673474543495, Final Batch Loss: 6.727859727106988e-05\n",
      "Epoch 2938, Loss: 0.0018112987273752879, Final Batch Loss: 1.4979676961957011e-05\n",
      "Epoch 2939, Loss: 0.0031791567367065454, Final Batch Loss: 6.008563559589675e-06\n",
      "Epoch 2940, Loss: 0.0026446634828971582, Final Batch Loss: 3.836548057734035e-05\n",
      "Epoch 2941, Loss: 0.002212662598424231, Final Batch Loss: 9.088961974157428e-07\n",
      "Epoch 2942, Loss: 0.00032791489539363283, Final Batch Loss: 5.907884315092815e-06\n",
      "Epoch 2943, Loss: 0.0012222950915656838, Final Batch Loss: 2.480257535353303e-06\n",
      "Epoch 2944, Loss: 0.0002741467843634382, Final Batch Loss: 1.919541318784468e-05\n",
      "Epoch 2945, Loss: 0.00023368265937051547, Final Batch Loss: 2.418780240986962e-05\n",
      "Epoch 2946, Loss: 0.003823405584370221, Final Batch Loss: 2.9390916097327136e-05\n",
      "Epoch 2947, Loss: 0.0004109268542151767, Final Batch Loss: 6.5448043642390985e-06\n",
      "Epoch 2948, Loss: 0.0014345008781901925, Final Batch Loss: 1.3317834373083315e-06\n",
      "Epoch 2949, Loss: 0.0005363273610328179, Final Batch Loss: 6.7472668888513e-05\n",
      "Epoch 2950, Loss: 0.00018804021465257392, Final Batch Loss: 1.888008910100325e-06\n",
      "Epoch 2951, Loss: 0.000330239401819199, Final Batch Loss: 6.495921297755558e-06\n",
      "Epoch 2952, Loss: 0.00201984430708535, Final Batch Loss: 2.3467812297894852e-06\n",
      "Epoch 2953, Loss: 0.001314684509310382, Final Batch Loss: 6.541998118336778e-06\n",
      "Epoch 2954, Loss: 0.012742573488822018, Final Batch Loss: 3.2226093935605604e-06\n",
      "Epoch 2955, Loss: 0.02431593825190248, Final Batch Loss: 9.576658158039209e-06\n",
      "Epoch 2956, Loss: 0.007637845907083829, Final Batch Loss: 4.279355380276684e-06\n",
      "Epoch 2957, Loss: 0.004787805711941928, Final Batch Loss: 9.003860213852022e-06\n",
      "Epoch 2958, Loss: 0.0022669995346404903, Final Batch Loss: 8.605259063187987e-05\n",
      "Epoch 2959, Loss: 0.005431805232262832, Final Batch Loss: 0.00035574822686612606\n",
      "Epoch 2960, Loss: 0.0028102932090234845, Final Batch Loss: 2.0597910861397395e-06\n",
      "Epoch 2961, Loss: 0.00036505014111298806, Final Batch Loss: 1.04340142570436e-05\n",
      "Epoch 2962, Loss: 0.0034813559263966454, Final Batch Loss: 5.891185355721973e-05\n",
      "Epoch 2963, Loss: 0.0019483523166172745, Final Batch Loss: 0.001022124895825982\n",
      "Epoch 2964, Loss: 0.0010143332875998112, Final Batch Loss: 4.6847144403727725e-06\n",
      "Epoch 2965, Loss: 0.0014044119707250502, Final Batch Loss: 1.9868089111696463e-06\n",
      "Epoch 2966, Loss: 0.000356944891564126, Final Batch Loss: 3.758742423087824e-06\n",
      "Epoch 2967, Loss: 0.002658327246876979, Final Batch Loss: 4.489535285756574e-07\n",
      "Epoch 2968, Loss: 0.0071932353124282145, Final Batch Loss: 0.00023526221048086882\n",
      "Epoch 2969, Loss: 0.0010750217364261516, Final Batch Loss: 0.00028801002190448344\n",
      "Epoch 2970, Loss: 0.0003001343057746908, Final Batch Loss: 1.0580654816294555e-05\n",
      "Epoch 2971, Loss: 0.0005409546179464542, Final Batch Loss: 0.0001375281426589936\n",
      "Epoch 2972, Loss: 0.0003521654867313373, Final Batch Loss: 2.650180476848618e-06\n",
      "Epoch 2973, Loss: 0.0010877490072083162, Final Batch Loss: 2.331270297872834e-05\n",
      "Epoch 2974, Loss: 0.00034420683071800795, Final Batch Loss: 1.6150718806784425e-07\n",
      "Epoch 2975, Loss: 0.0040327671586339875, Final Batch Loss: 2.4084176857286366e-06\n",
      "Epoch 2976, Loss: 0.0009107448046847821, Final Batch Loss: 5.521432285604533e-06\n",
      "Epoch 2977, Loss: 0.0006522143809917225, Final Batch Loss: 1.6087182075352757e-06\n",
      "Epoch 2978, Loss: 0.0017151351014490501, Final Batch Loss: 9.559969385009026e-07\n",
      "Epoch 2979, Loss: 0.00047320300751607647, Final Batch Loss: 6.998432945692912e-05\n",
      "Epoch 2980, Loss: 0.0006423132538770915, Final Batch Loss: 8.324697660100355e-07\n",
      "Epoch 2981, Loss: 0.002440662460855947, Final Batch Loss: 1.9788224108197028e-06\n",
      "Epoch 2982, Loss: 0.0009237287238192948, Final Batch Loss: 2.9233940949779935e-05\n",
      "Epoch 2983, Loss: 0.0043581346416203814, Final Batch Loss: 5.670188329531811e-06\n",
      "Epoch 2984, Loss: 0.005057857194174176, Final Batch Loss: 1.2478025155360228e-06\n",
      "Epoch 2985, Loss: 0.0035061445661312973, Final Batch Loss: 8.082757267402485e-05\n",
      "Epoch 2986, Loss: 0.0668564778268319, Final Batch Loss: 0.020200617611408234\n",
      "Epoch 2987, Loss: 0.15077438383264052, Final Batch Loss: 5.6630240578670055e-05\n",
      "Epoch 2988, Loss: 0.0393124450056348, Final Batch Loss: 8.634621917735785e-05\n",
      "Epoch 2989, Loss: 0.03371214250000776, Final Batch Loss: 0.0027169566601514816\n",
      "Epoch 2990, Loss: 0.044217128119271365, Final Batch Loss: 0.00025568847195245326\n",
      "Epoch 2991, Loss: 0.037179133883910254, Final Batch Loss: 0.00010692173236748204\n",
      "Epoch 2992, Loss: 0.010229558229184477, Final Batch Loss: 4.944087777403183e-05\n",
      "Epoch 2993, Loss: 0.03291599194653827, Final Batch Loss: 4.467190956347622e-05\n",
      "Epoch 2994, Loss: 0.05074654643249232, Final Batch Loss: 0.00017031117749866098\n",
      "Epoch 2995, Loss: 0.04822464610697352, Final Batch Loss: 0.00046639444190077484\n",
      "Epoch 2996, Loss: 0.06371639897770365, Final Batch Loss: 0.002609220100566745\n",
      "Epoch 2997, Loss: 0.012462803399102995, Final Batch Loss: 0.0004155913775321096\n",
      "Epoch 2998, Loss: 0.005734486683650175, Final Batch Loss: 4.34585235780105e-05\n",
      "Epoch 2999, Loss: 0.006903345196406008, Final Batch Loss: 0.004189970437437296\n",
      "Epoch 3000, Loss: 0.0016561983138672076, Final Batch Loss: 6.76037379889749e-05\n",
      "Epoch 3001, Loss: 0.003236382548493566, Final Batch Loss: 7.907325925771147e-05\n",
      "Epoch 3002, Loss: 0.005001149458166765, Final Batch Loss: 2.052126728813164e-05\n",
      "Epoch 3003, Loss: 0.00364375044910048, Final Batch Loss: 4.5474920625565574e-05\n",
      "Epoch 3004, Loss: 0.0032926229494023573, Final Batch Loss: 1.3987360944156535e-05\n",
      "Epoch 3005, Loss: 0.012770029822149809, Final Batch Loss: 3.489790469757281e-05\n",
      "Epoch 3006, Loss: 0.03882816404075129, Final Batch Loss: 0.02865736559033394\n",
      "Epoch 3007, Loss: 0.03129145288039581, Final Batch Loss: 0.011888048611581326\n",
      "Epoch 3008, Loss: 0.009696485895801743, Final Batch Loss: 0.0005045059369876981\n",
      "Epoch 3009, Loss: 0.010492220301784982, Final Batch Loss: 0.00013124619727022946\n",
      "Epoch 3010, Loss: 0.005837565271804124, Final Batch Loss: 9.425919415662065e-05\n",
      "Epoch 3011, Loss: 0.006572080334080965, Final Batch Loss: 1.905189492390491e-05\n",
      "Epoch 3012, Loss: 0.010130661246421369, Final Batch Loss: 0.0017107357271015644\n",
      "Epoch 3013, Loss: 0.0013422757865839685, Final Batch Loss: 5.076440174889285e-06\n",
      "Epoch 3014, Loss: 0.0007258657545889946, Final Batch Loss: 2.320545263501117e-06\n",
      "Epoch 3015, Loss: 0.0022205697950994363, Final Batch Loss: 2.9568262107204646e-05\n",
      "Epoch 3016, Loss: 0.0009618728042539715, Final Batch Loss: 0.0004078216734342277\n",
      "Epoch 3017, Loss: 0.00264242735102016, Final Batch Loss: 2.1603114873869345e-05\n",
      "Epoch 3018, Loss: 0.0033523136299322687, Final Batch Loss: 6.565765602317697e-07\n",
      "Epoch 3019, Loss: 0.007002173819785185, Final Batch Loss: 3.892113454639912e-06\n",
      "Epoch 3020, Loss: 0.00504572344175358, Final Batch Loss: 4.519213689491153e-06\n",
      "Epoch 3021, Loss: 0.0005951086836830655, Final Batch Loss: 9.636987670091912e-07\n",
      "Epoch 3022, Loss: 0.00867762518919335, Final Batch Loss: 4.376539072836749e-05\n",
      "Epoch 3023, Loss: 0.0057591661551441575, Final Batch Loss: 0.0009819751139730215\n",
      "Epoch 3024, Loss: 0.009316910274264956, Final Batch Loss: 1.7095810108003207e-05\n",
      "Epoch 3025, Loss: 0.0013898239606078278, Final Batch Loss: 0.00016010050603654236\n",
      "Epoch 3026, Loss: 0.000698074855449704, Final Batch Loss: 9.839991435001139e-06\n",
      "Epoch 3027, Loss: 0.0020952632212356548, Final Batch Loss: 2.4445813323836774e-05\n",
      "Epoch 3028, Loss: 0.007386579316175812, Final Batch Loss: 8.464659003948327e-06\n",
      "Epoch 3029, Loss: 0.0004679219295553594, Final Batch Loss: 1.8908256151917158e-06\n",
      "Epoch 3030, Loss: 0.01872613877890217, Final Batch Loss: 9.752405276231002e-06\n",
      "Epoch 3031, Loss: 0.0023314170548474067, Final Batch Loss: 2.883914703488699e-06\n",
      "Epoch 3032, Loss: 0.00037746034927010896, Final Batch Loss: 2.2039500890969066e-06\n",
      "Epoch 3033, Loss: 0.0031541871478566463, Final Batch Loss: 0.0028051184490323067\n",
      "Epoch 3034, Loss: 0.0029671310052208355, Final Batch Loss: 1.1377170494597522e-06\n",
      "Epoch 3035, Loss: 0.003923029630186647, Final Batch Loss: 0.00010073045268654823\n",
      "Epoch 3036, Loss: 0.010422893859072246, Final Batch Loss: 2.215121639892459e-05\n",
      "Epoch 3037, Loss: 0.002695278172268445, Final Batch Loss: 9.913740359479561e-05\n",
      "Epoch 3038, Loss: 0.0012165381540398812, Final Batch Loss: 0.0004485429381020367\n",
      "Epoch 3039, Loss: 0.0018953124019844836, Final Batch Loss: 2.9445862310240045e-05\n",
      "Epoch 3040, Loss: 0.007255272259726553, Final Batch Loss: 4.437194365891628e-05\n",
      "Epoch 3041, Loss: 0.008506291695255186, Final Batch Loss: 1.8602116824695258e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3042, Loss: 0.0042704999948455225, Final Batch Loss: 0.00331664877012372\n",
      "Epoch 3043, Loss: 0.002590358003601523, Final Batch Loss: 3.1056209991220385e-05\n",
      "Epoch 3044, Loss: 0.0026457060064331017, Final Batch Loss: 8.443897240795195e-05\n",
      "Epoch 3045, Loss: 0.0008713043991406266, Final Batch Loss: 8.611511293565854e-05\n",
      "Epoch 3046, Loss: 0.002065440168848909, Final Batch Loss: 2.715866230573738e-06\n",
      "Epoch 3047, Loss: 0.0009571015448273101, Final Batch Loss: 3.2585371627646964e-06\n",
      "Epoch 3048, Loss: 0.0015060528924095706, Final Batch Loss: 4.830603302252712e-06\n",
      "Epoch 3049, Loss: 0.00029948183828309993, Final Batch Loss: 3.3712606182234595e-06\n",
      "Epoch 3050, Loss: 0.0016735936737859447, Final Batch Loss: 0.00028277019737288356\n",
      "Epoch 3051, Loss: 0.000960491314515366, Final Batch Loss: 4.027967406727839e-06\n",
      "Epoch 3052, Loss: 0.0010687914940490373, Final Batch Loss: 0.00043113535502925515\n",
      "Epoch 3053, Loss: 0.0017776130126208045, Final Batch Loss: 6.176505848998204e-07\n",
      "Epoch 3054, Loss: 0.021005109353041007, Final Batch Loss: 0.000653618888463825\n",
      "Epoch 3055, Loss: 0.0014790518519021134, Final Batch Loss: 0.0008040370885282755\n",
      "Epoch 3056, Loss: 0.003809611924168621, Final Batch Loss: 1.9346445697010495e-05\n",
      "Epoch 3057, Loss: 0.0006777508166351254, Final Batch Loss: 4.5586046326207e-05\n",
      "Epoch 3058, Loss: 0.0012116348663084864, Final Batch Loss: 2.1289688447723165e-05\n",
      "Epoch 3059, Loss: 0.0008608009550243878, Final Batch Loss: 0.00024506516638211906\n",
      "Epoch 3060, Loss: 0.003072809927743947, Final Batch Loss: 0.002137901494279504\n",
      "Epoch 3061, Loss: 0.002038748824986669, Final Batch Loss: 2.536863348723273e-06\n",
      "Epoch 3062, Loss: 0.01086555046185822, Final Batch Loss: 0.0009418915724381804\n",
      "Epoch 3063, Loss: 0.003864813510631393, Final Batch Loss: 0.0006498711882159114\n",
      "Epoch 3064, Loss: 0.0030772990319860583, Final Batch Loss: 6.864004831186321e-07\n",
      "Epoch 3065, Loss: 0.0017278310732251612, Final Batch Loss: 7.435953648382565e-07\n",
      "Epoch 3066, Loss: 0.0019440198899474126, Final Batch Loss: 2.021758336923085e-05\n",
      "Epoch 3067, Loss: 0.0016402849253154272, Final Batch Loss: 4.322076620155713e-06\n",
      "Epoch 3068, Loss: 0.00021079182511130057, Final Batch Loss: 0.00014103461580816656\n",
      "Epoch 3069, Loss: 0.007529225742246126, Final Batch Loss: 1.9549006537999958e-05\n",
      "Epoch 3070, Loss: 0.0014743287064220567, Final Batch Loss: 2.055488948826678e-06\n",
      "Epoch 3071, Loss: 0.0004987998837577834, Final Batch Loss: 3.524990097503178e-05\n",
      "Epoch 3072, Loss: 0.008474891671113483, Final Batch Loss: 7.075420580804348e-05\n",
      "Epoch 3073, Loss: 0.01105029838640803, Final Batch Loss: 4.8778792915982194e-06\n",
      "Epoch 3074, Loss: 0.034541291254527096, Final Batch Loss: 5.9667654568329453e-05\n",
      "Epoch 3075, Loss: 0.01846444324019103, Final Batch Loss: 0.002877286169677973\n",
      "Epoch 3076, Loss: 0.03259462925984735, Final Batch Loss: 0.0007593867485411465\n",
      "Epoch 3077, Loss: 0.010909943952242429, Final Batch Loss: 4.6742966333113145e-06\n",
      "Epoch 3078, Loss: 0.015557175953290425, Final Batch Loss: 0.00010278527770424262\n",
      "Epoch 3079, Loss: 0.03444244649836037, Final Batch Loss: 0.00419236533343792\n",
      "Epoch 3080, Loss: 0.01479489956273028, Final Batch Loss: 0.0008756127208471298\n",
      "Epoch 3081, Loss: 0.017826745801926336, Final Batch Loss: 0.000522470276337117\n",
      "Epoch 3082, Loss: 0.023854799877881305, Final Batch Loss: 5.176729609956965e-05\n",
      "Epoch 3083, Loss: 0.020864058467168434, Final Batch Loss: 6.203699740581214e-05\n",
      "Epoch 3084, Loss: 0.03345683433826707, Final Batch Loss: 4.816707132704323e-06\n",
      "Epoch 3085, Loss: 0.028582632647953687, Final Batch Loss: 0.002209628466516733\n",
      "Epoch 3086, Loss: 0.037835505746670606, Final Batch Loss: 0.00011673098197206855\n",
      "Epoch 3087, Loss: 0.0031425855544284786, Final Batch Loss: 1.677100226515904e-05\n",
      "Epoch 3088, Loss: 0.0070524129978366545, Final Batch Loss: 1.826919469749555e-05\n",
      "Epoch 3089, Loss: 0.0023469587463296193, Final Batch Loss: 4.1567577682144474e-06\n",
      "Epoch 3090, Loss: 0.0025820093433139846, Final Batch Loss: 2.4903712983359583e-05\n",
      "Epoch 3091, Loss: 0.0008106555333142751, Final Batch Loss: 0.00015311504830606282\n",
      "Epoch 3092, Loss: 0.004230980786189775, Final Batch Loss: 9.383755241287872e-05\n",
      "Epoch 3093, Loss: 0.005667782465820892, Final Batch Loss: 0.004777710884809494\n",
      "Epoch 3094, Loss: 0.0043653631053075515, Final Batch Loss: 1.549757507746108e-05\n",
      "Epoch 3095, Loss: 0.0004923222381876258, Final Batch Loss: 1.31480401250883e-05\n",
      "Epoch 3096, Loss: 0.0011810348206608978, Final Batch Loss: 1.6063274870248279e-06\n",
      "Epoch 3097, Loss: 0.000549168806628586, Final Batch Loss: 1.6905814845813438e-05\n",
      "Epoch 3098, Loss: 0.003786478978724972, Final Batch Loss: 4.282746886019595e-07\n",
      "Epoch 3099, Loss: 0.0011109887529983098, Final Batch Loss: 5.499978215084411e-06\n",
      "Epoch 3100, Loss: 0.008634852791146841, Final Batch Loss: 7.542798994109035e-05\n",
      "Epoch 3101, Loss: 0.004680852180740658, Final Batch Loss: 0.00027261924697086215\n",
      "Epoch 3102, Loss: 0.002715725863197349, Final Batch Loss: 1.0634578757162672e-05\n",
      "Epoch 3103, Loss: 0.0007456111151213918, Final Batch Loss: 5.573490125243552e-05\n",
      "Epoch 3104, Loss: 0.0005510720609436248, Final Batch Loss: 3.8516896893270314e-05\n",
      "Epoch 3105, Loss: 0.0021965726900532445, Final Batch Loss: 8.019238885026425e-05\n",
      "Epoch 3106, Loss: 0.0019289840074634412, Final Batch Loss: 4.910976713290438e-06\n",
      "Epoch 3107, Loss: 0.0011807134630146265, Final Batch Loss: 6.535158718179446e-06\n",
      "Epoch 3108, Loss: 0.022640559611318167, Final Batch Loss: 0.00011097381502622738\n",
      "Epoch 3109, Loss: 0.004653043520626454, Final Batch Loss: 9.901977904291925e-08\n",
      "Epoch 3110, Loss: 0.010950695555365542, Final Batch Loss: 0.00815868191421032\n",
      "Epoch 3111, Loss: 0.0015621240294905192, Final Batch Loss: 0.0012315756175667048\n",
      "Epoch 3112, Loss: 0.006773477632918912, Final Batch Loss: 1.1283712410659064e-05\n",
      "Epoch 3113, Loss: 0.009267859847000182, Final Batch Loss: 2.824939656420611e-05\n",
      "Epoch 3114, Loss: 0.0035392840686085947, Final Batch Loss: 2.7908816264243796e-05\n",
      "Epoch 3115, Loss: 0.0032838133391237534, Final Batch Loss: 0.001551876193843782\n",
      "Epoch 3116, Loss: 0.00047878399080047984, Final Batch Loss: 1.3074470928131632e-07\n",
      "Epoch 3117, Loss: 0.000816767378609029, Final Batch Loss: 3.463295797700994e-05\n",
      "Epoch 3118, Loss: 0.17161697552953115, Final Batch Loss: 8.67631533765234e-05\n",
      "Epoch 3119, Loss: 0.02821760580263799, Final Batch Loss: 1.0530829968047328e-05\n",
      "Epoch 3120, Loss: 0.07109712202873197, Final Batch Loss: 0.006462180055677891\n",
      "Epoch 3121, Loss: 0.02516716297259336, Final Batch Loss: 0.0001307409693254158\n",
      "Epoch 3122, Loss: 0.02557873268096955, Final Batch Loss: 9.029003194882534e-06\n",
      "Epoch 3123, Loss: 0.005273218851471029, Final Batch Loss: 5.63976755074691e-06\n",
      "Epoch 3124, Loss: 0.001159365300736681, Final Batch Loss: 8.661692845635116e-05\n",
      "Epoch 3125, Loss: 0.004306216052100353, Final Batch Loss: 0.0004328657523728907\n",
      "Epoch 3126, Loss: 0.002323019179129915, Final Batch Loss: 0.00022124956012703478\n",
      "Epoch 3127, Loss: 0.016760399618760857, Final Batch Loss: 0.0005108813638798892\n",
      "Epoch 3128, Loss: 0.0020249896952009294, Final Batch Loss: 0.0003646202676463872\n",
      "Epoch 3129, Loss: 0.0015132176754377724, Final Batch Loss: 2.3559789042337798e-05\n",
      "Epoch 3130, Loss: 0.002125104777405795, Final Batch Loss: 0.0004980186349712312\n",
      "Epoch 3131, Loss: 0.0014256448632750107, Final Batch Loss: 3.13946875394322e-05\n",
      "Epoch 3132, Loss: 0.00591895436446066, Final Batch Loss: 3.824360828730278e-05\n",
      "Epoch 3133, Loss: 0.004398519865844719, Final Batch Loss: 1.8322900814382592e-06\n",
      "Epoch 3134, Loss: 0.00216328422220613, Final Batch Loss: 4.858346801484004e-05\n",
      "Epoch 3135, Loss: 0.0011772213676977117, Final Batch Loss: 0.00011389758583391085\n",
      "Epoch 3136, Loss: 0.0061697015696609014, Final Batch Loss: 9.298879376729019e-06\n",
      "Epoch 3137, Loss: 0.0014546264467298897, Final Batch Loss: 8.609576070739422e-06\n",
      "Epoch 3138, Loss: 0.00097432471193315, Final Batch Loss: 3.320458563393913e-05\n",
      "Epoch 3139, Loss: 0.016785397457397266, Final Batch Loss: 1.5264973626472056e-05\n",
      "Epoch 3140, Loss: 0.0009282468138280819, Final Batch Loss: 1.977734427782707e-05\n",
      "Epoch 3141, Loss: 0.0006454130207202979, Final Batch Loss: 2.0686955394921824e-05\n",
      "Epoch 3142, Loss: 0.0010812346451984922, Final Batch Loss: 4.909395556751406e-06\n",
      "Epoch 3143, Loss: 0.0043571065655214625, Final Batch Loss: 1.3132664207660127e-05\n",
      "Epoch 3144, Loss: 0.001261210891925657, Final Batch Loss: 0.0007770375232212245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3145, Loss: 0.0003255379078836995, Final Batch Loss: 7.708668817940634e-06\n",
      "Epoch 3146, Loss: 0.0011260431203936605, Final Batch Loss: 1.791318936739117e-05\n",
      "Epoch 3147, Loss: 0.0011947103184866137, Final Batch Loss: 1.0079642152049928e-06\n",
      "Epoch 3148, Loss: 0.03815634880425023, Final Batch Loss: 6.278698128880933e-05\n",
      "Epoch 3149, Loss: 0.01775021305275004, Final Batch Loss: 2.151768967451062e-05\n",
      "Epoch 3150, Loss: 0.007822948177931721, Final Batch Loss: 0.0002574156387709081\n",
      "Epoch 3151, Loss: 0.0021093691163969197, Final Batch Loss: 1.2291729944990948e-05\n",
      "Epoch 3152, Loss: 0.0003233674557350241, Final Batch Loss: 4.5670971303479746e-05\n",
      "Epoch 3153, Loss: 0.0016042080646911927, Final Batch Loss: 0.0010006320662796497\n",
      "Epoch 3154, Loss: 0.0008747233125632192, Final Batch Loss: 1.901554969663266e-05\n",
      "Epoch 3155, Loss: 0.0007817811920176609, Final Batch Loss: 7.0162504925974645e-06\n",
      "Epoch 3156, Loss: 0.00036809887714639444, Final Batch Loss: 2.8081944037694484e-05\n",
      "Epoch 3157, Loss: 0.005144671134530654, Final Batch Loss: 1.732246710162144e-05\n",
      "Epoch 3158, Loss: 0.0016930028917272466, Final Batch Loss: 0.00012310294550843537\n",
      "Epoch 3159, Loss: 0.0017365327452125712, Final Batch Loss: 7.619989628437907e-05\n",
      "Epoch 3160, Loss: 0.00039805184292163176, Final Batch Loss: 1.2679632845902233e-06\n",
      "Epoch 3161, Loss: 0.0008486580648394693, Final Batch Loss: 9.277255230699666e-06\n",
      "Epoch 3162, Loss: 0.0012078613146968564, Final Batch Loss: 4.1425490053370595e-05\n",
      "Epoch 3163, Loss: 0.022068588850402193, Final Batch Loss: 6.453276728279889e-05\n",
      "Epoch 3164, Loss: 0.0038375329359041643, Final Batch Loss: 0.00018384742725174874\n",
      "Epoch 3165, Loss: 0.0037087581840751227, Final Batch Loss: 2.6875652110902593e-05\n",
      "Epoch 3166, Loss: 0.0007815318914481395, Final Batch Loss: 1.5208416925815982e-06\n",
      "Epoch 3167, Loss: 0.0073352439817426784, Final Batch Loss: 0.0002595946134533733\n",
      "Epoch 3168, Loss: 0.009762827415556785, Final Batch Loss: 9.894309187075123e-05\n",
      "Epoch 3169, Loss: 0.012799982316550995, Final Batch Loss: 6.15500466665253e-05\n",
      "Epoch 3170, Loss: 0.014950446802458828, Final Batch Loss: 0.00010699639824451879\n",
      "Epoch 3171, Loss: 0.015993355133559817, Final Batch Loss: 0.00011910352623090148\n",
      "Epoch 3172, Loss: 0.02906763374971888, Final Batch Loss: 7.459575863322243e-05\n",
      "Epoch 3173, Loss: 0.03719292115238204, Final Batch Loss: 0.00018997366714756936\n",
      "Epoch 3174, Loss: 0.005031758205404913, Final Batch Loss: 0.00020819016208406538\n",
      "Epoch 3175, Loss: 0.008569434119635844, Final Batch Loss: 5.278477601677878e-06\n",
      "Epoch 3176, Loss: 0.026762767203308613, Final Batch Loss: 3.820234996965155e-05\n",
      "Epoch 3177, Loss: 0.012655071596782363, Final Batch Loss: 0.00028685334837064147\n",
      "Epoch 3178, Loss: 0.006618242924105289, Final Batch Loss: 0.0003800149424932897\n",
      "Epoch 3179, Loss: 0.00889364457884767, Final Batch Loss: 0.00022952878498472273\n",
      "Epoch 3180, Loss: 0.009546490517095663, Final Batch Loss: 3.7528508983086795e-05\n",
      "Epoch 3181, Loss: 0.001221537432684272, Final Batch Loss: 9.605276318325195e-06\n",
      "Epoch 3182, Loss: 0.0041088266398219275, Final Batch Loss: 0.0005012484616599977\n",
      "Epoch 3183, Loss: 0.0014638843285865732, Final Batch Loss: 0.00015422434080392122\n",
      "Epoch 3184, Loss: 0.01072132734952902, Final Batch Loss: 2.6168167096329853e-05\n",
      "Epoch 3185, Loss: 0.002409083170732629, Final Batch Loss: 0.00011484913557069376\n",
      "Epoch 3186, Loss: 0.003800004166578219, Final Batch Loss: 3.5790842503047315e-06\n",
      "Epoch 3187, Loss: 0.0008145497481564234, Final Batch Loss: 0.00016797341231722385\n",
      "Epoch 3188, Loss: 0.0026315024733776227, Final Batch Loss: 8.808068741927855e-06\n",
      "Epoch 3189, Loss: 0.002281058844630479, Final Batch Loss: 1.9949920897488482e-05\n",
      "Epoch 3190, Loss: 0.004256774495161153, Final Batch Loss: 2.8033327907905914e-05\n",
      "Epoch 3191, Loss: 0.0004913487068733957, Final Batch Loss: 2.6996427550329827e-05\n",
      "Epoch 3192, Loss: 0.00113661016041533, Final Batch Loss: 1.591842192283366e-05\n",
      "Epoch 3193, Loss: 0.0009211024551802893, Final Batch Loss: 1.5135808098420966e-05\n",
      "Epoch 3194, Loss: 0.001511189992470463, Final Batch Loss: 4.410904239193769e-06\n",
      "Epoch 3195, Loss: 0.001585021711889567, Final Batch Loss: 2.948466681118589e-05\n",
      "Epoch 3196, Loss: 0.00027649796027162665, Final Batch Loss: 1.4939120092094527e-06\n",
      "Epoch 3197, Loss: 0.0004760606557852043, Final Batch Loss: 7.677050234633498e-06\n",
      "Epoch 3198, Loss: 0.0045819395712669575, Final Batch Loss: 0.0042840964160859585\n",
      "Epoch 3199, Loss: 0.004380740254589455, Final Batch Loss: 5.5202337534865364e-05\n",
      "Epoch 3200, Loss: 0.0019342256899221866, Final Batch Loss: 1.4553382243320812e-05\n",
      "Epoch 3201, Loss: 0.0004322686495470407, Final Batch Loss: 8.539176633348688e-05\n",
      "Epoch 3202, Loss: 0.03514666027263047, Final Batch Loss: 4.6583852963522077e-05\n",
      "Epoch 3203, Loss: 0.003919232360317437, Final Batch Loss: 1.1607005035330076e-05\n",
      "Epoch 3204, Loss: 0.011998173174042392, Final Batch Loss: 0.0007076287874951959\n",
      "Epoch 3205, Loss: 0.005123248020936444, Final Batch Loss: 0.004526518750935793\n",
      "Epoch 3206, Loss: 0.0059781215430234624, Final Batch Loss: 5.8456582337385044e-05\n",
      "Epoch 3207, Loss: 0.001524200168319112, Final Batch Loss: 0.00047661797725595534\n",
      "Epoch 3208, Loss: 0.007053893685736057, Final Batch Loss: 4.0028730836638715e-06\n",
      "Epoch 3209, Loss: 0.003121170340534718, Final Batch Loss: 1.8365368532613502e-06\n",
      "Epoch 3210, Loss: 0.0007841815402116481, Final Batch Loss: 8.015253115445375e-06\n",
      "Epoch 3211, Loss: 0.011288577875347983, Final Batch Loss: 5.860226792719914e-06\n",
      "Epoch 3212, Loss: 0.0007379852951316934, Final Batch Loss: 2.343457481401856e-06\n",
      "Epoch 3213, Loss: 0.0009752302609626895, Final Batch Loss: 3.0078796044108458e-05\n",
      "Epoch 3214, Loss: 0.0026373905784566887, Final Batch Loss: 7.0482810770045035e-06\n",
      "Epoch 3215, Loss: 0.0036390761879374622, Final Batch Loss: 0.002563551301136613\n",
      "Epoch 3216, Loss: 0.005196656921782505, Final Batch Loss: 0.00012514220725279301\n",
      "Epoch 3217, Loss: 0.0020957389365321433, Final Batch Loss: 2.7589443561737426e-05\n",
      "Epoch 3218, Loss: 0.0005457802906221332, Final Batch Loss: 2.1873456717003137e-05\n",
      "Epoch 3219, Loss: 0.013319611859742508, Final Batch Loss: 3.1707174912298797e-06\n",
      "Epoch 3220, Loss: 0.00138073508708203, Final Batch Loss: 0.0001926943368744105\n",
      "Epoch 3221, Loss: 0.016490709913057344, Final Batch Loss: 1.5354024071712047e-05\n",
      "Epoch 3222, Loss: 0.015425315330048761, Final Batch Loss: 0.0012069953372702003\n",
      "Epoch 3223, Loss: 0.019537859192196194, Final Batch Loss: 0.01808040589094162\n",
      "Epoch 3224, Loss: 0.018839232971686215, Final Batch Loss: 9.7192038083449e-05\n",
      "Epoch 3225, Loss: 0.022103792461621197, Final Batch Loss: 0.00031765602761879563\n",
      "Epoch 3226, Loss: 0.0017175835373564041, Final Batch Loss: 0.0005494515062309802\n",
      "Epoch 3227, Loss: 0.002516825332349981, Final Batch Loss: 0.0002050520561169833\n",
      "Epoch 3228, Loss: 0.004205567487815642, Final Batch Loss: 7.430742243741406e-06\n",
      "Epoch 3229, Loss: 0.001178754917191327, Final Batch Loss: 9.217102160619106e-06\n",
      "Epoch 3230, Loss: 0.0034782182260642003, Final Batch Loss: 8.680090104462579e-06\n",
      "Epoch 3231, Loss: 0.007349529862040072, Final Batch Loss: 6.622412183787674e-05\n",
      "Epoch 3232, Loss: 0.0006626977531141165, Final Batch Loss: 8.704629181011114e-06\n",
      "Epoch 3233, Loss: 0.0010262572823194205, Final Batch Loss: 7.993276085471734e-07\n",
      "Epoch 3234, Loss: 0.0006490519287467578, Final Batch Loss: 3.198709009666345e-06\n",
      "Epoch 3235, Loss: 0.0008972107000886353, Final Batch Loss: 8.881262147042435e-06\n",
      "Epoch 3236, Loss: 0.001997375535779611, Final Batch Loss: 7.959692993608769e-07\n",
      "Epoch 3237, Loss: 0.0004176981041155159, Final Batch Loss: 1.3246217349660583e-05\n",
      "Epoch 3238, Loss: 0.0027558117513422076, Final Batch Loss: 1.2022771443298552e-05\n",
      "Epoch 3239, Loss: 0.030101844811952105, Final Batch Loss: 5.1380720833549276e-05\n",
      "Epoch 3240, Loss: 0.0046939458176780136, Final Batch Loss: 5.023185167374322e-06\n",
      "Epoch 3241, Loss: 0.0007255482986465722, Final Batch Loss: 8.605926268501207e-05\n",
      "Epoch 3242, Loss: 0.0015846683832592134, Final Batch Loss: 0.000777327106334269\n",
      "Epoch 3243, Loss: 0.011596671039569628, Final Batch Loss: 1.282028551941039e-05\n",
      "Epoch 3244, Loss: 0.005642284591303337, Final Batch Loss: 1.0736674994404893e-05\n",
      "Epoch 3245, Loss: 0.003071485207669866, Final Batch Loss: 6.819192640250549e-05\n",
      "Epoch 3246, Loss: 0.020182424796445275, Final Batch Loss: 4.358178557595238e-05\n",
      "Epoch 3247, Loss: 0.001773457591184524, Final Batch Loss: 0.00013267686881590635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3248, Loss: 0.029289358676976462, Final Batch Loss: 0.0018634973093867302\n",
      "Epoch 3249, Loss: 0.014892463258092903, Final Batch Loss: 0.0020051009487360716\n",
      "Epoch 3250, Loss: 0.05850069625466858, Final Batch Loss: 9.218926425091922e-05\n",
      "Epoch 3251, Loss: 0.004564771381410537, Final Batch Loss: 5.6426968512823805e-05\n",
      "Epoch 3252, Loss: 0.011596475253099925, Final Batch Loss: 0.002429865999147296\n",
      "Epoch 3253, Loss: 0.004704129540186841, Final Batch Loss: 0.0005210574017837644\n",
      "Epoch 3254, Loss: 0.002058572638077294, Final Batch Loss: 4.064469612785615e-05\n",
      "Epoch 3255, Loss: 0.025890862359403854, Final Batch Loss: 0.00015483346942346543\n",
      "Epoch 3256, Loss: 0.004175482686605392, Final Batch Loss: 0.00020549634064082056\n",
      "Epoch 3257, Loss: 0.002725869111600332, Final Batch Loss: 3.3192736736964434e-05\n",
      "Epoch 3258, Loss: 0.0010605575143927126, Final Batch Loss: 0.00019734875240828842\n",
      "Epoch 3259, Loss: 0.001044282752673098, Final Batch Loss: 1.717816667223815e-05\n",
      "Epoch 3260, Loss: 0.0007734964383416809, Final Batch Loss: 7.574835763080046e-06\n",
      "Epoch 3261, Loss: 0.002561893108577351, Final Batch Loss: 0.0008939541294239461\n",
      "Epoch 3262, Loss: 0.011858690153758289, Final Batch Loss: 0.00016477183089591563\n",
      "Epoch 3263, Loss: 0.013806945844521579, Final Batch Loss: 5.65451082366053e-05\n",
      "Epoch 3264, Loss: 0.023982914814041578, Final Batch Loss: 1.4506892512144987e-05\n",
      "Epoch 3265, Loss: 0.07457675309478873, Final Batch Loss: 0.03624684363603592\n",
      "Epoch 3266, Loss: 0.035182815645384835, Final Batch Loss: 0.007413958664983511\n",
      "Epoch 3267, Loss: 0.035804175329758436, Final Batch Loss: 0.0015902031445875764\n",
      "Epoch 3268, Loss: 0.03608405328486697, Final Batch Loss: 0.009770981967449188\n",
      "Epoch 3269, Loss: 0.013877844685339369, Final Batch Loss: 7.937852205941454e-05\n",
      "Epoch 3270, Loss: 0.02739356977508578, Final Batch Loss: 0.012590481899678707\n",
      "Epoch 3271, Loss: 0.002634114394822973, Final Batch Loss: 8.656881618662737e-06\n",
      "Epoch 3272, Loss: 0.0381119188368757, Final Batch Loss: 0.00020119892724324018\n",
      "Epoch 3273, Loss: 0.002590829202745226, Final Batch Loss: 7.74633081164211e-05\n",
      "Epoch 3274, Loss: 0.024345149274722644, Final Batch Loss: 0.00020600353309419006\n",
      "Epoch 3275, Loss: 0.011172325299412478, Final Batch Loss: 0.0034314068034291267\n",
      "Epoch 3276, Loss: 0.031679158173119504, Final Batch Loss: 0.0026340452022850513\n",
      "Epoch 3277, Loss: 0.015645965265321138, Final Batch Loss: 3.7788897316204384e-05\n",
      "Epoch 3278, Loss: 0.007209416409750702, Final Batch Loss: 0.00036225569783709943\n",
      "Epoch 3279, Loss: 0.003635015495092375, Final Batch Loss: 0.00022517146135214716\n",
      "Epoch 3280, Loss: 0.001955100014583877, Final Batch Loss: 0.00026193787925876677\n",
      "Epoch 3281, Loss: 0.009590266203304054, Final Batch Loss: 0.00042207675869576633\n",
      "Epoch 3282, Loss: 0.005270669859100963, Final Batch Loss: 2.337332944080117e-06\n",
      "Epoch 3283, Loss: 0.01196651027896678, Final Batch Loss: 3.9292077417485416e-05\n",
      "Epoch 3284, Loss: 0.007167283049057005, Final Batch Loss: 3.811797432717867e-05\n",
      "Epoch 3285, Loss: 0.003615249498579942, Final Batch Loss: 0.0001057264962582849\n",
      "Epoch 3286, Loss: 0.0021078172386523875, Final Batch Loss: 1.907805744849611e-05\n",
      "Epoch 3287, Loss: 0.0031363460466309334, Final Batch Loss: 4.986181011190638e-06\n",
      "Epoch 3288, Loss: 0.003404764295055429, Final Batch Loss: 0.00011056396033382043\n",
      "Epoch 3289, Loss: 0.018366363902941885, Final Batch Loss: 0.00012363686983007938\n",
      "Epoch 3290, Loss: 0.003692184506007834, Final Batch Loss: 9.227992995874956e-05\n",
      "Epoch 3291, Loss: 0.0019240805368099245, Final Batch Loss: 1.9142058590659872e-05\n",
      "Epoch 3292, Loss: 0.0023747751783957938, Final Batch Loss: 5.099542249809019e-05\n",
      "Epoch 3293, Loss: 0.0028778785276699637, Final Batch Loss: 4.441963028511964e-05\n",
      "Epoch 3294, Loss: 0.004307375661710466, Final Batch Loss: 0.0005175003898330033\n",
      "Epoch 3295, Loss: 0.008165083776020765, Final Batch Loss: 7.029627886367962e-05\n",
      "Epoch 3296, Loss: 0.017842277198724332, Final Batch Loss: 6.220225623110309e-05\n",
      "Epoch 3297, Loss: 0.004572500276481151, Final Batch Loss: 0.0015317543875426054\n",
      "Epoch 3298, Loss: 0.002657776583191662, Final Batch Loss: 5.296465315041132e-05\n",
      "Epoch 3299, Loss: 0.002372806512084935, Final Batch Loss: 4.428609463502653e-05\n",
      "Epoch 3300, Loss: 0.0024955314438557252, Final Batch Loss: 3.25750806950964e-05\n",
      "Epoch 3301, Loss: 0.00657201810645347, Final Batch Loss: 0.00014849624130874872\n",
      "Epoch 3302, Loss: 0.0013322663708095206, Final Batch Loss: 2.3130573026719503e-05\n",
      "Epoch 3303, Loss: 0.000853860990901012, Final Batch Loss: 1.2140557373641059e-05\n",
      "Epoch 3304, Loss: 0.0015448998344709253, Final Batch Loss: 1.4244337762647774e-05\n",
      "Epoch 3305, Loss: 0.0005524022949430218, Final Batch Loss: 2.9565230761363637e-06\n",
      "Epoch 3306, Loss: 0.01048166401801609, Final Batch Loss: 0.00010887161624850705\n",
      "Epoch 3307, Loss: 0.01818139278941544, Final Batch Loss: 0.00037398855783976614\n",
      "Epoch 3308, Loss: 0.006727069953967657, Final Batch Loss: 3.062924588448368e-05\n",
      "Epoch 3309, Loss: 0.008721766245116669, Final Batch Loss: 1.7282749467995018e-05\n",
      "Epoch 3310, Loss: 0.03040658002487362, Final Batch Loss: 0.00013558439968619496\n",
      "Epoch 3311, Loss: 0.002241577916379356, Final Batch Loss: 3.3235639875783818e-06\n",
      "Epoch 3312, Loss: 0.021243089433028217, Final Batch Loss: 0.0011701749172061682\n",
      "Epoch 3313, Loss: 0.006959379986142267, Final Batch Loss: 3.762832420761697e-05\n",
      "Epoch 3314, Loss: 0.0023470141596817484, Final Batch Loss: 7.24351848475635e-05\n",
      "Epoch 3315, Loss: 0.01281262544762285, Final Batch Loss: 8.800608338788152e-05\n",
      "Epoch 3316, Loss: 0.00036579324961394377, Final Batch Loss: 5.81603330829239e-07\n",
      "Epoch 3317, Loss: 0.0007927084083689806, Final Batch Loss: 5.5019959290802944e-06\n",
      "Epoch 3318, Loss: 0.000813884221997796, Final Batch Loss: 0.0002316474710823968\n",
      "Epoch 3319, Loss: 0.000642952951125153, Final Batch Loss: 0.0001271306973649189\n",
      "Epoch 3320, Loss: 0.0020917339064396856, Final Batch Loss: 2.670256799319759e-05\n",
      "Epoch 3321, Loss: 0.000686214538745844, Final Batch Loss: 8.067036105785519e-06\n",
      "Epoch 3322, Loss: 0.005387152153929264, Final Batch Loss: 3.4226730349473655e-05\n",
      "Epoch 3323, Loss: 0.00032091080083773704, Final Batch Loss: 2.176842281187419e-05\n",
      "Epoch 3324, Loss: 0.0026618128192694712, Final Batch Loss: 2.1324434783309698e-05\n",
      "Epoch 3325, Loss: 0.0005150279313852479, Final Batch Loss: 8.44467922433978e-06\n",
      "Epoch 3326, Loss: 0.003937034572061293, Final Batch Loss: 6.291939644142985e-05\n",
      "Epoch 3327, Loss: 0.0012592497190553331, Final Batch Loss: 2.880389274650952e-06\n",
      "Epoch 3328, Loss: 0.004321852949928484, Final Batch Loss: 1.7182966985274106e-05\n",
      "Epoch 3329, Loss: 0.009009979971381199, Final Batch Loss: 1.6404767393396469e-06\n",
      "Epoch 3330, Loss: 0.006172951843922192, Final Batch Loss: 0.0020421824883669615\n",
      "Epoch 3331, Loss: 0.0030311163018268417, Final Batch Loss: 4.227289082336938e-06\n",
      "Epoch 3332, Loss: 0.0005037468644673027, Final Batch Loss: 4.39662835560739e-06\n",
      "Epoch 3333, Loss: 0.012081969259810421, Final Batch Loss: 3.0245897505665198e-05\n",
      "Epoch 3334, Loss: 0.011215215324568817, Final Batch Loss: 5.028316536481725e-06\n",
      "Epoch 3335, Loss: 0.023852583537518512, Final Batch Loss: 2.4505561668775044e-05\n",
      "Epoch 3336, Loss: 0.01019662255384901, Final Batch Loss: 3.135505903628655e-05\n",
      "Epoch 3337, Loss: 0.0038540887808267144, Final Batch Loss: 0.0001912527222884819\n",
      "Epoch 3338, Loss: 0.0034539455969024857, Final Batch Loss: 1.925483775266912e-05\n",
      "Epoch 3339, Loss: 0.011189850460937123, Final Batch Loss: 2.4072264750429895e-06\n",
      "Epoch 3340, Loss: 0.0006510817482876519, Final Batch Loss: 0.00025938425096683204\n",
      "Epoch 3341, Loss: 0.0031699569061807154, Final Batch Loss: 3.2223786547547206e-05\n",
      "Epoch 3342, Loss: 0.014809967895700993, Final Batch Loss: 0.0003785556473303586\n",
      "Epoch 3343, Loss: 0.0014294918818222868, Final Batch Loss: 7.421967893606052e-05\n",
      "Epoch 3344, Loss: 0.01118822275157072, Final Batch Loss: 2.590068288554903e-05\n",
      "Epoch 3345, Loss: 0.0019160849460604368, Final Batch Loss: 5.160741784493439e-05\n",
      "Epoch 3346, Loss: 0.0009084189632631023, Final Batch Loss: 4.052742497151485e-06\n",
      "Epoch 3347, Loss: 0.0026133894538133973, Final Batch Loss: 1.7550630218465813e-05\n",
      "Epoch 3348, Loss: 0.0006408984904737736, Final Batch Loss: 6.620775820920244e-06\n",
      "Epoch 3349, Loss: 0.0005874259474580867, Final Batch Loss: 4.4586828153114766e-05\n",
      "Epoch 3350, Loss: 0.00040464434368914226, Final Batch Loss: 3.7483823689399287e-06\n",
      "Epoch 3351, Loss: 0.0008298352090605476, Final Batch Loss: 3.854513579426566e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3352, Loss: 0.000984063883901598, Final Batch Loss: 2.8550693969009444e-05\n",
      "Epoch 3353, Loss: 0.0025909643373154267, Final Batch Loss: 9.671774023445323e-06\n",
      "Epoch 3354, Loss: 0.0005335976326250602, Final Batch Loss: 2.971525191242108e-06\n",
      "Epoch 3355, Loss: 0.003008617823070381, Final Batch Loss: 6.993107672315091e-05\n",
      "Epoch 3356, Loss: 0.00405185065220337, Final Batch Loss: 3.7000802421971457e-06\n",
      "Epoch 3357, Loss: 0.00032002208149606304, Final Batch Loss: 1.8442617147229612e-05\n",
      "Epoch 3358, Loss: 0.000995669572262159, Final Batch Loss: 1.9099554720014567e-06\n",
      "Epoch 3359, Loss: 0.0007859944440440358, Final Batch Loss: 4.931698640575632e-07\n",
      "Epoch 3360, Loss: 0.00012425430664109172, Final Batch Loss: 6.464977673203975e-07\n",
      "Epoch 3361, Loss: 0.0008851385548354074, Final Batch Loss: 2.30650111916475e-05\n",
      "Epoch 3362, Loss: 0.00019349016747582937, Final Batch Loss: 4.48518039775081e-05\n",
      "Epoch 3363, Loss: 0.06486120965093534, Final Batch Loss: 0.03137078136205673\n",
      "Epoch 3364, Loss: 0.10450154989533189, Final Batch Loss: 0.0001300697767874226\n",
      "Epoch 3365, Loss: 0.030654104873974575, Final Batch Loss: 4.496609471971169e-05\n",
      "Epoch 3366, Loss: 0.0036605097047868185, Final Batch Loss: 8.60354193719104e-05\n",
      "Epoch 3367, Loss: 0.002457410964780138, Final Batch Loss: 3.2470365113113075e-05\n",
      "Epoch 3368, Loss: 0.007874379780332674, Final Batch Loss: 4.662453648052178e-05\n",
      "Epoch 3369, Loss: 0.0033715227377228985, Final Batch Loss: 6.26103428658098e-05\n",
      "Epoch 3370, Loss: 0.0035974005289745037, Final Batch Loss: 6.790674433432287e-06\n",
      "Epoch 3371, Loss: 0.011392074419063647, Final Batch Loss: 0.00013463622599374503\n",
      "Epoch 3372, Loss: 0.0012853563025601034, Final Batch Loss: 4.817240551346913e-05\n",
      "Epoch 3373, Loss: 0.0007302130147763819, Final Batch Loss: 3.5537475469027413e-06\n",
      "Epoch 3374, Loss: 0.0023183377422810736, Final Batch Loss: 2.8497754101408646e-05\n",
      "Epoch 3375, Loss: 0.004767384477418091, Final Batch Loss: 5.8017535593535285e-06\n",
      "Epoch 3376, Loss: 0.007134848347732259, Final Batch Loss: 0.0001125477283494547\n",
      "Epoch 3377, Loss: 0.003247576341209424, Final Batch Loss: 0.002121857600286603\n",
      "Epoch 3378, Loss: 0.0013277674588607624, Final Batch Loss: 3.1449879315914586e-05\n",
      "Epoch 3379, Loss: 0.0005514335528005176, Final Batch Loss: 5.250829053693451e-05\n",
      "Epoch 3380, Loss: 0.00022056510471202273, Final Batch Loss: 7.192206248873845e-05\n",
      "Epoch 3381, Loss: 0.004681578003328468, Final Batch Loss: 8.837767381919548e-06\n",
      "Epoch 3382, Loss: 0.0009057048948761803, Final Batch Loss: 2.708091415115632e-05\n",
      "Epoch 3383, Loss: 0.0007520315156170909, Final Batch Loss: 0.00019915268057957292\n",
      "Epoch 3384, Loss: 0.0023788629353589386, Final Batch Loss: 2.3827456061553676e-06\n",
      "Epoch 3385, Loss: 0.00048676459954322127, Final Batch Loss: 0.0001738924765959382\n",
      "Epoch 3386, Loss: 0.000845466563816899, Final Batch Loss: 1.9949568468291545e-06\n",
      "Epoch 3387, Loss: 0.0017891934863882852, Final Batch Loss: 7.795419151079841e-06\n",
      "Epoch 3388, Loss: 0.005100229798244982, Final Batch Loss: 2.037694866885431e-05\n",
      "Epoch 3389, Loss: 0.0022171260875438747, Final Batch Loss: 0.0017708432860672474\n",
      "Epoch 3390, Loss: 0.0002898516525533523, Final Batch Loss: 3.2138123060576618e-06\n",
      "Epoch 3391, Loss: 0.0003021919171146692, Final Batch Loss: 9.575938747730106e-06\n",
      "Epoch 3392, Loss: 0.0005717104774589643, Final Batch Loss: 2.682172089407686e-05\n",
      "Epoch 3393, Loss: 0.0008923459500920217, Final Batch Loss: 1.0556874258327298e-05\n",
      "Epoch 3394, Loss: 0.0001983193076284806, Final Batch Loss: 5.3028419642942026e-05\n",
      "Epoch 3395, Loss: 0.00016708782794694343, Final Batch Loss: 2.6222180622426094e-06\n",
      "Epoch 3396, Loss: 0.00023219698599064031, Final Batch Loss: 3.1276872505259234e-06\n",
      "Epoch 3397, Loss: 0.008128697829022258, Final Batch Loss: 1.3213154943514382e-06\n",
      "Epoch 3398, Loss: 0.00124693921651442, Final Batch Loss: 7.171222023316659e-06\n",
      "Epoch 3399, Loss: 0.00029586512582113755, Final Batch Loss: 6.464791113103274e-06\n",
      "Epoch 3400, Loss: 0.0007251442572169253, Final Batch Loss: 5.79676566303533e-07\n",
      "Epoch 3401, Loss: 0.00047473999700287095, Final Batch Loss: 1.3554238194046775e-06\n",
      "Epoch 3402, Loss: 0.005309012033649196, Final Batch Loss: 2.2654032363789156e-05\n",
      "Epoch 3403, Loss: 0.02034608761675827, Final Batch Loss: 2.5781716885830974e-06\n",
      "Epoch 3404, Loss: 0.002150679906037567, Final Batch Loss: 6.777464136575873e-07\n",
      "Epoch 3405, Loss: 0.0005678443698684532, Final Batch Loss: 8.5980227595428e-06\n",
      "Epoch 3406, Loss: 0.004077109556703817, Final Batch Loss: 5.18269334861543e-05\n",
      "Epoch 3407, Loss: 0.0006602686562473536, Final Batch Loss: 0.00035359489265829325\n",
      "Epoch 3408, Loss: 0.000517648770028245, Final Batch Loss: 5.77974196858122e-06\n",
      "Epoch 3409, Loss: 0.006259249521690435, Final Batch Loss: 4.216438901494257e-05\n",
      "Epoch 3410, Loss: 0.0006826473487535623, Final Batch Loss: 4.76275963592343e-05\n",
      "Epoch 3411, Loss: 0.0016895009091513202, Final Batch Loss: 2.3779963157721795e-05\n",
      "Epoch 3412, Loss: 0.006360517872167293, Final Batch Loss: 0.0015181455528363585\n",
      "Epoch 3413, Loss: 0.0003188678508081466, Final Batch Loss: 2.1443902369355783e-05\n",
      "Epoch 3414, Loss: 0.0008066348053716865, Final Batch Loss: 0.0001577454968355596\n",
      "Epoch 3415, Loss: 0.0025672942972221335, Final Batch Loss: 0.0003114707360509783\n",
      "Epoch 3416, Loss: 0.0030557518502973835, Final Batch Loss: 2.0833587768720463e-05\n",
      "Epoch 3417, Loss: 0.0003766280308923342, Final Batch Loss: 9.90325934253633e-05\n",
      "Epoch 3418, Loss: 0.0024698898651536183, Final Batch Loss: 3.3154806260426994e-06\n",
      "Epoch 3419, Loss: 0.009418879387169454, Final Batch Loss: 0.008939134888350964\n",
      "Epoch 3420, Loss: 0.025872539241703407, Final Batch Loss: 3.8079291698522866e-05\n",
      "Epoch 3421, Loss: 0.004002518311608583, Final Batch Loss: 0.0016490045236423612\n",
      "Epoch 3422, Loss: 0.0021857211488054418, Final Batch Loss: 2.5392168026883155e-05\n",
      "Epoch 3423, Loss: 0.0024309080224611535, Final Batch Loss: 4.3977852328680456e-05\n",
      "Epoch 3424, Loss: 0.0050921952893077105, Final Batch Loss: 0.00017426761041861027\n",
      "Epoch 3425, Loss: 0.058778912478146594, Final Batch Loss: 3.87500949727837e-05\n",
      "Epoch 3426, Loss: 0.018393697834824252, Final Batch Loss: 1.003607212624047e-05\n",
      "Epoch 3427, Loss: 0.013261591655464144, Final Batch Loss: 2.3112527287594276e-06\n",
      "Epoch 3428, Loss: 0.20329620263589732, Final Batch Loss: 9.094229608308524e-05\n",
      "Epoch 3429, Loss: 0.11059954182690035, Final Batch Loss: 0.0006922292523086071\n",
      "Epoch 3430, Loss: 0.02712788724306847, Final Batch Loss: 0.002079397439956665\n",
      "Epoch 3431, Loss: 0.08931131117833502, Final Batch Loss: 0.04965154081583023\n",
      "Epoch 3432, Loss: 0.008946879359882587, Final Batch Loss: 0.0007463869987986982\n",
      "Epoch 3433, Loss: 0.0036090055345994188, Final Batch Loss: 5.344141027308069e-05\n",
      "Epoch 3434, Loss: 0.004679727941038436, Final Batch Loss: 0.0006556668668054044\n",
      "Epoch 3435, Loss: 0.0073241210934611445, Final Batch Loss: 6.493594992207363e-05\n",
      "Epoch 3436, Loss: 0.008377644115626026, Final Batch Loss: 0.000530272489413619\n",
      "Epoch 3437, Loss: 0.0030992378055998415, Final Batch Loss: 9.002470505947713e-06\n",
      "Epoch 3438, Loss: 0.005251853069694334, Final Batch Loss: 1.1732867278624326e-05\n",
      "Epoch 3439, Loss: 0.005943883619238477, Final Batch Loss: 0.0002175189001718536\n",
      "Epoch 3440, Loss: 0.001013166135408028, Final Batch Loss: 0.00013555529585573822\n",
      "Epoch 3441, Loss: 0.0008539865248167189, Final Batch Loss: 9.449936442251783e-07\n",
      "Epoch 3442, Loss: 0.003487492228600786, Final Batch Loss: 0.0007520387298427522\n",
      "Epoch 3443, Loss: 0.0009088164453032732, Final Batch Loss: 1.4963214880481246e-06\n",
      "Epoch 3444, Loss: 0.0011029022166439972, Final Batch Loss: 0.0004630560288205743\n",
      "Epoch 3445, Loss: 0.0006740704354797344, Final Batch Loss: 7.703268056502566e-05\n",
      "Epoch 3446, Loss: 0.001299363917496521, Final Batch Loss: 8.52183293318376e-05\n",
      "Epoch 3447, Loss: 0.0010945394160444266, Final Batch Loss: 1.1664506018860266e-05\n",
      "Epoch 3448, Loss: 0.0010332786050639697, Final Batch Loss: 1.9853352569043636e-05\n",
      "Epoch 3449, Loss: 0.0004028363837278448, Final Batch Loss: 4.733231435238849e-06\n",
      "Epoch 3450, Loss: 0.0010153066332350136, Final Batch Loss: 2.622822648845613e-06\n",
      "Epoch 3451, Loss: 0.0003953150078359613, Final Batch Loss: 2.785592414511484e-06\n",
      "Epoch 3452, Loss: 0.0004507168067675593, Final Batch Loss: 1.913887672344572e-06\n",
      "Epoch 3453, Loss: 0.002065456111097319, Final Batch Loss: 1.2914896387883346e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3454, Loss: 0.004499152102880544, Final Batch Loss: 6.879176908114459e-06\n",
      "Epoch 3455, Loss: 0.0018512695713184257, Final Batch Loss: 0.00010201057739323005\n",
      "Epoch 3456, Loss: 0.0007562415607935691, Final Batch Loss: 1.086726024368545e-05\n",
      "Epoch 3457, Loss: 0.0009475987080236337, Final Batch Loss: 1.5901967344689183e-05\n",
      "Epoch 3458, Loss: 0.00047191640607024965, Final Batch Loss: 4.6125987864797935e-06\n",
      "Epoch 3459, Loss: 0.0006014578326585251, Final Batch Loss: 6.546327313117217e-06\n",
      "Epoch 3460, Loss: 0.0004780989892196885, Final Batch Loss: 1.1800836546171922e-05\n",
      "Epoch 3461, Loss: 0.00039188145211710435, Final Batch Loss: 1.775944951987185e-06\n",
      "Epoch 3462, Loss: 0.004488265233021593, Final Batch Loss: 1.3530011528928299e-05\n",
      "Epoch 3463, Loss: 0.0022222406743708234, Final Batch Loss: 5.886893632123247e-06\n",
      "Epoch 3464, Loss: 0.0010121610495730238, Final Batch Loss: 0.00014191324589774013\n",
      "Epoch 3465, Loss: 0.008279155787960235, Final Batch Loss: 6.318410305539146e-05\n",
      "Epoch 3466, Loss: 0.003577969203757192, Final Batch Loss: 1.0285552889399696e-06\n",
      "Epoch 3467, Loss: 0.0019039761927786003, Final Batch Loss: 7.871466550568584e-06\n",
      "Epoch 3468, Loss: 0.002172814030700465, Final Batch Loss: 1.8426492260914529e-06\n",
      "Epoch 3469, Loss: 0.0008939307393802665, Final Batch Loss: 0.00036146800266578794\n",
      "Epoch 3470, Loss: 0.0011804106360386868, Final Batch Loss: 5.49885908185388e-06\n",
      "Epoch 3471, Loss: 0.020145625401482903, Final Batch Loss: 8.623064786661416e-05\n",
      "Epoch 3472, Loss: 0.007450730846585429, Final Batch Loss: 0.00017009713337756693\n",
      "Epoch 3473, Loss: 0.016763078832127576, Final Batch Loss: 5.485812289407477e-05\n",
      "Epoch 3474, Loss: 0.007496735217500827, Final Batch Loss: 1.1829872164526023e-05\n",
      "Epoch 3475, Loss: 0.022372164666222716, Final Batch Loss: 0.0001455293531762436\n",
      "Epoch 3476, Loss: 0.009735155050520916, Final Batch Loss: 3.332659844090813e-06\n",
      "Epoch 3477, Loss: 0.0020681548687662143, Final Batch Loss: 6.395567197614582e-06\n",
      "Epoch 3478, Loss: 0.01339574302926394, Final Batch Loss: 0.00039593956898897886\n",
      "Epoch 3479, Loss: 0.013209451811690087, Final Batch Loss: 4.770686700794613e-06\n",
      "Epoch 3480, Loss: 0.006896979507359902, Final Batch Loss: 3.5651867165142903e-06\n",
      "Epoch 3481, Loss: 0.009741656871369742, Final Batch Loss: 1.343464987257903e-06\n",
      "Epoch 3482, Loss: 0.03536745689871168, Final Batch Loss: 0.010218409821391106\n",
      "Epoch 3483, Loss: 0.015253743790594854, Final Batch Loss: 5.334613888408057e-06\n",
      "Epoch 3484, Loss: 0.02073515633480838, Final Batch Loss: 0.0002086417080136016\n",
      "Epoch 3485, Loss: 0.0007800786731877452, Final Batch Loss: 0.00012179240002296865\n",
      "Epoch 3486, Loss: 0.001883022583569982, Final Batch Loss: 0.00018125689530279487\n",
      "Epoch 3487, Loss: 0.00387384885721076, Final Batch Loss: 5.59040745429229e-06\n",
      "Epoch 3488, Loss: 0.004788848128100653, Final Batch Loss: 3.81559002562426e-05\n",
      "Epoch 3489, Loss: 0.002608944049512729, Final Batch Loss: 5.181532287679147e-07\n",
      "Epoch 3490, Loss: 0.0004852071228924615, Final Batch Loss: 8.680780752001738e-07\n",
      "Epoch 3491, Loss: 0.0017509441258880543, Final Batch Loss: 4.6917475629015826e-06\n",
      "Epoch 3492, Loss: 0.0007679139829406267, Final Batch Loss: 1.0831153304025065e-05\n",
      "Epoch 3493, Loss: 0.0009867939018022298, Final Batch Loss: 0.00045923347352072597\n",
      "Epoch 3494, Loss: 0.0009406485423255617, Final Batch Loss: 6.264606054173782e-05\n",
      "Epoch 3495, Loss: 0.001434593917906568, Final Batch Loss: 7.388810900010867e-06\n",
      "Epoch 3496, Loss: 0.006659958904407404, Final Batch Loss: 1.819226895349857e-06\n",
      "Epoch 3497, Loss: 0.00019810653557783553, Final Batch Loss: 9.760416105564218e-06\n",
      "Epoch 3498, Loss: 0.0012387346414470812, Final Batch Loss: 3.3426204026909545e-05\n",
      "Epoch 3499, Loss: 0.0020814326793470173, Final Batch Loss: 7.627902505191742e-07\n",
      "Epoch 3500, Loss: 0.0013009056604573743, Final Batch Loss: 1.1091475244029425e-05\n",
      "Epoch 3501, Loss: 0.002108757864561994, Final Batch Loss: 5.141262136021396e-06\n",
      "Epoch 3502, Loss: 0.0010537171806390688, Final Batch Loss: 2.824656621669419e-05\n",
      "Epoch 3503, Loss: 0.002690752155217524, Final Batch Loss: 9.302802936872467e-06\n",
      "Epoch 3504, Loss: 0.0004247786708901913, Final Batch Loss: 4.642853582481621e-06\n",
      "Epoch 3505, Loss: 0.04403846225318375, Final Batch Loss: 0.0008195108966901898\n",
      "Epoch 3506, Loss: 0.006377627839981415, Final Batch Loss: 1.907893965835683e-05\n",
      "Epoch 3507, Loss: 0.0029146629934757584, Final Batch Loss: 6.356800895446213e-06\n",
      "Epoch 3508, Loss: 0.0023015134388515435, Final Batch Loss: 0.00013069216220173985\n",
      "Epoch 3509, Loss: 0.0166144313135419, Final Batch Loss: 1.0375958481745329e-05\n",
      "Epoch 3510, Loss: 0.009038965854756498, Final Batch Loss: 2.6881634767050855e-06\n",
      "Epoch 3511, Loss: 0.0013533823307625426, Final Batch Loss: 2.6755751605378464e-05\n",
      "Epoch 3512, Loss: 0.011478269084989279, Final Batch Loss: 1.5173085330388858e-06\n",
      "Epoch 3513, Loss: 0.013223103673226433, Final Batch Loss: 0.0003847465559374541\n",
      "Epoch 3514, Loss: 0.01262807316368253, Final Batch Loss: 2.7633423087536357e-06\n",
      "Epoch 3515, Loss: 0.014034593136727835, Final Batch Loss: 4.159527816227637e-05\n",
      "Epoch 3516, Loss: 0.01717672964468875, Final Batch Loss: 2.186983238061657e-06\n",
      "Epoch 3517, Loss: 0.015051605952066893, Final Batch Loss: 6.051251148164738e-06\n",
      "Epoch 3518, Loss: 0.019533756520267787, Final Batch Loss: 8.25536044430919e-05\n",
      "Epoch 3519, Loss: 0.021513844854780473, Final Batch Loss: 0.0005341207142919302\n",
      "Epoch 3520, Loss: 0.017774377338810154, Final Batch Loss: 0.0001993527839658782\n",
      "Epoch 3521, Loss: 0.03473549739737791, Final Batch Loss: 0.0058024609461426735\n",
      "Epoch 3522, Loss: 0.005100824826513417, Final Batch Loss: 1.4728305359312799e-05\n",
      "Epoch 3523, Loss: 0.0006935844194231322, Final Batch Loss: 6.104943622631254e-06\n",
      "Epoch 3524, Loss: 0.001357877757584447, Final Batch Loss: 6.061232511456183e-07\n",
      "Epoch 3525, Loss: 0.020192807843955052, Final Batch Loss: 0.0046794964000582695\n",
      "Epoch 3526, Loss: 0.010292315855622292, Final Batch Loss: 0.001294202171266079\n",
      "Epoch 3527, Loss: 0.004569996751001781, Final Batch Loss: 0.0001514623872935772\n",
      "Epoch 3528, Loss: 0.0004109243879497626, Final Batch Loss: 5.0872193241957575e-05\n",
      "Epoch 3529, Loss: 0.006952665342168984, Final Batch Loss: 4.614872523234226e-06\n",
      "Epoch 3530, Loss: 0.0008171263113609939, Final Batch Loss: 6.69177679810673e-05\n",
      "Epoch 3531, Loss: 0.0005325939100657706, Final Batch Loss: 2.554868297011126e-05\n",
      "Epoch 3532, Loss: 0.0012450606238871842, Final Batch Loss: 8.054051249928307e-06\n",
      "Epoch 3533, Loss: 0.005999336491868235, Final Batch Loss: 0.005215563345700502\n",
      "Epoch 3534, Loss: 0.009172641184363783, Final Batch Loss: 0.0001649181795073673\n",
      "Epoch 3535, Loss: 0.06847919782194367, Final Batch Loss: 0.01921694725751877\n",
      "Epoch 3536, Loss: 0.002280279442970823, Final Batch Loss: 0.00027814132045023143\n",
      "Epoch 3537, Loss: 0.0008707189299457241, Final Batch Loss: 2.1229345293249935e-05\n",
      "Epoch 3538, Loss: 0.002241443591174175, Final Batch Loss: 7.681866009079386e-06\n",
      "Epoch 3539, Loss: 0.009542270927738628, Final Batch Loss: 5.655583299812861e-05\n",
      "Epoch 3540, Loss: 0.00042746586746034154, Final Batch Loss: 2.2836409698356874e-05\n",
      "Epoch 3541, Loss: 0.00026029601258414914, Final Batch Loss: 3.95987335650716e-05\n",
      "Epoch 3542, Loss: 0.002520899557566736, Final Batch Loss: 5.6554072216385975e-06\n",
      "Epoch 3543, Loss: 0.0005192842515953089, Final Batch Loss: 6.80016164551489e-05\n",
      "Epoch 3544, Loss: 0.0013592660884285124, Final Batch Loss: 5.373526619223412e-06\n",
      "Epoch 3545, Loss: 0.0010708797204159737, Final Batch Loss: 1.3449393918563146e-05\n",
      "Epoch 3546, Loss: 0.0009591382113001146, Final Batch Loss: 0.00041642726864665747\n",
      "Epoch 3547, Loss: 0.0023314145390713747, Final Batch Loss: 0.001732191420160234\n",
      "Epoch 3548, Loss: 0.0004598232060857299, Final Batch Loss: 7.680040653212927e-06\n",
      "Epoch 3549, Loss: 0.0009055984765851122, Final Batch Loss: 0.00012141857587266713\n",
      "Epoch 3550, Loss: 0.0004391817549276311, Final Batch Loss: 3.498854857753031e-05\n",
      "Epoch 3551, Loss: 0.0005082346708604746, Final Batch Loss: 6.570784535142593e-06\n",
      "Epoch 3552, Loss: 0.03366512932052501, Final Batch Loss: 4.5656586735276505e-05\n",
      "Epoch 3553, Loss: 0.0012151537697207004, Final Batch Loss: 7.812479452695698e-06\n",
      "Epoch 3554, Loss: 0.0006231959999922765, Final Batch Loss: 8.753816473472398e-06\n",
      "Epoch 3555, Loss: 0.0013970370837341761, Final Batch Loss: 1.1467516742413864e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3556, Loss: 0.00036237177857856295, Final Batch Loss: 2.7654830319079338e-06\n",
      "Epoch 3557, Loss: 0.013532084045152715, Final Batch Loss: 0.00013738784764427692\n",
      "Epoch 3558, Loss: 0.0022127496286543646, Final Batch Loss: 6.750972261215793e-06\n",
      "Epoch 3559, Loss: 0.000940655861313644, Final Batch Loss: 1.2169219189672731e-05\n",
      "Epoch 3560, Loss: 0.0012293039152666552, Final Batch Loss: 7.0435266934509855e-06\n",
      "Epoch 3561, Loss: 0.0006583096275676326, Final Batch Loss: 1.3295148164615966e-06\n",
      "Epoch 3562, Loss: 0.005098266847653576, Final Batch Loss: 1.1245541827520356e-05\n",
      "Epoch 3563, Loss: 0.0013304297825698086, Final Batch Loss: 0.00013406758080236614\n",
      "Epoch 3564, Loss: 0.016541204396105513, Final Batch Loss: 3.8811558624729514e-05\n",
      "Epoch 3565, Loss: 0.02596003909465594, Final Batch Loss: 2.076186501653865e-05\n",
      "Epoch 3566, Loss: 0.0018946892619169375, Final Batch Loss: 7.494610144931357e-06\n",
      "Epoch 3567, Loss: 0.004614853999896695, Final Batch Loss: 6.097308869357221e-06\n",
      "Epoch 3568, Loss: 0.0024656099583353353, Final Batch Loss: 1.614697430341039e-05\n",
      "Epoch 3569, Loss: 0.0011605149709339457, Final Batch Loss: 6.910430965945125e-05\n",
      "Epoch 3570, Loss: 0.0016645152808649755, Final Batch Loss: 5.521375442185672e-06\n",
      "Epoch 3571, Loss: 0.00444484024006897, Final Batch Loss: 0.0001844873040681705\n",
      "Epoch 3572, Loss: 0.0004547580050200395, Final Batch Loss: 1.0340353583160322e-05\n",
      "Epoch 3573, Loss: 0.006240573298924801, Final Batch Loss: 7.368714705080492e-07\n",
      "Epoch 3574, Loss: 0.006196341618306178, Final Batch Loss: 3.6647118122346e-06\n",
      "Epoch 3575, Loss: 0.0031864939026036154, Final Batch Loss: 4.762746175401844e-05\n",
      "Epoch 3576, Loss: 0.00874756895768769, Final Batch Loss: 2.066637307507335e-06\n",
      "Epoch 3577, Loss: 0.009914278617998207, Final Batch Loss: 0.0005997078842483461\n",
      "Epoch 3578, Loss: 0.0049649932161628385, Final Batch Loss: 8.322871872223914e-05\n",
      "Epoch 3579, Loss: 0.019354035449282492, Final Batch Loss: 4.938036454404937e-06\n",
      "Epoch 3580, Loss: 0.002091586468850437, Final Batch Loss: 1.2894782230432611e-05\n",
      "Epoch 3581, Loss: 0.0005848256969329668, Final Batch Loss: 4.389919467939762e-06\n",
      "Epoch 3582, Loss: 0.002723382176782252, Final Batch Loss: 3.3349911973346025e-05\n",
      "Epoch 3583, Loss: 0.0006921980077549961, Final Batch Loss: 4.427448220667429e-05\n",
      "Epoch 3584, Loss: 0.002103083860447441, Final Batch Loss: 2.8078400191589026e-06\n",
      "Epoch 3585, Loss: 0.010812093259801259, Final Batch Loss: 7.7158847489045e-06\n",
      "Epoch 3586, Loss: 0.0022022446105438576, Final Batch Loss: 4.549909135675989e-06\n",
      "Epoch 3587, Loss: 0.0012861947510174332, Final Batch Loss: 2.7333100661053322e-05\n",
      "Epoch 3588, Loss: 0.0018949303724866695, Final Batch Loss: 4.7093349166971166e-06\n",
      "Epoch 3589, Loss: 0.0005953635119340106, Final Batch Loss: 8.277811139123514e-05\n",
      "Epoch 3590, Loss: 0.0015967448353677582, Final Batch Loss: 1.5237822481140029e-05\n",
      "Epoch 3591, Loss: 0.001382528421089546, Final Batch Loss: 3.191641155808611e-07\n",
      "Epoch 3592, Loss: 0.0047860319397727835, Final Batch Loss: 3.1605955882696435e-05\n",
      "Epoch 3593, Loss: 0.004777631071135602, Final Batch Loss: 5.176870558898372e-07\n",
      "Epoch 3594, Loss: 0.0034222973507951338, Final Batch Loss: 0.00015352136688306928\n",
      "Epoch 3595, Loss: 0.0005200179008397754, Final Batch Loss: 0.00018951980746351182\n",
      "Epoch 3596, Loss: 0.006806740243462173, Final Batch Loss: 2.372509015913238e-06\n",
      "Epoch 3597, Loss: 0.0068246286087969565, Final Batch Loss: 0.0001860986085375771\n",
      "Epoch 3598, Loss: 0.00040492761365840124, Final Batch Loss: 6.035252590663731e-05\n",
      "Epoch 3599, Loss: 0.0019650454410111706, Final Batch Loss: 4.076765890204115e-06\n",
      "Epoch 3600, Loss: 0.00040069174610835034, Final Batch Loss: 9.30837541091023e-06\n",
      "Epoch 3601, Loss: 0.01760079582572871, Final Batch Loss: 0.0008495224756188691\n",
      "Epoch 3602, Loss: 0.007845128878386731, Final Batch Loss: 6.2280319070850965e-06\n",
      "Epoch 3603, Loss: 0.006792394954917569, Final Batch Loss: 0.00022320629796013236\n",
      "Epoch 3604, Loss: 0.00048658319747119094, Final Batch Loss: 0.00015648228873033077\n",
      "Epoch 3605, Loss: 0.0025800962333164534, Final Batch Loss: 1.5438760101460502e-06\n",
      "Epoch 3606, Loss: 0.00024241497566634962, Final Batch Loss: 8.941087799030356e-06\n",
      "Epoch 3607, Loss: 0.011422269696879539, Final Batch Loss: 2.2350525341607863e-06\n",
      "Epoch 3608, Loss: 0.005333118212249133, Final Batch Loss: 9.938148650689982e-06\n",
      "Epoch 3609, Loss: 0.0007485381038918604, Final Batch Loss: 2.1632200514432043e-05\n",
      "Epoch 3610, Loss: 0.0004345175098023901, Final Batch Loss: 2.926079832832329e-05\n",
      "Epoch 3611, Loss: 0.0019876971530550236, Final Batch Loss: 1.8157797967432998e-06\n",
      "Epoch 3612, Loss: 0.0031365429491927443, Final Batch Loss: 2.0211393803037936e-06\n",
      "Epoch 3613, Loss: 0.00018856967531633018, Final Batch Loss: 3.110052375632222e-06\n",
      "Epoch 3614, Loss: 0.0005294982852888097, Final Batch Loss: 6.355281584546901e-06\n",
      "Epoch 3615, Loss: 0.0022855530030412297, Final Batch Loss: 2.9365096452238504e-06\n",
      "Epoch 3616, Loss: 0.000669232535244646, Final Batch Loss: 1.3399710041994695e-05\n",
      "Epoch 3617, Loss: 0.0013900498226178115, Final Batch Loss: 4.2827818447221944e-07\n",
      "Epoch 3618, Loss: 0.000391769372527051, Final Batch Loss: 3.952551560360007e-05\n",
      "Epoch 3619, Loss: 0.001465708076239025, Final Batch Loss: 6.204812507348834e-06\n",
      "Epoch 3620, Loss: 0.0003744259647646686, Final Batch Loss: 3.2292136893374845e-05\n",
      "Epoch 3621, Loss: 0.0006334476482834361, Final Batch Loss: 2.157585640816251e-06\n",
      "Epoch 3622, Loss: 0.00012093612247099372, Final Batch Loss: 9.223908250532986e-07\n",
      "Epoch 3623, Loss: 0.00014119524986710985, Final Batch Loss: 1.6246939082975587e-07\n",
      "Epoch 3624, Loss: 0.007807375493385393, Final Batch Loss: 0.006522202864289284\n",
      "Epoch 3625, Loss: 0.018438699139274206, Final Batch Loss: 0.017282698303461075\n",
      "Epoch 3626, Loss: 0.03494586163560598, Final Batch Loss: 1.1822037777164951e-05\n",
      "Epoch 3627, Loss: 0.04690718389565518, Final Batch Loss: 3.19258397212252e-05\n",
      "Epoch 3628, Loss: 0.008491810182476911, Final Batch Loss: 5.315910129866097e-06\n",
      "Epoch 3629, Loss: 0.0010659822982574951, Final Batch Loss: 4.136575171287404e-06\n",
      "Epoch 3630, Loss: 0.009223805197621004, Final Batch Loss: 8.349767085746862e-06\n",
      "Epoch 3631, Loss: 0.003263552630301092, Final Batch Loss: 3.94886455978849e-06\n",
      "Epoch 3632, Loss: 0.0008571774220769157, Final Batch Loss: 1.3520440234060516e-06\n",
      "Epoch 3633, Loss: 0.002770978100784305, Final Batch Loss: 2.2268036445893813e-06\n",
      "Epoch 3634, Loss: 0.0005674388143006581, Final Batch Loss: 8.16055471659638e-05\n",
      "Epoch 3635, Loss: 0.0006161671934705737, Final Batch Loss: 3.253145905546262e-06\n",
      "Epoch 3636, Loss: 0.0015792471667168684, Final Batch Loss: 1.6845415302668698e-05\n",
      "Epoch 3637, Loss: 0.0009277523849320346, Final Batch Loss: 3.934353571821703e-06\n",
      "Epoch 3638, Loss: 0.00023757286624004337, Final Batch Loss: 2.9989087124704383e-06\n",
      "Epoch 3639, Loss: 0.0017655681338055729, Final Batch Loss: 2.0143493202340323e-06\n",
      "Epoch 3640, Loss: 0.0006736823758046739, Final Batch Loss: 2.1440833734232e-05\n",
      "Epoch 3641, Loss: 0.012843546022338614, Final Batch Loss: 2.678479404494283e-06\n",
      "Epoch 3642, Loss: 0.0018088136034748459, Final Batch Loss: 0.00011128496407764032\n",
      "Epoch 3643, Loss: 0.003397997334438685, Final Batch Loss: 9.289775334764272e-06\n",
      "Epoch 3644, Loss: 0.00470438121280381, Final Batch Loss: 1.3314698321664764e-07\n",
      "Epoch 3645, Loss: 0.0015782771305765664, Final Batch Loss: 1.9227165637403232e-07\n",
      "Epoch 3646, Loss: 0.00012096172645925662, Final Batch Loss: 3.764266693906393e-06\n",
      "Epoch 3647, Loss: 0.004505622621536531, Final Batch Loss: 5.213876647758298e-06\n",
      "Epoch 3648, Loss: 0.0023340049222611015, Final Batch Loss: 2.965973635582486e-06\n",
      "Epoch 3649, Loss: 0.0016809687726322409, Final Batch Loss: 4.240598718752153e-05\n",
      "Epoch 3650, Loss: 0.0007125428038534665, Final Batch Loss: 2.363949352002237e-05\n",
      "Epoch 3651, Loss: 0.0013974715495805867, Final Batch Loss: 0.00011703268683049828\n",
      "Epoch 3652, Loss: 0.001832111320709373, Final Batch Loss: 7.822005500202067e-06\n",
      "Epoch 3653, Loss: 0.013835136511232804, Final Batch Loss: 2.2495690643609123e-07\n",
      "Epoch 3654, Loss: 0.006632766804614221, Final Batch Loss: 0.003792430041357875\n",
      "Epoch 3655, Loss: 0.0018403992677065162, Final Batch Loss: 9.896009942167439e-06\n",
      "Epoch 3656, Loss: 0.012520445070038022, Final Batch Loss: 2.14923893508967e-05\n",
      "Epoch 3657, Loss: 0.000562268986797676, Final Batch Loss: 5.833895102114184e-06\n",
      "Epoch 3658, Loss: 0.0011632881580680987, Final Batch Loss: 0.00031065542134456336\n",
      "Epoch 3659, Loss: 0.00026377303186464474, Final Batch Loss: 2.125675200659316e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3660, Loss: 0.0010704485283667964, Final Batch Loss: 1.0835688954102807e-05\n",
      "Epoch 3661, Loss: 0.0017295612066519084, Final Batch Loss: 1.4143258340482134e-05\n",
      "Epoch 3662, Loss: 0.007294430036495214, Final Batch Loss: 6.235748151084408e-05\n",
      "Epoch 3663, Loss: 0.011963548953985992, Final Batch Loss: 2.5155741241178475e-06\n",
      "Epoch 3664, Loss: 0.00015283936960486244, Final Batch Loss: 1.718805037853599e-06\n",
      "Epoch 3665, Loss: 0.00275919203081898, Final Batch Loss: 8.291526114589942e-07\n",
      "Epoch 3666, Loss: 0.003440208521482191, Final Batch Loss: 6.919004954397678e-05\n",
      "Epoch 3667, Loss: 3.3595755411397477e-05, Final Batch Loss: 1.002142653305782e-05\n",
      "Epoch 3668, Loss: 0.0011875754347556722, Final Batch Loss: 1.2135815268266015e-06\n",
      "Epoch 3669, Loss: 0.0003025579130451206, Final Batch Loss: 0.00020427808340173215\n",
      "Epoch 3670, Loss: 0.009391131089273586, Final Batch Loss: 4.089614958502352e-05\n",
      "Epoch 3671, Loss: 0.00016285415958350313, Final Batch Loss: 2.934453368652612e-05\n",
      "Epoch 3672, Loss: 0.0039736576186726325, Final Batch Loss: 1.3075673450657632e-05\n",
      "Epoch 3673, Loss: 0.001666842832840132, Final Batch Loss: 0.0004928234266117215\n",
      "Epoch 3674, Loss: 0.0016306708007221005, Final Batch Loss: 1.7362943253829144e-05\n",
      "Epoch 3675, Loss: 0.0003248632114036809, Final Batch Loss: 7.253210583257896e-07\n",
      "Epoch 3676, Loss: 0.0020421794729656995, Final Batch Loss: 0.00023766358208376914\n",
      "Epoch 3677, Loss: 0.004521041813035254, Final Batch Loss: 2.100559584050643e-07\n",
      "Epoch 3678, Loss: 0.0005404391198169378, Final Batch Loss: 0.00011046972940675914\n",
      "Epoch 3679, Loss: 0.013977199821511022, Final Batch Loss: 0.0010287831537425518\n",
      "Epoch 3680, Loss: 0.020195765374893426, Final Batch Loss: 2.5611225282773376e-06\n",
      "Epoch 3681, Loss: 0.008456050819475536, Final Batch Loss: 9.110030077863485e-06\n",
      "Epoch 3682, Loss: 0.02672110701564634, Final Batch Loss: 1.9154176698066294e-05\n",
      "Epoch 3683, Loss: 0.06223716567455995, Final Batch Loss: 5.009967935620807e-05\n",
      "Epoch 3684, Loss: 0.030582405968743842, Final Batch Loss: 0.0069549595937132835\n",
      "Epoch 3685, Loss: 0.012798685198191606, Final Batch Loss: 0.0002077951648971066\n",
      "Epoch 3686, Loss: 0.005811877511860075, Final Batch Loss: 0.00016933925508055836\n",
      "Epoch 3687, Loss: 0.0020244306919039445, Final Batch Loss: 2.0940227841492742e-05\n",
      "Epoch 3688, Loss: 0.0021731005130334324, Final Batch Loss: 1.526929008832667e-05\n",
      "Epoch 3689, Loss: 0.003939574236710541, Final Batch Loss: 2.8336186005617492e-05\n",
      "Epoch 3690, Loss: 0.0031924518492587595, Final Batch Loss: 9.379838047607336e-06\n",
      "Epoch 3691, Loss: 0.0023952556383619594, Final Batch Loss: 0.000979750999249518\n",
      "Epoch 3692, Loss: 0.001390731065384898, Final Batch Loss: 5.016247087041847e-06\n",
      "Epoch 3693, Loss: 0.04378801009625022, Final Batch Loss: 0.0003623134980443865\n",
      "Epoch 3694, Loss: 0.013194755233826072, Final Batch Loss: 3.4406646136631025e-06\n",
      "Epoch 3695, Loss: 0.01866402467135231, Final Batch Loss: 0.00016954494640231133\n",
      "Epoch 3696, Loss: 0.003135830598012035, Final Batch Loss: 5.003062597097596e-06\n",
      "Epoch 3697, Loss: 0.0023644383087457754, Final Batch Loss: 8.833857464196626e-06\n",
      "Epoch 3698, Loss: 0.007672585583534897, Final Batch Loss: 0.00020882286480627954\n",
      "Epoch 3699, Loss: 0.0020897460076412244, Final Batch Loss: 8.763842924963683e-05\n",
      "Epoch 3700, Loss: 0.001060104649184268, Final Batch Loss: 5.958194378763437e-06\n",
      "Epoch 3701, Loss: 0.0006353889002497226, Final Batch Loss: 7.723788257862907e-06\n",
      "Epoch 3702, Loss: 0.022439340552324438, Final Batch Loss: 1.7372145521221682e-05\n",
      "Epoch 3703, Loss: 0.022173667980268874, Final Batch Loss: 2.2376951164915226e-05\n",
      "Epoch 3704, Loss: 0.019187334407320122, Final Batch Loss: 0.004410681780427694\n",
      "Epoch 3705, Loss: 0.001670007184145561, Final Batch Loss: 1.929905920405872e-05\n",
      "Epoch 3706, Loss: 0.009093492833471828, Final Batch Loss: 3.263060534663964e-06\n",
      "Epoch 3707, Loss: 0.011467593281849986, Final Batch Loss: 6.121679325588048e-05\n",
      "Epoch 3708, Loss: 0.02112690955823382, Final Batch Loss: 1.12426664600207e-06\n",
      "Epoch 3709, Loss: 0.005220021218065085, Final Batch Loss: 0.0029472936876118183\n",
      "Epoch 3710, Loss: 0.006779531532629335, Final Batch Loss: 1.0970469702442642e-05\n",
      "Epoch 3711, Loss: 0.0013430765154680557, Final Batch Loss: 6.374803342623636e-05\n",
      "Epoch 3712, Loss: 0.006705727794496852, Final Batch Loss: 9.67482992564328e-05\n",
      "Epoch 3713, Loss: 0.0009905631345645816, Final Batch Loss: 1.5105378224689048e-05\n",
      "Epoch 3714, Loss: 0.001984228313730796, Final Batch Loss: 9.156281157629564e-05\n",
      "Epoch 3715, Loss: 0.01603983169974299, Final Batch Loss: 7.267703949764837e-07\n",
      "Epoch 3716, Loss: 0.04808002478830531, Final Batch Loss: 0.012815381400287151\n",
      "Epoch 3717, Loss: 0.004343216523011506, Final Batch Loss: 0.0001872463762992993\n",
      "Epoch 3718, Loss: 0.005059133649410796, Final Batch Loss: 6.62696547806263e-05\n",
      "Epoch 3719, Loss: 0.006383322637248057, Final Batch Loss: 9.758726082509384e-05\n",
      "Epoch 3720, Loss: 0.01922836610356171, Final Batch Loss: 2.8375989131745882e-05\n",
      "Epoch 3721, Loss: 0.0023765738606016384, Final Batch Loss: 0.00023640751896891743\n",
      "Epoch 3722, Loss: 0.02078305398390512, Final Batch Loss: 0.0006795705994591117\n",
      "Epoch 3723, Loss: 0.03384979076690797, Final Batch Loss: 2.9111393814673647e-05\n",
      "Epoch 3724, Loss: 0.0034151887946904935, Final Batch Loss: 8.147276844283624e-07\n",
      "Epoch 3725, Loss: 0.008055763103357094, Final Batch Loss: 0.0048926700837910175\n",
      "Epoch 3726, Loss: 0.0041285840586624545, Final Batch Loss: 2.6002886443166062e-05\n",
      "Epoch 3727, Loss: 0.003644376001091132, Final Batch Loss: 0.00015969913511071354\n",
      "Epoch 3728, Loss: 0.0009246775648534822, Final Batch Loss: 2.9702476240345277e-05\n",
      "Epoch 3729, Loss: 0.0008184359653569118, Final Batch Loss: 0.0002752972359303385\n",
      "Epoch 3730, Loss: 0.0009789675865476966, Final Batch Loss: 1.6562918290219386e-06\n",
      "Epoch 3731, Loss: 0.002437646306134411, Final Batch Loss: 7.28261802578345e-05\n",
      "Epoch 3732, Loss: 0.0013374765451317217, Final Batch Loss: 0.00014517255476675928\n",
      "Epoch 3733, Loss: 0.00033174805463431767, Final Batch Loss: 0.00012872768274974078\n",
      "Epoch 3734, Loss: 0.0007409195296759208, Final Batch Loss: 3.798126635956578e-05\n",
      "Epoch 3735, Loss: 0.047140429295097874, Final Batch Loss: 7.962920790305361e-05\n",
      "Epoch 3736, Loss: 0.007250977506316758, Final Batch Loss: 0.00010687726171454415\n",
      "Epoch 3737, Loss: 0.0037323854013493474, Final Batch Loss: 2.5164261387544684e-05\n",
      "Epoch 3738, Loss: 0.002589855309906852, Final Batch Loss: 4.4322827307041734e-05\n",
      "Epoch 3739, Loss: 0.000605858177209484, Final Batch Loss: 0.00015817751409485936\n",
      "Epoch 3740, Loss: 0.00044702631282689254, Final Batch Loss: 3.5532648325897753e-06\n",
      "Epoch 3741, Loss: 0.019078258744457344, Final Batch Loss: 8.309172699227929e-06\n",
      "Epoch 3742, Loss: 0.00505546257946321, Final Batch Loss: 5.97146163272555e-06\n",
      "Epoch 3743, Loss: 0.006364128399070523, Final Batch Loss: 4.629343038686784e-06\n",
      "Epoch 3744, Loss: 0.01924500649548122, Final Batch Loss: 0.0003193986776750535\n",
      "Epoch 3745, Loss: 0.04467142888131548, Final Batch Loss: 6.492404645541683e-05\n",
      "Epoch 3746, Loss: 0.002351775354441088, Final Batch Loss: 0.00026806857204064727\n",
      "Epoch 3747, Loss: 0.006640991871677215, Final Batch Loss: 6.906154158059508e-05\n",
      "Epoch 3748, Loss: 0.0011338935821640916, Final Batch Loss: 0.00015422783326357603\n",
      "Epoch 3749, Loss: 0.0006644712973411515, Final Batch Loss: 3.564974031178281e-05\n",
      "Epoch 3750, Loss: 0.015159007650481726, Final Batch Loss: 1.187793259305181e-05\n",
      "Epoch 3751, Loss: 0.002796728715111385, Final Batch Loss: 0.0002248758974019438\n",
      "Epoch 3752, Loss: 0.027195796484193124, Final Batch Loss: 0.00017686285718809813\n",
      "Epoch 3753, Loss: 0.007605588158185128, Final Batch Loss: 7.737647683825344e-05\n",
      "Epoch 3754, Loss: 0.002342367482356167, Final Batch Loss: 1.0489377928024624e-05\n",
      "Epoch 3755, Loss: 0.006606234286437029, Final Batch Loss: 0.000958532327786088\n",
      "Epoch 3756, Loss: 0.003557545052444766, Final Batch Loss: 2.6084950150107034e-05\n",
      "Epoch 3757, Loss: 0.0009254051574316691, Final Batch Loss: 8.947562491812278e-06\n",
      "Epoch 3758, Loss: 0.00991447514934407, Final Batch Loss: 2.398196556896437e-05\n",
      "Epoch 3759, Loss: 0.004669103569995059, Final Batch Loss: 0.0016202065162360668\n",
      "Epoch 3760, Loss: 0.0008095250358053363, Final Batch Loss: 1.0683093933039345e-05\n",
      "Epoch 3761, Loss: 0.0008984860050986754, Final Batch Loss: 8.615959814051166e-05\n",
      "Epoch 3762, Loss: 0.0005463929854272465, Final Batch Loss: 3.358574758749455e-05\n",
      "Epoch 3763, Loss: 0.004871697445594236, Final Batch Loss: 1.9268742107669823e-05\n",
      "Epoch 3764, Loss: 0.004296109671258819, Final Batch Loss: 0.0021399855613708496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3765, Loss: 0.06600014946343435, Final Batch Loss: 0.003538375021889806\n",
      "Epoch 3766, Loss: 0.003157563091178872, Final Batch Loss: 5.166243499843404e-05\n",
      "Epoch 3767, Loss: 0.002411229018434824, Final Batch Loss: 1.379523837385932e-05\n",
      "Epoch 3768, Loss: 0.0037703489051637007, Final Batch Loss: 3.0004304790054448e-05\n",
      "Epoch 3769, Loss: 0.014093978561959375, Final Batch Loss: 0.00012305034033488482\n",
      "Epoch 3770, Loss: 0.001855053312056043, Final Batch Loss: 9.734824743645731e-06\n",
      "Epoch 3771, Loss: 0.0004114892224151845, Final Batch Loss: 1.293438981520012e-05\n",
      "Epoch 3772, Loss: 0.00047344842823804356, Final Batch Loss: 7.263844963745214e-06\n",
      "Epoch 3773, Loss: 0.000771775868088298, Final Batch Loss: 9.226824658981059e-06\n",
      "Epoch 3774, Loss: 0.0006288882701142029, Final Batch Loss: 2.4899196660044254e-07\n",
      "Epoch 3775, Loss: 0.0017994749550211964, Final Batch Loss: 7.99083227320807e-06\n",
      "Epoch 3776, Loss: 0.0019819455200149605, Final Batch Loss: 9.717627835925668e-05\n",
      "Epoch 3777, Loss: 0.01765853791050631, Final Batch Loss: 0.00014497432857751846\n",
      "Epoch 3778, Loss: 0.0014439646920436644, Final Batch Loss: 3.055536944884807e-05\n",
      "Epoch 3779, Loss: 0.006967504410567926, Final Batch Loss: 0.0016654747305437922\n",
      "Epoch 3780, Loss: 0.002103884158486835, Final Batch Loss: 6.242270319489762e-05\n",
      "Epoch 3781, Loss: 0.0008384365850702125, Final Batch Loss: 0.0003197234182152897\n",
      "Epoch 3782, Loss: 0.022179631146855172, Final Batch Loss: 2.145043617929332e-05\n",
      "Epoch 3783, Loss: 0.01608818037243509, Final Batch Loss: 0.0030731474980711937\n",
      "Epoch 3784, Loss: 0.005980175785225583, Final Batch Loss: 6.261393991735531e-06\n",
      "Epoch 3785, Loss: 0.0011540030458263573, Final Batch Loss: 1.6363028407795355e-05\n",
      "Epoch 3786, Loss: 0.0013318717383299372, Final Batch Loss: 3.792583811446093e-05\n",
      "Epoch 3787, Loss: 0.004156386436534376, Final Batch Loss: 3.9422960981028154e-05\n",
      "Epoch 3788, Loss: 0.0015196276268056863, Final Batch Loss: 1.2834090057367575e-07\n",
      "Epoch 3789, Loss: 0.012289921302453877, Final Batch Loss: 0.0005249802488833666\n",
      "Epoch 3790, Loss: 0.002129159715877904, Final Batch Loss: 6.561816917383112e-06\n",
      "Epoch 3791, Loss: 0.007889588574073514, Final Batch Loss: 0.004913370590656996\n",
      "Epoch 3792, Loss: 0.004350254258042696, Final Batch Loss: 0.0007352756219916046\n",
      "Epoch 3793, Loss: 0.0019565977272577584, Final Batch Loss: 0.00016931405116338283\n",
      "Epoch 3794, Loss: 0.004227425688100084, Final Batch Loss: 0.002830401062965393\n",
      "Epoch 3795, Loss: 0.01349922532472192, Final Batch Loss: 0.00017334596486762166\n",
      "Epoch 3796, Loss: 0.006119870502516278, Final Batch Loss: 0.0005329551640897989\n",
      "Epoch 3797, Loss: 0.0020844780801212437, Final Batch Loss: 5.7170091167790815e-05\n",
      "Epoch 3798, Loss: 0.018081878269185836, Final Batch Loss: 1.8163814274885226e-06\n",
      "Epoch 3799, Loss: 0.0035219482134039026, Final Batch Loss: 0.0003330783802084625\n",
      "Epoch 3800, Loss: 0.0065712501259440614, Final Batch Loss: 0.0001679591223364696\n",
      "Epoch 3801, Loss: 0.0033374334473137424, Final Batch Loss: 1.3763508832198568e-05\n",
      "Epoch 3802, Loss: 0.0004893229590265946, Final Batch Loss: 0.00013408121594693512\n",
      "Epoch 3803, Loss: 0.0014898719460916254, Final Batch Loss: 3.2853690754564013e-06\n",
      "Epoch 3804, Loss: 0.0044241203825521325, Final Batch Loss: 1.9209624952054583e-05\n",
      "Epoch 3805, Loss: 0.12717686869928002, Final Batch Loss: 1.5232331861625426e-05\n",
      "Epoch 3806, Loss: 0.052563641458164057, Final Batch Loss: 4.103144965483807e-05\n",
      "Epoch 3807, Loss: 0.04865835678810981, Final Batch Loss: 5.815388067276217e-05\n",
      "Epoch 3808, Loss: 0.051989036804343414, Final Batch Loss: 0.0009728785371407866\n",
      "Epoch 3809, Loss: 0.01760736386950157, Final Batch Loss: 0.002792949555441737\n",
      "Epoch 3810, Loss: 0.006078890261051129, Final Batch Loss: 0.00022376251581590623\n",
      "Epoch 3811, Loss: 0.03550877417274023, Final Batch Loss: 1.965043156815227e-05\n",
      "Epoch 3812, Loss: 0.03231166258979101, Final Batch Loss: 0.001259575947187841\n",
      "Epoch 3813, Loss: 0.005148783819095115, Final Batch Loss: 0.0007454633596353233\n",
      "Epoch 3814, Loss: 0.0038814483251599086, Final Batch Loss: 7.546515234935214e-07\n",
      "Epoch 3815, Loss: 0.0029679722883884097, Final Batch Loss: 2.6081010219058953e-05\n",
      "Epoch 3816, Loss: 0.03652832647549076, Final Batch Loss: 0.025469480082392693\n",
      "Epoch 3817, Loss: 0.006995340813546136, Final Batch Loss: 0.003692776896059513\n",
      "Epoch 3818, Loss: 0.003944031136143167, Final Batch Loss: 9.886586485663429e-05\n",
      "Epoch 3819, Loss: 0.02076076438788732, Final Batch Loss: 9.67637388384901e-05\n",
      "Epoch 3820, Loss: 0.05068153373122186, Final Batch Loss: 0.0432988740503788\n",
      "Epoch 3821, Loss: 0.009894013954180991, Final Batch Loss: 8.264862117357552e-05\n",
      "Epoch 3822, Loss: 0.007063582367663912, Final Batch Loss: 2.927275090769399e-05\n",
      "Epoch 3823, Loss: 0.004829697715308612, Final Batch Loss: 1.520773935226316e-06\n",
      "Epoch 3824, Loss: 0.008099822250756006, Final Batch Loss: 4.601326963893371e-06\n",
      "Epoch 3825, Loss: 0.0035527649702089548, Final Batch Loss: 6.814163498347625e-05\n",
      "Epoch 3826, Loss: 0.002886019715418797, Final Batch Loss: 0.0018567772349342704\n",
      "Epoch 3827, Loss: 0.0014654116801011696, Final Batch Loss: 3.5708342238649493e-06\n",
      "Epoch 3828, Loss: 0.001167426210130884, Final Batch Loss: 0.00027495191898196936\n",
      "Epoch 3829, Loss: 0.006818291289704348, Final Batch Loss: 3.4357958611508366e-06\n",
      "Epoch 3830, Loss: 0.035964233950608104, Final Batch Loss: 0.0260971300303936\n",
      "Epoch 3831, Loss: 0.007958266648984136, Final Batch Loss: 3.832566562778084e-06\n",
      "Epoch 3832, Loss: 0.01309737984252024, Final Batch Loss: 0.0002343891392229125\n",
      "Epoch 3833, Loss: 0.00901699090263719, Final Batch Loss: 5.3371404646895826e-05\n",
      "Epoch 3834, Loss: 0.028787794699383085, Final Batch Loss: 0.00016308709746226668\n",
      "Epoch 3835, Loss: 0.006918516517998796, Final Batch Loss: 0.0014046774012967944\n",
      "Epoch 3836, Loss: 0.008078349208517466, Final Batch Loss: 7.491767610190436e-05\n",
      "Epoch 3837, Loss: 0.025093970968555368, Final Batch Loss: 0.014765695668756962\n",
      "Epoch 3838, Loss: 0.0056459993775206385, Final Batch Loss: 8.519821858499199e-05\n",
      "Epoch 3839, Loss: 0.004036956363052013, Final Batch Loss: 1.4375144019140862e-05\n",
      "Epoch 3840, Loss: 0.007790965475351186, Final Batch Loss: 4.851563789998181e-05\n",
      "Epoch 3841, Loss: 0.0007185503084485845, Final Batch Loss: 0.00014723469212185591\n",
      "Epoch 3842, Loss: 0.0017697089278954081, Final Batch Loss: 3.842918886221014e-06\n",
      "Epoch 3843, Loss: 0.0019693050935529754, Final Batch Loss: 1.4644702787336428e-05\n",
      "Epoch 3844, Loss: 0.001774536653101677, Final Batch Loss: 4.407761025504442e-06\n",
      "Epoch 3845, Loss: 0.0025994335146606318, Final Batch Loss: 7.853440183680505e-05\n",
      "Epoch 3846, Loss: 0.0016848423060764617, Final Batch Loss: 4.836978405364789e-06\n",
      "Epoch 3847, Loss: 0.016411718866947922, Final Batch Loss: 0.000996480113826692\n",
      "Epoch 3848, Loss: 0.0014683887424666864, Final Batch Loss: 0.0008606844348832965\n",
      "Epoch 3849, Loss: 0.0007288324743512931, Final Batch Loss: 6.883864443807397e-06\n",
      "Epoch 3850, Loss: 0.01527189151966013, Final Batch Loss: 0.0001957217900780961\n",
      "Epoch 3851, Loss: 0.0016081888970802538, Final Batch Loss: 2.2504109438159503e-05\n",
      "Epoch 3852, Loss: 0.0022316342469821393, Final Batch Loss: 0.00033053665538318455\n",
      "Epoch 3853, Loss: 0.013745303753154303, Final Batch Loss: 0.003380340291187167\n",
      "Epoch 3854, Loss: 0.03773192168273454, Final Batch Loss: 1.8982111214427277e-05\n",
      "Epoch 3855, Loss: 0.018339201937124017, Final Batch Loss: 0.0031957097817212343\n",
      "Epoch 3856, Loss: 0.002277473988215206, Final Batch Loss: 0.0001593648485140875\n",
      "Epoch 3857, Loss: 0.012406025664517983, Final Batch Loss: 9.24297455640044e-06\n",
      "Epoch 3858, Loss: 0.002041807727664491, Final Batch Loss: 0.0009179808548651636\n",
      "Epoch 3859, Loss: 0.016785353576096895, Final Batch Loss: 0.0011662531178444624\n",
      "Epoch 3860, Loss: 0.005072362845567113, Final Batch Loss: 0.0007677896064706147\n",
      "Epoch 3861, Loss: 0.004060083992783348, Final Batch Loss: 9.030433830048423e-06\n",
      "Epoch 3862, Loss: 0.0026918265253357276, Final Batch Loss: 1.4199188626662362e-05\n",
      "Epoch 3863, Loss: 0.01358500322794498, Final Batch Loss: 0.0010654788929969072\n",
      "Epoch 3864, Loss: 0.005267289816401899, Final Batch Loss: 0.003092545550316572\n",
      "Epoch 3865, Loss: 0.004482008409922855, Final Batch Loss: 2.026142283284571e-05\n",
      "Epoch 3866, Loss: 0.005508820360887512, Final Batch Loss: 3.019439873241936e-06\n",
      "Epoch 3867, Loss: 0.0019533638965185673, Final Batch Loss: 1.2695856639766134e-05\n",
      "Epoch 3868, Loss: 0.0017335955407133952, Final Batch Loss: 2.7183350539417006e-05\n",
      "Epoch 3869, Loss: 0.0005193863291879097, Final Batch Loss: 8.098561011138372e-06\n",
      "Epoch 3870, Loss: 0.0031722742760393885, Final Batch Loss: 0.0001666275056777522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3871, Loss: 0.0026018015278168605, Final Batch Loss: 1.1861871826113202e-05\n",
      "Epoch 3872, Loss: 0.0016103382115488785, Final Batch Loss: 0.001052180421538651\n",
      "Epoch 3873, Loss: 0.0008528900843884912, Final Batch Loss: 4.3239915612502955e-06\n",
      "Epoch 3874, Loss: 0.0015514401870859729, Final Batch Loss: 2.608879640320083e-06\n",
      "Epoch 3875, Loss: 0.040175147850732174, Final Batch Loss: 5.7154229580191895e-06\n",
      "Epoch 3876, Loss: 0.005573788823312498, Final Batch Loss: 3.087471122853458e-05\n",
      "Epoch 3877, Loss: 0.0023462416650090745, Final Batch Loss: 0.0007597468211315572\n",
      "Epoch 3878, Loss: 0.00452001972553262, Final Batch Loss: 2.7289948775433004e-05\n",
      "Epoch 3879, Loss: 0.0019985810928346837, Final Batch Loss: 8.872459147823974e-05\n",
      "Epoch 3880, Loss: 0.0008117249973480511, Final Batch Loss: 1.958664142875932e-06\n",
      "Epoch 3881, Loss: 0.004684782125679021, Final Batch Loss: 4.205981531413272e-05\n",
      "Epoch 3882, Loss: 0.00761243743492912, Final Batch Loss: 5.536618482437916e-05\n",
      "Epoch 3883, Loss: 0.01941141427232651, Final Batch Loss: 1.368386347166961e-05\n",
      "Epoch 3884, Loss: 0.0028814418715228385, Final Batch Loss: 0.00036483528674580157\n",
      "Epoch 3885, Loss: 0.003673336452948206, Final Batch Loss: 8.141308171616402e-06\n",
      "Epoch 3886, Loss: 0.002177205191401299, Final Batch Loss: 0.0003903888864442706\n",
      "Epoch 3887, Loss: 0.003588260001947674, Final Batch Loss: 0.0029667909257113934\n",
      "Epoch 3888, Loss: 0.009391193352144, Final Batch Loss: 0.0006929099909029901\n",
      "Epoch 3889, Loss: 0.0008724499625714088, Final Batch Loss: 2.871519200198236e-06\n",
      "Epoch 3890, Loss: 0.003408830818784736, Final Batch Loss: 2.0721670807688497e-05\n",
      "Epoch 3891, Loss: 0.05288401983591484, Final Batch Loss: 1.4568825008609565e-06\n",
      "Epoch 3892, Loss: 0.030984055487806472, Final Batch Loss: 0.00016871289699338377\n",
      "Epoch 3893, Loss: 0.0031261373907227608, Final Batch Loss: 0.0002693698916118592\n",
      "Epoch 3894, Loss: 0.007708328832450206, Final Batch Loss: 3.8646265920760925e-07\n",
      "Epoch 3895, Loss: 0.003237587079183868, Final Batch Loss: 3.1739698442834197e-06\n",
      "Epoch 3896, Loss: 0.002671555785127566, Final Batch Loss: 4.347495632828213e-05\n",
      "Epoch 3897, Loss: 0.00552561868067869, Final Batch Loss: 3.095199281233363e-05\n",
      "Epoch 3898, Loss: 0.024454220913057156, Final Batch Loss: 1.4721102161274757e-05\n",
      "Epoch 3899, Loss: 0.0028579547963829555, Final Batch Loss: 1.5129044186323881e-05\n",
      "Epoch 3900, Loss: 0.007894939816651458, Final Batch Loss: 1.6406351278419606e-05\n",
      "Epoch 3901, Loss: 0.0029757256291986778, Final Batch Loss: 1.2747191249218304e-06\n",
      "Epoch 3902, Loss: 0.0036250271086828434, Final Batch Loss: 0.0001978008367586881\n",
      "Epoch 3903, Loss: 0.006087777375569203, Final Batch Loss: 2.6723100745584816e-05\n",
      "Epoch 3904, Loss: 0.00045420637485449333, Final Batch Loss: 3.24427273881156e-05\n",
      "Epoch 3905, Loss: 0.0026423679505569453, Final Batch Loss: 1.3162097275198903e-05\n",
      "Epoch 3906, Loss: 0.000549866651979869, Final Batch Loss: 1.1760446795960888e-05\n",
      "Epoch 3907, Loss: 0.0647440917874178, Final Batch Loss: 0.00012670278374571353\n",
      "Epoch 3908, Loss: 0.02591427935635693, Final Batch Loss: 6.808117177570239e-06\n",
      "Epoch 3909, Loss: 0.041317478228847904, Final Batch Loss: 0.00864145252853632\n",
      "Epoch 3910, Loss: 0.01171237395828939, Final Batch Loss: 0.0001989977463381365\n",
      "Epoch 3911, Loss: 0.01685828103472886, Final Batch Loss: 3.236893462599255e-05\n",
      "Epoch 3912, Loss: 0.00517967475389014, Final Batch Loss: 2.416687857476063e-05\n",
      "Epoch 3913, Loss: 0.008625117830888485, Final Batch Loss: 0.005503081250935793\n",
      "Epoch 3914, Loss: 0.0033261492289966554, Final Batch Loss: 0.0003524258791003376\n",
      "Epoch 3915, Loss: 0.002723426835018472, Final Batch Loss: 1.682916990830563e-05\n",
      "Epoch 3916, Loss: 0.0019414099119785533, Final Batch Loss: 3.27270281559322e-05\n",
      "Epoch 3917, Loss: 0.009584573757592807, Final Batch Loss: 6.617973212996731e-06\n",
      "Epoch 3918, Loss: 0.003166292558717032, Final Batch Loss: 1.5086312487255782e-05\n",
      "Epoch 3919, Loss: 0.001474087946007785, Final Batch Loss: 9.475022125116084e-06\n",
      "Epoch 3920, Loss: 0.001058090667356737, Final Batch Loss: 1.8322491541766794e-06\n",
      "Epoch 3921, Loss: 0.0022384785274880414, Final Batch Loss: 1.825452272896655e-05\n",
      "Epoch 3922, Loss: 0.0007631775079062209, Final Batch Loss: 1.4010010090714786e-05\n",
      "Epoch 3923, Loss: 0.0010049086514527517, Final Batch Loss: 0.00013060515630058944\n",
      "Epoch 3924, Loss: 0.0028843664694022664, Final Batch Loss: 3.6121516586717917e-06\n",
      "Epoch 3925, Loss: 0.004543276606227664, Final Batch Loss: 0.0001099338405765593\n",
      "Epoch 3926, Loss: 0.0012334568368146392, Final Batch Loss: 5.643072995553666e-07\n",
      "Epoch 3927, Loss: 0.007530950414512461, Final Batch Loss: 6.392348950612359e-06\n",
      "Epoch 3928, Loss: 0.0018422797775201616, Final Batch Loss: 6.586901872651652e-05\n",
      "Epoch 3929, Loss: 0.015394797055023446, Final Batch Loss: 1.1367418665031437e-05\n",
      "Epoch 3930, Loss: 0.0008033415462023186, Final Batch Loss: 4.672789145843126e-06\n",
      "Epoch 3931, Loss: 0.01037657720610241, Final Batch Loss: 4.292033736419398e-06\n",
      "Epoch 3932, Loss: 0.009497741289123951, Final Batch Loss: 0.008818146772682667\n",
      "Epoch 3933, Loss: 0.005592081297209006, Final Batch Loss: 0.00019273605721537024\n",
      "Epoch 3934, Loss: 0.011244829783208843, Final Batch Loss: 0.008702261373400688\n",
      "Epoch 3935, Loss: 0.0022597267909532093, Final Batch Loss: 2.4890930944820866e-05\n",
      "Epoch 3936, Loss: 0.011456314000952261, Final Batch Loss: 9.953771223081276e-05\n",
      "Epoch 3937, Loss: 0.009308235932621756, Final Batch Loss: 0.0007907564868219197\n",
      "Epoch 3938, Loss: 0.035475597772475, Final Batch Loss: 0.027360491454601288\n",
      "Epoch 3939, Loss: 0.006848267339137237, Final Batch Loss: 0.0026870027650147676\n",
      "Epoch 3940, Loss: 0.014855440471137626, Final Batch Loss: 0.001395100262016058\n",
      "Epoch 3941, Loss: 0.0449811372720319, Final Batch Loss: 3.087661525569274e-06\n",
      "Epoch 3942, Loss: 0.007770011130730836, Final Batch Loss: 1.2309716339586885e-06\n",
      "Epoch 3943, Loss: 0.011090922786934243, Final Batch Loss: 5.565676838159561e-05\n",
      "Epoch 3944, Loss: 0.009976518885196128, Final Batch Loss: 2.83072567981435e-05\n",
      "Epoch 3945, Loss: 0.0033461262501077726, Final Batch Loss: 0.00024631983251310885\n",
      "Epoch 3946, Loss: 0.0023084836939233355, Final Batch Loss: 3.3598764275666326e-05\n",
      "Epoch 3947, Loss: 0.0014856184398013283, Final Batch Loss: 5.749363117502071e-05\n",
      "Epoch 3948, Loss: 0.002104191573380376, Final Batch Loss: 1.081629943655571e-05\n",
      "Epoch 3949, Loss: 0.0010557112480000796, Final Batch Loss: 7.048632687656209e-05\n",
      "Epoch 3950, Loss: 0.010811388036415792, Final Batch Loss: 0.010268704034388065\n",
      "Epoch 3951, Loss: 0.0015669390199946065, Final Batch Loss: 4.764989353134297e-05\n",
      "Epoch 3952, Loss: 0.0015794358059793012, Final Batch Loss: 6.766121805412695e-05\n",
      "Epoch 3953, Loss: 0.0011588293263002925, Final Batch Loss: 1.1473492804725538e-06\n",
      "Epoch 3954, Loss: 0.0006209124235283525, Final Batch Loss: 2.3664104446652345e-05\n",
      "Epoch 3955, Loss: 0.0011234605835852562, Final Batch Loss: 3.787615423789248e-05\n",
      "Epoch 3956, Loss: 0.005230831939456948, Final Batch Loss: 3.949864094465738e-06\n",
      "Epoch 3957, Loss: 0.001333429028782973, Final Batch Loss: 1.1247910691736251e-07\n",
      "Epoch 3958, Loss: 0.0013837570705561575, Final Batch Loss: 4.279419044905808e-06\n",
      "Epoch 3959, Loss: 0.0014152989959939077, Final Batch Loss: 7.381173054454848e-05\n",
      "Epoch 3960, Loss: 0.0005401557290838355, Final Batch Loss: 4.20428250436089e-06\n",
      "Epoch 3961, Loss: 0.03378387000611838, Final Batch Loss: 4.50906009064056e-06\n",
      "Epoch 3962, Loss: 0.0031804551483674004, Final Batch Loss: 0.00019720000273082405\n",
      "Epoch 3963, Loss: 0.01186311046717492, Final Batch Loss: 6.334349745884538e-05\n",
      "Epoch 3964, Loss: 0.0021467442179528007, Final Batch Loss: 2.8018355806125328e-05\n",
      "Epoch 3965, Loss: 0.005029925954886494, Final Batch Loss: 3.28746646118816e-05\n",
      "Epoch 3966, Loss: 0.0016146318575920304, Final Batch Loss: 9.606047387933359e-05\n",
      "Epoch 3967, Loss: 0.0019479133293316409, Final Batch Loss: 3.9872120396466926e-06\n",
      "Epoch 3968, Loss: 0.0018384055454134796, Final Batch Loss: 6.166689672681969e-06\n",
      "Epoch 3969, Loss: 0.019057659042573505, Final Batch Loss: 5.447838248073822e-06\n",
      "Epoch 3970, Loss: 0.004926830023691764, Final Batch Loss: 1.0309996469004545e-05\n",
      "Epoch 3971, Loss: 0.0035488011470761194, Final Batch Loss: 5.037795745010953e-06\n",
      "Epoch 3972, Loss: 0.006595439466707376, Final Batch Loss: 2.524852789065335e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3973, Loss: 0.0008810024835383956, Final Batch Loss: 0.00022824066400062293\n",
      "Epoch 3974, Loss: 0.03663077247097135, Final Batch Loss: 4.873055513598956e-05\n",
      "Epoch 3975, Loss: 0.0014386797893450876, Final Batch Loss: 1.3877595847588964e-05\n",
      "Epoch 3976, Loss: 0.002246420925160919, Final Batch Loss: 3.057096762404399e-07\n",
      "Epoch 3977, Loss: 0.0016519084476271928, Final Batch Loss: 4.304887625039555e-06\n",
      "Epoch 3978, Loss: 0.0024091263298942067, Final Batch Loss: 7.222623480629409e-06\n",
      "Epoch 3979, Loss: 0.0005659758603542286, Final Batch Loss: 4.3392104998929426e-05\n",
      "Epoch 3980, Loss: 0.0003378865737175829, Final Batch Loss: 1.9400556993787177e-05\n",
      "Epoch 3981, Loss: 0.003333026828954644, Final Batch Loss: 0.0025740484707057476\n",
      "Epoch 3982, Loss: 0.001202094968732581, Final Batch Loss: 1.9416862414800562e-05\n",
      "Epoch 3983, Loss: 0.00020843019251515216, Final Batch Loss: 9.781422249943716e-07\n",
      "Epoch 3984, Loss: 0.00015087115946244012, Final Batch Loss: 4.3740698174588033e-07\n",
      "Epoch 3985, Loss: 0.00561450447978018, Final Batch Loss: 6.240013590286253e-06\n",
      "Epoch 3986, Loss: 0.0012949879453003632, Final Batch Loss: 4.382146926218411e-06\n",
      "Epoch 3987, Loss: 0.002848955998931757, Final Batch Loss: 8.08960692211258e-07\n",
      "Epoch 3988, Loss: 0.0003495366318446713, Final Batch Loss: 8.871975296642631e-05\n",
      "Epoch 3989, Loss: 0.0004074746501601112, Final Batch Loss: 1.586240188089505e-07\n",
      "Epoch 3990, Loss: 0.0006160959196961358, Final Batch Loss: 1.2700879779004026e-05\n",
      "Epoch 3991, Loss: 0.0017496503988354561, Final Batch Loss: 4.644225555239245e-06\n",
      "Epoch 3992, Loss: 0.01903181344803606, Final Batch Loss: 2.812057573464699e-05\n",
      "Epoch 3993, Loss: 0.0019370630112902631, Final Batch Loss: 2.056524635918322e-06\n",
      "Epoch 3994, Loss: 0.006454524870150635, Final Batch Loss: 3.0782975954934955e-05\n",
      "Epoch 3995, Loss: 0.003324063412492251, Final Batch Loss: 3.6050255403097253e-07\n",
      "Epoch 3996, Loss: 0.003993478641177717, Final Batch Loss: 3.809057488979306e-06\n",
      "Epoch 3997, Loss: 0.0004504385757968521, Final Batch Loss: 4.989392436982598e-07\n",
      "Epoch 3998, Loss: 0.0001363453495741851, Final Batch Loss: 5.690098078048322e-06\n",
      "Epoch 3999, Loss: 0.0002029309516160538, Final Batch Loss: 3.862606263282942e-06\n",
      "Epoch 4000, Loss: 0.0010662454508008068, Final Batch Loss: 5.810324728372507e-05\n",
      "Epoch 4001, Loss: 0.00021839439648374537, Final Batch Loss: 1.0440414371259976e-05\n",
      "Epoch 4002, Loss: 0.0019928203614654194, Final Batch Loss: 5.083264841232449e-05\n",
      "Epoch 4003, Loss: 0.0004386220577998756, Final Batch Loss: 5.737405899708392e-06\n",
      "Epoch 4004, Loss: 0.0013948852292173797, Final Batch Loss: 4.556038220471237e-06\n",
      "Epoch 4005, Loss: 0.00039883892537773136, Final Batch Loss: 2.480612056388054e-05\n",
      "Epoch 4006, Loss: 0.0009002018143746682, Final Batch Loss: 2.2212214389583096e-05\n",
      "Epoch 4007, Loss: 0.003601744288971531, Final Batch Loss: 8.811888619675301e-06\n",
      "Epoch 4008, Loss: 0.0072146410209370515, Final Batch Loss: 0.00028015277348458767\n",
      "Epoch 4009, Loss: 0.0010056487906240363, Final Batch Loss: 8.896943768377241e-07\n",
      "Epoch 4010, Loss: 0.00023247578121754486, Final Batch Loss: 2.922519115600153e-07\n",
      "Epoch 4011, Loss: 0.00035272579620482247, Final Batch Loss: 1.6016241715988144e-05\n",
      "Epoch 4012, Loss: 0.0004385740338079813, Final Batch Loss: 2.4608030798844993e-05\n",
      "Epoch 4013, Loss: 0.00022318843350888073, Final Batch Loss: 2.270435288664885e-06\n",
      "Epoch 4014, Loss: 0.0012227928435777358, Final Batch Loss: 9.995958862418775e-06\n",
      "Epoch 4015, Loss: 0.0024592381031709465, Final Batch Loss: 0.00021460259449668229\n",
      "Epoch 4016, Loss: 0.00046618789579611075, Final Batch Loss: 8.512558906659251e-07\n",
      "Epoch 4017, Loss: 0.0007642338400160043, Final Batch Loss: 2.2256586817093194e-05\n",
      "Epoch 4018, Loss: 0.0008123898677041552, Final Batch Loss: 3.959587047575042e-06\n",
      "Epoch 4019, Loss: 0.009139565909720204, Final Batch Loss: 4.6885848860256374e-05\n",
      "Epoch 4020, Loss: 0.00724570180499029, Final Batch Loss: 5.998628012093832e-07\n",
      "Epoch 4021, Loss: 0.008083508849153986, Final Batch Loss: 9.020147444971371e-06\n",
      "Epoch 4022, Loss: 0.005281532556812962, Final Batch Loss: 0.0010168271837756038\n",
      "Epoch 4023, Loss: 0.11355006961946401, Final Batch Loss: 1.8737573554972187e-05\n",
      "Epoch 4024, Loss: 0.0055630483766435646, Final Batch Loss: 0.00013980148651171476\n",
      "Epoch 4025, Loss: 0.050383763351419475, Final Batch Loss: 0.00029758442542515695\n",
      "Epoch 4026, Loss: 0.02880915934656514, Final Batch Loss: 0.00012658568448387086\n",
      "Epoch 4027, Loss: 0.036961691150281695, Final Batch Loss: 6.502187898149714e-05\n",
      "Epoch 4028, Loss: 0.0515926427069644, Final Batch Loss: 0.0017266172217205167\n",
      "Epoch 4029, Loss: 0.011768973028665641, Final Batch Loss: 4.4154803617857397e-05\n",
      "Epoch 4030, Loss: 0.0479169666141388, Final Batch Loss: 0.002373855095356703\n",
      "Epoch 4031, Loss: 0.007466555542123388, Final Batch Loss: 0.00039909573388285935\n",
      "Epoch 4032, Loss: 0.00871261976317328, Final Batch Loss: 4.3937438022112474e-05\n",
      "Epoch 4033, Loss: 0.03264204802144377, Final Batch Loss: 0.00033456951496191323\n",
      "Epoch 4034, Loss: 0.014998402046330739, Final Batch Loss: 1.6274871086352505e-05\n",
      "Epoch 4035, Loss: 0.00348966513229243, Final Batch Loss: 1.9441868062131107e-05\n",
      "Epoch 4036, Loss: 0.002209523499914212, Final Batch Loss: 0.00021133579139132053\n",
      "Epoch 4037, Loss: 0.0735349859296548, Final Batch Loss: 0.0002279796462971717\n",
      "Epoch 4038, Loss: 0.08516214904011576, Final Batch Loss: 0.00024097136338241398\n",
      "Epoch 4039, Loss: 0.07837074267081334, Final Batch Loss: 0.00012808997416868806\n",
      "Epoch 4040, Loss: 0.023587384988786653, Final Batch Loss: 0.003232391318306327\n",
      "Epoch 4041, Loss: 0.02685448684496805, Final Batch Loss: 0.0021200980991125107\n",
      "Epoch 4042, Loss: 0.08340446064175921, Final Batch Loss: 0.00027722405502572656\n",
      "Epoch 4043, Loss: 0.023303823421883862, Final Batch Loss: 0.00060497090453282\n",
      "Epoch 4044, Loss: 0.012102224407499307, Final Batch Loss: 9.974059503292665e-05\n",
      "Epoch 4045, Loss: 0.010577016389106575, Final Batch Loss: 0.0001461852079955861\n",
      "Epoch 4046, Loss: 0.011643105648545315, Final Batch Loss: 0.0001177285157609731\n",
      "Epoch 4047, Loss: 0.0025778907802305184, Final Batch Loss: 0.00036421799450181425\n",
      "Epoch 4048, Loss: 0.022994429600657895, Final Batch Loss: 7.330621156143025e-05\n",
      "Epoch 4049, Loss: 0.005987871333672956, Final Batch Loss: 4.678332516050432e-06\n",
      "Epoch 4050, Loss: 0.001705547614619718, Final Batch Loss: 4.236437234794721e-05\n",
      "Epoch 4051, Loss: 0.003357032222993439, Final Batch Loss: 0.0006326839793473482\n",
      "Epoch 4052, Loss: 0.0050145616389727365, Final Batch Loss: 3.0252006126829656e-06\n",
      "Epoch 4053, Loss: 0.002841893644472293, Final Batch Loss: 4.306049959268421e-05\n",
      "Epoch 4054, Loss: 0.012436041716227919, Final Batch Loss: 0.00019637843070086092\n",
      "Epoch 4055, Loss: 0.0032207368913077516, Final Batch Loss: 0.0015781050315126777\n",
      "Epoch 4056, Loss: 0.00954409214784846, Final Batch Loss: 0.0006646834081038833\n",
      "Epoch 4057, Loss: 0.0006818747219767829, Final Batch Loss: 1.8167860616813414e-05\n",
      "Epoch 4058, Loss: 0.04623621712858039, Final Batch Loss: 4.299971988075413e-05\n",
      "Epoch 4059, Loss: 0.002753959108304116, Final Batch Loss: 8.829592843540013e-05\n",
      "Epoch 4060, Loss: 0.001939257203048328, Final Batch Loss: 4.123138205613941e-05\n",
      "Epoch 4061, Loss: 0.01627777129488095, Final Batch Loss: 0.002424520207569003\n",
      "Epoch 4062, Loss: 0.003811088487964298, Final Batch Loss: 3.881031079799868e-05\n",
      "Epoch 4063, Loss: 0.006613714922195868, Final Batch Loss: 0.0007230526534840465\n",
      "Epoch 4064, Loss: 0.0010506349744900945, Final Batch Loss: 0.0003925293276552111\n",
      "Epoch 4065, Loss: 0.009108619594371703, Final Batch Loss: 0.006377771496772766\n",
      "Epoch 4066, Loss: 0.002357715069592814, Final Batch Loss: 3.547859159880318e-05\n",
      "Epoch 4067, Loss: 0.0014362450820044614, Final Batch Loss: 1.093639548344072e-05\n",
      "Epoch 4068, Loss: 0.0019328953535477922, Final Batch Loss: 2.952446084236726e-05\n",
      "Epoch 4069, Loss: 0.00308479940451889, Final Batch Loss: 1.1098460390712717e-06\n",
      "Epoch 4070, Loss: 0.0007590847826577374, Final Batch Loss: 1.3111072803440038e-05\n",
      "Epoch 4071, Loss: 0.0028653562862928084, Final Batch Loss: 3.250978988944553e-05\n",
      "Epoch 4072, Loss: 0.0010083132847285015, Final Batch Loss: 7.630681648151949e-05\n",
      "Epoch 4073, Loss: 0.0011105754419986624, Final Batch Loss: 4.479107883526012e-05\n",
      "Epoch 4074, Loss: 0.0037405343859973073, Final Batch Loss: 5.157440682523884e-06\n",
      "Epoch 4075, Loss: 0.0004427402050168894, Final Batch Loss: 5.778925697086379e-06\n",
      "Epoch 4076, Loss: 0.021219926055749738, Final Batch Loss: 8.976815479400102e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4077, Loss: 0.002127007939179748, Final Batch Loss: 1.0159182238567155e-05\n",
      "Epoch 4078, Loss: 0.0028526811956908205, Final Batch Loss: 7.499133062083274e-05\n",
      "Epoch 4079, Loss: 0.005174154468477354, Final Batch Loss: 1.801673170120921e-05\n",
      "Epoch 4080, Loss: 0.0016122096071740089, Final Batch Loss: 1.8754853954305872e-05\n",
      "Epoch 4081, Loss: 0.0043791689931822475, Final Batch Loss: 5.321714525052812e-06\n",
      "Epoch 4082, Loss: 0.006516349067169358, Final Batch Loss: 1.627176061447244e-05\n",
      "Epoch 4083, Loss: 0.001129664304016842, Final Batch Loss: 0.00013309059431776404\n",
      "Epoch 4084, Loss: 0.008547338831931484, Final Batch Loss: 1.3500979548553005e-05\n",
      "Epoch 4085, Loss: 0.00055258472798414, Final Batch Loss: 9.1544625320239e-06\n",
      "Epoch 4086, Loss: 0.0009116086912399624, Final Batch Loss: 2.3164127469499363e-06\n",
      "Epoch 4087, Loss: 0.0046133341146514795, Final Batch Loss: 0.003509657923132181\n",
      "Epoch 4088, Loss: 0.0004059114106667039, Final Batch Loss: 6.653209766227519e-06\n",
      "Epoch 4089, Loss: 0.00021509002488073747, Final Batch Loss: 2.3545849217043724e-06\n",
      "Epoch 4090, Loss: 0.0006107224076004059, Final Batch Loss: 4.232603532727808e-05\n",
      "Epoch 4091, Loss: 0.0008948056938606896, Final Batch Loss: 4.3120276131958235e-06\n",
      "Epoch 4092, Loss: 0.007321335887979785, Final Batch Loss: 5.960763246548595e-06\n",
      "Epoch 4093, Loss: 0.0018396525879325054, Final Batch Loss: 4.430234639585251e-06\n",
      "Epoch 4094, Loss: 0.0005871660405318835, Final Batch Loss: 5.2695304475491866e-05\n",
      "Epoch 4095, Loss: 0.00047181509773963626, Final Batch Loss: 1.0844511052710004e-05\n",
      "Epoch 4096, Loss: 0.004278720623460686, Final Batch Loss: 0.0036551763769239187\n",
      "Epoch 4097, Loss: 0.000306199128928597, Final Batch Loss: 4.647516561817611e-06\n",
      "Epoch 4098, Loss: 0.0007209950830713296, Final Batch Loss: 0.00027906984905712306\n",
      "Epoch 4099, Loss: 0.0028616878846605687, Final Batch Loss: 8.823008101899177e-06\n",
      "Epoch 4100, Loss: 0.002665068319288366, Final Batch Loss: 2.4689961719559506e-05\n",
      "Epoch 4101, Loss: 0.0020064825851591195, Final Batch Loss: 2.158933421014808e-05\n",
      "Epoch 4102, Loss: 0.0006004587201573486, Final Batch Loss: 1.3855621546099428e-05\n",
      "Epoch 4103, Loss: 0.0053803247225836515, Final Batch Loss: 6.0167938499944285e-05\n",
      "Epoch 4104, Loss: 0.0035365803445301935, Final Batch Loss: 0.002327280817553401\n",
      "Epoch 4105, Loss: 0.004602888093131696, Final Batch Loss: 8.853890562932065e-07\n",
      "Epoch 4106, Loss: 0.0015438002892551594, Final Batch Loss: 8.128875924739987e-05\n",
      "Epoch 4107, Loss: 0.0009113817527577339, Final Batch Loss: 4.685236854129471e-05\n",
      "Epoch 4108, Loss: 0.0006152018817147109, Final Batch Loss: 1.7618354831938632e-05\n",
      "Epoch 4109, Loss: 0.005943498377092737, Final Batch Loss: 3.1724258064969035e-07\n",
      "Epoch 4110, Loss: 0.0005944121044194617, Final Batch Loss: 3.631560275607626e-06\n",
      "Epoch 4111, Loss: 0.0036432638942187623, Final Batch Loss: 0.00011634336988208815\n",
      "Epoch 4112, Loss: 0.001627075522492305, Final Batch Loss: 2.7878334094566526e-06\n",
      "Epoch 4113, Loss: 0.0032394514183806677, Final Batch Loss: 1.82665535248816e-05\n",
      "Epoch 4114, Loss: 0.003107266079496185, Final Batch Loss: 2.548747943365015e-05\n",
      "Epoch 4115, Loss: 0.0007207763524093025, Final Batch Loss: 2.101573409163393e-05\n",
      "Epoch 4116, Loss: 0.013429135786850566, Final Batch Loss: 7.086510322551476e-06\n",
      "Epoch 4117, Loss: 0.0013796230136904342, Final Batch Loss: 0.0001959981891559437\n",
      "Epoch 4118, Loss: 0.03312763509507022, Final Batch Loss: 0.00010669879702618346\n",
      "Epoch 4119, Loss: 0.08787618782571371, Final Batch Loss: 0.0002897589292842895\n",
      "Epoch 4120, Loss: 0.004059408432112832, Final Batch Loss: 0.0013780437875539064\n",
      "Epoch 4121, Loss: 0.0006963031673876685, Final Batch Loss: 6.060145460651256e-05\n",
      "Epoch 4122, Loss: 0.003591589688937802, Final Batch Loss: 0.0001397348241880536\n",
      "Epoch 4123, Loss: 0.001998273978188081, Final Batch Loss: 6.013010988681344e-06\n",
      "Epoch 4124, Loss: 0.0003862294464909155, Final Batch Loss: 2.7536543711903505e-05\n",
      "Epoch 4125, Loss: 0.0061877358247102165, Final Batch Loss: 0.00045178362051956356\n",
      "Epoch 4126, Loss: 0.005495003414239363, Final Batch Loss: 3.679558722069487e-05\n",
      "Epoch 4127, Loss: 0.01920511895787058, Final Batch Loss: 6.088465397624532e-06\n",
      "Epoch 4128, Loss: 0.00033922112038453633, Final Batch Loss: 7.911839929874986e-07\n",
      "Epoch 4129, Loss: 0.00045471033081412315, Final Batch Loss: 5.30933493791963e-06\n",
      "Epoch 4130, Loss: 0.0005595252443413301, Final Batch Loss: 7.892595931480173e-06\n",
      "Epoch 4131, Loss: 0.003510119871975803, Final Batch Loss: 7.277735676325392e-06\n",
      "Epoch 4132, Loss: 0.0013844902177879703, Final Batch Loss: 2.77024428214645e-05\n",
      "Epoch 4133, Loss: 0.00033592159627460205, Final Batch Loss: 1.6595920897088945e-05\n",
      "Epoch 4134, Loss: 0.011278566709165716, Final Batch Loss: 7.85120137152262e-05\n",
      "Epoch 4135, Loss: 0.007119669973917553, Final Batch Loss: 5.689504905603826e-05\n",
      "Epoch 4136, Loss: 0.0017432911197374779, Final Batch Loss: 9.627881809137762e-05\n",
      "Epoch 4137, Loss: 0.0016491691510225337, Final Batch Loss: 6.559528992511332e-05\n",
      "Epoch 4138, Loss: 0.014642823414362738, Final Batch Loss: 0.014235811308026314\n",
      "Epoch 4139, Loss: 0.0031965429187721384, Final Batch Loss: 0.0003391639911569655\n",
      "Epoch 4140, Loss: 0.004233796999614015, Final Batch Loss: 1.178014645120129e-05\n",
      "Epoch 4141, Loss: 0.001238588320561007, Final Batch Loss: 1.4505482113236212e-06\n",
      "Epoch 4142, Loss: 0.00020318404088470743, Final Batch Loss: 4.231280854583019e-06\n",
      "Epoch 4143, Loss: 0.0002450626409427059, Final Batch Loss: 3.1822894470678875e-06\n",
      "Epoch 4144, Loss: 0.00020625570942911509, Final Batch Loss: 4.4737303142028395e-06\n",
      "Epoch 4145, Loss: 0.0037732563535541885, Final Batch Loss: 0.0021357766818255186\n",
      "Epoch 4146, Loss: 0.0011228033738461818, Final Batch Loss: 3.7204392810963327e-07\n",
      "Epoch 4147, Loss: 0.0011231494969479172, Final Batch Loss: 6.822247814852744e-05\n",
      "Epoch 4148, Loss: 0.0010120584993273951, Final Batch Loss: 5.582963422057219e-05\n",
      "Epoch 4149, Loss: 0.0006095540855994841, Final Batch Loss: 5.229346425039694e-05\n",
      "Epoch 4150, Loss: 0.00015799851202302762, Final Batch Loss: 6.955231697247655e-07\n",
      "Epoch 4151, Loss: 0.0006278278875697652, Final Batch Loss: 0.00039313858724199235\n",
      "Epoch 4152, Loss: 0.0006848686364833156, Final Batch Loss: 4.770030136569403e-05\n",
      "Epoch 4153, Loss: 0.0004835003799144033, Final Batch Loss: 6.124274659669027e-05\n",
      "Epoch 4154, Loss: 0.0007637504272963724, Final Batch Loss: 1.638297544559464e-05\n",
      "Epoch 4155, Loss: 0.000620678277741149, Final Batch Loss: 1.3113379282003734e-05\n",
      "Epoch 4156, Loss: 0.02030795032882793, Final Batch Loss: 4.959336365573108e-06\n",
      "Epoch 4157, Loss: 0.08541877993235403, Final Batch Loss: 2.1749994630226865e-05\n",
      "Epoch 4158, Loss: 0.00041242363502647095, Final Batch Loss: 2.660954305611085e-05\n",
      "Epoch 4159, Loss: 0.019393434050471114, Final Batch Loss: 2.1711166482418776e-06\n",
      "Epoch 4160, Loss: 0.008805723550494804, Final Batch Loss: 7.009856744844001e-06\n",
      "Epoch 4161, Loss: 0.0011510927895130862, Final Batch Loss: 5.322640845406568e-06\n",
      "Epoch 4162, Loss: 0.023339858593203644, Final Batch Loss: 2.5189707230310887e-05\n",
      "Epoch 4163, Loss: 0.008396938053920167, Final Batch Loss: 9.059951844392344e-05\n",
      "Epoch 4164, Loss: 0.0016192610883081215, Final Batch Loss: 4.859414912061766e-05\n",
      "Epoch 4165, Loss: 0.0015477932017802232, Final Batch Loss: 4.110221561859362e-05\n",
      "Epoch 4166, Loss: 0.0023663772644795245, Final Batch Loss: 0.0009950249223038554\n",
      "Epoch 4167, Loss: 0.00035485633569010133, Final Batch Loss: 3.6248172818886815e-06\n",
      "Epoch 4168, Loss: 0.0013807345310397068, Final Batch Loss: 0.0004967279965057969\n",
      "Epoch 4169, Loss: 0.00042826586036426306, Final Batch Loss: 1.55538350554707e-06\n",
      "Epoch 4170, Loss: 0.006825115296237527, Final Batch Loss: 1.600212635821663e-05\n",
      "Epoch 4171, Loss: 0.006099194128083241, Final Batch Loss: 1.2044877621519845e-05\n",
      "Epoch 4172, Loss: 0.017644037020403402, Final Batch Loss: 0.008565676398575306\n",
      "Epoch 4173, Loss: 0.009261360718483047, Final Batch Loss: 3.525181455188431e-05\n",
      "Epoch 4174, Loss: 0.007171253802425781, Final Batch Loss: 2.244597635581158e-05\n",
      "Epoch 4175, Loss: 0.010213931478574523, Final Batch Loss: 5.437148138298653e-05\n",
      "Epoch 4176, Loss: 0.034745711481832586, Final Batch Loss: 0.028258709236979485\n",
      "Epoch 4177, Loss: 0.10002385638483702, Final Batch Loss: 0.045197922736406326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4178, Loss: 0.008029121505387593, Final Batch Loss: 0.0008049592142924666\n",
      "Epoch 4179, Loss: 0.0055028484403010225, Final Batch Loss: 0.00017650198424234986\n",
      "Epoch 4180, Loss: 0.0030207990471353696, Final Batch Loss: 0.0005350104183889925\n",
      "Epoch 4181, Loss: 0.004999576158297714, Final Batch Loss: 4.772092142957263e-05\n",
      "Epoch 4182, Loss: 0.02974161980455392, Final Batch Loss: 0.00015930502559058368\n",
      "Epoch 4183, Loss: 0.004881892433331814, Final Batch Loss: 2.5674800781416707e-05\n",
      "Epoch 4184, Loss: 0.00322540938941529, Final Batch Loss: 2.27325417654356e-05\n",
      "Epoch 4185, Loss: 0.0009978981561289402, Final Batch Loss: 4.465098027139902e-05\n",
      "Epoch 4186, Loss: 0.0007912105047580553, Final Batch Loss: 5.387925557442941e-05\n",
      "Epoch 4187, Loss: 0.017770707516319817, Final Batch Loss: 7.830528193153441e-05\n",
      "Epoch 4188, Loss: 0.020689900586148724, Final Batch Loss: 5.475449142977595e-06\n",
      "Epoch 4189, Loss: 0.0017320044819371105, Final Batch Loss: 0.00016839540330693126\n",
      "Epoch 4190, Loss: 0.0009863054947345518, Final Batch Loss: 6.528140602313215e-06\n",
      "Epoch 4191, Loss: 0.003530386391958018, Final Batch Loss: 9.324256825493649e-05\n",
      "Epoch 4192, Loss: 0.017206092674314277, Final Batch Loss: 8.284051546070259e-06\n",
      "Epoch 4193, Loss: 0.00399912217471865, Final Batch Loss: 1.2457498087314889e-05\n",
      "Epoch 4194, Loss: 0.0015057167393024429, Final Batch Loss: 2.2752248696633615e-05\n",
      "Epoch 4195, Loss: 0.002244428957965283, Final Batch Loss: 9.288663022744004e-06\n",
      "Epoch 4196, Loss: 0.01908742255272955, Final Batch Loss: 0.0003414249513298273\n",
      "Epoch 4197, Loss: 0.0054149408078956185, Final Batch Loss: 0.00011426246055634692\n",
      "Epoch 4198, Loss: 0.011975116685789544, Final Batch Loss: 0.00010123381798621267\n",
      "Epoch 4199, Loss: 0.017259194544749334, Final Batch Loss: 3.1070234399521723e-05\n",
      "Epoch 4200, Loss: 0.003628179991210345, Final Batch Loss: 0.0007268532062880695\n",
      "Epoch 4201, Loss: 0.001021415976993012, Final Batch Loss: 9.826176210481208e-06\n",
      "Epoch 4202, Loss: 0.0032222603944092043, Final Batch Loss: 2.8006227239529835e-06\n",
      "Epoch 4203, Loss: 0.03183364429696667, Final Batch Loss: 1.5967489161994308e-05\n",
      "Epoch 4204, Loss: 0.02299589571703109, Final Batch Loss: 0.009175657294690609\n",
      "Epoch 4205, Loss: 0.003688545561203682, Final Batch Loss: 5.532443765332573e-07\n",
      "Epoch 4206, Loss: 0.0006649123008060087, Final Batch Loss: 5.595637503574835e-06\n",
      "Epoch 4207, Loss: 0.0005277107419487947, Final Batch Loss: 1.3743373528996017e-05\n",
      "Epoch 4208, Loss: 0.0024131589714215806, Final Batch Loss: 4.936487675877288e-05\n",
      "Epoch 4209, Loss: 0.009674371033042917, Final Batch Loss: 1.6745185348554514e-05\n",
      "Epoch 4210, Loss: 0.028665744999671006, Final Batch Loss: 0.027234118431806564\n",
      "Epoch 4211, Loss: 0.0012902101207146188, Final Batch Loss: 3.746287984540686e-05\n",
      "Epoch 4212, Loss: 0.006048443917393342, Final Batch Loss: 3.094139901804738e-05\n",
      "Epoch 4213, Loss: 0.0017454547614761395, Final Batch Loss: 2.565372415119782e-05\n",
      "Epoch 4214, Loss: 0.001601356100763951, Final Batch Loss: 0.00036635305150412023\n",
      "Epoch 4215, Loss: 0.0016012536040079794, Final Batch Loss: 8.909811003832147e-05\n",
      "Epoch 4216, Loss: 0.0003722488909261301, Final Batch Loss: 3.705814606291824e-06\n",
      "Epoch 4217, Loss: 0.013165529670914111, Final Batch Loss: 2.1893934899708256e-05\n",
      "Epoch 4218, Loss: 0.023055053802636394, Final Batch Loss: 0.013628684915602207\n",
      "Epoch 4219, Loss: 0.013878510797439958, Final Batch Loss: 0.0054428414441645145\n",
      "Epoch 4220, Loss: 0.024152875880076863, Final Batch Loss: 8.563280061935075e-06\n",
      "Epoch 4221, Loss: 0.004539740211839671, Final Batch Loss: 0.0002828045398928225\n",
      "Epoch 4222, Loss: 0.001175615675492736, Final Batch Loss: 7.908535735623445e-06\n",
      "Epoch 4223, Loss: 0.002141052283377576, Final Batch Loss: 8.695920405443758e-05\n",
      "Epoch 4224, Loss: 0.01185734894579582, Final Batch Loss: 0.00013490012497641146\n",
      "Epoch 4225, Loss: 0.03073443441849122, Final Batch Loss: 0.0007971279555931687\n",
      "Epoch 4226, Loss: 0.013891418491766672, Final Batch Loss: 2.6625133614288643e-05\n",
      "Epoch 4227, Loss: 0.016843312505443464, Final Batch Loss: 0.00012643588706851006\n",
      "Epoch 4228, Loss: 0.0018716641257014999, Final Batch Loss: 1.4838725292065646e-05\n",
      "Epoch 4229, Loss: 0.0022819086952949874, Final Batch Loss: 2.9001308575971052e-05\n",
      "Epoch 4230, Loss: 0.009047658477001619, Final Batch Loss: 2.6325567887397483e-05\n",
      "Epoch 4231, Loss: 0.0063040770646694, Final Batch Loss: 2.40746776398737e-05\n",
      "Epoch 4232, Loss: 0.004921957785370523, Final Batch Loss: 1.3610347195935901e-05\n",
      "Epoch 4233, Loss: 0.0013932061163757226, Final Batch Loss: 3.964667484979145e-06\n",
      "Epoch 4234, Loss: 0.019641003944343538, Final Batch Loss: 0.00029496190836653113\n",
      "Epoch 4235, Loss: 0.005009241125208064, Final Batch Loss: 5.441077064460842e-06\n",
      "Epoch 4236, Loss: 0.0008365036117083946, Final Batch Loss: 1.0583399671304505e-05\n",
      "Epoch 4237, Loss: 0.0006716098337165022, Final Batch Loss: 5.800278449896723e-05\n",
      "Epoch 4238, Loss: 0.021170492744431613, Final Batch Loss: 0.0003114631399512291\n",
      "Epoch 4239, Loss: 0.014510589605833957, Final Batch Loss: 0.00025872941478155553\n",
      "Epoch 4240, Loss: 0.04380856005678879, Final Batch Loss: 6.372956704581156e-05\n",
      "Epoch 4241, Loss: 0.006142470753843554, Final Batch Loss: 0.002945392392575741\n",
      "Epoch 4242, Loss: 0.012163065922777605, Final Batch Loss: 0.00019807013450190425\n",
      "Epoch 4243, Loss: 0.004790256310116092, Final Batch Loss: 0.0005729421973228455\n",
      "Epoch 4244, Loss: 0.01972688408477552, Final Batch Loss: 0.011030909605324268\n",
      "Epoch 4245, Loss: 0.0026841352832605025, Final Batch Loss: 0.0004454258596524596\n",
      "Epoch 4246, Loss: 0.0026143820174411303, Final Batch Loss: 5.148000127519481e-06\n",
      "Epoch 4247, Loss: 0.002003981674761235, Final Batch Loss: 0.00010645783186191693\n",
      "Epoch 4248, Loss: 0.0025542919961480948, Final Batch Loss: 3.508025474729948e-05\n",
      "Epoch 4249, Loss: 0.0005976527508693152, Final Batch Loss: 1.1185363291588146e-05\n",
      "Epoch 4250, Loss: 0.002904453236737936, Final Batch Loss: 9.176692401524633e-06\n",
      "Epoch 4251, Loss: 0.004408706329172674, Final Batch Loss: 3.668657154776156e-05\n",
      "Epoch 4252, Loss: 0.007841117526140806, Final Batch Loss: 0.0001619367249077186\n",
      "Epoch 4253, Loss: 0.02606783929240919, Final Batch Loss: 1.212784081872087e-05\n",
      "Epoch 4254, Loss: 0.00035270762600703165, Final Batch Loss: 7.50898561818758e-06\n",
      "Epoch 4255, Loss: 0.014546280700528769, Final Batch Loss: 1.040264487528475e-05\n",
      "Epoch 4256, Loss: 0.0022968088951529353, Final Batch Loss: 1.895619607239496e-05\n",
      "Epoch 4257, Loss: 0.002354562979462571, Final Batch Loss: 3.696253997986787e-06\n",
      "Epoch 4258, Loss: 0.015375243293874519, Final Batch Loss: 6.87589908920927e-06\n",
      "Epoch 4259, Loss: 0.014698605379720675, Final Batch Loss: 0.00035675466642715037\n",
      "Epoch 4260, Loss: 0.0034302941616033422, Final Batch Loss: 0.0016011240659281611\n",
      "Epoch 4261, Loss: 0.028793959335047248, Final Batch Loss: 2.087146094709169e-05\n",
      "Epoch 4262, Loss: 0.006628078537573856, Final Batch Loss: 0.00034690109896473587\n",
      "Epoch 4263, Loss: 0.002102955207192281, Final Batch Loss: 8.634084224468097e-05\n",
      "Epoch 4264, Loss: 0.002583842597232433, Final Batch Loss: 0.00018146520596928895\n",
      "Epoch 4265, Loss: 0.0073597933014752925, Final Batch Loss: 0.0005249954992905259\n",
      "Epoch 4266, Loss: 0.0006288139927619341, Final Batch Loss: 9.000029422168154e-06\n",
      "Epoch 4267, Loss: 0.0018600276963525175, Final Batch Loss: 5.162940942682326e-05\n",
      "Epoch 4268, Loss: 0.0010977116852686208, Final Batch Loss: 3.892508539138362e-05\n",
      "Epoch 4269, Loss: 0.0004289932689403031, Final Batch Loss: 6.998873868724331e-05\n",
      "Epoch 4270, Loss: 0.0007498261159071262, Final Batch Loss: 0.00010253521759295836\n",
      "Epoch 4271, Loss: 0.006707986904302743, Final Batch Loss: 6.264149760681903e-06\n",
      "Epoch 4272, Loss: 0.027028415164068065, Final Batch Loss: 1.19545684356126e-05\n",
      "Epoch 4273, Loss: 0.0052553255898146745, Final Batch Loss: 1.8026177713181823e-05\n",
      "Epoch 4274, Loss: 0.009840638216786601, Final Batch Loss: 0.0004149549931753427\n",
      "Epoch 4275, Loss: 0.011168511820017102, Final Batch Loss: 1.476138368161628e-05\n",
      "Epoch 4276, Loss: 0.026814090404741364, Final Batch Loss: 2.9646696475538192e-06\n",
      "Epoch 4277, Loss: 0.01915910115803854, Final Batch Loss: 3.036069028894417e-05\n",
      "Epoch 4278, Loss: 0.032620289943224634, Final Batch Loss: 1.7666305211605504e-05\n",
      "Epoch 4279, Loss: 0.030806258035227074, Final Batch Loss: 5.9396665164968e-05\n",
      "Epoch 4280, Loss: 0.015765478655339393, Final Batch Loss: 0.0002752220316324383\n",
      "Epoch 4281, Loss: 0.011321718489398336, Final Batch Loss: 0.0034837741404771805\n",
      "Epoch 4282, Loss: 0.038606028583672014, Final Batch Loss: 1.0572545761533547e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4283, Loss: 0.03188755195333215, Final Batch Loss: 0.00012668916315305978\n",
      "Epoch 4284, Loss: 0.007193456909590168, Final Batch Loss: 0.0001536609051981941\n",
      "Epoch 4285, Loss: 0.021453722831211053, Final Batch Loss: 9.122175833908841e-05\n",
      "Epoch 4286, Loss: 0.02473689198086504, Final Batch Loss: 3.9214824937516823e-05\n",
      "Epoch 4287, Loss: 0.0021631461968354415, Final Batch Loss: 5.3820665925741196e-05\n",
      "Epoch 4288, Loss: 0.003943236162740504, Final Batch Loss: 0.00016022853378672153\n",
      "Epoch 4289, Loss: 0.00667686864562711, Final Batch Loss: 9.513284567219671e-06\n",
      "Epoch 4290, Loss: 0.006214546310275182, Final Batch Loss: 1.3440178918244783e-05\n",
      "Epoch 4291, Loss: 0.00849645777952901, Final Batch Loss: 1.080429592548171e-05\n",
      "Epoch 4292, Loss: 0.001205400849300986, Final Batch Loss: 0.00019567135313991457\n",
      "Epoch 4293, Loss: 0.0006225484004858117, Final Batch Loss: 0.00010931205906672403\n",
      "Epoch 4294, Loss: 0.08097572426936495, Final Batch Loss: 0.000726977305021137\n",
      "Epoch 4295, Loss: 0.028017156298119517, Final Batch Loss: 0.00010268695768900216\n",
      "Epoch 4296, Loss: 0.01380501154335434, Final Batch Loss: 0.0007839477038942277\n",
      "Epoch 4297, Loss: 0.015935624415305938, Final Batch Loss: 0.0007015357841737568\n",
      "Epoch 4298, Loss: 0.007276138007000554, Final Batch Loss: 0.0003742402186617255\n",
      "Epoch 4299, Loss: 0.0029450451693264768, Final Batch Loss: 8.126857574097812e-05\n",
      "Epoch 4300, Loss: 0.002616618600768561, Final Batch Loss: 0.00015264209650922567\n",
      "Epoch 4301, Loss: 0.0037544736459835804, Final Batch Loss: 2.1646466848324053e-05\n",
      "Epoch 4302, Loss: 0.0013564978993372279, Final Batch Loss: 0.00023294916900340468\n",
      "Epoch 4303, Loss: 0.0024625210305657674, Final Batch Loss: 0.0019586635753512383\n",
      "Epoch 4304, Loss: 0.03817625259398483, Final Batch Loss: 0.00012250109284650534\n",
      "Epoch 4305, Loss: 0.0007539747218743287, Final Batch Loss: 5.0790094974217936e-05\n",
      "Epoch 4306, Loss: 0.007783282938589764, Final Batch Loss: 0.0014371947618201375\n",
      "Epoch 4307, Loss: 0.010539398003857059, Final Batch Loss: 6.704768748022616e-05\n",
      "Epoch 4308, Loss: 0.0008192666255126824, Final Batch Loss: 0.00016111247532535344\n",
      "Epoch 4309, Loss: 0.004208603976735503, Final Batch Loss: 3.255598130635917e-05\n",
      "Epoch 4310, Loss: 0.0011438575859301636, Final Batch Loss: 4.341200110502541e-06\n",
      "Epoch 4311, Loss: 0.000653707014862448, Final Batch Loss: 3.682166789076291e-05\n",
      "Epoch 4312, Loss: 0.0010109037380061636, Final Batch Loss: 8.056822116486728e-05\n",
      "Epoch 4313, Loss: 0.004061149484243742, Final Batch Loss: 2.114942435582634e-05\n",
      "Epoch 4314, Loss: 0.009904683212880627, Final Batch Loss: 1.2379738109302707e-05\n",
      "Epoch 4315, Loss: 0.0006677182068415277, Final Batch Loss: 4.250380152370781e-05\n",
      "Epoch 4316, Loss: 0.0025449735566098752, Final Batch Loss: 8.026906471059192e-06\n",
      "Epoch 4317, Loss: 0.0018518075652309562, Final Batch Loss: 1.6273808114419808e-06\n",
      "Epoch 4318, Loss: 0.001125788080798884, Final Batch Loss: 0.0001561350072734058\n",
      "Epoch 4319, Loss: 0.0005857869683723038, Final Batch Loss: 1.8595800383991445e-06\n",
      "Epoch 4320, Loss: 0.0008002702755902646, Final Batch Loss: 5.228727331996197e-06\n",
      "Epoch 4321, Loss: 0.00028269823700100005, Final Batch Loss: 6.001388101140037e-06\n",
      "Epoch 4322, Loss: 0.00020649442706144328, Final Batch Loss: 4.0212416934082285e-06\n",
      "Epoch 4323, Loss: 0.0008604063788766325, Final Batch Loss: 5.916182544751791e-06\n",
      "Epoch 4324, Loss: 0.00020412157721239055, Final Batch Loss: 1.9998455172753893e-05\n",
      "Epoch 4325, Loss: 0.0019350451521518153, Final Batch Loss: 8.18919488665415e-06\n",
      "Epoch 4326, Loss: 0.00019015505350239437, Final Batch Loss: 4.9057773139793426e-05\n",
      "Epoch 4327, Loss: 0.00018709773240743743, Final Batch Loss: 1.2941162822244223e-05\n",
      "Epoch 4328, Loss: 0.0012402367801769287, Final Batch Loss: 8.014397462829947e-05\n",
      "Epoch 4329, Loss: 0.0009349452351443688, Final Batch Loss: 9.560271791997366e-07\n",
      "Epoch 4330, Loss: 0.00027687960761824115, Final Batch Loss: 1.4490590729110409e-05\n",
      "Epoch 4331, Loss: 0.00847774952487157, Final Batch Loss: 1.2353481793070387e-07\n",
      "Epoch 4332, Loss: 0.0004804478990649841, Final Batch Loss: 2.345034999962081e-06\n",
      "Epoch 4333, Loss: 0.007868164035926384, Final Batch Loss: 1.382062600896461e-05\n",
      "Epoch 4334, Loss: 0.010812127967028573, Final Batch Loss: 3.0100181902525946e-06\n",
      "Epoch 4335, Loss: 0.0017791535799673852, Final Batch Loss: 6.446897896239534e-05\n",
      "Epoch 4336, Loss: 0.002407203153438786, Final Batch Loss: 5.06610058437218e-06\n",
      "Epoch 4337, Loss: 0.04169044455665727, Final Batch Loss: 1.0204561476712115e-05\n",
      "Epoch 4338, Loss: 0.004765582672689561, Final Batch Loss: 0.0033419583924114704\n",
      "Epoch 4339, Loss: 0.006910931754418925, Final Batch Loss: 3.273517722846009e-05\n",
      "Epoch 4340, Loss: 0.0022853309890251694, Final Batch Loss: 0.0009550544782541692\n",
      "Epoch 4341, Loss: 0.001030259017966273, Final Batch Loss: 1.07466303234105e-05\n",
      "Epoch 4342, Loss: 0.0169206477171997, Final Batch Loss: 0.0003855303511954844\n",
      "Epoch 4343, Loss: 0.01272025147147815, Final Batch Loss: 0.00034129267442040145\n",
      "Epoch 4344, Loss: 0.001839985615504247, Final Batch Loss: 7.614145033585373e-06\n",
      "Epoch 4345, Loss: 0.002402353132765711, Final Batch Loss: 0.00016808371583465487\n",
      "Epoch 4346, Loss: 0.0003590882254229655, Final Batch Loss: 1.4071057194087189e-05\n",
      "Epoch 4347, Loss: 0.0021024245393164165, Final Batch Loss: 1.9240010260546114e-06\n",
      "Epoch 4348, Loss: 0.037761307694381685, Final Batch Loss: 0.0012378032552078366\n",
      "Epoch 4349, Loss: 0.010303795789951664, Final Batch Loss: 2.9590391932288185e-05\n",
      "Epoch 4350, Loss: 0.003509223559282404, Final Batch Loss: 2.9541246476583183e-05\n",
      "Epoch 4351, Loss: 0.0008249464666505446, Final Batch Loss: 2.1955186184641207e-06\n",
      "Epoch 4352, Loss: 0.0008499093791840551, Final Batch Loss: 8.568049452151172e-06\n",
      "Epoch 4353, Loss: 0.0018389497147381917, Final Batch Loss: 6.501925327029312e-06\n",
      "Epoch 4354, Loss: 0.012769615287368197, Final Batch Loss: 2.0819077690248378e-05\n",
      "Epoch 4355, Loss: 0.0006426343738041851, Final Batch Loss: 1.0041132554761134e-05\n",
      "Epoch 4356, Loss: 0.013958155940599681, Final Batch Loss: 4.4042924855602905e-05\n",
      "Epoch 4357, Loss: 0.0008277833176180138, Final Batch Loss: 3.987695436080685e-06\n",
      "Epoch 4358, Loss: 0.0005263099805397076, Final Batch Loss: 5.008592438571213e-07\n",
      "Epoch 4359, Loss: 0.009946273820077067, Final Batch Loss: 0.0033342689275741577\n",
      "Epoch 4360, Loss: 0.00046759132050055996, Final Batch Loss: 2.666277578100562e-05\n",
      "Epoch 4361, Loss: 0.013849770505466097, Final Batch Loss: 3.181794090778567e-05\n",
      "Epoch 4362, Loss: 0.00615992753074579, Final Batch Loss: 5.178720130061265e-06\n",
      "Epoch 4363, Loss: 0.0005115720360890919, Final Batch Loss: 0.00014701396867167205\n",
      "Epoch 4364, Loss: 0.0031093677714579826, Final Batch Loss: 0.001509837107732892\n",
      "Epoch 4365, Loss: 0.012913723976907932, Final Batch Loss: 0.004926932044327259\n",
      "Epoch 4366, Loss: 0.0072641630172256555, Final Batch Loss: 1.4027625184098724e-05\n",
      "Epoch 4367, Loss: 0.0006240868460167803, Final Batch Loss: 4.091295340913348e-05\n",
      "Epoch 4368, Loss: 0.006962549266745555, Final Batch Loss: 8.632030585431494e-06\n",
      "Epoch 4369, Loss: 0.0018979978432298594, Final Batch Loss: 9.95477330434369e-06\n",
      "Epoch 4370, Loss: 0.003098107273842743, Final Batch Loss: 6.594752335331577e-07\n",
      "Epoch 4371, Loss: 0.0026413460932417365, Final Batch Loss: 3.744416244444437e-05\n",
      "Epoch 4372, Loss: 0.0019366631962611791, Final Batch Loss: 5.2208265515218955e-06\n",
      "Epoch 4373, Loss: 0.003985580582821058, Final Batch Loss: 4.9992941058008e-05\n",
      "Epoch 4374, Loss: 0.0023026571347202207, Final Batch Loss: 1.13572423288133e-05\n",
      "Epoch 4375, Loss: 0.002360572709335429, Final Batch Loss: 7.711099897278473e-05\n",
      "Epoch 4376, Loss: 0.0004825758271636005, Final Batch Loss: 1.8651149730430916e-05\n",
      "Epoch 4377, Loss: 0.0007993537153083707, Final Batch Loss: 4.046519461553544e-05\n",
      "Epoch 4378, Loss: 0.012787054453951896, Final Batch Loss: 8.409714064328e-05\n",
      "Epoch 4379, Loss: 0.015383014655981242, Final Batch Loss: 1.8156099031330086e-05\n",
      "Epoch 4380, Loss: 0.0021236140436542428, Final Batch Loss: 0.0007126962882466614\n",
      "Epoch 4381, Loss: 0.004431594841491915, Final Batch Loss: 3.0792158213444054e-05\n",
      "Epoch 4382, Loss: 0.0033838109096677726, Final Batch Loss: 0.0005843865219503641\n",
      "Epoch 4383, Loss: 0.0003130700592350877, Final Batch Loss: 6.888424832141027e-05\n",
      "Epoch 4384, Loss: 0.015896640448943344, Final Batch Loss: 0.006495414301753044\n",
      "Epoch 4385, Loss: 0.013639560394437922, Final Batch Loss: 0.00034056490403600037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4386, Loss: 0.008687395457627645, Final Batch Loss: 1.6281635907944292e-05\n",
      "Epoch 4387, Loss: 0.006023529090612101, Final Batch Loss: 3.272526782893692e-06\n",
      "Epoch 4388, Loss: 0.007307604854943861, Final Batch Loss: 5.289656201057369e-06\n",
      "Epoch 4389, Loss: 0.003105315854213586, Final Batch Loss: 0.00011434334010118619\n",
      "Epoch 4390, Loss: 0.014251150332711404, Final Batch Loss: 1.3643407328345347e-05\n",
      "Epoch 4391, Loss: 0.0027061111927650927, Final Batch Loss: 7.185695722000673e-05\n",
      "Epoch 4392, Loss: 0.002402913941807583, Final Batch Loss: 5.85779844186618e-06\n",
      "Epoch 4393, Loss: 0.011988329933430464, Final Batch Loss: 0.010592786595225334\n",
      "Epoch 4394, Loss: 0.0003141677478879501, Final Batch Loss: 1.2826452802983113e-05\n",
      "Epoch 4395, Loss: 0.0004662288858980901, Final Batch Loss: 8.871699537849054e-05\n",
      "Epoch 4396, Loss: 0.006088501288928683, Final Batch Loss: 1.5131932741496712e-05\n",
      "Epoch 4397, Loss: 0.0034885075037323077, Final Batch Loss: 0.002682407619431615\n",
      "Epoch 4398, Loss: 0.005700406740743347, Final Batch Loss: 4.449344123713672e-05\n",
      "Epoch 4399, Loss: 0.008203583845705964, Final Batch Loss: 0.0004128908913116902\n",
      "Epoch 4400, Loss: 0.01318808892136758, Final Batch Loss: 0.0001306648482568562\n",
      "Epoch 4401, Loss: 0.01121195099074157, Final Batch Loss: 0.007059928495436907\n",
      "Epoch 4402, Loss: 0.004725497864001227, Final Batch Loss: 0.0028334232047200203\n",
      "Epoch 4403, Loss: 0.004934448085350596, Final Batch Loss: 3.2430885767098516e-05\n",
      "Epoch 4404, Loss: 0.03696412231437307, Final Batch Loss: 5.710305117645476e-07\n",
      "Epoch 4405, Loss: 0.04263294346128532, Final Batch Loss: 1.8516811906010844e-05\n",
      "Epoch 4406, Loss: 0.037069605343276635, Final Batch Loss: 5.626196798402816e-05\n",
      "Epoch 4407, Loss: 0.02345905304377993, Final Batch Loss: 0.005682339891791344\n",
      "Epoch 4408, Loss: 0.03376028484967719, Final Batch Loss: 0.00022241761325858533\n",
      "Epoch 4409, Loss: 0.010941634964524383, Final Batch Loss: 0.002934447256848216\n",
      "Epoch 4410, Loss: 0.001918064552683063, Final Batch Loss: 1.3918657714384608e-05\n",
      "Epoch 4411, Loss: 0.00912643619130904, Final Batch Loss: 6.632386066485196e-05\n",
      "Epoch 4412, Loss: 0.001972262845356454, Final Batch Loss: 0.00012207480904180557\n",
      "Epoch 4413, Loss: 0.01139792640003634, Final Batch Loss: 0.0001690300414338708\n",
      "Epoch 4414, Loss: 0.020977480879594168, Final Batch Loss: 6.738151569152251e-05\n",
      "Epoch 4415, Loss: 0.007706732175392972, Final Batch Loss: 0.00011543324217200279\n",
      "Epoch 4416, Loss: 0.015318234358119298, Final Batch Loss: 3.475961193544208e-06\n",
      "Epoch 4417, Loss: 0.03260345503110784, Final Batch Loss: 0.02914285659790039\n",
      "Epoch 4418, Loss: 0.004502426670910609, Final Batch Loss: 0.000790668185800314\n",
      "Epoch 4419, Loss: 0.00180025422196195, Final Batch Loss: 0.00044477300252765417\n",
      "Epoch 4420, Loss: 0.006816270311446715, Final Batch Loss: 0.00017450281302444637\n",
      "Epoch 4421, Loss: 0.0012115457875552238, Final Batch Loss: 3.6115314287599176e-05\n",
      "Epoch 4422, Loss: 0.0010820925135703874, Final Batch Loss: 1.9998651623609476e-06\n",
      "Epoch 4423, Loss: 0.0015853673303070082, Final Batch Loss: 2.308538205397781e-05\n",
      "Epoch 4424, Loss: 0.002086272297560754, Final Batch Loss: 3.6335648474050686e-05\n",
      "Epoch 4425, Loss: 0.0005794942644570256, Final Batch Loss: 0.00015910802176222205\n",
      "Epoch 4426, Loss: 0.010905115747050331, Final Batch Loss: 0.0001510487636551261\n",
      "Epoch 4427, Loss: 0.001640235766672049, Final Batch Loss: 4.825860378332436e-05\n",
      "Epoch 4428, Loss: 0.00041668794364113637, Final Batch Loss: 1.0557483619777486e-05\n",
      "Epoch 4429, Loss: 0.0008835770712494195, Final Batch Loss: 5.970147867628839e-06\n",
      "Epoch 4430, Loss: 0.007818480959826957, Final Batch Loss: 6.077850048313849e-05\n",
      "Epoch 4431, Loss: 0.001148066575382245, Final Batch Loss: 6.223933269211557e-06\n",
      "Epoch 4432, Loss: 0.002694284040671846, Final Batch Loss: 6.0675854911096394e-05\n",
      "Epoch 4433, Loss: 0.0036420715646272583, Final Batch Loss: 1.812787559174467e-05\n",
      "Epoch 4434, Loss: 0.0043882849188321416, Final Batch Loss: 0.003873600857332349\n",
      "Epoch 4435, Loss: 0.0004684194150286203, Final Batch Loss: 1.8775688658934087e-05\n",
      "Epoch 4436, Loss: 0.0003653637693332712, Final Batch Loss: 1.6852425687829964e-05\n",
      "Epoch 4437, Loss: 0.0015546388518714593, Final Batch Loss: 0.00041444620001129806\n",
      "Epoch 4438, Loss: 0.0001895201093589094, Final Batch Loss: 2.144024847439141e-06\n",
      "Epoch 4439, Loss: 0.37242761689753934, Final Batch Loss: 1.117048554988287e-06\n",
      "Epoch 4440, Loss: 0.0006611383486045952, Final Batch Loss: 0.00016702651919331402\n",
      "Epoch 4441, Loss: 0.005736285778425554, Final Batch Loss: 8.317344327224419e-05\n",
      "Epoch 4442, Loss: 0.002488561276265955, Final Batch Loss: 5.262477498035878e-05\n",
      "Epoch 4443, Loss: 0.001095544804002202, Final Batch Loss: 0.00045813986798748374\n",
      "Epoch 4444, Loss: 0.0008692848964528821, Final Batch Loss: 0.00010575037595117465\n",
      "Epoch 4445, Loss: 0.007196441308678914, Final Batch Loss: 1.3176098036637995e-05\n",
      "Epoch 4446, Loss: 0.0017702290870147408, Final Batch Loss: 2.0127066818531603e-05\n",
      "Epoch 4447, Loss: 0.005297648829014179, Final Batch Loss: 5.160853106644936e-05\n",
      "Epoch 4448, Loss: 0.003365067480331163, Final Batch Loss: 3.6485907912719995e-05\n",
      "Epoch 4449, Loss: 0.0017983158713832381, Final Batch Loss: 2.9076330974930897e-05\n",
      "Epoch 4450, Loss: 0.007139987610401022, Final Batch Loss: 3.103424751316197e-05\n",
      "Epoch 4451, Loss: 0.001912718892981502, Final Batch Loss: 4.822987193620065e-06\n",
      "Epoch 4452, Loss: 0.001551836360249581, Final Batch Loss: 1.5945008271955885e-05\n",
      "Epoch 4453, Loss: 0.0008954459292453976, Final Batch Loss: 0.0005256475997157395\n",
      "Epoch 4454, Loss: 0.0006016589702539932, Final Batch Loss: 3.91967023460893e-06\n",
      "Epoch 4455, Loss: 0.004370796280227296, Final Batch Loss: 0.0005926013109274209\n",
      "Epoch 4456, Loss: 0.00860076328535797, Final Batch Loss: 0.00015384063590317965\n",
      "Epoch 4457, Loss: 0.0037270099651323108, Final Batch Loss: 4.274684215488378e-06\n",
      "Epoch 4458, Loss: 0.004492515738888869, Final Batch Loss: 1.0266714525641873e-05\n",
      "Epoch 4459, Loss: 0.00028535820047181915, Final Batch Loss: 9.228527233062778e-06\n",
      "Epoch 4460, Loss: 0.012227846916573526, Final Batch Loss: 1.1171420737809967e-05\n",
      "Epoch 4461, Loss: 0.004611667620110893, Final Batch Loss: 3.138717875117436e-05\n",
      "Epoch 4462, Loss: 0.0034787550893042862, Final Batch Loss: 4.413841907080496e-06\n",
      "Epoch 4463, Loss: 0.00037348972445272466, Final Batch Loss: 0.00011294736032141373\n",
      "Epoch 4464, Loss: 0.00030051941871533927, Final Batch Loss: 3.43698266078718e-05\n",
      "Epoch 4465, Loss: 0.0003238796118694154, Final Batch Loss: 6.046799398973235e-07\n",
      "Epoch 4466, Loss: 0.013427757002659746, Final Batch Loss: 1.1651208296825644e-05\n",
      "Epoch 4467, Loss: 0.0004424245869394383, Final Batch Loss: 2.5894667487591505e-05\n",
      "Epoch 4468, Loss: 0.024105319123691515, Final Batch Loss: 0.00018204467778559774\n",
      "Epoch 4469, Loss: 0.004715617019769525, Final Batch Loss: 1.8306722267880104e-05\n",
      "Epoch 4470, Loss: 0.0213709354961793, Final Batch Loss: 0.0004943220410495996\n",
      "Epoch 4471, Loss: 0.01178317600124501, Final Batch Loss: 8.057767445279751e-06\n",
      "Epoch 4472, Loss: 0.003920997210457244, Final Batch Loss: 0.0020299421157687902\n",
      "Epoch 4473, Loss: 0.00039159662543397644, Final Batch Loss: 7.3870705818990245e-06\n",
      "Epoch 4474, Loss: 0.0003604684300739791, Final Batch Loss: 0.00011742865899577737\n",
      "Epoch 4475, Loss: 0.017166912765105735, Final Batch Loss: 7.188625750131905e-05\n",
      "Epoch 4476, Loss: 0.002116315676175873, Final Batch Loss: 0.00012148597306804731\n",
      "Epoch 4477, Loss: 0.006167426195133885, Final Batch Loss: 2.0652785224228865e-06\n",
      "Epoch 4478, Loss: 0.0015520516112701443, Final Batch Loss: 4.615454963641241e-05\n",
      "Epoch 4479, Loss: 0.023796380442036025, Final Batch Loss: 3.223145176889375e-05\n",
      "Epoch 4480, Loss: 0.005163327096852299, Final Batch Loss: 1.2348679774731863e-05\n",
      "Epoch 4481, Loss: 0.003850953314668004, Final Batch Loss: 2.537702675908804e-05\n",
      "Epoch 4482, Loss: 0.0014477334201501435, Final Batch Loss: 1.7208796634804457e-05\n",
      "Epoch 4483, Loss: 0.01976043417067075, Final Batch Loss: 7.129806908778846e-05\n",
      "Epoch 4484, Loss: 0.021390472846405828, Final Batch Loss: 0.00010717388067860156\n",
      "Epoch 4485, Loss: 0.009395057202709722, Final Batch Loss: 2.4318936993950047e-05\n",
      "Epoch 4486, Loss: 0.01319488576697836, Final Batch Loss: 0.001432908116839826\n",
      "Epoch 4487, Loss: 0.004714488480658474, Final Batch Loss: 1.029549639497418e-05\n",
      "Epoch 4488, Loss: 0.0013059277509910316, Final Batch Loss: 1.8143330180464545e-06\n",
      "Epoch 4489, Loss: 0.027012158245725004, Final Batch Loss: 0.005642329342663288\n",
      "Epoch 4490, Loss: 0.0013120233880385967, Final Batch Loss: 0.00022903745411895216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4491, Loss: 0.0007698750806639509, Final Batch Loss: 1.9319981220178306e-05\n",
      "Epoch 4492, Loss: 0.014596150054387635, Final Batch Loss: 9.252873383047699e-07\n",
      "Epoch 4493, Loss: 0.0030777922489164666, Final Batch Loss: 8.845024240144994e-06\n",
      "Epoch 4494, Loss: 0.045609932503509754, Final Batch Loss: 9.413105726707727e-05\n",
      "Epoch 4495, Loss: 0.004987828480579992, Final Batch Loss: 0.002336266450583935\n",
      "Epoch 4496, Loss: 0.009103236322971497, Final Batch Loss: 2.4648419639561325e-05\n",
      "Epoch 4497, Loss: 0.0016412610838187902, Final Batch Loss: 1.8311563962924993e-06\n",
      "Epoch 4498, Loss: 0.0009362438599964662, Final Batch Loss: 1.3006980225327425e-05\n",
      "Epoch 4499, Loss: 0.01833366290689753, Final Batch Loss: 4.2732204747153446e-05\n",
      "Epoch 4500, Loss: 0.06297439738415278, Final Batch Loss: 0.004648556932806969\n",
      "Epoch 4501, Loss: 0.19497780707376933, Final Batch Loss: 5.40274299964949e-07\n",
      "Epoch 4502, Loss: 0.05114017840696761, Final Batch Loss: 0.024582387879490852\n",
      "Epoch 4503, Loss: 0.036740325723030764, Final Batch Loss: 0.03227105736732483\n",
      "Epoch 4504, Loss: 0.01113076114870637, Final Batch Loss: 0.0011385335819795728\n",
      "Epoch 4505, Loss: 0.012956167060110602, Final Batch Loss: 0.00018936960259452462\n",
      "Epoch 4506, Loss: 0.010615998686262174, Final Batch Loss: 2.1963214749121107e-05\n",
      "Epoch 4507, Loss: 0.005853308022778947, Final Batch Loss: 0.0008883984992280602\n",
      "Epoch 4508, Loss: 0.023659818956730305, Final Batch Loss: 0.0006065753987058997\n",
      "Epoch 4509, Loss: 0.004256213402186404, Final Batch Loss: 4.436195740709081e-05\n",
      "Epoch 4510, Loss: 0.010312955635072285, Final Batch Loss: 1.158785198640544e-05\n",
      "Epoch 4511, Loss: 0.0042806948213183205, Final Batch Loss: 0.0006455174298025668\n",
      "Epoch 4512, Loss: 0.004490054727739334, Final Batch Loss: 9.984013013308868e-05\n",
      "Epoch 4513, Loss: 0.001982893807507935, Final Batch Loss: 0.00021211123385000974\n",
      "Epoch 4514, Loss: 0.010926056228981906, Final Batch Loss: 0.003386574797332287\n",
      "Epoch 4515, Loss: 0.0038707310454810795, Final Batch Loss: 8.211324711737689e-06\n",
      "Epoch 4516, Loss: 0.0018153923325030519, Final Batch Loss: 0.00010362056491430849\n",
      "Epoch 4517, Loss: 0.00317003602594923, Final Batch Loss: 0.00021164369536563754\n",
      "Epoch 4518, Loss: 0.01649002475846828, Final Batch Loss: 2.0379047782626003e-05\n",
      "Epoch 4519, Loss: 0.0020260883707123867, Final Batch Loss: 0.0001968511933228001\n",
      "Epoch 4520, Loss: 0.01093060490006792, Final Batch Loss: 1.3536078768083826e-05\n",
      "Epoch 4521, Loss: 0.029089359670933845, Final Batch Loss: 0.00015780671674292535\n",
      "Epoch 4522, Loss: 0.004008239227005106, Final Batch Loss: 0.0001350975944660604\n",
      "Epoch 4523, Loss: 0.002661714366581691, Final Batch Loss: 8.765384336584248e-06\n",
      "Epoch 4524, Loss: 0.0018356206862790714, Final Batch Loss: 5.4375592299038544e-05\n",
      "Epoch 4525, Loss: 0.00424960799409746, Final Batch Loss: 0.00013623142149299383\n",
      "Epoch 4526, Loss: 0.0009091153733606916, Final Batch Loss: 3.1307390599977225e-05\n",
      "Epoch 4527, Loss: 0.0031434883974270633, Final Batch Loss: 5.720711669709999e-06\n",
      "Epoch 4528, Loss: 0.0059333415549645, Final Batch Loss: 0.00090503238607198\n",
      "Epoch 4529, Loss: 0.0017382122166509362, Final Batch Loss: 1.9126173356198706e-05\n",
      "Epoch 4530, Loss: 0.0009821222429309273, Final Batch Loss: 2.389054134255275e-05\n",
      "Epoch 4531, Loss: 0.0007285254339137737, Final Batch Loss: 6.701005986542441e-06\n",
      "Epoch 4532, Loss: 0.0035333091566371877, Final Batch Loss: 8.060591062530875e-05\n",
      "Epoch 4533, Loss: 0.0013680411060477127, Final Batch Loss: 0.0006478412542492151\n",
      "Epoch 4534, Loss: 0.002728895119162189, Final Batch Loss: 8.26757968752645e-07\n",
      "Epoch 4535, Loss: 0.0027590748732109205, Final Batch Loss: 0.00026050041196867824\n",
      "Epoch 4536, Loss: 0.0009125250217039138, Final Batch Loss: 0.0001385099603794515\n",
      "Epoch 4537, Loss: 0.001128616542700911, Final Batch Loss: 8.183754289348144e-06\n",
      "Epoch 4538, Loss: 0.00043342906383259105, Final Batch Loss: 6.3295387917605694e-06\n",
      "Epoch 4539, Loss: 0.030640677542180583, Final Batch Loss: 0.00024166909861378372\n",
      "Epoch 4540, Loss: 0.001019847257452966, Final Batch Loss: 3.96455179725308e-05\n",
      "Epoch 4541, Loss: 0.0015459309349807882, Final Batch Loss: 8.976949175121263e-06\n",
      "Epoch 4542, Loss: 0.002241511628653825, Final Batch Loss: 8.37358966236934e-05\n",
      "Epoch 4543, Loss: 0.013915070582243061, Final Batch Loss: 0.0016814330592751503\n",
      "Epoch 4544, Loss: 0.0018134380329684063, Final Batch Loss: 9.790603508008644e-05\n",
      "Epoch 4545, Loss: 0.006468780064096791, Final Batch Loss: 0.0011436877539381385\n",
      "Epoch 4546, Loss: 0.0027521211752628005, Final Batch Loss: 4.834109859075397e-05\n",
      "Epoch 4547, Loss: 0.000805857458999526, Final Batch Loss: 1.9287856048322283e-05\n",
      "Epoch 4548, Loss: 0.00658657622238934, Final Batch Loss: 0.0005228689406067133\n",
      "Epoch 4549, Loss: 0.003320436051581055, Final Batch Loss: 3.0690160201629624e-05\n",
      "Epoch 4550, Loss: 0.01046643741187836, Final Batch Loss: 0.00018756403005681932\n",
      "Epoch 4551, Loss: 0.01041323604158606, Final Batch Loss: 3.5860455682268366e-05\n",
      "Epoch 4552, Loss: 0.0012402312831909512, Final Batch Loss: 8.995391544885933e-05\n",
      "Epoch 4553, Loss: 0.005075707261653406, Final Batch Loss: 0.002455249661579728\n",
      "Epoch 4554, Loss: 0.002734769168910134, Final Batch Loss: 4.073973832419142e-05\n",
      "Epoch 4555, Loss: 0.0007697512068034484, Final Batch Loss: 0.0001033040025504306\n",
      "Epoch 4556, Loss: 0.0014624731438743765, Final Batch Loss: 4.3849086068803445e-05\n",
      "Epoch 4557, Loss: 0.0009748345766524835, Final Batch Loss: 4.355962573754368e-06\n",
      "Epoch 4558, Loss: 0.004007165686743974, Final Batch Loss: 5.43608985026367e-05\n",
      "Epoch 4559, Loss: 0.009528182033136545, Final Batch Loss: 5.4560889111598954e-05\n",
      "Epoch 4560, Loss: 0.0012352142753115913, Final Batch Loss: 8.299529872601852e-05\n",
      "Epoch 4561, Loss: 0.003288514691803357, Final Batch Loss: 1.782723848009482e-05\n",
      "Epoch 4562, Loss: 0.0020668046986429545, Final Batch Loss: 0.0002680522738955915\n",
      "Epoch 4563, Loss: 0.006715042430414542, Final Batch Loss: 1.2694688848569058e-05\n",
      "Epoch 4564, Loss: 0.03677085830457827, Final Batch Loss: 0.00036526875919662416\n",
      "Epoch 4565, Loss: 0.11635029872468294, Final Batch Loss: 0.05121524631977081\n",
      "Epoch 4566, Loss: 0.05339081341210772, Final Batch Loss: 4.383773841709626e-07\n",
      "Epoch 4567, Loss: 0.06271047559425824, Final Batch Loss: 0.00014640766312368214\n",
      "Epoch 4568, Loss: 0.025624156813137233, Final Batch Loss: 0.00033214440918527544\n",
      "Epoch 4569, Loss: 0.0021570474327745615, Final Batch Loss: 1.054553081303311e-06\n",
      "Epoch 4570, Loss: 0.008482267686019895, Final Batch Loss: 3.033059670087823e-07\n",
      "Epoch 4571, Loss: 0.000855629198895258, Final Batch Loss: 0.00017845026741269976\n",
      "Epoch 4572, Loss: 0.01102252618784405, Final Batch Loss: 0.00786716677248478\n",
      "Epoch 4573, Loss: 0.0013269031554727917, Final Batch Loss: 2.300389269294101e-06\n",
      "Epoch 4574, Loss: 0.002539776071216693, Final Batch Loss: 1.5072853784658946e-05\n",
      "Epoch 4575, Loss: 0.001978152670176314, Final Batch Loss: 7.837698649382219e-05\n",
      "Epoch 4576, Loss: 0.09432133884547511, Final Batch Loss: 9.112407133216038e-05\n",
      "Epoch 4577, Loss: 0.03369019653473515, Final Batch Loss: 6.249827129067853e-05\n",
      "Epoch 4578, Loss: 0.013423900421003054, Final Batch Loss: 0.0014174350071698427\n",
      "Epoch 4579, Loss: 0.006570069174813398, Final Batch Loss: 1.0838924026757013e-05\n",
      "Epoch 4580, Loss: 0.0013420677978501772, Final Batch Loss: 0.00010457379539730027\n",
      "Epoch 4581, Loss: 0.00299150194973663, Final Batch Loss: 1.1314391485939268e-05\n",
      "Epoch 4582, Loss: 0.029609811138016084, Final Batch Loss: 0.002300860360264778\n",
      "Epoch 4583, Loss: 0.002898779665656548, Final Batch Loss: 2.9741236176050734e-06\n",
      "Epoch 4584, Loss: 0.004384717469292809, Final Batch Loss: 1.732494456518907e-05\n",
      "Epoch 4585, Loss: 0.003089783674568025, Final Batch Loss: 9.693663014331833e-05\n",
      "Epoch 4586, Loss: 0.0024619367623870403, Final Batch Loss: 0.00018436780374031514\n",
      "Epoch 4587, Loss: 0.005979190611469676, Final Batch Loss: 0.001513906056061387\n",
      "Epoch 4588, Loss: 0.001695467492595526, Final Batch Loss: 3.6620444006985053e-05\n",
      "Epoch 4589, Loss: 0.007309277510216816, Final Batch Loss: 6.622059299843386e-05\n",
      "Epoch 4590, Loss: 0.005438710650196299, Final Batch Loss: 0.0001509889552835375\n",
      "Epoch 4591, Loss: 0.0076977858116151765, Final Batch Loss: 1.8178781829192303e-05\n",
      "Epoch 4592, Loss: 0.0006265639608500351, Final Batch Loss: 6.764809950254858e-05\n",
      "Epoch 4593, Loss: 0.0026537994672253262, Final Batch Loss: 7.696582179050893e-05\n",
      "Epoch 4594, Loss: 0.00325628972677805, Final Batch Loss: 2.3586282623000443e-05\n",
      "Epoch 4595, Loss: 0.003771171522203076, Final Batch Loss: 2.4105500415316783e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4596, Loss: 0.0013853205432354798, Final Batch Loss: 2.110189001314211e-07\n",
      "Epoch 4597, Loss: 0.0014094106559241482, Final Batch Loss: 1.016303758660797e-05\n",
      "Epoch 4598, Loss: 0.003576900279313122, Final Batch Loss: 3.5496232158038765e-05\n",
      "Epoch 4599, Loss: 0.0007929778698780865, Final Batch Loss: 5.715712177334353e-06\n",
      "Epoch 4600, Loss: 0.0009897111481222964, Final Batch Loss: 1.3136511824995978e-06\n",
      "Epoch 4601, Loss: 0.00045742893166789145, Final Batch Loss: 1.7019763618009165e-05\n",
      "Epoch 4602, Loss: 0.0009663240269901507, Final Batch Loss: 6.35547039564699e-05\n",
      "Epoch 4603, Loss: 0.0027026265933614013, Final Batch Loss: 0.00014825370453763753\n",
      "Epoch 4604, Loss: 0.00034608969596661154, Final Batch Loss: 3.0086930564721115e-06\n",
      "Epoch 4605, Loss: 0.0008063490582799204, Final Batch Loss: 9.257896635972429e-06\n",
      "Epoch 4606, Loss: 0.0012229547886590808, Final Batch Loss: 2.6344558136770502e-05\n",
      "Epoch 4607, Loss: 0.00032211722418651334, Final Batch Loss: 1.8314465705771e-05\n",
      "Epoch 4608, Loss: 0.01335485656329638, Final Batch Loss: 2.03532435989473e-05\n",
      "Epoch 4609, Loss: 0.0004456960842276203, Final Batch Loss: 1.5404768873850117e-06\n",
      "Epoch 4610, Loss: 0.00048823655596663684, Final Batch Loss: 1.9793305909843184e-05\n",
      "Epoch 4611, Loss: 0.000895501800528109, Final Batch Loss: 5.717278327210806e-06\n",
      "Epoch 4612, Loss: 0.0006972030328142864, Final Batch Loss: 1.028202586894622e-05\n",
      "Epoch 4613, Loss: 0.0005622870064314611, Final Batch Loss: 3.8699316064594314e-05\n",
      "Epoch 4614, Loss: 0.0023460313732925897, Final Batch Loss: 9.256295925297309e-06\n",
      "Epoch 4615, Loss: 0.012386435549842645, Final Batch Loss: 2.1442776414914988e-05\n",
      "Epoch 4616, Loss: 0.004119910637996327, Final Batch Loss: 2.385939660598524e-05\n",
      "Epoch 4617, Loss: 0.0013809234299060336, Final Batch Loss: 4.812849965674104e-06\n",
      "Epoch 4618, Loss: 0.0004927089428292675, Final Batch Loss: 1.3472780665324535e-05\n",
      "Epoch 4619, Loss: 0.0019683079481183086, Final Batch Loss: 1.3056626812613104e-05\n",
      "Epoch 4620, Loss: 0.006036765612805084, Final Batch Loss: 8.81021551322192e-05\n",
      "Epoch 4621, Loss: 0.0018907398984993051, Final Batch Loss: 0.00012083294132025912\n",
      "Epoch 4622, Loss: 0.00029019198370860977, Final Batch Loss: 1.3895888741899398e-06\n",
      "Epoch 4623, Loss: 0.0046392810286306485, Final Batch Loss: 6.269941513892263e-05\n",
      "Epoch 4624, Loss: 0.0009676368604232266, Final Batch Loss: 0.00015091689419932663\n",
      "Epoch 4625, Loss: 0.0008090527785498125, Final Batch Loss: 0.00027032254729419947\n",
      "Epoch 4626, Loss: 0.00034723213912002393, Final Batch Loss: 7.438713055307744e-06\n",
      "Epoch 4627, Loss: 0.0029954795525100053, Final Batch Loss: 9.949749255611096e-07\n",
      "Epoch 4628, Loss: 0.006055167588215227, Final Batch Loss: 1.8204627849627286e-05\n",
      "Epoch 4629, Loss: 0.0016742816879187217, Final Batch Loss: 3.233118832213222e-06\n",
      "Epoch 4630, Loss: 0.0017374316528275813, Final Batch Loss: 5.5955541029106826e-05\n",
      "Epoch 4631, Loss: 0.0065893035267095, Final Batch Loss: 4.348713900981238e-06\n",
      "Epoch 4632, Loss: 0.003439804482013642, Final Batch Loss: 8.188280844478868e-06\n",
      "Epoch 4633, Loss: 0.0003343980699810345, Final Batch Loss: 1.7105377992265858e-05\n",
      "Epoch 4634, Loss: 0.0005048659041904102, Final Batch Loss: 3.3496571631985717e-06\n",
      "Epoch 4635, Loss: 0.00950818810997589, Final Batch Loss: 1.582313961989712e-05\n",
      "Epoch 4636, Loss: 0.07198465713008773, Final Batch Loss: 1.1603305210883263e-05\n",
      "Epoch 4637, Loss: 0.059717805988839245, Final Batch Loss: 0.00034893807605840266\n",
      "Epoch 4638, Loss: 0.01748111952466047, Final Batch Loss: 0.00016703273286111653\n",
      "Epoch 4639, Loss: 0.0048504246976790455, Final Batch Loss: 4.475852256291546e-05\n",
      "Epoch 4640, Loss: 0.0360877736366092, Final Batch Loss: 0.02604113332927227\n",
      "Epoch 4641, Loss: 0.021661048712758202, Final Batch Loss: 0.01660771295428276\n",
      "Epoch 4642, Loss: 0.011989967588704076, Final Batch Loss: 0.002162588993087411\n",
      "Epoch 4643, Loss: 0.010080046428583955, Final Batch Loss: 0.0012919347500428557\n",
      "Epoch 4644, Loss: 0.030799939879784688, Final Batch Loss: 0.029591932892799377\n",
      "Epoch 4645, Loss: 0.0036926052107446594, Final Batch Loss: 2.715106529649347e-05\n",
      "Epoch 4646, Loss: 0.01751430447484381, Final Batch Loss: 0.00561969168484211\n",
      "Epoch 4647, Loss: 0.0035515326221684518, Final Batch Loss: 1.7485770513303578e-05\n",
      "Epoch 4648, Loss: 0.001184563736273958, Final Batch Loss: 6.653901891695568e-06\n",
      "Epoch 4649, Loss: 0.0008732447804504773, Final Batch Loss: 4.200708644930273e-05\n",
      "Epoch 4650, Loss: 0.002822340149350566, Final Batch Loss: 0.00016397998842876405\n",
      "Epoch 4651, Loss: 0.0009649589259197455, Final Batch Loss: 5.6394481362076476e-05\n",
      "Epoch 4652, Loss: 0.022728641314643028, Final Batch Loss: 7.426059164572507e-05\n",
      "Epoch 4653, Loss: 0.005384264077292755, Final Batch Loss: 1.7095651855925098e-05\n",
      "Epoch 4654, Loss: 0.0013728060866924352, Final Batch Loss: 4.136307325097732e-06\n",
      "Epoch 4655, Loss: 0.0019884986093074986, Final Batch Loss: 0.00031843327451497316\n",
      "Epoch 4656, Loss: 0.0020265210928300803, Final Batch Loss: 4.045024070364889e-06\n",
      "Epoch 4657, Loss: 0.0025263829411414918, Final Batch Loss: 0.0001328755752183497\n",
      "Epoch 4658, Loss: 0.005393704817834077, Final Batch Loss: 8.083016837190371e-06\n",
      "Epoch 4659, Loss: 0.021658996612131887, Final Batch Loss: 1.5019577404018492e-05\n",
      "Epoch 4660, Loss: 0.0036354534759084345, Final Batch Loss: 6.861428846605122e-05\n",
      "Epoch 4661, Loss: 0.0012966216249878926, Final Batch Loss: 3.496706631267443e-05\n",
      "Epoch 4662, Loss: 0.0030406454527565074, Final Batch Loss: 0.0001293842651648447\n",
      "Epoch 4663, Loss: 0.0016465510111629555, Final Batch Loss: 8.434462870354764e-06\n",
      "Epoch 4664, Loss: 0.004722378276710515, Final Batch Loss: 1.6667707313899882e-05\n",
      "Epoch 4665, Loss: 0.007519720260233953, Final Batch Loss: 0.0003122728085145354\n",
      "Epoch 4666, Loss: 0.02973535316800735, Final Batch Loss: 1.0128243047802243e-05\n",
      "Epoch 4667, Loss: 0.0012497939537752245, Final Batch Loss: 1.3419840797723737e-05\n",
      "Epoch 4668, Loss: 0.0007129075589773493, Final Batch Loss: 1.48633253047592e-05\n",
      "Epoch 4669, Loss: 0.001147457040133304, Final Batch Loss: 4.5928763938718475e-06\n",
      "Epoch 4670, Loss: 0.0036988596687024256, Final Batch Loss: 0.0010808618972077966\n",
      "Epoch 4671, Loss: 0.0015317393018392522, Final Batch Loss: 6.198552728164941e-05\n",
      "Epoch 4672, Loss: 0.001055105439036197, Final Batch Loss: 2.4406554075540043e-05\n",
      "Epoch 4673, Loss: 0.02126617976352918, Final Batch Loss: 0.001223105238750577\n",
      "Epoch 4674, Loss: 0.00912903041376012, Final Batch Loss: 4.218070171191357e-05\n",
      "Epoch 4675, Loss: 0.017734555980496225, Final Batch Loss: 0.00011677206930471584\n",
      "Epoch 4676, Loss: 0.0019862408271364984, Final Batch Loss: 0.001003608456812799\n",
      "Epoch 4677, Loss: 0.0033969799915212207, Final Batch Loss: 0.000702719553373754\n",
      "Epoch 4678, Loss: 0.028204691531527715, Final Batch Loss: 2.0384146409924142e-05\n",
      "Epoch 4679, Loss: 0.0030586843356559257, Final Batch Loss: 3.802546643782989e-06\n",
      "Epoch 4680, Loss: 0.001623729750917846, Final Batch Loss: 3.6734068089572247e-06\n",
      "Epoch 4681, Loss: 0.0009138215658595072, Final Batch Loss: 5.048639650340192e-05\n",
      "Epoch 4682, Loss: 0.0004678006214930974, Final Batch Loss: 0.0001644237490836531\n",
      "Epoch 4683, Loss: 0.0007964703059997191, Final Batch Loss: 2.9808803446940146e-05\n",
      "Epoch 4684, Loss: 0.01570651137205914, Final Batch Loss: 8.516882189724129e-06\n",
      "Epoch 4685, Loss: 0.0015478048463819505, Final Batch Loss: 5.7464705605525523e-05\n",
      "Epoch 4686, Loss: 0.001600652045112838, Final Batch Loss: 5.691766546078725e-06\n",
      "Epoch 4687, Loss: 0.0020785277336017316, Final Batch Loss: 2.9116927180439234e-06\n",
      "Epoch 4688, Loss: 0.0004486944485506683, Final Batch Loss: 1.9018732928088866e-05\n",
      "Epoch 4689, Loss: 0.0021471848835972196, Final Batch Loss: 4.479015387914842e-06\n",
      "Epoch 4690, Loss: 0.002626681799938524, Final Batch Loss: 0.002236147876828909\n",
      "Epoch 4691, Loss: 0.0017324854762250652, Final Batch Loss: 3.1231375032803044e-06\n",
      "Epoch 4692, Loss: 0.0026233050089103926, Final Batch Loss: 1.1222646207897924e-06\n",
      "Epoch 4693, Loss: 0.000326996594310458, Final Batch Loss: 9.292365575674921e-06\n",
      "Epoch 4694, Loss: 0.00023729977363018406, Final Batch Loss: 9.8282753242529e-06\n",
      "Epoch 4695, Loss: 0.0004445240562063191, Final Batch Loss: 4.120094672543928e-05\n",
      "Epoch 4696, Loss: 0.00013112993281083618, Final Batch Loss: 5.982905349810608e-06\n",
      "Epoch 4697, Loss: 0.0015591486414336941, Final Batch Loss: 1.8477749108569697e-05\n",
      "Epoch 4698, Loss: 0.00033599512966020484, Final Batch Loss: 6.205354452504253e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4699, Loss: 0.000536087342254632, Final Batch Loss: 1.6390340533689596e-05\n",
      "Epoch 4700, Loss: 0.009749503842272134, Final Batch Loss: 0.0005533194052986801\n",
      "Epoch 4701, Loss: 0.012150688625524708, Final Batch Loss: 2.2585886654269416e-06\n",
      "Epoch 4702, Loss: 0.008442863045274862, Final Batch Loss: 7.939853094285354e-05\n",
      "Epoch 4703, Loss: 0.00404770075124361, Final Batch Loss: 0.0002442715922370553\n",
      "Epoch 4704, Loss: 0.0011113075032653796, Final Batch Loss: 3.7124766095075756e-05\n",
      "Epoch 4705, Loss: 0.005428329770097662, Final Batch Loss: 1.5970308595569804e-05\n",
      "Epoch 4706, Loss: 0.0007768368162146544, Final Batch Loss: 1.1838121281471103e-05\n",
      "Epoch 4707, Loss: 0.0016489311601617374, Final Batch Loss: 1.211514972965233e-05\n",
      "Epoch 4708, Loss: 0.03885886678213524, Final Batch Loss: 7.770645606797189e-05\n",
      "Epoch 4709, Loss: 0.0027120424733766413, Final Batch Loss: 7.99174522398971e-05\n",
      "Epoch 4710, Loss: 0.0011673267747482896, Final Batch Loss: 1.621359115233645e-05\n",
      "Epoch 4711, Loss: 0.0016697654668860196, Final Batch Loss: 7.592391739308368e-06\n",
      "Epoch 4712, Loss: 0.006474756777606672, Final Batch Loss: 1.5494642866542563e-05\n",
      "Epoch 4713, Loss: 0.0019735724201837, Final Batch Loss: 6.397708602889907e-07\n",
      "Epoch 4714, Loss: 0.011517586825789294, Final Batch Loss: 2.7044914077123394e-06\n",
      "Epoch 4715, Loss: 0.0036469807369030605, Final Batch Loss: 0.0003003693709615618\n",
      "Epoch 4716, Loss: 0.0022402224964253037, Final Batch Loss: 8.114915544865653e-06\n",
      "Epoch 4717, Loss: 0.002750346649918356, Final Batch Loss: 4.660963895730674e-05\n",
      "Epoch 4718, Loss: 0.00743461949241464, Final Batch Loss: 0.0008379805949516594\n",
      "Epoch 4719, Loss: 0.0016704154407989336, Final Batch Loss: 0.00106077641248703\n",
      "Epoch 4720, Loss: 0.0006837048594547923, Final Batch Loss: 2.656274773471523e-05\n",
      "Epoch 4721, Loss: 0.002073187838618651, Final Batch Loss: 5.524940661416622e-06\n",
      "Epoch 4722, Loss: 0.013548831078423973, Final Batch Loss: 6.423955346690491e-05\n",
      "Epoch 4723, Loss: 0.008681371957095507, Final Batch Loss: 6.28505804343149e-05\n",
      "Epoch 4724, Loss: 0.0014283408638391393, Final Batch Loss: 2.183093101848499e-06\n",
      "Epoch 4725, Loss: 0.001467668397253874, Final Batch Loss: 0.00012739450903609395\n",
      "Epoch 4726, Loss: 0.0012320166072186112, Final Batch Loss: 4.094587893632706e-06\n",
      "Epoch 4727, Loss: 0.006925326795226283, Final Batch Loss: 0.006425242871046066\n",
      "Epoch 4728, Loss: 0.014881116033620856, Final Batch Loss: 9.30831884033978e-05\n",
      "Epoch 4729, Loss: 0.1462732876834707, Final Batch Loss: 7.777615792292636e-06\n",
      "Epoch 4730, Loss: 0.05085707346597701, Final Batch Loss: 5.594051617663354e-05\n",
      "Epoch 4731, Loss: 0.006807591480935571, Final Batch Loss: 0.003235784126445651\n",
      "Epoch 4732, Loss: 0.011194465527182729, Final Batch Loss: 1.5637264368706383e-05\n",
      "Epoch 4733, Loss: 0.0020060752242443414, Final Batch Loss: 0.00023933911870699376\n",
      "Epoch 4734, Loss: 0.003147356726003636, Final Batch Loss: 2.5051460397662595e-05\n",
      "Epoch 4735, Loss: 0.02863523494625042, Final Batch Loss: 3.891113465215312e-06\n",
      "Epoch 4736, Loss: 0.013059910877700531, Final Batch Loss: 1.2862523362855427e-05\n",
      "Epoch 4737, Loss: 0.011879544741987047, Final Batch Loss: 4.105302195966942e-06\n",
      "Epoch 4738, Loss: 0.003444022703661176, Final Batch Loss: 3.737089718924835e-05\n",
      "Epoch 4739, Loss: 0.022901996780774425, Final Batch Loss: 5.629526640404947e-05\n",
      "Epoch 4740, Loss: 0.004722862753624213, Final Batch Loss: 3.1090909033082426e-05\n",
      "Epoch 4741, Loss: 0.008438732547347172, Final Batch Loss: 2.4056157599261496e-06\n",
      "Epoch 4742, Loss: 0.001151807045971509, Final Batch Loss: 2.9511853426811285e-05\n",
      "Epoch 4743, Loss: 0.0014764613752049627, Final Batch Loss: 5.033661363995634e-05\n",
      "Epoch 4744, Loss: 0.0037702096394696127, Final Batch Loss: 0.00039759898209013045\n",
      "Epoch 4745, Loss: 0.0017942196877811512, Final Batch Loss: 1.7337752069579437e-05\n",
      "Epoch 4746, Loss: 0.007313396337849554, Final Batch Loss: 2.973158007080201e-05\n",
      "Epoch 4747, Loss: 0.0036265824446672923, Final Batch Loss: 7.264300074893981e-05\n",
      "Epoch 4748, Loss: 0.0032560346164700604, Final Batch Loss: 6.0868991567986086e-05\n",
      "Epoch 4749, Loss: 0.0034972601133631542, Final Batch Loss: 7.09957821527496e-05\n",
      "Epoch 4750, Loss: 0.006963796462969185, Final Batch Loss: 7.225760055007413e-05\n",
      "Epoch 4751, Loss: 0.0020620067361960537, Final Batch Loss: 0.00021853034559171647\n",
      "Epoch 4752, Loss: 0.0026527972522671917, Final Batch Loss: 0.0009950598469004035\n",
      "Epoch 4753, Loss: 0.005704813737793302, Final Batch Loss: 0.0004866081872023642\n",
      "Epoch 4754, Loss: 0.004731848199241995, Final Batch Loss: 0.0026858660858124495\n",
      "Epoch 4755, Loss: 0.0017235450004591257, Final Batch Loss: 3.3927590266102925e-06\n",
      "Epoch 4756, Loss: 0.0028542304436314225, Final Batch Loss: 0.00020834860333707184\n",
      "Epoch 4757, Loss: 0.0014176508002492483, Final Batch Loss: 1.0309051504009403e-05\n",
      "Epoch 4758, Loss: 0.001297845312365098, Final Batch Loss: 5.7383576859137975e-06\n",
      "Epoch 4759, Loss: 0.0011748509268727503, Final Batch Loss: 3.457272032392211e-05\n",
      "Epoch 4760, Loss: 0.0035618326769508712, Final Batch Loss: 7.916580216260627e-06\n",
      "Epoch 4761, Loss: 0.0015326790457947936, Final Batch Loss: 0.00034055145806632936\n",
      "Epoch 4762, Loss: 0.001528520395538635, Final Batch Loss: 4.281259862182196e-06\n",
      "Epoch 4763, Loss: 0.0004993920655351758, Final Batch Loss: 5.204078206588747e-06\n",
      "Epoch 4764, Loss: 0.00033137642273572965, Final Batch Loss: 4.3257496145088226e-06\n",
      "Epoch 4765, Loss: 0.0014140890281879592, Final Batch Loss: 6.143427162896842e-05\n",
      "Epoch 4766, Loss: 0.007692184390975854, Final Batch Loss: 2.2220544906303985e-06\n",
      "Epoch 4767, Loss: 0.004303333101461249, Final Batch Loss: 4.857138264924288e-06\n",
      "Epoch 4768, Loss: 0.00023733214311505435, Final Batch Loss: 4.561515015666373e-05\n",
      "Epoch 4769, Loss: 0.005888179777230107, Final Batch Loss: 0.00010195704089710489\n",
      "Epoch 4770, Loss: 0.0013351416281892625, Final Batch Loss: 4.2676678276620805e-05\n",
      "Epoch 4771, Loss: 0.029833047756255837, Final Batch Loss: 6.300584936980158e-05\n",
      "Epoch 4772, Loss: 0.005775018646318131, Final Batch Loss: 2.781039484034409e-06\n",
      "Epoch 4773, Loss: 0.052860023768630526, Final Batch Loss: 0.00020782680076081306\n",
      "Epoch 4774, Loss: 0.0020587837593666336, Final Batch Loss: 0.00038857542676851153\n",
      "Epoch 4775, Loss: 0.0018506346493722958, Final Batch Loss: 3.32178569806274e-05\n",
      "Epoch 4776, Loss: 0.0007349300112764467, Final Batch Loss: 3.621036375989206e-05\n",
      "Epoch 4777, Loss: 0.0014735713475602097, Final Batch Loss: 1.98393299797317e-05\n",
      "Epoch 4778, Loss: 0.003422476900595939, Final Batch Loss: 9.127128578256816e-06\n",
      "Epoch 4779, Loss: 0.0007731438518021605, Final Batch Loss: 2.4210976334870793e-05\n",
      "Epoch 4780, Loss: 0.03279887530425185, Final Batch Loss: 3.313504203106277e-05\n",
      "Epoch 4781, Loss: 0.02088093570455385, Final Batch Loss: 8.347310540557373e-06\n",
      "Epoch 4782, Loss: 0.011344106159413059, Final Batch Loss: 9.431142643734347e-06\n",
      "Epoch 4783, Loss: 0.005254894369159047, Final Batch Loss: 0.002708583604544401\n",
      "Epoch 4784, Loss: 0.0034439199500582163, Final Batch Loss: 0.0001628813915885985\n",
      "Epoch 4785, Loss: 0.0016422714268173877, Final Batch Loss: 9.803630382521078e-05\n",
      "Epoch 4786, Loss: 0.0011906065907396624, Final Batch Loss: 3.4004409826593474e-05\n",
      "Epoch 4787, Loss: 0.008099374385380997, Final Batch Loss: 0.0001388873060932383\n",
      "Epoch 4788, Loss: 0.002641283635966829, Final Batch Loss: 0.00012977405276615173\n",
      "Epoch 4789, Loss: 0.001147805520986367, Final Batch Loss: 1.643801442696713e-05\n",
      "Epoch 4790, Loss: 0.000766216162787714, Final Batch Loss: 4.68092730443459e-06\n",
      "Epoch 4791, Loss: 0.0009302822367942554, Final Batch Loss: 3.15487386615132e-06\n",
      "Epoch 4792, Loss: 0.0006591979511227919, Final Batch Loss: 6.916096481290879e-06\n",
      "Epoch 4793, Loss: 0.003909775502393131, Final Batch Loss: 2.5382132662343793e-05\n",
      "Epoch 4794, Loss: 0.004551335338874196, Final Batch Loss: 0.003585421247407794\n",
      "Epoch 4795, Loss: 0.007112296352318026, Final Batch Loss: 4.729791385216231e-07\n",
      "Epoch 4796, Loss: 0.005956262070213825, Final Batch Loss: 3.3170535971294157e-06\n",
      "Epoch 4797, Loss: 0.005543388626620072, Final Batch Loss: 0.00043800679850392044\n",
      "Epoch 4798, Loss: 0.007075558858559816, Final Batch Loss: 4.6078905143076554e-05\n",
      "Epoch 4799, Loss: 0.0011935912982607988, Final Batch Loss: 3.741419277503155e-05\n",
      "Epoch 4800, Loss: 0.017327773847682693, Final Batch Loss: 2.5920578991645016e-05\n",
      "Epoch 4801, Loss: 0.0005423212191999482, Final Batch Loss: 2.327046968275681e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4802, Loss: 0.0013804680935436409, Final Batch Loss: 2.9613498554681428e-05\n",
      "Epoch 4803, Loss: 0.0003964924205774878, Final Batch Loss: 1.4845912119199056e-05\n",
      "Epoch 4804, Loss: 0.0007444023551670398, Final Batch Loss: 9.055657983481069e-07\n",
      "Epoch 4805, Loss: 0.0006621156633173086, Final Batch Loss: 7.48401816963451e-07\n",
      "Epoch 4806, Loss: 0.0008422777317491636, Final Batch Loss: 4.592840559780598e-05\n",
      "Epoch 4807, Loss: 0.000502171703857357, Final Batch Loss: 1.7817473008108209e-06\n",
      "Epoch 4808, Loss: 0.00030305435689115257, Final Batch Loss: 1.712834091449622e-05\n",
      "Epoch 4809, Loss: 0.0004524608504539174, Final Batch Loss: 1.1338486274325987e-06\n",
      "Epoch 4810, Loss: 0.002092068137358183, Final Batch Loss: 2.45949013333302e-06\n",
      "Epoch 4811, Loss: 0.0003273898011855181, Final Batch Loss: 1.1150597856612876e-05\n",
      "Epoch 4812, Loss: 0.0013351834983268418, Final Batch Loss: 4.8416263780382e-06\n",
      "Epoch 4813, Loss: 0.001933526936340968, Final Batch Loss: 2.8039525204803795e-05\n",
      "Epoch 4814, Loss: 0.0002471165055339952, Final Batch Loss: 1.2276583220227621e-05\n",
      "Epoch 4815, Loss: 0.0068723945308875045, Final Batch Loss: 0.00027061314904130995\n",
      "Epoch 4816, Loss: 0.0009192419490418047, Final Batch Loss: 1.4179403251546319e-06\n",
      "Epoch 4817, Loss: 0.02205982987874222, Final Batch Loss: 2.4128454242600128e-05\n",
      "Epoch 4818, Loss: 0.002650312490231954, Final Batch Loss: 3.997980820713565e-05\n",
      "Epoch 4819, Loss: 0.0009014639530278146, Final Batch Loss: 8.1336129369447e-06\n",
      "Epoch 4820, Loss: 0.00030260641045742886, Final Batch Loss: 2.3663938918616623e-05\n",
      "Epoch 4821, Loss: 0.007012953616595041, Final Batch Loss: 9.081507596420124e-05\n",
      "Epoch 4822, Loss: 0.000650580957881175, Final Batch Loss: 4.348677248344757e-05\n",
      "Epoch 4823, Loss: 0.01175844469958065, Final Batch Loss: 9.017250704346225e-06\n",
      "Epoch 4824, Loss: 0.018669958569802247, Final Batch Loss: 1.9461911051621428e-06\n",
      "Epoch 4825, Loss: 0.0019890300900442526, Final Batch Loss: 4.594268375512911e-06\n",
      "Epoch 4826, Loss: 0.015240326627917966, Final Batch Loss: 3.2759850000729784e-05\n",
      "Epoch 4827, Loss: 0.0017986762034070125, Final Batch Loss: 0.00010203334386460483\n",
      "Epoch 4828, Loss: 0.006712976061407971, Final Batch Loss: 0.002705206163227558\n",
      "Epoch 4829, Loss: 0.00021033087205069023, Final Batch Loss: 9.520902494841721e-06\n",
      "Epoch 4830, Loss: 0.0005160695838526408, Final Batch Loss: 6.166419916553423e-05\n",
      "Epoch 4831, Loss: 0.010527548107463147, Final Batch Loss: 0.010383350774645805\n",
      "Epoch 4832, Loss: 0.020424522173925652, Final Batch Loss: 3.570969420252368e-05\n",
      "Epoch 4833, Loss: 0.0036349704546410067, Final Batch Loss: 1.2570841136039235e-05\n",
      "Epoch 4834, Loss: 0.0019569495414941684, Final Batch Loss: 2.49746171903098e-05\n",
      "Epoch 4835, Loss: 0.0022553729374976683, Final Batch Loss: 0.00011918444943148643\n",
      "Epoch 4836, Loss: 0.004626375955467665, Final Batch Loss: 1.6050207705120556e-05\n",
      "Epoch 4837, Loss: 0.008487787775266042, Final Batch Loss: 1.0067340554087423e-05\n",
      "Epoch 4838, Loss: 0.0015595478971590637, Final Batch Loss: 2.098605182254687e-05\n",
      "Epoch 4839, Loss: 0.004337832860869639, Final Batch Loss: 2.9307560907909647e-05\n",
      "Epoch 4840, Loss: 0.18674472326719638, Final Batch Loss: 3.0162687835399993e-05\n",
      "Epoch 4841, Loss: 0.001471005361963762, Final Batch Loss: 1.4000333067087922e-05\n",
      "Epoch 4842, Loss: 0.0022333394317683997, Final Batch Loss: 7.807285874150693e-05\n",
      "Epoch 4843, Loss: 0.0007335641657846281, Final Batch Loss: 0.0002026452129939571\n",
      "Epoch 4844, Loss: 0.0006400455717994191, Final Batch Loss: 2.4756551283644512e-05\n",
      "Epoch 4845, Loss: 0.0015907434280961752, Final Batch Loss: 0.0002047489397227764\n",
      "Epoch 4846, Loss: 0.0008297380227304529, Final Batch Loss: 8.130728383548558e-05\n",
      "Epoch 4847, Loss: 0.0009924644883767542, Final Batch Loss: 2.637519355630502e-05\n",
      "Epoch 4848, Loss: 0.0010454054512933908, Final Batch Loss: 0.0003481740423012525\n",
      "Epoch 4849, Loss: 0.0006863554433493846, Final Batch Loss: 5.280516234051902e-06\n",
      "Epoch 4850, Loss: 0.0006169146490719868, Final Batch Loss: 8.4977327787783e-06\n",
      "Epoch 4851, Loss: 0.003743576780834701, Final Batch Loss: 9.210898497258313e-06\n",
      "Epoch 4852, Loss: 0.035439858556912895, Final Batch Loss: 1.477705063734902e-05\n",
      "Epoch 4853, Loss: 0.018423086800453348, Final Batch Loss: 0.001000728807412088\n",
      "Epoch 4854, Loss: 0.053143707820709096, Final Batch Loss: 0.0011181874433532357\n",
      "Epoch 4855, Loss: 0.1130872508936136, Final Batch Loss: 0.00015086344501469284\n",
      "Epoch 4856, Loss: 0.05257886913614129, Final Batch Loss: 0.0005231915274634957\n",
      "Epoch 4857, Loss: 0.026890202118011075, Final Batch Loss: 2.4103193936753087e-05\n",
      "Epoch 4858, Loss: 0.03683670552095464, Final Batch Loss: 9.948794286174234e-06\n",
      "Epoch 4859, Loss: 0.011575346757126681, Final Batch Loss: 0.0008076816448010504\n",
      "Epoch 4860, Loss: 0.024114392243518523, Final Batch Loss: 6.913226116012083e-06\n",
      "Epoch 4861, Loss: 0.01881149596238174, Final Batch Loss: 9.669365681475028e-05\n",
      "Epoch 4862, Loss: 0.0032788717362564057, Final Batch Loss: 2.5899124011630192e-05\n",
      "Epoch 4863, Loss: 0.004201506043500558, Final Batch Loss: 0.0001278879353776574\n",
      "Epoch 4864, Loss: 0.015934747407300165, Final Batch Loss: 7.54121138015762e-05\n",
      "Epoch 4865, Loss: 0.00837670548571623, Final Batch Loss: 6.8954388552811e-05\n",
      "Epoch 4866, Loss: 0.001709192966700357, Final Batch Loss: 0.0001187447487609461\n",
      "Epoch 4867, Loss: 0.0019107501700545981, Final Batch Loss: 0.00011736989108612761\n",
      "Epoch 4868, Loss: 0.0009760973398442729, Final Batch Loss: 2.1214602384134196e-05\n",
      "Epoch 4869, Loss: 0.002068735230295715, Final Batch Loss: 2.812035927490797e-05\n",
      "Epoch 4870, Loss: 0.001119269708055981, Final Batch Loss: 7.241557614179328e-05\n",
      "Epoch 4871, Loss: 0.0008897616426111199, Final Batch Loss: 7.370615549007198e-06\n",
      "Epoch 4872, Loss: 0.007025784602092244, Final Batch Loss: 2.657982986420393e-05\n",
      "Epoch 4873, Loss: 0.0008909467319426767, Final Batch Loss: 0.0001701996079646051\n",
      "Epoch 4874, Loss: 0.0023709992947260616, Final Batch Loss: 0.0008716724696569145\n",
      "Epoch 4875, Loss: 0.015404513004796172, Final Batch Loss: 2.2554080715053715e-05\n",
      "Epoch 4876, Loss: 0.0064850714866224735, Final Batch Loss: 0.0011166480835527182\n",
      "Epoch 4877, Loss: 0.001568985668654932, Final Batch Loss: 4.430173430591822e-05\n",
      "Epoch 4878, Loss: 0.00501666645413934, Final Batch Loss: 0.0005060074618086219\n",
      "Epoch 4879, Loss: 0.01219112598312222, Final Batch Loss: 1.1945746337005403e-05\n",
      "Epoch 4880, Loss: 0.0031384775447804714, Final Batch Loss: 3.8478043279610574e-05\n",
      "Epoch 4881, Loss: 0.0070725989526181365, Final Batch Loss: 1.6886335288290866e-05\n",
      "Epoch 4882, Loss: 0.004444386075192597, Final Batch Loss: 1.4664439731859602e-05\n",
      "Epoch 4883, Loss: 0.0024888072207431833, Final Batch Loss: 4.845753210247494e-05\n",
      "Epoch 4884, Loss: 0.015565216608592891, Final Batch Loss: 1.6467627574456856e-05\n",
      "Epoch 4885, Loss: 0.004822596385565703, Final Batch Loss: 0.0005005317507311702\n",
      "Epoch 4886, Loss: 0.0011574515747270198, Final Batch Loss: 3.5090200981358066e-05\n",
      "Epoch 4887, Loss: 0.007769889807605068, Final Batch Loss: 0.0001829485991038382\n",
      "Epoch 4888, Loss: 0.004706906758428886, Final Batch Loss: 2.3953765776241198e-05\n",
      "Epoch 4889, Loss: 0.006728777869057012, Final Batch Loss: 3.781174882533378e-06\n",
      "Epoch 4890, Loss: 0.0015773039116311338, Final Batch Loss: 8.029139280552045e-05\n",
      "Epoch 4891, Loss: 0.0007559700436843286, Final Batch Loss: 1.7988295439863577e-05\n",
      "Epoch 4892, Loss: 0.00040339447920700877, Final Batch Loss: 1.5797735613887198e-05\n",
      "Epoch 4893, Loss: 0.0002014009825188623, Final Batch Loss: 1.1463175724202301e-06\n",
      "Epoch 4894, Loss: 0.001753948205589495, Final Batch Loss: 4.04728198191151e-05\n",
      "Epoch 4895, Loss: 0.03491879129916242, Final Batch Loss: 2.3965762011357583e-05\n",
      "Epoch 4896, Loss: 0.002923035940511909, Final Batch Loss: 5.0409394134476315e-06\n",
      "Epoch 4897, Loss: 0.009358248282069326, Final Batch Loss: 0.0001010225314530544\n",
      "Epoch 4898, Loss: 0.0015127943129300547, Final Batch Loss: 7.849273060855921e-06\n",
      "Epoch 4899, Loss: 0.0011037613111284372, Final Batch Loss: 0.0001560501113999635\n",
      "Epoch 4900, Loss: 0.004961464427651663, Final Batch Loss: 9.273599061998539e-06\n",
      "Epoch 4901, Loss: 0.000401603574573528, Final Batch Loss: 0.00010239609400741756\n",
      "Epoch 4902, Loss: 0.0013969656627068616, Final Batch Loss: 1.9657358279800974e-05\n",
      "Epoch 4903, Loss: 0.0006654006106145971, Final Batch Loss: 1.1430443919380195e-05\n",
      "Epoch 4904, Loss: 0.0007533460963031757, Final Batch Loss: 3.253906106692739e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4905, Loss: 0.0005824160913334708, Final Batch Loss: 2.430165523037431e-06\n",
      "Epoch 4906, Loss: 0.0005010670393517103, Final Batch Loss: 6.43242965452373e-05\n",
      "Epoch 4907, Loss: 0.0006312166165827193, Final Batch Loss: 2.1371320144680794e-06\n",
      "Epoch 4908, Loss: 0.0013301402759111625, Final Batch Loss: 1.6851154214236885e-05\n",
      "Epoch 4909, Loss: 0.0029407784236994416, Final Batch Loss: 0.0001833117421483621\n",
      "Epoch 4910, Loss: 0.0006851934156770767, Final Batch Loss: 1.1824029570561834e-05\n",
      "Epoch 4911, Loss: 0.0018505644824813317, Final Batch Loss: 2.2661317416350357e-05\n",
      "Epoch 4912, Loss: 0.0009510568527559826, Final Batch Loss: 8.891574907465838e-06\n",
      "Epoch 4913, Loss: 0.0018084703867202734, Final Batch Loss: 9.107306141231675e-06\n",
      "Epoch 4914, Loss: 0.0014229390736772984, Final Batch Loss: 1.4655242921435274e-06\n",
      "Epoch 4915, Loss: 0.001150818642372542, Final Batch Loss: 1.6755344404373318e-05\n",
      "Epoch 4916, Loss: 0.0002700047939470096, Final Batch Loss: 4.4108346628490835e-06\n",
      "Epoch 4917, Loss: 0.00028346837376602707, Final Batch Loss: 1.2432320545485709e-05\n",
      "Epoch 4918, Loss: 0.00024837886280693056, Final Batch Loss: 4.8755206080386415e-05\n",
      "Epoch 4919, Loss: 0.0005626033671575215, Final Batch Loss: 1.4245360034692567e-05\n",
      "Epoch 4920, Loss: 0.00033006952014602575, Final Batch Loss: 2.8245844987395685e-06\n",
      "Epoch 4921, Loss: 0.00040523839919615057, Final Batch Loss: 1.4759912119188812e-06\n",
      "Epoch 4922, Loss: 0.0005553249650915859, Final Batch Loss: 3.4855031572078587e-06\n",
      "Epoch 4923, Loss: 0.0004464554733658588, Final Batch Loss: 6.594673891413549e-07\n",
      "Epoch 4924, Loss: 0.0006247071958682682, Final Batch Loss: 4.427029978160135e-07\n",
      "Epoch 4925, Loss: 0.0016389742690421372, Final Batch Loss: 2.347048393858131e-06\n",
      "Epoch 4926, Loss: 0.011700626519200341, Final Batch Loss: 5.193897322897101e-06\n",
      "Epoch 4927, Loss: 0.007762416478954037, Final Batch Loss: 8.584542570133635e-07\n",
      "Epoch 4928, Loss: 0.001788980509729754, Final Batch Loss: 8.807278936728835e-05\n",
      "Epoch 4929, Loss: 0.000724016290689633, Final Batch Loss: 1.3731282706430648e-05\n",
      "Epoch 4930, Loss: 0.0016026801601185525, Final Batch Loss: 1.0719839337980375e-05\n",
      "Epoch 4931, Loss: 0.002142344379876704, Final Batch Loss: 0.0015622611390426755\n",
      "Epoch 4932, Loss: 0.0011374757463329388, Final Batch Loss: 4.2804131226148456e-05\n",
      "Epoch 4933, Loss: 0.005024843232092735, Final Batch Loss: 4.749733761855168e-06\n",
      "Epoch 4934, Loss: 0.0001895394767501557, Final Batch Loss: 7.115156222425867e-06\n",
      "Epoch 4935, Loss: 0.004310909214133574, Final Batch Loss: 6.885595212224871e-05\n",
      "Epoch 4936, Loss: 0.002550997667640331, Final Batch Loss: 3.4118293115170673e-06\n",
      "Epoch 4937, Loss: 0.017838788499830116, Final Batch Loss: 7.491698488593102e-05\n",
      "Epoch 4938, Loss: 0.004363305962101549, Final Batch Loss: 3.2521977573196637e-06\n",
      "Epoch 4939, Loss: 0.01693210798111977, Final Batch Loss: 0.0028967345133423805\n",
      "Epoch 4940, Loss: 0.002849923889925776, Final Batch Loss: 2.1704820028389804e-05\n",
      "Epoch 4941, Loss: 0.003968929741859029, Final Batch Loss: 4.6917280087654945e-06\n",
      "Epoch 4942, Loss: 0.008398528748500667, Final Batch Loss: 0.00010396636207588017\n",
      "Epoch 4943, Loss: 0.00115853695763235, Final Batch Loss: 9.714383850223385e-06\n",
      "Epoch 4944, Loss: 0.00035515459236989955, Final Batch Loss: 5.550732112169499e-06\n",
      "Epoch 4945, Loss: 0.00130594233166903, Final Batch Loss: 0.0004546903073787689\n",
      "Epoch 4946, Loss: 0.0008050114274738007, Final Batch Loss: 1.4121590083959745e-06\n",
      "Epoch 4947, Loss: 0.0011153118501852077, Final Batch Loss: 0.001029323204420507\n",
      "Epoch 4948, Loss: 0.0005890846319971388, Final Batch Loss: 0.00012002496077911928\n",
      "Epoch 4949, Loss: 0.010639148669326914, Final Batch Loss: 8.711647751624696e-06\n",
      "Epoch 4950, Loss: 0.0021420233726985316, Final Batch Loss: 4.825787073059473e-06\n",
      "Epoch 4951, Loss: 0.0005182536272059224, Final Batch Loss: 5.881946890440304e-06\n",
      "Epoch 4952, Loss: 0.0006008718783050426, Final Batch Loss: 4.555348277790472e-05\n",
      "Epoch 4953, Loss: 0.001011031764960535, Final Batch Loss: 0.00019162913667969406\n",
      "Epoch 4954, Loss: 0.0003608270369568345, Final Batch Loss: 0.00023259139561560005\n",
      "Epoch 4955, Loss: 0.00038844665030524084, Final Batch Loss: 2.0525050103969988e-07\n",
      "Epoch 4956, Loss: 0.0013114277269323793, Final Batch Loss: 2.5804924916883465e-06\n",
      "Epoch 4957, Loss: 0.00019279562539509243, Final Batch Loss: 1.3675428817805368e-05\n",
      "Epoch 4958, Loss: 0.0019434325899396754, Final Batch Loss: 3.4945256288665405e-07\n",
      "Epoch 4959, Loss: 0.0005260268226265907, Final Batch Loss: 6.870391644042684e-06\n",
      "Epoch 4960, Loss: 0.0022568648171841232, Final Batch Loss: 6.633204520767322e-06\n",
      "Epoch 4961, Loss: 0.0001377520096639273, Final Batch Loss: 1.4645451074102311e-06\n",
      "Epoch 4962, Loss: 0.00287274489619449, Final Batch Loss: 1.0801560165418778e-05\n",
      "Epoch 4963, Loss: 0.0470483497473424, Final Batch Loss: 9.551034054311458e-06\n",
      "Epoch 4964, Loss: 0.000519331386669819, Final Batch Loss: 4.7556168283335865e-05\n",
      "Epoch 4965, Loss: 0.010932372352755237, Final Batch Loss: 9.979214155464433e-06\n",
      "Epoch 4966, Loss: 0.00032564022239967017, Final Batch Loss: 3.8308906368911266e-05\n",
      "Epoch 4967, Loss: 0.0006512745611644277, Final Batch Loss: 2.3282002530322643e-06\n",
      "Epoch 4968, Loss: 0.0013946341036898957, Final Batch Loss: 3.256986747146584e-05\n",
      "Epoch 4969, Loss: 0.008148427586633034, Final Batch Loss: 1.182345840788912e-06\n",
      "Epoch 4970, Loss: 0.05961794419954458, Final Batch Loss: 0.024639086797833443\n",
      "Epoch 4971, Loss: 0.000734345172368478, Final Batch Loss: 0.00011656217247946188\n",
      "Epoch 4972, Loss: 0.0005195637026531585, Final Batch Loss: 9.100700117414817e-05\n",
      "Epoch 4973, Loss: 0.0186574011427183, Final Batch Loss: 0.004623865243047476\n",
      "Epoch 4974, Loss: 0.0796249036586687, Final Batch Loss: 0.00033082341542467475\n",
      "Epoch 4975, Loss: 0.06075669662823202, Final Batch Loss: 0.00015760371752548963\n",
      "Epoch 4976, Loss: 0.034830031454248456, Final Batch Loss: 0.00022495625307783484\n",
      "Epoch 4977, Loss: 0.010099233251821715, Final Batch Loss: 0.004557057283818722\n",
      "Epoch 4978, Loss: 0.005853370726981666, Final Batch Loss: 8.330573109560646e-06\n",
      "Epoch 4979, Loss: 0.011797475054663664, Final Batch Loss: 0.0038143289275467396\n",
      "Epoch 4980, Loss: 0.012025736422742739, Final Batch Loss: 3.155237209284678e-05\n",
      "Epoch 4981, Loss: 0.005706685116365406, Final Batch Loss: 0.0021111241076141596\n",
      "Epoch 4982, Loss: 0.01565500095580319, Final Batch Loss: 9.92147579381708e-06\n",
      "Epoch 4983, Loss: 0.004417384750922793, Final Batch Loss: 3.898156137438491e-05\n",
      "Epoch 4984, Loss: 0.001184544963962253, Final Batch Loss: 7.486637059628265e-06\n",
      "Epoch 4985, Loss: 0.0007830122617633606, Final Batch Loss: 1.553801484988071e-05\n",
      "Epoch 4986, Loss: 0.001160499465072462, Final Batch Loss: 9.079412848223001e-05\n",
      "Epoch 4987, Loss: 0.0009177262721777879, Final Batch Loss: 3.0996416171547025e-05\n",
      "Epoch 4988, Loss: 0.002075626848295542, Final Batch Loss: 3.756205478566699e-05\n",
      "Epoch 4989, Loss: 0.0009249206647155006, Final Batch Loss: 5.417210786617943e-07\n",
      "Epoch 4990, Loss: 0.02085286612236814, Final Batch Loss: 3.808926703641191e-05\n",
      "Epoch 4991, Loss: 0.008339400352838311, Final Batch Loss: 1.6307224086631322e-06\n",
      "Epoch 4992, Loss: 0.01600834722376021, Final Batch Loss: 0.00011989776976406574\n",
      "Epoch 4993, Loss: 0.006400525684512104, Final Batch Loss: 0.0004444692749530077\n",
      "Epoch 4994, Loss: 0.025057668222416396, Final Batch Loss: 4.103900209884159e-05\n",
      "Epoch 4995, Loss: 0.014413642980287023, Final Batch Loss: 1.3964038771518972e-05\n",
      "Epoch 4996, Loss: 0.0017894235825792748, Final Batch Loss: 0.00014433040632866323\n",
      "Epoch 4997, Loss: 0.009777838623904245, Final Batch Loss: 7.634503162989859e-06\n",
      "Epoch 4998, Loss: 0.006346048195325693, Final Batch Loss: 0.0014042595867067575\n",
      "Epoch 4999, Loss: 0.001692229480795504, Final Batch Loss: 0.0003174282028339803\n",
      "Epoch 5000, Loss: 0.00742973857211382, Final Batch Loss: 1.0233995453745592e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[488   8   0]\n",
      " [ 11 409   0]\n",
      " [  0   0 491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.984     0.981       496\n",
      "           1      0.981     0.974     0.977       420\n",
      "           2      1.000     1.000     1.000       491\n",
      "\n",
      "    accuracy                          0.986      1407\n",
      "   macro avg      0.986     0.986     0.986      1407\n",
      "weighted avg      0.987     0.986     0.986      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../saved_models/UCI 3 Label Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
