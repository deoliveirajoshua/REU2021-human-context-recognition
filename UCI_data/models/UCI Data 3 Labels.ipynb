{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 tBodyAcc-mean()-X</th>\n",
       "      <th>2 tBodyAcc-mean()-Y</th>\n",
       "      <th>3 tBodyAcc-mean()-Z</th>\n",
       "      <th>4 tBodyAcc-std()-X</th>\n",
       "      <th>5 tBodyAcc-std()-Y</th>\n",
       "      <th>6 tBodyAcc-std()-Z</th>\n",
       "      <th>7 tBodyAcc-mad()-X</th>\n",
       "      <th>8 tBodyAcc-mad()-Y</th>\n",
       "      <th>9 tBodyAcc-mad()-Z</th>\n",
       "      <th>10 tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>112 tBodyAccJerk-arCoeff()-Y,3</th>\n",
       "      <th>113 tBodyAccJerk-arCoeff()-Y,4</th>\n",
       "      <th>114 tBodyAccJerk-arCoeff()-Z,1</th>\n",
       "      <th>115 tBodyAccJerk-arCoeff()-Z,2</th>\n",
       "      <th>116 tBodyAccJerk-arCoeff()-Z,3</th>\n",
       "      <th>117 tBodyAccJerk-arCoeff()-Z,4</th>\n",
       "      <th>118 tBodyAccJerk-correlation()-X,Y</th>\n",
       "      <th>119 tBodyAccJerk-correlation()-X,Z</th>\n",
       "      <th>120 tBodyAccJerk-correlation()-Y,Z</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264177</td>\n",
       "      <td>0.373439</td>\n",
       "      <td>0.341778</td>\n",
       "      <td>-0.569791</td>\n",
       "      <td>0.265399</td>\n",
       "      <td>-0.477875</td>\n",
       "      <td>-0.385300</td>\n",
       "      <td>0.033644</td>\n",
       "      <td>-0.126511</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370493</td>\n",
       "      <td>0.413548</td>\n",
       "      <td>0.122216</td>\n",
       "      <td>0.180613</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>0.166573</td>\n",
       "      <td>-0.208772</td>\n",
       "      <td>0.084104</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>0.437623</td>\n",
       "      <td>0.257891</td>\n",
       "      <td>0.070030</td>\n",
       "      <td>0.186973</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>-0.120105</td>\n",
       "      <td>-0.110026</td>\n",
       "      <td>-0.039953</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.484244</td>\n",
       "      <td>0.357657</td>\n",
       "      <td>-0.187032</td>\n",
       "      <td>0.298069</td>\n",
       "      <td>0.451870</td>\n",
       "      <td>-0.127495</td>\n",
       "      <td>-0.083278</td>\n",
       "      <td>0.457060</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477454</td>\n",
       "      <td>0.417966</td>\n",
       "      <td>0.389537</td>\n",
       "      <td>-0.030309</td>\n",
       "      <td>0.163261</td>\n",
       "      <td>0.180189</td>\n",
       "      <td>-0.272884</td>\n",
       "      <td>0.103065</td>\n",
       "      <td>0.064729</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>0.299665</td>\n",
       "      <td>-0.057193</td>\n",
       "      <td>-0.181233</td>\n",
       "      <td>-0.195387</td>\n",
       "      <td>0.039905</td>\n",
       "      <td>0.077078</td>\n",
       "      <td>-0.282301</td>\n",
       "      <td>0.043616</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>0.210795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080322</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>-0.448491</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>-0.349855</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>-0.523499</td>\n",
       "      <td>-0.263124</td>\n",
       "      <td>0.333620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>0.273853</td>\n",
       "      <td>-0.007749</td>\n",
       "      <td>-0.147468</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-0.322552</td>\n",
       "      <td>-0.029456</td>\n",
       "      <td>0.080585</td>\n",
       "      <td>0.117440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020136</td>\n",
       "      <td>0.218178</td>\n",
       "      <td>-0.327139</td>\n",
       "      <td>-0.108303</td>\n",
       "      <td>-0.065145</td>\n",
       "      <td>0.042680</td>\n",
       "      <td>-0.460900</td>\n",
       "      <td>-0.178567</td>\n",
       "      <td>0.355012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>0.273387</td>\n",
       "      <td>-0.017011</td>\n",
       "      <td>-0.045022</td>\n",
       "      <td>-0.218218</td>\n",
       "      <td>-0.103822</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>-0.304515</td>\n",
       "      <td>-0.098913</td>\n",
       "      <td>0.332584</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102722</td>\n",
       "      <td>0.236469</td>\n",
       "      <td>-0.393169</td>\n",
       "      <td>-0.041687</td>\n",
       "      <td>-0.214678</td>\n",
       "      <td>-0.005115</td>\n",
       "      <td>-0.534302</td>\n",
       "      <td>-0.102262</td>\n",
       "      <td>0.387323</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>0.289654</td>\n",
       "      <td>-0.018843</td>\n",
       "      <td>-0.158281</td>\n",
       "      <td>-0.219139</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>0.268893</td>\n",
       "      <td>-0.310487</td>\n",
       "      <td>-0.068200</td>\n",
       "      <td>0.319473</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180158</td>\n",
       "      <td>0.175288</td>\n",
       "      <td>-0.439943</td>\n",
       "      <td>0.024245</td>\n",
       "      <td>-0.332076</td>\n",
       "      <td>-0.117280</td>\n",
       "      <td>-0.551732</td>\n",
       "      <td>-0.020034</td>\n",
       "      <td>0.263609</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>0.351503</td>\n",
       "      <td>-0.012423</td>\n",
       "      <td>-0.203867</td>\n",
       "      <td>-0.269270</td>\n",
       "      <td>-0.087212</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>-0.377404</td>\n",
       "      <td>-0.038678</td>\n",
       "      <td>0.229430</td>\n",
       "      <td>0.269013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077490</td>\n",
       "      <td>0.156481</td>\n",
       "      <td>-0.342625</td>\n",
       "      <td>-0.112329</td>\n",
       "      <td>-0.050668</td>\n",
       "      <td>-0.348724</td>\n",
       "      <td>-0.420532</td>\n",
       "      <td>-0.166305</td>\n",
       "      <td>0.166394</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1 tBodyAcc-mean()-X  2 tBodyAcc-mean()-Y  3 tBodyAcc-mean()-Z  \\\n",
       "0                0.288585            -0.020294            -0.132905   \n",
       "1                0.278419            -0.016411            -0.123520   \n",
       "2                0.279653            -0.019467            -0.113462   \n",
       "3                0.279174            -0.026201            -0.123283   \n",
       "4                0.276629            -0.016570            -0.115362   \n",
       "...                   ...                  ...                  ...   \n",
       "7347             0.299665            -0.057193            -0.181233   \n",
       "7348             0.273853            -0.007749            -0.147468   \n",
       "7349             0.273387            -0.017011            -0.045022   \n",
       "7350             0.289654            -0.018843            -0.158281   \n",
       "7351             0.351503            -0.012423            -0.203867   \n",
       "\n",
       "      4 tBodyAcc-std()-X  5 tBodyAcc-std()-Y  6 tBodyAcc-std()-Z  \\\n",
       "0              -0.995279           -0.983111           -0.913526   \n",
       "1              -0.998245           -0.975300           -0.960322   \n",
       "2              -0.995380           -0.967187           -0.978944   \n",
       "3              -0.996091           -0.983403           -0.990675   \n",
       "4              -0.998139           -0.980817           -0.990482   \n",
       "...                  ...                 ...                 ...   \n",
       "7347           -0.195387            0.039905            0.077078   \n",
       "7348           -0.235309            0.004816            0.059280   \n",
       "7349           -0.218218           -0.103822            0.274533   \n",
       "7350           -0.219139           -0.111412            0.268893   \n",
       "7351           -0.269270           -0.087212            0.177404   \n",
       "\n",
       "      7 tBodyAcc-mad()-X  8 tBodyAcc-mad()-Y  9 tBodyAcc-mad()-Z  \\\n",
       "0              -0.995112           -0.983185           -0.923527   \n",
       "1              -0.998807           -0.974914           -0.957686   \n",
       "2              -0.996520           -0.963668           -0.977469   \n",
       "3              -0.997099           -0.982750           -0.989302   \n",
       "4              -0.998321           -0.979672           -0.990441   \n",
       "...                  ...                 ...                 ...   \n",
       "7347           -0.282301            0.043616            0.060410   \n",
       "7348           -0.322552           -0.029456            0.080585   \n",
       "7349           -0.304515           -0.098913            0.332584   \n",
       "7350           -0.310487           -0.068200            0.319473   \n",
       "7351           -0.377404           -0.038678            0.229430   \n",
       "\n",
       "      10 tBodyAcc-max()-X  ...  112 tBodyAccJerk-arCoeff()-Y,3  \\\n",
       "0               -0.934724  ...                        0.264177   \n",
       "1               -0.943068  ...                        0.370493   \n",
       "2               -0.938692  ...                        0.327470   \n",
       "3               -0.938692  ...                        0.194679   \n",
       "4               -0.942469  ...                        0.477454   \n",
       "...                   ...  ...                             ...   \n",
       "7347             0.210795  ...                       -0.080322   \n",
       "7348             0.117440  ...                       -0.020136   \n",
       "7349             0.043999  ...                        0.102722   \n",
       "7350             0.101702  ...                        0.180158   \n",
       "7351             0.269013  ...                       -0.077490   \n",
       "\n",
       "      113 tBodyAccJerk-arCoeff()-Y,4  114 tBodyAccJerk-arCoeff()-Z,1  \\\n",
       "0                           0.373439                        0.341778   \n",
       "1                           0.413548                        0.122216   \n",
       "2                           0.437623                        0.257891   \n",
       "3                           0.484244                        0.357657   \n",
       "4                           0.417966                        0.389537   \n",
       "...                              ...                             ...   \n",
       "7347                        0.126940                       -0.448491   \n",
       "7348                        0.218178                       -0.327139   \n",
       "7349                        0.236469                       -0.393169   \n",
       "7350                        0.175288                       -0.439943   \n",
       "7351                        0.156481                       -0.342625   \n",
       "\n",
       "      115 tBodyAccJerk-arCoeff()-Z,2  116 tBodyAccJerk-arCoeff()-Z,3  \\\n",
       "0                          -0.569791                        0.265399   \n",
       "1                           0.180613                        0.047424   \n",
       "2                           0.070030                        0.186973   \n",
       "3                          -0.187032                        0.298069   \n",
       "4                          -0.030309                        0.163261   \n",
       "...                              ...                             ...   \n",
       "7347                        0.100100                       -0.349855   \n",
       "7348                       -0.108303                       -0.065145   \n",
       "7349                       -0.041687                       -0.214678   \n",
       "7350                        0.024245                       -0.332076   \n",
       "7351                       -0.112329                       -0.050668   \n",
       "\n",
       "      117 tBodyAccJerk-arCoeff()-Z,4  118 tBodyAccJerk-correlation()-X,Y  \\\n",
       "0                          -0.477875                           -0.385300   \n",
       "1                           0.166573                           -0.208772   \n",
       "2                           0.246800                           -0.120105   \n",
       "3                           0.451870                           -0.127495   \n",
       "4                           0.180189                           -0.272884   \n",
       "...                              ...                                 ...   \n",
       "7347                        0.003027                           -0.523499   \n",
       "7348                        0.042680                           -0.460900   \n",
       "7349                       -0.005115                           -0.534302   \n",
       "7350                       -0.117280                           -0.551732   \n",
       "7351                       -0.348724                           -0.420532   \n",
       "\n",
       "      119 tBodyAccJerk-correlation()-X,Z  120 tBodyAccJerk-correlation()-Y,Z  \\\n",
       "0                               0.033644                           -0.126511   \n",
       "1                               0.084104                           -0.268554   \n",
       "2                              -0.110026                           -0.039953   \n",
       "3                              -0.083278                            0.457060   \n",
       "4                               0.103065                            0.064729   \n",
       "...                                  ...                                 ...   \n",
       "7347                           -0.263124                            0.333620   \n",
       "7348                           -0.178567                            0.355012   \n",
       "7349                           -0.102262                            0.387323   \n",
       "7350                           -0.020034                            0.263609   \n",
       "7351                           -0.166305                            0.166394   \n",
       "\n",
       "      Activity  \n",
       "0            5  \n",
       "1            5  \n",
       "2            5  \n",
       "3            5  \n",
       "4            5  \n",
       "...        ...  \n",
       "7347         2  \n",
       "7348         2  \n",
       "7349         2  \n",
       "7350         2  \n",
       "7351         2  \n",
       "\n",
       "[7352 rows x 81 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "X_train_1 = train_data.loc[:,'1 tBodyAcc-mean()-X':'40 tBodyAcc-correlation()-Y,Z']\n",
    "X_train_2 = train_data.loc[:,'81 tBodyAccJerk-mean()-X':'120 tBodyAccJerk-correlation()-Y,Z']\n",
    "X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train = pd.concat([X_train, y_train], axis = 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[(X_train['Activity'] == 1) | (X_train['Activity'] == 3) | (X_train['Activity'] == 4)]\n",
    "X_train = X_train.iloc[:,:-1].values\n",
    "\n",
    "y_train = y_train[(y_train['Activity'] == 1) | (y_train['Activity'] == 3) | (y_train['Activity'] == 4)]\n",
    "y_train = y_train.values\n",
    "y_train = y_train.flatten()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_subjects = pd.read_csv('UCI/subject_train.txt', header = None)\n",
    "# train_subjects.columns = ['Subject']\n",
    "# train_subjects = train_subjects.values\n",
    "# train_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 tBodyAcc-mean()-X</th>\n",
       "      <th>2 tBodyAcc-mean()-Y</th>\n",
       "      <th>3 tBodyAcc-mean()-Z</th>\n",
       "      <th>4 tBodyAcc-std()-X</th>\n",
       "      <th>5 tBodyAcc-std()-Y</th>\n",
       "      <th>6 tBodyAcc-std()-Z</th>\n",
       "      <th>7 tBodyAcc-mad()-X</th>\n",
       "      <th>8 tBodyAcc-mad()-Y</th>\n",
       "      <th>9 tBodyAcc-mad()-Z</th>\n",
       "      <th>10 tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>112 tBodyAccJerk-arCoeff()-Y,3</th>\n",
       "      <th>113 tBodyAccJerk-arCoeff()-Y,4</th>\n",
       "      <th>114 tBodyAccJerk-arCoeff()-Z,1</th>\n",
       "      <th>115 tBodyAccJerk-arCoeff()-Z,2</th>\n",
       "      <th>116 tBodyAccJerk-arCoeff()-Z,3</th>\n",
       "      <th>117 tBodyAccJerk-arCoeff()-Z,4</th>\n",
       "      <th>118 tBodyAccJerk-correlation()-X,Y</th>\n",
       "      <th>119 tBodyAccJerk-correlation()-X,Z</th>\n",
       "      <th>120 tBodyAccJerk-correlation()-Y,Z</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219879</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>-0.082633</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>-0.196232</td>\n",
       "      <td>0.072358</td>\n",
       "      <td>-0.264860</td>\n",
       "      <td>0.035852</td>\n",
       "      <td>-0.349735</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508418</td>\n",
       "      <td>0.232150</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>-0.038097</td>\n",
       "      <td>-0.082657</td>\n",
       "      <td>0.101561</td>\n",
       "      <td>-0.153197</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>0.497612</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416121</td>\n",
       "      <td>0.561439</td>\n",
       "      <td>0.251901</td>\n",
       "      <td>-0.186509</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.708153</td>\n",
       "      <td>-0.063624</td>\n",
       "      <td>0.182786</td>\n",
       "      <td>0.756378</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270298</td>\n",
       "      <td>-0.032614</td>\n",
       "      <td>-0.117520</td>\n",
       "      <td>-0.994743</td>\n",
       "      <td>-0.973268</td>\n",
       "      <td>-0.967091</td>\n",
       "      <td>-0.995274</td>\n",
       "      <td>-0.974471</td>\n",
       "      <td>-0.968897</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374966</td>\n",
       "      <td>0.478378</td>\n",
       "      <td>0.212301</td>\n",
       "      <td>-0.112063</td>\n",
       "      <td>0.113197</td>\n",
       "      <td>0.565742</td>\n",
       "      <td>-0.197876</td>\n",
       "      <td>0.175518</td>\n",
       "      <td>0.619629</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274833</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>-0.129527</td>\n",
       "      <td>-0.993852</td>\n",
       "      <td>-0.967445</td>\n",
       "      <td>-0.978295</td>\n",
       "      <td>-0.994111</td>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-0.977346</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085211</td>\n",
       "      <td>0.436506</td>\n",
       "      <td>0.057438</td>\n",
       "      <td>0.258878</td>\n",
       "      <td>-0.120670</td>\n",
       "      <td>0.267825</td>\n",
       "      <td>0.086585</td>\n",
       "      <td>0.424799</td>\n",
       "      <td>0.345779</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>0.310155</td>\n",
       "      <td>-0.053391</td>\n",
       "      <td>-0.099109</td>\n",
       "      <td>-0.287866</td>\n",
       "      <td>-0.140589</td>\n",
       "      <td>-0.215088</td>\n",
       "      <td>-0.356083</td>\n",
       "      <td>-0.148775</td>\n",
       "      <td>-0.232057</td>\n",
       "      <td>0.185361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017944</td>\n",
       "      <td>0.139010</td>\n",
       "      <td>-0.532189</td>\n",
       "      <td>0.489649</td>\n",
       "      <td>-0.349313</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>-0.294837</td>\n",
       "      <td>-0.244100</td>\n",
       "      <td>0.123568</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>0.363385</td>\n",
       "      <td>-0.039214</td>\n",
       "      <td>-0.105915</td>\n",
       "      <td>-0.305388</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>-0.196373</td>\n",
       "      <td>-0.373540</td>\n",
       "      <td>-0.030036</td>\n",
       "      <td>-0.270237</td>\n",
       "      <td>0.185361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085628</td>\n",
       "      <td>0.384926</td>\n",
       "      <td>-0.416616</td>\n",
       "      <td>0.276557</td>\n",
       "      <td>-0.079494</td>\n",
       "      <td>-0.117911</td>\n",
       "      <td>-0.502786</td>\n",
       "      <td>-0.180374</td>\n",
       "      <td>0.138153</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>0.349966</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>-0.115788</td>\n",
       "      <td>-0.329638</td>\n",
       "      <td>-0.042143</td>\n",
       "      <td>-0.250181</td>\n",
       "      <td>-0.388017</td>\n",
       "      <td>-0.133257</td>\n",
       "      <td>-0.347029</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032617</td>\n",
       "      <td>0.426332</td>\n",
       "      <td>-0.034838</td>\n",
       "      <td>-0.060873</td>\n",
       "      <td>0.170071</td>\n",
       "      <td>-0.029039</td>\n",
       "      <td>-0.593716</td>\n",
       "      <td>-0.338919</td>\n",
       "      <td>0.284571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.237594</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>-0.096499</td>\n",
       "      <td>-0.323114</td>\n",
       "      <td>-0.229775</td>\n",
       "      <td>-0.207574</td>\n",
       "      <td>-0.392380</td>\n",
       "      <td>-0.279610</td>\n",
       "      <td>-0.289477</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157741</td>\n",
       "      <td>0.061688</td>\n",
       "      <td>-0.279348</td>\n",
       "      <td>0.125248</td>\n",
       "      <td>-0.065002</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>-0.277632</td>\n",
       "      <td>-0.597772</td>\n",
       "      <td>0.352172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>0.153627</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>-0.137018</td>\n",
       "      <td>-0.330046</td>\n",
       "      <td>-0.195253</td>\n",
       "      <td>-0.164339</td>\n",
       "      <td>-0.430974</td>\n",
       "      <td>-0.218295</td>\n",
       "      <td>-0.229933</td>\n",
       "      <td>-0.111527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030062</td>\n",
       "      <td>0.443505</td>\n",
       "      <td>-0.384250</td>\n",
       "      <td>0.167728</td>\n",
       "      <td>0.038046</td>\n",
       "      <td>-0.022593</td>\n",
       "      <td>-0.068147</td>\n",
       "      <td>-0.491751</td>\n",
       "      <td>0.055146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2947 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1 tBodyAcc-mean()-X  2 tBodyAcc-mean()-Y  3 tBodyAcc-mean()-Z  \\\n",
       "0                0.257178            -0.023285            -0.014654   \n",
       "1                0.286027            -0.013163            -0.119083   \n",
       "2                0.275485            -0.026050            -0.118152   \n",
       "3                0.270298            -0.032614            -0.117520   \n",
       "4                0.274833            -0.027848            -0.129527   \n",
       "...                   ...                  ...                  ...   \n",
       "2942             0.310155            -0.053391            -0.099109   \n",
       "2943             0.363385            -0.039214            -0.105915   \n",
       "2944             0.349966             0.030077            -0.115788   \n",
       "2945             0.237594             0.018467            -0.096499   \n",
       "2946             0.153627            -0.018437            -0.137018   \n",
       "\n",
       "      4 tBodyAcc-std()-X  5 tBodyAcc-std()-Y  6 tBodyAcc-std()-Z  \\\n",
       "0              -0.938404           -0.920091           -0.667683   \n",
       "1              -0.975415           -0.967458           -0.944958   \n",
       "2              -0.993819           -0.969926           -0.962748   \n",
       "3              -0.994743           -0.973268           -0.967091   \n",
       "4              -0.993852           -0.967445           -0.978295   \n",
       "...                  ...                 ...                 ...   \n",
       "2942           -0.287866           -0.140589           -0.215088   \n",
       "2943           -0.305388            0.028148           -0.196373   \n",
       "2944           -0.329638           -0.042143           -0.250181   \n",
       "2945           -0.323114           -0.229775           -0.207574   \n",
       "2946           -0.330046           -0.195253           -0.164339   \n",
       "\n",
       "      7 tBodyAcc-mad()-X  8 tBodyAcc-mad()-Y  9 tBodyAcc-mad()-Z  \\\n",
       "0              -0.952501           -0.925249           -0.674302   \n",
       "1              -0.986799           -0.968401           -0.945823   \n",
       "2              -0.994403           -0.970735           -0.963483   \n",
       "3              -0.995274           -0.974471           -0.968897   \n",
       "4              -0.994111           -0.965953           -0.977346   \n",
       "...                  ...                 ...                 ...   \n",
       "2942           -0.356083           -0.148775           -0.232057   \n",
       "2943           -0.373540           -0.030036           -0.270237   \n",
       "2944           -0.388017           -0.133257           -0.347029   \n",
       "2945           -0.392380           -0.279610           -0.289477   \n",
       "2946           -0.430974           -0.218295           -0.229933   \n",
       "\n",
       "      10 tBodyAcc-max()-X  ...  112 tBodyAccJerk-arCoeff()-Y,3  \\\n",
       "0               -0.894088  ...                        0.219879   \n",
       "1               -0.894088  ...                        0.508418   \n",
       "2               -0.939260  ...                        0.416121   \n",
       "3               -0.938610  ...                        0.374966   \n",
       "4               -0.938610  ...                        0.085211   \n",
       "...                   ...  ...                             ...   \n",
       "2942             0.185361  ...                       -0.017944   \n",
       "2943             0.185361  ...                       -0.085628   \n",
       "2944             0.007471  ...                       -0.032617   \n",
       "2945             0.007471  ...                        0.157741   \n",
       "2946            -0.111527  ...                        0.030062   \n",
       "\n",
       "      113 tBodyAccJerk-arCoeff()-Y,4  114 tBodyAccJerk-arCoeff()-Z,1  \\\n",
       "0                           0.422975                       -0.082633   \n",
       "1                           0.232150                       -0.002832   \n",
       "2                           0.561439                        0.251901   \n",
       "3                           0.478378                        0.212301   \n",
       "4                           0.436506                        0.057438   \n",
       "...                              ...                             ...   \n",
       "2942                        0.139010                       -0.532189   \n",
       "2943                        0.384926                       -0.416616   \n",
       "2944                        0.426332                       -0.034838   \n",
       "2945                        0.061688                       -0.279348   \n",
       "2946                        0.443505                       -0.384250   \n",
       "\n",
       "      115 tBodyAccJerk-arCoeff()-Z,2  116 tBodyAccJerk-arCoeff()-Z,3  \\\n",
       "0                           0.140427                       -0.196232   \n",
       "1                          -0.038097                       -0.082657   \n",
       "2                          -0.186509                        0.259740   \n",
       "3                          -0.112063                        0.113197   \n",
       "4                           0.258878                       -0.120670   \n",
       "...                              ...                             ...   \n",
       "2942                        0.489649                       -0.349313   \n",
       "2943                        0.276557                       -0.079494   \n",
       "2944                       -0.060873                        0.170071   \n",
       "2945                        0.125248                       -0.065002   \n",
       "2946                        0.167728                        0.038046   \n",
       "\n",
       "      117 tBodyAccJerk-arCoeff()-Z,4  118 tBodyAccJerk-correlation()-X,Y  \\\n",
       "0                           0.072358                           -0.264860   \n",
       "1                           0.101561                           -0.153197   \n",
       "2                           0.708153                           -0.063624   \n",
       "3                           0.565742                           -0.197876   \n",
       "4                           0.267825                            0.086585   \n",
       "...                              ...                                 ...   \n",
       "2942                        0.075277                           -0.294837   \n",
       "2943                       -0.117911                           -0.502786   \n",
       "2944                       -0.029039                           -0.593716   \n",
       "2945                        0.005851                           -0.277632   \n",
       "2946                       -0.022593                           -0.068147   \n",
       "\n",
       "      119 tBodyAccJerk-correlation()-X,Z  120 tBodyAccJerk-correlation()-Y,Z  \\\n",
       "0                               0.035852                           -0.349735   \n",
       "1                              -0.279966                            0.497612   \n",
       "2                               0.182786                            0.756378   \n",
       "3                               0.175518                            0.619629   \n",
       "4                               0.424799                            0.345779   \n",
       "...                                  ...                                 ...   \n",
       "2942                           -0.244100                            0.123568   \n",
       "2943                           -0.180374                            0.138153   \n",
       "2944                           -0.338919                            0.284571   \n",
       "2945                           -0.597772                            0.352172   \n",
       "2946                           -0.491751                            0.055146   \n",
       "\n",
       "      Activity  \n",
       "0            5  \n",
       "1            5  \n",
       "2            5  \n",
       "3            5  \n",
       "4            5  \n",
       "...        ...  \n",
       "2942         2  \n",
       "2943         2  \n",
       "2944         2  \n",
       "2945         2  \n",
       "2946         2  \n",
       "\n",
       "[2947 rows x 81 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "test_column_names = test_names.values.tolist()\n",
    "test_column_names = [k for row in test_column_names for k in row]\n",
    "\n",
    "test_data = pd.read_csv('../data/X_test.txt', delim_whitespace = True, header = None)\n",
    "test_data.columns = test_column_names\n",
    "\n",
    "y_test = pd.read_csv('../data/y_test.txt', header = None)\n",
    "y_test.columns = ['Activity']\n",
    "\n",
    "X_test_1 = test_data.loc[:,'1 tBodyAcc-mean()-X':'40 tBodyAcc-correlation()-Y,Z']\n",
    "X_test_2 = test_data.loc[:,'81 tBodyAccJerk-mean()-X':'120 tBodyAccJerk-correlation()-Y,Z']\n",
    "X_test = pd.concat([X_test_1, X_test_2], axis = 1)\n",
    "\n",
    "X_test = pd.concat([X_test, y_test], axis = 1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[(X_test['Activity'] == 1) | (X_test['Activity'] == 3) | (X_test['Activity'] == 4)]\n",
    "X_test = X_test.iloc[:,:-1].values\n",
    "\n",
    "y_test = y_test[(y_test['Activity'] == 1) | (y_test['Activity'] == 3) | (y_test['Activity'] == 4)]\n",
    "y_test = y_test.values\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2\n",
    "        \n",
    "for k in range(len(y_test)):\n",
    "    if y_test[k] == 1:\n",
    "        y_test[k] = 0\n",
    "    elif y_test[k] == 3:\n",
    "        y_test[k] = 1\n",
    "    else:\n",
    "        y_test[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_subjects = pd.read_csv('UCI/subject_test.txt', header = None)\n",
    "# test_subjects.columns = ['Subject']\n",
    "# test_subjects = test_subjects.values\n",
    "# test_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classifier_block(input_dim, output_dim):\n",
    "#     return nn.Sequential(\n",
    "#         nn.Linear(input_dim, output_dim),\n",
    "#         nn.Dropout(0.1),\n",
    "#         nn.LeakyReLU(0.05)\n",
    "#     )\n",
    "\n",
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self, feature_dim = 40):\n",
    "#         super(Classifier, self).__init__()\n",
    "#         self.network = nn.Sequential(\n",
    "#             classifier_block(feature_dim, 30),\n",
    "#             classifier_block(30, 25),\n",
    "#             classifier_block(25, 20),\n",
    "#             classifier_block(20, 10),\n",
    "#             nn.Linear(10, 3)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = 80):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 60),\n",
    "            classifier_block(60, 40),\n",
    "            classifier_block(40, 20),\n",
    "            classifier_block(20, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 15.229276418685913, Final Batch Loss: 1.0629549026489258\n",
      "Epoch 2, Loss: 14.034622311592102, Final Batch Loss: 0.9361550807952881\n",
      "Epoch 3, Loss: 11.237817943096161, Final Batch Loss: 0.6553452014923096\n",
      "Epoch 4, Loss: 7.329952359199524, Final Batch Loss: 0.4514380991458893\n",
      "Epoch 5, Loss: 5.006294906139374, Final Batch Loss: 0.28629472851753235\n",
      "Epoch 6, Loss: 3.94045652449131, Final Batch Loss: 0.2193487286567688\n",
      "Epoch 7, Loss: 2.6530322954058647, Final Batch Loss: 0.1693955808877945\n",
      "Epoch 8, Loss: 1.8113057985901833, Final Batch Loss: 0.12494426965713501\n",
      "Epoch 9, Loss: 1.3806631229817867, Final Batch Loss: 0.05913328006863594\n",
      "Epoch 10, Loss: 1.1615499630570412, Final Batch Loss: 0.06297887861728668\n",
      "Epoch 11, Loss: 0.9097705446183681, Final Batch Loss: 0.06066957488656044\n",
      "Epoch 12, Loss: 0.7372481431812048, Final Batch Loss: 0.04554713889956474\n",
      "Epoch 13, Loss: 0.6903793308883905, Final Batch Loss: 0.024413758888840675\n",
      "Epoch 14, Loss: 0.5713962819427252, Final Batch Loss: 0.04422365501523018\n",
      "Epoch 15, Loss: 0.5351059287786484, Final Batch Loss: 0.04430389404296875\n",
      "Epoch 16, Loss: 0.38459828961640596, Final Batch Loss: 0.037943702191114426\n",
      "Epoch 17, Loss: 0.5648995786905289, Final Batch Loss: 0.02942798100411892\n",
      "Epoch 18, Loss: 0.41191258653998375, Final Batch Loss: 0.033422280102968216\n",
      "Epoch 19, Loss: 0.42051073256880045, Final Batch Loss: 0.018020574003458023\n",
      "Epoch 20, Loss: 0.3115204581990838, Final Batch Loss: 0.025818390771746635\n",
      "Epoch 21, Loss: 0.3230012645944953, Final Batch Loss: 0.0302666537463665\n",
      "Epoch 22, Loss: 0.33297185599803925, Final Batch Loss: 0.010105079971253872\n",
      "Epoch 23, Loss: 0.23726300010457635, Final Batch Loss: 0.011421547271311283\n",
      "Epoch 24, Loss: 0.253120644018054, Final Batch Loss: 0.0309281162917614\n",
      "Epoch 25, Loss: 0.2802954474464059, Final Batch Loss: 0.012053470127284527\n",
      "Epoch 26, Loss: 0.3156231176108122, Final Batch Loss: 0.023868300020694733\n",
      "Epoch 27, Loss: 0.22480864357203245, Final Batch Loss: 0.011156264692544937\n",
      "Epoch 28, Loss: 0.22628996148705482, Final Batch Loss: 0.016757218167185783\n",
      "Epoch 29, Loss: 0.19836228294298053, Final Batch Loss: 0.013722697272896767\n",
      "Epoch 30, Loss: 0.20779717015102506, Final Batch Loss: 0.006619502790272236\n",
      "Epoch 31, Loss: 0.20232148841023445, Final Batch Loss: 0.006572375074028969\n",
      "Epoch 32, Loss: 0.15563496574759483, Final Batch Loss: 0.007497153710573912\n",
      "Epoch 33, Loss: 0.14524448313750327, Final Batch Loss: 0.012200910598039627\n",
      "Epoch 34, Loss: 0.2040541109163314, Final Batch Loss: 0.003866569371894002\n",
      "Epoch 35, Loss: 0.13111223885789514, Final Batch Loss: 0.01850361004471779\n",
      "Epoch 36, Loss: 0.1778939375653863, Final Batch Loss: 0.004735549911856651\n",
      "Epoch 37, Loss: 0.11338031478226185, Final Batch Loss: 0.005060961470007896\n",
      "Epoch 38, Loss: 0.11131413443945348, Final Batch Loss: 0.011371953412890434\n",
      "Epoch 39, Loss: 0.12163507868535817, Final Batch Loss: 0.004556538537144661\n",
      "Epoch 40, Loss: 0.08764354628510773, Final Batch Loss: 0.012977711856365204\n",
      "Epoch 41, Loss: 0.13478037202730775, Final Batch Loss: 0.015778375789523125\n",
      "Epoch 42, Loss: 0.0799157713772729, Final Batch Loss: 0.001899080933071673\n",
      "Epoch 43, Loss: 0.10286402545170859, Final Batch Loss: 0.032789867371320724\n",
      "Epoch 44, Loss: 0.17532452114392072, Final Batch Loss: 0.019606241956353188\n",
      "Epoch 45, Loss: 0.16191944386810064, Final Batch Loss: 0.03659641742706299\n",
      "Epoch 46, Loss: 0.08164705603849143, Final Batch Loss: 0.0015699234791100025\n",
      "Epoch 47, Loss: 0.08710812020581216, Final Batch Loss: 0.001671584672294557\n",
      "Epoch 48, Loss: 0.06840824999380857, Final Batch Loss: 0.002668570028617978\n",
      "Epoch 49, Loss: 0.06410031602717936, Final Batch Loss: 0.001781792612746358\n",
      "Epoch 50, Loss: 0.07827103754971176, Final Batch Loss: 0.0030124718323349953\n",
      "Epoch 51, Loss: 0.027056339662522078, Final Batch Loss: 0.001725786249153316\n",
      "Epoch 52, Loss: 0.08871454186737537, Final Batch Loss: 0.005370536353439093\n",
      "Epoch 53, Loss: 0.04941111512016505, Final Batch Loss: 0.0021186331287026405\n",
      "Epoch 54, Loss: 0.037660361151210964, Final Batch Loss: 0.002378838835284114\n",
      "Epoch 55, Loss: 0.05402866308577359, Final Batch Loss: 0.001686583855189383\n",
      "Epoch 56, Loss: 0.05848096986301243, Final Batch Loss: 0.010576842352747917\n",
      "Epoch 57, Loss: 0.05604795186081901, Final Batch Loss: 0.008923347108066082\n",
      "Epoch 58, Loss: 0.05641314905369654, Final Batch Loss: 0.0004571456229314208\n",
      "Epoch 59, Loss: 0.027155058225616813, Final Batch Loss: 0.0012587795499712229\n",
      "Epoch 60, Loss: 0.047441529779462144, Final Batch Loss: 0.0012041417649015784\n",
      "Epoch 61, Loss: 0.06525127482018434, Final Batch Loss: 0.0011712335981428623\n",
      "Epoch 62, Loss: 0.05493737442884594, Final Batch Loss: 0.0014770877314731479\n",
      "Epoch 63, Loss: 0.029563255549874157, Final Batch Loss: 0.0013106160331517458\n",
      "Epoch 64, Loss: 0.037374934006948024, Final Batch Loss: 0.008006955496966839\n",
      "Epoch 65, Loss: 0.037882215285208076, Final Batch Loss: 0.004202249459922314\n",
      "Epoch 66, Loss: 0.017361245467327535, Final Batch Loss: 0.001507303910329938\n",
      "Epoch 67, Loss: 0.032933350012172014, Final Batch Loss: 0.003273522015661001\n",
      "Epoch 68, Loss: 0.023870478617027402, Final Batch Loss: 0.0006745944847352803\n",
      "Epoch 69, Loss: 0.027702591352863237, Final Batch Loss: 0.0055955396965146065\n",
      "Epoch 70, Loss: 0.017043608298990875, Final Batch Loss: 0.00030865927692502737\n",
      "Epoch 71, Loss: 0.018258954311022535, Final Batch Loss: 0.0012783620040863752\n",
      "Epoch 72, Loss: 0.06599114928394556, Final Batch Loss: 0.004615365527570248\n",
      "Epoch 73, Loss: 0.05686505924677476, Final Batch Loss: 0.0007599915261380374\n",
      "Epoch 74, Loss: 0.028442577488021925, Final Batch Loss: 0.0001704557507764548\n",
      "Epoch 75, Loss: 0.01199253517552279, Final Batch Loss: 0.0004208364407531917\n",
      "Epoch 76, Loss: 0.030789730633841828, Final Batch Loss: 0.0017256800783798099\n",
      "Epoch 77, Loss: 0.048325036972528324, Final Batch Loss: 0.0009619914344511926\n",
      "Epoch 78, Loss: 0.04019870785123203, Final Batch Loss: 0.0012692298041656613\n",
      "Epoch 79, Loss: 0.061833385785575956, Final Batch Loss: 0.0009689785074442625\n",
      "Epoch 80, Loss: 0.03336233735899441, Final Batch Loss: 0.002304432913661003\n",
      "Epoch 81, Loss: 0.026203142799204215, Final Batch Loss: 0.0011081141419708729\n",
      "Epoch 82, Loss: 0.026513242526561953, Final Batch Loss: 0.0027318403590470552\n",
      "Epoch 83, Loss: 0.040457660041283816, Final Batch Loss: 0.0005315407761372626\n",
      "Epoch 84, Loss: 0.0374834053509403, Final Batch Loss: 0.0009808072354644537\n",
      "Epoch 85, Loss: 0.07826761688920669, Final Batch Loss: 0.0028761657886207104\n",
      "Epoch 86, Loss: 0.017575632082298398, Final Batch Loss: 0.0006933468976058066\n",
      "Epoch 87, Loss: 0.024890855245757848, Final Batch Loss: 0.00044038394116796553\n",
      "Epoch 88, Loss: 0.04185610140848439, Final Batch Loss: 0.00019181524112354964\n",
      "Epoch 89, Loss: 0.02263909686007537, Final Batch Loss: 0.004949710797518492\n",
      "Epoch 90, Loss: 0.05196908273501322, Final Batch Loss: 0.0008857722277753055\n",
      "Epoch 91, Loss: 0.023052327218465507, Final Batch Loss: 0.0006810297491028905\n",
      "Epoch 92, Loss: 0.059658667392795905, Final Batch Loss: 0.0003399670240469277\n",
      "Epoch 93, Loss: 0.029690366907743737, Final Batch Loss: 0.0005642551695927978\n",
      "Epoch 94, Loss: 0.0316349494678434, Final Batch Loss: 0.0006845832103863358\n",
      "Epoch 95, Loss: 0.02143654592509847, Final Batch Loss: 0.0007090015569701791\n",
      "Epoch 96, Loss: 0.015447964411578141, Final Batch Loss: 0.0009301812970079482\n",
      "Epoch 97, Loss: 0.016636713524349034, Final Batch Loss: 0.0005260542966425419\n",
      "Epoch 98, Loss: 0.013057001255219802, Final Batch Loss: 0.0008153871749527752\n",
      "Epoch 99, Loss: 0.01105428393202601, Final Batch Loss: 0.00033845039433799684\n",
      "Epoch 100, Loss: 0.014235087641282007, Final Batch Loss: 0.0018001808784902096\n",
      "Epoch 101, Loss: 0.021402497513918206, Final Batch Loss: 0.0007314452086575329\n",
      "Epoch 102, Loss: 0.014888854988384992, Final Batch Loss: 0.0001717310951789841\n",
      "Epoch 103, Loss: 0.015408079590997659, Final Batch Loss: 0.00023404507373925298\n",
      "Epoch 104, Loss: 0.027655797624902334, Final Batch Loss: 0.0022876879666000605\n",
      "Epoch 105, Loss: 0.011917392199393362, Final Batch Loss: 0.0009656739421188831\n",
      "Epoch 106, Loss: 0.02111497087753378, Final Batch Loss: 9.329928434453905e-05\n",
      "Epoch 107, Loss: 0.0198065662625595, Final Batch Loss: 0.0004562821995932609\n",
      "Epoch 108, Loss: 0.05064776840299601, Final Batch Loss: 0.0025098472833633423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109, Loss: 0.02523817373730708, Final Batch Loss: 0.0010316823609173298\n",
      "Epoch 110, Loss: 0.01765268779854523, Final Batch Loss: 0.00041801040060818195\n",
      "Epoch 111, Loss: 0.025304877693997696, Final Batch Loss: 0.014641310088336468\n",
      "Epoch 112, Loss: 0.020270493056159467, Final Batch Loss: 0.0025692947674542665\n",
      "Epoch 113, Loss: 0.028584340878296643, Final Batch Loss: 0.00021564810595009476\n",
      "Epoch 114, Loss: 0.027874463026819285, Final Batch Loss: 0.00025944848312065005\n",
      "Epoch 115, Loss: 0.028441320842830464, Final Batch Loss: 0.0012257444905117154\n",
      "Epoch 116, Loss: 0.01768949825782329, Final Batch Loss: 0.0023531480692327023\n",
      "Epoch 117, Loss: 0.01698677786043845, Final Batch Loss: 0.0014588991180062294\n",
      "Epoch 118, Loss: 0.013895336538553238, Final Batch Loss: 0.0009142173221334815\n",
      "Epoch 119, Loss: 0.008022538138902746, Final Batch Loss: 0.00020716294238809496\n",
      "Epoch 120, Loss: 0.020469211238378193, Final Batch Loss: 0.0007648173486813903\n",
      "Epoch 121, Loss: 0.011313612783851568, Final Batch Loss: 0.0022212101612240076\n",
      "Epoch 122, Loss: 0.01044732220179867, Final Batch Loss: 0.002995460992679\n",
      "Epoch 123, Loss: 0.020014490371977445, Final Batch Loss: 0.0003279218217357993\n",
      "Epoch 124, Loss: 0.015625548920070287, Final Batch Loss: 0.00021296915656421334\n",
      "Epoch 125, Loss: 0.01993057948857313, Final Batch Loss: 0.0004382887273095548\n",
      "Epoch 126, Loss: 0.020019452373162494, Final Batch Loss: 0.0002115708339260891\n",
      "Epoch 127, Loss: 0.009276290802517906, Final Batch Loss: 0.0008785935351625085\n",
      "Epoch 128, Loss: 0.012543325450678822, Final Batch Loss: 0.00019371701637282968\n",
      "Epoch 129, Loss: 0.012162362458184361, Final Batch Loss: 0.00015370806795544922\n",
      "Epoch 130, Loss: 0.011592180366278626, Final Batch Loss: 0.00279817171394825\n",
      "Epoch 131, Loss: 0.01515390349959489, Final Batch Loss: 0.00012773698836099356\n",
      "Epoch 132, Loss: 0.01796465511142742, Final Batch Loss: 0.0012466565240174532\n",
      "Epoch 133, Loss: 0.043428377612144686, Final Batch Loss: 0.0003014446119777858\n",
      "Epoch 134, Loss: 0.016885446319065522, Final Batch Loss: 0.003202787833288312\n",
      "Epoch 135, Loss: 0.00997648717748234, Final Batch Loss: 0.0002597116108518094\n",
      "Epoch 136, Loss: 0.011019224271876737, Final Batch Loss: 0.0001070990547304973\n",
      "Epoch 137, Loss: 0.0824883453460643, Final Batch Loss: 0.004469286650419235\n",
      "Epoch 138, Loss: 0.06516016896057408, Final Batch Loss: 0.0004669411573559046\n",
      "Epoch 139, Loss: 0.019028852257179096, Final Batch Loss: 0.0001958192588062957\n",
      "Epoch 140, Loss: 0.01142338306090096, Final Batch Loss: 0.00018480939615983516\n",
      "Epoch 141, Loss: 0.008640341424325015, Final Batch Loss: 0.00011700254981406033\n",
      "Epoch 142, Loss: 0.004602283548592823, Final Batch Loss: 0.0004412262933328748\n",
      "Epoch 143, Loss: 0.0070909256537561305, Final Batch Loss: 0.0003246738633606583\n",
      "Epoch 144, Loss: 0.024500434672518168, Final Batch Loss: 0.0004413995484355837\n",
      "Epoch 145, Loss: 0.013622840808238834, Final Batch Loss: 0.0002563258749432862\n",
      "Epoch 146, Loss: 0.005143916991073638, Final Batch Loss: 0.00014095238293521106\n",
      "Epoch 147, Loss: 0.015851234769797884, Final Batch Loss: 0.002021282911300659\n",
      "Epoch 148, Loss: 0.00647283920989139, Final Batch Loss: 0.0006047388887964189\n",
      "Epoch 149, Loss: 0.019360217338544317, Final Batch Loss: 1.490652357460931e-05\n",
      "Epoch 150, Loss: 0.006926157933776267, Final Batch Loss: 0.00028432722319848835\n",
      "Epoch 151, Loss: 0.005276543321087956, Final Batch Loss: 0.00016943548689596355\n",
      "Epoch 152, Loss: 0.013476952251949115, Final Batch Loss: 0.00013198632223065943\n",
      "Epoch 153, Loss: 0.011194621205504518, Final Batch Loss: 0.00010272538202116266\n",
      "Epoch 154, Loss: 0.01065335315070115, Final Batch Loss: 0.00304838246665895\n",
      "Epoch 155, Loss: 0.004512287194302189, Final Batch Loss: 5.9459955082274973e-05\n",
      "Epoch 156, Loss: 0.006924565749613976, Final Batch Loss: 9.652347944211215e-05\n",
      "Epoch 157, Loss: 0.004739601521578152, Final Batch Loss: 0.0007276466931216419\n",
      "Epoch 158, Loss: 0.01673579285852611, Final Batch Loss: 0.0001638570538489148\n",
      "Epoch 159, Loss: 0.013472150052621146, Final Batch Loss: 0.00016650097677484155\n",
      "Epoch 160, Loss: 0.010139370693650562, Final Batch Loss: 1.9771621737163514e-05\n",
      "Epoch 161, Loss: 0.018460201419657096, Final Batch Loss: 7.53577405703254e-05\n",
      "Epoch 162, Loss: 0.00733405763094197, Final Batch Loss: 0.00014785297389607877\n",
      "Epoch 163, Loss: 0.014576103629224235, Final Batch Loss: 3.9005797589197755e-05\n",
      "Epoch 164, Loss: 0.007621094583555532, Final Batch Loss: 0.00018924643518403172\n",
      "Epoch 165, Loss: 0.00321907290344825, Final Batch Loss: 5.7052293414017186e-05\n",
      "Epoch 166, Loss: 0.005854378679941874, Final Batch Loss: 2.592474629636854e-05\n",
      "Epoch 167, Loss: 0.00697655844851397, Final Batch Loss: 9.427949407836422e-05\n",
      "Epoch 168, Loss: 0.009309143842983758, Final Batch Loss: 0.0002997667179442942\n",
      "Epoch 169, Loss: 0.0038719128560842364, Final Batch Loss: 0.0010918581392616034\n",
      "Epoch 170, Loss: 0.008544561236703885, Final Batch Loss: 0.0020848384592682123\n",
      "Epoch 171, Loss: 0.01713081444177078, Final Batch Loss: 0.0002234763087471947\n",
      "Epoch 172, Loss: 0.003972035887272796, Final Batch Loss: 0.0005360344075597823\n",
      "Epoch 173, Loss: 0.008141313435316988, Final Batch Loss: 6.5127055677294265e-06\n",
      "Epoch 174, Loss: 0.029036646368695074, Final Batch Loss: 1.753285869199317e-05\n",
      "Epoch 175, Loss: 0.03917691573406046, Final Batch Loss: 0.00015061096928548068\n",
      "Epoch 176, Loss: 0.038173188957443926, Final Batch Loss: 0.005031203851103783\n",
      "Epoch 177, Loss: 0.03127634345582919, Final Batch Loss: 0.0004105454427190125\n",
      "Epoch 178, Loss: 0.017062967133824714, Final Batch Loss: 0.0001773063268046826\n",
      "Epoch 179, Loss: 0.03281597717796103, Final Batch Loss: 9.454414976062253e-05\n",
      "Epoch 180, Loss: 0.006944331798877101, Final Batch Loss: 0.00010778008436318487\n",
      "Epoch 181, Loss: 0.012908965973110753, Final Batch Loss: 0.004701114259660244\n",
      "Epoch 182, Loss: 0.015231027216941584, Final Batch Loss: 0.0006150822737254202\n",
      "Epoch 183, Loss: 0.013645465034642257, Final Batch Loss: 0.000328649504808709\n",
      "Epoch 184, Loss: 0.014850901587124099, Final Batch Loss: 0.00023573869839310646\n",
      "Epoch 185, Loss: 0.02969712833146332, Final Batch Loss: 0.0011099448893219233\n",
      "Epoch 186, Loss: 0.0295653770735953, Final Batch Loss: 0.000174286964465864\n",
      "Epoch 187, Loss: 0.014942905143470853, Final Batch Loss: 6.450036744354293e-05\n",
      "Epoch 188, Loss: 0.0069566021775244735, Final Batch Loss: 0.0008729632827453315\n",
      "Epoch 189, Loss: 0.006952181462111184, Final Batch Loss: 0.0001762240135576576\n",
      "Epoch 190, Loss: 0.029882225213441416, Final Batch Loss: 0.00016513191803824157\n",
      "Epoch 191, Loss: 0.00504028309842397, Final Batch Loss: 3.890280277119018e-05\n",
      "Epoch 192, Loss: 0.014513195750623709, Final Batch Loss: 0.00018255252507515252\n",
      "Epoch 193, Loss: 0.006839597121143015, Final Batch Loss: 7.738541899016127e-05\n",
      "Epoch 194, Loss: 0.0036883875654893927, Final Batch Loss: 0.0002570964861661196\n",
      "Epoch 195, Loss: 0.008786490296188276, Final Batch Loss: 0.0015875233802944422\n",
      "Epoch 196, Loss: 0.009690834396678838, Final Batch Loss: 6.061098974896595e-05\n",
      "Epoch 197, Loss: 0.0034653636776056373, Final Batch Loss: 3.170849959133193e-05\n",
      "Epoch 198, Loss: 0.0042658372803998645, Final Batch Loss: 0.00017612810188438743\n",
      "Epoch 199, Loss: 0.005269284600217361, Final Batch Loss: 5.6623008276801556e-05\n",
      "Epoch 200, Loss: 0.007861350717575988, Final Batch Loss: 0.0006337262457236648\n",
      "Epoch 201, Loss: 0.005040724312493694, Final Batch Loss: 4.248745244694874e-05\n",
      "Epoch 202, Loss: 0.004088142440195952, Final Batch Loss: 9.549391506880056e-06\n",
      "Epoch 203, Loss: 0.0019645248830784112, Final Batch Loss: 6.258819485083222e-05\n",
      "Epoch 204, Loss: 0.012098583787519601, Final Batch Loss: 0.003007862949743867\n",
      "Epoch 205, Loss: 0.008969929651357234, Final Batch Loss: 0.0009534426499158144\n",
      "Epoch 206, Loss: 0.005762093656358047, Final Batch Loss: 1.8884918972617015e-05\n",
      "Epoch 207, Loss: 0.0067207502070232294, Final Batch Loss: 3.625222962000407e-05\n",
      "Epoch 208, Loss: 0.0008758127946748573, Final Batch Loss: 7.2570742304378655e-06\n",
      "Epoch 209, Loss: 0.006964440525280224, Final Batch Loss: 2.9889526558690704e-05\n",
      "Epoch 210, Loss: 0.006842242439688562, Final Batch Loss: 6.953100819373503e-05\n",
      "Epoch 211, Loss: 0.004443473124410957, Final Batch Loss: 3.7682606489397585e-05\n",
      "Epoch 212, Loss: 0.0022033502150407003, Final Batch Loss: 0.00011077191447839141\n",
      "Epoch 213, Loss: 0.007040193651164373, Final Batch Loss: 2.2868671294418164e-05\n",
      "Epoch 214, Loss: 0.01734223809398827, Final Batch Loss: 2.3683511244598776e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215, Loss: 0.0026182271494690212, Final Batch Loss: 3.5484823456499726e-05\n",
      "Epoch 216, Loss: 0.020404822883847373, Final Batch Loss: 7.836137956473976e-05\n",
      "Epoch 217, Loss: 0.014077597783398232, Final Batch Loss: 1.5743022231617942e-05\n",
      "Epoch 218, Loss: 0.014122322955699929, Final Batch Loss: 0.004553369712084532\n",
      "Epoch 219, Loss: 0.0047026848787936615, Final Batch Loss: 5.859213706571609e-05\n",
      "Epoch 220, Loss: 0.006363833956129383, Final Batch Loss: 6.297647632891312e-05\n",
      "Epoch 221, Loss: 0.004539172048680484, Final Batch Loss: 6.137976743048057e-05\n",
      "Epoch 222, Loss: 0.003665443728095852, Final Batch Loss: 0.00026120967231690884\n",
      "Epoch 223, Loss: 0.009478434342781838, Final Batch Loss: 4.231733691995032e-05\n",
      "Epoch 224, Loss: 0.0030392959160963073, Final Batch Loss: 6.197441689437255e-05\n",
      "Epoch 225, Loss: 0.003747116891645419, Final Batch Loss: 0.00017076407675631344\n",
      "Epoch 226, Loss: 0.002152791128537501, Final Batch Loss: 9.674468310549855e-05\n",
      "Epoch 227, Loss: 0.0013190582740207901, Final Batch Loss: 0.000163972785230726\n",
      "Epoch 228, Loss: 0.0033314102092845133, Final Batch Loss: 1.436201091564726e-05\n",
      "Epoch 229, Loss: 0.004806146135706513, Final Batch Loss: 8.690142567502335e-05\n",
      "Epoch 230, Loss: 0.003056784850286931, Final Batch Loss: 4.2398780351504683e-05\n",
      "Epoch 231, Loss: 0.0015070027311594458, Final Batch Loss: 2.098499498970341e-05\n",
      "Epoch 232, Loss: 0.003000112989866466, Final Batch Loss: 1.3071626199234743e-05\n",
      "Epoch 233, Loss: 0.004896424807611766, Final Batch Loss: 5.178642459213734e-05\n",
      "Epoch 234, Loss: 0.005193953998059442, Final Batch Loss: 0.00036660206387750804\n",
      "Epoch 235, Loss: 0.0011442912041275122, Final Batch Loss: 3.748727249330841e-05\n",
      "Epoch 236, Loss: 0.012113330920783483, Final Batch Loss: 3.235634358134121e-05\n",
      "Epoch 237, Loss: 0.005133531687533832, Final Batch Loss: 5.051112566434313e-06\n",
      "Epoch 238, Loss: 0.006654375193647866, Final Batch Loss: 0.0017140767304226756\n",
      "Epoch 239, Loss: 0.0011774572999456723, Final Batch Loss: 2.4425793526461348e-05\n",
      "Epoch 240, Loss: 0.0009815142427669343, Final Batch Loss: 0.00015865665045566857\n",
      "Epoch 241, Loss: 0.0024105019433591224, Final Batch Loss: 1.3809859410685021e-05\n",
      "Epoch 242, Loss: 0.0035502224054653198, Final Batch Loss: 1.1414123946451582e-05\n",
      "Epoch 243, Loss: 0.004361802475841614, Final Batch Loss: 6.497848517028615e-05\n",
      "Epoch 244, Loss: 0.0008542452287656488, Final Batch Loss: 1.5033660929475445e-05\n",
      "Epoch 245, Loss: 0.005738607052080624, Final Batch Loss: 0.0001682741567492485\n",
      "Epoch 246, Loss: 0.004924017493976862, Final Batch Loss: 5.9235753724351525e-06\n",
      "Epoch 247, Loss: 0.0012843687336498988, Final Batch Loss: 9.642221993999556e-05\n",
      "Epoch 248, Loss: 0.0009736521888044081, Final Batch Loss: 3.53677460225299e-05\n",
      "Epoch 249, Loss: 0.0005353659610705108, Final Batch Loss: 2.1645610104314983e-05\n",
      "Epoch 250, Loss: 0.0015192259835430377, Final Batch Loss: 1.876466399153287e-06\n",
      "Epoch 251, Loss: 0.0026720371827195777, Final Batch Loss: 1.2229779713379685e-05\n",
      "Epoch 252, Loss: 0.0008572497231398302, Final Batch Loss: 0.00014974562509451061\n",
      "Epoch 253, Loss: 0.0006165085010252369, Final Batch Loss: 2.5549470592522994e-05\n",
      "Epoch 254, Loss: 0.010786944852043234, Final Batch Loss: 0.008284280076622963\n",
      "Epoch 255, Loss: 0.011573931904422352, Final Batch Loss: 0.010679098777472973\n",
      "Epoch 256, Loss: 0.001004598532063028, Final Batch Loss: 1.0395764547865838e-05\n",
      "Epoch 257, Loss: 0.002070827208456194, Final Batch Loss: 0.0002023474662564695\n",
      "Epoch 258, Loss: 0.001103002582112822, Final Batch Loss: 9.751821926329285e-05\n",
      "Epoch 259, Loss: 0.0005766093993315735, Final Batch Loss: 4.8742094804765657e-05\n",
      "Epoch 260, Loss: 0.005296316960539116, Final Batch Loss: 0.003613976761698723\n",
      "Epoch 261, Loss: 0.010849527039681561, Final Batch Loss: 0.00017557977116666734\n",
      "Epoch 262, Loss: 0.001888110136405885, Final Batch Loss: 0.0005543819279409945\n",
      "Epoch 263, Loss: 0.013749220194085865, Final Batch Loss: 0.00021788885351270437\n",
      "Epoch 264, Loss: 0.012743044706439832, Final Batch Loss: 6.347902672132477e-05\n",
      "Epoch 265, Loss: 0.0023765393079884234, Final Batch Loss: 5.620323645416647e-05\n",
      "Epoch 266, Loss: 0.012275605222384911, Final Batch Loss: 4.1488608985673636e-05\n",
      "Epoch 267, Loss: 0.017583186635420134, Final Batch Loss: 5.018788579036482e-05\n",
      "Epoch 268, Loss: 0.11333036878750136, Final Batch Loss: 0.03260046988725662\n",
      "Epoch 269, Loss: 0.1301066406940663, Final Batch Loss: 0.0016578573267906904\n",
      "Epoch 270, Loss: 0.103358955202566, Final Batch Loss: 0.0006831748178228736\n",
      "Epoch 271, Loss: 0.028873907343950123, Final Batch Loss: 0.00017086307343561202\n",
      "Epoch 272, Loss: 0.03550359145447146, Final Batch Loss: 0.0006218738853931427\n",
      "Epoch 273, Loss: 0.005326875805621967, Final Batch Loss: 0.00020363103249110281\n",
      "Epoch 274, Loss: 0.00603070614306489, Final Batch Loss: 0.0006325332797132432\n",
      "Epoch 275, Loss: 0.005880431541299913, Final Batch Loss: 0.0001528831635368988\n",
      "Epoch 276, Loss: 0.003242670169129269, Final Batch Loss: 0.00047712467494420707\n",
      "Epoch 277, Loss: 0.011146657194331056, Final Batch Loss: 0.001625093980692327\n",
      "Epoch 278, Loss: 0.009342504181404365, Final Batch Loss: 0.0008596524712629616\n",
      "Epoch 279, Loss: 0.004405725856486242, Final Batch Loss: 6.943438347661868e-05\n",
      "Epoch 280, Loss: 0.0026638509034455637, Final Batch Loss: 0.00011770366836572066\n",
      "Epoch 281, Loss: 0.004318005667300895, Final Batch Loss: 0.0003121155023109168\n",
      "Epoch 282, Loss: 0.00442773748000036, Final Batch Loss: 8.10673154774122e-05\n",
      "Epoch 283, Loss: 0.007011543251792318, Final Batch Loss: 0.00010808269871631637\n",
      "Epoch 284, Loss: 0.0019386662715987768, Final Batch Loss: 5.9723206504713744e-05\n",
      "Epoch 285, Loss: 0.005849199259500892, Final Batch Loss: 1.2805106962332502e-05\n",
      "Epoch 286, Loss: 0.004162306748185074, Final Batch Loss: 0.0006804958102293313\n",
      "Epoch 287, Loss: 0.003897519502970681, Final Batch Loss: 0.00015426248137373477\n",
      "Epoch 288, Loss: 0.0031013453626655973, Final Batch Loss: 6.077065336285159e-05\n",
      "Epoch 289, Loss: 0.0037225859207410394, Final Batch Loss: 0.0003861450240947306\n",
      "Epoch 290, Loss: 0.0033814660378084227, Final Batch Loss: 0.0006838797708041966\n",
      "Epoch 291, Loss: 0.003048243361263303, Final Batch Loss: 1.7039015801856294e-05\n",
      "Epoch 292, Loss: 0.003661449010905926, Final Batch Loss: 0.0007752887322567403\n",
      "Epoch 293, Loss: 0.0028058567941116053, Final Batch Loss: 0.00011295603326288983\n",
      "Epoch 294, Loss: 0.003617485655922792, Final Batch Loss: 5.417669308371842e-05\n",
      "Epoch 295, Loss: 0.013073464699118631, Final Batch Loss: 0.00011765560338972136\n",
      "Epoch 296, Loss: 0.02019150808541781, Final Batch Loss: 0.00014608031779062003\n",
      "Epoch 297, Loss: 0.028530667604172777, Final Batch Loss: 0.00023668573703616858\n",
      "Epoch 298, Loss: 0.004795448590812157, Final Batch Loss: 0.00021597201703116298\n",
      "Epoch 299, Loss: 0.003259341780903924, Final Batch Loss: 0.0001324377371929586\n",
      "Epoch 300, Loss: 0.001681453602941474, Final Batch Loss: 0.00010343931353418157\n",
      "Epoch 301, Loss: 0.010821183474035934, Final Batch Loss: 0.00015686960250604898\n",
      "Epoch 302, Loss: 0.002498142543117865, Final Batch Loss: 3.1079463951755315e-05\n",
      "Epoch 303, Loss: 0.007826574410501053, Final Batch Loss: 1.9048640751861967e-05\n",
      "Epoch 304, Loss: 0.003992702449977514, Final Batch Loss: 3.89192791772075e-05\n",
      "Epoch 305, Loss: 0.005884205423171807, Final Batch Loss: 2.8156708140159026e-05\n",
      "Epoch 306, Loss: 0.02315541859570658, Final Batch Loss: 0.00040220559458248317\n",
      "Epoch 307, Loss: 0.006741998187408171, Final Batch Loss: 0.00011971992353210226\n",
      "Epoch 308, Loss: 0.003224744643375743, Final Batch Loss: 8.994551171781495e-05\n",
      "Epoch 309, Loss: 0.005377961902922834, Final Batch Loss: 0.00012428588524926454\n",
      "Epoch 310, Loss: 0.0028887255848530913, Final Batch Loss: 0.00016918627079576254\n",
      "Epoch 311, Loss: 0.007179385574090702, Final Batch Loss: 5.306812090566382e-05\n",
      "Epoch 312, Loss: 0.001945782585607958, Final Batch Loss: 0.00019108715059701353\n",
      "Epoch 313, Loss: 0.003146877492326894, Final Batch Loss: 1.583861194376368e-05\n",
      "Epoch 314, Loss: 0.0036467360023380024, Final Batch Loss: 1.5414098015753552e-05\n",
      "Epoch 315, Loss: 0.00415765787147393, Final Batch Loss: 1.1663931218208745e-05\n",
      "Epoch 316, Loss: 0.0642689188202894, Final Batch Loss: 4.69455226266291e-05\n",
      "Epoch 317, Loss: 0.009301230544224381, Final Batch Loss: 3.690915764309466e-05\n",
      "Epoch 318, Loss: 0.007046074755635345, Final Batch Loss: 3.698458385770209e-05\n",
      "Epoch 319, Loss: 0.0009792437840587809, Final Batch Loss: 3.5470284274197184e-06\n",
      "Epoch 320, Loss: 0.0077949351816641865, Final Batch Loss: 2.1085672415210865e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321, Loss: 0.004729426992525987, Final Batch Loss: 2.4298304197145626e-05\n",
      "Epoch 322, Loss: 0.0024790758689050563, Final Batch Loss: 0.00030219421023502946\n",
      "Epoch 323, Loss: 0.0019684015305756475, Final Batch Loss: 1.8563330741017126e-05\n",
      "Epoch 324, Loss: 0.0023594746226081043, Final Batch Loss: 0.0006288277800194919\n",
      "Epoch 325, Loss: 0.005474295209523916, Final Batch Loss: 1.7501550246379338e-05\n",
      "Epoch 326, Loss: 0.00886429775346187, Final Batch Loss: 0.00023944169515743852\n",
      "Epoch 327, Loss: 0.0029825938988778944, Final Batch Loss: 1.6787260392447934e-05\n",
      "Epoch 328, Loss: 0.001074960704499972, Final Batch Loss: 0.00010250038030790165\n",
      "Epoch 329, Loss: 0.005295583032420836, Final Batch Loss: 0.0012275089975446463\n",
      "Epoch 330, Loss: 0.0018651440886969795, Final Batch Loss: 0.00033743554376997054\n",
      "Epoch 331, Loss: 0.0012219293553243915, Final Batch Loss: 2.1499557988136075e-05\n",
      "Epoch 332, Loss: 0.03214494119220035, Final Batch Loss: 2.685606523300521e-05\n",
      "Epoch 333, Loss: 0.006364617255712801, Final Batch Loss: 0.002087702276185155\n",
      "Epoch 334, Loss: 0.005002980626159115, Final Batch Loss: 0.0013836189173161983\n",
      "Epoch 335, Loss: 0.030004114290932193, Final Batch Loss: 0.00011677788279484957\n",
      "Epoch 336, Loss: 0.007345263516072009, Final Batch Loss: 1.0866827324207406e-05\n",
      "Epoch 337, Loss: 0.003657995102912537, Final Batch Loss: 6.647320697084069e-05\n",
      "Epoch 338, Loss: 0.004316871432820335, Final Batch Loss: 0.00022051611449569464\n",
      "Epoch 339, Loss: 0.004306259038457938, Final Batch Loss: 0.0005946634919382632\n",
      "Epoch 340, Loss: 0.005062126744633133, Final Batch Loss: 0.00016433997370768338\n",
      "Epoch 341, Loss: 0.0013036647023909609, Final Batch Loss: 0.00023437102208845317\n",
      "Epoch 342, Loss: 0.0024727488184907997, Final Batch Loss: 3.798115358222276e-05\n",
      "Epoch 343, Loss: 0.0046185649507606286, Final Batch Loss: 0.00016163203690666705\n",
      "Epoch 344, Loss: 0.002122206019294026, Final Batch Loss: 3.7693969261454185e-06\n",
      "Epoch 345, Loss: 0.0021842940429905866, Final Batch Loss: 6.266741547733545e-05\n",
      "Epoch 346, Loss: 0.004576450227659734, Final Batch Loss: 3.5711041164177004e-06\n",
      "Epoch 347, Loss: 0.0008949158174118566, Final Batch Loss: 6.138917524367571e-05\n",
      "Epoch 348, Loss: 0.003198775262262643, Final Batch Loss: 0.00016002854681573808\n",
      "Epoch 349, Loss: 0.006793652722535626, Final Batch Loss: 0.00028580884099937975\n",
      "Epoch 350, Loss: 0.0023115679409784207, Final Batch Loss: 0.00010046159877674654\n",
      "Epoch 351, Loss: 0.009518784460397, Final Batch Loss: 0.00040472435648553073\n",
      "Epoch 352, Loss: 0.008827461511373258, Final Batch Loss: 2.5885967261274345e-05\n",
      "Epoch 353, Loss: 0.004511455087595095, Final Batch Loss: 4.403164712130092e-05\n",
      "Epoch 354, Loss: 0.001890350972644228, Final Batch Loss: 0.0006000639987178147\n",
      "Epoch 355, Loss: 0.003569868186787062, Final Batch Loss: 0.00014896455104462802\n",
      "Epoch 356, Loss: 0.013158080424545915, Final Batch Loss: 8.211627573473379e-05\n",
      "Epoch 357, Loss: 0.008615440674475394, Final Batch Loss: 1.2742058970616199e-05\n",
      "Epoch 358, Loss: 0.0045525791647378355, Final Batch Loss: 0.001051005907356739\n",
      "Epoch 359, Loss: 0.0046830002061142295, Final Batch Loss: 0.0012939891312271357\n",
      "Epoch 360, Loss: 0.03197772554540279, Final Batch Loss: 9.513667464489117e-05\n",
      "Epoch 361, Loss: 0.002843564029717527, Final Batch Loss: 4.6752651542192325e-05\n",
      "Epoch 362, Loss: 0.014797952730987163, Final Batch Loss: 8.01118731033057e-05\n",
      "Epoch 363, Loss: 0.005762739608144329, Final Batch Loss: 9.570779366185889e-05\n",
      "Epoch 364, Loss: 0.006850041697816778, Final Batch Loss: 9.293103175878059e-06\n",
      "Epoch 365, Loss: 0.0022350913677655626, Final Batch Loss: 0.00020549084001686424\n",
      "Epoch 366, Loss: 0.002050115166184696, Final Batch Loss: 0.00014822981029283255\n",
      "Epoch 367, Loss: 0.004672259225117159, Final Batch Loss: 7.699932757532224e-05\n",
      "Epoch 368, Loss: 0.0011490958477224922, Final Batch Loss: 1.8473012460162863e-05\n",
      "Epoch 369, Loss: 0.00404910194220065, Final Batch Loss: 0.00011878296209033579\n",
      "Epoch 370, Loss: 0.0013022046905462048, Final Batch Loss: 0.00011273693962721154\n",
      "Epoch 371, Loss: 0.0019302431619507843, Final Batch Loss: 2.371927439526189e-05\n",
      "Epoch 372, Loss: 0.0011707322596521408, Final Batch Loss: 4.509335667535197e-06\n",
      "Epoch 373, Loss: 0.0015461180764759774, Final Batch Loss: 0.0002514727821107954\n",
      "Epoch 374, Loss: 0.0031448046438526944, Final Batch Loss: 2.287233655806631e-05\n",
      "Epoch 375, Loss: 0.0008173959698183353, Final Batch Loss: 9.880475772661157e-06\n",
      "Epoch 376, Loss: 0.0010250393493151932, Final Batch Loss: 2.632502855703933e-06\n",
      "Epoch 377, Loss: 0.00584811535964036, Final Batch Loss: 1.5290714145521633e-05\n",
      "Epoch 378, Loss: 0.0034166741788794752, Final Batch Loss: 2.8715458029182628e-05\n",
      "Epoch 379, Loss: 0.0011366155440555303, Final Batch Loss: 1.2749173038173467e-05\n",
      "Epoch 380, Loss: 0.0010705503436838626, Final Batch Loss: 4.294201426091604e-05\n",
      "Epoch 381, Loss: 0.007905200758614228, Final Batch Loss: 0.00015622173668816686\n",
      "Epoch 382, Loss: 0.0016551169069884963, Final Batch Loss: 3.78716504201293e-05\n",
      "Epoch 383, Loss: 0.0066194572452786815, Final Batch Loss: 1.0293395462213084e-05\n",
      "Epoch 384, Loss: 0.0026779375385217463, Final Batch Loss: 0.0009140067268162966\n",
      "Epoch 385, Loss: 0.0011158340826114, Final Batch Loss: 3.846404069918208e-06\n",
      "Epoch 386, Loss: 0.0045690920476033625, Final Batch Loss: 3.9971706428332254e-05\n",
      "Epoch 387, Loss: 0.005701045560726925, Final Batch Loss: 0.0011376877082511783\n",
      "Epoch 388, Loss: 0.006514673060564746, Final Batch Loss: 6.389217014657333e-05\n",
      "Epoch 389, Loss: 0.0012855092673476065, Final Batch Loss: 1.5481086848012637e-06\n",
      "Epoch 390, Loss: 0.003510582047056232, Final Batch Loss: 2.4860744815669023e-05\n",
      "Epoch 391, Loss: 0.005985660994610953, Final Batch Loss: 2.308539296791423e-05\n",
      "Epoch 392, Loss: 0.0015966219998517772, Final Batch Loss: 6.183591904118657e-05\n",
      "Epoch 393, Loss: 0.0005784430356925441, Final Batch Loss: 0.00012502571917138994\n",
      "Epoch 394, Loss: 0.002215394581980945, Final Batch Loss: 6.298387597780675e-05\n",
      "Epoch 395, Loss: 0.0004458631898387466, Final Batch Loss: 3.948783705709502e-05\n",
      "Epoch 396, Loss: 0.005940870974868062, Final Batch Loss: 8.34570346341934e-06\n",
      "Epoch 397, Loss: 0.0008013650149223395, Final Batch Loss: 0.0003242120728828013\n",
      "Epoch 398, Loss: 0.0011123290191790147, Final Batch Loss: 6.935592864465434e-06\n",
      "Epoch 399, Loss: 0.0007403862542219031, Final Batch Loss: 1.970715675270185e-05\n",
      "Epoch 400, Loss: 0.001836213738670267, Final Batch Loss: 0.00047776842257007957\n",
      "Epoch 401, Loss: 0.0005260307356707017, Final Batch Loss: 2.0120849512750283e-05\n",
      "Epoch 402, Loss: 0.0028075985547957316, Final Batch Loss: 0.00019764277385547757\n",
      "Epoch 403, Loss: 0.0005612071963128074, Final Batch Loss: 1.6691892597009428e-05\n",
      "Epoch 404, Loss: 0.001149368652022531, Final Batch Loss: 4.304237518226728e-05\n",
      "Epoch 405, Loss: 0.004101710279542203, Final Batch Loss: 0.003965782467275858\n",
      "Epoch 406, Loss: 0.00451969891707904, Final Batch Loss: 6.573608698090538e-05\n",
      "Epoch 407, Loss: 0.001043824492285239, Final Batch Loss: 1.7350108464597724e-05\n",
      "Epoch 408, Loss: 0.001657173874093587, Final Batch Loss: 0.00016994879115372896\n",
      "Epoch 409, Loss: 0.003714627623438105, Final Batch Loss: 3.2016552722780034e-05\n",
      "Epoch 410, Loss: 0.0017300805820923415, Final Batch Loss: 2.9165359592298046e-05\n",
      "Epoch 411, Loss: 0.0001434236774571218, Final Batch Loss: 8.742889804125298e-06\n",
      "Epoch 412, Loss: 0.0010249025147004431, Final Batch Loss: 9.910593689710367e-06\n",
      "Epoch 413, Loss: 0.00046334990202012705, Final Batch Loss: 2.1076741177239455e-05\n",
      "Epoch 414, Loss: 0.0012800437748978766, Final Batch Loss: 9.065475410352519e-07\n",
      "Epoch 415, Loss: 0.00575228645993775, Final Batch Loss: 4.300903583498439e-06\n",
      "Epoch 416, Loss: 0.002781282989730016, Final Batch Loss: 1.9971123492723564e-06\n",
      "Epoch 417, Loss: 0.0005531523011939043, Final Batch Loss: 0.00035504429251886904\n",
      "Epoch 418, Loss: 0.00394217274825337, Final Batch Loss: 0.00021202194329816848\n",
      "Epoch 419, Loss: 0.00038748555726897393, Final Batch Loss: 5.234166110312799e-06\n",
      "Epoch 420, Loss: 0.0003655734796836896, Final Batch Loss: 1.5538685147475917e-06\n",
      "Epoch 421, Loss: 0.0028893373854756987, Final Batch Loss: 1.2577786947076675e-05\n",
      "Epoch 422, Loss: 0.010305400012299515, Final Batch Loss: 7.210677722468972e-05\n",
      "Epoch 423, Loss: 0.0008319028015648655, Final Batch Loss: 0.0006480825832113624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424, Loss: 0.0005263811213467307, Final Batch Loss: 4.680639449361479e-06\n",
      "Epoch 425, Loss: 0.0003123923436234577, Final Batch Loss: 1.7893769381771563e-06\n",
      "Epoch 426, Loss: 0.00017217356432297493, Final Batch Loss: 4.2827625179597817e-07\n",
      "Epoch 427, Loss: 0.0006503042022814043, Final Batch Loss: 8.497876251567504e-07\n",
      "Epoch 428, Loss: 0.0013357791058226098, Final Batch Loss: 9.27715220200298e-08\n",
      "Epoch 429, Loss: 0.0005467494167703535, Final Batch Loss: 2.4435016712232027e-06\n",
      "Epoch 430, Loss: 0.0005858575894990281, Final Batch Loss: 1.0397598089184612e-05\n",
      "Epoch 431, Loss: 0.0013091820597708193, Final Batch Loss: 2.4940884486568393e-06\n",
      "Epoch 432, Loss: 0.0009334319479421538, Final Batch Loss: 2.0806594420719193e-06\n",
      "Epoch 433, Loss: 0.00048725712210284655, Final Batch Loss: 5.683364179276396e-06\n",
      "Epoch 434, Loss: 0.005863419481329402, Final Batch Loss: 1.0667382412066218e-05\n",
      "Epoch 435, Loss: 0.004388060318433418, Final Batch Loss: 6.9998523031244986e-06\n",
      "Epoch 436, Loss: 0.0006839965651863622, Final Batch Loss: 2.288862560817506e-05\n",
      "Epoch 437, Loss: 0.005735324572498257, Final Batch Loss: 8.063285349635407e-06\n",
      "Epoch 438, Loss: 0.0008142053970914276, Final Batch Loss: 4.253672614140669e-06\n",
      "Epoch 439, Loss: 0.0016456416950560993, Final Batch Loss: 0.001199872582219541\n",
      "Epoch 440, Loss: 0.00033964164279609577, Final Batch Loss: 4.763368269777857e-05\n",
      "Epoch 441, Loss: 0.0001622155702989403, Final Batch Loss: 1.8357553926762193e-05\n",
      "Epoch 442, Loss: 0.0016690700478818599, Final Batch Loss: 2.8912920697621303e-06\n",
      "Epoch 443, Loss: 0.0005674910230908381, Final Batch Loss: 1.7750394363247324e-06\n",
      "Epoch 444, Loss: 0.0001721272269463725, Final Batch Loss: 4.3237720092292875e-05\n",
      "Epoch 445, Loss: 0.00044540472947574017, Final Batch Loss: 3.6968442600482376e-06\n",
      "Epoch 446, Loss: 0.0005312298583248776, Final Batch Loss: 1.0611400284687988e-05\n",
      "Epoch 447, Loss: 0.00031641555332839744, Final Batch Loss: 9.469699762121309e-06\n",
      "Epoch 448, Loss: 0.000751021158478693, Final Batch Loss: 1.4837363551123417e-06\n",
      "Epoch 449, Loss: 0.0005747062169163542, Final Batch Loss: 1.4615438885812182e-06\n",
      "Epoch 450, Loss: 0.0017167925852987764, Final Batch Loss: 1.8403919739284902e-06\n",
      "Epoch 451, Loss: 0.00020554215672063947, Final Batch Loss: 1.4864726836094633e-05\n",
      "Epoch 452, Loss: 0.0001840921547895391, Final Batch Loss: 8.459991107656606e-08\n",
      "Epoch 453, Loss: 0.00011690233617400736, Final Batch Loss: 3.325177021906711e-05\n",
      "Epoch 454, Loss: 0.0032606851682928095, Final Batch Loss: 2.66543770521821e-06\n",
      "Epoch 455, Loss: 0.003369700055515068, Final Batch Loss: 5.681417405867251e-06\n",
      "Epoch 456, Loss: 0.0004989407374011989, Final Batch Loss: 1.86753040907206e-05\n",
      "Epoch 457, Loss: 0.0012526921839253191, Final Batch Loss: 2.4785767891444266e-06\n",
      "Epoch 458, Loss: 0.00019347296196770003, Final Batch Loss: 3.1547110665997025e-06\n",
      "Epoch 459, Loss: 0.0016636445194535554, Final Batch Loss: 6.100584869273007e-06\n",
      "Epoch 460, Loss: 0.00034868126379983266, Final Batch Loss: 1.7599513739696704e-05\n",
      "Epoch 461, Loss: 0.0006228468394340325, Final Batch Loss: 1.4510014807456173e-06\n",
      "Epoch 462, Loss: 0.0006091682873261561, Final Batch Loss: 5.965108016425802e-07\n",
      "Epoch 463, Loss: 0.0005142212983031413, Final Batch Loss: 5.36896607172821e-07\n",
      "Epoch 464, Loss: 0.00014802570488825495, Final Batch Loss: 1.6343035724730726e-07\n",
      "Epoch 465, Loss: 0.000489836909935093, Final Batch Loss: 6.859036716377886e-07\n",
      "Epoch 466, Loss: 0.0002093749360749797, Final Batch Loss: 9.247881394003343e-07\n",
      "Epoch 467, Loss: 0.0002474473830034185, Final Batch Loss: 1.546713519928744e-06\n",
      "Epoch 468, Loss: 0.00015991898531808602, Final Batch Loss: 1.213755695061991e-05\n",
      "Epoch 469, Loss: 4.173215498326499e-05, Final Batch Loss: 3.082810053456342e-06\n",
      "Epoch 470, Loss: 0.0010768893790782386, Final Batch Loss: 1.0699603080865927e-05\n",
      "Epoch 471, Loss: 4.262211380279268e-05, Final Batch Loss: 1.8804774981617811e-06\n",
      "Epoch 472, Loss: 0.0005881369440352557, Final Batch Loss: 1.118010231948574e-06\n",
      "Epoch 473, Loss: 0.0001817249185362968, Final Batch Loss: 2.0381378362799296e-06\n",
      "Epoch 474, Loss: 0.0006186181316110151, Final Batch Loss: 1.828357426347793e-06\n",
      "Epoch 475, Loss: 6.568632347025982e-05, Final Batch Loss: 1.2213596392030013e-06\n",
      "Epoch 476, Loss: 0.0005486107649801397, Final Batch Loss: 3.5137534723617136e-05\n",
      "Epoch 477, Loss: 0.00011292159231857113, Final Batch Loss: 2.071692790650559e-07\n",
      "Epoch 478, Loss: 0.0009454375174442475, Final Batch Loss: 1.3098014051138307e-06\n",
      "Epoch 479, Loss: 0.005226875392054353, Final Batch Loss: 6.698780453007203e-06\n",
      "Epoch 480, Loss: 0.05232544787432403, Final Batch Loss: 0.00034450239036232233\n",
      "Epoch 481, Loss: 0.09534439271874362, Final Batch Loss: 2.5460374672547914e-05\n",
      "Epoch 482, Loss: 0.03403149150040008, Final Batch Loss: 1.5178886769717792e-06\n",
      "Epoch 483, Loss: 0.06228171147949979, Final Batch Loss: 0.00017116589879151434\n",
      "Epoch 484, Loss: 0.011590051097300602, Final Batch Loss: 0.0001287093764403835\n",
      "Epoch 485, Loss: 0.059447584295412526, Final Batch Loss: 0.03350537270307541\n",
      "Epoch 486, Loss: 0.0033479804233138566, Final Batch Loss: 5.640113522531465e-05\n",
      "Epoch 487, Loss: 0.0038481455649161944, Final Batch Loss: 1.9857136067003012e-05\n",
      "Epoch 488, Loss: 0.0011824609709947254, Final Batch Loss: 8.729164255782962e-05\n",
      "Epoch 489, Loss: 0.0026759624743135646, Final Batch Loss: 2.6337638701079413e-05\n",
      "Epoch 490, Loss: 0.0017756319025465928, Final Batch Loss: 1.4302395356935449e-05\n",
      "Epoch 491, Loss: 0.0014593389828405634, Final Batch Loss: 0.00011296808952465653\n",
      "Epoch 492, Loss: 0.0015260199952535913, Final Batch Loss: 1.4415760233532637e-05\n",
      "Epoch 493, Loss: 0.0015490802861677366, Final Batch Loss: 7.969589933054522e-05\n",
      "Epoch 494, Loss: 0.008954926945079933, Final Batch Loss: 6.348013266688213e-05\n",
      "Epoch 495, Loss: 0.00306050437848171, Final Batch Loss: 6.603459769394249e-05\n",
      "Epoch 496, Loss: 0.0064924668840831146, Final Batch Loss: 0.00040139100747182965\n",
      "Epoch 497, Loss: 0.0018611475748002704, Final Batch Loss: 2.7526175472303294e-05\n",
      "Epoch 498, Loss: 0.0008776833133197215, Final Batch Loss: 0.0005776280886493623\n",
      "Epoch 499, Loss: 0.006181367548833805, Final Batch Loss: 0.0004736997652798891\n",
      "Epoch 500, Loss: 0.00153459184912208, Final Batch Loss: 6.421800935640931e-05\n",
      "Epoch 501, Loss: 0.0005433538107126878, Final Batch Loss: 1.0549440048635006e-05\n",
      "Epoch 502, Loss: 0.0015596028197251144, Final Batch Loss: 0.00013536876940634102\n",
      "Epoch 503, Loss: 0.01489006402493942, Final Batch Loss: 7.2387815635011066e-06\n",
      "Epoch 504, Loss: 0.0030087960517448664, Final Batch Loss: 7.514145636378089e-06\n",
      "Epoch 505, Loss: 0.0014935585161879317, Final Batch Loss: 0.00016881676856428385\n",
      "Epoch 506, Loss: 0.006847379714372437, Final Batch Loss: 1.6515068637090735e-05\n",
      "Epoch 507, Loss: 0.00034126557306990435, Final Batch Loss: 1.9616436475189403e-05\n",
      "Epoch 508, Loss: 0.00034154046011281025, Final Batch Loss: 8.857630018610507e-05\n",
      "Epoch 509, Loss: 0.00044407992436390487, Final Batch Loss: 3.149414624203928e-05\n",
      "Epoch 510, Loss: 0.0011527012952683435, Final Batch Loss: 8.60526597534772e-06\n",
      "Epoch 511, Loss: 0.009876505381498646, Final Batch Loss: 1.9715564121725038e-05\n",
      "Epoch 512, Loss: 0.0027016934241714807, Final Batch Loss: 0.0011416568886488676\n",
      "Epoch 513, Loss: 0.001218221491399163, Final Batch Loss: 2.9898205866629723e-07\n",
      "Epoch 514, Loss: 0.004796538223388325, Final Batch Loss: 1.193297612189781e-05\n",
      "Epoch 515, Loss: 0.0002244607635475404, Final Batch Loss: 1.2455801879696082e-05\n",
      "Epoch 516, Loss: 0.004411039452804744, Final Batch Loss: 9.941939060809091e-05\n",
      "Epoch 517, Loss: 0.0016857108870453885, Final Batch Loss: 9.709481673780829e-05\n",
      "Epoch 518, Loss: 0.0005175330954898527, Final Batch Loss: 3.428765921853483e-05\n",
      "Epoch 519, Loss: 0.010183481657008997, Final Batch Loss: 2.0819548808503896e-05\n",
      "Epoch 520, Loss: 0.002903410684780283, Final Batch Loss: 1.73598039054923e-06\n",
      "Epoch 521, Loss: 0.0007681303886784008, Final Batch Loss: 2.336481884412933e-06\n",
      "Epoch 522, Loss: 0.001071123449037259, Final Batch Loss: 6.853723334643291e-06\n",
      "Epoch 523, Loss: 0.0012265495565770834, Final Batch Loss: 1.0664812180039007e-05\n",
      "Epoch 524, Loss: 0.0026380644490018312, Final Batch Loss: 0.0001903114898595959\n",
      "Epoch 525, Loss: 0.0014749552305488578, Final Batch Loss: 0.00022311974316835403\n",
      "Epoch 526, Loss: 0.00391838830796587, Final Batch Loss: 3.678528082673438e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527, Loss: 0.022366060420040412, Final Batch Loss: 8.024579983612057e-06\n",
      "Epoch 528, Loss: 0.000927909591922571, Final Batch Loss: 4.009152689832263e-05\n",
      "Epoch 529, Loss: 0.008723378052309272, Final Batch Loss: 4.07123343393323e-06\n",
      "Epoch 530, Loss: 0.001575234172605633, Final Batch Loss: 0.00041543165571056306\n",
      "Epoch 531, Loss: 0.0007425942137615493, Final Batch Loss: 4.403487764648162e-06\n",
      "Epoch 532, Loss: 0.0006962729526094336, Final Batch Loss: 2.143367782991845e-05\n",
      "Epoch 533, Loss: 0.011959128250623507, Final Batch Loss: 0.010542205534875393\n",
      "Epoch 534, Loss: 0.01714404044105322, Final Batch Loss: 0.00942120049148798\n",
      "Epoch 535, Loss: 0.014775246186815139, Final Batch Loss: 3.7936079024802893e-05\n",
      "Epoch 536, Loss: 0.06385932588216292, Final Batch Loss: 0.02723708562552929\n",
      "Epoch 537, Loss: 0.001410533709986339, Final Batch Loss: 0.00011350673594279215\n",
      "Epoch 538, Loss: 0.019765353090861026, Final Batch Loss: 0.009547065943479538\n",
      "Epoch 539, Loss: 0.0024796345062441105, Final Batch Loss: 7.476044265786186e-05\n",
      "Epoch 540, Loss: 0.0009805708582462103, Final Batch Loss: 1.0254764674755279e-05\n",
      "Epoch 541, Loss: 0.002032645249073539, Final Batch Loss: 9.407634206581861e-05\n",
      "Epoch 542, Loss: 0.0013470369694914552, Final Batch Loss: 1.2156765478721354e-05\n",
      "Epoch 543, Loss: 0.0010468479511018813, Final Batch Loss: 8.352026270586066e-06\n",
      "Epoch 544, Loss: 0.0025990434153300157, Final Batch Loss: 1.849171894718893e-05\n",
      "Epoch 545, Loss: 0.0007267982223311265, Final Batch Loss: 1.2180084922874812e-05\n",
      "Epoch 546, Loss: 0.0009747923168106354, Final Batch Loss: 2.229419806099031e-05\n",
      "Epoch 547, Loss: 0.0016826815187869215, Final Batch Loss: 2.289348230988253e-06\n",
      "Epoch 548, Loss: 0.0005877267003597808, Final Batch Loss: 3.26881418004632e-05\n",
      "Epoch 549, Loss: 0.0039683961608716345, Final Batch Loss: 2.1773268599645235e-05\n",
      "Epoch 550, Loss: 0.0007007216826195872, Final Batch Loss: 1.1506381270010024e-05\n",
      "Epoch 551, Loss: 0.0005363504907336392, Final Batch Loss: 2.003833969865809e-06\n",
      "Epoch 552, Loss: 0.0009389079955326451, Final Batch Loss: 4.363268817542121e-05\n",
      "Epoch 553, Loss: 0.0004179179666152777, Final Batch Loss: 4.001609795523109e-06\n",
      "Epoch 554, Loss: 0.00045482443385935767, Final Batch Loss: 0.00013291057257447392\n",
      "Epoch 555, Loss: 0.00840462188125457, Final Batch Loss: 5.341852556739468e-06\n",
      "Epoch 556, Loss: 0.0017592399785826274, Final Batch Loss: 8.040575630730018e-05\n",
      "Epoch 557, Loss: 0.000943908440603991, Final Batch Loss: 2.3576079911435954e-05\n",
      "Epoch 558, Loss: 0.006793840223792813, Final Batch Loss: 1.5151288607739843e-05\n",
      "Epoch 559, Loss: 0.0005604972107562389, Final Batch Loss: 8.411710155087349e-07\n",
      "Epoch 560, Loss: 0.008120818217889791, Final Batch Loss: 1.0263196600135416e-05\n",
      "Epoch 561, Loss: 0.001438002665508975, Final Batch Loss: 3.1773975024407264e-06\n",
      "Epoch 562, Loss: 0.0009616878107863158, Final Batch Loss: 2.0341232811915688e-05\n",
      "Epoch 563, Loss: 0.001856922530976135, Final Batch Loss: 9.057115676114336e-06\n",
      "Epoch 564, Loss: 0.002113665467732062, Final Batch Loss: 1.3059808225079905e-05\n",
      "Epoch 565, Loss: 0.0002660511868270987, Final Batch Loss: 7.137448119465262e-05\n",
      "Epoch 566, Loss: 0.0036592639655737003, Final Batch Loss: 0.00011848046415252611\n",
      "Epoch 567, Loss: 0.0005441497708034149, Final Batch Loss: 1.8495152289688122e-06\n",
      "Epoch 568, Loss: 0.00045974164748940893, Final Batch Loss: 2.618272992549464e-05\n",
      "Epoch 569, Loss: 0.0006560750583162189, Final Batch Loss: 6.911516720720101e-06\n",
      "Epoch 570, Loss: 0.005114160068615092, Final Batch Loss: 1.9311946743982844e-05\n",
      "Epoch 571, Loss: 0.0015416927678870707, Final Batch Loss: 1.4924455172149464e-05\n",
      "Epoch 572, Loss: 0.0007234140912260045, Final Batch Loss: 7.282895967364311e-05\n",
      "Epoch 573, Loss: 0.0011615926986223712, Final Batch Loss: 3.7265365335770184e-06\n",
      "Epoch 574, Loss: 0.00047825139336055145, Final Batch Loss: 2.5444867333135335e-06\n",
      "Epoch 575, Loss: 0.0010385201579765635, Final Batch Loss: 3.0437775421887636e-05\n",
      "Epoch 576, Loss: 0.003322962282481967, Final Batch Loss: 0.00015840541163925081\n",
      "Epoch 577, Loss: 0.00026489606034374447, Final Batch Loss: 2.231126927654259e-05\n",
      "Epoch 578, Loss: 0.0023294363987815814, Final Batch Loss: 0.0001206919114338234\n",
      "Epoch 579, Loss: 0.0003921300879028422, Final Batch Loss: 7.157820073189214e-05\n",
      "Epoch 580, Loss: 0.0003630287579881042, Final Batch Loss: 9.64225705502031e-07\n",
      "Epoch 581, Loss: 0.0013515387121856293, Final Batch Loss: 6.690022019029129e-06\n",
      "Epoch 582, Loss: 0.00022069945453040418, Final Batch Loss: 6.080466619096114e-07\n",
      "Epoch 583, Loss: 0.000714923833101011, Final Batch Loss: 2.2142523448565044e-05\n",
      "Epoch 584, Loss: 0.0030538001240074664, Final Batch Loss: 7.525829914811766e-06\n",
      "Epoch 585, Loss: 0.00024531040051556374, Final Batch Loss: 4.594122856360627e-06\n",
      "Epoch 586, Loss: 0.0003266309364775566, Final Batch Loss: 5.811376126985124e-07\n",
      "Epoch 587, Loss: 0.0003783253479241466, Final Batch Loss: 3.461646701907739e-05\n",
      "Epoch 588, Loss: 0.0004744947782739928, Final Batch Loss: 3.2170182748814113e-06\n",
      "Epoch 589, Loss: 0.0028433609348894606, Final Batch Loss: 3.8702569327142555e-06\n",
      "Epoch 590, Loss: 0.0003760695469097186, Final Batch Loss: 1.959927612915635e-05\n",
      "Epoch 591, Loss: 9.580531228436939e-05, Final Batch Loss: 8.666700523463078e-06\n",
      "Epoch 592, Loss: 0.0001600211521122219, Final Batch Loss: 1.980274282686878e-05\n",
      "Epoch 593, Loss: 0.00010929678095550344, Final Batch Loss: 1.932065060827881e-06\n",
      "Epoch 594, Loss: 0.0003917881459187811, Final Batch Loss: 4.327901024225866e-06\n",
      "Epoch 595, Loss: 0.0006686685394186043, Final Batch Loss: 7.104510586941615e-05\n",
      "Epoch 596, Loss: 0.00037062973336787763, Final Batch Loss: 4.480586540012155e-06\n",
      "Epoch 597, Loss: 0.002499586893804917, Final Batch Loss: 1.9888568658643635e-06\n",
      "Epoch 598, Loss: 0.0003881361787136939, Final Batch Loss: 4.1193618471879745e-07\n",
      "Epoch 599, Loss: 0.0012609273096586548, Final Batch Loss: 6.572960955963936e-06\n",
      "Epoch 600, Loss: 0.0002941378996581534, Final Batch Loss: 4.577240815706318e-06\n",
      "Epoch 601, Loss: 0.0003739290866064948, Final Batch Loss: 9.454593623559049e-07\n",
      "Epoch 602, Loss: 0.002187545623620224, Final Batch Loss: 0.00010912231664406136\n",
      "Epoch 603, Loss: 0.0001232883900286197, Final Batch Loss: 2.537992429552105e-07\n",
      "Epoch 604, Loss: 0.0010775875833815007, Final Batch Loss: 4.2683711853896966e-07\n",
      "Epoch 605, Loss: 0.00012938486078795108, Final Batch Loss: 1.610163394616393e-06\n",
      "Epoch 606, Loss: 0.0012863011174317762, Final Batch Loss: 1.210250957228709e-06\n",
      "Epoch 607, Loss: 0.0002451086223800303, Final Batch Loss: 2.5804576580412686e-05\n",
      "Epoch 608, Loss: 0.00024183040778780196, Final Batch Loss: 2.689189614102361e-06\n",
      "Epoch 609, Loss: 0.0023326938783156947, Final Batch Loss: 8.339415558111796e-07\n",
      "Epoch 610, Loss: 0.00212045685486828, Final Batch Loss: 1.1309647334201145e-06\n",
      "Epoch 611, Loss: 0.002728273136128223, Final Batch Loss: 2.3058364604366943e-05\n",
      "Epoch 612, Loss: 0.001025495202725324, Final Batch Loss: 2.145747021131683e-05\n",
      "Epoch 613, Loss: 0.00023023394831156452, Final Batch Loss: 0.00015376493684016168\n",
      "Epoch 614, Loss: 0.00026722562870418187, Final Batch Loss: 5.187848364585079e-05\n",
      "Epoch 615, Loss: 0.00031110324555072566, Final Batch Loss: 2.0537116142804734e-05\n",
      "Epoch 616, Loss: 0.001396107128272206, Final Batch Loss: 1.2732485856759013e-06\n",
      "Epoch 617, Loss: 0.0006613955893328693, Final Batch Loss: 4.178610470262356e-05\n",
      "Epoch 618, Loss: 0.0005994478431587957, Final Batch Loss: 6.716380448779091e-05\n",
      "Epoch 619, Loss: 0.002367327832018873, Final Batch Loss: 0.00011544937297003344\n",
      "Epoch 620, Loss: 0.0060610209161025, Final Batch Loss: 3.822875441983342e-06\n",
      "Epoch 621, Loss: 0.0004097283496093951, Final Batch Loss: 5.572439113166183e-05\n",
      "Epoch 622, Loss: 0.001744212085441177, Final Batch Loss: 4.944376541970996e-06\n",
      "Epoch 623, Loss: 0.008631945284783171, Final Batch Loss: 0.0020592075306922197\n",
      "Epoch 624, Loss: 0.02814537484530888, Final Batch Loss: 1.3074513560695777e-07\n",
      "Epoch 625, Loss: 0.006895599192823454, Final Batch Loss: 5.420517027232563e-06\n",
      "Epoch 626, Loss: 0.005004559528572372, Final Batch Loss: 3.8080363538028905e-06\n",
      "Epoch 627, Loss: 0.0003010430656900098, Final Batch Loss: 1.245459498022683e-05\n",
      "Epoch 628, Loss: 0.0013492096848040092, Final Batch Loss: 0.00012887621414847672\n",
      "Epoch 629, Loss: 0.0005169135605456177, Final Batch Loss: 7.325997103180271e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 630, Loss: 0.00040985729390285996, Final Batch Loss: 0.00014577143883798271\n",
      "Epoch 631, Loss: 0.0018516734490958697, Final Batch Loss: 1.2713230717054103e-06\n",
      "Epoch 632, Loss: 0.002118451248350084, Final Batch Loss: 8.833797437546309e-06\n",
      "Epoch 633, Loss: 0.002581778858797179, Final Batch Loss: 0.00018599553732201457\n",
      "Epoch 634, Loss: 0.0017710681115090665, Final Batch Loss: 5.758867700933479e-05\n",
      "Epoch 635, Loss: 0.0004217921375300193, Final Batch Loss: 3.924734755855752e-06\n",
      "Epoch 636, Loss: 0.0002797235722482583, Final Batch Loss: 2.475665269230376e-06\n",
      "Epoch 637, Loss: 0.002147298006661913, Final Batch Loss: 0.00040288909804075956\n",
      "Epoch 638, Loss: 0.0021854680142041616, Final Batch Loss: 1.4635859315603739e-06\n",
      "Epoch 639, Loss: 0.00024395162142809568, Final Batch Loss: 9.944845942300162e-07\n",
      "Epoch 640, Loss: 0.00040928931622374876, Final Batch Loss: 2.444615574859199e-06\n",
      "Epoch 641, Loss: 0.00029359790923422224, Final Batch Loss: 2.8009089874103665e-06\n",
      "Epoch 642, Loss: 0.00015654183241053943, Final Batch Loss: 2.7053136363974772e-05\n",
      "Epoch 643, Loss: 0.0027861984618766655, Final Batch Loss: 0.0023121500853449106\n",
      "Epoch 644, Loss: 0.00027615497755562046, Final Batch Loss: 3.37436574682215e-07\n",
      "Epoch 645, Loss: 0.029462864666498945, Final Batch Loss: 3.1654767553845886e-06\n",
      "Epoch 646, Loss: 0.02104856416030998, Final Batch Loss: 7.5652310442819726e-06\n",
      "Epoch 647, Loss: 0.014534451441477358, Final Batch Loss: 7.655017725483049e-06\n",
      "Epoch 648, Loss: 0.0006452107900258852, Final Batch Loss: 3.303689300082624e-05\n",
      "Epoch 649, Loss: 0.0014532690227042622, Final Batch Loss: 0.0005731216515414417\n",
      "Epoch 650, Loss: 0.0006803733435845061, Final Batch Loss: 6.598155596293509e-05\n",
      "Epoch 651, Loss: 0.0006641909003519686, Final Batch Loss: 3.1343315640697256e-05\n",
      "Epoch 652, Loss: 0.023759750773933774, Final Batch Loss: 0.001890685991384089\n",
      "Epoch 653, Loss: 0.005520888993430617, Final Batch Loss: 0.0005967001197859645\n",
      "Epoch 654, Loss: 0.0004597403834054603, Final Batch Loss: 8.152208010869799e-07\n",
      "Epoch 655, Loss: 0.0007201511817527262, Final Batch Loss: 1.566123501106631e-05\n",
      "Epoch 656, Loss: 0.0004761436857734225, Final Batch Loss: 2.0077799490536563e-05\n",
      "Epoch 657, Loss: 0.001527592416096013, Final Batch Loss: 2.4964325348264538e-05\n",
      "Epoch 658, Loss: 0.00041662971807454596, Final Batch Loss: 0.0001189189133583568\n",
      "Epoch 659, Loss: 0.0010005538010773307, Final Batch Loss: 4.916183024761267e-05\n",
      "Epoch 660, Loss: 0.0005789884409068691, Final Batch Loss: 9.925125596055295e-06\n",
      "Epoch 661, Loss: 0.000747942139071256, Final Batch Loss: 5.450084790936671e-05\n",
      "Epoch 662, Loss: 0.0011169305573730526, Final Batch Loss: 0.0001979276566999033\n",
      "Epoch 663, Loss: 0.001956014705825737, Final Batch Loss: 1.972643076442182e-06\n",
      "Epoch 664, Loss: 0.0005896504498252852, Final Batch Loss: 3.5989312891615555e-05\n",
      "Epoch 665, Loss: 0.003252125478866219, Final Batch Loss: 1.1088467317676987e-06\n",
      "Epoch 666, Loss: 0.00018413339591916156, Final Batch Loss: 4.768531653098762e-06\n",
      "Epoch 667, Loss: 0.0006829880487657647, Final Batch Loss: 0.00014974272926338017\n",
      "Epoch 668, Loss: 0.0001961971394308648, Final Batch Loss: 1.2808303608835558e-06\n",
      "Epoch 669, Loss: 0.0003561297659189222, Final Batch Loss: 6.759200459782733e-06\n",
      "Epoch 670, Loss: 0.0002487096556933466, Final Batch Loss: 4.5127180783310905e-06\n",
      "Epoch 671, Loss: 0.0003393792835595377, Final Batch Loss: 8.527166528438102e-07\n",
      "Epoch 672, Loss: 0.0005067282078528024, Final Batch Loss: 8.49857406137744e-06\n",
      "Epoch 673, Loss: 0.00023159691556884354, Final Batch Loss: 2.1346224457374774e-05\n",
      "Epoch 674, Loss: 0.00017628566075700292, Final Batch Loss: 1.7286914953729138e-05\n",
      "Epoch 675, Loss: 0.0013325127529810743, Final Batch Loss: 6.969485752961191e-07\n",
      "Epoch 676, Loss: 0.0031939017816853266, Final Batch Loss: 3.5936466247221688e-06\n",
      "Epoch 677, Loss: 0.0001549540478436029, Final Batch Loss: 1.9926940240111435e-06\n",
      "Epoch 678, Loss: 0.0003461633952355214, Final Batch Loss: 1.4083950361509778e-07\n",
      "Epoch 679, Loss: 0.00012315677884089382, Final Batch Loss: 1.5923594673949992e-06\n",
      "Epoch 680, Loss: 0.00023195653784569004, Final Batch Loss: 5.388377530834987e-07\n",
      "Epoch 681, Loss: 0.00039669861490665426, Final Batch Loss: 1.5436455214512534e-05\n",
      "Epoch 682, Loss: 0.0004182449936820376, Final Batch Loss: 8.757559157857031e-07\n",
      "Epoch 683, Loss: 0.0007141164102506536, Final Batch Loss: 1.7741042029228993e-05\n",
      "Epoch 684, Loss: 0.0004744972304706607, Final Batch Loss: 7.964482620081981e-07\n",
      "Epoch 685, Loss: 0.0005360968704941627, Final Batch Loss: 1.639780202822294e-05\n",
      "Epoch 686, Loss: 0.0005207473862185452, Final Batch Loss: 1.2738008081214502e-05\n",
      "Epoch 687, Loss: 6.223923300296974e-05, Final Batch Loss: 8.448907465208322e-06\n",
      "Epoch 688, Loss: 0.0004600882168119824, Final Batch Loss: 0.0002548054326325655\n",
      "Epoch 689, Loss: 0.00043641312117870257, Final Batch Loss: 4.7442242134820845e-07\n",
      "Epoch 690, Loss: 0.000477860817909459, Final Batch Loss: 6.128362201707205e-06\n",
      "Epoch 691, Loss: 0.0007604966596659324, Final Batch Loss: 5.023311587137869e-06\n",
      "Epoch 692, Loss: 0.0002465525329711227, Final Batch Loss: 1.9494916614348767e-06\n",
      "Epoch 693, Loss: 0.00035569624241560405, Final Batch Loss: 2.40431040765543e-06\n",
      "Epoch 694, Loss: 0.00011254022329953983, Final Batch Loss: 1.7448650169171742e-07\n",
      "Epoch 695, Loss: 8.075677403951431e-05, Final Batch Loss: 5.523414529307047e-06\n",
      "Epoch 696, Loss: 0.0006085436116620713, Final Batch Loss: 2.9580448881461052e-06\n",
      "Epoch 697, Loss: 0.00013294463646218446, Final Batch Loss: 1.0618127816997003e-05\n",
      "Epoch 698, Loss: 0.0005175752915320686, Final Batch Loss: 1.3120963558321819e-05\n",
      "Epoch 699, Loss: 0.00018514657443802207, Final Batch Loss: 1.507374327047728e-05\n",
      "Epoch 700, Loss: 0.0008776737270252966, Final Batch Loss: 1.5527351933997124e-05\n",
      "Epoch 701, Loss: 9.44792050745491e-05, Final Batch Loss: 8.165022336470429e-06\n",
      "Epoch 702, Loss: 0.0024806421271250656, Final Batch Loss: 4.277913831174374e-06\n",
      "Epoch 703, Loss: 0.0001823013485395819, Final Batch Loss: 1.1536380739585184e-08\n",
      "Epoch 704, Loss: 8.993147471159091e-05, Final Batch Loss: 2.1954831481707515e-06\n",
      "Epoch 705, Loss: 0.0018388689233859168, Final Batch Loss: 4.803888077731244e-05\n",
      "Epoch 706, Loss: 0.000144529941515259, Final Batch Loss: 2.4599245080025867e-05\n",
      "Epoch 707, Loss: 0.0005302817314500885, Final Batch Loss: 0.00040878605796024203\n",
      "Epoch 708, Loss: 0.0005518701998568076, Final Batch Loss: 1.874661137435396e-08\n",
      "Epoch 709, Loss: 0.001756874393322505, Final Batch Loss: 2.473101812938694e-05\n",
      "Epoch 710, Loss: 0.0015390479901071785, Final Batch Loss: 3.215718038518389e-07\n",
      "Epoch 711, Loss: 0.0010657558853495175, Final Batch Loss: 1.0040981806014315e-06\n",
      "Epoch 712, Loss: 0.0012258581872544028, Final Batch Loss: 4.244761839800049e-06\n",
      "Epoch 713, Loss: 0.01074005425159541, Final Batch Loss: 4.664764674089383e-06\n",
      "Epoch 714, Loss: 0.00022208252893562985, Final Batch Loss: 1.430080010322854e-05\n",
      "Epoch 715, Loss: 0.0004845503298156473, Final Batch Loss: 2.1785340322821867e-06\n",
      "Epoch 716, Loss: 0.0007402926747772653, Final Batch Loss: 1.8842686699827027e-07\n",
      "Epoch 717, Loss: 0.00018691317791308393, Final Batch Loss: 6.306102591224771e-07\n",
      "Epoch 718, Loss: 0.0003289058173123749, Final Batch Loss: 3.662716494545748e-07\n",
      "Epoch 719, Loss: 0.000916270606815317, Final Batch Loss: 1.4965370610298123e-05\n",
      "Epoch 720, Loss: 9.608082260115225e-05, Final Batch Loss: 1.4589317288482562e-05\n",
      "Epoch 721, Loss: 0.0018078809090340542, Final Batch Loss: 1.0963707381961285e-06\n",
      "Epoch 722, Loss: 0.0007409630671375567, Final Batch Loss: 3.0423929274547845e-05\n",
      "Epoch 723, Loss: 0.00014640001847965323, Final Batch Loss: 2.2207258609796554e-07\n",
      "Epoch 724, Loss: 0.0015844746306790114, Final Batch Loss: 0.0014346507377922535\n",
      "Epoch 725, Loss: 0.00029985962538603417, Final Batch Loss: 5.179726940696128e-06\n",
      "Epoch 726, Loss: 4.004658060097199e-05, Final Batch Loss: 4.359436843515141e-06\n",
      "Epoch 727, Loss: 0.0001057065742813279, Final Batch Loss: 1.0286546370252836e-07\n",
      "Epoch 728, Loss: 7.304183085921068e-05, Final Batch Loss: 4.161205652053468e-06\n",
      "Epoch 729, Loss: 0.0016909032845831007, Final Batch Loss: 0.00010706811735872179\n",
      "Epoch 730, Loss: 0.0006381282724845505, Final Batch Loss: 1.7510138832221855e-06\n",
      "Epoch 731, Loss: 0.002979416167306681, Final Batch Loss: 1.5918234339551418e-06\n",
      "Epoch 732, Loss: 0.0001117073864218554, Final Batch Loss: 2.646918801474385e-06\n",
      "Epoch 733, Loss: 0.00013092211598575432, Final Batch Loss: 1.6690286429366097e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 734, Loss: 0.000220230401635213, Final Batch Loss: 0.00011068870662711561\n",
      "Epoch 735, Loss: 9.134263518717489e-05, Final Batch Loss: 2.0309113097027875e-05\n",
      "Epoch 736, Loss: 6.108474691757237e-05, Final Batch Loss: 3.371221828274429e-05\n",
      "Epoch 737, Loss: 0.0006976293726665972, Final Batch Loss: 5.7450301937933546e-06\n",
      "Epoch 738, Loss: 0.00035086742498435797, Final Batch Loss: 1.1597802540563862e-06\n",
      "Epoch 739, Loss: 0.00043144192258637304, Final Batch Loss: 5.046952651355241e-07\n",
      "Epoch 740, Loss: 7.938101255078323e-05, Final Batch Loss: 3.7973862276885484e-08\n",
      "Epoch 741, Loss: 0.00011265232612345244, Final Batch Loss: 3.2108403047459433e-07\n",
      "Epoch 742, Loss: 7.742531226284655e-05, Final Batch Loss: 2.7069841962656938e-05\n",
      "Epoch 743, Loss: 0.0003992375834087625, Final Batch Loss: 8.152110240189359e-06\n",
      "Epoch 744, Loss: 0.00013052035134819562, Final Batch Loss: 3.657943352664006e-07\n",
      "Epoch 745, Loss: 0.0019364261079637402, Final Batch Loss: 3.776400944843772e-06\n",
      "Epoch 746, Loss: 4.1078059570764935e-05, Final Batch Loss: 7.650466613995377e-06\n",
      "Epoch 747, Loss: 0.00030086847880994583, Final Batch Loss: 4.628799104011705e-07\n",
      "Epoch 748, Loss: 0.00015781184394825232, Final Batch Loss: 3.5137384202243993e-07\n",
      "Epoch 749, Loss: 0.000573003538981709, Final Batch Loss: 1.2209224564685428e-07\n",
      "Epoch 750, Loss: 4.377515962517009e-05, Final Batch Loss: 1.2886421245639212e-05\n",
      "Epoch 751, Loss: 0.001522555062528852, Final Batch Loss: 2.715818823162408e-07\n",
      "Epoch 752, Loss: 0.0002363649062475659, Final Batch Loss: 2.3307643459702376e-06\n",
      "Epoch 753, Loss: 0.002817340134962265, Final Batch Loss: 3.8598179230575624e-07\n",
      "Epoch 754, Loss: 0.00017645031352575558, Final Batch Loss: 8.310260568578087e-07\n",
      "Epoch 755, Loss: 0.0016652213571006769, Final Batch Loss: 1.6668259377183858e-06\n",
      "Epoch 756, Loss: 7.028453602409002e-05, Final Batch Loss: 4.2586586346260447e-07\n",
      "Epoch 757, Loss: 8.631926789171018e-05, Final Batch Loss: 1.3851517906005029e-06\n",
      "Epoch 758, Loss: 0.00015444616326476535, Final Batch Loss: 2.964535042337957e-06\n",
      "Epoch 759, Loss: 5.574148350095953e-05, Final Batch Loss: 9.905545084620826e-06\n",
      "Epoch 760, Loss: 0.0014228490487546708, Final Batch Loss: 0.00023723646881990135\n",
      "Epoch 761, Loss: 7.72321883175664e-05, Final Batch Loss: 4.649013135349378e-06\n",
      "Epoch 762, Loss: 0.00024286781925297873, Final Batch Loss: 5.053400400356622e-06\n",
      "Epoch 763, Loss: 0.00016461517049037866, Final Batch Loss: 6.5919989538087975e-06\n",
      "Epoch 764, Loss: 0.00011431222303270872, Final Batch Loss: 1.759276671009502e-07\n",
      "Epoch 765, Loss: 0.000360323275714336, Final Batch Loss: 3.565606220945483e-06\n",
      "Epoch 766, Loss: 0.0023649637554790104, Final Batch Loss: 8.65176843944937e-07\n",
      "Epoch 767, Loss: 0.00018023403806211036, Final Batch Loss: 2.307272595203358e-08\n",
      "Epoch 768, Loss: 0.0008054089788345209, Final Batch Loss: 3.2088403258967446e-06\n",
      "Epoch 769, Loss: 3.3525864898020785e-05, Final Batch Loss: 5.564694220083766e-06\n",
      "Epoch 770, Loss: 8.180174241800842e-05, Final Batch Loss: 3.615136301959865e-05\n",
      "Epoch 771, Loss: 0.0013945406877198252, Final Batch Loss: 3.760911340577877e-06\n",
      "Epoch 772, Loss: 0.00012930281646106323, Final Batch Loss: 1.490107024437748e-07\n",
      "Epoch 773, Loss: 6.0230746590228534e-05, Final Batch Loss: 4.088059085916029e-06\n",
      "Epoch 774, Loss: 0.0014575498020921174, Final Batch Loss: 1.4486499821941834e-06\n",
      "Epoch 775, Loss: 0.0006155691143074904, Final Batch Loss: 2.3312686892040801e-07\n",
      "Epoch 776, Loss: 0.0012691618165018292, Final Batch Loss: 2.1534202687689685e-07\n",
      "Epoch 777, Loss: 3.935486199146965e-05, Final Batch Loss: 1.1938685702261864e-06\n",
      "Epoch 778, Loss: 0.00011135718466803723, Final Batch Loss: 1.922728465331147e-08\n",
      "Epoch 779, Loss: 0.00038033625909494884, Final Batch Loss: 7.505362646043068e-06\n",
      "Epoch 780, Loss: 0.0003724405067657699, Final Batch Loss: 3.9312591979978606e-05\n",
      "Epoch 781, Loss: 3.244872467078608e-05, Final Batch Loss: 4.024827376269968e-06\n",
      "Epoch 782, Loss: 2.1279909424798404e-05, Final Batch Loss: 1.579214199409762e-06\n",
      "Epoch 783, Loss: 2.5361841809790064e-05, Final Batch Loss: 2.9321588712605262e-08\n",
      "Epoch 784, Loss: 1.691992588059854e-05, Final Batch Loss: 4.2251122067682445e-07\n",
      "Epoch 785, Loss: 0.00011729428651197082, Final Batch Loss: 6.45024954337714e-07\n",
      "Epoch 786, Loss: 0.0013317220206481295, Final Batch Loss: 5.272788712318288e-07\n",
      "Epoch 787, Loss: 3.220023977235087e-05, Final Batch Loss: 2.8263445983611746e-07\n",
      "Epoch 788, Loss: 3.275131932989339e-06, Final Batch Loss: 1.7833134791089833e-07\n",
      "Epoch 789, Loss: 0.00019152314311199348, Final Batch Loss: 2.4094711989164352e-05\n",
      "Epoch 790, Loss: 2.3228942572894873e-05, Final Batch Loss: 3.3167012247758976e-08\n",
      "Epoch 791, Loss: 0.00016168189270082678, Final Batch Loss: 2.1390140148014325e-07\n",
      "Epoch 792, Loss: 2.9157766158860454e-05, Final Batch Loss: 1.0046149867548593e-07\n",
      "Epoch 793, Loss: 8.032900933407916e-05, Final Batch Loss: 6.767667741769401e-07\n",
      "Epoch 794, Loss: 0.00010868970272603917, Final Batch Loss: 1.5269528375938535e-05\n",
      "Epoch 795, Loss: 0.0075426186453843025, Final Batch Loss: 0.007527279667556286\n",
      "Epoch 796, Loss: 0.00021564166942189544, Final Batch Loss: 4.6672687403770396e-07\n",
      "Epoch 797, Loss: 1.6868031364580816e-05, Final Batch Loss: 4.240305315761361e-06\n",
      "Epoch 798, Loss: 8.940187399186783e-05, Final Batch Loss: 8.027369347018976e-08\n",
      "Epoch 799, Loss: 4.1221706124972e-05, Final Batch Loss: 1.1295961854784764e-07\n",
      "Epoch 800, Loss: 0.0004914018396675601, Final Batch Loss: 1.9631113445939263e-06\n",
      "Epoch 801, Loss: 1.769423690678451e-05, Final Batch Loss: 2.682818831090117e-06\n",
      "Epoch 802, Loss: 0.00032075675776610524, Final Batch Loss: 3.539454382917029e-06\n",
      "Epoch 803, Loss: 5.6398150000802616e-05, Final Batch Loss: 9.809542689254158e-07\n",
      "Epoch 804, Loss: 0.00010960341807031426, Final Batch Loss: 1.1055688808880859e-08\n",
      "Epoch 805, Loss: 0.041497785193485015, Final Batch Loss: 2.247168140456779e-06\n",
      "Epoch 806, Loss: 0.12988420532201417, Final Batch Loss: 3.112767217317014e-06\n",
      "Epoch 807, Loss: 0.1061459732172807, Final Batch Loss: 0.010002663359045982\n",
      "Epoch 808, Loss: 0.02939939496900479, Final Batch Loss: 0.00016016069275792688\n",
      "Epoch 809, Loss: 0.002890942654630635, Final Batch Loss: 2.0274870621506125e-05\n",
      "Epoch 810, Loss: 0.019456651934888214, Final Batch Loss: 0.00032094158814288676\n",
      "Epoch 811, Loss: 0.0024649222277730587, Final Batch Loss: 0.00032735997228883207\n",
      "Epoch 812, Loss: 0.004260272031388013, Final Batch Loss: 0.003195054829120636\n",
      "Epoch 813, Loss: 0.0022393772123905364, Final Batch Loss: 0.00015372614143416286\n",
      "Epoch 814, Loss: 0.0013971488306196989, Final Batch Loss: 1.4834944522590376e-05\n",
      "Epoch 815, Loss: 0.0018401023612568679, Final Batch Loss: 6.392702198354527e-05\n",
      "Epoch 816, Loss: 0.0022231678121897858, Final Batch Loss: 3.798415491473861e-05\n",
      "Epoch 817, Loss: 0.0007017797406660975, Final Batch Loss: 6.612195284105837e-05\n",
      "Epoch 818, Loss: 0.0020564796850521816, Final Batch Loss: 0.00012342797708697617\n",
      "Epoch 819, Loss: 0.003552469122041657, Final Batch Loss: 0.0005876946961507201\n",
      "Epoch 820, Loss: 0.0005143890507497417, Final Batch Loss: 7.300868310267106e-05\n",
      "Epoch 821, Loss: 0.001266099297367873, Final Batch Loss: 0.0002890525502152741\n",
      "Epoch 822, Loss: 0.0015340351028498844, Final Batch Loss: 0.0001534448965685442\n",
      "Epoch 823, Loss: 0.0005219883289555582, Final Batch Loss: 2.089917188641266e-06\n",
      "Epoch 824, Loss: 0.0006440533466047782, Final Batch Loss: 1.9931288989027962e-05\n",
      "Epoch 825, Loss: 0.0005896004992109738, Final Batch Loss: 5.5295522543019615e-06\n",
      "Epoch 826, Loss: 0.0009418015897608711, Final Batch Loss: 0.00014440987433772534\n",
      "Epoch 827, Loss: 0.0017857760915376275, Final Batch Loss: 6.673738243989646e-05\n",
      "Epoch 828, Loss: 0.007182621193578598, Final Batch Loss: 0.00010405408829683438\n",
      "Epoch 829, Loss: 0.008275281937585532, Final Batch Loss: 9.535487333778292e-05\n",
      "Epoch 830, Loss: 0.0038002526166565076, Final Batch Loss: 0.0012339588720351458\n",
      "Epoch 831, Loss: 0.0006342610909086943, Final Batch Loss: 3.3644671930233017e-05\n",
      "Epoch 832, Loss: 0.000921468144042592, Final Batch Loss: 3.068500882363878e-05\n",
      "Epoch 833, Loss: 0.0006458748312070384, Final Batch Loss: 0.00022294728842098266\n",
      "Epoch 834, Loss: 0.0018055293139696005, Final Batch Loss: 4.568213989841752e-05\n",
      "Epoch 835, Loss: 0.0019379454241743588, Final Batch Loss: 1.3864080756320618e-05\n",
      "Epoch 836, Loss: 0.0017389467411703663, Final Batch Loss: 0.00035598533577285707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837, Loss: 0.0004746490507159251, Final Batch Loss: 5.9330683143343776e-05\n",
      "Epoch 838, Loss: 0.0004852791269058798, Final Batch Loss: 4.775249180966057e-06\n",
      "Epoch 839, Loss: 0.005514430234029533, Final Batch Loss: 3.199353159288876e-05\n",
      "Epoch 840, Loss: 0.00042235258706568857, Final Batch Loss: 3.093960458500078e-06\n",
      "Epoch 841, Loss: 0.0026382927621853014, Final Batch Loss: 8.997512850328349e-06\n",
      "Epoch 842, Loss: 0.0003877678362869119, Final Batch Loss: 2.2930200429982506e-05\n",
      "Epoch 843, Loss: 0.0003801651412231877, Final Batch Loss: 1.920668864840991e-06\n",
      "Epoch 844, Loss: 0.002264807426627158, Final Batch Loss: 0.0006969980313442647\n",
      "Epoch 845, Loss: 0.0006995920306280823, Final Batch Loss: 2.230781137768645e-05\n",
      "Epoch 846, Loss: 0.0005834281800787267, Final Batch Loss: 2.772171501419507e-05\n",
      "Epoch 847, Loss: 0.0004130648559907968, Final Batch Loss: 9.483337635174394e-05\n",
      "Epoch 848, Loss: 0.0003120161325114168, Final Batch Loss: 4.324581823311746e-06\n",
      "Epoch 849, Loss: 0.0005255437161082455, Final Batch Loss: 5.809990852867486e-06\n",
      "Epoch 850, Loss: 0.0004659380587099804, Final Batch Loss: 3.9160746382549405e-05\n",
      "Epoch 851, Loss: 0.0020167531305332886, Final Batch Loss: 8.86525413079653e-06\n",
      "Epoch 852, Loss: 0.00025012998827378397, Final Batch Loss: 1.025735286930285e-06\n",
      "Epoch 853, Loss: 0.0003683085328916036, Final Batch Loss: 2.5529914637445472e-05\n",
      "Epoch 854, Loss: 0.0004907502090389926, Final Batch Loss: 1.3669261988979997e-06\n",
      "Epoch 855, Loss: 0.00017903722289247526, Final Batch Loss: 3.952044062316418e-05\n",
      "Epoch 856, Loss: 0.00028025106939821853, Final Batch Loss: 6.0727134041371755e-06\n",
      "Epoch 857, Loss: 0.00040699923027887053, Final Batch Loss: 3.982321504736319e-05\n",
      "Epoch 858, Loss: 0.0057749115817387064, Final Batch Loss: 0.00010067471157526597\n",
      "Epoch 859, Loss: 0.0019376640925088395, Final Batch Loss: 1.9877375052601565e-06\n",
      "Epoch 860, Loss: 0.0002488584215711853, Final Batch Loss: 7.58711894377484e-06\n",
      "Epoch 861, Loss: 0.00033326709569792, Final Batch Loss: 1.3024970257902169e-06\n",
      "Epoch 862, Loss: 0.0005760656590041435, Final Batch Loss: 1.181449420073477e-06\n",
      "Epoch 863, Loss: 0.0005387568080976735, Final Batch Loss: 2.622522970341379e-06\n",
      "Epoch 864, Loss: 0.00046772360370539445, Final Batch Loss: 2.0380677767661837e-07\n",
      "Epoch 865, Loss: 0.0002422010487421744, Final Batch Loss: 1.245367184310453e-05\n",
      "Epoch 866, Loss: 0.0009055211439275013, Final Batch Loss: 1.3851896483174642e-06\n",
      "Epoch 867, Loss: 0.00038690687223663645, Final Batch Loss: 7.459831863343425e-07\n",
      "Epoch 868, Loss: 0.00011215830880928479, Final Batch Loss: 2.165957766919746e-06\n",
      "Epoch 869, Loss: 0.00010005718505112782, Final Batch Loss: 2.3023123503662646e-05\n",
      "Epoch 870, Loss: 0.00015361693468207704, Final Batch Loss: 5.359505621527205e-07\n",
      "Epoch 871, Loss: 0.00020932384379790392, Final Batch Loss: 7.402483248597491e-08\n",
      "Epoch 872, Loss: 0.0005028806754410198, Final Batch Loss: 1.7528279840917094e-06\n",
      "Epoch 873, Loss: 6.603215446432387e-05, Final Batch Loss: 1.2552614862215705e-05\n",
      "Epoch 874, Loss: 0.0002586974071121517, Final Batch Loss: 5.41714655355463e-07\n",
      "Epoch 875, Loss: 8.62714149718613e-05, Final Batch Loss: 7.21411879567313e-06\n",
      "Epoch 876, Loss: 0.0001991001523151681, Final Batch Loss: 1.0672068128769752e-05\n",
      "Epoch 877, Loss: 0.00024153559951400894, Final Batch Loss: 4.761802301800344e-06\n",
      "Epoch 878, Loss: 8.550204967860964e-05, Final Batch Loss: 1.1055646353952397e-07\n",
      "Epoch 879, Loss: 0.000986625747298575, Final Batch Loss: 1.1151767864703288e-07\n",
      "Epoch 880, Loss: 0.00011222431966473323, Final Batch Loss: 3.081140960148332e-07\n",
      "Epoch 881, Loss: 0.05203720119463995, Final Batch Loss: 1.6295041405101074e-07\n",
      "Epoch 882, Loss: 0.04919061246732781, Final Batch Loss: 0.008034997619688511\n",
      "Epoch 883, Loss: 0.00023827859186553724, Final Batch Loss: 4.42571990788565e-06\n",
      "Epoch 884, Loss: 0.0811307805197714, Final Batch Loss: 0.043599165976047516\n",
      "Epoch 885, Loss: 0.003372978558672912, Final Batch Loss: 4.991652076569153e-06\n",
      "Epoch 886, Loss: 0.005989249101048699, Final Batch Loss: 9.388050966663286e-05\n",
      "Epoch 887, Loss: 0.00998090918278649, Final Batch Loss: 3.4913116451207316e-06\n",
      "Epoch 888, Loss: 0.005518283272749613, Final Batch Loss: 4.950854054186493e-05\n",
      "Epoch 889, Loss: 0.0012003543565697328, Final Batch Loss: 1.3631292858917732e-05\n",
      "Epoch 890, Loss: 0.001384623379635741, Final Batch Loss: 1.0887081316468539e-06\n",
      "Epoch 891, Loss: 0.00037789027214785165, Final Batch Loss: 4.736979462904856e-06\n",
      "Epoch 892, Loss: 0.0008921797342509308, Final Batch Loss: 6.6470643105276395e-06\n",
      "Epoch 893, Loss: 0.001101375024745721, Final Batch Loss: 1.1875694326590747e-05\n",
      "Epoch 894, Loss: 0.000732185456854495, Final Batch Loss: 0.0001732546224957332\n",
      "Epoch 895, Loss: 0.0009204571383634175, Final Batch Loss: 2.9251871183078038e-06\n",
      "Epoch 896, Loss: 0.00031613242651928886, Final Batch Loss: 3.164593636029167e-06\n",
      "Epoch 897, Loss: 0.0002386098249189672, Final Batch Loss: 5.633454929920845e-05\n",
      "Epoch 898, Loss: 0.0004639410694835533, Final Batch Loss: 3.2645459668856347e-06\n",
      "Epoch 899, Loss: 0.005435133713376672, Final Batch Loss: 1.905367025756277e-05\n",
      "Epoch 900, Loss: 0.0006788915374329463, Final Batch Loss: 8.869397788657807e-06\n",
      "Epoch 901, Loss: 0.0004274627929135022, Final Batch Loss: 5.958327164989896e-06\n",
      "Epoch 902, Loss: 0.0007629852987918184, Final Batch Loss: 4.1365670767845586e-05\n",
      "Epoch 903, Loss: 0.0007331573183364526, Final Batch Loss: 3.2075240596896037e-06\n",
      "Epoch 904, Loss: 0.0014334627853429538, Final Batch Loss: 1.384785036862013e-06\n",
      "Epoch 905, Loss: 0.0012648292886296986, Final Batch Loss: 3.845172159344656e-06\n",
      "Epoch 906, Loss: 0.0001278197632359479, Final Batch Loss: 4.6624711558251875e-07\n",
      "Epoch 907, Loss: 0.001221844133851846, Final Batch Loss: 2.1762527921964647e-06\n",
      "Epoch 908, Loss: 0.0017668592070094746, Final Batch Loss: 1.8619773982209153e-05\n",
      "Epoch 909, Loss: 0.0007875419508991399, Final Batch Loss: 0.00012503199104685336\n",
      "Epoch 910, Loss: 0.0004800940738505233, Final Batch Loss: 5.035782669438049e-05\n",
      "Epoch 911, Loss: 0.0007445916153301368, Final Batch Loss: 3.439755801082356e-06\n",
      "Epoch 912, Loss: 0.0004427070315387027, Final Batch Loss: 1.410718482475204e-06\n",
      "Epoch 913, Loss: 0.006305215671631004, Final Batch Loss: 1.5767011063871905e-05\n",
      "Epoch 914, Loss: 0.003312625789874346, Final Batch Loss: 0.0008718042518012226\n",
      "Epoch 915, Loss: 0.014018194655832872, Final Batch Loss: 2.9181348963902565e-06\n",
      "Epoch 916, Loss: 0.0006307830140031001, Final Batch Loss: 7.519480732298689e-06\n",
      "Epoch 917, Loss: 0.00025923188789533924, Final Batch Loss: 1.938459490702371e-06\n",
      "Epoch 918, Loss: 0.04592712848352676, Final Batch Loss: 7.787001777614933e-06\n",
      "Epoch 919, Loss: 0.000974242741733633, Final Batch Loss: 6.385261258401442e-06\n",
      "Epoch 920, Loss: 0.001291603003551245, Final Batch Loss: 4.980197445547674e-06\n",
      "Epoch 921, Loss: 0.006852745441278785, Final Batch Loss: 0.0010766133200377226\n",
      "Epoch 922, Loss: 0.007300371713199638, Final Batch Loss: 0.004222871270030737\n",
      "Epoch 923, Loss: 0.0009335465355775341, Final Batch Loss: 2.3196727852337062e-05\n",
      "Epoch 924, Loss: 0.001159995562829863, Final Batch Loss: 0.00033317256020382047\n",
      "Epoch 925, Loss: 0.0006411247175037715, Final Batch Loss: 0.00013475483865477145\n",
      "Epoch 926, Loss: 0.00869850847948328, Final Batch Loss: 0.0008512274944223464\n",
      "Epoch 927, Loss: 0.014523697392888835, Final Batch Loss: 2.318284032298834e-06\n",
      "Epoch 928, Loss: 0.0004655649232745418, Final Batch Loss: 8.631831587990746e-05\n",
      "Epoch 929, Loss: 9.787526877858e-05, Final Batch Loss: 3.837961685349001e-06\n",
      "Epoch 930, Loss: 0.005052836807521999, Final Batch Loss: 1.4251193078962388e-06\n",
      "Epoch 931, Loss: 0.00020553860642280597, Final Batch Loss: 5.864229137841903e-07\n",
      "Epoch 932, Loss: 0.00025503873183652104, Final Batch Loss: 1.1207965144421905e-05\n",
      "Epoch 933, Loss: 0.00023308673203814578, Final Batch Loss: 2.5091469524340937e-07\n",
      "Epoch 934, Loss: 0.00014931828559383575, Final Batch Loss: 1.8184231521445327e-05\n",
      "Epoch 935, Loss: 0.00028557798874828677, Final Batch Loss: 2.321684888784148e-07\n",
      "Epoch 936, Loss: 6.409707759758021e-05, Final Batch Loss: 7.349687621172052e-06\n",
      "Epoch 937, Loss: 0.00026092694025692253, Final Batch Loss: 8.278898349090014e-06\n",
      "Epoch 938, Loss: 0.0002543306494260378, Final Batch Loss: 2.7126484383188654e-06\n",
      "Epoch 939, Loss: 0.00023204328658721352, Final Batch Loss: 6.171195309434552e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940, Loss: 0.0008013999816398609, Final Batch Loss: 1.9831163626804482e-06\n",
      "Epoch 941, Loss: 0.0006376413386988133, Final Batch Loss: 2.426365426799748e-05\n",
      "Epoch 942, Loss: 0.0007358364069958157, Final Batch Loss: 6.359248345688684e-07\n",
      "Epoch 943, Loss: 0.00015356744589922755, Final Batch Loss: 1.6515508605152718e-06\n",
      "Epoch 944, Loss: 0.0005415941136845959, Final Batch Loss: 1.597016762389103e-06\n",
      "Epoch 945, Loss: 0.0006459542292418519, Final Batch Loss: 6.940342245798092e-06\n",
      "Epoch 946, Loss: 0.0001746910465669771, Final Batch Loss: 1.9595368030422833e-06\n",
      "Epoch 947, Loss: 0.00013229385109525538, Final Batch Loss: 3.2405619094788563e-06\n",
      "Epoch 948, Loss: 0.00041083486229354094, Final Batch Loss: 5.051793436905427e-07\n",
      "Epoch 949, Loss: 0.0006713992176372585, Final Batch Loss: 2.297931132488884e-06\n",
      "Epoch 950, Loss: 0.0005963015127719018, Final Batch Loss: 2.2008655378158437e-06\n",
      "Epoch 951, Loss: 0.00024109907691638455, Final Batch Loss: 4.43585668108426e-06\n",
      "Epoch 952, Loss: 0.00014119723259398143, Final Batch Loss: 3.749358802451752e-05\n",
      "Epoch 953, Loss: 0.0001091346319128661, Final Batch Loss: 5.069956841907697e-06\n",
      "Epoch 954, Loss: 0.0002952595534111424, Final Batch Loss: 0.00019680337572935969\n",
      "Epoch 955, Loss: 0.00011922933783381495, Final Batch Loss: 2.879264116018021e-07\n",
      "Epoch 956, Loss: 4.737529256004791e-05, Final Batch Loss: 4.3356872083677445e-06\n",
      "Epoch 957, Loss: 0.00016348638538943305, Final Batch Loss: 4.4560065362020396e-06\n",
      "Epoch 958, Loss: 0.00023056758573147818, Final Batch Loss: 1.8787795852404088e-06\n",
      "Epoch 959, Loss: 0.00024237059994902665, Final Batch Loss: 9.694923619463225e-07\n",
      "Epoch 960, Loss: 0.000672116040078663, Final Batch Loss: 7.637631256329769e-07\n",
      "Epoch 961, Loss: 8.493737792036882e-05, Final Batch Loss: 2.581240892141068e-07\n",
      "Epoch 962, Loss: 0.0002978121111141263, Final Batch Loss: 4.600078398198093e-07\n",
      "Epoch 963, Loss: 0.00023749088748559188, Final Batch Loss: 2.0092448949071695e-07\n",
      "Epoch 964, Loss: 9.555665641869382e-05, Final Batch Loss: 9.733353181218263e-07\n",
      "Epoch 965, Loss: 3.415717061017176e-05, Final Batch Loss: 7.258297074486109e-08\n",
      "Epoch 966, Loss: 0.0005069669536297283, Final Batch Loss: 0.00010357268183724955\n",
      "Epoch 967, Loss: 0.00031210810379889153, Final Batch Loss: 5.912275469199813e-07\n",
      "Epoch 968, Loss: 7.546936561197981e-05, Final Batch Loss: 1.8894005506808753e-06\n",
      "Epoch 969, Loss: 0.00010843291562423474, Final Batch Loss: 1.5189478119737032e-07\n",
      "Epoch 970, Loss: 0.00010538546166216634, Final Batch Loss: 1.9782713934546337e-05\n",
      "Epoch 971, Loss: 0.00010292560730817968, Final Batch Loss: 9.584161489328835e-06\n",
      "Epoch 972, Loss: 0.00012956376214390275, Final Batch Loss: 8.300833087560022e-07\n",
      "Epoch 973, Loss: 0.00023557382685801542, Final Batch Loss: 7.253283342834038e-07\n",
      "Epoch 974, Loss: 6.529235882268836e-05, Final Batch Loss: 5.375130058382638e-06\n",
      "Epoch 975, Loss: 0.00012515566528747968, Final Batch Loss: 5.291984166433394e-07\n",
      "Epoch 976, Loss: 0.00010989679437045652, Final Batch Loss: 1.6015087567211594e-06\n",
      "Epoch 977, Loss: 2.0750357450083357e-05, Final Batch Loss: 3.220567634798499e-08\n",
      "Epoch 978, Loss: 8.461585869667942e-05, Final Batch Loss: 8.151783958965098e-07\n",
      "Epoch 979, Loss: 0.0016353334361554062, Final Batch Loss: 1.2261626807230641e-06\n",
      "Epoch 980, Loss: 0.00021608123419269987, Final Batch Loss: 9.798101928026881e-06\n",
      "Epoch 981, Loss: 0.0013415436531971636, Final Batch Loss: 1.7931697584572248e-05\n",
      "Epoch 982, Loss: 0.00017955715541262407, Final Batch Loss: 3.5902910894947127e-05\n",
      "Epoch 983, Loss: 4.831759338230768e-05, Final Batch Loss: 5.341213636711473e-06\n",
      "Epoch 984, Loss: 0.00011492503080745564, Final Batch Loss: 5.503051943378523e-05\n",
      "Epoch 985, Loss: 0.0009319802173024527, Final Batch Loss: 9.848555237113032e-06\n",
      "Epoch 986, Loss: 0.0014668911731519074, Final Batch Loss: 5.647879106618348e-07\n",
      "Epoch 987, Loss: 0.00023966918996265463, Final Batch Loss: 1.8613502561493078e-06\n",
      "Epoch 988, Loss: 0.0006799022546601918, Final Batch Loss: 7.876320523791946e-06\n",
      "Epoch 989, Loss: 0.0014682970268609097, Final Batch Loss: 2.8888698011542147e-07\n",
      "Epoch 990, Loss: 9.839190565230638e-05, Final Batch Loss: 9.950039725481474e-08\n",
      "Epoch 991, Loss: 2.4044561836689127e-05, Final Batch Loss: 1.3665051028510788e-06\n",
      "Epoch 992, Loss: 3.1709768290255624e-05, Final Batch Loss: 3.153221541651874e-07\n",
      "Epoch 993, Loss: 0.0005553203750281455, Final Batch Loss: 8.757668865655432e-07\n",
      "Epoch 994, Loss: 5.552296627264752e-05, Final Batch Loss: 1.3459109382552015e-08\n",
      "Epoch 995, Loss: 0.0012933709193863052, Final Batch Loss: 2.75909428637533e-07\n",
      "Epoch 996, Loss: 6.1027331469176715e-05, Final Batch Loss: 4.5663756509384257e-07\n",
      "Epoch 997, Loss: 3.7856449328188546e-05, Final Batch Loss: 5.061326646682573e-07\n",
      "Epoch 998, Loss: 0.0005653741608568907, Final Batch Loss: 5.715221504942747e-07\n",
      "Epoch 999, Loss: 0.0008695682223063272, Final Batch Loss: 2.922496662449703e-07\n",
      "Epoch 1000, Loss: 2.690143674355383e-05, Final Batch Loss: 2.658115079157142e-07\n",
      "Epoch 1001, Loss: 7.680526483966332e-05, Final Batch Loss: 1.7881318115087197e-07\n",
      "Epoch 1002, Loss: 0.00010451430010238738, Final Batch Loss: 2.9067844025121303e-06\n",
      "Epoch 1003, Loss: 0.00043974976154359524, Final Batch Loss: 2.63909055320255e-06\n",
      "Epoch 1004, Loss: 0.000134532147894717, Final Batch Loss: 3.239780426156358e-07\n",
      "Epoch 1005, Loss: 7.553446083363724e-05, Final Batch Loss: 2.2222864117793506e-06\n",
      "Epoch 1006, Loss: 0.0002549883143707632, Final Batch Loss: 2.4514761776117666e-08\n",
      "Epoch 1007, Loss: 0.00016771018514560865, Final Batch Loss: 9.757767571727527e-08\n",
      "Epoch 1008, Loss: 0.003955140696163539, Final Batch Loss: 3.504089249872777e-07\n",
      "Epoch 1009, Loss: 3.882336623206584e-05, Final Batch Loss: 3.867619852826465e-06\n",
      "Epoch 1010, Loss: 0.00010319946700221294, Final Batch Loss: 2.840737352016731e-07\n",
      "Epoch 1011, Loss: 0.00013128091244496432, Final Batch Loss: 1.456447620284962e-07\n",
      "Epoch 1012, Loss: 0.0003685080456499179, Final Batch Loss: 4.5903314571660303e-07\n",
      "Epoch 1013, Loss: 0.00016372908235418038, Final Batch Loss: 8.939781537264935e-07\n",
      "Epoch 1014, Loss: 0.0002330247520134776, Final Batch Loss: 4.0184377212426625e-06\n",
      "Epoch 1015, Loss: 0.0004355794473696051, Final Batch Loss: 2.29707757171127e-06\n",
      "Epoch 1016, Loss: 0.0002278502046237918, Final Batch Loss: 1.3389892501436407e-06\n",
      "Epoch 1017, Loss: 1.7850580363187873e-05, Final Batch Loss: 4.657677266095561e-07\n",
      "Epoch 1018, Loss: 0.0001765493836227705, Final Batch Loss: 6.825664655707442e-08\n",
      "Epoch 1019, Loss: 8.543424954332579e-05, Final Batch Loss: 5.811493792862166e-06\n",
      "Epoch 1020, Loss: 0.00010529906158662783, Final Batch Loss: 1.4285490578913596e-05\n",
      "Epoch 1021, Loss: 4.449750610291403e-05, Final Batch Loss: 2.274489452247508e-05\n",
      "Epoch 1022, Loss: 0.00021319776276129687, Final Batch Loss: 1.880132913356647e-06\n",
      "Epoch 1023, Loss: 0.0003167827717396321, Final Batch Loss: 2.3859620341681875e-06\n",
      "Epoch 1024, Loss: 0.00015235433157734235, Final Batch Loss: 5.790852810605429e-06\n",
      "Epoch 1025, Loss: 8.17236571659663e-05, Final Batch Loss: 8.892328082765744e-07\n",
      "Epoch 1026, Loss: 0.00012189082278979413, Final Batch Loss: 3.410296358197229e-06\n",
      "Epoch 1027, Loss: 0.0003458328975760594, Final Batch Loss: 3.239759109874285e-07\n",
      "Epoch 1028, Loss: 4.721545850472353e-05, Final Batch Loss: 8.12805581063003e-07\n",
      "Epoch 1029, Loss: 0.0003347466752003925, Final Batch Loss: 1.3433015055852593e-06\n",
      "Epoch 1030, Loss: 0.0014199518826014668, Final Batch Loss: 8.652256155983196e-08\n",
      "Epoch 1031, Loss: 0.0005819730283298519, Final Batch Loss: 1.8897471818490885e-05\n",
      "Epoch 1032, Loss: 0.00011802274400807278, Final Batch Loss: 9.886806537906523e-07\n",
      "Epoch 1033, Loss: 0.00012620857211942393, Final Batch Loss: 2.0957615731731494e-07\n",
      "Epoch 1034, Loss: 7.602747937696108e-05, Final Batch Loss: 1.874661492706764e-08\n",
      "Epoch 1035, Loss: 7.97902503231196e-05, Final Batch Loss: 1.0986911547661293e-05\n",
      "Epoch 1036, Loss: 0.00011049282894504131, Final Batch Loss: 2.1534135896672524e-07\n",
      "Epoch 1037, Loss: 6.668300562751028e-05, Final Batch Loss: 1.28568922264094e-06\n",
      "Epoch 1038, Loss: 0.00020246350963248894, Final Batch Loss: 9.181005111713603e-08\n",
      "Epoch 1039, Loss: 1.78265078840667e-05, Final Batch Loss: 1.8458032968737825e-07\n",
      "Epoch 1040, Loss: 0.00010312127269607174, Final Batch Loss: 7.883141961428919e-08\n",
      "Epoch 1041, Loss: 3.913111103281963e-05, Final Batch Loss: 1.970796681405318e-08\n",
      "Epoch 1042, Loss: 0.00011598930454503886, Final Batch Loss: 1.4437880508921808e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1043, Loss: 3.957034015122929e-05, Final Batch Loss: 1.138658831223438e-06\n",
      "Epoch 1044, Loss: 3.3518811217270184e-05, Final Batch Loss: 5.782335392723326e-07\n",
      "Epoch 1045, Loss: 5.2323630958639455e-05, Final Batch Loss: 1.5355711866504862e-06\n",
      "Epoch 1046, Loss: 0.0061284263769856295, Final Batch Loss: 5.686210897692945e-07\n",
      "Epoch 1047, Loss: 7.614586540638513e-05, Final Batch Loss: 9.314750286648632e-07\n",
      "Epoch 1048, Loss: 7.095901193565624e-05, Final Batch Loss: 1.3457007526085363e-06\n",
      "Epoch 1049, Loss: 0.0003394934562486185, Final Batch Loss: 8.267473276646342e-06\n",
      "Epoch 1050, Loss: 0.00010489944748570679, Final Batch Loss: 6.953584670554847e-05\n",
      "Epoch 1051, Loss: 5.161362932160074e-06, Final Batch Loss: 1.056961309586768e-06\n",
      "Epoch 1052, Loss: 0.0002638988582503998, Final Batch Loss: 1.0094331592824801e-08\n",
      "Epoch 1053, Loss: 0.00017117776891950598, Final Batch Loss: 7.330149287554377e-07\n",
      "Epoch 1054, Loss: 2.784529531840718e-05, Final Batch Loss: 1.4312433904706268e-06\n",
      "Epoch 1055, Loss: 7.168650882771743e-05, Final Batch Loss: 1.682388450774397e-08\n",
      "Epoch 1056, Loss: 0.0002548149661691923, Final Batch Loss: 5.74856869661744e-07\n",
      "Epoch 1057, Loss: 0.0008155940671326078, Final Batch Loss: 4.6529174824172514e-07\n",
      "Epoch 1058, Loss: 3.6514157338629616e-05, Final Batch Loss: 9.132917710985566e-08\n",
      "Epoch 1059, Loss: 0.00010902028760595428, Final Batch Loss: 6.537259622518832e-08\n",
      "Epoch 1060, Loss: 3.825054777450987e-05, Final Batch Loss: 9.757771124441206e-08\n",
      "Epoch 1061, Loss: 4.44115294300218e-05, Final Batch Loss: 1.1994496162515134e-05\n",
      "Epoch 1062, Loss: 2.3785209060545043e-05, Final Batch Loss: 4.013518264400773e-07\n",
      "Epoch 1063, Loss: 2.4803514978799512e-05, Final Batch Loss: 9.649797902966384e-06\n",
      "Epoch 1064, Loss: 3.13927894897148e-05, Final Batch Loss: 3.028297257401391e-08\n",
      "Epoch 1065, Loss: 1.00689264006526e-05, Final Batch Loss: 2.425462071187212e-06\n",
      "Epoch 1066, Loss: 8.997458546966541e-05, Final Batch Loss: 9.778627827472519e-06\n",
      "Epoch 1067, Loss: 1.6400618187972782e-05, Final Batch Loss: 1.105568703252402e-08\n",
      "Epoch 1068, Loss: 2.6917994762953867e-05, Final Batch Loss: 7.517509743593109e-07\n",
      "Epoch 1069, Loss: 0.0014463943673526103, Final Batch Loss: 7.883122066232318e-08\n",
      "Epoch 1070, Loss: 0.00023222673663081395, Final Batch Loss: 1.587941255820624e-06\n",
      "Epoch 1071, Loss: 8.042347872727618e-05, Final Batch Loss: 5.782412131338788e-07\n",
      "Epoch 1072, Loss: 1.821635154986012e-05, Final Batch Loss: 2.288096538904938e-06\n",
      "Epoch 1073, Loss: 0.00022928364868302076, Final Batch Loss: 2.787950670324335e-08\n",
      "Epoch 1074, Loss: 4.3069527288164267e-05, Final Batch Loss: 2.0238792330928845e-06\n",
      "Epoch 1075, Loss: 0.0003114119675426963, Final Batch Loss: 2.1678347650322394e-07\n",
      "Epoch 1076, Loss: 0.00011330497198258627, Final Batch Loss: 3.9270832985494053e-07\n",
      "Epoch 1077, Loss: 0.0051458528205419185, Final Batch Loss: 2.0251493424439104e-06\n",
      "Epoch 1078, Loss: 2.037689669265319e-05, Final Batch Loss: 3.956036835006671e-06\n",
      "Epoch 1079, Loss: 0.00011869133386355202, Final Batch Loss: 5.960438542729207e-08\n",
      "Epoch 1080, Loss: 5.530214782556442e-06, Final Batch Loss: 3.508976575972156e-08\n",
      "Epoch 1081, Loss: 0.0004475623381687832, Final Batch Loss: 4.330064984969795e-05\n",
      "Epoch 1082, Loss: 2.586738606691341e-05, Final Batch Loss: 2.6821774667951104e-07\n",
      "Epoch 1083, Loss: 2.2843238493663875e-05, Final Batch Loss: 1.4901141653922423e-08\n",
      "Epoch 1084, Loss: 6.171614611361065e-06, Final Batch Loss: 4.6626073668676327e-08\n",
      "Epoch 1085, Loss: 2.7932605373592878e-05, Final Batch Loss: 1.460164867239655e-06\n",
      "Epoch 1086, Loss: 7.931363943658454e-05, Final Batch Loss: 4.974895659870526e-07\n",
      "Epoch 1087, Loss: 4.1689264884237076e-05, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 1088, Loss: 1.1057633929945077e-05, Final Batch Loss: 9.613650320261513e-09\n",
      "Epoch 1089, Loss: 4.6886845346705286e-05, Final Batch Loss: 3.340628609294072e-07\n",
      "Epoch 1090, Loss: 1.8763693692136485e-05, Final Batch Loss: 9.805883394164994e-08\n",
      "Epoch 1091, Loss: 4.6112900621508857e-05, Final Batch Loss: 3.542579634085996e-07\n",
      "Epoch 1092, Loss: 0.00030659961966339466, Final Batch Loss: 1.1824725021369886e-07\n",
      "Epoch 1093, Loss: 2.38301350172776e-05, Final Batch Loss: 1.4467253777183942e-06\n",
      "Epoch 1094, Loss: 2.8898692986389918e-05, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 1095, Loss: 0.0001928171303422488, Final Batch Loss: 2.75907780178386e-07\n",
      "Epoch 1096, Loss: 0.00016363168371658077, Final Batch Loss: 4.037719136817941e-08\n",
      "Epoch 1097, Loss: 2.750652339500448e-05, Final Batch Loss: 1.8785621023198473e-06\n",
      "Epoch 1098, Loss: 7.186080116738935e-05, Final Batch Loss: 1.071912902261829e-05\n",
      "Epoch 1099, Loss: 0.00013059527540848492, Final Batch Loss: 4.917185378872091e-07\n",
      "Epoch 1100, Loss: 5.082423924918089e-05, Final Batch Loss: 7.204817507044936e-07\n",
      "Epoch 1101, Loss: 1.7996230709194094e-05, Final Batch Loss: 6.142701067801681e-07\n",
      "Epoch 1102, Loss: 2.1554766905573786e-05, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 1103, Loss: 0.0001512656597967288, Final Batch Loss: 1.1055694137951377e-08\n",
      "Epoch 1104, Loss: 2.6437513783394984e-05, Final Batch Loss: 4.657638612570736e-07\n",
      "Epoch 1105, Loss: 0.00028978320553063597, Final Batch Loss: 2.408184798241564e-07\n",
      "Epoch 1106, Loss: 0.00016190116424108503, Final Batch Loss: 1.8265927437255414e-08\n",
      "Epoch 1107, Loss: 1.6279723683787495e-05, Final Batch Loss: 1.3597190445580054e-05\n",
      "Epoch 1108, Loss: 0.0003122015608703066, Final Batch Loss: 2.3601235454862035e-07\n",
      "Epoch 1109, Loss: 5.8442116379620046e-05, Final Batch Loss: 2.451478309239974e-08\n",
      "Epoch 1110, Loss: 0.0003843896623068055, Final Batch Loss: 5.195906851440668e-07\n",
      "Epoch 1111, Loss: 0.00015323486266716202, Final Batch Loss: 1.201699433295289e-07\n",
      "Epoch 1112, Loss: 5.654511395558615e-06, Final Batch Loss: 2.0188656080222245e-08\n",
      "Epoch 1113, Loss: 2.0924714955183887e-05, Final Batch Loss: 2.004414199063831e-07\n",
      "Epoch 1114, Loss: 1.0853342351957451e-05, Final Batch Loss: 3.220459916519758e-07\n",
      "Epoch 1115, Loss: 6.873428285925076e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 1116, Loss: 0.00035204775621322515, Final Batch Loss: 4.08578770816348e-08\n",
      "Epoch 1117, Loss: 8.022288354947449e-06, Final Batch Loss: 9.824418611970032e-07\n",
      "Epoch 1118, Loss: 0.005272937072877681, Final Batch Loss: 3.792440850247658e-07\n",
      "Epoch 1119, Loss: 3.625334238321898e-05, Final Batch Loss: 1.1840567822218873e-05\n",
      "Epoch 1120, Loss: 5.9931377098476624e-05, Final Batch Loss: 9.132966383162966e-09\n",
      "Epoch 1121, Loss: 1.3074574475524514e-05, Final Batch Loss: 2.9321581607177905e-08\n",
      "Epoch 1122, Loss: 5.921653430496221e-05, Final Batch Loss: 5.768189037524962e-09\n",
      "Epoch 1123, Loss: 4.1668969605002104e-05, Final Batch Loss: 6.951012437639292e-06\n",
      "Epoch 1124, Loss: 0.00018970918343275134, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 1125, Loss: 2.9950309215820425e-05, Final Batch Loss: 2.3360617262824235e-07\n",
      "Epoch 1126, Loss: 6.361526672793438e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 1127, Loss: 0.0028302219033691234, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 1128, Loss: 2.6806422154246334e-06, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 1129, Loss: 2.448336347771196e-05, Final Batch Loss: 1.356279199171695e-06\n",
      "Epoch 1130, Loss: 0.0006551890209056666, Final Batch Loss: 1.3939784437866365e-08\n",
      "Epoch 1131, Loss: 1.6452890030604905e-05, Final Batch Loss: 6.455306902353186e-07\n",
      "Epoch 1132, Loss: 8.841349057964187e-05, Final Batch Loss: 4.328698923927732e-05\n",
      "Epoch 1133, Loss: 2.596710334734631e-05, Final Batch Loss: 3.923399162886199e-06\n",
      "Epoch 1134, Loss: 0.0005827601458797682, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 1135, Loss: 6.702675437786354e-05, Final Batch Loss: 2.7398872504136307e-08\n",
      "Epoch 1136, Loss: 2.4463954532816246e-05, Final Batch Loss: 8.713882948541141e-07\n",
      "Epoch 1137, Loss: 6.299852621338697e-05, Final Batch Loss: 1.5862514857190035e-08\n",
      "Epoch 1138, Loss: 1.1681325140955323e-05, Final Batch Loss: 1.4802358236920554e-06\n",
      "Epoch 1139, Loss: 3.8479368224320076e-05, Final Batch Loss: 8.700325793142838e-08\n",
      "Epoch 1140, Loss: 0.0027398379539282924, Final Batch Loss: 8.616030390840024e-05\n",
      "Epoch 1141, Loss: 0.0005924200021989456, Final Batch Loss: 1.6919894108013978e-07\n",
      "Epoch 1142, Loss: 3.4811570745141296e-05, Final Batch Loss: 2.3632903776160674e-06\n",
      "Epoch 1143, Loss: 0.0007522198681546577, Final Batch Loss: 1.0094324487397444e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1144, Loss: 2.0219439950341922e-05, Final Batch Loss: 1.4516504620587511e-07\n",
      "Epoch 1145, Loss: 5.132969071475202e-05, Final Batch Loss: 2.7734685659197567e-07\n",
      "Epoch 1146, Loss: 5.319932268310623e-05, Final Batch Loss: 3.4079508282047755e-07\n",
      "Epoch 1147, Loss: 0.00015321912163956952, Final Batch Loss: 3.292295787105104e-06\n",
      "Epoch 1148, Loss: 1.0602159525863186e-05, Final Batch Loss: 5.085313205199782e-06\n",
      "Epoch 1149, Loss: 0.00013069818321032045, Final Batch Loss: 7.066004314992824e-08\n",
      "Epoch 1150, Loss: 2.5858192674421687e-05, Final Batch Loss: 1.71601769238805e-07\n",
      "Epoch 1151, Loss: 1.0180343298471506e-05, Final Batch Loss: 5.9123618001422074e-08\n",
      "Epoch 1152, Loss: 6.216583287699251e-06, Final Batch Loss: 9.180967452948607e-08\n",
      "Epoch 1153, Loss: 4.576343712869857e-06, Final Batch Loss: 3.124425873579639e-08\n",
      "Epoch 1154, Loss: 8.495496998417451e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 1155, Loss: 4.7104107147144525e-05, Final Batch Loss: 5.469939310387417e-07\n",
      "Epoch 1156, Loss: 0.00021394109974082198, Final Batch Loss: 1.2183484159322688e-06\n",
      "Epoch 1157, Loss: 6.189607655526785e-06, Final Batch Loss: 1.3170512147553382e-07\n",
      "Epoch 1158, Loss: 2.501840712199055e-05, Final Batch Loss: 5.287337216941523e-07\n",
      "Epoch 1159, Loss: 9.55212934328209e-06, Final Batch Loss: 2.4321974478880293e-07\n",
      "Epoch 1160, Loss: 1.2262556107978106e-05, Final Batch Loss: 1.2497729073857045e-08\n",
      "Epoch 1161, Loss: 0.0001775423187905245, Final Batch Loss: 3.845460394558131e-09\n",
      "Epoch 1162, Loss: 6.616067770881529e-05, Final Batch Loss: 4.806365723197814e-06\n",
      "Epoch 1163, Loss: 1.5982050858287522e-05, Final Batch Loss: 5.090226977699785e-07\n",
      "Epoch 1164, Loss: 6.780358357660887e-06, Final Batch Loss: 6.729554691276007e-09\n",
      "Epoch 1165, Loss: 0.00010071657240473542, Final Batch Loss: 1.0420438911751262e-06\n",
      "Epoch 1166, Loss: 2.6571289695187517e-06, Final Batch Loss: 1.7112078865011426e-07\n",
      "Epoch 1167, Loss: 3.4798152993564813e-06, Final Batch Loss: 9.517458465779782e-08\n",
      "Epoch 1168, Loss: 1.0660122831906982e-05, Final Batch Loss: 9.613645879369415e-09\n",
      "Epoch 1169, Loss: 0.00012914921804263457, Final Batch Loss: 0.00011913056368939579\n",
      "Epoch 1170, Loss: 1.1349453968301226e-05, Final Batch Loss: 6.441120348199547e-08\n",
      "Epoch 1171, Loss: 1.2718335910988365e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 1172, Loss: 0.00014556102133622684, Final Batch Loss: 1.225724730602451e-07\n",
      "Epoch 1173, Loss: 2.132973086155232e-06, Final Batch Loss: 2.6437499300868694e-08\n",
      "Epoch 1174, Loss: 3.869766156749943e-05, Final Batch Loss: 2.1245611492304306e-07\n",
      "Epoch 1175, Loss: 0.00031547750200289215, Final Batch Loss: 2.2915221506991656e-06\n",
      "Epoch 1176, Loss: 3.0005359306306545e-05, Final Batch Loss: 8.075388535644379e-08\n",
      "Epoch 1177, Loss: 4.5472066979135306e-05, Final Batch Loss: 3.810159250861034e-05\n",
      "Epoch 1178, Loss: 0.006606216003737675, Final Batch Loss: 1.8771774193737656e-05\n",
      "Epoch 1179, Loss: 0.006091672651645119, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 1180, Loss: 1.9348437156008202e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1181, Loss: 0.034866323358052176, Final Batch Loss: 7.642168498023238e-07\n",
      "Epoch 1182, Loss: 0.00994224131337429, Final Batch Loss: 1.1548375368874986e-05\n",
      "Epoch 1183, Loss: 0.042427528765415445, Final Batch Loss: 0.015255755744874477\n",
      "Epoch 1184, Loss: 0.015818010020748785, Final Batch Loss: 1.4612587051487935e-07\n",
      "Epoch 1185, Loss: 0.0003144024195744777, Final Batch Loss: 1.272670579055557e-05\n",
      "Epoch 1186, Loss: 0.003109047502420026, Final Batch Loss: 0.00016692510689608753\n",
      "Epoch 1187, Loss: 0.009749905855452434, Final Batch Loss: 2.6918140605403096e-08\n",
      "Epoch 1188, Loss: 0.004668081860053519, Final Batch Loss: 2.88469746010378e-05\n",
      "Epoch 1189, Loss: 0.00017564112752377348, Final Batch Loss: 1.3506959817277675e-07\n",
      "Epoch 1190, Loss: 0.01200851573890338, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1191, Loss: 0.003960623421785492, Final Batch Loss: 9.277103174554213e-08\n",
      "Epoch 1192, Loss: 0.0003864303332932195, Final Batch Loss: 2.225507103048585e-07\n",
      "Epoch 1193, Loss: 0.00033409884347512797, Final Batch Loss: 6.488720600827946e-07\n",
      "Epoch 1194, Loss: 0.002348725776419869, Final Batch Loss: 1.1792457371484488e-05\n",
      "Epoch 1195, Loss: 0.0022301464152365558, Final Batch Loss: 8.26953983050771e-05\n",
      "Epoch 1196, Loss: 0.06416695181115273, Final Batch Loss: 0.03360000625252724\n",
      "Epoch 1197, Loss: 6.866804930005799e-05, Final Batch Loss: 3.38769200425304e-06\n",
      "Epoch 1198, Loss: 0.01825474517337966, Final Batch Loss: 1.681824323895853e-05\n",
      "Epoch 1199, Loss: 0.002158342643440392, Final Batch Loss: 3.5173966352886055e-06\n",
      "Epoch 1200, Loss: 0.001486579222166995, Final Batch Loss: 1.970796148498266e-08\n",
      "Epoch 1201, Loss: 0.00036178328481817346, Final Batch Loss: 3.2316856959369034e-05\n",
      "Epoch 1202, Loss: 0.00011766569412685612, Final Batch Loss: 2.149545025531552e-06\n",
      "Epoch 1203, Loss: 0.006524428602018517, Final Batch Loss: 0.0059995041228830814\n",
      "Epoch 1204, Loss: 7.755900419148531e-05, Final Batch Loss: 4.44620155803932e-07\n",
      "Epoch 1205, Loss: 0.004020136717297618, Final Batch Loss: 3.657953584479401e-07\n",
      "Epoch 1206, Loss: 0.00013967520495583585, Final Batch Loss: 1.1886699212482199e-05\n",
      "Epoch 1207, Loss: 0.00016841370079134776, Final Batch Loss: 1.7477026631240733e-05\n",
      "Epoch 1208, Loss: 0.00038856714596846587, Final Batch Loss: 0.00020222491002641618\n",
      "Epoch 1209, Loss: 0.0002353760216635692, Final Batch Loss: 6.794057753722882e-06\n",
      "Epoch 1210, Loss: 0.0003362350501330269, Final Batch Loss: 1.42761564347893e-07\n",
      "Epoch 1211, Loss: 4.3263496377399235e-05, Final Batch Loss: 2.3457087650058384e-07\n",
      "Epoch 1212, Loss: 0.00033204553773913403, Final Batch Loss: 3.20130396858076e-07\n",
      "Epoch 1213, Loss: 4.790087784378727e-05, Final Batch Loss: 1.5663675867472193e-06\n",
      "Epoch 1214, Loss: 0.0002708795005048614, Final Batch Loss: 3.8790170719948946e-07\n",
      "Epoch 1215, Loss: 7.061620605952612e-05, Final Batch Loss: 5.54205030312005e-07\n",
      "Epoch 1216, Loss: 0.00021163375682675678, Final Batch Loss: 2.3441086796083255e-06\n",
      "Epoch 1217, Loss: 0.00107327878229313, Final Batch Loss: 4.80468625028152e-05\n",
      "Epoch 1218, Loss: 0.00019418740267340695, Final Batch Loss: 7.564358384115621e-05\n",
      "Epoch 1219, Loss: 0.0004704356295235357, Final Batch Loss: 5.865832918061642e-06\n",
      "Epoch 1220, Loss: 4.1755001806365044e-05, Final Batch Loss: 1.1867198281834135e-06\n",
      "Epoch 1221, Loss: 3.895419505539621e-05, Final Batch Loss: 2.0815230072912527e-06\n",
      "Epoch 1222, Loss: 0.0001110801238297654, Final Batch Loss: 7.820971404726151e-06\n",
      "Epoch 1223, Loss: 0.00038635145424636974, Final Batch Loss: 2.1949433630652493e-06\n",
      "Epoch 1224, Loss: 3.883558061446024e-05, Final Batch Loss: 1.7256419937439205e-07\n",
      "Epoch 1225, Loss: 5.404799387465076e-05, Final Batch Loss: 4.951006005171621e-08\n",
      "Epoch 1226, Loss: 0.00011840954728192798, Final Batch Loss: 2.355339567827741e-08\n",
      "Epoch 1227, Loss: 0.0001065556394692635, Final Batch Loss: 2.7496382699609967e-06\n",
      "Epoch 1228, Loss: 7.819184569157756e-05, Final Batch Loss: 9.545270813759998e-07\n",
      "Epoch 1229, Loss: 0.00015201634999861824, Final Batch Loss: 1.5862509528119517e-08\n",
      "Epoch 1230, Loss: 0.06695078718213665, Final Batch Loss: 6.575342581527366e-07\n",
      "Epoch 1231, Loss: 0.03427304255433228, Final Batch Loss: 1.5416817404911853e-05\n",
      "Epoch 1232, Loss: 0.012957849708527647, Final Batch Loss: 1.2276000234123785e-06\n",
      "Epoch 1233, Loss: 0.0014278642224780924, Final Batch Loss: 4.013380021206103e-05\n",
      "Epoch 1234, Loss: 0.0017757326043295052, Final Batch Loss: 5.165273978491314e-05\n",
      "Epoch 1235, Loss: 0.0011554255427626003, Final Batch Loss: 0.0002878417435567826\n",
      "Epoch 1236, Loss: 0.0006240253664486772, Final Batch Loss: 3.9269900298677385e-05\n",
      "Epoch 1237, Loss: 0.0004441640024879234, Final Batch Loss: 6.165502327348804e-06\n",
      "Epoch 1238, Loss: 0.000285573069476186, Final Batch Loss: 1.1968941748818906e-07\n",
      "Epoch 1239, Loss: 0.0012485619553217475, Final Batch Loss: 9.98339828583994e-07\n",
      "Epoch 1240, Loss: 0.00036184873532363326, Final Batch Loss: 3.313257548143156e-05\n",
      "Epoch 1241, Loss: 0.00036789478834009515, Final Batch Loss: 1.6487302900713985e-07\n",
      "Epoch 1242, Loss: 0.00045983419249751023, Final Batch Loss: 0.00016810826491564512\n",
      "Epoch 1243, Loss: 0.0003894519253080375, Final Batch Loss: 4.782672817782441e-07\n",
      "Epoch 1244, Loss: 0.0001899259710924639, Final Batch Loss: 9.350216714665294e-05\n",
      "Epoch 1245, Loss: 6.840246196304633e-05, Final Batch Loss: 1.4424661003431538e-06\n",
      "Epoch 1246, Loss: 0.0030260865614337717, Final Batch Loss: 4.3079955503344536e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1247, Loss: 0.00045794852363201244, Final Batch Loss: 8.286681918434624e-07\n",
      "Epoch 1248, Loss: 0.0010092017068288328, Final Batch Loss: 4.575219918478979e-06\n",
      "Epoch 1249, Loss: 0.0010976329267862184, Final Batch Loss: 3.2549633033340797e-06\n",
      "Epoch 1250, Loss: 0.0012772209752824892, Final Batch Loss: 0.0001273555535590276\n",
      "Epoch 1251, Loss: 0.0019017773756786482, Final Batch Loss: 1.0090862815559376e-05\n",
      "Epoch 1252, Loss: 6.315456160166377e-05, Final Batch Loss: 2.453479510222678e-06\n",
      "Epoch 1253, Loss: 0.003724214245693247, Final Batch Loss: 2.5523914359837363e-07\n",
      "Epoch 1254, Loss: 0.0002925602796040039, Final Batch Loss: 1.8085328292727354e-06\n",
      "Epoch 1255, Loss: 0.0004093564330105437, Final Batch Loss: 7.284628281922778e-06\n",
      "Epoch 1256, Loss: 0.00021617432996379193, Final Batch Loss: 2.2110937436536915e-07\n",
      "Epoch 1257, Loss: 0.000128120975958268, Final Batch Loss: 1.5741076140329824e-06\n",
      "Epoch 1258, Loss: 0.000275474465787795, Final Batch Loss: 3.818771347141592e-06\n",
      "Epoch 1259, Loss: 0.0001420172765485006, Final Batch Loss: 1.1266762385275797e-06\n",
      "Epoch 1260, Loss: 0.0007217649736759313, Final Batch Loss: 9.874317765934393e-05\n",
      "Epoch 1261, Loss: 0.0002520913520740464, Final Batch Loss: 5.103167950437637e-06\n",
      "Epoch 1262, Loss: 0.00013243789851458132, Final Batch Loss: 1.1939383739445475e-06\n",
      "Epoch 1263, Loss: 0.00012743302308493298, Final Batch Loss: 7.248077054100577e-07\n",
      "Epoch 1264, Loss: 0.0007381019785839271, Final Batch Loss: 0.00011829769209725782\n",
      "Epoch 1265, Loss: 0.00013306769560017528, Final Batch Loss: 4.613509190676268e-06\n",
      "Epoch 1266, Loss: 0.000282305395408855, Final Batch Loss: 1.1007586664391056e-07\n",
      "Epoch 1267, Loss: 0.00014722193377814108, Final Batch Loss: 1.6054562479439483e-07\n",
      "Epoch 1268, Loss: 6.584863510283867e-05, Final Batch Loss: 1.3062996231383295e-06\n",
      "Epoch 1269, Loss: 4.8820223270240604e-05, Final Batch Loss: 1.1055663406978056e-07\n",
      "Epoch 1270, Loss: 0.00016441857685123296, Final Batch Loss: 2.7025455437978962e-06\n",
      "Epoch 1271, Loss: 8.328526156731186e-05, Final Batch Loss: 1.2641915247968427e-07\n",
      "Epoch 1272, Loss: 0.00015105246756519364, Final Batch Loss: 1.2621196674444946e-06\n",
      "Epoch 1273, Loss: 0.000671549829018403, Final Batch Loss: 5.567546395468526e-06\n",
      "Epoch 1274, Loss: 0.0001362840677359145, Final Batch Loss: 6.8359909164428245e-06\n",
      "Epoch 1275, Loss: 3.4939539149903e-05, Final Batch Loss: 2.8792291573154216e-07\n",
      "Epoch 1276, Loss: 0.00011168488973289925, Final Batch Loss: 9.661626165780035e-08\n",
      "Epoch 1277, Loss: 6.099498818912252e-05, Final Batch Loss: 3.787670550536859e-07\n",
      "Epoch 1278, Loss: 0.00022954034709243842, Final Batch Loss: 3.8645171684947854e-07\n",
      "Epoch 1279, Loss: 0.0008800734553773282, Final Batch Loss: 0.0004996557254344225\n",
      "Epoch 1280, Loss: 5.186691775804775e-05, Final Batch Loss: 1.0343641179133556e-06\n",
      "Epoch 1281, Loss: 0.00010623132112641542, Final Batch Loss: 9.705248885438778e-06\n",
      "Epoch 1282, Loss: 2.4239559309080505e-05, Final Batch Loss: 4.585790520650335e-06\n",
      "Epoch 1283, Loss: 0.000542762304974076, Final Batch Loss: 2.343236928936676e-06\n",
      "Epoch 1284, Loss: 0.00011480853289924653, Final Batch Loss: 7.555652814517089e-07\n",
      "Epoch 1285, Loss: 0.00035507841873538837, Final Batch Loss: 2.624483101953956e-07\n",
      "Epoch 1286, Loss: 7.028465113290139e-05, Final Batch Loss: 7.161963253565773e-07\n",
      "Epoch 1287, Loss: 9.922209459034548e-05, Final Batch Loss: 6.777608518859779e-08\n",
      "Epoch 1288, Loss: 8.751895153125133e-05, Final Batch Loss: 1.0863286803441952e-07\n",
      "Epoch 1289, Loss: 0.00011968360077219131, Final Batch Loss: 1.2323281225690152e-05\n",
      "Epoch 1290, Loss: 0.0001020232175008573, Final Batch Loss: 4.326135893961691e-08\n",
      "Epoch 1291, Loss: 0.0019886425044575162, Final Batch Loss: 3.116667357971892e-05\n",
      "Epoch 1292, Loss: 0.00020371318639433866, Final Batch Loss: 5.584713653661311e-05\n",
      "Epoch 1293, Loss: 0.00011558393329380579, Final Batch Loss: 1.773705236018941e-07\n",
      "Epoch 1294, Loss: 0.0002327557695096516, Final Batch Loss: 8.164724931702949e-06\n",
      "Epoch 1295, Loss: 8.774013195989028e-05, Final Batch Loss: 1.4098575775278732e-05\n",
      "Epoch 1296, Loss: 0.0003462261697038116, Final Batch Loss: 3.3117729003606655e-07\n",
      "Epoch 1297, Loss: 8.252732860825063e-05, Final Batch Loss: 3.597558361434494e-06\n",
      "Epoch 1298, Loss: 0.0005179734300160277, Final Batch Loss: 9.7577988356079e-08\n",
      "Epoch 1299, Loss: 0.01340069441142333, Final Batch Loss: 0.00044418603647500277\n",
      "Epoch 1300, Loss: 0.022648007562523276, Final Batch Loss: 0.0038102404214441776\n",
      "Epoch 1301, Loss: 0.0010317613075514487, Final Batch Loss: 1.4335800187836867e-05\n",
      "Epoch 1302, Loss: 0.001499349080859247, Final Batch Loss: 2.3669238089496503e-06\n",
      "Epoch 1303, Loss: 0.006047645870774332, Final Batch Loss: 5.455484028971114e-07\n",
      "Epoch 1304, Loss: 9.142442185083866e-05, Final Batch Loss: 2.4947161136879004e-07\n",
      "Epoch 1305, Loss: 0.00015980719717845204, Final Batch Loss: 2.557210052600567e-07\n",
      "Epoch 1306, Loss: 0.00011263735741451342, Final Batch Loss: 1.95558504856308e-06\n",
      "Epoch 1307, Loss: 0.0002563491367197912, Final Batch Loss: 5.431473368844308e-07\n",
      "Epoch 1308, Loss: 0.00018833203425216993, Final Batch Loss: 5.7427432693657465e-06\n",
      "Epoch 1309, Loss: 0.00014581887236175817, Final Batch Loss: 8.918024832382798e-06\n",
      "Epoch 1310, Loss: 0.0002584534832266172, Final Batch Loss: 1.037511810864089e-05\n",
      "Epoch 1311, Loss: 0.00017331353663507798, Final Batch Loss: 2.5812295234572957e-07\n",
      "Epoch 1312, Loss: 0.00014916622284033565, Final Batch Loss: 1.7544665809055005e-07\n",
      "Epoch 1313, Loss: 0.0009330254899850843, Final Batch Loss: 3.1387767762680596e-07\n",
      "Epoch 1314, Loss: 0.00015830675679495698, Final Batch Loss: 3.138779050004814e-07\n",
      "Epoch 1315, Loss: 0.0003540708543994242, Final Batch Loss: 2.78789940466595e-07\n",
      "Epoch 1316, Loss: 0.0003401579046702352, Final Batch Loss: 5.476284968608525e-06\n",
      "Epoch 1317, Loss: 0.00020116973450967635, Final Batch Loss: 8.390816219616681e-06\n",
      "Epoch 1318, Loss: 0.0004231636068432465, Final Batch Loss: 2.840765205291973e-07\n",
      "Epoch 1319, Loss: 0.0003419312580608125, Final Batch Loss: 1.0526908056363027e-07\n",
      "Epoch 1320, Loss: 0.00017676996363746866, Final Batch Loss: 9.277082568814876e-08\n",
      "Epoch 1321, Loss: 0.00012033445144155053, Final Batch Loss: 3.752312068172614e-06\n",
      "Epoch 1322, Loss: 0.0006532961241560997, Final Batch Loss: 3.749257473373291e-07\n",
      "Epoch 1323, Loss: 0.02602062805381422, Final Batch Loss: 2.139011741064678e-07\n",
      "Epoch 1324, Loss: 0.01446139357805265, Final Batch Loss: 6.853206286905333e-06\n",
      "Epoch 1325, Loss: 0.002355528731680323, Final Batch Loss: 2.5476150966596833e-08\n",
      "Epoch 1326, Loss: 0.019347565703071723, Final Batch Loss: 5.931434543526848e-07\n",
      "Epoch 1327, Loss: 9.413199877883471e-05, Final Batch Loss: 3.0229341518861474e-06\n",
      "Epoch 1328, Loss: 0.01949151592656051, Final Batch Loss: 8.587854608776979e-06\n",
      "Epoch 1329, Loss: 0.00012454028234998304, Final Batch Loss: 3.1397517886944115e-05\n",
      "Epoch 1330, Loss: 0.0016929063584427695, Final Batch Loss: 1.8327138604945503e-05\n",
      "Epoch 1331, Loss: 0.00020768476815646864, Final Batch Loss: 1.6856806723808404e-06\n",
      "Epoch 1332, Loss: 0.0004204473343634163, Final Batch Loss: 3.0003298888914287e-05\n",
      "Epoch 1333, Loss: 0.0005661159992627063, Final Batch Loss: 0.0004824975039809942\n",
      "Epoch 1334, Loss: 0.002795492118139009, Final Batch Loss: 1.748639760990045e-06\n",
      "Epoch 1335, Loss: 0.0004455986519893429, Final Batch Loss: 4.902953421037637e-08\n",
      "Epoch 1336, Loss: 0.001558967334119643, Final Batch Loss: 4.090557013114449e-06\n",
      "Epoch 1337, Loss: 0.0026655165251057156, Final Batch Loss: 2.071728317787347e-07\n",
      "Epoch 1338, Loss: 0.006404731863943525, Final Batch Loss: 3.5863865832652664e-06\n",
      "Epoch 1339, Loss: 0.004587163711875064, Final Batch Loss: 1.0478057674845331e-06\n",
      "Epoch 1340, Loss: 7.083480895175853e-05, Final Batch Loss: 1.0458903716425993e-06\n",
      "Epoch 1341, Loss: 0.00013606013283151697, Final Batch Loss: 4.287194315111265e-06\n",
      "Epoch 1342, Loss: 0.0001702527950158128, Final Batch Loss: 3.1916229659145756e-07\n",
      "Epoch 1343, Loss: 0.00012218056370727481, Final Batch Loss: 4.885936050413875e-06\n",
      "Epoch 1344, Loss: 0.0006599094421346763, Final Batch Loss: 0.0002934943186119199\n",
      "Epoch 1345, Loss: 6.166078364344685e-05, Final Batch Loss: 1.8470468603482004e-06\n",
      "Epoch 1346, Loss: 3.4771396126842546e-05, Final Batch Loss: 1.4564527361926594e-07\n",
      "Epoch 1347, Loss: 0.00043744415189905794, Final Batch Loss: 1.0623040225254954e-07\n",
      "Epoch 1348, Loss: 2.418440003282285e-05, Final Batch Loss: 2.531960717533366e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1349, Loss: 0.00025287813751262433, Final Batch Loss: 5.758466841143672e-07\n",
      "Epoch 1350, Loss: 0.00014511615212597917, Final Batch Loss: 4.38306960859336e-06\n",
      "Epoch 1351, Loss: 0.0005962794941929417, Final Batch Loss: 1.5461535440408625e-05\n",
      "Epoch 1352, Loss: 0.00010343745726260067, Final Batch Loss: 6.615534948650748e-05\n",
      "Epoch 1353, Loss: 4.5707465318400864e-05, Final Batch Loss: 5.027670226809278e-07\n",
      "Epoch 1354, Loss: 0.00019738657503864943, Final Batch Loss: 9.08487223227894e-08\n",
      "Epoch 1355, Loss: 9.223241336542287e-05, Final Batch Loss: 1.5899371419436648e-06\n",
      "Epoch 1356, Loss: 0.00012928935374745265, Final Batch Loss: 1.3385624697548337e-06\n",
      "Epoch 1357, Loss: 0.0012377726070127437, Final Batch Loss: 3.928631031158147e-06\n",
      "Epoch 1358, Loss: 0.0001844031263456003, Final Batch Loss: 6.689429028483573e-06\n",
      "Epoch 1359, Loss: 4.827547945751576e-05, Final Batch Loss: 4.888304374617292e-07\n",
      "Epoch 1360, Loss: 8.924815273658737e-05, Final Batch Loss: 3.730042976712866e-07\n",
      "Epoch 1361, Loss: 3.595318109361756e-05, Final Batch Loss: 2.6068748866237e-06\n",
      "Epoch 1362, Loss: 7.212529623235042e-05, Final Batch Loss: 1.499137215432711e-05\n",
      "Epoch 1363, Loss: 4.8635366145077796e-05, Final Batch Loss: 2.3216614408738678e-07\n",
      "Epoch 1364, Loss: 3.6668773219616924e-05, Final Batch Loss: 2.215543872807757e-06\n",
      "Epoch 1365, Loss: 2.6449122534799585e-05, Final Batch Loss: 3.152653789584292e-06\n",
      "Epoch 1366, Loss: 1.778010601327651e-05, Final Batch Loss: 1.5172472558333538e-06\n",
      "Epoch 1367, Loss: 3.319963056824804e-05, Final Batch Loss: 3.701251571897046e-08\n",
      "Epoch 1368, Loss: 3.0066695202890514e-05, Final Batch Loss: 4.5614928012582823e-07\n",
      "Epoch 1369, Loss: 0.00020341856205163822, Final Batch Loss: 8.233562880377576e-07\n",
      "Epoch 1370, Loss: 8.540458004135942e-05, Final Batch Loss: 9.7138013188669e-07\n",
      "Epoch 1371, Loss: 0.0002666967896054473, Final Batch Loss: 2.52356016972044e-07\n",
      "Epoch 1372, Loss: 0.0002643576836334205, Final Batch Loss: 5.441588200483238e-06\n",
      "Epoch 1373, Loss: 0.00015632383193420196, Final Batch Loss: 1.0746249245130457e-05\n",
      "Epoch 1374, Loss: 0.00012730185331122357, Final Batch Loss: 3.438464091232163e-06\n",
      "Epoch 1375, Loss: 0.0006869150440245164, Final Batch Loss: 3.480062105154502e-07\n",
      "Epoch 1376, Loss: 0.00020123008463457381, Final Batch Loss: 6.948117516003549e-05\n",
      "Epoch 1377, Loss: 9.146088978440048e-05, Final Batch Loss: 1.12859629552986e-06\n",
      "Epoch 1378, Loss: 3.272265471565561e-05, Final Batch Loss: 9.278040124627296e-06\n",
      "Epoch 1379, Loss: 0.0001528112832644979, Final Batch Loss: 4.5183966790318664e-08\n",
      "Epoch 1380, Loss: 1.8188455392476044e-05, Final Batch Loss: 3.46091084679756e-08\n",
      "Epoch 1381, Loss: 3.519432895426888e-05, Final Batch Loss: 2.118626753144781e-06\n",
      "Epoch 1382, Loss: 6.637314669610817e-05, Final Batch Loss: 6.777599281804214e-08\n",
      "Epoch 1383, Loss: 9.124586830822068e-05, Final Batch Loss: 3.277300493209623e-05\n",
      "Epoch 1384, Loss: 0.00026334008855055657, Final Batch Loss: 1.1295975355096743e-07\n",
      "Epoch 1385, Loss: 4.89484161203535e-05, Final Batch Loss: 5.176211743673775e-06\n",
      "Epoch 1386, Loss: 5.254426157907943e-05, Final Batch Loss: 3.792447387240827e-07\n",
      "Epoch 1387, Loss: 3.709340103696945e-05, Final Batch Loss: 3.350251631673018e-07\n",
      "Epoch 1388, Loss: 0.0001299429810330821, Final Batch Loss: 7.553835530416109e-06\n",
      "Epoch 1389, Loss: 4.836764908588975e-05, Final Batch Loss: 7.671105208828521e-07\n",
      "Epoch 1390, Loss: 0.00010653477357358554, Final Batch Loss: 1.538163445502505e-07\n",
      "Epoch 1391, Loss: 4.296297569439389e-05, Final Batch Loss: 7.546678659764439e-08\n",
      "Epoch 1392, Loss: 0.0013662130461802313, Final Batch Loss: 7.209699219856702e-07\n",
      "Epoch 1393, Loss: 5.2195599433702e-05, Final Batch Loss: 3.5089716021730055e-08\n",
      "Epoch 1394, Loss: 3.764243395387723e-05, Final Batch Loss: 2.4995467029498286e-08\n",
      "Epoch 1395, Loss: 0.0002704534993052121, Final Batch Loss: 1.49971128848847e-07\n",
      "Epoch 1396, Loss: 0.00031421489311156403, Final Batch Loss: 4.614533111180208e-08\n",
      "Epoch 1397, Loss: 8.537019257071066e-05, Final Batch Loss: 1.2077879546268377e-05\n",
      "Epoch 1398, Loss: 3.0586383168440534e-05, Final Batch Loss: 8.709663234185427e-06\n",
      "Epoch 1399, Loss: 7.886434324611002e-05, Final Batch Loss: 2.4034083168089637e-08\n",
      "Epoch 1400, Loss: 4.8464492648392365e-05, Final Batch Loss: 2.3841569429805531e-07\n",
      "Epoch 1401, Loss: 0.0005493139364243227, Final Batch Loss: 1.8601998874601122e-07\n",
      "Epoch 1402, Loss: 0.0022484913638662896, Final Batch Loss: 0.0022173020988702774\n",
      "Epoch 1403, Loss: 0.0002953329152224349, Final Batch Loss: 2.0015857444377616e-05\n",
      "Epoch 1404, Loss: 3.488615445146337e-05, Final Batch Loss: 6.056582435576274e-08\n",
      "Epoch 1405, Loss: 9.255236316008109e-06, Final Batch Loss: 1.3939785326044785e-08\n",
      "Epoch 1406, Loss: 3.6534814531696824e-05, Final Batch Loss: 1.1799569620052353e-05\n",
      "Epoch 1407, Loss: 8.239339767790455e-05, Final Batch Loss: 5.1618280849652365e-05\n",
      "Epoch 1408, Loss: 1.0681051459737745e-05, Final Batch Loss: 1.0190407095933551e-07\n",
      "Epoch 1409, Loss: 4.4272948915846655e-05, Final Batch Loss: 1.97079632613395e-08\n",
      "Epoch 1410, Loss: 2.7271425138364336e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 1411, Loss: 0.00025937021977728847, Final Batch Loss: 6.2488698659990405e-09\n",
      "Epoch 1412, Loss: 1.53999063834398e-05, Final Batch Loss: 1.4420466598608073e-08\n",
      "Epoch 1413, Loss: 2.2062793254562507e-05, Final Batch Loss: 6.74617922413745e-06\n",
      "Epoch 1414, Loss: 0.0006465070457253308, Final Batch Loss: 1.1440106106874737e-07\n",
      "Epoch 1415, Loss: 1.0558509028313345e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 1416, Loss: 1.877572976616282e-05, Final Batch Loss: 3.0282926388736087e-08\n",
      "Epoch 1417, Loss: 1.628013318200061e-05, Final Batch Loss: 6.24887164235588e-09\n",
      "Epoch 1418, Loss: 2.817953136347029e-05, Final Batch Loss: 2.5956822469197505e-08\n",
      "Epoch 1419, Loss: 1.1693144069901962e-05, Final Batch Loss: 1.7022247220666031e-06\n",
      "Epoch 1420, Loss: 0.00035320493657131635, Final Batch Loss: 1.4420468374964912e-08\n",
      "Epoch 1421, Loss: 0.0003833282436520591, Final Batch Loss: 6.681469244540494e-08\n",
      "Epoch 1422, Loss: 0.00020934393889482372, Final Batch Loss: 7.224156206575572e-07\n",
      "Epoch 1423, Loss: 0.00012929792429616782, Final Batch Loss: 3.19817045237869e-05\n",
      "Epoch 1424, Loss: 9.455094999277769e-06, Final Batch Loss: 8.796456540949293e-08\n",
      "Epoch 1425, Loss: 1.9374913023728624e-05, Final Batch Loss: 1.6343200570645422e-08\n",
      "Epoch 1426, Loss: 0.00038601063349275044, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 1427, Loss: 0.00010599729308158334, Final Batch Loss: 5.81624810536141e-08\n",
      "Epoch 1428, Loss: 7.81344327620559e-05, Final Batch Loss: 2.643747798458662e-08\n",
      "Epoch 1429, Loss: 2.5381149628245225e-05, Final Batch Loss: 6.122854301793268e-06\n",
      "Epoch 1430, Loss: 5.9079005008122465e-06, Final Batch Loss: 3.677136817259452e-07\n",
      "Epoch 1431, Loss: 3.982552247505655e-05, Final Batch Loss: 1.1536278776702602e-07\n",
      "Epoch 1432, Loss: 1.4685679530002105e-05, Final Batch Loss: 1.0338478659832617e-06\n",
      "Epoch 1433, Loss: 0.00011824547796723817, Final Batch Loss: 3.941437682897231e-07\n",
      "Epoch 1434, Loss: 6.442217068114431e-05, Final Batch Loss: 8.02734518856596e-08\n",
      "Epoch 1435, Loss: 1.2481574316658417e-05, Final Batch Loss: 2.0188657856579084e-08\n",
      "Epoch 1436, Loss: 3.071633312312638e-05, Final Batch Loss: 1.4372200496381993e-07\n",
      "Epoch 1437, Loss: 2.8828274387660002e-06, Final Batch Loss: 1.225727430664847e-07\n",
      "Epoch 1438, Loss: 0.00010896691643580425, Final Batch Loss: 2.1438142994156806e-07\n",
      "Epoch 1439, Loss: 1.3502316953406535e-05, Final Batch Loss: 3.701239492670538e-08\n",
      "Epoch 1440, Loss: 2.8050587992711762e-05, Final Batch Loss: 3.4896254419436445e-07\n",
      "Epoch 1441, Loss: 4.340354600695928e-05, Final Batch Loss: 2.488275094947312e-05\n",
      "Epoch 1442, Loss: 2.9026695057776664e-05, Final Batch Loss: 6.393057816467262e-08\n",
      "Epoch 1443, Loss: 0.0013297746270399813, Final Batch Loss: 7.565580517621129e-07\n",
      "Epoch 1444, Loss: 1.357229696230533e-05, Final Batch Loss: 0.0\n",
      "Epoch 1445, Loss: 8.183795375260594e-06, Final Batch Loss: 8.171598508965872e-09\n",
      "Epoch 1446, Loss: 1.6822287622897392e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 1447, Loss: 9.109913897509259e-05, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 1448, Loss: 9.59198948491391e-06, Final Batch Loss: 7.233679752971511e-07\n",
      "Epoch 1449, Loss: 2.055011913248972e-05, Final Batch Loss: 1.297842011638295e-08\n",
      "Epoch 1450, Loss: 0.0005154879823452418, Final Batch Loss: 1.0575013753566509e-08\n",
      "Epoch 1451, Loss: 2.0322727942279073e-05, Final Batch Loss: 1.0222875062027015e-06\n",
      "Epoch 1452, Loss: 3.478546100366131e-05, Final Batch Loss: 7.502953280891234e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1453, Loss: 7.772427482155564e-05, Final Batch Loss: 2.6918195672465117e-08\n",
      "Epoch 1454, Loss: 3.167956784244641e-05, Final Batch Loss: 5.469809138958226e-07\n",
      "Epoch 1455, Loss: 0.0006785363348580375, Final Batch Loss: 1.189587237604428e-06\n",
      "Epoch 1456, Loss: 2.166780642709476e-05, Final Batch Loss: 4.287529407065449e-07\n",
      "Epoch 1457, Loss: 4.108477006359301e-05, Final Batch Loss: 2.0957301671842288e-07\n",
      "Epoch 1458, Loss: 1.904782294337437e-06, Final Batch Loss: 2.225507813591321e-07\n",
      "Epoch 1459, Loss: 7.953500080648546e-06, Final Batch Loss: 1.5381594664631848e-07\n",
      "Epoch 1460, Loss: 4.183462031792651e-06, Final Batch Loss: 1.9176256955688586e-06\n",
      "Epoch 1461, Loss: 2.5441923119373655e-06, Final Batch Loss: 5.287507764961674e-09\n",
      "Epoch 1462, Loss: 3.6084844692307882e-06, Final Batch Loss: 1.216118619140616e-07\n",
      "Epoch 1463, Loss: 5.6488689893385846e-05, Final Batch Loss: 5.070890551905904e-07\n",
      "Epoch 1464, Loss: 1.8896622380193406e-05, Final Batch Loss: 2.2495326845728414e-07\n",
      "Epoch 1465, Loss: 7.886326302353197e-05, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 1466, Loss: 4.1374978396069295e-05, Final Batch Loss: 3.7973858724171805e-08\n",
      "Epoch 1467, Loss: 3.991931680880079e-06, Final Batch Loss: 2.403410093165803e-08\n",
      "Epoch 1468, Loss: 8.964255466326065e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1469, Loss: 2.0818912886966245e-06, Final Batch Loss: 1.8842628435322695e-07\n",
      "Epoch 1470, Loss: 6.933030683020647e-05, Final Batch Loss: 7.162149273653995e-08\n",
      "Epoch 1471, Loss: 2.2699046772434173e-05, Final Batch Loss: 7.210237296106925e-09\n",
      "Epoch 1472, Loss: 0.00031461671629839927, Final Batch Loss: 1.0575007536317571e-08\n",
      "Epoch 1473, Loss: 6.835212362266141e-05, Final Batch Loss: 9.194424706038262e-07\n",
      "Epoch 1474, Loss: 0.00018712334267456665, Final Batch Loss: 0.00016248419706244022\n",
      "Epoch 1475, Loss: 0.00017364556893451066, Final Batch Loss: 5.287507764961674e-09\n",
      "Epoch 1476, Loss: 8.339773129861783e-06, Final Batch Loss: 1.057501020085283e-08\n",
      "Epoch 1477, Loss: 3.851789234943226e-05, Final Batch Loss: 6.801278686907608e-06\n",
      "Epoch 1478, Loss: 4.9937606602323825e-05, Final Batch Loss: 1.4324210440008756e-07\n",
      "Epoch 1479, Loss: 0.00022443000572691663, Final Batch Loss: 2.1250214103929466e-06\n",
      "Epoch 1480, Loss: 7.488939410316142e-05, Final Batch Loss: 2.9802222911712306e-08\n",
      "Epoch 1481, Loss: 1.2353707405154957e-05, Final Batch Loss: 1.5229966265906114e-06\n",
      "Epoch 1482, Loss: 0.0007433432150047992, Final Batch Loss: 0.0\n",
      "Epoch 1483, Loss: 4.6233403335760315e-06, Final Batch Loss: 4.710665990614871e-08\n",
      "Epoch 1484, Loss: 3.498166446025408e-05, Final Batch Loss: 3.843632839561906e-06\n",
      "Epoch 1485, Loss: 2.7671426893305373e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 1486, Loss: 8.991853071971256e-05, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 1487, Loss: 9.586072836853532e-06, Final Batch Loss: 4.5135124082662514e-07\n",
      "Epoch 1488, Loss: 3.959169434408771e-06, Final Batch Loss: 5.431698824054365e-08\n",
      "Epoch 1489, Loss: 2.098908774872399e-05, Final Batch Loss: 4.374197359879872e-08\n",
      "Epoch 1490, Loss: 0.08291358603806731, Final Batch Loss: 4.480762981984299e-06\n",
      "Epoch 1491, Loss: 0.001236096797931463, Final Batch Loss: 1.7688741138499608e-07\n",
      "Epoch 1492, Loss: 1.5810215659661786e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 1493, Loss: 3.7162463359941e-06, Final Batch Loss: 0.0\n",
      "Epoch 1494, Loss: 7.438228421718929e-05, Final Batch Loss: 1.251051571671269e-06\n",
      "Epoch 1495, Loss: 1.4742698035363766e-05, Final Batch Loss: 5.0471392398776516e-08\n",
      "Epoch 1496, Loss: 6.181286233886141e-05, Final Batch Loss: 2.932156384360951e-08\n",
      "Epoch 1497, Loss: 3.515096198780654e-06, Final Batch Loss: 1.2668846238739206e-06\n",
      "Epoch 1498, Loss: 0.00024981634871457103, Final Batch Loss: 1.057501020085283e-08\n",
      "Epoch 1499, Loss: 7.848282222921998e-05, Final Batch Loss: 6.835072667854547e-07\n",
      "Epoch 1500, Loss: 0.00021416119782580179, Final Batch Loss: 3.076361565490515e-08\n",
      "Epoch 1501, Loss: 5.73959394589707e-06, Final Batch Loss: 4.0135086010195664e-07\n",
      "Epoch 1502, Loss: 7.020504337207356e-06, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 1503, Loss: 1.663056919254391e-05, Final Batch Loss: 1.2978425445453468e-08\n",
      "Epoch 1504, Loss: 1.139342631972795e-05, Final Batch Loss: 4.566468092548348e-08\n",
      "Epoch 1505, Loss: 1.054310392722968e-05, Final Batch Loss: 7.376554549409775e-06\n",
      "Epoch 1506, Loss: 5.281779403398801e-06, Final Batch Loss: 2.163069900973369e-08\n",
      "Epoch 1507, Loss: 0.0006341071572213419, Final Batch Loss: 0.0005930259940214455\n",
      "Epoch 1508, Loss: 0.00042146364393569336, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 1509, Loss: 0.0039011446989654086, Final Batch Loss: 6.815748747612815e-07\n",
      "Epoch 1510, Loss: 0.006664247523821221, Final Batch Loss: 1.3458983971759153e-07\n",
      "Epoch 1511, Loss: 0.010056819604923106, Final Batch Loss: 4.375016942503862e-05\n",
      "Epoch 1512, Loss: 0.04842502922968883, Final Batch Loss: 7.53362428440596e-06\n",
      "Epoch 1513, Loss: 0.009624218426068865, Final Batch Loss: 6.798656977480277e-05\n",
      "Epoch 1514, Loss: 0.008569961096583256, Final Batch Loss: 5.7990018831333145e-06\n",
      "Epoch 1515, Loss: 0.0036404884552183603, Final Batch Loss: 3.268634429787198e-08\n",
      "Epoch 1516, Loss: 5.3627520983035026e-05, Final Batch Loss: 7.3907035584852565e-06\n",
      "Epoch 1517, Loss: 0.00018296614102730757, Final Batch Loss: 4.566472000533395e-08\n",
      "Epoch 1518, Loss: 8.502685101241525e-05, Final Batch Loss: 5.23941459107391e-08\n",
      "Epoch 1519, Loss: 6.189366583164713e-05, Final Batch Loss: 1.1007553979425211e-07\n",
      "Epoch 1520, Loss: 5.3728554291865294e-05, Final Batch Loss: 5.635029538098024e-06\n",
      "Epoch 1521, Loss: 3.457391513705943e-05, Final Batch Loss: 1.2177413736935705e-05\n",
      "Epoch 1522, Loss: 5.293480623436153e-05, Final Batch Loss: 1.9372814676898997e-06\n",
      "Epoch 1523, Loss: 2.6416877140889028e-05, Final Batch Loss: 1.1827457456092816e-05\n",
      "Epoch 1524, Loss: 5.389184044801709e-05, Final Batch Loss: 1.898788923426764e-06\n",
      "Epoch 1525, Loss: 0.00012600150584418657, Final Batch Loss: 2.5908070711011533e-07\n",
      "Epoch 1526, Loss: 9.823178146817213e-05, Final Batch Loss: 5.575904538090981e-08\n",
      "Epoch 1527, Loss: 0.00020274135958564532, Final Batch Loss: 1.9060606064158492e-05\n",
      "Epoch 1528, Loss: 5.179741508953839e-05, Final Batch Loss: 5.436364745037281e-07\n",
      "Epoch 1529, Loss: 0.00016951023944589139, Final Batch Loss: 2.388966606758913e-07\n",
      "Epoch 1530, Loss: 0.00023590521880834103, Final Batch Loss: 4.840240421799535e-07\n",
      "Epoch 1531, Loss: 9.697956714482814e-05, Final Batch Loss: 4.510523285716772e-05\n",
      "Epoch 1532, Loss: 0.00014823171424538373, Final Batch Loss: 2.879925204979372e-06\n",
      "Epoch 1533, Loss: 2.2990201178352265e-05, Final Batch Loss: 2.0380640819439577e-07\n",
      "Epoch 1534, Loss: 3.577932699183606e-05, Final Batch Loss: 8.435496852143842e-07\n",
      "Epoch 1535, Loss: 2.494716472511982e-05, Final Batch Loss: 2.2255335352383554e-07\n",
      "Epoch 1536, Loss: 2.981631734333412e-05, Final Batch Loss: 1.3259880233817967e-06\n",
      "Epoch 1537, Loss: 4.8365172903075404e-05, Final Batch Loss: 3.3110115964518627e-06\n",
      "Epoch 1538, Loss: 0.00022677248897906566, Final Batch Loss: 3.3369944958394626e-06\n",
      "Epoch 1539, Loss: 7.493429907867721e-05, Final Batch Loss: 1.2113140712699533e-07\n",
      "Epoch 1540, Loss: 7.723739631537718e-06, Final Batch Loss: 1.658512815083668e-06\n",
      "Epoch 1541, Loss: 1.3875503274807244e-05, Final Batch Loss: 3.941590875911061e-08\n",
      "Epoch 1542, Loss: 2.9129576099684584e-05, Final Batch Loss: 6.151507022877922e-06\n",
      "Epoch 1543, Loss: 2.4435532661071235e-05, Final Batch Loss: 1.2017057571256373e-08\n",
      "Epoch 1544, Loss: 3.1056873670998186e-05, Final Batch Loss: 8.916185265661625e-07\n",
      "Epoch 1545, Loss: 0.0001393046452662361, Final Batch Loss: 4.258622357156128e-05\n",
      "Epoch 1546, Loss: 0.0002952349782887609, Final Batch Loss: 0.0001903781230794266\n",
      "Epoch 1547, Loss: 1.9718217052044906e-05, Final Batch Loss: 6.521205705212196e-06\n",
      "Epoch 1548, Loss: 3.2145619298873385e-05, Final Batch Loss: 5.570175289904e-06\n",
      "Epoch 1549, Loss: 0.00032566007437395683, Final Batch Loss: 1.3034308494752622e-06\n",
      "Epoch 1550, Loss: 0.00018243132200446155, Final Batch Loss: 3.816477374130045e-07\n",
      "Epoch 1551, Loss: 7.454975879195302e-05, Final Batch Loss: 3.423025191295892e-05\n",
      "Epoch 1552, Loss: 0.0003537782329385841, Final Batch Loss: 1.249774239653334e-08\n",
      "Epoch 1553, Loss: 4.716156972950358e-05, Final Batch Loss: 3.475239509498351e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1554, Loss: 2.5648889172558142e-05, Final Batch Loss: 5.3671565183321945e-06\n",
      "Epoch 1555, Loss: 0.0002920077734476223, Final Batch Loss: 1.0286546370252836e-07\n",
      "Epoch 1556, Loss: 7.2291730459639325e-06, Final Batch Loss: 3.74931587998617e-08\n",
      "Epoch 1557, Loss: 4.9887470598974915e-05, Final Batch Loss: 1.0021163916462683e-06\n",
      "Epoch 1558, Loss: 1.33399112067778e-05, Final Batch Loss: 6.29690148912232e-08\n",
      "Epoch 1559, Loss: 2.499179875981028e-05, Final Batch Loss: 2.0708946522063343e-06\n",
      "Epoch 1560, Loss: 1.0773713923661887e-05, Final Batch Loss: 7.065542035888939e-07\n",
      "Epoch 1561, Loss: 1.7452500116643677e-05, Final Batch Loss: 2.898457580613467e-07\n",
      "Epoch 1562, Loss: 5.6539915068043456e-05, Final Batch Loss: 7.123089744709432e-07\n",
      "Epoch 1563, Loss: 4.547020722922568e-05, Final Batch Loss: 3.860446213366231e-06\n",
      "Epoch 1564, Loss: 2.1375056905803547e-05, Final Batch Loss: 9.540497103444068e-07\n",
      "Epoch 1565, Loss: 3.0678135526818195e-05, Final Batch Loss: 9.252083259525534e-07\n",
      "Epoch 1566, Loss: 2.0698777558614267e-06, Final Batch Loss: 5.9123763662682904e-08\n",
      "Epoch 1567, Loss: 8.842096350436535e-06, Final Batch Loss: 6.39302797367236e-08\n",
      "Epoch 1568, Loss: 2.34639570377837e-05, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 1569, Loss: 2.2812834671981363e-05, Final Batch Loss: 3.3598982440707914e-07\n",
      "Epoch 1570, Loss: 2.421081023840088e-05, Final Batch Loss: 8.693092240719125e-06\n",
      "Epoch 1571, Loss: 0.0001225397586994692, Final Batch Loss: 1.1728501903007782e-07\n",
      "Epoch 1572, Loss: 0.00019460073914190357, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 1573, Loss: 7.338378077648144e-05, Final Batch Loss: 1.0742708127509104e-06\n",
      "Epoch 1574, Loss: 3.625622397762651e-05, Final Batch Loss: 1.3939596499312756e-07\n",
      "Epoch 1575, Loss: 5.9488238171256924e-05, Final Batch Loss: 3.818173809122527e-06\n",
      "Epoch 1576, Loss: 6.267483614841307e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1577, Loss: 2.7033218178651452e-05, Final Batch Loss: 9.132959277735608e-09\n",
      "Epoch 1578, Loss: 0.00023769965000075555, Final Batch Loss: 3.2444830821987125e-07\n",
      "Epoch 1579, Loss: 0.00029089490111999794, Final Batch Loss: 2.5713454760989407e-06\n",
      "Epoch 1580, Loss: 0.00047114397533354335, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 1581, Loss: 1.1415842707585e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1582, Loss: 1.0507879927068586e-05, Final Batch Loss: 1.3026433975937834e-07\n",
      "Epoch 1583, Loss: 4.759021121514273e-06, Final Batch Loss: 3.316703356404105e-08\n",
      "Epoch 1584, Loss: 1.6021585773629e-06, Final Batch Loss: 4.8068251601307566e-09\n",
      "Epoch 1585, Loss: 8.587202685461648e-05, Final Batch Loss: 1.0440877304063179e-05\n",
      "Epoch 1586, Loss: 0.0001948372190673231, Final Batch Loss: 4.094173709745519e-05\n",
      "Epoch 1587, Loss: 5.8154226703743817e-05, Final Batch Loss: 3.78143486159388e-05\n",
      "Epoch 1588, Loss: 6.033388598847278e-05, Final Batch Loss: 2.460853238517302e-06\n",
      "Epoch 1589, Loss: 2.9464465928219497e-06, Final Batch Loss: 9.036771331238924e-08\n",
      "Epoch 1590, Loss: 7.367682471226544e-06, Final Batch Loss: 1.970796859041002e-08\n",
      "Epoch 1591, Loss: 5.522860009277153e-05, Final Batch Loss: 1.7304421362496214e-07\n",
      "Epoch 1592, Loss: 9.313612848949049e-06, Final Batch Loss: 1.9034683873542235e-07\n",
      "Epoch 1593, Loss: 1.1727864345889571e-05, Final Batch Loss: 2.499545992407093e-08\n",
      "Epoch 1594, Loss: 4.77247152046445e-05, Final Batch Loss: 0.0\n",
      "Epoch 1595, Loss: 2.0548966608524566e-05, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 1596, Loss: 3.450679755745423e-05, Final Batch Loss: 8.247931191363023e-07\n",
      "Epoch 1597, Loss: 5.184458830909122e-06, Final Batch Loss: 1.480491675920348e-07\n",
      "Epoch 1598, Loss: 3.384449008714263e-06, Final Batch Loss: 3.3647662434077574e-08\n",
      "Epoch 1599, Loss: 7.168381992228579e-05, Final Batch Loss: 1.1199760052704733e-07\n",
      "Epoch 1600, Loss: 2.5068213801326955e-05, Final Batch Loss: 4.0519617527934315e-07\n",
      "Epoch 1601, Loss: 3.357091040312454e-05, Final Batch Loss: 2.4706648105166096e-07\n",
      "Epoch 1602, Loss: 4.531910293703589e-06, Final Batch Loss: 1.499714130659413e-07\n",
      "Epoch 1603, Loss: 4.2828587951126984e-05, Final Batch Loss: 0.0\n",
      "Epoch 1604, Loss: 0.00021638952033420367, Final Batch Loss: 1.9959421479143202e-05\n",
      "Epoch 1605, Loss: 6.041984071947226e-06, Final Batch Loss: 9.132964606806127e-09\n",
      "Epoch 1606, Loss: 5.572560257682824e-07, Final Batch Loss: 3.94158092831276e-08\n",
      "Epoch 1607, Loss: 1.457273253968605e-05, Final Batch Loss: 2.4514788421470257e-08\n",
      "Epoch 1608, Loss: 1.8379793695011415e-05, Final Batch Loss: 2.307272417567674e-08\n",
      "Epoch 1609, Loss: 0.0005296644090475588, Final Batch Loss: 2.024649575105286e-06\n",
      "Epoch 1610, Loss: 6.874965780667708e-06, Final Batch Loss: 4.287525712243223e-07\n",
      "Epoch 1611, Loss: 1.0063736034515713e-05, Final Batch Loss: 1.2005664302705554e-06\n",
      "Epoch 1612, Loss: 1.4483814251287086e-05, Final Batch Loss: 1.3089583262626547e-05\n",
      "Epoch 1613, Loss: 4.6740037368042664e-05, Final Batch Loss: 9.569355370331323e-07\n",
      "Epoch 1614, Loss: 0.00015613430382799276, Final Batch Loss: 1.5766278238515952e-07\n",
      "Epoch 1615, Loss: 0.00024053633558640541, Final Batch Loss: 5.1432717640409464e-08\n",
      "Epoch 1616, Loss: 3.1536685950461774e-06, Final Batch Loss: 1.2161090978679567e-07\n",
      "Epoch 1617, Loss: 6.780452509791424e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 1618, Loss: 0.0001729327138010328, Final Batch Loss: 2.3553408112775287e-08\n",
      "Epoch 1619, Loss: 6.3496242715954665e-06, Final Batch Loss: 6.825659681908292e-08\n",
      "Epoch 1620, Loss: 0.0019088923921788403, Final Batch Loss: 1.2497734402927563e-08\n",
      "Epoch 1621, Loss: 8.421872413577614e-05, Final Batch Loss: 1.6489224435645156e-05\n",
      "Epoch 1622, Loss: 3.2275538410342364e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 1623, Loss: 0.0001477326914760546, Final Batch Loss: 1.067471430360456e-06\n",
      "Epoch 1624, Loss: 7.515150143255767e-05, Final Batch Loss: 5.959518239251338e-05\n",
      "Epoch 1625, Loss: 1.4373374057408128e-05, Final Batch Loss: 3.927036971163034e-07\n",
      "Epoch 1626, Loss: 2.2704337791501494e-05, Final Batch Loss: 1.2978421892739789e-08\n",
      "Epoch 1627, Loss: 7.253105870397292e-05, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 1628, Loss: 9.855736497121903e-05, Final Batch Loss: 6.008513508959368e-08\n",
      "Epoch 1629, Loss: 2.4333470912352162e-05, Final Batch Loss: 9.709212918096455e-07\n",
      "Epoch 1630, Loss: 5.050690134456026e-06, Final Batch Loss: 1.2497737067462822e-08\n",
      "Epoch 1631, Loss: 1.3039115867363726e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 1632, Loss: 6.571010355616025e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1633, Loss: 7.302760859584367e-06, Final Batch Loss: 3.802020387411176e-07\n",
      "Epoch 1634, Loss: 4.814585643497793e-06, Final Batch Loss: 0.0\n",
      "Epoch 1635, Loss: 2.19680396911226e-05, Final Batch Loss: 0.0\n",
      "Epoch 1636, Loss: 1.1732521286278441e-05, Final Batch Loss: 7.558381639682921e-06\n",
      "Epoch 1637, Loss: 1.2544843726924881e-05, Final Batch Loss: 1.297842011638295e-08\n",
      "Epoch 1638, Loss: 2.762026585312327e-05, Final Batch Loss: 1.6343184583433867e-08\n",
      "Epoch 1639, Loss: 7.1617785283306645e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 1640, Loss: 4.605989996686599e-05, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 1641, Loss: 1.3569248311862125e-05, Final Batch Loss: 9.229054853676644e-08\n",
      "Epoch 1642, Loss: 1.3695663150792292e-05, Final Batch Loss: 8.299579349113628e-06\n",
      "Epoch 1643, Loss: 5.436404430847475e-06, Final Batch Loss: 3.653171987139103e-08\n",
      "Epoch 1644, Loss: 6.0939541579818624e-05, Final Batch Loss: 1.067104378194017e-07\n",
      "Epoch 1645, Loss: 5.840465894801916e-06, Final Batch Loss: 0.0\n",
      "Epoch 1646, Loss: 2.3511622502025986e-05, Final Batch Loss: 1.1536371857800987e-08\n",
      "Epoch 1647, Loss: 5.337742320132843e-05, Final Batch Loss: 8.171595844430612e-09\n",
      "Epoch 1648, Loss: 7.172396191079677e-06, Final Batch Loss: 4.154345333517995e-06\n",
      "Epoch 1649, Loss: 7.198850515377497e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 1650, Loss: 7.762372740360846e-06, Final Batch Loss: 0.0\n",
      "Epoch 1651, Loss: 2.211776635263618e-05, Final Batch Loss: 2.7398851187854234e-08\n",
      "Epoch 1652, Loss: 1.191358617025351e-05, Final Batch Loss: 9.007108587866242e-07\n",
      "Epoch 1653, Loss: 2.3922829565869996e-05, Final Batch Loss: 8.652281557885999e-09\n",
      "Epoch 1654, Loss: 6.681349630544009e-05, Final Batch Loss: 5.287505988604835e-09\n",
      "Epoch 1655, Loss: 4.3271435502867384e-05, Final Batch Loss: 5.8642878997261505e-08\n",
      "Epoch 1656, Loss: 2.30826876823631e-06, Final Batch Loss: 1.9227299752344607e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1657, Loss: 0.0003947652588622841, Final Batch Loss: 4.811351459466096e-07\n",
      "Epoch 1658, Loss: 5.987231924131642e-06, Final Batch Loss: 6.248868977820621e-09\n",
      "Epoch 1659, Loss: 1.2661794091872736e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1660, Loss: 1.4435005930013567e-05, Final Batch Loss: 2.980221580628495e-08\n",
      "Epoch 1661, Loss: 2.865461679490977e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 1662, Loss: 4.388643751407351e-06, Final Batch Loss: 1.537895400360867e-06\n",
      "Epoch 1663, Loss: 1.3335390076640863e-05, Final Batch Loss: 1.3218584626883967e-07\n",
      "Epoch 1664, Loss: 2.133259965308998e-05, Final Batch Loss: 0.0\n",
      "Epoch 1665, Loss: 8.208701686163167e-06, Final Batch Loss: 2.412954529518174e-07\n",
      "Epoch 1666, Loss: 1.588155767617838e-05, Final Batch Loss: 2.5476108334032688e-08\n",
      "Epoch 1667, Loss: 1.4214370948062438e-06, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 1668, Loss: 0.00017477934885345991, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1669, Loss: 3.913521014742294e-05, Final Batch Loss: 2.6437458444661388e-08\n",
      "Epoch 1670, Loss: 1.4868975681925356e-05, Final Batch Loss: 4.0458539842802566e-06\n",
      "Epoch 1671, Loss: 1.7262679808949244e-06, Final Batch Loss: 3.5570479894886375e-08\n",
      "Epoch 1672, Loss: 0.00023084962634301043, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1673, Loss: 4.969551637534764e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1674, Loss: 5.90813607405094e-05, Final Batch Loss: 6.729553359008378e-09\n",
      "Epoch 1675, Loss: 6.068904518119478e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1676, Loss: 2.705668609470635e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 1677, Loss: 7.21281172005872e-05, Final Batch Loss: 2.504315261830925e-07\n",
      "Epoch 1678, Loss: 2.789269239134029e-06, Final Batch Loss: 0.0\n",
      "Epoch 1679, Loss: 3.3080662563689245e-06, Final Batch Loss: 4.326141667121419e-09\n",
      "Epoch 1680, Loss: 5.707407285338029e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1681, Loss: 4.5871558207455365e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1682, Loss: 0.00010009197409388548, Final Batch Loss: 8.457676449324936e-05\n",
      "Epoch 1683, Loss: 8.752427923797157e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1684, Loss: 6.340954470829274e-06, Final Batch Loss: 8.988664745857022e-08\n",
      "Epoch 1685, Loss: 4.396299495557088e-07, Final Batch Loss: 0.0\n",
      "Epoch 1686, Loss: 1.9964467165012323e-06, Final Batch Loss: 1.5381814932879934e-08\n",
      "Epoch 1687, Loss: 9.09757771716535e-06, Final Batch Loss: 5.768187261168123e-09\n",
      "Epoch 1688, Loss: 1.1084243567438534e-06, Final Batch Loss: 4.51839277104682e-08\n",
      "Epoch 1689, Loss: 3.7559233340145326e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 1690, Loss: 7.815120327547831e-07, Final Batch Loss: 0.0\n",
      "Epoch 1691, Loss: 0.019020280594803207, Final Batch Loss: 0.003977315966039896\n",
      "Epoch 1692, Loss: 2.043754741887227e-05, Final Batch Loss: 3.412833038396457e-08\n",
      "Epoch 1693, Loss: 0.00019013730856354272, Final Batch Loss: 1.1440180003319256e-07\n",
      "Epoch 1694, Loss: 0.012166068375833783, Final Batch Loss: 2.2592038462221353e-08\n",
      "Epoch 1695, Loss: 0.005096010474071377, Final Batch Loss: 3.701243400655585e-08\n",
      "Epoch 1696, Loss: 1.436761084105953e-05, Final Batch Loss: 0.0\n",
      "Epoch 1697, Loss: 0.0005669275803946716, Final Batch Loss: 1.95638790501107e-06\n",
      "Epoch 1698, Loss: 0.0001783480540881177, Final Batch Loss: 9.517440702211388e-08\n",
      "Epoch 1699, Loss: 1.3169939980794965e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1700, Loss: 7.343170068785376e-05, Final Batch Loss: 2.211137406504804e-08\n",
      "Epoch 1701, Loss: 0.0029534943304834194, Final Batch Loss: 3.028294415230448e-08\n",
      "Epoch 1702, Loss: 0.028210996084503615, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 1703, Loss: 0.014418860830773816, Final Batch Loss: 5.467204118758673e-06\n",
      "Epoch 1704, Loss: 0.008675134504114723, Final Batch Loss: 8.363805648059497e-08\n",
      "Epoch 1705, Loss: 0.030175594313667897, Final Batch Loss: 2.326440409206043e-07\n",
      "Epoch 1706, Loss: 0.02850828526841287, Final Batch Loss: 5.622093522106297e-05\n",
      "Epoch 1707, Loss: 0.12057245941878136, Final Batch Loss: 0.00211436883546412\n",
      "Epoch 1708, Loss: 0.03097606391506247, Final Batch Loss: 4.04969287046697e-05\n",
      "Epoch 1709, Loss: 0.0258785435655966, Final Batch Loss: 2.4514545771125995e-07\n",
      "Epoch 1710, Loss: 0.0004033892003008077, Final Batch Loss: 1.5380874174297787e-06\n",
      "Epoch 1711, Loss: 0.0005659704565914581, Final Batch Loss: 7.0395490183727816e-06\n",
      "Epoch 1712, Loss: 0.00022831427153846562, Final Batch Loss: 3.946383912989404e-06\n",
      "Epoch 1713, Loss: 0.0005765117545166731, Final Batch Loss: 0.0003141488414257765\n",
      "Epoch 1714, Loss: 0.003158451245269589, Final Batch Loss: 3.629065759014338e-07\n",
      "Epoch 1715, Loss: 0.0006990560316353367, Final Batch Loss: 5.558166776609141e-06\n",
      "Epoch 1716, Loss: 0.00014243388573453863, Final Batch Loss: 8.697826160641853e-06\n",
      "Epoch 1717, Loss: 0.00018596617694299766, Final Batch Loss: 1.7707309325487586e-06\n",
      "Epoch 1718, Loss: 0.0006000615233858753, Final Batch Loss: 7.133855888241669e-06\n",
      "Epoch 1719, Loss: 0.00011873092004677233, Final Batch Loss: 3.859082789858803e-05\n",
      "Epoch 1720, Loss: 0.00041447360087332186, Final Batch Loss: 6.907080205564853e-06\n",
      "Epoch 1721, Loss: 0.0035176504565482825, Final Batch Loss: 0.0033391350880265236\n",
      "Epoch 1722, Loss: 0.00011251619282859338, Final Batch Loss: 2.8888445058328216e-07\n",
      "Epoch 1723, Loss: 0.00025324609703858414, Final Batch Loss: 5.220109073889034e-07\n",
      "Epoch 1724, Loss: 0.00015246708444749402, Final Batch Loss: 4.428744887263747e-06\n",
      "Epoch 1725, Loss: 8.816509129694339e-05, Final Batch Loss: 3.181527426932007e-05\n",
      "Epoch 1726, Loss: 0.0003121191549766422, Final Batch Loss: 9.363898243464064e-06\n",
      "Epoch 1727, Loss: 0.0020670895084067276, Final Batch Loss: 1.6822311863506911e-06\n",
      "Epoch 1728, Loss: 0.00031974486722674555, Final Batch Loss: 4.9308896450384054e-06\n",
      "Epoch 1729, Loss: 0.000763802820749504, Final Batch Loss: 2.1961612219456583e-05\n",
      "Epoch 1730, Loss: 8.381112290223314e-05, Final Batch Loss: 2.434914449622738e-06\n",
      "Epoch 1731, Loss: 0.0001623481186321385, Final Batch Loss: 6.0226454934309e-07\n",
      "Epoch 1732, Loss: 0.02187846835344409, Final Batch Loss: 1.8385189832770266e-05\n",
      "Epoch 1733, Loss: 0.006601797336095672, Final Batch Loss: 0.0006372982170432806\n",
      "Epoch 1734, Loss: 0.004945587693811149, Final Batch Loss: 2.4850885438354453e-07\n",
      "Epoch 1735, Loss: 0.02470584418404087, Final Batch Loss: 2.9079162686684867e-06\n",
      "Epoch 1736, Loss: 0.000368725862788466, Final Batch Loss: 1.8754335542325862e-06\n",
      "Epoch 1737, Loss: 0.0008409621491125563, Final Batch Loss: 2.735039004164719e-07\n",
      "Epoch 1738, Loss: 0.0001743703851566636, Final Batch Loss: 8.815445085019746e-07\n",
      "Epoch 1739, Loss: 0.0010598601566016441, Final Batch Loss: 7.128169841053023e-07\n",
      "Epoch 1740, Loss: 0.00023282531003587792, Final Batch Loss: 1.2549832035801955e-06\n",
      "Epoch 1741, Loss: 0.0035498191517717714, Final Batch Loss: 7.065753834467614e-06\n",
      "Epoch 1742, Loss: 0.0006526211944191118, Final Batch Loss: 9.252770496459561e-07\n",
      "Epoch 1743, Loss: 0.003358813506935121, Final Batch Loss: 2.468854745529825e-06\n",
      "Epoch 1744, Loss: 0.0004212231704627811, Final Batch Loss: 1.0238136383122765e-05\n",
      "Epoch 1745, Loss: 0.00031972471207097897, Final Batch Loss: 2.78354082183796e-06\n",
      "Epoch 1746, Loss: 0.00014403255215000854, Final Batch Loss: 8.756226634432096e-06\n",
      "Epoch 1747, Loss: 0.00016501533723101147, Final Batch Loss: 2.0771180061274208e-05\n",
      "Epoch 1748, Loss: 0.0002805543488193507, Final Batch Loss: 3.334190751047572e-06\n",
      "Epoch 1749, Loss: 0.00018912775655621772, Final Batch Loss: 4.331200671003899e-06\n",
      "Epoch 1750, Loss: 0.0006691784210204332, Final Batch Loss: 1.6451765532110585e-06\n",
      "Epoch 1751, Loss: 0.0001079834891157816, Final Batch Loss: 7.791657594680146e-07\n",
      "Epoch 1752, Loss: 0.0004621206271151479, Final Batch Loss: 4.054247256135568e-06\n",
      "Epoch 1753, Loss: 0.0008134699996134032, Final Batch Loss: 1.538868104944413e-06\n",
      "Epoch 1754, Loss: 0.00013064000625107042, Final Batch Loss: 4.0857634076019167e-07\n",
      "Epoch 1755, Loss: 0.00019445108377169618, Final Batch Loss: 1.3332430171431042e-05\n",
      "Epoch 1756, Loss: 0.00032935117604893094, Final Batch Loss: 9.73812461779744e-07\n",
      "Epoch 1757, Loss: 0.00032692650936283485, Final Batch Loss: 2.2907519451109692e-05\n",
      "Epoch 1758, Loss: 9.499513510835556e-05, Final Batch Loss: 4.7499211177637335e-06\n",
      "Epoch 1759, Loss: 0.00015555606744754868, Final Batch Loss: 8.175877042049251e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1760, Loss: 5.7231984326833185e-05, Final Batch Loss: 1.288596081394644e-06\n",
      "Epoch 1761, Loss: 1.8370630286312917e-05, Final Batch Loss: 4.715413126632484e-07\n",
      "Epoch 1762, Loss: 0.00023712020251309696, Final Batch Loss: 1.8602298723635613e-07\n",
      "Epoch 1763, Loss: 4.52365832659396e-05, Final Batch Loss: 2.9501870812964626e-05\n",
      "Epoch 1764, Loss: 0.00022550260797382649, Final Batch Loss: 1.2352530802672845e-06\n",
      "Epoch 1765, Loss: 0.0001381692859325767, Final Batch Loss: 8.652240524043009e-08\n",
      "Epoch 1766, Loss: 0.00013379409544889143, Final Batch Loss: 1.8746591834428727e-08\n",
      "Epoch 1767, Loss: 0.00013014917980669338, Final Batch Loss: 1.4270405017668963e-06\n",
      "Epoch 1768, Loss: 0.00013472832007899171, Final Batch Loss: 1.3843602175711567e-07\n",
      "Epoch 1769, Loss: 8.425916054255467e-05, Final Batch Loss: 8.89257023573009e-08\n",
      "Epoch 1770, Loss: 4.632786113933918e-05, Final Batch Loss: 1.7929269802152703e-07\n",
      "Epoch 1771, Loss: 8.480464705939994e-05, Final Batch Loss: 5.921833690081257e-07\n",
      "Epoch 1772, Loss: 0.00014576028647184103, Final Batch Loss: 7.979321026141406e-08\n",
      "Epoch 1773, Loss: 3.988578490066175e-05, Final Batch Loss: 1.3866571180187748e-06\n",
      "Epoch 1774, Loss: 3.3864796137095254e-05, Final Batch Loss: 8.546755452698562e-06\n",
      "Epoch 1775, Loss: 3.438384125331595e-05, Final Batch Loss: 1.7038399846569519e-06\n",
      "Epoch 1776, Loss: 0.0007349223243551251, Final Batch Loss: 1.1919424878215068e-06\n",
      "Epoch 1777, Loss: 0.00032959846215785404, Final Batch Loss: 1.8938744972274435e-07\n",
      "Epoch 1778, Loss: 2.734664942849463e-05, Final Batch Loss: 3.701251927168414e-08\n",
      "Epoch 1779, Loss: 0.0002128496809383762, Final Batch Loss: 0.00011801008804468438\n",
      "Epoch 1780, Loss: 4.2137331448088844e-05, Final Batch Loss: 1.3170546253604698e-07\n",
      "Epoch 1781, Loss: 0.0001408681191890082, Final Batch Loss: 6.969870725015426e-08\n",
      "Epoch 1782, Loss: 2.7735989466037836e-05, Final Batch Loss: 1.4129777810012456e-06\n",
      "Epoch 1783, Loss: 1.5033007798592735e-05, Final Batch Loss: 1.361612248729216e-06\n",
      "Epoch 1784, Loss: 7.527991265732226e-05, Final Batch Loss: 9.146361890088883e-07\n",
      "Epoch 1785, Loss: 3.7201772464356964e-05, Final Batch Loss: 1.4490681223833235e-06\n",
      "Epoch 1786, Loss: 5.2983912487647444e-05, Final Batch Loss: 1.0190365884454877e-07\n",
      "Epoch 1787, Loss: 0.010490179913887232, Final Batch Loss: 2.0506824967014836e-06\n",
      "Epoch 1788, Loss: 2.795398675559113e-05, Final Batch Loss: 3.2686365614154056e-08\n",
      "Epoch 1789, Loss: 0.00013380669106410892, Final Batch Loss: 9.066157872439362e-06\n",
      "Epoch 1790, Loss: 7.934476582960315e-05, Final Batch Loss: 9.517448518181482e-08\n",
      "Epoch 1791, Loss: 0.00015040851327441374, Final Batch Loss: 2.4909104467951693e-06\n",
      "Epoch 1792, Loss: 0.0001499028924900614, Final Batch Loss: 8.041258183766331e-07\n",
      "Epoch 1793, Loss: 0.000303323476233075, Final Batch Loss: 1.1362635632394813e-06\n",
      "Epoch 1794, Loss: 0.0003841664836343739, Final Batch Loss: 3.8770463106629904e-06\n",
      "Epoch 1795, Loss: 3.97152087181496e-05, Final Batch Loss: 3.2467557957716053e-06\n",
      "Epoch 1796, Loss: 0.00011948301900677194, Final Batch Loss: 1.009433336918164e-08\n",
      "Epoch 1797, Loss: 4.223831259153599e-05, Final Batch Loss: 5.955413371339091e-07\n",
      "Epoch 1798, Loss: 2.461158290190113e-05, Final Batch Loss: 1.5739994978503091e-06\n",
      "Epoch 1799, Loss: 7.31768657686871e-05, Final Batch Loss: 8.257340482487052e-07\n",
      "Epoch 1800, Loss: 0.0002280586927660977, Final Batch Loss: 4.3261348281475875e-08\n",
      "Epoch 1801, Loss: 3.963095481651635e-05, Final Batch Loss: 2.364932640830375e-07\n",
      "Epoch 1802, Loss: 3.0039903501144494e-05, Final Batch Loss: 1.1549592500159633e-06\n",
      "Epoch 1803, Loss: 6.200902545749898e-05, Final Batch Loss: 4.7106844647260004e-08\n",
      "Epoch 1804, Loss: 0.0021261370400047497, Final Batch Loss: 3.130308414256433e-06\n",
      "Epoch 1805, Loss: 3.468704488795993e-05, Final Batch Loss: 1.4137113794276956e-05\n",
      "Epoch 1806, Loss: 1.6536238799602643e-05, Final Batch Loss: 6.393066342980092e-08\n",
      "Epoch 1807, Loss: 3.553165697312011e-05, Final Batch Loss: 5.18631486556842e-06\n",
      "Epoch 1808, Loss: 4.745122639082666e-05, Final Batch Loss: 1.139208407607839e-07\n",
      "Epoch 1809, Loss: 7.89947330197549e-05, Final Batch Loss: 1.5189347379873652e-07\n",
      "Epoch 1810, Loss: 0.00023450074790787312, Final Batch Loss: 1.23566496768035e-06\n",
      "Epoch 1811, Loss: 0.0001792673775193876, Final Batch Loss: 1.4420462157715974e-08\n",
      "Epoch 1812, Loss: 4.535602536748229e-05, Final Batch Loss: 4.647916739486391e-06\n",
      "Epoch 1813, Loss: 6.295442220238812e-05, Final Batch Loss: 2.2706019535689848e-06\n",
      "Epoch 1814, Loss: 2.6257768029225304e-05, Final Batch Loss: 9.53098890477122e-07\n",
      "Epoch 1815, Loss: 6.199454454303144e-05, Final Batch Loss: 3.951073779262515e-07\n",
      "Epoch 1816, Loss: 7.594123101029027e-05, Final Batch Loss: 1.4192108892530086e-06\n",
      "Epoch 1817, Loss: 0.0009490933721760797, Final Batch Loss: 1.1057768460887019e-05\n",
      "Epoch 1818, Loss: 0.0002775287991232389, Final Batch Loss: 3.3069724736378703e-07\n",
      "Epoch 1819, Loss: 0.0007864688331018499, Final Batch Loss: 2.3456867381810298e-07\n",
      "Epoch 1820, Loss: 0.00020827582483917695, Final Batch Loss: 3.3936998079298064e-05\n",
      "Epoch 1821, Loss: 6.2155653930418e-06, Final Batch Loss: 3.081081274558528e-07\n",
      "Epoch 1822, Loss: 0.000110334295658987, Final Batch Loss: 1.6343191688861225e-08\n",
      "Epoch 1823, Loss: 0.00012285238187459413, Final Batch Loss: 5.12375072503346e-06\n",
      "Epoch 1824, Loss: 9.465917234940946e-06, Final Batch Loss: 2.9993382213433506e-06\n",
      "Epoch 1825, Loss: 4.899885955556016e-05, Final Batch Loss: 6.441115374400397e-08\n",
      "Epoch 1826, Loss: 0.0001254547766436076, Final Batch Loss: 4.255682142684236e-06\n",
      "Epoch 1827, Loss: 1.2043216500057241e-05, Final Batch Loss: 1.3699306578018877e-07\n",
      "Epoch 1828, Loss: 1.5203088388204833e-05, Final Batch Loss: 3.3167047774895764e-08\n",
      "Epoch 1829, Loss: 0.00015414533783397744, Final Batch Loss: 3.845460394558131e-09\n",
      "Epoch 1830, Loss: 6.320283927152559e-05, Final Batch Loss: 2.1678341965980508e-07\n",
      "Epoch 1831, Loss: 3.4921620359895655e-05, Final Batch Loss: 1.8417734963804833e-06\n",
      "Epoch 1832, Loss: 1.745536804387271e-05, Final Batch Loss: 4.806825604219966e-09\n",
      "Epoch 1833, Loss: 0.0004385244769977703, Final Batch Loss: 2.1735482732765377e-05\n",
      "Epoch 1834, Loss: 0.00010122177764770868, Final Batch Loss: 2.3571287783852313e-06\n",
      "Epoch 1835, Loss: 9.166960131423707e-06, Final Batch Loss: 1.5381832696448328e-08\n",
      "Epoch 1836, Loss: 0.0002431371671329785, Final Batch Loss: 3.5599923648987897e-06\n",
      "Epoch 1837, Loss: 0.00290602981533139, Final Batch Loss: 1.6102792699257407e-07\n",
      "Epoch 1838, Loss: 1.980223472308751e-05, Final Batch Loss: 1.544623046356719e-06\n",
      "Epoch 1839, Loss: 2.8887571289715197e-05, Final Batch Loss: 3.9366315718325495e-07\n",
      "Epoch 1840, Loss: 6.165314031747471e-05, Final Batch Loss: 1.4249128980736714e-05\n",
      "Epoch 1841, Loss: 0.0002891964265092639, Final Batch Loss: 3.819692210527137e-06\n",
      "Epoch 1842, Loss: 0.0001357551763986331, Final Batch Loss: 6.921791140257483e-08\n",
      "Epoch 1843, Loss: 0.0002394973546868684, Final Batch Loss: 4.951022702925911e-08\n",
      "Epoch 1844, Loss: 0.00014606560405461266, Final Batch Loss: 7.353527053055586e-06\n",
      "Epoch 1845, Loss: 0.00011708787036557311, Final Batch Loss: 1.4092586297920207e-06\n",
      "Epoch 1846, Loss: 2.690743339073265e-05, Final Batch Loss: 4.724781774712028e-06\n",
      "Epoch 1847, Loss: 0.0007611336271931002, Final Batch Loss: 9.595539449946955e-05\n",
      "Epoch 1848, Loss: 7.102397909486413e-05, Final Batch Loss: 1.3410861754437065e-07\n",
      "Epoch 1849, Loss: 0.0002320780797767652, Final Batch Loss: 1.961150815077417e-07\n",
      "Epoch 1850, Loss: 2.5120763393005063e-05, Final Batch Loss: 2.4938244678196497e-06\n",
      "Epoch 1851, Loss: 6.051592186828714e-05, Final Batch Loss: 3.035396957784542e-06\n",
      "Epoch 1852, Loss: 5.9942630115106255e-05, Final Batch Loss: 1.1440196345802178e-07\n",
      "Epoch 1853, Loss: 5.29628367118562e-05, Final Batch Loss: 4.892845481663244e-06\n",
      "Epoch 1854, Loss: 0.00011753845698336818, Final Batch Loss: 3.100324192928383e-07\n",
      "Epoch 1855, Loss: 4.026728894812592e-05, Final Batch Loss: 1.2497734402927563e-08\n",
      "Epoch 1856, Loss: 0.0026352594345964153, Final Batch Loss: 1.5452594652742846e-06\n",
      "Epoch 1857, Loss: 0.0003083213183305844, Final Batch Loss: 0.0002752943546511233\n",
      "Epoch 1858, Loss: 0.00015467687553694098, Final Batch Loss: 1.089577949642262e-06\n",
      "Epoch 1859, Loss: 0.00015334047644799398, Final Batch Loss: 9.132936185096696e-08\n",
      "Epoch 1860, Loss: 2.4471527003022686e-05, Final Batch Loss: 1.2260996982149663e-06\n",
      "Epoch 1861, Loss: 0.0002597943640592071, Final Batch Loss: 0.00016251688066404313\n",
      "Epoch 1862, Loss: 0.00013004558951301703, Final Batch Loss: 1.1536377186871505e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1863, Loss: 3.845913183475602e-06, Final Batch Loss: 1.0094324487397444e-08\n",
      "Epoch 1864, Loss: 0.00047086001333962457, Final Batch Loss: 3.6288038245402277e-06\n",
      "Epoch 1865, Loss: 3.6835453112615824e-05, Final Batch Loss: 1.2146241488153464e-06\n",
      "Epoch 1866, Loss: 1.0347505187024986e-05, Final Batch Loss: 6.825666076792913e-08\n",
      "Epoch 1867, Loss: 6.915221022074647e-05, Final Batch Loss: 4.455690998383943e-07\n",
      "Epoch 1868, Loss: 4.505840305790709e-05, Final Batch Loss: 1.5718035228928784e-07\n",
      "Epoch 1869, Loss: 0.00014848195699179723, Final Batch Loss: 4.5566929429696756e-07\n",
      "Epoch 1870, Loss: 2.791763198572994e-05, Final Batch Loss: 3.268635140329934e-08\n",
      "Epoch 1871, Loss: 1.415463034626363e-05, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 1872, Loss: 9.155444175590333e-05, Final Batch Loss: 2.321533884241944e-06\n",
      "Epoch 1873, Loss: 1.952104998004245e-05, Final Batch Loss: 2.991716883116169e-06\n",
      "Epoch 1874, Loss: 0.00033222981145175634, Final Batch Loss: 1.297842011638295e-08\n",
      "Epoch 1875, Loss: 0.00011222414773115474, Final Batch Loss: 2.939461774076335e-05\n",
      "Epoch 1876, Loss: 1.2761804390137854e-05, Final Batch Loss: 5.912357536885793e-08\n",
      "Epoch 1877, Loss: 5.9043331375185915e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 1878, Loss: 7.175704029549479e-05, Final Batch Loss: 1.8197777535533533e-05\n",
      "Epoch 1879, Loss: 7.1156570253805285e-06, Final Batch Loss: 1.2251804264451494e-06\n",
      "Epoch 1880, Loss: 1.193759104722858e-05, Final Batch Loss: 1.5862509528119517e-08\n",
      "Epoch 1881, Loss: 5.9370175722550655e-05, Final Batch Loss: 5.018187039240729e-07\n",
      "Epoch 1882, Loss: 1.9654948199665512e-05, Final Batch Loss: 1.0142296957837971e-07\n",
      "Epoch 1883, Loss: 3.1794106358784546e-05, Final Batch Loss: 2.259145759353487e-07\n",
      "Epoch 1884, Loss: 2.844627465936611e-05, Final Batch Loss: 1.1536374522336246e-08\n",
      "Epoch 1885, Loss: 7.592056541394498e-05, Final Batch Loss: 6.24887208644509e-09\n",
      "Epoch 1886, Loss: 3.8828624904230225e-05, Final Batch Loss: 6.729554691276007e-09\n",
      "Epoch 1887, Loss: 1.0458878294095086e-05, Final Batch Loss: 5.720104212514343e-08\n",
      "Epoch 1888, Loss: 2.5694542904908246e-05, Final Batch Loss: 2.783084198654251e-07\n",
      "Epoch 1889, Loss: 4.140395738261304e-06, Final Batch Loss: 1.1055696802486636e-08\n",
      "Epoch 1890, Loss: 0.0007452951613267089, Final Batch Loss: 3.028296902130023e-08\n",
      "Epoch 1891, Loss: 1.3455751995739007e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 1892, Loss: 6.360927659643245e-05, Final Batch Loss: 1.2593835663210484e-07\n",
      "Epoch 1893, Loss: 7.33901128304737e-05, Final Batch Loss: 3.9415830599409674e-08\n",
      "Epoch 1894, Loss: 6.136512377707959e-05, Final Batch Loss: 1.8313792793378525e-07\n",
      "Epoch 1895, Loss: 1.2811036619098104e-05, Final Batch Loss: 1.9995910349734913e-07\n",
      "Epoch 1896, Loss: 8.269180546771615e-05, Final Batch Loss: 2.4750108423177153e-05\n",
      "Epoch 1897, Loss: 2.1360778578838335e-05, Final Batch Loss: 1.8698175097142666e-07\n",
      "Epoch 1898, Loss: 2.7272763969410363e-05, Final Batch Loss: 8.652283334242838e-09\n",
      "Epoch 1899, Loss: 1.2957144356895434e-05, Final Batch Loss: 0.0\n",
      "Epoch 1900, Loss: 4.0151482923578286e-05, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 1901, Loss: 8.705100973838142e-06, Final Batch Loss: 8.459979738972834e-08\n",
      "Epoch 1902, Loss: 1.2374948603177671e-05, Final Batch Loss: 1.9227266889743078e-08\n",
      "Epoch 1903, Loss: 0.004657749303567549, Final Batch Loss: 4.782555720339587e-07\n",
      "Epoch 1904, Loss: 0.00020558025768657728, Final Batch Loss: 2.5958575861295685e-05\n",
      "Epoch 1905, Loss: 0.005328674396357869, Final Batch Loss: 5.724547236241051e-07\n",
      "Epoch 1906, Loss: 0.0016205877631056964, Final Batch Loss: 0.0007643249700777233\n",
      "Epoch 1907, Loss: 0.007042418017161989, Final Batch Loss: 3.076361210219147e-08\n",
      "Epoch 1908, Loss: 0.00254229208360357, Final Batch Loss: 1.7935154801307363e-06\n",
      "Epoch 1909, Loss: 0.0006050387442312344, Final Batch Loss: 9.132966383162966e-09\n",
      "Epoch 1910, Loss: 4.607245116083902e-05, Final Batch Loss: 4.99908452411546e-08\n",
      "Epoch 1911, Loss: 2.583061739047654e-05, Final Batch Loss: 1.309278104599798e-06\n",
      "Epoch 1912, Loss: 0.0004306482294644809, Final Batch Loss: 0.00012170954869361594\n",
      "Epoch 1913, Loss: 3.215161310343717e-05, Final Batch Loss: 2.36009029208617e-07\n",
      "Epoch 1914, Loss: 0.0003740016804130164, Final Batch Loss: 0.0003140612388961017\n",
      "Epoch 1915, Loss: 0.002434293477242222, Final Batch Loss: 1.0588083796392311e-06\n",
      "Epoch 1916, Loss: 0.00036067056590116664, Final Batch Loss: 0.0003553472924977541\n",
      "Epoch 1917, Loss: 8.721217867524445e-05, Final Batch Loss: 3.8741234220651677e-07\n",
      "Epoch 1918, Loss: 3.2355640777748107e-06, Final Batch Loss: 2.869580271180894e-07\n",
      "Epoch 1919, Loss: 1.1349629015722229e-05, Final Batch Loss: 3.7012419795701135e-08\n",
      "Epoch 1920, Loss: 1.3102321314018006e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 1921, Loss: 5.334587812377833e-06, Final Batch Loss: 9.036737225187608e-08\n",
      "Epoch 1922, Loss: 4.7892545582683965e-06, Final Batch Loss: 1.922728998238199e-08\n",
      "Epoch 1923, Loss: 1.4681406490968385e-05, Final Batch Loss: 9.132962830449287e-09\n",
      "Epoch 1924, Loss: 0.00039662911243298904, Final Batch Loss: 6.152692577643393e-08\n",
      "Epoch 1925, Loss: 1.630370566185757e-05, Final Batch Loss: 9.781250582818757e-07\n",
      "Epoch 1926, Loss: 3.7888874722558086e-05, Final Batch Loss: 4.72002938067817e-07\n",
      "Epoch 1927, Loss: 9.191564468846725e-05, Final Batch Loss: 1.922315732372226e-06\n",
      "Epoch 1928, Loss: 9.743986417765083e-05, Final Batch Loss: 1.6631335597594443e-07\n",
      "Epoch 1929, Loss: 7.400299092763518e-05, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 1930, Loss: 1.7793045149594455e-05, Final Batch Loss: 3.297352009212773e-07\n",
      "Epoch 1931, Loss: 3.843171648687527e-05, Final Batch Loss: 6.24887119826667e-09\n",
      "Epoch 1932, Loss: 3.327452830903521e-05, Final Batch Loss: 3.7299918176358915e-07\n",
      "Epoch 1933, Loss: 3.289940924033896e-05, Final Batch Loss: 1.4420221816635603e-07\n",
      "Epoch 1934, Loss: 0.00015649414772667125, Final Batch Loss: 7.354383058100211e-08\n",
      "Epoch 1935, Loss: 1.8072298491045302e-06, Final Batch Loss: 1.3074470928131632e-07\n",
      "Epoch 1936, Loss: 7.80150330315088e-06, Final Batch Loss: 2.6918140605403096e-08\n",
      "Epoch 1937, Loss: 3.988940218579984e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 1938, Loss: 1.827507190155231e-05, Final Batch Loss: 1.4420462157715974e-08\n",
      "Epoch 1939, Loss: 5.3258941443701246e-05, Final Batch Loss: 8.98867682508353e-08\n",
      "Epoch 1940, Loss: 0.0029951590351062762, Final Batch Loss: 1.586250597540584e-08\n",
      "Epoch 1941, Loss: 0.0004071242780296913, Final Batch Loss: 0.00031341734575107694\n",
      "Epoch 1942, Loss: 0.00019085516932415558, Final Batch Loss: 6.729552470829958e-09\n",
      "Epoch 1943, Loss: 0.00040264878187024067, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 1944, Loss: 3.982628443210956e-05, Final Batch Loss: 5.450729645417596e-07\n",
      "Epoch 1945, Loss: 1.17567976912758e-05, Final Batch Loss: 4.8068137914469844e-08\n",
      "Epoch 1946, Loss: 3.725573418345007e-05, Final Batch Loss: 1.0478762391130658e-07\n",
      "Epoch 1947, Loss: 6.290793789776039e-05, Final Batch Loss: 1.5335765510826604e-06\n",
      "Epoch 1948, Loss: 0.00021734572524312323, Final Batch Loss: 0.0002038699749391526\n",
      "Epoch 1949, Loss: 3.617196836347425e-05, Final Batch Loss: 1.2497737955641242e-08\n",
      "Epoch 1950, Loss: 0.00010211451494868129, Final Batch Loss: 1.538182736737781e-08\n",
      "Epoch 1951, Loss: 1.562291712375874e-05, Final Batch Loss: 8.652281557885999e-09\n",
      "Epoch 1952, Loss: 5.031794705834258e-05, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 1953, Loss: 0.00012898178313447417, Final Batch Loss: 8.988697430822867e-08\n",
      "Epoch 1954, Loss: 9.923677547318821e-05, Final Batch Loss: 3.3647777897272135e-09\n",
      "Epoch 1955, Loss: 0.0004440705288720759, Final Batch Loss: 3.3268752304138616e-06\n",
      "Epoch 1956, Loss: 4.2351952883601385e-06, Final Batch Loss: 4.0712066606829467e-07\n",
      "Epoch 1957, Loss: 5.36269096929054e-06, Final Batch Loss: 1.778508362804132e-07\n",
      "Epoch 1958, Loss: 9.1275063772156e-05, Final Batch Loss: 1.6967742055840063e-07\n",
      "Epoch 1959, Loss: 3.7580875666964886e-05, Final Batch Loss: 1.9269155018264428e-05\n",
      "Epoch 1960, Loss: 1.071847527267522e-05, Final Batch Loss: 4.5902586975898885e-07\n",
      "Epoch 1961, Loss: 2.7061296686281544e-05, Final Batch Loss: 9.613642326655736e-09\n",
      "Epoch 1962, Loss: 0.00010915938943223402, Final Batch Loss: 4.03753631417203e-07\n",
      "Epoch 1963, Loss: 4.356823488871342e-06, Final Batch Loss: 7.210233743393246e-09\n",
      "Epoch 1964, Loss: 9.212477528386387e-06, Final Batch Loss: 2.3518475700257113e-06\n",
      "Epoch 1965, Loss: 5.468968153676812e-06, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1966, Loss: 9.813076401687937e-06, Final Batch Loss: 5.912365352855886e-08\n",
      "Epoch 1967, Loss: 2.24593185809141e-05, Final Batch Loss: 1.1632371155201326e-07\n",
      "Epoch 1968, Loss: 5.871162184734047e-05, Final Batch Loss: 1.3939772003368489e-08\n",
      "Epoch 1969, Loss: 2.283557596760577e-05, Final Batch Loss: 1.874658828171505e-08\n",
      "Epoch 1970, Loss: 7.3809699993043765e-06, Final Batch Loss: 1.4420471039500171e-08\n",
      "Epoch 1971, Loss: 0.0011656983024816991, Final Batch Loss: 5.04713781879218e-08\n",
      "Epoch 1972, Loss: 3.298227012682453e-05, Final Batch Loss: 1.682385608603454e-08\n",
      "Epoch 1973, Loss: 6.225931126535578e-06, Final Batch Loss: 5.768187261168123e-09\n",
      "Epoch 1974, Loss: 5.13942215486507e-05, Final Batch Loss: 2.3583004804095253e-05\n",
      "Epoch 1975, Loss: 3.146610111448567e-05, Final Batch Loss: 6.152691156557921e-08\n",
      "Epoch 1976, Loss: 7.182148254791798e-06, Final Batch Loss: 1.2978409458241913e-08\n",
      "Epoch 1977, Loss: 4.7805300508629855e-05, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 1978, Loss: 1.970317036659175e-05, Final Batch Loss: 3.7588517898257123e-07\n",
      "Epoch 1979, Loss: 2.4426500460195122e-05, Final Batch Loss: 1.1247839637462675e-07\n",
      "Epoch 1980, Loss: 2.8716264405370673e-05, Final Batch Loss: 2.1293688234891306e-07\n",
      "Epoch 1981, Loss: 4.000819280425283e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 1982, Loss: 1.2906963575032293e-05, Final Batch Loss: 0.0\n",
      "Epoch 1983, Loss: 3.97120149532304e-05, Final Batch Loss: 7.4398690230736975e-06\n",
      "Epoch 1984, Loss: 4.0786827996353026e-05, Final Batch Loss: 0.0\n",
      "Epoch 1985, Loss: 0.00042726183031360776, Final Batch Loss: 1.4901133660316646e-08\n",
      "Epoch 1986, Loss: 2.19291061593907e-05, Final Batch Loss: 0.0\n",
      "Epoch 1987, Loss: 8.618964939133278e-05, Final Batch Loss: 1.2978412122777172e-08\n",
      "Epoch 1988, Loss: 3.594429024866841e-06, Final Batch Loss: 0.0\n",
      "Epoch 1989, Loss: 5.3802429524907325e-06, Final Batch Loss: 1.0478746048647736e-07\n",
      "Epoch 1990, Loss: 0.00011653389787458224, Final Batch Loss: 2.5043158302651136e-07\n",
      "Epoch 1991, Loss: 6.833365597636032e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 1992, Loss: 2.5662294668160612e-06, Final Batch Loss: 8.171600285322711e-09\n",
      "Epoch 1993, Loss: 6.196019966209221e-06, Final Batch Loss: 1.1536375410514665e-08\n",
      "Epoch 1994, Loss: 5.1032428778685635e-05, Final Batch Loss: 9.613645879369415e-09\n",
      "Epoch 1995, Loss: 3.72352208755089e-06, Final Batch Loss: 1.730455601034464e-08\n",
      "Epoch 1996, Loss: 1.1747572013165453e-05, Final Batch Loss: 3.704844630192383e-06\n",
      "Epoch 1997, Loss: 9.349064065689028e-06, Final Batch Loss: 1.4420453275931777e-08\n",
      "Epoch 1998, Loss: 1.3555463287406866e-06, Final Batch Loss: 5.287497018002796e-08\n",
      "Epoch 1999, Loss: 6.891494205218951e-05, Final Batch Loss: 8.002617164493131e-07\n",
      "Epoch 2000, Loss: 1.7880349456600442e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 2001, Loss: 0.000989755065391007, Final Batch Loss: 9.763823982211761e-06\n",
      "Epoch 2002, Loss: 4.520896315085565e-07, Final Batch Loss: 7.210235075660876e-09\n",
      "Epoch 2003, Loss: 3.46999225009359e-06, Final Batch Loss: 0.0\n",
      "Epoch 2004, Loss: 1.642694725145777e-05, Final Batch Loss: 4.965146445101709e-07\n",
      "Epoch 2005, Loss: 0.00015205779354865445, Final Batch Loss: 2.3504695434439782e-07\n",
      "Epoch 2006, Loss: 0.0002592073782872184, Final Batch Loss: 1.244948890644082e-07\n",
      "Epoch 2007, Loss: 1.9311707951663593e-06, Final Batch Loss: 9.613645879369415e-09\n",
      "Epoch 2008, Loss: 4.655798081176776e-05, Final Batch Loss: 1.4804763281972555e-07\n",
      "Epoch 2009, Loss: 6.678177703944854e-06, Final Batch Loss: 6.440782271965872e-07\n",
      "Epoch 2010, Loss: 0.00038689020503179794, Final Batch Loss: 0.0001663217699388042\n",
      "Epoch 2011, Loss: 0.00019716332163211003, Final Batch Loss: 2.403410093165803e-08\n",
      "Epoch 2012, Loss: 3.735947856065014e-05, Final Batch Loss: 2.7398815660717446e-08\n",
      "Epoch 2013, Loss: 8.633913171851582e-06, Final Batch Loss: 0.0\n",
      "Epoch 2014, Loss: 1.9828261306198414e-06, Final Batch Loss: 0.0\n",
      "Epoch 2015, Loss: 2.1923779933707976e-06, Final Batch Loss: 3.033055975265597e-07\n",
      "Epoch 2016, Loss: 5.6795789141528275e-05, Final Batch Loss: 3.797215697431966e-07\n",
      "Epoch 2017, Loss: 2.4435106263931416e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 2018, Loss: 5.2171237734377485e-06, Final Batch Loss: 1.0575003983603892e-08\n",
      "Epoch 2019, Loss: 7.953852769315706e-05, Final Batch Loss: 1.7785218631161115e-08\n",
      "Epoch 2020, Loss: 3.275810042147054e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2021, Loss: 9.164289657137559e-06, Final Batch Loss: 4.1338591216799614e-08\n",
      "Epoch 2022, Loss: 3.0369316713629857e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2023, Loss: 1.3903985486396486e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2024, Loss: 1.868840814467365e-05, Final Batch Loss: 2.307272417567674e-08\n",
      "Epoch 2025, Loss: 3.060063637394528e-05, Final Batch Loss: 9.132959277735608e-09\n",
      "Epoch 2026, Loss: 2.0000614045168064e-05, Final Batch Loss: 0.0\n",
      "Epoch 2027, Loss: 2.5129489089614765e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2028, Loss: 7.312036782614051e-06, Final Batch Loss: 0.0\n",
      "Epoch 2029, Loss: 3.2040681842149255e-06, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 2030, Loss: 0.00024565867060821756, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2031, Loss: 2.387560939298705e-05, Final Batch Loss: 4.2780524012187016e-08\n",
      "Epoch 2032, Loss: 8.945792753056736e-05, Final Batch Loss: 1.10556861443456e-08\n",
      "Epoch 2033, Loss: 0.0003631063671588608, Final Batch Loss: 0.0\n",
      "Epoch 2034, Loss: 2.4076754583379767e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2035, Loss: 9.464786488999621e-07, Final Batch Loss: 6.056555434952315e-08\n",
      "Epoch 2036, Loss: 5.025864876606612e-06, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 2037, Loss: 6.507718270265528e-06, Final Batch Loss: 3.172496576553385e-08\n",
      "Epoch 2038, Loss: 1.9359410663444265e-07, Final Batch Loss: 0.0\n",
      "Epoch 2039, Loss: 2.3349903050084997e-05, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 2040, Loss: 1.1207640063570778e-05, Final Batch Loss: 0.0\n",
      "Epoch 2041, Loss: 2.4409741600228685e-05, Final Batch Loss: 2.6437458444661388e-08\n",
      "Epoch 2042, Loss: 4.03107853763629e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 2043, Loss: 0.0005728460965608306, Final Batch Loss: 8.171598508965872e-09\n",
      "Epoch 2044, Loss: 5.420669072120354e-05, Final Batch Loss: 0.0\n",
      "Epoch 2045, Loss: 5.469128495194653e-05, Final Batch Loss: 4.037713807747423e-08\n",
      "Epoch 2046, Loss: 7.78155067160391e-07, Final Batch Loss: 0.0\n",
      "Epoch 2047, Loss: 0.00010835636952244432, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2048, Loss: 3.492424924700366e-05, Final Batch Loss: 1.6121563021442853e-05\n",
      "Epoch 2049, Loss: 1.9504071828713165e-05, Final Batch Loss: 0.0\n",
      "Epoch 2050, Loss: 5.20373034085253e-06, Final Batch Loss: 0.0\n",
      "Epoch 2051, Loss: 4.205739195795033e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2052, Loss: 4.870368764509081e-06, Final Batch Loss: 1.2978411234598752e-08\n",
      "Epoch 2053, Loss: 8.894288641014825e-05, Final Batch Loss: 2.734253394010011e-05\n",
      "Epoch 2054, Loss: 1.158942025680787e-07, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 2055, Loss: 1.0532467527024636e-06, Final Batch Loss: 0.0\n",
      "Epoch 2056, Loss: 2.6347975201623797e-07, Final Batch Loss: 1.5285419863175775e-07\n",
      "Epoch 2057, Loss: 0.00013105547254643746, Final Batch Loss: 5.768188593435752e-09\n",
      "Epoch 2058, Loss: 1.2635354373902175e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2059, Loss: 3.579176140688922e-06, Final Batch Loss: 2.951283306629193e-07\n",
      "Epoch 2060, Loss: 1.3468014853357246e-06, Final Batch Loss: 3.316696606248115e-08\n",
      "Epoch 2061, Loss: 5.049598511552844e-07, Final Batch Loss: 0.0\n",
      "Epoch 2062, Loss: 1.5029484046191754e-07, Final Batch Loss: 1.1536367416908888e-08\n",
      "Epoch 2063, Loss: 6.1825144913596475e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2064, Loss: 7.924947196258358e-07, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2065, Loss: 3.0099510358594372e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2066, Loss: 7.576638996198426e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2067, Loss: 9.302173942238312e-07, Final Batch Loss: 0.0\n",
      "Epoch 2068, Loss: 3.7975123900912955e-05, Final Batch Loss: 1.129927227339067e-06\n",
      "Epoch 2069, Loss: 2.351082388329928e-06, Final Batch Loss: 0.0\n",
      "Epoch 2070, Loss: 4.0453922753869165e-05, Final Batch Loss: 0.0\n",
      "Epoch 2071, Loss: 3.493065075554913e-05, Final Batch Loss: 9.613641438477316e-09\n",
      "Epoch 2072, Loss: 0.000148296330828801, Final Batch Loss: 4.461963180801831e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2073, Loss: 1.8501550180793913e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2074, Loss: 3.584150783386697e-06, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 2075, Loss: 1.126236437110073e-06, Final Batch Loss: 1.1824619150502258e-07\n",
      "Epoch 2076, Loss: 5.7851731106728366e-06, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 2077, Loss: 3.389700015232755e-06, Final Batch Loss: 2.736483793341904e-06\n",
      "Epoch 2078, Loss: 8.442217766635451e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2079, Loss: 3.5094837624871644e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2080, Loss: 7.487841757747304e-08, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2081, Loss: 7.636848446068711e-06, Final Batch Loss: 2.3553381467422696e-08\n",
      "Epoch 2082, Loss: 2.354914344182557e-05, Final Batch Loss: 2.374502230395592e-07\n",
      "Epoch 2083, Loss: 1.1878943650955875e-07, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 2084, Loss: 1.6372034891021237e-05, Final Batch Loss: 1.6277144823106937e-05\n",
      "Epoch 2085, Loss: 7.292946456405325e-05, Final Batch Loss: 5.287487780947231e-08\n",
      "Epoch 2086, Loss: 4.2332013941992486e-06, Final Batch Loss: 5.287505988604835e-09\n",
      "Epoch 2087, Loss: 8.64559147939481e-07, Final Batch Loss: 7.065974472197922e-08\n",
      "Epoch 2088, Loss: 0.0023646848841809565, Final Batch Loss: 1.0458311408001464e-06\n",
      "Epoch 2089, Loss: 4.670485284796744e-05, Final Batch Loss: 0.0\n",
      "Epoch 2090, Loss: 2.093727155649816e-06, Final Batch Loss: 3.220564792627556e-08\n",
      "Epoch 2091, Loss: 5.869761814381036e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2092, Loss: 6.836569533152925e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2093, Loss: 1.508326109955771e-05, Final Batch Loss: 0.0\n",
      "Epoch 2094, Loss: 1.6022035786988909e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2095, Loss: 9.74117959628984e-07, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2096, Loss: 2.2997202301366926e-06, Final Batch Loss: 1.413184094190001e-07\n",
      "Epoch 2097, Loss: 5.86646232847432e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2098, Loss: 3.752616035690437e-07, Final Batch Loss: 0.0\n",
      "Epoch 2099, Loss: 6.760909874170551e-07, Final Batch Loss: 5.287487780947231e-08\n",
      "Epoch 2100, Loss: 4.140396453466977e-07, Final Batch Loss: 1.9707945497771107e-08\n",
      "Epoch 2101, Loss: 5.447671163949508e-06, Final Batch Loss: 0.0\n",
      "Epoch 2102, Loss: 1.6094676003053365e-07, Final Batch Loss: 9.132866551908592e-08\n",
      "Epoch 2103, Loss: 1.2986480088073016e-05, Final Batch Loss: 0.0\n",
      "Epoch 2104, Loss: 1.4950881471742505e-06, Final Batch Loss: 6.36386857877369e-07\n",
      "Epoch 2105, Loss: 8.578420820359867e-07, Final Batch Loss: 3.624201951879513e-07\n",
      "Epoch 2106, Loss: 1.0592990946634018e-05, Final Batch Loss: 1.6823873849602933e-08\n",
      "Epoch 2107, Loss: 3.63570015253778e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2108, Loss: 1.7160352506762067e-06, Final Batch Loss: 1.4901144318457682e-08\n",
      "Epoch 2109, Loss: 3.1330703365028967e-07, Final Batch Loss: 3.845459062290502e-09\n",
      "Epoch 2110, Loss: 1.917213797919537e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 2111, Loss: 4.243845319606976e-08, Final Batch Loss: 0.0\n",
      "Epoch 2112, Loss: 8.106982429811893e-08, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2113, Loss: 4.628814962326366e-06, Final Batch Loss: 2.3072699306680988e-08\n",
      "Epoch 2114, Loss: 0.00013538056866413406, Final Batch Loss: 0.0\n",
      "Epoch 2115, Loss: 0.00014677614355296242, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2116, Loss: 1.3548103613536533e-05, Final Batch Loss: 6.248868977820621e-09\n",
      "Epoch 2117, Loss: 9.717039063383837e-07, Final Batch Loss: 0.0\n",
      "Epoch 2118, Loss: 4.5172866579568094e-05, Final Batch Loss: 0.0\n",
      "Epoch 2119, Loss: 1.1833260189497707e-05, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 2120, Loss: 3.1280033763181336e-07, Final Batch Loss: 0.0\n",
      "Epoch 2121, Loss: 9.060605432598123e-08, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2122, Loss: 0.005891564451400821, Final Batch Loss: 7.738923102351691e-08\n",
      "Epoch 2123, Loss: 0.004577735306892428, Final Batch Loss: 1.0094321822862184e-08\n",
      "Epoch 2124, Loss: 3.2954317190636573e-06, Final Batch Loss: 9.46853106142953e-07\n",
      "Epoch 2125, Loss: 0.037230752039489, Final Batch Loss: 4.979743835065165e-07\n",
      "Epoch 2126, Loss: 0.03741176424550585, Final Batch Loss: 5.287505988604835e-09\n",
      "Epoch 2127, Loss: 0.05615922210802493, Final Batch Loss: 5.8643081501941197e-08\n",
      "Epoch 2128, Loss: 0.02413173722683648, Final Batch Loss: 8.00773875653249e-07\n",
      "Epoch 2129, Loss: 0.07422945040701734, Final Batch Loss: 2.6077455004269723e-06\n",
      "Epoch 2130, Loss: 0.007686776110162441, Final Batch Loss: 1.7437176893508877e-06\n",
      "Epoch 2131, Loss: 0.0001336096389494834, Final Batch Loss: 2.8803033274016343e-05\n",
      "Epoch 2132, Loss: 0.002088134748163384, Final Batch Loss: 3.920182280126028e-06\n",
      "Epoch 2133, Loss: 0.0047147115681269725, Final Batch Loss: 3.648228812380694e-07\n",
      "Epoch 2134, Loss: 0.00041586617892619415, Final Batch Loss: 1.5636152966180816e-05\n",
      "Epoch 2135, Loss: 0.000312845023717756, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 2136, Loss: 0.0003329602723560754, Final Batch Loss: 1.1997060482826782e-06\n",
      "Epoch 2137, Loss: 8.277158081426705e-05, Final Batch Loss: 1.7823003872763366e-05\n",
      "Epoch 2138, Loss: 5.92216203649798e-05, Final Batch Loss: 2.965742567084817e-07\n",
      "Epoch 2139, Loss: 0.00021386506852039133, Final Batch Loss: 1.4197263453752385e-06\n",
      "Epoch 2140, Loss: 6.591456316140665e-05, Final Batch Loss: 5.287313342705602e-07\n",
      "Epoch 2141, Loss: 0.00020141710919530098, Final Batch Loss: 5.977523869660217e-06\n",
      "Epoch 2142, Loss: 0.00044914858245448386, Final Batch Loss: 7.835085824581256e-08\n",
      "Epoch 2143, Loss: 3.8861148602187257e-05, Final Batch Loss: 7.354411479809642e-08\n",
      "Epoch 2144, Loss: 0.00031836135558371836, Final Batch Loss: 6.302147994574625e-06\n",
      "Epoch 2145, Loss: 5.367365563191395e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2146, Loss: 3.3311290804860505e-05, Final Batch Loss: 4.902676664642058e-07\n",
      "Epoch 2147, Loss: 6.21918095866647e-05, Final Batch Loss: 5.883335347789398e-07\n",
      "Epoch 2148, Loss: 8.399954106330654e-05, Final Batch Loss: 1.5567138689220883e-06\n",
      "Epoch 2149, Loss: 0.0001522050242706019, Final Batch Loss: 0.00014190850197337568\n",
      "Epoch 2150, Loss: 0.00015366634600155749, Final Batch Loss: 9.998078809303479e-08\n",
      "Epoch 2151, Loss: 0.00042515537163456685, Final Batch Loss: 6.39302797367236e-08\n",
      "Epoch 2152, Loss: 5.616798970820014e-05, Final Batch Loss: 7.252848490679753e-07\n",
      "Epoch 2153, Loss: 0.0005275753121942728, Final Batch Loss: 4.623925065061485e-07\n",
      "Epoch 2154, Loss: 0.00021978368323516406, Final Batch Loss: 9.901997799488527e-08\n",
      "Epoch 2155, Loss: 0.00043035427567517104, Final Batch Loss: 5.484409371092624e-07\n",
      "Epoch 2156, Loss: 0.0001307811157609251, Final Batch Loss: 1.2309046724112704e-05\n",
      "Epoch 2157, Loss: 7.313226898553182e-05, Final Batch Loss: 8.17160117350113e-09\n",
      "Epoch 2158, Loss: 0.00022744230921345476, Final Batch Loss: 5.018081878915837e-07\n",
      "Epoch 2159, Loss: 2.7849512385103026e-05, Final Batch Loss: 2.0103684619243722e-06\n",
      "Epoch 2160, Loss: 1.875364078207653e-05, Final Batch Loss: 6.796530556130165e-07\n",
      "Epoch 2161, Loss: 6.280470981856467e-05, Final Batch Loss: 4.608306880982127e-06\n",
      "Epoch 2162, Loss: 0.0002506856707116256, Final Batch Loss: 2.408158934485982e-07\n",
      "Epoch 2163, Loss: 0.00030421841455785525, Final Batch Loss: 1.9227270442456756e-08\n",
      "Epoch 2164, Loss: 0.0003562008782616033, Final Batch Loss: 1.4490750572804245e-06\n",
      "Epoch 2165, Loss: 8.512307576058475e-05, Final Batch Loss: 4.8548841391493625e-08\n",
      "Epoch 2166, Loss: 3.21995004037845e-05, Final Batch Loss: 2.1630675917094777e-08\n",
      "Epoch 2167, Loss: 0.00016873243238091362, Final Batch Loss: 2.7879529795882263e-08\n",
      "Epoch 2168, Loss: 2.1067205971059266e-05, Final Batch Loss: 1.922729175873883e-08\n",
      "Epoch 2169, Loss: 7.077128106414143e-05, Final Batch Loss: 3.085699427174404e-05\n",
      "Epoch 2170, Loss: 3.419912682622872e-05, Final Batch Loss: 6.282365916376875e-07\n",
      "Epoch 2171, Loss: 0.000383027625306287, Final Batch Loss: 3.494482143651112e-07\n",
      "Epoch 2172, Loss: 2.778638586919957e-05, Final Batch Loss: 3.680140480355476e-06\n",
      "Epoch 2173, Loss: 0.00013287841750275753, Final Batch Loss: 6.092830517445691e-06\n",
      "Epoch 2174, Loss: 3.703816689493156e-05, Final Batch Loss: 3.4367343459962285e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2175, Loss: 1.8156643258104843e-05, Final Batch Loss: 1.3823274684909848e-06\n",
      "Epoch 2176, Loss: 7.719235014835846e-05, Final Batch Loss: 1.6343195241574904e-08\n",
      "Epoch 2177, Loss: 9.440114701164681e-06, Final Batch Loss: 2.711019249090896e-07\n",
      "Epoch 2178, Loss: 3.523157694473866e-05, Final Batch Loss: 1.74003460529093e-07\n",
      "Epoch 2179, Loss: 0.0004371056208170021, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 2180, Loss: 0.00020231249049251776, Final Batch Loss: 2.4795139324851334e-05\n",
      "Epoch 2181, Loss: 0.0006361791498490366, Final Batch Loss: 1.6805978475531447e-06\n",
      "Epoch 2182, Loss: 1.3679159420298959e-05, Final Batch Loss: 4.3355410639378533e-07\n",
      "Epoch 2183, Loss: 3.032202265185191e-05, Final Batch Loss: 3.7012451770124244e-08\n",
      "Epoch 2184, Loss: 8.908776816252129e-06, Final Batch Loss: 3.898203146945889e-07\n",
      "Epoch 2185, Loss: 6.271208151664709e-06, Final Batch Loss: 1.374734779346909e-07\n",
      "Epoch 2186, Loss: 0.006370067946238733, Final Batch Loss: 4.489350260428182e-07\n",
      "Epoch 2187, Loss: 0.00010492493363400968, Final Batch Loss: 3.628251579357311e-05\n",
      "Epoch 2188, Loss: 5.9687612370851184e-05, Final Batch Loss: 2.3098193196346983e-05\n",
      "Epoch 2189, Loss: 0.00022036468775921136, Final Batch Loss: 4.46541577048265e-07\n",
      "Epoch 2190, Loss: 3.525271735227431e-05, Final Batch Loss: 5.6240255617012735e-06\n",
      "Epoch 2191, Loss: 2.4945555885835802e-05, Final Batch Loss: 1.1488155848837778e-07\n",
      "Epoch 2192, Loss: 0.00014997572289687788, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2193, Loss: 1.5734403194578306e-05, Final Batch Loss: 3.3225542210857384e-06\n",
      "Epoch 2194, Loss: 5.734880300245493e-05, Final Batch Loss: 7.372998993560032e-07\n",
      "Epoch 2195, Loss: 0.0002368838314406041, Final Batch Loss: 1.4372203338552936e-07\n",
      "Epoch 2196, Loss: 0.0002407327692739436, Final Batch Loss: 4.498941450492566e-07\n",
      "Epoch 2197, Loss: 0.00017478340489285316, Final Batch Loss: 7.25284962754813e-07\n",
      "Epoch 2198, Loss: 0.00016720542808545957, Final Batch Loss: 2.0073116502317134e-06\n",
      "Epoch 2199, Loss: 0.0002447662733122691, Final Batch Loss: 6.479137368842203e-07\n",
      "Epoch 2200, Loss: 6.688907590235438e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2201, Loss: 1.739796387723036e-05, Final Batch Loss: 3.749310550915652e-08\n",
      "Epoch 2202, Loss: 8.36540787331197e-05, Final Batch Loss: 0.0\n",
      "Epoch 2203, Loss: 0.00038068963955151247, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 2204, Loss: 2.8395117780632972e-05, Final Batch Loss: 2.5523880253786047e-07\n",
      "Epoch 2205, Loss: 7.289875806515411e-05, Final Batch Loss: 4.8068251601307566e-09\n",
      "Epoch 2206, Loss: 0.00014962117460859403, Final Batch Loss: 7.2102359638392954e-09\n",
      "Epoch 2207, Loss: 0.0003601495080278738, Final Batch Loss: 0.0\n",
      "Epoch 2208, Loss: 0.0017411805262561586, Final Batch Loss: 5.008633934266982e-07\n",
      "Epoch 2209, Loss: 0.0010516635079270698, Final Batch Loss: 2.296337697771378e-06\n",
      "Epoch 2210, Loss: 1.4815446274685229e-05, Final Batch Loss: 1.3795445852338162e-07\n",
      "Epoch 2211, Loss: 6.518985756431839e-05, Final Batch Loss: 1.4480373238257016e-06\n",
      "Epoch 2212, Loss: 0.00011025547746967845, Final Batch Loss: 4.210584734209988e-07\n",
      "Epoch 2213, Loss: 4.48533648285121e-05, Final Batch Loss: 6.210195806488628e-07\n",
      "Epoch 2214, Loss: 1.0911567700055969e-05, Final Batch Loss: 7.258277179289507e-08\n",
      "Epoch 2215, Loss: 2.4834495817138702e-05, Final Batch Loss: 1.8926557459053583e-05\n",
      "Epoch 2216, Loss: 6.021434149583449e-05, Final Batch Loss: 2.4514763552474506e-08\n",
      "Epoch 2217, Loss: 9.18259603372995e-05, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 2218, Loss: 4.619655501492126e-05, Final Batch Loss: 5.123894766256853e-07\n",
      "Epoch 2219, Loss: 1.2117263894495522e-05, Final Batch Loss: 1.369931936778812e-07\n",
      "Epoch 2220, Loss: 4.976732834283126e-06, Final Batch Loss: 1.4901021927471447e-07\n",
      "Epoch 2221, Loss: 0.00018916723429729387, Final Batch Loss: 2.115001862534882e-08\n",
      "Epoch 2222, Loss: 6.283151067920656e-05, Final Batch Loss: 7.940103614600957e-07\n",
      "Epoch 2223, Loss: 0.0008328553209389078, Final Batch Loss: 2.0188648974794887e-08\n",
      "Epoch 2224, Loss: 2.7602661174519483e-06, Final Batch Loss: 6.729552470829958e-09\n",
      "Epoch 2225, Loss: 0.00020166762057527432, Final Batch Loss: 1.7352434156236995e-07\n",
      "Epoch 2226, Loss: 1.542543158927767e-05, Final Batch Loss: 5.5278125188351623e-08\n",
      "Epoch 2227, Loss: 6.157322527289288e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2228, Loss: 9.074056390723229e-06, Final Batch Loss: 2.9080547392368317e-07\n",
      "Epoch 2229, Loss: 6.2296733607247745e-06, Final Batch Loss: 1.7070381090888986e-06\n",
      "Epoch 2230, Loss: 7.844358031583454e-05, Final Batch Loss: 8.652236260786594e-08\n",
      "Epoch 2231, Loss: 2.1453570452134585e-05, Final Batch Loss: 5.7681589282765344e-08\n",
      "Epoch 2232, Loss: 6.040650847416451e-06, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 2233, Loss: 7.929290647756826e-05, Final Batch Loss: 9.613643214834156e-09\n",
      "Epoch 2234, Loss: 3.43404315887863e-05, Final Batch Loss: 2.4995435055075177e-08\n",
      "Epoch 2235, Loss: 1.6836301646616647e-05, Final Batch Loss: 1.6738711110519944e-06\n",
      "Epoch 2236, Loss: 5.704004463691348e-05, Final Batch Loss: 2.749412715274957e-07\n",
      "Epoch 2237, Loss: 0.00029215001810123375, Final Batch Loss: 2.6337681902077748e-06\n",
      "Epoch 2238, Loss: 8.029256351427261e-05, Final Batch Loss: 1.0526812133093699e-07\n",
      "Epoch 2239, Loss: 1.5225825752862576e-05, Final Batch Loss: 4.278054888118277e-08\n",
      "Epoch 2240, Loss: 7.913802087866628e-06, Final Batch Loss: 8.17160117350113e-09\n",
      "Epoch 2241, Loss: 2.6538971671374867e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2242, Loss: 9.034460778156728e-06, Final Batch Loss: 1.2017048689472176e-08\n",
      "Epoch 2243, Loss: 2.1149814486420837e-05, Final Batch Loss: 1.2100173989892937e-05\n",
      "Epoch 2244, Loss: 0.00019099644472764243, Final Batch Loss: 4.6626080774103684e-08\n",
      "Epoch 2245, Loss: 0.0001938100630622941, Final Batch Loss: 4.181928758839604e-08\n",
      "Epoch 2246, Loss: 2.9588445255024354e-06, Final Batch Loss: 3.8885349340489483e-07\n",
      "Epoch 2247, Loss: 1.0090822733843652e-05, Final Batch Loss: 0.0\n",
      "Epoch 2248, Loss: 0.0001274497882375325, Final Batch Loss: 1.2978421892739789e-08\n",
      "Epoch 2249, Loss: 2.3090823954130535e-05, Final Batch Loss: 1.2544246601464693e-06\n",
      "Epoch 2250, Loss: 1.2300563323797142e-05, Final Batch Loss: 3.941581994126864e-08\n",
      "Epoch 2251, Loss: 3.1321047767596255e-06, Final Batch Loss: 7.210236407928505e-09\n",
      "Epoch 2252, Loss: 3.8107273888643434e-06, Final Batch Loss: 3.8789227119195857e-07\n",
      "Epoch 2253, Loss: 1.5724918722703762e-05, Final Batch Loss: 9.843171028478537e-06\n",
      "Epoch 2254, Loss: 2.1157274896710376e-05, Final Batch Loss: 2.769703996818862e-06\n",
      "Epoch 2255, Loss: 3.212376917383075e-05, Final Batch Loss: 6.7295542471867975e-09\n",
      "Epoch 2256, Loss: 5.250850712323896e-05, Final Batch Loss: 9.613644991190995e-09\n",
      "Epoch 2257, Loss: 6.81178982082642e-05, Final Batch Loss: 1.9041351606574608e-06\n",
      "Epoch 2258, Loss: 4.683156471696481e-05, Final Batch Loss: 8.267699769248793e-08\n",
      "Epoch 2259, Loss: 8.258346512746151e-05, Final Batch Loss: 1.1968892010827403e-07\n",
      "Epoch 2260, Loss: 8.203501316583761e-06, Final Batch Loss: 5.672017167057675e-08\n",
      "Epoch 2261, Loss: 1.3572869883127225e-05, Final Batch Loss: 4.133856634780386e-08\n",
      "Epoch 2262, Loss: 1.9514602831338657e-05, Final Batch Loss: 1.3939779108795847e-08\n",
      "Epoch 2263, Loss: 7.92185000797474e-06, Final Batch Loss: 4.4990707692704746e-07\n",
      "Epoch 2264, Loss: 0.0005027607716150406, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2265, Loss: 0.0001283445877799938, Final Batch Loss: 1.0873863175220322e-05\n",
      "Epoch 2266, Loss: 1.1584777138473612e-05, Final Batch Loss: 0.0\n",
      "Epoch 2267, Loss: 1.7335461232059757e-05, Final Batch Loss: 1.0671017491858947e-07\n",
      "Epoch 2268, Loss: 1.7337006307238667e-06, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 2269, Loss: 5.914242586446683e-06, Final Batch Loss: 3.2108695791066566e-07\n",
      "Epoch 2270, Loss: 5.190224833118151e-05, Final Batch Loss: 3.94607923226431e-05\n",
      "Epoch 2271, Loss: 4.691427067049503e-06, Final Batch Loss: 3.701240203213274e-08\n",
      "Epoch 2272, Loss: 3.688687472480634e-05, Final Batch Loss: 2.2111363406907003e-08\n",
      "Epoch 2273, Loss: 7.871195009889753e-06, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 2274, Loss: 3.265725387890939e-05, Final Batch Loss: 5.061295951236389e-07\n",
      "Epoch 2275, Loss: 7.618805904074932e-05, Final Batch Loss: 9.373232501275197e-08\n",
      "Epoch 2276, Loss: 1.6068626076282122e-05, Final Batch Loss: 2.1293708130087907e-07\n",
      "Epoch 2277, Loss: 9.094088126770927e-06, Final Batch Loss: 2.488011432433268e-06\n",
      "Epoch 2278, Loss: 5.187282202445687e-06, Final Batch Loss: 6.969843724391467e-08\n",
      "Epoch 2279, Loss: 1.3548657008755072e-05, Final Batch Loss: 4.326142999389049e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2280, Loss: 6.977152957832189e-06, Final Batch Loss: 4.841553163714707e-06\n",
      "Epoch 2281, Loss: 7.080897188593838e-07, Final Batch Loss: 0.0\n",
      "Epoch 2282, Loss: 1.1437408024117524e-05, Final Batch Loss: 8.17160206167955e-09\n",
      "Epoch 2283, Loss: 0.00010883407861594918, Final Batch Loss: 0.0\n",
      "Epoch 2284, Loss: 3.163502721892364e-06, Final Batch Loss: 3.5857399893757247e-07\n",
      "Epoch 2285, Loss: 2.091749776944596e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 2286, Loss: 4.8164107083747965e-06, Final Batch Loss: 1.1295888668882981e-07\n",
      "Epoch 2287, Loss: 0.00014735230089457652, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2288, Loss: 3.922810240197805e-06, Final Batch Loss: 8.310150860779686e-07\n",
      "Epoch 2289, Loss: 1.80912169491787e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2290, Loss: 6.473457481503964e-06, Final Batch Loss: 1.0544797532929806e-06\n",
      "Epoch 2291, Loss: 1.4729474772878781e-05, Final Batch Loss: 0.0\n",
      "Epoch 2292, Loss: 0.0004228133504374787, Final Batch Loss: 0.00042036455124616623\n",
      "Epoch 2293, Loss: 1.7737845249277129e-06, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 2294, Loss: 2.5525797759051727e-05, Final Batch Loss: 2.5050455860764487e-06\n",
      "Epoch 2295, Loss: 8.327298657850868e-06, Final Batch Loss: 9.132866551908592e-08\n",
      "Epoch 2296, Loss: 0.0008043143555785948, Final Batch Loss: 3.0282897967026656e-08\n",
      "Epoch 2297, Loss: 2.032434012977369e-06, Final Batch Loss: 3.1725015503525356e-08\n",
      "Epoch 2298, Loss: 7.493999190355538e-05, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 2299, Loss: 1.3009373205585817e-05, Final Batch Loss: 1.2017046913115337e-08\n",
      "Epoch 2300, Loss: 9.970313405438525e-06, Final Batch Loss: 2.9080311492180044e-07\n",
      "Epoch 2301, Loss: 2.2143422363396503e-05, Final Batch Loss: 1.360309909159696e-07\n",
      "Epoch 2302, Loss: 2.2135395179589956e-05, Final Batch Loss: 6.248831851962677e-08\n",
      "Epoch 2303, Loss: 1.4882485688483271e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2304, Loss: 4.0629954231041765e-06, Final Batch Loss: 7.512373940699035e-07\n",
      "Epoch 2305, Loss: 0.002412245763660059, Final Batch Loss: 3.220562305727981e-08\n",
      "Epoch 2306, Loss: 0.00010208535132716356, Final Batch Loss: 2.8840855037515212e-08\n",
      "Epoch 2307, Loss: 0.0002788137025618864, Final Batch Loss: 2.5698714125610422e-06\n",
      "Epoch 2308, Loss: 1.9617087735346317e-06, Final Batch Loss: 1.5862495317264802e-08\n",
      "Epoch 2309, Loss: 1.595006187415926e-05, Final Batch Loss: 8.65227800517232e-09\n",
      "Epoch 2310, Loss: 3.4950161187374817e-06, Final Batch Loss: 6.887594850013556e-07\n",
      "Epoch 2311, Loss: 3.191680185699042e-05, Final Batch Loss: 6.0775241763622034e-06\n",
      "Epoch 2312, Loss: 2.2805633138056614e-05, Final Batch Loss: 0.0\n",
      "Epoch 2313, Loss: 4.214414389913657e-06, Final Batch Loss: 1.6823859638748218e-08\n",
      "Epoch 2314, Loss: 9.82251563238501e-05, Final Batch Loss: 1.0094321822862184e-08\n",
      "Epoch 2315, Loss: 3.287220525793888e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2316, Loss: 1.4418093328583126e-05, Final Batch Loss: 3.3647777897272135e-09\n",
      "Epoch 2317, Loss: 1.4314523349323593e-05, Final Batch Loss: 1.4420453275931777e-08\n",
      "Epoch 2318, Loss: 3.037816548090433e-06, Final Batch Loss: 7.162139326055694e-08\n",
      "Epoch 2319, Loss: 1.0824825961153195e-05, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 2320, Loss: 6.9617193907411945e-06, Final Batch Loss: 1.2891124470115756e-06\n",
      "Epoch 2321, Loss: 7.4768354136889315e-06, Final Batch Loss: 0.0\n",
      "Epoch 2322, Loss: 1.350177826320298e-06, Final Batch Loss: 1.5573824896364385e-07\n",
      "Epoch 2323, Loss: 6.218258666979004e-06, Final Batch Loss: 3.6338738595986797e-07\n",
      "Epoch 2324, Loss: 0.0004239016817118024, Final Batch Loss: 0.0\n",
      "Epoch 2325, Loss: 2.8035483011890072e-05, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 2326, Loss: 2.7907154111939114e-05, Final Batch Loss: 3.417510470171692e-07\n",
      "Epoch 2327, Loss: 4.051977681274188e-06, Final Batch Loss: 3.3167044222182085e-08\n",
      "Epoch 2328, Loss: 2.0961526369767114e-05, Final Batch Loss: 4.0759840658211033e-07\n",
      "Epoch 2329, Loss: 2.4941524751631583e-05, Final Batch Loss: 1.6379879525629804e-05\n",
      "Epoch 2330, Loss: 6.921854532215832e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2331, Loss: 4.395787268363094e-05, Final Batch Loss: 1.7785227512945312e-08\n",
      "Epoch 2332, Loss: 1.0508980470280704e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 2333, Loss: 6.106651700976684e-06, Final Batch Loss: 8.266973168247205e-07\n",
      "Epoch 2334, Loss: 4.780758930178486e-06, Final Batch Loss: 2.0284318225094466e-07\n",
      "Epoch 2335, Loss: 7.838990482289532e-07, Final Batch Loss: 0.0\n",
      "Epoch 2336, Loss: 2.619550202531684e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 2337, Loss: 4.6384554249101484e-05, Final Batch Loss: 4.6145377297079904e-08\n",
      "Epoch 2338, Loss: 8.737612211540124e-07, Final Batch Loss: 2.6437463773731906e-08\n",
      "Epoch 2339, Loss: 4.251916297826064e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2340, Loss: 1.4808598029714126e-05, Final Batch Loss: 2.523504747387051e-07\n",
      "Epoch 2341, Loss: 1.0640121979710315e-05, Final Batch Loss: 0.0\n",
      "Epoch 2342, Loss: 1.5246001354274341e-05, Final Batch Loss: 2.927257867213484e-07\n",
      "Epoch 2343, Loss: 0.00019502874466126308, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2344, Loss: 1.949676892820662e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 2345, Loss: 2.563290965040821e-07, Final Batch Loss: 3.364766598679125e-08\n",
      "Epoch 2346, Loss: 3.5499003115946337e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2347, Loss: 1.9447843848885427e-05, Final Batch Loss: 0.0\n",
      "Epoch 2348, Loss: 1.2744707430512037e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 2349, Loss: 3.7076890087028858e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2350, Loss: 0.00011063039229264326, Final Batch Loss: 0.0\n",
      "Epoch 2351, Loss: 0.00014656992259731716, Final Batch Loss: 4.4868233089800924e-05\n",
      "Epoch 2352, Loss: 1.0588342957973396e-06, Final Batch Loss: 1.5573859002415702e-07\n",
      "Epoch 2353, Loss: 3.662124549186352e-05, Final Batch Loss: 2.932153364554324e-08\n",
      "Epoch 2354, Loss: 7.578128542851115e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2355, Loss: 2.0679831060910203e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2356, Loss: 1.3599956408816283e-06, Final Batch Loss: 1.5862495317264802e-08\n",
      "Epoch 2357, Loss: 1.606832214395837e-06, Final Batch Loss: 0.0\n",
      "Epoch 2358, Loss: 6.265533415428237e-07, Final Batch Loss: 0.0\n",
      "Epoch 2359, Loss: 4.453646201829642e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2360, Loss: 1.4692030246843402e-05, Final Batch Loss: 4.326141223032209e-09\n",
      "Epoch 2361, Loss: 6.838399713826604e-05, Final Batch Loss: 4.886035094386898e-05\n",
      "Epoch 2362, Loss: 7.412789823080246e-07, Final Batch Loss: 9.805825840203397e-08\n",
      "Epoch 2363, Loss: 4.461683646539427e-06, Final Batch Loss: 6.969451646909874e-07\n",
      "Epoch 2364, Loss: 1.4547695013300554e-05, Final Batch Loss: 1.044179589371197e-05\n",
      "Epoch 2365, Loss: 0.00021652303706520826, Final Batch Loss: 0.0\n",
      "Epoch 2366, Loss: 2.6416596154987815e-07, Final Batch Loss: 0.0\n",
      "Epoch 2367, Loss: 6.27502687144954e-07, Final Batch Loss: 0.0\n",
      "Epoch 2368, Loss: 1.5649280810325905e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2369, Loss: 5.515458118998673e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2370, Loss: 1.865571255921239e-06, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 2371, Loss: 1.4892268990207569e-06, Final Batch Loss: 2.211134031426809e-08\n",
      "Epoch 2372, Loss: 8.95202273087925e-07, Final Batch Loss: 2.691816014532833e-08\n",
      "Epoch 2373, Loss: 2.060545999382768e-07, Final Batch Loss: 7.690917236402584e-09\n",
      "Epoch 2374, Loss: 2.8446598876352702e-05, Final Batch Loss: 2.3505052126893133e-07\n",
      "Epoch 2375, Loss: 2.035555013990553e-06, Final Batch Loss: 2.8360197745769256e-08\n",
      "Epoch 2376, Loss: 8.306001423319387e-07, Final Batch Loss: 0.0\n",
      "Epoch 2377, Loss: 9.74976954737361e-06, Final Batch Loss: 7.410857506329194e-06\n",
      "Epoch 2378, Loss: 2.035692365676134e-06, Final Batch Loss: 0.0\n",
      "Epoch 2379, Loss: 3.8957851833387735e-07, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2380, Loss: 3.0507156839498784e-05, Final Batch Loss: 4.326141223032209e-09\n",
      "Epoch 2381, Loss: 2.8383206521764848e-06, Final Batch Loss: 1.970794016870059e-08\n",
      "Epoch 2382, Loss: 5.713437373211505e-07, Final Batch Loss: 7.210206831587129e-08\n",
      "Epoch 2383, Loss: 8.979530246033818e-07, Final Batch Loss: 1.7304540023133086e-08\n",
      "Epoch 2384, Loss: 1.3146948118269997e-05, Final Batch Loss: 1.2978413899134011e-08\n",
      "Epoch 2385, Loss: 3.6467290366770655e-05, Final Batch Loss: 6.7295511385623286e-09\n",
      "Epoch 2386, Loss: 6.954746400889e-06, Final Batch Loss: 5.627280188491568e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2387, Loss: 1.8354566267864136e-05, Final Batch Loss: 2.499542439693414e-08\n",
      "Epoch 2388, Loss: 6.717778522014051e-06, Final Batch Loss: 1.057501020085283e-08\n",
      "Epoch 2389, Loss: 8.096551605496494e-06, Final Batch Loss: 4.847172931476962e-06\n",
      "Epoch 2390, Loss: 1.187271527869349e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2391, Loss: 6.494273696588948e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2392, Loss: 7.456357261848012e-06, Final Batch Loss: 7.210234187482456e-09\n",
      "Epoch 2393, Loss: 1.033708227127228e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2394, Loss: 1.0654420385280972e-05, Final Batch Loss: 6.24887031008825e-09\n",
      "Epoch 2395, Loss: 1.9420974471051622e-05, Final Batch Loss: 0.0\n",
      "Epoch 2396, Loss: 3.228151774781196e-07, Final Batch Loss: 0.0\n",
      "Epoch 2397, Loss: 0.00018379499759735296, Final Batch Loss: 4.326142111210629e-09\n",
      "Epoch 2398, Loss: 2.8058896208715822e-06, Final Batch Loss: 0.0\n",
      "Epoch 2399, Loss: 9.447924688710252e-06, Final Batch Loss: 8.729353794478811e-06\n",
      "Epoch 2400, Loss: 0.0006066651942098211, Final Batch Loss: 2.259201892229612e-08\n",
      "Epoch 2401, Loss: 3.827807262934968e-06, Final Batch Loss: 2.018863654029701e-08\n",
      "Epoch 2402, Loss: 1.6578088513075073e-07, Final Batch Loss: 3.98964594694462e-08\n",
      "Epoch 2403, Loss: 6.050687053060777e-06, Final Batch Loss: 7.210234631571666e-09\n",
      "Epoch 2404, Loss: 0.0004992167636129752, Final Batch Loss: 1.5525749574862857e-07\n",
      "Epoch 2405, Loss: 2.9271239649575342e-05, Final Batch Loss: 9.45392343965068e-07\n",
      "Epoch 2406, Loss: 7.467059703891721e-07, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 2407, Loss: 7.37652477877937e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2408, Loss: 4.3486066880760177e-07, Final Batch Loss: 0.0\n",
      "Epoch 2409, Loss: 3.878622697794931e-06, Final Batch Loss: 1.3616606793220853e-06\n",
      "Epoch 2410, Loss: 7.829436391437739e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2411, Loss: 1.1796160115373766e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 2412, Loss: 1.52770800794233e-05, Final Batch Loss: 2.4514738683478754e-08\n",
      "Epoch 2413, Loss: 8.177503731943148e-07, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 2414, Loss: 2.0610634221540636e-06, Final Batch Loss: 7.210237740196135e-09\n",
      "Epoch 2415, Loss: 9.035332729334655e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 2416, Loss: 0.0008410204155770984, Final Batch Loss: 0.0008404186810366809\n",
      "Epoch 2417, Loss: 0.0002754588918163492, Final Batch Loss: 2.5476124321244242e-08\n",
      "Epoch 2418, Loss: 0.04479709460373993, Final Batch Loss: 1.3365602171688806e-06\n",
      "Epoch 2419, Loss: 0.01396602928383095, Final Batch Loss: 0.0\n",
      "Epoch 2420, Loss: 0.15145234688065545, Final Batch Loss: 2.023636653802896e-07\n",
      "Epoch 2421, Loss: 0.022615210752139236, Final Batch Loss: 0.0010063655208796263\n",
      "Epoch 2422, Loss: 0.004752404025616386, Final Batch Loss: 0.0009551224648021162\n",
      "Epoch 2423, Loss: 0.0105596480251684, Final Batch Loss: 0.0031889514066278934\n",
      "Epoch 2424, Loss: 0.0007136770500679734, Final Batch Loss: 8.700268949723977e-08\n",
      "Epoch 2425, Loss: 5.5130603806796685e-05, Final Batch Loss: 3.729980164735025e-07\n",
      "Epoch 2426, Loss: 3.4403858166776047e-06, Final Batch Loss: 5.9123731688259795e-08\n",
      "Epoch 2427, Loss: 1.5163046817701087e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 2428, Loss: 2.177131139169397e-05, Final Batch Loss: 1.795920525182737e-06\n",
      "Epoch 2429, Loss: 6.954457203389719e-05, Final Batch Loss: 1.4125326970315655e-06\n",
      "Epoch 2430, Loss: 0.0031991856050532785, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 2431, Loss: 0.0011864984076344065, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2432, Loss: 0.008787473354641362, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 2433, Loss: 8.205141362127577e-06, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 2434, Loss: 4.2513248195485964e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2435, Loss: 6.083323035532828e-06, Final Batch Loss: 3.138744659736403e-07\n",
      "Epoch 2436, Loss: 0.0018850580531246663, Final Batch Loss: 7.853964234527666e-07\n",
      "Epoch 2437, Loss: 0.008860533522413894, Final Batch Loss: 1.8109968777935137e-06\n",
      "Epoch 2438, Loss: 0.007013394047705512, Final Batch Loss: 1.24977406201765e-08\n",
      "Epoch 2439, Loss: 2.8789942282614334e-05, Final Batch Loss: 4.181835322469851e-07\n",
      "Epoch 2440, Loss: 2.5146335487225002e-05, Final Batch Loss: 1.1607344276853837e-06\n",
      "Epoch 2441, Loss: 0.0005774707486549957, Final Batch Loss: 1.2497737955641242e-08\n",
      "Epoch 2442, Loss: 0.00022048511530170511, Final Batch Loss: 3.4993166764252237e-07\n",
      "Epoch 2443, Loss: 0.00010480556198833035, Final Batch Loss: 3.8164517945915577e-07\n",
      "Epoch 2444, Loss: 6.448337976294738e-05, Final Batch Loss: 1.1199757921076525e-07\n",
      "Epoch 2445, Loss: 0.00012821155320263955, Final Batch Loss: 3.9270244656108844e-07\n",
      "Epoch 2446, Loss: 0.00035538065943807595, Final Batch Loss: 9.325194127995928e-08\n",
      "Epoch 2447, Loss: 6.382578065267097e-05, Final Batch Loss: 2.6030113531305688e-06\n",
      "Epoch 2448, Loss: 0.00010137360287898467, Final Batch Loss: 1.7785239947443188e-08\n",
      "Epoch 2449, Loss: 2.2687000328147633e-05, Final Batch Loss: 5.143288817066605e-08\n",
      "Epoch 2450, Loss: 1.884321513512255e-05, Final Batch Loss: 7.306334737222642e-08\n",
      "Epoch 2451, Loss: 0.0005614024414518637, Final Batch Loss: 2.9802277978774327e-08\n",
      "Epoch 2452, Loss: 5.241123755339583e-05, Final Batch Loss: 5.0037342589348555e-06\n",
      "Epoch 2453, Loss: 4.61798105916289e-05, Final Batch Loss: 1.7790949868867756e-06\n",
      "Epoch 2454, Loss: 1.4020848258189389e-05, Final Batch Loss: 3.076356946962733e-08\n",
      "Epoch 2455, Loss: 3.933417492718583e-05, Final Batch Loss: 1.0117810234078206e-06\n",
      "Epoch 2456, Loss: 2.4170848089255514e-05, Final Batch Loss: 6.200762214803035e-08\n",
      "Epoch 2457, Loss: 1.1884357446145799e-05, Final Batch Loss: 8.508002480311916e-08\n",
      "Epoch 2458, Loss: 0.0001095694686199522, Final Batch Loss: 3.7203895431048295e-07\n",
      "Epoch 2459, Loss: 2.1046048450434895e-05, Final Batch Loss: 1.251313733519055e-05\n",
      "Epoch 2460, Loss: 5.856081411947933e-05, Final Batch Loss: 2.6633259039954282e-05\n",
      "Epoch 2461, Loss: 5.547615879164525e-05, Final Batch Loss: 3.3647777897272135e-09\n",
      "Epoch 2462, Loss: 3.3678323813735034e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 2463, Loss: 0.00020034054718198746, Final Batch Loss: 2.4034065404521243e-08\n",
      "Epoch 2464, Loss: 0.0012829261948104076, Final Batch Loss: 3.734781444109103e-07\n",
      "Epoch 2465, Loss: 0.0005877528870072979, Final Batch Loss: 0.000579691375605762\n",
      "Epoch 2466, Loss: 0.00043000175038088173, Final Batch Loss: 0.00040768642793409526\n",
      "Epoch 2467, Loss: 0.003156956402470712, Final Batch Loss: 6.344961889226397e-08\n",
      "Epoch 2468, Loss: 0.00012667491901297012, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 2469, Loss: 5.806942737218712e-06, Final Batch Loss: 1.8602307250148442e-07\n",
      "Epoch 2470, Loss: 0.00016454977227509104, Final Batch Loss: 4.489325817758072e-07\n",
      "Epoch 2471, Loss: 6.250566653953626e-05, Final Batch Loss: 7.306311999855097e-08\n",
      "Epoch 2472, Loss: 2.582936397099722e-06, Final Batch Loss: 5.287505988604835e-09\n",
      "Epoch 2473, Loss: 0.00017284646357829114, Final Batch Loss: 3.946285573874775e-07\n",
      "Epoch 2474, Loss: 0.0004464740602924122, Final Batch Loss: 4.4703394763701e-08\n",
      "Epoch 2475, Loss: 1.4958341211013249e-05, Final Batch Loss: 7.835091508923142e-08\n",
      "Epoch 2476, Loss: 7.041957951336997e-05, Final Batch Loss: 5.508279059540655e-07\n",
      "Epoch 2477, Loss: 8.05569375494919e-06, Final Batch Loss: 8.07975254701887e-07\n",
      "Epoch 2478, Loss: 4.427010679286525e-05, Final Batch Loss: 7.210235075660876e-09\n",
      "Epoch 2479, Loss: 3.4498057662202264e-05, Final Batch Loss: 2.456217771396041e-07\n",
      "Epoch 2480, Loss: 7.049844115336601e-05, Final Batch Loss: 1.4179993002017e-07\n",
      "Epoch 2481, Loss: 4.821533932308775e-05, Final Batch Loss: 8.95290395419579e-06\n",
      "Epoch 2482, Loss: 5.791129481425017e-05, Final Batch Loss: 2.2592054449432908e-08\n",
      "Epoch 2483, Loss: 0.00017658573646839315, Final Batch Loss: 1.3226299415691756e-06\n",
      "Epoch 2484, Loss: 0.0007051759752811915, Final Batch Loss: 1.701586285207668e-07\n",
      "Epoch 2485, Loss: 8.947207237097743e-05, Final Batch Loss: 4.5664606318496226e-08\n",
      "Epoch 2486, Loss: 3.072869517328769e-05, Final Batch Loss: 9.156472060567467e-07\n",
      "Epoch 2487, Loss: 3.442857178859171e-05, Final Batch Loss: 4.40964277004241e-06\n",
      "Epoch 2488, Loss: 6.2500149766719915e-06, Final Batch Loss: 1.9227299752344607e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2489, Loss: 4.417072460938254e-05, Final Batch Loss: 6.743413223375683e-07\n",
      "Epoch 2490, Loss: 0.002087377123938361, Final Batch Loss: 2.438794126646826e-06\n",
      "Epoch 2491, Loss: 3.517569616262595e-05, Final Batch Loss: 3.360415803399519e-06\n",
      "Epoch 2492, Loss: 4.778167983054971e-06, Final Batch Loss: 1.10556861443456e-08\n",
      "Epoch 2493, Loss: 8.998197614129566e-06, Final Batch Loss: 6.184584890434053e-06\n",
      "Epoch 2494, Loss: 3.345427913514776e-05, Final Batch Loss: 1.2505927315942245e-06\n",
      "Epoch 2495, Loss: 1.158266545886466e-05, Final Batch Loss: 7.690891123957044e-08\n",
      "Epoch 2496, Loss: 0.00012168418536573355, Final Batch Loss: 1.504526352391622e-07\n",
      "Epoch 2497, Loss: 2.4674682482794807e-06, Final Batch Loss: 5.263286766421515e-07\n",
      "Epoch 2498, Loss: 7.69858713343119e-05, Final Batch Loss: 4.806823827863127e-09\n",
      "Epoch 2499, Loss: 6.580923500942859e-05, Final Batch Loss: 5.0926482799695805e-05\n",
      "Epoch 2500, Loss: 4.579230509449417e-06, Final Batch Loss: 5.282391839500633e-07\n",
      "Epoch 2501, Loss: 5.901305135114221e-06, Final Batch Loss: 5.7681621257188453e-08\n",
      "Epoch 2502, Loss: 7.079969302214995e-05, Final Batch Loss: 1.3939774667903748e-08\n",
      "Epoch 2503, Loss: 2.8727480401835592e-05, Final Batch Loss: 2.403407783901912e-08\n",
      "Epoch 2504, Loss: 5.201038560498361e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 2505, Loss: 4.386093080954723e-05, Final Batch Loss: 4.75873775940272e-08\n",
      "Epoch 2506, Loss: 0.0003862999278230195, Final Batch Loss: 1.38915225988967e-07\n",
      "Epoch 2507, Loss: 3.102669330112828e-05, Final Batch Loss: 4.0377145182901586e-08\n",
      "Epoch 2508, Loss: 7.082699910898604e-05, Final Batch Loss: 1.1536376298693085e-08\n",
      "Epoch 2509, Loss: 2.9341084525791317e-05, Final Batch Loss: 3.89351093588175e-08\n",
      "Epoch 2510, Loss: 3.846077480451626e-05, Final Batch Loss: 0.0\n",
      "Epoch 2511, Loss: 3.45842023774523e-06, Final Batch Loss: 2.3072709964822025e-08\n",
      "Epoch 2512, Loss: 2.5050963237127633e-06, Final Batch Loss: 6.498336233562441e-07\n",
      "Epoch 2513, Loss: 1.8333658153291132e-05, Final Batch Loss: 4.614542703507141e-08\n",
      "Epoch 2514, Loss: 2.0286551570158906e-05, Final Batch Loss: 1.5862507751762678e-08\n",
      "Epoch 2515, Loss: 3.5519951940510275e-05, Final Batch Loss: 2.4384218704653904e-05\n",
      "Epoch 2516, Loss: 1.5984062135876442e-05, Final Batch Loss: 3.364772638292379e-08\n",
      "Epoch 2517, Loss: 2.5965537471250855e-06, Final Batch Loss: 3.7973769906329835e-08\n",
      "Epoch 2518, Loss: 2.1420936164751048e-05, Final Batch Loss: 1.7400442686721362e-07\n",
      "Epoch 2519, Loss: 1.5475754348237558e-05, Final Batch Loss: 8.748335744712676e-08\n",
      "Epoch 2520, Loss: 9.582512125483333e-05, Final Batch Loss: 2.3930453608045354e-05\n",
      "Epoch 2521, Loss: 3.354984139303241e-05, Final Batch Loss: 1.0430684938000923e-07\n",
      "Epoch 2522, Loss: 9.452422410682892e-06, Final Batch Loss: 1.2113144975955947e-07\n",
      "Epoch 2523, Loss: 1.8392033580560962e-06, Final Batch Loss: 1.730455956305832e-08\n",
      "Epoch 2524, Loss: 4.525624855755694e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2525, Loss: 3.332680709644542e-05, Final Batch Loss: 2.5225112040061504e-05\n",
      "Epoch 2526, Loss: 9.248382402349264e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2527, Loss: 6.998492184662197e-06, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 2528, Loss: 3.0160518870392394e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2529, Loss: 4.212051408214457e-06, Final Batch Loss: 5.647819989462732e-07\n",
      "Epoch 2530, Loss: 2.112113105601221e-05, Final Batch Loss: 5.445791089186969e-07\n",
      "Epoch 2531, Loss: 6.29207103565177e-05, Final Batch Loss: 1.826590967368702e-08\n",
      "Epoch 2532, Loss: 5.221957588896764e-06, Final Batch Loss: 1.92272633370294e-08\n",
      "Epoch 2533, Loss: 1.1427062220570328e-05, Final Batch Loss: 9.709709303251657e-08\n",
      "Epoch 2534, Loss: 1.1213035562174234e-05, Final Batch Loss: 2.818300572471344e-06\n",
      "Epoch 2535, Loss: 4.7282249382440966e-07, Final Batch Loss: 3.5570426604181193e-08\n",
      "Epoch 2536, Loss: 2.0695275306348293e-05, Final Batch Loss: 3.8454505357776725e-08\n",
      "Epoch 2537, Loss: 2.9875433816828334e-06, Final Batch Loss: 5.768188593435752e-09\n",
      "Epoch 2538, Loss: 0.0005686340761589248, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2539, Loss: 1.3643821030639991e-05, Final Batch Loss: 3.941580573041392e-08\n",
      "Epoch 2540, Loss: 5.057333866353986e-05, Final Batch Loss: 3.605107323778611e-08\n",
      "Epoch 2541, Loss: 2.4169362469850242e-05, Final Batch Loss: 1.0040389497589786e-06\n",
      "Epoch 2542, Loss: 1.8014050034542706e-05, Final Batch Loss: 1.4420471039500171e-08\n",
      "Epoch 2543, Loss: 8.198654795399385e-06, Final Batch Loss: 1.3939779108795847e-08\n",
      "Epoch 2544, Loss: 6.904761490011957e-06, Final Batch Loss: 6.2488698659990405e-09\n",
      "Epoch 2545, Loss: 8.60619717035771e-06, Final Batch Loss: 1.1536222643826477e-07\n",
      "Epoch 2546, Loss: 4.7672419721811465e-06, Final Batch Loss: 8.416390073762159e-07\n",
      "Epoch 2547, Loss: 2.2260475996405127e-05, Final Batch Loss: 1.6343189912504386e-08\n",
      "Epoch 2548, Loss: 1.729681314699416e-05, Final Batch Loss: 6.056585277747217e-08\n",
      "Epoch 2549, Loss: 3.908684127873485e-05, Final Batch Loss: 2.739798503625934e-07\n",
      "Epoch 2550, Loss: 0.000316470300463112, Final Batch Loss: 1.3939780885152686e-08\n",
      "Epoch 2551, Loss: 1.9604567984332633e-05, Final Batch Loss: 8.027383557873691e-08\n",
      "Epoch 2552, Loss: 1.2074129414063606e-06, Final Batch Loss: 1.2497735291105982e-08\n",
      "Epoch 2553, Loss: 4.410962320067213e-06, Final Batch Loss: 1.2257268622306583e-07\n",
      "Epoch 2554, Loss: 1.2469598862141495e-05, Final Batch Loss: 1.240150595549494e-07\n",
      "Epoch 2555, Loss: 0.0003339557883932365, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2556, Loss: 4.113696637997322e-06, Final Batch Loss: 7.210233743393246e-09\n",
      "Epoch 2557, Loss: 2.2479424689247907e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2558, Loss: 7.734255015323654e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2559, Loss: 1.4705006771142948e-06, Final Batch Loss: 0.0\n",
      "Epoch 2560, Loss: 0.00037176836365304666, Final Batch Loss: 3.460790196641028e-07\n",
      "Epoch 2561, Loss: 3.0752884844775785e-05, Final Batch Loss: 4.801749469152128e-07\n",
      "Epoch 2562, Loss: 2.1695032483837196e-06, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 2563, Loss: 1.1458507526151962e-05, Final Batch Loss: 1.1776560882026388e-07\n",
      "Epoch 2564, Loss: 4.7700119622851034e-05, Final Batch Loss: 3.582018325687386e-05\n",
      "Epoch 2565, Loss: 2.6142824789410213e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 2566, Loss: 3.4738650230181634e-05, Final Batch Loss: 0.0\n",
      "Epoch 2567, Loss: 8.190094292626071e-05, Final Batch Loss: 3.6051041263363004e-08\n",
      "Epoch 2568, Loss: 3.1082696223538875e-06, Final Batch Loss: 1.196887069454533e-07\n",
      "Epoch 2569, Loss: 7.61508305191505e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2570, Loss: 4.263274420934771e-06, Final Batch Loss: 3.8935123569672214e-08\n",
      "Epoch 2571, Loss: 6.427352577831336e-06, Final Batch Loss: 9.795148798730224e-07\n",
      "Epoch 2572, Loss: 3.43599867114186e-06, Final Batch Loss: 3.9655597561250033e-07\n",
      "Epoch 2573, Loss: 1.285044139387459e-05, Final Batch Loss: 1.0978048976539867e-06\n",
      "Epoch 2574, Loss: 2.1838471786495006e-06, Final Batch Loss: 8.652282446064419e-09\n",
      "Epoch 2575, Loss: 3.608442810409951e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2576, Loss: 9.960850749779482e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2577, Loss: 0.0005364357539955344, Final Batch Loss: 0.0005236793658696115\n",
      "Epoch 2578, Loss: 1.0961268707476712e-05, Final Batch Loss: 7.301981440832606e-06\n",
      "Epoch 2579, Loss: 4.991939465115447e-05, Final Batch Loss: 4.806823827863127e-09\n",
      "Epoch 2580, Loss: 9.546527314341358e-05, Final Batch Loss: 4.882806751993485e-05\n",
      "Epoch 2581, Loss: 2.70490245500854e-05, Final Batch Loss: 4.133860898036801e-08\n",
      "Epoch 2582, Loss: 6.568500479109396e-05, Final Batch Loss: 3.0848050300846808e-06\n",
      "Epoch 2583, Loss: 1.0733567687992718e-06, Final Batch Loss: 1.249755570142952e-07\n",
      "Epoch 2584, Loss: 4.023632865002291e-06, Final Batch Loss: 1.2785955050276243e-07\n",
      "Epoch 2585, Loss: 8.773469421630153e-06, Final Batch Loss: 2.4034060075450725e-08\n",
      "Epoch 2586, Loss: 7.371717105630893e-06, Final Batch Loss: 2.3072709964822025e-08\n",
      "Epoch 2587, Loss: 6.395580644524834e-06, Final Batch Loss: 3.826065437806392e-07\n",
      "Epoch 2588, Loss: 1.3880427795043282e-05, Final Batch Loss: 1.4324133701393293e-07\n",
      "Epoch 2589, Loss: 9.952898819665101e-06, Final Batch Loss: 4.97968869694887e-07\n",
      "Epoch 2590, Loss: 4.941877548181317e-06, Final Batch Loss: 3.749308419287445e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2591, Loss: 2.636117505905311e-05, Final Batch Loss: 1.586249886997848e-08\n",
      "Epoch 2592, Loss: 2.6421514020102954e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2593, Loss: 1.0934701516474021e-06, Final Batch Loss: 7.258253731379227e-08\n",
      "Epoch 2594, Loss: 5.669783784689741e-07, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 2595, Loss: 3.0643136790242664e-06, Final Batch Loss: 7.690919012759423e-09\n",
      "Epoch 2596, Loss: 0.0005328527331036614, Final Batch Loss: 4.8548780995361085e-08\n",
      "Epoch 2597, Loss: 2.6905714365588196e-05, Final Batch Loss: 4.9029512894094296e-08\n",
      "Epoch 2598, Loss: 6.38215347918969e-05, Final Batch Loss: 9.613648543904674e-09\n",
      "Epoch 2599, Loss: 0.004887484713967605, Final Batch Loss: 7.205109682217881e-07\n",
      "Epoch 2600, Loss: 0.000743357534737199, Final Batch Loss: 5.5278356114740745e-08\n",
      "Epoch 2601, Loss: 0.017368290741501813, Final Batch Loss: 3.26862910071668e-08\n",
      "Epoch 2602, Loss: 0.11301704593027662, Final Batch Loss: 0.11284258216619492\n",
      "Epoch 2603, Loss: 0.002699359338073415, Final Batch Loss: 4.881190761807375e-06\n",
      "Epoch 2604, Loss: 0.005357702483297366, Final Batch Loss: 0.005311864428222179\n",
      "Epoch 2605, Loss: 0.0002128477593659195, Final Batch Loss: 2.5956441618291137e-07\n",
      "Epoch 2606, Loss: 3.8973623418314673e-05, Final Batch Loss: 1.1808716635641758e-06\n",
      "Epoch 2607, Loss: 6.773439800489278e-05, Final Batch Loss: 2.8555541575769894e-05\n",
      "Epoch 2608, Loss: 4.612647074919707e-05, Final Batch Loss: 2.1966772578707605e-07\n",
      "Epoch 2609, Loss: 3.222874939134979e-05, Final Batch Loss: 8.652244787299423e-08\n",
      "Epoch 2610, Loss: 0.0001373685252508139, Final Batch Loss: 2.5139161152765155e-07\n",
      "Epoch 2611, Loss: 4.989019211532053e-05, Final Batch Loss: 3.965697032981552e-06\n",
      "Epoch 2612, Loss: 0.0001696124829322354, Final Batch Loss: 7.041492153803119e-07\n",
      "Epoch 2613, Loss: 0.00018240529704427466, Final Batch Loss: 2.759051653811184e-07\n",
      "Epoch 2614, Loss: 7.879157397638892e-06, Final Batch Loss: 2.7398368729336653e-07\n",
      "Epoch 2615, Loss: 2.5837924134464174e-05, Final Batch Loss: 1.6110936940094689e-06\n",
      "Epoch 2616, Loss: 7.524126842439749e-05, Final Batch Loss: 1.4422946151171345e-05\n",
      "Epoch 2617, Loss: 0.00011586971579324867, Final Batch Loss: 4.518398455388706e-08\n",
      "Epoch 2618, Loss: 1.9407851275854426e-05, Final Batch Loss: 2.4322068270521413e-07\n",
      "Epoch 2619, Loss: 0.00022205357436888562, Final Batch Loss: 3.653179092566461e-08\n",
      "Epoch 2620, Loss: 5.755137730645288e-05, Final Batch Loss: 4.8556874389760196e-05\n",
      "Epoch 2621, Loss: 0.00011907207727057667, Final Batch Loss: 3.8789394807281496e-07\n",
      "Epoch 2622, Loss: 2.9654438509663095e-05, Final Batch Loss: 3.6531801583805645e-08\n",
      "Epoch 2623, Loss: 9.002361031029693e-05, Final Batch Loss: 1.1920759845907014e-07\n",
      "Epoch 2624, Loss: 2.234732921457816e-05, Final Batch Loss: 4.1780858737183735e-06\n",
      "Epoch 2625, Loss: 3.614622167091852e-05, Final Batch Loss: 6.200782109999636e-08\n",
      "Epoch 2626, Loss: 1.6580841434077342e-05, Final Batch Loss: 2.119757454011051e-07\n",
      "Epoch 2627, Loss: 7.834091384140152e-05, Final Batch Loss: 2.3456885855921428e-07\n",
      "Epoch 2628, Loss: 0.0002261473593959673, Final Batch Loss: 3.6531716318677354e-08\n",
      "Epoch 2629, Loss: 8.462383052121325e-05, Final Batch Loss: 5.816243486833628e-08\n",
      "Epoch 2630, Loss: 3.842440227375121e-05, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 2631, Loss: 4.059040327297758e-06, Final Batch Loss: 1.7221742609763169e-06\n",
      "Epoch 2632, Loss: 1.0320360934068518e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2633, Loss: 2.508410953161455e-05, Final Batch Loss: 7.642814381370044e-08\n",
      "Epoch 2634, Loss: 0.00010108596381908086, Final Batch Loss: 3.34068658958131e-07\n",
      "Epoch 2635, Loss: 3.752810938917328e-05, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 2636, Loss: 4.1938907337168985e-05, Final Batch Loss: 1.8746602492569764e-08\n",
      "Epoch 2637, Loss: 1.3861149177341048e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 2638, Loss: 9.418452928011689e-06, Final Batch Loss: 3.138121201118338e-06\n",
      "Epoch 2639, Loss: 8.47046801042417e-05, Final Batch Loss: 3.845460394558131e-09\n",
      "Epoch 2640, Loss: 8.575653867026745e-06, Final Batch Loss: 7.78701689796435e-08\n",
      "Epoch 2641, Loss: 8.391480129343876e-05, Final Batch Loss: 5.38362634472378e-08\n",
      "Epoch 2642, Loss: 1.6843806627919733e-05, Final Batch Loss: 1.773680082806095e-07\n",
      "Epoch 2643, Loss: 0.000110370134724036, Final Batch Loss: 6.596589628315996e-06\n",
      "Epoch 2644, Loss: 3.4393419098277533e-05, Final Batch Loss: 8.94064697831709e-08\n",
      "Epoch 2645, Loss: 1.9853058454089023e-05, Final Batch Loss: 2.787956709937589e-08\n",
      "Epoch 2646, Loss: 0.00017473454275507283, Final Batch Loss: 3.3369799439242342e-06\n",
      "Epoch 2647, Loss: 5.4697292394711994e-05, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 2648, Loss: 6.842872819801116e-05, Final Batch Loss: 2.9826804166077636e-05\n",
      "Epoch 2649, Loss: 2.804860965333056e-05, Final Batch Loss: 3.5088476124656154e-07\n",
      "Epoch 2650, Loss: 7.199369642296727e-05, Final Batch Loss: 2.382881348239607e-06\n",
      "Epoch 2651, Loss: 3.8200446821345935e-05, Final Batch Loss: 4.614526716295586e-08\n",
      "Epoch 2652, Loss: 2.3987117706014693e-05, Final Batch Loss: 1.6109407852127333e-06\n",
      "Epoch 2653, Loss: 3.6339515352423746e-06, Final Batch Loss: 3.076361920761883e-08\n",
      "Epoch 2654, Loss: 1.10987697925502e-05, Final Batch Loss: 2.4706645262995153e-07\n",
      "Epoch 2655, Loss: 0.0007565706813259521, Final Batch Loss: 4.739233190775849e-06\n",
      "Epoch 2656, Loss: 1.4108331408801966e-05, Final Batch Loss: 1.1040148137908545e-06\n",
      "Epoch 2657, Loss: 0.0002677957775034656, Final Batch Loss: 1.5425370293087326e-05\n",
      "Epoch 2658, Loss: 8.882729527925903e-06, Final Batch Loss: 9.401091460858879e-07\n",
      "Epoch 2659, Loss: 6.990614928459316e-05, Final Batch Loss: 9.59263343247585e-06\n",
      "Epoch 2660, Loss: 1.2337035812381991e-05, Final Batch Loss: 9.853958715666522e-08\n",
      "Epoch 2661, Loss: 0.001228967066960962, Final Batch Loss: 0.0011684041237458587\n",
      "Epoch 2662, Loss: 2.6894685572820265e-05, Final Batch Loss: 3.374331072336645e-07\n",
      "Epoch 2663, Loss: 6.823719297788244e-05, Final Batch Loss: 1.24977406201765e-08\n",
      "Epoch 2664, Loss: 3.962982775629342e-05, Final Batch Loss: 3.6651445043389685e-06\n",
      "Epoch 2665, Loss: 2.5185398486837762e-05, Final Batch Loss: 9.506623428023886e-06\n",
      "Epoch 2666, Loss: 3.409055136049943e-05, Final Batch Loss: 1.2353436318335298e-07\n",
      "Epoch 2667, Loss: 3.1150468092988604e-05, Final Batch Loss: 1.393970165963765e-07\n",
      "Epoch 2668, Loss: 0.000586547748524846, Final Batch Loss: 1.7016007802794775e-07\n",
      "Epoch 2669, Loss: 1.1792931339460466e-05, Final Batch Loss: 3.1435430969395384e-07\n",
      "Epoch 2670, Loss: 1.261940569352582e-05, Final Batch Loss: 3.6208289202477317e-06\n",
      "Epoch 2671, Loss: 9.41514531849208e-06, Final Batch Loss: 2.2543487432358233e-07\n",
      "Epoch 2672, Loss: 5.868018319588053e-06, Final Batch Loss: 1.0959488605521983e-07\n",
      "Epoch 2673, Loss: 6.340646100611025e-06, Final Batch Loss: 2.9128312917237054e-07\n",
      "Epoch 2674, Loss: 3.4028354252590987e-05, Final Batch Loss: 5.575905603905085e-08\n",
      "Epoch 2675, Loss: 3.7527830864192424e-05, Final Batch Loss: 9.613589213586238e-08\n",
      "Epoch 2676, Loss: 8.476049539574149e-06, Final Batch Loss: 9.477982416683517e-07\n",
      "Epoch 2677, Loss: 2.5773877364687614e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2678, Loss: 3.320793159233837e-06, Final Batch Loss: 2.1630260960137093e-07\n",
      "Epoch 2679, Loss: 1.080956578070058e-05, Final Batch Loss: 4.326133407062116e-08\n",
      "Epoch 2680, Loss: 6.786393011926073e-05, Final Batch Loss: 3.921918960259063e-06\n",
      "Epoch 2681, Loss: 2.1184712593269595e-05, Final Batch Loss: 6.729551582651538e-09\n",
      "Epoch 2682, Loss: 8.648921966725176e-06, Final Batch Loss: 8.319899507114314e-07\n",
      "Epoch 2683, Loss: 6.146665477335667e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2684, Loss: 9.545629251395127e-05, Final Batch Loss: 2.0620832685835921e-07\n",
      "Epoch 2685, Loss: 6.229864139195573e-05, Final Batch Loss: 1.8650247568530176e-07\n",
      "Epoch 2686, Loss: 1.4842625774669216e-05, Final Batch Loss: 7.498625365087719e-08\n",
      "Epoch 2687, Loss: 3.701123125510186e-05, Final Batch Loss: 4.859438718085585e-07\n",
      "Epoch 2688, Loss: 2.385387343351031e-05, Final Batch Loss: 1.927387529576663e-05\n",
      "Epoch 2689, Loss: 3.54237823669834e-05, Final Batch Loss: 7.363495910794882e-07\n",
      "Epoch 2690, Loss: 2.5115283103560593e-05, Final Batch Loss: 5.047141726777227e-08\n",
      "Epoch 2691, Loss: 2.915975894324241e-05, Final Batch Loss: 2.884095406940901e-09\n",
      "Epoch 2692, Loss: 3.129336436535901e-06, Final Batch Loss: 1.538182203830729e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2693, Loss: 2.219256453750429e-05, Final Batch Loss: 1.3908767186876503e-06\n",
      "Epoch 2694, Loss: 6.066693824524627e-06, Final Batch Loss: 2.0669327582822916e-08\n",
      "Epoch 2695, Loss: 1.1467023309785773e-05, Final Batch Loss: 6.7295511385623286e-09\n",
      "Epoch 2696, Loss: 4.2621733482239854e-05, Final Batch Loss: 1.5188500128715532e-06\n",
      "Epoch 2697, Loss: 3.114061316811245e-05, Final Batch Loss: 7.003216069279006e-07\n",
      "Epoch 2698, Loss: 2.607682352895324e-05, Final Batch Loss: 1.798429548216518e-05\n",
      "Epoch 2699, Loss: 8.326871928510116e-05, Final Batch Loss: 1.064096977643203e-05\n",
      "Epoch 2700, Loss: 2.1770956217359583e-05, Final Batch Loss: 8.171600285322711e-09\n",
      "Epoch 2701, Loss: 0.00013207717318797219, Final Batch Loss: 9.896205028780969e-07\n",
      "Epoch 2702, Loss: 6.873414822083923e-06, Final Batch Loss: 1.382693653795286e-06\n",
      "Epoch 2703, Loss: 2.1044375531076298e-05, Final Batch Loss: 1.9130737882733229e-07\n",
      "Epoch 2704, Loss: 9.137812088533259e-05, Final Batch Loss: 9.132962830449287e-09\n",
      "Epoch 2705, Loss: 8.865035120653175e-06, Final Batch Loss: 3.5367554573895177e-06\n",
      "Epoch 2706, Loss: 0.00026775053098648804, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 2707, Loss: 8.650678821164881e-06, Final Batch Loss: 3.7012419795701135e-08\n",
      "Epoch 2708, Loss: 2.275781798011245e-06, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 2709, Loss: 3.6032189445700524e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 2710, Loss: 2.840192625286342e-05, Final Batch Loss: 1.5385257938760333e-05\n",
      "Epoch 2711, Loss: 3.966586501924496e-06, Final Batch Loss: 4.9990870110150354e-08\n",
      "Epoch 2712, Loss: 7.662174737932403e-05, Final Batch Loss: 1.1584324255409228e-07\n",
      "Epoch 2713, Loss: 0.0002990826324601459, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 2714, Loss: 3.743278274015438e-06, Final Batch Loss: 1.538182203830729e-08\n",
      "Epoch 2715, Loss: 7.544981005636053e-06, Final Batch Loss: 2.0309025785536505e-06\n",
      "Epoch 2716, Loss: 1.67374775348339e-05, Final Batch Loss: 3.936612529287231e-07\n",
      "Epoch 2717, Loss: 7.521545190358747e-05, Final Batch Loss: 2.4034083168089637e-08\n",
      "Epoch 2718, Loss: 2.876622410608043e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2719, Loss: 0.00016661993436040134, Final Batch Loss: 1.2976827292732196e-06\n",
      "Epoch 2720, Loss: 5.1452952041231015e-06, Final Batch Loss: 1.707512865323224e-06\n",
      "Epoch 2721, Loss: 5.5503711660076505e-06, Final Batch Loss: 2.4034060075450725e-08\n",
      "Epoch 2722, Loss: 2.8969533426570493e-06, Final Batch Loss: 1.4901142542100843e-08\n",
      "Epoch 2723, Loss: 4.8176016411716205e-06, Final Batch Loss: 2.163067058802426e-08\n",
      "Epoch 2724, Loss: 6.6433225167639165e-06, Final Batch Loss: 1.970794016870059e-08\n",
      "Epoch 2725, Loss: 3.7884618263595016e-05, Final Batch Loss: 3.350343104102649e-05\n",
      "Epoch 2726, Loss: 4.5117894628798894e-05, Final Batch Loss: 8.748397561930688e-08\n",
      "Epoch 2727, Loss: 7.220813150310423e-05, Final Batch Loss: 2.3072736610174616e-08\n",
      "Epoch 2728, Loss: 1.0613107990442572e-05, Final Batch Loss: 1.0575007536317571e-08\n",
      "Epoch 2729, Loss: 0.0014146018148512018, Final Batch Loss: 2.9802230017139664e-08\n",
      "Epoch 2730, Loss: 6.379141769652374e-05, Final Batch Loss: 6.10463146699658e-08\n",
      "Epoch 2731, Loss: 5.540890491895212e-05, Final Batch Loss: 4.849842412113503e-07\n",
      "Epoch 2732, Loss: 5.246786098034306e-05, Final Batch Loss: 4.741749580716714e-05\n",
      "Epoch 2733, Loss: 9.33076135911648e-07, Final Batch Loss: 1.1007553979425211e-07\n",
      "Epoch 2734, Loss: 7.882139084314232e-06, Final Batch Loss: 1.2769932027367759e-06\n",
      "Epoch 2735, Loss: 5.143998168366526e-05, Final Batch Loss: 4.726994666270912e-05\n",
      "Epoch 2736, Loss: 1.4995465114742146e-05, Final Batch Loss: 5.9123763662682904e-08\n",
      "Epoch 2737, Loss: 1.6243370418722591e-06, Final Batch Loss: 9.421276558896352e-08\n",
      "Epoch 2738, Loss: 7.795133812427135e-05, Final Batch Loss: 6.645439862040803e-05\n",
      "Epoch 2739, Loss: 5.7458857789516316e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2740, Loss: 5.279210346986751e-06, Final Batch Loss: 1.2017056683077953e-08\n",
      "Epoch 2741, Loss: 3.5314152093679496e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 2742, Loss: 4.015127947565311e-06, Final Batch Loss: 3.3647777897272135e-09\n",
      "Epoch 2743, Loss: 5.5742740274755676e-06, Final Batch Loss: 1.0094328040111122e-08\n",
      "Epoch 2744, Loss: 1.0357483708367532e-05, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 2745, Loss: 0.0027406421169088313, Final Batch Loss: 8.584106012676784e-07\n",
      "Epoch 2746, Loss: 9.953902251336189e-06, Final Batch Loss: 8.577791959396563e-06\n",
      "Epoch 2747, Loss: 0.00035173115834796764, Final Batch Loss: 8.652281557885999e-09\n",
      "Epoch 2748, Loss: 1.0271348150348025e-05, Final Batch Loss: 9.175202535516291e-07\n",
      "Epoch 2749, Loss: 2.8343149650167376e-05, Final Batch Loss: 3.053601403735229e-06\n",
      "Epoch 2750, Loss: 7.445574195963367e-06, Final Batch Loss: 2.5094952889048727e-06\n",
      "Epoch 2751, Loss: 0.0003151280742446083, Final Batch Loss: 3.028291217788137e-08\n",
      "Epoch 2752, Loss: 7.4466778483550655e-06, Final Batch Loss: 7.306314131483305e-08\n",
      "Epoch 2753, Loss: 7.464962029413158e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 2754, Loss: 5.172819154797281e-05, Final Batch Loss: 1.586222424521111e-07\n",
      "Epoch 2755, Loss: 3.795405515083505e-05, Final Batch Loss: 2.0332487338237115e-07\n",
      "Epoch 2756, Loss: 3.506142693732173e-05, Final Batch Loss: 3.6531716318677354e-08\n",
      "Epoch 2757, Loss: 7.355970480626972e-06, Final Batch Loss: 1.943893039424438e-06\n",
      "Epoch 2758, Loss: 3.621278348076018e-06, Final Batch Loss: 1.9178783361439855e-07\n",
      "Epoch 2759, Loss: 0.00011210060136090938, Final Batch Loss: 5.479771658656318e-08\n",
      "Epoch 2760, Loss: 9.034832072596366e-06, Final Batch Loss: 1.033457053267739e-07\n",
      "Epoch 2761, Loss: 1.708585304549537e-05, Final Batch Loss: 1.586249709362164e-08\n",
      "Epoch 2762, Loss: 1.7732708272877318e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2763, Loss: 0.0002156395002904654, Final Batch Loss: 4.7106631484439276e-08\n",
      "Epoch 2764, Loss: 4.760920042212735e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2765, Loss: 1.0310109078703888e-06, Final Batch Loss: 1.3266632947761536e-07\n",
      "Epoch 2766, Loss: 5.426446353706815e-06, Final Batch Loss: 0.0\n",
      "Epoch 2767, Loss: 8.972424829223336e-06, Final Batch Loss: 1.2449496011868177e-07\n",
      "Epoch 2768, Loss: 6.835758672751879e-05, Final Batch Loss: 9.950014145942987e-08\n",
      "Epoch 2769, Loss: 2.3691603688424934e-05, Final Batch Loss: 2.6437474431872943e-08\n",
      "Epoch 2770, Loss: 7.1618095963676964e-06, Final Batch Loss: 1.5862507751762678e-08\n",
      "Epoch 2771, Loss: 5.316806083177639e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2772, Loss: 1.9410801297414793e-06, Final Batch Loss: 0.0\n",
      "Epoch 2773, Loss: 3.8919230194278676e-05, Final Batch Loss: 2.691815481625781e-08\n",
      "Epoch 2774, Loss: 7.816086928413846e-05, Final Batch Loss: 7.415907020913437e-06\n",
      "Epoch 2775, Loss: 4.567575788594347e-06, Final Batch Loss: 0.0\n",
      "Epoch 2776, Loss: 4.654875868315145e-06, Final Batch Loss: 1.9707950826841625e-08\n",
      "Epoch 2777, Loss: 5.259448464922656e-05, Final Batch Loss: 3.806671156780794e-05\n",
      "Epoch 2778, Loss: 6.328750102868597e-07, Final Batch Loss: 1.538182203830729e-08\n",
      "Epoch 2779, Loss: 1.716052419331593e-05, Final Batch Loss: 8.613062618678669e-07\n",
      "Epoch 2780, Loss: 2.994587530613657e-06, Final Batch Loss: 4.5664730663474984e-08\n",
      "Epoch 2781, Loss: 0.00013657691725466048, Final Batch Loss: 6.441096189746531e-08\n",
      "Epoch 2782, Loss: 2.6474407735399552e-05, Final Batch Loss: 1.7785245276513706e-08\n",
      "Epoch 2783, Loss: 2.4346238448713642e-05, Final Batch Loss: 0.0\n",
      "Epoch 2784, Loss: 1.823175283210965e-05, Final Batch Loss: 6.916860002093017e-06\n",
      "Epoch 2785, Loss: 4.315419597222814e-07, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2786, Loss: 9.80835964004001e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2787, Loss: 1.198689740800063e-06, Final Batch Loss: 4.7488657628491637e-07\n",
      "Epoch 2788, Loss: 1.3427278407585064e-05, Final Batch Loss: 2.114999553270991e-08\n",
      "Epoch 2789, Loss: 1.0337430677576087e-05, Final Batch Loss: 1.35146228785743e-06\n",
      "Epoch 2790, Loss: 1.3813117050176515e-06, Final Batch Loss: 0.0\n",
      "Epoch 2791, Loss: 2.1097597952879354e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 2792, Loss: 2.2789549066315473e-05, Final Batch Loss: 1.7666025087237358e-06\n",
      "Epoch 2793, Loss: 1.0444760927263985e-06, Final Batch Loss: 2.0861114080616971e-07\n",
      "Epoch 2794, Loss: 0.00017614224017459268, Final Batch Loss: 4.326141667121419e-09\n",
      "Epoch 2795, Loss: 3.3555972742682627e-06, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2796, Loss: 2.5197899498063947e-06, Final Batch Loss: 1.2209153510411852e-07\n",
      "Epoch 2797, Loss: 4.4003235259992834e-06, Final Batch Loss: 3.989648789115563e-08\n",
      "Epoch 2798, Loss: 4.999720572218536e-06, Final Batch Loss: 4.806823827863127e-09\n",
      "Epoch 2799, Loss: 1.0947661550630983e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2800, Loss: 3.358243572093578e-05, Final Batch Loss: 3.012754177689203e-06\n",
      "Epoch 2801, Loss: 1.944699523859228e-06, Final Batch Loss: 0.0\n",
      "Epoch 2802, Loss: 7.49067039051976e-06, Final Batch Loss: 1.9885742403857876e-06\n",
      "Epoch 2803, Loss: 2.9288926114423575e-06, Final Batch Loss: 0.0\n",
      "Epoch 2804, Loss: 5.040127440958386e-07, Final Batch Loss: 0.0\n",
      "Epoch 2805, Loss: 1.9752231956715605e-06, Final Batch Loss: 3.9606374002687517e-07\n",
      "Epoch 2806, Loss: 2.273759264204145e-06, Final Batch Loss: 0.0\n",
      "Epoch 2807, Loss: 2.646293071562056e-06, Final Batch Loss: 7.354382347557475e-08\n",
      "Epoch 2808, Loss: 4.727280117799992e-06, Final Batch Loss: 7.210234187482456e-09\n",
      "Epoch 2809, Loss: 3.122330631377679e-06, Final Batch Loss: 3.460900188656524e-08\n",
      "Epoch 2810, Loss: 7.977430100947203e-07, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 2811, Loss: 2.5000681404874214e-05, Final Batch Loss: 1.4564423622687173e-07\n",
      "Epoch 2812, Loss: 1.0189684415129463e-06, Final Batch Loss: 0.0\n",
      "Epoch 2813, Loss: 3.109675299484138e-07, Final Batch Loss: 9.132961942270867e-09\n",
      "Epoch 2814, Loss: 2.360086839514608e-06, Final Batch Loss: 7.931190992849224e-08\n",
      "Epoch 2815, Loss: 1.4799893488515181e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2816, Loss: 3.348027571259404e-05, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 2817, Loss: 1.1204392043717704e-05, Final Batch Loss: 5.768187261168123e-09\n",
      "Epoch 2818, Loss: 7.357121524109722e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2819, Loss: 1.7073420390478766e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2820, Loss: 1.0409117363607834e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2821, Loss: 5.321604796937329e-06, Final Batch Loss: 5.6720175223290425e-08\n",
      "Epoch 2822, Loss: 1.8190557563912968e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2823, Loss: 4.363080377656203e-06, Final Batch Loss: 1.6296677358695888e-06\n",
      "Epoch 2824, Loss: 2.239663350778187e-06, Final Batch Loss: 2.7398815660717446e-08\n",
      "Epoch 2825, Loss: 9.685899756473049e-06, Final Batch Loss: 6.392573368430021e-07\n",
      "Epoch 2826, Loss: 1.5910200021340692e-05, Final Batch Loss: 7.258269363319414e-08\n",
      "Epoch 2827, Loss: 2.375347392447047e-06, Final Batch Loss: 0.0\n",
      "Epoch 2828, Loss: 7.218428264010868e-06, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 2829, Loss: 1.6785821183029626e-06, Final Batch Loss: 4.902948091967119e-08\n",
      "Epoch 2830, Loss: 1.1179691827845062e-06, Final Batch Loss: 4.542234535165335e-07\n",
      "Epoch 2831, Loss: 1.055615302703039e-05, Final Batch Loss: 1.0423593266750686e-05\n",
      "Epoch 2832, Loss: 5.872649659899309e-07, Final Batch Loss: 3.7012416242987456e-08\n",
      "Epoch 2833, Loss: 1.1824236982871383e-05, Final Batch Loss: 0.0\n",
      "Epoch 2834, Loss: 1.4124073756116573e-06, Final Batch Loss: 1.10556861443456e-08\n",
      "Epoch 2835, Loss: 1.3248296695467232e-05, Final Batch Loss: 1.965944420589949e-07\n",
      "Epoch 2836, Loss: 5.168434970792557e-05, Final Batch Loss: 5.272748353490897e-07\n",
      "Epoch 2837, Loss: 2.8398944437180162e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2838, Loss: 3.0164703154644812e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 2839, Loss: 4.7580162865212827e-07, Final Batch Loss: 4.9990688921752735e-08\n",
      "Epoch 2840, Loss: 1.0485911215996069e-06, Final Batch Loss: 7.690915460045744e-09\n",
      "Epoch 2841, Loss: 6.003293107070817e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2842, Loss: 2.516840657107444e-06, Final Batch Loss: 8.156402486747538e-07\n",
      "Epoch 2843, Loss: 3.0168093674287633e-06, Final Batch Loss: 1.6397557374148164e-06\n",
      "Epoch 2844, Loss: 2.924622833799795e-06, Final Batch Loss: 4.806824716041547e-09\n",
      "Epoch 2845, Loss: 4.207725146865293e-05, Final Batch Loss: 0.0\n",
      "Epoch 2846, Loss: 2.572051469251768e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 2847, Loss: 1.1510682995652388e-06, Final Batch Loss: 6.29691641051977e-08\n",
      "Epoch 2848, Loss: 5.152189864410239e-06, Final Batch Loss: 2.5732342692208476e-06\n",
      "Epoch 2849, Loss: 1.0512695315489928e-05, Final Batch Loss: 5.361469447962008e-06\n",
      "Epoch 2850, Loss: 6.795065240483567e-07, Final Batch Loss: 6.729553359008378e-09\n",
      "Epoch 2851, Loss: 6.995962830713687e-06, Final Batch Loss: 3.3647777897272135e-09\n",
      "Epoch 2852, Loss: 5.598713592736004e-07, Final Batch Loss: 9.132962830449287e-09\n",
      "Epoch 2853, Loss: 3.4024915098740394e-06, Final Batch Loss: 1.8505858179196366e-07\n",
      "Epoch 2854, Loss: 1.2058176803719789e-05, Final Batch Loss: 8.171599397144291e-09\n",
      "Epoch 2855, Loss: 6.008124242562474e-08, Final Batch Loss: 0.0\n",
      "Epoch 2856, Loss: 1.3382673811568324e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2857, Loss: 8.156588682250998e-08, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 2858, Loss: 0.0009402391501900365, Final Batch Loss: 0.00019296618120279163\n",
      "Epoch 2859, Loss: 0.05271795880197594, Final Batch Loss: 0.003938707988709211\n",
      "Epoch 2860, Loss: 0.030723605178350155, Final Batch Loss: 1.0775897862913553e-06\n",
      "Epoch 2861, Loss: 0.005561698716858743, Final Batch Loss: 1.317059457051073e-07\n",
      "Epoch 2862, Loss: 0.0015342885718103716, Final Batch Loss: 3.7107574257788656e-07\n",
      "Epoch 2863, Loss: 0.004767282086741709, Final Batch Loss: 9.564474794387934e-07\n",
      "Epoch 2864, Loss: 9.30137001002862e-05, Final Batch Loss: 6.681437270117385e-08\n",
      "Epoch 2865, Loss: 0.0011051270203248365, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 2866, Loss: 0.001843033206712752, Final Batch Loss: 2.2111359854193324e-08\n",
      "Epoch 2867, Loss: 3.0524421958944004e-05, Final Batch Loss: 7.979298288773862e-08\n",
      "Epoch 2868, Loss: 0.00027417688757758185, Final Batch Loss: 1.657765096751973e-05\n",
      "Epoch 2869, Loss: 0.00017061059111878052, Final Batch Loss: 9.613614793124725e-08\n",
      "Epoch 2870, Loss: 2.9114269738172993e-05, Final Batch Loss: 9.565531655653103e-08\n",
      "Epoch 2871, Loss: 4.0017485028354116e-05, Final Batch Loss: 4.5421998606798297e-07\n",
      "Epoch 2872, Loss: 2.474963451959411e-06, Final Batch Loss: 1.0190379384766857e-07\n",
      "Epoch 2873, Loss: 6.387432960408557e-05, Final Batch Loss: 7.594759665607853e-08\n",
      "Epoch 2874, Loss: 0.0003032880581240738, Final Batch Loss: 1.0093112905451562e-06\n",
      "Epoch 2875, Loss: 0.00010358766669815722, Final Batch Loss: 9.985012729885057e-05\n",
      "Epoch 2876, Loss: 6.620840546411877e-05, Final Batch Loss: 3.191646840150497e-07\n",
      "Epoch 2877, Loss: 9.650808997319071e-05, Final Batch Loss: 6.293876140262e-06\n",
      "Epoch 2878, Loss: 0.00015096461757124757, Final Batch Loss: 5.86429464988214e-08\n",
      "Epoch 2879, Loss: 1.0033093669425952e-05, Final Batch Loss: 5.768189481614172e-09\n",
      "Epoch 2880, Loss: 2.7625312960521953e-06, Final Batch Loss: 1.0526883187367275e-07\n",
      "Epoch 2881, Loss: 7.852744003056245e-06, Final Batch Loss: 2.263977876282297e-07\n",
      "Epoch 2882, Loss: 6.809710158151017e-05, Final Batch Loss: 4.3261287885343336e-08\n",
      "Epoch 2883, Loss: 1.0183698074817116e-05, Final Batch Loss: 0.0\n",
      "Epoch 2884, Loss: 0.0003037601680774271, Final Batch Loss: 3.52116949215997e-05\n",
      "Epoch 2885, Loss: 1.0537816298672453e-05, Final Batch Loss: 1.1536366528730468e-08\n",
      "Epoch 2886, Loss: 1.415156256179273e-05, Final Batch Loss: 6.6814415333738e-08\n",
      "Epoch 2887, Loss: 8.842100429951039e-06, Final Batch Loss: 2.557178504503099e-07\n",
      "Epoch 2888, Loss: 1.5029291479340401e-05, Final Batch Loss: 0.0\n",
      "Epoch 2889, Loss: 0.0013603992392553499, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 2890, Loss: 4.353299849935155e-06, Final Batch Loss: 2.1630686575235814e-08\n",
      "Epoch 2891, Loss: 3.8381511301754934e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2892, Loss: 0.0001150343855600422, Final Batch Loss: 1.4420465710429653e-08\n",
      "Epoch 2893, Loss: 5.83243658747179e-06, Final Batch Loss: 1.0435156809762702e-06\n",
      "Epoch 2894, Loss: 5.0504690134567376e-05, Final Batch Loss: 3.893519817665947e-08\n",
      "Epoch 2895, Loss: 1.3946224960315057e-05, Final Batch Loss: 1.2497737955641242e-08\n",
      "Epoch 2896, Loss: 4.752935765628408e-06, Final Batch Loss: 2.7061551577389764e-07\n",
      "Epoch 2897, Loss: 6.005495863825594e-05, Final Batch Loss: 3.9415859021119104e-08\n",
      "Epoch 2898, Loss: 1.4878993321865153e-06, Final Batch Loss: 2.0428518610060564e-07\n",
      "Epoch 2899, Loss: 0.00043991638592710824, Final Batch Loss: 6.393033658014247e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2900, Loss: 8.121166295782523e-06, Final Batch Loss: 5.474653903547733e-07\n",
      "Epoch 2901, Loss: 2.2480530884161354e-05, Final Batch Loss: 4.326141667121419e-09\n",
      "Epoch 2902, Loss: 3.365697033785864e-05, Final Batch Loss: 1.3005804930799059e-06\n",
      "Epoch 2903, Loss: 2.027627126777176e-05, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 2904, Loss: 1.9721020322327476e-06, Final Batch Loss: 8.123477357457887e-08\n",
      "Epoch 2905, Loss: 2.4160141692819437e-06, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 2906, Loss: 9.130217698438692e-06, Final Batch Loss: 6.441110400601247e-08\n",
      "Epoch 2907, Loss: 4.562061270085849e-06, Final Batch Loss: 1.634317747800651e-08\n",
      "Epoch 2908, Loss: 2.9770866297740284e-06, Final Batch Loss: 2.835928398781107e-07\n",
      "Epoch 2909, Loss: 1.61035922836561e-05, Final Batch Loss: 6.056556145495051e-08\n",
      "Epoch 2910, Loss: 6.351338028398601e-06, Final Batch Loss: 1.057501020085283e-08\n",
      "Epoch 2911, Loss: 4.420516466674407e-05, Final Batch Loss: 3.6051041263363004e-08\n",
      "Epoch 2912, Loss: 1.1763148086485486e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2913, Loss: 1.6215091422910888e-06, Final Batch Loss: 1.062295211795572e-07\n",
      "Epoch 2914, Loss: 8.38256849466923e-06, Final Batch Loss: 1.9707941945057428e-08\n",
      "Epoch 2915, Loss: 1.282575510419548e-05, Final Batch Loss: 5.479754250359292e-08\n",
      "Epoch 2916, Loss: 0.0009356144890030338, Final Batch Loss: 1.6343186359790707e-08\n",
      "Epoch 2917, Loss: 3.5044826151353625e-05, Final Batch Loss: 3.946212814298633e-07\n",
      "Epoch 2918, Loss: 5.875986873293826e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 2919, Loss: 0.0002336248322266643, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2920, Loss: 1.1918818545453291e-06, Final Batch Loss: 4.278057019746484e-08\n",
      "Epoch 2921, Loss: 3.7899616580183704e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2922, Loss: 7.4747315589318575e-06, Final Batch Loss: 1.4901133660316646e-08\n",
      "Epoch 2923, Loss: 0.00011965791350987409, Final Batch Loss: 8.677256118971854e-05\n",
      "Epoch 2924, Loss: 4.9324359123748e-06, Final Batch Loss: 1.8910445760411676e-06\n",
      "Epoch 2925, Loss: 1.2619125614232729e-05, Final Batch Loss: 0.0\n",
      "Epoch 2926, Loss: 7.614030302915964e-06, Final Batch Loss: 9.535634717394714e-07\n",
      "Epoch 2927, Loss: 3.817161830999005e-05, Final Batch Loss: 3.29680296999868e-05\n",
      "Epoch 2928, Loss: 6.4651006534965916e-06, Final Batch Loss: 0.0\n",
      "Epoch 2929, Loss: 0.00016072461075389288, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2930, Loss: 1.956313494755335e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 2931, Loss: 0.0001532207396043317, Final Batch Loss: 7.738959340031215e-08\n",
      "Epoch 2932, Loss: 8.412321111261889e-06, Final Batch Loss: 2.6807194899447495e-06\n",
      "Epoch 2933, Loss: 5.436744040820951e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 2934, Loss: 9.560095859839635e-06, Final Batch Loss: 7.690916348224164e-09\n",
      "Epoch 2935, Loss: 1.159168874775851e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 2936, Loss: 0.00019815469036665867, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2937, Loss: 3.256743177604271e-05, Final Batch Loss: 9.75669308900251e-07\n",
      "Epoch 2938, Loss: 4.1670119323988786e-06, Final Batch Loss: 7.210234631571666e-09\n",
      "Epoch 2939, Loss: 2.9831629532739434e-05, Final Batch Loss: 4.462898687052075e-06\n",
      "Epoch 2940, Loss: 9.018422090889544e-06, Final Batch Loss: 5.3836270552665155e-08\n",
      "Epoch 2941, Loss: 1.7758285852820244e-05, Final Batch Loss: 4.37419274135209e-08\n",
      "Epoch 2942, Loss: 1.6707157296513842e-06, Final Batch Loss: 6.104638572423937e-08\n",
      "Epoch 2943, Loss: 2.0966327186511258e-05, Final Batch Loss: 6.474425049418642e-07\n",
      "Epoch 2944, Loss: 1.3503183433627441e-06, Final Batch Loss: 8.652283334242838e-09\n",
      "Epoch 2945, Loss: 2.175390430125823e-06, Final Batch Loss: 5.003595902053348e-07\n",
      "Epoch 2946, Loss: 5.513646349597501e-06, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 2947, Loss: 4.979276921457387e-05, Final Batch Loss: 2.485056711520883e-07\n",
      "Epoch 2948, Loss: 9.879902003184782e-07, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 2949, Loss: 0.0011505490284116071, Final Batch Loss: 2.982118303407333e-06\n",
      "Epoch 2950, Loss: 0.000383958576592458, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 2951, Loss: 1.0430186644261319e-05, Final Batch Loss: 5.575532782131631e-07\n",
      "Epoch 2952, Loss: 0.0003150749375759876, Final Batch Loss: 0.0\n",
      "Epoch 2953, Loss: 0.01970944521278395, Final Batch Loss: 1.5477692727472459e-07\n",
      "Epoch 2954, Loss: 0.00756875003384283, Final Batch Loss: 1.168045571375842e-07\n",
      "Epoch 2955, Loss: 0.009091384737145547, Final Batch Loss: 5.383629542166091e-08\n",
      "Epoch 2956, Loss: 0.006430364225788132, Final Batch Loss: 7.129155164875556e-06\n",
      "Epoch 2957, Loss: 0.0032364929916610663, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 2958, Loss: 0.0018390061648771994, Final Batch Loss: 4.3836982399625413e-07\n",
      "Epoch 2959, Loss: 0.00011918830672463798, Final Batch Loss: 2.2410131350625306e-05\n",
      "Epoch 2960, Loss: 7.315045780842411e-05, Final Batch Loss: 3.911194289685227e-05\n",
      "Epoch 2961, Loss: 0.005985739083279817, Final Batch Loss: 3.845459062290502e-09\n",
      "Epoch 2962, Loss: 0.0097408014341267, Final Batch Loss: 9.98260134110751e-07\n",
      "Epoch 2963, Loss: 2.224281510465609e-05, Final Batch Loss: 7.690919900937843e-09\n",
      "Epoch 2964, Loss: 4.023817316145539e-05, Final Batch Loss: 7.210234187482456e-09\n",
      "Epoch 2965, Loss: 4.1298293515401596e-05, Final Batch Loss: 2.3793602110799839e-07\n",
      "Epoch 2966, Loss: 8.453850878220592e-05, Final Batch Loss: 1.40047461627546e-06\n",
      "Epoch 2967, Loss: 8.50374682581645e-06, Final Batch Loss: 7.800741741448292e-07\n",
      "Epoch 2968, Loss: 2.3007209191128197e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 2969, Loss: 8.971555784720309e-05, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 2970, Loss: 2.6767366734681275e-05, Final Batch Loss: 4.2779993236763403e-07\n",
      "Epoch 2971, Loss: 1.2173197760034782e-05, Final Batch Loss: 7.58935584599385e-07\n",
      "Epoch 2972, Loss: 2.3885675158652475e-05, Final Batch Loss: 2.0188657856579084e-08\n",
      "Epoch 2973, Loss: 1.8049495723371223e-05, Final Batch Loss: 1.1965627891186159e-05\n",
      "Epoch 2974, Loss: 2.7030215770107446e-05, Final Batch Loss: 9.700035661808215e-06\n",
      "Epoch 2975, Loss: 5.027419377334752e-05, Final Batch Loss: 2.898483728586143e-07\n",
      "Epoch 2976, Loss: 0.00010423514879476237, Final Batch Loss: 1.6032433904911159e-06\n",
      "Epoch 2977, Loss: 0.00014559117598800242, Final Batch Loss: 5.591287845163606e-06\n",
      "Epoch 2978, Loss: 7.54400275688738e-05, Final Batch Loss: 1.2161135032329184e-07\n",
      "Epoch 2979, Loss: 2.0325824202416243e-05, Final Batch Loss: 2.1150000861780427e-08\n",
      "Epoch 2980, Loss: 7.441331954893826e-05, Final Batch Loss: 2.4615392248961143e-06\n",
      "Epoch 2981, Loss: 5.3116050293011696e-05, Final Batch Loss: 6.34498817930762e-08\n",
      "Epoch 2982, Loss: 6.0425933142704835e-06, Final Batch Loss: 9.613647655726254e-09\n",
      "Epoch 2983, Loss: 0.0007494885248212624, Final Batch Loss: 5.623969201451473e-08\n",
      "Epoch 2984, Loss: 3.942019424174603e-05, Final Batch Loss: 1.6823870296889254e-08\n",
      "Epoch 2985, Loss: 0.0005476756053970355, Final Batch Loss: 6.537235464065816e-08\n",
      "Epoch 2986, Loss: 0.00019582220143110618, Final Batch Loss: 1.528227949165739e-05\n",
      "Epoch 2987, Loss: 0.0002625418593535933, Final Batch Loss: 1.9227279324240953e-08\n",
      "Epoch 2988, Loss: 5.3342037700243594e-05, Final Batch Loss: 1.490115231206346e-08\n",
      "Epoch 2989, Loss: 0.00013286540936974234, Final Batch Loss: 1.6631466337457823e-07\n",
      "Epoch 2990, Loss: 3.090859446652772e-05, Final Batch Loss: 8.573963896196801e-06\n",
      "Epoch 2991, Loss: 1.770302393389045e-05, Final Batch Loss: 1.6823875625959772e-08\n",
      "Epoch 2992, Loss: 1.2561744774597372e-05, Final Batch Loss: 5.542102030631213e-07\n",
      "Epoch 2993, Loss: 3.733281954898526e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 2994, Loss: 7.153093617873196e-06, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 2995, Loss: 7.867849635967428e-05, Final Batch Loss: 1.547776946608792e-07\n",
      "Epoch 2996, Loss: 2.9254675480316905e-05, Final Batch Loss: 1.1237468697800068e-06\n",
      "Epoch 2997, Loss: 0.00022062988391879923, Final Batch Loss: 8.65227889335074e-09\n",
      "Epoch 2998, Loss: 7.635320009358182e-06, Final Batch Loss: 0.0\n",
      "Epoch 2999, Loss: 5.407819711700235e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3000, Loss: 5.210486527129632e-06, Final Batch Loss: 6.296904331293263e-08\n",
      "Epoch 3001, Loss: 0.022635069625903892, Final Batch Loss: 2.5818858375714626e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3002, Loss: 0.04575166055596469, Final Batch Loss: 0.0004092474700883031\n",
      "Epoch 3003, Loss: 0.005741830037067075, Final Batch Loss: 2.439158834022237e-06\n",
      "Epoch 3004, Loss: 0.003156831816511385, Final Batch Loss: 4.280807843315415e-06\n",
      "Epoch 3005, Loss: 0.00033172562802974426, Final Batch Loss: 8.692466508364305e-06\n",
      "Epoch 3006, Loss: 0.0006486683441266905, Final Batch Loss: 0.00023086332657840103\n",
      "Epoch 3007, Loss: 0.0037868681176718155, Final Batch Loss: 4.3788298853542074e-07\n",
      "Epoch 3008, Loss: 0.00016531756565996147, Final Batch Loss: 6.901296274008928e-06\n",
      "Epoch 3009, Loss: 0.0005650583866909642, Final Batch Loss: 1.3543656223191647e-06\n",
      "Epoch 3010, Loss: 0.00012299441480934092, Final Batch Loss: 3.133965549295681e-07\n",
      "Epoch 3011, Loss: 0.0003839437887940278, Final Batch Loss: 1.0415544693387346e-06\n",
      "Epoch 3012, Loss: 0.00028256991172881385, Final Batch Loss: 5.6239674250946337e-08\n",
      "Epoch 3013, Loss: 0.0005217796985164114, Final Batch Loss: 7.070289029798005e-07\n",
      "Epoch 3014, Loss: 0.0005336433329858892, Final Batch Loss: 1.6391147994454514e-07\n",
      "Epoch 3015, Loss: 0.0004508062788985967, Final Batch Loss: 8.65186223109049e-07\n",
      "Epoch 3016, Loss: 3.575094130070511e-05, Final Batch Loss: 1.4804933812229137e-07\n",
      "Epoch 3017, Loss: 0.00014641807369741855, Final Batch Loss: 2.061542090814328e-06\n",
      "Epoch 3018, Loss: 0.0001826828696422922, Final Batch Loss: 1.3045071227679728e-06\n",
      "Epoch 3019, Loss: 0.00014385828524421385, Final Batch Loss: 4.806736342288787e-07\n",
      "Epoch 3020, Loss: 0.00012914468718339123, Final Batch Loss: 8.022196311685548e-07\n",
      "Epoch 3021, Loss: 0.0009609479379335539, Final Batch Loss: 1.0496812592464266e-06\n",
      "Epoch 3022, Loss: 0.0002612921677513924, Final Batch Loss: 3.708456461026799e-06\n",
      "Epoch 3023, Loss: 0.00011480555682652493, Final Batch Loss: 2.1918908998941333e-07\n",
      "Epoch 3024, Loss: 0.00013506795841067287, Final Batch Loss: 4.0246541175292805e-05\n",
      "Epoch 3025, Loss: 6.256290910755524e-05, Final Batch Loss: 1.1074029089286341e-06\n",
      "Epoch 3026, Loss: 0.00021426749590602867, Final Batch Loss: 1.6535322799882124e-07\n",
      "Epoch 3027, Loss: 0.0012168727218724307, Final Batch Loss: 0.0008218201692216098\n",
      "Epoch 3028, Loss: 0.0003531457107079916, Final Batch Loss: 7.83506166612824e-08\n",
      "Epoch 3029, Loss: 6.844345931078522e-05, Final Batch Loss: 1.706388275124482e-07\n",
      "Epoch 3030, Loss: 0.0003340546556396262, Final Batch Loss: 9.598178394298884e-07\n",
      "Epoch 3031, Loss: 0.00010375285147068425, Final Batch Loss: 4.705917490355205e-06\n",
      "Epoch 3032, Loss: 4.096383349816435e-05, Final Batch Loss: 6.24887119826667e-09\n",
      "Epoch 3033, Loss: 0.00020044294164067722, Final Batch Loss: 7.161855251069937e-07\n",
      "Epoch 3034, Loss: 0.0002832961841963133, Final Batch Loss: 7.593688678753097e-06\n",
      "Epoch 3035, Loss: 6.990687999941514e-05, Final Batch Loss: 3.605111587035026e-08\n",
      "Epoch 3036, Loss: 5.3335071475757445e-05, Final Batch Loss: 1.4409198456633021e-06\n",
      "Epoch 3037, Loss: 0.00012956386993012714, Final Batch Loss: 1.2275155540919513e-06\n",
      "Epoch 3038, Loss: 0.000437290323195505, Final Batch Loss: 5.8431405705050565e-06\n",
      "Epoch 3039, Loss: 0.00012848846400004277, Final Batch Loss: 9.617924661142752e-06\n",
      "Epoch 3040, Loss: 0.00044664867511190476, Final Batch Loss: 1.4117408682068344e-05\n",
      "Epoch 3041, Loss: 0.00010636812300823806, Final Batch Loss: 2.2658055058855098e-06\n",
      "Epoch 3042, Loss: 5.406519317263658e-05, Final Batch Loss: 8.171567600356866e-08\n",
      "Epoch 3043, Loss: 0.00016930699248141057, Final Batch Loss: 1.96071505342843e-06\n",
      "Epoch 3044, Loss: 7.930510669584834e-05, Final Batch Loss: 1.2304136589591508e-06\n",
      "Epoch 3045, Loss: 6.137561172003814e-05, Final Batch Loss: 3.744425498553028e-07\n",
      "Epoch 3046, Loss: 6.739086751839096e-05, Final Batch Loss: 5.575902406462774e-08\n",
      "Epoch 3047, Loss: 9.693646162034497e-05, Final Batch Loss: 1.2978421892739789e-08\n",
      "Epoch 3048, Loss: 5.82493360572478e-05, Final Batch Loss: 8.240459465014283e-06\n",
      "Epoch 3049, Loss: 0.000104122833255893, Final Batch Loss: 1.3113164641254116e-05\n",
      "Epoch 3050, Loss: 0.00017208854747963187, Final Batch Loss: 2.077641966025112e-06\n",
      "Epoch 3051, Loss: 5.2512950994731966e-05, Final Batch Loss: 2.7466403480502777e-05\n",
      "Epoch 3052, Loss: 0.00017814469467514193, Final Batch Loss: 6.6809400323109e-07\n",
      "Epoch 3053, Loss: 2.7443428518125756e-05, Final Batch Loss: 2.196673989374176e-07\n",
      "Epoch 3054, Loss: 1.657354614792439e-05, Final Batch Loss: 1.220916061583921e-07\n",
      "Epoch 3055, Loss: 0.00012324089403747962, Final Batch Loss: 1.5141226583637035e-07\n",
      "Epoch 3056, Loss: 4.256738522434578e-05, Final Batch Loss: 5.239429512471361e-08\n",
      "Epoch 3057, Loss: 7.067014149431117e-06, Final Batch Loss: 8.03194325271761e-07\n",
      "Epoch 3058, Loss: 7.282993754387235e-05, Final Batch Loss: 5.2394071303751844e-08\n",
      "Epoch 3059, Loss: 0.0006654505636387587, Final Batch Loss: 0.0\n",
      "Epoch 3060, Loss: 0.0002415602204045575, Final Batch Loss: 0.0\n",
      "Epoch 3061, Loss: 1.287832843033243e-05, Final Batch Loss: 1.8505886600905797e-07\n",
      "Epoch 3062, Loss: 5.508753111604925e-05, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 3063, Loss: 0.0020999694110273026, Final Batch Loss: 1.2593787346304453e-07\n",
      "Epoch 3064, Loss: 0.00024745702552264603, Final Batch Loss: 1.2305321206440567e-07\n",
      "Epoch 3065, Loss: 8.473247203166778e-05, Final Batch Loss: 1.7304552457630962e-08\n",
      "Epoch 3066, Loss: 3.631798496228633e-05, Final Batch Loss: 1.768888324704676e-07\n",
      "Epoch 3067, Loss: 2.0979216982297544e-05, Final Batch Loss: 5.3355591944637126e-08\n",
      "Epoch 3068, Loss: 8.011623498993536e-05, Final Batch Loss: 0.0\n",
      "Epoch 3069, Loss: 1.1990506967096692e-05, Final Batch Loss: 2.7398876056849986e-08\n",
      "Epoch 3070, Loss: 1.3223764153580397e-05, Final Batch Loss: 1.7785241723800027e-08\n",
      "Epoch 3071, Loss: 3.856329066009856e-05, Final Batch Loss: 9.613648543904674e-09\n",
      "Epoch 3072, Loss: 6.254164645902449e-05, Final Batch Loss: 6.248868977820621e-09\n",
      "Epoch 3073, Loss: 8.837304314446293e-06, Final Batch Loss: 2.6484798354431405e-07\n",
      "Epoch 3074, Loss: 8.39349789227839e-06, Final Batch Loss: 4.5547822082880884e-06\n",
      "Epoch 3075, Loss: 6.896154597235693e-05, Final Batch Loss: 2.5235135581169743e-07\n",
      "Epoch 3076, Loss: 0.00013278991666165751, Final Batch Loss: 3.422375414174894e-07\n",
      "Epoch 3077, Loss: 1.7060475445362933e-05, Final Batch Loss: 1.0526816396350114e-07\n",
      "Epoch 3078, Loss: 5.835598350678595e-05, Final Batch Loss: 2.586002949556132e-07\n",
      "Epoch 3079, Loss: 1.1546724336564118e-05, Final Batch Loss: 5.777407068308094e-07\n",
      "Epoch 3080, Loss: 0.00021060236105374663, Final Batch Loss: 4.114441765068477e-07\n",
      "Epoch 3081, Loss: 9.24566579330044e-06, Final Batch Loss: 2.0669327582822916e-08\n",
      "Epoch 3082, Loss: 7.386841047785087e-05, Final Batch Loss: 6.911864147696178e-07\n",
      "Epoch 3083, Loss: 4.482349689893805e-05, Final Batch Loss: 3.950552854803391e-05\n",
      "Epoch 3084, Loss: 3.308254581235737e-05, Final Batch Loss: 9.151515314442804e-07\n",
      "Epoch 3085, Loss: 8.738904263827507e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3086, Loss: 0.00031381156802823273, Final Batch Loss: 9.613645879369415e-09\n",
      "Epoch 3087, Loss: 4.815705954552829e-05, Final Batch Loss: 1.2305338259466225e-07\n",
      "Epoch 3088, Loss: 6.832121895228305e-05, Final Batch Loss: 3.124433334278365e-08\n",
      "Epoch 3089, Loss: 1.6672962955710524e-05, Final Batch Loss: 1.4022794857737608e-05\n",
      "Epoch 3090, Loss: 6.389433921172305e-06, Final Batch Loss: 0.0\n",
      "Epoch 3091, Loss: 9.70009331213717e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3092, Loss: 1.0189473155008955e-05, Final Batch Loss: 1.8314696035304223e-06\n",
      "Epoch 3093, Loss: 6.328044891423801e-06, Final Batch Loss: 7.123177283574478e-07\n",
      "Epoch 3094, Loss: 3.019988832342335e-06, Final Batch Loss: 4.869035024057666e-07\n",
      "Epoch 3095, Loss: 0.00013171182859061936, Final Batch Loss: 3.41284085436655e-08\n",
      "Epoch 3096, Loss: 9.196656317678187e-05, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 3097, Loss: 5.90718007491553e-05, Final Batch Loss: 1.0046159104604158e-07\n",
      "Epoch 3098, Loss: 3.62313844104456e-06, Final Batch Loss: 1.6287050357277622e-06\n",
      "Epoch 3099, Loss: 5.7759435305504425e-05, Final Batch Loss: 1.7495310657977825e-06\n",
      "Epoch 3100, Loss: 2.5562026687575568e-06, Final Batch Loss: 1.249762249244668e-07\n",
      "Epoch 3101, Loss: 3.083373763290709e-05, Final Batch Loss: 1.8968113408845966e-06\n",
      "Epoch 3102, Loss: 6.43985616921583e-06, Final Batch Loss: 9.132959277735608e-09\n",
      "Epoch 3103, Loss: 5.669468028490776e-06, Final Batch Loss: 2.6328061721869744e-06\n",
      "Epoch 3104, Loss: 1.0502912148213639e-05, Final Batch Loss: 1.0094331592824801e-08\n",
      "Epoch 3105, Loss: 1.5612147159949075e-05, Final Batch Loss: 1.3603209936263738e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3106, Loss: 3.34180714711696e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3107, Loss: 1.04096330703074e-05, Final Batch Loss: 1.5381834472805167e-08\n",
      "Epoch 3108, Loss: 5.653248075532247e-05, Final Batch Loss: 1.792907085018669e-07\n",
      "Epoch 3109, Loss: 0.006537007455709509, Final Batch Loss: 7.262723897838441e-07\n",
      "Epoch 3110, Loss: 0.00019307813424596088, Final Batch Loss: 0.0001826969237299636\n",
      "Epoch 3111, Loss: 2.2581725036108224e-05, Final Batch Loss: 1.5381832696448328e-08\n",
      "Epoch 3112, Loss: 6.694257737027698e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3113, Loss: 0.0033922118899420983, Final Batch Loss: 0.0002895621000789106\n",
      "Epoch 3114, Loss: 9.902691896712668e-06, Final Batch Loss: 1.3891539651922358e-07\n",
      "Epoch 3115, Loss: 0.00046606304199059423, Final Batch Loss: 2.6903919660981046e-06\n",
      "Epoch 3116, Loss: 5.0016778207595536e-05, Final Batch Loss: 6.532491624966497e-06\n",
      "Epoch 3117, Loss: 5.081041115051477e-05, Final Batch Loss: 7.690914571867324e-09\n",
      "Epoch 3118, Loss: 2.1446541748737502e-05, Final Batch Loss: 8.171595844430612e-09\n",
      "Epoch 3119, Loss: 2.397326120506804e-05, Final Batch Loss: 5.768187261168123e-09\n",
      "Epoch 3120, Loss: 3.9157780779341955e-05, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 3121, Loss: 0.00014655045906630804, Final Batch Loss: 4.4460728076956e-07\n",
      "Epoch 3122, Loss: 7.45955766980888e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 3123, Loss: 2.701415306527455e-05, Final Batch Loss: 4.8068251601307566e-09\n",
      "Epoch 3124, Loss: 4.24467230781822e-05, Final Batch Loss: 1.521234253232251e-06\n",
      "Epoch 3125, Loss: 3.8174953997049954e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3126, Loss: 9.139752650710875e-06, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 3127, Loss: 0.015446032048900715, Final Batch Loss: 1.7883658074424602e-06\n",
      "Epoch 3128, Loss: 0.002860592913691562, Final Batch Loss: 0.00012371959746815264\n",
      "Epoch 3129, Loss: 1.7751676066657396e-05, Final Batch Loss: 1.0767183056259455e-07\n",
      "Epoch 3130, Loss: 1.1385731773394525e-05, Final Batch Loss: 1.8265925660898574e-08\n",
      "Epoch 3131, Loss: 0.00011095003316019536, Final Batch Loss: 8.598327440267894e-06\n",
      "Epoch 3132, Loss: 6.926172500820726e-05, Final Batch Loss: 6.969415835555992e-07\n",
      "Epoch 3133, Loss: 6.329181927888783e-06, Final Batch Loss: 1.586249886997848e-08\n",
      "Epoch 3134, Loss: 2.12170016382629e-05, Final Batch Loss: 2.5956786942060717e-08\n",
      "Epoch 3135, Loss: 8.041909070888309e-06, Final Batch Loss: 1.0671017491858947e-07\n",
      "Epoch 3136, Loss: 8.117402255880535e-05, Final Batch Loss: 1.6571177638979862e-06\n",
      "Epoch 3137, Loss: 1.4175298236995815e-05, Final Batch Loss: 4.364167580206413e-06\n",
      "Epoch 3138, Loss: 6.82285077743261e-05, Final Batch Loss: 2.5476138532098958e-08\n",
      "Epoch 3139, Loss: 0.0004202730869813376, Final Batch Loss: 3.7973830302462375e-08\n",
      "Epoch 3140, Loss: 1.4823625241633387e-05, Final Batch Loss: 2.7782638767348544e-07\n",
      "Epoch 3141, Loss: 2.3034394435850203e-05, Final Batch Loss: 4.1338584111372256e-08\n",
      "Epoch 3142, Loss: 1.2544364779265571e-05, Final Batch Loss: 1.0238444048127349e-07\n",
      "Epoch 3143, Loss: 0.0002580033990962072, Final Batch Loss: 3.316699448419058e-08\n",
      "Epoch 3144, Loss: 7.249091387429019e-05, Final Batch Loss: 6.585322154251116e-08\n",
      "Epoch 3145, Loss: 9.358334253661837e-05, Final Batch Loss: 6.743713356627268e-07\n",
      "Epoch 3146, Loss: 4.457466927565434e-06, Final Batch Loss: 9.362906325804943e-07\n",
      "Epoch 3147, Loss: 2.6597100069025714e-06, Final Batch Loss: 1.1472272944956785e-06\n",
      "Epoch 3148, Loss: 1.5727015066802075e-05, Final Batch Loss: 1.3939776444260588e-08\n",
      "Epoch 3149, Loss: 6.72162351089689e-06, Final Batch Loss: 4.013571697214502e-07\n",
      "Epoch 3150, Loss: 5.301509915178748e-06, Final Batch Loss: 6.729553359008378e-09\n",
      "Epoch 3151, Loss: 0.00042114688011096746, Final Batch Loss: 6.24887208644509e-09\n",
      "Epoch 3152, Loss: 9.240067937676955e-06, Final Batch Loss: 2.850352700534131e-07\n",
      "Epoch 3153, Loss: 5.275451516073559e-06, Final Batch Loss: 2.1150002638137266e-08\n",
      "Epoch 3154, Loss: 3.0218201302334435e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3155, Loss: 0.0004097340260140747, Final Batch Loss: 9.180957505350307e-08\n",
      "Epoch 3156, Loss: 1.308400365052087e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3157, Loss: 3.023390124479164e-06, Final Batch Loss: 6.512726713481243e-07\n",
      "Epoch 3158, Loss: 1.4564914392778405e-05, Final Batch Loss: 1.1392022258860379e-07\n",
      "Epoch 3159, Loss: 0.0001728754626670881, Final Batch Loss: 5.768151467577809e-08\n",
      "Epoch 3160, Loss: 1.81937426946277e-05, Final Batch Loss: 3.845460394558131e-09\n",
      "Epoch 3161, Loss: 1.6691649589839486e-05, Final Batch Loss: 2.9032432848907774e-06\n",
      "Epoch 3162, Loss: 0.00010125522349702099, Final Batch Loss: 2.163069900973369e-08\n",
      "Epoch 3163, Loss: 5.113560412217666e-06, Final Batch Loss: 1.9707945497771107e-08\n",
      "Epoch 3164, Loss: 2.204386349591303e-05, Final Batch Loss: 0.0\n",
      "Epoch 3165, Loss: 4.193308002831131e-06, Final Batch Loss: 1.538182559102097e-08\n",
      "Epoch 3166, Loss: 5.9837234939186246e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 3167, Loss: 3.060346950678472e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3168, Loss: 1.60627634226973e-05, Final Batch Loss: 5.960437121643736e-08\n",
      "Epoch 3169, Loss: 6.750858053794495e-06, Final Batch Loss: 1.343827648270235e-06\n",
      "Epoch 3170, Loss: 5.6283928375755465e-06, Final Batch Loss: 1.6383148704335326e-06\n",
      "Epoch 3171, Loss: 9.170411159331593e-07, Final Batch Loss: 1.2017052242185855e-08\n",
      "Epoch 3172, Loss: 1.4303243151658762e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3173, Loss: 2.7743316184158928e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3174, Loss: 2.5377642819401913e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3175, Loss: 9.540208798508587e-07, Final Batch Loss: 1.0574904507620886e-07\n",
      "Epoch 3176, Loss: 1.2849356014088542e-05, Final Batch Loss: 3.605115139748705e-08\n",
      "Epoch 3177, Loss: 6.4677000498614134e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3178, Loss: 4.282695443724727e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 3179, Loss: 0.00014528202853414385, Final Batch Loss: 1.24977406201765e-08\n",
      "Epoch 3180, Loss: 1.2084176275628522e-05, Final Batch Loss: 1.5045119994283596e-07\n",
      "Epoch 3181, Loss: 2.5435751680458196e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3182, Loss: 2.0501560636265737e-05, Final Batch Loss: 1.7304538246776247e-08\n",
      "Epoch 3183, Loss: 1.1327591832088757e-05, Final Batch Loss: 3.07145285205479e-07\n",
      "Epoch 3184, Loss: 4.329131196212366e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3185, Loss: 6.7443572170367005e-06, Final Batch Loss: 3.941588033740118e-08\n",
      "Epoch 3186, Loss: 2.34835935029043e-05, Final Batch Loss: 4.513677595241461e-06\n",
      "Epoch 3187, Loss: 3.870248173720725e-06, Final Batch Loss: 0.0\n",
      "Epoch 3188, Loss: 5.597085986353001e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3189, Loss: 1.1261901143644337e-05, Final Batch Loss: 9.90194024552693e-08\n",
      "Epoch 3190, Loss: 9.031159762251662e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3191, Loss: 1.4222050342183046e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3192, Loss: 8.046943057227196e-06, Final Batch Loss: 6.935663350304822e-07\n",
      "Epoch 3193, Loss: 1.2149697552921168e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3194, Loss: 6.072915396782008e-06, Final Batch Loss: 2.3024263384741062e-07\n",
      "Epoch 3195, Loss: 1.5971968011507798e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3196, Loss: 0.00015805948267799685, Final Batch Loss: 2.140985316145816e-06\n",
      "Epoch 3197, Loss: 4.215995826895025e-07, Final Batch Loss: 1.0094326263754283e-08\n",
      "Epoch 3198, Loss: 2.2796330015339983e-05, Final Batch Loss: 3.220566924255763e-08\n",
      "Epoch 3199, Loss: 2.4511254035353147e-06, Final Batch Loss: 4.1336645040246367e-07\n",
      "Epoch 3200, Loss: 2.6624877327297014e-06, Final Batch Loss: 2.8360174653130343e-08\n",
      "Epoch 3201, Loss: 6.281214923187228e-06, Final Batch Loss: 4.037713807747423e-08\n",
      "Epoch 3202, Loss: 1.3207747830312755e-05, Final Batch Loss: 4.614526716295586e-08\n",
      "Epoch 3203, Loss: 4.662714151004721e-06, Final Batch Loss: 2.56678333698801e-07\n",
      "Epoch 3204, Loss: 3.7718200882608244e-06, Final Batch Loss: 6.24887031008825e-09\n",
      "Epoch 3205, Loss: 0.00018429891957894018, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3206, Loss: 1.5401537916126529e-06, Final Batch Loss: 2.0669309819254522e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3207, Loss: 6.271586233475013e-05, Final Batch Loss: 5.8642964262389796e-08\n",
      "Epoch 3208, Loss: 2.870455536241323e-05, Final Batch Loss: 3.5761226513386646e-07\n",
      "Epoch 3209, Loss: 2.3931745894989476e-06, Final Batch Loss: 1.5141219478209678e-07\n",
      "Epoch 3210, Loss: 4.295640516849275e-06, Final Batch Loss: 9.613645879369415e-09\n",
      "Epoch 3211, Loss: 4.090239971943355e-06, Final Batch Loss: 3.5199498142901575e-06\n",
      "Epoch 3212, Loss: 9.508702547567083e-07, Final Batch Loss: 1.326663578993248e-07\n",
      "Epoch 3213, Loss: 2.5719973696824994e-05, Final Batch Loss: 5.6720413255106905e-08\n",
      "Epoch 3214, Loss: 5.920132539338763e-05, Final Batch Loss: 3.316700158961794e-08\n",
      "Epoch 3215, Loss: 1.2022334181183147e-05, Final Batch Loss: 8.062662345764693e-06\n",
      "Epoch 3216, Loss: 7.786312520297045e-07, Final Batch Loss: 0.0\n",
      "Epoch 3217, Loss: 1.1899125404335464e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3218, Loss: 1.1121163612348717e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3219, Loss: 7.727126751433389e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3220, Loss: 0.0006181538814122867, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3221, Loss: 2.0202676292102595e-05, Final Batch Loss: 2.6851259917748393e-06\n",
      "Epoch 3222, Loss: 0.0012209605086972442, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3223, Loss: 0.005918117397172962, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3224, Loss: 0.010989967683673552, Final Batch Loss: 5.740073447668692e-06\n",
      "Epoch 3225, Loss: 1.1490883366382931e-05, Final Batch Loss: 5.43168461319965e-08\n",
      "Epoch 3226, Loss: 0.027805441228169858, Final Batch Loss: 6.633370475128686e-08\n",
      "Epoch 3227, Loss: 0.04172654946967147, Final Batch Loss: 4.8068137914469844e-08\n",
      "Epoch 3228, Loss: 0.00021467715121126218, Final Batch Loss: 3.1244308473787896e-08\n",
      "Epoch 3229, Loss: 3.92635129187191e-05, Final Batch Loss: 6.815648134761432e-07\n",
      "Epoch 3230, Loss: 0.0028860168362623284, Final Batch Loss: 3.7012444664696886e-08\n",
      "Epoch 3231, Loss: 0.0001779330195184059, Final Batch Loss: 3.39829881568221e-07\n",
      "Epoch 3232, Loss: 5.606540823510642e-05, Final Batch Loss: 1.989987623574052e-07\n",
      "Epoch 3233, Loss: 0.0001211792564790315, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 3234, Loss: 0.000576156845852438, Final Batch Loss: 9.084838126227623e-08\n",
      "Epoch 3235, Loss: 9.800879928467676e-05, Final Batch Loss: 4.1819170348844636e-08\n",
      "Epoch 3236, Loss: 0.01558496975071666, Final Batch Loss: 5.01331396662863e-06\n",
      "Epoch 3237, Loss: 0.0001015106119368614, Final Batch Loss: 3.845460394558131e-09\n",
      "Epoch 3238, Loss: 0.00015502936589228966, Final Batch Loss: 0.00010333608224755153\n",
      "Epoch 3239, Loss: 3.329857472422759e-05, Final Batch Loss: 2.329468316020211e-06\n",
      "Epoch 3240, Loss: 0.0008196975867447165, Final Batch Loss: 1.7219498431586544e-06\n",
      "Epoch 3241, Loss: 0.0002986398237649901, Final Batch Loss: 1.931882979988586e-05\n",
      "Epoch 3242, Loss: 0.00029445896551616446, Final Batch Loss: 3.1340514397015795e-06\n",
      "Epoch 3243, Loss: 4.4792177341435035e-05, Final Batch Loss: 1.0382657933405426e-07\n",
      "Epoch 3244, Loss: 1.3729776609849864e-05, Final Batch Loss: 8.17160117350113e-09\n",
      "Epoch 3245, Loss: 0.0001173155297458095, Final Batch Loss: 6.248838246847299e-08\n",
      "Epoch 3246, Loss: 1.6150950358451155e-05, Final Batch Loss: 5.287497373274164e-08\n",
      "Epoch 3247, Loss: 0.00013054090629860404, Final Batch Loss: 1.3459102277124657e-08\n",
      "Epoch 3248, Loss: 2.5024055686273527e-05, Final Batch Loss: 3.4608035548444605e-07\n",
      "Epoch 3249, Loss: 2.062946461534043e-05, Final Batch Loss: 2.4622661385365063e-06\n",
      "Epoch 3250, Loss: 1.5025874239960046e-05, Final Batch Loss: 3.6939284200343536e-06\n",
      "Epoch 3251, Loss: 4.811721072917052e-06, Final Batch Loss: 2.8359292514323897e-07\n",
      "Epoch 3252, Loss: 2.7899212507342952e-05, Final Batch Loss: 1.0016235592047451e-06\n",
      "Epoch 3253, Loss: 3.6216284973633606e-05, Final Batch Loss: 2.0861095606505842e-07\n",
      "Epoch 3254, Loss: 1.384468342191525e-05, Final Batch Loss: 3.364766953950493e-08\n",
      "Epoch 3255, Loss: 1.3440061519709445e-05, Final Batch Loss: 8.344304092133825e-07\n",
      "Epoch 3256, Loss: 7.241366843291352e-05, Final Batch Loss: 3.4944181948048936e-07\n",
      "Epoch 3257, Loss: 1.4427365091052025e-05, Final Batch Loss: 2.8167423238301126e-07\n",
      "Epoch 3258, Loss: 2.8679941332487857e-05, Final Batch Loss: 2.3072747268315652e-08\n",
      "Epoch 3259, Loss: 0.0002077912079505584, Final Batch Loss: 1.3459105829838336e-08\n",
      "Epoch 3260, Loss: 3.5865043305882693e-05, Final Batch Loss: 1.5019688362372108e-05\n",
      "Epoch 3261, Loss: 2.5516776659628704e-05, Final Batch Loss: 1.6123945897561498e-05\n",
      "Epoch 3262, Loss: 6.342886238464018e-06, Final Batch Loss: 4.422274102466872e-08\n",
      "Epoch 3263, Loss: 2.407181639796363e-05, Final Batch Loss: 1.1229009942326229e-05\n",
      "Epoch 3264, Loss: 7.100482995336943e-05, Final Batch Loss: 9.229003694599669e-08\n",
      "Epoch 3265, Loss: 0.0011449371068692482, Final Batch Loss: 3.5206403481424786e-06\n",
      "Epoch 3266, Loss: 4.302416783730223e-05, Final Batch Loss: 0.0\n",
      "Epoch 3267, Loss: 0.00010627746530156301, Final Batch Loss: 1.4625724134020857e-06\n",
      "Epoch 3268, Loss: 9.306990213531208e-05, Final Batch Loss: 3.50897089163027e-08\n",
      "Epoch 3269, Loss: 0.00021620981594683286, Final Batch Loss: 6.383169193213689e-07\n",
      "Epoch 3270, Loss: 4.3432984607960634e-05, Final Batch Loss: 4.547047183223185e-07\n",
      "Epoch 3271, Loss: 0.001565323222989079, Final Batch Loss: 6.880894034111407e-06\n",
      "Epoch 3272, Loss: 6.0748095554341575e-05, Final Batch Loss: 8.988708088963904e-08\n",
      "Epoch 3273, Loss: 3.4375476714032516e-05, Final Batch Loss: 5.0952042585095114e-08\n",
      "Epoch 3274, Loss: 6.456630608830949e-05, Final Batch Loss: 5.683109520759899e-06\n",
      "Epoch 3275, Loss: 0.0002584136811334403, Final Batch Loss: 1.7108679912780644e-06\n",
      "Epoch 3276, Loss: 0.0009502849552269765, Final Batch Loss: 2.4704761017346755e-05\n",
      "Epoch 3277, Loss: 5.255180922558722e-05, Final Batch Loss: 1.338971514996956e-06\n",
      "Epoch 3278, Loss: 9.610195362674823e-05, Final Batch Loss: 3.9991866174204915e-07\n",
      "Epoch 3279, Loss: 0.000301211101255916, Final Batch Loss: 1.5814224241239572e-07\n",
      "Epoch 3280, Loss: 1.141638343771234e-05, Final Batch Loss: 1.3170583201826958e-07\n",
      "Epoch 3281, Loss: 5.6871784863687935e-06, Final Batch Loss: 2.9128332812433655e-07\n",
      "Epoch 3282, Loss: 3.149969775106953e-05, Final Batch Loss: 2.3553415218202645e-08\n",
      "Epoch 3283, Loss: 6.035235938961492e-05, Final Batch Loss: 9.132964606806127e-09\n",
      "Epoch 3284, Loss: 1.186328707314388e-05, Final Batch Loss: 6.969840882220524e-08\n",
      "Epoch 3285, Loss: 1.7679490284971955e-05, Final Batch Loss: 1.3987622082822782e-07\n",
      "Epoch 3286, Loss: 1.026522990865697e-05, Final Batch Loss: 1.219310092892556e-06\n",
      "Epoch 3287, Loss: 7.283620508324873e-05, Final Batch Loss: 2.0188659632935924e-08\n",
      "Epoch 3288, Loss: 4.5566465871615947e-05, Final Batch Loss: 1.831382547834437e-07\n",
      "Epoch 3289, Loss: 0.00020510161262221605, Final Batch Loss: 2.3553381467422696e-08\n",
      "Epoch 3290, Loss: 0.000915183530057373, Final Batch Loss: 0.0\n",
      "Epoch 3291, Loss: 1.3631210863840337e-05, Final Batch Loss: 2.682138813270285e-07\n",
      "Epoch 3292, Loss: 1.8842806939978196e-05, Final Batch Loss: 4.326141223032209e-09\n",
      "Epoch 3293, Loss: 1.1100569001998295e-05, Final Batch Loss: 2.9802249557064897e-08\n",
      "Epoch 3294, Loss: 5.334628481734605e-06, Final Batch Loss: 1.2798581110473606e-06\n",
      "Epoch 3295, Loss: 7.956390288066384e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3296, Loss: 7.2885002273537225e-06, Final Batch Loss: 1.182462057158773e-07\n",
      "Epoch 3297, Loss: 2.8750133942989642e-05, Final Batch Loss: 1.1055691473416118e-08\n",
      "Epoch 3298, Loss: 7.332792080849693e-05, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 3299, Loss: 0.00015234250727891308, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3300, Loss: 3.622023694038745e-05, Final Batch Loss: 2.0332610972673137e-07\n",
      "Epoch 3301, Loss: 2.9339622301893797e-05, Final Batch Loss: 4.253835186318611e-07\n",
      "Epoch 3302, Loss: 1.1461107292887185e-05, Final Batch Loss: 1.9967444586654892e-06\n",
      "Epoch 3303, Loss: 7.393520972120982e-06, Final Batch Loss: 5.720083962046374e-08\n",
      "Epoch 3304, Loss: 1.2179258915501201e-05, Final Batch Loss: 1.0911347914088765e-07\n",
      "Epoch 3305, Loss: 1.1334052314238008e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3306, Loss: 1.9285263700652422e-05, Final Batch Loss: 5.123750952407136e-07\n",
      "Epoch 3307, Loss: 2.022613047669708e-05, Final Batch Loss: 1.2978423669096628e-08\n",
      "Epoch 3308, Loss: 1.0767095175445718e-06, Final Batch Loss: 3.3647777897272135e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3309, Loss: 1.7966856693196753e-05, Final Batch Loss: 1.4545652447850443e-05\n",
      "Epoch 3310, Loss: 0.00040665953048923953, Final Batch Loss: 6.712852155033033e-06\n",
      "Epoch 3311, Loss: 8.733884230816003e-05, Final Batch Loss: 0.0\n",
      "Epoch 3312, Loss: 5.45439981336493e-06, Final Batch Loss: 1.538182381466413e-08\n",
      "Epoch 3313, Loss: 3.490592295651851e-06, Final Batch Loss: 1.0035424793386483e-06\n",
      "Epoch 3314, Loss: 4.513645213588546e-06, Final Batch Loss: 6.070603149055387e-07\n",
      "Epoch 3315, Loss: 1.9012105431315263e-05, Final Batch Loss: 0.0\n",
      "Epoch 3316, Loss: 1.1791761284296598e-05, Final Batch Loss: 2.165383648389252e-06\n",
      "Epoch 3317, Loss: 0.0006501947394814689, Final Batch Loss: 1.2017046913115337e-08\n",
      "Epoch 3318, Loss: 1.157257236672482e-05, Final Batch Loss: 5.287177486934524e-07\n",
      "Epoch 3319, Loss: 5.371587894931196e-06, Final Batch Loss: 2.9407804049697006e-06\n",
      "Epoch 3320, Loss: 3.181200006585616e-05, Final Batch Loss: 2.7830577664644807e-07\n",
      "Epoch 3321, Loss: 4.4403997772057835e-06, Final Batch Loss: 1.5028180087028886e-06\n",
      "Epoch 3322, Loss: 0.00017011491769691744, Final Batch Loss: 1.5274610632332042e-05\n",
      "Epoch 3323, Loss: 0.0011453128118328326, Final Batch Loss: 0.0010909123811870813\n",
      "Epoch 3324, Loss: 2.9370870626488355e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3325, Loss: 6.923260590085967e-05, Final Batch Loss: 6.171513859953848e-07\n",
      "Epoch 3326, Loss: 9.095041023643446e-06, Final Batch Loss: 7.450517358620345e-08\n",
      "Epoch 3327, Loss: 8.974962672203546e-05, Final Batch Loss: 1.2017046913115337e-08\n",
      "Epoch 3328, Loss: 0.0036938282897365227, Final Batch Loss: 0.003684493014588952\n",
      "Epoch 3329, Loss: 4.141396314394363e-05, Final Batch Loss: 1.363168212265009e-05\n",
      "Epoch 3330, Loss: 0.00043636361191268236, Final Batch Loss: 2.0542942365864292e-05\n",
      "Epoch 3331, Loss: 7.493292549920483e-05, Final Batch Loss: 4.450875792372244e-07\n",
      "Epoch 3332, Loss: 0.004174178813404428, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 3333, Loss: 0.00046753458875292697, Final Batch Loss: 1.0035988680101582e-06\n",
      "Epoch 3334, Loss: 3.509790801148327e-05, Final Batch Loss: 1.9950522982981056e-05\n",
      "Epoch 3335, Loss: 9.301677236606132e-05, Final Batch Loss: 2.5235399903067446e-07\n",
      "Epoch 3336, Loss: 7.17188057786089e-06, Final Batch Loss: 7.210236407928505e-09\n",
      "Epoch 3337, Loss: 6.95680920664854e-05, Final Batch Loss: 7.690916348224164e-09\n",
      "Epoch 3338, Loss: 1.1484187175003768e-05, Final Batch Loss: 1.0094331592824801e-08\n",
      "Epoch 3339, Loss: 1.6216058577600556e-05, Final Batch Loss: 0.0\n",
      "Epoch 3340, Loss: 0.0008346540695698401, Final Batch Loss: 3.941408124319423e-07\n",
      "Epoch 3341, Loss: 1.587379268208622e-05, Final Batch Loss: 6.8859731072734576e-06\n",
      "Epoch 3342, Loss: 1.775851603724732e-05, Final Batch Loss: 6.081303581595421e-06\n",
      "Epoch 3343, Loss: 6.611832157332742e-06, Final Batch Loss: 4.6626023930684823e-08\n",
      "Epoch 3344, Loss: 6.746510517796622e-06, Final Batch Loss: 5.816237091949006e-08\n",
      "Epoch 3345, Loss: 7.687060147110181e-05, Final Batch Loss: 3.3502240626148705e-07\n",
      "Epoch 3346, Loss: 3.349042900979704e-05, Final Batch Loss: 4.571138561004773e-07\n",
      "Epoch 3347, Loss: 7.815184287718324e-06, Final Batch Loss: 1.0767249136733881e-07\n",
      "Epoch 3348, Loss: 1.3349180366772906e-05, Final Batch Loss: 7.690919900937843e-09\n",
      "Epoch 3349, Loss: 9.46377376243035e-06, Final Batch Loss: 1.4901139877565583e-08\n",
      "Epoch 3350, Loss: 8.02316462233943e-06, Final Batch Loss: 1.8553940606125252e-07\n",
      "Epoch 3351, Loss: 5.122326473649963e-06, Final Batch Loss: 6.729508328362499e-08\n",
      "Epoch 3352, Loss: 5.727182514680962e-06, Final Batch Loss: 9.229064090732209e-08\n",
      "Epoch 3353, Loss: 3.250744388227922e-06, Final Batch Loss: 1.6487091158978728e-07\n",
      "Epoch 3354, Loss: 5.669277131969963e-06, Final Batch Loss: 3.508976220700788e-08\n",
      "Epoch 3355, Loss: 9.291368355546226e-05, Final Batch Loss: 5.234456921243691e-07\n",
      "Epoch 3356, Loss: 8.826653738502888e-05, Final Batch Loss: 7.690852044106578e-08\n",
      "Epoch 3357, Loss: 3.6373309850734614e-06, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 3358, Loss: 2.0944466189165567e-06, Final Batch Loss: 3.316696961519483e-08\n",
      "Epoch 3359, Loss: 3.289349454593804e-06, Final Batch Loss: 1.369933784189925e-07\n",
      "Epoch 3360, Loss: 1.0711893834169928e-06, Final Batch Loss: 3.0763640523900904e-08\n",
      "Epoch 3361, Loss: 4.536640153984806e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3362, Loss: 7.0681423414153954e-06, Final Batch Loss: 1.4901141653922423e-08\n",
      "Epoch 3363, Loss: 0.0003999952047273325, Final Batch Loss: 1.7881009739539877e-07\n",
      "Epoch 3364, Loss: 9.02743762210001e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3365, Loss: 1.6688452992852376e-06, Final Batch Loss: 6.24887208644509e-09\n",
      "Epoch 3366, Loss: 8.46011210394737e-05, Final Batch Loss: 2.398540459580545e-07\n",
      "Epoch 3367, Loss: 1.4690967292674273e-06, Final Batch Loss: 1.211312934401576e-07\n",
      "Epoch 3368, Loss: 5.953326332686082e-06, Final Batch Loss: 5.383616397125479e-08\n",
      "Epoch 3369, Loss: 3.237806105471641e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3370, Loss: 5.328267580539947e-05, Final Batch Loss: 0.0\n",
      "Epoch 3371, Loss: 2.2895167014480577e-06, Final Batch Loss: 0.0\n",
      "Epoch 3372, Loss: 2.027975327789644e-05, Final Batch Loss: 9.132959277735608e-09\n",
      "Epoch 3373, Loss: 0.0005485437848938846, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3374, Loss: 6.989963445724889e-06, Final Batch Loss: 5.154914106242359e-06\n",
      "Epoch 3375, Loss: 3.313632871315697e-06, Final Batch Loss: 2.744605751558993e-07\n",
      "Epoch 3376, Loss: 0.0002773825532724761, Final Batch Loss: 7.210233743393246e-09\n",
      "Epoch 3377, Loss: 3.5219186471868724e-05, Final Batch Loss: 3.3452135539846495e-05\n",
      "Epoch 3378, Loss: 1.193942851140939e-06, Final Batch Loss: 1.768888324704676e-07\n",
      "Epoch 3379, Loss: 4.74911654602117e-06, Final Batch Loss: 8.65227800517232e-09\n",
      "Epoch 3380, Loss: 1.0073256007991915e-05, Final Batch Loss: 2.41776490383927e-07\n",
      "Epoch 3381, Loss: 8.157163451372185e-07, Final Batch Loss: 2.2158920387482794e-07\n",
      "Epoch 3382, Loss: 3.889932643108551e-06, Final Batch Loss: 2.93215904889621e-08\n",
      "Epoch 3383, Loss: 9.05122319898588e-05, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 3384, Loss: 2.9243911078280505e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3385, Loss: 2.5349734830149018e-06, Final Batch Loss: 2.5956786942060717e-08\n",
      "Epoch 3386, Loss: 1.7908757794504737e-06, Final Batch Loss: 0.0\n",
      "Epoch 3387, Loss: 3.4911017205985218e-06, Final Batch Loss: 1.7785218631161115e-08\n",
      "Epoch 3388, Loss: 6.792133310784543e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3389, Loss: 4.077963873760915e-05, Final Batch Loss: 0.0\n",
      "Epoch 3390, Loss: 1.690289502365161e-06, Final Batch Loss: 6.921771955603617e-08\n",
      "Epoch 3391, Loss: 6.860495450067283e-06, Final Batch Loss: 1.36589778776397e-06\n",
      "Epoch 3392, Loss: 3.832360571887072e-06, Final Batch Loss: 8.752281814849994e-07\n",
      "Epoch 3393, Loss: 6.162808685472587e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3394, Loss: 1.056204389393578e-06, Final Batch Loss: 1.2930254911225347e-07\n",
      "Epoch 3395, Loss: 1.8378365105764516e-05, Final Batch Loss: 6.729552470829958e-09\n",
      "Epoch 3396, Loss: 1.5244741943254425e-06, Final Batch Loss: 1.538182559102097e-08\n",
      "Epoch 3397, Loss: 1.118328959570647e-05, Final Batch Loss: 4.8068251601307566e-09\n",
      "Epoch 3398, Loss: 1.2515967175663611e-05, Final Batch Loss: 0.0\n",
      "Epoch 3399, Loss: 1.8382020773977104e-05, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 3400, Loss: 0.0002095630493068601, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3401, Loss: 2.673844697653749e-06, Final Batch Loss: 5.768187705257333e-09\n",
      "Epoch 3402, Loss: 2.0502031606861593e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3403, Loss: 2.0708494030685642e-07, Final Batch Loss: 7.690870518217707e-08\n",
      "Epoch 3404, Loss: 2.6653473180759946e-06, Final Batch Loss: 0.0\n",
      "Epoch 3405, Loss: 1.6530549875604095e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 3406, Loss: 1.8175179563595378e-06, Final Batch Loss: 0.0\n",
      "Epoch 3407, Loss: 1.8698856633747596e-05, Final Batch Loss: 6.297321306192316e-06\n",
      "Epoch 3408, Loss: 2.625932477373638e-05, Final Batch Loss: 1.5381816709236773e-08\n",
      "Epoch 3409, Loss: 2.7682595008515776e-06, Final Batch Loss: 0.0\n",
      "Epoch 3410, Loss: 8.790126002633514e-07, Final Batch Loss: 2.6580872258819e-07\n",
      "Epoch 3411, Loss: 1.2761436861685738e-06, Final Batch Loss: 2.028431111966711e-07\n",
      "Epoch 3412, Loss: 5.414069695675039e-06, Final Batch Loss: 2.3666684683121275e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3413, Loss: 1.0846643041517723e-06, Final Batch Loss: 4.6626073668676327e-08\n",
      "Epoch 3414, Loss: 4.784258875956127e-06, Final Batch Loss: 1.1632356944346611e-07\n",
      "Epoch 3415, Loss: 1.530087849643813e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3416, Loss: 4.270230430702959e-06, Final Batch Loss: 8.324563509631844e-07\n",
      "Epoch 3417, Loss: 2.679339018540894e-06, Final Batch Loss: 3.31670086950453e-08\n",
      "Epoch 3418, Loss: 2.9296843223614033e-06, Final Batch Loss: 4.354757265900844e-07\n",
      "Epoch 3419, Loss: 4.984488541692755e-06, Final Batch Loss: 0.0\n",
      "Epoch 3420, Loss: 3.5622624696696192e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3421, Loss: 9.637844627929937e-07, Final Batch Loss: 1.4901135436673485e-08\n",
      "Epoch 3422, Loss: 1.2080046604023842e-05, Final Batch Loss: 6.24887119826667e-09\n",
      "Epoch 3423, Loss: 3.090128217531074e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3424, Loss: 3.8481498654263646e-07, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3425, Loss: 3.395210566026208e-07, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3426, Loss: 4.1140604399192426e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3427, Loss: 3.0013955536478676e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3428, Loss: 1.6587290936342924e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3429, Loss: 2.173747597811193e-06, Final Batch Loss: 0.0\n",
      "Epoch 3430, Loss: 0.0006832231792937016, Final Batch Loss: 2.68212460241557e-07\n",
      "Epoch 3431, Loss: 1.0795453018186407e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3432, Loss: 6.272563328302283e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3433, Loss: 6.499157144679302e-07, Final Batch Loss: 0.0\n",
      "Epoch 3434, Loss: 1.7505758429514628e-06, Final Batch Loss: 2.2592034909507674e-08\n",
      "Epoch 3435, Loss: 4.7493603794190875e-07, Final Batch Loss: 6.104649230564974e-08\n",
      "Epoch 3436, Loss: 2.6293917435582514e-06, Final Batch Loss: 5.806232934446598e-07\n",
      "Epoch 3437, Loss: 2.449927408942898e-06, Final Batch Loss: 1.3410846122496878e-07\n",
      "Epoch 3438, Loss: 6.934063457086914e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3439, Loss: 4.898038433320817e-05, Final Batch Loss: 2.4995431502361498e-08\n",
      "Epoch 3440, Loss: 4.104652424952171e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3441, Loss: 1.0938538438809431e-05, Final Batch Loss: 5.527818913719784e-08\n",
      "Epoch 3442, Loss: 9.317163888300506e-06, Final Batch Loss: 9.132961942270867e-09\n",
      "Epoch 3443, Loss: 1.157348699321048e-06, Final Batch Loss: 1.538182203830729e-08\n",
      "Epoch 3444, Loss: 4.8016415332141626e-05, Final Batch Loss: 0.0\n",
      "Epoch 3445, Loss: 4.780203517240622e-06, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 3446, Loss: 1.9418760975886684e-06, Final Batch Loss: 1.3029410865783575e-06\n",
      "Epoch 3447, Loss: 2.450903477169142e-06, Final Batch Loss: 0.0\n",
      "Epoch 3448, Loss: 4.36180493301741e-06, Final Batch Loss: 6.969838040049581e-08\n",
      "Epoch 3449, Loss: 1.6355491456732096e-06, Final Batch Loss: 1.2978409458241913e-08\n",
      "Epoch 3450, Loss: 0.00015023501038269327, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3451, Loss: 8.672305936596736e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3452, Loss: 0.00022338289702017455, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3453, Loss: 4.581016377680491e-06, Final Batch Loss: 6.363911211337836e-07\n",
      "Epoch 3454, Loss: 6.296304878250503e-06, Final Batch Loss: 1.4773478369534132e-06\n",
      "Epoch 3455, Loss: 4.804464330820934e-07, Final Batch Loss: 3.460903386098835e-08\n",
      "Epoch 3456, Loss: 1.4829986016984265e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3457, Loss: 0.00017175188037976685, Final Batch Loss: 0.0\n",
      "Epoch 3458, Loss: 2.1216180838834475e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3459, Loss: 1.0283727329918335e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3460, Loss: 8.916383790191773e-07, Final Batch Loss: 0.0\n",
      "Epoch 3461, Loss: 6.143005510272914e-06, Final Batch Loss: 4.806823827863127e-09\n",
      "Epoch 3462, Loss: 6.881010721548897e-06, Final Batch Loss: 5.5278125188351623e-08\n",
      "Epoch 3463, Loss: 2.363367086255508e-06, Final Batch Loss: 3.537726911417849e-07\n",
      "Epoch 3464, Loss: 1.7971303072350509e-06, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 3465, Loss: 1.4007823831097e-05, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 3466, Loss: 2.2020045332693527e-06, Final Batch Loss: 2.1630659929883223e-08\n",
      "Epoch 3467, Loss: 3.304279596938464e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3468, Loss: 3.414376303634281e-05, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3469, Loss: 4.315257746367873e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3470, Loss: 1.7991525509852835e-05, Final Batch Loss: 1.847803787313751e-06\n",
      "Epoch 3471, Loss: 5.511959213500006e-07, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3472, Loss: 0.00039612375519382237, Final Batch Loss: 6.277265924836684e-07\n",
      "Epoch 3473, Loss: 1.1910097487133342e-06, Final Batch Loss: 0.0\n",
      "Epoch 3474, Loss: 2.6386183751281322e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 3475, Loss: 8.069924246079108e-05, Final Batch Loss: 7.531913865932438e-07\n",
      "Epoch 3476, Loss: 3.825152442793467e-06, Final Batch Loss: 7.11403984610115e-08\n",
      "Epoch 3477, Loss: 4.2614699841903025e-05, Final Batch Loss: 0.0\n",
      "Epoch 3478, Loss: 1.1206410666098066e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3479, Loss: 1.2016220574118108e-07, Final Batch Loss: 0.0\n",
      "Epoch 3480, Loss: 1.6214703646433293e-07, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 3481, Loss: 6.062430409015107e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3482, Loss: 1.6422500394019934e-06, Final Batch Loss: 8.315725352758818e-08\n",
      "Epoch 3483, Loss: 2.3166795671825113e-06, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 3484, Loss: 0.00034430502136351127, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 3485, Loss: 5.251491743463177e-06, Final Batch Loss: 1.826591145004386e-08\n",
      "Epoch 3486, Loss: 3.417462602905985e-06, Final Batch Loss: 2.6437460221018227e-08\n",
      "Epoch 3487, Loss: 5.173640376110455e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3488, Loss: 2.6896036722345862e-05, Final Batch Loss: 0.0\n",
      "Epoch 3489, Loss: 1.2591783541404666e-06, Final Batch Loss: 0.0\n",
      "Epoch 3490, Loss: 2.5146922044694264e-07, Final Batch Loss: 2.259205089671923e-08\n",
      "Epoch 3491, Loss: 6.923871566644202e-06, Final Batch Loss: 1.4708621165482327e-07\n",
      "Epoch 3492, Loss: 3.0109036062042627e-05, Final Batch Loss: 1.36511587811583e-07\n",
      "Epoch 3493, Loss: 0.00014852739157433792, Final Batch Loss: 6.344985337136677e-08\n",
      "Epoch 3494, Loss: 4.4202222515554723e-07, Final Batch Loss: 0.0\n",
      "Epoch 3495, Loss: 2.527206052205244e-07, Final Batch Loss: 0.0\n",
      "Epoch 3496, Loss: 8.859317263132382e-07, Final Batch Loss: 6.152714604468201e-08\n",
      "Epoch 3497, Loss: 1.161639835656203e-06, Final Batch Loss: 8.363790726662046e-08\n",
      "Epoch 3498, Loss: 4.740726636898174e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3499, Loss: 8.768708538164915e-07, Final Batch Loss: 0.0\n",
      "Epoch 3500, Loss: 2.2382427150358097e-05, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 3501, Loss: 3.6636713175441926e-06, Final Batch Loss: 5.28747783334893e-08\n",
      "Epoch 3502, Loss: 5.531756344656635e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3503, Loss: 6.8063996025991e-06, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 3504, Loss: 3.1667722520056785e-05, Final Batch Loss: 1.9256353880336974e-06\n",
      "Epoch 3505, Loss: 6.484956616148452e-08, Final Batch Loss: 0.0\n",
      "Epoch 3506, Loss: 1.4913151645812306e-06, Final Batch Loss: 4.133854147880811e-08\n",
      "Epoch 3507, Loss: 0.00016807116469386152, Final Batch Loss: 0.0\n",
      "Epoch 3508, Loss: 2.2370252512615707e-06, Final Batch Loss: 0.0\n",
      "Epoch 3509, Loss: 1.2182766581103621e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3510, Loss: 1.4162553254926102e-05, Final Batch Loss: 0.0\n",
      "Epoch 3511, Loss: 5.0834698879231865e-06, Final Batch Loss: 7.546692160076418e-08\n",
      "Epoch 3512, Loss: 1.0418418402435847e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3513, Loss: 1.459814818804972e-06, Final Batch Loss: 0.0\n",
      "Epoch 3514, Loss: 3.571473613517284e-07, Final Batch Loss: 0.0\n",
      "Epoch 3515, Loss: 2.50507119714527e-06, Final Batch Loss: 0.0\n",
      "Epoch 3516, Loss: 9.782475990482986e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3517, Loss: 2.184648115521881e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3518, Loss: 1.309789846803966e-05, Final Batch Loss: 0.0\n",
      "Epoch 3519, Loss: 1.2540668326010973e-07, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3520, Loss: 1.3432120467005149e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3521, Loss: 2.560584398958454e-07, Final Batch Loss: 0.0\n",
      "Epoch 3522, Loss: 3.187488904043967e-06, Final Batch Loss: 0.0\n",
      "Epoch 3523, Loss: 3.4987554979881708e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3524, Loss: 3.189241129619713e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3525, Loss: 2.1398491556468002e-07, Final Batch Loss: 1.6487079790294956e-07\n",
      "Epoch 3526, Loss: 1.8794051581672022e-07, Final Batch Loss: 8.65227889335074e-09\n",
      "Epoch 3527, Loss: 0.00012334667482061246, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 3528, Loss: 2.3845685981349618e-08, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3529, Loss: 1.964632136974842e-07, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3530, Loss: 3.311303657560494e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3531, Loss: 2.6405514712557476e-06, Final Batch Loss: 9.613641438477316e-09\n",
      "Epoch 3532, Loss: 1.6011140953064995e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3533, Loss: 2.0442497110639835e-06, Final Batch Loss: 3.412832327853721e-08\n",
      "Epoch 3534, Loss: 2.8696680901552085e-06, Final Batch Loss: 0.0\n",
      "Epoch 3535, Loss: 1.6266450697521861e-07, Final Batch Loss: 8.171595844430612e-09\n",
      "Epoch 3536, Loss: 2.1047087056524916e-06, Final Batch Loss: 0.0\n",
      "Epoch 3537, Loss: 1.7882938810886984e-06, Final Batch Loss: 1.2016887751542527e-07\n",
      "Epoch 3538, Loss: 7.865463624856517e-08, Final Batch Loss: 5.6720150354294674e-08\n",
      "Epoch 3539, Loss: 4.421423847045247e-07, Final Batch Loss: 7.498579179809894e-08\n",
      "Epoch 3540, Loss: 2.674003296498917e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3541, Loss: 6.567744045282708e-07, Final Batch Loss: 5.018034130443993e-07\n",
      "Epoch 3542, Loss: 9.502609805700502e-07, Final Batch Loss: 0.0\n",
      "Epoch 3543, Loss: 3.533078309914117e-07, Final Batch Loss: 1.759259902200938e-07\n",
      "Epoch 3544, Loss: 1.401933384936882e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3545, Loss: 6.468854820806946e-06, Final Batch Loss: 1.2257221726486023e-07\n",
      "Epoch 3546, Loss: 5.521662184149179e-07, Final Batch Loss: 0.0\n",
      "Epoch 3547, Loss: 1.2225105032737105e-06, Final Batch Loss: 0.0\n",
      "Epoch 3548, Loss: 1.8890460182774405e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3549, Loss: 4.665387293945056e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3550, Loss: 1.14479293822356e-08, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3551, Loss: 8.649467803212296e-06, Final Batch Loss: 0.0\n",
      "Epoch 3552, Loss: 2.7449037043325575e-07, Final Batch Loss: 3.9415798624986564e-08\n",
      "Epoch 3553, Loss: 4.2055982458766294e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3554, Loss: 2.8928337495459644e-06, Final Batch Loss: 7.373110975095187e-07\n",
      "Epoch 3555, Loss: 1.711825704520109e-07, Final Batch Loss: 0.0\n",
      "Epoch 3556, Loss: 3.863530073644483e-08, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3557, Loss: 2.3558105521903627e-07, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3558, Loss: 1.4250206615273875e-05, Final Batch Loss: 9.132961942270867e-09\n",
      "Epoch 3559, Loss: 9.364533960498633e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3560, Loss: 1.4013387054978566e-05, Final Batch Loss: 0.0\n",
      "Epoch 3561, Loss: 1.1038138080232685e-06, Final Batch Loss: 1.196882379872477e-07\n",
      "Epoch 3562, Loss: 6.677409520761124e-06, Final Batch Loss: 0.0\n",
      "Epoch 3563, Loss: 5.840842670634672e-07, Final Batch Loss: 0.0\n",
      "Epoch 3564, Loss: 2.378497644839328e-06, Final Batch Loss: 0.0\n",
      "Epoch 3565, Loss: 3.871776675934413e-07, Final Batch Loss: 0.0\n",
      "Epoch 3566, Loss: 4.6014334909028065e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3567, Loss: 6.370050463777588e-07, Final Batch Loss: 0.0\n",
      "Epoch 3568, Loss: 4.343962330954909e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3569, Loss: 3.8909207844550764e-07, Final Batch Loss: 0.0\n",
      "Epoch 3570, Loss: 2.093293918203898e-07, Final Batch Loss: 0.0\n",
      "Epoch 3571, Loss: 8.201561652043665e-08, Final Batch Loss: 0.0\n",
      "Epoch 3572, Loss: 2.1886407064464208e-07, Final Batch Loss: 0.0\n",
      "Epoch 3573, Loss: 6.534772695188096e-07, Final Batch Loss: 3.27331576954748e-07\n",
      "Epoch 3574, Loss: 3.121208103529227e-06, Final Batch Loss: 0.0\n",
      "Epoch 3575, Loss: 9.963238534194119e-07, Final Batch Loss: 3.172494800196546e-08\n",
      "Epoch 3576, Loss: 2.7395848556377445e-07, Final Batch Loss: 9.180937610153705e-08\n",
      "Epoch 3577, Loss: 1.305016917863e-06, Final Batch Loss: 6.873730740153405e-08\n",
      "Epoch 3578, Loss: 1.5648390327971384e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3579, Loss: 5.703961147851544e-08, Final Batch Loss: 3.701247308640632e-08\n",
      "Epoch 3580, Loss: 1.5959077005467392e-06, Final Batch Loss: 1.2593689291406918e-07\n",
      "Epoch 3581, Loss: 1.210108415383715e-05, Final Batch Loss: 1.1392020837774908e-07\n",
      "Epoch 3582, Loss: 3.9252948945689425e-06, Final Batch Loss: 0.0\n",
      "Epoch 3583, Loss: 7.309705356561835e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3584, Loss: 1.687975698105859e-07, Final Batch Loss: 0.0\n",
      "Epoch 3585, Loss: 5.192691168165453e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3586, Loss: 3.323489322637485e-07, Final Batch Loss: 0.0\n",
      "Epoch 3587, Loss: 3.7617143919810303e-06, Final Batch Loss: 0.0\n",
      "Epoch 3588, Loss: 1.29092256839769e-06, Final Batch Loss: 8.700267528638506e-08\n",
      "Epoch 3589, Loss: 5.28504680941122e-06, Final Batch Loss: 0.0\n",
      "Epoch 3590, Loss: 7.449080186239243e-06, Final Batch Loss: 0.0\n",
      "Epoch 3591, Loss: 2.5424175839061647e-06, Final Batch Loss: 1.874658472900137e-08\n",
      "Epoch 3592, Loss: 9.512378696951984e-07, Final Batch Loss: 0.0\n",
      "Epoch 3593, Loss: 2.164308591345865e-06, Final Batch Loss: 0.0\n",
      "Epoch 3594, Loss: 8.615719355731244e-07, Final Batch Loss: 0.0\n",
      "Epoch 3595, Loss: 1.3097229806247057e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3596, Loss: 1.4070330285331778e-06, Final Batch Loss: 0.0\n",
      "Epoch 3597, Loss: 1.5080570343606325e-06, Final Batch Loss: 0.0\n",
      "Epoch 3598, Loss: 1.5640157402518895e-07, Final Batch Loss: 0.0\n",
      "Epoch 3599, Loss: 7.295576553989491e-08, Final Batch Loss: 0.0\n",
      "Epoch 3600, Loss: 9.393644639921206e-08, Final Batch Loss: 0.0\n",
      "Epoch 3601, Loss: 1.2080318702589743e-05, Final Batch Loss: 1.0761569683381822e-05\n",
      "Epoch 3602, Loss: 5.6266665104942604e-08, Final Batch Loss: 0.0\n",
      "Epoch 3603, Loss: 2.961124437872442e-07, Final Batch Loss: 0.0\n",
      "Epoch 3604, Loss: 3.157501778927596e-07, Final Batch Loss: 1.1536366528730468e-08\n",
      "Epoch 3605, Loss: 9.555096035507304e-07, Final Batch Loss: 0.0\n",
      "Epoch 3606, Loss: 3.4916748270497067e-08, Final Batch Loss: 1.345909161898362e-08\n",
      "Epoch 3607, Loss: 2.6798117747084405e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3608, Loss: 1.3749458835921047e-06, Final Batch Loss: 8.771514217187359e-07\n",
      "Epoch 3609, Loss: 1.27488138501608e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3610, Loss: 6.504586191891093e-08, Final Batch Loss: 2.451475467069031e-08\n",
      "Epoch 3611, Loss: 7.009477176467271e-08, Final Batch Loss: 0.0\n",
      "Epoch 3612, Loss: 7.772408316952806e-08, Final Batch Loss: 0.0\n",
      "Epoch 3613, Loss: 2.8119333278509018e-06, Final Batch Loss: 0.0\n",
      "Epoch 3614, Loss: 6.919880457534333e-08, Final Batch Loss: 7.210233743393246e-09\n",
      "Epoch 3615, Loss: 2.9563271886079434e-07, Final Batch Loss: 0.0\n",
      "Epoch 3616, Loss: 8.345003432719267e-08, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3617, Loss: 3.004454773858356e-08, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3618, Loss: 4.750753404225705e-06, Final Batch Loss: 4.2299848956872665e-08\n",
      "Epoch 3619, Loss: 2.4891329962750675e-06, Final Batch Loss: 2.0188618776728617e-08\n",
      "Epoch 3620, Loss: 2.9021778646942664e-07, Final Batch Loss: 3.845442719807579e-08\n",
      "Epoch 3621, Loss: 1.8844108510274182e-06, Final Batch Loss: 1.3939788878758463e-08\n",
      "Epoch 3622, Loss: 2.7679607050856703e-08, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 3623, Loss: 4.749187180186354e-07, Final Batch Loss: 0.0\n",
      "Epoch 3624, Loss: 4.7722161777841166e-09, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3625, Loss: 1.1276702143181438e-06, Final Batch Loss: 0.0\n",
      "Epoch 3626, Loss: 1.979976462451738e-06, Final Batch Loss: 0.0\n",
      "Epoch 3627, Loss: 2.431866963359397e-08, Final Batch Loss: 0.0\n",
      "Epoch 3628, Loss: 1.3877037363663192e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3629, Loss: 2.5987638507807276e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3630, Loss: 9.822762270239593e-08, Final Batch Loss: 0.0\n",
      "Epoch 3631, Loss: 2.384180475267783e-08, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3632, Loss: 2.3221654810168246e-07, Final Batch Loss: 0.0\n",
      "Epoch 3633, Loss: 4.41536528006381e-07, Final Batch Loss: 0.0\n",
      "Epoch 3634, Loss: 7.953148883910188e-08, Final Batch Loss: 4.710662082629824e-08\n",
      "Epoch 3635, Loss: 4.148476118182032e-08, Final Batch Loss: 0.0\n",
      "Epoch 3636, Loss: 0.003924723030954702, Final Batch Loss: 4.854864954495497e-08\n",
      "Epoch 3637, Loss: 6.1741922842140085e-06, Final Batch Loss: 0.0\n",
      "Epoch 3638, Loss: 1.5285534495923514e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3639, Loss: 0.0003898843668126428, Final Batch Loss: 9.46934690659873e-08\n",
      "Epoch 3640, Loss: 9.771836393168698e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 3641, Loss: 0.024711969384243804, Final Batch Loss: 0.008291767910122871\n",
      "Epoch 3642, Loss: 0.0156857331168484, Final Batch Loss: 3.134766757284524e-06\n",
      "Epoch 3643, Loss: 0.03302297992609593, Final Batch Loss: 1.9707957932268982e-08\n",
      "Epoch 3644, Loss: 0.0328908409725136, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3645, Loss: 7.53284366541429e-05, Final Batch Loss: 1.779095214260451e-06\n",
      "Epoch 3646, Loss: 0.00034863466458845416, Final Batch Loss: 0.0\n",
      "Epoch 3647, Loss: 0.014378314951373317, Final Batch Loss: 0.0\n",
      "Epoch 3648, Loss: 0.014410163090682437, Final Batch Loss: 1.5045088730403222e-07\n",
      "Epoch 3649, Loss: 0.0005391474312423927, Final Batch Loss: 1.332232045569981e-06\n",
      "Epoch 3650, Loss: 0.004173408547415214, Final Batch Loss: 4.326131275433909e-08\n",
      "Epoch 3651, Loss: 0.00010498806703507224, Final Batch Loss: 2.1072426079626894e-06\n",
      "Epoch 3652, Loss: 0.002391430751926271, Final Batch Loss: 0.0\n",
      "Epoch 3653, Loss: 7.839911764229157e-05, Final Batch Loss: 0.0\n",
      "Epoch 3654, Loss: 3.9351279060850786e-05, Final Batch Loss: 0.0\n",
      "Epoch 3655, Loss: 5.1348984873023085e-06, Final Batch Loss: 0.0\n",
      "Epoch 3656, Loss: 4.982981778312023e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3657, Loss: 0.0400952794276358, Final Batch Loss: 2.321669967386697e-07\n",
      "Epoch 3658, Loss: 0.003514682002569658, Final Batch Loss: 9.28141901113122e-07\n",
      "Epoch 3659, Loss: 0.0011412735845746091, Final Batch Loss: 1.0094321822862184e-08\n",
      "Epoch 3660, Loss: 8.101357097278772e-06, Final Batch Loss: 1.2689953621247696e-07\n",
      "Epoch 3661, Loss: 0.00027321666502277964, Final Batch Loss: 5.287505988604835e-09\n",
      "Epoch 3662, Loss: 0.006439590129686312, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3663, Loss: 0.0010368542740621933, Final Batch Loss: 4.27806270408837e-08\n",
      "Epoch 3664, Loss: 0.000778728280356189, Final Batch Loss: 2.643747798458662e-08\n",
      "Epoch 3665, Loss: 1.9394378999448847e-05, Final Batch Loss: 1.4372153600561433e-07\n",
      "Epoch 3666, Loss: 1.6901860559359605e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3667, Loss: 2.167467473590534e-05, Final Batch Loss: 1.3170534884920926e-07\n",
      "Epoch 3668, Loss: 5.363771539235174e-05, Final Batch Loss: 3.5184442026547913e-07\n",
      "Epoch 3669, Loss: 2.8862867545553783e-05, Final Batch Loss: 1.2497735291105982e-08\n",
      "Epoch 3670, Loss: 0.0008892264214610535, Final Batch Loss: 2.662948475062876e-07\n",
      "Epoch 3671, Loss: 7.052099881466045e-05, Final Batch Loss: 1.917405279527884e-05\n",
      "Epoch 3672, Loss: 2.9625816739597965e-05, Final Batch Loss: 2.349737042095512e-05\n",
      "Epoch 3673, Loss: 1.3138027272319164e-05, Final Batch Loss: 1.3074364346721268e-07\n",
      "Epoch 3674, Loss: 6.232367688596696e-06, Final Batch Loss: 3.0795292786933715e-06\n",
      "Epoch 3675, Loss: 0.00016862407908813104, Final Batch Loss: 8.843622367749049e-07\n",
      "Epoch 3676, Loss: 0.00038815087556276495, Final Batch Loss: 3.268631942887623e-08\n",
      "Epoch 3677, Loss: 4.74852728549191e-06, Final Batch Loss: 0.0\n",
      "Epoch 3678, Loss: 1.4573861431776969e-05, Final Batch Loss: 3.355094690959959e-07\n",
      "Epoch 3679, Loss: 6.991818113855075e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3680, Loss: 6.622204004602672e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3681, Loss: 1.7781882643452818e-05, Final Batch Loss: 1.730455956305832e-08\n",
      "Epoch 3682, Loss: 6.30978855313824e-05, Final Batch Loss: 7.215120149339782e-06\n",
      "Epoch 3683, Loss: 4.656547816783707e-06, Final Batch Loss: 1.9707950826841625e-08\n",
      "Epoch 3684, Loss: 0.0005578042922304016, Final Batch Loss: 9.132967271341386e-09\n",
      "Epoch 3685, Loss: 6.894468093432415e-06, Final Batch Loss: 0.0\n",
      "Epoch 3686, Loss: 8.224781883559018e-06, Final Batch Loss: 2.6292545385331323e-07\n",
      "Epoch 3687, Loss: 3.4831353823427946e-06, Final Batch Loss: 8.593700044912111e-07\n",
      "Epoch 3688, Loss: 5.448185363965408e-07, Final Batch Loss: 9.421295033007482e-08\n",
      "Epoch 3689, Loss: 3.1364776250653037e-06, Final Batch Loss: 9.613642326655736e-09\n",
      "Epoch 3690, Loss: 7.688915523273998e-06, Final Batch Loss: 4.3261287885343336e-08\n",
      "Epoch 3691, Loss: 2.1426797223167426e-06, Final Batch Loss: 2.2927964948848967e-07\n",
      "Epoch 3692, Loss: 0.00031267760877906614, Final Batch Loss: 0.0\n",
      "Epoch 3693, Loss: 1.5872934664873384e-05, Final Batch Loss: 1.5381814932879934e-08\n",
      "Epoch 3694, Loss: 2.690508667857472e-06, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 3695, Loss: 7.403306745423777e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3696, Loss: 5.228615055363761e-07, Final Batch Loss: 1.509315410430645e-07\n",
      "Epoch 3697, Loss: 3.2325143520806066e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3698, Loss: 2.029100657607863e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 3699, Loss: 0.0024165396879916035, Final Batch Loss: 5.287162139211432e-07\n",
      "Epoch 3700, Loss: 0.00011993370047569396, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3701, Loss: 3.368780040613473e-05, Final Batch Loss: 3.9029572462823126e-07\n",
      "Epoch 3702, Loss: 7.83761523315274e-06, Final Batch Loss: 1.4798614529354381e-06\n",
      "Epoch 3703, Loss: 0.001972150792256211, Final Batch Loss: 9.613641438477316e-09\n",
      "Epoch 3704, Loss: 6.852307419180637e-05, Final Batch Loss: 5.25844143339782e-06\n",
      "Epoch 3705, Loss: 2.8678550776373157e-06, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 3706, Loss: 4.951151771237505e-06, Final Batch Loss: 2.787953690130962e-08\n",
      "Epoch 3707, Loss: 8.381742292973282e-05, Final Batch Loss: 1.5381814932879934e-08\n",
      "Epoch 3708, Loss: 5.441103642755962e-06, Final Batch Loss: 5.820651267640642e-07\n",
      "Epoch 3709, Loss: 8.334805144061264e-06, Final Batch Loss: 1.345909161898362e-08\n",
      "Epoch 3710, Loss: 2.2420163824254935e-05, Final Batch Loss: 4.229315436532488e-06\n",
      "Epoch 3711, Loss: 5.882427257852818e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3712, Loss: 0.0002727977979228857, Final Batch Loss: 2.3312780683681922e-07\n",
      "Epoch 3713, Loss: 3.816819920454684e-06, Final Batch Loss: 0.0\n",
      "Epoch 3714, Loss: 5.5416611806080596e-06, Final Batch Loss: 3.3489691304566804e-06\n",
      "Epoch 3715, Loss: 1.5217667107214616e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3716, Loss: 4.523978949122487e-06, Final Batch Loss: 1.1055692361594538e-08\n",
      "Epoch 3717, Loss: 4.2524655607167894e-05, Final Batch Loss: 4.326141667121419e-09\n",
      "Epoch 3718, Loss: 2.8170055618170764e-05, Final Batch Loss: 1.249100705535966e-06\n",
      "Epoch 3719, Loss: 1.5715924915893353e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3720, Loss: 6.492700542337637e-05, Final Batch Loss: 2.9321553185468474e-08\n",
      "Epoch 3721, Loss: 5.154469848722698e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3722, Loss: 1.7628576406414354e-06, Final Batch Loss: 4.3260098436803673e-07\n",
      "Epoch 3723, Loss: 1.17045220983103e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3724, Loss: 4.736926051629453e-06, Final Batch Loss: 0.0\n",
      "Epoch 3725, Loss: 1.7680617493409656e-06, Final Batch Loss: 9.132960165914028e-09\n",
      "Epoch 3726, Loss: 8.727842058520174e-06, Final Batch Loss: 0.0\n",
      "Epoch 3727, Loss: 1.757400655610919e-05, Final Batch Loss: 1.4072928024688736e-05\n",
      "Epoch 3728, Loss: 3.344436120966687e-05, Final Batch Loss: 0.0\n",
      "Epoch 3729, Loss: 1.4231562878275206e-05, Final Batch Loss: 3.4750189570331713e-06\n",
      "Epoch 3730, Loss: 9.249814336698137e-06, Final Batch Loss: 0.0\n",
      "Epoch 3731, Loss: 1.2278830569090182e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3732, Loss: 0.00010385972246285124, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3733, Loss: 1.6447448558332134e-05, Final Batch Loss: 9.132962830449287e-09\n",
      "Epoch 3734, Loss: 4.239241221171142e-06, Final Batch Loss: 3.8645040945084475e-07\n",
      "Epoch 3735, Loss: 4.911361073389742e-07, Final Batch Loss: 0.0\n",
      "Epoch 3736, Loss: 3.2817423896158715e-06, Final Batch Loss: 9.607700803826447e-07\n",
      "Epoch 3737, Loss: 1.044423915130821e-07, Final Batch Loss: 1.9227304193236705e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3738, Loss: 1.1352517792495576e-07, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 3739, Loss: 1.7205397724318061e-06, Final Batch Loss: 2.1149979545498354e-08\n",
      "Epoch 3740, Loss: 2.4082620829757317e-06, Final Batch Loss: 3.26862910071668e-08\n",
      "Epoch 3741, Loss: 1.0581159030742526e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3742, Loss: 6.338761225244127e-06, Final Batch Loss: 3.1136210054683033e-06\n",
      "Epoch 3743, Loss: 5.72305938195683e-07, Final Batch Loss: 1.538182381466413e-08\n",
      "Epoch 3744, Loss: 1.8120247431419045e-06, Final Batch Loss: 1.922725978431572e-08\n",
      "Epoch 3745, Loss: 2.213548399576659e-06, Final Batch Loss: 9.901942377155137e-08\n",
      "Epoch 3746, Loss: 2.0443057271446463e-06, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 3747, Loss: 1.0394148459380581e-05, Final Batch Loss: 0.0\n",
      "Epoch 3748, Loss: 1.5067484485653537e-06, Final Batch Loss: 0.0\n",
      "Epoch 3749, Loss: 4.881467809081386e-06, Final Batch Loss: 1.8265897239189144e-08\n",
      "Epoch 3750, Loss: 2.6730231837968077e-06, Final Batch Loss: 2.547609767589165e-08\n",
      "Epoch 3751, Loss: 1.626337140792078e-05, Final Batch Loss: 9.469336248457694e-08\n",
      "Epoch 3752, Loss: 4.947150669121214e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3753, Loss: 5.884653313970034e-05, Final Batch Loss: 0.0\n",
      "Epoch 3754, Loss: 6.794736423509917e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3755, Loss: 0.0007055670169187067, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3756, Loss: 3.3622306139236e-07, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 3757, Loss: 4.4870578885802814e-07, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3758, Loss: 7.44293501053761e-07, Final Batch Loss: 0.0\n",
      "Epoch 3759, Loss: 5.369598075066762e-07, Final Batch Loss: 2.4466160652991675e-07\n",
      "Epoch 3760, Loss: 2.928138450375428e-06, Final Batch Loss: 7.354377373758325e-08\n",
      "Epoch 3761, Loss: 4.1730676174633885e-06, Final Batch Loss: 0.0\n",
      "Epoch 3762, Loss: 1.2718875539330377e-05, Final Batch Loss: 5.763092758570565e-07\n",
      "Epoch 3763, Loss: 2.2661504395227183e-07, Final Batch Loss: 1.490114787117136e-08\n",
      "Epoch 3764, Loss: 8.864932236396506e-06, Final Batch Loss: 0.0\n",
      "Epoch 3765, Loss: 2.0200086303767684e-05, Final Batch Loss: 0.0\n",
      "Epoch 3766, Loss: 7.824400960476652e-07, Final Batch Loss: 0.0\n",
      "Epoch 3767, Loss: 8.160435875481653e-06, Final Batch Loss: 2.4466012860102637e-07\n",
      "Epoch 3768, Loss: 1.3974822089646288e-05, Final Batch Loss: 8.07541340464013e-08\n",
      "Epoch 3769, Loss: 8.1219084734796e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3770, Loss: 0.010680532825789069, Final Batch Loss: 0.0\n",
      "Epoch 3771, Loss: 0.03796736605007556, Final Batch Loss: 0.0\n",
      "Epoch 3772, Loss: 4.21098533561759e-05, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3773, Loss: 0.006671141065245134, Final Batch Loss: 3.4607793963914446e-07\n",
      "Epoch 3774, Loss: 0.03470843477373542, Final Batch Loss: 0.0017103665741160512\n",
      "Epoch 3775, Loss: 0.0023455215082319736, Final Batch Loss: 1.0526846949687751e-07\n",
      "Epoch 3776, Loss: 0.00043036749449143485, Final Batch Loss: 0.0001984456175705418\n",
      "Epoch 3777, Loss: 0.0006469937784601143, Final Batch Loss: 7.748308235022705e-06\n",
      "Epoch 3778, Loss: 9.348742868553472e-05, Final Batch Loss: 4.461174739844864e-06\n",
      "Epoch 3779, Loss: 0.0007460539602206495, Final Batch Loss: 9.703813930173055e-07\n",
      "Epoch 3780, Loss: 0.00014859563893665495, Final Batch Loss: 2.105175099131884e-06\n",
      "Epoch 3781, Loss: 0.001777019641058697, Final Batch Loss: 1.20164600048156e-06\n",
      "Epoch 3782, Loss: 1.4914408903110576e-05, Final Batch Loss: 4.0377241106170914e-08\n",
      "Epoch 3783, Loss: 1.4944608249911617e-05, Final Batch Loss: 9.180009215015161e-07\n",
      "Epoch 3784, Loss: 2.7407313901828267e-05, Final Batch Loss: 8.782433724263683e-06\n",
      "Epoch 3785, Loss: 5.58568607784693e-05, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 3786, Loss: 1.816235111040676e-05, Final Batch Loss: 8.815073329060397e-07\n",
      "Epoch 3787, Loss: 0.00012643494337194472, Final Batch Loss: 8.440013061772333e-07\n",
      "Epoch 3788, Loss: 5.726972864561475e-05, Final Batch Loss: 9.709681592084962e-08\n",
      "Epoch 3789, Loss: 7.103784547268788e-06, Final Batch Loss: 4.1819202323267746e-08\n",
      "Epoch 3790, Loss: 8.965700850738223e-06, Final Batch Loss: 6.585329259678474e-08\n",
      "Epoch 3791, Loss: 9.86281711217174e-05, Final Batch Loss: 2.619690349092707e-07\n",
      "Epoch 3792, Loss: 5.667067844994378e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3793, Loss: 0.00018099275628769007, Final Batch Loss: 3.2397776521975175e-05\n",
      "Epoch 3794, Loss: 3.162947767409996e-05, Final Batch Loss: 5.222743311605882e-06\n",
      "Epoch 3795, Loss: 0.00012090142798504289, Final Batch Loss: 1.2209159194753738e-07\n",
      "Epoch 3796, Loss: 6.055290907702737e-05, Final Batch Loss: 0.0\n",
      "Epoch 3797, Loss: 9.454534701647255e-05, Final Batch Loss: 5.960029056950589e-07\n",
      "Epoch 3798, Loss: 2.922825593643097e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 3799, Loss: 1.1274958382045952e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3800, Loss: 2.843261963270116e-05, Final Batch Loss: 1.3170526358408097e-07\n",
      "Epoch 3801, Loss: 1.0368720342546212e-05, Final Batch Loss: 1.3699343526241137e-07\n",
      "Epoch 3802, Loss: 9.24062824780858e-06, Final Batch Loss: 5.239408906732024e-08\n",
      "Epoch 3803, Loss: 1.93019916417958e-05, Final Batch Loss: 1.156575763161527e-05\n",
      "Epoch 3804, Loss: 2.029481292575852e-06, Final Batch Loss: 1.4639626897405833e-06\n",
      "Epoch 3805, Loss: 1.3375737579757185e-05, Final Batch Loss: 4.64793572518829e-07\n",
      "Epoch 3806, Loss: 2.025595592369811e-06, Final Batch Loss: 4.845003331865883e-07\n",
      "Epoch 3807, Loss: 6.816832257672267e-06, Final Batch Loss: 5.292131390888244e-07\n",
      "Epoch 3808, Loss: 1.5070394425165112e-05, Final Batch Loss: 1.2305387997457728e-07\n",
      "Epoch 3809, Loss: 5.830704329468084e-06, Final Batch Loss: 9.564450920152012e-07\n",
      "Epoch 3810, Loss: 6.505413504775959e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3811, Loss: 4.645026673055774e-05, Final Batch Loss: 8.604154544400444e-08\n",
      "Epoch 3812, Loss: 3.173225265884483e-06, Final Batch Loss: 2.6773193440021714e-07\n",
      "Epoch 3813, Loss: 0.00019074483167091927, Final Batch Loss: 3.8501727317452605e-07\n",
      "Epoch 3814, Loss: 2.0842546116894844e-05, Final Batch Loss: 3.701239492670538e-08\n",
      "Epoch 3815, Loss: 2.045529954086689e-05, Final Batch Loss: 1.329349288425874e-06\n",
      "Epoch 3816, Loss: 8.887949636271486e-06, Final Batch Loss: 5.287507764961674e-09\n",
      "Epoch 3817, Loss: 3.1899734931339907e-06, Final Batch Loss: 3.0570518561034987e-07\n",
      "Epoch 3818, Loss: 1.3727597377055645e-05, Final Batch Loss: 1.6487108212004387e-07\n",
      "Epoch 3819, Loss: 5.239675045731751e-06, Final Batch Loss: 0.0\n",
      "Epoch 3820, Loss: 1.9275816611874497e-05, Final Batch Loss: 1.2803384379367344e-06\n",
      "Epoch 3821, Loss: 1.5126517902808168e-05, Final Batch Loss: 1.5528962649113964e-06\n",
      "Epoch 3822, Loss: 1.091933748464946e-05, Final Batch Loss: 1.4901133660316646e-08\n",
      "Epoch 3823, Loss: 7.16327516925297e-05, Final Batch Loss: 1.3459102277124657e-08\n",
      "Epoch 3824, Loss: 0.000250272552634212, Final Batch Loss: 1.1055690585237699e-08\n",
      "Epoch 3825, Loss: 2.901893752360607e-05, Final Batch Loss: 4.066390033585776e-07\n",
      "Epoch 3826, Loss: 1.2119051268966174e-05, Final Batch Loss: 2.547609767589165e-08\n",
      "Epoch 3827, Loss: 9.769096663259091e-05, Final Batch Loss: 4.705660501258535e-07\n",
      "Epoch 3828, Loss: 1.0576186876276594e-06, Final Batch Loss: 6.008492903220031e-08\n",
      "Epoch 3829, Loss: 4.709909311828575e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3830, Loss: 1.405533442211393e-05, Final Batch Loss: 4.758741312116399e-08\n",
      "Epoch 3831, Loss: 2.2761188991249348e-05, Final Batch Loss: 1.826574873575737e-07\n",
      "Epoch 3832, Loss: 8.740028433096292e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 3833, Loss: 7.348626094194621e-06, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 3834, Loss: 1.3690458039228304e-05, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 3835, Loss: 4.476545683484989e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3836, Loss: 7.858170397168074e-06, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 3837, Loss: 8.149737098950283e-06, Final Batch Loss: 4.049191375088412e-06\n",
      "Epoch 3838, Loss: 2.2266359166467353e-05, Final Batch Loss: 0.0\n",
      "Epoch 3839, Loss: 1.2387609318098569e-05, Final Batch Loss: 1.5862507751762678e-08\n",
      "Epoch 3840, Loss: 1.0093676640399174e-05, Final Batch Loss: 3.6051130081204974e-08\n",
      "Epoch 3841, Loss: 1.3883250115531709e-05, Final Batch Loss: 4.801866566594981e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3842, Loss: 9.8368409647831e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3843, Loss: 1.1495640975134336e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3844, Loss: 2.310620038947775e-05, Final Batch Loss: 7.2102359638392954e-09\n",
      "Epoch 3845, Loss: 2.2697041954344854e-05, Final Batch Loss: 1.230534252272264e-07\n",
      "Epoch 3846, Loss: 3.049030154378407e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3847, Loss: 6.688463362491959e-06, Final Batch Loss: 3.3647719277496435e-08\n",
      "Epoch 3848, Loss: 2.631572864286724e-06, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 3849, Loss: 3.782121575923725e-05, Final Batch Loss: 2.5633427867433056e-05\n",
      "Epoch 3850, Loss: 8.789536118047891e-06, Final Batch Loss: 1.2785973524387373e-07\n",
      "Epoch 3851, Loss: 2.7644091251777247e-05, Final Batch Loss: 1.3314762270510982e-07\n",
      "Epoch 3852, Loss: 0.011866275616232547, Final Batch Loss: 2.9321588712605262e-08\n",
      "Epoch 3853, Loss: 0.00010316165285595424, Final Batch Loss: 2.0062358089489862e-05\n",
      "Epoch 3854, Loss: 0.002827000045256378, Final Batch Loss: 3.984715419846907e-07\n",
      "Epoch 3855, Loss: 2.005446242403508e-05, Final Batch Loss: 3.941589454825589e-08\n",
      "Epoch 3856, Loss: 8.523603758470166e-06, Final Batch Loss: 9.61317596193112e-07\n",
      "Epoch 3857, Loss: 9.549977328515702e-05, Final Batch Loss: 7.699419802520424e-05\n",
      "Epoch 3858, Loss: 4.569859715308766e-06, Final Batch Loss: 1.485516349930549e-06\n",
      "Epoch 3859, Loss: 3.181166400523239e-05, Final Batch Loss: 4.0857912608771585e-08\n",
      "Epoch 3860, Loss: 2.9009150526615457e-05, Final Batch Loss: 2.8360178205844022e-08\n",
      "Epoch 3861, Loss: 6.658431544637189e-05, Final Batch Loss: 6.73690965413698e-06\n",
      "Epoch 3862, Loss: 0.00018154969628270123, Final Batch Loss: 1.634999875932408e-06\n",
      "Epoch 3863, Loss: 5.6425095498635613e-05, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 3864, Loss: 7.809336624475804e-06, Final Batch Loss: 2.1630143010042957e-07\n",
      "Epoch 3865, Loss: 2.181454552108164e-06, Final Batch Loss: 4.326142111210629e-09\n",
      "Epoch 3866, Loss: 1.0712843411364581e-05, Final Batch Loss: 6.99367035394971e-07\n",
      "Epoch 3867, Loss: 0.000478794942519456, Final Batch Loss: 9.108459266826685e-07\n",
      "Epoch 3868, Loss: 4.027178240739726e-05, Final Batch Loss: 2.9321588712605262e-08\n",
      "Epoch 3869, Loss: 5.3104549077587215e-05, Final Batch Loss: 3.619385893216531e-07\n",
      "Epoch 3870, Loss: 2.1964560879106365e-05, Final Batch Loss: 4.326142111210629e-09\n",
      "Epoch 3871, Loss: 3.5031714498034994e-05, Final Batch Loss: 2.2720437300449703e-06\n",
      "Epoch 3872, Loss: 8.68712434476393e-06, Final Batch Loss: 7.690915460045744e-09\n",
      "Epoch 3873, Loss: 2.173027702523367e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 3874, Loss: 2.3681192284463748e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3875, Loss: 0.00011356601881651329, Final Batch Loss: 1.706395948986028e-07\n",
      "Epoch 3876, Loss: 1.9134818821653354e-06, Final Batch Loss: 6.777577965522141e-08\n",
      "Epoch 3877, Loss: 5.727427716539779e-06, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 3878, Loss: 3.6537964890115404e-05, Final Batch Loss: 5.335569142062013e-08\n",
      "Epoch 3879, Loss: 9.385614839541034e-06, Final Batch Loss: 0.0\n",
      "Epoch 3880, Loss: 1.863003908553207e-05, Final Batch Loss: 0.0\n",
      "Epoch 3881, Loss: 1.925383537160208e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 3882, Loss: 9.483935229592788e-06, Final Batch Loss: 3.701249795540207e-08\n",
      "Epoch 3883, Loss: 8.206354864870313e-06, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 3884, Loss: 7.303143792491973e-06, Final Batch Loss: 3.465215968390112e-06\n",
      "Epoch 3885, Loss: 0.0003748816686528489, Final Batch Loss: 1.057500842449599e-08\n",
      "Epoch 3886, Loss: 2.169488727365998e-05, Final Batch Loss: 2.0524792887499643e-07\n",
      "Epoch 3887, Loss: 1.1383843801282545e-05, Final Batch Loss: 3.028291217788137e-08\n",
      "Epoch 3888, Loss: 2.4068149243605674e-06, Final Batch Loss: 1.9147246348438784e-06\n",
      "Epoch 3889, Loss: 1.2513131590452531e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3890, Loss: 1.6963157163929488e-05, Final Batch Loss: 6.296914278891563e-08\n",
      "Epoch 3891, Loss: 4.652203362098817e-06, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 3892, Loss: 1.3051945153774724e-05, Final Batch Loss: 0.0\n",
      "Epoch 3893, Loss: 3.119924204719737e-05, Final Batch Loss: 1.6450936755063594e-06\n",
      "Epoch 3894, Loss: 8.495464678737186e-06, Final Batch Loss: 1.2606368500200915e-06\n",
      "Epoch 3895, Loss: 5.638849142264313e-05, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 3896, Loss: 1.7436534830661543e-05, Final Batch Loss: 9.709672355029397e-08\n",
      "Epoch 3897, Loss: 1.7685127543520807e-06, Final Batch Loss: 0.0\n",
      "Epoch 3898, Loss: 4.8265774854616694e-06, Final Batch Loss: 0.0\n",
      "Epoch 3899, Loss: 2.076907593673294e-05, Final Batch Loss: 1.93586583918659e-05\n",
      "Epoch 3900, Loss: 0.0001302639172633402, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3901, Loss: 5.5029168827269714e-06, Final Batch Loss: 6.873714397670483e-08\n",
      "Epoch 3902, Loss: 1.9399419304066967e-05, Final Batch Loss: 2.499545459500041e-08\n",
      "Epoch 3903, Loss: 1.7537567407188703e-06, Final Batch Loss: 1.2497729962035464e-08\n",
      "Epoch 3904, Loss: 3.981316592849282e-06, Final Batch Loss: 1.2497729073857045e-08\n",
      "Epoch 3905, Loss: 8.571333948159676e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3906, Loss: 7.744100555262534e-07, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 3907, Loss: 5.885736109823014e-06, Final Batch Loss: 0.0\n",
      "Epoch 3908, Loss: 2.1719457197311165e-05, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 3909, Loss: 7.725209904108077e-06, Final Batch Loss: 4.133852016252604e-08\n",
      "Epoch 3910, Loss: 5.6074839203001936e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3911, Loss: 1.1794143364829424e-05, Final Batch Loss: 3.749307708744709e-08\n",
      "Epoch 3912, Loss: 0.000945095309934918, Final Batch Loss: 4.662594932369757e-08\n",
      "Epoch 3913, Loss: 1.1837759519295332e-05, Final Batch Loss: 1.9899839287518262e-07\n",
      "Epoch 3914, Loss: 7.719678791429097e-06, Final Batch Loss: 9.036734383016665e-08\n",
      "Epoch 3915, Loss: 1.344677803549743e-07, Final Batch Loss: 0.0\n",
      "Epoch 3916, Loss: 8.106394343165846e-05, Final Batch Loss: 5.9604204238894454e-08\n",
      "Epoch 3917, Loss: 1.0595337072150102e-06, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 3918, Loss: 5.100947819691726e-07, Final Batch Loss: 1.0478748180275943e-07\n",
      "Epoch 3919, Loss: 1.374172718171529e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3920, Loss: 8.269753133949287e-06, Final Batch Loss: 2.1485948309418745e-07\n",
      "Epoch 3921, Loss: 2.120239183556194e-06, Final Batch Loss: 0.0\n",
      "Epoch 3922, Loss: 3.4390825476293685e-07, Final Batch Loss: 1.3939772003368489e-08\n",
      "Epoch 3923, Loss: 9.976088204188827e-06, Final Batch Loss: 0.0\n",
      "Epoch 3924, Loss: 2.8315863075389913e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3925, Loss: 1.59152901335613e-06, Final Batch Loss: 0.0\n",
      "Epoch 3926, Loss: 1.4972344447583552e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3927, Loss: 4.116021306677098e-06, Final Batch Loss: 9.343389706373273e-07\n",
      "Epoch 3928, Loss: 4.349237811562823e-06, Final Batch Loss: 7.690915460045744e-09\n",
      "Epoch 3929, Loss: 4.901922663336222e-07, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3930, Loss: 0.0010436369177214688, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3931, Loss: 5.569284815543085e-07, Final Batch Loss: 0.0\n",
      "Epoch 3932, Loss: 2.2062596038985305e-06, Final Batch Loss: 6.729551582651538e-09\n",
      "Epoch 3933, Loss: 9.769874078968677e-06, Final Batch Loss: 7.979262051094338e-08\n",
      "Epoch 3934, Loss: 5.584113405010527e-07, Final Batch Loss: 1.2497578438797063e-07\n",
      "Epoch 3935, Loss: 1.4857538075396803e-06, Final Batch Loss: 0.0\n",
      "Epoch 3936, Loss: 9.026309653048514e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3937, Loss: 2.408787985075378e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3938, Loss: 4.880303337562175e-06, Final Batch Loss: 6.830051120232383e-07\n",
      "Epoch 3939, Loss: 1.6330492058624912e-06, Final Batch Loss: 1.5105025568118435e-06\n",
      "Epoch 3940, Loss: 4.315192362325249e-06, Final Batch Loss: 0.0\n",
      "Epoch 3941, Loss: 2.5924786980491277e-06, Final Batch Loss: 6.248846773360128e-08\n",
      "Epoch 3942, Loss: 4.3110110414801284e-07, Final Batch Loss: 7.210233743393246e-09\n",
      "Epoch 3943, Loss: 8.625620124824707e-07, Final Batch Loss: 0.0\n",
      "Epoch 3944, Loss: 1.2470586181034804e-05, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 3945, Loss: 5.721922931023471e-07, Final Batch Loss: 0.0\n",
      "Epoch 3946, Loss: 1.1811667567029893e-05, Final Batch Loss: 2.884094740807086e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3947, Loss: 4.850646639908973e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3948, Loss: 1.2459090679151075e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3949, Loss: 1.7394148811300525e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3950, Loss: 1.0846810713283084e-05, Final Batch Loss: 5.051658149568539e-07\n",
      "Epoch 3951, Loss: 3.61563432071943e-05, Final Batch Loss: 0.0\n",
      "Epoch 3952, Loss: 2.9127065809264607e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3953, Loss: 1.4913067124422419e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 3954, Loss: 5.54259746754493e-06, Final Batch Loss: 0.0\n",
      "Epoch 3955, Loss: 8.659007038058775e-07, Final Batch Loss: 0.0\n",
      "Epoch 3956, Loss: 8.196556368078589e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3957, Loss: 1.458775380658306e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3958, Loss: 4.433610553578049e-06, Final Batch Loss: 2.4127862161549274e-06\n",
      "Epoch 3959, Loss: 3.103268456927655e-05, Final Batch Loss: 1.301962856814498e-05\n",
      "Epoch 3960, Loss: 1.8447023594214684e-06, Final Batch Loss: 0.0\n",
      "Epoch 3961, Loss: 1.0552128973939645e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3962, Loss: 2.414504565284581e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 3963, Loss: 1.154352630705624e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 3964, Loss: 2.081062540626455e-06, Final Batch Loss: 1.9034608556012245e-07\n",
      "Epoch 3965, Loss: 2.5710882015084202e-05, Final Batch Loss: 0.0\n",
      "Epoch 3966, Loss: 2.109797908822486e-06, Final Batch Loss: 0.0\n",
      "Epoch 3967, Loss: 4.1198378897266963e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3968, Loss: 1.6071286396801554e-05, Final Batch Loss: 1.7785220407517954e-08\n",
      "Epoch 3969, Loss: 0.000307092915316054, Final Batch Loss: 0.0\n",
      "Epoch 3970, Loss: 4.2912338940048755e-06, Final Batch Loss: 0.0\n",
      "Epoch 3971, Loss: 1.8550479917944784e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 3972, Loss: 4.864802556792114e-06, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 3973, Loss: 5.540232188938621e-05, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 3974, Loss: 7.355949405263296e-06, Final Batch Loss: 2.3024324491416337e-07\n",
      "Epoch 3975, Loss: 6.360758412204959e-07, Final Batch Loss: 2.374502230395592e-07\n",
      "Epoch 3976, Loss: 1.061323050888241e-06, Final Batch Loss: 0.0\n",
      "Epoch 3977, Loss: 4.064245041068837e-06, Final Batch Loss: 1.944856876434642e-06\n",
      "Epoch 3978, Loss: 2.947276273923549e-06, Final Batch Loss: 6.2488698659990405e-09\n",
      "Epoch 3979, Loss: 1.728094529807045e-06, Final Batch Loss: 1.3747346372383618e-07\n",
      "Epoch 3980, Loss: 3.920053516237587e-07, Final Batch Loss: 2.451407397074945e-07\n",
      "Epoch 3981, Loss: 6.8258651977348705e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 3982, Loss: 7.78145902380345e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3983, Loss: 5.680689488807289e-07, Final Batch Loss: 7.979289762261033e-08\n",
      "Epoch 3984, Loss: 2.6667634352994796e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3985, Loss: 2.0548286102650692e-06, Final Batch Loss: 0.0\n",
      "Epoch 3986, Loss: 6.73258097756424e-05, Final Batch Loss: 7.574846563329629e-07\n",
      "Epoch 3987, Loss: 3.2634283247956475e-06, Final Batch Loss: 0.0\n",
      "Epoch 3988, Loss: 6.313273006930409e-06, Final Batch Loss: 0.0\n",
      "Epoch 3989, Loss: 0.00018914544962600477, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3990, Loss: 1.9914124017583745e-06, Final Batch Loss: 9.132960165914028e-09\n",
      "Epoch 3991, Loss: 7.24920519279415e-07, Final Batch Loss: 2.1149979545498354e-08\n",
      "Epoch 3992, Loss: 5.900059430130611e-06, Final Batch Loss: 0.0\n",
      "Epoch 3993, Loss: 1.4543151222068396e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3994, Loss: 1.6191790387365401e-06, Final Batch Loss: 0.0\n",
      "Epoch 3995, Loss: 6.349163232055588e-06, Final Batch Loss: 2.0909163822580012e-07\n",
      "Epoch 3996, Loss: 4.5251692581960157e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 3997, Loss: 1.9216829205692676e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 3998, Loss: 7.394630853196915e-06, Final Batch Loss: 0.0\n",
      "Epoch 3999, Loss: 0.0003106717545038329, Final Batch Loss: 1.4564520256499236e-07\n",
      "Epoch 4000, Loss: 5.799314536658606e-05, Final Batch Loss: 2.871542847060482e-06\n",
      "Epoch 4001, Loss: 0.0007476549974468893, Final Batch Loss: 0.0\n",
      "Epoch 4002, Loss: 1.8024353454215714e-07, Final Batch Loss: 0.0\n",
      "Epoch 4003, Loss: 0.0021482271362616157, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4004, Loss: 8.773109754223185e-07, Final Batch Loss: 5.575899564291831e-08\n",
      "Epoch 4005, Loss: 0.008885543177149069, Final Batch Loss: 1.3459104053481497e-08\n",
      "Epoch 4006, Loss: 0.025857862754171013, Final Batch Loss: 0.002057064091786742\n",
      "Epoch 4007, Loss: 0.0007153332212750385, Final Batch Loss: 8.652246208384895e-08\n",
      "Epoch 4008, Loss: 0.061615516620770805, Final Batch Loss: 1.1862046449095942e-05\n",
      "Epoch 4009, Loss: 0.008157466017439607, Final Batch Loss: 2.2036124391888734e-06\n",
      "Epoch 4010, Loss: 0.001951315820582722, Final Batch Loss: 3.3647655328650217e-08\n",
      "Epoch 4011, Loss: 8.101531387938454e-05, Final Batch Loss: 5.287507764961674e-09\n",
      "Epoch 4012, Loss: 8.23884093821281e-05, Final Batch Loss: 4.224978908951016e-07\n",
      "Epoch 4013, Loss: 0.00011971092095985902, Final Batch Loss: 1.64390257850755e-07\n",
      "Epoch 4014, Loss: 0.0020255330318608156, Final Batch Loss: 5.709705874323845e-06\n",
      "Epoch 4015, Loss: 0.004327954069659468, Final Batch Loss: 9.252085533262289e-07\n",
      "Epoch 4016, Loss: 5.580539305105603e-06, Final Batch Loss: 2.211134031426809e-08\n",
      "Epoch 4017, Loss: 0.00022233497668566748, Final Batch Loss: 1.0094329816467962e-08\n",
      "Epoch 4018, Loss: 1.6213813664234245e-05, Final Batch Loss: 6.3398765632882714e-06\n",
      "Epoch 4019, Loss: 0.00012086841480951627, Final Batch Loss: 1.2401433480135893e-07\n",
      "Epoch 4020, Loss: 3.1339079531456093e-06, Final Batch Loss: 0.0\n",
      "Epoch 4021, Loss: 0.0002420447898409117, Final Batch Loss: 0.0\n",
      "Epoch 4022, Loss: 8.282940419990226e-06, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 4023, Loss: 6.435876298804821e-05, Final Batch Loss: 1.7160212451017287e-07\n",
      "Epoch 4024, Loss: 4.60501168767502e-05, Final Batch Loss: 2.8058448151568882e-05\n",
      "Epoch 4025, Loss: 1.0180566170858718e-05, Final Batch Loss: 1.47567092767531e-07\n",
      "Epoch 4026, Loss: 1.2438764698252669e-05, Final Batch Loss: 2.096197249557008e-06\n",
      "Epoch 4027, Loss: 3.097377854421879e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4028, Loss: 1.3937275449293907e-06, Final Batch Loss: 1.0575003983603892e-08\n",
      "Epoch 4029, Loss: 7.620531289331822e-07, Final Batch Loss: 1.1536376298693085e-08\n",
      "Epoch 4030, Loss: 6.28055432139174e-06, Final Batch Loss: 2.7398844082426876e-08\n",
      "Epoch 4031, Loss: 1.43975313053879e-05, Final Batch Loss: 1.5381814932879934e-08\n",
      "Epoch 4032, Loss: 0.030726060199056215, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4033, Loss: 0.0001027261418159453, Final Batch Loss: 2.338337708351901e-06\n",
      "Epoch 4034, Loss: 7.445381645210247e-06, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 4035, Loss: 9.431678209881333e-06, Final Batch Loss: 4.0377241106170914e-08\n",
      "Epoch 4036, Loss: 1.5461906599401054e-05, Final Batch Loss: 8.324805094162002e-07\n",
      "Epoch 4037, Loss: 5.887920281544279e-05, Final Batch Loss: 2.1678206962860713e-07\n",
      "Epoch 4038, Loss: 0.0001788012697394592, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4039, Loss: 4.232244844448729e-05, Final Batch Loss: 2.552346245465742e-07\n",
      "Epoch 4040, Loss: 0.00016741329487368617, Final Batch Loss: 1.0871576705540065e-06\n",
      "Epoch 4041, Loss: 2.617719798048146e-05, Final Batch Loss: 6.056563961465145e-08\n",
      "Epoch 4042, Loss: 5.248291996107213e-06, Final Batch Loss: 3.5858136016031494e-07\n",
      "Epoch 4043, Loss: 1.1149955563838354e-05, Final Batch Loss: 4.326121683106976e-08\n",
      "Epoch 4044, Loss: 3.364544681705439e-05, Final Batch Loss: 1.634317747800651e-08\n",
      "Epoch 4045, Loss: 8.483180572449456e-07, Final Batch Loss: 4.8068251601307566e-09\n",
      "Epoch 4046, Loss: 2.4164503632517764e-06, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 4047, Loss: 1.1649295630578038e-05, Final Batch Loss: 8.748340007969091e-08\n",
      "Epoch 4048, Loss: 3.0013610725632134e-06, Final Batch Loss: 7.690917236402584e-09\n",
      "Epoch 4049, Loss: 9.907191546809635e-06, Final Batch Loss: 1.7262476603718824e-06\n",
      "Epoch 4050, Loss: 2.525514210538482e-06, Final Batch Loss: 0.0\n",
      "Epoch 4051, Loss: 8.987826598971793e-06, Final Batch Loss: 3.9558238995596184e-07\n",
      "Epoch 4052, Loss: 2.624168505827029e-06, Final Batch Loss: 4.806826048309176e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4053, Loss: 3.4591492117042044e-05, Final Batch Loss: 7.464311124749656e-07\n",
      "Epoch 4054, Loss: 5.791846590796901e-05, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 4055, Loss: 2.9575637850665082e-05, Final Batch Loss: 1.538182381466413e-08\n",
      "Epoch 4056, Loss: 0.00018990703648924523, Final Batch Loss: 1.9755846381031006e-07\n",
      "Epoch 4057, Loss: 8.544244211483587e-06, Final Batch Loss: 0.0\n",
      "Epoch 4058, Loss: 7.079045623026303e-06, Final Batch Loss: 6.729552470829958e-09\n",
      "Epoch 4059, Loss: 1.7034609868238348e-06, Final Batch Loss: 3.557044081503591e-08\n",
      "Epoch 4060, Loss: 2.665048249239632e-05, Final Batch Loss: 5.104686806589598e-07\n",
      "Epoch 4061, Loss: 4.952972784133536e-06, Final Batch Loss: 4.5183991659314415e-08\n",
      "Epoch 4062, Loss: 6.041638856535414e-06, Final Batch Loss: 7.01254975865595e-07\n",
      "Epoch 4063, Loss: 7.862074761189053e-05, Final Batch Loss: 4.6143642862261913e-07\n",
      "Epoch 4064, Loss: 0.005174782959735946, Final Batch Loss: 5.902305929339491e-06\n",
      "Epoch 4065, Loss: 6.286547314382496e-05, Final Batch Loss: 3.0248318125813967e-06\n",
      "Epoch 4066, Loss: 3.3418104994353826e-05, Final Batch Loss: 6.056577461777124e-08\n",
      "Epoch 4067, Loss: 0.003439227858356708, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 4068, Loss: 8.416994013304979e-05, Final Batch Loss: 1.2030068319290876e-06\n",
      "Epoch 4069, Loss: 4.761143983655902e-05, Final Batch Loss: 7.3643886935315095e-06\n",
      "Epoch 4070, Loss: 0.0002366705903957822, Final Batch Loss: 3.7965683077345602e-06\n",
      "Epoch 4071, Loss: 0.0001552744364987646, Final Batch Loss: 6.585304390682722e-08\n",
      "Epoch 4072, Loss: 0.0003198185271739984, Final Batch Loss: 1.225586515829491e-06\n",
      "Epoch 4073, Loss: 4.357490294815136e-06, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 4074, Loss: 0.00011171780382879248, Final Batch Loss: 3.9317967548413435e-07\n",
      "Epoch 4075, Loss: 3.0827187909476805e-05, Final Batch Loss: 5.375759428716265e-06\n",
      "Epoch 4076, Loss: 0.00010100475410013132, Final Batch Loss: 1.8986609973126178e-07\n",
      "Epoch 4077, Loss: 2.257826727691814e-05, Final Batch Loss: 9.69911980064353e-07\n",
      "Epoch 4078, Loss: 4.017726295413304e-05, Final Batch Loss: 1.5381816709236773e-08\n",
      "Epoch 4079, Loss: 2.0611170520323796e-05, Final Batch Loss: 2.770704895738163e-06\n",
      "Epoch 4080, Loss: 3.8536424244339784e-05, Final Batch Loss: 2.8792276225431124e-06\n",
      "Epoch 4081, Loss: 1.7360108012454134e-05, Final Batch Loss: 7.690860570619407e-08\n",
      "Epoch 4082, Loss: 6.6584854504503355e-06, Final Batch Loss: 3.6051041263363004e-08\n",
      "Epoch 4083, Loss: 2.386471216597741e-05, Final Batch Loss: 1.6967958060831734e-07\n",
      "Epoch 4084, Loss: 2.4581772384735245e-05, Final Batch Loss: 6.633366211872271e-08\n",
      "Epoch 4085, Loss: 0.00047729537592855475, Final Batch Loss: 2.1149979545498354e-08\n",
      "Epoch 4086, Loss: 3.5487368921227613e-06, Final Batch Loss: 5.59962359147903e-07\n",
      "Epoch 4087, Loss: 5.469586389028613e-06, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 4088, Loss: 7.353915543306666e-05, Final Batch Loss: 0.0\n",
      "Epoch 4089, Loss: 9.573937806983679e-06, Final Batch Loss: 1.7977214383790852e-07\n",
      "Epoch 4090, Loss: 2.5099751542745352e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4091, Loss: 5.005697614224314e-05, Final Batch Loss: 4.326142111210629e-09\n",
      "Epoch 4092, Loss: 0.0013907315789045693, Final Batch Loss: 4.3740504906963906e-07\n",
      "Epoch 4093, Loss: 2.5443444809924998e-06, Final Batch Loss: 1.6775645406141848e-07\n",
      "Epoch 4094, Loss: 4.02227083726725e-05, Final Batch Loss: 1.1632453578158675e-07\n",
      "Epoch 4095, Loss: 6.473278130303406e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4096, Loss: 1.4345727045395051e-05, Final Batch Loss: 2.547612787395792e-08\n",
      "Epoch 4097, Loss: 9.336084196176486e-06, Final Batch Loss: 2.7398828095215322e-08\n",
      "Epoch 4098, Loss: 7.409798169599746e-06, Final Batch Loss: 2.5476124321244242e-08\n",
      "Epoch 4099, Loss: 0.0034833361905499682, Final Batch Loss: 5.214945758780232e-06\n",
      "Epoch 4100, Loss: 9.744600434347106e-07, Final Batch Loss: 4.133849174081661e-08\n",
      "Epoch 4101, Loss: 5.860735971197073e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4102, Loss: 3.1443057639135574e-05, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 4103, Loss: 2.3044219341628036e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 4104, Loss: 9.444467365948839e-07, Final Batch Loss: 4.42225598362711e-08\n",
      "Epoch 4105, Loss: 5.844855879844069e-06, Final Batch Loss: 1.4420464822251233e-08\n",
      "Epoch 4106, Loss: 1.2800518998101751e-05, Final Batch Loss: 1.6823873849602933e-08\n",
      "Epoch 4107, Loss: 3.1790180241575428e-06, Final Batch Loss: 8.641751492177718e-07\n",
      "Epoch 4108, Loss: 8.191199145191064e-06, Final Batch Loss: 1.2497736179284402e-08\n",
      "Epoch 4109, Loss: 6.233248611486886e-06, Final Batch Loss: 2.585997265214246e-07\n",
      "Epoch 4110, Loss: 1.3020430917443093e-05, Final Batch Loss: 4.902933170569668e-08\n",
      "Epoch 4111, Loss: 9.937428590012232e-07, Final Batch Loss: 6.729552914919168e-09\n",
      "Epoch 4112, Loss: 8.634270325380555e-06, Final Batch Loss: 7.883274520281702e-06\n",
      "Epoch 4113, Loss: 5.761282296345982e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 4114, Loss: 1.235429337342886e-05, Final Batch Loss: 7.690917236402584e-09\n",
      "Epoch 4115, Loss: 3.3964948948916884e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4116, Loss: 4.01179453457523e-06, Final Batch Loss: 3.460902320284731e-08\n",
      "Epoch 4117, Loss: 1.2830497876370472e-06, Final Batch Loss: 0.0\n",
      "Epoch 4118, Loss: 9.936226133655524e-06, Final Batch Loss: 5.525507731363177e-06\n",
      "Epoch 4119, Loss: 1.1429345913027689e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4120, Loss: 5.650701794701618e-06, Final Batch Loss: 1.605648321856279e-06\n",
      "Epoch 4121, Loss: 9.619602456600873e-05, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4122, Loss: 9.966112711756736e-07, Final Batch Loss: 4.806824271952337e-09\n",
      "Epoch 4123, Loss: 1.3681001400978055e-05, Final Batch Loss: 0.0\n",
      "Epoch 4124, Loss: 3.628811073852489e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4125, Loss: 9.257033128928782e-06, Final Batch Loss: 5.768189481614172e-09\n",
      "Epoch 4126, Loss: 5.864385502762914e-07, Final Batch Loss: 5.191350282984786e-08\n",
      "Epoch 4127, Loss: 0.001805675489076175, Final Batch Loss: 5.720103857242975e-08\n",
      "Epoch 4128, Loss: 3.2505897157308894e-06, Final Batch Loss: 3.701246598097896e-08\n",
      "Epoch 4129, Loss: 9.727138461368412e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4130, Loss: 3.184507177622642e-06, Final Batch Loss: 2.214638470832142e-06\n",
      "Epoch 4131, Loss: 7.885131972029669e-06, Final Batch Loss: 0.0\n",
      "Epoch 4132, Loss: 1.0895780688802148e-06, Final Batch Loss: 9.132966383162966e-09\n",
      "Epoch 4133, Loss: 1.096826502144932e-05, Final Batch Loss: 1.1199817606666329e-07\n",
      "Epoch 4134, Loss: 2.666797684458544e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4135, Loss: 1.3391428930975557e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4136, Loss: 0.00046764596660597846, Final Batch Loss: 0.0\n",
      "Epoch 4137, Loss: 2.251881837445069e-06, Final Batch Loss: 0.0\n",
      "Epoch 4138, Loss: 7.355233190842192e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4139, Loss: 2.3500559594435977e-05, Final Batch Loss: 0.0\n",
      "Epoch 4140, Loss: 1.6152696655780119e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4141, Loss: 1.6577581987142764e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4142, Loss: 1.6164737037804855e-07, Final Batch Loss: 0.0\n",
      "Epoch 4143, Loss: 9.74472958270578e-06, Final Batch Loss: 1.7785239947443188e-08\n",
      "Epoch 4144, Loss: 1.751637565439168e-06, Final Batch Loss: 0.0\n",
      "Epoch 4145, Loss: 3.232930818608537e-07, Final Batch Loss: 0.0\n",
      "Epoch 4146, Loss: 1.45314781874184e-06, Final Batch Loss: 0.0\n",
      "Epoch 4147, Loss: 6.437812389847863e-07, Final Batch Loss: 8.65227800517232e-09\n",
      "Epoch 4148, Loss: 1.2530372490715536e-06, Final Batch Loss: 0.0\n",
      "Epoch 4149, Loss: 3.26277560103172e-06, Final Batch Loss: 0.0\n",
      "Epoch 4150, Loss: 3.2637193651541274e-05, Final Batch Loss: 5.466944458021317e-06\n",
      "Epoch 4151, Loss: 4.93313620086866e-06, Final Batch Loss: 2.191884931335153e-07\n",
      "Epoch 4152, Loss: 9.562528906936762e-06, Final Batch Loss: 0.0\n",
      "Epoch 4153, Loss: 0.0001785673428993384, Final Batch Loss: 0.0\n",
      "Epoch 4154, Loss: 5.170602278559144e-07, Final Batch Loss: 2.2592024251366638e-08\n",
      "Epoch 4155, Loss: 5.9105545831994455e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4156, Loss: 3.0624101821086214e-06, Final Batch Loss: 1.7550722759551718e-06\n",
      "Epoch 4157, Loss: 0.00011801055138882521, Final Batch Loss: 2.6918142381759935e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4158, Loss: 2.2983822889344196e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4159, Loss: 6.251228286124899e-07, Final Batch Loss: 0.0\n",
      "Epoch 4160, Loss: 1.0704701809416406e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4161, Loss: 5.887581704389078e-06, Final Batch Loss: 0.0\n",
      "Epoch 4162, Loss: 2.212541622137465e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4163, Loss: 5.498743036458364e-07, Final Batch Loss: 1.2978411234598752e-08\n",
      "Epoch 4164, Loss: 3.0904906798134846e-06, Final Batch Loss: 0.0\n",
      "Epoch 4165, Loss: 2.3628646799500608e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4166, Loss: 2.493872965914079e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4167, Loss: 1.3065317527871656e-07, Final Batch Loss: 0.0\n",
      "Epoch 4168, Loss: 9.929216562842846e-06, Final Batch Loss: 0.0\n",
      "Epoch 4169, Loss: 3.961031073929089e-05, Final Batch Loss: 0.0\n",
      "Epoch 4170, Loss: 9.489238694815327e-07, Final Batch Loss: 9.132964606806127e-09\n",
      "Epoch 4171, Loss: 7.24314655475844e-07, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4172, Loss: 1.7574390398511497e-07, Final Batch Loss: 3.364766598679125e-08\n",
      "Epoch 4173, Loss: 0.013234259013752747, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4174, Loss: 1.1358724568699685e-06, Final Batch Loss: 1.105568436798876e-08\n",
      "Epoch 4175, Loss: 3.3436523600993695e-06, Final Batch Loss: 0.0\n",
      "Epoch 4176, Loss: 1.862408645447733e-05, Final Batch Loss: 1.255952702194918e-05\n",
      "Epoch 4177, Loss: 3.184431184188874e-06, Final Batch Loss: 3.931818923774699e-07\n",
      "Epoch 4178, Loss: 9.93929482062672e-06, Final Batch Loss: 9.664638128015213e-06\n",
      "Epoch 4179, Loss: 1.8456987199710895e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4180, Loss: 1.0504966045932207e-06, Final Batch Loss: 8.17160117350113e-09\n",
      "Epoch 4181, Loss: 1.1267597156416898e-06, Final Batch Loss: 7.690914571867324e-09\n",
      "Epoch 4182, Loss: 1.9209307533518682e-06, Final Batch Loss: 3.604974665449845e-07\n",
      "Epoch 4183, Loss: 1.7460622391274327e-06, Final Batch Loss: 0.0\n",
      "Epoch 4184, Loss: 2.7199205365757706e-06, Final Batch Loss: 4.133859832222697e-08\n",
      "Epoch 4185, Loss: 4.268646928262676e-06, Final Batch Loss: 0.0\n",
      "Epoch 4186, Loss: 6.189836170289453e-07, Final Batch Loss: 8.171597620787452e-09\n",
      "Epoch 4187, Loss: 7.948741163055217e-07, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4188, Loss: 4.776197561007223e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4189, Loss: 3.1030988248970104e-06, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 4190, Loss: 1.9863306430778493e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4191, Loss: 1.346047855621535e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 4192, Loss: 0.00018688971451574776, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4193, Loss: 2.189679818243029e-06, Final Batch Loss: 3.845452312134512e-08\n",
      "Epoch 4194, Loss: 1.6647991902041248e-05, Final Batch Loss: 3.749310195644284e-08\n",
      "Epoch 4195, Loss: 1.1354924569606517e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4196, Loss: 4.0281076603032595e-05, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4197, Loss: 9.432247860319265e-06, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 4198, Loss: 8.299573118542014e-06, Final Batch Loss: 0.0\n",
      "Epoch 4199, Loss: 1.4270481076827934e-06, Final Batch Loss: 0.0\n",
      "Epoch 4200, Loss: 1.3669857640286054e-06, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 4201, Loss: 5.104919161835753e-07, Final Batch Loss: 3.5089772865148916e-08\n",
      "Epoch 4202, Loss: 4.3678568950600294e-07, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4203, Loss: 6.618974096594954e-07, Final Batch Loss: 7.690919012759423e-09\n",
      "Epoch 4204, Loss: 1.973448092940089e-06, Final Batch Loss: 7.690919012759423e-09\n",
      "Epoch 4205, Loss: 1.1481593193973794e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 4206, Loss: 2.066374503284507e-06, Final Batch Loss: 2.3168298923792463e-07\n",
      "Epoch 4207, Loss: 1.563978969332247e-06, Final Batch Loss: 0.0\n",
      "Epoch 4208, Loss: 4.8818472403455715e-06, Final Batch Loss: 5.77258958855964e-07\n",
      "Epoch 4209, Loss: 3.518950713155e-06, Final Batch Loss: 0.0\n",
      "Epoch 4210, Loss: 3.3939477141808894e-05, Final Batch Loss: 2.7686485282174544e-07\n",
      "Epoch 4211, Loss: 8.38226201416159e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4212, Loss: 2.915381357881941e-06, Final Batch Loss: 0.0\n",
      "Epoch 4213, Loss: 1.0918887571875757e-06, Final Batch Loss: 0.0\n",
      "Epoch 4214, Loss: 1.606934836306806e-07, Final Batch Loss: 0.0\n",
      "Epoch 4215, Loss: 8.291725195341826e-07, Final Batch Loss: 0.0\n",
      "Epoch 4216, Loss: 6.638064680153377e-07, Final Batch Loss: 7.690914571867324e-09\n",
      "Epoch 4217, Loss: 1.325515574412961e-06, Final Batch Loss: 0.0\n",
      "Epoch 4218, Loss: 5.3846388397005285e-06, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 4219, Loss: 4.458302045318163e-07, Final Batch Loss: 0.0\n",
      "Epoch 4220, Loss: 1.9216682916045613e-06, Final Batch Loss: 3.3069662208617956e-07\n",
      "Epoch 4221, Loss: 1.120924671971224e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4222, Loss: 9.157559388572878e-08, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 4223, Loss: 1.3426406382244238e-06, Final Batch Loss: 3.845459062290502e-09\n",
      "Epoch 4224, Loss: 0.00010538873718812791, Final Batch Loss: 7.83506663992739e-08\n",
      "Epoch 4225, Loss: 2.7243778955021725e-07, Final Batch Loss: 8.027319609027472e-08\n",
      "Epoch 4226, Loss: 2.40366924475488e-07, Final Batch Loss: 5.287506432694045e-09\n",
      "Epoch 4227, Loss: 7.2364216379128266e-06, Final Batch Loss: 0.0\n",
      "Epoch 4228, Loss: 7.625901392915857e-06, Final Batch Loss: 0.0\n",
      "Epoch 4229, Loss: 3.527872948883015e-06, Final Batch Loss: 5.594797016783559e-07\n",
      "Epoch 4230, Loss: 8.28084932291695e-07, Final Batch Loss: 1.5910281092601508e-07\n",
      "Epoch 4231, Loss: 2.005249036818313e-07, Final Batch Loss: 3.1724955107392816e-08\n",
      "Epoch 4232, Loss: 1.0090831248366072e-06, Final Batch Loss: 7.786999134395955e-08\n",
      "Epoch 4233, Loss: 3.955574336134138e-05, Final Batch Loss: 0.0\n",
      "Epoch 4234, Loss: 1.198121567291821e-06, Final Batch Loss: 1.696775768778025e-07\n",
      "Epoch 4235, Loss: 3.3467882311954966e-05, Final Batch Loss: 4.3741994915080795e-08\n",
      "Epoch 4236, Loss: 3.6530337610418684e-07, Final Batch Loss: 6.24887119826667e-09\n",
      "Epoch 4237, Loss: 7.548163796999852e-06, Final Batch Loss: 0.0\n",
      "Epoch 4238, Loss: 4.9442890543649476e-05, Final Batch Loss: 1.345909161898362e-08\n",
      "Epoch 4239, Loss: 5.85536030661693e-07, Final Batch Loss: 0.0\n",
      "Epoch 4240, Loss: 1.057602121656842e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4241, Loss: 4.481006041778812e-06, Final Batch Loss: 2.0669300937470325e-08\n",
      "Epoch 4242, Loss: 1.7087170927077011e-06, Final Batch Loss: 0.0\n",
      "Epoch 4243, Loss: 1.3975511858888012e-07, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4244, Loss: 2.3474209789320355e-06, Final Batch Loss: 1.3456879059958737e-06\n",
      "Epoch 4245, Loss: 2.3553819613608695e-06, Final Batch Loss: 3.1868000860413304e-07\n",
      "Epoch 4246, Loss: 1.4819103293373104e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4247, Loss: 1.9330787794924476e-06, Final Batch Loss: 1.1539540309968288e-06\n",
      "Epoch 4248, Loss: 1.5647079454339519e-06, Final Batch Loss: 1.0622956381212134e-07\n",
      "Epoch 4249, Loss: 4.832395951392954e-06, Final Batch Loss: 0.0\n",
      "Epoch 4250, Loss: 8.736033175749114e-07, Final Batch Loss: 7.690914571867324e-09\n",
      "Epoch 4251, Loss: 1.3359483052255428e-05, Final Batch Loss: 2.9008513138251146e-06\n",
      "Epoch 4252, Loss: 1.4932755894037086e-06, Final Batch Loss: 0.0\n",
      "Epoch 4253, Loss: 8.506554437515135e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4254, Loss: 4.592530776892367e-06, Final Batch Loss: 1.9011321228390443e-06\n",
      "Epoch 4255, Loss: 1.3160986422899867e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4256, Loss: 1.3814057769900856e-06, Final Batch Loss: 1.297841656366927e-08\n",
      "Epoch 4257, Loss: 2.654812039093457e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4258, Loss: 2.4690046429576284e-06, Final Batch Loss: 1.8986516181485058e-07\n",
      "Epoch 4259, Loss: 6.756704888921661e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4260, Loss: 2.6014476912750162e-05, Final Batch Loss: 1.345909161898362e-08\n",
      "Epoch 4261, Loss: 1.3687059530198553e-07, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 4262, Loss: 2.005122051285113e-06, Final Batch Loss: 2.3072704635751506e-08\n",
      "Epoch 4263, Loss: 0.00020349399226649023, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4264, Loss: 4.2829906810037954e-07, Final Batch Loss: 1.2978409458241913e-08\n",
      "Epoch 4265, Loss: 2.0087094074749956e-05, Final Batch Loss: 8.65227978152916e-09\n",
      "Epoch 4266, Loss: 1.0983812366638368e-05, Final Batch Loss: 5.77942910240381e-06\n",
      "Epoch 4267, Loss: 4.662666495014456e-06, Final Batch Loss: 3.749306998201973e-08\n",
      "Epoch 4268, Loss: 2.2648022760529685e-06, Final Batch Loss: 2.007792090807925e-06\n",
      "Epoch 4269, Loss: 2.439165746936922e-06, Final Batch Loss: 3.749151176180021e-07\n",
      "Epoch 4270, Loss: 1.0737250605297177e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4271, Loss: 9.157446568819338e-07, Final Batch Loss: 3.076358723319572e-08\n",
      "Epoch 4272, Loss: 1.9693557495870095e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4273, Loss: 5.616371316907731e-07, Final Batch Loss: 5.287483872962184e-08\n",
      "Epoch 4274, Loss: 6.503912548527779e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4275, Loss: 1.0341468776875473e-06, Final Batch Loss: 5.883129574613122e-07\n",
      "Epoch 4276, Loss: 1.383677005639683e-06, Final Batch Loss: 0.0\n",
      "Epoch 4277, Loss: 3.2281805217859727e-07, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4278, Loss: 6.599316242361652e-07, Final Batch Loss: 0.0\n",
      "Epoch 4279, Loss: 1.800576390020847e-05, Final Batch Loss: 0.0\n",
      "Epoch 4280, Loss: 2.130755884488522e-05, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 4281, Loss: 2.7180184613007086e-06, Final Batch Loss: 0.0\n",
      "Epoch 4282, Loss: 1.1610207225620783e-06, Final Batch Loss: 0.0\n",
      "Epoch 4283, Loss: 7.990829711590486e-06, Final Batch Loss: 7.630823347426485e-06\n",
      "Epoch 4284, Loss: 3.295349594178987e-05, Final Batch Loss: 1.7785220407517954e-08\n",
      "Epoch 4285, Loss: 4.606410615171086e-07, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4286, Loss: 1.8668992423531705e-05, Final Batch Loss: 0.0\n",
      "Epoch 4287, Loss: 2.7254732869463894e-06, Final Batch Loss: 8.550444476895791e-07\n",
      "Epoch 4288, Loss: 4.906492722223099e-06, Final Batch Loss: 9.613643214834156e-09\n",
      "Epoch 4289, Loss: 1.3064945111107562e-05, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4290, Loss: 8.377580396068396e-07, Final Batch Loss: 0.0\n",
      "Epoch 4291, Loss: 2.804403902434416e-07, Final Batch Loss: 8.65227800517232e-09\n",
      "Epoch 4292, Loss: 7.290611734322994e-07, Final Batch Loss: 0.0\n",
      "Epoch 4293, Loss: 9.479257893074688e-07, Final Batch Loss: 1.7977144750602747e-07\n",
      "Epoch 4294, Loss: 1.8405683166466957e-07, Final Batch Loss: 0.0\n",
      "Epoch 4295, Loss: 1.1386494576104411e-06, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4296, Loss: 1.2452295128362323e-07, Final Batch Loss: 8.652282446064419e-09\n",
      "Epoch 4297, Loss: 1.644253332822032e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4298, Loss: 5.255653823255102e-06, Final Batch Loss: 0.0\n",
      "Epoch 4299, Loss: 3.878110477306684e-06, Final Batch Loss: 0.0\n",
      "Epoch 4300, Loss: 2.4317378893856656e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4301, Loss: 1.287989021092617e-05, Final Batch Loss: 0.0\n",
      "Epoch 4302, Loss: 6.923400401870339e-07, Final Batch Loss: 0.0\n",
      "Epoch 4303, Loss: 2.7137041266334094e-06, Final Batch Loss: 4.42225598362711e-08\n",
      "Epoch 4304, Loss: 1.8358105791094204e-07, Final Batch Loss: 0.0\n",
      "Epoch 4305, Loss: 5.883525159733338e-06, Final Batch Loss: 4.271006218914408e-06\n",
      "Epoch 4306, Loss: 3.4838705305073603e-06, Final Batch Loss: 2.4514738683478754e-08\n",
      "Epoch 4307, Loss: 0.0001529691078345774, Final Batch Loss: 3.917392064067826e-07\n",
      "Epoch 4308, Loss: 1.1571654644160212e-05, Final Batch Loss: 6.152707499040844e-08\n",
      "Epoch 4309, Loss: 1.3033316761390523e-06, Final Batch Loss: 8.556087749411745e-08\n",
      "Epoch 4310, Loss: 1.8412381708188263e-07, Final Batch Loss: 8.171597620787452e-09\n",
      "Epoch 4311, Loss: 1.2745309209138966e-06, Final Batch Loss: 0.0\n",
      "Epoch 4312, Loss: 5.8141394956967574e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4313, Loss: 1.8505005421332044e-06, Final Batch Loss: 2.393731222127826e-07\n",
      "Epoch 4314, Loss: 6.543180638418633e-07, Final Batch Loss: 1.3362767958824406e-07\n",
      "Epoch 4315, Loss: 2.268046503273169e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4316, Loss: 8.680324391607819e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 4317, Loss: 1.8032944731904976e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4318, Loss: 3.4585775388062956e-06, Final Batch Loss: 3.3647775676826086e-09\n",
      "Epoch 4319, Loss: 4.4917904062913294e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4320, Loss: 7.3809117863143925e-06, Final Batch Loss: 0.0\n",
      "Epoch 4321, Loss: 2.505760128834744e-06, Final Batch Loss: 1.0575003983603892e-08\n",
      "Epoch 4322, Loss: 4.540733299362998e-07, Final Batch Loss: 1.7304552457630962e-08\n",
      "Epoch 4323, Loss: 9.680918366949953e-08, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4324, Loss: 1.975819972965809e-06, Final Batch Loss: 1.2737888255287544e-07\n",
      "Epoch 4325, Loss: 0.00012962349034428833, Final Batch Loss: 0.0\n",
      "Epoch 4326, Loss: 2.90332324648368e-06, Final Batch Loss: 3.4128362358387676e-08\n",
      "Epoch 4327, Loss: 1.5877931133223555e-06, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 4328, Loss: 3.924479172190409e-06, Final Batch Loss: 0.0\n",
      "Epoch 4329, Loss: 1.321473208082402e-06, Final Batch Loss: 2.1005283201702696e-07\n",
      "Epoch 4330, Loss: 5.885557459173185e-06, Final Batch Loss: 1.8785507336360752e-06\n",
      "Epoch 4331, Loss: 4.411250078217854e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4332, Loss: 4.681956437180279e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4333, Loss: 1.5928521068797608e-07, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4334, Loss: 8.678405827300395e-08, Final Batch Loss: 0.0\n",
      "Epoch 4335, Loss: 1.6214417382087731e-06, Final Batch Loss: 0.0\n",
      "Epoch 4336, Loss: 1.878778113084678e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4337, Loss: 5.906495709750992e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4338, Loss: 8.123233777856953e-07, Final Batch Loss: 9.85393384667077e-08\n",
      "Epoch 4339, Loss: 1.593817297029787e-07, Final Batch Loss: 1.4901141653922423e-08\n",
      "Epoch 4340, Loss: 7.576392597741233e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4341, Loss: 1.2206688984051084e-06, Final Batch Loss: 0.0\n",
      "Epoch 4342, Loss: 4.320620561237831e-05, Final Batch Loss: 6.7295511385623286e-09\n",
      "Epoch 4343, Loss: 4.410765767071112e-07, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 4344, Loss: 1.156288347514689e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4345, Loss: 8.280248592340556e-07, Final Batch Loss: 6.926041464794253e-07\n",
      "Epoch 4346, Loss: 2.1031591600495503e-06, Final Batch Loss: 2.211134031426809e-08\n",
      "Epoch 4347, Loss: 1.32132822905362e-07, Final Batch Loss: 6.24887119826667e-09\n",
      "Epoch 4348, Loss: 1.383169668800477e-07, Final Batch Loss: 4.326141223032209e-09\n",
      "Epoch 4349, Loss: 6.561800078408453e-06, Final Batch Loss: 0.0\n",
      "Epoch 4350, Loss: 2.3032969331815423e-07, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 4351, Loss: 1.1240037861903751e-05, Final Batch Loss: 3.845459062290502e-09\n",
      "Epoch 4352, Loss: 6.6467285859683756e-06, Final Batch Loss: 0.0\n",
      "Epoch 4353, Loss: 1.3017957178895756e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4354, Loss: 1.0508803442998982e-06, Final Batch Loss: 0.0\n",
      "Epoch 4355, Loss: 4.365107447168448e-06, Final Batch Loss: 4.326141223032209e-09\n",
      "Epoch 4356, Loss: 9.088936877565956e-07, Final Batch Loss: 1.105568436798876e-08\n",
      "Epoch 4357, Loss: 7.176256232588329e-07, Final Batch Loss: 0.0\n",
      "Epoch 4358, Loss: 4.646261243301808e-06, Final Batch Loss: 0.0\n",
      "Epoch 4359, Loss: 2.451109701873122e-07, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 4360, Loss: 2.8713218469533786e-07, Final Batch Loss: 1.0094321822862184e-08\n",
      "Epoch 4361, Loss: 1.9697124631345986e-07, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 4362, Loss: 3.8479325559226396e-07, Final Batch Loss: 0.0\n",
      "Epoch 4363, Loss: 2.4366153383859057e-07, Final Batch Loss: 0.0\n",
      "Epoch 4364, Loss: 2.2991408735739682e-06, Final Batch Loss: 1.8585534462545183e-06\n",
      "Epoch 4365, Loss: 4.485274826548924e-06, Final Batch Loss: 1.2017049577650596e-08\n",
      "Epoch 4366, Loss: 2.0604054056239107e-06, Final Batch Loss: 0.0\n",
      "Epoch 4367, Loss: 2.8085343362072024e-07, Final Batch Loss: 0.0\n",
      "Epoch 4368, Loss: 8.239628909167962e-07, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4369, Loss: 7.184704970963907e-07, Final Batch Loss: 1.6679388181728427e-07\n",
      "Epoch 4370, Loss: 5.244094910539232e-07, Final Batch Loss: 4.662354626816523e-07\n",
      "Epoch 4371, Loss: 8.924928676101729e-07, Final Batch Loss: 4.806797448964062e-08\n",
      "Epoch 4372, Loss: 3.476098914267922e-07, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4373, Loss: 1.2281988887030693e-06, Final Batch Loss: 0.0\n",
      "Epoch 4374, Loss: 1.7452075828927605e-07, Final Batch Loss: 0.0\n",
      "Epoch 4375, Loss: 3.771721957246399e-05, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4376, Loss: 3.086371345939476e-06, Final Batch Loss: 3.845459062290502e-09\n",
      "Epoch 4377, Loss: 1.058174329793271e-05, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 4378, Loss: 2.122918881242164e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4379, Loss: 1.5386489066182563e-06, Final Batch Loss: 1.634317570164967e-08\n",
      "Epoch 4380, Loss: 1.403186654980182e-06, Final Batch Loss: 0.0\n",
      "Epoch 4381, Loss: 1.5527936496617656e-06, Final Batch Loss: 0.0\n",
      "Epoch 4382, Loss: 2.668078614043168e-06, Final Batch Loss: 0.0\n",
      "Epoch 4383, Loss: 1.7857012202249223e-07, Final Batch Loss: 2.932153364554324e-08\n",
      "Epoch 4384, Loss: 3.188509135054751e-06, Final Batch Loss: 2.1149979545498354e-08\n",
      "Epoch 4385, Loss: 1.9824940722390494e-07, Final Batch Loss: 1.6487088316807785e-07\n",
      "Epoch 4386, Loss: 3.305094776306916e-06, Final Batch Loss: 4.326141223032209e-09\n",
      "Epoch 4387, Loss: 2.5605861730948476e-07, Final Batch Loss: 0.0\n",
      "Epoch 4388, Loss: 8.295973514593769e-06, Final Batch Loss: 3.105090513599862e-07\n",
      "Epoch 4389, Loss: 1.5783040951955485e-07, Final Batch Loss: 0.0\n",
      "Epoch 4390, Loss: 7.047311302299519e-07, Final Batch Loss: 0.0\n",
      "Epoch 4391, Loss: 1.4923594696680809e-06, Final Batch Loss: 0.0\n",
      "Epoch 4392, Loss: 4.719203843706055e-06, Final Batch Loss: 0.0\n",
      "Epoch 4393, Loss: 1.6463882093198379e-06, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 4394, Loss: 3.157810690712637e-07, Final Batch Loss: 1.4901133660316646e-08\n",
      "Epoch 4395, Loss: 6.298910061319773e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4396, Loss: 2.336477482600685e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4397, Loss: 0.0014969683849721527, Final Batch Loss: 1.5862495317264802e-08\n",
      "Epoch 4398, Loss: 2.3800927999251265e-05, Final Batch Loss: 1.099171640817076e-06\n",
      "Epoch 4399, Loss: 6.871143863884654e-07, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 4400, Loss: 1.2547220205272325e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4401, Loss: 3.6106466860807984e-07, Final Batch Loss: 1.345909161898362e-08\n",
      "Epoch 4402, Loss: 7.903450858659511e-06, Final Batch Loss: 0.0\n",
      "Epoch 4403, Loss: 1.0741098765976176e-07, Final Batch Loss: 1.5381814932879934e-08\n",
      "Epoch 4404, Loss: 1.3733780477975799e-05, Final Batch Loss: 0.0\n",
      "Epoch 4405, Loss: 1.380353223945363e-07, Final Batch Loss: 2.8840879906510963e-08\n",
      "Epoch 4406, Loss: 1.4146588468433308e-06, Final Batch Loss: 0.0\n",
      "Epoch 4407, Loss: 2.3106631260594312e-06, Final Batch Loss: 0.0\n",
      "Epoch 4408, Loss: 1.3495565615695426e-05, Final Batch Loss: 0.0\n",
      "Epoch 4409, Loss: 3.909991771466892e-07, Final Batch Loss: 0.0\n",
      "Epoch 4410, Loss: 4.8087891303394414e-06, Final Batch Loss: 0.0\n",
      "Epoch 4411, Loss: 7.877471870876285e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4412, Loss: 4.584139203123172e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4413, Loss: 4.499072709496232e-06, Final Batch Loss: 0.0\n",
      "Epoch 4414, Loss: 3.1185570914527005e-07, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4415, Loss: 1.5207091019764363e-06, Final Batch Loss: 1.4105601167102577e-06\n",
      "Epoch 4416, Loss: 1.1453084914903044e-06, Final Batch Loss: 0.0\n",
      "Epoch 4417, Loss: 4.911412432306861e-08, Final Batch Loss: 0.0\n",
      "Epoch 4418, Loss: 3.0810916118451104e-06, Final Batch Loss: 0.0\n",
      "Epoch 4419, Loss: 1.0875603739801676e-07, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 4420, Loss: 6.026794612257191e-07, Final Batch Loss: 0.0\n",
      "Epoch 4421, Loss: 2.293564849153995e-07, Final Batch Loss: 0.0\n",
      "Epoch 4422, Loss: 3.85752549858509e-06, Final Batch Loss: 0.0\n",
      "Epoch 4423, Loss: 7.128129682065776e-07, Final Batch Loss: 0.0\n",
      "Epoch 4424, Loss: 6.055819701256127e-08, Final Batch Loss: 0.0\n",
      "Epoch 4425, Loss: 0.00045366160498849784, Final Batch Loss: 0.0\n",
      "Epoch 4426, Loss: 5.8401321333168e-05, Final Batch Loss: 2.4514742236192433e-08\n",
      "Epoch 4427, Loss: 8.956626287759395e-05, Final Batch Loss: 4.400689431349747e-05\n",
      "Epoch 4428, Loss: 0.004492826817304674, Final Batch Loss: 0.0\n",
      "Epoch 4429, Loss: 0.0025406296919094906, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4430, Loss: 0.049894686585905235, Final Batch Loss: 0.0\n",
      "Epoch 4431, Loss: 0.01880529012774612, Final Batch Loss: 4.326142555299839e-09\n",
      "Epoch 4432, Loss: 0.006646253621801046, Final Batch Loss: 1.2161089557594096e-07\n",
      "Epoch 4433, Loss: 0.00016903670586931874, Final Batch Loss: 1.2978409458241913e-08\n",
      "Epoch 4434, Loss: 0.00012462512872035703, Final Batch Loss: 3.845459062290502e-09\n",
      "Epoch 4435, Loss: 5.449718963657091e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4436, Loss: 1.1246600706282806e-05, Final Batch Loss: 1.5993946362868883e-06\n",
      "Epoch 4437, Loss: 1.788401782476523e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4438, Loss: 0.004151692709519872, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4439, Loss: 0.00041502663362613657, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4440, Loss: 0.0008079369566811323, Final Batch Loss: 4.2490253804317035e-07\n",
      "Epoch 4441, Loss: 0.00023089829377032078, Final Batch Loss: 0.00023034469631966203\n",
      "Epoch 4442, Loss: 3.714535370402672e-07, Final Batch Loss: 0.0\n",
      "Epoch 4443, Loss: 8.693627896239065e-06, Final Batch Loss: 3.4723987027973635e-06\n",
      "Epoch 4444, Loss: 0.00016686765814355464, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4445, Loss: 2.2805944167592074e-06, Final Batch Loss: 0.0\n",
      "Epoch 4446, Loss: 3.404581980781529e-07, Final Batch Loss: 0.0\n",
      "Epoch 4447, Loss: 9.23474605372121e-05, Final Batch Loss: 0.0\n",
      "Epoch 4448, Loss: 3.710194474981776e-06, Final Batch Loss: 3.364776901548794e-09\n",
      "Epoch 4449, Loss: 2.310372399838556e-06, Final Batch Loss: 6.2488698659990405e-09\n",
      "Epoch 4450, Loss: 1.321230872264323e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4451, Loss: 1.946444420819482e-05, Final Batch Loss: 4.181918100698567e-08\n",
      "Epoch 4452, Loss: 1.751533257654536e-05, Final Batch Loss: 2.211134031426809e-08\n",
      "Epoch 4453, Loss: 2.1181317882090767e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4454, Loss: 0.00023557174579003082, Final Batch Loss: 0.0\n",
      "Epoch 4455, Loss: 1.4309656004574123e-07, Final Batch Loss: 6.537253938176946e-08\n",
      "Epoch 4456, Loss: 1.2693454879975086e-05, Final Batch Loss: 0.0\n",
      "Epoch 4457, Loss: 9.372992399447888e-05, Final Batch Loss: 0.0\n",
      "Epoch 4458, Loss: 8.962652624400214e-06, Final Batch Loss: 0.0\n",
      "Epoch 4459, Loss: 1.190029056519215e-06, Final Batch Loss: 0.0\n",
      "Epoch 4460, Loss: 8.345351387717415e-08, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4461, Loss: 2.351922817167562e-06, Final Batch Loss: 0.0\n",
      "Epoch 4462, Loss: 3.213811123892185e-07, Final Batch Loss: 0.0\n",
      "Epoch 4463, Loss: 9.908302087691112e-07, Final Batch Loss: 3.845459950468921e-09\n",
      "Epoch 4464, Loss: 5.313582467136868e-06, Final Batch Loss: 5.3836128444118e-08\n",
      "Epoch 4465, Loss: 5.769553265144722e-07, Final Batch Loss: 0.0\n",
      "Epoch 4466, Loss: 0.00015610116717146294, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4467, Loss: 8.335041022045075e-06, Final Batch Loss: 0.0\n",
      "Epoch 4468, Loss: 1.807195982861387e-07, Final Batch Loss: 0.0\n",
      "Epoch 4469, Loss: 6.465722807158514e-07, Final Batch Loss: 0.0\n",
      "Epoch 4470, Loss: 9.870491790575642e-08, Final Batch Loss: 0.0\n",
      "Epoch 4471, Loss: 8.486203743451881e-05, Final Batch Loss: 0.0\n",
      "Epoch 4472, Loss: 2.8518393582199764e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4473, Loss: 2.7663404977840145e-07, Final Batch Loss: 9.613641438477316e-09\n",
      "Epoch 4474, Loss: 1.9943202500538604e-07, Final Batch Loss: 7.402444168747024e-08\n",
      "Epoch 4475, Loss: 2.432766733617697e-07, Final Batch Loss: 7.11403984610115e-08\n",
      "Epoch 4476, Loss: 8.05852820029429e-08, Final Batch Loss: 0.0\n",
      "Epoch 4477, Loss: 1.5509626063447968e-06, Final Batch Loss: 0.0\n",
      "Epoch 4478, Loss: 8.778371203277402e-07, Final Batch Loss: 0.0\n",
      "Epoch 4479, Loss: 2.149579944488167e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 4480, Loss: 3.7287365683980056e-07, Final Batch Loss: 0.0\n",
      "Epoch 4481, Loss: 6.675719199655816e-09, Final Batch Loss: 0.0\n",
      "Epoch 4482, Loss: 2.418318596486557e-07, Final Batch Loss: 9.613641438477316e-09\n",
      "Epoch 4483, Loss: 1.2206970134709394e-07, Final Batch Loss: 0.0\n",
      "Epoch 4484, Loss: 3.3316954199946736e-06, Final Batch Loss: 4.590257560721511e-07\n",
      "Epoch 4485, Loss: 2.3606232988360176e-06, Final Batch Loss: 0.0\n",
      "Epoch 4486, Loss: 2.5972386131778435e-06, Final Batch Loss: 1.7757312207322684e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4487, Loss: 4.4450002137930156e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4488, Loss: 7.604836157470984e-07, Final Batch Loss: 0.0\n",
      "Epoch 4489, Loss: 1.168940569251653e-05, Final Batch Loss: 0.0\n",
      "Epoch 4490, Loss: 2.3511702240686105e-07, Final Batch Loss: 4.806823827863127e-09\n",
      "Epoch 4491, Loss: 4.025811878305419e-06, Final Batch Loss: 0.0\n",
      "Epoch 4492, Loss: 3.6382158452585855e-07, Final Batch Loss: 0.0\n",
      "Epoch 4493, Loss: 7.638570614920681e-07, Final Batch Loss: 0.0\n",
      "Epoch 4494, Loss: 1.0967251440341386e-08, Final Batch Loss: 0.0\n",
      "Epoch 4495, Loss: 4.1976929598952495e-08, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4496, Loss: 2.650539453585843e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4497, Loss: 2.534293701561552e-06, Final Batch Loss: 0.0\n",
      "Epoch 4498, Loss: 2.8945010315251096e-06, Final Batch Loss: 1.345909161898362e-08\n",
      "Epoch 4499, Loss: 1.8073295493525876e-07, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4500, Loss: 1.678441490238214e-07, Final Batch Loss: 0.0\n",
      "Epoch 4501, Loss: 6.064970616836973e-07, Final Batch Loss: 0.0\n",
      "Epoch 4502, Loss: 3.3378575459153126e-08, Final Batch Loss: 0.0\n",
      "Epoch 4503, Loss: 8.821461916497242e-08, Final Batch Loss: 0.0\n",
      "Epoch 4504, Loss: 1.7452112044402668e-07, Final Batch Loss: 0.0\n",
      "Epoch 4505, Loss: 6.098674414367622e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4506, Loss: 6.570571068342801e-07, Final Batch Loss: 0.0\n",
      "Epoch 4507, Loss: 1.8169406224011198e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 4508, Loss: 8.201573908905857e-08, Final Batch Loss: 0.0\n",
      "Epoch 4509, Loss: 7.247904110219139e-08, Final Batch Loss: 0.0\n",
      "Epoch 4510, Loss: 7.90925426438216e-05, Final Batch Loss: 0.0\n",
      "Epoch 4511, Loss: 6.150905458301992e-07, Final Batch Loss: 0.0\n",
      "Epoch 4512, Loss: 1.3925024855421242e-07, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4513, Loss: 4.927263663301318e-06, Final Batch Loss: 2.2111352748765967e-08\n",
      "Epoch 4514, Loss: 1.1008751492624924e-06, Final Batch Loss: 0.0\n",
      "Epoch 4515, Loss: 1.7444628639395887e-06, Final Batch Loss: 0.0\n",
      "Epoch 4516, Loss: 3.528591552282023e-08, Final Batch Loss: 0.0\n",
      "Epoch 4517, Loss: 1.0279332005591613e-06, Final Batch Loss: 5.277549348647881e-07\n",
      "Epoch 4518, Loss: 5.111521230727334e-07, Final Batch Loss: 0.0\n",
      "Epoch 4519, Loss: 5.722044615907862e-09, Final Batch Loss: 0.0\n",
      "Epoch 4520, Loss: 7.151568403696018e-06, Final Batch Loss: 1.7304538246776247e-08\n",
      "Epoch 4521, Loss: 2.6590309809559898e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4522, Loss: 0.0028132585490224793, Final Batch Loss: 4.518391349961348e-08\n",
      "Epoch 4523, Loss: 0.013259228878082285, Final Batch Loss: 0.013039578683674335\n",
      "Epoch 4524, Loss: 0.025124791646994327, Final Batch Loss: 3.4609044519129384e-08\n",
      "Epoch 4525, Loss: 0.004297637876844895, Final Batch Loss: 6.44112816416964e-08\n",
      "Epoch 4526, Loss: 0.0038811807414318444, Final Batch Loss: 0.0028634490445256233\n",
      "Epoch 4527, Loss: 3.7553180946003906e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4528, Loss: 1.0560673721959901e-05, Final Batch Loss: 9.877628599497257e-07\n",
      "Epoch 4529, Loss: 0.0008767109984526567, Final Batch Loss: 1.8746598939856085e-08\n",
      "Epoch 4530, Loss: 1.067235885032769e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4531, Loss: 6.786586498774838e-06, Final Batch Loss: 0.0\n",
      "Epoch 4532, Loss: 1.9210559152327278e-06, Final Batch Loss: 0.0\n",
      "Epoch 4533, Loss: 6.375152783011373e-06, Final Batch Loss: 6.834727628302062e-07\n",
      "Epoch 4534, Loss: 2.4389472487618136e-05, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 4535, Loss: 4.657296202470462e-06, Final Batch Loss: 1.82659043446165e-08\n",
      "Epoch 4536, Loss: 5.437463287405464e-07, Final Batch Loss: 2.0669325806466077e-08\n",
      "Epoch 4537, Loss: 0.0005247197018981575, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4538, Loss: 3.852420258909639e-06, Final Batch Loss: 2.2735723348432657e-07\n",
      "Epoch 4539, Loss: 6.990145742236109e-07, Final Batch Loss: 0.0\n",
      "Epoch 4540, Loss: 1.871103715334055e-05, Final Batch Loss: 4.2299848956872665e-08\n",
      "Epoch 4541, Loss: 7.092513662487754e-06, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4542, Loss: 1.7576629642857e-06, Final Batch Loss: 5.066077051196771e-07\n",
      "Epoch 4543, Loss: 1.8824521901272817e-06, Final Batch Loss: 0.0\n",
      "Epoch 4544, Loss: 7.281087733845837e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4545, Loss: 4.799588838011459e-05, Final Batch Loss: 4.5664606318496226e-08\n",
      "Epoch 4546, Loss: 5.53592451879581e-07, Final Batch Loss: 0.0\n",
      "Epoch 4547, Loss: 3.140346450880571e-06, Final Batch Loss: 3.4128369463815034e-08\n",
      "Epoch 4548, Loss: 3.70502299285036e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4549, Loss: 0.00018312028880262954, Final Batch Loss: 0.0\n",
      "Epoch 4550, Loss: 9.723822590013143e-06, Final Batch Loss: 3.974727405875456e-06\n",
      "Epoch 4551, Loss: 6.403699318591194e-07, Final Batch Loss: 0.0\n",
      "Epoch 4552, Loss: 8.167814978587984e-06, Final Batch Loss: 0.0\n",
      "Epoch 4553, Loss: 8.583105619575093e-07, Final Batch Loss: 4.806824716041547e-09\n",
      "Epoch 4554, Loss: 8.567542276960438e-06, Final Batch Loss: 0.0\n",
      "Epoch 4555, Loss: 1.8267769760216268e-06, Final Batch Loss: 3.7395372487480927e-07\n",
      "Epoch 4556, Loss: 1.421926247857641e-07, Final Batch Loss: 1.2017046913115337e-08\n",
      "Epoch 4557, Loss: 1.151016662204185e-06, Final Batch Loss: 0.0\n",
      "Epoch 4558, Loss: 6.603940050142754e-06, Final Batch Loss: 1.0094321822862184e-08\n",
      "Epoch 4559, Loss: 4.6032961731334865e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 4560, Loss: 1.1164637717109294e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4561, Loss: 1.4092905519791366e-05, Final Batch Loss: 0.0\n",
      "Epoch 4562, Loss: 0.021230053411374405, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4563, Loss: 4.845215229987154e-05, Final Batch Loss: 1.586249709362164e-08\n",
      "Epoch 4564, Loss: 0.010848385697190932, Final Batch Loss: 1.951524239984792e-07\n",
      "Epoch 4565, Loss: 3.871514363096296e-06, Final Batch Loss: 1.2545622496418218e-07\n",
      "Epoch 4566, Loss: 3.0435473326706486e-05, Final Batch Loss: 2.8797048798878677e-06\n",
      "Epoch 4567, Loss: 0.02586974119004537, Final Batch Loss: 4.470328107686328e-08\n",
      "Epoch 4568, Loss: 0.014555700019821094, Final Batch Loss: 9.613542317765678e-08\n",
      "Epoch 4569, Loss: 0.003404436989734916, Final Batch Loss: 1.2978425445453468e-08\n",
      "Epoch 4570, Loss: 0.0038554888885471428, Final Batch Loss: 6.344998837448657e-08\n",
      "Epoch 4571, Loss: 0.00010572157390953407, Final Batch Loss: 1.6825255215735524e-06\n",
      "Epoch 4572, Loss: 9.609407620736476e-06, Final Batch Loss: 4.8068251601307566e-09\n",
      "Epoch 4573, Loss: 4.206485431335061e-05, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4574, Loss: 3.412154309434534e-06, Final Batch Loss: 8.17160206167955e-09\n",
      "Epoch 4575, Loss: 0.0001733715197239638, Final Batch Loss: 9.950034751682324e-08\n",
      "Epoch 4576, Loss: 2.246463291077916e-05, Final Batch Loss: 2.1239662601146847e-05\n",
      "Epoch 4577, Loss: 4.2143150003060015e-06, Final Batch Loss: 4.422263089054468e-08\n",
      "Epoch 4578, Loss: 0.00016664741131444671, Final Batch Loss: 3.4030955475827795e-07\n",
      "Epoch 4579, Loss: 0.0002577092044673268, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4580, Loss: 8.850630170975649e-06, Final Batch Loss: 1.5898644960543606e-06\n",
      "Epoch 4581, Loss: 2.096699458353779e-05, Final Batch Loss: 3.4008376132987905e-06\n",
      "Epoch 4582, Loss: 6.131962298194793e-05, Final Batch Loss: 3.5089772865148916e-08\n",
      "Epoch 4583, Loss: 1.9301288689987928e-05, Final Batch Loss: 2.5667770842119353e-07\n",
      "Epoch 4584, Loss: 0.00010231772924351734, Final Batch Loss: 3.364768019764597e-08\n",
      "Epoch 4585, Loss: 6.330855487735043e-05, Final Batch Loss: 1.2017051354007435e-08\n",
      "Epoch 4586, Loss: 7.353516874941679e-05, Final Batch Loss: 2.0669331135536595e-08\n",
      "Epoch 4587, Loss: 5.903746798763265e-06, Final Batch Loss: 1.965969715911342e-07\n",
      "Epoch 4588, Loss: 4.283875518318325e-06, Final Batch Loss: 8.171600285322711e-09\n",
      "Epoch 4589, Loss: 3.783223143882797e-05, Final Batch Loss: 1.1337975820424617e-06\n",
      "Epoch 4590, Loss: 7.789871835472972e-06, Final Batch Loss: 1.8938555967906723e-07\n",
      "Epoch 4591, Loss: 2.828828959788865e-05, Final Batch Loss: 1.297841745184769e-08\n",
      "Epoch 4592, Loss: 2.2053335936411678e-05, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4593, Loss: 1.2745240347666886e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4594, Loss: 0.0001096149559934867, Final Batch Loss: 2.4034123580207734e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4595, Loss: 0.011700249745505542, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4596, Loss: 2.4127226186942963e-05, Final Batch Loss: 1.344018255622359e-05\n",
      "Epoch 4597, Loss: 4.087449502754303e-06, Final Batch Loss: 1.144015087106709e-07\n",
      "Epoch 4598, Loss: 2.824765718889566e-05, Final Batch Loss: 2.4832102099026088e-06\n",
      "Epoch 4599, Loss: 2.6772709780464865e-05, Final Batch Loss: 0.0\n",
      "Epoch 4600, Loss: 1.309112602099205e-05, Final Batch Loss: 3.2125665256899083e-06\n",
      "Epoch 4601, Loss: 0.003507331901145383, Final Batch Loss: 3.479254019111977e-06\n",
      "Epoch 4602, Loss: 4.863568994561973e-05, Final Batch Loss: 4.470339121098732e-08\n",
      "Epoch 4603, Loss: 3.0831691009147733e-06, Final Batch Loss: 1.3939555287834082e-07\n",
      "Epoch 4604, Loss: 1.6941033554207507e-05, Final Batch Loss: 3.941588033740118e-08\n",
      "Epoch 4605, Loss: 0.0001659557113597998, Final Batch Loss: 5.825514790558373e-07\n",
      "Epoch 4606, Loss: 5.91085287253712e-05, Final Batch Loss: 1.0977300917147659e-06\n",
      "Epoch 4607, Loss: 6.542561450173512e-05, Final Batch Loss: 1.682383481238503e-05\n",
      "Epoch 4608, Loss: 0.0005625620771292361, Final Batch Loss: 0.0004775197303388268\n",
      "Epoch 4609, Loss: 1.4651028500400898e-05, Final Batch Loss: 2.0669308042897683e-08\n",
      "Epoch 4610, Loss: 0.00017855304676273054, Final Batch Loss: 8.228717547353881e-07\n",
      "Epoch 4611, Loss: 2.780233169574764e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4612, Loss: 3.0416787117903965e-06, Final Batch Loss: 1.057501108903125e-08\n",
      "Epoch 4613, Loss: 1.6078999994562082e-05, Final Batch Loss: 1.874657939993085e-08\n",
      "Epoch 4614, Loss: 1.961510657122467e-06, Final Batch Loss: 1.586250064633532e-08\n",
      "Epoch 4615, Loss: 2.5817104103431632e-05, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 4616, Loss: 1.4433031721550194e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4617, Loss: 3.514144818417275e-05, Final Batch Loss: 0.0\n",
      "Epoch 4618, Loss: 3.610781118967843e-05, Final Batch Loss: 3.301493052276783e-05\n",
      "Epoch 4619, Loss: 1.1775123142765409e-05, Final Batch Loss: 2.884095406940901e-09\n",
      "Epoch 4620, Loss: 2.0401632498057154e-05, Final Batch Loss: 6.301510779849195e-07\n",
      "Epoch 4621, Loss: 3.960320350326896e-06, Final Batch Loss: 6.647325676567561e-07\n",
      "Epoch 4622, Loss: 0.00017967683015829294, Final Batch Loss: 3.7012391373991704e-08\n",
      "Epoch 4623, Loss: 2.1583573526218203e-06, Final Batch Loss: 1.3653940413860255e-06\n",
      "Epoch 4624, Loss: 7.306619972391459e-07, Final Batch Loss: 2.0188618776728617e-08\n",
      "Epoch 4625, Loss: 1.9352703374053704e-05, Final Batch Loss: 0.0\n",
      "Epoch 4626, Loss: 1.9424213907326404e-06, Final Batch Loss: 9.613646767547834e-09\n",
      "Epoch 4627, Loss: 6.80214112469546e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4628, Loss: 5.00165656047713e-06, Final Batch Loss: 2.4034125800653783e-09\n",
      "Epoch 4629, Loss: 1.1658340794973299e-06, Final Batch Loss: 0.0\n",
      "Epoch 4630, Loss: 4.306516769447821e-05, Final Batch Loss: 0.0\n",
      "Epoch 4631, Loss: 7.243417783353578e-07, Final Batch Loss: 6.248868977820621e-09\n",
      "Epoch 4632, Loss: 1.2597494006838517e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4633, Loss: 0.0001446882345660372, Final Batch Loss: 1.7785248829227385e-08\n",
      "Epoch 4634, Loss: 1.1491502822091881e-05, Final Batch Loss: 1.5862514857190035e-08\n",
      "Epoch 4635, Loss: 1.0799041668674292e-05, Final Batch Loss: 6.681435849031914e-08\n",
      "Epoch 4636, Loss: 2.4950416053215463e-06, Final Batch Loss: 2.059694907075027e-06\n",
      "Epoch 4637, Loss: 1.5657257452117435e-05, Final Batch Loss: 1.1250050192757044e-05\n",
      "Epoch 4638, Loss: 0.0003516371959668696, Final Batch Loss: 0.00034916927688755095\n",
      "Epoch 4639, Loss: 1.4776089267698467e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 4640, Loss: 9.672982824726617e-06, Final Batch Loss: 2.2495331108984828e-07\n",
      "Epoch 4641, Loss: 8.900530772071313e-06, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4642, Loss: 4.516810382049208e-06, Final Batch Loss: 1.634317570164967e-08\n",
      "Epoch 4643, Loss: 5.935143751245597e-06, Final Batch Loss: 1.3939558130005025e-07\n",
      "Epoch 4644, Loss: 4.553442947918818e-06, Final Batch Loss: 3.234864607293275e-07\n",
      "Epoch 4645, Loss: 1.7903618465542337e-06, Final Batch Loss: 0.0\n",
      "Epoch 4646, Loss: 6.164483935311438e-06, Final Batch Loss: 6.873718660926897e-08\n",
      "Epoch 4647, Loss: 0.00047073256681040565, Final Batch Loss: 1.3939776444260588e-08\n",
      "Epoch 4648, Loss: 3.3514373660059604e-05, Final Batch Loss: 1.720807745186903e-07\n",
      "Epoch 4649, Loss: 1.8763377047648078e-06, Final Batch Loss: 1.2017051354007435e-08\n",
      "Epoch 4650, Loss: 4.053801703540749e-06, Final Batch Loss: 3.26862910071668e-08\n",
      "Epoch 4651, Loss: 5.861668440676482e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4652, Loss: 1.1620607198725708e-06, Final Batch Loss: 8.65227889335074e-09\n",
      "Epoch 4653, Loss: 1.0270002394507927e-05, Final Batch Loss: 2.980221225357127e-08\n",
      "Epoch 4654, Loss: 6.265458289522741e-06, Final Batch Loss: 6.152698261985279e-08\n",
      "Epoch 4655, Loss: 2.7245155798105714e-06, Final Batch Loss: 8.507184361405962e-07\n",
      "Epoch 4656, Loss: 6.520226815909247e-06, Final Batch Loss: 1.9487006284180097e-06\n",
      "Epoch 4657, Loss: 6.932820024840858e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4658, Loss: 5.003224123556471e-06, Final Batch Loss: 0.0\n",
      "Epoch 4659, Loss: 2.967096267014746e-06, Final Batch Loss: 1.4461149930866668e-06\n",
      "Epoch 4660, Loss: 5.402989741309927e-05, Final Batch Loss: 1.2978414787312431e-08\n",
      "Epoch 4661, Loss: 0.0004220535668899572, Final Batch Loss: 2.7350284881322295e-07\n",
      "Epoch 4662, Loss: 1.3617460915327229e-05, Final Batch Loss: 3.5040241641581815e-07\n",
      "Epoch 4663, Loss: 1.0666879688314701e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4664, Loss: 1.8131613328420393e-05, Final Batch Loss: 9.084799046377157e-08\n",
      "Epoch 4665, Loss: 2.477397642142165e-06, Final Batch Loss: 2.435436044834205e-06\n",
      "Epoch 4666, Loss: 8.210825185317461e-07, Final Batch Loss: 2.3648966873679456e-07\n",
      "Epoch 4667, Loss: 1.4424613358210436e-05, Final Batch Loss: 2.403407606266228e-08\n",
      "Epoch 4668, Loss: 4.415080917163916e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4669, Loss: 4.016495613656801e-06, Final Batch Loss: 1.9659451311326848e-07\n",
      "Epoch 4670, Loss: 3.911831281455669e-06, Final Batch Loss: 2.531922291382216e-06\n",
      "Epoch 4671, Loss: 7.182756910251165e-06, Final Batch Loss: 8.050673727666435e-07\n",
      "Epoch 4672, Loss: 2.0157091142225525e-05, Final Batch Loss: 1.792906232367386e-07\n",
      "Epoch 4673, Loss: 8.425543239765076e-07, Final Batch Loss: 0.0\n",
      "Epoch 4674, Loss: 4.96380320724743e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4675, Loss: 5.027048737615836e-06, Final Batch Loss: 5.768189481614172e-09\n",
      "Epoch 4676, Loss: 8.061017163440987e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4677, Loss: 1.2081380140860354e-05, Final Batch Loss: 2.211134031426809e-08\n",
      "Epoch 4678, Loss: 1.3698788627891645e-06, Final Batch Loss: 5.3836128444118e-08\n",
      "Epoch 4679, Loss: 3.195596051297489e-05, Final Batch Loss: 4.470324199701281e-08\n",
      "Epoch 4680, Loss: 3.3689426462979455e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4681, Loss: 7.516251511607841e-05, Final Batch Loss: 4.902933170569668e-08\n",
      "Epoch 4682, Loss: 7.738931038225871e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4683, Loss: 1.4409189960096214e-06, Final Batch Loss: 0.0\n",
      "Epoch 4684, Loss: 1.08004195831235e-06, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 4685, Loss: 1.5040516577746743e-06, Final Batch Loss: 2.403407783901912e-08\n",
      "Epoch 4686, Loss: 1.6240241904608155e-06, Final Batch Loss: 9.132960165914028e-09\n",
      "Epoch 4687, Loss: 0.00039363452868446114, Final Batch Loss: 5.33554285198079e-08\n",
      "Epoch 4688, Loss: 3.0231031026728417e-05, Final Batch Loss: 5.325910478859441e-06\n",
      "Epoch 4689, Loss: 1.3072633196942185e-05, Final Batch Loss: 0.0\n",
      "Epoch 4690, Loss: 5.1344938113428995e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4691, Loss: 2.5727843983025522e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4692, Loss: 2.508903672704399e-06, Final Batch Loss: 1.8746577623574012e-08\n",
      "Epoch 4693, Loss: 2.369031503324237e-05, Final Batch Loss: 0.0\n",
      "Epoch 4694, Loss: 2.3839278344706116e-06, Final Batch Loss: 9.132961942270867e-09\n",
      "Epoch 4695, Loss: 7.78372213250389e-06, Final Batch Loss: 1.3212303429099848e-06\n",
      "Epoch 4696, Loss: 1.0325592906257341e-05, Final Batch Loss: 4.143842488701921e-06\n",
      "Epoch 4697, Loss: 1.711194339115707e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4698, Loss: 4.182274122910279e-06, Final Batch Loss: 3.114732294307032e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4699, Loss: 2.7553636455790453e-06, Final Batch Loss: 1.2017054906721114e-08\n",
      "Epoch 4700, Loss: 5.268631048993555e-06, Final Batch Loss: 3.1608260542270727e-06\n",
      "Epoch 4701, Loss: 8.440002730036866e-08, Final Batch Loss: 0.0\n",
      "Epoch 4702, Loss: 3.4830109292949274e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4703, Loss: 1.9474927483997817e-06, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4704, Loss: 6.321211510673663e-06, Final Batch Loss: 5.835064484926988e-07\n",
      "Epoch 4705, Loss: 2.662299523725764e-06, Final Batch Loss: 1.5862504199049e-08\n",
      "Epoch 4706, Loss: 8.557256480412612e-06, Final Batch Loss: 1.7304543575846765e-08\n",
      "Epoch 4707, Loss: 7.354857820551786e-06, Final Batch Loss: 0.0\n",
      "Epoch 4708, Loss: 6.780961652741446e-06, Final Batch Loss: 6.729508328362499e-08\n",
      "Epoch 4709, Loss: 4.243854254681878e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4710, Loss: 0.0033979522360347847, Final Batch Loss: 2.3072711741178864e-08\n",
      "Epoch 4711, Loss: 1.0232591381997835e-06, Final Batch Loss: 0.0\n",
      "Epoch 4712, Loss: 7.430559754273425e-06, Final Batch Loss: 4.951000676101103e-08\n",
      "Epoch 4713, Loss: 2.927753061887639e-05, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4714, Loss: 1.435828623486124e-05, Final Batch Loss: 4.470332370942742e-08\n",
      "Epoch 4715, Loss: 3.886517081508334e-05, Final Batch Loss: 1.9227304193236705e-09\n",
      "Epoch 4716, Loss: 2.137307573812919e-06, Final Batch Loss: 4.374201623136287e-08\n",
      "Epoch 4717, Loss: 2.9316294275494315e-06, Final Batch Loss: 1.0574947850727767e-07\n",
      "Epoch 4718, Loss: 6.64107531422875e-06, Final Batch Loss: 2.1101429581449338e-07\n",
      "Epoch 4719, Loss: 4.4036378930023545e-06, Final Batch Loss: 7.690918124581003e-09\n",
      "Epoch 4720, Loss: 2.156092070104698e-05, Final Batch Loss: 0.0\n",
      "Epoch 4721, Loss: 6.643625563684807e-06, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4722, Loss: 5.322067053570301e-05, Final Batch Loss: 9.415198292117566e-06\n",
      "Epoch 4723, Loss: 1.0486133207310289e-05, Final Batch Loss: 4.993988227397494e-07\n",
      "Epoch 4724, Loss: 5.233569385643122e-07, Final Batch Loss: 2.7349912556928757e-07\n",
      "Epoch 4725, Loss: 1.6808396715695118e-05, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4726, Loss: 1.0447441898264742e-05, Final Batch Loss: 0.0\n",
      "Epoch 4727, Loss: 2.8521097285794106e-05, Final Batch Loss: 3.845460394558131e-09\n",
      "Epoch 4728, Loss: 3.0048017776174163e-06, Final Batch Loss: 2.1149979545498354e-08\n",
      "Epoch 4729, Loss: 5.4265178560441996e-05, Final Batch Loss: 0.0\n",
      "Epoch 4730, Loss: 4.455014090409826e-06, Final Batch Loss: 3.196416287210013e-07\n",
      "Epoch 4731, Loss: 0.00034072748126956487, Final Batch Loss: 1.0767146818579931e-07\n",
      "Epoch 4732, Loss: 5.480477224706348e-06, Final Batch Loss: 9.805807366092267e-08\n",
      "Epoch 4733, Loss: 1.7482089457065975e-05, Final Batch Loss: 5.768187261168123e-09\n",
      "Epoch 4734, Loss: 3.352403795675585e-07, Final Batch Loss: 3.3647773456380037e-09\n",
      "Epoch 4735, Loss: 8.776919933728422e-06, Final Batch Loss: 7.642780985861464e-08\n",
      "Epoch 4736, Loss: 2.341135346584089e-06, Final Batch Loss: 4.326141223032209e-09\n",
      "Epoch 4737, Loss: 2.7078409847725027e-06, Final Batch Loss: 4.133860187494065e-08\n",
      "Epoch 4738, Loss: 1.090374580448028e-05, Final Batch Loss: 5.734789738198742e-06\n",
      "Epoch 4739, Loss: 3.9510235533279925e-06, Final Batch Loss: 0.0\n",
      "Epoch 4740, Loss: 0.00023373457347375393, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 4741, Loss: 9.614474228536452e-06, Final Batch Loss: 2.7879494268745475e-08\n",
      "Epoch 4742, Loss: 1.666650295084615e-05, Final Batch Loss: 0.0\n",
      "Epoch 4743, Loss: 1.099573031626555e-06, Final Batch Loss: 6.24887119826667e-09\n",
      "Epoch 4744, Loss: 1.1539063647925119e-06, Final Batch Loss: 3.845459062290502e-09\n",
      "Epoch 4745, Loss: 7.964061081722207e-07, Final Batch Loss: 1.8746593610785567e-08\n",
      "Epoch 4746, Loss: 9.989395629128595e-06, Final Batch Loss: 2.273590382628754e-07\n",
      "Epoch 4747, Loss: 2.5512474309818955e-06, Final Batch Loss: 0.0\n",
      "Epoch 4748, Loss: 2.299486794365979e-05, Final Batch Loss: 2.884094740807086e-09\n",
      "Epoch 4749, Loss: 2.569601786461817e-06, Final Batch Loss: 1.696775768778025e-07\n",
      "Epoch 4750, Loss: 3.498756748987475e-06, Final Batch Loss: 7.402172741421964e-07\n",
      "Epoch 4751, Loss: 1.408255787094248e-06, Final Batch Loss: 3.412833038396457e-08\n",
      "Epoch 4752, Loss: 1.1898450169578467e-06, Final Batch Loss: 1.0472714393472415e-06\n",
      "Epoch 4753, Loss: 1.7118198952781327e-06, Final Batch Loss: 2.8360178205844022e-08\n",
      "Epoch 4754, Loss: 6.303681162611596e-07, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4755, Loss: 2.869936246652216e-06, Final Batch Loss: 1.1678905593726085e-06\n",
      "Epoch 4756, Loss: 7.109080172318372e-07, Final Batch Loss: 0.0\n",
      "Epoch 4757, Loss: 4.797467900718999e-07, Final Batch Loss: 3.6578288131750014e-07\n",
      "Epoch 4758, Loss: 9.598575995140024e-07, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 4759, Loss: 7.249899712125085e-06, Final Batch Loss: 2.3072701083037828e-08\n",
      "Epoch 4760, Loss: 4.827966244569382e-07, Final Batch Loss: 3.17249408965381e-08\n",
      "Epoch 4761, Loss: 8.892892562339938e-07, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4762, Loss: 2.5375274618988364e-05, Final Batch Loss: 0.0\n",
      "Epoch 4763, Loss: 1.7302810400465773e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4764, Loss: 4.626511733496486e-06, Final Batch Loss: 5.1913389143010136e-08\n",
      "Epoch 4765, Loss: 2.556781994456081e-06, Final Batch Loss: 2.3072701083037828e-08\n",
      "Epoch 4766, Loss: 4.10266717543184e-06, Final Batch Loss: 7.210234187482456e-09\n",
      "Epoch 4767, Loss: 6.795454054686623e-06, Final Batch Loss: 4.566261111449421e-07\n",
      "Epoch 4768, Loss: 0.00014879812297763362, Final Batch Loss: 1.3939772003368489e-08\n",
      "Epoch 4769, Loss: 2.3555603689828786e-07, Final Batch Loss: 0.0\n",
      "Epoch 4770, Loss: 2.2129680687932307e-07, Final Batch Loss: 5.768187261168123e-09\n",
      "Epoch 4771, Loss: 4.901821405445261e-07, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4772, Loss: 0.00014173925763283357, Final Batch Loss: 0.0\n",
      "Epoch 4773, Loss: 2.479534702004571e-07, Final Batch Loss: 0.0\n",
      "Epoch 4774, Loss: 3.277121198075328e-06, Final Batch Loss: 1.9227301972790656e-09\n",
      "Epoch 4775, Loss: 5.00677780346237e-08, Final Batch Loss: 0.0\n",
      "Epoch 4776, Loss: 6.376329150348248e-06, Final Batch Loss: 1.3601023738374352e-06\n",
      "Epoch 4777, Loss: 0.013161079363181671, Final Batch Loss: 1.535008095743251e-06\n",
      "Epoch 4778, Loss: 0.002803545144715258, Final Batch Loss: 0.0009253729949705303\n",
      "Epoch 4779, Loss: 0.0021783625515228167, Final Batch Loss: 0.0\n",
      "Epoch 4780, Loss: 0.003975754999092862, Final Batch Loss: 0.000306805974105373\n",
      "Epoch 4781, Loss: 0.0003921969070650455, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 4782, Loss: 7.938887662539695e-05, Final Batch Loss: 5.960442095442886e-08\n",
      "Epoch 4783, Loss: 4.762710826033967e-05, Final Batch Loss: 1.540871608085581e-06\n",
      "Epoch 4784, Loss: 0.0009869320703018714, Final Batch Loss: 0.0\n",
      "Epoch 4785, Loss: 5.59760934359943e-06, Final Batch Loss: 2.8840855037515212e-08\n",
      "Epoch 4786, Loss: 2.312069035992348e-05, Final Batch Loss: 9.613641438477316e-09\n",
      "Epoch 4787, Loss: 2.1333152939728706e-06, Final Batch Loss: 1.874657939993085e-08\n",
      "Epoch 4788, Loss: 0.00034982169187003365, Final Batch Loss: 3.364765177593654e-08\n",
      "Epoch 4789, Loss: 3.3241734738176376e-06, Final Batch Loss: 8.944511478148343e-07\n",
      "Epoch 4790, Loss: 1.374281228427865e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4791, Loss: 4.469249671457121e-06, Final Batch Loss: 7.2102328552148265e-09\n",
      "Epoch 4792, Loss: 5.541431033040389e-06, Final Batch Loss: 2.4034123580207734e-09\n",
      "Epoch 4793, Loss: 1.3474464124474395e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4794, Loss: 3.5476347437501943e-07, Final Batch Loss: 0.0\n",
      "Epoch 4795, Loss: 6.923940214509372e-07, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4796, Loss: 4.3498882570380815e-06, Final Batch Loss: 7.747859172013705e-07\n",
      "Epoch 4797, Loss: 6.155844515243203e-07, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 4798, Loss: 2.8275251175990945e-06, Final Batch Loss: 6.248868977820621e-09\n",
      "Epoch 4799, Loss: 4.932064661011815e-06, Final Batch Loss: 4.709861059382092e-06\n",
      "Epoch 4800, Loss: 1.1747148804697183e-05, Final Batch Loss: 0.0\n",
      "Epoch 4801, Loss: 4.862764086399629e-06, Final Batch Loss: 0.0\n",
      "Epoch 4802, Loss: 2.9020494805021e-06, Final Batch Loss: 0.0\n",
      "Epoch 4803, Loss: 2.6779972678303565e-05, Final Batch Loss: 2.802312906169391e-07\n",
      "Epoch 4804, Loss: 0.01702667543150438, Final Batch Loss: 6.7295511385623286e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4805, Loss: 8.327970762733727e-05, Final Batch Loss: 8.171595844430612e-09\n",
      "Epoch 4806, Loss: 0.00010312330056971852, Final Batch Loss: 0.0\n",
      "Epoch 4807, Loss: 0.0009873548664152132, Final Batch Loss: 0.0\n",
      "Epoch 4808, Loss: 5.131027012161837e-07, Final Batch Loss: 4.806823383773917e-09\n",
      "Epoch 4809, Loss: 6.265198719823672e-07, Final Batch Loss: 0.0\n",
      "Epoch 4810, Loss: 7.247894895368034e-08, Final Batch Loss: 0.0\n",
      "Epoch 4811, Loss: 3.195951259193919e-08, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4812, Loss: 8.391471527646743e-07, Final Batch Loss: 0.0\n",
      "Epoch 4813, Loss: 2.966550852745442e-07, Final Batch Loss: 8.652283334242838e-09\n",
      "Epoch 4814, Loss: 1.057296666140406e-05, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4815, Loss: 9.951803102703494e-07, Final Batch Loss: 4.253816712207481e-07\n",
      "Epoch 4816, Loss: 6.580317701843086e-08, Final Batch Loss: 0.0\n",
      "Epoch 4817, Loss: 3.073788447749415e-05, Final Batch Loss: 8.954123700277705e-07\n",
      "Epoch 4818, Loss: 2.102743414833519e-06, Final Batch Loss: 5.1432714087695786e-08\n",
      "Epoch 4819, Loss: 3.62395726760667e-08, Final Batch Loss: 0.0\n",
      "Epoch 4820, Loss: 8.355498905210368e-06, Final Batch Loss: 0.0\n",
      "Epoch 4821, Loss: 2.047505046731679e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4822, Loss: 3.623955224796305e-08, Final Batch Loss: 0.0\n",
      "Epoch 4823, Loss: 1.335142518765764e-08, Final Batch Loss: 0.0\n",
      "Epoch 4824, Loss: 4.968949205208517e-06, Final Batch Loss: 0.0\n",
      "Epoch 4825, Loss: 1.401954441426767e-07, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4826, Loss: 1.0490410762287183e-08, Final Batch Loss: 0.0\n",
      "Epoch 4827, Loss: 5.157802842981063e-05, Final Batch Loss: 5.088810212328099e-05\n",
      "Epoch 4828, Loss: 1.0647465911395315e-05, Final Batch Loss: 1.0646512237144634e-05\n",
      "Epoch 4829, Loss: 7.423721195554123e-07, Final Batch Loss: 0.0\n",
      "Epoch 4830, Loss: 5.173483508258414e-07, Final Batch Loss: 0.0\n",
      "Epoch 4831, Loss: 0.04871662467867499, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4832, Loss: 0.07355199930268641, Final Batch Loss: 6.825640497254426e-08\n",
      "Epoch 4833, Loss: 0.04964519510723475, Final Batch Loss: 3.566523787412734e-07\n",
      "Epoch 4834, Loss: 0.032419455907862105, Final Batch Loss: 9.585505722498056e-06\n",
      "Epoch 4835, Loss: 0.00011521876281639365, Final Batch Loss: 3.332557753310539e-05\n",
      "Epoch 4836, Loss: 4.68345808881665e-05, Final Batch Loss: 5.776442776550539e-06\n",
      "Epoch 4837, Loss: 0.00044222701307639056, Final Batch Loss: 6.344991732021299e-08\n",
      "Epoch 4838, Loss: 0.00017052562768427038, Final Batch Loss: 1.6439265948520188e-07\n",
      "Epoch 4839, Loss: 0.00012079132577813567, Final Batch Loss: 1.2611142210516846e-06\n",
      "Epoch 4840, Loss: 5.795989732959583e-05, Final Batch Loss: 2.2592040238578193e-08\n",
      "Epoch 4841, Loss: 8.409807175979722e-05, Final Batch Loss: 2.163022969625672e-07\n",
      "Epoch 4842, Loss: 8.272158240885119e-05, Final Batch Loss: 5.2058903747820295e-06\n",
      "Epoch 4843, Loss: 5.329166841505639e-05, Final Batch Loss: 2.7471844532556133e-06\n",
      "Epoch 4844, Loss: 0.00012287297629143268, Final Batch Loss: 1.5669976960452914e-07\n",
      "Epoch 4845, Loss: 0.00024459682621502665, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 4846, Loss: 6.473830304276618e-06, Final Batch Loss: 1.3395771247814992e-06\n",
      "Epoch 4847, Loss: 0.00040937060179513374, Final Batch Loss: 7.594730533355687e-08\n",
      "Epoch 4848, Loss: 0.000632716314824755, Final Batch Loss: 4.9585542001295835e-06\n",
      "Epoch 4849, Loss: 7.103079231018938e-05, Final Batch Loss: 9.117520676227286e-07\n",
      "Epoch 4850, Loss: 1.7752533129189452e-05, Final Batch Loss: 2.0188627658512814e-08\n",
      "Epoch 4851, Loss: 3.696589547708129e-05, Final Batch Loss: 4.5759722411276016e-07\n",
      "Epoch 4852, Loss: 0.00018417031159145836, Final Batch Loss: 6.508118985948386e-07\n",
      "Epoch 4853, Loss: 2.0376174914016332e-05, Final Batch Loss: 1.326663721101795e-07\n",
      "Epoch 4854, Loss: 5.819234603055001e-05, Final Batch Loss: 2.8456125278353284e-07\n",
      "Epoch 4855, Loss: 0.0007916485028838238, Final Batch Loss: 0.0006118833553045988\n",
      "Epoch 4856, Loss: 1.0659911102495201e-05, Final Batch Loss: 7.306351079705564e-08\n",
      "Epoch 4857, Loss: 2.4731805758904102e-05, Final Batch Loss: 1.3459107606195175e-08\n",
      "Epoch 4858, Loss: 4.235923958839649e-05, Final Batch Loss: 1.2832128959416877e-05\n",
      "Epoch 4859, Loss: 1.546371922245271e-05, Final Batch Loss: 9.565518155341124e-08\n",
      "Epoch 4860, Loss: 4.304950544042896e-05, Final Batch Loss: 2.517995199013967e-06\n",
      "Epoch 4861, Loss: 3.138817170544872e-05, Final Batch Loss: 1.442047592448148e-09\n",
      "Epoch 4862, Loss: 3.55949087618157e-05, Final Batch Loss: 8.075428326037581e-08\n",
      "Epoch 4863, Loss: 6.003434783075079e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4864, Loss: 2.9750523855565092e-05, Final Batch Loss: 9.505007255938835e-06\n",
      "Epoch 4865, Loss: 9.23580681910785e-06, Final Batch Loss: 2.643751528808025e-08\n",
      "Epoch 4866, Loss: 3.1673819736566244e-05, Final Batch Loss: 1.249774239653334e-08\n",
      "Epoch 4867, Loss: 8.557985239554533e-05, Final Batch Loss: 1.1055659143721641e-07\n",
      "Epoch 4868, Loss: 2.0450525788362484e-05, Final Batch Loss: 4.734503704639792e-07\n",
      "Epoch 4869, Loss: 0.00018717527375611276, Final Batch Loss: 7.787042477502837e-08\n",
      "Epoch 4870, Loss: 1.078071880300513e-05, Final Batch Loss: 4.806824271952337e-09\n",
      "Epoch 4871, Loss: 0.00019929676317542722, Final Batch Loss: 8.17160117350113e-09\n",
      "Epoch 4872, Loss: 0.00030804562447395156, Final Batch Loss: 2.1630437174735562e-07\n",
      "Epoch 4873, Loss: 4.710985630040909e-06, Final Batch Loss: 0.0\n",
      "Epoch 4874, Loss: 1.7996675253151295e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4875, Loss: 4.875528301639953e-06, Final Batch Loss: 1.3507118978850485e-07\n",
      "Epoch 4876, Loss: 2.4283473544883805e-05, Final Batch Loss: 1.9227282876954632e-08\n",
      "Epoch 4877, Loss: 1.604789108511362e-05, Final Batch Loss: 1.1151721679425464e-07\n",
      "Epoch 4878, Loss: 9.308600157487135e-05, Final Batch Loss: 3.508967694187959e-08\n",
      "Epoch 4879, Loss: 3.4485480244983435e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4880, Loss: 1.7734942379554752e-05, Final Batch Loss: 8.764914127823431e-06\n",
      "Epoch 4881, Loss: 3.577571568991189e-05, Final Batch Loss: 7.3833298301906325e-06\n",
      "Epoch 4882, Loss: 7.299799362259218e-05, Final Batch Loss: 5.56128100015485e-07\n",
      "Epoch 4883, Loss: 2.3493837195687206e-06, Final Batch Loss: 7.258284995259601e-08\n",
      "Epoch 4884, Loss: 1.3506815020991603e-05, Final Batch Loss: 2.422574425509083e-07\n",
      "Epoch 4885, Loss: 7.290117736147295e-06, Final Batch Loss: 6.661986731160141e-07\n",
      "Epoch 4886, Loss: 2.0823888326360063e-05, Final Batch Loss: 1.871349809334788e-06\n",
      "Epoch 4887, Loss: 1.341947198807425e-06, Final Batch Loss: 4.998806844014325e-07\n",
      "Epoch 4888, Loss: 9.937760900369241e-05, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4889, Loss: 1.0463543851813029e-05, Final Batch Loss: 1.5285428389688605e-07\n",
      "Epoch 4890, Loss: 3.6009772552692e-06, Final Batch Loss: 2.3072734833817776e-08\n",
      "Epoch 4891, Loss: 4.136602841597892e-05, Final Batch Loss: 1.0574927955531166e-07\n",
      "Epoch 4892, Loss: 3.394708978821104e-05, Final Batch Loss: 5.28749133366091e-08\n",
      "Epoch 4893, Loss: 4.103992243709165e-06, Final Batch Loss: 1.7075188907256234e-06\n",
      "Epoch 4894, Loss: 2.121865989912486e-06, Final Batch Loss: 2.884094962851691e-09\n",
      "Epoch 4895, Loss: 6.581187435417135e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4896, Loss: 4.601373951973464e-06, Final Batch Loss: 1.3843506962984975e-07\n",
      "Epoch 4897, Loss: 7.69820643962138e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4898, Loss: 5.193836627670478e-06, Final Batch Loss: 7.786984212998505e-08\n",
      "Epoch 4899, Loss: 3.674200363756874e-05, Final Batch Loss: 1.0575006648139151e-08\n",
      "Epoch 4900, Loss: 5.1179870483863965e-06, Final Batch Loss: 6.825649734309991e-08\n",
      "Epoch 4901, Loss: 2.759998203549774e-05, Final Batch Loss: 7.258254441921963e-08\n",
      "Epoch 4902, Loss: 0.0001292535716850285, Final Batch Loss: 1.3817569879392977e-06\n",
      "Epoch 4903, Loss: 0.00011691131244351283, Final Batch Loss: 7.835101456521443e-08\n",
      "Epoch 4904, Loss: 2.971578029309363e-06, Final Batch Loss: 6.709867648169165e-07\n",
      "Epoch 4905, Loss: 1.2781466391165175e-05, Final Batch Loss: 1.9227299752344607e-09\n",
      "Epoch 4906, Loss: 0.04231197793071628, Final Batch Loss: 1.8265925660898574e-08\n",
      "Epoch 4907, Loss: 3.70574750607755e-05, Final Batch Loss: 2.7204607249586843e-05\n",
      "Epoch 4908, Loss: 3.0804621290903e-05, Final Batch Loss: 2.8840890564652e-08\n",
      "Epoch 4909, Loss: 0.00041251507979012114, Final Batch Loss: 9.613652096618353e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4910, Loss: 0.0016534071764565672, Final Batch Loss: 3.977625510742655e-06\n",
      "Epoch 4911, Loss: 2.6003799501239655e-05, Final Batch Loss: 8.219605263093399e-08\n",
      "Epoch 4912, Loss: 9.201712697581854e-06, Final Batch Loss: 1.9320934825373115e-06\n",
      "Epoch 4913, Loss: 5.120273079639581e-05, Final Batch Loss: 4.316327704145806e-07\n",
      "Epoch 4914, Loss: 8.135015547772184e-05, Final Batch Loss: 5.808552032249281e-06\n",
      "Epoch 4915, Loss: 2.19930309497407e-05, Final Batch Loss: 1.5333485237079003e-07\n",
      "Epoch 4916, Loss: 0.00013949973699645124, Final Batch Loss: 2.5668052217042714e-07\n",
      "Epoch 4917, Loss: 6.23858983528347e-06, Final Batch Loss: 4.109736551072274e-07\n",
      "Epoch 4918, Loss: 9.50752664952148e-06, Final Batch Loss: 1.341082906947122e-07\n",
      "Epoch 4919, Loss: 4.640894428042941e-05, Final Batch Loss: 4.181930179925075e-08\n",
      "Epoch 4920, Loss: 0.00036856163427234634, Final Batch Loss: 1.7949876109923935e-06\n",
      "Epoch 4921, Loss: 5.4927651557790114e-05, Final Batch Loss: 3.124430492107422e-08\n",
      "Epoch 4922, Loss: 7.425209577760494e-05, Final Batch Loss: 1.470712504669791e-06\n",
      "Epoch 4923, Loss: 6.845868415261691e-06, Final Batch Loss: 1.9227279324240953e-08\n",
      "Epoch 4924, Loss: 0.00024198014117171596, Final Batch Loss: 4.422269128667722e-08\n",
      "Epoch 4925, Loss: 2.403930039784896e-05, Final Batch Loss: 3.3214482186849636e-07\n",
      "Epoch 4926, Loss: 2.4137232890186766e-05, Final Batch Loss: 1.3963529454485979e-05\n",
      "Epoch 4927, Loss: 1.4225995933259128e-05, Final Batch Loss: 5.8255254771211185e-06\n",
      "Epoch 4928, Loss: 2.2365769377197253e-05, Final Batch Loss: 1.5530895325355232e-05\n",
      "Epoch 4929, Loss: 3.2504877178318736e-05, Final Batch Loss: 1.7304538246776247e-08\n",
      "Epoch 4930, Loss: 2.216749954930819e-06, Final Batch Loss: 6.969866461759011e-08\n",
      "Epoch 4931, Loss: 4.764951857216815e-05, Final Batch Loss: 5.287492754746381e-08\n",
      "Epoch 4932, Loss: 0.00020621269764764527, Final Batch Loss: 5.032433136875625e-07\n",
      "Epoch 4933, Loss: 5.887330285059278e-06, Final Batch Loss: 7.017919756435731e-08\n",
      "Epoch 4934, Loss: 1.2287187959536539e-05, Final Batch Loss: 2.3892466742836405e-06\n",
      "Epoch 4935, Loss: 5.5200254727383324e-05, Final Batch Loss: 8.228449814851047e-07\n",
      "Epoch 4936, Loss: 1.4909114165906345e-05, Final Batch Loss: 1.1390571899028146e-06\n",
      "Epoch 4937, Loss: 4.36419702110058e-06, Final Batch Loss: 7.402446300375232e-08\n",
      "Epoch 4938, Loss: 1.3974710370567855e-05, Final Batch Loss: 3.936599171083799e-07\n",
      "Epoch 4939, Loss: 0.00025625476218982257, Final Batch Loss: 3.220567990069867e-08\n",
      "Epoch 4940, Loss: 3.974568407061341e-06, Final Batch Loss: 2.403412802109983e-09\n",
      "Epoch 4941, Loss: 2.87987278393409e-05, Final Batch Loss: 1.22092160381726e-07\n",
      "Epoch 4942, Loss: 8.655207130003895e-06, Final Batch Loss: 3.985790954175172e-06\n",
      "Epoch 4943, Loss: 0.00017257758429356507, Final Batch Loss: 2.4246528482763097e-05\n",
      "Epoch 4944, Loss: 2.6871063395494943e-06, Final Batch Loss: 8.776332265370002e-07\n",
      "Epoch 4945, Loss: 8.86784312870148e-07, Final Batch Loss: 2.831188226082304e-07\n",
      "Epoch 4946, Loss: 1.657500172780324e-06, Final Batch Loss: 1.8986523286912416e-07\n",
      "Epoch 4947, Loss: 9.605247881638856e-05, Final Batch Loss: 9.833590866037412e-07\n",
      "Epoch 4948, Loss: 7.630942737923974e-06, Final Batch Loss: 9.613641438477316e-09\n",
      "Epoch 4949, Loss: 4.1261602088060734e-05, Final Batch Loss: 4.821044399250241e-07\n",
      "Epoch 4950, Loss: 1.951151148205099e-05, Final Batch Loss: 1.9611378831996262e-07\n",
      "Epoch 4951, Loss: 1.8159748266799447e-05, Final Batch Loss: 2.884095184896296e-09\n",
      "Epoch 4952, Loss: 3.606810732526e-06, Final Batch Loss: 6.729553803097588e-09\n",
      "Epoch 4953, Loss: 1.2319142490557766e-05, Final Batch Loss: 6.393035789642454e-08\n",
      "Epoch 4954, Loss: 0.00012488960092749135, Final Batch Loss: 0.0\n",
      "Epoch 4955, Loss: 0.00031255790303552633, Final Batch Loss: 1.4917725366103696e-06\n",
      "Epoch 4956, Loss: 2.404145278189773e-06, Final Batch Loss: 1.9227282876954632e-08\n",
      "Epoch 4957, Loss: 2.7925675289974805e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4958, Loss: 2.310122432458428e-06, Final Batch Loss: 9.613652096618353e-10\n",
      "Epoch 4959, Loss: 6.439631234922416e-07, Final Batch Loss: 8.940607898466624e-08\n",
      "Epoch 4960, Loss: 1.1848030350924965e-05, Final Batch Loss: 2.7500095711729955e-06\n",
      "Epoch 4961, Loss: 8.96502173164393e-07, Final Batch Loss: 8.17160117350113e-09\n",
      "Epoch 4962, Loss: 6.68667559278191e-06, Final Batch Loss: 0.0\n",
      "Epoch 4963, Loss: 1.226873315496313e-06, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 4964, Loss: 7.0485178405022e-07, Final Batch Loss: 1.2017048689472176e-08\n",
      "Epoch 4965, Loss: 3.6480877740885376e-07, Final Batch Loss: 3.8454595063797115e-09\n",
      "Epoch 4966, Loss: 5.041611311862315e-05, Final Batch Loss: 1.3747356319981918e-07\n",
      "Epoch 4967, Loss: 1.4171218529757112e-06, Final Batch Loss: 9.613650986395328e-10\n",
      "Epoch 4968, Loss: 5.328240280211283e-06, Final Batch Loss: 5.2875068767832545e-09\n",
      "Epoch 4969, Loss: 0.0001231145491022989, Final Batch Loss: 1.1536372745979406e-08\n",
      "Epoch 4970, Loss: 0.00012408191982193895, Final Batch Loss: 5.768189481614172e-09\n",
      "Epoch 4971, Loss: 7.862650477696853e-06, Final Batch Loss: 4.460509615000774e-07\n",
      "Epoch 4972, Loss: 4.298310290540286e-05, Final Batch Loss: 3.9896505654724024e-08\n",
      "Epoch 4973, Loss: 0.003940020156445345, Final Batch Loss: 1.2978409458241913e-08\n",
      "Epoch 4974, Loss: 2.0292984055814145e-05, Final Batch Loss: 1.602805923539563e-06\n",
      "Epoch 4975, Loss: 0.0007332057467087649, Final Batch Loss: 0.0004077983321622014\n",
      "Epoch 4976, Loss: 1.3223067134582323e-06, Final Batch Loss: 1.3939780885152686e-08\n",
      "Epoch 4977, Loss: 0.0001580386735005046, Final Batch Loss: 3.6534554510581074e-06\n",
      "Epoch 4978, Loss: 2.3742892495626222e-05, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4979, Loss: 9.41266641174554e-06, Final Batch Loss: 8.411873153590932e-08\n",
      "Epoch 4980, Loss: 3.0179703162103166e-06, Final Batch Loss: 1.4420477034704504e-09\n",
      "Epoch 4981, Loss: 1.9556935101028294e-05, Final Batch Loss: 1.0094329816467962e-08\n",
      "Epoch 4982, Loss: 1.3820608909753673e-05, Final Batch Loss: 5.094917696624179e-07\n",
      "Epoch 4983, Loss: 7.198523132245782e-06, Final Batch Loss: 5.287505100426415e-09\n",
      "Epoch 4984, Loss: 1.6483611412487775e-06, Final Batch Loss: 4.806826048309176e-10\n",
      "Epoch 4985, Loss: 0.00018479899900292196, Final Batch Loss: 0.0001839879114413634\n",
      "Epoch 4986, Loss: 8.447677170675405e-06, Final Batch Loss: 7.210235075660876e-09\n",
      "Epoch 4987, Loss: 1.1078492697880193e-05, Final Batch Loss: 6.873703028986711e-08\n",
      "Epoch 4988, Loss: 7.886841084769891e-06, Final Batch Loss: 5.930265160714043e-06\n",
      "Epoch 4989, Loss: 0.0003852494458390643, Final Batch Loss: 0.0\n",
      "Epoch 4990, Loss: 3.944069037664644e-05, Final Batch Loss: 1.3747343530212675e-07\n",
      "Epoch 4991, Loss: 4.4029062116202056e-06, Final Batch Loss: 2.5476138532098958e-08\n",
      "Epoch 4992, Loss: 0.00015332262804634844, Final Batch Loss: 7.450547201415247e-08\n",
      "Epoch 4993, Loss: 4.107267877218046e-05, Final Batch Loss: 2.451478486875658e-08\n",
      "Epoch 4994, Loss: 0.00018785477915472804, Final Batch Loss: 8.436823009105865e-06\n",
      "Epoch 4995, Loss: 3.4276870403138204e-06, Final Batch Loss: 0.0\n",
      "Epoch 4996, Loss: 7.765385423130766e-06, Final Batch Loss: 1.1199806948525293e-07\n",
      "Epoch 4997, Loss: 2.1407986599886186e-05, Final Batch Loss: 3.3647694408500683e-08\n",
      "Epoch 4998, Loss: 3.2326859304987465e-06, Final Batch Loss: 2.018863654029701e-08\n",
      "Epoch 4999, Loss: 4.955542291296133e-06, Final Batch Loss: 6.42140946638392e-07\n",
      "Epoch 5000, Loss: 2.676529919587445e-06, Final Batch Loss: 4.0712561144573556e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[484  12   0]\n",
      " [  8 412   0]\n",
      " [  0   0 491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.976     0.980       496\n",
      "           1      0.972     0.981     0.976       420\n",
      "           2      1.000     1.000     1.000       491\n",
      "\n",
      "    accuracy                          0.986      1407\n",
      "   macro avg      0.985     0.986     0.985      1407\n",
      "weighted avg      0.986     0.986     0.986      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../saved_models/UCI 3 Label Classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
