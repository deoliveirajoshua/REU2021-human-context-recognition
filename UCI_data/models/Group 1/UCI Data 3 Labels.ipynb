{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>125 tBodyGyro-std()-Y</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>506 fBodyAccMag-max()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.976623</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.974321</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.989046</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.978226</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.993552</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.993062</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.992407</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.990230</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.992378</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.990506</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.065142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.401674</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.410577</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.362904</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.190360</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.397687</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.620014</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  59 tGravityAcc-energy()-Z  \\\n",
       "0                   0.056483             -0.375426                  -0.975510   \n",
       "1                   0.102764             -0.383430                  -0.978500   \n",
       "2                   0.102764             -0.401602                  -0.981672   \n",
       "3                   0.095753             -0.400278                  -0.982420   \n",
       "4                   0.094059             -0.400477                  -0.984363   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.995193   \n",
       "7348               -0.068919             -0.358934                  -0.995151   \n",
       "7349               -0.068919             -0.377025                  -0.995450   \n",
       "7350               -0.040009             -0.440050                  -0.998824   \n",
       "7351               -0.047491             -0.432003                  -0.998144   \n",
       "\n",
       "      125 tBodyGyro-std()-Y  128 tBodyGyro-mad()-Y  ...  \\\n",
       "0                 -0.976623              -0.976353  ...   \n",
       "1                 -0.989046              -0.989038  ...   \n",
       "2                 -0.993552              -0.994122  ...   \n",
       "3                 -0.992407              -0.993142  ...   \n",
       "4                 -0.992378              -0.992542  ...   \n",
       "...                     ...                    ...  ...   \n",
       "7347               0.084878               0.065142  ...   \n",
       "7348               0.098249               0.091791  ...   \n",
       "7349               0.185902               0.170686  ...   \n",
       "7350               0.190360               0.178939  ...   \n",
       "7351               0.022216              -0.073681  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      504 fBodyAccMag-std()  505 fBodyAccMag-mad()  506 fBodyAccMag-max()  \\\n",
       "0                 -0.956134              -0.948870              -0.974321   \n",
       "1                 -0.975866              -0.975777              -0.978226   \n",
       "2                 -0.989015              -0.985594              -0.993062   \n",
       "3                 -0.986742              -0.983524              -0.990230   \n",
       "4                 -0.990063              -0.992324              -0.990506   \n",
       "...                     ...                    ...                    ...   \n",
       "7347              -0.232600              -0.007392              -0.401674   \n",
       "7348              -0.275373              -0.172448              -0.410577   \n",
       "7349              -0.220288              -0.216074              -0.362904   \n",
       "7350              -0.234539              -0.220443              -0.397687   \n",
       "7351              -0.342670              -0.146649              -0.620014   \n",
       "\n",
       "      509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                    -0.998285         5        1  \n",
       "1                    -0.999472         5        1  \n",
       "2                    -0.999807         5        1  \n",
       "3                    -0.999770         5        1  \n",
       "4                    -0.999873         5        1  \n",
       "...                        ...       ...      ...  \n",
       "7347                 -0.584282         2       30  \n",
       "7348                 -0.632536         2       30  \n",
       "7349                 -0.641170         2       30  \n",
       "7350                 -0.663579         2       30  \n",
       "7351                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.208835244178772, Final Batch Loss: 1.1044903993606567\n",
      "Epoch 2, Loss: 2.203732967376709, Final Batch Loss: 1.0948216915130615\n",
      "Epoch 3, Loss: 2.195630192756653, Final Batch Loss: 1.0868468284606934\n",
      "Epoch 4, Loss: 2.1939148902893066, Final Batch Loss: 1.0972943305969238\n",
      "Epoch 5, Loss: 2.1912232637405396, Final Batch Loss: 1.1016713380813599\n",
      "Epoch 6, Loss: 2.1809449195861816, Final Batch Loss: 1.0899635553359985\n",
      "Epoch 7, Loss: 2.173010468482971, Final Batch Loss: 1.083828091621399\n",
      "Epoch 8, Loss: 2.168437361717224, Final Batch Loss: 1.085244059562683\n",
      "Epoch 9, Loss: 2.158227324485779, Final Batch Loss: 1.0768591165542603\n",
      "Epoch 10, Loss: 2.1527105569839478, Final Batch Loss: 1.0717421770095825\n",
      "Epoch 11, Loss: 2.1457027196884155, Final Batch Loss: 1.073594331741333\n",
      "Epoch 12, Loss: 2.1393579244613647, Final Batch Loss: 1.0708775520324707\n",
      "Epoch 13, Loss: 2.1294994354248047, Final Batch Loss: 1.0655531883239746\n",
      "Epoch 14, Loss: 2.1188182830810547, Final Batch Loss: 1.0585155487060547\n",
      "Epoch 15, Loss: 2.1079760789871216, Final Batch Loss: 1.051133394241333\n",
      "Epoch 16, Loss: 2.0949697494506836, Final Batch Loss: 1.040252447128296\n",
      "Epoch 17, Loss: 2.080203890800476, Final Batch Loss: 1.0376447439193726\n",
      "Epoch 18, Loss: 2.0687127113342285, Final Batch Loss: 1.0373525619506836\n",
      "Epoch 19, Loss: 2.0459976196289062, Final Batch Loss: 1.0202767848968506\n",
      "Epoch 20, Loss: 2.022182583808899, Final Batch Loss: 1.0097099542617798\n",
      "Epoch 21, Loss: 1.9906685948371887, Final Batch Loss: 0.9878587126731873\n",
      "Epoch 22, Loss: 1.9660251140594482, Final Batch Loss: 0.9779504537582397\n",
      "Epoch 23, Loss: 1.9271820783615112, Final Batch Loss: 0.9653711318969727\n",
      "Epoch 24, Loss: 1.8843908905982971, Final Batch Loss: 0.9354050159454346\n",
      "Epoch 25, Loss: 1.8663792610168457, Final Batch Loss: 0.9248400926589966\n",
      "Epoch 26, Loss: 1.8279966711997986, Final Batch Loss: 0.91171795129776\n",
      "Epoch 27, Loss: 1.762656807899475, Final Batch Loss: 0.8739021420478821\n",
      "Epoch 28, Loss: 1.7043684124946594, Final Batch Loss: 0.8447174429893494\n",
      "Epoch 29, Loss: 1.6398385763168335, Final Batch Loss: 0.8067513108253479\n",
      "Epoch 30, Loss: 1.5784828066825867, Final Batch Loss: 0.777243971824646\n",
      "Epoch 31, Loss: 1.51905757188797, Final Batch Loss: 0.7565113306045532\n",
      "Epoch 32, Loss: 1.4416433572769165, Final Batch Loss: 0.713437557220459\n",
      "Epoch 33, Loss: 1.3520095944404602, Final Batch Loss: 0.685941755771637\n",
      "Epoch 34, Loss: 1.2881720662117004, Final Batch Loss: 0.6435267329216003\n",
      "Epoch 35, Loss: 1.2261136174201965, Final Batch Loss: 0.6106431484222412\n",
      "Epoch 36, Loss: 1.1860892176628113, Final Batch Loss: 0.5867499709129333\n",
      "Epoch 37, Loss: 1.0469169616699219, Final Batch Loss: 0.5176914930343628\n",
      "Epoch 38, Loss: 0.9915143847465515, Final Batch Loss: 0.49306586384773254\n",
      "Epoch 39, Loss: 0.9455487728118896, Final Batch Loss: 0.44964534044265747\n",
      "Epoch 40, Loss: 0.8517442643642426, Final Batch Loss: 0.39369112253189087\n",
      "Epoch 41, Loss: 0.864209771156311, Final Batch Loss: 0.44519975781440735\n",
      "Epoch 42, Loss: 0.7757019996643066, Final Batch Loss: 0.39540037512779236\n",
      "Epoch 43, Loss: 0.723625510931015, Final Batch Loss: 0.35570448637008667\n",
      "Epoch 44, Loss: 0.7040010988712311, Final Batch Loss: 0.33135050535202026\n",
      "Epoch 45, Loss: 0.6499036252498627, Final Batch Loss: 0.32597997784614563\n",
      "Epoch 46, Loss: 0.6291625499725342, Final Batch Loss: 0.30638957023620605\n",
      "Epoch 47, Loss: 0.531168133020401, Final Batch Loss: 0.25319328904151917\n",
      "Epoch 48, Loss: 0.5741764903068542, Final Batch Loss: 0.28148549795150757\n",
      "Epoch 49, Loss: 0.4917996972799301, Final Batch Loss: 0.2397117167711258\n",
      "Epoch 50, Loss: 0.4754459261894226, Final Batch Loss: 0.2249789535999298\n",
      "Epoch 51, Loss: 0.4602106213569641, Final Batch Loss: 0.24441146850585938\n",
      "Epoch 52, Loss: 0.4453032910823822, Final Batch Loss: 0.20499750971794128\n",
      "Epoch 53, Loss: 0.47757306694984436, Final Batch Loss: 0.2516387403011322\n",
      "Epoch 54, Loss: 0.40087634325027466, Final Batch Loss: 0.1934918910264969\n",
      "Epoch 55, Loss: 0.3950987011194229, Final Batch Loss: 0.19446109235286713\n",
      "Epoch 56, Loss: 0.3922750651836395, Final Batch Loss: 0.17614203691482544\n",
      "Epoch 57, Loss: 0.38185299932956696, Final Batch Loss: 0.17978787422180176\n",
      "Epoch 58, Loss: 0.32534173130989075, Final Batch Loss: 0.16237357258796692\n",
      "Epoch 59, Loss: 0.361428901553154, Final Batch Loss: 0.18879972398281097\n",
      "Epoch 60, Loss: 0.3800456374883652, Final Batch Loss: 0.20210480690002441\n",
      "Epoch 61, Loss: 0.3299444019794464, Final Batch Loss: 0.16714344918727875\n",
      "Epoch 62, Loss: 0.33432435989379883, Final Batch Loss: 0.173592671751976\n",
      "Epoch 63, Loss: 0.2669846713542938, Final Batch Loss: 0.12403781712055206\n",
      "Epoch 64, Loss: 0.32474686205387115, Final Batch Loss: 0.1737956702709198\n",
      "Epoch 65, Loss: 0.3091251254081726, Final Batch Loss: 0.1300877034664154\n",
      "Epoch 66, Loss: 0.2958197668194771, Final Batch Loss: 0.1921634078025818\n",
      "Epoch 67, Loss: 0.3243005871772766, Final Batch Loss: 0.17192257940769196\n",
      "Epoch 68, Loss: 0.2611113041639328, Final Batch Loss: 0.1413877010345459\n",
      "Epoch 69, Loss: 0.22328193485736847, Final Batch Loss: 0.09825104475021362\n",
      "Epoch 70, Loss: 0.3287188857793808, Final Batch Loss: 0.17636045813560486\n",
      "Epoch 71, Loss: 0.2725229188799858, Final Batch Loss: 0.12321691960096359\n",
      "Epoch 72, Loss: 0.2527063190937042, Final Batch Loss: 0.10633303225040436\n",
      "Epoch 73, Loss: 0.24814873933792114, Final Batch Loss: 0.1278703361749649\n",
      "Epoch 74, Loss: 0.23771124333143234, Final Batch Loss: 0.11517874896526337\n",
      "Epoch 75, Loss: 0.29229316115379333, Final Batch Loss: 0.16491729021072388\n",
      "Epoch 76, Loss: 0.24449900537729263, Final Batch Loss: 0.12521368265151978\n",
      "Epoch 77, Loss: 0.2547812759876251, Final Batch Loss: 0.12746693193912506\n",
      "Epoch 78, Loss: 0.21246346086263657, Final Batch Loss: 0.09029893577098846\n",
      "Epoch 79, Loss: 0.23655354976654053, Final Batch Loss: 0.11934816837310791\n",
      "Epoch 80, Loss: 0.20967135578393936, Final Batch Loss: 0.08615437150001526\n",
      "Epoch 81, Loss: 0.19484251737594604, Final Batch Loss: 0.09333398938179016\n",
      "Epoch 82, Loss: 0.20939116179943085, Final Batch Loss: 0.10588642954826355\n",
      "Epoch 83, Loss: 0.17703375965356827, Final Batch Loss: 0.08161070942878723\n",
      "Epoch 84, Loss: 0.24395869672298431, Final Batch Loss: 0.1100739985704422\n",
      "Epoch 85, Loss: 0.20647642761468887, Final Batch Loss: 0.08527428656816483\n",
      "Epoch 86, Loss: 0.20059459283947945, Final Batch Loss: 0.05594295635819435\n",
      "Epoch 87, Loss: 0.2630211338400841, Final Batch Loss: 0.13963539898395538\n",
      "Epoch 88, Loss: 0.24181699007749557, Final Batch Loss: 0.10792963951826096\n",
      "Epoch 89, Loss: 0.2873384356498718, Final Batch Loss: 0.17114730179309845\n",
      "Epoch 90, Loss: 0.25300831347703934, Final Batch Loss: 0.14588041603565216\n",
      "Epoch 91, Loss: 0.19349104166030884, Final Batch Loss: 0.0774993821978569\n",
      "Epoch 92, Loss: 0.1781805232167244, Final Batch Loss: 0.06603384763002396\n",
      "Epoch 93, Loss: 0.19687340408563614, Final Batch Loss: 0.0814119502902031\n",
      "Epoch 94, Loss: 0.21004699170589447, Final Batch Loss: 0.08616238087415695\n",
      "Epoch 95, Loss: 0.1888526901602745, Final Batch Loss: 0.07730113714933395\n",
      "Epoch 96, Loss: 0.22753550112247467, Final Batch Loss: 0.11228299885988235\n",
      "Epoch 97, Loss: 0.21315236389636993, Final Batch Loss: 0.13620184361934662\n",
      "Epoch 98, Loss: 0.19190141558647156, Final Batch Loss: 0.12247585505247116\n",
      "Epoch 99, Loss: 0.15896163880825043, Final Batch Loss: 0.06344063580036163\n",
      "Epoch 100, Loss: 0.18264780193567276, Final Batch Loss: 0.07824777811765671\n",
      "Epoch 101, Loss: 0.15237823501229286, Final Batch Loss: 0.05434022471308708\n",
      "Epoch 102, Loss: 0.2262430563569069, Final Batch Loss: 0.08818518370389938\n",
      "Epoch 103, Loss: 0.1666131317615509, Final Batch Loss: 0.11741436272859573\n",
      "Epoch 104, Loss: 0.20443516969680786, Final Batch Loss: 0.11141688376665115\n",
      "Epoch 105, Loss: 0.22996597737073898, Final Batch Loss: 0.08362141996622086\n",
      "Epoch 106, Loss: 0.1747400313615799, Final Batch Loss: 0.1118067130446434\n",
      "Epoch 107, Loss: 0.17919618636369705, Final Batch Loss: 0.08268394321203232\n",
      "Epoch 108, Loss: 0.2069477066397667, Final Batch Loss: 0.1355872005224228\n",
      "Epoch 109, Loss: 0.1550532877445221, Final Batch Loss: 0.0769290179014206\n",
      "Epoch 110, Loss: 0.17775121331214905, Final Batch Loss: 0.0780581682920456\n",
      "Epoch 111, Loss: 0.17434748262166977, Final Batch Loss: 0.07621198892593384\n",
      "Epoch 112, Loss: 0.1760583221912384, Final Batch Loss: 0.08480915427207947\n",
      "Epoch 113, Loss: 0.14515789598226547, Final Batch Loss: 0.06730363517999649\n",
      "Epoch 114, Loss: 0.18894856423139572, Final Batch Loss: 0.06903582811355591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115, Loss: 0.1623915582895279, Final Batch Loss: 0.06348594278097153\n",
      "Epoch 116, Loss: 0.15791354328393936, Final Batch Loss: 0.0827261283993721\n",
      "Epoch 117, Loss: 0.19564774259924889, Final Batch Loss: 0.05369968339800835\n",
      "Epoch 118, Loss: 0.19134796410799026, Final Batch Loss: 0.06776823848485947\n",
      "Epoch 119, Loss: 0.1775161176919937, Final Batch Loss: 0.10176283866167068\n",
      "Epoch 120, Loss: 0.1867794655263424, Final Batch Loss: 0.04293322190642357\n",
      "Epoch 121, Loss: 0.1357877515256405, Final Batch Loss: 0.08135896921157837\n",
      "Epoch 122, Loss: 0.1650495082139969, Final Batch Loss: 0.08428363502025604\n",
      "Epoch 123, Loss: 0.14466815441846848, Final Batch Loss: 0.07027824968099594\n",
      "Epoch 124, Loss: 0.2281637117266655, Final Batch Loss: 0.16480688750743866\n",
      "Epoch 125, Loss: 0.190804585814476, Final Batch Loss: 0.11190646141767502\n",
      "Epoch 126, Loss: 0.1463141068816185, Final Batch Loss: 0.07422153651714325\n",
      "Epoch 127, Loss: 0.19016434252262115, Final Batch Loss: 0.09144441038370132\n",
      "Epoch 128, Loss: 0.1441221572458744, Final Batch Loss: 0.10470960289239883\n",
      "Epoch 129, Loss: 0.16699794679880142, Final Batch Loss: 0.06283390522003174\n",
      "Epoch 130, Loss: 0.1561107560992241, Final Batch Loss: 0.06119261682033539\n",
      "Epoch 131, Loss: 0.18064364045858383, Final Batch Loss: 0.10624594986438751\n",
      "Epoch 132, Loss: 0.1526506021618843, Final Batch Loss: 0.06259586662054062\n",
      "Epoch 133, Loss: 0.13959461450576782, Final Batch Loss: 0.06919901072978973\n",
      "Epoch 134, Loss: 0.12170658260583878, Final Batch Loss: 0.0386817529797554\n",
      "Epoch 135, Loss: 0.1334046795964241, Final Batch Loss: 0.08195754885673523\n",
      "Epoch 136, Loss: 0.16513587906956673, Final Batch Loss: 0.10825095325708389\n",
      "Epoch 137, Loss: 0.14383943006396294, Final Batch Loss: 0.054522912949323654\n",
      "Epoch 138, Loss: 0.20743834972381592, Final Batch Loss: 0.09588999301195145\n",
      "Epoch 139, Loss: 0.0984664149582386, Final Batch Loss: 0.036950018256902695\n",
      "Epoch 140, Loss: 0.1729198545217514, Final Batch Loss: 0.0942642092704773\n",
      "Epoch 141, Loss: 0.16768822073936462, Final Batch Loss: 0.04967011511325836\n",
      "Epoch 142, Loss: 0.11639445275068283, Final Batch Loss: 0.05736112594604492\n",
      "Epoch 143, Loss: 0.13407237455248833, Final Batch Loss: 0.06105554476380348\n",
      "Epoch 144, Loss: 0.15263954550027847, Final Batch Loss: 0.08920098841190338\n",
      "Epoch 145, Loss: 0.1356419026851654, Final Batch Loss: 0.06252595037221909\n",
      "Epoch 146, Loss: 0.1262296736240387, Final Batch Loss: 0.07050496339797974\n",
      "Epoch 147, Loss: 0.13447009772062302, Final Batch Loss: 0.05901740491390228\n",
      "Epoch 148, Loss: 0.1531786173582077, Final Batch Loss: 0.08062808215618134\n",
      "Epoch 149, Loss: 0.15865518152713776, Final Batch Loss: 0.10788767039775848\n",
      "Epoch 150, Loss: 0.1813531592488289, Final Batch Loss: 0.1063876822590828\n",
      "Epoch 151, Loss: 0.13965041935443878, Final Batch Loss: 0.06622885912656784\n",
      "Epoch 152, Loss: 0.12184255570173264, Final Batch Loss: 0.06225479394197464\n",
      "Epoch 153, Loss: 0.13137881830334663, Final Batch Loss: 0.041048962622880936\n",
      "Epoch 154, Loss: 0.14787758141756058, Final Batch Loss: 0.07159698009490967\n",
      "Epoch 155, Loss: 0.17530487850308418, Final Batch Loss: 0.11629454046487808\n",
      "Epoch 156, Loss: 0.112100875005126, Final Batch Loss: 0.03055339865386486\n",
      "Epoch 157, Loss: 0.1252208836376667, Final Batch Loss: 0.05096607282757759\n",
      "Epoch 158, Loss: 0.10267866030335426, Final Batch Loss: 0.050800904631614685\n",
      "Epoch 159, Loss: 0.14166738092899323, Final Batch Loss: 0.07684080302715302\n",
      "Epoch 160, Loss: 0.1415855810046196, Final Batch Loss: 0.0630159080028534\n",
      "Epoch 161, Loss: 0.14560047909617424, Final Batch Loss: 0.0427657850086689\n",
      "Epoch 162, Loss: 0.11912816017866135, Final Batch Loss: 0.06061919406056404\n",
      "Epoch 163, Loss: 0.11869842559099197, Final Batch Loss: 0.07644013315439224\n",
      "Epoch 164, Loss: 0.14080652594566345, Final Batch Loss: 0.07450038194656372\n",
      "Epoch 165, Loss: 0.13465048745274544, Final Batch Loss: 0.07248296588659286\n",
      "Epoch 166, Loss: 0.11710599809885025, Final Batch Loss: 0.06590614467859268\n",
      "Epoch 167, Loss: 0.1771387718617916, Final Batch Loss: 0.1261531263589859\n",
      "Epoch 168, Loss: 0.1623823083937168, Final Batch Loss: 0.1077989861369133\n",
      "Epoch 169, Loss: 0.12001881003379822, Final Batch Loss: 0.038345277309417725\n",
      "Epoch 170, Loss: 0.1626637503504753, Final Batch Loss: 0.07102183997631073\n",
      "Epoch 171, Loss: 0.1451839655637741, Final Batch Loss: 0.07081644237041473\n",
      "Epoch 172, Loss: 0.11460747569799423, Final Batch Loss: 0.07445288449525833\n",
      "Epoch 173, Loss: 0.20425806194543839, Final Batch Loss: 0.08286496996879578\n",
      "Epoch 174, Loss: 0.14867819100618362, Final Batch Loss: 0.07057704776525497\n",
      "Epoch 175, Loss: 0.13011683151125908, Final Batch Loss: 0.06872346997261047\n",
      "Epoch 176, Loss: 0.14438315853476524, Final Batch Loss: 0.044519711285829544\n",
      "Epoch 177, Loss: 0.12993508577346802, Final Batch Loss: 0.0661315992474556\n",
      "Epoch 178, Loss: 0.1323264129459858, Final Batch Loss: 0.052568469196558\n",
      "Epoch 179, Loss: 0.1303486004471779, Final Batch Loss: 0.044806383550167084\n",
      "Epoch 180, Loss: 0.123308464884758, Final Batch Loss: 0.0572056770324707\n",
      "Epoch 181, Loss: 0.10841064527630806, Final Batch Loss: 0.05216609686613083\n",
      "Epoch 182, Loss: 0.14399012178182602, Final Batch Loss: 0.03885989636182785\n",
      "Epoch 183, Loss: 0.12896467000246048, Final Batch Loss: 0.06388695538043976\n",
      "Epoch 184, Loss: 0.11904412880539894, Final Batch Loss: 0.0448467843234539\n",
      "Epoch 185, Loss: 0.0977092944085598, Final Batch Loss: 0.04328419268131256\n",
      "Epoch 186, Loss: 0.14836281910538673, Final Batch Loss: 0.10179730504751205\n",
      "Epoch 187, Loss: 0.14841381087899208, Final Batch Loss: 0.09176163375377655\n",
      "Epoch 188, Loss: 0.13713406398892403, Final Batch Loss: 0.04905056580901146\n",
      "Epoch 189, Loss: 0.16218676418066025, Final Batch Loss: 0.07087322324514389\n",
      "Epoch 190, Loss: 0.14543500542640686, Final Batch Loss: 0.07183744013309479\n",
      "Epoch 191, Loss: 0.07497140020132065, Final Batch Loss: 0.02263600379228592\n",
      "Epoch 192, Loss: 0.1706048846244812, Final Batch Loss: 0.08463654667139053\n",
      "Epoch 193, Loss: 0.1543358787894249, Final Batch Loss: 0.10562435537576675\n",
      "Epoch 194, Loss: 0.11262544244527817, Final Batch Loss: 0.051508087664842606\n",
      "Epoch 195, Loss: 0.1247018575668335, Final Batch Loss: 0.060426585376262665\n",
      "Epoch 196, Loss: 0.1572372503578663, Final Batch Loss: 0.05255386605858803\n",
      "Epoch 197, Loss: 0.15140201896429062, Final Batch Loss: 0.09425387531518936\n",
      "Epoch 198, Loss: 0.10659030824899673, Final Batch Loss: 0.06451869755983353\n",
      "Epoch 199, Loss: 0.09677477926015854, Final Batch Loss: 0.032346516847610474\n",
      "Epoch 200, Loss: 0.10557491704821587, Final Batch Loss: 0.03567462041974068\n",
      "Epoch 201, Loss: 0.11175555363297462, Final Batch Loss: 0.03881656005978584\n",
      "Epoch 202, Loss: 0.0972619280219078, Final Batch Loss: 0.059765975922346115\n",
      "Epoch 203, Loss: 0.11907179281115532, Final Batch Loss: 0.05243183299899101\n",
      "Epoch 204, Loss: 0.11132850497961044, Final Batch Loss: 0.0829090103507042\n",
      "Epoch 205, Loss: 0.12345743924379349, Final Batch Loss: 0.04577122628688812\n",
      "Epoch 206, Loss: 0.15354201197624207, Final Batch Loss: 0.0859837606549263\n",
      "Epoch 207, Loss: 0.16902128607034683, Final Batch Loss: 0.12475261837244034\n",
      "Epoch 208, Loss: 0.14386752247810364, Final Batch Loss: 0.07101281732320786\n",
      "Epoch 209, Loss: 0.11110324785113335, Final Batch Loss: 0.052168186753988266\n",
      "Epoch 210, Loss: 0.10242241248488426, Final Batch Loss: 0.032193440943956375\n",
      "Epoch 211, Loss: 0.14606976881623268, Final Batch Loss: 0.09748165309429169\n",
      "Epoch 212, Loss: 0.19612408429384232, Final Batch Loss: 0.14094631373882294\n",
      "Epoch 213, Loss: 0.09262101352214813, Final Batch Loss: 0.04785090684890747\n",
      "Epoch 214, Loss: 0.1502375639975071, Final Batch Loss: 0.11577143520116806\n",
      "Epoch 215, Loss: 0.13333465531468391, Final Batch Loss: 0.09417255222797394\n",
      "Epoch 216, Loss: 0.09356968477368355, Final Batch Loss: 0.03815928101539612\n",
      "Epoch 217, Loss: 0.14434052631258965, Final Batch Loss: 0.09136751294136047\n",
      "Epoch 218, Loss: 0.11477495357394218, Final Batch Loss: 0.048668306320905685\n",
      "Epoch 219, Loss: 0.08194344490766525, Final Batch Loss: 0.0236920528113842\n",
      "Epoch 220, Loss: 0.12189335748553276, Final Batch Loss: 0.07747562974691391\n",
      "Epoch 221, Loss: 0.10239960253238678, Final Batch Loss: 0.044306155294179916\n",
      "Epoch 222, Loss: 0.1098322756588459, Final Batch Loss: 0.04215141013264656\n",
      "Epoch 223, Loss: 0.08573932200670242, Final Batch Loss: 0.03650541603565216\n",
      "Epoch 224, Loss: 0.11127759888768196, Final Batch Loss: 0.052893299609422684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225, Loss: 0.15634440630674362, Final Batch Loss: 0.06499448418617249\n",
      "Epoch 226, Loss: 0.07435356825590134, Final Batch Loss: 0.0416194349527359\n",
      "Epoch 227, Loss: 0.1364922635257244, Final Batch Loss: 0.05160472169518471\n",
      "Epoch 228, Loss: 0.13281067460775375, Final Batch Loss: 0.07098838686943054\n",
      "Epoch 229, Loss: 0.1099979467689991, Final Batch Loss: 0.06904308497905731\n",
      "Epoch 230, Loss: 0.12235135957598686, Final Batch Loss: 0.075180783867836\n",
      "Epoch 231, Loss: 0.11166074872016907, Final Batch Loss: 0.03679005056619644\n",
      "Epoch 232, Loss: 0.10392464697360992, Final Batch Loss: 0.07126693427562714\n",
      "Epoch 233, Loss: 0.10638422518968582, Final Batch Loss: 0.03881991654634476\n",
      "Epoch 234, Loss: 0.1201836783438921, Final Batch Loss: 0.026598872616887093\n",
      "Epoch 235, Loss: 0.09221119061112404, Final Batch Loss: 0.04183005541563034\n",
      "Epoch 236, Loss: 0.07735492289066315, Final Batch Loss: 0.04235640540719032\n",
      "Epoch 237, Loss: 0.08981449902057648, Final Batch Loss: 0.05196192115545273\n",
      "Epoch 238, Loss: 0.07131876610219479, Final Batch Loss: 0.030001366510987282\n",
      "Epoch 239, Loss: 0.07988951727747917, Final Batch Loss: 0.03584415838122368\n",
      "Epoch 240, Loss: 0.14470328390598297, Final Batch Loss: 0.10669930279254913\n",
      "Epoch 241, Loss: 0.06896952539682388, Final Batch Loss: 0.026071064174175262\n",
      "Epoch 242, Loss: 0.1339377984404564, Final Batch Loss: 0.07324396818876266\n",
      "Epoch 243, Loss: 0.13644691184163094, Final Batch Loss: 0.1106325313448906\n",
      "Epoch 244, Loss: 0.057015785947442055, Final Batch Loss: 0.028594929724931717\n",
      "Epoch 245, Loss: 0.07679818570613861, Final Batch Loss: 0.04924653843045235\n",
      "Epoch 246, Loss: 0.1021028570830822, Final Batch Loss: 0.05684385821223259\n",
      "Epoch 247, Loss: 0.08688052743673325, Final Batch Loss: 0.04653317853808403\n",
      "Epoch 248, Loss: 0.09967240691184998, Final Batch Loss: 0.028177931904792786\n",
      "Epoch 249, Loss: 0.07277954369783401, Final Batch Loss: 0.032740380614995956\n",
      "Epoch 250, Loss: 0.13730619102716446, Final Batch Loss: 0.08360422402620316\n",
      "Epoch 251, Loss: 0.10266051813960075, Final Batch Loss: 0.052190568298101425\n",
      "Epoch 252, Loss: 0.07932618819177151, Final Batch Loss: 0.05287361517548561\n",
      "Epoch 253, Loss: 0.11114564165472984, Final Batch Loss: 0.060757819563150406\n",
      "Epoch 254, Loss: 0.10785076394677162, Final Batch Loss: 0.050154831260442734\n",
      "Epoch 255, Loss: 0.09155846759676933, Final Batch Loss: 0.052721861749887466\n",
      "Epoch 256, Loss: 0.0785874705761671, Final Batch Loss: 0.05231922119855881\n",
      "Epoch 257, Loss: 0.12464161217212677, Final Batch Loss: 0.07583433389663696\n",
      "Epoch 258, Loss: 0.07140717096626759, Final Batch Loss: 0.023218905553221703\n",
      "Epoch 259, Loss: 0.08743411675095558, Final Batch Loss: 0.022262971848249435\n",
      "Epoch 260, Loss: 0.10539219155907631, Final Batch Loss: 0.06506294757127762\n",
      "Epoch 261, Loss: 0.08103741332888603, Final Batch Loss: 0.03771306574344635\n",
      "Epoch 262, Loss: 0.09832140803337097, Final Batch Loss: 0.05710354074835777\n",
      "Epoch 263, Loss: 0.06408411264419556, Final Batch Loss: 0.017424102872610092\n",
      "Epoch 264, Loss: 0.0856550894677639, Final Batch Loss: 0.04744397848844528\n",
      "Epoch 265, Loss: 0.09878777153789997, Final Batch Loss: 0.029205286875367165\n",
      "Epoch 266, Loss: 0.125316571444273, Final Batch Loss: 0.0663003996014595\n",
      "Epoch 267, Loss: 0.10593615472316742, Final Batch Loss: 0.034497134387493134\n",
      "Epoch 268, Loss: 0.11228637397289276, Final Batch Loss: 0.07121752947568893\n",
      "Epoch 269, Loss: 0.10544624924659729, Final Batch Loss: 0.03164501488208771\n",
      "Epoch 270, Loss: 0.126641396433115, Final Batch Loss: 0.07269162684679031\n",
      "Epoch 271, Loss: 0.08889441192150116, Final Batch Loss: 0.0395374558866024\n",
      "Epoch 272, Loss: 0.10830061696469784, Final Batch Loss: 0.0790780559182167\n",
      "Epoch 273, Loss: 0.12041093409061432, Final Batch Loss: 0.052551835775375366\n",
      "Epoch 274, Loss: 0.07758809998631477, Final Batch Loss: 0.05369396507740021\n",
      "Epoch 275, Loss: 0.10462026856839657, Final Batch Loss: 0.07984399795532227\n",
      "Epoch 276, Loss: 0.08032621815800667, Final Batch Loss: 0.032565101981163025\n",
      "Epoch 277, Loss: 0.07088985294103622, Final Batch Loss: 0.027582745999097824\n",
      "Epoch 278, Loss: 0.0871981717646122, Final Batch Loss: 0.04794834926724434\n",
      "Epoch 279, Loss: 0.13726560212671757, Final Batch Loss: 0.10818014293909073\n",
      "Epoch 280, Loss: 0.07251829467713833, Final Batch Loss: 0.043994855135679245\n",
      "Epoch 281, Loss: 0.12282643094658852, Final Batch Loss: 0.04953715577721596\n",
      "Epoch 282, Loss: 0.10438485443592072, Final Batch Loss: 0.06304632872343063\n",
      "Epoch 283, Loss: 0.05083807557821274, Final Batch Loss: 0.02468089386820793\n",
      "Epoch 284, Loss: 0.13204053044319153, Final Batch Loss: 0.08440079540014267\n",
      "Epoch 285, Loss: 0.06877308711409569, Final Batch Loss: 0.023086778819561005\n",
      "Epoch 286, Loss: 0.07378029078245163, Final Batch Loss: 0.051440298557281494\n",
      "Epoch 287, Loss: 0.11472003906965256, Final Batch Loss: 0.06560298800468445\n",
      "Epoch 288, Loss: 0.13436387851834297, Final Batch Loss: 0.05930383875966072\n",
      "Epoch 289, Loss: 0.08228052593767643, Final Batch Loss: 0.06355059146881104\n",
      "Epoch 290, Loss: 0.08311015740036964, Final Batch Loss: 0.028720267117023468\n",
      "Epoch 291, Loss: 0.0768923219293356, Final Batch Loss: 0.02478322945535183\n",
      "Epoch 292, Loss: 0.06811364181339741, Final Batch Loss: 0.023792782798409462\n",
      "Epoch 293, Loss: 0.11021801084280014, Final Batch Loss: 0.08677702397108078\n",
      "Epoch 294, Loss: 0.11927292309701443, Final Batch Loss: 0.09795183688402176\n",
      "Epoch 295, Loss: 0.09173855744302273, Final Batch Loss: 0.023949293419718742\n",
      "Epoch 296, Loss: 0.08717071451246738, Final Batch Loss: 0.06059931591153145\n",
      "Epoch 297, Loss: 0.06703891418874264, Final Batch Loss: 0.022477256134152412\n",
      "Epoch 298, Loss: 0.0764838345348835, Final Batch Loss: 0.03872295469045639\n",
      "Epoch 299, Loss: 0.08767825551331043, Final Batch Loss: 0.06588223576545715\n",
      "Epoch 300, Loss: 0.1252826415002346, Final Batch Loss: 0.08375542610883713\n",
      "Epoch 301, Loss: 0.1173633262515068, Final Batch Loss: 0.03327213227748871\n",
      "Epoch 302, Loss: 0.07205101475119591, Final Batch Loss: 0.0426676943898201\n",
      "Epoch 303, Loss: 0.07201996259391308, Final Batch Loss: 0.025316691026091576\n",
      "Epoch 304, Loss: 0.11859180592000484, Final Batch Loss: 0.022155186161398888\n",
      "Epoch 305, Loss: 0.10810232162475586, Final Batch Loss: 0.03364018350839615\n",
      "Epoch 306, Loss: 0.1034280825406313, Final Batch Loss: 0.01697278954088688\n",
      "Epoch 307, Loss: 0.09021101519465446, Final Batch Loss: 0.03436896577477455\n",
      "Epoch 308, Loss: 0.08866121247410774, Final Batch Loss: 0.061219438910484314\n",
      "Epoch 309, Loss: 0.08101870492100716, Final Batch Loss: 0.042091526091098785\n",
      "Epoch 310, Loss: 0.05920582450926304, Final Batch Loss: 0.023241369053721428\n",
      "Epoch 311, Loss: 0.08116989023983479, Final Batch Loss: 0.06536523997783661\n",
      "Epoch 312, Loss: 0.0913747251033783, Final Batch Loss: 0.033778782933950424\n",
      "Epoch 313, Loss: 0.087128896266222, Final Batch Loss: 0.04115831479430199\n",
      "Epoch 314, Loss: 0.07883870135992765, Final Batch Loss: 0.009351315908133984\n",
      "Epoch 315, Loss: 0.0815040823072195, Final Batch Loss: 0.051798660308122635\n",
      "Epoch 316, Loss: 0.09725868701934814, Final Batch Loss: 0.059699513018131256\n",
      "Epoch 317, Loss: 0.08823089674115181, Final Batch Loss: 0.05501439794898033\n",
      "Epoch 318, Loss: 0.06885183043777943, Final Batch Loss: 0.022121677175164223\n",
      "Epoch 319, Loss: 0.10195605456829071, Final Batch Loss: 0.06126159802079201\n",
      "Epoch 320, Loss: 0.08429109677672386, Final Batch Loss: 0.0528690330684185\n",
      "Epoch 321, Loss: 0.08171059563755989, Final Batch Loss: 0.04875112697482109\n",
      "Epoch 322, Loss: 0.07513714209198952, Final Batch Loss: 0.04052923619747162\n",
      "Epoch 323, Loss: 0.08030552603304386, Final Batch Loss: 0.030925052240490913\n",
      "Epoch 324, Loss: 0.08361819945275784, Final Batch Loss: 0.06314262747764587\n",
      "Epoch 325, Loss: 0.07897473126649857, Final Batch Loss: 0.04611535370349884\n",
      "Epoch 326, Loss: 0.09068835340440273, Final Batch Loss: 0.07080907374620438\n",
      "Epoch 327, Loss: 0.0554326456040144, Final Batch Loss: 0.035971641540527344\n",
      "Epoch 328, Loss: 0.07548617944121361, Final Batch Loss: 0.04093584790825844\n",
      "Epoch 329, Loss: 0.04876040294766426, Final Batch Loss: 0.020241886377334595\n",
      "Epoch 330, Loss: 0.1228301040828228, Final Batch Loss: 0.07178135961294174\n",
      "Epoch 331, Loss: 0.07620035670697689, Final Batch Loss: 0.01800026185810566\n",
      "Epoch 332, Loss: 0.07897263206541538, Final Batch Loss: 0.030345140025019646\n",
      "Epoch 333, Loss: 0.05122421868145466, Final Batch Loss: 0.018856776878237724\n",
      "Epoch 334, Loss: 0.0743443351238966, Final Batch Loss: 0.028695276007056236\n",
      "Epoch 335, Loss: 0.0951361283659935, Final Batch Loss: 0.04039689898490906\n",
      "Epoch 336, Loss: 0.05476061813533306, Final Batch Loss: 0.02021077834069729\n",
      "Epoch 337, Loss: 0.11409398354589939, Final Batch Loss: 0.024892346933484077\n",
      "Epoch 338, Loss: 0.06969502381980419, Final Batch Loss: 0.045223139226436615\n",
      "Epoch 339, Loss: 0.08194665797054768, Final Batch Loss: 0.058741454035043716\n",
      "Epoch 340, Loss: 0.07932807132601738, Final Batch Loss: 0.04056419059634209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341, Loss: 0.06943738646805286, Final Batch Loss: 0.04553559049963951\n",
      "Epoch 342, Loss: 0.11388468369841576, Final Batch Loss: 0.05977773666381836\n",
      "Epoch 343, Loss: 0.08878713101148605, Final Batch Loss: 0.03764127194881439\n",
      "Epoch 344, Loss: 0.07118739979341626, Final Batch Loss: 0.0077073280699551105\n",
      "Epoch 345, Loss: 0.06614714674651623, Final Batch Loss: 0.01627401076257229\n",
      "Epoch 346, Loss: 0.06745726801455021, Final Batch Loss: 0.030943194404244423\n",
      "Epoch 347, Loss: 0.06484689563512802, Final Batch Loss: 0.029022961854934692\n",
      "Epoch 348, Loss: 0.05189050920307636, Final Batch Loss: 0.0304675605148077\n",
      "Epoch 349, Loss: 0.03706669341772795, Final Batch Loss: 0.010754627175629139\n",
      "Epoch 350, Loss: 0.10813109204173088, Final Batch Loss: 0.07600674033164978\n",
      "Epoch 351, Loss: 0.06098710000514984, Final Batch Loss: 0.03540623560547829\n",
      "Epoch 352, Loss: 0.057590801268815994, Final Batch Loss: 0.029352223500609398\n",
      "Epoch 353, Loss: 0.06556807085871696, Final Batch Loss: 0.031359802931547165\n",
      "Epoch 354, Loss: 0.07400454767048359, Final Batch Loss: 0.018164241686463356\n",
      "Epoch 355, Loss: 0.07995976135134697, Final Batch Loss: 0.041806720197200775\n",
      "Epoch 356, Loss: 0.06610919535160065, Final Batch Loss: 0.041211728006601334\n",
      "Epoch 357, Loss: 0.05295216105878353, Final Batch Loss: 0.018134931102395058\n",
      "Epoch 358, Loss: 0.05283939652144909, Final Batch Loss: 0.020298680290579796\n",
      "Epoch 359, Loss: 0.08276070654392242, Final Batch Loss: 0.015543237328529358\n",
      "Epoch 360, Loss: 0.08075755462050438, Final Batch Loss: 0.04270073026418686\n",
      "Epoch 361, Loss: 0.060860494151711464, Final Batch Loss: 0.03625332936644554\n",
      "Epoch 362, Loss: 0.0624369140714407, Final Batch Loss: 0.02197694592177868\n",
      "Epoch 363, Loss: 0.07863564789295197, Final Batch Loss: 0.024572201073169708\n",
      "Epoch 364, Loss: 0.08151351474225521, Final Batch Loss: 0.03053351677954197\n",
      "Epoch 365, Loss: 0.046205807477235794, Final Batch Loss: 0.017759228125214577\n",
      "Epoch 366, Loss: 0.086761724203825, Final Batch Loss: 0.0527050644159317\n",
      "Epoch 367, Loss: 0.04032178595662117, Final Batch Loss: 0.02448977902531624\n",
      "Epoch 368, Loss: 0.07655076310038567, Final Batch Loss: 0.024818874895572662\n",
      "Epoch 369, Loss: 0.0926085114479065, Final Batch Loss: 0.046428751200437546\n",
      "Epoch 370, Loss: 0.08410010859370232, Final Batch Loss: 0.04837322607636452\n",
      "Epoch 371, Loss: 0.08604764938354492, Final Batch Loss: 0.05218427628278732\n",
      "Epoch 372, Loss: 0.06748561188578606, Final Batch Loss: 0.04806962236762047\n",
      "Epoch 373, Loss: 0.054756298661231995, Final Batch Loss: 0.031376782804727554\n",
      "Epoch 374, Loss: 0.09007273986935616, Final Batch Loss: 0.03846808522939682\n",
      "Epoch 375, Loss: 0.05553766619414091, Final Batch Loss: 0.01308904867619276\n",
      "Epoch 376, Loss: 0.05870017781853676, Final Batch Loss: 0.024493031203746796\n",
      "Epoch 377, Loss: 0.06586012244224548, Final Batch Loss: 0.030683211982250214\n",
      "Epoch 378, Loss: 0.04518221132457256, Final Batch Loss: 0.021035900339484215\n",
      "Epoch 379, Loss: 0.0798012875020504, Final Batch Loss: 0.03750167787075043\n",
      "Epoch 380, Loss: 0.07299352437257767, Final Batch Loss: 0.05485515296459198\n",
      "Epoch 381, Loss: 0.08820069581270218, Final Batch Loss: 0.050218354910612106\n",
      "Epoch 382, Loss: 0.05990364961326122, Final Batch Loss: 0.029259784147143364\n",
      "Epoch 383, Loss: 0.08613420277833939, Final Batch Loss: 0.057585060596466064\n",
      "Epoch 384, Loss: 0.03934915363788605, Final Batch Loss: 0.012591583654284477\n",
      "Epoch 385, Loss: 0.04715498397126794, Final Batch Loss: 0.007790005300194025\n",
      "Epoch 386, Loss: 0.06368811428546906, Final Batch Loss: 0.040473464876413345\n",
      "Epoch 387, Loss: 0.07232817634940147, Final Batch Loss: 0.04145447537302971\n",
      "Epoch 388, Loss: 0.029623590409755707, Final Batch Loss: 0.011792344972491264\n",
      "Epoch 389, Loss: 0.0461411289870739, Final Batch Loss: 0.03333147242665291\n",
      "Epoch 390, Loss: 0.04710736498236656, Final Batch Loss: 0.007968060672283173\n",
      "Epoch 391, Loss: 0.06454937905073166, Final Batch Loss: 0.024665385484695435\n",
      "Epoch 392, Loss: 0.03858328051865101, Final Batch Loss: 0.008142245933413506\n",
      "Epoch 393, Loss: 0.0876035988330841, Final Batch Loss: 0.06824236363172531\n",
      "Epoch 394, Loss: 0.04936623573303223, Final Batch Loss: 0.018601490184664726\n",
      "Epoch 395, Loss: 0.040790751576423645, Final Batch Loss: 0.02094932273030281\n",
      "Epoch 396, Loss: 0.06075039505958557, Final Batch Loss: 0.019865818321704865\n",
      "Epoch 397, Loss: 0.04127633851021528, Final Batch Loss: 0.011934109963476658\n",
      "Epoch 398, Loss: 0.0552956759929657, Final Batch Loss: 0.02966519072651863\n",
      "Epoch 399, Loss: 0.07076841779053211, Final Batch Loss: 0.04636901244521141\n",
      "Epoch 400, Loss: 0.08192500472068787, Final Batch Loss: 0.044648174196481705\n",
      "Epoch 401, Loss: 0.06983355060219765, Final Batch Loss: 0.04464543238282204\n",
      "Epoch 402, Loss: 0.08764790371060371, Final Batch Loss: 0.05591047555208206\n",
      "Epoch 403, Loss: 0.058344801887869835, Final Batch Loss: 0.029391249641776085\n",
      "Epoch 404, Loss: 0.06135218217968941, Final Batch Loss: 0.013193164020776749\n",
      "Epoch 405, Loss: 0.04758244939148426, Final Batch Loss: 0.01811126433312893\n",
      "Epoch 406, Loss: 0.04139405582100153, Final Batch Loss: 0.015547278337180614\n",
      "Epoch 407, Loss: 0.042249664664268494, Final Batch Loss: 0.010006137192249298\n",
      "Epoch 408, Loss: 0.04618658125400543, Final Batch Loss: 0.026517203077673912\n",
      "Epoch 409, Loss: 0.059629688039422035, Final Batch Loss: 0.04488487169146538\n",
      "Epoch 410, Loss: 0.05263851210474968, Final Batch Loss: 0.017707183957099915\n",
      "Epoch 411, Loss: 0.022477060556411743, Final Batch Loss: 0.013140643946826458\n",
      "Epoch 412, Loss: 0.08839831128716469, Final Batch Loss: 0.04720695689320564\n",
      "Epoch 413, Loss: 0.06444472074508667, Final Batch Loss: 0.040035225450992584\n",
      "Epoch 414, Loss: 0.053568869829177856, Final Batch Loss: 0.02702462486922741\n",
      "Epoch 415, Loss: 0.051415033638477325, Final Batch Loss: 0.026441581547260284\n",
      "Epoch 416, Loss: 0.10915150865912437, Final Batch Loss: 0.02419830486178398\n",
      "Epoch 417, Loss: 0.07151930406689644, Final Batch Loss: 0.04426756873726845\n",
      "Epoch 418, Loss: 0.03910858370363712, Final Batch Loss: 0.018179384991526604\n",
      "Epoch 419, Loss: 0.05122663639485836, Final Batch Loss: 0.02570183016359806\n",
      "Epoch 420, Loss: 0.06871190294623375, Final Batch Loss: 0.0325770266354084\n",
      "Epoch 421, Loss: 0.03887030482292175, Final Batch Loss: 0.015396291390061378\n",
      "Epoch 422, Loss: 0.04387299157679081, Final Batch Loss: 0.019825240597128868\n",
      "Epoch 423, Loss: 0.06710412725806236, Final Batch Loss: 0.028047766536474228\n",
      "Epoch 424, Loss: 0.0704188197851181, Final Batch Loss: 0.042086161673069\n",
      "Epoch 425, Loss: 0.039910875260829926, Final Batch Loss: 0.022245891392230988\n",
      "Epoch 426, Loss: 0.06046012230217457, Final Batch Loss: 0.030949395149946213\n",
      "Epoch 427, Loss: 0.049947891384363174, Final Batch Loss: 0.03195605427026749\n",
      "Epoch 428, Loss: 0.09488038159906864, Final Batch Loss: 0.07060832530260086\n",
      "Epoch 429, Loss: 0.051362767815589905, Final Batch Loss: 0.03363240510225296\n",
      "Epoch 430, Loss: 0.051700590178370476, Final Batch Loss: 0.016871454194188118\n",
      "Epoch 431, Loss: 0.05759122595191002, Final Batch Loss: 0.021707098931074142\n",
      "Epoch 432, Loss: 0.08297759294509888, Final Batch Loss: 0.06450031697750092\n",
      "Epoch 433, Loss: 0.030797073617577553, Final Batch Loss: 0.02331641875207424\n",
      "Epoch 434, Loss: 0.029614759609103203, Final Batch Loss: 0.012916579842567444\n",
      "Epoch 435, Loss: 0.03460593521595001, Final Batch Loss: 0.01788243278861046\n",
      "Epoch 436, Loss: 0.047814540565013885, Final Batch Loss: 0.010787494480609894\n",
      "Epoch 437, Loss: 0.06554543226957321, Final Batch Loss: 0.02480105683207512\n",
      "Epoch 438, Loss: 0.04528931062668562, Final Batch Loss: 0.03206915035843849\n",
      "Epoch 439, Loss: 0.048058124259114265, Final Batch Loss: 0.033610016107559204\n",
      "Epoch 440, Loss: 0.05615425296127796, Final Batch Loss: 0.0065256040543317795\n",
      "Epoch 441, Loss: 0.09137384593486786, Final Batch Loss: 0.036413393914699554\n",
      "Epoch 442, Loss: 0.057087672874331474, Final Batch Loss: 0.03651559725403786\n",
      "Epoch 443, Loss: 0.038270559161901474, Final Batch Loss: 0.019970344379544258\n",
      "Epoch 444, Loss: 0.038790369406342506, Final Batch Loss: 0.009263116866350174\n",
      "Epoch 445, Loss: 0.06548630818724632, Final Batch Loss: 0.032654669135808945\n",
      "Epoch 446, Loss: 0.05400841869413853, Final Batch Loss: 0.016411105170845985\n",
      "Epoch 447, Loss: 0.0454391036182642, Final Batch Loss: 0.022655673325061798\n",
      "Epoch 448, Loss: 0.08623556047677994, Final Batch Loss: 0.03257934749126434\n",
      "Epoch 449, Loss: 0.03562226053327322, Final Batch Loss: 0.021473899483680725\n",
      "Epoch 450, Loss: 0.04721353389322758, Final Batch Loss: 0.02498031221330166\n",
      "Epoch 451, Loss: 0.06119917705655098, Final Batch Loss: 0.02636801451444626\n",
      "Epoch 452, Loss: 0.04822781682014465, Final Batch Loss: 0.01752672716975212\n",
      "Epoch 453, Loss: 0.0591565053910017, Final Batch Loss: 0.008448025211691856\n",
      "Epoch 454, Loss: 0.08655373379588127, Final Batch Loss: 0.054074693471193314\n",
      "Epoch 455, Loss: 0.041998155415058136, Final Batch Loss: 0.02444363385438919\n",
      "Epoch 456, Loss: 0.03797862213104963, Final Batch Loss: 0.014760221354663372\n",
      "Epoch 457, Loss: 0.043904149904847145, Final Batch Loss: 0.03562941029667854\n",
      "Epoch 458, Loss: 0.05028382129967213, Final Batch Loss: 0.008965449407696724\n",
      "Epoch 459, Loss: 0.04056553356349468, Final Batch Loss: 0.020895056426525116\n",
      "Epoch 460, Loss: 0.06063470244407654, Final Batch Loss: 0.017449773848056793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461, Loss: 0.0487317917868495, Final Batch Loss: 0.012770059518516064\n",
      "Epoch 462, Loss: 0.028718431014567614, Final Batch Loss: 0.004335189703851938\n",
      "Epoch 463, Loss: 0.042472632601857185, Final Batch Loss: 0.014313796535134315\n",
      "Epoch 464, Loss: 0.01847628178074956, Final Batch Loss: 0.0064447238110005856\n",
      "Epoch 465, Loss: 0.033806754276156425, Final Batch Loss: 0.010029992088675499\n",
      "Epoch 466, Loss: 0.06138037145137787, Final Batch Loss: 0.03400389105081558\n",
      "Epoch 467, Loss: 0.05475881602615118, Final Batch Loss: 0.04160654917359352\n",
      "Epoch 468, Loss: 0.03389884624630213, Final Batch Loss: 0.020821649581193924\n",
      "Epoch 469, Loss: 0.04312466084957123, Final Batch Loss: 0.017336001619696617\n",
      "Epoch 470, Loss: 0.01711550378240645, Final Batch Loss: 0.0023071367759257555\n",
      "Epoch 471, Loss: 0.043922292068600655, Final Batch Loss: 0.019072990864515305\n",
      "Epoch 472, Loss: 0.06290345080196857, Final Batch Loss: 0.04537580907344818\n",
      "Epoch 473, Loss: 0.03221643902361393, Final Batch Loss: 0.015086216852068901\n",
      "Epoch 474, Loss: 0.030352977104485035, Final Batch Loss: 0.010440672747790813\n",
      "Epoch 475, Loss: 0.04376986436545849, Final Batch Loss: 0.012621792033314705\n",
      "Epoch 476, Loss: 0.01516219088807702, Final Batch Loss: 0.006434209179133177\n",
      "Epoch 477, Loss: 0.05190479941666126, Final Batch Loss: 0.0327361561357975\n",
      "Epoch 478, Loss: 0.0362551286816597, Final Batch Loss: 0.007453834637999535\n",
      "Epoch 479, Loss: 0.030530793592333794, Final Batch Loss: 0.016901571303606033\n",
      "Epoch 480, Loss: 0.04151836782693863, Final Batch Loss: 0.02018534578382969\n",
      "Epoch 481, Loss: 0.02911253459751606, Final Batch Loss: 0.015408008359372616\n",
      "Epoch 482, Loss: 0.03215348906815052, Final Batch Loss: 0.01837502047419548\n",
      "Epoch 483, Loss: 0.0268739378079772, Final Batch Loss: 0.007304987870156765\n",
      "Epoch 484, Loss: 0.05354081094264984, Final Batch Loss: 0.020909816026687622\n",
      "Epoch 485, Loss: 0.040085870772600174, Final Batch Loss: 0.02188412845134735\n",
      "Epoch 486, Loss: 0.023339062929153442, Final Batch Loss: 0.011596404947340488\n",
      "Epoch 487, Loss: 0.036374472081661224, Final Batch Loss: 0.018632348626852036\n",
      "Epoch 488, Loss: 0.03818661626428366, Final Batch Loss: 0.012360169552266598\n",
      "Epoch 489, Loss: 0.056520868092775345, Final Batch Loss: 0.036448244005441666\n",
      "Epoch 490, Loss: 0.03628624975681305, Final Batch Loss: 0.014446942135691643\n",
      "Epoch 491, Loss: 0.02550250105559826, Final Batch Loss: 0.011960159987211227\n",
      "Epoch 492, Loss: 0.04679487086832523, Final Batch Loss: 0.02628345601260662\n",
      "Epoch 493, Loss: 0.01833462342619896, Final Batch Loss: 0.005474641919136047\n",
      "Epoch 494, Loss: 0.04418631922453642, Final Batch Loss: 0.03176632523536682\n",
      "Epoch 495, Loss: 0.025624110363423824, Final Batch Loss: 0.01319226436316967\n",
      "Epoch 496, Loss: 0.04807310411706567, Final Batch Loss: 0.0050224424339830875\n",
      "Epoch 497, Loss: 0.05358448810875416, Final Batch Loss: 0.027920149266719818\n",
      "Epoch 498, Loss: 0.020742245018482208, Final Batch Loss: 0.009154739789664745\n",
      "Epoch 499, Loss: 0.08040612936019897, Final Batch Loss: 0.04202795773744583\n",
      "Epoch 500, Loss: 0.031960743479430676, Final Batch Loss: 0.021266983821988106\n",
      "Epoch 501, Loss: 0.032696669921278954, Final Batch Loss: 0.010868240147829056\n",
      "Epoch 502, Loss: 0.03652125783264637, Final Batch Loss: 0.013766473159193993\n",
      "Epoch 503, Loss: 0.02209837595000863, Final Batch Loss: 0.016450976952910423\n",
      "Epoch 504, Loss: 0.040654104202985764, Final Batch Loss: 0.023242808878421783\n",
      "Epoch 505, Loss: 0.03176800347864628, Final Batch Loss: 0.017992183566093445\n",
      "Epoch 506, Loss: 0.039579697884619236, Final Batch Loss: 0.032030511647462845\n",
      "Epoch 507, Loss: 0.042152851819992065, Final Batch Loss: 0.032076410949230194\n",
      "Epoch 508, Loss: 0.01563650369644165, Final Batch Loss: 0.006248916499316692\n",
      "Epoch 509, Loss: 0.04396349750459194, Final Batch Loss: 0.012769732624292374\n",
      "Epoch 510, Loss: 0.04893793165683746, Final Batch Loss: 0.031704310327768326\n",
      "Epoch 511, Loss: 0.014649501070380211, Final Batch Loss: 0.011550855822861195\n",
      "Epoch 512, Loss: 0.03151186183094978, Final Batch Loss: 0.015085194259881973\n",
      "Epoch 513, Loss: 0.04414362832903862, Final Batch Loss: 0.026510976254940033\n",
      "Epoch 514, Loss: 0.02963430341333151, Final Batch Loss: 0.013158119283616543\n",
      "Epoch 515, Loss: 0.07253017462790012, Final Batch Loss: 0.055823132395744324\n",
      "Epoch 516, Loss: 0.02249972801655531, Final Batch Loss: 0.008340236730873585\n",
      "Epoch 517, Loss: 0.03098685434088111, Final Batch Loss: 0.006425762083381414\n",
      "Epoch 518, Loss: 0.041705713141709566, Final Batch Loss: 0.0042513576336205006\n",
      "Epoch 519, Loss: 0.03998812101781368, Final Batch Loss: 0.02272643707692623\n",
      "Epoch 520, Loss: 0.044227590784430504, Final Batch Loss: 0.023047111928462982\n",
      "Epoch 521, Loss: 0.05076307151466608, Final Batch Loss: 0.042177118360996246\n",
      "Epoch 522, Loss: 0.012059183325618505, Final Batch Loss: 0.006348864175379276\n",
      "Epoch 523, Loss: 0.04369764216244221, Final Batch Loss: 0.014254048466682434\n",
      "Epoch 524, Loss: 0.035862911492586136, Final Batch Loss: 0.026544634252786636\n",
      "Epoch 525, Loss: 0.04551577568054199, Final Batch Loss: 0.0244298055768013\n",
      "Epoch 526, Loss: 0.021662537939846516, Final Batch Loss: 0.01035468652844429\n",
      "Epoch 527, Loss: 0.02442072657868266, Final Batch Loss: 0.005423023831099272\n",
      "Epoch 528, Loss: 0.02871574554592371, Final Batch Loss: 0.00829696748405695\n",
      "Epoch 529, Loss: 0.04396827705204487, Final Batch Loss: 0.02865879237651825\n",
      "Epoch 530, Loss: 0.04061055835336447, Final Batch Loss: 0.012471440248191357\n",
      "Epoch 531, Loss: 0.03102098498493433, Final Batch Loss: 0.01511294860392809\n",
      "Epoch 532, Loss: 0.013137945206835866, Final Batch Loss: 0.002365358406677842\n",
      "Epoch 533, Loss: 0.02477953117340803, Final Batch Loss: 0.013134059496223927\n",
      "Epoch 534, Loss: 0.020849513821303844, Final Batch Loss: 0.006941074505448341\n",
      "Epoch 535, Loss: 0.02827757317572832, Final Batch Loss: 0.017551986500620842\n",
      "Epoch 536, Loss: 0.026629825122654438, Final Batch Loss: 0.01206198800355196\n",
      "Epoch 537, Loss: 0.02548749279230833, Final Batch Loss: 0.01661352999508381\n",
      "Epoch 538, Loss: 0.03836904838681221, Final Batch Loss: 0.017980514094233513\n",
      "Epoch 539, Loss: 0.018108977936208248, Final Batch Loss: 0.003572484478354454\n",
      "Epoch 540, Loss: 0.04169160034507513, Final Batch Loss: 0.02886357344686985\n",
      "Epoch 541, Loss: 0.016860416624695063, Final Batch Loss: 0.0026869974099099636\n",
      "Epoch 542, Loss: 0.03983464278280735, Final Batch Loss: 0.015678809955716133\n",
      "Epoch 543, Loss: 0.03620618022978306, Final Batch Loss: 0.020634789019823074\n",
      "Epoch 544, Loss: 0.03995847422629595, Final Batch Loss: 0.01277862023562193\n",
      "Epoch 545, Loss: 0.044416265562176704, Final Batch Loss: 0.024857284501194954\n",
      "Epoch 546, Loss: 0.026984453201293945, Final Batch Loss: 0.014694174751639366\n",
      "Epoch 547, Loss: 0.05825249757617712, Final Batch Loss: 0.05265091359615326\n",
      "Epoch 548, Loss: 0.022181353997439146, Final Batch Loss: 0.014985819347202778\n",
      "Epoch 549, Loss: 0.04801063425838947, Final Batch Loss: 0.012284526601433754\n",
      "Epoch 550, Loss: 0.03128623962402344, Final Batch Loss: 0.01577330380678177\n",
      "Epoch 551, Loss: 0.025832524057477713, Final Batch Loss: 0.004811172839254141\n",
      "Epoch 552, Loss: 0.026200124993920326, Final Batch Loss: 0.0099100973457098\n",
      "Epoch 553, Loss: 0.027231395710259676, Final Batch Loss: 0.004152341280132532\n",
      "Epoch 554, Loss: 0.04569208435714245, Final Batch Loss: 0.01708992011845112\n",
      "Epoch 555, Loss: 0.029188784770667553, Final Batch Loss: 0.011205512098968029\n",
      "Epoch 556, Loss: 0.015533276367932558, Final Batch Loss: 0.004929476883262396\n",
      "Epoch 557, Loss: 0.024837682954967022, Final Batch Loss: 0.0063718343153595924\n",
      "Epoch 558, Loss: 0.04666606895625591, Final Batch Loss: 0.026545710861682892\n",
      "Epoch 559, Loss: 0.034068336710333824, Final Batch Loss: 0.01576615869998932\n",
      "Epoch 560, Loss: 0.01565919304266572, Final Batch Loss: 0.009525473229587078\n",
      "Epoch 561, Loss: 0.020921657793223858, Final Batch Loss: 0.01138655561953783\n",
      "Epoch 562, Loss: 0.012142813298851252, Final Batch Loss: 0.004500578157603741\n",
      "Epoch 563, Loss: 0.018586739082820714, Final Batch Loss: 0.001872957800514996\n",
      "Epoch 564, Loss: 0.04580748174339533, Final Batch Loss: 0.010447927750647068\n",
      "Epoch 565, Loss: 0.029300625436007977, Final Batch Loss: 0.02084866538643837\n",
      "Epoch 566, Loss: 0.016043394338339567, Final Batch Loss: 0.0054633780382573605\n",
      "Epoch 567, Loss: 0.0341870104894042, Final Batch Loss: 0.014008297584950924\n",
      "Epoch 568, Loss: 0.04405871964991093, Final Batch Loss: 0.016660479828715324\n",
      "Epoch 569, Loss: 0.050803206861019135, Final Batch Loss: 0.011174276471138\n",
      "Epoch 570, Loss: 0.013055318035185337, Final Batch Loss: 0.008700782433152199\n",
      "Epoch 571, Loss: 0.016492754220962524, Final Batch Loss: 0.008504264056682587\n",
      "Epoch 572, Loss: 0.011486684437841177, Final Batch Loss: 0.008245962671935558\n",
      "Epoch 573, Loss: 0.022932663559913635, Final Batch Loss: 0.010189125314354897\n",
      "Epoch 574, Loss: 0.03622489329427481, Final Batch Loss: 0.014644461683928967\n",
      "Epoch 575, Loss: 0.026471632532775402, Final Batch Loss: 0.009621822275221348\n",
      "Epoch 576, Loss: 0.043425170704722404, Final Batch Loss: 0.025010181590914726\n",
      "Epoch 577, Loss: 0.016113953664898872, Final Batch Loss: 0.006874589249491692\n",
      "Epoch 578, Loss: 0.014652831014245749, Final Batch Loss: 0.0054889763705432415\n",
      "Epoch 579, Loss: 0.029565975069999695, Final Batch Loss: 0.01425811555236578\n",
      "Epoch 580, Loss: 0.01768496260046959, Final Batch Loss: 0.006766255013644695\n",
      "Epoch 581, Loss: 0.0197651837952435, Final Batch Loss: 0.012414634227752686\n",
      "Epoch 582, Loss: 0.014009732753038406, Final Batch Loss: 0.008541944436728954\n",
      "Epoch 583, Loss: 0.018672602716833353, Final Batch Loss: 0.004003074485808611\n",
      "Epoch 584, Loss: 0.031108247116208076, Final Batch Loss: 0.00533733144402504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 585, Loss: 0.014933837577700615, Final Batch Loss: 0.01227056048810482\n",
      "Epoch 586, Loss: 0.02819674089550972, Final Batch Loss: 0.00969228520989418\n",
      "Epoch 587, Loss: 0.016546801663935184, Final Batch Loss: 0.008668188005685806\n",
      "Epoch 588, Loss: 0.01929283980280161, Final Batch Loss: 0.008485979400575161\n",
      "Epoch 589, Loss: 0.022523208521306515, Final Batch Loss: 0.017247281968593597\n",
      "Epoch 590, Loss: 0.023926973808556795, Final Batch Loss: 0.0027980231679975986\n",
      "Epoch 591, Loss: 0.013488840777426958, Final Batch Loss: 0.006973967421799898\n",
      "Epoch 592, Loss: 0.04434187896549702, Final Batch Loss: 0.028342194855213165\n",
      "Epoch 593, Loss: 0.06935915956273675, Final Batch Loss: 0.0645487904548645\n",
      "Epoch 594, Loss: 0.016459001693874598, Final Batch Loss: 0.006015195976942778\n",
      "Epoch 595, Loss: 0.028043841011822224, Final Batch Loss: 0.01593625918030739\n",
      "Epoch 596, Loss: 0.023718757554888725, Final Batch Loss: 0.010905229486525059\n",
      "Epoch 597, Loss: 0.02422061376273632, Final Batch Loss: 0.01652125082910061\n",
      "Epoch 598, Loss: 0.03278495371341705, Final Batch Loss: 0.02224748581647873\n",
      "Epoch 599, Loss: 0.0329977897927165, Final Batch Loss: 0.021168945357203484\n",
      "Epoch 600, Loss: 0.013028943445533514, Final Batch Loss: 0.008163283579051495\n",
      "Epoch 601, Loss: 0.029104555491358042, Final Batch Loss: 0.005570628214627504\n",
      "Epoch 602, Loss: 0.011809108778834343, Final Batch Loss: 0.0036074938252568245\n",
      "Epoch 603, Loss: 0.03718130104243755, Final Batch Loss: 0.022708509117364883\n",
      "Epoch 604, Loss: 0.014485277701169252, Final Batch Loss: 0.004184048157185316\n",
      "Epoch 605, Loss: 0.027370895259082317, Final Batch Loss: 0.010844063945114613\n",
      "Epoch 606, Loss: 0.017892529256641865, Final Batch Loss: 0.009367971681058407\n",
      "Epoch 607, Loss: 0.021058002253994346, Final Batch Loss: 0.0035169997718185186\n",
      "Epoch 608, Loss: 0.019702267833054066, Final Batch Loss: 0.011736001819372177\n",
      "Epoch 609, Loss: 0.019207416102290154, Final Batch Loss: 0.011547011323273182\n",
      "Epoch 610, Loss: 0.023524338379502296, Final Batch Loss: 0.015117107890546322\n",
      "Epoch 611, Loss: 0.020060026086866856, Final Batch Loss: 0.008403363637626171\n",
      "Epoch 612, Loss: 0.0352232966106385, Final Batch Loss: 0.03160213306546211\n",
      "Epoch 613, Loss: 0.02192489430308342, Final Batch Loss: 0.009285260923206806\n",
      "Epoch 614, Loss: 0.020247054286301136, Final Batch Loss: 0.010566305369138718\n",
      "Epoch 615, Loss: 0.015145973768085241, Final Batch Loss: 0.004872156772762537\n",
      "Epoch 616, Loss: 0.013078379910439253, Final Batch Loss: 0.006535448133945465\n",
      "Epoch 617, Loss: 0.019978344906121492, Final Batch Loss: 0.0158989317715168\n",
      "Epoch 618, Loss: 0.03928881138563156, Final Batch Loss: 0.01971951685845852\n",
      "Epoch 619, Loss: 0.017890993040055037, Final Batch Loss: 0.01344978529959917\n",
      "Epoch 620, Loss: 0.010621128138154745, Final Batch Loss: 0.005961745511740446\n",
      "Epoch 621, Loss: 0.0195159949362278, Final Batch Loss: 0.008953786455094814\n",
      "Epoch 622, Loss: 0.014974947087466717, Final Batch Loss: 0.010572319850325584\n",
      "Epoch 623, Loss: 0.028552000410854816, Final Batch Loss: 0.009137450717389584\n",
      "Epoch 624, Loss: 0.03825219301506877, Final Batch Loss: 0.004963166546076536\n",
      "Epoch 625, Loss: 0.012606953270733356, Final Batch Loss: 0.0070265899412333965\n",
      "Epoch 626, Loss: 0.021321316249668598, Final Batch Loss: 0.007877073250710964\n",
      "Epoch 627, Loss: 0.014048966579139233, Final Batch Loss: 0.005658517591655254\n",
      "Epoch 628, Loss: 0.01424071192741394, Final Batch Loss: 0.006191768683493137\n",
      "Epoch 629, Loss: 0.018994132289662957, Final Batch Loss: 0.015700122341513634\n",
      "Epoch 630, Loss: 0.024928065948188305, Final Batch Loss: 0.01683761738240719\n",
      "Epoch 631, Loss: 0.03096701391041279, Final Batch Loss: 0.015228262171149254\n",
      "Epoch 632, Loss: 0.03059559455141425, Final Batch Loss: 0.004726835992187262\n",
      "Epoch 633, Loss: 0.025489683263003826, Final Batch Loss: 0.006613443605601788\n",
      "Epoch 634, Loss: 0.028955796733498573, Final Batch Loss: 0.025273442268371582\n",
      "Epoch 635, Loss: 0.028014973271638155, Final Batch Loss: 0.021000372245907784\n",
      "Epoch 636, Loss: 0.028242929838597775, Final Batch Loss: 0.01347246952354908\n",
      "Epoch 637, Loss: 0.01703138998709619, Final Batch Loss: 0.0031518794130533934\n",
      "Epoch 638, Loss: 0.034312029369175434, Final Batch Loss: 0.020634125918149948\n",
      "Epoch 639, Loss: 0.029120026156306267, Final Batch Loss: 0.018166836351156235\n",
      "Epoch 640, Loss: 0.014338932000100613, Final Batch Loss: 0.005945579148828983\n",
      "Epoch 641, Loss: 0.0377377076074481, Final Batch Loss: 0.007800034247338772\n",
      "Epoch 642, Loss: 0.020011803600937128, Final Batch Loss: 0.007403515744954348\n",
      "Epoch 643, Loss: 0.01737787015736103, Final Batch Loss: 0.01004412118345499\n",
      "Epoch 644, Loss: 0.023120959289371967, Final Batch Loss: 0.010755922645330429\n",
      "Epoch 645, Loss: 0.013298148289322853, Final Batch Loss: 0.00789504311978817\n",
      "Epoch 646, Loss: 0.023578795604407787, Final Batch Loss: 0.01902991533279419\n",
      "Epoch 647, Loss: 0.016291781794279814, Final Batch Loss: 0.009332755580544472\n",
      "Epoch 648, Loss: 0.019033068092539907, Final Batch Loss: 0.016835642978549004\n",
      "Epoch 649, Loss: 0.02416710276156664, Final Batch Loss: 0.013849340379238129\n",
      "Epoch 650, Loss: 0.01602397719398141, Final Batch Loss: 0.006919767241925001\n",
      "Epoch 651, Loss: 0.04044930264353752, Final Batch Loss: 0.0145114716142416\n",
      "Epoch 652, Loss: 0.027217091992497444, Final Batch Loss: 0.012715271674096584\n",
      "Epoch 653, Loss: 0.031199205201119184, Final Batch Loss: 0.02433815598487854\n",
      "Epoch 654, Loss: 0.015343336388468742, Final Batch Loss: 0.005082319490611553\n",
      "Epoch 655, Loss: 0.03428485011681914, Final Batch Loss: 0.0268013346940279\n",
      "Epoch 656, Loss: 0.04765959829092026, Final Batch Loss: 0.01857413724064827\n",
      "Epoch 657, Loss: 0.025005646515637636, Final Batch Loss: 0.018494034186005592\n",
      "Epoch 658, Loss: 0.040797611232846975, Final Batch Loss: 0.037491556257009506\n",
      "Epoch 659, Loss: 0.030458804219961166, Final Batch Loss: 0.015183390118181705\n",
      "Epoch 660, Loss: 0.02110188454389572, Final Batch Loss: 0.006757422350347042\n",
      "Epoch 661, Loss: 0.015144734643399715, Final Batch Loss: 0.004213953390717506\n",
      "Epoch 662, Loss: 0.015116269001737237, Final Batch Loss: 0.011670676991343498\n",
      "Epoch 663, Loss: 0.022936974768526852, Final Batch Loss: 0.0019460386829450727\n",
      "Epoch 664, Loss: 0.01083995564840734, Final Batch Loss: 0.0076319207437336445\n",
      "Epoch 665, Loss: 0.02260583732277155, Final Batch Loss: 0.005479154177010059\n",
      "Epoch 666, Loss: 0.00870080222375691, Final Batch Loss: 0.006306571885943413\n",
      "Epoch 667, Loss: 0.01688657607883215, Final Batch Loss: 0.004622073844075203\n",
      "Epoch 668, Loss: 0.012602005619555712, Final Batch Loss: 0.0057844542898237705\n",
      "Epoch 669, Loss: 0.07311932183802128, Final Batch Loss: 0.025213202461600304\n",
      "Epoch 670, Loss: 0.011528470553457737, Final Batch Loss: 0.004964815452694893\n",
      "Epoch 671, Loss: 0.015257848659530282, Final Batch Loss: 0.001868111314252019\n",
      "Epoch 672, Loss: 0.021481477189809084, Final Batch Loss: 0.006866604555398226\n",
      "Epoch 673, Loss: 0.030199472792446613, Final Batch Loss: 0.014161859638988972\n",
      "Epoch 674, Loss: 0.019384989514946938, Final Batch Loss: 0.01282417867332697\n",
      "Epoch 675, Loss: 0.025076918536797166, Final Batch Loss: 0.003843186656013131\n",
      "Epoch 676, Loss: 0.014289273880422115, Final Batch Loss: 0.009193562902510166\n",
      "Epoch 677, Loss: 0.02673997962847352, Final Batch Loss: 0.00743884826079011\n",
      "Epoch 678, Loss: 0.015094497706741095, Final Batch Loss: 0.005663278046995401\n",
      "Epoch 679, Loss: 0.015864794608205557, Final Batch Loss: 0.0033731921575963497\n",
      "Epoch 680, Loss: 0.01333670737221837, Final Batch Loss: 0.005239024292677641\n",
      "Epoch 681, Loss: 0.01725077722221613, Final Batch Loss: 0.0060100313276052475\n",
      "Epoch 682, Loss: 0.023405302315950394, Final Batch Loss: 0.012001730501651764\n",
      "Epoch 683, Loss: 0.013120913645252585, Final Batch Loss: 0.0028033952694386244\n",
      "Epoch 684, Loss: 0.017823060043156147, Final Batch Loss: 0.004878083243966103\n",
      "Epoch 685, Loss: 0.02596216183155775, Final Batch Loss: 0.01727338694036007\n",
      "Epoch 686, Loss: 0.05005250871181488, Final Batch Loss: 0.009826209396123886\n",
      "Epoch 687, Loss: 0.010320331901311874, Final Batch Loss: 0.008023197762668133\n",
      "Epoch 688, Loss: 0.013911866582930088, Final Batch Loss: 0.008719944395124912\n",
      "Epoch 689, Loss: 0.03160728421062231, Final Batch Loss: 0.022892000153660774\n",
      "Epoch 690, Loss: 0.0351188937202096, Final Batch Loss: 0.013330544345080853\n",
      "Epoch 691, Loss: 0.03863067086786032, Final Batch Loss: 0.01141821127384901\n",
      "Epoch 692, Loss: 0.009065038291737437, Final Batch Loss: 0.0054148295894265175\n",
      "Epoch 693, Loss: 0.02424931456334889, Final Batch Loss: 0.002575331600382924\n",
      "Epoch 694, Loss: 0.008898840518668294, Final Batch Loss: 0.0031051679980009794\n",
      "Epoch 695, Loss: 0.01587789971381426, Final Batch Loss: 0.0064565399661660194\n",
      "Epoch 696, Loss: 0.023451474495232105, Final Batch Loss: 0.0069088684394955635\n",
      "Epoch 697, Loss: 0.03970116749405861, Final Batch Loss: 0.0300478246062994\n",
      "Epoch 698, Loss: 0.01401977357454598, Final Batch Loss: 0.01040079165250063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699, Loss: 0.01297143567353487, Final Batch Loss: 0.004156440496444702\n",
      "Epoch 700, Loss: 0.018874757923185825, Final Batch Loss: 0.01160553377121687\n",
      "Epoch 701, Loss: 0.029286241624504328, Final Batch Loss: 0.02288973145186901\n",
      "Epoch 702, Loss: 0.009278066223487258, Final Batch Loss: 0.0031768723856657743\n",
      "Epoch 703, Loss: 0.025131103582680225, Final Batch Loss: 0.010962562635540962\n",
      "Epoch 704, Loss: 0.006098942831158638, Final Batch Loss: 0.0024105808697640896\n",
      "Epoch 705, Loss: 0.014712362084537745, Final Batch Loss: 0.0076969582587480545\n",
      "Epoch 706, Loss: 0.026618588715791702, Final Batch Loss: 0.005788305774331093\n",
      "Epoch 707, Loss: 0.019588660448789597, Final Batch Loss: 0.004961169324815273\n",
      "Epoch 708, Loss: 0.016636827029287815, Final Batch Loss: 0.006799551658332348\n",
      "Epoch 709, Loss: 0.0330823790282011, Final Batch Loss: 0.005184205248951912\n",
      "Epoch 710, Loss: 0.014975512865930796, Final Batch Loss: 0.0069727119989693165\n",
      "Epoch 711, Loss: 0.010019727982580662, Final Batch Loss: 0.005221270024776459\n",
      "Epoch 712, Loss: 0.007584427483379841, Final Batch Loss: 0.004365450702607632\n",
      "Epoch 713, Loss: 0.015385099686682224, Final Batch Loss: 0.008803929202258587\n",
      "Epoch 714, Loss: 0.011663768440485, Final Batch Loss: 0.00873618759214878\n",
      "Epoch 715, Loss: 0.009395529283210635, Final Batch Loss: 0.003558397525921464\n",
      "Epoch 716, Loss: 0.010088494047522545, Final Batch Loss: 0.004928352311253548\n",
      "Epoch 717, Loss: 0.01989659620448947, Final Batch Loss: 0.005802287254482508\n",
      "Epoch 718, Loss: 0.022977459244430065, Final Batch Loss: 0.011357495561242104\n",
      "Epoch 719, Loss: 0.02107804175466299, Final Batch Loss: 0.017752135172486305\n",
      "Epoch 720, Loss: 0.014712266623973846, Final Batch Loss: 0.002931610681116581\n",
      "Epoch 721, Loss: 0.014491720125079155, Final Batch Loss: 0.011516597121953964\n",
      "Epoch 722, Loss: 0.024719194043427706, Final Batch Loss: 0.020280994474887848\n",
      "Epoch 723, Loss: 0.014553650747984648, Final Batch Loss: 0.010113433003425598\n",
      "Epoch 724, Loss: 0.013659820891916752, Final Batch Loss: 0.005856071133166552\n",
      "Epoch 725, Loss: 0.04101896192878485, Final Batch Loss: 0.033930037170648575\n",
      "Epoch 726, Loss: 0.03629692271351814, Final Batch Loss: 0.018697693943977356\n",
      "Epoch 727, Loss: 0.011972260195761919, Final Batch Loss: 0.00416176300495863\n",
      "Epoch 728, Loss: 0.009863979648798704, Final Batch Loss: 0.004266518633812666\n",
      "Epoch 729, Loss: 0.037945812568068504, Final Batch Loss: 0.02262672781944275\n",
      "Epoch 730, Loss: 0.013160370057448745, Final Batch Loss: 0.002750930143520236\n",
      "Epoch 731, Loss: 0.02786232641665265, Final Batch Loss: 0.0007553148898296058\n",
      "Epoch 732, Loss: 0.04564437735825777, Final Batch Loss: 0.010895912535488605\n",
      "Epoch 733, Loss: 0.02154923789203167, Final Batch Loss: 0.008122313767671585\n",
      "Epoch 734, Loss: 0.02582230605185032, Final Batch Loss: 0.012700879015028477\n",
      "Epoch 735, Loss: 0.014844626188278198, Final Batch Loss: 0.006373029202222824\n",
      "Epoch 736, Loss: 0.011877550277858973, Final Batch Loss: 0.004329499322921038\n",
      "Epoch 737, Loss: 0.010718330508098006, Final Batch Loss: 0.002024981891736388\n",
      "Epoch 738, Loss: 0.014701921725645661, Final Batch Loss: 0.003904074663296342\n",
      "Epoch 739, Loss: 0.0166225447319448, Final Batch Loss: 0.002876770216971636\n",
      "Epoch 740, Loss: 0.019381389021873474, Final Batch Loss: 0.01098928228020668\n",
      "Epoch 741, Loss: 0.014750022499356419, Final Batch Loss: 0.0007261019782163203\n",
      "Epoch 742, Loss: 0.013152839615941048, Final Batch Loss: 0.00213462021201849\n",
      "Epoch 743, Loss: 0.028031103080138564, Final Batch Loss: 0.024812618270516396\n",
      "Epoch 744, Loss: 0.005268589244224131, Final Batch Loss: 0.003936121705919504\n",
      "Epoch 745, Loss: 0.01951046707108617, Final Batch Loss: 0.005915336776524782\n",
      "Epoch 746, Loss: 0.039004582446068525, Final Batch Loss: 0.004345513414591551\n",
      "Epoch 747, Loss: 0.008198036579415202, Final Batch Loss: 0.005581778008490801\n",
      "Epoch 748, Loss: 0.01211418048478663, Final Batch Loss: 0.009817601181566715\n",
      "Epoch 749, Loss: 0.0213719317689538, Final Batch Loss: 0.013552862219512463\n",
      "Epoch 750, Loss: 0.02498913649469614, Final Batch Loss: 0.0025951052084565163\n",
      "Epoch 751, Loss: 0.007758688647300005, Final Batch Loss: 0.003568489570170641\n",
      "Epoch 752, Loss: 0.02119778620544821, Final Batch Loss: 0.019529791548848152\n",
      "Epoch 753, Loss: 0.018123828805983067, Final Batch Loss: 0.010305545292794704\n",
      "Epoch 754, Loss: 0.0145831941626966, Final Batch Loss: 0.007631855085492134\n",
      "Epoch 755, Loss: 0.0066717450972646475, Final Batch Loss: 0.0027340201195329428\n",
      "Epoch 756, Loss: 0.008589022560045123, Final Batch Loss: 0.003292784793302417\n",
      "Epoch 757, Loss: 0.020238645374774933, Final Batch Loss: 0.0040191542357206345\n",
      "Epoch 758, Loss: 0.01817827927879989, Final Batch Loss: 0.003230795031413436\n",
      "Epoch 759, Loss: 0.01434634835459292, Final Batch Loss: 0.002080595353618264\n",
      "Epoch 760, Loss: 0.02596922218799591, Final Batch Loss: 0.01692807301878929\n",
      "Epoch 761, Loss: 0.008257771143689752, Final Batch Loss: 0.0022206988651305437\n",
      "Epoch 762, Loss: 0.0264477024320513, Final Batch Loss: 0.0025967771653085947\n",
      "Epoch 763, Loss: 0.03074490185827017, Final Batch Loss: 0.010087947361171246\n",
      "Epoch 764, Loss: 0.024876534938812256, Final Batch Loss: 0.014505195431411266\n",
      "Epoch 765, Loss: 0.01021698396652937, Final Batch Loss: 0.00411576172336936\n",
      "Epoch 766, Loss: 0.023092858726158738, Final Batch Loss: 0.0020846317056566477\n",
      "Epoch 767, Loss: 0.011813149088993669, Final Batch Loss: 0.0016060362104326487\n",
      "Epoch 768, Loss: 0.010170287219807506, Final Batch Loss: 0.0070878383703529835\n",
      "Epoch 769, Loss: 0.03814280591905117, Final Batch Loss: 0.029438994824886322\n",
      "Epoch 770, Loss: 0.00925787934102118, Final Batch Loss: 0.003862051060423255\n",
      "Epoch 771, Loss: 0.027620310662314296, Final Batch Loss: 0.0016445971559733152\n",
      "Epoch 772, Loss: 0.01684330846183002, Final Batch Loss: 0.003409889293834567\n",
      "Epoch 773, Loss: 0.02526741987094283, Final Batch Loss: 0.02115519903600216\n",
      "Epoch 774, Loss: 0.006870744284242392, Final Batch Loss: 0.0028608497232198715\n",
      "Epoch 775, Loss: 0.02589172963052988, Final Batch Loss: 0.014324747025966644\n",
      "Epoch 776, Loss: 0.007020878838375211, Final Batch Loss: 0.004727024119347334\n",
      "Epoch 777, Loss: 0.02420132141560316, Final Batch Loss: 0.018753796815872192\n",
      "Epoch 778, Loss: 0.010506472550332546, Final Batch Loss: 0.0026632165536284447\n",
      "Epoch 779, Loss: 0.010875098872929811, Final Batch Loss: 0.006147807464003563\n",
      "Epoch 780, Loss: 0.014229694847017527, Final Batch Loss: 0.011693806387484074\n",
      "Epoch 781, Loss: 0.0054829660803079605, Final Batch Loss: 0.002062267391011119\n",
      "Epoch 782, Loss: 0.019040842074900866, Final Batch Loss: 0.01453968696296215\n",
      "Epoch 783, Loss: 0.00806956528685987, Final Batch Loss: 0.0036209977697581053\n",
      "Epoch 784, Loss: 0.010253002401441336, Final Batch Loss: 0.0032244245521724224\n",
      "Epoch 785, Loss: 0.00882603507488966, Final Batch Loss: 0.004139041993767023\n",
      "Epoch 786, Loss: 0.00777410389855504, Final Batch Loss: 0.0022885757498443127\n",
      "Epoch 787, Loss: 0.009270219597965479, Final Batch Loss: 0.004284620750695467\n",
      "Epoch 788, Loss: 0.016577877569943666, Final Batch Loss: 0.004618197213858366\n",
      "Epoch 789, Loss: 0.012652776902541518, Final Batch Loss: 0.0015103619080036879\n",
      "Epoch 790, Loss: 0.021095209755003452, Final Batch Loss: 0.01160335447639227\n",
      "Epoch 791, Loss: 0.006052457261830568, Final Batch Loss: 0.0036530743818730116\n",
      "Epoch 792, Loss: 0.008251033024862409, Final Batch Loss: 0.005839338060468435\n",
      "Epoch 793, Loss: 0.003841408179141581, Final Batch Loss: 0.001971192890778184\n",
      "Epoch 794, Loss: 0.020617418689653277, Final Batch Loss: 0.0022877498995512724\n",
      "Epoch 795, Loss: 0.0143029959872365, Final Batch Loss: 0.002386585809290409\n",
      "Epoch 796, Loss: 0.013340615900233388, Final Batch Loss: 0.010293250903487206\n",
      "Epoch 797, Loss: 0.004496327834203839, Final Batch Loss: 0.003526457119733095\n",
      "Epoch 798, Loss: 0.00837722304277122, Final Batch Loss: 0.004651952534914017\n",
      "Epoch 799, Loss: 0.02690911036916077, Final Batch Loss: 0.023597177118062973\n",
      "Epoch 800, Loss: 0.022451546974480152, Final Batch Loss: 0.01569809764623642\n",
      "Epoch 801, Loss: 0.01566678239032626, Final Batch Loss: 0.010615373961627483\n",
      "Epoch 802, Loss: 0.02353771449998021, Final Batch Loss: 0.01643461175262928\n",
      "Epoch 803, Loss: 0.014667096314951777, Final Batch Loss: 0.0026975662913173437\n",
      "Epoch 804, Loss: 0.03994227387011051, Final Batch Loss: 0.02228470891714096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 805, Loss: 0.028927907813340425, Final Batch Loss: 0.02430112659931183\n",
      "Epoch 806, Loss: 0.0195981883443892, Final Batch Loss: 0.013716831803321838\n",
      "Epoch 807, Loss: 0.00593206740450114, Final Batch Loss: 0.004098033998161554\n",
      "Epoch 808, Loss: 0.051250893622636795, Final Batch Loss: 0.04553115740418434\n",
      "Epoch 809, Loss: 0.01387551287189126, Final Batch Loss: 0.01000995934009552\n",
      "Epoch 810, Loss: 0.009171221405267715, Final Batch Loss: 0.005916120484471321\n",
      "Epoch 811, Loss: 0.01648444728925824, Final Batch Loss: 0.005899528507143259\n",
      "Epoch 812, Loss: 0.010767454979941249, Final Batch Loss: 0.0038290356751531363\n",
      "Epoch 813, Loss: 0.012615319807082415, Final Batch Loss: 0.008345224894583225\n",
      "Epoch 814, Loss: 0.016552505549043417, Final Batch Loss: 0.002972265239804983\n",
      "Epoch 815, Loss: 0.006543013267219067, Final Batch Loss: 0.0025549293495714664\n",
      "Epoch 816, Loss: 0.016558038536459208, Final Batch Loss: 0.0022815284319221973\n",
      "Epoch 817, Loss: 0.006283731781877577, Final Batch Loss: 0.0018098411383107305\n",
      "Epoch 818, Loss: 0.01784871402196586, Final Batch Loss: 0.014837169088423252\n",
      "Epoch 819, Loss: 0.014112954493612051, Final Batch Loss: 0.006207800004631281\n",
      "Epoch 820, Loss: 0.004749613115563989, Final Batch Loss: 0.0013992760796099901\n",
      "Epoch 821, Loss: 0.004995201365090907, Final Batch Loss: 0.0038626024033874273\n",
      "Epoch 822, Loss: 0.008886670228093863, Final Batch Loss: 0.004542395006865263\n",
      "Epoch 823, Loss: 0.025592333637177944, Final Batch Loss: 0.005641798488795757\n",
      "Epoch 824, Loss: 0.007822372717782855, Final Batch Loss: 0.005900496616959572\n",
      "Epoch 825, Loss: 0.017152851913124323, Final Batch Loss: 0.0120017621666193\n",
      "Epoch 826, Loss: 0.022678349167108536, Final Batch Loss: 0.00933005753904581\n",
      "Epoch 827, Loss: 0.005129718920215964, Final Batch Loss: 0.0028109687846153975\n",
      "Epoch 828, Loss: 0.010554252658039331, Final Batch Loss: 0.005881612189114094\n",
      "Epoch 829, Loss: 0.007951126666739583, Final Batch Loss: 0.006718210875988007\n",
      "Epoch 830, Loss: 0.017330529633909464, Final Batch Loss: 0.006599050480872393\n",
      "Epoch 831, Loss: 0.016972403042018414, Final Batch Loss: 0.008705971762537956\n",
      "Epoch 832, Loss: 0.007142331916838884, Final Batch Loss: 0.0034274861682206392\n",
      "Epoch 833, Loss: 0.007351614534854889, Final Batch Loss: 0.0034354152157902718\n",
      "Epoch 834, Loss: 0.014175608288496733, Final Batch Loss: 0.009428366087377071\n",
      "Epoch 835, Loss: 0.010456812335178256, Final Batch Loss: 0.008081194013357162\n",
      "Epoch 836, Loss: 0.030856595374643803, Final Batch Loss: 0.009062922559678555\n",
      "Epoch 837, Loss: 0.01315308385528624, Final Batch Loss: 0.0037775340024381876\n",
      "Epoch 838, Loss: 0.009246081346645951, Final Batch Loss: 0.002618582686409354\n",
      "Epoch 839, Loss: 0.01923077553510666, Final Batch Loss: 0.002226445823907852\n",
      "Epoch 840, Loss: 0.00930357159813866, Final Batch Loss: 0.0005201734020374715\n",
      "Epoch 841, Loss: 0.005026246886700392, Final Batch Loss: 0.001727113500237465\n",
      "Epoch 842, Loss: 0.006570143159478903, Final Batch Loss: 0.0011742026545107365\n",
      "Epoch 843, Loss: 0.015127464663237333, Final Batch Loss: 0.0024440097622573376\n",
      "Epoch 844, Loss: 0.01963412028271705, Final Batch Loss: 0.0010499005438759923\n",
      "Epoch 845, Loss: 0.00395704444963485, Final Batch Loss: 0.001021391130052507\n",
      "Epoch 846, Loss: 0.009903531288728118, Final Batch Loss: 0.0016142658423632383\n",
      "Epoch 847, Loss: 0.03645046055316925, Final Batch Loss: 0.025060178712010384\n",
      "Epoch 848, Loss: 0.009017030708491802, Final Batch Loss: 0.008016088977456093\n",
      "Epoch 849, Loss: 0.026899049058556557, Final Batch Loss: 0.016480732709169388\n",
      "Epoch 850, Loss: 0.006729832384735346, Final Batch Loss: 0.004645852837711573\n",
      "Epoch 851, Loss: 0.025192808359861374, Final Batch Loss: 0.013748007826507092\n",
      "Epoch 852, Loss: 0.014162288105580956, Final Batch Loss: 0.0005198754952289164\n",
      "Epoch 853, Loss: 0.00460597628261894, Final Batch Loss: 0.0028176242485642433\n",
      "Epoch 854, Loss: 0.015599277103319764, Final Batch Loss: 0.0025558576453477144\n",
      "Epoch 855, Loss: 0.025050143711268902, Final Batch Loss: 0.02002720534801483\n",
      "Epoch 856, Loss: 0.011212109588086605, Final Batch Loss: 0.005059862043708563\n",
      "Epoch 857, Loss: 0.022952889557927847, Final Batch Loss: 0.016412874683737755\n",
      "Epoch 858, Loss: 0.009651543223299086, Final Batch Loss: 0.0007590284803882241\n",
      "Epoch 859, Loss: 0.03765675984323025, Final Batch Loss: 0.01795763522386551\n",
      "Epoch 860, Loss: 0.011093745531979948, Final Batch Loss: 0.01039920561015606\n",
      "Epoch 861, Loss: 0.008052831050008535, Final Batch Loss: 0.002035179641097784\n",
      "Epoch 862, Loss: 0.006150841945782304, Final Batch Loss: 0.003805930493399501\n",
      "Epoch 863, Loss: 0.012233815621584654, Final Batch Loss: 0.007320815231651068\n",
      "Epoch 864, Loss: 0.008261614246293902, Final Batch Loss: 0.006899588275700808\n",
      "Epoch 865, Loss: 0.006678889039903879, Final Batch Loss: 0.002159345895051956\n",
      "Epoch 866, Loss: 0.007035462884232402, Final Batch Loss: 0.0023979151155799627\n",
      "Epoch 867, Loss: 0.008285597432404757, Final Batch Loss: 0.004086610395461321\n",
      "Epoch 868, Loss: 0.005079597467556596, Final Batch Loss: 0.0018726261332631111\n",
      "Epoch 869, Loss: 0.0058086460921913385, Final Batch Loss: 0.004117869306355715\n",
      "Epoch 870, Loss: 0.013151083141565323, Final Batch Loss: 0.009117603302001953\n",
      "Epoch 871, Loss: 0.007419257424771786, Final Batch Loss: 0.005063201300799847\n",
      "Epoch 872, Loss: 0.007225303095765412, Final Batch Loss: 0.0017536148661747575\n",
      "Epoch 873, Loss: 0.008757854928262532, Final Batch Loss: 0.00059268728364259\n",
      "Epoch 874, Loss: 0.007242217427119613, Final Batch Loss: 0.0023786278907209635\n",
      "Epoch 875, Loss: 0.006102248560637236, Final Batch Loss: 0.001990047749131918\n",
      "Epoch 876, Loss: 0.0010141443635802716, Final Batch Loss: 0.0005678953602910042\n",
      "Epoch 877, Loss: 0.007013489259406924, Final Batch Loss: 0.004518984351307154\n",
      "Epoch 878, Loss: 0.023724187165498734, Final Batch Loss: 0.017560170963406563\n",
      "Epoch 879, Loss: 0.006519941845908761, Final Batch Loss: 0.004363394342362881\n",
      "Epoch 880, Loss: 0.006993708549998701, Final Batch Loss: 0.001026437501423061\n",
      "Epoch 881, Loss: 0.007412773324176669, Final Batch Loss: 0.004322010558098555\n",
      "Epoch 882, Loss: 0.016140087274834514, Final Batch Loss: 0.002937690122053027\n",
      "Epoch 883, Loss: 0.01413396350108087, Final Batch Loss: 0.011626326479017735\n",
      "Epoch 884, Loss: 0.003411900601349771, Final Batch Loss: 0.0015820879489183426\n",
      "Epoch 885, Loss: 0.009999884758144617, Final Batch Loss: 0.0021536829881370068\n",
      "Epoch 886, Loss: 0.005305001745000482, Final Batch Loss: 0.002534938510507345\n",
      "Epoch 887, Loss: 0.01875258143991232, Final Batch Loss: 0.006829587742686272\n",
      "Epoch 888, Loss: 0.004239807545673102, Final Batch Loss: 0.0032891160808503628\n",
      "Epoch 889, Loss: 0.00310773984529078, Final Batch Loss: 0.0016054777661338449\n",
      "Epoch 890, Loss: 0.01444485504180193, Final Batch Loss: 0.004088513553142548\n",
      "Epoch 891, Loss: 0.004933149553835392, Final Batch Loss: 0.0028747939504683018\n",
      "Epoch 892, Loss: 0.00532555440440774, Final Batch Loss: 0.0016776551492512226\n",
      "Epoch 893, Loss: 0.0047318958677351475, Final Batch Loss: 0.002189862774685025\n",
      "Epoch 894, Loss: 0.005113950464874506, Final Batch Loss: 0.0015022421721369028\n",
      "Epoch 895, Loss: 0.0035745808854699135, Final Batch Loss: 0.002335520228371024\n",
      "Epoch 896, Loss: 0.016137764789164066, Final Batch Loss: 0.002010948024690151\n",
      "Epoch 897, Loss: 0.002998150943312794, Final Batch Loss: 0.0004495776374824345\n",
      "Epoch 898, Loss: 0.012162066996097565, Final Batch Loss: 0.003655245527625084\n",
      "Epoch 899, Loss: 0.007594001712277532, Final Batch Loss: 0.0012512824032455683\n",
      "Epoch 900, Loss: 0.011249959992710501, Final Batch Loss: 0.0008750414126552641\n",
      "Epoch 901, Loss: 0.019259744323790073, Final Batch Loss: 0.009942799806594849\n",
      "Epoch 902, Loss: 0.006356743397191167, Final Batch Loss: 0.002659653779119253\n",
      "Epoch 903, Loss: 0.014322121627628803, Final Batch Loss: 0.008821087889373302\n",
      "Epoch 904, Loss: 0.026399411377497017, Final Batch Loss: 0.024509236216545105\n",
      "Epoch 905, Loss: 0.005681098205968738, Final Batch Loss: 0.002460991498082876\n",
      "Epoch 906, Loss: 0.007342590251937509, Final Batch Loss: 0.004960996098816395\n",
      "Epoch 907, Loss: 0.0031777137191966176, Final Batch Loss: 0.0011164447059854865\n",
      "Epoch 908, Loss: 0.008575514424592257, Final Batch Loss: 0.0017680954188108444\n",
      "Epoch 909, Loss: 0.030973979737609625, Final Batch Loss: 0.02481011673808098\n",
      "Epoch 910, Loss: 0.028223835863173008, Final Batch Loss: 0.006065468303859234\n",
      "Epoch 911, Loss: 0.006410364992916584, Final Batch Loss: 0.0016105351969599724\n",
      "Epoch 912, Loss: 0.02540602267254144, Final Batch Loss: 0.001842246507294476\n",
      "Epoch 913, Loss: 0.01355443848297, Final Batch Loss: 0.011558973230421543\n",
      "Epoch 914, Loss: 0.0013214530190452933, Final Batch Loss: 0.0004699809360317886\n",
      "Epoch 915, Loss: 0.015105907572433352, Final Batch Loss: 0.012062503956258297\n",
      "Epoch 916, Loss: 0.003969521960243583, Final Batch Loss: 0.0026475817430764437\n",
      "Epoch 917, Loss: 0.010582878720015287, Final Batch Loss: 0.004802393261343241\n",
      "Epoch 918, Loss: 0.016151420772075653, Final Batch Loss: 0.006280205212533474\n",
      "Epoch 919, Loss: 0.006127489730715752, Final Batch Loss: 0.001036275178194046\n",
      "Epoch 920, Loss: 0.004239015514031053, Final Batch Loss: 0.00106044951826334\n",
      "Epoch 921, Loss: 0.005552218644879758, Final Batch Loss: 0.001596467918716371\n",
      "Epoch 922, Loss: 0.015196932014077902, Final Batch Loss: 0.012313867919147015\n",
      "Epoch 923, Loss: 0.004994307644665241, Final Batch Loss: 0.0027073652017861605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924, Loss: 0.022902468917891383, Final Batch Loss: 0.020560555160045624\n",
      "Epoch 925, Loss: 0.011810554657131433, Final Batch Loss: 0.009469068609178066\n",
      "Epoch 926, Loss: 0.01362615218386054, Final Batch Loss: 0.010112643241882324\n",
      "Epoch 927, Loss: 0.005076080211438239, Final Batch Loss: 0.001893513253889978\n",
      "Epoch 928, Loss: 0.0033614792628213763, Final Batch Loss: 0.002791329752653837\n",
      "Epoch 929, Loss: 0.006551220314577222, Final Batch Loss: 0.0026526139117777348\n",
      "Epoch 930, Loss: 0.0036442315904423594, Final Batch Loss: 0.001990759512409568\n",
      "Epoch 931, Loss: 0.010554707143455744, Final Batch Loss: 0.003464949782937765\n",
      "Epoch 932, Loss: 0.015943582635372877, Final Batch Loss: 0.011286399327218533\n",
      "Epoch 933, Loss: 0.019245462492108345, Final Batch Loss: 0.010905849747359753\n",
      "Epoch 934, Loss: 0.003830005298368633, Final Batch Loss: 0.0016910444246605039\n",
      "Epoch 935, Loss: 0.00575706793460995, Final Batch Loss: 0.0009500036248937249\n",
      "Epoch 936, Loss: 0.004800741677172482, Final Batch Loss: 0.0029082722030580044\n",
      "Epoch 937, Loss: 0.011073251254856586, Final Batch Loss: 0.004281846806406975\n",
      "Epoch 938, Loss: 0.0138768752804026, Final Batch Loss: 0.0017912940820679069\n",
      "Epoch 939, Loss: 0.011463697999715805, Final Batch Loss: 0.008847677148878574\n",
      "Epoch 940, Loss: 0.021623243112117052, Final Batch Loss: 0.0018583429045975208\n",
      "Epoch 941, Loss: 0.013578342914115638, Final Batch Loss: 0.0006751433829776943\n",
      "Epoch 942, Loss: 0.005063936579972506, Final Batch Loss: 0.0013892697170376778\n",
      "Epoch 943, Loss: 0.020649639423936605, Final Batch Loss: 0.015139139257371426\n",
      "Epoch 944, Loss: 0.004739374155178666, Final Batch Loss: 0.002092513721436262\n",
      "Epoch 945, Loss: 0.007623597281053662, Final Batch Loss: 0.004332304932177067\n",
      "Epoch 946, Loss: 0.015676059294492006, Final Batch Loss: 0.00982650276273489\n",
      "Epoch 947, Loss: 0.0069577512331306934, Final Batch Loss: 0.0035014657769352198\n",
      "Epoch 948, Loss: 0.012557843700051308, Final Batch Loss: 0.005025606136769056\n",
      "Epoch 949, Loss: 0.008055869489908218, Final Batch Loss: 0.002980248536914587\n",
      "Epoch 950, Loss: 0.002523091621696949, Final Batch Loss: 0.001126644085161388\n",
      "Epoch 951, Loss: 0.017915851436555386, Final Batch Loss: 0.01125046331435442\n",
      "Epoch 952, Loss: 0.003568826010450721, Final Batch Loss: 0.002011382719501853\n",
      "Epoch 953, Loss: 0.007532156305387616, Final Batch Loss: 0.006477197166532278\n",
      "Epoch 954, Loss: 0.010953889810480177, Final Batch Loss: 0.009441436268389225\n",
      "Epoch 955, Loss: 0.006308086100034416, Final Batch Loss: 0.0015580224571749568\n",
      "Epoch 956, Loss: 0.021929805167019367, Final Batch Loss: 0.008591585792601109\n",
      "Epoch 957, Loss: 0.012300636270083487, Final Batch Loss: 0.0012044307077303529\n",
      "Epoch 958, Loss: 0.016615011962130666, Final Batch Loss: 0.0022895385045558214\n",
      "Epoch 959, Loss: 0.019147034734487534, Final Batch Loss: 0.001858459785580635\n",
      "Epoch 960, Loss: 0.008760147728025913, Final Batch Loss: 0.004231056664139032\n",
      "Epoch 961, Loss: 0.012852291110903025, Final Batch Loss: 0.003304780926555395\n",
      "Epoch 962, Loss: 0.003541114798281342, Final Batch Loss: 0.0029053008183836937\n",
      "Epoch 963, Loss: 0.0035559237003326416, Final Batch Loss: 0.0012935209088027477\n",
      "Epoch 964, Loss: 0.005347149213775992, Final Batch Loss: 0.003369299927726388\n",
      "Epoch 965, Loss: 0.005037113733123988, Final Batch Loss: 0.0005038177478127182\n",
      "Epoch 966, Loss: 0.006641013082116842, Final Batch Loss: 0.005344957113265991\n",
      "Epoch 967, Loss: 0.007742789341136813, Final Batch Loss: 0.006123979575932026\n",
      "Epoch 968, Loss: 0.014313342049717903, Final Batch Loss: 0.010385174304246902\n",
      "Epoch 969, Loss: 0.005424837814643979, Final Batch Loss: 0.004203219432383776\n",
      "Epoch 970, Loss: 0.02707055941573344, Final Batch Loss: 0.0003566777741070837\n",
      "Epoch 971, Loss: 0.014735945966094732, Final Batch Loss: 0.001335452776402235\n",
      "Epoch 972, Loss: 0.014022153336554766, Final Batch Loss: 0.003377180080860853\n",
      "Epoch 973, Loss: 0.015572255942970514, Final Batch Loss: 0.005178757477551699\n",
      "Epoch 974, Loss: 0.026173704187385738, Final Batch Loss: 0.001282949815504253\n",
      "Epoch 975, Loss: 0.003632914391346276, Final Batch Loss: 0.0025396356359124184\n",
      "Epoch 976, Loss: 0.013672884437255561, Final Batch Loss: 0.0014016673667356372\n",
      "Epoch 977, Loss: 0.012907774187624454, Final Batch Loss: 0.0032685361802577972\n",
      "Epoch 978, Loss: 0.014763811050215736, Final Batch Loss: 0.0004527684359345585\n",
      "Epoch 979, Loss: 0.012991124764084816, Final Batch Loss: 0.007682166062295437\n",
      "Epoch 980, Loss: 0.007242292398586869, Final Batch Loss: 0.004027922637760639\n",
      "Epoch 981, Loss: 0.0068511031568050385, Final Batch Loss: 0.003059572307392955\n",
      "Epoch 982, Loss: 0.008318808395415545, Final Batch Loss: 0.005986161530017853\n",
      "Epoch 983, Loss: 0.01190261309966445, Final Batch Loss: 0.0024918015114963055\n",
      "Epoch 984, Loss: 0.018702914705500007, Final Batch Loss: 0.0029433739837259054\n",
      "Epoch 985, Loss: 0.006359337130561471, Final Batch Loss: 0.005707073491066694\n",
      "Epoch 986, Loss: 0.004879146872553974, Final Batch Loss: 0.0005880348035134375\n",
      "Epoch 987, Loss: 0.00448667851742357, Final Batch Loss: 0.0014803222147747874\n",
      "Epoch 988, Loss: 0.0025410937378183007, Final Batch Loss: 0.00041252037044614553\n",
      "Epoch 989, Loss: 0.003595126559957862, Final Batch Loss: 0.0018034789245575666\n",
      "Epoch 990, Loss: 0.006088907830417156, Final Batch Loss: 0.004238350782543421\n",
      "Epoch 991, Loss: 0.0024326078419107944, Final Batch Loss: 0.0020072085317224264\n",
      "Epoch 992, Loss: 0.002013955934671685, Final Batch Loss: 0.00039597004069946706\n",
      "Epoch 993, Loss: 0.016351307625882328, Final Batch Loss: 0.015523322857916355\n",
      "Epoch 994, Loss: 0.011476907879114151, Final Batch Loss: 0.0051834131591022015\n",
      "Epoch 995, Loss: 0.005400685127824545, Final Batch Loss: 0.003439123509451747\n",
      "Epoch 996, Loss: 0.0049965037032961845, Final Batch Loss: 0.003476798767223954\n",
      "Epoch 997, Loss: 0.007890881737694144, Final Batch Loss: 0.005426274612545967\n",
      "Epoch 998, Loss: 0.02316003292798996, Final Batch Loss: 0.01236423198133707\n",
      "Epoch 999, Loss: 0.02159312181174755, Final Batch Loss: 0.009312713518738747\n",
      "Epoch 1000, Loss: 0.006001871544867754, Final Batch Loss: 0.00376507337205112\n",
      "Epoch 1001, Loss: 0.0056032417342066765, Final Batch Loss: 0.0025383764877915382\n",
      "Epoch 1002, Loss: 0.01609175931662321, Final Batch Loss: 0.013677573762834072\n",
      "Epoch 1003, Loss: 0.0047380749601870775, Final Batch Loss: 0.0024148686788976192\n",
      "Epoch 1004, Loss: 0.00741992675466463, Final Batch Loss: 0.0006046180496923625\n",
      "Epoch 1005, Loss: 0.006688765715807676, Final Batch Loss: 0.0008114064112305641\n",
      "Epoch 1006, Loss: 0.01238260604441166, Final Batch Loss: 0.009060421958565712\n",
      "Epoch 1007, Loss: 0.015381788369268179, Final Batch Loss: 0.008264811709523201\n",
      "Epoch 1008, Loss: 0.016894792206585407, Final Batch Loss: 0.014065706171095371\n",
      "Epoch 1009, Loss: 0.0022494992590509355, Final Batch Loss: 0.0007814139244146645\n",
      "Epoch 1010, Loss: 0.006021592358592898, Final Batch Loss: 0.0009558313176967204\n",
      "Epoch 1011, Loss: 0.004451195476576686, Final Batch Loss: 0.001000657444819808\n",
      "Epoch 1012, Loss: 0.023409722838550806, Final Batch Loss: 0.016738492995500565\n",
      "Epoch 1013, Loss: 0.02006451738998294, Final Batch Loss: 0.0008828244172036648\n",
      "Epoch 1014, Loss: 0.0019318675913382322, Final Batch Loss: 0.00031140391365624964\n",
      "Epoch 1015, Loss: 0.002520102309063077, Final Batch Loss: 0.0021748486906290054\n",
      "Epoch 1016, Loss: 0.009837416699156165, Final Batch Loss: 0.00692796753719449\n",
      "Epoch 1017, Loss: 0.016937050502747297, Final Batch Loss: 0.0035214112140238285\n",
      "Epoch 1018, Loss: 0.004591453820466995, Final Batch Loss: 0.0028585928957909346\n",
      "Epoch 1019, Loss: 0.013379140524193645, Final Batch Loss: 0.011969937942922115\n",
      "Epoch 1020, Loss: 0.025974641554057598, Final Batch Loss: 0.01717442087829113\n",
      "Epoch 1021, Loss: 0.007913413923233747, Final Batch Loss: 0.004047886934131384\n",
      "Epoch 1022, Loss: 0.04165815142914653, Final Batch Loss: 0.001372139435261488\n",
      "Epoch 1023, Loss: 0.002240551315480843, Final Batch Loss: 0.00030993824475444853\n",
      "Epoch 1024, Loss: 0.003206502995453775, Final Batch Loss: 0.0012884485768154263\n",
      "Epoch 1025, Loss: 0.004189283354207873, Final Batch Loss: 0.002204030752182007\n",
      "Epoch 1026, Loss: 0.023904945701360703, Final Batch Loss: 0.012563040480017662\n",
      "Epoch 1027, Loss: 0.004315955040510744, Final Batch Loss: 0.0035413808654993773\n",
      "Epoch 1028, Loss: 0.01818730472587049, Final Batch Loss: 0.0008409579750150442\n",
      "Epoch 1029, Loss: 0.024873233400285244, Final Batch Loss: 0.015397888608276844\n",
      "Epoch 1030, Loss: 0.0062844594940543175, Final Batch Loss: 0.002825639909133315\n",
      "Epoch 1031, Loss: 0.011105928104370832, Final Batch Loss: 0.0022802636958658695\n",
      "Epoch 1032, Loss: 0.016924827359616756, Final Batch Loss: 0.010031592100858688\n",
      "Epoch 1033, Loss: 0.03482150100171566, Final Batch Loss: 0.030957382172346115\n",
      "Epoch 1034, Loss: 0.012583038304001093, Final Batch Loss: 0.010528302751481533\n",
      "Epoch 1035, Loss: 0.00766234565526247, Final Batch Loss: 0.0026076845824718475\n",
      "Epoch 1036, Loss: 0.010653859470039606, Final Batch Loss: 0.004134542774409056\n",
      "Epoch 1037, Loss: 0.010820759925991297, Final Batch Loss: 0.008263625204563141\n",
      "Epoch 1038, Loss: 0.003113995771855116, Final Batch Loss: 0.000734047731384635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1039, Loss: 0.02577651897445321, Final Batch Loss: 0.0214968491345644\n",
      "Epoch 1040, Loss: 0.007605016347952187, Final Batch Loss: 0.0013688156614080071\n",
      "Epoch 1041, Loss: 0.010218510869890451, Final Batch Loss: 0.005907755810767412\n",
      "Epoch 1042, Loss: 0.019728905404917896, Final Batch Loss: 0.01798976957798004\n",
      "Epoch 1043, Loss: 0.0047818931634537876, Final Batch Loss: 0.0006394835072569549\n",
      "Epoch 1044, Loss: 0.005793531658127904, Final Batch Loss: 0.004091852810233831\n",
      "Epoch 1045, Loss: 0.006108767352998257, Final Batch Loss: 0.002585526555776596\n",
      "Epoch 1046, Loss: 0.00997112412005663, Final Batch Loss: 0.0038006710819900036\n",
      "Epoch 1047, Loss: 0.01918500754982233, Final Batch Loss: 0.0046468330547213554\n",
      "Epoch 1048, Loss: 0.002165721612982452, Final Batch Loss: 0.001156435115262866\n",
      "Epoch 1049, Loss: 0.002321074833162129, Final Batch Loss: 0.0016055837040767074\n",
      "Epoch 1050, Loss: 0.008120690239593387, Final Batch Loss: 0.00375724327750504\n",
      "Epoch 1051, Loss: 0.021781086921691895, Final Batch Loss: 0.00604747049510479\n",
      "Epoch 1052, Loss: 0.007339797215536237, Final Batch Loss: 0.002317986683920026\n",
      "Epoch 1053, Loss: 0.011919848155230284, Final Batch Loss: 0.005873511079698801\n",
      "Epoch 1054, Loss: 0.006531089427880943, Final Batch Loss: 0.005040536168962717\n",
      "Epoch 1055, Loss: 0.003287752973847091, Final Batch Loss: 0.0015498349675908685\n",
      "Epoch 1056, Loss: 0.0074574213940650225, Final Batch Loss: 0.005450901109725237\n",
      "Epoch 1057, Loss: 0.012981133768334985, Final Batch Loss: 0.009744369424879551\n",
      "Epoch 1058, Loss: 0.003462077467702329, Final Batch Loss: 0.0011291207047179341\n",
      "Epoch 1059, Loss: 0.007445670198649168, Final Batch Loss: 0.004228602163493633\n",
      "Epoch 1060, Loss: 0.0252426021033898, Final Batch Loss: 0.0011004764819517732\n",
      "Epoch 1061, Loss: 0.007493552519008517, Final Batch Loss: 0.0014375427272170782\n",
      "Epoch 1062, Loss: 0.01295463228598237, Final Batch Loss: 0.0058427052572369576\n",
      "Epoch 1063, Loss: 0.01362244039773941, Final Batch Loss: 0.01226811669766903\n",
      "Epoch 1064, Loss: 0.018682973459362984, Final Batch Loss: 0.01077443640679121\n",
      "Epoch 1065, Loss: 0.005461147986352444, Final Batch Loss: 0.0020279299933463335\n",
      "Epoch 1066, Loss: 0.0035058120265603065, Final Batch Loss: 0.002353413961827755\n",
      "Epoch 1067, Loss: 0.04469522670842707, Final Batch Loss: 0.0012315197382122278\n",
      "Epoch 1068, Loss: 0.006576793035492301, Final Batch Loss: 0.0027719640638679266\n",
      "Epoch 1069, Loss: 0.004434070084244013, Final Batch Loss: 0.0020854747854173183\n",
      "Epoch 1070, Loss: 0.018800377612933517, Final Batch Loss: 0.0029356719460338354\n",
      "Epoch 1071, Loss: 0.0170510346069932, Final Batch Loss: 0.007154830731451511\n",
      "Epoch 1072, Loss: 0.0052186730317771435, Final Batch Loss: 0.0006581516936421394\n",
      "Epoch 1073, Loss: 0.005196621874347329, Final Batch Loss: 0.0014924644492566586\n",
      "Epoch 1074, Loss: 0.005131123005412519, Final Batch Loss: 0.001356802531518042\n",
      "Epoch 1075, Loss: 0.005334783112630248, Final Batch Loss: 0.002402323065325618\n",
      "Epoch 1076, Loss: 0.005581488134339452, Final Batch Loss: 0.004218866117298603\n",
      "Epoch 1077, Loss: 0.0061931617092341185, Final Batch Loss: 0.003725705435499549\n",
      "Epoch 1078, Loss: 0.03973407098965254, Final Batch Loss: 0.03951774165034294\n",
      "Epoch 1079, Loss: 0.007187436043750495, Final Batch Loss: 0.0005003951373510063\n",
      "Epoch 1080, Loss: 0.01249108780757524, Final Batch Loss: 0.0003990730328951031\n",
      "Epoch 1081, Loss: 0.008574638050049543, Final Batch Loss: 0.005028948653489351\n",
      "Epoch 1082, Loss: 0.005298342905007303, Final Batch Loss: 0.0036958216223865747\n",
      "Epoch 1083, Loss: 0.012231967644765973, Final Batch Loss: 0.009965112432837486\n",
      "Epoch 1084, Loss: 0.002763938857242465, Final Batch Loss: 0.0018896631663665175\n",
      "Epoch 1085, Loss: 0.0031495672883465886, Final Batch Loss: 0.0012922142632305622\n",
      "Epoch 1086, Loss: 0.0050153546035289764, Final Batch Loss: 0.0014223377220332623\n",
      "Epoch 1087, Loss: 0.0031265114957932383, Final Batch Loss: 0.0027797732036560774\n",
      "Epoch 1088, Loss: 0.011755191255360842, Final Batch Loss: 0.01136698666960001\n",
      "Epoch 1089, Loss: 0.00468890811316669, Final Batch Loss: 0.002799268113449216\n",
      "Epoch 1090, Loss: 0.003971985541284084, Final Batch Loss: 0.001330722589045763\n",
      "Epoch 1091, Loss: 0.009117898531258106, Final Batch Loss: 0.00467069074511528\n",
      "Epoch 1092, Loss: 0.012289406731724739, Final Batch Loss: 0.0019253939390182495\n",
      "Epoch 1093, Loss: 0.0032373841386288404, Final Batch Loss: 0.0015891914954409003\n",
      "Epoch 1094, Loss: 0.010117880534380674, Final Batch Loss: 0.007719343528151512\n",
      "Epoch 1095, Loss: 0.006052164128050208, Final Batch Loss: 0.0022921599447727203\n",
      "Epoch 1096, Loss: 0.008290477911941707, Final Batch Loss: 0.0006181936478242278\n",
      "Epoch 1097, Loss: 0.005099426256492734, Final Batch Loss: 0.0033289596904069185\n",
      "Epoch 1098, Loss: 0.0036056096432730556, Final Batch Loss: 0.0027152816765010357\n",
      "Epoch 1099, Loss: 0.005405300995334983, Final Batch Loss: 0.0024075822439044714\n",
      "Epoch 1100, Loss: 0.005670279148034751, Final Batch Loss: 0.005122687201946974\n",
      "Epoch 1101, Loss: 0.0011723261850420386, Final Batch Loss: 0.0004235815431457013\n",
      "Epoch 1102, Loss: 0.005370707716792822, Final Batch Loss: 0.003165661357343197\n",
      "Epoch 1103, Loss: 0.021444896468892694, Final Batch Loss: 0.0022418333683162928\n",
      "Epoch 1104, Loss: 0.007943407515995204, Final Batch Loss: 0.0011764116352424026\n",
      "Epoch 1105, Loss: 0.0032104236306622624, Final Batch Loss: 0.0010682420106604695\n",
      "Epoch 1106, Loss: 0.005386250908486545, Final Batch Loss: 0.003816316369920969\n",
      "Epoch 1107, Loss: 0.015163915086304769, Final Batch Loss: 0.014696246944367886\n",
      "Epoch 1108, Loss: 0.03167891671182588, Final Batch Loss: 0.030912909656763077\n",
      "Epoch 1109, Loss: 0.02387773571535945, Final Batch Loss: 0.019398825243115425\n",
      "Epoch 1110, Loss: 0.007273547118529677, Final Batch Loss: 0.0033627848606556654\n",
      "Epoch 1111, Loss: 0.00951611460186541, Final Batch Loss: 0.008566435426473618\n",
      "Epoch 1112, Loss: 0.00533273332985118, Final Batch Loss: 0.0007071581785567105\n",
      "Epoch 1113, Loss: 0.005569898872636259, Final Batch Loss: 0.0006116455188021064\n",
      "Epoch 1114, Loss: 0.022844730177894235, Final Batch Loss: 0.019858837127685547\n",
      "Epoch 1115, Loss: 0.0016916796448640525, Final Batch Loss: 0.000555865524802357\n",
      "Epoch 1116, Loss: 0.0017860105726867914, Final Batch Loss: 0.00041379814501851797\n",
      "Epoch 1117, Loss: 0.016782879130914807, Final Batch Loss: 0.003021740587428212\n",
      "Epoch 1118, Loss: 0.0037174209719523787, Final Batch Loss: 0.0025258345995098352\n",
      "Epoch 1119, Loss: 0.002074729069136083, Final Batch Loss: 0.0007169896271079779\n",
      "Epoch 1120, Loss: 0.03218597173690796, Final Batch Loss: 0.022990604862570763\n",
      "Epoch 1121, Loss: 0.012459778692573309, Final Batch Loss: 0.006856812164187431\n",
      "Epoch 1122, Loss: 0.02604619594058022, Final Batch Loss: 0.0005471985205076635\n",
      "Epoch 1123, Loss: 0.029533641412854195, Final Batch Loss: 0.011293036863207817\n",
      "Epoch 1124, Loss: 0.002671685768291354, Final Batch Loss: 0.0013976607006043196\n",
      "Epoch 1125, Loss: 0.0038636383833363652, Final Batch Loss: 0.0024296510964632034\n",
      "Epoch 1126, Loss: 0.005243418971076608, Final Batch Loss: 0.0019120622891932726\n",
      "Epoch 1127, Loss: 0.002027841517701745, Final Batch Loss: 0.0008047322044149041\n",
      "Epoch 1128, Loss: 0.0034767085453495383, Final Batch Loss: 0.0022233701311051846\n",
      "Epoch 1129, Loss: 0.013381788972765207, Final Batch Loss: 0.009158218279480934\n",
      "Epoch 1130, Loss: 0.01629731513094157, Final Batch Loss: 0.014924121089279652\n",
      "Epoch 1131, Loss: 0.00402400572784245, Final Batch Loss: 0.0027208582032471895\n",
      "Epoch 1132, Loss: 0.0026026946143247187, Final Batch Loss: 0.0020528773311525583\n",
      "Epoch 1133, Loss: 0.018477434758096933, Final Batch Loss: 0.0033912700600922108\n",
      "Epoch 1134, Loss: 0.0043431690428406, Final Batch Loss: 0.0030690489802509546\n",
      "Epoch 1135, Loss: 0.015960287302732468, Final Batch Loss: 0.007831777445971966\n",
      "Epoch 1136, Loss: 0.003902746713720262, Final Batch Loss: 0.0006359320832416415\n",
      "Epoch 1137, Loss: 0.003907353966496885, Final Batch Loss: 0.0011212880490347743\n",
      "Epoch 1138, Loss: 0.01183578820200637, Final Batch Loss: 0.0004918079939670861\n",
      "Epoch 1139, Loss: 0.009653448360040784, Final Batch Loss: 0.006670484784990549\n",
      "Epoch 1140, Loss: 0.019192564010154456, Final Batch Loss: 0.0009340184624306858\n",
      "Epoch 1141, Loss: 0.0031767835607752204, Final Batch Loss: 0.0011031090980395675\n",
      "Epoch 1142, Loss: 0.010492060333490372, Final Batch Loss: 0.007450771983712912\n",
      "Epoch 1143, Loss: 0.00885577080771327, Final Batch Loss: 0.004458579700440168\n",
      "Epoch 1144, Loss: 0.004024957655929029, Final Batch Loss: 0.0028468365781009197\n",
      "Epoch 1145, Loss: 0.0011060934630222619, Final Batch Loss: 0.0007156913634389639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1146, Loss: 0.008940858591813594, Final Batch Loss: 0.0005599770811386406\n",
      "Epoch 1147, Loss: 0.003607312508393079, Final Batch Loss: 0.003024523612111807\n",
      "Epoch 1148, Loss: 0.0023487022845074534, Final Batch Loss: 0.0007788782240822911\n",
      "Epoch 1149, Loss: 0.004577053245157003, Final Batch Loss: 0.0022840462625026703\n",
      "Epoch 1150, Loss: 0.00855625537224114, Final Batch Loss: 0.002739983843639493\n",
      "Epoch 1151, Loss: 0.0031683598645031452, Final Batch Loss: 0.0011383604723960161\n",
      "Epoch 1152, Loss: 0.008243659045547247, Final Batch Loss: 0.0021308446303009987\n",
      "Epoch 1153, Loss: 0.009693771367892623, Final Batch Loss: 0.001304123317822814\n",
      "Epoch 1154, Loss: 0.007528513320721686, Final Batch Loss: 0.0007640655385330319\n",
      "Epoch 1155, Loss: 0.002502748859114945, Final Batch Loss: 0.0016299487324431539\n",
      "Epoch 1156, Loss: 0.003130277618765831, Final Batch Loss: 0.0011634957045316696\n",
      "Epoch 1157, Loss: 0.0037755415542051196, Final Batch Loss: 0.0018233007285743952\n",
      "Epoch 1158, Loss: 0.001610627572517842, Final Batch Loss: 0.0007588107837364078\n",
      "Epoch 1159, Loss: 0.002105866326019168, Final Batch Loss: 0.0009628479601815343\n",
      "Epoch 1160, Loss: 0.010371600044891238, Final Batch Loss: 0.0019814379047602415\n",
      "Epoch 1161, Loss: 0.006797241047024727, Final Batch Loss: 0.004291093442589045\n",
      "Epoch 1162, Loss: 0.0032778317690826952, Final Batch Loss: 0.000737622904125601\n",
      "Epoch 1163, Loss: 0.006718007614836097, Final Batch Loss: 0.0043503837659955025\n",
      "Epoch 1164, Loss: 0.005215350160142407, Final Batch Loss: 0.00043627116247080266\n",
      "Epoch 1165, Loss: 0.002192610700149089, Final Batch Loss: 0.0007883996586315334\n",
      "Epoch 1166, Loss: 0.002792900428175926, Final Batch Loss: 0.0005293020512908697\n",
      "Epoch 1167, Loss: 0.002735523390583694, Final Batch Loss: 0.0017791856080293655\n",
      "Epoch 1168, Loss: 0.0030341576784849167, Final Batch Loss: 0.0015799583634361625\n",
      "Epoch 1169, Loss: 0.010423176863696426, Final Batch Loss: 0.000554267258848995\n",
      "Epoch 1170, Loss: 0.015973949804902077, Final Batch Loss: 0.011013475246727467\n",
      "Epoch 1171, Loss: 0.0021662709186784923, Final Batch Loss: 0.0015336282085627317\n",
      "Epoch 1172, Loss: 0.007901256860350259, Final Batch Loss: 0.0002416064526187256\n",
      "Epoch 1173, Loss: 0.004646563553251326, Final Batch Loss: 0.003215055912733078\n",
      "Epoch 1174, Loss: 0.020725095375382807, Final Batch Loss: 7.75826265453361e-05\n",
      "Epoch 1175, Loss: 0.00927884696284309, Final Batch Loss: 0.0005124323652125895\n",
      "Epoch 1176, Loss: 0.0034110292326658964, Final Batch Loss: 0.0015247903065755963\n",
      "Epoch 1177, Loss: 0.002082905877614394, Final Batch Loss: 0.00043870790977962315\n",
      "Epoch 1178, Loss: 0.002920542028732598, Final Batch Loss: 0.0008471155306324363\n",
      "Epoch 1179, Loss: 0.0010694396041799337, Final Batch Loss: 0.00034151526051573455\n",
      "Epoch 1180, Loss: 0.002188395184930414, Final Batch Loss: 0.0012899133143946528\n",
      "Epoch 1181, Loss: 0.005316818249411881, Final Batch Loss: 0.0013794639380648732\n",
      "Epoch 1182, Loss: 0.01072633103467524, Final Batch Loss: 0.003831550246104598\n",
      "Epoch 1183, Loss: 0.0036538925487548113, Final Batch Loss: 0.0016253660432994366\n",
      "Epoch 1184, Loss: 0.007915205555036664, Final Batch Loss: 0.006359754130244255\n",
      "Epoch 1185, Loss: 0.0029796769376844168, Final Batch Loss: 0.0014380165375769138\n",
      "Epoch 1186, Loss: 0.01343516947235912, Final Batch Loss: 0.011805606074631214\n",
      "Epoch 1187, Loss: 0.0038317018188536167, Final Batch Loss: 0.0016720613930374384\n",
      "Epoch 1188, Loss: 0.009803716850001365, Final Batch Loss: 0.008997425436973572\n",
      "Epoch 1189, Loss: 0.008280308451503515, Final Batch Loss: 0.0038799927569925785\n",
      "Epoch 1190, Loss: 0.003210608381778002, Final Batch Loss: 0.0005807497072964907\n",
      "Epoch 1191, Loss: 0.019941735081374645, Final Batch Loss: 0.01872383989393711\n",
      "Epoch 1192, Loss: 0.004127710533794016, Final Batch Loss: 0.0006347051239572465\n",
      "Epoch 1193, Loss: 0.004158849478699267, Final Batch Loss: 0.0010052601573988795\n",
      "Epoch 1194, Loss: 0.0015705083787906915, Final Batch Loss: 0.0011151949875056744\n",
      "Epoch 1195, Loss: 0.012866270844824612, Final Batch Loss: 0.011655247770249844\n",
      "Epoch 1196, Loss: 0.005496078287251294, Final Batch Loss: 0.0016903214855119586\n",
      "Epoch 1197, Loss: 0.0010036502790171653, Final Batch Loss: 0.0006876756087876856\n",
      "Epoch 1198, Loss: 0.008996371645480394, Final Batch Loss: 0.006915668956935406\n",
      "Epoch 1199, Loss: 0.0021771492902189493, Final Batch Loss: 0.0010591688333079219\n",
      "Epoch 1200, Loss: 0.0017196940607391298, Final Batch Loss: 0.0009927647188305855\n",
      "Epoch 1201, Loss: 0.0038287425122689456, Final Batch Loss: 0.003346528857946396\n",
      "Epoch 1202, Loss: 0.0042425911233294755, Final Batch Loss: 0.003845125436782837\n",
      "Epoch 1203, Loss: 0.0033500909339636564, Final Batch Loss: 0.0015392197528854012\n",
      "Epoch 1204, Loss: 0.001992099219933152, Final Batch Loss: 0.0005271298578009009\n",
      "Epoch 1205, Loss: 0.0025308694457635283, Final Batch Loss: 0.0013364130863919854\n",
      "Epoch 1206, Loss: 0.002942516701295972, Final Batch Loss: 0.0011887145228683949\n",
      "Epoch 1207, Loss: 0.004381304373964667, Final Batch Loss: 0.0023900538217276335\n",
      "Epoch 1208, Loss: 0.008803550037555397, Final Batch Loss: 0.0009343576384708285\n",
      "Epoch 1209, Loss: 0.011964314267970622, Final Batch Loss: 0.010659469291567802\n",
      "Epoch 1210, Loss: 0.005016845127101988, Final Batch Loss: 0.004513690713793039\n",
      "Epoch 1211, Loss: 0.0016721816500648856, Final Batch Loss: 0.0011829405557364225\n",
      "Epoch 1212, Loss: 0.002554322825744748, Final Batch Loss: 0.001384664443321526\n",
      "Epoch 1213, Loss: 0.002750648942310363, Final Batch Loss: 0.0018219351768493652\n",
      "Epoch 1214, Loss: 0.01848785486072302, Final Batch Loss: 0.011927278712391853\n",
      "Epoch 1215, Loss: 0.004340785904787481, Final Batch Loss: 0.002970403991639614\n",
      "Epoch 1216, Loss: 0.005946518795099109, Final Batch Loss: 0.0007702563307248056\n",
      "Epoch 1217, Loss: 0.0010216684313490987, Final Batch Loss: 0.00033785728737711906\n",
      "Epoch 1218, Loss: 0.011182087939232588, Final Batch Loss: 0.005783642176538706\n",
      "Epoch 1219, Loss: 0.00583229772746563, Final Batch Loss: 0.002761935582384467\n",
      "Epoch 1220, Loss: 0.0026835245080292225, Final Batch Loss: 0.001992962323129177\n",
      "Epoch 1221, Loss: 0.0030279495113063604, Final Batch Loss: 0.0003929692611563951\n",
      "Epoch 1222, Loss: 0.002265872433781624, Final Batch Loss: 0.0012445617467164993\n",
      "Epoch 1223, Loss: 0.0038090329617261887, Final Batch Loss: 0.0018801926635205746\n",
      "Epoch 1224, Loss: 0.0019061562488786876, Final Batch Loss: 0.0007227212772704661\n",
      "Epoch 1225, Loss: 0.0016809242079034448, Final Batch Loss: 0.0007620907854288816\n",
      "Epoch 1226, Loss: 0.01242334209382534, Final Batch Loss: 0.011569520458579063\n",
      "Epoch 1227, Loss: 0.020627273246645927, Final Batch Loss: 0.01119416207075119\n",
      "Epoch 1228, Loss: 0.003927218378521502, Final Batch Loss: 0.0031606429256498814\n",
      "Epoch 1229, Loss: 0.008294401573948562, Final Batch Loss: 0.0016944858944043517\n",
      "Epoch 1230, Loss: 0.003776194411329925, Final Batch Loss: 0.0020294636487960815\n",
      "Epoch 1231, Loss: 0.008895004983060062, Final Batch Loss: 0.0069900453090667725\n",
      "Epoch 1232, Loss: 0.002402410958893597, Final Batch Loss: 0.0012510744854807854\n",
      "Epoch 1233, Loss: 0.013568311580456793, Final Batch Loss: 0.012016617693006992\n",
      "Epoch 1234, Loss: 0.001385564035444986, Final Batch Loss: 0.00011459079541964456\n",
      "Epoch 1235, Loss: 0.022554961033165455, Final Batch Loss: 0.013537606224417686\n",
      "Epoch 1236, Loss: 0.0019001559121534228, Final Batch Loss: 0.0005331611027941108\n",
      "Epoch 1237, Loss: 0.0029837171314284205, Final Batch Loss: 0.0017238777363672853\n",
      "Epoch 1238, Loss: 0.014278501039370894, Final Batch Loss: 0.002922753570601344\n",
      "Epoch 1239, Loss: 0.003652096726000309, Final Batch Loss: 0.001905563985928893\n",
      "Epoch 1240, Loss: 0.005633666733046994, Final Batch Loss: 0.005457814317196608\n",
      "Epoch 1241, Loss: 0.003046832396648824, Final Batch Loss: 0.0017552673816680908\n",
      "Epoch 1242, Loss: 0.004194437409751117, Final Batch Loss: 0.0017490164609625936\n",
      "Epoch 1243, Loss: 0.0024418170214630663, Final Batch Loss: 0.00032477109925821424\n",
      "Epoch 1244, Loss: 0.013069335254840553, Final Batch Loss: 0.0012566427467390895\n",
      "Epoch 1245, Loss: 0.024638168513774872, Final Batch Loss: 0.0035882629454135895\n",
      "Epoch 1246, Loss: 0.014564621727913618, Final Batch Loss: 0.004396362695842981\n",
      "Epoch 1247, Loss: 0.02270625438541174, Final Batch Loss: 0.016419000923633575\n",
      "Epoch 1248, Loss: 0.00903886035666801, Final Batch Loss: 0.008597703650593758\n",
      "Epoch 1249, Loss: 0.010531893814913929, Final Batch Loss: 0.00013719114940613508\n",
      "Epoch 1250, Loss: 0.008218258386477828, Final Batch Loss: 0.00030342279933393\n",
      "Epoch 1251, Loss: 0.012417904799804091, Final Batch Loss: 0.008696679025888443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1252, Loss: 0.008308013319037855, Final Batch Loss: 0.007190111093223095\n",
      "Epoch 1253, Loss: 0.02512717363424599, Final Batch Loss: 0.023120053112506866\n",
      "Epoch 1254, Loss: 0.004169642110355198, Final Batch Loss: 0.0018105796771124005\n",
      "Epoch 1255, Loss: 0.006816557957790792, Final Batch Loss: 0.0010071758879348636\n",
      "Epoch 1256, Loss: 0.028045265935361385, Final Batch Loss: 0.015390375629067421\n",
      "Epoch 1257, Loss: 0.04281793045811355, Final Batch Loss: 0.0406501367688179\n",
      "Epoch 1258, Loss: 0.006168098654597998, Final Batch Loss: 0.0031806067563593388\n",
      "Epoch 1259, Loss: 0.0014717311423737556, Final Batch Loss: 0.0002334920282009989\n",
      "Epoch 1260, Loss: 0.002902489621192217, Final Batch Loss: 0.0016993756871670485\n",
      "Epoch 1261, Loss: 0.02545096876565367, Final Batch Loss: 0.023996131494641304\n",
      "Epoch 1262, Loss: 0.025229948107153177, Final Batch Loss: 0.0189451165497303\n",
      "Epoch 1263, Loss: 0.003135496284812689, Final Batch Loss: 0.0014464951818808913\n",
      "Epoch 1264, Loss: 0.022504912689328194, Final Batch Loss: 0.021510111168026924\n",
      "Epoch 1265, Loss: 0.010456122341565788, Final Batch Loss: 0.0017895548371598125\n",
      "Epoch 1266, Loss: 0.009523964719846845, Final Batch Loss: 0.003752931719645858\n",
      "Epoch 1267, Loss: 0.0016416055004810914, Final Batch Loss: 0.00022374953550752252\n",
      "Epoch 1268, Loss: 0.010604712646454573, Final Batch Loss: 0.006676507648080587\n",
      "Epoch 1269, Loss: 0.07058682409115136, Final Batch Loss: 0.0026242819149047136\n",
      "Epoch 1270, Loss: 0.004177102004177868, Final Batch Loss: 0.0008015354396775365\n",
      "Epoch 1271, Loss: 0.010020365240052342, Final Batch Loss: 0.0011058954987674952\n",
      "Epoch 1272, Loss: 0.002772535022813827, Final Batch Loss: 0.0003436322440393269\n",
      "Epoch 1273, Loss: 0.004728862666524947, Final Batch Loss: 0.00038556952495127916\n",
      "Epoch 1274, Loss: 0.004289360251277685, Final Batch Loss: 0.0020910485181957483\n",
      "Epoch 1275, Loss: 0.006905873364303261, Final Batch Loss: 0.005981741473078728\n",
      "Epoch 1276, Loss: 0.004210536426398903, Final Batch Loss: 0.0009684421238489449\n",
      "Epoch 1277, Loss: 0.0058987922966480255, Final Batch Loss: 0.0032981235999614\n",
      "Epoch 1278, Loss: 0.01154256146401167, Final Batch Loss: 0.0011632544919848442\n",
      "Epoch 1279, Loss: 0.002151084510842338, Final Batch Loss: 0.00026964375865645707\n",
      "Epoch 1280, Loss: 0.004450402921065688, Final Batch Loss: 0.0020606403704732656\n",
      "Epoch 1281, Loss: 0.009852029732428491, Final Batch Loss: 0.0014925695722922683\n",
      "Epoch 1282, Loss: 0.0025500484043732285, Final Batch Loss: 0.0012500168522819877\n",
      "Epoch 1283, Loss: 0.009664758574217558, Final Batch Loss: 0.002406901679933071\n",
      "Epoch 1284, Loss: 0.015527560841292143, Final Batch Loss: 0.0074287536554038525\n",
      "Epoch 1285, Loss: 0.015445876400917768, Final Batch Loss: 0.007962489500641823\n",
      "Epoch 1286, Loss: 0.004975545569323003, Final Batch Loss: 0.0006505245110020041\n",
      "Epoch 1287, Loss: 0.0010438129684189335, Final Batch Loss: 0.00018271776207257062\n",
      "Epoch 1288, Loss: 0.007650635903701186, Final Batch Loss: 0.002759382827207446\n",
      "Epoch 1289, Loss: 0.005474682664498687, Final Batch Loss: 0.002926058601588011\n",
      "Epoch 1290, Loss: 0.008225052384659648, Final Batch Loss: 0.004974525887519121\n",
      "Epoch 1291, Loss: 0.003694988088682294, Final Batch Loss: 0.0006604879163205624\n",
      "Epoch 1292, Loss: 0.001723234832752496, Final Batch Loss: 0.0011387848062440753\n",
      "Epoch 1293, Loss: 0.04236648068763316, Final Batch Loss: 0.04067019373178482\n",
      "Epoch 1294, Loss: 0.007509280927479267, Final Batch Loss: 0.002073636744171381\n",
      "Epoch 1295, Loss: 0.0029024682007730007, Final Batch Loss: 0.0011044587008655071\n",
      "Epoch 1296, Loss: 0.002817746950313449, Final Batch Loss: 0.0007585710845887661\n",
      "Epoch 1297, Loss: 0.0022540832578670233, Final Batch Loss: 0.0003165634989272803\n",
      "Epoch 1298, Loss: 0.0012948342773597687, Final Batch Loss: 0.00038454795139841735\n",
      "Epoch 1299, Loss: 0.01378558948636055, Final Batch Loss: 0.006409636698663235\n",
      "Epoch 1300, Loss: 0.0012641368375625461, Final Batch Loss: 0.00045991313527338207\n",
      "Epoch 1301, Loss: 0.007459879212547094, Final Batch Loss: 0.0007551645976491272\n",
      "Epoch 1302, Loss: 0.0016399568412452936, Final Batch Loss: 0.000635855714790523\n",
      "Epoch 1303, Loss: 0.005970710248220712, Final Batch Loss: 0.0050140563398599625\n",
      "Epoch 1304, Loss: 0.002458959468640387, Final Batch Loss: 0.001129721524193883\n",
      "Epoch 1305, Loss: 0.0012969759700354189, Final Batch Loss: 0.00026723273913376033\n",
      "Epoch 1306, Loss: 0.004026483715279028, Final Batch Loss: 0.00024438832770101726\n",
      "Epoch 1307, Loss: 0.005259069032035768, Final Batch Loss: 0.0034090608824044466\n",
      "Epoch 1308, Loss: 0.008078759303316474, Final Batch Loss: 0.001939322566613555\n",
      "Epoch 1309, Loss: 0.004170862608589232, Final Batch Loss: 0.00130893022287637\n",
      "Epoch 1310, Loss: 0.01301014143973589, Final Batch Loss: 0.0015188409015536308\n",
      "Epoch 1311, Loss: 0.009120728354901075, Final Batch Loss: 0.0017107832245528698\n",
      "Epoch 1312, Loss: 0.013526368420571089, Final Batch Loss: 0.009583257138729095\n",
      "Epoch 1313, Loss: 0.0014606546610593796, Final Batch Loss: 0.00034812313970178366\n",
      "Epoch 1314, Loss: 0.004243887378834188, Final Batch Loss: 0.0028938523028045893\n",
      "Epoch 1315, Loss: 0.0034519462496973574, Final Batch Loss: 0.0008639081497676671\n",
      "Epoch 1316, Loss: 0.0032030633519752882, Final Batch Loss: 0.0030865627340972424\n",
      "Epoch 1317, Loss: 0.004147253464907408, Final Batch Loss: 0.0011955348309129477\n",
      "Epoch 1318, Loss: 0.0012134280987083912, Final Batch Loss: 0.0003255886840634048\n",
      "Epoch 1319, Loss: 0.002012728597037494, Final Batch Loss: 0.001296892180107534\n",
      "Epoch 1320, Loss: 0.024791411589831114, Final Batch Loss: 0.017722809687256813\n",
      "Epoch 1321, Loss: 0.0016691742930561304, Final Batch Loss: 0.0010589712765067816\n",
      "Epoch 1322, Loss: 0.016197577584534883, Final Batch Loss: 0.002144154626876116\n",
      "Epoch 1323, Loss: 0.008925109170377254, Final Batch Loss: 0.0023408839479088783\n",
      "Epoch 1324, Loss: 0.01781131245661527, Final Batch Loss: 0.0012373282806947827\n",
      "Epoch 1325, Loss: 0.0037612285232171416, Final Batch Loss: 0.001928731449879706\n",
      "Epoch 1326, Loss: 0.003362810704857111, Final Batch Loss: 0.0009859835263341665\n",
      "Epoch 1327, Loss: 0.0010051348072011024, Final Batch Loss: 0.0005868509178981185\n",
      "Epoch 1328, Loss: 0.002602966851554811, Final Batch Loss: 0.0014984054723754525\n",
      "Epoch 1329, Loss: 0.011038486787583679, Final Batch Loss: 0.010359405539929867\n",
      "Epoch 1330, Loss: 0.005104073614347726, Final Batch Loss: 0.0008560193818993866\n",
      "Epoch 1331, Loss: 0.0016532015870325267, Final Batch Loss: 0.0010147813009098172\n",
      "Epoch 1332, Loss: 0.007637971430085599, Final Batch Loss: 0.0010123023530468345\n",
      "Epoch 1333, Loss: 0.005242393584921956, Final Batch Loss: 0.0023255411069840193\n",
      "Epoch 1334, Loss: 0.0016312163788825274, Final Batch Loss: 0.0002802204107865691\n",
      "Epoch 1335, Loss: 0.0010900606430368498, Final Batch Loss: 0.00021727495186496526\n",
      "Epoch 1336, Loss: 0.005159795400686562, Final Batch Loss: 0.003812456503510475\n",
      "Epoch 1337, Loss: 0.003555025701643899, Final Batch Loss: 0.0004556335334200412\n",
      "Epoch 1338, Loss: 0.0016156627680175006, Final Batch Loss: 0.0007015651208348572\n",
      "Epoch 1339, Loss: 0.0017415987676940858, Final Batch Loss: 0.001047062105499208\n",
      "Epoch 1340, Loss: 0.010968836955726147, Final Batch Loss: 0.0041754781268537045\n",
      "Epoch 1341, Loss: 0.004462218901608139, Final Batch Loss: 0.0035024136304855347\n",
      "Epoch 1342, Loss: 0.03086902294307947, Final Batch Loss: 0.022620176896452904\n",
      "Epoch 1343, Loss: 0.006279843219090253, Final Batch Loss: 0.005627180449664593\n",
      "Epoch 1344, Loss: 0.00814913073554635, Final Batch Loss: 0.004039686638861895\n",
      "Epoch 1345, Loss: 0.014064700459130108, Final Batch Loss: 0.013091075234115124\n",
      "Epoch 1346, Loss: 0.022462578024715185, Final Batch Loss: 0.017025819048285484\n",
      "Epoch 1347, Loss: 0.005663133691996336, Final Batch Loss: 0.0019621846731752157\n",
      "Epoch 1348, Loss: 0.001483319967519492, Final Batch Loss: 0.0008243204792961478\n",
      "Epoch 1349, Loss: 0.003975652274675667, Final Batch Loss: 0.0024855758529156446\n",
      "Epoch 1350, Loss: 0.05376671999692917, Final Batch Loss: 0.0005079880356788635\n",
      "Epoch 1351, Loss: 0.004260257788700983, Final Batch Loss: 0.003958310000598431\n",
      "Epoch 1352, Loss: 0.003822187485639006, Final Batch Loss: 0.0030819575767964125\n",
      "Epoch 1353, Loss: 0.002114666858687997, Final Batch Loss: 0.0013658793177455664\n",
      "Epoch 1354, Loss: 0.006498233298771083, Final Batch Loss: 0.005246814340353012\n",
      "Epoch 1355, Loss: 0.003692297512316145, Final Batch Loss: 0.0001950538862729445\n",
      "Epoch 1356, Loss: 0.0029681805754080415, Final Batch Loss: 0.0011303952196612954\n",
      "Epoch 1357, Loss: 0.0026614103699102998, Final Batch Loss: 0.0005542229628190398\n",
      "Epoch 1358, Loss: 0.004186622041743249, Final Batch Loss: 0.0007403962663374841\n",
      "Epoch 1359, Loss: 0.002567778923548758, Final Batch Loss: 0.0015420871786773205\n",
      "Epoch 1360, Loss: 0.0020206572953611612, Final Batch Loss: 0.0013824006309732795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1361, Loss: 0.004862255300395191, Final Batch Loss: 0.001796156051568687\n",
      "Epoch 1362, Loss: 0.002604999695904553, Final Batch Loss: 0.00127820810303092\n",
      "Epoch 1363, Loss: 0.003803842351771891, Final Batch Loss: 0.0013832469703629613\n",
      "Epoch 1364, Loss: 0.002593229291960597, Final Batch Loss: 0.001268042717128992\n",
      "Epoch 1365, Loss: 0.013576954137533903, Final Batch Loss: 0.0065101017244160175\n",
      "Epoch 1366, Loss: 0.004281217290554196, Final Batch Loss: 0.0037126815877854824\n",
      "Epoch 1367, Loss: 0.005300349905155599, Final Batch Loss: 0.0013058463810011744\n",
      "Epoch 1368, Loss: 0.003059539361856878, Final Batch Loss: 0.001795268035493791\n",
      "Epoch 1369, Loss: 0.010603357339277864, Final Batch Loss: 0.0010116745252162218\n",
      "Epoch 1370, Loss: 0.00362172385212034, Final Batch Loss: 0.0011122786672785878\n",
      "Epoch 1371, Loss: 0.003071266575716436, Final Batch Loss: 0.0012391341151669621\n",
      "Epoch 1372, Loss: 0.001658655033679679, Final Batch Loss: 0.0014125863090157509\n",
      "Epoch 1373, Loss: 0.006269745295867324, Final Batch Loss: 0.0024401461705565453\n",
      "Epoch 1374, Loss: 0.004014647100120783, Final Batch Loss: 0.0009163832291960716\n",
      "Epoch 1375, Loss: 0.0025112410075962543, Final Batch Loss: 0.0010297448607161641\n",
      "Epoch 1376, Loss: 0.0009084077319130301, Final Batch Loss: 0.0002606749767437577\n",
      "Epoch 1377, Loss: 0.0022720620036125183, Final Batch Loss: 0.0009292963659390807\n",
      "Epoch 1378, Loss: 0.0033642015187069774, Final Batch Loss: 0.0011710956459864974\n",
      "Epoch 1379, Loss: 0.0106501211412251, Final Batch Loss: 0.003027527127414942\n",
      "Epoch 1380, Loss: 0.0013037038152106106, Final Batch Loss: 0.0006971211987547576\n",
      "Epoch 1381, Loss: 0.00429170299321413, Final Batch Loss: 0.003524978179484606\n",
      "Epoch 1382, Loss: 0.003992057405412197, Final Batch Loss: 0.002393987961113453\n",
      "Epoch 1383, Loss: 0.011809268034994602, Final Batch Loss: 0.0023632096126675606\n",
      "Epoch 1384, Loss: 0.004391363938339055, Final Batch Loss: 0.0012224201345816255\n",
      "Epoch 1385, Loss: 0.0021073060343042016, Final Batch Loss: 0.0014174877433106303\n",
      "Epoch 1386, Loss: 0.026463327929377556, Final Batch Loss: 0.01499114464968443\n",
      "Epoch 1387, Loss: 0.004787165147718042, Final Batch Loss: 0.0009234402677975595\n",
      "Epoch 1388, Loss: 0.0021400643163360655, Final Batch Loss: 0.0005898214294575155\n",
      "Epoch 1389, Loss: 0.009214152116328478, Final Batch Loss: 0.007903734222054482\n",
      "Epoch 1390, Loss: 0.0029474965995177627, Final Batch Loss: 0.00137874367646873\n",
      "Epoch 1391, Loss: 0.004527211072854698, Final Batch Loss: 0.0015483855968341231\n",
      "Epoch 1392, Loss: 0.016966563649475574, Final Batch Loss: 0.00666433572769165\n",
      "Epoch 1393, Loss: 0.004500072216615081, Final Batch Loss: 0.0029146254528313875\n",
      "Epoch 1394, Loss: 0.003029333776794374, Final Batch Loss: 0.0016629926394671202\n",
      "Epoch 1395, Loss: 0.007146795745939016, Final Batch Loss: 0.0014760163612663746\n",
      "Epoch 1396, Loss: 0.0009829969785641879, Final Batch Loss: 0.00043873596587218344\n",
      "Epoch 1397, Loss: 0.008170888526365161, Final Batch Loss: 0.007058840245008469\n",
      "Epoch 1398, Loss: 0.004265694180503488, Final Batch Loss: 0.002032601973041892\n",
      "Epoch 1399, Loss: 0.00890917656943202, Final Batch Loss: 0.0023866076953709126\n",
      "Epoch 1400, Loss: 0.029310467129107565, Final Batch Loss: 0.028640473261475563\n",
      "Epoch 1401, Loss: 0.0019200019596610218, Final Batch Loss: 0.0003071718674618751\n",
      "Epoch 1402, Loss: 0.047498585190624, Final Batch Loss: 0.004888498689979315\n",
      "Epoch 1403, Loss: 0.0065718223340809345, Final Batch Loss: 0.001212571281939745\n",
      "Epoch 1404, Loss: 0.0034576292091514915, Final Batch Loss: 0.00030722617520950735\n",
      "Epoch 1405, Loss: 0.0029851620201952755, Final Batch Loss: 0.0023598698899149895\n",
      "Epoch 1406, Loss: 0.015640801517292857, Final Batch Loss: 0.0026725016068667173\n",
      "Epoch 1407, Loss: 0.0019919538754038513, Final Batch Loss: 0.00019437092123553157\n",
      "Epoch 1408, Loss: 0.0023733507841825485, Final Batch Loss: 0.0013156947679817677\n",
      "Epoch 1409, Loss: 0.0013025386142544448, Final Batch Loss: 0.000737507943995297\n",
      "Epoch 1410, Loss: 0.0035113991471007466, Final Batch Loss: 0.0021126584615558386\n",
      "Epoch 1411, Loss: 0.009317229269072413, Final Batch Loss: 0.008251187391579151\n",
      "Epoch 1412, Loss: 0.013552975375205278, Final Batch Loss: 0.009466749615967274\n",
      "Epoch 1413, Loss: 0.012113527162000537, Final Batch Loss: 0.011281470768153667\n",
      "Epoch 1414, Loss: 0.009091698913834989, Final Batch Loss: 0.008407101966440678\n",
      "Epoch 1415, Loss: 0.029311124235391617, Final Batch Loss: 0.014584300108253956\n",
      "Epoch 1416, Loss: 0.007316262170206755, Final Batch Loss: 0.006962019484490156\n",
      "Epoch 1417, Loss: 0.008884258102625608, Final Batch Loss: 0.002127682324498892\n",
      "Epoch 1418, Loss: 0.006219890434294939, Final Batch Loss: 0.0021072737872600555\n",
      "Epoch 1419, Loss: 0.0015608420362696052, Final Batch Loss: 0.00031510693952441216\n",
      "Epoch 1420, Loss: 0.020742272376082838, Final Batch Loss: 0.0007215192308649421\n",
      "Epoch 1421, Loss: 0.03681710874661803, Final Batch Loss: 0.03153800219297409\n",
      "Epoch 1422, Loss: 0.01913320366293192, Final Batch Loss: 0.010455806739628315\n",
      "Epoch 1423, Loss: 0.005672344355843961, Final Batch Loss: 0.004291840363293886\n",
      "Epoch 1424, Loss: 0.0505123547045514, Final Batch Loss: 0.04930984601378441\n",
      "Epoch 1425, Loss: 0.015035758027806878, Final Batch Loss: 0.0006029496435075998\n",
      "Epoch 1426, Loss: 0.06689560622908175, Final Batch Loss: 0.06335220485925674\n",
      "Epoch 1427, Loss: 0.00629773736000061, Final Batch Loss: 0.0052493722178041935\n",
      "Epoch 1428, Loss: 0.07674060011049733, Final Batch Loss: 0.07579757273197174\n",
      "Epoch 1429, Loss: 0.0036331001319922507, Final Batch Loss: 0.0008196603157557547\n",
      "Epoch 1430, Loss: 0.005024059442803264, Final Batch Loss: 0.0026618705596774817\n",
      "Epoch 1431, Loss: 0.02046874165534973, Final Batch Loss: 0.009224091656506062\n",
      "Epoch 1432, Loss: 0.015261129126884043, Final Batch Loss: 0.001504147076047957\n",
      "Epoch 1433, Loss: 0.0027202213532291353, Final Batch Loss: 0.0019820521119982004\n",
      "Epoch 1434, Loss: 0.0016301003051921725, Final Batch Loss: 0.0006530678365379572\n",
      "Epoch 1435, Loss: 0.004828354896744713, Final Batch Loss: 0.0002777181507553905\n",
      "Epoch 1436, Loss: 0.012129754992201924, Final Batch Loss: 0.002310182200744748\n",
      "Epoch 1437, Loss: 0.001584689860465005, Final Batch Loss: 0.0004102668317500502\n",
      "Epoch 1438, Loss: 0.013837419915944338, Final Batch Loss: 0.010727227665483952\n",
      "Epoch 1439, Loss: 0.0023627490445505828, Final Batch Loss: 0.0019587543793022633\n",
      "Epoch 1440, Loss: 0.004656882956624031, Final Batch Loss: 0.002376183168962598\n",
      "Epoch 1441, Loss: 0.001301692333072424, Final Batch Loss: 0.0005757682956755161\n",
      "Epoch 1442, Loss: 0.002088399196509272, Final Batch Loss: 0.0012940154410898685\n",
      "Epoch 1443, Loss: 0.012176245916634798, Final Batch Loss: 0.007288648746907711\n",
      "Epoch 1444, Loss: 0.0046616714098490775, Final Batch Loss: 0.0009616821189410985\n",
      "Epoch 1445, Loss: 0.007902429904788733, Final Batch Loss: 0.0026551783084869385\n",
      "Epoch 1446, Loss: 0.0034606483532115817, Final Batch Loss: 0.0014411163283511996\n",
      "Epoch 1447, Loss: 0.0018502174643799663, Final Batch Loss: 0.0006089636590331793\n",
      "Epoch 1448, Loss: 0.005448510521091521, Final Batch Loss: 0.0010976811172440648\n",
      "Epoch 1449, Loss: 0.04233511979691684, Final Batch Loss: 0.0023163564037531614\n",
      "Epoch 1450, Loss: 0.01470212358981371, Final Batch Loss: 0.0012224698439240456\n",
      "Epoch 1451, Loss: 0.005539664183743298, Final Batch Loss: 0.004622031468898058\n",
      "Epoch 1452, Loss: 0.0025189570151269436, Final Batch Loss: 0.0007361306343227625\n",
      "Epoch 1453, Loss: 0.00704464630689472, Final Batch Loss: 0.005196516402065754\n",
      "Epoch 1454, Loss: 0.007132889120839536, Final Batch Loss: 0.005931997671723366\n",
      "Epoch 1455, Loss: 0.00905135105131194, Final Batch Loss: 0.008118473924696445\n",
      "Epoch 1456, Loss: 0.01910173532087356, Final Batch Loss: 0.0013298896374180913\n",
      "Epoch 1457, Loss: 0.0022340682335197926, Final Batch Loss: 0.0011931988410651684\n",
      "Epoch 1458, Loss: 0.001754867291310802, Final Batch Loss: 0.00026836738106794655\n",
      "Epoch 1459, Loss: 0.007955756853334606, Final Batch Loss: 0.001737971673719585\n",
      "Epoch 1460, Loss: 0.014598198933526874, Final Batch Loss: 0.001815018942579627\n",
      "Epoch 1461, Loss: 0.010157771408557892, Final Batch Loss: 0.009055023081600666\n",
      "Epoch 1462, Loss: 0.05150323174893856, Final Batch Loss: 0.0417068749666214\n",
      "Epoch 1463, Loss: 0.004879375686869025, Final Batch Loss: 0.002736941911280155\n",
      "Epoch 1464, Loss: 0.001368977129459381, Final Batch Loss: 0.000680602272041142\n",
      "Epoch 1465, Loss: 0.002985526400152594, Final Batch Loss: 0.0005461350665427744\n",
      "Epoch 1466, Loss: 0.005407460441347212, Final Batch Loss: 0.004639352671802044\n",
      "Epoch 1467, Loss: 0.0019060825579799712, Final Batch Loss: 0.0008342305081896484\n",
      "Epoch 1468, Loss: 0.007962691131979227, Final Batch Loss: 0.002051184419542551\n",
      "Epoch 1469, Loss: 0.010311552323400974, Final Batch Loss: 0.007864191196858883\n",
      "Epoch 1470, Loss: 0.006741007324308157, Final Batch Loss: 0.0014404463581740856\n",
      "Epoch 1471, Loss: 0.0034269678872078657, Final Batch Loss: 0.0005039924290031195\n",
      "Epoch 1472, Loss: 0.001451758376788348, Final Batch Loss: 0.0006638376507908106\n",
      "Epoch 1473, Loss: 0.003590952721424401, Final Batch Loss: 0.0020773469004780054\n",
      "Epoch 1474, Loss: 0.00958757835905999, Final Batch Loss: 0.00829417072236538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1475, Loss: 0.003587521845474839, Final Batch Loss: 0.002035468118265271\n",
      "Epoch 1476, Loss: 0.0037973884027451277, Final Batch Loss: 0.001294432207942009\n",
      "Epoch 1477, Loss: 0.016100456472486258, Final Batch Loss: 0.0014089127071201801\n",
      "Epoch 1478, Loss: 0.0034516118466854095, Final Batch Loss: 0.0005707873497158289\n",
      "Epoch 1479, Loss: 0.0028730614576488733, Final Batch Loss: 0.0020960699766874313\n",
      "Epoch 1480, Loss: 0.003634426277130842, Final Batch Loss: 0.0006075927522033453\n",
      "Epoch 1481, Loss: 0.012158079538494349, Final Batch Loss: 0.00835583359003067\n",
      "Epoch 1482, Loss: 0.048787035746499896, Final Batch Loss: 0.04634648188948631\n",
      "Epoch 1483, Loss: 0.004131081514060497, Final Batch Loss: 0.0019527305848896503\n",
      "Epoch 1484, Loss: 0.010736993397586048, Final Batch Loss: 0.009538045153021812\n",
      "Epoch 1485, Loss: 0.01047044328879565, Final Batch Loss: 0.0005550541682168841\n",
      "Epoch 1486, Loss: 0.0020073430496267974, Final Batch Loss: 0.000603673339355737\n",
      "Epoch 1487, Loss: 0.0031043459894135594, Final Batch Loss: 0.0010344217298552394\n",
      "Epoch 1488, Loss: 0.003219583537429571, Final Batch Loss: 0.0015516031999140978\n",
      "Epoch 1489, Loss: 0.0021049687638878822, Final Batch Loss: 0.0012558300513774157\n",
      "Epoch 1490, Loss: 0.002066376036964357, Final Batch Loss: 0.0008356425678357482\n",
      "Epoch 1491, Loss: 0.0015666925464756787, Final Batch Loss: 0.0008854262996464968\n",
      "Epoch 1492, Loss: 0.008834137115627527, Final Batch Loss: 0.0070113823749125\n",
      "Epoch 1493, Loss: 0.0015905651380307972, Final Batch Loss: 0.0008628762443549931\n",
      "Epoch 1494, Loss: 0.003963583265431225, Final Batch Loss: 0.0023593108635395765\n",
      "Epoch 1495, Loss: 0.0033401743276044726, Final Batch Loss: 0.0012706703273579478\n",
      "Epoch 1496, Loss: 0.0029299919260665774, Final Batch Loss: 0.0011900394456461072\n",
      "Epoch 1497, Loss: 0.0072408937849104404, Final Batch Loss: 0.004809441976249218\n",
      "Epoch 1498, Loss: 0.02564605325460434, Final Batch Loss: 0.008571488782763481\n",
      "Epoch 1499, Loss: 0.00414844776969403, Final Batch Loss: 0.0014216616982594132\n",
      "Epoch 1500, Loss: 0.0009279032819904387, Final Batch Loss: 0.0002289250260218978\n",
      "Epoch 1501, Loss: 0.001019192859530449, Final Batch Loss: 0.00038405542727559805\n",
      "Epoch 1502, Loss: 0.0037720838154200464, Final Batch Loss: 0.000323860120261088\n",
      "Epoch 1503, Loss: 0.003117332744295709, Final Batch Loss: 0.00021360167011152953\n",
      "Epoch 1504, Loss: 0.006267750868573785, Final Batch Loss: 0.002209120662882924\n",
      "Epoch 1505, Loss: 0.004719042452052236, Final Batch Loss: 0.0028328823391348124\n",
      "Epoch 1506, Loss: 0.02126755256904289, Final Batch Loss: 0.02057824283838272\n",
      "Epoch 1507, Loss: 0.0026554258074611425, Final Batch Loss: 0.0009591166162863374\n",
      "Epoch 1508, Loss: 0.0026415424654260278, Final Batch Loss: 0.0016453680582344532\n",
      "Epoch 1509, Loss: 0.0033622158225625753, Final Batch Loss: 0.0006385915912687778\n",
      "Epoch 1510, Loss: 0.03504009684547782, Final Batch Loss: 0.029565276578068733\n",
      "Epoch 1511, Loss: 0.003438699641264975, Final Batch Loss: 0.0012867426266893744\n",
      "Epoch 1512, Loss: 0.011694486252963543, Final Batch Loss: 0.005421955604106188\n",
      "Epoch 1513, Loss: 0.006226245779544115, Final Batch Loss: 0.00031884247437119484\n",
      "Epoch 1514, Loss: 0.010914231883361936, Final Batch Loss: 0.009653759188950062\n",
      "Epoch 1515, Loss: 0.004016654100269079, Final Batch Loss: 0.0014116372913122177\n",
      "Epoch 1516, Loss: 0.012198072450701147, Final Batch Loss: 0.011716626584529877\n",
      "Epoch 1517, Loss: 0.0033418117091059685, Final Batch Loss: 0.0012923120521008968\n",
      "Epoch 1518, Loss: 0.0021103189792484045, Final Batch Loss: 0.0017819276545196772\n",
      "Epoch 1519, Loss: 0.008888349053449929, Final Batch Loss: 0.007908765226602554\n",
      "Epoch 1520, Loss: 0.0013610947935376316, Final Batch Loss: 0.00046946844668127596\n",
      "Epoch 1521, Loss: 0.0020936620130669326, Final Batch Loss: 0.0004381626786198467\n",
      "Epoch 1522, Loss: 0.010184770915657282, Final Batch Loss: 0.0028886599466204643\n",
      "Epoch 1523, Loss: 0.001299666939303279, Final Batch Loss: 0.0003025894984602928\n",
      "Epoch 1524, Loss: 0.00207570445491001, Final Batch Loss: 0.0015181548660621047\n",
      "Epoch 1525, Loss: 0.0036325177643448114, Final Batch Loss: 0.0012127100490033627\n",
      "Epoch 1526, Loss: 0.0012527565704658628, Final Batch Loss: 0.00041331839747726917\n",
      "Epoch 1527, Loss: 0.001039899085299112, Final Batch Loss: 0.00017739263421390206\n",
      "Epoch 1528, Loss: 0.00223717832705006, Final Batch Loss: 0.0003429760108701885\n",
      "Epoch 1529, Loss: 0.004077095887623727, Final Batch Loss: 0.0026559417601674795\n",
      "Epoch 1530, Loss: 0.003979138593422249, Final Batch Loss: 0.0002830524754244834\n",
      "Epoch 1531, Loss: 0.010501049509912264, Final Batch Loss: 0.010404735803604126\n",
      "Epoch 1532, Loss: 0.005641489056870341, Final Batch Loss: 0.0016804744955152273\n",
      "Epoch 1533, Loss: 0.007059095019940287, Final Batch Loss: 0.0008960022241808474\n",
      "Epoch 1534, Loss: 0.0026682798052206635, Final Batch Loss: 0.0010276813991367817\n",
      "Epoch 1535, Loss: 0.001882881042547524, Final Batch Loss: 0.0002484788419678807\n",
      "Epoch 1536, Loss: 0.0039038717513903975, Final Batch Loss: 0.0026355849113315344\n",
      "Epoch 1537, Loss: 0.0014566496829502285, Final Batch Loss: 0.00047366676153615117\n",
      "Epoch 1538, Loss: 0.0067291962914168835, Final Batch Loss: 0.005067269317805767\n",
      "Epoch 1539, Loss: 0.0020396782783791423, Final Batch Loss: 0.0007566941203549504\n",
      "Epoch 1540, Loss: 0.004258671193383634, Final Batch Loss: 0.0028993054293096066\n",
      "Epoch 1541, Loss: 0.003323047742014751, Final Batch Loss: 0.00021822968847118318\n",
      "Epoch 1542, Loss: 0.0045868479064665735, Final Batch Loss: 0.0036331627052277327\n",
      "Epoch 1543, Loss: 0.003298215917311609, Final Batch Loss: 0.0013423949712887406\n",
      "Epoch 1544, Loss: 0.002213412954006344, Final Batch Loss: 0.0019797307904809713\n",
      "Epoch 1545, Loss: 0.0013906920503359288, Final Batch Loss: 0.00036033926880918443\n",
      "Epoch 1546, Loss: 0.0017146305181086063, Final Batch Loss: 0.0006933357799425721\n",
      "Epoch 1547, Loss: 0.001067973003955558, Final Batch Loss: 0.0006156464805826545\n",
      "Epoch 1548, Loss: 0.0018450388452038169, Final Batch Loss: 0.0010389602975919843\n",
      "Epoch 1549, Loss: 0.0022621002281084657, Final Batch Loss: 0.00165808096062392\n",
      "Epoch 1550, Loss: 0.038603908848017454, Final Batch Loss: 0.03771993890404701\n",
      "Epoch 1551, Loss: 0.004025975038530305, Final Batch Loss: 0.0036708025727421045\n",
      "Epoch 1552, Loss: 0.0019229380995966494, Final Batch Loss: 0.0005405988194979727\n",
      "Epoch 1553, Loss: 0.005255881464108825, Final Batch Loss: 0.0027379842940717936\n",
      "Epoch 1554, Loss: 0.0013458235771395266, Final Batch Loss: 0.0006815542583353817\n",
      "Epoch 1555, Loss: 0.001779249869287014, Final Batch Loss: 0.0002657350851222873\n",
      "Epoch 1556, Loss: 0.030437905807048082, Final Batch Loss: 0.0013925065286457539\n",
      "Epoch 1557, Loss: 0.011811793665401638, Final Batch Loss: 0.011179263703525066\n",
      "Epoch 1558, Loss: 0.0016019927570596337, Final Batch Loss: 0.0008577213156968355\n",
      "Epoch 1559, Loss: 0.010810890438733622, Final Batch Loss: 0.000460363196907565\n",
      "Epoch 1560, Loss: 0.005971869133645669, Final Batch Loss: 0.00044954303302802145\n",
      "Epoch 1561, Loss: 0.006901217857375741, Final Batch Loss: 0.002439080970361829\n",
      "Epoch 1562, Loss: 0.005333786481060088, Final Batch Loss: 0.004347438458353281\n",
      "Epoch 1563, Loss: 0.0009122197225224227, Final Batch Loss: 0.00026259812875650823\n",
      "Epoch 1564, Loss: 0.015031796356197447, Final Batch Loss: 0.0006233085296116769\n",
      "Epoch 1565, Loss: 0.002878309809602797, Final Batch Loss: 0.0023683917243033648\n",
      "Epoch 1566, Loss: 0.0017513107741251588, Final Batch Loss: 0.0008696072618477046\n",
      "Epoch 1567, Loss: 0.004448958556167781, Final Batch Loss: 0.0019328048219904304\n",
      "Epoch 1568, Loss: 0.00897141988389194, Final Batch Loss: 0.007366590201854706\n",
      "Epoch 1569, Loss: 0.002036183825111948, Final Batch Loss: 0.001866796868853271\n",
      "Epoch 1570, Loss: 0.0013892642309656367, Final Batch Loss: 0.001179573475383222\n",
      "Epoch 1571, Loss: 0.001843242789618671, Final Batch Loss: 0.0014354725135490298\n",
      "Epoch 1572, Loss: 0.0014479588135145605, Final Batch Loss: 0.0008001304231584072\n",
      "Epoch 1573, Loss: 0.008554035099223256, Final Batch Loss: 0.0012508805375546217\n",
      "Epoch 1574, Loss: 0.009860343707259744, Final Batch Loss: 0.009431174024939537\n",
      "Epoch 1575, Loss: 0.0028477542218752205, Final Batch Loss: 0.0007143370457924902\n",
      "Epoch 1576, Loss: 0.001966342912055552, Final Batch Loss: 0.0012466831831261516\n",
      "Epoch 1577, Loss: 0.0028118641930632293, Final Batch Loss: 0.0008422471000812948\n",
      "Epoch 1578, Loss: 0.017952279653400183, Final Batch Loss: 0.012743759900331497\n",
      "Epoch 1579, Loss: 0.004126385669223964, Final Batch Loss: 0.002411435591056943\n",
      "Epoch 1580, Loss: 0.0025001211324706674, Final Batch Loss: 0.001412748359143734\n",
      "Epoch 1581, Loss: 0.0030490961798932403, Final Batch Loss: 0.002840503118932247\n",
      "Epoch 1582, Loss: 0.014766116975806653, Final Batch Loss: 0.013733011670410633\n",
      "Epoch 1583, Loss: 0.0011350938584655523, Final Batch Loss: 0.0006928928196430206\n",
      "Epoch 1584, Loss: 0.002931963768787682, Final Batch Loss: 0.002291945042088628\n",
      "Epoch 1585, Loss: 0.01524203340522945, Final Batch Loss: 0.0012760802637785673\n",
      "Epoch 1586, Loss: 0.001859906769823283, Final Batch Loss: 0.0005104659940116107\n",
      "Epoch 1587, Loss: 0.0029271271778270602, Final Batch Loss: 0.0014780635247007012\n",
      "Epoch 1588, Loss: 0.00327976793050766, Final Batch Loss: 0.002130465814843774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1589, Loss: 0.003989742457633838, Final Batch Loss: 0.0036461784038692713\n",
      "Epoch 1590, Loss: 0.002512012026272714, Final Batch Loss: 0.001829863409511745\n",
      "Epoch 1591, Loss: 0.0016565096593694761, Final Batch Loss: 0.00016305393364746124\n",
      "Epoch 1592, Loss: 0.013276449870318174, Final Batch Loss: 0.009350222535431385\n",
      "Epoch 1593, Loss: 0.017928992165252566, Final Batch Loss: 0.001032695872709155\n",
      "Epoch 1594, Loss: 0.0033928705961443484, Final Batch Loss: 0.002419427502900362\n",
      "Epoch 1595, Loss: 0.002222925948444754, Final Batch Loss: 0.0006937772850506008\n",
      "Epoch 1596, Loss: 0.002731997228693217, Final Batch Loss: 0.001924444455653429\n",
      "Epoch 1597, Loss: 0.026334121997933835, Final Batch Loss: 0.025562500581145287\n",
      "Epoch 1598, Loss: 0.01596710691228509, Final Batch Loss: 0.015214125625789165\n",
      "Epoch 1599, Loss: 0.002591654905700125, Final Batch Loss: 0.00013555401528719813\n",
      "Epoch 1600, Loss: 0.006535313674248755, Final Batch Loss: 0.0052262283861637115\n",
      "Epoch 1601, Loss: 0.0014362024958245456, Final Batch Loss: 0.00019197218352928758\n",
      "Epoch 1602, Loss: 0.00872675352729857, Final Batch Loss: 0.008187012746930122\n",
      "Epoch 1603, Loss: 0.0024259232450276613, Final Batch Loss: 0.0017832417506724596\n",
      "Epoch 1604, Loss: 0.004441162338480353, Final Batch Loss: 0.0036451220512390137\n",
      "Epoch 1605, Loss: 0.0021485279430635273, Final Batch Loss: 0.0014108234317973256\n",
      "Epoch 1606, Loss: 0.0026308827800676227, Final Batch Loss: 0.0012672427110373974\n",
      "Epoch 1607, Loss: 0.0011120076524093747, Final Batch Loss: 0.0005257269949652255\n",
      "Epoch 1608, Loss: 0.0015827161842025816, Final Batch Loss: 0.0007384748896583915\n",
      "Epoch 1609, Loss: 0.004207652062177658, Final Batch Loss: 0.003663458162918687\n",
      "Epoch 1610, Loss: 0.0022679290268570185, Final Batch Loss: 0.001167031703516841\n",
      "Epoch 1611, Loss: 0.003612196771427989, Final Batch Loss: 0.00029012025333940983\n",
      "Epoch 1612, Loss: 0.0034555933088995516, Final Batch Loss: 0.0008307386306114495\n",
      "Epoch 1613, Loss: 0.004820673377253115, Final Batch Loss: 0.0017993702786043286\n",
      "Epoch 1614, Loss: 0.0041372402920387685, Final Batch Loss: 0.0009436294785700738\n",
      "Epoch 1615, Loss: 0.0023311207769438624, Final Batch Loss: 0.001270461012609303\n",
      "Epoch 1616, Loss: 0.0011135528329759836, Final Batch Loss: 0.0006184973753988743\n",
      "Epoch 1617, Loss: 0.0008535655506420881, Final Batch Loss: 0.00035465360269881785\n",
      "Epoch 1618, Loss: 0.002666797343408689, Final Batch Loss: 0.0004754451510962099\n",
      "Epoch 1619, Loss: 0.0009362594792037271, Final Batch Loss: 0.00010620292596286163\n",
      "Epoch 1620, Loss: 0.010593118495307863, Final Batch Loss: 0.0011873481562361121\n",
      "Epoch 1621, Loss: 0.009806695394217968, Final Batch Loss: 0.004167761653661728\n",
      "Epoch 1622, Loss: 0.008346955059096217, Final Batch Loss: 0.0063021485693752766\n",
      "Epoch 1623, Loss: 0.00887403846718371, Final Batch Loss: 0.008474346250295639\n",
      "Epoch 1624, Loss: 0.007592533715069294, Final Batch Loss: 0.002232735510915518\n",
      "Epoch 1625, Loss: 0.006077792000724003, Final Batch Loss: 0.00023324458743445575\n",
      "Epoch 1626, Loss: 0.002097875054460019, Final Batch Loss: 0.0008284599171020091\n",
      "Epoch 1627, Loss: 0.00904647121205926, Final Batch Loss: 0.0010356293059885502\n",
      "Epoch 1628, Loss: 0.014132770244032145, Final Batch Loss: 0.009459109045565128\n",
      "Epoch 1629, Loss: 0.0022561722435057163, Final Batch Loss: 0.0012059420114383101\n",
      "Epoch 1630, Loss: 0.003272436326369643, Final Batch Loss: 0.00154025643132627\n",
      "Epoch 1631, Loss: 0.007051876978948712, Final Batch Loss: 0.0031222801189869642\n",
      "Epoch 1632, Loss: 0.0007405965006910264, Final Batch Loss: 0.00030426541343331337\n",
      "Epoch 1633, Loss: 0.0036782583920285106, Final Batch Loss: 0.000981152174063027\n",
      "Epoch 1634, Loss: 0.002883320557884872, Final Batch Loss: 0.0007263709558174014\n",
      "Epoch 1635, Loss: 0.005164005211554468, Final Batch Loss: 0.0041243573650717735\n",
      "Epoch 1636, Loss: 0.002018196042627096, Final Batch Loss: 0.0009828374022617936\n",
      "Epoch 1637, Loss: 0.006052518263459206, Final Batch Loss: 0.0032032961025834084\n",
      "Epoch 1638, Loss: 0.007559094810858369, Final Batch Loss: 0.0051608821377158165\n",
      "Epoch 1639, Loss: 0.0024833756760926917, Final Batch Loss: 0.0022654219064861536\n",
      "Epoch 1640, Loss: 0.0014325054362416267, Final Batch Loss: 0.0007586796418763697\n",
      "Epoch 1641, Loss: 0.005641269031912088, Final Batch Loss: 0.0016335188411176205\n",
      "Epoch 1642, Loss: 0.0014566101890522987, Final Batch Loss: 0.00044611378689296544\n",
      "Epoch 1643, Loss: 0.0014598559937439859, Final Batch Loss: 0.0004807270015589893\n",
      "Epoch 1644, Loss: 0.001139166190114338, Final Batch Loss: 8.511241321684793e-05\n",
      "Epoch 1645, Loss: 0.0009510972304269671, Final Batch Loss: 0.00026458868524059653\n",
      "Epoch 1646, Loss: 0.0026213383534923196, Final Batch Loss: 0.0016997712664306164\n",
      "Epoch 1647, Loss: 0.0008560691785532981, Final Batch Loss: 0.00017296723672188818\n",
      "Epoch 1648, Loss: 0.0021044202730990946, Final Batch Loss: 0.0012523672776296735\n",
      "Epoch 1649, Loss: 0.002890428062528372, Final Batch Loss: 0.00215043849311769\n",
      "Epoch 1650, Loss: 0.0010438496683491394, Final Batch Loss: 0.00011994199303444475\n",
      "Epoch 1651, Loss: 0.0004580681852530688, Final Batch Loss: 0.00030101690208539367\n",
      "Epoch 1652, Loss: 0.0012402967258822173, Final Batch Loss: 0.0011032662587240338\n",
      "Epoch 1653, Loss: 0.0004494319000514224, Final Batch Loss: 0.00016058153414633125\n",
      "Epoch 1654, Loss: 0.002680787816643715, Final Batch Loss: 0.0008890096796676517\n",
      "Epoch 1655, Loss: 0.0031317626708187163, Final Batch Loss: 0.0006976714939810336\n",
      "Epoch 1656, Loss: 0.0014013366599101573, Final Batch Loss: 0.0002454144705552608\n",
      "Epoch 1657, Loss: 0.0007204058929346502, Final Batch Loss: 0.00036477376124821603\n",
      "Epoch 1658, Loss: 0.0017179155838675797, Final Batch Loss: 0.0005739040789194405\n",
      "Epoch 1659, Loss: 0.002814864186802879, Final Batch Loss: 0.00042520571150816977\n",
      "Epoch 1660, Loss: 0.004823431838303804, Final Batch Loss: 0.001014928799122572\n",
      "Epoch 1661, Loss: 0.0018677517655305564, Final Batch Loss: 0.0009935371344909072\n",
      "Epoch 1662, Loss: 0.0012796330847777426, Final Batch Loss: 0.00012381962733343244\n",
      "Epoch 1663, Loss: 0.0011234705743845552, Final Batch Loss: 0.000752320745959878\n",
      "Epoch 1664, Loss: 0.004251028018188663, Final Batch Loss: 0.004011166747659445\n",
      "Epoch 1665, Loss: 0.0010389248564024456, Final Batch Loss: 9.559922182234004e-05\n",
      "Epoch 1666, Loss: 0.0007524032989749685, Final Batch Loss: 0.00020211581431794912\n",
      "Epoch 1667, Loss: 0.0008943690190790221, Final Batch Loss: 0.000652622664347291\n",
      "Epoch 1668, Loss: 0.0039910010527819395, Final Batch Loss: 0.0007482350338250399\n",
      "Epoch 1669, Loss: 0.001108404016122222, Final Batch Loss: 0.0005128345801495016\n",
      "Epoch 1670, Loss: 0.0094391827005893, Final Batch Loss: 0.0032321230974048376\n",
      "Epoch 1671, Loss: 0.009859268640866503, Final Batch Loss: 0.009443467482924461\n",
      "Epoch 1672, Loss: 0.0012477778655011207, Final Batch Loss: 0.001000424730591476\n",
      "Epoch 1673, Loss: 0.002009723801165819, Final Batch Loss: 0.0010184576967731118\n",
      "Epoch 1674, Loss: 0.0017562024004291743, Final Batch Loss: 0.00047697030822746456\n",
      "Epoch 1675, Loss: 0.010802953969687223, Final Batch Loss: 0.005838280543684959\n",
      "Epoch 1676, Loss: 0.0028124151285737753, Final Batch Loss: 0.001477011595852673\n",
      "Epoch 1677, Loss: 0.002201437164330855, Final Batch Loss: 0.001724311034195125\n",
      "Epoch 1678, Loss: 0.0014293620188254863, Final Batch Loss: 0.001170834992080927\n",
      "Epoch 1679, Loss: 0.005496188590768725, Final Batch Loss: 0.004780855495482683\n",
      "Epoch 1680, Loss: 0.0015619030164089054, Final Batch Loss: 0.0012142314808443189\n",
      "Epoch 1681, Loss: 0.001219331898028031, Final Batch Loss: 0.0009487209026701748\n",
      "Epoch 1682, Loss: 0.012233751913299784, Final Batch Loss: 0.00012267203419469297\n",
      "Epoch 1683, Loss: 0.0015532955003436655, Final Batch Loss: 0.0003580596239771694\n",
      "Epoch 1684, Loss: 0.006280229659751058, Final Batch Loss: 0.002550424076616764\n",
      "Epoch 1685, Loss: 0.006261423841351643, Final Batch Loss: 0.0060197352431714535\n",
      "Epoch 1686, Loss: 0.014243165962398052, Final Batch Loss: 0.007900333032011986\n",
      "Epoch 1687, Loss: 0.004237276967614889, Final Batch Loss: 0.0035772393457591534\n",
      "Epoch 1688, Loss: 0.0042217354057356715, Final Batch Loss: 0.0023687316570430994\n",
      "Epoch 1689, Loss: 0.004376924247480929, Final Batch Loss: 0.0030365181155502796\n",
      "Epoch 1690, Loss: 0.0022821497404947877, Final Batch Loss: 0.001357324537821114\n",
      "Epoch 1691, Loss: 0.009922674391418695, Final Batch Loss: 0.002832300029695034\n",
      "Epoch 1692, Loss: 0.0025233791093342006, Final Batch Loss: 0.00024531473172828555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1693, Loss: 0.0019637149525806308, Final Batch Loss: 0.0008156837429851294\n",
      "Epoch 1694, Loss: 0.004288226249627769, Final Batch Loss: 0.0006692501483485103\n",
      "Epoch 1695, Loss: 0.002309850067831576, Final Batch Loss: 0.0005582669982686639\n",
      "Epoch 1696, Loss: 0.0010727279004640877, Final Batch Loss: 0.0004938954953104258\n",
      "Epoch 1697, Loss: 0.0026217023259960115, Final Batch Loss: 0.0008467010338790715\n",
      "Epoch 1698, Loss: 0.013311545830219984, Final Batch Loss: 0.012723807245492935\n",
      "Epoch 1699, Loss: 0.010419991391245276, Final Batch Loss: 0.009726032614707947\n",
      "Epoch 1700, Loss: 0.004269898578058928, Final Batch Loss: 0.0034027851652354\n",
      "Epoch 1701, Loss: 0.0011890567257069051, Final Batch Loss: 0.00012422684812918305\n",
      "Epoch 1702, Loss: 0.005139635875821114, Final Batch Loss: 0.004532686900347471\n",
      "Epoch 1703, Loss: 0.016502222511917353, Final Batch Loss: 0.01524763647466898\n",
      "Epoch 1704, Loss: 0.0020426184055395424, Final Batch Loss: 0.0009408448240719736\n",
      "Epoch 1705, Loss: 0.01989888068055734, Final Batch Loss: 0.0008884169510565698\n",
      "Epoch 1706, Loss: 0.0024663889198563993, Final Batch Loss: 0.0002311786520294845\n",
      "Epoch 1707, Loss: 0.0036756068002432585, Final Batch Loss: 0.0011552984360605478\n",
      "Epoch 1708, Loss: 0.0022919025213923305, Final Batch Loss: 0.002098019467666745\n",
      "Epoch 1709, Loss: 0.0011942519631702453, Final Batch Loss: 0.0007097208290360868\n",
      "Epoch 1710, Loss: 0.003158452542265877, Final Batch Loss: 0.0029568078462034464\n",
      "Epoch 1711, Loss: 0.0013146449346095324, Final Batch Loss: 0.0006218011258170009\n",
      "Epoch 1712, Loss: 0.007353716413490474, Final Batch Loss: 0.001285587321035564\n",
      "Epoch 1713, Loss: 0.004192864405922592, Final Batch Loss: 0.002414183458313346\n",
      "Epoch 1714, Loss: 0.002106045722030103, Final Batch Loss: 0.0017678006552159786\n",
      "Epoch 1715, Loss: 0.00918359705246985, Final Batch Loss: 0.003532912814989686\n",
      "Epoch 1716, Loss: 0.0014411995653063059, Final Batch Loss: 0.0008584604947827756\n",
      "Epoch 1717, Loss: 0.005301788856741041, Final Batch Loss: 0.0009647555998526514\n",
      "Epoch 1718, Loss: 0.0006387637840816751, Final Batch Loss: 0.00042751661385409534\n",
      "Epoch 1719, Loss: 0.005053118278738111, Final Batch Loss: 0.004556642379611731\n",
      "Epoch 1720, Loss: 0.0024807094305288047, Final Batch Loss: 0.0003095871943514794\n",
      "Epoch 1721, Loss: 0.002937618031864986, Final Batch Loss: 0.00041418857290409505\n",
      "Epoch 1722, Loss: 0.0005942548741586506, Final Batch Loss: 0.00026200528373010457\n",
      "Epoch 1723, Loss: 0.002095355375786312, Final Batch Loss: 0.00022349537175614387\n",
      "Epoch 1724, Loss: 0.0020801647333428264, Final Batch Loss: 0.0007227460155263543\n",
      "Epoch 1725, Loss: 0.0038104719715192914, Final Batch Loss: 0.0022617485374212265\n",
      "Epoch 1726, Loss: 0.0005057973539805971, Final Batch Loss: 0.00010154331539524719\n",
      "Epoch 1727, Loss: 0.0011805889080278575, Final Batch Loss: 0.0004269785713404417\n",
      "Epoch 1728, Loss: 0.0007318853749893606, Final Batch Loss: 0.00020393967861309648\n",
      "Epoch 1729, Loss: 0.000392128829844296, Final Batch Loss: 0.0001138492370955646\n",
      "Epoch 1730, Loss: 0.003931938670575619, Final Batch Loss: 0.00282283965498209\n",
      "Epoch 1731, Loss: 0.007293333299458027, Final Batch Loss: 0.006453868933022022\n",
      "Epoch 1732, Loss: 0.00791369695798494, Final Batch Loss: 0.00024608513922430575\n",
      "Epoch 1733, Loss: 0.0018976629944518209, Final Batch Loss: 0.0013039871118962765\n",
      "Epoch 1734, Loss: 0.0020051408355357125, Final Batch Loss: 0.00016260631673503667\n",
      "Epoch 1735, Loss: 0.0009746579744387418, Final Batch Loss: 0.000436263537267223\n",
      "Epoch 1736, Loss: 0.0032447881530970335, Final Batch Loss: 0.0019354212563484907\n",
      "Epoch 1737, Loss: 0.011646873550489545, Final Batch Loss: 0.001285092206671834\n",
      "Epoch 1738, Loss: 0.001955705462023616, Final Batch Loss: 0.0005408489378169179\n",
      "Epoch 1739, Loss: 0.0037004989571869373, Final Batch Loss: 0.0003895084373652935\n",
      "Epoch 1740, Loss: 0.00026217400591121987, Final Batch Loss: 6.212155130924657e-05\n",
      "Epoch 1741, Loss: 0.0008607793715782464, Final Batch Loss: 0.0005922681884840131\n",
      "Epoch 1742, Loss: 0.002038883394561708, Final Batch Loss: 0.001465239329263568\n",
      "Epoch 1743, Loss: 0.0010609861346893013, Final Batch Loss: 0.00034847791539505124\n",
      "Epoch 1744, Loss: 0.0026407953700982034, Final Batch Loss: 0.000650713627692312\n",
      "Epoch 1745, Loss: 0.00043651768646668643, Final Batch Loss: 0.00025910549447871745\n",
      "Epoch 1746, Loss: 0.004488043719902635, Final Batch Loss: 0.0038714678958058357\n",
      "Epoch 1747, Loss: 0.0040009735384956, Final Batch Loss: 0.0029403320513665676\n",
      "Epoch 1748, Loss: 0.003808651468716562, Final Batch Loss: 0.002401400124654174\n",
      "Epoch 1749, Loss: 0.002914638665970415, Final Batch Loss: 0.0025123516097664833\n",
      "Epoch 1750, Loss: 0.0023725280188955367, Final Batch Loss: 0.0018653912702575326\n",
      "Epoch 1751, Loss: 0.03222382999956608, Final Batch Loss: 0.030239541083574295\n",
      "Epoch 1752, Loss: 0.0004685125022660941, Final Batch Loss: 0.00013188557932153344\n",
      "Epoch 1753, Loss: 0.0019804598996415734, Final Batch Loss: 0.0006434280658140779\n",
      "Epoch 1754, Loss: 0.003307498074718751, Final Batch Loss: 0.0001351670507574454\n",
      "Epoch 1755, Loss: 0.00869401206728071, Final Batch Loss: 0.007521247491240501\n",
      "Epoch 1756, Loss: 0.0018926215707324445, Final Batch Loss: 0.0006825177115388215\n",
      "Epoch 1757, Loss: 0.001805294887162745, Final Batch Loss: 0.0008065284928306937\n",
      "Epoch 1758, Loss: 0.0005349921411834657, Final Batch Loss: 0.00028689566534012556\n",
      "Epoch 1759, Loss: 0.000605765832006, Final Batch Loss: 0.00016834501002449542\n",
      "Epoch 1760, Loss: 0.0035325780045241117, Final Batch Loss: 0.0004932032898068428\n",
      "Epoch 1761, Loss: 0.0006155391311040148, Final Batch Loss: 0.0003737721126526594\n",
      "Epoch 1762, Loss: 0.000933660427108407, Final Batch Loss: 0.0006529754027724266\n",
      "Epoch 1763, Loss: 0.0011581631260924041, Final Batch Loss: 0.0009345896542072296\n",
      "Epoch 1764, Loss: 0.001486174762248993, Final Batch Loss: 0.0009188688709400594\n",
      "Epoch 1765, Loss: 0.003134123246127274, Final Batch Loss: 0.0030380673706531525\n",
      "Epoch 1766, Loss: 0.0006552331324201077, Final Batch Loss: 0.00028644289704971015\n",
      "Epoch 1767, Loss: 0.014378590974956751, Final Batch Loss: 0.012960460036993027\n",
      "Epoch 1768, Loss: 0.009428348857909441, Final Batch Loss: 0.002944416832178831\n",
      "Epoch 1769, Loss: 0.0010541189403738827, Final Batch Loss: 0.0004290917713660747\n",
      "Epoch 1770, Loss: 0.0039171099197119474, Final Batch Loss: 0.0006741909310221672\n",
      "Epoch 1771, Loss: 0.002368134359130636, Final Batch Loss: 0.0019864430651068687\n",
      "Epoch 1772, Loss: 0.0008567821350879967, Final Batch Loss: 0.00037530987174250185\n",
      "Epoch 1773, Loss: 0.0026823136722669005, Final Batch Loss: 0.002105554798617959\n",
      "Epoch 1774, Loss: 0.006222874639206566, Final Batch Loss: 0.005980867892503738\n",
      "Epoch 1775, Loss: 0.003698203305248171, Final Batch Loss: 0.003298030234873295\n",
      "Epoch 1776, Loss: 0.004911570460535586, Final Batch Loss: 0.0011198577703908086\n",
      "Epoch 1777, Loss: 0.0005824482213938609, Final Batch Loss: 0.000180430433829315\n",
      "Epoch 1778, Loss: 0.007477220409782603, Final Batch Loss: 0.00039644146454520524\n",
      "Epoch 1779, Loss: 0.0012248583370819688, Final Batch Loss: 0.000669719884172082\n",
      "Epoch 1780, Loss: 0.0009706690034363419, Final Batch Loss: 0.0005084797157905996\n",
      "Epoch 1781, Loss: 0.0034406551203574054, Final Batch Loss: 0.00010079220373881981\n",
      "Epoch 1782, Loss: 0.00043205043039051816, Final Batch Loss: 4.7673027438577265e-05\n",
      "Epoch 1783, Loss: 0.0020558040705509484, Final Batch Loss: 0.0009108819649554789\n",
      "Epoch 1784, Loss: 0.024299410171806812, Final Batch Loss: 0.00909095723181963\n",
      "Epoch 1785, Loss: 0.021016433835029602, Final Batch Loss: 0.015552422031760216\n",
      "Epoch 1786, Loss: 0.0035954021150246263, Final Batch Loss: 0.0030131652019917965\n",
      "Epoch 1787, Loss: 0.0011803986853919923, Final Batch Loss: 0.0002299083862453699\n",
      "Epoch 1788, Loss: 0.001800112622731831, Final Batch Loss: 5.1043192797806114e-05\n",
      "Epoch 1789, Loss: 0.002428743027849123, Final Batch Loss: 0.002269787946715951\n",
      "Epoch 1790, Loss: 0.00043983221985399723, Final Batch Loss: 0.00022461758635472506\n",
      "Epoch 1791, Loss: 0.010238411370664835, Final Batch Loss: 0.00957119558006525\n",
      "Epoch 1792, Loss: 0.005268514796625823, Final Batch Loss: 0.0004724140162579715\n",
      "Epoch 1793, Loss: 0.004590144584653899, Final Batch Loss: 8.173540118150413e-05\n",
      "Epoch 1794, Loss: 0.02300106087932363, Final Batch Loss: 0.022066207602620125\n",
      "Epoch 1795, Loss: 0.004923079191939905, Final Batch Loss: 0.0002688169770408422\n",
      "Epoch 1796, Loss: 0.0022811916714999825, Final Batch Loss: 0.0004834042920265347\n",
      "Epoch 1797, Loss: 0.0004371283866930753, Final Batch Loss: 0.0003186036192346364\n",
      "Epoch 1798, Loss: 0.004104648425709456, Final Batch Loss: 0.0032687352504581213\n",
      "Epoch 1799, Loss: 0.001027231162879616, Final Batch Loss: 0.0006283309194259346\n",
      "Epoch 1800, Loss: 0.004249746882123873, Final Batch Loss: 0.003958437591791153\n",
      "Epoch 1801, Loss: 0.0045818701619282365, Final Batch Loss: 0.0014953167410567403\n",
      "Epoch 1802, Loss: 0.00045665497600566596, Final Batch Loss: 0.00015621287457179278\n",
      "Epoch 1803, Loss: 0.01002797597902827, Final Batch Loss: 9.304771083407104e-05\n",
      "Epoch 1804, Loss: 0.0022432960104197264, Final Batch Loss: 0.0016005291836336255\n",
      "Epoch 1805, Loss: 0.009736663661897182, Final Batch Loss: 0.0017677070572972298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1806, Loss: 0.0023769200779497623, Final Batch Loss: 0.0015244378009811044\n",
      "Epoch 1807, Loss: 0.0022059550101403147, Final Batch Loss: 0.0001559610536787659\n",
      "Epoch 1808, Loss: 0.0036255946761230007, Final Batch Loss: 0.003401970723643899\n",
      "Epoch 1809, Loss: 0.009936814894899726, Final Batch Loss: 0.0031899164896458387\n",
      "Epoch 1810, Loss: 0.008789334679022431, Final Batch Loss: 0.0008479973766952753\n",
      "Epoch 1811, Loss: 0.0034746904857456684, Final Batch Loss: 0.0024655922316014767\n",
      "Epoch 1812, Loss: 0.0005470726973726414, Final Batch Loss: 0.00045749751734547317\n",
      "Epoch 1813, Loss: 0.000818026892375201, Final Batch Loss: 0.0003780617262236774\n",
      "Epoch 1814, Loss: 0.0007928032573545352, Final Batch Loss: 0.00020179538114462048\n",
      "Epoch 1815, Loss: 0.0072117558447644114, Final Batch Loss: 0.000587544753216207\n",
      "Epoch 1816, Loss: 0.0017196600674651563, Final Batch Loss: 0.0011648819781839848\n",
      "Epoch 1817, Loss: 0.0006363302818499506, Final Batch Loss: 0.0003840591525658965\n",
      "Epoch 1818, Loss: 0.0005520477279787883, Final Batch Loss: 0.0001992914912989363\n",
      "Epoch 1819, Loss: 0.001059365109540522, Final Batch Loss: 0.0004971139715053141\n",
      "Epoch 1820, Loss: 0.0008501969277858734, Final Batch Loss: 0.00015929789515212178\n",
      "Epoch 1821, Loss: 0.0034768461191561073, Final Batch Loss: 0.00036800335510633886\n",
      "Epoch 1822, Loss: 0.00450715611805208, Final Batch Loss: 0.00011283953790552914\n",
      "Epoch 1823, Loss: 0.00040268687007483095, Final Batch Loss: 0.000124039375805296\n",
      "Epoch 1824, Loss: 0.0026977874513249844, Final Batch Loss: 0.0003074260603170842\n",
      "Epoch 1825, Loss: 0.0100984384334879, Final Batch Loss: 0.009905776008963585\n",
      "Epoch 1826, Loss: 0.003919931827113032, Final Batch Loss: 0.0031364248134195805\n",
      "Epoch 1827, Loss: 0.0009402671712450683, Final Batch Loss: 0.0006600672495551407\n",
      "Epoch 1828, Loss: 0.011830263654701412, Final Batch Loss: 0.011117026209831238\n",
      "Epoch 1829, Loss: 0.0022780518047511578, Final Batch Loss: 0.0008943151915445924\n",
      "Epoch 1830, Loss: 0.009280155645683408, Final Batch Loss: 0.002382683800533414\n",
      "Epoch 1831, Loss: 0.0008805600191408303, Final Batch Loss: 5.289609180181287e-05\n",
      "Epoch 1832, Loss: 0.0059743384044850245, Final Batch Loss: 0.00013603085244540125\n",
      "Epoch 1833, Loss: 0.009526073539745994, Final Batch Loss: 6.657799531240016e-05\n",
      "Epoch 1834, Loss: 0.0026364579098299146, Final Batch Loss: 0.0010149903828278184\n",
      "Epoch 1835, Loss: 0.009138403052929789, Final Batch Loss: 0.008522571064531803\n",
      "Epoch 1836, Loss: 0.000948497123317793, Final Batch Loss: 0.00039315453614108264\n",
      "Epoch 1837, Loss: 0.0018308512517251074, Final Batch Loss: 0.0011493897764012218\n",
      "Epoch 1838, Loss: 0.002838515501935035, Final Batch Loss: 0.0006328593590296805\n",
      "Epoch 1839, Loss: 0.0008679277671035379, Final Batch Loss: 0.00019437182345427573\n",
      "Epoch 1840, Loss: 0.008612503399490379, Final Batch Loss: 0.0001613126223674044\n",
      "Epoch 1841, Loss: 0.0017174195381812751, Final Batch Loss: 0.0010275281965732574\n",
      "Epoch 1842, Loss: 0.005305210594087839, Final Batch Loss: 0.003672919934615493\n",
      "Epoch 1843, Loss: 0.001979179069167003, Final Batch Loss: 0.00040861297748051584\n",
      "Epoch 1844, Loss: 0.0008904526475816965, Final Batch Loss: 0.000712093897163868\n",
      "Epoch 1845, Loss: 0.021487833000719547, Final Batch Loss: 0.00791847798973322\n",
      "Epoch 1846, Loss: 0.0027062802691943944, Final Batch Loss: 0.0021944036707282066\n",
      "Epoch 1847, Loss: 0.0020250890811439604, Final Batch Loss: 0.0017510701436549425\n",
      "Epoch 1848, Loss: 0.010904637398198247, Final Batch Loss: 0.010621686466038227\n",
      "Epoch 1849, Loss: 0.009314450435340405, Final Batch Loss: 0.0029816492460668087\n",
      "Epoch 1850, Loss: 0.0010359484003856778, Final Batch Loss: 0.0002950753550976515\n",
      "Epoch 1851, Loss: 0.0006941274041309953, Final Batch Loss: 0.0003705131239257753\n",
      "Epoch 1852, Loss: 0.004529989790171385, Final Batch Loss: 0.0020983670838177204\n",
      "Epoch 1853, Loss: 0.026827852241694927, Final Batch Loss: 0.004498357884585857\n",
      "Epoch 1854, Loss: 0.001391251920722425, Final Batch Loss: 0.0008983463631011546\n",
      "Epoch 1855, Loss: 0.012701368192210793, Final Batch Loss: 0.010754665359854698\n",
      "Epoch 1856, Loss: 0.011136751156300306, Final Batch Loss: 0.008597807958722115\n",
      "Epoch 1857, Loss: 0.06774630467407405, Final Batch Loss: 0.0012675083708018064\n",
      "Epoch 1858, Loss: 0.0038244676834437996, Final Batch Loss: 0.0003323689161334187\n",
      "Epoch 1859, Loss: 0.00604512523568701, Final Batch Loss: 0.00020503606356214732\n",
      "Epoch 1860, Loss: 0.012679527746513486, Final Batch Loss: 0.0029741909820586443\n",
      "Epoch 1861, Loss: 0.00022098921908764169, Final Batch Loss: 7.521118823206052e-05\n",
      "Epoch 1862, Loss: 0.0019584365654736757, Final Batch Loss: 0.0005948031321167946\n",
      "Epoch 1863, Loss: 0.001866303791757673, Final Batch Loss: 0.00032755901338532567\n",
      "Epoch 1864, Loss: 0.004010118136648089, Final Batch Loss: 0.0034668331500142813\n",
      "Epoch 1865, Loss: 0.000714178808266297, Final Batch Loss: 0.00040613210876472294\n",
      "Epoch 1866, Loss: 0.0008357582555618137, Final Batch Loss: 0.00040806937613524497\n",
      "Epoch 1867, Loss: 0.0014443187101278454, Final Batch Loss: 0.0010940900538116693\n",
      "Epoch 1868, Loss: 0.023637384234461933, Final Batch Loss: 0.023068128153681755\n",
      "Epoch 1869, Loss: 0.0037225246196612716, Final Batch Loss: 0.0026079327799379826\n",
      "Epoch 1870, Loss: 0.0003932309919036925, Final Batch Loss: 0.00013910591951571405\n",
      "Epoch 1871, Loss: 0.000708712192135863, Final Batch Loss: 0.0004743075114674866\n",
      "Epoch 1872, Loss: 0.06845694078947417, Final Batch Loss: 0.06798078119754791\n",
      "Epoch 1873, Loss: 0.004720238910522312, Final Batch Loss: 0.0009168411488644779\n",
      "Epoch 1874, Loss: 0.0008842691604513675, Final Batch Loss: 0.000458658643765375\n",
      "Epoch 1875, Loss: 0.013127617072314024, Final Batch Loss: 0.008689644746482372\n",
      "Epoch 1876, Loss: 0.0015406656311824918, Final Batch Loss: 0.000842226087115705\n",
      "Epoch 1877, Loss: 0.0010756195988506079, Final Batch Loss: 0.00045276229502633214\n",
      "Epoch 1878, Loss: 0.006952250900212675, Final Batch Loss: 0.0008442253456450999\n",
      "Epoch 1879, Loss: 0.0020318604656495154, Final Batch Loss: 0.0013683257857337594\n",
      "Epoch 1880, Loss: 0.004307842697016895, Final Batch Loss: 0.0006287893047556281\n",
      "Epoch 1881, Loss: 0.014488326152786613, Final Batch Loss: 0.012792523950338364\n",
      "Epoch 1882, Loss: 0.005864713806658983, Final Batch Loss: 0.003695431863889098\n",
      "Epoch 1883, Loss: 0.0008960225968621671, Final Batch Loss: 0.00039855565410107374\n",
      "Epoch 1884, Loss: 0.007377406167506706, Final Batch Loss: 0.0001209392721648328\n",
      "Epoch 1885, Loss: 0.0010893135040532798, Final Batch Loss: 0.0006279803346842527\n",
      "Epoch 1886, Loss: 0.0009321593461208977, Final Batch Loss: 0.00011527338210726157\n",
      "Epoch 1887, Loss: 0.00885495194233954, Final Batch Loss: 0.00757586257532239\n",
      "Epoch 1888, Loss: 0.0012765025239787064, Final Batch Loss: 0.0011673595290631056\n",
      "Epoch 1889, Loss: 0.001370771846268326, Final Batch Loss: 0.0006443114834837615\n",
      "Epoch 1890, Loss: 0.005659039365127683, Final Batch Loss: 0.0022798131685703993\n",
      "Epoch 1891, Loss: 0.00173140229890123, Final Batch Loss: 0.0012832052307203412\n",
      "Epoch 1892, Loss: 0.0007692470971960574, Final Batch Loss: 0.0003775133518502116\n",
      "Epoch 1893, Loss: 0.0005310135675244965, Final Batch Loss: 0.0004263922164682299\n",
      "Epoch 1894, Loss: 0.0024117992143146694, Final Batch Loss: 0.0018527412321418524\n",
      "Epoch 1895, Loss: 0.016918094595894217, Final Batch Loss: 0.013159393332898617\n",
      "Epoch 1896, Loss: 0.003529824360157363, Final Batch Loss: 0.00014605400792788714\n",
      "Epoch 1897, Loss: 0.0015117001021280885, Final Batch Loss: 0.001066331285983324\n",
      "Epoch 1898, Loss: 0.0006366521993186325, Final Batch Loss: 0.0003201687359251082\n",
      "Epoch 1899, Loss: 0.0023306725779548287, Final Batch Loss: 0.0007341449381783605\n",
      "Epoch 1900, Loss: 0.006568948971107602, Final Batch Loss: 0.005533331539481878\n",
      "Epoch 1901, Loss: 0.001915514876600355, Final Batch Loss: 0.0005184851470403373\n",
      "Epoch 1902, Loss: 0.001101844070944935, Final Batch Loss: 0.0006416577380150557\n",
      "Epoch 1903, Loss: 0.01404744281899184, Final Batch Loss: 0.01227827649563551\n",
      "Epoch 1904, Loss: 0.003285145969130099, Final Batch Loss: 0.0022602868266403675\n",
      "Epoch 1905, Loss: 0.001734434044919908, Final Batch Loss: 0.001174060394987464\n",
      "Epoch 1906, Loss: 0.002613862423459068, Final Batch Loss: 0.002241547917947173\n",
      "Epoch 1907, Loss: 0.001157034799689427, Final Batch Loss: 0.0008673992124386132\n",
      "Epoch 1908, Loss: 0.00539881840813905, Final Batch Loss: 0.0003664429532364011\n",
      "Epoch 1909, Loss: 0.0029698843136429787, Final Batch Loss: 0.002335412660613656\n",
      "Epoch 1910, Loss: 0.006019935361109674, Final Batch Loss: 0.0016239405376836658\n",
      "Epoch 1911, Loss: 0.004392476519569755, Final Batch Loss: 0.003653638530522585\n",
      "Epoch 1912, Loss: 0.0017699088712106459, Final Batch Loss: 0.00011948710744036362\n",
      "Epoch 1913, Loss: 0.0006558936147484928, Final Batch Loss: 0.0003815432428382337\n",
      "Epoch 1914, Loss: 0.0011855315242428333, Final Batch Loss: 0.00037316934322007\n",
      "Epoch 1915, Loss: 0.0066941582335857674, Final Batch Loss: 7.54810607759282e-05\n",
      "Epoch 1916, Loss: 0.004685148349381052, Final Batch Loss: 0.00015441163850482553\n",
      "Epoch 1917, Loss: 0.002402312122285366, Final Batch Loss: 0.002157985931262374\n",
      "Epoch 1918, Loss: 0.0011549248010851443, Final Batch Loss: 0.0005193498218432069\n",
      "Epoch 1919, Loss: 0.0010737554548541084, Final Batch Loss: 8.428016735706478e-05\n",
      "Epoch 1920, Loss: 0.0006636706239078194, Final Batch Loss: 0.0003903503529727459\n",
      "Epoch 1921, Loss: 0.0018292234744876623, Final Batch Loss: 0.00110587477684021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1922, Loss: 0.0011011864116881043, Final Batch Loss: 0.001073359395377338\n",
      "Epoch 1923, Loss: 0.0012194315931992605, Final Batch Loss: 0.0009761888650245965\n",
      "Epoch 1924, Loss: 0.0007381751493085176, Final Batch Loss: 0.00012290666927583516\n",
      "Epoch 1925, Loss: 0.010365551919676363, Final Batch Loss: 0.009724169969558716\n",
      "Epoch 1926, Loss: 0.0017735541332513094, Final Batch Loss: 0.0009934359695762396\n",
      "Epoch 1927, Loss: 0.010120597085915506, Final Batch Loss: 0.009136015549302101\n",
      "Epoch 1928, Loss: 0.0013776522246189415, Final Batch Loss: 0.0002546879113651812\n",
      "Epoch 1929, Loss: 0.0009463086571486201, Final Batch Loss: 3.7586312828352675e-05\n",
      "Epoch 1930, Loss: 0.0006437439005821943, Final Batch Loss: 0.00026747278752736747\n",
      "Epoch 1931, Loss: 0.003972885351686273, Final Batch Loss: 0.00011486947914818302\n",
      "Epoch 1932, Loss: 0.003559551783837378, Final Batch Loss: 0.00108062953222543\n",
      "Epoch 1933, Loss: 0.0003820732090389356, Final Batch Loss: 0.00018699138308875263\n",
      "Epoch 1934, Loss: 0.0006476465059677139, Final Batch Loss: 0.00023102825798559934\n",
      "Epoch 1935, Loss: 0.002658496145159006, Final Batch Loss: 0.0006718076765537262\n",
      "Epoch 1936, Loss: 0.006097679026424885, Final Batch Loss: 0.0014526676386594772\n",
      "Epoch 1937, Loss: 0.0007907092658570036, Final Batch Loss: 0.000704130856320262\n",
      "Epoch 1938, Loss: 0.0010773822432383895, Final Batch Loss: 0.0005232788971625268\n",
      "Epoch 1939, Loss: 0.002138718293281272, Final Batch Loss: 0.00022410930250771344\n",
      "Epoch 1940, Loss: 0.005894303089007735, Final Batch Loss: 0.0029718782752752304\n",
      "Epoch 1941, Loss: 0.00037124597292859107, Final Batch Loss: 0.00018610480765346438\n",
      "Epoch 1942, Loss: 0.0022245057916734368, Final Batch Loss: 0.00021238918998278677\n",
      "Epoch 1943, Loss: 0.0034881344763562083, Final Batch Loss: 0.0005549500929191709\n",
      "Epoch 1944, Loss: 0.0003822165308520198, Final Batch Loss: 0.00017905858112499118\n",
      "Epoch 1945, Loss: 0.0018585718353278935, Final Batch Loss: 0.0006993755814619362\n",
      "Epoch 1946, Loss: 0.007870703906519338, Final Batch Loss: 0.0001969891309272498\n",
      "Epoch 1947, Loss: 0.0004435662121977657, Final Batch Loss: 0.00021988232037983835\n",
      "Epoch 1948, Loss: 0.0008829958387650549, Final Batch Loss: 0.00032256520353257656\n",
      "Epoch 1949, Loss: 0.0009003414597827941, Final Batch Loss: 0.0004307715280447155\n",
      "Epoch 1950, Loss: 0.0014498529344564304, Final Batch Loss: 0.0002434383932268247\n",
      "Epoch 1951, Loss: 0.005009925880585797, Final Batch Loss: 0.004855082370340824\n",
      "Epoch 1952, Loss: 0.0058962590410374105, Final Batch Loss: 0.0008279834291897714\n",
      "Epoch 1953, Loss: 0.00603629054967314, Final Batch Loss: 0.005669077858328819\n",
      "Epoch 1954, Loss: 0.0010624226997606456, Final Batch Loss: 0.0004712871159426868\n",
      "Epoch 1955, Loss: 0.0007003082428127527, Final Batch Loss: 0.00042528589256107807\n",
      "Epoch 1956, Loss: 0.001677446998655796, Final Batch Loss: 0.0004978813230991364\n",
      "Epoch 1957, Loss: 0.0047947742423275486, Final Batch Loss: 0.004575112368911505\n",
      "Epoch 1958, Loss: 0.00842476193793118, Final Batch Loss: 0.0023233613464981318\n",
      "Epoch 1959, Loss: 0.005294042290188372, Final Batch Loss: 0.0009654263267293572\n",
      "Epoch 1960, Loss: 0.0012043153983540833, Final Batch Loss: 0.00013908912660554051\n",
      "Epoch 1961, Loss: 0.0017476892098784447, Final Batch Loss: 0.001408380689099431\n",
      "Epoch 1962, Loss: 0.0003737668303074315, Final Batch Loss: 0.00020303930796217173\n",
      "Epoch 1963, Loss: 0.0016825924394652247, Final Batch Loss: 0.001154811354354024\n",
      "Epoch 1964, Loss: 0.001825302984798327, Final Batch Loss: 0.00021363041014410555\n",
      "Epoch 1965, Loss: 0.0024771433672867715, Final Batch Loss: 0.00027002644492313266\n",
      "Epoch 1966, Loss: 0.0005202174070291221, Final Batch Loss: 0.00025630072923377156\n",
      "Epoch 1967, Loss: 0.005075640045106411, Final Batch Loss: 0.0025351280346512794\n",
      "Epoch 1968, Loss: 0.007160225977713708, Final Batch Loss: 0.0070669339038431644\n",
      "Epoch 1969, Loss: 0.0012180190969957039, Final Batch Loss: 0.0010437264572829008\n",
      "Epoch 1970, Loss: 0.0027043819427490234, Final Batch Loss: 0.001829173299483955\n",
      "Epoch 1971, Loss: 0.0008600364380981773, Final Batch Loss: 0.00028232744080014527\n",
      "Epoch 1972, Loss: 0.0006676886841887608, Final Batch Loss: 9.830955241341144e-05\n",
      "Epoch 1973, Loss: 0.0011710690705513116, Final Batch Loss: 4.582941983244382e-05\n",
      "Epoch 1974, Loss: 0.0017792211147025228, Final Batch Loss: 0.0011065573198720813\n",
      "Epoch 1975, Loss: 0.0005846091662533581, Final Batch Loss: 0.00011643319157883525\n",
      "Epoch 1976, Loss: 0.0008305607334477827, Final Batch Loss: 0.00018192331481259316\n",
      "Epoch 1977, Loss: 0.002549544849898666, Final Batch Loss: 0.0008257743320427835\n",
      "Epoch 1978, Loss: 0.0023350937699433416, Final Batch Loss: 0.0020476628560572863\n",
      "Epoch 1979, Loss: 0.00018182096391683444, Final Batch Loss: 6.927725917194039e-05\n",
      "Epoch 1980, Loss: 0.00383165996754542, Final Batch Loss: 0.0008476428338326514\n",
      "Epoch 1981, Loss: 0.00027251511346548796, Final Batch Loss: 0.00014068238670006394\n",
      "Epoch 1982, Loss: 0.0010056494502350688, Final Batch Loss: 0.00013478542678058147\n",
      "Epoch 1983, Loss: 0.00679905476863496, Final Batch Loss: 0.00036906308378092945\n",
      "Epoch 1984, Loss: 0.002171561456634663, Final Batch Loss: 0.0019890705589205027\n",
      "Epoch 1985, Loss: 0.0025673302297946066, Final Batch Loss: 0.00019319294369779527\n",
      "Epoch 1986, Loss: 0.0009907470412144903, Final Batch Loss: 5.210444578551687e-05\n",
      "Epoch 1987, Loss: 0.0017156693938886747, Final Batch Loss: 0.001559155760332942\n",
      "Epoch 1988, Loss: 0.0036295100580900908, Final Batch Loss: 0.0028969505801796913\n",
      "Epoch 1989, Loss: 0.0011575983662623912, Final Batch Loss: 0.0003909346123691648\n",
      "Epoch 1990, Loss: 0.0014842886594124138, Final Batch Loss: 0.00020603503799065948\n",
      "Epoch 1991, Loss: 0.0007295689138118178, Final Batch Loss: 0.00039810669841244817\n",
      "Epoch 1992, Loss: 0.00282429889193736, Final Batch Loss: 0.0002765065000858158\n",
      "Epoch 1993, Loss: 0.006048038336302852, Final Batch Loss: 4.993073162040673e-05\n",
      "Epoch 1994, Loss: 0.00045538292033597827, Final Batch Loss: 0.000312495423713699\n",
      "Epoch 1995, Loss: 0.0019963811500929296, Final Batch Loss: 0.000260534870903939\n",
      "Epoch 1996, Loss: 0.0006832084618508816, Final Batch Loss: 0.00042972518713213503\n",
      "Epoch 1997, Loss: 0.0011264695785939693, Final Batch Loss: 0.0005409402074292302\n",
      "Epoch 1998, Loss: 0.0008908329618861899, Final Batch Loss: 0.00013958707859274\n",
      "Epoch 1999, Loss: 0.0010208237654296681, Final Batch Loss: 0.00017014930199366063\n",
      "Epoch 2000, Loss: 0.0005701920599676669, Final Batch Loss: 0.0003877722774632275\n",
      "Epoch 2001, Loss: 0.0008083109860308468, Final Batch Loss: 0.00044871403952129185\n",
      "Epoch 2002, Loss: 0.0009854020026978105, Final Batch Loss: 0.0006401905557140708\n",
      "Epoch 2003, Loss: 0.001710283919237554, Final Batch Loss: 0.0006817335961386561\n",
      "Epoch 2004, Loss: 0.001837492745835334, Final Batch Loss: 0.0007369659724645317\n",
      "Epoch 2005, Loss: 0.0040832254162523896, Final Batch Loss: 0.0002569767239037901\n",
      "Epoch 2006, Loss: 0.016383227426558733, Final Batch Loss: 0.010240092873573303\n",
      "Epoch 2007, Loss: 0.0007190245669335127, Final Batch Loss: 0.0003213593445252627\n",
      "Epoch 2008, Loss: 0.0012770810280926526, Final Batch Loss: 0.0004902486689388752\n",
      "Epoch 2009, Loss: 0.003386768643395044, Final Batch Loss: 7.620769611094147e-05\n",
      "Epoch 2010, Loss: 0.0006064645858714357, Final Batch Loss: 0.0005237226723693311\n",
      "Epoch 2011, Loss: 0.0022022610646672547, Final Batch Loss: 0.0016953378217294812\n",
      "Epoch 2012, Loss: 0.001477097554015927, Final Batch Loss: 0.0012408215552568436\n",
      "Epoch 2013, Loss: 0.000714340596459806, Final Batch Loss: 0.00031979326740838587\n",
      "Epoch 2014, Loss: 0.0006722858088323846, Final Batch Loss: 0.0005347664700821042\n",
      "Epoch 2015, Loss: 0.0002877554143196903, Final Batch Loss: 0.0001901056821225211\n",
      "Epoch 2016, Loss: 0.008383255364606157, Final Batch Loss: 0.00046617529005743563\n",
      "Epoch 2017, Loss: 0.004774279324919917, Final Batch Loss: 0.004540010821074247\n",
      "Epoch 2018, Loss: 0.0015136956935748458, Final Batch Loss: 0.0008438864606432617\n",
      "Epoch 2019, Loss: 0.0020891173044219613, Final Batch Loss: 0.0012534874258562922\n",
      "Epoch 2020, Loss: 0.001574561232700944, Final Batch Loss: 0.0007989241275936365\n",
      "Epoch 2021, Loss: 0.005154345975824981, Final Batch Loss: 2.703987956920173e-05\n",
      "Epoch 2022, Loss: 0.0016732979856897146, Final Batch Loss: 0.0012276797788217664\n",
      "Epoch 2023, Loss: 0.006857156578917056, Final Batch Loss: 0.006157785188406706\n",
      "Epoch 2024, Loss: 0.003799757396336645, Final Batch Loss: 0.003602013224735856\n",
      "Epoch 2025, Loss: 0.005187872389797121, Final Batch Loss: 0.0002598739811219275\n",
      "Epoch 2026, Loss: 0.027506226673722267, Final Batch Loss: 0.0004105661064386368\n",
      "Epoch 2027, Loss: 0.0009113269916269928, Final Batch Loss: 0.0005087453755550086\n",
      "Epoch 2028, Loss: 0.000865919268107973, Final Batch Loss: 0.0007964963442645967\n",
      "Epoch 2029, Loss: 0.0002504286949260859, Final Batch Loss: 1.1961541531491093e-05\n",
      "Epoch 2030, Loss: 0.0008370165596716106, Final Batch Loss: 0.00035663580638356507\n",
      "Epoch 2031, Loss: 0.02615465340204537, Final Batch Loss: 0.0030998021829873323\n",
      "Epoch 2032, Loss: 0.005526824781554751, Final Batch Loss: 7.29331950424239e-05\n",
      "Epoch 2033, Loss: 0.0015692829620093107, Final Batch Loss: 0.0005202631000429392\n",
      "Epoch 2034, Loss: 0.00013585561100626364, Final Batch Loss: 2.010958269238472e-05\n",
      "Epoch 2035, Loss: 0.006865689021651633, Final Batch Loss: 0.000163886186783202\n",
      "Epoch 2036, Loss: 0.0008532620122423396, Final Batch Loss: 0.00014218657452147454\n",
      "Epoch 2037, Loss: 0.00969254004303366, Final Batch Loss: 0.008377192541956902\n",
      "Epoch 2038, Loss: 0.0056415555300191045, Final Batch Loss: 0.0019278955878689885\n",
      "Epoch 2039, Loss: 0.001919821836054325, Final Batch Loss: 0.0012503606267273426\n",
      "Epoch 2040, Loss: 0.029128726018825546, Final Batch Loss: 0.00024885256425477564\n",
      "Epoch 2041, Loss: 0.007726851967163384, Final Batch Loss: 0.0009031976805999875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2042, Loss: 0.000708431180100888, Final Batch Loss: 0.0004184070567134768\n",
      "Epoch 2043, Loss: 0.0007932451990200207, Final Batch Loss: 0.000549602322280407\n",
      "Epoch 2044, Loss: 0.0014416060876101255, Final Batch Loss: 0.00044562516268342733\n",
      "Epoch 2045, Loss: 0.0010012451384682208, Final Batch Loss: 0.0005201061721891165\n",
      "Epoch 2046, Loss: 0.0004030148120364174, Final Batch Loss: 0.00029032945167273283\n",
      "Epoch 2047, Loss: 0.0013904816005378962, Final Batch Loss: 0.0007720270077697933\n",
      "Epoch 2048, Loss: 0.019433530513197184, Final Batch Loss: 0.0033527598716318607\n",
      "Epoch 2049, Loss: 0.001274901325814426, Final Batch Loss: 0.0008198379073292017\n",
      "Epoch 2050, Loss: 0.0027075528632849455, Final Batch Loss: 0.0012341119581833482\n",
      "Epoch 2051, Loss: 0.022362166782841086, Final Batch Loss: 0.0021006313618272543\n",
      "Epoch 2052, Loss: 0.0005546288848563563, Final Batch Loss: 4.501912553678267e-05\n",
      "Epoch 2053, Loss: 0.00416359829614521, Final Batch Loss: 0.004137961659580469\n",
      "Epoch 2054, Loss: 0.0011038376251235604, Final Batch Loss: 0.00032627879409119487\n",
      "Epoch 2055, Loss: 0.0003412272271816619, Final Batch Loss: 0.0002505251031834632\n",
      "Epoch 2056, Loss: 0.002523147384636104, Final Batch Loss: 0.001022272277623415\n",
      "Epoch 2057, Loss: 0.0005988957709632814, Final Batch Loss: 0.0002463637210894376\n",
      "Epoch 2058, Loss: 0.0011180471337866038, Final Batch Loss: 0.0007270713103935122\n",
      "Epoch 2059, Loss: 0.002193573527620174, Final Batch Loss: 9.477291314397007e-05\n",
      "Epoch 2060, Loss: 0.002354571595788002, Final Batch Loss: 0.0005245354259386659\n",
      "Epoch 2061, Loss: 0.029626269766595215, Final Batch Loss: 0.0008451053290627897\n",
      "Epoch 2062, Loss: 0.0026451776502653956, Final Batch Loss: 0.001969881122931838\n",
      "Epoch 2063, Loss: 0.009635463444283232, Final Batch Loss: 0.009176933206617832\n",
      "Epoch 2064, Loss: 0.0020236896816641092, Final Batch Loss: 0.0004918832564726472\n",
      "Epoch 2065, Loss: 0.00269382749684155, Final Batch Loss: 0.0005048373714089394\n",
      "Epoch 2066, Loss: 0.015003308071754873, Final Batch Loss: 0.013178790919482708\n",
      "Epoch 2067, Loss: 0.001569000247400254, Final Batch Loss: 0.0006762722041457891\n",
      "Epoch 2068, Loss: 0.002253224854939617, Final Batch Loss: 0.0001230517082149163\n",
      "Epoch 2069, Loss: 0.008997021708637476, Final Batch Loss: 0.0045167519710958\n",
      "Epoch 2070, Loss: 0.059303253390680766, Final Batch Loss: 5.8128931414103135e-05\n",
      "Epoch 2071, Loss: 0.006046585040166974, Final Batch Loss: 0.0011256232392042875\n",
      "Epoch 2072, Loss: 0.003413797283428721, Final Batch Loss: 0.00023494607012253255\n",
      "Epoch 2073, Loss: 0.001633009291253984, Final Batch Loss: 0.0008066809386946261\n",
      "Epoch 2074, Loss: 0.005105973104946315, Final Batch Loss: 0.0019303389126434922\n",
      "Epoch 2075, Loss: 0.004858118569245562, Final Batch Loss: 0.00029335179715417325\n",
      "Epoch 2076, Loss: 0.00514660426415503, Final Batch Loss: 0.0027385433204472065\n",
      "Epoch 2077, Loss: 0.007734085578704253, Final Batch Loss: 0.007578068878501654\n",
      "Epoch 2078, Loss: 0.0015184784424491227, Final Batch Loss: 0.0011920926626771688\n",
      "Epoch 2079, Loss: 0.0009014242386911064, Final Batch Loss: 0.0005310146370902658\n",
      "Epoch 2080, Loss: 0.006202165503054857, Final Batch Loss: 0.001851691398769617\n",
      "Epoch 2081, Loss: 0.05830843670992181, Final Batch Loss: 0.0007172517362050712\n",
      "Epoch 2082, Loss: 0.004067069530719891, Final Batch Loss: 0.00048709908151067793\n",
      "Epoch 2083, Loss: 0.008644221408758312, Final Batch Loss: 0.008201711811125278\n",
      "Epoch 2084, Loss: 0.01154161063459469, Final Batch Loss: 9.679706272436306e-05\n",
      "Epoch 2085, Loss: 0.0010577513603493571, Final Batch Loss: 0.0007861245539970696\n",
      "Epoch 2086, Loss: 0.009268468129448593, Final Batch Loss: 0.008568862453103065\n",
      "Epoch 2087, Loss: 0.04974993130599614, Final Batch Loss: 0.00020184552704449743\n",
      "Epoch 2088, Loss: 0.0017236194835277274, Final Batch Loss: 0.00013634546485263854\n",
      "Epoch 2089, Loss: 0.010883383896725718, Final Batch Loss: 0.00011606000043684617\n",
      "Epoch 2090, Loss: 0.03774111543316394, Final Batch Loss: 0.036670710891485214\n",
      "Epoch 2091, Loss: 0.004919824423268437, Final Batch Loss: 0.00042388890869915485\n",
      "Epoch 2092, Loss: 0.012795269023627043, Final Batch Loss: 0.005642865784466267\n",
      "Epoch 2093, Loss: 0.009817767655476928, Final Batch Loss: 0.0026194320525974035\n",
      "Epoch 2094, Loss: 0.0008416233031312004, Final Batch Loss: 0.0006130422698333859\n",
      "Epoch 2095, Loss: 0.009359716670587659, Final Batch Loss: 0.002998873358592391\n",
      "Epoch 2096, Loss: 0.03239713015500456, Final Batch Loss: 0.03178081661462784\n",
      "Epoch 2097, Loss: 0.0037021329626441, Final Batch Loss: 0.0026858963537961245\n",
      "Epoch 2098, Loss: 0.006620367988944054, Final Batch Loss: 0.0006790976040065289\n",
      "Epoch 2099, Loss: 0.007587025756947696, Final Batch Loss: 0.0014133810764178634\n",
      "Epoch 2100, Loss: 0.0038305841153487563, Final Batch Loss: 0.002979745389893651\n",
      "Epoch 2101, Loss: 0.0008814571920083836, Final Batch Loss: 0.00020742540073115379\n",
      "Epoch 2102, Loss: 0.00030625534418504685, Final Batch Loss: 0.00016580719966441393\n",
      "Epoch 2103, Loss: 0.005882979836314917, Final Batch Loss: 0.003953279461711645\n",
      "Epoch 2104, Loss: 0.001720272091915831, Final Batch Loss: 0.00018646111129783094\n",
      "Epoch 2105, Loss: 0.0013950603461125866, Final Batch Loss: 0.0001317007845500484\n",
      "Epoch 2106, Loss: 0.0013660625118063763, Final Batch Loss: 0.0011693901615217328\n",
      "Epoch 2107, Loss: 0.006127814791398123, Final Batch Loss: 0.005790858529508114\n",
      "Epoch 2108, Loss: 0.0008300846966449171, Final Batch Loss: 0.00040330522460862994\n",
      "Epoch 2109, Loss: 0.005986508214846253, Final Batch Loss: 0.004432240035384893\n",
      "Epoch 2110, Loss: 0.003507514949887991, Final Batch Loss: 0.0009528673253953457\n",
      "Epoch 2111, Loss: 0.0012518701259978116, Final Batch Loss: 0.0008204263867810369\n",
      "Epoch 2112, Loss: 0.0021660003112629056, Final Batch Loss: 0.0011742584174498916\n",
      "Epoch 2113, Loss: 0.001167262380477041, Final Batch Loss: 0.00035151030169799924\n",
      "Epoch 2114, Loss: 0.018849552609026432, Final Batch Loss: 0.0006241248920559883\n",
      "Epoch 2115, Loss: 0.0033873075735755265, Final Batch Loss: 0.000389394408557564\n",
      "Epoch 2116, Loss: 0.005034543813962955, Final Batch Loss: 8.94914919626899e-05\n",
      "Epoch 2117, Loss: 0.005863118218258023, Final Batch Loss: 0.003562940051779151\n",
      "Epoch 2118, Loss: 0.0024046493199421093, Final Batch Loss: 0.0001286270999116823\n",
      "Epoch 2119, Loss: 0.002224149473477155, Final Batch Loss: 0.0008102754945866764\n",
      "Epoch 2120, Loss: 0.0013198069063946605, Final Batch Loss: 0.0005805894616059959\n",
      "Epoch 2121, Loss: 0.00825184106361121, Final Batch Loss: 0.0003609823761507869\n",
      "Epoch 2122, Loss: 0.005234677577391267, Final Batch Loss: 0.004530656151473522\n",
      "Epoch 2123, Loss: 0.0025305694434791803, Final Batch Loss: 0.0010239314287900925\n",
      "Epoch 2124, Loss: 0.004559270455501974, Final Batch Loss: 0.004197945352643728\n",
      "Epoch 2125, Loss: 0.0010313797974959016, Final Batch Loss: 0.0005031064501963556\n",
      "Epoch 2126, Loss: 0.000671140180202201, Final Batch Loss: 0.00023631853400729597\n",
      "Epoch 2127, Loss: 0.0020132913487032056, Final Batch Loss: 0.0014367575058713555\n",
      "Epoch 2128, Loss: 0.0005804620450362563, Final Batch Loss: 0.00027545460034161806\n",
      "Epoch 2129, Loss: 0.006280124187469482, Final Batch Loss: 0.00019094999879598618\n",
      "Epoch 2130, Loss: 0.0008848336728988215, Final Batch Loss: 0.00018316488421987742\n",
      "Epoch 2131, Loss: 0.002774506341665983, Final Batch Loss: 0.00030225026421248913\n",
      "Epoch 2132, Loss: 0.001322347015957348, Final Batch Loss: 0.00012669099669437855\n",
      "Epoch 2133, Loss: 0.002011926204431802, Final Batch Loss: 0.0009582050261087716\n",
      "Epoch 2134, Loss: 0.001419645850546658, Final Batch Loss: 0.000997290015220642\n",
      "Epoch 2135, Loss: 0.001528579945443198, Final Batch Loss: 0.0011151516810059547\n",
      "Epoch 2136, Loss: 0.0011169998324476182, Final Batch Loss: 0.0008349844720214605\n",
      "Epoch 2137, Loss: 0.014437104866374284, Final Batch Loss: 0.0006140715559013188\n",
      "Epoch 2138, Loss: 0.0019005663780262694, Final Batch Loss: 0.0017771116690710187\n",
      "Epoch 2139, Loss: 0.0036258746404200792, Final Batch Loss: 0.00028871605172753334\n",
      "Epoch 2140, Loss: 0.0034930596593767405, Final Batch Loss: 0.0012584675569087267\n",
      "Epoch 2141, Loss: 0.006819465837907046, Final Batch Loss: 0.006103772670030594\n",
      "Epoch 2142, Loss: 0.0004239453555783257, Final Batch Loss: 0.00012915425759274513\n",
      "Epoch 2143, Loss: 0.003977244487032294, Final Batch Loss: 0.0005087314639240503\n",
      "Epoch 2144, Loss: 0.0005525068991119042, Final Batch Loss: 0.00034460166352801025\n",
      "Epoch 2145, Loss: 0.0016103977977763861, Final Batch Loss: 0.00022302320576272905\n",
      "Epoch 2146, Loss: 0.004237598041072488, Final Batch Loss: 0.0006432624068111181\n",
      "Epoch 2147, Loss: 0.0005240386526565999, Final Batch Loss: 0.0003435419057495892\n",
      "Epoch 2148, Loss: 0.0021188246610108763, Final Batch Loss: 0.00042614343692548573\n",
      "Epoch 2149, Loss: 0.004685475229052827, Final Batch Loss: 0.00014568280312232673\n",
      "Epoch 2150, Loss: 0.0006767874583601952, Final Batch Loss: 0.00020930817117914557\n",
      "Epoch 2151, Loss: 0.0005715721054002643, Final Batch Loss: 0.00023979166871868074\n",
      "Epoch 2152, Loss: 0.00043617420305963606, Final Batch Loss: 5.522301944438368e-05\n",
      "Epoch 2153, Loss: 0.004982044803909957, Final Batch Loss: 0.0008202808676287532\n",
      "Epoch 2154, Loss: 0.0006295319690252654, Final Batch Loss: 6.561591726494953e-05\n",
      "Epoch 2155, Loss: 0.0009916253911796957, Final Batch Loss: 0.0008282154449261725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2156, Loss: 0.0004146068968111649, Final Batch Loss: 0.0001447530376026407\n",
      "Epoch 2157, Loss: 0.0013028656612732448, Final Batch Loss: 0.00012108122609788552\n",
      "Epoch 2158, Loss: 0.0009998998139053583, Final Batch Loss: 0.0003465517074801028\n",
      "Epoch 2159, Loss: 0.0011283588246442378, Final Batch Loss: 0.00040637567872181535\n",
      "Epoch 2160, Loss: 0.0015813852405699436, Final Batch Loss: 0.001540013705380261\n",
      "Epoch 2161, Loss: 0.00020785000015166588, Final Batch Loss: 0.0001492826413596049\n",
      "Epoch 2162, Loss: 0.001094886156352004, Final Batch Loss: 5.614413748844527e-05\n",
      "Epoch 2163, Loss: 0.0006232732848729938, Final Batch Loss: 0.00029063640977256\n",
      "Epoch 2164, Loss: 0.00042030731856357306, Final Batch Loss: 9.939090523403138e-05\n",
      "Epoch 2165, Loss: 0.0008851892489474267, Final Batch Loss: 0.0002714527945499867\n",
      "Epoch 2166, Loss: 0.0003621308278525248, Final Batch Loss: 0.000199628368136473\n",
      "Epoch 2167, Loss: 0.0047642851786804385, Final Batch Loss: 9.799400140764192e-05\n",
      "Epoch 2168, Loss: 0.008176899165846407, Final Batch Loss: 0.007412808481603861\n",
      "Epoch 2169, Loss: 0.0006400290585588664, Final Batch Loss: 0.00032251645461656153\n",
      "Epoch 2170, Loss: 0.0014219244476407766, Final Batch Loss: 0.0009818697581067681\n",
      "Epoch 2171, Loss: 0.0013399335439316928, Final Batch Loss: 0.000759115326218307\n",
      "Epoch 2172, Loss: 0.0016441356274299324, Final Batch Loss: 0.001484601991251111\n",
      "Epoch 2173, Loss: 0.0011008547007804736, Final Batch Loss: 0.00017995275266002864\n",
      "Epoch 2174, Loss: 0.0016360005247406662, Final Batch Loss: 0.0005237716832198203\n",
      "Epoch 2175, Loss: 0.00147819152334705, Final Batch Loss: 0.0008555212407372892\n",
      "Epoch 2176, Loss: 0.00481260969536379, Final Batch Loss: 0.004622995387762785\n",
      "Epoch 2177, Loss: 0.0025636487698648125, Final Batch Loss: 0.00014017164357937872\n",
      "Epoch 2178, Loss: 0.00034510230034356937, Final Batch Loss: 9.307407162850723e-05\n",
      "Epoch 2179, Loss: 0.0008765235834289342, Final Batch Loss: 0.0005438398802652955\n",
      "Epoch 2180, Loss: 0.005983516573905945, Final Batch Loss: 0.0018063127063214779\n",
      "Epoch 2181, Loss: 0.0005860637611476704, Final Batch Loss: 0.00020984896400477737\n",
      "Epoch 2182, Loss: 0.0057822325034067035, Final Batch Loss: 0.003964022267609835\n",
      "Epoch 2183, Loss: 0.0011408101418055594, Final Batch Loss: 0.0007804877241142094\n",
      "Epoch 2184, Loss: 0.0004051894211443141, Final Batch Loss: 0.00020132183271925896\n",
      "Epoch 2185, Loss: 0.0027446096064522862, Final Batch Loss: 0.00199502008035779\n",
      "Epoch 2186, Loss: 0.002970050205476582, Final Batch Loss: 0.0005701935151591897\n",
      "Epoch 2187, Loss: 0.007214055251097307, Final Batch Loss: 0.006779784336686134\n",
      "Epoch 2188, Loss: 0.0008046583097893745, Final Batch Loss: 0.00027363040135242045\n",
      "Epoch 2189, Loss: 0.0010529413120821118, Final Batch Loss: 0.0003955174470320344\n",
      "Epoch 2190, Loss: 0.0009570563124725595, Final Batch Loss: 8.526771853212267e-05\n",
      "Epoch 2191, Loss: 0.0007278731936821714, Final Batch Loss: 0.00017302676860708743\n",
      "Epoch 2192, Loss: 0.0030658108298666775, Final Batch Loss: 0.0008961244602687657\n",
      "Epoch 2193, Loss: 0.0012084566988050938, Final Batch Loss: 0.0006483452743850648\n",
      "Epoch 2194, Loss: 0.0021773133194074035, Final Batch Loss: 0.0013963333331048489\n",
      "Epoch 2195, Loss: 0.0012036912376061082, Final Batch Loss: 0.0005767868715338409\n",
      "Epoch 2196, Loss: 0.004778268281370401, Final Batch Loss: 0.0031178216449916363\n",
      "Epoch 2197, Loss: 0.0006091752438805997, Final Batch Loss: 0.0003343010030221194\n",
      "Epoch 2198, Loss: 0.0005268193344818428, Final Batch Loss: 0.00042355983168818057\n",
      "Epoch 2199, Loss: 0.01694085606141016, Final Batch Loss: 0.00035008572740480304\n",
      "Epoch 2200, Loss: 0.00039173191180452704, Final Batch Loss: 0.0002669516543392092\n",
      "Epoch 2201, Loss: 0.01889039680827409, Final Batch Loss: 0.01717762090265751\n",
      "Epoch 2202, Loss: 0.0015307282446883619, Final Batch Loss: 0.0013093119487166405\n",
      "Epoch 2203, Loss: 0.0011171379883307964, Final Batch Loss: 0.0008945310255512595\n",
      "Epoch 2204, Loss: 0.009962594514945522, Final Batch Loss: 0.00039326996193267405\n",
      "Epoch 2205, Loss: 0.0005507777896127664, Final Batch Loss: 0.0004500665236264467\n",
      "Epoch 2206, Loss: 0.0006016837432980537, Final Batch Loss: 0.00040468198130838573\n",
      "Epoch 2207, Loss: 0.01339948846725747, Final Batch Loss: 0.013019219040870667\n",
      "Epoch 2208, Loss: 0.0009813574724830687, Final Batch Loss: 0.0003966425429098308\n",
      "Epoch 2209, Loss: 0.0013221201079431921, Final Batch Loss: 0.0011158384149894118\n",
      "Epoch 2210, Loss: 0.0009428074845345691, Final Batch Loss: 0.0001280761935049668\n",
      "Epoch 2211, Loss: 0.0007844168867450207, Final Batch Loss: 0.0001876948808785528\n",
      "Epoch 2212, Loss: 0.002016687474679202, Final Batch Loss: 0.0013082192745059729\n",
      "Epoch 2213, Loss: 0.0010104325483553112, Final Batch Loss: 0.0003661699593067169\n",
      "Epoch 2214, Loss: 0.003841565689072013, Final Batch Loss: 0.0017682998441159725\n",
      "Epoch 2215, Loss: 0.0006760758260497823, Final Batch Loss: 0.00016709069313947111\n",
      "Epoch 2216, Loss: 0.005510889110155404, Final Batch Loss: 0.0043474119156599045\n",
      "Epoch 2217, Loss: 0.002549365919549018, Final Batch Loss: 0.0017638617428019643\n",
      "Epoch 2218, Loss: 0.0012590565311256796, Final Batch Loss: 0.0004129928711336106\n",
      "Epoch 2219, Loss: 0.0009519571322016418, Final Batch Loss: 0.00048134662210941315\n",
      "Epoch 2220, Loss: 0.0008427381835645065, Final Batch Loss: 0.00020720255270134658\n",
      "Epoch 2221, Loss: 0.005351670493837446, Final Batch Loss: 0.0004646065062843263\n",
      "Epoch 2222, Loss: 0.0015591933479299769, Final Batch Loss: 0.00014475324132945389\n",
      "Epoch 2223, Loss: 0.00021979764278512448, Final Batch Loss: 0.00013281026622280478\n",
      "Epoch 2224, Loss: 0.00023664838954573497, Final Batch Loss: 9.760706598171964e-05\n",
      "Epoch 2225, Loss: 0.0005992619699100032, Final Batch Loss: 9.239099745173007e-05\n",
      "Epoch 2226, Loss: 0.013845363107975572, Final Batch Loss: 0.013014736585319042\n",
      "Epoch 2227, Loss: 0.0011348473490215838, Final Batch Loss: 0.00025692686904221773\n",
      "Epoch 2228, Loss: 0.00810999923851341, Final Batch Loss: 0.00725804315879941\n",
      "Epoch 2229, Loss: 0.0008821599185466766, Final Batch Loss: 0.000564752088394016\n",
      "Epoch 2230, Loss: 0.0012399722181726247, Final Batch Loss: 0.000244624592596665\n",
      "Epoch 2231, Loss: 0.007389052072539926, Final Batch Loss: 0.004032745957374573\n",
      "Epoch 2232, Loss: 0.0008408052381128073, Final Batch Loss: 0.0001927264383994043\n",
      "Epoch 2233, Loss: 0.0019424542697379366, Final Batch Loss: 0.0001225085143232718\n",
      "Epoch 2234, Loss: 0.0014653519028797746, Final Batch Loss: 0.0005126961041241884\n",
      "Epoch 2235, Loss: 0.0020773661672137678, Final Batch Loss: 0.0014353998703882098\n",
      "Epoch 2236, Loss: 0.000909853661141824, Final Batch Loss: 0.0001109020013245754\n",
      "Epoch 2237, Loss: 0.00038611051422776654, Final Batch Loss: 9.603051148587838e-05\n",
      "Epoch 2238, Loss: 0.006873939768411219, Final Batch Loss: 0.006395426113158464\n",
      "Epoch 2239, Loss: 0.0008511123305652291, Final Batch Loss: 0.00030733118182979524\n",
      "Epoch 2240, Loss: 0.0012755501084029675, Final Batch Loss: 0.0005064941360615194\n",
      "Epoch 2241, Loss: 0.001486073830164969, Final Batch Loss: 0.0004531125305220485\n",
      "Epoch 2242, Loss: 0.0017108283354900777, Final Batch Loss: 0.0008265099604614079\n",
      "Epoch 2243, Loss: 0.006939940620213747, Final Batch Loss: 0.004968089982867241\n",
      "Epoch 2244, Loss: 0.0004318007704569027, Final Batch Loss: 0.00022166846611071378\n",
      "Epoch 2245, Loss: 0.0008478460949845612, Final Batch Loss: 0.0002759505878202617\n",
      "Epoch 2246, Loss: 0.004489111830480397, Final Batch Loss: 0.0038247406482696533\n",
      "Epoch 2247, Loss: 0.00020711856996058486, Final Batch Loss: 5.40139117219951e-05\n",
      "Epoch 2248, Loss: 0.0025930077536031604, Final Batch Loss: 0.0012111340183764696\n",
      "Epoch 2249, Loss: 0.0006464618199970573, Final Batch Loss: 0.00017705344362184405\n",
      "Epoch 2250, Loss: 0.0003319340539746918, Final Batch Loss: 0.00026576907839626074\n",
      "Epoch 2251, Loss: 0.0009131019469350576, Final Batch Loss: 0.0002264052745886147\n",
      "Epoch 2252, Loss: 0.002501153059711214, Final Batch Loss: 8.595352846896276e-05\n",
      "Epoch 2253, Loss: 0.00014662015746580437, Final Batch Loss: 5.4284486395772547e-05\n",
      "Epoch 2254, Loss: 0.0019183461554348469, Final Batch Loss: 0.0010853182757273316\n",
      "Epoch 2255, Loss: 0.00462710065767169, Final Batch Loss: 0.0014379541389644146\n",
      "Epoch 2256, Loss: 0.0031969799601938576, Final Batch Loss: 0.0028550252318382263\n",
      "Epoch 2257, Loss: 0.0006935510318726301, Final Batch Loss: 0.00031999030034057796\n",
      "Epoch 2258, Loss: 0.0024805269204080105, Final Batch Loss: 0.00028012413531541824\n",
      "Epoch 2259, Loss: 0.0006517730071209371, Final Batch Loss: 0.0003900200827047229\n",
      "Epoch 2260, Loss: 0.002004291513003409, Final Batch Loss: 0.0014541561249643564\n",
      "Epoch 2261, Loss: 0.00022193125187186524, Final Batch Loss: 8.100522245513275e-05\n",
      "Epoch 2262, Loss: 0.0011298313038423657, Final Batch Loss: 0.0008112518698908389\n",
      "Epoch 2263, Loss: 0.009212435426888987, Final Batch Loss: 0.0001682855363469571\n",
      "Epoch 2264, Loss: 0.005287942753056996, Final Batch Loss: 0.0001669547491474077\n",
      "Epoch 2265, Loss: 0.0010795361595228314, Final Batch Loss: 0.00034167140256613493\n",
      "Epoch 2266, Loss: 0.0058253013994544744, Final Batch Loss: 0.0032707799691706896\n",
      "Epoch 2267, Loss: 0.005074510438134894, Final Batch Loss: 0.0002637580910231918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2268, Loss: 0.0016859991592355072, Final Batch Loss: 0.0005164556787349284\n",
      "Epoch 2269, Loss: 0.00034429689549142495, Final Batch Loss: 6.637478509219363e-05\n",
      "Epoch 2270, Loss: 0.0005214152479311451, Final Batch Loss: 0.000315831508487463\n",
      "Epoch 2271, Loss: 0.014826764905592427, Final Batch Loss: 0.00031128767295740545\n",
      "Epoch 2272, Loss: 0.001161501117167063, Final Batch Loss: 0.0010100294603034854\n",
      "Epoch 2273, Loss: 0.0007714833627687767, Final Batch Loss: 0.0002181676827603951\n",
      "Epoch 2274, Loss: 0.006176876893732697, Final Batch Loss: 0.0009345077560283244\n",
      "Epoch 2275, Loss: 0.006984676467254758, Final Batch Loss: 0.002175787230953574\n",
      "Epoch 2276, Loss: 0.0003274354967288673, Final Batch Loss: 6.387644680216908e-05\n",
      "Epoch 2277, Loss: 0.002464098040945828, Final Batch Loss: 0.0008388683199882507\n",
      "Epoch 2278, Loss: 0.0005135072424309328, Final Batch Loss: 0.00020674960978794843\n",
      "Epoch 2279, Loss: 0.0061098861042410135, Final Batch Loss: 0.002686868654564023\n",
      "Epoch 2280, Loss: 0.0016862981719896197, Final Batch Loss: 0.000822504865936935\n",
      "Epoch 2281, Loss: 0.0010375365382060409, Final Batch Loss: 0.0002915940131060779\n",
      "Epoch 2282, Loss: 0.00045231645344756544, Final Batch Loss: 0.00018094709957949817\n",
      "Epoch 2283, Loss: 0.004244325333274901, Final Batch Loss: 0.00038041931111365557\n",
      "Epoch 2284, Loss: 0.0006413918454200029, Final Batch Loss: 0.00023203817545436323\n",
      "Epoch 2285, Loss: 0.0005453753801702987, Final Batch Loss: 4.3444142647786066e-05\n",
      "Epoch 2286, Loss: 0.0004616343358065933, Final Batch Loss: 7.210366311483085e-05\n",
      "Epoch 2287, Loss: 0.0008352644217666239, Final Batch Loss: 0.0004000485350843519\n",
      "Epoch 2288, Loss: 0.040609843214042485, Final Batch Loss: 0.0013432978885248303\n",
      "Epoch 2289, Loss: 0.00040242298564407974, Final Batch Loss: 0.0001998479856410995\n",
      "Epoch 2290, Loss: 0.00034325244632782415, Final Batch Loss: 6.491333624580875e-05\n",
      "Epoch 2291, Loss: 0.0007447915995726362, Final Batch Loss: 0.00021726284467149526\n",
      "Epoch 2292, Loss: 0.0017025583074428141, Final Batch Loss: 0.00020716519793495536\n",
      "Epoch 2293, Loss: 0.021819786983542144, Final Batch Loss: 0.00014690111856907606\n",
      "Epoch 2294, Loss: 0.030188516655471176, Final Batch Loss: 0.02975158393383026\n",
      "Epoch 2295, Loss: 0.007986910757608712, Final Batch Loss: 0.001126289484091103\n",
      "Epoch 2296, Loss: 0.0016293899097945541, Final Batch Loss: 0.0004048300615977496\n",
      "Epoch 2297, Loss: 0.0006471317756222561, Final Batch Loss: 0.00015507750504184514\n",
      "Epoch 2298, Loss: 0.00269867928000167, Final Batch Loss: 0.0004960965015925467\n",
      "Epoch 2299, Loss: 0.0026429774006828666, Final Batch Loss: 0.001887712860479951\n",
      "Epoch 2300, Loss: 0.013728770427405834, Final Batch Loss: 0.0013426421210169792\n",
      "Epoch 2301, Loss: 0.010460898280143738, Final Batch Loss: 0.0062896437011659145\n",
      "Epoch 2302, Loss: 0.005279036122374237, Final Batch Loss: 0.004778163507580757\n",
      "Epoch 2303, Loss: 0.004065886838361621, Final Batch Loss: 0.00301523064263165\n",
      "Epoch 2304, Loss: 0.0007115573971532285, Final Batch Loss: 0.0005382657982409\n",
      "Epoch 2305, Loss: 0.010859413538128138, Final Batch Loss: 0.006827280856668949\n",
      "Epoch 2306, Loss: 0.0007569309382233769, Final Batch Loss: 6.974281859584153e-05\n",
      "Epoch 2307, Loss: 0.00122455175005598, Final Batch Loss: 0.0011292229173704982\n",
      "Epoch 2308, Loss: 0.0004257258915458806, Final Batch Loss: 0.00036557429120875895\n",
      "Epoch 2309, Loss: 0.0007386710785795003, Final Batch Loss: 0.00036261716741137207\n",
      "Epoch 2310, Loss: 0.0023482784163206816, Final Batch Loss: 0.0016488400287926197\n",
      "Epoch 2311, Loss: 0.013424078235402703, Final Batch Loss: 0.00017419853247702122\n",
      "Epoch 2312, Loss: 0.0009476952254772186, Final Batch Loss: 0.0008029080927371979\n",
      "Epoch 2313, Loss: 0.003580674761906266, Final Batch Loss: 0.001969126984477043\n",
      "Epoch 2314, Loss: 0.0022107025724835694, Final Batch Loss: 0.0006255992338992655\n",
      "Epoch 2315, Loss: 0.002075441414490342, Final Batch Loss: 0.00026546057779341936\n",
      "Epoch 2316, Loss: 0.004163314821198583, Final Batch Loss: 0.0034455389250069857\n",
      "Epoch 2317, Loss: 0.02090401464374736, Final Batch Loss: 0.000559625041205436\n",
      "Epoch 2318, Loss: 0.007819740450941026, Final Batch Loss: 0.006183806341141462\n",
      "Epoch 2319, Loss: 0.01341643845080398, Final Batch Loss: 0.00019330819486640394\n",
      "Epoch 2320, Loss: 0.006344028166495264, Final Batch Loss: 0.004511700477451086\n",
      "Epoch 2321, Loss: 0.000880275183590129, Final Batch Loss: 0.0001570666499901563\n",
      "Epoch 2322, Loss: 0.0007533181778853759, Final Batch Loss: 0.00011920345423277467\n",
      "Epoch 2323, Loss: 0.07261727610602975, Final Batch Loss: 0.06635133922100067\n",
      "Epoch 2324, Loss: 0.004800742492079735, Final Batch Loss: 0.0039849793538451195\n",
      "Epoch 2325, Loss: 0.00042642939661163837, Final Batch Loss: 0.00017514776845928282\n",
      "Epoch 2326, Loss: 0.002371476439293474, Final Batch Loss: 0.00048399990191683173\n",
      "Epoch 2327, Loss: 0.000830616889288649, Final Batch Loss: 0.000263112218817696\n",
      "Epoch 2328, Loss: 0.001277712086448446, Final Batch Loss: 0.00036902682040818036\n",
      "Epoch 2329, Loss: 0.006584404094610363, Final Batch Loss: 0.006311341654509306\n",
      "Epoch 2330, Loss: 0.0012212551082484424, Final Batch Loss: 0.00023831991711631417\n",
      "Epoch 2331, Loss: 0.0059275196108501405, Final Batch Loss: 0.005450360476970673\n",
      "Epoch 2332, Loss: 0.0052328837919048965, Final Batch Loss: 0.00024491146905347705\n",
      "Epoch 2333, Loss: 0.004092608593055047, Final Batch Loss: 0.0038700054865330458\n",
      "Epoch 2334, Loss: 0.000659113735309802, Final Batch Loss: 0.0004562339745461941\n",
      "Epoch 2335, Loss: 0.0009781589615158737, Final Batch Loss: 0.0004579520900733769\n",
      "Epoch 2336, Loss: 0.002947879911516793, Final Batch Loss: 0.0002240007306681946\n",
      "Epoch 2337, Loss: 0.0013121161609888077, Final Batch Loss: 0.00029384507797658443\n",
      "Epoch 2338, Loss: 0.0022971378784859553, Final Batch Loss: 0.0002240659814560786\n",
      "Epoch 2339, Loss: 0.0029056770144961774, Final Batch Loss: 0.0003652078448794782\n",
      "Epoch 2340, Loss: 0.0025341903092339635, Final Batch Loss: 0.0009951748652383685\n",
      "Epoch 2341, Loss: 0.0024388383608311415, Final Batch Loss: 0.0017859385116025805\n",
      "Epoch 2342, Loss: 0.0012264519755262882, Final Batch Loss: 0.0009837438119575381\n",
      "Epoch 2343, Loss: 0.0008139459532685578, Final Batch Loss: 0.0005370376165956259\n",
      "Epoch 2344, Loss: 0.0008677886798977852, Final Batch Loss: 0.0005056814989075065\n",
      "Epoch 2345, Loss: 0.00023948930902406573, Final Batch Loss: 9.707880963105708e-05\n",
      "Epoch 2346, Loss: 0.0007559816876892, Final Batch Loss: 0.00048490497283637524\n",
      "Epoch 2347, Loss: 0.00687370402738452, Final Batch Loss: 0.0030499505810439587\n",
      "Epoch 2348, Loss: 0.002222939277999103, Final Batch Loss: 0.0005519845290109515\n",
      "Epoch 2349, Loss: 0.0045599052391480654, Final Batch Loss: 0.004212461411952972\n",
      "Epoch 2350, Loss: 0.0006529139063786715, Final Batch Loss: 0.00021864945301786065\n",
      "Epoch 2351, Loss: 0.01080243699834682, Final Batch Loss: 0.00026708320365287364\n",
      "Epoch 2352, Loss: 0.004084538668394089, Final Batch Loss: 0.0030318789649754763\n",
      "Epoch 2353, Loss: 0.0007590489985886961, Final Batch Loss: 0.00037522497586905956\n",
      "Epoch 2354, Loss: 0.0009861519938567653, Final Batch Loss: 8.16558749647811e-05\n",
      "Epoch 2355, Loss: 0.0018992203113157302, Final Batch Loss: 0.0017054583877325058\n",
      "Epoch 2356, Loss: 0.0020182838779874146, Final Batch Loss: 0.000926165550481528\n",
      "Epoch 2357, Loss: 0.0007897660325397737, Final Batch Loss: 5.9680613048840314e-05\n",
      "Epoch 2358, Loss: 0.0007999002700671554, Final Batch Loss: 0.00027008092729374766\n",
      "Epoch 2359, Loss: 0.0032373466674471274, Final Batch Loss: 0.0031115987803786993\n",
      "Epoch 2360, Loss: 0.0015225964889395982, Final Batch Loss: 0.0012355243088677526\n",
      "Epoch 2361, Loss: 0.0007838090532459319, Final Batch Loss: 0.0005361087969504297\n",
      "Epoch 2362, Loss: 0.0018493358511477709, Final Batch Loss: 0.0006454853573814034\n",
      "Epoch 2363, Loss: 0.005348844104446471, Final Batch Loss: 0.00014379306230694056\n",
      "Epoch 2364, Loss: 0.004514074007602176, Final Batch Loss: 4.684418308897875e-05\n",
      "Epoch 2365, Loss: 0.004976196127245203, Final Batch Loss: 0.004816283937543631\n",
      "Epoch 2366, Loss: 0.00045098950795363635, Final Batch Loss: 0.00019201218674425036\n",
      "Epoch 2367, Loss: 0.0005209681403357536, Final Batch Loss: 0.00020354916341602802\n",
      "Epoch 2368, Loss: 0.001528634806163609, Final Batch Loss: 0.0006384633597917855\n",
      "Epoch 2369, Loss: 0.0014475533098448068, Final Batch Loss: 0.0012955146376043558\n",
      "Epoch 2370, Loss: 0.0005646260397043079, Final Batch Loss: 0.00042717435280792415\n",
      "Epoch 2371, Loss: 0.0016221604164456949, Final Batch Loss: 0.00013176687934901565\n",
      "Epoch 2372, Loss: 0.0014645594346802682, Final Batch Loss: 0.0010699235135689378\n",
      "Epoch 2373, Loss: 0.0012491678935475647, Final Batch Loss: 0.0006162307690829039\n",
      "Epoch 2374, Loss: 0.0014548624167218804, Final Batch Loss: 0.0010082399239763618\n",
      "Epoch 2375, Loss: 0.0013339321012608707, Final Batch Loss: 0.0008058947278186679\n",
      "Epoch 2376, Loss: 0.0030393959605135024, Final Batch Loss: 0.0005776382167823613\n",
      "Epoch 2377, Loss: 0.0006056509591871873, Final Batch Loss: 4.436146991793066e-05\n",
      "Epoch 2378, Loss: 0.0012946940260007977, Final Batch Loss: 0.0002961637219414115\n",
      "Epoch 2379, Loss: 0.002320873783901334, Final Batch Loss: 0.0022211831528693438\n",
      "Epoch 2380, Loss: 0.0011503208370413631, Final Batch Loss: 0.000364242383511737\n",
      "Epoch 2381, Loss: 0.0013242250424809754, Final Batch Loss: 0.0006233425228856504\n",
      "Epoch 2382, Loss: 0.000802303635282442, Final Batch Loss: 0.0005992858787067235\n",
      "Epoch 2383, Loss: 0.000626298482529819, Final Batch Loss: 0.00036384438863024116\n",
      "Epoch 2384, Loss: 0.0033910074635059573, Final Batch Loss: 5.2153867727611214e-05\n",
      "Epoch 2385, Loss: 0.0008902489207684994, Final Batch Loss: 0.0005428338190540671\n",
      "Epoch 2386, Loss: 0.0011262793850619346, Final Batch Loss: 0.0007114644395187497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2387, Loss: 0.0007241138082463294, Final Batch Loss: 0.0004010841075796634\n",
      "Epoch 2388, Loss: 0.0010982637468259782, Final Batch Loss: 0.0002845793205779046\n",
      "Epoch 2389, Loss: 0.0002634910852066241, Final Batch Loss: 6.896226113894954e-05\n",
      "Epoch 2390, Loss: 0.0018414326186757535, Final Batch Loss: 0.00030644095386378467\n",
      "Epoch 2391, Loss: 0.00043865830230060965, Final Batch Loss: 0.00016809550288598984\n",
      "Epoch 2392, Loss: 0.0031797525007277727, Final Batch Loss: 0.0005331407301127911\n",
      "Epoch 2393, Loss: 0.00031221448443830013, Final Batch Loss: 0.00021213930449448526\n",
      "Epoch 2394, Loss: 0.0012218010961078107, Final Batch Loss: 0.0005212259129621089\n",
      "Epoch 2395, Loss: 0.0007650475308764726, Final Batch Loss: 0.0002573820238467306\n",
      "Epoch 2396, Loss: 0.0010672772768884897, Final Batch Loss: 0.0007128769066184759\n",
      "Epoch 2397, Loss: 0.007299189339391887, Final Batch Loss: 0.0016735693207010627\n",
      "Epoch 2398, Loss: 0.001340082730166614, Final Batch Loss: 0.0009315917268395424\n",
      "Epoch 2399, Loss: 0.0017023867112584412, Final Batch Loss: 0.00037045677891001105\n",
      "Epoch 2400, Loss: 0.006196187896421179, Final Batch Loss: 0.0003880305157508701\n",
      "Epoch 2401, Loss: 0.0005787102418253198, Final Batch Loss: 0.0003931107930839062\n",
      "Epoch 2402, Loss: 0.0005016376962885261, Final Batch Loss: 0.00021469243802130222\n",
      "Epoch 2403, Loss: 0.0026263304898748174, Final Batch Loss: 4.5624226913787425e-05\n",
      "Epoch 2404, Loss: 0.0009050646622199565, Final Batch Loss: 0.0004704020684584975\n",
      "Epoch 2405, Loss: 0.001158316561486572, Final Batch Loss: 0.000695370661560446\n",
      "Epoch 2406, Loss: 0.0006635173922404647, Final Batch Loss: 0.00027556426357477903\n",
      "Epoch 2407, Loss: 0.0004995654308004305, Final Batch Loss: 0.00012129989045206457\n",
      "Epoch 2408, Loss: 0.0010255171509925276, Final Batch Loss: 0.0006089587113820016\n",
      "Epoch 2409, Loss: 0.01629652376868762, Final Batch Loss: 0.00039223316707648337\n",
      "Epoch 2410, Loss: 0.0009584286890458316, Final Batch Loss: 0.0007463389774784446\n",
      "Epoch 2411, Loss: 0.0022978464839980006, Final Batch Loss: 0.0011259119492024183\n",
      "Epoch 2412, Loss: 0.0002483282078173943, Final Batch Loss: 0.00011784880916820839\n",
      "Epoch 2413, Loss: 0.004225574724841863, Final Batch Loss: 0.004087378270924091\n",
      "Epoch 2414, Loss: 0.0007289337809197605, Final Batch Loss: 0.00040988385444507003\n",
      "Epoch 2415, Loss: 0.0030717400513822213, Final Batch Loss: 0.00010148646833840758\n",
      "Epoch 2416, Loss: 0.0005992325895931572, Final Batch Loss: 9.71924455370754e-05\n",
      "Epoch 2417, Loss: 0.0006091969626140781, Final Batch Loss: 0.0005401019006967545\n",
      "Epoch 2418, Loss: 0.0003726222275872715, Final Batch Loss: 9.976584260584787e-05\n",
      "Epoch 2419, Loss: 0.000415819653426297, Final Batch Loss: 0.00015929080836940557\n",
      "Epoch 2420, Loss: 0.0008204052137443796, Final Batch Loss: 3.969362296629697e-05\n",
      "Epoch 2421, Loss: 0.0009204317029798403, Final Batch Loss: 0.0001499785721534863\n",
      "Epoch 2422, Loss: 0.0008211662352550775, Final Batch Loss: 0.0005017014918848872\n",
      "Epoch 2423, Loss: 0.003168009570799768, Final Batch Loss: 0.0012554145650938153\n",
      "Epoch 2424, Loss: 0.0053088662680238485, Final Batch Loss: 0.00404798798263073\n",
      "Epoch 2425, Loss: 0.0004446481470949948, Final Batch Loss: 0.0002945587912108749\n",
      "Epoch 2426, Loss: 0.010903366550337523, Final Batch Loss: 0.010749991983175278\n",
      "Epoch 2427, Loss: 0.0007122282113414258, Final Batch Loss: 0.0003733124758582562\n",
      "Epoch 2428, Loss: 0.0023268115473911166, Final Batch Loss: 0.0006150903645902872\n",
      "Epoch 2429, Loss: 0.002928534086095169, Final Batch Loss: 0.002809736179187894\n",
      "Epoch 2430, Loss: 0.0074871929828077555, Final Batch Loss: 0.0027784674894064665\n",
      "Epoch 2431, Loss: 0.0004939254140481353, Final Batch Loss: 0.000379326258553192\n",
      "Epoch 2432, Loss: 0.0017255037964787334, Final Batch Loss: 0.00033481160062365234\n",
      "Epoch 2433, Loss: 0.0008726974338060245, Final Batch Loss: 8.111474744509906e-05\n",
      "Epoch 2434, Loss: 0.03034984099213034, Final Batch Loss: 0.0004657894605770707\n",
      "Epoch 2435, Loss: 0.0009595807350706309, Final Batch Loss: 0.0005848223227076232\n",
      "Epoch 2436, Loss: 0.0002387362692388706, Final Batch Loss: 0.000141949494718574\n",
      "Epoch 2437, Loss: 0.0008948791946750134, Final Batch Loss: 0.000531399913597852\n",
      "Epoch 2438, Loss: 0.007426822558045387, Final Batch Loss: 0.0044394065625965595\n",
      "Epoch 2439, Loss: 0.0013803769834339619, Final Batch Loss: 0.0003025643527507782\n",
      "Epoch 2440, Loss: 0.000938571261940524, Final Batch Loss: 0.0005943936994299293\n",
      "Epoch 2441, Loss: 0.0012722242972813547, Final Batch Loss: 0.0007835005526430905\n",
      "Epoch 2442, Loss: 0.009504603687673807, Final Batch Loss: 0.0010069948621094227\n",
      "Epoch 2443, Loss: 0.002046748442808166, Final Batch Loss: 0.0003155526064801961\n",
      "Epoch 2444, Loss: 0.000277058185019996, Final Batch Loss: 0.00019554061873350292\n",
      "Epoch 2445, Loss: 0.0001800672907847911, Final Batch Loss: 8.369502756977454e-05\n",
      "Epoch 2446, Loss: 0.004343696171417832, Final Batch Loss: 0.000943017890676856\n",
      "Epoch 2447, Loss: 0.0007014234724920243, Final Batch Loss: 0.00037411972880363464\n",
      "Epoch 2448, Loss: 0.00013879103789804503, Final Batch Loss: 3.6258767067920417e-05\n",
      "Epoch 2449, Loss: 0.0025556139880791306, Final Batch Loss: 0.0003334098728373647\n",
      "Epoch 2450, Loss: 0.0002818940411088988, Final Batch Loss: 9.567996312398463e-05\n",
      "Epoch 2451, Loss: 0.0002011732940445654, Final Batch Loss: 6.836471584392712e-05\n",
      "Epoch 2452, Loss: 0.000656198593787849, Final Batch Loss: 0.00018388440366834402\n",
      "Epoch 2453, Loss: 0.00030071895162109286, Final Batch Loss: 7.387003279291093e-05\n",
      "Epoch 2454, Loss: 0.0005320168129401281, Final Batch Loss: 0.00011937528324779123\n",
      "Epoch 2455, Loss: 0.005744019872508943, Final Batch Loss: 0.005237330682575703\n",
      "Epoch 2456, Loss: 0.0022734923841198906, Final Batch Loss: 6.531398685183376e-05\n",
      "Epoch 2457, Loss: 0.0026133940555155277, Final Batch Loss: 0.0021609903778880835\n",
      "Epoch 2458, Loss: 0.00029167292086640373, Final Batch Loss: 6.927643698872998e-05\n",
      "Epoch 2459, Loss: 0.0006537350127473474, Final Batch Loss: 0.0002469184692017734\n",
      "Epoch 2460, Loss: 0.0009265629341825843, Final Batch Loss: 0.0003223971580155194\n",
      "Epoch 2461, Loss: 0.0004084496176801622, Final Batch Loss: 0.00033460886334069073\n",
      "Epoch 2462, Loss: 0.0006517037327284925, Final Batch Loss: 0.0005411937017925084\n",
      "Epoch 2463, Loss: 0.002332823001779616, Final Batch Loss: 0.0019458540482446551\n",
      "Epoch 2464, Loss: 0.0016868588281795382, Final Batch Loss: 0.0013775582192465663\n",
      "Epoch 2465, Loss: 0.0004929477581754327, Final Batch Loss: 0.00018611524137668312\n",
      "Epoch 2466, Loss: 0.0006365489243762568, Final Batch Loss: 0.0005135383107699454\n",
      "Epoch 2467, Loss: 0.0017365525127388537, Final Batch Loss: 0.0012157916789874434\n",
      "Epoch 2468, Loss: 0.0027087893467978574, Final Batch Loss: 0.002600588835775852\n",
      "Epoch 2469, Loss: 0.0005601276279776357, Final Batch Loss: 6.382512947311625e-05\n",
      "Epoch 2470, Loss: 0.0010245224693790078, Final Batch Loss: 0.000421774631831795\n",
      "Epoch 2471, Loss: 0.0015596773009747267, Final Batch Loss: 0.001154686906374991\n",
      "Epoch 2472, Loss: 0.00024937485432019457, Final Batch Loss: 0.00013411528198048472\n",
      "Epoch 2473, Loss: 0.011313330323901027, Final Batch Loss: 0.0005032885237596929\n",
      "Epoch 2474, Loss: 0.0008002827453310601, Final Batch Loss: 8.242378680733964e-05\n",
      "Epoch 2475, Loss: 0.001969048462342471, Final Batch Loss: 0.0009511544485576451\n",
      "Epoch 2476, Loss: 0.00037354789492383134, Final Batch Loss: 2.1927813577349298e-05\n",
      "Epoch 2477, Loss: 0.00017897986163006863, Final Batch Loss: 1.2175171832495835e-05\n",
      "Epoch 2478, Loss: 0.00048288473226421047, Final Batch Loss: 1.754326694936026e-05\n",
      "Epoch 2479, Loss: 0.0017802802394726314, Final Batch Loss: 0.0017213172977790236\n",
      "Epoch 2480, Loss: 0.0005253676790744066, Final Batch Loss: 0.00035780001780949533\n",
      "Epoch 2481, Loss: 0.00043468656804179773, Final Batch Loss: 0.00033779689692892134\n",
      "Epoch 2482, Loss: 0.0003733460762305185, Final Batch Loss: 0.00020370606216602027\n",
      "Epoch 2483, Loss: 0.0036778782377950847, Final Batch Loss: 0.0005662310286425054\n",
      "Epoch 2484, Loss: 0.0007338841860473622, Final Batch Loss: 0.0006865595350973308\n",
      "Epoch 2485, Loss: 0.0006947184738237411, Final Batch Loss: 0.00030941361910663545\n",
      "Epoch 2486, Loss: 0.0052957418956793845, Final Batch Loss: 0.0003444781177677214\n",
      "Epoch 2487, Loss: 0.0008101324201561511, Final Batch Loss: 0.0004853266291320324\n",
      "Epoch 2488, Loss: 0.0005336489412002265, Final Batch Loss: 0.000272392004262656\n",
      "Epoch 2489, Loss: 0.00245534919667989, Final Batch Loss: 0.001395565108396113\n",
      "Epoch 2490, Loss: 0.003131673831376247, Final Batch Loss: 0.0029711320530623198\n",
      "Epoch 2491, Loss: 0.00023447484272764996, Final Batch Loss: 4.6861481678206474e-05\n",
      "Epoch 2492, Loss: 0.0036637372177210636, Final Batch Loss: 0.003575306385755539\n",
      "Epoch 2493, Loss: 0.006470026884926483, Final Batch Loss: 6.505564670078456e-05\n",
      "Epoch 2494, Loss: 0.0014235430571716279, Final Batch Loss: 0.0002906300069298595\n",
      "Epoch 2495, Loss: 0.0025615222984924912, Final Batch Loss: 0.0018848362378776073\n",
      "Epoch 2496, Loss: 0.00226812731125392, Final Batch Loss: 0.002197608118876815\n",
      "Epoch 2497, Loss: 0.012324492447078228, Final Batch Loss: 0.005002221092581749\n",
      "Epoch 2498, Loss: 0.0008013768529053777, Final Batch Loss: 0.0005315710441209376\n",
      "Epoch 2499, Loss: 0.0006930403033038601, Final Batch Loss: 0.00017768771795090288\n",
      "Epoch 2500, Loss: 0.005649441620334983, Final Batch Loss: 0.002728651510551572\n",
      "Epoch 2501, Loss: 0.003122116788290441, Final Batch Loss: 0.0028071170672774315\n",
      "Epoch 2502, Loss: 0.0010325674811610952, Final Batch Loss: 3.31258779624477e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2503, Loss: 0.007460636668838561, Final Batch Loss: 0.0008394202450290322\n",
      "Epoch 2504, Loss: 0.0038237779517658055, Final Batch Loss: 0.00048684311332181096\n",
      "Epoch 2505, Loss: 7.151532190619037e-05, Final Batch Loss: 2.35086445172783e-05\n",
      "Epoch 2506, Loss: 0.0002605537447379902, Final Batch Loss: 4.764781624544412e-05\n",
      "Epoch 2507, Loss: 0.0002389865112490952, Final Batch Loss: 7.97838147263974e-05\n",
      "Epoch 2508, Loss: 0.0011416726192692295, Final Batch Loss: 0.0002112669317284599\n",
      "Epoch 2509, Loss: 0.013203378053731285, Final Batch Loss: 0.00018598254246171564\n",
      "Epoch 2510, Loss: 0.005020481476094574, Final Batch Loss: 0.0006313407211564481\n",
      "Epoch 2511, Loss: 0.0013555184850702062, Final Batch Loss: 0.0012182161444798112\n",
      "Epoch 2512, Loss: 0.0021125628845766187, Final Batch Loss: 0.0007837665034458041\n",
      "Epoch 2513, Loss: 0.00024558205041103065, Final Batch Loss: 0.00013731261424254626\n",
      "Epoch 2514, Loss: 0.0009143829520326108, Final Batch Loss: 0.00029361245105974376\n",
      "Epoch 2515, Loss: 0.006641122745350003, Final Batch Loss: 0.0012257529888302088\n",
      "Epoch 2516, Loss: 0.0009991475380957127, Final Batch Loss: 0.0005410067387856543\n",
      "Epoch 2517, Loss: 0.00214659288758412, Final Batch Loss: 0.0018320133676752448\n",
      "Epoch 2518, Loss: 0.0003207194840797456, Final Batch Loss: 2.9158474717405625e-05\n",
      "Epoch 2519, Loss: 0.0006034046673448756, Final Batch Loss: 0.0001917779300129041\n",
      "Epoch 2520, Loss: 0.001995563681703061, Final Batch Loss: 0.00034688232699409127\n",
      "Epoch 2521, Loss: 0.0012962587497895584, Final Batch Loss: 0.0011908143060281873\n",
      "Epoch 2522, Loss: 0.0008313356665894389, Final Batch Loss: 0.000653679424431175\n",
      "Epoch 2523, Loss: 0.00900421547703445, Final Batch Loss: 0.00830707885324955\n",
      "Epoch 2524, Loss: 0.0011475988212623633, Final Batch Loss: 6.92520770826377e-05\n",
      "Epoch 2525, Loss: 0.00039003786514513195, Final Batch Loss: 0.00010130301234312356\n",
      "Epoch 2526, Loss: 0.0007489619601983577, Final Batch Loss: 0.00034030617098324\n",
      "Epoch 2527, Loss: 0.001340193150099367, Final Batch Loss: 0.0006403940496966243\n",
      "Epoch 2528, Loss: 0.002309884290298214, Final Batch Loss: 5.9352601965656504e-05\n",
      "Epoch 2529, Loss: 0.0011605461477302015, Final Batch Loss: 0.0010441060876473784\n",
      "Epoch 2530, Loss: 0.0009456448606215417, Final Batch Loss: 0.0005894355708733201\n",
      "Epoch 2531, Loss: 0.0004446371312951669, Final Batch Loss: 0.00016857664741110057\n",
      "Epoch 2532, Loss: 0.00422582877217792, Final Batch Loss: 0.004083588253706694\n",
      "Epoch 2533, Loss: 0.0008780674543231726, Final Batch Loss: 0.0007230195915326476\n",
      "Epoch 2534, Loss: 0.002896635363867972, Final Batch Loss: 0.0028228762093931437\n",
      "Epoch 2535, Loss: 0.00010894420483964495, Final Batch Loss: 6.786011363146827e-05\n",
      "Epoch 2536, Loss: 0.001467540583689697, Final Batch Loss: 0.0012369160540401936\n",
      "Epoch 2537, Loss: 0.00042129677603952587, Final Batch Loss: 0.00020695953571703285\n",
      "Epoch 2538, Loss: 0.003792763571254909, Final Batch Loss: 0.003417413914576173\n",
      "Epoch 2539, Loss: 0.0011107400641776621, Final Batch Loss: 0.0004140912205912173\n",
      "Epoch 2540, Loss: 0.018945959585835226, Final Batch Loss: 0.01887919194996357\n",
      "Epoch 2541, Loss: 0.004641890889615752, Final Batch Loss: 0.0001617459492990747\n",
      "Epoch 2542, Loss: 0.0034652026370167732, Final Batch Loss: 0.0005064797587692738\n",
      "Epoch 2543, Loss: 0.0004939813443343155, Final Batch Loss: 0.0004706914769485593\n",
      "Epoch 2544, Loss: 0.000256202467426192, Final Batch Loss: 0.00016133814642671496\n",
      "Epoch 2545, Loss: 0.0005684796196874231, Final Batch Loss: 0.00019357242854312062\n",
      "Epoch 2546, Loss: 0.0011654349145828746, Final Batch Loss: 3.461396408965811e-05\n",
      "Epoch 2547, Loss: 0.0004844497161684558, Final Batch Loss: 0.00028827274218201637\n",
      "Epoch 2548, Loss: 0.0008022590518521611, Final Batch Loss: 5.758097177022137e-05\n",
      "Epoch 2549, Loss: 0.061852128244936466, Final Batch Loss: 0.05705660581588745\n",
      "Epoch 2550, Loss: 0.0008609189244452864, Final Batch Loss: 0.0006362375570461154\n",
      "Epoch 2551, Loss: 0.007844151085009798, Final Batch Loss: 0.00765228969976306\n",
      "Epoch 2552, Loss: 0.03256465634331107, Final Batch Loss: 0.03073294460773468\n",
      "Epoch 2553, Loss: 0.044498901545011904, Final Batch Loss: 0.0443870984017849\n",
      "Epoch 2554, Loss: 0.0004222373681841418, Final Batch Loss: 0.00021294761972967535\n",
      "Epoch 2555, Loss: 0.0007299904973478988, Final Batch Loss: 0.00011351106513757259\n",
      "Epoch 2556, Loss: 0.00038527604192495346, Final Batch Loss: 8.547297329641879e-05\n",
      "Epoch 2557, Loss: 0.03316738095600158, Final Batch Loss: 0.00037605699617415667\n",
      "Epoch 2558, Loss: 0.0060077843081671745, Final Batch Loss: 0.0003701381210703403\n",
      "Epoch 2559, Loss: 0.0041011352150235325, Final Batch Loss: 0.00022539185010828078\n",
      "Epoch 2560, Loss: 0.0016033580177463591, Final Batch Loss: 0.001316832727752626\n",
      "Epoch 2561, Loss: 0.000622010586084798, Final Batch Loss: 0.0002861616085283458\n",
      "Epoch 2562, Loss: 0.0010657933889888227, Final Batch Loss: 0.00020965485600754619\n",
      "Epoch 2563, Loss: 0.0008059709798544645, Final Batch Loss: 8.393591269850731e-05\n",
      "Epoch 2564, Loss: 0.0006599073822144419, Final Batch Loss: 0.00030860918923281133\n",
      "Epoch 2565, Loss: 0.02068705357305589, Final Batch Loss: 2.5420111342100427e-05\n",
      "Epoch 2566, Loss: 0.0026809154078364372, Final Batch Loss: 0.0018910468788817525\n",
      "Epoch 2567, Loss: 0.001595543755684048, Final Batch Loss: 0.0009466827032156289\n",
      "Epoch 2568, Loss: 0.0003486523128231056, Final Batch Loss: 0.00010702377039706334\n",
      "Epoch 2569, Loss: 0.01249912814819254, Final Batch Loss: 0.012080320157110691\n",
      "Epoch 2570, Loss: 0.00294780038530007, Final Batch Loss: 0.0006398556870408356\n",
      "Epoch 2571, Loss: 0.000609008886385709, Final Batch Loss: 0.0003773121861740947\n",
      "Epoch 2572, Loss: 0.005626685451716185, Final Batch Loss: 0.004610956180840731\n",
      "Epoch 2573, Loss: 0.0002736035457928665, Final Batch Loss: 0.00011080009426223114\n",
      "Epoch 2574, Loss: 0.0009457752457819879, Final Batch Loss: 0.00040930870454758406\n",
      "Epoch 2575, Loss: 0.0044173120986670256, Final Batch Loss: 0.0002782160881906748\n",
      "Epoch 2576, Loss: 0.002165563579183072, Final Batch Loss: 0.0009691052255220711\n",
      "Epoch 2577, Loss: 0.005969393328996375, Final Batch Loss: 0.00016170440358109772\n",
      "Epoch 2578, Loss: 0.0015564514906145632, Final Batch Loss: 0.00025573541643097997\n",
      "Epoch 2579, Loss: 0.00047485725372098386, Final Batch Loss: 0.00031323765870183706\n",
      "Epoch 2580, Loss: 0.0019665329018607736, Final Batch Loss: 0.000863892724737525\n",
      "Epoch 2581, Loss: 0.00036719165655085817, Final Batch Loss: 0.00027542441966943443\n",
      "Epoch 2582, Loss: 0.0007510732102673501, Final Batch Loss: 0.00035413040313869715\n",
      "Epoch 2583, Loss: 0.0004167523293290287, Final Batch Loss: 0.00021561048924922943\n",
      "Epoch 2584, Loss: 0.004197173286229372, Final Batch Loss: 0.002419714815914631\n",
      "Epoch 2585, Loss: 0.0010050218843389302, Final Batch Loss: 0.0003431417571846396\n",
      "Epoch 2586, Loss: 0.0016740107676014304, Final Batch Loss: 0.001419621636159718\n",
      "Epoch 2587, Loss: 0.002926631714217365, Final Batch Loss: 0.002337503479793668\n",
      "Epoch 2588, Loss: 0.0017814316670410335, Final Batch Loss: 0.0002696852316148579\n",
      "Epoch 2589, Loss: 0.0005815081531181931, Final Batch Loss: 0.00012258536298759282\n",
      "Epoch 2590, Loss: 0.0005832063252455555, Final Batch Loss: 0.0001042883304762654\n",
      "Epoch 2591, Loss: 0.0004917341793770902, Final Batch Loss: 0.00038194205262698233\n",
      "Epoch 2592, Loss: 0.0006678862118860707, Final Batch Loss: 0.0004501387011259794\n",
      "Epoch 2593, Loss: 0.0006534432905027643, Final Batch Loss: 0.00021061186271253973\n",
      "Epoch 2594, Loss: 0.00019636219076346606, Final Batch Loss: 7.695898966630921e-05\n",
      "Epoch 2595, Loss: 0.0003264402039349079, Final Batch Loss: 0.00016851237160153687\n",
      "Epoch 2596, Loss: 0.001986200877581723, Final Batch Loss: 6.318122905213386e-05\n",
      "Epoch 2597, Loss: 0.004504230455495417, Final Batch Loss: 0.003957940265536308\n",
      "Epoch 2598, Loss: 0.0008217832000809722, Final Batch Loss: 0.00011751794227166101\n",
      "Epoch 2599, Loss: 0.0006862404989078641, Final Batch Loss: 0.00018307159189134836\n",
      "Epoch 2600, Loss: 0.002903000800870359, Final Batch Loss: 0.0004018523031845689\n",
      "Epoch 2601, Loss: 0.0007541464292444289, Final Batch Loss: 0.0004486003308556974\n",
      "Epoch 2602, Loss: 0.0010677439568098634, Final Batch Loss: 0.0007813682896085083\n",
      "Epoch 2603, Loss: 0.0005863866972504184, Final Batch Loss: 0.00012776291987393051\n",
      "Epoch 2604, Loss: 0.0010565165284788236, Final Batch Loss: 0.0008921567932702601\n",
      "Epoch 2605, Loss: 0.004304630740080029, Final Batch Loss: 0.0033621538896113634\n",
      "Epoch 2606, Loss: 0.0012986845977138728, Final Batch Loss: 0.00035663179005496204\n",
      "Epoch 2607, Loss: 0.00045218635932542384, Final Batch Loss: 0.0002523754083085805\n",
      "Epoch 2608, Loss: 0.006565779913216829, Final Batch Loss: 0.0028272010385990143\n",
      "Epoch 2609, Loss: 0.0001943327224580571, Final Batch Loss: 9.693863830761984e-05\n",
      "Epoch 2610, Loss: 0.0011086674057878554, Final Batch Loss: 0.0007046497776173055\n",
      "Epoch 2611, Loss: 0.0008723993087187409, Final Batch Loss: 7.392902625724673e-05\n",
      "Epoch 2612, Loss: 0.022209247021237388, Final Batch Loss: 0.00010159742669202387\n",
      "Epoch 2613, Loss: 0.0008443872793577611, Final Batch Loss: 0.0007031965651549399\n",
      "Epoch 2614, Loss: 0.0008478489908156916, Final Batch Loss: 0.0006607004324905574\n",
      "Epoch 2615, Loss: 0.00038766046054661274, Final Batch Loss: 7.126250420697033e-05\n",
      "Epoch 2616, Loss: 0.0027338737418176606, Final Batch Loss: 0.00018021588039118797\n",
      "Epoch 2617, Loss: 0.0011962693242821842, Final Batch Loss: 0.000903976266272366\n",
      "Epoch 2618, Loss: 0.0007317546114791185, Final Batch Loss: 0.00023141552810557187\n",
      "Epoch 2619, Loss: 0.0024377048466703855, Final Batch Loss: 0.0023271937388926744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2620, Loss: 0.0007266198881552555, Final Batch Loss: 0.0006633659941144288\n",
      "Epoch 2621, Loss: 0.0018083182076225057, Final Batch Loss: 0.0016495666932314634\n",
      "Epoch 2622, Loss: 0.0003771523624891415, Final Batch Loss: 0.0002433321496937424\n",
      "Epoch 2623, Loss: 0.0005552531074499711, Final Batch Loss: 0.0003343518765177578\n",
      "Epoch 2624, Loss: 0.0008320471970364451, Final Batch Loss: 0.0002555312239564955\n",
      "Epoch 2625, Loss: 0.0016383121073886286, Final Batch Loss: 0.0016006181249395013\n",
      "Epoch 2626, Loss: 0.006605744012631476, Final Batch Loss: 0.006228459998965263\n",
      "Epoch 2627, Loss: 0.0028534773737192154, Final Batch Loss: 0.0015037903795018792\n",
      "Epoch 2628, Loss: 0.002037696074694395, Final Batch Loss: 0.0006020173896104097\n",
      "Epoch 2629, Loss: 0.0008421821767115034, Final Batch Loss: 0.000735929177608341\n",
      "Epoch 2630, Loss: 0.00040580856148153543, Final Batch Loss: 0.00020724706701003015\n",
      "Epoch 2631, Loss: 0.00035659938293974847, Final Batch Loss: 0.00029540108516812325\n",
      "Epoch 2632, Loss: 0.002257616724818945, Final Batch Loss: 0.001420502900145948\n",
      "Epoch 2633, Loss: 0.0013721796567551792, Final Batch Loss: 0.0007394739077426493\n",
      "Epoch 2634, Loss: 0.0004065565444761887, Final Batch Loss: 0.00017552565259393305\n",
      "Epoch 2635, Loss: 0.0011137892724946141, Final Batch Loss: 0.0005914286593906581\n",
      "Epoch 2636, Loss: 0.0002356953264097683, Final Batch Loss: 0.00012119134044041857\n",
      "Epoch 2637, Loss: 0.01423438501660712, Final Batch Loss: 0.00019782179151661694\n",
      "Epoch 2638, Loss: 0.11574003225541674, Final Batch Loss: 0.1156344935297966\n",
      "Epoch 2639, Loss: 0.003228971268981695, Final Batch Loss: 0.0017186157638207078\n",
      "Epoch 2640, Loss: 0.0018681943765841424, Final Batch Loss: 0.0009426978067494929\n",
      "Epoch 2641, Loss: 0.003553695452865213, Final Batch Loss: 0.003231917740777135\n",
      "Epoch 2642, Loss: 0.0007603401318192482, Final Batch Loss: 0.0005006222636438906\n",
      "Epoch 2643, Loss: 0.0008742433892621193, Final Batch Loss: 5.282718120724894e-05\n",
      "Epoch 2644, Loss: 0.005862745572812855, Final Batch Loss: 0.0013803784968331456\n",
      "Epoch 2645, Loss: 0.00029736998840235174, Final Batch Loss: 0.00023133415379561484\n",
      "Epoch 2646, Loss: 0.00047672801883891225, Final Batch Loss: 0.00040022042230702937\n",
      "Epoch 2647, Loss: 0.0027883551083505154, Final Batch Loss: 0.00018282816745340824\n",
      "Epoch 2648, Loss: 0.034518287604441866, Final Batch Loss: 9.050694643519819e-05\n",
      "Epoch 2649, Loss: 0.0005041978583903983, Final Batch Loss: 0.0004106101696379483\n",
      "Epoch 2650, Loss: 0.04738142853602767, Final Batch Loss: 0.04621122032403946\n",
      "Epoch 2651, Loss: 0.00048634022823534906, Final Batch Loss: 0.00013657420640811324\n",
      "Epoch 2652, Loss: 0.000999229134322377, Final Batch Loss: 0.000956348201725632\n",
      "Epoch 2653, Loss: 0.0008347628463525325, Final Batch Loss: 0.0006781978299841285\n",
      "Epoch 2654, Loss: 0.0005022925688535906, Final Batch Loss: 0.0003970332909375429\n",
      "Epoch 2655, Loss: 0.001125842274632305, Final Batch Loss: 0.0007017547031864524\n",
      "Epoch 2656, Loss: 0.002924271044321358, Final Batch Loss: 0.0007558126235380769\n",
      "Epoch 2657, Loss: 0.0004444114747457206, Final Batch Loss: 0.00018316550995223224\n",
      "Epoch 2658, Loss: 0.015063600614666939, Final Batch Loss: 0.004967127926647663\n",
      "Epoch 2659, Loss: 0.0003628600388765335, Final Batch Loss: 0.0001992268953472376\n",
      "Epoch 2660, Loss: 0.0004679684934671968, Final Batch Loss: 0.00026228142087347806\n",
      "Epoch 2661, Loss: 0.0006625522946706042, Final Batch Loss: 0.000236497275182046\n",
      "Epoch 2662, Loss: 0.0035367197124287486, Final Batch Loss: 0.002259331988170743\n",
      "Epoch 2663, Loss: 0.0011172096128575504, Final Batch Loss: 0.0007645446457900107\n",
      "Epoch 2664, Loss: 0.001789350266335532, Final Batch Loss: 0.0016082801157608628\n",
      "Epoch 2665, Loss: 0.0005437067593447864, Final Batch Loss: 0.00033412210177630186\n",
      "Epoch 2666, Loss: 0.001543479913379997, Final Batch Loss: 0.0004788330406881869\n",
      "Epoch 2667, Loss: 0.0014023903931956738, Final Batch Loss: 0.0009466571500524879\n",
      "Epoch 2668, Loss: 0.001050081045832485, Final Batch Loss: 0.00036231050034984946\n",
      "Epoch 2669, Loss: 0.000882550171809271, Final Batch Loss: 0.0005797683843411505\n",
      "Epoch 2670, Loss: 0.003903172488207929, Final Batch Loss: 0.0001395144936395809\n",
      "Epoch 2671, Loss: 0.0004462407814571634, Final Batch Loss: 0.00031232365290634334\n",
      "Epoch 2672, Loss: 0.0006990843539824709, Final Batch Loss: 0.0001346434437436983\n",
      "Epoch 2673, Loss: 0.0034950447734445333, Final Batch Loss: 0.0005999237764626741\n",
      "Epoch 2674, Loss: 0.0002727030405367259, Final Batch Loss: 0.00022060846094973385\n",
      "Epoch 2675, Loss: 0.0005559764395002276, Final Batch Loss: 7.558221113868058e-05\n",
      "Epoch 2676, Loss: 0.002936108212452382, Final Batch Loss: 0.0009052412933669984\n",
      "Epoch 2677, Loss: 0.00027500131545821205, Final Batch Loss: 0.0001905528042698279\n",
      "Epoch 2678, Loss: 0.009555973956594244, Final Batch Loss: 0.009201549924910069\n",
      "Epoch 2679, Loss: 0.0024382677511312068, Final Batch Loss: 0.0004981372621841729\n",
      "Epoch 2680, Loss: 0.0007780100240779575, Final Batch Loss: 4.5599907025462016e-05\n",
      "Epoch 2681, Loss: 0.001296641828957945, Final Batch Loss: 0.00018702546367421746\n",
      "Epoch 2682, Loss: 0.00039948370249476284, Final Batch Loss: 0.00022796625853516161\n",
      "Epoch 2683, Loss: 0.0003601561184041202, Final Batch Loss: 0.0002536274550948292\n",
      "Epoch 2684, Loss: 0.0010335957631468773, Final Batch Loss: 0.0007666647434234619\n",
      "Epoch 2685, Loss: 0.0007369355298578739, Final Batch Loss: 0.0004762070602737367\n",
      "Epoch 2686, Loss: 0.0019002074841409922, Final Batch Loss: 0.0009570508264005184\n",
      "Epoch 2687, Loss: 0.0011555731762200594, Final Batch Loss: 0.00026261137099936604\n",
      "Epoch 2688, Loss: 0.0031151014045462944, Final Batch Loss: 6.885609036544338e-05\n",
      "Epoch 2689, Loss: 0.0003187922957295086, Final Batch Loss: 3.5651082725962624e-05\n",
      "Epoch 2690, Loss: 0.0025975028111133724, Final Batch Loss: 0.002209283644333482\n",
      "Epoch 2691, Loss: 0.0004380584869068116, Final Batch Loss: 9.759142994880676e-05\n",
      "Epoch 2692, Loss: 0.0024251494323834777, Final Batch Loss: 0.0005393803585320711\n",
      "Epoch 2693, Loss: 0.033828288287622854, Final Batch Loss: 0.00016297769616357982\n",
      "Epoch 2694, Loss: 0.0006992945272941142, Final Batch Loss: 0.0002600444422569126\n",
      "Epoch 2695, Loss: 0.0007324121397687122, Final Batch Loss: 0.0006424412713386118\n",
      "Epoch 2696, Loss: 0.006814463064074516, Final Batch Loss: 0.0028174412436783314\n",
      "Epoch 2697, Loss: 0.0015092652247403748, Final Batch Loss: 0.0014423760585486889\n",
      "Epoch 2698, Loss: 0.0012381374544929713, Final Batch Loss: 0.00045986377517692745\n",
      "Epoch 2699, Loss: 0.0004276795662008226, Final Batch Loss: 0.0001572600449435413\n",
      "Epoch 2700, Loss: 0.0005741244531236589, Final Batch Loss: 0.00026974116917699575\n",
      "Epoch 2701, Loss: 0.0005516700475709513, Final Batch Loss: 0.0003197338373865932\n",
      "Epoch 2702, Loss: 0.0010902218346018344, Final Batch Loss: 0.00040121955680660903\n",
      "Epoch 2703, Loss: 0.0021812048507854342, Final Batch Loss: 0.001475182012654841\n",
      "Epoch 2704, Loss: 0.0008529824553988874, Final Batch Loss: 0.0005442050751298666\n",
      "Epoch 2705, Loss: 0.0008078631362877786, Final Batch Loss: 0.00035768558154813945\n",
      "Epoch 2706, Loss: 0.015548042516456917, Final Batch Loss: 0.01508967112749815\n",
      "Epoch 2707, Loss: 0.0047169641038635746, Final Batch Loss: 0.00015999529568944126\n",
      "Epoch 2708, Loss: 0.01604930285247974, Final Batch Loss: 0.015819992870092392\n",
      "Epoch 2709, Loss: 0.0006655694596702233, Final Batch Loss: 0.00023754405265208334\n",
      "Epoch 2710, Loss: 0.001671734469709918, Final Batch Loss: 0.0002555839892011136\n",
      "Epoch 2711, Loss: 0.000945677311392501, Final Batch Loss: 0.0004298459680285305\n",
      "Epoch 2712, Loss: 0.0004937488920404576, Final Batch Loss: 4.585793794831261e-05\n",
      "Epoch 2713, Loss: 0.0014274996356107295, Final Batch Loss: 0.0011756266467273235\n",
      "Epoch 2714, Loss: 0.00044531629828270525, Final Batch Loss: 0.00025067420210689306\n",
      "Epoch 2715, Loss: 0.006264117517275736, Final Batch Loss: 0.0059854923747479916\n",
      "Epoch 2716, Loss: 0.0006260594236664474, Final Batch Loss: 0.00027392522315494716\n",
      "Epoch 2717, Loss: 0.0030264892120612785, Final Batch Loss: 0.0028643293771892786\n",
      "Epoch 2718, Loss: 0.00012032334780087695, Final Batch Loss: 6.348561873892322e-05\n",
      "Epoch 2719, Loss: 0.0006252433522604406, Final Batch Loss: 0.00020480883540585637\n",
      "Epoch 2720, Loss: 0.0009384877193951979, Final Batch Loss: 0.0007988910074345767\n",
      "Epoch 2721, Loss: 0.0003450798976700753, Final Batch Loss: 0.00017684978956822306\n",
      "Epoch 2722, Loss: 0.0006088304071454331, Final Batch Loss: 0.00048077668179757893\n",
      "Epoch 2723, Loss: 0.0029378661420196295, Final Batch Loss: 0.0010343253379687667\n",
      "Epoch 2724, Loss: 0.00031461696926271543, Final Batch Loss: 0.0002283960347995162\n",
      "Epoch 2725, Loss: 0.0003278248477727175, Final Batch Loss: 0.00012767202861141413\n",
      "Epoch 2726, Loss: 0.006442306868848391, Final Batch Loss: 0.000154640365508385\n",
      "Epoch 2727, Loss: 0.0004081162915099412, Final Batch Loss: 0.00023671257076784968\n",
      "Epoch 2728, Loss: 0.0003801881175604649, Final Batch Loss: 0.00027116917772218585\n",
      "Epoch 2729, Loss: 0.0010573584295343608, Final Batch Loss: 0.0009939760202541947\n",
      "Epoch 2730, Loss: 0.001750490628182888, Final Batch Loss: 0.0009889098582789302\n",
      "Epoch 2731, Loss: 0.000298742153972853, Final Batch Loss: 8.9673550974112e-05\n",
      "Epoch 2732, Loss: 0.0015993854904081672, Final Batch Loss: 0.0011787496041506529\n",
      "Epoch 2733, Loss: 0.0004484420715016313, Final Batch Loss: 6.968575326027349e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2734, Loss: 0.01708779769251123, Final Batch Loss: 0.016814924776554108\n",
      "Epoch 2735, Loss: 0.00040865341725293547, Final Batch Loss: 0.00012875204265583307\n",
      "Epoch 2736, Loss: 0.002165247919037938, Final Batch Loss: 0.0010430804686620831\n",
      "Epoch 2737, Loss: 0.0003998706888523884, Final Batch Loss: 0.000331749179167673\n",
      "Epoch 2738, Loss: 0.0003944334894185886, Final Batch Loss: 0.00022540685313288122\n",
      "Epoch 2739, Loss: 0.0002750181156443432, Final Batch Loss: 8.56172846397385e-05\n",
      "Epoch 2740, Loss: 0.002758952687145211, Final Batch Loss: 0.00017098420357797295\n",
      "Epoch 2741, Loss: 0.007013252063188702, Final Batch Loss: 0.0008228305377997458\n",
      "Epoch 2742, Loss: 0.009104349417611957, Final Batch Loss: 0.007789922412484884\n",
      "Epoch 2743, Loss: 0.0015186270466074347, Final Batch Loss: 0.001015921006910503\n",
      "Epoch 2744, Loss: 0.0009037715790327638, Final Batch Loss: 0.0006768760504201055\n",
      "Epoch 2745, Loss: 0.000970082706771791, Final Batch Loss: 0.000314587086904794\n",
      "Epoch 2746, Loss: 0.04798292578198016, Final Batch Loss: 0.047348503023386\n",
      "Epoch 2747, Loss: 0.001452452561352402, Final Batch Loss: 0.0008463115082122386\n",
      "Epoch 2748, Loss: 0.00031842263706494123, Final Batch Loss: 0.0001390089455526322\n",
      "Epoch 2749, Loss: 0.04449654556810856, Final Batch Loss: 0.020494239404797554\n",
      "Epoch 2750, Loss: 0.057319073006510735, Final Batch Loss: 0.0091348085552454\n",
      "Epoch 2751, Loss: 0.0005613718967651948, Final Batch Loss: 0.00018011090287473053\n",
      "Epoch 2752, Loss: 0.0002889384704758413, Final Batch Loss: 7.95572777860798e-05\n",
      "Epoch 2753, Loss: 0.001537717878818512, Final Batch Loss: 0.0006981438491493464\n",
      "Epoch 2754, Loss: 0.05967997433617711, Final Batch Loss: 0.0024700541980564594\n",
      "Epoch 2755, Loss: 0.0044301943853497505, Final Batch Loss: 0.000615833094343543\n",
      "Epoch 2756, Loss: 0.0016109372372739017, Final Batch Loss: 0.0002474185894243419\n",
      "Epoch 2757, Loss: 0.0012705758272204548, Final Batch Loss: 0.00047932154848240316\n",
      "Epoch 2758, Loss: 0.0019544129027053714, Final Batch Loss: 0.000289738061837852\n",
      "Epoch 2759, Loss: 0.0016042166098486632, Final Batch Loss: 0.00030092542874626815\n",
      "Epoch 2760, Loss: 0.0014172994706314057, Final Batch Loss: 0.0010473919101059437\n",
      "Epoch 2761, Loss: 0.0008447822474408895, Final Batch Loss: 0.0003563234640751034\n",
      "Epoch 2762, Loss: 0.03290067898342386, Final Batch Loss: 0.03273632377386093\n",
      "Epoch 2763, Loss: 0.002921297535067424, Final Batch Loss: 0.0003257250355090946\n",
      "Epoch 2764, Loss: 0.0010011586418841034, Final Batch Loss: 0.00045497340033762157\n",
      "Epoch 2765, Loss: 0.0010975980258081108, Final Batch Loss: 0.0006979790632613003\n",
      "Epoch 2766, Loss: 0.013003625499550253, Final Batch Loss: 0.0006626560934819281\n",
      "Epoch 2767, Loss: 0.0009914228285197169, Final Batch Loss: 0.0006646784022450447\n",
      "Epoch 2768, Loss: 0.003418903681449592, Final Batch Loss: 0.0027584333438426256\n",
      "Epoch 2769, Loss: 0.0010543314274400473, Final Batch Loss: 0.00036486948374658823\n",
      "Epoch 2770, Loss: 0.004066253313794732, Final Batch Loss: 0.0029781353659927845\n",
      "Epoch 2771, Loss: 0.005218286911258474, Final Batch Loss: 0.00036835289211012423\n",
      "Epoch 2772, Loss: 0.0012094186386093497, Final Batch Loss: 0.0007653181673958898\n",
      "Epoch 2773, Loss: 0.00032128040766110644, Final Batch Loss: 9.262823004974052e-05\n",
      "Epoch 2774, Loss: 0.0016181233222596347, Final Batch Loss: 0.0008382731466554105\n",
      "Epoch 2775, Loss: 0.0009178719046758488, Final Batch Loss: 0.00019097731274086982\n",
      "Epoch 2776, Loss: 0.012181297468487173, Final Batch Loss: 0.011983070522546768\n",
      "Epoch 2777, Loss: 0.006214269204065204, Final Batch Loss: 0.0002045945730060339\n",
      "Epoch 2778, Loss: 0.002940131031209603, Final Batch Loss: 0.0004374123236630112\n",
      "Epoch 2779, Loss: 0.03679629135876894, Final Batch Loss: 0.021816255524754524\n",
      "Epoch 2780, Loss: 0.0009895068651530892, Final Batch Loss: 0.0002461109252180904\n",
      "Epoch 2781, Loss: 0.0014491908950731158, Final Batch Loss: 0.0008727049571461976\n",
      "Epoch 2782, Loss: 0.011959691648371518, Final Batch Loss: 0.010498606599867344\n",
      "Epoch 2783, Loss: 0.0006624981033382937, Final Batch Loss: 0.000441839947598055\n",
      "Epoch 2784, Loss: 0.0013669124891748652, Final Batch Loss: 0.0012984246714040637\n",
      "Epoch 2785, Loss: 0.0099507873528637, Final Batch Loss: 0.009273982606828213\n",
      "Epoch 2786, Loss: 0.019448530860245228, Final Batch Loss: 0.003421151079237461\n",
      "Epoch 2787, Loss: 0.0021394380019046366, Final Batch Loss: 0.0002649463131092489\n",
      "Epoch 2788, Loss: 0.0022506789537146688, Final Batch Loss: 0.0005311565473675728\n",
      "Epoch 2789, Loss: 0.002843821421265602, Final Batch Loss: 0.0008443719707429409\n",
      "Epoch 2790, Loss: 0.0027993114781565964, Final Batch Loss: 0.0003456273698247969\n",
      "Epoch 2791, Loss: 0.005829391535371542, Final Batch Loss: 0.0014972211793065071\n",
      "Epoch 2792, Loss: 0.08658647001720965, Final Batch Loss: 0.0014945364091545343\n",
      "Epoch 2793, Loss: 0.0018099105218425393, Final Batch Loss: 0.001389778801240027\n",
      "Epoch 2794, Loss: 0.010429968009702861, Final Batch Loss: 0.008509315550327301\n",
      "Epoch 2795, Loss: 0.0020745876827277243, Final Batch Loss: 0.0007601758115924895\n",
      "Epoch 2796, Loss: 0.0028538820915855467, Final Batch Loss: 0.002277614548802376\n",
      "Epoch 2797, Loss: 0.001596237299963832, Final Batch Loss: 0.0007775811245664954\n",
      "Epoch 2798, Loss: 0.0013890041154809296, Final Batch Loss: 0.0005852088797837496\n",
      "Epoch 2799, Loss: 0.002137910109013319, Final Batch Loss: 0.0013906786916777492\n",
      "Epoch 2800, Loss: 0.001032960688462481, Final Batch Loss: 0.0006143710925243795\n",
      "Epoch 2801, Loss: 0.002363242849241942, Final Batch Loss: 0.0008045012946240604\n",
      "Epoch 2802, Loss: 0.0029420300270430744, Final Batch Loss: 0.002253650687634945\n",
      "Epoch 2803, Loss: 0.000955476047238335, Final Batch Loss: 0.0005115005187690258\n",
      "Epoch 2804, Loss: 0.004550483979983255, Final Batch Loss: 0.00027750522713176906\n",
      "Epoch 2805, Loss: 0.00247046300501097, Final Batch Loss: 0.0002304717927472666\n",
      "Epoch 2806, Loss: 0.000357728247763589, Final Batch Loss: 0.00018584598728921264\n",
      "Epoch 2807, Loss: 0.009438384731765836, Final Batch Loss: 0.008681252598762512\n",
      "Epoch 2808, Loss: 0.0007972264720592648, Final Batch Loss: 0.0004991537425667048\n",
      "Epoch 2809, Loss: 0.0022449278039857745, Final Batch Loss: 0.0008049915777519345\n",
      "Epoch 2810, Loss: 0.002592920616734773, Final Batch Loss: 0.0021981524769216776\n",
      "Epoch 2811, Loss: 0.002882774017052725, Final Batch Loss: 0.00033526288461871445\n",
      "Epoch 2812, Loss: 0.0008679928723722696, Final Batch Loss: 0.0005779050989076495\n",
      "Epoch 2813, Loss: 0.0019087569089606404, Final Batch Loss: 0.0007472038269042969\n",
      "Epoch 2814, Loss: 0.0010489431442692876, Final Batch Loss: 0.00046073831617832184\n",
      "Epoch 2815, Loss: 0.0005204788030823693, Final Batch Loss: 0.00016876701556611806\n",
      "Epoch 2816, Loss: 0.0008258555899374187, Final Batch Loss: 0.0002621123567223549\n",
      "Epoch 2817, Loss: 0.0005324487137841061, Final Batch Loss: 0.00023791631974745542\n",
      "Epoch 2818, Loss: 0.006099219550378621, Final Batch Loss: 0.005766433663666248\n",
      "Epoch 2819, Loss: 0.00038046798727009445, Final Batch Loss: 0.00018752604955807328\n",
      "Epoch 2820, Loss: 0.006946615991182625, Final Batch Loss: 0.005890564061701298\n",
      "Epoch 2821, Loss: 0.002659516758285463, Final Batch Loss: 0.0019253968494012952\n",
      "Epoch 2822, Loss: 0.0012989586684852839, Final Batch Loss: 0.0004285414470359683\n",
      "Epoch 2823, Loss: 0.0012690112926065922, Final Batch Loss: 0.0006795099470764399\n",
      "Epoch 2824, Loss: 0.0007235591183416545, Final Batch Loss: 0.00011738884495571256\n",
      "Epoch 2825, Loss: 0.0026671088999137282, Final Batch Loss: 0.0017736897571012378\n",
      "Epoch 2826, Loss: 0.0011901678517460823, Final Batch Loss: 0.0005987277836538851\n",
      "Epoch 2827, Loss: 0.018770452734315768, Final Batch Loss: 0.0002118909324053675\n",
      "Epoch 2828, Loss: 0.0003386660246178508, Final Batch Loss: 0.00012355446233414114\n",
      "Epoch 2829, Loss: 0.0032766860531410202, Final Batch Loss: 0.0031327882315963507\n",
      "Epoch 2830, Loss: 0.0011651979730231687, Final Batch Loss: 0.0001889153354568407\n",
      "Epoch 2831, Loss: 0.0006213604137883522, Final Batch Loss: 0.0005486763548105955\n",
      "Epoch 2832, Loss: 0.001589129795320332, Final Batch Loss: 0.0010569687001407146\n",
      "Epoch 2833, Loss: 0.003299415286164731, Final Batch Loss: 0.0031727361492812634\n",
      "Epoch 2834, Loss: 0.003268616128480062, Final Batch Loss: 0.00012650838471017778\n",
      "Epoch 2835, Loss: 0.0010360432788729668, Final Batch Loss: 0.0006071157404221594\n",
      "Epoch 2836, Loss: 0.0006337080558296293, Final Batch Loss: 0.00018063216703012586\n",
      "Epoch 2837, Loss: 0.000976905197603628, Final Batch Loss: 0.0009427174809388816\n",
      "Epoch 2838, Loss: 0.000811476435046643, Final Batch Loss: 0.0005371763836592436\n",
      "Epoch 2839, Loss: 0.0022166831186041236, Final Batch Loss: 0.0004198747919872403\n",
      "Epoch 2840, Loss: 0.0008020343375392258, Final Batch Loss: 0.0005471807671710849\n",
      "Epoch 2841, Loss: 0.0005031832406530157, Final Batch Loss: 0.00023755944857839495\n",
      "Epoch 2842, Loss: 0.004282278969185427, Final Batch Loss: 0.0003501363389659673\n",
      "Epoch 2843, Loss: 0.0008962706633610651, Final Batch Loss: 0.0007244274602271616\n",
      "Epoch 2844, Loss: 0.0006218465423444286, Final Batch Loss: 0.0002358297206228599\n",
      "Epoch 2845, Loss: 0.0006478379509644583, Final Batch Loss: 0.00044223491568118334\n",
      "Epoch 2846, Loss: 0.002462847565766424, Final Batch Loss: 0.0017214053077623248\n",
      "Epoch 2847, Loss: 0.0022363843163475394, Final Batch Loss: 0.0005095404339954257\n",
      "Epoch 2848, Loss: 0.0006950630631763488, Final Batch Loss: 0.0004702938604168594\n",
      "Epoch 2849, Loss: 0.0005898666277062148, Final Batch Loss: 0.0002573477104306221\n",
      "Epoch 2850, Loss: 0.003903987424564548, Final Batch Loss: 0.0038072799798101187\n",
      "Epoch 2851, Loss: 0.01393513398943469, Final Batch Loss: 0.01377062313258648\n",
      "Epoch 2852, Loss: 0.0007681457500439137, Final Batch Loss: 0.00026087803416885436\n",
      "Epoch 2853, Loss: 0.011126340890768915, Final Batch Loss: 0.01054083090275526\n",
      "Epoch 2854, Loss: 0.07610286772251129, Final Batch Loss: 0.06316965818405151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2855, Loss: 0.009441566420719028, Final Batch Loss: 0.0024909910280257463\n",
      "Epoch 2856, Loss: 0.0014820850774412975, Final Batch Loss: 0.00015734600310679525\n",
      "Epoch 2857, Loss: 0.0015444262826349586, Final Batch Loss: 0.00045664291246794164\n",
      "Epoch 2858, Loss: 0.0014233756519388407, Final Batch Loss: 0.0004128273285459727\n",
      "Epoch 2859, Loss: 0.0006250127917155623, Final Batch Loss: 0.00032823102083057165\n",
      "Epoch 2860, Loss: 0.0078101446852087975, Final Batch Loss: 0.004015774931758642\n",
      "Epoch 2861, Loss: 0.002254731924040243, Final Batch Loss: 0.00035609243786893785\n",
      "Epoch 2862, Loss: 0.002134294423740357, Final Batch Loss: 0.0013453552965074778\n",
      "Epoch 2863, Loss: 0.0030465604504570365, Final Batch Loss: 0.0017572084907442331\n",
      "Epoch 2864, Loss: 0.03835893888026476, Final Batch Loss: 0.03347161039710045\n",
      "Epoch 2865, Loss: 0.0018618770991452038, Final Batch Loss: 0.000696896982844919\n",
      "Epoch 2866, Loss: 0.0069126279558986425, Final Batch Loss: 0.006371010094881058\n",
      "Epoch 2867, Loss: 0.02421852108091116, Final Batch Loss: 0.008264117874205112\n",
      "Epoch 2868, Loss: 0.008920733875129372, Final Batch Loss: 0.008062818087637424\n",
      "Epoch 2869, Loss: 0.014106083195656538, Final Batch Loss: 0.007225989829748869\n",
      "Epoch 2870, Loss: 0.0015721485251560807, Final Batch Loss: 0.0008495769579894841\n",
      "Epoch 2871, Loss: 0.0010627763986121863, Final Batch Loss: 0.0002806319098453969\n",
      "Epoch 2872, Loss: 0.0009575864824000746, Final Batch Loss: 0.00028645663405768573\n",
      "Epoch 2873, Loss: 0.003992197569459677, Final Batch Loss: 0.0037487447261810303\n",
      "Epoch 2874, Loss: 0.006602489214856178, Final Batch Loss: 0.0007437824388034642\n",
      "Epoch 2875, Loss: 0.0021020405692979693, Final Batch Loss: 0.0014978073304519057\n",
      "Epoch 2876, Loss: 0.004867983254371211, Final Batch Loss: 0.00048537758993916214\n",
      "Epoch 2877, Loss: 0.0022513052681460977, Final Batch Loss: 0.0005124093731865287\n",
      "Epoch 2878, Loss: 0.00368452665861696, Final Batch Loss: 0.0029083893168717623\n",
      "Epoch 2879, Loss: 0.0013094840396661311, Final Batch Loss: 0.0009377831593155861\n",
      "Epoch 2880, Loss: 0.0009186979732476175, Final Batch Loss: 0.000552067591343075\n",
      "Epoch 2881, Loss: 0.001723974070046097, Final Batch Loss: 0.0011775112943723798\n",
      "Epoch 2882, Loss: 0.004842655849643052, Final Batch Loss: 0.004551878664642572\n",
      "Epoch 2883, Loss: 0.0008971423521870747, Final Batch Loss: 0.00016293478256557137\n",
      "Epoch 2884, Loss: 0.0006500094605144113, Final Batch Loss: 0.0003705584385897964\n",
      "Epoch 2885, Loss: 0.06167274812469259, Final Batch Loss: 0.06147851422429085\n",
      "Epoch 2886, Loss: 0.0033864426077343524, Final Batch Loss: 0.0008722465136088431\n",
      "Epoch 2887, Loss: 0.0009431320067960769, Final Batch Loss: 0.00046547138481400907\n",
      "Epoch 2888, Loss: 0.001302639371715486, Final Batch Loss: 0.0004908964619971812\n",
      "Epoch 2889, Loss: 0.0027652535354718566, Final Batch Loss: 0.0007220626575872302\n",
      "Epoch 2890, Loss: 0.000598117578192614, Final Batch Loss: 0.00012567882367875427\n",
      "Epoch 2891, Loss: 0.0005522042920347303, Final Batch Loss: 0.000320797465974465\n",
      "Epoch 2892, Loss: 0.0003838478878606111, Final Batch Loss: 0.0001702874869806692\n",
      "Epoch 2893, Loss: 0.0030313238385133445, Final Batch Loss: 0.0025400349404662848\n",
      "Epoch 2894, Loss: 0.0006605692324228585, Final Batch Loss: 0.00027929237694479525\n",
      "Epoch 2895, Loss: 0.00072606818866916, Final Batch Loss: 0.0002532590879127383\n",
      "Epoch 2896, Loss: 0.0020968536846339703, Final Batch Loss: 0.0009953412227332592\n",
      "Epoch 2897, Loss: 0.002627691952511668, Final Batch Loss: 0.0006304497364908457\n",
      "Epoch 2898, Loss: 0.0035370609839446843, Final Batch Loss: 0.0003174418234266341\n",
      "Epoch 2899, Loss: 0.023027284012641758, Final Batch Loss: 0.022402413189411163\n",
      "Epoch 2900, Loss: 0.001847386418376118, Final Batch Loss: 0.0010950230062007904\n",
      "Epoch 2901, Loss: 0.0019779509166255593, Final Batch Loss: 0.0007628473686054349\n",
      "Epoch 2902, Loss: 0.01881193768349476, Final Batch Loss: 0.018445033580064774\n",
      "Epoch 2903, Loss: 0.0004984695842722431, Final Batch Loss: 0.00013814867998007685\n",
      "Epoch 2904, Loss: 0.0006096955912653357, Final Batch Loss: 0.0002755003806669265\n",
      "Epoch 2905, Loss: 0.0008023618720471859, Final Batch Loss: 0.00042578752618283033\n",
      "Epoch 2906, Loss: 0.001650983322178945, Final Batch Loss: 0.0012026965850964189\n",
      "Epoch 2907, Loss: 0.0010960184154100716, Final Batch Loss: 0.0006259173387661576\n",
      "Epoch 2908, Loss: 0.0011413483589421958, Final Batch Loss: 0.0008671781979501247\n",
      "Epoch 2909, Loss: 0.00161748070968315, Final Batch Loss: 6.336282240226865e-05\n",
      "Epoch 2910, Loss: 0.00030286396213341504, Final Batch Loss: 0.0001580915559316054\n",
      "Epoch 2911, Loss: 0.0013857790036126971, Final Batch Loss: 0.0003115885192528367\n",
      "Epoch 2912, Loss: 0.0006639390776399523, Final Batch Loss: 0.00035480267251841724\n",
      "Epoch 2913, Loss: 0.011710742488503456, Final Batch Loss: 0.010433820076286793\n",
      "Epoch 2914, Loss: 0.0005158876301720738, Final Batch Loss: 0.00015170522965490818\n",
      "Epoch 2915, Loss: 0.0019535570172592998, Final Batch Loss: 0.0005920911207795143\n",
      "Epoch 2916, Loss: 0.0005791144430986606, Final Batch Loss: 0.00012076703569618985\n",
      "Epoch 2917, Loss: 0.0005763801891589537, Final Batch Loss: 0.00020443795074243098\n",
      "Epoch 2918, Loss: 0.009335149225080386, Final Batch Loss: 0.0002031551266554743\n",
      "Epoch 2919, Loss: 0.02499275328591466, Final Batch Loss: 0.0019150902517139912\n",
      "Epoch 2920, Loss: 0.0012387850147206336, Final Batch Loss: 0.0009426249307580292\n",
      "Epoch 2921, Loss: 0.0009690831939224154, Final Batch Loss: 0.0006033184472471476\n",
      "Epoch 2922, Loss: 0.000805525342002511, Final Batch Loss: 0.000608291185926646\n",
      "Epoch 2923, Loss: 0.0018396543855487835, Final Batch Loss: 4.507925405050628e-05\n",
      "Epoch 2924, Loss: 0.000553826946998015, Final Batch Loss: 0.00036295640165917575\n",
      "Epoch 2925, Loss: 0.0005326954560587183, Final Batch Loss: 0.0003412532387301326\n",
      "Epoch 2926, Loss: 0.0008284640207421035, Final Batch Loss: 0.0005090428167022765\n",
      "Epoch 2927, Loss: 0.000974341353867203, Final Batch Loss: 0.0005354098393581808\n",
      "Epoch 2928, Loss: 0.0023034485056996346, Final Batch Loss: 0.0018214278388768435\n",
      "Epoch 2929, Loss: 0.0007643659191671759, Final Batch Loss: 0.00033704281668178737\n",
      "Epoch 2930, Loss: 0.0021054164390079677, Final Batch Loss: 0.00038695469265803695\n",
      "Epoch 2931, Loss: 0.0021859864937141538, Final Batch Loss: 0.0010070300195366144\n",
      "Epoch 2932, Loss: 0.0014400758082047105, Final Batch Loss: 0.0009745240677148104\n",
      "Epoch 2933, Loss: 0.0008841669769026339, Final Batch Loss: 0.0004246149037498981\n",
      "Epoch 2934, Loss: 0.0008566225005779415, Final Batch Loss: 0.0001636674569454044\n",
      "Epoch 2935, Loss: 0.0005612480454146862, Final Batch Loss: 0.0002532486105337739\n",
      "Epoch 2936, Loss: 0.001459935971070081, Final Batch Loss: 0.000206535158213228\n",
      "Epoch 2937, Loss: 0.0010025388619396836, Final Batch Loss: 0.00039665374788455665\n",
      "Epoch 2938, Loss: 0.0004921467188978568, Final Batch Loss: 0.00026124287978745997\n",
      "Epoch 2939, Loss: 0.000360520338290371, Final Batch Loss: 0.000224720875849016\n",
      "Epoch 2940, Loss: 0.0012666861293837428, Final Batch Loss: 0.0007440113113261759\n",
      "Epoch 2941, Loss: 0.005174257152248174, Final Batch Loss: 0.0007084904354996979\n",
      "Epoch 2942, Loss: 0.0005287695385050029, Final Batch Loss: 0.000293978228000924\n",
      "Epoch 2943, Loss: 0.0058183284709230065, Final Batch Loss: 0.0003509811358526349\n",
      "Epoch 2944, Loss: 0.0015838387189432979, Final Batch Loss: 0.0012506525963544846\n",
      "Epoch 2945, Loss: 0.0014358984772115946, Final Batch Loss: 0.000760492985136807\n",
      "Epoch 2946, Loss: 0.0004380510072223842, Final Batch Loss: 0.0001440283958800137\n",
      "Epoch 2947, Loss: 0.0030163422343321145, Final Batch Loss: 0.0028059734031558037\n",
      "Epoch 2948, Loss: 0.006921087377122603, Final Batch Loss: 0.00013235023652669042\n",
      "Epoch 2949, Loss: 0.007481581764295697, Final Batch Loss: 0.0038431123830378056\n",
      "Epoch 2950, Loss: 0.0016205705469474196, Final Batch Loss: 0.0005913317436352372\n",
      "Epoch 2951, Loss: 0.002725050813751295, Final Batch Loss: 0.0004106480919290334\n",
      "Epoch 2952, Loss: 0.022107706288807094, Final Batch Loss: 0.02115803398191929\n",
      "Epoch 2953, Loss: 0.00228443033847725, Final Batch Loss: 0.0021684858947992325\n",
      "Epoch 2954, Loss: 0.021149726526346058, Final Batch Loss: 0.020261071622371674\n",
      "Epoch 2955, Loss: 0.016727442387491465, Final Batch Loss: 0.01364732626825571\n",
      "Epoch 2956, Loss: 0.0014660038577858359, Final Batch Loss: 0.0013348791981115937\n",
      "Epoch 2957, Loss: 0.0003305308782728389, Final Batch Loss: 0.00013407367805484682\n",
      "Epoch 2958, Loss: 0.001480581471696496, Final Batch Loss: 0.0007817908190190792\n",
      "Epoch 2959, Loss: 0.0017143847071565688, Final Batch Loss: 0.0008366892579942942\n",
      "Epoch 2960, Loss: 0.006037249928340316, Final Batch Loss: 0.004516747780144215\n",
      "Epoch 2961, Loss: 0.007866045227274299, Final Batch Loss: 0.001197148347273469\n",
      "Epoch 2962, Loss: 0.0015485489275306463, Final Batch Loss: 0.0008962746360339224\n",
      "Epoch 2963, Loss: 0.001998195599298924, Final Batch Loss: 0.0007376470020972192\n",
      "Epoch 2964, Loss: 0.0006788732862332836, Final Batch Loss: 0.00019819270528387278\n",
      "Epoch 2965, Loss: 0.0004254418599884957, Final Batch Loss: 0.00021982267207931727\n",
      "Epoch 2966, Loss: 0.0038914126344025135, Final Batch Loss: 0.0005013304762542248\n",
      "Epoch 2967, Loss: 0.0012534719571704045, Final Batch Loss: 0.00018451678624842316\n",
      "Epoch 2968, Loss: 0.0021546191856032237, Final Batch Loss: 0.00016960779612418264\n",
      "Epoch 2969, Loss: 0.0009461724839638919, Final Batch Loss: 0.0002726011152844876\n",
      "Epoch 2970, Loss: 0.0033607493387535214, Final Batch Loss: 0.0008777437033131719\n",
      "Epoch 2971, Loss: 0.0019724584562936798, Final Batch Loss: 0.00013477403263095766\n",
      "Epoch 2972, Loss: 0.001554774644318968, Final Batch Loss: 0.00013370002852752805\n",
      "Epoch 2973, Loss: 0.0015802785637788475, Final Batch Loss: 0.0009652315638959408\n",
      "Epoch 2974, Loss: 0.000669033732265234, Final Batch Loss: 0.00050841283518821\n",
      "Epoch 2975, Loss: 0.0023313642013818026, Final Batch Loss: 0.0009722097311168909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2976, Loss: 0.0007198435632744804, Final Batch Loss: 0.0005318679031915963\n",
      "Epoch 2977, Loss: 0.003967056545661762, Final Batch Loss: 7.348510553129017e-05\n",
      "Epoch 2978, Loss: 0.006374228047206998, Final Batch Loss: 0.0008844465482980013\n",
      "Epoch 2979, Loss: 0.0015736684144940227, Final Batch Loss: 0.0013395525747910142\n",
      "Epoch 2980, Loss: 0.000806928685051389, Final Batch Loss: 0.00015470154176000506\n",
      "Epoch 2981, Loss: 0.014132821204839274, Final Batch Loss: 0.00018113313126377761\n",
      "Epoch 2982, Loss: 0.004241634451318532, Final Batch Loss: 0.0003137111780233681\n",
      "Epoch 2983, Loss: 0.0013155671767890453, Final Batch Loss: 0.0005367752746678889\n",
      "Epoch 2984, Loss: 0.008431482870946638, Final Batch Loss: 0.00016362387395929545\n",
      "Epoch 2985, Loss: 0.00031162163941189647, Final Batch Loss: 0.00013066496467217803\n",
      "Epoch 2986, Loss: 0.0021890842326683924, Final Batch Loss: 0.000153879911522381\n",
      "Epoch 2987, Loss: 0.000735722336685285, Final Batch Loss: 0.000374138995539397\n",
      "Epoch 2988, Loss: 0.0008681292383698747, Final Batch Loss: 0.00024267779372166842\n",
      "Epoch 2989, Loss: 0.005572385853156447, Final Batch Loss: 0.004832406062632799\n",
      "Epoch 2990, Loss: 0.00122871229541488, Final Batch Loss: 0.0007994450279511511\n",
      "Epoch 2991, Loss: 0.0005442947294795886, Final Batch Loss: 0.0002407177962595597\n",
      "Epoch 2992, Loss: 0.0012244789686519653, Final Batch Loss: 0.0004663390282075852\n",
      "Epoch 2993, Loss: 0.0028841184685006738, Final Batch Loss: 0.0008896802319213748\n",
      "Epoch 2994, Loss: 0.0036113788082730025, Final Batch Loss: 0.003357195295393467\n",
      "Epoch 2995, Loss: 0.00186261348426342, Final Batch Loss: 0.0005847590509802103\n",
      "Epoch 2996, Loss: 0.010104779154062271, Final Batch Loss: 0.001973547041416168\n",
      "Epoch 2997, Loss: 0.0022248092864174396, Final Batch Loss: 0.001764126936905086\n",
      "Epoch 2998, Loss: 0.0013407088408712298, Final Batch Loss: 0.0003426729526836425\n",
      "Epoch 2999, Loss: 0.005467771552503109, Final Batch Loss: 0.0030865794979035854\n",
      "Epoch 3000, Loss: 0.0006230497820070013, Final Batch Loss: 0.00015060884470585734\n",
      "Epoch 3001, Loss: 0.007746322778984904, Final Batch Loss: 0.006352934520691633\n",
      "Epoch 3002, Loss: 0.0005376050248742104, Final Batch Loss: 4.8133544623851776e-05\n",
      "Epoch 3003, Loss: 0.0034422249445924535, Final Batch Loss: 0.00010747242777142674\n",
      "Epoch 3004, Loss: 0.0007418817331199534, Final Batch Loss: 0.0001056306718965061\n",
      "Epoch 3005, Loss: 0.012605996977072209, Final Batch Loss: 0.011807986535131931\n",
      "Epoch 3006, Loss: 0.0006961004983168095, Final Batch Loss: 0.0005312153953127563\n",
      "Epoch 3007, Loss: 0.017229969409527257, Final Batch Loss: 0.01697865128517151\n",
      "Epoch 3008, Loss: 0.0015129123348742723, Final Batch Loss: 0.0008311186102218926\n",
      "Epoch 3009, Loss: 0.0012803453719243407, Final Batch Loss: 0.00017884490080177784\n",
      "Epoch 3010, Loss: 0.0007596405557706021, Final Batch Loss: 0.00010775666305562481\n",
      "Epoch 3011, Loss: 0.00031177701021078974, Final Batch Loss: 0.00015742290997877717\n",
      "Epoch 3012, Loss: 0.005431501645944081, Final Batch Loss: 0.005255242343991995\n",
      "Epoch 3013, Loss: 0.0040442843092023395, Final Batch Loss: 0.00011800901120295748\n",
      "Epoch 3014, Loss: 0.0008172504021786153, Final Batch Loss: 0.0005079731927253306\n",
      "Epoch 3015, Loss: 0.008222310716519132, Final Batch Loss: 0.007968173362314701\n",
      "Epoch 3016, Loss: 0.00042729845154099166, Final Batch Loss: 0.00033942348090931773\n",
      "Epoch 3017, Loss: 0.00020329413018771447, Final Batch Loss: 0.00015006009198259562\n",
      "Epoch 3018, Loss: 0.000290704649160034, Final Batch Loss: 2.9866312615922652e-05\n",
      "Epoch 3019, Loss: 0.0004892348515568301, Final Batch Loss: 6.776674126740545e-05\n",
      "Epoch 3020, Loss: 0.00990206003189087, Final Batch Loss: 0.0008237920701503754\n",
      "Epoch 3021, Loss: 0.0006078600999899209, Final Batch Loss: 0.00034697316004894674\n",
      "Epoch 3022, Loss: 0.000907034394913353, Final Batch Loss: 0.00014575869136024266\n",
      "Epoch 3023, Loss: 0.0003470591764198616, Final Batch Loss: 0.00016055075684562325\n",
      "Epoch 3024, Loss: 0.05069304024800658, Final Batch Loss: 0.04511069133877754\n",
      "Epoch 3025, Loss: 0.0029540291652665474, Final Batch Loss: 0.00010299791028955951\n",
      "Epoch 3026, Loss: 0.0004494116292335093, Final Batch Loss: 0.00012134740245528519\n",
      "Epoch 3027, Loss: 0.00021267002739477903, Final Batch Loss: 5.398289067670703e-05\n",
      "Epoch 3028, Loss: 0.0018316982022952288, Final Batch Loss: 0.00015890304348431528\n",
      "Epoch 3029, Loss: 0.00030533083918271586, Final Batch Loss: 9.291907917940989e-05\n",
      "Epoch 3030, Loss: 0.016139024344738573, Final Batch Loss: 0.0002729310072027147\n",
      "Epoch 3031, Loss: 0.0007021247238299111, Final Batch Loss: 2.4514267352060415e-05\n",
      "Epoch 3032, Loss: 0.0004215696098981425, Final Batch Loss: 0.00024363939883187413\n",
      "Epoch 3033, Loss: 0.0014819684147369117, Final Batch Loss: 0.000164278520969674\n",
      "Epoch 3034, Loss: 0.021606182563118637, Final Batch Loss: 0.02033902145922184\n",
      "Epoch 3035, Loss: 0.002089588320814073, Final Batch Loss: 0.0011614925460889935\n",
      "Epoch 3036, Loss: 0.00900156494753901, Final Batch Loss: 0.00011201367306057364\n",
      "Epoch 3037, Loss: 0.015701882730354555, Final Batch Loss: 0.00020287763618398458\n",
      "Epoch 3038, Loss: 0.0019696514355018735, Final Batch Loss: 0.0013225299771875143\n",
      "Epoch 3039, Loss: 0.0018640141352079809, Final Batch Loss: 0.001079483306966722\n",
      "Epoch 3040, Loss: 0.0034770898637361825, Final Batch Loss: 0.00045438279630616307\n",
      "Epoch 3041, Loss: 0.000962647667620331, Final Batch Loss: 0.0006960799801163375\n",
      "Epoch 3042, Loss: 0.03429677244275808, Final Batch Loss: 0.00026484858244657516\n",
      "Epoch 3043, Loss: 0.005038621893618256, Final Batch Loss: 0.0002460894756950438\n",
      "Epoch 3044, Loss: 0.002581858483608812, Final Batch Loss: 0.0006047081551514566\n",
      "Epoch 3045, Loss: 0.001987401978112757, Final Batch Loss: 0.0014461312675848603\n",
      "Epoch 3046, Loss: 0.000711835891706869, Final Batch Loss: 0.0005113307270221412\n",
      "Epoch 3047, Loss: 0.001002453253022395, Final Batch Loss: 0.00017880926316138357\n",
      "Epoch 3048, Loss: 0.0006523204792756587, Final Batch Loss: 0.00026270555099472404\n",
      "Epoch 3049, Loss: 0.0027845574950333685, Final Batch Loss: 0.0024319130461663008\n",
      "Epoch 3050, Loss: 0.0009063399338629097, Final Batch Loss: 0.0005275571020320058\n",
      "Epoch 3051, Loss: 0.002520417794585228, Final Batch Loss: 0.001235945033840835\n",
      "Epoch 3052, Loss: 0.0010549219732638448, Final Batch Loss: 0.000692602654453367\n",
      "Epoch 3053, Loss: 0.0014624804898630828, Final Batch Loss: 0.0002127579355146736\n",
      "Epoch 3054, Loss: 0.0005872425244888291, Final Batch Loss: 0.0001720896252663806\n",
      "Epoch 3055, Loss: 0.001628213853109628, Final Batch Loss: 0.0013516192557290196\n",
      "Epoch 3056, Loss: 0.03473232174292207, Final Batch Loss: 0.03035951778292656\n",
      "Epoch 3057, Loss: 0.0003663900188257685, Final Batch Loss: 2.0393816157593392e-05\n",
      "Epoch 3058, Loss: 0.0013993177562952042, Final Batch Loss: 0.0006039379513822496\n",
      "Epoch 3059, Loss: 0.0007460819615516812, Final Batch Loss: 0.0002057535166386515\n",
      "Epoch 3060, Loss: 0.0013705625315196812, Final Batch Loss: 0.00023213675012812018\n",
      "Epoch 3061, Loss: 0.0002701702032936737, Final Batch Loss: 0.0001158079830929637\n",
      "Epoch 3062, Loss: 0.0001882253636722453, Final Batch Loss: 8.600824367022142e-05\n",
      "Epoch 3063, Loss: 0.11553911498049274, Final Batch Loss: 0.0005915351794101298\n",
      "Epoch 3064, Loss: 0.00036030670889886096, Final Batch Loss: 6.109904643381014e-05\n",
      "Epoch 3065, Loss: 0.00156642054207623, Final Batch Loss: 0.0001112957252189517\n",
      "Epoch 3066, Loss: 0.00018778094818117097, Final Batch Loss: 9.941857570083812e-05\n",
      "Epoch 3067, Loss: 0.001631932333111763, Final Batch Loss: 0.0013819618616253138\n",
      "Epoch 3068, Loss: 0.000682908168528229, Final Batch Loss: 9.433849481865764e-05\n",
      "Epoch 3069, Loss: 0.0006755198119208217, Final Batch Loss: 0.0001779409940354526\n",
      "Epoch 3070, Loss: 0.0018979533342644572, Final Batch Loss: 0.001236588810570538\n",
      "Epoch 3071, Loss: 0.0006670455331914127, Final Batch Loss: 0.0002992495719809085\n",
      "Epoch 3072, Loss: 0.0003566662853700109, Final Batch Loss: 9.577055607223883e-05\n",
      "Epoch 3073, Loss: 0.0029867783887311816, Final Batch Loss: 0.0009488601936027408\n",
      "Epoch 3074, Loss: 0.0004968936846125871, Final Batch Loss: 0.0002014649799093604\n",
      "Epoch 3075, Loss: 0.00183676861342974, Final Batch Loss: 0.001394309219904244\n",
      "Epoch 3076, Loss: 0.0025418734367121942, Final Batch Loss: 8.975395030574873e-05\n",
      "Epoch 3077, Loss: 0.009416842804057524, Final Batch Loss: 0.009040573611855507\n",
      "Epoch 3078, Loss: 0.0007662428251933306, Final Batch Loss: 0.00042186002247035503\n",
      "Epoch 3079, Loss: 0.0007987405551830307, Final Batch Loss: 0.0005948821199126542\n",
      "Epoch 3080, Loss: 0.006912786629982293, Final Batch Loss: 0.0011837385827675462\n",
      "Epoch 3081, Loss: 0.00013623175618704408, Final Batch Loss: 4.4409665861167014e-05\n",
      "Epoch 3082, Loss: 0.000707004961441271, Final Batch Loss: 0.00019469296967145056\n",
      "Epoch 3083, Loss: 0.0011054303613491356, Final Batch Loss: 0.0006345454021357\n",
      "Epoch 3084, Loss: 0.0010697791585698724, Final Batch Loss: 0.0004908505943603814\n",
      "Epoch 3085, Loss: 0.004611277036019601, Final Batch Loss: 0.004455350339412689\n",
      "Epoch 3086, Loss: 0.0012824989098589867, Final Batch Loss: 0.0009020266588777304\n",
      "Epoch 3087, Loss: 0.003711003693751991, Final Batch Loss: 0.002731108805164695\n",
      "Epoch 3088, Loss: 0.0014656836283393204, Final Batch Loss: 0.0004561285604722798\n",
      "Epoch 3089, Loss: 0.004686332540586591, Final Batch Loss: 0.00022522429935634136\n",
      "Epoch 3090, Loss: 0.005343901109881699, Final Batch Loss: 0.00119804369751364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3091, Loss: 0.0013268741895444691, Final Batch Loss: 0.001011344720609486\n",
      "Epoch 3092, Loss: 0.0006758377276128158, Final Batch Loss: 0.0004460264462977648\n",
      "Epoch 3093, Loss: 0.0018422382418066263, Final Batch Loss: 0.0012804835569113493\n",
      "Epoch 3094, Loss: 0.0005316756432875991, Final Batch Loss: 0.0002538991393521428\n",
      "Epoch 3095, Loss: 0.0006553755374625325, Final Batch Loss: 0.00024436417152173817\n",
      "Epoch 3096, Loss: 0.005411105812527239, Final Batch Loss: 0.0013392368564382195\n",
      "Epoch 3097, Loss: 0.005808564335893607, Final Batch Loss: 4.49800536443945e-05\n",
      "Epoch 3098, Loss: 0.003374212745256955, Final Batch Loss: 1.9069851987296715e-05\n",
      "Epoch 3099, Loss: 0.0013145761186024174, Final Batch Loss: 0.0001358592271571979\n",
      "Epoch 3100, Loss: 0.000410667184041813, Final Batch Loss: 0.00022351715597324073\n",
      "Epoch 3101, Loss: 0.001374796440359205, Final Batch Loss: 0.0012817211681976914\n",
      "Epoch 3102, Loss: 0.0031136200996115804, Final Batch Loss: 0.0025873736012727022\n",
      "Epoch 3103, Loss: 0.0013086465187370777, Final Batch Loss: 0.0002828278811648488\n",
      "Epoch 3104, Loss: 0.0004462241049623117, Final Batch Loss: 0.0002424034901196137\n",
      "Epoch 3105, Loss: 0.0024591248875367455, Final Batch Loss: 0.0023379072081297636\n",
      "Epoch 3106, Loss: 0.0007760182052152231, Final Batch Loss: 0.0005679517635144293\n",
      "Epoch 3107, Loss: 0.0006534889980684966, Final Batch Loss: 0.00030388031154870987\n",
      "Epoch 3108, Loss: 0.0007222536951303482, Final Batch Loss: 0.00038491038139909506\n",
      "Epoch 3109, Loss: 0.0017161285504698753, Final Batch Loss: 0.0005861765239387751\n",
      "Epoch 3110, Loss: 0.0015334346680901945, Final Batch Loss: 0.0007763648754917085\n",
      "Epoch 3111, Loss: 0.0021862440335098654, Final Batch Loss: 0.0002741478674579412\n",
      "Epoch 3112, Loss: 0.0033824374695541337, Final Batch Loss: 0.0002284707297803834\n",
      "Epoch 3113, Loss: 0.0005994991661282256, Final Batch Loss: 0.00016112295270431787\n",
      "Epoch 3114, Loss: 0.0014896421344019473, Final Batch Loss: 0.0007995196501724422\n",
      "Epoch 3115, Loss: 0.00037369129131548107, Final Batch Loss: 8.455358329229057e-05\n",
      "Epoch 3116, Loss: 0.0014806071994826198, Final Batch Loss: 0.0008600109722465277\n",
      "Epoch 3117, Loss: 0.00032230132637778297, Final Batch Loss: 8.470711327390745e-05\n",
      "Epoch 3118, Loss: 0.0009948820516001433, Final Batch Loss: 0.0005453724297694862\n",
      "Epoch 3119, Loss: 0.000489321057102643, Final Batch Loss: 0.0003172751748934388\n",
      "Epoch 3120, Loss: 0.000547893883776851, Final Batch Loss: 0.00043873355025425553\n",
      "Epoch 3121, Loss: 0.0006649391580140218, Final Batch Loss: 0.00010255111556034535\n",
      "Epoch 3122, Loss: 0.0035586741869337857, Final Batch Loss: 0.002769751474261284\n",
      "Epoch 3123, Loss: 0.00013576543278759345, Final Batch Loss: 4.832450213143602e-05\n",
      "Epoch 3124, Loss: 0.0008974753072834574, Final Batch Loss: 0.0008228284423239529\n",
      "Epoch 3125, Loss: 0.00042119775025639683, Final Batch Loss: 0.00015311197785194963\n",
      "Epoch 3126, Loss: 0.0020559162367135286, Final Batch Loss: 0.0005081684794276953\n",
      "Epoch 3127, Loss: 0.00017733301501721144, Final Batch Loss: 0.00011006015120074153\n",
      "Epoch 3128, Loss: 0.0009392723150085658, Final Batch Loss: 0.0005232524708844721\n",
      "Epoch 3129, Loss: 0.0004621163534466177, Final Batch Loss: 0.00022524887754116207\n",
      "Epoch 3130, Loss: 0.0002743228542385623, Final Batch Loss: 0.000148241626447998\n",
      "Epoch 3131, Loss: 0.00023931460600579157, Final Batch Loss: 0.00011252192052779719\n",
      "Epoch 3132, Loss: 0.003093970532063395, Final Batch Loss: 0.0008159014978446066\n",
      "Epoch 3133, Loss: 0.00021342850959626958, Final Batch Loss: 0.00013039330951869488\n",
      "Epoch 3134, Loss: 0.00035456074692774564, Final Batch Loss: 0.00023123675782699138\n",
      "Epoch 3135, Loss: 0.0038536416250281036, Final Batch Loss: 0.0036024118307977915\n",
      "Epoch 3136, Loss: 0.0003369300247868523, Final Batch Loss: 0.0001571981265442446\n",
      "Epoch 3137, Loss: 0.0029142459388822317, Final Batch Loss: 6.938423030078411e-05\n",
      "Epoch 3138, Loss: 0.004830521967960522, Final Batch Loss: 0.0003903791948687285\n",
      "Epoch 3139, Loss: 0.0016259496187558398, Final Batch Loss: 0.0014823181554675102\n",
      "Epoch 3140, Loss: 0.0023462983081117272, Final Batch Loss: 0.0009025735780596733\n",
      "Epoch 3141, Loss: 0.0006851374637335539, Final Batch Loss: 0.0004886355600319803\n",
      "Epoch 3142, Loss: 0.001984151662327349, Final Batch Loss: 0.0014071300392970443\n",
      "Epoch 3143, Loss: 0.0011220469896215945, Final Batch Loss: 0.000647730368655175\n",
      "Epoch 3144, Loss: 0.0005214385746512562, Final Batch Loss: 0.0002445415302645415\n",
      "Epoch 3145, Loss: 0.0009457774140173569, Final Batch Loss: 0.0007700750138610601\n",
      "Epoch 3146, Loss: 0.0011675248970277607, Final Batch Loss: 0.00102163664996624\n",
      "Epoch 3147, Loss: 0.001045837445417419, Final Batch Loss: 0.0006773648783564568\n",
      "Epoch 3148, Loss: 0.00010639081301633269, Final Batch Loss: 4.757376154884696e-05\n",
      "Epoch 3149, Loss: 0.0017377230687998235, Final Batch Loss: 8.286378579214215e-05\n",
      "Epoch 3150, Loss: 0.0010687565809348598, Final Batch Loss: 0.0008643323089927435\n",
      "Epoch 3151, Loss: 0.0001889153390948195, Final Batch Loss: 5.895116555620916e-05\n",
      "Epoch 3152, Loss: 0.0012863890951848589, Final Batch Loss: 0.00012014959793305025\n",
      "Epoch 3153, Loss: 0.0005536048411158845, Final Batch Loss: 0.00010212870256509632\n",
      "Epoch 3154, Loss: 0.00034839757427107543, Final Batch Loss: 0.00014987225586082786\n",
      "Epoch 3155, Loss: 0.0005067457095719874, Final Batch Loss: 0.00041409957339055836\n",
      "Epoch 3156, Loss: 0.00027573380430112593, Final Batch Loss: 5.874970156583004e-05\n",
      "Epoch 3157, Loss: 0.0007489530689781532, Final Batch Loss: 0.0005397493368946016\n",
      "Epoch 3158, Loss: 0.0007365887067862786, Final Batch Loss: 0.0006615046295337379\n",
      "Epoch 3159, Loss: 0.001415934082615422, Final Batch Loss: 5.9063680964754894e-05\n",
      "Epoch 3160, Loss: 0.0006715622002957389, Final Batch Loss: 9.656713518779725e-05\n",
      "Epoch 3161, Loss: 0.0006129764951765537, Final Batch Loss: 0.00017817632760852575\n",
      "Epoch 3162, Loss: 0.0005932959611527622, Final Batch Loss: 0.0002854014455806464\n",
      "Epoch 3163, Loss: 0.0002598534993012436, Final Batch Loss: 0.00011929439642699435\n",
      "Epoch 3164, Loss: 0.0003055682245758362, Final Batch Loss: 0.00022632464242633432\n",
      "Epoch 3165, Loss: 0.00030104516190476716, Final Batch Loss: 0.0001659349218243733\n",
      "Epoch 3166, Loss: 0.0006613490986637771, Final Batch Loss: 0.00042501784628257155\n",
      "Epoch 3167, Loss: 0.002468812119332142, Final Batch Loss: 0.00011888875451404601\n",
      "Epoch 3168, Loss: 0.0004728118146886118, Final Batch Loss: 0.0001056529363268055\n",
      "Epoch 3169, Loss: 0.000138508366944734, Final Batch Loss: 6.161193596199155e-05\n",
      "Epoch 3170, Loss: 0.002055685850791633, Final Batch Loss: 0.0007258993573486805\n",
      "Epoch 3171, Loss: 0.00013963419769424945, Final Batch Loss: 2.6031702873297036e-05\n",
      "Epoch 3172, Loss: 0.0006782048003515229, Final Batch Loss: 0.000528724049217999\n",
      "Epoch 3173, Loss: 0.0005203678956604563, Final Batch Loss: 9.59352109930478e-05\n",
      "Epoch 3174, Loss: 0.0010727693297667429, Final Batch Loss: 0.0009401768911629915\n",
      "Epoch 3175, Loss: 0.00031081706401892006, Final Batch Loss: 0.00012136762961745262\n",
      "Epoch 3176, Loss: 0.0004949717040290125, Final Batch Loss: 0.0004323153116274625\n",
      "Epoch 3177, Loss: 0.00039067781472112983, Final Batch Loss: 0.00016436744772363454\n",
      "Epoch 3178, Loss: 0.0007645233708899468, Final Batch Loss: 0.00012996853911317885\n",
      "Epoch 3179, Loss: 0.00026359636103734374, Final Batch Loss: 0.00018722968525253236\n",
      "Epoch 3180, Loss: 0.0033561891759745777, Final Batch Loss: 0.0030139549635350704\n",
      "Epoch 3181, Loss: 0.0011530744159244932, Final Batch Loss: 9.134537685895339e-05\n",
      "Epoch 3182, Loss: 0.00016832646360853687, Final Batch Loss: 7.167542207753286e-05\n",
      "Epoch 3183, Loss: 0.0015459031565114856, Final Batch Loss: 0.0009728498407639563\n",
      "Epoch 3184, Loss: 0.006459528187406249, Final Batch Loss: 0.00010745979670900851\n",
      "Epoch 3185, Loss: 0.0009842388972174376, Final Batch Loss: 0.0009504130575805902\n",
      "Epoch 3186, Loss: 0.00034581257204990834, Final Batch Loss: 0.00020289198437239975\n",
      "Epoch 3187, Loss: 0.002240545058157295, Final Batch Loss: 0.00013618957018479705\n",
      "Epoch 3188, Loss: 0.00023198064081952907, Final Batch Loss: 5.912589040235616e-05\n",
      "Epoch 3189, Loss: 0.0013103984274493996, Final Batch Loss: 3.6465793527895585e-05\n",
      "Epoch 3190, Loss: 0.0019439060633885674, Final Batch Loss: 0.00012055667320964858\n",
      "Epoch 3191, Loss: 0.0009747193253133446, Final Batch Loss: 0.00031418519211001694\n",
      "Epoch 3192, Loss: 0.0006343837158055976, Final Batch Loss: 0.0005526423337869346\n",
      "Epoch 3193, Loss: 0.0002471690568199847, Final Batch Loss: 0.0002121202414855361\n",
      "Epoch 3194, Loss: 0.0002009398231166415, Final Batch Loss: 7.461579662049189e-05\n",
      "Epoch 3195, Loss: 0.000872007596626645, Final Batch Loss: 5.5079373851185665e-05\n",
      "Epoch 3196, Loss: 0.000350278802216053, Final Batch Loss: 0.0001636513479752466\n",
      "Epoch 3197, Loss: 0.0003699587832670659, Final Batch Loss: 6.297850632108748e-05\n",
      "Epoch 3198, Loss: 0.0009191059834847692, Final Batch Loss: 1.563210753374733e-05\n",
      "Epoch 3199, Loss: 0.0005484858702402562, Final Batch Loss: 0.0003485170309431851\n",
      "Epoch 3200, Loss: 0.0005665836215484887, Final Batch Loss: 0.0003857029660139233\n",
      "Epoch 3201, Loss: 0.0005153494421392679, Final Batch Loss: 0.00026001938385888934\n",
      "Epoch 3202, Loss: 0.00043639344221446663, Final Batch Loss: 0.00023540265101473778\n",
      "Epoch 3203, Loss: 0.00031667330767959356, Final Batch Loss: 0.0001824974169721827\n",
      "Epoch 3204, Loss: 0.0004703545564552769, Final Batch Loss: 9.455376130063087e-05\n",
      "Epoch 3205, Loss: 0.0006766095757484436, Final Batch Loss: 0.000611119088716805\n",
      "Epoch 3206, Loss: 0.0025289355471613817, Final Batch Loss: 0.0001003966826829128\n",
      "Epoch 3207, Loss: 0.0018069415091304109, Final Batch Loss: 0.0001721827284200117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3208, Loss: 0.04049469856545329, Final Batch Loss: 0.03588397428393364\n",
      "Epoch 3209, Loss: 0.0008327506511704996, Final Batch Loss: 0.0006388548063114285\n",
      "Epoch 3210, Loss: 0.000978608186414931, Final Batch Loss: 0.0008959812694229186\n",
      "Epoch 3211, Loss: 0.0018976505962200463, Final Batch Loss: 0.0007362878532148898\n",
      "Epoch 3212, Loss: 0.002037180500337854, Final Batch Loss: 0.0015870686620473862\n",
      "Epoch 3213, Loss: 0.0013493729347828776, Final Batch Loss: 0.0010610725730657578\n",
      "Epoch 3214, Loss: 0.0002790511025523301, Final Batch Loss: 5.769123890786432e-05\n",
      "Epoch 3215, Loss: 0.0006517260917462409, Final Batch Loss: 0.0004984537372365594\n",
      "Epoch 3216, Loss: 0.000659901910694316, Final Batch Loss: 0.0005295033915899694\n",
      "Epoch 3217, Loss: 0.007391724961053114, Final Batch Loss: 0.0073068891651928425\n",
      "Epoch 3218, Loss: 0.0009186566167045385, Final Batch Loss: 0.0006448639906011522\n",
      "Epoch 3219, Loss: 0.012443328741937876, Final Batch Loss: 0.011823262088000774\n",
      "Epoch 3220, Loss: 0.0012288527650525793, Final Batch Loss: 0.0001461264764657244\n",
      "Epoch 3221, Loss: 0.0006913835823070258, Final Batch Loss: 0.0005782279185950756\n",
      "Epoch 3222, Loss: 0.00030331345260492526, Final Batch Loss: 0.00025521006318740547\n",
      "Epoch 3223, Loss: 0.012335980180068873, Final Batch Loss: 0.00022120853827800602\n",
      "Epoch 3224, Loss: 0.020120852626860142, Final Batch Loss: 0.004213537089526653\n",
      "Epoch 3225, Loss: 0.00012672265074797906, Final Batch Loss: 8.55970720294863e-05\n",
      "Epoch 3226, Loss: 0.0011135938111692667, Final Batch Loss: 0.0008280546753667295\n",
      "Epoch 3227, Loss: 0.06369254062883556, Final Batch Loss: 0.06040172278881073\n",
      "Epoch 3228, Loss: 0.002900558232795447, Final Batch Loss: 0.0021493181120604277\n",
      "Epoch 3229, Loss: 0.0002030620744335465, Final Batch Loss: 0.00012225765385665\n",
      "Epoch 3230, Loss: 0.02359741076361388, Final Batch Loss: 0.0005861156387254596\n",
      "Epoch 3231, Loss: 0.024901257536839694, Final Batch Loss: 0.024653567001223564\n",
      "Epoch 3232, Loss: 0.005424269242212176, Final Batch Loss: 0.002744070254266262\n",
      "Epoch 3233, Loss: 0.012825909194361884, Final Batch Loss: 0.01271270215511322\n",
      "Epoch 3234, Loss: 0.0016880818584468216, Final Batch Loss: 0.0003467400965746492\n",
      "Epoch 3235, Loss: 0.0009271000744774938, Final Batch Loss: 0.0003519441233947873\n",
      "Epoch 3236, Loss: 0.0012445627944543958, Final Batch Loss: 0.00010167818982154131\n",
      "Epoch 3237, Loss: 0.0004143134210607968, Final Batch Loss: 0.00010461184865562245\n",
      "Epoch 3238, Loss: 0.0008303699432872236, Final Batch Loss: 0.0003286488354206085\n",
      "Epoch 3239, Loss: 0.0007159763481467962, Final Batch Loss: 0.0004109738511033356\n",
      "Epoch 3240, Loss: 0.0009373731591040269, Final Batch Loss: 0.00020204258908051997\n",
      "Epoch 3241, Loss: 0.0028094795998185873, Final Batch Loss: 0.0022054119035601616\n",
      "Epoch 3242, Loss: 0.0013851244002580643, Final Batch Loss: 0.0007946629775688052\n",
      "Epoch 3243, Loss: 0.003012913904967718, Final Batch Loss: 0.002805323339998722\n",
      "Epoch 3244, Loss: 0.0007012602873146534, Final Batch Loss: 0.00044226599857211113\n",
      "Epoch 3245, Loss: 0.001303531404118985, Final Batch Loss: 0.0006502627511508763\n",
      "Epoch 3246, Loss: 0.0017731133993947878, Final Batch Loss: 0.00010095375182572752\n",
      "Epoch 3247, Loss: 0.0004621816478902474, Final Batch Loss: 5.070540646556765e-05\n",
      "Epoch 3248, Loss: 0.00027234618755755946, Final Batch Loss: 5.763574881711975e-05\n",
      "Epoch 3249, Loss: 0.0007751632074359804, Final Batch Loss: 0.00045972043881192803\n",
      "Epoch 3250, Loss: 0.000744601507904008, Final Batch Loss: 0.00037052511470392346\n",
      "Epoch 3251, Loss: 0.0009458734712097794, Final Batch Loss: 0.0005311578279361129\n",
      "Epoch 3252, Loss: 0.0021399199758889154, Final Batch Loss: 0.0020036122296005487\n",
      "Epoch 3253, Loss: 0.00030338844226207584, Final Batch Loss: 3.49787442246452e-05\n",
      "Epoch 3254, Loss: 0.0002550995777710341, Final Batch Loss: 8.244787022704259e-05\n",
      "Epoch 3255, Loss: 0.00025419760640943423, Final Batch Loss: 0.00016023736679926515\n",
      "Epoch 3256, Loss: 0.002523981616832316, Final Batch Loss: 0.0021175150759518147\n",
      "Epoch 3257, Loss: 0.0010852105042431504, Final Batch Loss: 0.0007077738991938531\n",
      "Epoch 3258, Loss: 0.0006253284227568656, Final Batch Loss: 0.0003600404888857156\n",
      "Epoch 3259, Loss: 0.0023245220363605767, Final Batch Loss: 0.0004404615901876241\n",
      "Epoch 3260, Loss: 0.0013785694318357855, Final Batch Loss: 0.0009217128972522914\n",
      "Epoch 3261, Loss: 0.0007503380620619282, Final Batch Loss: 0.0005278302705846727\n",
      "Epoch 3262, Loss: 0.0008572051592636853, Final Batch Loss: 0.0001012063876260072\n",
      "Epoch 3263, Loss: 0.01699081636616029, Final Batch Loss: 0.00023902408429421484\n",
      "Epoch 3264, Loss: 0.0008926483278628439, Final Batch Loss: 0.00038793994463048875\n",
      "Epoch 3265, Loss: 0.001645237673074007, Final Batch Loss: 0.0006896522245369852\n",
      "Epoch 3266, Loss: 0.001526739913970232, Final Batch Loss: 0.0008216655114665627\n",
      "Epoch 3267, Loss: 0.0012819476542063057, Final Batch Loss: 0.000653985480312258\n",
      "Epoch 3268, Loss: 0.0010233142820652574, Final Batch Loss: 0.0002290185948368162\n",
      "Epoch 3269, Loss: 0.0015277718339348212, Final Batch Loss: 3.1219227821566164e-05\n",
      "Epoch 3270, Loss: 0.0006982947525102645, Final Batch Loss: 0.0005755017045885324\n",
      "Epoch 3271, Loss: 0.0007035218222881667, Final Batch Loss: 0.00012122379121137783\n",
      "Epoch 3272, Loss: 0.00028837184072472155, Final Batch Loss: 5.988810153212398e-05\n",
      "Epoch 3273, Loss: 0.0017530852783238515, Final Batch Loss: 0.00018518567958381027\n",
      "Epoch 3274, Loss: 0.0006639531929977238, Final Batch Loss: 0.0003333138593006879\n",
      "Epoch 3275, Loss: 0.0010360677260905504, Final Batch Loss: 0.0007646360900253057\n",
      "Epoch 3276, Loss: 0.0014813993475399911, Final Batch Loss: 0.00031180743826553226\n",
      "Epoch 3277, Loss: 0.014031206206709612, Final Batch Loss: 9.072473767446354e-05\n",
      "Epoch 3278, Loss: 0.0009295626077800989, Final Batch Loss: 0.0005019682575948536\n",
      "Epoch 3279, Loss: 0.0017714413988869637, Final Batch Loss: 0.0001833148708101362\n",
      "Epoch 3280, Loss: 0.0004270917997928336, Final Batch Loss: 5.0132672186009586e-05\n",
      "Epoch 3281, Loss: 0.0033268816769123077, Final Batch Loss: 0.002572148572653532\n",
      "Epoch 3282, Loss: 0.0002187118006986566, Final Batch Loss: 0.0001617883681319654\n",
      "Epoch 3283, Loss: 0.002000133572437335, Final Batch Loss: 0.00010536850459175184\n",
      "Epoch 3284, Loss: 0.001352519539068453, Final Batch Loss: 0.00013497732288669795\n",
      "Epoch 3285, Loss: 0.00033232333953492343, Final Batch Loss: 0.00012762115511577576\n",
      "Epoch 3286, Loss: 0.002340719940548297, Final Batch Loss: 0.0022722790017724037\n",
      "Epoch 3287, Loss: 0.0007005967781879008, Final Batch Loss: 0.00047538746730424464\n",
      "Epoch 3288, Loss: 0.0007454422011505812, Final Batch Loss: 0.0002481932460796088\n",
      "Epoch 3289, Loss: 0.0012983099441044033, Final Batch Loss: 0.0009712643804959953\n",
      "Epoch 3290, Loss: 0.0008388797141378745, Final Batch Loss: 0.0006895605474710464\n",
      "Epoch 3291, Loss: 0.00023339467225014232, Final Batch Loss: 0.00017848391144070774\n",
      "Epoch 3292, Loss: 0.00020653489991673268, Final Batch Loss: 4.5176366256782785e-05\n",
      "Epoch 3293, Loss: 0.006161876488476992, Final Batch Loss: 0.003391747595742345\n",
      "Epoch 3294, Loss: 0.004889235831797123, Final Batch Loss: 0.00036998325958848\n",
      "Epoch 3295, Loss: 0.0007125399133656174, Final Batch Loss: 0.00020726144430227578\n",
      "Epoch 3296, Loss: 0.001310712941631209, Final Batch Loss: 6.075452984077856e-05\n",
      "Epoch 3297, Loss: 0.00176325508437003, Final Batch Loss: 5.1423539844108745e-05\n",
      "Epoch 3298, Loss: 0.0003272700705565512, Final Batch Loss: 0.00020502801635302603\n",
      "Epoch 3299, Loss: 0.0007896003371570259, Final Batch Loss: 0.0004261855501681566\n",
      "Epoch 3300, Loss: 0.002257043539430015, Final Batch Loss: 0.0020242477767169476\n",
      "Epoch 3301, Loss: 0.00044837722089141607, Final Batch Loss: 4.9948925152421e-05\n",
      "Epoch 3302, Loss: 0.0045429428573697805, Final Batch Loss: 0.00014542113058269024\n",
      "Epoch 3303, Loss: 0.0071166660491144285, Final Batch Loss: 0.00014872847532387823\n",
      "Epoch 3304, Loss: 0.0005286814193823375, Final Batch Loss: 0.00010845985525520518\n",
      "Epoch 3305, Loss: 0.0017480292299296707, Final Batch Loss: 0.0002397767675574869\n",
      "Epoch 3306, Loss: 0.0008075526857282966, Final Batch Loss: 0.00019361588056199253\n",
      "Epoch 3307, Loss: 0.0007932370062917471, Final Batch Loss: 0.0004737554700113833\n",
      "Epoch 3308, Loss: 0.009283143073844258, Final Batch Loss: 0.00010998265497619286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3309, Loss: 0.0025604511465644464, Final Batch Loss: 0.0024025491438806057\n",
      "Epoch 3310, Loss: 0.0014207799540599808, Final Batch Loss: 0.0001191806368296966\n",
      "Epoch 3311, Loss: 0.0005769151321146637, Final Batch Loss: 0.00035435811150819063\n",
      "Epoch 3312, Loss: 0.0031445106615137774, Final Batch Loss: 0.0030854721553623676\n",
      "Epoch 3313, Loss: 0.0005409328223322518, Final Batch Loss: 7.941667718114331e-05\n",
      "Epoch 3314, Loss: 0.0007153172191465273, Final Batch Loss: 0.0005109438207000494\n",
      "Epoch 3315, Loss: 0.0010483827209100127, Final Batch Loss: 0.00017930578906089067\n",
      "Epoch 3316, Loss: 0.0016698825056664646, Final Batch Loss: 0.0011636262061074376\n",
      "Epoch 3317, Loss: 0.0002139194548362866, Final Batch Loss: 0.00010929032578133047\n",
      "Epoch 3318, Loss: 0.0005104238225612789, Final Batch Loss: 0.0003080822352785617\n",
      "Epoch 3319, Loss: 0.0011505338625283912, Final Batch Loss: 0.0009473164682276547\n",
      "Epoch 3320, Loss: 0.0014666905044578016, Final Batch Loss: 0.0008692745468579233\n",
      "Epoch 3321, Loss: 0.0001121503664762713, Final Batch Loss: 8.253756823251024e-05\n",
      "Epoch 3322, Loss: 0.000618313773884438, Final Batch Loss: 0.00012694309407379478\n",
      "Epoch 3323, Loss: 0.006249087608011905, Final Batch Loss: 5.3705858590546995e-05\n",
      "Epoch 3324, Loss: 0.00104309301241301, Final Batch Loss: 0.0006105248467065394\n",
      "Epoch 3325, Loss: 0.000919263533432968, Final Batch Loss: 0.0006764247664250433\n",
      "Epoch 3326, Loss: 0.00028418660804163665, Final Batch Loss: 0.00021010402997490019\n",
      "Epoch 3327, Loss: 0.0036949278437532485, Final Batch Loss: 0.003620338626205921\n",
      "Epoch 3328, Loss: 0.0047296229167841375, Final Batch Loss: 0.00015929521759971976\n",
      "Epoch 3329, Loss: 0.0008658803126309067, Final Batch Loss: 0.00015381569392047822\n",
      "Epoch 3330, Loss: 0.0005772478471044451, Final Batch Loss: 0.00038151469198055565\n",
      "Epoch 3331, Loss: 0.0283930481527932, Final Batch Loss: 0.02774105593562126\n",
      "Epoch 3332, Loss: 0.006844817064120434, Final Batch Loss: 0.006668462418019772\n",
      "Epoch 3333, Loss: 0.0008339807827724144, Final Batch Loss: 0.0006212797597981989\n",
      "Epoch 3334, Loss: 0.0008594695536885411, Final Batch Loss: 0.0002926359011325985\n",
      "Epoch 3335, Loss: 0.00045102879812475294, Final Batch Loss: 0.00026386798708699644\n",
      "Epoch 3336, Loss: 0.0008135603566188365, Final Batch Loss: 6.919304723851383e-05\n",
      "Epoch 3337, Loss: 0.0012571865081554279, Final Batch Loss: 0.00012801318371202797\n",
      "Epoch 3338, Loss: 0.0010845755168702453, Final Batch Loss: 0.0008374846656806767\n",
      "Epoch 3339, Loss: 0.0033823929625214078, Final Batch Loss: 9.456164116272703e-05\n",
      "Epoch 3340, Loss: 0.0002910636394517496, Final Batch Loss: 0.0001599461684236303\n",
      "Epoch 3341, Loss: 0.0001282457869820064, Final Batch Loss: 2.0755220248247497e-05\n",
      "Epoch 3342, Loss: 0.0001871398744697217, Final Batch Loss: 5.208378206589259e-05\n",
      "Epoch 3343, Loss: 0.0011320021440042183, Final Batch Loss: 0.0010040346533060074\n",
      "Epoch 3344, Loss: 0.00017573696823092178, Final Batch Loss: 0.00011314589210087433\n",
      "Epoch 3345, Loss: 0.00021124874183442444, Final Batch Loss: 0.00017918219964485615\n",
      "Epoch 3346, Loss: 0.00034341013815719634, Final Batch Loss: 0.00021816190565004945\n",
      "Epoch 3347, Loss: 0.004157756418862846, Final Batch Loss: 0.004064096137881279\n",
      "Epoch 3348, Loss: 0.0001955228508450091, Final Batch Loss: 7.347522478085011e-05\n",
      "Epoch 3349, Loss: 0.00041053340828511864, Final Batch Loss: 0.0002132351219188422\n",
      "Epoch 3350, Loss: 0.0005210833915043622, Final Batch Loss: 0.00012493249960243702\n",
      "Epoch 3351, Loss: 0.0002864204070647247, Final Batch Loss: 7.67728706705384e-05\n",
      "Epoch 3352, Loss: 0.00012195006274851039, Final Batch Loss: 5.400002555688843e-05\n",
      "Epoch 3353, Loss: 0.0002154386238544248, Final Batch Loss: 0.00012426056491676718\n",
      "Epoch 3354, Loss: 0.0004251371283316985, Final Batch Loss: 0.0002637393481563777\n",
      "Epoch 3355, Loss: 0.00021102776918269228, Final Batch Loss: 1.888864608190488e-05\n",
      "Epoch 3356, Loss: 0.0002802674498525448, Final Batch Loss: 0.00019375626288820058\n",
      "Epoch 3357, Loss: 0.002934025011199992, Final Batch Loss: 0.0028827732894569635\n",
      "Epoch 3358, Loss: 0.00029471157176885754, Final Batch Loss: 0.00019723677542060614\n",
      "Epoch 3359, Loss: 0.0004922928928863257, Final Batch Loss: 0.00027932325610890985\n",
      "Epoch 3360, Loss: 0.00045614357804879546, Final Batch Loss: 0.00030967293423600495\n",
      "Epoch 3361, Loss: 0.0003321690237498842, Final Batch Loss: 0.0002465113066136837\n",
      "Epoch 3362, Loss: 0.002723041397985071, Final Batch Loss: 0.0023366680834442377\n",
      "Epoch 3363, Loss: 0.004296784274629317, Final Batch Loss: 0.0001660431589698419\n",
      "Epoch 3364, Loss: 0.00022306443861452863, Final Batch Loss: 0.0001598274684511125\n",
      "Epoch 3365, Loss: 0.0001839841643231921, Final Batch Loss: 9.421924914931878e-05\n",
      "Epoch 3366, Loss: 0.0005464545683935285, Final Batch Loss: 0.000326691719237715\n",
      "Epoch 3367, Loss: 0.001603831296961289, Final Batch Loss: 0.00011721695045707747\n",
      "Epoch 3368, Loss: 0.00028402146926964633, Final Batch Loss: 2.279392720083706e-05\n",
      "Epoch 3369, Loss: 0.02843270928133279, Final Batch Loss: 0.02835158072412014\n",
      "Epoch 3370, Loss: 0.0018918484565801919, Final Batch Loss: 0.00024627294624224305\n",
      "Epoch 3371, Loss: 0.013183294387999922, Final Batch Loss: 0.012433520518243313\n",
      "Epoch 3372, Loss: 0.01066974940476939, Final Batch Loss: 0.01008457038551569\n",
      "Epoch 3373, Loss: 0.009244448156096041, Final Batch Loss: 0.009180630557239056\n",
      "Epoch 3374, Loss: 0.014409792609512806, Final Batch Loss: 0.008344605565071106\n",
      "Epoch 3375, Loss: 0.0006482380558736622, Final Batch Loss: 0.00021673593437299132\n",
      "Epoch 3376, Loss: 0.0007992390892468393, Final Batch Loss: 0.00033938820706680417\n",
      "Epoch 3377, Loss: 0.006555684260092676, Final Batch Loss: 0.005876868963241577\n",
      "Epoch 3378, Loss: 0.00030109010549494997, Final Batch Loss: 9.503708133706823e-05\n",
      "Epoch 3379, Loss: 0.013969138963147998, Final Batch Loss: 0.00014527211897075176\n",
      "Epoch 3380, Loss: 0.0024410021724179387, Final Batch Loss: 0.0018657321343198419\n",
      "Epoch 3381, Loss: 0.001093290265998803, Final Batch Loss: 0.0002185633493354544\n",
      "Epoch 3382, Loss: 0.00043051165994256735, Final Batch Loss: 0.0002189136721426621\n",
      "Epoch 3383, Loss: 0.007717327680438757, Final Batch Loss: 0.004595273640006781\n",
      "Epoch 3384, Loss: 0.0012381933629512787, Final Batch Loss: 0.0005929879262112081\n",
      "Epoch 3385, Loss: 0.0016885335207916796, Final Batch Loss: 0.0011324849911034107\n",
      "Epoch 3386, Loss: 0.00030072116351220757, Final Batch Loss: 0.00015386674203909934\n",
      "Epoch 3387, Loss: 0.0002262957495986484, Final Batch Loss: 0.00016194260388147086\n",
      "Epoch 3388, Loss: 0.0014519323303829879, Final Batch Loss: 0.0001443250512238592\n",
      "Epoch 3389, Loss: 0.00043398466368671507, Final Batch Loss: 0.00020837230840697885\n",
      "Epoch 3390, Loss: 0.0007455823506461456, Final Batch Loss: 0.00021421398560050875\n",
      "Epoch 3391, Loss: 0.0010102894448209554, Final Batch Loss: 0.0006597547326236963\n",
      "Epoch 3392, Loss: 0.00040927909140009433, Final Batch Loss: 2.846580173354596e-05\n",
      "Epoch 3393, Loss: 0.0013810741947963834, Final Batch Loss: 0.0009662189404480159\n",
      "Epoch 3394, Loss: 0.0008757673786021769, Final Batch Loss: 0.00031224836129695177\n",
      "Epoch 3395, Loss: 0.0014306537341326475, Final Batch Loss: 0.0008709024405106902\n",
      "Epoch 3396, Loss: 0.0007454623992089182, Final Batch Loss: 0.00028724755975417793\n",
      "Epoch 3397, Loss: 0.0033618654124438763, Final Batch Loss: 0.002151812892407179\n",
      "Epoch 3398, Loss: 0.0007376958383247256, Final Batch Loss: 0.00038361106999218464\n",
      "Epoch 3399, Loss: 0.0014919465320417657, Final Batch Loss: 0.00014717075100634247\n",
      "Epoch 3400, Loss: 0.000652183050988242, Final Batch Loss: 0.0004992596805095673\n",
      "Epoch 3401, Loss: 0.0004028675830340944, Final Batch Loss: 0.00011254502896917984\n",
      "Epoch 3402, Loss: 0.0009631356806494296, Final Batch Loss: 0.0005915104993619025\n",
      "Epoch 3403, Loss: 0.000519941037055105, Final Batch Loss: 9.630664135329425e-05\n",
      "Epoch 3404, Loss: 0.004092850285815075, Final Batch Loss: 0.003683611052110791\n",
      "Epoch 3405, Loss: 0.0006061070307623595, Final Batch Loss: 0.00030409969622269273\n",
      "Epoch 3406, Loss: 0.0009825311717577279, Final Batch Loss: 0.0006196672329679132\n",
      "Epoch 3407, Loss: 0.0007372393883997574, Final Batch Loss: 8.911413897294551e-05\n",
      "Epoch 3408, Loss: 0.0006812400679336861, Final Batch Loss: 0.00013305306492839009\n",
      "Epoch 3409, Loss: 0.0017302940832450986, Final Batch Loss: 0.0002527843462303281\n",
      "Epoch 3410, Loss: 0.0003420488355914131, Final Batch Loss: 8.008260920178145e-05\n",
      "Epoch 3411, Loss: 0.00010309907156624831, Final Batch Loss: 4.190566323813982e-05\n",
      "Epoch 3412, Loss: 0.0002804045216180384, Final Batch Loss: 0.00012422891450114548\n",
      "Epoch 3413, Loss: 0.000405430473620072, Final Batch Loss: 9.930573287419975e-05\n",
      "Epoch 3414, Loss: 0.00022497330428450368, Final Batch Loss: 3.1357612897409126e-05\n",
      "Epoch 3415, Loss: 0.00016657029482303187, Final Batch Loss: 7.729367644060403e-05\n",
      "Epoch 3416, Loss: 0.00856595049117459, Final Batch Loss: 8.399533544434234e-05\n",
      "Epoch 3417, Loss: 0.00019354180403752252, Final Batch Loss: 0.0001349227095488459\n",
      "Epoch 3418, Loss: 0.00036560388980433345, Final Batch Loss: 0.00020736115402542055\n",
      "Epoch 3419, Loss: 0.007492882199585438, Final Batch Loss: 0.007196230348199606\n",
      "Epoch 3420, Loss: 0.00026528317539487034, Final Batch Loss: 0.00012151850387454033\n",
      "Epoch 3421, Loss: 0.00041950105151045136, Final Batch Loss: 0.00037139077903702855\n",
      "Epoch 3422, Loss: 0.001327429199591279, Final Batch Loss: 0.0011351605644449592\n",
      "Epoch 3423, Loss: 0.00035429096897132695, Final Batch Loss: 0.0001813864364521578\n",
      "Epoch 3424, Loss: 0.0014210078225005418, Final Batch Loss: 0.0010188398882746696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3425, Loss: 0.008113255258649588, Final Batch Loss: 0.0075064729899168015\n",
      "Epoch 3426, Loss: 0.0019258577340224292, Final Batch Loss: 3.880192161886953e-05\n",
      "Epoch 3427, Loss: 0.0009598058531992137, Final Batch Loss: 0.0006084335036575794\n",
      "Epoch 3428, Loss: 0.002360417100135237, Final Batch Loss: 0.0017295237630605698\n",
      "Epoch 3429, Loss: 8.381336374441162e-05, Final Batch Loss: 1.4281446055974811e-05\n",
      "Epoch 3430, Loss: 0.0008931483898777515, Final Batch Loss: 0.00031811962253414094\n",
      "Epoch 3431, Loss: 0.0007677892863284796, Final Batch Loss: 0.00023717476869933307\n",
      "Epoch 3432, Loss: 0.0013457535533234477, Final Batch Loss: 0.0008490286418236792\n",
      "Epoch 3433, Loss: 0.009688253747299314, Final Batch Loss: 0.0025979375932365656\n",
      "Epoch 3434, Loss: 0.004811614911886863, Final Batch Loss: 0.00013738514098804444\n",
      "Epoch 3435, Loss: 0.002478717957274057, Final Batch Loss: 0.0022643725387752056\n",
      "Epoch 3436, Loss: 0.0013017757883062586, Final Batch Loss: 6.456706614699215e-05\n",
      "Epoch 3437, Loss: 0.0005712130659958348, Final Batch Loss: 0.00023570981284137815\n",
      "Epoch 3438, Loss: 0.002137237708666362, Final Batch Loss: 0.00019863703346345574\n",
      "Epoch 3439, Loss: 0.0007439008768415079, Final Batch Loss: 0.00022963927767705172\n",
      "Epoch 3440, Loss: 0.029272870568092912, Final Batch Loss: 0.02892686240375042\n",
      "Epoch 3441, Loss: 0.0005799974896945059, Final Batch Loss: 0.0002736553142312914\n",
      "Epoch 3442, Loss: 0.0003479103179415688, Final Batch Loss: 0.00011005994747392833\n",
      "Epoch 3443, Loss: 0.001688029384240508, Final Batch Loss: 0.0004589327145367861\n",
      "Epoch 3444, Loss: 0.0016801803722046316, Final Batch Loss: 0.000170723011251539\n",
      "Epoch 3445, Loss: 0.003680672321934253, Final Batch Loss: 0.0031882552430033684\n",
      "Epoch 3446, Loss: 0.006663406500592828, Final Batch Loss: 0.004573801066726446\n",
      "Epoch 3447, Loss: 0.0013936430914327502, Final Batch Loss: 0.0007896229508332908\n",
      "Epoch 3448, Loss: 0.001320698851486668, Final Batch Loss: 0.00039334295433945954\n",
      "Epoch 3449, Loss: 0.0008486790466122329, Final Batch Loss: 0.0002901305560953915\n",
      "Epoch 3450, Loss: 0.0006432570517063141, Final Batch Loss: 0.000502305687405169\n",
      "Epoch 3451, Loss: 0.0007834705138520803, Final Batch Loss: 5.811953087686561e-05\n",
      "Epoch 3452, Loss: 0.00038123199192341417, Final Batch Loss: 0.00028801950975321233\n",
      "Epoch 3453, Loss: 0.004248694531270303, Final Batch Loss: 0.00013845741341356188\n",
      "Epoch 3454, Loss: 0.001345349352050107, Final Batch Loss: 9.168171527562663e-05\n",
      "Epoch 3455, Loss: 0.0006444719620049, Final Batch Loss: 0.0003581986529752612\n",
      "Epoch 3456, Loss: 0.0008425355918006971, Final Batch Loss: 0.0007076563779264688\n",
      "Epoch 3457, Loss: 0.00017836501501733437, Final Batch Loss: 3.2317104341927916e-05\n",
      "Epoch 3458, Loss: 0.00025486035883659497, Final Batch Loss: 0.00014623730385210365\n",
      "Epoch 3459, Loss: 0.0016717843827791512, Final Batch Loss: 0.0011057622032240033\n",
      "Epoch 3460, Loss: 0.0007301964360522106, Final Batch Loss: 0.0005896696820855141\n",
      "Epoch 3461, Loss: 0.0032114580390043557, Final Batch Loss: 0.0027646333910524845\n",
      "Epoch 3462, Loss: 0.0013556762569351122, Final Batch Loss: 0.001197432866320014\n",
      "Epoch 3463, Loss: 0.00024253292940557003, Final Batch Loss: 4.301896842662245e-05\n",
      "Epoch 3464, Loss: 0.00033956646802835166, Final Batch Loss: 0.00018989229283761233\n",
      "Epoch 3465, Loss: 0.0001828700114856474, Final Batch Loss: 9.543635678710416e-05\n",
      "Epoch 3466, Loss: 0.0004710740759037435, Final Batch Loss: 9.565305663272738e-05\n",
      "Epoch 3467, Loss: 0.00020619435963453725, Final Batch Loss: 0.0001049937418429181\n",
      "Epoch 3468, Loss: 0.0005070922197774053, Final Batch Loss: 0.00015025012544356287\n",
      "Epoch 3469, Loss: 0.0016306451288983226, Final Batch Loss: 0.0008479576208628714\n",
      "Epoch 3470, Loss: 0.0009294144692830741, Final Batch Loss: 0.000669301429297775\n",
      "Epoch 3471, Loss: 0.049253824225161225, Final Batch Loss: 0.049016233533620834\n",
      "Epoch 3472, Loss: 0.0005046656297054142, Final Batch Loss: 0.00015263905515894294\n",
      "Epoch 3473, Loss: 0.0017459359078202397, Final Batch Loss: 0.00038516594213433564\n",
      "Epoch 3474, Loss: 0.0003142074783681892, Final Batch Loss: 0.00012005909957224503\n",
      "Epoch 3475, Loss: 0.00024171585391741246, Final Batch Loss: 0.00012734372285194695\n",
      "Epoch 3476, Loss: 0.0005594761787506286, Final Batch Loss: 0.0005086776800453663\n",
      "Epoch 3477, Loss: 0.014261028132750653, Final Batch Loss: 0.0001643778377911076\n",
      "Epoch 3478, Loss: 0.0004124615661567077, Final Batch Loss: 0.00011963171709794551\n",
      "Epoch 3479, Loss: 0.0030004152795299888, Final Batch Loss: 0.002703305333852768\n",
      "Epoch 3480, Loss: 0.00023999415861908346, Final Batch Loss: 0.00012057245476171374\n",
      "Epoch 3481, Loss: 0.0003010937689396087, Final Batch Loss: 4.970864756614901e-05\n",
      "Epoch 3482, Loss: 0.0006152966234367341, Final Batch Loss: 0.0002090277266688645\n",
      "Epoch 3483, Loss: 0.0005752081087848637, Final Batch Loss: 0.0005370720173232257\n",
      "Epoch 3484, Loss: 0.0002976621690322645, Final Batch Loss: 0.00010895435843849555\n",
      "Epoch 3485, Loss: 0.0003227082052035257, Final Batch Loss: 0.0001410373079124838\n",
      "Epoch 3486, Loss: 0.00043730396282626316, Final Batch Loss: 0.0003292037290520966\n",
      "Epoch 3487, Loss: 0.0008459861855953932, Final Batch Loss: 0.00035376427695155144\n",
      "Epoch 3488, Loss: 0.0008340121567016467, Final Batch Loss: 0.0006464488687925041\n",
      "Epoch 3489, Loss: 0.00037320959381759167, Final Batch Loss: 0.0002925334556493908\n",
      "Epoch 3490, Loss: 0.0003073145489906892, Final Batch Loss: 9.779191168490797e-05\n",
      "Epoch 3491, Loss: 0.0007943341479403898, Final Batch Loss: 0.0006901118904352188\n",
      "Epoch 3492, Loss: 0.004144413163885474, Final Batch Loss: 0.0011369120329618454\n",
      "Epoch 3493, Loss: 0.0002566187540651299, Final Batch Loss: 8.988909394247457e-05\n",
      "Epoch 3494, Loss: 0.006915190955623984, Final Batch Loss: 0.006363551132380962\n",
      "Epoch 3495, Loss: 0.023961859857081436, Final Batch Loss: 0.02388439141213894\n",
      "Epoch 3496, Loss: 0.0016660991095704958, Final Batch Loss: 0.0014929291792213917\n",
      "Epoch 3497, Loss: 0.010947167524136603, Final Batch Loss: 0.009917672723531723\n",
      "Epoch 3498, Loss: 0.18438194692134857, Final Batch Loss: 0.18426603078842163\n",
      "Epoch 3499, Loss: 0.14942985028028488, Final Batch Loss: 0.07908895611763\n",
      "Epoch 3500, Loss: 0.002243321287096478, Final Batch Loss: 0.0001911354629555717\n",
      "Epoch 3501, Loss: 0.0004552473983494565, Final Batch Loss: 0.00015453358355443925\n",
      "Epoch 3502, Loss: 0.000566354749025777, Final Batch Loss: 0.0002872236364055425\n",
      "Epoch 3503, Loss: 0.07975933683337644, Final Batch Loss: 0.07941184192895889\n",
      "Epoch 3504, Loss: 0.0018037365516647696, Final Batch Loss: 0.0008773881709203124\n",
      "Epoch 3505, Loss: 0.0012113885604776442, Final Batch Loss: 0.00030557916034013033\n",
      "Epoch 3506, Loss: 0.0037556334282271564, Final Batch Loss: 0.000409914820920676\n",
      "Epoch 3507, Loss: 0.0010044584923889488, Final Batch Loss: 0.00030112292733974755\n",
      "Epoch 3508, Loss: 0.018920132890343666, Final Batch Loss: 0.012112746015191078\n",
      "Epoch 3509, Loss: 0.008242977084591985, Final Batch Loss: 0.004778428003191948\n",
      "Epoch 3510, Loss: 0.015080991899594665, Final Batch Loss: 0.0022700296249240637\n",
      "Epoch 3511, Loss: 0.0010297468688804656, Final Batch Loss: 0.0007386883371509612\n",
      "Epoch 3512, Loss: 0.0019196135108359158, Final Batch Loss: 0.0007423424976877868\n",
      "Epoch 3513, Loss: 0.0026069954328704625, Final Batch Loss: 0.00034162032534368336\n",
      "Epoch 3514, Loss: 0.0012754079652950168, Final Batch Loss: 0.0003310783067718148\n",
      "Epoch 3515, Loss: 0.0022277128882706165, Final Batch Loss: 0.001096579129807651\n",
      "Epoch 3516, Loss: 0.0015778596862219274, Final Batch Loss: 0.0011178991990163922\n",
      "Epoch 3517, Loss: 0.0029366827802732587, Final Batch Loss: 0.0015727872960269451\n",
      "Epoch 3518, Loss: 0.002158616785891354, Final Batch Loss: 0.0010735983960330486\n",
      "Epoch 3519, Loss: 0.005238416080828756, Final Batch Loss: 0.004344568587839603\n",
      "Epoch 3520, Loss: 0.0023472635075449944, Final Batch Loss: 0.0006615569582208991\n",
      "Epoch 3521, Loss: 0.0012738369987346232, Final Batch Loss: 0.0006573632126674056\n",
      "Epoch 3522, Loss: 0.0015107281506061554, Final Batch Loss: 0.0008397726342082024\n",
      "Epoch 3523, Loss: 0.0011567922629183158, Final Batch Loss: 0.00016551707813050598\n",
      "Epoch 3524, Loss: 0.0022142953239381313, Final Batch Loss: 0.0014799247728660703\n",
      "Epoch 3525, Loss: 0.0011246687645325437, Final Batch Loss: 0.0009673137101344764\n",
      "Epoch 3526, Loss: 0.0027495890390127897, Final Batch Loss: 0.002143561840057373\n",
      "Epoch 3527, Loss: 0.0015359236276708543, Final Batch Loss: 0.0009427362820133567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3528, Loss: 0.002837881271261722, Final Batch Loss: 0.002153037115931511\n",
      "Epoch 3529, Loss: 0.0020780394261237234, Final Batch Loss: 0.00024548961664550006\n",
      "Epoch 3530, Loss: 0.0010807762446347624, Final Batch Loss: 0.000746171164792031\n",
      "Epoch 3531, Loss: 0.0009118070011027157, Final Batch Loss: 0.00036613829433918\n",
      "Epoch 3532, Loss: 0.008445106912404299, Final Batch Loss: 0.005759244319051504\n",
      "Epoch 3533, Loss: 0.0009114359709201381, Final Batch Loss: 0.00020433041208889335\n",
      "Epoch 3534, Loss: 0.0009647541010053828, Final Batch Loss: 0.00019316929683554918\n",
      "Epoch 3535, Loss: 0.0014868026482872665, Final Batch Loss: 0.0005839200457558036\n",
      "Epoch 3536, Loss: 0.0015259691281244159, Final Batch Loss: 0.0008408528519794345\n",
      "Epoch 3537, Loss: 0.0013294509844854474, Final Batch Loss: 0.0004130988381803036\n",
      "Epoch 3538, Loss: 0.046899082080926746, Final Batch Loss: 0.04610109329223633\n",
      "Epoch 3539, Loss: 0.0040660814847797155, Final Batch Loss: 0.0025277116801589727\n",
      "Epoch 3540, Loss: 0.01001776082557626, Final Batch Loss: 0.00041897015762515366\n",
      "Epoch 3541, Loss: 0.005679485504515469, Final Batch Loss: 0.005274736322462559\n",
      "Epoch 3542, Loss: 0.0021253564045764506, Final Batch Loss: 0.0009192764409817755\n",
      "Epoch 3543, Loss: 0.006149732507765293, Final Batch Loss: 0.004525052849203348\n",
      "Epoch 3544, Loss: 0.015345069448812865, Final Batch Loss: 0.0001872059510787949\n",
      "Epoch 3545, Loss: 0.0014236089773476124, Final Batch Loss: 0.0001337965950369835\n",
      "Epoch 3546, Loss: 0.000628770882030949, Final Batch Loss: 0.00041133855120278895\n",
      "Epoch 3547, Loss: 0.0004422684869496152, Final Batch Loss: 0.00013429207319859415\n",
      "Epoch 3548, Loss: 0.0006405192980309948, Final Batch Loss: 0.0005243181367404759\n",
      "Epoch 3549, Loss: 0.002616763929836452, Final Batch Loss: 0.0021806014701724052\n",
      "Epoch 3550, Loss: 0.0011633083049673587, Final Batch Loss: 0.00038728126673959196\n",
      "Epoch 3551, Loss: 0.0019437051669228822, Final Batch Loss: 0.001618209294974804\n",
      "Epoch 3552, Loss: 0.002711663255468011, Final Batch Loss: 0.001568998908624053\n",
      "Epoch 3553, Loss: 0.0019537143234629184, Final Batch Loss: 0.00034191497252322733\n",
      "Epoch 3554, Loss: 0.0006292536272667348, Final Batch Loss: 0.0002487210149411112\n",
      "Epoch 3555, Loss: 0.0009732296457514167, Final Batch Loss: 0.00037062267074361444\n",
      "Epoch 3556, Loss: 0.0010204592545051128, Final Batch Loss: 0.0007004468934610486\n",
      "Epoch 3557, Loss: 0.0015911540831439197, Final Batch Loss: 0.0007819667807780206\n",
      "Epoch 3558, Loss: 0.001151223637862131, Final Batch Loss: 0.000884173670783639\n",
      "Epoch 3559, Loss: 0.003848070395179093, Final Batch Loss: 0.0034021621104329824\n",
      "Epoch 3560, Loss: 0.01288514828775078, Final Batch Loss: 0.0010013176361098886\n",
      "Epoch 3561, Loss: 0.0012071482778992504, Final Batch Loss: 0.0008970857015810907\n",
      "Epoch 3562, Loss: 0.0009743824775796384, Final Batch Loss: 0.0005479682586155832\n",
      "Epoch 3563, Loss: 0.0005685493815690279, Final Batch Loss: 0.00027004798175767064\n",
      "Epoch 3564, Loss: 0.0016312826192006469, Final Batch Loss: 0.0011549906339496374\n",
      "Epoch 3565, Loss: 0.0006477315037045628, Final Batch Loss: 0.00026456371415406466\n",
      "Epoch 3566, Loss: 0.0005851567548234016, Final Batch Loss: 0.00013232941273599863\n",
      "Epoch 3567, Loss: 0.002953433315269649, Final Batch Loss: 0.002440638607367873\n",
      "Epoch 3568, Loss: 0.000831043696962297, Final Batch Loss: 0.0005941626732237637\n",
      "Epoch 3569, Loss: 0.0008650405798107386, Final Batch Loss: 0.0005077359382994473\n",
      "Epoch 3570, Loss: 0.002570591983385384, Final Batch Loss: 0.0015146703226491809\n",
      "Epoch 3571, Loss: 0.0012594552244991064, Final Batch Loss: 0.0007592184701934457\n",
      "Epoch 3572, Loss: 0.0014393019664566964, Final Batch Loss: 0.0002784103562589735\n",
      "Epoch 3573, Loss: 0.00039460045809391886, Final Batch Loss: 0.0002669815148692578\n",
      "Epoch 3574, Loss: 0.000678912183502689, Final Batch Loss: 0.00042427401058375835\n",
      "Epoch 3575, Loss: 0.0015563508495688438, Final Batch Loss: 0.0009318382362835109\n",
      "Epoch 3576, Loss: 0.0026868758723139763, Final Batch Loss: 0.00041480991058051586\n",
      "Epoch 3577, Loss: 0.00048835038614925, Final Batch Loss: 0.0002571120858192444\n",
      "Epoch 3578, Loss: 0.0005154999089427292, Final Batch Loss: 0.0001899847120512277\n",
      "Epoch 3579, Loss: 0.0032160331320483238, Final Batch Loss: 0.0003168694966007024\n",
      "Epoch 3580, Loss: 0.009191165736410767, Final Batch Loss: 0.008696181699633598\n",
      "Epoch 3581, Loss: 0.0005130845675012097, Final Batch Loss: 6.477224815171212e-05\n",
      "Epoch 3582, Loss: 0.0006140957702882588, Final Batch Loss: 0.00024854327784851193\n",
      "Epoch 3583, Loss: 0.0015868104819674045, Final Batch Loss: 0.0013225734001025558\n",
      "Epoch 3584, Loss: 0.0012141665793024004, Final Batch Loss: 0.0006201887154020369\n",
      "Epoch 3585, Loss: 0.0019385089399293065, Final Batch Loss: 0.0008462488185614347\n",
      "Epoch 3586, Loss: 0.0005267192609608173, Final Batch Loss: 0.0001306647900491953\n",
      "Epoch 3587, Loss: 0.001282622484723106, Final Batch Loss: 0.001096474239602685\n",
      "Epoch 3588, Loss: 0.000497123459354043, Final Batch Loss: 0.0003782243875321001\n",
      "Epoch 3589, Loss: 0.0025757739786058664, Final Batch Loss: 0.0012213303707540035\n",
      "Epoch 3590, Loss: 0.0016205979190999642, Final Batch Loss: 0.00149394606705755\n",
      "Epoch 3591, Loss: 0.0006821985734859481, Final Batch Loss: 0.00045364725519903004\n",
      "Epoch 3592, Loss: 0.0002880443644244224, Final Batch Loss: 0.00011394046305213124\n",
      "Epoch 3593, Loss: 0.0005773680750280619, Final Batch Loss: 0.00031977923936210573\n",
      "Epoch 3594, Loss: 0.0006256226188270375, Final Batch Loss: 0.00013699829287361354\n",
      "Epoch 3595, Loss: 0.0017204844043590128, Final Batch Loss: 0.00022600177908316255\n",
      "Epoch 3596, Loss: 0.00026870614965446293, Final Batch Loss: 0.00011220324086025357\n",
      "Epoch 3597, Loss: 0.0010318054919480346, Final Batch Loss: 9.736950596561655e-05\n",
      "Epoch 3598, Loss: 0.00012435687312972732, Final Batch Loss: 5.2863153541693464e-05\n",
      "Epoch 3599, Loss: 0.0021182864365982823, Final Batch Loss: 0.002007400617003441\n",
      "Epoch 3600, Loss: 0.000417597264458891, Final Batch Loss: 0.00011139708658447489\n",
      "Epoch 3601, Loss: 0.00021768076840089634, Final Batch Loss: 9.979536116588861e-05\n",
      "Epoch 3602, Loss: 0.0008107078610919416, Final Batch Loss: 0.0004393331764731556\n",
      "Epoch 3603, Loss: 0.00034701994445640594, Final Batch Loss: 0.00021454234956763685\n",
      "Epoch 3604, Loss: 0.0012441504513844848, Final Batch Loss: 0.00016049470286816359\n",
      "Epoch 3605, Loss: 0.000316891455440782, Final Batch Loss: 0.00016542374214623123\n",
      "Epoch 3606, Loss: 0.0008311902784043923, Final Batch Loss: 0.0002029779861913994\n",
      "Epoch 3607, Loss: 0.0003807715402217582, Final Batch Loss: 0.0001259306591236964\n",
      "Epoch 3608, Loss: 0.0002244802235509269, Final Batch Loss: 0.00015180438640527427\n",
      "Epoch 3609, Loss: 0.00197725702309981, Final Batch Loss: 0.0015871956711634994\n",
      "Epoch 3610, Loss: 0.0006308799638645723, Final Batch Loss: 0.00022464343055617064\n",
      "Epoch 3611, Loss: 0.0004609850366250612, Final Batch Loss: 8.165572216967121e-05\n",
      "Epoch 3612, Loss: 0.0016495166055392474, Final Batch Loss: 0.0014908057637512684\n",
      "Epoch 3613, Loss: 0.0018914936226792634, Final Batch Loss: 0.0005060668918304145\n",
      "Epoch 3614, Loss: 0.0010154567135032266, Final Batch Loss: 0.0008817336056381464\n",
      "Epoch 3615, Loss: 0.0013060500787105411, Final Batch Loss: 0.0002665276115294546\n",
      "Epoch 3616, Loss: 0.0024037799739744514, Final Batch Loss: 0.0021150626707822084\n",
      "Epoch 3617, Loss: 0.002042724343482405, Final Batch Loss: 0.0017012321623042226\n",
      "Epoch 3618, Loss: 0.000629740345175378, Final Batch Loss: 0.0004737524432130158\n",
      "Epoch 3619, Loss: 0.0001823794809752144, Final Batch Loss: 9.275326010538265e-05\n",
      "Epoch 3620, Loss: 0.0002083164727082476, Final Batch Loss: 7.832095434423536e-05\n",
      "Epoch 3621, Loss: 0.001989238866372034, Final Batch Loss: 0.0002884056593757123\n",
      "Epoch 3622, Loss: 0.0034940046607516706, Final Batch Loss: 8.4525381680578e-05\n",
      "Epoch 3623, Loss: 0.0007731356017757207, Final Batch Loss: 0.00012801532284356654\n",
      "Epoch 3624, Loss: 0.0006450539658544585, Final Batch Loss: 0.0004748455248773098\n",
      "Epoch 3625, Loss: 0.0005682429145963397, Final Batch Loss: 3.1366358598461375e-05\n",
      "Epoch 3626, Loss: 0.0005214811390032992, Final Batch Loss: 0.0002920372935477644\n",
      "Epoch 3627, Loss: 0.00040077655285131186, Final Batch Loss: 0.00014015553460922092\n",
      "Epoch 3628, Loss: 0.0003645126707851887, Final Batch Loss: 0.0002299653715454042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3629, Loss: 0.0007116669985407498, Final Batch Loss: 0.0006732423789799213\n",
      "Epoch 3630, Loss: 0.0004700555364252068, Final Batch Loss: 0.0003900030569639057\n",
      "Epoch 3631, Loss: 0.0006395973032340407, Final Batch Loss: 0.00017534630023874342\n",
      "Epoch 3632, Loss: 0.0015479627472814173, Final Batch Loss: 0.0013149863807484508\n",
      "Epoch 3633, Loss: 0.0008649026567582041, Final Batch Loss: 0.0007532737217843533\n",
      "Epoch 3634, Loss: 0.00021239194393274374, Final Batch Loss: 5.455997961689718e-05\n",
      "Epoch 3635, Loss: 0.0019507710276229773, Final Batch Loss: 0.0019109294516965747\n",
      "Epoch 3636, Loss: 0.0005445449351100251, Final Batch Loss: 0.00017818853666540235\n",
      "Epoch 3637, Loss: 0.00047888039262034, Final Batch Loss: 0.00034786449396051466\n",
      "Epoch 3638, Loss: 0.0018792071787174791, Final Batch Loss: 0.0014417637139558792\n",
      "Epoch 3639, Loss: 0.0029693288961425424, Final Batch Loss: 0.0011723842471837997\n",
      "Epoch 3640, Loss: 0.00677106853981968, Final Batch Loss: 0.00013655841758009046\n",
      "Epoch 3641, Loss: 0.0001912742754939245, Final Batch Loss: 2.8044336431776173e-05\n",
      "Epoch 3642, Loss: 0.00012898887507617474, Final Batch Loss: 5.8824582083616406e-05\n",
      "Epoch 3643, Loss: 0.00067905307514593, Final Batch Loss: 0.0003350905899424106\n",
      "Epoch 3644, Loss: 0.002109642999130301, Final Batch Loss: 0.000206879383767955\n",
      "Epoch 3645, Loss: 0.0005735021113650873, Final Batch Loss: 0.00018280725635122508\n",
      "Epoch 3646, Loss: 0.0039720019267406315, Final Batch Loss: 0.0037654838524758816\n",
      "Epoch 3647, Loss: 0.0007575258350698277, Final Batch Loss: 0.0007248875917866826\n",
      "Epoch 3648, Loss: 0.0002495350636309013, Final Batch Loss: 9.385791781824082e-05\n",
      "Epoch 3649, Loss: 0.0006131003610789776, Final Batch Loss: 0.000540386768989265\n",
      "Epoch 3650, Loss: 0.00023962464547366835, Final Batch Loss: 5.0264879973838106e-05\n",
      "Epoch 3651, Loss: 0.0007675963861402124, Final Batch Loss: 0.00029729382367804646\n",
      "Epoch 3652, Loss: 0.0009867711778497323, Final Batch Loss: 0.00024183587811421603\n",
      "Epoch 3653, Loss: 0.0003177333055646159, Final Batch Loss: 9.74207287072204e-05\n",
      "Epoch 3654, Loss: 0.0018526860512793064, Final Batch Loss: 0.00013114616740494967\n",
      "Epoch 3655, Loss: 0.00014381942673935555, Final Batch Loss: 1.9951152353314683e-05\n",
      "Epoch 3656, Loss: 0.00031277575180865824, Final Batch Loss: 5.413702456280589e-05\n",
      "Epoch 3657, Loss: 0.0009014835814014077, Final Batch Loss: 0.0007053804001770914\n",
      "Epoch 3658, Loss: 0.0003657242195913568, Final Batch Loss: 0.00021067779744043946\n",
      "Epoch 3659, Loss: 0.00020606344332918525, Final Batch Loss: 3.811187343671918e-05\n",
      "Epoch 3660, Loss: 0.0004334822078817524, Final Batch Loss: 0.00032671965891495347\n",
      "Epoch 3661, Loss: 0.00019804581825155765, Final Batch Loss: 9.849019988905638e-05\n",
      "Epoch 3662, Loss: 0.0007559510486316867, Final Batch Loss: 0.0006540499744005501\n",
      "Epoch 3663, Loss: 0.004455111891729757, Final Batch Loss: 0.00013160330126993358\n",
      "Epoch 3664, Loss: 0.00043685206765076146, Final Batch Loss: 7.956937042763457e-05\n",
      "Epoch 3665, Loss: 0.00030196280567906797, Final Batch Loss: 7.395689317490906e-05\n",
      "Epoch 3666, Loss: 0.00024057802511379123, Final Batch Loss: 6.136189040262252e-05\n",
      "Epoch 3667, Loss: 0.0001313257380388677, Final Batch Loss: 2.9012437153141946e-05\n",
      "Epoch 3668, Loss: 0.0005436556893982925, Final Batch Loss: 5.5728865845594555e-05\n",
      "Epoch 3669, Loss: 0.0001799167694116477, Final Batch Loss: 4.365551649243571e-05\n",
      "Epoch 3670, Loss: 0.00024312060850206763, Final Batch Loss: 0.00012704756227321923\n",
      "Epoch 3671, Loss: 0.0008009054836293217, Final Batch Loss: 0.0007538847276009619\n",
      "Epoch 3672, Loss: 0.0009627585022826679, Final Batch Loss: 0.0008715029689483345\n",
      "Epoch 3673, Loss: 0.0008022023102967069, Final Batch Loss: 0.0005891328328289092\n",
      "Epoch 3674, Loss: 0.00043165209353901446, Final Batch Loss: 0.00013429406681098044\n",
      "Epoch 3675, Loss: 0.0026857321499846876, Final Batch Loss: 0.0017202997114509344\n",
      "Epoch 3676, Loss: 0.00011345670645823702, Final Batch Loss: 6.141819176264107e-05\n",
      "Epoch 3677, Loss: 0.0013119965296937153, Final Batch Loss: 0.001141086919233203\n",
      "Epoch 3678, Loss: 0.0006531629187520593, Final Batch Loss: 0.0004239971749484539\n",
      "Epoch 3679, Loss: 0.0011273506679572165, Final Batch Loss: 0.0010786274215206504\n",
      "Epoch 3680, Loss: 0.0014354916056618094, Final Batch Loss: 0.0008381299558095634\n",
      "Epoch 3681, Loss: 0.0012426521861925721, Final Batch Loss: 0.0002735937014222145\n",
      "Epoch 3682, Loss: 0.0006533383566420525, Final Batch Loss: 0.0003109962271992117\n",
      "Epoch 3683, Loss: 0.0012360383698251098, Final Batch Loss: 0.0009809480980038643\n",
      "Epoch 3684, Loss: 0.007952268540975638, Final Batch Loss: 0.0078033762983977795\n",
      "Epoch 3685, Loss: 0.0008392865565838292, Final Batch Loss: 0.0006180177442729473\n",
      "Epoch 3686, Loss: 0.0018193283467553556, Final Batch Loss: 0.0010443150531500578\n",
      "Epoch 3687, Loss: 0.0004323515895521268, Final Batch Loss: 0.00012433518713805825\n",
      "Epoch 3688, Loss: 0.0007068800623528659, Final Batch Loss: 0.00020398874767124653\n",
      "Epoch 3689, Loss: 0.0010102399828610942, Final Batch Loss: 0.0008562985458411276\n",
      "Epoch 3690, Loss: 0.0310237711382797, Final Batch Loss: 0.0001285379839828238\n",
      "Epoch 3691, Loss: 0.0010040749443760433, Final Batch Loss: 6.07840456723352e-06\n",
      "Epoch 3692, Loss: 0.0003862773301079869, Final Batch Loss: 0.00014905081479810178\n",
      "Epoch 3693, Loss: 0.000607613350439351, Final Batch Loss: 0.0005194745026528835\n",
      "Epoch 3694, Loss: 0.000700836448231712, Final Batch Loss: 0.0006372604402713478\n",
      "Epoch 3695, Loss: 0.0008160483557730913, Final Batch Loss: 0.0004768967628479004\n",
      "Epoch 3696, Loss: 0.0004034646990476176, Final Batch Loss: 9.17261786526069e-05\n",
      "Epoch 3697, Loss: 0.00201159346033819, Final Batch Loss: 0.000295047095278278\n",
      "Epoch 3698, Loss: 0.0008256617802544497, Final Batch Loss: 9.137824963545427e-05\n",
      "Epoch 3699, Loss: 0.0002862478722818196, Final Batch Loss: 5.53568679606542e-05\n",
      "Epoch 3700, Loss: 0.00222239958748105, Final Batch Loss: 0.0021810331381857395\n",
      "Epoch 3701, Loss: 0.0008443241531495005, Final Batch Loss: 0.000567871262319386\n",
      "Epoch 3702, Loss: 0.0013721786490350496, Final Batch Loss: 4.578228617901914e-05\n",
      "Epoch 3703, Loss: 0.0069255233102012426, Final Batch Loss: 0.006680221762508154\n",
      "Epoch 3704, Loss: 0.0005635577035718597, Final Batch Loss: 6.43045423203148e-05\n",
      "Epoch 3705, Loss: 0.0016617797591607086, Final Batch Loss: 0.0015598939498886466\n",
      "Epoch 3706, Loss: 0.0005205565175856464, Final Batch Loss: 5.308476829668507e-05\n",
      "Epoch 3707, Loss: 0.0005743916262872517, Final Batch Loss: 0.0003004297614097595\n",
      "Epoch 3708, Loss: 0.0002759140406851657, Final Batch Loss: 8.045158028835431e-05\n",
      "Epoch 3709, Loss: 0.00028916886731167324, Final Batch Loss: 4.150161475990899e-05\n",
      "Epoch 3710, Loss: 0.00045582792881759815, Final Batch Loss: 4.2554001993266866e-05\n",
      "Epoch 3711, Loss: 0.001151026583102066, Final Batch Loss: 4.389568493934348e-05\n",
      "Epoch 3712, Loss: 0.00037733002682216465, Final Batch Loss: 0.0001863145880633965\n",
      "Epoch 3713, Loss: 0.002882087996113114, Final Batch Loss: 0.00011387925769668072\n",
      "Epoch 3714, Loss: 0.0016573078246437944, Final Batch Loss: 7.754108082735911e-05\n",
      "Epoch 3715, Loss: 0.00015871205323492177, Final Batch Loss: 4.4597498344955966e-05\n",
      "Epoch 3716, Loss: 0.0008921548578655347, Final Batch Loss: 0.0001729672512738034\n",
      "Epoch 3717, Loss: 0.0005151911464054137, Final Batch Loss: 0.0002135575341526419\n",
      "Epoch 3718, Loss: 0.00047051857109181583, Final Batch Loss: 0.0001427574025001377\n",
      "Epoch 3719, Loss: 0.001478629361372441, Final Batch Loss: 0.00012231356231495738\n",
      "Epoch 3720, Loss: 0.003405492810998112, Final Batch Loss: 0.003282115561887622\n",
      "Epoch 3721, Loss: 0.0023405260872095823, Final Batch Loss: 0.001642575953155756\n",
      "Epoch 3722, Loss: 0.00025831965467659757, Final Batch Loss: 6.787920574424788e-05\n",
      "Epoch 3723, Loss: 9.987771954911295e-05, Final Batch Loss: 2.0808935005334206e-05\n",
      "Epoch 3724, Loss: 0.00038786618097219616, Final Batch Loss: 0.00017242970352526754\n",
      "Epoch 3725, Loss: 0.00018445382738718763, Final Batch Loss: 0.00015091932436916977\n",
      "Epoch 3726, Loss: 0.00029235214242362417, Final Batch Loss: 0.00025208460283465683\n",
      "Epoch 3727, Loss: 0.0006693232571706176, Final Batch Loss: 0.0003437567502260208\n",
      "Epoch 3728, Loss: 0.0006690133886877447, Final Batch Loss: 0.00019078372861258686\n",
      "Epoch 3729, Loss: 0.0016831388929858804, Final Batch Loss: 0.0005323609802871943\n",
      "Epoch 3730, Loss: 0.0017467474390286952, Final Batch Loss: 0.00023275232524611056\n",
      "Epoch 3731, Loss: 0.007043371209874749, Final Batch Loss: 0.0014399813953787088\n",
      "Epoch 3732, Loss: 0.0010706343746278435, Final Batch Loss: 9.987156954593956e-05\n",
      "Epoch 3733, Loss: 0.001694371945632156, Final Batch Loss: 6.348187889670953e-05\n",
      "Epoch 3734, Loss: 0.0003907025675289333, Final Batch Loss: 0.0002243492635898292\n",
      "Epoch 3735, Loss: 0.006647644127951935, Final Batch Loss: 0.0002851793833542615\n",
      "Epoch 3736, Loss: 0.0015714001492597163, Final Batch Loss: 0.0013261642307043076\n",
      "Epoch 3737, Loss: 0.004256768734194338, Final Batch Loss: 0.0037501149345189333\n",
      "Epoch 3738, Loss: 0.0003769901959458366, Final Batch Loss: 8.444116974715143e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3739, Loss: 0.0003291612592875026, Final Batch Loss: 0.0001158515879069455\n",
      "Epoch 3740, Loss: 0.0002529541161493398, Final Batch Loss: 0.00017096599913202226\n",
      "Epoch 3741, Loss: 0.0006881030203658156, Final Batch Loss: 0.0006418174016289413\n",
      "Epoch 3742, Loss: 0.0003477785940049216, Final Batch Loss: 0.00012221108772791922\n",
      "Epoch 3743, Loss: 0.0010215855727437884, Final Batch Loss: 0.0005735449376516044\n",
      "Epoch 3744, Loss: 0.0015543642221018672, Final Batch Loss: 0.00023117661476135254\n",
      "Epoch 3745, Loss: 0.00012492200403357856, Final Batch Loss: 7.926036778371781e-05\n",
      "Epoch 3746, Loss: 0.0013729265774600208, Final Batch Loss: 0.0008988850750029087\n",
      "Epoch 3747, Loss: 0.0019236359948990867, Final Batch Loss: 0.00016163689724635333\n",
      "Epoch 3748, Loss: 0.000775508196966257, Final Batch Loss: 0.0006995957810431719\n",
      "Epoch 3749, Loss: 0.00029538886883528903, Final Batch Loss: 0.00010959943028865382\n",
      "Epoch 3750, Loss: 0.00037854872789466754, Final Batch Loss: 0.00010591603495413437\n",
      "Epoch 3751, Loss: 0.0002379371435381472, Final Batch Loss: 0.00011656244896585122\n",
      "Epoch 3752, Loss: 0.0002957420874736272, Final Batch Loss: 0.0001017113754642196\n",
      "Epoch 3753, Loss: 0.00035365845542401075, Final Batch Loss: 0.00024236127501353621\n",
      "Epoch 3754, Loss: 0.00015471646474907175, Final Batch Loss: 0.00010353280958952382\n",
      "Epoch 3755, Loss: 0.00019267413154011592, Final Batch Loss: 7.983073737705126e-05\n",
      "Epoch 3756, Loss: 0.0004971662274328992, Final Batch Loss: 0.000290215975837782\n",
      "Epoch 3757, Loss: 0.0004582312540151179, Final Batch Loss: 0.0003317564260214567\n",
      "Epoch 3758, Loss: 0.0004583484187605791, Final Batch Loss: 0.00035837729228660464\n",
      "Epoch 3759, Loss: 0.00021508457575691864, Final Batch Loss: 0.0001373756240354851\n",
      "Epoch 3760, Loss: 0.0005434719787444919, Final Batch Loss: 0.00016969666467048228\n",
      "Epoch 3761, Loss: 0.0007855113799450919, Final Batch Loss: 0.0001447157555958256\n",
      "Epoch 3762, Loss: 0.0005095988453831524, Final Batch Loss: 0.00018367942539043725\n",
      "Epoch 3763, Loss: 0.005357034804546856, Final Batch Loss: 2.791110637190286e-05\n",
      "Epoch 3764, Loss: 0.0011049551831092685, Final Batch Loss: 3.217355697415769e-05\n",
      "Epoch 3765, Loss: 0.0006412782386178151, Final Batch Loss: 0.00014657586871180683\n",
      "Epoch 3766, Loss: 0.00040267696022056043, Final Batch Loss: 0.00026972341584041715\n",
      "Epoch 3767, Loss: 0.00019486231030896306, Final Batch Loss: 0.00011797807383118197\n",
      "Epoch 3768, Loss: 0.0002597862549009733, Final Batch Loss: 0.00018566659127827734\n",
      "Epoch 3769, Loss: 0.0005405753909144551, Final Batch Loss: 0.0003556172887329012\n",
      "Epoch 3770, Loss: 0.001977503110538237, Final Batch Loss: 0.001899408409371972\n",
      "Epoch 3771, Loss: 0.0001308958417212125, Final Batch Loss: 1.9016199075849727e-05\n",
      "Epoch 3772, Loss: 0.0008656447098474018, Final Batch Loss: 0.000745042460039258\n",
      "Epoch 3773, Loss: 0.0001694158199825324, Final Batch Loss: 0.00012911726662423462\n",
      "Epoch 3774, Loss: 0.0018095888663083315, Final Batch Loss: 8.161505684256554e-05\n",
      "Epoch 3775, Loss: 0.0003289817614131607, Final Batch Loss: 8.445583080174401e-05\n",
      "Epoch 3776, Loss: 0.0005358258058549836, Final Batch Loss: 0.00020105410658288747\n",
      "Epoch 3777, Loss: 0.0001232280756084947, Final Batch Loss: 3.0101777156232856e-05\n",
      "Epoch 3778, Loss: 0.0007100876537151635, Final Batch Loss: 0.0005279261968098581\n",
      "Epoch 3779, Loss: 0.00011562174768187106, Final Batch Loss: 3.9025973819661885e-05\n",
      "Epoch 3780, Loss: 0.0015998476737877354, Final Batch Loss: 0.00016292497457470745\n",
      "Epoch 3781, Loss: 0.0004514392785495147, Final Batch Loss: 0.0002106885949615389\n",
      "Epoch 3782, Loss: 0.00017595160170458257, Final Batch Loss: 2.817211498040706e-05\n",
      "Epoch 3783, Loss: 0.000480583737953566, Final Batch Loss: 0.00016152880562003702\n",
      "Epoch 3784, Loss: 0.0011279954051133245, Final Batch Loss: 0.0007445597439073026\n",
      "Epoch 3785, Loss: 0.0034523053327575326, Final Batch Loss: 0.002070908434689045\n",
      "Epoch 3786, Loss: 0.0014489046589005738, Final Batch Loss: 0.001171031966805458\n",
      "Epoch 3787, Loss: 0.0024845916486810893, Final Batch Loss: 0.00043321793782524765\n",
      "Epoch 3788, Loss: 0.0005780169012723491, Final Batch Loss: 6.786284211557359e-05\n",
      "Epoch 3789, Loss: 0.024276847354485653, Final Batch Loss: 0.0001665375748416409\n",
      "Epoch 3790, Loss: 0.0002279586624354124, Final Batch Loss: 6.882798334117979e-05\n",
      "Epoch 3791, Loss: 0.0003185702080372721, Final Batch Loss: 0.00019343414169270545\n",
      "Epoch 3792, Loss: 0.0006059099250705913, Final Batch Loss: 0.0004667917964980006\n",
      "Epoch 3793, Loss: 0.0011170974757988006, Final Batch Loss: 0.0010361680760979652\n",
      "Epoch 3794, Loss: 0.00047932514280546457, Final Batch Loss: 0.00013322582526598126\n",
      "Epoch 3795, Loss: 0.0007254946540342644, Final Batch Loss: 3.8418351323343813e-05\n",
      "Epoch 3796, Loss: 0.0003937165456591174, Final Batch Loss: 0.0003281027893535793\n",
      "Epoch 3797, Loss: 0.0008339300547959283, Final Batch Loss: 0.0001236983953276649\n",
      "Epoch 3798, Loss: 0.00035613194631878287, Final Batch Loss: 0.00016575791232753545\n",
      "Epoch 3799, Loss: 0.00019180145318387076, Final Batch Loss: 8.589372737333179e-05\n",
      "Epoch 3800, Loss: 0.0001871712229331024, Final Batch Loss: 7.768087380100042e-05\n",
      "Epoch 3801, Loss: 7.812452531652525e-05, Final Batch Loss: 3.834281596937217e-05\n",
      "Epoch 3802, Loss: 0.00021264574024826288, Final Batch Loss: 3.51258204318583e-05\n",
      "Epoch 3803, Loss: 8.346432150574401e-05, Final Batch Loss: 3.6577159335138276e-05\n",
      "Epoch 3804, Loss: 0.00014460840611718595, Final Batch Loss: 4.334101686254144e-05\n",
      "Epoch 3805, Loss: 5.741377935919445e-05, Final Batch Loss: 3.2561845728196204e-05\n",
      "Epoch 3806, Loss: 0.00037642758252331987, Final Batch Loss: 7.000842742854729e-05\n",
      "Epoch 3807, Loss: 0.0026394523956696503, Final Batch Loss: 0.0025733618531376123\n",
      "Epoch 3808, Loss: 0.0009775658618309535, Final Batch Loss: 0.0008620803710073233\n",
      "Epoch 3809, Loss: 0.00017863936227513477, Final Batch Loss: 5.549376510316506e-05\n",
      "Epoch 3810, Loss: 0.0038565033464692533, Final Batch Loss: 0.0006373875658027828\n",
      "Epoch 3811, Loss: 0.0006262724091357086, Final Batch Loss: 5.587702980847098e-05\n",
      "Epoch 3812, Loss: 0.0002699872275115922, Final Batch Loss: 0.00010893137368839234\n",
      "Epoch 3813, Loss: 0.0013390726962825283, Final Batch Loss: 0.0012059026630595326\n",
      "Epoch 3814, Loss: 0.0002549019263824448, Final Batch Loss: 0.00018541098688729107\n",
      "Epoch 3815, Loss: 0.000410354565246962, Final Batch Loss: 0.00024647192913107574\n",
      "Epoch 3816, Loss: 0.00013625790597870946, Final Batch Loss: 5.002736725145951e-05\n",
      "Epoch 3817, Loss: 0.019596411468228325, Final Batch Loss: 0.00025039035244844854\n",
      "Epoch 3818, Loss: 0.0019758517682930687, Final Batch Loss: 1.7862703316495754e-05\n",
      "Epoch 3819, Loss: 0.00020427171693881974, Final Batch Loss: 6.140606274129823e-05\n",
      "Epoch 3820, Loss: 0.0005472634293255396, Final Batch Loss: 0.0005188197246752679\n",
      "Epoch 3821, Loss: 0.0001057979607139714, Final Batch Loss: 3.956718137487769e-05\n",
      "Epoch 3822, Loss: 0.0003442210509092547, Final Batch Loss: 0.00022549812274519354\n",
      "Epoch 3823, Loss: 0.000800482648628531, Final Batch Loss: 1.5234061720548198e-05\n",
      "Epoch 3824, Loss: 0.0003741271357284859, Final Batch Loss: 3.1257994123734534e-05\n",
      "Epoch 3825, Loss: 0.001061679844497121, Final Batch Loss: 1.9867022274411283e-05\n",
      "Epoch 3826, Loss: 0.00016849788516992703, Final Batch Loss: 8.663167682243511e-05\n",
      "Epoch 3827, Loss: 0.0001668797922320664, Final Batch Loss: 0.00014501911937259138\n",
      "Epoch 3828, Loss: 0.0006787236125092022, Final Batch Loss: 0.00010773439862532541\n",
      "Epoch 3829, Loss: 0.0019622701984189916, Final Batch Loss: 1.7005444533424452e-05\n",
      "Epoch 3830, Loss: 0.00023638285892957356, Final Batch Loss: 2.4130617021000944e-05\n",
      "Epoch 3831, Loss: 0.0004150801250943914, Final Batch Loss: 4.381923645269126e-05\n",
      "Epoch 3832, Loss: 0.00028939305047970265, Final Batch Loss: 0.00015224088565446436\n",
      "Epoch 3833, Loss: 8.479009557049721e-05, Final Batch Loss: 3.943569754483178e-05\n",
      "Epoch 3834, Loss: 4.4479700591182336e-05, Final Batch Loss: 1.533779504825361e-05\n",
      "Epoch 3835, Loss: 0.00023319742467720062, Final Batch Loss: 0.00022110622376203537\n",
      "Epoch 3836, Loss: 0.0002255736108054407, Final Batch Loss: 0.00016117701306939125\n",
      "Epoch 3837, Loss: 0.00023165684615378268, Final Batch Loss: 0.00019634720229078084\n",
      "Epoch 3838, Loss: 0.00011513927893247455, Final Batch Loss: 6.002882946631871e-05\n",
      "Epoch 3839, Loss: 0.0057544821975170635, Final Batch Loss: 9.455272083869204e-05\n",
      "Epoch 3840, Loss: 0.0001293784662266262, Final Batch Loss: 6.765593570889905e-05\n",
      "Epoch 3841, Loss: 0.00012512324246927164, Final Batch Loss: 7.613922207383439e-05\n",
      "Epoch 3842, Loss: 0.0020613593223970383, Final Batch Loss: 0.0004066206456627697\n",
      "Epoch 3843, Loss: 0.00011290900147287175, Final Batch Loss: 9.348153253085911e-05\n",
      "Epoch 3844, Loss: 0.01733244094066322, Final Batch Loss: 0.0015072308015078306\n",
      "Epoch 3845, Loss: 3.7430205338750966e-05, Final Batch Loss: 1.5390511180157773e-05\n",
      "Epoch 3846, Loss: 0.00025870213721645996, Final Batch Loss: 0.00016833860718179494\n",
      "Epoch 3847, Loss: 0.0006385961532942019, Final Batch Loss: 0.0005819668294861913\n",
      "Epoch 3848, Loss: 0.0002296401871717535, Final Batch Loss: 0.00012643200170714408\n",
      "Epoch 3849, Loss: 0.0016119795400300063, Final Batch Loss: 9.728558507049456e-05\n",
      "Epoch 3850, Loss: 0.0003772606432903558, Final Batch Loss: 8.815818000584841e-05\n",
      "Epoch 3851, Loss: 0.014314539563201834, Final Batch Loss: 0.014218448661267757\n",
      "Epoch 3852, Loss: 0.05262373690493405, Final Batch Loss: 0.0032087110448628664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3853, Loss: 0.0021152706613065675, Final Batch Loss: 6.357424717862159e-05\n",
      "Epoch 3854, Loss: 0.0023726538092887495, Final Batch Loss: 4.782679388881661e-05\n",
      "Epoch 3855, Loss: 0.0013880006517865695, Final Batch Loss: 6.95606941008009e-05\n",
      "Epoch 3856, Loss: 0.00024921638760133646, Final Batch Loss: 5.2109822718193755e-05\n",
      "Epoch 3857, Loss: 0.0007061451724439394, Final Batch Loss: 0.000654304982163012\n",
      "Epoch 3858, Loss: 0.006984103696595412, Final Batch Loss: 0.0069023058749735355\n",
      "Epoch 3859, Loss: 0.0001461253414163366, Final Batch Loss: 0.00011934051144635305\n",
      "Epoch 3860, Loss: 0.000352526312781265, Final Batch Loss: 0.00030811631586402655\n",
      "Epoch 3861, Loss: 0.0006245448894333094, Final Batch Loss: 0.00017729384126141667\n",
      "Epoch 3862, Loss: 0.0069441169034689665, Final Batch Loss: 0.0026599362026900053\n",
      "Epoch 3863, Loss: 0.0003687943681143224, Final Batch Loss: 0.00028142204973846674\n",
      "Epoch 3864, Loss: 0.0005047417507739738, Final Batch Loss: 0.00027354451594874263\n",
      "Epoch 3865, Loss: 0.00017069323803298175, Final Batch Loss: 4.6997476601973176e-05\n",
      "Epoch 3866, Loss: 0.001419716041709762, Final Batch Loss: 6.703857070533559e-05\n",
      "Epoch 3867, Loss: 0.01443605286476668, Final Batch Loss: 9.629943815525621e-05\n",
      "Epoch 3868, Loss: 0.0013639439712278545, Final Batch Loss: 0.0007944861426949501\n",
      "Epoch 3869, Loss: 0.05341720240176073, Final Batch Loss: 3.303619087091647e-05\n",
      "Epoch 3870, Loss: 0.0002688595268409699, Final Batch Loss: 0.00010969815775752068\n",
      "Epoch 3871, Loss: 0.0029707298381254077, Final Batch Loss: 0.000751874758861959\n",
      "Epoch 3872, Loss: 0.018592267209896818, Final Batch Loss: 5.3445721277967095e-05\n",
      "Epoch 3873, Loss: 0.00012374879588605836, Final Batch Loss: 3.365905286045745e-05\n",
      "Epoch 3874, Loss: 0.04312699974980205, Final Batch Loss: 0.0017976047238335013\n",
      "Epoch 3875, Loss: 0.0012715009215753525, Final Batch Loss: 0.00023039590450935066\n",
      "Epoch 3876, Loss: 0.0002699487376958132, Final Batch Loss: 0.00013348687207326293\n",
      "Epoch 3877, Loss: 0.00042240862967446446, Final Batch Loss: 0.00015917734708637\n",
      "Epoch 3878, Loss: 0.00037937187880743295, Final Batch Loss: 0.00019306023023091257\n",
      "Epoch 3879, Loss: 0.0003825213425443508, Final Batch Loss: 0.00011996739340247586\n",
      "Epoch 3880, Loss: 0.004956849690643139, Final Batch Loss: 0.00020612154912669212\n",
      "Epoch 3881, Loss: 0.0006502199830720201, Final Batch Loss: 0.00017734851280692965\n",
      "Epoch 3882, Loss: 0.00031954656878951937, Final Batch Loss: 0.0002520690322853625\n",
      "Epoch 3883, Loss: 0.0006397744873538613, Final Batch Loss: 0.0001723853638395667\n",
      "Epoch 3884, Loss: 0.0021475261892192066, Final Batch Loss: 0.0016898034373298287\n",
      "Epoch 3885, Loss: 0.0003755840880330652, Final Batch Loss: 0.00024476999533362687\n",
      "Epoch 3886, Loss: 0.0009417418041266501, Final Batch Loss: 0.0004165454884059727\n",
      "Epoch 3887, Loss: 0.00017070328613044694, Final Batch Loss: 0.00010024516814155504\n",
      "Epoch 3888, Loss: 0.00033425536457798444, Final Batch Loss: 5.861688623554073e-05\n",
      "Epoch 3889, Loss: 0.0005143517337273806, Final Batch Loss: 0.00025573919992893934\n",
      "Epoch 3890, Loss: 0.009152812039246783, Final Batch Loss: 0.00016734571545384824\n",
      "Epoch 3891, Loss: 0.00041051088192034513, Final Batch Loss: 0.00030785772833041847\n",
      "Epoch 3892, Loss: 0.009108366066357121, Final Batch Loss: 0.00010778065188787878\n",
      "Epoch 3893, Loss: 0.0009167209209408611, Final Batch Loss: 0.00041642689029686153\n",
      "Epoch 3894, Loss: 0.00024370318715227768, Final Batch Loss: 0.0001742223830660805\n",
      "Epoch 3895, Loss: 0.0004494681488722563, Final Batch Loss: 6.055156700313091e-05\n",
      "Epoch 3896, Loss: 0.0009082533069886267, Final Batch Loss: 0.00039703038055449724\n",
      "Epoch 3897, Loss: 0.000691278139129281, Final Batch Loss: 0.0003620126808527857\n",
      "Epoch 3898, Loss: 0.0015832225908525288, Final Batch Loss: 0.0008248696103692055\n",
      "Epoch 3899, Loss: 0.00233680458040908, Final Batch Loss: 0.001965966774150729\n",
      "Epoch 3900, Loss: 0.00035955265047959983, Final Batch Loss: 0.000134744550450705\n",
      "Epoch 3901, Loss: 0.0005596427217824385, Final Batch Loss: 0.00041456992039456964\n",
      "Epoch 3902, Loss: 0.0014237735740607604, Final Batch Loss: 0.0012292347382754087\n",
      "Epoch 3903, Loss: 0.00010953280434478074, Final Batch Loss: 3.552916314220056e-05\n",
      "Epoch 3904, Loss: 0.00036685210943687707, Final Batch Loss: 0.0002262714406242594\n",
      "Epoch 3905, Loss: 0.0007973164902068675, Final Batch Loss: 0.0005769862327724695\n",
      "Epoch 3906, Loss: 0.00020174099336145446, Final Batch Loss: 5.009843880543485e-05\n",
      "Epoch 3907, Loss: 0.00096447131363675, Final Batch Loss: 0.00046397175174206495\n",
      "Epoch 3908, Loss: 0.0004533036262728274, Final Batch Loss: 0.0002901753759942949\n",
      "Epoch 3909, Loss: 0.004342020460171625, Final Batch Loss: 0.0040847365744411945\n",
      "Epoch 3910, Loss: 0.0012051027151755989, Final Batch Loss: 0.0007286830805242062\n",
      "Epoch 3911, Loss: 0.00026568265457171947, Final Batch Loss: 0.00015862919099163264\n",
      "Epoch 3912, Loss: 0.00021803569688927382, Final Batch Loss: 9.454507380723953e-05\n",
      "Epoch 3913, Loss: 0.0004681650607381016, Final Batch Loss: 0.00025407999055460095\n",
      "Epoch 3914, Loss: 0.0010111247829627246, Final Batch Loss: 0.0006240304210223258\n",
      "Epoch 3915, Loss: 0.0005269679095363244, Final Batch Loss: 0.0004037986509501934\n",
      "Epoch 3916, Loss: 0.00033464128500781953, Final Batch Loss: 0.00018360641843173653\n",
      "Epoch 3917, Loss: 0.0005885618120373692, Final Batch Loss: 0.0005306331440806389\n",
      "Epoch 3918, Loss: 0.0022978919587330893, Final Batch Loss: 0.00013334090181160718\n",
      "Epoch 3919, Loss: 0.0019556013867259026, Final Batch Loss: 0.0008508739992976189\n",
      "Epoch 3920, Loss: 0.0037005176418460906, Final Batch Loss: 0.0035428290721029043\n",
      "Epoch 3921, Loss: 0.002144547092029825, Final Batch Loss: 0.000140682008350268\n",
      "Epoch 3922, Loss: 0.00023368549955193885, Final Batch Loss: 5.665100252372213e-05\n",
      "Epoch 3923, Loss: 0.0009579743273206986, Final Batch Loss: 9.799484541872516e-05\n",
      "Epoch 3924, Loss: 0.00026174970116699114, Final Batch Loss: 6.16749093751423e-05\n",
      "Epoch 3925, Loss: 0.0004928505077259615, Final Batch Loss: 6.495237175840884e-05\n",
      "Epoch 3926, Loss: 0.000718608993338421, Final Batch Loss: 0.00044634201913140714\n",
      "Epoch 3927, Loss: 0.002387097294558771, Final Batch Loss: 0.0001520008809166029\n",
      "Epoch 3928, Loss: 0.00023905810303403996, Final Batch Loss: 3.8974463677732274e-05\n",
      "Epoch 3929, Loss: 0.0012769087625201792, Final Batch Loss: 0.0008507443126291037\n",
      "Epoch 3930, Loss: 0.0001702452209428884, Final Batch Loss: 8.044001151574776e-05\n",
      "Epoch 3931, Loss: 0.0004652980132959783, Final Batch Loss: 0.00023318165040109307\n",
      "Epoch 3932, Loss: 0.0006305474998953287, Final Batch Loss: 0.0005747087998315692\n",
      "Epoch 3933, Loss: 0.00012950239761266857, Final Batch Loss: 6.378840771503747e-05\n",
      "Epoch 3934, Loss: 0.0006624762754654512, Final Batch Loss: 6.516596477013081e-05\n",
      "Epoch 3935, Loss: 0.00174152001272887, Final Batch Loss: 0.0013444984797388315\n",
      "Epoch 3936, Loss: 0.00041379583126399666, Final Batch Loss: 0.00010098198254127055\n",
      "Epoch 3937, Loss: 0.0004167207080172375, Final Batch Loss: 0.00034257268998771906\n",
      "Epoch 3938, Loss: 0.0010267253601341508, Final Batch Loss: 8.314442675327882e-05\n",
      "Epoch 3939, Loss: 0.00018968634685734287, Final Batch Loss: 8.023480040719733e-05\n",
      "Epoch 3940, Loss: 0.0006692395400023088, Final Batch Loss: 5.4722928325645626e-05\n",
      "Epoch 3941, Loss: 0.0003261875390307978, Final Batch Loss: 0.0001677084801485762\n",
      "Epoch 3942, Loss: 0.009747112795594148, Final Batch Loss: 0.009679270908236504\n",
      "Epoch 3943, Loss: 0.0006908869909239002, Final Batch Loss: 0.00010767381900222972\n",
      "Epoch 3944, Loss: 0.0014378135092556477, Final Batch Loss: 0.00023640843573957682\n",
      "Epoch 3945, Loss: 0.0005382558665587567, Final Batch Loss: 6.982217746553943e-05\n",
      "Epoch 3946, Loss: 0.0009906177874654531, Final Batch Loss: 0.0004975206684321165\n",
      "Epoch 3947, Loss: 0.0005583364691119641, Final Batch Loss: 0.00036767515121027827\n",
      "Epoch 3948, Loss: 0.02587715905974619, Final Batch Loss: 0.025526536628603935\n",
      "Epoch 3949, Loss: 0.002698223863262683, Final Batch Loss: 0.00015630718553438783\n",
      "Epoch 3950, Loss: 0.05538318745675497, Final Batch Loss: 0.05494106560945511\n",
      "Epoch 3951, Loss: 0.002103545135469176, Final Batch Loss: 0.0019671262707561255\n",
      "Epoch 3952, Loss: 0.021507375582586974, Final Batch Loss: 0.02111095003783703\n",
      "Epoch 3953, Loss: 0.00021926243061898276, Final Batch Loss: 0.00012629888078663498\n",
      "Epoch 3954, Loss: 0.00544084922876209, Final Batch Loss: 0.0005299084587022662\n",
      "Epoch 3955, Loss: 0.0020748678070958704, Final Batch Loss: 8.35613755043596e-05\n",
      "Epoch 3956, Loss: 0.0005735454324167222, Final Batch Loss: 0.00030201245681382716\n",
      "Epoch 3957, Loss: 0.0033644672876107506, Final Batch Loss: 0.00011783837544498965\n",
      "Epoch 3958, Loss: 0.01013911617337726, Final Batch Loss: 0.0097917215898633\n",
      "Epoch 3959, Loss: 0.0004299216525396332, Final Batch Loss: 0.0002540002460591495\n",
      "Epoch 3960, Loss: 0.0009436624532099813, Final Batch Loss: 0.0006622616783715785\n",
      "Epoch 3961, Loss: 0.0031966344686225057, Final Batch Loss: 0.0028790156356990337\n",
      "Epoch 3962, Loss: 0.00040019328298512846, Final Batch Loss: 0.00011647144856397063\n",
      "Epoch 3963, Loss: 0.011232963850488886, Final Batch Loss: 0.00018698078929446638\n",
      "Epoch 3964, Loss: 0.006010220575262792, Final Batch Loss: 0.00023634145327378064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3965, Loss: 0.001912255393108353, Final Batch Loss: 0.0015757177025079727\n",
      "Epoch 3966, Loss: 0.0025716054369695485, Final Batch Loss: 0.002027516718953848\n",
      "Epoch 3967, Loss: 0.01650164183229208, Final Batch Loss: 0.010921468026936054\n",
      "Epoch 3968, Loss: 0.0015161698684096336, Final Batch Loss: 0.0004684552550315857\n",
      "Epoch 3969, Loss: 0.0004809228557860479, Final Batch Loss: 0.00023566554591525346\n",
      "Epoch 3970, Loss: 0.004305030655814335, Final Batch Loss: 0.0004455682064872235\n",
      "Epoch 3971, Loss: 0.003086873286520131, Final Batch Loss: 0.0001826795778470114\n",
      "Epoch 3972, Loss: 0.0007182868430390954, Final Batch Loss: 0.0001768332440406084\n",
      "Epoch 3973, Loss: 0.0014826903643552214, Final Batch Loss: 0.0012230409774929285\n",
      "Epoch 3974, Loss: 0.0008159716089721769, Final Batch Loss: 0.00010089928400702775\n",
      "Epoch 3975, Loss: 0.0008520503324689344, Final Batch Loss: 0.0007043377845548093\n",
      "Epoch 3976, Loss: 0.005229867616435513, Final Batch Loss: 8.904197602532804e-05\n",
      "Epoch 3977, Loss: 0.0005004306003684178, Final Batch Loss: 0.0002922543208114803\n",
      "Epoch 3978, Loss: 0.000516544736456126, Final Batch Loss: 0.00025661225663498044\n",
      "Epoch 3979, Loss: 0.001478853781009093, Final Batch Loss: 0.0002507649187464267\n",
      "Epoch 3980, Loss: 0.0035052443126915023, Final Batch Loss: 0.0033542278688400984\n",
      "Epoch 3981, Loss: 0.004936729310429655, Final Batch Loss: 0.00013100051728542894\n",
      "Epoch 3982, Loss: 0.00028785537142539397, Final Batch Loss: 0.0001917948538903147\n",
      "Epoch 3983, Loss: 0.00017887695867102593, Final Batch Loss: 9.333422349300236e-05\n",
      "Epoch 3984, Loss: 0.009333348600193858, Final Batch Loss: 0.0062319692224264145\n",
      "Epoch 3985, Loss: 0.0006939058075658977, Final Batch Loss: 0.00022138352505862713\n",
      "Epoch 3986, Loss: 0.0005852234608028084, Final Batch Loss: 0.000288028153590858\n",
      "Epoch 3987, Loss: 0.0007669372425880283, Final Batch Loss: 0.00020428907009772956\n",
      "Epoch 3988, Loss: 0.000471160004963167, Final Batch Loss: 0.0001687801122898236\n",
      "Epoch 3989, Loss: 0.00021167247905395925, Final Batch Loss: 0.00010306711919838563\n",
      "Epoch 3990, Loss: 0.0015003918670117855, Final Batch Loss: 0.00026672566309571266\n",
      "Epoch 3991, Loss: 0.004820916612516157, Final Batch Loss: 0.004729762207716703\n",
      "Epoch 3992, Loss: 0.00032625898893456906, Final Batch Loss: 0.0001460951316403225\n",
      "Epoch 3993, Loss: 0.00019237192464061081, Final Batch Loss: 0.00012263380631338805\n",
      "Epoch 3994, Loss: 0.0008006610005395487, Final Batch Loss: 0.00016539405623916537\n",
      "Epoch 3995, Loss: 0.00015265207912307233, Final Batch Loss: 5.223902553552762e-05\n",
      "Epoch 3996, Loss: 0.0002561286819400266, Final Batch Loss: 0.00011758756591007113\n",
      "Epoch 3997, Loss: 0.0034710208637989126, Final Batch Loss: 8.938347309594974e-05\n",
      "Epoch 3998, Loss: 0.006071788586268667, Final Batch Loss: 0.006014931946992874\n",
      "Epoch 3999, Loss: 0.00816447802935727, Final Batch Loss: 9.017300908453763e-05\n",
      "Epoch 4000, Loss: 0.004299751693906728, Final Batch Loss: 6.655904144281521e-05\n",
      "Epoch 4001, Loss: 0.0007072981970850378, Final Batch Loss: 0.0001486173423472792\n",
      "Epoch 4002, Loss: 0.00032690064108464867, Final Batch Loss: 0.0001872976281447336\n",
      "Epoch 4003, Loss: 0.021280688903061673, Final Batch Loss: 0.02118247002363205\n",
      "Epoch 4004, Loss: 0.0007302354788407683, Final Batch Loss: 0.000476080400403589\n",
      "Epoch 4005, Loss: 0.0010923065419774503, Final Batch Loss: 0.00010895144077949226\n",
      "Epoch 4006, Loss: 0.0006157444295240566, Final Batch Loss: 0.00017351713904645294\n",
      "Epoch 4007, Loss: 0.0005276244919514284, Final Batch Loss: 0.00035820051562041044\n",
      "Epoch 4008, Loss: 0.00022941790302866139, Final Batch Loss: 4.6779070544289425e-05\n",
      "Epoch 4009, Loss: 0.0022336766778607853, Final Batch Loss: 0.0021449155174195766\n",
      "Epoch 4010, Loss: 0.0017570358468219638, Final Batch Loss: 0.0010985068511217833\n",
      "Epoch 4011, Loss: 0.0002988506057590712, Final Batch Loss: 3.10240029648412e-05\n",
      "Epoch 4012, Loss: 0.0009029655775520951, Final Batch Loss: 0.0005139587447047234\n",
      "Epoch 4013, Loss: 0.0006817677640356123, Final Batch Loss: 0.0003644712269306183\n",
      "Epoch 4014, Loss: 0.0034658478398341686, Final Batch Loss: 0.00026944003184325993\n",
      "Epoch 4015, Loss: 0.0002714275033213198, Final Batch Loss: 9.17382858460769e-05\n",
      "Epoch 4016, Loss: 0.000760040624300018, Final Batch Loss: 0.00029292135150171816\n",
      "Epoch 4017, Loss: 0.0003795885277213529, Final Batch Loss: 0.00011006848944816738\n",
      "Epoch 4018, Loss: 0.0016469888796564192, Final Batch Loss: 0.00014293458661995828\n",
      "Epoch 4019, Loss: 0.0008201530145015568, Final Batch Loss: 0.00026492474717088044\n",
      "Epoch 4020, Loss: 0.004426338477060199, Final Batch Loss: 0.0009823448490351439\n",
      "Epoch 4021, Loss: 0.0008976076060207561, Final Batch Loss: 0.0007214393117465079\n",
      "Epoch 4022, Loss: 0.0007065698009682819, Final Batch Loss: 0.0001866142119979486\n",
      "Epoch 4023, Loss: 0.00021628005197271705, Final Batch Loss: 0.00012646705727092922\n",
      "Epoch 4024, Loss: 0.00023303737543756142, Final Batch Loss: 9.241514635505155e-05\n",
      "Epoch 4025, Loss: 0.002658687299117446, Final Batch Loss: 0.0021247067488729954\n",
      "Epoch 4026, Loss: 0.0009593656577635556, Final Batch Loss: 0.0006637178012169898\n",
      "Epoch 4027, Loss: 0.005903419863898307, Final Batch Loss: 0.0006063816254027188\n",
      "Epoch 4028, Loss: 0.004362349107395858, Final Batch Loss: 0.00021314917830750346\n",
      "Epoch 4029, Loss: 0.00045631362445419654, Final Batch Loss: 9.770740143721923e-05\n",
      "Epoch 4030, Loss: 0.001263901125639677, Final Batch Loss: 0.0008426104905083776\n",
      "Epoch 4031, Loss: 0.0008790485007921234, Final Batch Loss: 0.0006365660228766501\n",
      "Epoch 4032, Loss: 0.0005418146174633875, Final Batch Loss: 0.0001482845254940912\n",
      "Epoch 4033, Loss: 0.0003993760619778186, Final Batch Loss: 0.00020172097720205784\n",
      "Epoch 4034, Loss: 0.0002593587269075215, Final Batch Loss: 9.31917893467471e-05\n",
      "Epoch 4035, Loss: 0.00029544688732130453, Final Batch Loss: 5.564236926147714e-05\n",
      "Epoch 4036, Loss: 0.00029393399017862976, Final Batch Loss: 0.00013169764133635908\n",
      "Epoch 4037, Loss: 0.0010167109139729291, Final Batch Loss: 0.0004309569194447249\n",
      "Epoch 4038, Loss: 0.0005062200507381931, Final Batch Loss: 0.0001303619792452082\n",
      "Epoch 4039, Loss: 0.0020661633971030824, Final Batch Loss: 6.658751954091713e-05\n",
      "Epoch 4040, Loss: 0.0003594022709876299, Final Batch Loss: 0.00012825909652747214\n",
      "Epoch 4041, Loss: 0.00034700067044468597, Final Batch Loss: 0.0002738846524152905\n",
      "Epoch 4042, Loss: 0.000277771549008321, Final Batch Loss: 0.00015818409156054258\n",
      "Epoch 4043, Loss: 0.0003210194845451042, Final Batch Loss: 0.00016250615590251982\n",
      "Epoch 4044, Loss: 0.00038687924097757787, Final Batch Loss: 0.0002917804813478142\n",
      "Epoch 4045, Loss: 0.0009088342194445431, Final Batch Loss: 0.0007323087193071842\n",
      "Epoch 4046, Loss: 0.001702158187981695, Final Batch Loss: 0.001502407481893897\n",
      "Epoch 4047, Loss: 0.0003992717174696736, Final Batch Loss: 0.0002836981730069965\n",
      "Epoch 4048, Loss: 0.0004877778992522508, Final Batch Loss: 0.0002516742970328778\n",
      "Epoch 4049, Loss: 0.0008049029129324481, Final Batch Loss: 0.00018198198813479394\n",
      "Epoch 4050, Loss: 0.0007720675494056195, Final Batch Loss: 0.00026097704540006816\n",
      "Epoch 4051, Loss: 0.0026042681420221925, Final Batch Loss: 0.0015880001010373235\n",
      "Epoch 4052, Loss: 0.0002306785390828736, Final Batch Loss: 0.00010695383389247581\n",
      "Epoch 4053, Loss: 0.0006946845242055133, Final Batch Loss: 0.00048279351904056966\n",
      "Epoch 4054, Loss: 0.00037290430191205814, Final Batch Loss: 0.00026000142679549754\n",
      "Epoch 4055, Loss: 0.0002841029709088616, Final Batch Loss: 0.00010171390749746934\n",
      "Epoch 4056, Loss: 0.00031604729883838445, Final Batch Loss: 0.00025829282822087407\n",
      "Epoch 4057, Loss: 0.0005492557083925931, Final Batch Loss: 2.4032093278947286e-05\n",
      "Epoch 4058, Loss: 0.00041408022661926225, Final Batch Loss: 0.0003107388620264828\n",
      "Epoch 4059, Loss: 0.0007560415106127039, Final Batch Loss: 0.0006625682581216097\n",
      "Epoch 4060, Loss: 0.001015459158224985, Final Batch Loss: 0.0008347518742084503\n",
      "Epoch 4061, Loss: 0.00012810002954211086, Final Batch Loss: 7.864801591495052e-05\n",
      "Epoch 4062, Loss: 0.0005740947090089321, Final Batch Loss: 0.00019414146663621068\n",
      "Epoch 4063, Loss: 0.0007325913175009191, Final Batch Loss: 6.521737668663263e-05\n",
      "Epoch 4064, Loss: 0.00040008549694903195, Final Batch Loss: 8.374781464226544e-05\n",
      "Epoch 4065, Loss: 0.0005924991564825177, Final Batch Loss: 0.0002892765332944691\n",
      "Epoch 4066, Loss: 0.0005318914481904358, Final Batch Loss: 0.00041781828622333705\n",
      "Epoch 4067, Loss: 0.00037538670585490763, Final Batch Loss: 0.00019900377083104104\n",
      "Epoch 4068, Loss: 0.0009284110201406293, Final Batch Loss: 4.837911546928808e-05\n",
      "Epoch 4069, Loss: 0.00023142954159993678, Final Batch Loss: 8.247172809205949e-05\n",
      "Epoch 4070, Loss: 0.0005795457400381565, Final Batch Loss: 0.0003215530887246132\n",
      "Epoch 4071, Loss: 0.00019183791300747544, Final Batch Loss: 6.733315240126103e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4072, Loss: 0.0008389748691115528, Final Batch Loss: 0.0002566770708654076\n",
      "Epoch 4073, Loss: 0.00020263516489649191, Final Batch Loss: 0.00014208024367690086\n",
      "Epoch 4074, Loss: 0.0006391035567503422, Final Batch Loss: 0.000222240254515782\n",
      "Epoch 4075, Loss: 0.0004901720094494522, Final Batch Loss: 0.00022245419677346945\n",
      "Epoch 4076, Loss: 0.006957529025385156, Final Batch Loss: 0.006542174145579338\n",
      "Epoch 4077, Loss: 0.000719317868060898, Final Batch Loss: 5.4516705858986825e-05\n",
      "Epoch 4078, Loss: 0.0005669280071742833, Final Batch Loss: 0.00036467835889197886\n",
      "Epoch 4079, Loss: 0.00037658712244592607, Final Batch Loss: 7.536585326306522e-05\n",
      "Epoch 4080, Loss: 0.00041593283094698563, Final Batch Loss: 6.61682352074422e-05\n",
      "Epoch 4081, Loss: 0.0005178163119126111, Final Batch Loss: 0.0002951406640931964\n",
      "Epoch 4082, Loss: 0.0015183740761131048, Final Batch Loss: 0.0007285366300493479\n",
      "Epoch 4083, Loss: 0.0004553142352961004, Final Batch Loss: 0.00033744826214388013\n",
      "Epoch 4084, Loss: 0.0005705615840270184, Final Batch Loss: 0.0005387444398365915\n",
      "Epoch 4085, Loss: 0.00021396815645857714, Final Batch Loss: 4.433942012838088e-05\n",
      "Epoch 4086, Loss: 0.0002810532314470038, Final Batch Loss: 0.0001741594314808026\n",
      "Epoch 4087, Loss: 0.00016488681285409257, Final Batch Loss: 8.734238508623093e-05\n",
      "Epoch 4088, Loss: 0.0006858210253994912, Final Batch Loss: 0.0002690452092792839\n",
      "Epoch 4089, Loss: 0.0009532768817734905, Final Batch Loss: 0.0008814401808194816\n",
      "Epoch 4090, Loss: 0.0030104813049547374, Final Batch Loss: 0.002302126493304968\n",
      "Epoch 4091, Loss: 0.0010274950473103672, Final Batch Loss: 0.0005662327748723328\n",
      "Epoch 4092, Loss: 0.0052194234522175975, Final Batch Loss: 8.009118755580857e-05\n",
      "Epoch 4093, Loss: 0.00035264771577203646, Final Batch Loss: 0.00011993548105238006\n",
      "Epoch 4094, Loss: 0.0002901292064052541, Final Batch Loss: 0.00023824545496609062\n",
      "Epoch 4095, Loss: 0.00048218757729046047, Final Batch Loss: 0.00037692009937018156\n",
      "Epoch 4096, Loss: 0.0006247029741643928, Final Batch Loss: 0.0005617515998892486\n",
      "Epoch 4097, Loss: 0.00023964829051692504, Final Batch Loss: 1.5209037883323617e-05\n",
      "Epoch 4098, Loss: 0.0001593369488546159, Final Batch Loss: 5.351919753593393e-05\n",
      "Epoch 4099, Loss: 0.000916263903491199, Final Batch Loss: 0.00022420776076614857\n",
      "Epoch 4100, Loss: 0.0009320976096205413, Final Batch Loss: 0.0006564802606590092\n",
      "Epoch 4101, Loss: 0.0021045222383691, Final Batch Loss: 0.001939029316417873\n",
      "Epoch 4102, Loss: 0.00016052980936365202, Final Batch Loss: 3.7827012420166284e-05\n",
      "Epoch 4103, Loss: 0.00022634517517872155, Final Batch Loss: 0.00013130786828696728\n",
      "Epoch 4104, Loss: 0.0005517409299500287, Final Batch Loss: 0.0002803865063469857\n",
      "Epoch 4105, Loss: 0.000199060799786821, Final Batch Loss: 7.389957318082452e-05\n",
      "Epoch 4106, Loss: 9.490834418102168e-05, Final Batch Loss: 2.1081399609101936e-05\n",
      "Epoch 4107, Loss: 0.0010087787231896073, Final Batch Loss: 0.0008420021622441709\n",
      "Epoch 4108, Loss: 0.0004258352710166946, Final Batch Loss: 8.089201583061367e-05\n",
      "Epoch 4109, Loss: 0.00020463232067413628, Final Batch Loss: 0.0001038945047184825\n",
      "Epoch 4110, Loss: 0.0001566150131111499, Final Batch Loss: 3.7599911593133584e-05\n",
      "Epoch 4111, Loss: 0.00024861874408088624, Final Batch Loss: 0.00010943124652840197\n",
      "Epoch 4112, Loss: 0.00028932286659255624, Final Batch Loss: 0.0001498434430686757\n",
      "Epoch 4113, Loss: 0.0014346564857987687, Final Batch Loss: 0.0012559746392071247\n",
      "Epoch 4114, Loss: 0.0002746141253737733, Final Batch Loss: 0.00019442672783043236\n",
      "Epoch 4115, Loss: 0.0006587418611161411, Final Batch Loss: 0.000338161364197731\n",
      "Epoch 4116, Loss: 0.00027173197304364294, Final Batch Loss: 0.0001412768178852275\n",
      "Epoch 4117, Loss: 0.00019930427151848562, Final Batch Loss: 3.412097066757269e-05\n",
      "Epoch 4118, Loss: 0.00026801582134794444, Final Batch Loss: 0.0001390760444337502\n",
      "Epoch 4119, Loss: 0.02447757282789098, Final Batch Loss: 7.4365823820699e-05\n",
      "Epoch 4120, Loss: 0.0005611375017906539, Final Batch Loss: 9.179818880511448e-05\n",
      "Epoch 4121, Loss: 0.0001985899216379039, Final Batch Loss: 1.7794700397644192e-05\n",
      "Epoch 4122, Loss: 0.000529563840245828, Final Batch Loss: 0.00024758235667832196\n",
      "Epoch 4123, Loss: 0.0018448027258273214, Final Batch Loss: 0.00016712708747945726\n",
      "Epoch 4124, Loss: 0.0002461927433614619, Final Batch Loss: 4.2839681555051357e-05\n",
      "Epoch 4125, Loss: 0.0006355150580930058, Final Batch Loss: 0.0005836751079186797\n",
      "Epoch 4126, Loss: 0.0007880123012000695, Final Batch Loss: 9.600068733561784e-05\n",
      "Epoch 4127, Loss: 0.00032655097311362624, Final Batch Loss: 6.517997826449573e-05\n",
      "Epoch 4128, Loss: 0.00010083194501930848, Final Batch Loss: 6.310512981144711e-05\n",
      "Epoch 4129, Loss: 0.00044179837277624756, Final Batch Loss: 0.0002927184395957738\n",
      "Epoch 4130, Loss: 0.00027683330699801445, Final Batch Loss: 0.00021250812278594822\n",
      "Epoch 4131, Loss: 0.00026912320754490793, Final Batch Loss: 0.00010745346662588418\n",
      "Epoch 4132, Loss: 0.00031641398527426645, Final Batch Loss: 8.665156929055229e-05\n",
      "Epoch 4133, Loss: 0.0008285379299195483, Final Batch Loss: 0.000593797245528549\n",
      "Epoch 4134, Loss: 0.0003425984068599064, Final Batch Loss: 3.817562901531346e-05\n",
      "Epoch 4135, Loss: 0.0013032379793003201, Final Batch Loss: 0.000310985604301095\n",
      "Epoch 4136, Loss: 0.00013957844385004137, Final Batch Loss: 0.00011674960114760324\n",
      "Epoch 4137, Loss: 0.00041303526813862845, Final Batch Loss: 7.192935299826786e-05\n",
      "Epoch 4138, Loss: 0.0001468685586587526, Final Batch Loss: 3.0360934033524245e-05\n",
      "Epoch 4139, Loss: 0.00023019742366159335, Final Batch Loss: 5.8390833146404475e-05\n",
      "Epoch 4140, Loss: 0.00021077049314044416, Final Batch Loss: 6.70956214889884e-05\n",
      "Epoch 4141, Loss: 0.0003015695256181061, Final Batch Loss: 0.00019530492136254907\n",
      "Epoch 4142, Loss: 0.007436971878632903, Final Batch Loss: 8.993572555482388e-05\n",
      "Epoch 4143, Loss: 0.0003486925415927544, Final Batch Loss: 0.00022434178390540183\n",
      "Epoch 4144, Loss: 0.0014359987289935816, Final Batch Loss: 0.001393991056829691\n",
      "Epoch 4145, Loss: 0.000194871099665761, Final Batch Loss: 6.69608562020585e-05\n",
      "Epoch 4146, Loss: 0.0007812020776327699, Final Batch Loss: 0.0005136669497005641\n",
      "Epoch 4147, Loss: 0.00212639789970126, Final Batch Loss: 0.00015327903383877128\n",
      "Epoch 4148, Loss: 0.00018861353601096198, Final Batch Loss: 0.00010876572196139023\n",
      "Epoch 4149, Loss: 0.0006830724305473268, Final Batch Loss: 0.0005080780247226357\n",
      "Epoch 4150, Loss: 0.0006830199272371829, Final Batch Loss: 0.0005681162001565099\n",
      "Epoch 4151, Loss: 0.00014993327931733802, Final Batch Loss: 0.00012056515697622672\n",
      "Epoch 4152, Loss: 0.0006012576559442095, Final Batch Loss: 7.100041693774983e-05\n",
      "Epoch 4153, Loss: 0.0015945770574035123, Final Batch Loss: 0.0014211437664926052\n",
      "Epoch 4154, Loss: 9.256941120838746e-05, Final Batch Loss: 6.316192593658343e-05\n",
      "Epoch 4155, Loss: 0.0019169120641890913, Final Batch Loss: 0.001663861097767949\n",
      "Epoch 4156, Loss: 0.0007931619184091687, Final Batch Loss: 0.0003672795428428799\n",
      "Epoch 4157, Loss: 0.0003224202919227537, Final Batch Loss: 3.3229236578335986e-05\n",
      "Epoch 4158, Loss: 0.005959294336207677, Final Batch Loss: 6.389531336026266e-05\n",
      "Epoch 4159, Loss: 0.0029338605236262083, Final Batch Loss: 0.00041335891000926495\n",
      "Epoch 4160, Loss: 0.0003395074963918887, Final Batch Loss: 6.658981874352321e-05\n",
      "Epoch 4161, Loss: 0.0007546445995103568, Final Batch Loss: 7.997019565664232e-05\n",
      "Epoch 4162, Loss: 0.0002935094053100329, Final Batch Loss: 3.0363949917955324e-05\n",
      "Epoch 4163, Loss: 0.00046613001177320257, Final Batch Loss: 0.00011530373740242794\n",
      "Epoch 4164, Loss: 0.0011468162992969155, Final Batch Loss: 0.0008584090392105281\n",
      "Epoch 4165, Loss: 0.0007215578807517886, Final Batch Loss: 0.00039368364377878606\n",
      "Epoch 4166, Loss: 0.0008452146139461547, Final Batch Loss: 0.00024423320428468287\n",
      "Epoch 4167, Loss: 0.00016740311548346654, Final Batch Loss: 2.5083143555093557e-05\n",
      "Epoch 4168, Loss: 0.0009183820802718401, Final Batch Loss: 0.0005622115568257868\n",
      "Epoch 4169, Loss: 0.0005695949039363768, Final Batch Loss: 0.0005211277748458087\n",
      "Epoch 4170, Loss: 0.03888418291171547, Final Batch Loss: 0.00022757564147468656\n",
      "Epoch 4171, Loss: 0.0005442164983833209, Final Batch Loss: 0.00038856419268995523\n",
      "Epoch 4172, Loss: 0.00014073219426791184, Final Batch Loss: 0.00010911442223004997\n",
      "Epoch 4173, Loss: 0.0002628989313961938, Final Batch Loss: 0.00015889122732914984\n",
      "Epoch 4174, Loss: 0.0002876148500945419, Final Batch Loss: 0.00014648944488726556\n",
      "Epoch 4175, Loss: 0.00011616181654972024, Final Batch Loss: 8.0366269685328e-05\n",
      "Epoch 4176, Loss: 0.0001566882165207062, Final Batch Loss: 9.88510437309742e-05\n",
      "Epoch 4177, Loss: 0.00011322570571792312, Final Batch Loss: 5.8759018429555e-05\n",
      "Epoch 4178, Loss: 0.00011068798994529061, Final Batch Loss: 7.497870683437213e-05\n",
      "Epoch 4179, Loss: 0.00041169737960444763, Final Batch Loss: 7.75643638917245e-05\n",
      "Epoch 4180, Loss: 0.00015056371194077656, Final Batch Loss: 3.360531263751909e-05\n",
      "Epoch 4181, Loss: 0.00029902546521043405, Final Batch Loss: 0.00010109089635079727\n",
      "Epoch 4182, Loss: 0.0002932927200163249, Final Batch Loss: 4.498946145758964e-05\n",
      "Epoch 4183, Loss: 8.185438491636887e-05, Final Batch Loss: 2.2933585569262505e-05\n",
      "Epoch 4184, Loss: 0.0007259630838234443, Final Batch Loss: 5.249421883490868e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4185, Loss: 0.0006315343052847311, Final Batch Loss: 0.0004346306959632784\n",
      "Epoch 4186, Loss: 0.000232061451242771, Final Batch Loss: 0.00010536245099501684\n",
      "Epoch 4187, Loss: 0.012696000976575306, Final Batch Loss: 0.012664715759456158\n",
      "Epoch 4188, Loss: 0.00045787500857841223, Final Batch Loss: 0.00014950755576137453\n",
      "Epoch 4189, Loss: 0.0001333806230832124, Final Batch Loss: 2.3498769223806448e-05\n",
      "Epoch 4190, Loss: 0.0016321332368534058, Final Batch Loss: 0.0003969107929151505\n",
      "Epoch 4191, Loss: 0.00022547848129761405, Final Batch Loss: 0.00017702620243653655\n",
      "Epoch 4192, Loss: 0.0003902695461874828, Final Batch Loss: 0.00032917287899181247\n",
      "Epoch 4193, Loss: 0.00025369669310748577, Final Batch Loss: 0.00014601599832531065\n",
      "Epoch 4194, Loss: 0.00021977112191962078, Final Batch Loss: 0.00010433029819978401\n",
      "Epoch 4195, Loss: 0.00016969630814855918, Final Batch Loss: 4.2537190893199295e-05\n",
      "Epoch 4196, Loss: 0.0002917365563916974, Final Batch Loss: 8.420873928116634e-05\n",
      "Epoch 4197, Loss: 0.00013449931793729775, Final Batch Loss: 8.806448022369295e-05\n",
      "Epoch 4198, Loss: 0.0007814888667780906, Final Batch Loss: 0.0005826868582516909\n",
      "Epoch 4199, Loss: 0.0013386920109041966, Final Batch Loss: 8.318675827467814e-05\n",
      "Epoch 4200, Loss: 0.0005455704958876595, Final Batch Loss: 0.00035335254506208\n",
      "Epoch 4201, Loss: 0.00019243472706875764, Final Batch Loss: 4.8454265197506174e-05\n",
      "Epoch 4202, Loss: 0.0005102653085486963, Final Batch Loss: 0.00018282495148014277\n",
      "Epoch 4203, Loss: 0.00028603871032828465, Final Batch Loss: 0.00019054545555263758\n",
      "Epoch 4204, Loss: 7.21818687452469e-05, Final Batch Loss: 2.4830813345033675e-05\n",
      "Epoch 4205, Loss: 0.00033681878994684666, Final Batch Loss: 6.462879537139088e-05\n",
      "Epoch 4206, Loss: 0.002001900898903841, Final Batch Loss: 3.2037703931564465e-05\n",
      "Epoch 4207, Loss: 0.0004600625252351165, Final Batch Loss: 0.00015962502220645547\n",
      "Epoch 4208, Loss: 0.001268448046175763, Final Batch Loss: 0.0009282334358431399\n",
      "Epoch 4209, Loss: 0.0006761533659300767, Final Batch Loss: 8.81692030816339e-05\n",
      "Epoch 4210, Loss: 0.0007054558955132961, Final Batch Loss: 0.0005506799789145589\n",
      "Epoch 4211, Loss: 0.00020241315723978914, Final Batch Loss: 3.8159287214512005e-05\n",
      "Epoch 4212, Loss: 0.0002591255670267856, Final Batch Loss: 2.8672488042502664e-05\n",
      "Epoch 4213, Loss: 0.00025972600269597024, Final Batch Loss: 0.00016258624964393675\n",
      "Epoch 4214, Loss: 0.004981615093129221, Final Batch Loss: 6.67539206915535e-05\n",
      "Epoch 4215, Loss: 0.0017419927899027243, Final Batch Loss: 0.0001902822550619021\n",
      "Epoch 4216, Loss: 0.00015926920605124906, Final Batch Loss: 3.179779014317319e-05\n",
      "Epoch 4217, Loss: 0.0008698903147887904, Final Batch Loss: 3.0140963644953445e-05\n",
      "Epoch 4218, Loss: 0.00012686224727076478, Final Batch Loss: 5.851494279340841e-05\n",
      "Epoch 4219, Loss: 0.00026857340708374977, Final Batch Loss: 0.0001328433572780341\n",
      "Epoch 4220, Loss: 0.0006079813174437732, Final Batch Loss: 0.00016461362247355282\n",
      "Epoch 4221, Loss: 0.000549243253772147, Final Batch Loss: 0.00015775735664647073\n",
      "Epoch 4222, Loss: 5.947157842456363e-05, Final Batch Loss: 1.951321610249579e-05\n",
      "Epoch 4223, Loss: 0.01403191639110446, Final Batch Loss: 0.013890758156776428\n",
      "Epoch 4224, Loss: 0.0014113337674643844, Final Batch Loss: 8.922300185076892e-05\n",
      "Epoch 4225, Loss: 0.0001445793895982206, Final Batch Loss: 8.098020771285519e-05\n",
      "Epoch 4226, Loss: 0.00013126103658578359, Final Batch Loss: 7.269426714628935e-05\n",
      "Epoch 4227, Loss: 0.0002991650180774741, Final Batch Loss: 8.606617484474555e-05\n",
      "Epoch 4228, Loss: 0.00033616489963606, Final Batch Loss: 0.0002214409178122878\n",
      "Epoch 4229, Loss: 9.148817116511054e-05, Final Batch Loss: 4.417910167830996e-05\n",
      "Epoch 4230, Loss: 0.13098281592101557, Final Batch Loss: 0.13089041411876678\n",
      "Epoch 4231, Loss: 0.0006740559329045936, Final Batch Loss: 0.00014132492651697248\n",
      "Epoch 4232, Loss: 0.0011107855243608356, Final Batch Loss: 0.0006054151454009116\n",
      "Epoch 4233, Loss: 0.00033405013527953997, Final Batch Loss: 5.783097731182352e-05\n",
      "Epoch 4234, Loss: 0.0003654515166999772, Final Batch Loss: 0.00018028214981313795\n",
      "Epoch 4235, Loss: 0.00016462824714835733, Final Batch Loss: 0.00011574650125112385\n",
      "Epoch 4236, Loss: 0.0004488229278649669, Final Batch Loss: 0.0004144713457208127\n",
      "Epoch 4237, Loss: 0.0011749835102818906, Final Batch Loss: 0.0008320161141455173\n",
      "Epoch 4238, Loss: 0.0006529166712425649, Final Batch Loss: 0.00043614147580228746\n",
      "Epoch 4239, Loss: 0.0002528004552004859, Final Batch Loss: 0.0001359259767923504\n",
      "Epoch 4240, Loss: 0.0007436985615640879, Final Batch Loss: 0.00034502954804338515\n",
      "Epoch 4241, Loss: 0.00012375195728964172, Final Batch Loss: 3.90598397643771e-05\n",
      "Epoch 4242, Loss: 0.00024239821505034342, Final Batch Loss: 5.876537034055218e-05\n",
      "Epoch 4243, Loss: 0.00031703280546935275, Final Batch Loss: 0.00025628338335081935\n",
      "Epoch 4244, Loss: 0.0004325516347307712, Final Batch Loss: 0.00013831479009240866\n",
      "Epoch 4245, Loss: 0.0003120042019872926, Final Batch Loss: 7.611061300849542e-05\n",
      "Epoch 4246, Loss: 0.00042049409239552915, Final Batch Loss: 0.00016282172873616219\n",
      "Epoch 4247, Loss: 0.0005072657950222492, Final Batch Loss: 0.00024822543491609395\n",
      "Epoch 4248, Loss: 0.0003654049141914584, Final Batch Loss: 8.248797530541196e-05\n",
      "Epoch 4249, Loss: 0.00036818705848418176, Final Batch Loss: 0.00022086793615017086\n",
      "Epoch 4250, Loss: 0.00032156241650227457, Final Batch Loss: 0.00017687388753984123\n",
      "Epoch 4251, Loss: 0.00019238529057474807, Final Batch Loss: 9.702544775791466e-05\n",
      "Epoch 4252, Loss: 0.00023854617757024243, Final Batch Loss: 0.0001229577319463715\n",
      "Epoch 4253, Loss: 0.0003966743825003505, Final Batch Loss: 0.00023277883883565664\n",
      "Epoch 4254, Loss: 0.0008472024346701801, Final Batch Loss: 0.00034480029717087746\n",
      "Epoch 4255, Loss: 0.0013994561159051955, Final Batch Loss: 0.0012016951804980636\n",
      "Epoch 4256, Loss: 0.0018546120263636112, Final Batch Loss: 0.0006875082617625594\n",
      "Epoch 4257, Loss: 0.0002843833790393546, Final Batch Loss: 0.00020061770919710398\n",
      "Epoch 4258, Loss: 0.0005934014916419983, Final Batch Loss: 0.00015801249537616968\n",
      "Epoch 4259, Loss: 0.004155852482654154, Final Batch Loss: 0.0032113883644342422\n",
      "Epoch 4260, Loss: 0.007038821582682431, Final Batch Loss: 0.0015417678514495492\n",
      "Epoch 4261, Loss: 0.0010274144151480868, Final Batch Loss: 0.0008366969996131957\n",
      "Epoch 4262, Loss: 0.000301832624245435, Final Batch Loss: 0.00016264284204225987\n",
      "Epoch 4263, Loss: 0.00038929017318878323, Final Batch Loss: 0.0001526410924270749\n",
      "Epoch 4264, Loss: 0.0008255481880041771, Final Batch Loss: 0.000707274884916842\n",
      "Epoch 4265, Loss: 0.006583400863746647, Final Batch Loss: 0.006464920938014984\n",
      "Epoch 4266, Loss: 0.0011375416070222855, Final Batch Loss: 0.0005531100905500352\n",
      "Epoch 4267, Loss: 0.002495586610166356, Final Batch Loss: 7.202589767985046e-05\n",
      "Epoch 4268, Loss: 0.0006816172535764053, Final Batch Loss: 0.00043942034244537354\n",
      "Epoch 4269, Loss: 0.0005866643332410604, Final Batch Loss: 0.00030217933817766607\n",
      "Epoch 4270, Loss: 0.00018742867541732267, Final Batch Loss: 0.00010386466601630673\n",
      "Epoch 4271, Loss: 0.00020183748711133376, Final Batch Loss: 6.626228423556313e-05\n",
      "Epoch 4272, Loss: 0.0002583914392744191, Final Batch Loss: 0.00010050027776742354\n",
      "Epoch 4273, Loss: 0.00019685225197463296, Final Batch Loss: 5.345299359760247e-05\n",
      "Epoch 4274, Loss: 0.0008379757855436765, Final Batch Loss: 0.0007330313674174249\n",
      "Epoch 4275, Loss: 0.0004294031241443008, Final Batch Loss: 0.00015374296344816685\n",
      "Epoch 4276, Loss: 0.00011554433149285614, Final Batch Loss: 8.105173037620261e-05\n",
      "Epoch 4277, Loss: 0.00040730895125307143, Final Batch Loss: 0.00018583783821668476\n",
      "Epoch 4278, Loss: 0.0005276815354591236, Final Batch Loss: 0.00021522953466046602\n",
      "Epoch 4279, Loss: 0.0003720780623552855, Final Batch Loss: 0.00031692616175860167\n",
      "Epoch 4280, Loss: 0.00018046055629383773, Final Batch Loss: 0.00010808135994011536\n",
      "Epoch 4281, Loss: 0.0010044574228231795, Final Batch Loss: 0.0009613973670639098\n",
      "Epoch 4282, Loss: 0.00028487169765867293, Final Batch Loss: 0.00017872815078590065\n",
      "Epoch 4283, Loss: 0.00018850600463338196, Final Batch Loss: 0.00011886697757290676\n",
      "Epoch 4284, Loss: 0.0006505415658466518, Final Batch Loss: 0.00037820381112396717\n",
      "Epoch 4285, Loss: 0.0001553779984533321, Final Batch Loss: 0.00011527007882250473\n",
      "Epoch 4286, Loss: 0.0004335142148192972, Final Batch Loss: 0.0002687066444195807\n",
      "Epoch 4287, Loss: 0.036153199209365994, Final Batch Loss: 0.0006145183579064906\n",
      "Epoch 4288, Loss: 0.001053691448760219, Final Batch Loss: 0.000122753917821683\n",
      "Epoch 4289, Loss: 0.00022220320533961058, Final Batch Loss: 0.00011339676711941138\n",
      "Epoch 4290, Loss: 0.0009920140291796997, Final Batch Loss: 0.00015995187277439982\n",
      "Epoch 4291, Loss: 0.00010149719128094148, Final Batch Loss: 8.083055581664667e-05\n",
      "Epoch 4292, Loss: 0.0005134370003361255, Final Batch Loss: 0.0002520731068216264\n",
      "Epoch 4293, Loss: 0.00036502538569038734, Final Batch Loss: 7.009196997387335e-05\n",
      "Epoch 4294, Loss: 0.0005026974249631166, Final Batch Loss: 0.00042905614827759564\n",
      "Epoch 4295, Loss: 0.00027786794817075133, Final Batch Loss: 0.00014206123887561262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4296, Loss: 0.0004080000362591818, Final Batch Loss: 0.00030604025232605636\n",
      "Epoch 4297, Loss: 0.0005236632277956232, Final Batch Loss: 0.00012109721137676388\n",
      "Epoch 4298, Loss: 0.0005042347183916718, Final Batch Loss: 0.00021245499374344945\n",
      "Epoch 4299, Loss: 0.0014915455249138176, Final Batch Loss: 0.00018496514530852437\n",
      "Epoch 4300, Loss: 0.00014594672757084481, Final Batch Loss: 8.591840014560148e-05\n",
      "Epoch 4301, Loss: 0.0003014125977642834, Final Batch Loss: 0.00020161678548902273\n",
      "Epoch 4302, Loss: 0.00043188734707655385, Final Batch Loss: 7.478707266272977e-05\n",
      "Epoch 4303, Loss: 0.00016114443496917374, Final Batch Loss: 5.183769462746568e-05\n",
      "Epoch 4304, Loss: 0.0005059695977251977, Final Batch Loss: 0.0002584235626272857\n",
      "Epoch 4305, Loss: 0.0008943730208557099, Final Batch Loss: 0.00029558237292803824\n",
      "Epoch 4306, Loss: 0.0006648523412877694, Final Batch Loss: 0.00014836493937764317\n",
      "Epoch 4307, Loss: 0.00034736262750811875, Final Batch Loss: 0.00022314967645797879\n",
      "Epoch 4308, Loss: 0.007952939471579157, Final Batch Loss: 4.74115222459659e-05\n",
      "Epoch 4309, Loss: 0.00020474612392717972, Final Batch Loss: 0.00012359788524918258\n",
      "Epoch 4310, Loss: 0.0002385566185694188, Final Batch Loss: 9.664046228863299e-05\n",
      "Epoch 4311, Loss: 0.00017007913993438706, Final Batch Loss: 0.00011933534551644698\n",
      "Epoch 4312, Loss: 0.00018324438133277, Final Batch Loss: 8.317323954543099e-05\n",
      "Epoch 4313, Loss: 0.00024338218099728692, Final Batch Loss: 1.7560685591888614e-05\n",
      "Epoch 4314, Loss: 0.0015007479232735932, Final Batch Loss: 7.010990520939231e-05\n",
      "Epoch 4315, Loss: 0.0003504419146338478, Final Batch Loss: 0.00016858213348314166\n",
      "Epoch 4316, Loss: 0.004973687668098137, Final Batch Loss: 0.0002982644073199481\n",
      "Epoch 4317, Loss: 0.00032183289295062423, Final Batch Loss: 1.6245001461356878e-05\n",
      "Epoch 4318, Loss: 0.00015832885219424497, Final Batch Loss: 2.8911685149068944e-05\n",
      "Epoch 4319, Loss: 0.0003019612195203081, Final Batch Loss: 0.0001203909341711551\n",
      "Epoch 4320, Loss: 0.005644897079037037, Final Batch Loss: 0.005611751228570938\n",
      "Epoch 4321, Loss: 0.00019950226305809338, Final Batch Loss: 1.7928077795659192e-05\n",
      "Epoch 4322, Loss: 0.00020824861348955892, Final Batch Loss: 0.00017177307745441794\n",
      "Epoch 4323, Loss: 0.00030122122552711517, Final Batch Loss: 7.406149234157056e-05\n",
      "Epoch 4324, Loss: 0.0005076593806734309, Final Batch Loss: 0.00027592972037382424\n",
      "Epoch 4325, Loss: 0.0004522787712630816, Final Batch Loss: 0.00038051261799409986\n",
      "Epoch 4326, Loss: 0.00020412628146004863, Final Batch Loss: 5.500176121131517e-05\n",
      "Epoch 4327, Loss: 0.0003069724261877127, Final Batch Loss: 0.00010494881280465052\n",
      "Epoch 4328, Loss: 0.0005409461555245798, Final Batch Loss: 0.0004891957505606115\n",
      "Epoch 4329, Loss: 0.0001805755600798875, Final Batch Loss: 9.82577694230713e-05\n",
      "Epoch 4330, Loss: 0.0004718951095128432, Final Batch Loss: 0.00029949963209219277\n",
      "Epoch 4331, Loss: 0.0002584042740636505, Final Batch Loss: 0.0001445588713977486\n",
      "Epoch 4332, Loss: 0.0004294234677217901, Final Batch Loss: 0.0002785324468277395\n",
      "Epoch 4333, Loss: 0.0011782602523453534, Final Batch Loss: 0.0005665818462148309\n",
      "Epoch 4334, Loss: 0.00011282740524620749, Final Batch Loss: 5.646339195664041e-05\n",
      "Epoch 4335, Loss: 0.000685147344483994, Final Batch Loss: 0.0005355268367566168\n",
      "Epoch 4336, Loss: 0.00015458980487892404, Final Batch Loss: 8.669630187796429e-05\n",
      "Epoch 4337, Loss: 0.0005493951175594702, Final Batch Loss: 0.00017966049199458212\n",
      "Epoch 4338, Loss: 0.0008166616462403908, Final Batch Loss: 0.0006540229078382254\n",
      "Epoch 4339, Loss: 0.00017721857511787675, Final Batch Loss: 3.803876097663306e-05\n",
      "Epoch 4340, Loss: 0.00022930234990781173, Final Batch Loss: 0.00016523041995242238\n",
      "Epoch 4341, Loss: 0.00021887743059778586, Final Batch Loss: 0.00014178433048073202\n",
      "Epoch 4342, Loss: 0.0002798409477691166, Final Batch Loss: 7.59811737225391e-05\n",
      "Epoch 4343, Loss: 0.0004513384628808126, Final Batch Loss: 0.00029783378704451025\n",
      "Epoch 4344, Loss: 0.00023915460769785568, Final Batch Loss: 7.187497249105945e-05\n",
      "Epoch 4345, Loss: 0.00012608029283001088, Final Batch Loss: 3.721897883224301e-05\n",
      "Epoch 4346, Loss: 0.0001847195380833, Final Batch Loss: 9.676024637883529e-05\n",
      "Epoch 4347, Loss: 0.0006442118319682777, Final Batch Loss: 0.00041393074207007885\n",
      "Epoch 4348, Loss: 7.835465657990426e-05, Final Batch Loss: 4.3075378926005214e-05\n",
      "Epoch 4349, Loss: 9.322127152699977e-05, Final Batch Loss: 7.04902340658009e-05\n",
      "Epoch 4350, Loss: 0.0002644201958901249, Final Batch Loss: 0.00011035877832910046\n",
      "Epoch 4351, Loss: 0.00021144984202692285, Final Batch Loss: 0.0001046946199494414\n",
      "Epoch 4352, Loss: 9.099227827391587e-05, Final Batch Loss: 5.4633026593364775e-05\n",
      "Epoch 4353, Loss: 0.00024939182185335085, Final Batch Loss: 0.00016739075363148004\n",
      "Epoch 4354, Loss: 0.000639732024865225, Final Batch Loss: 0.0005134849925525486\n",
      "Epoch 4355, Loss: 0.0002781455696094781, Final Batch Loss: 0.00021507461497094482\n",
      "Epoch 4356, Loss: 0.0004256272950442508, Final Batch Loss: 0.00022279426048044115\n",
      "Epoch 4357, Loss: 0.00038868753472343087, Final Batch Loss: 6.35197211522609e-05\n",
      "Epoch 4358, Loss: 0.004063112544827163, Final Batch Loss: 0.00010779767762869596\n",
      "Epoch 4359, Loss: 0.0005821054801344872, Final Batch Loss: 0.0002507155295461416\n",
      "Epoch 4360, Loss: 0.0002012363402172923, Final Batch Loss: 7.321209704969078e-05\n",
      "Epoch 4361, Loss: 0.00011011116293957457, Final Batch Loss: 7.920528878457844e-05\n",
      "Epoch 4362, Loss: 0.00022567030100617558, Final Batch Loss: 0.0001499401405453682\n",
      "Epoch 4363, Loss: 0.0013300164137035608, Final Batch Loss: 0.0008209476945921779\n",
      "Epoch 4364, Loss: 0.0006052935423213057, Final Batch Loss: 0.0005716486484743655\n",
      "Epoch 4365, Loss: 0.0002833475882653147, Final Batch Loss: 0.00017993649817071855\n",
      "Epoch 4366, Loss: 0.00012935741324326955, Final Batch Loss: 6.887273775646463e-05\n",
      "Epoch 4367, Loss: 0.00022016221919329837, Final Batch Loss: 0.00010003243369283155\n",
      "Epoch 4368, Loss: 0.00044708579662255943, Final Batch Loss: 0.0001983636466320604\n",
      "Epoch 4369, Loss: 0.00046873952669557184, Final Batch Loss: 0.00022839134908281267\n",
      "Epoch 4370, Loss: 0.00026325194630771875, Final Batch Loss: 0.0001445723173674196\n",
      "Epoch 4371, Loss: 0.02989615043043159, Final Batch Loss: 0.029755692929029465\n",
      "Epoch 4372, Loss: 0.0001936849657795392, Final Batch Loss: 6.455835682572797e-05\n",
      "Epoch 4373, Loss: 0.028740645986545132, Final Batch Loss: 0.028702566400170326\n",
      "Epoch 4374, Loss: 0.0028849650407209992, Final Batch Loss: 0.0009249685099348426\n",
      "Epoch 4375, Loss: 0.0033452185889473185, Final Batch Loss: 0.003157910192385316\n",
      "Epoch 4376, Loss: 0.000265560724074021, Final Batch Loss: 0.00015912474191281945\n",
      "Epoch 4377, Loss: 0.00038343814958352596, Final Batch Loss: 0.0003165536327287555\n",
      "Epoch 4378, Loss: 0.00015469574645976536, Final Batch Loss: 4.817865919903852e-05\n",
      "Epoch 4379, Loss: 0.000642483624687884, Final Batch Loss: 0.0005979413981549442\n",
      "Epoch 4380, Loss: 0.001474313496146351, Final Batch Loss: 0.0008817556081339717\n",
      "Epoch 4381, Loss: 0.00141982440254651, Final Batch Loss: 0.00013693349319510162\n",
      "Epoch 4382, Loss: 0.008831838349578902, Final Batch Loss: 0.008467471227049828\n",
      "Epoch 4383, Loss: 0.00037291333865141496, Final Batch Loss: 0.00026245231856592\n",
      "Epoch 4384, Loss: 0.028576740878634155, Final Batch Loss: 0.027711806818842888\n",
      "Epoch 4385, Loss: 0.00041664656600914896, Final Batch Loss: 0.00021519915026146919\n",
      "Epoch 4386, Loss: 0.06500856633647345, Final Batch Loss: 0.00013714339002035558\n",
      "Epoch 4387, Loss: 0.0003159670432069106, Final Batch Loss: 0.0002910273615270853\n",
      "Epoch 4388, Loss: 0.002241802438220475, Final Batch Loss: 8.117667312035337e-05\n",
      "Epoch 4389, Loss: 0.030164642274030484, Final Batch Loss: 0.00014175289834383875\n",
      "Epoch 4390, Loss: 0.0457774018868804, Final Batch Loss: 0.03927164897322655\n",
      "Epoch 4391, Loss: 0.02175534908019472, Final Batch Loss: 0.00016071107529569417\n",
      "Epoch 4392, Loss: 0.059494671018910594, Final Batch Loss: 0.05939868837594986\n",
      "Epoch 4393, Loss: 0.00047049457498360425, Final Batch Loss: 0.00012665415124502033\n",
      "Epoch 4394, Loss: 0.030426537559833378, Final Batch Loss: 0.0006608459516428411\n",
      "Epoch 4395, Loss: 0.00040091208938974887, Final Batch Loss: 0.00010735228715930134\n",
      "Epoch 4396, Loss: 0.005338939874491189, Final Batch Loss: 8.63136156112887e-05\n",
      "Epoch 4397, Loss: 0.002452971270031412, Final Batch Loss: 3.047529207833577e-05\n",
      "Epoch 4398, Loss: 0.026530506504059304, Final Batch Loss: 9.833131480263546e-05\n",
      "Epoch 4399, Loss: 0.003481035389995668, Final Batch Loss: 0.0033726824913173914\n",
      "Epoch 4400, Loss: 0.0008455885981675237, Final Batch Loss: 0.0006978875026106834\n",
      "Epoch 4401, Loss: 0.0011654089903458953, Final Batch Loss: 0.0004188366001471877\n",
      "Epoch 4402, Loss: 0.00471301436482463, Final Batch Loss: 0.00022969501151237637\n",
      "Epoch 4403, Loss: 0.003052633721381426, Final Batch Loss: 0.0011477636871859431\n",
      "Epoch 4404, Loss: 0.002015352714806795, Final Batch Loss: 0.00047970388550311327\n",
      "Epoch 4405, Loss: 0.0007911455759312958, Final Batch Loss: 0.00048065470764413476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4406, Loss: 0.0011655995331238955, Final Batch Loss: 0.000972234585788101\n",
      "Epoch 4407, Loss: 0.0015337438089773059, Final Batch Loss: 0.000643666775431484\n",
      "Epoch 4408, Loss: 0.0010966492409352213, Final Batch Loss: 0.0006745180580765009\n",
      "Epoch 4409, Loss: 0.001997127146751154, Final Batch Loss: 9.918917930917814e-05\n",
      "Epoch 4410, Loss: 0.001110677549149841, Final Batch Loss: 0.0006230711005628109\n",
      "Epoch 4411, Loss: 0.0019038363243453205, Final Batch Loss: 0.0007252180366776884\n",
      "Epoch 4412, Loss: 0.0006695822667097673, Final Batch Loss: 0.00019344479369465262\n",
      "Epoch 4413, Loss: 0.0005272252310533077, Final Batch Loss: 0.00014024964184500277\n",
      "Epoch 4414, Loss: 0.0048066860472317785, Final Batch Loss: 0.00016481414786539972\n",
      "Epoch 4415, Loss: 0.0021264414535835385, Final Batch Loss: 0.0011334612499922514\n",
      "Epoch 4416, Loss: 0.00044426026579458266, Final Batch Loss: 0.00031501430203206837\n",
      "Epoch 4417, Loss: 0.0022963242809055373, Final Batch Loss: 7.712600927334279e-05\n",
      "Epoch 4418, Loss: 0.0005855393828824162, Final Batch Loss: 0.00033815676579251885\n",
      "Epoch 4419, Loss: 0.000333431686158292, Final Batch Loss: 7.824595377314836e-05\n",
      "Epoch 4420, Loss: 0.0006852186197647825, Final Batch Loss: 0.00017611532530281693\n",
      "Epoch 4421, Loss: 0.00022671229089610279, Final Batch Loss: 6.950451643206179e-05\n",
      "Epoch 4422, Loss: 0.00015152321429923177, Final Batch Loss: 3.87294712709263e-05\n",
      "Epoch 4423, Loss: 0.0011655184061964974, Final Batch Loss: 0.00012807139137294143\n",
      "Epoch 4424, Loss: 0.0010952610900858417, Final Batch Loss: 0.00012531016545835882\n",
      "Epoch 4425, Loss: 0.0011733864666894078, Final Batch Loss: 0.0010278300615027547\n",
      "Epoch 4426, Loss: 0.001294375178986229, Final Batch Loss: 8.079457620624453e-05\n",
      "Epoch 4427, Loss: 0.00030412300111493096, Final Batch Loss: 0.00018915791588369757\n",
      "Epoch 4428, Loss: 0.00038635644887108356, Final Batch Loss: 0.00027536790003068745\n",
      "Epoch 4429, Loss: 0.0002862772817024961, Final Batch Loss: 0.00024509141803719103\n",
      "Epoch 4430, Loss: 0.0003173320001224056, Final Batch Loss: 9.413326915819198e-05\n",
      "Epoch 4431, Loss: 0.0011034093040507287, Final Batch Loss: 0.0009287370485253632\n",
      "Epoch 4432, Loss: 0.0003057618159800768, Final Batch Loss: 0.00023611709184478968\n",
      "Epoch 4433, Loss: 0.0002464714416419156, Final Batch Loss: 0.00012931448873132467\n",
      "Epoch 4434, Loss: 0.00044779470772482455, Final Batch Loss: 6.560125621035695e-05\n",
      "Epoch 4435, Loss: 0.0003031428568647243, Final Batch Loss: 0.00020964666327927262\n",
      "Epoch 4436, Loss: 0.0019671353220473975, Final Batch Loss: 0.00020689875236712396\n",
      "Epoch 4437, Loss: 0.00016893065185286105, Final Batch Loss: 6.315820064628497e-05\n",
      "Epoch 4438, Loss: 0.0007553824107162654, Final Batch Loss: 0.0005815969780087471\n",
      "Epoch 4439, Loss: 0.00017617786579648964, Final Batch Loss: 3.6553592508425936e-05\n",
      "Epoch 4440, Loss: 0.0013105229882057756, Final Batch Loss: 0.0009777621598914266\n",
      "Epoch 4441, Loss: 0.017347431457892526, Final Batch Loss: 0.00010393997217761353\n",
      "Epoch 4442, Loss: 0.00054299123439705, Final Batch Loss: 0.0004580662935040891\n",
      "Epoch 4443, Loss: 0.002086186137603363, Final Batch Loss: 5.7930414186557755e-05\n",
      "Epoch 4444, Loss: 0.00010932789882645011, Final Batch Loss: 2.0819490600842983e-05\n",
      "Epoch 4445, Loss: 0.0006977937373449095, Final Batch Loss: 7.667300087632611e-05\n",
      "Epoch 4446, Loss: 0.00022069884107622784, Final Batch Loss: 0.00019263906870037317\n",
      "Epoch 4447, Loss: 0.00011548570546437986, Final Batch Loss: 5.324196899891831e-05\n",
      "Epoch 4448, Loss: 0.009488251394941472, Final Batch Loss: 0.009358365088701248\n",
      "Epoch 4449, Loss: 0.00020797719480469823, Final Batch Loss: 0.0001693588274065405\n",
      "Epoch 4450, Loss: 0.001026277372147888, Final Batch Loss: 0.0006199127528816462\n",
      "Epoch 4451, Loss: 0.00018203158833784983, Final Batch Loss: 0.00011724229261744767\n",
      "Epoch 4452, Loss: 0.0012459353310987353, Final Batch Loss: 0.0011306711239740252\n",
      "Epoch 4453, Loss: 0.0002834669539879542, Final Batch Loss: 5.076174784335308e-05\n",
      "Epoch 4454, Loss: 0.0017429400468245149, Final Batch Loss: 0.0004863649373874068\n",
      "Epoch 4455, Loss: 0.017303186585195363, Final Batch Loss: 0.0014755382435396314\n",
      "Epoch 4456, Loss: 0.0038823921931907535, Final Batch Loss: 0.0014188484055921435\n",
      "Epoch 4457, Loss: 0.00023341408086707816, Final Batch Loss: 9.412607323611155e-05\n",
      "Epoch 4458, Loss: 0.015812672238098457, Final Batch Loss: 0.0002546920732129365\n",
      "Epoch 4459, Loss: 0.000355633907020092, Final Batch Loss: 0.00010110661969520152\n",
      "Epoch 4460, Loss: 0.0015539007144980133, Final Batch Loss: 0.00018947204807773232\n",
      "Epoch 4461, Loss: 0.0002680612087715417, Final Batch Loss: 0.00011408489081077278\n",
      "Epoch 4462, Loss: 0.001420041371602565, Final Batch Loss: 0.0007348734652623534\n",
      "Epoch 4463, Loss: 0.0032776502484921366, Final Batch Loss: 0.0002795852778945118\n",
      "Epoch 4464, Loss: 0.0009628419065847993, Final Batch Loss: 0.00025470933178439736\n",
      "Epoch 4465, Loss: 0.00031540919007966295, Final Batch Loss: 0.00012105452333344147\n",
      "Epoch 4466, Loss: 0.00034731414052657783, Final Batch Loss: 0.00023286436044145375\n",
      "Epoch 4467, Loss: 0.00026535131109994836, Final Batch Loss: 4.989318040315993e-05\n",
      "Epoch 4468, Loss: 0.002078403347695712, Final Batch Loss: 8.919658284867182e-05\n",
      "Epoch 4469, Loss: 0.0014780214405618608, Final Batch Loss: 0.0002811655285768211\n",
      "Epoch 4470, Loss: 0.00033777914359234273, Final Batch Loss: 0.00014595570974051952\n",
      "Epoch 4471, Loss: 0.010924578840786126, Final Batch Loss: 4.239679401507601e-05\n",
      "Epoch 4472, Loss: 0.0005140254070283845, Final Batch Loss: 0.00010661179840099066\n",
      "Epoch 4473, Loss: 0.0005126920150360093, Final Batch Loss: 8.536518726032227e-05\n",
      "Epoch 4474, Loss: 0.007788821196299978, Final Batch Loss: 0.00765530439093709\n",
      "Epoch 4475, Loss: 0.0005790001450804994, Final Batch Loss: 0.0004289841454010457\n",
      "Epoch 4476, Loss: 0.001272483030334115, Final Batch Loss: 0.0009269593865610659\n",
      "Epoch 4477, Loss: 0.003800189937464893, Final Batch Loss: 0.002303416607901454\n",
      "Epoch 4478, Loss: 0.0006676563061773777, Final Batch Loss: 0.00017961100093089044\n",
      "Epoch 4479, Loss: 0.0009298255390604027, Final Batch Loss: 0.0008576308027841151\n",
      "Epoch 4480, Loss: 0.0004455002708709799, Final Batch Loss: 0.0003294018388260156\n",
      "Epoch 4481, Loss: 0.00017480465612607077, Final Batch Loss: 0.000126351005746983\n",
      "Epoch 4482, Loss: 0.0004494032036745921, Final Batch Loss: 0.0003356695524416864\n",
      "Epoch 4483, Loss: 0.0005009000888094306, Final Batch Loss: 0.00012561032781377435\n",
      "Epoch 4484, Loss: 0.0015027662593638524, Final Batch Loss: 0.001330906874500215\n",
      "Epoch 4485, Loss: 0.000282563574728556, Final Batch Loss: 8.202131721191108e-05\n",
      "Epoch 4486, Loss: 0.0001738228093017824, Final Batch Loss: 7.189212192315608e-05\n",
      "Epoch 4487, Loss: 0.00037184661050559953, Final Batch Loss: 0.0002771279541775584\n",
      "Epoch 4488, Loss: 0.00017511106852907687, Final Batch Loss: 6.48033237666823e-05\n",
      "Epoch 4489, Loss: 0.001607513113413006, Final Batch Loss: 0.00032789952820166945\n",
      "Epoch 4490, Loss: 0.0027941672306042165, Final Batch Loss: 0.00015639697085134685\n",
      "Epoch 4491, Loss: 0.000597347563598305, Final Batch Loss: 3.412360092625022e-05\n",
      "Epoch 4492, Loss: 0.0004717194096883759, Final Batch Loss: 0.0003446736081968993\n",
      "Epoch 4493, Loss: 0.00038169489562278613, Final Batch Loss: 0.00010084473615279421\n",
      "Epoch 4494, Loss: 0.0013689651532331482, Final Batch Loss: 0.001307027880102396\n",
      "Epoch 4495, Loss: 0.00038032763768569566, Final Batch Loss: 3.420011853449978e-05\n",
      "Epoch 4496, Loss: 0.0003740920546988491, Final Batch Loss: 0.0003261634265072644\n",
      "Epoch 4497, Loss: 0.00026935098867397755, Final Batch Loss: 0.00016530985885765404\n",
      "Epoch 4498, Loss: 0.0014899320958647877, Final Batch Loss: 0.00011121566058136523\n",
      "Epoch 4499, Loss: 0.0006561551708728075, Final Batch Loss: 0.0002818252833094448\n",
      "Epoch 4500, Loss: 0.0027013286016881466, Final Batch Loss: 0.002449756022542715\n",
      "Epoch 4501, Loss: 0.0008991278664325364, Final Batch Loss: 8.023356349440292e-05\n",
      "Epoch 4502, Loss: 0.0003742988337762654, Final Batch Loss: 9.760170360095799e-05\n",
      "Epoch 4503, Loss: 0.0006316668004728854, Final Batch Loss: 0.00033750245347619057\n",
      "Epoch 4504, Loss: 0.0003658183559309691, Final Batch Loss: 0.00023850567231420428\n",
      "Epoch 4505, Loss: 0.0048455370124429464, Final Batch Loss: 0.0033376438077539206\n",
      "Epoch 4506, Loss: 0.0003964414354413748, Final Batch Loss: 0.00017351476708427072\n",
      "Epoch 4507, Loss: 0.0002666441178007517, Final Batch Loss: 0.0002084846782963723\n",
      "Epoch 4508, Loss: 0.0002539278139011003, Final Batch Loss: 3.8769991078879684e-05\n",
      "Epoch 4509, Loss: 0.0003704801492858678, Final Batch Loss: 0.0002990459615830332\n",
      "Epoch 4510, Loss: 0.061874416656792164, Final Batch Loss: 0.005395730026066303\n",
      "Epoch 4511, Loss: 0.000671631823934149, Final Batch Loss: 0.0006033484824001789\n",
      "Epoch 4512, Loss: 0.0007838396413717419, Final Batch Loss: 0.0002646674693096429\n",
      "Epoch 4513, Loss: 0.00039922552241478115, Final Batch Loss: 0.00016076515021268278\n",
      "Epoch 4514, Loss: 0.00024899342679418623, Final Batch Loss: 9.006969048641622e-05\n",
      "Epoch 4515, Loss: 0.0006720803212374449, Final Batch Loss: 0.000500186812132597\n",
      "Epoch 4516, Loss: 0.0003212408337276429, Final Batch Loss: 0.00015834649093449116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4517, Loss: 0.0006918332073837519, Final Batch Loss: 0.00040353817166760564\n",
      "Epoch 4518, Loss: 0.0023009973810985684, Final Batch Loss: 0.00030217424500733614\n",
      "Epoch 4519, Loss: 0.0005313106230460107, Final Batch Loss: 0.00026646751211956143\n",
      "Epoch 4520, Loss: 0.006210301537066698, Final Batch Loss: 0.002252767328172922\n",
      "Epoch 4521, Loss: 0.0011414880063966848, Final Batch Loss: 3.5088662116322666e-05\n",
      "Epoch 4522, Loss: 0.00020260588644305244, Final Batch Loss: 5.242611950961873e-05\n",
      "Epoch 4523, Loss: 0.00024027764447964728, Final Batch Loss: 9.047739149536937e-05\n",
      "Epoch 4524, Loss: 0.0003167655668221414, Final Batch Loss: 0.00013787197531200945\n",
      "Epoch 4525, Loss: 0.0006638873746851459, Final Batch Loss: 0.0004642044077627361\n",
      "Epoch 4526, Loss: 0.0005735558224841952, Final Batch Loss: 0.00037105672527104616\n",
      "Epoch 4527, Loss: 0.0008264422358479351, Final Batch Loss: 0.0006941678002476692\n",
      "Epoch 4528, Loss: 0.0006606185343116522, Final Batch Loss: 0.0004627001180779189\n",
      "Epoch 4529, Loss: 0.00014737249148311093, Final Batch Loss: 5.9223631978966296e-05\n",
      "Epoch 4530, Loss: 0.0012798176903743297, Final Batch Loss: 0.0010716536780819297\n",
      "Epoch 4531, Loss: 0.0005008908192394301, Final Batch Loss: 0.0001444325753254816\n",
      "Epoch 4532, Loss: 0.00040945234650280327, Final Batch Loss: 0.0002340760111110285\n",
      "Epoch 4533, Loss: 0.0004324288456700742, Final Batch Loss: 0.00027909790514968336\n",
      "Epoch 4534, Loss: 0.00019046029046876356, Final Batch Loss: 6.882586603751406e-05\n",
      "Epoch 4535, Loss: 0.0004070226423209533, Final Batch Loss: 0.00018418629770167172\n",
      "Epoch 4536, Loss: 0.0012090962118236348, Final Batch Loss: 0.0010153073817491531\n",
      "Epoch 4537, Loss: 0.0007042944198474288, Final Batch Loss: 0.0004480345523916185\n",
      "Epoch 4538, Loss: 0.0007524463289882988, Final Batch Loss: 0.00030048814369365573\n",
      "Epoch 4539, Loss: 0.00028320894489297643, Final Batch Loss: 0.00019867213268298656\n",
      "Epoch 4540, Loss: 0.00040713803900871426, Final Batch Loss: 0.00018007948528975248\n",
      "Epoch 4541, Loss: 0.0005030518950661644, Final Batch Loss: 0.00021355434728320688\n",
      "Epoch 4542, Loss: 0.0003426324255997315, Final Batch Loss: 4.8440779210068285e-05\n",
      "Epoch 4543, Loss: 0.00016201585094677284, Final Batch Loss: 7.043047662591562e-05\n",
      "Epoch 4544, Loss: 0.0012532981636468321, Final Batch Loss: 0.0012192626018077135\n",
      "Epoch 4545, Loss: 0.0004046011745231226, Final Batch Loss: 0.00022087902470957488\n",
      "Epoch 4546, Loss: 0.000810073281172663, Final Batch Loss: 0.00028002739418298006\n",
      "Epoch 4547, Loss: 0.0002688558743102476, Final Batch Loss: 8.81021551322192e-05\n",
      "Epoch 4548, Loss: 0.0002203378789999988, Final Batch Loss: 4.979388540959917e-05\n",
      "Epoch 4549, Loss: 0.00018650358833838254, Final Batch Loss: 0.00012504296319093555\n",
      "Epoch 4550, Loss: 0.0006017813575454056, Final Batch Loss: 0.0001332377432845533\n",
      "Epoch 4551, Loss: 0.00017435597692383453, Final Batch Loss: 0.00014060501416679472\n",
      "Epoch 4552, Loss: 0.0002587609051261097, Final Batch Loss: 8.343465742655098e-05\n",
      "Epoch 4553, Loss: 0.0023163409059634432, Final Batch Loss: 0.0001859931362560019\n",
      "Epoch 4554, Loss: 0.00016611934915999882, Final Batch Loss: 0.00011004267435055226\n",
      "Epoch 4555, Loss: 0.0004075097822351381, Final Batch Loss: 0.0001787526998668909\n",
      "Epoch 4556, Loss: 0.004456816186575452, Final Batch Loss: 3.579532858566381e-05\n",
      "Epoch 4557, Loss: 0.00030407827580347657, Final Batch Loss: 0.0001503374514868483\n",
      "Epoch 4558, Loss: 0.0004781571878993418, Final Batch Loss: 5.673779742210172e-05\n",
      "Epoch 4559, Loss: 0.00012005986354779452, Final Batch Loss: 4.4404849177226424e-05\n",
      "Epoch 4560, Loss: 0.0004335793055361137, Final Batch Loss: 0.00029117611120454967\n",
      "Epoch 4561, Loss: 0.0015116321592358872, Final Batch Loss: 7.711564830970019e-05\n",
      "Epoch 4562, Loss: 0.0005231067189015448, Final Batch Loss: 0.00015650209388695657\n",
      "Epoch 4563, Loss: 0.0019910935661755502, Final Batch Loss: 0.001480658771470189\n",
      "Epoch 4564, Loss: 0.0012010574282612652, Final Batch Loss: 4.042891669087112e-05\n",
      "Epoch 4565, Loss: 0.0019396663992665708, Final Batch Loss: 0.0017005440313369036\n",
      "Epoch 4566, Loss: 0.0001690164572210051, Final Batch Loss: 0.00010259407281409949\n",
      "Epoch 4567, Loss: 0.0002411145469523035, Final Batch Loss: 0.0001450330892112106\n",
      "Epoch 4568, Loss: 0.0002912655909312889, Final Batch Loss: 0.00011665074271149933\n",
      "Epoch 4569, Loss: 0.00013964142272016034, Final Batch Loss: 6.106149521656334e-05\n",
      "Epoch 4570, Loss: 0.0011581292055780068, Final Batch Loss: 4.386402724776417e-05\n",
      "Epoch 4571, Loss: 0.0010264318916597404, Final Batch Loss: 0.00011043667473131791\n",
      "Epoch 4572, Loss: 0.0008483538113068789, Final Batch Loss: 0.000562027154956013\n",
      "Epoch 4573, Loss: 0.0021424159058369696, Final Batch Loss: 0.0012157604796811938\n",
      "Epoch 4574, Loss: 0.0004601104592438787, Final Batch Loss: 0.0001688928168732673\n",
      "Epoch 4575, Loss: 0.0006875590333947912, Final Batch Loss: 0.00018033858214039356\n",
      "Epoch 4576, Loss: 0.0022541807556990534, Final Batch Loss: 0.0019540023058652878\n",
      "Epoch 4577, Loss: 0.00018993426056113094, Final Batch Loss: 7.693217776250094e-05\n",
      "Epoch 4578, Loss: 0.00025491642009001225, Final Batch Loss: 0.00012798342504538596\n",
      "Epoch 4579, Loss: 0.00017334299627691507, Final Batch Loss: 0.00011076911323470995\n",
      "Epoch 4580, Loss: 0.000211776998185087, Final Batch Loss: 0.00010791161184897646\n",
      "Epoch 4581, Loss: 0.0004236156528349966, Final Batch Loss: 0.0001530542504042387\n",
      "Epoch 4582, Loss: 0.00040644123509991914, Final Batch Loss: 0.00016489284462295473\n",
      "Epoch 4583, Loss: 0.00012776200310327113, Final Batch Loss: 6.371908966684714e-05\n",
      "Epoch 4584, Loss: 0.0009534685086691752, Final Batch Loss: 0.00021564921189565212\n",
      "Epoch 4585, Loss: 0.00019683637583511882, Final Batch Loss: 0.0001455615129088983\n",
      "Epoch 4586, Loss: 0.01695920834026765, Final Batch Loss: 0.016896696761250496\n",
      "Epoch 4587, Loss: 0.0003726293798536062, Final Batch Loss: 0.00021064747124910355\n",
      "Epoch 4588, Loss: 0.00020778984617209062, Final Batch Loss: 4.783274926012382e-05\n",
      "Epoch 4589, Loss: 0.00041470705036772415, Final Batch Loss: 4.6337889216374606e-05\n",
      "Epoch 4590, Loss: 0.00017703378398437053, Final Batch Loss: 6.649803253822029e-05\n",
      "Epoch 4591, Loss: 0.0073315013432875276, Final Batch Loss: 0.00010714365635067225\n",
      "Epoch 4592, Loss: 0.00028680686227744445, Final Batch Loss: 7.452646241290495e-05\n",
      "Epoch 4593, Loss: 0.002082488492305856, Final Batch Loss: 6.283772381721064e-05\n",
      "Epoch 4594, Loss: 0.0005074155633337796, Final Batch Loss: 0.00018557586008682847\n",
      "Epoch 4595, Loss: 0.000226684696826851, Final Batch Loss: 3.381943315616809e-05\n",
      "Epoch 4596, Loss: 0.0003346023695485201, Final Batch Loss: 0.0002860755193978548\n",
      "Epoch 4597, Loss: 0.00015899301070021465, Final Batch Loss: 1.6437370504718274e-05\n",
      "Epoch 4598, Loss: 0.0007045623642625287, Final Batch Loss: 0.00018902671581599861\n",
      "Epoch 4599, Loss: 0.00010160128294955939, Final Batch Loss: 4.9789887270890176e-05\n",
      "Epoch 4600, Loss: 0.0002732815482886508, Final Batch Loss: 9.35753487283364e-05\n",
      "Epoch 4601, Loss: 0.00013818351362715475, Final Batch Loss: 7.729553180979565e-05\n",
      "Epoch 4602, Loss: 0.0003823657025350258, Final Batch Loss: 0.000104348044260405\n",
      "Epoch 4603, Loss: 0.0008019748638616875, Final Batch Loss: 0.0001517458149464801\n",
      "Epoch 4604, Loss: 0.00011432546307332814, Final Batch Loss: 4.899944178760052e-05\n",
      "Epoch 4605, Loss: 0.0001927322955452837, Final Batch Loss: 0.00010004705836763605\n",
      "Epoch 4606, Loss: 0.0003217868579667993, Final Batch Loss: 0.00021795532666146755\n",
      "Epoch 4607, Loss: 0.00025546650431351736, Final Batch Loss: 6.649303395533934e-05\n",
      "Epoch 4608, Loss: 0.010529591527301818, Final Batch Loss: 5.086773307994008e-05\n",
      "Epoch 4609, Loss: 0.00010798179573612288, Final Batch Loss: 6.922142347320914e-05\n",
      "Epoch 4610, Loss: 0.0005389403959270567, Final Batch Loss: 0.0002831002639140934\n",
      "Epoch 4611, Loss: 0.0004132266476517543, Final Batch Loss: 0.0003643126110546291\n",
      "Epoch 4612, Loss: 0.00030957921990193427, Final Batch Loss: 0.00020634519751183689\n",
      "Epoch 4613, Loss: 0.03134100394709094, Final Batch Loss: 2.7271680664853193e-05\n",
      "Epoch 4614, Loss: 0.0010566659329924732, Final Batch Loss: 0.0007846597000025213\n",
      "Epoch 4615, Loss: 8.624711153970566e-05, Final Batch Loss: 2.980688623210881e-05\n",
      "Epoch 4616, Loss: 0.000319822873279918, Final Batch Loss: 0.00024300627410411835\n",
      "Epoch 4617, Loss: 0.0012646145041799173, Final Batch Loss: 0.001178118516691029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4618, Loss: 0.00036749799619428813, Final Batch Loss: 0.00015242089284583926\n",
      "Epoch 4619, Loss: 0.00012082920875400305, Final Batch Loss: 3.2478696084581316e-05\n",
      "Epoch 4620, Loss: 0.00017729968021740206, Final Batch Loss: 0.00014504553109873086\n",
      "Epoch 4621, Loss: 0.0008002023969311267, Final Batch Loss: 0.0007337104761973023\n",
      "Epoch 4622, Loss: 0.0036688371328637004, Final Batch Loss: 0.0028631798923015594\n",
      "Epoch 4623, Loss: 0.00032079738957691006, Final Batch Loss: 2.706019949982874e-05\n",
      "Epoch 4624, Loss: 0.00025209460727637634, Final Batch Loss: 0.00017980276606976986\n",
      "Epoch 4625, Loss: 0.00017493534687673673, Final Batch Loss: 0.00010067858238471672\n",
      "Epoch 4626, Loss: 0.00013385424972511828, Final Batch Loss: 5.8859208365902305e-05\n",
      "Epoch 4627, Loss: 0.0002082903665723279, Final Batch Loss: 0.00018104050832334906\n",
      "Epoch 4628, Loss: 0.00035332865445525385, Final Batch Loss: 4.672439899877645e-05\n",
      "Epoch 4629, Loss: 0.00045049340405967087, Final Batch Loss: 0.0001177804806502536\n",
      "Epoch 4630, Loss: 0.00026277115830453113, Final Batch Loss: 0.00016534839232917875\n",
      "Epoch 4631, Loss: 0.0001783801126293838, Final Batch Loss: 0.0001116018756874837\n",
      "Epoch 4632, Loss: 0.0005582111807598267, Final Batch Loss: 0.0005331067368388176\n",
      "Epoch 4633, Loss: 0.00037523738137679175, Final Batch Loss: 0.00026081502437591553\n",
      "Epoch 4634, Loss: 0.0002696412193472497, Final Batch Loss: 6.256714550545439e-05\n",
      "Epoch 4635, Loss: 0.00016608438454568386, Final Batch Loss: 9.267288987757638e-05\n",
      "Epoch 4636, Loss: 0.007001569028943777, Final Batch Loss: 0.0030618091113865376\n",
      "Epoch 4637, Loss: 0.00018405479931971058, Final Batch Loss: 0.00013584147382061929\n",
      "Epoch 4638, Loss: 0.0001023172171699116, Final Batch Loss: 1.6979212887235917e-05\n",
      "Epoch 4639, Loss: 0.0008145251558744349, Final Batch Loss: 0.0007149861194193363\n",
      "Epoch 4640, Loss: 0.0004488971026148647, Final Batch Loss: 0.00010156791540794075\n",
      "Epoch 4641, Loss: 0.0003093106461165007, Final Batch Loss: 3.189424387528561e-05\n",
      "Epoch 4642, Loss: 0.0011415926710469648, Final Batch Loss: 0.0010501726064831018\n",
      "Epoch 4643, Loss: 0.0005477810900629265, Final Batch Loss: 0.0005276535521261394\n",
      "Epoch 4644, Loss: 0.0003189931230735965, Final Batch Loss: 0.00020470336312428117\n",
      "Epoch 4645, Loss: 0.0002455993017065339, Final Batch Loss: 6.501474854303524e-05\n",
      "Epoch 4646, Loss: 0.00018558703595772386, Final Batch Loss: 8.780699863564223e-05\n",
      "Epoch 4647, Loss: 0.001218999779666774, Final Batch Loss: 0.0001345094497082755\n",
      "Epoch 4648, Loss: 0.0007258495752466843, Final Batch Loss: 0.00011857568460982293\n",
      "Epoch 4649, Loss: 0.0006496895439340733, Final Batch Loss: 0.0005777025362476707\n",
      "Epoch 4650, Loss: 0.001602999196620658, Final Batch Loss: 0.00032132319756783545\n",
      "Epoch 4651, Loss: 0.00014288111196947284, Final Batch Loss: 8.401444210903719e-05\n",
      "Epoch 4652, Loss: 0.0010839245514944196, Final Batch Loss: 0.0007625895086675882\n",
      "Epoch 4653, Loss: 0.0006487059872597456, Final Batch Loss: 0.00019739678828045726\n",
      "Epoch 4654, Loss: 0.0007483026420231909, Final Batch Loss: 0.0006450455985032022\n",
      "Epoch 4655, Loss: 0.0007416118023684248, Final Batch Loss: 0.000508093333337456\n",
      "Epoch 4656, Loss: 0.00018402015120955184, Final Batch Loss: 9.657826012698933e-05\n",
      "Epoch 4657, Loss: 0.00035601605850388296, Final Batch Loss: 4.9707992729963735e-05\n",
      "Epoch 4658, Loss: 0.00013510863209376112, Final Batch Loss: 8.87301575858146e-05\n",
      "Epoch 4659, Loss: 0.000344905725796707, Final Batch Loss: 0.0002929364563897252\n",
      "Epoch 4660, Loss: 0.0002363741077715531, Final Batch Loss: 0.00010401985491625965\n",
      "Epoch 4661, Loss: 0.00048088052426464856, Final Batch Loss: 0.00016768561908975244\n",
      "Epoch 4662, Loss: 0.0005798701895400882, Final Batch Loss: 0.0002793080057017505\n",
      "Epoch 4663, Loss: 0.0001399218108417699, Final Batch Loss: 1.720585896691773e-05\n",
      "Epoch 4664, Loss: 0.0002584729445516132, Final Batch Loss: 0.0001010521300486289\n",
      "Epoch 4665, Loss: 0.00036518938577501103, Final Batch Loss: 8.4469465946313e-05\n",
      "Epoch 4666, Loss: 0.0001482671832491178, Final Batch Loss: 9.961563773686066e-05\n",
      "Epoch 4667, Loss: 0.00017007492715492845, Final Batch Loss: 0.00010838488378794864\n",
      "Epoch 4668, Loss: 0.000152054795762524, Final Batch Loss: 6.36228869552724e-05\n",
      "Epoch 4669, Loss: 0.0002668067754711956, Final Batch Loss: 6.51670852676034e-05\n",
      "Epoch 4670, Loss: 8.67286253196653e-05, Final Batch Loss: 4.669520421884954e-05\n",
      "Epoch 4671, Loss: 0.00025524017110001296, Final Batch Loss: 0.0001248334883712232\n",
      "Epoch 4672, Loss: 0.00035040851798839867, Final Batch Loss: 0.00011147123586852103\n",
      "Epoch 4673, Loss: 0.0013087422812532168, Final Batch Loss: 0.0012778647942468524\n",
      "Epoch 4674, Loss: 7.539608486695215e-05, Final Batch Loss: 2.0072060578968376e-05\n",
      "Epoch 4675, Loss: 0.0010030502453446388, Final Batch Loss: 0.000887107802554965\n",
      "Epoch 4676, Loss: 0.00021119933080626652, Final Batch Loss: 8.301437628688291e-05\n",
      "Epoch 4677, Loss: 7.338653813349083e-05, Final Batch Loss: 3.219361315132119e-05\n",
      "Epoch 4678, Loss: 0.0005415011401055381, Final Batch Loss: 0.000149541549035348\n",
      "Epoch 4679, Loss: 0.0014223967009456828, Final Batch Loss: 0.0013969895662739873\n",
      "Epoch 4680, Loss: 0.003550262044882402, Final Batch Loss: 0.00033340402296744287\n",
      "Epoch 4681, Loss: 0.0005678628876921721, Final Batch Loss: 9.985254291677848e-05\n",
      "Epoch 4682, Loss: 0.0003220001526642591, Final Batch Loss: 0.00013230439799372107\n",
      "Epoch 4683, Loss: 0.0002857607323676348, Final Batch Loss: 7.852804264985025e-05\n",
      "Epoch 4684, Loss: 9.67205960478168e-05, Final Batch Loss: 3.7815127143403515e-05\n",
      "Epoch 4685, Loss: 0.00019706734747160226, Final Batch Loss: 9.159209730569273e-05\n",
      "Epoch 4686, Loss: 0.0003284903086751001, Final Batch Loss: 0.0003119584871456027\n",
      "Epoch 4687, Loss: 0.0002613844917505048, Final Batch Loss: 0.0001626974844839424\n",
      "Epoch 4688, Loss: 0.0020177791302558035, Final Batch Loss: 0.001926940050907433\n",
      "Epoch 4689, Loss: 0.00014136681420495734, Final Batch Loss: 9.263319952879101e-05\n",
      "Epoch 4690, Loss: 0.0010381542379036546, Final Batch Loss: 0.000754049455281347\n",
      "Epoch 4691, Loss: 0.0006561257177963853, Final Batch Loss: 0.0003500973107293248\n",
      "Epoch 4692, Loss: 0.00011598977289395407, Final Batch Loss: 3.879183350363746e-05\n",
      "Epoch 4693, Loss: 0.0003796952514676377, Final Batch Loss: 0.00019381790480110794\n",
      "Epoch 4694, Loss: 0.0001372358965454623, Final Batch Loss: 6.438318087020889e-05\n",
      "Epoch 4695, Loss: 0.000257704290561378, Final Batch Loss: 0.00013891626440454274\n",
      "Epoch 4696, Loss: 0.0009132108170888387, Final Batch Loss: 0.000877874088473618\n",
      "Epoch 4697, Loss: 0.0016365184856113046, Final Batch Loss: 0.0011914612259715796\n",
      "Epoch 4698, Loss: 6.693411978631048e-05, Final Batch Loss: 1.4575291970686521e-05\n",
      "Epoch 4699, Loss: 0.0003591213098843582, Final Batch Loss: 0.00011369153071427718\n",
      "Epoch 4700, Loss: 0.0004593013654812239, Final Batch Loss: 8.885544229997322e-05\n",
      "Epoch 4701, Loss: 0.0016749874339438975, Final Batch Loss: 0.0015646418323740363\n",
      "Epoch 4702, Loss: 9.96799863060005e-05, Final Batch Loss: 3.137557359877974e-05\n",
      "Epoch 4703, Loss: 0.0005606307095149532, Final Batch Loss: 0.00019217583758290857\n",
      "Epoch 4704, Loss: 0.0002592908203951083, Final Batch Loss: 6.747846055077389e-05\n",
      "Epoch 4705, Loss: 0.00011294147407170385, Final Batch Loss: 7.052319415379316e-05\n",
      "Epoch 4706, Loss: 0.000599051229073666, Final Batch Loss: 0.0004834718129131943\n",
      "Epoch 4707, Loss: 0.00037795151001773775, Final Batch Loss: 0.00023912212054710835\n",
      "Epoch 4708, Loss: 0.0018146481015719473, Final Batch Loss: 0.0007378683076240122\n",
      "Epoch 4709, Loss: 0.00020040128038090188, Final Batch Loss: 2.3178656192612834e-05\n",
      "Epoch 4710, Loss: 9.066934944712557e-05, Final Batch Loss: 1.6650406905682757e-05\n",
      "Epoch 4711, Loss: 0.0029625725437654182, Final Batch Loss: 0.0028257942758500576\n",
      "Epoch 4712, Loss: 0.0015999928582459688, Final Batch Loss: 0.0001727613853290677\n",
      "Epoch 4713, Loss: 0.0003437324321566848, Final Batch Loss: 0.00031835338450036943\n",
      "Epoch 4714, Loss: 9.71063163888175e-05, Final Batch Loss: 3.2700107112759724e-05\n",
      "Epoch 4715, Loss: 7.297774209291674e-05, Final Batch Loss: 4.166448343312368e-05\n",
      "Epoch 4716, Loss: 0.01972062641289085, Final Batch Loss: 0.018215356394648552\n",
      "Epoch 4717, Loss: 0.00022994577011559159, Final Batch Loss: 0.00011544548033270985\n",
      "Epoch 4718, Loss: 0.00037779232297907583, Final Batch Loss: 0.000354656542185694\n",
      "Epoch 4719, Loss: 0.0003316200527478941, Final Batch Loss: 2.272596611874178e-05\n",
      "Epoch 4720, Loss: 0.00017738796304911375, Final Batch Loss: 0.00012496253475546837\n",
      "Epoch 4721, Loss: 0.00013641891564475372, Final Batch Loss: 5.802271334687248e-05\n",
      "Epoch 4722, Loss: 0.0006399676494766027, Final Batch Loss: 0.00016914602019824088\n",
      "Epoch 4723, Loss: 4.1523235267959535e-05, Final Batch Loss: 1.7174183085444383e-05\n",
      "Epoch 4724, Loss: 0.0022464998219220433, Final Batch Loss: 3.3487860491732135e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4725, Loss: 0.000283960675005801, Final Batch Loss: 0.000236197593039833\n",
      "Epoch 4726, Loss: 0.00019670181791298091, Final Batch Loss: 1.9934435840696096e-05\n",
      "Epoch 4727, Loss: 0.00014115465091890655, Final Batch Loss: 8.654066186863929e-05\n",
      "Epoch 4728, Loss: 0.00019111171422991902, Final Batch Loss: 8.308871474582702e-05\n",
      "Epoch 4729, Loss: 0.00113954291009577, Final Batch Loss: 7.608708256157115e-05\n",
      "Epoch 4730, Loss: 0.0003413591184653342, Final Batch Loss: 0.00027269701240584254\n",
      "Epoch 4731, Loss: 0.00025902588822646067, Final Batch Loss: 0.00019697654352057725\n",
      "Epoch 4732, Loss: 3.440253112785285e-05, Final Batch Loss: 8.764206540945452e-06\n",
      "Epoch 4733, Loss: 0.0002663101040525362, Final Batch Loss: 0.00014926146832294762\n",
      "Epoch 4734, Loss: 0.0002386236228630878, Final Batch Loss: 0.0001473152224207297\n",
      "Epoch 4735, Loss: 0.00029663959503523074, Final Batch Loss: 4.842679118155502e-05\n",
      "Epoch 4736, Loss: 0.00018992912373505533, Final Batch Loss: 6.865818431833759e-05\n",
      "Epoch 4737, Loss: 0.00014848963473923504, Final Batch Loss: 5.332771979738027e-05\n",
      "Epoch 4738, Loss: 8.200616866815835e-05, Final Batch Loss: 3.94811577280052e-05\n",
      "Epoch 4739, Loss: 0.00010196285438723862, Final Batch Loss: 1.0497591574676335e-05\n",
      "Epoch 4740, Loss: 0.00047949215513654053, Final Batch Loss: 5.773728480562568e-05\n",
      "Epoch 4741, Loss: 0.0002513118233764544, Final Batch Loss: 0.00013807787036057562\n",
      "Epoch 4742, Loss: 0.0021136701689101756, Final Batch Loss: 0.00041163834976032376\n",
      "Epoch 4743, Loss: 0.00015499539586016908, Final Batch Loss: 8.019180677365512e-05\n",
      "Epoch 4744, Loss: 0.00011088531391578726, Final Batch Loss: 4.541077578323893e-05\n",
      "Epoch 4745, Loss: 0.00021521479357033968, Final Batch Loss: 0.0001054190652212128\n",
      "Epoch 4746, Loss: 0.00017008416762109846, Final Batch Loss: 7.909356645541266e-05\n",
      "Epoch 4747, Loss: 9.97718125290703e-05, Final Batch Loss: 8.695059659658e-05\n",
      "Epoch 4748, Loss: 9.065928952622926e-05, Final Batch Loss: 9.645641512179282e-06\n",
      "Epoch 4749, Loss: 0.00020622832107619615, Final Batch Loss: 4.054881173942704e-06\n",
      "Epoch 4750, Loss: 8.184150829038117e-05, Final Batch Loss: 2.230220525234472e-05\n",
      "Epoch 4751, Loss: 0.0003698907676152885, Final Batch Loss: 6.11970026511699e-05\n",
      "Epoch 4752, Loss: 0.0055218412016984075, Final Batch Loss: 0.005499724298715591\n",
      "Epoch 4753, Loss: 0.00017634842879488133, Final Batch Loss: 0.00014362986257765442\n",
      "Epoch 4754, Loss: 0.0009239640785381198, Final Batch Loss: 0.0003821561695076525\n",
      "Epoch 4755, Loss: 0.0003614750196447858, Final Batch Loss: 2.5303190795966657e-06\n",
      "Epoch 4756, Loss: 0.00010755307084764354, Final Batch Loss: 1.0111773008247837e-05\n",
      "Epoch 4757, Loss: 0.0006866907788207754, Final Batch Loss: 0.0005091839120723307\n",
      "Epoch 4758, Loss: 8.135617099469528e-05, Final Batch Loss: 3.259816730860621e-05\n",
      "Epoch 4759, Loss: 0.00016619831876596436, Final Batch Loss: 7.79354595579207e-05\n",
      "Epoch 4760, Loss: 0.0002830246085068211, Final Batch Loss: 6.897671846672893e-05\n",
      "Epoch 4761, Loss: 0.00047250420902855694, Final Batch Loss: 0.0003157016180921346\n",
      "Epoch 4762, Loss: 0.0006820924318162724, Final Batch Loss: 9.628929547034204e-06\n",
      "Epoch 4763, Loss: 0.00034580062492750585, Final Batch Loss: 0.00024483026936650276\n",
      "Epoch 4764, Loss: 8.867510132404277e-05, Final Batch Loss: 1.2020530448353384e-05\n",
      "Epoch 4765, Loss: 0.002813305203744676, Final Batch Loss: 0.002749031176790595\n",
      "Epoch 4766, Loss: 2.86807135125855e-05, Final Batch Loss: 1.1490879842313007e-05\n",
      "Epoch 4767, Loss: 6.384713014995214e-05, Final Batch Loss: 1.2901136869913898e-05\n",
      "Epoch 4768, Loss: 0.0005675780557794496, Final Batch Loss: 0.0004393519484438002\n",
      "Epoch 4769, Loss: 6.3984130974859e-05, Final Batch Loss: 1.934026659000665e-05\n",
      "Epoch 4770, Loss: 0.00048671055992599577, Final Batch Loss: 0.00025266598095186055\n",
      "Epoch 4771, Loss: 0.0006541867878695484, Final Batch Loss: 0.0005962135619483888\n",
      "Epoch 4772, Loss: 0.0003454868456174154, Final Batch Loss: 5.1070925110252574e-05\n",
      "Epoch 4773, Loss: 5.5144944781204686e-05, Final Batch Loss: 3.327235026517883e-05\n",
      "Epoch 4774, Loss: 0.002812947306665592, Final Batch Loss: 0.002774706808850169\n",
      "Epoch 4775, Loss: 0.0014649125732830726, Final Batch Loss: 0.0013598327059298754\n",
      "Epoch 4776, Loss: 0.00023207179765449837, Final Batch Loss: 0.00017235225823242217\n",
      "Epoch 4777, Loss: 7.027839092188515e-05, Final Batch Loss: 3.6018809623783454e-05\n",
      "Epoch 4778, Loss: 4.1336445065098815e-05, Final Batch Loss: 2.0138717445661314e-05\n",
      "Epoch 4779, Loss: 0.0026358998075011186, Final Batch Loss: 3.080453461734578e-05\n",
      "Epoch 4780, Loss: 0.0004555460691335611, Final Batch Loss: 0.00041384046198800206\n",
      "Epoch 4781, Loss: 0.00028945290978299454, Final Batch Loss: 0.0002576014958322048\n",
      "Epoch 4782, Loss: 0.00013703754666494206, Final Batch Loss: 7.007719250395894e-05\n",
      "Epoch 4783, Loss: 0.0001537758726044558, Final Batch Loss: 3.729850141098723e-05\n",
      "Epoch 4784, Loss: 0.00010730582653195597, Final Batch Loss: 8.423381223110482e-05\n",
      "Epoch 4785, Loss: 0.00021565055067185313, Final Batch Loss: 3.2371433917433023e-05\n",
      "Epoch 4786, Loss: 8.827024066704325e-05, Final Batch Loss: 4.411031477502547e-05\n",
      "Epoch 4787, Loss: 0.00017509591634734534, Final Batch Loss: 0.00014016279601491988\n",
      "Epoch 4788, Loss: 4.933201125822961e-05, Final Batch Loss: 1.9345363398315385e-05\n",
      "Epoch 4789, Loss: 0.00012589697871590033, Final Batch Loss: 2.9720438760705292e-05\n",
      "Epoch 4790, Loss: 0.00032906981505220756, Final Batch Loss: 0.0002914362703450024\n",
      "Epoch 4791, Loss: 0.0002335100380150834, Final Batch Loss: 2.927235073002521e-05\n",
      "Epoch 4792, Loss: 0.00014689263298350852, Final Batch Loss: 0.00012953614350408316\n",
      "Epoch 4793, Loss: 0.00019132949091726914, Final Batch Loss: 5.346035322872922e-05\n",
      "Epoch 4794, Loss: 9.280601079808548e-05, Final Batch Loss: 1.950810110429302e-05\n",
      "Epoch 4795, Loss: 0.004701065132394433, Final Batch Loss: 0.0006162014324218035\n",
      "Epoch 4796, Loss: 0.00014038251174497418, Final Batch Loss: 5.207108551985584e-05\n",
      "Epoch 4797, Loss: 0.0001662683571339585, Final Batch Loss: 7.864724466344342e-05\n",
      "Epoch 4798, Loss: 0.00012430775859684218, Final Batch Loss: 1.5521714885835536e-05\n",
      "Epoch 4799, Loss: 0.0001720624823065009, Final Batch Loss: 3.19592327286955e-05\n",
      "Epoch 4800, Loss: 0.00034565642999950796, Final Batch Loss: 0.00020825992396567017\n",
      "Epoch 4801, Loss: 1.1980393537669443e-05, Final Batch Loss: 5.463231445901329e-06\n",
      "Epoch 4802, Loss: 5.1120265197823755e-05, Final Batch Loss: 6.946213034098037e-06\n",
      "Epoch 4803, Loss: 0.00024484222740284167, Final Batch Loss: 2.19010362343397e-05\n",
      "Epoch 4804, Loss: 3.101883066847222e-05, Final Batch Loss: 1.2726658496831078e-05\n",
      "Epoch 4805, Loss: 9.301366299041547e-05, Final Batch Loss: 2.0274161215638742e-05\n",
      "Epoch 4806, Loss: 7.223842112580314e-05, Final Batch Loss: 3.1077535822987556e-05\n",
      "Epoch 4807, Loss: 0.0004272678452252876, Final Batch Loss: 0.00037040101597085595\n",
      "Epoch 4808, Loss: 4.235190590407001e-05, Final Batch Loss: 3.088585799559951e-05\n",
      "Epoch 4809, Loss: 9.244438115274534e-05, Final Batch Loss: 5.4600091971224174e-05\n",
      "Epoch 4810, Loss: 5.270959309200407e-05, Final Batch Loss: 4.961244940204779e-06\n",
      "Epoch 4811, Loss: 5.1243234338471666e-05, Final Batch Loss: 1.5994872228475288e-05\n",
      "Epoch 4812, Loss: 3.787911828112556e-05, Final Batch Loss: 1.3264280823932495e-05\n",
      "Epoch 4813, Loss: 0.0013673335779458284, Final Batch Loss: 0.00010565714910626411\n",
      "Epoch 4814, Loss: 0.0006903944886289537, Final Batch Loss: 0.0005631210515275598\n",
      "Epoch 4815, Loss: 8.439045996055938e-05, Final Batch Loss: 6.73408794682473e-05\n",
      "Epoch 4816, Loss: 6.988805034779944e-05, Final Batch Loss: 3.1115963793126866e-05\n",
      "Epoch 4817, Loss: 0.00030758506909478456, Final Batch Loss: 6.615542224608362e-05\n",
      "Epoch 4818, Loss: 0.0004919865750707686, Final Batch Loss: 0.00025195436319336295\n",
      "Epoch 4819, Loss: 7.760905464238022e-05, Final Batch Loss: 6.95457129040733e-05\n",
      "Epoch 4820, Loss: 8.141169928421732e-05, Final Batch Loss: 2.022347143793013e-05\n",
      "Epoch 4821, Loss: 5.085015254735481e-05, Final Batch Loss: 3.141200068057515e-05\n",
      "Epoch 4822, Loss: 0.00011293873467366211, Final Batch Loss: 8.716141746845096e-05\n",
      "Epoch 4823, Loss: 7.041860953904688e-05, Final Batch Loss: 2.701325502130203e-05\n",
      "Epoch 4824, Loss: 0.013580223007011227, Final Batch Loss: 0.013409466482698917\n",
      "Epoch 4825, Loss: 0.0006001246511004865, Final Batch Loss: 7.822614861652255e-05\n",
      "Epoch 4826, Loss: 0.00014403613204194698, Final Batch Loss: 1.7859589206636883e-05\n",
      "Epoch 4827, Loss: 0.0003436639963183552, Final Batch Loss: 0.0002504489675629884\n",
      "Epoch 4828, Loss: 0.0004576718347379938, Final Batch Loss: 0.0002572935482021421\n",
      "Epoch 4829, Loss: 8.205083395296242e-05, Final Batch Loss: 2.8806434784200974e-05\n",
      "Epoch 4830, Loss: 0.013688311111764051, Final Batch Loss: 3.8447920815087855e-05\n",
      "Epoch 4831, Loss: 0.0001748436673096876, Final Batch Loss: 3.2026048302213894e-06\n",
      "Epoch 4832, Loss: 7.390231257886626e-05, Final Batch Loss: 5.467408846016042e-05\n",
      "Epoch 4833, Loss: 0.0011158255838381592, Final Batch Loss: 4.7116049245232716e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4834, Loss: 0.00010310295692761429, Final Batch Loss: 3.431357254157774e-05\n",
      "Epoch 4835, Loss: 3.6046270906808786e-05, Final Batch Loss: 7.638935130671598e-06\n",
      "Epoch 4836, Loss: 0.00032474961881234776, Final Batch Loss: 0.000304948422126472\n",
      "Epoch 4837, Loss: 0.0005045322759542614, Final Batch Loss: 0.0003254302137065679\n",
      "Epoch 4838, Loss: 0.00036445115256356075, Final Batch Loss: 8.607345080235973e-05\n",
      "Epoch 4839, Loss: 0.0009861594153335318, Final Batch Loss: 6.242572271730751e-05\n",
      "Epoch 4840, Loss: 0.00922733321931446, Final Batch Loss: 0.009151780977845192\n",
      "Epoch 4841, Loss: 0.0013767824857495725, Final Batch Loss: 0.0005234073614701629\n",
      "Epoch 4842, Loss: 0.00029742351034656167, Final Batch Loss: 0.0001043499942170456\n",
      "Epoch 4843, Loss: 0.0004446985713002505, Final Batch Loss: 2.3061280444380827e-05\n",
      "Epoch 4844, Loss: 0.0004812445240531815, Final Batch Loss: 1.9086261090706103e-05\n",
      "Epoch 4845, Loss: 0.00040299964166479185, Final Batch Loss: 9.071309614228085e-05\n",
      "Epoch 4846, Loss: 7.707463009865023e-05, Final Batch Loss: 4.537116546998732e-05\n",
      "Epoch 4847, Loss: 0.0007755726983305067, Final Batch Loss: 0.0002933239738922566\n",
      "Epoch 4848, Loss: 8.023464761208743e-05, Final Batch Loss: 2.7429196052253246e-05\n",
      "Epoch 4849, Loss: 0.00038214150845305994, Final Batch Loss: 8.276012522401288e-05\n",
      "Epoch 4850, Loss: 8.114613410725724e-05, Final Batch Loss: 3.000729157065507e-05\n",
      "Epoch 4851, Loss: 0.00014661241220892407, Final Batch Loss: 1.6267560567939654e-05\n",
      "Epoch 4852, Loss: 0.005658850308464025, Final Batch Loss: 2.7176693038200028e-05\n",
      "Epoch 4853, Loss: 0.0003467632268439047, Final Batch Loss: 0.0002549233613535762\n",
      "Epoch 4854, Loss: 4.579738924803678e-05, Final Batch Loss: 9.55462564888876e-06\n",
      "Epoch 4855, Loss: 8.572582737542689e-05, Final Batch Loss: 2.8765134629793465e-05\n",
      "Epoch 4856, Loss: 0.0003015981492353603, Final Batch Loss: 4.883059591520578e-05\n",
      "Epoch 4857, Loss: 0.0015087947831489146, Final Batch Loss: 0.0008707190281711519\n",
      "Epoch 4858, Loss: 0.00037719930696766824, Final Batch Loss: 0.0003406244213692844\n",
      "Epoch 4859, Loss: 0.000319975231832359, Final Batch Loss: 6.831973587395623e-05\n",
      "Epoch 4860, Loss: 2.7342113753547892e-05, Final Batch Loss: 1.3191967809689231e-05\n",
      "Epoch 4861, Loss: 0.0015718104841653258, Final Batch Loss: 0.001384506467729807\n",
      "Epoch 4862, Loss: 0.00021938532154308632, Final Batch Loss: 1.9186940335202962e-05\n",
      "Epoch 4863, Loss: 0.0006516850626212545, Final Batch Loss: 0.0005801522056572139\n",
      "Epoch 4864, Loss: 0.00033827504921646323, Final Batch Loss: 0.000309388356981799\n",
      "Epoch 4865, Loss: 0.0002752114742179401, Final Batch Loss: 1.887910912046209e-05\n",
      "Epoch 4866, Loss: 0.00043494604688021354, Final Batch Loss: 5.4616026318399236e-05\n",
      "Epoch 4867, Loss: 0.00018971266490552807, Final Batch Loss: 1.339582468062872e-05\n",
      "Epoch 4868, Loss: 0.00012191920723125804, Final Batch Loss: 2.4217066311393864e-05\n",
      "Epoch 4869, Loss: 0.00018994602578459308, Final Batch Loss: 5.125493771629408e-05\n",
      "Epoch 4870, Loss: 0.0001065848337020725, Final Batch Loss: 3.360124537721276e-05\n",
      "Epoch 4871, Loss: 9.643858356866986e-05, Final Batch Loss: 3.2311014365404844e-05\n",
      "Epoch 4872, Loss: 0.00012245663674548268, Final Batch Loss: 5.8996636653319e-05\n",
      "Epoch 4873, Loss: 0.00039242856655619107, Final Batch Loss: 3.043919787160121e-05\n",
      "Epoch 4874, Loss: 0.00031596455301041715, Final Batch Loss: 0.000287260307231918\n",
      "Epoch 4875, Loss: 0.00011911400724784471, Final Batch Loss: 4.327870192355476e-05\n",
      "Epoch 4876, Loss: 0.0001136051578214392, Final Batch Loss: 5.5217285989783704e-05\n",
      "Epoch 4877, Loss: 0.000871047202963382, Final Batch Loss: 0.0005688751698471606\n",
      "Epoch 4878, Loss: 8.989822890725918e-05, Final Batch Loss: 2.5435332645429298e-05\n",
      "Epoch 4879, Loss: 2.0780460090463748e-05, Final Batch Loss: 4.852563051827019e-06\n",
      "Epoch 4880, Loss: 0.0006494464032584801, Final Batch Loss: 0.0005344350356608629\n",
      "Epoch 4881, Loss: 0.00014888052464812063, Final Batch Loss: 2.523796501918696e-05\n",
      "Epoch 4882, Loss: 0.00037744791188742965, Final Batch Loss: 0.0002865530550479889\n",
      "Epoch 4883, Loss: 0.0003824368759524077, Final Batch Loss: 0.00029295479180291295\n",
      "Epoch 4884, Loss: 0.00035816887248074636, Final Batch Loss: 7.892588473623618e-05\n",
      "Epoch 4885, Loss: 0.0024269339628517628, Final Batch Loss: 0.0005743261426687241\n",
      "Epoch 4886, Loss: 0.0002916195589932613, Final Batch Loss: 0.00025404428015463054\n",
      "Epoch 4887, Loss: 0.000232583061006153, Final Batch Loss: 0.00017739507893566042\n",
      "Epoch 4888, Loss: 0.00300349312601611, Final Batch Loss: 0.0024826359003782272\n",
      "Epoch 4889, Loss: 7.053125591482967e-05, Final Batch Loss: 3.5310185921844095e-05\n",
      "Epoch 4890, Loss: 0.00010492437104403507, Final Batch Loss: 2.203622534580063e-05\n",
      "Epoch 4891, Loss: 0.02361976653628517, Final Batch Loss: 0.00017282665066886693\n",
      "Epoch 4892, Loss: 0.0002642910840222612, Final Batch Loss: 9.906094055622816e-05\n",
      "Epoch 4893, Loss: 8.310045814141631e-05, Final Batch Loss: 4.1182702261721715e-05\n",
      "Epoch 4894, Loss: 0.00029447000997606665, Final Batch Loss: 0.0002680325123947114\n",
      "Epoch 4895, Loss: 0.0002119755736202933, Final Batch Loss: 7.017203461145982e-05\n",
      "Epoch 4896, Loss: 0.018937558685138356, Final Batch Loss: 0.00010871217091334984\n",
      "Epoch 4897, Loss: 9.13799067348009e-05, Final Batch Loss: 2.0648110876209103e-05\n",
      "Epoch 4898, Loss: 0.00024551725800847635, Final Batch Loss: 5.576511466642842e-05\n",
      "Epoch 4899, Loss: 0.00010804365592775866, Final Batch Loss: 6.120480975368991e-05\n",
      "Epoch 4900, Loss: 0.00028317468422756065, Final Batch Loss: 8.780802090768702e-06\n",
      "Epoch 4901, Loss: 0.012996544181078207, Final Batch Loss: 0.012906394898891449\n",
      "Epoch 4902, Loss: 0.00018194971198681742, Final Batch Loss: 7.226449815789238e-05\n",
      "Epoch 4903, Loss: 0.0008473950874758884, Final Batch Loss: 0.00013382387987803668\n",
      "Epoch 4904, Loss: 0.00016234105714829639, Final Batch Loss: 9.018096898216754e-05\n",
      "Epoch 4905, Loss: 0.00019446499754849356, Final Batch Loss: 2.4662947907927446e-05\n",
      "Epoch 4906, Loss: 0.0010894145525526255, Final Batch Loss: 0.00062136584892869\n",
      "Epoch 4907, Loss: 0.00201577803818509, Final Batch Loss: 0.000649667636025697\n",
      "Epoch 4908, Loss: 0.0024063092350843363, Final Batch Loss: 6.225762626854703e-05\n",
      "Epoch 4909, Loss: 0.0005785926769021899, Final Batch Loss: 0.0003485267807263881\n",
      "Epoch 4910, Loss: 9.183676229440607e-05, Final Batch Loss: 4.299794090911746e-05\n",
      "Epoch 4911, Loss: 0.0008521551208104938, Final Batch Loss: 0.0007466941606253386\n",
      "Epoch 4912, Loss: 0.00019542573136277497, Final Batch Loss: 7.10565218469128e-05\n",
      "Epoch 4913, Loss: 0.0002977102922159247, Final Batch Loss: 0.0002487461606506258\n",
      "Epoch 4914, Loss: 0.000179049362486694, Final Batch Loss: 1.2033931852784008e-05\n",
      "Epoch 4915, Loss: 0.0002826399577315897, Final Batch Loss: 0.000150454870890826\n",
      "Epoch 4916, Loss: 0.00012862399671575986, Final Batch Loss: 4.787181023857556e-05\n",
      "Epoch 4917, Loss: 0.00034191425947938114, Final Batch Loss: 3.928963269572705e-05\n",
      "Epoch 4918, Loss: 0.0014461872124229558, Final Batch Loss: 1.9742474250961095e-05\n",
      "Epoch 4919, Loss: 0.00014568179176421836, Final Batch Loss: 8.984006126411259e-05\n",
      "Epoch 4920, Loss: 0.00026509593681112165, Final Batch Loss: 7.991039638000075e-06\n",
      "Epoch 4921, Loss: 0.000160876374138752, Final Batch Loss: 0.00012586235243361443\n",
      "Epoch 4922, Loss: 0.02914548477565404, Final Batch Loss: 0.0290128942579031\n",
      "Epoch 4923, Loss: 0.00045478354149963707, Final Batch Loss: 0.00037124683149158955\n",
      "Epoch 4924, Loss: 0.007043055258691311, Final Batch Loss: 0.0003108559176325798\n",
      "Epoch 4925, Loss: 0.00022944442025618628, Final Batch Loss: 7.908643601695076e-05\n",
      "Epoch 4926, Loss: 0.00017265100905206054, Final Batch Loss: 0.0001324818003922701\n",
      "Epoch 4927, Loss: 0.00024133597980835475, Final Batch Loss: 4.235207234160043e-05\n",
      "Epoch 4928, Loss: 0.0003755793732125312, Final Batch Loss: 0.00019100122153759003\n",
      "Epoch 4929, Loss: 0.00018957768406835385, Final Batch Loss: 2.1920383005635813e-05\n",
      "Epoch 4930, Loss: 0.000236820662394166, Final Batch Loss: 0.00017192914674524218\n",
      "Epoch 4931, Loss: 0.0003949741367250681, Final Batch Loss: 0.00018187487148679793\n",
      "Epoch 4932, Loss: 0.0013947725528851151, Final Batch Loss: 0.0007232223288156092\n",
      "Epoch 4933, Loss: 0.00040494767017662525, Final Batch Loss: 0.0001247901818715036\n",
      "Epoch 4934, Loss: 0.00016327482444467023, Final Batch Loss: 8.974719094112515e-05\n",
      "Epoch 4935, Loss: 0.00017154891247628257, Final Batch Loss: 6.769499304937199e-05\n",
      "Epoch 4936, Loss: 0.0006813633372075856, Final Batch Loss: 0.0001107022981159389\n",
      "Epoch 4937, Loss: 8.898055966710672e-05, Final Batch Loss: 5.656723442371003e-05\n",
      "Epoch 4938, Loss: 0.00023517462250310928, Final Batch Loss: 0.00016080022032838315\n",
      "Epoch 4939, Loss: 0.00018137291226594243, Final Batch Loss: 0.00015984533820301294\n",
      "Epoch 4940, Loss: 0.0008331461067427881, Final Batch Loss: 6.608269904972985e-05\n",
      "Epoch 4941, Loss: 0.00021656008539139293, Final Batch Loss: 0.0001894442830234766\n",
      "Epoch 4942, Loss: 0.0016134755569510162, Final Batch Loss: 0.0007373625412583351\n",
      "Epoch 4943, Loss: 0.000269499067144352, Final Batch Loss: 9.141962436842732e-06\n",
      "Epoch 4944, Loss: 0.0006297236104728654, Final Batch Loss: 0.00020331489213276654\n",
      "Epoch 4945, Loss: 0.00047845294830040075, Final Batch Loss: 4.59040493296925e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4946, Loss: 0.0003898990398738533, Final Batch Loss: 0.00012000507558695972\n",
      "Epoch 4947, Loss: 0.0006094788259360939, Final Batch Loss: 0.0003243631508667022\n",
      "Epoch 4948, Loss: 0.00012782146222889423, Final Batch Loss: 0.00011688522499753162\n",
      "Epoch 4949, Loss: 0.011427356919739395, Final Batch Loss: 0.011240779422223568\n",
      "Epoch 4950, Loss: 0.0008912117191357538, Final Batch Loss: 0.000128955565742217\n",
      "Epoch 4951, Loss: 6.241845221666154e-05, Final Batch Loss: 1.5730607628938742e-05\n",
      "Epoch 4952, Loss: 0.00014889146041241474, Final Batch Loss: 3.2052052119979635e-05\n",
      "Epoch 4953, Loss: 0.0009803129105421249, Final Batch Loss: 3.129869946860708e-05\n",
      "Epoch 4954, Loss: 0.00024039588606683537, Final Batch Loss: 0.00020275106362532824\n",
      "Epoch 4955, Loss: 0.0020665375122916885, Final Batch Loss: 7.954054308356717e-05\n",
      "Epoch 4956, Loss: 0.00040579734195489436, Final Batch Loss: 0.00019585051632020622\n",
      "Epoch 4957, Loss: 0.0003023045137524605, Final Batch Loss: 0.00017801056674215943\n",
      "Epoch 4958, Loss: 0.00029558135793195106, Final Batch Loss: 3.767817179323174e-05\n",
      "Epoch 4959, Loss: 0.004091253642400261, Final Batch Loss: 6.241458322620019e-05\n",
      "Epoch 4960, Loss: 0.00011590243229875341, Final Batch Loss: 1.4537014067173004e-05\n",
      "Epoch 4961, Loss: 0.006822287165050511, Final Batch Loss: 0.006794346496462822\n",
      "Epoch 4962, Loss: 0.0016873020576895215, Final Batch Loss: 0.0016194049967452884\n",
      "Epoch 4963, Loss: 0.0002322587024536915, Final Batch Loss: 6.519382441183552e-05\n",
      "Epoch 4964, Loss: 0.034430409694323316, Final Batch Loss: 0.034300461411476135\n",
      "Epoch 4965, Loss: 0.00022803957108408213, Final Batch Loss: 4.0876970160752535e-05\n",
      "Epoch 4966, Loss: 8.04245901235845e-05, Final Batch Loss: 4.4537606299854815e-05\n",
      "Epoch 4967, Loss: 0.00020241855236236006, Final Batch Loss: 0.00010969336290145293\n",
      "Epoch 4968, Loss: 0.028591021429747343, Final Batch Loss: 0.02595498412847519\n",
      "Epoch 4969, Loss: 0.0050022828072542325, Final Batch Loss: 0.004786197561770678\n",
      "Epoch 4970, Loss: 0.02283220284152776, Final Batch Loss: 0.02271292358636856\n",
      "Epoch 4971, Loss: 0.02392011105257552, Final Batch Loss: 0.00012823908764403313\n",
      "Epoch 4972, Loss: 0.00026830047863768414, Final Batch Loss: 6.319612293737009e-05\n",
      "Epoch 4973, Loss: 0.0166602972894907, Final Batch Loss: 0.0022322405129671097\n",
      "Epoch 4974, Loss: 0.0036917533143423498, Final Batch Loss: 0.00029544223798438907\n",
      "Epoch 4975, Loss: 0.00014502808699035086, Final Batch Loss: 4.9755301006371155e-05\n",
      "Epoch 4976, Loss: 0.0003029163781320676, Final Batch Loss: 0.0001649525365792215\n",
      "Epoch 4977, Loss: 0.0009525052300887182, Final Batch Loss: 0.0001100006775232032\n",
      "Epoch 4978, Loss: 0.004073705349583179, Final Batch Loss: 0.0008910841424949467\n",
      "Epoch 4979, Loss: 0.002983822312671691, Final Batch Loss: 0.0006765882135368884\n",
      "Epoch 4980, Loss: 0.013543154753278941, Final Batch Loss: 0.013201914727687836\n",
      "Epoch 4981, Loss: 0.02226185555991833, Final Batch Loss: 5.12091392010916e-05\n",
      "Epoch 4982, Loss: 0.007780158419336658, Final Batch Loss: 0.007665878161787987\n",
      "Epoch 4983, Loss: 0.005009075939597096, Final Batch Loss: 0.00010779903823276982\n",
      "Epoch 4984, Loss: 0.0008458444899588358, Final Batch Loss: 0.0008052057237364352\n",
      "Epoch 4985, Loss: 0.0002345841785427183, Final Batch Loss: 0.000193142332136631\n",
      "Epoch 4986, Loss: 0.002686055593585479, Final Batch Loss: 2.5973406081902795e-05\n",
      "Epoch 4987, Loss: 0.00010249585830024444, Final Batch Loss: 6.316108192550018e-05\n",
      "Epoch 4988, Loss: 0.0011485580180305988, Final Batch Loss: 0.0008876950014382601\n",
      "Epoch 4989, Loss: 0.00011365905083948746, Final Batch Loss: 8.872711623553187e-05\n",
      "Epoch 4990, Loss: 7.793287659296766e-05, Final Batch Loss: 3.098849629168399e-05\n",
      "Epoch 4991, Loss: 0.00040038278530118987, Final Batch Loss: 0.000355692085577175\n",
      "Epoch 4992, Loss: 0.006646523795097892, Final Batch Loss: 1.3835339814249892e-05\n",
      "Epoch 4993, Loss: 0.00011794527381425723, Final Batch Loss: 3.268774162279442e-05\n",
      "Epoch 4994, Loss: 0.0001418985157215502, Final Batch Loss: 4.276427716831677e-05\n",
      "Epoch 4995, Loss: 0.0001088222925318405, Final Batch Loss: 6.140768527984619e-05\n",
      "Epoch 4996, Loss: 0.00014821424701949582, Final Batch Loss: 9.10386661416851e-05\n",
      "Epoch 4997, Loss: 0.0003944942873204127, Final Batch Loss: 0.00026103624259121716\n",
      "Epoch 4998, Loss: 0.0003659449002952897, Final Batch Loss: 1.4968071809562389e-05\n",
      "Epoch 4999, Loss: 0.009735092695336789, Final Batch Loss: 4.777422873303294e-05\n",
      "Epoch 5000, Loss: 0.0002115568804583745, Final Batch Loss: 1.7814165403251536e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  1  0]\n",
      " [ 0 22  0]\n",
      " [ 0  0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.968     0.984        31\n",
      "           1      0.957     1.000     0.978        22\n",
      "           2      1.000     1.000     1.000        22\n",
      "\n",
      "    accuracy                          0.987        75\n",
      "   macro avg      0.986     0.989     0.987        75\n",
      "weighted avg      0.987     0.987     0.987        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../saved_models/UCI 3 Label Classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
