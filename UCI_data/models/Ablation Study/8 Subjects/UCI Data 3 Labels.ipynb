{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '390 fBodyAccJerk-bandsEnergy()-1,16',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>58 tGravityAcc-energy()-Y</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>475 fBodyGyro-bandsEnergy()-1,8</th>\n",
       "      <th>...</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>382 fBodyAccJerk-bandsEnergy()-1,8</th>\n",
       "      <th>390 fBodyAccJerk-bandsEnergy()-1,16</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.970905</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.999454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.970583</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999987</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.970368</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.969400</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.999931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.999978</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.967051</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999995</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.918375</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>-0.053258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.839256</td>\n",
       "      <td>-0.775736</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.902880</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>-0.029411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.854278</td>\n",
       "      <td>-0.780751</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.907561</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.161404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.815380</td>\n",
       "      <td>-0.783616</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.910648</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.822905</td>\n",
       "      <td>-0.821137</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.910579</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>-0.129277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.834215</td>\n",
       "      <td>-0.825848</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  58 tGravityAcc-energy()-Y  \\\n",
       "0                   0.056483             -0.375426                  -0.970905   \n",
       "1                   0.102764             -0.383430                  -0.970583   \n",
       "2                   0.102764             -0.401602                  -0.970368   \n",
       "3                   0.095753             -0.400278                  -0.969400   \n",
       "4                   0.094059             -0.400477                  -0.967051   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.918375   \n",
       "7348               -0.068919             -0.358934                  -0.902880   \n",
       "7349               -0.068919             -0.377025                  -0.907561   \n",
       "7350               -0.040009             -0.440050                  -0.910648   \n",
       "7351               -0.047491             -0.432003                  -0.910579   \n",
       "\n",
       "      59 tGravityAcc-energy()-Z  475 fBodyGyro-bandsEnergy()-1,8  ...  \\\n",
       "0                     -0.975510                        -0.999454  ...   \n",
       "1                     -0.978500                        -0.999856  ...   \n",
       "2                     -0.981672                        -0.999954  ...   \n",
       "3                     -0.982420                        -0.999931  ...   \n",
       "4                     -0.984363                        -0.999926  ...   \n",
       "...                         ...                              ...  ...   \n",
       "7347                  -0.995193                        -0.053258  ...   \n",
       "7348                  -0.995151                        -0.029411  ...   \n",
       "7349                  -0.995450                         0.161404  ...   \n",
       "7350                  -0.998824                         0.193585  ...   \n",
       "7351                  -0.998144                        -0.129277  ...   \n",
       "\n",
       "      303 fBodyAcc-bandsEnergy()-1,8  311 fBodyAcc-bandsEnergy()-1,16  \\\n",
       "0                          -0.999963                        -0.999969   \n",
       "1                          -0.999996                        -0.999994   \n",
       "2                          -0.999989                        -0.999983   \n",
       "3                          -0.999989                        -0.999986   \n",
       "4                          -0.999994                        -0.999993   \n",
       "...                              ...                              ...   \n",
       "7347                       -0.684177                        -0.666429   \n",
       "7348                       -0.726986                        -0.704444   \n",
       "7349                       -0.655263                        -0.674515   \n",
       "7350                       -0.643425                        -0.677215   \n",
       "7351                       -0.709495                        -0.728519   \n",
       "\n",
       "      315 fBodyAcc-bandsEnergy()-1,24  382 fBodyAccJerk-bandsEnergy()-1,8  \\\n",
       "0                           -0.999971                           -0.999986   \n",
       "1                           -0.999992                           -0.999996   \n",
       "2                           -0.999972                           -0.999994   \n",
       "3                           -0.999977                           -0.999998   \n",
       "4                           -0.999991                           -0.999995   \n",
       "...                               ...                                 ...   \n",
       "7347                        -0.668164                           -0.839256   \n",
       "7348                        -0.705435                           -0.854278   \n",
       "7349                        -0.684729                           -0.815380   \n",
       "7350                        -0.685088                           -0.822905   \n",
       "7351                        -0.727441                           -0.834215   \n",
       "\n",
       "      390 fBodyAccJerk-bandsEnergy()-1,16  504 fBodyAccMag-std()  \\\n",
       "0                               -0.999982              -0.956134   \n",
       "1                               -0.999987              -0.975866   \n",
       "2                               -0.999963              -0.989015   \n",
       "3                               -0.999978              -0.986742   \n",
       "4                               -0.999988              -0.990063   \n",
       "...                                   ...                    ...   \n",
       "7347                            -0.775736              -0.232600   \n",
       "7348                            -0.780751              -0.275373   \n",
       "7349                            -0.783616              -0.220288   \n",
       "7350                            -0.821137              -0.234539   \n",
       "7351                            -0.825848              -0.342670   \n",
       "\n",
       "      505 fBodyAccMag-mad()  509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                 -0.948870                 -0.998285         5        1  \n",
       "1                 -0.975777                 -0.999472         5        1  \n",
       "2                 -0.985594                 -0.999807         5        1  \n",
       "3                 -0.983524                 -0.999770         5        1  \n",
       "4                 -0.992324                 -0.999873         5        1  \n",
       "...                     ...                       ...       ...      ...  \n",
       "7347              -0.007392                 -0.584282         2       30  \n",
       "7348              -0.172448                 -0.632536         2       30  \n",
       "7349              -0.216074                 -0.641170         2       30  \n",
       "7350              -0.220443                 -0.663579         2       30  \n",
       "7351              -0.146649                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8, 11, 14])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8, 11, 14])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.590729475021362, Final Batch Loss: 1.1597975492477417\n",
      "Epoch 2, Loss: 4.5504618883132935, Final Batch Loss: 1.125124216079712\n",
      "Epoch 3, Loss: 4.523435592651367, Final Batch Loss: 1.1354899406433105\n",
      "Epoch 4, Loss: 4.488095164299011, Final Batch Loss: 1.1036112308502197\n",
      "Epoch 5, Loss: 4.470677018165588, Final Batch Loss: 1.1239631175994873\n",
      "Epoch 6, Loss: 4.432924509048462, Final Batch Loss: 1.099493145942688\n",
      "Epoch 7, Loss: 4.4088335037231445, Final Batch Loss: 1.1004339456558228\n",
      "Epoch 8, Loss: 4.376299023628235, Final Batch Loss: 1.0981435775756836\n",
      "Epoch 9, Loss: 4.334288835525513, Final Batch Loss: 1.0759193897247314\n",
      "Epoch 10, Loss: 4.272749900817871, Final Batch Loss: 1.0467890501022339\n",
      "Epoch 11, Loss: 4.217272877693176, Final Batch Loss: 1.0496777296066284\n",
      "Epoch 12, Loss: 4.114961862564087, Final Batch Loss: 1.0096440315246582\n",
      "Epoch 13, Loss: 3.9895283579826355, Final Batch Loss: 0.9802008271217346\n",
      "Epoch 14, Loss: 3.8248255848884583, Final Batch Loss: 0.9250591397285461\n",
      "Epoch 15, Loss: 3.6219393610954285, Final Batch Loss: 0.8825532793998718\n",
      "Epoch 16, Loss: 3.3687536120414734, Final Batch Loss: 0.8081793189048767\n",
      "Epoch 17, Loss: 3.062169671058655, Final Batch Loss: 0.7443016171455383\n",
      "Epoch 18, Loss: 2.76182758808136, Final Batch Loss: 0.6629332900047302\n",
      "Epoch 19, Loss: 2.4047235250473022, Final Batch Loss: 0.589214563369751\n",
      "Epoch 20, Loss: 2.124941051006317, Final Batch Loss: 0.5247044563293457\n",
      "Epoch 21, Loss: 1.8112383782863617, Final Batch Loss: 0.4214409291744232\n",
      "Epoch 22, Loss: 1.4873598515987396, Final Batch Loss: 0.32809725403785706\n",
      "Epoch 23, Loss: 1.287430852651596, Final Batch Loss: 0.3017177879810333\n",
      "Epoch 24, Loss: 1.1192160844802856, Final Batch Loss: 0.26007556915283203\n",
      "Epoch 25, Loss: 1.0296524316072464, Final Batch Loss: 0.2835538387298584\n",
      "Epoch 26, Loss: 0.8185932040214539, Final Batch Loss: 0.1678401231765747\n",
      "Epoch 27, Loss: 0.7830313891172409, Final Batch Loss: 0.1746312528848648\n",
      "Epoch 28, Loss: 0.764322966337204, Final Batch Loss: 0.18955928087234497\n",
      "Epoch 29, Loss: 0.7036154866218567, Final Batch Loss: 0.17936955392360687\n",
      "Epoch 30, Loss: 0.6032337248325348, Final Batch Loss: 0.13262584805488586\n",
      "Epoch 31, Loss: 0.6468259394168854, Final Batch Loss: 0.21705402433872223\n",
      "Epoch 32, Loss: 0.6125994697213173, Final Batch Loss: 0.15850596129894257\n",
      "Epoch 33, Loss: 0.5828572809696198, Final Batch Loss: 0.09832791984081268\n",
      "Epoch 34, Loss: 0.510275349020958, Final Batch Loss: 0.07668035477399826\n",
      "Epoch 35, Loss: 0.5354525670409203, Final Batch Loss: 0.11312676221132278\n",
      "Epoch 36, Loss: 0.45895257592201233, Final Batch Loss: 0.11242585629224777\n",
      "Epoch 37, Loss: 0.5037587285041809, Final Batch Loss: 0.18111923336982727\n",
      "Epoch 38, Loss: 0.4382436126470566, Final Batch Loss: 0.08638119697570801\n",
      "Epoch 39, Loss: 0.48693691194057465, Final Batch Loss: 0.09727812558412552\n",
      "Epoch 40, Loss: 0.514090470969677, Final Batch Loss: 0.16369813680648804\n",
      "Epoch 41, Loss: 0.43135567754507065, Final Batch Loss: 0.0674154981970787\n",
      "Epoch 42, Loss: 0.47784119844436646, Final Batch Loss: 0.13835982978343964\n",
      "Epoch 43, Loss: 0.4137974828481674, Final Batch Loss: 0.12470615655183792\n",
      "Epoch 44, Loss: 0.36734911799430847, Final Batch Loss: 0.08788225054740906\n",
      "Epoch 45, Loss: 0.3988189697265625, Final Batch Loss: 0.06422893702983856\n",
      "Epoch 46, Loss: 0.4350742697715759, Final Batch Loss: 0.13756287097930908\n",
      "Epoch 47, Loss: 0.47550730407238007, Final Batch Loss: 0.14019650220870972\n",
      "Epoch 48, Loss: 0.37025054916739464, Final Batch Loss: 0.04868124797940254\n",
      "Epoch 49, Loss: 0.35586030036211014, Final Batch Loss: 0.08957381546497345\n",
      "Epoch 50, Loss: 0.42122112959623337, Final Batch Loss: 0.12002386152744293\n",
      "Epoch 51, Loss: 0.3886001855134964, Final Batch Loss: 0.07309690117835999\n",
      "Epoch 52, Loss: 0.38028277456760406, Final Batch Loss: 0.08028625696897507\n",
      "Epoch 53, Loss: 0.32489797100424767, Final Batch Loss: 0.07568950951099396\n",
      "Epoch 54, Loss: 0.3361554332077503, Final Batch Loss: 0.03325585648417473\n",
      "Epoch 55, Loss: 0.3810323625802994, Final Batch Loss: 0.11026021093130112\n",
      "Epoch 56, Loss: 0.3649759776890278, Final Batch Loss: 0.10083270817995071\n",
      "Epoch 57, Loss: 0.35562578216195107, Final Batch Loss: 0.1364605575799942\n",
      "Epoch 58, Loss: 0.37550482898950577, Final Batch Loss: 0.103175088763237\n",
      "Epoch 59, Loss: 0.34905510395765305, Final Batch Loss: 0.05769763141870499\n",
      "Epoch 60, Loss: 0.3633738085627556, Final Batch Loss: 0.0891452431678772\n",
      "Epoch 61, Loss: 0.37788810580968857, Final Batch Loss: 0.07926540821790695\n",
      "Epoch 62, Loss: 0.37087482213974, Final Batch Loss: 0.1009669378399849\n",
      "Epoch 63, Loss: 0.3585672378540039, Final Batch Loss: 0.09574815630912781\n",
      "Epoch 64, Loss: 0.3257729634642601, Final Batch Loss: 0.09810040891170502\n",
      "Epoch 65, Loss: 0.31481291726231575, Final Batch Loss: 0.038715507835149765\n",
      "Epoch 66, Loss: 0.3613981828093529, Final Batch Loss: 0.07093015313148499\n",
      "Epoch 67, Loss: 0.26622777059674263, Final Batch Loss: 0.06109942868351936\n",
      "Epoch 68, Loss: 0.3231189548969269, Final Batch Loss: 0.06449757516384125\n",
      "Epoch 69, Loss: 0.30774158611893654, Final Batch Loss: 0.05297084525227547\n",
      "Epoch 70, Loss: 0.3348827324807644, Final Batch Loss: 0.1162320151925087\n",
      "Epoch 71, Loss: 0.2873089388012886, Final Batch Loss: 0.08723268657922745\n",
      "Epoch 72, Loss: 0.28767772018909454, Final Batch Loss: 0.09152638912200928\n",
      "Epoch 73, Loss: 0.33071261644363403, Final Batch Loss: 0.08772953599691391\n",
      "Epoch 74, Loss: 0.2918078899383545, Final Batch Loss: 0.0605178102850914\n",
      "Epoch 75, Loss: 0.3602044805884361, Final Batch Loss: 0.06651802361011505\n",
      "Epoch 76, Loss: 0.3254731446504593, Final Batch Loss: 0.12721581757068634\n",
      "Epoch 77, Loss: 0.34755588322877884, Final Batch Loss: 0.1320413202047348\n",
      "Epoch 78, Loss: 0.3456786051392555, Final Batch Loss: 0.09671171754598618\n",
      "Epoch 79, Loss: 0.28912436962127686, Final Batch Loss: 0.06603362411260605\n",
      "Epoch 80, Loss: 0.2958635948598385, Final Batch Loss: 0.09101615846157074\n",
      "Epoch 81, Loss: 0.2972109988331795, Final Batch Loss: 0.06377923488616943\n",
      "Epoch 82, Loss: 0.30946045368909836, Final Batch Loss: 0.03657720983028412\n",
      "Epoch 83, Loss: 0.2580352798104286, Final Batch Loss: 0.07998437434434891\n",
      "Epoch 84, Loss: 0.31724361702799797, Final Batch Loss: 0.06973710656166077\n",
      "Epoch 85, Loss: 0.26483020186424255, Final Batch Loss: 0.020901530981063843\n",
      "Epoch 86, Loss: 0.2515097074210644, Final Batch Loss: 0.03487163037061691\n",
      "Epoch 87, Loss: 0.25044289976358414, Final Batch Loss: 0.07846307754516602\n",
      "Epoch 88, Loss: 0.296465165913105, Final Batch Loss: 0.11422700434923172\n",
      "Epoch 89, Loss: 0.2745125778019428, Final Batch Loss: 0.08698660135269165\n",
      "Epoch 90, Loss: 0.2363976091146469, Final Batch Loss: 0.027906637638807297\n",
      "Epoch 91, Loss: 0.2749211862683296, Final Batch Loss: 0.06598228216171265\n",
      "Epoch 92, Loss: 0.2310224175453186, Final Batch Loss: 0.06152596324682236\n",
      "Epoch 93, Loss: 0.2538580223917961, Final Batch Loss: 0.04977237805724144\n",
      "Epoch 94, Loss: 0.23059682920575142, Final Batch Loss: 0.044188883155584335\n",
      "Epoch 95, Loss: 0.24925203621387482, Final Batch Loss: 0.0933455154299736\n",
      "Epoch 96, Loss: 0.26354575902223587, Final Batch Loss: 0.07110939174890518\n",
      "Epoch 97, Loss: 0.25775567814707756, Final Batch Loss: 0.04328771308064461\n",
      "Epoch 98, Loss: 0.2722640372812748, Final Batch Loss: 0.06819421797990799\n",
      "Epoch 99, Loss: 0.25037164054811, Final Batch Loss: 0.08184215426445007\n",
      "Epoch 100, Loss: 0.24911332875490189, Final Batch Loss: 0.05018351972103119\n",
      "Epoch 101, Loss: 0.23822508193552494, Final Batch Loss: 0.045051779597997665\n",
      "Epoch 102, Loss: 0.26834849640727043, Final Batch Loss: 0.03419089317321777\n",
      "Epoch 103, Loss: 0.250921081751585, Final Batch Loss: 0.06215948238968849\n",
      "Epoch 104, Loss: 0.23073025047779083, Final Batch Loss: 0.08201812207698822\n",
      "Epoch 105, Loss: 0.20573434606194496, Final Batch Loss: 0.04038749262690544\n",
      "Epoch 106, Loss: 0.22143226489424706, Final Batch Loss: 0.020551569759845734\n",
      "Epoch 107, Loss: 0.21933029778301716, Final Batch Loss: 0.053966738283634186\n",
      "Epoch 108, Loss: 0.22936490550637245, Final Batch Loss: 0.06786482036113739\n",
      "Epoch 109, Loss: 0.21313558891415596, Final Batch Loss: 0.04194528982043266\n",
      "Epoch 110, Loss: 0.23216449469327927, Final Batch Loss: 0.020461909472942352\n",
      "Epoch 111, Loss: 0.2284817397594452, Final Batch Loss: 0.05532322824001312\n",
      "Epoch 112, Loss: 0.23646213114261627, Final Batch Loss: 0.0992133766412735\n",
      "Epoch 113, Loss: 0.19247161224484444, Final Batch Loss: 0.03738749772310257\n",
      "Epoch 114, Loss: 0.20953389629721642, Final Batch Loss: 0.05574391409754753\n",
      "Epoch 115, Loss: 0.2203060034662485, Final Batch Loss: 0.05067608505487442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116, Loss: 0.21896670758724213, Final Batch Loss: 0.09374352544546127\n",
      "Epoch 117, Loss: 0.18558645620942116, Final Batch Loss: 0.02377527579665184\n",
      "Epoch 118, Loss: 0.2137792930006981, Final Batch Loss: 0.061128731817007065\n",
      "Epoch 119, Loss: 0.18222667649388313, Final Batch Loss: 0.01988399401307106\n",
      "Epoch 120, Loss: 0.18868771754205227, Final Batch Loss: 0.044558677822351456\n",
      "Epoch 121, Loss: 0.2400779239833355, Final Batch Loss: 0.03909701108932495\n",
      "Epoch 122, Loss: 0.2212142813950777, Final Batch Loss: 0.06717634201049805\n",
      "Epoch 123, Loss: 0.2282230593264103, Final Batch Loss: 0.07736064493656158\n",
      "Epoch 124, Loss: 0.1875443309545517, Final Batch Loss: 0.0321127250790596\n",
      "Epoch 125, Loss: 0.20529186725616455, Final Batch Loss: 0.029057040810585022\n",
      "Epoch 126, Loss: 0.25036250054836273, Final Batch Loss: 0.07990387082099915\n",
      "Epoch 127, Loss: 0.2360910400748253, Final Batch Loss: 0.12948091328144073\n",
      "Epoch 128, Loss: 0.22851430252194405, Final Batch Loss: 0.08107877522706985\n",
      "Epoch 129, Loss: 0.21175426244735718, Final Batch Loss: 0.0437592938542366\n",
      "Epoch 130, Loss: 0.1959402672946453, Final Batch Loss: 0.05561031028628349\n",
      "Epoch 131, Loss: 0.17638182267546654, Final Batch Loss: 0.047551143914461136\n",
      "Epoch 132, Loss: 0.20397217199206352, Final Batch Loss: 0.043461523950099945\n",
      "Epoch 133, Loss: 0.22173884138464928, Final Batch Loss: 0.03890702500939369\n",
      "Epoch 134, Loss: 0.22540725581347942, Final Batch Loss: 0.08914989233016968\n",
      "Epoch 135, Loss: 0.20519345998764038, Final Batch Loss: 0.058505795896053314\n",
      "Epoch 136, Loss: 0.2075928896665573, Final Batch Loss: 0.05078770965337753\n",
      "Epoch 137, Loss: 0.19687747955322266, Final Batch Loss: 0.058769769966602325\n",
      "Epoch 138, Loss: 0.20291701704263687, Final Batch Loss: 0.03566495701670647\n",
      "Epoch 139, Loss: 0.19223254546523094, Final Batch Loss: 0.05121706798672676\n",
      "Epoch 140, Loss: 0.2060941606760025, Final Batch Loss: 0.09183119982481003\n",
      "Epoch 141, Loss: 0.16346296109259129, Final Batch Loss: 0.027248550206422806\n",
      "Epoch 142, Loss: 0.15858343616127968, Final Batch Loss: 0.0384182408452034\n",
      "Epoch 143, Loss: 0.20990730822086334, Final Batch Loss: 0.06013816222548485\n",
      "Epoch 144, Loss: 0.20668882690370083, Final Batch Loss: 0.014975856989622116\n",
      "Epoch 145, Loss: 0.17720544897019863, Final Batch Loss: 0.020447181537747383\n",
      "Epoch 146, Loss: 0.18422432988882065, Final Batch Loss: 0.03959827870130539\n",
      "Epoch 147, Loss: 0.15931264497339725, Final Batch Loss: 0.02319960482418537\n",
      "Epoch 148, Loss: 0.14622612856328487, Final Batch Loss: 0.025199400261044502\n",
      "Epoch 149, Loss: 0.18181965872645378, Final Batch Loss: 0.05165030062198639\n",
      "Epoch 150, Loss: 0.15378937683999538, Final Batch Loss: 0.03332669660449028\n",
      "Epoch 151, Loss: 0.19137267768383026, Final Batch Loss: 0.04400428384542465\n",
      "Epoch 152, Loss: 0.15885844454169273, Final Batch Loss: 0.06298433989286423\n",
      "Epoch 153, Loss: 0.1481376253068447, Final Batch Loss: 0.028823446482419968\n",
      "Epoch 154, Loss: 0.18311425298452377, Final Batch Loss: 0.024851500988006592\n",
      "Epoch 155, Loss: 0.1846366971731186, Final Batch Loss: 0.029824353754520416\n",
      "Epoch 156, Loss: 0.1449878141283989, Final Batch Loss: 0.026186225935816765\n",
      "Epoch 157, Loss: 0.17801869474351406, Final Batch Loss: 0.023238593712449074\n",
      "Epoch 158, Loss: 0.15708919428288937, Final Batch Loss: 0.022894421592354774\n",
      "Epoch 159, Loss: 0.15853138267993927, Final Batch Loss: 0.04804963245987892\n",
      "Epoch 160, Loss: 0.15851061791181564, Final Batch Loss: 0.05808408930897713\n",
      "Epoch 161, Loss: 0.1588154286146164, Final Batch Loss: 0.050741493701934814\n",
      "Epoch 162, Loss: 0.1758692655712366, Final Batch Loss: 0.04148464277386665\n",
      "Epoch 163, Loss: 0.1846124529838562, Final Batch Loss: 0.0618269219994545\n",
      "Epoch 164, Loss: 0.13570506498217583, Final Batch Loss: 0.02292698249220848\n",
      "Epoch 165, Loss: 0.17690863087773323, Final Batch Loss: 0.07587981224060059\n",
      "Epoch 166, Loss: 0.12969162315130234, Final Batch Loss: 0.037665870040655136\n",
      "Epoch 167, Loss: 0.13594687171280384, Final Batch Loss: 0.0403931699693203\n",
      "Epoch 168, Loss: 0.1489729806780815, Final Batch Loss: 0.03296132758259773\n",
      "Epoch 169, Loss: 0.1541683878749609, Final Batch Loss: 0.048353906720876694\n",
      "Epoch 170, Loss: 0.13384196255356073, Final Batch Loss: 0.015572416596114635\n",
      "Epoch 171, Loss: 0.15967068821191788, Final Batch Loss: 0.01259429007768631\n",
      "Epoch 172, Loss: 0.16756081487983465, Final Batch Loss: 0.06269773840904236\n",
      "Epoch 173, Loss: 0.1517670378088951, Final Batch Loss: 0.04781335964798927\n",
      "Epoch 174, Loss: 0.11855417117476463, Final Batch Loss: 0.013853462412953377\n",
      "Epoch 175, Loss: 0.12484771013259888, Final Batch Loss: 0.021844809874892235\n",
      "Epoch 176, Loss: 0.13650962337851524, Final Batch Loss: 0.020439263433218002\n",
      "Epoch 177, Loss: 0.14324811100959778, Final Batch Loss: 0.041005633771419525\n",
      "Epoch 178, Loss: 0.14925171434879303, Final Batch Loss: 0.03338327631354332\n",
      "Epoch 179, Loss: 0.1420596018433571, Final Batch Loss: 0.03514567390084267\n",
      "Epoch 180, Loss: 0.13530348800122738, Final Batch Loss: 0.05883067101240158\n",
      "Epoch 181, Loss: 0.12340485956519842, Final Batch Loss: 0.0387367382645607\n",
      "Epoch 182, Loss: 0.13619566708803177, Final Batch Loss: 0.0409737303853035\n",
      "Epoch 183, Loss: 0.08708067797124386, Final Batch Loss: 0.018744224682450294\n",
      "Epoch 184, Loss: 0.12810704950243235, Final Batch Loss: 0.01262305211275816\n",
      "Epoch 185, Loss: 0.11543123982846737, Final Batch Loss: 0.021490611135959625\n",
      "Epoch 186, Loss: 0.15289950743317604, Final Batch Loss: 0.026011113077402115\n",
      "Epoch 187, Loss: 0.1093344260007143, Final Batch Loss: 0.03256306052207947\n",
      "Epoch 188, Loss: 0.11183416750282049, Final Batch Loss: 0.023364730179309845\n",
      "Epoch 189, Loss: 0.11848048865795135, Final Batch Loss: 0.0417361818253994\n",
      "Epoch 190, Loss: 0.11454662587493658, Final Batch Loss: 0.03798936679959297\n",
      "Epoch 191, Loss: 0.12767666578292847, Final Batch Loss: 0.024836335331201553\n",
      "Epoch 192, Loss: 0.105983205139637, Final Batch Loss: 0.029830751940608025\n",
      "Epoch 193, Loss: 0.10832554567605257, Final Batch Loss: 0.030825182795524597\n",
      "Epoch 194, Loss: 0.13555757328867912, Final Batch Loss: 0.041048724204301834\n",
      "Epoch 195, Loss: 0.10452177189290524, Final Batch Loss: 0.014560671523213387\n",
      "Epoch 196, Loss: 0.13428411819040775, Final Batch Loss: 0.020922044292092323\n",
      "Epoch 197, Loss: 0.1362184714525938, Final Batch Loss: 0.046000611037015915\n",
      "Epoch 198, Loss: 0.11912471149116755, Final Batch Loss: 0.02636081911623478\n",
      "Epoch 199, Loss: 0.12186858430504799, Final Batch Loss: 0.02952997200191021\n",
      "Epoch 200, Loss: 0.11465881206095219, Final Batch Loss: 0.0414624884724617\n",
      "Epoch 201, Loss: 0.1605708785355091, Final Batch Loss: 0.05343776196241379\n",
      "Epoch 202, Loss: 0.09946374967694283, Final Batch Loss: 0.028840605169534683\n",
      "Epoch 203, Loss: 0.0780457966029644, Final Batch Loss: 0.013572031632065773\n",
      "Epoch 204, Loss: 0.08050455991178751, Final Batch Loss: 0.03275703266263008\n",
      "Epoch 205, Loss: 0.10864344332367182, Final Batch Loss: 0.03936326503753662\n",
      "Epoch 206, Loss: 0.09027077723294497, Final Batch Loss: 0.026590919122099876\n",
      "Epoch 207, Loss: 0.08810281846672297, Final Batch Loss: 0.034041713923215866\n",
      "Epoch 208, Loss: 0.09469620045274496, Final Batch Loss: 0.010854951106011868\n",
      "Epoch 209, Loss: 0.11302329506725073, Final Batch Loss: 0.05874643847346306\n",
      "Epoch 210, Loss: 0.055316606536507607, Final Batch Loss: 0.004399166442453861\n",
      "Epoch 211, Loss: 0.1115754097700119, Final Batch Loss: 0.041991978883743286\n",
      "Epoch 212, Loss: 0.09299673605710268, Final Batch Loss: 0.021816203370690346\n",
      "Epoch 213, Loss: 0.11751067452132702, Final Batch Loss: 0.03260422125458717\n",
      "Epoch 214, Loss: 0.07661164458841085, Final Batch Loss: 0.02554033324122429\n",
      "Epoch 215, Loss: 0.09494331385940313, Final Batch Loss: 0.012596551328897476\n",
      "Epoch 216, Loss: 0.09346607513725758, Final Batch Loss: 0.03007693402469158\n",
      "Epoch 217, Loss: 0.07342410460114479, Final Batch Loss: 0.01951330341398716\n",
      "Epoch 218, Loss: 0.09242098685353994, Final Batch Loss: 0.017719553783535957\n",
      "Epoch 219, Loss: 0.0885351411998272, Final Batch Loss: 0.01822001300752163\n",
      "Epoch 220, Loss: 0.11920815706253052, Final Batch Loss: 0.028287282213568687\n",
      "Epoch 221, Loss: 0.10146990418434143, Final Batch Loss: 0.02744828164577484\n",
      "Epoch 222, Loss: 0.09948695823550224, Final Batch Loss: 0.024562513455748558\n",
      "Epoch 223, Loss: 0.08659355249255896, Final Batch Loss: 0.02641116827726364\n",
      "Epoch 224, Loss: 0.10494257882237434, Final Batch Loss: 0.03437397629022598\n",
      "Epoch 225, Loss: 0.08103479957208037, Final Batch Loss: 0.03837965428829193\n",
      "Epoch 226, Loss: 0.13648641668260098, Final Batch Loss: 0.037809062749147415\n",
      "Epoch 227, Loss: 0.09900528751313686, Final Batch Loss: 0.050064291805028915\n",
      "Epoch 228, Loss: 0.11599258705973625, Final Batch Loss: 0.026463916525244713\n",
      "Epoch 229, Loss: 0.09439610317349434, Final Batch Loss: 0.029262050986289978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230, Loss: 0.09022623393684626, Final Batch Loss: 0.01671525090932846\n",
      "Epoch 231, Loss: 0.07395067438483238, Final Batch Loss: 0.019060838967561722\n",
      "Epoch 232, Loss: 0.0690472424030304, Final Batch Loss: 0.009407714009284973\n",
      "Epoch 233, Loss: 0.07237404817715287, Final Batch Loss: 0.016835330054163933\n",
      "Epoch 234, Loss: 0.05852318415418267, Final Batch Loss: 0.011278713122010231\n",
      "Epoch 235, Loss: 0.09057104960083961, Final Batch Loss: 0.02628057822585106\n",
      "Epoch 236, Loss: 0.1007166150957346, Final Batch Loss: 0.05145980417728424\n",
      "Epoch 237, Loss: 0.07307244092226028, Final Batch Loss: 0.015547549352049828\n",
      "Epoch 238, Loss: 0.09572455938905478, Final Batch Loss: 0.010921912267804146\n",
      "Epoch 239, Loss: 0.08140474837273359, Final Batch Loss: 0.03340332955121994\n",
      "Epoch 240, Loss: 0.06760546937584877, Final Batch Loss: 0.008517468348145485\n",
      "Epoch 241, Loss: 0.06394462287425995, Final Batch Loss: 0.014065687544643879\n",
      "Epoch 242, Loss: 0.08335690572857857, Final Batch Loss: 0.015395269729197025\n",
      "Epoch 243, Loss: 0.08513800799846649, Final Batch Loss: 0.027283374220132828\n",
      "Epoch 244, Loss: 0.09052459429949522, Final Batch Loss: 0.03712146356701851\n",
      "Epoch 245, Loss: 0.10369277466088533, Final Batch Loss: 0.0504937469959259\n",
      "Epoch 246, Loss: 0.07707476057112217, Final Batch Loss: 0.011167819611728191\n",
      "Epoch 247, Loss: 0.07979580434039235, Final Batch Loss: 0.022592410445213318\n",
      "Epoch 248, Loss: 0.08597798319533467, Final Batch Loss: 0.033027857542037964\n",
      "Epoch 249, Loss: 0.09071828238666058, Final Batch Loss: 0.013496843166649342\n",
      "Epoch 250, Loss: 0.07012636959552765, Final Batch Loss: 0.03728148713707924\n",
      "Epoch 251, Loss: 0.057070400565862656, Final Batch Loss: 0.014802585355937481\n",
      "Epoch 252, Loss: 0.09068320598453283, Final Batch Loss: 0.009698288515210152\n",
      "Epoch 253, Loss: 0.09085183637216687, Final Batch Loss: 0.011011033318936825\n",
      "Epoch 254, Loss: 0.10059609822928905, Final Batch Loss: 0.023368699476122856\n",
      "Epoch 255, Loss: 0.08762708585709333, Final Batch Loss: 0.006419726647436619\n",
      "Epoch 256, Loss: 0.05479944217950106, Final Batch Loss: 0.006620028987526894\n",
      "Epoch 257, Loss: 0.05457139294594526, Final Batch Loss: 0.013537502847611904\n",
      "Epoch 258, Loss: 0.05746316257864237, Final Batch Loss: 0.009830488823354244\n",
      "Epoch 259, Loss: 0.07005214411765337, Final Batch Loss: 0.009600824676454067\n",
      "Epoch 260, Loss: 0.1150595499202609, Final Batch Loss: 0.012194269336760044\n",
      "Epoch 261, Loss: 0.06456134747713804, Final Batch Loss: 0.01213911734521389\n",
      "Epoch 262, Loss: 0.10073930583894253, Final Batch Loss: 0.03392288088798523\n",
      "Epoch 263, Loss: 0.049303432926535606, Final Batch Loss: 0.008135641925036907\n",
      "Epoch 264, Loss: 0.09113895893096924, Final Batch Loss: 0.010041612200438976\n",
      "Epoch 265, Loss: 0.10168378334492445, Final Batch Loss: 0.045390814542770386\n",
      "Epoch 266, Loss: 0.0520114884711802, Final Batch Loss: 0.029874950647354126\n",
      "Epoch 267, Loss: 0.06358670815825462, Final Batch Loss: 0.019442906603217125\n",
      "Epoch 268, Loss: 0.0673666619695723, Final Batch Loss: 0.009687311947345734\n",
      "Epoch 269, Loss: 0.05399447330273688, Final Batch Loss: 0.026367027312517166\n",
      "Epoch 270, Loss: 0.05818637181073427, Final Batch Loss: 0.031029928475618362\n",
      "Epoch 271, Loss: 0.07458308897912502, Final Batch Loss: 0.012662851251661777\n",
      "Epoch 272, Loss: 0.08034986490383744, Final Batch Loss: 0.004408899694681168\n",
      "Epoch 273, Loss: 0.06743053160607815, Final Batch Loss: 0.006040756590664387\n",
      "Epoch 274, Loss: 0.039180314633995295, Final Batch Loss: 0.004957391414791346\n",
      "Epoch 275, Loss: 0.06325201503932476, Final Batch Loss: 0.016392435878515244\n",
      "Epoch 276, Loss: 0.04976562550291419, Final Batch Loss: 0.007431017234921455\n",
      "Epoch 277, Loss: 0.05322495009750128, Final Batch Loss: 0.02360137738287449\n",
      "Epoch 278, Loss: 0.03533766698092222, Final Batch Loss: 0.013536186888813972\n",
      "Epoch 279, Loss: 0.03743777656927705, Final Batch Loss: 0.004503100179135799\n",
      "Epoch 280, Loss: 0.08178482856601477, Final Batch Loss: 0.02769465744495392\n",
      "Epoch 281, Loss: 0.056863585487008095, Final Batch Loss: 0.004570541437715292\n",
      "Epoch 282, Loss: 0.0716853472404182, Final Batch Loss: 0.03545677661895752\n",
      "Epoch 283, Loss: 0.07839341182261705, Final Batch Loss: 0.011443857103586197\n",
      "Epoch 284, Loss: 0.04304203297942877, Final Batch Loss: 0.010552585124969482\n",
      "Epoch 285, Loss: 0.05882810242474079, Final Batch Loss: 0.018755899742245674\n",
      "Epoch 286, Loss: 0.04698196053504944, Final Batch Loss: 0.005072609521448612\n",
      "Epoch 287, Loss: 0.07468000706285238, Final Batch Loss: 0.041606903076171875\n",
      "Epoch 288, Loss: 0.05785016855224967, Final Batch Loss: 0.006392171140760183\n",
      "Epoch 289, Loss: 0.11754065286368132, Final Batch Loss: 0.06633225828409195\n",
      "Epoch 290, Loss: 0.060065947473049164, Final Batch Loss: 0.008769643492996693\n",
      "Epoch 291, Loss: 0.051089916843920946, Final Batch Loss: 0.004771084524691105\n",
      "Epoch 292, Loss: 0.05010752845555544, Final Batch Loss: 0.005770818330347538\n",
      "Epoch 293, Loss: 0.04654709552414715, Final Batch Loss: 0.0025400782469660044\n",
      "Epoch 294, Loss: 0.07912653824314475, Final Batch Loss: 0.005546178203076124\n",
      "Epoch 295, Loss: 0.0641219113022089, Final Batch Loss: 0.014224052429199219\n",
      "Epoch 296, Loss: 0.10030774865299463, Final Batch Loss: 0.007382066920399666\n",
      "Epoch 297, Loss: 0.04506776574999094, Final Batch Loss: 0.01932598650455475\n",
      "Epoch 298, Loss: 0.058711939956992865, Final Batch Loss: 0.012519665993750095\n",
      "Epoch 299, Loss: 0.08913357276469469, Final Batch Loss: 0.018973002210259438\n",
      "Epoch 300, Loss: 0.06158658675849438, Final Batch Loss: 0.005701893009245396\n",
      "Epoch 301, Loss: 0.06525615975260735, Final Batch Loss: 0.010431305505335331\n",
      "Epoch 302, Loss: 0.08753460738807917, Final Batch Loss: 0.03384687379002571\n",
      "Epoch 303, Loss: 0.057819906156510115, Final Batch Loss: 0.022762509062886238\n",
      "Epoch 304, Loss: 0.08427247125655413, Final Batch Loss: 0.03277061507105827\n",
      "Epoch 305, Loss: 0.02987883845344186, Final Batch Loss: 0.007889073342084885\n",
      "Epoch 306, Loss: 0.0646290578879416, Final Batch Loss: 0.02575003355741501\n",
      "Epoch 307, Loss: 0.05651661101728678, Final Batch Loss: 0.009500456042587757\n",
      "Epoch 308, Loss: 0.059454796370118856, Final Batch Loss: 0.006201085168868303\n",
      "Epoch 309, Loss: 0.053800822934135795, Final Batch Loss: 0.01983283832669258\n",
      "Epoch 310, Loss: 0.040208063554018736, Final Batch Loss: 0.007489935960620642\n",
      "Epoch 311, Loss: 0.05050876107998192, Final Batch Loss: 0.00545160798355937\n",
      "Epoch 312, Loss: 0.058587232138961554, Final Batch Loss: 0.0067497603595256805\n",
      "Epoch 313, Loss: 0.06884864997118711, Final Batch Loss: 0.010388188064098358\n",
      "Epoch 314, Loss: 0.09067410230636597, Final Batch Loss: 0.020856153219938278\n",
      "Epoch 315, Loss: 0.040727871702983975, Final Batch Loss: 0.0054163564927875996\n",
      "Epoch 316, Loss: 0.08734774077311158, Final Batch Loss: 0.016576893627643585\n",
      "Epoch 317, Loss: 0.0722861303947866, Final Batch Loss: 0.022993095219135284\n",
      "Epoch 318, Loss: 0.028262421488761902, Final Batch Loss: 0.0034367162734270096\n",
      "Epoch 319, Loss: 0.04786677239462733, Final Batch Loss: 0.00930135790258646\n",
      "Epoch 320, Loss: 0.08275509579107165, Final Batch Loss: 0.007977478206157684\n",
      "Epoch 321, Loss: 0.06621921807527542, Final Batch Loss: 0.009381052106618881\n",
      "Epoch 322, Loss: 0.046654950361698866, Final Batch Loss: 0.0061028082855045795\n",
      "Epoch 323, Loss: 0.03175382502377033, Final Batch Loss: 0.0032913824543356895\n",
      "Epoch 324, Loss: 0.04989878926426172, Final Batch Loss: 0.01907685585319996\n",
      "Epoch 325, Loss: 0.07859920850023627, Final Batch Loss: 0.0535568930208683\n",
      "Epoch 326, Loss: 0.043231633491814137, Final Batch Loss: 0.009212040342390537\n",
      "Epoch 327, Loss: 0.03899035044014454, Final Batch Loss: 0.009788436815142632\n",
      "Epoch 328, Loss: 0.03268249938264489, Final Batch Loss: 0.004570554476231337\n",
      "Epoch 329, Loss: 0.05973328463733196, Final Batch Loss: 0.010873420163989067\n",
      "Epoch 330, Loss: 0.07622194243595004, Final Batch Loss: 0.03768058866262436\n",
      "Epoch 331, Loss: 0.038500349037349224, Final Batch Loss: 0.005677761510014534\n",
      "Epoch 332, Loss: 0.05766092333942652, Final Batch Loss: 0.024786219000816345\n",
      "Epoch 333, Loss: 0.05381024908274412, Final Batch Loss: 0.012062427587807178\n",
      "Epoch 334, Loss: 0.04281067242845893, Final Batch Loss: 0.00767803518101573\n",
      "Epoch 335, Loss: 0.03850902896374464, Final Batch Loss: 0.0032200217247009277\n",
      "Epoch 336, Loss: 0.033508815336972475, Final Batch Loss: 0.00396985188126564\n",
      "Epoch 337, Loss: 0.05721604358404875, Final Batch Loss: 0.011717221699655056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338, Loss: 0.03051302465610206, Final Batch Loss: 0.013839521445333958\n",
      "Epoch 339, Loss: 0.04721287405118346, Final Batch Loss: 0.00479637598618865\n",
      "Epoch 340, Loss: 0.04432735778391361, Final Batch Loss: 0.00864405743777752\n",
      "Epoch 341, Loss: 0.06886004377156496, Final Batch Loss: 0.008638282306492329\n",
      "Epoch 342, Loss: 0.0380384111776948, Final Batch Loss: 0.0013469390105456114\n",
      "Epoch 343, Loss: 0.038882755441591144, Final Batch Loss: 0.011708121746778488\n",
      "Epoch 344, Loss: 0.046639314852654934, Final Batch Loss: 0.023503201082348824\n",
      "Epoch 345, Loss: 0.025595281971618533, Final Batch Loss: 0.0016793045215308666\n",
      "Epoch 346, Loss: 0.042345326161012053, Final Batch Loss: 0.008040592074394226\n",
      "Epoch 347, Loss: 0.020454293116927147, Final Batch Loss: 0.0033224294893443584\n",
      "Epoch 348, Loss: 0.04653412289917469, Final Batch Loss: 0.009310765191912651\n",
      "Epoch 349, Loss: 0.032854844350367785, Final Batch Loss: 0.006392322946339846\n",
      "Epoch 350, Loss: 0.04981443239375949, Final Batch Loss: 0.002559471409767866\n",
      "Epoch 351, Loss: 0.07501680217683315, Final Batch Loss: 0.014274765737354755\n",
      "Epoch 352, Loss: 0.03830623137764633, Final Batch Loss: 0.017274284735322\n",
      "Epoch 353, Loss: 0.03709696023724973, Final Batch Loss: 0.007154006045311689\n",
      "Epoch 354, Loss: 0.06309008598327637, Final Batch Loss: 0.002691815607249737\n",
      "Epoch 355, Loss: 0.05464646336622536, Final Batch Loss: 0.005060253664851189\n",
      "Epoch 356, Loss: 0.06084472453221679, Final Batch Loss: 0.017571786418557167\n",
      "Epoch 357, Loss: 0.024479836225509644, Final Batch Loss: 0.005121349357068539\n",
      "Epoch 358, Loss: 0.04627144243568182, Final Batch Loss: 0.011124465614557266\n",
      "Epoch 359, Loss: 0.026092593790963292, Final Batch Loss: 0.006177375093102455\n",
      "Epoch 360, Loss: 0.042726179119199514, Final Batch Loss: 0.020055273547768593\n",
      "Epoch 361, Loss: 0.03907182812690735, Final Batch Loss: 0.004065182991325855\n",
      "Epoch 362, Loss: 0.028181901201605797, Final Batch Loss: 0.004102037753909826\n",
      "Epoch 363, Loss: 0.028425076510757208, Final Batch Loss: 0.006750341970473528\n",
      "Epoch 364, Loss: 0.0767179960384965, Final Batch Loss: 0.03036322444677353\n",
      "Epoch 365, Loss: 0.057616822654381394, Final Batch Loss: 0.002992268418893218\n",
      "Epoch 366, Loss: 0.020418575732037425, Final Batch Loss: 0.008162685669958591\n",
      "Epoch 367, Loss: 0.035907980520278215, Final Batch Loss: 0.012068604119122028\n",
      "Epoch 368, Loss: 0.04054498975165188, Final Batch Loss: 0.024266153573989868\n",
      "Epoch 369, Loss: 0.04158536158502102, Final Batch Loss: 0.008625226095318794\n",
      "Epoch 370, Loss: 0.040211062412709, Final Batch Loss: 0.01425105519592762\n",
      "Epoch 371, Loss: 0.05060632945969701, Final Batch Loss: 0.004388406872749329\n",
      "Epoch 372, Loss: 0.03902582521550357, Final Batch Loss: 0.021560320630669594\n",
      "Epoch 373, Loss: 0.04361509811133146, Final Batch Loss: 0.002714775502681732\n",
      "Epoch 374, Loss: 0.040408934000879526, Final Batch Loss: 0.010651009157299995\n",
      "Epoch 375, Loss: 0.04716989491134882, Final Batch Loss: 0.0035415831953287125\n",
      "Epoch 376, Loss: 0.020273108035326004, Final Batch Loss: 0.005164158996194601\n",
      "Epoch 377, Loss: 0.0630142129957676, Final Batch Loss: 0.006579820066690445\n",
      "Epoch 378, Loss: 0.028172536985948682, Final Batch Loss: 0.002097195712849498\n",
      "Epoch 379, Loss: 0.04329537437297404, Final Batch Loss: 0.014365793205797672\n",
      "Epoch 380, Loss: 0.033573244349099696, Final Batch Loss: 0.0016210755566135049\n",
      "Epoch 381, Loss: 0.039932069601491094, Final Batch Loss: 0.0027321914676576853\n",
      "Epoch 382, Loss: 0.03062342875637114, Final Batch Loss: 0.0018779193051159382\n",
      "Epoch 383, Loss: 0.030053875409066677, Final Batch Loss: 0.001984822563827038\n",
      "Epoch 384, Loss: 0.061259442241862416, Final Batch Loss: 0.0037195447366684675\n",
      "Epoch 385, Loss: 0.03046541614457965, Final Batch Loss: 0.008035639300942421\n",
      "Epoch 386, Loss: 0.04107665456831455, Final Batch Loss: 0.012089560739696026\n",
      "Epoch 387, Loss: 0.03966312436386943, Final Batch Loss: 0.0026775668375194073\n",
      "Epoch 388, Loss: 0.02170976367779076, Final Batch Loss: 0.012751628644764423\n",
      "Epoch 389, Loss: 0.06642760382965207, Final Batch Loss: 0.021110774949193\n",
      "Epoch 390, Loss: 0.03734828042797744, Final Batch Loss: 0.024910474196076393\n",
      "Epoch 391, Loss: 0.03966078464873135, Final Batch Loss: 0.010829849168658257\n",
      "Epoch 392, Loss: 0.03932971484027803, Final Batch Loss: 0.0012848770711570978\n",
      "Epoch 393, Loss: 0.04601458786055446, Final Batch Loss: 0.022744763642549515\n",
      "Epoch 394, Loss: 0.0234293065732345, Final Batch Loss: 0.0013500008499249816\n",
      "Epoch 395, Loss: 0.024483437882736325, Final Batch Loss: 0.003290861612185836\n",
      "Epoch 396, Loss: 0.031044272938743234, Final Batch Loss: 0.004016910679638386\n",
      "Epoch 397, Loss: 0.01761155901476741, Final Batch Loss: 0.004165593534708023\n",
      "Epoch 398, Loss: 0.025508926366455853, Final Batch Loss: 0.0017679721349850297\n",
      "Epoch 399, Loss: 0.0342013374902308, Final Batch Loss: 0.007705433759838343\n",
      "Epoch 400, Loss: 0.03941552247852087, Final Batch Loss: 0.005686859600245953\n",
      "Epoch 401, Loss: 0.038036872167140245, Final Batch Loss: 0.025350363925099373\n",
      "Epoch 402, Loss: 0.03661564295180142, Final Batch Loss: 0.0025710146874189377\n",
      "Epoch 403, Loss: 0.052723702508956194, Final Batch Loss: 0.023769430816173553\n",
      "Epoch 404, Loss: 0.013411996071226895, Final Batch Loss: 0.001479263766668737\n",
      "Epoch 405, Loss: 0.025276532396674156, Final Batch Loss: 0.017360437661409378\n",
      "Epoch 406, Loss: 0.04174289805814624, Final Batch Loss: 0.005118632223457098\n",
      "Epoch 407, Loss: 0.031590773025527596, Final Batch Loss: 0.0022146953269839287\n",
      "Epoch 408, Loss: 0.031230053398758173, Final Batch Loss: 0.005742125678807497\n",
      "Epoch 409, Loss: 0.01651262608356774, Final Batch Loss: 0.0025012418627738953\n",
      "Epoch 410, Loss: 0.03680751635693014, Final Batch Loss: 0.00257661915384233\n",
      "Epoch 411, Loss: 0.0782092185690999, Final Batch Loss: 0.02620837464928627\n",
      "Epoch 412, Loss: 0.0239965938962996, Final Batch Loss: 0.0036814850755035877\n",
      "Epoch 413, Loss: 0.05362505407538265, Final Batch Loss: 0.0019397364230826497\n",
      "Epoch 414, Loss: 0.028407816076651216, Final Batch Loss: 0.00593216810375452\n",
      "Epoch 415, Loss: 0.034243165515363216, Final Batch Loss: 0.0018465404864400625\n",
      "Epoch 416, Loss: 0.04684079717844725, Final Batch Loss: 0.012331879697740078\n",
      "Epoch 417, Loss: 0.0609649692196399, Final Batch Loss: 0.022126777097582817\n",
      "Epoch 418, Loss: 0.05092707043513656, Final Batch Loss: 0.019783305004239082\n",
      "Epoch 419, Loss: 0.046002898598089814, Final Batch Loss: 0.02030920423567295\n",
      "Epoch 420, Loss: 0.03371235926169902, Final Batch Loss: 0.0042165047489106655\n",
      "Epoch 421, Loss: 0.02364689647220075, Final Batch Loss: 0.002101552439853549\n",
      "Epoch 422, Loss: 0.030057627009227872, Final Batch Loss: 0.015456324443221092\n",
      "Epoch 423, Loss: 0.04370814538560808, Final Batch Loss: 0.009241338819265366\n",
      "Epoch 424, Loss: 0.032537618186324835, Final Batch Loss: 0.004228382371366024\n",
      "Epoch 425, Loss: 0.035589253064244986, Final Batch Loss: 0.0026461081579327583\n",
      "Epoch 426, Loss: 0.06293029012158513, Final Batch Loss: 0.03531217202544212\n",
      "Epoch 427, Loss: 0.024737575324252248, Final Batch Loss: 0.004362893756479025\n",
      "Epoch 428, Loss: 0.03753025596961379, Final Batch Loss: 0.0027793659828603268\n",
      "Epoch 429, Loss: 0.0407818160019815, Final Batch Loss: 0.004767277278006077\n",
      "Epoch 430, Loss: 0.016006308374926448, Final Batch Loss: 0.0025639396626502275\n",
      "Epoch 431, Loss: 0.022564822807908058, Final Batch Loss: 0.0015161861665546894\n",
      "Epoch 432, Loss: 0.014724153792485595, Final Batch Loss: 0.0007204427383840084\n",
      "Epoch 433, Loss: 0.01464374945499003, Final Batch Loss: 0.0018330344464629889\n",
      "Epoch 434, Loss: 0.02801853744313121, Final Batch Loss: 0.014129777438938618\n",
      "Epoch 435, Loss: 0.023763511329889297, Final Batch Loss: 0.004383050370961428\n",
      "Epoch 436, Loss: 0.04823188506998122, Final Batch Loss: 0.03418244421482086\n",
      "Epoch 437, Loss: 0.031838885275647044, Final Batch Loss: 0.007350102998316288\n",
      "Epoch 438, Loss: 0.022439397405833006, Final Batch Loss: 0.01053662970662117\n",
      "Epoch 439, Loss: 0.06438359641470015, Final Batch Loss: 0.00533703388646245\n",
      "Epoch 440, Loss: 0.027289830497466028, Final Batch Loss: 0.0019503663061186671\n",
      "Epoch 441, Loss: 0.013187652453780174, Final Batch Loss: 0.0007998228538781404\n",
      "Epoch 442, Loss: 0.028977564303204417, Final Batch Loss: 0.0020927111618220806\n",
      "Epoch 443, Loss: 0.04423548746854067, Final Batch Loss: 0.0037672303151339293\n",
      "Epoch 444, Loss: 0.02787383017130196, Final Batch Loss: 0.0024611500557512045\n",
      "Epoch 445, Loss: 0.016954785329289734, Final Batch Loss: 0.0025191272143274546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446, Loss: 0.02825837559066713, Final Batch Loss: 0.015377269126474857\n",
      "Epoch 447, Loss: 0.0357852938468568, Final Batch Loss: 0.0009521820466034114\n",
      "Epoch 448, Loss: 0.019723363337107003, Final Batch Loss: 0.0018827918684110045\n",
      "Epoch 449, Loss: 0.03338792780414224, Final Batch Loss: 0.014114809222519398\n",
      "Epoch 450, Loss: 0.03467042720876634, Final Batch Loss: 0.0016903718933463097\n",
      "Epoch 451, Loss: 0.025280545698478818, Final Batch Loss: 0.012500608339905739\n",
      "Epoch 452, Loss: 0.022470247582532465, Final Batch Loss: 0.0017187269404530525\n",
      "Epoch 453, Loss: 0.026552395313046873, Final Batch Loss: 0.003404494607821107\n",
      "Epoch 454, Loss: 0.022247896064072847, Final Batch Loss: 0.005260231904685497\n",
      "Epoch 455, Loss: 0.04002218437381089, Final Batch Loss: 0.007130675483494997\n",
      "Epoch 456, Loss: 0.02197816502302885, Final Batch Loss: 0.0020607453770935535\n",
      "Epoch 457, Loss: 0.02536082686856389, Final Batch Loss: 0.002962122205644846\n",
      "Epoch 458, Loss: 0.037347937119193375, Final Batch Loss: 0.0018533292459324002\n",
      "Epoch 459, Loss: 0.01625121058896184, Final Batch Loss: 0.006874603684991598\n",
      "Epoch 460, Loss: 0.029436328448355198, Final Batch Loss: 0.009907497093081474\n",
      "Epoch 461, Loss: 0.03106849454343319, Final Batch Loss: 0.009136593900620937\n",
      "Epoch 462, Loss: 0.022881121141836047, Final Batch Loss: 0.0046483902260661125\n",
      "Epoch 463, Loss: 0.025576352141797543, Final Batch Loss: 0.004068997222930193\n",
      "Epoch 464, Loss: 0.01832183700753376, Final Batch Loss: 0.0009232777520082891\n",
      "Epoch 465, Loss: 0.04276926536113024, Final Batch Loss: 0.0004845922812819481\n",
      "Epoch 466, Loss: 0.04628410725854337, Final Batch Loss: 0.009446981362998486\n",
      "Epoch 467, Loss: 0.01693134941160679, Final Batch Loss: 0.001494936877861619\n",
      "Epoch 468, Loss: 0.03641344630159438, Final Batch Loss: 0.010170974768698215\n",
      "Epoch 469, Loss: 0.03915108949877322, Final Batch Loss: 0.003690031822770834\n",
      "Epoch 470, Loss: 0.047765037044882774, Final Batch Loss: 0.005814719945192337\n",
      "Epoch 471, Loss: 0.06485052546486259, Final Batch Loss: 0.03619588911533356\n",
      "Epoch 472, Loss: 0.05900624510832131, Final Batch Loss: 0.0020794931333512068\n",
      "Epoch 473, Loss: 0.07926273765042424, Final Batch Loss: 0.06553258746862411\n",
      "Epoch 474, Loss: 0.015342910308390856, Final Batch Loss: 0.0007324828766286373\n",
      "Epoch 475, Loss: 0.04913043696433306, Final Batch Loss: 0.019737496972084045\n",
      "Epoch 476, Loss: 0.022037046845071018, Final Batch Loss: 0.0007497427286580205\n",
      "Epoch 477, Loss: 0.058910449617542326, Final Batch Loss: 0.023865653201937675\n",
      "Epoch 478, Loss: 0.01805986138060689, Final Batch Loss: 0.0014073667116463184\n",
      "Epoch 479, Loss: 0.029474652837961912, Final Batch Loss: 0.014561241492629051\n",
      "Epoch 480, Loss: 0.02903781016357243, Final Batch Loss: 0.010855859145522118\n",
      "Epoch 481, Loss: 0.029498245334252715, Final Batch Loss: 0.0028566422406584024\n",
      "Epoch 482, Loss: 0.04088915418833494, Final Batch Loss: 0.006812657695263624\n",
      "Epoch 483, Loss: 0.038564805407077074, Final Batch Loss: 0.011953984387218952\n",
      "Epoch 484, Loss: 0.015572425676509738, Final Batch Loss: 0.009745960123836994\n",
      "Epoch 485, Loss: 0.02398119354620576, Final Batch Loss: 0.006222594995051622\n",
      "Epoch 486, Loss: 0.025092187337577343, Final Batch Loss: 0.010512896813452244\n",
      "Epoch 487, Loss: 0.01656276942230761, Final Batch Loss: 0.0022907035890966654\n",
      "Epoch 488, Loss: 0.021970189874991775, Final Batch Loss: 0.008048302493989468\n",
      "Epoch 489, Loss: 0.01745330507401377, Final Batch Loss: 0.003814161755144596\n",
      "Epoch 490, Loss: 0.018826214014552534, Final Batch Loss: 0.00920574925839901\n",
      "Epoch 491, Loss: 0.030439758207648993, Final Batch Loss: 0.004709712695330381\n",
      "Epoch 492, Loss: 0.04441710514947772, Final Batch Loss: 0.024972496554255486\n",
      "Epoch 493, Loss: 0.027084742323495448, Final Batch Loss: 0.01758704148232937\n",
      "Epoch 494, Loss: 0.010151620139367878, Final Batch Loss: 0.005388733930885792\n",
      "Epoch 495, Loss: 0.03538982663303614, Final Batch Loss: 0.003439926542341709\n",
      "Epoch 496, Loss: 0.005618706054519862, Final Batch Loss: 0.0013180114328861237\n",
      "Epoch 497, Loss: 0.01184069481678307, Final Batch Loss: 0.0013668113388121128\n",
      "Epoch 498, Loss: 0.012986515183001757, Final Batch Loss: 0.0029563612770289183\n",
      "Epoch 499, Loss: 0.030194882303476334, Final Batch Loss: 0.002681674435734749\n",
      "Epoch 500, Loss: 0.019041327526792884, Final Batch Loss: 0.003786372020840645\n",
      "Epoch 501, Loss: 0.006598034698981792, Final Batch Loss: 0.0015947195934131742\n",
      "Epoch 502, Loss: 0.012265078257769346, Final Batch Loss: 0.0010720742866396904\n",
      "Epoch 503, Loss: 0.016100574634037912, Final Batch Loss: 0.001711832475848496\n",
      "Epoch 504, Loss: 0.009783774497918785, Final Batch Loss: 0.00128932052757591\n",
      "Epoch 505, Loss: 0.008892623125575483, Final Batch Loss: 0.0011865153210237622\n",
      "Epoch 506, Loss: 0.004421865567564964, Final Batch Loss: 0.0016268299659714103\n",
      "Epoch 507, Loss: 0.016342536080628633, Final Batch Loss: 0.004713482689112425\n",
      "Epoch 508, Loss: 0.033565799007192254, Final Batch Loss: 0.022911082953214645\n",
      "Epoch 509, Loss: 0.01974902395159006, Final Batch Loss: 0.010378262959420681\n",
      "Epoch 510, Loss: 0.009483673493377864, Final Batch Loss: 0.001136954640969634\n",
      "Epoch 511, Loss: 0.018585022538900375, Final Batch Loss: 0.0008428626460954547\n",
      "Epoch 512, Loss: 0.016504399827681482, Final Batch Loss: 0.0013537921477109194\n",
      "Epoch 513, Loss: 0.018016330257523805, Final Batch Loss: 0.002572134369984269\n",
      "Epoch 514, Loss: 0.005283480160869658, Final Batch Loss: 0.0014589062193408608\n",
      "Epoch 515, Loss: 0.03128691005986184, Final Batch Loss: 0.001727545284666121\n",
      "Epoch 516, Loss: 0.013190926751121879, Final Batch Loss: 0.0009690462611615658\n",
      "Epoch 517, Loss: 0.022606515674851835, Final Batch Loss: 0.0011352094588801265\n",
      "Epoch 518, Loss: 0.02022226998815313, Final Batch Loss: 0.0027594720013439655\n",
      "Epoch 519, Loss: 0.02813653228804469, Final Batch Loss: 0.0014683338813483715\n",
      "Epoch 520, Loss: 0.008580927387811244, Final Batch Loss: 0.0020543374121189117\n",
      "Epoch 521, Loss: 0.0453319163643755, Final Batch Loss: 0.006926573812961578\n",
      "Epoch 522, Loss: 0.01338536397088319, Final Batch Loss: 0.007043182849884033\n",
      "Epoch 523, Loss: 0.03504151292145252, Final Batch Loss: 0.02511543780565262\n",
      "Epoch 524, Loss: 0.023515919456258416, Final Batch Loss: 0.007418077904731035\n",
      "Epoch 525, Loss: 0.031408005277626216, Final Batch Loss: 0.0013366687344387174\n",
      "Epoch 526, Loss: 0.019545126939192414, Final Batch Loss: 0.005713137798011303\n",
      "Epoch 527, Loss: 0.05429143289802596, Final Batch Loss: 0.0019309712806716561\n",
      "Epoch 528, Loss: 0.024394278647378087, Final Batch Loss: 0.005363537929952145\n",
      "Epoch 529, Loss: 0.005960751499515027, Final Batch Loss: 0.0023569294717162848\n",
      "Epoch 530, Loss: 0.015076808689627796, Final Batch Loss: 0.001156381331384182\n",
      "Epoch 531, Loss: 0.02950315736234188, Final Batch Loss: 0.0008310778066515923\n",
      "Epoch 532, Loss: 0.029887696087826043, Final Batch Loss: 0.016111018136143684\n",
      "Epoch 533, Loss: 0.01102462608832866, Final Batch Loss: 0.001071831095032394\n",
      "Epoch 534, Loss: 0.005018232041038573, Final Batch Loss: 0.001221746439114213\n",
      "Epoch 535, Loss: 0.04254906560527161, Final Batch Loss: 0.0008081058622337878\n",
      "Epoch 536, Loss: 0.018633903586305678, Final Batch Loss: 0.0024540768936276436\n",
      "Epoch 537, Loss: 0.05800765403546393, Final Batch Loss: 0.0085429847240448\n",
      "Epoch 538, Loss: 0.017338475794531405, Final Batch Loss: 0.0008108867332339287\n",
      "Epoch 539, Loss: 0.025220450712367892, Final Batch Loss: 0.003954474348574877\n",
      "Epoch 540, Loss: 0.01273634482640773, Final Batch Loss: 0.0014428903814405203\n",
      "Epoch 541, Loss: 0.020805114414542913, Final Batch Loss: 0.005193416960537434\n",
      "Epoch 542, Loss: 0.041921711061149836, Final Batch Loss: 0.0021182477939873934\n",
      "Epoch 543, Loss: 0.018161814543418586, Final Batch Loss: 0.0006884022150188684\n",
      "Epoch 544, Loss: 0.018764894688501954, Final Batch Loss: 0.003710791002959013\n",
      "Epoch 545, Loss: 0.035150618525221944, Final Batch Loss: 0.021358324214816093\n",
      "Epoch 546, Loss: 0.020269640837796032, Final Batch Loss: 0.005288794636726379\n",
      "Epoch 547, Loss: 0.005551402718992904, Final Batch Loss: 0.0006649757269769907\n",
      "Epoch 548, Loss: 0.005830946611240506, Final Batch Loss: 0.00117042928468436\n",
      "Epoch 549, Loss: 0.011086451821029186, Final Batch Loss: 0.00413163797929883\n",
      "Epoch 550, Loss: 0.008328234660439193, Final Batch Loss: 0.0013807757059112191\n",
      "Epoch 551, Loss: 0.0236227095592767, Final Batch Loss: 0.013949395157396793\n",
      "Epoch 552, Loss: 0.008485518279485404, Final Batch Loss: 0.002184466226026416\n",
      "Epoch 553, Loss: 0.028164681454654783, Final Batch Loss: 0.003381996415555477\n",
      "Epoch 554, Loss: 0.006520506809465587, Final Batch Loss: 0.0023164378944784403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555, Loss: 0.015380247961729765, Final Batch Loss: 0.004863137844949961\n",
      "Epoch 556, Loss: 0.008943324850406498, Final Batch Loss: 0.002124563790857792\n",
      "Epoch 557, Loss: 0.05188971315510571, Final Batch Loss: 0.02376989834010601\n",
      "Epoch 558, Loss: 0.006326759932562709, Final Batch Loss: 0.0008443882106803358\n",
      "Epoch 559, Loss: 0.02528980653733015, Final Batch Loss: 0.002467108890414238\n",
      "Epoch 560, Loss: 0.027050599339418113, Final Batch Loss: 0.0006059878505766392\n",
      "Epoch 561, Loss: 0.009306678781285882, Final Batch Loss: 0.001787904417142272\n",
      "Epoch 562, Loss: 0.031606267439201474, Final Batch Loss: 0.01374244038015604\n",
      "Epoch 563, Loss: 0.07721188804134727, Final Batch Loss: 0.005502819549292326\n",
      "Epoch 564, Loss: 0.025400816928595304, Final Batch Loss: 0.0012634340673685074\n",
      "Epoch 565, Loss: 0.00533581170020625, Final Batch Loss: 0.0007471055723726749\n",
      "Epoch 566, Loss: 0.010708253365010023, Final Batch Loss: 0.0055519635789096355\n",
      "Epoch 567, Loss: 0.010964358923956752, Final Batch Loss: 0.0028282534331083298\n",
      "Epoch 568, Loss: 0.0340623676602263, Final Batch Loss: 0.00039439581451006234\n",
      "Epoch 569, Loss: 0.013023510458879173, Final Batch Loss: 0.0056436131708323956\n",
      "Epoch 570, Loss: 0.02198132046032697, Final Batch Loss: 0.0029784319922327995\n",
      "Epoch 571, Loss: 0.01630169281270355, Final Batch Loss: 0.0032923228573054075\n",
      "Epoch 572, Loss: 0.025096417870372534, Final Batch Loss: 0.004172022454440594\n",
      "Epoch 573, Loss: 0.013265392510220408, Final Batch Loss: 0.00853398721665144\n",
      "Epoch 574, Loss: 0.01006711833178997, Final Batch Loss: 0.0013365910854190588\n",
      "Epoch 575, Loss: 0.012318589782807976, Final Batch Loss: 0.000673798902425915\n",
      "Epoch 576, Loss: 0.00858210411388427, Final Batch Loss: 0.0016529182903468609\n",
      "Epoch 577, Loss: 0.011106196325272322, Final Batch Loss: 0.005275233648717403\n",
      "Epoch 578, Loss: 0.01635864027775824, Final Batch Loss: 0.003202220890671015\n",
      "Epoch 579, Loss: 0.009430757025256753, Final Batch Loss: 0.0016375635750591755\n",
      "Epoch 580, Loss: 0.010336198844015598, Final Batch Loss: 0.0028037664014846087\n",
      "Epoch 581, Loss: 0.022616352885961533, Final Batch Loss: 0.005424936302006245\n",
      "Epoch 582, Loss: 0.011102456250227988, Final Batch Loss: 0.001698745763860643\n",
      "Epoch 583, Loss: 0.009950471459887922, Final Batch Loss: 0.004776121117174625\n",
      "Epoch 584, Loss: 0.004874899459537119, Final Batch Loss: 0.0016323663294315338\n",
      "Epoch 585, Loss: 0.006168101914227009, Final Batch Loss: 0.002350454218685627\n",
      "Epoch 586, Loss: 0.01716136996401474, Final Batch Loss: 0.002345707267522812\n",
      "Epoch 587, Loss: 0.010470093635376543, Final Batch Loss: 0.000840586784761399\n",
      "Epoch 588, Loss: 0.006393880699761212, Final Batch Loss: 0.002998224925249815\n",
      "Epoch 589, Loss: 0.009250522474758327, Final Batch Loss: 0.0035910443402826786\n",
      "Epoch 590, Loss: 0.015021398197859526, Final Batch Loss: 0.005350839346647263\n",
      "Epoch 591, Loss: 0.011409539903979748, Final Batch Loss: 0.0004439744516275823\n",
      "Epoch 592, Loss: 0.0508193897549063, Final Batch Loss: 0.021583599969744682\n",
      "Epoch 593, Loss: 0.013625498744659126, Final Batch Loss: 0.005890368018299341\n",
      "Epoch 594, Loss: 0.015103469486348331, Final Batch Loss: 0.004421248100697994\n",
      "Epoch 595, Loss: 0.01425395009573549, Final Batch Loss: 0.0007343749166466296\n",
      "Epoch 596, Loss: 0.007036858180072159, Final Batch Loss: 0.0012765866704285145\n",
      "Epoch 597, Loss: 0.0068740289425477386, Final Batch Loss: 0.0005361642688512802\n",
      "Epoch 598, Loss: 0.015854282130021602, Final Batch Loss: 0.0008554594242013991\n",
      "Epoch 599, Loss: 0.04027124657295644, Final Batch Loss: 0.010684368200600147\n",
      "Epoch 600, Loss: 0.034989651292562485, Final Batch Loss: 0.0013634699862450361\n",
      "Epoch 601, Loss: 0.025666419707704335, Final Batch Loss: 0.00032197049586102366\n",
      "Epoch 602, Loss: 0.03034999838564545, Final Batch Loss: 0.01770964078605175\n",
      "Epoch 603, Loss: 0.004550462123006582, Final Batch Loss: 0.0015935143455863\n",
      "Epoch 604, Loss: 0.006393219635356218, Final Batch Loss: 0.0009431727812625468\n",
      "Epoch 605, Loss: 0.04378095199353993, Final Batch Loss: 0.0036575626581907272\n",
      "Epoch 606, Loss: 0.010224002762697637, Final Batch Loss: 0.004543547052890062\n",
      "Epoch 607, Loss: 0.024190670723328367, Final Batch Loss: 0.00044743044418282807\n",
      "Epoch 608, Loss: 0.01309487025719136, Final Batch Loss: 0.0018277453491464257\n",
      "Epoch 609, Loss: 0.008829984464682639, Final Batch Loss: 0.0027757666539400816\n",
      "Epoch 610, Loss: 0.0072191174840554595, Final Batch Loss: 0.0012968432856723666\n",
      "Epoch 611, Loss: 0.008279434870928526, Final Batch Loss: 0.0008362405351363122\n",
      "Epoch 612, Loss: 0.016343073919415474, Final Batch Loss: 0.0023535352665930986\n",
      "Epoch 613, Loss: 0.02030039971577935, Final Batch Loss: 0.00025751747307367623\n",
      "Epoch 614, Loss: 0.008598672051448375, Final Batch Loss: 0.0004567998112179339\n",
      "Epoch 615, Loss: 0.005277133663184941, Final Batch Loss: 0.0006375586381182075\n",
      "Epoch 616, Loss: 0.012460027355700731, Final Batch Loss: 0.0012159938924014568\n",
      "Epoch 617, Loss: 0.0339337334735319, Final Batch Loss: 0.026350483298301697\n",
      "Epoch 618, Loss: 0.03722361219115555, Final Batch Loss: 0.029977571219205856\n",
      "Epoch 619, Loss: 0.042168099142145365, Final Batch Loss: 0.0023317341692745686\n",
      "Epoch 620, Loss: 0.008630874857772142, Final Batch Loss: 0.005513946525752544\n",
      "Epoch 621, Loss: 0.007256804849021137, Final Batch Loss: 0.004160141572356224\n",
      "Epoch 622, Loss: 0.01971660798881203, Final Batch Loss: 0.000981927034445107\n",
      "Epoch 623, Loss: 0.01083058025687933, Final Batch Loss: 0.0036825337447226048\n",
      "Epoch 624, Loss: 0.03769097971962765, Final Batch Loss: 0.03226478025317192\n",
      "Epoch 625, Loss: 0.02419461903627962, Final Batch Loss: 0.01809491217136383\n",
      "Epoch 626, Loss: 0.008118018740788102, Final Batch Loss: 0.0012571188854053617\n",
      "Epoch 627, Loss: 0.015784250979777426, Final Batch Loss: 0.004574581980705261\n",
      "Epoch 628, Loss: 0.017269872245378792, Final Batch Loss: 0.0011089785257354379\n",
      "Epoch 629, Loss: 0.043281793768983334, Final Batch Loss: 0.0012281779199838638\n",
      "Epoch 630, Loss: 0.010255869303364307, Final Batch Loss: 0.006132080685347319\n",
      "Epoch 631, Loss: 0.016109948977828026, Final Batch Loss: 0.00461698230355978\n",
      "Epoch 632, Loss: 0.012667324801441282, Final Batch Loss: 0.004700805060565472\n",
      "Epoch 633, Loss: 0.00767930067377165, Final Batch Loss: 0.002286311471834779\n",
      "Epoch 634, Loss: 0.004955659533152357, Final Batch Loss: 0.0014008235884830356\n",
      "Epoch 635, Loss: 0.01379286521114409, Final Batch Loss: 0.004170541185885668\n",
      "Epoch 636, Loss: 0.006085287895984948, Final Batch Loss: 0.0011771187419071794\n",
      "Epoch 637, Loss: 0.021247560158371925, Final Batch Loss: 0.011647701263427734\n",
      "Epoch 638, Loss: 0.006831012666225433, Final Batch Loss: 0.0017040432430803776\n",
      "Epoch 639, Loss: 0.017757023684680462, Final Batch Loss: 0.00507262023165822\n",
      "Epoch 640, Loss: 0.016210002824664116, Final Batch Loss: 0.009691255167126656\n",
      "Epoch 641, Loss: 0.013840341824106872, Final Batch Loss: 0.005211001727730036\n",
      "Epoch 642, Loss: 0.011433778621722013, Final Batch Loss: 0.0022517465986311436\n",
      "Epoch 643, Loss: 0.017055489006452262, Final Batch Loss: 0.010036120191216469\n",
      "Epoch 644, Loss: 0.046212493209168315, Final Batch Loss: 0.0018990852404385805\n",
      "Epoch 645, Loss: 0.003591773915104568, Final Batch Loss: 0.0006934716366231441\n",
      "Epoch 646, Loss: 0.011559081496670842, Final Batch Loss: 0.000309790950268507\n",
      "Epoch 647, Loss: 0.0065345256589353085, Final Batch Loss: 0.003121034475043416\n",
      "Epoch 648, Loss: 0.005108269513584673, Final Batch Loss: 0.00042995065450668335\n",
      "Epoch 649, Loss: 0.006618009880185127, Final Batch Loss: 0.0011938916286453605\n",
      "Epoch 650, Loss: 0.0072382881480734795, Final Batch Loss: 0.005303104408085346\n",
      "Epoch 651, Loss: 0.008145626808982342, Final Batch Loss: 0.002721222350373864\n",
      "Epoch 652, Loss: 0.014760698803002015, Final Batch Loss: 0.0003921463212464005\n",
      "Epoch 653, Loss: 0.00909812276950106, Final Batch Loss: 0.0002492729399818927\n",
      "Epoch 654, Loss: 0.006586897419765592, Final Batch Loss: 0.0010388604132458568\n",
      "Epoch 655, Loss: 0.014698070648591965, Final Batch Loss: 0.0013084469828754663\n",
      "Epoch 656, Loss: 0.03439117351081222, Final Batch Loss: 0.0009557834127917886\n",
      "Epoch 657, Loss: 0.01171158510260284, Final Batch Loss: 0.004738733638077974\n",
      "Epoch 658, Loss: 0.0050165640423074365, Final Batch Loss: 0.0011540724663063884\n",
      "Epoch 659, Loss: 0.03294476890005171, Final Batch Loss: 0.017285212874412537\n",
      "Epoch 660, Loss: 0.024334576621185988, Final Batch Loss: 0.0008920623804442585\n",
      "Epoch 661, Loss: 0.008638753206469119, Final Batch Loss: 0.0012060016160830855\n",
      "Epoch 662, Loss: 0.01602557147271, Final Batch Loss: 0.0008594386163167655\n",
      "Epoch 663, Loss: 0.010898769774939865, Final Batch Loss: 0.002120434772223234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 664, Loss: 0.008942549757193774, Final Batch Loss: 0.0028851565439254045\n",
      "Epoch 665, Loss: 0.014189613051712513, Final Batch Loss: 0.007279504556208849\n",
      "Epoch 666, Loss: 0.006517932866699994, Final Batch Loss: 0.0035157084930688143\n",
      "Epoch 667, Loss: 0.00832546380115673, Final Batch Loss: 0.0007508299895562232\n",
      "Epoch 668, Loss: 0.024684147792868316, Final Batch Loss: 0.003623114200308919\n",
      "Epoch 669, Loss: 0.013493731035850942, Final Batch Loss: 0.0011862913379445672\n",
      "Epoch 670, Loss: 0.00480501598212868, Final Batch Loss: 0.0005819327780045569\n",
      "Epoch 671, Loss: 0.030467968608718365, Final Batch Loss: 0.027739660814404488\n",
      "Epoch 672, Loss: 0.011269892536802217, Final Batch Loss: 0.002199774608016014\n",
      "Epoch 673, Loss: 0.0017577327089384198, Final Batch Loss: 0.00044898357009515166\n",
      "Epoch 674, Loss: 0.04465652635553852, Final Batch Loss: 0.010251511819660664\n",
      "Epoch 675, Loss: 0.019993162190075964, Final Batch Loss: 0.0005560376448556781\n",
      "Epoch 676, Loss: 0.017958347219973803, Final Batch Loss: 0.004386431071907282\n",
      "Epoch 677, Loss: 0.01037000521318987, Final Batch Loss: 0.0007954888278618455\n",
      "Epoch 678, Loss: 0.021734134294092655, Final Batch Loss: 0.0025953876320272684\n",
      "Epoch 679, Loss: 0.024928753351559862, Final Batch Loss: 0.0011856583878397942\n",
      "Epoch 680, Loss: 0.00958732352592051, Final Batch Loss: 0.0047160424292087555\n",
      "Epoch 681, Loss: 0.0028894782881252468, Final Batch Loss: 0.0005498867249116302\n",
      "Epoch 682, Loss: 0.012715312506770715, Final Batch Loss: 0.0006177431205287576\n",
      "Epoch 683, Loss: 0.019938535115215927, Final Batch Loss: 0.0046267276629805565\n",
      "Epoch 684, Loss: 0.015598840021993965, Final Batch Loss: 0.0006742937839590013\n",
      "Epoch 685, Loss: 0.004371863644337282, Final Batch Loss: 0.0022744638845324516\n",
      "Epoch 686, Loss: 0.008244955854024738, Final Batch Loss: 0.0007426752708852291\n",
      "Epoch 687, Loss: 0.0307514455053024, Final Batch Loss: 0.0012094075791537762\n",
      "Epoch 688, Loss: 0.022992021054960787, Final Batch Loss: 0.0007770938100293279\n",
      "Epoch 689, Loss: 0.011571662325877696, Final Batch Loss: 0.0008246626239269972\n",
      "Epoch 690, Loss: 0.009484396083280444, Final Batch Loss: 0.0005829022265970707\n",
      "Epoch 691, Loss: 0.02086909592617303, Final Batch Loss: 0.003390222555026412\n",
      "Epoch 692, Loss: 0.03135257080430165, Final Batch Loss: 0.0003141094057355076\n",
      "Epoch 693, Loss: 0.007143537746742368, Final Batch Loss: 0.001711731543764472\n",
      "Epoch 694, Loss: 0.007433567167026922, Final Batch Loss: 0.00047240775893442333\n",
      "Epoch 695, Loss: 0.00410858413670212, Final Batch Loss: 0.0005449984455481172\n",
      "Epoch 696, Loss: 0.030054027622099966, Final Batch Loss: 0.0008702102932147682\n",
      "Epoch 697, Loss: 0.014072052377741784, Final Batch Loss: 0.00341943372040987\n",
      "Epoch 698, Loss: 0.013024836196564138, Final Batch Loss: 0.00101977598387748\n",
      "Epoch 699, Loss: 0.0030321867670863867, Final Batch Loss: 0.0007192533230409026\n",
      "Epoch 700, Loss: 0.005975251435302198, Final Batch Loss: 0.0015989448875188828\n",
      "Epoch 701, Loss: 0.012066288327332586, Final Batch Loss: 0.001885378616861999\n",
      "Epoch 702, Loss: 0.017784339317586273, Final Batch Loss: 0.00045075194793753326\n",
      "Epoch 703, Loss: 0.0181567725376226, Final Batch Loss: 0.0003332383348606527\n",
      "Epoch 704, Loss: 0.01934138312935829, Final Batch Loss: 0.00034352485090494156\n",
      "Epoch 705, Loss: 0.040021704946411774, Final Batch Loss: 0.0019678091630339622\n",
      "Epoch 706, Loss: 0.013603283034171909, Final Batch Loss: 0.0024434952065348625\n",
      "Epoch 707, Loss: 0.03405674663372338, Final Batch Loss: 0.0020314743742346764\n",
      "Epoch 708, Loss: 0.03797281184233725, Final Batch Loss: 0.012704298831522465\n",
      "Epoch 709, Loss: 0.03921952017117292, Final Batch Loss: 0.006590224336832762\n",
      "Epoch 710, Loss: 0.02007513027638197, Final Batch Loss: 0.001326626050285995\n",
      "Epoch 711, Loss: 0.007357785652857274, Final Batch Loss: 0.000605449138674885\n",
      "Epoch 712, Loss: 0.0075618133414536715, Final Batch Loss: 0.00198908569291234\n",
      "Epoch 713, Loss: 0.020127660245634615, Final Batch Loss: 0.0020713394042104483\n",
      "Epoch 714, Loss: 0.03920772988931276, Final Batch Loss: 0.03224276378750801\n",
      "Epoch 715, Loss: 0.013786631054244936, Final Batch Loss: 0.000687409657984972\n",
      "Epoch 716, Loss: 0.005827392189530656, Final Batch Loss: 0.0001941754308063537\n",
      "Epoch 717, Loss: 0.03370481380261481, Final Batch Loss: 0.0026584859006106853\n",
      "Epoch 718, Loss: 0.014130159979686141, Final Batch Loss: 0.012734880670905113\n",
      "Epoch 719, Loss: 0.007645573059562594, Final Batch Loss: 0.0009358251700177789\n",
      "Epoch 720, Loss: 0.011555633944226429, Final Batch Loss: 0.0038037693593651056\n",
      "Epoch 721, Loss: 0.012219382158946246, Final Batch Loss: 0.001606213510967791\n",
      "Epoch 722, Loss: 0.012938574305735528, Final Batch Loss: 0.004816852044314146\n",
      "Epoch 723, Loss: 0.01604911853792146, Final Batch Loss: 0.008320982567965984\n",
      "Epoch 724, Loss: 0.0053800651512574404, Final Batch Loss: 0.0004228839825373143\n",
      "Epoch 725, Loss: 0.012687273614574224, Final Batch Loss: 0.0013643669662997127\n",
      "Epoch 726, Loss: 0.014818853582255542, Final Batch Loss: 0.005949974060058594\n",
      "Epoch 727, Loss: 0.009296939009800553, Final Batch Loss: 0.0013234632788226008\n",
      "Epoch 728, Loss: 0.007689163496252149, Final Batch Loss: 0.0008053840138018131\n",
      "Epoch 729, Loss: 0.011587578454054892, Final Batch Loss: 0.0017766227247193456\n",
      "Epoch 730, Loss: 0.026465415256097913, Final Batch Loss: 0.008192431181669235\n",
      "Epoch 731, Loss: 0.01469904399709776, Final Batch Loss: 0.0004678394761867821\n",
      "Epoch 732, Loss: 0.009128064848482609, Final Batch Loss: 0.003764483379200101\n",
      "Epoch 733, Loss: 0.008070369891356677, Final Batch Loss: 0.00039387104334309697\n",
      "Epoch 734, Loss: 0.006592194142285734, Final Batch Loss: 0.0027311453595757484\n",
      "Epoch 735, Loss: 0.006287238764343783, Final Batch Loss: 0.003284265287220478\n",
      "Epoch 736, Loss: 0.004928019305225462, Final Batch Loss: 0.0010842069750651717\n",
      "Epoch 737, Loss: 0.014734123833477497, Final Batch Loss: 0.009234319441020489\n",
      "Epoch 738, Loss: 0.008320233901031315, Final Batch Loss: 0.0007721102447248995\n",
      "Epoch 739, Loss: 0.007217853213660419, Final Batch Loss: 0.000538008171133697\n",
      "Epoch 740, Loss: 0.009363241435494274, Final Batch Loss: 0.0025299834087491035\n",
      "Epoch 741, Loss: 0.006871451914776117, Final Batch Loss: 0.0006661423249170184\n",
      "Epoch 742, Loss: 0.003227044071536511, Final Batch Loss: 0.000749976490624249\n",
      "Epoch 743, Loss: 0.0035795568546745926, Final Batch Loss: 0.001245374558493495\n",
      "Epoch 744, Loss: 0.005407552467659116, Final Batch Loss: 0.0001727194176055491\n",
      "Epoch 745, Loss: 0.019198457041056827, Final Batch Loss: 0.00865886453539133\n",
      "Epoch 746, Loss: 0.0017595645767869428, Final Batch Loss: 0.0004399603058118373\n",
      "Epoch 747, Loss: 0.0037626618868671358, Final Batch Loss: 0.0005140247521921992\n",
      "Epoch 748, Loss: 0.009895229246467352, Final Batch Loss: 0.0004098088829778135\n",
      "Epoch 749, Loss: 0.006128967506811023, Final Batch Loss: 0.0007058525225147605\n",
      "Epoch 750, Loss: 0.003094017185503617, Final Batch Loss: 0.0005438448279164732\n",
      "Epoch 751, Loss: 0.008897235835320316, Final Batch Loss: 0.0028345277532935143\n",
      "Epoch 752, Loss: 0.008077848178800195, Final Batch Loss: 0.00025059215840883553\n",
      "Epoch 753, Loss: 0.00516344812058378, Final Batch Loss: 0.0036919903941452503\n",
      "Epoch 754, Loss: 0.029740926751401275, Final Batch Loss: 0.008534776978194714\n",
      "Epoch 755, Loss: 0.012547285557957366, Final Batch Loss: 0.00036083083250559866\n",
      "Epoch 756, Loss: 0.01069323328556493, Final Batch Loss: 0.007394381798803806\n",
      "Epoch 757, Loss: 0.008323558373376727, Final Batch Loss: 0.0032343785278499126\n",
      "Epoch 758, Loss: 0.002316980855539441, Final Batch Loss: 0.0004329474759288132\n",
      "Epoch 759, Loss: 0.013272612763103098, Final Batch Loss: 0.005769217386841774\n",
      "Epoch 760, Loss: 0.03419866261538118, Final Batch Loss: 0.001459286897443235\n",
      "Epoch 761, Loss: 0.007960510964039713, Final Batch Loss: 0.004188545048236847\n",
      "Epoch 762, Loss: 0.006073346419725567, Final Batch Loss: 0.0008320393972098827\n",
      "Epoch 763, Loss: 0.016182840103283525, Final Batch Loss: 0.006263003218919039\n",
      "Epoch 764, Loss: 0.009006090404000133, Final Batch Loss: 0.0045626177452504635\n",
      "Epoch 765, Loss: 0.011279494763584808, Final Batch Loss: 0.0009678667993284762\n",
      "Epoch 766, Loss: 0.00494785193586722, Final Batch Loss: 0.0006217266782186925\n",
      "Epoch 767, Loss: 0.002156154834665358, Final Batch Loss: 0.0002653638366609812\n",
      "Epoch 768, Loss: 0.053803517992491834, Final Batch Loss: 0.00015004152373876423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769, Loss: 0.006971076596528292, Final Batch Loss: 0.0002973649534396827\n",
      "Epoch 770, Loss: 0.009987224824726582, Final Batch Loss: 0.008034386672079563\n",
      "Epoch 771, Loss: 0.008609221433289349, Final Batch Loss: 0.0012824254808947444\n",
      "Epoch 772, Loss: 0.02178166143130511, Final Batch Loss: 0.01913350261747837\n",
      "Epoch 773, Loss: 0.038853886479046196, Final Batch Loss: 0.0015496894484385848\n",
      "Epoch 774, Loss: 0.023583170725032687, Final Batch Loss: 0.008194717578589916\n",
      "Epoch 775, Loss: 0.00230130874842871, Final Batch Loss: 0.00018738988728728145\n",
      "Epoch 776, Loss: 0.017610301729291677, Final Batch Loss: 0.008181695826351643\n",
      "Epoch 777, Loss: 0.01151278568431735, Final Batch Loss: 0.00602700375020504\n",
      "Epoch 778, Loss: 0.0023170929052866995, Final Batch Loss: 0.0005135680548846722\n",
      "Epoch 779, Loss: 0.011245000292547047, Final Batch Loss: 0.0047759851440787315\n",
      "Epoch 780, Loss: 0.0026844660460483283, Final Batch Loss: 0.0003701206005644053\n",
      "Epoch 781, Loss: 0.010220566880889237, Final Batch Loss: 0.0015573081327602267\n",
      "Epoch 782, Loss: 0.02581781253684312, Final Batch Loss: 0.003077085129916668\n",
      "Epoch 783, Loss: 0.008422377868555486, Final Batch Loss: 0.00047401548363268375\n",
      "Epoch 784, Loss: 0.004091852781130001, Final Batch Loss: 0.00035862476215697825\n",
      "Epoch 785, Loss: 0.013598233053926378, Final Batch Loss: 0.0011753463186323643\n",
      "Epoch 786, Loss: 0.00611637847032398, Final Batch Loss: 0.0006206055404618382\n",
      "Epoch 787, Loss: 0.01554399449378252, Final Batch Loss: 0.0025277240201830864\n",
      "Epoch 788, Loss: 0.01601303176721558, Final Batch Loss: 0.007439559791237116\n",
      "Epoch 789, Loss: 0.01804507162887603, Final Batch Loss: 0.0007393810665234923\n",
      "Epoch 790, Loss: 0.010059312480734661, Final Batch Loss: 0.0003639830101747066\n",
      "Epoch 791, Loss: 0.04383081977721304, Final Batch Loss: 0.0008954521035775542\n",
      "Epoch 792, Loss: 0.007272865856066346, Final Batch Loss: 0.004698468837887049\n",
      "Epoch 793, Loss: 0.0017743730277288705, Final Batch Loss: 0.0003360052651260048\n",
      "Epoch 794, Loss: 0.011884926934726536, Final Batch Loss: 0.006557251792401075\n",
      "Epoch 795, Loss: 0.015606179949827492, Final Batch Loss: 0.0035071028396487236\n",
      "Epoch 796, Loss: 0.0057997655239887536, Final Batch Loss: 0.0007137489155866206\n",
      "Epoch 797, Loss: 0.004542729497188702, Final Batch Loss: 0.0010025575757026672\n",
      "Epoch 798, Loss: 0.009526912705041468, Final Batch Loss: 0.0005231941468082368\n",
      "Epoch 799, Loss: 0.03789560330915265, Final Batch Loss: 0.00013197134830988944\n",
      "Epoch 800, Loss: 0.002603779430501163, Final Batch Loss: 0.0005715377628803253\n",
      "Epoch 801, Loss: 0.007381459116004407, Final Batch Loss: 0.0018784793792292476\n",
      "Epoch 802, Loss: 0.0217419003311079, Final Batch Loss: 0.00016389708616770804\n",
      "Epoch 803, Loss: 0.010305194242391735, Final Batch Loss: 0.00044528901344165206\n",
      "Epoch 804, Loss: 0.005425629438832402, Final Batch Loss: 0.001446965616196394\n",
      "Epoch 805, Loss: 0.0030844008724670857, Final Batch Loss: 0.0004309424839448184\n",
      "Epoch 806, Loss: 0.0050974092446267605, Final Batch Loss: 0.0007039436022751033\n",
      "Epoch 807, Loss: 0.013615932635730132, Final Batch Loss: 0.0056847818195819855\n",
      "Epoch 808, Loss: 0.030504368216497824, Final Batch Loss: 0.0004834675637539476\n",
      "Epoch 809, Loss: 0.006803318596212193, Final Batch Loss: 0.0038504167459905148\n",
      "Epoch 810, Loss: 0.007720264955423772, Final Batch Loss: 0.0024096814449876547\n",
      "Epoch 811, Loss: 0.006649941555224359, Final Batch Loss: 0.0005690831458196044\n",
      "Epoch 812, Loss: 0.008519093389622867, Final Batch Loss: 0.0010251047788187861\n",
      "Epoch 813, Loss: 0.0024642716452945024, Final Batch Loss: 0.0003933947009500116\n",
      "Epoch 814, Loss: 0.0037695817300118506, Final Batch Loss: 0.000798143504653126\n",
      "Epoch 815, Loss: 0.029742982078460045, Final Batch Loss: 0.001372193917632103\n",
      "Epoch 816, Loss: 0.0036826587456744164, Final Batch Loss: 0.0003288532898295671\n",
      "Epoch 817, Loss: 0.01076089742127806, Final Batch Loss: 0.0016125940019264817\n",
      "Epoch 818, Loss: 0.005464295420097187, Final Batch Loss: 0.0006254492909647524\n",
      "Epoch 819, Loss: 0.002342372143175453, Final Batch Loss: 0.0006032781675457954\n",
      "Epoch 820, Loss: 0.00731255259597674, Final Batch Loss: 0.0014839662471786141\n",
      "Epoch 821, Loss: 0.0036915581731591374, Final Batch Loss: 0.0010986010311171412\n",
      "Epoch 822, Loss: 0.009371340915095061, Final Batch Loss: 0.0006248768768273294\n",
      "Epoch 823, Loss: 0.004406579479109496, Final Batch Loss: 0.0004320728767197579\n",
      "Epoch 824, Loss: 0.009615163478883915, Final Batch Loss: 0.006370761897414923\n",
      "Epoch 825, Loss: 0.00217951388185611, Final Batch Loss: 0.0003502412000671029\n",
      "Epoch 826, Loss: 0.005943436364759691, Final Batch Loss: 0.0010437613818794489\n",
      "Epoch 827, Loss: 0.0022581489611184224, Final Batch Loss: 0.0006045736954547465\n",
      "Epoch 828, Loss: 0.013771119352895766, Final Batch Loss: 0.0005954428925178945\n",
      "Epoch 829, Loss: 0.006553689134307206, Final Batch Loss: 0.004618529230356216\n",
      "Epoch 830, Loss: 0.022963690396863967, Final Batch Loss: 0.00014206278137862682\n",
      "Epoch 831, Loss: 0.003394093131646514, Final Batch Loss: 0.00033939944114536047\n",
      "Epoch 832, Loss: 0.00496318656951189, Final Batch Loss: 0.0006564961513504386\n",
      "Epoch 833, Loss: 0.0018909788195742294, Final Batch Loss: 0.0003995303704869002\n",
      "Epoch 834, Loss: 0.011989846359938383, Final Batch Loss: 0.005481106694787741\n",
      "Epoch 835, Loss: 0.0020771605195477605, Final Batch Loss: 0.0001345070340903476\n",
      "Epoch 836, Loss: 0.011115006112959236, Final Batch Loss: 0.00017158911214210093\n",
      "Epoch 837, Loss: 0.0040529984398745, Final Batch Loss: 0.0025993180461227894\n",
      "Epoch 838, Loss: 0.011180607027199585, Final Batch Loss: 0.00045620452146977186\n",
      "Epoch 839, Loss: 0.014614017534768209, Final Batch Loss: 0.007067881990224123\n",
      "Epoch 840, Loss: 0.006119964877143502, Final Batch Loss: 0.0008498728275299072\n",
      "Epoch 841, Loss: 0.014466134831309319, Final Batch Loss: 0.003407662734389305\n",
      "Epoch 842, Loss: 0.006465127284172922, Final Batch Loss: 0.0008035028586164117\n",
      "Epoch 843, Loss: 0.0026703821204137057, Final Batch Loss: 0.00043387673213146627\n",
      "Epoch 844, Loss: 0.027741174468246754, Final Batch Loss: 0.0001192819545394741\n",
      "Epoch 845, Loss: 0.005489097035024315, Final Batch Loss: 0.000968094274867326\n",
      "Epoch 846, Loss: 0.01605036377441138, Final Batch Loss: 0.009985302574932575\n",
      "Epoch 847, Loss: 0.010282102099154145, Final Batch Loss: 0.002636887598782778\n",
      "Epoch 848, Loss: 0.02560265797364991, Final Batch Loss: 0.0001343780168099329\n",
      "Epoch 849, Loss: 0.003126668685581535, Final Batch Loss: 0.0005019863601773977\n",
      "Epoch 850, Loss: 0.004455622838577256, Final Batch Loss: 0.0009779410902410746\n",
      "Epoch 851, Loss: 0.03512705655884929, Final Batch Loss: 0.002879874315112829\n",
      "Epoch 852, Loss: 0.018992479250300676, Final Batch Loss: 0.00025358638959005475\n",
      "Epoch 853, Loss: 0.0103466167638544, Final Batch Loss: 0.00039555414696224034\n",
      "Epoch 854, Loss: 0.0045710098929703236, Final Batch Loss: 0.0008286593947559595\n",
      "Epoch 855, Loss: 0.030978083377704024, Final Batch Loss: 0.00857601873576641\n",
      "Epoch 856, Loss: 0.005020612763473764, Final Batch Loss: 0.0017614128300920129\n",
      "Epoch 857, Loss: 0.008556914806831628, Final Batch Loss: 0.001314064022153616\n",
      "Epoch 858, Loss: 0.006667601759545505, Final Batch Loss: 0.00027915072860196233\n",
      "Epoch 859, Loss: 0.009039453289005905, Final Batch Loss: 0.00047946220729500055\n",
      "Epoch 860, Loss: 0.0047950530497473665, Final Batch Loss: 7.518882193835452e-05\n",
      "Epoch 861, Loss: 0.007413742860080674, Final Batch Loss: 0.0003344153519719839\n",
      "Epoch 862, Loss: 0.0017178608977701515, Final Batch Loss: 0.00011279969476163387\n",
      "Epoch 863, Loss: 0.02066778010339476, Final Batch Loss: 0.017420222982764244\n",
      "Epoch 864, Loss: 0.03137499908916652, Final Batch Loss: 0.0002701462944969535\n",
      "Epoch 865, Loss: 0.008331650809850544, Final Batch Loss: 0.0038362827617675066\n",
      "Epoch 866, Loss: 0.008248980331700295, Final Batch Loss: 0.004729084670543671\n",
      "Epoch 867, Loss: 0.005653592117596418, Final Batch Loss: 0.00033824803540483117\n",
      "Epoch 868, Loss: 0.0064850885537453, Final Batch Loss: 0.0002605037880130112\n",
      "Epoch 869, Loss: 0.003188436705386266, Final Batch Loss: 0.0011530136689543724\n",
      "Epoch 870, Loss: 0.01343440980417654, Final Batch Loss: 0.0007932442240417004\n",
      "Epoch 871, Loss: 0.03553877689410001, Final Batch Loss: 0.0010443871142342687\n",
      "Epoch 872, Loss: 0.004543036862742156, Final Batch Loss: 0.002334756311029196\n",
      "Epoch 873, Loss: 0.005256085642031394, Final Batch Loss: 0.001129636657424271\n",
      "Epoch 874, Loss: 0.010374173521995544, Final Batch Loss: 0.0023237820714712143\n",
      "Epoch 875, Loss: 0.003548171604052186, Final Batch Loss: 0.00026950862957164645\n",
      "Epoch 876, Loss: 0.004447022394742817, Final Batch Loss: 0.0008063032873906195\n",
      "Epoch 877, Loss: 0.05329559824895114, Final Batch Loss: 0.02138998918235302\n",
      "Epoch 878, Loss: 0.03609352506464347, Final Batch Loss: 0.0237802155315876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879, Loss: 0.01506806316319853, Final Batch Loss: 0.000557298306375742\n",
      "Epoch 880, Loss: 0.008549611578928307, Final Batch Loss: 0.0004240938287694007\n",
      "Epoch 881, Loss: 0.0036324947723187506, Final Batch Loss: 0.0003329108003526926\n",
      "Epoch 882, Loss: 0.005312344612320885, Final Batch Loss: 0.0007287736516445875\n",
      "Epoch 883, Loss: 0.031174700940027833, Final Batch Loss: 0.0005529951304197311\n",
      "Epoch 884, Loss: 0.02121464876108803, Final Batch Loss: 0.00022853209520690143\n",
      "Epoch 885, Loss: 0.006168627878651023, Final Batch Loss: 0.0015785133000463247\n",
      "Epoch 886, Loss: 0.006004545633913949, Final Batch Loss: 0.00031268157181330025\n",
      "Epoch 887, Loss: 0.015054352232255042, Final Batch Loss: 0.006764459889382124\n",
      "Epoch 888, Loss: 0.02827996958512813, Final Batch Loss: 0.0040139323100447655\n",
      "Epoch 889, Loss: 0.008109020884148777, Final Batch Loss: 0.0008318073814734817\n",
      "Epoch 890, Loss: 0.02266724337823689, Final Batch Loss: 0.001283908961340785\n",
      "Epoch 891, Loss: 0.0034542415814939886, Final Batch Loss: 0.0015402628341689706\n",
      "Epoch 892, Loss: 0.006857029307866469, Final Batch Loss: 0.0003804680018220097\n",
      "Epoch 893, Loss: 0.005130334699060768, Final Batch Loss: 0.000159638118930161\n",
      "Epoch 894, Loss: 0.003967125900089741, Final Batch Loss: 0.001604351680725813\n",
      "Epoch 895, Loss: 0.0038000722706783563, Final Batch Loss: 0.0008942587883211672\n",
      "Epoch 896, Loss: 0.003343279124237597, Final Batch Loss: 0.00036284883390180767\n",
      "Epoch 897, Loss: 0.0038727549399482086, Final Batch Loss: 0.0006273455801419914\n",
      "Epoch 898, Loss: 0.0032735193090047687, Final Batch Loss: 0.0003972230770159513\n",
      "Epoch 899, Loss: 0.006507204263471067, Final Batch Loss: 0.0025659026578068733\n",
      "Epoch 900, Loss: 0.02010952334967442, Final Batch Loss: 0.012618300504982471\n",
      "Epoch 901, Loss: 0.01274660526541993, Final Batch Loss: 0.0011921300319954753\n",
      "Epoch 902, Loss: 0.005982491100439802, Final Batch Loss: 0.004266553092747927\n",
      "Epoch 903, Loss: 0.011089601903222501, Final Batch Loss: 0.007479617837816477\n",
      "Epoch 904, Loss: 0.0061333090998232365, Final Batch Loss: 0.001138310064561665\n",
      "Epoch 905, Loss: 0.008475243143038824, Final Batch Loss: 0.0050962455570697784\n",
      "Epoch 906, Loss: 0.0027818476664833724, Final Batch Loss: 0.0003689433215186\n",
      "Epoch 907, Loss: 0.005217328638536856, Final Batch Loss: 0.0006341779371723533\n",
      "Epoch 908, Loss: 0.005037299852119759, Final Batch Loss: 0.00035015822504647076\n",
      "Epoch 909, Loss: 0.004185818135738373, Final Batch Loss: 0.0006396665121428668\n",
      "Epoch 910, Loss: 0.005932151252636686, Final Batch Loss: 0.0030819037929177284\n",
      "Epoch 911, Loss: 0.00314002601953689, Final Batch Loss: 0.0012694220058619976\n",
      "Epoch 912, Loss: 0.013029290246777236, Final Batch Loss: 0.005599099211394787\n",
      "Epoch 913, Loss: 0.0029368165050982498, Final Batch Loss: 7.726836338406429e-05\n",
      "Epoch 914, Loss: 0.025166011953842826, Final Batch Loss: 0.0007086229743435979\n",
      "Epoch 915, Loss: 0.004528067191131413, Final Batch Loss: 0.0009942053584381938\n",
      "Epoch 916, Loss: 0.0117946635291446, Final Batch Loss: 0.0003994703583884984\n",
      "Epoch 917, Loss: 0.005141248955624178, Final Batch Loss: 0.0005817976780235767\n",
      "Epoch 918, Loss: 0.001967573305591941, Final Batch Loss: 0.00031833373941481113\n",
      "Epoch 919, Loss: 0.006294280319707468, Final Batch Loss: 0.0003127357049379498\n",
      "Epoch 920, Loss: 0.0018171900301240385, Final Batch Loss: 0.00018278605421073735\n",
      "Epoch 921, Loss: 0.0052796543459407985, Final Batch Loss: 0.0005035026115365326\n",
      "Epoch 922, Loss: 0.00421891306177713, Final Batch Loss: 0.0018495530821383\n",
      "Epoch 923, Loss: 0.005646929726935923, Final Batch Loss: 0.0003879685536958277\n",
      "Epoch 924, Loss: 0.002080142148770392, Final Batch Loss: 0.00047144884592853487\n",
      "Epoch 925, Loss: 0.003626202524174005, Final Batch Loss: 0.0009657551418058574\n",
      "Epoch 926, Loss: 0.005081721174065024, Final Batch Loss: 0.0007517792982980609\n",
      "Epoch 927, Loss: 0.004992275440599769, Final Batch Loss: 0.0005926319281570613\n",
      "Epoch 928, Loss: 0.04648460919270292, Final Batch Loss: 0.0003643045201897621\n",
      "Epoch 929, Loss: 0.005659494723659009, Final Batch Loss: 0.00019291130593046546\n",
      "Epoch 930, Loss: 0.0034710208710748702, Final Batch Loss: 0.00019155009067617357\n",
      "Epoch 931, Loss: 0.024972484912723303, Final Batch Loss: 0.02271658554673195\n",
      "Epoch 932, Loss: 0.012849061953602359, Final Batch Loss: 0.0018386212177574635\n",
      "Epoch 933, Loss: 0.008338405925314873, Final Batch Loss: 0.003796806326135993\n",
      "Epoch 934, Loss: 0.0020248848450137302, Final Batch Loss: 0.0007887849351391196\n",
      "Epoch 935, Loss: 0.007243068510433659, Final Batch Loss: 0.005547581240534782\n",
      "Epoch 936, Loss: 0.004595206795784179, Final Batch Loss: 0.0005920995026826859\n",
      "Epoch 937, Loss: 0.007552663497335743, Final Batch Loss: 6.199152994668111e-05\n",
      "Epoch 938, Loss: 0.010257267102133483, Final Batch Loss: 0.0009054160909727216\n",
      "Epoch 939, Loss: 0.0012949114898219705, Final Batch Loss: 0.00020092645718250424\n",
      "Epoch 940, Loss: 0.00299076693772804, Final Batch Loss: 0.000633012386970222\n",
      "Epoch 941, Loss: 0.11158926586358575, Final Batch Loss: 0.058570247143507004\n",
      "Epoch 942, Loss: 0.006075679208151996, Final Batch Loss: 0.0010790217202156782\n",
      "Epoch 943, Loss: 0.06868981447769329, Final Batch Loss: 0.002944227773696184\n",
      "Epoch 944, Loss: 0.003978163207648322, Final Batch Loss: 0.0009130658581852913\n",
      "Epoch 945, Loss: 0.0034780734567902982, Final Batch Loss: 0.0006353931385092437\n",
      "Epoch 946, Loss: 0.008136123244185, Final Batch Loss: 0.0003077051951549947\n",
      "Epoch 947, Loss: 0.023879151645815, Final Batch Loss: 0.00029125853325240314\n",
      "Epoch 948, Loss: 0.007593377376906574, Final Batch Loss: 0.003743912559002638\n",
      "Epoch 949, Loss: 0.020344612887129188, Final Batch Loss: 0.009427541866898537\n",
      "Epoch 950, Loss: 0.0022441548644565046, Final Batch Loss: 0.0003304347046650946\n",
      "Epoch 951, Loss: 0.015126152080483735, Final Batch Loss: 0.0009237679187208414\n",
      "Epoch 952, Loss: 0.0077369352511595935, Final Batch Loss: 0.0007734860992059112\n",
      "Epoch 953, Loss: 0.004487135971430689, Final Batch Loss: 0.0003130445838905871\n",
      "Epoch 954, Loss: 0.0039138285792432725, Final Batch Loss: 0.0019129643915221095\n",
      "Epoch 955, Loss: 0.0032878580677788705, Final Batch Loss: 0.0006202581571415067\n",
      "Epoch 956, Loss: 0.005175025435164571, Final Batch Loss: 0.0006776106311008334\n",
      "Epoch 957, Loss: 0.006730515378876589, Final Batch Loss: 0.002573082922026515\n",
      "Epoch 958, Loss: 0.0176581873674877, Final Batch Loss: 0.016295431181788445\n",
      "Epoch 959, Loss: 0.024115043139318004, Final Batch Loss: 0.0001470220449846238\n",
      "Epoch 960, Loss: 0.013790464960038662, Final Batch Loss: 0.004331167787313461\n",
      "Epoch 961, Loss: 0.00699467136291787, Final Batch Loss: 0.002729753265157342\n",
      "Epoch 962, Loss: 0.007417312503093854, Final Batch Loss: 0.0013328344793990254\n",
      "Epoch 963, Loss: 0.008621171524282545, Final Batch Loss: 0.0009845294989645481\n",
      "Epoch 964, Loss: 0.020676251588156447, Final Batch Loss: 0.00022348531638272107\n",
      "Epoch 965, Loss: 0.005377231078455225, Final Batch Loss: 0.0002653668343555182\n",
      "Epoch 966, Loss: 0.002976694842800498, Final Batch Loss: 0.0005704096984118223\n",
      "Epoch 967, Loss: 0.002426786028081551, Final Batch Loss: 0.0009900290751829743\n",
      "Epoch 968, Loss: 0.0048281949711963534, Final Batch Loss: 0.0006041801534593105\n",
      "Epoch 969, Loss: 0.003476019948720932, Final Batch Loss: 0.0005631844978779554\n",
      "Epoch 970, Loss: 0.024636763890157454, Final Batch Loss: 0.0017362068174406886\n",
      "Epoch 971, Loss: 0.004218596019200049, Final Batch Loss: 0.0015820004045963287\n",
      "Epoch 972, Loss: 0.002844396309228614, Final Batch Loss: 0.0005136695690453053\n",
      "Epoch 973, Loss: 0.014814432768616825, Final Batch Loss: 0.011710704304277897\n",
      "Epoch 974, Loss: 0.0021173504064790905, Final Batch Loss: 0.0007767147617414594\n",
      "Epoch 975, Loss: 0.004774084722157568, Final Batch Loss: 0.00011699547758325934\n",
      "Epoch 976, Loss: 0.022678303183056414, Final Batch Loss: 0.0001348382793366909\n",
      "Epoch 977, Loss: 0.019936980679631233, Final Batch Loss: 0.016923125833272934\n",
      "Epoch 978, Loss: 0.0049803111323853955, Final Batch Loss: 8.05870076874271e-05\n",
      "Epoch 979, Loss: 0.004737783980090171, Final Batch Loss: 0.00052987365052104\n",
      "Epoch 980, Loss: 0.010173575778026134, Final Batch Loss: 0.0007231924100778997\n",
      "Epoch 981, Loss: 0.005581034842180088, Final Batch Loss: 0.0007091800216585398\n",
      "Epoch 982, Loss: 0.016749158094171435, Final Batch Loss: 0.005461651831865311\n",
      "Epoch 983, Loss: 0.004108969355002046, Final Batch Loss: 0.0011878811055794358\n",
      "Epoch 984, Loss: 0.001791305243386887, Final Batch Loss: 0.0010057918261736631\n",
      "Epoch 985, Loss: 0.004440282820723951, Final Batch Loss: 0.0022221182007342577\n",
      "Epoch 986, Loss: 0.0019816027124761604, Final Batch Loss: 0.000377876014681533\n",
      "Epoch 987, Loss: 0.0023478113143937662, Final Batch Loss: 0.00031904943170957267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988, Loss: 0.008933330565923825, Final Batch Loss: 0.0019215426873415709\n",
      "Epoch 989, Loss: 0.013485648698406294, Final Batch Loss: 0.00048482263810001314\n",
      "Epoch 990, Loss: 0.008000736765097827, Final Batch Loss: 0.005603870376944542\n",
      "Epoch 991, Loss: 0.01901076576905325, Final Batch Loss: 0.006994709838181734\n",
      "Epoch 992, Loss: 0.0019220361355110072, Final Batch Loss: 0.00044246719335205853\n",
      "Epoch 993, Loss: 0.016638199653243646, Final Batch Loss: 0.013533158227801323\n",
      "Epoch 994, Loss: 0.004015063459519297, Final Batch Loss: 0.0002453038177918643\n",
      "Epoch 995, Loss: 0.011143735493533313, Final Batch Loss: 0.0006647355621680617\n",
      "Epoch 996, Loss: 0.009218979626893997, Final Batch Loss: 0.0025434454437345266\n",
      "Epoch 997, Loss: 0.01486458524595946, Final Batch Loss: 0.0008560535497963428\n",
      "Epoch 998, Loss: 0.0029103640554239973, Final Batch Loss: 0.00022630263993050903\n",
      "Epoch 999, Loss: 0.002034383825957775, Final Batch Loss: 0.00048073308425955474\n",
      "Epoch 1000, Loss: 0.002009299787459895, Final Batch Loss: 0.0005683931522071362\n",
      "Epoch 1001, Loss: 0.0034880522289313376, Final Batch Loss: 0.0003601812932174653\n",
      "Epoch 1002, Loss: 0.005116233762237243, Final Batch Loss: 0.0002097803953802213\n",
      "Epoch 1003, Loss: 0.01222353915363783, Final Batch Loss: 0.011504040099680424\n",
      "Epoch 1004, Loss: 0.0035342347691766918, Final Batch Loss: 0.0016470628324896097\n",
      "Epoch 1005, Loss: 0.002105391184159089, Final Batch Loss: 0.00015958095900714397\n",
      "Epoch 1006, Loss: 0.005924033437622711, Final Batch Loss: 0.0034400620497763157\n",
      "Epoch 1007, Loss: 0.04060720055713318, Final Batch Loss: 0.00015523444744758308\n",
      "Epoch 1008, Loss: 0.026943578668578994, Final Batch Loss: 0.00010719562851591036\n",
      "Epoch 1009, Loss: 0.025363147084135562, Final Batch Loss: 0.0028259996324777603\n",
      "Epoch 1010, Loss: 0.006065791705623269, Final Batch Loss: 0.0021255153696984053\n",
      "Epoch 1011, Loss: 0.03212308825459331, Final Batch Loss: 0.0009735483909025788\n",
      "Epoch 1012, Loss: 0.0037987907126080245, Final Batch Loss: 0.0002587806375231594\n",
      "Epoch 1013, Loss: 0.0054000490345060825, Final Batch Loss: 0.002370934933423996\n",
      "Epoch 1014, Loss: 0.002004029505769722, Final Batch Loss: 0.0002727995452005416\n",
      "Epoch 1015, Loss: 0.002823802024067845, Final Batch Loss: 3.686750278575346e-05\n",
      "Epoch 1016, Loss: 0.005640510484226979, Final Batch Loss: 6.682770617771894e-05\n",
      "Epoch 1017, Loss: 0.010872030194150284, Final Batch Loss: 0.00034548345138318837\n",
      "Epoch 1018, Loss: 0.003933555795811117, Final Batch Loss: 0.0007741543813608587\n",
      "Epoch 1019, Loss: 0.005659626622218639, Final Batch Loss: 0.000802250171545893\n",
      "Epoch 1020, Loss: 0.0020974012441001832, Final Batch Loss: 0.00014552689390257\n",
      "Epoch 1021, Loss: 0.017544233247463126, Final Batch Loss: 0.0007327712955884635\n",
      "Epoch 1022, Loss: 0.008078287995886058, Final Batch Loss: 0.00021316016500350088\n",
      "Epoch 1023, Loss: 0.0009220507927238941, Final Batch Loss: 0.00023967394372448325\n",
      "Epoch 1024, Loss: 0.006508122736704536, Final Batch Loss: 0.005741332191973925\n",
      "Epoch 1025, Loss: 0.038162895129062235, Final Batch Loss: 0.0019055110169574618\n",
      "Epoch 1026, Loss: 0.012333867431152612, Final Batch Loss: 0.0005379531648941338\n",
      "Epoch 1027, Loss: 0.0025423054030397907, Final Batch Loss: 0.0015257657505571842\n",
      "Epoch 1028, Loss: 0.007243912637932226, Final Batch Loss: 8.574509411118925e-05\n",
      "Epoch 1029, Loss: 0.015009195660240948, Final Batch Loss: 0.011469653807580471\n",
      "Epoch 1030, Loss: 0.0026595013623591512, Final Batch Loss: 0.0004905569367110729\n",
      "Epoch 1031, Loss: 0.019243444869061932, Final Batch Loss: 0.0021211474668234587\n",
      "Epoch 1032, Loss: 0.004053454351378605, Final Batch Loss: 0.001446206821128726\n",
      "Epoch 1033, Loss: 0.005445467002573423, Final Batch Loss: 0.0045954035595059395\n",
      "Epoch 1034, Loss: 0.003228280460461974, Final Batch Loss: 0.0008537081303074956\n",
      "Epoch 1035, Loss: 0.007681603688979521, Final Batch Loss: 0.00294579123146832\n",
      "Epoch 1036, Loss: 0.03196971900615608, Final Batch Loss: 0.00010108964488608763\n",
      "Epoch 1037, Loss: 0.006542661983985454, Final Batch Loss: 0.0014064341085031629\n",
      "Epoch 1038, Loss: 0.002492533778422512, Final Batch Loss: 0.000582408276386559\n",
      "Epoch 1039, Loss: 0.023913719662232324, Final Batch Loss: 0.02324734441936016\n",
      "Epoch 1040, Loss: 0.004597843158990145, Final Batch Loss: 0.002934920834377408\n",
      "Epoch 1041, Loss: 0.0036454906803555787, Final Batch Loss: 0.0010031347628682852\n",
      "Epoch 1042, Loss: 0.007258242490934208, Final Batch Loss: 0.00019184299162589014\n",
      "Epoch 1043, Loss: 0.0027285564283374697, Final Batch Loss: 0.00037029714439995587\n",
      "Epoch 1044, Loss: 0.006662662781309336, Final Batch Loss: 0.00014541359269060194\n",
      "Epoch 1045, Loss: 0.006188873841892928, Final Batch Loss: 0.0006336552323773503\n",
      "Epoch 1046, Loss: 0.01238671035389416, Final Batch Loss: 0.00027120564482174814\n",
      "Epoch 1047, Loss: 0.007843743529519998, Final Batch Loss: 0.0005131761427037418\n",
      "Epoch 1048, Loss: 0.014301058545242995, Final Batch Loss: 0.0002925158478319645\n",
      "Epoch 1049, Loss: 0.024818078920361586, Final Batch Loss: 0.0018788866000249982\n",
      "Epoch 1050, Loss: 0.00746212515514344, Final Batch Loss: 0.0009099695598706603\n",
      "Epoch 1051, Loss: 0.0027683811786118895, Final Batch Loss: 0.0006283358670771122\n",
      "Epoch 1052, Loss: 0.03543634619563818, Final Batch Loss: 0.001523718237876892\n",
      "Epoch 1053, Loss: 0.0022838751901872456, Final Batch Loss: 0.00013289465277921408\n",
      "Epoch 1054, Loss: 0.007068106875522062, Final Batch Loss: 0.004584476817399263\n",
      "Epoch 1055, Loss: 0.00266848268074682, Final Batch Loss: 4.88673904328607e-05\n",
      "Epoch 1056, Loss: 0.0031942408822942525, Final Batch Loss: 0.0012913505779579282\n",
      "Epoch 1057, Loss: 0.010607842516037636, Final Batch Loss: 0.0016823677578940988\n",
      "Epoch 1058, Loss: 0.004953079085680656, Final Batch Loss: 0.00026214905665256083\n",
      "Epoch 1059, Loss: 0.0030763945542275906, Final Batch Loss: 0.0003675800107885152\n",
      "Epoch 1060, Loss: 0.005410264042438939, Final Batch Loss: 0.0014508190797641873\n",
      "Epoch 1061, Loss: 0.0020471425232244655, Final Batch Loss: 0.0005524798762053251\n",
      "Epoch 1062, Loss: 0.004312466844567098, Final Batch Loss: 0.00016154425975400954\n",
      "Epoch 1063, Loss: 0.007476156228221953, Final Batch Loss: 0.003056395798921585\n",
      "Epoch 1064, Loss: 0.0057102308492176235, Final Batch Loss: 0.0006144977523945272\n",
      "Epoch 1065, Loss: 0.0034835927363019437, Final Batch Loss: 0.0006043160101398826\n",
      "Epoch 1066, Loss: 0.0053446024539880455, Final Batch Loss: 0.0008344708476215601\n",
      "Epoch 1067, Loss: 0.0065160760132130235, Final Batch Loss: 0.00030723397503606975\n",
      "Epoch 1068, Loss: 0.0033858443130156957, Final Batch Loss: 6.301534449448809e-05\n",
      "Epoch 1069, Loss: 0.038142339675687253, Final Batch Loss: 0.03558523580431938\n",
      "Epoch 1070, Loss: 0.0054578571289312094, Final Batch Loss: 0.001617833273485303\n",
      "Epoch 1071, Loss: 0.0076915288518648595, Final Batch Loss: 0.0045507848262786865\n",
      "Epoch 1072, Loss: 0.0009602763602742925, Final Batch Loss: 0.000206147029530257\n",
      "Epoch 1073, Loss: 0.004839240224100649, Final Batch Loss: 0.00027067982591688633\n",
      "Epoch 1074, Loss: 0.002169727216823958, Final Batch Loss: 0.0001489490969106555\n",
      "Epoch 1075, Loss: 0.002216145920101553, Final Batch Loss: 0.000894210475962609\n",
      "Epoch 1076, Loss: 0.0012848025799030438, Final Batch Loss: 0.00023333608987741172\n",
      "Epoch 1077, Loss: 0.004922297492157668, Final Batch Loss: 0.0006244909018278122\n",
      "Epoch 1078, Loss: 0.001131868724769447, Final Batch Loss: 0.0003873951791319996\n",
      "Epoch 1079, Loss: 0.001622512201720383, Final Batch Loss: 0.0002575746038928628\n",
      "Epoch 1080, Loss: 0.00426291671465151, Final Batch Loss: 0.0007775307749398053\n",
      "Epoch 1081, Loss: 0.0025486361992079765, Final Batch Loss: 0.0008597687701694667\n",
      "Epoch 1082, Loss: 0.0018452426047588233, Final Batch Loss: 0.0010785097256302834\n",
      "Epoch 1083, Loss: 0.003204717861081008, Final Batch Loss: 4.410019755596295e-05\n",
      "Epoch 1084, Loss: 0.02638357793330215, Final Batch Loss: 0.0259868111461401\n",
      "Epoch 1085, Loss: 0.0009748840020620264, Final Batch Loss: 6.41861479380168e-05\n",
      "Epoch 1086, Loss: 0.0035681703011505306, Final Batch Loss: 0.0028482619673013687\n",
      "Epoch 1087, Loss: 0.004939396574627608, Final Batch Loss: 0.0005975390085950494\n",
      "Epoch 1088, Loss: 0.00567495365976356, Final Batch Loss: 0.00026346961385570467\n",
      "Epoch 1089, Loss: 0.011248926763073541, Final Batch Loss: 0.009524728171527386\n",
      "Epoch 1090, Loss: 0.003804542779107578, Final Batch Loss: 0.0026286065112799406\n",
      "Epoch 1091, Loss: 0.006151720976049546, Final Batch Loss: 6.412267248379067e-05\n",
      "Epoch 1092, Loss: 0.006366008223267272, Final Batch Loss: 0.00024738244246691465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1093, Loss: 0.0025325765600427985, Final Batch Loss: 0.001502336235716939\n",
      "Epoch 1094, Loss: 0.029236806876724586, Final Batch Loss: 0.0002109124034177512\n",
      "Epoch 1095, Loss: 0.006653565214946866, Final Batch Loss: 0.0001718261046335101\n",
      "Epoch 1096, Loss: 0.014799482371017803, Final Batch Loss: 7.092068699421361e-05\n",
      "Epoch 1097, Loss: 0.0022970263853494544, Final Batch Loss: 4.0826333133736625e-05\n",
      "Epoch 1098, Loss: 0.020109884964767843, Final Batch Loss: 0.0017180475406348705\n",
      "Epoch 1099, Loss: 0.0029691640738747083, Final Batch Loss: 0.00022555959003511816\n",
      "Epoch 1100, Loss: 0.015438034432008862, Final Batch Loss: 0.011085773818194866\n",
      "Epoch 1101, Loss: 0.023190283915027976, Final Batch Loss: 0.017481183633208275\n",
      "Epoch 1102, Loss: 0.00541181190055795, Final Batch Loss: 0.00048514132504351437\n",
      "Epoch 1103, Loss: 0.004118642071262002, Final Batch Loss: 0.0005728520336560905\n",
      "Epoch 1104, Loss: 0.0049806946772150695, Final Batch Loss: 0.0036670074332505465\n",
      "Epoch 1105, Loss: 0.0035816815798170865, Final Batch Loss: 0.00015151139814406633\n",
      "Epoch 1106, Loss: 0.004332571043050848, Final Batch Loss: 0.00043805036693811417\n",
      "Epoch 1107, Loss: 0.002949453264591284, Final Batch Loss: 7.777727296343073e-05\n",
      "Epoch 1108, Loss: 0.008975260174338473, Final Batch Loss: 4.483972952584736e-05\n",
      "Epoch 1109, Loss: 0.003923979355022311, Final Batch Loss: 0.001456057303585112\n",
      "Epoch 1110, Loss: 0.0033919327543117106, Final Batch Loss: 0.00086612330051139\n",
      "Epoch 1111, Loss: 0.016240133089013398, Final Batch Loss: 0.0012628353433683515\n",
      "Epoch 1112, Loss: 0.011439133551903069, Final Batch Loss: 0.0001663014991208911\n",
      "Epoch 1113, Loss: 0.012452249706257135, Final Batch Loss: 0.0001507794513599947\n",
      "Epoch 1114, Loss: 0.019663071288960055, Final Batch Loss: 0.0003218970960006118\n",
      "Epoch 1115, Loss: 0.0023401930448017083, Final Batch Loss: 7.590051245642826e-05\n",
      "Epoch 1116, Loss: 0.0037289574393071234, Final Batch Loss: 0.00041841354686766863\n",
      "Epoch 1117, Loss: 0.00907239515800029, Final Batch Loss: 0.0040443954057991505\n",
      "Epoch 1118, Loss: 0.019468788836093154, Final Batch Loss: 0.0006004013703204691\n",
      "Epoch 1119, Loss: 0.004542437120107934, Final Batch Loss: 0.00029760957113467157\n",
      "Epoch 1120, Loss: 0.01837089503533207, Final Batch Loss: 0.004992690868675709\n",
      "Epoch 1121, Loss: 0.021052284369943663, Final Batch Loss: 0.019452182576060295\n",
      "Epoch 1122, Loss: 0.0073155876161763445, Final Batch Loss: 0.0045655230060219765\n",
      "Epoch 1123, Loss: 0.0014435022021643817, Final Batch Loss: 0.00025249324971809983\n",
      "Epoch 1124, Loss: 0.004375964432256296, Final Batch Loss: 0.00021607015514746308\n",
      "Epoch 1125, Loss: 0.0045160079607740045, Final Batch Loss: 0.00012715806951746345\n",
      "Epoch 1126, Loss: 0.03239935639430769, Final Batch Loss: 0.030541755259037018\n",
      "Epoch 1127, Loss: 0.0052629624551627785, Final Batch Loss: 0.00023818787303753197\n",
      "Epoch 1128, Loss: 0.002777850197162479, Final Batch Loss: 0.0002467971935402602\n",
      "Epoch 1129, Loss: 0.030008980189450085, Final Batch Loss: 0.001715567777864635\n",
      "Epoch 1130, Loss: 0.0014995573437772691, Final Batch Loss: 0.0002550352073740214\n",
      "Epoch 1131, Loss: 0.005907561659114435, Final Batch Loss: 0.002432894427329302\n",
      "Epoch 1132, Loss: 0.013286836794577539, Final Batch Loss: 0.001347305136732757\n",
      "Epoch 1133, Loss: 0.0011630478111328557, Final Batch Loss: 0.00019949105626437813\n",
      "Epoch 1134, Loss: 0.003568328102119267, Final Batch Loss: 0.0007696474203839898\n",
      "Epoch 1135, Loss: 0.009899354947265238, Final Batch Loss: 0.00035230728099122643\n",
      "Epoch 1136, Loss: 0.048217535120784305, Final Batch Loss: 0.0006584400543943048\n",
      "Epoch 1137, Loss: 0.009166898671537638, Final Batch Loss: 0.0030123749747872353\n",
      "Epoch 1138, Loss: 0.0015096596907824278, Final Batch Loss: 0.0002780470240395516\n",
      "Epoch 1139, Loss: 0.0023079907696228474, Final Batch Loss: 0.00028273474890738726\n",
      "Epoch 1140, Loss: 0.0019427885999903083, Final Batch Loss: 0.00033425033325329423\n",
      "Epoch 1141, Loss: 0.015996742513380013, Final Batch Loss: 0.0001744782639434561\n",
      "Epoch 1142, Loss: 0.010866754353628494, Final Batch Loss: 0.007823018357157707\n",
      "Epoch 1143, Loss: 0.004335385950980708, Final Batch Loss: 0.003424174850806594\n",
      "Epoch 1144, Loss: 0.002599867933895439, Final Batch Loss: 0.0008836240158416331\n",
      "Epoch 1145, Loss: 0.0013824526395183057, Final Batch Loss: 0.0004783993645105511\n",
      "Epoch 1146, Loss: 0.000998192306724377, Final Batch Loss: 0.0003741489490494132\n",
      "Epoch 1147, Loss: 0.025705053471028805, Final Batch Loss: 0.024235719814896584\n",
      "Epoch 1148, Loss: 0.002379062687396072, Final Batch Loss: 0.0008925418369472027\n",
      "Epoch 1149, Loss: 0.0028105018427595496, Final Batch Loss: 0.00010082597145810723\n",
      "Epoch 1150, Loss: 0.0028204554255353287, Final Batch Loss: 0.00016078341286629438\n",
      "Epoch 1151, Loss: 0.004805543547263369, Final Batch Loss: 0.0004992292379029095\n",
      "Epoch 1152, Loss: 0.005751806325861253, Final Batch Loss: 0.00017781194765120745\n",
      "Epoch 1153, Loss: 0.005567851854721084, Final Batch Loss: 0.0026478320360183716\n",
      "Epoch 1154, Loss: 0.00438785609730985, Final Batch Loss: 0.0027778083458542824\n",
      "Epoch 1155, Loss: 0.0024169378157239407, Final Batch Loss: 0.0001415486040059477\n",
      "Epoch 1156, Loss: 0.0033126150228781626, Final Batch Loss: 0.0012349402531981468\n",
      "Epoch 1157, Loss: 0.0018054839310934767, Final Batch Loss: 0.0010737342527136207\n",
      "Epoch 1158, Loss: 0.005576526178629138, Final Batch Loss: 0.0012943708570674062\n",
      "Epoch 1159, Loss: 0.001526924126665108, Final Batch Loss: 0.0006558123277500272\n",
      "Epoch 1160, Loss: 0.0005365085307857953, Final Batch Loss: 8.954646182246506e-05\n",
      "Epoch 1161, Loss: 0.004035431178635918, Final Batch Loss: 0.0003391575301066041\n",
      "Epoch 1162, Loss: 0.0008215106099669356, Final Batch Loss: 5.5469765356974676e-05\n",
      "Epoch 1163, Loss: 0.006325719041342381, Final Batch Loss: 8.968690963229164e-05\n",
      "Epoch 1164, Loss: 0.001107669377233833, Final Batch Loss: 0.00012570842227432877\n",
      "Epoch 1165, Loss: 0.0011505914371809922, Final Batch Loss: 0.0006501111201941967\n",
      "Epoch 1166, Loss: 0.006733908528985921, Final Batch Loss: 0.0033118571154773235\n",
      "Epoch 1167, Loss: 0.0015837890314287506, Final Batch Loss: 6.754608330084011e-05\n",
      "Epoch 1168, Loss: 0.003533501469064504, Final Batch Loss: 7.957310299389064e-05\n",
      "Epoch 1169, Loss: 0.00470113025221508, Final Batch Loss: 0.0018934423569589853\n",
      "Epoch 1170, Loss: 0.0068614103947766125, Final Batch Loss: 0.0005553902010433376\n",
      "Epoch 1171, Loss: 0.006431950110709295, Final Batch Loss: 0.0043683359399437904\n",
      "Epoch 1172, Loss: 0.005995546613121405, Final Batch Loss: 0.0033875226508826017\n",
      "Epoch 1173, Loss: 0.005636741509079002, Final Batch Loss: 9.943473560269922e-05\n",
      "Epoch 1174, Loss: 0.003203960135579109, Final Batch Loss: 0.0005334928864613175\n",
      "Epoch 1175, Loss: 0.0017541568959131837, Final Batch Loss: 0.00027026861789636314\n",
      "Epoch 1176, Loss: 0.0012266339799680281, Final Batch Loss: 3.0130253435345367e-05\n",
      "Epoch 1177, Loss: 0.005628612154396251, Final Batch Loss: 0.00033984173205681145\n",
      "Epoch 1178, Loss: 0.020473242009757087, Final Batch Loss: 0.0002579131396487355\n",
      "Epoch 1179, Loss: 0.0023934782984724734, Final Batch Loss: 4.828079545404762e-05\n",
      "Epoch 1180, Loss: 0.006258193039684556, Final Batch Loss: 0.0021457388065755367\n",
      "Epoch 1181, Loss: 0.020097445099963807, Final Batch Loss: 0.0016123256646096706\n",
      "Epoch 1182, Loss: 0.0015102705583558418, Final Batch Loss: 0.00011131109931739047\n",
      "Epoch 1183, Loss: 0.03974332615325693, Final Batch Loss: 0.0001725719921523705\n",
      "Epoch 1184, Loss: 0.0023476605383621063, Final Batch Loss: 6.506915087811649e-05\n",
      "Epoch 1185, Loss: 0.01695621805265546, Final Batch Loss: 0.0009018992423079908\n",
      "Epoch 1186, Loss: 0.0017977379975491203, Final Batch Loss: 0.00031395646510645747\n",
      "Epoch 1187, Loss: 0.016999378654873, Final Batch Loss: 0.008737324737012386\n",
      "Epoch 1188, Loss: 0.011147866127430461, Final Batch Loss: 0.0002309941774001345\n",
      "Epoch 1189, Loss: 0.0019601725216489285, Final Batch Loss: 0.0005655612330883741\n",
      "Epoch 1190, Loss: 0.013482989139447454, Final Batch Loss: 0.00011935662041651085\n",
      "Epoch 1191, Loss: 0.0023660099686821923, Final Batch Loss: 7.688791083637625e-05\n",
      "Epoch 1192, Loss: 0.004557272462989204, Final Batch Loss: 0.0004215491935610771\n",
      "Epoch 1193, Loss: 0.007918042945675552, Final Batch Loss: 0.000188045363756828\n",
      "Epoch 1194, Loss: 0.00546065501839621, Final Batch Loss: 8.038015948841348e-05\n",
      "Epoch 1195, Loss: 0.0009214209458150435, Final Batch Loss: 0.0003696145140565932\n",
      "Epoch 1196, Loss: 0.0030313844472402707, Final Batch Loss: 0.00037777776014991105\n",
      "Epoch 1197, Loss: 0.002821408968884498, Final Batch Loss: 0.0002897478698287159\n",
      "Epoch 1198, Loss: 0.011529844719916582, Final Batch Loss: 0.0004257949476595968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199, Loss: 0.003345200588228181, Final Batch Loss: 0.00030987607897259295\n",
      "Epoch 1200, Loss: 0.015555732665234245, Final Batch Loss: 0.005723900161683559\n",
      "Epoch 1201, Loss: 0.0019113160597044043, Final Batch Loss: 0.0005445839487947524\n",
      "Epoch 1202, Loss: 0.004640799990738742, Final Batch Loss: 0.0014108787290751934\n",
      "Epoch 1203, Loss: 0.0027496217662701383, Final Batch Loss: 0.00022811962116975337\n",
      "Epoch 1204, Loss: 0.0034371482906863093, Final Batch Loss: 0.0002713671128731221\n",
      "Epoch 1205, Loss: 0.001575885951751843, Final Batch Loss: 0.0002866864379029721\n",
      "Epoch 1206, Loss: 0.0020209343201713637, Final Batch Loss: 0.0002863233385141939\n",
      "Epoch 1207, Loss: 0.002675298987014685, Final Batch Loss: 0.0002647648798301816\n",
      "Epoch 1208, Loss: 0.045063624798785895, Final Batch Loss: 0.00038002891233190894\n",
      "Epoch 1209, Loss: 0.006733577800332569, Final Batch Loss: 0.0001168402231996879\n",
      "Epoch 1210, Loss: 0.004217207468173001, Final Batch Loss: 0.00019577305647544563\n",
      "Epoch 1211, Loss: 0.006341677624732256, Final Batch Loss: 0.0025197104550898075\n",
      "Epoch 1212, Loss: 0.003975190804339945, Final Batch Loss: 0.0005828011780977249\n",
      "Epoch 1213, Loss: 0.0039994179023779, Final Batch Loss: 0.0003956726286560297\n",
      "Epoch 1214, Loss: 0.0020373249135445803, Final Batch Loss: 0.00024409305478911847\n",
      "Epoch 1215, Loss: 0.001716952639981173, Final Batch Loss: 0.00019912088464479893\n",
      "Epoch 1216, Loss: 0.0353802382160211, Final Batch Loss: 0.00015360477846115828\n",
      "Epoch 1217, Loss: 0.0008687243389431387, Final Batch Loss: 0.0001517625933047384\n",
      "Epoch 1218, Loss: 0.00648362120409729, Final Batch Loss: 0.00023215687542688102\n",
      "Epoch 1219, Loss: 0.0017439081566408277, Final Batch Loss: 0.00016383518232032657\n",
      "Epoch 1220, Loss: 0.016147409587574657, Final Batch Loss: 0.011240082792937756\n",
      "Epoch 1221, Loss: 0.0014270602696342394, Final Batch Loss: 0.0008032486657612026\n",
      "Epoch 1222, Loss: 0.0028234872152097523, Final Batch Loss: 0.0004279919376131147\n",
      "Epoch 1223, Loss: 0.004815296153537929, Final Batch Loss: 0.002067493973299861\n",
      "Epoch 1224, Loss: 0.0016194715281017125, Final Batch Loss: 0.0002657818258740008\n",
      "Epoch 1225, Loss: 0.03148445702390745, Final Batch Loss: 0.026161523535847664\n",
      "Epoch 1226, Loss: 0.00570264458656311, Final Batch Loss: 0.0012977516744285822\n",
      "Epoch 1227, Loss: 0.004634618584532291, Final Batch Loss: 0.000491214101202786\n",
      "Epoch 1228, Loss: 0.004127599819184979, Final Batch Loss: 8.352373697562143e-05\n",
      "Epoch 1229, Loss: 0.010095688223373145, Final Batch Loss: 8.482769771944731e-05\n",
      "Epoch 1230, Loss: 0.000753147280192934, Final Batch Loss: 0.00016856109141372144\n",
      "Epoch 1231, Loss: 0.00277591438498348, Final Batch Loss: 0.00041486986447125673\n",
      "Epoch 1232, Loss: 0.005941776078543626, Final Batch Loss: 0.002589181298390031\n",
      "Epoch 1233, Loss: 0.005250467511359602, Final Batch Loss: 0.004477593116462231\n",
      "Epoch 1234, Loss: 0.005138795298989862, Final Batch Loss: 0.0022900765761733055\n",
      "Epoch 1235, Loss: 0.004206731035083067, Final Batch Loss: 0.0005852364120073617\n",
      "Epoch 1236, Loss: 0.0012036913649353664, Final Batch Loss: 0.0005460583488456905\n",
      "Epoch 1237, Loss: 0.001996459744987078, Final Batch Loss: 0.0007460428751073778\n",
      "Epoch 1238, Loss: 0.004730638102046214, Final Batch Loss: 0.000922510982491076\n",
      "Epoch 1239, Loss: 0.016976334678474814, Final Batch Loss: 0.0012426829198375344\n",
      "Epoch 1240, Loss: 0.005290644683555001, Final Batch Loss: 0.00043312652269378304\n",
      "Epoch 1241, Loss: 0.0010794248228194192, Final Batch Loss: 0.0003192418080288917\n",
      "Epoch 1242, Loss: 0.014413362863706425, Final Batch Loss: 0.0001489445858169347\n",
      "Epoch 1243, Loss: 0.0010330021905247122, Final Batch Loss: 0.0002685000654309988\n",
      "Epoch 1244, Loss: 0.010133096191566437, Final Batch Loss: 0.0006751620094291866\n",
      "Epoch 1245, Loss: 0.014385711983777583, Final Batch Loss: 0.006666137836873531\n",
      "Epoch 1246, Loss: 0.0021677013428416103, Final Batch Loss: 0.00035807749372906983\n",
      "Epoch 1247, Loss: 0.01831455682986416, Final Batch Loss: 0.0003945831849705428\n",
      "Epoch 1248, Loss: 0.0027783315599663183, Final Batch Loss: 0.000179322887561284\n",
      "Epoch 1249, Loss: 0.021880891647015233, Final Batch Loss: 0.0023940824903547764\n",
      "Epoch 1250, Loss: 0.002220637114078272, Final Batch Loss: 3.987650416092947e-05\n",
      "Epoch 1251, Loss: 0.01352350325032603, Final Batch Loss: 0.011619722470641136\n",
      "Epoch 1252, Loss: 0.0032805468363221735, Final Batch Loss: 0.00015701208030804992\n",
      "Epoch 1253, Loss: 0.012113199598388746, Final Batch Loss: 0.0014837912749499083\n",
      "Epoch 1254, Loss: 0.0021408924512797967, Final Batch Loss: 0.000879986269865185\n",
      "Epoch 1255, Loss: 0.0030665779631817713, Final Batch Loss: 0.0003469299408607185\n",
      "Epoch 1256, Loss: 0.0025708024768391624, Final Batch Loss: 0.00011937979434151202\n",
      "Epoch 1257, Loss: 0.012648801668547094, Final Batch Loss: 0.006520330905914307\n",
      "Epoch 1258, Loss: 0.0016691042837919667, Final Batch Loss: 0.00015537612489424646\n",
      "Epoch 1259, Loss: 0.003098827859503217, Final Batch Loss: 0.00011277843441348523\n",
      "Epoch 1260, Loss: 0.03633080728468485, Final Batch Loss: 0.0003021204611286521\n",
      "Epoch 1261, Loss: 0.00792376371100545, Final Batch Loss: 0.00046450269292108715\n",
      "Epoch 1262, Loss: 0.0016778030585555825, Final Batch Loss: 5.1901271945098415e-05\n",
      "Epoch 1263, Loss: 0.002488339931005612, Final Batch Loss: 0.0004921458312310278\n",
      "Epoch 1264, Loss: 0.004190593579551205, Final Batch Loss: 0.0010369967203587294\n",
      "Epoch 1265, Loss: 0.0017451809108024463, Final Batch Loss: 0.0005084090516902506\n",
      "Epoch 1266, Loss: 0.018010430030699354, Final Batch Loss: 0.0018932452658191323\n",
      "Epoch 1267, Loss: 0.0029043076356174424, Final Batch Loss: 0.0006980327889323235\n",
      "Epoch 1268, Loss: 0.005659424787154421, Final Batch Loss: 0.000146912265336141\n",
      "Epoch 1269, Loss: 0.04440342093585059, Final Batch Loss: 0.008457829244434834\n",
      "Epoch 1270, Loss: 0.0031991498472052626, Final Batch Loss: 0.00010400526662124321\n",
      "Epoch 1271, Loss: 0.04109043933021894, Final Batch Loss: 0.04074437916278839\n",
      "Epoch 1272, Loss: 0.016557338574784808, Final Batch Loss: 0.00020184255845379084\n",
      "Epoch 1273, Loss: 0.0018714401521719992, Final Batch Loss: 0.0009105025674216449\n",
      "Epoch 1274, Loss: 0.006082360225263983, Final Batch Loss: 0.0014970684424042702\n",
      "Epoch 1275, Loss: 0.0018544573395047337, Final Batch Loss: 0.0004993383772671223\n",
      "Epoch 1276, Loss: 0.006352841039188206, Final Batch Loss: 0.00021333358017727733\n",
      "Epoch 1277, Loss: 0.008207802020478994, Final Batch Loss: 0.002594543853774667\n",
      "Epoch 1278, Loss: 0.0018900213035522029, Final Batch Loss: 0.00018587593513075262\n",
      "Epoch 1279, Loss: 0.01604922185651958, Final Batch Loss: 0.00022585777333006263\n",
      "Epoch 1280, Loss: 0.005254592440905981, Final Batch Loss: 0.00044350113603286445\n",
      "Epoch 1281, Loss: 0.018770409165881574, Final Batch Loss: 0.000703166238963604\n",
      "Epoch 1282, Loss: 0.007059529743855819, Final Batch Loss: 0.0003421098517719656\n",
      "Epoch 1283, Loss: 0.005394086823798716, Final Batch Loss: 0.0032856690231710672\n",
      "Epoch 1284, Loss: 0.003803287137998268, Final Batch Loss: 0.0007963585085235536\n",
      "Epoch 1285, Loss: 0.009284125204430893, Final Batch Loss: 0.0029546418227255344\n",
      "Epoch 1286, Loss: 0.00448135623082635, Final Batch Loss: 0.0015336330980062485\n",
      "Epoch 1287, Loss: 0.00814072102366481, Final Batch Loss: 0.000541538989637047\n",
      "Epoch 1288, Loss: 0.002808594348607585, Final Batch Loss: 0.000882202060893178\n",
      "Epoch 1289, Loss: 0.0031600641668774188, Final Batch Loss: 0.00024595577269792557\n",
      "Epoch 1290, Loss: 0.0019065976375713944, Final Batch Loss: 0.00021272702724672854\n",
      "Epoch 1291, Loss: 0.014836259564617649, Final Batch Loss: 0.001010159496217966\n",
      "Epoch 1292, Loss: 0.003432002165936865, Final Batch Loss: 0.002400539815425873\n",
      "Epoch 1293, Loss: 0.003410472010727972, Final Batch Loss: 0.0010176884243264794\n",
      "Epoch 1294, Loss: 0.004457267525140196, Final Batch Loss: 0.0030726678669452667\n",
      "Epoch 1295, Loss: 0.0013962084340164438, Final Batch Loss: 0.000557507446501404\n",
      "Epoch 1296, Loss: 0.003515089541906491, Final Batch Loss: 0.001962515292689204\n",
      "Epoch 1297, Loss: 0.0014859999937471002, Final Batch Loss: 0.0003703995025716722\n",
      "Epoch 1298, Loss: 0.0032390783599112183, Final Batch Loss: 0.0004727404739242047\n",
      "Epoch 1299, Loss: 0.0013805832422804087, Final Batch Loss: 0.0005618270370177925\n",
      "Epoch 1300, Loss: 0.0017077199299819767, Final Batch Loss: 0.0004613966157194227\n",
      "Epoch 1301, Loss: 0.005640086295898072, Final Batch Loss: 0.0034244852140545845\n",
      "Epoch 1302, Loss: 0.004898170300293714, Final Batch Loss: 0.0004837293236050755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1303, Loss: 0.0019075802938459674, Final Batch Loss: 2.3000591681920923e-05\n",
      "Epoch 1304, Loss: 0.0008375945326406509, Final Batch Loss: 0.0002502370625734329\n",
      "Epoch 1305, Loss: 0.029933013785921503, Final Batch Loss: 0.00011586514301598072\n",
      "Epoch 1306, Loss: 0.004233262006891891, Final Batch Loss: 0.0014223448233678937\n",
      "Epoch 1307, Loss: 0.005754144607635681, Final Batch Loss: 6.200996722327545e-05\n",
      "Epoch 1308, Loss: 0.002086114516714588, Final Batch Loss: 0.0005451969336718321\n",
      "Epoch 1309, Loss: 0.0030732126033399254, Final Batch Loss: 0.0001693198282737285\n",
      "Epoch 1310, Loss: 0.03754918931372231, Final Batch Loss: 0.00010932058648904786\n",
      "Epoch 1311, Loss: 0.004052039148518816, Final Batch Loss: 0.00014269773964770138\n",
      "Epoch 1312, Loss: 0.013319160585524514, Final Batch Loss: 0.00028307430329732597\n",
      "Epoch 1313, Loss: 0.005495021439855918, Final Batch Loss: 0.0007629587780684233\n",
      "Epoch 1314, Loss: 0.003952461640437832, Final Batch Loss: 5.3983672842150554e-05\n",
      "Epoch 1315, Loss: 0.0016855966532602906, Final Batch Loss: 0.00042988130007870495\n",
      "Epoch 1316, Loss: 0.021211725877947174, Final Batch Loss: 0.0170737411826849\n",
      "Epoch 1317, Loss: 0.0033700765707180835, Final Batch Loss: 0.0012179255718365312\n",
      "Epoch 1318, Loss: 0.002163595363526838, Final Batch Loss: 2.8435246349545196e-05\n",
      "Epoch 1319, Loss: 0.013676024245796725, Final Batch Loss: 0.0013188874581828713\n",
      "Epoch 1320, Loss: 0.0012489928703871556, Final Batch Loss: 5.705405055778101e-05\n",
      "Epoch 1321, Loss: 0.0029640552202181425, Final Batch Loss: 5.793937816633843e-05\n",
      "Epoch 1322, Loss: 0.002251668687677011, Final Batch Loss: 0.0009144232608377934\n",
      "Epoch 1323, Loss: 0.02661421408993192, Final Batch Loss: 0.0003685281553771347\n",
      "Epoch 1324, Loss: 0.0027586329670157284, Final Batch Loss: 6.397449760697782e-05\n",
      "Epoch 1325, Loss: 0.002592582954093814, Final Batch Loss: 0.000272226519882679\n",
      "Epoch 1326, Loss: 0.012056798106641509, Final Batch Loss: 0.000963441445492208\n",
      "Epoch 1327, Loss: 0.003409079392440617, Final Batch Loss: 0.0010722604347392917\n",
      "Epoch 1328, Loss: 0.021305847534677014, Final Batch Loss: 0.0026218409184366465\n",
      "Epoch 1329, Loss: 0.006095678196288645, Final Batch Loss: 0.001014693989418447\n",
      "Epoch 1330, Loss: 0.0034416690177749842, Final Batch Loss: 0.0016737496480345726\n",
      "Epoch 1331, Loss: 0.001323053176747635, Final Batch Loss: 0.0003177046019118279\n",
      "Epoch 1332, Loss: 0.0010203816491411999, Final Batch Loss: 0.00016442123160231858\n",
      "Epoch 1333, Loss: 0.0005970701240585186, Final Batch Loss: 8.211816020775586e-05\n",
      "Epoch 1334, Loss: 0.0016059166373452172, Final Batch Loss: 9.368204337079078e-05\n",
      "Epoch 1335, Loss: 0.001398725427861791, Final Batch Loss: 0.00017521611880511045\n",
      "Epoch 1336, Loss: 0.0014048285956960171, Final Batch Loss: 0.0002107568725477904\n",
      "Epoch 1337, Loss: 0.008593040649429895, Final Batch Loss: 0.004238313529640436\n",
      "Epoch 1338, Loss: 0.002289758231199812, Final Batch Loss: 0.00028439483139663935\n",
      "Epoch 1339, Loss: 0.0061486825288739055, Final Batch Loss: 0.0004637146776076406\n",
      "Epoch 1340, Loss: 0.0019257890526205301, Final Batch Loss: 0.0003903532342519611\n",
      "Epoch 1341, Loss: 0.003029027400771156, Final Batch Loss: 0.00011679722229018807\n",
      "Epoch 1342, Loss: 0.01337981820688583, Final Batch Loss: 0.012123838998377323\n",
      "Epoch 1343, Loss: 0.0008185017723008059, Final Batch Loss: 0.00034706539008766413\n",
      "Epoch 1344, Loss: 0.0012860015194746666, Final Batch Loss: 0.0006500466843135655\n",
      "Epoch 1345, Loss: 0.010409313952550292, Final Batch Loss: 0.00028858432779088616\n",
      "Epoch 1346, Loss: 0.002614234166685492, Final Batch Loss: 0.001610808540135622\n",
      "Epoch 1347, Loss: 0.0021876742248423398, Final Batch Loss: 0.0007329313666559756\n",
      "Epoch 1348, Loss: 0.009597613476216793, Final Batch Loss: 0.004195821937173605\n",
      "Epoch 1349, Loss: 0.005361253919545561, Final Batch Loss: 0.0008528110338374972\n",
      "Epoch 1350, Loss: 0.001291883731028065, Final Batch Loss: 0.0005850807065144181\n",
      "Epoch 1351, Loss: 0.0033667088646325283, Final Batch Loss: 0.0017127266619354486\n",
      "Epoch 1352, Loss: 0.0031809701467864215, Final Batch Loss: 0.0007773168035782874\n",
      "Epoch 1353, Loss: 0.06104382716875989, Final Batch Loss: 0.05965267866849899\n",
      "Epoch 1354, Loss: 0.0016037027526181191, Final Batch Loss: 0.0004093211318831891\n",
      "Epoch 1355, Loss: 0.0012959998566657305, Final Batch Loss: 0.00020132555800955743\n",
      "Epoch 1356, Loss: 0.0029009854843025096, Final Batch Loss: 0.0006304181297309697\n",
      "Epoch 1357, Loss: 0.009760357352206483, Final Batch Loss: 0.0035691051743924618\n",
      "Epoch 1358, Loss: 0.0017136690148618072, Final Batch Loss: 0.0003050306986551732\n",
      "Epoch 1359, Loss: 0.032123696291819215, Final Batch Loss: 0.023182915523648262\n",
      "Epoch 1360, Loss: 0.003599633608246222, Final Batch Loss: 0.0015606158412992954\n",
      "Epoch 1361, Loss: 0.001672736680120579, Final Batch Loss: 2.3485275960410945e-05\n",
      "Epoch 1362, Loss: 0.021755052206572145, Final Batch Loss: 0.0014477272052317858\n",
      "Epoch 1363, Loss: 0.002007989416597411, Final Batch Loss: 0.00012485060142353177\n",
      "Epoch 1364, Loss: 0.0021961935563012958, Final Batch Loss: 0.0010332352248951793\n",
      "Epoch 1365, Loss: 0.0018697351188166067, Final Batch Loss: 0.00020566261082421988\n",
      "Epoch 1366, Loss: 0.0024899315321817994, Final Batch Loss: 0.0003849522036034614\n",
      "Epoch 1367, Loss: 0.008390880597289652, Final Batch Loss: 0.0003254100738558918\n",
      "Epoch 1368, Loss: 0.001302983524510637, Final Batch Loss: 0.0001291636290261522\n",
      "Epoch 1369, Loss: 0.002002198751142714, Final Batch Loss: 6.314341590041295e-05\n",
      "Epoch 1370, Loss: 0.0018589845567476004, Final Batch Loss: 0.0003557119925972074\n",
      "Epoch 1371, Loss: 0.004821669092052616, Final Batch Loss: 0.0006205282988958061\n",
      "Epoch 1372, Loss: 0.013639205295476131, Final Batch Loss: 0.00023970480833668262\n",
      "Epoch 1373, Loss: 0.003606578611652367, Final Batch Loss: 0.002764353761449456\n",
      "Epoch 1374, Loss: 0.007207369431853294, Final Batch Loss: 0.00024745409609749913\n",
      "Epoch 1375, Loss: 0.005831063070218079, Final Batch Loss: 0.005390421021729708\n",
      "Epoch 1376, Loss: 0.004064903572725598, Final Batch Loss: 0.0036431550979614258\n",
      "Epoch 1377, Loss: 0.0037883165568928234, Final Batch Loss: 0.00010287913028150797\n",
      "Epoch 1378, Loss: 0.0014727323214174248, Final Batch Loss: 0.000692240078933537\n",
      "Epoch 1379, Loss: 0.007687507008085959, Final Batch Loss: 0.00014428496069740504\n",
      "Epoch 1380, Loss: 0.004338750877650455, Final Batch Loss: 0.0002998670097440481\n",
      "Epoch 1381, Loss: 0.006926973568624817, Final Batch Loss: 0.00016355657135136425\n",
      "Epoch 1382, Loss: 0.01956241783045698, Final Batch Loss: 0.00013401012984104455\n",
      "Epoch 1383, Loss: 0.002439005140331574, Final Batch Loss: 0.00012574062566272914\n",
      "Epoch 1384, Loss: 0.005486336565809324, Final Batch Loss: 0.00024665819364599884\n",
      "Epoch 1385, Loss: 0.0211555928690359, Final Batch Loss: 0.000800383451860398\n",
      "Epoch 1386, Loss: 0.001739874656777829, Final Batch Loss: 0.00041511846939101815\n",
      "Epoch 1387, Loss: 0.0030276677280198783, Final Batch Loss: 0.0005907344166189432\n",
      "Epoch 1388, Loss: 0.013513596510165371, Final Batch Loss: 4.2643965571187437e-05\n",
      "Epoch 1389, Loss: 0.0036901118874084204, Final Batch Loss: 0.0006377462996169925\n",
      "Epoch 1390, Loss: 0.0021511647501029074, Final Batch Loss: 0.0007918928167782724\n",
      "Epoch 1391, Loss: 0.0029046899144304916, Final Batch Loss: 0.0007730001234449446\n",
      "Epoch 1392, Loss: 0.0017377367476001382, Final Batch Loss: 0.0004320498264860362\n",
      "Epoch 1393, Loss: 0.0017634695104788989, Final Batch Loss: 0.0010540903313085437\n",
      "Epoch 1394, Loss: 0.002085691136016976, Final Batch Loss: 0.00107861019205302\n",
      "Epoch 1395, Loss: 0.003146517548884731, Final Batch Loss: 0.0007375033455900848\n",
      "Epoch 1396, Loss: 0.002940674778074026, Final Batch Loss: 0.00021746456332039088\n",
      "Epoch 1397, Loss: 0.0026610240893205628, Final Batch Loss: 0.000579685962293297\n",
      "Epoch 1398, Loss: 0.0014236467177397572, Final Batch Loss: 5.925737787038088e-05\n",
      "Epoch 1399, Loss: 0.00868371850810945, Final Batch Loss: 0.007430525496602058\n",
      "Epoch 1400, Loss: 0.003440860178670846, Final Batch Loss: 0.000217932989471592\n",
      "Epoch 1401, Loss: 0.003834072340396233, Final Batch Loss: 0.0009123004856519401\n",
      "Epoch 1402, Loss: 0.0016185478652914753, Final Batch Loss: 2.2868835003464483e-05\n",
      "Epoch 1403, Loss: 0.0012483769678510725, Final Batch Loss: 9.707749268272892e-05\n",
      "Epoch 1404, Loss: 0.0013766769407084212, Final Batch Loss: 0.00046560922055505216\n",
      "Epoch 1405, Loss: 0.008704459105501883, Final Batch Loss: 0.00014984546578489244\n",
      "Epoch 1406, Loss: 0.0023528056335635483, Final Batch Loss: 0.001117585925385356\n",
      "Epoch 1407, Loss: 0.0009968146914616227, Final Batch Loss: 0.0005185033078305423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1408, Loss: 0.015520804190600757, Final Batch Loss: 0.0002107957552652806\n",
      "Epoch 1409, Loss: 0.00104936194838956, Final Batch Loss: 0.0001615684450371191\n",
      "Epoch 1410, Loss: 0.00458395984605886, Final Batch Loss: 0.00023893025354482234\n",
      "Epoch 1411, Loss: 0.003200589031621348, Final Batch Loss: 0.0002949414774775505\n",
      "Epoch 1412, Loss: 0.0026365088706370443, Final Batch Loss: 0.00038692806265316904\n",
      "Epoch 1413, Loss: 0.00249526491825236, Final Batch Loss: 6.169018888613209e-05\n",
      "Epoch 1414, Loss: 0.001842444427893497, Final Batch Loss: 7.649784674867988e-05\n",
      "Epoch 1415, Loss: 0.0010119342914549634, Final Batch Loss: 0.0001418212486896664\n",
      "Epoch 1416, Loss: 0.0016758133115217788, Final Batch Loss: 0.00046182755613699555\n",
      "Epoch 1417, Loss: 0.004373314914118964, Final Batch Loss: 0.0008050860487855971\n",
      "Epoch 1418, Loss: 0.00031475338255404495, Final Batch Loss: 0.00014053266204427928\n",
      "Epoch 1419, Loss: 0.0031403595057781786, Final Batch Loss: 0.002343835774809122\n",
      "Epoch 1420, Loss: 0.0008336008268088335, Final Batch Loss: 2.7047100957133807e-05\n",
      "Epoch 1421, Loss: 0.00025744310732989106, Final Batch Loss: 6.71689776936546e-05\n",
      "Epoch 1422, Loss: 0.0015665248793084174, Final Batch Loss: 0.0002667548833414912\n",
      "Epoch 1423, Loss: 0.011066290237067733, Final Batch Loss: 0.008736008778214455\n",
      "Epoch 1424, Loss: 0.002063084175460972, Final Batch Loss: 0.00023865090042818338\n",
      "Epoch 1425, Loss: 0.0005706702286261134, Final Batch Loss: 0.00012668216368183494\n",
      "Epoch 1426, Loss: 0.00040275488208862953, Final Batch Loss: 0.00018697766063269228\n",
      "Epoch 1427, Loss: 0.003951554361265153, Final Batch Loss: 0.0018408918986096978\n",
      "Epoch 1428, Loss: 0.006908782863320084, Final Batch Loss: 0.0005135657265782356\n",
      "Epoch 1429, Loss: 0.0010198239469900727, Final Batch Loss: 1.6021986084524542e-05\n",
      "Epoch 1430, Loss: 0.0007157684376579709, Final Batch Loss: 7.49043028918095e-05\n",
      "Epoch 1431, Loss: 0.003653002087958157, Final Batch Loss: 0.002872378332540393\n",
      "Epoch 1432, Loss: 0.011979619637713768, Final Batch Loss: 0.004937929101288319\n",
      "Epoch 1433, Loss: 0.001741586733260192, Final Batch Loss: 0.0004676140670198947\n",
      "Epoch 1434, Loss: 0.0016558165079914033, Final Batch Loss: 0.00022441662440542132\n",
      "Epoch 1435, Loss: 0.0008859398258209694, Final Batch Loss: 4.627522503142245e-05\n",
      "Epoch 1436, Loss: 0.000738493945391383, Final Batch Loss: 0.00027853145729750395\n",
      "Epoch 1437, Loss: 0.003316131071187556, Final Batch Loss: 0.0019758089911192656\n",
      "Epoch 1438, Loss: 0.01127153859124519, Final Batch Loss: 0.009376708418130875\n",
      "Epoch 1439, Loss: 0.0007949624050525017, Final Batch Loss: 0.00013040134217590094\n",
      "Epoch 1440, Loss: 0.002552416372054722, Final Batch Loss: 0.001453713746741414\n",
      "Epoch 1441, Loss: 0.0031329632947745267, Final Batch Loss: 0.00028953797300346196\n",
      "Epoch 1442, Loss: 0.0009075889829546213, Final Batch Loss: 0.000169509687111713\n",
      "Epoch 1443, Loss: 0.003624277225753758, Final Batch Loss: 0.0033676461316645145\n",
      "Epoch 1444, Loss: 0.0016364876901207026, Final Batch Loss: 0.00011862297833431512\n",
      "Epoch 1445, Loss: 0.0009154068320640363, Final Batch Loss: 0.00014821652439422905\n",
      "Epoch 1446, Loss: 0.002066254230157938, Final Batch Loss: 0.00019075634190812707\n",
      "Epoch 1447, Loss: 0.00039613992703380063, Final Batch Loss: 8.974840602604672e-05\n",
      "Epoch 1448, Loss: 0.00213945799805515, Final Batch Loss: 0.0015831617638468742\n",
      "Epoch 1449, Loss: 0.00458171046921052, Final Batch Loss: 0.0013011679984629154\n",
      "Epoch 1450, Loss: 0.0018191342533100396, Final Batch Loss: 6.23999658273533e-05\n",
      "Epoch 1451, Loss: 0.0025508513645036146, Final Batch Loss: 0.0014789861161261797\n",
      "Epoch 1452, Loss: 0.01729642739519477, Final Batch Loss: 0.000411643908591941\n",
      "Epoch 1453, Loss: 0.0006644620243605459, Final Batch Loss: 0.00034557393519207835\n",
      "Epoch 1454, Loss: 0.0014143403204798233, Final Batch Loss: 0.00014835629553999752\n",
      "Epoch 1455, Loss: 0.005293088852340588, Final Batch Loss: 0.0037654300685971975\n",
      "Epoch 1456, Loss: 0.006528171146783279, Final Batch Loss: 2.3224918550113216e-05\n",
      "Epoch 1457, Loss: 0.0046810971543891355, Final Batch Loss: 0.0018107801442965865\n",
      "Epoch 1458, Loss: 0.0070768281948403455, Final Batch Loss: 7.06110949977301e-05\n",
      "Epoch 1459, Loss: 0.0003798923753493, Final Batch Loss: 7.711208309046924e-05\n",
      "Epoch 1460, Loss: 0.01632679749309318, Final Batch Loss: 0.001763732056133449\n",
      "Epoch 1461, Loss: 0.0018638135079527274, Final Batch Loss: 0.00014855658810120076\n",
      "Epoch 1462, Loss: 0.005249236557574477, Final Batch Loss: 2.1838997781742364e-05\n",
      "Epoch 1463, Loss: 0.0009497028149780817, Final Batch Loss: 0.0004878155596088618\n",
      "Epoch 1464, Loss: 0.0006706920030410402, Final Batch Loss: 0.00017237410065717995\n",
      "Epoch 1465, Loss: 0.011511152362800203, Final Batch Loss: 0.0001164348068414256\n",
      "Epoch 1466, Loss: 0.0006302182646322763, Final Batch Loss: 1.4644267139374278e-05\n",
      "Epoch 1467, Loss: 0.0029383655837591505, Final Batch Loss: 0.002613426186144352\n",
      "Epoch 1468, Loss: 0.0012322227521508466, Final Batch Loss: 0.00013240694534033537\n",
      "Epoch 1469, Loss: 0.004380679893074557, Final Batch Loss: 0.0019235007930547\n",
      "Epoch 1470, Loss: 0.001464133410991053, Final Batch Loss: 0.0005945111624896526\n",
      "Epoch 1471, Loss: 0.0010089604102176963, Final Batch Loss: 0.0003884264442604035\n",
      "Epoch 1472, Loss: 0.0007567283464595675, Final Batch Loss: 0.00032062080572359264\n",
      "Epoch 1473, Loss: 0.0006409276757040061, Final Batch Loss: 8.383530075661838e-05\n",
      "Epoch 1474, Loss: 0.001340688355412567, Final Batch Loss: 5.107818651595153e-05\n",
      "Epoch 1475, Loss: 0.0014523125973937567, Final Batch Loss: 0.00019647341105155647\n",
      "Epoch 1476, Loss: 0.0028380530329741305, Final Batch Loss: 3.2729025406297296e-05\n",
      "Epoch 1477, Loss: 0.0037827704509254545, Final Batch Loss: 0.0005485749570652843\n",
      "Epoch 1478, Loss: 0.0004615330308297416, Final Batch Loss: 0.00016185521963052452\n",
      "Epoch 1479, Loss: 0.06472407047112938, Final Batch Loss: 0.00012736509961541742\n",
      "Epoch 1480, Loss: 0.0016996062677208101, Final Batch Loss: 2.2298416297417134e-05\n",
      "Epoch 1481, Loss: 0.0017145600213552825, Final Batch Loss: 0.0004920487408526242\n",
      "Epoch 1482, Loss: 0.0007537777055404149, Final Batch Loss: 0.00021769102022517473\n",
      "Epoch 1483, Loss: 0.0023294796483241953, Final Batch Loss: 0.00041864984086714685\n",
      "Epoch 1484, Loss: 0.0019370555091882125, Final Batch Loss: 0.00023561982379760593\n",
      "Epoch 1485, Loss: 0.0021723858881159686, Final Batch Loss: 0.0006271769525483251\n",
      "Epoch 1486, Loss: 0.003373387509782333, Final Batch Loss: 0.0025852967519313097\n",
      "Epoch 1487, Loss: 0.0027286178919894155, Final Batch Loss: 0.0024623617064207792\n",
      "Epoch 1488, Loss: 0.003011798340594396, Final Batch Loss: 0.0017305989749729633\n",
      "Epoch 1489, Loss: 0.004124251921894029, Final Batch Loss: 0.00025091925635933876\n",
      "Epoch 1490, Loss: 0.0015312032555812038, Final Batch Loss: 0.0008830378064885736\n",
      "Epoch 1491, Loss: 0.0005438810258056037, Final Batch Loss: 0.00018005265155807137\n",
      "Epoch 1492, Loss: 0.0008577301159675699, Final Batch Loss: 0.00037461717147380114\n",
      "Epoch 1493, Loss: 0.0016730695642763749, Final Batch Loss: 0.00037586636608466506\n",
      "Epoch 1494, Loss: 0.002151658365619369, Final Batch Loss: 4.6194974856916815e-05\n",
      "Epoch 1495, Loss: 0.0020154539961367846, Final Batch Loss: 0.0010248476173728704\n",
      "Epoch 1496, Loss: 0.0006261634716793196, Final Batch Loss: 0.00011301191989332438\n",
      "Epoch 1497, Loss: 0.001654478612181265, Final Batch Loss: 0.00010500135977054015\n",
      "Epoch 1498, Loss: 0.0015147372432693373, Final Batch Loss: 0.0010046891402453184\n",
      "Epoch 1499, Loss: 0.0010085449030157179, Final Batch Loss: 0.0008483187411911786\n",
      "Epoch 1500, Loss: 0.032420525665656896, Final Batch Loss: 5.956027962383814e-05\n",
      "Epoch 1501, Loss: 0.00149503117063432, Final Batch Loss: 5.084737131255679e-05\n",
      "Epoch 1502, Loss: 0.004696172640251461, Final Batch Loss: 0.0038800889160484076\n",
      "Epoch 1503, Loss: 0.005746808663388947, Final Batch Loss: 1.189404065371491e-05\n",
      "Epoch 1504, Loss: 0.000641458895188407, Final Batch Loss: 0.00020188934286125004\n",
      "Epoch 1505, Loss: 0.001118636610044632, Final Batch Loss: 0.0008694021962583065\n",
      "Epoch 1506, Loss: 0.0012749130601150682, Final Batch Loss: 9.703769319457933e-05\n",
      "Epoch 1507, Loss: 0.002240072310087271, Final Batch Loss: 4.4234751840122044e-05\n",
      "Epoch 1508, Loss: 0.0009428572957403958, Final Batch Loss: 0.00013185900752432644\n",
      "Epoch 1509, Loss: 0.018482983410649467, Final Batch Loss: 0.00012755159696098417\n",
      "Epoch 1510, Loss: 0.02187495122780092, Final Batch Loss: 0.016296248883008957\n",
      "Epoch 1511, Loss: 0.0035640896276163403, Final Batch Loss: 3.611325882957317e-05\n",
      "Epoch 1512, Loss: 0.0011604802712099627, Final Batch Loss: 4.769968654727563e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1513, Loss: 0.006423035069019534, Final Batch Loss: 0.00015631852147635072\n",
      "Epoch 1514, Loss: 0.03254524229851086, Final Batch Loss: 0.001021563308313489\n",
      "Epoch 1515, Loss: 0.019296369922813028, Final Batch Loss: 0.00045048422180116177\n",
      "Epoch 1516, Loss: 0.011276478860963834, Final Batch Loss: 4.329345756559633e-05\n",
      "Epoch 1517, Loss: 0.0005963217263342813, Final Batch Loss: 8.259747846750543e-05\n",
      "Epoch 1518, Loss: 0.004234449646901339, Final Batch Loss: 0.0026133039500564337\n",
      "Epoch 1519, Loss: 0.0063221371892723255, Final Batch Loss: 0.00570277776569128\n",
      "Epoch 1520, Loss: 0.006705596671963576, Final Batch Loss: 0.006000468507409096\n",
      "Epoch 1521, Loss: 0.0032302009203704074, Final Batch Loss: 0.00012759958917740732\n",
      "Epoch 1522, Loss: 0.009653880719270092, Final Batch Loss: 0.0026906896382570267\n",
      "Epoch 1523, Loss: 0.006584934322745539, Final Batch Loss: 0.0001358592271571979\n",
      "Epoch 1524, Loss: 0.0025169674190692604, Final Batch Loss: 0.00046388263581320643\n",
      "Epoch 1525, Loss: 0.01301789629360428, Final Batch Loss: 0.011956115253269672\n",
      "Epoch 1526, Loss: 0.020548938657157123, Final Batch Loss: 0.0007748648058623075\n",
      "Epoch 1527, Loss: 0.013103056182444561, Final Batch Loss: 8.74628676683642e-05\n",
      "Epoch 1528, Loss: 0.003077700050198473, Final Batch Loss: 0.00045668031089007854\n",
      "Epoch 1529, Loss: 0.0036089961358811706, Final Batch Loss: 0.00223750458098948\n",
      "Epoch 1530, Loss: 0.0019488480575091671, Final Batch Loss: 0.0008504912257194519\n",
      "Epoch 1531, Loss: 0.0042355560944997706, Final Batch Loss: 0.0010921130888164043\n",
      "Epoch 1532, Loss: 0.0026242097083013505, Final Batch Loss: 0.00045315545867197216\n",
      "Epoch 1533, Loss: 0.0014278157177614048, Final Batch Loss: 0.000442052521975711\n",
      "Epoch 1534, Loss: 0.002087734028464183, Final Batch Loss: 0.0005807075649499893\n",
      "Epoch 1535, Loss: 0.0025589263532310724, Final Batch Loss: 0.0003214020689483732\n",
      "Epoch 1536, Loss: 0.011448335622844752, Final Batch Loss: 0.0003345588338561356\n",
      "Epoch 1537, Loss: 0.007238573023641948, Final Batch Loss: 0.0001597138325450942\n",
      "Epoch 1538, Loss: 0.0047888568878988735, Final Batch Loss: 0.0012788608437404037\n",
      "Epoch 1539, Loss: 0.0009127332959906198, Final Batch Loss: 0.0003188383998349309\n",
      "Epoch 1540, Loss: 0.00034152746229665354, Final Batch Loss: 3.3199852623511106e-05\n",
      "Epoch 1541, Loss: 0.001373978186165914, Final Batch Loss: 0.00030164149939082563\n",
      "Epoch 1542, Loss: 0.003559740580385551, Final Batch Loss: 0.0003348602040205151\n",
      "Epoch 1543, Loss: 0.002741914431680925, Final Batch Loss: 9.837806283030659e-05\n",
      "Epoch 1544, Loss: 0.001416758583218325, Final Batch Loss: 7.95403029769659e-05\n",
      "Epoch 1545, Loss: 0.001928627403685823, Final Batch Loss: 0.00028073490830138326\n",
      "Epoch 1546, Loss: 0.004280826849935693, Final Batch Loss: 2.3267131837201305e-05\n",
      "Epoch 1547, Loss: 0.0007323831287067151, Final Batch Loss: 2.4521044906578027e-05\n",
      "Epoch 1548, Loss: 0.0010936081962427124, Final Batch Loss: 6.91934983478859e-05\n",
      "Epoch 1549, Loss: 0.0018695302278501913, Final Batch Loss: 0.0005807192646898329\n",
      "Epoch 1550, Loss: 0.0004338785038271453, Final Batch Loss: 1.9037015590583906e-05\n",
      "Epoch 1551, Loss: 0.0005952952487859875, Final Batch Loss: 1.6125253750942647e-05\n",
      "Epoch 1552, Loss: 0.004689504516136367, Final Batch Loss: 0.0001360551395919174\n",
      "Epoch 1553, Loss: 0.0051726968013099395, Final Batch Loss: 2.944784500868991e-05\n",
      "Epoch 1554, Loss: 0.0011461077956482768, Final Batch Loss: 0.000637500430457294\n",
      "Epoch 1555, Loss: 0.0018052599189104512, Final Batch Loss: 5.212517862673849e-05\n",
      "Epoch 1556, Loss: 0.009736621992487926, Final Batch Loss: 7.354445551754907e-05\n",
      "Epoch 1557, Loss: 0.0037699710665037856, Final Batch Loss: 3.991763514932245e-05\n",
      "Epoch 1558, Loss: 0.018130905729776714, Final Batch Loss: 0.016119958832859993\n",
      "Epoch 1559, Loss: 0.0033412964330636896, Final Batch Loss: 6.382712308550254e-05\n",
      "Epoch 1560, Loss: 0.0017782684553822037, Final Batch Loss: 0.00010355392441852018\n",
      "Epoch 1561, Loss: 0.0013600397214759141, Final Batch Loss: 6.177213072078303e-05\n",
      "Epoch 1562, Loss: 0.0052773415663978085, Final Batch Loss: 0.0011504915310069919\n",
      "Epoch 1563, Loss: 0.002182395866839215, Final Batch Loss: 0.0007112447055988014\n",
      "Epoch 1564, Loss: 0.0010606766736600548, Final Batch Loss: 0.0005623174947686493\n",
      "Epoch 1565, Loss: 0.0021344299930206034, Final Batch Loss: 0.00013337172276806086\n",
      "Epoch 1566, Loss: 0.0010202875928371213, Final Batch Loss: 7.92276332504116e-05\n",
      "Epoch 1567, Loss: 0.0026883964383159764, Final Batch Loss: 0.0002148604835383594\n",
      "Epoch 1568, Loss: 0.0007265141175594181, Final Batch Loss: 0.0004245975287631154\n",
      "Epoch 1569, Loss: 0.0017605094180908054, Final Batch Loss: 0.0005716934101656079\n",
      "Epoch 1570, Loss: 0.0013090353513689479, Final Batch Loss: 3.7665380659746006e-05\n",
      "Epoch 1571, Loss: 0.0025975650059990585, Final Batch Loss: 0.00013024000509176403\n",
      "Epoch 1572, Loss: 0.0030514572845277144, Final Batch Loss: 0.0008250711834989488\n",
      "Epoch 1573, Loss: 0.0006065068737370893, Final Batch Loss: 0.00023487844737246633\n",
      "Epoch 1574, Loss: 0.004179044928605435, Final Batch Loss: 0.003914475440979004\n",
      "Epoch 1575, Loss: 0.0012675239813688677, Final Batch Loss: 5.2712504839291796e-05\n",
      "Epoch 1576, Loss: 0.00036745921715919394, Final Batch Loss: 2.1286969058564864e-05\n",
      "Epoch 1577, Loss: 0.0032665926300978754, Final Batch Loss: 2.8237853257451206e-05\n",
      "Epoch 1578, Loss: 0.0010015160441980697, Final Batch Loss: 9.304787818109617e-05\n",
      "Epoch 1579, Loss: 0.00045351505832513794, Final Batch Loss: 6.163590296637267e-05\n",
      "Epoch 1580, Loss: 0.0007942743759485893, Final Batch Loss: 0.00016339580179192126\n",
      "Epoch 1581, Loss: 0.0010351825585530605, Final Batch Loss: 0.0004718966083601117\n",
      "Epoch 1582, Loss: 0.0007478962979803327, Final Batch Loss: 3.975565414293669e-05\n",
      "Epoch 1583, Loss: 0.0017862385866465047, Final Batch Loss: 0.00013352371752262115\n",
      "Epoch 1584, Loss: 0.0016932400394580327, Final Batch Loss: 0.0002500202681403607\n",
      "Epoch 1585, Loss: 0.00047244962479453534, Final Batch Loss: 8.837314089760184e-05\n",
      "Epoch 1586, Loss: 0.0009375643930980004, Final Batch Loss: 0.0005108237382955849\n",
      "Epoch 1587, Loss: 0.002094452502205968, Final Batch Loss: 0.00033143587643280625\n",
      "Epoch 1588, Loss: 0.0027745851875806693, Final Batch Loss: 0.0003884259203914553\n",
      "Epoch 1589, Loss: 0.0061351580698101316, Final Batch Loss: 0.002037476049736142\n",
      "Epoch 1590, Loss: 0.0006276895519476966, Final Batch Loss: 0.00019889457325916737\n",
      "Epoch 1591, Loss: 0.0022314329689834267, Final Batch Loss: 0.0006396790267899632\n",
      "Epoch 1592, Loss: 0.01507815501827281, Final Batch Loss: 0.0013857287121936679\n",
      "Epoch 1593, Loss: 0.0028905656945426017, Final Batch Loss: 0.0019387667998671532\n",
      "Epoch 1594, Loss: 0.0004988751607015729, Final Batch Loss: 2.538358239689842e-05\n",
      "Epoch 1595, Loss: 0.0008432784234173596, Final Batch Loss: 0.00014833960449323058\n",
      "Epoch 1596, Loss: 0.0017124443693319336, Final Batch Loss: 0.00046662864042446017\n",
      "Epoch 1597, Loss: 0.0034960626162501285, Final Batch Loss: 0.0032405925448983908\n",
      "Epoch 1598, Loss: 0.0001742491531331325, Final Batch Loss: 2.8830034352722578e-05\n",
      "Epoch 1599, Loss: 0.0009842394974839408, Final Batch Loss: 4.5908756874268875e-05\n",
      "Epoch 1600, Loss: 0.0014997749240137637, Final Batch Loss: 1.880501804407686e-05\n",
      "Epoch 1601, Loss: 0.0006488525832537562, Final Batch Loss: 9.598100587027147e-05\n",
      "Epoch 1602, Loss: 0.001147014419984771, Final Batch Loss: 0.00010246560123050585\n",
      "Epoch 1603, Loss: 0.0019454926314210752, Final Batch Loss: 2.2200836610863917e-05\n",
      "Epoch 1604, Loss: 0.00016351829071936663, Final Batch Loss: 5.244016392680351e-06\n",
      "Epoch 1605, Loss: 0.001157786226940516, Final Batch Loss: 9.268167923437431e-05\n",
      "Epoch 1606, Loss: 0.0007307863743335474, Final Batch Loss: 0.00044470952707342803\n",
      "Epoch 1607, Loss: 0.0024161543624359183, Final Batch Loss: 3.2586751331109554e-05\n",
      "Epoch 1608, Loss: 0.001180014156489051, Final Batch Loss: 0.00010529850260354578\n",
      "Epoch 1609, Loss: 0.0002444203091727104, Final Batch Loss: 4.730863292934373e-05\n",
      "Epoch 1610, Loss: 0.0011153295508847805, Final Batch Loss: 1.1918342352146283e-05\n",
      "Epoch 1611, Loss: 0.0005643727254209807, Final Batch Loss: 0.00023799615155439824\n",
      "Epoch 1612, Loss: 0.0036527745833154768, Final Batch Loss: 2.4365443096030504e-05\n",
      "Epoch 1613, Loss: 0.0003296193435744499, Final Batch Loss: 3.453784665907733e-05\n",
      "Epoch 1614, Loss: 0.0021333173135644756, Final Batch Loss: 0.000589907169342041\n",
      "Epoch 1615, Loss: 0.0012114053001823777, Final Batch Loss: 6.9651628109568264e-06\n",
      "Epoch 1616, Loss: 0.0007880664907133905, Final Batch Loss: 2.662672159203794e-05\n",
      "Epoch 1617, Loss: 0.0010075609134219121, Final Batch Loss: 0.0002493175270501524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1618, Loss: 0.00119035870739026, Final Batch Loss: 0.00013275207311380655\n",
      "Epoch 1619, Loss: 0.000653100956697017, Final Batch Loss: 5.005372076993808e-05\n",
      "Epoch 1620, Loss: 0.0005271909258226515, Final Batch Loss: 0.0002588283095974475\n",
      "Epoch 1621, Loss: 0.0037613033564412035, Final Batch Loss: 4.0177303162636235e-05\n",
      "Epoch 1622, Loss: 0.0012537621878436767, Final Batch Loss: 0.00011477509542601183\n",
      "Epoch 1623, Loss: 0.001172835250144999, Final Batch Loss: 0.0002930136979557574\n",
      "Epoch 1624, Loss: 0.0004652257784982794, Final Batch Loss: 7.90772264736006e-06\n",
      "Epoch 1625, Loss: 0.007720399946265388, Final Batch Loss: 0.005010959692299366\n",
      "Epoch 1626, Loss: 0.00659267207083758, Final Batch Loss: 0.0003852696972899139\n",
      "Epoch 1627, Loss: 0.001371548027236713, Final Batch Loss: 3.174836092512123e-05\n",
      "Epoch 1628, Loss: 0.029627728084960836, Final Batch Loss: 5.41826339031104e-05\n",
      "Epoch 1629, Loss: 0.000982582436336088, Final Batch Loss: 0.0005065000732429326\n",
      "Epoch 1630, Loss: 0.009660557905590395, Final Batch Loss: 0.0005855442141182721\n",
      "Epoch 1631, Loss: 0.0028021529578836635, Final Batch Loss: 9.071013482753187e-05\n",
      "Epoch 1632, Loss: 0.01582901347137522, Final Batch Loss: 0.0007353410474024713\n",
      "Epoch 1633, Loss: 0.0038855088569107465, Final Batch Loss: 0.003109921235591173\n",
      "Epoch 1634, Loss: 0.002402284062554827, Final Batch Loss: 2.6409998099552467e-05\n",
      "Epoch 1635, Loss: 0.004721002682799735, Final Batch Loss: 0.0001888771657831967\n",
      "Epoch 1636, Loss: 0.0012976062071174965, Final Batch Loss: 9.6272860901081e-06\n",
      "Epoch 1637, Loss: 0.025051752832951024, Final Batch Loss: 0.024444187059998512\n",
      "Epoch 1638, Loss: 0.00101388420080184, Final Batch Loss: 0.0005288219545036554\n",
      "Epoch 1639, Loss: 0.01821151387412101, Final Batch Loss: 0.0032470966689288616\n",
      "Epoch 1640, Loss: 0.02511103447614005, Final Batch Loss: 0.00026952673215419054\n",
      "Epoch 1641, Loss: 0.008911352953873575, Final Batch Loss: 5.4205494961934164e-05\n",
      "Epoch 1642, Loss: 0.012379012867313577, Final Batch Loss: 0.0047977399080991745\n",
      "Epoch 1643, Loss: 0.00046524878962372895, Final Batch Loss: 8.964807420852594e-06\n",
      "Epoch 1644, Loss: 0.004497907415498048, Final Batch Loss: 0.0001241385325556621\n",
      "Epoch 1645, Loss: 0.04866875788138714, Final Batch Loss: 0.003388793207705021\n",
      "Epoch 1646, Loss: 0.019639724217995536, Final Batch Loss: 5.441880057333037e-05\n",
      "Epoch 1647, Loss: 0.0006827749348303769, Final Batch Loss: 2.7441197744337842e-05\n",
      "Epoch 1648, Loss: 0.00039359632773994235, Final Batch Loss: 4.344623812357895e-05\n",
      "Epoch 1649, Loss: 0.00722945413144771, Final Batch Loss: 0.00038562322151847184\n",
      "Epoch 1650, Loss: 0.0012202772632008418, Final Batch Loss: 0.00039203910273499787\n",
      "Epoch 1651, Loss: 0.000809723642305471, Final Batch Loss: 0.00014964975707698613\n",
      "Epoch 1652, Loss: 0.005522219289559871, Final Batch Loss: 0.00014588786871172488\n",
      "Epoch 1653, Loss: 0.03998038473946508, Final Batch Loss: 0.00010477796604391187\n",
      "Epoch 1654, Loss: 0.00876749513190589, Final Batch Loss: 0.00020304507052060217\n",
      "Epoch 1655, Loss: 0.001576793296408141, Final Batch Loss: 3.020285294041969e-05\n",
      "Epoch 1656, Loss: 0.003983679984230548, Final Batch Loss: 0.0010601503308862448\n",
      "Epoch 1657, Loss: 0.0006026029295753688, Final Batch Loss: 0.0001757104037096724\n",
      "Epoch 1658, Loss: 0.0006213750602910295, Final Batch Loss: 7.813421689206734e-05\n",
      "Epoch 1659, Loss: 0.006181246804771945, Final Batch Loss: 0.004629124421626329\n",
      "Epoch 1660, Loss: 0.00215595144618419, Final Batch Loss: 3.083217961830087e-05\n",
      "Epoch 1661, Loss: 0.0005421105634013657, Final Batch Loss: 3.7783316656714305e-05\n",
      "Epoch 1662, Loss: 0.004193301880150102, Final Batch Loss: 0.002568559255450964\n",
      "Epoch 1663, Loss: 0.022218603815417737, Final Batch Loss: 0.0197397843003273\n",
      "Epoch 1664, Loss: 0.00610056692676153, Final Batch Loss: 0.00017586864123586565\n",
      "Epoch 1665, Loss: 0.002897186073823832, Final Batch Loss: 0.0009674299508333206\n",
      "Epoch 1666, Loss: 0.008837362453050446, Final Batch Loss: 0.00011264706699876115\n",
      "Epoch 1667, Loss: 0.0036382705220603384, Final Batch Loss: 0.0003538138698786497\n",
      "Epoch 1668, Loss: 0.045337015648328816, Final Batch Loss: 0.041704319417476654\n",
      "Epoch 1669, Loss: 0.0016553908062633127, Final Batch Loss: 0.0001936906628543511\n",
      "Epoch 1670, Loss: 0.0035420744970906526, Final Batch Loss: 0.0006712997565045953\n",
      "Epoch 1671, Loss: 0.013165836775442585, Final Batch Loss: 0.00014429542352445424\n",
      "Epoch 1672, Loss: 0.06644704627979081, Final Batch Loss: 0.025077221915125847\n",
      "Epoch 1673, Loss: 0.0029028056233073585, Final Batch Loss: 0.00015854135563131422\n",
      "Epoch 1674, Loss: 0.013232403374786372, Final Batch Loss: 0.0014506271108984947\n",
      "Epoch 1675, Loss: 0.0006551087317347992, Final Batch Loss: 8.089584298431873e-05\n",
      "Epoch 1676, Loss: 0.08736717919964576, Final Batch Loss: 0.07474321126937866\n",
      "Epoch 1677, Loss: 0.001761443418217823, Final Batch Loss: 0.0005044971476309001\n",
      "Epoch 1678, Loss: 0.001219892204971984, Final Batch Loss: 0.0007479017367586493\n",
      "Epoch 1679, Loss: 0.0371562873624498, Final Batch Loss: 0.00016854571003932506\n",
      "Epoch 1680, Loss: 0.03890304037486203, Final Batch Loss: 0.00037883545155636966\n",
      "Epoch 1681, Loss: 0.06366550222446676, Final Batch Loss: 3.728631418198347e-05\n",
      "Epoch 1682, Loss: 0.0047742406313773245, Final Batch Loss: 0.0002681567275431007\n",
      "Epoch 1683, Loss: 0.004568175208987668, Final Batch Loss: 0.0003279846569057554\n",
      "Epoch 1684, Loss: 0.006999859266215935, Final Batch Loss: 0.0011678558075800538\n",
      "Epoch 1685, Loss: 0.003910933621227741, Final Batch Loss: 7.750977238174528e-05\n",
      "Epoch 1686, Loss: 0.0023356844849331537, Final Batch Loss: 0.00017705195932649076\n",
      "Epoch 1687, Loss: 0.0006896570048411377, Final Batch Loss: 0.00012556073488667607\n",
      "Epoch 1688, Loss: 0.0008696213189978153, Final Batch Loss: 0.00014778508921153843\n",
      "Epoch 1689, Loss: 0.00014674032900074963, Final Batch Loss: 3.7127130781300366e-05\n",
      "Epoch 1690, Loss: 0.0037496866571018472, Final Batch Loss: 0.001050175167620182\n",
      "Epoch 1691, Loss: 0.0008437014294031542, Final Batch Loss: 3.229565845686011e-05\n",
      "Epoch 1692, Loss: 0.0004418951320985798, Final Batch Loss: 8.116514072753489e-05\n",
      "Epoch 1693, Loss: 0.001954381266841665, Final Batch Loss: 0.0011957973474636674\n",
      "Epoch 1694, Loss: 0.0007181750261224806, Final Batch Loss: 0.000301937572658062\n",
      "Epoch 1695, Loss: 0.0019665503714350052, Final Batch Loss: 0.00010285256576025859\n",
      "Epoch 1696, Loss: 0.004171214524831157, Final Batch Loss: 0.0008320788037963212\n",
      "Epoch 1697, Loss: 0.0006952329349587671, Final Batch Loss: 6.209097773535177e-05\n",
      "Epoch 1698, Loss: 0.005007218715036288, Final Batch Loss: 7.165827992139384e-05\n",
      "Epoch 1699, Loss: 0.004402941201988142, Final Batch Loss: 8.610510121798143e-05\n",
      "Epoch 1700, Loss: 0.01413573575700866, Final Batch Loss: 7.297307456610724e-05\n",
      "Epoch 1701, Loss: 0.003658651650766842, Final Batch Loss: 0.0004410330730024725\n",
      "Epoch 1702, Loss: 0.006200186602654867, Final Batch Loss: 0.0009542902698740363\n",
      "Epoch 1703, Loss: 0.010211391316261142, Final Batch Loss: 0.0009803255088627338\n",
      "Epoch 1704, Loss: 0.003963940740504768, Final Batch Loss: 9.285200940212235e-05\n",
      "Epoch 1705, Loss: 0.0022690306868753396, Final Batch Loss: 0.00044490175787359476\n",
      "Epoch 1706, Loss: 0.0014927742959116586, Final Batch Loss: 0.0008475306676700711\n",
      "Epoch 1707, Loss: 0.002158718096325174, Final Batch Loss: 0.0012843402801081538\n",
      "Epoch 1708, Loss: 0.0011837368438136764, Final Batch Loss: 0.00031667642178945243\n",
      "Epoch 1709, Loss: 0.001651693215535488, Final Batch Loss: 4.389642708702013e-05\n",
      "Epoch 1710, Loss: 0.0014624191808252363, Final Batch Loss: 0.00017920030222740024\n",
      "Epoch 1711, Loss: 0.003608192491810769, Final Batch Loss: 0.0017731949919834733\n",
      "Epoch 1712, Loss: 0.0005915919628023403, Final Batch Loss: 0.00023946150031406432\n",
      "Epoch 1713, Loss: 0.001738573017064482, Final Batch Loss: 0.00012322337715886533\n",
      "Epoch 1714, Loss: 0.0007029789812804665, Final Batch Loss: 4.245534000801854e-05\n",
      "Epoch 1715, Loss: 0.001326235716987867, Final Batch Loss: 0.0006712311296723783\n",
      "Epoch 1716, Loss: 0.004971707458025776, Final Batch Loss: 7.221945270430297e-05\n",
      "Epoch 1717, Loss: 0.0014910759418853559, Final Batch Loss: 0.00021327544527594\n",
      "Epoch 1718, Loss: 0.01166271502734162, Final Batch Loss: 0.010167647153139114\n",
      "Epoch 1719, Loss: 0.0037994024460203946, Final Batch Loss: 0.00017726171063259244\n",
      "Epoch 1720, Loss: 0.010880538959099795, Final Batch Loss: 0.010423452593386173\n",
      "Epoch 1721, Loss: 0.0018395282240817323, Final Batch Loss: 0.00011291237024124712\n",
      "Epoch 1722, Loss: 0.003773800504859537, Final Batch Loss: 0.002938024001196027\n",
      "Epoch 1723, Loss: 0.0052437742706388235, Final Batch Loss: 0.0011421430390328169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1724, Loss: 0.0040019675143412314, Final Batch Loss: 0.00028084684163331985\n",
      "Epoch 1725, Loss: 0.0009475771694269497, Final Batch Loss: 5.9926966059720144e-05\n",
      "Epoch 1726, Loss: 0.002597084479930345, Final Batch Loss: 0.0005808909190818667\n",
      "Epoch 1727, Loss: 0.0019086588290520012, Final Batch Loss: 0.0002388256398262456\n",
      "Epoch 1728, Loss: 0.0010539967515796889, Final Batch Loss: 0.00033728309790603817\n",
      "Epoch 1729, Loss: 0.001179233135189861, Final Batch Loss: 0.00029316500877030194\n",
      "Epoch 1730, Loss: 0.004057991762238089, Final Batch Loss: 0.0025325866881757975\n",
      "Epoch 1731, Loss: 0.000470125818537781, Final Batch Loss: 0.00021291225857567042\n",
      "Epoch 1732, Loss: 0.01498548363088048, Final Batch Loss: 0.0014678562292829156\n",
      "Epoch 1733, Loss: 0.006673134979791939, Final Batch Loss: 0.005785044282674789\n",
      "Epoch 1734, Loss: 0.0010787934879772365, Final Batch Loss: 0.00019252029596827924\n",
      "Epoch 1735, Loss: 0.0027728580025723204, Final Batch Loss: 2.115602546837181e-05\n",
      "Epoch 1736, Loss: 0.001036242552800104, Final Batch Loss: 0.00029984230059199035\n",
      "Epoch 1737, Loss: 0.0024070376675808802, Final Batch Loss: 0.0019142181845381856\n",
      "Epoch 1738, Loss: 0.010073509300127625, Final Batch Loss: 0.003189699724316597\n",
      "Epoch 1739, Loss: 0.013347233125386992, Final Batch Loss: 4.185471698292531e-05\n",
      "Epoch 1740, Loss: 0.0022261500416789204, Final Batch Loss: 5.9030644479207695e-05\n",
      "Epoch 1741, Loss: 0.0017539713735459372, Final Batch Loss: 0.00011037032527383417\n",
      "Epoch 1742, Loss: 0.0037541180427069776, Final Batch Loss: 0.0016646047588437796\n",
      "Epoch 1743, Loss: 0.0005274665672914125, Final Batch Loss: 2.947854227386415e-05\n",
      "Epoch 1744, Loss: 0.002462114774971269, Final Batch Loss: 0.0001594615023350343\n",
      "Epoch 1745, Loss: 0.007929323299322277, Final Batch Loss: 0.00023688049986958504\n",
      "Epoch 1746, Loss: 0.0015110329404706135, Final Batch Loss: 0.0004248308832757175\n",
      "Epoch 1747, Loss: 0.002647429679200286, Final Batch Loss: 3.436721453908831e-05\n",
      "Epoch 1748, Loss: 0.002858638157704263, Final Batch Loss: 0.0006788353202864528\n",
      "Epoch 1749, Loss: 0.00022570403598365374, Final Batch Loss: 9.945056808646768e-05\n",
      "Epoch 1750, Loss: 0.005141968613315839, Final Batch Loss: 0.00018214857846032828\n",
      "Epoch 1751, Loss: 0.0024780931416898966, Final Batch Loss: 0.00031434831907972693\n",
      "Epoch 1752, Loss: 0.012942412817210425, Final Batch Loss: 2.3800359485903755e-05\n",
      "Epoch 1753, Loss: 0.0013213604324846528, Final Batch Loss: 0.00020612822845578194\n",
      "Epoch 1754, Loss: 0.0016321151633746922, Final Batch Loss: 0.00041813531424850225\n",
      "Epoch 1755, Loss: 0.0010607742588035762, Final Batch Loss: 7.478526094928384e-05\n",
      "Epoch 1756, Loss: 0.003338739537866786, Final Batch Loss: 7.18210794730112e-05\n",
      "Epoch 1757, Loss: 0.007832129405869637, Final Batch Loss: 0.00720912404358387\n",
      "Epoch 1758, Loss: 0.004199539868750435, Final Batch Loss: 0.0033282525837421417\n",
      "Epoch 1759, Loss: 0.0005975610220048111, Final Batch Loss: 5.078596223029308e-05\n",
      "Epoch 1760, Loss: 0.001385733765346231, Final Batch Loss: 8.814449392957613e-05\n",
      "Epoch 1761, Loss: 0.0002607912974781357, Final Batch Loss: 4.847163654631004e-05\n",
      "Epoch 1762, Loss: 0.0009475309052504599, Final Batch Loss: 0.00015314444317482412\n",
      "Epoch 1763, Loss: 0.0012724386324407533, Final Batch Loss: 4.578617517836392e-05\n",
      "Epoch 1764, Loss: 0.0007450953489751555, Final Batch Loss: 0.0001351170358248055\n",
      "Epoch 1765, Loss: 0.0006880442761030281, Final Batch Loss: 0.00014528243627864867\n",
      "Epoch 1766, Loss: 0.05670762510271743, Final Batch Loss: 3.478371218079701e-05\n",
      "Epoch 1767, Loss: 0.0027743819809984416, Final Batch Loss: 0.002101910300552845\n",
      "Epoch 1768, Loss: 0.0005829907458974048, Final Batch Loss: 7.986580021679401e-05\n",
      "Epoch 1769, Loss: 0.0007545344269601628, Final Batch Loss: 0.00024138196022249758\n",
      "Epoch 1770, Loss: 0.0009529292292427272, Final Batch Loss: 0.0001533559407107532\n",
      "Epoch 1771, Loss: 0.023586773928400362, Final Batch Loss: 0.0014317749300971627\n",
      "Epoch 1772, Loss: 0.001049711943778675, Final Batch Loss: 0.00010607991134747863\n",
      "Epoch 1773, Loss: 0.0008574279090680648, Final Batch Loss: 3.5704721085494384e-05\n",
      "Epoch 1774, Loss: 0.0013529883508454077, Final Batch Loss: 0.00014852333697490394\n",
      "Epoch 1775, Loss: 0.004310334210458677, Final Batch Loss: 8.20108616608195e-05\n",
      "Epoch 1776, Loss: 0.0020120714980293997, Final Batch Loss: 0.00012864923337474465\n",
      "Epoch 1777, Loss: 0.001994953054236248, Final Batch Loss: 0.00020006278646178544\n",
      "Epoch 1778, Loss: 0.0010708504851209, Final Batch Loss: 0.0001777095312718302\n",
      "Epoch 1779, Loss: 0.012299574707867578, Final Batch Loss: 0.011614571325480938\n",
      "Epoch 1780, Loss: 0.026280042802682146, Final Batch Loss: 0.024269089102745056\n",
      "Epoch 1781, Loss: 0.0016471301642013714, Final Batch Loss: 0.00021325808484107256\n",
      "Epoch 1782, Loss: 0.0036416274961084127, Final Batch Loss: 0.001355138374492526\n",
      "Epoch 1783, Loss: 0.002941062906756997, Final Batch Loss: 0.00018085289048030972\n",
      "Epoch 1784, Loss: 0.01926083407306578, Final Batch Loss: 0.0001577478542458266\n",
      "Epoch 1785, Loss: 0.010759839035017649, Final Batch Loss: 0.0004901200882159173\n",
      "Epoch 1786, Loss: 0.00022923640244698618, Final Batch Loss: 4.2573279642965645e-05\n",
      "Epoch 1787, Loss: 0.0018313698965357617, Final Batch Loss: 0.00010529364226385951\n",
      "Epoch 1788, Loss: 0.013433326319500338, Final Batch Loss: 2.975828101625666e-05\n",
      "Epoch 1789, Loss: 0.04283122923516203, Final Batch Loss: 0.03986365348100662\n",
      "Epoch 1790, Loss: 0.0015653368100174703, Final Batch Loss: 0.0001498162018833682\n",
      "Epoch 1791, Loss: 0.005178754930966534, Final Batch Loss: 0.0008341091452166438\n",
      "Epoch 1792, Loss: 0.001321090036071837, Final Batch Loss: 0.00041056956979446113\n",
      "Epoch 1793, Loss: 0.0016406734503107145, Final Batch Loss: 0.0006574500002898276\n",
      "Epoch 1794, Loss: 0.003909784078132361, Final Batch Loss: 0.0013459883630275726\n",
      "Epoch 1795, Loss: 0.0016691678029019386, Final Batch Loss: 0.0006238408386707306\n",
      "Epoch 1796, Loss: 0.012815174413844943, Final Batch Loss: 0.000309137103613466\n",
      "Epoch 1797, Loss: 0.0009209585477947257, Final Batch Loss: 0.00012807447637896985\n",
      "Epoch 1798, Loss: 0.0022797806032031076, Final Batch Loss: 0.000136603630380705\n",
      "Epoch 1799, Loss: 0.0014113312063273042, Final Batch Loss: 2.547315125411842e-05\n",
      "Epoch 1800, Loss: 0.011812352866400033, Final Batch Loss: 0.006517884321510792\n",
      "Epoch 1801, Loss: 0.00179978710366413, Final Batch Loss: 0.0006344302091747522\n",
      "Epoch 1802, Loss: 0.0038814104555058293, Final Batch Loss: 0.00026062701363116503\n",
      "Epoch 1803, Loss: 0.0032567247399128973, Final Batch Loss: 0.000171595616848208\n",
      "Epoch 1804, Loss: 0.001260631783225108, Final Batch Loss: 0.0007034236332401633\n",
      "Epoch 1805, Loss: 0.001599108254595194, Final Batch Loss: 0.00020752222917508334\n",
      "Epoch 1806, Loss: 0.0019010158066521399, Final Batch Loss: 0.0006153265712782741\n",
      "Epoch 1807, Loss: 0.0009565303334966302, Final Batch Loss: 0.0001365042116958648\n",
      "Epoch 1808, Loss: 0.0012156279117334634, Final Batch Loss: 0.00016577407950535417\n",
      "Epoch 1809, Loss: 0.0014614272731705569, Final Batch Loss: 0.00012614286970347166\n",
      "Epoch 1810, Loss: 0.0033215322109754197, Final Batch Loss: 0.00029594358056783676\n",
      "Epoch 1811, Loss: 0.001243861606781138, Final Batch Loss: 0.0001908126287162304\n",
      "Epoch 1812, Loss: 0.0009189525444526225, Final Batch Loss: 6.204649980645627e-05\n",
      "Epoch 1813, Loss: 0.0005613663197436836, Final Batch Loss: 0.0002459737006574869\n",
      "Epoch 1814, Loss: 0.00030443356990872417, Final Batch Loss: 1.1802245353464969e-05\n",
      "Epoch 1815, Loss: 0.0026236662233714014, Final Batch Loss: 0.0005501210107468069\n",
      "Epoch 1816, Loss: 0.0015311070310417563, Final Batch Loss: 7.533177267760038e-06\n",
      "Epoch 1817, Loss: 0.0008753249967412557, Final Batch Loss: 0.0007137438515201211\n",
      "Epoch 1818, Loss: 0.00032003215983422706, Final Batch Loss: 4.2189076339127496e-05\n",
      "Epoch 1819, Loss: 0.0009408759215148166, Final Batch Loss: 4.1500694351270795e-05\n",
      "Epoch 1820, Loss: 0.0010786629827634897, Final Batch Loss: 0.0008364837849512696\n",
      "Epoch 1821, Loss: 0.0005360977884265594, Final Batch Loss: 0.00020946636504959315\n",
      "Epoch 1822, Loss: 0.001347464058198966, Final Batch Loss: 0.00036497905966825783\n",
      "Epoch 1823, Loss: 0.0012248119528521784, Final Batch Loss: 7.265131716849282e-05\n",
      "Epoch 1824, Loss: 0.035459783215628704, Final Batch Loss: 0.0347989983856678\n",
      "Epoch 1825, Loss: 0.0006163031066535041, Final Batch Loss: 0.00015616962627973408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826, Loss: 0.003694501238896919, Final Batch Loss: 0.001187973190099001\n",
      "Epoch 1827, Loss: 0.0041628245016909204, Final Batch Loss: 0.0033731539733707905\n",
      "Epoch 1828, Loss: 0.011371469307050575, Final Batch Loss: 0.00010105413821293041\n",
      "Epoch 1829, Loss: 0.0014733240568602923, Final Batch Loss: 0.0008285538642667234\n",
      "Epoch 1830, Loss: 0.0028016714204568416, Final Batch Loss: 0.00013342674355953932\n",
      "Epoch 1831, Loss: 0.0201241268805461, Final Batch Loss: 0.004277309402823448\n",
      "Epoch 1832, Loss: 0.001285886057303287, Final Batch Loss: 0.0005495001096278429\n",
      "Epoch 1833, Loss: 0.00191521507804282, Final Batch Loss: 0.0002988624037243426\n",
      "Epoch 1834, Loss: 0.00047832173731876537, Final Batch Loss: 7.743342575849965e-05\n",
      "Epoch 1835, Loss: 0.004152782683377154, Final Batch Loss: 0.00023084912390913814\n",
      "Epoch 1836, Loss: 0.01275100411294261, Final Batch Loss: 0.003975619096308947\n",
      "Epoch 1837, Loss: 0.001227252563694492, Final Batch Loss: 6.176292663440108e-05\n",
      "Epoch 1838, Loss: 0.052522486530506285, Final Batch Loss: 0.00032608199398964643\n",
      "Epoch 1839, Loss: 0.0015487635791942012, Final Batch Loss: 0.00020846763800363988\n",
      "Epoch 1840, Loss: 0.0017410414329788182, Final Batch Loss: 0.0006004869937896729\n",
      "Epoch 1841, Loss: 0.0067646504830918275, Final Batch Loss: 4.775354318553582e-05\n",
      "Epoch 1842, Loss: 0.001161703206889797, Final Batch Loss: 0.00010700365965021774\n",
      "Epoch 1843, Loss: 0.001725679190712981, Final Batch Loss: 4.330510273575783e-05\n",
      "Epoch 1844, Loss: 0.025617807055823505, Final Batch Loss: 0.009428709745407104\n",
      "Epoch 1845, Loss: 0.0018040015929727815, Final Batch Loss: 8.396014891332015e-05\n",
      "Epoch 1846, Loss: 0.000957718031713739, Final Batch Loss: 0.00024906545877456665\n",
      "Epoch 1847, Loss: 0.0012135309516452253, Final Batch Loss: 0.0003277239156886935\n",
      "Epoch 1848, Loss: 0.014140433253487572, Final Batch Loss: 0.00045708820107392967\n",
      "Epoch 1849, Loss: 0.017955272895051166, Final Batch Loss: 0.00143461546394974\n",
      "Epoch 1850, Loss: 0.0017065070405806182, Final Batch Loss: 2.7488646082929336e-05\n",
      "Epoch 1851, Loss: 0.016857718335813843, Final Batch Loss: 0.01323832105845213\n",
      "Epoch 1852, Loss: 0.0011768984841182828, Final Batch Loss: 0.0001966861163964495\n",
      "Epoch 1853, Loss: 0.0025615369122533593, Final Batch Loss: 1.9840434106299654e-05\n",
      "Epoch 1854, Loss: 0.007619007534231059, Final Batch Loss: 0.0001515999174444005\n",
      "Epoch 1855, Loss: 0.02070001785614295, Final Batch Loss: 9.542074258206412e-05\n",
      "Epoch 1856, Loss: 0.0007081365765770897, Final Batch Loss: 0.0001610913168406114\n",
      "Epoch 1857, Loss: 0.0040193178137997165, Final Batch Loss: 0.0036727844271808863\n",
      "Epoch 1858, Loss: 0.0031289568869397044, Final Batch Loss: 0.0017211445374414325\n",
      "Epoch 1859, Loss: 0.007371322513790801, Final Batch Loss: 0.00041977837099693716\n",
      "Epoch 1860, Loss: 0.0006424061193683883, Final Batch Loss: 3.039823604922276e-05\n",
      "Epoch 1861, Loss: 0.0015887149966147263, Final Batch Loss: 0.0010896087624132633\n",
      "Epoch 1862, Loss: 0.009429566616745433, Final Batch Loss: 5.855570998392068e-05\n",
      "Epoch 1863, Loss: 0.002104834253259469, Final Batch Loss: 0.0003499628510326147\n",
      "Epoch 1864, Loss: 0.002055547563941218, Final Batch Loss: 0.0015401088166981936\n",
      "Epoch 1865, Loss: 0.015554603618511464, Final Batch Loss: 0.0002828742144629359\n",
      "Epoch 1866, Loss: 0.0014829074061708525, Final Batch Loss: 0.000159485251060687\n",
      "Epoch 1867, Loss: 0.00533340590482112, Final Batch Loss: 0.004479188472032547\n",
      "Epoch 1868, Loss: 0.002558113857958233, Final Batch Loss: 0.002015776466578245\n",
      "Epoch 1869, Loss: 0.0012416639583534561, Final Batch Loss: 4.467026883503422e-05\n",
      "Epoch 1870, Loss: 0.00528166807089292, Final Batch Loss: 2.828636388585437e-05\n",
      "Epoch 1871, Loss: 0.008308147967909463, Final Batch Loss: 0.00016927144315559417\n",
      "Epoch 1872, Loss: 0.006833648312749574, Final Batch Loss: 6.051664604456164e-05\n",
      "Epoch 1873, Loss: 0.0007250124217534903, Final Batch Loss: 0.0005589232314378023\n",
      "Epoch 1874, Loss: 0.0012835259185521863, Final Batch Loss: 8.00857087597251e-05\n",
      "Epoch 1875, Loss: 0.0015548750998277683, Final Batch Loss: 0.0006500963354483247\n",
      "Epoch 1876, Loss: 0.0036982647579861805, Final Batch Loss: 5.051503831055015e-05\n",
      "Epoch 1877, Loss: 0.001531211568362778, Final Batch Loss: 0.0006784395663999021\n",
      "Epoch 1878, Loss: 0.00044893766244058497, Final Batch Loss: 2.5376666599186137e-05\n",
      "Epoch 1879, Loss: 0.008778685165452771, Final Batch Loss: 0.008194505237042904\n",
      "Epoch 1880, Loss: 0.0006293859787547262, Final Batch Loss: 0.0003514908894430846\n",
      "Epoch 1881, Loss: 0.001263100464711897, Final Batch Loss: 0.00037168245762586594\n",
      "Epoch 1882, Loss: 0.0010037428946816362, Final Batch Loss: 0.00014845583064015955\n",
      "Epoch 1883, Loss: 0.0006762889097444713, Final Batch Loss: 0.00020439625950530171\n",
      "Epoch 1884, Loss: 0.0035157490201527253, Final Batch Loss: 0.002136810449883342\n",
      "Epoch 1885, Loss: 0.0040173345696530305, Final Batch Loss: 0.003000029595568776\n",
      "Epoch 1886, Loss: 0.00019440867799858097, Final Batch Loss: 7.70442420616746e-05\n",
      "Epoch 1887, Loss: 0.001835333212511614, Final Batch Loss: 0.00020572483481373638\n",
      "Epoch 1888, Loss: 0.001407326475600712, Final Batch Loss: 0.0001562993275001645\n",
      "Epoch 1889, Loss: 0.002172497199353529, Final Batch Loss: 0.0006034860853105783\n",
      "Epoch 1890, Loss: 0.004009795724414289, Final Batch Loss: 7.402844494208694e-05\n",
      "Epoch 1891, Loss: 0.0009265383887395728, Final Batch Loss: 0.0001305502955801785\n",
      "Epoch 1892, Loss: 0.0011264705972280353, Final Batch Loss: 7.988453580765054e-05\n",
      "Epoch 1893, Loss: 0.002694139053346589, Final Batch Loss: 0.00202944572083652\n",
      "Epoch 1894, Loss: 0.0013719929829676403, Final Batch Loss: 1.1799189451267011e-05\n",
      "Epoch 1895, Loss: 0.001061011353158392, Final Batch Loss: 2.9754235583823174e-05\n",
      "Epoch 1896, Loss: 0.00039164450572570786, Final Batch Loss: 2.7812024200102314e-05\n",
      "Epoch 1897, Loss: 0.0005126478681631852, Final Batch Loss: 8.94998011062853e-05\n",
      "Epoch 1898, Loss: 0.00141446484849439, Final Batch Loss: 3.161270069540478e-05\n",
      "Epoch 1899, Loss: 0.0021450742569868453, Final Batch Loss: 7.397999434033409e-05\n",
      "Epoch 1900, Loss: 0.0007042545548756607, Final Batch Loss: 7.37542868591845e-05\n",
      "Epoch 1901, Loss: 0.00022081114911998156, Final Batch Loss: 1.9964187231380492e-05\n",
      "Epoch 1902, Loss: 0.0008350865027750842, Final Batch Loss: 0.00012319786765147\n",
      "Epoch 1903, Loss: 0.0009272273309761658, Final Batch Loss: 0.0002596530830487609\n",
      "Epoch 1904, Loss: 0.002473580985679291, Final Batch Loss: 0.00048584514297544956\n",
      "Epoch 1905, Loss: 0.0013299008860485628, Final Batch Loss: 0.0006282912800088525\n",
      "Epoch 1906, Loss: 0.0010775753598863957, Final Batch Loss: 0.000388272397685796\n",
      "Epoch 1907, Loss: 0.0014100883672654163, Final Batch Loss: 7.703297887928784e-05\n",
      "Epoch 1908, Loss: 0.0009010578760353383, Final Batch Loss: 0.0006085884524509311\n",
      "Epoch 1909, Loss: 0.0014901274807925802, Final Batch Loss: 4.052339500049129e-05\n",
      "Epoch 1910, Loss: 0.0046015773332328536, Final Batch Loss: 0.00043719797395169735\n",
      "Epoch 1911, Loss: 0.0036096797084610444, Final Batch Loss: 0.0030405449215322733\n",
      "Epoch 1912, Loss: 0.0011770784403779544, Final Batch Loss: 0.0006754896021448076\n",
      "Epoch 1913, Loss: 0.00035601440231403103, Final Batch Loss: 1.0136714081454556e-05\n",
      "Epoch 1914, Loss: 0.00042662248597480357, Final Batch Loss: 2.1020216081524268e-05\n",
      "Epoch 1915, Loss: 0.00016983494060696103, Final Batch Loss: 2.639590275066439e-05\n",
      "Epoch 1916, Loss: 0.00043411275692051277, Final Batch Loss: 0.00017976427625399083\n",
      "Epoch 1917, Loss: 0.0069036211680213455, Final Batch Loss: 4.258176340954378e-05\n",
      "Epoch 1918, Loss: 0.0012225847931404132, Final Batch Loss: 4.4916279875906184e-05\n",
      "Epoch 1919, Loss: 0.00028035432296746876, Final Batch Loss: 0.00012038731074426323\n",
      "Epoch 1920, Loss: 0.00046374479734367924, Final Batch Loss: 0.00013117821072228253\n",
      "Epoch 1921, Loss: 0.0015575231009279378, Final Batch Loss: 0.00041092230821959674\n",
      "Epoch 1922, Loss: 0.005184800589631777, Final Batch Loss: 0.004988996312022209\n",
      "Epoch 1923, Loss: 0.0017654987022979185, Final Batch Loss: 0.0005767681868746877\n",
      "Epoch 1924, Loss: 0.0013619876554002985, Final Batch Loss: 0.0005092506762593985\n",
      "Epoch 1925, Loss: 0.022922234962607035, Final Batch Loss: 0.022271445021033287\n",
      "Epoch 1926, Loss: 0.0244239796011243, Final Batch Loss: 0.023651471361517906\n",
      "Epoch 1927, Loss: 0.03720784441156866, Final Batch Loss: 1.2592506209330168e-05\n",
      "Epoch 1928, Loss: 0.0017409255378879607, Final Batch Loss: 0.0014704151544719934\n",
      "Epoch 1929, Loss: 0.040757720827969024, Final Batch Loss: 4.807305958820507e-05\n",
      "Epoch 1930, Loss: 0.0009756823492352851, Final Batch Loss: 8.235475979745388e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1931, Loss: 0.04622281835327158, Final Batch Loss: 3.917110007023439e-05\n",
      "Epoch 1932, Loss: 0.0009189924821839668, Final Batch Loss: 1.2000113201793283e-05\n",
      "Epoch 1933, Loss: 0.001898861606605351, Final Batch Loss: 0.0009146523661911488\n",
      "Epoch 1934, Loss: 0.03940493650952703, Final Batch Loss: 7.98413748270832e-06\n",
      "Epoch 1935, Loss: 0.00501819551573135, Final Batch Loss: 0.004012963734567165\n",
      "Epoch 1936, Loss: 0.002646273875143379, Final Batch Loss: 0.0001940832007676363\n",
      "Epoch 1937, Loss: 0.001960511341167148, Final Batch Loss: 9.336628863820806e-05\n",
      "Epoch 1938, Loss: 0.0030670157575514168, Final Batch Loss: 0.0003029578074347228\n",
      "Epoch 1939, Loss: 0.005364955744880717, Final Batch Loss: 0.00012088992662029341\n",
      "Epoch 1940, Loss: 0.003258603232097812, Final Batch Loss: 0.0019504206720739603\n",
      "Epoch 1941, Loss: 0.0018683805319597013, Final Batch Loss: 0.0006142359343357384\n",
      "Epoch 1942, Loss: 0.0008029029704630375, Final Batch Loss: 0.0003779375401791185\n",
      "Epoch 1943, Loss: 0.0019128135063510854, Final Batch Loss: 2.1362753614084795e-05\n",
      "Epoch 1944, Loss: 0.002256552364997333, Final Batch Loss: 0.0005612305249087512\n",
      "Epoch 1945, Loss: 0.0007576340576633811, Final Batch Loss: 0.00023308326490223408\n",
      "Epoch 1946, Loss: 0.000756472163629951, Final Batch Loss: 5.760098065366037e-05\n",
      "Epoch 1947, Loss: 0.001641031907638535, Final Batch Loss: 0.0004139818192925304\n",
      "Epoch 1948, Loss: 0.0032558011189394165, Final Batch Loss: 0.00027377044898457825\n",
      "Epoch 1949, Loss: 0.0006279653716774192, Final Batch Loss: 0.00041813371353782713\n",
      "Epoch 1950, Loss: 0.0009611942150513642, Final Batch Loss: 0.0001346060016658157\n",
      "Epoch 1951, Loss: 0.001985788345336914, Final Batch Loss: 0.0004942422383464873\n",
      "Epoch 1952, Loss: 0.001008199127682019, Final Batch Loss: 0.0007033253205008805\n",
      "Epoch 1953, Loss: 0.0005697115302609745, Final Batch Loss: 0.00017542048590257764\n",
      "Epoch 1954, Loss: 0.007265256208484061, Final Batch Loss: 0.0027289162389934063\n",
      "Epoch 1955, Loss: 0.007453176302078646, Final Batch Loss: 0.0006555759464390576\n",
      "Epoch 1956, Loss: 0.0006864411916467361, Final Batch Loss: 0.00013277240213938057\n",
      "Epoch 1957, Loss: 0.0011707656158250757, Final Batch Loss: 0.00011833747703349218\n",
      "Epoch 1958, Loss: 0.0012357480445643887, Final Batch Loss: 7.798554725013673e-05\n",
      "Epoch 1959, Loss: 0.0007210250905700377, Final Batch Loss: 1.223834897245979e-05\n",
      "Epoch 1960, Loss: 0.002813336941471789, Final Batch Loss: 3.073095285799354e-05\n",
      "Epoch 1961, Loss: 0.004762034834129736, Final Batch Loss: 0.0035163972061127424\n",
      "Epoch 1962, Loss: 0.0007369775157712866, Final Batch Loss: 7.230764458654448e-05\n",
      "Epoch 1963, Loss: 0.009836521538090892, Final Batch Loss: 0.002754810731858015\n",
      "Epoch 1964, Loss: 0.0051057498349109665, Final Batch Loss: 9.901856537908316e-05\n",
      "Epoch 1965, Loss: 0.017528224569105078, Final Batch Loss: 3.250328154535964e-05\n",
      "Epoch 1966, Loss: 0.0004618589227902703, Final Batch Loss: 3.335823566885665e-05\n",
      "Epoch 1967, Loss: 0.009155862106126733, Final Batch Loss: 0.00015144902863539755\n",
      "Epoch 1968, Loss: 0.0012379274921840988, Final Batch Loss: 0.0009017211850732565\n",
      "Epoch 1969, Loss: 0.0033984751062234864, Final Batch Loss: 0.0021574804559350014\n",
      "Epoch 1970, Loss: 0.000739930423151236, Final Batch Loss: 7.179840031312779e-05\n",
      "Epoch 1971, Loss: 0.0036974427493987605, Final Batch Loss: 0.0010022666538134217\n",
      "Epoch 1972, Loss: 0.01622858223345247, Final Batch Loss: 3.774101423914544e-05\n",
      "Epoch 1973, Loss: 0.0010981215236824937, Final Batch Loss: 0.0001349156373180449\n",
      "Epoch 1974, Loss: 0.07841417896997882, Final Batch Loss: 8.43318339320831e-05\n",
      "Epoch 1975, Loss: 0.0013074390953988768, Final Batch Loss: 0.0007375982240773737\n",
      "Epoch 1976, Loss: 0.0052486953645711765, Final Batch Loss: 0.0033500331919640303\n",
      "Epoch 1977, Loss: 0.004324461740907282, Final Batch Loss: 9.839770791586488e-05\n",
      "Epoch 1978, Loss: 0.00473252238589339, Final Batch Loss: 0.0003523964260239154\n",
      "Epoch 1979, Loss: 0.00385533152075368, Final Batch Loss: 0.0024038369301706553\n",
      "Epoch 1980, Loss: 0.005371138686314225, Final Batch Loss: 0.0020920932292938232\n",
      "Epoch 1981, Loss: 0.003826812288025394, Final Batch Loss: 0.0014500453835353255\n",
      "Epoch 1982, Loss: 0.004225591881549917, Final Batch Loss: 0.0002245325449621305\n",
      "Epoch 1983, Loss: 0.002008074274272076, Final Batch Loss: 2.654921445355285e-05\n",
      "Epoch 1984, Loss: 0.002746429614489898, Final Batch Loss: 0.00017072948685381562\n",
      "Epoch 1985, Loss: 0.0055204410091391765, Final Batch Loss: 0.00010077031765831634\n",
      "Epoch 1986, Loss: 0.0007175414539233316, Final Batch Loss: 1.3887769455322996e-05\n",
      "Epoch 1987, Loss: 0.001012531400192529, Final Batch Loss: 0.00023993168724700809\n",
      "Epoch 1988, Loss: 0.000662018788716523, Final Batch Loss: 0.00033974312827922404\n",
      "Epoch 1989, Loss: 0.00079820588871371, Final Batch Loss: 0.00048490826156921685\n",
      "Epoch 1990, Loss: 0.00257803743443219, Final Batch Loss: 0.00011937602539546788\n",
      "Epoch 1991, Loss: 0.0026278492077835836, Final Batch Loss: 0.0019516593310981989\n",
      "Epoch 1992, Loss: 0.00040318703395314515, Final Batch Loss: 0.00029413984157145023\n",
      "Epoch 1993, Loss: 0.0017798153567127883, Final Batch Loss: 0.00041205334127880633\n",
      "Epoch 1994, Loss: 0.0014881927927490324, Final Batch Loss: 0.00043765263399109244\n",
      "Epoch 1995, Loss: 0.0003813914345300873, Final Batch Loss: 1.1939721844100859e-05\n",
      "Epoch 1996, Loss: 0.0015781527140461549, Final Batch Loss: 4.354205429990543e-06\n",
      "Epoch 1997, Loss: 0.0011455307248979807, Final Batch Loss: 0.00011338604963384569\n",
      "Epoch 1998, Loss: 0.00047470210847677663, Final Batch Loss: 7.50966282794252e-05\n",
      "Epoch 1999, Loss: 0.00590177476988174, Final Batch Loss: 0.00014675820420961827\n",
      "Epoch 2000, Loss: 0.001803911269234959, Final Batch Loss: 0.0007358653820119798\n",
      "Epoch 2001, Loss: 0.0007663577089260798, Final Batch Loss: 0.00017166182806249708\n",
      "Epoch 2002, Loss: 0.0016863095479493495, Final Batch Loss: 4.3082134652649984e-05\n",
      "Epoch 2003, Loss: 0.0030090305481280666, Final Batch Loss: 0.0001558449730509892\n",
      "Epoch 2004, Loss: 0.0008084346936811926, Final Batch Loss: 0.0005339671624824405\n",
      "Epoch 2005, Loss: 0.0002323761896150245, Final Batch Loss: 5.804339252790669e-06\n",
      "Epoch 2006, Loss: 0.002561265711847227, Final Batch Loss: 4.85120908706449e-05\n",
      "Epoch 2007, Loss: 0.004420976278197486, Final Batch Loss: 0.00040427185012958944\n",
      "Epoch 2008, Loss: 0.0014477590084425174, Final Batch Loss: 0.0009988173842430115\n",
      "Epoch 2009, Loss: 0.0009750973695190623, Final Batch Loss: 9.402788418810815e-05\n",
      "Epoch 2010, Loss: 0.002688713459065184, Final Batch Loss: 0.001100430847145617\n",
      "Epoch 2011, Loss: 0.0005132400474394672, Final Batch Loss: 2.089691406581551e-05\n",
      "Epoch 2012, Loss: 0.0037595048270304687, Final Batch Loss: 0.0021280432119965553\n",
      "Epoch 2013, Loss: 0.0005500573024619371, Final Batch Loss: 0.00025234720669686794\n",
      "Epoch 2014, Loss: 0.0018019093695329502, Final Batch Loss: 0.0014113736106082797\n",
      "Epoch 2015, Loss: 0.0013505105816875584, Final Batch Loss: 8.651644748169929e-06\n",
      "Epoch 2016, Loss: 0.0006249841317185201, Final Batch Loss: 3.4253826015628874e-05\n",
      "Epoch 2017, Loss: 0.002288185683937627, Final Batch Loss: 2.416483584966045e-05\n",
      "Epoch 2018, Loss: 0.001116898254622356, Final Batch Loss: 0.0009127844823524356\n",
      "Epoch 2019, Loss: 0.001631712555536069, Final Batch Loss: 0.0007631438202224672\n",
      "Epoch 2020, Loss: 0.004694882766671071, Final Batch Loss: 0.004312209319323301\n",
      "Epoch 2021, Loss: 0.0004076632649230305, Final Batch Loss: 7.770380034344271e-05\n",
      "Epoch 2022, Loss: 0.0012298012952669524, Final Batch Loss: 0.000319998012855649\n",
      "Epoch 2023, Loss: 0.0009485349009992206, Final Batch Loss: 6.496071728179231e-05\n",
      "Epoch 2024, Loss: 0.000716584636393236, Final Batch Loss: 3.836405448964797e-05\n",
      "Epoch 2025, Loss: 0.00030931916717236163, Final Batch Loss: 4.614924910129048e-05\n",
      "Epoch 2026, Loss: 0.013188332926802104, Final Batch Loss: 0.00014994321099948138\n",
      "Epoch 2027, Loss: 0.0002207881279900903, Final Batch Loss: 0.00013389297237154096\n",
      "Epoch 2028, Loss: 0.002198929059886723, Final Batch Loss: 4.29719511885196e-06\n",
      "Epoch 2029, Loss: 0.00041501837768009864, Final Batch Loss: 6.957516598049551e-05\n",
      "Epoch 2030, Loss: 0.012670484305999707, Final Batch Loss: 6.752716581104323e-05\n",
      "Epoch 2031, Loss: 0.001214613646880025, Final Batch Loss: 3.164753070450388e-05\n",
      "Epoch 2032, Loss: 0.0005761059874203056, Final Batch Loss: 0.00019031412375625223\n",
      "Epoch 2033, Loss: 0.0011060577362513868, Final Batch Loss: 1.7655316696618684e-05\n",
      "Epoch 2034, Loss: 0.0393307184567675, Final Batch Loss: 0.020545775070786476\n",
      "Epoch 2035, Loss: 0.0008236836874857545, Final Batch Loss: 0.000609405804425478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2036, Loss: 0.03265968470441294, Final Batch Loss: 0.02844085730612278\n",
      "Epoch 2037, Loss: 0.03185435886553023, Final Batch Loss: 0.0012842322466894984\n",
      "Epoch 2038, Loss: 0.000926033200812526, Final Batch Loss: 4.529509169515222e-05\n",
      "Epoch 2039, Loss: 0.07929035520646721, Final Batch Loss: 0.046730849891901016\n",
      "Epoch 2040, Loss: 0.05739400149832363, Final Batch Loss: 0.001991851953789592\n",
      "Epoch 2041, Loss: 0.010706333254347555, Final Batch Loss: 3.17267986247316e-05\n",
      "Epoch 2042, Loss: 0.10500862047774717, Final Batch Loss: 0.00678842281922698\n",
      "Epoch 2043, Loss: 0.0015596828088746406, Final Batch Loss: 6.30994763923809e-05\n",
      "Epoch 2044, Loss: 0.0018687459887587465, Final Batch Loss: 0.0005805707769468427\n",
      "Epoch 2045, Loss: 0.007557257937151007, Final Batch Loss: 0.006210708525031805\n",
      "Epoch 2046, Loss: 0.03342979194712825, Final Batch Loss: 0.0007800537860020995\n",
      "Epoch 2047, Loss: 0.001792564376955852, Final Batch Loss: 0.0007249658228829503\n",
      "Epoch 2048, Loss: 0.0038906151239643805, Final Batch Loss: 0.001193499774672091\n",
      "Epoch 2049, Loss: 0.01939628458057996, Final Batch Loss: 0.0017657441785559058\n",
      "Epoch 2050, Loss: 0.004234654272295302, Final Batch Loss: 5.570199209614657e-05\n",
      "Epoch 2051, Loss: 0.003233197348890826, Final Batch Loss: 0.000686167215462774\n",
      "Epoch 2052, Loss: 0.012311837723245844, Final Batch Loss: 0.00010662040585884824\n",
      "Epoch 2053, Loss: 0.001181967209049617, Final Batch Loss: 2.9769247703370638e-05\n",
      "Epoch 2054, Loss: 0.0017542294735903852, Final Batch Loss: 0.0004653399810194969\n",
      "Epoch 2055, Loss: 0.004195329587673768, Final Batch Loss: 0.00036048798938281834\n",
      "Epoch 2056, Loss: 0.026865553110837936, Final Batch Loss: 0.0002562975278124213\n",
      "Epoch 2057, Loss: 0.0028805108668166213, Final Batch Loss: 0.0005302720237523317\n",
      "Epoch 2058, Loss: 0.0019446577207418159, Final Batch Loss: 0.0001475300086895004\n",
      "Epoch 2059, Loss: 0.007037632676656358, Final Batch Loss: 7.939162605907768e-05\n",
      "Epoch 2060, Loss: 0.019520026398822665, Final Batch Loss: 3.810851922025904e-05\n",
      "Epoch 2061, Loss: 0.002137413714081049, Final Batch Loss: 0.00018966282368637621\n",
      "Epoch 2062, Loss: 0.002484489516064059, Final Batch Loss: 0.0008154549286700785\n",
      "Epoch 2063, Loss: 0.0029405908135231584, Final Batch Loss: 0.0002587004273664206\n",
      "Epoch 2064, Loss: 0.03962343017337844, Final Batch Loss: 0.001388099044561386\n",
      "Epoch 2065, Loss: 0.018501889309845865, Final Batch Loss: 0.00015910709043964744\n",
      "Epoch 2066, Loss: 0.0019246072333771735, Final Batch Loss: 0.000548548880033195\n",
      "Epoch 2067, Loss: 0.0020576534589054063, Final Batch Loss: 0.00018813904898706824\n",
      "Epoch 2068, Loss: 0.003336085625051055, Final Batch Loss: 0.0020259935408830643\n",
      "Epoch 2069, Loss: 0.002195602748543024, Final Batch Loss: 0.00040674261981621385\n",
      "Epoch 2070, Loss: 0.003796610559220426, Final Batch Loss: 0.0003572180576156825\n",
      "Epoch 2071, Loss: 0.0017811791622079909, Final Batch Loss: 0.001239906414411962\n",
      "Epoch 2072, Loss: 0.0007244578519021161, Final Batch Loss: 7.422766793752089e-05\n",
      "Epoch 2073, Loss: 0.0018362745322519913, Final Batch Loss: 0.0003840205317828804\n",
      "Epoch 2074, Loss: 0.0013578014113591053, Final Batch Loss: 0.0005659231101162732\n",
      "Epoch 2075, Loss: 0.000690959061103058, Final Batch Loss: 2.94884684990393e-05\n",
      "Epoch 2076, Loss: 0.0012139664322603494, Final Batch Loss: 0.0002201184834120795\n",
      "Epoch 2077, Loss: 0.0031249648236553185, Final Batch Loss: 0.0025855929125100374\n",
      "Epoch 2078, Loss: 0.0018967496362165548, Final Batch Loss: 0.00042142922757193446\n",
      "Epoch 2079, Loss: 0.0017295293946517631, Final Batch Loss: 5.0958256906596944e-05\n",
      "Epoch 2080, Loss: 0.000647136981569929, Final Batch Loss: 5.377673005568795e-05\n",
      "Epoch 2081, Loss: 0.0004261500253051054, Final Batch Loss: 0.00019380576850380749\n",
      "Epoch 2082, Loss: 0.0014651911296823528, Final Batch Loss: 0.00035746110370382667\n",
      "Epoch 2083, Loss: 0.0016698994950274937, Final Batch Loss: 0.0002282996429130435\n",
      "Epoch 2084, Loss: 0.004918705539239454, Final Batch Loss: 2.6911218810710125e-05\n",
      "Epoch 2085, Loss: 0.0033658344618743286, Final Batch Loss: 8.136491669574752e-05\n",
      "Epoch 2086, Loss: 0.0010983809625031427, Final Batch Loss: 0.0005257406155578792\n",
      "Epoch 2087, Loss: 0.0011101964155386668, Final Batch Loss: 0.0007518372149206698\n",
      "Epoch 2088, Loss: 0.0031979188206605613, Final Batch Loss: 0.0007699728012084961\n",
      "Epoch 2089, Loss: 0.0027679408085532486, Final Batch Loss: 0.0009740637033246458\n",
      "Epoch 2090, Loss: 0.0013675966765731573, Final Batch Loss: 2.6454355975147337e-05\n",
      "Epoch 2091, Loss: 0.0015473218663828447, Final Batch Loss: 0.00010514684254303575\n",
      "Epoch 2092, Loss: 0.003096949469181709, Final Batch Loss: 0.00011870975140482187\n",
      "Epoch 2093, Loss: 0.0006447118066716939, Final Batch Loss: 5.0496622861828655e-05\n",
      "Epoch 2094, Loss: 0.0010974854358209996, Final Batch Loss: 2.6987776436726563e-05\n",
      "Epoch 2095, Loss: 0.07528537825055537, Final Batch Loss: 0.001144467736594379\n",
      "Epoch 2096, Loss: 0.0026192893274128437, Final Batch Loss: 0.0014941359404474497\n",
      "Epoch 2097, Loss: 0.0003723349582287483, Final Batch Loss: 4.08721316489391e-05\n",
      "Epoch 2098, Loss: 0.004181478230748326, Final Batch Loss: 0.00014333234867081046\n",
      "Epoch 2099, Loss: 0.005110448793857358, Final Batch Loss: 9.38349767238833e-05\n",
      "Epoch 2100, Loss: 0.0033083257658290677, Final Batch Loss: 0.00010166543506784365\n",
      "Epoch 2101, Loss: 0.03858027232490713, Final Batch Loss: 0.0001603947748662904\n",
      "Epoch 2102, Loss: 0.016251717985142022, Final Batch Loss: 0.004498329479247332\n",
      "Epoch 2103, Loss: 0.003373265117261326, Final Batch Loss: 0.00020697682339232415\n",
      "Epoch 2104, Loss: 0.03265661862678826, Final Batch Loss: 0.030997946858406067\n",
      "Epoch 2105, Loss: 0.0021944626205367967, Final Batch Loss: 0.0003004065656568855\n",
      "Epoch 2106, Loss: 0.008743360987864435, Final Batch Loss: 0.0011705508222803473\n",
      "Epoch 2107, Loss: 0.016559601288463455, Final Batch Loss: 0.00025982255465351045\n",
      "Epoch 2108, Loss: 0.0007217334496090189, Final Batch Loss: 4.409326356835663e-05\n",
      "Epoch 2109, Loss: 0.0027290918224025518, Final Batch Loss: 0.0005815561162307858\n",
      "Epoch 2110, Loss: 0.007699046669586096, Final Batch Loss: 0.006723023485392332\n",
      "Epoch 2111, Loss: 0.0009273156028939411, Final Batch Loss: 0.00019607783178798854\n",
      "Epoch 2112, Loss: 0.035584657423896715, Final Batch Loss: 0.00014491876936517656\n",
      "Epoch 2113, Loss: 0.01653778794570826, Final Batch Loss: 0.015189595520496368\n",
      "Epoch 2114, Loss: 0.0014889879312249832, Final Batch Loss: 8.382242231164128e-05\n",
      "Epoch 2115, Loss: 0.029132219293387607, Final Batch Loss: 0.00792553648352623\n",
      "Epoch 2116, Loss: 0.005559327488299459, Final Batch Loss: 0.0012518016155809164\n",
      "Epoch 2117, Loss: 0.0009158948087133467, Final Batch Loss: 9.515343117527664e-05\n",
      "Epoch 2118, Loss: 0.01317312206083443, Final Batch Loss: 0.0006120166508480906\n",
      "Epoch 2119, Loss: 0.0013689478582818992, Final Batch Loss: 9.758910891832784e-05\n",
      "Epoch 2120, Loss: 0.00587084774451796, Final Batch Loss: 0.0002803560928441584\n",
      "Epoch 2121, Loss: 0.0017319790204055607, Final Batch Loss: 0.0009040405275300145\n",
      "Epoch 2122, Loss: 0.004051533935125917, Final Batch Loss: 0.0024046648759394884\n",
      "Epoch 2123, Loss: 0.02415629758615978, Final Batch Loss: 0.0003973209240939468\n",
      "Epoch 2124, Loss: 0.029700919723836705, Final Batch Loss: 0.0002941646089311689\n",
      "Epoch 2125, Loss: 0.0015106514474609867, Final Batch Loss: 0.00034603176754899323\n",
      "Epoch 2126, Loss: 0.010792255343403667, Final Batch Loss: 0.0007495255558751523\n",
      "Epoch 2127, Loss: 0.002982598583912477, Final Batch Loss: 0.0005028358427807689\n",
      "Epoch 2128, Loss: 0.0018939936344395392, Final Batch Loss: 0.000478349655168131\n",
      "Epoch 2129, Loss: 0.0020045619748998433, Final Batch Loss: 0.0006017611012794077\n",
      "Epoch 2130, Loss: 0.0009916136114043184, Final Batch Loss: 0.0002831560268532485\n",
      "Epoch 2131, Loss: 0.002203877127612941, Final Batch Loss: 0.000861518841702491\n",
      "Epoch 2132, Loss: 0.005190307041630149, Final Batch Loss: 0.0002575902035459876\n",
      "Epoch 2133, Loss: 0.003741911961697042, Final Batch Loss: 0.0005758427432738245\n",
      "Epoch 2134, Loss: 0.013104231788020115, Final Batch Loss: 0.0002642139734234661\n",
      "Epoch 2135, Loss: 0.0026106884761247784, Final Batch Loss: 0.0003105097566731274\n",
      "Epoch 2136, Loss: 0.003210296097677201, Final Batch Loss: 0.0008665802888572216\n",
      "Epoch 2137, Loss: 0.006708315035211854, Final Batch Loss: 0.005336756352335215\n",
      "Epoch 2138, Loss: 0.003938737903808942, Final Batch Loss: 0.00040003727190196514\n",
      "Epoch 2139, Loss: 0.0027891542558791116, Final Batch Loss: 7.04793055774644e-05\n",
      "Epoch 2140, Loss: 0.0023538637105957605, Final Batch Loss: 0.00023708518710918725\n",
      "Epoch 2141, Loss: 0.003226372296921909, Final Batch Loss: 0.002606732537969947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2142, Loss: 0.0016632185888738604, Final Batch Loss: 2.893370583478827e-05\n",
      "Epoch 2143, Loss: 0.0008110229791782331, Final Batch Loss: 0.00037535029696300626\n",
      "Epoch 2144, Loss: 0.004141098979744129, Final Batch Loss: 0.0009320526733063161\n",
      "Epoch 2145, Loss: 0.0007914695288491203, Final Batch Loss: 1.9912969946744852e-05\n",
      "Epoch 2146, Loss: 0.004301865890738554, Final Batch Loss: 0.00019113553571514785\n",
      "Epoch 2147, Loss: 0.008677711244672537, Final Batch Loss: 0.0007948469137772918\n",
      "Epoch 2148, Loss: 0.03086865625664359, Final Batch Loss: 6.35961550869979e-05\n",
      "Epoch 2149, Loss: 0.0011491947516333312, Final Batch Loss: 0.0003883716999553144\n",
      "Epoch 2150, Loss: 0.0016499126722919755, Final Batch Loss: 0.0006389938644133508\n",
      "Epoch 2151, Loss: 0.001434389763744548, Final Batch Loss: 8.724158396944404e-05\n",
      "Epoch 2152, Loss: 0.001913939973746892, Final Batch Loss: 0.0004319255822338164\n",
      "Epoch 2153, Loss: 0.003359802441991633, Final Batch Loss: 0.0005518612451851368\n",
      "Epoch 2154, Loss: 0.0012692317177425139, Final Batch Loss: 0.00013689365005120635\n",
      "Epoch 2155, Loss: 0.004425667782925302, Final Batch Loss: 0.0030649120453745127\n",
      "Epoch 2156, Loss: 0.003587751642044168, Final Batch Loss: 0.002523586619645357\n",
      "Epoch 2157, Loss: 0.0030783975598751567, Final Batch Loss: 0.00010328814823878929\n",
      "Epoch 2158, Loss: 0.0005929119997745147, Final Batch Loss: 2.4575301722506993e-05\n",
      "Epoch 2159, Loss: 0.0019041480954911094, Final Batch Loss: 2.1667274268111214e-05\n",
      "Epoch 2160, Loss: 0.006379190424922854, Final Batch Loss: 0.0001354775158688426\n",
      "Epoch 2161, Loss: 0.0007950633516884409, Final Batch Loss: 0.00034056411823257804\n",
      "Epoch 2162, Loss: 0.002868839626898989, Final Batch Loss: 0.00047551869647577405\n",
      "Epoch 2163, Loss: 0.00449608834242099, Final Batch Loss: 0.0013551946030929685\n",
      "Epoch 2164, Loss: 0.0011152599836350419, Final Batch Loss: 0.0001611204497748986\n",
      "Epoch 2165, Loss: 0.0031842510361457244, Final Batch Loss: 0.0008518691174685955\n",
      "Epoch 2166, Loss: 0.0005708410153602017, Final Batch Loss: 7.369996455963701e-05\n",
      "Epoch 2167, Loss: 0.004436985200300114, Final Batch Loss: 0.0004529092402663082\n",
      "Epoch 2168, Loss: 0.0008109476293611806, Final Batch Loss: 5.453524136100896e-05\n",
      "Epoch 2169, Loss: 0.0005584933223872213, Final Batch Loss: 2.0343666619737633e-05\n",
      "Epoch 2170, Loss: 0.0005523390746020596, Final Batch Loss: 2.6159055778407492e-05\n",
      "Epoch 2171, Loss: 0.0008873870174284093, Final Batch Loss: 7.261450809892267e-05\n",
      "Epoch 2172, Loss: 0.0007003053178777918, Final Batch Loss: 0.00016750175564084202\n",
      "Epoch 2173, Loss: 0.000513254759425763, Final Batch Loss: 9.794010111363605e-05\n",
      "Epoch 2174, Loss: 0.007816521803761134, Final Batch Loss: 5.877024159417488e-05\n",
      "Epoch 2175, Loss: 0.0024356820722459815, Final Batch Loss: 0.0008110114140436053\n",
      "Epoch 2176, Loss: 0.004546944415778853, Final Batch Loss: 0.0001667128672124818\n",
      "Epoch 2177, Loss: 0.0022714558381267125, Final Batch Loss: 2.2947686375118792e-05\n",
      "Epoch 2178, Loss: 0.00046568877223762684, Final Batch Loss: 2.6921381504507735e-05\n",
      "Epoch 2179, Loss: 0.0005754366065957583, Final Batch Loss: 0.00039252135320566595\n",
      "Epoch 2180, Loss: 0.0034432597476552473, Final Batch Loss: 0.0020096253138035536\n",
      "Epoch 2181, Loss: 0.003128043161723326, Final Batch Loss: 6.0725287767127156e-05\n",
      "Epoch 2182, Loss: 0.0008876283391145989, Final Batch Loss: 0.00036158374859951437\n",
      "Epoch 2183, Loss: 0.0010538561255089007, Final Batch Loss: 8.244989294325933e-05\n",
      "Epoch 2184, Loss: 0.0011901694106200011, Final Batch Loss: 0.0003882356686517596\n",
      "Epoch 2185, Loss: 0.001395925908582285, Final Batch Loss: 0.0008222215692512691\n",
      "Epoch 2186, Loss: 0.0003194261789758457, Final Batch Loss: 7.198623279691674e-06\n",
      "Epoch 2187, Loss: 0.0014440975719480775, Final Batch Loss: 0.0002633384719956666\n",
      "Epoch 2188, Loss: 0.0009772400990186725, Final Batch Loss: 0.0003661156224552542\n",
      "Epoch 2189, Loss: 0.00035560534524847753, Final Batch Loss: 0.00013079062046017498\n",
      "Epoch 2190, Loss: 0.00359740488420357, Final Batch Loss: 0.0001417371240677312\n",
      "Epoch 2191, Loss: 0.009435448821022874, Final Batch Loss: 3.374990774318576e-05\n",
      "Epoch 2192, Loss: 0.00036735273533849977, Final Batch Loss: 7.75023945607245e-05\n",
      "Epoch 2193, Loss: 0.02458049480628688, Final Batch Loss: 0.00028191617457196116\n",
      "Epoch 2194, Loss: 0.005589723223238252, Final Batch Loss: 0.0036446405574679375\n",
      "Epoch 2195, Loss: 0.025340854132082313, Final Batch Loss: 0.0008639477891847491\n",
      "Epoch 2196, Loss: 0.0006467127859650645, Final Batch Loss: 4.103996980120428e-05\n",
      "Epoch 2197, Loss: 0.0013030643021920696, Final Batch Loss: 1.6130146832438186e-05\n",
      "Epoch 2198, Loss: 0.0006016864863340743, Final Batch Loss: 6.538852903759107e-05\n",
      "Epoch 2199, Loss: 0.007171807606937364, Final Batch Loss: 0.006792706437408924\n",
      "Epoch 2200, Loss: 0.004672521958127618, Final Batch Loss: 0.0025421695318073034\n",
      "Epoch 2201, Loss: 0.00126251775509445, Final Batch Loss: 1.3667879102285951e-05\n",
      "Epoch 2202, Loss: 0.03805933597323019, Final Batch Loss: 0.00011445854033809155\n",
      "Epoch 2203, Loss: 0.00079596886280342, Final Batch Loss: 1.2913063983432949e-05\n",
      "Epoch 2204, Loss: 0.00150362410931848, Final Batch Loss: 0.0007976539200171828\n",
      "Epoch 2205, Loss: 0.0013394367415457964, Final Batch Loss: 0.0001516702031949535\n",
      "Epoch 2206, Loss: 0.0006823268595326226, Final Batch Loss: 0.0003152040299028158\n",
      "Epoch 2207, Loss: 0.005248720066447277, Final Batch Loss: 0.0033209025859832764\n",
      "Epoch 2208, Loss: 0.0013451687700580806, Final Batch Loss: 0.00011190283112227917\n",
      "Epoch 2209, Loss: 0.0013968653001938947, Final Batch Loss: 5.197634891374037e-05\n",
      "Epoch 2210, Loss: 0.0021363869491324294, Final Batch Loss: 6.116537406342104e-05\n",
      "Epoch 2211, Loss: 0.0010597390682960395, Final Batch Loss: 3.8646914617856964e-05\n",
      "Epoch 2212, Loss: 0.034779066118062474, Final Batch Loss: 0.03038748726248741\n",
      "Epoch 2213, Loss: 0.0010569229198154062, Final Batch Loss: 0.0007034008740447462\n",
      "Epoch 2214, Loss: 0.009655281983214081, Final Batch Loss: 2.959889570774976e-05\n",
      "Epoch 2215, Loss: 0.0019175800480297767, Final Batch Loss: 0.00037399286520667374\n",
      "Epoch 2216, Loss: 0.0031521494702246855, Final Batch Loss: 1.2496787348936778e-05\n",
      "Epoch 2217, Loss: 0.008142398670315742, Final Batch Loss: 0.0061520677991211414\n",
      "Epoch 2218, Loss: 0.0010196902840107214, Final Batch Loss: 0.0006456376286223531\n",
      "Epoch 2219, Loss: 0.0007663346550543793, Final Batch Loss: 0.0003064731427002698\n",
      "Epoch 2220, Loss: 0.0003262347963755019, Final Batch Loss: 0.00017060170648619533\n",
      "Epoch 2221, Loss: 0.0024345170459127985, Final Batch Loss: 0.0006156816962175071\n",
      "Epoch 2222, Loss: 0.005119181761983782, Final Batch Loss: 0.0004765743506141007\n",
      "Epoch 2223, Loss: 0.0018293374305358157, Final Batch Loss: 3.7217498174868524e-05\n",
      "Epoch 2224, Loss: 0.0003349298240209464, Final Batch Loss: 5.651059836964123e-05\n",
      "Epoch 2225, Loss: 0.0013470150079228915, Final Batch Loss: 4.462729339138605e-05\n",
      "Epoch 2226, Loss: 0.00093075905169826, Final Batch Loss: 5.73688666918315e-05\n",
      "Epoch 2227, Loss: 0.0032521218963665888, Final Batch Loss: 2.41054585785605e-05\n",
      "Epoch 2228, Loss: 0.015565790170512628, Final Batch Loss: 5.636360583594069e-05\n",
      "Epoch 2229, Loss: 0.0006282416597969132, Final Batch Loss: 1.681759204075206e-05\n",
      "Epoch 2230, Loss: 0.0009895558687276207, Final Batch Loss: 0.0004006352392025292\n",
      "Epoch 2231, Loss: 0.0007035320668364875, Final Batch Loss: 4.634187280316837e-05\n",
      "Epoch 2232, Loss: 0.006309707305263146, Final Batch Loss: 2.072103052341845e-05\n",
      "Epoch 2233, Loss: 0.0016887448819034034, Final Batch Loss: 0.0003630654828157276\n",
      "Epoch 2234, Loss: 0.0010594927953206934, Final Batch Loss: 0.0001212997012771666\n",
      "Epoch 2235, Loss: 0.0006205150166351814, Final Batch Loss: 2.8374681278364733e-05\n",
      "Epoch 2236, Loss: 0.0019208697412977926, Final Batch Loss: 8.674796117702499e-05\n",
      "Epoch 2237, Loss: 0.000916002467420185, Final Batch Loss: 3.5403227229835466e-05\n",
      "Epoch 2238, Loss: 0.00270585433463566, Final Batch Loss: 0.0017641186714172363\n",
      "Epoch 2239, Loss: 0.005123669927343144, Final Batch Loss: 0.0001204667059937492\n",
      "Epoch 2240, Loss: 0.003611535577874747, Final Batch Loss: 4.050379357067868e-05\n",
      "Epoch 2241, Loss: 0.00027420627884566784, Final Batch Loss: 8.260364847956225e-05\n",
      "Epoch 2242, Loss: 0.0017684523045318201, Final Batch Loss: 0.0004716048133559525\n",
      "Epoch 2243, Loss: 0.001516502205049619, Final Batch Loss: 0.00048477889504283667\n",
      "Epoch 2244, Loss: 0.0014257008515414782, Final Batch Loss: 4.670525231631473e-05\n",
      "Epoch 2245, Loss: 0.0009918068890328868, Final Batch Loss: 0.0005423980765044689\n",
      "Epoch 2246, Loss: 0.0009389641563757323, Final Batch Loss: 4.681955761043355e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2247, Loss: 0.003020907868631184, Final Batch Loss: 0.00024512538220733404\n",
      "Epoch 2248, Loss: 0.0028572093578986824, Final Batch Loss: 0.0008557333494536579\n",
      "Epoch 2249, Loss: 0.003221361277610413, Final Batch Loss: 3.038980321434792e-05\n",
      "Epoch 2250, Loss: 0.0008938273067542468, Final Batch Loss: 0.000607088441029191\n",
      "Epoch 2251, Loss: 0.0007169037380663212, Final Batch Loss: 0.00020564872829709202\n",
      "Epoch 2252, Loss: 0.0010076791113533545, Final Batch Loss: 0.00041975383646786213\n",
      "Epoch 2253, Loss: 0.003009212996403221, Final Batch Loss: 0.001039261231198907\n",
      "Epoch 2254, Loss: 0.002122853577020578, Final Batch Loss: 0.0012892729137092829\n",
      "Epoch 2255, Loss: 0.000251633369771298, Final Batch Loss: 7.416576409013942e-05\n",
      "Epoch 2256, Loss: 0.0006397840570571134, Final Batch Loss: 2.6645137040759437e-05\n",
      "Epoch 2257, Loss: 0.00016136860722326674, Final Batch Loss: 2.272122037538793e-05\n",
      "Epoch 2258, Loss: 0.00015625139531039167, Final Batch Loss: 3.017237213498447e-05\n",
      "Epoch 2259, Loss: 0.001335703465883853, Final Batch Loss: 4.8220859753200784e-05\n",
      "Epoch 2260, Loss: 0.00041251159927924164, Final Batch Loss: 5.897548180655576e-05\n",
      "Epoch 2261, Loss: 0.00030689997583976947, Final Batch Loss: 2.62938228843268e-05\n",
      "Epoch 2262, Loss: 0.0033217806867469335, Final Batch Loss: 2.2586706108995713e-05\n",
      "Epoch 2263, Loss: 0.0012852056534029543, Final Batch Loss: 0.0003224234387744218\n",
      "Epoch 2264, Loss: 0.000592501943174284, Final Batch Loss: 9.344711725134403e-05\n",
      "Epoch 2265, Loss: 0.0020071804901817814, Final Batch Loss: 0.0003414008824620396\n",
      "Epoch 2266, Loss: 0.0011946948534387047, Final Batch Loss: 1.4790960449317936e-05\n",
      "Epoch 2267, Loss: 0.007800916668202262, Final Batch Loss: 0.0001179796745418571\n",
      "Epoch 2268, Loss: 0.0011753176513593644, Final Batch Loss: 0.00026755727594718337\n",
      "Epoch 2269, Loss: 0.001991650555282831, Final Batch Loss: 0.00032024391111917794\n",
      "Epoch 2270, Loss: 0.0007051721404423006, Final Batch Loss: 0.00021598230523522943\n",
      "Epoch 2271, Loss: 0.001171666155642015, Final Batch Loss: 0.0009879308054223657\n",
      "Epoch 2272, Loss: 0.0004788465921592433, Final Batch Loss: 0.00031244155252352357\n",
      "Epoch 2273, Loss: 0.0031998680788092315, Final Batch Loss: 0.0007546478300355375\n",
      "Epoch 2274, Loss: 0.00037971374695189297, Final Batch Loss: 0.00010611450852593407\n",
      "Epoch 2275, Loss: 0.0005314857880875934, Final Batch Loss: 0.0003157042374368757\n",
      "Epoch 2276, Loss: 0.0014828871571808122, Final Batch Loss: 0.00044353154953569174\n",
      "Epoch 2277, Loss: 0.0005355839666663087, Final Batch Loss: 1.2623694601643365e-05\n",
      "Epoch 2278, Loss: 0.0012964210181962699, Final Batch Loss: 0.0002042432752205059\n",
      "Epoch 2279, Loss: 0.00030608892120653763, Final Batch Loss: 8.796646579867229e-05\n",
      "Epoch 2280, Loss: 0.0002900570798374247, Final Batch Loss: 0.00017597600526642054\n",
      "Epoch 2281, Loss: 0.0010123193496838212, Final Batch Loss: 1.0728261258918792e-05\n",
      "Epoch 2282, Loss: 0.0013439815302263014, Final Batch Loss: 0.00047270749928429723\n",
      "Epoch 2283, Loss: 0.0002124829243257409, Final Batch Loss: 1.8507305867387913e-05\n",
      "Epoch 2284, Loss: 0.0001807040571293328, Final Batch Loss: 3.7393081584014e-05\n",
      "Epoch 2285, Loss: 0.005329701198206749, Final Batch Loss: 0.004999255295842886\n",
      "Epoch 2286, Loss: 0.0005169418473087717, Final Batch Loss: 6.205189129104838e-05\n",
      "Epoch 2287, Loss: 0.0016563980989303673, Final Batch Loss: 0.0014711564872413874\n",
      "Epoch 2288, Loss: 0.0010781067867355887, Final Batch Loss: 5.018482988816686e-05\n",
      "Epoch 2289, Loss: 0.0011961370673816418, Final Batch Loss: 0.00011703927884809673\n",
      "Epoch 2290, Loss: 0.0009745620118337683, Final Batch Loss: 0.0006012038211338222\n",
      "Epoch 2291, Loss: 0.00033108662864833605, Final Batch Loss: 1.4824543541180901e-05\n",
      "Epoch 2292, Loss: 0.0003585169652069453, Final Batch Loss: 5.632471584249288e-05\n",
      "Epoch 2293, Loss: 0.0042968577981810085, Final Batch Loss: 0.000244805560214445\n",
      "Epoch 2294, Loss: 0.0008288982116937404, Final Batch Loss: 2.528391451050993e-05\n",
      "Epoch 2295, Loss: 0.00280574328644434, Final Batch Loss: 6.2411098042503e-05\n",
      "Epoch 2296, Loss: 0.0006205675053934101, Final Batch Loss: 9.398078691447154e-05\n",
      "Epoch 2297, Loss: 0.0015545317437499762, Final Batch Loss: 2.296324964845553e-05\n",
      "Epoch 2298, Loss: 0.0004929982114845188, Final Batch Loss: 0.00017749813559930772\n",
      "Epoch 2299, Loss: 0.00020418184612935875, Final Batch Loss: 1.8990513126482256e-05\n",
      "Epoch 2300, Loss: 0.003839586104732007, Final Batch Loss: 0.0013244501315057278\n",
      "Epoch 2301, Loss: 0.0017961908961297013, Final Batch Loss: 0.0001272953668376431\n",
      "Epoch 2302, Loss: 0.0021643057552864775, Final Batch Loss: 0.00043730236939154565\n",
      "Epoch 2303, Loss: 0.0007329045874939766, Final Batch Loss: 4.3684318370651454e-05\n",
      "Epoch 2304, Loss: 0.0009473103173149866, Final Batch Loss: 0.0008453374612145126\n",
      "Epoch 2305, Loss: 0.0012553731794469059, Final Batch Loss: 0.0006511468673124909\n",
      "Epoch 2306, Loss: 0.0003283495989307994, Final Batch Loss: 8.344167144969106e-05\n",
      "Epoch 2307, Loss: 0.0002287943243572954, Final Batch Loss: 1.1484487004054245e-05\n",
      "Epoch 2308, Loss: 0.0028434249143174384, Final Batch Loss: 3.8982656406005844e-05\n",
      "Epoch 2309, Loss: 0.001488934534791042, Final Batch Loss: 0.0005328312399797142\n",
      "Epoch 2310, Loss: 0.00029848933627363294, Final Batch Loss: 8.792246808297932e-05\n",
      "Epoch 2311, Loss: 0.000890346615051385, Final Batch Loss: 3.825125168077648e-05\n",
      "Epoch 2312, Loss: 0.00034771379000630986, Final Batch Loss: 9.880853758659214e-05\n",
      "Epoch 2313, Loss: 0.0003329776382088312, Final Batch Loss: 8.695645192347001e-06\n",
      "Epoch 2314, Loss: 0.0004301830103941029, Final Batch Loss: 0.0001283333112951368\n",
      "Epoch 2315, Loss: 0.0008972527139121667, Final Batch Loss: 0.000712896347977221\n",
      "Epoch 2316, Loss: 0.0002283334033563733, Final Batch Loss: 0.00014161424769554287\n",
      "Epoch 2317, Loss: 0.00011532526605151361, Final Batch Loss: 1.7736383597366512e-05\n",
      "Epoch 2318, Loss: 0.001045679411618039, Final Batch Loss: 0.0002363054227316752\n",
      "Epoch 2319, Loss: 0.0006255587845771515, Final Batch Loss: 2.2192007236299105e-05\n",
      "Epoch 2320, Loss: 8.907021401682869e-05, Final Batch Loss: 2.6979585527442396e-05\n",
      "Epoch 2321, Loss: 0.00033325217009405605, Final Batch Loss: 9.804792352952063e-05\n",
      "Epoch 2322, Loss: 0.00038653208957839524, Final Batch Loss: 5.726809467887506e-05\n",
      "Epoch 2323, Loss: 8.722261736693326e-05, Final Batch Loss: 2.8825999834225513e-05\n",
      "Epoch 2324, Loss: 0.019780920428729587, Final Batch Loss: 0.00016323661839123815\n",
      "Epoch 2325, Loss: 0.002244027270535298, Final Batch Loss: 1.3269481314637233e-05\n",
      "Epoch 2326, Loss: 0.0004207359997963067, Final Batch Loss: 6.04839988227468e-05\n",
      "Epoch 2327, Loss: 0.0022504177595692454, Final Batch Loss: 0.002138458425179124\n",
      "Epoch 2328, Loss: 0.00161720248797792, Final Batch Loss: 0.0004976995987817645\n",
      "Epoch 2329, Loss: 0.0007557435019407421, Final Batch Loss: 0.00010916217433987185\n",
      "Epoch 2330, Loss: 0.0017886282148538157, Final Batch Loss: 0.0008096932433545589\n",
      "Epoch 2331, Loss: 0.0012279273814783664, Final Batch Loss: 0.00010994822514476255\n",
      "Epoch 2332, Loss: 0.0013752215381828137, Final Batch Loss: 7.943945092847571e-05\n",
      "Epoch 2333, Loss: 0.00019796385822701268, Final Batch Loss: 1.64430784934666e-05\n",
      "Epoch 2334, Loss: 0.00038208765545277856, Final Batch Loss: 0.00018426853057462722\n",
      "Epoch 2335, Loss: 0.00016808790678624064, Final Batch Loss: 8.653145050629973e-05\n",
      "Epoch 2336, Loss: 0.001071930157195311, Final Batch Loss: 5.366530240280554e-05\n",
      "Epoch 2337, Loss: 0.00072246250056196, Final Batch Loss: 6.231648876564577e-05\n",
      "Epoch 2338, Loss: 0.00011088875169207313, Final Batch Loss: 1.0935657883237582e-05\n",
      "Epoch 2339, Loss: 0.0008907657793315593, Final Batch Loss: 8.980689017334953e-06\n",
      "Epoch 2340, Loss: 0.0028891669353470206, Final Batch Loss: 0.0027477918192744255\n",
      "Epoch 2341, Loss: 0.0013547366120292281, Final Batch Loss: 0.00031323242001235485\n",
      "Epoch 2342, Loss: 9.064174719242146e-05, Final Batch Loss: 2.64556711044861e-05\n",
      "Epoch 2343, Loss: 0.00025498029754089657, Final Batch Loss: 8.655372221255675e-05\n",
      "Epoch 2344, Loss: 0.0032371067736676196, Final Batch Loss: 1.5864265151321888e-05\n",
      "Epoch 2345, Loss: 0.02182950047972554, Final Batch Loss: 4.094907490070909e-05\n",
      "Epoch 2346, Loss: 0.0029989675094839185, Final Batch Loss: 0.0026085125282406807\n",
      "Epoch 2347, Loss: 0.0005288917818688788, Final Batch Loss: 6.596880848519504e-05\n",
      "Epoch 2348, Loss: 0.001244243117980659, Final Batch Loss: 0.000807547417934984\n",
      "Epoch 2349, Loss: 0.004383357532788068, Final Batch Loss: 0.00019336053810548037\n",
      "Epoch 2350, Loss: 0.00042506713907641824, Final Batch Loss: 0.00011397263006074354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2351, Loss: 0.000661814262457483, Final Batch Loss: 0.00014696994912810624\n",
      "Epoch 2352, Loss: 0.003395122243091464, Final Batch Loss: 9.319152741227299e-05\n",
      "Epoch 2353, Loss: 0.00048472097478224896, Final Batch Loss: 5.849438821314834e-06\n",
      "Epoch 2354, Loss: 0.0003613143544498598, Final Batch Loss: 8.563076335121877e-06\n",
      "Epoch 2355, Loss: 0.00015085825543792453, Final Batch Loss: 4.357576108304784e-05\n",
      "Epoch 2356, Loss: 0.0012101142274332233, Final Batch Loss: 0.00029060710221529007\n",
      "Epoch 2357, Loss: 0.00012916393279738259, Final Batch Loss: 7.86655982665252e-06\n",
      "Epoch 2358, Loss: 0.0004125783834751928, Final Batch Loss: 0.00016739856800995767\n",
      "Epoch 2359, Loss: 0.0008864585724950302, Final Batch Loss: 3.425746763241477e-05\n",
      "Epoch 2360, Loss: 0.0008129361012834124, Final Batch Loss: 0.00032294142874889076\n",
      "Epoch 2361, Loss: 0.0004055319118378975, Final Batch Loss: 8.066775626502931e-05\n",
      "Epoch 2362, Loss: 0.0006538956868098467, Final Batch Loss: 2.7423589017416816e-06\n",
      "Epoch 2363, Loss: 0.000840208845147572, Final Batch Loss: 6.784887955291197e-05\n",
      "Epoch 2364, Loss: 0.012280347014893778, Final Batch Loss: 2.040287472482305e-05\n",
      "Epoch 2365, Loss: 0.003595553593186196, Final Batch Loss: 0.0006678968784399331\n",
      "Epoch 2366, Loss: 0.0013924446720920969, Final Batch Loss: 0.0010151726892217994\n",
      "Epoch 2367, Loss: 0.001032287735142745, Final Batch Loss: 5.828970461152494e-05\n",
      "Epoch 2368, Loss: 0.004159318248639465, Final Batch Loss: 0.003249954665079713\n",
      "Epoch 2369, Loss: 0.0011621912053669803, Final Batch Loss: 8.933168282965198e-05\n",
      "Epoch 2370, Loss: 4.042957016281434e-05, Final Batch Loss: 9.266031156585086e-06\n",
      "Epoch 2371, Loss: 0.0005454444835777394, Final Batch Loss: 0.00035307256621308625\n",
      "Epoch 2372, Loss: 0.011396101681384607, Final Batch Loss: 0.0005405573174357414\n",
      "Epoch 2373, Loss: 0.006091592906159349, Final Batch Loss: 0.000229928846238181\n",
      "Epoch 2374, Loss: 0.02948862933408236, Final Batch Loss: 0.028655052185058594\n",
      "Epoch 2375, Loss: 0.00019165808316756738, Final Batch Loss: 7.327636558329687e-05\n",
      "Epoch 2376, Loss: 0.0006468589754149434, Final Batch Loss: 1.442401571694063e-05\n",
      "Epoch 2377, Loss: 0.008319364940689411, Final Batch Loss: 0.0007061570067889988\n",
      "Epoch 2378, Loss: 0.0007229121147247497, Final Batch Loss: 5.0401304179104045e-05\n",
      "Epoch 2379, Loss: 0.00023219003105623415, Final Batch Loss: 7.5575690061668865e-06\n",
      "Epoch 2380, Loss: 0.0005335300029400969, Final Batch Loss: 5.031024556956254e-05\n",
      "Epoch 2381, Loss: 0.007939579920275719, Final Batch Loss: 0.00010029591794591397\n",
      "Epoch 2382, Loss: 0.001481690820583026, Final Batch Loss: 0.001355217071250081\n",
      "Epoch 2383, Loss: 0.0012493609901866876, Final Batch Loss: 3.3679811167530715e-05\n",
      "Epoch 2384, Loss: 0.004271252005423776, Final Batch Loss: 1.5548404235232738e-06\n",
      "Epoch 2385, Loss: 0.0002527046290197177, Final Batch Loss: 2.4572969778091647e-05\n",
      "Epoch 2386, Loss: 0.001404458185788826, Final Batch Loss: 6.0218637372599915e-05\n",
      "Epoch 2387, Loss: 0.0001746272237141966, Final Batch Loss: 5.246305954642594e-05\n",
      "Epoch 2388, Loss: 0.0003847826610581251, Final Batch Loss: 6.426910840673372e-05\n",
      "Epoch 2389, Loss: 0.0003413488120713737, Final Batch Loss: 8.252004045061767e-05\n",
      "Epoch 2390, Loss: 0.0006853149061498698, Final Batch Loss: 5.6160501117119566e-05\n",
      "Epoch 2391, Loss: 0.0007714371458860114, Final Batch Loss: 4.080749931745231e-05\n",
      "Epoch 2392, Loss: 0.0018897748814197257, Final Batch Loss: 0.00010999522055499256\n",
      "Epoch 2393, Loss: 0.0008661925221531419, Final Batch Loss: 0.00016240074182860553\n",
      "Epoch 2394, Loss: 0.00047778329826542176, Final Batch Loss: 0.00011883102706633508\n",
      "Epoch 2395, Loss: 0.0007802857253409456, Final Batch Loss: 3.931033643311821e-05\n",
      "Epoch 2396, Loss: 0.0019951403128288803, Final Batch Loss: 1.0855213076865766e-05\n",
      "Epoch 2397, Loss: 0.0018931531312773586, Final Batch Loss: 1.9950321075157262e-06\n",
      "Epoch 2398, Loss: 0.00024096697688946733, Final Batch Loss: 9.706426681077573e-06\n",
      "Epoch 2399, Loss: 0.01972569783902145, Final Batch Loss: 0.019430188462138176\n",
      "Epoch 2400, Loss: 0.026720450020093267, Final Batch Loss: 0.0006286184070631862\n",
      "Epoch 2401, Loss: 0.00023215359396999702, Final Batch Loss: 2.3553348000859842e-05\n",
      "Epoch 2402, Loss: 0.004956594937539194, Final Batch Loss: 2.905113433371298e-05\n",
      "Epoch 2403, Loss: 0.0007365299316006713, Final Batch Loss: 3.5414537705946714e-05\n",
      "Epoch 2404, Loss: 0.0017090587643906474, Final Batch Loss: 0.0002570427895989269\n",
      "Epoch 2405, Loss: 0.002072013321594568, Final Batch Loss: 0.0016113994643092155\n",
      "Epoch 2406, Loss: 0.0013200643697928172, Final Batch Loss: 0.00023271133250091225\n",
      "Epoch 2407, Loss: 0.0007468272633559536, Final Batch Loss: 2.3446216800948605e-05\n",
      "Epoch 2408, Loss: 0.0005429163102235179, Final Batch Loss: 0.00021798102534376085\n",
      "Epoch 2409, Loss: 0.002980724841108895, Final Batch Loss: 0.0025683387648314238\n",
      "Epoch 2410, Loss: 0.00856866576395987, Final Batch Loss: 1.954319486685563e-05\n",
      "Epoch 2411, Loss: 0.000963756525379722, Final Batch Loss: 7.312020898098126e-05\n",
      "Epoch 2412, Loss: 0.0008786014186625835, Final Batch Loss: 0.0002991685760207474\n",
      "Epoch 2413, Loss: 0.026768382820591796, Final Batch Loss: 2.9325728974072263e-05\n",
      "Epoch 2414, Loss: 0.04253444073401624, Final Batch Loss: 0.04175402596592903\n",
      "Epoch 2415, Loss: 0.024899803844164126, Final Batch Loss: 0.00018900517898146063\n",
      "Epoch 2416, Loss: 0.0007634156354470178, Final Batch Loss: 0.00042856865911744535\n",
      "Epoch 2417, Loss: 0.017532621692225803, Final Batch Loss: 0.01726149208843708\n",
      "Epoch 2418, Loss: 0.0014925128562026657, Final Batch Loss: 7.016669405857101e-05\n",
      "Epoch 2419, Loss: 0.0010051991648651892, Final Batch Loss: 9.824321023188531e-05\n",
      "Epoch 2420, Loss: 0.000959012184466701, Final Batch Loss: 0.0003007593913935125\n",
      "Epoch 2421, Loss: 0.0008787954175204504, Final Batch Loss: 0.00047130018356256187\n",
      "Epoch 2422, Loss: 0.0011236097234359477, Final Batch Loss: 3.253893737564795e-05\n",
      "Epoch 2423, Loss: 0.0012187488973722793, Final Batch Loss: 0.00010189096065005288\n",
      "Epoch 2424, Loss: 0.0006269878231250914, Final Batch Loss: 6.329586176434532e-05\n",
      "Epoch 2425, Loss: 0.0005422645635917434, Final Batch Loss: 0.00018208922119811177\n",
      "Epoch 2426, Loss: 0.0005985038606013404, Final Batch Loss: 0.0001635891676414758\n",
      "Epoch 2427, Loss: 0.0024920066389313433, Final Batch Loss: 8.026578143471852e-06\n",
      "Epoch 2428, Loss: 0.0014173310628393665, Final Batch Loss: 0.0003388161421753466\n",
      "Epoch 2429, Loss: 0.00039422494228347205, Final Batch Loss: 6.614409358007833e-05\n",
      "Epoch 2430, Loss: 0.0005542052749660797, Final Batch Loss: 6.313188350759447e-05\n",
      "Epoch 2431, Loss: 0.001470174243877409, Final Batch Loss: 2.4375494831474498e-05\n",
      "Epoch 2432, Loss: 0.0027987081793980906, Final Batch Loss: 0.0017189222853630781\n",
      "Epoch 2433, Loss: 0.0009192756915581413, Final Batch Loss: 0.00011368091509211808\n",
      "Epoch 2434, Loss: 0.0008634779660496861, Final Batch Loss: 0.00048239328316412866\n",
      "Epoch 2435, Loss: 0.0012304049364502134, Final Batch Loss: 0.0006469843210652471\n",
      "Epoch 2436, Loss: 0.022490619663585676, Final Batch Loss: 0.003641147632151842\n",
      "Epoch 2437, Loss: 0.0022515825603477424, Final Batch Loss: 0.00040721773984842\n",
      "Epoch 2438, Loss: 0.02049683016957715, Final Batch Loss: 0.003354751504957676\n",
      "Epoch 2439, Loss: 0.022845535830128938, Final Batch Loss: 0.0008968798792921007\n",
      "Epoch 2440, Loss: 0.000556997605599463, Final Batch Loss: 0.00010827455844264477\n",
      "Epoch 2441, Loss: 0.0013083115218250896, Final Batch Loss: 0.0006412354414351285\n",
      "Epoch 2442, Loss: 0.000984163983957842, Final Batch Loss: 0.0001250759669346735\n",
      "Epoch 2443, Loss: 0.0021208294965617824, Final Batch Loss: 9.340736869489774e-05\n",
      "Epoch 2444, Loss: 0.0004190463005215861, Final Batch Loss: 6.229226710274816e-05\n",
      "Epoch 2445, Loss: 0.0007934884088172112, Final Batch Loss: 4.4318923755781725e-05\n",
      "Epoch 2446, Loss: 0.0009178801119560376, Final Batch Loss: 0.0005798398633487523\n",
      "Epoch 2447, Loss: 0.0006884920803713612, Final Batch Loss: 0.00010330869554309174\n",
      "Epoch 2448, Loss: 0.0026793604592967313, Final Batch Loss: 5.54669568373356e-05\n",
      "Epoch 2449, Loss: 0.004375733180495445, Final Batch Loss: 0.0025260227266699076\n",
      "Epoch 2450, Loss: 0.0028729022524203174, Final Batch Loss: 0.002570230280980468\n",
      "Epoch 2451, Loss: 0.0007474105887013138, Final Batch Loss: 2.1702351659769192e-05\n",
      "Epoch 2452, Loss: 0.0006165279828564962, Final Batch Loss: 0.00012248032726347446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2453, Loss: 0.0044891701836604625, Final Batch Loss: 0.003766253124922514\n",
      "Epoch 2454, Loss: 0.012173924863418506, Final Batch Loss: 0.00012995275028515607\n",
      "Epoch 2455, Loss: 0.0005602750788966659, Final Batch Loss: 0.00027219398180022836\n",
      "Epoch 2456, Loss: 0.0018469832357368432, Final Batch Loss: 0.0010320500005036592\n",
      "Epoch 2457, Loss: 0.002335280427359976, Final Batch Loss: 0.0018436484970152378\n",
      "Epoch 2458, Loss: 0.0005629722400044557, Final Batch Loss: 0.00028095734887756407\n",
      "Epoch 2459, Loss: 0.0024188362585846335, Final Batch Loss: 0.0003809240006376058\n",
      "Epoch 2460, Loss: 0.0020446470662136562, Final Batch Loss: 0.000602341431658715\n",
      "Epoch 2461, Loss: 0.0025110491515079048, Final Batch Loss: 0.00031780419521965086\n",
      "Epoch 2462, Loss: 0.005430438326584408, Final Batch Loss: 0.005120535846799612\n",
      "Epoch 2463, Loss: 0.017555041828018147, Final Batch Loss: 0.00807221420109272\n",
      "Epoch 2464, Loss: 0.001014649711578386, Final Batch Loss: 4.023536530439742e-05\n",
      "Epoch 2465, Loss: 0.0006705292144033592, Final Batch Loss: 0.00022495292068924755\n",
      "Epoch 2466, Loss: 0.0015546106296824291, Final Batch Loss: 0.0002647710498422384\n",
      "Epoch 2467, Loss: 0.0008177038689609617, Final Batch Loss: 2.6034966140286997e-05\n",
      "Epoch 2468, Loss: 0.004687417440436548, Final Batch Loss: 5.516300370800309e-05\n",
      "Epoch 2469, Loss: 0.002021675530158973, Final Batch Loss: 1.3056626812613104e-05\n",
      "Epoch 2470, Loss: 0.0008862351296556881, Final Batch Loss: 0.0002687112137209624\n",
      "Epoch 2471, Loss: 0.0005746164752054028, Final Batch Loss: 0.00025276574888266623\n",
      "Epoch 2472, Loss: 0.0005507601563294884, Final Batch Loss: 4.405020081321709e-05\n",
      "Epoch 2473, Loss: 0.0009686796474852599, Final Batch Loss: 0.00039845742867328227\n",
      "Epoch 2474, Loss: 0.0009165841729554813, Final Batch Loss: 0.0004436803865246475\n",
      "Epoch 2475, Loss: 0.002146170681953663, Final Batch Loss: 0.00022501203056890517\n",
      "Epoch 2476, Loss: 0.000994144575088285, Final Batch Loss: 4.3509728129720315e-05\n",
      "Epoch 2477, Loss: 0.004355204495368525, Final Batch Loss: 0.00409481767565012\n",
      "Epoch 2478, Loss: 0.0011590835274546407, Final Batch Loss: 0.00010525286052143201\n",
      "Epoch 2479, Loss: 0.0017353861421725014, Final Batch Loss: 0.0011031568283215165\n",
      "Epoch 2480, Loss: 0.000747407733797445, Final Batch Loss: 1.8611563064041547e-05\n",
      "Epoch 2481, Loss: 0.0015239304175338475, Final Batch Loss: 0.0013980804942548275\n",
      "Epoch 2482, Loss: 0.0003456677968642907, Final Batch Loss: 4.6148630644893274e-05\n",
      "Epoch 2483, Loss: 0.0004126538915443234, Final Batch Loss: 8.684534986969084e-05\n",
      "Epoch 2484, Loss: 0.0009344833215436665, Final Batch Loss: 1.0688276233850047e-05\n",
      "Epoch 2485, Loss: 0.0005299375643517124, Final Batch Loss: 5.656796565745026e-05\n",
      "Epoch 2486, Loss: 0.010795714930281974, Final Batch Loss: 4.338365761213936e-05\n",
      "Epoch 2487, Loss: 0.0010887894004554255, Final Batch Loss: 0.00015102335601113737\n",
      "Epoch 2488, Loss: 0.00015822885870875325, Final Batch Loss: 1.6399260857724585e-05\n",
      "Epoch 2489, Loss: 0.0003502320505504031, Final Batch Loss: 8.143895684042946e-05\n",
      "Epoch 2490, Loss: 0.0026778958781505935, Final Batch Loss: 5.493524804478511e-05\n",
      "Epoch 2491, Loss: 0.0018967532378155738, Final Batch Loss: 0.00023844189126975834\n",
      "Epoch 2492, Loss: 0.007263518469699193, Final Batch Loss: 0.00014330232806969434\n",
      "Epoch 2493, Loss: 0.0006776303093829483, Final Batch Loss: 0.00026237632846459746\n",
      "Epoch 2494, Loss: 0.017202697570610326, Final Batch Loss: 0.014426231384277344\n",
      "Epoch 2495, Loss: 0.0017199461290147156, Final Batch Loss: 0.0006577894673682749\n",
      "Epoch 2496, Loss: 0.00041273850365541875, Final Batch Loss: 3.5091728932457045e-05\n",
      "Epoch 2497, Loss: 0.00021455139540194068, Final Batch Loss: 1.8430697309668176e-05\n",
      "Epoch 2498, Loss: 0.00047457068740186514, Final Batch Loss: 8.691869879839942e-05\n",
      "Epoch 2499, Loss: 0.0008043782363529317, Final Batch Loss: 2.8687143640127033e-05\n",
      "Epoch 2500, Loss: 0.0019242994767409982, Final Batch Loss: 0.0005067993188276887\n",
      "Epoch 2501, Loss: 0.00027857091299665626, Final Batch Loss: 8.252331463154405e-05\n",
      "Epoch 2502, Loss: 0.0004390422127471538, Final Batch Loss: 0.0001317966089118272\n",
      "Epoch 2503, Loss: 0.000428852252298384, Final Batch Loss: 0.0003010998771060258\n",
      "Epoch 2504, Loss: 0.0011214271708013257, Final Batch Loss: 0.00024750831653364\n",
      "Epoch 2505, Loss: 0.00017216416745213792, Final Batch Loss: 2.290323027409613e-05\n",
      "Epoch 2506, Loss: 0.0011686003126669675, Final Batch Loss: 0.0002998039417434484\n",
      "Epoch 2507, Loss: 0.021373945004597772, Final Batch Loss: 8.607336349086836e-05\n",
      "Epoch 2508, Loss: 0.00030542835884261876, Final Batch Loss: 0.00016355447587557137\n",
      "Epoch 2509, Loss: 0.05529630281671416, Final Batch Loss: 1.8588245438877493e-05\n",
      "Epoch 2510, Loss: 0.007307542546186596, Final Batch Loss: 0.0008932595956139266\n",
      "Epoch 2511, Loss: 0.001178144570076256, Final Batch Loss: 5.750815398641862e-05\n",
      "Epoch 2512, Loss: 0.0013724158379773144, Final Batch Loss: 0.0005129606579430401\n",
      "Epoch 2513, Loss: 0.022419519311370095, Final Batch Loss: 0.0002448348677717149\n",
      "Epoch 2514, Loss: 0.007726823736447841, Final Batch Loss: 0.00039625150384381413\n",
      "Epoch 2515, Loss: 0.004030382417113287, Final Batch Loss: 0.002452494576573372\n",
      "Epoch 2516, Loss: 0.0197830060205888, Final Batch Loss: 0.0007658562390133739\n",
      "Epoch 2517, Loss: 0.000451092090770544, Final Batch Loss: 1.139685537054902e-05\n",
      "Epoch 2518, Loss: 0.04011288959736703, Final Batch Loss: 0.00011408348655095324\n",
      "Epoch 2519, Loss: 0.027532930791494437, Final Batch Loss: 0.00011568436457309872\n",
      "Epoch 2520, Loss: 0.02710018701327499, Final Batch Loss: 0.02665996365249157\n",
      "Epoch 2521, Loss: 0.0037920966333331307, Final Batch Loss: 2.233904342574533e-05\n",
      "Epoch 2522, Loss: 0.020429309976861987, Final Batch Loss: 1.4117710634309333e-05\n",
      "Epoch 2523, Loss: 0.04301350764581002, Final Batch Loss: 0.00019549709395505488\n",
      "Epoch 2524, Loss: 0.001729356255964376, Final Batch Loss: 0.00022315778187476099\n",
      "Epoch 2525, Loss: 0.0009799345716601238, Final Batch Loss: 0.0005647953366860747\n",
      "Epoch 2526, Loss: 0.001380216926918365, Final Batch Loss: 0.0009602527134120464\n",
      "Epoch 2527, Loss: 0.001858368661487475, Final Batch Loss: 0.00030116175184957683\n",
      "Epoch 2528, Loss: 0.007062203458190197, Final Batch Loss: 1.0785577615024522e-05\n",
      "Epoch 2529, Loss: 0.008688732756127138, Final Batch Loss: 4.758395516546443e-05\n",
      "Epoch 2530, Loss: 0.0006505945821118075, Final Batch Loss: 0.00019527963013388216\n",
      "Epoch 2531, Loss: 0.005086407021735795, Final Batch Loss: 0.00017547495372127742\n",
      "Epoch 2532, Loss: 0.0013392407272476703, Final Batch Loss: 0.00012368954776320606\n",
      "Epoch 2533, Loss: 0.001757762824126985, Final Batch Loss: 0.0002482416166458279\n",
      "Epoch 2534, Loss: 0.0007624909994774498, Final Batch Loss: 0.00014652196841780096\n",
      "Epoch 2535, Loss: 0.0008218580624088645, Final Batch Loss: 0.0001367714285152033\n",
      "Epoch 2536, Loss: 0.00044903151865582913, Final Batch Loss: 0.0001738787250360474\n",
      "Epoch 2537, Loss: 0.0013854074059054255, Final Batch Loss: 0.0002590483636595309\n",
      "Epoch 2538, Loss: 0.00224137281475123, Final Batch Loss: 0.0006022749585099518\n",
      "Epoch 2539, Loss: 0.0034779248308041133, Final Batch Loss: 0.0011447431752458215\n",
      "Epoch 2540, Loss: 0.001885360266896896, Final Batch Loss: 0.00021184915385674685\n",
      "Epoch 2541, Loss: 0.0002863127629098017, Final Batch Loss: 4.672638897318393e-05\n",
      "Epoch 2542, Loss: 0.0014247783838072792, Final Batch Loss: 0.0002490724727977067\n",
      "Epoch 2543, Loss: 0.0008005664712982252, Final Batch Loss: 4.224367148708552e-05\n",
      "Epoch 2544, Loss: 0.007325133121412364, Final Batch Loss: 1.736033482302446e-05\n",
      "Epoch 2545, Loss: 0.0008561714348616078, Final Batch Loss: 0.000313650380121544\n",
      "Epoch 2546, Loss: 0.00047164115676423535, Final Batch Loss: 0.00017452699830755591\n",
      "Epoch 2547, Loss: 0.002447228238452226, Final Batch Loss: 4.5658453018404543e-05\n",
      "Epoch 2548, Loss: 0.0009005536921904422, Final Batch Loss: 0.0006336437654681504\n",
      "Epoch 2549, Loss: 0.0024055067806330044, Final Batch Loss: 0.0001911397703224793\n",
      "Epoch 2550, Loss: 0.0005974382656859234, Final Batch Loss: 7.932938751764596e-05\n",
      "Epoch 2551, Loss: 0.006646792622632347, Final Batch Loss: 3.19331738865003e-05\n",
      "Epoch 2552, Loss: 0.0009167478128802031, Final Batch Loss: 4.8017573135439306e-05\n",
      "Epoch 2553, Loss: 0.0006615802412852645, Final Batch Loss: 0.00021148522500880063\n",
      "Epoch 2554, Loss: 0.0006271567617659457, Final Batch Loss: 7.463848305633292e-05\n",
      "Epoch 2555, Loss: 0.01017282395332586, Final Batch Loss: 9.841046994552016e-05\n",
      "Epoch 2556, Loss: 0.001189816859550774, Final Batch Loss: 0.000726562924683094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2557, Loss: 0.003714277598191984, Final Batch Loss: 7.21550386515446e-05\n",
      "Epoch 2558, Loss: 0.0004735680340672843, Final Batch Loss: 0.00023111469636205584\n",
      "Epoch 2559, Loss: 0.00032602808641968295, Final Batch Loss: 1.8590821127872914e-05\n",
      "Epoch 2560, Loss: 0.011096940481365891, Final Batch Loss: 0.010351537726819515\n",
      "Epoch 2561, Loss: 0.0004398262608447112, Final Batch Loss: 0.00010875273437704891\n",
      "Epoch 2562, Loss: 0.0012098797706130426, Final Batch Loss: 0.0005319582996889949\n",
      "Epoch 2563, Loss: 0.001770733782905154, Final Batch Loss: 0.0005085349548608065\n",
      "Epoch 2564, Loss: 0.04753425311355386, Final Batch Loss: 0.04461357742547989\n",
      "Epoch 2565, Loss: 0.010215899033937603, Final Batch Loss: 0.007373531349003315\n",
      "Epoch 2566, Loss: 0.003979569984949194, Final Batch Loss: 0.003615319961681962\n",
      "Epoch 2567, Loss: 0.014390078278665897, Final Batch Loss: 6.66879495838657e-05\n",
      "Epoch 2568, Loss: 0.0012336497329670237, Final Batch Loss: 3.0483703085337766e-05\n",
      "Epoch 2569, Loss: 0.016705476795323193, Final Batch Loss: 0.006231463979929686\n",
      "Epoch 2570, Loss: 0.0008446955180261284, Final Batch Loss: 0.0005854876362718642\n",
      "Epoch 2571, Loss: 0.008971639203082304, Final Batch Loss: 0.00018135725986212492\n",
      "Epoch 2572, Loss: 0.0015659893251722679, Final Batch Loss: 0.000621640239842236\n",
      "Epoch 2573, Loss: 0.00105777910357574, Final Batch Loss: 0.0004951703594997525\n",
      "Epoch 2574, Loss: 0.0013316864933585748, Final Batch Loss: 6.781861156923696e-05\n",
      "Epoch 2575, Loss: 0.011395961373636965, Final Batch Loss: 0.00786685012280941\n",
      "Epoch 2576, Loss: 0.0012754333693010267, Final Batch Loss: 5.0980121159227565e-05\n",
      "Epoch 2577, Loss: 0.0025574711326044053, Final Batch Loss: 0.000483361684018746\n",
      "Epoch 2578, Loss: 0.002411661211226601, Final Batch Loss: 0.0009565273066982627\n",
      "Epoch 2579, Loss: 0.009180089575238526, Final Batch Loss: 0.0006267349817790091\n",
      "Epoch 2580, Loss: 0.0012254926696186885, Final Batch Loss: 3.610113344620913e-05\n",
      "Epoch 2581, Loss: 0.0005470028227136936, Final Batch Loss: 3.8462207157863304e-05\n",
      "Epoch 2582, Loss: 0.002276185441587586, Final Batch Loss: 8.328021067427471e-05\n",
      "Epoch 2583, Loss: 0.0009718869478092529, Final Batch Loss: 0.00019775965483859181\n",
      "Epoch 2584, Loss: 0.0006806758774473565, Final Batch Loss: 0.0004438138857949525\n",
      "Epoch 2585, Loss: 0.0005410415997175733, Final Batch Loss: 0.0001654763036640361\n",
      "Epoch 2586, Loss: 0.002770930004771799, Final Batch Loss: 8.080536645138636e-05\n",
      "Epoch 2587, Loss: 0.0007481624415959232, Final Batch Loss: 8.093118231045082e-05\n",
      "Epoch 2588, Loss: 0.0018247614207211882, Final Batch Loss: 0.001237676478922367\n",
      "Epoch 2589, Loss: 0.00037762242209282704, Final Batch Loss: 8.734068251214921e-05\n",
      "Epoch 2590, Loss: 0.0022777081103413366, Final Batch Loss: 0.0005950008635409176\n",
      "Epoch 2591, Loss: 0.0017856080394267337, Final Batch Loss: 1.1705220458679833e-05\n",
      "Epoch 2592, Loss: 0.0026589132103254087, Final Batch Loss: 0.0018403230933472514\n",
      "Epoch 2593, Loss: 0.0005280160330585204, Final Batch Loss: 0.0001801728649297729\n",
      "Epoch 2594, Loss: 0.005673628038493916, Final Batch Loss: 2.2783373424317688e-05\n",
      "Epoch 2595, Loss: 0.0007238232137751766, Final Batch Loss: 0.00025203757104463875\n",
      "Epoch 2596, Loss: 0.004811132166651078, Final Batch Loss: 0.00025416718563064933\n",
      "Epoch 2597, Loss: 0.006077430167351849, Final Batch Loss: 0.00016772157687228173\n",
      "Epoch 2598, Loss: 0.0010152680697501637, Final Batch Loss: 0.00011036074283765629\n",
      "Epoch 2599, Loss: 0.0030105255282251164, Final Batch Loss: 0.0017793376464396715\n",
      "Epoch 2600, Loss: 0.000774781292420812, Final Batch Loss: 0.00013733681407757103\n",
      "Epoch 2601, Loss: 0.0018209992012998555, Final Batch Loss: 0.00016556460468564183\n",
      "Epoch 2602, Loss: 0.017778898756660055, Final Batch Loss: 0.017192687839269638\n",
      "Epoch 2603, Loss: 0.0032264616475004004, Final Batch Loss: 5.243607120064553e-06\n",
      "Epoch 2604, Loss: 0.0004000904518761672, Final Batch Loss: 3.307496081106365e-05\n",
      "Epoch 2605, Loss: 0.00154155467680539, Final Batch Loss: 0.0006114198477007449\n",
      "Epoch 2606, Loss: 0.006431469904782716, Final Batch Loss: 0.005622277036309242\n",
      "Epoch 2607, Loss: 0.0011408687169023324, Final Batch Loss: 0.00030219467589631677\n",
      "Epoch 2608, Loss: 0.000831363104225602, Final Batch Loss: 0.00014208110223989934\n",
      "Epoch 2609, Loss: 0.0009598809956514742, Final Batch Loss: 0.0005371136940084398\n",
      "Epoch 2610, Loss: 0.00022165188056533225, Final Batch Loss: 3.079733141930774e-05\n",
      "Epoch 2611, Loss: 0.010576418935670517, Final Batch Loss: 9.607517858967185e-05\n",
      "Epoch 2612, Loss: 0.0005747398536186665, Final Batch Loss: 0.0002129079948645085\n",
      "Epoch 2613, Loss: 0.001076906233720365, Final Batch Loss: 0.0001360197929898277\n",
      "Epoch 2614, Loss: 0.006145375773485284, Final Batch Loss: 0.00546739436686039\n",
      "Epoch 2615, Loss: 0.006173669175041141, Final Batch Loss: 0.00010187458974542096\n",
      "Epoch 2616, Loss: 0.0010739041281340178, Final Batch Loss: 0.00045332818990573287\n",
      "Epoch 2617, Loss: 0.001479203870985657, Final Batch Loss: 0.0008575257961638272\n",
      "Epoch 2618, Loss: 0.0008587246193201281, Final Batch Loss: 0.00029667626949958503\n",
      "Epoch 2619, Loss: 0.0018247799671371467, Final Batch Loss: 0.0007734731771051884\n",
      "Epoch 2620, Loss: 0.0057968084038293455, Final Batch Loss: 0.0017140741692855954\n",
      "Epoch 2621, Loss: 0.018445760717440862, Final Batch Loss: 0.000528189295437187\n",
      "Epoch 2622, Loss: 0.001435692796803778, Final Batch Loss: 8.067707676673308e-05\n",
      "Epoch 2623, Loss: 0.0022497624449897557, Final Batch Loss: 0.0015597561141476035\n",
      "Epoch 2624, Loss: 0.0029898470747866668, Final Batch Loss: 0.002194830449298024\n",
      "Epoch 2625, Loss: 0.0008382793166674674, Final Batch Loss: 0.0005046858568675816\n",
      "Epoch 2626, Loss: 0.0007645301957381889, Final Batch Loss: 0.00017763608775567263\n",
      "Epoch 2627, Loss: 0.0008155920702392905, Final Batch Loss: 3.2295836263074307e-06\n",
      "Epoch 2628, Loss: 0.0008918049170461018, Final Batch Loss: 5.1637067372212186e-05\n",
      "Epoch 2629, Loss: 0.0012367189119686373, Final Batch Loss: 0.00012375685037113726\n",
      "Epoch 2630, Loss: 0.0009243634858648875, Final Batch Loss: 0.00012657706975005567\n",
      "Epoch 2631, Loss: 0.0014699900275445543, Final Batch Loss: 0.00024149722594302148\n",
      "Epoch 2632, Loss: 0.0014795107053942047, Final Batch Loss: 0.00010243737779092044\n",
      "Epoch 2633, Loss: 0.036140973927103914, Final Batch Loss: 0.035725004971027374\n",
      "Epoch 2634, Loss: 0.0015324556443374604, Final Batch Loss: 3.481657768134028e-05\n",
      "Epoch 2635, Loss: 0.0007998194341780618, Final Batch Loss: 0.0003933594562113285\n",
      "Epoch 2636, Loss: 0.0004395083478812012, Final Batch Loss: 0.0003344374999869615\n",
      "Epoch 2637, Loss: 0.00043592452493612655, Final Batch Loss: 0.00015359286044258624\n",
      "Epoch 2638, Loss: 0.001857683491834905, Final Batch Loss: 7.735290273558348e-05\n",
      "Epoch 2639, Loss: 0.0010464440947544063, Final Batch Loss: 8.77668135217391e-05\n",
      "Epoch 2640, Loss: 0.006431910383980721, Final Batch Loss: 3.84913946618326e-05\n",
      "Epoch 2641, Loss: 0.0006035735605109949, Final Batch Loss: 0.00014828157145529985\n",
      "Epoch 2642, Loss: 0.0002941738803201588, Final Batch Loss: 2.0660680092987604e-05\n",
      "Epoch 2643, Loss: 0.0004419254182721488, Final Batch Loss: 0.00014622652088291943\n",
      "Epoch 2644, Loss: 0.005648602469591424, Final Batch Loss: 0.00012325242278166115\n",
      "Epoch 2645, Loss: 0.0005640525705530308, Final Batch Loss: 0.00023146685271058232\n",
      "Epoch 2646, Loss: 0.0003352429521328304, Final Batch Loss: 0.00013555381156038493\n",
      "Epoch 2647, Loss: 0.0009223844826919958, Final Batch Loss: 0.00019988210988231003\n",
      "Epoch 2648, Loss: 0.00035920987102144863, Final Batch Loss: 8.09358898550272e-05\n",
      "Epoch 2649, Loss: 0.003289290823886404, Final Batch Loss: 0.0013360314769670367\n",
      "Epoch 2650, Loss: 0.0012020993344776798, Final Batch Loss: 0.00013663418940268457\n",
      "Epoch 2651, Loss: 0.013218032341683283, Final Batch Loss: 0.0001208940229844302\n",
      "Epoch 2652, Loss: 0.0010161146892642137, Final Batch Loss: 0.0006206301623024046\n",
      "Epoch 2653, Loss: 0.002134353646397358, Final Batch Loss: 6.007183765177615e-05\n",
      "Epoch 2654, Loss: 0.002467248144967016, Final Batch Loss: 2.3272328689927235e-05\n",
      "Epoch 2655, Loss: 0.02309551742655458, Final Batch Loss: 0.021926071494817734\n",
      "Epoch 2656, Loss: 0.00036132901414021035, Final Batch Loss: 7.089297014317708e-06\n",
      "Epoch 2657, Loss: 0.00028922520505147986, Final Batch Loss: 0.000108786640339531\n",
      "Epoch 2658, Loss: 0.04366217770802905, Final Batch Loss: 6.531408871524036e-05\n",
      "Epoch 2659, Loss: 0.004054611366882455, Final Batch Loss: 8.210195665014908e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2660, Loss: 0.00237291357916547, Final Batch Loss: 2.981512079713866e-05\n",
      "Epoch 2661, Loss: 0.002192575964727439, Final Batch Loss: 0.0003676640335470438\n",
      "Epoch 2662, Loss: 0.018149712144804653, Final Batch Loss: 0.0003161169297527522\n",
      "Epoch 2663, Loss: 0.000647905017103767, Final Batch Loss: 0.00024293333990499377\n",
      "Epoch 2664, Loss: 0.0006605553571716882, Final Batch Loss: 0.0002598375722300261\n",
      "Epoch 2665, Loss: 0.00027130738271807786, Final Batch Loss: 0.00013112819578964263\n",
      "Epoch 2666, Loss: 0.00044347041693981737, Final Batch Loss: 1.7136975657194853e-05\n",
      "Epoch 2667, Loss: 0.0031690815194451716, Final Batch Loss: 0.00034412971581332386\n",
      "Epoch 2668, Loss: 0.005933644133619964, Final Batch Loss: 0.0001410578261129558\n",
      "Epoch 2669, Loss: 0.0006653217060375027, Final Batch Loss: 0.00024904924794100225\n",
      "Epoch 2670, Loss: 0.007639702365850098, Final Batch Loss: 0.005730907432734966\n",
      "Epoch 2671, Loss: 0.002388767865340924, Final Batch Loss: 7.546803681179881e-05\n",
      "Epoch 2672, Loss: 0.000815475381386932, Final Batch Loss: 0.0002044958237092942\n",
      "Epoch 2673, Loss: 0.0004752228778670542, Final Batch Loss: 0.00017151786596514285\n",
      "Epoch 2674, Loss: 0.001012891279970063, Final Batch Loss: 3.264307088102214e-05\n",
      "Epoch 2675, Loss: 0.0020481898973230273, Final Batch Loss: 0.00011796127364505082\n",
      "Epoch 2676, Loss: 0.0004411354530020617, Final Batch Loss: 8.116589742712677e-05\n",
      "Epoch 2677, Loss: 0.005723082484109909, Final Batch Loss: 0.0055064852349460125\n",
      "Epoch 2678, Loss: 0.023570501398353372, Final Batch Loss: 0.00015172992425505072\n",
      "Epoch 2679, Loss: 0.024523494870663853, Final Batch Loss: 0.024167776107788086\n",
      "Epoch 2680, Loss: 0.005761215383245144, Final Batch Loss: 4.11620203522034e-05\n",
      "Epoch 2681, Loss: 0.001984365124371834, Final Batch Loss: 0.0001770378730725497\n",
      "Epoch 2682, Loss: 0.0009275981738028349, Final Batch Loss: 0.00011349661508575082\n",
      "Epoch 2683, Loss: 0.0010349417789257132, Final Batch Loss: 0.00018119574815500528\n",
      "Epoch 2684, Loss: 0.0014843775788904168, Final Batch Loss: 0.0003591490094549954\n",
      "Epoch 2685, Loss: 0.0008165100407495629, Final Batch Loss: 0.0002004040143219754\n",
      "Epoch 2686, Loss: 0.003381323396752123, Final Batch Loss: 0.0030307373963296413\n",
      "Epoch 2687, Loss: 0.008561932983866427, Final Batch Loss: 7.034592272248119e-05\n",
      "Epoch 2688, Loss: 0.0017799182332964847, Final Batch Loss: 0.0004672440409194678\n",
      "Epoch 2689, Loss: 0.002633321586472448, Final Batch Loss: 2.754940214799717e-05\n",
      "Epoch 2690, Loss: 0.0023602821838721866, Final Batch Loss: 1.8819753677234985e-05\n",
      "Epoch 2691, Loss: 0.0009986745317291934, Final Batch Loss: 0.0008158452110365033\n",
      "Epoch 2692, Loss: 0.003225149921490811, Final Batch Loss: 0.00036222164635546505\n",
      "Epoch 2693, Loss: 0.003326794132590294, Final Batch Loss: 3.085465868934989e-05\n",
      "Epoch 2694, Loss: 0.0005444511007226538, Final Batch Loss: 1.8551403627498075e-05\n",
      "Epoch 2695, Loss: 0.0037866681232117116, Final Batch Loss: 0.00017994089284911752\n",
      "Epoch 2696, Loss: 0.0007072227235767059, Final Batch Loss: 0.00017976871458813548\n",
      "Epoch 2697, Loss: 0.0009111551917158067, Final Batch Loss: 0.00011390765575924888\n",
      "Epoch 2698, Loss: 0.03663175857946044, Final Batch Loss: 8.636924758320674e-05\n",
      "Epoch 2699, Loss: 0.0013214317659731023, Final Batch Loss: 0.00028423868934623897\n",
      "Epoch 2700, Loss: 0.0016216366766457213, Final Batch Loss: 0.000590983428992331\n",
      "Epoch 2701, Loss: 0.00041645655073807575, Final Batch Loss: 0.0001336623972747475\n",
      "Epoch 2702, Loss: 0.013395034504355863, Final Batch Loss: 0.0008136976975947618\n",
      "Epoch 2703, Loss: 0.012033487710141344, Final Batch Loss: 7.954396278364584e-05\n",
      "Epoch 2704, Loss: 0.0011564390806597658, Final Batch Loss: 0.00026355759473517537\n",
      "Epoch 2705, Loss: 0.0011805002868641168, Final Batch Loss: 0.0003488117072265595\n",
      "Epoch 2706, Loss: 0.018089869015966542, Final Batch Loss: 0.0006163020734675229\n",
      "Epoch 2707, Loss: 0.008042518093134277, Final Batch Loss: 3.4000062441919e-05\n",
      "Epoch 2708, Loss: 0.0004168478371866513, Final Batch Loss: 4.879142579738982e-05\n",
      "Epoch 2709, Loss: 0.0018406443414278328, Final Batch Loss: 0.0005525578744709492\n",
      "Epoch 2710, Loss: 0.0007254441989061888, Final Batch Loss: 0.00022153208556119353\n",
      "Epoch 2711, Loss: 0.01578800377319567, Final Batch Loss: 1.171327312476933e-05\n",
      "Epoch 2712, Loss: 0.001323951531048806, Final Batch Loss: 9.352434972242918e-06\n",
      "Epoch 2713, Loss: 0.0011310000190860592, Final Batch Loss: 9.058848081622273e-05\n",
      "Epoch 2714, Loss: 0.0005140615830896422, Final Batch Loss: 3.5810095141641796e-05\n",
      "Epoch 2715, Loss: 0.0029007433586230036, Final Batch Loss: 3.742866465472616e-05\n",
      "Epoch 2716, Loss: 0.030115077664959244, Final Batch Loss: 2.9280377930263057e-05\n",
      "Epoch 2717, Loss: 0.0017494086714577861, Final Batch Loss: 0.0008610901422798634\n",
      "Epoch 2718, Loss: 0.005605939641100122, Final Batch Loss: 4.800244278158061e-05\n",
      "Epoch 2719, Loss: 0.0021452264536492294, Final Batch Loss: 2.6880921723204665e-05\n",
      "Epoch 2720, Loss: 0.03855700972417253, Final Batch Loss: 0.0006036360282450914\n",
      "Epoch 2721, Loss: 0.001503047138612601, Final Batch Loss: 2.815994776028674e-05\n",
      "Epoch 2722, Loss: 0.0033142012980533764, Final Batch Loss: 0.0017754050204530358\n",
      "Epoch 2723, Loss: 0.0024308839565492235, Final Batch Loss: 0.00023750634863972664\n",
      "Epoch 2724, Loss: 0.0012413482982083224, Final Batch Loss: 0.000330348004354164\n",
      "Epoch 2725, Loss: 0.002043114247499034, Final Batch Loss: 0.0009643955272622406\n",
      "Epoch 2726, Loss: 0.0011191210651304573, Final Batch Loss: 0.0004069740534760058\n",
      "Epoch 2727, Loss: 0.020130193792283535, Final Batch Loss: 0.0001309470972046256\n",
      "Epoch 2728, Loss: 0.0025375285404152237, Final Batch Loss: 0.0013251660857349634\n",
      "Epoch 2729, Loss: 0.016680230910424143, Final Batch Loss: 0.00029747089138254523\n",
      "Epoch 2730, Loss: 0.001038591221004026, Final Batch Loss: 0.00020529722678475082\n",
      "Epoch 2731, Loss: 0.0010865700533031486, Final Batch Loss: 4.546131822280586e-05\n",
      "Epoch 2732, Loss: 0.003819474033662118, Final Batch Loss: 0.0027026368770748377\n",
      "Epoch 2733, Loss: 0.03572239485220052, Final Batch Loss: 0.03412811458110809\n",
      "Epoch 2734, Loss: 0.0008634184159745928, Final Batch Loss: 3.984184513683431e-05\n",
      "Epoch 2735, Loss: 0.0033701460124575533, Final Batch Loss: 9.672679152572528e-05\n",
      "Epoch 2736, Loss: 0.0033223562058992684, Final Batch Loss: 0.0015846405876800418\n",
      "Epoch 2737, Loss: 0.0017733210734149907, Final Batch Loss: 0.0005412222817540169\n",
      "Epoch 2738, Loss: 0.0019027207690669456, Final Batch Loss: 2.2831840396975167e-05\n",
      "Epoch 2739, Loss: 0.018320677347219316, Final Batch Loss: 0.0001220954436575994\n",
      "Epoch 2740, Loss: 0.002398099808488041, Final Batch Loss: 0.00010514018504181877\n",
      "Epoch 2741, Loss: 0.0009803015936995507, Final Batch Loss: 0.00010785317135741934\n",
      "Epoch 2742, Loss: 0.000786200791480951, Final Batch Loss: 0.00038386115920729935\n",
      "Epoch 2743, Loss: 0.0009942037249857094, Final Batch Loss: 0.00023109391622710973\n",
      "Epoch 2744, Loss: 0.0016370547818951309, Final Batch Loss: 0.00042294460581615567\n",
      "Epoch 2745, Loss: 0.0004938475467497483, Final Batch Loss: 1.9809951481875032e-05\n",
      "Epoch 2746, Loss: 0.0015553670527879149, Final Batch Loss: 9.167748794425279e-05\n",
      "Epoch 2747, Loss: 0.006471978461377148, Final Batch Loss: 0.00016062500071711838\n",
      "Epoch 2748, Loss: 0.001822289232222829, Final Batch Loss: 0.00011879006342496723\n",
      "Epoch 2749, Loss: 0.0010590456395220826, Final Batch Loss: 0.0005000411183573306\n",
      "Epoch 2750, Loss: 0.0021259159075270873, Final Batch Loss: 0.0017322921194136143\n",
      "Epoch 2751, Loss: 0.003058861784666078, Final Batch Loss: 4.66417295683641e-05\n",
      "Epoch 2752, Loss: 0.0010580538400972728, Final Batch Loss: 5.361071816878393e-05\n",
      "Epoch 2753, Loss: 0.000282182234514039, Final Batch Loss: 8.396418706979603e-05\n",
      "Epoch 2754, Loss: 0.0007056126341922209, Final Batch Loss: 0.00017429782019462436\n",
      "Epoch 2755, Loss: 0.0004152433593844762, Final Batch Loss: 0.00012816877278964967\n",
      "Epoch 2756, Loss: 0.0021767352081951685, Final Batch Loss: 0.00018377102969679981\n",
      "Epoch 2757, Loss: 0.0011257486476097256, Final Batch Loss: 7.304034079425037e-05\n",
      "Epoch 2758, Loss: 0.00027536507900549623, Final Batch Loss: 2.8464512524806196e-06\n",
      "Epoch 2759, Loss: 0.00032385296071879566, Final Batch Loss: 1.9060946215176955e-05\n",
      "Epoch 2760, Loss: 0.008737662802559498, Final Batch Loss: 0.00014286924852058291\n",
      "Epoch 2761, Loss: 0.03734792378236307, Final Batch Loss: 0.0004324814071878791\n",
      "Epoch 2762, Loss: 0.0016568838582315948, Final Batch Loss: 0.0009995558066293597\n",
      "Epoch 2763, Loss: 0.0028305051382631063, Final Batch Loss: 0.0013232904020696878\n",
      "Epoch 2764, Loss: 0.001398059532220941, Final Batch Loss: 0.0010914287995547056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2765, Loss: 0.005586302864685422, Final Batch Loss: 0.00010596960055409\n",
      "Epoch 2766, Loss: 0.003277929066825891, Final Batch Loss: 0.002484878757968545\n",
      "Epoch 2767, Loss: 0.0025453236121393275, Final Batch Loss: 2.9751918191323057e-05\n",
      "Epoch 2768, Loss: 0.00325736452214187, Final Batch Loss: 7.442972128046677e-05\n",
      "Epoch 2769, Loss: 0.0006799103248340543, Final Batch Loss: 0.0001887097314465791\n",
      "Epoch 2770, Loss: 0.001035887617035769, Final Batch Loss: 0.0003482576285023242\n",
      "Epoch 2771, Loss: 0.003280506170995068, Final Batch Loss: 3.407893382245675e-05\n",
      "Epoch 2772, Loss: 0.0012495394112193026, Final Batch Loss: 0.0004964168183505535\n",
      "Epoch 2773, Loss: 0.0009803814491533558, Final Batch Loss: 7.092850864864886e-05\n",
      "Epoch 2774, Loss: 0.006410852030967362, Final Batch Loss: 0.00606025755405426\n",
      "Epoch 2775, Loss: 0.009782416571397334, Final Batch Loss: 6.398020195774734e-05\n",
      "Epoch 2776, Loss: 0.002521827358577866, Final Batch Loss: 0.001525441650301218\n",
      "Epoch 2777, Loss: 0.0016135496261995286, Final Batch Loss: 0.00010619944077916443\n",
      "Epoch 2778, Loss: 0.021273633956298, Final Batch Loss: 0.0003094489802606404\n",
      "Epoch 2779, Loss: 0.002783807682135375, Final Batch Loss: 0.00014012394240126014\n",
      "Epoch 2780, Loss: 0.001042982245053281, Final Batch Loss: 0.00045659058378078043\n",
      "Epoch 2781, Loss: 0.0006661036022705957, Final Batch Loss: 3.6388373700901866e-05\n",
      "Epoch 2782, Loss: 0.0006140056284493767, Final Batch Loss: 8.143054583342746e-05\n",
      "Epoch 2783, Loss: 0.13135421794868307, Final Batch Loss: 7.940500654513016e-05\n",
      "Epoch 2784, Loss: 0.0009159289766103029, Final Batch Loss: 0.0001168974704341963\n",
      "Epoch 2785, Loss: 0.0015991548279998824, Final Batch Loss: 3.280283999629319e-05\n",
      "Epoch 2786, Loss: 0.0012502822282840498, Final Batch Loss: 0.000118041287350934\n",
      "Epoch 2787, Loss: 0.0033064446251955815, Final Batch Loss: 0.0016222255071625113\n",
      "Epoch 2788, Loss: 0.02729573324904777, Final Batch Loss: 0.025829467922449112\n",
      "Epoch 2789, Loss: 0.005073080865258817, Final Batch Loss: 7.673734944546595e-05\n",
      "Epoch 2790, Loss: 0.0006864728056825697, Final Batch Loss: 0.0002247916127089411\n",
      "Epoch 2791, Loss: 0.0010728725828812458, Final Batch Loss: 0.00038197555113583803\n",
      "Epoch 2792, Loss: 0.0007173095655161887, Final Batch Loss: 0.00021164400095585734\n",
      "Epoch 2793, Loss: 0.004647244191801292, Final Batch Loss: 0.00118262751493603\n",
      "Epoch 2794, Loss: 0.0012312595208641142, Final Batch Loss: 0.00014558041584677994\n",
      "Epoch 2795, Loss: 0.0005727570460294373, Final Batch Loss: 0.0001038741393131204\n",
      "Epoch 2796, Loss: 0.12033033435000107, Final Batch Loss: 0.11969556659460068\n",
      "Epoch 2797, Loss: 0.004007485156762414, Final Batch Loss: 0.0005270474357530475\n",
      "Epoch 2798, Loss: 0.002073297386232298, Final Batch Loss: 0.00022176837956067175\n",
      "Epoch 2799, Loss: 0.05954838008619845, Final Batch Loss: 0.03634819760918617\n",
      "Epoch 2800, Loss: 0.0037449474330060184, Final Batch Loss: 0.0031668972223997116\n",
      "Epoch 2801, Loss: 0.003463613182248082, Final Batch Loss: 0.00046658344217576087\n",
      "Epoch 2802, Loss: 0.002002910274313763, Final Batch Loss: 0.0009726737043820322\n",
      "Epoch 2803, Loss: 0.001109653225285001, Final Batch Loss: 0.0001899337803479284\n",
      "Epoch 2804, Loss: 0.0012419777922332287, Final Batch Loss: 0.000495712913107127\n",
      "Epoch 2805, Loss: 0.0013962317316327244, Final Batch Loss: 0.0005643889890052378\n",
      "Epoch 2806, Loss: 0.000767023790103849, Final Batch Loss: 0.00011107383761554956\n",
      "Epoch 2807, Loss: 0.0021647668327204883, Final Batch Loss: 0.0001571002503624186\n",
      "Epoch 2808, Loss: 0.005996069550747052, Final Batch Loss: 0.0011880923993885517\n",
      "Epoch 2809, Loss: 0.001287539729673881, Final Batch Loss: 0.0004888511030003428\n",
      "Epoch 2810, Loss: 0.0008366805850528181, Final Batch Loss: 0.00038128599408082664\n",
      "Epoch 2811, Loss: 0.00040200607327278703, Final Batch Loss: 9.853290976025164e-06\n",
      "Epoch 2812, Loss: 0.006761852739145979, Final Batch Loss: 0.0005726352683268487\n",
      "Epoch 2813, Loss: 0.004809992227819748, Final Batch Loss: 0.0031698348466306925\n",
      "Epoch 2814, Loss: 0.0012198119547974784, Final Batch Loss: 2.5125274987658486e-05\n",
      "Epoch 2815, Loss: 0.0005475502930494258, Final Batch Loss: 2.9709555747103877e-05\n",
      "Epoch 2816, Loss: 0.03821070406775107, Final Batch Loss: 0.00013664117432199419\n",
      "Epoch 2817, Loss: 0.0012040447909384966, Final Batch Loss: 0.00020235843840055168\n",
      "Epoch 2818, Loss: 0.002584972869954072, Final Batch Loss: 0.002027767477557063\n",
      "Epoch 2819, Loss: 0.0006768201856175438, Final Batch Loss: 6.604444934055209e-05\n",
      "Epoch 2820, Loss: 0.001352674498775741, Final Batch Loss: 3.4777051041601226e-05\n",
      "Epoch 2821, Loss: 0.001510196721937973, Final Batch Loss: 4.995002382202074e-05\n",
      "Epoch 2822, Loss: 0.0012768758097081445, Final Batch Loss: 0.00012248473649378866\n",
      "Epoch 2823, Loss: 0.00040086422814056277, Final Batch Loss: 4.934172102366574e-05\n",
      "Epoch 2824, Loss: 0.0064325607654609485, Final Batch Loss: 0.0008574468083679676\n",
      "Epoch 2825, Loss: 0.0003580345801310614, Final Batch Loss: 9.958733426174149e-05\n",
      "Epoch 2826, Loss: 0.0010562437382759526, Final Batch Loss: 0.0001725755719235167\n",
      "Epoch 2827, Loss: 0.0005752598262915853, Final Batch Loss: 2.10869220609311e-05\n",
      "Epoch 2828, Loss: 0.00037500037069548853, Final Batch Loss: 4.325087138568051e-05\n",
      "Epoch 2829, Loss: 0.006131767851911718, Final Batch Loss: 6.00935636612121e-05\n",
      "Epoch 2830, Loss: 0.0011788135161623359, Final Batch Loss: 7.257939432747662e-05\n",
      "Epoch 2831, Loss: 0.003210782228052267, Final Batch Loss: 2.2835929485154338e-05\n",
      "Epoch 2832, Loss: 0.0003224620704713743, Final Batch Loss: 9.332165063824505e-05\n",
      "Epoch 2833, Loss: 0.002207656652899459, Final Batch Loss: 8.941257692640647e-05\n",
      "Epoch 2834, Loss: 0.0014808762753091287, Final Batch Loss: 4.51693958893884e-05\n",
      "Epoch 2835, Loss: 0.0007356136484304443, Final Batch Loss: 0.00011450299643911421\n",
      "Epoch 2836, Loss: 0.001415584050846519, Final Batch Loss: 8.51241493364796e-05\n",
      "Epoch 2837, Loss: 0.002047715628577862, Final Batch Loss: 0.00016824551858007908\n",
      "Epoch 2838, Loss: 0.0002985221472044941, Final Batch Loss: 0.00019768881611526012\n",
      "Epoch 2839, Loss: 0.0012542940021376126, Final Batch Loss: 3.252027090638876e-05\n",
      "Epoch 2840, Loss: 0.001268983782210853, Final Batch Loss: 6.17360055912286e-05\n",
      "Epoch 2841, Loss: 0.0015497502745347447, Final Batch Loss: 9.557449629937764e-06\n",
      "Epoch 2842, Loss: 0.000925961350731086, Final Batch Loss: 0.0001833108253777027\n",
      "Epoch 2843, Loss: 0.0009217262468155241, Final Batch Loss: 1.8148492017644458e-05\n",
      "Epoch 2844, Loss: 0.003275261689850595, Final Batch Loss: 0.002526226919144392\n",
      "Epoch 2845, Loss: 0.0003141321358270943, Final Batch Loss: 3.957868830184452e-05\n",
      "Epoch 2846, Loss: 0.0006531869457830908, Final Batch Loss: 0.0004974403418600559\n",
      "Epoch 2847, Loss: 0.0014165558150125435, Final Batch Loss: 0.0003213584132026881\n",
      "Epoch 2848, Loss: 0.009515393954643514, Final Batch Loss: 8.468223677482456e-05\n",
      "Epoch 2849, Loss: 0.001549398552015191, Final Batch Loss: 0.0011887331493198872\n",
      "Epoch 2850, Loss: 0.0009090321418625535, Final Batch Loss: 6.056639540474862e-05\n",
      "Epoch 2851, Loss: 0.000575412841499201, Final Batch Loss: 5.950515696895309e-05\n",
      "Epoch 2852, Loss: 0.00038715239588782424, Final Batch Loss: 0.00018780387472361326\n",
      "Epoch 2853, Loss: 0.0026735782375908457, Final Batch Loss: 0.0008910555625334382\n",
      "Epoch 2854, Loss: 0.0009065189078683034, Final Batch Loss: 0.00020279137243051082\n",
      "Epoch 2855, Loss: 0.006761522250599228, Final Batch Loss: 3.121273766737431e-05\n",
      "Epoch 2856, Loss: 0.0007337387396546546, Final Batch Loss: 2.787400080705993e-05\n",
      "Epoch 2857, Loss: 0.0026449945580679923, Final Batch Loss: 0.0003912282991223037\n",
      "Epoch 2858, Loss: 0.0009894138602248859, Final Batch Loss: 0.000636884942650795\n",
      "Epoch 2859, Loss: 0.00056387791846646, Final Batch Loss: 0.0001020326089928858\n",
      "Epoch 2860, Loss: 0.000816745166957844, Final Batch Loss: 0.00011763857764890417\n",
      "Epoch 2861, Loss: 0.0016187296132557094, Final Batch Loss: 5.7089782785624266e-05\n",
      "Epoch 2862, Loss: 0.00036669600376626477, Final Batch Loss: 0.00010984430991811678\n",
      "Epoch 2863, Loss: 0.0012829919287469238, Final Batch Loss: 0.00013319960271473974\n",
      "Epoch 2864, Loss: 0.0011454578798293369, Final Batch Loss: 4.776835339725949e-05\n",
      "Epoch 2865, Loss: 0.0015152367632254027, Final Batch Loss: 0.0010232110507786274\n",
      "Epoch 2866, Loss: 0.00029076448845444247, Final Batch Loss: 2.4587810912635177e-05\n",
      "Epoch 2867, Loss: 0.002982829522807151, Final Batch Loss: 8.285212243208662e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2868, Loss: 0.0008293827740999404, Final Batch Loss: 9.434046660317108e-05\n",
      "Epoch 2869, Loss: 0.0005640039362333482, Final Batch Loss: 4.904915840597823e-05\n",
      "Epoch 2870, Loss: 0.00554588169507042, Final Batch Loss: 2.4464810849167407e-05\n",
      "Epoch 2871, Loss: 0.00119621688281768, Final Batch Loss: 0.00017410219879820943\n",
      "Epoch 2872, Loss: 0.018322662072023377, Final Batch Loss: 0.00033998722210526466\n",
      "Epoch 2873, Loss: 0.047273603226130945, Final Batch Loss: 0.02394755557179451\n",
      "Epoch 2874, Loss: 0.0002971401954710018, Final Batch Loss: 4.4640932173933834e-05\n",
      "Epoch 2875, Loss: 0.0026992008915840415, Final Batch Loss: 0.0009047202183865011\n",
      "Epoch 2876, Loss: 0.002188446385844145, Final Batch Loss: 0.0004614700155798346\n",
      "Epoch 2877, Loss: 0.001464505105104763, Final Batch Loss: 0.0006341656553559005\n",
      "Epoch 2878, Loss: 0.024699576941202395, Final Batch Loss: 0.00023911985044833273\n",
      "Epoch 2879, Loss: 0.0008142116621456807, Final Batch Loss: 3.3405653084628284e-05\n",
      "Epoch 2880, Loss: 0.014635630881457473, Final Batch Loss: 0.009938322007656097\n",
      "Epoch 2881, Loss: 0.0022924648528714897, Final Batch Loss: 6.185765414556954e-06\n",
      "Epoch 2882, Loss: 0.00033331686609017197, Final Batch Loss: 7.700271089561284e-05\n",
      "Epoch 2883, Loss: 0.004439711372469901, Final Batch Loss: 0.000540950451977551\n",
      "Epoch 2884, Loss: 0.0008402953026234172, Final Batch Loss: 0.00021386946900747716\n",
      "Epoch 2885, Loss: 0.0005465976701088948, Final Batch Loss: 0.0002635295386426151\n",
      "Epoch 2886, Loss: 0.0008001859532669187, Final Batch Loss: 0.00019986707775387913\n",
      "Epoch 2887, Loss: 0.0003598717776185367, Final Batch Loss: 2.106811552948784e-05\n",
      "Epoch 2888, Loss: 0.0007595813549414743, Final Batch Loss: 1.0640716936904937e-05\n",
      "Epoch 2889, Loss: 0.000797979453636799, Final Batch Loss: 0.0002547660260461271\n",
      "Epoch 2890, Loss: 0.0011744916628231294, Final Batch Loss: 0.0001626041193958372\n",
      "Epoch 2891, Loss: 0.0004150165532337269, Final Batch Loss: 2.6623862140695564e-05\n",
      "Epoch 2892, Loss: 0.00029473667382262647, Final Batch Loss: 4.90116435685195e-05\n",
      "Epoch 2893, Loss: 0.0009033628848555963, Final Batch Loss: 3.845433457172476e-05\n",
      "Epoch 2894, Loss: 0.0008216753594751935, Final Batch Loss: 0.000447225000243634\n",
      "Epoch 2895, Loss: 0.0002595515707071172, Final Batch Loss: 2.729591869865544e-05\n",
      "Epoch 2896, Loss: 0.0007181072469393257, Final Batch Loss: 0.00036878499668091536\n",
      "Epoch 2897, Loss: 0.0006652832871623104, Final Batch Loss: 0.0004848423122894019\n",
      "Epoch 2898, Loss: 0.004253985031027696, Final Batch Loss: 0.004022130277007818\n",
      "Epoch 2899, Loss: 0.00028742793438141234, Final Batch Loss: 7.814651326043531e-05\n",
      "Epoch 2900, Loss: 0.0003541155128914397, Final Batch Loss: 6.704022962367162e-05\n",
      "Epoch 2901, Loss: 0.0008087888054433279, Final Batch Loss: 0.000363555591320619\n",
      "Epoch 2902, Loss: 0.0003990827790403273, Final Batch Loss: 9.707557910587639e-05\n",
      "Epoch 2903, Loss: 0.00018339492453378625, Final Batch Loss: 3.3433047065045685e-05\n",
      "Epoch 2904, Loss: 0.05527356630045688, Final Batch Loss: 0.00035622765426523983\n",
      "Epoch 2905, Loss: 0.001370053221762646, Final Batch Loss: 0.000873271026648581\n",
      "Epoch 2906, Loss: 0.0005202090324019082, Final Batch Loss: 3.5161065170541406e-05\n",
      "Epoch 2907, Loss: 0.0006613690129597671, Final Batch Loss: 0.00010024081711890176\n",
      "Epoch 2908, Loss: 0.0010995027942044544, Final Batch Loss: 0.0005384329706430435\n",
      "Epoch 2909, Loss: 0.0014531703432112408, Final Batch Loss: 4.037193775729975e-06\n",
      "Epoch 2910, Loss: 0.0011830845123768086, Final Batch Loss: 0.0009494933183304965\n",
      "Epoch 2911, Loss: 0.0006363209686242044, Final Batch Loss: 0.00027876824606209993\n",
      "Epoch 2912, Loss: 0.0014688296614622232, Final Batch Loss: 8.378701750189066e-05\n",
      "Epoch 2913, Loss: 0.0009150053356279386, Final Batch Loss: 1.9229997633374296e-05\n",
      "Epoch 2914, Loss: 0.00033506882027722895, Final Batch Loss: 8.237320435000584e-05\n",
      "Epoch 2915, Loss: 0.0008798309791018255, Final Batch Loss: 0.00038647864130325615\n",
      "Epoch 2916, Loss: 0.00039122497037169524, Final Batch Loss: 0.0002703626814763993\n",
      "Epoch 2917, Loss: 0.0007337665874729282, Final Batch Loss: 0.00022615089255850762\n",
      "Epoch 2918, Loss: 0.0038603582870564424, Final Batch Loss: 0.0022908702958375216\n",
      "Epoch 2919, Loss: 0.0011718677887984086, Final Batch Loss: 3.99695745727513e-05\n",
      "Epoch 2920, Loss: 0.00031910862344375346, Final Batch Loss: 5.378008063416928e-05\n",
      "Epoch 2921, Loss: 0.00059189705280005, Final Batch Loss: 3.5559129173634574e-05\n",
      "Epoch 2922, Loss: 0.0027209614681851235, Final Batch Loss: 1.440498908777954e-05\n",
      "Epoch 2923, Loss: 0.0003240591522626346, Final Batch Loss: 2.0938350644428283e-05\n",
      "Epoch 2924, Loss: 0.00018807091873895843, Final Batch Loss: 2.1361161998356692e-05\n",
      "Epoch 2925, Loss: 0.0007059956042212434, Final Batch Loss: 4.0375420212512836e-05\n",
      "Epoch 2926, Loss: 0.0009919509175233543, Final Batch Loss: 8.935981895774603e-05\n",
      "Epoch 2927, Loss: 0.00018934067702502944, Final Batch Loss: 3.554300565156154e-05\n",
      "Epoch 2928, Loss: 0.025546480614139, Final Batch Loss: 3.390437996131368e-05\n",
      "Epoch 2929, Loss: 0.0004678022141888505, Final Batch Loss: 0.00011354954040143639\n",
      "Epoch 2930, Loss: 0.0010616387298796326, Final Batch Loss: 6.371892231982201e-05\n",
      "Epoch 2931, Loss: 0.00043296031435602345, Final Batch Loss: 2.204784868808929e-05\n",
      "Epoch 2932, Loss: 0.0010167616492253728, Final Batch Loss: 0.00011650772648863494\n",
      "Epoch 2933, Loss: 0.00025362736687384313, Final Batch Loss: 4.756596536026336e-05\n",
      "Epoch 2934, Loss: 0.007500230402001762, Final Batch Loss: 3.938628651667386e-05\n",
      "Epoch 2935, Loss: 0.00033576747227925807, Final Batch Loss: 3.7278205127222463e-05\n",
      "Epoch 2936, Loss: 0.0005100268117530504, Final Batch Loss: 2.0210272850818e-05\n",
      "Epoch 2937, Loss: 0.004775096927915001, Final Batch Loss: 0.0045322878286242485\n",
      "Epoch 2938, Loss: 0.00011084673860750627, Final Batch Loss: 5.1647475629579276e-05\n",
      "Epoch 2939, Loss: 0.00031689650040789274, Final Batch Loss: 3.790103073697537e-05\n",
      "Epoch 2940, Loss: 0.0003495217188174138, Final Batch Loss: 1.98467678274028e-05\n",
      "Epoch 2941, Loss: 0.002101027188473381, Final Batch Loss: 0.00015937611169647425\n",
      "Epoch 2942, Loss: 0.0028720029549731407, Final Batch Loss: 0.002517406363040209\n",
      "Epoch 2943, Loss: 0.000923986381621944, Final Batch Loss: 4.044995421281783e-06\n",
      "Epoch 2944, Loss: 0.00023169983614934608, Final Batch Loss: 0.00010082082008011639\n",
      "Epoch 2945, Loss: 0.00022449913558375556, Final Batch Loss: 2.3689726731390692e-05\n",
      "Epoch 2946, Loss: 0.00024297185700561386, Final Batch Loss: 1.5687286577303894e-05\n",
      "Epoch 2947, Loss: 0.0005251471302472055, Final Batch Loss: 3.325538637000136e-05\n",
      "Epoch 2948, Loss: 0.0004980218509444967, Final Batch Loss: 2.9791925044264644e-05\n",
      "Epoch 2949, Loss: 0.0026962071569869295, Final Batch Loss: 0.0014400859363377094\n",
      "Epoch 2950, Loss: 0.0008438388031208888, Final Batch Loss: 0.00033019791590049863\n",
      "Epoch 2951, Loss: 0.0014025383134139702, Final Batch Loss: 3.4071505069732666e-05\n",
      "Epoch 2952, Loss: 0.0010222874243481783, Final Batch Loss: 7.93799918028526e-05\n",
      "Epoch 2953, Loss: 0.005996819159690858, Final Batch Loss: 3.573205685825087e-05\n",
      "Epoch 2954, Loss: 0.000277760140306782, Final Batch Loss: 1.1652311513898894e-05\n",
      "Epoch 2955, Loss: 0.021149768930627033, Final Batch Loss: 0.016558798030018806\n",
      "Epoch 2956, Loss: 0.001056513501680456, Final Batch Loss: 0.0001050280625349842\n",
      "Epoch 2957, Loss: 0.0016529554086446296, Final Batch Loss: 0.0014888820005580783\n",
      "Epoch 2958, Loss: 0.0026686671044444665, Final Batch Loss: 0.0023510653991252184\n",
      "Epoch 2959, Loss: 0.00727193288912531, Final Batch Loss: 0.006844107992947102\n",
      "Epoch 2960, Loss: 0.0005998089909553528, Final Batch Loss: 9.499864972895011e-05\n",
      "Epoch 2961, Loss: 0.0006658154361502966, Final Batch Loss: 2.3519989554188214e-05\n",
      "Epoch 2962, Loss: 0.002145760254279594, Final Batch Loss: 0.00025919050676748157\n",
      "Epoch 2963, Loss: 0.0013144911063136533, Final Batch Loss: 9.493758989265189e-05\n",
      "Epoch 2964, Loss: 0.0026653661334421486, Final Batch Loss: 0.0006017356063239276\n",
      "Epoch 2965, Loss: 0.030977289476140868, Final Batch Loss: 0.0005480097606778145\n",
      "Epoch 2966, Loss: 0.000302995067613665, Final Batch Loss: 8.425142004853114e-05\n",
      "Epoch 2967, Loss: 0.0011894841227331199, Final Batch Loss: 9.784269059309736e-05\n",
      "Epoch 2968, Loss: 0.0016833991576277185, Final Batch Loss: 5.3210500482236966e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2969, Loss: 0.04551916616037488, Final Batch Loss: 0.01888907700777054\n",
      "Epoch 2970, Loss: 0.0006806350211263634, Final Batch Loss: 0.00012079329462721944\n",
      "Epoch 2971, Loss: 0.011296886526736216, Final Batch Loss: 8.829209150462702e-07\n",
      "Epoch 2972, Loss: 0.018117267492925748, Final Batch Loss: 0.015778524801135063\n",
      "Epoch 2973, Loss: 0.016023629734263523, Final Batch Loss: 0.00016119101201184094\n",
      "Epoch 2974, Loss: 0.0007941774165374227, Final Batch Loss: 0.00030095918918959796\n",
      "Epoch 2975, Loss: 0.007265370702953078, Final Batch Loss: 0.00027985815540887415\n",
      "Epoch 2976, Loss: 0.06471436723950319, Final Batch Loss: 0.0004482459626160562\n",
      "Epoch 2977, Loss: 0.009015453470055945, Final Batch Loss: 5.478756793309003e-05\n",
      "Epoch 2978, Loss: 0.010648126153682824, Final Batch Loss: 0.0006868317141197622\n",
      "Epoch 2979, Loss: 0.007270432468430954, Final Batch Loss: 0.00018286379054188728\n",
      "Epoch 2980, Loss: 0.05601255386136472, Final Batch Loss: 0.005865578539669514\n",
      "Epoch 2981, Loss: 0.0014247824583435431, Final Batch Loss: 0.0005203275359235704\n",
      "Epoch 2982, Loss: 0.0007330529188038781, Final Batch Loss: 0.00016085366951301694\n",
      "Epoch 2983, Loss: 0.0022677667293464765, Final Batch Loss: 0.00017637075507082045\n",
      "Epoch 2984, Loss: 0.0015292772950488143, Final Batch Loss: 0.0004025027446914464\n",
      "Epoch 2985, Loss: 0.01789260005170945, Final Batch Loss: 0.0002189239748986438\n",
      "Epoch 2986, Loss: 0.0019925974775105715, Final Batch Loss: 6.477769056800753e-05\n",
      "Epoch 2987, Loss: 0.0008236894282163121, Final Batch Loss: 8.393816096941009e-05\n",
      "Epoch 2988, Loss: 0.002194137512560701, Final Batch Loss: 0.00022074684966355562\n",
      "Epoch 2989, Loss: 0.0016840406897244975, Final Batch Loss: 0.00045386762940324843\n",
      "Epoch 2990, Loss: 0.0010800246454891749, Final Batch Loss: 0.0001621962437639013\n",
      "Epoch 2991, Loss: 0.0008059184838202782, Final Batch Loss: 0.00020675372797995806\n",
      "Epoch 2992, Loss: 0.00882970581005793, Final Batch Loss: 0.00012527134094852954\n",
      "Epoch 2993, Loss: 0.04444403792876983, Final Batch Loss: 0.04410925507545471\n",
      "Epoch 2994, Loss: 0.0017521540430607274, Final Batch Loss: 0.0002828237193170935\n",
      "Epoch 2995, Loss: 0.0005880364478798583, Final Batch Loss: 0.00020382610091473907\n",
      "Epoch 2996, Loss: 0.0031333903316408396, Final Batch Loss: 0.0023641439620405436\n",
      "Epoch 2997, Loss: 0.0010773328831419349, Final Batch Loss: 0.00022671766055282205\n",
      "Epoch 2998, Loss: 0.0013276813915581442, Final Batch Loss: 3.836138785118237e-05\n",
      "Epoch 2999, Loss: 0.001944751915289089, Final Batch Loss: 0.0006075197015888989\n",
      "Epoch 3000, Loss: 0.0032410633721156046, Final Batch Loss: 0.0003854593960568309\n",
      "Epoch 3001, Loss: 0.0027987340872641653, Final Batch Loss: 0.0006755301728844643\n",
      "Epoch 3002, Loss: 0.0008114194424706511, Final Batch Loss: 6.20584687567316e-05\n",
      "Epoch 3003, Loss: 0.0008892520127119496, Final Batch Loss: 8.001750393304974e-05\n",
      "Epoch 3004, Loss: 0.0008240886527346447, Final Batch Loss: 0.00020819943165406585\n",
      "Epoch 3005, Loss: 0.0008127868350129575, Final Batch Loss: 0.00014131447824183851\n",
      "Epoch 3006, Loss: 0.0014058843371458352, Final Batch Loss: 0.00020405069517437369\n",
      "Epoch 3007, Loss: 0.0007998658620635979, Final Batch Loss: 4.624461871571839e-05\n",
      "Epoch 3008, Loss: 0.0005180232328712009, Final Batch Loss: 3.334834036650136e-05\n",
      "Epoch 3009, Loss: 0.0004811218532267958, Final Batch Loss: 5.0304246542509645e-05\n",
      "Epoch 3010, Loss: 0.0006726775027345866, Final Batch Loss: 8.500288095092401e-05\n",
      "Epoch 3011, Loss: 0.0011769099946832284, Final Batch Loss: 0.00021637536701746285\n",
      "Epoch 3012, Loss: 0.001376527281536255, Final Batch Loss: 0.00010947258124360815\n",
      "Epoch 3013, Loss: 0.0009414793530595489, Final Batch Loss: 4.393278868519701e-05\n",
      "Epoch 3014, Loss: 0.0005959500704193488, Final Batch Loss: 0.00020749752002302557\n",
      "Epoch 3015, Loss: 0.002866534166969359, Final Batch Loss: 0.00031236044014804065\n",
      "Epoch 3016, Loss: 0.0006134180639492115, Final Batch Loss: 0.00024119007866829634\n",
      "Epoch 3017, Loss: 0.0030518582789227366, Final Batch Loss: 8.20847344584763e-05\n",
      "Epoch 3018, Loss: 0.0011545881461643148, Final Batch Loss: 5.944179793004878e-05\n",
      "Epoch 3019, Loss: 0.041033790628716815, Final Batch Loss: 0.040240295231342316\n",
      "Epoch 3020, Loss: 0.0010380788280599518, Final Batch Loss: 0.0008939263061620295\n",
      "Epoch 3021, Loss: 0.00340221929945983, Final Batch Loss: 0.0025954742450267076\n",
      "Epoch 3022, Loss: 0.0003103463059233036, Final Batch Loss: 0.00012366671580821276\n",
      "Epoch 3023, Loss: 0.03638983167911647, Final Batch Loss: 0.035471562296152115\n",
      "Epoch 3024, Loss: 0.0010466370222275145, Final Batch Loss: 0.0005735729355365038\n",
      "Epoch 3025, Loss: 0.0007025907543720677, Final Batch Loss: 0.00020191949442960322\n",
      "Epoch 3026, Loss: 0.0024963824107544497, Final Batch Loss: 0.0008517090464010835\n",
      "Epoch 3027, Loss: 0.002589553812867962, Final Batch Loss: 0.0010675874073058367\n",
      "Epoch 3028, Loss: 0.0028962697979295626, Final Batch Loss: 0.0012442349689081311\n",
      "Epoch 3029, Loss: 0.0009284511543228291, Final Batch Loss: 6.151697743916884e-05\n",
      "Epoch 3030, Loss: 0.0004949899812345393, Final Batch Loss: 0.00012643840454984456\n",
      "Epoch 3031, Loss: 0.0011257932856096886, Final Batch Loss: 0.000571570242755115\n",
      "Epoch 3032, Loss: 0.0009202386281685904, Final Batch Loss: 0.00010733950330177322\n",
      "Epoch 3033, Loss: 0.0021997338881192263, Final Batch Loss: 0.0007029806729406118\n",
      "Epoch 3034, Loss: 0.001149551579146646, Final Batch Loss: 6.425070750992745e-05\n",
      "Epoch 3035, Loss: 0.0007940733266877942, Final Batch Loss: 0.0002256551815662533\n",
      "Epoch 3036, Loss: 0.010210839616775047, Final Batch Loss: 0.00012101597531000152\n",
      "Epoch 3037, Loss: 0.0015385829901788384, Final Batch Loss: 0.0008581391302868724\n",
      "Epoch 3038, Loss: 0.0012433828014764003, Final Batch Loss: 0.0006452191737480462\n",
      "Epoch 3039, Loss: 0.00027308503740641754, Final Batch Loss: 1.0768684660433792e-05\n",
      "Epoch 3040, Loss: 0.006323258428892586, Final Batch Loss: 0.0013891010312363505\n",
      "Epoch 3041, Loss: 0.0010879341498366557, Final Batch Loss: 7.911606371635571e-05\n",
      "Epoch 3042, Loss: 0.006578168198757339, Final Batch Loss: 1.3461984053719789e-05\n",
      "Epoch 3043, Loss: 0.0009981798648368567, Final Batch Loss: 0.0003063987533096224\n",
      "Epoch 3044, Loss: 0.0011114511053165188, Final Batch Loss: 8.810258805169724e-06\n",
      "Epoch 3045, Loss: 0.0005860186247446109, Final Batch Loss: 8.036682265810668e-05\n",
      "Epoch 3046, Loss: 0.000363036771886982, Final Batch Loss: 4.870725388173014e-05\n",
      "Epoch 3047, Loss: 0.00032867716799955815, Final Batch Loss: 6.402977305697277e-05\n",
      "Epoch 3048, Loss: 0.001007957736874232, Final Batch Loss: 0.0002846362185664475\n",
      "Epoch 3049, Loss: 0.0005774627861683257, Final Batch Loss: 5.3017312893643975e-05\n",
      "Epoch 3050, Loss: 0.0018964910486829467, Final Batch Loss: 3.1813979148864746e-05\n",
      "Epoch 3051, Loss: 0.0015997936116036726, Final Batch Loss: 0.00031306096934713423\n",
      "Epoch 3052, Loss: 0.0005494104552781209, Final Batch Loss: 5.2818220865447074e-05\n",
      "Epoch 3053, Loss: 0.0011821371299447492, Final Batch Loss: 0.00010814762208610773\n",
      "Epoch 3054, Loss: 0.0005090740487503354, Final Batch Loss: 0.00028470950201153755\n",
      "Epoch 3055, Loss: 0.00022405903655453585, Final Batch Loss: 7.875997835071757e-05\n",
      "Epoch 3056, Loss: 0.0007033881884126458, Final Batch Loss: 0.00011229258961975574\n",
      "Epoch 3057, Loss: 0.0007432871007040376, Final Batch Loss: 0.0004712806548923254\n",
      "Epoch 3058, Loss: 0.0003546913867467083, Final Batch Loss: 4.418705066200346e-05\n",
      "Epoch 3059, Loss: 0.003687782573251752, Final Batch Loss: 0.002981902100145817\n",
      "Epoch 3060, Loss: 0.00037543810685747303, Final Batch Loss: 9.244812099495903e-05\n",
      "Epoch 3061, Loss: 0.00038238877459662035, Final Batch Loss: 0.00020797463366761804\n",
      "Epoch 3062, Loss: 0.00045355779366218485, Final Batch Loss: 8.828515274217352e-05\n",
      "Epoch 3063, Loss: 0.000490755695864209, Final Batch Loss: 2.9089645977364853e-05\n",
      "Epoch 3064, Loss: 0.003340609120641602, Final Batch Loss: 2.2079997506807558e-05\n",
      "Epoch 3065, Loss: 0.0010979809439959354, Final Batch Loss: 0.0005777647020295262\n",
      "Epoch 3066, Loss: 0.028717786819470348, Final Batch Loss: 0.00020036922069266438\n",
      "Epoch 3067, Loss: 0.001161947540822439, Final Batch Loss: 6.331423355732113e-05\n",
      "Epoch 3068, Loss: 0.000699029770657944, Final Batch Loss: 1.2888079254480544e-05\n",
      "Epoch 3069, Loss: 0.0009775361379524838, Final Batch Loss: 2.9500099572032923e-06\n",
      "Epoch 3070, Loss: 0.0007596689792990219, Final Batch Loss: 3.4553839213913307e-05\n",
      "Epoch 3071, Loss: 0.0008363323941011913, Final Batch Loss: 4.847847594646737e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3072, Loss: 0.0008055580838117748, Final Batch Loss: 7.881147030275315e-05\n",
      "Epoch 3073, Loss: 0.00022004689526511356, Final Batch Loss: 2.3774910005158745e-05\n",
      "Epoch 3074, Loss: 0.0008524667282472365, Final Batch Loss: 0.0004492686130106449\n",
      "Epoch 3075, Loss: 0.00032941099925665185, Final Batch Loss: 0.00013959869102109224\n",
      "Epoch 3076, Loss: 0.0017976143426494673, Final Batch Loss: 0.0010247862664982677\n",
      "Epoch 3077, Loss: 0.010750378805823857, Final Batch Loss: 5.071710984339006e-05\n",
      "Epoch 3078, Loss: 0.0005219760878389934, Final Batch Loss: 4.5960507122799754e-05\n",
      "Epoch 3079, Loss: 0.00032380561333411606, Final Batch Loss: 1.2408397196850274e-05\n",
      "Epoch 3080, Loss: 0.00024093039428407792, Final Batch Loss: 9.979368769563735e-05\n",
      "Epoch 3081, Loss: 0.0005496336489159148, Final Batch Loss: 0.0002022463158937171\n",
      "Epoch 3082, Loss: 0.00046640501204819884, Final Batch Loss: 2.4237133402493782e-05\n",
      "Epoch 3083, Loss: 0.002206538283644477, Final Batch Loss: 0.00014240316522773355\n",
      "Epoch 3084, Loss: 0.0008451116555079352, Final Batch Loss: 4.164744677837007e-05\n",
      "Epoch 3085, Loss: 0.0004605283829732798, Final Batch Loss: 1.7070477042580023e-05\n",
      "Epoch 3086, Loss: 0.000352493480022531, Final Batch Loss: 1.166705806099344e-05\n",
      "Epoch 3087, Loss: 0.0010765434381028172, Final Batch Loss: 0.00044709545909427106\n",
      "Epoch 3088, Loss: 0.0009501271706540138, Final Batch Loss: 1.6797239368315786e-05\n",
      "Epoch 3089, Loss: 0.0005084016265755054, Final Batch Loss: 8.275716390926391e-05\n",
      "Epoch 3090, Loss: 0.0003697968786582351, Final Batch Loss: 0.00013737654080614448\n",
      "Epoch 3091, Loss: 0.0003749696734303143, Final Batch Loss: 8.47725459607318e-05\n",
      "Epoch 3092, Loss: 0.00039862044286564924, Final Batch Loss: 0.0002247724769404158\n",
      "Epoch 3093, Loss: 0.001353009807644412, Final Batch Loss: 0.00011864429689012468\n",
      "Epoch 3094, Loss: 0.0020436736158444546, Final Batch Loss: 4.432498826645315e-05\n",
      "Epoch 3095, Loss: 0.010862624418223277, Final Batch Loss: 0.0002992455556523055\n",
      "Epoch 3096, Loss: 0.001056515426171245, Final Batch Loss: 0.00013740913709625602\n",
      "Epoch 3097, Loss: 0.0017536165341880405, Final Batch Loss: 0.0015417258255183697\n",
      "Epoch 3098, Loss: 0.0005684625211870298, Final Batch Loss: 4.515839464147575e-05\n",
      "Epoch 3099, Loss: 0.001680321125604678, Final Batch Loss: 0.0012334040366113186\n",
      "Epoch 3100, Loss: 0.0030679998744744807, Final Batch Loss: 0.0005336734466254711\n",
      "Epoch 3101, Loss: 0.0009242604573955759, Final Batch Loss: 0.00023791439889464527\n",
      "Epoch 3102, Loss: 0.0005937420246482361, Final Batch Loss: 0.0003405335883144289\n",
      "Epoch 3103, Loss: 0.0040648770718689775, Final Batch Loss: 0.00373262632638216\n",
      "Epoch 3104, Loss: 0.00047982412979763467, Final Batch Loss: 2.0788962501683272e-05\n",
      "Epoch 3105, Loss: 0.0010991470408043824, Final Batch Loss: 0.0001589248131494969\n",
      "Epoch 3106, Loss: 0.0005113302086101612, Final Batch Loss: 1.0803376426338218e-05\n",
      "Epoch 3107, Loss: 0.0004575831444526557, Final Batch Loss: 0.0003137292806059122\n",
      "Epoch 3108, Loss: 0.0011884912128152791, Final Batch Loss: 3.1134539312915877e-05\n",
      "Epoch 3109, Loss: 0.0004363583357189782, Final Batch Loss: 4.0614817407913506e-05\n",
      "Epoch 3110, Loss: 0.0025397586105100345, Final Batch Loss: 1.5010724382591434e-05\n",
      "Epoch 3111, Loss: 0.0007578873191960156, Final Batch Loss: 0.0002075830998364836\n",
      "Epoch 3112, Loss: 0.0005048460880061612, Final Batch Loss: 1.991364115383476e-05\n",
      "Epoch 3113, Loss: 0.0003475300800346304, Final Batch Loss: 5.334587694960646e-05\n",
      "Epoch 3114, Loss: 0.0018038294947473332, Final Batch Loss: 0.00018918278510682285\n",
      "Epoch 3115, Loss: 0.0003694958668347681, Final Batch Loss: 0.0001610891049494967\n",
      "Epoch 3116, Loss: 0.0004807845089089824, Final Batch Loss: 0.0002029695751843974\n",
      "Epoch 3117, Loss: 0.0011048094966099598, Final Batch Loss: 9.567416418576613e-05\n",
      "Epoch 3118, Loss: 0.0004569697775878012, Final Batch Loss: 0.00011746439849957824\n",
      "Epoch 3119, Loss: 0.004118837493479077, Final Batch Loss: 8.440202691417653e-06\n",
      "Epoch 3120, Loss: 0.00047424119202332804, Final Batch Loss: 1.9124177924823016e-05\n",
      "Epoch 3121, Loss: 0.004171244831923104, Final Batch Loss: 6.215753091964871e-05\n",
      "Epoch 3122, Loss: 0.00041955547203542665, Final Batch Loss: 0.00029861179064027965\n",
      "Epoch 3123, Loss: 0.00039248754364962224, Final Batch Loss: 0.0003257709031458944\n",
      "Epoch 3124, Loss: 0.00046988078975118697, Final Batch Loss: 4.0192575397668406e-05\n",
      "Epoch 3125, Loss: 0.012690404932072852, Final Batch Loss: 0.0001456472818972543\n",
      "Epoch 3126, Loss: 0.0005430476248875493, Final Batch Loss: 4.9789938202593476e-05\n",
      "Epoch 3127, Loss: 0.0006614720041397959, Final Batch Loss: 0.00045533053344115615\n",
      "Epoch 3128, Loss: 0.0010817066649906337, Final Batch Loss: 0.0004988501314073801\n",
      "Epoch 3129, Loss: 0.0004400258567329729, Final Batch Loss: 4.89248959638644e-05\n",
      "Epoch 3130, Loss: 0.0016320860522682779, Final Batch Loss: 0.0009271009475924075\n",
      "Epoch 3131, Loss: 0.007669358802559145, Final Batch Loss: 0.0002575102262198925\n",
      "Epoch 3132, Loss: 0.01566589682988706, Final Batch Loss: 3.897398346452974e-05\n",
      "Epoch 3133, Loss: 0.006601205212064087, Final Batch Loss: 5.2504758059512824e-05\n",
      "Epoch 3134, Loss: 0.012324775307206437, Final Batch Loss: 0.00018861923308577389\n",
      "Epoch 3135, Loss: 0.02959563320291636, Final Batch Loss: 2.8862308681709692e-05\n",
      "Epoch 3136, Loss: 0.0003365236952959094, Final Batch Loss: 0.00011794297461165115\n",
      "Epoch 3137, Loss: 0.0023006392002571374, Final Batch Loss: 0.00021179615578148514\n",
      "Epoch 3138, Loss: 0.0022181013191584498, Final Batch Loss: 0.0006681566592305899\n",
      "Epoch 3139, Loss: 0.003000584474648349, Final Batch Loss: 7.835266296751797e-05\n",
      "Epoch 3140, Loss: 0.0028315632953308523, Final Batch Loss: 0.00016633450286462903\n",
      "Epoch 3141, Loss: 0.0009445815071558172, Final Batch Loss: 7.050874501146609e-06\n",
      "Epoch 3142, Loss: 0.0022106099131633528, Final Batch Loss: 0.0003534352290444076\n",
      "Epoch 3143, Loss: 0.017334390548057854, Final Batch Loss: 0.002064422471448779\n",
      "Epoch 3144, Loss: 0.00037020151557953795, Final Batch Loss: 1.412861001881538e-05\n",
      "Epoch 3145, Loss: 0.0029522975055442657, Final Batch Loss: 2.8745955205522478e-05\n",
      "Epoch 3146, Loss: 0.0007880954090069281, Final Batch Loss: 0.000518420129083097\n",
      "Epoch 3147, Loss: 0.0011832213058369234, Final Batch Loss: 9.30684691411443e-05\n",
      "Epoch 3148, Loss: 0.006261510872718645, Final Batch Loss: 0.0005594068788923323\n",
      "Epoch 3149, Loss: 0.08218913979362696, Final Batch Loss: 8.416623313678429e-05\n",
      "Epoch 3150, Loss: 0.00045166794370743446, Final Batch Loss: 9.11264942260459e-05\n",
      "Epoch 3151, Loss: 0.0007345829708356177, Final Batch Loss: 8.963456639321521e-05\n",
      "Epoch 3152, Loss: 0.0001520322646229033, Final Batch Loss: 2.446290409352514e-06\n",
      "Epoch 3153, Loss: 0.0007333016274060355, Final Batch Loss: 2.2318114133668132e-05\n",
      "Epoch 3154, Loss: 0.01851678145612823, Final Batch Loss: 0.016713041812181473\n",
      "Epoch 3155, Loss: 0.0030872357147018192, Final Batch Loss: 0.00017053348710760474\n",
      "Epoch 3156, Loss: 0.0009784957564988872, Final Batch Loss: 2.1682428268832155e-05\n",
      "Epoch 3157, Loss: 0.0009294664450862911, Final Batch Loss: 1.639794572838582e-05\n",
      "Epoch 3158, Loss: 0.0008594550818088464, Final Batch Loss: 6.863488670205697e-05\n",
      "Epoch 3159, Loss: 0.0007550094214821002, Final Batch Loss: 1.9480319679132663e-05\n",
      "Epoch 3160, Loss: 0.0006030074546288233, Final Batch Loss: 2.010437674471177e-05\n",
      "Epoch 3161, Loss: 0.0005541226819332223, Final Batch Loss: 3.831598587566987e-05\n",
      "Epoch 3162, Loss: 0.0038358147139661014, Final Batch Loss: 0.0014024086995050311\n",
      "Epoch 3163, Loss: 0.0023977573146112263, Final Batch Loss: 0.001132320030592382\n",
      "Epoch 3164, Loss: 0.047938136936863884, Final Batch Loss: 0.0010570785962045193\n",
      "Epoch 3165, Loss: 0.0015174881464190548, Final Batch Loss: 2.0613506421796046e-05\n",
      "Epoch 3166, Loss: 0.00012259762479516212, Final Batch Loss: 6.586188828805462e-05\n",
      "Epoch 3167, Loss: 0.0007210643348116719, Final Batch Loss: 7.541737431893125e-05\n",
      "Epoch 3168, Loss: 0.0002975089446408674, Final Batch Loss: 3.435659527895041e-05\n",
      "Epoch 3169, Loss: 0.001309848587425222, Final Batch Loss: 7.07168192093377e-06\n",
      "Epoch 3170, Loss: 0.0015319363583330414, Final Batch Loss: 0.0011525149457156658\n",
      "Epoch 3171, Loss: 0.00274643674492836, Final Batch Loss: 0.0018264546524733305\n",
      "Epoch 3172, Loss: 0.0013475132946041413, Final Batch Loss: 0.0003101942711509764\n",
      "Epoch 3173, Loss: 0.001929036550791352, Final Batch Loss: 1.6724216038710438e-05\n",
      "Epoch 3174, Loss: 0.0011717000520548027, Final Batch Loss: 0.0009640952339395881\n",
      "Epoch 3175, Loss: 0.0005287658350425772, Final Batch Loss: 0.00027373587363399565\n",
      "Epoch 3176, Loss: 0.000167354880431958, Final Batch Loss: 9.87139264907455e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3177, Loss: 0.0008510930638294667, Final Batch Loss: 9.489319199929014e-05\n",
      "Epoch 3178, Loss: 0.004483800672460347, Final Batch Loss: 0.003992737270891666\n",
      "Epoch 3179, Loss: 0.0008407543646171689, Final Batch Loss: 6.055654012016021e-05\n",
      "Epoch 3180, Loss: 0.0014239278425520752, Final Batch Loss: 2.0900279196212068e-05\n",
      "Epoch 3181, Loss: 0.0037764735097880475, Final Batch Loss: 0.0012397293467074633\n",
      "Epoch 3182, Loss: 0.00066295641954639, Final Batch Loss: 0.00011883756815223023\n",
      "Epoch 3183, Loss: 0.00019609352693805704, Final Batch Loss: 8.530168088327628e-06\n",
      "Epoch 3184, Loss: 0.0003854141687043011, Final Batch Loss: 0.00012415215314831585\n",
      "Epoch 3185, Loss: 0.0007607306179124862, Final Batch Loss: 0.00017579349514562637\n",
      "Epoch 3186, Loss: 0.0004071536468472914, Final Batch Loss: 6.411614594981074e-05\n",
      "Epoch 3187, Loss: 0.00041425434301345376, Final Batch Loss: 1.2818282812077086e-05\n",
      "Epoch 3188, Loss: 0.0007734206592431292, Final Batch Loss: 7.890510460129008e-05\n",
      "Epoch 3189, Loss: 0.0008432775639448664, Final Batch Loss: 0.0001044356104102917\n",
      "Epoch 3190, Loss: 0.0002016638682107441, Final Batch Loss: 2.063588544842787e-05\n",
      "Epoch 3191, Loss: 0.002019012803430087, Final Batch Loss: 2.349168607906904e-05\n",
      "Epoch 3192, Loss: 0.0005246251366770593, Final Batch Loss: 0.00010840196773642674\n",
      "Epoch 3193, Loss: 0.00016087177482404513, Final Batch Loss: 1.0019858564191964e-05\n",
      "Epoch 3194, Loss: 0.001292075543460669, Final Batch Loss: 2.3742031771689653e-05\n",
      "Epoch 3195, Loss: 0.0008345389396708924, Final Batch Loss: 5.487005182658322e-05\n",
      "Epoch 3196, Loss: 0.0008462570585834328, Final Batch Loss: 5.251047696219757e-06\n",
      "Epoch 3197, Loss: 0.000583034557166684, Final Batch Loss: 1.0395199751656037e-05\n",
      "Epoch 3198, Loss: 0.0019228622259106487, Final Batch Loss: 0.0004609856114257127\n",
      "Epoch 3199, Loss: 0.0006159264503367012, Final Batch Loss: 3.00677875202382e-05\n",
      "Epoch 3200, Loss: 0.0009094957258639624, Final Batch Loss: 0.00010266150638926774\n",
      "Epoch 3201, Loss: 0.0008330705750267953, Final Batch Loss: 0.00025752378860488534\n",
      "Epoch 3202, Loss: 0.0013240866755950265, Final Batch Loss: 0.0005035251379013062\n",
      "Epoch 3203, Loss: 0.004865019978751661, Final Batch Loss: 0.004752206150442362\n",
      "Epoch 3204, Loss: 0.0005449638738355134, Final Batch Loss: 0.0004509130958467722\n",
      "Epoch 3205, Loss: 0.00022544260536960792, Final Batch Loss: 3.685499177663587e-05\n",
      "Epoch 3206, Loss: 0.0015657549515708524, Final Batch Loss: 0.0001012805660138838\n",
      "Epoch 3207, Loss: 0.0006822986370025319, Final Batch Loss: 8.648833500046749e-06\n",
      "Epoch 3208, Loss: 0.011287993113910488, Final Batch Loss: 0.011074742302298546\n",
      "Epoch 3209, Loss: 0.01193798652843725, Final Batch Loss: 1.0774377187772188e-05\n",
      "Epoch 3210, Loss: 0.0013158639540051809, Final Batch Loss: 0.0012137979501858354\n",
      "Epoch 3211, Loss: 0.011920170818484621, Final Batch Loss: 0.00022072797582950443\n",
      "Epoch 3212, Loss: 0.005211842679273104, Final Batch Loss: 0.0015806573210284114\n",
      "Epoch 3213, Loss: 0.00036217828892404214, Final Batch Loss: 2.461172334733419e-05\n",
      "Epoch 3214, Loss: 0.0004971883972757496, Final Batch Loss: 0.0002362435479881242\n",
      "Epoch 3215, Loss: 0.00629803873016499, Final Batch Loss: 0.0042399875819683075\n",
      "Epoch 3216, Loss: 0.04725421668990748, Final Batch Loss: 0.0001224828010890633\n",
      "Epoch 3217, Loss: 0.0011690996470861137, Final Batch Loss: 0.0008561396389268339\n",
      "Epoch 3218, Loss: 0.0014996603240433615, Final Batch Loss: 3.290331733296625e-05\n",
      "Epoch 3219, Loss: 0.0022166709786688443, Final Batch Loss: 0.000380839774152264\n",
      "Epoch 3220, Loss: 0.0006953054416953819, Final Batch Loss: 0.000125843973364681\n",
      "Epoch 3221, Loss: 0.0004955955046170857, Final Batch Loss: 0.0001530487061245367\n",
      "Epoch 3222, Loss: 0.00024054917230387218, Final Batch Loss: 1.9487973986542784e-05\n",
      "Epoch 3223, Loss: 0.0029213852394605055, Final Batch Loss: 0.0022371960803866386\n",
      "Epoch 3224, Loss: 0.00022099921625340357, Final Batch Loss: 5.4505122534465045e-05\n",
      "Epoch 3225, Loss: 0.0009095577152038459, Final Batch Loss: 0.0005326893297024071\n",
      "Epoch 3226, Loss: 0.001225416206580121, Final Batch Loss: 0.0007348606595769525\n",
      "Epoch 3227, Loss: 0.00035452898737275973, Final Batch Loss: 8.167723717633635e-05\n",
      "Epoch 3228, Loss: 0.0018274875092174625, Final Batch Loss: 0.00015725228877272457\n",
      "Epoch 3229, Loss: 0.001213894418469863, Final Batch Loss: 0.000696590868756175\n",
      "Epoch 3230, Loss: 0.0007094574343682325, Final Batch Loss: 0.00025766497128643095\n",
      "Epoch 3231, Loss: 0.000666885945975082, Final Batch Loss: 3.785064836847596e-05\n",
      "Epoch 3232, Loss: 0.0006757411756552756, Final Batch Loss: 0.00010165551793761551\n",
      "Epoch 3233, Loss: 0.0005251382731330523, Final Batch Loss: 2.8145350370323285e-05\n",
      "Epoch 3234, Loss: 0.001363417157335789, Final Batch Loss: 6.215364555828273e-05\n",
      "Epoch 3235, Loss: 0.0014520152544719167, Final Batch Loss: 7.673164509469643e-05\n",
      "Epoch 3236, Loss: 0.0005765349178545875, Final Batch Loss: 0.00012539162707980722\n",
      "Epoch 3237, Loss: 0.0005963834446447436, Final Batch Loss: 0.00041241166763938963\n",
      "Epoch 3238, Loss: 0.0005431968093034811, Final Batch Loss: 7.0076399424579e-05\n",
      "Epoch 3239, Loss: 0.0010953675373457372, Final Batch Loss: 0.00047264984459616244\n",
      "Epoch 3240, Loss: 0.015479853231227025, Final Batch Loss: 9.70105393207632e-05\n",
      "Epoch 3241, Loss: 0.0005771856140199816, Final Batch Loss: 3.142508285236545e-05\n",
      "Epoch 3242, Loss: 0.0028202679895912297, Final Batch Loss: 0.00034251451143063605\n",
      "Epoch 3243, Loss: 0.0010240584524581209, Final Batch Loss: 0.00026113714557141066\n",
      "Epoch 3244, Loss: 0.0006822174436820205, Final Batch Loss: 1.8644597730599344e-05\n",
      "Epoch 3245, Loss: 0.00029394172997854184, Final Batch Loss: 1.3982402379042469e-05\n",
      "Epoch 3246, Loss: 0.002088876972266007, Final Batch Loss: 0.0013414897257462144\n",
      "Epoch 3247, Loss: 0.0013678473624167964, Final Batch Loss: 0.00015634777082595974\n",
      "Epoch 3248, Loss: 0.007514979624829721, Final Batch Loss: 7.195700163720176e-05\n",
      "Epoch 3249, Loss: 0.001820519766624784, Final Batch Loss: 4.3710035242838785e-05\n",
      "Epoch 3250, Loss: 0.000719847550499253, Final Batch Loss: 0.0002108593180309981\n",
      "Epoch 3251, Loss: 0.040065014403808163, Final Batch Loss: 0.0006920141750015318\n",
      "Epoch 3252, Loss: 0.0007642543205292895, Final Batch Loss: 0.00037618252099491656\n",
      "Epoch 3253, Loss: 0.002092342114337953, Final Batch Loss: 6.379112164722756e-05\n",
      "Epoch 3254, Loss: 0.000423021410824731, Final Batch Loss: 0.00016122427769005299\n",
      "Epoch 3255, Loss: 0.005048341874498874, Final Batch Loss: 3.551140980562195e-05\n",
      "Epoch 3256, Loss: 0.00810457752959337, Final Batch Loss: 0.00027927805786021054\n",
      "Epoch 3257, Loss: 0.013592454568424728, Final Batch Loss: 0.00012119647726649418\n",
      "Epoch 3258, Loss: 0.00024215118355641607, Final Batch Loss: 7.749604992568493e-05\n",
      "Epoch 3259, Loss: 0.003004618396062142, Final Batch Loss: 7.506925157940714e-06\n",
      "Epoch 3260, Loss: 0.0002354267198825255, Final Batch Loss: 7.196135265985504e-05\n",
      "Epoch 3261, Loss: 0.003920226951777295, Final Batch Loss: 7.57708494347753e-06\n",
      "Epoch 3262, Loss: 0.0002936831697297748, Final Batch Loss: 0.00016119789506774396\n",
      "Epoch 3263, Loss: 0.0007229941456898814, Final Batch Loss: 0.00012768291344400495\n",
      "Epoch 3264, Loss: 0.002502061359336949, Final Batch Loss: 1.5921030353638344e-05\n",
      "Epoch 3265, Loss: 0.001985418923140969, Final Batch Loss: 0.00034315872471779585\n",
      "Epoch 3266, Loss: 0.0018506270007492276, Final Batch Loss: 4.697966141975485e-05\n",
      "Epoch 3267, Loss: 0.0005314149384503253, Final Batch Loss: 8.373532182304189e-06\n",
      "Epoch 3268, Loss: 0.0005184852052479982, Final Batch Loss: 0.0001425511291017756\n",
      "Epoch 3269, Loss: 0.0010956845108012203, Final Batch Loss: 4.9550853873370215e-05\n",
      "Epoch 3270, Loss: 0.0013339588113012724, Final Batch Loss: 0.00022968125995248556\n",
      "Epoch 3271, Loss: 0.0004689492197940126, Final Batch Loss: 6.794486398575827e-05\n",
      "Epoch 3272, Loss: 0.00017508426026324742, Final Batch Loss: 5.1254730351502076e-05\n",
      "Epoch 3273, Loss: 0.0006993349852564279, Final Batch Loss: 2.957647666335106e-05\n",
      "Epoch 3274, Loss: 0.002161955737392418, Final Batch Loss: 0.0010137526551261544\n",
      "Epoch 3275, Loss: 0.000468644936063356, Final Batch Loss: 9.348323510494083e-05\n",
      "Epoch 3276, Loss: 0.00364038195766625, Final Batch Loss: 5.763597073382698e-06\n",
      "Epoch 3277, Loss: 0.016405716807639692, Final Batch Loss: 1.390202214679448e-05\n",
      "Epoch 3278, Loss: 0.0009408854130015243, Final Batch Loss: 4.2582887544995174e-05\n",
      "Epoch 3279, Loss: 0.002421751640213188, Final Batch Loss: 0.00027987349312752485\n",
      "Epoch 3280, Loss: 0.0007186935581557918, Final Batch Loss: 0.0005371421575546265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3281, Loss: 0.00022860553144710138, Final Batch Loss: 4.496272958931513e-05\n",
      "Epoch 3282, Loss: 0.0010101842726726318, Final Batch Loss: 0.00010152244794880971\n",
      "Epoch 3283, Loss: 0.001735173770612164, Final Batch Loss: 3.319927054690197e-05\n",
      "Epoch 3284, Loss: 0.001652977764933894, Final Batch Loss: 6.360564293572679e-05\n",
      "Epoch 3285, Loss: 0.0008953524156822823, Final Batch Loss: 1.90075152204372e-05\n",
      "Epoch 3286, Loss: 0.0008083110988081899, Final Batch Loss: 0.0004374533018562943\n",
      "Epoch 3287, Loss: 0.004682743265220779, Final Batch Loss: 0.00035860849311575294\n",
      "Epoch 3288, Loss: 0.0008336611645063385, Final Batch Loss: 0.000406152568757534\n",
      "Epoch 3289, Loss: 0.00230662258763914, Final Batch Loss: 0.0019687230233103037\n",
      "Epoch 3290, Loss: 0.0005290122062433511, Final Batch Loss: 0.0001119464504881762\n",
      "Epoch 3291, Loss: 0.00018936682454295806, Final Batch Loss: 5.283473728923127e-05\n",
      "Epoch 3292, Loss: 0.0005319978527040803, Final Batch Loss: 1.1349043234076817e-05\n",
      "Epoch 3293, Loss: 0.0002235579222542583, Final Batch Loss: 9.905693332257215e-06\n",
      "Epoch 3294, Loss: 0.0006462100664066384, Final Batch Loss: 2.253095772175584e-05\n",
      "Epoch 3295, Loss: 0.0005960980543022742, Final Batch Loss: 0.00015793593775015324\n",
      "Epoch 3296, Loss: 0.0004729506399598904, Final Batch Loss: 0.00022498381440527737\n",
      "Epoch 3297, Loss: 0.0007702310867898632, Final Batch Loss: 5.7214849221054465e-05\n",
      "Epoch 3298, Loss: 0.00021442282559291925, Final Batch Loss: 0.0001158558443421498\n",
      "Epoch 3299, Loss: 0.003469874527581851, Final Batch Loss: 0.0026918319053947926\n",
      "Epoch 3300, Loss: 0.0003154457835989888, Final Batch Loss: 5.8196128520648926e-05\n",
      "Epoch 3301, Loss: 0.0016725385758036282, Final Batch Loss: 9.682085510576144e-05\n",
      "Epoch 3302, Loss: 0.0008972083960543387, Final Batch Loss: 0.00010335872502764687\n",
      "Epoch 3303, Loss: 0.0004893705481663346, Final Batch Loss: 0.00012394551595207304\n",
      "Epoch 3304, Loss: 0.000609304534009425, Final Batch Loss: 6.695227784803137e-05\n",
      "Epoch 3305, Loss: 0.0012769464829034405, Final Batch Loss: 2.5753661248018034e-05\n",
      "Epoch 3306, Loss: 0.0003824428058578633, Final Batch Loss: 4.8218833399005234e-05\n",
      "Epoch 3307, Loss: 0.001347469678876223, Final Batch Loss: 0.0006949473172426224\n",
      "Epoch 3308, Loss: 0.0008573796585551463, Final Batch Loss: 0.0005111707141622901\n",
      "Epoch 3309, Loss: 0.0016906276159716072, Final Batch Loss: 1.1792626537499018e-05\n",
      "Epoch 3310, Loss: 0.0005517828540178016, Final Batch Loss: 0.00019788736244663596\n",
      "Epoch 3311, Loss: 0.000516293406690238, Final Batch Loss: 0.00035943672992289066\n",
      "Epoch 3312, Loss: 0.003978854549131938, Final Batch Loss: 0.001531918183900416\n",
      "Epoch 3313, Loss: 0.0007603365702379961, Final Batch Loss: 0.0003973374841734767\n",
      "Epoch 3314, Loss: 0.0031965093221515417, Final Batch Loss: 0.00010879989713430405\n",
      "Epoch 3315, Loss: 0.00019493995387165342, Final Batch Loss: 7.2493712650612e-05\n",
      "Epoch 3316, Loss: 0.0001678734606684884, Final Batch Loss: 5.0850339903263375e-05\n",
      "Epoch 3317, Loss: 0.0004274943312339019, Final Batch Loss: 0.0002068790781777352\n",
      "Epoch 3318, Loss: 0.0010983113479596796, Final Batch Loss: 2.493171086825896e-05\n",
      "Epoch 3319, Loss: 0.0007243517688948486, Final Batch Loss: 0.0006390116759575903\n",
      "Epoch 3320, Loss: 0.0012054055005137343, Final Batch Loss: 3.467077112873085e-05\n",
      "Epoch 3321, Loss: 0.0005644061347993556, Final Batch Loss: 0.0001190546463476494\n",
      "Epoch 3322, Loss: 0.0006250269925658358, Final Batch Loss: 0.00013540126383304596\n",
      "Epoch 3323, Loss: 0.0002444008023303468, Final Batch Loss: 6.30291979177855e-05\n",
      "Epoch 3324, Loss: 0.001387161499224021, Final Batch Loss: 7.4696963565656915e-06\n",
      "Epoch 3325, Loss: 0.0003598670518840663, Final Batch Loss: 3.294984344393015e-05\n",
      "Epoch 3326, Loss: 0.0004948966779920738, Final Batch Loss: 2.0942341507179663e-05\n",
      "Epoch 3327, Loss: 0.00020888752214887063, Final Batch Loss: 7.60169814384426e-06\n",
      "Epoch 3328, Loss: 0.0004053798347740667, Final Batch Loss: 4.4565800635609776e-05\n",
      "Epoch 3329, Loss: 0.00021956658702038112, Final Batch Loss: 9.249598224414513e-05\n",
      "Epoch 3330, Loss: 0.0012188388136564754, Final Batch Loss: 3.923381518688984e-05\n",
      "Epoch 3331, Loss: 0.00016964438600552967, Final Batch Loss: 0.00010455098527017981\n",
      "Epoch 3332, Loss: 0.0006217743575689383, Final Batch Loss: 8.365820394828916e-05\n",
      "Epoch 3333, Loss: 0.00011629175787675194, Final Batch Loss: 3.3775468182284385e-05\n",
      "Epoch 3334, Loss: 0.04333026755375613, Final Batch Loss: 0.042379871010780334\n",
      "Epoch 3335, Loss: 0.001435663642041618, Final Batch Loss: 5.19844725204166e-05\n",
      "Epoch 3336, Loss: 0.0007237257777887862, Final Batch Loss: 5.481180778588168e-05\n",
      "Epoch 3337, Loss: 0.000755831047626998, Final Batch Loss: 4.193095719529083e-06\n",
      "Epoch 3338, Loss: 0.001729818857711507, Final Batch Loss: 2.665480860741809e-05\n",
      "Epoch 3339, Loss: 0.00010305293153578532, Final Batch Loss: 4.5879583922214806e-05\n",
      "Epoch 3340, Loss: 0.0005415914174591308, Final Batch Loss: 6.116628355812281e-05\n",
      "Epoch 3341, Loss: 0.0012075102349626832, Final Batch Loss: 0.0002872021577786654\n",
      "Epoch 3342, Loss: 0.008451649680864648, Final Batch Loss: 0.0007264144369401038\n",
      "Epoch 3343, Loss: 0.0015250286323862383, Final Batch Loss: 0.0007114428444765508\n",
      "Epoch 3344, Loss: 0.0008382361438634689, Final Batch Loss: 0.0006682463572360575\n",
      "Epoch 3345, Loss: 0.0010325267794542015, Final Batch Loss: 0.00011181624722667038\n",
      "Epoch 3346, Loss: 0.0006997684877205756, Final Batch Loss: 1.2007706573058385e-05\n",
      "Epoch 3347, Loss: 0.0001615544979358674, Final Batch Loss: 6.138720345916227e-05\n",
      "Epoch 3348, Loss: 0.00019164494369761087, Final Batch Loss: 0.00015107094077393413\n",
      "Epoch 3349, Loss: 0.0005026270882808603, Final Batch Loss: 0.00016110907017719\n",
      "Epoch 3350, Loss: 9.79777028078388e-05, Final Batch Loss: 6.838547506049508e-06\n",
      "Epoch 3351, Loss: 0.0046592245998908766, Final Batch Loss: 2.716420749493409e-05\n",
      "Epoch 3352, Loss: 0.001716842845780775, Final Batch Loss: 6.163264333736151e-05\n",
      "Epoch 3353, Loss: 0.0016267733881250024, Final Batch Loss: 8.460247045150027e-06\n",
      "Epoch 3354, Loss: 0.00021481740077433642, Final Batch Loss: 9.39407545956783e-05\n",
      "Epoch 3355, Loss: 0.00023108606364985462, Final Batch Loss: 7.799670856911689e-05\n",
      "Epoch 3356, Loss: 0.000525065604961128, Final Batch Loss: 6.514706910820678e-05\n",
      "Epoch 3357, Loss: 0.0005390600472310325, Final Batch Loss: 1.583050652698148e-05\n",
      "Epoch 3358, Loss: 0.0002290982174599776, Final Batch Loss: 9.603926446288824e-05\n",
      "Epoch 3359, Loss: 0.005417905565991532, Final Batch Loss: 0.005304222460836172\n",
      "Epoch 3360, Loss: 0.0011157671933688107, Final Batch Loss: 5.915892870689277e-06\n",
      "Epoch 3361, Loss: 5.63824818300418e-05, Final Batch Loss: 8.606369874541997e-07\n",
      "Epoch 3362, Loss: 0.00019799700362455042, Final Batch Loss: 7.869405817473307e-05\n",
      "Epoch 3363, Loss: 0.00024842401762725785, Final Batch Loss: 0.00010819116869242862\n",
      "Epoch 3364, Loss: 0.00010524189258376282, Final Batch Loss: 1.600797077117022e-05\n",
      "Epoch 3365, Loss: 0.00554047292780524, Final Batch Loss: 1.8658844055607915e-05\n",
      "Epoch 3366, Loss: 0.0001951608355739154, Final Batch Loss: 5.321352546161506e-06\n",
      "Epoch 3367, Loss: 0.0007806558087395388, Final Batch Loss: 0.00046378414845094085\n",
      "Epoch 3368, Loss: 0.0030614280108238745, Final Batch Loss: 0.0006018824060447514\n",
      "Epoch 3369, Loss: 0.015390444589229446, Final Batch Loss: 0.015046127140522003\n",
      "Epoch 3370, Loss: 0.0008343743575096596, Final Batch Loss: 0.00018867503968067467\n",
      "Epoch 3371, Loss: 0.011027797079805168, Final Batch Loss: 0.00011178886779816821\n",
      "Epoch 3372, Loss: 0.0008547781326342374, Final Batch Loss: 6.370276241796091e-05\n",
      "Epoch 3373, Loss: 0.03258135112628224, Final Batch Loss: 3.4164837416028604e-05\n",
      "Epoch 3374, Loss: 0.000245171520873555, Final Batch Loss: 1.6237585441558622e-05\n",
      "Epoch 3375, Loss: 0.0008504114593961276, Final Batch Loss: 0.0005751168937422335\n",
      "Epoch 3376, Loss: 0.0004194555731373839, Final Batch Loss: 0.0003019398427568376\n",
      "Epoch 3377, Loss: 0.040546709544287296, Final Batch Loss: 0.0003765290603041649\n",
      "Epoch 3378, Loss: 0.0004145226448599715, Final Batch Loss: 0.0001650555495871231\n",
      "Epoch 3379, Loss: 0.0024476651087752543, Final Batch Loss: 1.0288531484548002e-05\n",
      "Epoch 3380, Loss: 0.0016071132631623186, Final Batch Loss: 0.00012250615691300482\n",
      "Epoch 3381, Loss: 0.005127316628204426, Final Batch Loss: 0.0002806041156873107\n",
      "Epoch 3382, Loss: 0.040802696930768434, Final Batch Loss: 6.730690802214667e-05\n",
      "Epoch 3383, Loss: 0.0028201493405504152, Final Batch Loss: 0.0013762314338237047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3384, Loss: 0.02136308773424389, Final Batch Loss: 0.00023024134861771017\n",
      "Epoch 3385, Loss: 0.0007854802934161853, Final Batch Loss: 0.00013969794963486493\n",
      "Epoch 3386, Loss: 0.018922059563919902, Final Batch Loss: 0.017856670543551445\n",
      "Epoch 3387, Loss: 0.0009025226027006283, Final Batch Loss: 0.0001773245312506333\n",
      "Epoch 3388, Loss: 0.0010716655724536395, Final Batch Loss: 2.8291038688621484e-05\n",
      "Epoch 3389, Loss: 0.012518809329776559, Final Batch Loss: 0.011973750777542591\n",
      "Epoch 3390, Loss: 0.0007532409799750894, Final Batch Loss: 0.00023420633806381375\n",
      "Epoch 3391, Loss: 0.038530555670149624, Final Batch Loss: 0.03164674714207649\n",
      "Epoch 3392, Loss: 0.004331280593760312, Final Batch Loss: 0.0003616943722590804\n",
      "Epoch 3393, Loss: 0.0018260821016156115, Final Batch Loss: 8.396066550631076e-05\n",
      "Epoch 3394, Loss: 0.004138130250794347, Final Batch Loss: 0.00010478588956175372\n",
      "Epoch 3395, Loss: 0.0043863662431249395, Final Batch Loss: 0.0007153389160521328\n",
      "Epoch 3396, Loss: 0.02101712154399138, Final Batch Loss: 0.003095852443948388\n",
      "Epoch 3397, Loss: 0.012076897080987692, Final Batch Loss: 9.174508159048855e-05\n",
      "Epoch 3398, Loss: 0.0036523067392408848, Final Batch Loss: 0.00297799170948565\n",
      "Epoch 3399, Loss: 0.0009264920217901818, Final Batch Loss: 1.431659529771423e-05\n",
      "Epoch 3400, Loss: 0.008400043414440006, Final Batch Loss: 0.0002540192217566073\n",
      "Epoch 3401, Loss: 0.004298120009480044, Final Batch Loss: 0.0003881485899910331\n",
      "Epoch 3402, Loss: 0.0015814927610335872, Final Batch Loss: 0.0005530270282179117\n",
      "Epoch 3403, Loss: 0.0029174477294873213, Final Batch Loss: 1.547489046060946e-05\n",
      "Epoch 3404, Loss: 0.005520056762179593, Final Batch Loss: 0.005113378167152405\n",
      "Epoch 3405, Loss: 0.008207111408410128, Final Batch Loss: 7.424402429023758e-05\n",
      "Epoch 3406, Loss: 0.0010664643559721299, Final Batch Loss: 7.397242734441534e-05\n",
      "Epoch 3407, Loss: 0.0013925137536716647, Final Batch Loss: 0.00020610788487829268\n",
      "Epoch 3408, Loss: 0.0007412007253151387, Final Batch Loss: 0.0001940986403496936\n",
      "Epoch 3409, Loss: 0.090403715003049, Final Batch Loss: 0.0001733818498905748\n",
      "Epoch 3410, Loss: 0.003640216418716591, Final Batch Loss: 0.0001571971515659243\n",
      "Epoch 3411, Loss: 0.0008817331308819121, Final Batch Loss: 0.0006634504534304142\n",
      "Epoch 3412, Loss: 0.0012322586444497574, Final Batch Loss: 5.195778430788778e-05\n",
      "Epoch 3413, Loss: 0.003027200036740396, Final Batch Loss: 0.00044733102549798787\n",
      "Epoch 3414, Loss: 0.0020246371132088825, Final Batch Loss: 0.0010533921886235476\n",
      "Epoch 3415, Loss: 0.001766269133440801, Final Batch Loss: 0.00128157006110996\n",
      "Epoch 3416, Loss: 0.0005563728918787092, Final Batch Loss: 0.0001594219938851893\n",
      "Epoch 3417, Loss: 0.0016980488144326955, Final Batch Loss: 0.000556641723960638\n",
      "Epoch 3418, Loss: 0.0006222168958629481, Final Batch Loss: 4.270387944416143e-05\n",
      "Epoch 3419, Loss: 0.0004513276326179039, Final Batch Loss: 3.745835056179203e-05\n",
      "Epoch 3420, Loss: 0.0003714505601237761, Final Batch Loss: 2.199362097599078e-05\n",
      "Epoch 3421, Loss: 0.0005463902452902403, Final Batch Loss: 0.00010664077126421034\n",
      "Epoch 3422, Loss: 0.00030694259294250514, Final Batch Loss: 4.7163834096863866e-05\n",
      "Epoch 3423, Loss: 0.0004057622281834483, Final Batch Loss: 6.568998651346192e-05\n",
      "Epoch 3424, Loss: 0.0003761095840673079, Final Batch Loss: 4.555964551400393e-05\n",
      "Epoch 3425, Loss: 0.0016993306162476074, Final Batch Loss: 0.00035764419590123\n",
      "Epoch 3426, Loss: 0.00036685070153907873, Final Batch Loss: 0.0001308928185608238\n",
      "Epoch 3427, Loss: 0.0006288591284828726, Final Batch Loss: 0.00016296704416163266\n",
      "Epoch 3428, Loss: 0.0011321555357426405, Final Batch Loss: 0.0001438151957700029\n",
      "Epoch 3429, Loss: 0.010351004491894855, Final Batch Loss: 0.0005187222850508988\n",
      "Epoch 3430, Loss: 0.006259765421418706, Final Batch Loss: 0.005810829810798168\n",
      "Epoch 3431, Loss: 0.001761551458912436, Final Batch Loss: 0.001131119322963059\n",
      "Epoch 3432, Loss: 0.0010262721225444693, Final Batch Loss: 0.0005488243186846375\n",
      "Epoch 3433, Loss: 0.0007301569130504504, Final Batch Loss: 0.00016047694953158498\n",
      "Epoch 3434, Loss: 0.0019720787204278167, Final Batch Loss: 4.180326504865661e-05\n",
      "Epoch 3435, Loss: 0.0005993513750581769, Final Batch Loss: 8.393474854528904e-05\n",
      "Epoch 3436, Loss: 0.0005431258123280713, Final Batch Loss: 7.802264008205384e-06\n",
      "Epoch 3437, Loss: 0.0008303148715640418, Final Batch Loss: 0.0003061190072912723\n",
      "Epoch 3438, Loss: 0.0010170203968300484, Final Batch Loss: 0.0004456879978533834\n",
      "Epoch 3439, Loss: 0.0010536389017943293, Final Batch Loss: 0.00043422201997600496\n",
      "Epoch 3440, Loss: 0.0007804091146681458, Final Batch Loss: 9.592535207048059e-05\n",
      "Epoch 3441, Loss: 0.004864335642196238, Final Batch Loss: 9.020278957905248e-05\n",
      "Epoch 3442, Loss: 0.001943846706126351, Final Batch Loss: 0.0018482526065781713\n",
      "Epoch 3443, Loss: 0.0021594972458842676, Final Batch Loss: 4.229361002217047e-05\n",
      "Epoch 3444, Loss: 0.00046994891636131797, Final Batch Loss: 6.305770511971787e-05\n",
      "Epoch 3445, Loss: 0.0010227074344584253, Final Batch Loss: 2.628580477903597e-05\n",
      "Epoch 3446, Loss: 0.0012122477273805998, Final Batch Loss: 0.0002479793329257518\n",
      "Epoch 3447, Loss: 0.00020617252266674768, Final Batch Loss: 0.00011801256914623082\n",
      "Epoch 3448, Loss: 0.002474923830050102, Final Batch Loss: 0.0005148093914613128\n",
      "Epoch 3449, Loss: 0.024203277956985403, Final Batch Loss: 0.0001145807109423913\n",
      "Epoch 3450, Loss: 0.00043723382623284124, Final Batch Loss: 6.367983587551862e-05\n",
      "Epoch 3451, Loss: 0.0013445352742564864, Final Batch Loss: 0.00023161980789154768\n",
      "Epoch 3452, Loss: 0.0010578489018371329, Final Batch Loss: 2.2135838662507012e-05\n",
      "Epoch 3453, Loss: 0.029661525801202515, Final Batch Loss: 0.0005954348598606884\n",
      "Epoch 3454, Loss: 0.00487179851916153, Final Batch Loss: 7.815070421202108e-05\n",
      "Epoch 3455, Loss: 0.0125632564049738, Final Batch Loss: 0.012136504054069519\n",
      "Epoch 3456, Loss: 0.003077749155636411, Final Batch Loss: 0.00205534347333014\n",
      "Epoch 3457, Loss: 0.0026337251329096034, Final Batch Loss: 0.0011478683445602655\n",
      "Epoch 3458, Loss: 0.0008606854171375744, Final Batch Loss: 0.0001416117447661236\n",
      "Epoch 3459, Loss: 0.0004624027860700153, Final Batch Loss: 2.5559034838806838e-05\n",
      "Epoch 3460, Loss: 0.0009889564462355338, Final Batch Loss: 0.0003414511738810688\n",
      "Epoch 3461, Loss: 0.000561521592317149, Final Batch Loss: 0.00016031035920605063\n",
      "Epoch 3462, Loss: 0.00850121091116307, Final Batch Loss: 2.339782986382488e-05\n",
      "Epoch 3463, Loss: 0.0003668148310680408, Final Batch Loss: 0.0001351395039819181\n",
      "Epoch 3464, Loss: 0.0018230992682219949, Final Batch Loss: 2.570542710600421e-05\n",
      "Epoch 3465, Loss: 0.0011806484690168872, Final Batch Loss: 8.037681982386857e-05\n",
      "Epoch 3466, Loss: 0.012519899468315998, Final Batch Loss: 6.6200147557538e-05\n",
      "Epoch 3467, Loss: 0.0006188902152644005, Final Batch Loss: 0.0001745745976222679\n",
      "Epoch 3468, Loss: 0.0002452568960507051, Final Batch Loss: 8.158930540957954e-06\n",
      "Epoch 3469, Loss: 0.01637225294507516, Final Batch Loss: 0.01625584438443184\n",
      "Epoch 3470, Loss: 0.0003181647416568012, Final Batch Loss: 8.673571755934972e-06\n",
      "Epoch 3471, Loss: 0.0008348801316060417, Final Batch Loss: 6.711914920742856e-06\n",
      "Epoch 3472, Loss: 0.010954805824439973, Final Batch Loss: 0.00024195844889618456\n",
      "Epoch 3473, Loss: 0.0064156172429647995, Final Batch Loss: 0.00013002782361581922\n",
      "Epoch 3474, Loss: 0.00043312338857504074, Final Batch Loss: 4.64176555396989e-05\n",
      "Epoch 3475, Loss: 0.007278866047272459, Final Batch Loss: 0.005331540945917368\n",
      "Epoch 3476, Loss: 0.02637871333354269, Final Batch Loss: 0.025146406143903732\n",
      "Epoch 3477, Loss: 0.0025082706997636706, Final Batch Loss: 0.00013544327521231025\n",
      "Epoch 3478, Loss: 0.05657443027848785, Final Batch Loss: 1.422431341779884e-05\n",
      "Epoch 3479, Loss: 0.04334585195465479, Final Batch Loss: 0.03906199708580971\n",
      "Epoch 3480, Loss: 0.01981635454467323, Final Batch Loss: 0.00021847107564099133\n",
      "Epoch 3481, Loss: 0.006783443903259467, Final Batch Loss: 0.0001197506717289798\n",
      "Epoch 3482, Loss: 0.0013124237229931168, Final Batch Loss: 0.0007886618259362876\n",
      "Epoch 3483, Loss: 0.030441657290793955, Final Batch Loss: 0.028780458495020866\n",
      "Epoch 3484, Loss: 0.003866603430651594, Final Batch Loss: 0.00019565032562240958\n",
      "Epoch 3485, Loss: 0.00904189033099101, Final Batch Loss: 9.896628034766763e-05\n",
      "Epoch 3486, Loss: 0.00077716181112919, Final Batch Loss: 0.00024668380501680076\n",
      "Epoch 3487, Loss: 0.04412204927939456, Final Batch Loss: 0.00024499717983417213\n",
      "Epoch 3488, Loss: 0.03319985835332773, Final Batch Loss: 5.262776539893821e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3489, Loss: 0.0010074390938825672, Final Batch Loss: 1.793554656615015e-05\n",
      "Epoch 3490, Loss: 0.0008659580707899295, Final Batch Loss: 0.0005826019332744181\n",
      "Epoch 3491, Loss: 0.0005398808934842236, Final Batch Loss: 0.00017842459783423692\n",
      "Epoch 3492, Loss: 0.002172401931602508, Final Batch Loss: 0.0013574459590017796\n",
      "Epoch 3493, Loss: 0.000633210212981794, Final Batch Loss: 0.0001007280734484084\n",
      "Epoch 3494, Loss: 0.0018687578376557212, Final Batch Loss: 0.00012378755491226912\n",
      "Epoch 3495, Loss: 0.0012297487846808508, Final Batch Loss: 0.00045528251212090254\n",
      "Epoch 3496, Loss: 0.0013242438435554504, Final Batch Loss: 0.00019823448383249342\n",
      "Epoch 3497, Loss: 0.0006782732889405452, Final Batch Loss: 7.66147204558365e-05\n",
      "Epoch 3498, Loss: 0.00623865429952275, Final Batch Loss: 0.0059496620669960976\n",
      "Epoch 3499, Loss: 0.001676807656622259, Final Batch Loss: 0.0009802618296816945\n",
      "Epoch 3500, Loss: 0.0007751174416625872, Final Batch Loss: 0.0002500330447219312\n",
      "Epoch 3501, Loss: 0.0011270250979578122, Final Batch Loss: 0.00012663885718211532\n",
      "Epoch 3502, Loss: 0.00030658243485959247, Final Batch Loss: 0.00010950483556371182\n",
      "Epoch 3503, Loss: 0.0008869448065524921, Final Batch Loss: 0.00025036459555849433\n",
      "Epoch 3504, Loss: 0.0006948697227926459, Final Batch Loss: 2.3884644178906456e-05\n",
      "Epoch 3505, Loss: 0.0005013593217881862, Final Batch Loss: 3.714328704518266e-05\n",
      "Epoch 3506, Loss: 0.0013581342336692614, Final Batch Loss: 5.577465344686061e-05\n",
      "Epoch 3507, Loss: 0.0033378590596839786, Final Batch Loss: 0.0003893451939802617\n",
      "Epoch 3508, Loss: 0.0003112620543106459, Final Batch Loss: 8.968296606326476e-05\n",
      "Epoch 3509, Loss: 0.0009780796681297943, Final Batch Loss: 0.0003372450591996312\n",
      "Epoch 3510, Loss: 0.001236921987583628, Final Batch Loss: 0.0004399003810249269\n",
      "Epoch 3511, Loss: 0.0006847530166851357, Final Batch Loss: 0.00015192276623565704\n",
      "Epoch 3512, Loss: 0.0005548591652768664, Final Batch Loss: 7.628899038536474e-05\n",
      "Epoch 3513, Loss: 0.0003676211963465903, Final Batch Loss: 4.7499652282567695e-05\n",
      "Epoch 3514, Loss: 0.0031769360139151104, Final Batch Loss: 4.839452594751492e-05\n",
      "Epoch 3515, Loss: 0.0005124749586684629, Final Batch Loss: 0.00025671676849015057\n",
      "Epoch 3516, Loss: 0.001200311140564736, Final Batch Loss: 0.00016337308625224978\n",
      "Epoch 3517, Loss: 0.0006032599721947918, Final Batch Loss: 3.133071368210949e-05\n",
      "Epoch 3518, Loss: 0.0008842566239763983, Final Batch Loss: 0.000636974407825619\n",
      "Epoch 3519, Loss: 0.0004699584715126548, Final Batch Loss: 5.7769797422224656e-05\n",
      "Epoch 3520, Loss: 0.0007361545276580728, Final Batch Loss: 0.0003757690137717873\n",
      "Epoch 3521, Loss: 0.0005905385187361389, Final Batch Loss: 0.00013831765681970865\n",
      "Epoch 3522, Loss: 0.0009297875367337838, Final Batch Loss: 0.0005928560276515782\n",
      "Epoch 3523, Loss: 0.0006277397424128139, Final Batch Loss: 2.0075547581654973e-05\n",
      "Epoch 3524, Loss: 0.005106308410177007, Final Batch Loss: 0.0003576704766601324\n",
      "Epoch 3525, Loss: 0.003971286547312047, Final Batch Loss: 0.00011085302685387433\n",
      "Epoch 3526, Loss: 0.0005742087741964497, Final Batch Loss: 9.26114953472279e-05\n",
      "Epoch 3527, Loss: 0.0022852643824080587, Final Batch Loss: 0.00017979097901843488\n",
      "Epoch 3528, Loss: 0.003984490605944302, Final Batch Loss: 0.0002147269988199696\n",
      "Epoch 3529, Loss: 0.001907472891616635, Final Batch Loss: 1.1436154636612628e-05\n",
      "Epoch 3530, Loss: 0.0006233819949557073, Final Batch Loss: 0.00011105925659649074\n",
      "Epoch 3531, Loss: 0.0019150756943417946, Final Batch Loss: 2.8348867999739014e-05\n",
      "Epoch 3532, Loss: 0.0007985940756043419, Final Batch Loss: 3.6920857382938266e-05\n",
      "Epoch 3533, Loss: 0.005221089422775549, Final Batch Loss: 6.681979357381351e-06\n",
      "Epoch 3534, Loss: 0.0012329719411354745, Final Batch Loss: 2.731129279709421e-05\n",
      "Epoch 3535, Loss: 0.0007279119345184881, Final Batch Loss: 0.00010056620521936566\n",
      "Epoch 3536, Loss: 0.0010232963322778232, Final Batch Loss: 0.000221821348532103\n",
      "Epoch 3537, Loss: 0.0008366802394448314, Final Batch Loss: 0.0002995066752191633\n",
      "Epoch 3538, Loss: 0.00046119653052301146, Final Batch Loss: 5.034895002609119e-05\n",
      "Epoch 3539, Loss: 0.0008033017802517861, Final Batch Loss: 0.00028779509011656046\n",
      "Epoch 3540, Loss: 0.013122329284669831, Final Batch Loss: 0.010833571664988995\n",
      "Epoch 3541, Loss: 0.001276003440580098, Final Batch Loss: 8.545553282601759e-05\n",
      "Epoch 3542, Loss: 0.0009468089192523621, Final Batch Loss: 0.00035288758226670325\n",
      "Epoch 3543, Loss: 0.0022684382238367107, Final Batch Loss: 8.670071110827848e-05\n",
      "Epoch 3544, Loss: 0.004078607656992972, Final Batch Loss: 0.00022481929045170546\n",
      "Epoch 3545, Loss: 0.00068213306076359, Final Batch Loss: 9.028157364809886e-05\n",
      "Epoch 3546, Loss: 0.00035861603100784123, Final Batch Loss: 1.0379233572166413e-05\n",
      "Epoch 3547, Loss: 0.0008461109318886884, Final Batch Loss: 0.00014800911594647914\n",
      "Epoch 3548, Loss: 0.000320770668622572, Final Batch Loss: 0.00010322347225155681\n",
      "Epoch 3549, Loss: 0.0003429139906074852, Final Batch Loss: 7.780766463838518e-05\n",
      "Epoch 3550, Loss: 0.00027098798454971984, Final Batch Loss: 6.070893141441047e-05\n",
      "Epoch 3551, Loss: 0.002318375372851733, Final Batch Loss: 0.0015734047628939152\n",
      "Epoch 3552, Loss: 0.0054418401850853115, Final Batch Loss: 0.0046320948749780655\n",
      "Epoch 3553, Loss: 0.0003008228495673393, Final Batch Loss: 5.8012308727484196e-05\n",
      "Epoch 3554, Loss: 0.0007886953808338149, Final Batch Loss: 0.0003435203107073903\n",
      "Epoch 3555, Loss: 0.0018771526265481953, Final Batch Loss: 1.9530820281943306e-05\n",
      "Epoch 3556, Loss: 0.003359941503731534, Final Batch Loss: 0.0003707112919073552\n",
      "Epoch 3557, Loss: 0.001185596251161769, Final Batch Loss: 0.0006333620403893292\n",
      "Epoch 3558, Loss: 0.0010174798480875324, Final Batch Loss: 0.0001418370084138587\n",
      "Epoch 3559, Loss: 0.0005645007549901493, Final Batch Loss: 3.0539988074451685e-05\n",
      "Epoch 3560, Loss: 0.010292449136613868, Final Batch Loss: 0.009815381839871407\n",
      "Epoch 3561, Loss: 0.0011768141484935768, Final Batch Loss: 0.0001573583867866546\n",
      "Epoch 3562, Loss: 0.0004714141268777894, Final Batch Loss: 3.998808824690059e-05\n",
      "Epoch 3563, Loss: 0.002706485156522831, Final Batch Loss: 5.865917410119437e-05\n",
      "Epoch 3564, Loss: 0.00040974684634420555, Final Batch Loss: 6.66159758111462e-05\n",
      "Epoch 3565, Loss: 0.0007326779498271208, Final Batch Loss: 0.00015145057113841176\n",
      "Epoch 3566, Loss: 0.00022872935369377956, Final Batch Loss: 8.573862032790203e-06\n",
      "Epoch 3567, Loss: 0.0013169986068533035, Final Batch Loss: 9.523797416477464e-06\n",
      "Epoch 3568, Loss: 0.00040457486829836853, Final Batch Loss: 2.673047492862679e-05\n",
      "Epoch 3569, Loss: 0.007360107789281756, Final Batch Loss: 1.832801353884861e-05\n",
      "Epoch 3570, Loss: 0.0008178965608749422, Final Batch Loss: 9.392852916789707e-06\n",
      "Epoch 3571, Loss: 0.0004694069084507646, Final Batch Loss: 1.6505024177604355e-05\n",
      "Epoch 3572, Loss: 0.0005003044689146918, Final Batch Loss: 0.00042628758819773793\n",
      "Epoch 3573, Loss: 0.00036640281177824363, Final Batch Loss: 6.520390161313117e-05\n",
      "Epoch 3574, Loss: 0.0018719915506153484, Final Batch Loss: 5.053863787907176e-05\n",
      "Epoch 3575, Loss: 0.0007035310336505063, Final Batch Loss: 4.682955477619544e-05\n",
      "Epoch 3576, Loss: 0.0008046919811022235, Final Batch Loss: 9.035370021592826e-05\n",
      "Epoch 3577, Loss: 0.0002732001830736408, Final Batch Loss: 2.279801083204802e-05\n",
      "Epoch 3578, Loss: 0.0009668655002315063, Final Batch Loss: 0.00016234237409662455\n",
      "Epoch 3579, Loss: 0.0007548923422291409, Final Batch Loss: 4.220793198328465e-05\n",
      "Epoch 3580, Loss: 0.0007784827175782993, Final Batch Loss: 0.0005337067414075136\n",
      "Epoch 3581, Loss: 0.00046916302972022095, Final Batch Loss: 0.0002995262620970607\n",
      "Epoch 3582, Loss: 0.000799216327322938, Final Batch Loss: 1.5216825886454899e-05\n",
      "Epoch 3583, Loss: 0.0004208867176203057, Final Batch Loss: 0.00011585751781240106\n",
      "Epoch 3584, Loss: 0.008543426385585917, Final Batch Loss: 4.091652590432204e-05\n",
      "Epoch 3585, Loss: 0.008532322713108442, Final Batch Loss: 5.598601092060562e-06\n",
      "Epoch 3586, Loss: 0.0036683676662505604, Final Batch Loss: 0.0024436211679130793\n",
      "Epoch 3587, Loss: 0.0016367799939871475, Final Batch Loss: 5.3868188842898235e-05\n",
      "Epoch 3588, Loss: 0.00089646198466653, Final Batch Loss: 3.838978591375053e-05\n",
      "Epoch 3589, Loss: 0.004438728556124261, Final Batch Loss: 0.004359572194516659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3590, Loss: 0.0005261857804725878, Final Batch Loss: 0.00019425249774940312\n",
      "Epoch 3591, Loss: 0.0003983692567999242, Final Batch Loss: 2.3389007765217684e-05\n",
      "Epoch 3592, Loss: 0.004484292359848041, Final Batch Loss: 0.0008722301572561264\n",
      "Epoch 3593, Loss: 0.00043839699446834857, Final Batch Loss: 9.205960850522388e-06\n",
      "Epoch 3594, Loss: 0.00026141076523344964, Final Batch Loss: 2.3490509192924947e-05\n",
      "Epoch 3595, Loss: 0.00040305834795617557, Final Batch Loss: 0.00016166850400622934\n",
      "Epoch 3596, Loss: 0.011046482999518048, Final Batch Loss: 0.0001487476984038949\n",
      "Epoch 3597, Loss: 0.0475200649616454, Final Batch Loss: 0.00021796718647237867\n",
      "Epoch 3598, Loss: 0.0026602469733916223, Final Batch Loss: 0.00030839184182696044\n",
      "Epoch 3599, Loss: 0.00038127953848743346, Final Batch Loss: 0.00020382137154228985\n",
      "Epoch 3600, Loss: 0.001506254768173676, Final Batch Loss: 7.410805119434372e-05\n",
      "Epoch 3601, Loss: 0.0020825582887482597, Final Batch Loss: 0.00021715850743930787\n",
      "Epoch 3602, Loss: 0.015387048217235133, Final Batch Loss: 0.00011762800568249077\n",
      "Epoch 3603, Loss: 0.0004007547122455435, Final Batch Loss: 0.0002604448818601668\n",
      "Epoch 3604, Loss: 0.008839939862809842, Final Batch Loss: 0.0012362233828753233\n",
      "Epoch 3605, Loss: 0.00045986792247276753, Final Batch Loss: 6.681292143184692e-05\n",
      "Epoch 3606, Loss: 0.00029271578023326583, Final Batch Loss: 8.561449794797227e-05\n",
      "Epoch 3607, Loss: 0.033696104130285676, Final Batch Loss: 3.894258043146692e-06\n",
      "Epoch 3608, Loss: 0.0041486668269499205, Final Batch Loss: 2.098422555718571e-05\n",
      "Epoch 3609, Loss: 0.013707307545701042, Final Batch Loss: 0.0007571811438538134\n",
      "Epoch 3610, Loss: 0.0010419791324238759, Final Batch Loss: 4.7787932999199256e-05\n",
      "Epoch 3611, Loss: 0.0010911519784713164, Final Batch Loss: 7.6545104093384e-05\n",
      "Epoch 3612, Loss: 0.0009216440739692189, Final Batch Loss: 0.00022775358229409903\n",
      "Epoch 3613, Loss: 0.02931362319213804, Final Batch Loss: 0.0011891776230186224\n",
      "Epoch 3614, Loss: 0.0008903886628104374, Final Batch Loss: 0.00011769078264478594\n",
      "Epoch 3615, Loss: 0.0037557632895186543, Final Batch Loss: 0.0003010297368746251\n",
      "Epoch 3616, Loss: 0.003357182693434879, Final Batch Loss: 0.0024476745165884495\n",
      "Epoch 3617, Loss: 0.0006748543491994496, Final Batch Loss: 9.095646964851767e-05\n",
      "Epoch 3618, Loss: 0.0010463030630489811, Final Batch Loss: 5.848145519848913e-05\n",
      "Epoch 3619, Loss: 0.0006940958301129285, Final Batch Loss: 2.6882331439992413e-05\n",
      "Epoch 3620, Loss: 0.00047159509085759055, Final Batch Loss: 5.205092747928575e-05\n",
      "Epoch 3621, Loss: 0.0002731783933995757, Final Batch Loss: 0.00010846609802683815\n",
      "Epoch 3622, Loss: 0.001818733122490812, Final Batch Loss: 6.565837247762829e-05\n",
      "Epoch 3623, Loss: 0.000821923982584849, Final Batch Loss: 0.0003665797703433782\n",
      "Epoch 3624, Loss: 0.00044321119821688626, Final Batch Loss: 2.264738031954039e-05\n",
      "Epoch 3625, Loss: 0.0008436047264694935, Final Batch Loss: 2.576319639047142e-05\n",
      "Epoch 3626, Loss: 0.009579080920957495, Final Batch Loss: 4.999744851374999e-05\n",
      "Epoch 3627, Loss: 0.00035528856824385, Final Batch Loss: 6.924954504938796e-05\n",
      "Epoch 3628, Loss: 0.0006870682918815874, Final Batch Loss: 0.00038901736843399704\n",
      "Epoch 3629, Loss: 0.0005124710096424678, Final Batch Loss: 0.00017530286277178675\n",
      "Epoch 3630, Loss: 0.0026018466742243618, Final Batch Loss: 0.0002983191516250372\n",
      "Epoch 3631, Loss: 0.002228761266451329, Final Batch Loss: 0.0002624472544994205\n",
      "Epoch 3632, Loss: 0.0006141258709249087, Final Batch Loss: 6.637016485910863e-05\n",
      "Epoch 3633, Loss: 0.000733217293600319, Final Batch Loss: 9.796060476219282e-05\n",
      "Epoch 3634, Loss: 0.0006657317753706593, Final Batch Loss: 3.549859320628457e-05\n",
      "Epoch 3635, Loss: 0.001434137613614439, Final Batch Loss: 0.0010223283898085356\n",
      "Epoch 3636, Loss: 0.0009191503195324913, Final Batch Loss: 5.3260613640304655e-05\n",
      "Epoch 3637, Loss: 0.00024326470156665891, Final Batch Loss: 8.513839566148818e-05\n",
      "Epoch 3638, Loss: 0.0005720298904634546, Final Batch Loss: 9.960162424249575e-05\n",
      "Epoch 3639, Loss: 0.0006412927996279905, Final Batch Loss: 0.00026166814495809376\n",
      "Epoch 3640, Loss: 0.0012928818132422748, Final Batch Loss: 0.0011310239788144827\n",
      "Epoch 3641, Loss: 0.0005775433464805246, Final Batch Loss: 7.022333193162922e-06\n",
      "Epoch 3642, Loss: 0.0008362505486729788, Final Batch Loss: 0.00013580339145846665\n",
      "Epoch 3643, Loss: 0.0006355850055115297, Final Batch Loss: 7.49991086195223e-05\n",
      "Epoch 3644, Loss: 0.011764503091399092, Final Batch Loss: 0.010863633826375008\n",
      "Epoch 3645, Loss: 0.0018026142570306547, Final Batch Loss: 0.0007123374962247908\n",
      "Epoch 3646, Loss: 0.03011508466443047, Final Batch Loss: 0.00017772166756913066\n",
      "Epoch 3647, Loss: 0.0005055944893683773, Final Batch Loss: 2.7563681214815006e-05\n",
      "Epoch 3648, Loss: 0.0006492543816420948, Final Batch Loss: 2.0494982891250402e-05\n",
      "Epoch 3649, Loss: 0.0006005815284879645, Final Batch Loss: 2.7983978725387715e-05\n",
      "Epoch 3650, Loss: 0.0007066669586492935, Final Batch Loss: 0.00012357709056232125\n",
      "Epoch 3651, Loss: 0.0008709256435395218, Final Batch Loss: 0.0003360907721798867\n",
      "Epoch 3652, Loss: 0.001697246203548275, Final Batch Loss: 0.0010564284166321158\n",
      "Epoch 3653, Loss: 0.0003911858075298369, Final Batch Loss: 9.779709944268689e-05\n",
      "Epoch 3654, Loss: 0.0005278694716253085, Final Batch Loss: 1.9651079128379934e-05\n",
      "Epoch 3655, Loss: 0.0006063548062229529, Final Batch Loss: 0.00021772545005660504\n",
      "Epoch 3656, Loss: 0.0008757429677643813, Final Batch Loss: 0.0003274668415542692\n",
      "Epoch 3657, Loss: 0.002730467647779733, Final Batch Loss: 0.00015926567721180618\n",
      "Epoch 3658, Loss: 0.00035351000042282976, Final Batch Loss: 0.00016959907952696085\n",
      "Epoch 3659, Loss: 0.0036928658446413465, Final Batch Loss: 0.003440935630351305\n",
      "Epoch 3660, Loss: 0.0006696707678202074, Final Batch Loss: 0.0002263220667373389\n",
      "Epoch 3661, Loss: 0.0004750576408696361, Final Batch Loss: 9.723874245537445e-05\n",
      "Epoch 3662, Loss: 0.0006605188327739597, Final Batch Loss: 1.5114078451006208e-05\n",
      "Epoch 3663, Loss: 0.0006568062672158703, Final Batch Loss: 3.5489927540766075e-05\n",
      "Epoch 3664, Loss: 0.00028684760400210507, Final Batch Loss: 0.00019027022062800825\n",
      "Epoch 3665, Loss: 0.0004063236774527468, Final Batch Loss: 0.00033035280648618937\n",
      "Epoch 3666, Loss: 0.0007968270474520978, Final Batch Loss: 7.856023876229301e-05\n",
      "Epoch 3667, Loss: 0.0015896612185315462, Final Batch Loss: 0.0011933797504752874\n",
      "Epoch 3668, Loss: 0.0010512365188333206, Final Batch Loss: 9.920231968862936e-05\n",
      "Epoch 3669, Loss: 0.00021904505229031201, Final Batch Loss: 1.1698071830323897e-05\n",
      "Epoch 3670, Loss: 0.006710176996421069, Final Batch Loss: 0.00015599864127580076\n",
      "Epoch 3671, Loss: 0.0003317230621178169, Final Batch Loss: 9.127172234002501e-05\n",
      "Epoch 3672, Loss: 0.01262707900696114, Final Batch Loss: 3.722409383044578e-05\n",
      "Epoch 3673, Loss: 0.0003752279735635966, Final Batch Loss: 4.893256846116856e-05\n",
      "Epoch 3674, Loss: 0.0013503438021871261, Final Batch Loss: 0.0010316625703126192\n",
      "Epoch 3675, Loss: 0.0018314604694751324, Final Batch Loss: 0.00035019582719542086\n",
      "Epoch 3676, Loss: 0.0031210839515551925, Final Batch Loss: 4.0452490793541074e-05\n",
      "Epoch 3677, Loss: 0.00037974595034029335, Final Batch Loss: 0.0001315321569563821\n",
      "Epoch 3678, Loss: 0.00042910413685604, Final Batch Loss: 0.00024232360010500997\n",
      "Epoch 3679, Loss: 0.0009928104263963178, Final Batch Loss: 0.00010708245827117935\n",
      "Epoch 3680, Loss: 0.0008271176811831538, Final Batch Loss: 2.3230895749293268e-05\n",
      "Epoch 3681, Loss: 0.0021085462722112425, Final Batch Loss: 0.0016904195072129369\n",
      "Epoch 3682, Loss: 0.0020110384648432955, Final Batch Loss: 0.00012206505925860256\n",
      "Epoch 3683, Loss: 0.0013680866759386845, Final Batch Loss: 0.0013062016805633903\n",
      "Epoch 3684, Loss: 0.0008943600114434958, Final Batch Loss: 8.462455298285931e-05\n",
      "Epoch 3685, Loss: 0.0009839105659921188, Final Batch Loss: 1.5286979760276154e-05\n",
      "Epoch 3686, Loss: 0.00046911377512515173, Final Batch Loss: 2.9729294510616455e-06\n",
      "Epoch 3687, Loss: 0.0003081133290834259, Final Batch Loss: 0.00016340991714969277\n",
      "Epoch 3688, Loss: 0.0002441750475554727, Final Batch Loss: 4.7021494538057595e-05\n",
      "Epoch 3689, Loss: 0.00048748084918770473, Final Batch Loss: 4.6210199798224494e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3690, Loss: 0.0006255197008613322, Final Batch Loss: 9.669783321442083e-05\n",
      "Epoch 3691, Loss: 0.000383298849556013, Final Batch Loss: 0.00019004885689355433\n",
      "Epoch 3692, Loss: 0.00023073803004081128, Final Batch Loss: 8.031487959669903e-05\n",
      "Epoch 3693, Loss: 0.0003431342429394135, Final Batch Loss: 0.0001629567559575662\n",
      "Epoch 3694, Loss: 0.0002290376760356594, Final Batch Loss: 5.0380887842038646e-05\n",
      "Epoch 3695, Loss: 0.0005678674260707339, Final Batch Loss: 0.00010880759509745985\n",
      "Epoch 3696, Loss: 0.0006954426389711443, Final Batch Loss: 1.5340947356889956e-05\n",
      "Epoch 3697, Loss: 0.0012780592451235862, Final Batch Loss: 8.96643632586347e-06\n",
      "Epoch 3698, Loss: 0.0002515277283237083, Final Batch Loss: 8.345876995008439e-05\n",
      "Epoch 3699, Loss: 0.00041554177823854843, Final Batch Loss: 1.6252202840405516e-05\n",
      "Epoch 3700, Loss: 0.029990866078151157, Final Batch Loss: 4.094851828995161e-05\n",
      "Epoch 3701, Loss: 0.002547562203289999, Final Batch Loss: 5.802948180644307e-06\n",
      "Epoch 3702, Loss: 0.0002973113751068013, Final Batch Loss: 0.0001080621950677596\n",
      "Epoch 3703, Loss: 0.006204032789355551, Final Batch Loss: 0.00569854537025094\n",
      "Epoch 3704, Loss: 0.0009024060859701422, Final Batch Loss: 0.0005957531975582242\n",
      "Epoch 3705, Loss: 0.0013444873402477242, Final Batch Loss: 2.0632260202546604e-05\n",
      "Epoch 3706, Loss: 0.000967774132732302, Final Batch Loss: 0.00014430411101784557\n",
      "Epoch 3707, Loss: 0.005097508834296605, Final Batch Loss: 0.0005985553725622594\n",
      "Epoch 3708, Loss: 0.0012657285751629388, Final Batch Loss: 2.6019826691481285e-05\n",
      "Epoch 3709, Loss: 0.0005291011511872057, Final Batch Loss: 9.148359822575003e-05\n",
      "Epoch 3710, Loss: 0.001963593953405507, Final Batch Loss: 0.00014502907288260758\n",
      "Epoch 3711, Loss: 0.0002435719566165062, Final Batch Loss: 4.961084869137267e-06\n",
      "Epoch 3712, Loss: 0.00022444325441028923, Final Batch Loss: 4.22756202169694e-05\n",
      "Epoch 3713, Loss: 0.018235798052046448, Final Batch Loss: 0.016513783484697342\n",
      "Epoch 3714, Loss: 0.0002633146050357027, Final Batch Loss: 7.932867447379977e-05\n",
      "Epoch 3715, Loss: 0.012308030854910612, Final Batch Loss: 0.01154759805649519\n",
      "Epoch 3716, Loss: 0.0013398124265222577, Final Batch Loss: 1.836963747336995e-05\n",
      "Epoch 3717, Loss: 0.0005918101160204969, Final Batch Loss: 0.00018855334201361984\n",
      "Epoch 3718, Loss: 0.0005098022716083506, Final Batch Loss: 5.417649390437873e-06\n",
      "Epoch 3719, Loss: 0.00023671541021030862, Final Batch Loss: 0.0001705507020233199\n",
      "Epoch 3720, Loss: 0.034195234798971796, Final Batch Loss: 0.0340484119951725\n",
      "Epoch 3721, Loss: 0.0001337863850494614, Final Batch Loss: 9.015896466735285e-06\n",
      "Epoch 3722, Loss: 0.00042866981857514475, Final Batch Loss: 0.00012681751104537398\n",
      "Epoch 3723, Loss: 0.00028033995840814896, Final Batch Loss: 4.7150650061666965e-05\n",
      "Epoch 3724, Loss: 0.000682310634147143, Final Batch Loss: 2.228490120614879e-05\n",
      "Epoch 3725, Loss: 0.004384460175060667, Final Batch Loss: 1.8992512195836753e-05\n",
      "Epoch 3726, Loss: 0.00048013924606493674, Final Batch Loss: 0.00014720606850460172\n",
      "Epoch 3727, Loss: 0.02008364660287043, Final Batch Loss: 0.01953386515378952\n",
      "Epoch 3728, Loss: 0.003207934081729036, Final Batch Loss: 0.00015235604951158166\n",
      "Epoch 3729, Loss: 0.0012928343012390542, Final Batch Loss: 4.185347643215209e-05\n",
      "Epoch 3730, Loss: 0.0007751090579404263, Final Batch Loss: 0.00039498446858488023\n",
      "Epoch 3731, Loss: 0.0018020510178757831, Final Batch Loss: 0.0005200980813242495\n",
      "Epoch 3732, Loss: 0.000362119943019934, Final Batch Loss: 5.0580169045133516e-05\n",
      "Epoch 3733, Loss: 0.0006494086737802718, Final Batch Loss: 0.00016950444842223078\n",
      "Epoch 3734, Loss: 0.0035242559242760763, Final Batch Loss: 6.748508894816041e-05\n",
      "Epoch 3735, Loss: 0.001985408045584336, Final Batch Loss: 0.0013235401129350066\n",
      "Epoch 3736, Loss: 0.0003071304040531686, Final Batch Loss: 4.010477368865395e-06\n",
      "Epoch 3737, Loss: 0.0003916921896234271, Final Batch Loss: 3.0787115974817425e-05\n",
      "Epoch 3738, Loss: 0.0013673868088517338, Final Batch Loss: 0.0004067081608809531\n",
      "Epoch 3739, Loss: 0.0020982160485800705, Final Batch Loss: 0.0010034303413704038\n",
      "Epoch 3740, Loss: 0.0002530900251258572, Final Batch Loss: 0.00010857283632503822\n",
      "Epoch 3741, Loss: 0.0044523164838210505, Final Batch Loss: 4.654423264582874e-06\n",
      "Epoch 3742, Loss: 0.0005407526305134525, Final Batch Loss: 8.383719432458747e-06\n",
      "Epoch 3743, Loss: 0.0008825435452308739, Final Batch Loss: 0.0006405625026673079\n",
      "Epoch 3744, Loss: 0.0003609522627812112, Final Batch Loss: 2.0090947145945393e-05\n",
      "Epoch 3745, Loss: 0.012263572645679233, Final Batch Loss: 0.011732418090105057\n",
      "Epoch 3746, Loss: 0.013031881062488537, Final Batch Loss: 7.222089334391057e-05\n",
      "Epoch 3747, Loss: 0.003327805214212276, Final Batch Loss: 0.001262356759980321\n",
      "Epoch 3748, Loss: 0.0009822383944992907, Final Batch Loss: 0.0003999844193458557\n",
      "Epoch 3749, Loss: 0.001110241156311531, Final Batch Loss: 6.0984357332927175e-06\n",
      "Epoch 3750, Loss: 0.0044687040644930676, Final Batch Loss: 0.0021666213870048523\n",
      "Epoch 3751, Loss: 0.0017211858212249354, Final Batch Loss: 2.7279616915620863e-05\n",
      "Epoch 3752, Loss: 0.0011132928193546832, Final Batch Loss: 0.00021288424613885581\n",
      "Epoch 3753, Loss: 0.00023669711572438246, Final Batch Loss: 1.4895264939696062e-05\n",
      "Epoch 3754, Loss: 0.0015530530035903212, Final Batch Loss: 0.00021222549548838288\n",
      "Epoch 3755, Loss: 0.00032654431197443046, Final Batch Loss: 0.00024191474949475378\n",
      "Epoch 3756, Loss: 0.0006006850944686448, Final Batch Loss: 0.0003852732479572296\n",
      "Epoch 3757, Loss: 0.0012760243598677334, Final Batch Loss: 1.0745171493908856e-05\n",
      "Epoch 3758, Loss: 0.0007463727019967337, Final Batch Loss: 0.0006970020476728678\n",
      "Epoch 3759, Loss: 0.002206992852734402, Final Batch Loss: 0.00010404264321550727\n",
      "Epoch 3760, Loss: 0.001531929976408719, Final Batch Loss: 0.0008545793825760484\n",
      "Epoch 3761, Loss: 0.0013477528727889876, Final Batch Loss: 0.00024022258003242314\n",
      "Epoch 3762, Loss: 0.006243688418180682, Final Batch Loss: 0.0055444687604904175\n",
      "Epoch 3763, Loss: 0.0006325579579424812, Final Batch Loss: 2.7520682124304585e-05\n",
      "Epoch 3764, Loss: 0.025132448641670635, Final Batch Loss: 3.128585740341805e-05\n",
      "Epoch 3765, Loss: 0.0012571431848300563, Final Batch Loss: 6.351886895572534e-06\n",
      "Epoch 3766, Loss: 0.0010300337671651505, Final Batch Loss: 0.0006671336595900357\n",
      "Epoch 3767, Loss: 0.0010639922020345693, Final Batch Loss: 1.9708457330125384e-05\n",
      "Epoch 3768, Loss: 0.0004409213470353279, Final Batch Loss: 0.00014108262257650495\n",
      "Epoch 3769, Loss: 0.0016582170683250297, Final Batch Loss: 0.0008829431608319283\n",
      "Epoch 3770, Loss: 0.00023868515199865215, Final Batch Loss: 4.077287667314522e-05\n",
      "Epoch 3771, Loss: 0.0037346040189731866, Final Batch Loss: 0.00033937187981791794\n",
      "Epoch 3772, Loss: 0.0003150603788526496, Final Batch Loss: 0.00022137898486107588\n",
      "Epoch 3773, Loss: 0.00048340228022425435, Final Batch Loss: 0.00019488902762532234\n",
      "Epoch 3774, Loss: 0.0006808823618484894, Final Batch Loss: 0.0004887814284302294\n",
      "Epoch 3775, Loss: 0.00492087187103607, Final Batch Loss: 1.3418118214758579e-05\n",
      "Epoch 3776, Loss: 0.00028936145736224717, Final Batch Loss: 0.00010556114284554496\n",
      "Epoch 3777, Loss: 0.0004646846700779861, Final Batch Loss: 9.61049045145046e-06\n",
      "Epoch 3778, Loss: 0.00037715279540861957, Final Batch Loss: 0.00022136526240501553\n",
      "Epoch 3779, Loss: 0.00021754991939815227, Final Batch Loss: 8.771158172748983e-05\n",
      "Epoch 3780, Loss: 0.0012483840837376192, Final Batch Loss: 3.926851422875188e-05\n",
      "Epoch 3781, Loss: 0.0003337568814458791, Final Batch Loss: 2.2741482098354027e-05\n",
      "Epoch 3782, Loss: 0.0001576892727825907, Final Batch Loss: 7.956655463203788e-05\n",
      "Epoch 3783, Loss: 0.0005154858463356504, Final Batch Loss: 0.00036679356708191335\n",
      "Epoch 3784, Loss: 0.0009903665079491475, Final Batch Loss: 4.2155828850809485e-05\n",
      "Epoch 3785, Loss: 7.425485318890424e-05, Final Batch Loss: 2.6279036319465376e-05\n",
      "Epoch 3786, Loss: 0.00033564036175448564, Final Batch Loss: 7.129483037715545e-06\n",
      "Epoch 3787, Loss: 9.977526224247413e-05, Final Batch Loss: 1.1689769962686114e-05\n",
      "Epoch 3788, Loss: 0.00046155950030879467, Final Batch Loss: 6.595458671654342e-06\n",
      "Epoch 3789, Loss: 0.0008802361398920766, Final Batch Loss: 1.9255348888691515e-05\n",
      "Epoch 3790, Loss: 0.00016300734341712086, Final Batch Loss: 7.618982181156753e-06\n",
      "Epoch 3791, Loss: 0.02233175852961722, Final Batch Loss: 3.690308585646562e-05\n",
      "Epoch 3792, Loss: 0.00025477078361291206, Final Batch Loss: 0.00011828338756458834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3793, Loss: 0.0006914463201610488, Final Batch Loss: 0.0005858202930539846\n",
      "Epoch 3794, Loss: 0.008211822203520569, Final Batch Loss: 0.0021572718396782875\n",
      "Epoch 3795, Loss: 0.0021546862917602994, Final Batch Loss: 0.0002637789584696293\n",
      "Epoch 3796, Loss: 0.0015000070798123488, Final Batch Loss: 0.0002967726904898882\n",
      "Epoch 3797, Loss: 0.0005216064582782565, Final Batch Loss: 7.448032556567341e-05\n",
      "Epoch 3798, Loss: 0.0007083391901687719, Final Batch Loss: 1.8828330212272704e-05\n",
      "Epoch 3799, Loss: 0.0005740046399296261, Final Batch Loss: 0.00019594783952925354\n",
      "Epoch 3800, Loss: 0.001267078987439163, Final Batch Loss: 4.0452112443745136e-05\n",
      "Epoch 3801, Loss: 0.0002955334639409557, Final Batch Loss: 6.160452903714031e-05\n",
      "Epoch 3802, Loss: 0.00012664991299971007, Final Batch Loss: 4.262636502971873e-05\n",
      "Epoch 3803, Loss: 0.0007867360600357642, Final Batch Loss: 9.904410035233013e-06\n",
      "Epoch 3804, Loss: 0.0011165143878315575, Final Batch Loss: 1.5360214092652313e-05\n",
      "Epoch 3805, Loss: 0.00017493927225586958, Final Batch Loss: 0.0001071011065505445\n",
      "Epoch 3806, Loss: 0.0001392478084198956, Final Batch Loss: 5.706791125703603e-05\n",
      "Epoch 3807, Loss: 0.00017439473549529794, Final Batch Loss: 0.00012423371663317084\n",
      "Epoch 3808, Loss: 0.0006110644790169317, Final Batch Loss: 0.00039870190084911883\n",
      "Epoch 3809, Loss: 0.020096476378967054, Final Batch Loss: 0.0005237020086497068\n",
      "Epoch 3810, Loss: 0.002204519745646394, Final Batch Loss: 0.0020551288034766912\n",
      "Epoch 3811, Loss: 0.002948449468021863, Final Batch Loss: 4.983356484444812e-05\n",
      "Epoch 3812, Loss: 0.0012331926845945418, Final Batch Loss: 0.0006940535386092961\n",
      "Epoch 3813, Loss: 0.0018597322014102247, Final Batch Loss: 1.6862588381627575e-05\n",
      "Epoch 3814, Loss: 0.0007543850515503436, Final Batch Loss: 4.599919338943437e-05\n",
      "Epoch 3815, Loss: 0.0008033082167457906, Final Batch Loss: 0.00010506023681955412\n",
      "Epoch 3816, Loss: 0.004726814164314419, Final Batch Loss: 0.004646784160286188\n",
      "Epoch 3817, Loss: 0.0006424467956094304, Final Batch Loss: 0.0004419421893544495\n",
      "Epoch 3818, Loss: 0.0012307628508096968, Final Batch Loss: 0.0011320316698402166\n",
      "Epoch 3819, Loss: 0.0008990970254671993, Final Batch Loss: 6.589486019947799e-06\n",
      "Epoch 3820, Loss: 0.0017006284554099693, Final Batch Loss: 2.3452823825209634e-06\n",
      "Epoch 3821, Loss: 0.00028903990823891945, Final Batch Loss: 3.0979983876022743e-06\n",
      "Epoch 3822, Loss: 0.0009565070940880105, Final Batch Loss: 0.00012961421452928334\n",
      "Epoch 3823, Loss: 0.0014804866286795004, Final Batch Loss: 1.0140457561647054e-05\n",
      "Epoch 3824, Loss: 0.0001761777421052102, Final Batch Loss: 1.5781646652612835e-05\n",
      "Epoch 3825, Loss: 0.0021820404381287517, Final Batch Loss: 0.00036710459971800447\n",
      "Epoch 3826, Loss: 0.00011981090847257292, Final Batch Loss: 1.210332993650809e-05\n",
      "Epoch 3827, Loss: 0.00020972510810679523, Final Batch Loss: 0.00016434123972430825\n",
      "Epoch 3828, Loss: 0.00027773163719757576, Final Batch Loss: 0.0001512942253611982\n",
      "Epoch 3829, Loss: 0.001697291423624847, Final Batch Loss: 0.00035534254857338965\n",
      "Epoch 3830, Loss: 0.0010436645807203604, Final Batch Loss: 1.4424002074520104e-05\n",
      "Epoch 3831, Loss: 0.0005261315864117933, Final Batch Loss: 0.0002997303381562233\n",
      "Epoch 3832, Loss: 0.00035355410182091873, Final Batch Loss: 9.84034068096662e-06\n",
      "Epoch 3833, Loss: 6.665438013442326e-05, Final Batch Loss: 2.7467063773656264e-05\n",
      "Epoch 3834, Loss: 0.00018897504969572765, Final Batch Loss: 5.818239060317865e-06\n",
      "Epoch 3835, Loss: 0.00013290395509102382, Final Batch Loss: 6.143665814306587e-06\n",
      "Epoch 3836, Loss: 0.010404937809653347, Final Batch Loss: 1.4455918972089421e-05\n",
      "Epoch 3837, Loss: 0.00018107722189597553, Final Batch Loss: 1.1522205568326171e-05\n",
      "Epoch 3838, Loss: 0.0001643077944208926, Final Batch Loss: 1.0761309567897115e-06\n",
      "Epoch 3839, Loss: 0.0001025936439873476, Final Batch Loss: 6.3788120314711705e-06\n",
      "Epoch 3840, Loss: 0.0009929337975336239, Final Batch Loss: 6.133068382041529e-05\n",
      "Epoch 3841, Loss: 0.0005313414822012419, Final Batch Loss: 0.00028152146842330694\n",
      "Epoch 3842, Loss: 0.0011834202077807277, Final Batch Loss: 0.0009248617570847273\n",
      "Epoch 3843, Loss: 0.0010462854770594276, Final Batch Loss: 0.00015185153461061418\n",
      "Epoch 3844, Loss: 0.0005911046973778866, Final Batch Loss: 7.421927148243412e-05\n",
      "Epoch 3845, Loss: 0.0003790931841649581, Final Batch Loss: 3.547515007085167e-05\n",
      "Epoch 3846, Loss: 0.006922242988366634, Final Batch Loss: 0.00012443616287782788\n",
      "Epoch 3847, Loss: 0.0001978561940632062, Final Batch Loss: 4.5118449634173885e-05\n",
      "Epoch 3848, Loss: 0.00028767561980203027, Final Batch Loss: 1.129934116761433e-05\n",
      "Epoch 3849, Loss: 0.00013714137730858056, Final Batch Loss: 9.710366612125654e-06\n",
      "Epoch 3850, Loss: 0.0017347836965200258, Final Batch Loss: 5.341600990504958e-05\n",
      "Epoch 3851, Loss: 0.0007080037280502438, Final Batch Loss: 0.0006563809001818299\n",
      "Epoch 3852, Loss: 3.8766097986808745e-05, Final Batch Loss: 6.987240794842364e-06\n",
      "Epoch 3853, Loss: 0.0008093257110886043, Final Batch Loss: 8.177717973012477e-06\n",
      "Epoch 3854, Loss: 0.0005781177642347757, Final Batch Loss: 7.047739927656949e-05\n",
      "Epoch 3855, Loss: 0.0006238200990082987, Final Batch Loss: 1.4569995073543396e-05\n",
      "Epoch 3856, Loss: 0.00013147010940883774, Final Batch Loss: 4.7811863623792306e-05\n",
      "Epoch 3857, Loss: 0.0004573176506710297, Final Batch Loss: 7.717160769971088e-05\n",
      "Epoch 3858, Loss: 0.0003902014100276574, Final Batch Loss: 0.00014995790843386203\n",
      "Epoch 3859, Loss: 0.00011585330412344774, Final Batch Loss: 9.734265404404141e-06\n",
      "Epoch 3860, Loss: 0.0011204404604541196, Final Batch Loss: 4.245263426128076e-06\n",
      "Epoch 3861, Loss: 0.0013061580721114296, Final Batch Loss: 0.00033666641684249043\n",
      "Epoch 3862, Loss: 0.0004786938261531759, Final Batch Loss: 1.803196755645331e-05\n",
      "Epoch 3863, Loss: 0.0005565639658016153, Final Batch Loss: 1.6255427908618003e-05\n",
      "Epoch 3864, Loss: 0.00031836572588872514, Final Batch Loss: 6.136884167062817e-06\n",
      "Epoch 3865, Loss: 0.00011256948300797376, Final Batch Loss: 3.7680805689888075e-05\n",
      "Epoch 3866, Loss: 0.00010012023676608806, Final Batch Loss: 2.8805034162360243e-05\n",
      "Epoch 3867, Loss: 0.00047640691491324105, Final Batch Loss: 0.000401943048927933\n",
      "Epoch 3868, Loss: 0.005398446999720363, Final Batch Loss: 7.775190169923007e-06\n",
      "Epoch 3869, Loss: 0.00010565723823674489, Final Batch Loss: 1.7436059351894073e-05\n",
      "Epoch 3870, Loss: 0.000861959863868833, Final Batch Loss: 0.0004887770628556609\n",
      "Epoch 3871, Loss: 0.0013751779333688319, Final Batch Loss: 0.00028191262390464544\n",
      "Epoch 3872, Loss: 0.004863529502472375, Final Batch Loss: 0.00015006924513727427\n",
      "Epoch 3873, Loss: 0.00015902572067716392, Final Batch Loss: 6.503710756078362e-05\n",
      "Epoch 3874, Loss: 0.032292988211338525, Final Batch Loss: 2.6918549338006414e-05\n",
      "Epoch 3875, Loss: 0.0012874974654550897, Final Batch Loss: 2.95774207188515e-05\n",
      "Epoch 3876, Loss: 0.0006758066574548138, Final Batch Loss: 0.00028585956897586584\n",
      "Epoch 3877, Loss: 0.0006589707772945985, Final Batch Loss: 8.698899910086766e-05\n",
      "Epoch 3878, Loss: 0.0015580609688186087, Final Batch Loss: 5.404821058618836e-05\n",
      "Epoch 3879, Loss: 0.003350830751514877, Final Batch Loss: 0.0026794709265232086\n",
      "Epoch 3880, Loss: 0.000507680611917749, Final Batch Loss: 3.461753294686787e-05\n",
      "Epoch 3881, Loss: 0.003966110874898732, Final Batch Loss: 0.003788260044530034\n",
      "Epoch 3882, Loss: 0.00035132305856677704, Final Batch Loss: 0.0003004276950377971\n",
      "Epoch 3883, Loss: 0.00029049766635580454, Final Batch Loss: 1.7616608602111228e-05\n",
      "Epoch 3884, Loss: 0.000427184841100825, Final Batch Loss: 0.0002542340662330389\n",
      "Epoch 3885, Loss: 0.0001923979234561557, Final Batch Loss: 1.63441218319349e-05\n",
      "Epoch 3886, Loss: 0.0001485703105572611, Final Batch Loss: 4.6742479753447697e-05\n",
      "Epoch 3887, Loss: 6.078719889046624e-05, Final Batch Loss: 1.738457831379492e-05\n",
      "Epoch 3888, Loss: 0.0007707371405558661, Final Batch Loss: 0.0005753054865635931\n",
      "Epoch 3889, Loss: 0.0007331173183047213, Final Batch Loss: 0.00032741075847297907\n",
      "Epoch 3890, Loss: 0.00011305750558676664, Final Batch Loss: 3.0488145057461224e-05\n",
      "Epoch 3891, Loss: 0.00016859124843904283, Final Batch Loss: 2.273363497806713e-05\n",
      "Epoch 3892, Loss: 9.122789697357803e-05, Final Batch Loss: 5.97585813011392e-06\n",
      "Epoch 3893, Loss: 0.00024243585153271852, Final Batch Loss: 1.4684435882372782e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3894, Loss: 0.00033129072789961356, Final Batch Loss: 1.253973096027039e-05\n",
      "Epoch 3895, Loss: 0.0003733651401489624, Final Batch Loss: 8.464544407615904e-06\n",
      "Epoch 3896, Loss: 0.00037555589915427845, Final Batch Loss: 0.00023960946418810636\n",
      "Epoch 3897, Loss: 0.001073071613063803, Final Batch Loss: 0.00033721295767463744\n",
      "Epoch 3898, Loss: 0.00019469988910714164, Final Batch Loss: 9.897989002638496e-06\n",
      "Epoch 3899, Loss: 0.0005129110732013942, Final Batch Loss: 1.7469194062869065e-05\n",
      "Epoch 3900, Loss: 0.06512742007907946, Final Batch Loss: 0.06451959162950516\n",
      "Epoch 3901, Loss: 0.017401776087353937, Final Batch Loss: 0.017107905820012093\n",
      "Epoch 3902, Loss: 0.0017733531603880692, Final Batch Loss: 0.00012193567090434954\n",
      "Epoch 3903, Loss: 0.008725054503884166, Final Batch Loss: 0.0012110427487641573\n",
      "Epoch 3904, Loss: 0.01393273615030921, Final Batch Loss: 0.00022554372844751924\n",
      "Epoch 3905, Loss: 0.0025621694803703576, Final Batch Loss: 0.0007553986506536603\n",
      "Epoch 3906, Loss: 0.03340739486156963, Final Batch Loss: 0.00012483926548156887\n",
      "Epoch 3907, Loss: 0.001482708175899461, Final Batch Loss: 0.00018095370614901185\n",
      "Epoch 3908, Loss: 0.0005755355959990993, Final Batch Loss: 2.9664573958143592e-05\n",
      "Epoch 3909, Loss: 0.0006462986348196864, Final Batch Loss: 0.0002623616310302168\n",
      "Epoch 3910, Loss: 0.023074870434356853, Final Batch Loss: 0.02138817496597767\n",
      "Epoch 3911, Loss: 0.0006872307494631968, Final Batch Loss: 0.00048451751354150474\n",
      "Epoch 3912, Loss: 0.0018927325691038277, Final Batch Loss: 0.0014967055758461356\n",
      "Epoch 3913, Loss: 0.0008800242831057403, Final Batch Loss: 0.0007566770073026419\n",
      "Epoch 3914, Loss: 0.0032317790610250086, Final Batch Loss: 0.0012717340141534805\n",
      "Epoch 3915, Loss: 0.0003963594754168298, Final Batch Loss: 8.081173291429877e-05\n",
      "Epoch 3916, Loss: 0.001866650911324541, Final Batch Loss: 0.00062669807812199\n",
      "Epoch 3917, Loss: 0.0005788774951724918, Final Batch Loss: 1.82773255801294e-05\n",
      "Epoch 3918, Loss: 0.00026747189440357033, Final Batch Loss: 8.705245272722095e-05\n",
      "Epoch 3919, Loss: 0.0006923100909261848, Final Batch Loss: 1.2113810043956619e-05\n",
      "Epoch 3920, Loss: 0.0006615126931137638, Final Batch Loss: 1.4942645975679625e-05\n",
      "Epoch 3921, Loss: 0.0003409501323403674, Final Batch Loss: 3.391201971680857e-05\n",
      "Epoch 3922, Loss: 0.0002745700621744618, Final Batch Loss: 1.526471896795556e-05\n",
      "Epoch 3923, Loss: 0.003672346217172162, Final Batch Loss: 0.0035938555374741554\n",
      "Epoch 3924, Loss: 0.0008518445793015417, Final Batch Loss: 2.1618136088363826e-05\n",
      "Epoch 3925, Loss: 0.0025845541458693333, Final Batch Loss: 0.00213466864079237\n",
      "Epoch 3926, Loss: 0.0003120667788607534, Final Batch Loss: 5.4463554988615215e-05\n",
      "Epoch 3927, Loss: 0.005949028511167853, Final Batch Loss: 2.7397427402320318e-05\n",
      "Epoch 3928, Loss: 0.0005980376718071057, Final Batch Loss: 2.4987466531456448e-05\n",
      "Epoch 3929, Loss: 0.00019735861314984504, Final Batch Loss: 2.641727951413486e-05\n",
      "Epoch 3930, Loss: 0.002369959438510705, Final Batch Loss: 0.0003689429722726345\n",
      "Epoch 3931, Loss: 0.00033929478922800627, Final Batch Loss: 0.00019000505562871695\n",
      "Epoch 3932, Loss: 0.0009407721081515774, Final Batch Loss: 0.00022672780323773623\n",
      "Epoch 3933, Loss: 0.0003427267074584961, Final Batch Loss: 0.00016619892267044634\n",
      "Epoch 3934, Loss: 0.0005630922348700551, Final Batch Loss: 2.656484639373957e-06\n",
      "Epoch 3935, Loss: 0.00014219684635463636, Final Batch Loss: 0.00011366786202415824\n",
      "Epoch 3936, Loss: 0.00025501551954221213, Final Batch Loss: 4.542943861451931e-05\n",
      "Epoch 3937, Loss: 0.017561847547767684, Final Batch Loss: 2.7294063329463825e-05\n",
      "Epoch 3938, Loss: 0.00033640886067587417, Final Batch Loss: 1.9019456885871477e-05\n",
      "Epoch 3939, Loss: 0.00043356965397833847, Final Batch Loss: 8.992082257464062e-06\n",
      "Epoch 3940, Loss: 0.00037559076713478134, Final Batch Loss: 5.621378295472823e-05\n",
      "Epoch 3941, Loss: 0.000295202735287603, Final Batch Loss: 9.99903422780335e-05\n",
      "Epoch 3942, Loss: 0.0017337955453058385, Final Batch Loss: 1.9629026155598694e-06\n",
      "Epoch 3943, Loss: 0.00013324479050424998, Final Batch Loss: 0.00011396946501918137\n",
      "Epoch 3944, Loss: 0.060446935110576305, Final Batch Loss: 3.534714414854534e-05\n",
      "Epoch 3945, Loss: 0.0004541201910797099, Final Batch Loss: 0.0004066831897944212\n",
      "Epoch 3946, Loss: 0.00015552546892649843, Final Batch Loss: 5.095390406495426e-06\n",
      "Epoch 3947, Loss: 0.0002970779714814853, Final Batch Loss: 7.579843804705888e-05\n",
      "Epoch 3948, Loss: 0.00026958994385495316, Final Batch Loss: 0.00016745094035286456\n",
      "Epoch 3949, Loss: 0.0007293091794053908, Final Batch Loss: 2.240914909634739e-05\n",
      "Epoch 3950, Loss: 0.008981235170722357, Final Batch Loss: 1.7693304471322335e-05\n",
      "Epoch 3951, Loss: 0.0001228454357260489, Final Batch Loss: 1.260589124285616e-05\n",
      "Epoch 3952, Loss: 0.031762392396558425, Final Batch Loss: 1.202953171741683e-05\n",
      "Epoch 3953, Loss: 0.00280552232629816, Final Batch Loss: 3.2888672194530955e-06\n",
      "Epoch 3954, Loss: 0.0016849877556524007, Final Batch Loss: 3.8855265302117914e-05\n",
      "Epoch 3955, Loss: 0.0006474117290053982, Final Batch Loss: 0.0003084507479798049\n",
      "Epoch 3956, Loss: 0.0004006820199720096, Final Batch Loss: 0.00025441477191634476\n",
      "Epoch 3957, Loss: 0.0008166271177287854, Final Batch Loss: 7.608486612298293e-06\n",
      "Epoch 3958, Loss: 0.00020002441306132823, Final Batch Loss: 0.00014963634021114558\n",
      "Epoch 3959, Loss: 0.0019016298838323564, Final Batch Loss: 0.001837285002693534\n",
      "Epoch 3960, Loss: 0.0012325498792051803, Final Batch Loss: 0.0008780491189099848\n",
      "Epoch 3961, Loss: 0.0019285833866433677, Final Batch Loss: 8.691656603332376e-07\n",
      "Epoch 3962, Loss: 0.007644293736120744, Final Batch Loss: 8.231549873016775e-05\n",
      "Epoch 3963, Loss: 0.0002757912516244687, Final Batch Loss: 0.00013362281606532633\n",
      "Epoch 3964, Loss: 0.000796750146037084, Final Batch Loss: 7.246670065796934e-06\n",
      "Epoch 3965, Loss: 9.58266989528056e-05, Final Batch Loss: 2.671565880518756e-06\n",
      "Epoch 3966, Loss: 8.113209833027213e-05, Final Batch Loss: 3.915677370969206e-05\n",
      "Epoch 3967, Loss: 0.0012123268988943892, Final Batch Loss: 0.00021291995653882623\n",
      "Epoch 3968, Loss: 0.0001079311214198242, Final Batch Loss: 6.607298564631492e-05\n",
      "Epoch 3969, Loss: 0.0002565923950896831, Final Batch Loss: 8.705121217644773e-06\n",
      "Epoch 3970, Loss: 0.00021246155574772274, Final Batch Loss: 2.6999858164344914e-05\n",
      "Epoch 3971, Loss: 0.0002761969099083217, Final Batch Loss: 6.494812623714097e-06\n",
      "Epoch 3972, Loss: 0.0001221613470079319, Final Batch Loss: 2.3500646420870908e-05\n",
      "Epoch 3973, Loss: 0.0002454389095873921, Final Batch Loss: 4.603833440341987e-05\n",
      "Epoch 3974, Loss: 0.0005968802433926612, Final Batch Loss: 0.0005463716224767268\n",
      "Epoch 3975, Loss: 0.0002858791049220599, Final Batch Loss: 8.074907964328304e-05\n",
      "Epoch 3976, Loss: 0.0008765229681557685, Final Batch Loss: 9.148292883764952e-05\n",
      "Epoch 3977, Loss: 0.00014205032675818074, Final Batch Loss: 3.444538378971629e-05\n",
      "Epoch 3978, Loss: 5.1547903694881825e-05, Final Batch Loss: 4.970150257577188e-06\n",
      "Epoch 3979, Loss: 0.00012069454169250093, Final Batch Loss: 1.5549801901215687e-05\n",
      "Epoch 3980, Loss: 0.00036511233611236094, Final Batch Loss: 7.858067692723125e-05\n",
      "Epoch 3981, Loss: 9.255872373614693e-05, Final Batch Loss: 1.0218275747320149e-05\n",
      "Epoch 3982, Loss: 0.0002085894784613629, Final Batch Loss: 9.991384104068857e-06\n",
      "Epoch 3983, Loss: 0.0011496519136926509, Final Batch Loss: 8.978067489806563e-05\n",
      "Epoch 3984, Loss: 0.0006925887046236312, Final Batch Loss: 2.559008680691477e-05\n",
      "Epoch 3985, Loss: 5.4520872254215647e-05, Final Batch Loss: 1.3871193004888482e-05\n",
      "Epoch 3986, Loss: 0.00024152429341484094, Final Batch Loss: 7.652782187506091e-06\n",
      "Epoch 3987, Loss: 5.572991994995391e-05, Final Batch Loss: 6.12697476753965e-06\n",
      "Epoch 3988, Loss: 9.796216954782722e-05, Final Batch Loss: 7.5946104516333435e-06\n",
      "Epoch 3989, Loss: 0.00014443862391999573, Final Batch Loss: 0.00011652024113573134\n",
      "Epoch 3990, Loss: 0.0011608929441990767, Final Batch Loss: 3.293487316113897e-05\n",
      "Epoch 3991, Loss: 0.00014319561887532473, Final Batch Loss: 1.771894676494412e-05\n",
      "Epoch 3992, Loss: 0.0017414998210369959, Final Batch Loss: 1.119568696594797e-05\n",
      "Epoch 3993, Loss: 0.00011356359391356818, Final Batch Loss: 5.064524884801358e-05\n",
      "Epoch 3994, Loss: 0.00033082992467825534, Final Batch Loss: 1.7730115359881893e-05\n",
      "Epoch 3995, Loss: 0.00014059405111765955, Final Batch Loss: 4.722652738564648e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3996, Loss: 0.00011533291490195552, Final Batch Loss: 8.685780812811572e-06\n",
      "Epoch 3997, Loss: 9.771847999218153e-05, Final Batch Loss: 8.439425982942339e-06\n",
      "Epoch 3998, Loss: 0.005495733752468368, Final Batch Loss: 0.00502269109711051\n",
      "Epoch 3999, Loss: 0.0001166095817097812, Final Batch Loss: 1.4500447832688224e-05\n",
      "Epoch 4000, Loss: 0.00040888296462071594, Final Batch Loss: 9.144985961029306e-05\n",
      "Epoch 4001, Loss: 0.0006850088377632346, Final Batch Loss: 0.0006049178191460669\n",
      "Epoch 4002, Loss: 0.00018009720179179567, Final Batch Loss: 1.1928671483474318e-05\n",
      "Epoch 4003, Loss: 0.021800809205160476, Final Batch Loss: 0.02148931287229061\n",
      "Epoch 4004, Loss: 0.004861906972223551, Final Batch Loss: 7.696045258853701e-07\n",
      "Epoch 4005, Loss: 0.016683849821902186, Final Batch Loss: 1.459940222048317e-06\n",
      "Epoch 4006, Loss: 0.0011766211973736063, Final Batch Loss: 0.00034255351056344807\n",
      "Epoch 4007, Loss: 0.003044001874513924, Final Batch Loss: 0.001082869479432702\n",
      "Epoch 4008, Loss: 0.007595677991048433, Final Batch Loss: 9.014910028781742e-05\n",
      "Epoch 4009, Loss: 0.00029108606941008475, Final Batch Loss: 0.00019469241669867188\n",
      "Epoch 4010, Loss: 0.0009796564154385123, Final Batch Loss: 0.00033868884202092886\n",
      "Epoch 4011, Loss: 0.0008475981976516778, Final Batch Loss: 4.051033829455264e-05\n",
      "Epoch 4012, Loss: 0.00014526458289765287, Final Batch Loss: 8.618068932264578e-06\n",
      "Epoch 4013, Loss: 0.000401710993173765, Final Batch Loss: 1.825537401600741e-05\n",
      "Epoch 4014, Loss: 0.0007789766132191289, Final Batch Loss: 1.76240318978671e-05\n",
      "Epoch 4015, Loss: 0.0008418262277700705, Final Batch Loss: 0.0007204011199064553\n",
      "Epoch 4016, Loss: 0.00031512872919847723, Final Batch Loss: 0.00012363053974695504\n",
      "Epoch 4017, Loss: 0.001136923144258617, Final Batch Loss: 1.3205281902628485e-05\n",
      "Epoch 4018, Loss: 0.00015412719312735135, Final Batch Loss: 7.874471521063242e-06\n",
      "Epoch 4019, Loss: 0.000357671130586823, Final Batch Loss: 6.780545663787052e-05\n",
      "Epoch 4020, Loss: 0.0001669911339376995, Final Batch Loss: 6.580277386092348e-06\n",
      "Epoch 4021, Loss: 0.007011843041254906, Final Batch Loss: 4.80868766317144e-06\n",
      "Epoch 4022, Loss: 0.00030283845489975647, Final Batch Loss: 2.167954789911164e-06\n",
      "Epoch 4023, Loss: 0.0009385569937876426, Final Batch Loss: 0.0003510279639158398\n",
      "Epoch 4024, Loss: 0.0053653564027627, Final Batch Loss: 0.00010445094085298479\n",
      "Epoch 4025, Loss: 0.00898846178461099, Final Batch Loss: 0.005284307524561882\n",
      "Epoch 4026, Loss: 0.001340770266324398, Final Batch Loss: 1.6602405594312586e-05\n",
      "Epoch 4027, Loss: 0.011030520969143254, Final Batch Loss: 0.00038125328137539327\n",
      "Epoch 4028, Loss: 0.0044697428347717505, Final Batch Loss: 5.7090310292551294e-05\n",
      "Epoch 4029, Loss: 0.0012476098745537456, Final Batch Loss: 0.0003391185309737921\n",
      "Epoch 4030, Loss: 0.00044642944430961506, Final Batch Loss: 2.8009659217786975e-05\n",
      "Epoch 4031, Loss: 0.00029689918301301077, Final Batch Loss: 0.00010476798343006521\n",
      "Epoch 4032, Loss: 0.0036886946954837185, Final Batch Loss: 0.0004037081962451339\n",
      "Epoch 4033, Loss: 0.0008416840828431305, Final Batch Loss: 0.0003664036630652845\n",
      "Epoch 4034, Loss: 0.0009032741072587669, Final Batch Loss: 3.842885416815989e-05\n",
      "Epoch 4035, Loss: 0.08214719269381021, Final Batch Loss: 0.08206045627593994\n",
      "Epoch 4036, Loss: 0.0003888663159159478, Final Batch Loss: 0.00015641846403013915\n",
      "Epoch 4037, Loss: 0.005665944188422145, Final Batch Loss: 3.699367425724631e-06\n",
      "Epoch 4038, Loss: 0.0003210505037714029, Final Batch Loss: 9.21805803955067e-06\n",
      "Epoch 4039, Loss: 0.004019067495391937, Final Batch Loss: 0.002397578675299883\n",
      "Epoch 4040, Loss: 0.0019901998193745385, Final Batch Loss: 0.00035672064404934645\n",
      "Epoch 4041, Loss: 0.001098549135349458, Final Batch Loss: 0.0001294340327149257\n",
      "Epoch 4042, Loss: 0.0002395581286691595, Final Batch Loss: 5.1241633627796546e-05\n",
      "Epoch 4043, Loss: 0.01877233355116914, Final Batch Loss: 0.00022971593716647476\n",
      "Epoch 4044, Loss: 0.001625274380785413, Final Batch Loss: 2.24196191993542e-05\n",
      "Epoch 4045, Loss: 0.000680736979120411, Final Batch Loss: 0.00010046599345514551\n",
      "Epoch 4046, Loss: 0.0015263116401911248, Final Batch Loss: 0.00110776093788445\n",
      "Epoch 4047, Loss: 0.029938628309537307, Final Batch Loss: 2.621368366817478e-05\n",
      "Epoch 4048, Loss: 0.0005233042888903583, Final Batch Loss: 0.00046043601469136775\n",
      "Epoch 4049, Loss: 0.00022101952345110476, Final Batch Loss: 2.3450596927432343e-05\n",
      "Epoch 4050, Loss: 0.0007519979026255896, Final Batch Loss: 1.1520774933160283e-05\n",
      "Epoch 4051, Loss: 0.0005479367573570926, Final Batch Loss: 0.00012744084233418107\n",
      "Epoch 4052, Loss: 0.00035845957063429523, Final Batch Loss: 6.7704477260122076e-06\n",
      "Epoch 4053, Loss: 0.00022593843823415227, Final Batch Loss: 6.738810043316334e-05\n",
      "Epoch 4054, Loss: 0.0002882159205910284, Final Batch Loss: 7.354434637818485e-05\n",
      "Epoch 4055, Loss: 0.0008246276120189577, Final Batch Loss: 6.085238783271052e-05\n",
      "Epoch 4056, Loss: 0.0017498808992968407, Final Batch Loss: 5.0700582505669445e-05\n",
      "Epoch 4057, Loss: 0.00019187384532415308, Final Batch Loss: 1.1828546121250838e-05\n",
      "Epoch 4058, Loss: 0.0016151753661688417, Final Batch Loss: 0.0007267866749316454\n",
      "Epoch 4059, Loss: 0.00040915876343206037, Final Batch Loss: 1.0591717000352219e-05\n",
      "Epoch 4060, Loss: 0.000724008355064143, Final Batch Loss: 0.00035131751792505383\n",
      "Epoch 4061, Loss: 0.0005878867668798193, Final Batch Loss: 2.947203211078886e-05\n",
      "Epoch 4062, Loss: 0.0008545719283574726, Final Batch Loss: 0.0004758807481266558\n",
      "Epoch 4063, Loss: 0.0002436216273054015, Final Batch Loss: 5.3499312343774363e-05\n",
      "Epoch 4064, Loss: 0.029087187368531886, Final Batch Loss: 0.02887667715549469\n",
      "Epoch 4065, Loss: 0.0001427720862920978, Final Batch Loss: 6.528449011966586e-05\n",
      "Epoch 4066, Loss: 0.000609103990427684, Final Batch Loss: 5.030706597608514e-05\n",
      "Epoch 4067, Loss: 0.00017132281482190592, Final Batch Loss: 5.5848053307272494e-05\n",
      "Epoch 4068, Loss: 0.0007191610066001886, Final Batch Loss: 0.0004867935786023736\n",
      "Epoch 4069, Loss: 0.013408501392405014, Final Batch Loss: 0.00040952698327600956\n",
      "Epoch 4070, Loss: 0.00889189978261129, Final Batch Loss: 1.520115438324865e-05\n",
      "Epoch 4071, Loss: 0.00029845778226444963, Final Batch Loss: 2.1564395865425467e-05\n",
      "Epoch 4072, Loss: 0.00021287881327225477, Final Batch Loss: 4.89986132379272e-06\n",
      "Epoch 4073, Loss: 0.002729936872583494, Final Batch Loss: 0.00037262096884660423\n",
      "Epoch 4074, Loss: 0.026899109941950883, Final Batch Loss: 0.02658761292695999\n",
      "Epoch 4075, Loss: 0.0002417651267023757, Final Batch Loss: 3.9314483728958294e-05\n",
      "Epoch 4076, Loss: 0.000901599989447277, Final Batch Loss: 0.0003548012755345553\n",
      "Epoch 4077, Loss: 0.0016866805090103298, Final Batch Loss: 0.001242034020833671\n",
      "Epoch 4078, Loss: 0.05362978943685448, Final Batch Loss: 1.0721888429543469e-05\n",
      "Epoch 4079, Loss: 0.0006575948482350213, Final Batch Loss: 0.00019240511755924672\n",
      "Epoch 4080, Loss: 0.0006441198474931298, Final Batch Loss: 0.00021060752624180168\n",
      "Epoch 4081, Loss: 0.0009964689561456908, Final Batch Loss: 0.0008392829331569374\n",
      "Epoch 4082, Loss: 0.00048142466039280407, Final Batch Loss: 5.166180926607922e-05\n",
      "Epoch 4083, Loss: 0.0006879782158648595, Final Batch Loss: 3.118104359600693e-05\n",
      "Epoch 4084, Loss: 0.002686940188141307, Final Batch Loss: 0.00020138021500315517\n",
      "Epoch 4085, Loss: 0.000657089680316858, Final Batch Loss: 0.0002146995102521032\n",
      "Epoch 4086, Loss: 0.00022612629345530877, Final Batch Loss: 4.441726196091622e-05\n",
      "Epoch 4087, Loss: 0.0008924919093260542, Final Batch Loss: 4.509709106059745e-05\n",
      "Epoch 4088, Loss: 0.0004274326747690793, Final Batch Loss: 5.26400217495393e-05\n",
      "Epoch 4089, Loss: 0.00048099800551426597, Final Batch Loss: 7.500409992644563e-05\n",
      "Epoch 4090, Loss: 0.0010622370464261621, Final Batch Loss: 0.0006383851286955178\n",
      "Epoch 4091, Loss: 0.00042081707579200156, Final Batch Loss: 5.217351281316951e-05\n",
      "Epoch 4092, Loss: 0.0003078485515288776, Final Batch Loss: 5.877299918211065e-05\n",
      "Epoch 4093, Loss: 0.00022910517691343557, Final Batch Loss: 8.272404375020415e-05\n",
      "Epoch 4094, Loss: 0.001983959893550491, Final Batch Loss: 0.00021403581195045263\n",
      "Epoch 4095, Loss: 0.00043940833711531013, Final Batch Loss: 0.000161823452799581\n",
      "Epoch 4096, Loss: 0.000970411016169237, Final Batch Loss: 0.0007897058967500925\n",
      "Epoch 4097, Loss: 0.00041083509313466493, Final Batch Loss: 1.8153665223508142e-05\n",
      "Epoch 4098, Loss: 0.0007677851608605124, Final Batch Loss: 0.00011104700388386846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4099, Loss: 0.0003315834578643262, Final Batch Loss: 0.0001425286172889173\n",
      "Epoch 4100, Loss: 0.00028803460008930415, Final Batch Loss: 2.93159500870388e-05\n",
      "Epoch 4101, Loss: 0.0001208542716994998, Final Batch Loss: 8.165648068825249e-06\n",
      "Epoch 4102, Loss: 0.0005562158839893527, Final Batch Loss: 8.458277443423867e-05\n",
      "Epoch 4103, Loss: 0.0004987236316082999, Final Batch Loss: 8.807899575913325e-05\n",
      "Epoch 4104, Loss: 0.0022340245495797717, Final Batch Loss: 8.069527211773675e-06\n",
      "Epoch 4105, Loss: 0.0006633815992245218, Final Batch Loss: 5.671956023434177e-05\n",
      "Epoch 4106, Loss: 0.0006802763236919418, Final Batch Loss: 0.00024999305605888367\n",
      "Epoch 4107, Loss: 0.0006259092606342165, Final Batch Loss: 1.0798807124956511e-05\n",
      "Epoch 4108, Loss: 0.00013613038117910037, Final Batch Loss: 4.477141555980779e-05\n",
      "Epoch 4109, Loss: 0.00024745505061218864, Final Batch Loss: 1.3522504559659865e-05\n",
      "Epoch 4110, Loss: 0.0004465107676878688, Final Batch Loss: 7.980136615515221e-06\n",
      "Epoch 4111, Loss: 0.0008399993389502924, Final Batch Loss: 0.0003971574187744409\n",
      "Epoch 4112, Loss: 0.00010915354323515203, Final Batch Loss: 2.8484769245551433e-06\n",
      "Epoch 4113, Loss: 0.00014643102622358128, Final Batch Loss: 3.883766839862801e-05\n",
      "Epoch 4114, Loss: 0.0006099809288571123, Final Batch Loss: 4.33812674600631e-05\n",
      "Epoch 4115, Loss: 0.009599680837709457, Final Batch Loss: 6.640665378654376e-05\n",
      "Epoch 4116, Loss: 0.007102839600065636, Final Batch Loss: 0.0004512487503234297\n",
      "Epoch 4117, Loss: 0.0010525798152229981, Final Batch Loss: 0.0008847946883179247\n",
      "Epoch 4118, Loss: 0.005044231467763893, Final Batch Loss: 4.3220556108281016e-05\n",
      "Epoch 4119, Loss: 0.00012119575512770098, Final Batch Loss: 1.2403905202518217e-05\n",
      "Epoch 4120, Loss: 0.0005351042836991837, Final Batch Loss: 0.00010210072650806978\n",
      "Epoch 4121, Loss: 0.001233953275004751, Final Batch Loss: 3.1185041734715924e-05\n",
      "Epoch 4122, Loss: 0.0006687004461127799, Final Batch Loss: 3.598825423978269e-05\n",
      "Epoch 4123, Loss: 0.001058455072779907, Final Batch Loss: 0.0004580190288834274\n",
      "Epoch 4124, Loss: 0.0003784980763157364, Final Batch Loss: 3.8728459912817925e-05\n",
      "Epoch 4125, Loss: 0.00019015873658645432, Final Batch Loss: 6.862304144306108e-05\n",
      "Epoch 4126, Loss: 0.01462865479697939, Final Batch Loss: 0.0009397727553732693\n",
      "Epoch 4127, Loss: 0.0011070517657572054, Final Batch Loss: 0.00036758306669071317\n",
      "Epoch 4128, Loss: 0.001995804160287662, Final Batch Loss: 0.00019795809930656105\n",
      "Epoch 4129, Loss: 0.012449296093109297, Final Batch Loss: 0.0018552436958998442\n",
      "Epoch 4130, Loss: 0.0011782229848904535, Final Batch Loss: 7.217901293188334e-05\n",
      "Epoch 4131, Loss: 0.00023683442577748792, Final Batch Loss: 5.82890170335304e-05\n",
      "Epoch 4132, Loss: 0.0010705006352509372, Final Batch Loss: 0.0009024616447277367\n",
      "Epoch 4133, Loss: 0.00048785534090711735, Final Batch Loss: 1.4572075997421052e-05\n",
      "Epoch 4134, Loss: 0.00044974931006436236, Final Batch Loss: 4.3328236642992124e-05\n",
      "Epoch 4135, Loss: 0.0004643987922463566, Final Batch Loss: 0.00016734930977690965\n",
      "Epoch 4136, Loss: 0.00021819539188072667, Final Batch Loss: 5.147437332198024e-05\n",
      "Epoch 4137, Loss: 0.00047408786304004025, Final Batch Loss: 0.0001098697684938088\n",
      "Epoch 4138, Loss: 0.0003489373275442631, Final Batch Loss: 3.128574462607503e-05\n",
      "Epoch 4139, Loss: 0.0007334418746722804, Final Batch Loss: 3.35072836605832e-05\n",
      "Epoch 4140, Loss: 0.03954992169747129, Final Batch Loss: 0.0013972923625260592\n",
      "Epoch 4141, Loss: 0.0003283119913248811, Final Batch Loss: 5.93754775763955e-05\n",
      "Epoch 4142, Loss: 0.0004985102605132852, Final Batch Loss: 2.389233122812584e-05\n",
      "Epoch 4143, Loss: 0.00026180091026617447, Final Batch Loss: 8.235342647822108e-06\n",
      "Epoch 4144, Loss: 0.01446804657643952, Final Batch Loss: 1.887019789137412e-05\n",
      "Epoch 4145, Loss: 0.0010397680471214699, Final Batch Loss: 2.5571518563083373e-05\n",
      "Epoch 4146, Loss: 0.0006101108738221228, Final Batch Loss: 0.00034468932426534593\n",
      "Epoch 4147, Loss: 0.00044789371895603836, Final Batch Loss: 6.66201303829439e-05\n",
      "Epoch 4148, Loss: 0.0011238997758482583, Final Batch Loss: 0.0008643287001177669\n",
      "Epoch 4149, Loss: 0.001727768404634844, Final Batch Loss: 0.0011608456261456013\n",
      "Epoch 4150, Loss: 0.0005016826362407301, Final Batch Loss: 3.423858652240597e-05\n",
      "Epoch 4151, Loss: 0.003737723969607032, Final Batch Loss: 0.003596562659367919\n",
      "Epoch 4152, Loss: 0.0009232697648258181, Final Batch Loss: 5.2382758440217e-05\n",
      "Epoch 4153, Loss: 0.00033196472577401437, Final Batch Loss: 9.277720528189093e-05\n",
      "Epoch 4154, Loss: 0.0005766147314716363, Final Batch Loss: 3.677556014736183e-05\n",
      "Epoch 4155, Loss: 0.00022320493962979526, Final Batch Loss: 4.6100292820483446e-05\n",
      "Epoch 4156, Loss: 0.00015369716493296437, Final Batch Loss: 2.5784025638131425e-05\n",
      "Epoch 4157, Loss: 0.0016833357631185208, Final Batch Loss: 0.001129562733694911\n",
      "Epoch 4158, Loss: 0.0008177767231245525, Final Batch Loss: 7.48801976442337e-05\n",
      "Epoch 4159, Loss: 0.0013604499836219475, Final Batch Loss: 0.0002483904536347836\n",
      "Epoch 4160, Loss: 0.0016098376217996702, Final Batch Loss: 9.437370317755267e-05\n",
      "Epoch 4161, Loss: 0.0006598269028472714, Final Batch Loss: 9.158271132037044e-05\n",
      "Epoch 4162, Loss: 0.00029774951144645456, Final Batch Loss: 2.341236722713802e-05\n",
      "Epoch 4163, Loss: 0.026419163645186927, Final Batch Loss: 0.00036478196852840483\n",
      "Epoch 4164, Loss: 0.0015601868399244267, Final Batch Loss: 1.8085100236930884e-05\n",
      "Epoch 4165, Loss: 0.000543880472832825, Final Batch Loss: 8.138592238537967e-05\n",
      "Epoch 4166, Loss: 0.0002531743793952046, Final Batch Loss: 1.5933577742544003e-05\n",
      "Epoch 4167, Loss: 0.0005494228726092842, Final Batch Loss: 0.00021361508697737008\n",
      "Epoch 4168, Loss: 0.00033454455297032837, Final Batch Loss: 9.463183960178867e-05\n",
      "Epoch 4169, Loss: 0.00023716995201539248, Final Batch Loss: 2.0850065993727185e-05\n",
      "Epoch 4170, Loss: 0.0001743373886711197, Final Batch Loss: 4.995347262592986e-05\n",
      "Epoch 4171, Loss: 0.002574835398263531, Final Batch Loss: 0.0002690282999537885\n",
      "Epoch 4172, Loss: 0.0003623775146479602, Final Batch Loss: 4.0110418922267854e-05\n",
      "Epoch 4173, Loss: 0.00026975896253134124, Final Batch Loss: 2.245569703518413e-05\n",
      "Epoch 4174, Loss: 0.00017448845119361067, Final Batch Loss: 1.1013714356522541e-05\n",
      "Epoch 4175, Loss: 0.0016990874210023321, Final Batch Loss: 5.4337640904122964e-05\n",
      "Epoch 4176, Loss: 0.00017753729753167136, Final Batch Loss: 0.00013251193740870804\n",
      "Epoch 4177, Loss: 0.0014557184513250832, Final Batch Loss: 1.8852399080060422e-05\n",
      "Epoch 4178, Loss: 0.0005458509585878346, Final Batch Loss: 1.0358653526054695e-05\n",
      "Epoch 4179, Loss: 0.013527517252441612, Final Batch Loss: 1.9374629118829034e-05\n",
      "Epoch 4180, Loss: 0.0006791198338760296, Final Batch Loss: 0.0002302278153365478\n",
      "Epoch 4181, Loss: 0.008467713887512218, Final Batch Loss: 0.00013088295236229897\n",
      "Epoch 4182, Loss: 0.0022966344986343756, Final Batch Loss: 8.773365698289126e-05\n",
      "Epoch 4183, Loss: 0.0034384557975499774, Final Batch Loss: 1.1932136658288073e-05\n",
      "Epoch 4184, Loss: 0.007566992362626479, Final Batch Loss: 0.0022891368716955185\n",
      "Epoch 4185, Loss: 0.0008381227889913134, Final Batch Loss: 0.0003800459671765566\n",
      "Epoch 4186, Loss: 0.0005937930036452599, Final Batch Loss: 1.204193540615961e-05\n",
      "Epoch 4187, Loss: 0.0008647254053357756, Final Batch Loss: 0.0006196211907081306\n",
      "Epoch 4188, Loss: 0.0002596820322651183, Final Batch Loss: 0.0001476226607337594\n",
      "Epoch 4189, Loss: 0.00034503459573898, Final Batch Loss: 9.886914631351829e-05\n",
      "Epoch 4190, Loss: 0.0023966061125975102, Final Batch Loss: 7.591838948428631e-05\n",
      "Epoch 4191, Loss: 0.00021114616538397968, Final Batch Loss: 9.414566738996655e-05\n",
      "Epoch 4192, Loss: 0.000666518283651385, Final Batch Loss: 3.316135553177446e-05\n",
      "Epoch 4193, Loss: 0.0005416066669567954, Final Batch Loss: 0.00010655439837137237\n",
      "Epoch 4194, Loss: 0.0003521542967064306, Final Batch Loss: 0.00010980564547935501\n",
      "Epoch 4195, Loss: 0.00018271412045578472, Final Batch Loss: 2.7620320906862617e-05\n",
      "Epoch 4196, Loss: 0.00101109219576756, Final Batch Loss: 0.0002573903475422412\n",
      "Epoch 4197, Loss: 0.0002185300072596874, Final Batch Loss: 2.436607246636413e-05\n",
      "Epoch 4198, Loss: 0.0005838433398821508, Final Batch Loss: 0.0002678098971955478\n",
      "Epoch 4199, Loss: 0.0005263893690425903, Final Batch Loss: 0.00017301416664849967\n",
      "Epoch 4200, Loss: 0.0002213001462223474, Final Batch Loss: 4.5651519030798227e-05\n",
      "Epoch 4201, Loss: 0.0008488686862619943, Final Batch Loss: 1.3129446415405255e-05\n",
      "Epoch 4202, Loss: 0.0002493438046258234, Final Batch Loss: 0.00019383242761250585\n",
      "Epoch 4203, Loss: 0.00011370696574886097, Final Batch Loss: 3.587696119211614e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4204, Loss: 7.41592875783681e-05, Final Batch Loss: 6.394722277036635e-06\n",
      "Epoch 4205, Loss: 0.00028121285595261725, Final Batch Loss: 6.28898196737282e-05\n",
      "Epoch 4206, Loss: 0.0004834672390643391, Final Batch Loss: 0.0003789766924455762\n",
      "Epoch 4207, Loss: 0.00016041162280089338, Final Batch Loss: 5.554927156481426e-06\n",
      "Epoch 4208, Loss: 0.0005168839779798873, Final Batch Loss: 0.0003873964597005397\n",
      "Epoch 4209, Loss: 0.00019600325413193787, Final Batch Loss: 6.153233698569238e-05\n",
      "Epoch 4210, Loss: 0.0005953818363195751, Final Batch Loss: 0.00026511793839745224\n",
      "Epoch 4211, Loss: 0.004524021542238188, Final Batch Loss: 0.0044064088724553585\n",
      "Epoch 4212, Loss: 0.0020831196397921303, Final Batch Loss: 0.00036695567541755736\n",
      "Epoch 4213, Loss: 0.0001280186834264896, Final Batch Loss: 9.98748691927176e-06\n",
      "Epoch 4214, Loss: 0.00019458915085124318, Final Batch Loss: 4.693823211709969e-05\n",
      "Epoch 4215, Loss: 8.234630558945355e-05, Final Batch Loss: 1.1314272342133336e-05\n",
      "Epoch 4216, Loss: 0.0020129466047364986, Final Batch Loss: 4.615656507667154e-05\n",
      "Epoch 4217, Loss: 0.0007063695993565489, Final Batch Loss: 2.0401908841449767e-05\n",
      "Epoch 4218, Loss: 0.00037073833709655446, Final Batch Loss: 2.6255844204570167e-05\n",
      "Epoch 4219, Loss: 0.00026355449699622113, Final Batch Loss: 3.362500137882307e-06\n",
      "Epoch 4220, Loss: 0.0009079328865482239, Final Batch Loss: 1.863203760876786e-05\n",
      "Epoch 4221, Loss: 0.00016635240353934933, Final Batch Loss: 1.854553738667164e-05\n",
      "Epoch 4222, Loss: 0.0009995391901611583, Final Batch Loss: 0.0003864099853672087\n",
      "Epoch 4223, Loss: 0.00020069813615464227, Final Batch Loss: 1.1894302360815345e-06\n",
      "Epoch 4224, Loss: 0.0002757202846623841, Final Batch Loss: 3.773794560402166e-06\n",
      "Epoch 4225, Loss: 0.00020043465428898344, Final Batch Loss: 8.28532429295592e-05\n",
      "Epoch 4226, Loss: 0.0001713842029857915, Final Batch Loss: 7.001986523391679e-05\n",
      "Epoch 4227, Loss: 0.00010013246128437459, Final Batch Loss: 5.645887085847789e-06\n",
      "Epoch 4228, Loss: 0.0005969716266918113, Final Batch Loss: 5.53989866602933e-06\n",
      "Epoch 4229, Loss: 0.00046233374132498284, Final Batch Loss: 0.0003727741714101285\n",
      "Epoch 4230, Loss: 0.00026059891933982726, Final Batch Loss: 0.00020819276687689126\n",
      "Epoch 4231, Loss: 0.0004558585187623976, Final Batch Loss: 1.159752173407469e-05\n",
      "Epoch 4232, Loss: 0.0003115393756161211, Final Batch Loss: 0.0001698951964499429\n",
      "Epoch 4233, Loss: 0.00011399053255445324, Final Batch Loss: 3.323628334328532e-05\n",
      "Epoch 4234, Loss: 0.0003478204580460442, Final Batch Loss: 0.00024435389786958694\n",
      "Epoch 4235, Loss: 0.0002608707559375034, Final Batch Loss: 6.81862875353545e-05\n",
      "Epoch 4236, Loss: 0.00010433910483698128, Final Batch Loss: 1.044660803017905e-05\n",
      "Epoch 4237, Loss: 0.0016393383762078884, Final Batch Loss: 4.161616743658669e-06\n",
      "Epoch 4238, Loss: 0.00012239279180903395, Final Batch Loss: 6.460329313995317e-05\n",
      "Epoch 4239, Loss: 0.00016086528648884268, Final Batch Loss: 1.6802374375401996e-05\n",
      "Epoch 4240, Loss: 0.000675232409776072, Final Batch Loss: 0.000592513126321137\n",
      "Epoch 4241, Loss: 0.00010249212573398836, Final Batch Loss: 1.2601375601661857e-05\n",
      "Epoch 4242, Loss: 0.00010936471790046198, Final Batch Loss: 5.5655759751971345e-06\n",
      "Epoch 4243, Loss: 0.00035389084791859204, Final Batch Loss: 5.2979530664742924e-06\n",
      "Epoch 4244, Loss: 0.0008849619189277291, Final Batch Loss: 9.3543749244418e-05\n",
      "Epoch 4245, Loss: 0.0001309346816924517, Final Batch Loss: 3.199255661456846e-05\n",
      "Epoch 4246, Loss: 9.15332143449632e-05, Final Batch Loss: 7.157404070312623e-06\n",
      "Epoch 4247, Loss: 0.0003171331836711033, Final Batch Loss: 1.285380949411774e-05\n",
      "Epoch 4248, Loss: 0.00020096379375900142, Final Batch Loss: 1.3637149095302448e-05\n",
      "Epoch 4249, Loss: 0.0021492752894118894, Final Batch Loss: 0.001575324684381485\n",
      "Epoch 4250, Loss: 0.0014165953323299618, Final Batch Loss: 0.001295568305067718\n",
      "Epoch 4251, Loss: 0.0008545028849766823, Final Batch Loss: 4.689017805503681e-05\n",
      "Epoch 4252, Loss: 0.0001918997131724609, Final Batch Loss: 2.9744536732323468e-05\n",
      "Epoch 4253, Loss: 0.0004836657244595699, Final Batch Loss: 3.8280213630059734e-05\n",
      "Epoch 4254, Loss: 0.00043320218173903413, Final Batch Loss: 0.00023374201555270702\n",
      "Epoch 4255, Loss: 4.9240238240599865e-05, Final Batch Loss: 1.9225681171519682e-05\n",
      "Epoch 4256, Loss: 0.0008441071645393095, Final Batch Loss: 1.4861284398648422e-06\n",
      "Epoch 4257, Loss: 0.000165764558914816, Final Batch Loss: 1.5407045793836005e-05\n",
      "Epoch 4258, Loss: 0.0001001812252070522, Final Batch Loss: 1.4910574464011006e-05\n",
      "Epoch 4259, Loss: 7.801166111676139e-05, Final Batch Loss: 1.682328002061695e-05\n",
      "Epoch 4260, Loss: 0.00043968274326289247, Final Batch Loss: 0.0002910075709223747\n",
      "Epoch 4261, Loss: 0.00283486597436422, Final Batch Loss: 0.0027215483132749796\n",
      "Epoch 4262, Loss: 0.0042364227838334045, Final Batch Loss: 1.7697335351840593e-05\n",
      "Epoch 4263, Loss: 0.0003282062411926745, Final Batch Loss: 7.74760246713413e-06\n",
      "Epoch 4264, Loss: 0.00034012490687018726, Final Batch Loss: 0.00012870565115008503\n",
      "Epoch 4265, Loss: 0.0011089095528404869, Final Batch Loss: 9.339132702734787e-06\n",
      "Epoch 4266, Loss: 0.004328127895860234, Final Batch Loss: 4.600020474754274e-06\n",
      "Epoch 4267, Loss: 0.0005246053500513881, Final Batch Loss: 1.7487803916083067e-06\n",
      "Epoch 4268, Loss: 0.0005865528692083899, Final Batch Loss: 4.533626270131208e-05\n",
      "Epoch 4269, Loss: 0.000603411750489613, Final Batch Loss: 2.0462503016460687e-05\n",
      "Epoch 4270, Loss: 0.0003798460988946317, Final Batch Loss: 6.965586180740502e-06\n",
      "Epoch 4271, Loss: 0.00022459814317699056, Final Batch Loss: 2.0531175323412754e-05\n",
      "Epoch 4272, Loss: 0.000846048451421666, Final Batch Loss: 2.079760997730773e-05\n",
      "Epoch 4273, Loss: 0.00016402895812461793, Final Batch Loss: 2.7000576210411964e-06\n",
      "Epoch 4274, Loss: 0.009285936288506491, Final Batch Loss: 0.00024396942171733826\n",
      "Epoch 4275, Loss: 0.05021086088777338, Final Batch Loss: 3.5090174606011715e-06\n",
      "Epoch 4276, Loss: 0.00015782753780513303, Final Batch Loss: 8.402755156566855e-06\n",
      "Epoch 4277, Loss: 0.005610253995200765, Final Batch Loss: 2.285129539814079e-06\n",
      "Epoch 4278, Loss: 0.0007254748052218929, Final Batch Loss: 9.671261068433523e-05\n",
      "Epoch 4279, Loss: 0.0006579535620403476, Final Batch Loss: 0.00017135798407252878\n",
      "Epoch 4280, Loss: 0.0012017017033940647, Final Batch Loss: 1.1038160664611496e-05\n",
      "Epoch 4281, Loss: 0.0002467396516294684, Final Batch Loss: 1.3636454241350293e-06\n",
      "Epoch 4282, Loss: 0.0008080631805569283, Final Batch Loss: 2.6231095034745522e-05\n",
      "Epoch 4283, Loss: 0.0011966471956839086, Final Batch Loss: 2.0137198589509353e-05\n",
      "Epoch 4284, Loss: 6.186980044731172e-05, Final Batch Loss: 1.700204302323982e-05\n",
      "Epoch 4285, Loss: 0.0001176342311737244, Final Batch Loss: 6.8490562625811435e-06\n",
      "Epoch 4286, Loss: 0.0017720883333822712, Final Batch Loss: 0.0017124974401667714\n",
      "Epoch 4287, Loss: 0.00013960285286884755, Final Batch Loss: 5.7911012845579535e-05\n",
      "Epoch 4288, Loss: 0.00026033281937998254, Final Batch Loss: 7.868649117881432e-05\n",
      "Epoch 4289, Loss: 0.0003555760285962606, Final Batch Loss: 2.5642788386903703e-05\n",
      "Epoch 4290, Loss: 0.00015657625772291794, Final Batch Loss: 1.3264843801152892e-05\n",
      "Epoch 4291, Loss: 0.00011955959598708432, Final Batch Loss: 4.907456968794577e-06\n",
      "Epoch 4292, Loss: 0.00035167489500054216, Final Batch Loss: 5.554794552153908e-05\n",
      "Epoch 4293, Loss: 0.000619883708168345, Final Batch Loss: 1.1191847988811787e-05\n",
      "Epoch 4294, Loss: 0.0002820420268108137, Final Batch Loss: 3.8699476135661826e-05\n",
      "Epoch 4295, Loss: 3.736028611456277e-05, Final Batch Loss: 1.6754556781961583e-05\n",
      "Epoch 4296, Loss: 9.234048661710403e-05, Final Batch Loss: 2.0435406895558117e-06\n",
      "Epoch 4297, Loss: 0.0014275249295678805, Final Batch Loss: 7.775947779009584e-06\n",
      "Epoch 4298, Loss: 0.0007228235190268606, Final Batch Loss: 0.00019588095892686397\n",
      "Epoch 4299, Loss: 0.00014750459558854345, Final Batch Loss: 4.5598808355862275e-06\n",
      "Epoch 4300, Loss: 0.0002263754622617853, Final Batch Loss: 1.2747937034873758e-05\n",
      "Epoch 4301, Loss: 6.44782921881415e-05, Final Batch Loss: 6.257821041799616e-06\n",
      "Epoch 4302, Loss: 0.012928314701298405, Final Batch Loss: 0.012866604141891003\n",
      "Epoch 4303, Loss: 0.019009325086244644, Final Batch Loss: 7.211383490357548e-05\n",
      "Epoch 4304, Loss: 0.012564607183776388, Final Batch Loss: 6.466655031545088e-05\n",
      "Epoch 4305, Loss: 0.004705567020209855, Final Batch Loss: 0.00018231873400509357\n",
      "Epoch 4306, Loss: 0.0018995864002135932, Final Batch Loss: 0.0012784345308318734\n",
      "Epoch 4307, Loss: 0.00023515137763752136, Final Batch Loss: 2.0331690393504687e-05\n",
      "Epoch 4308, Loss: 0.0003268636310167494, Final Batch Loss: 0.00016882942873053253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4309, Loss: 4.3333489884389564e-05, Final Batch Loss: 1.2397325917845592e-05\n",
      "Epoch 4310, Loss: 0.0009802929480429157, Final Batch Loss: 7.806167559465393e-05\n",
      "Epoch 4311, Loss: 0.0005139198638062226, Final Batch Loss: 1.7225063857040368e-05\n",
      "Epoch 4312, Loss: 0.005419281092144956, Final Batch Loss: 1.0851093065866735e-05\n",
      "Epoch 4313, Loss: 0.0001278373483728501, Final Batch Loss: 3.026821832463611e-05\n",
      "Epoch 4314, Loss: 0.0005479752452970388, Final Batch Loss: 7.257112315528502e-07\n",
      "Epoch 4315, Loss: 0.0002527293831917632, Final Batch Loss: 2.9060133783787023e-06\n",
      "Epoch 4316, Loss: 0.0008257076765403326, Final Batch Loss: 6.0388159909052774e-05\n",
      "Epoch 4317, Loss: 0.0007895095095591387, Final Batch Loss: 0.0006329099414870143\n",
      "Epoch 4318, Loss: 0.00011195633101124258, Final Batch Loss: 1.7446653146180324e-05\n",
      "Epoch 4319, Loss: 0.00036351560265757143, Final Batch Loss: 9.011429938254878e-05\n",
      "Epoch 4320, Loss: 0.0020172821887172177, Final Batch Loss: 8.065003203228116e-05\n",
      "Epoch 4321, Loss: 8.714712339497055e-05, Final Batch Loss: 6.890035820106277e-06\n",
      "Epoch 4322, Loss: 0.001628573677407985, Final Batch Loss: 2.6699455702328123e-05\n",
      "Epoch 4323, Loss: 0.005820007694183005, Final Batch Loss: 4.672631621360779e-05\n",
      "Epoch 4324, Loss: 0.00014826443384663435, Final Batch Loss: 7.147387805161998e-06\n",
      "Epoch 4325, Loss: 0.0019427008664933965, Final Batch Loss: 0.0015159501926973462\n",
      "Epoch 4326, Loss: 0.004611303838373715, Final Batch Loss: 1.0729209861892741e-05\n",
      "Epoch 4327, Loss: 0.025372250885993708, Final Batch Loss: 0.0025290180929005146\n",
      "Epoch 4328, Loss: 0.004217306028294843, Final Batch Loss: 0.0038978715892881155\n",
      "Epoch 4329, Loss: 0.025069837652154092, Final Batch Loss: 3.685617048176937e-05\n",
      "Epoch 4330, Loss: 0.0013585353945018142, Final Batch Loss: 7.879504846641794e-05\n",
      "Epoch 4331, Loss: 0.0010234342980766087, Final Batch Loss: 5.929553481109906e-06\n",
      "Epoch 4332, Loss: 0.00024342964934476186, Final Batch Loss: 8.069418981904164e-07\n",
      "Epoch 4333, Loss: 6.610107129745302e-05, Final Batch Loss: 1.1403872122173198e-05\n",
      "Epoch 4334, Loss: 0.000427979353844421, Final Batch Loss: 6.561033660545945e-05\n",
      "Epoch 4335, Loss: 0.014539670461090282, Final Batch Loss: 0.01311636995524168\n",
      "Epoch 4336, Loss: 0.006723134149524412, Final Batch Loss: 7.062061195028946e-05\n",
      "Epoch 4337, Loss: 0.10133038371168368, Final Batch Loss: 1.5091647583176382e-05\n",
      "Epoch 4338, Loss: 0.005447538469979918, Final Batch Loss: 2.105820385622792e-05\n",
      "Epoch 4339, Loss: 0.012340114757535048, Final Batch Loss: 0.00021903110609855503\n",
      "Epoch 4340, Loss: 0.01788183822282008, Final Batch Loss: 0.008337844163179398\n",
      "Epoch 4341, Loss: 0.006066353747883113, Final Batch Loss: 0.004708467051386833\n",
      "Epoch 4342, Loss: 0.00028761718931491487, Final Batch Loss: 8.364428504137322e-05\n",
      "Epoch 4343, Loss: 0.0024532493589504156, Final Batch Loss: 1.946704651345499e-05\n",
      "Epoch 4344, Loss: 0.032871631508896826, Final Batch Loss: 9.447328193346038e-05\n",
      "Epoch 4345, Loss: 0.000612989275396103, Final Batch Loss: 6.547085649799556e-05\n",
      "Epoch 4346, Loss: 0.014921054997103056, Final Batch Loss: 8.388700734940358e-06\n",
      "Epoch 4347, Loss: 0.0004089684480277356, Final Batch Loss: 3.2211242796620354e-05\n",
      "Epoch 4348, Loss: 0.0026467892537311855, Final Batch Loss: 3.487549065539497e-06\n",
      "Epoch 4349, Loss: 0.009431771817617118, Final Batch Loss: 0.00493391789495945\n",
      "Epoch 4350, Loss: 0.0040174567111535, Final Batch Loss: 0.0014413332100957632\n",
      "Epoch 4351, Loss: 0.0005966060234641191, Final Batch Loss: 0.000179670998477377\n",
      "Epoch 4352, Loss: 0.00039149619988165796, Final Batch Loss: 0.00012234458699822426\n",
      "Epoch 4353, Loss: 0.0016907324134081136, Final Batch Loss: 0.0003662085218820721\n",
      "Epoch 4354, Loss: 0.0007498997656512074, Final Batch Loss: 2.731350832618773e-05\n",
      "Epoch 4355, Loss: 0.00043443044705782086, Final Batch Loss: 4.93941261083819e-05\n",
      "Epoch 4356, Loss: 0.0005962140785413794, Final Batch Loss: 4.490805804380216e-05\n",
      "Epoch 4357, Loss: 0.0005836416821694002, Final Batch Loss: 0.0002213194384239614\n",
      "Epoch 4358, Loss: 0.005874467831745278, Final Batch Loss: 0.0002055400109384209\n",
      "Epoch 4359, Loss: 0.0008547475008526817, Final Batch Loss: 9.344163845526055e-05\n",
      "Epoch 4360, Loss: 0.0005210097733652219, Final Batch Loss: 4.02638252126053e-05\n",
      "Epoch 4361, Loss: 0.0022082934010541067, Final Batch Loss: 9.158892498817295e-05\n",
      "Epoch 4362, Loss: 0.0007582072976219933, Final Batch Loss: 0.0005126706091687083\n",
      "Epoch 4363, Loss: 0.00038987976586213335, Final Batch Loss: 0.00014028266014065593\n",
      "Epoch 4364, Loss: 0.00042883730748144444, Final Batch Loss: 3.207023473805748e-05\n",
      "Epoch 4365, Loss: 0.0015524123609793605, Final Batch Loss: 2.0893823602818884e-05\n",
      "Epoch 4366, Loss: 0.013492537577803887, Final Batch Loss: 0.012625697068870068\n",
      "Epoch 4367, Loss: 0.001329984940639406, Final Batch Loss: 1.5174005056906026e-05\n",
      "Epoch 4368, Loss: 0.00207124089502031, Final Batch Loss: 3.369808109709993e-05\n",
      "Epoch 4369, Loss: 0.000578649494855199, Final Batch Loss: 0.0001405143120791763\n",
      "Epoch 4370, Loss: 0.0034251671022502705, Final Batch Loss: 0.0025637794751673937\n",
      "Epoch 4371, Loss: 0.0009664753852121066, Final Batch Loss: 0.0005031388136558235\n",
      "Epoch 4372, Loss: 0.001416632549080532, Final Batch Loss: 0.00023109915491659194\n",
      "Epoch 4373, Loss: 0.0032078040167107247, Final Batch Loss: 0.000992614426650107\n",
      "Epoch 4374, Loss: 0.0013336955353224766, Final Batch Loss: 0.0001194411888718605\n",
      "Epoch 4375, Loss: 0.0007167385956563521, Final Batch Loss: 7.09291998646222e-05\n",
      "Epoch 4376, Loss: 0.0015334208342210331, Final Batch Loss: 0.0014011735329404473\n",
      "Epoch 4377, Loss: 0.000580650994379539, Final Batch Loss: 0.00011609884677454829\n",
      "Epoch 4378, Loss: 0.0003744300265680067, Final Batch Loss: 0.00021744304103776813\n",
      "Epoch 4379, Loss: 0.00032032419676397694, Final Batch Loss: 8.220099516620394e-06\n",
      "Epoch 4380, Loss: 0.0007334487536354573, Final Batch Loss: 3.673230457934551e-05\n",
      "Epoch 4381, Loss: 0.00028670036954281386, Final Batch Loss: 0.00020002225937787443\n",
      "Epoch 4382, Loss: 0.00132678428235522, Final Batch Loss: 3.4466855140635744e-05\n",
      "Epoch 4383, Loss: 0.000632303548627533, Final Batch Loss: 6.077500438550487e-05\n",
      "Epoch 4384, Loss: 0.0012567473841045285, Final Batch Loss: 0.00011361049837432802\n",
      "Epoch 4385, Loss: 0.0023233529491335503, Final Batch Loss: 5.677756416844204e-05\n",
      "Epoch 4386, Loss: 0.0007400209015031578, Final Batch Loss: 2.184834193030838e-05\n",
      "Epoch 4387, Loss: 0.0004578034677251708, Final Batch Loss: 2.0164607121841982e-05\n",
      "Epoch 4388, Loss: 0.0001236280131706735, Final Batch Loss: 2.1831056074006483e-05\n",
      "Epoch 4389, Loss: 0.0006689109254693903, Final Batch Loss: 3.991689482063521e-06\n",
      "Epoch 4390, Loss: 8.591366895416286e-05, Final Batch Loss: 4.320423977333121e-05\n",
      "Epoch 4391, Loss: 0.00011028093922504922, Final Batch Loss: 4.0825589167070575e-06\n",
      "Epoch 4392, Loss: 0.00037139980668143835, Final Batch Loss: 7.952368832775392e-06\n",
      "Epoch 4393, Loss: 0.002685850497073261, Final Batch Loss: 4.252338476362638e-05\n",
      "Epoch 4394, Loss: 0.00022357706802722532, Final Batch Loss: 9.663750824984163e-05\n",
      "Epoch 4395, Loss: 0.000381011614081217, Final Batch Loss: 2.4726859919610433e-05\n",
      "Epoch 4396, Loss: 9.713315102999331e-05, Final Batch Loss: 6.016757834004238e-05\n",
      "Epoch 4397, Loss: 0.0004977815042366274, Final Batch Loss: 1.6552148736082017e-05\n",
      "Epoch 4398, Loss: 6.762995440112718e-05, Final Batch Loss: 6.243257303140126e-06\n",
      "Epoch 4399, Loss: 0.016030362095989403, Final Batch Loss: 4.0227416320703924e-05\n",
      "Epoch 4400, Loss: 0.0008255319717136445, Final Batch Loss: 7.1023805503500625e-06\n",
      "Epoch 4401, Loss: 0.000706507133145351, Final Batch Loss: 7.26918297004886e-05\n",
      "Epoch 4402, Loss: 0.0005223766929702833, Final Batch Loss: 5.8887453633360565e-05\n",
      "Epoch 4403, Loss: 0.00029940531794636627, Final Batch Loss: 2.3968814275576733e-05\n",
      "Epoch 4404, Loss: 0.0003888722626470553, Final Batch Loss: 5.2349810175655875e-06\n",
      "Epoch 4405, Loss: 0.0016749756405260996, Final Batch Loss: 0.0009823725558817387\n",
      "Epoch 4406, Loss: 0.0006825597029092023, Final Batch Loss: 0.00010772602399811149\n",
      "Epoch 4407, Loss: 0.0005518118450709153, Final Batch Loss: 2.0149376723566093e-05\n",
      "Epoch 4408, Loss: 0.0006643242159043439, Final Batch Loss: 8.940860425354913e-05\n",
      "Epoch 4409, Loss: 0.0002138288054993609, Final Batch Loss: 2.4775394194875844e-05\n",
      "Epoch 4410, Loss: 0.0010034851002274081, Final Batch Loss: 1.3424360076896846e-05\n",
      "Epoch 4411, Loss: 0.00035144399271302973, Final Batch Loss: 7.495912086596945e-06\n",
      "Epoch 4412, Loss: 0.0019811226484307554, Final Batch Loss: 4.371435716166161e-05\n",
      "Epoch 4413, Loss: 0.0010357870378356893, Final Batch Loss: 0.0009674528264440596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4414, Loss: 0.0010196071682457841, Final Batch Loss: 2.355902552153566e-06\n",
      "Epoch 4415, Loss: 0.00048310526017303346, Final Batch Loss: 8.87853548192652e-06\n",
      "Epoch 4416, Loss: 0.0004145950269958121, Final Batch Loss: 1.5366669686045498e-05\n",
      "Epoch 4417, Loss: 0.0001827379692258546, Final Batch Loss: 4.7324856495833956e-06\n",
      "Epoch 4418, Loss: 0.0002496939014235977, Final Batch Loss: 4.895815800409764e-05\n",
      "Epoch 4419, Loss: 0.00011507896306284238, Final Batch Loss: 9.346073056804016e-06\n",
      "Epoch 4420, Loss: 0.0002373229854129022, Final Batch Loss: 0.00011551408533705398\n",
      "Epoch 4421, Loss: 0.00024744933580223005, Final Batch Loss: 4.7396697482327e-06\n",
      "Epoch 4422, Loss: 0.001260434734831506, Final Batch Loss: 0.000989548396319151\n",
      "Epoch 4423, Loss: 0.001701289843822451, Final Batch Loss: 0.00046098779421299696\n",
      "Epoch 4424, Loss: 0.0004564226082948153, Final Batch Loss: 0.0004210665647406131\n",
      "Epoch 4425, Loss: 0.00012139877571826219, Final Batch Loss: 4.9726178986020386e-05\n",
      "Epoch 4426, Loss: 0.0006114567186159547, Final Batch Loss: 2.6179772248724476e-05\n",
      "Epoch 4427, Loss: 0.0010152295637908537, Final Batch Loss: 3.285188358859159e-05\n",
      "Epoch 4428, Loss: 6.286081432449464e-05, Final Batch Loss: 2.5937723080460273e-07\n",
      "Epoch 4429, Loss: 0.0027146433722009533, Final Batch Loss: 4.8870433602132834e-06\n",
      "Epoch 4430, Loss: 0.0013128444588801358, Final Batch Loss: 0.000878851511515677\n",
      "Epoch 4431, Loss: 0.00022779386381444056, Final Batch Loss: 1.2173144568805583e-05\n",
      "Epoch 4432, Loss: 0.0002878449298577834, Final Batch Loss: 1.714629775051435e-06\n",
      "Epoch 4433, Loss: 0.0007712512324360432, Final Batch Loss: 0.0005689013050869107\n",
      "Epoch 4434, Loss: 0.0013482368158292957, Final Batch Loss: 0.00040373741649091244\n",
      "Epoch 4435, Loss: 0.0004357030047685839, Final Batch Loss: 6.521595059894025e-05\n",
      "Epoch 4436, Loss: 0.000883427190274233, Final Batch Loss: 0.0004926012479700148\n",
      "Epoch 4437, Loss: 0.002801665774313733, Final Batch Loss: 5.385227996157482e-05\n",
      "Epoch 4438, Loss: 0.0018158621751354076, Final Batch Loss: 2.426698847557418e-05\n",
      "Epoch 4439, Loss: 0.05821360793925123, Final Batch Loss: 0.00011761134373955429\n",
      "Epoch 4440, Loss: 0.0004504903045017272, Final Batch Loss: 1.555637027195189e-05\n",
      "Epoch 4441, Loss: 0.001174856402712976, Final Batch Loss: 9.731475438456982e-05\n",
      "Epoch 4442, Loss: 0.00028553387164720334, Final Batch Loss: 2.526917160139419e-05\n",
      "Epoch 4443, Loss: 0.00040610323776490986, Final Batch Loss: 1.4333581930259243e-05\n",
      "Epoch 4444, Loss: 0.0025741660056155524, Final Batch Loss: 5.396063897933345e-06\n",
      "Epoch 4445, Loss: 0.0002135574886779068, Final Batch Loss: 0.0001304763718508184\n",
      "Epoch 4446, Loss: 0.0017471998689870816, Final Batch Loss: 0.0005758297629654408\n",
      "Epoch 4447, Loss: 0.022330406271976244, Final Batch Loss: 9.037205018103123e-05\n",
      "Epoch 4448, Loss: 0.001091180924049695, Final Batch Loss: 2.3701475583948195e-05\n",
      "Epoch 4449, Loss: 0.0007757227058391436, Final Batch Loss: 3.5248949643573724e-06\n",
      "Epoch 4450, Loss: 0.0027002014612662606, Final Batch Loss: 0.001840408192947507\n",
      "Epoch 4451, Loss: 0.00030963532663008664, Final Batch Loss: 1.807368425943423e-05\n",
      "Epoch 4452, Loss: 0.0007618319687026087, Final Batch Loss: 2.1564610506175086e-05\n",
      "Epoch 4453, Loss: 0.0018526527383073699, Final Batch Loss: 6.396935350494459e-05\n",
      "Epoch 4454, Loss: 0.0005985705292914645, Final Batch Loss: 4.037000508105848e-06\n",
      "Epoch 4455, Loss: 0.0010165163284909795, Final Batch Loss: 3.9119891880545765e-05\n",
      "Epoch 4456, Loss: 0.006477401719166664, Final Batch Loss: 0.0058058141730725765\n",
      "Epoch 4457, Loss: 0.000273280465762582, Final Batch Loss: 2.3217382477014326e-05\n",
      "Epoch 4458, Loss: 0.0015626507802153355, Final Batch Loss: 0.0014952149940654635\n",
      "Epoch 4459, Loss: 0.0026940787702187663, Final Batch Loss: 2.1003081201342866e-05\n",
      "Epoch 4460, Loss: 0.0009902018432512705, Final Batch Loss: 2.4429289624094963e-05\n",
      "Epoch 4461, Loss: 0.0008594786977482727, Final Batch Loss: 1.466296635044273e-05\n",
      "Epoch 4462, Loss: 0.00034453425087122014, Final Batch Loss: 0.00020102869893889874\n",
      "Epoch 4463, Loss: 6.995504463702673e-05, Final Batch Loss: 2.7264279196970165e-05\n",
      "Epoch 4464, Loss: 0.0004778544671353302, Final Batch Loss: 5.014151611248963e-06\n",
      "Epoch 4465, Loss: 0.0007439755790983327, Final Batch Loss: 0.0005300341872498393\n",
      "Epoch 4466, Loss: 0.00017763966934580822, Final Batch Loss: 1.161952968686819e-05\n",
      "Epoch 4467, Loss: 0.00038792731902503874, Final Batch Loss: 4.0089340473059565e-05\n",
      "Epoch 4468, Loss: 0.0001089870222585887, Final Batch Loss: 2.2170184820424765e-05\n",
      "Epoch 4469, Loss: 0.00015232404621201567, Final Batch Loss: 5.850794696016237e-05\n",
      "Epoch 4470, Loss: 8.905270351533545e-05, Final Batch Loss: 4.223453288432211e-06\n",
      "Epoch 4471, Loss: 0.00026387583784526214, Final Batch Loss: 0.00017672615649644285\n",
      "Epoch 4472, Loss: 0.0003049910724257643, Final Batch Loss: 9.197796316584572e-06\n",
      "Epoch 4473, Loss: 0.003326137315525557, Final Batch Loss: 2.3772783606546e-05\n",
      "Epoch 4474, Loss: 0.00041848470937111415, Final Batch Loss: 1.1741787602659315e-05\n",
      "Epoch 4475, Loss: 6.578530161505114e-05, Final Batch Loss: 3.3833343877631705e-06\n",
      "Epoch 4476, Loss: 0.00036054470047020004, Final Batch Loss: 2.1043992092018016e-05\n",
      "Epoch 4477, Loss: 0.00010885277924899128, Final Batch Loss: 9.929594853019807e-07\n",
      "Epoch 4478, Loss: 0.001716650584967283, Final Batch Loss: 0.0013444693759083748\n",
      "Epoch 4479, Loss: 0.00457746805568604, Final Batch Loss: 3.497434954624623e-05\n",
      "Epoch 4480, Loss: 0.023580993073665013, Final Batch Loss: 1.3754454812442418e-05\n",
      "Epoch 4481, Loss: 0.00044941302985535003, Final Batch Loss: 0.0001553004258312285\n",
      "Epoch 4482, Loss: 0.0037455987394423573, Final Batch Loss: 2.5688255846034735e-05\n",
      "Epoch 4483, Loss: 3.600136960812961e-05, Final Batch Loss: 6.337563718261663e-06\n",
      "Epoch 4484, Loss: 0.0033681126824376406, Final Batch Loss: 1.085557414626237e-05\n",
      "Epoch 4485, Loss: 0.028564478365296964, Final Batch Loss: 0.005931633058935404\n",
      "Epoch 4486, Loss: 0.00048336907912016613, Final Batch Loss: 0.0002431501925457269\n",
      "Epoch 4487, Loss: 0.0003987127074651653, Final Batch Loss: 1.0078203558805399e-05\n",
      "Epoch 4488, Loss: 0.018868854131142143, Final Batch Loss: 9.212064469465986e-05\n",
      "Epoch 4489, Loss: 0.0002957514889203594, Final Batch Loss: 9.9247794423718e-05\n",
      "Epoch 4490, Loss: 0.0004700036806752905, Final Batch Loss: 5.592887828242965e-05\n",
      "Epoch 4491, Loss: 0.0004163458115726826, Final Batch Loss: 1.2855536624556407e-05\n",
      "Epoch 4492, Loss: 0.0006838718745711958, Final Batch Loss: 0.00029529555467888713\n",
      "Epoch 4493, Loss: 0.0038078858342487365, Final Batch Loss: 1.8098213331541047e-05\n",
      "Epoch 4494, Loss: 0.0018305151188542368, Final Batch Loss: 0.0015877983532845974\n",
      "Epoch 4495, Loss: 0.008334502777870512, Final Batch Loss: 4.2868865421041846e-05\n",
      "Epoch 4496, Loss: 0.0010620773041409848, Final Batch Loss: 0.0010221349075436592\n",
      "Epoch 4497, Loss: 0.001763048493558017, Final Batch Loss: 0.001317373476922512\n",
      "Epoch 4498, Loss: 0.00018594442371977493, Final Batch Loss: 1.9938317564083263e-05\n",
      "Epoch 4499, Loss: 0.0007328849205805454, Final Batch Loss: 0.00010704622400226071\n",
      "Epoch 4500, Loss: 0.00046725960055482574, Final Batch Loss: 9.619734191801399e-05\n",
      "Epoch 4501, Loss: 0.02278281605686061, Final Batch Loss: 0.00016562463133595884\n",
      "Epoch 4502, Loss: 0.0002426675218885066, Final Batch Loss: 7.00028904248029e-05\n",
      "Epoch 4503, Loss: 0.0021229050144029316, Final Batch Loss: 7.316319533856586e-05\n",
      "Epoch 4504, Loss: 0.00029352519595704507, Final Batch Loss: 0.0001187114103231579\n",
      "Epoch 4505, Loss: 0.016672831936375587, Final Batch Loss: 0.00013261278218124062\n",
      "Epoch 4506, Loss: 0.0005712319180020131, Final Batch Loss: 0.0001771938696037978\n",
      "Epoch 4507, Loss: 0.0003573159938241588, Final Batch Loss: 0.00014571650535799563\n",
      "Epoch 4508, Loss: 0.002261903508042451, Final Batch Loss: 0.000741137599106878\n",
      "Epoch 4509, Loss: 0.0007300078323169146, Final Batch Loss: 0.00023106162552721798\n",
      "Epoch 4510, Loss: 0.01485904939181637, Final Batch Loss: 0.0008246993529610336\n",
      "Epoch 4511, Loss: 0.001379524874209892, Final Batch Loss: 0.0001283966121263802\n",
      "Epoch 4512, Loss: 0.002405821669526631, Final Batch Loss: 0.00030030051129870117\n",
      "Epoch 4513, Loss: 0.0005271381305647083, Final Batch Loss: 2.9390619602054358e-05\n",
      "Epoch 4514, Loss: 0.0003145603586744983, Final Batch Loss: 0.00012108271039323881\n",
      "Epoch 4515, Loss: 0.0006637454262090614, Final Batch Loss: 0.00013150190352462232\n",
      "Epoch 4516, Loss: 0.0006726100582454819, Final Batch Loss: 0.000362149701686576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4517, Loss: 0.0014889353878970724, Final Batch Loss: 3.368513353052549e-05\n",
      "Epoch 4518, Loss: 0.000677743677442777, Final Batch Loss: 0.0002730980340857059\n",
      "Epoch 4519, Loss: 0.0003366873424965888, Final Batch Loss: 6.624692468903959e-05\n",
      "Epoch 4520, Loss: 0.0179802178281534, Final Batch Loss: 2.4076958652585745e-05\n",
      "Epoch 4521, Loss: 0.0012298194033064647, Final Batch Loss: 1.8419483239995316e-05\n",
      "Epoch 4522, Loss: 0.0002994420519826235, Final Batch Loss: 6.915085396030918e-05\n",
      "Epoch 4523, Loss: 0.00044454772796598263, Final Batch Loss: 3.160904816468246e-05\n",
      "Epoch 4524, Loss: 0.0034279693791177124, Final Batch Loss: 5.809135836898349e-05\n",
      "Epoch 4525, Loss: 0.0014080053333600517, Final Batch Loss: 0.0008499589748680592\n",
      "Epoch 4526, Loss: 0.0028234445126145147, Final Batch Loss: 0.0002306061942363158\n",
      "Epoch 4527, Loss: 0.00532699011182558, Final Batch Loss: 1.1891689609910827e-05\n",
      "Epoch 4528, Loss: 0.0012340004486759426, Final Batch Loss: 2.077429053315427e-05\n",
      "Epoch 4529, Loss: 0.0007251173428812763, Final Batch Loss: 7.348899816861376e-05\n",
      "Epoch 4530, Loss: 0.0006665871715085814, Final Batch Loss: 0.00010169520828640088\n",
      "Epoch 4531, Loss: 0.0015494613908231258, Final Batch Loss: 7.816286233719438e-05\n",
      "Epoch 4532, Loss: 0.0003532672863002517, Final Batch Loss: 8.318215986946598e-05\n",
      "Epoch 4533, Loss: 0.0008023527625482529, Final Batch Loss: 0.0005489777540788054\n",
      "Epoch 4534, Loss: 0.0007332285003940342, Final Batch Loss: 1.0413654308649711e-05\n",
      "Epoch 4535, Loss: 0.00047904637540341355, Final Batch Loss: 4.699080818681978e-05\n",
      "Epoch 4536, Loss: 0.00033759509460651316, Final Batch Loss: 8.889839227776974e-05\n",
      "Epoch 4537, Loss: 0.00020728220533783315, Final Batch Loss: 9.085079364012927e-05\n",
      "Epoch 4538, Loss: 0.0003494884731480852, Final Batch Loss: 6.26051114522852e-05\n",
      "Epoch 4539, Loss: 0.00015462056626347476, Final Batch Loss: 4.671489296015352e-05\n",
      "Epoch 4540, Loss: 0.00025145491690636845, Final Batch Loss: 0.00012057518324581906\n",
      "Epoch 4541, Loss: 0.00040168265900319966, Final Batch Loss: 3.0515250273310812e-06\n",
      "Epoch 4542, Loss: 0.00046548968020942993, Final Batch Loss: 0.00011211819219170138\n",
      "Epoch 4543, Loss: 0.00039344469769275747, Final Batch Loss: 1.6668764146743342e-05\n",
      "Epoch 4544, Loss: 0.0002685810704861069, Final Batch Loss: 8.523638098267838e-05\n",
      "Epoch 4545, Loss: 0.00012591161339514656, Final Batch Loss: 1.1065266335208435e-05\n",
      "Epoch 4546, Loss: 0.00024946855410235, Final Batch Loss: 7.216402445919812e-05\n",
      "Epoch 4547, Loss: 0.00034789772053045454, Final Batch Loss: 9.471107659919653e-06\n",
      "Epoch 4548, Loss: 0.0025655689096311107, Final Batch Loss: 1.0116636985912919e-05\n",
      "Epoch 4549, Loss: 0.00019037247511732858, Final Batch Loss: 8.059720858000219e-05\n",
      "Epoch 4550, Loss: 0.00018799054305418395, Final Batch Loss: 9.90934349829331e-05\n",
      "Epoch 4551, Loss: 0.002360803082410712, Final Batch Loss: 0.0007003318169154227\n",
      "Epoch 4552, Loss: 0.00021458277626607014, Final Batch Loss: 7.415696745738387e-05\n",
      "Epoch 4553, Loss: 0.0021592763719127106, Final Batch Loss: 5.8357586567581166e-06\n",
      "Epoch 4554, Loss: 0.000481923315419408, Final Batch Loss: 2.092558133881539e-05\n",
      "Epoch 4555, Loss: 0.0008231645479099825, Final Batch Loss: 0.0005263808998279274\n",
      "Epoch 4556, Loss: 0.00023748219791741576, Final Batch Loss: 2.7050102289649658e-05\n",
      "Epoch 4557, Loss: 0.0004643476459023077, Final Batch Loss: 3.849745917250402e-05\n",
      "Epoch 4558, Loss: 0.0002491157565600588, Final Batch Loss: 0.00013126978592481464\n",
      "Epoch 4559, Loss: 0.0009004505482153036, Final Batch Loss: 0.00013524075620807707\n",
      "Epoch 4560, Loss: 9.174724550575775e-05, Final Batch Loss: 3.830314381048083e-05\n",
      "Epoch 4561, Loss: 0.0005977932969472022, Final Batch Loss: 1.1594886927923653e-05\n",
      "Epoch 4562, Loss: 0.0018894895292760339, Final Batch Loss: 0.0017174596432596445\n",
      "Epoch 4563, Loss: 0.0007910624966598334, Final Batch Loss: 1.4435039474847144e-06\n",
      "Epoch 4564, Loss: 0.00024368070899072336, Final Batch Loss: 5.366823643271346e-06\n",
      "Epoch 4565, Loss: 0.00013617319063996547, Final Batch Loss: 2.479748673067661e-06\n",
      "Epoch 4566, Loss: 0.0019709669732037582, Final Batch Loss: 2.6419575078762136e-06\n",
      "Epoch 4567, Loss: 0.004755694968480384, Final Batch Loss: 0.0044354940764606\n",
      "Epoch 4568, Loss: 0.00030892518952896353, Final Batch Loss: 1.7797447071643546e-05\n",
      "Epoch 4569, Loss: 0.00019322059051773977, Final Batch Loss: 3.6188819649396464e-05\n",
      "Epoch 4570, Loss: 0.00017975743048737058, Final Batch Loss: 8.752284884394612e-06\n",
      "Epoch 4571, Loss: 3.9231660423411086e-05, Final Batch Loss: 1.7063439372577704e-05\n",
      "Epoch 4572, Loss: 0.00027635300102701876, Final Batch Loss: 2.1845009541721083e-05\n",
      "Epoch 4573, Loss: 0.00025657918376964517, Final Batch Loss: 0.0001459357445128262\n",
      "Epoch 4574, Loss: 0.0001796444203137071, Final Batch Loss: 4.9225895054405555e-05\n",
      "Epoch 4575, Loss: 0.0001506757253082469, Final Batch Loss: 6.876667612232268e-05\n",
      "Epoch 4576, Loss: 0.0002964595787489088, Final Batch Loss: 5.834607873111963e-05\n",
      "Epoch 4577, Loss: 0.00015526897936979367, Final Batch Loss: 2.0677045995398657e-06\n",
      "Epoch 4578, Loss: 0.0015699662899351097, Final Batch Loss: 0.0005530126509256661\n",
      "Epoch 4579, Loss: 0.00012678323037107475, Final Batch Loss: 2.404675069556106e-05\n",
      "Epoch 4580, Loss: 0.003878263493106715, Final Batch Loss: 1.0639872925821692e-05\n",
      "Epoch 4581, Loss: 0.00017379304290443542, Final Batch Loss: 0.0001343986950814724\n",
      "Epoch 4582, Loss: 0.0002276455566061486, Final Batch Loss: 3.9456321246689186e-05\n",
      "Epoch 4583, Loss: 0.0020457596592677874, Final Batch Loss: 2.04741536435904e-06\n",
      "Epoch 4584, Loss: 0.0007501089921788662, Final Batch Loss: 3.816673415713012e-05\n",
      "Epoch 4585, Loss: 0.00022782136784371687, Final Batch Loss: 0.0001628044992685318\n",
      "Epoch 4586, Loss: 0.00015834053829166805, Final Batch Loss: 0.00011665659258142114\n",
      "Epoch 4587, Loss: 0.0005430117944342783, Final Batch Loss: 3.881118118442828e-06\n",
      "Epoch 4588, Loss: 7.952228042995557e-05, Final Batch Loss: 2.1119703887961805e-05\n",
      "Epoch 4589, Loss: 0.000733963837774354, Final Batch Loss: 0.0004497165500652045\n",
      "Epoch 4590, Loss: 0.0003885261648974847, Final Batch Loss: 1.3211660188972019e-05\n",
      "Epoch 4591, Loss: 0.0007540202313975897, Final Batch Loss: 0.000509569188579917\n",
      "Epoch 4592, Loss: 0.0001729823457026214, Final Batch Loss: 3.545214349287562e-05\n",
      "Epoch 4593, Loss: 0.0003152317234480506, Final Batch Loss: 1.584887650096789e-05\n",
      "Epoch 4594, Loss: 0.0001952628772414755, Final Batch Loss: 7.587747677462175e-05\n",
      "Epoch 4595, Loss: 0.0001432119724995573, Final Batch Loss: 0.00010412831034045666\n",
      "Epoch 4596, Loss: 0.0013536673359340057, Final Batch Loss: 3.4900367609225214e-05\n",
      "Epoch 4597, Loss: 0.00011525933814482414, Final Batch Loss: 4.0375630305788945e-06\n",
      "Epoch 4598, Loss: 0.00037840371919628524, Final Batch Loss: 1.90796927199699e-05\n",
      "Epoch 4599, Loss: 0.0006007988690726052, Final Batch Loss: 4.224893564241938e-05\n",
      "Epoch 4600, Loss: 0.0004062632469867822, Final Batch Loss: 1.623426578589715e-05\n",
      "Epoch 4601, Loss: 0.00010156699227081845, Final Batch Loss: 1.421757770003751e-05\n",
      "Epoch 4602, Loss: 0.00022445653848990332, Final Batch Loss: 1.602992597327102e-05\n",
      "Epoch 4603, Loss: 0.00018649750995791692, Final Batch Loss: 4.2033403587993234e-05\n",
      "Epoch 4604, Loss: 0.0001639241777411371, Final Batch Loss: 2.809117631841218e-06\n",
      "Epoch 4605, Loss: 0.0008982407525763847, Final Batch Loss: 7.154628110583872e-05\n",
      "Epoch 4606, Loss: 0.0002542760248616105, Final Batch Loss: 3.085147909587249e-05\n",
      "Epoch 4607, Loss: 0.0002661817115949816, Final Batch Loss: 1.3694265362573788e-05\n",
      "Epoch 4608, Loss: 5.731225246563554e-05, Final Batch Loss: 2.0585393940564245e-06\n",
      "Epoch 4609, Loss: 0.0008290207638310676, Final Batch Loss: 3.4954150578414556e-06\n",
      "Epoch 4610, Loss: 0.0002639071135490667, Final Batch Loss: 1.023207551043015e-05\n",
      "Epoch 4611, Loss: 0.0002705130509639275, Final Batch Loss: 5.55978185730055e-05\n",
      "Epoch 4612, Loss: 0.00036345672742754687, Final Batch Loss: 9.667727863416076e-05\n",
      "Epoch 4613, Loss: 0.00012864629206887912, Final Batch Loss: 6.233388558030128e-05\n",
      "Epoch 4614, Loss: 1.7323033887350903e-05, Final Batch Loss: 4.948767582391156e-06\n",
      "Epoch 4615, Loss: 0.0001271340439643609, Final Batch Loss: 4.001206616521813e-05\n",
      "Epoch 4616, Loss: 9.182037001664867e-05, Final Batch Loss: 6.268397555686533e-05\n",
      "Epoch 4617, Loss: 4.4442038642955595e-05, Final Batch Loss: 2.4797382138785906e-05\n",
      "Epoch 4618, Loss: 0.0002673478320502909, Final Batch Loss: 8.061602784437127e-06\n",
      "Epoch 4619, Loss: 0.0023543821412204124, Final Batch Loss: 1.8923932657344267e-05\n",
      "Epoch 4620, Loss: 0.0004223206426559045, Final Batch Loss: 0.00021628239483106881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4621, Loss: 0.00023806571732620796, Final Batch Loss: 7.57160364628362e-07\n",
      "Epoch 4622, Loss: 0.0002487219796876161, Final Batch Loss: 1.0597548225632636e-06\n",
      "Epoch 4623, Loss: 0.0007061912865538034, Final Batch Loss: 6.696687705698423e-06\n",
      "Epoch 4624, Loss: 0.0016728697278267646, Final Batch Loss: 0.000629036279860884\n",
      "Epoch 4625, Loss: 0.001003895265967003, Final Batch Loss: 0.0008802214870229363\n",
      "Epoch 4626, Loss: 6.444452651521715e-05, Final Batch Loss: 3.6411904602573486e-06\n",
      "Epoch 4627, Loss: 8.127083538056468e-05, Final Batch Loss: 4.2180221498711035e-05\n",
      "Epoch 4628, Loss: 0.00013160978960513603, Final Batch Loss: 1.0992991519742645e-05\n",
      "Epoch 4629, Loss: 4.651017286505521e-05, Final Batch Loss: 1.1108469379905728e-06\n",
      "Epoch 4630, Loss: 0.00031327230186661836, Final Batch Loss: 5.162058187124785e-06\n",
      "Epoch 4631, Loss: 0.00019380217418074608, Final Batch Loss: 2.994251190102659e-05\n",
      "Epoch 4632, Loss: 0.00011407275542296702, Final Batch Loss: 6.7227565523353405e-06\n",
      "Epoch 4633, Loss: 0.0005793880106921279, Final Batch Loss: 0.00021606578957289457\n",
      "Epoch 4634, Loss: 0.0016110120486700907, Final Batch Loss: 5.4277847084449604e-05\n",
      "Epoch 4635, Loss: 9.745808245043008e-05, Final Batch Loss: 7.918741857793066e-07\n",
      "Epoch 4636, Loss: 0.001645257172640413, Final Batch Loss: 6.190532076288946e-06\n",
      "Epoch 4637, Loss: 9.746509294927819e-05, Final Batch Loss: 3.0264867746154778e-05\n",
      "Epoch 4638, Loss: 0.00025338991565604374, Final Batch Loss: 5.267685992293991e-05\n",
      "Epoch 4639, Loss: 0.00019611267271102406, Final Batch Loss: 0.0001214713993249461\n",
      "Epoch 4640, Loss: 0.000104600075246708, Final Batch Loss: 9.929515272233402e-07\n",
      "Epoch 4641, Loss: 0.0015877657817782165, Final Batch Loss: 1.963597014764673e-06\n",
      "Epoch 4642, Loss: 0.000599215399233799, Final Batch Loss: 0.0005107097676955163\n",
      "Epoch 4643, Loss: 0.00032001968065742403, Final Batch Loss: 5.027699808124453e-05\n",
      "Epoch 4644, Loss: 0.0008013760307221673, Final Batch Loss: 7.352578541031107e-05\n",
      "Epoch 4645, Loss: 0.00034801659694494447, Final Batch Loss: 0.00027819231036119163\n",
      "Epoch 4646, Loss: 0.00045813724238996656, Final Batch Loss: 6.923229420863208e-07\n",
      "Epoch 4647, Loss: 0.0005137004990274363, Final Batch Loss: 1.673872429819312e-05\n",
      "Epoch 4648, Loss: 0.0017280594361182011, Final Batch Loss: 0.0002656033611856401\n",
      "Epoch 4649, Loss: 0.02840946174740111, Final Batch Loss: 0.028362441807985306\n",
      "Epoch 4650, Loss: 9.22934950722265e-05, Final Batch Loss: 2.0622766896849498e-05\n",
      "Epoch 4651, Loss: 0.0014463273503224627, Final Batch Loss: 4.392009213916026e-05\n",
      "Epoch 4652, Loss: 0.004886697997790179, Final Batch Loss: 0.001421813271008432\n",
      "Epoch 4653, Loss: 0.02627606175155961, Final Batch Loss: 5.000218880013563e-05\n",
      "Epoch 4654, Loss: 0.0036511519001578563, Final Batch Loss: 3.652191662695259e-05\n",
      "Epoch 4655, Loss: 0.00013461345383802836, Final Batch Loss: 0.00010949093120871112\n",
      "Epoch 4656, Loss: 0.0009749349737830926, Final Batch Loss: 7.127365097403526e-05\n",
      "Epoch 4657, Loss: 0.0002562492318247678, Final Batch Loss: 0.0001660471607465297\n",
      "Epoch 4658, Loss: 0.0009790012090888922, Final Batch Loss: 1.8010123312706128e-05\n",
      "Epoch 4659, Loss: 0.0021493044841918163, Final Batch Loss: 8.585848263464868e-06\n",
      "Epoch 4660, Loss: 8.860030629875837e-05, Final Batch Loss: 2.8717287932522595e-05\n",
      "Epoch 4661, Loss: 0.0002454667705933389, Final Batch Loss: 7.534528322139522e-06\n",
      "Epoch 4662, Loss: 0.0006540357580888667, Final Batch Loss: 7.804613414919004e-05\n",
      "Epoch 4663, Loss: 0.00023715065799478907, Final Batch Loss: 1.4691428987134714e-05\n",
      "Epoch 4664, Loss: 0.0014746184442628874, Final Batch Loss: 0.0010012299753725529\n",
      "Epoch 4665, Loss: 0.00020140872038609814, Final Batch Loss: 1.1172741324116942e-05\n",
      "Epoch 4666, Loss: 0.0004861614670517156, Final Batch Loss: 1.4646255294792354e-05\n",
      "Epoch 4667, Loss: 0.0002024429190896626, Final Batch Loss: 8.300549234263599e-05\n",
      "Epoch 4668, Loss: 5.8264154063181195e-05, Final Batch Loss: 3.293002737336792e-05\n",
      "Epoch 4669, Loss: 0.00024356539097425411, Final Batch Loss: 7.708193879807368e-05\n",
      "Epoch 4670, Loss: 0.00012504351980169304, Final Batch Loss: 3.0830145988147706e-05\n",
      "Epoch 4671, Loss: 0.00011542685933818575, Final Batch Loss: 8.570528007112443e-05\n",
      "Epoch 4672, Loss: 0.0005787845120721613, Final Batch Loss: 5.51991752217873e-06\n",
      "Epoch 4673, Loss: 0.0002318409874533245, Final Batch Loss: 1.8712196379055968e-06\n",
      "Epoch 4674, Loss: 0.0007659258708372363, Final Batch Loss: 0.0006913089309819043\n",
      "Epoch 4675, Loss: 0.00017867967653728556, Final Batch Loss: 7.116216875147074e-05\n",
      "Epoch 4676, Loss: 0.00016196713158933562, Final Batch Loss: 1.151713149738498e-05\n",
      "Epoch 4677, Loss: 8.266252143585007e-05, Final Batch Loss: 4.439859822014114e-06\n",
      "Epoch 4678, Loss: 0.00013005037965285737, Final Batch Loss: 6.079419108573347e-06\n",
      "Epoch 4679, Loss: 0.00024816115364956204, Final Batch Loss: 3.767268935916945e-05\n",
      "Epoch 4680, Loss: 0.0002737656511726527, Final Batch Loss: 5.405871706898324e-05\n",
      "Epoch 4681, Loss: 4.218440312797611e-05, Final Batch Loss: 1.6596988643868826e-05\n",
      "Epoch 4682, Loss: 0.00024879551529011223, Final Batch Loss: 0.00011929285392398015\n",
      "Epoch 4683, Loss: 8.891667266652803e-05, Final Batch Loss: 2.694636714295484e-05\n",
      "Epoch 4684, Loss: 0.0005174656203053019, Final Batch Loss: 3.6002334127260838e-06\n",
      "Epoch 4685, Loss: 0.00017946269008461968, Final Batch Loss: 1.0060462045657914e-06\n",
      "Epoch 4686, Loss: 0.0002281718257108878, Final Batch Loss: 4.819526566279819e-06\n",
      "Epoch 4687, Loss: 0.0037907439527771203, Final Batch Loss: 1.3161325114197098e-05\n",
      "Epoch 4688, Loss: 0.00023027456495583465, Final Batch Loss: 3.4140123261749977e-06\n",
      "Epoch 4689, Loss: 0.000390742080412565, Final Batch Loss: 1.7179537508127396e-06\n",
      "Epoch 4690, Loss: 5.7569540331314784e-05, Final Batch Loss: 2.9141039703972638e-05\n",
      "Epoch 4691, Loss: 8.667251256611053e-05, Final Batch Loss: 2.7906044124392793e-06\n",
      "Epoch 4692, Loss: 0.00395053180773175, Final Batch Loss: 2.3012007659417577e-05\n",
      "Epoch 4693, Loss: 0.0001232253571288311, Final Batch Loss: 5.8972646002075635e-06\n",
      "Epoch 4694, Loss: 0.00035516018181169784, Final Batch Loss: 3.76540151592053e-06\n",
      "Epoch 4695, Loss: 0.00013006487006350653, Final Batch Loss: 3.5145894798915833e-06\n",
      "Epoch 4696, Loss: 0.00032072448266262654, Final Batch Loss: 5.297022653394379e-06\n",
      "Epoch 4697, Loss: 0.00011364206477537664, Final Batch Loss: 2.703317477426026e-05\n",
      "Epoch 4698, Loss: 5.0788473345164675e-05, Final Batch Loss: 1.0806890713865869e-05\n",
      "Epoch 4699, Loss: 0.00013641180521517526, Final Batch Loss: 7.864386861911044e-05\n",
      "Epoch 4700, Loss: 0.0023856289863033453, Final Batch Loss: 0.0010370858944952488\n",
      "Epoch 4701, Loss: 9.597482039680472e-05, Final Batch Loss: 4.708558844868094e-05\n",
      "Epoch 4702, Loss: 0.032659909100857476, Final Batch Loss: 2.9696533601963893e-05\n",
      "Epoch 4703, Loss: 0.0001037719011947047, Final Batch Loss: 3.90782042813953e-06\n",
      "Epoch 4704, Loss: 0.00019382406298973365, Final Batch Loss: 0.00013872806448489428\n",
      "Epoch 4705, Loss: 0.0038032470570215082, Final Batch Loss: 5.122090897202725e-06\n",
      "Epoch 4706, Loss: 0.0021474943605426233, Final Batch Loss: 3.2158855901798233e-05\n",
      "Epoch 4707, Loss: 0.0010724111962190364, Final Batch Loss: 1.4523714526148979e-05\n",
      "Epoch 4708, Loss: 0.00012275978087927797, Final Batch Loss: 1.7465034034103155e-05\n",
      "Epoch 4709, Loss: 7.591710891574621e-05, Final Batch Loss: 1.5006856301624794e-05\n",
      "Epoch 4710, Loss: 0.0019916324438327138, Final Batch Loss: 1.3066639894532273e-06\n",
      "Epoch 4711, Loss: 0.0011030892601411324, Final Batch Loss: 3.064152770093642e-05\n",
      "Epoch 4712, Loss: 0.00018807848709911923, Final Batch Loss: 1.4252859728003386e-05\n",
      "Epoch 4713, Loss: 0.00011786674531322205, Final Batch Loss: 5.64380461582914e-05\n",
      "Epoch 4714, Loss: 0.0002511320903977321, Final Batch Loss: 3.525537522364175e-06\n",
      "Epoch 4715, Loss: 0.00015952986359479837, Final Batch Loss: 5.5384782172041014e-05\n",
      "Epoch 4716, Loss: 1.3600348779618798e-05, Final Batch Loss: 8.128309900712338e-07\n",
      "Epoch 4717, Loss: 7.110488695616368e-05, Final Batch Loss: 8.711085683899e-06\n",
      "Epoch 4718, Loss: 0.0007469155316357501, Final Batch Loss: 6.380112608894706e-05\n",
      "Epoch 4719, Loss: 0.0002134447753405766, Final Batch Loss: 1.0564186595729552e-05\n",
      "Epoch 4720, Loss: 5.783067035736167e-05, Final Batch Loss: 6.367511105054291e-06\n",
      "Epoch 4721, Loss: 0.0031919463435770012, Final Batch Loss: 0.003118830733001232\n",
      "Epoch 4722, Loss: 0.00028739579056491493, Final Batch Loss: 1.1206711860722862e-06\n",
      "Epoch 4723, Loss: 0.00029749961061042995, Final Batch Loss: 4.3622083012451185e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4724, Loss: 0.006931194378921646, Final Batch Loss: 4.452760549611412e-05\n",
      "Epoch 4725, Loss: 0.00017256209866900463, Final Batch Loss: 2.371825758018531e-05\n",
      "Epoch 4726, Loss: 7.72475682424556e-05, Final Batch Loss: 7.615214144607307e-06\n",
      "Epoch 4727, Loss: 0.00014525725418934599, Final Batch Loss: 4.917271508020349e-05\n",
      "Epoch 4728, Loss: 0.00019269162942237017, Final Batch Loss: 1.371411713080306e-06\n",
      "Epoch 4729, Loss: 0.00016080185559985694, Final Batch Loss: 1.1903075574082322e-05\n",
      "Epoch 4730, Loss: 0.001221694192281575, Final Batch Loss: 0.0004227870376780629\n",
      "Epoch 4731, Loss: 7.824887507013045e-05, Final Batch Loss: 7.269744855875615e-06\n",
      "Epoch 4732, Loss: 0.0009808276977310015, Final Batch Loss: 8.932752280088607e-06\n",
      "Epoch 4733, Loss: 5.981333083582285e-05, Final Batch Loss: 2.5719713448779657e-05\n",
      "Epoch 4734, Loss: 0.0003042022087811347, Final Batch Loss: 3.235288386349566e-05\n",
      "Epoch 4735, Loss: 0.0009019596654979978, Final Batch Loss: 8.74110082804691e-06\n",
      "Epoch 4736, Loss: 0.0004169073083630792, Final Batch Loss: 1.452098558729631e-06\n",
      "Epoch 4737, Loss: 7.426831780321663e-05, Final Batch Loss: 9.428664270672016e-06\n",
      "Epoch 4738, Loss: 0.0005688061155524338, Final Batch Loss: 0.00046216894406825304\n",
      "Epoch 4739, Loss: 0.0002988016649396741, Final Batch Loss: 4.079677819390781e-05\n",
      "Epoch 4740, Loss: 0.0001509380840616359, Final Batch Loss: 7.52315972931683e-05\n",
      "Epoch 4741, Loss: 0.0013253382953735127, Final Batch Loss: 1.7535714505356736e-05\n",
      "Epoch 4742, Loss: 0.00037343970393521886, Final Batch Loss: 0.00010920607746811584\n",
      "Epoch 4743, Loss: 0.00014971695145504782, Final Batch Loss: 9.054459042090457e-06\n",
      "Epoch 4744, Loss: 0.021477565733221127, Final Batch Loss: 0.0214653629809618\n",
      "Epoch 4745, Loss: 0.000104117852743002, Final Batch Loss: 4.648968388210051e-05\n",
      "Epoch 4746, Loss: 0.00022960023670748342, Final Batch Loss: 0.00010302518785465509\n",
      "Epoch 4747, Loss: 0.008654004022446316, Final Batch Loss: 2.7206253434997052e-05\n",
      "Epoch 4748, Loss: 0.011275558583292877, Final Batch Loss: 4.8828773287823424e-05\n",
      "Epoch 4749, Loss: 0.00017592143831279827, Final Batch Loss: 7.12342716724379e-06\n",
      "Epoch 4750, Loss: 0.003257631493397639, Final Batch Loss: 1.0709680282161571e-05\n",
      "Epoch 4751, Loss: 0.002242669541374198, Final Batch Loss: 0.002051039133220911\n",
      "Epoch 4752, Loss: 0.00030762338792555965, Final Batch Loss: 8.836396591505036e-05\n",
      "Epoch 4753, Loss: 0.014716673798830016, Final Batch Loss: 0.0026268272195011377\n",
      "Epoch 4754, Loss: 0.03554047819125117, Final Batch Loss: 0.0002586025220807642\n",
      "Epoch 4755, Loss: 0.0004044884681206895, Final Batch Loss: 2.5891205950756557e-05\n",
      "Epoch 4756, Loss: 0.0010947882760774519, Final Batch Loss: 6.73173371978919e-06\n",
      "Epoch 4757, Loss: 0.00027951885203947313, Final Batch Loss: 2.6411918952362612e-05\n",
      "Epoch 4758, Loss: 0.03711433413263876, Final Batch Loss: 3.735795326065272e-05\n",
      "Epoch 4759, Loss: 0.0009014053830469493, Final Batch Loss: 0.00036971253575757146\n",
      "Epoch 4760, Loss: 0.004399214085424319, Final Batch Loss: 0.00014778555487282574\n",
      "Epoch 4761, Loss: 0.006467273487942293, Final Batch Loss: 0.00033487327164039016\n",
      "Epoch 4762, Loss: 0.0020906642375848605, Final Batch Loss: 1.4327596545626875e-05\n",
      "Epoch 4763, Loss: 0.0003451907505223062, Final Batch Loss: 0.00012795945804100484\n",
      "Epoch 4764, Loss: 0.0013765312505711336, Final Batch Loss: 0.0006334923091344535\n",
      "Epoch 4765, Loss: 0.007203081047919113, Final Batch Loss: 0.0042974092066287994\n",
      "Epoch 4766, Loss: 0.0007847317174309865, Final Batch Loss: 6.811049388488755e-05\n",
      "Epoch 4767, Loss: 0.0009804525616345927, Final Batch Loss: 0.00014450594608206302\n",
      "Epoch 4768, Loss: 0.00041781238360272255, Final Batch Loss: 5.0742124585667625e-05\n",
      "Epoch 4769, Loss: 0.0004853839909628732, Final Batch Loss: 0.00039695939631201327\n",
      "Epoch 4770, Loss: 0.00019978050568170147, Final Batch Loss: 9.240494364348706e-06\n",
      "Epoch 4771, Loss: 0.002571729099145159, Final Batch Loss: 0.0018483995227143168\n",
      "Epoch 4772, Loss: 0.002326786910998635, Final Batch Loss: 3.379186091478914e-05\n",
      "Epoch 4773, Loss: 0.0012056347522957367, Final Batch Loss: 0.000827840412966907\n",
      "Epoch 4774, Loss: 0.00048820253687154036, Final Batch Loss: 9.56479852902703e-05\n",
      "Epoch 4775, Loss: 0.002134208118150127, Final Batch Loss: 1.6762811355874874e-05\n",
      "Epoch 4776, Loss: 0.00019664510455186246, Final Batch Loss: 6.668837886536494e-05\n",
      "Epoch 4777, Loss: 0.00047519263171125203, Final Batch Loss: 4.36259651905857e-05\n",
      "Epoch 4778, Loss: 0.0011892427028215025, Final Batch Loss: 0.0008364387904293835\n",
      "Epoch 4779, Loss: 0.0006805174580222229, Final Batch Loss: 1.609487117093522e-05\n",
      "Epoch 4780, Loss: 0.005687064248377283, Final Batch Loss: 7.690511120017618e-05\n",
      "Epoch 4781, Loss: 0.0002212534709542524, Final Batch Loss: 6.652763113379478e-05\n",
      "Epoch 4782, Loss: 0.0003008532767125871, Final Batch Loss: 9.169692930299789e-06\n",
      "Epoch 4783, Loss: 0.001129065667555551, Final Batch Loss: 0.0001746503112372011\n",
      "Epoch 4784, Loss: 0.0013383563182287617, Final Batch Loss: 1.9339417121955194e-05\n",
      "Epoch 4785, Loss: 0.0002456260335748084, Final Batch Loss: 2.2165768314152956e-05\n",
      "Epoch 4786, Loss: 0.0011929983702430036, Final Batch Loss: 6.431735528167337e-05\n",
      "Epoch 4787, Loss: 0.00013070615841570543, Final Batch Loss: 9.776230399438646e-06\n",
      "Epoch 4788, Loss: 0.0003476245974525227, Final Batch Loss: 0.00013548364222515374\n",
      "Epoch 4789, Loss: 0.0001299601526625338, Final Batch Loss: 1.3240848602436017e-05\n",
      "Epoch 4790, Loss: 0.00044570173622560105, Final Batch Loss: 7.579626253573224e-05\n",
      "Epoch 4791, Loss: 0.00014325212396215647, Final Batch Loss: 4.839233952225186e-05\n",
      "Epoch 4792, Loss: 0.000267080527919461, Final Batch Loss: 5.621969830826856e-05\n",
      "Epoch 4793, Loss: 0.00037058969701320166, Final Batch Loss: 1.3280027815198991e-05\n",
      "Epoch 4794, Loss: 0.0028576494978551636, Final Batch Loss: 5.547469845623709e-05\n",
      "Epoch 4795, Loss: 0.00015471862570848316, Final Batch Loss: 1.929709287651349e-05\n",
      "Epoch 4796, Loss: 0.0009237091799150221, Final Batch Loss: 6.418046541512012e-05\n",
      "Epoch 4797, Loss: 0.02780230805365136, Final Batch Loss: 4.146587525610812e-05\n",
      "Epoch 4798, Loss: 0.00056211868468381, Final Batch Loss: 0.00021288456628099084\n",
      "Epoch 4799, Loss: 0.001041237067511247, Final Batch Loss: 1.5052642083901446e-05\n",
      "Epoch 4800, Loss: 0.0003767314337892458, Final Batch Loss: 1.5865272871451452e-05\n",
      "Epoch 4801, Loss: 0.011789827825850807, Final Batch Loss: 0.00012256923946551979\n",
      "Epoch 4802, Loss: 0.000548751506357803, Final Batch Loss: 1.484184576838743e-05\n",
      "Epoch 4803, Loss: 0.0002917019464803161, Final Batch Loss: 7.059768540784717e-05\n",
      "Epoch 4804, Loss: 0.00025990339781856164, Final Batch Loss: 3.9723112422507256e-05\n",
      "Epoch 4805, Loss: 9.635003334551584e-05, Final Batch Loss: 4.2022138586617075e-06\n",
      "Epoch 4806, Loss: 0.0002912044401455205, Final Batch Loss: 3.2654974347678944e-05\n",
      "Epoch 4807, Loss: 0.001201152157591423, Final Batch Loss: 2.96629368676804e-05\n",
      "Epoch 4808, Loss: 0.00010161918453377439, Final Batch Loss: 4.101014565094374e-05\n",
      "Epoch 4809, Loss: 0.00014355293797052582, Final Batch Loss: 7.3393271122768056e-06\n",
      "Epoch 4810, Loss: 0.0003955784359277459, Final Batch Loss: 1.080672700481955e-05\n",
      "Epoch 4811, Loss: 0.0005036641632614192, Final Batch Loss: 2.8949625630048104e-05\n",
      "Epoch 4812, Loss: 0.0002929227539425483, Final Batch Loss: 3.271002788096666e-05\n",
      "Epoch 4813, Loss: 0.0004977376884198748, Final Batch Loss: 9.599306213203818e-05\n",
      "Epoch 4814, Loss: 0.0004240375528752338, Final Batch Loss: 4.722684025182389e-05\n",
      "Epoch 4815, Loss: 0.0008451765570498537, Final Batch Loss: 3.299393938505091e-05\n",
      "Epoch 4816, Loss: 0.0006237153793335892, Final Batch Loss: 1.240381971001625e-05\n",
      "Epoch 4817, Loss: 0.00025398421894351486, Final Batch Loss: 6.971127277211053e-06\n",
      "Epoch 4818, Loss: 0.000558285100851208, Final Batch Loss: 0.00022251970949582756\n",
      "Epoch 4819, Loss: 0.0004658107827708591, Final Batch Loss: 3.360789196449332e-05\n",
      "Epoch 4820, Loss: 0.00012196579928058782, Final Batch Loss: 3.700279557961039e-05\n",
      "Epoch 4821, Loss: 0.00034738396607281175, Final Batch Loss: 0.00028064317302778363\n",
      "Epoch 4822, Loss: 0.008031114608456846, Final Batch Loss: 1.258249903912656e-05\n",
      "Epoch 4823, Loss: 0.0006892718101880746, Final Batch Loss: 7.651332271052524e-05\n",
      "Epoch 4824, Loss: 0.0024236892140834243, Final Batch Loss: 0.0012073991820216179\n",
      "Epoch 4825, Loss: 0.000576966780499788, Final Batch Loss: 2.463377677486278e-05\n",
      "Epoch 4826, Loss: 0.0005670028758686385, Final Batch Loss: 0.0001364673225907609\n",
      "Epoch 4827, Loss: 0.0003013494979313691, Final Batch Loss: 4.6700090024387464e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4828, Loss: 0.00024233564545284025, Final Batch Loss: 4.322435415815562e-05\n",
      "Epoch 4829, Loss: 0.00012632336984097492, Final Batch Loss: 1.99015557882376e-05\n",
      "Epoch 4830, Loss: 0.00042743828635138925, Final Batch Loss: 0.0003392650105524808\n",
      "Epoch 4831, Loss: 0.0007941006126657157, Final Batch Loss: 0.0006262278184294701\n",
      "Epoch 4832, Loss: 0.0003640674965481594, Final Batch Loss: 0.00016195091302506626\n",
      "Epoch 4833, Loss: 0.00040844091927283444, Final Batch Loss: 6.0788748669438064e-05\n",
      "Epoch 4834, Loss: 0.00033214688937732717, Final Batch Loss: 5.9336500271456316e-05\n",
      "Epoch 4835, Loss: 0.0009753576377988793, Final Batch Loss: 0.00020548551401589066\n",
      "Epoch 4836, Loss: 0.0007624853114975849, Final Batch Loss: 0.00010678108810679987\n",
      "Epoch 4837, Loss: 0.008107685112918261, Final Batch Loss: 0.007571594323962927\n",
      "Epoch 4838, Loss: 0.0009367812863274594, Final Batch Loss: 0.0001140690510510467\n",
      "Epoch 4839, Loss: 0.0001963591857929714, Final Batch Loss: 5.3190877224551514e-05\n",
      "Epoch 4840, Loss: 0.0019149674553773366, Final Batch Loss: 1.9499559130053967e-05\n",
      "Epoch 4841, Loss: 7.057429047563346e-05, Final Batch Loss: 8.027886906347703e-06\n",
      "Epoch 4842, Loss: 0.004349981600626052, Final Batch Loss: 1.723188233881956e-06\n",
      "Epoch 4843, Loss: 0.00027838305868499447, Final Batch Loss: 0.0001389384997310117\n",
      "Epoch 4844, Loss: 0.00033822076193246176, Final Batch Loss: 1.773609074007254e-05\n",
      "Epoch 4845, Loss: 0.0002936345172201982, Final Batch Loss: 5.8601897762855515e-05\n",
      "Epoch 4846, Loss: 0.0006027564213582082, Final Batch Loss: 0.0004323223838582635\n",
      "Epoch 4847, Loss: 5.7928465139411855e-05, Final Batch Loss: 9.35194384510396e-06\n",
      "Epoch 4848, Loss: 0.0009358846787108632, Final Batch Loss: 2.154744379367912e-06\n",
      "Epoch 4849, Loss: 0.0022386361233657226, Final Batch Loss: 2.6121328119188547e-05\n",
      "Epoch 4850, Loss: 0.0105333049523324, Final Batch Loss: 9.224392124451697e-05\n",
      "Epoch 4851, Loss: 0.000541319745934743, Final Batch Loss: 1.3959691386844497e-05\n",
      "Epoch 4852, Loss: 0.00042996188312827144, Final Batch Loss: 1.1905892279173713e-05\n",
      "Epoch 4853, Loss: 0.0018869425100547232, Final Batch Loss: 0.0017764928052201867\n",
      "Epoch 4854, Loss: 0.0002659808851603884, Final Batch Loss: 0.00015644700033590198\n",
      "Epoch 4855, Loss: 0.000883864860952599, Final Batch Loss: 4.1399933252250776e-05\n",
      "Epoch 4856, Loss: 0.0003127259151369799, Final Batch Loss: 0.00015261762018781155\n",
      "Epoch 4857, Loss: 0.0008833837309794035, Final Batch Loss: 0.00014737747551407665\n",
      "Epoch 4858, Loss: 0.00019113831331196707, Final Batch Loss: 1.5187875760602765e-05\n",
      "Epoch 4859, Loss: 5.8482155964156846e-05, Final Batch Loss: 2.9267637728480622e-05\n",
      "Epoch 4860, Loss: 0.00015657262338208966, Final Batch Loss: 7.441748311975971e-05\n",
      "Epoch 4861, Loss: 0.000656295062526624, Final Batch Loss: 6.85368149788701e-06\n",
      "Epoch 4862, Loss: 6.420054978661938e-05, Final Batch Loss: 1.844733560574241e-05\n",
      "Epoch 4863, Loss: 0.003671550463877793, Final Batch Loss: 0.00030576676363125443\n",
      "Epoch 4864, Loss: 0.000590506835578708, Final Batch Loss: 3.69064073311165e-05\n",
      "Epoch 4865, Loss: 0.0004561709911286016, Final Batch Loss: 1.8611501218401827e-05\n",
      "Epoch 4866, Loss: 0.0007433792570736841, Final Batch Loss: 2.3571459678350948e-05\n",
      "Epoch 4867, Loss: 0.00012901282025268301, Final Batch Loss: 9.197083272738382e-06\n",
      "Epoch 4868, Loss: 0.00013058362128504086, Final Batch Loss: 7.316662959055975e-05\n",
      "Epoch 4869, Loss: 4.5454425389834796e-05, Final Batch Loss: 1.6292837244691327e-05\n",
      "Epoch 4870, Loss: 7.87411654528114e-05, Final Batch Loss: 1.6803312973934226e-05\n",
      "Epoch 4871, Loss: 0.00022540571490026196, Final Batch Loss: 3.2289473892888054e-05\n",
      "Epoch 4872, Loss: 0.0017191681981785223, Final Batch Loss: 0.00014577172987628728\n",
      "Epoch 4873, Loss: 4.8996290388458874e-05, Final Batch Loss: 2.31197991524823e-05\n",
      "Epoch 4874, Loss: 0.00029442860795825254, Final Batch Loss: 0.00018126795475836843\n",
      "Epoch 4875, Loss: 0.0009889498064694635, Final Batch Loss: 6.940160801605089e-06\n",
      "Epoch 4876, Loss: 0.0003550740003674946, Final Batch Loss: 9.765627737579052e-07\n",
      "Epoch 4877, Loss: 8.687254285177914e-05, Final Batch Loss: 1.689167220320087e-05\n",
      "Epoch 4878, Loss: 0.00017725397174217505, Final Batch Loss: 0.00013700732961297035\n",
      "Epoch 4879, Loss: 4.881053087046894e-05, Final Batch Loss: 2.6812833766598487e-06\n",
      "Epoch 4880, Loss: 0.0003770658561847995, Final Batch Loss: 0.0003643339150585234\n",
      "Epoch 4881, Loss: 0.00013178724634599348, Final Batch Loss: 3.5536610084818676e-05\n",
      "Epoch 4882, Loss: 3.482315844394179e-05, Final Batch Loss: 1.7971466377275647e-06\n",
      "Epoch 4883, Loss: 0.00012051810927005135, Final Batch Loss: 4.569853444991168e-06\n",
      "Epoch 4884, Loss: 5.2903126743331086e-05, Final Batch Loss: 1.7395506802131422e-05\n",
      "Epoch 4885, Loss: 0.00011979017062913044, Final Batch Loss: 3.744660352822393e-05\n",
      "Epoch 4886, Loss: 0.000228602870265604, Final Batch Loss: 0.00011894653289346024\n",
      "Epoch 4887, Loss: 9.944551311491523e-05, Final Batch Loss: 2.9397186153801158e-05\n",
      "Epoch 4888, Loss: 0.0005192130847717635, Final Batch Loss: 0.0003203842497896403\n",
      "Epoch 4889, Loss: 0.002437606124658487, Final Batch Loss: 4.9054659029934555e-05\n",
      "Epoch 4890, Loss: 0.00025569350236764876, Final Batch Loss: 3.8197864341782406e-05\n",
      "Epoch 4891, Loss: 7.799632567184744e-05, Final Batch Loss: 7.631385415152181e-06\n",
      "Epoch 4892, Loss: 4.120400592455553e-05, Final Batch Loss: 2.3117370801628567e-05\n",
      "Epoch 4893, Loss: 0.0006461209090957709, Final Batch Loss: 6.954110176593531e-06\n",
      "Epoch 4894, Loss: 0.000671524085191777, Final Batch Loss: 5.347454134607688e-06\n",
      "Epoch 4895, Loss: 0.0004016280772702885, Final Batch Loss: 2.260885594296269e-06\n",
      "Epoch 4896, Loss: 9.666733603808098e-05, Final Batch Loss: 6.075130841054488e-06\n",
      "Epoch 4897, Loss: 7.41508006285585e-05, Final Batch Loss: 1.2404212611727417e-05\n",
      "Epoch 4898, Loss: 0.0016013793606930449, Final Batch Loss: 0.001568885170854628\n",
      "Epoch 4899, Loss: 9.036502069648122e-05, Final Batch Loss: 2.715330629143864e-05\n",
      "Epoch 4900, Loss: 9.724887286211015e-05, Final Batch Loss: 8.905700269679073e-06\n",
      "Epoch 4901, Loss: 4.576252331389696e-05, Final Batch Loss: 2.065945773210842e-05\n",
      "Epoch 4902, Loss: 0.0002234118283013231, Final Batch Loss: 0.0001314035471295938\n",
      "Epoch 4903, Loss: 6.151512707219808e-05, Final Batch Loss: 5.845510258950526e-06\n",
      "Epoch 4904, Loss: 0.0001407518811902264, Final Batch Loss: 6.470299558714032e-05\n",
      "Epoch 4905, Loss: 0.00028594236755452584, Final Batch Loss: 1.8189832189818844e-05\n",
      "Epoch 4906, Loss: 0.0005347367698504968, Final Batch Loss: 0.0004988422151654959\n",
      "Epoch 4907, Loss: 0.0002493003680683614, Final Batch Loss: 1.7053169358405285e-05\n",
      "Epoch 4908, Loss: 0.00012971750265933224, Final Batch Loss: 9.864137973636389e-05\n",
      "Epoch 4909, Loss: 2.4230701455962844e-05, Final Batch Loss: 5.709433935408015e-06\n",
      "Epoch 4910, Loss: 0.00023968473033164628, Final Batch Loss: 5.291773413773626e-05\n",
      "Epoch 4911, Loss: 0.00034905573784271837, Final Batch Loss: 0.00031773175578564405\n",
      "Epoch 4912, Loss: 8.203210063584265e-05, Final Batch Loss: 1.6932805010583252e-05\n",
      "Epoch 4913, Loss: 7.391986810034723e-05, Final Batch Loss: 2.8788723284378648e-05\n",
      "Epoch 4914, Loss: 6.72922255944286e-05, Final Batch Loss: 4.658702891902067e-05\n",
      "Epoch 4915, Loss: 0.00018270647615281632, Final Batch Loss: 0.00013251512427814305\n",
      "Epoch 4916, Loss: 0.00010686230280043674, Final Batch Loss: 4.36564869232825e-06\n",
      "Epoch 4917, Loss: 0.0004124939935081784, Final Batch Loss: 0.00018013898807112128\n",
      "Epoch 4918, Loss: 0.00021467104897965328, Final Batch Loss: 2.067316927423235e-05\n",
      "Epoch 4919, Loss: 7.868752572903759e-05, Final Batch Loss: 6.951895102247363e-06\n",
      "Epoch 4920, Loss: 5.320355546700739e-05, Final Batch Loss: 1.6426537285951781e-06\n",
      "Epoch 4921, Loss: 5.481245125338319e-05, Final Batch Loss: 3.795904831349617e-06\n",
      "Epoch 4922, Loss: 4.118844663025811e-05, Final Batch Loss: 2.7815362955152523e-06\n",
      "Epoch 4923, Loss: 0.0002117585411269829, Final Batch Loss: 0.00019521432113833725\n",
      "Epoch 4924, Loss: 8.180800796253607e-05, Final Batch Loss: 1.060529666574439e-05\n",
      "Epoch 4925, Loss: 6.169700117197863e-05, Final Batch Loss: 2.9867732109778444e-07\n",
      "Epoch 4926, Loss: 0.00011271839827031727, Final Batch Loss: 1.5247713918142836e-06\n",
      "Epoch 4927, Loss: 0.00026145856088533037, Final Batch Loss: 1.5876229326750035e-06\n",
      "Epoch 4928, Loss: 4.0899803934735246e-05, Final Batch Loss: 1.5433408407261595e-05\n",
      "Epoch 4929, Loss: 5.5009232255542884e-05, Final Batch Loss: 1.8412916688248515e-05\n",
      "Epoch 4930, Loss: 0.0004071241983183427, Final Batch Loss: 1.4726881090609822e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4931, Loss: 9.386796978105849e-05, Final Batch Loss: 2.5625906346249394e-05\n",
      "Epoch 4932, Loss: 5.5552510730194626e-05, Final Batch Loss: 8.389049071411137e-06\n",
      "Epoch 4933, Loss: 0.0007503339488721394, Final Batch Loss: 0.00021876687242183834\n",
      "Epoch 4934, Loss: 7.03995060575835e-05, Final Batch Loss: 2.2317781258607283e-05\n",
      "Epoch 4935, Loss: 0.0004265225088602165, Final Batch Loss: 9.077445429284126e-05\n",
      "Epoch 4936, Loss: 0.00013787578564006253, Final Batch Loss: 2.712061814236222e-06\n",
      "Epoch 4937, Loss: 2.435721057736373e-05, Final Batch Loss: 5.1859801715181675e-06\n",
      "Epoch 4938, Loss: 0.00022327225087792613, Final Batch Loss: 7.831669790903106e-05\n",
      "Epoch 4939, Loss: 7.178835903687286e-05, Final Batch Loss: 2.9398374863376375e-06\n",
      "Epoch 4940, Loss: 0.0006075201872590696, Final Batch Loss: 5.381572918849997e-05\n",
      "Epoch 4941, Loss: 0.00011143120383394489, Final Batch Loss: 9.830267663346604e-05\n",
      "Epoch 4942, Loss: 0.000359520823622006, Final Batch Loss: 1.4137178368400782e-05\n",
      "Epoch 4943, Loss: 0.0013573991928979012, Final Batch Loss: 0.001273833098821342\n",
      "Epoch 4944, Loss: 5.416123303803033e-05, Final Batch Loss: 3.939134785468923e-06\n",
      "Epoch 4945, Loss: 0.00016242773210706218, Final Batch Loss: 2.1042940261395415e-06\n",
      "Epoch 4946, Loss: 9.02446479358332e-05, Final Batch Loss: 1.8457023998053046e-06\n",
      "Epoch 4947, Loss: 7.95291930444364e-05, Final Batch Loss: 1.7450942323193885e-05\n",
      "Epoch 4948, Loss: 4.224000440444797e-05, Final Batch Loss: 7.33271690478432e-06\n",
      "Epoch 4949, Loss: 7.491125302294677e-05, Final Batch Loss: 8.058066669036634e-06\n",
      "Epoch 4950, Loss: 0.00034427603185349653, Final Batch Loss: 0.0002213880798080936\n",
      "Epoch 4951, Loss: 0.0003069718004553579, Final Batch Loss: 0.00010145284613827243\n",
      "Epoch 4952, Loss: 0.0005258332821540534, Final Batch Loss: 0.00033924137824214995\n",
      "Epoch 4953, Loss: 3.430696256145893e-05, Final Batch Loss: 1.966001400433015e-05\n",
      "Epoch 4954, Loss: 0.0002220052324446442, Final Batch Loss: 0.00016830640379339457\n",
      "Epoch 4955, Loss: 5.564842558669625e-05, Final Batch Loss: 4.888807961833663e-05\n",
      "Epoch 4956, Loss: 0.0003819678898935308, Final Batch Loss: 0.0003466358466539532\n",
      "Epoch 4957, Loss: 0.0009566437183821108, Final Batch Loss: 0.0001782457111403346\n",
      "Epoch 4958, Loss: 0.0007588197258883156, Final Batch Loss: 2.4307080821017735e-05\n",
      "Epoch 4959, Loss: 7.863474425562345e-05, Final Batch Loss: 2.8058597308699973e-05\n",
      "Epoch 4960, Loss: 9.26109721604007e-05, Final Batch Loss: 1.3031922208028845e-05\n",
      "Epoch 4961, Loss: 0.0004164893176721307, Final Batch Loss: 9.752108098837198e-07\n",
      "Epoch 4962, Loss: 0.0038112836997470367, Final Batch Loss: 0.00033053531660698354\n",
      "Epoch 4963, Loss: 0.06953712223867115, Final Batch Loss: 2.972993752337061e-05\n",
      "Epoch 4964, Loss: 0.0005989806586512714, Final Batch Loss: 9.203692570736166e-06\n",
      "Epoch 4965, Loss: 8.127254545797769e-05, Final Batch Loss: 4.249975609127432e-05\n",
      "Epoch 4966, Loss: 0.00012242062166478718, Final Batch Loss: 1.8423064830130897e-05\n",
      "Epoch 4967, Loss: 0.0013082677523925668, Final Batch Loss: 1.9735913156182505e-05\n",
      "Epoch 4968, Loss: 0.0004185217685517273, Final Batch Loss: 4.347376489022281e-06\n",
      "Epoch 4969, Loss: 0.00040623948007123545, Final Batch Loss: 0.0002099455741699785\n",
      "Epoch 4970, Loss: 0.007104095674094424, Final Batch Loss: 3.65896376024466e-05\n",
      "Epoch 4971, Loss: 0.008303886483190581, Final Batch Loss: 0.0007185434806160629\n",
      "Epoch 4972, Loss: 0.00026302900914743077, Final Batch Loss: 1.465343484596815e-05\n",
      "Epoch 4973, Loss: 0.0007340121155721135, Final Batch Loss: 1.614779102965258e-05\n",
      "Epoch 4974, Loss: 0.01533698035927955, Final Batch Loss: 1.788511872291565e-05\n",
      "Epoch 4975, Loss: 0.00018356212285652873, Final Batch Loss: 6.607522664126009e-05\n",
      "Epoch 4976, Loss: 0.0033940034040824685, Final Batch Loss: 4.433036792761413e-06\n",
      "Epoch 4977, Loss: 0.015613124036462978, Final Batch Loss: 0.008954111486673355\n",
      "Epoch 4978, Loss: 0.0014314008876681328, Final Batch Loss: 9.860340651357546e-05\n",
      "Epoch 4979, Loss: 0.0019184504562872462, Final Batch Loss: 6.279680383158848e-05\n",
      "Epoch 4980, Loss: 0.00346153078135103, Final Batch Loss: 0.0005161336739547551\n",
      "Epoch 4981, Loss: 0.01082026846415829, Final Batch Loss: 0.0004962551174685359\n",
      "Epoch 4982, Loss: 0.0005749298625232768, Final Batch Loss: 1.1318109500280116e-05\n",
      "Epoch 4983, Loss: 0.0002861617242615466, Final Batch Loss: 3.2896962238737615e-06\n",
      "Epoch 4984, Loss: 0.0005235350440671027, Final Batch Loss: 4.426298801263329e-06\n",
      "Epoch 4985, Loss: 0.0003344860379002057, Final Batch Loss: 9.790287003852427e-05\n",
      "Epoch 4986, Loss: 0.0015029023779788986, Final Batch Loss: 0.00037820564466528594\n",
      "Epoch 4987, Loss: 0.003218031551114109, Final Batch Loss: 0.00031574873719364405\n",
      "Epoch 4988, Loss: 0.00022593649009650107, Final Batch Loss: 5.306105958879925e-05\n",
      "Epoch 4989, Loss: 0.00017519847096991725, Final Batch Loss: 3.785119770327583e-05\n",
      "Epoch 4990, Loss: 5.852431468156283e-05, Final Batch Loss: 1.0599527740851045e-05\n",
      "Epoch 4991, Loss: 0.00014552923494193237, Final Batch Loss: 9.006043001136277e-06\n",
      "Epoch 4992, Loss: 0.00018424104837322375, Final Batch Loss: 8.211143722292036e-06\n",
      "Epoch 4993, Loss: 0.0004005938035334111, Final Batch Loss: 1.236640218849061e-05\n",
      "Epoch 4994, Loss: 0.009840228263783501, Final Batch Loss: 1.0393228876637295e-05\n",
      "Epoch 4995, Loss: 0.0005701909358322155, Final Batch Loss: 0.00023186368343885988\n",
      "Epoch 4996, Loss: 0.0006299346516698279, Final Batch Loss: 2.199238451794372e-06\n",
      "Epoch 4997, Loss: 0.00029406870089587756, Final Batch Loss: 0.00013792875688523054\n",
      "Epoch 4998, Loss: 0.004801631891211855, Final Batch Loss: 8.32002770039253e-05\n",
      "Epoch 4999, Loss: 0.0020191149724269053, Final Batch Loss: 1.5996467482182197e-05\n",
      "Epoch 5000, Loss: 0.00013678727191290818, Final Batch Loss: 4.9814966587291565e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  0  0]\n",
      " [ 0 45  0]\n",
      " [ 0  0 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        71\n",
      "           1      1.000     1.000     1.000        45\n",
      "           2      1.000     1.000     1.000        49\n",
      "\n",
      "    accuracy                          1.000       165\n",
      "   macro avg      1.000     1.000     1.000       165\n",
      "weighted avg      1.000     1.000     1.000       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../../saved_models/UCI 3 Label 8 Subject Classifier Ablation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
