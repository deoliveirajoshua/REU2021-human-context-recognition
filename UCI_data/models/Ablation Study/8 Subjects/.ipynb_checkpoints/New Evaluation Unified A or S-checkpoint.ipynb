{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '390 fBodyAccJerk-bandsEnergy()-1,16',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 8)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11, 14, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.793289542198181, Final Batch Loss: 1.1685408353805542\n",
      "Epoch 2, Loss: 5.746871590614319, Final Batch Loss: 1.1598280668258667\n",
      "Epoch 3, Loss: 5.720897793769836, Final Batch Loss: 1.184833288192749\n",
      "Epoch 4, Loss: 5.618387579917908, Final Batch Loss: 1.1261212825775146\n",
      "Epoch 5, Loss: 5.512786149978638, Final Batch Loss: 1.081322431564331\n",
      "Epoch 6, Loss: 5.540046691894531, Final Batch Loss: 1.1708849668502808\n",
      "Epoch 7, Loss: 5.27354884147644, Final Batch Loss: 0.9860907793045044\n",
      "Epoch 8, Loss: 5.095059633255005, Final Batch Loss: 0.8904725313186646\n",
      "Epoch 9, Loss: 5.149024248123169, Final Batch Loss: 1.0956534147262573\n",
      "Epoch 10, Loss: 4.892622411251068, Final Batch Loss: 0.9938508868217468\n",
      "Epoch 11, Loss: 4.694000780582428, Final Batch Loss: 0.9760113954544067\n",
      "Epoch 12, Loss: 4.285695493221283, Final Batch Loss: 0.8030155301094055\n",
      "Epoch 13, Loss: 4.1782315373420715, Final Batch Loss: 0.9280681610107422\n",
      "Epoch 14, Loss: 3.7054680585861206, Final Batch Loss: 0.6711429357528687\n",
      "Epoch 15, Loss: 3.545481264591217, Final Batch Loss: 0.7447251081466675\n",
      "Epoch 16, Loss: 3.1592955589294434, Final Batch Loss: 0.5625818967819214\n",
      "Epoch 17, Loss: 2.8995189666748047, Final Batch Loss: 0.5044381022453308\n",
      "Epoch 18, Loss: 2.676901191473007, Final Batch Loss: 0.4840620458126068\n",
      "Epoch 19, Loss: 2.5735760927200317, Final Batch Loss: 0.5846444964408875\n",
      "Epoch 20, Loss: 2.333064615726471, Final Batch Loss: 0.48244819045066833\n",
      "Epoch 21, Loss: 2.0063164234161377, Final Batch Loss: 0.32830747961997986\n",
      "Epoch 22, Loss: 1.9097214043140411, Final Batch Loss: 0.34331703186035156\n",
      "Epoch 23, Loss: 1.799956202507019, Final Batch Loss: 0.3554878234863281\n",
      "Epoch 24, Loss: 1.4555808156728745, Final Batch Loss: 0.1068267971277237\n",
      "Epoch 25, Loss: 1.5569155514240265, Final Batch Loss: 0.2931336462497711\n",
      "Epoch 26, Loss: 1.341421589255333, Final Batch Loss: 0.19549261033535004\n",
      "Epoch 27, Loss: 1.1236734166741371, Final Batch Loss: 0.10587071627378464\n",
      "Epoch 28, Loss: 1.1229182481765747, Final Batch Loss: 0.1881655603647232\n",
      "Epoch 29, Loss: 0.9672737866640091, Final Batch Loss: 0.16656331717967987\n",
      "Epoch 30, Loss: 0.8858073651790619, Final Batch Loss: 0.16614072024822235\n",
      "Epoch 31, Loss: 0.9510486721992493, Final Batch Loss: 0.29757434129714966\n",
      "Epoch 32, Loss: 0.8175158798694611, Final Batch Loss: 0.15236441791057587\n",
      "Epoch 33, Loss: 0.7804736793041229, Final Batch Loss: 0.17836856842041016\n",
      "Epoch 34, Loss: 0.8881643265485764, Final Batch Loss: 0.24148771166801453\n",
      "Epoch 35, Loss: 0.6701615527272224, Final Batch Loss: 0.013707436621189117\n",
      "Epoch 36, Loss: 0.8569664657115936, Final Batch Loss: 0.36342519521713257\n",
      "Epoch 37, Loss: 0.7133782841265202, Final Batch Loss: 0.05795053020119667\n",
      "Epoch 38, Loss: 0.9849365800619125, Final Batch Loss: 0.38705974817276\n",
      "Epoch 39, Loss: 0.805237703025341, Final Batch Loss: 0.2998945415019989\n",
      "Epoch 40, Loss: 0.6393526196479797, Final Batch Loss: 0.07747001200914383\n",
      "Epoch 41, Loss: 0.5478958245366812, Final Batch Loss: 0.020044824108481407\n",
      "Epoch 42, Loss: 0.5196100659668446, Final Batch Loss: 0.018217820674180984\n",
      "Epoch 43, Loss: 0.5318790040910244, Final Batch Loss: 0.06180413439869881\n",
      "Epoch 44, Loss: 0.5546097606420517, Final Batch Loss: 0.0671534314751625\n",
      "Epoch 45, Loss: 0.7798377349972725, Final Batch Loss: 0.2814064621925354\n",
      "Epoch 46, Loss: 0.5758148431777954, Final Batch Loss: 0.09691191464662552\n",
      "Epoch 47, Loss: 0.5289151258766651, Final Batch Loss: 0.04323398694396019\n",
      "Epoch 48, Loss: 0.6927025467157364, Final Batch Loss: 0.28390389680862427\n",
      "Epoch 49, Loss: 0.721221849322319, Final Batch Loss: 0.2572838366031647\n",
      "Epoch 50, Loss: 0.5131978606805205, Final Batch Loss: 0.015153764747083187\n",
      "Epoch 51, Loss: 0.6703120619058609, Final Batch Loss: 0.16394487023353577\n",
      "Epoch 52, Loss: 0.7226901724934578, Final Batch Loss: 0.26551884412765503\n",
      "Epoch 53, Loss: 0.581724263727665, Final Batch Loss: 0.1107255145907402\n",
      "Epoch 54, Loss: 0.6106923744082451, Final Batch Loss: 0.07669305056333542\n",
      "Epoch 55, Loss: 0.5556715205311775, Final Batch Loss: 0.11605637520551682\n",
      "Epoch 56, Loss: 0.410472996532917, Final Batch Loss: 0.015356004238128662\n",
      "Epoch 57, Loss: 0.48710136115550995, Final Batch Loss: 0.07118507474660873\n",
      "Epoch 58, Loss: 0.48380883783102036, Final Batch Loss: 0.033519648015499115\n",
      "Epoch 59, Loss: 0.5091077568940818, Final Batch Loss: 0.006890434306114912\n",
      "Epoch 60, Loss: 0.5828539133071899, Final Batch Loss: 0.1872946172952652\n",
      "Epoch 61, Loss: 0.3631449565291405, Final Batch Loss: 0.06168530508875847\n",
      "Epoch 62, Loss: 0.41992760123685, Final Batch Loss: 0.006096136290580034\n",
      "Epoch 63, Loss: 0.4619441106915474, Final Batch Loss: 0.065391406416893\n",
      "Epoch 64, Loss: 0.6647292785346508, Final Batch Loss: 0.263862669467926\n",
      "Epoch 65, Loss: 0.39348823204636574, Final Batch Loss: 0.032698433846235275\n",
      "Epoch 66, Loss: 0.4837567061185837, Final Batch Loss: 0.07167582213878632\n",
      "Epoch 67, Loss: 0.4880552515387535, Final Batch Loss: 0.10549319535493851\n",
      "Epoch 68, Loss: 0.5737257897853851, Final Batch Loss: 0.15959247946739197\n",
      "Epoch 69, Loss: 0.44671016186475754, Final Batch Loss: 0.06438326090574265\n",
      "Epoch 70, Loss: 0.7005976885557175, Final Batch Loss: 0.29331517219543457\n",
      "Epoch 71, Loss: 0.5004378668963909, Final Batch Loss: 0.04491812363266945\n",
      "Epoch 72, Loss: 0.4694977067410946, Final Batch Loss: 0.11954126507043839\n",
      "Epoch 73, Loss: 0.34571967273950577, Final Batch Loss: 0.03042873740196228\n",
      "Epoch 74, Loss: 0.3422550056129694, Final Batch Loss: 0.022882169112563133\n",
      "Epoch 75, Loss: 0.44788531213998795, Final Batch Loss: 0.04090549796819687\n",
      "Epoch 76, Loss: 0.4622856676578522, Final Batch Loss: 0.12042661756277084\n",
      "Epoch 77, Loss: 0.4023545365780592, Final Batch Loss: 0.02739478088915348\n",
      "Epoch 78, Loss: 0.44356080889701843, Final Batch Loss: 0.09029919654130936\n",
      "Epoch 79, Loss: 0.405351672321558, Final Batch Loss: 0.04255199804902077\n",
      "Epoch 80, Loss: 0.33428225107491016, Final Batch Loss: 0.01133628748357296\n",
      "Epoch 81, Loss: 0.33421013224869967, Final Batch Loss: 0.012799211777746677\n",
      "Epoch 82, Loss: 0.5389082208275795, Final Batch Loss: 0.24282066524028778\n",
      "Epoch 83, Loss: 0.5038301832973957, Final Batch Loss: 0.10102717578411102\n",
      "Epoch 84, Loss: 0.41602070443332195, Final Batch Loss: 0.020620746538043022\n",
      "Epoch 85, Loss: 0.38268480729311705, Final Batch Loss: 0.011789756827056408\n",
      "Epoch 86, Loss: 0.6098104752600193, Final Batch Loss: 0.2906453311443329\n",
      "Epoch 87, Loss: 0.3379339352250099, Final Batch Loss: 0.0478084422647953\n",
      "Epoch 88, Loss: 0.5401672199368477, Final Batch Loss: 0.23118169605731964\n",
      "Epoch 89, Loss: 0.29457190353423357, Final Batch Loss: 0.010693741030991077\n",
      "Epoch 90, Loss: 0.34996238723397255, Final Batch Loss: 0.03384038433432579\n",
      "Epoch 91, Loss: 0.36381057649850845, Final Batch Loss: 0.058726660907268524\n",
      "Epoch 92, Loss: 0.34097740799188614, Final Batch Loss: 0.020465422421693802\n",
      "Epoch 93, Loss: 0.3514149319380522, Final Batch Loss: 0.01944534294307232\n",
      "Epoch 94, Loss: 0.2664404585957527, Final Batch Loss: 0.003208242356777191\n",
      "Epoch 95, Loss: 0.38701656833291054, Final Batch Loss: 0.04626355692744255\n",
      "Epoch 96, Loss: 0.3542243279516697, Final Batch Loss: 0.04711208865046501\n",
      "Epoch 97, Loss: 0.39346472918987274, Final Batch Loss: 0.09054099023342133\n",
      "Epoch 98, Loss: 0.27444555470719934, Final Batch Loss: 0.005833207163959742\n",
      "Epoch 99, Loss: 0.3015622366219759, Final Batch Loss: 0.019000152125954628\n",
      "Epoch 100, Loss: 0.373982947319746, Final Batch Loss: 0.05751795694231987\n",
      "Epoch 101, Loss: 0.349023062735796, Final Batch Loss: 0.06469457596540451\n",
      "Epoch 102, Loss: 0.32994545064866543, Final Batch Loss: 0.011775447055697441\n",
      "Epoch 103, Loss: 0.5249365419149399, Final Batch Loss: 0.23925110697746277\n",
      "Epoch 104, Loss: 0.37196624279022217, Final Batch Loss: 0.09668868780136108\n",
      "Epoch 105, Loss: 0.5700783506035805, Final Batch Loss: 0.2996985912322998\n",
      "Epoch 106, Loss: 0.3506842255592346, Final Batch Loss: 0.06170064955949783\n",
      "Epoch 107, Loss: 0.8993681818246841, Final Batch Loss: 0.5314488410949707\n",
      "Epoch 108, Loss: 0.35317306965589523, Final Batch Loss: 0.04530879110097885\n",
      "Epoch 109, Loss: 0.33481185510754585, Final Batch Loss: 0.03438297659158707\n",
      "Epoch 110, Loss: 0.37138206884264946, Final Batch Loss: 0.03585377708077431\n",
      "Epoch 111, Loss: 0.29811334889382124, Final Batch Loss: 0.00788967963308096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112, Loss: 0.26840880792587996, Final Batch Loss: 0.011926955543458462\n",
      "Epoch 113, Loss: 0.3304487429559231, Final Batch Loss: 0.0357091948390007\n",
      "Epoch 114, Loss: 0.3473401851952076, Final Batch Loss: 0.07426541298627853\n",
      "Epoch 115, Loss: 0.2910336051136255, Final Batch Loss: 0.012061892077326775\n",
      "Epoch 116, Loss: 0.2940939115360379, Final Batch Loss: 0.01192693505436182\n",
      "Epoch 117, Loss: 0.38904154673218727, Final Batch Loss: 0.11667788028717041\n",
      "Epoch 118, Loss: 0.2758764801546931, Final Batch Loss: 0.007896757684648037\n",
      "Epoch 119, Loss: 0.28452393785119057, Final Batch Loss: 0.018149930983781815\n",
      "Epoch 120, Loss: 0.4096669740974903, Final Batch Loss: 0.14452585577964783\n",
      "Epoch 121, Loss: 0.2725923848338425, Final Batch Loss: 0.007536661345511675\n",
      "Epoch 122, Loss: 0.4822039231657982, Final Batch Loss: 0.1824682503938675\n",
      "Epoch 123, Loss: 0.292252354323864, Final Batch Loss: 0.009511098265647888\n",
      "Epoch 124, Loss: 0.2889366038143635, Final Batch Loss: 0.006680574268102646\n",
      "Epoch 125, Loss: 0.2514430247247219, Final Batch Loss: 0.01734783500432968\n",
      "Epoch 126, Loss: 0.27374662831425667, Final Batch Loss: 0.011165626347064972\n",
      "Epoch 127, Loss: 0.22907031164504588, Final Batch Loss: 0.000977179268375039\n",
      "Epoch 128, Loss: 0.24701523315161467, Final Batch Loss: 0.008712111972272396\n",
      "Epoch 129, Loss: 0.3310271315276623, Final Batch Loss: 0.029318582266569138\n",
      "Epoch 130, Loss: 0.2815157603472471, Final Batch Loss: 0.019802061840891838\n",
      "Epoch 131, Loss: 0.3158431090414524, Final Batch Loss: 0.04556955024600029\n",
      "Epoch 132, Loss: 0.34376078471541405, Final Batch Loss: 0.05524280294775963\n",
      "Epoch 133, Loss: 0.3538190498948097, Final Batch Loss: 0.04316474124789238\n",
      "Epoch 134, Loss: 0.25749084167182446, Final Batch Loss: 0.024667860940098763\n",
      "Epoch 135, Loss: 0.4542246460914612, Final Batch Loss: 0.19255545735359192\n",
      "Epoch 136, Loss: 0.29472925141453743, Final Batch Loss: 0.06235742196440697\n",
      "Epoch 137, Loss: 0.2355239875614643, Final Batch Loss: 0.019915413111448288\n",
      "Epoch 138, Loss: 0.277121665654704, Final Batch Loss: 0.003530579386278987\n",
      "Epoch 139, Loss: 0.2769105889601633, Final Batch Loss: 0.0009933010442182422\n",
      "Epoch 140, Loss: 0.26614204980432987, Final Batch Loss: 0.015710318461060524\n",
      "Epoch 141, Loss: 0.23397958558052778, Final Batch Loss: 0.013177507556974888\n",
      "Epoch 142, Loss: 0.30101103335618973, Final Batch Loss: 0.046580132097005844\n",
      "Epoch 143, Loss: 0.3029788862913847, Final Batch Loss: 0.02275092341005802\n",
      "Epoch 144, Loss: 0.30460352823138237, Final Batch Loss: 0.02785724401473999\n",
      "Epoch 145, Loss: 0.2856106720864773, Final Batch Loss: 0.06123887747526169\n",
      "Epoch 146, Loss: 0.26586213940754533, Final Batch Loss: 0.006586937699466944\n",
      "Epoch 147, Loss: 0.24096744507551193, Final Batch Loss: 0.009187676012516022\n",
      "Epoch 148, Loss: 0.220849615521729, Final Batch Loss: 0.010750935412943363\n",
      "Epoch 149, Loss: 0.2807345800101757, Final Batch Loss: 0.06104355677962303\n",
      "Epoch 150, Loss: 0.3950829952955246, Final Batch Loss: 0.17651380598545074\n",
      "Epoch 151, Loss: 0.25348890013992786, Final Batch Loss: 0.010182194411754608\n",
      "Epoch 152, Loss: 0.24271629424765706, Final Batch Loss: 0.006311491597443819\n",
      "Epoch 153, Loss: 0.2629700470715761, Final Batch Loss: 0.014990685507655144\n",
      "Epoch 154, Loss: 0.3726356253027916, Final Batch Loss: 0.17946477234363556\n",
      "Epoch 155, Loss: 0.2706930236890912, Final Batch Loss: 0.010095902718603611\n",
      "Epoch 156, Loss: 0.22585765086114407, Final Batch Loss: 0.007828621193766594\n",
      "Epoch 157, Loss: 0.24260905850678682, Final Batch Loss: 0.009678863920271397\n",
      "Epoch 158, Loss: 0.38745468482375145, Final Batch Loss: 0.1459762305021286\n",
      "Epoch 159, Loss: 0.2130791493691504, Final Batch Loss: 0.005812904331833124\n",
      "Epoch 160, Loss: 0.2282534547848627, Final Batch Loss: 0.0007567413849756122\n",
      "Epoch 161, Loss: 0.2479609427973628, Final Batch Loss: 0.008087939582765102\n",
      "Epoch 162, Loss: 0.2740800912724808, Final Batch Loss: 0.001843624864704907\n",
      "Epoch 163, Loss: 0.2761789597570896, Final Batch Loss: 0.036127202212810516\n",
      "Epoch 164, Loss: 0.20100552029907703, Final Batch Loss: 0.023951362818479538\n",
      "Epoch 165, Loss: 0.3429867662489414, Final Batch Loss: 0.10578858852386475\n",
      "Epoch 166, Loss: 0.29857301339507103, Final Batch Loss: 0.08811896294355392\n",
      "Epoch 167, Loss: 0.44098688662052155, Final Batch Loss: 0.26646751165390015\n",
      "Epoch 168, Loss: 0.3058730624616146, Final Batch Loss: 0.06615348905324936\n",
      "Epoch 169, Loss: 0.21008093282580376, Final Batch Loss: 0.01770646683871746\n",
      "Epoch 170, Loss: 0.24236282147467136, Final Batch Loss: 0.03986353427171707\n",
      "Epoch 171, Loss: 0.23940479382872581, Final Batch Loss: 0.017915118485689163\n",
      "Epoch 172, Loss: 0.26215798035264015, Final Batch Loss: 0.0055072121322155\n",
      "Epoch 173, Loss: 0.259218106046319, Final Batch Loss: 0.02718277834355831\n",
      "Epoch 174, Loss: 0.29976035840809345, Final Batch Loss: 0.06765403598546982\n",
      "Epoch 175, Loss: 0.21898273145779967, Final Batch Loss: 0.005483092274516821\n",
      "Epoch 176, Loss: 0.30665209516882896, Final Batch Loss: 0.10265450924634933\n",
      "Epoch 177, Loss: 0.2005304404301569, Final Batch Loss: 0.000998848001472652\n",
      "Epoch 178, Loss: 0.41373493894934654, Final Batch Loss: 0.20983991026878357\n",
      "Epoch 179, Loss: 0.2221561772748828, Final Batch Loss: 0.01518403273075819\n",
      "Epoch 180, Loss: 0.4656903874129057, Final Batch Loss: 0.2461705207824707\n",
      "Epoch 181, Loss: 0.24605126678943634, Final Batch Loss: 0.03378339111804962\n",
      "Epoch 182, Loss: 0.230316624045372, Final Batch Loss: 0.05413343757390976\n",
      "Epoch 183, Loss: 0.21791084064170718, Final Batch Loss: 0.0030992659740149975\n",
      "Epoch 184, Loss: 0.20943663292564452, Final Batch Loss: 0.002165023470297456\n",
      "Epoch 185, Loss: 0.23649574257433414, Final Batch Loss: 0.029123501852154732\n",
      "Epoch 186, Loss: 0.2686411701142788, Final Batch Loss: 0.05811162665486336\n",
      "Epoch 187, Loss: 0.21175667643547058, Final Batch Loss: 0.008328473195433617\n",
      "Epoch 188, Loss: 0.24740175157785416, Final Batch Loss: 0.03669626638293266\n",
      "Epoch 189, Loss: 0.19753586128354073, Final Batch Loss: 0.01419045589864254\n",
      "Epoch 190, Loss: 0.2148947548121214, Final Batch Loss: 0.016826869919896126\n",
      "Epoch 191, Loss: 0.24857855401933193, Final Batch Loss: 0.029261821880936623\n",
      "Epoch 192, Loss: 0.21564612165093422, Final Batch Loss: 0.028041068464517593\n",
      "Epoch 193, Loss: 0.4523978978395462, Final Batch Loss: 0.2407025843858719\n",
      "Epoch 194, Loss: 0.40360146574676037, Final Batch Loss: 0.2370157390832901\n",
      "Epoch 195, Loss: 0.21869567036628723, Final Batch Loss: 0.026689840480685234\n",
      "Epoch 196, Loss: 0.19689663394819945, Final Batch Loss: 0.001371196354739368\n",
      "Epoch 197, Loss: 0.2745850458741188, Final Batch Loss: 0.042933616787195206\n",
      "Epoch 198, Loss: 0.20401203073561192, Final Batch Loss: 0.025988051667809486\n",
      "Epoch 199, Loss: 0.1901330891996622, Final Batch Loss: 0.02174089290201664\n",
      "Epoch 200, Loss: 0.32287449203431606, Final Batch Loss: 0.15149764716625214\n",
      "Epoch 201, Loss: 0.26238105446100235, Final Batch Loss: 0.08499157428741455\n",
      "Epoch 202, Loss: 0.1571878727991134, Final Batch Loss: 0.0017781548667699099\n",
      "Epoch 203, Loss: 0.2049162625335157, Final Batch Loss: 0.004865876864641905\n",
      "Epoch 204, Loss: 0.20647978549823165, Final Batch Loss: 0.00413874676451087\n",
      "Epoch 205, Loss: 0.22099250182509422, Final Batch Loss: 0.01883077621459961\n",
      "Epoch 206, Loss: 0.24053197167813778, Final Batch Loss: 0.06558681279420853\n",
      "Epoch 207, Loss: 0.1743829781189561, Final Batch Loss: 0.010262482799589634\n",
      "Epoch 208, Loss: 0.24041610583662987, Final Batch Loss: 0.04355715587735176\n",
      "Epoch 209, Loss: 0.19994705356657505, Final Batch Loss: 0.020995337516069412\n",
      "Epoch 210, Loss: 0.19067671289667487, Final Batch Loss: 0.007692848797887564\n",
      "Epoch 211, Loss: 0.22051981324329972, Final Batch Loss: 0.003816543612629175\n",
      "Epoch 212, Loss: 0.6356447860598564, Final Batch Loss: 0.4765319228172302\n",
      "Epoch 213, Loss: 0.20794825116172433, Final Batch Loss: 0.0022995718754827976\n",
      "Epoch 214, Loss: 0.21489848010241985, Final Batch Loss: 0.014427261427044868\n",
      "Epoch 215, Loss: 0.2660813070833683, Final Batch Loss: 0.058506857603788376\n",
      "Epoch 216, Loss: 0.2407669685781002, Final Batch Loss: 0.05555129423737526\n",
      "Epoch 217, Loss: 0.227449219673872, Final Batch Loss: 0.01574629917740822\n",
      "Epoch 218, Loss: 0.3052932657301426, Final Batch Loss: 0.10827066749334335\n",
      "Epoch 219, Loss: 0.20932569913566113, Final Batch Loss: 0.010045744478702545\n",
      "Epoch 220, Loss: 0.23262133076786995, Final Batch Loss: 0.042285215109586716\n",
      "Epoch 221, Loss: 0.18237669696100056, Final Batch Loss: 0.0029744498897343874\n",
      "Epoch 222, Loss: 0.20226544281467795, Final Batch Loss: 0.005868454929441214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223, Loss: 0.21934903040528297, Final Batch Loss: 0.00733146071434021\n",
      "Epoch 224, Loss: 0.2510334961116314, Final Batch Loss: 0.07616271078586578\n",
      "Epoch 225, Loss: 0.2806739807128906, Final Batch Loss: 0.11731583625078201\n",
      "Epoch 226, Loss: 0.18649018555879593, Final Batch Loss: 0.0249526035040617\n",
      "Epoch 227, Loss: 0.2598944902420044, Final Batch Loss: 0.048719193786382675\n",
      "Epoch 228, Loss: 0.21752718545030802, Final Batch Loss: 0.0011523187858983874\n",
      "Epoch 229, Loss: 0.18296023178845644, Final Batch Loss: 0.008816913701593876\n",
      "Epoch 230, Loss: 0.20981061598286033, Final Batch Loss: 0.007078201975673437\n",
      "Epoch 231, Loss: 0.16351992590352893, Final Batch Loss: 0.007654470857232809\n",
      "Epoch 232, Loss: 0.1879942959640175, Final Batch Loss: 0.002608174690976739\n",
      "Epoch 233, Loss: 0.1825035698711872, Final Batch Loss: 0.03572344779968262\n",
      "Epoch 234, Loss: 0.20265116356313229, Final Batch Loss: 0.044775910675525665\n",
      "Epoch 235, Loss: 0.4328589662909508, Final Batch Loss: 0.2924640476703644\n",
      "Epoch 236, Loss: 0.1887798197567463, Final Batch Loss: 0.03359309211373329\n",
      "Epoch 237, Loss: 0.17512342147529125, Final Batch Loss: 0.0218435637652874\n",
      "Epoch 238, Loss: 0.49535258673131466, Final Batch Loss: 0.3299724757671356\n",
      "Epoch 239, Loss: 0.17389048915356398, Final Batch Loss: 0.014737331308424473\n",
      "Epoch 240, Loss: 0.20479127764701843, Final Batch Loss: 0.030535152181982994\n",
      "Epoch 241, Loss: 0.21065914258360863, Final Batch Loss: 0.03662626072764397\n",
      "Epoch 242, Loss: 0.15595713490620255, Final Batch Loss: 0.007718617562204599\n",
      "Epoch 243, Loss: 0.28422239050269127, Final Batch Loss: 0.14032115042209625\n",
      "Epoch 244, Loss: 0.1821400159969926, Final Batch Loss: 0.013710466213524342\n",
      "Epoch 245, Loss: 0.20536735840141773, Final Batch Loss: 0.010437032207846642\n",
      "Epoch 246, Loss: 0.18347955867648125, Final Batch Loss: 0.004860103130340576\n",
      "Epoch 247, Loss: 0.18383844569325447, Final Batch Loss: 0.015888992697000504\n",
      "Epoch 248, Loss: 0.19036713521927595, Final Batch Loss: 0.002043084241449833\n",
      "Epoch 249, Loss: 0.3433686764910817, Final Batch Loss: 0.19207347929477692\n",
      "Epoch 250, Loss: 0.19363199267536402, Final Batch Loss: 0.008952603675425053\n",
      "Epoch 251, Loss: 0.18141130928415805, Final Batch Loss: 0.0012190231354907155\n",
      "Epoch 252, Loss: 0.19318329775705934, Final Batch Loss: 0.0075627644546329975\n",
      "Epoch 253, Loss: 0.18401168566197157, Final Batch Loss: 0.008430049754679203\n",
      "Epoch 254, Loss: 0.16253585182130337, Final Batch Loss: 0.02157951518893242\n",
      "Epoch 255, Loss: 0.1923162781749852, Final Batch Loss: 0.0005772107397206128\n",
      "Epoch 256, Loss: 0.21358846873044968, Final Batch Loss: 0.046681974083185196\n",
      "Epoch 257, Loss: 0.18522085063159466, Final Batch Loss: 0.022711027413606644\n",
      "Epoch 258, Loss: 0.20518574211746454, Final Batch Loss: 0.011174951680004597\n",
      "Epoch 259, Loss: 0.1923490073531866, Final Batch Loss: 0.05515790730714798\n",
      "Epoch 260, Loss: 0.46338365599513054, Final Batch Loss: 0.3050976097583771\n",
      "Epoch 261, Loss: 0.1830422692000866, Final Batch Loss: 0.01826646365225315\n",
      "Epoch 262, Loss: 0.15019795575062744, Final Batch Loss: 0.00024599485914222896\n",
      "Epoch 263, Loss: 0.1754059442318976, Final Batch Loss: 0.0021773711778223515\n",
      "Epoch 264, Loss: 0.15587922342820093, Final Batch Loss: 0.0007489562849514186\n",
      "Epoch 265, Loss: 0.17100107204169035, Final Batch Loss: 0.03784943372011185\n",
      "Epoch 266, Loss: 0.23392057605087757, Final Batch Loss: 0.05826278403401375\n",
      "Epoch 267, Loss: 0.18276307545602322, Final Batch Loss: 0.05440491437911987\n",
      "Epoch 268, Loss: 0.1715570108499378, Final Batch Loss: 0.0026379914488643408\n",
      "Epoch 269, Loss: 0.16854507056996226, Final Batch Loss: 0.000566121656447649\n",
      "Epoch 270, Loss: 0.15714243985712528, Final Batch Loss: 0.009057112038135529\n",
      "Epoch 271, Loss: 0.14796707779169083, Final Batch Loss: 0.002957794815301895\n",
      "Epoch 272, Loss: 0.20682076923549175, Final Batch Loss: 0.05720251053571701\n",
      "Epoch 273, Loss: 0.24904092215001583, Final Batch Loss: 0.12399060279130936\n",
      "Epoch 274, Loss: 0.22589804045856, Final Batch Loss: 0.040616098791360855\n",
      "Epoch 275, Loss: 0.19542974047362804, Final Batch Loss: 0.02047758921980858\n",
      "Epoch 276, Loss: 0.2670486867427826, Final Batch Loss: 0.051123518496751785\n",
      "Epoch 277, Loss: 0.16342059150338173, Final Batch Loss: 0.02017812989652157\n",
      "Epoch 278, Loss: 0.19732520543038845, Final Batch Loss: 0.06027292460203171\n",
      "Epoch 279, Loss: 0.15105416753794998, Final Batch Loss: 0.0013006398221477866\n",
      "Epoch 280, Loss: 0.1509482234250754, Final Batch Loss: 0.003881056560203433\n",
      "Epoch 281, Loss: 0.6858353316783905, Final Batch Loss: 0.5763145685195923\n",
      "Epoch 282, Loss: 0.16481760959140956, Final Batch Loss: 0.0026006835978478193\n",
      "Epoch 283, Loss: 0.23539059422910213, Final Batch Loss: 0.0741046816110611\n",
      "Epoch 284, Loss: 0.23796172067523003, Final Batch Loss: 0.03752933070063591\n",
      "Epoch 285, Loss: 0.15473853144794703, Final Batch Loss: 0.007627495564520359\n",
      "Epoch 286, Loss: 0.13505693385377526, Final Batch Loss: 0.004303079564124346\n",
      "Epoch 287, Loss: 0.20086119510233402, Final Batch Loss: 0.03429156169295311\n",
      "Epoch 288, Loss: 0.142298330552876, Final Batch Loss: 0.00894895475357771\n",
      "Epoch 289, Loss: 0.18453100975602865, Final Batch Loss: 0.008745714090764523\n",
      "Epoch 290, Loss: 0.14819710608571768, Final Batch Loss: 0.001442871056497097\n",
      "Epoch 291, Loss: 0.16162819659803063, Final Batch Loss: 0.0018782062688842416\n",
      "Epoch 292, Loss: 0.148334339261055, Final Batch Loss: 0.013229480013251305\n",
      "Epoch 293, Loss: 0.14691303577274084, Final Batch Loss: 0.0019414452835917473\n",
      "Epoch 294, Loss: 0.24378880113363266, Final Batch Loss: 0.10933034867048264\n",
      "Epoch 295, Loss: 0.17306568659842014, Final Batch Loss: 0.023085545748472214\n",
      "Epoch 296, Loss: 0.14782975753769279, Final Batch Loss: 0.002756544854491949\n",
      "Epoch 297, Loss: 0.1324151400476694, Final Batch Loss: 0.002402510493993759\n",
      "Epoch 298, Loss: 0.13294139225035906, Final Batch Loss: 0.006565042771399021\n",
      "Epoch 299, Loss: 0.2062901295721531, Final Batch Loss: 0.05684012174606323\n",
      "Epoch 300, Loss: 0.1507358020171523, Final Batch Loss: 0.03003247082233429\n",
      "Epoch 301, Loss: 0.1345046750502661, Final Batch Loss: 0.0014109975891187787\n",
      "Epoch 302, Loss: 0.4241577014327049, Final Batch Loss: 0.26834315061569214\n",
      "Epoch 303, Loss: 0.1230912059545517, Final Batch Loss: 0.006704796105623245\n",
      "Epoch 304, Loss: 0.1423024763353169, Final Batch Loss: 0.004661294165998697\n",
      "Epoch 305, Loss: 0.15113607188686728, Final Batch Loss: 0.006734700407832861\n",
      "Epoch 306, Loss: 0.17525465320795774, Final Batch Loss: 0.01091113593429327\n",
      "Epoch 307, Loss: 0.14883464854210615, Final Batch Loss: 0.007174492813646793\n",
      "Epoch 308, Loss: 0.1831534430384636, Final Batch Loss: 0.042445842176675797\n",
      "Epoch 309, Loss: 0.16786842234432697, Final Batch Loss: 0.02490856684744358\n",
      "Epoch 310, Loss: 0.15572075452655554, Final Batch Loss: 0.028996167704463005\n",
      "Epoch 311, Loss: 0.19557222910225391, Final Batch Loss: 0.057444434612989426\n",
      "Epoch 312, Loss: 0.12105969851836562, Final Batch Loss: 0.00034830113872885704\n",
      "Epoch 313, Loss: 0.1473475517705083, Final Batch Loss: 0.009562182240188122\n",
      "Epoch 314, Loss: 0.1624809866771102, Final Batch Loss: 0.008286898024380207\n",
      "Epoch 315, Loss: 0.15711522125639021, Final Batch Loss: 0.003731156000867486\n",
      "Epoch 316, Loss: 0.15831769327633083, Final Batch Loss: 0.0023837198968976736\n",
      "Epoch 317, Loss: 0.1310299914330244, Final Batch Loss: 0.004715736955404282\n",
      "Epoch 318, Loss: 0.14103984460234642, Final Batch Loss: 0.012121878564357758\n",
      "Epoch 319, Loss: 0.17212603241205215, Final Batch Loss: 0.037125054746866226\n",
      "Epoch 320, Loss: 0.1741055164602585, Final Batch Loss: 0.0004397284355945885\n",
      "Epoch 321, Loss: 0.17847014777362347, Final Batch Loss: 0.026809168979525566\n",
      "Epoch 322, Loss: 0.1290635429613758, Final Batch Loss: 0.0004349518858361989\n",
      "Epoch 323, Loss: 0.12932389182969928, Final Batch Loss: 0.014594824984669685\n",
      "Epoch 324, Loss: 0.14271568320691586, Final Batch Loss: 0.003258500248193741\n",
      "Epoch 325, Loss: 0.2206420637667179, Final Batch Loss: 0.11668957024812698\n",
      "Epoch 326, Loss: 0.17013549245893955, Final Batch Loss: 0.02786277048289776\n",
      "Epoch 327, Loss: 0.14688339456915855, Final Batch Loss: 0.035466842353343964\n",
      "Epoch 328, Loss: 0.14479465410113335, Final Batch Loss: 0.054898958653211594\n",
      "Epoch 329, Loss: 0.14049377385526896, Final Batch Loss: 0.013725532218813896\n",
      "Epoch 330, Loss: 0.3330080024898052, Final Batch Loss: 0.20146770775318146\n",
      "Epoch 331, Loss: 0.12428134214133024, Final Batch Loss: 0.003955644555389881\n",
      "Epoch 332, Loss: 0.15718851052224636, Final Batch Loss: 0.03588318079710007\n",
      "Epoch 333, Loss: 0.15203224122524261, Final Batch Loss: 0.008567322045564651\n",
      "Epoch 334, Loss: 0.16759751737117767, Final Batch Loss: 0.0326567105948925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335, Loss: 0.16140657663345337, Final Batch Loss: 0.03501678630709648\n",
      "Epoch 336, Loss: 0.12573418021202087, Final Batch Loss: 0.00958002358675003\n",
      "Epoch 337, Loss: 0.16296866163611412, Final Batch Loss: 0.028146058320999146\n",
      "Epoch 338, Loss: 0.11363703873939812, Final Batch Loss: 0.0014042493421584368\n",
      "Epoch 339, Loss: 0.10404518051655032, Final Batch Loss: 0.00047658654511906207\n",
      "Epoch 340, Loss: 0.11243701935745776, Final Batch Loss: 0.000979618402197957\n",
      "Epoch 341, Loss: 0.24175847973674536, Final Batch Loss: 0.12073463201522827\n",
      "Epoch 342, Loss: 0.13297756761312485, Final Batch Loss: 0.024574559181928635\n",
      "Epoch 343, Loss: 0.409659237600863, Final Batch Loss: 0.29531130194664\n",
      "Epoch 344, Loss: 0.13447934202849865, Final Batch Loss: 0.03928713873028755\n",
      "Epoch 345, Loss: 0.17097183130681515, Final Batch Loss: 0.03341618925333023\n",
      "Epoch 346, Loss: 0.16964103421196342, Final Batch Loss: 0.005212086718529463\n",
      "Epoch 347, Loss: 0.12380477890837938, Final Batch Loss: 0.0013761046575382352\n",
      "Epoch 348, Loss: 0.16198964603245258, Final Batch Loss: 0.026081116870045662\n",
      "Epoch 349, Loss: 0.2382247750647366, Final Batch Loss: 0.11379797756671906\n",
      "Epoch 350, Loss: 0.1440197043120861, Final Batch Loss: 0.04294143244624138\n",
      "Epoch 351, Loss: 0.11687183496542275, Final Batch Loss: 0.0018680852372199297\n",
      "Epoch 352, Loss: 0.13485866272822022, Final Batch Loss: 0.002762686926871538\n",
      "Epoch 353, Loss: 0.13115269620902836, Final Batch Loss: 0.0023357507307082415\n",
      "Epoch 354, Loss: 0.12916601134929806, Final Batch Loss: 0.0009959196904674172\n",
      "Epoch 355, Loss: 0.1519661396741867, Final Batch Loss: 0.011360900476574898\n",
      "Epoch 356, Loss: 0.13829244673252106, Final Batch Loss: 0.0140009056776762\n",
      "Epoch 357, Loss: 0.17127441056072712, Final Batch Loss: 0.05697449669241905\n",
      "Epoch 358, Loss: 0.10950437560677528, Final Batch Loss: 0.012158634141087532\n",
      "Epoch 359, Loss: 0.10953930299729109, Final Batch Loss: 0.0020979908294975758\n",
      "Epoch 360, Loss: 0.24094569962471724, Final Batch Loss: 0.1524762213230133\n",
      "Epoch 361, Loss: 0.14595186104997993, Final Batch Loss: 0.038347385823726654\n",
      "Epoch 362, Loss: 0.1163712777197361, Final Batch Loss: 0.004747871309518814\n",
      "Epoch 363, Loss: 0.1498794350773096, Final Batch Loss: 0.01611890085041523\n",
      "Epoch 364, Loss: 0.13752301968634129, Final Batch Loss: 0.019598808139562607\n",
      "Epoch 365, Loss: 0.17619416117668152, Final Batch Loss: 0.055360402911901474\n",
      "Epoch 366, Loss: 0.12415583804249763, Final Batch Loss: 0.027041513472795486\n",
      "Epoch 367, Loss: 0.4592321654781699, Final Batch Loss: 0.3663298487663269\n",
      "Epoch 368, Loss: 0.1233225567266345, Final Batch Loss: 0.01098461914807558\n",
      "Epoch 369, Loss: 0.14137679152190685, Final Batch Loss: 0.02033163793385029\n",
      "Epoch 370, Loss: 0.1208357831928879, Final Batch Loss: 0.00017708749510347843\n",
      "Epoch 371, Loss: 0.13023116812109947, Final Batch Loss: 0.027817798778414726\n",
      "Epoch 372, Loss: 0.08948064967989922, Final Batch Loss: 0.006835597567260265\n",
      "Epoch 373, Loss: 0.2214851980097592, Final Batch Loss: 0.1079290360212326\n",
      "Epoch 374, Loss: 0.1021898165345192, Final Batch Loss: 0.009462560527026653\n",
      "Epoch 375, Loss: 0.12432985752820969, Final Batch Loss: 0.02055974490940571\n",
      "Epoch 376, Loss: 0.11473513464443386, Final Batch Loss: 0.0019174546469002962\n",
      "Epoch 377, Loss: 0.09919163957238197, Final Batch Loss: 0.0017573852092027664\n",
      "Epoch 378, Loss: 0.1124367481097579, Final Batch Loss: 0.007393076084554195\n",
      "Epoch 379, Loss: 0.0969649269245565, Final Batch Loss: 0.004780376795679331\n",
      "Epoch 380, Loss: 0.10903473850339651, Final Batch Loss: 0.00463480968028307\n",
      "Epoch 381, Loss: 0.09357921406626701, Final Batch Loss: 0.00906599871814251\n",
      "Epoch 382, Loss: 0.09576479624956846, Final Batch Loss: 0.004069730639457703\n",
      "Epoch 383, Loss: 0.09949167165905237, Final Batch Loss: 0.01749251037836075\n",
      "Epoch 384, Loss: 0.08530622359830886, Final Batch Loss: 0.0005892637418583035\n",
      "Epoch 385, Loss: 0.113942782394588, Final Batch Loss: 0.011816233396530151\n",
      "Epoch 386, Loss: 0.08947874722070992, Final Batch Loss: 0.0011910202447324991\n",
      "Epoch 387, Loss: 0.09873025957494974, Final Batch Loss: 0.0004268488846719265\n",
      "Epoch 388, Loss: 0.11952235852368176, Final Batch Loss: 0.0034365758765488863\n",
      "Epoch 389, Loss: 0.10947405267506838, Final Batch Loss: 0.014144082553684711\n",
      "Epoch 390, Loss: 0.086609699530527, Final Batch Loss: 0.0011047848965972662\n",
      "Epoch 391, Loss: 0.08286383515223861, Final Batch Loss: 0.007680168841034174\n",
      "Epoch 392, Loss: 0.08845336514059454, Final Batch Loss: 0.0009124508360400796\n",
      "Epoch 393, Loss: 0.07592523749917746, Final Batch Loss: 0.0032875710166990757\n",
      "Epoch 394, Loss: 0.10410603770287707, Final Batch Loss: 0.0002598895807750523\n",
      "Epoch 395, Loss: 0.10298152733594179, Final Batch Loss: 0.024732891470193863\n",
      "Epoch 396, Loss: 0.09443822503089905, Final Batch Loss: 0.007500906474888325\n",
      "Epoch 397, Loss: 0.08093530195765197, Final Batch Loss: 0.0023534761276096106\n",
      "Epoch 398, Loss: 0.0802273927256465, Final Batch Loss: 0.017643896862864494\n",
      "Epoch 399, Loss: 0.08184350002557039, Final Batch Loss: 0.007641240488737822\n",
      "Epoch 400, Loss: 0.10680453898385167, Final Batch Loss: 0.002391363959759474\n",
      "Epoch 401, Loss: 0.08420642418786883, Final Batch Loss: 0.002827312331646681\n",
      "Epoch 402, Loss: 0.07996045146137476, Final Batch Loss: 0.007221934385597706\n",
      "Epoch 403, Loss: 0.1000573206692934, Final Batch Loss: 0.0280755627900362\n",
      "Epoch 404, Loss: 0.08133611502125859, Final Batch Loss: 0.004892968572676182\n",
      "Epoch 405, Loss: 0.08390374830923975, Final Batch Loss: 0.0010753560345619917\n",
      "Epoch 406, Loss: 0.0647651725448668, Final Batch Loss: 0.0010506068356335163\n",
      "Epoch 407, Loss: 0.09258157480508089, Final Batch Loss: 0.028019145131111145\n",
      "Epoch 408, Loss: 0.12437102710828185, Final Batch Loss: 0.032597389072179794\n",
      "Epoch 409, Loss: 0.07705882890149951, Final Batch Loss: 0.004641199950128794\n",
      "Epoch 410, Loss: 0.06012422894127667, Final Batch Loss: 0.0032369059044867754\n",
      "Epoch 411, Loss: 0.13355970839620568, Final Batch Loss: 0.00025382163585163653\n",
      "Epoch 412, Loss: 0.05864511649997439, Final Batch Loss: 0.00018762597755994648\n",
      "Epoch 413, Loss: 0.050998164660995826, Final Batch Loss: 0.00038395155570469797\n",
      "Epoch 414, Loss: 0.07267376547679305, Final Batch Loss: 0.0007853168062865734\n",
      "Epoch 415, Loss: 0.06882594246417284, Final Batch Loss: 0.002935840282589197\n",
      "Epoch 416, Loss: 0.05919453766546212, Final Batch Loss: 0.00021820314577780664\n",
      "Epoch 417, Loss: 0.05828240793198347, Final Batch Loss: 0.0012043612077832222\n",
      "Epoch 418, Loss: 0.0567689489107579, Final Batch Loss: 0.014017661102116108\n",
      "Epoch 419, Loss: 0.09641553787514567, Final Batch Loss: 0.028917821124196053\n",
      "Epoch 420, Loss: 0.07712198016815819, Final Batch Loss: 0.0002914538199547678\n",
      "Epoch 421, Loss: 0.04059648513793945, Final Batch Loss: 0.00015386100858449936\n",
      "Epoch 422, Loss: 0.049314731266349554, Final Batch Loss: 0.004716154653578997\n",
      "Epoch 423, Loss: 0.06916070482111536, Final Batch Loss: 0.00029342746711336076\n",
      "Epoch 424, Loss: 0.06691375735681504, Final Batch Loss: 0.000664598192088306\n",
      "Epoch 425, Loss: 0.09006912913173437, Final Batch Loss: 0.00023618433624505997\n",
      "Epoch 426, Loss: 0.11236632661893964, Final Batch Loss: 0.048922181129455566\n",
      "Epoch 427, Loss: 0.09602315910160542, Final Batch Loss: 0.024658847600221634\n",
      "Epoch 428, Loss: 0.08966930904352921, Final Batch Loss: 4.97227993037086e-05\n",
      "Epoch 429, Loss: 0.0700139245018363, Final Batch Loss: 0.010266461409628391\n",
      "Epoch 430, Loss: 0.08387246099300683, Final Batch Loss: 0.00144336954690516\n",
      "Epoch 431, Loss: 0.09675833070650697, Final Batch Loss: 0.004709993954747915\n",
      "Epoch 432, Loss: 0.08105947286821902, Final Batch Loss: 0.002910071285441518\n",
      "Epoch 433, Loss: 0.06532532931305468, Final Batch Loss: 0.0037611329462379217\n",
      "Epoch 434, Loss: 0.07320896824239753, Final Batch Loss: 0.00041580674587748945\n",
      "Epoch 435, Loss: 0.06727550394134596, Final Batch Loss: 0.0005017456714995205\n",
      "Epoch 436, Loss: 0.06112738931551576, Final Batch Loss: 0.01118056382983923\n",
      "Epoch 437, Loss: 0.0862350957468152, Final Batch Loss: 0.004055213648825884\n",
      "Epoch 438, Loss: 0.07022181386128068, Final Batch Loss: 0.0029113427735865116\n",
      "Epoch 439, Loss: 0.07058683666400611, Final Batch Loss: 0.0015836150851100683\n",
      "Epoch 440, Loss: 0.053111771936528385, Final Batch Loss: 0.0012945643393322825\n",
      "Epoch 441, Loss: 0.055674933828413486, Final Batch Loss: 0.003200424835085869\n",
      "Epoch 442, Loss: 0.06547879986464977, Final Batch Loss: 0.0024349153973162174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443, Loss: 0.07218497875146568, Final Batch Loss: 0.0026235750410705805\n",
      "Epoch 444, Loss: 0.09338280418887734, Final Batch Loss: 0.003374185413122177\n",
      "Epoch 445, Loss: 0.05983043275773525, Final Batch Loss: 0.0011850977316498756\n",
      "Epoch 446, Loss: 0.0631250249571167, Final Batch Loss: 0.000876714417245239\n",
      "Epoch 447, Loss: 0.04539426538394764, Final Batch Loss: 0.0006089949165470898\n",
      "Epoch 448, Loss: 0.10220334102632478, Final Batch Loss: 0.0009341368568129838\n",
      "Epoch 449, Loss: 0.06249604174263368, Final Batch Loss: 2.3815178792574443e-05\n",
      "Epoch 450, Loss: 0.07275304337963462, Final Batch Loss: 0.002923190128058195\n",
      "Epoch 451, Loss: 0.22914066724479198, Final Batch Loss: 0.173019140958786\n",
      "Epoch 452, Loss: 0.09708290314301848, Final Batch Loss: 0.038553692400455475\n",
      "Epoch 453, Loss: 0.0828342018648982, Final Batch Loss: 0.006734245456755161\n",
      "Epoch 454, Loss: 0.07092566741630435, Final Batch Loss: 0.004277224186807871\n",
      "Epoch 455, Loss: 0.07003411374171264, Final Batch Loss: 0.00022548719425685704\n",
      "Epoch 456, Loss: 0.07181638479232788, Final Batch Loss: 0.009928987361490726\n",
      "Epoch 457, Loss: 0.0736384530318901, Final Batch Loss: 0.0010139386868104339\n",
      "Epoch 458, Loss: 0.06663366971770301, Final Batch Loss: 0.0002815416664816439\n",
      "Epoch 459, Loss: 0.048063077731058, Final Batch Loss: 0.00594542920589447\n",
      "Epoch 460, Loss: 0.08178558945655823, Final Batch Loss: 0.005417573265731335\n",
      "Epoch 461, Loss: 0.06881103594787419, Final Batch Loss: 0.0033357867505401373\n",
      "Epoch 462, Loss: 0.1360898776911199, Final Batch Loss: 0.06154249981045723\n",
      "Epoch 463, Loss: 0.08324009273201227, Final Batch Loss: 0.007666163612157106\n",
      "Epoch 464, Loss: 0.06352096697082743, Final Batch Loss: 0.00031076971208676696\n",
      "Epoch 465, Loss: 0.04374777979683131, Final Batch Loss: 0.0016616637585684657\n",
      "Epoch 466, Loss: 0.05747011862695217, Final Batch Loss: 0.025445621460676193\n",
      "Epoch 467, Loss: 0.13186265900731087, Final Batch Loss: 0.035552624613046646\n",
      "Epoch 468, Loss: 0.05103970124037005, Final Batch Loss: 0.00018778714002110064\n",
      "Epoch 469, Loss: 0.06213066400960088, Final Batch Loss: 0.001663808710873127\n",
      "Epoch 470, Loss: 0.0620833495631814, Final Batch Loss: 0.0012689465656876564\n",
      "Epoch 471, Loss: 0.055541587265906855, Final Batch Loss: 0.000257547217188403\n",
      "Epoch 472, Loss: 0.05841403244994581, Final Batch Loss: 0.0012700699735432863\n",
      "Epoch 473, Loss: 0.05554899130947888, Final Batch Loss: 0.0014815314207226038\n",
      "Epoch 474, Loss: 0.04191903228638694, Final Batch Loss: 0.0007657722453586757\n",
      "Epoch 475, Loss: 0.04123124363832176, Final Batch Loss: 0.0015033052768558264\n",
      "Epoch 476, Loss: 0.09722616104409099, Final Batch Loss: 0.04730069264769554\n",
      "Epoch 477, Loss: 0.06922897277399898, Final Batch Loss: 0.013777161948382854\n",
      "Epoch 478, Loss: 0.10265407837869134, Final Batch Loss: 0.00013083811791148037\n",
      "Epoch 479, Loss: 0.08798750443384051, Final Batch Loss: 0.0012039458379149437\n",
      "Epoch 480, Loss: 0.11764531023800373, Final Batch Loss: 0.038877952843904495\n",
      "Epoch 481, Loss: 0.06446226895786822, Final Batch Loss: 0.00389796937815845\n",
      "Epoch 482, Loss: 0.07606633426621556, Final Batch Loss: 0.002715952228754759\n",
      "Epoch 483, Loss: 0.08242616709321737, Final Batch Loss: 0.009947486221790314\n",
      "Epoch 484, Loss: 0.04848062340170145, Final Batch Loss: 0.0007274141535162926\n",
      "Epoch 485, Loss: 0.09226186177693307, Final Batch Loss: 0.005634021479636431\n",
      "Epoch 486, Loss: 0.05677795407245867, Final Batch Loss: 0.0002133669040631503\n",
      "Epoch 487, Loss: 0.05224770004861057, Final Batch Loss: 0.0029180890414863825\n",
      "Epoch 488, Loss: 0.043679514434188604, Final Batch Loss: 0.0044344584457576275\n",
      "Epoch 489, Loss: 0.053006202913820744, Final Batch Loss: 0.016686610877513885\n",
      "Epoch 490, Loss: 0.055769242346286774, Final Batch Loss: 0.00976377073675394\n",
      "Epoch 491, Loss: 0.0660935272462666, Final Batch Loss: 0.00032167229801416397\n",
      "Epoch 492, Loss: 0.053336484750616364, Final Batch Loss: 0.00014322290371637791\n",
      "Epoch 493, Loss: 0.04421966290101409, Final Batch Loss: 0.005966811440885067\n",
      "Epoch 494, Loss: 0.04521136567927897, Final Batch Loss: 0.001190130366012454\n",
      "Epoch 495, Loss: 0.04784458637004718, Final Batch Loss: 0.0006127440719865263\n",
      "Epoch 496, Loss: 0.05497543275123462, Final Batch Loss: 0.000338557583745569\n",
      "Epoch 497, Loss: 0.05983390612527728, Final Batch Loss: 0.003640249837189913\n",
      "Epoch 498, Loss: 0.056012706423643976, Final Batch Loss: 0.0005079485126771033\n",
      "Epoch 499, Loss: 0.06082536233589053, Final Batch Loss: 0.000755376648157835\n",
      "Epoch 500, Loss: 0.05843686405569315, Final Batch Loss: 0.013822225853800774\n",
      "Epoch 501, Loss: 0.05745632137404755, Final Batch Loss: 0.0005890143220312893\n",
      "Epoch 502, Loss: 0.05133081553503871, Final Batch Loss: 0.0002573765814304352\n",
      "Epoch 503, Loss: 0.03185998224944342, Final Batch Loss: 9.538438462186605e-05\n",
      "Epoch 504, Loss: 0.03686962177744135, Final Batch Loss: 0.0005563534214161336\n",
      "Epoch 505, Loss: 0.03787054819986224, Final Batch Loss: 0.004712746012955904\n",
      "Epoch 506, Loss: 0.07607211731374264, Final Batch Loss: 0.003145769704133272\n",
      "Epoch 507, Loss: 0.05602874676696956, Final Batch Loss: 0.0021163688506931067\n",
      "Epoch 508, Loss: 0.06763172033242881, Final Batch Loss: 0.0025604532565921545\n",
      "Epoch 509, Loss: 0.07486707828502404, Final Batch Loss: 9.398273687111214e-05\n",
      "Epoch 510, Loss: 0.08211015374399722, Final Batch Loss: 0.01740165986120701\n",
      "Epoch 511, Loss: 0.04673348390497267, Final Batch Loss: 0.004571995697915554\n",
      "Epoch 512, Loss: 0.04644647418172099, Final Batch Loss: 0.00030614659772254527\n",
      "Epoch 513, Loss: 0.07156737381592393, Final Batch Loss: 0.00776611128821969\n",
      "Epoch 514, Loss: 0.055003619054332376, Final Batch Loss: 0.001750563969835639\n",
      "Epoch 515, Loss: 0.04800077946856618, Final Batch Loss: 0.0004605725407600403\n",
      "Epoch 516, Loss: 0.04861216037534177, Final Batch Loss: 0.0018703514942899346\n",
      "Epoch 517, Loss: 0.06252771383151412, Final Batch Loss: 0.005642212461680174\n",
      "Epoch 518, Loss: 0.03256014466751367, Final Batch Loss: 0.0010085623944178224\n",
      "Epoch 519, Loss: 0.06331654079258442, Final Batch Loss: 0.002710032742470503\n",
      "Epoch 520, Loss: 0.04690794716589153, Final Batch Loss: 0.002999198390170932\n",
      "Epoch 521, Loss: 0.0372992148186313, Final Batch Loss: 0.00017359988123644143\n",
      "Epoch 522, Loss: 0.049443501979112625, Final Batch Loss: 0.016346769407391548\n",
      "Epoch 523, Loss: 0.059260614681988955, Final Batch Loss: 0.0009724008850753307\n",
      "Epoch 524, Loss: 0.06500394968315959, Final Batch Loss: 0.004775044973939657\n",
      "Epoch 525, Loss: 0.05692056939005852, Final Batch Loss: 0.003808042500168085\n",
      "Epoch 526, Loss: 0.047920707904268056, Final Batch Loss: 0.00039952161023393273\n",
      "Epoch 527, Loss: 0.048442559549584985, Final Batch Loss: 0.018448617309331894\n",
      "Epoch 528, Loss: 0.04451889466145076, Final Batch Loss: 0.00040483675547875464\n",
      "Epoch 529, Loss: 0.05720351496711373, Final Batch Loss: 0.0022849254310131073\n",
      "Epoch 530, Loss: 0.3106030449271202, Final Batch Loss: 0.25905153155326843\n",
      "Epoch 531, Loss: 0.05297761084511876, Final Batch Loss: 0.006834680680185556\n",
      "Epoch 532, Loss: 0.12589289085008204, Final Batch Loss: 0.001163772540166974\n",
      "Epoch 533, Loss: 0.12861937697743997, Final Batch Loss: 0.0007249651825986803\n",
      "Epoch 534, Loss: 0.1433729249984026, Final Batch Loss: 0.0964856818318367\n",
      "Epoch 535, Loss: 0.0435759324755054, Final Batch Loss: 0.00017586510512046516\n",
      "Epoch 536, Loss: 0.05580964501132257, Final Batch Loss: 0.00032296733115799725\n",
      "Epoch 537, Loss: 0.08221655604029365, Final Batch Loss: 2.3150672859628685e-05\n",
      "Epoch 538, Loss: 0.0559417272452265, Final Batch Loss: 0.0025688831228762865\n",
      "Epoch 539, Loss: 0.030611098918598145, Final Batch Loss: 0.0002571541699580848\n",
      "Epoch 540, Loss: 0.08317727828398347, Final Batch Loss: 0.04552159458398819\n",
      "Epoch 541, Loss: 0.06575138168409467, Final Batch Loss: 0.0046206191182136536\n",
      "Epoch 542, Loss: 0.07206912011679378, Final Batch Loss: 5.262600097921677e-05\n",
      "Epoch 543, Loss: 0.06489664502441883, Final Batch Loss: 0.0033505153842270374\n",
      "Epoch 544, Loss: 0.03922373126260936, Final Batch Loss: 0.002476561814546585\n",
      "Epoch 545, Loss: 0.03749151760712266, Final Batch Loss: 0.010570519603788853\n",
      "Epoch 546, Loss: 0.06137100499472581, Final Batch Loss: 0.00025791986263357103\n",
      "Epoch 547, Loss: 0.05234324082266539, Final Batch Loss: 0.001927322125993669\n",
      "Epoch 548, Loss: 0.0544772301800549, Final Batch Loss: 0.006908015348017216\n",
      "Epoch 549, Loss: 0.05282179836649448, Final Batch Loss: 0.0010981644736602902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550, Loss: 0.04757500495179556, Final Batch Loss: 0.0002914183714892715\n",
      "Epoch 551, Loss: 0.0735106528736651, Final Batch Loss: 0.030595315620303154\n",
      "Epoch 552, Loss: 0.04457505128812045, Final Batch Loss: 0.0016671543708071113\n",
      "Epoch 553, Loss: 0.04374549072235823, Final Batch Loss: 0.009645200334489346\n",
      "Epoch 554, Loss: 0.030241669563110918, Final Batch Loss: 0.0008568209013901651\n",
      "Epoch 555, Loss: 0.0690035296138376, Final Batch Loss: 0.011455037631094456\n",
      "Epoch 556, Loss: 0.038882691180333495, Final Batch Loss: 0.0024511043448001146\n",
      "Epoch 557, Loss: 0.04338357041706331, Final Batch Loss: 0.0003037068818230182\n",
      "Epoch 558, Loss: 0.04227614589035511, Final Batch Loss: 0.00435648113489151\n",
      "Epoch 559, Loss: 0.03820572909899056, Final Batch Loss: 0.0025005240458995104\n",
      "Epoch 560, Loss: 0.03882076236186549, Final Batch Loss: 0.0003780254046432674\n",
      "Epoch 561, Loss: 0.0715542614707374, Final Batch Loss: 6.916092388564721e-05\n",
      "Epoch 562, Loss: 0.029123171443643514, Final Batch Loss: 0.00011613520473474637\n",
      "Epoch 563, Loss: 0.022213955293409526, Final Batch Loss: 0.001893259002827108\n",
      "Epoch 564, Loss: 0.03514851653017104, Final Batch Loss: 0.003596231574192643\n",
      "Epoch 565, Loss: 0.03924360335804522, Final Batch Loss: 0.003542091231793165\n",
      "Epoch 566, Loss: 0.2866781083866954, Final Batch Loss: 0.27003714442253113\n",
      "Epoch 567, Loss: 0.055296534788794816, Final Batch Loss: 0.001478898455388844\n",
      "Epoch 568, Loss: 0.032610096503049135, Final Batch Loss: 0.000714167021214962\n",
      "Epoch 569, Loss: 0.06422301195561886, Final Batch Loss: 0.0071629928424954414\n",
      "Epoch 570, Loss: 0.037473391625098884, Final Batch Loss: 0.00022737157996743917\n",
      "Epoch 571, Loss: 0.037714802543632686, Final Batch Loss: 0.0008743460057303309\n",
      "Epoch 572, Loss: 0.02900326461531222, Final Batch Loss: 0.006807349156588316\n",
      "Epoch 573, Loss: 0.048106909496709704, Final Batch Loss: 0.002664712490513921\n",
      "Epoch 574, Loss: 0.04868353856727481, Final Batch Loss: 0.022769451141357422\n",
      "Epoch 575, Loss: 0.03757696965476498, Final Batch Loss: 0.00033185345819219947\n",
      "Epoch 576, Loss: 0.04513125272933394, Final Batch Loss: 0.001803313265554607\n",
      "Epoch 577, Loss: 0.038650070782750845, Final Batch Loss: 0.001542900688946247\n",
      "Epoch 578, Loss: 0.03832390406751074, Final Batch Loss: 0.0003616285102907568\n",
      "Epoch 579, Loss: 0.03764973394572735, Final Batch Loss: 0.0052484734915196896\n",
      "Epoch 580, Loss: 0.042405220796354115, Final Batch Loss: 0.0016599009977653623\n",
      "Epoch 581, Loss: 0.03322952138114488, Final Batch Loss: 4.668524343287572e-05\n",
      "Epoch 582, Loss: 0.049649365595541894, Final Batch Loss: 0.0007553229806944728\n",
      "Epoch 583, Loss: 0.059606272960081697, Final Batch Loss: 0.04253891855478287\n",
      "Epoch 584, Loss: 0.01883680654282216, Final Batch Loss: 0.00016103046073112637\n",
      "Epoch 585, Loss: 0.022644043317995965, Final Batch Loss: 0.001218785415403545\n",
      "Epoch 586, Loss: 0.053597287740558386, Final Batch Loss: 0.0035939032677561045\n",
      "Epoch 587, Loss: 0.02457896328996867, Final Batch Loss: 0.0013631581095978618\n",
      "Epoch 588, Loss: 0.057376490673050284, Final Batch Loss: 0.037876926362514496\n",
      "Epoch 589, Loss: 0.0438513396657072, Final Batch Loss: 0.0006110423128120601\n",
      "Epoch 590, Loss: 0.04766033939085901, Final Batch Loss: 0.0033882271964102983\n",
      "Epoch 591, Loss: 0.06495879823341966, Final Batch Loss: 0.00882579293102026\n",
      "Epoch 592, Loss: 0.11590360233094543, Final Batch Loss: 0.06797771900892258\n",
      "Epoch 593, Loss: 0.02561164901999291, Final Batch Loss: 8.10687051853165e-05\n",
      "Epoch 594, Loss: 0.05413700867211446, Final Batch Loss: 0.0006439659628085792\n",
      "Epoch 595, Loss: 0.02965700982895214, Final Batch Loss: 0.00020632318046409637\n",
      "Epoch 596, Loss: 0.04027772566769272, Final Batch Loss: 0.001798461307771504\n",
      "Epoch 597, Loss: 0.02671687980182469, Final Batch Loss: 0.0049042729660868645\n",
      "Epoch 598, Loss: 0.02452479694329668, Final Batch Loss: 0.00013020374171901494\n",
      "Epoch 599, Loss: 0.044683926505967975, Final Batch Loss: 0.015781870111823082\n",
      "Epoch 600, Loss: 0.03159247082658112, Final Batch Loss: 0.0034358210396021605\n",
      "Epoch 601, Loss: 0.06700165283837123, Final Batch Loss: 5.228950612945482e-05\n",
      "Epoch 602, Loss: 0.04242406954290345, Final Batch Loss: 0.0008528747712261975\n",
      "Epoch 603, Loss: 0.022053968754335074, Final Batch Loss: 5.6937347835628316e-05\n",
      "Epoch 604, Loss: 0.05731844750698656, Final Batch Loss: 0.0008743788348510861\n",
      "Epoch 605, Loss: 0.038233960745856166, Final Batch Loss: 0.004161928314715624\n",
      "Epoch 606, Loss: 0.1914430393371731, Final Batch Loss: 0.15959201753139496\n",
      "Epoch 607, Loss: 0.032523807720281184, Final Batch Loss: 0.001377283246256411\n",
      "Epoch 608, Loss: 0.11404671348282136, Final Batch Loss: 0.00039415262290276587\n",
      "Epoch 609, Loss: 0.14007811341434717, Final Batch Loss: 0.017571421340107918\n",
      "Epoch 610, Loss: 0.04747139473329298, Final Batch Loss: 0.0002810326113831252\n",
      "Epoch 611, Loss: 0.07272233767434955, Final Batch Loss: 0.0044246758334338665\n",
      "Epoch 612, Loss: 0.2820678725838661, Final Batch Loss: 0.22616128623485565\n",
      "Epoch 613, Loss: 0.047145147022092715, Final Batch Loss: 0.0003746423462871462\n",
      "Epoch 614, Loss: 0.08547067828476429, Final Batch Loss: 0.017587674781680107\n",
      "Epoch 615, Loss: 0.09692610520869493, Final Batch Loss: 0.014331297017633915\n",
      "Epoch 616, Loss: 0.03242221148684621, Final Batch Loss: 0.003313512308523059\n",
      "Epoch 617, Loss: 0.04826747707556933, Final Batch Loss: 0.0016803451580926776\n",
      "Epoch 618, Loss: 0.07157560507766902, Final Batch Loss: 0.025523262098431587\n",
      "Epoch 619, Loss: 0.043898479103518184, Final Batch Loss: 4.060126229887828e-05\n",
      "Epoch 620, Loss: 0.07067050412297249, Final Batch Loss: 0.016399960964918137\n",
      "Epoch 621, Loss: 0.03426335671611014, Final Batch Loss: 3.837236363324337e-05\n",
      "Epoch 622, Loss: 0.030390302592422813, Final Batch Loss: 0.0002644394407980144\n",
      "Epoch 623, Loss: 0.05673302221111953, Final Batch Loss: 0.007251077331602573\n",
      "Epoch 624, Loss: 0.019823578419163823, Final Batch Loss: 0.001352984574623406\n",
      "Epoch 625, Loss: 0.03694884857395664, Final Batch Loss: 0.0008311570272780955\n",
      "Epoch 626, Loss: 0.05945481057278812, Final Batch Loss: 0.029914790764451027\n",
      "Epoch 627, Loss: 0.017283275214140303, Final Batch Loss: 0.00014091267075855285\n",
      "Epoch 628, Loss: 0.028543366817757487, Final Batch Loss: 0.007804516237229109\n",
      "Epoch 629, Loss: 0.03624430822674185, Final Batch Loss: 0.000593773671425879\n",
      "Epoch 630, Loss: 0.03948787087574601, Final Batch Loss: 0.003342697396874428\n",
      "Epoch 631, Loss: 0.020990441742469557, Final Batch Loss: 0.00020981226407457143\n",
      "Epoch 632, Loss: 0.036492968909442425, Final Batch Loss: 0.002002511639147997\n",
      "Epoch 633, Loss: 0.0356945259263739, Final Batch Loss: 0.00687347212806344\n",
      "Epoch 634, Loss: 0.01958055072464049, Final Batch Loss: 0.0008303838549181819\n",
      "Epoch 635, Loss: 0.041630465668276884, Final Batch Loss: 0.0001614830835023895\n",
      "Epoch 636, Loss: 0.021080991718918085, Final Batch Loss: 5.3985510021448135e-05\n",
      "Epoch 637, Loss: 0.06853527552448213, Final Batch Loss: 0.0021326353307813406\n",
      "Epoch 638, Loss: 0.026888705207966268, Final Batch Loss: 0.001041257637552917\n",
      "Epoch 639, Loss: 0.03421708173118532, Final Batch Loss: 0.0021603740751743317\n",
      "Epoch 640, Loss: 0.024090542108751833, Final Batch Loss: 0.006302804220467806\n",
      "Epoch 641, Loss: 0.03632662948803045, Final Batch Loss: 0.00012324904673732817\n",
      "Epoch 642, Loss: 0.03230278647970408, Final Batch Loss: 0.00420257868245244\n",
      "Epoch 643, Loss: 0.010193888095272996, Final Batch Loss: 8.191153938241769e-06\n",
      "Epoch 644, Loss: 0.02405928017833503, Final Batch Loss: 8.199720468837768e-06\n",
      "Epoch 645, Loss: 0.016464118263684213, Final Batch Loss: 0.004407468717545271\n",
      "Epoch 646, Loss: 0.012859018403105438, Final Batch Loss: 0.0012552293483167887\n",
      "Epoch 647, Loss: 0.02066143724368885, Final Batch Loss: 0.0006060544983483851\n",
      "Epoch 648, Loss: 0.016354101277102018, Final Batch Loss: 3.1790263165021315e-05\n",
      "Epoch 649, Loss: 0.027304148534312844, Final Batch Loss: 0.005741597153246403\n",
      "Epoch 650, Loss: 0.020704582682810724, Final Batch Loss: 0.00075938506051898\n",
      "Epoch 651, Loss: 0.020226205175276846, Final Batch Loss: 0.0007096384069882333\n",
      "Epoch 652, Loss: 0.016528189182281494, Final Batch Loss: 0.007297879550606012\n",
      "Epoch 653, Loss: 0.03596563544124365, Final Batch Loss: 0.003443326335400343\n",
      "Epoch 654, Loss: 0.05066872714087367, Final Batch Loss: 0.007097523659467697\n",
      "Epoch 655, Loss: 0.049580791499465704, Final Batch Loss: 0.013313011266291142\n",
      "Epoch 656, Loss: 0.021767750557046384, Final Batch Loss: 0.0009386942838318646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657, Loss: 0.016338369954610243, Final Batch Loss: 0.0002936220553237945\n",
      "Epoch 658, Loss: 0.016139752988237888, Final Batch Loss: 0.0008312765276059508\n",
      "Epoch 659, Loss: 0.0490034958202159, Final Batch Loss: 0.00010466294770594686\n",
      "Epoch 660, Loss: 0.007998079803655855, Final Batch Loss: 6.7180226324126124e-06\n",
      "Epoch 661, Loss: 0.025094267795793712, Final Batch Loss: 0.00067849550396204\n",
      "Epoch 662, Loss: 0.05291709047742188, Final Batch Loss: 0.004797700792551041\n",
      "Epoch 663, Loss: 0.014447912719333544, Final Batch Loss: 0.0003751173208002001\n",
      "Epoch 664, Loss: 0.04923174879513681, Final Batch Loss: 0.0019155207555741072\n",
      "Epoch 665, Loss: 0.03634331573266536, Final Batch Loss: 0.0004896929021924734\n",
      "Epoch 666, Loss: 0.011732299055438489, Final Batch Loss: 0.0004904959932900965\n",
      "Epoch 667, Loss: 0.01824827934615314, Final Batch Loss: 0.0044950819574296474\n",
      "Epoch 668, Loss: 0.04406873086554697, Final Batch Loss: 8.296404121210799e-05\n",
      "Epoch 669, Loss: 0.011001110193319619, Final Batch Loss: 0.0003513926931191236\n",
      "Epoch 670, Loss: 0.008807072474155575, Final Batch Loss: 0.0013610406313091516\n",
      "Epoch 671, Loss: 0.017125342470535543, Final Batch Loss: 0.0001041502328007482\n",
      "Epoch 672, Loss: 0.02767987181141507, Final Batch Loss: 1.3606200809590518e-05\n",
      "Epoch 673, Loss: 0.011935378977796063, Final Batch Loss: 0.0002978058473672718\n",
      "Epoch 674, Loss: 0.0159989406929526, Final Batch Loss: 4.3091840780107304e-05\n",
      "Epoch 675, Loss: 0.01618928788229823, Final Batch Loss: 0.00043929251842200756\n",
      "Epoch 676, Loss: 0.024117070832289755, Final Batch Loss: 0.007655817549675703\n",
      "Epoch 677, Loss: 0.053011191255791346, Final Batch Loss: 4.010453267255798e-06\n",
      "Epoch 678, Loss: 0.018340486664783384, Final Batch Loss: 8.165584404196125e-06\n",
      "Epoch 679, Loss: 0.01699092194212426, Final Batch Loss: 2.047654015768785e-05\n",
      "Epoch 680, Loss: 0.026835703290998936, Final Batch Loss: 0.003207447240129113\n",
      "Epoch 681, Loss: 0.013788445154204965, Final Batch Loss: 0.0003358658868819475\n",
      "Epoch 682, Loss: 0.022533356968779117, Final Batch Loss: 0.0003577747556846589\n",
      "Epoch 683, Loss: 0.042379524325951934, Final Batch Loss: 0.00023898703511804342\n",
      "Epoch 684, Loss: 0.055974494647671236, Final Batch Loss: 4.6418612328125164e-05\n",
      "Epoch 685, Loss: 0.061572709411848336, Final Batch Loss: 0.04884788766503334\n",
      "Epoch 686, Loss: 0.024817320194415515, Final Batch Loss: 1.811867332435213e-05\n",
      "Epoch 687, Loss: 0.07260450591275003, Final Batch Loss: 0.00022884095960762352\n",
      "Epoch 688, Loss: 0.04758522060728865, Final Batch Loss: 3.365585143910721e-05\n",
      "Epoch 689, Loss: 0.0652453703514766, Final Batch Loss: 0.00025002562324516475\n",
      "Epoch 690, Loss: 0.024587478605099022, Final Batch Loss: 0.0013617743970826268\n",
      "Epoch 691, Loss: 0.012914638175061555, Final Batch Loss: 3.36337870976422e-06\n",
      "Epoch 692, Loss: 0.03696667333133519, Final Batch Loss: 0.007087938021868467\n",
      "Epoch 693, Loss: 0.07410370791330934, Final Batch Loss: 0.0016442041378468275\n",
      "Epoch 694, Loss: 0.021740560419857502, Final Batch Loss: 0.004775300621986389\n",
      "Epoch 695, Loss: 0.025618179235607386, Final Batch Loss: 0.0003068288788199425\n",
      "Epoch 696, Loss: 0.022439994907472283, Final Batch Loss: 0.0005291487905196846\n",
      "Epoch 697, Loss: 0.023456968243408483, Final Batch Loss: 9.630480053601786e-05\n",
      "Epoch 698, Loss: 0.027177611831575632, Final Batch Loss: 0.013621014542877674\n",
      "Epoch 699, Loss: 0.02607454074313864, Final Batch Loss: 0.0007526695844717324\n",
      "Epoch 700, Loss: 0.02823478856589645, Final Batch Loss: 0.0018086576601490378\n",
      "Epoch 701, Loss: 0.03204919703057385, Final Batch Loss: 3.9283910155063495e-05\n",
      "Epoch 702, Loss: 0.02612397726625204, Final Batch Loss: 0.0055063264444470406\n",
      "Epoch 703, Loss: 0.0227962797798682, Final Batch Loss: 0.00016784630133770406\n",
      "Epoch 704, Loss: 0.012616889202035964, Final Batch Loss: 0.0014452344039455056\n",
      "Epoch 705, Loss: 0.015181274473434314, Final Batch Loss: 0.0003260017547290772\n",
      "Epoch 706, Loss: 0.033640645900050004, Final Batch Loss: 9.536500328977127e-06\n",
      "Epoch 707, Loss: 0.024947985002654605, Final Batch Loss: 0.00017265665519516915\n",
      "Epoch 708, Loss: 0.03679346447461285, Final Batch Loss: 0.0003124117210973054\n",
      "Epoch 709, Loss: 0.009936851594829932, Final Batch Loss: 0.00028398228459991515\n",
      "Epoch 710, Loss: 0.04321157779486384, Final Batch Loss: 0.00012143082858528942\n",
      "Epoch 711, Loss: 0.03454758201041841, Final Batch Loss: 3.4447966754669324e-05\n",
      "Epoch 712, Loss: 0.014328150582514354, Final Batch Loss: 2.275789483974222e-05\n",
      "Epoch 713, Loss: 0.027817402660730295, Final Batch Loss: 0.00014605226169805974\n",
      "Epoch 714, Loss: 0.016833011410199106, Final Batch Loss: 0.005516770761460066\n",
      "Epoch 715, Loss: 0.023887013783678412, Final Batch Loss: 0.006078357808291912\n",
      "Epoch 716, Loss: 0.024536047887522727, Final Batch Loss: 0.0002858252846635878\n",
      "Epoch 717, Loss: 0.028721264214254916, Final Batch Loss: 0.002846777206286788\n",
      "Epoch 718, Loss: 0.013509788666027589, Final Batch Loss: 3.5762704442277027e-07\n",
      "Epoch 719, Loss: 0.04767446615733206, Final Batch Loss: 0.0006510427338071167\n",
      "Epoch 720, Loss: 0.018070685284328647, Final Batch Loss: 0.00023582456924486905\n",
      "Epoch 721, Loss: 0.032492383987118956, Final Batch Loss: 0.0001104613984352909\n",
      "Epoch 722, Loss: 0.01713690930046141, Final Batch Loss: 0.0009577097371220589\n",
      "Epoch 723, Loss: 0.05071061052149162, Final Batch Loss: 0.00026576773962005973\n",
      "Epoch 724, Loss: 0.02876273369474802, Final Batch Loss: 0.0010239490075036883\n",
      "Epoch 725, Loss: 0.016405351867433637, Final Batch Loss: 0.00034771603532135487\n",
      "Epoch 726, Loss: 0.016132733740960248, Final Batch Loss: 0.00020389440760482103\n",
      "Epoch 727, Loss: 0.02096147515112534, Final Batch Loss: 0.0008116253302432597\n",
      "Epoch 728, Loss: 0.06421186274383217, Final Batch Loss: 0.010186937637627125\n",
      "Epoch 729, Loss: 0.026365955243818462, Final Batch Loss: 0.0012653999729081988\n",
      "Epoch 730, Loss: 0.02060842004721053, Final Batch Loss: 6.955504068173468e-05\n",
      "Epoch 731, Loss: 0.057332657277584076, Final Batch Loss: 0.04430414363741875\n",
      "Epoch 732, Loss: 0.05886972788721323, Final Batch Loss: 0.008424676023423672\n",
      "Epoch 733, Loss: 0.03819109470532567, Final Batch Loss: 1.3052662325208075e-05\n",
      "Epoch 734, Loss: 0.059909940289799124, Final Batch Loss: 0.0006453111418522894\n",
      "Epoch 735, Loss: 0.009260190621716902, Final Batch Loss: 0.0001367826189380139\n",
      "Epoch 736, Loss: 0.039631023437323165, Final Batch Loss: 2.4061782823991962e-05\n",
      "Epoch 737, Loss: 0.036997461938881315, Final Batch Loss: 1.8543811165727675e-05\n",
      "Epoch 738, Loss: 0.024654584065501695, Final Batch Loss: 2.4777256840025075e-05\n",
      "Epoch 739, Loss: 0.017797119944589213, Final Batch Loss: 0.00032657411065883934\n",
      "Epoch 740, Loss: 0.02743691671639681, Final Batch Loss: 0.011360089294612408\n",
      "Epoch 741, Loss: 0.04518616580753587, Final Batch Loss: 0.00034117416362278163\n",
      "Epoch 742, Loss: 0.04833826422691345, Final Batch Loss: 0.006319202017039061\n",
      "Epoch 743, Loss: 0.02343469054903835, Final Batch Loss: 0.00569279445335269\n",
      "Epoch 744, Loss: 0.013039129436947405, Final Batch Loss: 0.0009124195203185081\n",
      "Epoch 745, Loss: 0.021373640340243583, Final Batch Loss: 3.0227838578866795e-06\n",
      "Epoch 746, Loss: 0.023057063575834036, Final Batch Loss: 0.0003117151209153235\n",
      "Epoch 747, Loss: 0.027300807945721317, Final Batch Loss: 4.7474932216573507e-05\n",
      "Epoch 748, Loss: 0.029939062806079164, Final Batch Loss: 0.00033520531724207103\n",
      "Epoch 749, Loss: 0.021869083873298223, Final Batch Loss: 5.6538333410571795e-06\n",
      "Epoch 750, Loss: 0.03104856191202998, Final Batch Loss: 0.0047606476582586765\n",
      "Epoch 751, Loss: 0.04650389513699338, Final Batch Loss: 0.0006719768862240016\n",
      "Epoch 752, Loss: 0.023776956601068377, Final Batch Loss: 0.005129148252308369\n",
      "Epoch 753, Loss: 0.040322408196516335, Final Batch Loss: 0.0008913445053622127\n",
      "Epoch 754, Loss: 0.03263058012817055, Final Batch Loss: 0.021525749936699867\n",
      "Epoch 755, Loss: 0.07227578864603856, Final Batch Loss: 1.3198068700148724e-06\n",
      "Epoch 756, Loss: 0.012453586750780232, Final Batch Loss: 0.00011553075455594808\n",
      "Epoch 757, Loss: 0.015469467150978744, Final Batch Loss: 0.0008108934271149337\n",
      "Epoch 758, Loss: 0.07411948032677174, Final Batch Loss: 0.03923870995640755\n",
      "Epoch 759, Loss: 0.014064351133129094, Final Batch Loss: 0.00011553549120435491\n",
      "Epoch 760, Loss: 0.018265074515511515, Final Batch Loss: 2.9978156817378476e-05\n",
      "Epoch 761, Loss: 0.1438519035000354, Final Batch Loss: 0.10772401094436646\n",
      "Epoch 762, Loss: 0.03289305226644501, Final Batch Loss: 0.0006296822684817016\n",
      "Epoch 763, Loss: 0.010712741774373313, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 764, Loss: 0.04451144870836288, Final Batch Loss: 0.001668822136707604\n",
      "Epoch 765, Loss: 0.031876574154011905, Final Batch Loss: 0.0015515944687649608\n",
      "Epoch 766, Loss: 0.018252280704473378, Final Batch Loss: 5.5095810239436105e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767, Loss: 0.01237463529650995, Final Batch Loss: 1.221823004016187e-05\n",
      "Epoch 768, Loss: 0.0158218518972717, Final Batch Loss: 1.9028657334274612e-05\n",
      "Epoch 769, Loss: 0.03168099451431772, Final Batch Loss: 0.00011063794227084145\n",
      "Epoch 770, Loss: 0.03586382166804469, Final Batch Loss: 6.011436653352575e-06\n",
      "Epoch 771, Loss: 0.02761726512107998, Final Batch Loss: 3.171130083501339e-05\n",
      "Epoch 772, Loss: 0.011445754349551862, Final Batch Loss: 3.967925295000896e-06\n",
      "Epoch 773, Loss: 0.03557085455395281, Final Batch Loss: 0.0036748715210705996\n",
      "Epoch 774, Loss: 0.01389340974856168, Final Batch Loss: 0.0012516116257756948\n",
      "Epoch 775, Loss: 0.022997971239419712, Final Batch Loss: 1.4372309124155436e-05\n",
      "Epoch 776, Loss: 0.018632889084983617, Final Batch Loss: 0.0008725543157197535\n",
      "Epoch 777, Loss: 0.008502826647600159, Final Batch Loss: 0.00024955414119176567\n",
      "Epoch 778, Loss: 0.014075254672206938, Final Batch Loss: 0.0003869147039949894\n",
      "Epoch 779, Loss: 0.021724081365391612, Final Batch Loss: 0.0032610695343464613\n",
      "Epoch 780, Loss: 0.041329955027322285, Final Batch Loss: 0.000130436776089482\n",
      "Epoch 781, Loss: 0.013874598545953631, Final Batch Loss: 0.0012583171483129263\n",
      "Epoch 782, Loss: 0.01765592722222209, Final Batch Loss: 0.0017856338527053595\n",
      "Epoch 783, Loss: 0.04322733774461085, Final Batch Loss: 0.00010593652405077592\n",
      "Epoch 784, Loss: 0.010151829977985471, Final Batch Loss: 0.000270008051302284\n",
      "Epoch 785, Loss: 0.027151308486281778, Final Batch Loss: 1.2541886462713592e-05\n",
      "Epoch 786, Loss: 0.010549925122177228, Final Batch Loss: 0.00012913040700368583\n",
      "Epoch 787, Loss: 0.014408156799618155, Final Batch Loss: 0.0003273271140642464\n",
      "Epoch 788, Loss: 0.049633087881375104, Final Batch Loss: 0.0037281750701367855\n",
      "Epoch 789, Loss: 0.036211292739608325, Final Batch Loss: 9.801705891732126e-05\n",
      "Epoch 790, Loss: 0.03513681562617421, Final Batch Loss: 0.013577151112258434\n",
      "Epoch 791, Loss: 0.021276143583236262, Final Batch Loss: 0.0003342478012200445\n",
      "Epoch 792, Loss: 0.017402891451638425, Final Batch Loss: 4.061099389218725e-05\n",
      "Epoch 793, Loss: 0.04298566980287433, Final Batch Loss: 0.0009538987651467323\n",
      "Epoch 794, Loss: 0.01639925484982996, Final Batch Loss: 1.047332489179098e-06\n",
      "Epoch 795, Loss: 0.031994610268156976, Final Batch Loss: 4.470290150493383e-06\n",
      "Epoch 796, Loss: 0.012688721218182764, Final Batch Loss: 3.984933755418751e-06\n",
      "Epoch 797, Loss: 0.00749501830432564, Final Batch Loss: 0.0003789739275816828\n",
      "Epoch 798, Loss: 0.04827219306025654, Final Batch Loss: 0.0007599993841722608\n",
      "Epoch 799, Loss: 0.013103298144415021, Final Batch Loss: 0.0022425309289246798\n",
      "Epoch 800, Loss: 0.03470096876844764, Final Batch Loss: 0.0008953548385761678\n",
      "Epoch 801, Loss: 0.007635756395757198, Final Batch Loss: 0.00010735890828073025\n",
      "Epoch 802, Loss: 0.006235938330064528, Final Batch Loss: 9.956552821677178e-05\n",
      "Epoch 803, Loss: 0.00988695746370638, Final Batch Loss: 2.043586135869191e-07\n",
      "Epoch 804, Loss: 0.011983497635810636, Final Batch Loss: 6.732622568961233e-05\n",
      "Epoch 805, Loss: 0.0526674137217924, Final Batch Loss: 0.029823658987879753\n",
      "Epoch 806, Loss: 0.016684399888617918, Final Batch Loss: 0.0004536583728622645\n",
      "Epoch 807, Loss: 0.0330281119022402, Final Batch Loss: 5.979713023407385e-05\n",
      "Epoch 808, Loss: 0.024725939030759037, Final Batch Loss: 0.0017495539505034685\n",
      "Epoch 809, Loss: 0.013810529781039804, Final Batch Loss: 0.001209782436490059\n",
      "Epoch 810, Loss: 0.04689825307650608, Final Batch Loss: 5.705473085981794e-05\n",
      "Epoch 811, Loss: 0.026828195674170274, Final Batch Loss: 0.004115647170692682\n",
      "Epoch 812, Loss: 0.012904030256322585, Final Batch Loss: 0.0002251592668471858\n",
      "Epoch 813, Loss: 0.008296785148559138, Final Batch Loss: 0.0001530976442154497\n",
      "Epoch 814, Loss: 0.027425042749200657, Final Batch Loss: 1.209932361234678e-05\n",
      "Epoch 815, Loss: 0.01098554494092241, Final Batch Loss: 0.00024934980319812894\n",
      "Epoch 816, Loss: 0.005192053988139378, Final Batch Loss: 3.1791500077815726e-05\n",
      "Epoch 817, Loss: 0.026197862360277213, Final Batch Loss: 0.00013519918138626963\n",
      "Epoch 818, Loss: 0.04370210724300705, Final Batch Loss: 0.03460272029042244\n",
      "Epoch 819, Loss: 0.020429179829079658, Final Batch Loss: 0.0006897732964716852\n",
      "Epoch 820, Loss: 0.0072397006006212905, Final Batch Loss: 0.00016453310672659427\n",
      "Epoch 821, Loss: 0.015637867123587057, Final Batch Loss: 0.00027288697310723364\n",
      "Epoch 822, Loss: 0.014507099931051926, Final Batch Loss: 7.356694823101861e-06\n",
      "Epoch 823, Loss: 0.01809012720332248, Final Batch Loss: 0.00010118824866367504\n",
      "Epoch 824, Loss: 0.014184667107656423, Final Batch Loss: 8.591120604251046e-06\n",
      "Epoch 825, Loss: 0.013380909455008805, Final Batch Loss: 0.0012188516557216644\n",
      "Epoch 826, Loss: 0.030926121631637216, Final Batch Loss: 0.0016266971360892057\n",
      "Epoch 827, Loss: 0.018409399321171804, Final Batch Loss: 1.238860386365559e-05\n",
      "Epoch 828, Loss: 0.020744079491123557, Final Batch Loss: 0.004113173112273216\n",
      "Epoch 829, Loss: 0.005928243524977006, Final Batch Loss: 0.00016215928189922124\n",
      "Epoch 830, Loss: 0.017282909073401242, Final Batch Loss: 0.00032078963704407215\n",
      "Epoch 831, Loss: 0.0070927347405813634, Final Batch Loss: 0.00030095450347289443\n",
      "Epoch 832, Loss: 0.01574530662765028, Final Batch Loss: 0.00012206845713080838\n",
      "Epoch 833, Loss: 0.011357630161000998, Final Batch Loss: 2.3676222554058768e-05\n",
      "Epoch 834, Loss: 0.013593941053841263, Final Batch Loss: 0.004647435154765844\n",
      "Epoch 835, Loss: 0.017180216149426997, Final Batch Loss: 0.0014394790632650256\n",
      "Epoch 836, Loss: 0.007920692723928369, Final Batch Loss: 1.8033539163297974e-05\n",
      "Epoch 837, Loss: 0.027492231502264985, Final Batch Loss: 3.2696864309400553e-06\n",
      "Epoch 838, Loss: 0.011704163208690943, Final Batch Loss: 4.427759847658308e-07\n",
      "Epoch 839, Loss: 0.02453873085323721, Final Batch Loss: 0.0012095281854271889\n",
      "Epoch 840, Loss: 0.008878863121594804, Final Batch Loss: 9.536703373669297e-07\n",
      "Epoch 841, Loss: 0.018175335738305876, Final Batch Loss: 4.274442289897706e-06\n",
      "Epoch 842, Loss: 0.014569307641068008, Final Batch Loss: 6.937474972801283e-05\n",
      "Epoch 843, Loss: 0.018954471961478703, Final Batch Loss: 0.00017870105511974543\n",
      "Epoch 844, Loss: 0.013780764603126272, Final Batch Loss: 3.320826920116815e-07\n",
      "Epoch 845, Loss: 0.014476094976998866, Final Batch Loss: 0.002414129441604018\n",
      "Epoch 846, Loss: 0.025107992463745177, Final Batch Loss: 0.00024423672584816813\n",
      "Epoch 847, Loss: 0.019627767615020275, Final Batch Loss: 0.005178752820938826\n",
      "Epoch 848, Loss: 0.005974501254968345, Final Batch Loss: 0.0004748721548821777\n",
      "Epoch 849, Loss: 0.031668639596318826, Final Batch Loss: 0.011429617181420326\n",
      "Epoch 850, Loss: 0.01450398805536679, Final Batch Loss: 3.666188786155544e-05\n",
      "Epoch 851, Loss: 0.015372085850685835, Final Batch Loss: 0.0001206560991704464\n",
      "Epoch 852, Loss: 0.02335129666607827, Final Batch Loss: 0.001264789025299251\n",
      "Epoch 853, Loss: 0.009572206495249702, Final Batch Loss: 8.599913599027786e-06\n",
      "Epoch 854, Loss: 0.031562287877022754, Final Batch Loss: 5.312274879543111e-05\n",
      "Epoch 855, Loss: 0.005899138850509189, Final Batch Loss: 0.00015152983542066067\n",
      "Epoch 856, Loss: 0.40798150905175135, Final Batch Loss: 0.4010177254676819\n",
      "Epoch 857, Loss: 0.031398142891703174, Final Batch Loss: 0.0003162760112900287\n",
      "Epoch 858, Loss: 0.09761389117920771, Final Batch Loss: 0.0006080405437387526\n",
      "Epoch 859, Loss: 0.08707189559936523, Final Batch Loss: 0.006143701262772083\n",
      "Epoch 860, Loss: 0.02322209463454783, Final Batch Loss: 0.00033071055077016354\n",
      "Epoch 861, Loss: 0.04823470351402648, Final Batch Loss: 0.0004588985175359994\n",
      "Epoch 862, Loss: 0.020308038248913363, Final Batch Loss: 0.0003152205899823457\n",
      "Epoch 863, Loss: 0.03910985016045743, Final Batch Loss: 5.0253558583790436e-05\n",
      "Epoch 864, Loss: 0.027611320314463228, Final Batch Loss: 0.0002477482776157558\n",
      "Epoch 865, Loss: 0.015375643235529424, Final Batch Loss: 2.3338210667134263e-05\n",
      "Epoch 866, Loss: 0.016677520354278386, Final Batch Loss: 0.0010182323167100549\n",
      "Epoch 867, Loss: 0.03355552686844021, Final Batch Loss: 0.000645051128230989\n",
      "Epoch 868, Loss: 0.026907693478278816, Final Batch Loss: 0.0020937740337103605\n",
      "Epoch 869, Loss: 0.0472022477258065, Final Batch Loss: 5.108956315780233e-07\n",
      "Epoch 870, Loss: 0.011127543599286582, Final Batch Loss: 9.993157436838374e-05\n",
      "Epoch 871, Loss: 0.0093852995087218, Final Batch Loss: 2.5720208213897422e-05\n",
      "Epoch 872, Loss: 0.013151367485988885, Final Batch Loss: 0.0014662452740594745\n",
      "Epoch 873, Loss: 0.006714262854075059, Final Batch Loss: 0.00046346578164957464\n",
      "Epoch 874, Loss: 0.03303289075847715, Final Batch Loss: 0.0014823450474068522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875, Loss: 0.013868055153579917, Final Batch Loss: 6.511908577522263e-05\n",
      "Epoch 876, Loss: 0.029550659892265685, Final Batch Loss: 0.0001722996385069564\n",
      "Epoch 877, Loss: 0.009084907433134504, Final Batch Loss: 0.0001779214508133009\n",
      "Epoch 878, Loss: 0.02674505952745676, Final Batch Loss: 0.0078074256889522076\n",
      "Epoch 879, Loss: 0.010218503768456344, Final Batch Loss: 1.1920919007479824e-07\n",
      "Epoch 880, Loss: 0.021564507856965065, Final Batch Loss: 0.0022403427865356207\n",
      "Epoch 881, Loss: 0.006450168235460296, Final Batch Loss: 0.00013842745102010667\n",
      "Epoch 882, Loss: 0.011453236850684334, Final Batch Loss: 1.4968264622439165e-05\n",
      "Epoch 883, Loss: 0.006138045483112364, Final Batch Loss: 5.236561719357269e-06\n",
      "Epoch 884, Loss: 0.05435322847915813, Final Batch Loss: 0.04639880731701851\n",
      "Epoch 885, Loss: 0.007428858761791446, Final Batch Loss: 1.1069432304111615e-07\n",
      "Epoch 886, Loss: 0.004752174216264393, Final Batch Loss: 6.173177098389715e-06\n",
      "Epoch 887, Loss: 0.014014705258887261, Final Batch Loss: 0.0018551696557551622\n",
      "Epoch 888, Loss: 0.08056155931262765, Final Batch Loss: 1.8245205865241587e-05\n",
      "Epoch 889, Loss: 0.024042117046974454, Final Batch Loss: 6.2922931647335645e-06\n",
      "Epoch 890, Loss: 0.022758013765269425, Final Batch Loss: 6.569732067873701e-05\n",
      "Epoch 891, Loss: 0.022971289610723034, Final Batch Loss: 0.00034571767901070416\n",
      "Epoch 892, Loss: 0.021157633737175274, Final Batch Loss: 3.2015871056501055e-06\n",
      "Epoch 893, Loss: 0.02879456547088921, Final Batch Loss: 0.002038243692368269\n",
      "Epoch 894, Loss: 0.029975369972817134, Final Batch Loss: 9.926739585353062e-05\n",
      "Epoch 895, Loss: 0.024292363552376628, Final Batch Loss: 0.005386393517255783\n",
      "Epoch 896, Loss: 0.036443083273297816, Final Batch Loss: 1.2320076166361105e-05\n",
      "Epoch 897, Loss: 0.022906409081770107, Final Batch Loss: 0.00029916022322140634\n",
      "Epoch 898, Loss: 0.016173441661521792, Final Batch Loss: 0.0005234518321231008\n",
      "Epoch 899, Loss: 0.041432708443608135, Final Batch Loss: 0.0293154064565897\n",
      "Epoch 900, Loss: 0.019008858274901286, Final Batch Loss: 0.000333843199769035\n",
      "Epoch 901, Loss: 0.006292539736023173, Final Batch Loss: 0.00034688948653638363\n",
      "Epoch 902, Loss: 0.01571948191121919, Final Batch Loss: 0.0015439463313668966\n",
      "Epoch 903, Loss: 0.02721324921640189, Final Batch Loss: 9.025424333231058e-06\n",
      "Epoch 904, Loss: 0.020772627569385804, Final Batch Loss: 7.754190301056951e-05\n",
      "Epoch 905, Loss: 0.02382856304757297, Final Batch Loss: 0.0010486416285857558\n",
      "Epoch 906, Loss: 0.0159689619904384, Final Batch Loss: 0.00010170915629714727\n",
      "Epoch 907, Loss: 0.00808434613281861, Final Batch Loss: 0.00013376062270253897\n",
      "Epoch 908, Loss: 0.006167309169541113, Final Batch Loss: 6.373472569976002e-05\n",
      "Epoch 909, Loss: 0.010839873575605452, Final Batch Loss: 0.0007555970223620534\n",
      "Epoch 910, Loss: 0.011254651541776184, Final Batch Loss: 1.9499100289976923e-06\n",
      "Epoch 911, Loss: 0.02101079445810683, Final Batch Loss: 4.836372227146057e-06\n",
      "Epoch 912, Loss: 0.01635138806886971, Final Batch Loss: 0.00020759180188179016\n",
      "Epoch 913, Loss: 0.011843753323773853, Final Batch Loss: 0.00018315562920179218\n",
      "Epoch 914, Loss: 0.008344311048858799, Final Batch Loss: 7.398404704872519e-05\n",
      "Epoch 915, Loss: 0.0049743274139473215, Final Batch Loss: 0.0001700318680377677\n",
      "Epoch 916, Loss: 0.01101712426998347, Final Batch Loss: 5.900728410779266e-06\n",
      "Epoch 917, Loss: 0.021654147072695196, Final Batch Loss: 0.001821710728108883\n",
      "Epoch 918, Loss: 0.026168622949626297, Final Batch Loss: 0.0017689457163214684\n",
      "Epoch 919, Loss: 0.011689631728586392, Final Batch Loss: 2.794150532281492e-05\n",
      "Epoch 920, Loss: 0.01880058779238425, Final Batch Loss: 1.4475403986580204e-07\n",
      "Epoch 921, Loss: 0.012642989924643189, Final Batch Loss: 0.0004935752949677408\n",
      "Epoch 922, Loss: 0.02955654068500735, Final Batch Loss: 0.0018902597948908806\n",
      "Epoch 923, Loss: 0.01190294508705847, Final Batch Loss: 0.00035061314702033997\n",
      "Epoch 924, Loss: 0.025308420736109838, Final Batch Loss: 0.0002805378462653607\n",
      "Epoch 925, Loss: 0.05458410852588713, Final Batch Loss: 0.026274455711245537\n",
      "Epoch 926, Loss: 0.01893064204705297, Final Batch Loss: 2.4025208404054865e-05\n",
      "Epoch 927, Loss: 0.03492429131438257, Final Batch Loss: 9.701308590592816e-05\n",
      "Epoch 928, Loss: 0.05241126741748303, Final Batch Loss: 0.0010170204332098365\n",
      "Epoch 929, Loss: 0.034237719723023474, Final Batch Loss: 0.0007066610269248486\n",
      "Epoch 930, Loss: 0.020806846034247428, Final Batch Loss: 0.009630479849874973\n",
      "Epoch 931, Loss: 0.011040250571177523, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 932, Loss: 0.04606461359071545, Final Batch Loss: 0.00042729670531116426\n",
      "Epoch 933, Loss: 0.02726814574270975, Final Batch Loss: 6.130673864390701e-05\n",
      "Epoch 934, Loss: 0.11769046768313274, Final Batch Loss: 0.09947601705789566\n",
      "Epoch 935, Loss: 0.0339434077613987, Final Batch Loss: 0.009878815151751041\n",
      "Epoch 936, Loss: 0.21845913666766137, Final Batch Loss: 0.17071740329265594\n",
      "Epoch 937, Loss: 0.04223684526368743, Final Batch Loss: 3.4087592212017626e-05\n",
      "Epoch 938, Loss: 0.0505362207586586, Final Batch Loss: 2.5227414880646393e-05\n",
      "Epoch 939, Loss: 0.07545787881826982, Final Batch Loss: 0.0008842164534144104\n",
      "Epoch 940, Loss: 0.15908954525366426, Final Batch Loss: 0.10605216026306152\n",
      "Epoch 941, Loss: 0.03358747022866737, Final Batch Loss: 0.0001599459646968171\n",
      "Epoch 942, Loss: 0.07301515806466341, Final Batch Loss: 0.003322916105389595\n",
      "Epoch 943, Loss: 0.032926802057772875, Final Batch Loss: 0.0005630794912576675\n",
      "Epoch 944, Loss: 0.03442556725349277, Final Batch Loss: 0.00019760883878916502\n",
      "Epoch 945, Loss: 0.05423068023446831, Final Batch Loss: 4.879101106780581e-05\n",
      "Epoch 946, Loss: 0.03056764384291455, Final Batch Loss: 7.594963790324982e-06\n",
      "Epoch 947, Loss: 0.0187338947544049, Final Batch Loss: 3.428542913752608e-05\n",
      "Epoch 948, Loss: 0.01293637219350785, Final Batch Loss: 6.175530143082142e-05\n",
      "Epoch 949, Loss: 0.012258314425707795, Final Batch Loss: 0.00016775763651821762\n",
      "Epoch 950, Loss: 0.021800277158035897, Final Batch Loss: 8.632520621176809e-05\n",
      "Epoch 951, Loss: 0.013712688723899191, Final Batch Loss: 2.3082156985765323e-05\n",
      "Epoch 952, Loss: 0.012007698547677137, Final Batch Loss: 0.00022177382197696716\n",
      "Epoch 953, Loss: 0.04700612862507114, Final Batch Loss: 1.0183292033616453e-05\n",
      "Epoch 954, Loss: 0.037453933036886156, Final Batch Loss: 0.00010750000365078449\n",
      "Epoch 955, Loss: 0.015326509717851877, Final Batch Loss: 0.0068237632513046265\n",
      "Epoch 956, Loss: 0.01323357643559575, Final Batch Loss: 5.4566189646720886e-05\n",
      "Epoch 957, Loss: 0.012824994952097768, Final Batch Loss: 5.924332435824908e-05\n",
      "Epoch 958, Loss: 0.031365409144200385, Final Batch Loss: 0.007830413058400154\n",
      "Epoch 959, Loss: 0.023276326479390264, Final Batch Loss: 0.001296713831834495\n",
      "Epoch 960, Loss: 0.010734209034126252, Final Batch Loss: 0.00028251251205801964\n",
      "Epoch 961, Loss: 0.01858264353359118, Final Batch Loss: 0.002122323727235198\n",
      "Epoch 962, Loss: 0.01587768821627833, Final Batch Loss: 0.00040098061435855925\n",
      "Epoch 963, Loss: 0.03191961928314413, Final Batch Loss: 7.663438736926764e-07\n",
      "Epoch 964, Loss: 0.00834853487322107, Final Batch Loss: 0.003581755328923464\n",
      "Epoch 965, Loss: 0.011364630307070911, Final Batch Loss: 0.0036723811645060778\n",
      "Epoch 966, Loss: 0.008515361521858722, Final Batch Loss: 0.0005507164751179516\n",
      "Epoch 967, Loss: 0.025446410221775295, Final Batch Loss: 4.231889761285856e-06\n",
      "Epoch 968, Loss: 0.020142577646765858, Final Batch Loss: 0.013031347654759884\n",
      "Epoch 969, Loss: 0.1815669967327267, Final Batch Loss: 0.168905109167099\n",
      "Epoch 970, Loss: 0.006834458181401715, Final Batch Loss: 0.00032003314117901027\n",
      "Epoch 971, Loss: 0.05277151883637998, Final Batch Loss: 0.00011216466373298317\n",
      "Epoch 972, Loss: 0.04488231998402625, Final Batch Loss: 0.0014874321641400456\n",
      "Epoch 973, Loss: 0.010130429349374026, Final Batch Loss: 0.0003103713970631361\n",
      "Epoch 974, Loss: 0.024822359322570264, Final Batch Loss: 0.0014290226390585303\n",
      "Epoch 975, Loss: 0.007829946582205594, Final Batch Loss: 3.818387631326914e-05\n",
      "Epoch 976, Loss: 0.005660546725266613, Final Batch Loss: 9.899250289890915e-05\n",
      "Epoch 977, Loss: 0.013716592854621013, Final Batch Loss: 1.58376599301846e-06\n",
      "Epoch 978, Loss: 0.011415690649300814, Final Batch Loss: 0.00014543719589710236\n",
      "Epoch 979, Loss: 0.0176157386158593, Final Batch Loss: 0.001568335690535605\n",
      "Epoch 980, Loss: 0.02070605346739285, Final Batch Loss: 3.618763685153681e-06\n",
      "Epoch 981, Loss: 0.015471060964046046, Final Batch Loss: 0.0002742269716691226\n",
      "Epoch 982, Loss: 0.02124279085546732, Final Batch Loss: 0.0005442939000204206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983, Loss: 0.015196740787359886, Final Batch Loss: 0.00021696909971069545\n",
      "Epoch 984, Loss: 0.0074633926269598305, Final Batch Loss: 0.0016339365392923355\n",
      "Epoch 985, Loss: 0.04028429993195459, Final Batch Loss: 0.0037122643552720547\n",
      "Epoch 986, Loss: 0.00967399759269938, Final Batch Loss: 1.6518827123945812e-06\n",
      "Epoch 987, Loss: 0.016294330634082144, Final Batch Loss: 8.84653036337113e-06\n",
      "Epoch 988, Loss: 0.011399884075672162, Final Batch Loss: 4.163718131167116e-06\n",
      "Epoch 989, Loss: 0.061157743679359555, Final Batch Loss: 0.021381622180342674\n",
      "Epoch 990, Loss: 0.011057723888370674, Final Batch Loss: 8.136271935654804e-05\n",
      "Epoch 991, Loss: 0.042271472280845046, Final Batch Loss: 0.00739684421569109\n",
      "Epoch 992, Loss: 0.027041454100981355, Final Batch Loss: 0.0015398355899378657\n",
      "Epoch 993, Loss: 0.01365102973068133, Final Batch Loss: 0.005544375628232956\n",
      "Epoch 994, Loss: 0.01151021133409813, Final Batch Loss: 0.002273957710713148\n",
      "Epoch 995, Loss: 0.01338925879827002, Final Batch Loss: 0.00010980576189467683\n",
      "Epoch 996, Loss: 0.012701648636721075, Final Batch Loss: 0.001922994153574109\n",
      "Epoch 997, Loss: 0.005275511804939015, Final Batch Loss: 5.009326196159236e-05\n",
      "Epoch 998, Loss: 0.005381017384934239, Final Batch Loss: 8.198410796467215e-05\n",
      "Epoch 999, Loss: 0.006302556808805093, Final Batch Loss: 0.0002540740242693573\n",
      "Epoch 1000, Loss: 0.045102930649591144, Final Batch Loss: 9.54113420448266e-05\n",
      "Epoch 1001, Loss: 0.009819034199608723, Final Batch Loss: 2.3718752345303074e-05\n",
      "Epoch 1002, Loss: 0.005960943846730515, Final Batch Loss: 0.0005454263300634921\n",
      "Epoch 1003, Loss: 0.013984889390712851, Final Batch Loss: 2.4011844743654365e-06\n",
      "Epoch 1004, Loss: 0.009310471796197817, Final Batch Loss: 0.0026036794297397137\n",
      "Epoch 1005, Loss: 0.01819789459477761, Final Batch Loss: 4.100476871826686e-05\n",
      "Epoch 1006, Loss: 0.021320680448980056, Final Batch Loss: 9.877273896563565e-07\n",
      "Epoch 1007, Loss: 0.07770093635190278, Final Batch Loss: 0.06244125962257385\n",
      "Epoch 1008, Loss: 0.026214629877358675, Final Batch Loss: 0.002015788108110428\n",
      "Epoch 1009, Loss: 0.00807587908275309, Final Batch Loss: 5.189982402953319e-05\n",
      "Epoch 1010, Loss: 0.01447827965102988, Final Batch Loss: 6.036973445588956e-06\n",
      "Epoch 1011, Loss: 0.006223978900379734, Final Batch Loss: 1.7131056665675715e-05\n",
      "Epoch 1012, Loss: 0.016179924532480072, Final Batch Loss: 0.00011236668069614097\n",
      "Epoch 1013, Loss: 0.03108007926493883, Final Batch Loss: 0.0018134888960048556\n",
      "Epoch 1014, Loss: 0.018515461786591914, Final Batch Loss: 6.325521826511249e-05\n",
      "Epoch 1015, Loss: 0.021202556272328366, Final Batch Loss: 7.907843246357515e-05\n",
      "Epoch 1016, Loss: 0.013570009454269893, Final Batch Loss: 0.006969900336116552\n",
      "Epoch 1017, Loss: 0.025914922531228513, Final Batch Loss: 0.007975898683071136\n",
      "Epoch 1018, Loss: 0.016711260033844155, Final Batch Loss: 3.7039153539808467e-06\n",
      "Epoch 1019, Loss: 0.0045542746665887535, Final Batch Loss: 0.00013551708252634853\n",
      "Epoch 1020, Loss: 0.006786979589378461, Final Batch Loss: 0.0004523176758084446\n",
      "Epoch 1021, Loss: 0.0177177322038915, Final Batch Loss: 0.00027956513804383576\n",
      "Epoch 1022, Loss: 0.007576337886348483, Final Batch Loss: 1.6305320968967862e-05\n",
      "Epoch 1023, Loss: 0.030399151844903827, Final Batch Loss: 0.0012272046878933907\n",
      "Epoch 1024, Loss: 0.005129001128807431, Final Batch Loss: 2.8454083803808317e-05\n",
      "Epoch 1025, Loss: 0.008710150825208984, Final Batch Loss: 0.00012280033843126148\n",
      "Epoch 1026, Loss: 0.010975526238325983, Final Batch Loss: 0.0002943399013020098\n",
      "Epoch 1027, Loss: 0.0064685396500863135, Final Batch Loss: 3.714731428772211e-05\n",
      "Epoch 1028, Loss: 0.008668330905493349, Final Batch Loss: 0.0032304455526173115\n",
      "Epoch 1029, Loss: 0.027382500877138227, Final Batch Loss: 0.0029839277267456055\n",
      "Epoch 1030, Loss: 0.020205921377055347, Final Batch Loss: 0.0001061796210706234\n",
      "Epoch 1031, Loss: 0.009241891093779486, Final Batch Loss: 2.579996589702205e-06\n",
      "Epoch 1032, Loss: 0.02233787369914353, Final Batch Loss: 0.0037517454475164413\n",
      "Epoch 1033, Loss: 0.006847995478892699, Final Batch Loss: 0.003563188249245286\n",
      "Epoch 1034, Loss: 0.011772100893722381, Final Batch Loss: 3.241767262807116e-05\n",
      "Epoch 1035, Loss: 0.033486869504486094, Final Batch Loss: 8.965695087681524e-06\n",
      "Epoch 1036, Loss: 0.009397331602258419, Final Batch Loss: 2.929102947746287e-06\n",
      "Epoch 1037, Loss: 0.0560579446319025, Final Batch Loss: 0.012116136960685253\n",
      "Epoch 1038, Loss: 0.02215859605348669, Final Batch Loss: 4.4553453335538507e-05\n",
      "Epoch 1039, Loss: 0.02405226806695282, Final Batch Loss: 2.229738856840413e-05\n",
      "Epoch 1040, Loss: 0.03366555867251009, Final Batch Loss: 0.006397489923983812\n",
      "Epoch 1041, Loss: 0.008507909452767137, Final Batch Loss: 1.0217934942602369e-07\n",
      "Epoch 1042, Loss: 0.012875353250592525, Final Batch Loss: 2.946154154415126e-06\n",
      "Epoch 1043, Loss: 0.008558897192415316, Final Batch Loss: 6.643686356255785e-05\n",
      "Epoch 1044, Loss: 0.0056697063555475324, Final Batch Loss: 0.0022650829050689936\n",
      "Epoch 1045, Loss: 0.02639770758105442, Final Batch Loss: 0.00027491635410115123\n",
      "Epoch 1046, Loss: 0.012765664321705117, Final Batch Loss: 2.21387563215103e-06\n",
      "Epoch 1047, Loss: 0.019644506988697685, Final Batch Loss: 0.0002351406292291358\n",
      "Epoch 1048, Loss: 0.010521259907193325, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 1049, Loss: 0.010891132231108713, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 1050, Loss: 0.004645609533667994, Final Batch Loss: 1.9584365418268135e-07\n",
      "Epoch 1051, Loss: 0.035732708318391815, Final Batch Loss: 0.008750724606215954\n",
      "Epoch 1052, Loss: 0.04056968979421072, Final Batch Loss: 0.0013326200423762202\n",
      "Epoch 1053, Loss: 0.013390151609200984, Final Batch Loss: 0.005645195487886667\n",
      "Epoch 1054, Loss: 0.010829223960172385, Final Batch Loss: 0.0006340228719636798\n",
      "Epoch 1055, Loss: 0.012784240148903336, Final Batch Loss: 9.63010752457194e-05\n",
      "Epoch 1056, Loss: 0.03547186489049636, Final Batch Loss: 1.1188067219336517e-05\n",
      "Epoch 1057, Loss: 0.020788690897461493, Final Batch Loss: 0.0001091294179786928\n",
      "Epoch 1058, Loss: 0.019679442640608613, Final Batch Loss: 5.755875008617295e-06\n",
      "Epoch 1059, Loss: 0.013769753739666157, Final Batch Loss: 7.152524403863936e-07\n",
      "Epoch 1060, Loss: 0.006269013261771761, Final Batch Loss: 0.0011589772766456008\n",
      "Epoch 1061, Loss: 0.016717326565412804, Final Batch Loss: 0.01011343952268362\n",
      "Epoch 1062, Loss: 0.03969904596539209, Final Batch Loss: 4.598064720084949e-07\n",
      "Epoch 1063, Loss: 0.0065136066423292505, Final Batch Loss: 1.6015985238482244e-05\n",
      "Epoch 1064, Loss: 0.039077062374531124, Final Batch Loss: 5.875300530533423e-07\n",
      "Epoch 1065, Loss: 0.027534513297723606, Final Batch Loss: 0.0005073228967376053\n",
      "Epoch 1066, Loss: 0.01929937549357419, Final Batch Loss: 1.7284550267504528e-05\n",
      "Epoch 1067, Loss: 0.008215736044803634, Final Batch Loss: 0.00030010208138264716\n",
      "Epoch 1068, Loss: 0.008487130777666607, Final Batch Loss: 3.848661890515359e-06\n",
      "Epoch 1069, Loss: 0.02119872202456463, Final Batch Loss: 0.0001256424147868529\n",
      "Epoch 1070, Loss: 0.011218541738344356, Final Batch Loss: 0.004558548331260681\n",
      "Epoch 1071, Loss: 0.011452134232968092, Final Batch Loss: 0.0012787885498255491\n",
      "Epoch 1072, Loss: 0.007509822666179389, Final Batch Loss: 0.00102785334456712\n",
      "Epoch 1073, Loss: 0.006763913745089667, Final Batch Loss: 3.237686541979201e-05\n",
      "Epoch 1074, Loss: 0.007047748749556604, Final Batch Loss: 3.7465704849637405e-07\n",
      "Epoch 1075, Loss: 0.007959165348438546, Final Batch Loss: 0.001308120903559029\n",
      "Epoch 1076, Loss: 0.02040042818407528, Final Batch Loss: 0.00014619386638514698\n",
      "Epoch 1077, Loss: 0.007053849237536269, Final Batch Loss: 3.3633343718975084e-06\n",
      "Epoch 1078, Loss: 0.0055120028810051735, Final Batch Loss: 6.173122528707609e-06\n",
      "Epoch 1079, Loss: 0.04032958781499474, Final Batch Loss: 1.451663592888508e-05\n",
      "Epoch 1080, Loss: 0.030684407480293885, Final Batch Loss: 0.028566820546984673\n",
      "Epoch 1081, Loss: 0.01668361888732761, Final Batch Loss: 0.0003579985350370407\n",
      "Epoch 1082, Loss: 0.011326753530738642, Final Batch Loss: 2.011941614910029e-05\n",
      "Epoch 1083, Loss: 0.03675059229135513, Final Batch Loss: 0.021560635417699814\n",
      "Epoch 1084, Loss: 0.026270858168061295, Final Batch Loss: 7.663433621019067e-07\n",
      "Epoch 1085, Loss: 0.00622873316751793, Final Batch Loss: 0.0006665139808319509\n",
      "Epoch 1086, Loss: 0.006427383490517968, Final Batch Loss: 5.5639862694079056e-05\n",
      "Epoch 1087, Loss: 0.010335823073546635, Final Batch Loss: 2.0764960936503485e-05\n",
      "Epoch 1088, Loss: 0.006288180855335668, Final Batch Loss: 0.00046792920329608023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1089, Loss: 0.02266938058892265, Final Batch Loss: 0.010359169915318489\n",
      "Epoch 1090, Loss: 0.04436870258359704, Final Batch Loss: 0.00023478188086301088\n",
      "Epoch 1091, Loss: 0.009227785375230724, Final Batch Loss: 2.6396327257316443e-07\n",
      "Epoch 1092, Loss: 0.026472789568021682, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 1093, Loss: 0.01127886722315452, Final Batch Loss: 2.775573739199899e-05\n",
      "Epoch 1094, Loss: 0.011624073772964039, Final Batch Loss: 3.916840341844363e-06\n",
      "Epoch 1095, Loss: 0.024051425003563054, Final Batch Loss: 0.00020614142704289407\n",
      "Epoch 1096, Loss: 0.009949254304956412, Final Batch Loss: 5.530984708457254e-05\n",
      "Epoch 1097, Loss: 0.018939313042210415, Final Batch Loss: 0.001376151223666966\n",
      "Epoch 1098, Loss: 0.007530736082117073, Final Batch Loss: 0.00020529584435280412\n",
      "Epoch 1099, Loss: 0.006275432169786654, Final Batch Loss: 0.0001694193488219753\n",
      "Epoch 1100, Loss: 0.005138849533977918, Final Batch Loss: 0.002192628802731633\n",
      "Epoch 1101, Loss: 0.006620517671990456, Final Batch Loss: 1.2431721643224591e-06\n",
      "Epoch 1102, Loss: 0.008650371550174896, Final Batch Loss: 7.794195698807016e-05\n",
      "Epoch 1103, Loss: 0.012732105315080844, Final Batch Loss: 0.0001984828122658655\n",
      "Epoch 1104, Loss: 0.016305708122672513, Final Batch Loss: 0.001107856398448348\n",
      "Epoch 1105, Loss: 0.017262732093513478, Final Batch Loss: 0.00011550571798579767\n",
      "Epoch 1106, Loss: 0.010688591995858587, Final Batch Loss: 0.0002184970217058435\n",
      "Epoch 1107, Loss: 0.015664736813107538, Final Batch Loss: 6.045593750059197e-07\n",
      "Epoch 1108, Loss: 0.008896889863535762, Final Batch Loss: 0.0013632402988150716\n",
      "Epoch 1109, Loss: 0.024563315499108285, Final Batch Loss: 0.001141343847848475\n",
      "Epoch 1110, Loss: 0.0073077279957942665, Final Batch Loss: 0.0010377210564911366\n",
      "Epoch 1111, Loss: 0.014045496325707063, Final Batch Loss: 2.612764365039766e-05\n",
      "Epoch 1112, Loss: 0.003738870276720263, Final Batch Loss: 0.00014307039964478463\n",
      "Epoch 1113, Loss: 0.003821087593678385, Final Batch Loss: 0.0005746046081185341\n",
      "Epoch 1114, Loss: 0.0038814155595900957, Final Batch Loss: 3.148537143715657e-05\n",
      "Epoch 1115, Loss: 0.00449407201080021, Final Batch Loss: 7.833731956452539e-07\n",
      "Epoch 1116, Loss: 0.02357806812506169, Final Batch Loss: 0.0007462462526746094\n",
      "Epoch 1117, Loss: 0.004376978671643883, Final Batch Loss: 0.0002620896848384291\n",
      "Epoch 1118, Loss: 0.008286913670417562, Final Batch Loss: 9.757847692526411e-06\n",
      "Epoch 1119, Loss: 0.004892065713647753, Final Batch Loss: 0.001026578014716506\n",
      "Epoch 1120, Loss: 0.01923029695171863, Final Batch Loss: 0.001333582797087729\n",
      "Epoch 1121, Loss: 0.022671486028229992, Final Batch Loss: 1.3665786354977172e-05\n",
      "Epoch 1122, Loss: 0.007163808186305687, Final Batch Loss: 0.0003870825457852334\n",
      "Epoch 1123, Loss: 0.036668128857854754, Final Batch Loss: 0.001488114707171917\n",
      "Epoch 1124, Loss: 0.013415963854640722, Final Batch Loss: 0.002052877563983202\n",
      "Epoch 1125, Loss: 0.0038867749611881663, Final Batch Loss: 1.0728766710599302e-06\n",
      "Epoch 1126, Loss: 0.059058880142401904, Final Batch Loss: 0.039560917764902115\n",
      "Epoch 1127, Loss: 0.010674255351659667, Final Batch Loss: 8.855019586917479e-06\n",
      "Epoch 1128, Loss: 0.009399610444745576, Final Batch Loss: 6.215892085492669e-07\n",
      "Epoch 1129, Loss: 0.024545111602492398, Final Batch Loss: 2.860990207409486e-06\n",
      "Epoch 1130, Loss: 0.00429216065822402, Final Batch Loss: 9.368899191031232e-05\n",
      "Epoch 1131, Loss: 0.005347121497379703, Final Batch Loss: 4.4277612687437795e-07\n",
      "Epoch 1132, Loss: 0.009433911007818097, Final Batch Loss: 6.6584912019607145e-06\n",
      "Epoch 1133, Loss: 0.010006599198689514, Final Batch Loss: 2.2990339232364931e-07\n",
      "Epoch 1134, Loss: 0.005882985191419721, Final Batch Loss: 0.00013885481166653335\n",
      "Epoch 1135, Loss: 0.025573410230208538, Final Batch Loss: 1.597314803802874e-05\n",
      "Epoch 1136, Loss: 0.019185481315957986, Final Batch Loss: 1.711493837319722e-06\n",
      "Epoch 1137, Loss: 0.02763099533899549, Final Batch Loss: 3.5847390336130047e-06\n",
      "Epoch 1138, Loss: 0.012644919019521694, Final Batch Loss: 3.0738649456907297e-06\n",
      "Epoch 1139, Loss: 0.010670846881112084, Final Batch Loss: 0.001420332700945437\n",
      "Epoch 1140, Loss: 0.018094205311172118, Final Batch Loss: 1.052407515089726e-05\n",
      "Epoch 1141, Loss: 0.01700474394237972, Final Batch Loss: 5.009819506085478e-05\n",
      "Epoch 1142, Loss: 0.015197251559584402, Final Batch Loss: 9.239565406460315e-05\n",
      "Epoch 1143, Loss: 0.005164017726201564, Final Batch Loss: 5.694275023415685e-05\n",
      "Epoch 1144, Loss: 0.0023457115994460764, Final Batch Loss: 5.5090013120207004e-06\n",
      "Epoch 1145, Loss: 0.007849245048419107, Final Batch Loss: 8.181480370694771e-05\n",
      "Epoch 1146, Loss: 0.013703403114050161, Final Batch Loss: 0.00016313108790200204\n",
      "Epoch 1147, Loss: 0.004063531290739775, Final Batch Loss: 0.00033562071621418\n",
      "Epoch 1148, Loss: 0.0077157877094578, Final Batch Loss: 0.00010893429862335324\n",
      "Epoch 1149, Loss: 0.008148587847244926, Final Batch Loss: 0.00020982175192330033\n",
      "Epoch 1150, Loss: 0.00851403007254703, Final Batch Loss: 0.005405676085501909\n",
      "Epoch 1151, Loss: 0.040687537722988054, Final Batch Loss: 0.005022136028856039\n",
      "Epoch 1152, Loss: 0.0043641246861625405, Final Batch Loss: 4.4617386265599634e-06\n",
      "Epoch 1153, Loss: 0.011570749706152128, Final Batch Loss: 6.445643521146849e-06\n",
      "Epoch 1154, Loss: 0.02022701082023559, Final Batch Loss: 0.00011164228635607287\n",
      "Epoch 1155, Loss: 0.001978491676709382, Final Batch Loss: 3.922424730262719e-05\n",
      "Epoch 1156, Loss: 0.019611927215009928, Final Batch Loss: 0.004141902085393667\n",
      "Epoch 1157, Loss: 0.009515784520772286, Final Batch Loss: 6.142434722278267e-05\n",
      "Epoch 1158, Loss: 0.04172237827697245, Final Batch Loss: 2.0160679923719727e-05\n",
      "Epoch 1159, Loss: 0.04025953687960282, Final Batch Loss: 0.03480788692831993\n",
      "Epoch 1160, Loss: 0.02622913174855057, Final Batch Loss: 0.0011723767966032028\n",
      "Epoch 1161, Loss: 0.036717286144266836, Final Batch Loss: 0.0001253080990863964\n",
      "Epoch 1162, Loss: 0.04896733645000495, Final Batch Loss: 8.106091991066933e-05\n",
      "Epoch 1163, Loss: 0.02223585012689, Final Batch Loss: 4.6619381464552134e-05\n",
      "Epoch 1164, Loss: 0.017524451122881146, Final Batch Loss: 2.2978394554229453e-05\n",
      "Epoch 1165, Loss: 0.007328453044465277, Final Batch Loss: 0.00010294284584233537\n",
      "Epoch 1166, Loss: 0.032341299071049434, Final Batch Loss: 2.7543124815565534e-05\n",
      "Epoch 1167, Loss: 0.004394722469442058, Final Batch Loss: 0.0001054821113939397\n",
      "Epoch 1168, Loss: 0.009189329725813877, Final Batch Loss: 5.534534466278274e-06\n",
      "Epoch 1169, Loss: 0.015110341690160567, Final Batch Loss: 3.7465724744834006e-07\n",
      "Epoch 1170, Loss: 0.020085139622096904, Final Batch Loss: 0.012603017501533031\n",
      "Epoch 1171, Loss: 0.00896606667083688, Final Batch Loss: 0.00410597724840045\n",
      "Epoch 1172, Loss: 0.016879427602077612, Final Batch Loss: 6.301040116341028e-07\n",
      "Epoch 1173, Loss: 0.004035286320572595, Final Batch Loss: 8.089181164905312e-07\n",
      "Epoch 1174, Loss: 0.009797688260732684, Final Batch Loss: 3.6601013562176377e-05\n",
      "Epoch 1175, Loss: 0.022495908808195964, Final Batch Loss: 0.00044670168426819146\n",
      "Epoch 1176, Loss: 0.025690094917081296, Final Batch Loss: 0.004906754940748215\n",
      "Epoch 1177, Loss: 0.03834236887632869, Final Batch Loss: 7.753627141937613e-05\n",
      "Epoch 1178, Loss: 0.013207598545704968, Final Batch Loss: 0.00023357135069090873\n",
      "Epoch 1179, Loss: 0.006993385113673867, Final Batch Loss: 2.2791000446886756e-05\n",
      "Epoch 1180, Loss: 0.010384074562125534, Final Batch Loss: 2.605553845569375e-06\n",
      "Epoch 1181, Loss: 0.008926273687393405, Final Batch Loss: 0.00021966152417007834\n",
      "Epoch 1182, Loss: 0.002497337862223503, Final Batch Loss: 1.6091698853415437e-05\n",
      "Epoch 1183, Loss: 0.03217266089632176, Final Batch Loss: 0.0007502216612920165\n",
      "Epoch 1184, Loss: 0.0037814324168721214, Final Batch Loss: 0.0001703521265881136\n",
      "Epoch 1185, Loss: 0.011814733962580704, Final Batch Loss: 8.34460422538541e-07\n",
      "Epoch 1186, Loss: 0.01915955338790809, Final Batch Loss: 1.5018963495094795e-05\n",
      "Epoch 1187, Loss: 0.00256131959031336, Final Batch Loss: 0.0003254259645473212\n",
      "Epoch 1188, Loss: 0.024348854058189318, Final Batch Loss: 0.0008206547936424613\n",
      "Epoch 1189, Loss: 0.009549092763336375, Final Batch Loss: 0.0033334624022245407\n",
      "Epoch 1190, Loss: 0.007991749327629805, Final Batch Loss: 0.0026510090101510286\n",
      "Epoch 1191, Loss: 0.008841065515298396, Final Batch Loss: 0.003058760892599821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1192, Loss: 0.016415282761954586, Final Batch Loss: 2.1038567865616642e-05\n",
      "Epoch 1193, Loss: 0.03776593640213832, Final Batch Loss: 0.011076526716351509\n",
      "Epoch 1194, Loss: 0.011565098509890959, Final Batch Loss: 0.0011036377400159836\n",
      "Epoch 1195, Loss: 0.010862959301448427, Final Batch Loss: 7.541965169366449e-05\n",
      "Epoch 1196, Loss: 0.027145432301040273, Final Batch Loss: 8.603964670328423e-05\n",
      "Epoch 1197, Loss: 0.01652250805636868, Final Batch Loss: 0.0009670271538197994\n",
      "Epoch 1198, Loss: 0.00701554209243227, Final Batch Loss: 4.5980576146575913e-07\n",
      "Epoch 1199, Loss: 0.019534102696070477, Final Batch Loss: 4.7768085096322466e-06\n",
      "Epoch 1200, Loss: 0.036218687702785246, Final Batch Loss: 0.029140502214431763\n",
      "Epoch 1201, Loss: 0.036063933512195945, Final Batch Loss: 0.00017410574946552515\n",
      "Epoch 1202, Loss: 0.009175437535276387, Final Batch Loss: 3.1505257425124e-07\n",
      "Epoch 1203, Loss: 0.025078031600319406, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1204, Loss: 0.002570766821008874, Final Batch Loss: 4.1662260628072545e-05\n",
      "Epoch 1205, Loss: 0.039035506270010956, Final Batch Loss: 0.0009104653145186603\n",
      "Epoch 1206, Loss: 0.005609003490022246, Final Batch Loss: 2.2990344916706817e-07\n",
      "Epoch 1207, Loss: 0.02848011320384103, Final Batch Loss: 1.8782604456646368e-05\n",
      "Epoch 1208, Loss: 0.007778005416156475, Final Batch Loss: 4.3426186380202125e-07\n",
      "Epoch 1209, Loss: 0.010987931039224463, Final Batch Loss: 8.514946614468499e-08\n",
      "Epoch 1210, Loss: 0.018765867978800088, Final Batch Loss: 0.012209462933242321\n",
      "Epoch 1211, Loss: 0.0037735536648142443, Final Batch Loss: 4.870428256253945e-06\n",
      "Epoch 1212, Loss: 0.004096618514267902, Final Batch Loss: 6.6074235292035155e-06\n",
      "Epoch 1213, Loss: 0.09178465005243197, Final Batch Loss: 0.06632909923791885\n",
      "Epoch 1214, Loss: 0.02853917398677197, Final Batch Loss: 1.702988612350964e-07\n",
      "Epoch 1215, Loss: 0.02210431802086532, Final Batch Loss: 0.00012453479575924575\n",
      "Epoch 1216, Loss: 0.061229219296365045, Final Batch Loss: 8.305154915433377e-05\n",
      "Epoch 1217, Loss: 0.006037083195224113, Final Batch Loss: 1.3486412171914708e-05\n",
      "Epoch 1218, Loss: 0.13317577954148874, Final Batch Loss: 0.1236381009221077\n",
      "Epoch 1219, Loss: 0.015721729985671118, Final Batch Loss: 0.001447591232135892\n",
      "Epoch 1220, Loss: 0.08874564978759736, Final Batch Loss: 0.001386180636473\n",
      "Epoch 1221, Loss: 0.05269225733354688, Final Batch Loss: 0.015142294578254223\n",
      "Epoch 1222, Loss: 0.015631658920028713, Final Batch Loss: 8.525893645128235e-05\n",
      "Epoch 1223, Loss: 0.02978989336406812, Final Batch Loss: 0.0022146571427583694\n",
      "Epoch 1224, Loss: 0.08918475324753672, Final Batch Loss: 0.071563221514225\n",
      "Epoch 1225, Loss: 0.04241374088451266, Final Batch Loss: 0.0006786602316424251\n",
      "Epoch 1226, Loss: 0.10261999079375528, Final Batch Loss: 0.00042513784137554467\n",
      "Epoch 1227, Loss: 0.040149157226551324, Final Batch Loss: 0.0013334702234715223\n",
      "Epoch 1228, Loss: 0.04622297299465572, Final Batch Loss: 1.7939679310075007e-05\n",
      "Epoch 1229, Loss: 0.033925467054359615, Final Batch Loss: 0.006191580090671778\n",
      "Epoch 1230, Loss: 0.024101336486637592, Final Batch Loss: 0.000998379080556333\n",
      "Epoch 1231, Loss: 0.009033385497851043, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 1232, Loss: 0.024839364807121456, Final Batch Loss: 0.001226964988745749\n",
      "Epoch 1233, Loss: 0.034670675871893764, Final Batch Loss: 0.015122137032449245\n",
      "Epoch 1234, Loss: 0.015992578701116145, Final Batch Loss: 0.0026863228995352983\n",
      "Epoch 1235, Loss: 0.011615128547418863, Final Batch Loss: 0.00021073315292596817\n",
      "Epoch 1236, Loss: 0.007444320523063652, Final Batch Loss: 6.557795859407634e-05\n",
      "Epoch 1237, Loss: 0.010701100341975689, Final Batch Loss: 0.0001426241360604763\n",
      "Epoch 1238, Loss: 0.025669235037639737, Final Batch Loss: 0.0013665809528902173\n",
      "Epoch 1239, Loss: 0.00829838634490443, Final Batch Loss: 1.5717805581516586e-05\n",
      "Epoch 1240, Loss: 0.005547796139126149, Final Batch Loss: 5.142846475791885e-06\n",
      "Epoch 1241, Loss: 0.027234535714208974, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 1242, Loss: 0.029504403821192682, Final Batch Loss: 0.0027095929253846407\n",
      "Epoch 1243, Loss: 0.00612769809049496, Final Batch Loss: 1.7386255422024988e-05\n",
      "Epoch 1244, Loss: 0.013572016934631392, Final Batch Loss: 0.0020590536296367645\n",
      "Epoch 1245, Loss: 0.010699186238070979, Final Batch Loss: 1.0132757779501844e-06\n",
      "Epoch 1246, Loss: 0.01331342980847694, Final Batch Loss: 0.0013320271391421556\n",
      "Epoch 1247, Loss: 0.010543374228291214, Final Batch Loss: 0.0024931610096246004\n",
      "Epoch 1248, Loss: 0.015335334866904304, Final Batch Loss: 2.9977260055602528e-05\n",
      "Epoch 1249, Loss: 0.005606855336736771, Final Batch Loss: 2.08614619623404e-06\n",
      "Epoch 1250, Loss: 0.016958516090483045, Final Batch Loss: 5.364411777009082e-07\n",
      "Epoch 1251, Loss: 0.019534689316060394, Final Batch Loss: 0.015110919252038002\n",
      "Epoch 1252, Loss: 0.005035876868092259, Final Batch Loss: 1.3623913730498316e-07\n",
      "Epoch 1253, Loss: 0.02060336832437315, Final Batch Loss: 4.516847911872901e-05\n",
      "Epoch 1254, Loss: 0.007925331185106188, Final Batch Loss: 9.733624756336212e-05\n",
      "Epoch 1255, Loss: 0.04870474711060524, Final Batch Loss: 0.040201544761657715\n",
      "Epoch 1256, Loss: 0.0044920707296114415, Final Batch Loss: 0.001027213642373681\n",
      "Epoch 1257, Loss: 0.007539825717685744, Final Batch Loss: 0.00041779977618716657\n",
      "Epoch 1258, Loss: 0.007848918406125449, Final Batch Loss: 5.4834790716995485e-06\n",
      "Epoch 1259, Loss: 0.004146236264205072, Final Batch Loss: 8.768641419010237e-05\n",
      "Epoch 1260, Loss: 0.004878755898971576, Final Batch Loss: 9.126893564825878e-05\n",
      "Epoch 1261, Loss: 0.00268350713304244, Final Batch Loss: 0.0001562528486829251\n",
      "Epoch 1262, Loss: 0.02234932640567422, Final Batch Loss: 0.018852774053812027\n",
      "Epoch 1263, Loss: 0.033540401000209386, Final Batch Loss: 4.536056439974345e-05\n",
      "Epoch 1264, Loss: 0.0093852757681816, Final Batch Loss: 5.764389243267942e-06\n",
      "Epoch 1265, Loss: 0.008815374312689528, Final Batch Loss: 0.00033911896753124893\n",
      "Epoch 1266, Loss: 0.0072157776849053334, Final Batch Loss: 2.127569678123109e-05\n",
      "Epoch 1267, Loss: 0.011761105718051112, Final Batch Loss: 3.831647063634591e-06\n",
      "Epoch 1268, Loss: 0.029987399408128113, Final Batch Loss: 0.0005589103675447404\n",
      "Epoch 1269, Loss: 0.023031723609165056, Final Batch Loss: 1.934410465764813e-05\n",
      "Epoch 1270, Loss: 0.009881470708933193, Final Batch Loss: 6.712793401675299e-05\n",
      "Epoch 1271, Loss: 0.004031370219308883, Final Batch Loss: 0.0013537007616832852\n",
      "Epoch 1272, Loss: 0.024541241189581342, Final Batch Loss: 0.0012966763461008668\n",
      "Epoch 1273, Loss: 0.005362066232464713, Final Batch Loss: 3.4825311558961403e-06\n",
      "Epoch 1274, Loss: 0.023638312559342012, Final Batch Loss: 0.020761145278811455\n",
      "Epoch 1275, Loss: 0.004242501454427838, Final Batch Loss: 0.0003919461159966886\n",
      "Epoch 1276, Loss: 0.004061252577230334, Final Batch Loss: 2.3055210476741195e-05\n",
      "Epoch 1277, Loss: 0.0038941238744882867, Final Batch Loss: 6.224414391908795e-05\n",
      "Epoch 1278, Loss: 0.003092201450272114, Final Batch Loss: 2.3012364181340672e-05\n",
      "Epoch 1279, Loss: 0.0034595674750903527, Final Batch Loss: 2.469332116561418e-07\n",
      "Epoch 1280, Loss: 0.005422398004157003, Final Batch Loss: 4.5798275095876306e-05\n",
      "Epoch 1281, Loss: 0.014908596975146793, Final Batch Loss: 0.00011143360461574048\n",
      "Epoch 1282, Loss: 0.00354370641434798, Final Batch Loss: 7.835956785129383e-05\n",
      "Epoch 1283, Loss: 0.0034731568448478356, Final Batch Loss: 0.0008967594476416707\n",
      "Epoch 1284, Loss: 0.004858814136241563, Final Batch Loss: 0.00017640758596826345\n",
      "Epoch 1285, Loss: 0.003213613430489204, Final Batch Loss: 2.8981934519833885e-05\n",
      "Epoch 1286, Loss: 0.019430373527939082, Final Batch Loss: 2.7738302378566004e-05\n",
      "Epoch 1287, Loss: 0.002574813302999246, Final Batch Loss: 2.51061992457835e-05\n",
      "Epoch 1288, Loss: 0.004243822128046304, Final Batch Loss: 0.00033380789682269096\n",
      "Epoch 1289, Loss: 0.0048614520783303306, Final Batch Loss: 7.934040331747383e-05\n",
      "Epoch 1290, Loss: 0.004935200333420653, Final Batch Loss: 6.412386574083939e-05\n",
      "Epoch 1291, Loss: 0.001870974461780861, Final Batch Loss: 0.0002690115652512759\n",
      "Epoch 1292, Loss: 0.018893314292654395, Final Batch Loss: 0.0016406693030148745\n",
      "Epoch 1293, Loss: 0.004440524848178029, Final Batch Loss: 0.001834883471019566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1294, Loss: 0.004821201873710379, Final Batch Loss: 0.000919842510484159\n",
      "Epoch 1295, Loss: 0.0026582187492749654, Final Batch Loss: 1.0881303751375526e-05\n",
      "Epoch 1296, Loss: 0.02431058116053464, Final Batch Loss: 8.254711428890005e-05\n",
      "Epoch 1297, Loss: 0.008093348397778755, Final Batch Loss: 8.395246368309017e-06\n",
      "Epoch 1298, Loss: 0.004542459239019081, Final Batch Loss: 0.0010981984669342637\n",
      "Epoch 1299, Loss: 0.004026019429147709, Final Batch Loss: 0.0002185592893511057\n",
      "Epoch 1300, Loss: 0.00556338626483921, Final Batch Loss: 6.839341949671507e-05\n",
      "Epoch 1301, Loss: 0.025890843251545448, Final Batch Loss: 5.866699211765081e-06\n",
      "Epoch 1302, Loss: 0.006416558739147149, Final Batch Loss: 0.00032563760760240257\n",
      "Epoch 1303, Loss: 0.006581441297385027, Final Batch Loss: 2.612151911307592e-05\n",
      "Epoch 1304, Loss: 0.0036942407314199954, Final Batch Loss: 0.001114986720494926\n",
      "Epoch 1305, Loss: 0.018385416791716125, Final Batch Loss: 0.0001542118116049096\n",
      "Epoch 1306, Loss: 0.024104070259276966, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 1307, Loss: 0.011361549913999625, Final Batch Loss: 0.00011343498772475868\n",
      "Epoch 1308, Loss: 0.003877495065353287, Final Batch Loss: 5.687760676664766e-06\n",
      "Epoch 1309, Loss: 0.05935508804395795, Final Batch Loss: 0.007795811165124178\n",
      "Epoch 1310, Loss: 0.00779810716997531, Final Batch Loss: 4.342619206454401e-07\n",
      "Epoch 1311, Loss: 0.055335016462777276, Final Batch Loss: 6.240641960175708e-05\n",
      "Epoch 1312, Loss: 0.007180599852517844, Final Batch Loss: 3.508125018925057e-06\n",
      "Epoch 1313, Loss: 0.005341338042171628, Final Batch Loss: 2.852485749826883e-06\n",
      "Epoch 1314, Loss: 0.020665615821979344, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 1315, Loss: 0.011893720831722021, Final Batch Loss: 0.0010682818247005343\n",
      "Epoch 1316, Loss: 0.010496586532099172, Final Batch Loss: 0.0\n",
      "Epoch 1317, Loss: 0.004368629948658054, Final Batch Loss: 9.46816180658061e-06\n",
      "Epoch 1318, Loss: 0.005604587335255928, Final Batch Loss: 0.0002042512787738815\n",
      "Epoch 1319, Loss: 0.0020587299804901704, Final Batch Loss: 5.601838347502053e-05\n",
      "Epoch 1320, Loss: 0.0054824272610858316, Final Batch Loss: 8.276323569589294e-06\n",
      "Epoch 1321, Loss: 0.015186401549101447, Final Batch Loss: 8.514901423950505e-07\n",
      "Epoch 1322, Loss: 0.014903660179697908, Final Batch Loss: 0.00021476864640135318\n",
      "Epoch 1323, Loss: 0.00735918153077364, Final Batch Loss: 0.0019376490963622928\n",
      "Epoch 1324, Loss: 0.004135275725275278, Final Batch Loss: 0.001096418360248208\n",
      "Epoch 1325, Loss: 0.39425051934085786, Final Batch Loss: 0.38332438468933105\n",
      "Epoch 1326, Loss: 0.021507985690732312, Final Batch Loss: 9.791871889319737e-06\n",
      "Epoch 1327, Loss: 0.022961115976656288, Final Batch Loss: 2.2138833344342856e-07\n",
      "Epoch 1328, Loss: 0.012397043571070299, Final Batch Loss: 8.004030291886011e-07\n",
      "Epoch 1329, Loss: 0.047234398080036044, Final Batch Loss: 0.002755860099568963\n",
      "Epoch 1330, Loss: 0.011960210351389833, Final Batch Loss: 0.0006134851137176156\n",
      "Epoch 1331, Loss: 0.009836231809458695, Final Batch Loss: 0.0037939748726785183\n",
      "Epoch 1332, Loss: 0.01663352924492756, Final Batch Loss: 2.3841835172788706e-07\n",
      "Epoch 1333, Loss: 0.010242328331514727, Final Batch Loss: 4.1588958993088454e-05\n",
      "Epoch 1334, Loss: 0.010137983859749511, Final Batch Loss: 0.0008299579494632781\n",
      "Epoch 1335, Loss: 0.011159995216075913, Final Batch Loss: 1.2567115845740773e-05\n",
      "Epoch 1336, Loss: 0.010072522163682152, Final Batch Loss: 4.807423829333857e-05\n",
      "Epoch 1337, Loss: 0.0049471946695121005, Final Batch Loss: 0.00019440446340013295\n",
      "Epoch 1338, Loss: 0.006579914159374312, Final Batch Loss: 0.00012297742068767548\n",
      "Epoch 1339, Loss: 0.008928407871280797, Final Batch Loss: 0.0016168073052540421\n",
      "Epoch 1340, Loss: 0.029706909554079175, Final Batch Loss: 0.02394447661936283\n",
      "Epoch 1341, Loss: 0.006185596983414143, Final Batch Loss: 0.0034813249949365854\n",
      "Epoch 1342, Loss: 0.026104454991582315, Final Batch Loss: 7.803241169312969e-05\n",
      "Epoch 1343, Loss: 0.006806372504797764, Final Batch Loss: 0.0003683737013489008\n",
      "Epoch 1344, Loss: 0.00850831237175953, Final Batch Loss: 3.857219326164341e-06\n",
      "Epoch 1345, Loss: 0.016132692828250583, Final Batch Loss: 6.903643225086853e-05\n",
      "Epoch 1346, Loss: 0.02183793534641154, Final Batch Loss: 0.011687719263136387\n",
      "Epoch 1347, Loss: 0.019217151516507158, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 1348, Loss: 0.017609425849514082, Final Batch Loss: 0.00032511059544049203\n",
      "Epoch 1349, Loss: 0.016442719755445978, Final Batch Loss: 1.0217934232059633e-07\n",
      "Epoch 1350, Loss: 0.011526600335855619, Final Batch Loss: 2.1030829884693958e-05\n",
      "Epoch 1351, Loss: 0.009866193415291491, Final Batch Loss: 1.7888769434648566e-05\n",
      "Epoch 1352, Loss: 0.003376652195584029, Final Batch Loss: 0.0002491433115210384\n",
      "Epoch 1353, Loss: 0.008840737151331268, Final Batch Loss: 0.00019640031678136438\n",
      "Epoch 1354, Loss: 0.0522402512433473, Final Batch Loss: 0.00015837156388442963\n",
      "Epoch 1355, Loss: 0.007487223840143997, Final Batch Loss: 6.11969517194666e-05\n",
      "Epoch 1356, Loss: 0.01325326890219003, Final Batch Loss: 0.0007688619079999626\n",
      "Epoch 1357, Loss: 0.00768977774441737, Final Batch Loss: 7.66310859035002e-06\n",
      "Epoch 1358, Loss: 0.01986812418908812, Final Batch Loss: 0.007905485108494759\n",
      "Epoch 1359, Loss: 0.028568304638611153, Final Batch Loss: 0.0015448263147845864\n",
      "Epoch 1360, Loss: 0.021312507829861715, Final Batch Loss: 3.061399911530316e-05\n",
      "Epoch 1361, Loss: 0.009275259311834816, Final Batch Loss: 0.00011690756218740717\n",
      "Epoch 1362, Loss: 0.010014177183620632, Final Batch Loss: 0.0025087932590395212\n",
      "Epoch 1363, Loss: 0.005479895635289722, Final Batch Loss: 1.8773784177028574e-05\n",
      "Epoch 1364, Loss: 0.015018285092082806, Final Batch Loss: 0.005575259681791067\n",
      "Epoch 1365, Loss: 0.005358575767786533, Final Batch Loss: 7.671723324165214e-06\n",
      "Epoch 1366, Loss: 0.005876282084500417, Final Batch Loss: 0.0005827572313137352\n",
      "Epoch 1367, Loss: 0.03699800110189244, Final Batch Loss: 0.03360045328736305\n",
      "Epoch 1368, Loss: 0.03184696970129153, Final Batch Loss: 0.028276918455958366\n",
      "Epoch 1369, Loss: 0.004098509132745676, Final Batch Loss: 0.0003810662019532174\n",
      "Epoch 1370, Loss: 0.022213409189134836, Final Batch Loss: 0.00028963503427803516\n",
      "Epoch 1371, Loss: 0.008698232374399595, Final Batch Loss: 2.716221160881105e-06\n",
      "Epoch 1372, Loss: 0.003286932100309059, Final Batch Loss: 5.5343261919915676e-05\n",
      "Epoch 1373, Loss: 0.003842375489576, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 1374, Loss: 0.030709541818424668, Final Batch Loss: 1.5326898505918507e-07\n",
      "Epoch 1375, Loss: 0.006010862940456718, Final Batch Loss: 0.00042543624294921756\n",
      "Epoch 1376, Loss: 0.01746384787838906, Final Batch Loss: 0.012982839718461037\n",
      "Epoch 1377, Loss: 0.001402122747094836, Final Batch Loss: 3.3736803743522614e-05\n",
      "Epoch 1378, Loss: 0.009497056598775089, Final Batch Loss: 0.0015350905014201999\n",
      "Epoch 1379, Loss: 0.015001912513980642, Final Batch Loss: 1.8493374227546155e-05\n",
      "Epoch 1380, Loss: 0.019433197182856077, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 1381, Loss: 0.020993968467337254, Final Batch Loss: 8.633937795821112e-06\n",
      "Epoch 1382, Loss: 0.017126587034516305, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 1383, Loss: 0.005062192358309403, Final Batch Loss: 0.0003433742094784975\n",
      "Epoch 1384, Loss: 0.0066396634856573655, Final Batch Loss: 5.236629476712551e-06\n",
      "Epoch 1385, Loss: 0.01989158989454154, Final Batch Loss: 0.017429819330573082\n",
      "Epoch 1386, Loss: 0.007684774219114843, Final Batch Loss: 1.2176340078440262e-06\n",
      "Epoch 1387, Loss: 0.0029581634189526085, Final Batch Loss: 2.4522632884327322e-06\n",
      "Epoch 1388, Loss: 0.0030700785282533616, Final Batch Loss: 0.00043477449798956513\n",
      "Epoch 1389, Loss: 0.005775865283794701, Final Batch Loss: 0.00021193994325585663\n",
      "Epoch 1390, Loss: 0.019792294173385017, Final Batch Loss: 0.0004930642899125814\n",
      "Epoch 1391, Loss: 0.015098532920092111, Final Batch Loss: 2.069759284495376e-05\n",
      "Epoch 1392, Loss: 0.02918734735885664, Final Batch Loss: 8.310159500979353e-06\n",
      "Epoch 1393, Loss: 0.012648318949246118, Final Batch Loss: 1.3623913730498316e-07\n",
      "Epoch 1394, Loss: 0.0024001558813324664, Final Batch Loss: 2.16418739000801e-05\n",
      "Epoch 1395, Loss: 0.007052656819269032, Final Batch Loss: 2.171294454456074e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1396, Loss: 0.004509601181780454, Final Batch Loss: 7.04226185916923e-05\n",
      "Epoch 1397, Loss: 0.007593565200295416, Final Batch Loss: 1.620211151021067e-05\n",
      "Epoch 1398, Loss: 0.0017531019693706185, Final Batch Loss: 7.750750955892727e-05\n",
      "Epoch 1399, Loss: 0.0030730564658369985, Final Batch Loss: 7.348023245867807e-06\n",
      "Epoch 1400, Loss: 0.009604130922525655, Final Batch Loss: 0.000777843059040606\n",
      "Epoch 1401, Loss: 0.022994811508397106, Final Batch Loss: 8.682136103743687e-05\n",
      "Epoch 1402, Loss: 0.04507154209431974, Final Batch Loss: 2.963183305837447e-06\n",
      "Epoch 1403, Loss: 0.003930929611669853, Final Batch Loss: 0.0002572086814325303\n",
      "Epoch 1404, Loss: 0.022543005583429476, Final Batch Loss: 2.5686804292490706e-05\n",
      "Epoch 1405, Loss: 0.010083536806632765, Final Batch Loss: 6.508851947728544e-05\n",
      "Epoch 1406, Loss: 0.01117287810484413, Final Batch Loss: 0.0001385788491461426\n",
      "Epoch 1407, Loss: 0.010688659152947366, Final Batch Loss: 0.0022791598457843065\n",
      "Epoch 1408, Loss: 0.001286661912672571, Final Batch Loss: 2.1898280465393327e-05\n",
      "Epoch 1409, Loss: 0.04092455131467432, Final Batch Loss: 0.0006082852487452328\n",
      "Epoch 1410, Loss: 0.015022049462459108, Final Batch Loss: 1.4355443454405759e-05\n",
      "Epoch 1411, Loss: 0.005179509295885509, Final Batch Loss: 1.1588076631596778e-05\n",
      "Epoch 1412, Loss: 0.005017009478137879, Final Batch Loss: 1.294263597628742e-06\n",
      "Epoch 1413, Loss: 0.021330434014089406, Final Batch Loss: 0.014632211066782475\n",
      "Epoch 1414, Loss: 0.007549636124167591, Final Batch Loss: 0.0013122825184836984\n",
      "Epoch 1415, Loss: 0.050493971983541996, Final Batch Loss: 3.2015527722251136e-06\n",
      "Epoch 1416, Loss: 0.003862022271277965, Final Batch Loss: 8.667726433486678e-06\n",
      "Epoch 1417, Loss: 0.009034511212462348, Final Batch Loss: 8.600048886364675e-07\n",
      "Epoch 1418, Loss: 0.03075833500963654, Final Batch Loss: 1.353868469777808e-06\n",
      "Epoch 1419, Loss: 0.012873632047558203, Final Batch Loss: 0.00014421078958548605\n",
      "Epoch 1420, Loss: 0.009987210723920725, Final Batch Loss: 0.0012979187304154038\n",
      "Epoch 1421, Loss: 0.0035063496652583126, Final Batch Loss: 2.10218749998603e-05\n",
      "Epoch 1422, Loss: 0.004290604323614389, Final Batch Loss: 0.0001640272093936801\n",
      "Epoch 1423, Loss: 0.004352978348833858, Final Batch Loss: 1.8433265722705983e-05\n",
      "Epoch 1424, Loss: 0.007034375594230369, Final Batch Loss: 2.9873684979975224e-05\n",
      "Epoch 1425, Loss: 0.01655286741879536, Final Batch Loss: 6.254665640881285e-05\n",
      "Epoch 1426, Loss: 0.006049083533305577, Final Batch Loss: 6.811956865249158e-08\n",
      "Epoch 1427, Loss: 0.006162630510516465, Final Batch Loss: 0.002765271347016096\n",
      "Epoch 1428, Loss: 0.004395952040795237, Final Batch Loss: 0.0010379337472841144\n",
      "Epoch 1429, Loss: 0.005046650177973788, Final Batch Loss: 1.2414435332175344e-05\n",
      "Epoch 1430, Loss: 0.01041374562191777, Final Batch Loss: 0.0001603895507287234\n",
      "Epoch 1431, Loss: 0.005761744369010557, Final Batch Loss: 8.31882243801374e-06\n",
      "Epoch 1432, Loss: 0.013142478735410634, Final Batch Loss: 1.0217934942602369e-07\n",
      "Epoch 1433, Loss: 0.004657484661493072, Final Batch Loss: 4.8874476306082215e-06\n",
      "Epoch 1434, Loss: 0.008703406126187474, Final Batch Loss: 6.394443516910542e-06\n",
      "Epoch 1435, Loss: 0.0056653115861990955, Final Batch Loss: 4.649426773539744e-05\n",
      "Epoch 1436, Loss: 0.02015243800788724, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 1437, Loss: 0.005060341347416397, Final Batch Loss: 0.00011392353189876303\n",
      "Epoch 1438, Loss: 0.004113327857339755, Final Batch Loss: 0.00026739624445326626\n",
      "Epoch 1439, Loss: 0.011327693447583442, Final Batch Loss: 6.607476734643569e-06\n",
      "Epoch 1440, Loss: 0.02220337987287735, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 1441, Loss: 0.002199090366445944, Final Batch Loss: 7.407983844132104e-07\n",
      "Epoch 1442, Loss: 0.007272008479503711, Final Batch Loss: 1.9924705156881828e-06\n",
      "Epoch 1443, Loss: 0.00821993058480075, Final Batch Loss: 5.662217063218122e-06\n",
      "Epoch 1444, Loss: 0.0030196947627700865, Final Batch Loss: 2.1403393475338817e-05\n",
      "Epoch 1445, Loss: 0.018678429532883456, Final Batch Loss: 4.4169541070004925e-05\n",
      "Epoch 1446, Loss: 0.0046026379422983155, Final Batch Loss: 0.0010973355965688825\n",
      "Epoch 1447, Loss: 0.00364082878741101, Final Batch Loss: 5.8240716498403344e-06\n",
      "Epoch 1448, Loss: 0.015463070293662895, Final Batch Loss: 1.1171058758918662e-05\n",
      "Epoch 1449, Loss: 0.017008796872687526, Final Batch Loss: 0.00013428278907667845\n",
      "Epoch 1450, Loss: 0.0019797053828369826, Final Batch Loss: 0.0001936383923748508\n",
      "Epoch 1451, Loss: 0.0020391864691191586, Final Batch Loss: 7.782380635035224e-06\n",
      "Epoch 1452, Loss: 0.0043511366114081795, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1453, Loss: 0.0014927367701602634, Final Batch Loss: 4.01894430979155e-06\n",
      "Epoch 1454, Loss: 0.0040749086007849655, Final Batch Loss: 6.556480798280973e-07\n",
      "Epoch 1455, Loss: 0.004122637830732856, Final Batch Loss: 0.0006576409214176238\n",
      "Epoch 1456, Loss: 0.05497994719189592, Final Batch Loss: 0.0008979826816357672\n",
      "Epoch 1457, Loss: 0.006313248679362005, Final Batch Loss: 3.7912072002654895e-05\n",
      "Epoch 1458, Loss: 0.005469157164043281, Final Batch Loss: 7.490083953598514e-05\n",
      "Epoch 1459, Loss: 0.009924236343522352, Final Batch Loss: 3.780544375331374e-06\n",
      "Epoch 1460, Loss: 0.0017474845590186305, Final Batch Loss: 2.736241731327027e-05\n",
      "Epoch 1461, Loss: 0.0012872231443026294, Final Batch Loss: 2.0435864200862852e-07\n",
      "Epoch 1462, Loss: 0.001760167462634854, Final Batch Loss: 0.00019436716684140265\n",
      "Epoch 1463, Loss: 0.04513712308835238, Final Batch Loss: 0.03543807938694954\n",
      "Epoch 1464, Loss: 0.0033803133555920795, Final Batch Loss: 0.00025795763940550387\n",
      "Epoch 1465, Loss: 0.011905931669389247, Final Batch Loss: 2.6995801817975007e-05\n",
      "Epoch 1466, Loss: 0.0020797203989175728, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 1467, Loss: 0.01460715293035264, Final Batch Loss: 9.70699716162926e-07\n",
      "Epoch 1468, Loss: 0.017146885074907914, Final Batch Loss: 0.00033578710281290114\n",
      "Epoch 1469, Loss: 0.007676757872104645, Final Batch Loss: 0.002038633683696389\n",
      "Epoch 1470, Loss: 0.008078010083409026, Final Batch Loss: 1.6806676285341382e-05\n",
      "Epoch 1471, Loss: 0.006273893697652966, Final Batch Loss: 0.002051557181403041\n",
      "Epoch 1472, Loss: 0.014280577498198, Final Batch Loss: 1.5922875036267214e-06\n",
      "Epoch 1473, Loss: 0.015274535731805372, Final Batch Loss: 2.0220772057655267e-05\n",
      "Epoch 1474, Loss: 0.01055630948212638, Final Batch Loss: 2.104637496813666e-05\n",
      "Epoch 1475, Loss: 0.018173917662352324, Final Batch Loss: 0.013279207982122898\n",
      "Epoch 1476, Loss: 0.003463681330572399, Final Batch Loss: 1.6518841903234716e-06\n",
      "Epoch 1477, Loss: 0.005293609538966848, Final Batch Loss: 9.629956366552506e-06\n",
      "Epoch 1478, Loss: 0.05442065224633552, Final Batch Loss: 0.03588968515396118\n",
      "Epoch 1479, Loss: 0.03844846994616091, Final Batch Loss: 0.027658548206090927\n",
      "Epoch 1480, Loss: 0.05446272017189813, Final Batch Loss: 5.960440034868952e-07\n",
      "Epoch 1481, Loss: 0.047155480133369565, Final Batch Loss: 0.02321513369679451\n",
      "Epoch 1482, Loss: 0.005022664729040116, Final Batch Loss: 0.00114600476808846\n",
      "Epoch 1483, Loss: 0.008152234227054578, Final Batch Loss: 1.4500144061457831e-05\n",
      "Epoch 1484, Loss: 0.01517577440245077, Final Batch Loss: 0.0010088620474562049\n",
      "Epoch 1485, Loss: 0.02160047695724643, Final Batch Loss: 3.18226775561925e-05\n",
      "Epoch 1486, Loss: 0.008727097552764462, Final Batch Loss: 8.591090590925887e-06\n",
      "Epoch 1487, Loss: 0.002208837687817322, Final Batch Loss: 9.877272759695188e-07\n",
      "Epoch 1488, Loss: 0.008409603440668434, Final Batch Loss: 0.0030600924510508776\n",
      "Epoch 1489, Loss: 0.008895677845430328, Final Batch Loss: 1.9956594769610092e-05\n",
      "Epoch 1490, Loss: 0.013693478365894407, Final Batch Loss: 0.00375136430375278\n",
      "Epoch 1491, Loss: 0.024714898336242186, Final Batch Loss: 3.179688428645022e-05\n",
      "Epoch 1492, Loss: 0.002402592795988312, Final Batch Loss: 3.868195562972687e-05\n",
      "Epoch 1493, Loss: 0.006666852712442051, Final Batch Loss: 9.50250068854075e-06\n",
      "Epoch 1494, Loss: 0.01667843349969189, Final Batch Loss: 2.2154226826387458e-05\n",
      "Epoch 1495, Loss: 0.012703374053671723, Final Batch Loss: 2.8556296456372365e-05\n",
      "Epoch 1496, Loss: 0.003738928519718243, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 1497, Loss: 0.00817643939080881, Final Batch Loss: 3.8833146390970796e-05\n",
      "Epoch 1498, Loss: 0.0022767562477383763, Final Batch Loss: 0.0001945740368682891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1499, Loss: 0.005893088417792569, Final Batch Loss: 8.089181164905312e-07\n",
      "Epoch 1500, Loss: 0.0022266423984547146, Final Batch Loss: 0.0005284268991090357\n",
      "Epoch 1501, Loss: 0.025210613355739042, Final Batch Loss: 0.0005418431246653199\n",
      "Epoch 1502, Loss: 0.004006888562344102, Final Batch Loss: 5.210958534007659e-06\n",
      "Epoch 1503, Loss: 0.06056845324928872, Final Batch Loss: 0.04138540104031563\n",
      "Epoch 1504, Loss: 0.02080257419083864, Final Batch Loss: 3.789051788771758e-06\n",
      "Epoch 1505, Loss: 0.030303041450672197, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 1506, Loss: 0.1338119324791478, Final Batch Loss: 0.00011412003368604928\n",
      "Epoch 1507, Loss: 0.010135835429082363, Final Batch Loss: 7.297217507584719e-06\n",
      "Epoch 1508, Loss: 0.010749690358352382, Final Batch Loss: 9.703974501462653e-05\n",
      "Epoch 1509, Loss: 0.004484333293277132, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 1510, Loss: 0.030705953570759448, Final Batch Loss: 6.62432375975186e-06\n",
      "Epoch 1511, Loss: 0.0023740266624372452, Final Batch Loss: 0.0\n",
      "Epoch 1512, Loss: 0.006284025032073259, Final Batch Loss: 0.0002495369699317962\n",
      "Epoch 1513, Loss: 0.02581881514925044, Final Batch Loss: 0.00023040104133542627\n",
      "Epoch 1514, Loss: 0.005478977051090794, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 1515, Loss: 0.007676480454392731, Final Batch Loss: 0.0009965011849999428\n",
      "Epoch 1516, Loss: 0.008831221391801591, Final Batch Loss: 1.23465702017711e-06\n",
      "Epoch 1517, Loss: 0.032216559193329886, Final Batch Loss: 0.000628827721811831\n",
      "Epoch 1518, Loss: 0.011689545994158834, Final Batch Loss: 0.0007112268358469009\n",
      "Epoch 1519, Loss: 0.00325144600111571, Final Batch Loss: 8.344625825884577e-07\n",
      "Epoch 1520, Loss: 0.017992111846979242, Final Batch Loss: 6.766197475371882e-05\n",
      "Epoch 1521, Loss: 0.0049563858774490654, Final Batch Loss: 0.000617713259998709\n",
      "Epoch 1522, Loss: 0.011858160010888241, Final Batch Loss: 1.2558462913148105e-05\n",
      "Epoch 1523, Loss: 0.0077445049755624495, Final Batch Loss: 8.423448161920533e-05\n",
      "Epoch 1524, Loss: 0.004602007174980827, Final Batch Loss: 0.0\n",
      "Epoch 1525, Loss: 0.03086769685614854, Final Batch Loss: 0.00034164730459451675\n",
      "Epoch 1526, Loss: 0.011560369081053068, Final Batch Loss: 1.932874511112459e-06\n",
      "Epoch 1527, Loss: 0.016203114856580214, Final Batch Loss: 9.272195711673703e-06\n",
      "Epoch 1528, Loss: 0.0041483537142994464, Final Batch Loss: 5.730450538976584e-06\n",
      "Epoch 1529, Loss: 0.018631729235494277, Final Batch Loss: 5.7555556850275025e-05\n",
      "Epoch 1530, Loss: 0.019955128416768275, Final Batch Loss: 0.0007433771388605237\n",
      "Epoch 1531, Loss: 0.05620579268725123, Final Batch Loss: 8.18425469333306e-05\n",
      "Epoch 1532, Loss: 0.04785248586995294, Final Batch Loss: 0.00010518720227992162\n",
      "Epoch 1533, Loss: 0.005860770514118485, Final Batch Loss: 0.0002384475665166974\n",
      "Epoch 1534, Loss: 0.0038454978452264754, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 1535, Loss: 0.004116744588827714, Final Batch Loss: 3.5911245504394174e-05\n",
      "Epoch 1536, Loss: 0.02887970956726349, Final Batch Loss: 6.073995245969854e-05\n",
      "Epoch 1537, Loss: 0.023727499463660706, Final Batch Loss: 3.235676047097513e-07\n",
      "Epoch 1538, Loss: 0.03320261056069285, Final Batch Loss: 0.018891939893364906\n",
      "Epoch 1539, Loss: 0.0029983184940647334, Final Batch Loss: 1.3418379239737988e-05\n",
      "Epoch 1540, Loss: 0.033488426241092384, Final Batch Loss: 0.0003942730836570263\n",
      "Epoch 1541, Loss: 0.04962354549206793, Final Batch Loss: 0.001013009692542255\n",
      "Epoch 1542, Loss: 0.018994474873920808, Final Batch Loss: 1.7796149904825143e-06\n",
      "Epoch 1543, Loss: 0.00930808185981391, Final Batch Loss: 4.683217014189722e-07\n",
      "Epoch 1544, Loss: 0.01854718421304824, Final Batch Loss: 2.2989995613897918e-06\n",
      "Epoch 1545, Loss: 0.010509970314160455, Final Batch Loss: 6.875489634694532e-05\n",
      "Epoch 1546, Loss: 0.013217741172411479, Final Batch Loss: 0.0001636838132981211\n",
      "Epoch 1547, Loss: 0.020420062443008646, Final Batch Loss: 0.008549932390451431\n",
      "Epoch 1548, Loss: 0.012846376340803545, Final Batch Loss: 3.831637059192872e-06\n",
      "Epoch 1549, Loss: 0.008959336177213117, Final Batch Loss: 0.0022530953865498304\n",
      "Epoch 1550, Loss: 0.006622530802683713, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 1551, Loss: 0.005252076918623061, Final Batch Loss: 3.167509930790402e-06\n",
      "Epoch 1552, Loss: 0.03250837838277221, Final Batch Loss: 0.013222931884229183\n",
      "Epoch 1553, Loss: 0.003286729666797328, Final Batch Loss: 1.7054042473318987e-05\n",
      "Epoch 1554, Loss: 0.02371413579021464, Final Batch Loss: 7.32263652025722e-06\n",
      "Epoch 1555, Loss: 0.005790300249657321, Final Batch Loss: 5.619847911475517e-07\n",
      "Epoch 1556, Loss: 0.004044959005568671, Final Batch Loss: 5.866725132364081e-06\n",
      "Epoch 1557, Loss: 0.002915362740168348, Final Batch Loss: 0.0003903674951288849\n",
      "Epoch 1558, Loss: 0.001892434709588997, Final Batch Loss: 1.590444298926741e-05\n",
      "Epoch 1559, Loss: 0.0031853664622758515, Final Batch Loss: 5.290960689308122e-05\n",
      "Epoch 1560, Loss: 0.006990899422589791, Final Batch Loss: 3.2526475024496904e-06\n",
      "Epoch 1561, Loss: 0.013988959852472505, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1562, Loss: 0.014553933899151161, Final Batch Loss: 0.0015940706944093108\n",
      "Epoch 1563, Loss: 0.015510054325943656, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 1564, Loss: 0.001933255567564629, Final Batch Loss: 4.554222687147558e-05\n",
      "Epoch 1565, Loss: 0.004452341784599412, Final Batch Loss: 1.600793439138215e-06\n",
      "Epoch 1566, Loss: 0.00501509869354777, Final Batch Loss: 0.0012920955196022987\n",
      "Epoch 1567, Loss: 0.004011700482806191, Final Batch Loss: 0.0013681270647794008\n",
      "Epoch 1568, Loss: 0.004158267414823058, Final Batch Loss: 1.0421570550533943e-05\n",
      "Epoch 1569, Loss: 0.005392742081312463, Final Batch Loss: 0.0\n",
      "Epoch 1570, Loss: 0.013957649762232904, Final Batch Loss: 2.340375976928044e-05\n",
      "Epoch 1571, Loss: 0.003036073027033126, Final Batch Loss: 2.656615833984688e-06\n",
      "Epoch 1572, Loss: 0.0047916850744513795, Final Batch Loss: 0.0008247970254160464\n",
      "Epoch 1573, Loss: 0.0020279306254451512, Final Batch Loss: 8.548499863536563e-06\n",
      "Epoch 1574, Loss: 0.04986517831275705, Final Batch Loss: 0.04786006733775139\n",
      "Epoch 1575, Loss: 0.009171808616883936, Final Batch Loss: 2.125015998899471e-05\n",
      "Epoch 1576, Loss: 0.021150602027773857, Final Batch Loss: 0.0006874164682812989\n",
      "Epoch 1577, Loss: 0.011489713651826605, Final Batch Loss: 0.006573463790118694\n",
      "Epoch 1578, Loss: 0.012662327087184622, Final Batch Loss: 4.938656843478384e-07\n",
      "Epoch 1579, Loss: 0.017814371287386166, Final Batch Loss: 3.0316488846438006e-05\n",
      "Epoch 1580, Loss: 0.0029280701754714755, Final Batch Loss: 1.7114842876253533e-06\n",
      "Epoch 1581, Loss: 0.014465727224887814, Final Batch Loss: 0.010531222447752953\n",
      "Epoch 1582, Loss: 0.052019508458485575, Final Batch Loss: 2.2990325021510216e-07\n",
      "Epoch 1583, Loss: 0.017005404095698395, Final Batch Loss: 3.6357907902129227e-06\n",
      "Epoch 1584, Loss: 0.04708990582416561, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 1585, Loss: 0.005333942390279844, Final Batch Loss: 0.002083210740238428\n",
      "Epoch 1586, Loss: 0.0034573114524878434, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 1587, Loss: 0.0039067384095687885, Final Batch Loss: 4.10047396144364e-05\n",
      "Epoch 1588, Loss: 0.0759063679807852, Final Batch Loss: 9.366441844349538e-08\n",
      "Epoch 1589, Loss: 0.0014566806457878556, Final Batch Loss: 3.2983934943331406e-05\n",
      "Epoch 1590, Loss: 0.003834358403707938, Final Batch Loss: 3.065378564315324e-07\n",
      "Epoch 1591, Loss: 0.011588819204462197, Final Batch Loss: 6.471145297837211e-06\n",
      "Epoch 1592, Loss: 0.010471765435795533, Final Batch Loss: 3.912931788363494e-05\n",
      "Epoch 1593, Loss: 0.00277909662491993, Final Batch Loss: 5.364398134588555e-07\n",
      "Epoch 1594, Loss: 0.0028694693049011732, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1595, Loss: 0.003219456659280695, Final Batch Loss: 0.0002719687472563237\n",
      "Epoch 1596, Loss: 0.004224522184813395, Final Batch Loss: 0.0013061349745839834\n",
      "Epoch 1597, Loss: 0.001648334404308116, Final Batch Loss: 0.00021541511523537338\n",
      "Epoch 1598, Loss: 0.006560619891388342, Final Batch Loss: 8.895985956769437e-05\n",
      "Epoch 1599, Loss: 0.002487350391959353, Final Batch Loss: 2.6396293151265127e-07\n",
      "Epoch 1600, Loss: 0.0030262437066994607, Final Batch Loss: 4.003586218459532e-05\n",
      "Epoch 1601, Loss: 0.006674548429145943, Final Batch Loss: 0.00011185894982190803\n",
      "Epoch 1602, Loss: 0.0026045910562970676, Final Batch Loss: 0.00034713486093096435\n",
      "Epoch 1603, Loss: 0.008963499349192716, Final Batch Loss: 0.00016279892588499933\n",
      "Epoch 1604, Loss: 0.14737305787275545, Final Batch Loss: 0.12797173857688904\n",
      "Epoch 1605, Loss: 0.025325355731183663, Final Batch Loss: 0.0028755911625921726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1606, Loss: 0.10300351271871477, Final Batch Loss: 0.007027037907391787\n",
      "Epoch 1607, Loss: 0.018162170814321144, Final Batch Loss: 3.249027577112429e-05\n",
      "Epoch 1608, Loss: 0.035456822241940245, Final Batch Loss: 1.3937667063146364e-05\n",
      "Epoch 1609, Loss: 0.07063807899493213, Final Batch Loss: 4.938653432873252e-07\n",
      "Epoch 1610, Loss: 0.0077366761080384094, Final Batch Loss: 1.7200046613652376e-06\n",
      "Epoch 1611, Loss: 0.004894070366617598, Final Batch Loss: 1.9499086647556396e-06\n",
      "Epoch 1612, Loss: 0.015666845288251352, Final Batch Loss: 9.936255992215592e-06\n",
      "Epoch 1613, Loss: 0.03238014513044618, Final Batch Loss: 0.0\n",
      "Epoch 1614, Loss: 0.01687126569049724, Final Batch Loss: 8.514822184224613e-06\n",
      "Epoch 1615, Loss: 0.003413772139538196, Final Batch Loss: 2.394853981968481e-05\n",
      "Epoch 1616, Loss: 0.0019875074722222053, Final Batch Loss: 0.00019012702978216112\n",
      "Epoch 1617, Loss: 0.025478853145614266, Final Batch Loss: 0.0009991072583943605\n",
      "Epoch 1618, Loss: 0.14877498628629837, Final Batch Loss: 0.14339594542980194\n",
      "Epoch 1619, Loss: 0.0477280436023193, Final Batch Loss: 2.384171011726721e-06\n",
      "Epoch 1620, Loss: 0.09821478841240605, Final Batch Loss: 1.3589210539066698e-05\n",
      "Epoch 1621, Loss: 0.01805115206298069, Final Batch Loss: 3.474524783086963e-05\n",
      "Epoch 1622, Loss: 0.7363179727108218, Final Batch Loss: 0.7171422243118286\n",
      "Epoch 1623, Loss: 0.04555880972839077, Final Batch Loss: 3.338311580591835e-05\n",
      "Epoch 1624, Loss: 0.033667776588117704, Final Batch Loss: 0.0002695225120987743\n",
      "Epoch 1625, Loss: 0.04078605549875647, Final Batch Loss: 0.0037616693880409002\n",
      "Epoch 1626, Loss: 0.03658702422399074, Final Batch Loss: 0.0004937913035973907\n",
      "Epoch 1627, Loss: 0.027265644253930077, Final Batch Loss: 0.00035349276731722057\n",
      "Epoch 1628, Loss: 0.023660097824176773, Final Batch Loss: 0.0004089218273293227\n",
      "Epoch 1629, Loss: 0.02193031253409572, Final Batch Loss: 0.0002529799530748278\n",
      "Epoch 1630, Loss: 0.030341878737090155, Final Batch Loss: 0.0002533059741836041\n",
      "Epoch 1631, Loss: 0.023389861424220726, Final Batch Loss: 0.00016708439216017723\n",
      "Epoch 1632, Loss: 0.019952369817360704, Final Batch Loss: 1.6689153881088714e-06\n",
      "Epoch 1633, Loss: 0.01249158865539357, Final Batch Loss: 9.672512533143163e-06\n",
      "Epoch 1634, Loss: 0.005909330084250541, Final Batch Loss: 1.695976607152261e-05\n",
      "Epoch 1635, Loss: 0.007886999170295894, Final Batch Loss: 0.001028382102958858\n",
      "Epoch 1636, Loss: 0.0017386724346692972, Final Batch Loss: 6.556500125043385e-07\n",
      "Epoch 1637, Loss: 0.043943353346548975, Final Batch Loss: 0.010484765283763409\n",
      "Epoch 1638, Loss: 0.016128289920743555, Final Batch Loss: 0.0006093450938351452\n",
      "Epoch 1639, Loss: 0.011935872782487422, Final Batch Loss: 0.0002143928868463263\n",
      "Epoch 1640, Loss: 0.016048540215706453, Final Batch Loss: 0.0008350101998075843\n",
      "Epoch 1641, Loss: 0.004718025654256053, Final Batch Loss: 1.0966413356072735e-05\n",
      "Epoch 1642, Loss: 0.02869930181519109, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 1643, Loss: 0.0036356530617922544, Final Batch Loss: 0.00014061600086279213\n",
      "Epoch 1644, Loss: 0.02076125383609906, Final Batch Loss: 0.0028486347291618586\n",
      "Epoch 1645, Loss: 0.01843283095096737, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 1646, Loss: 0.016633910620384995, Final Batch Loss: 6.419983492378378e-06\n",
      "Epoch 1647, Loss: 0.003284409307525493, Final Batch Loss: 6.134116847533733e-05\n",
      "Epoch 1648, Loss: 0.01272534386953339, Final Batch Loss: 0.0006314269849099219\n",
      "Epoch 1649, Loss: 0.00410597535665147, Final Batch Loss: 0.00020790260168723762\n",
      "Epoch 1650, Loss: 0.014205123763531446, Final Batch Loss: 4.589065792970359e-05\n",
      "Epoch 1651, Loss: 0.005438421154394746, Final Batch Loss: 0.000493241532240063\n",
      "Epoch 1652, Loss: 0.0042011569794340176, Final Batch Loss: 1.1545785127964336e-05\n",
      "Epoch 1653, Loss: 0.03529834529035725, Final Batch Loss: 0.008150873705744743\n",
      "Epoch 1654, Loss: 0.002464502162183635, Final Batch Loss: 0.0004180345858912915\n",
      "Epoch 1655, Loss: 0.01577811816241592, Final Batch Loss: 0.0006937390426173806\n",
      "Epoch 1656, Loss: 0.025955942444852553, Final Batch Loss: 7.11632746970281e-05\n",
      "Epoch 1657, Loss: 0.002392031754425261, Final Batch Loss: 6.152515561552718e-05\n",
      "Epoch 1658, Loss: 0.00476818585809724, Final Batch Loss: 8.600057981311693e-07\n",
      "Epoch 1659, Loss: 0.005325447069481015, Final Batch Loss: 0.0004152821493335068\n",
      "Epoch 1660, Loss: 0.005263754748739302, Final Batch Loss: 1.7640937585383654e-05\n",
      "Epoch 1661, Loss: 0.00407029248890467, Final Batch Loss: 0.001221301732584834\n",
      "Epoch 1662, Loss: 0.0010931370893558778, Final Batch Loss: 4.2488359213166405e-06\n",
      "Epoch 1663, Loss: 0.018842020064766984, Final Batch Loss: 1.086424890672788e-05\n",
      "Epoch 1664, Loss: 0.027808129671029747, Final Batch Loss: 3.0182971386238933e-05\n",
      "Epoch 1665, Loss: 0.01432856958854245, Final Batch Loss: 0.002465753583237529\n",
      "Epoch 1666, Loss: 0.004562085647194181, Final Batch Loss: 7.022466888884082e-05\n",
      "Epoch 1667, Loss: 0.0024746870403760113, Final Batch Loss: 0.00010652693890733644\n",
      "Epoch 1668, Loss: 0.009673632659541909, Final Batch Loss: 8.02911163191311e-05\n",
      "Epoch 1669, Loss: 0.015237148992298444, Final Batch Loss: 2.809931061165116e-07\n",
      "Epoch 1670, Loss: 0.021483395801624283, Final Batch Loss: 0.00032131021725945175\n",
      "Epoch 1671, Loss: 0.0016930174169829115, Final Batch Loss: 2.6597495889291167e-05\n",
      "Epoch 1672, Loss: 0.0028843930006132723, Final Batch Loss: 3.780554152399418e-06\n",
      "Epoch 1673, Loss: 0.0034205189604108455, Final Batch Loss: 1.902871190395672e-05\n",
      "Epoch 1674, Loss: 0.0026583826111163944, Final Batch Loss: 0.00034181386581622064\n",
      "Epoch 1675, Loss: 0.009894713148241863, Final Batch Loss: 0.005689974874258041\n",
      "Epoch 1676, Loss: 0.0026521750442043412, Final Batch Loss: 4.718870695796795e-05\n",
      "Epoch 1677, Loss: 0.018217980716144666, Final Batch Loss: 0.0001476630277466029\n",
      "Epoch 1678, Loss: 0.002926825940647859, Final Batch Loss: 1.2772417790074542e-07\n",
      "Epoch 1679, Loss: 0.0077977655455470085, Final Batch Loss: 0.00039199594175443053\n",
      "Epoch 1680, Loss: 0.005202280648518354, Final Batch Loss: 0.0008857767679728568\n",
      "Epoch 1681, Loss: 0.0026145410956814885, Final Batch Loss: 0.00010194675996899605\n",
      "Epoch 1682, Loss: 0.018592747441743995, Final Batch Loss: 6.215891517058481e-07\n",
      "Epoch 1683, Loss: 0.0036203552808729, Final Batch Loss: 3.054067929042503e-05\n",
      "Epoch 1684, Loss: 0.011443386465543881, Final Batch Loss: 0.009420990012586117\n",
      "Epoch 1685, Loss: 0.0037976500170771033, Final Batch Loss: 0.00048547875485382974\n",
      "Epoch 1686, Loss: 0.009210201002133545, Final Batch Loss: 0.0010999118676409125\n",
      "Epoch 1687, Loss: 0.006749127302100533, Final Batch Loss: 2.068846697511617e-05\n",
      "Epoch 1688, Loss: 0.01006194092133228, Final Batch Loss: 4.444665137270931e-06\n",
      "Epoch 1689, Loss: 0.014566483928774687, Final Batch Loss: 2.1627706701110583e-06\n",
      "Epoch 1690, Loss: 0.013411258607447962, Final Batch Loss: 2.505513657524716e-05\n",
      "Epoch 1691, Loss: 0.0020166735121165402, Final Batch Loss: 5.722326022805646e-05\n",
      "Epoch 1692, Loss: 0.027282949828077108, Final Batch Loss: 0.0071027204394340515\n",
      "Epoch 1693, Loss: 0.00934070604853332, Final Batch Loss: 0.0\n",
      "Epoch 1694, Loss: 0.01962017340474631, Final Batch Loss: 7.186257334979018e-06\n",
      "Epoch 1695, Loss: 0.0053958570351824164, Final Batch Loss: 3.94133385270834e-05\n",
      "Epoch 1696, Loss: 0.0030886374890997104, Final Batch Loss: 3.4144334222219186e-06\n",
      "Epoch 1697, Loss: 0.036330557049950585, Final Batch Loss: 0.0005006337887607515\n",
      "Epoch 1698, Loss: 0.018605710536576225, Final Batch Loss: 2.127569132426288e-05\n",
      "Epoch 1699, Loss: 0.003961817448725924, Final Batch Loss: 0.0005412622122094035\n",
      "Epoch 1700, Loss: 0.0028918438983964734, Final Batch Loss: 1.027706457534805e-05\n",
      "Epoch 1701, Loss: 0.0030496281979139894, Final Batch Loss: 0.00043654924957081676\n",
      "Epoch 1702, Loss: 0.012152738448548916, Final Batch Loss: 4.410614110383904e-06\n",
      "Epoch 1703, Loss: 0.018350940837990493, Final Batch Loss: 0.0010098047787323594\n",
      "Epoch 1704, Loss: 0.002821709005388584, Final Batch Loss: 1.7370381328873918e-06\n",
      "Epoch 1705, Loss: 0.00202263613937248, Final Batch Loss: 2.2817710487288423e-05\n",
      "Epoch 1706, Loss: 0.00551245134556666, Final Batch Loss: 0.0019641038961708546\n",
      "Epoch 1707, Loss: 0.0018887737533077598, Final Batch Loss: 0.00012069010699633509\n",
      "Epoch 1708, Loss: 0.0032028064447331417, Final Batch Loss: 6.249741545616416e-06\n",
      "Epoch 1709, Loss: 0.0026931552096698397, Final Batch Loss: 7.748571420052031e-07\n",
      "Epoch 1710, Loss: 0.0022206238281796686, Final Batch Loss: 0.0003654443135019392\n",
      "Epoch 1711, Loss: 0.003401679001399316, Final Batch Loss: 0.00024310419394169003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1712, Loss: 0.018806037871399894, Final Batch Loss: 0.0008701423066668212\n",
      "Epoch 1713, Loss: 0.008603724039858207, Final Batch Loss: 0.00029400709900073707\n",
      "Epoch 1714, Loss: 0.014723174330356414, Final Batch Loss: 1.42017215694068e-05\n",
      "Epoch 1715, Loss: 0.0046655400261670366, Final Batch Loss: 1.2942660987391719e-06\n",
      "Epoch 1716, Loss: 0.003752751269360033, Final Batch Loss: 6.982234594943293e-07\n",
      "Epoch 1717, Loss: 0.023161944222270137, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1718, Loss: 0.00567748140463209, Final Batch Loss: 1.4390142268894124e-06\n",
      "Epoch 1719, Loss: 0.0017159511999125243, Final Batch Loss: 7.705683856329415e-06\n",
      "Epoch 1720, Loss: 0.013155688493498019, Final Batch Loss: 1.367462937196251e-05\n",
      "Epoch 1721, Loss: 0.0018670777571969666, Final Batch Loss: 0.00041503660031594336\n",
      "Epoch 1722, Loss: 0.04264493589653284, Final Batch Loss: 6.0538153775269166e-05\n",
      "Epoch 1723, Loss: 0.0022261845766706756, Final Batch Loss: 6.811930006733746e-07\n",
      "Epoch 1724, Loss: 0.0037272224653861485, Final Batch Loss: 3.139086038572714e-05\n",
      "Epoch 1725, Loss: 0.016568094812100753, Final Batch Loss: 0.0007803190383128822\n",
      "Epoch 1726, Loss: 0.011703607942763483, Final Batch Loss: 5.412459358922206e-05\n",
      "Epoch 1727, Loss: 0.00233816122636199, Final Batch Loss: 0.00028755926177836955\n",
      "Epoch 1728, Loss: 0.0067361059482209384, Final Batch Loss: 0.0020143240690231323\n",
      "Epoch 1729, Loss: 1.0626994429621845, Final Batch Loss: 1.0497983694076538\n",
      "Epoch 1730, Loss: 0.04335651748983338, Final Batch Loss: 1.1920923981278975e-07\n",
      "Epoch 1731, Loss: 0.09396290144650266, Final Batch Loss: 0.0004736655973829329\n",
      "Epoch 1732, Loss: 0.3817776670903186, Final Batch Loss: 5.1088854888803326e-06\n",
      "Epoch 1733, Loss: 0.09004950003873091, Final Batch Loss: 0.0001221447455463931\n",
      "Epoch 1734, Loss: 0.08172871667193249, Final Batch Loss: 0.0008721743361093104\n",
      "Epoch 1735, Loss: 0.04309624916277244, Final Batch Loss: 4.197487942292355e-05\n",
      "Epoch 1736, Loss: 0.04011166845157277, Final Batch Loss: 0.00021116963762324303\n",
      "Epoch 1737, Loss: 0.014546319987857714, Final Batch Loss: 0.0001941966183949262\n",
      "Epoch 1738, Loss: 0.027947251801379025, Final Batch Loss: 0.0028590892907232046\n",
      "Epoch 1739, Loss: 0.010974085198540706, Final Batch Loss: 7.828279194654897e-05\n",
      "Epoch 1740, Loss: 0.053222307295072824, Final Batch Loss: 0.014677450060844421\n",
      "Epoch 1741, Loss: 0.011033874485292472, Final Batch Loss: 0.0001361624017590657\n",
      "Epoch 1742, Loss: 0.007584601071130237, Final Batch Loss: 2.8269257654756075e-06\n",
      "Epoch 1743, Loss: 0.024917804315919057, Final Batch Loss: 2.230572863481939e-05\n",
      "Epoch 1744, Loss: 0.031608572346158326, Final Batch Loss: 0.0009451647056266665\n",
      "Epoch 1745, Loss: 0.019754067325266078, Final Batch Loss: 0.00032740880851633847\n",
      "Epoch 1746, Loss: 0.01566098938928917, Final Batch Loss: 0.0040189651772379875\n",
      "Epoch 1747, Loss: 0.004921693214669176, Final Batch Loss: 1.243175461240753e-06\n",
      "Epoch 1748, Loss: 0.029217756256912253, Final Batch Loss: 2.0221448721713386e-05\n",
      "Epoch 1749, Loss: 0.005679184519976843, Final Batch Loss: 3.416481922613457e-05\n",
      "Epoch 1750, Loss: 0.006914618279552087, Final Batch Loss: 0.0009478517458774149\n",
      "Epoch 1751, Loss: 0.01134417970024515, Final Batch Loss: 0.00018200052727479488\n",
      "Epoch 1752, Loss: 0.002247652464575367, Final Batch Loss: 4.451793574844487e-05\n",
      "Epoch 1753, Loss: 0.02322856865612266, Final Batch Loss: 2.8751868740073405e-05\n",
      "Epoch 1754, Loss: 0.004594497091602534, Final Batch Loss: 0.001051696832291782\n",
      "Epoch 1755, Loss: 0.007619831784722919, Final Batch Loss: 5.86659098189557e-06\n",
      "Epoch 1756, Loss: 0.0041750910622795345, Final Batch Loss: 9.451296136830933e-06\n",
      "Epoch 1757, Loss: 0.0381319414882455, Final Batch Loss: 0.02112816646695137\n",
      "Epoch 1758, Loss: 0.013012262023039511, Final Batch Loss: 1.8552838810137473e-05\n",
      "Epoch 1759, Loss: 0.019305731606436893, Final Batch Loss: 0.00031501732883043587\n",
      "Epoch 1760, Loss: 0.004876218241406605, Final Batch Loss: 0.0003549919347278774\n",
      "Epoch 1761, Loss: 0.01338967741912711, Final Batch Loss: 4.342493866715813e-06\n",
      "Epoch 1762, Loss: 0.02023836236912757, Final Batch Loss: 0.0004104913678020239\n",
      "Epoch 1763, Loss: 0.01130544761508645, Final Batch Loss: 2.8540152925415896e-05\n",
      "Epoch 1764, Loss: 0.011499849226311198, Final Batch Loss: 1.7981472410610877e-05\n",
      "Epoch 1765, Loss: 0.00993020334863104, Final Batch Loss: 0.0001701058354228735\n",
      "Epoch 1766, Loss: 0.042965857312083244, Final Batch Loss: 0.0065488191321492195\n",
      "Epoch 1767, Loss: 0.005340901239833329, Final Batch Loss: 3.0936709663365036e-05\n",
      "Epoch 1768, Loss: 0.005092068167869002, Final Batch Loss: 0.0014462500112131238\n",
      "Epoch 1769, Loss: 0.00423937184677925, Final Batch Loss: 0.00011554556840565056\n",
      "Epoch 1770, Loss: 0.0032840924002357497, Final Batch Loss: 2.6906971015705494e-06\n",
      "Epoch 1771, Loss: 0.0012362147966769044, Final Batch Loss: 1.6433763221357367e-06\n",
      "Epoch 1772, Loss: 0.012118486052713706, Final Batch Loss: 1.1204878319404088e-05\n",
      "Epoch 1773, Loss: 0.0058151422226728755, Final Batch Loss: 1.4337750144477468e-05\n",
      "Epoch 1774, Loss: 0.011364008096279576, Final Batch Loss: 5.935895751463249e-05\n",
      "Epoch 1775, Loss: 0.0261892627877387, Final Batch Loss: 1.84075743163703e-05\n",
      "Epoch 1776, Loss: 0.001904325969007914, Final Batch Loss: 1.5929721485008486e-05\n",
      "Epoch 1777, Loss: 0.0037885585625190288, Final Batch Loss: 0.0007592899492010474\n",
      "Epoch 1778, Loss: 0.005734548583859578, Final Batch Loss: 0.00031633657636120915\n",
      "Epoch 1779, Loss: 0.004815699356413461, Final Batch Loss: 1.6433752989541972e-06\n",
      "Epoch 1780, Loss: 0.02281257939466741, Final Batch Loss: 0.00014495720097329468\n",
      "Epoch 1781, Loss: 0.006257780747546349, Final Batch Loss: 9.029653301695362e-05\n",
      "Epoch 1782, Loss: 0.0017326387242064811, Final Batch Loss: 0.00010045927774626762\n",
      "Epoch 1783, Loss: 0.004372335930383997, Final Batch Loss: 4.3999654735671356e-05\n",
      "Epoch 1784, Loss: 0.00393651954800589, Final Batch Loss: 4.254504892742261e-05\n",
      "Epoch 1785, Loss: 0.03388762597751338, Final Batch Loss: 0.00017169893544632941\n",
      "Epoch 1786, Loss: 0.007874890769016929, Final Batch Loss: 0.0001365312928101048\n",
      "Epoch 1787, Loss: 0.025653877237346023, Final Batch Loss: 0.00034159646020270884\n",
      "Epoch 1788, Loss: 0.002359481601160951, Final Batch Loss: 0.0012131973635405302\n",
      "Epoch 1789, Loss: 0.007094585707818624, Final Batch Loss: 6.820308044552803e-05\n",
      "Epoch 1790, Loss: 0.0071443910793611565, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 1791, Loss: 0.010491571913007647, Final Batch Loss: 0.0071669211611151695\n",
      "Epoch 1792, Loss: 0.0035777783559751697, Final Batch Loss: 8.238104783231393e-05\n",
      "Epoch 1793, Loss: 0.006272989525314188, Final Batch Loss: 3.086958531639539e-05\n",
      "Epoch 1794, Loss: 0.010967030983010773, Final Batch Loss: 4.191825428279117e-05\n",
      "Epoch 1795, Loss: 0.0024934744724305347, Final Batch Loss: 0.0008389832219108939\n",
      "Epoch 1796, Loss: 0.002942666847957298, Final Batch Loss: 9.353172936243936e-05\n",
      "Epoch 1797, Loss: 0.017447262536734343, Final Batch Loss: 0.0002389036089880392\n",
      "Epoch 1798, Loss: 0.012819292827771278, Final Batch Loss: 2.2860058379592374e-05\n",
      "Epoch 1799, Loss: 0.0032494898750883294, Final Batch Loss: 8.991510185296647e-06\n",
      "Epoch 1800, Loss: 0.0018643356836491876, Final Batch Loss: 2.2564292976312572e-06\n",
      "Epoch 1801, Loss: 0.002220024420239497, Final Batch Loss: 0.0001256163086509332\n",
      "Epoch 1802, Loss: 0.005315011560924177, Final Batch Loss: 6.4030364228528924e-06\n",
      "Epoch 1803, Loss: 0.03420659410767257, Final Batch Loss: 0.014324593357741833\n",
      "Epoch 1804, Loss: 0.0032772568811196834, Final Batch Loss: 0.0005971557693555951\n",
      "Epoch 1805, Loss: 0.003082098555751145, Final Batch Loss: 0.00029991474002599716\n",
      "Epoch 1806, Loss: 0.07708483037094993, Final Batch Loss: 2.1062956875539385e-05\n",
      "Epoch 1807, Loss: 0.008804848068393767, Final Batch Loss: 0.0007960192742757499\n",
      "Epoch 1808, Loss: 0.027054042904524067, Final Batch Loss: 1.3453535530061345e-06\n",
      "Epoch 1809, Loss: 0.0043516860278032254, Final Batch Loss: 4.288543641450815e-05\n",
      "Epoch 1810, Loss: 0.0038245367468334734, Final Batch Loss: 0.00022650914615951478\n",
      "Epoch 1811, Loss: 0.003758144797757268, Final Batch Loss: 0.00039631343679502606\n",
      "Epoch 1812, Loss: 0.022907414895598777, Final Batch Loss: 0.003127046162262559\n",
      "Epoch 1813, Loss: 0.004675873717275181, Final Batch Loss: 1.8732876583271718e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1814, Loss: 0.01594907490652986, Final Batch Loss: 0.0010579510126262903\n",
      "Epoch 1815, Loss: 0.00434460290671268, Final Batch Loss: 2.6479732696316205e-05\n",
      "Epoch 1816, Loss: 0.0026480040195622223, Final Batch Loss: 3.661424727852136e-07\n",
      "Epoch 1817, Loss: 0.02567374979844317, Final Batch Loss: 0.00023696714197285473\n",
      "Epoch 1818, Loss: 0.032547105838602874, Final Batch Loss: 5.2671101002488285e-05\n",
      "Epoch 1819, Loss: 0.0036916093959007412, Final Batch Loss: 0.00030789567972533405\n",
      "Epoch 1820, Loss: 0.015589109987558913, Final Batch Loss: 8.642424290883355e-06\n",
      "Epoch 1821, Loss: 0.014150087838061154, Final Batch Loss: 0.00010581349488347769\n",
      "Epoch 1822, Loss: 0.005344933812011732, Final Batch Loss: 2.4256947654066607e-05\n",
      "Epoch 1823, Loss: 0.0036863477976112335, Final Batch Loss: 5.2195205171301495e-06\n",
      "Epoch 1824, Loss: 0.013244449597550556, Final Batch Loss: 0.010031914338469505\n",
      "Epoch 1825, Loss: 0.004222246559947962, Final Batch Loss: 1.9667906599352136e-05\n",
      "Epoch 1826, Loss: 0.0026633242767388765, Final Batch Loss: 8.855520832184993e-07\n",
      "Epoch 1827, Loss: 0.006473888223140989, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 1828, Loss: 0.009241424399078824, Final Batch Loss: 0.0003124241775367409\n",
      "Epoch 1829, Loss: 0.033106248088188295, Final Batch Loss: 6.130508154456038e-06\n",
      "Epoch 1830, Loss: 0.0036118410682774993, Final Batch Loss: 2.5289011773566017e-06\n",
      "Epoch 1831, Loss: 0.004765701706674008, Final Batch Loss: 9.357559065392707e-06\n",
      "Epoch 1832, Loss: 0.004885921780442004, Final Batch Loss: 2.179805960622616e-06\n",
      "Epoch 1833, Loss: 0.020214549789670855, Final Batch Loss: 0.0005290586268529296\n",
      "Epoch 1834, Loss: 0.005118761822814122, Final Batch Loss: 0.00017118356481660157\n",
      "Epoch 1835, Loss: 0.006245340145881073, Final Batch Loss: 7.833712629690126e-07\n",
      "Epoch 1836, Loss: 0.001920875823998358, Final Batch Loss: 2.290154225192964e-05\n",
      "Epoch 1837, Loss: 0.0034793729300872656, Final Batch Loss: 1.526605228718836e-05\n",
      "Epoch 1838, Loss: 0.0035697186503966805, Final Batch Loss: 2.9291149985510856e-06\n",
      "Epoch 1839, Loss: 0.0019791746917690034, Final Batch Loss: 7.075740541040432e-06\n",
      "Epoch 1840, Loss: 0.012964313717588993, Final Batch Loss: 1.0984209666276001e-06\n",
      "Epoch 1841, Loss: 0.0035350750599718594, Final Batch Loss: 8.770343811193015e-07\n",
      "Epoch 1842, Loss: 0.00920655467780307, Final Batch Loss: 0.0004926911205984652\n",
      "Epoch 1843, Loss: 0.002346057415707037, Final Batch Loss: 0.0005500164115801454\n",
      "Epoch 1844, Loss: 0.004287844785721973, Final Batch Loss: 5.219480954110622e-06\n",
      "Epoch 1845, Loss: 0.003928123944206163, Final Batch Loss: 0.0007785366615280509\n",
      "Epoch 1846, Loss: 0.009365459147375077, Final Batch Loss: 0.0012839393457397819\n",
      "Epoch 1847, Loss: 0.0022691396588925272, Final Batch Loss: 1.324014738202095e-05\n",
      "Epoch 1848, Loss: 0.007462816195982214, Final Batch Loss: 2.980227122861834e-07\n",
      "Epoch 1849, Loss: 0.0057846810086630285, Final Batch Loss: 0.0\n",
      "Epoch 1850, Loss: 0.0017289119568886235, Final Batch Loss: 0.00013844117347616702\n",
      "Epoch 1851, Loss: 0.002359672263992252, Final Batch Loss: 4.3053289118688554e-05\n",
      "Epoch 1852, Loss: 0.004326994995381028, Final Batch Loss: 2.7247576781519456e-06\n",
      "Epoch 1853, Loss: 0.022874332606855674, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 1854, Loss: 0.0014011868279339978, Final Batch Loss: 1.1698959497152828e-05\n",
      "Epoch 1855, Loss: 0.0038562215939919042, Final Batch Loss: 1.098423922485381e-06\n",
      "Epoch 1856, Loss: 0.02355643165356014, Final Batch Loss: 0.000575230282265693\n",
      "Epoch 1857, Loss: 0.005406830473344115, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 1858, Loss: 0.023438929525582353, Final Batch Loss: 8.455740317003801e-05\n",
      "Epoch 1859, Loss: 0.0066289728050605845, Final Batch Loss: 1.9073262365054688e-06\n",
      "Epoch 1860, Loss: 0.003870984714012593, Final Batch Loss: 0.0003501823521219194\n",
      "Epoch 1861, Loss: 0.012037125694405404, Final Batch Loss: 1.5793501006555744e-05\n",
      "Epoch 1862, Loss: 0.001341341520202377, Final Batch Loss: 3.2356754786633246e-07\n",
      "Epoch 1863, Loss: 0.004744779027532786, Final Batch Loss: 0.0\n",
      "Epoch 1864, Loss: 0.002570400210970547, Final Batch Loss: 7.34040149836801e-05\n",
      "Epoch 1865, Loss: 0.007897582829173189, Final Batch Loss: 8.017449727049097e-05\n",
      "Epoch 1866, Loss: 0.0030123726464807987, Final Batch Loss: 0.00018083401664625853\n",
      "Epoch 1867, Loss: 0.017651885296800174, Final Batch Loss: 0.00307111325673759\n",
      "Epoch 1868, Loss: 0.009770353397470899, Final Batch Loss: 0.0003254837356507778\n",
      "Epoch 1869, Loss: 0.013606807158794254, Final Batch Loss: 0.005864568520337343\n",
      "Epoch 1870, Loss: 0.0025573967818672827, Final Batch Loss: 5.491989668371389e-06\n",
      "Epoch 1871, Loss: 0.0019750085048144683, Final Batch Loss: 6.926164496690035e-05\n",
      "Epoch 1872, Loss: 0.007447743002558127, Final Batch Loss: 0.0002092634967993945\n",
      "Epoch 1873, Loss: 0.007057991368128569, Final Batch Loss: 8.165510735125281e-06\n",
      "Epoch 1874, Loss: 0.00104432120346587, Final Batch Loss: 4.598062730565289e-07\n",
      "Epoch 1875, Loss: 0.019489880300170626, Final Batch Loss: 1.300114490732085e-05\n",
      "Epoch 1876, Loss: 0.0016290313506033272, Final Batch Loss: 1.049817365128547e-05\n",
      "Epoch 1877, Loss: 0.00219317723531276, Final Batch Loss: 7.672268839087337e-05\n",
      "Epoch 1878, Loss: 0.008188839054241726, Final Batch Loss: 5.364400976759498e-07\n",
      "Epoch 1879, Loss: 0.006561938346180796, Final Batch Loss: 1.0728766710599302e-06\n",
      "Epoch 1880, Loss: 0.0013383881564550393, Final Batch Loss: 2.750279691099422e-06\n",
      "Epoch 1881, Loss: 0.030636113901437056, Final Batch Loss: 4.163689027336659e-06\n",
      "Epoch 1882, Loss: 0.009232445008819923, Final Batch Loss: 0.0005630230880342424\n",
      "Epoch 1883, Loss: 0.003258015349274501, Final Batch Loss: 0.00023525864526163787\n",
      "Epoch 1884, Loss: 0.02138803576212922, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 1885, Loss: 0.00402680499246344, Final Batch Loss: 0.0003536186704877764\n",
      "Epoch 1886, Loss: 0.020157035731244832, Final Batch Loss: 0.0029595501255244017\n",
      "Epoch 1887, Loss: 0.0026899602245293863, Final Batch Loss: 1.558220105835062e-06\n",
      "Epoch 1888, Loss: 0.00377836762345396, Final Batch Loss: 0.0022014740388840437\n",
      "Epoch 1889, Loss: 0.0018837542071707958, Final Batch Loss: 2.63963244151455e-07\n",
      "Epoch 1890, Loss: 0.0044726569030899554, Final Batch Loss: 0.0014678441220894456\n",
      "Epoch 1891, Loss: 0.001646698188778828, Final Batch Loss: 1.9726428945432417e-05\n",
      "Epoch 1892, Loss: 0.002206415131695394, Final Batch Loss: 1.0805114470713306e-05\n",
      "Epoch 1893, Loss: 0.0027499323296069633, Final Batch Loss: 3.56538912456017e-05\n",
      "Epoch 1894, Loss: 0.005993895370920654, Final Batch Loss: 0.0017273119883611798\n",
      "Epoch 1895, Loss: 0.0013007246500365, Final Batch Loss: 2.903541144405608e-06\n",
      "Epoch 1896, Loss: 0.004228517939964149, Final Batch Loss: 2.043572067123023e-06\n",
      "Epoch 1897, Loss: 0.002151150847566896, Final Batch Loss: 2.5583047317923047e-05\n",
      "Epoch 1898, Loss: 0.00354494781458925, Final Batch Loss: 2.7413158022682182e-05\n",
      "Epoch 1899, Loss: 0.02118364449142973, Final Batch Loss: 1.233712555404054e-05\n",
      "Epoch 1900, Loss: 0.0068445466822595336, Final Batch Loss: 5.429503653431311e-05\n",
      "Epoch 1901, Loss: 0.008663482658448629, Final Batch Loss: 0.00018104254559148103\n",
      "Epoch 1902, Loss: 0.0033545579653946334, Final Batch Loss: 6.232673513295595e-06\n",
      "Epoch 1903, Loss: 0.013396912967436947, Final Batch Loss: 0.010047431103885174\n",
      "Epoch 1904, Loss: 0.0011850409136968665, Final Batch Loss: 9.288539877161384e-05\n",
      "Epoch 1905, Loss: 0.008303116119350307, Final Batch Loss: 0.004231116734445095\n",
      "Epoch 1906, Loss: 0.014933596889022738, Final Batch Loss: 0.0018387731397524476\n",
      "Epoch 1907, Loss: 0.014507208159557194, Final Batch Loss: 2.6297837393940426e-05\n",
      "Epoch 1908, Loss: 0.007100904833350796, Final Batch Loss: 8.376873302040622e-05\n",
      "Epoch 1909, Loss: 0.0007797654752721428, Final Batch Loss: 1.4117124919721391e-05\n",
      "Epoch 1910, Loss: 0.005822441457894456, Final Batch Loss: 1.2260502444405574e-05\n",
      "Epoch 1911, Loss: 0.013749605021075695, Final Batch Loss: 2.2135440303827636e-05\n",
      "Epoch 1912, Loss: 0.0021995006785573423, Final Batch Loss: 1.0217934232059633e-07\n",
      "Epoch 1913, Loss: 0.006470221904237405, Final Batch Loss: 2.5551338694640435e-05\n",
      "Epoch 1914, Loss: 0.019768285550526343, Final Batch Loss: 0.0\n",
      "Epoch 1915, Loss: 0.0028035204668412916, Final Batch Loss: 5.251171387499198e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1916, Loss: 0.0031667448120060726, Final Batch Loss: 1.1468938282632735e-05\n",
      "Epoch 1917, Loss: 0.04242825185065158, Final Batch Loss: 0.0007779363659210503\n",
      "Epoch 1918, Loss: 0.00154159346857341, Final Batch Loss: 0.0005783112719655037\n",
      "Epoch 1919, Loss: 0.01441638877281548, Final Batch Loss: 2.7332482659403468e-06\n",
      "Epoch 1920, Loss: 0.0012772336267516948, Final Batch Loss: 7.713959348620847e-05\n",
      "Epoch 1921, Loss: 0.0035095826897304505, Final Batch Loss: 6.843890878371894e-05\n",
      "Epoch 1922, Loss: 0.004796928085852414, Final Batch Loss: 0.002124052494764328\n",
      "Epoch 1923, Loss: 0.0020324893282008816, Final Batch Loss: 6.130737233434047e-07\n",
      "Epoch 1924, Loss: 0.00590664991614176, Final Batch Loss: 9.648815466789529e-05\n",
      "Epoch 1925, Loss: 0.0019706370173082632, Final Batch Loss: 4.0020191249823256e-07\n",
      "Epoch 1926, Loss: 0.010499016541871242, Final Batch Loss: 0.00016049889381974936\n",
      "Epoch 1927, Loss: 0.019653986440971494, Final Batch Loss: 0.00035720356390811503\n",
      "Epoch 1928, Loss: 0.01100166682863346, Final Batch Loss: 1.3964408935862593e-06\n",
      "Epoch 1929, Loss: 0.003203910142076438, Final Batch Loss: 5.705001626665762e-07\n",
      "Epoch 1930, Loss: 0.001479843384004198, Final Batch Loss: 0.0\n",
      "Epoch 1931, Loss: 0.01175350395010355, Final Batch Loss: 1.7285240119235823e-06\n",
      "Epoch 1932, Loss: 0.01404058331536362, Final Batch Loss: 0.012677283026278019\n",
      "Epoch 1933, Loss: 0.002326134922896017, Final Batch Loss: 5.049292212788714e-06\n",
      "Epoch 1934, Loss: 0.005375621406756181, Final Batch Loss: 4.93865854878095e-07\n",
      "Epoch 1935, Loss: 0.0068031386221747425, Final Batch Loss: 1.362390804615643e-07\n",
      "Epoch 1936, Loss: 0.3536061186932784, Final Batch Loss: 0.34560689330101013\n",
      "Epoch 1937, Loss: 0.009717551554786041, Final Batch Loss: 0.0001588314480613917\n",
      "Epoch 1938, Loss: 0.011745539159164764, Final Batch Loss: 0.00019076450553257018\n",
      "Epoch 1939, Loss: 0.009227110189385712, Final Batch Loss: 0.0005161965964362025\n",
      "Epoch 1940, Loss: 0.01858535344217671, Final Batch Loss: 0.0015796542866155505\n",
      "Epoch 1941, Loss: 0.005109601886942983, Final Batch Loss: 0.0016158849466592073\n",
      "Epoch 1942, Loss: 0.006167571671539918, Final Batch Loss: 0.0001314797846134752\n",
      "Epoch 1943, Loss: 0.0012108315488603694, Final Batch Loss: 3.5336190649104537e-06\n",
      "Epoch 1944, Loss: 0.0037145145470276475, Final Batch Loss: 0.0\n",
      "Epoch 1945, Loss: 0.001914029446652421, Final Batch Loss: 3.942318016925128e-06\n",
      "Epoch 1946, Loss: 0.0030186952935764566, Final Batch Loss: 0.00045234712888486683\n",
      "Epoch 1947, Loss: 0.007554400071967393, Final Batch Loss: 0.00452450243756175\n",
      "Epoch 1948, Loss: 0.006739161137375049, Final Batch Loss: 0.0\n",
      "Epoch 1949, Loss: 0.0021293204663379584, Final Batch Loss: 2.1345538698369637e-05\n",
      "Epoch 1950, Loss: 0.005164015223272145, Final Batch Loss: 7.403717609122396e-05\n",
      "Epoch 1951, Loss: 0.0034896167966849134, Final Batch Loss: 8.089158995971957e-07\n",
      "Epoch 1952, Loss: 0.002651742756825115, Final Batch Loss: 1.4448999536398333e-05\n",
      "Epoch 1953, Loss: 0.002615293975395616, Final Batch Loss: 1.3009695976506919e-05\n",
      "Epoch 1954, Loss: 0.006565003248397261, Final Batch Loss: 0.00025705122970975935\n",
      "Epoch 1955, Loss: 0.013171724387575523, Final Batch Loss: 2.3233698811964132e-05\n",
      "Epoch 1956, Loss: 0.0011555100900295656, Final Batch Loss: 6.701801612507552e-05\n",
      "Epoch 1957, Loss: 0.017852596029115375, Final Batch Loss: 6.92790126777254e-05\n",
      "Epoch 1958, Loss: 0.019483311945805326, Final Batch Loss: 5.8240111684426665e-06\n",
      "Epoch 1959, Loss: 0.007980283485835571, Final Batch Loss: 5.023808853366063e-07\n",
      "Epoch 1960, Loss: 0.010325645089324098, Final Batch Loss: 8.562394214095548e-05\n",
      "Epoch 1961, Loss: 0.0019034034194191918, Final Batch Loss: 0.0\n",
      "Epoch 1962, Loss: 0.00291435862891376, Final Batch Loss: 0.0003197979531250894\n",
      "Epoch 1963, Loss: 0.0031225432012433885, Final Batch Loss: 1.583763150847517e-06\n",
      "Epoch 1964, Loss: 0.00964285945519805, Final Batch Loss: 0.0012060446897521615\n",
      "Epoch 1965, Loss: 0.0009686994999356102, Final Batch Loss: 1.781964601832442e-05\n",
      "Epoch 1966, Loss: 0.0016076035503544972, Final Batch Loss: 4.0871643136597413e-07\n",
      "Epoch 1967, Loss: 0.0022591306251342758, Final Batch Loss: 5.108798177388962e-06\n",
      "Epoch 1968, Loss: 0.006566048441470684, Final Batch Loss: 3.065378564315324e-07\n",
      "Epoch 1969, Loss: 0.00113280450750608, Final Batch Loss: 0.0\n",
      "Epoch 1970, Loss: 0.0025392125251073594, Final Batch Loss: 1.8392172478343127e-06\n",
      "Epoch 1971, Loss: 0.011507584291393869, Final Batch Loss: 0.00015349565364886075\n",
      "Epoch 1972, Loss: 0.005648849095450714, Final Batch Loss: 0.00015292355965357274\n",
      "Epoch 1973, Loss: 0.00459441885425349, Final Batch Loss: 9.366442554892274e-08\n",
      "Epoch 1974, Loss: 0.0012529994016858836, Final Batch Loss: 1.311291043748497e-06\n",
      "Epoch 1975, Loss: 0.0024291237350553274, Final Batch Loss: 0.000587600632570684\n",
      "Epoch 1976, Loss: 0.0026786304432366848, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 1977, Loss: 0.0027739156867028214, Final Batch Loss: 0.00015776096552144736\n",
      "Epoch 1978, Loss: 0.004102724886251963, Final Batch Loss: 7.67155688663479e-06\n",
      "Epoch 1979, Loss: 0.002570253735939332, Final Batch Loss: 4.614962563209701e-06\n",
      "Epoch 1980, Loss: 0.000689781418941493, Final Batch Loss: 3.116411562587018e-06\n",
      "Epoch 1981, Loss: 0.0033917770633706823, Final Batch Loss: 0.0001556538773002103\n",
      "Epoch 1982, Loss: 0.0013721760477238831, Final Batch Loss: 2.3841842278216063e-07\n",
      "Epoch 1983, Loss: 0.0009900930963340215, Final Batch Loss: 0.00018338939116802067\n",
      "Epoch 1984, Loss: 0.0033430473972657637, Final Batch Loss: 2.1883147383050527e-06\n",
      "Epoch 1985, Loss: 0.00146736576789408, Final Batch Loss: 0.0002121429715771228\n",
      "Epoch 1986, Loss: 0.0032620949496049434, Final Batch Loss: 0.0018518271390348673\n",
      "Epoch 1987, Loss: 0.003755366720724851, Final Batch Loss: 0.0005325750098563731\n",
      "Epoch 1988, Loss: 0.0038523899302163045, Final Batch Loss: 1.0455830306455027e-05\n",
      "Epoch 1989, Loss: 0.0026279168443466006, Final Batch Loss: 6.897091111568443e-07\n",
      "Epoch 1990, Loss: 0.014561442558260751, Final Batch Loss: 1.6177191355382092e-05\n",
      "Epoch 1991, Loss: 0.002715011047257576, Final Batch Loss: 0.00032210000790655613\n",
      "Epoch 1992, Loss: 0.004526629520114511, Final Batch Loss: 0.0\n",
      "Epoch 1993, Loss: 0.019097838971333658, Final Batch Loss: 1.0813949984367355e-06\n",
      "Epoch 1994, Loss: 0.019668695424115867, Final Batch Loss: 2.6570322006591596e-05\n",
      "Epoch 1995, Loss: 0.0068437365189311095, Final Batch Loss: 5.797598714707419e-05\n",
      "Epoch 1996, Loss: 0.009410976206709165, Final Batch Loss: 6.57647688058205e-05\n",
      "Epoch 1997, Loss: 0.004943968073348515, Final Batch Loss: 0.0001129831507569179\n",
      "Epoch 1998, Loss: 0.029139567457605153, Final Batch Loss: 0.0\n",
      "Epoch 1999, Loss: 0.02504484282667363, Final Batch Loss: 9.792127002583584e-07\n",
      "Epoch 2000, Loss: 0.014487683292827569, Final Batch Loss: 0.009593755938112736\n",
      "Epoch 2001, Loss: 0.0065273744985461235, Final Batch Loss: 0.0003839064738713205\n",
      "Epoch 2002, Loss: 0.0023733826060379215, Final Batch Loss: 2.622586634970503e-06\n",
      "Epoch 2003, Loss: 0.011761955072870478, Final Batch Loss: 0.0004873211437370628\n",
      "Epoch 2004, Loss: 0.00471946060341466, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2005, Loss: 0.0020412740657320683, Final Batch Loss: 2.4522839794371976e-06\n",
      "Epoch 2006, Loss: 0.006835898733697832, Final Batch Loss: 3.4077274904120713e-05\n",
      "Epoch 2007, Loss: 0.007552710245363414, Final Batch Loss: 0.00029847928090021014\n",
      "Epoch 2008, Loss: 0.0020349792077922757, Final Batch Loss: 2.5629753963585244e-06\n",
      "Epoch 2009, Loss: 0.007893035100778434, Final Batch Loss: 2.0691074951173505e-06\n",
      "Epoch 2010, Loss: 0.0017375324229078615, Final Batch Loss: 1.0984209666276001e-06\n",
      "Epoch 2011, Loss: 0.016342423195396805, Final Batch Loss: 1.0643647101460374e-06\n",
      "Epoch 2012, Loss: 0.003446388232987374, Final Batch Loss: 0.0002975167299155146\n",
      "Epoch 2013, Loss: 0.0030510878914356, Final Batch Loss: 1.4185256077325903e-05\n",
      "Epoch 2014, Loss: 0.008457367453956977, Final Batch Loss: 0.00403958884999156\n",
      "Epoch 2015, Loss: 0.002466337027726695, Final Batch Loss: 0.0001781840401235968\n",
      "Epoch 2016, Loss: 0.005702007285435684, Final Batch Loss: 0.0008209101506508887\n",
      "Epoch 2017, Loss: 0.006360975152347237, Final Batch Loss: 0.0\n",
      "Epoch 2018, Loss: 0.0011674170465383327, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 2019, Loss: 0.0008112651672202986, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2020, Loss: 0.02363676835784645, Final Batch Loss: 2.111676167260157e-06\n",
      "Epoch 2021, Loss: 0.0015748400255688466, Final Batch Loss: 0.0005981699796393514\n",
      "Epoch 2022, Loss: 0.004988349945051596, Final Batch Loss: 0.00014729774557054043\n",
      "Epoch 2023, Loss: 0.008224033110309392, Final Batch Loss: 0.0002811604936141521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2024, Loss: 0.02628374274354428, Final Batch Loss: 0.006143874488770962\n",
      "Epoch 2025, Loss: 0.009758937462720496, Final Batch Loss: 7.203400855360087e-06\n",
      "Epoch 2026, Loss: 0.004148814251948352, Final Batch Loss: 4.487300884647993e-06\n",
      "Epoch 2027, Loss: 0.01908652416535972, Final Batch Loss: 1.1069427330312465e-07\n",
      "Epoch 2028, Loss: 0.0015235677592499997, Final Batch Loss: 1.4610474863729905e-05\n",
      "Epoch 2029, Loss: 0.0011180275466813328, Final Batch Loss: 1.1239678769925376e-06\n",
      "Epoch 2030, Loss: 0.009582644117472228, Final Batch Loss: 0.0005304196965880692\n",
      "Epoch 2031, Loss: 0.002294455619448854, Final Batch Loss: 3.93379832530627e-06\n",
      "Epoch 2032, Loss: 0.040933988896753704, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 2033, Loss: 0.026092602495086936, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2034, Loss: 0.002349260745177162, Final Batch Loss: 2.7378964659874327e-05\n",
      "Epoch 2035, Loss: 0.014490807385300286, Final Batch Loss: 0.011082702316343784\n",
      "Epoch 2036, Loss: 0.03882655262714252, Final Batch Loss: 0.0024958804715424776\n",
      "Epoch 2037, Loss: 0.05489854145935169, Final Batch Loss: 5.2620694077631924e-06\n",
      "Epoch 2038, Loss: 0.013179107962059788, Final Batch Loss: 0.0001907928381115198\n",
      "Epoch 2039, Loss: 0.007928016064397525, Final Batch Loss: 0.0026716534048318863\n",
      "Epoch 2040, Loss: 0.014747179142432287, Final Batch Loss: 6.681110244244337e-05\n",
      "Epoch 2041, Loss: 0.012759028665641381, Final Batch Loss: 8.369891475012992e-06\n",
      "Epoch 2042, Loss: 0.0030433237843681127, Final Batch Loss: 0.0\n",
      "Epoch 2043, Loss: 0.031841323885601014, Final Batch Loss: 0.0005738795734941959\n",
      "Epoch 2044, Loss: 0.00952245026746823, Final Batch Loss: 1.936075022967998e-05\n",
      "Epoch 2045, Loss: 0.0034874095290433615, Final Batch Loss: 0.0\n",
      "Epoch 2046, Loss: 0.0048670224028910525, Final Batch Loss: 5.279258630253025e-07\n",
      "Epoch 2047, Loss: 0.0021066067988613213, Final Batch Loss: 4.725718554254854e-06\n",
      "Epoch 2048, Loss: 0.005434170751726697, Final Batch Loss: 2.128734593043191e-07\n",
      "Epoch 2049, Loss: 0.003323442082546535, Final Batch Loss: 9.136090739048086e-06\n",
      "Epoch 2050, Loss: 0.0022322065487969667, Final Batch Loss: 0.00043522167834453285\n",
      "Epoch 2051, Loss: 0.0011486348957987502, Final Batch Loss: 0.00013275555102154613\n",
      "Epoch 2052, Loss: 0.023497797374147922, Final Batch Loss: 1.2669217539951205e-05\n",
      "Epoch 2053, Loss: 0.014530436068810104, Final Batch Loss: 2.6396293151265127e-07\n",
      "Epoch 2054, Loss: 0.016352198649201455, Final Batch Loss: 2.758790742518613e-06\n",
      "Epoch 2055, Loss: 0.0015623119670635788, Final Batch Loss: 4.2403244151500985e-06\n",
      "Epoch 2056, Loss: 0.028729805647571993, Final Batch Loss: 2.3586228508065687e-06\n",
      "Epoch 2057, Loss: 0.0029122780833858997, Final Batch Loss: 0.0011267209192737937\n",
      "Epoch 2058, Loss: 0.006045408357749693, Final Batch Loss: 0.0030516742262989283\n",
      "Epoch 2059, Loss: 0.006193120207171887, Final Batch Loss: 0.0029985513538122177\n",
      "Epoch 2060, Loss: 0.00734830682631582, Final Batch Loss: 0.004439813084900379\n",
      "Epoch 2061, Loss: 0.013530597133012634, Final Batch Loss: 3.882777036778862e-06\n",
      "Epoch 2062, Loss: 0.0024507975540473126, Final Batch Loss: 6.530535029014573e-05\n",
      "Epoch 2063, Loss: 0.0033633436942182016, Final Batch Loss: 5.603192767011933e-05\n",
      "Epoch 2064, Loss: 0.007609134423546493, Final Batch Loss: 0.000808973447419703\n",
      "Epoch 2065, Loss: 0.014224432795572284, Final Batch Loss: 3.712434818226029e-06\n",
      "Epoch 2066, Loss: 0.0023330505537160207, Final Batch Loss: 0.0\n",
      "Epoch 2067, Loss: 0.008829872545902617, Final Batch Loss: 6.492761167464778e-05\n",
      "Epoch 2068, Loss: 0.0073495190881658345, Final Batch Loss: 0.002935436787083745\n",
      "Epoch 2069, Loss: 0.0013568662398029119, Final Batch Loss: 0.0005337994662113488\n",
      "Epoch 2070, Loss: 0.020463802514711915, Final Batch Loss: 2.895080228881852e-07\n",
      "Epoch 2071, Loss: 0.00345940214357654, Final Batch Loss: 1.8732863793502474e-07\n",
      "Epoch 2072, Loss: 0.02230612852073932, Final Batch Loss: 4.7683644766038924e-07\n",
      "Epoch 2073, Loss: 0.0022299058182397857, Final Batch Loss: 0.00018013631051871926\n",
      "Epoch 2074, Loss: 0.0025662172392912908, Final Batch Loss: 2.9856824767193757e-05\n",
      "Epoch 2075, Loss: 0.02708532656833995, Final Batch Loss: 7.934936002129689e-05\n",
      "Epoch 2076, Loss: 0.03317061994977166, Final Batch Loss: 2.9802259859934566e-07\n",
      "Epoch 2077, Loss: 0.0012631857275664515, Final Batch Loss: 4.19780872107367e-06\n",
      "Epoch 2078, Loss: 0.0024679003181518055, Final Batch Loss: 0.0005462287808768451\n",
      "Epoch 2079, Loss: 0.0041826055276033, Final Batch Loss: 6.074535849620588e-05\n",
      "Epoch 2080, Loss: 0.04173999570775777, Final Batch Loss: 0.03631630912423134\n",
      "Epoch 2081, Loss: 0.0031457342238354613, Final Batch Loss: 6.386189852491952e-07\n",
      "Epoch 2082, Loss: 0.003817594331501084, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2083, Loss: 0.004664138272346463, Final Batch Loss: 1.518951467005536e-05\n",
      "Epoch 2084, Loss: 0.004128306209167931, Final Batch Loss: 6.344992289086804e-05\n",
      "Epoch 2085, Loss: 0.0019935150194214657, Final Batch Loss: 0.0004890802083536983\n",
      "Epoch 2086, Loss: 0.0012630855453608092, Final Batch Loss: 6.309408490778878e-06\n",
      "Epoch 2087, Loss: 0.0014666585375380237, Final Batch Loss: 3.1175095500657335e-05\n",
      "Epoch 2088, Loss: 0.015207001380986185, Final Batch Loss: 2.784793650789652e-05\n",
      "Epoch 2089, Loss: 0.01707881009861012, Final Batch Loss: 3.9943759475136176e-05\n",
      "Epoch 2090, Loss: 0.008682551100491764, Final Batch Loss: 3.6188046124152606e-06\n",
      "Epoch 2091, Loss: 0.017901323043020057, Final Batch Loss: 1.7796031670513912e-06\n",
      "Epoch 2092, Loss: 0.005998548611842125, Final Batch Loss: 8.344618436240125e-07\n",
      "Epoch 2093, Loss: 0.0023881756754349226, Final Batch Loss: 9.025791882777412e-07\n",
      "Epoch 2094, Loss: 0.0012767073958457331, Final Batch Loss: 1.0362043212808203e-05\n",
      "Epoch 2095, Loss: 0.007119837424141906, Final Batch Loss: 3.746569916529552e-07\n",
      "Epoch 2096, Loss: 0.0014824058016529307, Final Batch Loss: 0.00025659313541837037\n",
      "Epoch 2097, Loss: 0.0031372856683447026, Final Batch Loss: 0.00021147647930774838\n",
      "Epoch 2098, Loss: 0.0015727667778016041, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 2099, Loss: 0.004553054750431329, Final Batch Loss: 0.0008260750910267234\n",
      "Epoch 2100, Loss: 0.010239466348139104, Final Batch Loss: 6.24493695795536e-05\n",
      "Epoch 2101, Loss: 0.003192663352820091, Final Batch Loss: 0.0018205847591161728\n",
      "Epoch 2102, Loss: 0.008640777479740791, Final Batch Loss: 6.353130447678268e-05\n",
      "Epoch 2103, Loss: 0.0015303929831134155, Final Batch Loss: 0.0001826630614232272\n",
      "Epoch 2104, Loss: 0.0033728071066434495, Final Batch Loss: 4.807636287296191e-05\n",
      "Epoch 2105, Loss: 0.02269860638807586, Final Batch Loss: 2.7822470656246878e-05\n",
      "Epoch 2106, Loss: 0.000922104726669204, Final Batch Loss: 1.3597081306215841e-05\n",
      "Epoch 2107, Loss: 0.0008284366194857284, Final Batch Loss: 6.819253030698746e-05\n",
      "Epoch 2108, Loss: 0.0018962943140650168, Final Batch Loss: 0.0008167613414116204\n",
      "Epoch 2109, Loss: 0.007891531093775939, Final Batch Loss: 2.639631588863267e-07\n",
      "Epoch 2110, Loss: 0.005276797237456776, Final Batch Loss: 0.0002008921146625653\n",
      "Epoch 2111, Loss: 0.0013747873069149819, Final Batch Loss: 1.1069430172483408e-07\n",
      "Epoch 2112, Loss: 0.006495678331702948, Final Batch Loss: 0.00028217234648764133\n",
      "Epoch 2113, Loss: 0.00741825802032281, Final Batch Loss: 6.4713384517745e-07\n",
      "Epoch 2114, Loss: 0.011042305382943596, Final Batch Loss: 1.3282244253787212e-05\n",
      "Epoch 2115, Loss: 0.0024867330175766256, Final Batch Loss: 0.0005286660161800683\n",
      "Epoch 2116, Loss: 0.0018206613188205267, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2117, Loss: 0.002983888943617785, Final Batch Loss: 6.224157459655544e-06\n",
      "Epoch 2118, Loss: 0.003481986146653071, Final Batch Loss: 3.6580964660970494e-05\n",
      "Epoch 2119, Loss: 0.004108324908884242, Final Batch Loss: 7.226847810670733e-05\n",
      "Epoch 2120, Loss: 0.0007532666122642695, Final Batch Loss: 1.4942364032322075e-05\n",
      "Epoch 2121, Loss: 0.0016572448283600494, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 2122, Loss: 0.002536494660034805, Final Batch Loss: 2.2479111976281274e-06\n",
      "Epoch 2123, Loss: 0.002251094604133641, Final Batch Loss: 1.3623909467241901e-07\n",
      "Epoch 2124, Loss: 0.0021893259513490193, Final Batch Loss: 6.2497242652170826e-06\n",
      "Epoch 2125, Loss: 0.004334683129854966, Final Batch Loss: 0.0003002535959240049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2126, Loss: 0.002797188935801387, Final Batch Loss: 0.0\n",
      "Epoch 2127, Loss: 0.0023661118939344306, Final Batch Loss: 0.0006150359404273331\n",
      "Epoch 2128, Loss: 0.0027935038015129976, Final Batch Loss: 0.0003471301752142608\n",
      "Epoch 2129, Loss: 0.0023281969138224667, Final Batch Loss: 0.0004985688719898462\n",
      "Epoch 2130, Loss: 0.022763450506317895, Final Batch Loss: 0.00010106914123753086\n",
      "Epoch 2131, Loss: 0.0017787051204187776, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2132, Loss: 0.0024676236280356534, Final Batch Loss: 0.0016437775921076536\n",
      "Epoch 2133, Loss: 0.0006667037378065288, Final Batch Loss: 6.671142909908667e-05\n",
      "Epoch 2134, Loss: 0.0028770393657993054, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 2135, Loss: 0.0019050206755970578, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 2136, Loss: 0.005466349651669589, Final Batch Loss: 8.344609341293108e-07\n",
      "Epoch 2137, Loss: 0.015486760086787399, Final Batch Loss: 5.5420743592549115e-05\n",
      "Epoch 2138, Loss: 0.0028190666530818476, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 2139, Loss: 0.0013118894416948024, Final Batch Loss: 5.832509032188682e-06\n",
      "Epoch 2140, Loss: 0.0009778503837196695, Final Batch Loss: 1.3964391882836935e-06\n",
      "Epoch 2141, Loss: 0.0018543707866882642, Final Batch Loss: 1.2772413526818127e-07\n",
      "Epoch 2142, Loss: 0.0018504588847889636, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 2143, Loss: 0.0014698153754579835, Final Batch Loss: 0.00017023287364281714\n",
      "Epoch 2144, Loss: 0.0005990040663164109, Final Batch Loss: 0.0\n",
      "Epoch 2145, Loss: 0.0011010658217855962, Final Batch Loss: 1.1885882486240007e-05\n",
      "Epoch 2146, Loss: 0.001147046723673384, Final Batch Loss: 3.831721926417231e-07\n",
      "Epoch 2147, Loss: 0.0009268062667615595, Final Batch Loss: 6.190110980242025e-06\n",
      "Epoch 2148, Loss: 0.01163063531566877, Final Batch Loss: 0.007598796393722296\n",
      "Epoch 2149, Loss: 0.018167369494676677, Final Batch Loss: 5.611150754702976e-06\n",
      "Epoch 2150, Loss: 0.001491695676499205, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 2151, Loss: 0.0012772482024274723, Final Batch Loss: 1.2516921970018302e-06\n",
      "Epoch 2152, Loss: 0.0005063767257524887, Final Batch Loss: 2.1318252038327046e-05\n",
      "Epoch 2153, Loss: 0.0020865475646587583, Final Batch Loss: 3.7465263176272856e-06\n",
      "Epoch 2154, Loss: 0.0016747356021369342, Final Batch Loss: 7.790753443259746e-06\n",
      "Epoch 2155, Loss: 0.01261508435709402, Final Batch Loss: 0.0\n",
      "Epoch 2156, Loss: 0.002157150655875739, Final Batch Loss: 5.449546733871102e-07\n",
      "Epoch 2157, Loss: 0.010676244099158794, Final Batch Loss: 0.002227859338745475\n",
      "Epoch 2158, Loss: 0.005613840393941416, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2159, Loss: 0.003810129730936751, Final Batch Loss: 4.061516392539488e-06\n",
      "Epoch 2160, Loss: 0.0011057056763092987, Final Batch Loss: 0.0\n",
      "Epoch 2161, Loss: 0.0024791352670945344, Final Batch Loss: 1.391207206324907e-05\n",
      "Epoch 2162, Loss: 0.0006003063554089749, Final Batch Loss: 0.0\n",
      "Epoch 2163, Loss: 0.05629828038425799, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2164, Loss: 0.0005433205878944136, Final Batch Loss: 0.00010634926002239808\n",
      "Epoch 2165, Loss: 0.00248211189682479, Final Batch Loss: 0.00016896055603865534\n",
      "Epoch 2166, Loss: 0.04104410865693353, Final Batch Loss: 0.03470752760767937\n",
      "Epoch 2167, Loss: 0.004574070432454391, Final Batch Loss: 2.6906734547083033e-06\n",
      "Epoch 2168, Loss: 0.050852057567681186, Final Batch Loss: 6.303800910245627e-05\n",
      "Epoch 2169, Loss: 0.004216930408802, Final Batch Loss: 2.137810406566132e-05\n",
      "Epoch 2170, Loss: 0.029980376462390268, Final Batch Loss: 1.7029879018082283e-07\n",
      "Epoch 2171, Loss: 0.004822709393920377, Final Batch Loss: 0.0\n",
      "Epoch 2172, Loss: 0.002635301593272743, Final Batch Loss: 4.461712251213612e-06\n",
      "Epoch 2173, Loss: 0.0017318769059784245, Final Batch Loss: 1.7224574548890814e-05\n",
      "Epoch 2174, Loss: 0.0020156904865871184, Final Batch Loss: 0.00010979681246681139\n",
      "Epoch 2175, Loss: 0.017595104773135972, Final Batch Loss: 1.1502897905302234e-05\n",
      "Epoch 2176, Loss: 0.0027468256370752897, Final Batch Loss: 5.108954042043479e-07\n",
      "Epoch 2177, Loss: 0.0013724068993710148, Final Batch Loss: 1.192091971802256e-07\n",
      "Epoch 2178, Loss: 0.00623898589037708, Final Batch Loss: 3.720364111359231e-05\n",
      "Epoch 2179, Loss: 0.01508780042786384, Final Batch Loss: 7.395304419333115e-05\n",
      "Epoch 2180, Loss: 0.001991751445789447, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2181, Loss: 0.002910491741658916, Final Batch Loss: 6.045597729098517e-07\n",
      "Epoch 2182, Loss: 0.006385655132817192, Final Batch Loss: 2.299020252394257e-06\n",
      "Epoch 2183, Loss: 0.0016784915256877753, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2184, Loss: 0.003018842754954676, Final Batch Loss: 2.903543190768687e-06\n",
      "Epoch 2185, Loss: 0.004297711100662127, Final Batch Loss: 0.0003529821406118572\n",
      "Epoch 2186, Loss: 0.025394704527570866, Final Batch Loss: 0.000817640800960362\n",
      "Epoch 2187, Loss: 0.0016599460498127883, Final Batch Loss: 2.4948378722911e-06\n",
      "Epoch 2188, Loss: 0.001826343336432501, Final Batch Loss: 4.1723134813764773e-07\n",
      "Epoch 2189, Loss: 0.0016564474790357053, Final Batch Loss: 0.00013963358651380986\n",
      "Epoch 2190, Loss: 0.0014598100005969172, Final Batch Loss: 1.8988121155416593e-06\n",
      "Epoch 2191, Loss: 0.0050726597028187825, Final Batch Loss: 9.834361662797164e-06\n",
      "Epoch 2192, Loss: 0.0128529753442308, Final Batch Loss: 7.5524462772591505e-06\n",
      "Epoch 2193, Loss: 0.00601562277006451, Final Batch Loss: 0.0008877384243533015\n",
      "Epoch 2194, Loss: 0.002281382112414576, Final Batch Loss: 0.0004044286033604294\n",
      "Epoch 2195, Loss: 0.004497563175391406, Final Batch Loss: 0.0019500720081850886\n",
      "Epoch 2196, Loss: 0.0009655317902570459, Final Batch Loss: 1.7029727814588114e-06\n",
      "Epoch 2197, Loss: 0.0010625984800327615, Final Batch Loss: 1.362390804615643e-07\n",
      "Epoch 2198, Loss: 0.016072092090325896, Final Batch Loss: 0.00017722298798616976\n",
      "Epoch 2199, Loss: 0.002149869855202269, Final Batch Loss: 0.0010381287429481745\n",
      "Epoch 2200, Loss: 0.0013953950769973744, Final Batch Loss: 5.108806817588629e-06\n",
      "Epoch 2201, Loss: 0.011149362519631723, Final Batch Loss: 1.2942660987391719e-06\n",
      "Epoch 2202, Loss: 0.0030331897219806336, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2203, Loss: 0.0015885597058513667, Final Batch Loss: 7.348044164245948e-06\n",
      "Epoch 2204, Loss: 0.0006875270319142146, Final Batch Loss: 1.5350842659245245e-05\n",
      "Epoch 2205, Loss: 0.0004704414864757922, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2206, Loss: 0.0027711171151167946, Final Batch Loss: 0.0025245703291147947\n",
      "Epoch 2207, Loss: 0.004674456009524874, Final Batch Loss: 0.00010755354014690965\n",
      "Epoch 2208, Loss: 0.011789212967983076, Final Batch Loss: 1.6178279338419088e-06\n",
      "Epoch 2209, Loss: 0.0017820122575358255, Final Batch Loss: 0.0009459269931539893\n",
      "Epoch 2210, Loss: 0.019035325836739503, Final Batch Loss: 0.0002709508698899299\n",
      "Epoch 2211, Loss: 0.0006002895043195622, Final Batch Loss: 1.8732865214587946e-07\n",
      "Epoch 2212, Loss: 0.08115292294314713, Final Batch Loss: 0.06221194192767143\n",
      "Epoch 2213, Loss: 0.0014702757474509554, Final Batch Loss: 1.9584363997182663e-07\n",
      "Epoch 2214, Loss: 0.009025002757994116, Final Batch Loss: 8.600046612627921e-07\n",
      "Epoch 2215, Loss: 0.0013112095221003983, Final Batch Loss: 1.825372237362899e-05\n",
      "Epoch 2216, Loss: 0.015783580344304937, Final Batch Loss: 6.403021416190313e-06\n",
      "Epoch 2217, Loss: 0.0012930023422086379, Final Batch Loss: 1.4942275811336003e-05\n",
      "Epoch 2218, Loss: 0.002867618568416219, Final Batch Loss: 0.001256264396943152\n",
      "Epoch 2219, Loss: 0.021856952364032622, Final Batch Loss: 3.8741032767575234e-05\n",
      "Epoch 2220, Loss: 0.01140709708124632, Final Batch Loss: 0.007893024943768978\n",
      "Epoch 2221, Loss: 0.013459808387892735, Final Batch Loss: 1.5241622577377711e-06\n",
      "Epoch 2222, Loss: 0.0035491839535097824, Final Batch Loss: 8.64215508045163e-06\n",
      "Epoch 2223, Loss: 0.00678620750841219, Final Batch Loss: 0.00016103549569379538\n",
      "Epoch 2224, Loss: 0.00598922269169222, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 2225, Loss: 0.04344484577547547, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 2226, Loss: 0.02683000502292998, Final Batch Loss: 0.011894394643604755\n",
      "Epoch 2227, Loss: 0.013603274415800115, Final Batch Loss: 4.1609073377912864e-05\n",
      "Epoch 2228, Loss: 0.008543440180801554, Final Batch Loss: 5.508750109584071e-05\n",
      "Epoch 2229, Loss: 0.002519810230296571, Final Batch Loss: 0.0001214551375596784\n",
      "Epoch 2230, Loss: 0.020178357604891062, Final Batch Loss: 0.0027313067112118006\n",
      "Epoch 2231, Loss: 0.009662207543442491, Final Batch Loss: 0.0\n",
      "Epoch 2232, Loss: 0.009014784961436817, Final Batch Loss: 1.2865369171777274e-05\n",
      "Epoch 2233, Loss: 0.003923486205167137, Final Batch Loss: 0.0008725085644982755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2234, Loss: 0.0027532734711428475, Final Batch Loss: 3.1505257425124e-07\n",
      "Epoch 2235, Loss: 0.02139632434239047, Final Batch Loss: 6.30103500043333e-07\n",
      "Epoch 2236, Loss: 0.0035995792428025197, Final Batch Loss: 6.641644745286612e-07\n",
      "Epoch 2237, Loss: 0.0013382596661131174, Final Batch Loss: 1.1665396186799626e-06\n",
      "Epoch 2238, Loss: 0.01996434583043083, Final Batch Loss: 2.0691200006695e-06\n",
      "Epoch 2239, Loss: 0.003963333983847406, Final Batch Loss: 6.640401261392981e-05\n",
      "Epoch 2240, Loss: 0.029757790505783532, Final Batch Loss: 3.23567320492657e-07\n",
      "Epoch 2241, Loss: 0.0062680176229150675, Final Batch Loss: 4.938660822517704e-07\n",
      "Epoch 2242, Loss: 0.0029665461656804837, Final Batch Loss: 5.364217486203415e-06\n",
      "Epoch 2243, Loss: 0.0024529152578800506, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 2244, Loss: 0.016673476053711056, Final Batch Loss: 3.9168148759927135e-06\n",
      "Epoch 2245, Loss: 0.003017354515122861, Final Batch Loss: 5.057815087639028e-06\n",
      "Epoch 2246, Loss: 0.0015820149037608644, Final Batch Loss: 0.0\n",
      "Epoch 2247, Loss: 0.0013447512610582635, Final Batch Loss: 0.00015164459182415158\n",
      "Epoch 2248, Loss: 0.01655464267025053, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2249, Loss: 0.03798847754660528, Final Batch Loss: 0.0006856395630165935\n",
      "Epoch 2250, Loss: 0.003397254137894379, Final Batch Loss: 1.0047580190075678e-06\n",
      "Epoch 2251, Loss: 0.025775617832543674, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 2252, Loss: 0.00358201295807703, Final Batch Loss: 2.1968246528558666e-06\n",
      "Epoch 2253, Loss: 0.01736246703148936, Final Batch Loss: 4.765660924022086e-05\n",
      "Epoch 2254, Loss: 0.0016471895651193336, Final Batch Loss: 3.139165346510708e-05\n",
      "Epoch 2255, Loss: 0.0034337004617555067, Final Batch Loss: 0.0003214279131498188\n",
      "Epoch 2256, Loss: 0.008513205524650402, Final Batch Loss: 8.603498281445354e-05\n",
      "Epoch 2257, Loss: 0.0009982986048271414, Final Batch Loss: 2.3089032765710726e-05\n",
      "Epoch 2258, Loss: 0.0010515215435589198, Final Batch Loss: 3.654589454527013e-05\n",
      "Epoch 2259, Loss: 0.01265984182828106, Final Batch Loss: 0.0\n",
      "Epoch 2260, Loss: 0.0076852300324876666, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 2261, Loss: 0.0018457011901773512, Final Batch Loss: 0.00016092686564661562\n",
      "Epoch 2262, Loss: 0.0030827298578515183, Final Batch Loss: 3.17804042424541e-05\n",
      "Epoch 2263, Loss: 0.01694295862080253, Final Batch Loss: 7.492763415939407e-06\n",
      "Epoch 2264, Loss: 0.012711839241092093, Final Batch Loss: 0.000411963410442695\n",
      "Epoch 2265, Loss: 0.0028503524627012666, Final Batch Loss: 2.051826231763698e-05\n",
      "Epoch 2266, Loss: 0.030484592163702473, Final Batch Loss: 5.253619747236371e-06\n",
      "Epoch 2267, Loss: 0.0026633801990101347, Final Batch Loss: 1.2516242350102402e-05\n",
      "Epoch 2268, Loss: 0.020955733142727695, Final Batch Loss: 1.302777491218876e-06\n",
      "Epoch 2269, Loss: 0.0017413148452760652, Final Batch Loss: 3.1030267564347014e-05\n",
      "Epoch 2270, Loss: 0.05098079487288487, Final Batch Loss: 3.1505260267294943e-07\n",
      "Epoch 2271, Loss: 0.004641168197849765, Final Batch Loss: 0.00013594460324384272\n",
      "Epoch 2272, Loss: 0.002253414215374505, Final Batch Loss: 3.385594391147606e-05\n",
      "Epoch 2273, Loss: 0.0037307229213183746, Final Batch Loss: 0.0\n",
      "Epoch 2274, Loss: 0.004158737225225195, Final Batch Loss: 2.5192628527292982e-05\n",
      "Epoch 2275, Loss: 0.04268458820297383, Final Batch Loss: 0.04213758185505867\n",
      "Epoch 2276, Loss: 0.00859350983614604, Final Batch Loss: 2.3330578642344335e-06\n",
      "Epoch 2277, Loss: 0.0016637402127344103, Final Batch Loss: 4.4277612687437795e-07\n",
      "Epoch 2278, Loss: 0.0032842605765548427, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2279, Loss: 0.07926120798219927, Final Batch Loss: 0.03889026492834091\n",
      "Epoch 2280, Loss: 0.00200027134204106, Final Batch Loss: 4.172318597284175e-07\n",
      "Epoch 2281, Loss: 0.4596958551555872, Final Batch Loss: 0.32049205899238586\n",
      "Epoch 2282, Loss: 0.03089710493804887, Final Batch Loss: 0.0\n",
      "Epoch 2283, Loss: 0.05139624154253397, Final Batch Loss: 0.0001356346911052242\n",
      "Epoch 2284, Loss: 0.06446342254093906, Final Batch Loss: 2.1906476831645705e-05\n",
      "Epoch 2285, Loss: 0.01936919565696371, Final Batch Loss: 7.109663329174509e-06\n",
      "Epoch 2286, Loss: 0.015212204831186682, Final Batch Loss: 0.00037962052738294005\n",
      "Epoch 2287, Loss: 0.017661369824054418, Final Batch Loss: 2.7083890017820522e-05\n",
      "Epoch 2288, Loss: 0.03016449650749564, Final Batch Loss: 0.0\n",
      "Epoch 2289, Loss: 0.015796527049587894, Final Batch Loss: 3.107926659140503e-06\n",
      "Epoch 2290, Loss: 0.0034309723414480686, Final Batch Loss: 0.000152483960846439\n",
      "Epoch 2291, Loss: 0.0063923275520210154, Final Batch Loss: 0.00012652238365262747\n",
      "Epoch 2292, Loss: 0.004676516927929697, Final Batch Loss: 1.7710879092192044e-06\n",
      "Epoch 2293, Loss: 0.026328874431783333, Final Batch Loss: 0.0\n",
      "Epoch 2294, Loss: 0.014890040911268443, Final Batch Loss: 0.0008358941995538771\n",
      "Epoch 2295, Loss: 0.030226660863263533, Final Batch Loss: 6.151691195555031e-05\n",
      "Epoch 2296, Loss: 0.00802050707534363, Final Batch Loss: 1.1306989108561538e-05\n",
      "Epoch 2297, Loss: 0.00584794589667581, Final Batch Loss: 0.0029088130686432123\n",
      "Epoch 2298, Loss: 0.008723246465109469, Final Batch Loss: 4.512915836585307e-07\n",
      "Epoch 2299, Loss: 0.0035084621435998997, Final Batch Loss: 4.921481831843266e-06\n",
      "Epoch 2300, Loss: 0.003283157795749503, Final Batch Loss: 1.6093074464151869e-06\n",
      "Epoch 2301, Loss: 0.0081504650588613, Final Batch Loss: 0.0012278776848688722\n",
      "Epoch 2302, Loss: 0.029179227147583475, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2303, Loss: 0.008386901889025467, Final Batch Loss: 4.11449909734074e-05\n",
      "Epoch 2304, Loss: 0.0035044399191974662, Final Batch Loss: 0.0001185899818665348\n",
      "Epoch 2305, Loss: 0.03335152279495901, Final Batch Loss: 2.895077102493815e-07\n",
      "Epoch 2306, Loss: 0.003936976630939171, Final Batch Loss: 0.0023201184812933207\n",
      "Epoch 2307, Loss: 0.016769681737059727, Final Batch Loss: 0.012208053842186928\n",
      "Epoch 2308, Loss: 0.0039770887711938485, Final Batch Loss: 1.3538707435145625e-06\n",
      "Epoch 2309, Loss: 0.008525224722689018, Final Batch Loss: 0.002952089998871088\n",
      "Epoch 2310, Loss: 0.003143533026559453, Final Batch Loss: 9.212827535520773e-06\n",
      "Epoch 2311, Loss: 0.002108733719069278, Final Batch Loss: 1.667947435635142e-05\n",
      "Epoch 2312, Loss: 0.003045464732167602, Final Batch Loss: 4.657556019083131e-06\n",
      "Epoch 2313, Loss: 0.0020482540185184916, Final Batch Loss: 2.2877260562381707e-05\n",
      "Epoch 2314, Loss: 0.002510649668693077, Final Batch Loss: 0.000263702793745324\n",
      "Epoch 2315, Loss: 0.0036976978417442297, Final Batch Loss: 8.250627615780104e-06\n",
      "Epoch 2316, Loss: 0.0206985163531499, Final Batch Loss: 0.00022676812659483403\n",
      "Epoch 2317, Loss: 0.006358150731344381, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 2318, Loss: 0.00958897187229013, Final Batch Loss: 3.938332520192489e-05\n",
      "Epoch 2319, Loss: 0.008862343759181712, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2320, Loss: 0.0045736668253084645, Final Batch Loss: 0.0001473586744396016\n",
      "Epoch 2321, Loss: 0.009179325280427975, Final Batch Loss: 1.532689282157662e-07\n",
      "Epoch 2322, Loss: 0.0022280205303104594, Final Batch Loss: 0.0002169045910704881\n",
      "Epoch 2323, Loss: 0.22187522394233383, Final Batch Loss: 0.22081030905246735\n",
      "Epoch 2324, Loss: 0.006031773194990819, Final Batch Loss: 4.170898682787083e-05\n",
      "Epoch 2325, Loss: 0.015269602812622907, Final Batch Loss: 4.538353095995262e-06\n",
      "Epoch 2326, Loss: 0.003439309867189877, Final Batch Loss: 2.2564258870261256e-06\n",
      "Epoch 2327, Loss: 0.005501796505996026, Final Batch Loss: 9.356923692394048e-05\n",
      "Epoch 2328, Loss: 0.004341672756581261, Final Batch Loss: 1.7881380642847944e-07\n",
      "Epoch 2329, Loss: 0.007020276533864944, Final Batch Loss: 8.514900287082128e-07\n",
      "Epoch 2330, Loss: 0.01010696790763177, Final Batch Loss: 0.005162524525076151\n",
      "Epoch 2331, Loss: 0.003910689505573828, Final Batch Loss: 3.361762355780229e-05\n",
      "Epoch 2332, Loss: 0.009819551480063637, Final Batch Loss: 1.13248086108797e-06\n",
      "Epoch 2333, Loss: 0.0023946030953396757, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 2334, Loss: 0.0028425425006446403, Final Batch Loss: 3.1505251740782114e-07\n",
      "Epoch 2335, Loss: 0.0012925178016303107, Final Batch Loss: 9.137076267506927e-05\n",
      "Epoch 2336, Loss: 0.002360681012078203, Final Batch Loss: 1.9498968413245166e-06\n",
      "Epoch 2337, Loss: 0.188174058610457, Final Batch Loss: 0.18612094223499298\n",
      "Epoch 2338, Loss: 0.00912261928897351, Final Batch Loss: 0.0034837163984775543\n",
      "Epoch 2339, Loss: 0.01649516841280274, Final Batch Loss: 0.00037850087392143905\n",
      "Epoch 2340, Loss: 0.007260087233060375, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 2341, Loss: 0.008296169702234124, Final Batch Loss: 1.7029888965680584e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2342, Loss: 0.01626507173932623, Final Batch Loss: 0.0008455949719063938\n",
      "Epoch 2343, Loss: 0.003940542178952455, Final Batch Loss: 3.950853624701267e-06\n",
      "Epoch 2344, Loss: 0.0028350795600999845, Final Batch Loss: 2.9960237952764146e-05\n",
      "Epoch 2345, Loss: 0.004106720181880519, Final Batch Loss: 0.0004065962857566774\n",
      "Epoch 2346, Loss: 0.005991858313791454, Final Batch Loss: 0.0005092488718219101\n",
      "Epoch 2347, Loss: 0.0034184112778969933, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2348, Loss: 0.003994482183770742, Final Batch Loss: 8.675085700815544e-05\n",
      "Epoch 2349, Loss: 0.0037034024571767077, Final Batch Loss: 9.503195906290784e-05\n",
      "Epoch 2350, Loss: 0.017719299743475858, Final Batch Loss: 1.467832043999806e-05\n",
      "Epoch 2351, Loss: 0.006100992006821571, Final Batch Loss: 2.5544838422320026e-07\n",
      "Epoch 2352, Loss: 0.004063479397188985, Final Batch Loss: 7.15254316219216e-07\n",
      "Epoch 2353, Loss: 0.006625997732044198, Final Batch Loss: 0.0013651890913024545\n",
      "Epoch 2354, Loss: 0.005015565977373626, Final Batch Loss: 0.0005720317712984979\n",
      "Epoch 2355, Loss: 0.010376972705842036, Final Batch Loss: 7.578266263408295e-07\n",
      "Epoch 2356, Loss: 0.0026793326978804544, Final Batch Loss: 6.802515417803079e-05\n",
      "Epoch 2357, Loss: 0.004890344326668128, Final Batch Loss: 1.3282088730193209e-05\n",
      "Epoch 2358, Loss: 0.0024553881303290837, Final Batch Loss: 5.79845072934404e-06\n",
      "Epoch 2359, Loss: 0.011614989602094283, Final Batch Loss: 8.344613888766617e-07\n",
      "Epoch 2360, Loss: 0.008441326972388197, Final Batch Loss: 6.904346082592383e-05\n",
      "Epoch 2361, Loss: 0.0020949906295300025, Final Batch Loss: 3.7550028082478093e-06\n",
      "Epoch 2362, Loss: 0.011850730900562212, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 2363, Loss: 0.01583040613331832, Final Batch Loss: 0.013608844950795174\n",
      "Epoch 2364, Loss: 0.005164500376849901, Final Batch Loss: 0.00017800202476792037\n",
      "Epoch 2365, Loss: 0.002060095719222943, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2366, Loss: 0.0021593326673610136, Final Batch Loss: 0.0004753179964609444\n",
      "Epoch 2367, Loss: 0.00225001741529951, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 2368, Loss: 0.002009620636336251, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 2369, Loss: 0.002011306770327792, Final Batch Loss: 7.61214778322028e-06\n",
      "Epoch 2370, Loss: 0.002995865768752992, Final Batch Loss: 0.0\n",
      "Epoch 2371, Loss: 0.006343195796944201, Final Batch Loss: 0.0003141873166896403\n",
      "Epoch 2372, Loss: 0.0015927597451081965, Final Batch Loss: 3.396657484699972e-05\n",
      "Epoch 2373, Loss: 0.0035499337545843446, Final Batch Loss: 6.9734096541651525e-06\n",
      "Epoch 2374, Loss: 0.009851961920503527, Final Batch Loss: 0.006892519537359476\n",
      "Epoch 2375, Loss: 0.0035657135922519956, Final Batch Loss: 6.590442353626713e-06\n",
      "Epoch 2376, Loss: 0.02572190067030533, Final Batch Loss: 7.492762506444706e-06\n",
      "Epoch 2377, Loss: 0.004749587770902508, Final Batch Loss: 2.2990036541159498e-06\n",
      "Epoch 2378, Loss: 0.0017382468099640391, Final Batch Loss: 4.64056529381196e-06\n",
      "Epoch 2379, Loss: 0.0020918440476975775, Final Batch Loss: 8.42976021431241e-07\n",
      "Epoch 2380, Loss: 0.013052115391474217, Final Batch Loss: 0.00017330472473986447\n",
      "Epoch 2381, Loss: 0.010965463920456386, Final Batch Loss: 2.264944214402931e-06\n",
      "Epoch 2382, Loss: 0.007639716612175107, Final Batch Loss: 0.0006418857956305146\n",
      "Epoch 2383, Loss: 0.0013722898002015427, Final Batch Loss: 0.00046270311577245593\n",
      "Epoch 2384, Loss: 0.003946709737647325, Final Batch Loss: 0.0\n",
      "Epoch 2385, Loss: 0.009337372946902178, Final Batch Loss: 0.00010390166426077485\n",
      "Epoch 2386, Loss: 0.005872950132470578, Final Batch Loss: 0.0038351286202669144\n",
      "Epoch 2387, Loss: 0.0016352340398952947, Final Batch Loss: 1.1188204553036485e-05\n",
      "Epoch 2388, Loss: 0.002147089466916441, Final Batch Loss: 3.772026275328244e-06\n",
      "Epoch 2389, Loss: 0.008059911637246842, Final Batch Loss: 1.5572211850667372e-05\n",
      "Epoch 2390, Loss: 0.001934500151296703, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2391, Loss: 0.003371207107193186, Final Batch Loss: 2.2664198695565574e-05\n",
      "Epoch 2392, Loss: 0.005250406596985613, Final Batch Loss: 1.1920923270736239e-07\n",
      "Epoch 2393, Loss: 0.009618238836765158, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 2394, Loss: 0.017747662737747305, Final Batch Loss: 9.834091542870738e-06\n",
      "Epoch 2395, Loss: 0.002094639254210051, Final Batch Loss: 5.390711157815531e-05\n",
      "Epoch 2396, Loss: 0.10426392746740021, Final Batch Loss: 0.09304241091012955\n",
      "Epoch 2397, Loss: 0.0037394243190647103, Final Batch Loss: 5.356208930606954e-05\n",
      "Epoch 2398, Loss: 0.07223053464986151, Final Batch Loss: 7.809462113073096e-05\n",
      "Epoch 2399, Loss: 0.06837304766304442, Final Batch Loss: 4.1013732698047534e-05\n",
      "Epoch 2400, Loss: 0.07786875579313346, Final Batch Loss: 9.868180313787889e-06\n",
      "Epoch 2401, Loss: 0.03769197789370082, Final Batch Loss: 0.00035599860711954534\n",
      "Epoch 2402, Loss: 0.015374321422314097, Final Batch Loss: 3.925340024579782e-06\n",
      "Epoch 2403, Loss: 0.012252507964149117, Final Batch Loss: 3.210350405424833e-05\n",
      "Epoch 2404, Loss: 0.006678562902379781, Final Batch Loss: 0.0011385848047211766\n",
      "Epoch 2405, Loss: 0.004500659252755668, Final Batch Loss: 2.8950768182767206e-07\n",
      "Epoch 2406, Loss: 0.002913622563937679, Final Batch Loss: 0.00039595685666427016\n",
      "Epoch 2407, Loss: 0.015932509648337145, Final Batch Loss: 2.9035745683358982e-06\n",
      "Epoch 2408, Loss: 0.0029541875410359353, Final Batch Loss: 0.0001452665019314736\n",
      "Epoch 2409, Loss: 0.0017243815473193536, Final Batch Loss: 2.687173582671676e-05\n",
      "Epoch 2410, Loss: 0.004080969069036655, Final Batch Loss: 0.0005255418946035206\n",
      "Epoch 2411, Loss: 0.002695436283829622, Final Batch Loss: 0.0006923337350599468\n",
      "Epoch 2412, Loss: 0.004724674763565417, Final Batch Loss: 3.692018071888015e-05\n",
      "Epoch 2413, Loss: 0.005143704730549814, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 2414, Loss: 0.0022412305406760424, Final Batch Loss: 0.00016518319898750633\n",
      "Epoch 2415, Loss: 0.002617153812906281, Final Batch Loss: 2.7247821776654746e-07\n",
      "Epoch 2416, Loss: 0.0027875833766302094, Final Batch Loss: 0.0008031633915379643\n",
      "Epoch 2417, Loss: 0.0030527244962286204, Final Batch Loss: 0.00039152460522018373\n",
      "Epoch 2418, Loss: 0.009656961919972673, Final Batch Loss: 0.0\n",
      "Epoch 2419, Loss: 0.006325915805064142, Final Batch Loss: 0.002679207129403949\n",
      "Epoch 2420, Loss: 0.00287514494266361, Final Batch Loss: 0.0006653928430750966\n",
      "Epoch 2421, Loss: 0.003199652783223428, Final Batch Loss: 1.3103926903568208e-05\n",
      "Epoch 2422, Loss: 0.0021837718501203085, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2423, Loss: 0.025452390575082973, Final Batch Loss: 0.0001418969768565148\n",
      "Epoch 2424, Loss: 0.0018694558384595439, Final Batch Loss: 0.00011462486872915179\n",
      "Epoch 2425, Loss: 0.0031883238840038075, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 2426, Loss: 0.0016355089319404215, Final Batch Loss: 4.0108803659677505e-05\n",
      "Epoch 2427, Loss: 0.008353050419827923, Final Batch Loss: 0.00015676720067858696\n",
      "Epoch 2428, Loss: 0.004727306828044675, Final Batch Loss: 7.467280283890432e-06\n",
      "Epoch 2429, Loss: 0.027072849712542535, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 2430, Loss: 0.0010132449388038367, Final Batch Loss: 0.00019444643112365156\n",
      "Epoch 2431, Loss: 0.0039929268262071105, Final Batch Loss: 6.81195828633463e-08\n",
      "Epoch 2432, Loss: 0.006355492516636474, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2433, Loss: 0.0013890123032069823, Final Batch Loss: 6.130629571998725e-06\n",
      "Epoch 2434, Loss: 0.025179960124635414, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 2435, Loss: 0.0037835823804925894, Final Batch Loss: 1.0591864338493906e-05\n",
      "Epoch 2436, Loss: 0.0024029065389186144, Final Batch Loss: 1.1502823326736689e-05\n",
      "Epoch 2437, Loss: 0.0029702443862333894, Final Batch Loss: 5.75720114284195e-05\n",
      "Epoch 2438, Loss: 0.006980463236686774, Final Batch Loss: 0.00041943107498809695\n",
      "Epoch 2439, Loss: 0.0018078637331200298, Final Batch Loss: 0.00010805810597958043\n",
      "Epoch 2440, Loss: 0.0020235209813108668, Final Batch Loss: 8.250545943155885e-05\n",
      "Epoch 2441, Loss: 0.002760481446784979, Final Batch Loss: 2.1287360141286626e-07\n",
      "Epoch 2442, Loss: 0.0040402449030807475, Final Batch Loss: 2.5380804800079204e-05\n",
      "Epoch 2443, Loss: 0.00920920374301204, Final Batch Loss: 2.5080638806684874e-05\n",
      "Epoch 2444, Loss: 0.0042847790973610245, Final Batch Loss: 0.00034537952160462737\n",
      "Epoch 2445, Loss: 0.001296279104280984, Final Batch Loss: 1.853584763011895e-05\n",
      "Epoch 2446, Loss: 0.0013212291523814201, Final Batch Loss: 0.0003177428152412176\n",
      "Epoch 2447, Loss: 0.0026492420908539316, Final Batch Loss: 5.279250103740196e-07\n",
      "Epoch 2448, Loss: 0.0021352348221626016, Final Batch Loss: 4.002022251370363e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2449, Loss: 0.0025712191709317267, Final Batch Loss: 0.0\n",
      "Epoch 2450, Loss: 0.0017220241832092142, Final Batch Loss: 3.508100007820758e-06\n",
      "Epoch 2451, Loss: 0.005879805063543131, Final Batch Loss: 1.3623905203985487e-07\n",
      "Epoch 2452, Loss: 0.004769186855099861, Final Batch Loss: 1.2772417790074542e-07\n",
      "Epoch 2453, Loss: 0.0017859562358353287, Final Batch Loss: 0.0005036179791204631\n",
      "Epoch 2454, Loss: 0.0011949960517085856, Final Batch Loss: 3.0240966225392185e-05\n",
      "Epoch 2455, Loss: 0.004421018064022064, Final Batch Loss: 0.0009944797493517399\n",
      "Epoch 2456, Loss: 0.002266958232212346, Final Batch Loss: 8.348843402927741e-05\n",
      "Epoch 2457, Loss: 0.0022227325389394537, Final Batch Loss: 0.0001263777376152575\n",
      "Epoch 2458, Loss: 0.0005257651464489754, Final Batch Loss: 4.5490167394746095e-05\n",
      "Epoch 2459, Loss: 0.001152388098944357, Final Batch Loss: 5.1769043238891754e-06\n",
      "Epoch 2460, Loss: 0.0039024878569762222, Final Batch Loss: 0.0001477647601859644\n",
      "Epoch 2461, Loss: 0.0017596274347511098, Final Batch Loss: 6.726777996846067e-07\n",
      "Epoch 2462, Loss: 0.03071223986808036, Final Batch Loss: 2.493593274266459e-05\n",
      "Epoch 2463, Loss: 0.0017554640329677795, Final Batch Loss: 1.9584366839353606e-07\n",
      "Epoch 2464, Loss: 0.02757980346950717, Final Batch Loss: 4.8704373512009624e-06\n",
      "Epoch 2465, Loss: 0.012094612626242451, Final Batch Loss: 0.00010919339547399431\n",
      "Epoch 2466, Loss: 0.007629369109054096, Final Batch Loss: 0.0001420998014509678\n",
      "Epoch 2467, Loss: 0.00860805532647646, Final Batch Loss: 5.567543121287599e-05\n",
      "Epoch 2468, Loss: 0.0035408994226600043, Final Batch Loss: 5.130119825480506e-05\n",
      "Epoch 2469, Loss: 0.0017828979617320329, Final Batch Loss: 5.449547302305291e-07\n",
      "Epoch 2470, Loss: 0.0019582815657486208, Final Batch Loss: 4.16526454500854e-05\n",
      "Epoch 2471, Loss: 0.0011647157016057008, Final Batch Loss: 2.1287357299115683e-07\n",
      "Epoch 2472, Loss: 0.0033835192275546433, Final Batch Loss: 2.1798091438540723e-06\n",
      "Epoch 2473, Loss: 0.004943753774568904, Final Batch Loss: 0.00015283301763702184\n",
      "Epoch 2474, Loss: 0.0028363860910758376, Final Batch Loss: 0.001183250336907804\n",
      "Epoch 2475, Loss: 0.0023131385969463736, Final Batch Loss: 0.0\n",
      "Epoch 2476, Loss: 0.003956997061322909, Final Batch Loss: 0.003054967848584056\n",
      "Epoch 2477, Loss: 0.0016671590615260357, Final Batch Loss: 3.86568854082725e-06\n",
      "Epoch 2478, Loss: 0.0007382772522888104, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 2479, Loss: 0.007973944880859563, Final Batch Loss: 3.252636588513269e-06\n",
      "Epoch 2480, Loss: 0.0011430734302848577, Final Batch Loss: 6.340310937957838e-05\n",
      "Epoch 2481, Loss: 0.0018236039322800934, Final Batch Loss: 0.0\n",
      "Epoch 2482, Loss: 0.012604991443367908, Final Batch Loss: 3.420660868869163e-05\n",
      "Epoch 2483, Loss: 0.009837200019042314, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 2484, Loss: 0.1727960811695084, Final Batch Loss: 0.1489185243844986\n",
      "Epoch 2485, Loss: 0.004157098442234997, Final Batch Loss: 2.2138833344342856e-07\n",
      "Epoch 2486, Loss: 0.1491383421816863, Final Batch Loss: 0.11703724414110184\n",
      "Epoch 2487, Loss: 0.016972714220173657, Final Batch Loss: 0.0008243267657235265\n",
      "Epoch 2488, Loss: 0.011704323720550747, Final Batch Loss: 2.33307400776539e-06\n",
      "Epoch 2489, Loss: 0.006643123522508176, Final Batch Loss: 3.244121899115271e-06\n",
      "Epoch 2490, Loss: 0.03239189111627638, Final Batch Loss: 0.01274182926863432\n",
      "Epoch 2491, Loss: 0.011244315188378096, Final Batch Loss: 0.0008085080189630389\n",
      "Epoch 2492, Loss: 0.0029190461999437645, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 2493, Loss: 0.012720426835585386, Final Batch Loss: 0.0004802600888069719\n",
      "Epoch 2494, Loss: 0.0058565758663462475, Final Batch Loss: 0.00016852914995979518\n",
      "Epoch 2495, Loss: 0.007978108299887765, Final Batch Loss: 1.0217934942602369e-07\n",
      "Epoch 2496, Loss: 0.005303779691075761, Final Batch Loss: 2.5799831746553537e-06\n",
      "Epoch 2497, Loss: 0.004460065974843275, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 2498, Loss: 0.007585404731699441, Final Batch Loss: 1.1920919007479824e-07\n",
      "Epoch 2499, Loss: 0.006843861277218366, Final Batch Loss: 6.215897769834555e-07\n",
      "Epoch 2500, Loss: 0.0022403746884265274, Final Batch Loss: 5.117316050018417e-06\n",
      "Epoch 2501, Loss: 0.004111491835374181, Final Batch Loss: 6.045382633601548e-06\n",
      "Epoch 2502, Loss: 0.026608155312715098, Final Batch Loss: 4.5983120799064636e-05\n",
      "Epoch 2503, Loss: 0.0031578210182487965, Final Batch Loss: 0.001554440357722342\n",
      "Epoch 2504, Loss: 0.0026646197014770223, Final Batch Loss: 8.600048886364675e-07\n",
      "Epoch 2505, Loss: 0.020925615232304295, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2506, Loss: 0.0033685881548990437, Final Batch Loss: 5.023807716497686e-07\n",
      "Epoch 2507, Loss: 0.002983367253477809, Final Batch Loss: 9.451551932215807e-07\n",
      "Epoch 2508, Loss: 0.0075378531400929205, Final Batch Loss: 7.775890844641253e-05\n",
      "Epoch 2509, Loss: 0.017705909122014418, Final Batch Loss: 0.003378642490133643\n",
      "Epoch 2510, Loss: 0.014051816513529047, Final Batch Loss: 9.9868921097368e-05\n",
      "Epoch 2511, Loss: 0.010273763038640027, Final Batch Loss: 1.635559783608187e-05\n",
      "Epoch 2512, Loss: 0.03913450323005918, Final Batch Loss: 5.279259198687214e-07\n",
      "Epoch 2513, Loss: 0.0019776770353701068, Final Batch Loss: 7.918864639577805e-07\n",
      "Epoch 2514, Loss: 0.006039271878428565, Final Batch Loss: 1.1069426619769729e-07\n",
      "Epoch 2515, Loss: 0.0031641144432796864, Final Batch Loss: 2.1096928321640007e-05\n",
      "Epoch 2516, Loss: 0.0022767963964724913, Final Batch Loss: 0.00019735029491130263\n",
      "Epoch 2517, Loss: 0.005003809666277448, Final Batch Loss: 1.6263395536952885e-06\n",
      "Epoch 2518, Loss: 0.003969486602997563, Final Batch Loss: 1.9584358312840777e-07\n",
      "Epoch 2519, Loss: 0.0029899375658715144, Final Batch Loss: 0.0\n",
      "Epoch 2520, Loss: 0.0035182201536372304, Final Batch Loss: 0.0\n",
      "Epoch 2521, Loss: 0.003318017321817024, Final Batch Loss: 5.790157047158573e-07\n",
      "Epoch 2522, Loss: 0.0020222910625307122, Final Batch Loss: 1.8347573131904937e-05\n",
      "Epoch 2523, Loss: 0.002537602120128213, Final Batch Loss: 1.9839696960843867e-06\n",
      "Epoch 2524, Loss: 0.01834201902966015, Final Batch Loss: 0.0\n",
      "Epoch 2525, Loss: 0.0022232615889379304, Final Batch Loss: 7.407967359540635e-07\n",
      "Epoch 2526, Loss: 0.003783211398513231, Final Batch Loss: 1.3469379155139904e-05\n",
      "Epoch 2527, Loss: 0.0043754673288276535, Final Batch Loss: 1.130749751609983e-05\n",
      "Epoch 2528, Loss: 0.002483094169292599, Final Batch Loss: 0.0\n",
      "Epoch 2529, Loss: 0.0017536109796765231, Final Batch Loss: 1.617822590560536e-06\n",
      "Epoch 2530, Loss: 0.0023605196711287135, Final Batch Loss: 8.872035323292948e-06\n",
      "Epoch 2531, Loss: 0.002814850203151309, Final Batch Loss: 6.04560057126946e-07\n",
      "Epoch 2532, Loss: 0.0012048028729623184, Final Batch Loss: 3.633584128692746e-05\n",
      "Epoch 2533, Loss: 0.004751850428874604, Final Batch Loss: 0.00113960902672261\n",
      "Epoch 2534, Loss: 0.005254981548695525, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 2535, Loss: 0.03251151218910309, Final Batch Loss: 2.16277157960576e-06\n",
      "Epoch 2536, Loss: 0.010659325321739743, Final Batch Loss: 2.8183926588098984e-06\n",
      "Epoch 2537, Loss: 0.009447314990552513, Final Batch Loss: 7.663433052584878e-07\n",
      "Epoch 2538, Loss: 0.0475927896037831, Final Batch Loss: 2.980229112381494e-07\n",
      "Epoch 2539, Loss: 0.004704743914771825, Final Batch Loss: 0.0\n",
      "Epoch 2540, Loss: 0.002184495115898244, Final Batch Loss: 2.179808461733046e-06\n",
      "Epoch 2541, Loss: 0.0022670428861601977, Final Batch Loss: 9.961809155356605e-06\n",
      "Epoch 2542, Loss: 0.02913278823160681, Final Batch Loss: 1.2772414947903599e-07\n",
      "Epoch 2543, Loss: 0.0037923412455711514, Final Batch Loss: 0.0\n",
      "Epoch 2544, Loss: 0.013308996480191126, Final Batch Loss: 0.00017249197117052972\n",
      "Epoch 2545, Loss: 0.003069551302360196, Final Batch Loss: 1.1902932783414144e-05\n",
      "Epoch 2546, Loss: 0.007455416474840604, Final Batch Loss: 6.138345634099096e-05\n",
      "Epoch 2547, Loss: 0.020023346231027972, Final Batch Loss: 0.0\n",
      "Epoch 2548, Loss: 0.0027631282282527536, Final Batch Loss: 4.7710404032841325e-05\n",
      "Epoch 2549, Loss: 0.0022398835330932343, Final Batch Loss: 4.7937551244103815e-06\n",
      "Epoch 2550, Loss: 0.0015250392829102566, Final Batch Loss: 1.9584365418268135e-07\n",
      "Epoch 2551, Loss: 0.004920082140415616, Final Batch Loss: 5.032200533605646e-06\n",
      "Epoch 2552, Loss: 0.0042755871363624465, Final Batch Loss: 5.855883864569478e-05\n",
      "Epoch 2553, Loss: 0.007362580706512745, Final Batch Loss: 2.639594868014683e-06\n",
      "Epoch 2554, Loss: 0.004619289559585127, Final Batch Loss: 8.514946614468499e-08\n",
      "Epoch 2555, Loss: 0.003039738860024954, Final Batch Loss: 2.213868356193416e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2556, Loss: 0.039424479291483294, Final Batch Loss: 0.00030130374943837523\n",
      "Epoch 2557, Loss: 0.0019961697316830396, Final Batch Loss: 6.053879587852862e-06\n",
      "Epoch 2558, Loss: 0.0019512965227477252, Final Batch Loss: 1.4235731214284897e-05\n",
      "Epoch 2559, Loss: 0.008456285606371239, Final Batch Loss: 0.003032400505617261\n",
      "Epoch 2560, Loss: 0.013118809438310564, Final Batch Loss: 0.0\n",
      "Epoch 2561, Loss: 0.0036619006423279643, Final Batch Loss: 2.8283800929784775e-05\n",
      "Epoch 2562, Loss: 0.027928417019211338, Final Batch Loss: 0.025977661833167076\n",
      "Epoch 2563, Loss: 0.033348260243656114, Final Batch Loss: 0.026728570461273193\n",
      "Epoch 2564, Loss: 0.00313929178082617, Final Batch Loss: 6.662225496256724e-05\n",
      "Epoch 2565, Loss: 0.0020688242439064197, Final Batch Loss: 8.655824785819277e-05\n",
      "Epoch 2566, Loss: 0.0022435981081798673, Final Batch Loss: 0.0006884366157464683\n",
      "Epoch 2567, Loss: 0.004928248410578817, Final Batch Loss: 0.0003059919108636677\n",
      "Epoch 2568, Loss: 0.004304972666382412, Final Batch Loss: 1.1920923981278975e-07\n",
      "Epoch 2569, Loss: 0.03530810943175311, Final Batch Loss: 8.497455382894259e-06\n",
      "Epoch 2570, Loss: 0.0023551097638119245, Final Batch Loss: 2.0399000277393498e-05\n",
      "Epoch 2571, Loss: 0.01845360259494555, Final Batch Loss: 5.134329967404483e-06\n",
      "Epoch 2572, Loss: 0.02096576616168022, Final Batch Loss: 0.0\n",
      "Epoch 2573, Loss: 0.0020655302942031994, Final Batch Loss: 0.00024475945974700153\n",
      "Epoch 2574, Loss: 0.029275214817971573, Final Batch Loss: 1.2950064046890475e-05\n",
      "Epoch 2575, Loss: 0.003303140244042879, Final Batch Loss: 7.01622275300906e-06\n",
      "Epoch 2576, Loss: 0.005222609514021315, Final Batch Loss: 0.002175698522478342\n",
      "Epoch 2577, Loss: 0.002468197031703312, Final Batch Loss: 0.0007165541173890233\n",
      "Epoch 2578, Loss: 0.0027814398345071822, Final Batch Loss: 0.0\n",
      "Epoch 2579, Loss: 0.007012026462973608, Final Batch Loss: 2.6396293151265127e-07\n",
      "Epoch 2580, Loss: 0.001525685755638051, Final Batch Loss: 3.320825783248438e-07\n",
      "Epoch 2581, Loss: 0.030343818536493927, Final Batch Loss: 0.028646742925047874\n",
      "Epoch 2582, Loss: 0.0017767736499081366, Final Batch Loss: 6.668585410807282e-05\n",
      "Epoch 2583, Loss: 0.015029656002297997, Final Batch Loss: 1.9198632799088955e-05\n",
      "Epoch 2584, Loss: 0.018148631206713617, Final Batch Loss: 0.00114695995580405\n",
      "Epoch 2585, Loss: 0.07847151883106562, Final Batch Loss: 0.023636674508452415\n",
      "Epoch 2586, Loss: 0.006364742868754547, Final Batch Loss: 4.633333446690813e-05\n",
      "Epoch 2587, Loss: 0.0038524094416061416, Final Batch Loss: 0.0014505262952297926\n",
      "Epoch 2588, Loss: 0.02517269505187869, Final Batch Loss: 0.0\n",
      "Epoch 2589, Loss: 0.0034514336730353534, Final Batch Loss: 0.0\n",
      "Epoch 2590, Loss: 0.0012090148046581817, Final Batch Loss: 1.0132752095159958e-06\n",
      "Epoch 2591, Loss: 0.02314848787682422, Final Batch Loss: 2.992392001033295e-05\n",
      "Epoch 2592, Loss: 0.0015961795534167322, Final Batch Loss: 3.891250344167929e-06\n",
      "Epoch 2593, Loss: 0.001309703780862037, Final Batch Loss: 4.894233279628679e-05\n",
      "Epoch 2594, Loss: 0.0017266389440919738, Final Batch Loss: 1.625325057830196e-05\n",
      "Epoch 2595, Loss: 0.001670165818723035, Final Batch Loss: 1.5214596714940853e-05\n",
      "Epoch 2596, Loss: 0.0039694728766335174, Final Batch Loss: 8.019321830943227e-05\n",
      "Epoch 2597, Loss: 0.00792422921222169, Final Batch Loss: 0.0017991364002227783\n",
      "Epoch 2598, Loss: 0.018318347487365827, Final Batch Loss: 0.0006104620988480747\n",
      "Epoch 2599, Loss: 0.003827724343864247, Final Batch Loss: 0.0016810026718303561\n",
      "Epoch 2600, Loss: 0.005940659385053948, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 2601, Loss: 0.0012840600620620535, Final Batch Loss: 1.3137506357452367e-05\n",
      "Epoch 2602, Loss: 0.0006724963423039299, Final Batch Loss: 0.0\n",
      "Epoch 2603, Loss: 0.013435969674901571, Final Batch Loss: 0.0006734170019626617\n",
      "Epoch 2604, Loss: 0.008811176856397651, Final Batch Loss: 8.707190863788128e-05\n",
      "Epoch 2605, Loss: 0.010043079981329583, Final Batch Loss: 4.598061025262723e-07\n",
      "Epoch 2606, Loss: 0.0020283302774259937, Final Batch Loss: 4.734250069304835e-06\n",
      "Epoch 2607, Loss: 0.013952018081909046, Final Batch Loss: 8.186687773559242e-05\n",
      "Epoch 2608, Loss: 0.0107642271759687, Final Batch Loss: 0.00011254702985752374\n",
      "Epoch 2609, Loss: 0.005583785734415869, Final Batch Loss: 2.0552173737087287e-05\n",
      "Epoch 2610, Loss: 0.023512778017902747, Final Batch Loss: 0.0009830583585426211\n",
      "Epoch 2611, Loss: 0.0017985094911523447, Final Batch Loss: 7.237687782435387e-07\n",
      "Epoch 2612, Loss: 0.014468948527792236, Final Batch Loss: 4.5745026000076905e-05\n",
      "Epoch 2613, Loss: 0.0049056516145356, Final Batch Loss: 0.0005590119399130344\n",
      "Epoch 2614, Loss: 0.000874655629559129, Final Batch Loss: 8.352867553185206e-06\n",
      "Epoch 2615, Loss: 0.0012307210199651308, Final Batch Loss: 0.00029244369943626225\n",
      "Epoch 2616, Loss: 0.002337981541359113, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 2617, Loss: 0.0036648715613409877, Final Batch Loss: 0.0\n",
      "Epoch 2618, Loss: 0.001695873141994042, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 2619, Loss: 0.001989526526813279, Final Batch Loss: 2.0776333258254454e-06\n",
      "Epoch 2620, Loss: 0.0026912393914244603, Final Batch Loss: 0.00013205598224885762\n",
      "Epoch 2621, Loss: 0.005802152372780256, Final Batch Loss: 0.0013946319231763482\n",
      "Epoch 2622, Loss: 0.0006989065550442319, Final Batch Loss: 8.821021765470505e-06\n",
      "Epoch 2623, Loss: 0.002325081753951963, Final Batch Loss: 4.9889211368281394e-05\n",
      "Epoch 2624, Loss: 0.00511939034588238, Final Batch Loss: 1.3623905203985487e-07\n",
      "Epoch 2625, Loss: 0.004470539758585801, Final Batch Loss: 9.36583001021063e-06\n",
      "Epoch 2626, Loss: 0.0036820951791014522, Final Batch Loss: 2.5541841750964522e-05\n",
      "Epoch 2627, Loss: 0.0009728910970352445, Final Batch Loss: 1.9669403172883904e-06\n",
      "Epoch 2628, Loss: 0.004982521570752851, Final Batch Loss: 7.407967927974823e-07\n",
      "Epoch 2629, Loss: 0.0016219434110098518, Final Batch Loss: 0.0004973371396772563\n",
      "Epoch 2630, Loss: 0.004701751400716603, Final Batch Loss: 0.0010609416058287024\n",
      "Epoch 2631, Loss: 0.002937677332997879, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2632, Loss: 0.01113524285859313, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 2633, Loss: 0.01390175170593011, Final Batch Loss: 5.704997647626442e-07\n",
      "Epoch 2634, Loss: 0.00553717187563052, Final Batch Loss: 2.358601932428428e-06\n",
      "Epoch 2635, Loss: 0.0024305769547936507, Final Batch Loss: 0.00012978028098586947\n",
      "Epoch 2636, Loss: 0.004031299801567911, Final Batch Loss: 1.387927909490827e-06\n",
      "Epoch 2637, Loss: 0.006402866955269815, Final Batch Loss: 1.3623905203985487e-07\n",
      "Epoch 2638, Loss: 0.0024742692103245645, Final Batch Loss: 1.1511284355947282e-05\n",
      "Epoch 2639, Loss: 0.005776733215498098, Final Batch Loss: 1.4635727893619332e-05\n",
      "Epoch 2640, Loss: 0.006192147788510738, Final Batch Loss: 6.556496146004065e-07\n",
      "Epoch 2641, Loss: 0.002223204928395006, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 2642, Loss: 0.000648184257443063, Final Batch Loss: 0.00017148219922091812\n",
      "Epoch 2643, Loss: 0.0014217586379210445, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2644, Loss: 0.0014944691065466031, Final Batch Loss: 0.0007357698632404208\n",
      "Epoch 2645, Loss: 0.0012587659584823996, Final Batch Loss: 0.00048424460692331195\n",
      "Epoch 2646, Loss: 0.0031063932001416106, Final Batch Loss: 2.179496004828252e-05\n",
      "Epoch 2647, Loss: 0.0012664038900140895, Final Batch Loss: 2.0435848568922665e-07\n",
      "Epoch 2648, Loss: 0.0028457905614232004, Final Batch Loss: 7.390594419121044e-06\n",
      "Epoch 2649, Loss: 0.0014943000642233528, Final Batch Loss: 3.545606887200847e-05\n",
      "Epoch 2650, Loss: 0.011103603304945864, Final Batch Loss: 0.0006253216415643692\n",
      "Epoch 2651, Loss: 0.0010203957708654343, Final Batch Loss: 1.2584342584887054e-05\n",
      "Epoch 2652, Loss: 0.012199163036768823, Final Batch Loss: 6.21588753801916e-07\n",
      "Epoch 2653, Loss: 0.02389694796665509, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 2654, Loss: 0.0030538894498022273, Final Batch Loss: 0.0002900531981140375\n",
      "Epoch 2655, Loss: 0.037616243770145275, Final Batch Loss: 3.405971540360042e-07\n",
      "Epoch 2656, Loss: 0.053309374721720815, Final Batch Loss: 0.00026485483977012336\n",
      "Epoch 2657, Loss: 0.003457810488725954, Final Batch Loss: 7.73973351897439e-06\n",
      "Epoch 2658, Loss: 0.00594029145395325, Final Batch Loss: 9.366394806420431e-07\n",
      "Epoch 2659, Loss: 0.06479736159315053, Final Batch Loss: 2.1287348772602854e-07\n",
      "Epoch 2660, Loss: 0.0020379638737040295, Final Batch Loss: 1.7540588714837213e-06\n",
      "Epoch 2661, Loss: 0.0014658381417120836, Final Batch Loss: 3.661418759293156e-07\n",
      "Epoch 2662, Loss: 0.001648683024541242, Final Batch Loss: 4.819299647351727e-06\n",
      "Epoch 2663, Loss: 0.0036731906314209084, Final Batch Loss: 8.514948746096707e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2664, Loss: 0.0018508239317611697, Final Batch Loss: 6.726785954924708e-07\n",
      "Epoch 2665, Loss: 0.0035986605580546893, Final Batch Loss: 4.395837459014729e-05\n",
      "Epoch 2666, Loss: 0.0041759385858135545, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 2667, Loss: 0.018663281466160697, Final Batch Loss: 3.772024228965165e-06\n",
      "Epoch 2668, Loss: 0.004481069130036985, Final Batch Loss: 4.427759847658308e-07\n",
      "Epoch 2669, Loss: 0.007265344167535659, Final Batch Loss: 3.849423228530213e-05\n",
      "Epoch 2670, Loss: 0.0035071911281967516, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2671, Loss: 0.0028390890547598246, Final Batch Loss: 4.969336077920161e-05\n",
      "Epoch 2672, Loss: 0.0032832829892868176, Final Batch Loss: 0.0001787009387044236\n",
      "Epoch 2673, Loss: 0.03897106015938334, Final Batch Loss: 0.0009356837836094201\n",
      "Epoch 2674, Loss: 0.014608654552180411, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2675, Loss: 0.0020554092752718134, Final Batch Loss: 2.4808678062981926e-05\n",
      "Epoch 2676, Loss: 0.0034343859369982965, Final Batch Loss: 7.451103738276288e-05\n",
      "Epoch 2677, Loss: 0.0038022682529117446, Final Batch Loss: 0.0002218365261796862\n",
      "Epoch 2678, Loss: 0.0012685679571404762, Final Batch Loss: 3.3803548831201624e-06\n",
      "Epoch 2679, Loss: 0.0005315884941410332, Final Batch Loss: 6.283861239353428e-06\n",
      "Epoch 2680, Loss: 0.003982085225288756, Final Batch Loss: 0.001106333453208208\n",
      "Epoch 2681, Loss: 0.011792282299470713, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2682, Loss: 0.036445325320528354, Final Batch Loss: 0.023696180433034897\n",
      "Epoch 2683, Loss: 0.008280214318801882, Final Batch Loss: 5.1778271881630644e-05\n",
      "Epoch 2684, Loss: 0.014430263545364141, Final Batch Loss: 0.0014907143777236342\n",
      "Epoch 2685, Loss: 0.002313181757926941, Final Batch Loss: 0.00029768128297291696\n",
      "Epoch 2686, Loss: 0.030014928879332103, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 2687, Loss: 0.024393076932028634, Final Batch Loss: 4.4576398067874834e-05\n",
      "Epoch 2688, Loss: 0.0011633969606350547, Final Batch Loss: 4.257462364876119e-07\n",
      "Epoch 2689, Loss: 0.001865023106802255, Final Batch Loss: 6.275447958614677e-05\n",
      "Epoch 2690, Loss: 0.003347861096131055, Final Batch Loss: 1.0899051403612248e-06\n",
      "Epoch 2691, Loss: 0.0014817667426854086, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 2692, Loss: 0.0025721995609728765, Final Batch Loss: 3.516599690556177e-06\n",
      "Epoch 2693, Loss: 0.0023876116174506024, Final Batch Loss: 0.0011866119457408786\n",
      "Epoch 2694, Loss: 0.018627627534392843, Final Batch Loss: 1.1920923981278975e-07\n",
      "Epoch 2695, Loss: 0.0036085248428889827, Final Batch Loss: 1.0047568821391906e-06\n",
      "Epoch 2696, Loss: 0.0006931307614195248, Final Batch Loss: 1.6518840766366338e-06\n",
      "Epoch 2697, Loss: 0.002527279451896902, Final Batch Loss: 6.50761867291294e-05\n",
      "Epoch 2698, Loss: 0.001590971263794927, Final Batch Loss: 3.617086258600466e-05\n",
      "Epoch 2699, Loss: 0.0042283883906613084, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2700, Loss: 0.006438082097417919, Final Batch Loss: 6.556498988175008e-07\n",
      "Epoch 2701, Loss: 0.0027680191510626173, Final Batch Loss: 7.177741736086318e-06\n",
      "Epoch 2702, Loss: 0.0016700400469744636, Final Batch Loss: 2.2393965082301293e-06\n",
      "Epoch 2703, Loss: 0.08133234662454925, Final Batch Loss: 0.08041707426309586\n",
      "Epoch 2704, Loss: 0.0032449144491693005, Final Batch Loss: 0.0016517702024430037\n",
      "Epoch 2705, Loss: 0.039065550634404644, Final Batch Loss: 0.00034070006222464144\n",
      "Epoch 2706, Loss: 0.030329948196708756, Final Batch Loss: 8.770367685428937e-07\n",
      "Epoch 2707, Loss: 0.0029648295676452108, Final Batch Loss: 0.00017913104966282845\n",
      "Epoch 2708, Loss: 0.018352620645600837, Final Batch Loss: 9.728513396112248e-05\n",
      "Epoch 2709, Loss: 0.003362213341461029, Final Batch Loss: 7.266471948241815e-05\n",
      "Epoch 2710, Loss: 0.010276618020725437, Final Batch Loss: 0.0002649850503075868\n",
      "Epoch 2711, Loss: 0.004370870512502734, Final Batch Loss: 2.247925294796005e-06\n",
      "Epoch 2712, Loss: 0.018584369835600967, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 2713, Loss: 0.005710905012847434, Final Batch Loss: 3.559211791070993e-06\n",
      "Epoch 2714, Loss: 0.0005942577907660507, Final Batch Loss: 2.809927934777079e-07\n",
      "Epoch 2715, Loss: 0.005186396792851156, Final Batch Loss: 0.0037157642655074596\n",
      "Epoch 2716, Loss: 0.03087439968265926, Final Batch Loss: 4.93866252782027e-07\n",
      "Epoch 2717, Loss: 0.0027484410966280848, Final Batch Loss: 0.0\n",
      "Epoch 2718, Loss: 0.004295123247857191, Final Batch Loss: 3.0568178317480488e-06\n",
      "Epoch 2719, Loss: 0.005502072910303468, Final Batch Loss: 2.4522685180272674e-06\n",
      "Epoch 2720, Loss: 0.009209077032956259, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 2721, Loss: 0.0009746096867502274, Final Batch Loss: 7.578265694974107e-07\n",
      "Epoch 2722, Loss: 0.001762105504361955, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 2723, Loss: 0.0013467694930113794, Final Batch Loss: 2.2990343495621346e-07\n",
      "Epoch 2724, Loss: 0.015624751713403384, Final Batch Loss: 2.0475517885643058e-05\n",
      "Epoch 2725, Loss: 0.003547478074835908, Final Batch Loss: 4.853505402024894e-07\n",
      "Epoch 2726, Loss: 0.002394920331425965, Final Batch Loss: 0.0002771599974948913\n",
      "Epoch 2727, Loss: 0.0009737200228983056, Final Batch Loss: 1.4219834838513634e-06\n",
      "Epoch 2728, Loss: 0.0020470939334700233, Final Batch Loss: 8.565532880311366e-06\n",
      "Epoch 2729, Loss: 0.00187052175624558, Final Batch Loss: 5.551531103265006e-06\n",
      "Epoch 2730, Loss: 0.0013886358866557202, Final Batch Loss: 6.982228342167218e-07\n",
      "Epoch 2731, Loss: 0.0008920797226892319, Final Batch Loss: 2.5497731257928535e-05\n",
      "Epoch 2732, Loss: 0.0027130634407512844, Final Batch Loss: 0.00020541739650070667\n",
      "Epoch 2733, Loss: 0.0011894779111116804, Final Batch Loss: 2.0009849777125055e-06\n",
      "Epoch 2734, Loss: 0.000766254604968708, Final Batch Loss: 5.406884156400338e-06\n",
      "Epoch 2735, Loss: 0.02019413936068304, Final Batch Loss: 0.014375920407474041\n",
      "Epoch 2736, Loss: 0.024477488271902104, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 2737, Loss: 0.665939982078271, Final Batch Loss: 0.6651471853256226\n",
      "Epoch 2738, Loss: 0.0027287507327855565, Final Batch Loss: 0.0013886479428038\n",
      "Epoch 2739, Loss: 0.02131496393537269, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2740, Loss: 0.06397952414408792, Final Batch Loss: 0.02713627927005291\n",
      "Epoch 2741, Loss: 0.004193950882836361, Final Batch Loss: 2.3813774532754906e-05\n",
      "Epoch 2742, Loss: 0.18942070694174618, Final Batch Loss: 0.12158495932817459\n",
      "Epoch 2743, Loss: 0.007450771291331648, Final Batch Loss: 2.0435865621948324e-07\n",
      "Epoch 2744, Loss: 0.034798247254911985, Final Batch Loss: 4.776734385814052e-06\n",
      "Epoch 2745, Loss: 0.013950472320175322, Final Batch Loss: 7.1096301326178946e-06\n",
      "Epoch 2746, Loss: 0.012947379291290417, Final Batch Loss: 0.0001380671455990523\n",
      "Epoch 2747, Loss: 0.08363575785188004, Final Batch Loss: 0.002952898619696498\n",
      "Epoch 2748, Loss: 0.009362658995087259, Final Batch Loss: 0.00024041884171310812\n",
      "Epoch 2749, Loss: 0.00986595795257017, Final Batch Loss: 0.0008267808589152992\n",
      "Epoch 2750, Loss: 0.0055375954252667725, Final Batch Loss: 0.0007696169195696712\n",
      "Epoch 2751, Loss: 0.02169866229814943, Final Batch Loss: 0.0005913484492339194\n",
      "Epoch 2752, Loss: 0.003443875248194672, Final Batch Loss: 8.446558786090463e-05\n",
      "Epoch 2753, Loss: 0.013806053769890525, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 2754, Loss: 0.037586651371384505, Final Batch Loss: 4.1212224459741265e-05\n",
      "Epoch 2755, Loss: 0.0053336615715622315, Final Batch Loss: 7.663452805672932e-08\n",
      "Epoch 2756, Loss: 0.020995876424422022, Final Batch Loss: 1.65188976097852e-06\n",
      "Epoch 2757, Loss: 0.012742328690364957, Final Batch Loss: 0.0003575404698494822\n",
      "Epoch 2758, Loss: 0.017241346766240895, Final Batch Loss: 0.005097000859677792\n",
      "Epoch 2759, Loss: 0.0049208757300220896, Final Batch Loss: 4.9364509322913364e-05\n",
      "Epoch 2760, Loss: 0.017492483588284813, Final Batch Loss: 0.009608329273760319\n",
      "Epoch 2761, Loss: 0.031851061852648854, Final Batch Loss: 0.0019739808049052954\n",
      "Epoch 2762, Loss: 0.009475801307416987, Final Batch Loss: 3.7673213228117675e-05\n",
      "Epoch 2763, Loss: 0.0184803472366184, Final Batch Loss: 7.231993367895484e-05\n",
      "Epoch 2764, Loss: 0.020932931423885748, Final Batch Loss: 4.020167398266494e-05\n",
      "Epoch 2765, Loss: 0.019152900682456675, Final Batch Loss: 8.173910828190856e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2766, Loss: 0.004293531778273518, Final Batch Loss: 9.196104997499788e-07\n",
      "Epoch 2767, Loss: 0.015609277725161519, Final Batch Loss: 5.0337308493908495e-05\n",
      "Epoch 2768, Loss: 0.00825469500705367, Final Batch Loss: 0.00017375020252075046\n",
      "Epoch 2769, Loss: 0.021167848564800806, Final Batch Loss: 0.00335494801402092\n",
      "Epoch 2770, Loss: 0.013516513772174221, Final Batch Loss: 4.674565843743039e-06\n",
      "Epoch 2771, Loss: 0.001776035933289677, Final Batch Loss: 2.4863402359187603e-06\n",
      "Epoch 2772, Loss: 0.008265084907179698, Final Batch Loss: 0.0052453866228461266\n",
      "Epoch 2773, Loss: 0.005768647728473297, Final Batch Loss: 2.320985913684126e-05\n",
      "Epoch 2774, Loss: 0.034403031357214786, Final Batch Loss: 0.0007430611294694245\n",
      "Epoch 2775, Loss: 0.00403188363998197, Final Batch Loss: 0.0006038513383828104\n",
      "Epoch 2776, Loss: 0.00238397916109534, Final Batch Loss: 0.0017069920431822538\n",
      "Epoch 2777, Loss: 0.00214189849793911, Final Batch Loss: 0.0\n",
      "Epoch 2778, Loss: 0.003969340547705258, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 2779, Loss: 0.003888156916218577, Final Batch Loss: 4.3349264160497114e-05\n",
      "Epoch 2780, Loss: 0.022622931654041167, Final Batch Loss: 4.1053273889701813e-05\n",
      "Epoch 2781, Loss: 0.0038057991168898297, Final Batch Loss: 1.2524627891252749e-05\n",
      "Epoch 2782, Loss: 0.004634801545137179, Final Batch Loss: 6.64163337660284e-07\n",
      "Epoch 2783, Loss: 0.0034028116933768615, Final Batch Loss: 1.2533681001514196e-05\n",
      "Epoch 2784, Loss: 0.00904182860125502, Final Batch Loss: 4.938660254083516e-07\n",
      "Epoch 2785, Loss: 0.001996050948946504, Final Batch Loss: 7.220554834930226e-06\n",
      "Epoch 2786, Loss: 0.006275839128647931, Final Batch Loss: 7.55292276153341e-05\n",
      "Epoch 2787, Loss: 0.0029200090757512953, Final Batch Loss: 3.7465724744834006e-07\n",
      "Epoch 2788, Loss: 0.0068020979342691135, Final Batch Loss: 3.176288373651914e-05\n",
      "Epoch 2789, Loss: 0.0025292551654274575, Final Batch Loss: 0.0001376097643515095\n",
      "Epoch 2790, Loss: 0.0036868388124275953, Final Batch Loss: 0.0008342411019839346\n",
      "Epoch 2791, Loss: 0.005057989090346382, Final Batch Loss: 1.7419510186300613e-05\n",
      "Epoch 2792, Loss: 0.001362440097182116, Final Batch Loss: 1.151997366832802e-05\n",
      "Epoch 2793, Loss: 0.003434757146962397, Final Batch Loss: 1.1069430172483408e-07\n",
      "Epoch 2794, Loss: 0.0029285021238365516, Final Batch Loss: 1.064364482772362e-06\n",
      "Epoch 2795, Loss: 0.0054116191505499955, Final Batch Loss: 9.962433296095696e-07\n",
      "Epoch 2796, Loss: 0.0015136714723666955, Final Batch Loss: 4.00195904148859e-06\n",
      "Epoch 2797, Loss: 0.002457023714669049, Final Batch Loss: 0.0003715252678375691\n",
      "Epoch 2798, Loss: 0.011413678628741764, Final Batch Loss: 0.0028816976118832827\n",
      "Epoch 2799, Loss: 0.002892435200919863, Final Batch Loss: 0.00011898243246832862\n",
      "Epoch 2800, Loss: 0.005853130205650814, Final Batch Loss: 0.0029488238506019115\n",
      "Epoch 2801, Loss: 0.003241091559175402, Final Batch Loss: 8.037961379159242e-06\n",
      "Epoch 2802, Loss: 0.025636218902945984, Final Batch Loss: 0.0006153458380140364\n",
      "Epoch 2803, Loss: 0.024876473199583415, Final Batch Loss: 1.3895730262447614e-05\n",
      "Epoch 2804, Loss: 0.001943027149536647, Final Batch Loss: 0.00035971077159047127\n",
      "Epoch 2805, Loss: 0.027763205163864768, Final Batch Loss: 8.778717528912239e-06\n",
      "Epoch 2806, Loss: 0.005911230415222235, Final Batch Loss: 0.00030542470631189644\n",
      "Epoch 2807, Loss: 0.0252728402701905, Final Batch Loss: 0.00015334071940742433\n",
      "Epoch 2808, Loss: 0.013648827512952266, Final Batch Loss: 0.0012836649548262358\n",
      "Epoch 2809, Loss: 0.008260626156697981, Final Batch Loss: 0.0058373259380459785\n",
      "Epoch 2810, Loss: 0.0043973470164928585, Final Batch Loss: 7.309851935133338e-05\n",
      "Epoch 2811, Loss: 0.003059367299783844, Final Batch Loss: 3.3548274132044753e-06\n",
      "Epoch 2812, Loss: 0.0029259316470415797, Final Batch Loss: 4.966754568158649e-05\n",
      "Epoch 2813, Loss: 0.029408897047687788, Final Batch Loss: 0.00019937093020416796\n",
      "Epoch 2814, Loss: 0.025200038362527266, Final Batch Loss: 0.0002618397702462971\n",
      "Epoch 2815, Loss: 0.002229989761950435, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 2816, Loss: 0.006009804698294374, Final Batch Loss: 7.918883397906029e-07\n",
      "Epoch 2817, Loss: 0.035710629861796406, Final Batch Loss: 1.0303049293725053e-06\n",
      "Epoch 2818, Loss: 0.005806215796837932, Final Batch Loss: 2.4833823772496544e-05\n",
      "Epoch 2819, Loss: 0.015449883350811433, Final Batch Loss: 0.00010033146099885926\n",
      "Epoch 2820, Loss: 0.0035315842669660924, Final Batch Loss: 2.5267900127801113e-05\n",
      "Epoch 2821, Loss: 0.0010198118679909385, Final Batch Loss: 9.144473551714327e-06\n",
      "Epoch 2822, Loss: 0.002104343118844554, Final Batch Loss: 0.0003943642077501863\n",
      "Epoch 2823, Loss: 0.0004207230231259018, Final Batch Loss: 5.449546733871102e-07\n",
      "Epoch 2824, Loss: 0.01874954690447339, Final Batch Loss: 1.0140761332877446e-05\n",
      "Epoch 2825, Loss: 0.0011767991322813032, Final Batch Loss: 8.259462447313126e-07\n",
      "Epoch 2826, Loss: 0.008293135979329236, Final Batch Loss: 0.0\n",
      "Epoch 2827, Loss: 0.0024283374518745404, Final Batch Loss: 5.526133918465348e-06\n",
      "Epoch 2828, Loss: 0.00927612854866311, Final Batch Loss: 0.0009407857432961464\n",
      "Epoch 2829, Loss: 0.0015571011072097463, Final Batch Loss: 6.982078957662452e-06\n",
      "Epoch 2830, Loss: 0.000821843672383693, Final Batch Loss: 2.069684887828771e-05\n",
      "Epoch 2831, Loss: 0.003983567097748164, Final Batch Loss: 0.0002561671717558056\n",
      "Epoch 2832, Loss: 0.0263335314757569, Final Batch Loss: 2.259661596326623e-05\n",
      "Epoch 2833, Loss: 0.0018064396429338103, Final Batch Loss: 3.320822372643306e-07\n",
      "Epoch 2834, Loss: 0.00692103448227499, Final Batch Loss: 5.636729383695638e-06\n",
      "Epoch 2835, Loss: 0.005679930647602305, Final Batch Loss: 0.00028820717125199735\n",
      "Epoch 2836, Loss: 0.014478965286912171, Final Batch Loss: 1.0558461553955567e-06\n",
      "Epoch 2837, Loss: 0.031511048931861296, Final Batch Loss: 0.0001286896876990795\n",
      "Epoch 2838, Loss: 0.00410850438856869, Final Batch Loss: 0.0013768590288236737\n",
      "Epoch 2839, Loss: 0.024071424555245358, Final Batch Loss: 1.345349687653652e-06\n",
      "Epoch 2840, Loss: 0.04159767039527651, Final Batch Loss: 0.0006351206684485078\n",
      "Epoch 2841, Loss: 0.003056945482960316, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 2842, Loss: 0.0016590073209954426, Final Batch Loss: 3.322640259284526e-05\n",
      "Epoch 2843, Loss: 0.0015781986330694053, Final Batch Loss: 3.6051769711775705e-05\n",
      "Epoch 2844, Loss: 0.018131381500484878, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 2845, Loss: 0.0017640162118937042, Final Batch Loss: 7.918866344880371e-07\n",
      "Epoch 2846, Loss: 0.006816286088515255, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 2847, Loss: 0.016227283216721844, Final Batch Loss: 8.180955046555027e-05\n",
      "Epoch 2848, Loss: 0.0012015709524462181, Final Batch Loss: 3.065377427446947e-07\n",
      "Epoch 2849, Loss: 0.022944098309380934, Final Batch Loss: 0.021745095029473305\n",
      "Epoch 2850, Loss: 0.0020365133916584455, Final Batch Loss: 2.409690068816417e-06\n",
      "Epoch 2851, Loss: 0.0061982801562407985, Final Batch Loss: 0.0003758810053113848\n",
      "Epoch 2852, Loss: 0.00419098068960011, Final Batch Loss: 0.0\n",
      "Epoch 2853, Loss: 0.001713374222163111, Final Batch Loss: 0.0\n",
      "Epoch 2854, Loss: 0.008991516926812437, Final Batch Loss: 9.877297770799487e-07\n",
      "Epoch 2855, Loss: 0.004026035574497655, Final Batch Loss: 0.0008211653912439942\n",
      "Epoch 2856, Loss: 0.023016351438542415, Final Batch Loss: 4.3426157958492695e-07\n",
      "Epoch 2857, Loss: 0.04080742994483444, Final Batch Loss: 2.657228833413683e-05\n",
      "Epoch 2858, Loss: 0.015237922526466718, Final Batch Loss: 1.1094621186202858e-05\n",
      "Epoch 2859, Loss: 0.012817318667657673, Final Batch Loss: 0.0\n",
      "Epoch 2860, Loss: 0.0063014316983753815, Final Batch Loss: 0.00014458804798778147\n",
      "Epoch 2861, Loss: 0.015187065546342637, Final Batch Loss: 0.002403643447905779\n",
      "Epoch 2862, Loss: 0.0046815818550101085, Final Batch Loss: 3.831719084246288e-07\n",
      "Epoch 2863, Loss: 0.0020607750866474817, Final Batch Loss: 9.731995305628516e-06\n",
      "Epoch 2864, Loss: 0.0024013165962060157, Final Batch Loss: 5.764507932326524e-06\n",
      "Epoch 2865, Loss: 0.0033282536605838686, Final Batch Loss: 0.00033836724469438195\n",
      "Epoch 2866, Loss: 0.026262603982880606, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 2867, Loss: 0.023675314344785647, Final Batch Loss: 4.427759847658308e-07\n",
      "Epoch 2868, Loss: 0.0023404040111927316, Final Batch Loss: 0.0005772607983089983\n",
      "Epoch 2869, Loss: 0.018341708602349627, Final Batch Loss: 5.790148520645744e-07\n",
      "Epoch 2870, Loss: 0.04858033751224866, Final Batch Loss: 0.0002684273640625179\n",
      "Epoch 2871, Loss: 0.0012284475542401196, Final Batch Loss: 1.3077764378977008e-05\n",
      "Epoch 2872, Loss: 0.0007722841396571312, Final Batch Loss: 6.011301138642011e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2873, Loss: 0.009552986240450423, Final Batch Loss: 1.0217932810974162e-07\n",
      "Epoch 2874, Loss: 0.003880002463120036, Final Batch Loss: 0.00018195543088950217\n",
      "Epoch 2875, Loss: 0.022808263063780032, Final Batch Loss: 0.018330609425902367\n",
      "Epoch 2876, Loss: 0.004182864338872605, Final Batch Loss: 2.7338779545971192e-05\n",
      "Epoch 2877, Loss: 0.004759202594868839, Final Batch Loss: 0.0005123246810398996\n",
      "Epoch 2878, Loss: 0.002956465679744724, Final Batch Loss: 4.1779632738325745e-05\n",
      "Epoch 2879, Loss: 0.027567574339627754, Final Batch Loss: 4.369387897895649e-05\n",
      "Epoch 2880, Loss: 0.01823768140309312, Final Batch Loss: 7.237671297843917e-07\n",
      "Epoch 2881, Loss: 0.012159745602730254, Final Batch Loss: 1.0745367944764439e-05\n",
      "Epoch 2882, Loss: 0.0013252341013867408, Final Batch Loss: 0.00023591684293933213\n",
      "Epoch 2883, Loss: 0.0018997853476321325, Final Batch Loss: 4.781250027008355e-05\n",
      "Epoch 2884, Loss: 0.0008237300394853264, Final Batch Loss: 9.025794156514166e-07\n",
      "Epoch 2885, Loss: 0.002496150527804275, Final Batch Loss: 1.4219858712749556e-06\n",
      "Epoch 2886, Loss: 0.02954763306388486, Final Batch Loss: 1.0260001545248087e-05\n",
      "Epoch 2887, Loss: 0.003205330872333434, Final Batch Loss: 6.207254955370445e-06\n",
      "Epoch 2888, Loss: 0.0014266157959355041, Final Batch Loss: 0.0002946143504232168\n",
      "Epoch 2889, Loss: 0.0015731691910332302, Final Batch Loss: 1.4219858712749556e-06\n",
      "Epoch 2890, Loss: 0.001298678296734579, Final Batch Loss: 6.031651719240472e-05\n",
      "Epoch 2891, Loss: 0.0023642872547497973, Final Batch Loss: 0.001005289377644658\n",
      "Epoch 2892, Loss: 0.0027576711080143923, Final Batch Loss: 3.3208274885510036e-07\n",
      "Epoch 2893, Loss: 0.0015587121347380162, Final Batch Loss: 7.271508820849704e-06\n",
      "Epoch 2894, Loss: 0.002121212177257803, Final Batch Loss: 9.70698124547198e-07\n",
      "Epoch 2895, Loss: 0.01590237148639062, Final Batch Loss: 7.135173746064538e-06\n",
      "Epoch 2896, Loss: 0.4221806025961996, Final Batch Loss: 0.4209202826023102\n",
      "Epoch 2897, Loss: 0.002479839314247556, Final Batch Loss: 1.5326898505918507e-07\n",
      "Epoch 2898, Loss: 0.00556732419772743, Final Batch Loss: 4.172204171482008e-06\n",
      "Epoch 2899, Loss: 0.002732814025648622, Final Batch Loss: 3.755032366825617e-06\n",
      "Epoch 2900, Loss: 0.010757076015579514, Final Batch Loss: 6.178552575875074e-05\n",
      "Epoch 2901, Loss: 0.012215430715286857, Final Batch Loss: 3.448525376370526e-06\n",
      "Epoch 2902, Loss: 0.01951886735332664, Final Batch Loss: 0.00018812545749824494\n",
      "Epoch 2903, Loss: 0.012267731770407408, Final Batch Loss: 0.0006988999666646123\n",
      "Epoch 2904, Loss: 0.015290982992155477, Final Batch Loss: 5.643133772537112e-05\n",
      "Epoch 2905, Loss: 0.004023750851047225, Final Batch Loss: 6.730310269631445e-05\n",
      "Epoch 2906, Loss: 0.013375604974498856, Final Batch Loss: 1.580263597134035e-05\n",
      "Epoch 2907, Loss: 0.010951630625640973, Final Batch Loss: 0.00033452617935836315\n",
      "Epoch 2908, Loss: 0.005879261949303327, Final Batch Loss: 2.5175173504976556e-05\n",
      "Epoch 2909, Loss: 0.00561652157921344, Final Batch Loss: 0.00012572534615173936\n",
      "Epoch 2910, Loss: 0.01368705919230706, Final Batch Loss: 2.3746466467855498e-05\n",
      "Epoch 2911, Loss: 0.0040983666985994205, Final Batch Loss: 0.0\n",
      "Epoch 2912, Loss: 0.00168560449310462, Final Batch Loss: 4.743163663079031e-05\n",
      "Epoch 2913, Loss: 0.0012035069012199529, Final Batch Loss: 9.842494182521477e-05\n",
      "Epoch 2914, Loss: 0.00558365407778183, Final Batch Loss: 0.002972366288304329\n",
      "Epoch 2915, Loss: 0.0018190241137290286, Final Batch Loss: 1.013275550576509e-06\n",
      "Epoch 2916, Loss: 0.0055537505832035094, Final Batch Loss: 0.0014435730408877134\n",
      "Epoch 2917, Loss: 0.0022858909505885094, Final Batch Loss: 1.9692815840244293e-05\n",
      "Epoch 2918, Loss: 0.0029119349201209843, Final Batch Loss: 0.00037657239590771496\n",
      "Epoch 2919, Loss: 0.019628032883531432, Final Batch Loss: 2.4693309796930407e-07\n",
      "Epoch 2920, Loss: 0.017007437116944857, Final Batch Loss: 2.8865094918728573e-06\n",
      "Epoch 2921, Loss: 0.004194689611054514, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 2922, Loss: 0.006629926661844365, Final Batch Loss: 0.0036606735084205866\n",
      "Epoch 2923, Loss: 0.011724782147211954, Final Batch Loss: 0.00029415430617518723\n",
      "Epoch 2924, Loss: 0.01258330827113241, Final Batch Loss: 0.00023752216657157987\n",
      "Epoch 2925, Loss: 0.002776446235657204, Final Batch Loss: 6.128985114628449e-05\n",
      "Epoch 2926, Loss: 0.00439158096742176, Final Batch Loss: 1.5325525964726694e-05\n",
      "Epoch 2927, Loss: 0.04915303258167114, Final Batch Loss: 0.002447366714477539\n",
      "Epoch 2928, Loss: 0.025296975294622825, Final Batch Loss: 3.133788050035946e-05\n",
      "Epoch 2929, Loss: 0.0040833257570511705, Final Batch Loss: 1.4986197811595048e-06\n",
      "Epoch 2930, Loss: 0.014572630514521734, Final Batch Loss: 2.1514157197088934e-05\n",
      "Epoch 2931, Loss: 0.001936848882905906, Final Batch Loss: 1.985502240131609e-05\n",
      "Epoch 2932, Loss: 0.014486875235888874, Final Batch Loss: 2.3199590941658244e-05\n",
      "Epoch 2933, Loss: 0.012206843929789102, Final Batch Loss: 1.5837642877158942e-06\n",
      "Epoch 2934, Loss: 0.0025429147436959454, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 2935, Loss: 0.004187024358543567, Final Batch Loss: 0.00018566542712505907\n",
      "Epoch 2936, Loss: 0.0031986337053240277, Final Batch Loss: 0.0\n",
      "Epoch 2937, Loss: 0.006244078491363325, Final Batch Loss: 2.7587902877712622e-06\n",
      "Epoch 2938, Loss: 0.020655250293430072, Final Batch Loss: 2.4607873001514236e-06\n",
      "Epoch 2939, Loss: 0.00526436285872478, Final Batch Loss: 0.002938187448307872\n",
      "Epoch 2940, Loss: 0.0038715985720045865, Final Batch Loss: 0.0\n",
      "Epoch 2941, Loss: 0.0018999307212652639, Final Batch Loss: 3.207033296348527e-05\n",
      "Epoch 2942, Loss: 0.002060574959614314, Final Batch Loss: 0.00017753832798916847\n",
      "Epoch 2943, Loss: 0.002846854829726908, Final Batch Loss: 1.5582226069454919e-06\n",
      "Epoch 2944, Loss: 0.0007704355363102877, Final Batch Loss: 1.4560415593223297e-06\n",
      "Epoch 2945, Loss: 0.0025503051874693483, Final Batch Loss: 0.00011348369298502803\n",
      "Epoch 2946, Loss: 0.0031240185926435515, Final Batch Loss: 9.098391456063837e-05\n",
      "Epoch 2947, Loss: 0.000799438523245044, Final Batch Loss: 0.00010481674689799547\n",
      "Epoch 2948, Loss: 0.00352802308043465, Final Batch Loss: 0.0006852009682916105\n",
      "Epoch 2949, Loss: 0.014161025137582328, Final Batch Loss: 8.600373257650062e-05\n",
      "Epoch 2950, Loss: 0.001721095060929656, Final Batch Loss: 4.8778900236357003e-05\n",
      "Epoch 2951, Loss: 0.0031366898814866317, Final Batch Loss: 2.2990336390193988e-07\n",
      "Epoch 2952, Loss: 0.0045603222479257965, Final Batch Loss: 2.6871881345869042e-05\n",
      "Epoch 2953, Loss: 0.001243171335659099, Final Batch Loss: 1.3964407798994216e-06\n",
      "Epoch 2954, Loss: 0.0013980010971863521, Final Batch Loss: 9.468041753279977e-06\n",
      "Epoch 2955, Loss: 0.0022969037418079097, Final Batch Loss: 3.29997310473118e-05\n",
      "Epoch 2956, Loss: 0.002541065847253776, Final Batch Loss: 2.2518490368383937e-05\n",
      "Epoch 2957, Loss: 0.0016453031021228526, Final Batch Loss: 4.450280175660737e-05\n",
      "Epoch 2958, Loss: 0.023837347223889083, Final Batch Loss: 9.23995248740539e-05\n",
      "Epoch 2959, Loss: 0.003335655688715633, Final Batch Loss: 4.4671025534626096e-05\n",
      "Epoch 2960, Loss: 0.02318064368486006, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 2961, Loss: 0.017810462893976364, Final Batch Loss: 8.617086132289842e-05\n",
      "Epoch 2962, Loss: 0.002845556358806789, Final Batch Loss: 0.0\n",
      "Epoch 2963, Loss: 0.025884925194986863, Final Batch Loss: 5.342594158719294e-05\n",
      "Epoch 2964, Loss: 0.00415874199825339, Final Batch Loss: 0.0010460809571668506\n",
      "Epoch 2965, Loss: 0.03882625643745996, Final Batch Loss: 0.00017023031250573695\n",
      "Epoch 2966, Loss: 0.006148907035822049, Final Batch Loss: 0.0\n",
      "Epoch 2967, Loss: 0.03612932766554877, Final Batch Loss: 0.013522208668291569\n",
      "Epoch 2968, Loss: 0.0029427051995298825, Final Batch Loss: 0.00019524060189723969\n",
      "Epoch 2969, Loss: 0.006904278624068283, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2970, Loss: 0.005001328885555267, Final Batch Loss: 0.0009701388771645725\n",
      "Epoch 2971, Loss: 0.021570479912270457, Final Batch Loss: 3.3974140478676418e-06\n",
      "Epoch 2972, Loss: 0.00443180228012352, Final Batch Loss: 6.121986189100426e-06\n",
      "Epoch 2973, Loss: 0.00291234843825805, Final Batch Loss: 5.817364944959991e-05\n",
      "Epoch 2974, Loss: 0.002705472513135021, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 2975, Loss: 0.018883077934937376, Final Batch Loss: 1.1069429461940672e-07\n",
      "Epoch 2976, Loss: 0.00369871529566268, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 2977, Loss: 0.002319605622687959, Final Batch Loss: 2.6273321054759435e-05\n",
      "Epoch 2978, Loss: 0.017780502967070788, Final Batch Loss: 0.005119555629789829\n",
      "Epoch 2979, Loss: 0.0018562069535335013, Final Batch Loss: 2.7247821776654746e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2980, Loss: 0.014558441866288518, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2981, Loss: 0.23698613642773125, Final Batch Loss: 0.23454904556274414\n",
      "Epoch 2982, Loss: 0.005351402462085986, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 2983, Loss: 0.025921560387359932, Final Batch Loss: 0.012371786870062351\n",
      "Epoch 2984, Loss: 0.04558809850789203, Final Batch Loss: 5.960442877039895e-07\n",
      "Epoch 2985, Loss: 0.009893346543321968, Final Batch Loss: 2.1897767510381527e-05\n",
      "Epoch 2986, Loss: 0.010290971520589665, Final Batch Loss: 1.9334984244778752e-05\n",
      "Epoch 2987, Loss: 0.009734044066135539, Final Batch Loss: 5.8133486163569614e-05\n",
      "Epoch 2988, Loss: 0.014022951749211643, Final Batch Loss: 4.5005181164015085e-05\n",
      "Epoch 2989, Loss: 0.003754270259378245, Final Batch Loss: 4.9881640734383836e-05\n",
      "Epoch 2990, Loss: 0.0024412422644672915, Final Batch Loss: 0.0\n",
      "Epoch 2991, Loss: 0.002199977409645726, Final Batch Loss: 3.0312573926494224e-06\n",
      "Epoch 2992, Loss: 0.0014829890424152836, Final Batch Loss: 1.0234238288830966e-05\n",
      "Epoch 2993, Loss: 0.006345027162751649, Final Batch Loss: 0.0031578734051436186\n",
      "Epoch 2994, Loss: 0.0023955259821377695, Final Batch Loss: 0.00025891128461807966\n",
      "Epoch 2995, Loss: 0.0017457216745242476, Final Batch Loss: 0.0\n",
      "Epoch 2996, Loss: 0.005558932163694408, Final Batch Loss: 7.258357800310478e-05\n",
      "Epoch 2997, Loss: 0.0029686456835378294, Final Batch Loss: 1.7881374958506058e-07\n",
      "Epoch 2998, Loss: 0.0025024644834275023, Final Batch Loss: 1.2261422170922742e-06\n",
      "Epoch 2999, Loss: 0.0012989048859708419, Final Batch Loss: 2.4096984816424083e-06\n",
      "Epoch 3000, Loss: 0.027824403543490916, Final Batch Loss: 0.006334897130727768\n",
      "Epoch 3001, Loss: 0.021040998442913406, Final Batch Loss: 0.0004284984024707228\n",
      "Epoch 3002, Loss: 0.00981277214924603, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 3003, Loss: 0.02414005564060062, Final Batch Loss: 0.000714327150490135\n",
      "Epoch 3004, Loss: 0.015037037907859485, Final Batch Loss: 1.367409549857257e-05\n",
      "Epoch 3005, Loss: 0.0034067379154780753, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3006, Loss: 0.02561107512883609, Final Batch Loss: 9.88549436442554e-06\n",
      "Epoch 3007, Loss: 0.0043527648535928165, Final Batch Loss: 7.092604846548056e-06\n",
      "Epoch 3008, Loss: 0.0020674171864811797, Final Batch Loss: 6.342525739455596e-05\n",
      "Epoch 3009, Loss: 0.004229449550603448, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 3010, Loss: 0.004009496120801259, Final Batch Loss: 2.639629599343607e-07\n",
      "Epoch 3011, Loss: 0.008295006083368861, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3012, Loss: 0.018814854614902288, Final Batch Loss: 0.00045720738125965\n",
      "Epoch 3013, Loss: 0.00206737342591623, Final Batch Loss: 2.6566274300421355e-06\n",
      "Epoch 3014, Loss: 0.007835378839097018, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 3015, Loss: 0.002920647380506125, Final Batch Loss: 3.652846771728946e-06\n",
      "Epoch 3016, Loss: 0.0657338395685656, Final Batch Loss: 0.010593937709927559\n",
      "Epoch 3017, Loss: 0.002112923906679498, Final Batch Loss: 1.5674395399400964e-05\n",
      "Epoch 3018, Loss: 0.0017298111197305843, Final Batch Loss: 0.00013283990847412497\n",
      "Epoch 3019, Loss: 0.007815852515964394, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3020, Loss: 0.0015692402957938612, Final Batch Loss: 2.2221196559257805e-05\n",
      "Epoch 3021, Loss: 0.0012405457091517746, Final Batch Loss: 0.0004287834744900465\n",
      "Epoch 3022, Loss: 0.008977210200100671, Final Batch Loss: 0.0002605290792416781\n",
      "Epoch 3023, Loss: 0.01823537942254916, Final Batch Loss: 0.002339153317734599\n",
      "Epoch 3024, Loss: 0.0015536971955043555, Final Batch Loss: 2.7673127078742255e-06\n",
      "Epoch 3025, Loss: 0.003022433171281591, Final Batch Loss: 1.3682212738785893e-05\n",
      "Epoch 3026, Loss: 0.020676061423728243, Final Batch Loss: 0.0015850617783144116\n",
      "Epoch 3027, Loss: 0.00510566524872047, Final Batch Loss: 2.094664978358196e-06\n",
      "Epoch 3028, Loss: 0.0034364157618256286, Final Batch Loss: 0.0003823486913461238\n",
      "Epoch 3029, Loss: 0.003869182022754103, Final Batch Loss: 0.0002097812102874741\n",
      "Epoch 3030, Loss: 0.0013497898833350064, Final Batch Loss: 2.384183801495965e-07\n",
      "Epoch 3031, Loss: 0.0032272669923258945, Final Batch Loss: 0.0019389867084100842\n",
      "Epoch 3032, Loss: 0.0016073093913746561, Final Batch Loss: 2.9716950393776642e-06\n",
      "Epoch 3033, Loss: 0.0029247020450249295, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3034, Loss: 0.01525899772440198, Final Batch Loss: 1.2772414947903599e-07\n",
      "Epoch 3035, Loss: 0.002127046878740657, Final Batch Loss: 0.000109214881376829\n",
      "Epoch 3036, Loss: 0.006102406030549901, Final Batch Loss: 2.573627352830954e-05\n",
      "Epoch 3037, Loss: 0.0012436623237590538, Final Batch Loss: 1.2405713277985342e-05\n",
      "Epoch 3038, Loss: 0.0038099874053614258, Final Batch Loss: 1.8817789850800182e-06\n",
      "Epoch 3039, Loss: 0.0013875504446332343, Final Batch Loss: 6.560311157954857e-05\n",
      "Epoch 3040, Loss: 0.0015243010152516945, Final Batch Loss: 4.104158961126814e-06\n",
      "Epoch 3041, Loss: 0.0026933501358143985, Final Batch Loss: 0.0014438203070312738\n",
      "Epoch 3042, Loss: 0.0010469486366559977, Final Batch Loss: 4.93866252782027e-07\n",
      "Epoch 3043, Loss: 0.004114066316105891, Final Batch Loss: 0.0021767604630440474\n",
      "Epoch 3044, Loss: 0.001782267394446535, Final Batch Loss: 6.990452675381675e-06\n",
      "Epoch 3045, Loss: 0.0017363278246698144, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3046, Loss: 0.0059832613387698075, Final Batch Loss: 0.0\n",
      "Epoch 3047, Loss: 0.002943771909485804, Final Batch Loss: 2.228017183369957e-05\n",
      "Epoch 3048, Loss: 0.0030120774265789407, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3049, Loss: 0.02633780872565694, Final Batch Loss: 0.005709883291274309\n",
      "Epoch 3050, Loss: 0.015128569901790456, Final Batch Loss: 2.0435858516520966e-07\n",
      "Epoch 3051, Loss: 0.007695512547797989, Final Batch Loss: 0.0001076159969670698\n",
      "Epoch 3052, Loss: 0.005413353850599378, Final Batch Loss: 0.0015007423935458064\n",
      "Epoch 3053, Loss: 0.029397649842849205, Final Batch Loss: 4.615030320564983e-06\n",
      "Epoch 3054, Loss: 0.0017455763722864504, Final Batch Loss: 5.960450835118536e-07\n",
      "Epoch 3055, Loss: 0.0028219218875165097, Final Batch Loss: 0.0017470410093665123\n",
      "Epoch 3056, Loss: 0.0052648482960648835, Final Batch Loss: 0.0030038401018828154\n",
      "Epoch 3057, Loss: 0.010290616410202347, Final Batch Loss: 0.0011186780175194144\n",
      "Epoch 3058, Loss: 0.0010609281439428742, Final Batch Loss: 3.8146431506902445e-06\n",
      "Epoch 3059, Loss: 0.0018257977462781128, Final Batch Loss: 5.448377851280384e-05\n",
      "Epoch 3060, Loss: 0.02073963232942333, Final Batch Loss: 1.7964301150641404e-05\n",
      "Epoch 3061, Loss: 0.003739989562404844, Final Batch Loss: 1.0899053677349002e-06\n",
      "Epoch 3062, Loss: 0.002175612717110198, Final Batch Loss: 0.000498166773468256\n",
      "Epoch 3063, Loss: 0.0016447929847061005, Final Batch Loss: 3.1505257425124e-07\n",
      "Epoch 3064, Loss: 0.016443091564724455, Final Batch Loss: 3.545600702636875e-05\n",
      "Epoch 3065, Loss: 0.0008250641403719783, Final Batch Loss: 0.00014401327644009143\n",
      "Epoch 3066, Loss: 0.001933549680188662, Final Batch Loss: 5.7325891248183325e-05\n",
      "Epoch 3067, Loss: 0.000638808064195473, Final Batch Loss: 2.6225811780022923e-06\n",
      "Epoch 3068, Loss: 0.018211945361599646, Final Batch Loss: 3.908274720743066e-06\n",
      "Epoch 3069, Loss: 0.009310512977435792, Final Batch Loss: 4.257465207047062e-07\n",
      "Epoch 3070, Loss: 0.007295456939395706, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3071, Loss: 0.0017941375217560562, Final Batch Loss: 1.0268408914271276e-05\n",
      "Epoch 3072, Loss: 0.008634427751530893, Final Batch Loss: 0.007200352847576141\n",
      "Epoch 3073, Loss: 0.0019022117525508975, Final Batch Loss: 1.3623905203985487e-07\n",
      "Epoch 3074, Loss: 0.0010917797082186098, Final Batch Loss: 3.150527447814966e-07\n",
      "Epoch 3075, Loss: 0.0014575948916899506, Final Batch Loss: 2.294416117365472e-05\n",
      "Epoch 3076, Loss: 0.0066788291357795515, Final Batch Loss: 1.447540114440926e-07\n",
      "Epoch 3077, Loss: 0.001996558905375423, Final Batch Loss: 6.776738882763311e-05\n",
      "Epoch 3078, Loss: 0.029867295088479295, Final Batch Loss: 0.0\n",
      "Epoch 3079, Loss: 0.0031403280145241297, Final Batch Loss: 1.0174640010518488e-05\n",
      "Epoch 3080, Loss: 0.1052445408568019, Final Batch Loss: 0.0\n",
      "Epoch 3081, Loss: 0.001962140766408993, Final Batch Loss: 4.757509668706916e-05\n",
      "Epoch 3082, Loss: 0.0016099505664897151, Final Batch Loss: 8.147460903273895e-05\n",
      "Epoch 3083, Loss: 0.016056949214544147, Final Batch Loss: 0.00014634981926064938\n",
      "Epoch 3084, Loss: 0.005136568560374144, Final Batch Loss: 3.848653250315692e-06\n",
      "Epoch 3085, Loss: 0.08873169685102766, Final Batch Loss: 0.08753740787506104\n",
      "Epoch 3086, Loss: 0.0028398785002536897, Final Batch Loss: 7.19493300493923e-06\n",
      "Epoch 3087, Loss: 0.0020161682623438537, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3088, Loss: 0.006719201192026958, Final Batch Loss: 0.0021314946934580803\n",
      "Epoch 3089, Loss: 0.0014548998624377418, Final Batch Loss: 0.0\n",
      "Epoch 3090, Loss: 0.010144685934477593, Final Batch Loss: 4.2574637859615905e-07\n",
      "Epoch 3091, Loss: 0.0013735856352923292, Final Batch Loss: 1.5667335446778452e-06\n",
      "Epoch 3092, Loss: 0.0013788344588192558, Final Batch Loss: 2.9801960863551358e-06\n",
      "Epoch 3093, Loss: 0.002495672852091957, Final Batch Loss: 0.00011690827523125336\n",
      "Epoch 3094, Loss: 0.001190529760492609, Final Batch Loss: 1.5667345678593847e-06\n",
      "Epoch 3095, Loss: 0.02231418046744693, Final Batch Loss: 2.052082209047512e-06\n",
      "Epoch 3096, Loss: 0.0014187830020091496, Final Batch Loss: 8.392489689867944e-05\n",
      "Epoch 3097, Loss: 0.00616340114720515, Final Batch Loss: 1.7453512555221096e-05\n",
      "Epoch 3098, Loss: 0.001447959897632245, Final Batch Loss: 0.00031972205033525825\n",
      "Epoch 3099, Loss: 0.0038313164485686, Final Batch Loss: 2.1287350193688326e-07\n",
      "Epoch 3100, Loss: 0.0033754564701666823, Final Batch Loss: 0.0014019993832334876\n",
      "Epoch 3101, Loss: 0.004349469760200009, Final Batch Loss: 0.003262672573328018\n",
      "Epoch 3102, Loss: 0.0013870401489839423, Final Batch Loss: 4.764179539051838e-05\n",
      "Epoch 3103, Loss: 0.001956930912044186, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 3104, Loss: 0.0020171295198281314, Final Batch Loss: 1.7881373537420586e-07\n",
      "Epoch 3105, Loss: 0.0008385308031257921, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3106, Loss: 0.006891169592563529, Final Batch Loss: 0.004965218249708414\n",
      "Epoch 3107, Loss: 0.005260122066829354, Final Batch Loss: 0.0\n",
      "Epoch 3108, Loss: 0.0009435091020062458, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3109, Loss: 0.00285091319528874, Final Batch Loss: 3.671674494398758e-05\n",
      "Epoch 3110, Loss: 0.0018318822367291432, Final Batch Loss: 5.209252776694484e-05\n",
      "Epoch 3111, Loss: 0.0008025576353247743, Final Batch Loss: 0.00021348902373574674\n",
      "Epoch 3112, Loss: 0.011177825082995696, Final Batch Loss: 5.163103560335003e-05\n",
      "Epoch 3113, Loss: 0.0007935701451060595, Final Batch Loss: 1.7972795831155963e-05\n",
      "Epoch 3114, Loss: 0.004582123272744099, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3115, Loss: 0.026992090465032703, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3116, Loss: 0.0005966643802821636, Final Batch Loss: 2.01520488189999e-05\n",
      "Epoch 3117, Loss: 0.003987536335216646, Final Batch Loss: 2.171297410313855e-06\n",
      "Epoch 3118, Loss: 0.004647937538493352, Final Batch Loss: 3.2441246275993763e-06\n",
      "Epoch 3119, Loss: 0.006689318956755841, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3120, Loss: 0.002252623994657199, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3121, Loss: 0.028651369797444204, Final Batch Loss: 4.419057586346753e-05\n",
      "Epoch 3122, Loss: 0.026804926560544118, Final Batch Loss: 6.718087206536438e-06\n",
      "Epoch 3123, Loss: 0.015555065504713639, Final Batch Loss: 1.0899086646531941e-06\n",
      "Epoch 3124, Loss: 0.002126233433955349, Final Batch Loss: 0.0012515807757154107\n",
      "Epoch 3125, Loss: 0.0008428703076788224, Final Batch Loss: 8.47849078127183e-05\n",
      "Epoch 3126, Loss: 0.00255356241541449, Final Batch Loss: 0.00016299940762110054\n",
      "Epoch 3127, Loss: 0.0013172892431612127, Final Batch Loss: 0.0\n",
      "Epoch 3128, Loss: 0.008858537275045819, Final Batch Loss: 5.100281669001561e-06\n",
      "Epoch 3129, Loss: 0.0010495812291146933, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 3130, Loss: 0.0010847082594409585, Final Batch Loss: 1.3538665371015668e-06\n",
      "Epoch 3131, Loss: 0.00133974142118376, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3132, Loss: 0.00411525489835185, Final Batch Loss: 3.985059811384417e-05\n",
      "Epoch 3133, Loss: 0.0017578926736234735, Final Batch Loss: 2.809929640079645e-07\n",
      "Epoch 3134, Loss: 0.0023898311757761803, Final Batch Loss: 9.110937639889016e-07\n",
      "Epoch 3135, Loss: 0.0023141658393797115, Final Batch Loss: 1.2669123861996923e-05\n",
      "Epoch 3136, Loss: 0.001497044124164404, Final Batch Loss: 5.364398134588555e-07\n",
      "Epoch 3137, Loss: 0.011261969213592238, Final Batch Loss: 2.688021595531609e-05\n",
      "Epoch 3138, Loss: 0.0029713582210071365, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3139, Loss: 0.002174984780140221, Final Batch Loss: 2.7838716050609946e-05\n",
      "Epoch 3140, Loss: 0.0010637127228783072, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3141, Loss: 0.0010802404558489798, Final Batch Loss: 7.833714334992692e-07\n",
      "Epoch 3142, Loss: 0.0013350326840964044, Final Batch Loss: 1.2176311656730832e-06\n",
      "Epoch 3143, Loss: 0.0012400253424402763, Final Batch Loss: 2.0691029476438416e-06\n",
      "Epoch 3144, Loss: 0.023648790740480763, Final Batch Loss: 1.541095298307482e-05\n",
      "Epoch 3145, Loss: 0.008459775082883425, Final Batch Loss: 4.5736182073596865e-05\n",
      "Epoch 3146, Loss: 0.022929981595552817, Final Batch Loss: 4.563870788842905e-06\n",
      "Epoch 3147, Loss: 0.013170451653422788, Final Batch Loss: 0.0\n",
      "Epoch 3148, Loss: 0.005010880077634283, Final Batch Loss: 2.7843404950544937e-06\n",
      "Epoch 3149, Loss: 0.002983099575885717, Final Batch Loss: 4.155174337938661e-06\n",
      "Epoch 3150, Loss: 0.00217267584594083, Final Batch Loss: 2.706481609493494e-05\n",
      "Epoch 3151, Loss: 0.017958695293344817, Final Batch Loss: 1.447540114440926e-07\n",
      "Epoch 3152, Loss: 0.002373439165499036, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3153, Loss: 0.0014958442271861827, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3154, Loss: 0.0208081878208759, Final Batch Loss: 5.330159183358774e-06\n",
      "Epoch 3155, Loss: 0.02344977687710781, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3156, Loss: 0.0016316138267455926, Final Batch Loss: 2.0435849990008137e-07\n",
      "Epoch 3157, Loss: 0.0025868393285009006, Final Batch Loss: 1.1580276577660698e-06\n",
      "Epoch 3158, Loss: 0.002230560436146334, Final Batch Loss: 0.00019479673937894404\n",
      "Epoch 3159, Loss: 0.001920997296110727, Final Batch Loss: 0.0006585997180081904\n",
      "Epoch 3160, Loss: 0.001101383048990101, Final Batch Loss: 3.491122697596438e-07\n",
      "Epoch 3161, Loss: 0.0020459477236727253, Final Batch Loss: 0.0\n",
      "Epoch 3162, Loss: 0.011364429554305389, Final Batch Loss: 9.36585092858877e-06\n",
      "Epoch 3163, Loss: 0.00501158632687293, Final Batch Loss: 0.002013562014326453\n",
      "Epoch 3164, Loss: 0.002024792876909487, Final Batch Loss: 5.733100260840729e-05\n",
      "Epoch 3165, Loss: 0.001565521424652161, Final Batch Loss: 2.469332116561418e-07\n",
      "Epoch 3166, Loss: 0.0014834062494628597, Final Batch Loss: 0.0\n",
      "Epoch 3167, Loss: 0.002133813963155262, Final Batch Loss: 0.0009127550874836743\n",
      "Epoch 3168, Loss: 0.002258396459637879, Final Batch Loss: 3.8316497921186965e-06\n",
      "Epoch 3169, Loss: 0.0027780005726185664, Final Batch Loss: 5.279248966871819e-07\n",
      "Epoch 3170, Loss: 0.001514138923084829, Final Batch Loss: 0.00018138685845769942\n",
      "Epoch 3171, Loss: 0.0011244287416047882, Final Batch Loss: 5.6967921409523115e-05\n",
      "Epoch 3172, Loss: 0.001094492068659747, Final Batch Loss: 5.178618084755726e-05\n",
      "Epoch 3173, Loss: 0.0014509383329368575, Final Batch Loss: 2.7077041977463523e-06\n",
      "Epoch 3174, Loss: 0.002073432675388176, Final Batch Loss: 0.0\n",
      "Epoch 3175, Loss: 0.000979335239037482, Final Batch Loss: 2.8099276505599846e-07\n",
      "Epoch 3176, Loss: 0.001845830275019722, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3177, Loss: 0.0015035021042422159, Final Batch Loss: 1.0276866305503063e-05\n",
      "Epoch 3178, Loss: 0.0010560447528860095, Final Batch Loss: 2.6055470243591117e-06\n",
      "Epoch 3179, Loss: 0.0023386474949802505, Final Batch Loss: 2.0952504200977273e-05\n",
      "Epoch 3180, Loss: 0.0009087655424764307, Final Batch Loss: 5.790142267869669e-07\n",
      "Epoch 3181, Loss: 0.0017054879463103134, Final Batch Loss: 2.195671186200343e-05\n",
      "Epoch 3182, Loss: 0.003416753632336622, Final Batch Loss: 4.808500307262875e-05\n",
      "Epoch 3183, Loss: 0.00048537028987993835, Final Batch Loss: 3.831624326267047e-06\n",
      "Epoch 3184, Loss: 0.011681909469189122, Final Batch Loss: 0.007693914230912924\n",
      "Epoch 3185, Loss: 0.0007287557665733857, Final Batch Loss: 2.2138843291941157e-07\n",
      "Epoch 3186, Loss: 0.0018552342462498927, Final Batch Loss: 0.0015654403250664473\n",
      "Epoch 3187, Loss: 0.0008939930664837448, Final Batch Loss: 1.7966337964026025e-06\n",
      "Epoch 3188, Loss: 0.001007176002790544, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3189, Loss: 0.013829900428390829, Final Batch Loss: 0.0006374631775543094\n",
      "Epoch 3190, Loss: 0.0065257427595497575, Final Batch Loss: 2.128554115188308e-05\n",
      "Epoch 3191, Loss: 0.002049415611963923, Final Batch Loss: 2.90353955278988e-06\n",
      "Epoch 3192, Loss: 0.012164320032596265, Final Batch Loss: 1.7881377800677e-07\n",
      "Epoch 3193, Loss: 0.030645954648207407, Final Batch Loss: 0.0\n",
      "Epoch 3194, Loss: 0.020322889386839904, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 3195, Loss: 0.0014738923382537905, Final Batch Loss: 8.425690612057224e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3196, Loss: 0.0009220079193710262, Final Batch Loss: 2.0691115878435085e-06\n",
      "Epoch 3197, Loss: 0.0011099416260549333, Final Batch Loss: 0.00046060114982537925\n",
      "Epoch 3198, Loss: 0.001524136097941664, Final Batch Loss: 2.9055621780571528e-05\n",
      "Epoch 3199, Loss: 0.0006773196190010822, Final Batch Loss: 4.93865456974163e-07\n",
      "Epoch 3200, Loss: 0.006296737608018077, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 3201, Loss: 0.0012876477505869843, Final Batch Loss: 4.0020154301600996e-07\n",
      "Epoch 3202, Loss: 0.0011720179973053746, Final Batch Loss: 0.0\n",
      "Epoch 3203, Loss: 0.00029107849955245513, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3204, Loss: 0.002842102098156829, Final Batch Loss: 2.929082484115497e-06\n",
      "Epoch 3205, Loss: 0.00311079782966317, Final Batch Loss: 1.4049595620235777e-06\n",
      "Epoch 3206, Loss: 0.005458408340928145, Final Batch Loss: 0.0\n",
      "Epoch 3207, Loss: 0.023965868800587486, Final Batch Loss: 9.273191244574264e-05\n",
      "Epoch 3208, Loss: 0.0010312945225763315, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 3209, Loss: 0.011771967623644741, Final Batch Loss: 0.0\n",
      "Epoch 3210, Loss: 0.001228114678269776, Final Batch Loss: 1.1000470294675324e-05\n",
      "Epoch 3211, Loss: 0.0016515582517016014, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3212, Loss: 0.0023022080586088123, Final Batch Loss: 0.0004187051090411842\n",
      "Epoch 3213, Loss: 0.0038694323050663115, Final Batch Loss: 9.536709626445372e-07\n",
      "Epoch 3214, Loss: 0.0022577121344511397, Final Batch Loss: 0.0\n",
      "Epoch 3215, Loss: 0.037153696961468086, Final Batch Loss: 0.035452377051115036\n",
      "Epoch 3216, Loss: 0.09248781876092949, Final Batch Loss: 1.6178390183085867e-07\n",
      "Epoch 3217, Loss: 0.31396656469814843, Final Batch Loss: 6.139142442407319e-06\n",
      "Epoch 3218, Loss: 0.003794160377310618, Final Batch Loss: 2.0776174096681643e-06\n",
      "Epoch 3219, Loss: 0.02422799550445731, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3220, Loss: 0.024853661993134324, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 3221, Loss: 0.014649659395217896, Final Batch Loss: 0.0005549747147597373\n",
      "Epoch 3222, Loss: 0.031744957144837826, Final Batch Loss: 0.0021122104953974485\n",
      "Epoch 3223, Loss: 0.015576213365420699, Final Batch Loss: 0.0015114889247342944\n",
      "Epoch 3224, Loss: 0.004533280909527093, Final Batch Loss: 0.00018349968013353646\n",
      "Epoch 3225, Loss: 0.024869179629604332, Final Batch Loss: 0.0001306359627051279\n",
      "Epoch 3226, Loss: 0.010177299913266324, Final Batch Loss: 2.3644019165658392e-05\n",
      "Epoch 3227, Loss: 0.002368143928833888, Final Batch Loss: 2.569349635450635e-05\n",
      "Epoch 3228, Loss: 0.00723870043293573, Final Batch Loss: 0.003878577845171094\n",
      "Epoch 3229, Loss: 0.010264130043083242, Final Batch Loss: 1.0217934232059633e-07\n",
      "Epoch 3230, Loss: 0.003001484405899646, Final Batch Loss: 1.3198122132962453e-06\n",
      "Epoch 3231, Loss: 0.010030825142166577, Final Batch Loss: 0.00019945924577768892\n",
      "Epoch 3232, Loss: 0.0037447531665293354, Final Batch Loss: 2.511865886845044e-06\n",
      "Epoch 3233, Loss: 0.012160348356701434, Final Batch Loss: 0.0003819693811237812\n",
      "Epoch 3234, Loss: 0.00834163450053893, Final Batch Loss: 0.0008128537447191775\n",
      "Epoch 3235, Loss: 0.006526053708512336, Final Batch Loss: 0.0016894257860258222\n",
      "Epoch 3236, Loss: 0.002135484772225027, Final Batch Loss: 1.8040927898255177e-05\n",
      "Epoch 3237, Loss: 0.0039924654411152005, Final Batch Loss: 0.00017961479898076504\n",
      "Epoch 3238, Loss: 0.001333284258294043, Final Batch Loss: 9.366442554892274e-08\n",
      "Epoch 3239, Loss: 0.016012901935027912, Final Batch Loss: 0.002885623136535287\n",
      "Epoch 3240, Loss: 0.0036725396021211054, Final Batch Loss: 7.59507020120509e-06\n",
      "Epoch 3241, Loss: 0.03154438649653457, Final Batch Loss: 0.00047826385707594454\n",
      "Epoch 3242, Loss: 0.004002814348496031, Final Batch Loss: 8.51490767672658e-07\n",
      "Epoch 3243, Loss: 0.002784966811304912, Final Batch Loss: 0.0003525461652316153\n",
      "Epoch 3244, Loss: 0.016554775568693003, Final Batch Loss: 1.5326895663747564e-07\n",
      "Epoch 3245, Loss: 0.0019428024825174361, Final Batch Loss: 0.0001369654492009431\n",
      "Epoch 3246, Loss: 0.007921877288026735, Final Batch Loss: 0.0002563403977546841\n",
      "Epoch 3247, Loss: 0.02385703856270993, Final Batch Loss: 6.388549081748351e-05\n",
      "Epoch 3248, Loss: 0.006173466701994812, Final Batch Loss: 2.0435848568922665e-07\n",
      "Epoch 3249, Loss: 0.004145969266698302, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3250, Loss: 0.002005821661441587, Final Batch Loss: 4.7967012505978346e-05\n",
      "Epoch 3251, Loss: 0.005589457447058521, Final Batch Loss: 0.0036833921913057566\n",
      "Epoch 3252, Loss: 0.003051786850846838, Final Batch Loss: 8.902802073862404e-05\n",
      "Epoch 3253, Loss: 0.002376956235821126, Final Batch Loss: 5.721940397052094e-06\n",
      "Epoch 3254, Loss: 0.02591051656054333, Final Batch Loss: 0.00015878898557275534\n",
      "Epoch 3255, Loss: 0.002422294724965468, Final Batch Loss: 0.00020042758842464536\n",
      "Epoch 3256, Loss: 0.010945096219074912, Final Batch Loss: 0.00039196870056912303\n",
      "Epoch 3257, Loss: 0.015121261771128047, Final Batch Loss: 0.0002964861341752112\n",
      "Epoch 3258, Loss: 0.03293774372468761, Final Batch Loss: 2.782316914817784e-05\n",
      "Epoch 3259, Loss: 0.0386149162586662, Final Batch Loss: 0.0009177701431326568\n",
      "Epoch 3260, Loss: 0.0023980126820788428, Final Batch Loss: 3.414413640712155e-06\n",
      "Epoch 3261, Loss: 0.02083551586838439, Final Batch Loss: 0.0011871253373101354\n",
      "Epoch 3262, Loss: 0.0034545760427135974, Final Batch Loss: 0.0013889811234548688\n",
      "Epoch 3263, Loss: 0.004083419720700476, Final Batch Loss: 6.533126725116745e-05\n",
      "Epoch 3264, Loss: 0.0028798818893847056, Final Batch Loss: 3.421378642087802e-05\n",
      "Epoch 3265, Loss: 0.008642196669825353, Final Batch Loss: 0.005786319263279438\n",
      "Epoch 3266, Loss: 0.007065860627335496, Final Batch Loss: 0.00026858592173084617\n",
      "Epoch 3267, Loss: 0.007424220797474845, Final Batch Loss: 2.0180286810500547e-06\n",
      "Epoch 3268, Loss: 0.007379093316558283, Final Batch Loss: 4.0180057112593204e-05\n",
      "Epoch 3269, Loss: 0.013416894085821696, Final Batch Loss: 0.0006047951756045222\n",
      "Epoch 3270, Loss: 0.0010845314484733137, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3271, Loss: 0.0014371837041835533, Final Batch Loss: 1.8041015209746547e-05\n",
      "Epoch 3272, Loss: 0.011673559418341029, Final Batch Loss: 1.850943772296887e-05\n",
      "Epoch 3273, Loss: 0.0019625590794021264, Final Batch Loss: 0.0009711464517749846\n",
      "Epoch 3274, Loss: 0.0015221692787577012, Final Batch Loss: 9.366389690512733e-07\n",
      "Epoch 3275, Loss: 0.004692841350333765, Final Batch Loss: 0.0011810737196356058\n",
      "Epoch 3276, Loss: 0.0013176393215417193, Final Batch Loss: 2.6651498501450988e-06\n",
      "Epoch 3277, Loss: 0.0018371796886640368, Final Batch Loss: 1.937024171638768e-05\n",
      "Epoch 3278, Loss: 0.00190257002802241, Final Batch Loss: 4.0871643136597413e-07\n",
      "Epoch 3279, Loss: 0.0025108312402153388, Final Batch Loss: 0.00016938199405558407\n",
      "Epoch 3280, Loss: 0.0018374844852360184, Final Batch Loss: 6.215899475137121e-07\n",
      "Epoch 3281, Loss: 0.0038154963549459353, Final Batch Loss: 0.00046413246309384704\n",
      "Epoch 3282, Loss: 0.0017430380612495355, Final Batch Loss: 1.3614720955956727e-05\n",
      "Epoch 3283, Loss: 0.0408118610503152, Final Batch Loss: 0.02329140715301037\n",
      "Epoch 3284, Loss: 0.01588026131867082, Final Batch Loss: 3.2681480661267415e-05\n",
      "Epoch 3285, Loss: 0.010327682907558255, Final Batch Loss: 2.7247810407970974e-07\n",
      "Epoch 3286, Loss: 0.017270242336962838, Final Batch Loss: 0.0002547590702306479\n",
      "Epoch 3287, Loss: 0.0014453762196353637, Final Batch Loss: 0.0\n",
      "Epoch 3288, Loss: 0.0019420768658164889, Final Batch Loss: 0.0003741166729014367\n",
      "Epoch 3289, Loss: 0.009343158759293146, Final Batch Loss: 0.0003191516443621367\n",
      "Epoch 3290, Loss: 0.0009215945678988646, Final Batch Loss: 7.467220257240115e-06\n",
      "Epoch 3291, Loss: 0.013021378297707997, Final Batch Loss: 0.00017641605518292636\n",
      "Epoch 3292, Loss: 0.001105030947655905, Final Batch Loss: 5.884826532565057e-05\n",
      "Epoch 3293, Loss: 0.004007670620921999, Final Batch Loss: 0.0013489144621416926\n",
      "Epoch 3294, Loss: 0.003401897778530838, Final Batch Loss: 5.225556742516346e-05\n",
      "Epoch 3295, Loss: 0.002903713713749312, Final Batch Loss: 0.0005380564834922552\n",
      "Epoch 3296, Loss: 0.015244596525917586, Final Batch Loss: 5.704788236471359e-06\n",
      "Epoch 3297, Loss: 0.0039127710842876695, Final Batch Loss: 9.014253009809181e-05\n",
      "Epoch 3298, Loss: 0.006450164787565882, Final Batch Loss: 1.096651340048993e-05\n",
      "Epoch 3299, Loss: 0.004474461742574931, Final Batch Loss: 1.9063090803683735e-05\n",
      "Epoch 3300, Loss: 0.002847475538146682, Final Batch Loss: 0.0006836781976744533\n",
      "Epoch 3301, Loss: 0.010707311252190266, Final Batch Loss: 0.0071742055006325245\n",
      "Epoch 3302, Loss: 0.017569296551300795, Final Batch Loss: 1.5521787645411678e-05\n",
      "Epoch 3303, Loss: 0.004219031634420389, Final Batch Loss: 0.0008341309730894864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3304, Loss: 0.0013966574770165607, Final Batch Loss: 0.0\n",
      "Epoch 3305, Loss: 0.0016935707847416381, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3306, Loss: 0.0020373623992782086, Final Batch Loss: 0.0004568614822346717\n",
      "Epoch 3307, Loss: 0.0009928706938069354, Final Batch Loss: 2.72477990392872e-07\n",
      "Epoch 3308, Loss: 0.000850309181259945, Final Batch Loss: 0.0\n",
      "Epoch 3309, Loss: 0.005933850698056631, Final Batch Loss: 0.0\n",
      "Epoch 3310, Loss: 0.003158022641628122, Final Batch Loss: 3.0142393825371983e-06\n",
      "Epoch 3311, Loss: 0.007261730293976143, Final Batch Loss: 0.0007520199869759381\n",
      "Epoch 3312, Loss: 0.010768583308422564, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3313, Loss: 0.010735237012600152, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3314, Loss: 0.002118512464122091, Final Batch Loss: 1.7881383485018887e-07\n",
      "Epoch 3315, Loss: 0.002793748688418418, Final Batch Loss: 7.484348316211253e-06\n",
      "Epoch 3316, Loss: 0.0007517330377595499, Final Batch Loss: 3.6487144825514406e-05\n",
      "Epoch 3317, Loss: 0.0023125019506551325, Final Batch Loss: 0.00033251880086027086\n",
      "Epoch 3318, Loss: 0.0034677651347010396, Final Batch Loss: 8.923425775719807e-05\n",
      "Epoch 3319, Loss: 0.0013708362203033175, Final Batch Loss: 0.00021443385048769414\n",
      "Epoch 3320, Loss: 0.001788467838196084, Final Batch Loss: 0.0\n",
      "Epoch 3321, Loss: 0.0014376007409779845, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3322, Loss: 0.02311675489602294, Final Batch Loss: 1.413468112332339e-06\n",
      "Epoch 3323, Loss: 0.01711371230834402, Final Batch Loss: 3.4911266766357585e-07\n",
      "Epoch 3324, Loss: 0.023392653103655903, Final Batch Loss: 0.00023042743850965053\n",
      "Epoch 3325, Loss: 0.0016149132161444868, Final Batch Loss: 8.718899152881932e-06\n",
      "Epoch 3326, Loss: 0.013649586006042824, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3327, Loss: 0.0015946023386277375, Final Batch Loss: 5.900631549593527e-06\n",
      "Epoch 3328, Loss: 0.04037839975660518, Final Batch Loss: 7.748561756670824e-07\n",
      "Epoch 3329, Loss: 0.001882697800169808, Final Batch Loss: 1.0558459280218813e-06\n",
      "Epoch 3330, Loss: 0.003963852075685281, Final Batch Loss: 5.783569213235751e-05\n",
      "Epoch 3331, Loss: 0.0016452801760973301, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3332, Loss: 0.006524967040604679, Final Batch Loss: 1.9930721464334056e-05\n",
      "Epoch 3333, Loss: 0.024258710081149104, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 3334, Loss: 0.0017051986360456795, Final Batch Loss: 0.00024739018408581614\n",
      "Epoch 3335, Loss: 0.007522576204394227, Final Batch Loss: 4.5129087311579497e-07\n",
      "Epoch 3336, Loss: 0.002071599931213086, Final Batch Loss: 1.3623909467241901e-07\n",
      "Epoch 3337, Loss: 0.006595681314914614, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3338, Loss: 0.00397624347533565, Final Batch Loss: 0.0010134183103218675\n",
      "Epoch 3339, Loss: 0.0020749259856529534, Final Batch Loss: 0.0\n",
      "Epoch 3340, Loss: 0.002195693741668947, Final Batch Loss: 9.937693539541215e-05\n",
      "Epoch 3341, Loss: 0.0021887454686293495, Final Batch Loss: 6.243890675250441e-05\n",
      "Epoch 3342, Loss: 0.0055001121436362155, Final Batch Loss: 0.0007993726176209748\n",
      "Epoch 3343, Loss: 0.00247554543602746, Final Batch Loss: 0.0003875860129483044\n",
      "Epoch 3344, Loss: 0.02047584785032086, Final Batch Loss: 7.161955727497116e-05\n",
      "Epoch 3345, Loss: 0.0021766081408713944, Final Batch Loss: 5.618507930194028e-05\n",
      "Epoch 3346, Loss: 0.00556162754946854, Final Batch Loss: 0.0006175790331326425\n",
      "Epoch 3347, Loss: 0.000739910377888009, Final Batch Loss: 0.0\n",
      "Epoch 3348, Loss: 0.0011012347968062386, Final Batch Loss: 5.648346268571913e-05\n",
      "Epoch 3349, Loss: 0.001998873395285372, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3350, Loss: 0.006842682456408511, Final Batch Loss: 0.004109746776521206\n",
      "Epoch 3351, Loss: 0.0027947087583015673, Final Batch Loss: 0.00020622512965928763\n",
      "Epoch 3352, Loss: 0.0006162217327982944, Final Batch Loss: 5.2365071496751625e-06\n",
      "Epoch 3353, Loss: 0.017087396805926858, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 3354, Loss: 0.002133707517714356, Final Batch Loss: 8.327149771503173e-06\n",
      "Epoch 3355, Loss: 0.004632525501278906, Final Batch Loss: 1.1835714985863888e-06\n",
      "Epoch 3356, Loss: 0.02308675833455709, Final Batch Loss: 0.0017585400491952896\n",
      "Epoch 3357, Loss: 0.0012660119280099025, Final Batch Loss: 1.932879740706994e-06\n",
      "Epoch 3358, Loss: 0.0045779241609125165, Final Batch Loss: 2.864947782654781e-05\n",
      "Epoch 3359, Loss: 0.0022276257035755975, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3360, Loss: 0.00824898243899952, Final Batch Loss: 4.265934876457322e-06\n",
      "Epoch 3361, Loss: 0.012539885869045975, Final Batch Loss: 0.001243320875801146\n",
      "Epoch 3362, Loss: 0.0019822436223861928, Final Batch Loss: 1.192091971802256e-07\n",
      "Epoch 3363, Loss: 0.0031298232643166557, Final Batch Loss: 0.00010035540617536753\n",
      "Epoch 3364, Loss: 0.0031882756666163914, Final Batch Loss: 0.0009723066468723118\n",
      "Epoch 3365, Loss: 0.0017539698640263168, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 3366, Loss: 0.028071323424228467, Final Batch Loss: 0.0008947705500759184\n",
      "Epoch 3367, Loss: 0.0015467945080445133, Final Batch Loss: 1.0899051403612248e-06\n",
      "Epoch 3368, Loss: 0.0032907212098507443, Final Batch Loss: 7.799268132657744e-06\n",
      "Epoch 3369, Loss: 0.01146187095686102, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3370, Loss: 0.0033527300838613883, Final Batch Loss: 0.00016668155149091035\n",
      "Epoch 3371, Loss: 0.006474518462994183, Final Batch Loss: 5.534696470022027e-07\n",
      "Epoch 3372, Loss: 0.0016041646886151284, Final Batch Loss: 0.0\n",
      "Epoch 3373, Loss: 0.007397126762953121, Final Batch Loss: 0.0\n",
      "Epoch 3374, Loss: 0.016183873949103145, Final Batch Loss: 3.90825653084903e-06\n",
      "Epoch 3375, Loss: 0.0016534488677280024, Final Batch Loss: 0.0\n",
      "Epoch 3376, Loss: 0.009363256273218212, Final Batch Loss: 4.768355665873969e-07\n",
      "Epoch 3377, Loss: 0.0014763646197799574, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3378, Loss: 0.002761327396001434, Final Batch Loss: 1.6866539226612076e-05\n",
      "Epoch 3379, Loss: 0.0014662396570201963, Final Batch Loss: 0.0003471511590760201\n",
      "Epoch 3380, Loss: 0.013098768790118953, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3381, Loss: 0.0006753689910965477, Final Batch Loss: 2.1627809019264532e-06\n",
      "Epoch 3382, Loss: 0.0019852426006927715, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3383, Loss: 0.0009202177192548788, Final Batch Loss: 4.002016851245571e-07\n",
      "Epoch 3384, Loss: 0.0032407621908987494, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 3385, Loss: 0.0026135212831945864, Final Batch Loss: 5.449549576042045e-07\n",
      "Epoch 3386, Loss: 0.004862439489443204, Final Batch Loss: 1.5120973330340348e-05\n",
      "Epoch 3387, Loss: 0.0013366297508241587, Final Batch Loss: 6.726777996846067e-07\n",
      "Epoch 3388, Loss: 0.0019610614422163053, Final Batch Loss: 2.758790742518613e-06\n",
      "Epoch 3389, Loss: 0.0010809476308963895, Final Batch Loss: 5.023804874326743e-07\n",
      "Epoch 3390, Loss: 0.020809272205951856, Final Batch Loss: 0.00019889406394213438\n",
      "Epoch 3391, Loss: 0.008245165925472975, Final Batch Loss: 0.006217379588633776\n",
      "Epoch 3392, Loss: 0.0005346190409056817, Final Batch Loss: 2.6396301677777956e-07\n",
      "Epoch 3393, Loss: 0.002581223930697263, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3394, Loss: 0.01188280749192927, Final Batch Loss: 0.00012514884292613715\n",
      "Epoch 3395, Loss: 0.0007972586936375592, Final Batch Loss: 1.3929804481449537e-05\n",
      "Epoch 3396, Loss: 0.002850924494850915, Final Batch Loss: 9.19112135306932e-05\n",
      "Epoch 3397, Loss: 0.0016126992995850742, Final Batch Loss: 0.0\n",
      "Epoch 3398, Loss: 0.0022465899371439946, Final Batch Loss: 1.4475402565494733e-07\n",
      "Epoch 3399, Loss: 0.0005508727670360258, Final Batch Loss: 4.0871671558306844e-07\n",
      "Epoch 3400, Loss: 0.0018699693464441225, Final Batch Loss: 0.0008483949350193143\n",
      "Epoch 3401, Loss: 0.002158311437398197, Final Batch Loss: 3.0653771432298527e-07\n",
      "Epoch 3402, Loss: 0.0006041869855835102, Final Batch Loss: 6.995976582402363e-05\n",
      "Epoch 3403, Loss: 0.0008006485375346983, Final Batch Loss: 2.1287340246090025e-07\n",
      "Epoch 3404, Loss: 0.005071593905086047, Final Batch Loss: 2.6911528038908727e-05\n",
      "Epoch 3405, Loss: 0.004228558822433115, Final Batch Loss: 0.0\n",
      "Epoch 3406, Loss: 0.005263569873477536, Final Batch Loss: 6.300869699771283e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3407, Loss: 0.0011145927556981405, Final Batch Loss: 5.875291435586405e-07\n",
      "Epoch 3408, Loss: 0.013016762610732258, Final Batch Loss: 5.491931460710475e-06\n",
      "Epoch 3409, Loss: 0.000636031190094144, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3410, Loss: 0.0018077520071528852, Final Batch Loss: 0.0\n",
      "Epoch 3411, Loss: 0.0027899377928406466, Final Batch Loss: 0.00011708671081578359\n",
      "Epoch 3412, Loss: 0.002592000806771466, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 3413, Loss: 0.0005070163824711926, Final Batch Loss: 0.0\n",
      "Epoch 3414, Loss: 0.0011384945319150575, Final Batch Loss: 0.0\n",
      "Epoch 3415, Loss: 0.0013691343519894872, Final Batch Loss: 0.0003373550425749272\n",
      "Epoch 3416, Loss: 0.0035066693978542673, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 3417, Loss: 0.003512767474013856, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 3418, Loss: 0.0010064545150498816, Final Batch Loss: 1.89880859124969e-06\n",
      "Epoch 3419, Loss: 0.015835732303717265, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3420, Loss: 0.0006210131281036979, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 3421, Loss: 0.0019701974524650723, Final Batch Loss: 0.0003987723321188241\n",
      "Epoch 3422, Loss: 0.0075557965842563135, Final Batch Loss: 2.1712853595090564e-06\n",
      "Epoch 3423, Loss: 0.040601993299787864, Final Batch Loss: 2.9577977329608984e-05\n",
      "Epoch 3424, Loss: 0.0036354215189930983, Final Batch Loss: 0.00015580833132844418\n",
      "Epoch 3425, Loss: 0.0035970070093753748, Final Batch Loss: 0.0001096224514185451\n",
      "Epoch 3426, Loss: 0.031157723075011745, Final Batch Loss: 0.0024336304049938917\n",
      "Epoch 3427, Loss: 0.0013418357525551983, Final Batch Loss: 3.3548244573466945e-06\n",
      "Epoch 3428, Loss: 0.004474748573557008, Final Batch Loss: 0.0\n",
      "Epoch 3429, Loss: 0.0038750218809582293, Final Batch Loss: 0.0005633694818243384\n",
      "Epoch 3430, Loss: 0.0014837535600236151, Final Batch Loss: 0.0004365535860415548\n",
      "Epoch 3431, Loss: 0.000893326253120108, Final Batch Loss: 1.447539972332379e-07\n",
      "Epoch 3432, Loss: 0.0014730423072251142, Final Batch Loss: 6.0198153732926585e-06\n",
      "Epoch 3433, Loss: 0.007298392250959296, Final Batch Loss: 0.005947177764028311\n",
      "Epoch 3434, Loss: 0.0005706966845266948, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3435, Loss: 0.0018953588173644675, Final Batch Loss: 3.312258286314318e-06\n",
      "Epoch 3436, Loss: 0.005005571305218837, Final Batch Loss: 3.116428842986352e-06\n",
      "Epoch 3437, Loss: 0.0051133662174223105, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3438, Loss: 0.00074819666301984, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3439, Loss: 0.0829955732660892, Final Batch Loss: 0.08191613107919693\n",
      "Epoch 3440, Loss: 0.021183561618897784, Final Batch Loss: 5.194103209760215e-07\n",
      "Epoch 3441, Loss: 0.1298860616516322, Final Batch Loss: 0.0\n",
      "Epoch 3442, Loss: 0.16936688125133514, Final Batch Loss: 0.030752582475543022\n",
      "Epoch 3443, Loss: 0.03811799771119695, Final Batch Loss: 9.97038932837313e-06\n",
      "Epoch 3444, Loss: 0.03611366148106754, Final Batch Loss: 0.0\n",
      "Epoch 3445, Loss: 0.04699175425685098, Final Batch Loss: 9.263857464247849e-06\n",
      "Epoch 3446, Loss: 0.006124830659246072, Final Batch Loss: 0.00018715221085585654\n",
      "Epoch 3447, Loss: 0.031449886917471304, Final Batch Loss: 2.741760908975266e-06\n",
      "Epoch 3448, Loss: 0.00425252020068001, Final Batch Loss: 5.9514917666092515e-05\n",
      "Epoch 3449, Loss: 0.008335478266275231, Final Batch Loss: 4.087167724264873e-07\n",
      "Epoch 3450, Loss: 0.008081370790023357, Final Batch Loss: 8.78426362760365e-05\n",
      "Epoch 3451, Loss: 0.004396779333617928, Final Batch Loss: 1.873286947784436e-07\n",
      "Epoch 3452, Loss: 0.020248515975254122, Final Batch Loss: 0.0002389660367043689\n",
      "Epoch 3453, Loss: 0.002959574805572629, Final Batch Loss: 0.0007622369448654354\n",
      "Epoch 3454, Loss: 0.01785355291212909, Final Batch Loss: 0.0010815883288159966\n",
      "Epoch 3455, Loss: 0.00830657861661166, Final Batch Loss: 8.067601447692141e-05\n",
      "Epoch 3456, Loss: 0.014365980197908357, Final Batch Loss: 0.0012425115564838052\n",
      "Epoch 3457, Loss: 0.007803928026987705, Final Batch Loss: 8.412995521211997e-05\n",
      "Epoch 3458, Loss: 0.004452716299283566, Final Batch Loss: 3.439958391027176e-06\n",
      "Epoch 3459, Loss: 0.0033608764642849565, Final Batch Loss: 0.000666834122966975\n",
      "Epoch 3460, Loss: 0.004281443820673303, Final Batch Loss: 6.019880402163835e-06\n",
      "Epoch 3461, Loss: 0.001805177322239615, Final Batch Loss: 4.265567258698866e-05\n",
      "Epoch 3462, Loss: 0.002936549160949653, Final Batch Loss: 5.3386866056825966e-06\n",
      "Epoch 3463, Loss: 0.001990447869758327, Final Batch Loss: 3.66141904351025e-07\n",
      "Epoch 3464, Loss: 0.0013468391516653355, Final Batch Loss: 1.718981729936786e-05\n",
      "Epoch 3465, Loss: 0.004711467991000973, Final Batch Loss: 0.0002025141875492409\n",
      "Epoch 3466, Loss: 0.003681352231069468, Final Batch Loss: 0.0012353855418041348\n",
      "Epoch 3467, Loss: 0.003533317687924864, Final Batch Loss: 2.205352302553365e-06\n",
      "Epoch 3468, Loss: 0.0033636073203524575, Final Batch Loss: 0.0001268016785616055\n",
      "Epoch 3469, Loss: 0.0029718449688971305, Final Batch Loss: 2.0350446447992e-06\n",
      "Epoch 3470, Loss: 0.0009380427093361732, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 3471, Loss: 0.0025661065017175133, Final Batch Loss: 2.5544511572661577e-06\n",
      "Epoch 3472, Loss: 0.00341951433892973, Final Batch Loss: 4.6064387788646854e-06\n",
      "Epoch 3473, Loss: 0.01334057975327596, Final Batch Loss: 0.0\n",
      "Epoch 3474, Loss: 0.007732937956461683, Final Batch Loss: 0.00012855391832999885\n",
      "Epoch 3475, Loss: 0.010437166743713533, Final Batch Loss: 2.486343646523892e-06\n",
      "Epoch 3476, Loss: 0.005938815480476478, Final Batch Loss: 0.0\n",
      "Epoch 3477, Loss: 0.025606175215216354, Final Batch Loss: 0.00016326640616171062\n",
      "Epoch 3478, Loss: 0.001347989818896167, Final Batch Loss: 0.00012172865535831079\n",
      "Epoch 3479, Loss: 0.0019258332176832482, Final Batch Loss: 4.9148402467835695e-05\n",
      "Epoch 3480, Loss: 0.018454213852237444, Final Batch Loss: 5.43408386874944e-05\n",
      "Epoch 3481, Loss: 0.017733613611198962, Final Batch Loss: 0.0005666062352247536\n",
      "Epoch 3482, Loss: 0.005362038253224455, Final Batch Loss: 0.00021968809596728534\n",
      "Epoch 3483, Loss: 0.026143661816604435, Final Batch Loss: 0.0018424865556880832\n",
      "Epoch 3484, Loss: 0.007693000959989149, Final Batch Loss: 0.0\n",
      "Epoch 3485, Loss: 0.012942231453571651, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3486, Loss: 0.013071573022216398, Final Batch Loss: 3.022743157998775e-06\n",
      "Epoch 3487, Loss: 0.002619081006308477, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 3488, Loss: 0.01552529329637764, Final Batch Loss: 0.0010572223691269755\n",
      "Epoch 3489, Loss: 0.005661221754394319, Final Batch Loss: 1.0388197324573412e-06\n",
      "Epoch 3490, Loss: 0.0017219767742062686, Final Batch Loss: 1.0745077815954573e-05\n",
      "Epoch 3491, Loss: 0.005070419749245048, Final Batch Loss: 0.0010915211169049144\n",
      "Epoch 3492, Loss: 0.021034284345660126, Final Batch Loss: 0.00045022001722827554\n",
      "Epoch 3493, Loss: 0.004431032462889561, Final Batch Loss: 0.0\n",
      "Epoch 3494, Loss: 0.0033470746857346967, Final Batch Loss: 0.002140565076842904\n",
      "Epoch 3495, Loss: 0.0014829180353022053, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3496, Loss: 0.005022227006520552, Final Batch Loss: 0.0003783282882068306\n",
      "Epoch 3497, Loss: 0.02307657322603518, Final Batch Loss: 3.576271865313174e-07\n",
      "Epoch 3498, Loss: 0.0027300169622321846, Final Batch Loss: 2.8700729671982117e-05\n",
      "Epoch 3499, Loss: 0.0006658061940925109, Final Batch Loss: 2.0094996671105037e-06\n",
      "Epoch 3500, Loss: 0.019387909225770272, Final Batch Loss: 0.007366938050836325\n",
      "Epoch 3501, Loss: 0.005150134814357443, Final Batch Loss: 0.00017355711315758526\n",
      "Epoch 3502, Loss: 0.003579908752726624, Final Batch Loss: 6.786126505176071e-06\n",
      "Epoch 3503, Loss: 0.003139978147430611, Final Batch Loss: 7.152521561692993e-07\n",
      "Epoch 3504, Loss: 0.07981128069513943, Final Batch Loss: 0.07568907737731934\n",
      "Epoch 3505, Loss: 0.0028436328431205027, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3506, Loss: 0.001103239082908658, Final Batch Loss: 8.089172069958295e-07\n",
      "Epoch 3507, Loss: 0.002791227627305659, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 3508, Loss: 0.011551598323938705, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3509, Loss: 0.006443915727572858, Final Batch Loss: 9.451531468585017e-07\n",
      "Epoch 3510, Loss: 0.04886966149206273, Final Batch Loss: 0.03244342654943466\n",
      "Epoch 3511, Loss: 0.00802158922306262, Final Batch Loss: 0.0008101466810330749\n",
      "Epoch 3512, Loss: 0.11695972746885275, Final Batch Loss: 2.2990344916706817e-07\n",
      "Epoch 3513, Loss: 0.0479156747772187, Final Batch Loss: 8.514948746096707e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3514, Loss: 0.023967929068021476, Final Batch Loss: 0.0031158237252384424\n",
      "Epoch 3515, Loss: 0.020040470271020183, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 3516, Loss: 0.007275231141761651, Final Batch Loss: 1.7285229887420428e-06\n",
      "Epoch 3517, Loss: 0.009426743366930168, Final Batch Loss: 3.472403477644548e-05\n",
      "Epoch 3518, Loss: 0.01164410370357416, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 3519, Loss: 0.006134902733720082, Final Batch Loss: 5.67073129786877e-06\n",
      "Epoch 3520, Loss: 0.011894529103301466, Final Batch Loss: 0.0\n",
      "Epoch 3521, Loss: 0.0026748296454570664, Final Batch Loss: 0.00036696900497190654\n",
      "Epoch 3522, Loss: 0.08463229317608523, Final Batch Loss: 1.362390804615643e-07\n",
      "Epoch 3523, Loss: 0.0018402950247811134, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3524, Loss: 0.0019014904974028468, Final Batch Loss: 0.00012347767187748104\n",
      "Epoch 3525, Loss: 0.0012261882484381204, Final Batch Loss: 9.612977919459809e-06\n",
      "Epoch 3526, Loss: 0.012265434199889569, Final Batch Loss: 4.819371042685816e-06\n",
      "Epoch 3527, Loss: 0.5853179247060325, Final Batch Loss: 0.5847673416137695\n",
      "Epoch 3528, Loss: 0.02268393855092654, Final Batch Loss: 6.462600595114054e-06\n",
      "Epoch 3529, Loss: 0.08283482880506199, Final Batch Loss: 0.00019833310216199607\n",
      "Epoch 3530, Loss: 0.08254321002601728, Final Batch Loss: 3.0653751537101925e-07\n",
      "Epoch 3531, Loss: 0.06365830660797656, Final Batch Loss: 0.0024318285286426544\n",
      "Epoch 3532, Loss: 0.025385670036484953, Final Batch Loss: 4.830696707358584e-05\n",
      "Epoch 3533, Loss: 0.004283476638192951, Final Batch Loss: 6.198754817887675e-06\n",
      "Epoch 3534, Loss: 0.03680386028281646, Final Batch Loss: 0.02844761498272419\n",
      "Epoch 3535, Loss: 0.010248963226331398, Final Batch Loss: 0.0012796001974493265\n",
      "Epoch 3536, Loss: 0.028127074971848742, Final Batch Loss: 1.63485208304337e-06\n",
      "Epoch 3537, Loss: 0.003306268496089615, Final Batch Loss: 0.0007559958612546325\n",
      "Epoch 3538, Loss: 0.002664404530378306, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 3539, Loss: 0.0018976878200192004, Final Batch Loss: 0.0001554273476358503\n",
      "Epoch 3540, Loss: 0.014817436020621244, Final Batch Loss: 6.002911050018156e-06\n",
      "Epoch 3541, Loss: 0.00855494382994948, Final Batch Loss: 8.906859875423834e-05\n",
      "Epoch 3542, Loss: 0.021373960929583546, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 3543, Loss: 0.011873342315084301, Final Batch Loss: 0.0003453327517490834\n",
      "Epoch 3544, Loss: 0.006192705266585108, Final Batch Loss: 0.0023319425527006388\n",
      "Epoch 3545, Loss: 0.00277933782490436, Final Batch Loss: 0.0\n",
      "Epoch 3546, Loss: 0.003914332068234216, Final Batch Loss: 3.2196294341702014e-05\n",
      "Epoch 3547, Loss: 0.003004794823937118, Final Batch Loss: 0.0004220201226416975\n",
      "Epoch 3548, Loss: 0.013553986638726201, Final Batch Loss: 1.515502663096413e-05\n",
      "Epoch 3549, Loss: 0.002336328718229197, Final Batch Loss: 0.0007024889928288758\n",
      "Epoch 3550, Loss: 0.017361867284535037, Final Batch Loss: 2.5885012746584835e-06\n",
      "Epoch 3551, Loss: 0.018798934033839032, Final Batch Loss: 0.0002476733934599906\n",
      "Epoch 3552, Loss: 0.0020041886766968275, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3553, Loss: 0.0018584991048555821, Final Batch Loss: 0.0005822327802889049\n",
      "Epoch 3554, Loss: 0.0048457750817760825, Final Batch Loss: 0.0005572965019382536\n",
      "Epoch 3555, Loss: 0.0043535665001854795, Final Batch Loss: 2.418205667709117e-06\n",
      "Epoch 3556, Loss: 0.009065297389618365, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3557, Loss: 0.006239594885300903, Final Batch Loss: 1.3410267456492875e-05\n",
      "Epoch 3558, Loss: 0.007420261099468917, Final Batch Loss: 0.0056267715990543365\n",
      "Epoch 3559, Loss: 0.0012905595067422837, Final Batch Loss: 2.6331919798394665e-05\n",
      "Epoch 3560, Loss: 0.005401128436801628, Final Batch Loss: 1.7881169469546876e-06\n",
      "Epoch 3561, Loss: 0.0011879221128765494, Final Batch Loss: 6.989289249759167e-05\n",
      "Epoch 3562, Loss: 0.005078720772871748, Final Batch Loss: 0.0021522166207432747\n",
      "Epoch 3563, Loss: 0.0033215191870112903, Final Batch Loss: 0.0\n",
      "Epoch 3564, Loss: 0.006187657986117756, Final Batch Loss: 4.853504265156516e-07\n",
      "Epoch 3565, Loss: 0.0018453953143762192, Final Batch Loss: 2.937956560344901e-05\n",
      "Epoch 3566, Loss: 0.02190436446107924, Final Batch Loss: 0.0\n",
      "Epoch 3567, Loss: 0.003801528840995161, Final Batch Loss: 2.8468970413086936e-05\n",
      "Epoch 3568, Loss: 0.0025096813624259084, Final Batch Loss: 0.0\n",
      "Epoch 3569, Loss: 0.00869427488942165, Final Batch Loss: 0.00017183898307848722\n",
      "Epoch 3570, Loss: 0.002738470706390217, Final Batch Loss: 0.0\n",
      "Epoch 3571, Loss: 0.010695656071902704, Final Batch Loss: 2.145746975656948e-06\n",
      "Epoch 3572, Loss: 0.0030135717824464336, Final Batch Loss: 8.514907108292391e-07\n",
      "Epoch 3573, Loss: 0.004488363687414676, Final Batch Loss: 0.0\n",
      "Epoch 3574, Loss: 0.0034610210059327073, Final Batch Loss: 6.311978359008208e-05\n",
      "Epoch 3575, Loss: 0.003276607798539999, Final Batch Loss: 3.2356743417949474e-07\n",
      "Epoch 3576, Loss: 0.002873269226256525, Final Batch Loss: 1.370895915897563e-06\n",
      "Epoch 3577, Loss: 0.007988574492628686, Final Batch Loss: 0.0059866649098694324\n",
      "Epoch 3578, Loss: 0.015661390625609783, Final Batch Loss: 3.940931856050156e-05\n",
      "Epoch 3579, Loss: 0.006855738472950179, Final Batch Loss: 1.0532254236750305e-05\n",
      "Epoch 3580, Loss: 0.015776341297168983, Final Batch Loss: 0.0001841452030930668\n",
      "Epoch 3581, Loss: 0.00111842023875397, Final Batch Loss: 3.4058987239404814e-06\n",
      "Epoch 3582, Loss: 0.0034334094296397666, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3583, Loss: 0.0012491618072090205, Final Batch Loss: 7.26699799997732e-05\n",
      "Epoch 3584, Loss: 0.013299623637294644, Final Batch Loss: 2.358601932428428e-06\n",
      "Epoch 3585, Loss: 0.0018688591090949558, Final Batch Loss: 1.7114845149990288e-06\n",
      "Epoch 3586, Loss: 0.02173050379496999, Final Batch Loss: 0.0004311707161832601\n",
      "Epoch 3587, Loss: 0.002016583283420914, Final Batch Loss: 3.295223450550111e-06\n",
      "Epoch 3588, Loss: 0.005754871064482359, Final Batch Loss: 2.7332605441188207e-06\n",
      "Epoch 3589, Loss: 0.004793450922338849, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3590, Loss: 0.001324612407188397, Final Batch Loss: 7.101926894392818e-05\n",
      "Epoch 3591, Loss: 0.007994824027719005, Final Batch Loss: 2.89502395389718e-06\n",
      "Epoch 3592, Loss: 0.019932842605545176, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 3593, Loss: 0.0028626230196096003, Final Batch Loss: 9.828852489590645e-05\n",
      "Epoch 3594, Loss: 0.0008413391354089583, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3595, Loss: 0.010885581254115095, Final Batch Loss: 2.13622952287551e-05\n",
      "Epoch 3596, Loss: 0.001271244567760732, Final Batch Loss: 8.233614062191918e-05\n",
      "Epoch 3597, Loss: 0.028310391320033546, Final Batch Loss: 2.2138853239539458e-07\n",
      "Epoch 3598, Loss: 0.014339317654957995, Final Batch Loss: 4.6676308556925505e-05\n",
      "Epoch 3599, Loss: 0.04985151670371124, Final Batch Loss: 1.0055466191261075e-05\n",
      "Epoch 3600, Loss: 0.009891852816508617, Final Batch Loss: 3.079194721067324e-05\n",
      "Epoch 3601, Loss: 0.0029343989361052536, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 3602, Loss: 0.001267356952666887, Final Batch Loss: 0.00010843855852726847\n",
      "Epoch 3603, Loss: 0.0025664871300250525, Final Batch Loss: 1.7641288650338538e-05\n",
      "Epoch 3604, Loss: 0.003745507953510696, Final Batch Loss: 2.8099276505599846e-07\n",
      "Epoch 3605, Loss: 0.0018154099442249105, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3606, Loss: 0.019419375021243468, Final Batch Loss: 0.0006801275885663927\n",
      "Epoch 3607, Loss: 0.0014991392880379095, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3608, Loss: 0.001319962242632755, Final Batch Loss: 1.1715697837644257e-05\n",
      "Epoch 3609, Loss: 0.005875957429452683, Final Batch Loss: 1.0046938768937252e-05\n",
      "Epoch 3610, Loss: 0.0050502766888289585, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3611, Loss: 0.01170080353767844, Final Batch Loss: 4.326986527303234e-05\n",
      "Epoch 3612, Loss: 0.0012003721120024125, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3613, Loss: 0.0006554987553499814, Final Batch Loss: 9.79212472884683e-07\n",
      "Epoch 3614, Loss: 0.002438077570332098, Final Batch Loss: 1.4551287677022628e-05\n",
      "Epoch 3615, Loss: 0.00455679954234256, Final Batch Loss: 3.0823450742900604e-06\n",
      "Epoch 3616, Loss: 0.015538013348759705, Final Batch Loss: 3.2441289476992097e-06\n",
      "Epoch 3617, Loss: 0.0024346508316739346, Final Batch Loss: 1.0659920917532872e-05\n",
      "Epoch 3618, Loss: 0.00315517328272108, Final Batch Loss: 0.00013473180297296494\n",
      "Epoch 3619, Loss: 0.010224553348962218, Final Batch Loss: 0.0095255421474576\n",
      "Epoch 3620, Loss: 0.0026973816229656222, Final Batch Loss: 1.4014945008966606e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3621, Loss: 0.0008754221099778192, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3622, Loss: 0.00083188884309493, Final Batch Loss: 0.0002594941761344671\n",
      "Epoch 3623, Loss: 0.0011371614491508808, Final Batch Loss: 0.0\n",
      "Epoch 3624, Loss: 0.0019507147790136514, Final Batch Loss: 2.9276909117470495e-05\n",
      "Epoch 3625, Loss: 0.0005626926931654452, Final Batch Loss: 9.400139788340311e-06\n",
      "Epoch 3626, Loss: 0.001276351758860983, Final Batch Loss: 0.00012109101953683421\n",
      "Epoch 3627, Loss: 0.0026243341162626166, Final Batch Loss: 0.002029774244874716\n",
      "Epoch 3628, Loss: 0.011113556451164186, Final Batch Loss: 0.0\n",
      "Epoch 3629, Loss: 0.0023056847176121664, Final Batch Loss: 1.5146810255828314e-05\n",
      "Epoch 3630, Loss: 0.001001431278950804, Final Batch Loss: 6.982223794693709e-07\n",
      "Epoch 3631, Loss: 0.020220925835928938, Final Batch Loss: 8.012118087208364e-06\n",
      "Epoch 3632, Loss: 0.006729474618623499, Final Batch Loss: 0.0\n",
      "Epoch 3633, Loss: 0.004924976765323663, Final Batch Loss: 0.004067111294716597\n",
      "Epoch 3634, Loss: 0.001543356105685234, Final Batch Loss: 0.0\n",
      "Epoch 3635, Loss: 0.018520550211675868, Final Batch Loss: 2.0435849990008137e-07\n",
      "Epoch 3636, Loss: 0.004704120247083665, Final Batch Loss: 1.2687215757978265e-06\n",
      "Epoch 3637, Loss: 0.0010187029350028354, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3638, Loss: 0.001379282160719697, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3639, Loss: 0.016294804459789702, Final Batch Loss: 1.7881382063933415e-07\n",
      "Epoch 3640, Loss: 0.0017660577304923208, Final Batch Loss: 0.000522300077136606\n",
      "Epoch 3641, Loss: 0.0010622843328746967, Final Batch Loss: 0.00011490745237097144\n",
      "Epoch 3642, Loss: 0.0030286398298926542, Final Batch Loss: 8.344625825884577e-07\n",
      "Epoch 3643, Loss: 0.0011255730059929192, Final Batch Loss: 0.0\n",
      "Epoch 3644, Loss: 0.0020936683722538874, Final Batch Loss: 1.0558105714153498e-05\n",
      "Epoch 3645, Loss: 0.001335655204456998, Final Batch Loss: 0.0\n",
      "Epoch 3646, Loss: 0.02030486351577565, Final Batch Loss: 0.0003142764908261597\n",
      "Epoch 3647, Loss: 0.013719475147809135, Final Batch Loss: 0.0\n",
      "Epoch 3648, Loss: 0.003330773931679687, Final Batch Loss: 1.0217934232059633e-07\n",
      "Epoch 3649, Loss: 0.005494568920923371, Final Batch Loss: 1.2772413526818127e-07\n",
      "Epoch 3650, Loss: 0.0006201819310120982, Final Batch Loss: 1.3623910888327373e-07\n",
      "Epoch 3651, Loss: 0.0163432712724898, Final Batch Loss: 0.0009494709083810449\n",
      "Epoch 3652, Loss: 0.003234104669900262, Final Batch Loss: 8.710261681699194e-06\n",
      "Epoch 3653, Loss: 0.003922404699551407, Final Batch Loss: 0.0\n",
      "Epoch 3654, Loss: 0.00455888568831142, Final Batch Loss: 8.957220416050404e-05\n",
      "Epoch 3655, Loss: 0.008589218919361485, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 3656, Loss: 0.012860800381758963, Final Batch Loss: 2.1201942672632867e-06\n",
      "Epoch 3657, Loss: 0.004588296140354942, Final Batch Loss: 1.8390519471722655e-05\n",
      "Epoch 3658, Loss: 0.009204025056874343, Final Batch Loss: 1.2091153394067078e-06\n",
      "Epoch 3659, Loss: 0.014179119264213114, Final Batch Loss: 1.6518812344656908e-06\n",
      "Epoch 3660, Loss: 0.003451804862246277, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3661, Loss: 0.004176162783551263, Final Batch Loss: 0.0006204316741786897\n",
      "Epoch 3662, Loss: 0.0024631879163052872, Final Batch Loss: 6.811927732996992e-07\n",
      "Epoch 3663, Loss: 0.015134662178752478, Final Batch Loss: 0.00013822309847455472\n",
      "Epoch 3664, Loss: 0.0007955424074452822, Final Batch Loss: 1.7881169469546876e-06\n",
      "Epoch 3665, Loss: 0.012755925563396886, Final Batch Loss: 0.011328122578561306\n",
      "Epoch 3666, Loss: 0.0028930740753594364, Final Batch Loss: 7.067372962410445e-07\n",
      "Epoch 3667, Loss: 0.006066330064641079, Final Batch Loss: 2.9064536647638306e-05\n",
      "Epoch 3668, Loss: 0.009313664468209026, Final Batch Loss: 2.8742866561515257e-05\n",
      "Epoch 3669, Loss: 0.029621108577941868, Final Batch Loss: 2.8950768182767206e-07\n",
      "Epoch 3670, Loss: 0.0023910656600492075, Final Batch Loss: 0.0009920767042785883\n",
      "Epoch 3671, Loss: 0.0018845845697796904, Final Batch Loss: 0.0005767875700257719\n",
      "Epoch 3672, Loss: 0.017955202027224004, Final Batch Loss: 0.0\n",
      "Epoch 3673, Loss: 0.0025194580466632033, Final Batch Loss: 8.378223355975933e-06\n",
      "Epoch 3674, Loss: 0.001468420438868634, Final Batch Loss: 7.075700523273554e-06\n",
      "Epoch 3675, Loss: 0.002245009405669407, Final Batch Loss: 2.2816422642790712e-05\n",
      "Epoch 3676, Loss: 0.009303900298391454, Final Batch Loss: 1.1750578323699301e-06\n",
      "Epoch 3677, Loss: 0.001360313691918691, Final Batch Loss: 8.940675684243615e-07\n",
      "Epoch 3678, Loss: 0.0008583553993730675, Final Batch Loss: 6.301037274170085e-07\n",
      "Epoch 3679, Loss: 0.004790134145878255, Final Batch Loss: 0.0004178789968136698\n",
      "Epoch 3680, Loss: 0.0008567189797652475, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 3681, Loss: 0.0051913776707195325, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3682, Loss: 0.021359584144448718, Final Batch Loss: 1.6178390183085867e-07\n",
      "Epoch 3683, Loss: 0.010844372714927886, Final Batch Loss: 6.553231651196256e-05\n",
      "Epoch 3684, Loss: 0.0017179617352667265, Final Batch Loss: 3.9268663385882974e-05\n",
      "Epoch 3685, Loss: 0.0012590040486024634, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3686, Loss: 0.0021790795512970362, Final Batch Loss: 2.8013969313178677e-06\n",
      "Epoch 3687, Loss: 0.011940511681132193, Final Batch Loss: 8.769867235969286e-06\n",
      "Epoch 3688, Loss: 0.0014043937062524492, Final Batch Loss: 1.0668454706319608e-05\n",
      "Epoch 3689, Loss: 0.004539878938885522, Final Batch Loss: 2.10980524570914e-05\n",
      "Epoch 3690, Loss: 0.030163029034156352, Final Batch Loss: 0.00030111175146885216\n",
      "Epoch 3691, Loss: 0.0014542073186021298, Final Batch Loss: 6.374450458679348e-05\n",
      "Epoch 3692, Loss: 0.0012999394571764356, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3693, Loss: 0.00725786408111162, Final Batch Loss: 2.053510797850322e-05\n",
      "Epoch 3694, Loss: 0.0010886158561334014, Final Batch Loss: 0.0\n",
      "Epoch 3695, Loss: 0.0015239360163832316, Final Batch Loss: 6.304842827375978e-05\n",
      "Epoch 3696, Loss: 0.0055947336804820225, Final Batch Loss: 4.4885608076583594e-05\n",
      "Epoch 3697, Loss: 0.0009055021350263814, Final Batch Loss: 5.619844500870386e-07\n",
      "Epoch 3698, Loss: 0.0035047326528001577, Final Batch Loss: 0.001015705754980445\n",
      "Epoch 3699, Loss: 0.01798925062030321, Final Batch Loss: 0.002208573743700981\n",
      "Epoch 3700, Loss: 0.001177645866846433, Final Batch Loss: 9.638642950449139e-06\n",
      "Epoch 3701, Loss: 0.004044995080903391, Final Batch Loss: 1.3453516203298932e-06\n",
      "Epoch 3702, Loss: 0.00413609321549302, Final Batch Loss: 0.00016416677681263536\n",
      "Epoch 3703, Loss: 0.00145191832024949, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3704, Loss: 0.001335464301519096, Final Batch Loss: 0.0\n",
      "Epoch 3705, Loss: 0.000741678370104637, Final Batch Loss: 8.348481787834316e-05\n",
      "Epoch 3706, Loss: 0.0010886723030125722, Final Batch Loss: 7.535592885687947e-05\n",
      "Epoch 3707, Loss: 0.0005778545474868224, Final Batch Loss: 1.1239645800742437e-06\n",
      "Epoch 3708, Loss: 0.0067278307396918535, Final Batch Loss: 0.0\n",
      "Epoch 3709, Loss: 0.0011159635001263268, Final Batch Loss: 6.215892085492669e-07\n",
      "Epoch 3710, Loss: 0.0005658480622514617, Final Batch Loss: 5.507901732926257e-05\n",
      "Epoch 3711, Loss: 0.0010555588432907825, Final Batch Loss: 0.00024908987688831985\n",
      "Epoch 3712, Loss: 0.0013587817011284642, Final Batch Loss: 0.00013126754492986947\n",
      "Epoch 3713, Loss: 0.012330999736150261, Final Batch Loss: 0.00017924972053151578\n",
      "Epoch 3714, Loss: 0.024089138717499736, Final Batch Loss: 9.476639206695836e-06\n",
      "Epoch 3715, Loss: 0.0012006172837324414, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3716, Loss: 0.0023630159415688468, Final Batch Loss: 1.030305043059343e-06\n",
      "Epoch 3717, Loss: 0.020070114582267706, Final Batch Loss: 9.01676139619667e-06\n",
      "Epoch 3718, Loss: 0.002652226194705065, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3719, Loss: 0.003028158216693555, Final Batch Loss: 2.0008186766062863e-05\n",
      "Epoch 3720, Loss: 0.006079539869915607, Final Batch Loss: 2.9801835808029864e-06\n",
      "Epoch 3721, Loss: 0.0015505453757214127, Final Batch Loss: 2.6808984330273233e-05\n",
      "Epoch 3722, Loss: 0.013799381471756078, Final Batch Loss: 6.982230047469784e-07\n",
      "Epoch 3723, Loss: 0.0025143744715023786, Final Batch Loss: 0.000581940112169832\n",
      "Epoch 3724, Loss: 0.0024848170578479767, Final Batch Loss: 0.00018546231149230152\n",
      "Epoch 3725, Loss: 0.0014999395882888678, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3726, Loss: 0.014479782224952942, Final Batch Loss: 4.6865559852449223e-05\n",
      "Epoch 3727, Loss: 0.006286597630946744, Final Batch Loss: 1.2772310356012895e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3728, Loss: 0.004953751296852715, Final Batch Loss: 0.000275329512078315\n",
      "Epoch 3729, Loss: 0.0015290383016690612, Final Batch Loss: 7.37952723284252e-05\n",
      "Epoch 3730, Loss: 0.0010874454981149029, Final Batch Loss: 1.5326820630434668e-06\n",
      "Epoch 3731, Loss: 0.00418390140930569, Final Batch Loss: 8.216703463403974e-06\n",
      "Epoch 3732, Loss: 0.0018847399005608167, Final Batch Loss: 4.7847690439084545e-05\n",
      "Epoch 3733, Loss: 0.0008810130007361749, Final Batch Loss: 2.639631304646173e-07\n",
      "Epoch 3734, Loss: 0.002485713138639767, Final Batch Loss: 3.0738403893337818e-06\n",
      "Epoch 3735, Loss: 0.02415724274760578, Final Batch Loss: 0.0003454240504652262\n",
      "Epoch 3736, Loss: 0.0033371277095284313, Final Batch Loss: 0.0\n",
      "Epoch 3737, Loss: 0.004679564921389101, Final Batch Loss: 5.6452299759257585e-06\n",
      "Epoch 3738, Loss: 0.0014648179749201518, Final Batch Loss: 0.0008693136041983962\n",
      "Epoch 3739, Loss: 0.01039840997691499, Final Batch Loss: 0.0011142927687615156\n",
      "Epoch 3740, Loss: 0.005358338379664929, Final Batch Loss: 1.9394419723539613e-05\n",
      "Epoch 3741, Loss: 0.0030294240866624023, Final Batch Loss: 2.290486690981197e-06\n",
      "Epoch 3742, Loss: 0.0030559494255157915, Final Batch Loss: 3.286694891357911e-06\n",
      "Epoch 3743, Loss: 0.0018339999592171807, Final Batch Loss: 1.3623912309412844e-07\n",
      "Epoch 3744, Loss: 0.014803821533860173, Final Batch Loss: 5.720605986425653e-05\n",
      "Epoch 3745, Loss: 0.0011679586914397078, Final Batch Loss: 0.0001256824325537309\n",
      "Epoch 3746, Loss: 0.004993769041902851, Final Batch Loss: 5.125862662680447e-05\n",
      "Epoch 3747, Loss: 0.0003793571181063271, Final Batch Loss: 4.853504265156516e-07\n",
      "Epoch 3748, Loss: 0.021155112124688458, Final Batch Loss: 0.005390997044742107\n",
      "Epoch 3749, Loss: 0.0022630355233559385, Final Batch Loss: 0.0001907184487208724\n",
      "Epoch 3750, Loss: 0.011177217403883333, Final Batch Loss: 3.2526711493119365e-06\n",
      "Epoch 3751, Loss: 0.0006600578217330622, Final Batch Loss: 3.644003299996257e-05\n",
      "Epoch 3752, Loss: 0.0036639208847191185, Final Batch Loss: 0.0008775457390584052\n",
      "Epoch 3753, Loss: 0.001209087951338006, Final Batch Loss: 6.786283393012127e-06\n",
      "Epoch 3754, Loss: 0.0008743292892177124, Final Batch Loss: 5.90914351050742e-06\n",
      "Epoch 3755, Loss: 0.0008791927693891921, Final Batch Loss: 8.812429769022856e-06\n",
      "Epoch 3756, Loss: 0.0027799378731288016, Final Batch Loss: 0.0006371618947014213\n",
      "Epoch 3757, Loss: 0.006834659020114486, Final Batch Loss: 3.55064594259602e-06\n",
      "Epoch 3758, Loss: 0.008634965375563297, Final Batch Loss: 1.4901050917615066e-06\n",
      "Epoch 3759, Loss: 0.0007446905892720679, Final Batch Loss: 2.3344184228335507e-05\n",
      "Epoch 3760, Loss: 0.0009152486405241689, Final Batch Loss: 9.110977430282219e-07\n",
      "Epoch 3761, Loss: 0.021847002433787566, Final Batch Loss: 0.01761326752603054\n",
      "Epoch 3762, Loss: 0.002792025901726447, Final Batch Loss: 0.00036766589619219303\n",
      "Epoch 3763, Loss: 0.0011311061170999892, Final Batch Loss: 0.00013707156176678836\n",
      "Epoch 3764, Loss: 0.023557514687126968, Final Batch Loss: 0.0004701185680460185\n",
      "Epoch 3765, Loss: 0.0008900867661907341, Final Batch Loss: 2.8950776709280035e-07\n",
      "Epoch 3766, Loss: 0.0032109021818254035, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3767, Loss: 0.0011259731254540384, Final Batch Loss: 0.00039207719964906573\n",
      "Epoch 3768, Loss: 0.0007695006821677453, Final Batch Loss: 1.072879626917711e-06\n",
      "Epoch 3769, Loss: 0.004770901214214973, Final Batch Loss: 1.6943527953117155e-05\n",
      "Epoch 3770, Loss: 0.0008962037245510146, Final Batch Loss: 0.00013602715625893325\n",
      "Epoch 3771, Loss: 0.0012971164032933302, Final Batch Loss: 0.0008826720295473933\n",
      "Epoch 3772, Loss: 0.0011181232524108964, Final Batch Loss: 2.895079092013475e-07\n",
      "Epoch 3773, Loss: 0.002335749441272128, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 3774, Loss: 0.021411701800388983, Final Batch Loss: 0.0\n",
      "Epoch 3775, Loss: 0.0007925742320367135, Final Batch Loss: 0.0002602537861093879\n",
      "Epoch 3776, Loss: 0.010525119142705819, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3777, Loss: 0.0007789832452544942, Final Batch Loss: 1.4959456166252494e-05\n",
      "Epoch 3778, Loss: 0.0034754551294611247, Final Batch Loss: 4.1723129129422887e-07\n",
      "Epoch 3779, Loss: 0.04016219113691477, Final Batch Loss: 0.0002526002353988588\n",
      "Epoch 3780, Loss: 0.0020216821976646315, Final Batch Loss: 0.0\n",
      "Epoch 3781, Loss: 0.0030344498591148295, Final Batch Loss: 0.0\n",
      "Epoch 3782, Loss: 0.0014386953989742324, Final Batch Loss: 0.00034464936470612884\n",
      "Epoch 3783, Loss: 0.028262343499591225, Final Batch Loss: 0.023898974061012268\n",
      "Epoch 3784, Loss: 0.004386195449910701, Final Batch Loss: 6.556482503583538e-07\n",
      "Epoch 3785, Loss: 0.08952114371277275, Final Batch Loss: 0.08884116262197495\n",
      "Epoch 3786, Loss: 0.001002370823698584, Final Batch Loss: 0.0\n",
      "Epoch 3787, Loss: 0.014120479175609546, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 3788, Loss: 0.010706983134070924, Final Batch Loss: 2.6396293151265127e-07\n",
      "Epoch 3789, Loss: 0.004443622991232132, Final Batch Loss: 8.940663178691466e-07\n",
      "Epoch 3790, Loss: 0.0018599769437059877, Final Batch Loss: 7.271436516020913e-06\n",
      "Epoch 3791, Loss: 0.0010492672086570565, Final Batch Loss: 7.918866344880371e-07\n",
      "Epoch 3792, Loss: 0.020926988120272938, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3793, Loss: 0.008759558123848876, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 3794, Loss: 0.02513190941681387, Final Batch Loss: 9.422955190530047e-05\n",
      "Epoch 3795, Loss: 0.004310849853936816, Final Batch Loss: 0.003172756638377905\n",
      "Epoch 3796, Loss: 0.035613847827718814, Final Batch Loss: 1.3623905203985487e-07\n",
      "Epoch 3797, Loss: 0.011296362517896341, Final Batch Loss: 5.417825377662666e-05\n",
      "Epoch 3798, Loss: 0.008187993873434607, Final Batch Loss: 1.1264790373388678e-05\n",
      "Epoch 3799, Loss: 0.002629356509714853, Final Batch Loss: 2.8385984478518367e-05\n",
      "Epoch 3800, Loss: 0.005650950042763725, Final Batch Loss: 0.00029541822732426226\n",
      "Epoch 3801, Loss: 0.01625323632833897, Final Batch Loss: 5.3046260291012004e-05\n",
      "Epoch 3802, Loss: 0.0020022764614751054, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3803, Loss: 0.00173656063634553, Final Batch Loss: 8.400296064792201e-05\n",
      "Epoch 3804, Loss: 0.027649070078041404, Final Batch Loss: 0.00011181145237060264\n",
      "Epoch 3805, Loss: 0.0006764491735999911, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3806, Loss: 0.0017344232546747662, Final Batch Loss: 0.00015127040387596935\n",
      "Epoch 3807, Loss: 0.004153062043769751, Final Batch Loss: 0.0009557681041769683\n",
      "Epoch 3808, Loss: 0.01602155191329757, Final Batch Loss: 7.91885838680173e-07\n",
      "Epoch 3809, Loss: 0.0019621269493654836, Final Batch Loss: 1.7053596820915118e-05\n",
      "Epoch 3810, Loss: 0.0020463700784603134, Final Batch Loss: 0.00012330342724453658\n",
      "Epoch 3811, Loss: 0.00440955419162492, Final Batch Loss: 8.259196874860208e-06\n",
      "Epoch 3812, Loss: 0.0010431341506773606, Final Batch Loss: 8.381195220863447e-05\n",
      "Epoch 3813, Loss: 0.0170506231370382, Final Batch Loss: 0.0002489242469891906\n",
      "Epoch 3814, Loss: 0.0025668789096791045, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3815, Loss: 0.007873751575971255, Final Batch Loss: 3.0342056561494246e-05\n",
      "Epoch 3816, Loss: 0.0008340323088305013, Final Batch Loss: 4.563871243590256e-06\n",
      "Epoch 3817, Loss: 0.0017138764445689958, Final Batch Loss: 1.2176273003206006e-06\n",
      "Epoch 3818, Loss: 0.005079289068817161, Final Batch Loss: 0.0030159824527800083\n",
      "Epoch 3819, Loss: 0.004468241462745937, Final Batch Loss: 4.891939533990808e-05\n",
      "Epoch 3820, Loss: 0.0016948101370584112, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3821, Loss: 0.001104813942220062, Final Batch Loss: 0.00015491689555346966\n",
      "Epoch 3822, Loss: 0.00640045937279865, Final Batch Loss: 7.5183047556492966e-06\n",
      "Epoch 3823, Loss: 0.0013558669816120528, Final Batch Loss: 4.477467155084014e-05\n",
      "Epoch 3824, Loss: 0.001033816982243252, Final Batch Loss: 1.532689282157662e-07\n",
      "Epoch 3825, Loss: 0.0013512654004443903, Final Batch Loss: 0.0006503678159788251\n",
      "Epoch 3826, Loss: 0.0032899997695494676, Final Batch Loss: 0.0005730417906306684\n",
      "Epoch 3827, Loss: 0.001219210938870674, Final Batch Loss: 5.0790640671039e-05\n",
      "Epoch 3828, Loss: 0.0004559074695862364, Final Batch Loss: 2.6513498596614227e-05\n",
      "Epoch 3829, Loss: 0.00246127339778468, Final Batch Loss: 1.4439952792599797e-05\n",
      "Epoch 3830, Loss: 0.0031387132108307014, Final Batch Loss: 6.045589202585688e-07\n",
      "Epoch 3831, Loss: 0.0032004470299398236, Final Batch Loss: 7.075770099618239e-06\n",
      "Epoch 3832, Loss: 0.006244069647436845, Final Batch Loss: 0.0001889525301521644\n",
      "Epoch 3833, Loss: 0.0011899916498805396, Final Batch Loss: 0.0\n",
      "Epoch 3834, Loss: 0.0010004154919442954, Final Batch Loss: 0.00036685573286376894\n",
      "Epoch 3835, Loss: 0.001407582244837613, Final Batch Loss: 2.835423629221623e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3836, Loss: 0.0013387105573201552, Final Batch Loss: 0.000218984205275774\n",
      "Epoch 3837, Loss: 0.006583662609045859, Final Batch Loss: 0.0005380851216614246\n",
      "Epoch 3838, Loss: 0.001125014134288449, Final Batch Loss: 8.940642715060676e-07\n",
      "Epoch 3839, Loss: 0.013498004643906825, Final Batch Loss: 3.678378334370791e-06\n",
      "Epoch 3840, Loss: 0.004841277527571464, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3841, Loss: 0.0191133730346138, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 3842, Loss: 0.020843255682848394, Final Batch Loss: 0.0\n",
      "Epoch 3843, Loss: 0.005813057407294764, Final Batch Loss: 2.3075156150298426e-06\n",
      "Epoch 3844, Loss: 0.0018660185705812182, Final Batch Loss: 0.0\n",
      "Epoch 3845, Loss: 0.0016869324899744242, Final Batch Loss: 0.00019641686230897903\n",
      "Epoch 3846, Loss: 0.0030560722152586095, Final Batch Loss: 0.0\n",
      "Epoch 3847, Loss: 0.033590165070620515, Final Batch Loss: 3.5762701600106084e-07\n",
      "Epoch 3848, Loss: 0.0017262404744542437, Final Batch Loss: 0.0011669294908642769\n",
      "Epoch 3849, Loss: 0.0006269376492582523, Final Batch Loss: 2.2223714495339664e-06\n",
      "Epoch 3850, Loss: 0.0024140302411979064, Final Batch Loss: 0.0015478575369343162\n",
      "Epoch 3851, Loss: 0.058312019214099564, Final Batch Loss: 2.0520737962215208e-06\n",
      "Epoch 3852, Loss: 0.0018285729938725126, Final Batch Loss: 9.22109484235989e-06\n",
      "Epoch 3853, Loss: 0.0010779041331261396, Final Batch Loss: 0.00010218298120889813\n",
      "Epoch 3854, Loss: 0.0054986204261240346, Final Batch Loss: 3.2015661872719647e-06\n",
      "Epoch 3855, Loss: 0.0029240044896141626, Final Batch Loss: 0.0\n",
      "Epoch 3856, Loss: 0.004324793895648327, Final Batch Loss: 0.0005638842703774571\n",
      "Epoch 3857, Loss: 0.0007434889048454352, Final Batch Loss: 0.0\n",
      "Epoch 3858, Loss: 0.0797834980087373, Final Batch Loss: 1.958417897185427e-06\n",
      "Epoch 3859, Loss: 0.002632061099575367, Final Batch Loss: 0.0003536131698638201\n",
      "Epoch 3860, Loss: 0.0013041843258179142, Final Batch Loss: 1.5752584658912383e-06\n",
      "Epoch 3861, Loss: 0.0016123996674650698, Final Batch Loss: 1.1503011592139956e-05\n",
      "Epoch 3862, Loss: 0.001704610426685349, Final Batch Loss: 2.7247821776654746e-07\n",
      "Epoch 3863, Loss: 0.002370683814660879, Final Batch Loss: 6.743521225871518e-06\n",
      "Epoch 3864, Loss: 0.0018756060926534701, Final Batch Loss: 0.00019762347801588476\n",
      "Epoch 3865, Loss: 0.019510124856878974, Final Batch Loss: 5.789977421954973e-06\n",
      "Epoch 3866, Loss: 0.0029810592386638746, Final Batch Loss: 0.0015469647478312254\n",
      "Epoch 3867, Loss: 0.0087919832294574, Final Batch Loss: 0.0001167051523225382\n",
      "Epoch 3868, Loss: 0.006772998376618489, Final Batch Loss: 1.8909284335677512e-05\n",
      "Epoch 3869, Loss: 0.0018918339956144337, Final Batch Loss: 5.875699935131706e-05\n",
      "Epoch 3870, Loss: 0.002680050554886293, Final Batch Loss: 1.788121267054521e-06\n",
      "Epoch 3871, Loss: 0.004710676752438303, Final Batch Loss: 0.003056660993024707\n",
      "Epoch 3872, Loss: 0.0062737243351875804, Final Batch Loss: 0.00010195241338806227\n",
      "Epoch 3873, Loss: 0.003951230366510572, Final Batch Loss: 0.0017099735559895635\n",
      "Epoch 3874, Loss: 0.0039772975142113864, Final Batch Loss: 0.0002996211696881801\n",
      "Epoch 3875, Loss: 0.0011952224203923834, Final Batch Loss: 4.197793714411091e-06\n",
      "Epoch 3876, Loss: 0.0042935705569107085, Final Batch Loss: 0.00376634718850255\n",
      "Epoch 3877, Loss: 0.04101839959184872, Final Batch Loss: 0.0403667688369751\n",
      "Epoch 3878, Loss: 0.0006136797837825725, Final Batch Loss: 3.22709274769295e-06\n",
      "Epoch 3879, Loss: 0.0020696141800726764, Final Batch Loss: 0.00010461472265888005\n",
      "Epoch 3880, Loss: 0.004569698008708656, Final Batch Loss: 2.108000626321882e-05\n",
      "Epoch 3881, Loss: 0.010686593016089319, Final Batch Loss: 6.096556262491504e-06\n",
      "Epoch 3882, Loss: 0.003952363568295425, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 3883, Loss: 0.0020832854227350595, Final Batch Loss: 6.81195828633463e-08\n",
      "Epoch 3884, Loss: 0.00700107491138624, Final Batch Loss: 0.001036832807585597\n",
      "Epoch 3885, Loss: 0.02531986675485598, Final Batch Loss: 1.447539972332379e-07\n",
      "Epoch 3886, Loss: 0.004629413087958056, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 3887, Loss: 0.03329895321588339, Final Batch Loss: 1.1069426619769729e-07\n",
      "Epoch 3888, Loss: 0.005089236282628917, Final Batch Loss: 3.014244839505409e-06\n",
      "Epoch 3889, Loss: 0.0005528550259441545, Final Batch Loss: 4.657541921915254e-06\n",
      "Epoch 3890, Loss: 0.003677916669403203, Final Batch Loss: 3.5749668313656e-05\n",
      "Epoch 3891, Loss: 0.004130981153656066, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3892, Loss: 0.002479782073351089, Final Batch Loss: 0.0002809977740980685\n",
      "Epoch 3893, Loss: 0.020848712068982422, Final Batch Loss: 0.00038426995160989463\n",
      "Epoch 3894, Loss: 0.001513547339300203, Final Batch Loss: 4.938654001307441e-07\n",
      "Epoch 3895, Loss: 0.0013456590168061666, Final Batch Loss: 0.00011358696792740375\n",
      "Epoch 3896, Loss: 0.0025607742500142194, Final Batch Loss: 0.0012327658478170633\n",
      "Epoch 3897, Loss: 0.001159714869572781, Final Batch Loss: 0.0\n",
      "Epoch 3898, Loss: 0.003966642608084214, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 3899, Loss: 0.0007725925934209954, Final Batch Loss: 0.00023829421843402088\n",
      "Epoch 3900, Loss: 0.0005063599828645238, Final Batch Loss: 3.754994395421818e-06\n",
      "Epoch 3901, Loss: 0.0024219187544076703, Final Batch Loss: 0.0011239368468523026\n",
      "Epoch 3902, Loss: 0.0015833492429919716, Final Batch Loss: 6.539186415466247e-06\n",
      "Epoch 3903, Loss: 0.0013423475465970114, Final Batch Loss: 5.600193253485486e-05\n",
      "Epoch 3904, Loss: 0.001914758829116181, Final Batch Loss: 9.476844752498437e-06\n",
      "Epoch 3905, Loss: 0.001149378944489854, Final Batch Loss: 9.110937639889016e-07\n",
      "Epoch 3906, Loss: 0.005991683618049137, Final Batch Loss: 6.996270531089976e-05\n",
      "Epoch 3907, Loss: 0.0018614491476398598, Final Batch Loss: 3.8317224948514195e-07\n",
      "Epoch 3908, Loss: 0.0026672116027839365, Final Batch Loss: 1.0898303116846364e-05\n",
      "Epoch 3909, Loss: 0.003900874364262563, Final Batch Loss: 1.54785029735649e-05\n",
      "Epoch 3910, Loss: 0.016178446434423677, Final Batch Loss: 0.015023804269731045\n",
      "Epoch 3911, Loss: 0.001914234931973624, Final Batch Loss: 1.2311613318161108e-05\n",
      "Epoch 3912, Loss: 0.0005972585704512312, Final Batch Loss: 0.0\n",
      "Epoch 3913, Loss: 0.0017429802234119052, Final Batch Loss: 1.2942606417709612e-06\n",
      "Epoch 3914, Loss: 0.022087680832790113, Final Batch Loss: 6.811956865249158e-08\n",
      "Epoch 3915, Loss: 0.0048414669881537975, Final Batch Loss: 2.1287357299115683e-07\n",
      "Epoch 3916, Loss: 0.0008500928938701691, Final Batch Loss: 4.1637590584286954e-06\n",
      "Epoch 3917, Loss: 0.06539776097997674, Final Batch Loss: 0.06400159001350403\n",
      "Epoch 3918, Loss: 0.013366116519250681, Final Batch Loss: 5.534703859666479e-07\n",
      "Epoch 3919, Loss: 0.0015283135189747554, Final Batch Loss: 4.555396117211785e-06\n",
      "Epoch 3920, Loss: 0.022795726734329946, Final Batch Loss: 0.0\n",
      "Epoch 3921, Loss: 0.024903396642002917, Final Batch Loss: 1.2091140888514929e-06\n",
      "Epoch 3922, Loss: 0.005068661543191411, Final Batch Loss: 0.0008159702410921454\n",
      "Epoch 3923, Loss: 0.0025767299293875112, Final Batch Loss: 8.968759357230738e-05\n",
      "Epoch 3924, Loss: 0.0028445889620343223, Final Batch Loss: 0.0\n",
      "Epoch 3925, Loss: 0.0034329977252767208, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 3926, Loss: 0.0020511324328253977, Final Batch Loss: 0.0011370135471224785\n",
      "Epoch 3927, Loss: 0.00044935410301150114, Final Batch Loss: 1.779613057806273e-06\n",
      "Epoch 3928, Loss: 0.004081645772458842, Final Batch Loss: 4.172318597284175e-07\n",
      "Epoch 3929, Loss: 0.0017251906356250402, Final Batch Loss: 3.228144851163961e-05\n",
      "Epoch 3930, Loss: 0.0006054003533790819, Final Batch Loss: 0.00015520353917963803\n",
      "Epoch 3931, Loss: 0.0008469663980577025, Final Batch Loss: 7.680107046326157e-06\n",
      "Epoch 3932, Loss: 0.001264888585080115, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3933, Loss: 0.003693593341210999, Final Batch Loss: 6.04559261319082e-07\n",
      "Epoch 3934, Loss: 0.002219362803657532, Final Batch Loss: 1.3623860013467493e-06\n",
      "Epoch 3935, Loss: 0.0009042363179645463, Final Batch Loss: 1.7881380642847944e-07\n",
      "Epoch 3936, Loss: 0.00039645855239101024, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3937, Loss: 0.0006911332294521344, Final Batch Loss: 1.0984205118802493e-06\n",
      "Epoch 3938, Loss: 0.0005348196718841791, Final Batch Loss: 3.176226164214313e-05\n",
      "Epoch 3939, Loss: 0.0010221587546190847, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3940, Loss: 0.0006587454938795645, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 3941, Loss: 0.00048754094911451773, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3942, Loss: 0.008155690610237798, Final Batch Loss: 4.7341550271085e-06\n",
      "Epoch 3943, Loss: 0.0006629389281442855, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3944, Loss: 0.0008049847403981403, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 3945, Loss: 0.026098656984686386, Final Batch Loss: 4.9805625167209655e-05\n",
      "Epoch 3946, Loss: 0.05033936101652614, Final Batch Loss: 1.3623910888327373e-07\n",
      "Epoch 3947, Loss: 0.02117971495317761, Final Batch Loss: 0.0002471836924087256\n",
      "Epoch 3948, Loss: 0.0027877577449544333, Final Batch Loss: 0.00040233711479231715\n",
      "Epoch 3949, Loss: 0.013089524393308238, Final Batch Loss: 1.0132721399713773e-06\n",
      "Epoch 3950, Loss: 0.0019300012295389024, Final Batch Loss: 5.440849690785399e-06\n",
      "Epoch 3951, Loss: 0.0012187641477794386, Final Batch Loss: 0.00027525966288521886\n",
      "Epoch 3952, Loss: 0.0005981807116768323, Final Batch Loss: 0.0\n",
      "Epoch 3953, Loss: 0.0037175886900513433, Final Batch Loss: 0.0\n",
      "Epoch 3954, Loss: 0.002561966721259523, Final Batch Loss: 7.170141179813072e-05\n",
      "Epoch 3955, Loss: 0.0010868652701532255, Final Batch Loss: 1.0217932810974162e-07\n",
      "Epoch 3956, Loss: 0.028801775409192487, Final Batch Loss: 0.0038463433738797903\n",
      "Epoch 3957, Loss: 0.0006979462791605329, Final Batch Loss: 0.0\n",
      "Epoch 3958, Loss: 0.0014082541638344992, Final Batch Loss: 0.0010977998608723283\n",
      "Epoch 3959, Loss: 0.0004974609733920943, Final Batch Loss: 2.0435855674350023e-07\n",
      "Epoch 3960, Loss: 0.004876852559391409, Final Batch Loss: 0.0\n",
      "Epoch 3961, Loss: 0.0034703111996350344, Final Batch Loss: 0.00035283100442029536\n",
      "Epoch 3962, Loss: 0.016145872290508123, Final Batch Loss: 0.0\n",
      "Epoch 3963, Loss: 0.0014742986718587758, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 3964, Loss: 0.01068324852026592, Final Batch Loss: 1.362390804615643e-07\n",
      "Epoch 3965, Loss: 0.013714123330032635, Final Batch Loss: 1.5667338857383584e-06\n",
      "Epoch 3966, Loss: 0.01154927253810456, Final Batch Loss: 0.0\n",
      "Epoch 3967, Loss: 0.0011436266804594197, Final Batch Loss: 0.00013070022396277636\n",
      "Epoch 3968, Loss: 0.0018039916030829772, Final Batch Loss: 0.0\n",
      "Epoch 3969, Loss: 0.0019605108290079443, Final Batch Loss: 1.106934973904572e-06\n",
      "Epoch 3970, Loss: 0.001919807146926189, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3971, Loss: 0.06771613055025227, Final Batch Loss: 0.05058145895600319\n",
      "Epoch 3972, Loss: 0.0009819724709814182, Final Batch Loss: 0.00029168775654397905\n",
      "Epoch 3973, Loss: 0.016062370315921726, Final Batch Loss: 4.966748019796796e-05\n",
      "Epoch 3974, Loss: 0.04202764081378518, Final Batch Loss: 3.516603783282335e-06\n",
      "Epoch 3975, Loss: 0.0030495159426209284, Final Batch Loss: 0.0\n",
      "Epoch 3976, Loss: 0.020931086313794367, Final Batch Loss: 0.0\n",
      "Epoch 3977, Loss: 0.0049536726819496835, Final Batch Loss: 9.766217772266828e-06\n",
      "Epoch 3978, Loss: 0.0023521429812944916, Final Batch Loss: 1.4730777593285893e-06\n",
      "Epoch 3979, Loss: 0.024861199903938314, Final Batch Loss: 2.7247810407970974e-07\n",
      "Epoch 3980, Loss: 0.01686216759844683, Final Batch Loss: 0.002556194318458438\n",
      "Epoch 3981, Loss: 0.006595064369321335, Final Batch Loss: 6.6328611865174025e-06\n",
      "Epoch 3982, Loss: 0.0011805330587861818, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 3983, Loss: 0.009134996329521528, Final Batch Loss: 0.00035931417369283736\n",
      "Epoch 3984, Loss: 0.034513823528300236, Final Batch Loss: 1.4475266425506561e-06\n",
      "Epoch 3985, Loss: 0.012976934112430172, Final Batch Loss: 5.338673418009421e-06\n",
      "Epoch 3986, Loss: 0.02798672068547603, Final Batch Loss: 1.0940887477772776e-05\n",
      "Epoch 3987, Loss: 0.0018211714326810124, Final Batch Loss: 3.831723063285608e-07\n",
      "Epoch 3988, Loss: 0.03212004403303581, Final Batch Loss: 3.57626959157642e-07\n",
      "Epoch 3989, Loss: 0.00104100166416643, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3990, Loss: 0.0021660146630892996, Final Batch Loss: 0.00019199085363652557\n",
      "Epoch 3991, Loss: 0.0035773170238826424, Final Batch Loss: 0.0\n",
      "Epoch 3992, Loss: 0.0011860233498737216, Final Batch Loss: 0.0\n",
      "Epoch 3993, Loss: 0.0015214195009320974, Final Batch Loss: 0.00016157267964445055\n",
      "Epoch 3994, Loss: 0.002907349102315493, Final Batch Loss: 0.0014359402703121305\n",
      "Epoch 3995, Loss: 0.0044607200725295115, Final Batch Loss: 0.003594270208850503\n",
      "Epoch 3996, Loss: 0.0005328169323277621, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3997, Loss: 0.008595674036769196, Final Batch Loss: 0.00266341888345778\n",
      "Epoch 3998, Loss: 0.013349136184842791, Final Batch Loss: 0.00403714319691062\n",
      "Epoch 3999, Loss: 0.010883498212990617, Final Batch Loss: 3.150526595163683e-07\n",
      "Epoch 4000, Loss: 0.01133096546982415, Final Batch Loss: 0.0\n",
      "Epoch 4001, Loss: 0.002993048729848624, Final Batch Loss: 1.532689282157662e-07\n",
      "Epoch 4002, Loss: 0.006102956351242028, Final Batch Loss: 0.0001311544911004603\n",
      "Epoch 4003, Loss: 0.004015886643628619, Final Batch Loss: 2.2479111976281274e-06\n",
      "Epoch 4004, Loss: 0.003970322724853759, Final Batch Loss: 8.029435775824822e-06\n",
      "Epoch 4005, Loss: 0.011410850762331393, Final Batch Loss: 6.258326902752742e-05\n",
      "Epoch 4006, Loss: 0.0023618754951577614, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4007, Loss: 0.0007243382091814965, Final Batch Loss: 4.938660254083516e-07\n",
      "Epoch 4008, Loss: 0.037162009117309935, Final Batch Loss: 0.00020489127200562507\n",
      "Epoch 4009, Loss: 0.023056128906318918, Final Batch Loss: 0.00030561097082681954\n",
      "Epoch 4010, Loss: 0.007595424016471952, Final Batch Loss: 0.0\n",
      "Epoch 4011, Loss: 0.0008294871809084725, Final Batch Loss: 2.809902525768848e-06\n",
      "Epoch 4012, Loss: 0.0010034116172104035, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4013, Loss: 0.00991935913771158, Final Batch Loss: 0.00012039353896398097\n",
      "Epoch 4014, Loss: 0.015460490410198702, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4015, Loss: 0.002353072741485107, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 4016, Loss: 0.0022794612086727284, Final Batch Loss: 0.0\n",
      "Epoch 4017, Loss: 0.013314734840832898, Final Batch Loss: 1.864749947344535e-06\n",
      "Epoch 4018, Loss: 0.00883337731283973, Final Batch Loss: 3.2813226425787434e-05\n",
      "Epoch 4019, Loss: 0.0024271043330372777, Final Batch Loss: 1.8169655959354714e-05\n",
      "Epoch 4020, Loss: 0.0011316472082398832, Final Batch Loss: 0.00033375617931596935\n",
      "Epoch 4021, Loss: 0.026670437311167916, Final Batch Loss: 4.087070465175202e-06\n",
      "Epoch 4022, Loss: 0.008753524866600415, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4023, Loss: 0.0019737791016609663, Final Batch Loss: 2.469332116561418e-07\n",
      "Epoch 4024, Loss: 0.01652651811400574, Final Batch Loss: 5.270559086056892e-06\n",
      "Epoch 4025, Loss: 0.0019510700838338835, Final Batch Loss: 4.51291072067761e-07\n",
      "Epoch 4026, Loss: 0.0006798513141177409, Final Batch Loss: 1.5326898505918507e-07\n",
      "Epoch 4027, Loss: 0.000723169603588758, Final Batch Loss: 6.687999848509207e-05\n",
      "Epoch 4028, Loss: 0.010520788359116295, Final Batch Loss: 3.831721357983042e-07\n",
      "Epoch 4029, Loss: 0.0019615335695561953, Final Batch Loss: 0.0005287493695504963\n",
      "Epoch 4030, Loss: 0.0042049944122481975, Final Batch Loss: 1.2422234249243047e-05\n",
      "Epoch 4031, Loss: 0.002064153566607274, Final Batch Loss: 3.277516952948645e-05\n",
      "Epoch 4032, Loss: 0.04422292356065327, Final Batch Loss: 3.491124402899004e-07\n",
      "Epoch 4033, Loss: 0.002641934210259933, Final Batch Loss: 1.5155055734794587e-05\n",
      "Epoch 4034, Loss: 0.005011706827644957, Final Batch Loss: 4.942096347804181e-05\n",
      "Epoch 4035, Loss: 0.001835159323491098, Final Batch Loss: 0.00023837592743802816\n",
      "Epoch 4036, Loss: 0.003486689100100193, Final Batch Loss: 0.0005071921041235328\n",
      "Epoch 4037, Loss: 0.0029969822541744406, Final Batch Loss: 1.447539972332379e-07\n",
      "Epoch 4038, Loss: 0.004981550293450709, Final Batch Loss: 0.0\n",
      "Epoch 4039, Loss: 0.0015087962979123404, Final Batch Loss: 4.333983724791324e-06\n",
      "Epoch 4040, Loss: 0.001190557734844333, Final Batch Loss: 1.3776117157249246e-05\n",
      "Epoch 4041, Loss: 0.0030060604767641053, Final Batch Loss: 0.0003645222168415785\n",
      "Epoch 4042, Loss: 0.004118752554859384, Final Batch Loss: 1.779405829438474e-05\n",
      "Epoch 4043, Loss: 0.004271272697224049, Final Batch Loss: 0.0004758706199936569\n",
      "Epoch 4044, Loss: 0.0018750813433143776, Final Batch Loss: 0.0007321396260522306\n",
      "Epoch 4045, Loss: 0.004602671615430154, Final Batch Loss: 0.0001586789294378832\n",
      "Epoch 4046, Loss: 0.0034944095303721667, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4047, Loss: 0.00760315003208234, Final Batch Loss: 2.196833520429209e-06\n",
      "Epoch 4048, Loss: 0.0021809910147112532, Final Batch Loss: 1.302775444855797e-06\n",
      "Epoch 4049, Loss: 0.001286315109609859, Final Batch Loss: 5.0850303523475304e-05\n",
      "Epoch 4050, Loss: 0.0035912124076276086, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4051, Loss: 0.01079372054403649, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4052, Loss: 0.006752402492566034, Final Batch Loss: 0.0\n",
      "Epoch 4053, Loss: 0.0009144480572764735, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 4054, Loss: 0.007639216710231267, Final Batch Loss: 0.0\n",
      "Epoch 4055, Loss: 0.001978447461624455, Final Batch Loss: 1.0481458048161585e-05\n",
      "Epoch 4056, Loss: 0.0018692486896725313, Final Batch Loss: 2.0009915715490934e-06\n",
      "Epoch 4057, Loss: 0.003804837048647869, Final Batch Loss: 3.491120708076778e-07\n",
      "Epoch 4058, Loss: 0.0013139786730853587, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 4059, Loss: 0.0014821497282042628, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 4060, Loss: 0.0012066615331605135, Final Batch Loss: 4.9470186240796465e-06\n",
      "Epoch 4061, Loss: 0.0027260015122010373, Final Batch Loss: 0.00038787032826803625\n",
      "Epoch 4062, Loss: 0.0008909983407647815, Final Batch Loss: 6.94245973136276e-05\n",
      "Epoch 4063, Loss: 0.0004080947169313731, Final Batch Loss: 4.265863481123233e-06\n",
      "Epoch 4064, Loss: 0.0016592478568782099, Final Batch Loss: 0.0\n",
      "Epoch 4065, Loss: 0.0005661119650994806, Final Batch Loss: 2.733246446950943e-06\n",
      "Epoch 4066, Loss: 0.0010925176356977317, Final Batch Loss: 0.0\n",
      "Epoch 4067, Loss: 0.002984701885516472, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4068, Loss: 0.0006603043038921896, Final Batch Loss: 7.68858808442019e-06\n",
      "Epoch 4069, Loss: 0.000575687496620958, Final Batch Loss: 2.077619228657568e-06\n",
      "Epoch 4070, Loss: 0.0011986670779720043, Final Batch Loss: 6.726777996846067e-07\n",
      "Epoch 4071, Loss: 0.0010585699819785077, Final Batch Loss: 4.169439125689678e-05\n",
      "Epoch 4072, Loss: 0.0017423142389816348, Final Batch Loss: 7.663137694180477e-06\n",
      "Epoch 4073, Loss: 0.0013827662769472227, Final Batch Loss: 0.00047991148312576115\n",
      "Epoch 4074, Loss: 0.0023860336859797826, Final Batch Loss: 2.3003702153800987e-05\n",
      "Epoch 4075, Loss: 0.006883394588840019, Final Batch Loss: 0.0001505303371232003\n",
      "Epoch 4076, Loss: 0.0058307221879658755, Final Batch Loss: 0.0\n",
      "Epoch 4077, Loss: 0.011782140132176266, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4078, Loss: 0.012933304369653342, Final Batch Loss: 0.000221648981096223\n",
      "Epoch 4079, Loss: 0.0007961815192949473, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4080, Loss: 0.007072584713824881, Final Batch Loss: 1.6178390183085867e-07\n",
      "Epoch 4081, Loss: 0.03881353051929182, Final Batch Loss: 0.01887090504169464\n",
      "Epoch 4082, Loss: 0.006812381560198588, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4083, Loss: 0.07971052403445356, Final Batch Loss: 0.04962655529379845\n",
      "Epoch 4084, Loss: 0.0006098016356190783, Final Batch Loss: 4.22335051553091e-06\n",
      "Epoch 4085, Loss: 0.002830133415045566, Final Batch Loss: 2.0296754883020185e-05\n",
      "Epoch 4086, Loss: 0.05997466322488165, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 4087, Loss: 0.021315171491551155, Final Batch Loss: 1.2916009836771991e-05\n",
      "Epoch 4088, Loss: 0.03784348706020424, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4089, Loss: 0.028910313063533977, Final Batch Loss: 0.00015501661982852966\n",
      "Epoch 4090, Loss: 0.01124069497018354, Final Batch Loss: 0.0\n",
      "Epoch 4091, Loss: 0.02586287329904735, Final Batch Loss: 0.0029518839437514544\n",
      "Epoch 4092, Loss: 0.010416308920866868, Final Batch Loss: 9.501276508672163e-05\n",
      "Epoch 4093, Loss: 0.0018191135916687529, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4094, Loss: 0.023335105402381373, Final Batch Loss: 2.2990325021510216e-07\n",
      "Epoch 4095, Loss: 0.01730136718833819, Final Batch Loss: 0.0\n",
      "Epoch 4096, Loss: 0.007573393274336482, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4097, Loss: 0.007298838174619959, Final Batch Loss: 3.729457830559113e-06\n",
      "Epoch 4098, Loss: 0.003355398483108729, Final Batch Loss: 0.0\n",
      "Epoch 4099, Loss: 0.0057314279256388545, Final Batch Loss: 0.004049974028021097\n",
      "Epoch 4100, Loss: 0.0026485339003556874, Final Batch Loss: 5.3589912567986175e-05\n",
      "Epoch 4101, Loss: 0.00263890549831558, Final Batch Loss: 0.0002663543855305761\n",
      "Epoch 4102, Loss: 0.010351609191275202, Final Batch Loss: 0.00010088393173646182\n",
      "Epoch 4103, Loss: 0.0036128549836575985, Final Batch Loss: 0.001061898423358798\n",
      "Epoch 4104, Loss: 0.012707277214246915, Final Batch Loss: 5.960450266684347e-07\n",
      "Epoch 4105, Loss: 0.0020384047493280377, Final Batch Loss: 0.0007320524309761822\n",
      "Epoch 4106, Loss: 0.0041818976647558515, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4107, Loss: 0.0051131786767655285, Final Batch Loss: 0.0\n",
      "Epoch 4108, Loss: 0.0026693275176512543, Final Batch Loss: 0.0012710683513432741\n",
      "Epoch 4109, Loss: 0.007939582712992888, Final Batch Loss: 1.3198083479437628e-06\n",
      "Epoch 4110, Loss: 0.0013647360107142958, Final Batch Loss: 1.813671246964077e-06\n",
      "Epoch 4111, Loss: 0.005684615764181444, Final Batch Loss: 3.150527447814966e-07\n",
      "Epoch 4112, Loss: 0.0011789205495915667, Final Batch Loss: 7.4672211667348165e-06\n",
      "Epoch 4113, Loss: 0.004762984448461793, Final Batch Loss: 0.0\n",
      "Epoch 4114, Loss: 0.0023304457634552023, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 4115, Loss: 0.07240826346242102, Final Batch Loss: 0.0713324174284935\n",
      "Epoch 4116, Loss: 0.005425655681619901, Final Batch Loss: 2.3245431748364354e-06\n",
      "Epoch 4117, Loss: 0.018018023351032753, Final Batch Loss: 0.00011021240061381832\n",
      "Epoch 4118, Loss: 0.01866251439878397, Final Batch Loss: 1.4986153473728336e-06\n",
      "Epoch 4119, Loss: 0.009879882372388238, Final Batch Loss: 7.56087456466048e-06\n",
      "Epoch 4120, Loss: 0.006761921784345759, Final Batch Loss: 4.26642618549522e-05\n",
      "Epoch 4121, Loss: 0.012851201867306372, Final Batch Loss: 3.9838898374000564e-05\n",
      "Epoch 4122, Loss: 0.014001662068039877, Final Batch Loss: 0.00027591275284066796\n",
      "Epoch 4123, Loss: 0.007728251331805325, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4124, Loss: 0.003389668308045657, Final Batch Loss: 1.0217226190434303e-05\n",
      "Epoch 4125, Loss: 0.00699106957836193, Final Batch Loss: 0.006623827386647463\n",
      "Epoch 4126, Loss: 0.01042053292182743, Final Batch Loss: 2.2138844713026629e-07\n",
      "Epoch 4127, Loss: 0.009515152980110742, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 4128, Loss: 0.0009979449619095249, Final Batch Loss: 4.3084669414383825e-06\n",
      "Epoch 4129, Loss: 0.021421701528197445, Final Batch Loss: 4.802303919859696e-06\n",
      "Epoch 4130, Loss: 0.001903743559765303, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 4131, Loss: 0.0026208394738205243, Final Batch Loss: 0.0\n",
      "Epoch 4132, Loss: 0.0046066692484600935, Final Batch Loss: 0.000767749734222889\n",
      "Epoch 4133, Loss: 0.010626237783583292, Final Batch Loss: 5.534698743758781e-07\n",
      "Epoch 4134, Loss: 0.022588504565646872, Final Batch Loss: 0.0\n",
      "Epoch 4135, Loss: 0.01405725086806342, Final Batch Loss: 8.008076110854745e-05\n",
      "Epoch 4136, Loss: 0.024551372648573988, Final Batch Loss: 1.532689282157662e-07\n",
      "Epoch 4137, Loss: 0.0017576490830748526, Final Batch Loss: 1.9584366839353606e-07\n",
      "Epoch 4138, Loss: 0.008375651238679893, Final Batch Loss: 5.108951199872536e-07\n",
      "Epoch 4139, Loss: 0.008983788487967104, Final Batch Loss: 0.0022724061273038387\n",
      "Epoch 4140, Loss: 0.09906087792114704, Final Batch Loss: 0.09820321947336197\n",
      "Epoch 4141, Loss: 0.0032258693945408368, Final Batch Loss: 1.5326894242662092e-07\n",
      "Epoch 4142, Loss: 0.029062603760394268, Final Batch Loss: 0.000242994909058325\n",
      "Epoch 4143, Loss: 0.003750538111489732, Final Batch Loss: 1.2379663530737162e-05\n",
      "Epoch 4144, Loss: 0.0018782191718855756, Final Batch Loss: 8.071731826930773e-06\n",
      "Epoch 4145, Loss: 0.00202871450164821, Final Batch Loss: 7.585162529721856e-05\n",
      "Epoch 4146, Loss: 0.0014181408569129417, Final Batch Loss: 3.925285454897676e-06\n",
      "Epoch 4147, Loss: 0.019317998456600094, Final Batch Loss: 1.9584366839353606e-07\n",
      "Epoch 4148, Loss: 0.04948245974446763, Final Batch Loss: 0.0\n",
      "Epoch 4149, Loss: 0.0012428988625288184, Final Batch Loss: 4.25735152020934e-06\n",
      "Epoch 4150, Loss: 0.014663419904536568, Final Batch Loss: 0.0009992180857807398\n",
      "Epoch 4151, Loss: 0.003204661581548862, Final Batch Loss: 0.00010247518366668373\n",
      "Epoch 4152, Loss: 0.0010552141902735457, Final Batch Loss: 0.00020812208822462708\n",
      "Epoch 4153, Loss: 0.023751284754538915, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 4154, Loss: 0.022821152044294024, Final Batch Loss: 1.1920923981278975e-07\n",
      "Epoch 4155, Loss: 0.004784387993645112, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 4156, Loss: 0.013353546931227811, Final Batch Loss: 3.405975235182268e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4157, Loss: 0.0012770149540788367, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4158, Loss: 0.0017163225652438996, Final Batch Loss: 5.057701400801307e-06\n",
      "Epoch 4159, Loss: 0.006715346891724039, Final Batch Loss: 5.399104702519253e-05\n",
      "Epoch 4160, Loss: 0.004155992691266874, Final Batch Loss: 0.0002935766242444515\n",
      "Epoch 4161, Loss: 0.0010978764797187068, Final Batch Loss: 5.534705564969045e-07\n",
      "Epoch 4162, Loss: 0.047612789589038584, Final Batch Loss: 8.812428859528154e-06\n",
      "Epoch 4163, Loss: 0.02036190967692164, Final Batch Loss: 1.7029879018082283e-07\n",
      "Epoch 4164, Loss: 0.004914305784016193, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 4165, Loss: 0.0007763011262795771, Final Batch Loss: 4.6234772526076995e-06\n",
      "Epoch 4166, Loss: 0.004938051293720491, Final Batch Loss: 0.0005504186265170574\n",
      "Epoch 4167, Loss: 0.019547935369423897, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4168, Loss: 0.0015224557282635942, Final Batch Loss: 0.00028563084197230637\n",
      "Epoch 4169, Loss: 0.0014406109285118873, Final Batch Loss: 1.4150605238683056e-05\n",
      "Epoch 4170, Loss: 0.0015389163527288474, Final Batch Loss: 0.0005673423293046653\n",
      "Epoch 4171, Loss: 0.0018397117019048892, Final Batch Loss: 0.0013097868068143725\n",
      "Epoch 4172, Loss: 0.0015075071169121657, Final Batch Loss: 0.00037678072112612426\n",
      "Epoch 4173, Loss: 0.0012886304903076962, Final Batch Loss: 7.685872697038576e-05\n",
      "Epoch 4174, Loss: 0.0064744434457679745, Final Batch Loss: 1.904549208120443e-05\n",
      "Epoch 4175, Loss: 0.0022321344149531797, Final Batch Loss: 0.0\n",
      "Epoch 4176, Loss: 0.00166041158081498, Final Batch Loss: 0.00017795457097236067\n",
      "Epoch 4177, Loss: 0.0018183808206231333, Final Batch Loss: 0.00016921288624871522\n",
      "Epoch 4178, Loss: 0.0010451056521105784, Final Batch Loss: 1.856242988651502e-06\n",
      "Epoch 4179, Loss: 0.0029396857125902898, Final Batch Loss: 1.2328581760812085e-05\n",
      "Epoch 4180, Loss: 0.0029090319733633407, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4181, Loss: 0.0007566431216083913, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4182, Loss: 0.003043863413040526, Final Batch Loss: 0.0\n",
      "Epoch 4183, Loss: 0.0011937276758544613, Final Batch Loss: 1.707043338683434e-05\n",
      "Epoch 4184, Loss: 0.021952211866846483, Final Batch Loss: 2.8099293558625504e-07\n",
      "Epoch 4185, Loss: 0.001298872521147132, Final Batch Loss: 0.0002003395784413442\n",
      "Epoch 4186, Loss: 0.0010999295489284577, Final Batch Loss: 2.1287340246090025e-07\n",
      "Epoch 4187, Loss: 0.019916700170142576, Final Batch Loss: 6.584983202628791e-05\n",
      "Epoch 4188, Loss: 0.0033039097232858694, Final Batch Loss: 7.833713198124315e-07\n",
      "Epoch 4189, Loss: 0.0029056052777090002, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4190, Loss: 0.0007630274333223497, Final Batch Loss: 9.621865046938183e-07\n",
      "Epoch 4191, Loss: 0.00904189902212238, Final Batch Loss: 5.075723311165348e-05\n",
      "Epoch 4192, Loss: 0.0009492763856542297, Final Batch Loss: 0.0\n",
      "Epoch 4193, Loss: 0.0018424499066895805, Final Batch Loss: 0.00010993700561812147\n",
      "Epoch 4194, Loss: 0.02583969762781635, Final Batch Loss: 0.00048706607776694\n",
      "Epoch 4195, Loss: 0.010188308529905044, Final Batch Loss: 0.0003244830877520144\n",
      "Epoch 4196, Loss: 0.0019322328334965277, Final Batch Loss: 5.568324195337482e-05\n",
      "Epoch 4197, Loss: 0.005235891092784328, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4198, Loss: 0.001116885119699873, Final Batch Loss: 0.0\n",
      "Epoch 4199, Loss: 0.008065745727890317, Final Batch Loss: 6.121989372331882e-06\n",
      "Epoch 4200, Loss: 0.008637480234028772, Final Batch Loss: 0.0016418049344792962\n",
      "Epoch 4201, Loss: 0.0017446850362148325, Final Batch Loss: 9.621836625228752e-07\n",
      "Epoch 4202, Loss: 0.0012939161770191276, Final Batch Loss: 0.0\n",
      "Epoch 4203, Loss: 0.01144730636588065, Final Batch Loss: 6.317171937553212e-05\n",
      "Epoch 4204, Loss: 0.012656165011321718, Final Batch Loss: 0.00014521951379720122\n",
      "Epoch 4205, Loss: 0.0010829174445916578, Final Batch Loss: 1.4134677712718258e-06\n",
      "Epoch 4206, Loss: 0.008600998891779454, Final Batch Loss: 0.006464035250246525\n",
      "Epoch 4207, Loss: 0.0022310760396067053, Final Batch Loss: 0.0\n",
      "Epoch 4208, Loss: 0.0005697161104762927, Final Batch Loss: 0.0\n",
      "Epoch 4209, Loss: 0.00048219371819868684, Final Batch Loss: 0.0\n",
      "Epoch 4210, Loss: 0.0013341974990908056, Final Batch Loss: 2.631073584780097e-06\n",
      "Epoch 4211, Loss: 0.0024767098802840337, Final Batch Loss: 0.0008576760301366448\n",
      "Epoch 4212, Loss: 0.0011148130706715165, Final Batch Loss: 0.00015272437303792685\n",
      "Epoch 4213, Loss: 0.0015661831330362475, Final Batch Loss: 0.0\n",
      "Epoch 4214, Loss: 0.002237003529444337, Final Batch Loss: 0.0\n",
      "Epoch 4215, Loss: 0.002467779193352726, Final Batch Loss: 1.0984202845065738e-06\n",
      "Epoch 4216, Loss: 0.0007861782347102775, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4217, Loss: 0.0006296699576751053, Final Batch Loss: 1.3623795211969991e-06\n",
      "Epoch 4218, Loss: 0.00230837878643797, Final Batch Loss: 1.0361950444348622e-05\n",
      "Epoch 4219, Loss: 0.0010635246326273773, Final Batch Loss: 2.4878438125597313e-05\n",
      "Epoch 4220, Loss: 0.0006158163523650728, Final Batch Loss: 0.00015076824638526887\n",
      "Epoch 4221, Loss: 0.00259670041816662, Final Batch Loss: 2.3841823804104934e-07\n",
      "Epoch 4222, Loss: 0.0007880588835860181, Final Batch Loss: 1.0047568821391906e-06\n",
      "Epoch 4223, Loss: 0.0013104005065542879, Final Batch Loss: 1.554661685077008e-05\n",
      "Epoch 4224, Loss: 0.01257341486400776, Final Batch Loss: 1.7881377800677e-07\n",
      "Epoch 4225, Loss: 0.0032485823903698474, Final Batch Loss: 0.0014324347721412778\n",
      "Epoch 4226, Loss: 0.009760679706232622, Final Batch Loss: 7.825263310223818e-05\n",
      "Epoch 4227, Loss: 0.0006356534816269743, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4228, Loss: 0.0009179103267342725, Final Batch Loss: 6.7520354605221655e-06\n",
      "Epoch 4229, Loss: 0.00299072646311771, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4230, Loss: 0.0017151014362752903, Final Batch Loss: 0.0002958938421215862\n",
      "Epoch 4231, Loss: 0.0015938920878397767, Final Batch Loss: 0.0\n",
      "Epoch 4232, Loss: 0.0015493265163968317, Final Batch Loss: 0.0\n",
      "Epoch 4233, Loss: 0.0019360958311409604, Final Batch Loss: 8.514946614468499e-08\n",
      "Epoch 4234, Loss: 0.0012036539381483635, Final Batch Loss: 8.429749982497015e-07\n",
      "Epoch 4235, Loss: 0.0033274009474553168, Final Batch Loss: 0.0\n",
      "Epoch 4236, Loss: 0.0046593181150456076, Final Batch Loss: 0.0014747962122783065\n",
      "Epoch 4237, Loss: 0.0004645955596060958, Final Batch Loss: 3.411141733522527e-05\n",
      "Epoch 4238, Loss: 0.00022050653049987545, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4239, Loss: 0.0035078739801974734, Final Batch Loss: 2.4714621758903377e-05\n",
      "Epoch 4240, Loss: 0.0007733323791399016, Final Batch Loss: 2.3415796022163704e-06\n",
      "Epoch 4241, Loss: 0.0014010550702323599, Final Batch Loss: 7.493116527257371e-07\n",
      "Epoch 4242, Loss: 0.002315303526529533, Final Batch Loss: 3.3718772556312615e-06\n",
      "Epoch 4243, Loss: 0.002491884645323239, Final Batch Loss: 2.0435855674350023e-07\n",
      "Epoch 4244, Loss: 0.016899213573196903, Final Batch Loss: 8.817813795758411e-05\n",
      "Epoch 4245, Loss: 0.0011519098692751584, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4246, Loss: 0.002107787619024748, Final Batch Loss: 3.2766827644081786e-05\n",
      "Epoch 4247, Loss: 0.0008547857250960078, Final Batch Loss: 0.0\n",
      "Epoch 4248, Loss: 0.000877701066979597, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4249, Loss: 0.0010343152207497042, Final Batch Loss: 0.00018100593297276646\n",
      "Epoch 4250, Loss: 0.0009790780086404993, Final Batch Loss: 0.0\n",
      "Epoch 4251, Loss: 0.0011775965049309889, Final Batch Loss: 0.0\n",
      "Epoch 4252, Loss: 0.009015107313251391, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4253, Loss: 0.0005472199366352015, Final Batch Loss: 1.6178390183085867e-07\n",
      "Epoch 4254, Loss: 0.0006285115437094646, Final Batch Loss: 5.117379714647541e-06\n",
      "Epoch 4255, Loss: 0.001045644627343023, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4256, Loss: 0.009709109137475025, Final Batch Loss: 0.002121806377544999\n",
      "Epoch 4257, Loss: 0.0018791144684655592, Final Batch Loss: 0.00020754076831508428\n",
      "Epoch 4258, Loss: 0.002340149789233692, Final Batch Loss: 0.0\n",
      "Epoch 4259, Loss: 0.002208890927590801, Final Batch Loss: 7.748561756670824e-07\n",
      "Epoch 4260, Loss: 0.0023836221953388304, Final Batch Loss: 0.0\n",
      "Epoch 4261, Loss: 0.004298495898442667, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4262, Loss: 0.004243013052949607, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4263, Loss: 0.0006344012945191935, Final Batch Loss: 9.402501018485054e-05\n",
      "Epoch 4264, Loss: 0.0012688030510616954, Final Batch Loss: 2.638295518408995e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4265, Loss: 0.0005303416510287207, Final Batch Loss: 2.8996186301810667e-05\n",
      "Epoch 4266, Loss: 0.0010600300348126979, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4267, Loss: 0.00433902764671501, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 4268, Loss: 0.0025467573723041426, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 4269, Loss: 0.018723400080432384, Final Batch Loss: 3.1505254582953057e-07\n",
      "Epoch 4270, Loss: 0.0018229747459237444, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4271, Loss: 0.008945602938183583, Final Batch Loss: 0.0\n",
      "Epoch 4272, Loss: 0.014137529673462268, Final Batch Loss: 0.0\n",
      "Epoch 4273, Loss: 0.0018105576850011573, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4274, Loss: 0.001108469370592502, Final Batch Loss: 1.0013203791459091e-05\n",
      "Epoch 4275, Loss: 0.022435414038440626, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 4276, Loss: 0.0010881503694690764, Final Batch Loss: 0.00022390017693396658\n",
      "Epoch 4277, Loss: 0.005135065546710393, Final Batch Loss: 0.0\n",
      "Epoch 4278, Loss: 0.002106371903209947, Final Batch Loss: 0.0007525999681092799\n",
      "Epoch 4279, Loss: 0.006299277755715593, Final Batch Loss: 4.947072739014402e-06\n",
      "Epoch 4280, Loss: 0.005329696329226863, Final Batch Loss: 2.222367129434133e-06\n",
      "Epoch 4281, Loss: 0.0014195954040587822, Final Batch Loss: 6.445593953685602e-06\n",
      "Epoch 4282, Loss: 0.0027969112104031524, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4283, Loss: 0.017843774672655854, Final Batch Loss: 6.925255729584023e-05\n",
      "Epoch 4284, Loss: 0.0006628140326938592, Final Batch Loss: 0.0\n",
      "Epoch 4285, Loss: 0.00584689142328898, Final Batch Loss: 9.706984656077111e-07\n",
      "Epoch 4286, Loss: 0.019236595412166935, Final Batch Loss: 5.193940978642786e-06\n",
      "Epoch 4287, Loss: 0.008033195174903085, Final Batch Loss: 3.7609141145367175e-05\n",
      "Epoch 4288, Loss: 0.0057922888217945, Final Batch Loss: 9.306421816290822e-06\n",
      "Epoch 4289, Loss: 0.020515263900961145, Final Batch Loss: 0.005607339553534985\n",
      "Epoch 4290, Loss: 0.05033189024834428, Final Batch Loss: 0.0006427631014958024\n",
      "Epoch 4291, Loss: 0.003719744525369606, Final Batch Loss: 1.5053081369842403e-05\n",
      "Epoch 4292, Loss: 0.001156864208951447, Final Batch Loss: 8.497444468957838e-06\n",
      "Epoch 4293, Loss: 0.03582769354397897, Final Batch Loss: 0.0008173911483027041\n",
      "Epoch 4294, Loss: 0.009945889734279234, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4295, Loss: 0.0018924106720987766, Final Batch Loss: 2.545924417063361e-06\n",
      "Epoch 4296, Loss: 0.0005718552802136401, Final Batch Loss: 2.0696841602330096e-05\n",
      "Epoch 4297, Loss: 0.000869186180352699, Final Batch Loss: 5.775096724391915e-05\n",
      "Epoch 4298, Loss: 0.15780622720655657, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 4299, Loss: 0.00076481494033942, Final Batch Loss: 0.00010818948067026213\n",
      "Epoch 4300, Loss: 0.028472851070546312, Final Batch Loss: 4.6663724788231775e-05\n",
      "Epoch 4301, Loss: 0.07972111543273286, Final Batch Loss: 6.811947628193593e-07\n",
      "Epoch 4302, Loss: 0.032825602174852975, Final Batch Loss: 0.0002072975767077878\n",
      "Epoch 4303, Loss: 0.007421067886753008, Final Batch Loss: 0.004922146908938885\n",
      "Epoch 4304, Loss: 0.001574424073623959, Final Batch Loss: 0.00038706077612005174\n",
      "Epoch 4305, Loss: 0.005326389513356844, Final Batch Loss: 3.100738467765041e-05\n",
      "Epoch 4306, Loss: 0.0005366908823205563, Final Batch Loss: 1.1069426619769729e-07\n",
      "Epoch 4307, Loss: 0.0015655605207030021, Final Batch Loss: 7.16942713552271e-06\n",
      "Epoch 4308, Loss: 0.0012177216704003513, Final Batch Loss: 0.0\n",
      "Epoch 4309, Loss: 0.014212200941528863, Final Batch Loss: 3.6187634577800054e-06\n",
      "Epoch 4310, Loss: 0.0008866405732987914, Final Batch Loss: 3.955396459787153e-05\n",
      "Epoch 4311, Loss: 0.0009348245509457342, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4312, Loss: 0.0009151196077255008, Final Batch Loss: 4.6490190470649395e-06\n",
      "Epoch 4313, Loss: 0.0012099447931177565, Final Batch Loss: 1.3724821656069253e-05\n",
      "Epoch 4314, Loss: 0.008359746614587493, Final Batch Loss: 0.0001510331203462556\n",
      "Epoch 4315, Loss: 0.0019043694774154574, Final Batch Loss: 0.000707896426320076\n",
      "Epoch 4316, Loss: 0.00461565062218483, Final Batch Loss: 2.809927934777079e-07\n",
      "Epoch 4317, Loss: 0.0021790530045109335, Final Batch Loss: 2.9660044674528763e-05\n",
      "Epoch 4318, Loss: 0.008062993287239806, Final Batch Loss: 1.2354708815109916e-05\n",
      "Epoch 4319, Loss: 0.0012305913774710575, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4320, Loss: 0.007229960236127653, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 4321, Loss: 0.006275932042626664, Final Batch Loss: 3.286695573478937e-06\n",
      "Epoch 4322, Loss: 0.0019186672088835621, Final Batch Loss: 0.0001958424545591697\n",
      "Epoch 4323, Loss: 0.059541727820374035, Final Batch Loss: 5.279256356516271e-07\n",
      "Epoch 4324, Loss: 0.00042644592758023236, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 4325, Loss: 0.010154206863262516, Final Batch Loss: 7.816318429831881e-06\n",
      "Epoch 4326, Loss: 0.0005275809835438849, Final Batch Loss: 2.060600309050642e-06\n",
      "Epoch 4327, Loss: 0.0009823134270163791, Final Batch Loss: 1.1920884617211414e-06\n",
      "Epoch 4328, Loss: 0.010219430556389852, Final Batch Loss: 2.396791933279019e-05\n",
      "Epoch 4329, Loss: 0.0006503747621167122, Final Batch Loss: 1.6178397288513224e-07\n",
      "Epoch 4330, Loss: 0.003069378408586232, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4331, Loss: 0.006948397212127588, Final Batch Loss: 3.4059794984386826e-08\n",
      "Epoch 4332, Loss: 0.004250567260896787, Final Batch Loss: 0.00015496595005970448\n",
      "Epoch 4333, Loss: 0.0007115122734830948, Final Batch Loss: 2.086712993332185e-05\n",
      "Epoch 4334, Loss: 0.0006080288794692024, Final Batch Loss: 1.0158059922105167e-05\n",
      "Epoch 4335, Loss: 0.0006167493911561905, Final Batch Loss: 1.0838731213880237e-05\n",
      "Epoch 4336, Loss: 0.001386735431424313, Final Batch Loss: 4.912958956992952e-06\n",
      "Epoch 4337, Loss: 0.006752082055754727, Final Batch Loss: 0.00024880885030142963\n",
      "Epoch 4338, Loss: 0.0006691416965622921, Final Batch Loss: 0.0003230662550777197\n",
      "Epoch 4339, Loss: 0.0005760026371106619, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4340, Loss: 0.0016636409091006499, Final Batch Loss: 0.0008523119613528252\n",
      "Epoch 4341, Loss: 0.0011017177698704472, Final Batch Loss: 5.4750075832998846e-06\n",
      "Epoch 4342, Loss: 0.014258215956033382, Final Batch Loss: 8.102523861452937e-05\n",
      "Epoch 4343, Loss: 0.00012034979044983629, Final Batch Loss: 1.710568722046446e-05\n",
      "Epoch 4344, Loss: 0.0006551409917392448, Final Batch Loss: 5.279255219647894e-07\n",
      "Epoch 4345, Loss: 0.0010131858039130748, Final Batch Loss: 3.3463115869381e-06\n",
      "Epoch 4346, Loss: 0.0015904159990896005, Final Batch Loss: 0.0\n",
      "Epoch 4347, Loss: 0.0013004742004341097, Final Batch Loss: 9.408501682628412e-06\n",
      "Epoch 4348, Loss: 0.002133596201929322, Final Batch Loss: 5.0151293180533685e-06\n",
      "Epoch 4349, Loss: 0.0007517094145441661, Final Batch Loss: 0.0\n",
      "Epoch 4350, Loss: 0.008401518043683609, Final Batch Loss: 3.1081326596904546e-05\n",
      "Epoch 4351, Loss: 0.0006699892541455199, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4352, Loss: 0.0024290250530611956, Final Batch Loss: 0.0018548788502812386\n",
      "Epoch 4353, Loss: 0.0010977801830449607, Final Batch Loss: 4.820787944481708e-05\n",
      "Epoch 4354, Loss: 0.010437231228934252, Final Batch Loss: 2.65130747720832e-05\n",
      "Epoch 4355, Loss: 0.0031569894392760034, Final Batch Loss: 2.443766106807743e-06\n",
      "Epoch 4356, Loss: 0.0035069917503278702, Final Batch Loss: 0.0\n",
      "Epoch 4357, Loss: 0.030451905185145733, Final Batch Loss: 4.930161594529636e-05\n",
      "Epoch 4358, Loss: 0.0019034588176509715, Final Batch Loss: 2.8099293558625504e-07\n",
      "Epoch 4359, Loss: 0.001296164908751507, Final Batch Loss: 5.61984677460714e-07\n",
      "Epoch 4360, Loss: 0.0006385777742252685, Final Batch Loss: 0.0\n",
      "Epoch 4361, Loss: 0.0006527291914153466, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 4362, Loss: 0.0009081968673854135, Final Batch Loss: 2.2050326151656918e-05\n",
      "Epoch 4363, Loss: 0.0009050487024069298, Final Batch Loss: 0.0001004313089651987\n",
      "Epoch 4364, Loss: 0.00529237034174912, Final Batch Loss: 1.8647599517862545e-06\n",
      "Epoch 4365, Loss: 0.0009024503241334969, Final Batch Loss: 2.1287348772602854e-07\n",
      "Epoch 4366, Loss: 0.004573407439238508, Final Batch Loss: 0.0023922380059957504\n",
      "Epoch 4367, Loss: 0.0008663906801871235, Final Batch Loss: 2.8950768182767206e-07\n",
      "Epoch 4368, Loss: 0.0019445702615144, Final Batch Loss: 7.833710355953372e-07\n",
      "Epoch 4369, Loss: 0.02296440774797759, Final Batch Loss: 1.1920919007479824e-07\n",
      "Epoch 4370, Loss: 0.00027067490100307623, Final Batch Loss: 5.9602762121357955e-06\n",
      "Epoch 4371, Loss: 0.0017271731994696893, Final Batch Loss: 6.803122232668102e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4372, Loss: 0.01311079906008672, Final Batch Loss: 0.0\n",
      "Epoch 4373, Loss: 0.00030326288234761023, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4374, Loss: 0.0011172267767562971, Final Batch Loss: 3.1505251740782114e-07\n",
      "Epoch 4375, Loss: 0.0033702987420838326, Final Batch Loss: 0.000678268785122782\n",
      "Epoch 4376, Loss: 0.003932174765395757, Final Batch Loss: 0.00016505799430888146\n",
      "Epoch 4377, Loss: 0.0007175759637902956, Final Batch Loss: 4.1838862671284005e-05\n",
      "Epoch 4378, Loss: 0.0010476642091816757, Final Batch Loss: 4.2137591663049534e-05\n",
      "Epoch 4379, Loss: 0.0008523565177576131, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4380, Loss: 0.0006146811192593304, Final Batch Loss: 6.334845238598064e-06\n",
      "Epoch 4381, Loss: 0.0026522793632466346, Final Batch Loss: 0.0006814607186242938\n",
      "Epoch 4382, Loss: 0.000526851188396904, Final Batch Loss: 3.0823450742900604e-06\n",
      "Epoch 4383, Loss: 0.00038950147427385673, Final Batch Loss: 0.0\n",
      "Epoch 4384, Loss: 0.0004444390469870996, Final Batch Loss: 0.0\n",
      "Epoch 4385, Loss: 0.001534811506871847, Final Batch Loss: 1.0217866019957e-06\n",
      "Epoch 4386, Loss: 0.0023747340819681995, Final Batch Loss: 0.0\n",
      "Epoch 4387, Loss: 0.01688881121299346, Final Batch Loss: 0.003822537837550044\n",
      "Epoch 4388, Loss: 0.0005855830814169849, Final Batch Loss: 2.2138833344342856e-07\n",
      "Epoch 4389, Loss: 0.007261055321578169, Final Batch Loss: 0.006639630533754826\n",
      "Epoch 4390, Loss: 0.0007857977980165742, Final Batch Loss: 0.0\n",
      "Epoch 4391, Loss: 0.001016160479082373, Final Batch Loss: 4.768357371176535e-07\n",
      "Epoch 4392, Loss: 0.029088934825267643, Final Batch Loss: 0.0003594043664634228\n",
      "Epoch 4393, Loss: 0.0011338184326632472, Final Batch Loss: 5.440846962301293e-06\n",
      "Epoch 4394, Loss: 0.001689100684245659, Final Batch Loss: 3.4911209922938724e-07\n",
      "Epoch 4395, Loss: 0.0018535717558734177, Final Batch Loss: 6.232791292859474e-06\n",
      "Epoch 4396, Loss: 0.004154762857545791, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4397, Loss: 0.003899501977741693, Final Batch Loss: 8.259476658167841e-07\n",
      "Epoch 4398, Loss: 0.00441383332508849, Final Batch Loss: 0.0019753058440983295\n",
      "Epoch 4399, Loss: 0.0009537069041698487, Final Batch Loss: 1.1324797242195928e-06\n",
      "Epoch 4400, Loss: 0.00034780509371046264, Final Batch Loss: 2.0435867043033795e-07\n",
      "Epoch 4401, Loss: 0.001375629565522729, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 4402, Loss: 0.00025732156245794613, Final Batch Loss: 0.0\n",
      "Epoch 4403, Loss: 0.0013830323696311098, Final Batch Loss: 0.0009583120117895305\n",
      "Epoch 4404, Loss: 0.0007585742017681696, Final Batch Loss: 1.2176273003206006e-06\n",
      "Epoch 4405, Loss: 0.03611082495262963, Final Batch Loss: 2.9702485335292295e-05\n",
      "Epoch 4406, Loss: 0.0027091105917449454, Final Batch Loss: 7.663452805672932e-08\n",
      "Epoch 4407, Loss: 0.0007160173754527932, Final Batch Loss: 0.000128366649732925\n",
      "Epoch 4408, Loss: 0.0009798825579174775, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4409, Loss: 0.0005928262239933701, Final Batch Loss: 2.0435848568922665e-07\n",
      "Epoch 4410, Loss: 0.001562388613820076, Final Batch Loss: 0.0\n",
      "Epoch 4411, Loss: 0.005905021927901544, Final Batch Loss: 0.004962126258760691\n",
      "Epoch 4412, Loss: 0.003951318770429424, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 4413, Loss: 0.001098797767287607, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 4414, Loss: 0.0009286903805332258, Final Batch Loss: 0.0\n",
      "Epoch 4415, Loss: 0.0007581051997931354, Final Batch Loss: 4.768355665873969e-07\n",
      "Epoch 4416, Loss: 0.0004167958946368344, Final Batch Loss: 6.38619496839965e-07\n",
      "Epoch 4417, Loss: 0.000888510894128558, Final Batch Loss: 2.3671341295994353e-06\n",
      "Epoch 4418, Loss: 0.0008301199322886532, Final Batch Loss: 7.347088103415444e-05\n",
      "Epoch 4419, Loss: 0.004015403334051371, Final Batch Loss: 0.0\n",
      "Epoch 4420, Loss: 0.00031438203768630046, Final Batch Loss: 9.842631698120385e-06\n",
      "Epoch 4421, Loss: 0.01780730710925127, Final Batch Loss: 0.0010719812707975507\n",
      "Epoch 4422, Loss: 0.0007032593128997178, Final Batch Loss: 8.429777835772256e-07\n",
      "Epoch 4423, Loss: 0.0004060350293002557, Final Batch Loss: 0.0\n",
      "Epoch 4424, Loss: 0.0005115606509207282, Final Batch Loss: 0.00012188807158963755\n",
      "Epoch 4425, Loss: 0.0007687663901378983, Final Batch Loss: 6.1560867834487e-06\n",
      "Epoch 4426, Loss: 0.000997478143354158, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 4427, Loss: 0.010347058565717049, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4428, Loss: 0.0015152755622693803, Final Batch Loss: 2.0203802705509588e-05\n",
      "Epoch 4429, Loss: 0.01618153354320384, Final Batch Loss: 1.1962501957896166e-05\n",
      "Epoch 4430, Loss: 0.001458628622458491, Final Batch Loss: 4.964073923474643e-06\n",
      "Epoch 4431, Loss: 0.002386736588960048, Final Batch Loss: 0.0006728581502102315\n",
      "Epoch 4432, Loss: 0.00040960451127602937, Final Batch Loss: 3.065378564315324e-07\n",
      "Epoch 4433, Loss: 0.00039413528065779246, Final Batch Loss: 0.0\n",
      "Epoch 4434, Loss: 0.0008307914631586755, Final Batch Loss: 1.6475367374368943e-05\n",
      "Epoch 4435, Loss: 0.01378198118459295, Final Batch Loss: 2.358601932428428e-06\n",
      "Epoch 4436, Loss: 0.18104051187947334, Final Batch Loss: 0.17722895741462708\n",
      "Epoch 4437, Loss: 0.019926689730969116, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4438, Loss: 0.041185186040820554, Final Batch Loss: 0.00040659596561454237\n",
      "Epoch 4439, Loss: 0.017817016690969467, Final Batch Loss: 0.0016614306950941682\n",
      "Epoch 4440, Loss: 0.001979910472755364, Final Batch Loss: 1.4475403986580204e-07\n",
      "Epoch 4441, Loss: 0.03877280088971702, Final Batch Loss: 3.7465696323124575e-07\n",
      "Epoch 4442, Loss: 0.08349069109863194, Final Batch Loss: 1.127291216107551e-05\n",
      "Epoch 4443, Loss: 0.023342321284872014, Final Batch Loss: 0.00046052600373513997\n",
      "Epoch 4444, Loss: 0.008076867603733717, Final Batch Loss: 2.6396293151265127e-07\n",
      "Epoch 4445, Loss: 0.0015247452538460493, Final Batch Loss: 0.0\n",
      "Epoch 4446, Loss: 0.015345228111982578, Final Batch Loss: 1.766633431543596e-05\n",
      "Epoch 4447, Loss: 0.024054165764937352, Final Batch Loss: 5.432360012491699e-06\n",
      "Epoch 4448, Loss: 0.26957461269921623, Final Batch Loss: 0.2503860890865326\n",
      "Epoch 4449, Loss: 0.02314363437470135, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 4450, Loss: 0.09670193586498499, Final Batch Loss: 0.0\n",
      "Epoch 4451, Loss: 0.02600030832036282, Final Batch Loss: 1.850920307333581e-05\n",
      "Epoch 4452, Loss: 0.04105613590218127, Final Batch Loss: 0.0\n",
      "Epoch 4453, Loss: 0.02598656551396772, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4454, Loss: 0.009989702813982149, Final Batch Loss: 1.7189626305480488e-05\n",
      "Epoch 4455, Loss: 0.046946370144723915, Final Batch Loss: 0.00011972592619713396\n",
      "Epoch 4456, Loss: 0.025833090097876266, Final Batch Loss: 0.00021056205150671303\n",
      "Epoch 4457, Loss: 0.00341162909171544, Final Batch Loss: 2.2391584934666753e-05\n",
      "Epoch 4458, Loss: 0.022056166902530094, Final Batch Loss: 7.296975581994047e-06\n",
      "Epoch 4459, Loss: 0.007702016460825689, Final Batch Loss: 0.001417865394614637\n",
      "Epoch 4460, Loss: 0.003914612225344172, Final Batch Loss: 0.0028275412041693926\n",
      "Epoch 4461, Loss: 0.005798314999992726, Final Batch Loss: 3.2608553738100454e-05\n",
      "Epoch 4462, Loss: 0.01145283807970543, Final Batch Loss: 2.3841828067361348e-07\n",
      "Epoch 4463, Loss: 0.002157464397896547, Final Batch Loss: 8.334682934219018e-05\n",
      "Epoch 4464, Loss: 0.0028614550828933716, Final Batch Loss: 0.00010420711623737589\n",
      "Epoch 4465, Loss: 0.006697822153000743, Final Batch Loss: 1.1835745681310073e-06\n",
      "Epoch 4466, Loss: 0.01700716144114267, Final Batch Loss: 0.015293696895241737\n",
      "Epoch 4467, Loss: 0.0009568441892042756, Final Batch Loss: 5.79168954573106e-05\n",
      "Epoch 4468, Loss: 0.0011335303706800914, Final Batch Loss: 1.0225748155789915e-05\n",
      "Epoch 4469, Loss: 0.0030675460974407542, Final Batch Loss: 1.5667345678593847e-06\n",
      "Epoch 4470, Loss: 0.0043846517842425214, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4471, Loss: 0.010653142162999174, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4472, Loss: 0.003576380834090287, Final Batch Loss: 3.916870241482684e-07\n",
      "Epoch 4473, Loss: 0.0014315785228973255, Final Batch Loss: 0.0\n",
      "Epoch 4474, Loss: 0.0010309307419902325, Final Batch Loss: 1.0217866019957e-06\n",
      "Epoch 4475, Loss: 0.0006563422120962059, Final Batch Loss: 1.0422047125757672e-05\n",
      "Epoch 4476, Loss: 0.002265527320560068, Final Batch Loss: 0.000302041822578758\n",
      "Epoch 4477, Loss: 0.015835931793844793, Final Batch Loss: 0.005068066995590925\n",
      "Epoch 4478, Loss: 0.008173989612259902, Final Batch Loss: 0.0010752914240583777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4479, Loss: 0.028920725324496743, Final Batch Loss: 0.004446765407919884\n",
      "Epoch 4480, Loss: 0.00953165758983232, Final Batch Loss: 0.0014439214719459414\n",
      "Epoch 4481, Loss: 0.009062869028070963, Final Batch Loss: 5.194100367589272e-07\n",
      "Epoch 4482, Loss: 0.00286457321681155, Final Batch Loss: 2.2649405764241237e-06\n",
      "Epoch 4483, Loss: 0.0033336733067699242, Final Batch Loss: 0.000295707315672189\n",
      "Epoch 4484, Loss: 0.005613456669379957, Final Batch Loss: 0.00017278299492318183\n",
      "Epoch 4485, Loss: 0.001365231153613422, Final Batch Loss: 0.0\n",
      "Epoch 4486, Loss: 0.003465118512394838, Final Batch Loss: 0.00016117763880174607\n",
      "Epoch 4487, Loss: 0.0023945832638219144, Final Batch Loss: 2.3160303044278407e-06\n",
      "Epoch 4488, Loss: 0.0017280872962146532, Final Batch Loss: 0.0004833868588320911\n",
      "Epoch 4489, Loss: 0.003048586626391625, Final Batch Loss: 3.874103640555404e-05\n",
      "Epoch 4490, Loss: 0.003267183846901389, Final Batch Loss: 3.6868784718535608e-06\n",
      "Epoch 4491, Loss: 0.0011956407834077254, Final Batch Loss: 7.918599294498563e-06\n",
      "Epoch 4492, Loss: 0.0015224475719151087, Final Batch Loss: 0.00031697904341854155\n",
      "Epoch 4493, Loss: 0.0005052889360470658, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4494, Loss: 0.001047584465203144, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4495, Loss: 0.004176174274107325, Final Batch Loss: 2.167634193028789e-05\n",
      "Epoch 4496, Loss: 0.0042123119746975135, Final Batch Loss: 5.01526337757241e-05\n",
      "Epoch 4497, Loss: 0.0013757900251221145, Final Batch Loss: 2.5131850634352304e-05\n",
      "Epoch 4498, Loss: 0.0014663079023833347, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4499, Loss: 0.002588166427813121, Final Batch Loss: 2.3914488338050433e-05\n",
      "Epoch 4500, Loss: 0.005959338195168584, Final Batch Loss: 8.429773856732936e-07\n",
      "Epoch 4501, Loss: 0.002702086589948749, Final Batch Loss: 4.2574620806590247e-07\n",
      "Epoch 4502, Loss: 0.0013217159557825653, Final Batch Loss: 1.7240801753359847e-05\n",
      "Epoch 4503, Loss: 0.0010450948357174639, Final Batch Loss: 2.214424966950901e-05\n",
      "Epoch 4504, Loss: 0.00098494931080495, Final Batch Loss: 5.664472337230109e-05\n",
      "Epoch 4505, Loss: 0.0009571020739258529, Final Batch Loss: 1.6178387340914924e-07\n",
      "Epoch 4506, Loss: 0.0020733502529424186, Final Batch Loss: 4.5129087311579497e-07\n",
      "Epoch 4507, Loss: 0.0028905405633850023, Final Batch Loss: 0.0\n",
      "Epoch 4508, Loss: 0.0025088433030759916, Final Batch Loss: 5.638937000185251e-05\n",
      "Epoch 4509, Loss: 0.004217806309497973, Final Batch Loss: 7.16939121048199e-06\n",
      "Epoch 4510, Loss: 0.0023404770465731417, Final Batch Loss: 2.2904853267391445e-06\n",
      "Epoch 4511, Loss: 0.0013159552397610241, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 4512, Loss: 0.0021044470340711996, Final Batch Loss: 0.0\n",
      "Epoch 4513, Loss: 0.0034335928357904777, Final Batch Loss: 0.00013137547648511827\n",
      "Epoch 4514, Loss: 0.0023338889945208052, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4515, Loss: 0.008374636687221937, Final Batch Loss: 0.0\n",
      "Epoch 4516, Loss: 0.001375787594497524, Final Batch Loss: 5.2875907385896426e-06\n",
      "Epoch 4517, Loss: 0.0009144625258556971, Final Batch Loss: 2.5544827053636254e-07\n",
      "Epoch 4518, Loss: 0.0034838355800275167, Final Batch Loss: 2.9631642064487096e-06\n",
      "Epoch 4519, Loss: 0.012069866941601504, Final Batch Loss: 0.010519368574023247\n",
      "Epoch 4520, Loss: 0.0010938734879815115, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 4521, Loss: 0.00043919826566707343, Final Batch Loss: 0.00014176125114317983\n",
      "Epoch 4522, Loss: 0.007447416151990183, Final Batch Loss: 0.00020001684606540948\n",
      "Epoch 4523, Loss: 0.003375624612090178, Final Batch Loss: 0.0001322030002484098\n",
      "Epoch 4524, Loss: 0.013396986326142724, Final Batch Loss: 2.3756390419293894e-06\n",
      "Epoch 4525, Loss: 0.0015441764771821909, Final Batch Loss: 1.3009659596718848e-05\n",
      "Epoch 4526, Loss: 0.000715874666639138, Final Batch Loss: 3.087094228249043e-05\n",
      "Epoch 4527, Loss: 0.002999253621965181, Final Batch Loss: 0.0016607192810624838\n",
      "Epoch 4528, Loss: 0.014101441265097492, Final Batch Loss: 1.2261474466868094e-06\n",
      "Epoch 4529, Loss: 0.0016955624614780618, Final Batch Loss: 1.8732863793502474e-07\n",
      "Epoch 4530, Loss: 0.0004925806151732104, Final Batch Loss: 5.611145752482116e-06\n",
      "Epoch 4531, Loss: 0.00043591855001068325, Final Batch Loss: 2.22237076741294e-06\n",
      "Epoch 4532, Loss: 0.0011308607427054085, Final Batch Loss: 0.00022477516904473305\n",
      "Epoch 4533, Loss: 0.004233039951941464, Final Batch Loss: 0.0034748122561722994\n",
      "Epoch 4534, Loss: 0.0015434353377372645, Final Batch Loss: 5.960451403552725e-07\n",
      "Epoch 4535, Loss: 0.001103554131987039, Final Batch Loss: 0.0\n",
      "Epoch 4536, Loss: 0.009011096683025244, Final Batch Loss: 2.1573925550910644e-05\n",
      "Epoch 4537, Loss: 0.011097808494469064, Final Batch Loss: 3.789051788771758e-06\n",
      "Epoch 4538, Loss: 0.0024354143970413134, Final Batch Loss: 0.0015220799250528216\n",
      "Epoch 4539, Loss: 0.0010687302019505296, Final Batch Loss: 0.0005236779106780887\n",
      "Epoch 4540, Loss: 0.0035260189246564266, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4541, Loss: 0.0031028091125335777, Final Batch Loss: 3.6528435884974897e-06\n",
      "Epoch 4542, Loss: 0.0025275431835325435, Final Batch Loss: 3.003446909133345e-05\n",
      "Epoch 4543, Loss: 0.0009193042320188027, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4544, Loss: 0.0011455084848908115, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4545, Loss: 0.0008615594393290849, Final Batch Loss: 7.833710355953372e-07\n",
      "Epoch 4546, Loss: 0.02433139368488213, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4547, Loss: 0.00047959393512897464, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4548, Loss: 0.0021527051540033426, Final Batch Loss: 0.0011207852512598038\n",
      "Epoch 4549, Loss: 0.006577530214087801, Final Batch Loss: 5.619844500870386e-07\n",
      "Epoch 4550, Loss: 0.00874885891789745, Final Batch Loss: 2.7200179829378612e-05\n",
      "Epoch 4551, Loss: 0.0013725803437409922, Final Batch Loss: 0.0004263881710357964\n",
      "Epoch 4552, Loss: 0.0003023158560608863, Final Batch Loss: 5.074741238786373e-06\n",
      "Epoch 4553, Loss: 0.0010201701638266059, Final Batch Loss: 6.726781407451199e-07\n",
      "Epoch 4554, Loss: 0.002714293856115546, Final Batch Loss: 0.00010745447070803493\n",
      "Epoch 4555, Loss: 0.0003097271255683154, Final Batch Loss: 0.00014330750855151564\n",
      "Epoch 4556, Loss: 0.0018855802842949743, Final Batch Loss: 9.366410154143523e-07\n",
      "Epoch 4557, Loss: 0.0008034240854613017, Final Batch Loss: 0.0005986493779346347\n",
      "Epoch 4558, Loss: 0.006170905746330391, Final Batch Loss: 3.185933019267395e-05\n",
      "Epoch 4559, Loss: 0.0020560453911944165, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4560, Loss: 0.010098789192852564, Final Batch Loss: 0.0\n",
      "Epoch 4561, Loss: 0.0007548313183178834, Final Batch Loss: 1.0558464964560699e-06\n",
      "Epoch 4562, Loss: 0.0009452761310058122, Final Batch Loss: 4.129631179239368e-06\n",
      "Epoch 4563, Loss: 0.0014419765611819457, Final Batch Loss: 3.750891119125299e-05\n",
      "Epoch 4564, Loss: 0.0033643282749835635, Final Batch Loss: 0.0031358529813587666\n",
      "Epoch 4565, Loss: 0.0006240310468683674, Final Batch Loss: 6.982228342167218e-07\n",
      "Epoch 4566, Loss: 0.00044929359552803305, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4567, Loss: 0.004713487865956267, Final Batch Loss: 0.0003875168622471392\n",
      "Epoch 4568, Loss: 0.0014602536903112195, Final Batch Loss: 4.49207509518601e-05\n",
      "Epoch 4569, Loss: 0.018518184926051617, Final Batch Loss: 5.806959507026477e-06\n",
      "Epoch 4570, Loss: 0.004874587861971591, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4571, Loss: 0.0006762784760212526, Final Batch Loss: 3.120078326901421e-05\n",
      "Epoch 4572, Loss: 0.0010788128984131617, Final Batch Loss: 0.0\n",
      "Epoch 4573, Loss: 0.0010198457352004198, Final Batch Loss: 1.9584366839353606e-07\n",
      "Epoch 4574, Loss: 0.0006142402579598638, Final Batch Loss: 1.243171823261946e-06\n",
      "Epoch 4575, Loss: 0.001402870593665284, Final Batch Loss: 1.3180074347474147e-05\n",
      "Epoch 4576, Loss: 0.0012686429443533598, Final Batch Loss: 8.429749982497015e-07\n",
      "Epoch 4577, Loss: 0.0005634920544252964, Final Batch Loss: 1.8755972632789053e-05\n",
      "Epoch 4578, Loss: 0.000840776483528316, Final Batch Loss: 0.0\n",
      "Epoch 4579, Loss: 0.0013358091346162837, Final Batch Loss: 0.00016988834249787033\n",
      "Epoch 4580, Loss: 0.002847861991767786, Final Batch Loss: 4.768355665873969e-07\n",
      "Epoch 4581, Loss: 0.0008021545612564296, Final Batch Loss: 8.685195780344657e-07\n",
      "Epoch 4582, Loss: 0.005323713082994175, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4583, Loss: 0.004342611379115624, Final Batch Loss: 3.235634949305677e-06\n",
      "Epoch 4584, Loss: 0.013248579334572241, Final Batch Loss: 1.8647496062840219e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4585, Loss: 0.0176463772399984, Final Batch Loss: 6.8201657086319756e-06\n",
      "Epoch 4586, Loss: 0.0004074441003467655, Final Batch Loss: 0.0001589843595866114\n",
      "Epoch 4587, Loss: 0.0012520670097728726, Final Batch Loss: 5.176915874471888e-05\n",
      "Epoch 4588, Loss: 0.005067588821734859, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4589, Loss: 0.0032315526441379916, Final Batch Loss: 3.908255166606978e-06\n",
      "Epoch 4590, Loss: 0.0033606430388317676, Final Batch Loss: 0.0\n",
      "Epoch 4591, Loss: 0.0024564571722294204, Final Batch Loss: 0.0013701680582016706\n",
      "Epoch 4592, Loss: 0.0009783225305000087, Final Batch Loss: 1.1230380550841801e-05\n",
      "Epoch 4593, Loss: 0.0011127182733616792, Final Batch Loss: 0.00011981243005720899\n",
      "Epoch 4594, Loss: 0.0008848485003909445, Final Batch Loss: 0.0\n",
      "Epoch 4595, Loss: 0.0015704406462759835, Final Batch Loss: 4.172318881501269e-07\n",
      "Epoch 4596, Loss: 0.0012496746312535834, Final Batch Loss: 0.0005256729782558978\n",
      "Epoch 4597, Loss: 0.002029171831736676, Final Batch Loss: 3.618762775658979e-06\n",
      "Epoch 4598, Loss: 0.00038881738768026253, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 4599, Loss: 0.02506760446522094, Final Batch Loss: 3.0094010071479715e-05\n",
      "Epoch 4600, Loss: 0.0011415214439693955, Final Batch Loss: 0.00046751831541769207\n",
      "Epoch 4601, Loss: 0.0009072623142856173, Final Batch Loss: 0.0002719938929658383\n",
      "Epoch 4602, Loss: 0.0005512301238468353, Final Batch Loss: 3.048317694265279e-06\n",
      "Epoch 4603, Loss: 0.0006075873435094081, Final Batch Loss: 2.21388361865138e-07\n",
      "Epoch 4604, Loss: 0.00953812948500854, Final Batch Loss: 0.004756813403218985\n",
      "Epoch 4605, Loss: 0.0013393731217092864, Final Batch Loss: 0.0006887472118251026\n",
      "Epoch 4606, Loss: 0.001435781374311773, Final Batch Loss: 0.0\n",
      "Epoch 4607, Loss: 0.004919163276731808, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4608, Loss: 0.002485664152004574, Final Batch Loss: 1.7796027123040403e-06\n",
      "Epoch 4609, Loss: 0.00040542134456700296, Final Batch Loss: 1.0336466402804945e-05\n",
      "Epoch 4610, Loss: 0.0008113235053315293, Final Batch Loss: 4.4868294935440645e-05\n",
      "Epoch 4611, Loss: 0.0021225514015608127, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4612, Loss: 0.0006577634449058678, Final Batch Loss: 0.0002048561436822638\n",
      "Epoch 4613, Loss: 0.003963879240473034, Final Batch Loss: 5.429629891295917e-05\n",
      "Epoch 4614, Loss: 0.0019799581437567326, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4615, Loss: 0.0013622306105389725, Final Batch Loss: 7.770771480863914e-05\n",
      "Epoch 4616, Loss: 0.0013290622326849189, Final Batch Loss: 9.281237680625054e-07\n",
      "Epoch 4617, Loss: 0.004127901847823523, Final Batch Loss: 0.00019731090287677944\n",
      "Epoch 4618, Loss: 0.002472999563906342, Final Batch Loss: 0.00045954700908623636\n",
      "Epoch 4619, Loss: 0.005555652704060776, Final Batch Loss: 0.0\n",
      "Epoch 4620, Loss: 0.0009903992031468078, Final Batch Loss: 7.48924576328136e-05\n",
      "Epoch 4621, Loss: 0.0007653148338704341, Final Batch Loss: 1.4475403986580204e-07\n",
      "Epoch 4622, Loss: 0.005578445254013076, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 4623, Loss: 0.0005067725126401967, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4624, Loss: 0.0026017644309543897, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4625, Loss: 0.031540072301140754, Final Batch Loss: 0.0001131834796979092\n",
      "Epoch 4626, Loss: 0.0009278177018359202, Final Batch Loss: 7.407967359540635e-07\n",
      "Epoch 4627, Loss: 0.0005935730951023288, Final Batch Loss: 0.00016255433729384094\n",
      "Epoch 4628, Loss: 0.013422756199084063, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4629, Loss: 0.0018268257605988936, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 4630, Loss: 0.0007931825603009202, Final Batch Loss: 0.0\n",
      "Epoch 4631, Loss: 0.0008891474774941344, Final Batch Loss: 5.875302235835989e-07\n",
      "Epoch 4632, Loss: 0.0021584536812042643, Final Batch Loss: 2.281973593198927e-06\n",
      "Epoch 4633, Loss: 0.016953741185716353, Final Batch Loss: 6.825731543358415e-05\n",
      "Epoch 4634, Loss: 0.014437929952691775, Final Batch Loss: 0.013677827082574368\n",
      "Epoch 4635, Loss: 0.005346965645003365, Final Batch Loss: 0.0031128174159675837\n",
      "Epoch 4636, Loss: 0.0010474914743099362, Final Batch Loss: 7.938793714856729e-05\n",
      "Epoch 4637, Loss: 0.0023699274825048633, Final Batch Loss: 0.0\n",
      "Epoch 4638, Loss: 0.0013129325774485778, Final Batch Loss: 1.0217935653145105e-07\n",
      "Epoch 4639, Loss: 0.00264270904361652, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4640, Loss: 0.015393237502280499, Final Batch Loss: 7.493134717151406e-07\n",
      "Epoch 4641, Loss: 0.0028734402076224796, Final Batch Loss: 0.0\n",
      "Epoch 4642, Loss: 0.002659211236826664, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4643, Loss: 0.006026925511832815, Final Batch Loss: 0.0009082895121537149\n",
      "Epoch 4644, Loss: 0.0023185534419098985, Final Batch Loss: 0.000709343352355063\n",
      "Epoch 4645, Loss: 0.001624956294108415, Final Batch Loss: 0.00024567608488723636\n",
      "Epoch 4646, Loss: 0.0011854038880514395, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4647, Loss: 0.013654334161941506, Final Batch Loss: 2.724778767060343e-07\n",
      "Epoch 4648, Loss: 0.0026105509659828385, Final Batch Loss: 0.0\n",
      "Epoch 4649, Loss: 0.002559803562007801, Final Batch Loss: 1.7285140074818628e-06\n",
      "Epoch 4650, Loss: 0.0021910370253728217, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4651, Loss: 0.0011577860814213636, Final Batch Loss: 9.135960681305733e-06\n",
      "Epoch 4652, Loss: 0.0011757074457818817, Final Batch Loss: 4.4532312131195795e-06\n",
      "Epoch 4653, Loss: 0.004907378692706743, Final Batch Loss: 3.746568211226986e-07\n",
      "Epoch 4654, Loss: 0.0004739034319527491, Final Batch Loss: 6.556491598530556e-07\n",
      "Epoch 4655, Loss: 0.009890740092743044, Final Batch Loss: 1.6178390183085867e-07\n",
      "Epoch 4656, Loss: 0.0027092644353778894, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4657, Loss: 0.0004907080486304949, Final Batch Loss: 8.600066507824522e-07\n",
      "Epoch 4658, Loss: 0.0013715613042997177, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4659, Loss: 0.0001697572411103465, Final Batch Loss: 3.176005975547014e-06\n",
      "Epoch 4660, Loss: 0.01208190267572462, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 4661, Loss: 0.010674004946288562, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4662, Loss: 0.00160840497913739, Final Batch Loss: 1.4475402565494733e-07\n",
      "Epoch 4663, Loss: 0.00145605709622032, Final Batch Loss: 0.0001231051719514653\n",
      "Epoch 4664, Loss: 0.00242206577968318, Final Batch Loss: 0.0012752310140058398\n",
      "Epoch 4665, Loss: 0.0009404888842006187, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 4666, Loss: 0.010512673183256993, Final Batch Loss: 4.442595309228636e-05\n",
      "Epoch 4667, Loss: 0.0006441264631575905, Final Batch Loss: 0.0\n",
      "Epoch 4668, Loss: 0.006755017071554903, Final Batch Loss: 0.00490420451387763\n",
      "Epoch 4669, Loss: 0.0025301027951627475, Final Batch Loss: 5.372733994590817e-06\n",
      "Epoch 4670, Loss: 0.003967929659275171, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4671, Loss: 0.0006361028401329349, Final Batch Loss: 1.2772414947903599e-07\n",
      "Epoch 4672, Loss: 0.0038381313352147117, Final Batch Loss: 0.0\n",
      "Epoch 4673, Loss: 0.0019681201317389707, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 4674, Loss: 0.004377955556524427, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4675, Loss: 0.0014050439203856513, Final Batch Loss: 7.327828643610701e-05\n",
      "Epoch 4676, Loss: 0.0026165001962681345, Final Batch Loss: 9.792146329345996e-07\n",
      "Epoch 4677, Loss: 0.0008048886630263041, Final Batch Loss: 5.875299962099234e-07\n",
      "Epoch 4678, Loss: 0.0008294017607113346, Final Batch Loss: 0.0\n",
      "Epoch 4679, Loss: 0.044590452140255366, Final Batch Loss: 0.0407148078083992\n",
      "Epoch 4680, Loss: 0.0005386572748875551, Final Batch Loss: 1.2176334394098376e-06\n",
      "Epoch 4681, Loss: 0.0004649770216929028, Final Batch Loss: 0.0\n",
      "Epoch 4682, Loss: 0.0004496974718222191, Final Batch Loss: 5.057700491306605e-06\n",
      "Epoch 4683, Loss: 0.00013554257111536572, Final Batch Loss: 0.0\n",
      "Epoch 4684, Loss: 0.0005217442776483949, Final Batch Loss: 0.00014302706404123455\n",
      "Epoch 4685, Loss: 0.015970719866345462, Final Batch Loss: 0.004512257874011993\n",
      "Epoch 4686, Loss: 0.017950984216440702, Final Batch Loss: 0.00030006011365912855\n",
      "Epoch 4687, Loss: 0.0008564186265402896, Final Batch Loss: 1.353864831799001e-06\n",
      "Epoch 4688, Loss: 0.01258791385407676, Final Batch Loss: 4.404283026815392e-05\n",
      "Epoch 4689, Loss: 0.01659938960619911, Final Batch Loss: 0.0\n",
      "Epoch 4690, Loss: 0.02822682483591521, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4691, Loss: 0.0010574797642561862, Final Batch Loss: 4.257462364876119e-07\n",
      "Epoch 4692, Loss: 0.0002676251502347071, Final Batch Loss: 1.7029895715836574e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4693, Loss: 0.0015613603245583363, Final Batch Loss: 0.0\n",
      "Epoch 4694, Loss: 0.012365392068659276, Final Batch Loss: 5.790147952211555e-07\n",
      "Epoch 4695, Loss: 0.0004954528940288583, Final Batch Loss: 1.0839257811312564e-05\n",
      "Epoch 4696, Loss: 0.0006993978261427003, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4697, Loss: 0.017300262367434982, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4698, Loss: 0.00254261695954483, Final Batch Loss: 0.0003697228094097227\n",
      "Epoch 4699, Loss: 0.0003477295051972362, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4700, Loss: 0.0005501597500234823, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4701, Loss: 0.0010002866592913051, Final Batch Loss: 1.1741151865862776e-05\n",
      "Epoch 4702, Loss: 0.0004360545572126284, Final Batch Loss: 0.0\n",
      "Epoch 4703, Loss: 0.0016985570582619403, Final Batch Loss: 2.810512341966387e-05\n",
      "Epoch 4704, Loss: 0.008291276797308456, Final Batch Loss: 3.244121899115271e-06\n",
      "Epoch 4705, Loss: 0.000904348555195611, Final Batch Loss: 5.1390328735578805e-05\n",
      "Epoch 4706, Loss: 0.017373465285345446, Final Batch Loss: 0.00011195278784725815\n",
      "Epoch 4707, Loss: 0.0005230118622421287, Final Batch Loss: 0.0\n",
      "Epoch 4708, Loss: 0.008347237609996228, Final Batch Loss: 0.0010197267401963472\n",
      "Epoch 4709, Loss: 0.02290606866881717, Final Batch Loss: 0.00012822411372326314\n",
      "Epoch 4710, Loss: 0.0003605371039157035, Final Batch Loss: 8.863482071319595e-05\n",
      "Epoch 4711, Loss: 0.0011922862262281342, Final Batch Loss: 1.7625728787606931e-06\n",
      "Epoch 4712, Loss: 0.0007779781557815113, Final Batch Loss: 3.1505254582953057e-07\n",
      "Epoch 4713, Loss: 0.0008487032955741824, Final Batch Loss: 1.8732863793502474e-07\n",
      "Epoch 4714, Loss: 0.0005131341472548456, Final Batch Loss: 1.7029880439167755e-07\n",
      "Epoch 4715, Loss: 0.0005923821927353856, Final Batch Loss: 9.536679499433376e-07\n",
      "Epoch 4716, Loss: 0.0003438747910422535, Final Batch Loss: 3.2781856589281233e-06\n",
      "Epoch 4717, Loss: 0.0009346651868327172, Final Batch Loss: 1.7598302292753942e-05\n",
      "Epoch 4718, Loss: 0.0007960053189890459, Final Batch Loss: 0.0005867015570402145\n",
      "Epoch 4719, Loss: 0.0002456201473250985, Final Batch Loss: 0.0\n",
      "Epoch 4720, Loss: 0.006397237859346205, Final Batch Loss: 2.4808256057440303e-05\n",
      "Epoch 4721, Loss: 0.000945691974266083, Final Batch Loss: 0.0\n",
      "Epoch 4722, Loss: 0.0019047449066249555, Final Batch Loss: 2.1287340246090025e-07\n",
      "Epoch 4723, Loss: 0.0003716112332767807, Final Batch Loss: 0.0\n",
      "Epoch 4724, Loss: 0.01733724605946918, Final Batch Loss: 0.005961921997368336\n",
      "Epoch 4725, Loss: 0.00035712378223706764, Final Batch Loss: 1.3879235893909936e-06\n",
      "Epoch 4726, Loss: 0.0026931743414024822, Final Batch Loss: 0.0006022123270668089\n",
      "Epoch 4727, Loss: 0.00249806957408083, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4728, Loss: 0.0076079810917555335, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4729, Loss: 0.0007880112898419611, Final Batch Loss: 0.0\n",
      "Epoch 4730, Loss: 0.0021193389839027077, Final Batch Loss: 0.0017342206556349993\n",
      "Epoch 4731, Loss: 0.000868567487486871, Final Batch Loss: 0.00042511377250775695\n",
      "Epoch 4732, Loss: 0.0005047664599260315, Final Batch Loss: 0.00021215016022324562\n",
      "Epoch 4733, Loss: 0.002571922587321751, Final Batch Loss: 0.0013061901554465294\n",
      "Epoch 4734, Loss: 0.0003592910170482355, Final Batch Loss: 1.3758837667410262e-05\n",
      "Epoch 4735, Loss: 0.00016533160199827535, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 4736, Loss: 0.008323456653322125, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 4737, Loss: 0.0019227069883527292, Final Batch Loss: 0.0\n",
      "Epoch 4738, Loss: 0.000488427347590914, Final Batch Loss: 8.906194852897897e-05\n",
      "Epoch 4739, Loss: 0.009557041913865305, Final Batch Loss: 4.257466912349628e-07\n",
      "Epoch 4740, Loss: 0.0004655453022976985, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4741, Loss: 0.002219482044893084, Final Batch Loss: 1.5384950529551134e-05\n",
      "Epoch 4742, Loss: 0.00038685292020090856, Final Batch Loss: 1.3776438208878972e-05\n",
      "Epoch 4743, Loss: 0.0014119581176466056, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4744, Loss: 0.00031424544431502, Final Batch Loss: 5.291823617881164e-05\n",
      "Epoch 4745, Loss: 0.0005168538978068682, Final Batch Loss: 2.6736438485386316e-06\n",
      "Epoch 4746, Loss: 0.0018099133276479051, Final Batch Loss: 1.8732863793502474e-07\n",
      "Epoch 4747, Loss: 0.0006695619704260025, Final Batch Loss: 2.576159022282809e-05\n",
      "Epoch 4748, Loss: 0.0015371936733004077, Final Batch Loss: 8.004007554518466e-07\n",
      "Epoch 4749, Loss: 0.0011126471581519581, Final Batch Loss: 0.00015946115308906883\n",
      "Epoch 4750, Loss: 0.0021840053668711334, Final Batch Loss: 0.00046358766849152744\n",
      "Epoch 4751, Loss: 0.0005302861793872182, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4752, Loss: 0.0006761398753951653, Final Batch Loss: 8.650678864796646e-06\n",
      "Epoch 4753, Loss: 0.00035366671386327653, Final Batch Loss: 3.669851366794319e-06\n",
      "Epoch 4754, Loss: 0.006818773897446562, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4755, Loss: 0.0141423279224, Final Batch Loss: 3.2781831578176934e-06\n",
      "Epoch 4756, Loss: 0.0012555718092528423, Final Batch Loss: 2.1287340246090025e-07\n",
      "Epoch 4757, Loss: 0.0009003770719573367, Final Batch Loss: 0.0\n",
      "Epoch 4758, Loss: 0.006546082639943052, Final Batch Loss: 0.006326076574623585\n",
      "Epoch 4759, Loss: 0.09748067237501346, Final Batch Loss: 0.09738697111606598\n",
      "Epoch 4760, Loss: 0.0006558663644682383, Final Batch Loss: 0.0\n",
      "Epoch 4761, Loss: 0.004848561769904336, Final Batch Loss: 7.87369572208263e-05\n",
      "Epoch 4762, Loss: 0.02019022370222956, Final Batch Loss: 0.0\n",
      "Epoch 4763, Loss: 0.04319609654407941, Final Batch Loss: 2.2564279333892046e-06\n",
      "Epoch 4764, Loss: 0.0068908256262147916, Final Batch Loss: 9.41702182899462e-06\n",
      "Epoch 4765, Loss: 0.00536462255877268, Final Batch Loss: 2.597547609184403e-05\n",
      "Epoch 4766, Loss: 0.02201614675394481, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4767, Loss: 0.0016591128496656893, Final Batch Loss: 0.0\n",
      "Epoch 4768, Loss: 0.006343582602312381, Final Batch Loss: 2.8298094548517838e-05\n",
      "Epoch 4769, Loss: 0.012598606504866439, Final Batch Loss: 8.94064100975811e-07\n",
      "Epoch 4770, Loss: 0.0015212499897856446, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4771, Loss: 0.01153322671711976, Final Batch Loss: 3.5932182527176337e-06\n",
      "Epoch 4772, Loss: 0.02051798687352857, Final Batch Loss: 2.0265360944904387e-06\n",
      "Epoch 4773, Loss: 0.014706737538290326, Final Batch Loss: 0.00032371716224588454\n",
      "Epoch 4774, Loss: 0.0007939274170212229, Final Batch Loss: 1.668910613261687e-06\n",
      "Epoch 4775, Loss: 0.049921086598260445, Final Batch Loss: 2.698889329622034e-05\n",
      "Epoch 4776, Loss: 0.002420222546788864, Final Batch Loss: 0.00077003677142784\n",
      "Epoch 4777, Loss: 0.003921283958334243, Final Batch Loss: 4.5729528210358694e-05\n",
      "Epoch 4778, Loss: 0.004014275728820849, Final Batch Loss: 2.7247818934483803e-07\n",
      "Epoch 4779, Loss: 0.0062596487870507644, Final Batch Loss: 3.405977224701928e-07\n",
      "Epoch 4780, Loss: 0.010592491947818417, Final Batch Loss: 2.860993618014618e-06\n",
      "Epoch 4781, Loss: 0.014143067889108352, Final Batch Loss: 3.7890681596763898e-06\n",
      "Epoch 4782, Loss: 0.011209996737306938, Final Batch Loss: 0.00014181410369928926\n",
      "Epoch 4783, Loss: 0.0004116582150004433, Final Batch Loss: 3.150526595163683e-07\n",
      "Epoch 4784, Loss: 0.007594375322696578, Final Batch Loss: 1.29842419482884e-05\n",
      "Epoch 4785, Loss: 0.0009930904634529725, Final Batch Loss: 0.00026894055190496147\n",
      "Epoch 4786, Loss: 0.06600378730945522, Final Batch Loss: 2.074835356324911e-05\n",
      "Epoch 4787, Loss: 0.001557421442157647, Final Batch Loss: 1.0506829312362242e-05\n",
      "Epoch 4788, Loss: 0.0034616388484209892, Final Batch Loss: 9.076674359675962e-06\n",
      "Epoch 4789, Loss: 0.008119298608107783, Final Batch Loss: 5.508959475264419e-06\n",
      "Epoch 4790, Loss: 0.0015704558827565052, Final Batch Loss: 0.0004565315321087837\n",
      "Epoch 4791, Loss: 0.00489569446654059, Final Batch Loss: 0.000644589017610997\n",
      "Epoch 4792, Loss: 0.00414246675427421, Final Batch Loss: 0.0009744762210175395\n",
      "Epoch 4793, Loss: 0.006708422914641687, Final Batch Loss: 5.704993668587122e-07\n",
      "Epoch 4794, Loss: 0.0062590561910838005, Final Batch Loss: 1.125589642470004e-05\n",
      "Epoch 4795, Loss: 0.0015993088818504475, Final Batch Loss: 0.0\n",
      "Epoch 4796, Loss: 0.0042350789826741675, Final Batch Loss: 1.4049528545001522e-06\n",
      "Epoch 4797, Loss: 0.0023725548077777603, Final Batch Loss: 7.152545435928914e-07\n",
      "Epoch 4798, Loss: 0.0015698886659265554, Final Batch Loss: 6.181604931043694e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4799, Loss: 0.001240583274011442, Final Batch Loss: 1.4295866094471421e-05\n",
      "Epoch 4800, Loss: 0.02232580376585247, Final Batch Loss: 3.9168662624433637e-07\n",
      "Epoch 4801, Loss: 0.0009493692341493443, Final Batch Loss: 0.0005306173115968704\n",
      "Epoch 4802, Loss: 0.0032600899950345763, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 4803, Loss: 0.0024117773937177844, Final Batch Loss: 0.00034302365384064615\n",
      "Epoch 4804, Loss: 0.000629245228715547, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 4805, Loss: 0.0017107679996115621, Final Batch Loss: 9.553414201945998e-06\n",
      "Epoch 4806, Loss: 0.001535013966531551, Final Batch Loss: 8.838288522383664e-06\n",
      "Epoch 4807, Loss: 0.004318557505030185, Final Batch Loss: 0.00020287868392188102\n",
      "Epoch 4808, Loss: 0.0025111885224760044, Final Batch Loss: 2.4612669221824035e-05\n",
      "Epoch 4809, Loss: 0.0014404935773200123, Final Batch Loss: 3.831719368463382e-07\n",
      "Epoch 4810, Loss: 0.0005150821152710705, Final Batch Loss: 7.892921530583408e-06\n",
      "Epoch 4811, Loss: 0.0009489777936693145, Final Batch Loss: 2.0435858516520966e-07\n",
      "Epoch 4812, Loss: 0.0018901017247117124, Final Batch Loss: 7.5523785199038684e-06\n",
      "Epoch 4813, Loss: 0.0015856949072485804, Final Batch Loss: 1.115452164413e-06\n",
      "Epoch 4814, Loss: 0.000981620636594016, Final Batch Loss: 0.0\n",
      "Epoch 4815, Loss: 0.0014631214257860847, Final Batch Loss: 4.070087470608996e-06\n",
      "Epoch 4816, Loss: 0.005371750911251638, Final Batch Loss: 6.215890948624292e-07\n",
      "Epoch 4817, Loss: 0.005907325876510328, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4818, Loss: 0.014550400108873873, Final Batch Loss: 2.3160287128121126e-06\n",
      "Epoch 4819, Loss: 0.000996663123714825, Final Batch Loss: 7.526823083026102e-06\n",
      "Epoch 4820, Loss: 0.0007009272430593683, Final Batch Loss: 2.469332400778512e-07\n",
      "Epoch 4821, Loss: 0.030957222292499864, Final Batch Loss: 3.0568028250854695e-06\n",
      "Epoch 4822, Loss: 0.0004444543592398986, Final Batch Loss: 8.694663847563788e-05\n",
      "Epoch 4823, Loss: 0.014235329475241087, Final Batch Loss: 1.737028696879861e-06\n",
      "Epoch 4824, Loss: 0.0018767683941405267, Final Batch Loss: 0.0\n",
      "Epoch 4825, Loss: 0.0010886266427405644, Final Batch Loss: 4.84344272990711e-05\n",
      "Epoch 4826, Loss: 0.0008064091707637999, Final Batch Loss: 0.0\n",
      "Epoch 4827, Loss: 0.013090439578235191, Final Batch Loss: 2.1287357299115683e-07\n",
      "Epoch 4828, Loss: 0.006123652842688898, Final Batch Loss: 8.199426702049095e-06\n",
      "Epoch 4829, Loss: 0.0027480879725771956, Final Batch Loss: 0.0\n",
      "Epoch 4830, Loss: 0.0015870619760676163, Final Batch Loss: 7.407986117868859e-07\n",
      "Epoch 4831, Loss: 0.0009545872017042711, Final Batch Loss: 0.0001091974409064278\n",
      "Epoch 4832, Loss: 0.0015438746650033863, Final Batch Loss: 2.092705290124286e-05\n",
      "Epoch 4833, Loss: 0.007759308887344218, Final Batch Loss: 3.4059794984386826e-08\n",
      "Epoch 4834, Loss: 0.0009241214247595053, Final Batch Loss: 6.966145883779973e-05\n",
      "Epoch 4835, Loss: 0.001188081005238928, Final Batch Loss: 7.484135130653158e-05\n",
      "Epoch 4836, Loss: 0.002759747547315783, Final Batch Loss: 1.4337740140035748e-05\n",
      "Epoch 4837, Loss: 0.0064389786488554535, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4838, Loss: 0.014951233090993554, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 4839, Loss: 0.0012233313958631697, Final Batch Loss: 1.4815863096373505e-06\n",
      "Epoch 4840, Loss: 0.0021045939711257233, Final Batch Loss: 0.00045055997907184064\n",
      "Epoch 4841, Loss: 0.0018446236315412534, Final Batch Loss: 2.8013707833451917e-06\n",
      "Epoch 4842, Loss: 0.0005639795192564634, Final Batch Loss: 5.108952336740913e-07\n",
      "Epoch 4843, Loss: 0.0019030889976647813, Final Batch Loss: 1.7370290379403741e-06\n",
      "Epoch 4844, Loss: 0.0005840405210619792, Final Batch Loss: 0.0\n",
      "Epoch 4845, Loss: 0.007463742011168506, Final Batch Loss: 0.0\n",
      "Epoch 4846, Loss: 0.002235939376987517, Final Batch Loss: 0.0003701415844261646\n",
      "Epoch 4847, Loss: 0.001689093405730091, Final Batch Loss: 1.8305767298443243e-05\n",
      "Epoch 4848, Loss: 0.0012280570226721466, Final Batch Loss: 0.0\n",
      "Epoch 4849, Loss: 0.0005136666586622596, Final Batch Loss: 0.0\n",
      "Epoch 4850, Loss: 0.002547560002781779, Final Batch Loss: 1.7029880439167755e-07\n",
      "Epoch 4851, Loss: 0.0016708483734646506, Final Batch Loss: 1.737039269755769e-06\n",
      "Epoch 4852, Loss: 0.0014260831862884515, Final Batch Loss: 4.904509751213482e-06\n",
      "Epoch 4853, Loss: 0.0025291173333243933, Final Batch Loss: 3.730670505319722e-05\n",
      "Epoch 4854, Loss: 0.0002969154620586778, Final Batch Loss: 3.218578513042303e-06\n",
      "Epoch 4855, Loss: 0.00010146009117306676, Final Batch Loss: 0.0\n",
      "Epoch 4856, Loss: 0.0009941875978256576, Final Batch Loss: 0.00048545465688221157\n",
      "Epoch 4857, Loss: 0.0006564150535268709, Final Batch Loss: 0.0\n",
      "Epoch 4858, Loss: 0.0005164024769328535, Final Batch Loss: 0.0\n",
      "Epoch 4859, Loss: 0.0002213215875599417, Final Batch Loss: 7.961077244544867e-06\n",
      "Epoch 4860, Loss: 0.0011621930758067833, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4861, Loss: 0.005958213266239909, Final Batch Loss: 4.487256774154957e-06\n",
      "Epoch 4862, Loss: 0.0006203211638649009, Final Batch Loss: 1.8817796672010445e-06\n",
      "Epoch 4863, Loss: 0.023738126148600713, Final Batch Loss: 0.0001450390846002847\n",
      "Epoch 4864, Loss: 0.007058790528844838, Final Batch Loss: 1.9498979781928938e-06\n",
      "Epoch 4865, Loss: 0.0010015485295298276, Final Batch Loss: 0.0\n",
      "Epoch 4866, Loss: 0.001936849923367845, Final Batch Loss: 9.605213563190773e-05\n",
      "Epoch 4867, Loss: 0.013871828247665974, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 4868, Loss: 0.0005312964353834104, Final Batch Loss: 2.094654064421775e-06\n",
      "Epoch 4869, Loss: 9.890023270031634e-05, Final Batch Loss: 2.469331263910135e-07\n",
      "Epoch 4870, Loss: 0.0034731931846181396, Final Batch Loss: 0.00010558396752458066\n",
      "Epoch 4871, Loss: 0.0008424232946708798, Final Batch Loss: 7.633040513610467e-05\n",
      "Epoch 4872, Loss: 0.0030548664238132517, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4873, Loss: 0.0033923803794095875, Final Batch Loss: 8.250511200458277e-06\n",
      "Epoch 4874, Loss: 0.00025335787370295293, Final Batch Loss: 7.237673571580672e-07\n",
      "Epoch 4875, Loss: 0.003994259226601571, Final Batch Loss: 8.370677096536383e-05\n",
      "Epoch 4876, Loss: 0.0006542441587953363, Final Batch Loss: 1.4465485037362669e-05\n",
      "Epoch 4877, Loss: 0.0053999311670978045, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4878, Loss: 0.002531671190808993, Final Batch Loss: 0.0018835279624909163\n",
      "Epoch 4879, Loss: 0.0007705237512709573, Final Batch Loss: 8.752831490710378e-06\n",
      "Epoch 4880, Loss: 0.012979043040104443, Final Batch Loss: 0.0006089996313676238\n",
      "Epoch 4881, Loss: 0.0003637886658509615, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 4882, Loss: 0.010343830144847743, Final Batch Loss: 0.0\n",
      "Epoch 4883, Loss: 0.0009588121006913752, Final Batch Loss: 7.833710355953372e-07\n",
      "Epoch 4884, Loss: 0.0011035390925826505, Final Batch Loss: 0.0\n",
      "Epoch 4885, Loss: 0.0001724266012388398, Final Batch Loss: 0.0\n",
      "Epoch 4886, Loss: 0.02904860910393836, Final Batch Loss: 2.0605898498615716e-06\n",
      "Epoch 4887, Loss: 0.0005937885071034543, Final Batch Loss: 6.730786117259413e-05\n",
      "Epoch 4888, Loss: 0.0173506252176594, Final Batch Loss: 0.0\n",
      "Epoch 4889, Loss: 0.0016520649169251556, Final Batch Loss: 0.00032326040673069656\n",
      "Epoch 4890, Loss: 0.001223927320097573, Final Batch Loss: 0.000420746102463454\n",
      "Epoch 4891, Loss: 0.0002268650732730748, Final Batch Loss: 1.908796730276663e-05\n",
      "Epoch 4892, Loss: 0.0006949563285161275, Final Batch Loss: 2.8232778277015314e-05\n",
      "Epoch 4893, Loss: 0.0008494688827340724, Final Batch Loss: 2.0162386135780253e-05\n",
      "Epoch 4894, Loss: 0.0003898090344591765, Final Batch Loss: 8.548542609787546e-06\n",
      "Epoch 4895, Loss: 0.0010160906706460082, Final Batch Loss: 1.7966406176128658e-06\n",
      "Epoch 4896, Loss: 0.0005624813311442267, Final Batch Loss: 2.161631709896028e-05\n",
      "Epoch 4897, Loss: 0.00046014171685726524, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 4898, Loss: 0.006957791367312893, Final Batch Loss: 4.828430974157527e-05\n",
      "Epoch 4899, Loss: 0.000874301868211802, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4900, Loss: 0.006466285581382181, Final Batch Loss: 2.8865408694400685e-06\n",
      "Epoch 4901, Loss: 0.004190303276118357, Final Batch Loss: 0.002582237124443054\n",
      "Epoch 4902, Loss: 0.0008753471620366327, Final Batch Loss: 7.790923518768977e-06\n",
      "Epoch 4903, Loss: 0.007831172741134651, Final Batch Loss: 0.0\n",
      "Epoch 4904, Loss: 0.0003565050015055249, Final Batch Loss: 1.7029880439167755e-07\n",
      "Epoch 4905, Loss: 0.00809659282293751, Final Batch Loss: 5.53469533315365e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4906, Loss: 0.0019162186363246292, Final Batch Loss: 2.2620835807174444e-05\n",
      "Epoch 4907, Loss: 0.0014989432830674332, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 4908, Loss: 0.000602023968440335, Final Batch Loss: 4.3765498958237e-06\n",
      "Epoch 4909, Loss: 0.00949186939707758, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4910, Loss: 0.000461586132132652, Final Batch Loss: 5.9006611081713345e-06\n",
      "Epoch 4911, Loss: 0.002286931315836682, Final Batch Loss: 6.045590339454066e-07\n",
      "Epoch 4912, Loss: 0.008432822727627354, Final Batch Loss: 8.379471546504647e-05\n",
      "Epoch 4913, Loss: 0.0009403798976563849, Final Batch Loss: 4.992273170500994e-05\n",
      "Epoch 4914, Loss: 0.0015378809550838923, Final Batch Loss: 3.2356076644646237e-06\n",
      "Epoch 4915, Loss: 0.0018226175188829075, Final Batch Loss: 2.728528306761291e-05\n",
      "Epoch 4916, Loss: 0.008640825206384761, Final Batch Loss: 0.0\n",
      "Epoch 4917, Loss: 0.002790134141832823, Final Batch Loss: 0.0\n",
      "Epoch 4918, Loss: 0.00035816450690617785, Final Batch Loss: 8.307460666401312e-05\n",
      "Epoch 4919, Loss: 0.000334341122652404, Final Batch Loss: 0.0\n",
      "Epoch 4920, Loss: 0.0021198260492667487, Final Batch Loss: 1.8732865214587946e-07\n",
      "Epoch 4921, Loss: 0.0022323115959519413, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4922, Loss: 0.0002925032035818731, Final Batch Loss: 1.2857499314122833e-06\n",
      "Epoch 4923, Loss: 0.006005107127343479, Final Batch Loss: 7.663452805672932e-08\n",
      "Epoch 4924, Loss: 0.00463866815334768, Final Batch Loss: 6.46928237983957e-05\n",
      "Epoch 4925, Loss: 0.0027465263709416377, Final Batch Loss: 2.809927934777079e-07\n",
      "Epoch 4926, Loss: 0.029716256554820575, Final Batch Loss: 3.656235639937222e-05\n",
      "Epoch 4927, Loss: 0.000653725187973464, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 4928, Loss: 0.001859415868693759, Final Batch Loss: 7.594943326694192e-06\n",
      "Epoch 4929, Loss: 0.0013158583594758966, Final Batch Loss: 2.460796849845792e-06\n",
      "Epoch 4930, Loss: 0.004388800855565478, Final Batch Loss: 5.704993668587122e-07\n",
      "Epoch 4931, Loss: 0.024324050919979356, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4932, Loss: 0.0008880067998688901, Final Batch Loss: 1.1009064110112377e-05\n",
      "Epoch 4933, Loss: 0.0019236315190482856, Final Batch Loss: 2.6395853183203144e-06\n",
      "Epoch 4934, Loss: 0.009668064404422694, Final Batch Loss: 1.1324798379064305e-06\n",
      "Epoch 4935, Loss: 0.000708147489433486, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 4936, Loss: 0.00047073761998461805, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 4937, Loss: 0.0007749068085445288, Final Batch Loss: 5.194110030970478e-07\n",
      "Epoch 4938, Loss: 0.0010753859087344608, Final Batch Loss: 1.255845472769579e-05\n",
      "Epoch 4939, Loss: 0.005196444864850491, Final Batch Loss: 0.0001665971940383315\n",
      "Epoch 4940, Loss: 0.00208083558936778, Final Batch Loss: 0.001712830737233162\n",
      "Epoch 4941, Loss: 0.001347061766182378, Final Batch Loss: 3.755035550057073e-06\n",
      "Epoch 4942, Loss: 0.0013135692515788833, Final Batch Loss: 4.8720132326707244e-05\n",
      "Epoch 4943, Loss: 0.0014597581955122507, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 4944, Loss: 0.006465113071108419, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4945, Loss: 0.00045330036573432153, Final Batch Loss: 2.290494876433513e-06\n",
      "Epoch 4946, Loss: 0.0007290539770110627, Final Batch Loss: 0.0\n",
      "Epoch 4947, Loss: 0.001501672983977187, Final Batch Loss: 1.1528506547620054e-05\n",
      "Epoch 4948, Loss: 0.0007746024602965917, Final Batch Loss: 0.0\n",
      "Epoch 4949, Loss: 0.0014555923153238837, Final Batch Loss: 0.0\n",
      "Epoch 4950, Loss: 0.004900933650844763, Final Batch Loss: 2.8950768182767206e-07\n",
      "Epoch 4951, Loss: 0.00067890063746745, Final Batch Loss: 3.993399332102854e-06\n",
      "Epoch 4952, Loss: 0.0003461159888367149, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4953, Loss: 0.002243899394898108, Final Batch Loss: 1.5326743323385017e-06\n",
      "Epoch 4954, Loss: 0.00032023382050283544, Final Batch Loss: 3.1590072921972023e-06\n",
      "Epoch 4955, Loss: 0.00026359375806350727, Final Batch Loss: 1.1681730029522441e-05\n",
      "Epoch 4956, Loss: 0.0009296438420278719, Final Batch Loss: 4.8671896365704015e-05\n",
      "Epoch 4957, Loss: 0.0004084205484105041, Final Batch Loss: 0.0\n",
      "Epoch 4958, Loss: 0.01286738466069437, Final Batch Loss: 2.2138533495308366e-06\n",
      "Epoch 4959, Loss: 0.003810734695434803, Final Batch Loss: 8.61365333548747e-05\n",
      "Epoch 4960, Loss: 0.001373696475639008, Final Batch Loss: 0.0002228807716164738\n",
      "Epoch 4961, Loss: 0.0009648866169484904, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 4962, Loss: 0.0024567333936147406, Final Batch Loss: 1.047333739734313e-06\n",
      "Epoch 4963, Loss: 0.011869375332025811, Final Batch Loss: 0.00046051249955780804\n",
      "Epoch 4964, Loss: 0.001739344748784788, Final Batch Loss: 0.0001004062287393026\n",
      "Epoch 4965, Loss: 0.014748723965482213, Final Batch Loss: 2.8099285032112675e-07\n",
      "Epoch 4966, Loss: 0.0006469836835094611, Final Batch Loss: 0.00036273463047109544\n",
      "Epoch 4967, Loss: 0.00044343685320669124, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4968, Loss: 0.0022116103045846103, Final Batch Loss: 0.0004978670040145516\n",
      "Epoch 4969, Loss: 0.0005742576795455534, Final Batch Loss: 0.00022554009046871215\n",
      "Epoch 4970, Loss: 0.020962235640297422, Final Batch Loss: 7.407967927974823e-07\n",
      "Epoch 4971, Loss: 0.02972672596661141, Final Batch Loss: 0.0\n",
      "Epoch 4972, Loss: 0.0013413385603371353, Final Batch Loss: 1.8306908486920292e-06\n",
      "Epoch 4973, Loss: 0.005053886197856627, Final Batch Loss: 0.00013053364818915725\n",
      "Epoch 4974, Loss: 0.002141854145520483, Final Batch Loss: 0.00037361084832809865\n",
      "Epoch 4975, Loss: 0.004635322905187422, Final Batch Loss: 1.6263427369267447e-06\n",
      "Epoch 4976, Loss: 0.0005186267122265775, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4977, Loss: 0.0005826982419421256, Final Batch Loss: 7.041581284283893e-06\n",
      "Epoch 4978, Loss: 0.0004118011474929517, Final Batch Loss: 1.9923108993680216e-05\n",
      "Epoch 4979, Loss: 0.0037900430179433897, Final Batch Loss: 0.0\n",
      "Epoch 4980, Loss: 0.0007601272886859078, Final Batch Loss: 4.402093054522993e-06\n",
      "Epoch 4981, Loss: 0.009203423047438264, Final Batch Loss: 0.005924351047724485\n",
      "Epoch 4982, Loss: 0.007099175396433566, Final Batch Loss: 0.006515141110867262\n",
      "Epoch 4983, Loss: 0.0011014457099918218, Final Batch Loss: 0.0\n",
      "Epoch 4984, Loss: 0.0021056156965642003, Final Batch Loss: 0.00010273984662489966\n",
      "Epoch 4985, Loss: 0.0008961099135831319, Final Batch Loss: 1.294264393436606e-06\n",
      "Epoch 4986, Loss: 0.001304807400174468, Final Batch Loss: 2.9285894925124012e-05\n",
      "Epoch 4987, Loss: 0.0035873330089088995, Final Batch Loss: 0.0001115612467401661\n",
      "Epoch 4988, Loss: 0.003275458712323598, Final Batch Loss: 6.096463494031923e-06\n",
      "Epoch 4989, Loss: 0.002840143505736137, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 4990, Loss: 0.0007732632374057857, Final Batch Loss: 1.9584363997182663e-07\n",
      "Epoch 4991, Loss: 0.004911619922722821, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 4992, Loss: 0.00038110502100607846, Final Batch Loss: 0.0\n",
      "Epoch 4993, Loss: 0.0002325144796486711, Final Batch Loss: 4.3255213313386776e-06\n",
      "Epoch 4994, Loss: 0.013258372790517114, Final Batch Loss: 2.7247784828432486e-07\n",
      "Epoch 4995, Loss: 0.006908437559104641, Final Batch Loss: 0.006325986236333847\n",
      "Epoch 4996, Loss: 0.00033039144776125795, Final Batch Loss: 3.405971540360042e-07\n",
      "Epoch 4997, Loss: 0.0019933575999857567, Final Batch Loss: 5.25353198099765e-06\n",
      "Epoch 4998, Loss: 0.0014027455608811579, Final Batch Loss: 0.0008735341834835708\n",
      "Epoch 4999, Loss: 0.0007288679391024289, Final Batch Loss: 3.2356743417949474e-07\n",
      "Epoch 5000, Loss: 0.0026616630166813593, Final Batch Loss: 7.322818760258087e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94  0  0]\n",
      " [ 0 77  0]\n",
      " [ 0  0 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        94\n",
      "           1    1.00000   1.00000   1.00000        77\n",
      "           2    1.00000   1.00000   1.00000        83\n",
      "\n",
      "    accuracy                        1.00000       254\n",
      "   macro avg    1.00000   1.00000   1.00000       254\n",
      "weighted avg    1.00000   1.00000   1.00000       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=111, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=32, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 111)\n",
    "load_model(gen, \"3 Label 8 Subject GAN Ablation_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 8)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80  0  0]\n",
      " [ 0 98  0]\n",
      " [ 0  0 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        80\n",
      "           1    1.00000   1.00000   1.00000        98\n",
      "           2    1.00000   1.00000   1.00000        76\n",
      "\n",
      "    accuracy                        1.00000       254\n",
      "   macro avg    1.00000   1.00000   1.00000       254\n",
      "weighted avg    1.00000   1.00000   1.00000       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11, 14, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    elif y[k] == 7:\n",
    "        y[k] = 3\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 4\n",
    "    elif y[k] == 11:\n",
    "        y[k] = 5\n",
    "    elif y[k] == 14:\n",
    "        y[k] = 6\n",
    "    else:\n",
    "        y[k] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 10.571826696395874, Final Batch Loss: 2.183654546737671\n",
      "Epoch 2, Loss: 10.56934142112732, Final Batch Loss: 2.18768310546875\n",
      "Epoch 3, Loss: 10.489869832992554, Final Batch Loss: 2.1151680946350098\n",
      "Epoch 4, Loss: 10.438005208969116, Final Batch Loss: 2.0732197761535645\n",
      "Epoch 5, Loss: 10.438110828399658, Final Batch Loss: 2.0876781940460205\n",
      "Epoch 6, Loss: 10.478564977645874, Final Batch Loss: 2.1347272396087646\n",
      "Epoch 7, Loss: 10.501586198806763, Final Batch Loss: 2.1670336723327637\n",
      "Epoch 8, Loss: 10.36659860610962, Final Batch Loss: 2.0351481437683105\n",
      "Epoch 9, Loss: 10.464903354644775, Final Batch Loss: 2.147918939590454\n",
      "Epoch 10, Loss: 10.360873460769653, Final Batch Loss: 2.056225061416626\n",
      "Epoch 11, Loss: 10.418897151947021, Final Batch Loss: 2.1256604194641113\n",
      "Epoch 12, Loss: 10.301491022109985, Final Batch Loss: 2.0226528644561768\n",
      "Epoch 13, Loss: 10.355299234390259, Final Batch Loss: 2.0985820293426514\n",
      "Epoch 14, Loss: 10.274491548538208, Final Batch Loss: 2.0293734073638916\n",
      "Epoch 15, Loss: 10.240286827087402, Final Batch Loss: 2.005932569503784\n",
      "Epoch 16, Loss: 10.316983938217163, Final Batch Loss: 2.1202056407928467\n",
      "Epoch 17, Loss: 10.199559926986694, Final Batch Loss: 2.047879695892334\n",
      "Epoch 18, Loss: 10.114190578460693, Final Batch Loss: 1.9851491451263428\n",
      "Epoch 19, Loss: 10.208573579788208, Final Batch Loss: 2.069688081741333\n",
      "Epoch 20, Loss: 10.10556697845459, Final Batch Loss: 2.02182936668396\n",
      "Epoch 21, Loss: 10.107878923416138, Final Batch Loss: 2.0466725826263428\n",
      "Epoch 22, Loss: 10.064093708992004, Final Batch Loss: 2.0493111610412598\n",
      "Epoch 23, Loss: 10.003301978111267, Final Batch Loss: 2.026697874069214\n",
      "Epoch 24, Loss: 9.834161162376404, Final Batch Loss: 1.8932608366012573\n",
      "Epoch 25, Loss: 9.83182179927826, Final Batch Loss: 1.9544583559036255\n",
      "Epoch 26, Loss: 9.833019614219666, Final Batch Loss: 1.9769134521484375\n",
      "Epoch 27, Loss: 9.602484941482544, Final Batch Loss: 1.8026621341705322\n",
      "Epoch 28, Loss: 9.599594473838806, Final Batch Loss: 1.8559550046920776\n",
      "Epoch 29, Loss: 9.634461760520935, Final Batch Loss: 1.9558279514312744\n",
      "Epoch 30, Loss: 9.62351930141449, Final Batch Loss: 1.95980966091156\n",
      "Epoch 31, Loss: 9.587052583694458, Final Batch Loss: 1.967814564704895\n",
      "Epoch 32, Loss: 9.345446705818176, Final Batch Loss: 1.7562878131866455\n",
      "Epoch 33, Loss: 9.275351405143738, Final Batch Loss: 1.7337082624435425\n",
      "Epoch 34, Loss: 9.3789781332016, Final Batch Loss: 1.8428336381912231\n",
      "Epoch 35, Loss: 9.457648754119873, Final Batch Loss: 2.017679214477539\n",
      "Epoch 36, Loss: 9.310382008552551, Final Batch Loss: 1.9215399026870728\n",
      "Epoch 37, Loss: 9.0617835521698, Final Batch Loss: 1.7017290592193604\n",
      "Epoch 38, Loss: 9.315147995948792, Final Batch Loss: 2.0620195865631104\n",
      "Epoch 39, Loss: 9.503417611122131, Final Batch Loss: 2.164876937866211\n",
      "Epoch 40, Loss: 9.153234720230103, Final Batch Loss: 1.901896357536316\n",
      "Epoch 41, Loss: 8.864193558692932, Final Batch Loss: 1.5644044876098633\n",
      "Epoch 42, Loss: 8.942763090133667, Final Batch Loss: 1.6619529724121094\n",
      "Epoch 43, Loss: 9.068721055984497, Final Batch Loss: 1.871783971786499\n",
      "Epoch 44, Loss: 9.086645722389221, Final Batch Loss: 2.0026776790618896\n",
      "Epoch 45, Loss: 8.849735975265503, Final Batch Loss: 1.725377082824707\n",
      "Epoch 46, Loss: 8.89058780670166, Final Batch Loss: 1.733216404914856\n",
      "Epoch 47, Loss: 9.040185451507568, Final Batch Loss: 1.902699589729309\n",
      "Epoch 48, Loss: 9.039742350578308, Final Batch Loss: 1.94400155544281\n",
      "Epoch 49, Loss: 8.82212495803833, Final Batch Loss: 1.7971900701522827\n",
      "Epoch 50, Loss: 8.625438690185547, Final Batch Loss: 1.6346696615219116\n",
      "Epoch 51, Loss: 8.92828893661499, Final Batch Loss: 1.909008264541626\n",
      "Epoch 52, Loss: 8.743910074234009, Final Batch Loss: 1.7410156726837158\n",
      "Epoch 53, Loss: 8.56227958202362, Final Batch Loss: 1.564635992050171\n",
      "Epoch 54, Loss: 8.941399455070496, Final Batch Loss: 1.9980915784835815\n",
      "Epoch 55, Loss: 8.546305060386658, Final Batch Loss: 1.6436859369277954\n",
      "Epoch 56, Loss: 8.63728415966034, Final Batch Loss: 1.678476333618164\n",
      "Epoch 57, Loss: 8.604806900024414, Final Batch Loss: 1.729310154914856\n",
      "Epoch 58, Loss: 8.512348651885986, Final Batch Loss: 1.5392649173736572\n",
      "Epoch 59, Loss: 8.459039211273193, Final Batch Loss: 1.5735570192337036\n",
      "Epoch 60, Loss: 8.392087817192078, Final Batch Loss: 1.6099927425384521\n",
      "Epoch 61, Loss: 8.302806854248047, Final Batch Loss: 1.556884765625\n",
      "Epoch 62, Loss: 8.421690225601196, Final Batch Loss: 1.6631481647491455\n",
      "Epoch 63, Loss: 8.260103940963745, Final Batch Loss: 1.5029370784759521\n",
      "Epoch 64, Loss: 8.439019083976746, Final Batch Loss: 1.7035143375396729\n",
      "Epoch 65, Loss: 8.63820207118988, Final Batch Loss: 1.940930724143982\n",
      "Epoch 66, Loss: 8.474135875701904, Final Batch Loss: 1.6520936489105225\n",
      "Epoch 67, Loss: 8.659950971603394, Final Batch Loss: 1.920756459236145\n",
      "Epoch 68, Loss: 8.39892327785492, Final Batch Loss: 1.7267637252807617\n",
      "Epoch 69, Loss: 8.356720447540283, Final Batch Loss: 1.6872071027755737\n",
      "Epoch 70, Loss: 8.633374691009521, Final Batch Loss: 1.9303741455078125\n",
      "Epoch 71, Loss: 8.261253952980042, Final Batch Loss: 1.5460584163665771\n",
      "Epoch 72, Loss: 8.214513540267944, Final Batch Loss: 1.5951591730117798\n",
      "Epoch 73, Loss: 8.355674743652344, Final Batch Loss: 1.6952714920043945\n",
      "Epoch 74, Loss: 8.319599151611328, Final Batch Loss: 1.6160252094268799\n",
      "Epoch 75, Loss: 8.38376259803772, Final Batch Loss: 1.857953429222107\n",
      "Epoch 76, Loss: 8.59669303894043, Final Batch Loss: 1.958614706993103\n",
      "Epoch 77, Loss: 8.213208317756653, Final Batch Loss: 1.6047321557998657\n",
      "Epoch 78, Loss: 8.368752360343933, Final Batch Loss: 1.7590605020523071\n",
      "Epoch 79, Loss: 8.112227439880371, Final Batch Loss: 1.5627256631851196\n",
      "Epoch 80, Loss: 8.234748125076294, Final Batch Loss: 1.7003564834594727\n",
      "Epoch 81, Loss: 8.70585286617279, Final Batch Loss: 2.1111438274383545\n",
      "Epoch 82, Loss: 8.075214266777039, Final Batch Loss: 1.5922173261642456\n",
      "Epoch 83, Loss: 8.279036045074463, Final Batch Loss: 1.7239919900894165\n",
      "Epoch 84, Loss: 8.177607297897339, Final Batch Loss: 1.6207157373428345\n",
      "Epoch 85, Loss: 8.359049797058105, Final Batch Loss: 1.821759581565857\n",
      "Epoch 86, Loss: 7.9860405921936035, Final Batch Loss: 1.5671566724777222\n",
      "Epoch 87, Loss: 8.212323069572449, Final Batch Loss: 1.7590065002441406\n",
      "Epoch 88, Loss: 7.891851902008057, Final Batch Loss: 1.413994550704956\n",
      "Epoch 89, Loss: 7.806123733520508, Final Batch Loss: 1.36611008644104\n",
      "Epoch 90, Loss: 7.96259069442749, Final Batch Loss: 1.5471316576004028\n",
      "Epoch 91, Loss: 8.059926271438599, Final Batch Loss: 1.6398839950561523\n",
      "Epoch 92, Loss: 7.808248162269592, Final Batch Loss: 1.4063066244125366\n",
      "Epoch 93, Loss: 8.209551811218262, Final Batch Loss: 1.8426649570465088\n",
      "Epoch 94, Loss: 7.990119218826294, Final Batch Loss: 1.6398451328277588\n",
      "Epoch 95, Loss: 8.117084264755249, Final Batch Loss: 1.8243796825408936\n",
      "Epoch 96, Loss: 7.895126581192017, Final Batch Loss: 1.5247399806976318\n",
      "Epoch 97, Loss: 8.236186981201172, Final Batch Loss: 1.8903474807739258\n",
      "Epoch 98, Loss: 7.837244510650635, Final Batch Loss: 1.5300893783569336\n",
      "Epoch 99, Loss: 7.868724584579468, Final Batch Loss: 1.5528466701507568\n",
      "Epoch 100, Loss: 7.950471997261047, Final Batch Loss: 1.6541240215301514\n",
      "Epoch 101, Loss: 7.846218228340149, Final Batch Loss: 1.563341736793518\n",
      "Epoch 102, Loss: 7.982576012611389, Final Batch Loss: 1.6876766681671143\n",
      "Epoch 103, Loss: 7.509214520454407, Final Batch Loss: 1.1773325204849243\n",
      "Epoch 104, Loss: 7.971171140670776, Final Batch Loss: 1.7597919702529907\n",
      "Epoch 105, Loss: 7.802649259567261, Final Batch Loss: 1.5562485456466675\n",
      "Epoch 106, Loss: 7.664587616920471, Final Batch Loss: 1.4184646606445312\n",
      "Epoch 107, Loss: 7.643463969230652, Final Batch Loss: 1.3690717220306396\n",
      "Epoch 108, Loss: 8.078938961029053, Final Batch Loss: 1.7535144090652466\n",
      "Epoch 109, Loss: 7.921300768852234, Final Batch Loss: 1.6841485500335693\n",
      "Epoch 110, Loss: 7.527315378189087, Final Batch Loss: 1.3439607620239258\n",
      "Epoch 111, Loss: 7.895050406455994, Final Batch Loss: 1.760867714881897\n",
      "Epoch 112, Loss: 7.655771613121033, Final Batch Loss: 1.569638967514038\n",
      "Epoch 113, Loss: 7.735138535499573, Final Batch Loss: 1.5638681650161743\n",
      "Epoch 114, Loss: 7.589763641357422, Final Batch Loss: 1.4009053707122803\n",
      "Epoch 115, Loss: 7.411302089691162, Final Batch Loss: 1.289136290550232\n",
      "Epoch 116, Loss: 7.614482402801514, Final Batch Loss: 1.5430406332015991\n",
      "Epoch 117, Loss: 7.749262690544128, Final Batch Loss: 1.729645013809204\n",
      "Epoch 118, Loss: 7.771828055381775, Final Batch Loss: 1.6746594905853271\n",
      "Epoch 119, Loss: 7.735690593719482, Final Batch Loss: 1.668824315071106\n",
      "Epoch 120, Loss: 7.821550726890564, Final Batch Loss: 1.763047456741333\n",
      "Epoch 121, Loss: 7.555889129638672, Final Batch Loss: 1.4772120714187622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Loss: 7.402411937713623, Final Batch Loss: 1.3753858804702759\n",
      "Epoch 123, Loss: 7.534527540206909, Final Batch Loss: 1.5489248037338257\n",
      "Epoch 124, Loss: 7.700833082199097, Final Batch Loss: 1.5646238327026367\n",
      "Epoch 125, Loss: 7.479296803474426, Final Batch Loss: 1.398524284362793\n",
      "Epoch 126, Loss: 7.5560948848724365, Final Batch Loss: 1.4683653116226196\n",
      "Epoch 127, Loss: 7.386120557785034, Final Batch Loss: 1.3412530422210693\n",
      "Epoch 128, Loss: 7.310458183288574, Final Batch Loss: 1.3022414445877075\n",
      "Epoch 129, Loss: 7.312313556671143, Final Batch Loss: 1.3073397874832153\n",
      "Epoch 130, Loss: 7.65856671333313, Final Batch Loss: 1.7904497385025024\n",
      "Epoch 131, Loss: 7.496137261390686, Final Batch Loss: 1.5601166486740112\n",
      "Epoch 132, Loss: 7.244857311248779, Final Batch Loss: 1.3148502111434937\n",
      "Epoch 133, Loss: 7.555341720581055, Final Batch Loss: 1.6939470767974854\n",
      "Epoch 134, Loss: 7.417517900466919, Final Batch Loss: 1.5141950845718384\n",
      "Epoch 135, Loss: 7.543098092079163, Final Batch Loss: 1.7579807043075562\n",
      "Epoch 136, Loss: 7.332032561302185, Final Batch Loss: 1.4386546611785889\n",
      "Epoch 137, Loss: 7.5847649574279785, Final Batch Loss: 1.787699818611145\n",
      "Epoch 138, Loss: 7.336236953735352, Final Batch Loss: 1.4873669147491455\n",
      "Epoch 139, Loss: 7.596164703369141, Final Batch Loss: 1.7071605920791626\n",
      "Epoch 140, Loss: 7.149917364120483, Final Batch Loss: 1.3443559408187866\n",
      "Epoch 141, Loss: 7.237080097198486, Final Batch Loss: 1.4413315057754517\n",
      "Epoch 142, Loss: 7.149129867553711, Final Batch Loss: 1.277488350868225\n",
      "Epoch 143, Loss: 7.456559658050537, Final Batch Loss: 1.6659895181655884\n",
      "Epoch 144, Loss: 7.087902784347534, Final Batch Loss: 1.2452346086502075\n",
      "Epoch 145, Loss: 7.0254738330841064, Final Batch Loss: 1.2056849002838135\n",
      "Epoch 146, Loss: 7.447164297103882, Final Batch Loss: 1.604662299156189\n",
      "Epoch 147, Loss: 6.7907350063323975, Final Batch Loss: 1.0312613248825073\n",
      "Epoch 148, Loss: 7.281798243522644, Final Batch Loss: 1.4942436218261719\n",
      "Epoch 149, Loss: 7.061378240585327, Final Batch Loss: 1.2951936721801758\n",
      "Epoch 150, Loss: 7.261745810508728, Final Batch Loss: 1.5616629123687744\n",
      "Epoch 151, Loss: 7.051964521408081, Final Batch Loss: 1.3311764001846313\n",
      "Epoch 152, Loss: 7.324246764183044, Final Batch Loss: 1.616061806678772\n",
      "Epoch 153, Loss: 7.054857969284058, Final Batch Loss: 1.3228694200515747\n",
      "Epoch 154, Loss: 7.146711230278015, Final Batch Loss: 1.5599849224090576\n",
      "Epoch 155, Loss: 7.10310685634613, Final Batch Loss: 1.4378257989883423\n",
      "Epoch 156, Loss: 7.075013637542725, Final Batch Loss: 1.4880210161209106\n",
      "Epoch 157, Loss: 6.820898652076721, Final Batch Loss: 1.1518994569778442\n",
      "Epoch 158, Loss: 6.92746639251709, Final Batch Loss: 1.2336152791976929\n",
      "Epoch 159, Loss: 7.272140383720398, Final Batch Loss: 1.653347134590149\n",
      "Epoch 160, Loss: 6.768110394477844, Final Batch Loss: 1.212885856628418\n",
      "Epoch 161, Loss: 7.384598612785339, Final Batch Loss: 1.811410665512085\n",
      "Epoch 162, Loss: 7.087460279464722, Final Batch Loss: 1.4498742818832397\n",
      "Epoch 163, Loss: 7.539905786514282, Final Batch Loss: 1.8695547580718994\n",
      "Epoch 164, Loss: 7.362777233123779, Final Batch Loss: 1.9069650173187256\n",
      "Epoch 165, Loss: 6.871595978736877, Final Batch Loss: 1.2704116106033325\n",
      "Epoch 166, Loss: 6.926957845687866, Final Batch Loss: 1.3321220874786377\n",
      "Epoch 167, Loss: 6.787466526031494, Final Batch Loss: 1.1943778991699219\n",
      "Epoch 168, Loss: 7.088534712791443, Final Batch Loss: 1.5111790895462036\n",
      "Epoch 169, Loss: 6.924124836921692, Final Batch Loss: 1.3996702432632446\n",
      "Epoch 170, Loss: 6.674619197845459, Final Batch Loss: 1.2314198017120361\n",
      "Epoch 171, Loss: 6.830943942070007, Final Batch Loss: 1.3144408464431763\n",
      "Epoch 172, Loss: 7.005545496940613, Final Batch Loss: 1.6099414825439453\n",
      "Epoch 173, Loss: 7.082522869110107, Final Batch Loss: 1.6022863388061523\n",
      "Epoch 174, Loss: 6.851975798606873, Final Batch Loss: 1.3121092319488525\n",
      "Epoch 175, Loss: 6.527883768081665, Final Batch Loss: 1.0485570430755615\n",
      "Epoch 176, Loss: 6.413211822509766, Final Batch Loss: 1.01714289188385\n",
      "Epoch 177, Loss: 6.62308144569397, Final Batch Loss: 1.1981451511383057\n",
      "Epoch 178, Loss: 6.588353872299194, Final Batch Loss: 1.1091407537460327\n",
      "Epoch 179, Loss: 6.587587356567383, Final Batch Loss: 1.1076807975769043\n",
      "Epoch 180, Loss: 6.898408055305481, Final Batch Loss: 1.502532958984375\n",
      "Epoch 181, Loss: 6.708575367927551, Final Batch Loss: 1.3939727544784546\n",
      "Epoch 182, Loss: 6.754558324813843, Final Batch Loss: 1.3870123624801636\n",
      "Epoch 183, Loss: 6.592830181121826, Final Batch Loss: 1.3024370670318604\n",
      "Epoch 184, Loss: 6.771112322807312, Final Batch Loss: 1.468462586402893\n",
      "Epoch 185, Loss: 6.5578696727752686, Final Batch Loss: 1.2233949899673462\n",
      "Epoch 186, Loss: 6.745772957801819, Final Batch Loss: 1.527318000793457\n",
      "Epoch 187, Loss: 6.7109832763671875, Final Batch Loss: 1.449082612991333\n",
      "Epoch 188, Loss: 6.466955661773682, Final Batch Loss: 1.2201957702636719\n",
      "Epoch 189, Loss: 6.672182083129883, Final Batch Loss: 1.486077070236206\n",
      "Epoch 190, Loss: 6.424330115318298, Final Batch Loss: 1.1483772993087769\n",
      "Epoch 191, Loss: 6.827789306640625, Final Batch Loss: 1.7208002805709839\n",
      "Epoch 192, Loss: 6.472097754478455, Final Batch Loss: 1.3543905019760132\n",
      "Epoch 193, Loss: 6.154896855354309, Final Batch Loss: 1.0290272235870361\n",
      "Epoch 194, Loss: 6.4898399114608765, Final Batch Loss: 1.3301516771316528\n",
      "Epoch 195, Loss: 6.148629665374756, Final Batch Loss: 1.0325862169265747\n",
      "Epoch 196, Loss: 6.725724101066589, Final Batch Loss: 1.5747212171554565\n",
      "Epoch 197, Loss: 6.374310493469238, Final Batch Loss: 1.1564668416976929\n",
      "Epoch 198, Loss: 6.181468963623047, Final Batch Loss: 1.0633853673934937\n",
      "Epoch 199, Loss: 6.3717042207717896, Final Batch Loss: 1.2669732570648193\n",
      "Epoch 200, Loss: 6.316666841506958, Final Batch Loss: 1.191868543624878\n",
      "Epoch 201, Loss: 6.576202034950256, Final Batch Loss: 1.4349682331085205\n",
      "Epoch 202, Loss: 6.451067209243774, Final Batch Loss: 1.4639619588851929\n",
      "Epoch 203, Loss: 6.156951069831848, Final Batch Loss: 1.0910285711288452\n",
      "Epoch 204, Loss: 6.133676171302795, Final Batch Loss: 1.1014645099639893\n",
      "Epoch 205, Loss: 6.760627746582031, Final Batch Loss: 1.6535694599151611\n",
      "Epoch 206, Loss: 6.4307273626327515, Final Batch Loss: 1.4397934675216675\n",
      "Epoch 207, Loss: 6.090158104896545, Final Batch Loss: 0.9600318670272827\n",
      "Epoch 208, Loss: 6.4994765520095825, Final Batch Loss: 1.5396702289581299\n",
      "Epoch 209, Loss: 6.131629467010498, Final Batch Loss: 1.1180052757263184\n",
      "Epoch 210, Loss: 6.220805644989014, Final Batch Loss: 1.2445452213287354\n",
      "Epoch 211, Loss: 6.568596243858337, Final Batch Loss: 1.6229246854782104\n",
      "Epoch 212, Loss: 6.290508270263672, Final Batch Loss: 1.2887102365493774\n",
      "Epoch 213, Loss: 6.109532833099365, Final Batch Loss: 1.2779511213302612\n",
      "Epoch 214, Loss: 6.28670060634613, Final Batch Loss: 1.424717903137207\n",
      "Epoch 215, Loss: 5.822894990444183, Final Batch Loss: 0.9557462334632874\n",
      "Epoch 216, Loss: 6.161863684654236, Final Batch Loss: 1.29354727268219\n",
      "Epoch 217, Loss: 5.988936543464661, Final Batch Loss: 1.0333596467971802\n",
      "Epoch 218, Loss: 5.764246821403503, Final Batch Loss: 0.9039216041564941\n",
      "Epoch 219, Loss: 6.278067708015442, Final Batch Loss: 1.3981322050094604\n",
      "Epoch 220, Loss: 5.883398532867432, Final Batch Loss: 1.0592963695526123\n",
      "Epoch 221, Loss: 6.158191442489624, Final Batch Loss: 1.3676280975341797\n",
      "Epoch 222, Loss: 6.0033721923828125, Final Batch Loss: 1.251473069190979\n",
      "Epoch 223, Loss: 5.6602113246917725, Final Batch Loss: 0.8794687986373901\n",
      "Epoch 224, Loss: 6.209376096725464, Final Batch Loss: 1.4336411952972412\n",
      "Epoch 225, Loss: 5.957234859466553, Final Batch Loss: 1.2172209024429321\n",
      "Epoch 226, Loss: 6.097824931144714, Final Batch Loss: 1.2675788402557373\n",
      "Epoch 227, Loss: 5.897902846336365, Final Batch Loss: 1.1141561269760132\n",
      "Epoch 228, Loss: 5.871112704277039, Final Batch Loss: 1.1661683320999146\n",
      "Epoch 229, Loss: 5.8790130615234375, Final Batch Loss: 1.1509453058242798\n",
      "Epoch 230, Loss: 5.568306148052216, Final Batch Loss: 0.8743067383766174\n",
      "Epoch 231, Loss: 6.088601231575012, Final Batch Loss: 1.4379771947860718\n",
      "Epoch 232, Loss: 5.860978364944458, Final Batch Loss: 1.2332093715667725\n",
      "Epoch 233, Loss: 5.7009516954422, Final Batch Loss: 1.0147727727890015\n",
      "Epoch 234, Loss: 5.7143166065216064, Final Batch Loss: 1.0772745609283447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235, Loss: 5.649630904197693, Final Batch Loss: 1.0352226495742798\n",
      "Epoch 236, Loss: 5.420782625675201, Final Batch Loss: 0.6849541068077087\n",
      "Epoch 237, Loss: 5.997173190116882, Final Batch Loss: 1.4083783626556396\n",
      "Epoch 238, Loss: 5.595331251621246, Final Batch Loss: 0.911438524723053\n",
      "Epoch 239, Loss: 6.234659552574158, Final Batch Loss: 1.6959736347198486\n",
      "Epoch 240, Loss: 6.1147929430007935, Final Batch Loss: 1.4471160173416138\n",
      "Epoch 241, Loss: 5.884374141693115, Final Batch Loss: 1.357959508895874\n",
      "Epoch 242, Loss: 5.28892320394516, Final Batch Loss: 0.7131752371788025\n",
      "Epoch 243, Loss: 5.86598539352417, Final Batch Loss: 1.2176915407180786\n",
      "Epoch 244, Loss: 5.52385014295578, Final Batch Loss: 0.9148558974266052\n",
      "Epoch 245, Loss: 5.813094615936279, Final Batch Loss: 1.145483136177063\n",
      "Epoch 246, Loss: 6.129200577735901, Final Batch Loss: 1.4460211992263794\n",
      "Epoch 247, Loss: 5.71763277053833, Final Batch Loss: 1.1355500221252441\n",
      "Epoch 248, Loss: 5.600103855133057, Final Batch Loss: 1.0162770748138428\n",
      "Epoch 249, Loss: 5.8172430992126465, Final Batch Loss: 1.1913540363311768\n",
      "Epoch 250, Loss: 5.635493516921997, Final Batch Loss: 1.1369421482086182\n",
      "Epoch 251, Loss: 5.6391414403915405, Final Batch Loss: 1.2347362041473389\n",
      "Epoch 252, Loss: 5.520984768867493, Final Batch Loss: 0.8727370500564575\n",
      "Epoch 253, Loss: 5.600008130073547, Final Batch Loss: 1.1322801113128662\n",
      "Epoch 254, Loss: 5.8607765436172485, Final Batch Loss: 1.3637601137161255\n",
      "Epoch 255, Loss: 5.26144140958786, Final Batch Loss: 0.8030419945716858\n",
      "Epoch 256, Loss: 5.772832632064819, Final Batch Loss: 1.2520819902420044\n",
      "Epoch 257, Loss: 5.7174506187438965, Final Batch Loss: 1.3145732879638672\n",
      "Epoch 258, Loss: 5.545374572277069, Final Batch Loss: 1.1166292428970337\n",
      "Epoch 259, Loss: 5.5465662479400635, Final Batch Loss: 1.109659194946289\n",
      "Epoch 260, Loss: 5.565303981304169, Final Batch Loss: 0.9935415387153625\n",
      "Epoch 261, Loss: 5.841128587722778, Final Batch Loss: 1.4994558095932007\n",
      "Epoch 262, Loss: 5.85542893409729, Final Batch Loss: 1.3384695053100586\n",
      "Epoch 263, Loss: 5.441871762275696, Final Batch Loss: 1.0226701498031616\n",
      "Epoch 264, Loss: 5.704762816429138, Final Batch Loss: 1.3180944919586182\n",
      "Epoch 265, Loss: 5.650294780731201, Final Batch Loss: 1.127130150794983\n",
      "Epoch 266, Loss: 5.802235126495361, Final Batch Loss: 1.2673746347427368\n",
      "Epoch 267, Loss: 5.465712785720825, Final Batch Loss: 1.0815476179122925\n",
      "Epoch 268, Loss: 5.462719798088074, Final Batch Loss: 1.0732545852661133\n",
      "Epoch 269, Loss: 5.43861198425293, Final Batch Loss: 1.0580260753631592\n",
      "Epoch 270, Loss: 5.836424350738525, Final Batch Loss: 1.4309324026107788\n",
      "Epoch 271, Loss: 5.220991134643555, Final Batch Loss: 1.059899926185608\n",
      "Epoch 272, Loss: 5.4799216985702515, Final Batch Loss: 1.036941647529602\n",
      "Epoch 273, Loss: 5.594680070877075, Final Batch Loss: 1.0912559032440186\n",
      "Epoch 274, Loss: 5.385617613792419, Final Batch Loss: 1.0643819570541382\n",
      "Epoch 275, Loss: 5.524281024932861, Final Batch Loss: 1.1961363554000854\n",
      "Epoch 276, Loss: 5.503792405128479, Final Batch Loss: 1.3013190031051636\n",
      "Epoch 277, Loss: 5.762250483036041, Final Batch Loss: 1.5342952013015747\n",
      "Epoch 278, Loss: 5.020963072776794, Final Batch Loss: 0.8299923539161682\n",
      "Epoch 279, Loss: 5.658044338226318, Final Batch Loss: 1.2963937520980835\n",
      "Epoch 280, Loss: 5.389803051948547, Final Batch Loss: 1.1079603433609009\n",
      "Epoch 281, Loss: 5.492977738380432, Final Batch Loss: 1.3043384552001953\n",
      "Epoch 282, Loss: 5.359407186508179, Final Batch Loss: 1.0640238523483276\n",
      "Epoch 283, Loss: 4.8871349692344666, Final Batch Loss: 0.5721473097801208\n",
      "Epoch 284, Loss: 5.412613153457642, Final Batch Loss: 1.1677957773208618\n",
      "Epoch 285, Loss: 5.415938138961792, Final Batch Loss: 1.2180325984954834\n",
      "Epoch 286, Loss: 5.268105745315552, Final Batch Loss: 0.995710551738739\n",
      "Epoch 287, Loss: 5.471125960350037, Final Batch Loss: 1.0902286767959595\n",
      "Epoch 288, Loss: 5.276873052120209, Final Batch Loss: 0.9917809367179871\n",
      "Epoch 289, Loss: 5.431390345096588, Final Batch Loss: 1.0983866453170776\n",
      "Epoch 290, Loss: 5.490612268447876, Final Batch Loss: 1.357704520225525\n",
      "Epoch 291, Loss: 5.4606329798698425, Final Batch Loss: 1.2307194471359253\n",
      "Epoch 292, Loss: 5.322336196899414, Final Batch Loss: 0.8794957399368286\n",
      "Epoch 293, Loss: 5.346777617931366, Final Batch Loss: 1.0617890357971191\n",
      "Epoch 294, Loss: 5.013198137283325, Final Batch Loss: 0.9072539210319519\n",
      "Epoch 295, Loss: 5.403053641319275, Final Batch Loss: 1.1295064687728882\n",
      "Epoch 296, Loss: 5.429489731788635, Final Batch Loss: 1.1304019689559937\n",
      "Epoch 297, Loss: 5.244739890098572, Final Batch Loss: 1.0370244979858398\n",
      "Epoch 298, Loss: 5.514350056648254, Final Batch Loss: 1.211342215538025\n",
      "Epoch 299, Loss: 5.424986243247986, Final Batch Loss: 1.3438421487808228\n",
      "Epoch 300, Loss: 5.367588698863983, Final Batch Loss: 1.230826735496521\n",
      "Epoch 301, Loss: 5.316491365432739, Final Batch Loss: 1.0999770164489746\n",
      "Epoch 302, Loss: 5.207770466804504, Final Batch Loss: 1.0226988792419434\n",
      "Epoch 303, Loss: 5.426419496536255, Final Batch Loss: 1.2734854221343994\n",
      "Epoch 304, Loss: 5.166717886924744, Final Batch Loss: 1.0170087814331055\n",
      "Epoch 305, Loss: 4.905910551548004, Final Batch Loss: 0.7712712287902832\n",
      "Epoch 306, Loss: 5.118044018745422, Final Batch Loss: 0.9520542025566101\n",
      "Epoch 307, Loss: 5.0230438113212585, Final Batch Loss: 0.9223862290382385\n",
      "Epoch 308, Loss: 5.088560402393341, Final Batch Loss: 0.9404560327529907\n",
      "Epoch 309, Loss: 5.4270129799842834, Final Batch Loss: 1.2644720077514648\n",
      "Epoch 310, Loss: 5.282666921615601, Final Batch Loss: 1.1667042970657349\n",
      "Epoch 311, Loss: 5.485244929790497, Final Batch Loss: 1.3131099939346313\n",
      "Epoch 312, Loss: 5.502296805381775, Final Batch Loss: 1.2876955270767212\n",
      "Epoch 313, Loss: 5.320702135562897, Final Batch Loss: 1.1472917795181274\n",
      "Epoch 314, Loss: 4.9583351612091064, Final Batch Loss: 0.830238938331604\n",
      "Epoch 315, Loss: 5.062359929084778, Final Batch Loss: 0.8387762308120728\n",
      "Epoch 316, Loss: 5.263999819755554, Final Batch Loss: 1.1183072328567505\n",
      "Epoch 317, Loss: 5.463927507400513, Final Batch Loss: 1.2795298099517822\n",
      "Epoch 318, Loss: 5.675281405448914, Final Batch Loss: 1.555835485458374\n",
      "Epoch 319, Loss: 4.941945493221283, Final Batch Loss: 0.8033391833305359\n",
      "Epoch 320, Loss: 5.421663820743561, Final Batch Loss: 1.321410059928894\n",
      "Epoch 321, Loss: 5.099682450294495, Final Batch Loss: 0.9226719737052917\n",
      "Epoch 322, Loss: 4.8724231123924255, Final Batch Loss: 0.738998293876648\n",
      "Epoch 323, Loss: 5.073187291622162, Final Batch Loss: 0.9451305270195007\n",
      "Epoch 324, Loss: 5.613854706287384, Final Batch Loss: 1.5444828271865845\n",
      "Epoch 325, Loss: 5.575796365737915, Final Batch Loss: 1.4259058237075806\n",
      "Epoch 326, Loss: 5.099190890789032, Final Batch Loss: 1.012315273284912\n",
      "Epoch 327, Loss: 5.3656365275383, Final Batch Loss: 1.2352768182754517\n",
      "Epoch 328, Loss: 4.920726239681244, Final Batch Loss: 0.8968111872673035\n",
      "Epoch 329, Loss: 5.234130442142487, Final Batch Loss: 1.186788558959961\n",
      "Epoch 330, Loss: 5.142310738563538, Final Batch Loss: 1.1288307905197144\n",
      "Epoch 331, Loss: 4.949877858161926, Final Batch Loss: 0.8193445801734924\n",
      "Epoch 332, Loss: 4.913903772830963, Final Batch Loss: 0.904919445514679\n",
      "Epoch 333, Loss: 5.311809718608856, Final Batch Loss: 1.1760826110839844\n",
      "Epoch 334, Loss: 4.914304137229919, Final Batch Loss: 0.8358622193336487\n",
      "Epoch 335, Loss: 4.931276738643646, Final Batch Loss: 0.8449295163154602\n",
      "Epoch 336, Loss: 4.858092486858368, Final Batch Loss: 0.7690324187278748\n",
      "Epoch 337, Loss: 5.478413820266724, Final Batch Loss: 1.4664214849472046\n",
      "Epoch 338, Loss: 5.130347549915314, Final Batch Loss: 1.1168066263198853\n",
      "Epoch 339, Loss: 5.113904237747192, Final Batch Loss: 1.0752689838409424\n",
      "Epoch 340, Loss: 5.062259376049042, Final Batch Loss: 1.0217443704605103\n",
      "Epoch 341, Loss: 5.202100336551666, Final Batch Loss: 1.0526703596115112\n",
      "Epoch 342, Loss: 5.051807880401611, Final Batch Loss: 1.0678216218948364\n",
      "Epoch 343, Loss: 5.063392162322998, Final Batch Loss: 1.0647785663604736\n",
      "Epoch 344, Loss: 5.085772931575775, Final Batch Loss: 1.1346015930175781\n",
      "Epoch 345, Loss: 4.739158034324646, Final Batch Loss: 0.7327059507369995\n",
      "Epoch 346, Loss: 4.770722985267639, Final Batch Loss: 0.7310924530029297\n",
      "Epoch 347, Loss: 4.923460304737091, Final Batch Loss: 0.9520729184150696\n",
      "Epoch 348, Loss: 5.1999452114105225, Final Batch Loss: 1.1480505466461182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349, Loss: 5.1949833035469055, Final Batch Loss: 1.1471025943756104\n",
      "Epoch 350, Loss: 5.317167162895203, Final Batch Loss: 1.3088855743408203\n",
      "Epoch 351, Loss: 4.938786566257477, Final Batch Loss: 0.8850039839744568\n",
      "Epoch 352, Loss: 5.315455198287964, Final Batch Loss: 1.1187536716461182\n",
      "Epoch 353, Loss: 5.254513800144196, Final Batch Loss: 1.0631020069122314\n",
      "Epoch 354, Loss: 5.163917541503906, Final Batch Loss: 1.1051205396652222\n",
      "Epoch 355, Loss: 4.65183812379837, Final Batch Loss: 0.6865507960319519\n",
      "Epoch 356, Loss: 4.925024211406708, Final Batch Loss: 0.9830484390258789\n",
      "Epoch 357, Loss: 4.928327918052673, Final Batch Loss: 0.8862530589103699\n",
      "Epoch 358, Loss: 5.3312530517578125, Final Batch Loss: 1.3421660661697388\n",
      "Epoch 359, Loss: 4.58327716588974, Final Batch Loss: 0.7081580758094788\n",
      "Epoch 360, Loss: 4.405513525009155, Final Batch Loss: 0.5363365411758423\n",
      "Epoch 361, Loss: 4.956339061260223, Final Batch Loss: 0.8974974751472473\n",
      "Epoch 362, Loss: 4.731024503707886, Final Batch Loss: 0.7121548056602478\n",
      "Epoch 363, Loss: 4.9735687375068665, Final Batch Loss: 1.0310865640640259\n",
      "Epoch 364, Loss: 4.8315629959106445, Final Batch Loss: 0.8637750744819641\n",
      "Epoch 365, Loss: 5.074160814285278, Final Batch Loss: 1.0227742195129395\n",
      "Epoch 366, Loss: 5.342603862285614, Final Batch Loss: 1.3094161748886108\n",
      "Epoch 367, Loss: 5.316113770008087, Final Batch Loss: 1.360987663269043\n",
      "Epoch 368, Loss: 4.912886559963226, Final Batch Loss: 0.955183207988739\n",
      "Epoch 369, Loss: 5.180149972438812, Final Batch Loss: 1.1952016353607178\n",
      "Epoch 370, Loss: 4.928602933883667, Final Batch Loss: 0.9494031667709351\n",
      "Epoch 371, Loss: 4.947373270988464, Final Batch Loss: 0.9065675735473633\n",
      "Epoch 372, Loss: 4.986459016799927, Final Batch Loss: 1.0423060655593872\n",
      "Epoch 373, Loss: 5.063699841499329, Final Batch Loss: 1.1610177755355835\n",
      "Epoch 374, Loss: 5.193557679653168, Final Batch Loss: 1.2704861164093018\n",
      "Epoch 375, Loss: 5.212375462055206, Final Batch Loss: 1.26703941822052\n",
      "Epoch 376, Loss: 5.006396472454071, Final Batch Loss: 1.045958161354065\n",
      "Epoch 377, Loss: 5.123173952102661, Final Batch Loss: 1.1768935918807983\n",
      "Epoch 378, Loss: 4.665568768978119, Final Batch Loss: 0.6424303650856018\n",
      "Epoch 379, Loss: 5.249452590942383, Final Batch Loss: 1.3447380065917969\n",
      "Epoch 380, Loss: 4.794703125953674, Final Batch Loss: 0.9308899641036987\n",
      "Epoch 381, Loss: 5.03565901517868, Final Batch Loss: 1.2200831174850464\n",
      "Epoch 382, Loss: 4.374634861946106, Final Batch Loss: 0.6318771243095398\n",
      "Epoch 383, Loss: 5.082577049732208, Final Batch Loss: 1.1972599029541016\n",
      "Epoch 384, Loss: 4.982673346996307, Final Batch Loss: 1.1613520383834839\n",
      "Epoch 385, Loss: 5.067386090755463, Final Batch Loss: 1.2237446308135986\n",
      "Epoch 386, Loss: 4.982937932014465, Final Batch Loss: 1.1655710935592651\n",
      "Epoch 387, Loss: 4.7900474071502686, Final Batch Loss: 0.9589284658432007\n",
      "Epoch 388, Loss: 4.910425007343292, Final Batch Loss: 1.0972706079483032\n",
      "Epoch 389, Loss: 4.912750422954559, Final Batch Loss: 0.9479632377624512\n",
      "Epoch 390, Loss: 5.069900035858154, Final Batch Loss: 1.2375630140304565\n",
      "Epoch 391, Loss: 4.673809111118317, Final Batch Loss: 0.8577015995979309\n",
      "Epoch 392, Loss: 4.957313358783722, Final Batch Loss: 1.047406554222107\n",
      "Epoch 393, Loss: 4.646039366722107, Final Batch Loss: 0.7935395836830139\n",
      "Epoch 394, Loss: 4.874479830265045, Final Batch Loss: 1.119585633277893\n",
      "Epoch 395, Loss: 4.722419619560242, Final Batch Loss: 0.8731886744499207\n",
      "Epoch 396, Loss: 5.397837162017822, Final Batch Loss: 1.5511372089385986\n",
      "Epoch 397, Loss: 5.334264099597931, Final Batch Loss: 1.5172191858291626\n",
      "Epoch 398, Loss: 4.458112835884094, Final Batch Loss: 0.6950971484184265\n",
      "Epoch 399, Loss: 5.030080735683441, Final Batch Loss: 1.1093246936798096\n",
      "Epoch 400, Loss: 5.000399112701416, Final Batch Loss: 1.0655864477157593\n",
      "Epoch 401, Loss: 4.710277020931244, Final Batch Loss: 0.9008113145828247\n",
      "Epoch 402, Loss: 4.916171133518219, Final Batch Loss: 1.1343034505844116\n",
      "Epoch 403, Loss: 4.8746591210365295, Final Batch Loss: 0.9789093732833862\n",
      "Epoch 404, Loss: 4.733021318912506, Final Batch Loss: 1.0158746242523193\n",
      "Epoch 405, Loss: 4.52798318862915, Final Batch Loss: 0.8001370429992676\n",
      "Epoch 406, Loss: 5.014076769351959, Final Batch Loss: 1.1078938245773315\n",
      "Epoch 407, Loss: 5.023486614227295, Final Batch Loss: 1.2945635318756104\n",
      "Epoch 408, Loss: 4.812467813491821, Final Batch Loss: 0.99998939037323\n",
      "Epoch 409, Loss: 4.399620056152344, Final Batch Loss: 0.5481189489364624\n",
      "Epoch 410, Loss: 4.778161883354187, Final Batch Loss: 0.9478301405906677\n",
      "Epoch 411, Loss: 4.551235735416412, Final Batch Loss: 0.7819369435310364\n",
      "Epoch 412, Loss: 4.994737982749939, Final Batch Loss: 1.2909201383590698\n",
      "Epoch 413, Loss: 4.624612212181091, Final Batch Loss: 0.7674563527107239\n",
      "Epoch 414, Loss: 4.768601477146149, Final Batch Loss: 1.016270399093628\n",
      "Epoch 415, Loss: 4.580966293811798, Final Batch Loss: 0.8138356804847717\n",
      "Epoch 416, Loss: 4.46954208612442, Final Batch Loss: 0.7912232279777527\n",
      "Epoch 417, Loss: 4.447076797485352, Final Batch Loss: 0.6522981524467468\n",
      "Epoch 418, Loss: 4.744814038276672, Final Batch Loss: 1.1084601879119873\n",
      "Epoch 419, Loss: 4.72697901725769, Final Batch Loss: 0.9489907026290894\n",
      "Epoch 420, Loss: 4.50092488527298, Final Batch Loss: 0.7698222398757935\n",
      "Epoch 421, Loss: 4.313009202480316, Final Batch Loss: 0.5857917070388794\n",
      "Epoch 422, Loss: 4.723981201648712, Final Batch Loss: 0.9076775908470154\n",
      "Epoch 423, Loss: 4.972591876983643, Final Batch Loss: 1.3802778720855713\n",
      "Epoch 424, Loss: 4.707426011562347, Final Batch Loss: 0.932031512260437\n",
      "Epoch 425, Loss: 4.492267668247223, Final Batch Loss: 0.6772369146347046\n",
      "Epoch 426, Loss: 4.721150577068329, Final Batch Loss: 0.9474232792854309\n",
      "Epoch 427, Loss: 4.769588351249695, Final Batch Loss: 1.0078456401824951\n",
      "Epoch 428, Loss: 4.501254975795746, Final Batch Loss: 0.7657774686813354\n",
      "Epoch 429, Loss: 5.272990882396698, Final Batch Loss: 1.4760228395462036\n",
      "Epoch 430, Loss: 4.545196712017059, Final Batch Loss: 0.9904287457466125\n",
      "Epoch 431, Loss: 4.39096075296402, Final Batch Loss: 0.6244548559188843\n",
      "Epoch 432, Loss: 4.329246699810028, Final Batch Loss: 0.6918088793754578\n",
      "Epoch 433, Loss: 4.123874872922897, Final Batch Loss: 0.44056007266044617\n",
      "Epoch 434, Loss: 4.590700387954712, Final Batch Loss: 0.9663395285606384\n",
      "Epoch 435, Loss: 4.798188030719757, Final Batch Loss: 1.0482546091079712\n",
      "Epoch 436, Loss: 4.320349216461182, Final Batch Loss: 0.5618876814842224\n",
      "Epoch 437, Loss: 4.388684868812561, Final Batch Loss: 0.6128174662590027\n",
      "Epoch 438, Loss: 5.327512741088867, Final Batch Loss: 1.5208450555801392\n",
      "Epoch 439, Loss: 4.8491199016571045, Final Batch Loss: 1.1588207483291626\n",
      "Epoch 440, Loss: 4.751245141029358, Final Batch Loss: 0.9566432237625122\n",
      "Epoch 441, Loss: 4.537136435508728, Final Batch Loss: 0.6836784482002258\n",
      "Epoch 442, Loss: 4.783828616142273, Final Batch Loss: 1.1497938632965088\n",
      "Epoch 443, Loss: 4.884742736816406, Final Batch Loss: 1.2238337993621826\n",
      "Epoch 444, Loss: 4.576241612434387, Final Batch Loss: 0.8998522162437439\n",
      "Epoch 445, Loss: 4.418453574180603, Final Batch Loss: 0.6262407898902893\n",
      "Epoch 446, Loss: 4.72785872220993, Final Batch Loss: 0.9685020446777344\n",
      "Epoch 447, Loss: 4.6176705956459045, Final Batch Loss: 0.8800214529037476\n",
      "Epoch 448, Loss: 4.526155054569244, Final Batch Loss: 0.9837265014648438\n",
      "Epoch 449, Loss: 4.253509879112244, Final Batch Loss: 0.5895673632621765\n",
      "Epoch 450, Loss: 4.391805171966553, Final Batch Loss: 0.773516058921814\n",
      "Epoch 451, Loss: 4.442600250244141, Final Batch Loss: 0.7831968665122986\n",
      "Epoch 452, Loss: 4.986559748649597, Final Batch Loss: 1.2407734394073486\n",
      "Epoch 453, Loss: 4.6927613615989685, Final Batch Loss: 0.9062072038650513\n",
      "Epoch 454, Loss: 4.826036691665649, Final Batch Loss: 1.062972903251648\n",
      "Epoch 455, Loss: 4.28791880607605, Final Batch Loss: 0.6457470655441284\n",
      "Epoch 456, Loss: 4.305725634098053, Final Batch Loss: 0.724483847618103\n",
      "Epoch 457, Loss: 4.678979754447937, Final Batch Loss: 0.9271530508995056\n",
      "Epoch 458, Loss: 4.577465534210205, Final Batch Loss: 0.8787702322006226\n",
      "Epoch 459, Loss: 4.513495862483978, Final Batch Loss: 0.7760713696479797\n",
      "Epoch 460, Loss: 4.408728241920471, Final Batch Loss: 0.7797945141792297\n",
      "Epoch 461, Loss: 4.344812870025635, Final Batch Loss: 0.6900656819343567\n",
      "Epoch 462, Loss: 4.656092643737793, Final Batch Loss: 0.9520338177680969\n",
      "Epoch 463, Loss: 4.381568014621735, Final Batch Loss: 0.7924628257751465\n",
      "Epoch 464, Loss: 4.792396128177643, Final Batch Loss: 1.088828206062317\n",
      "Epoch 465, Loss: 4.2867743372917175, Final Batch Loss: 0.6343308091163635\n",
      "Epoch 466, Loss: 4.3782766461372375, Final Batch Loss: 0.6607486009597778\n",
      "Epoch 467, Loss: 4.53812038898468, Final Batch Loss: 0.9962672591209412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468, Loss: 4.697218239307404, Final Batch Loss: 1.241021752357483\n",
      "Epoch 469, Loss: 4.589415669441223, Final Batch Loss: 0.9509838819503784\n",
      "Epoch 470, Loss: 4.803321599960327, Final Batch Loss: 1.086486577987671\n",
      "Epoch 471, Loss: 4.968891739845276, Final Batch Loss: 1.312026023864746\n",
      "Epoch 472, Loss: 4.604058921337128, Final Batch Loss: 1.1129223108291626\n",
      "Epoch 473, Loss: 4.36892557144165, Final Batch Loss: 0.82025545835495\n",
      "Epoch 474, Loss: 4.543309569358826, Final Batch Loss: 0.843180775642395\n",
      "Epoch 475, Loss: 4.483246982097626, Final Batch Loss: 0.9342211484909058\n",
      "Epoch 476, Loss: 3.8943221271038055, Final Batch Loss: 0.47067007422447205\n",
      "Epoch 477, Loss: 4.626850008964539, Final Batch Loss: 0.914088785648346\n",
      "Epoch 478, Loss: 4.334669351577759, Final Batch Loss: 0.7594773173332214\n",
      "Epoch 479, Loss: 4.249348759651184, Final Batch Loss: 0.823900580406189\n",
      "Epoch 480, Loss: 4.679914236068726, Final Batch Loss: 0.9958229660987854\n",
      "Epoch 481, Loss: 4.361842751502991, Final Batch Loss: 0.6589773297309875\n",
      "Epoch 482, Loss: 4.495530366897583, Final Batch Loss: 0.9078373312950134\n",
      "Epoch 483, Loss: 4.479958713054657, Final Batch Loss: 0.9505882859230042\n",
      "Epoch 484, Loss: 4.472664833068848, Final Batch Loss: 0.8537091016769409\n",
      "Epoch 485, Loss: 3.9922565817832947, Final Batch Loss: 0.5299491882324219\n",
      "Epoch 486, Loss: 4.334481179714203, Final Batch Loss: 0.8084178566932678\n",
      "Epoch 487, Loss: 4.582124650478363, Final Batch Loss: 0.9025834202766418\n",
      "Epoch 488, Loss: 4.19068044424057, Final Batch Loss: 0.6925655603408813\n",
      "Epoch 489, Loss: 4.4139328598976135, Final Batch Loss: 0.6938081979751587\n",
      "Epoch 490, Loss: 4.527665674686432, Final Batch Loss: 0.7886596322059631\n",
      "Epoch 491, Loss: 4.728325009346008, Final Batch Loss: 1.1317745447158813\n",
      "Epoch 492, Loss: 4.4709689021110535, Final Batch Loss: 0.9483846426010132\n",
      "Epoch 493, Loss: 4.363593399524689, Final Batch Loss: 0.9255842566490173\n",
      "Epoch 494, Loss: 4.016753852367401, Final Batch Loss: 0.5571957230567932\n",
      "Epoch 495, Loss: 4.081908762454987, Final Batch Loss: 0.5943108797073364\n",
      "Epoch 496, Loss: 4.433237314224243, Final Batch Loss: 0.9458504915237427\n",
      "Epoch 497, Loss: 4.154493987560272, Final Batch Loss: 0.6879889369010925\n",
      "Epoch 498, Loss: 4.691502034664154, Final Batch Loss: 1.0460643768310547\n",
      "Epoch 499, Loss: 4.650114417076111, Final Batch Loss: 1.0586268901824951\n",
      "Epoch 500, Loss: 4.711283266544342, Final Batch Loss: 1.2093496322631836\n",
      "Epoch 501, Loss: 4.534707188606262, Final Batch Loss: 1.1778404712677002\n",
      "Epoch 502, Loss: 4.490769982337952, Final Batch Loss: 0.9414997696876526\n",
      "Epoch 503, Loss: 4.53888064622879, Final Batch Loss: 1.0750259160995483\n",
      "Epoch 504, Loss: 4.766123175621033, Final Batch Loss: 1.2941551208496094\n",
      "Epoch 505, Loss: 4.848966002464294, Final Batch Loss: 1.4550559520721436\n",
      "Epoch 506, Loss: 4.9025779366493225, Final Batch Loss: 1.3757370710372925\n",
      "Epoch 507, Loss: 4.587922155857086, Final Batch Loss: 1.0570595264434814\n",
      "Epoch 508, Loss: 4.186137020587921, Final Batch Loss: 0.6696566343307495\n",
      "Epoch 509, Loss: 4.040847897529602, Final Batch Loss: 0.5664077997207642\n",
      "Epoch 510, Loss: 4.586599767208099, Final Batch Loss: 1.2183845043182373\n",
      "Epoch 511, Loss: 4.002270340919495, Final Batch Loss: 0.5855955481529236\n",
      "Epoch 512, Loss: 4.356327414512634, Final Batch Loss: 0.8413444757461548\n",
      "Epoch 513, Loss: 4.290916323661804, Final Batch Loss: 0.7743405699729919\n",
      "Epoch 514, Loss: 4.067527651786804, Final Batch Loss: 0.6298450827598572\n",
      "Epoch 515, Loss: 4.199514806270599, Final Batch Loss: 0.5805026888847351\n",
      "Epoch 516, Loss: 4.321400821208954, Final Batch Loss: 0.8344650268554688\n",
      "Epoch 517, Loss: 4.396305322647095, Final Batch Loss: 0.755963146686554\n",
      "Epoch 518, Loss: 4.287197649478912, Final Batch Loss: 0.7485812902450562\n",
      "Epoch 519, Loss: 4.015631556510925, Final Batch Loss: 0.5705990195274353\n",
      "Epoch 520, Loss: 4.400421738624573, Final Batch Loss: 0.8992112874984741\n",
      "Epoch 521, Loss: 3.861538380384445, Final Batch Loss: 0.4654674828052521\n",
      "Epoch 522, Loss: 4.6118029952049255, Final Batch Loss: 1.0522785186767578\n",
      "Epoch 523, Loss: 4.515108048915863, Final Batch Loss: 1.1381115913391113\n",
      "Epoch 524, Loss: 4.180875897407532, Final Batch Loss: 0.7490922212600708\n",
      "Epoch 525, Loss: 4.157658398151398, Final Batch Loss: 0.8012569546699524\n",
      "Epoch 526, Loss: 3.832791119813919, Final Batch Loss: 0.35980162024497986\n",
      "Epoch 527, Loss: 4.091572105884552, Final Batch Loss: 0.589080810546875\n",
      "Epoch 528, Loss: 4.557093679904938, Final Batch Loss: 1.0383108854293823\n",
      "Epoch 529, Loss: 4.100195467472076, Final Batch Loss: 0.7092140316963196\n",
      "Epoch 530, Loss: 4.46677702665329, Final Batch Loss: 0.9889703989028931\n",
      "Epoch 531, Loss: 4.482166647911072, Final Batch Loss: 0.9807062745094299\n",
      "Epoch 532, Loss: 4.191672146320343, Final Batch Loss: 0.6986209750175476\n",
      "Epoch 533, Loss: 4.551139771938324, Final Batch Loss: 1.3092880249023438\n",
      "Epoch 534, Loss: 4.689211308956146, Final Batch Loss: 1.2258623838424683\n",
      "Epoch 535, Loss: 4.181857585906982, Final Batch Loss: 0.7267078757286072\n",
      "Epoch 536, Loss: 4.137677192687988, Final Batch Loss: 0.7596392035484314\n",
      "Epoch 537, Loss: 4.376060605049133, Final Batch Loss: 0.8423328995704651\n",
      "Epoch 538, Loss: 4.257430195808411, Final Batch Loss: 0.8275008797645569\n",
      "Epoch 539, Loss: 4.106817901134491, Final Batch Loss: 0.7287534475326538\n",
      "Epoch 540, Loss: 4.407477855682373, Final Batch Loss: 0.9353009462356567\n",
      "Epoch 541, Loss: 4.200187087059021, Final Batch Loss: 0.8090346455574036\n",
      "Epoch 542, Loss: 4.0742974281311035, Final Batch Loss: 0.7658930420875549\n",
      "Epoch 543, Loss: 3.9819493889808655, Final Batch Loss: 0.5787530541419983\n",
      "Epoch 544, Loss: 4.325701653957367, Final Batch Loss: 0.9773984551429749\n",
      "Epoch 545, Loss: 4.342028379440308, Final Batch Loss: 0.9175872802734375\n",
      "Epoch 546, Loss: 4.098278045654297, Final Batch Loss: 0.6552944779396057\n",
      "Epoch 547, Loss: 4.750259160995483, Final Batch Loss: 1.2373745441436768\n",
      "Epoch 548, Loss: 4.5001861453056335, Final Batch Loss: 1.0769692659378052\n",
      "Epoch 549, Loss: 3.9583073556423187, Final Batch Loss: 0.4497605860233307\n",
      "Epoch 550, Loss: 4.197697758674622, Final Batch Loss: 0.7266923189163208\n",
      "Epoch 551, Loss: 4.510790288448334, Final Batch Loss: 1.0929235219955444\n",
      "Epoch 552, Loss: 4.157010734081268, Final Batch Loss: 0.7418366074562073\n",
      "Epoch 553, Loss: 4.4406105279922485, Final Batch Loss: 1.0078471899032593\n",
      "Epoch 554, Loss: 4.342767000198364, Final Batch Loss: 0.9603052735328674\n",
      "Epoch 555, Loss: 4.6250669956207275, Final Batch Loss: 1.2163974046707153\n",
      "Epoch 556, Loss: 4.491165995597839, Final Batch Loss: 1.1310694217681885\n",
      "Epoch 557, Loss: 4.264118194580078, Final Batch Loss: 0.7848054766654968\n",
      "Epoch 558, Loss: 4.082914590835571, Final Batch Loss: 0.6961289048194885\n",
      "Epoch 559, Loss: 4.434942841529846, Final Batch Loss: 1.0412226915359497\n",
      "Epoch 560, Loss: 3.968108594417572, Final Batch Loss: 0.6570754647254944\n",
      "Epoch 561, Loss: 4.43076890707016, Final Batch Loss: 1.0146857500076294\n",
      "Epoch 562, Loss: 4.196447014808655, Final Batch Loss: 0.8395842909812927\n",
      "Epoch 563, Loss: 4.296400606632233, Final Batch Loss: 0.8466466665267944\n",
      "Epoch 564, Loss: 4.074080765247345, Final Batch Loss: 0.8159967660903931\n",
      "Epoch 565, Loss: 4.15476131439209, Final Batch Loss: 0.8373274207115173\n",
      "Epoch 566, Loss: 4.135483980178833, Final Batch Loss: 0.6795142889022827\n",
      "Epoch 567, Loss: 4.00833398103714, Final Batch Loss: 0.5613462924957275\n",
      "Epoch 568, Loss: 4.245424151420593, Final Batch Loss: 0.8755022287368774\n",
      "Epoch 569, Loss: 4.329030156135559, Final Batch Loss: 1.039717435836792\n",
      "Epoch 570, Loss: 3.8327318131923676, Final Batch Loss: 0.47200122475624084\n",
      "Epoch 571, Loss: 3.9349039793014526, Final Batch Loss: 0.583856463432312\n",
      "Epoch 572, Loss: 4.353643119335175, Final Batch Loss: 0.9127596616744995\n",
      "Epoch 573, Loss: 4.12605494260788, Final Batch Loss: 0.7711149454116821\n",
      "Epoch 574, Loss: 4.265560567378998, Final Batch Loss: 0.9719452261924744\n",
      "Epoch 575, Loss: 3.8732880353927612, Final Batch Loss: 0.5706924200057983\n",
      "Epoch 576, Loss: 4.019753277301788, Final Batch Loss: 0.6986002922058105\n",
      "Epoch 577, Loss: 3.8914018273353577, Final Batch Loss: 0.6071139574050903\n",
      "Epoch 578, Loss: 4.1722100377082825, Final Batch Loss: 0.8948157429695129\n",
      "Epoch 579, Loss: 3.8744629621505737, Final Batch Loss: 0.595691978931427\n",
      "Epoch 580, Loss: 4.036616384983063, Final Batch Loss: 0.6987518072128296\n",
      "Epoch 581, Loss: 3.7632035613059998, Final Batch Loss: 0.46443939208984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 582, Loss: 4.385245263576508, Final Batch Loss: 0.8930073380470276\n",
      "Epoch 583, Loss: 4.1452584862709045, Final Batch Loss: 0.7287643551826477\n",
      "Epoch 584, Loss: 4.572543799877167, Final Batch Loss: 1.203540563583374\n",
      "Epoch 585, Loss: 4.443787932395935, Final Batch Loss: 1.1506694555282593\n",
      "Epoch 586, Loss: 4.185748040676117, Final Batch Loss: 0.7513657808303833\n",
      "Epoch 587, Loss: 3.9858701825141907, Final Batch Loss: 0.5897408723831177\n",
      "Epoch 588, Loss: 4.06921511888504, Final Batch Loss: 0.7516881227493286\n",
      "Epoch 589, Loss: 4.333373844623566, Final Batch Loss: 1.0322988033294678\n",
      "Epoch 590, Loss: 4.652604103088379, Final Batch Loss: 1.2417935132980347\n",
      "Epoch 591, Loss: 4.204196870326996, Final Batch Loss: 0.7356586456298828\n",
      "Epoch 592, Loss: 3.9159898161888123, Final Batch Loss: 0.5721367597579956\n",
      "Epoch 593, Loss: 4.116798937320709, Final Batch Loss: 0.7685213088989258\n",
      "Epoch 594, Loss: 4.045283198356628, Final Batch Loss: 0.8008231520652771\n",
      "Epoch 595, Loss: 4.123316526412964, Final Batch Loss: 0.8568480610847473\n",
      "Epoch 596, Loss: 3.946051836013794, Final Batch Loss: 0.7224848866462708\n",
      "Epoch 597, Loss: 4.1907477378845215, Final Batch Loss: 0.8414064645767212\n",
      "Epoch 598, Loss: 4.191571474075317, Final Batch Loss: 0.834218442440033\n",
      "Epoch 599, Loss: 3.9629935026168823, Final Batch Loss: 0.7219194173812866\n",
      "Epoch 600, Loss: 4.398842990398407, Final Batch Loss: 1.003033995628357\n",
      "Epoch 601, Loss: 3.92659854888916, Final Batch Loss: 0.769740104675293\n",
      "Epoch 602, Loss: 4.229219913482666, Final Batch Loss: 0.9059341549873352\n",
      "Epoch 603, Loss: 4.035323798656464, Final Batch Loss: 0.762150228023529\n",
      "Epoch 604, Loss: 3.9206289052963257, Final Batch Loss: 0.6895884275436401\n",
      "Epoch 605, Loss: 4.267026364803314, Final Batch Loss: 0.8805826902389526\n",
      "Epoch 606, Loss: 4.009961664676666, Final Batch Loss: 0.6626799702644348\n",
      "Epoch 607, Loss: 3.9176304936408997, Final Batch Loss: 0.6570903062820435\n",
      "Epoch 608, Loss: 3.871687173843384, Final Batch Loss: 0.6794632077217102\n",
      "Epoch 609, Loss: 4.240588307380676, Final Batch Loss: 0.8146476745605469\n",
      "Epoch 610, Loss: 4.4204108119010925, Final Batch Loss: 1.255103349685669\n",
      "Epoch 611, Loss: 4.093017518520355, Final Batch Loss: 0.7737864255905151\n",
      "Epoch 612, Loss: 4.541956961154938, Final Batch Loss: 1.297302484512329\n",
      "Epoch 613, Loss: 4.175530672073364, Final Batch Loss: 0.8705159425735474\n",
      "Epoch 614, Loss: 4.061943590641022, Final Batch Loss: 0.7628315091133118\n",
      "Epoch 615, Loss: 4.327285289764404, Final Batch Loss: 1.0180718898773193\n",
      "Epoch 616, Loss: 3.750837951898575, Final Batch Loss: 0.3681502044200897\n",
      "Epoch 617, Loss: 3.9997992515563965, Final Batch Loss: 0.7827461957931519\n",
      "Epoch 618, Loss: 3.5628081262111664, Final Batch Loss: 0.47341468930244446\n",
      "Epoch 619, Loss: 4.267430305480957, Final Batch Loss: 1.0672332048416138\n",
      "Epoch 620, Loss: 3.9688621163368225, Final Batch Loss: 0.7289384603500366\n",
      "Epoch 621, Loss: 4.492206454277039, Final Batch Loss: 1.2362679243087769\n",
      "Epoch 622, Loss: 3.8326709866523743, Final Batch Loss: 0.5770747065544128\n",
      "Epoch 623, Loss: 3.9212470650672913, Final Batch Loss: 0.8232231140136719\n",
      "Epoch 624, Loss: 4.0455323457717896, Final Batch Loss: 0.6017675399780273\n",
      "Epoch 625, Loss: 3.746362566947937, Final Batch Loss: 0.4468461871147156\n",
      "Epoch 626, Loss: 4.341308355331421, Final Batch Loss: 0.9928110837936401\n",
      "Epoch 627, Loss: 4.254964113235474, Final Batch Loss: 1.0427676439285278\n",
      "Epoch 628, Loss: 4.095119595527649, Final Batch Loss: 0.9252607226371765\n",
      "Epoch 629, Loss: 3.881207048892975, Final Batch Loss: 0.5287300944328308\n",
      "Epoch 630, Loss: 4.1550933718681335, Final Batch Loss: 0.9121178388595581\n",
      "Epoch 631, Loss: 4.165224611759186, Final Batch Loss: 0.8790256381034851\n",
      "Epoch 632, Loss: 4.244036793708801, Final Batch Loss: 1.1049458980560303\n",
      "Epoch 633, Loss: 3.727688819169998, Final Batch Loss: 0.4709584414958954\n",
      "Epoch 634, Loss: 4.021927893161774, Final Batch Loss: 0.7520237565040588\n",
      "Epoch 635, Loss: 4.1360719203948975, Final Batch Loss: 0.9526737332344055\n",
      "Epoch 636, Loss: 3.822455585002899, Final Batch Loss: 0.6944923996925354\n",
      "Epoch 637, Loss: 3.545012801885605, Final Batch Loss: 0.4067213833332062\n",
      "Epoch 638, Loss: 3.888699769973755, Final Batch Loss: 0.7416459918022156\n",
      "Epoch 639, Loss: 4.194318473339081, Final Batch Loss: 1.0147548913955688\n",
      "Epoch 640, Loss: 3.654546320438385, Final Batch Loss: 0.541662871837616\n",
      "Epoch 641, Loss: 3.852333724498749, Final Batch Loss: 0.6351483464241028\n",
      "Epoch 642, Loss: 4.012138605117798, Final Batch Loss: 0.8436509966850281\n",
      "Epoch 643, Loss: 4.038888096809387, Final Batch Loss: 0.9697853922843933\n",
      "Epoch 644, Loss: 3.9903905987739563, Final Batch Loss: 0.7305411100387573\n",
      "Epoch 645, Loss: 3.9407162070274353, Final Batch Loss: 0.7808718085289001\n",
      "Epoch 646, Loss: 3.9915027022361755, Final Batch Loss: 0.7186346650123596\n",
      "Epoch 647, Loss: 3.726869910955429, Final Batch Loss: 0.49246469140052795\n",
      "Epoch 648, Loss: 3.7484161257743835, Final Batch Loss: 0.5204038023948669\n",
      "Epoch 649, Loss: 3.898220956325531, Final Batch Loss: 0.7462247014045715\n",
      "Epoch 650, Loss: 3.6157987117767334, Final Batch Loss: 0.5250979065895081\n",
      "Epoch 651, Loss: 4.121371507644653, Final Batch Loss: 0.9709910750389099\n",
      "Epoch 652, Loss: 3.879475235939026, Final Batch Loss: 0.5802180171012878\n",
      "Epoch 653, Loss: 3.6792142391204834, Final Batch Loss: 0.6314214468002319\n",
      "Epoch 654, Loss: 3.5667601227760315, Final Batch Loss: 0.27744317054748535\n",
      "Epoch 655, Loss: 3.7876029014587402, Final Batch Loss: 0.6448198556900024\n",
      "Epoch 656, Loss: 4.294468283653259, Final Batch Loss: 1.3001699447631836\n",
      "Epoch 657, Loss: 4.029532074928284, Final Batch Loss: 0.912631630897522\n",
      "Epoch 658, Loss: 3.7933356165885925, Final Batch Loss: 0.49786949157714844\n",
      "Epoch 659, Loss: 3.876267731189728, Final Batch Loss: 0.7926434278488159\n",
      "Epoch 660, Loss: 3.719119071960449, Final Batch Loss: 0.6057882905006409\n",
      "Epoch 661, Loss: 3.6923856139183044, Final Batch Loss: 0.6333863139152527\n",
      "Epoch 662, Loss: 4.208524525165558, Final Batch Loss: 1.1204955577850342\n",
      "Epoch 663, Loss: 4.30563747882843, Final Batch Loss: 0.9634453058242798\n",
      "Epoch 664, Loss: 3.8535478711128235, Final Batch Loss: 0.683390200138092\n",
      "Epoch 665, Loss: 4.023574650287628, Final Batch Loss: 0.8587613701820374\n",
      "Epoch 666, Loss: 3.7172440886497498, Final Batch Loss: 0.5259900093078613\n",
      "Epoch 667, Loss: 3.7914668321609497, Final Batch Loss: 0.5149271488189697\n",
      "Epoch 668, Loss: 3.7799002528190613, Final Batch Loss: 0.5606132745742798\n",
      "Epoch 669, Loss: 3.8920891880989075, Final Batch Loss: 0.7115586400032043\n",
      "Epoch 670, Loss: 3.850628614425659, Final Batch Loss: 0.7461415529251099\n",
      "Epoch 671, Loss: 3.6470767855644226, Final Batch Loss: 0.5822282433509827\n",
      "Epoch 672, Loss: 4.33700293302536, Final Batch Loss: 1.1486483812332153\n",
      "Epoch 673, Loss: 3.9746870398521423, Final Batch Loss: 0.8824638724327087\n",
      "Epoch 674, Loss: 3.875692307949066, Final Batch Loss: 0.6923446655273438\n",
      "Epoch 675, Loss: 3.8841238021850586, Final Batch Loss: 0.779354989528656\n",
      "Epoch 676, Loss: 3.8735139966011047, Final Batch Loss: 0.8539453744888306\n",
      "Epoch 677, Loss: 3.6570888459682465, Final Batch Loss: 0.48390135169029236\n",
      "Epoch 678, Loss: 4.477913856506348, Final Batch Loss: 1.274580955505371\n",
      "Epoch 679, Loss: 3.65569144487381, Final Batch Loss: 0.634236752986908\n",
      "Epoch 680, Loss: 3.930033564567566, Final Batch Loss: 0.8675247430801392\n",
      "Epoch 681, Loss: 4.5426419377326965, Final Batch Loss: 1.375380516052246\n",
      "Epoch 682, Loss: 3.8265504837036133, Final Batch Loss: 0.8297128677368164\n",
      "Epoch 683, Loss: 3.806675970554352, Final Batch Loss: 0.61481773853302\n",
      "Epoch 684, Loss: 4.100394666194916, Final Batch Loss: 0.9389232397079468\n",
      "Epoch 685, Loss: 3.9340487122535706, Final Batch Loss: 0.786620020866394\n",
      "Epoch 686, Loss: 3.7746086716651917, Final Batch Loss: 0.6855010390281677\n",
      "Epoch 687, Loss: 3.771819055080414, Final Batch Loss: 0.741912841796875\n",
      "Epoch 688, Loss: 3.9340428709983826, Final Batch Loss: 0.8225973844528198\n",
      "Epoch 689, Loss: 3.437317967414856, Final Batch Loss: 0.3947065472602844\n",
      "Epoch 690, Loss: 3.828654646873474, Final Batch Loss: 0.7605204582214355\n",
      "Epoch 691, Loss: 3.8137750029563904, Final Batch Loss: 0.6825355291366577\n",
      "Epoch 692, Loss: 3.8377957344055176, Final Batch Loss: 0.8756262063980103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 693, Loss: 3.668268918991089, Final Batch Loss: 0.6130890250205994\n",
      "Epoch 694, Loss: 3.78283154964447, Final Batch Loss: 0.5960235595703125\n",
      "Epoch 695, Loss: 3.4443289935588837, Final Batch Loss: 0.4189692437648773\n",
      "Epoch 696, Loss: 4.14600282907486, Final Batch Loss: 1.132493019104004\n",
      "Epoch 697, Loss: 3.7296001315116882, Final Batch Loss: 0.741802990436554\n",
      "Epoch 698, Loss: 3.730657935142517, Final Batch Loss: 0.5773639678955078\n",
      "Epoch 699, Loss: 4.200086176395416, Final Batch Loss: 0.9638593792915344\n",
      "Epoch 700, Loss: 4.450598239898682, Final Batch Loss: 1.3436520099639893\n",
      "Epoch 701, Loss: 3.991232752799988, Final Batch Loss: 0.9044634699821472\n",
      "Epoch 702, Loss: 3.7196943759918213, Final Batch Loss: 0.6639606356620789\n",
      "Epoch 703, Loss: 3.745025396347046, Final Batch Loss: 0.6950076222419739\n",
      "Epoch 704, Loss: 4.3458132147789, Final Batch Loss: 1.1947144269943237\n",
      "Epoch 705, Loss: 4.185514986515045, Final Batch Loss: 1.1283148527145386\n",
      "Epoch 706, Loss: 3.7323689460754395, Final Batch Loss: 0.5091283917427063\n",
      "Epoch 707, Loss: 3.843723475933075, Final Batch Loss: 0.7481061816215515\n",
      "Epoch 708, Loss: 4.307243824005127, Final Batch Loss: 1.2934398651123047\n",
      "Epoch 709, Loss: 3.8165101408958435, Final Batch Loss: 0.5629198551177979\n",
      "Epoch 710, Loss: 4.306445956230164, Final Batch Loss: 1.3136523962020874\n",
      "Epoch 711, Loss: 3.518594652414322, Final Batch Loss: 0.4939134418964386\n",
      "Epoch 712, Loss: 3.7811098098754883, Final Batch Loss: 0.6632146835327148\n",
      "Epoch 713, Loss: 3.866463601589203, Final Batch Loss: 0.8301519155502319\n",
      "Epoch 714, Loss: 3.9559839963912964, Final Batch Loss: 0.8787593841552734\n",
      "Epoch 715, Loss: 3.763131320476532, Final Batch Loss: 0.6386107206344604\n",
      "Epoch 716, Loss: 4.0837483406066895, Final Batch Loss: 1.0875253677368164\n",
      "Epoch 717, Loss: 3.5400786995887756, Final Batch Loss: 0.494512140750885\n",
      "Epoch 718, Loss: 3.715959131717682, Final Batch Loss: 0.7386696934700012\n",
      "Epoch 719, Loss: 4.042325794696808, Final Batch Loss: 0.9363069534301758\n",
      "Epoch 720, Loss: 3.6853848695755005, Final Batch Loss: 0.6733933091163635\n",
      "Epoch 721, Loss: 3.7072585821151733, Final Batch Loss: 0.6171894073486328\n",
      "Epoch 722, Loss: 3.6936028599739075, Final Batch Loss: 0.6469893455505371\n",
      "Epoch 723, Loss: 4.0415162444114685, Final Batch Loss: 1.1023019552230835\n",
      "Epoch 724, Loss: 3.954048991203308, Final Batch Loss: 0.9549323916435242\n",
      "Epoch 725, Loss: 4.08038204908371, Final Batch Loss: 0.9822741746902466\n",
      "Epoch 726, Loss: 3.792996048927307, Final Batch Loss: 0.721928596496582\n",
      "Epoch 727, Loss: 3.6247546672821045, Final Batch Loss: 0.5107131004333496\n",
      "Epoch 728, Loss: 3.7702786326408386, Final Batch Loss: 0.6761040687561035\n",
      "Epoch 729, Loss: 3.44321608543396, Final Batch Loss: 0.4750993847846985\n",
      "Epoch 730, Loss: 3.9724209308624268, Final Batch Loss: 0.9186533689498901\n",
      "Epoch 731, Loss: 3.7629544138908386, Final Batch Loss: 0.8248482942581177\n",
      "Epoch 732, Loss: 3.881831705570221, Final Batch Loss: 0.9074620008468628\n",
      "Epoch 733, Loss: 3.688353180885315, Final Batch Loss: 0.6795153617858887\n",
      "Epoch 734, Loss: 3.674910068511963, Final Batch Loss: 0.5790234804153442\n",
      "Epoch 735, Loss: 3.549260288476944, Final Batch Loss: 0.3954666554927826\n",
      "Epoch 736, Loss: 3.878421366214752, Final Batch Loss: 0.8275666236877441\n",
      "Epoch 737, Loss: 4.1800084710121155, Final Batch Loss: 1.1925182342529297\n",
      "Epoch 738, Loss: 4.055382490158081, Final Batch Loss: 1.0032581090927124\n",
      "Epoch 739, Loss: 3.6333415508270264, Final Batch Loss: 0.6462975740432739\n",
      "Epoch 740, Loss: 3.805540680885315, Final Batch Loss: 0.5655612349510193\n",
      "Epoch 741, Loss: 4.167813837528229, Final Batch Loss: 1.1016508340835571\n",
      "Epoch 742, Loss: 3.729414641857147, Final Batch Loss: 0.6352525353431702\n",
      "Epoch 743, Loss: 3.4182674288749695, Final Batch Loss: 0.5428532958030701\n",
      "Epoch 744, Loss: 3.7815549969673157, Final Batch Loss: 0.7886847257614136\n",
      "Epoch 745, Loss: 3.9796425700187683, Final Batch Loss: 0.8288583755493164\n",
      "Epoch 746, Loss: 3.8745452165603638, Final Batch Loss: 1.0112087726593018\n",
      "Epoch 747, Loss: 3.9522206783294678, Final Batch Loss: 0.823573112487793\n",
      "Epoch 748, Loss: 4.110701262950897, Final Batch Loss: 0.9609108567237854\n",
      "Epoch 749, Loss: 3.9727500677108765, Final Batch Loss: 1.080487847328186\n",
      "Epoch 750, Loss: 3.9013107419013977, Final Batch Loss: 0.8322399258613586\n",
      "Epoch 751, Loss: 4.120603144168854, Final Batch Loss: 1.038492202758789\n",
      "Epoch 752, Loss: 3.8188246488571167, Final Batch Loss: 0.7678294777870178\n",
      "Epoch 753, Loss: 3.9560545682907104, Final Batch Loss: 0.8905997276306152\n",
      "Epoch 754, Loss: 4.147572934627533, Final Batch Loss: 1.0506799221038818\n",
      "Epoch 755, Loss: 3.4925296902656555, Final Batch Loss: 0.527645468711853\n",
      "Epoch 756, Loss: 3.4635481238365173, Final Batch Loss: 0.49622851610183716\n",
      "Epoch 757, Loss: 3.3948605954647064, Final Batch Loss: 0.40540167689323425\n",
      "Epoch 758, Loss: 3.612516224384308, Final Batch Loss: 0.7180392146110535\n",
      "Epoch 759, Loss: 3.5179356932640076, Final Batch Loss: 0.47858619689941406\n",
      "Epoch 760, Loss: 3.56449556350708, Final Batch Loss: 0.5751348733901978\n",
      "Epoch 761, Loss: 4.259591639041901, Final Batch Loss: 0.9999673962593079\n",
      "Epoch 762, Loss: 3.6887232065200806, Final Batch Loss: 0.7764795422554016\n",
      "Epoch 763, Loss: 3.6648932695388794, Final Batch Loss: 0.740651547908783\n",
      "Epoch 764, Loss: 3.8323919773101807, Final Batch Loss: 0.9177021384239197\n",
      "Epoch 765, Loss: 4.050692319869995, Final Batch Loss: 1.032876968383789\n",
      "Epoch 766, Loss: 3.6183465123176575, Final Batch Loss: 0.6536290049552917\n",
      "Epoch 767, Loss: 4.169679582118988, Final Batch Loss: 1.0881140232086182\n",
      "Epoch 768, Loss: 3.5775737166404724, Final Batch Loss: 0.5739601254463196\n",
      "Epoch 769, Loss: 3.7992875576019287, Final Batch Loss: 0.8994488716125488\n",
      "Epoch 770, Loss: 3.984276592731476, Final Batch Loss: 0.991132378578186\n",
      "Epoch 771, Loss: 3.416701853275299, Final Batch Loss: 0.4326311945915222\n",
      "Epoch 772, Loss: 3.761426568031311, Final Batch Loss: 0.7645224332809448\n",
      "Epoch 773, Loss: 3.7251381278038025, Final Batch Loss: 0.7340468764305115\n",
      "Epoch 774, Loss: 3.763611853122711, Final Batch Loss: 0.8871460556983948\n",
      "Epoch 775, Loss: 3.837498426437378, Final Batch Loss: 0.7438110709190369\n",
      "Epoch 776, Loss: 3.7344546914100647, Final Batch Loss: 0.6961822509765625\n",
      "Epoch 777, Loss: 3.5323809385299683, Final Batch Loss: 0.5190303325653076\n",
      "Epoch 778, Loss: 3.274039626121521, Final Batch Loss: 0.3432256579399109\n",
      "Epoch 779, Loss: 3.833513855934143, Final Batch Loss: 0.9883402585983276\n",
      "Epoch 780, Loss: 3.4879299998283386, Final Batch Loss: 0.5392414331436157\n",
      "Epoch 781, Loss: 3.668996751308441, Final Batch Loss: 0.5324161052703857\n",
      "Epoch 782, Loss: 3.742659628391266, Final Batch Loss: 0.777836799621582\n",
      "Epoch 783, Loss: 3.899999678134918, Final Batch Loss: 0.8936983346939087\n",
      "Epoch 784, Loss: 3.6796016097068787, Final Batch Loss: 0.7941437363624573\n",
      "Epoch 785, Loss: 3.9467998147010803, Final Batch Loss: 0.8687576055526733\n",
      "Epoch 786, Loss: 3.7244622111320496, Final Batch Loss: 0.882779598236084\n",
      "Epoch 787, Loss: 3.501013457775116, Final Batch Loss: 0.5156694650650024\n",
      "Epoch 788, Loss: 3.5192041993141174, Final Batch Loss: 0.637667179107666\n",
      "Epoch 789, Loss: 3.720591366291046, Final Batch Loss: 0.6520123481750488\n",
      "Epoch 790, Loss: 3.387019068002701, Final Batch Loss: 0.42183688282966614\n",
      "Epoch 791, Loss: 3.863915503025055, Final Batch Loss: 0.848969042301178\n",
      "Epoch 792, Loss: 3.681806266307831, Final Batch Loss: 0.7126413583755493\n",
      "Epoch 793, Loss: 3.3807945251464844, Final Batch Loss: 0.5311881303787231\n",
      "Epoch 794, Loss: 3.8317500352859497, Final Batch Loss: 0.6511048078536987\n",
      "Epoch 795, Loss: 3.690346658229828, Final Batch Loss: 0.6371715664863586\n",
      "Epoch 796, Loss: 4.16727751493454, Final Batch Loss: 1.171433448791504\n",
      "Epoch 797, Loss: 3.7205962538719177, Final Batch Loss: 0.5837612748146057\n",
      "Epoch 798, Loss: 3.516026020050049, Final Batch Loss: 0.5842987298965454\n",
      "Epoch 799, Loss: 3.301209658384323, Final Batch Loss: 0.2860986888408661\n",
      "Epoch 800, Loss: 3.4288004636764526, Final Batch Loss: 0.6088835000991821\n",
      "Epoch 801, Loss: 3.3937246799468994, Final Batch Loss: 0.5142262578010559\n",
      "Epoch 802, Loss: 3.6434967517852783, Final Batch Loss: 0.8114269971847534\n",
      "Epoch 803, Loss: 3.39865642786026, Final Batch Loss: 0.41185879707336426\n",
      "Epoch 804, Loss: 3.9789434671401978, Final Batch Loss: 1.0801212787628174\n",
      "Epoch 805, Loss: 3.681954860687256, Final Batch Loss: 0.7782703638076782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 806, Loss: 3.328952342271805, Final Batch Loss: 0.4653160870075226\n",
      "Epoch 807, Loss: 3.956421971321106, Final Batch Loss: 0.9649791717529297\n",
      "Epoch 808, Loss: 4.133729636669159, Final Batch Loss: 1.2842992544174194\n",
      "Epoch 809, Loss: 3.5217137336730957, Final Batch Loss: 0.7481050491333008\n",
      "Epoch 810, Loss: 3.6861727237701416, Final Batch Loss: 0.9432371258735657\n",
      "Epoch 811, Loss: 3.0838588178157806, Final Batch Loss: 0.21660277247428894\n",
      "Epoch 812, Loss: 3.717909812927246, Final Batch Loss: 0.8607949614524841\n",
      "Epoch 813, Loss: 3.4872357845306396, Final Batch Loss: 0.47565698623657227\n",
      "Epoch 814, Loss: 3.3691577911376953, Final Batch Loss: 0.4919036030769348\n",
      "Epoch 815, Loss: 3.4011518955230713, Final Batch Loss: 0.5355204343795776\n",
      "Epoch 816, Loss: 4.084299445152283, Final Batch Loss: 1.1542389392852783\n",
      "Epoch 817, Loss: 3.574577569961548, Final Batch Loss: 0.7374869585037231\n",
      "Epoch 818, Loss: 3.6272668838500977, Final Batch Loss: 0.756926417350769\n",
      "Epoch 819, Loss: 3.5991761088371277, Final Batch Loss: 0.7638689875602722\n",
      "Epoch 820, Loss: 3.311616450548172, Final Batch Loss: 0.48129329085350037\n",
      "Epoch 821, Loss: 3.7196361422538757, Final Batch Loss: 0.8499986529350281\n",
      "Epoch 822, Loss: 3.516983211040497, Final Batch Loss: 0.5959395170211792\n",
      "Epoch 823, Loss: 3.9924399852752686, Final Batch Loss: 1.1618069410324097\n",
      "Epoch 824, Loss: 3.549384832382202, Final Batch Loss: 0.6518232226371765\n",
      "Epoch 825, Loss: 3.974310338497162, Final Batch Loss: 1.1863383054733276\n",
      "Epoch 826, Loss: 3.793886363506317, Final Batch Loss: 0.7063249349594116\n",
      "Epoch 827, Loss: 3.5278998017311096, Final Batch Loss: 0.5909029841423035\n",
      "Epoch 828, Loss: 3.8058929443359375, Final Batch Loss: 0.7794082760810852\n",
      "Epoch 829, Loss: 3.329930394887924, Final Batch Loss: 0.4013310968875885\n",
      "Epoch 830, Loss: 4.20205157995224, Final Batch Loss: 1.2716519832611084\n",
      "Epoch 831, Loss: 3.866232216358185, Final Batch Loss: 0.8766636252403259\n",
      "Epoch 832, Loss: 3.470766931772232, Final Batch Loss: 0.46862950921058655\n",
      "Epoch 833, Loss: 3.8165706396102905, Final Batch Loss: 0.9224683046340942\n",
      "Epoch 834, Loss: 3.96629798412323, Final Batch Loss: 1.0439972877502441\n",
      "Epoch 835, Loss: 3.3384673595428467, Final Batch Loss: 0.45289403200149536\n",
      "Epoch 836, Loss: 3.960068702697754, Final Batch Loss: 1.0455825328826904\n",
      "Epoch 837, Loss: 3.4523287415504456, Final Batch Loss: 0.5516101717948914\n",
      "Epoch 838, Loss: 3.319546341896057, Final Batch Loss: 0.5272794365882874\n",
      "Epoch 839, Loss: 3.1729243099689484, Final Batch Loss: 0.36738982796669006\n",
      "Epoch 840, Loss: 3.3727440237998962, Final Batch Loss: 0.48911476135253906\n",
      "Epoch 841, Loss: 3.6570961475372314, Final Batch Loss: 0.6549647450447083\n",
      "Epoch 842, Loss: 3.8049387335777283, Final Batch Loss: 0.8660783171653748\n",
      "Epoch 843, Loss: 3.656132757663727, Final Batch Loss: 0.7964825630187988\n",
      "Epoch 844, Loss: 3.70452618598938, Final Batch Loss: 0.9382650256156921\n",
      "Epoch 845, Loss: 3.5001637935638428, Final Batch Loss: 0.5553199648857117\n",
      "Epoch 846, Loss: 3.7009833455085754, Final Batch Loss: 0.7341526746749878\n",
      "Epoch 847, Loss: 3.7756741046905518, Final Batch Loss: 0.9396470189094543\n",
      "Epoch 848, Loss: 3.371589243412018, Final Batch Loss: 0.6039117574691772\n",
      "Epoch 849, Loss: 3.735261380672455, Final Batch Loss: 0.7780834436416626\n",
      "Epoch 850, Loss: 3.6538766026496887, Final Batch Loss: 0.6673408150672913\n",
      "Epoch 851, Loss: 3.726346492767334, Final Batch Loss: 0.9448822736740112\n",
      "Epoch 852, Loss: 3.577744960784912, Final Batch Loss: 0.8929892182350159\n",
      "Epoch 853, Loss: 3.817740797996521, Final Batch Loss: 1.0208708047866821\n",
      "Epoch 854, Loss: 3.6431065797805786, Final Batch Loss: 0.7942708730697632\n",
      "Epoch 855, Loss: 3.349311739206314, Final Batch Loss: 0.43639835715293884\n",
      "Epoch 856, Loss: 3.5483967661857605, Final Batch Loss: 0.7131140828132629\n",
      "Epoch 857, Loss: 3.656684398651123, Final Batch Loss: 0.9001728892326355\n",
      "Epoch 858, Loss: 3.413184314966202, Final Batch Loss: 0.48420920968055725\n",
      "Epoch 859, Loss: 3.6907154321670532, Final Batch Loss: 0.9141831994056702\n",
      "Epoch 860, Loss: 3.725333094596863, Final Batch Loss: 0.9200237989425659\n",
      "Epoch 861, Loss: 3.4776017665863037, Final Batch Loss: 0.5967119932174683\n",
      "Epoch 862, Loss: 3.923806846141815, Final Batch Loss: 0.8858078718185425\n",
      "Epoch 863, Loss: 3.7641642689704895, Final Batch Loss: 0.785273551940918\n",
      "Epoch 864, Loss: 3.8997263312339783, Final Batch Loss: 1.1571969985961914\n",
      "Epoch 865, Loss: 3.40342915058136, Final Batch Loss: 0.6373844146728516\n",
      "Epoch 866, Loss: 3.488287627696991, Final Batch Loss: 0.5294556021690369\n",
      "Epoch 867, Loss: 3.656980812549591, Final Batch Loss: 0.8476175665855408\n",
      "Epoch 868, Loss: 3.846066415309906, Final Batch Loss: 0.867615282535553\n",
      "Epoch 869, Loss: 3.495231032371521, Final Batch Loss: 0.7138851881027222\n",
      "Epoch 870, Loss: 4.028823971748352, Final Batch Loss: 1.1170352697372437\n",
      "Epoch 871, Loss: 3.9401382207870483, Final Batch Loss: 0.9909110069274902\n",
      "Epoch 872, Loss: 3.5418185591697693, Final Batch Loss: 0.9170699715614319\n",
      "Epoch 873, Loss: 3.543764293193817, Final Batch Loss: 0.6053677201271057\n",
      "Epoch 874, Loss: 3.563599944114685, Final Batch Loss: 0.7224846482276917\n",
      "Epoch 875, Loss: 3.668134868144989, Final Batch Loss: 0.8725148439407349\n",
      "Epoch 876, Loss: 3.4410675764083862, Final Batch Loss: 0.5391417145729065\n",
      "Epoch 877, Loss: 3.828982174396515, Final Batch Loss: 0.9421269297599792\n",
      "Epoch 878, Loss: 3.9404227137565613, Final Batch Loss: 1.2292689085006714\n",
      "Epoch 879, Loss: 3.4485753774642944, Final Batch Loss: 0.6578990817070007\n",
      "Epoch 880, Loss: 3.468516767024994, Final Batch Loss: 0.5291649103164673\n",
      "Epoch 881, Loss: 3.6666305661201477, Final Batch Loss: 0.9338244199752808\n",
      "Epoch 882, Loss: 3.3744241297245026, Final Batch Loss: 0.4691101014614105\n",
      "Epoch 883, Loss: 3.305984914302826, Final Batch Loss: 0.5543183088302612\n",
      "Epoch 884, Loss: 3.7304123640060425, Final Batch Loss: 0.9400705695152283\n",
      "Epoch 885, Loss: 3.723750591278076, Final Batch Loss: 0.8654484748840332\n",
      "Epoch 886, Loss: 3.8368908166885376, Final Batch Loss: 1.057424783706665\n",
      "Epoch 887, Loss: 3.506160616874695, Final Batch Loss: 0.5614579319953918\n",
      "Epoch 888, Loss: 3.9843910336494446, Final Batch Loss: 1.1359188556671143\n",
      "Epoch 889, Loss: 3.993466079235077, Final Batch Loss: 1.1816993951797485\n",
      "Epoch 890, Loss: 3.2945675551891327, Final Batch Loss: 0.42241284251213074\n",
      "Epoch 891, Loss: 3.7986677289009094, Final Batch Loss: 0.8572657704353333\n",
      "Epoch 892, Loss: 3.4349777698516846, Final Batch Loss: 0.5430838465690613\n",
      "Epoch 893, Loss: 3.5079620480537415, Final Batch Loss: 0.6830692291259766\n",
      "Epoch 894, Loss: 3.4848142862319946, Final Batch Loss: 0.5346664190292358\n",
      "Epoch 895, Loss: 3.3290324807167053, Final Batch Loss: 0.48090511560440063\n",
      "Epoch 896, Loss: 3.7167429327964783, Final Batch Loss: 0.89997398853302\n",
      "Epoch 897, Loss: 3.2632865607738495, Final Batch Loss: 0.4663620889186859\n",
      "Epoch 898, Loss: 3.531463921070099, Final Batch Loss: 0.6406556963920593\n",
      "Epoch 899, Loss: 3.6252973079681396, Final Batch Loss: 0.8397523760795593\n",
      "Epoch 900, Loss: 3.216378003358841, Final Batch Loss: 0.47290512919425964\n",
      "Epoch 901, Loss: 3.8599225878715515, Final Batch Loss: 1.1495330333709717\n",
      "Epoch 902, Loss: 3.478035807609558, Final Batch Loss: 0.6060662865638733\n",
      "Epoch 903, Loss: 3.531018912792206, Final Batch Loss: 0.7691687941551208\n",
      "Epoch 904, Loss: 3.420992374420166, Final Batch Loss: 0.665179431438446\n",
      "Epoch 905, Loss: 3.740552306175232, Final Batch Loss: 0.9216786026954651\n",
      "Epoch 906, Loss: 2.9791706055402756, Final Batch Loss: 0.23137865960597992\n",
      "Epoch 907, Loss: 3.6871913075447083, Final Batch Loss: 0.8697201013565063\n",
      "Epoch 908, Loss: 3.1983735859394073, Final Batch Loss: 0.4074196517467499\n",
      "Epoch 909, Loss: 3.4837061762809753, Final Batch Loss: 0.723988950252533\n",
      "Epoch 910, Loss: 4.153851211071014, Final Batch Loss: 1.3117648363113403\n",
      "Epoch 911, Loss: 3.4669408202171326, Final Batch Loss: 0.6853727102279663\n",
      "Epoch 912, Loss: 3.5610560178756714, Final Batch Loss: 0.6484489440917969\n",
      "Epoch 913, Loss: 3.3422513902187347, Final Batch Loss: 0.46658024191856384\n",
      "Epoch 914, Loss: 4.031193673610687, Final Batch Loss: 1.2479944229125977\n",
      "Epoch 915, Loss: 3.485211193561554, Final Batch Loss: 0.6293836236000061\n",
      "Epoch 916, Loss: 3.704750895500183, Final Batch Loss: 1.0217769145965576\n",
      "Epoch 917, Loss: 3.659188389778137, Final Batch Loss: 0.9078852534294128\n",
      "Epoch 918, Loss: 3.4383370876312256, Final Batch Loss: 0.5418660640716553\n",
      "Epoch 919, Loss: 3.9637826085090637, Final Batch Loss: 1.0802347660064697\n",
      "Epoch 920, Loss: 3.686766743659973, Final Batch Loss: 0.8581178784370422\n",
      "Epoch 921, Loss: 3.430639147758484, Final Batch Loss: 0.662693977355957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922, Loss: 3.3369327187538147, Final Batch Loss: 0.5228896737098694\n",
      "Epoch 923, Loss: 3.2401561737060547, Final Batch Loss: 0.454509437084198\n",
      "Epoch 924, Loss: 3.4907912611961365, Final Batch Loss: 0.6882466673851013\n",
      "Epoch 925, Loss: 3.344448983669281, Final Batch Loss: 0.449431836605072\n",
      "Epoch 926, Loss: 3.3415589332580566, Final Batch Loss: 0.6798785924911499\n",
      "Epoch 927, Loss: 3.353379547595978, Final Batch Loss: 0.599650502204895\n",
      "Epoch 928, Loss: 3.5310229659080505, Final Batch Loss: 0.7658659219741821\n",
      "Epoch 929, Loss: 3.5056914687156677, Final Batch Loss: 0.8486666083335876\n",
      "Epoch 930, Loss: 3.35542094707489, Final Batch Loss: 0.5378090143203735\n",
      "Epoch 931, Loss: 3.4114118814468384, Final Batch Loss: 0.7358198165893555\n",
      "Epoch 932, Loss: 3.166831910610199, Final Batch Loss: 0.4374515414237976\n",
      "Epoch 933, Loss: 3.343546986579895, Final Batch Loss: 0.5486915111541748\n",
      "Epoch 934, Loss: 3.5544122457504272, Final Batch Loss: 0.8174822926521301\n",
      "Epoch 935, Loss: 3.2424024641513824, Final Batch Loss: 0.4584924280643463\n",
      "Epoch 936, Loss: 3.7269774675369263, Final Batch Loss: 0.965760350227356\n",
      "Epoch 937, Loss: 3.4399895668029785, Final Batch Loss: 0.7767627835273743\n",
      "Epoch 938, Loss: 3.0984259247779846, Final Batch Loss: 0.347636878490448\n",
      "Epoch 939, Loss: 3.2184427678585052, Final Batch Loss: 0.37276890873908997\n",
      "Epoch 940, Loss: 3.386429727077484, Final Batch Loss: 0.6203945279121399\n",
      "Epoch 941, Loss: 3.2978057265281677, Final Batch Loss: 0.7008677124977112\n",
      "Epoch 942, Loss: 3.526004433631897, Final Batch Loss: 0.9032103419303894\n",
      "Epoch 943, Loss: 3.3855385184288025, Final Batch Loss: 0.575214684009552\n",
      "Epoch 944, Loss: 3.4358274340629578, Final Batch Loss: 0.7103978395462036\n",
      "Epoch 945, Loss: 3.5566383004188538, Final Batch Loss: 0.711994469165802\n",
      "Epoch 946, Loss: 3.1731806695461273, Final Batch Loss: 0.39832422137260437\n",
      "Epoch 947, Loss: 3.178526997566223, Final Batch Loss: 0.40643197298049927\n",
      "Epoch 948, Loss: 3.340686619281769, Final Batch Loss: 0.5786987543106079\n",
      "Epoch 949, Loss: 3.3084275126457214, Final Batch Loss: 0.6041597723960876\n",
      "Epoch 950, Loss: 3.289169520139694, Final Batch Loss: 0.45708903670310974\n",
      "Epoch 951, Loss: 3.7704187631607056, Final Batch Loss: 1.0027153491973877\n",
      "Epoch 952, Loss: 3.1585053205490112, Final Batch Loss: 0.5204886794090271\n",
      "Epoch 953, Loss: 3.209869384765625, Final Batch Loss: 0.5038527846336365\n",
      "Epoch 954, Loss: 3.1707634925842285, Final Batch Loss: 0.523004949092865\n",
      "Epoch 955, Loss: 3.1316537857055664, Final Batch Loss: 0.39461714029312134\n",
      "Epoch 956, Loss: 3.167666405439377, Final Batch Loss: 0.41318175196647644\n",
      "Epoch 957, Loss: 3.235337555408478, Final Batch Loss: 0.5693687796592712\n",
      "Epoch 958, Loss: 3.2933125495910645, Final Batch Loss: 0.6488205194473267\n",
      "Epoch 959, Loss: 3.517767310142517, Final Batch Loss: 0.8791760206222534\n",
      "Epoch 960, Loss: 3.305374324321747, Final Batch Loss: 0.6501307487487793\n",
      "Epoch 961, Loss: 3.4123706221580505, Final Batch Loss: 0.6878195405006409\n",
      "Epoch 962, Loss: 3.4871020913124084, Final Batch Loss: 0.6120227575302124\n",
      "Epoch 963, Loss: 3.2070432603359222, Final Batch Loss: 0.47542604804039\n",
      "Epoch 964, Loss: 3.3943857550621033, Final Batch Loss: 0.5553565621376038\n",
      "Epoch 965, Loss: 3.2038731575012207, Final Batch Loss: 0.5565887689590454\n",
      "Epoch 966, Loss: 3.3957300782203674, Final Batch Loss: 0.6974810361862183\n",
      "Epoch 967, Loss: 3.553244173526764, Final Batch Loss: 0.9359132051467896\n",
      "Epoch 968, Loss: 3.370655834674835, Final Batch Loss: 0.7215628623962402\n",
      "Epoch 969, Loss: 3.553536593914032, Final Batch Loss: 0.7184780836105347\n",
      "Epoch 970, Loss: 3.2111184298992157, Final Batch Loss: 0.4843437969684601\n",
      "Epoch 971, Loss: 3.5090582966804504, Final Batch Loss: 0.7504264116287231\n",
      "Epoch 972, Loss: 3.2391271591186523, Final Batch Loss: 0.6397104859352112\n",
      "Epoch 973, Loss: 3.257678210735321, Final Batch Loss: 0.5837377309799194\n",
      "Epoch 974, Loss: 3.2323997616767883, Final Batch Loss: 0.5733968019485474\n",
      "Epoch 975, Loss: 3.516554057598114, Final Batch Loss: 0.770534873008728\n",
      "Epoch 976, Loss: 3.0368846654891968, Final Batch Loss: 0.4500473141670227\n",
      "Epoch 977, Loss: 3.283479869365692, Final Batch Loss: 0.43433189392089844\n",
      "Epoch 978, Loss: 3.835120439529419, Final Batch Loss: 1.0487273931503296\n",
      "Epoch 979, Loss: 3.1766397356987, Final Batch Loss: 0.4624996781349182\n",
      "Epoch 980, Loss: 3.2592429518699646, Final Batch Loss: 0.5214301943778992\n",
      "Epoch 981, Loss: 3.125889629125595, Final Batch Loss: 0.30006900429725647\n",
      "Epoch 982, Loss: 3.235341727733612, Final Batch Loss: 0.5449010729789734\n",
      "Epoch 983, Loss: 3.7237138748168945, Final Batch Loss: 0.986688494682312\n",
      "Epoch 984, Loss: 3.337155282497406, Final Batch Loss: 0.6778087615966797\n",
      "Epoch 985, Loss: 3.4175989627838135, Final Batch Loss: 0.7591190934181213\n",
      "Epoch 986, Loss: 3.095074623823166, Final Batch Loss: 0.45650145411491394\n",
      "Epoch 987, Loss: 3.431224226951599, Final Batch Loss: 0.6502875089645386\n",
      "Epoch 988, Loss: 4.176061034202576, Final Batch Loss: 1.322501540184021\n",
      "Epoch 989, Loss: 3.3671645522117615, Final Batch Loss: 0.6326256990432739\n",
      "Epoch 990, Loss: 3.4418511986732483, Final Batch Loss: 0.6363581418991089\n",
      "Epoch 991, Loss: 3.321939170360565, Final Batch Loss: 0.667065441608429\n",
      "Epoch 992, Loss: 3.086017906665802, Final Batch Loss: 0.3547214865684509\n",
      "Epoch 993, Loss: 3.2957684993743896, Final Batch Loss: 0.5739893317222595\n",
      "Epoch 994, Loss: 3.1780894994735718, Final Batch Loss: 0.6693245768547058\n",
      "Epoch 995, Loss: 3.119016945362091, Final Batch Loss: 0.473560631275177\n",
      "Epoch 996, Loss: 3.2206100821495056, Final Batch Loss: 0.6910380721092224\n",
      "Epoch 997, Loss: 3.032956302165985, Final Batch Loss: 0.43515586853027344\n",
      "Epoch 998, Loss: 3.357477366924286, Final Batch Loss: 0.6108769774436951\n",
      "Epoch 999, Loss: 3.5014349222183228, Final Batch Loss: 0.9006007313728333\n",
      "Epoch 1000, Loss: 3.343210518360138, Final Batch Loss: 0.7302729487419128\n",
      "Epoch 1001, Loss: 3.6074872612953186, Final Batch Loss: 0.9493151307106018\n",
      "Epoch 1002, Loss: 3.472898840904236, Final Batch Loss: 0.815836489200592\n",
      "Epoch 1003, Loss: 3.1414393186569214, Final Batch Loss: 0.490356981754303\n",
      "Epoch 1004, Loss: 3.373365342617035, Final Batch Loss: 0.5719038844108582\n",
      "Epoch 1005, Loss: 3.3084582090377808, Final Batch Loss: 0.5711013674736023\n",
      "Epoch 1006, Loss: 3.396746814250946, Final Batch Loss: 0.5936570763587952\n",
      "Epoch 1007, Loss: 3.5372962951660156, Final Batch Loss: 0.7410392761230469\n",
      "Epoch 1008, Loss: 2.905963808298111, Final Batch Loss: 0.24372181296348572\n",
      "Epoch 1009, Loss: 3.360013246536255, Final Batch Loss: 0.7846391797065735\n",
      "Epoch 1010, Loss: 3.4355016946792603, Final Batch Loss: 0.7064736485481262\n",
      "Epoch 1011, Loss: 2.9157536327838898, Final Batch Loss: 0.34837743639945984\n",
      "Epoch 1012, Loss: 3.1252830624580383, Final Batch Loss: 0.5243334174156189\n",
      "Epoch 1013, Loss: 3.47855007648468, Final Batch Loss: 0.9519067406654358\n",
      "Epoch 1014, Loss: 3.3609123826026917, Final Batch Loss: 0.7299718856811523\n",
      "Epoch 1015, Loss: 3.7125916481018066, Final Batch Loss: 1.0916931629180908\n",
      "Epoch 1016, Loss: 3.151428699493408, Final Batch Loss: 0.5330852270126343\n",
      "Epoch 1017, Loss: 3.776876389980316, Final Batch Loss: 1.0506190061569214\n",
      "Epoch 1018, Loss: 2.95964378118515, Final Batch Loss: 0.4104434847831726\n",
      "Epoch 1019, Loss: 3.6860286593437195, Final Batch Loss: 1.0058823823928833\n",
      "Epoch 1020, Loss: 3.467366099357605, Final Batch Loss: 0.776835024356842\n",
      "Epoch 1021, Loss: 3.5601691603660583, Final Batch Loss: 0.7907429933547974\n",
      "Epoch 1022, Loss: 3.3385373950004578, Final Batch Loss: 0.6664243936538696\n",
      "Epoch 1023, Loss: 3.1656518280506134, Final Batch Loss: 0.44281241297721863\n",
      "Epoch 1024, Loss: 3.078795164823532, Final Batch Loss: 0.4058491289615631\n",
      "Epoch 1025, Loss: 3.154359817504883, Final Batch Loss: 0.5585327744483948\n",
      "Epoch 1026, Loss: 3.471209764480591, Final Batch Loss: 0.8982322812080383\n",
      "Epoch 1027, Loss: 3.2393605709075928, Final Batch Loss: 0.6476747393608093\n",
      "Epoch 1028, Loss: 3.4189752340316772, Final Batch Loss: 0.6910879015922546\n",
      "Epoch 1029, Loss: 4.019630014896393, Final Batch Loss: 1.3945300579071045\n",
      "Epoch 1030, Loss: 3.2067139744758606, Final Batch Loss: 0.566010594367981\n",
      "Epoch 1031, Loss: 4.0441431403160095, Final Batch Loss: 1.1699150800704956\n",
      "Epoch 1032, Loss: 3.325055718421936, Final Batch Loss: 0.7578697204589844\n",
      "Epoch 1033, Loss: 3.082468032836914, Final Batch Loss: 0.4727630615234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1034, Loss: 3.234771966934204, Final Batch Loss: 0.5721049904823303\n",
      "Epoch 1035, Loss: 3.3613521456718445, Final Batch Loss: 0.7933138012886047\n",
      "Epoch 1036, Loss: 3.036580592393875, Final Batch Loss: 0.37439629435539246\n",
      "Epoch 1037, Loss: 3.2390254139900208, Final Batch Loss: 0.5817767381668091\n",
      "Epoch 1038, Loss: 3.634249687194824, Final Batch Loss: 1.0711264610290527\n",
      "Epoch 1039, Loss: 3.1439075767993927, Final Batch Loss: 0.4400184452533722\n",
      "Epoch 1040, Loss: 3.356740713119507, Final Batch Loss: 0.6905241012573242\n",
      "Epoch 1041, Loss: 3.304439127445221, Final Batch Loss: 0.7308392524719238\n",
      "Epoch 1042, Loss: 3.1820746660232544, Final Batch Loss: 0.5338428616523743\n",
      "Epoch 1043, Loss: 3.006591796875, Final Batch Loss: 0.4195532202720642\n",
      "Epoch 1044, Loss: 3.476635158061981, Final Batch Loss: 0.8811548948287964\n",
      "Epoch 1045, Loss: 2.9629963636398315, Final Batch Loss: 0.4496609568595886\n",
      "Epoch 1046, Loss: 3.065081238746643, Final Batch Loss: 0.525098443031311\n",
      "Epoch 1047, Loss: 3.384322464466095, Final Batch Loss: 0.7771271467208862\n",
      "Epoch 1048, Loss: 3.3995315432548523, Final Batch Loss: 0.6982524991035461\n",
      "Epoch 1049, Loss: 3.2222520112991333, Final Batch Loss: 0.620418906211853\n",
      "Epoch 1050, Loss: 3.2406628131866455, Final Batch Loss: 0.5604684948921204\n",
      "Epoch 1051, Loss: 3.1671175956726074, Final Batch Loss: 0.5630297660827637\n",
      "Epoch 1052, Loss: 3.5099751949310303, Final Batch Loss: 0.8758329153060913\n",
      "Epoch 1053, Loss: 3.195737212896347, Final Batch Loss: 0.4323326647281647\n",
      "Epoch 1054, Loss: 3.3043201565742493, Final Batch Loss: 0.6423174142837524\n",
      "Epoch 1055, Loss: 3.7983409762382507, Final Batch Loss: 1.252103567123413\n",
      "Epoch 1056, Loss: 3.4558175802230835, Final Batch Loss: 0.8527101874351501\n",
      "Epoch 1057, Loss: 2.9357244968414307, Final Batch Loss: 0.274130642414093\n",
      "Epoch 1058, Loss: 3.4815805554389954, Final Batch Loss: 0.7039275765419006\n",
      "Epoch 1059, Loss: 3.3144126534461975, Final Batch Loss: 0.6860084533691406\n",
      "Epoch 1060, Loss: 3.2537795901298523, Final Batch Loss: 0.6434437036514282\n",
      "Epoch 1061, Loss: 3.265477418899536, Final Batch Loss: 0.6708757281303406\n",
      "Epoch 1062, Loss: 3.883159041404724, Final Batch Loss: 1.2961350679397583\n",
      "Epoch 1063, Loss: 3.447768449783325, Final Batch Loss: 0.7513545751571655\n",
      "Epoch 1064, Loss: 3.1974107325077057, Final Batch Loss: 0.4577436149120331\n",
      "Epoch 1065, Loss: 3.151307851076126, Final Batch Loss: 0.498200386762619\n",
      "Epoch 1066, Loss: 3.6997048258781433, Final Batch Loss: 1.076207160949707\n",
      "Epoch 1067, Loss: 3.4082773327827454, Final Batch Loss: 0.79217129945755\n",
      "Epoch 1068, Loss: 3.4980356693267822, Final Batch Loss: 0.7017277479171753\n",
      "Epoch 1069, Loss: 3.3651397228240967, Final Batch Loss: 0.5601935982704163\n",
      "Epoch 1070, Loss: 3.7196248173713684, Final Batch Loss: 1.0366398096084595\n",
      "Epoch 1071, Loss: 3.618511378765106, Final Batch Loss: 0.966091513633728\n",
      "Epoch 1072, Loss: 3.4200202226638794, Final Batch Loss: 0.7605059742927551\n",
      "Epoch 1073, Loss: 3.150904417037964, Final Batch Loss: 0.4676676392555237\n",
      "Epoch 1074, Loss: 3.8381239771842957, Final Batch Loss: 1.2118587493896484\n",
      "Epoch 1075, Loss: 3.2743574380874634, Final Batch Loss: 0.657820999622345\n",
      "Epoch 1076, Loss: 3.343032479286194, Final Batch Loss: 0.757034420967102\n",
      "Epoch 1077, Loss: 3.206670880317688, Final Batch Loss: 0.6194566488265991\n",
      "Epoch 1078, Loss: 3.559529185295105, Final Batch Loss: 0.9353330731391907\n",
      "Epoch 1079, Loss: 2.9306122958660126, Final Batch Loss: 0.4262009561061859\n",
      "Epoch 1080, Loss: 3.3191924691200256, Final Batch Loss: 0.6793466210365295\n",
      "Epoch 1081, Loss: 2.9992836117744446, Final Batch Loss: 0.3859557509422302\n",
      "Epoch 1082, Loss: 3.570116102695465, Final Batch Loss: 0.9611836671829224\n",
      "Epoch 1083, Loss: 3.297918200492859, Final Batch Loss: 0.7642355561256409\n",
      "Epoch 1084, Loss: 3.4404104351997375, Final Batch Loss: 0.720873236656189\n",
      "Epoch 1085, Loss: 3.28496778011322, Final Batch Loss: 0.713560938835144\n",
      "Epoch 1086, Loss: 3.1812291741371155, Final Batch Loss: 0.7029703259468079\n",
      "Epoch 1087, Loss: 3.07463675737381, Final Batch Loss: 0.5796577334403992\n",
      "Epoch 1088, Loss: 3.483627736568451, Final Batch Loss: 0.8915494084358215\n",
      "Epoch 1089, Loss: 3.366810977458954, Final Batch Loss: 0.6146844625473022\n",
      "Epoch 1090, Loss: 3.0107552111148834, Final Batch Loss: 0.3719525635242462\n",
      "Epoch 1091, Loss: 3.2406612038612366, Final Batch Loss: 0.7858189940452576\n",
      "Epoch 1092, Loss: 3.1205632090568542, Final Batch Loss: 0.5782193541526794\n",
      "Epoch 1093, Loss: 3.3326104283332825, Final Batch Loss: 0.6311363577842712\n",
      "Epoch 1094, Loss: 3.1452596187591553, Final Batch Loss: 0.682742178440094\n",
      "Epoch 1095, Loss: 3.063651740550995, Final Batch Loss: 0.41210418939590454\n",
      "Epoch 1096, Loss: 3.027877300977707, Final Batch Loss: 0.6825599074363708\n",
      "Epoch 1097, Loss: 3.0968855023384094, Final Batch Loss: 0.5911207795143127\n",
      "Epoch 1098, Loss: 3.065354973077774, Final Batch Loss: 0.45466938614845276\n",
      "Epoch 1099, Loss: 2.8056480884552, Final Batch Loss: 0.30624157190322876\n",
      "Epoch 1100, Loss: 3.34785532951355, Final Batch Loss: 0.7799201011657715\n",
      "Epoch 1101, Loss: 3.3919647336006165, Final Batch Loss: 0.7252004742622375\n",
      "Epoch 1102, Loss: 3.3463931679725647, Final Batch Loss: 0.7486492991447449\n",
      "Epoch 1103, Loss: 3.1838517785072327, Final Batch Loss: 0.7132753729820251\n",
      "Epoch 1104, Loss: 3.002960741519928, Final Batch Loss: 0.5904502868652344\n",
      "Epoch 1105, Loss: 3.287174880504608, Final Batch Loss: 0.626059889793396\n",
      "Epoch 1106, Loss: 3.3503963351249695, Final Batch Loss: 0.9169396162033081\n",
      "Epoch 1107, Loss: 3.123626470565796, Final Batch Loss: 0.5140116214752197\n",
      "Epoch 1108, Loss: 2.8096426725387573, Final Batch Loss: 0.29532891511917114\n",
      "Epoch 1109, Loss: 3.2978292107582092, Final Batch Loss: 0.8062284588813782\n",
      "Epoch 1110, Loss: 2.997515082359314, Final Batch Loss: 0.516372561454773\n",
      "Epoch 1111, Loss: 3.0827571153640747, Final Batch Loss: 0.5295485258102417\n",
      "Epoch 1112, Loss: 3.1144636273384094, Final Batch Loss: 0.519267201423645\n",
      "Epoch 1113, Loss: 3.318449914455414, Final Batch Loss: 0.7954216599464417\n",
      "Epoch 1114, Loss: 3.0948124527931213, Final Batch Loss: 0.5538296699523926\n",
      "Epoch 1115, Loss: 3.4603800773620605, Final Batch Loss: 0.7738247513771057\n",
      "Epoch 1116, Loss: 3.9214418530464172, Final Batch Loss: 1.495592474937439\n",
      "Epoch 1117, Loss: 3.200941264629364, Final Batch Loss: 0.5389060378074646\n",
      "Epoch 1118, Loss: 3.667905807495117, Final Batch Loss: 1.0838825702667236\n",
      "Epoch 1119, Loss: 3.250649154186249, Final Batch Loss: 0.5219377875328064\n",
      "Epoch 1120, Loss: 3.4019368290901184, Final Batch Loss: 0.6237421631813049\n",
      "Epoch 1121, Loss: 3.272712767124176, Final Batch Loss: 0.7083835005760193\n",
      "Epoch 1122, Loss: 3.0941299200057983, Final Batch Loss: 0.63485187292099\n",
      "Epoch 1123, Loss: 3.074902057647705, Final Batch Loss: 0.5924537777900696\n",
      "Epoch 1124, Loss: 3.5526058077812195, Final Batch Loss: 1.032058835029602\n",
      "Epoch 1125, Loss: 3.2907015681266785, Final Batch Loss: 0.7653629183769226\n",
      "Epoch 1126, Loss: 3.0365540981292725, Final Batch Loss: 0.6183447241783142\n",
      "Epoch 1127, Loss: 3.4076030254364014, Final Batch Loss: 0.7950331568717957\n",
      "Epoch 1128, Loss: 2.8017636239528656, Final Batch Loss: 0.33150729537010193\n",
      "Epoch 1129, Loss: 3.177161931991577, Final Batch Loss: 0.6372280716896057\n",
      "Epoch 1130, Loss: 3.3157010674476624, Final Batch Loss: 0.7733660936355591\n",
      "Epoch 1131, Loss: 3.2148520946502686, Final Batch Loss: 0.7624484300613403\n",
      "Epoch 1132, Loss: 2.9993287920951843, Final Batch Loss: 0.4914894700050354\n",
      "Epoch 1133, Loss: 4.4435232281684875, Final Batch Loss: 1.8749845027923584\n",
      "Epoch 1134, Loss: 2.9723371267318726, Final Batch Loss: 0.3079259395599365\n",
      "Epoch 1135, Loss: 3.1459022164344788, Final Batch Loss: 0.5249308943748474\n",
      "Epoch 1136, Loss: 3.0233376026153564, Final Batch Loss: 0.4909178614616394\n",
      "Epoch 1137, Loss: 3.150114953517914, Final Batch Loss: 0.658908486366272\n",
      "Epoch 1138, Loss: 3.1845608949661255, Final Batch Loss: 0.6497899293899536\n",
      "Epoch 1139, Loss: 3.5926998257637024, Final Batch Loss: 1.0426310300827026\n",
      "Epoch 1140, Loss: 3.279246985912323, Final Batch Loss: 0.7280420064926147\n",
      "Epoch 1141, Loss: 3.1836380660533905, Final Batch Loss: 0.4974565804004669\n",
      "Epoch 1142, Loss: 3.131737768650055, Final Batch Loss: 0.537097156047821\n",
      "Epoch 1143, Loss: 2.981766939163208, Final Batch Loss: 0.5163289308547974\n",
      "Epoch 1144, Loss: 2.7030347287654877, Final Batch Loss: 0.3461340367794037\n",
      "Epoch 1145, Loss: 3.0763648748397827, Final Batch Loss: 0.5730196237564087\n",
      "Epoch 1146, Loss: 3.021194636821747, Final Batch Loss: 0.5635388493537903\n",
      "Epoch 1147, Loss: 3.336978018283844, Final Batch Loss: 0.7162660360336304\n",
      "Epoch 1148, Loss: 3.3033990263938904, Final Batch Loss: 0.7982345223426819\n",
      "Epoch 1149, Loss: 2.8312717378139496, Final Batch Loss: 0.39785048365592957\n",
      "Epoch 1150, Loss: 2.9488161504268646, Final Batch Loss: 0.3933134377002716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1151, Loss: 3.0297447443008423, Final Batch Loss: 0.5944899320602417\n",
      "Epoch 1152, Loss: 3.076723098754883, Final Batch Loss: 0.6192696690559387\n",
      "Epoch 1153, Loss: 3.067396819591522, Final Batch Loss: 0.5631569623947144\n",
      "Epoch 1154, Loss: 3.014706313610077, Final Batch Loss: 0.5778554677963257\n",
      "Epoch 1155, Loss: 3.212692141532898, Final Batch Loss: 0.8152910470962524\n",
      "Epoch 1156, Loss: 3.3910520672798157, Final Batch Loss: 0.7774471640586853\n",
      "Epoch 1157, Loss: 2.7324425876140594, Final Batch Loss: 0.29601606726646423\n",
      "Epoch 1158, Loss: 3.1369524598121643, Final Batch Loss: 0.6112813949584961\n",
      "Epoch 1159, Loss: 3.2406052350997925, Final Batch Loss: 0.729113757610321\n",
      "Epoch 1160, Loss: 3.4913185834884644, Final Batch Loss: 0.8715122938156128\n",
      "Epoch 1161, Loss: 2.9624790847301483, Final Batch Loss: 0.43144646286964417\n",
      "Epoch 1162, Loss: 3.116278648376465, Final Batch Loss: 0.7112005352973938\n",
      "Epoch 1163, Loss: 3.1601609587669373, Final Batch Loss: 0.6403193473815918\n",
      "Epoch 1164, Loss: 3.121545195579529, Final Batch Loss: 0.577688992023468\n",
      "Epoch 1165, Loss: 2.947855055332184, Final Batch Loss: 0.5562069416046143\n",
      "Epoch 1166, Loss: 3.2375349402427673, Final Batch Loss: 0.6366453766822815\n",
      "Epoch 1167, Loss: 3.210481345653534, Final Batch Loss: 0.6105262041091919\n",
      "Epoch 1168, Loss: 3.052361935377121, Final Batch Loss: 0.43789419531822205\n",
      "Epoch 1169, Loss: 3.495271623134613, Final Batch Loss: 0.848380982875824\n",
      "Epoch 1170, Loss: 3.2984266877174377, Final Batch Loss: 0.9252790808677673\n",
      "Epoch 1171, Loss: 2.9488735496997833, Final Batch Loss: 0.3473851978778839\n",
      "Epoch 1172, Loss: 2.9327820241451263, Final Batch Loss: 0.4649905860424042\n",
      "Epoch 1173, Loss: 3.8469144701957703, Final Batch Loss: 1.3187211751937866\n",
      "Epoch 1174, Loss: 3.1343802213668823, Final Batch Loss: 0.6708449721336365\n",
      "Epoch 1175, Loss: 3.5120837092399597, Final Batch Loss: 0.8083369135856628\n",
      "Epoch 1176, Loss: 2.9622429609298706, Final Batch Loss: 0.5258014798164368\n",
      "Epoch 1177, Loss: 3.071021020412445, Final Batch Loss: 0.6987826228141785\n",
      "Epoch 1178, Loss: 3.27841854095459, Final Batch Loss: 0.6667656898498535\n",
      "Epoch 1179, Loss: 3.260855555534363, Final Batch Loss: 0.6968818306922913\n",
      "Epoch 1180, Loss: 2.879646599292755, Final Batch Loss: 0.32370543479919434\n",
      "Epoch 1181, Loss: 3.1088176369667053, Final Batch Loss: 0.5769309997558594\n",
      "Epoch 1182, Loss: 3.4204888343811035, Final Batch Loss: 0.9480632543563843\n",
      "Epoch 1183, Loss: 3.0347813963890076, Final Batch Loss: 0.7035064697265625\n",
      "Epoch 1184, Loss: 2.949173152446747, Final Batch Loss: 0.4598107933998108\n",
      "Epoch 1185, Loss: 3.3564799427986145, Final Batch Loss: 0.9217442870140076\n",
      "Epoch 1186, Loss: 2.8815456926822662, Final Batch Loss: 0.37676963210105896\n",
      "Epoch 1187, Loss: 3.3300625681877136, Final Batch Loss: 0.7841513752937317\n",
      "Epoch 1188, Loss: 3.098931074142456, Final Batch Loss: 0.5495789647102356\n",
      "Epoch 1189, Loss: 3.3111896216869354, Final Batch Loss: 0.8651975989341736\n",
      "Epoch 1190, Loss: 3.1086503863334656, Final Batch Loss: 0.5447759032249451\n",
      "Epoch 1191, Loss: 2.98001229763031, Final Batch Loss: 0.37102580070495605\n",
      "Epoch 1192, Loss: 3.187330484390259, Final Batch Loss: 0.7101491093635559\n",
      "Epoch 1193, Loss: 3.2447327971458435, Final Batch Loss: 0.6022663712501526\n",
      "Epoch 1194, Loss: 2.829872101545334, Final Batch Loss: 0.35782817006111145\n",
      "Epoch 1195, Loss: 2.82742977142334, Final Batch Loss: 0.34840744733810425\n",
      "Epoch 1196, Loss: 3.253769636154175, Final Batch Loss: 0.8253952264785767\n",
      "Epoch 1197, Loss: 2.8180888295173645, Final Batch Loss: 0.40998220443725586\n",
      "Epoch 1198, Loss: 3.141059935092926, Final Batch Loss: 0.6325877904891968\n",
      "Epoch 1199, Loss: 3.0717493295669556, Final Batch Loss: 0.6492778062820435\n",
      "Epoch 1200, Loss: 3.0090810656547546, Final Batch Loss: 0.5538533926010132\n",
      "Epoch 1201, Loss: 3.2707725167274475, Final Batch Loss: 0.8784170746803284\n",
      "Epoch 1202, Loss: 3.2797996401786804, Final Batch Loss: 0.7891812920570374\n",
      "Epoch 1203, Loss: 3.264313220977783, Final Batch Loss: 0.6883535385131836\n",
      "Epoch 1204, Loss: 2.991354316473007, Final Batch Loss: 0.46618208289146423\n",
      "Epoch 1205, Loss: 3.1945983171463013, Final Batch Loss: 0.7989176511764526\n",
      "Epoch 1206, Loss: 3.012577474117279, Final Batch Loss: 0.6454002261161804\n",
      "Epoch 1207, Loss: 3.00974577665329, Final Batch Loss: 0.6113582849502563\n",
      "Epoch 1208, Loss: 3.373990535736084, Final Batch Loss: 0.8799319863319397\n",
      "Epoch 1209, Loss: 3.2547879219055176, Final Batch Loss: 0.6611744165420532\n",
      "Epoch 1210, Loss: 3.3199188113212585, Final Batch Loss: 0.7736319303512573\n",
      "Epoch 1211, Loss: 2.7641008496284485, Final Batch Loss: 0.32439112663269043\n",
      "Epoch 1212, Loss: 3.7069347500801086, Final Batch Loss: 1.128848671913147\n",
      "Epoch 1213, Loss: 3.166646957397461, Final Batch Loss: 0.6563431620597839\n",
      "Epoch 1214, Loss: 2.9171162843704224, Final Batch Loss: 0.2861660122871399\n",
      "Epoch 1215, Loss: 3.4844112396240234, Final Batch Loss: 0.9170607328414917\n",
      "Epoch 1216, Loss: 3.4989209175109863, Final Batch Loss: 0.964898407459259\n",
      "Epoch 1217, Loss: 3.065052032470703, Final Batch Loss: 0.5643702149391174\n",
      "Epoch 1218, Loss: 3.1286526918411255, Final Batch Loss: 0.5321143865585327\n",
      "Epoch 1219, Loss: 3.0963613092899323, Final Batch Loss: 0.4667382538318634\n",
      "Epoch 1220, Loss: 3.2790277004241943, Final Batch Loss: 0.8997983932495117\n",
      "Epoch 1221, Loss: 3.586984872817993, Final Batch Loss: 1.138797640800476\n",
      "Epoch 1222, Loss: 3.074544668197632, Final Batch Loss: 0.5228480696678162\n",
      "Epoch 1223, Loss: 2.915974587202072, Final Batch Loss: 0.40466275811195374\n",
      "Epoch 1224, Loss: 3.5478301644325256, Final Batch Loss: 1.2178611755371094\n",
      "Epoch 1225, Loss: 3.0449737906455994, Final Batch Loss: 0.5449702143669128\n",
      "Epoch 1226, Loss: 3.2229501008987427, Final Batch Loss: 0.7278488874435425\n",
      "Epoch 1227, Loss: 3.809106409549713, Final Batch Loss: 1.391684651374817\n",
      "Epoch 1228, Loss: 3.2337250113487244, Final Batch Loss: 0.8234306573867798\n",
      "Epoch 1229, Loss: 2.875131845474243, Final Batch Loss: 0.5172175765037537\n",
      "Epoch 1230, Loss: 3.030684530735016, Final Batch Loss: 0.5779462456703186\n",
      "Epoch 1231, Loss: 3.3986454606056213, Final Batch Loss: 0.6843690872192383\n",
      "Epoch 1232, Loss: 2.8400007784366608, Final Batch Loss: 0.29100045561790466\n",
      "Epoch 1233, Loss: 2.7105336785316467, Final Batch Loss: 0.34592264890670776\n",
      "Epoch 1234, Loss: 2.717012196779251, Final Batch Loss: 0.3858119547367096\n",
      "Epoch 1235, Loss: 3.2532323002815247, Final Batch Loss: 0.7431880235671997\n",
      "Epoch 1236, Loss: 2.7292287349700928, Final Batch Loss: 0.30203837156295776\n",
      "Epoch 1237, Loss: 2.961356610059738, Final Batch Loss: 0.34633198380470276\n",
      "Epoch 1238, Loss: 3.26619553565979, Final Batch Loss: 0.9829073548316956\n",
      "Epoch 1239, Loss: 2.853824347257614, Final Batch Loss: 0.5977920889854431\n",
      "Epoch 1240, Loss: 3.1304667592048645, Final Batch Loss: 0.6728587746620178\n",
      "Epoch 1241, Loss: 3.128024935722351, Final Batch Loss: 0.6185082197189331\n",
      "Epoch 1242, Loss: 3.056593894958496, Final Batch Loss: 0.5189288258552551\n",
      "Epoch 1243, Loss: 2.9874954223632812, Final Batch Loss: 0.5282469987869263\n",
      "Epoch 1244, Loss: 2.9965638518333435, Final Batch Loss: 0.5903262495994568\n",
      "Epoch 1245, Loss: 3.2323890924453735, Final Batch Loss: 0.8072912096977234\n",
      "Epoch 1246, Loss: 3.035778045654297, Final Batch Loss: 0.5945104956626892\n",
      "Epoch 1247, Loss: 2.847853034734726, Final Batch Loss: 0.29613104462623596\n",
      "Epoch 1248, Loss: 3.062134087085724, Final Batch Loss: 0.473196804523468\n",
      "Epoch 1249, Loss: 2.84559765458107, Final Batch Loss: 0.38130536675453186\n",
      "Epoch 1250, Loss: 2.760177582502365, Final Batch Loss: 0.26599904894828796\n",
      "Epoch 1251, Loss: 2.81929412484169, Final Batch Loss: 0.4108414351940155\n",
      "Epoch 1252, Loss: 3.627811551094055, Final Batch Loss: 1.0609331130981445\n",
      "Epoch 1253, Loss: 3.160601556301117, Final Batch Loss: 0.682956337928772\n",
      "Epoch 1254, Loss: 3.1841774582862854, Final Batch Loss: 0.7904525399208069\n",
      "Epoch 1255, Loss: 3.043309986591339, Final Batch Loss: 0.6568120718002319\n",
      "Epoch 1256, Loss: 2.809107154607773, Final Batch Loss: 0.4498670995235443\n",
      "Epoch 1257, Loss: 3.6005231738090515, Final Batch Loss: 1.066825032234192\n",
      "Epoch 1258, Loss: 2.9785033464431763, Final Batch Loss: 0.5825929045677185\n",
      "Epoch 1259, Loss: 2.789687544107437, Final Batch Loss: 0.4499281346797943\n",
      "Epoch 1260, Loss: 2.7789905965328217, Final Batch Loss: 0.3518328368663788\n",
      "Epoch 1261, Loss: 3.06142520904541, Final Batch Loss: 0.49159127473831177\n",
      "Epoch 1262, Loss: 2.9381496906280518, Final Batch Loss: 0.47977834939956665\n",
      "Epoch 1263, Loss: 3.000006914138794, Final Batch Loss: 0.758041501045227\n",
      "Epoch 1264, Loss: 3.004800498485565, Final Batch Loss: 0.6604275107383728\n",
      "Epoch 1265, Loss: 3.104661762714386, Final Batch Loss: 0.7192775011062622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1266, Loss: 2.905228227376938, Final Batch Loss: 0.46907052397727966\n",
      "Epoch 1267, Loss: 3.10541695356369, Final Batch Loss: 0.5293081402778625\n",
      "Epoch 1268, Loss: 3.111605226993561, Final Batch Loss: 0.7490958571434021\n",
      "Epoch 1269, Loss: 3.0724223852157593, Final Batch Loss: 0.6943368911743164\n",
      "Epoch 1270, Loss: 2.8700581789016724, Final Batch Loss: 0.491682231426239\n",
      "Epoch 1271, Loss: 2.824220895767212, Final Batch Loss: 0.3148173689842224\n",
      "Epoch 1272, Loss: 3.046865165233612, Final Batch Loss: 0.5527603030204773\n",
      "Epoch 1273, Loss: 2.6650184094905853, Final Batch Loss: 0.29661861062049866\n",
      "Epoch 1274, Loss: 2.9714153110980988, Final Batch Loss: 0.4745681583881378\n",
      "Epoch 1275, Loss: 2.8733773827552795, Final Batch Loss: 0.4420015215873718\n",
      "Epoch 1276, Loss: 2.8802176117897034, Final Batch Loss: 0.5159895420074463\n",
      "Epoch 1277, Loss: 2.8514286279678345, Final Batch Loss: 0.5104504227638245\n",
      "Epoch 1278, Loss: 2.658419445157051, Final Batch Loss: 0.2244470864534378\n",
      "Epoch 1279, Loss: 2.834165096282959, Final Batch Loss: 0.4549446105957031\n",
      "Epoch 1280, Loss: 3.5486560463905334, Final Batch Loss: 1.0725977420806885\n",
      "Epoch 1281, Loss: 3.5943187475204468, Final Batch Loss: 1.2905141115188599\n",
      "Epoch 1282, Loss: 3.2113982439041138, Final Batch Loss: 0.7344421148300171\n",
      "Epoch 1283, Loss: 2.986150026321411, Final Batch Loss: 0.41491490602493286\n",
      "Epoch 1284, Loss: 3.2605326175689697, Final Batch Loss: 0.7718348503112793\n",
      "Epoch 1285, Loss: 2.9569591283798218, Final Batch Loss: 0.6088399291038513\n",
      "Epoch 1286, Loss: 2.844232887029648, Final Batch Loss: 0.37534359097480774\n",
      "Epoch 1287, Loss: 2.82059782743454, Final Batch Loss: 0.4744611382484436\n",
      "Epoch 1288, Loss: 3.1943421959877014, Final Batch Loss: 0.7397332787513733\n",
      "Epoch 1289, Loss: 2.6713021993637085, Final Batch Loss: 0.2752581238746643\n",
      "Epoch 1290, Loss: 3.164483666419983, Final Batch Loss: 0.7610422372817993\n",
      "Epoch 1291, Loss: 2.951926827430725, Final Batch Loss: 0.5648410320281982\n",
      "Epoch 1292, Loss: 2.7499565184116364, Final Batch Loss: 0.3538913428783417\n",
      "Epoch 1293, Loss: 2.6859889030456543, Final Batch Loss: 0.2705541253089905\n",
      "Epoch 1294, Loss: 2.6835066825151443, Final Batch Loss: 0.24171645939350128\n",
      "Epoch 1295, Loss: 3.1348336935043335, Final Batch Loss: 0.7244147658348083\n",
      "Epoch 1296, Loss: 2.977357029914856, Final Batch Loss: 0.6224075555801392\n",
      "Epoch 1297, Loss: 2.6151964366436005, Final Batch Loss: 0.4596523940563202\n",
      "Epoch 1298, Loss: 2.9088993072509766, Final Batch Loss: 0.5046400427818298\n",
      "Epoch 1299, Loss: 2.947965085506439, Final Batch Loss: 0.5706697106361389\n",
      "Epoch 1300, Loss: 2.7062187492847443, Final Batch Loss: 0.3200724422931671\n",
      "Epoch 1301, Loss: 2.7090148627758026, Final Batch Loss: 0.4381311237812042\n",
      "Epoch 1302, Loss: 2.926918685436249, Final Batch Loss: 0.5943800210952759\n",
      "Epoch 1303, Loss: 3.5325576066970825, Final Batch Loss: 1.261513590812683\n",
      "Epoch 1304, Loss: 3.367122173309326, Final Batch Loss: 0.8946134448051453\n",
      "Epoch 1305, Loss: 3.0441895723342896, Final Batch Loss: 0.5677468180656433\n",
      "Epoch 1306, Loss: 3.384300410747528, Final Batch Loss: 0.6222572326660156\n",
      "Epoch 1307, Loss: 3.3567534685134888, Final Batch Loss: 0.9935019612312317\n",
      "Epoch 1308, Loss: 2.5124822854995728, Final Batch Loss: 0.24699270725250244\n",
      "Epoch 1309, Loss: 3.180414915084839, Final Batch Loss: 0.7290015816688538\n",
      "Epoch 1310, Loss: 2.9875760078430176, Final Batch Loss: 0.6596196293830872\n",
      "Epoch 1311, Loss: 3.2033587992191315, Final Batch Loss: 0.7248849272727966\n",
      "Epoch 1312, Loss: 3.28629469871521, Final Batch Loss: 0.7682744264602661\n",
      "Epoch 1313, Loss: 3.6991912126541138, Final Batch Loss: 1.3479915857315063\n",
      "Epoch 1314, Loss: 2.998824179172516, Final Batch Loss: 0.6993235349655151\n",
      "Epoch 1315, Loss: 2.998995155096054, Final Batch Loss: 0.477321058511734\n",
      "Epoch 1316, Loss: 3.395924150943756, Final Batch Loss: 0.7710054516792297\n",
      "Epoch 1317, Loss: 3.037251263856888, Final Batch Loss: 0.33831217885017395\n",
      "Epoch 1318, Loss: 3.1631595492362976, Final Batch Loss: 0.7065719962120056\n",
      "Epoch 1319, Loss: 3.0574474930763245, Final Batch Loss: 0.6230406761169434\n",
      "Epoch 1320, Loss: 3.16094172000885, Final Batch Loss: 0.7748962640762329\n",
      "Epoch 1321, Loss: 3.0514023900032043, Final Batch Loss: 0.593635082244873\n",
      "Epoch 1322, Loss: 3.171277642250061, Final Batch Loss: 0.8143288493156433\n",
      "Epoch 1323, Loss: 2.6751133501529694, Final Batch Loss: 0.354390949010849\n",
      "Epoch 1324, Loss: 2.681364208459854, Final Batch Loss: 0.46018633246421814\n",
      "Epoch 1325, Loss: 2.846373438835144, Final Batch Loss: 0.5069126486778259\n",
      "Epoch 1326, Loss: 2.758008897304535, Final Batch Loss: 0.42015939950942993\n",
      "Epoch 1327, Loss: 3.241230547428131, Final Batch Loss: 0.9806376099586487\n",
      "Epoch 1328, Loss: 3.3194153904914856, Final Batch Loss: 0.967845618724823\n",
      "Epoch 1329, Loss: 3.4681277871131897, Final Batch Loss: 1.0069434642791748\n",
      "Epoch 1330, Loss: 2.9182018637657166, Final Batch Loss: 0.5807281136512756\n",
      "Epoch 1331, Loss: 2.7727015614509583, Final Batch Loss: 0.3938589096069336\n",
      "Epoch 1332, Loss: 2.7705878913402557, Final Batch Loss: 0.41446825861930847\n",
      "Epoch 1333, Loss: 2.970596134662628, Final Batch Loss: 0.5327895879745483\n",
      "Epoch 1334, Loss: 3.1208459734916687, Final Batch Loss: 0.627149760723114\n",
      "Epoch 1335, Loss: 2.994173765182495, Final Batch Loss: 0.5548000335693359\n",
      "Epoch 1336, Loss: 2.736748307943344, Final Batch Loss: 0.4132096469402313\n",
      "Epoch 1337, Loss: 2.9373185634613037, Final Batch Loss: 0.5579919815063477\n",
      "Epoch 1338, Loss: 3.255400776863098, Final Batch Loss: 0.8991693258285522\n",
      "Epoch 1339, Loss: 2.5836347341537476, Final Batch Loss: 0.28986287117004395\n",
      "Epoch 1340, Loss: 2.712276041507721, Final Batch Loss: 0.35280662775039673\n",
      "Epoch 1341, Loss: 2.806295931339264, Final Batch Loss: 0.41200655698776245\n",
      "Epoch 1342, Loss: 2.843607485294342, Final Batch Loss: 0.524818480014801\n",
      "Epoch 1343, Loss: 2.822281777858734, Final Batch Loss: 0.507698118686676\n",
      "Epoch 1344, Loss: 2.917450726032257, Final Batch Loss: 0.5207115411758423\n",
      "Epoch 1345, Loss: 3.1372994780540466, Final Batch Loss: 0.6806377172470093\n",
      "Epoch 1346, Loss: 2.789538085460663, Final Batch Loss: 0.5002480149269104\n",
      "Epoch 1347, Loss: 2.731392949819565, Final Batch Loss: 0.339448481798172\n",
      "Epoch 1348, Loss: 2.807094097137451, Final Batch Loss: 0.4049904942512512\n",
      "Epoch 1349, Loss: 2.809803158044815, Final Batch Loss: 0.3628251254558563\n",
      "Epoch 1350, Loss: 2.659264475107193, Final Batch Loss: 0.28048762679100037\n",
      "Epoch 1351, Loss: 3.0215805172920227, Final Batch Loss: 0.5354283452033997\n",
      "Epoch 1352, Loss: 3.060226082801819, Final Batch Loss: 0.7915744185447693\n",
      "Epoch 1353, Loss: 3.0505564212799072, Final Batch Loss: 0.47674447298049927\n",
      "Epoch 1354, Loss: 2.8422001600265503, Final Batch Loss: 0.674293041229248\n",
      "Epoch 1355, Loss: 2.6828422844409943, Final Batch Loss: 0.4481658935546875\n",
      "Epoch 1356, Loss: 3.079861581325531, Final Batch Loss: 0.552919328212738\n",
      "Epoch 1357, Loss: 2.811697095632553, Final Batch Loss: 0.4639187157154083\n",
      "Epoch 1358, Loss: 3.097083330154419, Final Batch Loss: 0.7426770925521851\n",
      "Epoch 1359, Loss: 2.833132892847061, Final Batch Loss: 0.46272018551826477\n",
      "Epoch 1360, Loss: 2.8798505067825317, Final Batch Loss: 0.7089750170707703\n",
      "Epoch 1361, Loss: 2.74211585521698, Final Batch Loss: 0.41643691062927246\n",
      "Epoch 1362, Loss: 3.0302898287773132, Final Batch Loss: 0.6683042645454407\n",
      "Epoch 1363, Loss: 2.7718109786510468, Final Batch Loss: 0.33995625376701355\n",
      "Epoch 1364, Loss: 3.0750838220119476, Final Batch Loss: 0.8715835809707642\n",
      "Epoch 1365, Loss: 2.5149139165878296, Final Batch Loss: 0.27837425470352173\n",
      "Epoch 1366, Loss: 2.8899598717689514, Final Batch Loss: 0.46848440170288086\n",
      "Epoch 1367, Loss: 2.8928073346614838, Final Batch Loss: 0.5249606966972351\n",
      "Epoch 1368, Loss: 2.7319440245628357, Final Batch Loss: 0.32150834798812866\n",
      "Epoch 1369, Loss: 2.842091679573059, Final Batch Loss: 0.46304959058761597\n",
      "Epoch 1370, Loss: 2.9318359196186066, Final Batch Loss: 0.4739554822444916\n",
      "Epoch 1371, Loss: 2.758133113384247, Final Batch Loss: 0.4382858872413635\n",
      "Epoch 1372, Loss: 3.160519003868103, Final Batch Loss: 0.8388232588768005\n",
      "Epoch 1373, Loss: 2.6367546021938324, Final Batch Loss: 0.28154096007347107\n",
      "Epoch 1374, Loss: 2.94545316696167, Final Batch Loss: 0.5884782075881958\n",
      "Epoch 1375, Loss: 2.6915295720100403, Final Batch Loss: 0.3423905372619629\n",
      "Epoch 1376, Loss: 2.6477158814668655, Final Batch Loss: 0.2458592802286148\n",
      "Epoch 1377, Loss: 2.7459728121757507, Final Batch Loss: 0.5432568192481995\n",
      "Epoch 1378, Loss: 2.87087619304657, Final Batch Loss: 0.5751107931137085\n",
      "Epoch 1379, Loss: 2.8438168466091156, Final Batch Loss: 0.3847492039203644\n",
      "Epoch 1380, Loss: 2.8020169138908386, Final Batch Loss: 0.43528494238853455\n",
      "Epoch 1381, Loss: 3.2527542114257812, Final Batch Loss: 0.9796310663223267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1382, Loss: 2.6135966181755066, Final Batch Loss: 0.2651001811027527\n",
      "Epoch 1383, Loss: 3.0985385179519653, Final Batch Loss: 0.7956568002700806\n",
      "Epoch 1384, Loss: 2.824629306793213, Final Batch Loss: 0.5368447303771973\n",
      "Epoch 1385, Loss: 3.1325658559799194, Final Batch Loss: 0.605572521686554\n",
      "Epoch 1386, Loss: 3.2549145817756653, Final Batch Loss: 0.7939361929893494\n",
      "Epoch 1387, Loss: 3.120352625846863, Final Batch Loss: 0.9107127785682678\n",
      "Epoch 1388, Loss: 2.9689297676086426, Final Batch Loss: 0.6682021021842957\n",
      "Epoch 1389, Loss: 2.857946515083313, Final Batch Loss: 0.5873470902442932\n",
      "Epoch 1390, Loss: 3.065146028995514, Final Batch Loss: 0.7129687666893005\n",
      "Epoch 1391, Loss: 2.593491718173027, Final Batch Loss: 0.19467227160930634\n",
      "Epoch 1392, Loss: 2.6790380775928497, Final Batch Loss: 0.23552700877189636\n",
      "Epoch 1393, Loss: 2.635474771261215, Final Batch Loss: 0.41221001744270325\n",
      "Epoch 1394, Loss: 2.4982319325208664, Final Batch Loss: 0.13644413650035858\n",
      "Epoch 1395, Loss: 3.2854455709457397, Final Batch Loss: 0.9531630873680115\n",
      "Epoch 1396, Loss: 2.984677791595459, Final Batch Loss: 0.7356627583503723\n",
      "Epoch 1397, Loss: 2.957559883594513, Final Batch Loss: 0.5873354077339172\n",
      "Epoch 1398, Loss: 2.7497359812259674, Final Batch Loss: 0.4362092912197113\n",
      "Epoch 1399, Loss: 3.3648826479911804, Final Batch Loss: 0.9285475611686707\n",
      "Epoch 1400, Loss: 3.158515155315399, Final Batch Loss: 0.6585973501205444\n",
      "Epoch 1401, Loss: 2.893785148859024, Final Batch Loss: 0.397223562002182\n",
      "Epoch 1402, Loss: 3.051030218601227, Final Batch Loss: 0.6151372194290161\n",
      "Epoch 1403, Loss: 3.363866150379181, Final Batch Loss: 0.8798589706420898\n",
      "Epoch 1404, Loss: 3.456967830657959, Final Batch Loss: 0.9898455739021301\n",
      "Epoch 1405, Loss: 2.8994178771972656, Final Batch Loss: 0.39308756589889526\n",
      "Epoch 1406, Loss: 2.8045405745506287, Final Batch Loss: 0.5698562264442444\n",
      "Epoch 1407, Loss: 2.7853748202323914, Final Batch Loss: 0.49664801359176636\n",
      "Epoch 1408, Loss: 2.7437909841537476, Final Batch Loss: 0.40817075967788696\n",
      "Epoch 1409, Loss: 2.818787395954132, Final Batch Loss: 0.3597571849822998\n",
      "Epoch 1410, Loss: 3.079890727996826, Final Batch Loss: 0.8258177042007446\n",
      "Epoch 1411, Loss: 2.939226984977722, Final Batch Loss: 0.7103126645088196\n",
      "Epoch 1412, Loss: 3.361666679382324, Final Batch Loss: 1.0237880945205688\n",
      "Epoch 1413, Loss: 2.7456036806106567, Final Batch Loss: 0.4183542728424072\n",
      "Epoch 1414, Loss: 2.9633609652519226, Final Batch Loss: 0.7226401567459106\n",
      "Epoch 1415, Loss: 2.798811435699463, Final Batch Loss: 0.5710709095001221\n",
      "Epoch 1416, Loss: 2.7977045476436615, Final Batch Loss: 0.3965268135070801\n",
      "Epoch 1417, Loss: 2.744571566581726, Final Batch Loss: 0.3714786171913147\n",
      "Epoch 1418, Loss: 3.017920732498169, Final Batch Loss: 0.6271265745162964\n",
      "Epoch 1419, Loss: 2.665444552898407, Final Batch Loss: 0.36010169982910156\n",
      "Epoch 1420, Loss: 2.8572030663490295, Final Batch Loss: 0.5587114095687866\n",
      "Epoch 1421, Loss: 2.6527231335639954, Final Batch Loss: 0.2585408687591553\n",
      "Epoch 1422, Loss: 2.9953197240829468, Final Batch Loss: 0.8688582181930542\n",
      "Epoch 1423, Loss: 2.8085900843143463, Final Batch Loss: 0.3330818712711334\n",
      "Epoch 1424, Loss: 2.6719692051410675, Final Batch Loss: 0.4440896213054657\n",
      "Epoch 1425, Loss: 3.1681293845176697, Final Batch Loss: 0.9758507609367371\n",
      "Epoch 1426, Loss: 2.720513552427292, Final Batch Loss: 0.4981219470500946\n",
      "Epoch 1427, Loss: 2.545499712228775, Final Batch Loss: 0.3819907009601593\n",
      "Epoch 1428, Loss: 2.655860185623169, Final Batch Loss: 0.34487253427505493\n",
      "Epoch 1429, Loss: 2.7939122319221497, Final Batch Loss: 0.5354010462760925\n",
      "Epoch 1430, Loss: 3.3400878310203552, Final Batch Loss: 0.879538357257843\n",
      "Epoch 1431, Loss: 2.7985548973083496, Final Batch Loss: 0.5770345330238342\n",
      "Epoch 1432, Loss: 2.8251791894435883, Final Batch Loss: 0.40228351950645447\n",
      "Epoch 1433, Loss: 3.304985284805298, Final Batch Loss: 1.0156339406967163\n",
      "Epoch 1434, Loss: 3.2883946895599365, Final Batch Loss: 0.8461785912513733\n",
      "Epoch 1435, Loss: 3.201956808567047, Final Batch Loss: 0.5887492299079895\n",
      "Epoch 1436, Loss: 2.9489395022392273, Final Batch Loss: 0.4633139967918396\n",
      "Epoch 1437, Loss: 2.9725571870803833, Final Batch Loss: 0.5365515351295471\n",
      "Epoch 1438, Loss: 3.3200910687446594, Final Batch Loss: 0.8214465975761414\n",
      "Epoch 1439, Loss: 3.1284473538398743, Final Batch Loss: 0.5572412610054016\n",
      "Epoch 1440, Loss: 3.0134307146072388, Final Batch Loss: 0.7362760305404663\n",
      "Epoch 1441, Loss: 3.2093241214752197, Final Batch Loss: 0.733548104763031\n",
      "Epoch 1442, Loss: 2.8044968843460083, Final Batch Loss: 0.5480037331581116\n",
      "Epoch 1443, Loss: 3.1466644406318665, Final Batch Loss: 0.712020993232727\n",
      "Epoch 1444, Loss: 2.8639048635959625, Final Batch Loss: 0.4904225766658783\n",
      "Epoch 1445, Loss: 3.0279815196990967, Final Batch Loss: 0.7331401705741882\n",
      "Epoch 1446, Loss: 2.7365545332431793, Final Batch Loss: 0.4305960237979889\n",
      "Epoch 1447, Loss: 2.8986453115940094, Final Batch Loss: 0.5975608825683594\n",
      "Epoch 1448, Loss: 3.011983871459961, Final Batch Loss: 0.7475242018699646\n",
      "Epoch 1449, Loss: 2.83937406539917, Final Batch Loss: 0.5825595855712891\n",
      "Epoch 1450, Loss: 2.8538787961006165, Final Batch Loss: 0.5963417887687683\n",
      "Epoch 1451, Loss: 2.745616614818573, Final Batch Loss: 0.5283458232879639\n",
      "Epoch 1452, Loss: 3.1261309385299683, Final Batch Loss: 0.7429268956184387\n",
      "Epoch 1453, Loss: 3.205605387687683, Final Batch Loss: 0.8817160725593567\n",
      "Epoch 1454, Loss: 3.0611459612846375, Final Batch Loss: 0.7268092036247253\n",
      "Epoch 1455, Loss: 3.0017797350883484, Final Batch Loss: 0.7639350891113281\n",
      "Epoch 1456, Loss: 2.7358169555664062, Final Batch Loss: 0.36415261030197144\n",
      "Epoch 1457, Loss: 2.9596946239471436, Final Batch Loss: 0.5598544478416443\n",
      "Epoch 1458, Loss: 2.8527663350105286, Final Batch Loss: 0.588123619556427\n",
      "Epoch 1459, Loss: 2.8992260098457336, Final Batch Loss: 0.6302544474601746\n",
      "Epoch 1460, Loss: 3.0176653265953064, Final Batch Loss: 0.6950617432594299\n",
      "Epoch 1461, Loss: 3.0634233951568604, Final Batch Loss: 0.85676509141922\n",
      "Epoch 1462, Loss: 2.91738623380661, Final Batch Loss: 0.5566975474357605\n",
      "Epoch 1463, Loss: 2.801600396633148, Final Batch Loss: 0.5528041124343872\n",
      "Epoch 1464, Loss: 3.042890727519989, Final Batch Loss: 0.7863495945930481\n",
      "Epoch 1465, Loss: 2.795932173728943, Final Batch Loss: 0.5420787930488586\n",
      "Epoch 1466, Loss: 2.921193301677704, Final Batch Loss: 0.6817340850830078\n",
      "Epoch 1467, Loss: 2.6384121775627136, Final Batch Loss: 0.37546810507774353\n",
      "Epoch 1468, Loss: 2.7465019822120667, Final Batch Loss: 0.265563428401947\n",
      "Epoch 1469, Loss: 2.768360733985901, Final Batch Loss: 0.36005306243896484\n",
      "Epoch 1470, Loss: 3.032555103302002, Final Batch Loss: 0.7570918798446655\n",
      "Epoch 1471, Loss: 3.200157105922699, Final Batch Loss: 0.7916768789291382\n",
      "Epoch 1472, Loss: 2.8317770957946777, Final Batch Loss: 0.5241873860359192\n",
      "Epoch 1473, Loss: 3.1334765553474426, Final Batch Loss: 0.8237388730049133\n",
      "Epoch 1474, Loss: 2.8378250896930695, Final Batch Loss: 0.547239363193512\n",
      "Epoch 1475, Loss: 2.785908818244934, Final Batch Loss: 0.490540087223053\n",
      "Epoch 1476, Loss: 2.6930893063545227, Final Batch Loss: 0.3445720076560974\n",
      "Epoch 1477, Loss: 2.6753894686698914, Final Batch Loss: 0.331306129693985\n",
      "Epoch 1478, Loss: 2.739868402481079, Final Batch Loss: 0.5466428995132446\n",
      "Epoch 1479, Loss: 2.6991036236286163, Final Batch Loss: 0.45752009749412537\n",
      "Epoch 1480, Loss: 3.050351083278656, Final Batch Loss: 0.7344352006912231\n",
      "Epoch 1481, Loss: 3.1425397992134094, Final Batch Loss: 0.8613311052322388\n",
      "Epoch 1482, Loss: 2.8437960743904114, Final Batch Loss: 0.6502448320388794\n",
      "Epoch 1483, Loss: 2.710532158613205, Final Batch Loss: 0.3642749488353729\n",
      "Epoch 1484, Loss: 2.7525974810123444, Final Batch Loss: 0.4493023455142975\n",
      "Epoch 1485, Loss: 2.791025459766388, Final Batch Loss: 0.5511901378631592\n",
      "Epoch 1486, Loss: 2.6939879655838013, Final Batch Loss: 0.4064326286315918\n",
      "Epoch 1487, Loss: 2.8223089575767517, Final Batch Loss: 0.54813551902771\n",
      "Epoch 1488, Loss: 2.686566650867462, Final Batch Loss: 0.3158702254295349\n",
      "Epoch 1489, Loss: 3.022803843021393, Final Batch Loss: 0.7033601403236389\n",
      "Epoch 1490, Loss: 3.1497883796691895, Final Batch Loss: 1.0177454948425293\n",
      "Epoch 1491, Loss: 2.733192026615143, Final Batch Loss: 0.4296298325061798\n",
      "Epoch 1492, Loss: 2.527074873447418, Final Batch Loss: 0.3176436424255371\n",
      "Epoch 1493, Loss: 3.003866195678711, Final Batch Loss: 0.5716046690940857\n",
      "Epoch 1494, Loss: 2.9811404943466187, Final Batch Loss: 0.7830246090888977\n",
      "Epoch 1495, Loss: 2.7295850813388824, Final Batch Loss: 0.4756855070590973\n",
      "Epoch 1496, Loss: 2.7458002865314484, Final Batch Loss: 0.33804574608802795\n",
      "Epoch 1497, Loss: 2.5848287642002106, Final Batch Loss: 0.39945903420448303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1498, Loss: 2.581468403339386, Final Batch Loss: 0.312486469745636\n",
      "Epoch 1499, Loss: 2.6102814078330994, Final Batch Loss: 0.44818606972694397\n",
      "Epoch 1500, Loss: 2.750409722328186, Final Batch Loss: 0.4883870482444763\n",
      "Epoch 1501, Loss: 2.4837250858545303, Final Batch Loss: 0.18360330164432526\n",
      "Epoch 1502, Loss: 2.522540718317032, Final Batch Loss: 0.3811435401439667\n",
      "Epoch 1503, Loss: 2.6019629538059235, Final Batch Loss: 0.35683420300483704\n",
      "Epoch 1504, Loss: 2.7367043793201447, Final Batch Loss: 0.5534606575965881\n",
      "Epoch 1505, Loss: 2.5344839096069336, Final Batch Loss: 0.34403038024902344\n",
      "Epoch 1506, Loss: 2.570890873670578, Final Batch Loss: 0.44182631373405457\n",
      "Epoch 1507, Loss: 2.2580168694257736, Final Batch Loss: 0.20773260295391083\n",
      "Epoch 1508, Loss: 2.932988464832306, Final Batch Loss: 0.6372410655021667\n",
      "Epoch 1509, Loss: 3.2178875207901, Final Batch Loss: 0.9303910136222839\n",
      "Epoch 1510, Loss: 2.9273303151130676, Final Batch Loss: 0.6820003390312195\n",
      "Epoch 1511, Loss: 2.63848078250885, Final Batch Loss: 0.4771263599395752\n",
      "Epoch 1512, Loss: 2.73509481549263, Final Batch Loss: 0.5727326273918152\n",
      "Epoch 1513, Loss: 2.885738730430603, Final Batch Loss: 0.6232152581214905\n",
      "Epoch 1514, Loss: 3.0718517899513245, Final Batch Loss: 0.8677176237106323\n",
      "Epoch 1515, Loss: 2.7172842621803284, Final Batch Loss: 0.5594857931137085\n",
      "Epoch 1516, Loss: 3.4026295840740204, Final Batch Loss: 1.1768970489501953\n",
      "Epoch 1517, Loss: 2.787123918533325, Final Batch Loss: 0.3399342894554138\n",
      "Epoch 1518, Loss: 2.6407254338264465, Final Batch Loss: 0.3114190101623535\n",
      "Epoch 1519, Loss: 2.9600133895874023, Final Batch Loss: 0.7188490629196167\n",
      "Epoch 1520, Loss: 3.107086956501007, Final Batch Loss: 0.8474311232566833\n",
      "Epoch 1521, Loss: 3.2510159611701965, Final Batch Loss: 0.9472954869270325\n",
      "Epoch 1522, Loss: 4.015966296195984, Final Batch Loss: 1.7791024446487427\n",
      "Epoch 1523, Loss: 2.582545816898346, Final Batch Loss: 0.36677008867263794\n",
      "Epoch 1524, Loss: 3.132436752319336, Final Batch Loss: 0.9398621916770935\n",
      "Epoch 1525, Loss: 2.5641802847385406, Final Batch Loss: 0.4423352777957916\n",
      "Epoch 1526, Loss: 3.0999624133110046, Final Batch Loss: 0.8066750764846802\n",
      "Epoch 1527, Loss: 2.868012249469757, Final Batch Loss: 0.6113967299461365\n",
      "Epoch 1528, Loss: 3.147256374359131, Final Batch Loss: 0.7447218298912048\n",
      "Epoch 1529, Loss: 2.8124221563339233, Final Batch Loss: 0.437483549118042\n",
      "Epoch 1530, Loss: 2.885127902030945, Final Batch Loss: 0.5317994356155396\n",
      "Epoch 1531, Loss: 2.714388281106949, Final Batch Loss: 0.39213815331459045\n",
      "Epoch 1532, Loss: 2.4757540076971054, Final Batch Loss: 0.2182488888502121\n",
      "Epoch 1533, Loss: 2.9634376764297485, Final Batch Loss: 0.6846962571144104\n",
      "Epoch 1534, Loss: 2.6630871295928955, Final Batch Loss: 0.5176587700843811\n",
      "Epoch 1535, Loss: 2.928576111793518, Final Batch Loss: 0.6036409139633179\n",
      "Epoch 1536, Loss: 2.470629319548607, Final Batch Loss: 0.23710207641124725\n",
      "Epoch 1537, Loss: 3.087720274925232, Final Batch Loss: 0.8455618619918823\n",
      "Epoch 1538, Loss: 2.6003688275814056, Final Batch Loss: 0.33541157841682434\n",
      "Epoch 1539, Loss: 2.630415588617325, Final Batch Loss: 0.44344601035118103\n",
      "Epoch 1540, Loss: 2.6474002301692963, Final Batch Loss: 0.4705638289451599\n",
      "Epoch 1541, Loss: 2.7236133217811584, Final Batch Loss: 0.46888870000839233\n",
      "Epoch 1542, Loss: 2.87355837225914, Final Batch Loss: 0.8195909261703491\n",
      "Epoch 1543, Loss: 2.9964134097099304, Final Batch Loss: 0.8395071029663086\n",
      "Epoch 1544, Loss: 2.8487448990345, Final Batch Loss: 0.7064738273620605\n",
      "Epoch 1545, Loss: 2.6751343607902527, Final Batch Loss: 0.38898301124572754\n",
      "Epoch 1546, Loss: 2.5753350853919983, Final Batch Loss: 0.3320944905281067\n",
      "Epoch 1547, Loss: 2.674016237258911, Final Batch Loss: 0.44900208711624146\n",
      "Epoch 1548, Loss: 2.432856500148773, Final Batch Loss: 0.3270971477031708\n",
      "Epoch 1549, Loss: 2.496943950653076, Final Batch Loss: 0.286804735660553\n",
      "Epoch 1550, Loss: 2.9511698782444, Final Batch Loss: 0.8366249799728394\n",
      "Epoch 1551, Loss: 3.2086780667304993, Final Batch Loss: 1.1028178930282593\n",
      "Epoch 1552, Loss: 2.4958153069019318, Final Batch Loss: 0.2587551176548004\n",
      "Epoch 1553, Loss: 3.095211148262024, Final Batch Loss: 0.7788490653038025\n",
      "Epoch 1554, Loss: 3.0883509516716003, Final Batch Loss: 0.7557668089866638\n",
      "Epoch 1555, Loss: 2.722166270017624, Final Batch Loss: 0.2967574894428253\n",
      "Epoch 1556, Loss: 2.7817755937576294, Final Batch Loss: 0.3656585216522217\n",
      "Epoch 1557, Loss: 2.7953702211380005, Final Batch Loss: 0.399585485458374\n",
      "Epoch 1558, Loss: 2.6715485751628876, Final Batch Loss: 0.5103105306625366\n",
      "Epoch 1559, Loss: 2.6172838509082794, Final Batch Loss: 0.5064268708229065\n",
      "Epoch 1560, Loss: 2.8812880516052246, Final Batch Loss: 0.6589797139167786\n",
      "Epoch 1561, Loss: 2.6268263161182404, Final Batch Loss: 0.4804023206233978\n",
      "Epoch 1562, Loss: 2.3843257427215576, Final Batch Loss: 0.29090017080307007\n",
      "Epoch 1563, Loss: 2.417113170027733, Final Batch Loss: 0.22001563012599945\n",
      "Epoch 1564, Loss: 2.7158424258232117, Final Batch Loss: 0.48680782318115234\n",
      "Epoch 1565, Loss: 3.153011292219162, Final Batch Loss: 0.9025365114212036\n",
      "Epoch 1566, Loss: 3.188847839832306, Final Batch Loss: 0.7698173522949219\n",
      "Epoch 1567, Loss: 3.0566872358322144, Final Batch Loss: 0.6947447657585144\n",
      "Epoch 1568, Loss: 2.8027383238077164, Final Batch Loss: 0.24868591129779816\n",
      "Epoch 1569, Loss: 2.5769281685352325, Final Batch Loss: 0.3573576807975769\n",
      "Epoch 1570, Loss: 2.86866557598114, Final Batch Loss: 0.6854233145713806\n",
      "Epoch 1571, Loss: 2.9918151199817657, Final Batch Loss: 0.6520830988883972\n",
      "Epoch 1572, Loss: 2.6169724464416504, Final Batch Loss: 0.4490886330604553\n",
      "Epoch 1573, Loss: 2.978474944829941, Final Batch Loss: 0.8390089869499207\n",
      "Epoch 1574, Loss: 2.784648984670639, Final Batch Loss: 0.685109555721283\n",
      "Epoch 1575, Loss: 2.365676462650299, Final Batch Loss: 0.2500097155570984\n",
      "Epoch 1576, Loss: 2.831490218639374, Final Batch Loss: 0.6202718019485474\n",
      "Epoch 1577, Loss: 2.528902918100357, Final Batch Loss: 0.3645433783531189\n",
      "Epoch 1578, Loss: 2.7083566188812256, Final Batch Loss: 0.5789642333984375\n",
      "Epoch 1579, Loss: 3.0557568073272705, Final Batch Loss: 0.7116842865943909\n",
      "Epoch 1580, Loss: 2.72857728600502, Final Batch Loss: 0.5650440454483032\n",
      "Epoch 1581, Loss: 2.8170603811740875, Final Batch Loss: 0.5677480101585388\n",
      "Epoch 1582, Loss: 2.8718084394931793, Final Batch Loss: 0.6930124163627625\n",
      "Epoch 1583, Loss: 2.8994012475013733, Final Batch Loss: 0.7584840059280396\n",
      "Epoch 1584, Loss: 2.499698281288147, Final Batch Loss: 0.34401005506515503\n",
      "Epoch 1585, Loss: 3.288795053958893, Final Batch Loss: 1.1302225589752197\n",
      "Epoch 1586, Loss: 2.5813403725624084, Final Batch Loss: 0.39646342396736145\n",
      "Epoch 1587, Loss: 2.7920923829078674, Final Batch Loss: 0.4973464012145996\n",
      "Epoch 1588, Loss: 2.8876097202301025, Final Batch Loss: 0.583836555480957\n",
      "Epoch 1589, Loss: 2.594126969575882, Final Batch Loss: 0.3064979016780853\n",
      "Epoch 1590, Loss: 2.4304023683071136, Final Batch Loss: 0.3585619032382965\n",
      "Epoch 1591, Loss: 3.2212910652160645, Final Batch Loss: 0.8761786818504333\n",
      "Epoch 1592, Loss: 2.6145046055316925, Final Batch Loss: 0.31032225489616394\n",
      "Epoch 1593, Loss: 3.147165596485138, Final Batch Loss: 0.9721741080284119\n",
      "Epoch 1594, Loss: 2.5955832302570343, Final Batch Loss: 0.46302780508995056\n",
      "Epoch 1595, Loss: 2.5458457469940186, Final Batch Loss: 0.3220038414001465\n",
      "Epoch 1596, Loss: 2.4952177107334137, Final Batch Loss: 0.29247626662254333\n",
      "Epoch 1597, Loss: 2.6305098831653595, Final Batch Loss: 0.29941871762275696\n",
      "Epoch 1598, Loss: 2.512507885694504, Final Batch Loss: 0.2696152925491333\n",
      "Epoch 1599, Loss: 2.622869908809662, Final Batch Loss: 0.5126288533210754\n",
      "Epoch 1600, Loss: 2.5009217262268066, Final Batch Loss: 0.3155200183391571\n",
      "Epoch 1601, Loss: 2.9574962854385376, Final Batch Loss: 0.7180091738700867\n",
      "Epoch 1602, Loss: 3.31386536359787, Final Batch Loss: 1.084974765777588\n",
      "Epoch 1603, Loss: 2.9573686122894287, Final Batch Loss: 0.7075856328010559\n",
      "Epoch 1604, Loss: 3.2239906191825867, Final Batch Loss: 0.9759048819541931\n",
      "Epoch 1605, Loss: 2.9743207693099976, Final Batch Loss: 0.7523787617683411\n",
      "Epoch 1606, Loss: 2.7411484718322754, Final Batch Loss: 0.5415706038475037\n",
      "Epoch 1607, Loss: 2.78082937002182, Final Batch Loss: 0.6706872582435608\n",
      "Epoch 1608, Loss: 3.008945882320404, Final Batch Loss: 0.8521084785461426\n",
      "Epoch 1609, Loss: 2.2953238487243652, Final Batch Loss: 0.2567611634731293\n",
      "Epoch 1610, Loss: 2.72345632314682, Final Batch Loss: 0.5191516280174255\n",
      "Epoch 1611, Loss: 2.6602535247802734, Final Batch Loss: 0.5722495913505554\n",
      "Epoch 1612, Loss: 2.6084867417812347, Final Batch Loss: 0.4097340404987335\n",
      "Epoch 1613, Loss: 2.6387506425380707, Final Batch Loss: 0.46841904520988464\n",
      "Epoch 1614, Loss: 3.1671544313430786, Final Batch Loss: 0.9431897401809692\n",
      "Epoch 1615, Loss: 2.9188312292099, Final Batch Loss: 0.7081364989280701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1616, Loss: 2.7716363668441772, Final Batch Loss: 0.6134732365608215\n",
      "Epoch 1617, Loss: 2.4901817739009857, Final Batch Loss: 0.17980161309242249\n",
      "Epoch 1618, Loss: 2.7015485763549805, Final Batch Loss: 0.5303148031234741\n",
      "Epoch 1619, Loss: 2.4739312529563904, Final Batch Loss: 0.32979631423950195\n",
      "Epoch 1620, Loss: 2.5661990344524384, Final Batch Loss: 0.4177648723125458\n",
      "Epoch 1621, Loss: 2.8532567024230957, Final Batch Loss: 0.6123615503311157\n",
      "Epoch 1622, Loss: 3.1442605555057526, Final Batch Loss: 0.9668386578559875\n",
      "Epoch 1623, Loss: 2.9370752573013306, Final Batch Loss: 0.5940473675727844\n",
      "Epoch 1624, Loss: 2.7542975544929504, Final Batch Loss: 0.5532739758491516\n",
      "Epoch 1625, Loss: 2.3293686658143997, Final Batch Loss: 0.1729380041360855\n",
      "Epoch 1626, Loss: 2.5382805466651917, Final Batch Loss: 0.3309326767921448\n",
      "Epoch 1627, Loss: 2.910719394683838, Final Batch Loss: 0.60425865650177\n",
      "Epoch 1628, Loss: 2.954170346260071, Final Batch Loss: 0.674152672290802\n",
      "Epoch 1629, Loss: 2.8083895444869995, Final Batch Loss: 0.6891946792602539\n",
      "Epoch 1630, Loss: 2.389851897954941, Final Batch Loss: 0.39236170053482056\n",
      "Epoch 1631, Loss: 2.650460869073868, Final Batch Loss: 0.40083083510398865\n",
      "Epoch 1632, Loss: 2.7995822727680206, Final Batch Loss: 0.6207832098007202\n",
      "Epoch 1633, Loss: 2.7750611901283264, Final Batch Loss: 0.5874710083007812\n",
      "Epoch 1634, Loss: 2.512116700410843, Final Batch Loss: 0.3528604507446289\n",
      "Epoch 1635, Loss: 2.745466470718384, Final Batch Loss: 0.6530808806419373\n",
      "Epoch 1636, Loss: 2.7602952420711517, Final Batch Loss: 0.5822850465774536\n",
      "Epoch 1637, Loss: 2.6910790503025055, Final Batch Loss: 0.4582059681415558\n",
      "Epoch 1638, Loss: 2.6780853271484375, Final Batch Loss: 0.5233336687088013\n",
      "Epoch 1639, Loss: 2.7264793515205383, Final Batch Loss: 0.5007410049438477\n",
      "Epoch 1640, Loss: 2.762249141931534, Final Batch Loss: 0.6116809844970703\n",
      "Epoch 1641, Loss: 2.4653970897197723, Final Batch Loss: 0.4314937889575958\n",
      "Epoch 1642, Loss: 2.707221895456314, Final Batch Loss: 0.4890497326850891\n",
      "Epoch 1643, Loss: 2.7320793867111206, Final Batch Loss: 0.4658381938934326\n",
      "Epoch 1644, Loss: 2.885764241218567, Final Batch Loss: 0.567204475402832\n",
      "Epoch 1645, Loss: 2.640172928571701, Final Batch Loss: 0.5592566132545471\n",
      "Epoch 1646, Loss: 2.7884201109409332, Final Batch Loss: 0.661291241645813\n",
      "Epoch 1647, Loss: 2.222939059138298, Final Batch Loss: 0.1512458175420761\n",
      "Epoch 1648, Loss: 2.556419938802719, Final Batch Loss: 0.3796144425868988\n",
      "Epoch 1649, Loss: 2.4069089591503143, Final Batch Loss: 0.3280431628227234\n",
      "Epoch 1650, Loss: 2.317590653896332, Final Batch Loss: 0.28556784987449646\n",
      "Epoch 1651, Loss: 2.9952282905578613, Final Batch Loss: 0.7699676156044006\n",
      "Epoch 1652, Loss: 2.7469267547130585, Final Batch Loss: 0.6697906255722046\n",
      "Epoch 1653, Loss: 2.8368472158908844, Final Batch Loss: 0.6595169901847839\n",
      "Epoch 1654, Loss: 2.7463971376419067, Final Batch Loss: 0.591005265712738\n",
      "Epoch 1655, Loss: 2.5377185344696045, Final Batch Loss: 0.3840249478816986\n",
      "Epoch 1656, Loss: 2.7459584772586823, Final Batch Loss: 0.6024153828620911\n",
      "Epoch 1657, Loss: 2.742522895336151, Final Batch Loss: 0.5619011521339417\n",
      "Epoch 1658, Loss: 2.4305417835712433, Final Batch Loss: 0.33368590474128723\n",
      "Epoch 1659, Loss: 2.6660777926445007, Final Batch Loss: 0.5256605744361877\n",
      "Epoch 1660, Loss: 2.558917284011841, Final Batch Loss: 0.22979867458343506\n",
      "Epoch 1661, Loss: 2.6832138895988464, Final Batch Loss: 0.40455883741378784\n",
      "Epoch 1662, Loss: 2.3553386628627777, Final Batch Loss: 0.2147561013698578\n",
      "Epoch 1663, Loss: 2.6741020381450653, Final Batch Loss: 0.5704625844955444\n",
      "Epoch 1664, Loss: 2.7167070508003235, Final Batch Loss: 0.5080641508102417\n",
      "Epoch 1665, Loss: 2.601916342973709, Final Batch Loss: 0.4773871600627899\n",
      "Epoch 1666, Loss: 2.5352462828159332, Final Batch Loss: 0.513309121131897\n",
      "Epoch 1667, Loss: 2.637982487678528, Final Batch Loss: 0.37134647369384766\n",
      "Epoch 1668, Loss: 2.6278195679187775, Final Batch Loss: 0.38700294494628906\n",
      "Epoch 1669, Loss: 2.387810230255127, Final Batch Loss: 0.32395699620246887\n",
      "Epoch 1670, Loss: 2.8274789452552795, Final Batch Loss: 0.5770195126533508\n",
      "Epoch 1671, Loss: 2.740315169095993, Final Batch Loss: 0.31232377886772156\n",
      "Epoch 1672, Loss: 2.535763204097748, Final Batch Loss: 0.3571665287017822\n",
      "Epoch 1673, Loss: 2.7492964565753937, Final Batch Loss: 0.7013789415359497\n",
      "Epoch 1674, Loss: 2.607577294111252, Final Batch Loss: 0.510455310344696\n",
      "Epoch 1675, Loss: 3.040756404399872, Final Batch Loss: 0.8507267832756042\n",
      "Epoch 1676, Loss: 2.8203123807907104, Final Batch Loss: 0.6626943349838257\n",
      "Epoch 1677, Loss: 2.6927288472652435, Final Batch Loss: 0.6345697045326233\n",
      "Epoch 1678, Loss: 2.75021168589592, Final Batch Loss: 0.3872373402118683\n",
      "Epoch 1679, Loss: 4.530593663454056, Final Batch Loss: 2.269498109817505\n",
      "Epoch 1680, Loss: 3.205331951379776, Final Batch Loss: 1.038683295249939\n",
      "Epoch 1681, Loss: 2.501931667327881, Final Batch Loss: 0.3683544993400574\n",
      "Epoch 1682, Loss: 2.7942432165145874, Final Batch Loss: 0.6357156038284302\n",
      "Epoch 1683, Loss: 2.7021391689777374, Final Batch Loss: 0.3135972321033478\n",
      "Epoch 1684, Loss: 2.4697515666484833, Final Batch Loss: 0.4142248034477234\n",
      "Epoch 1685, Loss: 2.4019801318645477, Final Batch Loss: 0.2543613016605377\n",
      "Epoch 1686, Loss: 3.0787994861602783, Final Batch Loss: 0.9202814102172852\n",
      "Epoch 1687, Loss: 2.4628692865371704, Final Batch Loss: 0.2630477845668793\n",
      "Epoch 1688, Loss: 2.6334995925426483, Final Batch Loss: 0.5806947350502014\n",
      "Epoch 1689, Loss: 2.7495101392269135, Final Batch Loss: 0.6749840378761292\n",
      "Epoch 1690, Loss: 2.629661440849304, Final Batch Loss: 0.47791314125061035\n",
      "Epoch 1691, Loss: 2.6540268659591675, Final Batch Loss: 0.5589603185653687\n",
      "Epoch 1692, Loss: 2.5638289153575897, Final Batch Loss: 0.45095542073249817\n",
      "Epoch 1693, Loss: 2.9628626704216003, Final Batch Loss: 0.6851081252098083\n",
      "Epoch 1694, Loss: 2.392013430595398, Final Batch Loss: 0.44583505392074585\n",
      "Epoch 1695, Loss: 2.5231913030147552, Final Batch Loss: 0.3569595515727997\n",
      "Epoch 1696, Loss: 3.0217906534671783, Final Batch Loss: 0.916559100151062\n",
      "Epoch 1697, Loss: 2.581494241952896, Final Batch Loss: 0.271752268075943\n",
      "Epoch 1698, Loss: 2.2445418685674667, Final Batch Loss: 0.19752170145511627\n",
      "Epoch 1699, Loss: 2.5738105177879333, Final Batch Loss: 0.39550358057022095\n",
      "Epoch 1700, Loss: 2.610643684864044, Final Batch Loss: 0.5098220705986023\n",
      "Epoch 1701, Loss: 2.702038884162903, Final Batch Loss: 0.4446852207183838\n",
      "Epoch 1702, Loss: 2.466216057538986, Final Batch Loss: 0.2723921239376068\n",
      "Epoch 1703, Loss: 2.9503583908081055, Final Batch Loss: 0.6970592141151428\n",
      "Epoch 1704, Loss: 2.2535484731197357, Final Batch Loss: 0.23443284630775452\n",
      "Epoch 1705, Loss: 2.3176166266202927, Final Batch Loss: 0.21362800896167755\n",
      "Epoch 1706, Loss: 2.5666222870349884, Final Batch Loss: 0.41037413477897644\n",
      "Epoch 1707, Loss: 2.774179309606552, Final Batch Loss: 0.6425089836120605\n",
      "Epoch 1708, Loss: 2.3991653323173523, Final Batch Loss: 0.41790255904197693\n",
      "Epoch 1709, Loss: 2.3260888308286667, Final Batch Loss: 0.14976422488689423\n",
      "Epoch 1710, Loss: 2.6394676566123962, Final Batch Loss: 0.6454749703407288\n",
      "Epoch 1711, Loss: 2.7266075909137726, Final Batch Loss: 0.43014416098594666\n",
      "Epoch 1712, Loss: 2.5132535696029663, Final Batch Loss: 0.4271533191204071\n",
      "Epoch 1713, Loss: 3.664240002632141, Final Batch Loss: 1.400951623916626\n",
      "Epoch 1714, Loss: 2.47578302025795, Final Batch Loss: 0.31753912568092346\n",
      "Epoch 1715, Loss: 2.7527453005313873, Final Batch Loss: 0.7130621671676636\n",
      "Epoch 1716, Loss: 2.634820520877838, Final Batch Loss: 0.34995144605636597\n",
      "Epoch 1717, Loss: 2.575218230485916, Final Batch Loss: 0.42374342679977417\n",
      "Epoch 1718, Loss: 2.654270738363266, Final Batch Loss: 0.5401122570037842\n",
      "Epoch 1719, Loss: 2.25971919298172, Final Batch Loss: 0.2624140679836273\n",
      "Epoch 1720, Loss: 2.5817327201366425, Final Batch Loss: 0.2840091288089752\n",
      "Epoch 1721, Loss: 2.1698940694332123, Final Batch Loss: 0.14887556433677673\n",
      "Epoch 1722, Loss: 2.666276454925537, Final Batch Loss: 0.5665100812911987\n",
      "Epoch 1723, Loss: 3.237006664276123, Final Batch Loss: 1.036125898361206\n",
      "Epoch 1724, Loss: 3.014407992362976, Final Batch Loss: 0.8928272128105164\n",
      "Epoch 1725, Loss: 3.0426822006702423, Final Batch Loss: 0.9667609333992004\n",
      "Epoch 1726, Loss: 2.741506338119507, Final Batch Loss: 0.8071602582931519\n",
      "Epoch 1727, Loss: 3.176155596971512, Final Batch Loss: 1.0147589445114136\n",
      "Epoch 1728, Loss: 3.4770625233650208, Final Batch Loss: 1.3494952917099\n",
      "Epoch 1729, Loss: 2.5626276433467865, Final Batch Loss: 0.3566143810749054\n",
      "Epoch 1730, Loss: 2.9750261306762695, Final Batch Loss: 0.8205757737159729\n",
      "Epoch 1731, Loss: 2.521340936422348, Final Batch Loss: 0.31973347067832947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1732, Loss: 2.571283370256424, Final Batch Loss: 0.44686076045036316\n",
      "Epoch 1733, Loss: 2.7414492070674896, Final Batch Loss: 0.5622275471687317\n",
      "Epoch 1734, Loss: 2.473215937614441, Final Batch Loss: 0.5141423940658569\n",
      "Epoch 1735, Loss: 2.7937631011009216, Final Batch Loss: 0.6133829951286316\n",
      "Epoch 1736, Loss: 2.6020240783691406, Final Batch Loss: 0.500668466091156\n",
      "Epoch 1737, Loss: 2.543859899044037, Final Batch Loss: 0.4197423756122589\n",
      "Epoch 1738, Loss: 3.0262848138809204, Final Batch Loss: 0.913657009601593\n",
      "Epoch 1739, Loss: 2.7759362161159515, Final Batch Loss: 0.7270621657371521\n",
      "Epoch 1740, Loss: 2.698087215423584, Final Batch Loss: 0.5452660918235779\n",
      "Epoch 1741, Loss: 2.286976546049118, Final Batch Loss: 0.23433145880699158\n",
      "Epoch 1742, Loss: 2.2737885266542435, Final Batch Loss: 0.19373981654644012\n",
      "Epoch 1743, Loss: 2.5684997737407684, Final Batch Loss: 0.5403279066085815\n",
      "Epoch 1744, Loss: 2.8305851221084595, Final Batch Loss: 0.7693864107131958\n",
      "Epoch 1745, Loss: 2.6884084343910217, Final Batch Loss: 0.5405799150466919\n",
      "Epoch 1746, Loss: 2.4539006054401398, Final Batch Loss: 0.4869621694087982\n",
      "Epoch 1747, Loss: 2.5654438734054565, Final Batch Loss: 0.43168026208877563\n",
      "Epoch 1748, Loss: 2.2697733491659164, Final Batch Loss: 0.11759419739246368\n",
      "Epoch 1749, Loss: 2.6907088458538055, Final Batch Loss: 0.6786534190177917\n",
      "Epoch 1750, Loss: 2.4023903608322144, Final Batch Loss: 0.4834699034690857\n",
      "Epoch 1751, Loss: 2.278364270925522, Final Batch Loss: 0.23723328113555908\n",
      "Epoch 1752, Loss: 2.6212231814861298, Final Batch Loss: 0.5119471549987793\n",
      "Epoch 1753, Loss: 2.7931878864765167, Final Batch Loss: 0.7474352717399597\n",
      "Epoch 1754, Loss: 2.888927936553955, Final Batch Loss: 0.790149986743927\n",
      "Epoch 1755, Loss: 2.8205524384975433, Final Batch Loss: 0.758741021156311\n",
      "Epoch 1756, Loss: 2.4234164357185364, Final Batch Loss: 0.2893616557121277\n",
      "Epoch 1757, Loss: 2.855232834815979, Final Batch Loss: 0.6530674695968628\n",
      "Epoch 1758, Loss: 2.5174651741981506, Final Batch Loss: 0.48480135202407837\n",
      "Epoch 1759, Loss: 2.620341181755066, Final Batch Loss: 0.5922605395317078\n",
      "Epoch 1760, Loss: 2.5310099720954895, Final Batch Loss: 0.5293408036231995\n",
      "Epoch 1761, Loss: 3.301724374294281, Final Batch Loss: 1.2165559530258179\n",
      "Epoch 1762, Loss: 2.4043209552764893, Final Batch Loss: 0.2815149128437042\n",
      "Epoch 1763, Loss: 2.531627058982849, Final Batch Loss: 0.5649505257606506\n",
      "Epoch 1764, Loss: 2.851453959941864, Final Batch Loss: 0.7613210082054138\n",
      "Epoch 1765, Loss: 2.5996783673763275, Final Batch Loss: 0.44742298126220703\n",
      "Epoch 1766, Loss: 2.4312801361083984, Final Batch Loss: 0.4570729434490204\n",
      "Epoch 1767, Loss: 3.042874425649643, Final Batch Loss: 1.0132898092269897\n",
      "Epoch 1768, Loss: 2.827139049768448, Final Batch Loss: 0.7031992077827454\n",
      "Epoch 1769, Loss: 2.883110135793686, Final Batch Loss: 0.7568174004554749\n",
      "Epoch 1770, Loss: 2.8061724603176117, Final Batch Loss: 0.6067904829978943\n",
      "Epoch 1771, Loss: 2.371906578540802, Final Batch Loss: 0.16313329339027405\n",
      "Epoch 1772, Loss: 2.656777948141098, Final Batch Loss: 0.473698228597641\n",
      "Epoch 1773, Loss: 3.006797134876251, Final Batch Loss: 0.8440079689025879\n",
      "Epoch 1774, Loss: 2.798891305923462, Final Batch Loss: 0.7799217104911804\n",
      "Epoch 1775, Loss: 3.2949259877204895, Final Batch Loss: 1.1057127714157104\n",
      "Epoch 1776, Loss: 2.5946371257305145, Final Batch Loss: 0.5110843777656555\n",
      "Epoch 1777, Loss: 2.703747421503067, Final Batch Loss: 0.4129863381385803\n",
      "Epoch 1778, Loss: 2.6294854283332825, Final Batch Loss: 0.5400298833847046\n",
      "Epoch 1779, Loss: 2.466444492340088, Final Batch Loss: 0.45359888672828674\n",
      "Epoch 1780, Loss: 2.526345819234848, Final Batch Loss: 0.47143492102622986\n",
      "Epoch 1781, Loss: 2.6726219058036804, Final Batch Loss: 0.5808778405189514\n",
      "Epoch 1782, Loss: 2.9787704944610596, Final Batch Loss: 0.9962077140808105\n",
      "Epoch 1783, Loss: 2.3680175840854645, Final Batch Loss: 0.25687211751937866\n",
      "Epoch 1784, Loss: 2.7054381668567657, Final Batch Loss: 0.7015557289123535\n",
      "Epoch 1785, Loss: 2.3222233057022095, Final Batch Loss: 0.17415916919708252\n",
      "Epoch 1786, Loss: 2.8819345831871033, Final Batch Loss: 0.7966755628585815\n",
      "Epoch 1787, Loss: 2.3578999042510986, Final Batch Loss: 0.26108306646347046\n",
      "Epoch 1788, Loss: 2.969257950782776, Final Batch Loss: 0.9042229056358337\n",
      "Epoch 1789, Loss: 2.2100989520549774, Final Batch Loss: 0.13588014245033264\n",
      "Epoch 1790, Loss: 2.4661861658096313, Final Batch Loss: 0.38681986927986145\n",
      "Epoch 1791, Loss: 2.8040528893470764, Final Batch Loss: 0.7401935458183289\n",
      "Epoch 1792, Loss: 2.5136709809303284, Final Batch Loss: 0.3911125659942627\n",
      "Epoch 1793, Loss: 2.474347233772278, Final Batch Loss: 0.4208510220050812\n",
      "Epoch 1794, Loss: 2.6073863208293915, Final Batch Loss: 0.45084914565086365\n",
      "Epoch 1795, Loss: 3.0782013833522797, Final Batch Loss: 1.0426074266433716\n",
      "Epoch 1796, Loss: 2.316574603319168, Final Batch Loss: 0.31937918066978455\n",
      "Epoch 1797, Loss: 2.4817102253437042, Final Batch Loss: 0.46283674240112305\n",
      "Epoch 1798, Loss: 2.6828873455524445, Final Batch Loss: 0.7218393683433533\n",
      "Epoch 1799, Loss: 2.959733009338379, Final Batch Loss: 0.7809901237487793\n",
      "Epoch 1800, Loss: 2.3103003576397896, Final Batch Loss: 0.12298540025949478\n",
      "Epoch 1801, Loss: 2.6392478942871094, Final Batch Loss: 0.41692569851875305\n",
      "Epoch 1802, Loss: 2.5542459785938263, Final Batch Loss: 0.44135981798171997\n",
      "Epoch 1803, Loss: 3.008383631706238, Final Batch Loss: 0.863131582736969\n",
      "Epoch 1804, Loss: 2.5250084698200226, Final Batch Loss: 0.37542539834976196\n",
      "Epoch 1805, Loss: 2.5777964293956757, Final Batch Loss: 0.5134853720664978\n",
      "Epoch 1806, Loss: 2.4960546791553497, Final Batch Loss: 0.4409172236919403\n",
      "Epoch 1807, Loss: 2.578689157962799, Final Batch Loss: 0.6231160759925842\n",
      "Epoch 1808, Loss: 2.658095568418503, Final Batch Loss: 0.7123764753341675\n",
      "Epoch 1809, Loss: 2.996883451938629, Final Batch Loss: 0.8929896950721741\n",
      "Epoch 1810, Loss: 2.846994400024414, Final Batch Loss: 0.6837688684463501\n",
      "Epoch 1811, Loss: 2.2917331755161285, Final Batch Loss: 0.3207685947418213\n",
      "Epoch 1812, Loss: 2.9686746895313263, Final Batch Loss: 0.955064594745636\n",
      "Epoch 1813, Loss: 2.538249433040619, Final Batch Loss: 0.5142565965652466\n",
      "Epoch 1814, Loss: 2.7784575819969177, Final Batch Loss: 0.7979560494422913\n",
      "Epoch 1815, Loss: 2.447828471660614, Final Batch Loss: 0.3230981230735779\n",
      "Epoch 1816, Loss: 2.3575365841388702, Final Batch Loss: 0.2521231770515442\n",
      "Epoch 1817, Loss: 2.476738542318344, Final Batch Loss: 0.31731197237968445\n",
      "Epoch 1818, Loss: 2.50967276096344, Final Batch Loss: 0.41722509264945984\n",
      "Epoch 1819, Loss: 2.9000585973262787, Final Batch Loss: 0.8798924088478088\n",
      "Epoch 1820, Loss: 2.556567072868347, Final Batch Loss: 0.46187707781791687\n",
      "Epoch 1821, Loss: 2.541125386953354, Final Batch Loss: 0.41340476274490356\n",
      "Epoch 1822, Loss: 2.4174221009016037, Final Batch Loss: 0.19701068103313446\n",
      "Epoch 1823, Loss: 2.673229992389679, Final Batch Loss: 0.6334649920463562\n",
      "Epoch 1824, Loss: 2.5795670449733734, Final Batch Loss: 0.5282601714134216\n",
      "Epoch 1825, Loss: 2.52216699719429, Final Batch Loss: 0.3182443678379059\n",
      "Epoch 1826, Loss: 2.4812585711479187, Final Batch Loss: 0.3760887086391449\n",
      "Epoch 1827, Loss: 2.3188392221927643, Final Batch Loss: 0.323775053024292\n",
      "Epoch 1828, Loss: 2.7575489282608032, Final Batch Loss: 0.7839771509170532\n",
      "Epoch 1829, Loss: 2.0944535583257675, Final Batch Loss: 0.08515666425228119\n",
      "Epoch 1830, Loss: 2.5562567114830017, Final Batch Loss: 0.5738487839698792\n",
      "Epoch 1831, Loss: 2.9867160618305206, Final Batch Loss: 0.9786025285720825\n",
      "Epoch 1832, Loss: 2.253743678331375, Final Batch Loss: 0.17147567868232727\n",
      "Epoch 1833, Loss: 2.703744411468506, Final Batch Loss: 0.657045841217041\n",
      "Epoch 1834, Loss: 2.5147116482257843, Final Batch Loss: 0.3540239930152893\n",
      "Epoch 1835, Loss: 2.6479007601737976, Final Batch Loss: 0.5395839810371399\n",
      "Epoch 1836, Loss: 2.5877353847026825, Final Batch Loss: 0.48791906237602234\n",
      "Epoch 1837, Loss: 2.6151372492313385, Final Batch Loss: 0.48445191979408264\n",
      "Epoch 1838, Loss: 2.4067622423171997, Final Batch Loss: 0.42804720997810364\n",
      "Epoch 1839, Loss: 2.3582048267126083, Final Batch Loss: 0.22034065425395966\n",
      "Epoch 1840, Loss: 2.3626904487609863, Final Batch Loss: 0.20991778373718262\n",
      "Epoch 1841, Loss: 2.672581523656845, Final Batch Loss: 0.6406782865524292\n",
      "Epoch 1842, Loss: 2.7960304617881775, Final Batch Loss: 0.5352810621261597\n",
      "Epoch 1843, Loss: 2.695658564567566, Final Batch Loss: 0.6042246222496033\n",
      "Epoch 1844, Loss: 2.5238963663578033, Final Batch Loss: 0.3436269462108612\n",
      "Epoch 1845, Loss: 2.5138716399669647, Final Batch Loss: 0.3652637004852295\n",
      "Epoch 1846, Loss: 2.662287712097168, Final Batch Loss: 0.5042281150817871\n",
      "Epoch 1847, Loss: 2.3717202842235565, Final Batch Loss: 0.34470322728157043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1848, Loss: 2.6817322075366974, Final Batch Loss: 0.5599322319030762\n",
      "Epoch 1849, Loss: 2.7449517250061035, Final Batch Loss: 0.5505462288856506\n",
      "Epoch 1850, Loss: 2.4594237208366394, Final Batch Loss: 0.3545714318752289\n",
      "Epoch 1851, Loss: 2.3027939796447754, Final Batch Loss: 0.40626707673072815\n",
      "Epoch 1852, Loss: 2.724854737520218, Final Batch Loss: 0.7411447763442993\n",
      "Epoch 1853, Loss: 2.5532802045345306, Final Batch Loss: 0.44220155477523804\n",
      "Epoch 1854, Loss: 2.2512830048799515, Final Batch Loss: 0.24570854008197784\n",
      "Epoch 1855, Loss: 2.3439522236585617, Final Batch Loss: 0.22829259932041168\n",
      "Epoch 1856, Loss: 2.55271977186203, Final Batch Loss: 0.4491449296474457\n",
      "Epoch 1857, Loss: 2.4751827120780945, Final Batch Loss: 0.4186426103115082\n",
      "Epoch 1858, Loss: 2.4950398206710815, Final Batch Loss: 0.37047046422958374\n",
      "Epoch 1859, Loss: 2.1762433275580406, Final Batch Loss: 0.10307156294584274\n",
      "Epoch 1860, Loss: 2.9169867634773254, Final Batch Loss: 0.8961701989173889\n",
      "Epoch 1861, Loss: 2.614479809999466, Final Batch Loss: 0.5078484416007996\n",
      "Epoch 1862, Loss: 2.312023401260376, Final Batch Loss: 0.2926402688026428\n",
      "Epoch 1863, Loss: 2.205732375383377, Final Batch Loss: 0.17582178115844727\n",
      "Epoch 1864, Loss: 2.323677361011505, Final Batch Loss: 0.4525216519832611\n",
      "Epoch 1865, Loss: 2.3819424510002136, Final Batch Loss: 0.2628299593925476\n",
      "Epoch 1866, Loss: 2.739987850189209, Final Batch Loss: 0.5820425748825073\n",
      "Epoch 1867, Loss: 2.3946502655744553, Final Batch Loss: 0.19190393388271332\n",
      "Epoch 1868, Loss: 2.4017210006713867, Final Batch Loss: 0.51920086145401\n",
      "Epoch 1869, Loss: 2.617128401994705, Final Batch Loss: 0.6013168692588806\n",
      "Epoch 1870, Loss: 2.2611065208911896, Final Batch Loss: 0.4311961233615875\n",
      "Epoch 1871, Loss: 2.2540613561868668, Final Batch Loss: 0.14554463326931\n",
      "Epoch 1872, Loss: 2.584171712398529, Final Batch Loss: 0.5324466824531555\n",
      "Epoch 1873, Loss: 3.107426017522812, Final Batch Loss: 1.0853846073150635\n",
      "Epoch 1874, Loss: 2.7940292060375214, Final Batch Loss: 0.6424528360366821\n",
      "Epoch 1875, Loss: 2.4369115829467773, Final Batch Loss: 0.48274821043014526\n",
      "Epoch 1876, Loss: 2.3371016681194305, Final Batch Loss: 0.41567525267601013\n",
      "Epoch 1877, Loss: 2.608867794275284, Final Batch Loss: 0.4909805953502655\n",
      "Epoch 1878, Loss: 2.631138563156128, Final Batch Loss: 0.6157535314559937\n",
      "Epoch 1879, Loss: 2.213235542178154, Final Batch Loss: 0.147149458527565\n",
      "Epoch 1880, Loss: 2.2802422642707825, Final Batch Loss: 0.36403441429138184\n",
      "Epoch 1881, Loss: 2.5756691098213196, Final Batch Loss: 0.5780975222587585\n",
      "Epoch 1882, Loss: 2.60557621717453, Final Batch Loss: 0.49208906292915344\n",
      "Epoch 1883, Loss: 2.4371079802513123, Final Batch Loss: 0.5311617851257324\n",
      "Epoch 1884, Loss: 2.2718763947486877, Final Batch Loss: 0.329039603471756\n",
      "Epoch 1885, Loss: 2.0729431957006454, Final Batch Loss: 0.14866818487644196\n",
      "Epoch 1886, Loss: 2.433838278055191, Final Batch Loss: 0.42115411162376404\n",
      "Epoch 1887, Loss: 2.325624406337738, Final Batch Loss: 0.1812974512577057\n",
      "Epoch 1888, Loss: 2.5777748823165894, Final Batch Loss: 0.5657202005386353\n",
      "Epoch 1889, Loss: 2.4458844661712646, Final Batch Loss: 0.4366662800312042\n",
      "Epoch 1890, Loss: 2.3982769548892975, Final Batch Loss: 0.3409700393676758\n",
      "Epoch 1891, Loss: 2.460425227880478, Final Batch Loss: 0.4356129467487335\n",
      "Epoch 1892, Loss: 2.8088728189468384, Final Batch Loss: 0.7779844403266907\n",
      "Epoch 1893, Loss: 2.511981278657913, Final Batch Loss: 0.5148828625679016\n",
      "Epoch 1894, Loss: 2.4206182658672333, Final Batch Loss: 0.3818238079547882\n",
      "Epoch 1895, Loss: 2.7215490639209747, Final Batch Loss: 0.662350594997406\n",
      "Epoch 1896, Loss: 2.664131611585617, Final Batch Loss: 0.7089539766311646\n",
      "Epoch 1897, Loss: 2.591062068939209, Final Batch Loss: 0.6117897033691406\n",
      "Epoch 1898, Loss: 2.9502013325691223, Final Batch Loss: 0.9157743453979492\n",
      "Epoch 1899, Loss: 2.1141154915094376, Final Batch Loss: 0.16392730176448822\n",
      "Epoch 1900, Loss: 2.3559386134147644, Final Batch Loss: 0.5670174360275269\n",
      "Epoch 1901, Loss: 2.816691040992737, Final Batch Loss: 0.6460108160972595\n",
      "Epoch 1902, Loss: 2.3305731415748596, Final Batch Loss: 0.2891540825366974\n",
      "Epoch 1903, Loss: 2.2584567964076996, Final Batch Loss: 0.291901171207428\n",
      "Epoch 1904, Loss: 3.4616625607013702, Final Batch Loss: 1.3931738138198853\n",
      "Epoch 1905, Loss: 3.5437350273132324, Final Batch Loss: 1.4657827615737915\n",
      "Epoch 1906, Loss: 2.7191068530082703, Final Batch Loss: 0.5397897958755493\n",
      "Epoch 1907, Loss: 2.784184366464615, Final Batch Loss: 0.46810320019721985\n",
      "Epoch 1908, Loss: 2.8288739919662476, Final Batch Loss: 0.608557403087616\n",
      "Epoch 1909, Loss: 2.713842451572418, Final Batch Loss: 0.4350523352622986\n",
      "Epoch 1910, Loss: 2.333735242486, Final Batch Loss: 0.155867800116539\n",
      "Epoch 1911, Loss: 2.4114876985549927, Final Batch Loss: 0.3702825903892517\n",
      "Epoch 1912, Loss: 2.8640449941158295, Final Batch Loss: 0.7855585217475891\n",
      "Epoch 1913, Loss: 3.117167830467224, Final Batch Loss: 1.088982105255127\n",
      "Epoch 1914, Loss: 2.652573138475418, Final Batch Loss: 0.6532682776451111\n",
      "Epoch 1915, Loss: 2.712440252304077, Final Batch Loss: 0.620358943939209\n",
      "Epoch 1916, Loss: 2.3566622734069824, Final Batch Loss: 0.3221709132194519\n",
      "Epoch 1917, Loss: 2.6967466175556183, Final Batch Loss: 0.6738725900650024\n",
      "Epoch 1918, Loss: 2.503202974796295, Final Batch Loss: 0.5311778783798218\n",
      "Epoch 1919, Loss: 2.632081151008606, Final Batch Loss: 0.37195223569869995\n",
      "Epoch 1920, Loss: 2.2170985639095306, Final Batch Loss: 0.13759616017341614\n",
      "Epoch 1921, Loss: 2.7335015535354614, Final Batch Loss: 0.7105888724327087\n",
      "Epoch 1922, Loss: 2.1494679152965546, Final Batch Loss: 0.14803609251976013\n",
      "Epoch 1923, Loss: 2.4822514057159424, Final Batch Loss: 0.5317224860191345\n",
      "Epoch 1924, Loss: 2.960914760828018, Final Batch Loss: 1.0665113925933838\n",
      "Epoch 1925, Loss: 2.302213966846466, Final Batch Loss: 0.40409138798713684\n",
      "Epoch 1926, Loss: 2.5773959159851074, Final Batch Loss: 0.4211147427558899\n",
      "Epoch 1927, Loss: 2.488640308380127, Final Batch Loss: 0.4560803472995758\n",
      "Epoch 1928, Loss: 2.9585588574409485, Final Batch Loss: 0.9813822507858276\n",
      "Epoch 1929, Loss: 2.906121611595154, Final Batch Loss: 0.8510032892227173\n",
      "Epoch 1930, Loss: 2.483130067586899, Final Batch Loss: 0.41444921493530273\n",
      "Epoch 1931, Loss: 2.462617188692093, Final Batch Loss: 0.44326701760292053\n",
      "Epoch 1932, Loss: 2.3438948690891266, Final Batch Loss: 0.40897268056869507\n",
      "Epoch 1933, Loss: 2.379718393087387, Final Batch Loss: 0.37094804644584656\n",
      "Epoch 1934, Loss: 2.561491310596466, Final Batch Loss: 0.5754814147949219\n",
      "Epoch 1935, Loss: 2.713054269552231, Final Batch Loss: 0.6909705996513367\n",
      "Epoch 1936, Loss: 2.4829047322273254, Final Batch Loss: 0.4312348961830139\n",
      "Epoch 1937, Loss: 2.497556656599045, Final Batch Loss: 0.46395179629325867\n",
      "Epoch 1938, Loss: 2.6015261709690094, Final Batch Loss: 0.518785297870636\n",
      "Epoch 1939, Loss: 2.4799987077713013, Final Batch Loss: 0.5224663615226746\n",
      "Epoch 1940, Loss: 2.2667336016893387, Final Batch Loss: 0.155427947640419\n",
      "Epoch 1941, Loss: 2.317254513502121, Final Batch Loss: 0.3942503035068512\n",
      "Epoch 1942, Loss: 2.3392807245254517, Final Batch Loss: 0.45655912160873413\n",
      "Epoch 1943, Loss: 2.6232217252254486, Final Batch Loss: 0.525997519493103\n",
      "Epoch 1944, Loss: 2.8396352231502533, Final Batch Loss: 1.0187050104141235\n",
      "Epoch 1945, Loss: 2.64558944106102, Final Batch Loss: 0.634836733341217\n",
      "Epoch 1946, Loss: 2.469888150691986, Final Batch Loss: 0.47286176681518555\n",
      "Epoch 1947, Loss: 2.69386488199234, Final Batch Loss: 0.6647338271141052\n",
      "Epoch 1948, Loss: 2.350025475025177, Final Batch Loss: 0.29801076650619507\n",
      "Epoch 1949, Loss: 2.497181236743927, Final Batch Loss: 0.40618911385536194\n",
      "Epoch 1950, Loss: 2.2957135438919067, Final Batch Loss: 0.35043808817863464\n",
      "Epoch 1951, Loss: 2.4312629401683807, Final Batch Loss: 0.3014327883720398\n",
      "Epoch 1952, Loss: 2.3031885027885437, Final Batch Loss: 0.3246181905269623\n",
      "Epoch 1953, Loss: 2.7395070791244507, Final Batch Loss: 0.7914032936096191\n",
      "Epoch 1954, Loss: 2.626296281814575, Final Batch Loss: 0.5684940814971924\n",
      "Epoch 1955, Loss: 2.7571509778499603, Final Batch Loss: 0.7596989274024963\n",
      "Epoch 1956, Loss: 2.098065420985222, Final Batch Loss: 0.2435026317834854\n",
      "Epoch 1957, Loss: 2.5448074638843536, Final Batch Loss: 0.6453648805618286\n",
      "Epoch 1958, Loss: 3.0378819704055786, Final Batch Loss: 0.9154793620109558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1959, Loss: 2.7508234679698944, Final Batch Loss: 0.6090793609619141\n",
      "Epoch 1960, Loss: 2.8725055158138275, Final Batch Loss: 0.8158429265022278\n",
      "Epoch 1961, Loss: 2.434043228626251, Final Batch Loss: 0.5212628245353699\n",
      "Epoch 1962, Loss: 2.1646724343299866, Final Batch Loss: 0.13912776112556458\n",
      "Epoch 1963, Loss: 2.4678887128829956, Final Batch Loss: 0.44858571887016296\n",
      "Epoch 1964, Loss: 2.3139494359493256, Final Batch Loss: 0.2648458778858185\n",
      "Epoch 1965, Loss: 2.6054771542549133, Final Batch Loss: 0.540643036365509\n",
      "Epoch 1966, Loss: 2.501961052417755, Final Batch Loss: 0.5455944538116455\n",
      "Epoch 1967, Loss: 2.663255959749222, Final Batch Loss: 0.6766782402992249\n",
      "Epoch 1968, Loss: 2.6576226353645325, Final Batch Loss: 0.5440717935562134\n",
      "Epoch 1969, Loss: 2.6767870485782623, Final Batch Loss: 0.668562114238739\n",
      "Epoch 1970, Loss: 2.447456479072571, Final Batch Loss: 0.43703994154930115\n",
      "Epoch 1971, Loss: 2.5091516077518463, Final Batch Loss: 0.43687230348587036\n",
      "Epoch 1972, Loss: 2.7222379446029663, Final Batch Loss: 0.7379166483879089\n",
      "Epoch 1973, Loss: 2.700461268424988, Final Batch Loss: 0.7607043981552124\n",
      "Epoch 1974, Loss: 2.590356796979904, Final Batch Loss: 0.643375813961029\n",
      "Epoch 1975, Loss: 2.384792983531952, Final Batch Loss: 0.4393583834171295\n",
      "Epoch 1976, Loss: 2.76788666844368, Final Batch Loss: 0.7410275340080261\n",
      "Epoch 1977, Loss: 2.540695458650589, Final Batch Loss: 0.4565322697162628\n",
      "Epoch 1978, Loss: 2.410836488008499, Final Batch Loss: 0.405429869890213\n",
      "Epoch 1979, Loss: 2.7692104876041412, Final Batch Loss: 0.5442114472389221\n",
      "Epoch 1980, Loss: 2.485792815685272, Final Batch Loss: 0.4938993453979492\n",
      "Epoch 1981, Loss: 2.4336508214473724, Final Batch Loss: 0.4915159046649933\n",
      "Epoch 1982, Loss: 3.188472181558609, Final Batch Loss: 1.0977199077606201\n",
      "Epoch 1983, Loss: 2.330881655216217, Final Batch Loss: 0.2526569068431854\n",
      "Epoch 1984, Loss: 2.6736943423748016, Final Batch Loss: 0.5974141359329224\n",
      "Epoch 1985, Loss: 2.6587946712970734, Final Batch Loss: 0.5797991752624512\n",
      "Epoch 1986, Loss: 2.9622884690761566, Final Batch Loss: 0.8686981201171875\n",
      "Epoch 1987, Loss: 2.900068938732147, Final Batch Loss: 0.8083046674728394\n",
      "Epoch 1988, Loss: 3.026566803455353, Final Batch Loss: 0.8898344039916992\n",
      "Epoch 1989, Loss: 2.188663735985756, Final Batch Loss: 0.1973266750574112\n",
      "Epoch 1990, Loss: 2.3817721903324127, Final Batch Loss: 0.42390838265419006\n",
      "Epoch 1991, Loss: 2.190076470375061, Final Batch Loss: 0.35440951585769653\n",
      "Epoch 1992, Loss: 2.5459062457084656, Final Batch Loss: 0.5200077295303345\n",
      "Epoch 1993, Loss: 2.673895537853241, Final Batch Loss: 0.5056334733963013\n",
      "Epoch 1994, Loss: 2.4976319074630737, Final Batch Loss: 0.47350838780403137\n",
      "Epoch 1995, Loss: 2.4787207543849945, Final Batch Loss: 0.5404492020606995\n",
      "Epoch 1996, Loss: 2.2423106729984283, Final Batch Loss: 0.23894762992858887\n",
      "Epoch 1997, Loss: 2.268177807331085, Final Batch Loss: 0.2739066183567047\n",
      "Epoch 1998, Loss: 2.508385479450226, Final Batch Loss: 0.5975914597511292\n",
      "Epoch 1999, Loss: 2.33005753159523, Final Batch Loss: 0.3884173035621643\n",
      "Epoch 2000, Loss: 3.1936031579971313, Final Batch Loss: 1.1078813076019287\n",
      "Epoch 2001, Loss: 2.6106527149677277, Final Batch Loss: 0.6175530552864075\n",
      "Epoch 2002, Loss: 2.3791548013687134, Final Batch Loss: 0.39613232016563416\n",
      "Epoch 2003, Loss: 2.4942791759967804, Final Batch Loss: 0.3892589211463928\n",
      "Epoch 2004, Loss: 2.172308698296547, Final Batch Loss: 0.20439116656780243\n",
      "Epoch 2005, Loss: 2.0578032955527306, Final Batch Loss: 0.08586572855710983\n",
      "Epoch 2006, Loss: 2.694687098264694, Final Batch Loss: 0.7323857545852661\n",
      "Epoch 2007, Loss: 2.2871163189411163, Final Batch Loss: 0.37636056542396545\n",
      "Epoch 2008, Loss: 2.5723001658916473, Final Batch Loss: 0.5371050834655762\n",
      "Epoch 2009, Loss: 2.3059433698654175, Final Batch Loss: 0.28796228766441345\n",
      "Epoch 2010, Loss: 2.5374354422092438, Final Batch Loss: 0.5232323408126831\n",
      "Epoch 2011, Loss: 2.5272373855113983, Final Batch Loss: 0.4729142487049103\n",
      "Epoch 2012, Loss: 2.714955151081085, Final Batch Loss: 0.6256385445594788\n",
      "Epoch 2013, Loss: 2.3949279189109802, Final Batch Loss: 0.41681215167045593\n",
      "Epoch 2014, Loss: 2.4487415850162506, Final Batch Loss: 0.4592408835887909\n",
      "Epoch 2015, Loss: 2.234677314758301, Final Batch Loss: 0.1695793867111206\n",
      "Epoch 2016, Loss: 2.1371045112609863, Final Batch Loss: 0.2074929177761078\n",
      "Epoch 2017, Loss: 2.1994591057300568, Final Batch Loss: 0.3658732771873474\n",
      "Epoch 2018, Loss: 2.499390959739685, Final Batch Loss: 0.5412095785140991\n",
      "Epoch 2019, Loss: 3.0084185898303986, Final Batch Loss: 1.1015222072601318\n",
      "Epoch 2020, Loss: 2.6972725689411163, Final Batch Loss: 0.7615389823913574\n",
      "Epoch 2021, Loss: 2.5271658897399902, Final Batch Loss: 0.5171322226524353\n",
      "Epoch 2022, Loss: 2.49368953704834, Final Batch Loss: 0.5609728097915649\n",
      "Epoch 2023, Loss: 2.5554578602313995, Final Batch Loss: 0.42745622992515564\n",
      "Epoch 2024, Loss: 2.340180829167366, Final Batch Loss: 0.24062491953372955\n",
      "Epoch 2025, Loss: 2.418964684009552, Final Batch Loss: 0.48796629905700684\n",
      "Epoch 2026, Loss: 2.913737505674362, Final Batch Loss: 0.930580198764801\n",
      "Epoch 2027, Loss: 2.5938029885292053, Final Batch Loss: 0.6242170333862305\n",
      "Epoch 2028, Loss: 2.6475299894809723, Final Batch Loss: 0.47075146436691284\n",
      "Epoch 2029, Loss: 3.0629792511463165, Final Batch Loss: 0.9659779667854309\n",
      "Epoch 2030, Loss: 2.2306715846061707, Final Batch Loss: 0.14036020636558533\n",
      "Epoch 2031, Loss: 2.8493650257587433, Final Batch Loss: 0.8132757544517517\n",
      "Epoch 2032, Loss: 2.196448862552643, Final Batch Loss: 0.2232060730457306\n",
      "Epoch 2033, Loss: 2.9139958024024963, Final Batch Loss: 0.7938958406448364\n",
      "Epoch 2034, Loss: 2.4487365186214447, Final Batch Loss: 0.4279685914516449\n",
      "Epoch 2035, Loss: 2.3296859860420227, Final Batch Loss: 0.3078424036502838\n",
      "Epoch 2036, Loss: 2.250855952501297, Final Batch Loss: 0.33219021558761597\n",
      "Epoch 2037, Loss: 2.378943622112274, Final Batch Loss: 0.41891083121299744\n",
      "Epoch 2038, Loss: 2.839194178581238, Final Batch Loss: 0.8998047709465027\n",
      "Epoch 2039, Loss: 2.185202330350876, Final Batch Loss: 0.22317102551460266\n",
      "Epoch 2040, Loss: 2.3418245017528534, Final Batch Loss: 0.28425368666648865\n",
      "Epoch 2041, Loss: 2.2055886536836624, Final Batch Loss: 0.20856808125972748\n",
      "Epoch 2042, Loss: 2.2426232397556305, Final Batch Loss: 0.2791415750980377\n",
      "Epoch 2043, Loss: 2.2091231644153595, Final Batch Loss: 0.3083886206150055\n",
      "Epoch 2044, Loss: 2.5294675529003143, Final Batch Loss: 0.732559323310852\n",
      "Epoch 2045, Loss: 2.4510478377342224, Final Batch Loss: 0.3903498947620392\n",
      "Epoch 2046, Loss: 2.4377166032791138, Final Batch Loss: 0.42322009801864624\n",
      "Epoch 2047, Loss: 2.4140820503234863, Final Batch Loss: 0.39386871457099915\n",
      "Epoch 2048, Loss: 2.6142585575580597, Final Batch Loss: 0.6166085004806519\n",
      "Epoch 2049, Loss: 2.4744771122932434, Final Batch Loss: 0.41533616185188293\n",
      "Epoch 2050, Loss: 2.5460811853408813, Final Batch Loss: 0.5244273543357849\n",
      "Epoch 2051, Loss: 2.544708549976349, Final Batch Loss: 0.43770089745521545\n",
      "Epoch 2052, Loss: 2.3550056517124176, Final Batch Loss: 0.4473070204257965\n",
      "Epoch 2053, Loss: 2.3801306784152985, Final Batch Loss: 0.3151238262653351\n",
      "Epoch 2054, Loss: 2.4430240392684937, Final Batch Loss: 0.5586783289909363\n",
      "Epoch 2055, Loss: 2.8457987904548645, Final Batch Loss: 0.7954373359680176\n",
      "Epoch 2056, Loss: 2.7687986195087433, Final Batch Loss: 0.817579448223114\n",
      "Epoch 2057, Loss: 2.4486746191978455, Final Batch Loss: 0.4018564224243164\n",
      "Epoch 2058, Loss: 2.426617354154587, Final Batch Loss: 0.4493096172809601\n",
      "Epoch 2059, Loss: 2.7990595996379852, Final Batch Loss: 0.9105733633041382\n",
      "Epoch 2060, Loss: 2.699901044368744, Final Batch Loss: 0.6727547645568848\n",
      "Epoch 2061, Loss: 2.3922793567180634, Final Batch Loss: 0.4356819987297058\n",
      "Epoch 2062, Loss: 2.2913661003112793, Final Batch Loss: 0.336920827627182\n",
      "Epoch 2063, Loss: 2.058222070336342, Final Batch Loss: 0.17713962495326996\n",
      "Epoch 2064, Loss: 2.9776062667369843, Final Batch Loss: 1.1422325372695923\n",
      "Epoch 2065, Loss: 2.5289118587970734, Final Batch Loss: 0.5617436170578003\n",
      "Epoch 2066, Loss: 2.1969263553619385, Final Batch Loss: 0.3658243715763092\n",
      "Epoch 2067, Loss: 2.163298547267914, Final Batch Loss: 0.20508825778961182\n",
      "Epoch 2068, Loss: 2.5280470848083496, Final Batch Loss: 0.5360168814659119\n",
      "Epoch 2069, Loss: 2.473288506269455, Final Batch Loss: 0.4503348469734192\n",
      "Epoch 2070, Loss: 2.3879003524780273, Final Batch Loss: 0.5759709477424622\n",
      "Epoch 2071, Loss: 2.444893777370453, Final Batch Loss: 0.5957282781600952\n",
      "Epoch 2072, Loss: 2.2206573486328125, Final Batch Loss: 0.3192930817604065\n",
      "Epoch 2073, Loss: 2.533157706260681, Final Batch Loss: 0.6185529828071594\n",
      "Epoch 2074, Loss: 2.5378628373146057, Final Batch Loss: 0.5839627385139465\n",
      "Epoch 2075, Loss: 2.671727329492569, Final Batch Loss: 0.6356450319290161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2076, Loss: 2.845245808362961, Final Batch Loss: 0.8329827189445496\n",
      "Epoch 2077, Loss: 2.408213436603546, Final Batch Loss: 0.3134011924266815\n",
      "Epoch 2078, Loss: 2.4054461121559143, Final Batch Loss: 0.43754005432128906\n",
      "Epoch 2079, Loss: 2.48902028799057, Final Batch Loss: 0.4590533673763275\n",
      "Epoch 2080, Loss: 2.5333887338638306, Final Batch Loss: 0.6243603825569153\n",
      "Epoch 2081, Loss: 2.913666158914566, Final Batch Loss: 1.1113979816436768\n",
      "Epoch 2082, Loss: 2.4732098281383514, Final Batch Loss: 0.4445311427116394\n",
      "Epoch 2083, Loss: 2.5067542493343353, Final Batch Loss: 0.5979900360107422\n",
      "Epoch 2084, Loss: 2.264594167470932, Final Batch Loss: 0.314554899930954\n",
      "Epoch 2085, Loss: 2.1362148225307465, Final Batch Loss: 0.19926056265830994\n",
      "Epoch 2086, Loss: 2.1765475273132324, Final Batch Loss: 0.31611159443855286\n",
      "Epoch 2087, Loss: 2.327249825000763, Final Batch Loss: 0.4687986373901367\n",
      "Epoch 2088, Loss: 2.551481544971466, Final Batch Loss: 0.6848834753036499\n",
      "Epoch 2089, Loss: 2.327690064907074, Final Batch Loss: 0.2857096493244171\n",
      "Epoch 2090, Loss: 2.703483074903488, Final Batch Loss: 0.6982490420341492\n",
      "Epoch 2091, Loss: 2.9146850407123566, Final Batch Loss: 1.007358431816101\n",
      "Epoch 2092, Loss: 2.30462709069252, Final Batch Loss: 0.3016895651817322\n",
      "Epoch 2093, Loss: 2.5397506654262543, Final Batch Loss: 0.5546488761901855\n",
      "Epoch 2094, Loss: 2.544051378965378, Final Batch Loss: 0.5367448329925537\n",
      "Epoch 2095, Loss: 2.3404748737812042, Final Batch Loss: 0.535716712474823\n",
      "Epoch 2096, Loss: 2.2827446460723877, Final Batch Loss: 0.3045220375061035\n",
      "Epoch 2097, Loss: 2.2981731593608856, Final Batch Loss: 0.38336244225502014\n",
      "Epoch 2098, Loss: 3.270379453897476, Final Batch Loss: 1.2434499263763428\n",
      "Epoch 2099, Loss: 2.6325750648975372, Final Batch Loss: 0.635904848575592\n",
      "Epoch 2100, Loss: 2.6619197130203247, Final Batch Loss: 0.5662170648574829\n",
      "Epoch 2101, Loss: 2.6640302538871765, Final Batch Loss: 0.4280560612678528\n",
      "Epoch 2102, Loss: 2.4650402665138245, Final Batch Loss: 0.47729215025901794\n",
      "Epoch 2103, Loss: 2.231978803873062, Final Batch Loss: 0.18494129180908203\n",
      "Epoch 2104, Loss: 2.8640736043453217, Final Batch Loss: 0.9109722375869751\n",
      "Epoch 2105, Loss: 2.3792624473571777, Final Batch Loss: 0.333505779504776\n",
      "Epoch 2106, Loss: 2.0473180562257767, Final Batch Loss: 0.18217553198337555\n",
      "Epoch 2107, Loss: 2.6263632476329803, Final Batch Loss: 0.6856779456138611\n",
      "Epoch 2108, Loss: 2.502514511346817, Final Batch Loss: 0.43897029757499695\n",
      "Epoch 2109, Loss: 2.227735310792923, Final Batch Loss: 0.287372887134552\n",
      "Epoch 2110, Loss: 2.419068217277527, Final Batch Loss: 0.4776323437690735\n",
      "Epoch 2111, Loss: 2.6321683526039124, Final Batch Loss: 0.8159390687942505\n",
      "Epoch 2112, Loss: 2.2915366291999817, Final Batch Loss: 0.4367915987968445\n",
      "Epoch 2113, Loss: 2.141438990831375, Final Batch Loss: 0.20940998196601868\n",
      "Epoch 2114, Loss: 2.140657424926758, Final Batch Loss: 0.298270046710968\n",
      "Epoch 2115, Loss: 2.3671967685222626, Final Batch Loss: 0.45828744769096375\n",
      "Epoch 2116, Loss: 2.7583336532115936, Final Batch Loss: 0.8773154020309448\n",
      "Epoch 2117, Loss: 2.7393446266651154, Final Batch Loss: 0.6945170164108276\n",
      "Epoch 2118, Loss: 2.780698388814926, Final Batch Loss: 0.7019805312156677\n",
      "Epoch 2119, Loss: 2.3425126373767853, Final Batch Loss: 0.3828496038913727\n",
      "Epoch 2120, Loss: 2.5276715457439423, Final Batch Loss: 0.48356837034225464\n",
      "Epoch 2121, Loss: 2.295632988214493, Final Batch Loss: 0.4214097857475281\n",
      "Epoch 2122, Loss: 2.52520889043808, Final Batch Loss: 0.533070981502533\n",
      "Epoch 2123, Loss: 2.409584701061249, Final Batch Loss: 0.5345153212547302\n",
      "Epoch 2124, Loss: 2.2774739265441895, Final Batch Loss: 0.3179379105567932\n",
      "Epoch 2125, Loss: 2.62076735496521, Final Batch Loss: 0.6042035222053528\n",
      "Epoch 2126, Loss: 2.4201024770736694, Final Batch Loss: 0.48130160570144653\n",
      "Epoch 2127, Loss: 2.872113198041916, Final Batch Loss: 1.009307622909546\n",
      "Epoch 2128, Loss: 2.562148779630661, Final Batch Loss: 0.6152264475822449\n",
      "Epoch 2129, Loss: 2.5037125647068024, Final Batch Loss: 0.559393048286438\n",
      "Epoch 2130, Loss: 2.623555153608322, Final Batch Loss: 0.7377573847770691\n",
      "Epoch 2131, Loss: 2.086822807788849, Final Batch Loss: 0.15522626042366028\n",
      "Epoch 2132, Loss: 2.829142689704895, Final Batch Loss: 0.8042344450950623\n",
      "Epoch 2133, Loss: 2.51737117767334, Final Batch Loss: 0.6392685174942017\n",
      "Epoch 2134, Loss: 2.401023358106613, Final Batch Loss: 0.4690527319908142\n",
      "Epoch 2135, Loss: 2.2605908811092377, Final Batch Loss: 0.23241662979125977\n",
      "Epoch 2136, Loss: 2.3035590052604675, Final Batch Loss: 0.43349769711494446\n",
      "Epoch 2137, Loss: 2.4225524067878723, Final Batch Loss: 0.6123188734054565\n",
      "Epoch 2138, Loss: 2.4317738711833954, Final Batch Loss: 0.42026999592781067\n",
      "Epoch 2139, Loss: 2.513979911804199, Final Batch Loss: 0.6245609521865845\n",
      "Epoch 2140, Loss: 2.0556278228759766, Final Batch Loss: 0.1606357991695404\n",
      "Epoch 2141, Loss: 2.4357800781726837, Final Batch Loss: 0.5332347750663757\n",
      "Epoch 2142, Loss: 2.421058624982834, Final Batch Loss: 0.5074589848518372\n",
      "Epoch 2143, Loss: 2.283457040786743, Final Batch Loss: 0.418576180934906\n",
      "Epoch 2144, Loss: 2.268918037414551, Final Batch Loss: 0.4244215190410614\n",
      "Epoch 2145, Loss: 2.2950003147125244, Final Batch Loss: 0.40620869398117065\n",
      "Epoch 2146, Loss: 2.746299624443054, Final Batch Loss: 0.8703383803367615\n",
      "Epoch 2147, Loss: 2.3878831565380096, Final Batch Loss: 0.5112482905387878\n",
      "Epoch 2148, Loss: 2.445764720439911, Final Batch Loss: 0.40095847845077515\n",
      "Epoch 2149, Loss: 2.5630752444267273, Final Batch Loss: 0.6149684190750122\n",
      "Epoch 2150, Loss: 2.2049723863601685, Final Batch Loss: 0.25536462664604187\n",
      "Epoch 2151, Loss: 2.294092893600464, Final Batch Loss: 0.45028433203697205\n",
      "Epoch 2152, Loss: 2.108559027314186, Final Batch Loss: 0.20378442108631134\n",
      "Epoch 2153, Loss: 2.4649873673915863, Final Batch Loss: 0.6192253828048706\n",
      "Epoch 2154, Loss: 2.596768319606781, Final Batch Loss: 0.5806707739830017\n",
      "Epoch 2155, Loss: 2.429445803165436, Final Batch Loss: 0.5140259265899658\n",
      "Epoch 2156, Loss: 2.471863716840744, Final Batch Loss: 0.5297905802726746\n",
      "Epoch 2157, Loss: 3.173809289932251, Final Batch Loss: 1.1710127592086792\n",
      "Epoch 2158, Loss: 2.934860974550247, Final Batch Loss: 0.956727921962738\n",
      "Epoch 2159, Loss: 2.517334222793579, Final Batch Loss: 0.3424464166164398\n",
      "Epoch 2160, Loss: 2.24735626578331, Final Batch Loss: 0.34097644686698914\n",
      "Epoch 2161, Loss: 2.4761735796928406, Final Batch Loss: 0.4448539614677429\n",
      "Epoch 2162, Loss: 2.1641495525836945, Final Batch Loss: 0.2707425057888031\n",
      "Epoch 2163, Loss: 2.5327617526054382, Final Batch Loss: 0.4994068443775177\n",
      "Epoch 2164, Loss: 2.3603877425193787, Final Batch Loss: 0.3948478400707245\n",
      "Epoch 2165, Loss: 2.120045095682144, Final Batch Loss: 0.35304075479507446\n",
      "Epoch 2166, Loss: 2.1089205890893936, Final Batch Loss: 0.24726052582263947\n",
      "Epoch 2167, Loss: 2.3698154389858246, Final Batch Loss: 0.4928744435310364\n",
      "Epoch 2168, Loss: 2.333849787712097, Final Batch Loss: 0.41549620032310486\n",
      "Epoch 2169, Loss: 2.771878570318222, Final Batch Loss: 0.7815871834754944\n",
      "Epoch 2170, Loss: 2.274399548768997, Final Batch Loss: 0.41431400179862976\n",
      "Epoch 2171, Loss: 2.433694541454315, Final Batch Loss: 0.4912993907928467\n",
      "Epoch 2172, Loss: 2.3896681666374207, Final Batch Loss: 0.5829652547836304\n",
      "Epoch 2173, Loss: 2.1823960840702057, Final Batch Loss: 0.1929931938648224\n",
      "Epoch 2174, Loss: 2.4073283970355988, Final Batch Loss: 0.5026439428329468\n",
      "Epoch 2175, Loss: 2.195009797811508, Final Batch Loss: 0.296918123960495\n",
      "Epoch 2176, Loss: 2.1547513604164124, Final Batch Loss: 0.27787014842033386\n",
      "Epoch 2177, Loss: 2.4947478771209717, Final Batch Loss: 0.47068485617637634\n",
      "Epoch 2178, Loss: 2.5699329674243927, Final Batch Loss: 0.7862113118171692\n",
      "Epoch 2179, Loss: 2.6256341636180878, Final Batch Loss: 0.7235972285270691\n",
      "Epoch 2180, Loss: 2.537242114543915, Final Batch Loss: 0.7478479743003845\n",
      "Epoch 2181, Loss: 2.697996973991394, Final Batch Loss: 0.7942758798599243\n",
      "Epoch 2182, Loss: 2.7003402709960938, Final Batch Loss: 0.6174795031547546\n",
      "Epoch 2183, Loss: 2.7000275254249573, Final Batch Loss: 0.6976343393325806\n",
      "Epoch 2184, Loss: 2.420111358165741, Final Batch Loss: 0.36253777146339417\n",
      "Epoch 2185, Loss: 2.5250509083271027, Final Batch Loss: 0.549497663974762\n",
      "Epoch 2186, Loss: 2.526793271303177, Final Batch Loss: 0.6368428468704224\n",
      "Epoch 2187, Loss: 2.47141170501709, Final Batch Loss: 0.591293215751648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2188, Loss: 2.408861458301544, Final Batch Loss: 0.4196961224079132\n",
      "Epoch 2189, Loss: 2.217715159058571, Final Batch Loss: 0.17308183014392853\n",
      "Epoch 2190, Loss: 2.1250426173210144, Final Batch Loss: 0.2080603539943695\n",
      "Epoch 2191, Loss: 2.427395761013031, Final Batch Loss: 0.5630711317062378\n",
      "Epoch 2192, Loss: 2.2049800753593445, Final Batch Loss: 0.2987666130065918\n",
      "Epoch 2193, Loss: 2.5531741082668304, Final Batch Loss: 0.5784096717834473\n",
      "Epoch 2194, Loss: 2.0667231678962708, Final Batch Loss: 0.17422425746917725\n",
      "Epoch 2195, Loss: 2.2292710542678833, Final Batch Loss: 0.2989489436149597\n",
      "Epoch 2196, Loss: 2.2401023507118225, Final Batch Loss: 0.4591120779514313\n",
      "Epoch 2197, Loss: 2.3515074253082275, Final Batch Loss: 0.5086044669151306\n",
      "Epoch 2198, Loss: 2.142046645283699, Final Batch Loss: 0.18083499372005463\n",
      "Epoch 2199, Loss: 2.3896219432353973, Final Batch Loss: 0.5119616985321045\n",
      "Epoch 2200, Loss: 2.3417593240737915, Final Batch Loss: 0.41559869050979614\n",
      "Epoch 2201, Loss: 2.3854863047599792, Final Batch Loss: 0.4655255973339081\n",
      "Epoch 2202, Loss: 2.164629653096199, Final Batch Loss: 0.17792688310146332\n",
      "Epoch 2203, Loss: 2.752226173877716, Final Batch Loss: 0.6310202479362488\n",
      "Epoch 2204, Loss: 2.699148505926132, Final Batch Loss: 0.668755829334259\n",
      "Epoch 2205, Loss: 2.5849192142486572, Final Batch Loss: 0.7175712585449219\n",
      "Epoch 2206, Loss: 2.3362541794776917, Final Batch Loss: 0.30772608518600464\n",
      "Epoch 2207, Loss: 2.75402969121933, Final Batch Loss: 0.6064795255661011\n",
      "Epoch 2208, Loss: 2.2528590857982635, Final Batch Loss: 0.3363979756832123\n",
      "Epoch 2209, Loss: 2.509194701910019, Final Batch Loss: 0.6104020476341248\n",
      "Epoch 2210, Loss: 1.875186488032341, Final Batch Loss: 0.132738396525383\n",
      "Epoch 2211, Loss: 2.667236715555191, Final Batch Loss: 0.859757125377655\n",
      "Epoch 2212, Loss: 2.739180028438568, Final Batch Loss: 0.6906346082687378\n",
      "Epoch 2213, Loss: 2.8918405175209045, Final Batch Loss: 0.9003402590751648\n",
      "Epoch 2214, Loss: 1.9754254966974258, Final Batch Loss: 0.1882004588842392\n",
      "Epoch 2215, Loss: 2.4691694378852844, Final Batch Loss: 0.6020768284797668\n",
      "Epoch 2216, Loss: 2.5830572843551636, Final Batch Loss: 0.5927184820175171\n",
      "Epoch 2217, Loss: 2.484053313732147, Final Batch Loss: 0.5260413885116577\n",
      "Epoch 2218, Loss: 2.3459357619285583, Final Batch Loss: 0.48571935296058655\n",
      "Epoch 2219, Loss: 3.1526172757148743, Final Batch Loss: 1.1742771863937378\n",
      "Epoch 2220, Loss: 2.1521840542554855, Final Batch Loss: 0.23525603115558624\n",
      "Epoch 2221, Loss: 2.482070803642273, Final Batch Loss: 0.49493521451950073\n",
      "Epoch 2222, Loss: 2.610108494758606, Final Batch Loss: 0.5582000017166138\n",
      "Epoch 2223, Loss: 2.4347292482852936, Final Batch Loss: 0.4100353419780731\n",
      "Epoch 2224, Loss: 2.533296227455139, Final Batch Loss: 0.6324366927146912\n",
      "Epoch 2225, Loss: 2.522534102201462, Final Batch Loss: 0.4763423800468445\n",
      "Epoch 2226, Loss: 2.916802614927292, Final Batch Loss: 0.91162109375\n",
      "Epoch 2227, Loss: 2.513375371694565, Final Batch Loss: 0.5574057102203369\n",
      "Epoch 2228, Loss: 2.4876230657100677, Final Batch Loss: 0.647609531879425\n",
      "Epoch 2229, Loss: 2.636727035045624, Final Batch Loss: 0.6939687728881836\n",
      "Epoch 2230, Loss: 2.3831063508987427, Final Batch Loss: 0.46031761169433594\n",
      "Epoch 2231, Loss: 2.3487784266471863, Final Batch Loss: 0.3922787308692932\n",
      "Epoch 2232, Loss: 2.600050389766693, Final Batch Loss: 0.5804550051689148\n",
      "Epoch 2233, Loss: 2.5342526137828827, Final Batch Loss: 0.5306986570358276\n",
      "Epoch 2234, Loss: 2.979693293571472, Final Batch Loss: 0.8789125084877014\n",
      "Epoch 2235, Loss: 2.873737245798111, Final Batch Loss: 0.7531431317329407\n",
      "Epoch 2236, Loss: 2.4133125841617584, Final Batch Loss: 0.36060330271720886\n",
      "Epoch 2237, Loss: 2.2406474351882935, Final Batch Loss: 0.25385981798171997\n",
      "Epoch 2238, Loss: 2.51333886384964, Final Batch Loss: 0.5172335505485535\n",
      "Epoch 2239, Loss: 2.360477089881897, Final Batch Loss: 0.4916645884513855\n",
      "Epoch 2240, Loss: 2.2549373507499695, Final Batch Loss: 0.35405534505844116\n",
      "Epoch 2241, Loss: 2.3462447226047516, Final Batch Loss: 0.5187391042709351\n",
      "Epoch 2242, Loss: 2.410478115081787, Final Batch Loss: 0.5999876260757446\n",
      "Epoch 2243, Loss: 2.1243697106838226, Final Batch Loss: 0.2607247531414032\n",
      "Epoch 2244, Loss: 2.9644512236118317, Final Batch Loss: 1.1321293115615845\n",
      "Epoch 2245, Loss: 2.1789745092391968, Final Batch Loss: 0.3832496106624603\n",
      "Epoch 2246, Loss: 2.453651249408722, Final Batch Loss: 0.5306471586227417\n",
      "Epoch 2247, Loss: 2.998718708753586, Final Batch Loss: 1.008754014968872\n",
      "Epoch 2248, Loss: 2.2341133654117584, Final Batch Loss: 0.32917851209640503\n",
      "Epoch 2249, Loss: 2.278209924697876, Final Batch Loss: 0.4467394948005676\n",
      "Epoch 2250, Loss: 1.9845168590545654, Final Batch Loss: 0.2356012761592865\n",
      "Epoch 2251, Loss: 2.131192296743393, Final Batch Loss: 0.3135713040828705\n",
      "Epoch 2252, Loss: 2.1755005717277527, Final Batch Loss: 0.2647971510887146\n",
      "Epoch 2253, Loss: 2.2831850051879883, Final Batch Loss: 0.3962287902832031\n",
      "Epoch 2254, Loss: 2.1113457083702087, Final Batch Loss: 0.31633567810058594\n",
      "Epoch 2255, Loss: 2.3420208990573883, Final Batch Loss: 0.3460386097431183\n",
      "Epoch 2256, Loss: 2.325565427541733, Final Batch Loss: 0.48133584856987\n",
      "Epoch 2257, Loss: 2.421850770711899, Final Batch Loss: 0.476976603269577\n",
      "Epoch 2258, Loss: 2.4834550619125366, Final Batch Loss: 0.6372105479240417\n",
      "Epoch 2259, Loss: 2.554567813873291, Final Batch Loss: 0.606390655040741\n",
      "Epoch 2260, Loss: 2.077924907207489, Final Batch Loss: 0.2771386504173279\n",
      "Epoch 2261, Loss: 2.01468925178051, Final Batch Loss: 0.23520533740520477\n",
      "Epoch 2262, Loss: 2.3489971458911896, Final Batch Loss: 0.556136965751648\n",
      "Epoch 2263, Loss: 2.520859330892563, Final Batch Loss: 0.673904538154602\n",
      "Epoch 2264, Loss: 2.348489761352539, Final Batch Loss: 0.47081875801086426\n",
      "Epoch 2265, Loss: 2.4483590126037598, Final Batch Loss: 0.4512307941913605\n",
      "Epoch 2266, Loss: 2.2019695937633514, Final Batch Loss: 0.45701199769973755\n",
      "Epoch 2267, Loss: 2.1432488709688187, Final Batch Loss: 0.2052425891160965\n",
      "Epoch 2268, Loss: 2.2557154297828674, Final Batch Loss: 0.2958533763885498\n",
      "Epoch 2269, Loss: 2.360941916704178, Final Batch Loss: 0.4244826138019562\n",
      "Epoch 2270, Loss: 2.2979289889335632, Final Batch Loss: 0.3662961423397064\n",
      "Epoch 2271, Loss: 2.4928450286388397, Final Batch Loss: 0.5540607571601868\n",
      "Epoch 2272, Loss: 2.319957822561264, Final Batch Loss: 0.40106773376464844\n",
      "Epoch 2273, Loss: 2.1618445366621017, Final Batch Loss: 0.20805610716342926\n",
      "Epoch 2274, Loss: 2.1502651274204254, Final Batch Loss: 0.4130617082118988\n",
      "Epoch 2275, Loss: 2.3661179542541504, Final Batch Loss: 0.4442463517189026\n",
      "Epoch 2276, Loss: 2.0003366619348526, Final Batch Loss: 0.2343149036169052\n",
      "Epoch 2277, Loss: 2.438586860895157, Final Batch Loss: 0.6135548949241638\n",
      "Epoch 2278, Loss: 2.250353693962097, Final Batch Loss: 0.40588682889938354\n",
      "Epoch 2279, Loss: 2.360428124666214, Final Batch Loss: 0.4629693627357483\n",
      "Epoch 2280, Loss: 2.618349403142929, Final Batch Loss: 0.6732334494590759\n",
      "Epoch 2281, Loss: 2.4481063783168793, Final Batch Loss: 0.5437102317810059\n",
      "Epoch 2282, Loss: 2.659601628780365, Final Batch Loss: 0.6270256638526917\n",
      "Epoch 2283, Loss: 2.4490663707256317, Final Batch Loss: 0.3115682005882263\n",
      "Epoch 2284, Loss: 2.674692302942276, Final Batch Loss: 0.6497865319252014\n",
      "Epoch 2285, Loss: 2.291112631559372, Final Batch Loss: 0.3471989035606384\n",
      "Epoch 2286, Loss: 3.4330624639987946, Final Batch Loss: 1.4335600137710571\n",
      "Epoch 2287, Loss: 2.56771656870842, Final Batch Loss: 0.6650909185409546\n",
      "Epoch 2288, Loss: 2.2282075583934784, Final Batch Loss: 0.35752663016319275\n",
      "Epoch 2289, Loss: 2.261972963809967, Final Batch Loss: 0.39936938881874084\n",
      "Epoch 2290, Loss: 2.165810286998749, Final Batch Loss: 0.2353682816028595\n",
      "Epoch 2291, Loss: 2.313892215490341, Final Batch Loss: 0.3336973190307617\n",
      "Epoch 2292, Loss: 2.949474662542343, Final Batch Loss: 1.135144591331482\n",
      "Epoch 2293, Loss: 2.5737707316875458, Final Batch Loss: 0.5277440547943115\n",
      "Epoch 2294, Loss: 2.8238033950328827, Final Batch Loss: 0.9336485266685486\n",
      "Epoch 2295, Loss: 1.9992293417453766, Final Batch Loss: 0.19104281067848206\n",
      "Epoch 2296, Loss: 2.2182823717594147, Final Batch Loss: 0.3086094260215759\n",
      "Epoch 2297, Loss: 2.056606411933899, Final Batch Loss: 0.15297627449035645\n",
      "Epoch 2298, Loss: 2.152551978826523, Final Batch Loss: 0.2916411757469177\n",
      "Epoch 2299, Loss: 2.0454714447259903, Final Batch Loss: 0.20998962223529816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2300, Loss: 2.265923410654068, Final Batch Loss: 0.3298964500427246\n",
      "Epoch 2301, Loss: 2.5131316781044006, Final Batch Loss: 0.7383958101272583\n",
      "Epoch 2302, Loss: 2.466995358467102, Final Batch Loss: 0.5695976614952087\n",
      "Epoch 2303, Loss: 2.478713482618332, Final Batch Loss: 0.7049209475517273\n",
      "Epoch 2304, Loss: 2.433328241109848, Final Batch Loss: 0.5301446318626404\n",
      "Epoch 2305, Loss: 2.1796503365039825, Final Batch Loss: 0.4033161997795105\n",
      "Epoch 2306, Loss: 2.0455866008996964, Final Batch Loss: 0.20795844495296478\n",
      "Epoch 2307, Loss: 2.4518623054027557, Final Batch Loss: 0.6178199648857117\n",
      "Epoch 2308, Loss: 2.28820738196373, Final Batch Loss: 0.41657185554504395\n",
      "Epoch 2309, Loss: 2.2029812037944794, Final Batch Loss: 0.3666452467441559\n",
      "Epoch 2310, Loss: 2.5034318566322327, Final Batch Loss: 0.4037306606769562\n",
      "Epoch 2311, Loss: 2.0245741456747055, Final Batch Loss: 0.21830226480960846\n",
      "Epoch 2312, Loss: 2.2800713181495667, Final Batch Loss: 0.47602328658103943\n",
      "Epoch 2313, Loss: 2.3312034606933594, Final Batch Loss: 0.4324062168598175\n",
      "Epoch 2314, Loss: 2.2066787779331207, Final Batch Loss: 0.4353630542755127\n",
      "Epoch 2315, Loss: 2.559155821800232, Final Batch Loss: 0.6881479024887085\n",
      "Epoch 2316, Loss: 2.320712000131607, Final Batch Loss: 0.49102911353111267\n",
      "Epoch 2317, Loss: 2.2521028220653534, Final Batch Loss: 0.31763845682144165\n",
      "Epoch 2318, Loss: 2.5116540789604187, Final Batch Loss: 0.5416375398635864\n",
      "Epoch 2319, Loss: 2.29746213555336, Final Batch Loss: 0.5249377489089966\n",
      "Epoch 2320, Loss: 2.3720608055591583, Final Batch Loss: 0.5638166069984436\n",
      "Epoch 2321, Loss: 2.044807583093643, Final Batch Loss: 0.25579649209976196\n",
      "Epoch 2322, Loss: 2.2452124655246735, Final Batch Loss: 0.31775519251823425\n",
      "Epoch 2323, Loss: 2.4158382415771484, Final Batch Loss: 0.34440621733665466\n",
      "Epoch 2324, Loss: 2.8675543665885925, Final Batch Loss: 0.8424310684204102\n",
      "Epoch 2325, Loss: 2.768091142177582, Final Batch Loss: 0.9078764319419861\n",
      "Epoch 2326, Loss: 2.5336633026599884, Final Batch Loss: 0.6511468291282654\n",
      "Epoch 2327, Loss: 2.3129935264587402, Final Batch Loss: 0.4133079946041107\n",
      "Epoch 2328, Loss: 2.335457533597946, Final Batch Loss: 0.34734684228897095\n",
      "Epoch 2329, Loss: 2.599451929330826, Final Batch Loss: 0.6208930611610413\n",
      "Epoch 2330, Loss: 2.563696265220642, Final Batch Loss: 0.5135561227798462\n",
      "Epoch 2331, Loss: 2.472760558128357, Final Batch Loss: 0.509530246257782\n",
      "Epoch 2332, Loss: 2.514516294002533, Final Batch Loss: 0.6035467982292175\n",
      "Epoch 2333, Loss: 1.960352048277855, Final Batch Loss: 0.1466815322637558\n",
      "Epoch 2334, Loss: 2.2625651359558105, Final Batch Loss: 0.3060634732246399\n",
      "Epoch 2335, Loss: 2.5315704345703125, Final Batch Loss: 0.730866014957428\n",
      "Epoch 2336, Loss: 2.0209985822439194, Final Batch Loss: 0.2161639779806137\n",
      "Epoch 2337, Loss: 1.8909195736050606, Final Batch Loss: 0.10694841295480728\n",
      "Epoch 2338, Loss: 2.257921189069748, Final Batch Loss: 0.4127535820007324\n",
      "Epoch 2339, Loss: 2.400930941104889, Final Batch Loss: 0.6018052101135254\n",
      "Epoch 2340, Loss: 2.2591108083724976, Final Batch Loss: 0.484506219625473\n",
      "Epoch 2341, Loss: 2.492650717496872, Final Batch Loss: 0.5579330325126648\n",
      "Epoch 2342, Loss: 1.967443898320198, Final Batch Loss: 0.1529093235731125\n",
      "Epoch 2343, Loss: 2.765086591243744, Final Batch Loss: 0.8299075365066528\n",
      "Epoch 2344, Loss: 2.4343384504318237, Final Batch Loss: 0.4862668812274933\n",
      "Epoch 2345, Loss: 2.266132414340973, Final Batch Loss: 0.5658407807350159\n",
      "Epoch 2346, Loss: 2.1954135596752167, Final Batch Loss: 0.4467054009437561\n",
      "Epoch 2347, Loss: 2.1905146539211273, Final Batch Loss: 0.35280999541282654\n",
      "Epoch 2348, Loss: 2.515359491109848, Final Batch Loss: 0.6426331400871277\n",
      "Epoch 2349, Loss: 2.1858547627925873, Final Batch Loss: 0.4091840386390686\n",
      "Epoch 2350, Loss: 2.276528239250183, Final Batch Loss: 0.4219646751880646\n",
      "Epoch 2351, Loss: 2.6558212339878082, Final Batch Loss: 0.6163584589958191\n",
      "Epoch 2352, Loss: 2.3289968073368073, Final Batch Loss: 0.46968874335289\n",
      "Epoch 2353, Loss: 2.456383913755417, Final Batch Loss: 0.5256562829017639\n",
      "Epoch 2354, Loss: 2.831863820552826, Final Batch Loss: 0.9362911581993103\n",
      "Epoch 2355, Loss: 2.539324313402176, Final Batch Loss: 0.6578852534294128\n",
      "Epoch 2356, Loss: 2.447710871696472, Final Batch Loss: 0.6885101199150085\n",
      "Epoch 2357, Loss: 2.1796307265758514, Final Batch Loss: 0.4537275731563568\n",
      "Epoch 2358, Loss: 2.0081824958324432, Final Batch Loss: 0.3038516044616699\n",
      "Epoch 2359, Loss: 3.2100371718406677, Final Batch Loss: 1.3412177562713623\n",
      "Epoch 2360, Loss: 2.259265273809433, Final Batch Loss: 0.3910870850086212\n",
      "Epoch 2361, Loss: 2.355450391769409, Final Batch Loss: 0.5047056674957275\n",
      "Epoch 2362, Loss: 2.0478133857250214, Final Batch Loss: 0.2658955454826355\n",
      "Epoch 2363, Loss: 2.579974591732025, Final Batch Loss: 0.6581324338912964\n",
      "Epoch 2364, Loss: 2.115355759859085, Final Batch Loss: 0.2600536048412323\n",
      "Epoch 2365, Loss: 2.0480002015829086, Final Batch Loss: 0.21870730817317963\n",
      "Epoch 2366, Loss: 2.4319812655448914, Final Batch Loss: 0.47660836577415466\n",
      "Epoch 2367, Loss: 2.2724733352661133, Final Batch Loss: 0.3460162580013275\n",
      "Epoch 2368, Loss: 2.506701320409775, Final Batch Loss: 0.7739162445068359\n",
      "Epoch 2369, Loss: 2.2290535271167755, Final Batch Loss: 0.40242287516593933\n",
      "Epoch 2370, Loss: 2.0185428112745285, Final Batch Loss: 0.1927250772714615\n",
      "Epoch 2371, Loss: 2.157660961151123, Final Batch Loss: 0.3816583752632141\n",
      "Epoch 2372, Loss: 2.068652391433716, Final Batch Loss: 0.2835081219673157\n",
      "Epoch 2373, Loss: 2.064131498336792, Final Batch Loss: 0.33426031470298767\n",
      "Epoch 2374, Loss: 2.506774365901947, Final Batch Loss: 0.7278032302856445\n",
      "Epoch 2375, Loss: 2.215731233358383, Final Batch Loss: 0.29916688799858093\n",
      "Epoch 2376, Loss: 2.079756259918213, Final Batch Loss: 0.35849425196647644\n",
      "Epoch 2377, Loss: 2.4324703216552734, Final Batch Loss: 0.6046872735023499\n",
      "Epoch 2378, Loss: 2.623872071504593, Final Batch Loss: 0.7817478775978088\n",
      "Epoch 2379, Loss: 2.4638686776161194, Final Batch Loss: 0.5956417322158813\n",
      "Epoch 2380, Loss: 2.523670107126236, Final Batch Loss: 0.5814219117164612\n",
      "Epoch 2381, Loss: 2.0376026034355164, Final Batch Loss: 0.15432843565940857\n",
      "Epoch 2382, Loss: 2.329262465238571, Final Batch Loss: 0.5505098700523376\n",
      "Epoch 2383, Loss: 2.895564556121826, Final Batch Loss: 1.121806263923645\n",
      "Epoch 2384, Loss: 2.5017842948436737, Final Batch Loss: 0.6610180139541626\n",
      "Epoch 2385, Loss: 2.4618440568447113, Final Batch Loss: 0.5465407371520996\n",
      "Epoch 2386, Loss: 2.1717617213726044, Final Batch Loss: 0.2531544864177704\n",
      "Epoch 2387, Loss: 2.442635655403137, Final Batch Loss: 0.5462997555732727\n",
      "Epoch 2388, Loss: 2.373039722442627, Final Batch Loss: 0.543746829032898\n",
      "Epoch 2389, Loss: 2.729965627193451, Final Batch Loss: 0.7992804646492004\n",
      "Epoch 2390, Loss: 2.0702680945396423, Final Batch Loss: 0.29020956158638\n",
      "Epoch 2391, Loss: 2.0005858093500137, Final Batch Loss: 0.1681511253118515\n",
      "Epoch 2392, Loss: 2.138912171125412, Final Batch Loss: 0.34787824749946594\n",
      "Epoch 2393, Loss: 2.005417376756668, Final Batch Loss: 0.34987708926200867\n",
      "Epoch 2394, Loss: 1.8632853478193283, Final Batch Loss: 0.07591788470745087\n",
      "Epoch 2395, Loss: 2.299473136663437, Final Batch Loss: 0.46460673213005066\n",
      "Epoch 2396, Loss: 2.245169758796692, Final Batch Loss: 0.41982564330101013\n",
      "Epoch 2397, Loss: 2.814263015985489, Final Batch Loss: 1.0392614603042603\n",
      "Epoch 2398, Loss: 2.315480560064316, Final Batch Loss: 0.5139976143836975\n",
      "Epoch 2399, Loss: 2.446037173271179, Final Batch Loss: 0.4663255512714386\n",
      "Epoch 2400, Loss: 2.2730392515659332, Final Batch Loss: 0.2825758755207062\n",
      "Epoch 2401, Loss: 2.4376882910728455, Final Batch Loss: 0.63958740234375\n",
      "Epoch 2402, Loss: 2.4621629416942596, Final Batch Loss: 0.6371614336967468\n",
      "Epoch 2403, Loss: 2.2658360600471497, Final Batch Loss: 0.4744766056537628\n",
      "Epoch 2404, Loss: 2.3789037466049194, Final Batch Loss: 0.5481480956077576\n",
      "Epoch 2405, Loss: 2.478105992078781, Final Batch Loss: 0.7663235664367676\n",
      "Epoch 2406, Loss: 2.743647873401642, Final Batch Loss: 0.8377519249916077\n",
      "Epoch 2407, Loss: 2.3045195043087006, Final Batch Loss: 0.3854237496852875\n",
      "Epoch 2408, Loss: 1.9472345560789108, Final Batch Loss: 0.13156519830226898\n",
      "Epoch 2409, Loss: 1.8658360838890076, Final Batch Loss: 0.22739124298095703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2410, Loss: 2.221809834241867, Final Batch Loss: 0.2674919664859772\n",
      "Epoch 2411, Loss: 2.078651010990143, Final Batch Loss: 0.3026866912841797\n",
      "Epoch 2412, Loss: 2.0517461746931076, Final Batch Loss: 0.24949322640895844\n",
      "Epoch 2413, Loss: 2.2675971686840057, Final Batch Loss: 0.3968016505241394\n",
      "Epoch 2414, Loss: 2.5770955979824066, Final Batch Loss: 0.9199861288070679\n",
      "Epoch 2415, Loss: 2.2736566066741943, Final Batch Loss: 0.3223174512386322\n",
      "Epoch 2416, Loss: 2.4494125843048096, Final Batch Loss: 0.420982301235199\n",
      "Epoch 2417, Loss: 2.247121185064316, Final Batch Loss: 0.5577484965324402\n",
      "Epoch 2418, Loss: 2.4904783964157104, Final Batch Loss: 0.3824920058250427\n",
      "Epoch 2419, Loss: 2.139797329902649, Final Batch Loss: 0.3141445219516754\n",
      "Epoch 2420, Loss: 2.249543249607086, Final Batch Loss: 0.289969265460968\n",
      "Epoch 2421, Loss: 2.175526112318039, Final Batch Loss: 0.37975701689720154\n",
      "Epoch 2422, Loss: 2.2129824459552765, Final Batch Loss: 0.3454570174217224\n",
      "Epoch 2423, Loss: 2.1191490590572357, Final Batch Loss: 0.2973281443119049\n",
      "Epoch 2424, Loss: 2.5129725337028503, Final Batch Loss: 0.7959255576133728\n",
      "Epoch 2425, Loss: 2.0232323110103607, Final Batch Loss: 0.19718840718269348\n",
      "Epoch 2426, Loss: 2.2529085874557495, Final Batch Loss: 0.40851303935050964\n",
      "Epoch 2427, Loss: 2.4206540286540985, Final Batch Loss: 0.4705865681171417\n",
      "Epoch 2428, Loss: 2.1851491034030914, Final Batch Loss: 0.4922145903110504\n",
      "Epoch 2429, Loss: 2.3480756282806396, Final Batch Loss: 0.41378599405288696\n",
      "Epoch 2430, Loss: 2.6146439015865326, Final Batch Loss: 0.6222605109214783\n",
      "Epoch 2431, Loss: 2.109872430562973, Final Batch Loss: 0.36664319038391113\n",
      "Epoch 2432, Loss: 2.4229149520397186, Final Batch Loss: 0.6069327592849731\n",
      "Epoch 2433, Loss: 2.3189713060855865, Final Batch Loss: 0.5073774456977844\n",
      "Epoch 2434, Loss: 2.2387513518333435, Final Batch Loss: 0.4334719181060791\n",
      "Epoch 2435, Loss: 2.497696280479431, Final Batch Loss: 0.509208083152771\n",
      "Epoch 2436, Loss: 2.3171820044517517, Final Batch Loss: 0.5716241598129272\n",
      "Epoch 2437, Loss: 2.3289785385131836, Final Batch Loss: 0.3997289538383484\n",
      "Epoch 2438, Loss: 2.069517135620117, Final Batch Loss: 0.311239629983902\n",
      "Epoch 2439, Loss: 2.5600165724754333, Final Batch Loss: 0.6987119317054749\n",
      "Epoch 2440, Loss: 2.0861112028360367, Final Batch Loss: 0.2347298115491867\n",
      "Epoch 2441, Loss: 1.9607808738946915, Final Batch Loss: 0.21381999552249908\n",
      "Epoch 2442, Loss: 2.511206328868866, Final Batch Loss: 0.8228116631507874\n",
      "Epoch 2443, Loss: 2.230827808380127, Final Batch Loss: 0.3294994533061981\n",
      "Epoch 2444, Loss: 2.303953528404236, Final Batch Loss: 0.41253462433815\n",
      "Epoch 2445, Loss: 2.5748998522758484, Final Batch Loss: 0.7254491448402405\n",
      "Epoch 2446, Loss: 2.661434829235077, Final Batch Loss: 0.6087288856506348\n",
      "Epoch 2447, Loss: 2.420436441898346, Final Batch Loss: 0.5884934663772583\n",
      "Epoch 2448, Loss: 2.205115169286728, Final Batch Loss: 0.31713175773620605\n",
      "Epoch 2449, Loss: 3.0270042717456818, Final Batch Loss: 1.2521649599075317\n",
      "Epoch 2450, Loss: 2.5491138100624084, Final Batch Loss: 0.6456380486488342\n",
      "Epoch 2451, Loss: 2.6179822385311127, Final Batch Loss: 0.3696121871471405\n",
      "Epoch 2452, Loss: 2.7290196120738983, Final Batch Loss: 0.3164196312427521\n",
      "Epoch 2453, Loss: 2.3323423862457275, Final Batch Loss: 0.44434961676597595\n",
      "Epoch 2454, Loss: 2.3112871050834656, Final Batch Loss: 0.32297173142433167\n",
      "Epoch 2455, Loss: 2.3420777320861816, Final Batch Loss: 0.44040563702583313\n",
      "Epoch 2456, Loss: 2.312182694673538, Final Batch Loss: 0.3011769652366638\n",
      "Epoch 2457, Loss: 2.557774394750595, Final Batch Loss: 0.6747184991836548\n",
      "Epoch 2458, Loss: 2.243218421936035, Final Batch Loss: 0.21647265553474426\n",
      "Epoch 2459, Loss: 2.068880796432495, Final Batch Loss: 0.32424506545066833\n",
      "Epoch 2460, Loss: 2.2350323498249054, Final Batch Loss: 0.3613665699958801\n",
      "Epoch 2461, Loss: 2.5075603723526, Final Batch Loss: 0.6509596705436707\n",
      "Epoch 2462, Loss: 2.373477965593338, Final Batch Loss: 0.49921247363090515\n",
      "Epoch 2463, Loss: 2.1891151666641235, Final Batch Loss: 0.40576601028442383\n",
      "Epoch 2464, Loss: 2.620885133743286, Final Batch Loss: 0.6943240165710449\n",
      "Epoch 2465, Loss: 2.5091922283172607, Final Batch Loss: 0.21712160110473633\n",
      "Epoch 2466, Loss: 2.328937143087387, Final Batch Loss: 0.4393593370914459\n",
      "Epoch 2467, Loss: 1.8453150689601898, Final Batch Loss: 0.14659634232521057\n",
      "Epoch 2468, Loss: 2.1977672576904297, Final Batch Loss: 0.37691378593444824\n",
      "Epoch 2469, Loss: 2.2161552608013153, Final Batch Loss: 0.3707922101020813\n",
      "Epoch 2470, Loss: 2.401742070913315, Final Batch Loss: 0.5238023400306702\n",
      "Epoch 2471, Loss: 2.4683191776275635, Final Batch Loss: 0.5576379299163818\n",
      "Epoch 2472, Loss: 2.1850733160972595, Final Batch Loss: 0.3765318989753723\n",
      "Epoch 2473, Loss: 2.2111884355545044, Final Batch Loss: 0.46964141726493835\n",
      "Epoch 2474, Loss: 2.9035365283489227, Final Batch Loss: 1.1159225702285767\n",
      "Epoch 2475, Loss: 2.176118403673172, Final Batch Loss: 0.2743469774723053\n",
      "Epoch 2476, Loss: 1.9344477653503418, Final Batch Loss: 0.14037564396858215\n",
      "Epoch 2477, Loss: 2.2288899421691895, Final Batch Loss: 0.4904511272907257\n",
      "Epoch 2478, Loss: 1.7803040519356728, Final Batch Loss: 0.07435838133096695\n",
      "Epoch 2479, Loss: 2.2562749683856964, Final Batch Loss: 0.3439352810382843\n",
      "Epoch 2480, Loss: 2.398139536380768, Final Batch Loss: 0.6168385744094849\n",
      "Epoch 2481, Loss: 2.3422032296657562, Final Batch Loss: 0.6248430609703064\n",
      "Epoch 2482, Loss: 2.1351204812526703, Final Batch Loss: 0.38224735856056213\n",
      "Epoch 2483, Loss: 1.9105910062789917, Final Batch Loss: 0.22527292370796204\n",
      "Epoch 2484, Loss: 2.065942645072937, Final Batch Loss: 0.21333619952201843\n",
      "Epoch 2485, Loss: 2.0110343396663666, Final Batch Loss: 0.23863184452056885\n",
      "Epoch 2486, Loss: 3.0609413981437683, Final Batch Loss: 1.09515380859375\n",
      "Epoch 2487, Loss: 2.1535410284996033, Final Batch Loss: 0.27221253514289856\n",
      "Epoch 2488, Loss: 2.5340255796909332, Final Batch Loss: 0.4575485289096832\n",
      "Epoch 2489, Loss: 2.189730614423752, Final Batch Loss: 0.36185792088508606\n",
      "Epoch 2490, Loss: 2.910626620054245, Final Batch Loss: 0.7740218043327332\n",
      "Epoch 2491, Loss: 2.567820727825165, Final Batch Loss: 0.5103812217712402\n",
      "Epoch 2492, Loss: 2.3377417847514153, Final Batch Loss: 0.12445812672376633\n",
      "Epoch 2493, Loss: 2.3719849288463593, Final Batch Loss: 0.20916184782981873\n",
      "Epoch 2494, Loss: 2.3518419563770294, Final Batch Loss: 0.4895254969596863\n",
      "Epoch 2495, Loss: 2.326157420873642, Final Batch Loss: 0.3219701647758484\n",
      "Epoch 2496, Loss: 2.2993346452713013, Final Batch Loss: 0.35911959409713745\n",
      "Epoch 2497, Loss: 2.2755719423294067, Final Batch Loss: 0.4320574104785919\n",
      "Epoch 2498, Loss: 2.5566603541374207, Final Batch Loss: 0.6950824856758118\n",
      "Epoch 2499, Loss: 2.377614438533783, Final Batch Loss: 0.4732740521430969\n",
      "Epoch 2500, Loss: 2.2764256596565247, Final Batch Loss: 0.3054618537425995\n",
      "Epoch 2501, Loss: 2.624867618083954, Final Batch Loss: 0.8096829056739807\n",
      "Epoch 2502, Loss: 2.515118360519409, Final Batch Loss: 0.8454322814941406\n",
      "Epoch 2503, Loss: 2.1118988692760468, Final Batch Loss: 0.3835779130458832\n",
      "Epoch 2504, Loss: 2.3026238083839417, Final Batch Loss: 0.5135388374328613\n",
      "Epoch 2505, Loss: 2.3477552831172943, Final Batch Loss: 0.364840567111969\n",
      "Epoch 2506, Loss: 2.537416160106659, Final Batch Loss: 0.577049195766449\n",
      "Epoch 2507, Loss: 2.230267971754074, Final Batch Loss: 0.41645029187202454\n",
      "Epoch 2508, Loss: 2.203364312648773, Final Batch Loss: 0.4404798448085785\n",
      "Epoch 2509, Loss: 2.44968119263649, Final Batch Loss: 0.44711992144584656\n",
      "Epoch 2510, Loss: 1.9944383800029755, Final Batch Loss: 0.20711323618888855\n",
      "Epoch 2511, Loss: 2.3148160576820374, Final Batch Loss: 0.3284982144832611\n",
      "Epoch 2512, Loss: 2.4316448271274567, Final Batch Loss: 0.6450889706611633\n",
      "Epoch 2513, Loss: 2.196633130311966, Final Batch Loss: 0.41016584634780884\n",
      "Epoch 2514, Loss: 2.1456366181373596, Final Batch Loss: 0.3655272424221039\n",
      "Epoch 2515, Loss: 2.213205397129059, Final Batch Loss: 0.48739194869995117\n",
      "Epoch 2516, Loss: 1.8906402289867401, Final Batch Loss: 0.1683865785598755\n",
      "Epoch 2517, Loss: 2.2887535393238068, Final Batch Loss: 0.5314214825630188\n",
      "Epoch 2518, Loss: 2.3013852536678314, Final Batch Loss: 0.6306419968605042\n",
      "Epoch 2519, Loss: 2.9154971837997437, Final Batch Loss: 0.9037254452705383\n",
      "Epoch 2520, Loss: 2.4471199810504913, Final Batch Loss: 0.5979999899864197\n",
      "Epoch 2521, Loss: 2.1880848705768585, Final Batch Loss: 0.28066349029541016\n",
      "Epoch 2522, Loss: 2.8295653760433197, Final Batch Loss: 0.7485468983650208\n",
      "Epoch 2523, Loss: 2.5889809131622314, Final Batch Loss: 0.6215121150016785\n",
      "Epoch 2524, Loss: 2.6361823081970215, Final Batch Loss: 0.6961243748664856\n",
      "Epoch 2525, Loss: 2.297898679971695, Final Batch Loss: 0.3556705117225647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2526, Loss: 2.261502653360367, Final Batch Loss: 0.4272761940956116\n",
      "Epoch 2527, Loss: 2.1544480323791504, Final Batch Loss: 0.25697240233421326\n",
      "Epoch 2528, Loss: 2.4674117267131805, Final Batch Loss: 0.5385541319847107\n",
      "Epoch 2529, Loss: 2.5986850261688232, Final Batch Loss: 0.7325648665428162\n",
      "Epoch 2530, Loss: 2.464818626642227, Final Batch Loss: 0.5956675410270691\n",
      "Epoch 2531, Loss: 2.5453465580940247, Final Batch Loss: 0.5887259244918823\n",
      "Epoch 2532, Loss: 2.382624626159668, Final Batch Loss: 0.4086960256099701\n",
      "Epoch 2533, Loss: 2.4911579191684723, Final Batch Loss: 0.5584818720817566\n",
      "Epoch 2534, Loss: 2.2949028313159943, Final Batch Loss: 0.4177544414997101\n",
      "Epoch 2535, Loss: 2.1260041147470474, Final Batch Loss: 0.24342648684978485\n",
      "Epoch 2536, Loss: 2.537354290485382, Final Batch Loss: 0.7165050506591797\n",
      "Epoch 2537, Loss: 2.556332379579544, Final Batch Loss: 0.7762006521224976\n",
      "Epoch 2538, Loss: 2.2348264157772064, Final Batch Loss: 0.4758768379688263\n",
      "Epoch 2539, Loss: 2.0676253139972687, Final Batch Loss: 0.2798173129558563\n",
      "Epoch 2540, Loss: 1.8951927870512009, Final Batch Loss: 0.12301088869571686\n",
      "Epoch 2541, Loss: 2.211635321378708, Final Batch Loss: 0.48533371090888977\n",
      "Epoch 2542, Loss: 2.5317522585392, Final Batch Loss: 0.7014349102973938\n",
      "Epoch 2543, Loss: 2.218195617198944, Final Batch Loss: 0.5168902277946472\n",
      "Epoch 2544, Loss: 2.206681579351425, Final Batch Loss: 0.440692663192749\n",
      "Epoch 2545, Loss: 2.102753311395645, Final Batch Loss: 0.3456003665924072\n",
      "Epoch 2546, Loss: 2.003901854157448, Final Batch Loss: 0.21216358244419098\n",
      "Epoch 2547, Loss: 2.194392740726471, Final Batch Loss: 0.4227305054664612\n",
      "Epoch 2548, Loss: 2.1998798847198486, Final Batch Loss: 0.4960913360118866\n",
      "Epoch 2549, Loss: 2.138864904642105, Final Batch Loss: 0.32892507314682007\n",
      "Epoch 2550, Loss: 2.186223477125168, Final Batch Loss: 0.3235565721988678\n",
      "Epoch 2551, Loss: 2.417240560054779, Final Batch Loss: 0.6601402163505554\n",
      "Epoch 2552, Loss: 2.1856072545051575, Final Batch Loss: 0.3513011932373047\n",
      "Epoch 2553, Loss: 2.1430861949920654, Final Batch Loss: 0.32882314920425415\n",
      "Epoch 2554, Loss: 2.402293860912323, Final Batch Loss: 0.3555178642272949\n",
      "Epoch 2555, Loss: 2.2432680428028107, Final Batch Loss: 0.3339664936065674\n",
      "Epoch 2556, Loss: 1.8027305528521538, Final Batch Loss: 0.09574829787015915\n",
      "Epoch 2557, Loss: 2.0605036914348602, Final Batch Loss: 0.25408706068992615\n",
      "Epoch 2558, Loss: 2.087823271751404, Final Batch Loss: 0.3491499722003937\n",
      "Epoch 2559, Loss: 1.9914143979549408, Final Batch Loss: 0.30727508664131165\n",
      "Epoch 2560, Loss: 2.3287457525730133, Final Batch Loss: 0.6440749168395996\n",
      "Epoch 2561, Loss: 1.9398638308048248, Final Batch Loss: 0.27654537558555603\n",
      "Epoch 2562, Loss: 2.316069006919861, Final Batch Loss: 0.47844013571739197\n",
      "Epoch 2563, Loss: 2.1032616198062897, Final Batch Loss: 0.32578662037849426\n",
      "Epoch 2564, Loss: 1.9111205786466599, Final Batch Loss: 0.19339536130428314\n",
      "Epoch 2565, Loss: 2.413260191679001, Final Batch Loss: 0.6101433038711548\n",
      "Epoch 2566, Loss: 2.1090900897979736, Final Batch Loss: 0.3154255449771881\n",
      "Epoch 2567, Loss: 2.280509889125824, Final Batch Loss: 0.48778605461120605\n",
      "Epoch 2568, Loss: 2.2096608579158783, Final Batch Loss: 0.4883587658405304\n",
      "Epoch 2569, Loss: 2.161540150642395, Final Batch Loss: 0.3144536316394806\n",
      "Epoch 2570, Loss: 2.3560870885849, Final Batch Loss: 0.7396392226219177\n",
      "Epoch 2571, Loss: 2.4462153911590576, Final Batch Loss: 0.5358715653419495\n",
      "Epoch 2572, Loss: 2.026651620864868, Final Batch Loss: 0.3331257998943329\n",
      "Epoch 2573, Loss: 2.5821499824523926, Final Batch Loss: 0.7271025776863098\n",
      "Epoch 2574, Loss: 2.5925876200199127, Final Batch Loss: 0.5914581418037415\n",
      "Epoch 2575, Loss: 2.393226742744446, Final Batch Loss: 0.5068885087966919\n",
      "Epoch 2576, Loss: 2.172064244747162, Final Batch Loss: 0.3618372082710266\n",
      "Epoch 2577, Loss: 2.365500718355179, Final Batch Loss: 0.5284711122512817\n",
      "Epoch 2578, Loss: 2.4967091381549835, Final Batch Loss: 0.6924340128898621\n",
      "Epoch 2579, Loss: 2.1036959886550903, Final Batch Loss: 0.26061922311782837\n",
      "Epoch 2580, Loss: 2.4331699907779694, Final Batch Loss: 0.5995002388954163\n",
      "Epoch 2581, Loss: 2.9735259115695953, Final Batch Loss: 1.01005220413208\n",
      "Epoch 2582, Loss: 2.1031754314899445, Final Batch Loss: 0.3485627770423889\n",
      "Epoch 2583, Loss: 2.262831687927246, Final Batch Loss: 0.450753778219223\n",
      "Epoch 2584, Loss: 2.206484019756317, Final Batch Loss: 0.26401403546333313\n",
      "Epoch 2585, Loss: 3.1361153721809387, Final Batch Loss: 1.259136438369751\n",
      "Epoch 2586, Loss: 2.0459416955709457, Final Batch Loss: 0.24901466071605682\n",
      "Epoch 2587, Loss: 2.397659182548523, Final Batch Loss: 0.4334495961666107\n",
      "Epoch 2588, Loss: 2.0961437821388245, Final Batch Loss: 0.2327374517917633\n",
      "Epoch 2589, Loss: 2.271179348230362, Final Batch Loss: 0.5076962113380432\n",
      "Epoch 2590, Loss: 2.004891574382782, Final Batch Loss: 0.3094885051250458\n",
      "Epoch 2591, Loss: 2.2191901206970215, Final Batch Loss: 0.4584965109825134\n",
      "Epoch 2592, Loss: 2.0462244153022766, Final Batch Loss: 0.29224586486816406\n",
      "Epoch 2593, Loss: 1.8196320980787277, Final Batch Loss: 0.16175906360149384\n",
      "Epoch 2594, Loss: 1.89141446352005, Final Batch Loss: 0.25150126218795776\n",
      "Epoch 2595, Loss: 1.9247018843889236, Final Batch Loss: 0.24706493318080902\n",
      "Epoch 2596, Loss: 1.8935186713933945, Final Batch Loss: 0.2427157610654831\n",
      "Epoch 2597, Loss: 2.5793787837028503, Final Batch Loss: 0.9323979020118713\n",
      "Epoch 2598, Loss: 2.296550989151001, Final Batch Loss: 0.5691825747489929\n",
      "Epoch 2599, Loss: 2.223492443561554, Final Batch Loss: 0.5599572658538818\n",
      "Epoch 2600, Loss: 1.878522351384163, Final Batch Loss: 0.16393958032131195\n",
      "Epoch 2601, Loss: 2.083825796842575, Final Batch Loss: 0.34430602192878723\n",
      "Epoch 2602, Loss: 2.363471418619156, Final Batch Loss: 0.4836260676383972\n",
      "Epoch 2603, Loss: 1.9069786220788956, Final Batch Loss: 0.1795145720243454\n",
      "Epoch 2604, Loss: 2.1531313955783844, Final Batch Loss: 0.35315439105033875\n",
      "Epoch 2605, Loss: 2.244580417871475, Final Batch Loss: 0.40131038427352905\n",
      "Epoch 2606, Loss: 2.240461051464081, Final Batch Loss: 0.49219486117362976\n",
      "Epoch 2607, Loss: 2.1409085392951965, Final Batch Loss: 0.4029294550418854\n",
      "Epoch 2608, Loss: 2.1951321363449097, Final Batch Loss: 0.548257052898407\n",
      "Epoch 2609, Loss: 2.1531072556972504, Final Batch Loss: 0.2796338200569153\n",
      "Epoch 2610, Loss: 2.293715238571167, Final Batch Loss: 0.5369309186935425\n",
      "Epoch 2611, Loss: 3.4574648439884186, Final Batch Loss: 1.6366721391677856\n",
      "Epoch 2612, Loss: 2.4314330518245697, Final Batch Loss: 0.6916300654411316\n",
      "Epoch 2613, Loss: 2.1936234533786774, Final Batch Loss: 0.462449312210083\n",
      "Epoch 2614, Loss: 2.154917150735855, Final Batch Loss: 0.45643308758735657\n",
      "Epoch 2615, Loss: 2.9461332857608795, Final Batch Loss: 1.1676102876663208\n",
      "Epoch 2616, Loss: 2.0336692333221436, Final Batch Loss: 0.28285372257232666\n",
      "Epoch 2617, Loss: 2.29631444811821, Final Batch Loss: 0.4956991672515869\n",
      "Epoch 2618, Loss: 1.870511993765831, Final Batch Loss: 0.15915800631046295\n",
      "Epoch 2619, Loss: 2.1080906987190247, Final Batch Loss: 0.2986036241054535\n",
      "Epoch 2620, Loss: 2.0959215462207794, Final Batch Loss: 0.39663800597190857\n",
      "Epoch 2621, Loss: 2.3471354246139526, Final Batch Loss: 0.29200902581214905\n",
      "Epoch 2622, Loss: 2.30974805355072, Final Batch Loss: 0.4435124099254608\n",
      "Epoch 2623, Loss: 2.2219917476177216, Final Batch Loss: 0.46539780497550964\n",
      "Epoch 2624, Loss: 2.49362114071846, Final Batch Loss: 0.7481227517127991\n",
      "Epoch 2625, Loss: 2.599359393119812, Final Batch Loss: 0.8385242223739624\n",
      "Epoch 2626, Loss: 1.780087523162365, Final Batch Loss: 0.07637762278318405\n",
      "Epoch 2627, Loss: 2.1101622730493546, Final Batch Loss: 0.198701873421669\n",
      "Epoch 2628, Loss: 2.107772469520569, Final Batch Loss: 0.3499162793159485\n",
      "Epoch 2629, Loss: 2.2700237929821014, Final Batch Loss: 0.5218145251274109\n",
      "Epoch 2630, Loss: 2.3327762484550476, Final Batch Loss: 0.6266668438911438\n",
      "Epoch 2631, Loss: 2.078350305557251, Final Batch Loss: 0.28750157356262207\n",
      "Epoch 2632, Loss: 2.3407576382160187, Final Batch Loss: 0.5701690912246704\n",
      "Epoch 2633, Loss: 2.5919072329998016, Final Batch Loss: 0.7078713774681091\n",
      "Epoch 2634, Loss: 2.0255326479673386, Final Batch Loss: 0.16255329549312592\n",
      "Epoch 2635, Loss: 1.9269102662801743, Final Batch Loss: 0.1321239024400711\n",
      "Epoch 2636, Loss: 1.93143555149436, Final Batch Loss: 0.04663070663809776\n",
      "Epoch 2637, Loss: 2.1296344101428986, Final Batch Loss: 0.42501100897789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2638, Loss: 2.0808898508548737, Final Batch Loss: 0.31977930665016174\n",
      "Epoch 2639, Loss: 2.141147643327713, Final Batch Loss: 0.46520185470581055\n",
      "Epoch 2640, Loss: 2.5002021193504333, Final Batch Loss: 0.8686383366584778\n",
      "Epoch 2641, Loss: 2.1077721118927, Final Batch Loss: 0.274113267660141\n",
      "Epoch 2642, Loss: 2.1034438610076904, Final Batch Loss: 0.24755975604057312\n",
      "Epoch 2643, Loss: 2.1445159018039703, Final Batch Loss: 0.32886749505996704\n",
      "Epoch 2644, Loss: 2.355714499950409, Final Batch Loss: 0.6340789794921875\n",
      "Epoch 2645, Loss: 2.3475427329540253, Final Batch Loss: 0.6276435256004333\n",
      "Epoch 2646, Loss: 2.3015018701553345, Final Batch Loss: 0.6504054069519043\n",
      "Epoch 2647, Loss: 2.296181596815586, Final Batch Loss: 0.11645705252885818\n",
      "Epoch 2648, Loss: 1.9240400344133377, Final Batch Loss: 0.1661347895860672\n",
      "Epoch 2649, Loss: 2.2283279597759247, Final Batch Loss: 0.5688000321388245\n",
      "Epoch 2650, Loss: 2.5038812458515167, Final Batch Loss: 0.6037664413452148\n",
      "Epoch 2651, Loss: 2.0756202936172485, Final Batch Loss: 0.2816300094127655\n",
      "Epoch 2652, Loss: 1.9908294975757599, Final Batch Loss: 0.2747900187969208\n",
      "Epoch 2653, Loss: 2.1334840059280396, Final Batch Loss: 0.3448824882507324\n",
      "Epoch 2654, Loss: 2.4394049644470215, Final Batch Loss: 0.5882533192634583\n",
      "Epoch 2655, Loss: 1.9470586776733398, Final Batch Loss: 0.25655457377433777\n",
      "Epoch 2656, Loss: 2.155743420124054, Final Batch Loss: 0.37580418586730957\n",
      "Epoch 2657, Loss: 2.311960279941559, Final Batch Loss: 0.5980388522148132\n",
      "Epoch 2658, Loss: 2.2539446353912354, Final Batch Loss: 0.3973066508769989\n",
      "Epoch 2659, Loss: 2.3398500084877014, Final Batch Loss: 0.49872395396232605\n",
      "Epoch 2660, Loss: 2.3924993872642517, Final Batch Loss: 0.6086261868476868\n",
      "Epoch 2661, Loss: 2.1539425551891327, Final Batch Loss: 0.3010724186897278\n",
      "Epoch 2662, Loss: 2.0844076573848724, Final Batch Loss: 0.3648298382759094\n",
      "Epoch 2663, Loss: 2.158766597509384, Final Batch Loss: 0.4462280571460724\n",
      "Epoch 2664, Loss: 2.32241228222847, Final Batch Loss: 0.516118049621582\n",
      "Epoch 2665, Loss: 1.9619020223617554, Final Batch Loss: 0.2714062035083771\n",
      "Epoch 2666, Loss: 1.9940874725580215, Final Batch Loss: 0.24579991400241852\n",
      "Epoch 2667, Loss: 2.394638031721115, Final Batch Loss: 0.618037223815918\n",
      "Epoch 2668, Loss: 2.144345074892044, Final Batch Loss: 0.5144150853157043\n",
      "Epoch 2669, Loss: 2.8747965693473816, Final Batch Loss: 1.1296006441116333\n",
      "Epoch 2670, Loss: 2.2589728236198425, Final Batch Loss: 0.6710503697395325\n",
      "Epoch 2671, Loss: 2.1482973396778107, Final Batch Loss: 0.34374502301216125\n",
      "Epoch 2672, Loss: 2.156129479408264, Final Batch Loss: 0.277802050113678\n",
      "Epoch 2673, Loss: 2.4334080815315247, Final Batch Loss: 0.5251054167747498\n",
      "Epoch 2674, Loss: 2.11822971701622, Final Batch Loss: 0.3126041889190674\n",
      "Epoch 2675, Loss: 1.9805348068475723, Final Batch Loss: 0.1677730530500412\n",
      "Epoch 2676, Loss: 1.999917060136795, Final Batch Loss: 0.29015445709228516\n",
      "Epoch 2677, Loss: 2.622687131166458, Final Batch Loss: 0.7789958715438843\n",
      "Epoch 2678, Loss: 2.2522363662719727, Final Batch Loss: 0.5929170250892639\n",
      "Epoch 2679, Loss: 2.108188718557358, Final Batch Loss: 0.32360944151878357\n",
      "Epoch 2680, Loss: 2.1382861137390137, Final Batch Loss: 0.4377022683620453\n",
      "Epoch 2681, Loss: 2.3090680837631226, Final Batch Loss: 0.36776116490364075\n",
      "Epoch 2682, Loss: 1.9453882277011871, Final Batch Loss: 0.2725224792957306\n",
      "Epoch 2683, Loss: 2.068530321121216, Final Batch Loss: 0.3860023319721222\n",
      "Epoch 2684, Loss: 2.112313747406006, Final Batch Loss: 0.45462051033973694\n",
      "Epoch 2685, Loss: 2.285082757472992, Final Batch Loss: 0.6753902435302734\n",
      "Epoch 2686, Loss: 2.0923683643341064, Final Batch Loss: 0.4137392044067383\n",
      "Epoch 2687, Loss: 2.4962768256664276, Final Batch Loss: 0.6014037132263184\n",
      "Epoch 2688, Loss: 2.555991530418396, Final Batch Loss: 0.7806097269058228\n",
      "Epoch 2689, Loss: 2.30851411819458, Final Batch Loss: 0.5648508667945862\n",
      "Epoch 2690, Loss: 2.1127515733242035, Final Batch Loss: 0.377406507730484\n",
      "Epoch 2691, Loss: 1.804629534482956, Final Batch Loss: 0.13142159581184387\n",
      "Epoch 2692, Loss: 2.092970848083496, Final Batch Loss: 0.361975759267807\n",
      "Epoch 2693, Loss: 2.098533183336258, Final Batch Loss: 0.39256757497787476\n",
      "Epoch 2694, Loss: 2.284627467393875, Final Batch Loss: 0.4176543354988098\n",
      "Epoch 2695, Loss: 1.9051068127155304, Final Batch Loss: 0.25116509199142456\n",
      "Epoch 2696, Loss: 2.119302898645401, Final Batch Loss: 0.3908619284629822\n",
      "Epoch 2697, Loss: 1.8903448581695557, Final Batch Loss: 0.1845766305923462\n",
      "Epoch 2698, Loss: 2.271586298942566, Final Batch Loss: 0.626830518245697\n",
      "Epoch 2699, Loss: 2.33321076631546, Final Batch Loss: 0.6295371651649475\n",
      "Epoch 2700, Loss: 2.0267395973205566, Final Batch Loss: 0.2894819676876068\n",
      "Epoch 2701, Loss: 2.227438062429428, Final Batch Loss: 0.5320094227790833\n",
      "Epoch 2702, Loss: 2.1841706037521362, Final Batch Loss: 0.4131771922111511\n",
      "Epoch 2703, Loss: 2.4464845657348633, Final Batch Loss: 0.7469921708106995\n",
      "Epoch 2704, Loss: 2.0191698372364044, Final Batch Loss: 0.44686296582221985\n",
      "Epoch 2705, Loss: 2.4854361414909363, Final Batch Loss: 0.7004013657569885\n",
      "Epoch 2706, Loss: 1.8722280710935593, Final Batch Loss: 0.2487620860338211\n",
      "Epoch 2707, Loss: 2.2316761910915375, Final Batch Loss: 0.5805326104164124\n",
      "Epoch 2708, Loss: 2.239524185657501, Final Batch Loss: 0.4874882996082306\n",
      "Epoch 2709, Loss: 1.9188505411148071, Final Batch Loss: 0.2674901485443115\n",
      "Epoch 2710, Loss: 2.146819978952408, Final Batch Loss: 0.36060118675231934\n",
      "Epoch 2711, Loss: 1.8311061710119247, Final Batch Loss: 0.16941283643245697\n",
      "Epoch 2712, Loss: 2.1444186568260193, Final Batch Loss: 0.39996078610420227\n",
      "Epoch 2713, Loss: 2.302722752094269, Final Batch Loss: 0.6898294687271118\n",
      "Epoch 2714, Loss: 2.065687835216522, Final Batch Loss: 0.2685733139514923\n",
      "Epoch 2715, Loss: 2.2037991285324097, Final Batch Loss: 0.4304886758327484\n",
      "Epoch 2716, Loss: 2.041054368019104, Final Batch Loss: 0.33700746297836304\n",
      "Epoch 2717, Loss: 2.1052215695381165, Final Batch Loss: 0.28538888692855835\n",
      "Epoch 2718, Loss: 2.30511337518692, Final Batch Loss: 0.5409179925918579\n",
      "Epoch 2719, Loss: 2.208693027496338, Final Batch Loss: 0.3994872272014618\n",
      "Epoch 2720, Loss: 2.091414749622345, Final Batch Loss: 0.3244587481021881\n",
      "Epoch 2721, Loss: 2.7923097014427185, Final Batch Loss: 0.937254786491394\n",
      "Epoch 2722, Loss: 2.0007421672344208, Final Batch Loss: 0.32778310775756836\n",
      "Epoch 2723, Loss: 2.241365522146225, Final Batch Loss: 0.5479090809822083\n",
      "Epoch 2724, Loss: 2.2230096757411957, Final Batch Loss: 0.5491587519645691\n",
      "Epoch 2725, Loss: 2.201423317193985, Final Batch Loss: 0.4414041340351105\n",
      "Epoch 2726, Loss: 1.9527735263109207, Final Batch Loss: 0.2418794482946396\n",
      "Epoch 2727, Loss: 2.213643729686737, Final Batch Loss: 0.5695955157279968\n",
      "Epoch 2728, Loss: 2.114035338163376, Final Batch Loss: 0.2706960141658783\n",
      "Epoch 2729, Loss: 2.5310312509536743, Final Batch Loss: 0.8188864588737488\n",
      "Epoch 2730, Loss: 2.379848688840866, Final Batch Loss: 0.6069642305374146\n",
      "Epoch 2731, Loss: 2.2143997848033905, Final Batch Loss: 0.4037664234638214\n",
      "Epoch 2732, Loss: 2.225414991378784, Final Batch Loss: 0.5465577244758606\n",
      "Epoch 2733, Loss: 2.5991793870925903, Final Batch Loss: 0.7541964650154114\n",
      "Epoch 2734, Loss: 2.1238468885421753, Final Batch Loss: 0.34815865755081177\n",
      "Epoch 2735, Loss: 2.1211012303829193, Final Batch Loss: 0.46053165197372437\n",
      "Epoch 2736, Loss: 1.8281210958957672, Final Batch Loss: 0.0792001485824585\n",
      "Epoch 2737, Loss: 2.2780114710330963, Final Batch Loss: 0.6866171956062317\n",
      "Epoch 2738, Loss: 2.2287057042121887, Final Batch Loss: 0.4407145380973816\n",
      "Epoch 2739, Loss: 2.084342509508133, Final Batch Loss: 0.3754153549671173\n",
      "Epoch 2740, Loss: 2.5217241048812866, Final Batch Loss: 0.8020447492599487\n",
      "Epoch 2741, Loss: 1.8126150965690613, Final Batch Loss: 0.16672039031982422\n",
      "Epoch 2742, Loss: 2.3758829534053802, Final Batch Loss: 0.4937455356121063\n",
      "Epoch 2743, Loss: 2.194882035255432, Final Batch Loss: 0.43570950627326965\n",
      "Epoch 2744, Loss: 2.1095942854881287, Final Batch Loss: 0.29266032576560974\n",
      "Epoch 2745, Loss: 2.4489005506038666, Final Batch Loss: 0.4864484965801239\n",
      "Epoch 2746, Loss: 2.34992453455925, Final Batch Loss: 0.5087922811508179\n",
      "Epoch 2747, Loss: 2.200824409723282, Final Batch Loss: 0.3728525638580322\n",
      "Epoch 2748, Loss: 2.0110521465539932, Final Batch Loss: 0.20226357877254486\n",
      "Epoch 2749, Loss: 2.1213541626930237, Final Batch Loss: 0.4354102611541748\n",
      "Epoch 2750, Loss: 2.407738536596298, Final Batch Loss: 0.736083447933197\n",
      "Epoch 2751, Loss: 2.5131982564926147, Final Batch Loss: 0.7294646501541138\n",
      "Epoch 2752, Loss: 2.14286670088768, Final Batch Loss: 0.4939911961555481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2753, Loss: 2.76668643951416, Final Batch Loss: 0.9775711297988892\n",
      "Epoch 2754, Loss: 2.114558130502701, Final Batch Loss: 0.4408414661884308\n",
      "Epoch 2755, Loss: 2.0023163855075836, Final Batch Loss: 0.27182719111442566\n",
      "Epoch 2756, Loss: 2.597074657678604, Final Batch Loss: 0.7950459718704224\n",
      "Epoch 2757, Loss: 1.974126473069191, Final Batch Loss: 0.1328161507844925\n",
      "Epoch 2758, Loss: 2.518265813589096, Final Batch Loss: 0.5570271611213684\n",
      "Epoch 2759, Loss: 2.31060591340065, Final Batch Loss: 0.40444332361221313\n",
      "Epoch 2760, Loss: 2.277839183807373, Final Batch Loss: 0.3467670977115631\n",
      "Epoch 2761, Loss: 2.5744604766368866, Final Batch Loss: 0.7240412831306458\n",
      "Epoch 2762, Loss: 2.0091340839862823, Final Batch Loss: 0.2970651090145111\n",
      "Epoch 2763, Loss: 2.3267787396907806, Final Batch Loss: 0.5255027413368225\n",
      "Epoch 2764, Loss: 2.2391558587551117, Final Batch Loss: 0.45804402232170105\n",
      "Epoch 2765, Loss: 2.188140332698822, Final Batch Loss: 0.3207956850528717\n",
      "Epoch 2766, Loss: 2.059954807162285, Final Batch Loss: 0.1178000420331955\n",
      "Epoch 2767, Loss: 2.393893390893936, Final Batch Loss: 0.4677760601043701\n",
      "Epoch 2768, Loss: 2.0515124797821045, Final Batch Loss: 0.29225364327430725\n",
      "Epoch 2769, Loss: 2.199395641684532, Final Batch Loss: 0.23989905416965485\n",
      "Epoch 2770, Loss: 1.8832235634326935, Final Batch Loss: 0.09579092264175415\n",
      "Epoch 2771, Loss: 1.9377524107694626, Final Batch Loss: 0.12634186446666718\n",
      "Epoch 2772, Loss: 2.216403543949127, Final Batch Loss: 0.46931928396224976\n",
      "Epoch 2773, Loss: 2.3719727098941803, Final Batch Loss: 0.5269149541854858\n",
      "Epoch 2774, Loss: 2.083470582962036, Final Batch Loss: 0.3160608112812042\n",
      "Epoch 2775, Loss: 2.0226627737283707, Final Batch Loss: 0.10510669648647308\n",
      "Epoch 2776, Loss: 2.21898752450943, Final Batch Loss: 0.44987088441848755\n",
      "Epoch 2777, Loss: 1.9771944731473923, Final Batch Loss: 0.23681513965129852\n",
      "Epoch 2778, Loss: 2.051054395735264, Final Batch Loss: 0.09449572116136551\n",
      "Epoch 2779, Loss: 1.9592791348695755, Final Batch Loss: 0.2310151904821396\n",
      "Epoch 2780, Loss: 2.351459115743637, Final Batch Loss: 0.5008052587509155\n",
      "Epoch 2781, Loss: 1.9447315335273743, Final Batch Loss: 0.2532885670661926\n",
      "Epoch 2782, Loss: 2.1832271218299866, Final Batch Loss: 0.47993189096450806\n",
      "Epoch 2783, Loss: 2.2483279407024384, Final Batch Loss: 0.509132444858551\n",
      "Epoch 2784, Loss: 2.22719407081604, Final Batch Loss: 0.5164238810539246\n",
      "Epoch 2785, Loss: 2.421277940273285, Final Batch Loss: 0.4961180090904236\n",
      "Epoch 2786, Loss: 2.6328366100788116, Final Batch Loss: 0.9026041030883789\n",
      "Epoch 2787, Loss: 2.1105481684207916, Final Batch Loss: 0.3683170974254608\n",
      "Epoch 2788, Loss: 1.9701098501682281, Final Batch Loss: 0.2548295855522156\n",
      "Epoch 2789, Loss: 2.2955457866191864, Final Batch Loss: 0.6409450769424438\n",
      "Epoch 2790, Loss: 2.3736615777015686, Final Batch Loss: 0.6498441100120544\n",
      "Epoch 2791, Loss: 2.0867637991905212, Final Batch Loss: 0.46300071477890015\n",
      "Epoch 2792, Loss: 1.9926606863737106, Final Batch Loss: 0.248893603682518\n",
      "Epoch 2793, Loss: 1.9742750525474548, Final Batch Loss: 0.3067382872104645\n",
      "Epoch 2794, Loss: 1.937880516052246, Final Batch Loss: 0.32790160179138184\n",
      "Epoch 2795, Loss: 2.1834063827991486, Final Batch Loss: 0.5684736967086792\n",
      "Epoch 2796, Loss: 2.05752095580101, Final Batch Loss: 0.3249908983707428\n",
      "Epoch 2797, Loss: 2.02458718419075, Final Batch Loss: 0.38763874769210815\n",
      "Epoch 2798, Loss: 1.98703533411026, Final Batch Loss: 0.25940027832984924\n",
      "Epoch 2799, Loss: 2.0398344695568085, Final Batch Loss: 0.4116656184196472\n",
      "Epoch 2800, Loss: 1.9850354492664337, Final Batch Loss: 0.3585963547229767\n",
      "Epoch 2801, Loss: 2.043080598115921, Final Batch Loss: 0.33850184082984924\n",
      "Epoch 2802, Loss: 2.284771054983139, Final Batch Loss: 0.5301466584205627\n",
      "Epoch 2803, Loss: 2.040260970592499, Final Batch Loss: 0.2618655562400818\n",
      "Epoch 2804, Loss: 2.1160126626491547, Final Batch Loss: 0.5157372355461121\n",
      "Epoch 2805, Loss: 1.956392914056778, Final Batch Loss: 0.18685314059257507\n",
      "Epoch 2806, Loss: 2.2454740703105927, Final Batch Loss: 0.5945038795471191\n",
      "Epoch 2807, Loss: 1.9092233926057816, Final Batch Loss: 0.19363506138324738\n",
      "Epoch 2808, Loss: 2.1592524647712708, Final Batch Loss: 0.36958032846450806\n",
      "Epoch 2809, Loss: 2.36716166138649, Final Batch Loss: 0.598124623298645\n",
      "Epoch 2810, Loss: 2.0221492648124695, Final Batch Loss: 0.28397074341773987\n",
      "Epoch 2811, Loss: 2.0162366926670074, Final Batch Loss: 0.444700688123703\n",
      "Epoch 2812, Loss: 2.4574227333068848, Final Batch Loss: 0.7962007522583008\n",
      "Epoch 2813, Loss: 2.130648761987686, Final Batch Loss: 0.4700481593608856\n",
      "Epoch 2814, Loss: 2.1764671206474304, Final Batch Loss: 0.3621712327003479\n",
      "Epoch 2815, Loss: 2.238476514816284, Final Batch Loss: 0.42314061522483826\n",
      "Epoch 2816, Loss: 1.9529170989990234, Final Batch Loss: 0.3544771075248718\n",
      "Epoch 2817, Loss: 1.9396987408399582, Final Batch Loss: 0.17480985820293427\n",
      "Epoch 2818, Loss: 1.8705576658248901, Final Batch Loss: 0.20142397284507751\n",
      "Epoch 2819, Loss: 2.5360412001609802, Final Batch Loss: 0.7815607786178589\n",
      "Epoch 2820, Loss: 2.0026333034038544, Final Batch Loss: 0.37964436411857605\n",
      "Epoch 2821, Loss: 2.064937502145767, Final Batch Loss: 0.34100860357284546\n",
      "Epoch 2822, Loss: 2.1001604199409485, Final Batch Loss: 0.40296491980552673\n",
      "Epoch 2823, Loss: 2.115470290184021, Final Batch Loss: 0.3332099914550781\n",
      "Epoch 2824, Loss: 1.9741386026144028, Final Batch Loss: 0.12554247677326202\n",
      "Epoch 2825, Loss: 2.02184596657753, Final Batch Loss: 0.3155743181705475\n",
      "Epoch 2826, Loss: 2.324371039867401, Final Batch Loss: 0.6050662994384766\n",
      "Epoch 2827, Loss: 2.0439224541187286, Final Batch Loss: 0.40534067153930664\n",
      "Epoch 2828, Loss: 1.8512465953826904, Final Batch Loss: 0.1449403464794159\n",
      "Epoch 2829, Loss: 2.1035256683826447, Final Batch Loss: 0.3004491627216339\n",
      "Epoch 2830, Loss: 2.548154443502426, Final Batch Loss: 0.7718963027000427\n",
      "Epoch 2831, Loss: 2.2753401696681976, Final Batch Loss: 0.45702096819877625\n",
      "Epoch 2832, Loss: 2.253870278596878, Final Batch Loss: 0.4946838915348053\n",
      "Epoch 2833, Loss: 2.2553955912590027, Final Batch Loss: 0.5872467160224915\n",
      "Epoch 2834, Loss: 2.2754275500774384, Final Batch Loss: 0.42051711678504944\n",
      "Epoch 2835, Loss: 2.118161767721176, Final Batch Loss: 0.43955370783805847\n",
      "Epoch 2836, Loss: 1.956691935658455, Final Batch Loss: 0.19495941698551178\n",
      "Epoch 2837, Loss: 2.4429832696914673, Final Batch Loss: 0.6597045660018921\n",
      "Epoch 2838, Loss: 1.786721557378769, Final Batch Loss: 0.2069249451160431\n",
      "Epoch 2839, Loss: 2.2361009418964386, Final Batch Loss: 0.2947762608528137\n",
      "Epoch 2840, Loss: 1.938526175916195, Final Batch Loss: 0.11095824092626572\n",
      "Epoch 2841, Loss: 2.1589701771736145, Final Batch Loss: 0.41507813334465027\n",
      "Epoch 2842, Loss: 1.9461850821971893, Final Batch Loss: 0.19339466094970703\n",
      "Epoch 2843, Loss: 2.111190587282181, Final Batch Loss: 0.3972824513912201\n",
      "Epoch 2844, Loss: 2.155386984348297, Final Batch Loss: 0.40923771262168884\n",
      "Epoch 2845, Loss: 2.301628589630127, Final Batch Loss: 0.6657697558403015\n",
      "Epoch 2846, Loss: 2.0837469696998596, Final Batch Loss: 0.47628384828567505\n",
      "Epoch 2847, Loss: 2.5481460988521576, Final Batch Loss: 0.8420548439025879\n",
      "Epoch 2848, Loss: 2.2135795950889587, Final Batch Loss: 0.3340725004673004\n",
      "Epoch 2849, Loss: 2.113333150744438, Final Batch Loss: 0.15374447405338287\n",
      "Epoch 2850, Loss: 1.6570856273174286, Final Batch Loss: 0.07664090394973755\n",
      "Epoch 2851, Loss: 2.2738139033317566, Final Batch Loss: 0.5074664354324341\n",
      "Epoch 2852, Loss: 1.9120889157056808, Final Batch Loss: 0.17938543856143951\n",
      "Epoch 2853, Loss: 2.1713334918022156, Final Batch Loss: 0.6047910451889038\n",
      "Epoch 2854, Loss: 2.117979943752289, Final Batch Loss: 0.40307602286338806\n",
      "Epoch 2855, Loss: 1.7653682231903076, Final Batch Loss: 0.17786359786987305\n",
      "Epoch 2856, Loss: 1.803728461265564, Final Batch Loss: 0.2958647310733795\n",
      "Epoch 2857, Loss: 1.958426833152771, Final Batch Loss: 0.2841682732105255\n",
      "Epoch 2858, Loss: 2.2554311752319336, Final Batch Loss: 0.4507216811180115\n",
      "Epoch 2859, Loss: 2.1321409940719604, Final Batch Loss: 0.38533225655555725\n",
      "Epoch 2860, Loss: 1.93479385972023, Final Batch Loss: 0.339448481798172\n",
      "Epoch 2861, Loss: 2.092996269464493, Final Batch Loss: 0.3568967878818512\n",
      "Epoch 2862, Loss: 2.0446283519268036, Final Batch Loss: 0.4136212170124054\n",
      "Epoch 2863, Loss: 1.9886536598205566, Final Batch Loss: 0.26657941937446594\n",
      "Epoch 2864, Loss: 1.8149576112627983, Final Batch Loss: 0.06456878036260605\n",
      "Epoch 2865, Loss: 2.306006282567978, Final Batch Loss: 0.7484031915664673\n",
      "Epoch 2866, Loss: 2.6532972157001495, Final Batch Loss: 1.0957053899765015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2867, Loss: 3.0313863456249237, Final Batch Loss: 1.251320242881775\n",
      "Epoch 2868, Loss: 2.129241019487381, Final Batch Loss: 0.42052868008613586\n",
      "Epoch 2869, Loss: 2.417256146669388, Final Batch Loss: 0.7127469182014465\n",
      "Epoch 2870, Loss: 2.183129608631134, Final Batch Loss: 0.34502068161964417\n",
      "Epoch 2871, Loss: 1.9582498371601105, Final Batch Loss: 0.2372501790523529\n",
      "Epoch 2872, Loss: 2.281750828027725, Final Batch Loss: 0.6187458634376526\n",
      "Epoch 2873, Loss: 1.9857287108898163, Final Batch Loss: 0.3545680046081543\n",
      "Epoch 2874, Loss: 3.2012146711349487, Final Batch Loss: 1.5564415454864502\n",
      "Epoch 2875, Loss: 2.38928359746933, Final Batch Loss: 0.6933953166007996\n",
      "Epoch 2876, Loss: 2.461201459169388, Final Batch Loss: 0.7049392461776733\n",
      "Epoch 2877, Loss: 1.8384216725826263, Final Batch Loss: 0.26571330428123474\n",
      "Epoch 2878, Loss: 1.881884753704071, Final Batch Loss: 0.17688524723052979\n",
      "Epoch 2879, Loss: 2.1206029057502747, Final Batch Loss: 0.5118256211280823\n",
      "Epoch 2880, Loss: 2.130583345890045, Final Batch Loss: 0.287067711353302\n",
      "Epoch 2881, Loss: 1.9428477883338928, Final Batch Loss: 0.2285408079624176\n",
      "Epoch 2882, Loss: 1.7959049940109253, Final Batch Loss: 0.1446991264820099\n",
      "Epoch 2883, Loss: 2.400690406560898, Final Batch Loss: 0.825078547000885\n",
      "Epoch 2884, Loss: 2.180532604455948, Final Batch Loss: 0.5137608647346497\n",
      "Epoch 2885, Loss: 2.2860758900642395, Final Batch Loss: 0.46602004766464233\n",
      "Epoch 2886, Loss: 2.0548028647899628, Final Batch Loss: 0.4662463366985321\n",
      "Epoch 2887, Loss: 1.8987780511379242, Final Batch Loss: 0.30225759744644165\n",
      "Epoch 2888, Loss: 2.1012958586215973, Final Batch Loss: 0.4347088634967804\n",
      "Epoch 2889, Loss: 1.8904121667146683, Final Batch Loss: 0.21492190659046173\n",
      "Epoch 2890, Loss: 2.078585684299469, Final Batch Loss: 0.41311416029930115\n",
      "Epoch 2891, Loss: 2.225154995918274, Final Batch Loss: 0.6698898673057556\n",
      "Epoch 2892, Loss: 2.3152716755867004, Final Batch Loss: 0.5971636176109314\n",
      "Epoch 2893, Loss: 2.0721780955791473, Final Batch Loss: 0.2009100615978241\n",
      "Epoch 2894, Loss: 2.1910199522972107, Final Batch Loss: 0.48522210121154785\n",
      "Epoch 2895, Loss: 1.6951623186469078, Final Batch Loss: 0.08959298580884933\n",
      "Epoch 2896, Loss: 2.723237156867981, Final Batch Loss: 1.048826813697815\n",
      "Epoch 2897, Loss: 2.2090996503829956, Final Batch Loss: 0.3806571364402771\n",
      "Epoch 2898, Loss: 2.0152519047260284, Final Batch Loss: 0.33100101351737976\n",
      "Epoch 2899, Loss: 1.954569786787033, Final Batch Loss: 0.23988935351371765\n",
      "Epoch 2900, Loss: 2.3272576332092285, Final Batch Loss: 0.5331237316131592\n",
      "Epoch 2901, Loss: 1.8649716824293137, Final Batch Loss: 0.16206799447536469\n",
      "Epoch 2902, Loss: 2.0034259259700775, Final Batch Loss: 0.40383604168891907\n",
      "Epoch 2903, Loss: 2.0345315039157867, Final Batch Loss: 0.4319364130496979\n",
      "Epoch 2904, Loss: 2.170872747898102, Final Batch Loss: 0.5369365215301514\n",
      "Epoch 2905, Loss: 2.430241674184799, Final Batch Loss: 0.8684877157211304\n",
      "Epoch 2906, Loss: 2.165340155363083, Final Batch Loss: 0.2753242254257202\n",
      "Epoch 2907, Loss: 2.049884557723999, Final Batch Loss: 0.3832417130470276\n",
      "Epoch 2908, Loss: 2.3210637271404266, Final Batch Loss: 0.7796885371208191\n",
      "Epoch 2909, Loss: 2.145924985408783, Final Batch Loss: 0.38589414954185486\n",
      "Epoch 2910, Loss: 2.101698338985443, Final Batch Loss: 0.4398396909236908\n",
      "Epoch 2911, Loss: 1.996325820684433, Final Batch Loss: 0.34974542260169983\n",
      "Epoch 2912, Loss: 2.0405211746692657, Final Batch Loss: 0.38816097378730774\n",
      "Epoch 2913, Loss: 2.2578835487365723, Final Batch Loss: 0.6421800851821899\n",
      "Epoch 2914, Loss: 1.9550452828407288, Final Batch Loss: 0.29584890604019165\n",
      "Epoch 2915, Loss: 2.0695399045944214, Final Batch Loss: 0.43149182200431824\n",
      "Epoch 2916, Loss: 2.0604726672172546, Final Batch Loss: 0.2954873740673065\n",
      "Epoch 2917, Loss: 1.9553252458572388, Final Batch Loss: 0.26470497250556946\n",
      "Epoch 2918, Loss: 2.28208190202713, Final Batch Loss: 0.550942599773407\n",
      "Epoch 2919, Loss: 2.1174468398094177, Final Batch Loss: 0.3257555663585663\n",
      "Epoch 2920, Loss: 2.3262869715690613, Final Batch Loss: 0.5703936815261841\n",
      "Epoch 2921, Loss: 2.0398967564105988, Final Batch Loss: 0.35552293062210083\n",
      "Epoch 2922, Loss: 2.2817423343658447, Final Batch Loss: 0.6981316208839417\n",
      "Epoch 2923, Loss: 2.0993764400482178, Final Batch Loss: 0.41440349817276\n",
      "Epoch 2924, Loss: 2.0226247012615204, Final Batch Loss: 0.36483460664749146\n",
      "Epoch 2925, Loss: 2.461338520050049, Final Batch Loss: 0.7062004804611206\n",
      "Epoch 2926, Loss: 2.727979362010956, Final Batch Loss: 1.027190089225769\n",
      "Epoch 2927, Loss: 2.3772221207618713, Final Batch Loss: 0.6385555267333984\n",
      "Epoch 2928, Loss: 1.9035972952842712, Final Batch Loss: 0.3222941756248474\n",
      "Epoch 2929, Loss: 2.017120808362961, Final Batch Loss: 0.31451013684272766\n",
      "Epoch 2930, Loss: 2.1558846831321716, Final Batch Loss: 0.3842925429344177\n",
      "Epoch 2931, Loss: 1.9659750163555145, Final Batch Loss: 0.35855764150619507\n",
      "Epoch 2932, Loss: 2.0046878904104233, Final Batch Loss: 0.2293858677148819\n",
      "Epoch 2933, Loss: 1.9014541506767273, Final Batch Loss: 0.22070693969726562\n",
      "Epoch 2934, Loss: 1.9422686100006104, Final Batch Loss: 0.3960244953632355\n",
      "Epoch 2935, Loss: 2.650332123041153, Final Batch Loss: 0.85655277967453\n",
      "Epoch 2936, Loss: 2.1472243666648865, Final Batch Loss: 0.48895224928855896\n",
      "Epoch 2937, Loss: 1.9544731378555298, Final Batch Loss: 0.26239195466041565\n",
      "Epoch 2938, Loss: 2.0413988530635834, Final Batch Loss: 0.4543516933917999\n",
      "Epoch 2939, Loss: 2.004560887813568, Final Batch Loss: 0.31822898983955383\n",
      "Epoch 2940, Loss: 2.0750545263290405, Final Batch Loss: 0.5268123745918274\n",
      "Epoch 2941, Loss: 1.8793113827705383, Final Batch Loss: 0.3889469504356384\n",
      "Epoch 2942, Loss: 2.175629436969757, Final Batch Loss: 0.38803672790527344\n",
      "Epoch 2943, Loss: 2.1953775882720947, Final Batch Loss: 0.6738258600234985\n",
      "Epoch 2944, Loss: 2.0798868536949158, Final Batch Loss: 0.4291219711303711\n",
      "Epoch 2945, Loss: 2.393649935722351, Final Batch Loss: 0.693468451499939\n",
      "Epoch 2946, Loss: 2.0911634862422943, Final Batch Loss: 0.5193926095962524\n",
      "Epoch 2947, Loss: 1.7457748800516129, Final Batch Loss: 0.14456342160701752\n",
      "Epoch 2948, Loss: 2.1466901898384094, Final Batch Loss: 0.46886953711509705\n",
      "Epoch 2949, Loss: 1.7443795800209045, Final Batch Loss: 0.13263466954231262\n",
      "Epoch 2950, Loss: 2.1469547748565674, Final Batch Loss: 0.6266189217567444\n",
      "Epoch 2951, Loss: 1.9685639888048172, Final Batch Loss: 0.22571216523647308\n",
      "Epoch 2952, Loss: 1.9316210746765137, Final Batch Loss: 0.3566769063472748\n",
      "Epoch 2953, Loss: 1.8793297708034515, Final Batch Loss: 0.31226441264152527\n",
      "Epoch 2954, Loss: 1.9899883568286896, Final Batch Loss: 0.3833686411380768\n",
      "Epoch 2955, Loss: 2.0317337810993195, Final Batch Loss: 0.36180874705314636\n",
      "Epoch 2956, Loss: 1.836188554763794, Final Batch Loss: 0.24050211906433105\n",
      "Epoch 2957, Loss: 2.0899709165096283, Final Batch Loss: 0.34239107370376587\n",
      "Epoch 2958, Loss: 2.171489655971527, Final Batch Loss: 0.39562276005744934\n",
      "Epoch 2959, Loss: 2.08072891831398, Final Batch Loss: 0.4759138226509094\n",
      "Epoch 2960, Loss: 2.2289368212223053, Final Batch Loss: 0.6125965714454651\n",
      "Epoch 2961, Loss: 2.0199704468250275, Final Batch Loss: 0.426902711391449\n",
      "Epoch 2962, Loss: 2.122725486755371, Final Batch Loss: 0.42723363637924194\n",
      "Epoch 2963, Loss: 2.6703171730041504, Final Batch Loss: 0.9778604507446289\n",
      "Epoch 2964, Loss: 1.8308723270893097, Final Batch Loss: 0.25226348638534546\n",
      "Epoch 2965, Loss: 1.999876856803894, Final Batch Loss: 0.2778286337852478\n",
      "Epoch 2966, Loss: 2.0302723348140717, Final Batch Loss: 0.37416741251945496\n",
      "Epoch 2967, Loss: 1.9604461193084717, Final Batch Loss: 0.32081493735313416\n",
      "Epoch 2968, Loss: 1.8169233202934265, Final Batch Loss: 0.25125357508659363\n",
      "Epoch 2969, Loss: 2.5564351975917816, Final Batch Loss: 0.9372053742408752\n",
      "Epoch 2970, Loss: 2.169753462076187, Final Batch Loss: 0.5420975685119629\n",
      "Epoch 2971, Loss: 1.9157099723815918, Final Batch Loss: 0.2653453052043915\n",
      "Epoch 2972, Loss: 1.859794706106186, Final Batch Loss: 0.3044155538082123\n",
      "Epoch 2973, Loss: 2.025150239467621, Final Batch Loss: 0.40722909569740295\n",
      "Epoch 2974, Loss: 2.092941641807556, Final Batch Loss: 0.41388988494873047\n",
      "Epoch 2975, Loss: 1.9883029758930206, Final Batch Loss: 0.3985574543476105\n",
      "Epoch 2976, Loss: 2.0000649988651276, Final Batch Loss: 0.3072076737880707\n",
      "Epoch 2977, Loss: 2.2999625205993652, Final Batch Loss: 0.6899477243423462\n",
      "Epoch 2978, Loss: 2.0041394084692, Final Batch Loss: 0.24404428899288177\n",
      "Epoch 2979, Loss: 1.8549638390541077, Final Batch Loss: 0.21662962436676025\n",
      "Epoch 2980, Loss: 2.054822087287903, Final Batch Loss: 0.32531973719596863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2981, Loss: 1.9348956644535065, Final Batch Loss: 0.3055655360221863\n",
      "Epoch 2982, Loss: 1.9840839207172394, Final Batch Loss: 0.3936934173107147\n",
      "Epoch 2983, Loss: 2.049658328294754, Final Batch Loss: 0.3612465262413025\n",
      "Epoch 2984, Loss: 2.017023593187332, Final Batch Loss: 0.28406521677970886\n",
      "Epoch 2985, Loss: 1.9344581961631775, Final Batch Loss: 0.30110684037208557\n",
      "Epoch 2986, Loss: 1.9911453425884247, Final Batch Loss: 0.33928200602531433\n",
      "Epoch 2987, Loss: 2.0147534608840942, Final Batch Loss: 0.28521057963371277\n",
      "Epoch 2988, Loss: 2.1568384766578674, Final Batch Loss: 0.5523355007171631\n",
      "Epoch 2989, Loss: 1.9767484068870544, Final Batch Loss: 0.24686458706855774\n",
      "Epoch 2990, Loss: 2.1281654834747314, Final Batch Loss: 0.44799381494522095\n",
      "Epoch 2991, Loss: 2.0787712931632996, Final Batch Loss: 0.4634108245372772\n",
      "Epoch 2992, Loss: 1.9378763437271118, Final Batch Loss: 0.3705271780490875\n",
      "Epoch 2993, Loss: 1.7999008297920227, Final Batch Loss: 0.13929003477096558\n",
      "Epoch 2994, Loss: 2.1627141535282135, Final Batch Loss: 0.5357187390327454\n",
      "Epoch 2995, Loss: 1.8945987820625305, Final Batch Loss: 0.24535730481147766\n",
      "Epoch 2996, Loss: 1.9074527323246002, Final Batch Loss: 0.2504616379737854\n",
      "Epoch 2997, Loss: 3.613700568675995, Final Batch Loss: 1.8438570499420166\n",
      "Epoch 2998, Loss: 1.99199578166008, Final Batch Loss: 0.49772459268569946\n",
      "Epoch 2999, Loss: 2.3146423995494843, Final Batch Loss: 0.5699828267097473\n",
      "Epoch 3000, Loss: 2.0868928134441376, Final Batch Loss: 0.3192145526409149\n",
      "Epoch 3001, Loss: 2.439883381128311, Final Batch Loss: 0.6402342915534973\n",
      "Epoch 3002, Loss: 1.8145405501127243, Final Batch Loss: 0.19238190352916718\n",
      "Epoch 3003, Loss: 1.7791931480169296, Final Batch Loss: 0.08256258070468903\n",
      "Epoch 3004, Loss: 1.7659360393881798, Final Batch Loss: 0.07761567085981369\n",
      "Epoch 3005, Loss: 1.8462497740983963, Final Batch Loss: 0.19910992681980133\n",
      "Epoch 3006, Loss: 1.6292171999812126, Final Batch Loss: 0.08520319312810898\n",
      "Epoch 3007, Loss: 2.353862315416336, Final Batch Loss: 0.6313667297363281\n",
      "Epoch 3008, Loss: 1.88604274392128, Final Batch Loss: 0.31540390849113464\n",
      "Epoch 3009, Loss: 2.087688237428665, Final Batch Loss: 0.4581845700740814\n",
      "Epoch 3010, Loss: 2.1145018339157104, Final Batch Loss: 0.45445433259010315\n",
      "Epoch 3011, Loss: 2.2807274758815765, Final Batch Loss: 0.8097667098045349\n",
      "Epoch 3012, Loss: 1.8510787039995193, Final Batch Loss: 0.22403685748577118\n",
      "Epoch 3013, Loss: 1.9190681874752045, Final Batch Loss: 0.19208881258964539\n",
      "Epoch 3014, Loss: 2.099268674850464, Final Batch Loss: 0.4810107350349426\n",
      "Epoch 3015, Loss: 2.0718239843845367, Final Batch Loss: 0.387835830450058\n",
      "Epoch 3016, Loss: 2.1127161979675293, Final Batch Loss: 0.563748300075531\n",
      "Epoch 3017, Loss: 2.018174320459366, Final Batch Loss: 0.3143748939037323\n",
      "Epoch 3018, Loss: 1.999874234199524, Final Batch Loss: 0.4539176821708679\n",
      "Epoch 3019, Loss: 1.865879163146019, Final Batch Loss: 0.162552610039711\n",
      "Epoch 3020, Loss: 2.181269347667694, Final Batch Loss: 0.6035824418067932\n",
      "Epoch 3021, Loss: 1.8709119856357574, Final Batch Loss: 0.3025018274784088\n",
      "Epoch 3022, Loss: 2.627379208803177, Final Batch Loss: 1.0009812116622925\n",
      "Epoch 3023, Loss: 2.43273463845253, Final Batch Loss: 0.7793021202087402\n",
      "Epoch 3024, Loss: 1.6582351922988892, Final Batch Loss: 0.07266491651535034\n",
      "Epoch 3025, Loss: 2.1533743739128113, Final Batch Loss: 0.5809502005577087\n",
      "Epoch 3026, Loss: 2.0899347960948944, Final Batch Loss: 0.46579617261886597\n",
      "Epoch 3027, Loss: 1.8482158333063126, Final Batch Loss: 0.13376767933368683\n",
      "Epoch 3028, Loss: 1.9860369563102722, Final Batch Loss: 0.4038045406341553\n",
      "Epoch 3029, Loss: 2.145382583141327, Final Batch Loss: 0.6207266449928284\n",
      "Epoch 3030, Loss: 1.7318680584430695, Final Batch Loss: 0.21458753943443298\n",
      "Epoch 3031, Loss: 2.177314817905426, Final Batch Loss: 0.3282094895839691\n",
      "Epoch 3032, Loss: 2.245182454586029, Final Batch Loss: 0.5596677660942078\n",
      "Epoch 3033, Loss: 2.306542932987213, Final Batch Loss: 0.5707629919052124\n",
      "Epoch 3034, Loss: 2.0469759106636047, Final Batch Loss: 0.3132597506046295\n",
      "Epoch 3035, Loss: 1.948465883731842, Final Batch Loss: 0.36045271158218384\n",
      "Epoch 3036, Loss: 1.9836357533931732, Final Batch Loss: 0.3437632918357849\n",
      "Epoch 3037, Loss: 2.0049089193344116, Final Batch Loss: 0.3368179500102997\n",
      "Epoch 3038, Loss: 1.9257124960422516, Final Batch Loss: 0.2738540768623352\n",
      "Epoch 3039, Loss: 1.7611731886863708, Final Batch Loss: 0.11057084798812866\n",
      "Epoch 3040, Loss: 2.072326123714447, Final Batch Loss: 0.42807990312576294\n",
      "Epoch 3041, Loss: 2.4506682455539703, Final Batch Loss: 0.71271151304245\n",
      "Epoch 3042, Loss: 2.0349587202072144, Final Batch Loss: 0.3097449839115143\n",
      "Epoch 3043, Loss: 2.5214891135692596, Final Batch Loss: 0.9578614830970764\n",
      "Epoch 3044, Loss: 2.113520473241806, Final Batch Loss: 0.4446868300437927\n",
      "Epoch 3045, Loss: 2.055640697479248, Final Batch Loss: 0.3764784336090088\n",
      "Epoch 3046, Loss: 2.167877048254013, Final Batch Loss: 0.5209787487983704\n",
      "Epoch 3047, Loss: 2.1894210278987885, Final Batch Loss: 0.46600598096847534\n",
      "Epoch 3048, Loss: 1.8033262938261032, Final Batch Loss: 0.1484576314687729\n",
      "Epoch 3049, Loss: 2.2836606800556183, Final Batch Loss: 0.6065441370010376\n",
      "Epoch 3050, Loss: 2.1047828793525696, Final Batch Loss: 0.2898377776145935\n",
      "Epoch 3051, Loss: 2.1700519621372223, Final Batch Loss: 0.601077139377594\n",
      "Epoch 3052, Loss: 1.9597241580486298, Final Batch Loss: 0.4204523265361786\n",
      "Epoch 3053, Loss: 2.2112722396850586, Final Batch Loss: 0.5723172426223755\n",
      "Epoch 3054, Loss: 2.0993003845214844, Final Batch Loss: 0.49999552965164185\n",
      "Epoch 3055, Loss: 1.9242912530899048, Final Batch Loss: 0.38760611414909363\n",
      "Epoch 3056, Loss: 2.712333172559738, Final Batch Loss: 0.9692917466163635\n",
      "Epoch 3057, Loss: 2.233061373233795, Final Batch Loss: 0.7427043914794922\n",
      "Epoch 3058, Loss: 2.00446480512619, Final Batch Loss: 0.34109416604042053\n",
      "Epoch 3059, Loss: 2.061902105808258, Final Batch Loss: 0.38384562730789185\n",
      "Epoch 3060, Loss: 2.3788244426250458, Final Batch Loss: 0.6588815450668335\n",
      "Epoch 3061, Loss: 1.76844472438097, Final Batch Loss: 0.11382956057786942\n",
      "Epoch 3062, Loss: 1.930928573012352, Final Batch Loss: 0.21060647070407867\n",
      "Epoch 3063, Loss: 1.934497907757759, Final Batch Loss: 0.21601055562496185\n",
      "Epoch 3064, Loss: 1.8699736148118973, Final Batch Loss: 0.24767158925533295\n",
      "Epoch 3065, Loss: 2.2473279237747192, Final Batch Loss: 0.5777493119239807\n",
      "Epoch 3066, Loss: 1.7831682711839676, Final Batch Loss: 0.21379266679286957\n",
      "Epoch 3067, Loss: 2.127957284450531, Final Batch Loss: 0.5172590017318726\n",
      "Epoch 3068, Loss: 2.096995174884796, Final Batch Loss: 0.587157130241394\n",
      "Epoch 3069, Loss: 2.0212588608264923, Final Batch Loss: 0.3590097427368164\n",
      "Epoch 3070, Loss: 2.101946622133255, Final Batch Loss: 0.4348129630088806\n",
      "Epoch 3071, Loss: 1.9624506533145905, Final Batch Loss: 0.40488624572753906\n",
      "Epoch 3072, Loss: 2.101912260055542, Final Batch Loss: 0.4800046384334564\n",
      "Epoch 3073, Loss: 1.8991024792194366, Final Batch Loss: 0.3688385486602783\n",
      "Epoch 3074, Loss: 2.147706240415573, Final Batch Loss: 0.5458226203918457\n",
      "Epoch 3075, Loss: 2.2622645497322083, Final Batch Loss: 0.5408522486686707\n",
      "Epoch 3076, Loss: 2.130435883998871, Final Batch Loss: 0.3508186340332031\n",
      "Epoch 3077, Loss: 1.8012881428003311, Final Batch Loss: 0.16406799852848053\n",
      "Epoch 3078, Loss: 2.1821627616882324, Final Batch Loss: 0.42326197028160095\n",
      "Epoch 3079, Loss: 2.1353767812252045, Final Batch Loss: 0.6355471014976501\n",
      "Epoch 3080, Loss: 1.783727154135704, Final Batch Loss: 0.22854144871234894\n",
      "Epoch 3081, Loss: 2.412051737308502, Final Batch Loss: 0.7976118326187134\n",
      "Epoch 3082, Loss: 2.0395493507385254, Final Batch Loss: 0.3893340229988098\n",
      "Epoch 3083, Loss: 1.7174148708581924, Final Batch Loss: 0.12681661546230316\n",
      "Epoch 3084, Loss: 2.0973022282123566, Final Batch Loss: 0.33746883273124695\n",
      "Epoch 3085, Loss: 1.8286875933408737, Final Batch Loss: 0.18901501595973969\n",
      "Epoch 3086, Loss: 1.9795737862586975, Final Batch Loss: 0.3082844913005829\n",
      "Epoch 3087, Loss: 1.8812848627567291, Final Batch Loss: 0.27215370535850525\n",
      "Epoch 3088, Loss: 1.872897893190384, Final Batch Loss: 0.1924733817577362\n",
      "Epoch 3089, Loss: 1.9649293720722198, Final Batch Loss: 0.26641255617141724\n",
      "Epoch 3090, Loss: 1.9816993474960327, Final Batch Loss: 0.37439703941345215\n",
      "Epoch 3091, Loss: 2.064809501171112, Final Batch Loss: 0.551452100276947\n",
      "Epoch 3092, Loss: 1.966831237077713, Final Batch Loss: 0.28771036863327026\n",
      "Epoch 3093, Loss: 2.22916516661644, Final Batch Loss: 0.6680179238319397\n",
      "Epoch 3094, Loss: 2.112535744905472, Final Batch Loss: 0.507733941078186\n",
      "Epoch 3095, Loss: 2.1002494394779205, Final Batch Loss: 0.6108150482177734\n",
      "Epoch 3096, Loss: 1.962678700685501, Final Batch Loss: 0.3104361891746521\n",
      "Epoch 3097, Loss: 1.7669921517372131, Final Batch Loss: 0.2983319163322449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3098, Loss: 2.271386206150055, Final Batch Loss: 0.5461851358413696\n",
      "Epoch 3099, Loss: 2.2646982669830322, Final Batch Loss: 0.6147425770759583\n",
      "Epoch 3100, Loss: 1.7903261184692383, Final Batch Loss: 0.20018687844276428\n",
      "Epoch 3101, Loss: 1.9646007120609283, Final Batch Loss: 0.2589488923549652\n",
      "Epoch 3102, Loss: 2.2499551475048065, Final Batch Loss: 0.5649083852767944\n",
      "Epoch 3103, Loss: 2.6610688269138336, Final Batch Loss: 0.9163238406181335\n",
      "Epoch 3104, Loss: 2.3752520382404327, Final Batch Loss: 0.7370537519454956\n",
      "Epoch 3105, Loss: 2.7489105463027954, Final Batch Loss: 0.9236090779304504\n",
      "Epoch 3106, Loss: 2.1943439543247223, Final Batch Loss: 0.430649071931839\n",
      "Epoch 3107, Loss: 2.3281249403953552, Final Batch Loss: 0.36339589953422546\n",
      "Epoch 3108, Loss: 2.229810982942581, Final Batch Loss: 0.3661721646785736\n",
      "Epoch 3109, Loss: 2.113783895969391, Final Batch Loss: 0.35907673835754395\n",
      "Epoch 3110, Loss: 2.1364843547344208, Final Batch Loss: 0.3102920353412628\n",
      "Epoch 3111, Loss: 2.2148616313934326, Final Batch Loss: 0.5834364295005798\n",
      "Epoch 3112, Loss: 2.3449639678001404, Final Batch Loss: 0.5476817488670349\n",
      "Epoch 3113, Loss: 2.0825537145137787, Final Batch Loss: 0.3102903664112091\n",
      "Epoch 3114, Loss: 2.1803113520145416, Final Batch Loss: 0.4451231062412262\n",
      "Epoch 3115, Loss: 2.4530475735664368, Final Batch Loss: 0.7915981411933899\n",
      "Epoch 3116, Loss: 2.3528004586696625, Final Batch Loss: 0.4444618821144104\n",
      "Epoch 3117, Loss: 2.0972265899181366, Final Batch Loss: 0.36127927899360657\n",
      "Epoch 3118, Loss: 2.068840801715851, Final Batch Loss: 0.4369015395641327\n",
      "Epoch 3119, Loss: 2.767262041568756, Final Batch Loss: 1.0025233030319214\n",
      "Epoch 3120, Loss: 2.2643580734729767, Final Batch Loss: 0.594265878200531\n",
      "Epoch 3121, Loss: 2.1731342673301697, Final Batch Loss: 0.4618106484413147\n",
      "Epoch 3122, Loss: 2.041631817817688, Final Batch Loss: 0.43792837858200073\n",
      "Epoch 3123, Loss: 2.2401910424232483, Final Batch Loss: 0.44638916850090027\n",
      "Epoch 3124, Loss: 2.56401127576828, Final Batch Loss: 0.7762225270271301\n",
      "Epoch 3125, Loss: 1.8762368112802505, Final Batch Loss: 0.24757452309131622\n",
      "Epoch 3126, Loss: 2.0392238795757294, Final Batch Loss: 0.28689002990722656\n",
      "Epoch 3127, Loss: 2.257776916027069, Final Batch Loss: 0.3176371455192566\n",
      "Epoch 3128, Loss: 1.8203406035900116, Final Batch Loss: 0.1036786437034607\n",
      "Epoch 3129, Loss: 1.9019007682800293, Final Batch Loss: 0.2689535617828369\n",
      "Epoch 3130, Loss: 2.4465028643608093, Final Batch Loss: 0.7671813368797302\n",
      "Epoch 3131, Loss: 2.0294196605682373, Final Batch Loss: 0.5612016916275024\n",
      "Epoch 3132, Loss: 1.9698971509933472, Final Batch Loss: 0.25925686955451965\n",
      "Epoch 3133, Loss: 2.1160659193992615, Final Batch Loss: 0.382260799407959\n",
      "Epoch 3134, Loss: 1.9481833279132843, Final Batch Loss: 0.4969480335712433\n",
      "Epoch 3135, Loss: 1.76767398416996, Final Batch Loss: 0.19061611592769623\n",
      "Epoch 3136, Loss: 1.8597292602062225, Final Batch Loss: 0.32059335708618164\n",
      "Epoch 3137, Loss: 2.2158163487911224, Final Batch Loss: 0.5087076425552368\n",
      "Epoch 3138, Loss: 1.999807447195053, Final Batch Loss: 0.3516959547996521\n",
      "Epoch 3139, Loss: 2.126590132713318, Final Batch Loss: 0.5132239460945129\n",
      "Epoch 3140, Loss: 1.822643369436264, Final Batch Loss: 0.267079621553421\n",
      "Epoch 3141, Loss: 2.040892869234085, Final Batch Loss: 0.5124850869178772\n",
      "Epoch 3142, Loss: 1.8555229306221008, Final Batch Loss: 0.12430226802825928\n",
      "Epoch 3143, Loss: 1.7655217498540878, Final Batch Loss: 0.20616622269153595\n",
      "Epoch 3144, Loss: 2.025201916694641, Final Batch Loss: 0.5010577440261841\n",
      "Epoch 3145, Loss: 2.15800678730011, Final Batch Loss: 0.5953918695449829\n",
      "Epoch 3146, Loss: 2.1827481389045715, Final Batch Loss: 0.6340585350990295\n",
      "Epoch 3147, Loss: 1.8743296563625336, Final Batch Loss: 0.28709885478019714\n",
      "Epoch 3148, Loss: 1.9223427176475525, Final Batch Loss: 0.34655171632766724\n",
      "Epoch 3149, Loss: 2.2112759947776794, Final Batch Loss: 0.5095228552818298\n",
      "Epoch 3150, Loss: 2.1415034234523773, Final Batch Loss: 0.5539296865463257\n",
      "Epoch 3151, Loss: 2.555733233690262, Final Batch Loss: 0.8822707533836365\n",
      "Epoch 3152, Loss: 2.147546797990799, Final Batch Loss: 0.6547216773033142\n",
      "Epoch 3153, Loss: 1.84046071767807, Final Batch Loss: 0.35195186734199524\n",
      "Epoch 3154, Loss: 2.1679872572422028, Final Batch Loss: 0.5256582498550415\n",
      "Epoch 3155, Loss: 2.048031121492386, Final Batch Loss: 0.40572497248649597\n",
      "Epoch 3156, Loss: 2.1142288744449615, Final Batch Loss: 0.4833524227142334\n",
      "Epoch 3157, Loss: 1.871363826096058, Final Batch Loss: 0.10127643495798111\n",
      "Epoch 3158, Loss: 2.432968944311142, Final Batch Loss: 0.8317155838012695\n",
      "Epoch 3159, Loss: 2.0002963840961456, Final Batch Loss: 0.4222125709056854\n",
      "Epoch 3160, Loss: 1.7802345007658005, Final Batch Loss: 0.17387790977954865\n",
      "Epoch 3161, Loss: 2.40971976518631, Final Batch Loss: 0.7259518504142761\n",
      "Epoch 3162, Loss: 2.276191532611847, Final Batch Loss: 0.6710162162780762\n",
      "Epoch 3163, Loss: 2.0984444618225098, Final Batch Loss: 0.4159314036369324\n",
      "Epoch 3164, Loss: 2.3795456886291504, Final Batch Loss: 0.6660739183425903\n",
      "Epoch 3165, Loss: 1.7184588462114334, Final Batch Loss: 0.12905000150203705\n",
      "Epoch 3166, Loss: 2.2173912525177, Final Batch Loss: 0.5868154764175415\n",
      "Epoch 3167, Loss: 2.030103713274002, Final Batch Loss: 0.26625826954841614\n",
      "Epoch 3168, Loss: 1.7009426206350327, Final Batch Loss: 0.19898690283298492\n",
      "Epoch 3169, Loss: 2.0626537203788757, Final Batch Loss: 0.5632891058921814\n",
      "Epoch 3170, Loss: 2.095679372549057, Final Batch Loss: 0.3104567229747772\n",
      "Epoch 3171, Loss: 2.283049464225769, Final Batch Loss: 0.5270985960960388\n",
      "Epoch 3172, Loss: 1.9569972455501556, Final Batch Loss: 0.3216168284416199\n",
      "Epoch 3173, Loss: 2.125163584947586, Final Batch Loss: 0.40680304169654846\n",
      "Epoch 3174, Loss: 2.943968415260315, Final Batch Loss: 1.2674051523208618\n",
      "Epoch 3175, Loss: 1.826911821961403, Final Batch Loss: 0.1423727124929428\n",
      "Epoch 3176, Loss: 2.051406741142273, Final Batch Loss: 0.27475568652153015\n",
      "Epoch 3177, Loss: 2.685651034116745, Final Batch Loss: 0.8475947976112366\n",
      "Epoch 3178, Loss: 2.020214408636093, Final Batch Loss: 0.36268720030784607\n",
      "Epoch 3179, Loss: 2.061293363571167, Final Batch Loss: 0.41047126054763794\n",
      "Epoch 3180, Loss: 2.095634698867798, Final Batch Loss: 0.5527018308639526\n",
      "Epoch 3181, Loss: 2.180699408054352, Final Batch Loss: 0.6562839150428772\n",
      "Epoch 3182, Loss: 1.873300239443779, Final Batch Loss: 0.23054896295070648\n",
      "Epoch 3183, Loss: 2.151098281145096, Final Batch Loss: 0.3270774483680725\n",
      "Epoch 3184, Loss: 2.16532438993454, Final Batch Loss: 0.552907407283783\n",
      "Epoch 3185, Loss: 1.861530214548111, Final Batch Loss: 0.1732490062713623\n",
      "Epoch 3186, Loss: 2.288128435611725, Final Batch Loss: 0.6871775984764099\n",
      "Epoch 3187, Loss: 2.0807520747184753, Final Batch Loss: 0.4873180389404297\n",
      "Epoch 3188, Loss: 1.8659447133541107, Final Batch Loss: 0.26795440912246704\n",
      "Epoch 3189, Loss: 1.9344584047794342, Final Batch Loss: 0.2207481861114502\n",
      "Epoch 3190, Loss: 1.7981786578893661, Final Batch Loss: 0.16861771047115326\n",
      "Epoch 3191, Loss: 2.5393912196159363, Final Batch Loss: 0.9124244451522827\n",
      "Epoch 3192, Loss: 2.4230982661247253, Final Batch Loss: 0.7188106179237366\n",
      "Epoch 3193, Loss: 2.1252009868621826, Final Batch Loss: 0.5353261232376099\n",
      "Epoch 3194, Loss: 1.9869309961795807, Final Batch Loss: 0.3494444787502289\n",
      "Epoch 3195, Loss: 1.9905797690153122, Final Batch Loss: 0.21652661263942719\n",
      "Epoch 3196, Loss: 2.1828507483005524, Final Batch Loss: 0.4768020510673523\n",
      "Epoch 3197, Loss: 1.791359156370163, Final Batch Loss: 0.2390107810497284\n",
      "Epoch 3198, Loss: 2.066468209028244, Final Batch Loss: 0.42649462819099426\n",
      "Epoch 3199, Loss: 1.8178749978542328, Final Batch Loss: 0.22412148118019104\n",
      "Epoch 3200, Loss: 2.15839621424675, Final Batch Loss: 0.6159144043922424\n",
      "Epoch 3201, Loss: 2.0512449145317078, Final Batch Loss: 0.24530422687530518\n",
      "Epoch 3202, Loss: 1.8325567990541458, Final Batch Loss: 0.21741606295108795\n",
      "Epoch 3203, Loss: 2.004228800535202, Final Batch Loss: 0.3967954218387604\n",
      "Epoch 3204, Loss: 1.9072805047035217, Final Batch Loss: 0.37169474363327026\n",
      "Epoch 3205, Loss: 2.2989454865455627, Final Batch Loss: 0.7074809074401855\n",
      "Epoch 3206, Loss: 2.5557537972927094, Final Batch Loss: 1.032950758934021\n",
      "Epoch 3207, Loss: 1.9755379557609558, Final Batch Loss: 0.3688843548297882\n",
      "Epoch 3208, Loss: 1.775394156575203, Final Batch Loss: 0.1316758543252945\n",
      "Epoch 3209, Loss: 1.9162370041012764, Final Batch Loss: 0.07148579508066177\n",
      "Epoch 3210, Loss: 1.8150481432676315, Final Batch Loss: 0.14555378258228302\n",
      "Epoch 3211, Loss: 2.057200640439987, Final Batch Loss: 0.4365901052951813\n",
      "Epoch 3212, Loss: 2.131526291370392, Final Batch Loss: 0.5457506775856018\n",
      "Epoch 3213, Loss: 1.663929283618927, Final Batch Loss: 0.13856717944145203\n",
      "Epoch 3214, Loss: 1.7754752039909363, Final Batch Loss: 0.23717167973518372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3215, Loss: 2.1051137447357178, Final Batch Loss: 0.5130515098571777\n",
      "Epoch 3216, Loss: 1.8478341698646545, Final Batch Loss: 0.2902095317840576\n",
      "Epoch 3217, Loss: 1.6778753772377968, Final Batch Loss: 0.10894352942705154\n",
      "Epoch 3218, Loss: 1.725927695631981, Final Batch Loss: 0.23052088916301727\n",
      "Epoch 3219, Loss: 1.8408209532499313, Final Batch Loss: 0.20465846359729767\n",
      "Epoch 3220, Loss: 2.0041311383247375, Final Batch Loss: 0.35606446862220764\n",
      "Epoch 3221, Loss: 2.0586273968219757, Final Batch Loss: 0.527579128742218\n",
      "Epoch 3222, Loss: 1.8085506856441498, Final Batch Loss: 0.27153223752975464\n",
      "Epoch 3223, Loss: 1.7714583277702332, Final Batch Loss: 0.22139069437980652\n",
      "Epoch 3224, Loss: 2.4014828503131866, Final Batch Loss: 0.6694694757461548\n",
      "Epoch 3225, Loss: 1.8809616565704346, Final Batch Loss: 0.39826053380966187\n",
      "Epoch 3226, Loss: 2.5193202793598175, Final Batch Loss: 0.915069580078125\n",
      "Epoch 3227, Loss: 2.0815303325653076, Final Batch Loss: 0.4157054126262665\n",
      "Epoch 3228, Loss: 2.061982661485672, Final Batch Loss: 0.37489208579063416\n",
      "Epoch 3229, Loss: 1.9254522323608398, Final Batch Loss: 0.27303239703178406\n",
      "Epoch 3230, Loss: 2.048942059278488, Final Batch Loss: 0.5151475071907043\n",
      "Epoch 3231, Loss: 1.9569531232118607, Final Batch Loss: 0.21872325241565704\n",
      "Epoch 3232, Loss: 1.863702803850174, Final Batch Loss: 0.28681638836860657\n",
      "Epoch 3233, Loss: 2.1079190373420715, Final Batch Loss: 0.47706207633018494\n",
      "Epoch 3234, Loss: 2.250145763158798, Final Batch Loss: 0.6733430027961731\n",
      "Epoch 3235, Loss: 2.2534693479537964, Final Batch Loss: 0.6744769215583801\n",
      "Epoch 3236, Loss: 1.8699430227279663, Final Batch Loss: 0.21988821029663086\n",
      "Epoch 3237, Loss: 2.0153438448905945, Final Batch Loss: 0.47075194120407104\n",
      "Epoch 3238, Loss: 2.17937570810318, Final Batch Loss: 0.5508970022201538\n",
      "Epoch 3239, Loss: 1.904910534620285, Final Batch Loss: 0.37475380301475525\n",
      "Epoch 3240, Loss: 2.2067021429538727, Final Batch Loss: 0.5697575211524963\n",
      "Epoch 3241, Loss: 1.8596211671829224, Final Batch Loss: 0.2532408535480499\n",
      "Epoch 3242, Loss: 2.916661947965622, Final Batch Loss: 1.3335858583450317\n",
      "Epoch 3243, Loss: 1.968554437160492, Final Batch Loss: 0.46102309226989746\n",
      "Epoch 3244, Loss: 1.9989074170589447, Final Batch Loss: 0.2530588209629059\n",
      "Epoch 3245, Loss: 2.0965848565101624, Final Batch Loss: 0.3402574062347412\n",
      "Epoch 3246, Loss: 2.4614518880844116, Final Batch Loss: 0.3646782338619232\n",
      "Epoch 3247, Loss: 1.9529390335083008, Final Batch Loss: 0.2675863206386566\n",
      "Epoch 3248, Loss: 1.7536013424396515, Final Batch Loss: 0.18505701422691345\n",
      "Epoch 3249, Loss: 2.4455434679985046, Final Batch Loss: 0.960720956325531\n",
      "Epoch 3250, Loss: 2.06125545501709, Final Batch Loss: 0.5053480863571167\n",
      "Epoch 3251, Loss: 1.8884892463684082, Final Batch Loss: 0.26254987716674805\n",
      "Epoch 3252, Loss: 2.0351696014404297, Final Batch Loss: 0.3208708167076111\n",
      "Epoch 3253, Loss: 2.138083279132843, Final Batch Loss: 0.603753924369812\n",
      "Epoch 3254, Loss: 1.792315810918808, Final Batch Loss: 0.26342982053756714\n",
      "Epoch 3255, Loss: 1.8195465505123138, Final Batch Loss: 0.2739400863647461\n",
      "Epoch 3256, Loss: 2.1206538379192352, Final Batch Loss: 0.6111458539962769\n",
      "Epoch 3257, Loss: 2.0725629329681396, Final Batch Loss: 0.46106526255607605\n",
      "Epoch 3258, Loss: 2.009496808052063, Final Batch Loss: 0.3066282570362091\n",
      "Epoch 3259, Loss: 1.906839832663536, Final Batch Loss: 0.12750141322612762\n",
      "Epoch 3260, Loss: 2.1951097548007965, Final Batch Loss: 0.6181364059448242\n",
      "Epoch 3261, Loss: 2.121077746152878, Final Batch Loss: 0.49713680148124695\n",
      "Epoch 3262, Loss: 1.8735291510820389, Final Batch Loss: 0.1987805813550949\n",
      "Epoch 3263, Loss: 1.7818652093410492, Final Batch Loss: 0.20926722884178162\n",
      "Epoch 3264, Loss: 1.9259664714336395, Final Batch Loss: 0.29101136326789856\n",
      "Epoch 3265, Loss: 1.8376468122005463, Final Batch Loss: 0.28351014852523804\n",
      "Epoch 3266, Loss: 2.4289196729660034, Final Batch Loss: 0.9629579186439514\n",
      "Epoch 3267, Loss: 1.8917277306318283, Final Batch Loss: 0.22434677183628082\n",
      "Epoch 3268, Loss: 2.346021831035614, Final Batch Loss: 0.7051170468330383\n",
      "Epoch 3269, Loss: 2.0616041123867035, Final Batch Loss: 0.49447712302207947\n",
      "Epoch 3270, Loss: 2.250630497932434, Final Batch Loss: 0.5010648369789124\n",
      "Epoch 3271, Loss: 2.090659737586975, Final Batch Loss: 0.41145458817481995\n",
      "Epoch 3272, Loss: 2.1828153133392334, Final Batch Loss: 0.31042715907096863\n",
      "Epoch 3273, Loss: 1.9737184047698975, Final Batch Loss: 0.32237404584884644\n",
      "Epoch 3274, Loss: 1.6623129174113274, Final Batch Loss: 0.1168389841914177\n",
      "Epoch 3275, Loss: 1.688203439116478, Final Batch Loss: 0.17065535485744476\n",
      "Epoch 3276, Loss: 2.1256288588047028, Final Batch Loss: 0.6439571976661682\n",
      "Epoch 3277, Loss: 1.8269227892160416, Final Batch Loss: 0.19322143495082855\n",
      "Epoch 3278, Loss: 1.8666179776191711, Final Batch Loss: 0.2577650845050812\n",
      "Epoch 3279, Loss: 2.3155240416526794, Final Batch Loss: 0.2987167537212372\n",
      "Epoch 3280, Loss: 1.9937240779399872, Final Batch Loss: 0.2779522240161896\n",
      "Epoch 3281, Loss: 2.2288790941238403, Final Batch Loss: 0.49601736664772034\n",
      "Epoch 3282, Loss: 2.5223801136016846, Final Batch Loss: 0.8950632810592651\n",
      "Epoch 3283, Loss: 1.8276093006134033, Final Batch Loss: 0.15609660744667053\n",
      "Epoch 3284, Loss: 2.0181111097335815, Final Batch Loss: 0.3513096272945404\n",
      "Epoch 3285, Loss: 1.6478786394000053, Final Batch Loss: 0.06477906554937363\n",
      "Epoch 3286, Loss: 1.96291883289814, Final Batch Loss: 0.1691758781671524\n",
      "Epoch 3287, Loss: 1.8400463163852692, Final Batch Loss: 0.3215731680393219\n",
      "Epoch 3288, Loss: 2.093675881624222, Final Batch Loss: 0.45246556401252747\n",
      "Epoch 3289, Loss: 2.0166068971157074, Final Batch Loss: 0.4963201582431793\n",
      "Epoch 3290, Loss: 2.2816275656223297, Final Batch Loss: 0.6646324992179871\n",
      "Epoch 3291, Loss: 2.107000857591629, Final Batch Loss: 0.6296527981758118\n",
      "Epoch 3292, Loss: 2.084784835577011, Final Batch Loss: 0.34866029024124146\n",
      "Epoch 3293, Loss: 1.9376402795314789, Final Batch Loss: 0.28650346398353577\n",
      "Epoch 3294, Loss: 2.4195262491703033, Final Batch Loss: 0.8485161066055298\n",
      "Epoch 3295, Loss: 2.1049420833587646, Final Batch Loss: 0.4313599467277527\n",
      "Epoch 3296, Loss: 2.0738464295864105, Final Batch Loss: 0.40400126576423645\n",
      "Epoch 3297, Loss: 2.0674257576465607, Final Batch Loss: 0.4965299963951111\n",
      "Epoch 3298, Loss: 1.9867767691612244, Final Batch Loss: 0.4822770953178406\n",
      "Epoch 3299, Loss: 1.708636462688446, Final Batch Loss: 0.2596736252307892\n",
      "Epoch 3300, Loss: 1.9039370715618134, Final Batch Loss: 0.3111102879047394\n",
      "Epoch 3301, Loss: 2.2024256587028503, Final Batch Loss: 0.5861409306526184\n",
      "Epoch 3302, Loss: 1.9333795607089996, Final Batch Loss: 0.4832821488380432\n",
      "Epoch 3303, Loss: 1.7992303520441055, Final Batch Loss: 0.21161817014217377\n",
      "Epoch 3304, Loss: 1.6466994136571884, Final Batch Loss: 0.18385912477970123\n",
      "Epoch 3305, Loss: 2.040767729282379, Final Batch Loss: 0.5525838136672974\n",
      "Epoch 3306, Loss: 1.7749786376953125, Final Batch Loss: 0.1410992443561554\n",
      "Epoch 3307, Loss: 2.026090383529663, Final Batch Loss: 0.5828441977500916\n",
      "Epoch 3308, Loss: 1.8566855788230896, Final Batch Loss: 0.3080635368824005\n",
      "Epoch 3309, Loss: 1.7049903720617294, Final Batch Loss: 0.22327081859111786\n",
      "Epoch 3310, Loss: 2.3440707325935364, Final Batch Loss: 0.5267270803451538\n",
      "Epoch 3311, Loss: 1.844760462641716, Final Batch Loss: 0.223546102643013\n",
      "Epoch 3312, Loss: 1.8554757237434387, Final Batch Loss: 0.3325742185115814\n",
      "Epoch 3313, Loss: 1.9385654628276825, Final Batch Loss: 0.3698999583721161\n",
      "Epoch 3314, Loss: 1.6899243742227554, Final Batch Loss: 0.1623668521642685\n",
      "Epoch 3315, Loss: 1.6664823293685913, Final Batch Loss: 0.18358397483825684\n",
      "Epoch 3316, Loss: 1.7253685891628265, Final Batch Loss: 0.30985894799232483\n",
      "Epoch 3317, Loss: 2.2445941865444183, Final Batch Loss: 0.771178662776947\n",
      "Epoch 3318, Loss: 2.182563841342926, Final Batch Loss: 0.6414488554000854\n",
      "Epoch 3319, Loss: 1.9530150890350342, Final Batch Loss: 0.40616148710250854\n",
      "Epoch 3320, Loss: 2.2331228852272034, Final Batch Loss: 0.7035058736801147\n",
      "Epoch 3321, Loss: 2.009874016046524, Final Batch Loss: 0.5064975023269653\n",
      "Epoch 3322, Loss: 1.9259388148784637, Final Batch Loss: 0.30899158120155334\n",
      "Epoch 3323, Loss: 1.5933374911546707, Final Batch Loss: 0.08266215026378632\n",
      "Epoch 3324, Loss: 2.138828545808792, Final Batch Loss: 0.5901880860328674\n",
      "Epoch 3325, Loss: 1.8770284950733185, Final Batch Loss: 0.30295127630233765\n",
      "Epoch 3326, Loss: 1.7270953357219696, Final Batch Loss: 0.19766926765441895\n",
      "Epoch 3327, Loss: 1.9953179210424423, Final Batch Loss: 0.2339368611574173\n",
      "Epoch 3328, Loss: 1.907180905342102, Final Batch Loss: 0.3640315532684326\n",
      "Epoch 3329, Loss: 1.7819758504629135, Final Batch Loss: 0.19857950508594513\n",
      "Epoch 3330, Loss: 2.1188077330589294, Final Batch Loss: 0.4669952094554901\n",
      "Epoch 3331, Loss: 1.8195038437843323, Final Batch Loss: 0.29301586747169495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3332, Loss: 1.8746974170207977, Final Batch Loss: 0.44597241282463074\n",
      "Epoch 3333, Loss: 1.605867624282837, Final Batch Loss: 0.0947994589805603\n",
      "Epoch 3334, Loss: 1.7804211378097534, Final Batch Loss: 0.25099343061447144\n",
      "Epoch 3335, Loss: 2.127713233232498, Final Batch Loss: 0.4487359821796417\n",
      "Epoch 3336, Loss: 2.0383896827697754, Final Batch Loss: 0.3118338882923126\n",
      "Epoch 3337, Loss: 2.131286084651947, Final Batch Loss: 0.36969193816185\n",
      "Epoch 3338, Loss: 1.9998542666435242, Final Batch Loss: 0.28254473209381104\n",
      "Epoch 3339, Loss: 1.9036103785037994, Final Batch Loss: 0.34730538725852966\n",
      "Epoch 3340, Loss: 1.9397564828395844, Final Batch Loss: 0.4224933981895447\n",
      "Epoch 3341, Loss: 1.8043903857469559, Final Batch Loss: 0.19496701657772064\n",
      "Epoch 3342, Loss: 2.282442957162857, Final Batch Loss: 0.7097275853157043\n",
      "Epoch 3343, Loss: 1.9841740727424622, Final Batch Loss: 0.45265159010887146\n",
      "Epoch 3344, Loss: 1.7909140288829803, Final Batch Loss: 0.3240719437599182\n",
      "Epoch 3345, Loss: 1.8438912332057953, Final Batch Loss: 0.1928030252456665\n",
      "Epoch 3346, Loss: 2.404986709356308, Final Batch Loss: 0.7826460003852844\n",
      "Epoch 3347, Loss: 1.7703111320734024, Final Batch Loss: 0.12786062061786652\n",
      "Epoch 3348, Loss: 1.7391135692596436, Final Batch Loss: 0.2978953719139099\n",
      "Epoch 3349, Loss: 2.0358118414878845, Final Batch Loss: 0.3716229796409607\n",
      "Epoch 3350, Loss: 2.1968511641025543, Final Batch Loss: 0.5995127558708191\n",
      "Epoch 3351, Loss: 1.910635769367218, Final Batch Loss: 0.3503074645996094\n",
      "Epoch 3352, Loss: 2.741557240486145, Final Batch Loss: 1.090121865272522\n",
      "Epoch 3353, Loss: 2.1850802302360535, Final Batch Loss: 0.6208711862564087\n",
      "Epoch 3354, Loss: 2.2806358635425568, Final Batch Loss: 0.536364734172821\n",
      "Epoch 3355, Loss: 2.0748421251773834, Final Batch Loss: 0.42984214425086975\n",
      "Epoch 3356, Loss: 2.2816118001937866, Final Batch Loss: 0.6818877458572388\n",
      "Epoch 3357, Loss: 1.8951079547405243, Final Batch Loss: 0.2696332037448883\n",
      "Epoch 3358, Loss: 1.7870002090930939, Final Batch Loss: 0.2693834602832794\n",
      "Epoch 3359, Loss: 2.059134691953659, Final Batch Loss: 0.5692405104637146\n",
      "Epoch 3360, Loss: 1.7898464798927307, Final Batch Loss: 0.2557860314846039\n",
      "Epoch 3361, Loss: 1.7883562594652176, Final Batch Loss: 0.24908368289470673\n",
      "Epoch 3362, Loss: 2.0429751873016357, Final Batch Loss: 0.6072186827659607\n",
      "Epoch 3363, Loss: 2.272499531507492, Final Batch Loss: 0.7496417760848999\n",
      "Epoch 3364, Loss: 1.8287073969841003, Final Batch Loss: 0.3468206524848938\n",
      "Epoch 3365, Loss: 1.8488736748695374, Final Batch Loss: 0.32553818821907043\n",
      "Epoch 3366, Loss: 1.6061957031488419, Final Batch Loss: 0.14160142838954926\n",
      "Epoch 3367, Loss: 2.540256977081299, Final Batch Loss: 1.013670563697815\n",
      "Epoch 3368, Loss: 1.9435404688119888, Final Batch Loss: 0.20598642528057098\n",
      "Epoch 3369, Loss: 1.5713930949568748, Final Batch Loss: 0.11349087208509445\n",
      "Epoch 3370, Loss: 1.8433552086353302, Final Batch Loss: 0.29889535903930664\n",
      "Epoch 3371, Loss: 1.8122000992298126, Final Batch Loss: 0.3460778295993805\n",
      "Epoch 3372, Loss: 1.9544897973537445, Final Batch Loss: 0.41443514823913574\n",
      "Epoch 3373, Loss: 2.241719126701355, Final Batch Loss: 0.7009645700454712\n",
      "Epoch 3374, Loss: 2.105640321969986, Final Batch Loss: 0.3593578338623047\n",
      "Epoch 3375, Loss: 1.9812117516994476, Final Batch Loss: 0.4289935231208801\n",
      "Epoch 3376, Loss: 1.9689177870750427, Final Batch Loss: 0.48092588782310486\n",
      "Epoch 3377, Loss: 1.7644301801919937, Final Batch Loss: 0.23749057948589325\n",
      "Epoch 3378, Loss: 2.2698194682598114, Final Batch Loss: 0.7220006585121155\n",
      "Epoch 3379, Loss: 1.9163444638252258, Final Batch Loss: 0.5284484028816223\n",
      "Epoch 3380, Loss: 1.83223357796669, Final Batch Loss: 0.3364376127719879\n",
      "Epoch 3381, Loss: 1.7924617230892181, Final Batch Loss: 0.22350898385047913\n",
      "Epoch 3382, Loss: 2.0112372636795044, Final Batch Loss: 0.5134276151657104\n",
      "Epoch 3383, Loss: 1.6289573907852173, Final Batch Loss: 0.21580421924591064\n",
      "Epoch 3384, Loss: 1.9571565985679626, Final Batch Loss: 0.3360873758792877\n",
      "Epoch 3385, Loss: 2.0202929973602295, Final Batch Loss: 0.4406428337097168\n",
      "Epoch 3386, Loss: 1.8497593700885773, Final Batch Loss: 0.31496208906173706\n",
      "Epoch 3387, Loss: 1.8974467515945435, Final Batch Loss: 0.38671547174453735\n",
      "Epoch 3388, Loss: 2.4832946062088013, Final Batch Loss: 0.9214202165603638\n",
      "Epoch 3389, Loss: 2.213087946176529, Final Batch Loss: 0.6151099801063538\n",
      "Epoch 3390, Loss: 1.9575321823358536, Final Batch Loss: 0.22065170109272003\n",
      "Epoch 3391, Loss: 1.962213397026062, Final Batch Loss: 0.3440781533718109\n",
      "Epoch 3392, Loss: 2.0451482236385345, Final Batch Loss: 0.3951750695705414\n",
      "Epoch 3393, Loss: 1.8911860138177872, Final Batch Loss: 0.2251298576593399\n",
      "Epoch 3394, Loss: 1.9257475137710571, Final Batch Loss: 0.44242599606513977\n",
      "Epoch 3395, Loss: 2.0728633105754852, Final Batch Loss: 0.4519399106502533\n",
      "Epoch 3396, Loss: 1.8485044538974762, Final Batch Loss: 0.22634896636009216\n",
      "Epoch 3397, Loss: 2.049521714448929, Final Batch Loss: 0.6381428837776184\n",
      "Epoch 3398, Loss: 1.970509648323059, Final Batch Loss: 0.4407319128513336\n",
      "Epoch 3399, Loss: 2.0965794026851654, Final Batch Loss: 0.5952455401420593\n",
      "Epoch 3400, Loss: 1.9438705146312714, Final Batch Loss: 0.18503054976463318\n",
      "Epoch 3401, Loss: 1.7887617647647858, Final Batch Loss: 0.2181379497051239\n",
      "Epoch 3402, Loss: 1.9021450281143188, Final Batch Loss: 0.3272280693054199\n",
      "Epoch 3403, Loss: 2.1838427782058716, Final Batch Loss: 0.5422804951667786\n",
      "Epoch 3404, Loss: 1.642411157488823, Final Batch Loss: 0.1671421378850937\n",
      "Epoch 3405, Loss: 1.986287236213684, Final Batch Loss: 0.328412264585495\n",
      "Epoch 3406, Loss: 2.4317698180675507, Final Batch Loss: 0.6363211870193481\n",
      "Epoch 3407, Loss: 1.9878983050584793, Final Batch Loss: 0.215972438454628\n",
      "Epoch 3408, Loss: 2.1323563158512115, Final Batch Loss: 0.4055379331111908\n",
      "Epoch 3409, Loss: 2.3723422288894653, Final Batch Loss: 0.5764060616493225\n",
      "Epoch 3410, Loss: 1.8121549040079117, Final Batch Loss: 0.17589493095874786\n",
      "Epoch 3411, Loss: 1.9291361570358276, Final Batch Loss: 0.27005451917648315\n",
      "Epoch 3412, Loss: 1.8983595371246338, Final Batch Loss: 0.26738712191581726\n",
      "Epoch 3413, Loss: 2.1018770933151245, Final Batch Loss: 0.6000043749809265\n",
      "Epoch 3414, Loss: 1.9631240665912628, Final Batch Loss: 0.34267133474349976\n",
      "Epoch 3415, Loss: 2.128733217716217, Final Batch Loss: 0.5633663535118103\n",
      "Epoch 3416, Loss: 2.014847218990326, Final Batch Loss: 0.33597561717033386\n",
      "Epoch 3417, Loss: 1.730223923921585, Final Batch Loss: 0.24026954174041748\n",
      "Epoch 3418, Loss: 2.096897393465042, Final Batch Loss: 0.6105011701583862\n",
      "Epoch 3419, Loss: 1.861501157283783, Final Batch Loss: 0.2609449028968811\n",
      "Epoch 3420, Loss: 1.8629937171936035, Final Batch Loss: 0.3422958254814148\n",
      "Epoch 3421, Loss: 1.8181703686714172, Final Batch Loss: 0.3437892496585846\n",
      "Epoch 3422, Loss: 1.7310395389795303, Final Batch Loss: 0.22332344949245453\n",
      "Epoch 3423, Loss: 2.129922479391098, Final Batch Loss: 0.5710446834564209\n",
      "Epoch 3424, Loss: 1.6015617400407791, Final Batch Loss: 0.16549168527126312\n",
      "Epoch 3425, Loss: 1.5273307412862778, Final Batch Loss: 0.11857955157756805\n",
      "Epoch 3426, Loss: 2.0907863080501556, Final Batch Loss: 0.708872377872467\n",
      "Epoch 3427, Loss: 1.7728201746940613, Final Batch Loss: 0.280382364988327\n",
      "Epoch 3428, Loss: 1.925483524799347, Final Batch Loss: 0.4099371135234833\n",
      "Epoch 3429, Loss: 2.1583669781684875, Final Batch Loss: 0.5961335301399231\n",
      "Epoch 3430, Loss: 1.9069991707801819, Final Batch Loss: 0.4340426027774811\n",
      "Epoch 3431, Loss: 2.105421155691147, Final Batch Loss: 0.4892733693122864\n",
      "Epoch 3432, Loss: 2.4898335337638855, Final Batch Loss: 0.7403029203414917\n",
      "Epoch 3433, Loss: 1.9908336699008942, Final Batch Loss: 0.4537122845649719\n",
      "Epoch 3434, Loss: 2.1087996661663055, Final Batch Loss: 0.4034886658191681\n",
      "Epoch 3435, Loss: 1.6549879908561707, Final Batch Loss: 0.026770323514938354\n",
      "Epoch 3436, Loss: 1.9760639369487762, Final Batch Loss: 0.26875659823417664\n",
      "Epoch 3437, Loss: 2.0184015929698944, Final Batch Loss: 0.29765647649765015\n",
      "Epoch 3438, Loss: 2.678605228662491, Final Batch Loss: 1.0608832836151123\n",
      "Epoch 3439, Loss: 2.0750944912433624, Final Batch Loss: 0.45953041315078735\n",
      "Epoch 3440, Loss: 2.1865458488464355, Final Batch Loss: 0.3803529739379883\n",
      "Epoch 3441, Loss: 2.0775084793567657, Final Batch Loss: 0.32854601740837097\n",
      "Epoch 3442, Loss: 1.85078763961792, Final Batch Loss: 0.2656671404838562\n",
      "Epoch 3443, Loss: 2.715717315673828, Final Batch Loss: 0.8902543187141418\n",
      "Epoch 3444, Loss: 1.9386261999607086, Final Batch Loss: 0.3280024528503418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3445, Loss: 1.9218187183141708, Final Batch Loss: 0.18103225529193878\n",
      "Epoch 3446, Loss: 2.187621772289276, Final Batch Loss: 0.3750379979610443\n",
      "Epoch 3447, Loss: 1.8724780678749084, Final Batch Loss: 0.2845982015132904\n",
      "Epoch 3448, Loss: 2.0401903986930847, Final Batch Loss: 0.47918373346328735\n",
      "Epoch 3449, Loss: 1.7837947010993958, Final Batch Loss: 0.2842840254306793\n",
      "Epoch 3450, Loss: 2.0875493586063385, Final Batch Loss: 0.33722859621047974\n",
      "Epoch 3451, Loss: 2.12480491399765, Final Batch Loss: 0.4023154377937317\n",
      "Epoch 3452, Loss: 2.239314019680023, Final Batch Loss: 0.5608234405517578\n",
      "Epoch 3453, Loss: 1.998990535736084, Final Batch Loss: 0.3230259120464325\n",
      "Epoch 3454, Loss: 2.1829625964164734, Final Batch Loss: 0.5177740454673767\n",
      "Epoch 3455, Loss: 2.0931582748889923, Final Batch Loss: 0.5025923848152161\n",
      "Epoch 3456, Loss: 1.9156075417995453, Final Batch Loss: 0.32270708680152893\n",
      "Epoch 3457, Loss: 1.7920655012130737, Final Batch Loss: 0.17595136165618896\n",
      "Epoch 3458, Loss: 2.0250437259674072, Final Batch Loss: 0.2622055411338806\n",
      "Epoch 3459, Loss: 2.1167849600315094, Final Batch Loss: 0.419280469417572\n",
      "Epoch 3460, Loss: 2.0516426861286163, Final Batch Loss: 0.5687561631202698\n",
      "Epoch 3461, Loss: 1.9829983413219452, Final Batch Loss: 0.3795150816440582\n",
      "Epoch 3462, Loss: 1.8412147611379623, Final Batch Loss: 0.23641686141490936\n",
      "Epoch 3463, Loss: 2.338250696659088, Final Batch Loss: 0.6588583588600159\n",
      "Epoch 3464, Loss: 1.9190893769264221, Final Batch Loss: 0.3651273548603058\n",
      "Epoch 3465, Loss: 1.9354974329471588, Final Batch Loss: 0.43600931763648987\n",
      "Epoch 3466, Loss: 1.8724572956562042, Final Batch Loss: 0.42892876267433167\n",
      "Epoch 3467, Loss: 2.3292503654956818, Final Batch Loss: 0.6528692841529846\n",
      "Epoch 3468, Loss: 1.5561576820909977, Final Batch Loss: 0.051514748483896255\n",
      "Epoch 3469, Loss: 1.7869321405887604, Final Batch Loss: 0.36299681663513184\n",
      "Epoch 3470, Loss: 1.998276948928833, Final Batch Loss: 0.48925289511680603\n",
      "Epoch 3471, Loss: 1.7450600415468216, Final Batch Loss: 0.18650026619434357\n",
      "Epoch 3472, Loss: 1.7513832300901413, Final Batch Loss: 0.23909686505794525\n",
      "Epoch 3473, Loss: 2.065026581287384, Final Batch Loss: 0.5241833925247192\n",
      "Epoch 3474, Loss: 2.518564462661743, Final Batch Loss: 0.9890778660774231\n",
      "Epoch 3475, Loss: 2.1207349002361298, Final Batch Loss: 0.6059123277664185\n",
      "Epoch 3476, Loss: 1.874132513999939, Final Batch Loss: 0.4549102485179901\n",
      "Epoch 3477, Loss: 1.9914996027946472, Final Batch Loss: 0.5119568705558777\n",
      "Epoch 3478, Loss: 1.6955103799700737, Final Batch Loss: 0.08867102116346359\n",
      "Epoch 3479, Loss: 2.390736937522888, Final Batch Loss: 0.8348786234855652\n",
      "Epoch 3480, Loss: 1.940676897764206, Final Batch Loss: 0.324280709028244\n",
      "Epoch 3481, Loss: 2.196776032447815, Final Batch Loss: 0.43660858273506165\n",
      "Epoch 3482, Loss: 2.8081361055374146, Final Batch Loss: 1.1988954544067383\n",
      "Epoch 3483, Loss: 1.6209829300642014, Final Batch Loss: 0.21445991098880768\n",
      "Epoch 3484, Loss: 1.7750572860240936, Final Batch Loss: 0.2250790297985077\n",
      "Epoch 3485, Loss: 2.2554931938648224, Final Batch Loss: 0.6580457091331482\n",
      "Epoch 3486, Loss: 1.8120946735143661, Final Batch Loss: 0.19582371413707733\n",
      "Epoch 3487, Loss: 1.842149943113327, Final Batch Loss: 0.23444101214408875\n",
      "Epoch 3488, Loss: 2.1553851068019867, Final Batch Loss: 0.47580888867378235\n",
      "Epoch 3489, Loss: 1.7775691896677017, Final Batch Loss: 0.20634908974170685\n",
      "Epoch 3490, Loss: 2.42624968290329, Final Batch Loss: 0.8058403134346008\n",
      "Epoch 3491, Loss: 2.134263813495636, Final Batch Loss: 0.4306882321834564\n",
      "Epoch 3492, Loss: 2.029816508293152, Final Batch Loss: 0.31107640266418457\n",
      "Epoch 3493, Loss: 2.147531896829605, Final Batch Loss: 0.43002763390541077\n",
      "Epoch 3494, Loss: 2.469823479652405, Final Batch Loss: 0.8775234818458557\n",
      "Epoch 3495, Loss: 1.9683283567428589, Final Batch Loss: 0.3844574987888336\n",
      "Epoch 3496, Loss: 1.9903002679347992, Final Batch Loss: 0.397685706615448\n",
      "Epoch 3497, Loss: 2.0676662027835846, Final Batch Loss: 0.48774221539497375\n",
      "Epoch 3498, Loss: 1.897769257426262, Final Batch Loss: 0.19123516976833344\n",
      "Epoch 3499, Loss: 2.2237319946289062, Final Batch Loss: 0.47802093625068665\n",
      "Epoch 3500, Loss: 1.6677987799048424, Final Batch Loss: 0.09832512587308884\n",
      "Epoch 3501, Loss: 2.0044795721769333, Final Batch Loss: 0.12048955261707306\n",
      "Epoch 3502, Loss: 1.7198136895895004, Final Batch Loss: 0.22931115329265594\n",
      "Epoch 3503, Loss: 1.8364916145801544, Final Batch Loss: 0.3807697594165802\n",
      "Epoch 3504, Loss: 1.6613889634609222, Final Batch Loss: 0.22991526126861572\n",
      "Epoch 3505, Loss: 1.8716201186180115, Final Batch Loss: 0.3570118844509125\n",
      "Epoch 3506, Loss: 1.8716018795967102, Final Batch Loss: 0.34136220812797546\n",
      "Epoch 3507, Loss: 1.7860184758901596, Final Batch Loss: 0.1807853728532791\n",
      "Epoch 3508, Loss: 2.1449853479862213, Final Batch Loss: 0.6939067244529724\n",
      "Epoch 3509, Loss: 2.827095866203308, Final Batch Loss: 1.4349290132522583\n",
      "Epoch 3510, Loss: 2.6855494379997253, Final Batch Loss: 0.9038180708885193\n",
      "Epoch 3511, Loss: 3.0208320915699005, Final Batch Loss: 0.28424397110939026\n",
      "Epoch 3512, Loss: 2.980934292078018, Final Batch Loss: 0.40028509497642517\n",
      "Epoch 3513, Loss: 2.699659049510956, Final Batch Loss: 0.8181360960006714\n",
      "Epoch 3514, Loss: 2.0681556165218353, Final Batch Loss: 0.27441835403442383\n",
      "Epoch 3515, Loss: 2.1942995488643646, Final Batch Loss: 0.4358054995536804\n",
      "Epoch 3516, Loss: 1.9441317319869995, Final Batch Loss: 0.2767716646194458\n",
      "Epoch 3517, Loss: 1.8978895097970963, Final Batch Loss: 0.24430732429027557\n",
      "Epoch 3518, Loss: 1.940716028213501, Final Batch Loss: 0.3752635419368744\n",
      "Epoch 3519, Loss: 1.5723250731825829, Final Batch Loss: 0.07154124230146408\n",
      "Epoch 3520, Loss: 2.090231627225876, Final Batch Loss: 0.5466979146003723\n",
      "Epoch 3521, Loss: 2.139918953180313, Final Batch Loss: 0.4291628897190094\n",
      "Epoch 3522, Loss: 1.7955742329359055, Final Batch Loss: 0.19270892441272736\n",
      "Epoch 3523, Loss: 1.8346588760614395, Final Batch Loss: 0.19658394157886505\n",
      "Epoch 3524, Loss: 1.864286184310913, Final Batch Loss: 0.1989630162715912\n",
      "Epoch 3525, Loss: 2.093138039112091, Final Batch Loss: 0.5153384208679199\n",
      "Epoch 3526, Loss: 1.93241186439991, Final Batch Loss: 0.13692806661128998\n",
      "Epoch 3527, Loss: 1.8544520735740662, Final Batch Loss: 0.2975403368473053\n",
      "Epoch 3528, Loss: 1.8560154139995575, Final Batch Loss: 0.3015200197696686\n",
      "Epoch 3529, Loss: 2.0791158080101013, Final Batch Loss: 0.43146947026252747\n",
      "Epoch 3530, Loss: 1.691585212945938, Final Batch Loss: 0.18786677718162537\n",
      "Epoch 3531, Loss: 1.5629350543022156, Final Batch Loss: 0.22881636023521423\n",
      "Epoch 3532, Loss: 2.234755128622055, Final Batch Loss: 0.7096158862113953\n",
      "Epoch 3533, Loss: 2.073283225297928, Final Batch Loss: 0.4646945893764496\n",
      "Epoch 3534, Loss: 1.7053222805261612, Final Batch Loss: 0.17929865419864655\n",
      "Epoch 3535, Loss: 1.892562448978424, Final Batch Loss: 0.3618854582309723\n",
      "Epoch 3536, Loss: 1.7683814615011215, Final Batch Loss: 0.21713976562023163\n",
      "Epoch 3537, Loss: 2.2985582649707794, Final Batch Loss: 0.6385349035263062\n",
      "Epoch 3538, Loss: 1.785163015127182, Final Batch Loss: 0.280524343252182\n",
      "Epoch 3539, Loss: 1.8879699409008026, Final Batch Loss: 0.3531663119792938\n",
      "Epoch 3540, Loss: 1.8067129105329514, Final Batch Loss: 0.16827280819416046\n",
      "Epoch 3541, Loss: 1.9178326725959778, Final Batch Loss: 0.25547826290130615\n",
      "Epoch 3542, Loss: 2.29305961728096, Final Batch Loss: 0.6729082465171814\n",
      "Epoch 3543, Loss: 1.9040480256080627, Final Batch Loss: 0.24624326825141907\n",
      "Epoch 3544, Loss: 1.6918798834085464, Final Batch Loss: 0.1215619295835495\n",
      "Epoch 3545, Loss: 1.6222868412733078, Final Batch Loss: 0.08858205378055573\n",
      "Epoch 3546, Loss: 1.7448467314243317, Final Batch Loss: 0.3088977336883545\n",
      "Epoch 3547, Loss: 1.5227393731474876, Final Batch Loss: 0.08580230921506882\n",
      "Epoch 3548, Loss: 1.7412428855895996, Final Batch Loss: 0.2636694312095642\n",
      "Epoch 3549, Loss: 1.8897301852703094, Final Batch Loss: 0.3900575041770935\n",
      "Epoch 3550, Loss: 1.7604761123657227, Final Batch Loss: 0.3384498059749603\n",
      "Epoch 3551, Loss: 2.141342967748642, Final Batch Loss: 0.6001749038696289\n",
      "Epoch 3552, Loss: 1.9162285327911377, Final Batch Loss: 0.35333946347236633\n",
      "Epoch 3553, Loss: 1.907272070646286, Final Batch Loss: 0.28065818548202515\n",
      "Epoch 3554, Loss: 2.2615355849266052, Final Batch Loss: 0.5788089036941528\n",
      "Epoch 3555, Loss: 1.8518390357494354, Final Batch Loss: 0.31815603375434875\n",
      "Epoch 3556, Loss: 1.608981117606163, Final Batch Loss: 0.17412330210208893\n",
      "Epoch 3557, Loss: 2.413238137960434, Final Batch Loss: 0.8292128443717957\n",
      "Epoch 3558, Loss: 1.881610482931137, Final Batch Loss: 0.4062254726886749\n",
      "Epoch 3559, Loss: 1.8493954241275787, Final Batch Loss: 0.27219370007514954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3560, Loss: 2.1454219818115234, Final Batch Loss: 0.43116942048072815\n",
      "Epoch 3561, Loss: 2.2298290729522705, Final Batch Loss: 0.5329082012176514\n",
      "Epoch 3562, Loss: 2.217224270105362, Final Batch Loss: 0.428372859954834\n",
      "Epoch 3563, Loss: 2.321517050266266, Final Batch Loss: 0.7999233603477478\n",
      "Epoch 3564, Loss: 1.8221544027328491, Final Batch Loss: 0.3032997250556946\n",
      "Epoch 3565, Loss: 1.73087777197361, Final Batch Loss: 0.2488546520471573\n",
      "Epoch 3566, Loss: 2.2798473238945007, Final Batch Loss: 0.6729024648666382\n",
      "Epoch 3567, Loss: 1.8829350471496582, Final Batch Loss: 0.3492143154144287\n",
      "Epoch 3568, Loss: 2.0131331086158752, Final Batch Loss: 0.32850024104118347\n",
      "Epoch 3569, Loss: 2.591578096151352, Final Batch Loss: 0.7500948309898376\n",
      "Epoch 3570, Loss: 1.7367222607135773, Final Batch Loss: 0.15120753645896912\n",
      "Epoch 3571, Loss: 1.856791377067566, Final Batch Loss: 0.3493967056274414\n",
      "Epoch 3572, Loss: 1.7255500108003616, Final Batch Loss: 0.1650782972574234\n",
      "Epoch 3573, Loss: 2.377200871706009, Final Batch Loss: 0.776841938495636\n",
      "Epoch 3574, Loss: 1.8250921964645386, Final Batch Loss: 0.15190795063972473\n",
      "Epoch 3575, Loss: 2.0784711837768555, Final Batch Loss: 0.4862080216407776\n",
      "Epoch 3576, Loss: 2.410195916891098, Final Batch Loss: 0.6913056969642639\n",
      "Epoch 3577, Loss: 1.8642696142196655, Final Batch Loss: 0.2433300018310547\n",
      "Epoch 3578, Loss: 2.120685338973999, Final Batch Loss: 0.47591692209243774\n",
      "Epoch 3579, Loss: 1.8970927894115448, Final Batch Loss: 0.3236519396305084\n",
      "Epoch 3580, Loss: 1.9804913699626923, Final Batch Loss: 0.35005977749824524\n",
      "Epoch 3581, Loss: 1.7684483528137207, Final Batch Loss: 0.2532181143760681\n",
      "Epoch 3582, Loss: 1.6497493088245392, Final Batch Loss: 0.1896786391735077\n",
      "Epoch 3583, Loss: 2.0050548911094666, Final Batch Loss: 0.44870254397392273\n",
      "Epoch 3584, Loss: 1.5971838384866714, Final Batch Loss: 0.2287243753671646\n",
      "Epoch 3585, Loss: 1.757144570350647, Final Batch Loss: 0.37075915932655334\n",
      "Epoch 3586, Loss: 1.656222127377987, Final Batch Loss: 0.11420818418264389\n",
      "Epoch 3587, Loss: 1.7731730341911316, Final Batch Loss: 0.1810053586959839\n",
      "Epoch 3588, Loss: 1.8542405664920807, Final Batch Loss: 0.40169456601142883\n",
      "Epoch 3589, Loss: 1.9364979565143585, Final Batch Loss: 0.3709564208984375\n",
      "Epoch 3590, Loss: 2.0924534499645233, Final Batch Loss: 0.5908528566360474\n",
      "Epoch 3591, Loss: 1.7604036629199982, Final Batch Loss: 0.1872328817844391\n",
      "Epoch 3592, Loss: 1.7520359754562378, Final Batch Loss: 0.26506003737449646\n",
      "Epoch 3593, Loss: 1.876636654138565, Final Batch Loss: 0.4243347942829132\n",
      "Epoch 3594, Loss: 1.9430323541164398, Final Batch Loss: 0.41322681307792664\n",
      "Epoch 3595, Loss: 1.6928323805332184, Final Batch Loss: 0.24277177453041077\n",
      "Epoch 3596, Loss: 2.1627328991889954, Final Batch Loss: 0.6232088804244995\n",
      "Epoch 3597, Loss: 2.241230607032776, Final Batch Loss: 0.6991973519325256\n",
      "Epoch 3598, Loss: 1.815388798713684, Final Batch Loss: 0.4442918598651886\n",
      "Epoch 3599, Loss: 1.7697714269161224, Final Batch Loss: 0.28104928135871887\n",
      "Epoch 3600, Loss: 2.0245907306671143, Final Batch Loss: 0.4709371030330658\n",
      "Epoch 3601, Loss: 1.6822740882635117, Final Batch Loss: 0.15561755001544952\n",
      "Epoch 3602, Loss: 1.6275065168738365, Final Batch Loss: 0.06828292459249496\n",
      "Epoch 3603, Loss: 2.2786088287830353, Final Batch Loss: 0.5959760546684265\n",
      "Epoch 3604, Loss: 2.781157046556473, Final Batch Loss: 1.3423494100570679\n",
      "Epoch 3605, Loss: 2.148172438144684, Final Batch Loss: 0.6775942444801331\n",
      "Epoch 3606, Loss: 2.227693498134613, Final Batch Loss: 0.41994407773017883\n",
      "Epoch 3607, Loss: 2.3239244520664215, Final Batch Loss: 0.4065125286579132\n",
      "Epoch 3608, Loss: 2.541635811328888, Final Batch Loss: 0.7267475724220276\n",
      "Epoch 3609, Loss: 2.0403705835342407, Final Batch Loss: 0.48082035779953003\n",
      "Epoch 3610, Loss: 1.977895587682724, Final Batch Loss: 0.3717673122882843\n",
      "Epoch 3611, Loss: 2.1237038671970367, Final Batch Loss: 0.5115655064582825\n",
      "Epoch 3612, Loss: 1.962350308895111, Final Batch Loss: 0.4347434937953949\n",
      "Epoch 3613, Loss: 1.6363667696714401, Final Batch Loss: 0.15813089907169342\n",
      "Epoch 3614, Loss: 2.5744703710079193, Final Batch Loss: 1.0413274765014648\n",
      "Epoch 3615, Loss: 1.8325143456459045, Final Batch Loss: 0.2962094247341156\n",
      "Epoch 3616, Loss: 1.8331976532936096, Final Batch Loss: 0.1719573736190796\n",
      "Epoch 3617, Loss: 2.1467820703983307, Final Batch Loss: 0.3965674936771393\n",
      "Epoch 3618, Loss: 1.8042105436325073, Final Batch Loss: 0.3055250346660614\n",
      "Epoch 3619, Loss: 1.7213854640722275, Final Batch Loss: 0.24352283775806427\n",
      "Epoch 3620, Loss: 2.2093949615955353, Final Batch Loss: 0.6122273206710815\n",
      "Epoch 3621, Loss: 1.789193481206894, Final Batch Loss: 0.2046612799167633\n",
      "Epoch 3622, Loss: 1.937589019536972, Final Batch Loss: 0.37354087829589844\n",
      "Epoch 3623, Loss: 1.9164558947086334, Final Batch Loss: 0.34084802865982056\n",
      "Epoch 3624, Loss: 1.7676869183778763, Final Batch Loss: 0.1533127874135971\n",
      "Epoch 3625, Loss: 2.0702135860919952, Final Batch Loss: 0.427295058965683\n",
      "Epoch 3626, Loss: 1.6992338001728058, Final Batch Loss: 0.150120347738266\n",
      "Epoch 3627, Loss: 2.216641843318939, Final Batch Loss: 0.30851712822914124\n",
      "Epoch 3628, Loss: 2.3426518738269806, Final Batch Loss: 0.623417317867279\n",
      "Epoch 3629, Loss: 1.9365960955619812, Final Batch Loss: 0.2636691927909851\n",
      "Epoch 3630, Loss: 2.132127195596695, Final Batch Loss: 0.6398091316223145\n",
      "Epoch 3631, Loss: 2.0269813239574432, Final Batch Loss: 0.6207656264305115\n",
      "Epoch 3632, Loss: 2.2404113113880157, Final Batch Loss: 0.6350502371788025\n",
      "Epoch 3633, Loss: 2.4777800142765045, Final Batch Loss: 0.6642208695411682\n",
      "Epoch 3634, Loss: 2.055509865283966, Final Batch Loss: 0.49680250883102417\n",
      "Epoch 3635, Loss: 1.728793054819107, Final Batch Loss: 0.22008845210075378\n",
      "Epoch 3636, Loss: 2.006627857685089, Final Batch Loss: 0.4309709668159485\n",
      "Epoch 3637, Loss: 1.981784850358963, Final Batch Loss: 0.3162568509578705\n",
      "Epoch 3638, Loss: 1.9955655932426453, Final Batch Loss: 0.2781055271625519\n",
      "Epoch 3639, Loss: 2.071433573961258, Final Batch Loss: 0.34034818410873413\n",
      "Epoch 3640, Loss: 1.6314689368009567, Final Batch Loss: 0.2231474667787552\n",
      "Epoch 3641, Loss: 2.148306727409363, Final Batch Loss: 0.6105753183364868\n",
      "Epoch 3642, Loss: 1.8254112005233765, Final Batch Loss: 0.34018421173095703\n",
      "Epoch 3643, Loss: 1.70199716091156, Final Batch Loss: 0.16321668028831482\n",
      "Epoch 3644, Loss: 1.9494901597499847, Final Batch Loss: 0.43363675475120544\n",
      "Epoch 3645, Loss: 1.8465320765972137, Final Batch Loss: 0.4338536858558655\n",
      "Epoch 3646, Loss: 1.791790172457695, Final Batch Loss: 0.17955677211284637\n",
      "Epoch 3647, Loss: 1.5151263028383255, Final Batch Loss: 0.07377700507640839\n",
      "Epoch 3648, Loss: 1.8227157592773438, Final Batch Loss: 0.2760166823863983\n",
      "Epoch 3649, Loss: 1.807966187596321, Final Batch Loss: 0.21457450091838837\n",
      "Epoch 3650, Loss: 2.0173189640045166, Final Batch Loss: 0.5324981808662415\n",
      "Epoch 3651, Loss: 1.6889210641384125, Final Batch Loss: 0.30635812878608704\n",
      "Epoch 3652, Loss: 1.9531255066394806, Final Batch Loss: 0.33971524238586426\n",
      "Epoch 3653, Loss: 2.114970862865448, Final Batch Loss: 0.545430600643158\n",
      "Epoch 3654, Loss: 1.77423757314682, Final Batch Loss: 0.30511829257011414\n",
      "Epoch 3655, Loss: 1.9208192229270935, Final Batch Loss: 0.4029521942138672\n",
      "Epoch 3656, Loss: 1.894660472869873, Final Batch Loss: 0.30341652035713196\n",
      "Epoch 3657, Loss: 1.8630667328834534, Final Batch Loss: 0.26168039441108704\n",
      "Epoch 3658, Loss: 1.760761484503746, Final Batch Loss: 0.16866301000118256\n",
      "Epoch 3659, Loss: 1.6086440682411194, Final Batch Loss: 0.12799766659736633\n",
      "Epoch 3660, Loss: 2.1082452535629272, Final Batch Loss: 0.4815821647644043\n",
      "Epoch 3661, Loss: 1.8921676278114319, Final Batch Loss: 0.4865928590297699\n",
      "Epoch 3662, Loss: 1.8471064865589142, Final Batch Loss: 0.3086215555667877\n",
      "Epoch 3663, Loss: 1.8489142656326294, Final Batch Loss: 0.2914370894432068\n",
      "Epoch 3664, Loss: 1.781788855791092, Final Batch Loss: 0.40773504972457886\n",
      "Epoch 3665, Loss: 1.853301227092743, Final Batch Loss: 0.36530613899230957\n",
      "Epoch 3666, Loss: 1.8096541166305542, Final Batch Loss: 0.23686754703521729\n",
      "Epoch 3667, Loss: 2.1943215429782867, Final Batch Loss: 0.5562368631362915\n",
      "Epoch 3668, Loss: 1.914127916097641, Final Batch Loss: 0.453075647354126\n",
      "Epoch 3669, Loss: 1.8509043753147125, Final Batch Loss: 0.20798036456108093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3670, Loss: 1.5207909643650055, Final Batch Loss: 0.14554241299629211\n",
      "Epoch 3671, Loss: 2.0404253602027893, Final Batch Loss: 0.46376392245292664\n",
      "Epoch 3672, Loss: 1.6770502775907516, Final Batch Loss: 0.17836196720600128\n",
      "Epoch 3673, Loss: 1.9144386947154999, Final Batch Loss: 0.25915712118148804\n",
      "Epoch 3674, Loss: 2.111636221408844, Final Batch Loss: 0.43540260195732117\n",
      "Epoch 3675, Loss: 1.6370933428406715, Final Batch Loss: 0.1077573373913765\n",
      "Epoch 3676, Loss: 2.2964095920324326, Final Batch Loss: 0.23362098634243011\n",
      "Epoch 3677, Loss: 2.0623183250427246, Final Batch Loss: 0.3211265504360199\n",
      "Epoch 3678, Loss: 1.9012614488601685, Final Batch Loss: 0.4924613833427429\n",
      "Epoch 3679, Loss: 1.915346473455429, Final Batch Loss: 0.38888782262802124\n",
      "Epoch 3680, Loss: 2.0486347377300262, Final Batch Loss: 0.5255932807922363\n",
      "Epoch 3681, Loss: 1.544936429709196, Final Batch Loss: 0.0347430519759655\n",
      "Epoch 3682, Loss: 1.9265949428081512, Final Batch Loss: 0.2795926630496979\n",
      "Epoch 3683, Loss: 1.4981616362929344, Final Batch Loss: 0.07254549115896225\n",
      "Epoch 3684, Loss: 1.9152372777462006, Final Batch Loss: 0.48292192816734314\n",
      "Epoch 3685, Loss: 1.8388263583183289, Final Batch Loss: 0.32180455327033997\n",
      "Epoch 3686, Loss: 1.9189732372760773, Final Batch Loss: 0.40596526861190796\n",
      "Epoch 3687, Loss: 2.1605522632598877, Final Batch Loss: 0.5825167894363403\n",
      "Epoch 3688, Loss: 1.8865025639533997, Final Batch Loss: 0.4180777370929718\n",
      "Epoch 3689, Loss: 2.122791051864624, Final Batch Loss: 0.6732091307640076\n",
      "Epoch 3690, Loss: 1.9402201175689697, Final Batch Loss: 0.31515833735466003\n",
      "Epoch 3691, Loss: 1.9818487167358398, Final Batch Loss: 0.360423743724823\n",
      "Epoch 3692, Loss: 1.9033329486846924, Final Batch Loss: 0.2566743791103363\n",
      "Epoch 3693, Loss: 1.752371683716774, Final Batch Loss: 0.20174498856067657\n",
      "Epoch 3694, Loss: 1.9704606533050537, Final Batch Loss: 0.382985383272171\n",
      "Epoch 3695, Loss: 1.9710706621408463, Final Batch Loss: 0.2486889511346817\n",
      "Epoch 3696, Loss: 1.7676335722208023, Final Batch Loss: 0.17445321381092072\n",
      "Epoch 3697, Loss: 1.6050330698490143, Final Batch Loss: 0.15803444385528564\n",
      "Epoch 3698, Loss: 1.858016461133957, Final Batch Loss: 0.34677499532699585\n",
      "Epoch 3699, Loss: 1.8963549733161926, Final Batch Loss: 0.43768277764320374\n",
      "Epoch 3700, Loss: 1.8767406642436981, Final Batch Loss: 0.2921167016029358\n",
      "Epoch 3701, Loss: 1.802191510796547, Final Batch Loss: 0.21926744282245636\n",
      "Epoch 3702, Loss: 1.654060736298561, Final Batch Loss: 0.2454816848039627\n",
      "Epoch 3703, Loss: 1.6801948696374893, Final Batch Loss: 0.20528115332126617\n",
      "Epoch 3704, Loss: 1.729177102446556, Final Batch Loss: 0.19383634626865387\n",
      "Epoch 3705, Loss: 1.9634720087051392, Final Batch Loss: 0.3882383406162262\n",
      "Epoch 3706, Loss: 2.2282174825668335, Final Batch Loss: 0.6736940741539001\n",
      "Epoch 3707, Loss: 2.4790660440921783, Final Batch Loss: 0.7253036499023438\n",
      "Epoch 3708, Loss: 1.8519788533449173, Final Batch Loss: 0.12379245460033417\n",
      "Epoch 3709, Loss: 1.8019972443580627, Final Batch Loss: 0.368785560131073\n",
      "Epoch 3710, Loss: 2.214797705411911, Final Batch Loss: 0.5768567323684692\n",
      "Epoch 3711, Loss: 2.1254111230373383, Final Batch Loss: 0.3541095554828644\n",
      "Epoch 3712, Loss: 1.822809860110283, Final Batch Loss: 0.21712170541286469\n",
      "Epoch 3713, Loss: 2.099107503890991, Final Batch Loss: 0.4284532964229584\n",
      "Epoch 3714, Loss: 2.1727410554885864, Final Batch Loss: 0.5825758576393127\n",
      "Epoch 3715, Loss: 1.9630963206291199, Final Batch Loss: 0.3705141246318817\n",
      "Epoch 3716, Loss: 1.6413898020982742, Final Batch Loss: 0.22709624469280243\n",
      "Epoch 3717, Loss: 1.7586759328842163, Final Batch Loss: 0.21057608723640442\n",
      "Epoch 3718, Loss: 2.091892272233963, Final Batch Loss: 0.5334700345993042\n",
      "Epoch 3719, Loss: 1.7736401557922363, Final Batch Loss: 0.30109336972236633\n",
      "Epoch 3720, Loss: 1.7774997353553772, Final Batch Loss: 0.3559291362762451\n",
      "Epoch 3721, Loss: 1.627843089401722, Final Batch Loss: 0.1050882413983345\n",
      "Epoch 3722, Loss: 1.9054993391036987, Final Batch Loss: 0.2736813426017761\n",
      "Epoch 3723, Loss: 1.9286243915557861, Final Batch Loss: 0.4226636290550232\n",
      "Epoch 3724, Loss: 1.8424028009176254, Final Batch Loss: 0.24991293251514435\n",
      "Epoch 3725, Loss: 1.8215555548667908, Final Batch Loss: 0.34922394156455994\n",
      "Epoch 3726, Loss: 2.20537406206131, Final Batch Loss: 0.7445799708366394\n",
      "Epoch 3727, Loss: 1.3937075734138489, Final Batch Loss: 0.03730925917625427\n",
      "Epoch 3728, Loss: 1.7036579251289368, Final Batch Loss: 0.15135905146598816\n",
      "Epoch 3729, Loss: 1.6513646245002747, Final Batch Loss: 0.28344765305519104\n",
      "Epoch 3730, Loss: 1.9724370241165161, Final Batch Loss: 0.49175572395324707\n",
      "Epoch 3731, Loss: 1.7291814386844635, Final Batch Loss: 0.26946303248405457\n",
      "Epoch 3732, Loss: 2.3989956974983215, Final Batch Loss: 0.7986356616020203\n",
      "Epoch 3733, Loss: 1.8233613669872284, Final Batch Loss: 0.2641514241695404\n",
      "Epoch 3734, Loss: 1.987432599067688, Final Batch Loss: 0.4751485288143158\n",
      "Epoch 3735, Loss: 1.8054903745651245, Final Batch Loss: 0.27642589807510376\n",
      "Epoch 3736, Loss: 1.961667776107788, Final Batch Loss: 0.3310343623161316\n",
      "Epoch 3737, Loss: 1.808650940656662, Final Batch Loss: 0.333648681640625\n",
      "Epoch 3738, Loss: 1.9784563183784485, Final Batch Loss: 0.5395179986953735\n",
      "Epoch 3739, Loss: 1.984235793352127, Final Batch Loss: 0.35256901383399963\n",
      "Epoch 3740, Loss: 1.8582720458507538, Final Batch Loss: 0.3414026200771332\n",
      "Epoch 3741, Loss: 1.8621071875095367, Final Batch Loss: 0.3282499611377716\n",
      "Epoch 3742, Loss: 1.8653887510299683, Final Batch Loss: 0.38528960943222046\n",
      "Epoch 3743, Loss: 1.9407490640878677, Final Batch Loss: 0.24768586456775665\n",
      "Epoch 3744, Loss: 1.8900755643844604, Final Batch Loss: 0.4006841480731964\n",
      "Epoch 3745, Loss: 1.6765443682670593, Final Batch Loss: 0.2603100538253784\n",
      "Epoch 3746, Loss: 2.184452712535858, Final Batch Loss: 0.5510897040367126\n",
      "Epoch 3747, Loss: 1.71909661591053, Final Batch Loss: 0.13765813410282135\n",
      "Epoch 3748, Loss: 1.696887493133545, Final Batch Loss: 0.13177818059921265\n",
      "Epoch 3749, Loss: 2.1935303807258606, Final Batch Loss: 0.7566124796867371\n",
      "Epoch 3750, Loss: 1.827875405550003, Final Batch Loss: 0.4280921518802643\n",
      "Epoch 3751, Loss: 1.9328970313072205, Final Batch Loss: 0.3339175581932068\n",
      "Epoch 3752, Loss: 1.9277427196502686, Final Batch Loss: 0.3057117164134979\n",
      "Epoch 3753, Loss: 1.8847231566905975, Final Batch Loss: 0.44767266511917114\n",
      "Epoch 3754, Loss: 1.683312103152275, Final Batch Loss: 0.21560733020305634\n",
      "Epoch 3755, Loss: 1.5174202173948288, Final Batch Loss: 0.07852263748645782\n",
      "Epoch 3756, Loss: 2.0570669770240784, Final Batch Loss: 0.5908451080322266\n",
      "Epoch 3757, Loss: 1.718895137310028, Final Batch Loss: 0.32872557640075684\n",
      "Epoch 3758, Loss: 1.7689340710639954, Final Batch Loss: 0.2809714376926422\n",
      "Epoch 3759, Loss: 1.5335938185453415, Final Batch Loss: 0.19991149008274078\n",
      "Epoch 3760, Loss: 1.838014543056488, Final Batch Loss: 0.3086030185222626\n",
      "Epoch 3761, Loss: 1.983420193195343, Final Batch Loss: 0.5648503303527832\n",
      "Epoch 3762, Loss: 1.9101981818675995, Final Batch Loss: 0.380615770816803\n",
      "Epoch 3763, Loss: 1.7287166491150856, Final Batch Loss: 0.10683489590883255\n",
      "Epoch 3764, Loss: 1.957813173532486, Final Batch Loss: 0.3237122893333435\n",
      "Epoch 3765, Loss: 1.6588787361979485, Final Batch Loss: 0.08899607509374619\n",
      "Epoch 3766, Loss: 1.639658436179161, Final Batch Loss: 0.21385528147220612\n",
      "Epoch 3767, Loss: 1.956946611404419, Final Batch Loss: 0.3576890528202057\n",
      "Epoch 3768, Loss: 1.6665520668029785, Final Batch Loss: 0.2599686086177826\n",
      "Epoch 3769, Loss: 2.165656864643097, Final Batch Loss: 0.6045986413955688\n",
      "Epoch 3770, Loss: 2.1032468378543854, Final Batch Loss: 0.3711754381656647\n",
      "Epoch 3771, Loss: 1.9840429723262787, Final Batch Loss: 0.31323006749153137\n",
      "Epoch 3772, Loss: 2.0391184985637665, Final Batch Loss: 0.4887397885322571\n",
      "Epoch 3773, Loss: 2.0152658820152283, Final Batch Loss: 0.3869306445121765\n",
      "Epoch 3774, Loss: 1.8415526747703552, Final Batch Loss: 0.32388728857040405\n",
      "Epoch 3775, Loss: 1.868596076965332, Final Batch Loss: 0.2677200436592102\n",
      "Epoch 3776, Loss: 1.7081366777420044, Final Batch Loss: 0.22468769550323486\n",
      "Epoch 3777, Loss: 1.9117994606494904, Final Batch Loss: 0.28620460629463196\n",
      "Epoch 3778, Loss: 2.0379831194877625, Final Batch Loss: 0.4395037293434143\n",
      "Epoch 3779, Loss: 1.7830246090888977, Final Batch Loss: 0.3342178463935852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3780, Loss: 1.7746142148971558, Final Batch Loss: 0.1869862973690033\n",
      "Epoch 3781, Loss: 1.6710903495550156, Final Batch Loss: 0.10531382262706757\n",
      "Epoch 3782, Loss: 1.7657031416893005, Final Batch Loss: 0.2631163001060486\n",
      "Epoch 3783, Loss: 2.196752518415451, Final Batch Loss: 0.6721106767654419\n",
      "Epoch 3784, Loss: 1.6455643624067307, Final Batch Loss: 0.2446158081293106\n",
      "Epoch 3785, Loss: 1.955200582742691, Final Batch Loss: 0.47078976035118103\n",
      "Epoch 3786, Loss: 1.71113021671772, Final Batch Loss: 0.23250256478786469\n",
      "Epoch 3787, Loss: 1.9871592223644257, Final Batch Loss: 0.46908268332481384\n",
      "Epoch 3788, Loss: 1.6546193361282349, Final Batch Loss: 0.19553324580192566\n",
      "Epoch 3789, Loss: 1.976439356803894, Final Batch Loss: 0.4428003132343292\n",
      "Epoch 3790, Loss: 1.7157533019781113, Final Batch Loss: 0.146172896027565\n",
      "Epoch 3791, Loss: 1.7028354406356812, Final Batch Loss: 0.2555120587348938\n",
      "Epoch 3792, Loss: 2.24288809299469, Final Batch Loss: 0.657965362071991\n",
      "Epoch 3793, Loss: 2.2751505374908447, Final Batch Loss: 0.7497574090957642\n",
      "Epoch 3794, Loss: 1.9094176888465881, Final Batch Loss: 0.46625471115112305\n",
      "Epoch 3795, Loss: 2.548921078443527, Final Batch Loss: 0.9449682831764221\n",
      "Epoch 3796, Loss: 1.9174692332744598, Final Batch Loss: 0.299572229385376\n",
      "Epoch 3797, Loss: 1.938917875289917, Final Batch Loss: 0.3113410472869873\n",
      "Epoch 3798, Loss: 1.8652245998382568, Final Batch Loss: 0.25560736656188965\n",
      "Epoch 3799, Loss: 1.6145834475755692, Final Batch Loss: 0.20261900126934052\n",
      "Epoch 3800, Loss: 1.8824013769626617, Final Batch Loss: 0.40149980783462524\n",
      "Epoch 3801, Loss: 1.99247407913208, Final Batch Loss: 0.42208096385002136\n",
      "Epoch 3802, Loss: 1.9612262398004532, Final Batch Loss: 0.4413021206855774\n",
      "Epoch 3803, Loss: 2.113940477371216, Final Batch Loss: 0.5831230282783508\n",
      "Epoch 3804, Loss: 2.185307413339615, Final Batch Loss: 0.5121812224388123\n",
      "Epoch 3805, Loss: 1.8345313519239426, Final Batch Loss: 0.22190217673778534\n",
      "Epoch 3806, Loss: 2.101456493139267, Final Batch Loss: 0.5158482193946838\n",
      "Epoch 3807, Loss: 1.635131686925888, Final Batch Loss: 0.2054729461669922\n",
      "Epoch 3808, Loss: 1.5218207761645317, Final Batch Loss: 0.08649974316358566\n",
      "Epoch 3809, Loss: 2.083329677581787, Final Batch Loss: 0.6152195930480957\n",
      "Epoch 3810, Loss: 1.7657586634159088, Final Batch Loss: 0.3442201018333435\n",
      "Epoch 3811, Loss: 1.9809046387672424, Final Batch Loss: 0.6565089225769043\n",
      "Epoch 3812, Loss: 1.7165741920471191, Final Batch Loss: 0.3156385123729706\n",
      "Epoch 3813, Loss: 1.5898718684911728, Final Batch Loss: 0.14351870119571686\n",
      "Epoch 3814, Loss: 1.9684531390666962, Final Batch Loss: 0.5372808575630188\n",
      "Epoch 3815, Loss: 1.9533065259456635, Final Batch Loss: 0.40763506293296814\n",
      "Epoch 3816, Loss: 1.8917806446552277, Final Batch Loss: 0.4586685299873352\n",
      "Epoch 3817, Loss: 1.857542634010315, Final Batch Loss: 0.36687180399894714\n",
      "Epoch 3818, Loss: 1.7640808820724487, Final Batch Loss: 0.2513558566570282\n",
      "Epoch 3819, Loss: 1.8270444869995117, Final Batch Loss: 0.30707499384880066\n",
      "Epoch 3820, Loss: 1.8783657252788544, Final Batch Loss: 0.3831568658351898\n",
      "Epoch 3821, Loss: 1.9294062554836273, Final Batch Loss: 0.393004447221756\n",
      "Epoch 3822, Loss: 2.0774613320827484, Final Batch Loss: 0.3921666145324707\n",
      "Epoch 3823, Loss: 1.8850072622299194, Final Batch Loss: 0.34278422594070435\n",
      "Epoch 3824, Loss: 2.002509593963623, Final Batch Loss: 0.45321354269981384\n",
      "Epoch 3825, Loss: 1.818407028913498, Final Batch Loss: 0.2820436358451843\n",
      "Epoch 3826, Loss: 1.8434101045131683, Final Batch Loss: 0.33013033866882324\n",
      "Epoch 3827, Loss: 2.1926765143871307, Final Batch Loss: 0.6739841103553772\n",
      "Epoch 3828, Loss: 1.8395889103412628, Final Batch Loss: 0.25031912326812744\n",
      "Epoch 3829, Loss: 1.608565203845501, Final Batch Loss: 0.11461662501096725\n",
      "Epoch 3830, Loss: 1.9948581457138062, Final Batch Loss: 0.3841531276702881\n",
      "Epoch 3831, Loss: 2.1041580140590668, Final Batch Loss: 0.6230484843254089\n",
      "Epoch 3832, Loss: 1.7675746232271194, Final Batch Loss: 0.16494117677211761\n",
      "Epoch 3833, Loss: 1.7129697054624557, Final Batch Loss: 0.19393290579319\n",
      "Epoch 3834, Loss: 1.7519012540578842, Final Batch Loss: 0.13622109591960907\n",
      "Epoch 3835, Loss: 2.146445393562317, Final Batch Loss: 0.6747270822525024\n",
      "Epoch 3836, Loss: 2.01693457365036, Final Batch Loss: 0.5374504923820496\n",
      "Epoch 3837, Loss: 2.555317759513855, Final Batch Loss: 0.874954342842102\n",
      "Epoch 3838, Loss: 1.733593761920929, Final Batch Loss: 0.2698703706264496\n",
      "Epoch 3839, Loss: 1.6193695962429047, Final Batch Loss: 0.11995893716812134\n",
      "Epoch 3840, Loss: 1.8217221200466156, Final Batch Loss: 0.37718909978866577\n",
      "Epoch 3841, Loss: 1.9677926003932953, Final Batch Loss: 0.5431209206581116\n",
      "Epoch 3842, Loss: 1.9947782456874847, Final Batch Loss: 0.34589526057243347\n",
      "Epoch 3843, Loss: 1.919981449842453, Final Batch Loss: 0.2884952127933502\n",
      "Epoch 3844, Loss: 2.0664508938789368, Final Batch Loss: 0.4729415774345398\n",
      "Epoch 3845, Loss: 1.7688855230808258, Final Batch Loss: 0.2094285488128662\n",
      "Epoch 3846, Loss: 1.893735557794571, Final Batch Loss: 0.3249640166759491\n",
      "Epoch 3847, Loss: 1.7227020859718323, Final Batch Loss: 0.35125866532325745\n",
      "Epoch 3848, Loss: 2.007703021168709, Final Batch Loss: 0.20727749168872833\n",
      "Epoch 3849, Loss: 2.0471214950084686, Final Batch Loss: 0.5120030641555786\n",
      "Epoch 3850, Loss: 1.748293399810791, Final Batch Loss: 0.3239423334598541\n",
      "Epoch 3851, Loss: 1.9560670256614685, Final Batch Loss: 0.43282169103622437\n",
      "Epoch 3852, Loss: 1.5913125425577164, Final Batch Loss: 0.15062831342220306\n",
      "Epoch 3853, Loss: 1.7164634317159653, Final Batch Loss: 0.16941456496715546\n",
      "Epoch 3854, Loss: 1.6501757949590683, Final Batch Loss: 0.2110229879617691\n",
      "Epoch 3855, Loss: 1.5611235797405243, Final Batch Loss: 0.14421963691711426\n",
      "Epoch 3856, Loss: 1.591367483139038, Final Batch Loss: 0.18868422508239746\n",
      "Epoch 3857, Loss: 1.9967788755893707, Final Batch Loss: 0.4799415171146393\n",
      "Epoch 3858, Loss: 1.5644935201853514, Final Batch Loss: 0.027982784435153008\n",
      "Epoch 3859, Loss: 1.9405163526535034, Final Batch Loss: 0.3737965226173401\n",
      "Epoch 3860, Loss: 1.753327876329422, Final Batch Loss: 0.2582481801509857\n",
      "Epoch 3861, Loss: 1.9839349687099457, Final Batch Loss: 0.594659686088562\n",
      "Epoch 3862, Loss: 1.7589090764522552, Final Batch Loss: 0.18413051962852478\n",
      "Epoch 3863, Loss: 2.0431391894817352, Final Batch Loss: 0.4720918834209442\n",
      "Epoch 3864, Loss: 1.7214140892028809, Final Batch Loss: 0.31810644268989563\n",
      "Epoch 3865, Loss: 2.107515275478363, Final Batch Loss: 0.6212702393531799\n",
      "Epoch 3866, Loss: 2.0823260247707367, Final Batch Loss: 0.5458217263221741\n",
      "Epoch 3867, Loss: 1.6897814720869064, Final Batch Loss: 0.19420327246189117\n",
      "Epoch 3868, Loss: 1.9083235561847687, Final Batch Loss: 0.34613552689552307\n",
      "Epoch 3869, Loss: 1.54258181899786, Final Batch Loss: 0.07175987213850021\n",
      "Epoch 3870, Loss: 1.6547886431217194, Final Batch Loss: 0.281451016664505\n",
      "Epoch 3871, Loss: 1.855267733335495, Final Batch Loss: 0.46917253732681274\n",
      "Epoch 3872, Loss: 1.8508468568325043, Final Batch Loss: 0.2969467043876648\n",
      "Epoch 3873, Loss: 2.054586946964264, Final Batch Loss: 0.4285831153392792\n",
      "Epoch 3874, Loss: 1.9624085128307343, Final Batch Loss: 0.3662673532962799\n",
      "Epoch 3875, Loss: 1.7709332704544067, Final Batch Loss: 0.25795960426330566\n",
      "Epoch 3876, Loss: 2.1771382689476013, Final Batch Loss: 0.5658772587776184\n",
      "Epoch 3877, Loss: 1.656128853559494, Final Batch Loss: 0.12990882992744446\n",
      "Epoch 3878, Loss: 1.617834061384201, Final Batch Loss: 0.1973794400691986\n",
      "Epoch 3879, Loss: 1.587916687130928, Final Batch Loss: 0.14666666090488434\n",
      "Epoch 3880, Loss: 2.1044511795043945, Final Batch Loss: 0.5784077644348145\n",
      "Epoch 3881, Loss: 1.8586874306201935, Final Batch Loss: 0.40871211886405945\n",
      "Epoch 3882, Loss: 1.81011962890625, Final Batch Loss: 0.16484594345092773\n",
      "Epoch 3883, Loss: 1.829127013683319, Final Batch Loss: 0.32451799511909485\n",
      "Epoch 3884, Loss: 1.6732589900493622, Final Batch Loss: 0.27666905522346497\n",
      "Epoch 3885, Loss: 1.8580966293811798, Final Batch Loss: 0.2193944752216339\n",
      "Epoch 3886, Loss: 1.8917674869298935, Final Batch Loss: 0.23492975533008575\n",
      "Epoch 3887, Loss: 2.0315396785736084, Final Batch Loss: 0.6514361500740051\n",
      "Epoch 3888, Loss: 2.1652962267398834, Final Batch Loss: 0.6443691849708557\n",
      "Epoch 3889, Loss: 1.862919569015503, Final Batch Loss: 0.3587900698184967\n",
      "Epoch 3890, Loss: 1.974809467792511, Final Batch Loss: 0.35180947184562683\n",
      "Epoch 3891, Loss: 1.7753695994615555, Final Batch Loss: 0.23714189231395721\n",
      "Epoch 3892, Loss: 1.7303448617458344, Final Batch Loss: 0.2605283260345459\n",
      "Epoch 3893, Loss: 1.9313514232635498, Final Batch Loss: 0.5583584904670715\n",
      "Epoch 3894, Loss: 2.0859655141830444, Final Batch Loss: 0.6301758885383606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3895, Loss: 2.0890009105205536, Final Batch Loss: 0.6196280121803284\n",
      "Epoch 3896, Loss: 1.7363106906414032, Final Batch Loss: 0.33844736218452454\n",
      "Epoch 3897, Loss: 2.0785098373889923, Final Batch Loss: 0.5143343806266785\n",
      "Epoch 3898, Loss: 2.1701559126377106, Final Batch Loss: 0.5700585246086121\n",
      "Epoch 3899, Loss: 2.2370143830776215, Final Batch Loss: 0.7805241346359253\n",
      "Epoch 3900, Loss: 1.9054806232452393, Final Batch Loss: 0.4675578474998474\n",
      "Epoch 3901, Loss: 2.2907049655914307, Final Batch Loss: 0.7440900802612305\n",
      "Epoch 3902, Loss: 1.9435747563838959, Final Batch Loss: 0.37024936079978943\n",
      "Epoch 3903, Loss: 2.1422643959522247, Final Batch Loss: 0.3584476411342621\n",
      "Epoch 3904, Loss: 1.7577927857637405, Final Batch Loss: 0.10241629183292389\n",
      "Epoch 3905, Loss: 2.102354645729065, Final Batch Loss: 0.4318676292896271\n",
      "Epoch 3906, Loss: 1.7453462332487106, Final Batch Loss: 0.21652118861675262\n",
      "Epoch 3907, Loss: 2.5549520552158356, Final Batch Loss: 1.1048650741577148\n",
      "Epoch 3908, Loss: 1.9979682266712189, Final Batch Loss: 0.3318030834197998\n",
      "Epoch 3909, Loss: 1.5907786637544632, Final Batch Loss: 0.09498937427997589\n",
      "Epoch 3910, Loss: 1.6358674317598343, Final Batch Loss: 0.18180029094219208\n",
      "Epoch 3911, Loss: 1.7932901978492737, Final Batch Loss: 0.21843859553337097\n",
      "Epoch 3912, Loss: 2.2374681532382965, Final Batch Loss: 0.6502675414085388\n",
      "Epoch 3913, Loss: 2.1655741035938263, Final Batch Loss: 0.5003390312194824\n",
      "Epoch 3914, Loss: 2.0460354685783386, Final Batch Loss: 0.41477346420288086\n",
      "Epoch 3915, Loss: 2.157425671815872, Final Batch Loss: 0.5466713905334473\n",
      "Epoch 3916, Loss: 1.7990439534187317, Final Batch Loss: 0.2652405798435211\n",
      "Epoch 3917, Loss: 1.6080056875944138, Final Batch Loss: 0.10249803960323334\n",
      "Epoch 3918, Loss: 1.9187636524438858, Final Batch Loss: 0.19700200855731964\n",
      "Epoch 3919, Loss: 2.056722730398178, Final Batch Loss: 0.5689132809638977\n",
      "Epoch 3920, Loss: 1.6435569524765015, Final Batch Loss: 0.2095482051372528\n",
      "Epoch 3921, Loss: 1.6402310654520988, Final Batch Loss: 0.05326434224843979\n",
      "Epoch 3922, Loss: 2.1177406013011932, Final Batch Loss: 0.6841334104537964\n",
      "Epoch 3923, Loss: 2.1816143095493317, Final Batch Loss: 0.6021276116371155\n",
      "Epoch 3924, Loss: 1.5718607753515244, Final Batch Loss: 0.14248482882976532\n",
      "Epoch 3925, Loss: 3.79369780421257, Final Batch Loss: 2.1910364627838135\n",
      "Epoch 3926, Loss: 1.6875123083591461, Final Batch Loss: 0.2493647336959839\n",
      "Epoch 3927, Loss: 2.171113967895508, Final Batch Loss: 0.6371288299560547\n",
      "Epoch 3928, Loss: 1.88714100420475, Final Batch Loss: 0.2446271926164627\n",
      "Epoch 3929, Loss: 1.9105396270751953, Final Batch Loss: 0.34047093987464905\n",
      "Epoch 3930, Loss: 1.8838581442832947, Final Batch Loss: 0.2500680983066559\n",
      "Epoch 3931, Loss: 1.7851676046848297, Final Batch Loss: 0.29132339358329773\n",
      "Epoch 3932, Loss: 1.692740574479103, Final Batch Loss: 0.24094952642917633\n",
      "Epoch 3933, Loss: 1.6102675572037697, Final Batch Loss: 0.10139579325914383\n",
      "Epoch 3934, Loss: 1.9020664691925049, Final Batch Loss: 0.36491701006889343\n",
      "Epoch 3935, Loss: 2.0693707168102264, Final Batch Loss: 0.6750108003616333\n",
      "Epoch 3936, Loss: 2.1744764149188995, Final Batch Loss: 0.6669446229934692\n",
      "Epoch 3937, Loss: 1.7902449816465378, Final Batch Loss: 0.23387344181537628\n",
      "Epoch 3938, Loss: 1.6749838292598724, Final Batch Loss: 0.21120285987854004\n",
      "Epoch 3939, Loss: 2.172191560268402, Final Batch Loss: 0.543752133846283\n",
      "Epoch 3940, Loss: 2.0345703959465027, Final Batch Loss: 0.44698336720466614\n",
      "Epoch 3941, Loss: 2.053434431552887, Final Batch Loss: 0.320468008518219\n",
      "Epoch 3942, Loss: 2.1118157505989075, Final Batch Loss: 0.42162808775901794\n",
      "Epoch 3943, Loss: 1.9196597933769226, Final Batch Loss: 0.278493732213974\n",
      "Epoch 3944, Loss: 2.2272748351097107, Final Batch Loss: 0.48884373903274536\n",
      "Epoch 3945, Loss: 2.008077025413513, Final Batch Loss: 0.2670854926109314\n",
      "Epoch 3946, Loss: 2.056341528892517, Final Batch Loss: 0.5041406154632568\n",
      "Epoch 3947, Loss: 1.6865099966526031, Final Batch Loss: 0.14579841494560242\n",
      "Epoch 3948, Loss: 1.86630517244339, Final Batch Loss: 0.37418481707572937\n",
      "Epoch 3949, Loss: 1.9265890717506409, Final Batch Loss: 0.3924662172794342\n",
      "Epoch 3950, Loss: 1.7111219242215157, Final Batch Loss: 0.09772268682718277\n",
      "Epoch 3951, Loss: 1.854206919670105, Final Batch Loss: 0.4400767683982849\n",
      "Epoch 3952, Loss: 2.340536117553711, Final Batch Loss: 0.7279685139656067\n",
      "Epoch 3953, Loss: 2.2367524206638336, Final Batch Loss: 0.6607570052146912\n",
      "Epoch 3954, Loss: 1.8667103350162506, Final Batch Loss: 0.3281762897968292\n",
      "Epoch 3955, Loss: 2.4570270776748657, Final Batch Loss: 0.7612136006355286\n",
      "Epoch 3956, Loss: 2.202157199382782, Final Batch Loss: 0.6011226773262024\n",
      "Epoch 3957, Loss: 1.6750931218266487, Final Batch Loss: 0.05035371333360672\n",
      "Epoch 3958, Loss: 1.7327902019023895, Final Batch Loss: 0.2110934555530548\n",
      "Epoch 3959, Loss: 2.769357353448868, Final Batch Loss: 1.0787163972854614\n",
      "Epoch 3960, Loss: 1.6578442454338074, Final Batch Loss: 0.20736464858055115\n",
      "Epoch 3961, Loss: 1.8195963501930237, Final Batch Loss: 0.241798996925354\n",
      "Epoch 3962, Loss: 1.8135671466588974, Final Batch Loss: 0.20361141860485077\n",
      "Epoch 3963, Loss: 2.8681139945983887, Final Batch Loss: 1.3748128414154053\n",
      "Epoch 3964, Loss: 1.8673062920570374, Final Batch Loss: 0.39727163314819336\n",
      "Epoch 3965, Loss: 1.9686298370361328, Final Batch Loss: 0.3446802496910095\n",
      "Epoch 3966, Loss: 2.3680026531219482, Final Batch Loss: 0.8050025105476379\n",
      "Epoch 3967, Loss: 1.9602479040622711, Final Batch Loss: 0.26337963342666626\n",
      "Epoch 3968, Loss: 2.005110055208206, Final Batch Loss: 0.31388697028160095\n",
      "Epoch 3969, Loss: 1.7663389891386032, Final Batch Loss: 0.21847327053546906\n",
      "Epoch 3970, Loss: 2.490218073129654, Final Batch Loss: 0.9042325019836426\n",
      "Epoch 3971, Loss: 1.7508206367492676, Final Batch Loss: 0.18241629004478455\n",
      "Epoch 3972, Loss: 2.7504123747348785, Final Batch Loss: 0.7523140907287598\n",
      "Epoch 3973, Loss: 2.6223480999469757, Final Batch Loss: 0.7395673990249634\n",
      "Epoch 3974, Loss: 2.091703087091446, Final Batch Loss: 0.47336238622665405\n",
      "Epoch 3975, Loss: 2.2496725022792816, Final Batch Loss: 0.4027385115623474\n",
      "Epoch 3976, Loss: 2.172709748148918, Final Batch Loss: 0.24361179769039154\n",
      "Epoch 3977, Loss: 1.7432981729507446, Final Batch Loss: 0.19062736630439758\n",
      "Epoch 3978, Loss: 2.089539051055908, Final Batch Loss: 0.5790103077888489\n",
      "Epoch 3979, Loss: 1.9738179445266724, Final Batch Loss: 0.4789506793022156\n",
      "Epoch 3980, Loss: 1.9195435047149658, Final Batch Loss: 0.37057653069496155\n",
      "Epoch 3981, Loss: 1.9918759167194366, Final Batch Loss: 0.3998110294342041\n",
      "Epoch 3982, Loss: 1.675998568534851, Final Batch Loss: 0.16305610537528992\n",
      "Epoch 3983, Loss: 1.7841594815254211, Final Batch Loss: 0.3041131794452667\n",
      "Epoch 3984, Loss: 1.6761446744203568, Final Batch Loss: 0.1946275383234024\n",
      "Epoch 3985, Loss: 1.852403149008751, Final Batch Loss: 0.21953891217708588\n",
      "Epoch 3986, Loss: 1.774331510066986, Final Batch Loss: 0.3775849938392639\n",
      "Epoch 3987, Loss: 1.5974393039941788, Final Batch Loss: 0.14334280788898468\n",
      "Epoch 3988, Loss: 1.7425630390644073, Final Batch Loss: 0.34464043378829956\n",
      "Epoch 3989, Loss: 1.6551721543073654, Final Batch Loss: 0.1700470894575119\n",
      "Epoch 3990, Loss: 1.7599696815013885, Final Batch Loss: 0.3189143240451813\n",
      "Epoch 3991, Loss: 2.0228660106658936, Final Batch Loss: 0.6682154536247253\n",
      "Epoch 3992, Loss: 1.7647461891174316, Final Batch Loss: 0.32456454634666443\n",
      "Epoch 3993, Loss: 1.7200515270233154, Final Batch Loss: 0.25162073969841003\n",
      "Epoch 3994, Loss: 1.8872213959693909, Final Batch Loss: 0.3870014250278473\n",
      "Epoch 3995, Loss: 2.006156235933304, Final Batch Loss: 0.3581187129020691\n",
      "Epoch 3996, Loss: 1.9430104792118073, Final Batch Loss: 0.4060378074645996\n",
      "Epoch 3997, Loss: 1.5413994640111923, Final Batch Loss: 0.07381193339824677\n",
      "Epoch 3998, Loss: 1.9059946238994598, Final Batch Loss: 0.39122119545936584\n",
      "Epoch 3999, Loss: 1.977468490600586, Final Batch Loss: 0.4243742525577545\n",
      "Epoch 4000, Loss: 1.82851442694664, Final Batch Loss: 0.4076058864593506\n",
      "Epoch 4001, Loss: 1.8379251211881638, Final Batch Loss: 0.15511460602283478\n",
      "Epoch 4002, Loss: 2.06563737988472, Final Batch Loss: 0.552284836769104\n",
      "Epoch 4003, Loss: 2.0162400007247925, Final Batch Loss: 0.4648735225200653\n",
      "Epoch 4004, Loss: 1.7765299081802368, Final Batch Loss: 0.2851193845272064\n",
      "Epoch 4005, Loss: 2.0553946793079376, Final Batch Loss: 0.44886064529418945\n",
      "Epoch 4006, Loss: 1.823474794626236, Final Batch Loss: 0.3560987412929535\n",
      "Epoch 4007, Loss: 2.0779140293598175, Final Batch Loss: 0.5568712949752808\n",
      "Epoch 4008, Loss: 2.0689472258090973, Final Batch Loss: 0.4354468882083893\n",
      "Epoch 4009, Loss: 2.147218883037567, Final Batch Loss: 0.7266865968704224\n",
      "Epoch 4010, Loss: 1.6000179201364517, Final Batch Loss: 0.23966653645038605\n",
      "Epoch 4011, Loss: 1.5616216361522675, Final Batch Loss: 0.1253037452697754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4012, Loss: 1.806628257036209, Final Batch Loss: 0.3386826515197754\n",
      "Epoch 4013, Loss: 1.7042368352413177, Final Batch Loss: 0.2922815978527069\n",
      "Epoch 4014, Loss: 2.0957418084144592, Final Batch Loss: 0.48921987414360046\n",
      "Epoch 4015, Loss: 1.9989160895347595, Final Batch Loss: 0.4405296742916107\n",
      "Epoch 4016, Loss: 1.619734212756157, Final Batch Loss: 0.08045689761638641\n",
      "Epoch 4017, Loss: 1.7587441802024841, Final Batch Loss: 0.21832981705665588\n",
      "Epoch 4018, Loss: 2.12497615814209, Final Batch Loss: 0.7362433671951294\n",
      "Epoch 4019, Loss: 1.6835484057664871, Final Batch Loss: 0.20823217928409576\n",
      "Epoch 4020, Loss: 1.7079850137233734, Final Batch Loss: 0.18454119563102722\n",
      "Epoch 4021, Loss: 1.5773915089666843, Final Batch Loss: 0.04981306567788124\n",
      "Epoch 4022, Loss: 1.9108708053827286, Final Batch Loss: 0.48488298058509827\n",
      "Epoch 4023, Loss: 1.9295148253440857, Final Batch Loss: 0.5263331532478333\n",
      "Epoch 4024, Loss: 1.7430766820907593, Final Batch Loss: 0.28938937187194824\n",
      "Epoch 4025, Loss: 2.464819014072418, Final Batch Loss: 0.8909582495689392\n",
      "Epoch 4026, Loss: 1.7427320778369904, Final Batch Loss: 0.14261600375175476\n",
      "Epoch 4027, Loss: 1.898185908794403, Final Batch Loss: 0.373312771320343\n",
      "Epoch 4028, Loss: 1.5593032091856003, Final Batch Loss: 0.1382860392332077\n",
      "Epoch 4029, Loss: 1.952947050333023, Final Batch Loss: 0.3255811631679535\n",
      "Epoch 4030, Loss: 1.8858305215835571, Final Batch Loss: 0.350080668926239\n",
      "Epoch 4031, Loss: 1.5421690344810486, Final Batch Loss: 0.04508903622627258\n",
      "Epoch 4032, Loss: 1.8869799226522446, Final Batch Loss: 0.173514261841774\n",
      "Epoch 4033, Loss: 1.6677930057048798, Final Batch Loss: 0.12877491116523743\n",
      "Epoch 4034, Loss: 2.052307605743408, Final Batch Loss: 0.6471037268638611\n",
      "Epoch 4035, Loss: 2.166548579931259, Final Batch Loss: 0.5789762139320374\n",
      "Epoch 4036, Loss: 1.8088518977165222, Final Batch Loss: 0.2728045582771301\n",
      "Epoch 4037, Loss: 1.8711579740047455, Final Batch Loss: 0.3861784040927887\n",
      "Epoch 4038, Loss: 1.7156565934419632, Final Batch Loss: 0.23626531660556793\n",
      "Epoch 4039, Loss: 1.633155718445778, Final Batch Loss: 0.1301507204771042\n",
      "Epoch 4040, Loss: 1.9031753540039062, Final Batch Loss: 0.44106897711753845\n",
      "Epoch 4041, Loss: 2.1408106982707977, Final Batch Loss: 0.6504186987876892\n",
      "Epoch 4042, Loss: 1.5982339978218079, Final Batch Loss: 0.17410102486610413\n",
      "Epoch 4043, Loss: 1.891592025756836, Final Batch Loss: 0.3090970516204834\n",
      "Epoch 4044, Loss: 2.2292831540107727, Final Batch Loss: 0.7574070692062378\n",
      "Epoch 4045, Loss: 2.0889849066734314, Final Batch Loss: 0.7093364596366882\n",
      "Epoch 4046, Loss: 1.5435269922018051, Final Batch Loss: 0.2036331743001938\n",
      "Epoch 4047, Loss: 2.1601013243198395, Final Batch Loss: 0.5758777260780334\n",
      "Epoch 4048, Loss: 1.7388786375522614, Final Batch Loss: 0.29452425241470337\n",
      "Epoch 4049, Loss: 1.6502233743667603, Final Batch Loss: 0.36029741168022156\n",
      "Epoch 4050, Loss: 2.4175519347190857, Final Batch Loss: 1.0157617330551147\n",
      "Epoch 4051, Loss: 1.7442821115255356, Final Batch Loss: 0.20914243161678314\n",
      "Epoch 4052, Loss: 1.975166529417038, Final Batch Loss: 0.34674757719039917\n",
      "Epoch 4053, Loss: 1.6949325203895569, Final Batch Loss: 0.2539719343185425\n",
      "Epoch 4054, Loss: 2.093054711818695, Final Batch Loss: 0.6130293011665344\n",
      "Epoch 4055, Loss: 2.140623450279236, Final Batch Loss: 0.7277668118476868\n",
      "Epoch 4056, Loss: 1.704462081193924, Final Batch Loss: 0.16904985904693604\n",
      "Epoch 4057, Loss: 1.8161116689443588, Final Batch Loss: 0.20926381647586823\n",
      "Epoch 4058, Loss: 1.7104049623012543, Final Batch Loss: 0.1730336844921112\n",
      "Epoch 4059, Loss: 1.7080652862787247, Final Batch Loss: 0.22344286739826202\n",
      "Epoch 4060, Loss: 1.7346278727054596, Final Batch Loss: 0.1590782105922699\n",
      "Epoch 4061, Loss: 1.6911209374666214, Final Batch Loss: 0.2195344716310501\n",
      "Epoch 4062, Loss: 2.1351972818374634, Final Batch Loss: 0.5132332444190979\n",
      "Epoch 4063, Loss: 1.9232470989227295, Final Batch Loss: 0.3132418096065521\n",
      "Epoch 4064, Loss: 2.042789250612259, Final Batch Loss: 0.5298789739608765\n",
      "Epoch 4065, Loss: 2.030841439962387, Final Batch Loss: 0.40417447686195374\n",
      "Epoch 4066, Loss: 1.720460593700409, Final Batch Loss: 0.2317277491092682\n",
      "Epoch 4067, Loss: 2.0455357134342194, Final Batch Loss: 0.4849705398082733\n",
      "Epoch 4068, Loss: 2.321345031261444, Final Batch Loss: 0.8423870801925659\n",
      "Epoch 4069, Loss: 1.9683211147785187, Final Batch Loss: 0.4894285500049591\n",
      "Epoch 4070, Loss: 1.7604436725378036, Final Batch Loss: 0.21953369677066803\n",
      "Epoch 4071, Loss: 1.7105471938848495, Final Batch Loss: 0.20858092606067657\n",
      "Epoch 4072, Loss: 2.1952418088912964, Final Batch Loss: 0.47468703985214233\n",
      "Epoch 4073, Loss: 1.870507836341858, Final Batch Loss: 0.39449381828308105\n",
      "Epoch 4074, Loss: 2.354272246360779, Final Batch Loss: 0.8501968383789062\n",
      "Epoch 4075, Loss: 2.0293971598148346, Final Batch Loss: 0.41001632809638977\n",
      "Epoch 4076, Loss: 2.0076268315315247, Final Batch Loss: 0.4663720428943634\n",
      "Epoch 4077, Loss: 1.6938618570566177, Final Batch Loss: 0.23510940372943878\n",
      "Epoch 4078, Loss: 1.9792576730251312, Final Batch Loss: 0.376740425825119\n",
      "Epoch 4079, Loss: 1.8360615074634552, Final Batch Loss: 0.4462338984012604\n",
      "Epoch 4080, Loss: 2.1765270829200745, Final Batch Loss: 0.4992302358150482\n",
      "Epoch 4081, Loss: 2.1039430499076843, Final Batch Loss: 0.5324837565422058\n",
      "Epoch 4082, Loss: 1.9706864058971405, Final Batch Loss: 0.3337329924106598\n",
      "Epoch 4083, Loss: 2.231603592634201, Final Batch Loss: 0.5675140023231506\n",
      "Epoch 4084, Loss: 1.951760083436966, Final Batch Loss: 0.4054037928581238\n",
      "Epoch 4085, Loss: 2.234363079071045, Final Batch Loss: 0.627233624458313\n",
      "Epoch 4086, Loss: 1.882128044962883, Final Batch Loss: 0.1954812854528427\n",
      "Epoch 4087, Loss: 1.8708284497261047, Final Batch Loss: 0.31366199254989624\n",
      "Epoch 4088, Loss: 1.7562971338629723, Final Batch Loss: 0.10460373014211655\n",
      "Epoch 4089, Loss: 2.1505322754383087, Final Batch Loss: 0.5089990496635437\n",
      "Epoch 4090, Loss: 1.7085315585136414, Final Batch Loss: 0.20181119441986084\n",
      "Epoch 4091, Loss: 1.8961125612258911, Final Batch Loss: 0.3778002858161926\n",
      "Epoch 4092, Loss: 1.7753991484642029, Final Batch Loss: 0.3129664957523346\n",
      "Epoch 4093, Loss: 1.7672030329704285, Final Batch Loss: 0.22773292660713196\n",
      "Epoch 4094, Loss: 1.7809945940971375, Final Batch Loss: 0.34982436895370483\n",
      "Epoch 4095, Loss: 1.8280947506427765, Final Batch Loss: 0.37778258323669434\n",
      "Epoch 4096, Loss: 1.8551473021507263, Final Batch Loss: 0.30862829089164734\n",
      "Epoch 4097, Loss: 1.5278529301285744, Final Batch Loss: 0.06634388118982315\n",
      "Epoch 4098, Loss: 1.7958778142929077, Final Batch Loss: 0.2574847936630249\n",
      "Epoch 4099, Loss: 1.722924917936325, Final Batch Loss: 0.2622428238391876\n",
      "Epoch 4100, Loss: 2.2311490774154663, Final Batch Loss: 0.6839675903320312\n",
      "Epoch 4101, Loss: 2.709681987762451, Final Batch Loss: 1.010149359703064\n",
      "Epoch 4102, Loss: 2.004000872373581, Final Batch Loss: 0.5447496771812439\n",
      "Epoch 4103, Loss: 2.1895097196102142, Final Batch Loss: 0.70319664478302\n",
      "Epoch 4104, Loss: 2.3690727055072784, Final Batch Loss: 0.8045523762702942\n",
      "Epoch 4105, Loss: 1.987302452325821, Final Batch Loss: 0.28974053263664246\n",
      "Epoch 4106, Loss: 1.6840263307094574, Final Batch Loss: 0.11490708589553833\n",
      "Epoch 4107, Loss: 2.035307228565216, Final Batch Loss: 0.455495148897171\n",
      "Epoch 4108, Loss: 1.7075052708387375, Final Batch Loss: 0.23579801619052887\n",
      "Epoch 4109, Loss: 1.9911465048789978, Final Batch Loss: 0.3914535939693451\n",
      "Epoch 4110, Loss: 1.8846632838249207, Final Batch Loss: 0.3502044081687927\n",
      "Epoch 4111, Loss: 1.9503326416015625, Final Batch Loss: 0.36512765288352966\n",
      "Epoch 4112, Loss: 2.1532959640026093, Final Batch Loss: 0.47611990571022034\n",
      "Epoch 4113, Loss: 1.970205932855606, Final Batch Loss: 0.3234669864177704\n",
      "Epoch 4114, Loss: 2.1350038647651672, Final Batch Loss: 0.5935783982276917\n",
      "Epoch 4115, Loss: 1.864904209971428, Final Batch Loss: 0.1666068285703659\n",
      "Epoch 4116, Loss: 1.7685116082429886, Final Batch Loss: 0.12749536335468292\n",
      "Epoch 4117, Loss: 1.9042396545410156, Final Batch Loss: 0.4409599006175995\n",
      "Epoch 4118, Loss: 1.8934618830680847, Final Batch Loss: 0.3716807961463928\n",
      "Epoch 4119, Loss: 2.2875362038612366, Final Batch Loss: 0.744083046913147\n",
      "Epoch 4120, Loss: 1.6416206061840057, Final Batch Loss: 0.16118061542510986\n",
      "Epoch 4121, Loss: 1.5939317606389523, Final Batch Loss: 0.027468111366033554\n",
      "Epoch 4122, Loss: 1.9244173765182495, Final Batch Loss: 0.46308615803718567\n",
      "Epoch 4123, Loss: 1.725789800286293, Final Batch Loss: 0.23360316455364227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4124, Loss: 2.00600403547287, Final Batch Loss: 0.6013798117637634\n",
      "Epoch 4125, Loss: 1.7259488850831985, Final Batch Loss: 0.12507693469524384\n",
      "Epoch 4126, Loss: 1.745627522468567, Final Batch Loss: 0.19596174359321594\n",
      "Epoch 4127, Loss: 1.8541285246610641, Final Batch Loss: 0.18054364621639252\n",
      "Epoch 4128, Loss: 1.8335785269737244, Final Batch Loss: 0.3205830454826355\n",
      "Epoch 4129, Loss: 1.717157781124115, Final Batch Loss: 0.30775290727615356\n",
      "Epoch 4130, Loss: 1.9811387658119202, Final Batch Loss: 0.4616360366344452\n",
      "Epoch 4131, Loss: 1.8878862857818604, Final Batch Loss: 0.3389488160610199\n",
      "Epoch 4132, Loss: 1.6109410151839256, Final Batch Loss: 0.0830008015036583\n",
      "Epoch 4133, Loss: 1.531652718782425, Final Batch Loss: 0.13004985451698303\n",
      "Epoch 4134, Loss: 1.8956235945224762, Final Batch Loss: 0.3823237717151642\n",
      "Epoch 4135, Loss: 1.6577802896499634, Final Batch Loss: 0.20747438073158264\n",
      "Epoch 4136, Loss: 1.8423325419425964, Final Batch Loss: 0.35262584686279297\n",
      "Epoch 4137, Loss: 1.745124876499176, Final Batch Loss: 0.3728565275669098\n",
      "Epoch 4138, Loss: 1.7991116046905518, Final Batch Loss: 0.27389752864837646\n",
      "Epoch 4139, Loss: 1.693606197834015, Final Batch Loss: 0.19501543045043945\n",
      "Epoch 4140, Loss: 2.0175330340862274, Final Batch Loss: 0.6634283065795898\n",
      "Epoch 4141, Loss: 1.7171960771083832, Final Batch Loss: 0.40363630652427673\n",
      "Epoch 4142, Loss: 1.6747434884309769, Final Batch Loss: 0.13126398622989655\n",
      "Epoch 4143, Loss: 1.5573397427797318, Final Batch Loss: 0.1869235783815384\n",
      "Epoch 4144, Loss: 2.0695756673812866, Final Batch Loss: 0.5134809613227844\n",
      "Epoch 4145, Loss: 1.969499558210373, Final Batch Loss: 0.6027640104293823\n",
      "Epoch 4146, Loss: 1.983076959848404, Final Batch Loss: 0.4363801181316376\n",
      "Epoch 4147, Loss: 2.0184101164340973, Final Batch Loss: 0.34505176544189453\n",
      "Epoch 4148, Loss: 1.6409934014081955, Final Batch Loss: 0.23499207198619843\n",
      "Epoch 4149, Loss: 1.6799658238887787, Final Batch Loss: 0.1724412441253662\n",
      "Epoch 4150, Loss: 1.544253345578909, Final Batch Loss: 0.03736593946814537\n",
      "Epoch 4151, Loss: 2.1251669824123383, Final Batch Loss: 0.7106807827949524\n",
      "Epoch 4152, Loss: 1.8216293454170227, Final Batch Loss: 0.39381709694862366\n",
      "Epoch 4153, Loss: 2.524653732776642, Final Batch Loss: 0.9219793677330017\n",
      "Epoch 4154, Loss: 2.0604985058307648, Final Batch Loss: 0.4224880635738373\n",
      "Epoch 4155, Loss: 2.308894991874695, Final Batch Loss: 0.677269458770752\n",
      "Epoch 4156, Loss: 2.172072321176529, Final Batch Loss: 0.618619441986084\n",
      "Epoch 4157, Loss: 1.9269132316112518, Final Batch Loss: 0.3741576373577118\n",
      "Epoch 4158, Loss: 2.038978099822998, Final Batch Loss: 0.45307883620262146\n",
      "Epoch 4159, Loss: 2.4952763319015503, Final Batch Loss: 0.9361540675163269\n",
      "Epoch 4160, Loss: 1.7512603849172592, Final Batch Loss: 0.2283758968114853\n",
      "Epoch 4161, Loss: 1.7620625495910645, Final Batch Loss: 0.1946517527103424\n",
      "Epoch 4162, Loss: 2.287040650844574, Final Batch Loss: 0.43303531408309937\n",
      "Epoch 4163, Loss: 2.242032438516617, Final Batch Loss: 0.6713913679122925\n",
      "Epoch 4164, Loss: 2.7025910317897797, Final Batch Loss: 1.0847208499908447\n",
      "Epoch 4165, Loss: 1.715071827173233, Final Batch Loss: 0.13370269536972046\n",
      "Epoch 4166, Loss: 2.114569365978241, Final Batch Loss: 0.3716011643409729\n",
      "Epoch 4167, Loss: 1.9754111468791962, Final Batch Loss: 0.4999253749847412\n",
      "Epoch 4168, Loss: 2.1193154752254486, Final Batch Loss: 0.5345982313156128\n",
      "Epoch 4169, Loss: 1.9843544661998749, Final Batch Loss: 0.6093677282333374\n",
      "Epoch 4170, Loss: 1.8111315965652466, Final Batch Loss: 0.24616050720214844\n",
      "Epoch 4171, Loss: 1.7998530864715576, Final Batch Loss: 0.3570399284362793\n",
      "Epoch 4172, Loss: 1.6819095313549042, Final Batch Loss: 0.19775798916816711\n",
      "Epoch 4173, Loss: 1.7743633687496185, Final Batch Loss: 0.25273260474205017\n",
      "Epoch 4174, Loss: 2.222416251897812, Final Batch Loss: 0.6770477890968323\n",
      "Epoch 4175, Loss: 1.7249986231327057, Final Batch Loss: 0.25012072920799255\n",
      "Epoch 4176, Loss: 1.7863416373729706, Final Batch Loss: 0.32891935110092163\n",
      "Epoch 4177, Loss: 1.6588483899831772, Final Batch Loss: 0.1277667135000229\n",
      "Epoch 4178, Loss: 1.622769057750702, Final Batch Loss: 0.1462254524230957\n",
      "Epoch 4179, Loss: 1.4786180406808853, Final Batch Loss: 0.085060253739357\n",
      "Epoch 4180, Loss: 1.6760121285915375, Final Batch Loss: 0.27853691577911377\n",
      "Epoch 4181, Loss: 1.7120234072208405, Final Batch Loss: 0.257035493850708\n",
      "Epoch 4182, Loss: 1.6799594163894653, Final Batch Loss: 0.1207650899887085\n",
      "Epoch 4183, Loss: 1.8635276556015015, Final Batch Loss: 0.4391956925392151\n",
      "Epoch 4184, Loss: 1.615165039896965, Final Batch Loss: 0.21905510127544403\n",
      "Epoch 4185, Loss: 2.0329385101795197, Final Batch Loss: 0.6320427656173706\n",
      "Epoch 4186, Loss: 2.145535260438919, Final Batch Loss: 0.4954879581928253\n",
      "Epoch 4187, Loss: 2.323904573917389, Final Batch Loss: 0.8038737177848816\n",
      "Epoch 4188, Loss: 2.022589147090912, Final Batch Loss: 0.3915281295776367\n",
      "Epoch 4189, Loss: 2.081398367881775, Final Batch Loss: 0.626952588558197\n",
      "Epoch 4190, Loss: 2.30184543132782, Final Batch Loss: 0.7623828053474426\n",
      "Epoch 4191, Loss: 2.2732593715190887, Final Batch Loss: 0.7839695811271667\n",
      "Epoch 4192, Loss: 2.350397527217865, Final Batch Loss: 0.9160006642341614\n",
      "Epoch 4193, Loss: 2.04534775018692, Final Batch Loss: 0.41749969124794006\n",
      "Epoch 4194, Loss: 1.884471446275711, Final Batch Loss: 0.3211119771003723\n",
      "Epoch 4195, Loss: 2.39979088306427, Final Batch Loss: 0.8073030114173889\n",
      "Epoch 4196, Loss: 1.7463840693235397, Final Batch Loss: 0.20093069970607758\n",
      "Epoch 4197, Loss: 2.1145544052124023, Final Batch Loss: 0.5123911499977112\n",
      "Epoch 4198, Loss: 1.7760392278432846, Final Batch Loss: 0.16263051331043243\n",
      "Epoch 4199, Loss: 2.464136928319931, Final Batch Loss: 0.8280940651893616\n",
      "Epoch 4200, Loss: 1.8756367862224579, Final Batch Loss: 0.4003378450870514\n",
      "Epoch 4201, Loss: 1.8360326886177063, Final Batch Loss: 0.40888187289237976\n",
      "Epoch 4202, Loss: 1.95376056432724, Final Batch Loss: 0.5521171689033508\n",
      "Epoch 4203, Loss: 2.1734015941619873, Final Batch Loss: 0.4183056056499481\n",
      "Epoch 4204, Loss: 2.445625066757202, Final Batch Loss: 0.6624719500541687\n",
      "Epoch 4205, Loss: 1.8272496610879898, Final Batch Loss: 0.18840546905994415\n",
      "Epoch 4206, Loss: 2.5010712444782257, Final Batch Loss: 0.5770809054374695\n",
      "Epoch 4207, Loss: 2.3011669516563416, Final Batch Loss: 0.3317984938621521\n",
      "Epoch 4208, Loss: 2.3272279500961304, Final Batch Loss: 0.3040207028388977\n",
      "Epoch 4209, Loss: 2.187528520822525, Final Batch Loss: 0.36814531683921814\n",
      "Epoch 4210, Loss: 2.2365298867225647, Final Batch Loss: 0.6172952651977539\n",
      "Epoch 4211, Loss: 2.744673490524292, Final Batch Loss: 1.1653846502304077\n",
      "Epoch 4212, Loss: 1.8797460049390793, Final Batch Loss: 0.22621627151966095\n",
      "Epoch 4213, Loss: 2.3694611191749573, Final Batch Loss: 0.5988908410072327\n",
      "Epoch 4214, Loss: 1.7699168920516968, Final Batch Loss: 0.27224215865135193\n",
      "Epoch 4215, Loss: 1.984957605600357, Final Batch Loss: 0.36299464106559753\n",
      "Epoch 4216, Loss: 2.0038278698921204, Final Batch Loss: 0.30939245223999023\n",
      "Epoch 4217, Loss: 2.1999402046203613, Final Batch Loss: 0.6568703651428223\n",
      "Epoch 4218, Loss: 1.6815160363912582, Final Batch Loss: 0.18635721504688263\n",
      "Epoch 4219, Loss: 1.9556277096271515, Final Batch Loss: 0.4675304591655731\n",
      "Epoch 4220, Loss: 1.6509405374526978, Final Batch Loss: 0.30706483125686646\n",
      "Epoch 4221, Loss: 1.530811257660389, Final Batch Loss: 0.1104305163025856\n",
      "Epoch 4222, Loss: 1.81174536049366, Final Batch Loss: 0.209369495511055\n",
      "Epoch 4223, Loss: 1.6468799412250519, Final Batch Loss: 0.1830413043498993\n",
      "Epoch 4224, Loss: 2.0313620269298553, Final Batch Loss: 0.4428284168243408\n",
      "Epoch 4225, Loss: 2.0054096579551697, Final Batch Loss: 0.4369962811470032\n",
      "Epoch 4226, Loss: 1.6790886670351028, Final Batch Loss: 0.2001945823431015\n",
      "Epoch 4227, Loss: 1.9190032482147217, Final Batch Loss: 0.37883803248405457\n",
      "Epoch 4228, Loss: 1.6249069720506668, Final Batch Loss: 0.21583764255046844\n",
      "Epoch 4229, Loss: 1.707719773054123, Final Batch Loss: 0.22432485222816467\n",
      "Epoch 4230, Loss: 1.964518427848816, Final Batch Loss: 0.25340157747268677\n",
      "Epoch 4231, Loss: 1.5710515305399895, Final Batch Loss: 0.11575856059789658\n",
      "Epoch 4232, Loss: 1.6443186849355698, Final Batch Loss: 0.20491187274456024\n",
      "Epoch 4233, Loss: 1.7512377053499222, Final Batch Loss: 0.22326652705669403\n",
      "Epoch 4234, Loss: 1.7932488024234772, Final Batch Loss: 0.19695675373077393\n",
      "Epoch 4235, Loss: 2.0284681022167206, Final Batch Loss: 0.4973874092102051\n",
      "Epoch 4236, Loss: 1.641055628657341, Final Batch Loss: 0.186893031001091\n",
      "Epoch 4237, Loss: 1.9218043088912964, Final Batch Loss: 0.44912391901016235\n",
      "Epoch 4238, Loss: 1.8727390766143799, Final Batch Loss: 0.36368685960769653\n",
      "Epoch 4239, Loss: 2.1555643677711487, Final Batch Loss: 0.7295175194740295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4240, Loss: 1.706280492246151, Final Batch Loss: 0.07915481179952621\n",
      "Epoch 4241, Loss: 2.1789352893829346, Final Batch Loss: 0.5199079513549805\n",
      "Epoch 4242, Loss: 2.0701067447662354, Final Batch Loss: 0.3781341016292572\n",
      "Epoch 4243, Loss: 1.9239211976528168, Final Batch Loss: 0.3966609537601471\n",
      "Epoch 4244, Loss: 2.5315169394016266, Final Batch Loss: 0.8392283320426941\n",
      "Epoch 4245, Loss: 1.7356468439102173, Final Batch Loss: 0.1589125096797943\n",
      "Epoch 4246, Loss: 2.116881847381592, Final Batch Loss: 0.5502719283103943\n",
      "Epoch 4247, Loss: 1.920058786869049, Final Batch Loss: 0.6165379881858826\n",
      "Epoch 4248, Loss: 1.9628416299819946, Final Batch Loss: 0.4723454415798187\n",
      "Epoch 4249, Loss: 2.14385786652565, Final Batch Loss: 0.5662938356399536\n",
      "Epoch 4250, Loss: 2.2346754670143127, Final Batch Loss: 0.5228059887886047\n",
      "Epoch 4251, Loss: 1.8414697647094727, Final Batch Loss: 0.308076411485672\n",
      "Epoch 4252, Loss: 1.7500073909759521, Final Batch Loss: 0.18402209877967834\n",
      "Epoch 4253, Loss: 1.8018547594547272, Final Batch Loss: 0.21553611755371094\n",
      "Epoch 4254, Loss: 2.0099753737449646, Final Batch Loss: 0.5259174108505249\n",
      "Epoch 4255, Loss: 2.432614743709564, Final Batch Loss: 0.9405368566513062\n",
      "Epoch 4256, Loss: 2.017532765865326, Final Batch Loss: 0.5093573927879333\n",
      "Epoch 4257, Loss: 2.234539955854416, Final Batch Loss: 0.43939298391342163\n",
      "Epoch 4258, Loss: 2.095843583345413, Final Batch Loss: 0.461313396692276\n",
      "Epoch 4259, Loss: 2.2237431704998016, Final Batch Loss: 0.65220707654953\n",
      "Epoch 4260, Loss: 1.772005707025528, Final Batch Loss: 0.28905680775642395\n",
      "Epoch 4261, Loss: 1.6084971353411674, Final Batch Loss: 0.09374093264341354\n",
      "Epoch 4262, Loss: 1.7115497291088104, Final Batch Loss: 0.25488874316215515\n",
      "Epoch 4263, Loss: 1.679486483335495, Final Batch Loss: 0.1664825677871704\n",
      "Epoch 4264, Loss: 1.4413363724015653, Final Batch Loss: 0.007153668906539679\n",
      "Epoch 4265, Loss: 2.261530488729477, Final Batch Loss: 0.749478280544281\n",
      "Epoch 4266, Loss: 1.8941006064414978, Final Batch Loss: 0.44940754771232605\n",
      "Epoch 4267, Loss: 1.6687031239271164, Final Batch Loss: 0.12309171259403229\n",
      "Epoch 4268, Loss: 2.1777888536453247, Final Batch Loss: 0.5758141875267029\n",
      "Epoch 4269, Loss: 1.48707564920187, Final Batch Loss: 0.09033524245023727\n",
      "Epoch 4270, Loss: 1.7050997018814087, Final Batch Loss: 0.22172221541404724\n",
      "Epoch 4271, Loss: 1.7246244251728058, Final Batch Loss: 0.29256534576416016\n",
      "Epoch 4272, Loss: 1.6276894062757492, Final Batch Loss: 0.14527101814746857\n",
      "Epoch 4273, Loss: 1.8067552745342255, Final Batch Loss: 0.21596622467041016\n",
      "Epoch 4274, Loss: 2.0665439069271088, Final Batch Loss: 0.5657001733779907\n",
      "Epoch 4275, Loss: 1.532675176858902, Final Batch Loss: 0.1513148844242096\n",
      "Epoch 4276, Loss: 1.4272767920047045, Final Batch Loss: 0.021770210936665535\n",
      "Epoch 4277, Loss: 1.6813394725322723, Final Batch Loss: 0.30136871337890625\n",
      "Epoch 4278, Loss: 1.7599117457866669, Final Batch Loss: 0.38466838002204895\n",
      "Epoch 4279, Loss: 1.68641796708107, Final Batch Loss: 0.3370859622955322\n",
      "Epoch 4280, Loss: 2.3524499237537384, Final Batch Loss: 0.8843513131141663\n",
      "Epoch 4281, Loss: 1.7796846777200699, Final Batch Loss: 0.22396962344646454\n",
      "Epoch 4282, Loss: 1.7671508938074112, Final Batch Loss: 0.18225570023059845\n",
      "Epoch 4283, Loss: 1.6249022781848907, Final Batch Loss: 0.13939538598060608\n",
      "Epoch 4284, Loss: 1.9223170578479767, Final Batch Loss: 0.4931502640247345\n",
      "Epoch 4285, Loss: 1.7350758612155914, Final Batch Loss: 0.3102591931819916\n",
      "Epoch 4286, Loss: 1.8926380425691605, Final Batch Loss: 0.2194627970457077\n",
      "Epoch 4287, Loss: 1.8962202370166779, Final Batch Loss: 0.4612504541873932\n",
      "Epoch 4288, Loss: 1.6958352029323578, Final Batch Loss: 0.20095685124397278\n",
      "Epoch 4289, Loss: 1.8279304951429367, Final Batch Loss: 0.22822315990924835\n",
      "Epoch 4290, Loss: 1.8377367854118347, Final Batch Loss: 0.3255770206451416\n",
      "Epoch 4291, Loss: 1.8911166489124298, Final Batch Loss: 0.42686471343040466\n",
      "Epoch 4292, Loss: 1.9249794483184814, Final Batch Loss: 0.40603145956993103\n",
      "Epoch 4293, Loss: 1.6511818915605545, Final Batch Loss: 0.20484386384487152\n",
      "Epoch 4294, Loss: 1.8639830350875854, Final Batch Loss: 0.398698627948761\n",
      "Epoch 4295, Loss: 1.6526966243982315, Final Batch Loss: 0.2138085514307022\n",
      "Epoch 4296, Loss: 1.5274995416402817, Final Batch Loss: 0.17039258778095245\n",
      "Epoch 4297, Loss: 1.6462493240833282, Final Batch Loss: 0.31844577193260193\n",
      "Epoch 4298, Loss: 1.6158317103981972, Final Batch Loss: 0.06581798940896988\n",
      "Epoch 4299, Loss: 1.8707757592201233, Final Batch Loss: 0.30672556161880493\n",
      "Epoch 4300, Loss: 1.7055808454751968, Final Batch Loss: 0.16076283156871796\n",
      "Epoch 4301, Loss: 1.7020860612392426, Final Batch Loss: 0.261513352394104\n",
      "Epoch 4302, Loss: 2.5237535536289215, Final Batch Loss: 0.971372663974762\n",
      "Epoch 4303, Loss: 2.488986909389496, Final Batch Loss: 0.9603355526924133\n",
      "Epoch 4304, Loss: 2.109804183244705, Final Batch Loss: 0.5410303473472595\n",
      "Epoch 4305, Loss: 2.14579114317894, Final Batch Loss: 0.5982171297073364\n",
      "Epoch 4306, Loss: 2.071753889322281, Final Batch Loss: 0.5865957140922546\n",
      "Epoch 4307, Loss: 1.9973242580890656, Final Batch Loss: 0.6156792640686035\n",
      "Epoch 4308, Loss: 2.0606288611888885, Final Batch Loss: 0.5939196944236755\n",
      "Epoch 4309, Loss: 1.676186352968216, Final Batch Loss: 0.2080068588256836\n",
      "Epoch 4310, Loss: 1.803385153412819, Final Batch Loss: 0.18650169670581818\n",
      "Epoch 4311, Loss: 1.884911447763443, Final Batch Loss: 0.5415209531784058\n",
      "Epoch 4312, Loss: 1.7482221573591232, Final Batch Loss: 0.2381318360567093\n",
      "Epoch 4313, Loss: 1.7408621907234192, Final Batch Loss: 0.2902512550354004\n",
      "Epoch 4314, Loss: 2.750313878059387, Final Batch Loss: 1.3104640245437622\n",
      "Epoch 4315, Loss: 1.6856760680675507, Final Batch Loss: 0.27841052412986755\n",
      "Epoch 4316, Loss: 1.7428589761257172, Final Batch Loss: 0.3775821626186371\n",
      "Epoch 4317, Loss: 2.034223794937134, Final Batch Loss: 0.7050221562385559\n",
      "Epoch 4318, Loss: 1.6024625450372696, Final Batch Loss: 0.15917648375034332\n",
      "Epoch 4319, Loss: 2.2253597676754, Final Batch Loss: 0.763281524181366\n",
      "Epoch 4320, Loss: 1.7667062282562256, Final Batch Loss: 0.3833593726158142\n",
      "Epoch 4321, Loss: 2.3452283442020416, Final Batch Loss: 0.8846530318260193\n",
      "Epoch 4322, Loss: 2.2125162482261658, Final Batch Loss: 0.7117388844490051\n",
      "Epoch 4323, Loss: 1.884615570306778, Final Batch Loss: 0.3208656907081604\n",
      "Epoch 4324, Loss: 1.8228143751621246, Final Batch Loss: 0.3973877429962158\n",
      "Epoch 4325, Loss: 1.6444527059793472, Final Batch Loss: 0.2111433893442154\n",
      "Epoch 4326, Loss: 1.6680536419153214, Final Batch Loss: 0.20592103898525238\n",
      "Epoch 4327, Loss: 1.567173793911934, Final Batch Loss: 0.2319059818983078\n",
      "Epoch 4328, Loss: 1.65098637342453, Final Batch Loss: 0.302261620759964\n",
      "Epoch 4329, Loss: 2.031232327222824, Final Batch Loss: 0.6207364797592163\n",
      "Epoch 4330, Loss: 1.6453903019428253, Final Batch Loss: 0.2588765025138855\n",
      "Epoch 4331, Loss: 2.0994750261306763, Final Batch Loss: 0.6209931373596191\n",
      "Epoch 4332, Loss: 1.7517393827438354, Final Batch Loss: 0.21646425127983093\n",
      "Epoch 4333, Loss: 2.1309933364391327, Final Batch Loss: 0.5696336030960083\n",
      "Epoch 4334, Loss: 1.8754237294197083, Final Batch Loss: 0.3129560947418213\n",
      "Epoch 4335, Loss: 1.7123513221740723, Final Batch Loss: 0.2176831066608429\n",
      "Epoch 4336, Loss: 1.9411171078681946, Final Batch Loss: 0.4882175922393799\n",
      "Epoch 4337, Loss: 1.8747582733631134, Final Batch Loss: 0.5402181148529053\n",
      "Epoch 4338, Loss: 1.6265968084335327, Final Batch Loss: 0.3490291237831116\n",
      "Epoch 4339, Loss: 2.2603942453861237, Final Batch Loss: 0.6959777474403381\n",
      "Epoch 4340, Loss: 2.093171149492264, Final Batch Loss: 0.5006284117698669\n",
      "Epoch 4341, Loss: 1.818623125553131, Final Batch Loss: 0.2858741283416748\n",
      "Epoch 4342, Loss: 2.3745974600315094, Final Batch Loss: 0.7069717645645142\n",
      "Epoch 4343, Loss: 2.0877432823181152, Final Batch Loss: 0.36918336153030396\n",
      "Epoch 4344, Loss: 1.8330471217632294, Final Batch Loss: 0.30686721205711365\n",
      "Epoch 4345, Loss: 2.0727221369743347, Final Batch Loss: 0.5615158677101135\n",
      "Epoch 4346, Loss: 1.9186417162418365, Final Batch Loss: 0.37896108627319336\n",
      "Epoch 4347, Loss: 2.1175468266010284, Final Batch Loss: 0.5863205194473267\n",
      "Epoch 4348, Loss: 1.7436400428414345, Final Batch Loss: 0.11129812151193619\n",
      "Epoch 4349, Loss: 1.814431518316269, Final Batch Loss: 0.37786221504211426\n",
      "Epoch 4350, Loss: 1.772295504808426, Final Batch Loss: 0.30356910824775696\n",
      "Epoch 4351, Loss: 1.932259202003479, Final Batch Loss: 0.34896352887153625\n",
      "Epoch 4352, Loss: 2.115456283092499, Final Batch Loss: 0.5325725078582764\n",
      "Epoch 4353, Loss: 2.024984657764435, Final Batch Loss: 0.5955601930618286\n",
      "Epoch 4354, Loss: 2.1230033338069916, Final Batch Loss: 0.5643472075462341\n",
      "Epoch 4355, Loss: 2.2519393265247345, Final Batch Loss: 0.8504438996315002\n",
      "Epoch 4356, Loss: 1.86246557533741, Final Batch Loss: 0.2336174100637436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4357, Loss: 1.683083862066269, Final Batch Loss: 0.18071520328521729\n",
      "Epoch 4358, Loss: 2.0652541518211365, Final Batch Loss: 0.5035237669944763\n",
      "Epoch 4359, Loss: 1.6908391565084457, Final Batch Loss: 0.22448857128620148\n",
      "Epoch 4360, Loss: 1.7025355994701385, Final Batch Loss: 0.22670695185661316\n",
      "Epoch 4361, Loss: 2.0094099044799805, Final Batch Loss: 0.3501642346382141\n",
      "Epoch 4362, Loss: 2.4521319568157196, Final Batch Loss: 0.8311699032783508\n",
      "Epoch 4363, Loss: 1.6692189872264862, Final Batch Loss: 0.1570357382297516\n",
      "Epoch 4364, Loss: 1.8303762376308441, Final Batch Loss: 0.42989179491996765\n",
      "Epoch 4365, Loss: 1.8282670080661774, Final Batch Loss: 0.3802497684955597\n",
      "Epoch 4366, Loss: 2.0361516177654266, Final Batch Loss: 0.5859071016311646\n",
      "Epoch 4367, Loss: 1.623118832707405, Final Batch Loss: 0.20944182574748993\n",
      "Epoch 4368, Loss: 1.699746534228325, Final Batch Loss: 0.12566496431827545\n",
      "Epoch 4369, Loss: 1.742190182209015, Final Batch Loss: 0.28327327966690063\n",
      "Epoch 4370, Loss: 1.7894280850887299, Final Batch Loss: 0.3738915026187897\n",
      "Epoch 4371, Loss: 1.634577214717865, Final Batch Loss: 0.2626599371433258\n",
      "Epoch 4372, Loss: 1.8505843877792358, Final Batch Loss: 0.4273935854434967\n",
      "Epoch 4373, Loss: 2.1791125535964966, Final Batch Loss: 0.7843713760375977\n",
      "Epoch 4374, Loss: 2.1264115273952484, Final Batch Loss: 0.6267577409744263\n",
      "Epoch 4375, Loss: 2.1786056756973267, Final Batch Loss: 0.44987398386001587\n",
      "Epoch 4376, Loss: 1.7291172593832016, Final Batch Loss: 0.06613694131374359\n",
      "Epoch 4377, Loss: 1.7397947162389755, Final Batch Loss: 0.16804073750972748\n",
      "Epoch 4378, Loss: 2.055402934551239, Final Batch Loss: 0.5929772257804871\n",
      "Epoch 4379, Loss: 1.674467772245407, Final Batch Loss: 0.1711811125278473\n",
      "Epoch 4380, Loss: 1.9086744785308838, Final Batch Loss: 0.4146896302700043\n",
      "Epoch 4381, Loss: 1.8296168744564056, Final Batch Loss: 0.3824995458126068\n",
      "Epoch 4382, Loss: 1.5816825032234192, Final Batch Loss: 0.19537687301635742\n",
      "Epoch 4383, Loss: 1.8324274122714996, Final Batch Loss: 0.29939916729927063\n",
      "Epoch 4384, Loss: 2.1251706779003143, Final Batch Loss: 0.5644151568412781\n",
      "Epoch 4385, Loss: 1.619549199938774, Final Batch Loss: 0.16951961815357208\n",
      "Epoch 4386, Loss: 2.0148597061634064, Final Batch Loss: 0.49927327036857605\n",
      "Epoch 4387, Loss: 2.0878346860408783, Final Batch Loss: 0.5393930673599243\n",
      "Epoch 4388, Loss: 1.5812848508358002, Final Batch Loss: 0.16428151726722717\n",
      "Epoch 4389, Loss: 2.271832764148712, Final Batch Loss: 0.7098086476325989\n",
      "Epoch 4390, Loss: 1.8331507742404938, Final Batch Loss: 0.3432743549346924\n",
      "Epoch 4391, Loss: 1.8020108342170715, Final Batch Loss: 0.3625463843345642\n",
      "Epoch 4392, Loss: 1.6274800896644592, Final Batch Loss: 0.1973646879196167\n",
      "Epoch 4393, Loss: 1.8798888027668, Final Batch Loss: 0.44710850715637207\n",
      "Epoch 4394, Loss: 2.15801402926445, Final Batch Loss: 0.61712646484375\n",
      "Epoch 4395, Loss: 1.7678618729114532, Final Batch Loss: 0.31647035479545593\n",
      "Epoch 4396, Loss: 1.8764120638370514, Final Batch Loss: 0.49531474709510803\n",
      "Epoch 4397, Loss: 1.8026870787143707, Final Batch Loss: 0.2597232460975647\n",
      "Epoch 4398, Loss: 1.9219782948493958, Final Batch Loss: 0.47056347131729126\n",
      "Epoch 4399, Loss: 1.5566701889038086, Final Batch Loss: 0.14215359091758728\n",
      "Epoch 4400, Loss: 2.029293864965439, Final Batch Loss: 0.6190584897994995\n",
      "Epoch 4401, Loss: 1.8173468112945557, Final Batch Loss: 0.281460702419281\n",
      "Epoch 4402, Loss: 1.8601818978786469, Final Batch Loss: 0.32316190004348755\n",
      "Epoch 4403, Loss: 1.6552777886390686, Final Batch Loss: 0.3062696158885956\n",
      "Epoch 4404, Loss: 1.965570092201233, Final Batch Loss: 0.392791748046875\n",
      "Epoch 4405, Loss: 1.5521365851163864, Final Batch Loss: 0.202771857380867\n",
      "Epoch 4406, Loss: 1.9310725331306458, Final Batch Loss: 0.4542121887207031\n",
      "Epoch 4407, Loss: 1.8115170300006866, Final Batch Loss: 0.29612448811531067\n",
      "Epoch 4408, Loss: 1.6744546592235565, Final Batch Loss: 0.24493661522865295\n",
      "Epoch 4409, Loss: 1.9981158375740051, Final Batch Loss: 0.5443914532661438\n",
      "Epoch 4410, Loss: 1.560054488480091, Final Batch Loss: 0.07985324412584305\n",
      "Epoch 4411, Loss: 1.9092280268669128, Final Batch Loss: 0.4215773046016693\n",
      "Epoch 4412, Loss: 1.6811943054199219, Final Batch Loss: 0.27993592619895935\n",
      "Epoch 4413, Loss: 2.0977879464626312, Final Batch Loss: 0.6184307932853699\n",
      "Epoch 4414, Loss: 2.0544124841690063, Final Batch Loss: 0.5194779634475708\n",
      "Epoch 4415, Loss: 1.8220346868038177, Final Batch Loss: 0.3584462106227875\n",
      "Epoch 4416, Loss: 2.106542468070984, Final Batch Loss: 0.7114133238792419\n",
      "Epoch 4417, Loss: 1.8502109348773956, Final Batch Loss: 0.39550432562828064\n",
      "Epoch 4418, Loss: 1.841273009777069, Final Batch Loss: 0.4039178192615509\n",
      "Epoch 4419, Loss: 1.9843007922172546, Final Batch Loss: 0.5470179319381714\n",
      "Epoch 4420, Loss: 1.737338364124298, Final Batch Loss: 0.3055552840232849\n",
      "Epoch 4421, Loss: 1.7532312721014023, Final Batch Loss: 0.19558705389499664\n",
      "Epoch 4422, Loss: 1.8830186128616333, Final Batch Loss: 0.38037747144699097\n",
      "Epoch 4423, Loss: 1.8696761429309845, Final Batch Loss: 0.48192182183265686\n",
      "Epoch 4424, Loss: 1.6852467358112335, Final Batch Loss: 0.3525870740413666\n",
      "Epoch 4425, Loss: 1.7265600711107254, Final Batch Loss: 0.1658337265253067\n",
      "Epoch 4426, Loss: 1.7445365488529205, Final Batch Loss: 0.3435963988304138\n",
      "Epoch 4427, Loss: 1.525817260146141, Final Batch Loss: 0.21079657971858978\n",
      "Epoch 4428, Loss: 1.5864023119211197, Final Batch Loss: 0.10604901611804962\n",
      "Epoch 4429, Loss: 1.6584595292806625, Final Batch Loss: 0.13384361565113068\n",
      "Epoch 4430, Loss: 1.9089207351207733, Final Batch Loss: 0.4356622099876404\n",
      "Epoch 4431, Loss: 1.8238673210144043, Final Batch Loss: 0.431270569562912\n",
      "Epoch 4432, Loss: 1.9813889861106873, Final Batch Loss: 0.45234259963035583\n",
      "Epoch 4433, Loss: 1.6705740839242935, Final Batch Loss: 0.21807079017162323\n",
      "Epoch 4434, Loss: 2.087183117866516, Final Batch Loss: 0.5155618786811829\n",
      "Epoch 4435, Loss: 1.7354229092597961, Final Batch Loss: 0.16677305102348328\n",
      "Epoch 4436, Loss: 1.67158842086792, Final Batch Loss: 0.2783272862434387\n",
      "Epoch 4437, Loss: 1.8963612914085388, Final Batch Loss: 0.41511955857276917\n",
      "Epoch 4438, Loss: 1.8177285194396973, Final Batch Loss: 0.33979159593582153\n",
      "Epoch 4439, Loss: 1.6813644170761108, Final Batch Loss: 0.27917033433914185\n",
      "Epoch 4440, Loss: 1.6124643385410309, Final Batch Loss: 0.13834604620933533\n",
      "Epoch 4441, Loss: 1.8500171303749084, Final Batch Loss: 0.3205999433994293\n",
      "Epoch 4442, Loss: 1.8029450178146362, Final Batch Loss: 0.3631964325904846\n",
      "Epoch 4443, Loss: 1.7781489193439484, Final Batch Loss: 0.3543078601360321\n",
      "Epoch 4444, Loss: 1.650851160287857, Final Batch Loss: 0.28316548466682434\n",
      "Epoch 4445, Loss: 1.7967265844345093, Final Batch Loss: 0.2981990873813629\n",
      "Epoch 4446, Loss: 1.5338981673121452, Final Batch Loss: 0.09079428762197495\n",
      "Epoch 4447, Loss: 1.9765461385250092, Final Batch Loss: 0.39499273896217346\n",
      "Epoch 4448, Loss: 2.217497169971466, Final Batch Loss: 0.5725431442260742\n",
      "Epoch 4449, Loss: 1.7569681107997894, Final Batch Loss: 0.36507663130760193\n",
      "Epoch 4450, Loss: 1.6578707993030548, Final Batch Loss: 0.309734046459198\n",
      "Epoch 4451, Loss: 2.3983258605003357, Final Batch Loss: 0.8306195139884949\n",
      "Epoch 4452, Loss: 2.6696327924728394, Final Batch Loss: 1.0864695310592651\n",
      "Epoch 4453, Loss: 2.407807171344757, Final Batch Loss: 0.8705564737319946\n",
      "Epoch 4454, Loss: 2.009563535451889, Final Batch Loss: 0.3807084560394287\n",
      "Epoch 4455, Loss: 1.991089403629303, Final Batch Loss: 0.275154709815979\n",
      "Epoch 4456, Loss: 2.0984761118888855, Final Batch Loss: 0.5336447954177856\n",
      "Epoch 4457, Loss: 1.7083643972873688, Final Batch Loss: 0.1477598249912262\n",
      "Epoch 4458, Loss: 1.975600391626358, Final Batch Loss: 0.40368589758872986\n",
      "Epoch 4459, Loss: 1.8583748191595078, Final Batch Loss: 0.18982096016407013\n",
      "Epoch 4460, Loss: 1.9333249032497406, Final Batch Loss: 0.4856241047382355\n",
      "Epoch 4461, Loss: 1.7054395824670792, Final Batch Loss: 0.22156383097171783\n",
      "Epoch 4462, Loss: 1.6023721247911453, Final Batch Loss: 0.16116885840892792\n",
      "Epoch 4463, Loss: 2.2716874182224274, Final Batch Loss: 0.8684334754943848\n",
      "Epoch 4464, Loss: 1.8966544270515442, Final Batch Loss: 0.35901662707328796\n",
      "Epoch 4465, Loss: 1.818381428718567, Final Batch Loss: 0.338352769613266\n",
      "Epoch 4466, Loss: 1.60653717815876, Final Batch Loss: 0.11167292296886444\n",
      "Epoch 4467, Loss: 2.432209759950638, Final Batch Loss: 0.9163640737533569\n",
      "Epoch 4468, Loss: 1.7834046483039856, Final Batch Loss: 0.4255664050579071\n",
      "Epoch 4469, Loss: 1.6243007630109787, Final Batch Loss: 0.2057722955942154\n",
      "Epoch 4470, Loss: 1.6943786144256592, Final Batch Loss: 0.3060334324836731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4471, Loss: 2.0072669088840485, Final Batch Loss: 0.5371910333633423\n",
      "Epoch 4472, Loss: 1.802269697189331, Final Batch Loss: 0.28190484642982483\n",
      "Epoch 4473, Loss: 1.736202821135521, Final Batch Loss: 0.2262272983789444\n",
      "Epoch 4474, Loss: 2.230681836605072, Final Batch Loss: 0.8421255946159363\n",
      "Epoch 4475, Loss: 1.927001416683197, Final Batch Loss: 0.5138484835624695\n",
      "Epoch 4476, Loss: 1.8415015637874603, Final Batch Loss: 0.5232244729995728\n",
      "Epoch 4477, Loss: 1.8081265091896057, Final Batch Loss: 0.24155092239379883\n",
      "Epoch 4478, Loss: 1.7929177582263947, Final Batch Loss: 0.3464507460594177\n",
      "Epoch 4479, Loss: 1.811498373746872, Final Batch Loss: 0.37493258714675903\n",
      "Epoch 4480, Loss: 1.9138669967651367, Final Batch Loss: 0.37644606828689575\n",
      "Epoch 4481, Loss: 1.5667411237955093, Final Batch Loss: 0.1747061163187027\n",
      "Epoch 4482, Loss: 1.8649370968341827, Final Batch Loss: 0.3885219395160675\n",
      "Epoch 4483, Loss: 1.7194986045360565, Final Batch Loss: 0.2867826819419861\n",
      "Epoch 4484, Loss: 1.9896072447299957, Final Batch Loss: 0.43436503410339355\n",
      "Epoch 4485, Loss: 1.5100350230932236, Final Batch Loss: 0.07064662873744965\n",
      "Epoch 4486, Loss: 1.8645036220550537, Final Batch Loss: 0.3189997673034668\n",
      "Epoch 4487, Loss: 2.238981783390045, Final Batch Loss: 0.730669379234314\n",
      "Epoch 4488, Loss: 1.8295849561691284, Final Batch Loss: 0.38623952865600586\n",
      "Epoch 4489, Loss: 1.7558919191360474, Final Batch Loss: 0.30388039350509644\n",
      "Epoch 4490, Loss: 2.0225741267204285, Final Batch Loss: 0.44398218393325806\n",
      "Epoch 4491, Loss: 1.8196531236171722, Final Batch Loss: 0.3220398426055908\n",
      "Epoch 4492, Loss: 1.749205693602562, Final Batch Loss: 0.21768318116664886\n",
      "Epoch 4493, Loss: 1.8111195862293243, Final Batch Loss: 0.3858312964439392\n",
      "Epoch 4494, Loss: 1.78896164894104, Final Batch Loss: 0.24216818809509277\n",
      "Epoch 4495, Loss: 1.8248711824417114, Final Batch Loss: 0.30925899744033813\n",
      "Epoch 4496, Loss: 1.7012117207050323, Final Batch Loss: 0.3844360411167145\n",
      "Epoch 4497, Loss: 1.6025795936584473, Final Batch Loss: 0.1613452434539795\n",
      "Epoch 4498, Loss: 1.9141237139701843, Final Batch Loss: 0.5436877608299255\n",
      "Epoch 4499, Loss: 1.7395467162132263, Final Batch Loss: 0.2699742913246155\n",
      "Epoch 4500, Loss: 1.492310807108879, Final Batch Loss: 0.10100401937961578\n",
      "Epoch 4501, Loss: 1.6901169419288635, Final Batch Loss: 0.16126474738121033\n",
      "Epoch 4502, Loss: 1.7072911858558655, Final Batch Loss: 0.25787895917892456\n",
      "Epoch 4503, Loss: 1.8603639602661133, Final Batch Loss: 0.32852962613105774\n",
      "Epoch 4504, Loss: 1.899658888578415, Final Batch Loss: 0.29158684611320496\n",
      "Epoch 4505, Loss: 1.7772543728351593, Final Batch Loss: 0.4021994471549988\n",
      "Epoch 4506, Loss: 1.665077269077301, Final Batch Loss: 0.15612420439720154\n",
      "Epoch 4507, Loss: 1.6958355456590652, Final Batch Loss: 0.24146367609500885\n",
      "Epoch 4508, Loss: 1.6141841262578964, Final Batch Loss: 0.19477705657482147\n",
      "Epoch 4509, Loss: 1.383596170693636, Final Batch Loss: 0.04806001856923103\n",
      "Epoch 4510, Loss: 1.8330298960208893, Final Batch Loss: 0.23947608470916748\n",
      "Epoch 4511, Loss: 1.6040286719799042, Final Batch Loss: 0.1716078519821167\n",
      "Epoch 4512, Loss: 1.7585548758506775, Final Batch Loss: 0.3090720474720001\n",
      "Epoch 4513, Loss: 1.8189824521541595, Final Batch Loss: 0.35150763392448425\n",
      "Epoch 4514, Loss: 3.0279101133346558, Final Batch Loss: 1.4840260744094849\n",
      "Epoch 4515, Loss: 1.7681107819080353, Final Batch Loss: 0.4530492126941681\n",
      "Epoch 4516, Loss: 1.834283471107483, Final Batch Loss: 0.4845055043697357\n",
      "Epoch 4517, Loss: 1.6949228346347809, Final Batch Loss: 0.2741851806640625\n",
      "Epoch 4518, Loss: 1.9952223002910614, Final Batch Loss: 0.50703364610672\n",
      "Epoch 4519, Loss: 1.6844191253185272, Final Batch Loss: 0.14874505996704102\n",
      "Epoch 4520, Loss: 1.81699737906456, Final Batch Loss: 0.19374540448188782\n",
      "Epoch 4521, Loss: 1.541032001376152, Final Batch Loss: 0.1059303730726242\n",
      "Epoch 4522, Loss: 2.5327514111995697, Final Batch Loss: 0.9932872653007507\n",
      "Epoch 4523, Loss: 1.6853724420070648, Final Batch Loss: 0.2337276041507721\n",
      "Epoch 4524, Loss: 2.1219842433929443, Final Batch Loss: 0.6517219543457031\n",
      "Epoch 4525, Loss: 1.7659219205379486, Final Batch Loss: 0.28922733664512634\n",
      "Epoch 4526, Loss: 1.6857747584581375, Final Batch Loss: 0.21664871275424957\n",
      "Epoch 4527, Loss: 1.982188194990158, Final Batch Loss: 0.2965080142021179\n",
      "Epoch 4528, Loss: 1.9532418549060822, Final Batch Loss: 0.545329749584198\n",
      "Epoch 4529, Loss: 2.121260344982147, Final Batch Loss: 0.5347365140914917\n",
      "Epoch 4530, Loss: 1.65064737200737, Final Batch Loss: 0.22536614537239075\n",
      "Epoch 4531, Loss: 1.7497937828302383, Final Batch Loss: 0.4469350278377533\n",
      "Epoch 4532, Loss: 1.5639365762472153, Final Batch Loss: 0.20711921155452728\n",
      "Epoch 4533, Loss: 1.6896029710769653, Final Batch Loss: 0.31322842836380005\n",
      "Epoch 4534, Loss: 2.2107117772102356, Final Batch Loss: 0.7387816309928894\n",
      "Epoch 4535, Loss: 2.117144763469696, Final Batch Loss: 0.4112512469291687\n",
      "Epoch 4536, Loss: 1.7355882972478867, Final Batch Loss: 0.026515260338783264\n",
      "Epoch 4537, Loss: 1.5944141522049904, Final Batch Loss: 0.035763926804065704\n",
      "Epoch 4538, Loss: 1.8276439011096954, Final Batch Loss: 0.3853277266025543\n",
      "Epoch 4539, Loss: 1.5801546424627304, Final Batch Loss: 0.1971629410982132\n",
      "Epoch 4540, Loss: 1.7411348819732666, Final Batch Loss: 0.34849947690963745\n",
      "Epoch 4541, Loss: 2.1082866191864014, Final Batch Loss: 0.45410090684890747\n",
      "Epoch 4542, Loss: 1.6216453611850739, Final Batch Loss: 0.2044220268726349\n",
      "Epoch 4543, Loss: 1.743798851966858, Final Batch Loss: 0.27615708112716675\n",
      "Epoch 4544, Loss: 1.721694141626358, Final Batch Loss: 0.27573731541633606\n",
      "Epoch 4545, Loss: 1.7127957940101624, Final Batch Loss: 0.2719312012195587\n",
      "Epoch 4546, Loss: 1.4896598905324936, Final Batch Loss: 0.16290225088596344\n",
      "Epoch 4547, Loss: 1.94298854470253, Final Batch Loss: 0.45444759726524353\n",
      "Epoch 4548, Loss: 1.7659505009651184, Final Batch Loss: 0.2689172327518463\n",
      "Epoch 4549, Loss: 1.8975400030612946, Final Batch Loss: 0.2599060833454132\n",
      "Epoch 4550, Loss: 2.092129111289978, Final Batch Loss: 0.5083527565002441\n",
      "Epoch 4551, Loss: 1.7753007113933563, Final Batch Loss: 0.35402968525886536\n",
      "Epoch 4552, Loss: 1.862924873828888, Final Batch Loss: 0.47392794489860535\n",
      "Epoch 4553, Loss: 1.8452955186367035, Final Batch Loss: 0.47665590047836304\n",
      "Epoch 4554, Loss: 1.924855500459671, Final Batch Loss: 0.3118310272693634\n",
      "Epoch 4555, Loss: 1.6412551701068878, Final Batch Loss: 0.12795859575271606\n",
      "Epoch 4556, Loss: 1.783813938498497, Final Batch Loss: 0.2153172343969345\n",
      "Epoch 4557, Loss: 1.6327408403158188, Final Batch Loss: 0.13680677115917206\n",
      "Epoch 4558, Loss: 1.7325466573238373, Final Batch Loss: 0.26357534527778625\n",
      "Epoch 4559, Loss: 1.5790618509054184, Final Batch Loss: 0.13122515380382538\n",
      "Epoch 4560, Loss: 1.6571893244981766, Final Batch Loss: 0.21715973317623138\n",
      "Epoch 4561, Loss: 1.5467259138822556, Final Batch Loss: 0.15697012841701508\n",
      "Epoch 4562, Loss: 2.017434984445572, Final Batch Loss: 0.6156935095787048\n",
      "Epoch 4563, Loss: 1.5587112754583359, Final Batch Loss: 0.08111728727817535\n",
      "Epoch 4564, Loss: 1.6813553869724274, Final Batch Loss: 0.3250143229961395\n",
      "Epoch 4565, Loss: 1.7666554152965546, Final Batch Loss: 0.40735676884651184\n",
      "Epoch 4566, Loss: 1.6381212621927261, Final Batch Loss: 0.1172909289598465\n",
      "Epoch 4567, Loss: 2.0503097474575043, Final Batch Loss: 0.6701931357383728\n",
      "Epoch 4568, Loss: 1.78813898563385, Final Batch Loss: 0.45084723830223083\n",
      "Epoch 4569, Loss: 2.251397430896759, Final Batch Loss: 0.6680981516838074\n",
      "Epoch 4570, Loss: 2.13058802485466, Final Batch Loss: 0.7641805410385132\n",
      "Epoch 4571, Loss: 1.8403394371271133, Final Batch Loss: 0.2076118439435959\n",
      "Epoch 4572, Loss: 1.866266131401062, Final Batch Loss: 0.38207393884658813\n",
      "Epoch 4573, Loss: 2.9889756739139557, Final Batch Loss: 1.5987082719802856\n",
      "Epoch 4574, Loss: 1.996458113193512, Final Batch Loss: 0.3028208315372467\n",
      "Epoch 4575, Loss: 1.7524834424257278, Final Batch Loss: 0.1803482621908188\n",
      "Epoch 4576, Loss: 1.7238734513521194, Final Batch Loss: 0.24535922706127167\n",
      "Epoch 4577, Loss: 2.2935194969177246, Final Batch Loss: 0.7680686116218567\n",
      "Epoch 4578, Loss: 2.007511466741562, Final Batch Loss: 0.36282458901405334\n",
      "Epoch 4579, Loss: 2.1007891595363617, Final Batch Loss: 0.5934999585151672\n",
      "Epoch 4580, Loss: 1.962643176317215, Final Batch Loss: 0.49208492040634155\n",
      "Epoch 4581, Loss: 1.897493451833725, Final Batch Loss: 0.2564818561077118\n",
      "Epoch 4582, Loss: 1.9394260942935944, Final Batch Loss: 0.2990688681602478\n",
      "Epoch 4583, Loss: 2.2014708817005157, Final Batch Loss: 0.5671035051345825\n",
      "Epoch 4584, Loss: 1.823083907365799, Final Batch Loss: 0.34927937388420105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4585, Loss: 1.8086536973714828, Final Batch Loss: 0.1691276580095291\n",
      "Epoch 4586, Loss: 2.0426230132579803, Final Batch Loss: 0.6908171772956848\n",
      "Epoch 4587, Loss: 1.6277861595153809, Final Batch Loss: 0.20642808079719543\n",
      "Epoch 4588, Loss: 3.304761618375778, Final Batch Loss: 1.9442843198776245\n",
      "Epoch 4589, Loss: 2.0546587109565735, Final Batch Loss: 0.5081985592842102\n",
      "Epoch 4590, Loss: 1.690407246351242, Final Batch Loss: 0.19385871291160583\n",
      "Epoch 4591, Loss: 1.907818228006363, Final Batch Loss: 0.39497581124305725\n",
      "Epoch 4592, Loss: 1.9394323527812958, Final Batch Loss: 0.32486605644226074\n",
      "Epoch 4593, Loss: 1.6659985780715942, Final Batch Loss: 0.16569551825523376\n",
      "Epoch 4594, Loss: 2.243080794811249, Final Batch Loss: 0.6687192916870117\n",
      "Epoch 4595, Loss: 1.983955293893814, Final Batch Loss: 0.36170974373817444\n",
      "Epoch 4596, Loss: 1.6820991337299347, Final Batch Loss: 0.18110647797584534\n",
      "Epoch 4597, Loss: 1.5950107425451279, Final Batch Loss: 0.11995793879032135\n",
      "Epoch 4598, Loss: 1.679611086845398, Final Batch Loss: 0.17363834381103516\n",
      "Epoch 4599, Loss: 1.5144729912281036, Final Batch Loss: 0.058303505182266235\n",
      "Epoch 4600, Loss: 1.7401124238967896, Final Batch Loss: 0.2966785430908203\n",
      "Epoch 4601, Loss: 1.9274353086948395, Final Batch Loss: 0.3204391598701477\n",
      "Epoch 4602, Loss: 1.5133920460939407, Final Batch Loss: 0.13951162993907928\n",
      "Epoch 4603, Loss: 1.613242745399475, Final Batch Loss: 0.290001779794693\n",
      "Epoch 4604, Loss: 1.9411988258361816, Final Batch Loss: 0.5990864634513855\n",
      "Epoch 4605, Loss: 1.6215684413909912, Final Batch Loss: 0.2444307804107666\n",
      "Epoch 4606, Loss: 1.8822238445281982, Final Batch Loss: 0.4217517077922821\n",
      "Epoch 4607, Loss: 1.6546338945627213, Final Batch Loss: 0.20220153033733368\n",
      "Epoch 4608, Loss: 1.6672467738389969, Final Batch Loss: 0.17623712122440338\n",
      "Epoch 4609, Loss: 1.5583045333623886, Final Batch Loss: 0.129200741648674\n",
      "Epoch 4610, Loss: 1.6213741153478622, Final Batch Loss: 0.14672286808490753\n",
      "Epoch 4611, Loss: 1.8374705016613007, Final Batch Loss: 0.14070746302604675\n",
      "Epoch 4612, Loss: 1.5604973286390305, Final Batch Loss: 0.1661870926618576\n",
      "Epoch 4613, Loss: 2.456457644701004, Final Batch Loss: 1.1604315042495728\n",
      "Epoch 4614, Loss: 2.1385189592838287, Final Batch Loss: 0.7798457145690918\n",
      "Epoch 4615, Loss: 1.5558989644050598, Final Batch Loss: 0.2255232334136963\n",
      "Epoch 4616, Loss: 1.8544527143239975, Final Batch Loss: 0.24597103893756866\n",
      "Epoch 4617, Loss: 2.0285680294036865, Final Batch Loss: 0.46500614285469055\n",
      "Epoch 4618, Loss: 2.2755064964294434, Final Batch Loss: 0.7389326095581055\n",
      "Epoch 4619, Loss: 2.409781128168106, Final Batch Loss: 1.007066011428833\n",
      "Epoch 4620, Loss: 1.978817105293274, Final Batch Loss: 0.6593910455703735\n",
      "Epoch 4621, Loss: 1.7982060611248016, Final Batch Loss: 0.303609699010849\n",
      "Epoch 4622, Loss: 2.043530762195587, Final Batch Loss: 0.7868277430534363\n",
      "Epoch 4623, Loss: 1.853337824344635, Final Batch Loss: 0.2630137801170349\n",
      "Epoch 4624, Loss: 2.1441502273082733, Final Batch Loss: 0.6675462126731873\n",
      "Epoch 4625, Loss: 1.6474106013774872, Final Batch Loss: 0.22052904963493347\n",
      "Epoch 4626, Loss: 1.6114695519208908, Final Batch Loss: 0.09685654938220978\n",
      "Epoch 4627, Loss: 1.707210898399353, Final Batch Loss: 0.4010724723339081\n",
      "Epoch 4628, Loss: 1.652324914932251, Final Batch Loss: 0.23714888095855713\n",
      "Epoch 4629, Loss: 2.339635819196701, Final Batch Loss: 0.8027086853981018\n",
      "Epoch 4630, Loss: 1.7961210012435913, Final Batch Loss: 0.3309250473976135\n",
      "Epoch 4631, Loss: 1.6835921108722687, Final Batch Loss: 0.2674148678779602\n",
      "Epoch 4632, Loss: 1.7868618816137314, Final Batch Loss: 0.17778263986110687\n",
      "Epoch 4633, Loss: 1.6026426553726196, Final Batch Loss: 0.31291744112968445\n",
      "Epoch 4634, Loss: 1.5529462397098541, Final Batch Loss: 0.16714122891426086\n",
      "Epoch 4635, Loss: 1.751802459359169, Final Batch Loss: 0.2020357996225357\n",
      "Epoch 4636, Loss: 2.14735546708107, Final Batch Loss: 0.6365135312080383\n",
      "Epoch 4637, Loss: 1.606741264462471, Final Batch Loss: 0.17602138221263885\n",
      "Epoch 4638, Loss: 1.5094053596258163, Final Batch Loss: 0.1617109626531601\n",
      "Epoch 4639, Loss: 1.7702464163303375, Final Batch Loss: 0.31486859917640686\n",
      "Epoch 4640, Loss: 1.971110224723816, Final Batch Loss: 0.5755599737167358\n",
      "Epoch 4641, Loss: 1.7251207828521729, Final Batch Loss: 0.29705220460891724\n",
      "Epoch 4642, Loss: 1.8271717727184296, Final Batch Loss: 0.39296093583106995\n",
      "Epoch 4643, Loss: 2.1325549483299255, Final Batch Loss: 0.5549995303153992\n",
      "Epoch 4644, Loss: 2.106319785118103, Final Batch Loss: 0.6429792046546936\n",
      "Epoch 4645, Loss: 1.557808294892311, Final Batch Loss: 0.12671007215976715\n",
      "Epoch 4646, Loss: 1.7450146675109863, Final Batch Loss: 0.31185516715049744\n",
      "Epoch 4647, Loss: 1.9700045585632324, Final Batch Loss: 0.6090797781944275\n",
      "Epoch 4648, Loss: 1.6276525929570198, Final Batch Loss: 0.09055650979280472\n",
      "Epoch 4649, Loss: 1.8949734270572662, Final Batch Loss: 0.43993431329727173\n",
      "Epoch 4650, Loss: 1.8756917715072632, Final Batch Loss: 0.43599897623062134\n",
      "Epoch 4651, Loss: 1.7727690935134888, Final Batch Loss: 0.4671526253223419\n",
      "Epoch 4652, Loss: 1.9007206559181213, Final Batch Loss: 0.37270885705947876\n",
      "Epoch 4653, Loss: 1.7618330717086792, Final Batch Loss: 0.36911171674728394\n",
      "Epoch 4654, Loss: 2.105779230594635, Final Batch Loss: 0.6715624928474426\n",
      "Epoch 4655, Loss: 1.745028793811798, Final Batch Loss: 0.35103440284729004\n",
      "Epoch 4656, Loss: 1.7578091323375702, Final Batch Loss: 0.28417274355888367\n",
      "Epoch 4657, Loss: 1.6200259327888489, Final Batch Loss: 0.25401702523231506\n",
      "Epoch 4658, Loss: 1.7528079599142075, Final Batch Loss: 0.18608905375003815\n",
      "Epoch 4659, Loss: 1.670812726020813, Final Batch Loss: 0.2708968222141266\n",
      "Epoch 4660, Loss: 1.7991344332695007, Final Batch Loss: 0.4352523386478424\n",
      "Epoch 4661, Loss: 2.1872973144054413, Final Batch Loss: 0.7045920491218567\n",
      "Epoch 4662, Loss: 1.9608984291553497, Final Batch Loss: 0.6560763716697693\n",
      "Epoch 4663, Loss: 2.0268160104751587, Final Batch Loss: 0.5163311958312988\n",
      "Epoch 4664, Loss: 2.0238698422908783, Final Batch Loss: 0.4523024260997772\n",
      "Epoch 4665, Loss: 1.8427810966968536, Final Batch Loss: 0.26769959926605225\n",
      "Epoch 4666, Loss: 1.643997684121132, Final Batch Loss: 0.1030919998884201\n",
      "Epoch 4667, Loss: 2.141777217388153, Final Batch Loss: 0.5183202028274536\n",
      "Epoch 4668, Loss: 2.0772025287151337, Final Batch Loss: 0.6238507628440857\n",
      "Epoch 4669, Loss: 1.6722931414842606, Final Batch Loss: 0.2004934400320053\n",
      "Epoch 4670, Loss: 1.6346138417720795, Final Batch Loss: 0.2733806073665619\n",
      "Epoch 4671, Loss: 1.7133951932191849, Final Batch Loss: 0.13909952342510223\n",
      "Epoch 4672, Loss: 1.6398297250270844, Final Batch Loss: 0.25352758169174194\n",
      "Epoch 4673, Loss: 1.6946755200624466, Final Batch Loss: 0.2113255113363266\n",
      "Epoch 4674, Loss: 1.834166020154953, Final Batch Loss: 0.24070122838020325\n",
      "Epoch 4675, Loss: 2.394112467765808, Final Batch Loss: 0.9539646506309509\n",
      "Epoch 4676, Loss: 2.1106881499290466, Final Batch Loss: 0.6742895245552063\n",
      "Epoch 4677, Loss: 1.6603559851646423, Final Batch Loss: 0.22737064957618713\n",
      "Epoch 4678, Loss: 1.5948405116796494, Final Batch Loss: 0.18873880803585052\n",
      "Epoch 4679, Loss: 1.834757536649704, Final Batch Loss: 0.4366591274738312\n",
      "Epoch 4680, Loss: 2.192540317773819, Final Batch Loss: 0.6566877365112305\n",
      "Epoch 4681, Loss: 1.6760911643505096, Final Batch Loss: 0.26760268211364746\n",
      "Epoch 4682, Loss: 1.7873197495937347, Final Batch Loss: 0.26798537373542786\n",
      "Epoch 4683, Loss: 1.6822768151760101, Final Batch Loss: 0.2301711142063141\n",
      "Epoch 4684, Loss: 1.7875890135765076, Final Batch Loss: 0.30188941955566406\n",
      "Epoch 4685, Loss: 1.62238210439682, Final Batch Loss: 0.2811010777950287\n",
      "Epoch 4686, Loss: 1.868867039680481, Final Batch Loss: 0.5057600736618042\n",
      "Epoch 4687, Loss: 2.058186948299408, Final Batch Loss: 0.5580024123191833\n",
      "Epoch 4688, Loss: 2.2087424099445343, Final Batch Loss: 0.6989492177963257\n",
      "Epoch 4689, Loss: 1.9055619835853577, Final Batch Loss: 0.41370925307273865\n",
      "Epoch 4690, Loss: 1.9296825528144836, Final Batch Loss: 0.43213680386543274\n",
      "Epoch 4691, Loss: 1.741122305393219, Final Batch Loss: 0.3082504868507385\n",
      "Epoch 4692, Loss: 1.6475321501493454, Final Batch Loss: 0.1925661712884903\n",
      "Epoch 4693, Loss: 1.924030601978302, Final Batch Loss: 0.5400000810623169\n",
      "Epoch 4694, Loss: 1.6613689959049225, Final Batch Loss: 0.1596963107585907\n",
      "Epoch 4695, Loss: 1.6163122206926346, Final Batch Loss: 0.2066679447889328\n",
      "Epoch 4696, Loss: 1.6618206053972244, Final Batch Loss: 0.2198552042245865\n",
      "Epoch 4697, Loss: 1.9970752000808716, Final Batch Loss: 0.3719426095485687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4698, Loss: 2.0592669546604156, Final Batch Loss: 0.4902910590171814\n",
      "Epoch 4699, Loss: 1.9255658090114594, Final Batch Loss: 0.46121975779533386\n",
      "Epoch 4700, Loss: 1.7837788760662079, Final Batch Loss: 0.39662209153175354\n",
      "Epoch 4701, Loss: 1.9129701554775238, Final Batch Loss: 0.3923199772834778\n",
      "Epoch 4702, Loss: 1.8276249468326569, Final Batch Loss: 0.4288693368434906\n",
      "Epoch 4703, Loss: 1.56390979886055, Final Batch Loss: 0.19626346230506897\n",
      "Epoch 4704, Loss: 1.674322485923767, Final Batch Loss: 0.22937703132629395\n",
      "Epoch 4705, Loss: 1.849617600440979, Final Batch Loss: 0.4534069001674652\n",
      "Epoch 4706, Loss: 1.839546650648117, Final Batch Loss: 0.28835350275039673\n",
      "Epoch 4707, Loss: 1.6667131781578064, Final Batch Loss: 0.2389216125011444\n",
      "Epoch 4708, Loss: 1.8638632595539093, Final Batch Loss: 0.46314093470573425\n",
      "Epoch 4709, Loss: 1.5765220671892166, Final Batch Loss: 0.22314240038394928\n",
      "Epoch 4710, Loss: 1.6296333819627762, Final Batch Loss: 0.09766407310962677\n",
      "Epoch 4711, Loss: 1.6880141198635101, Final Batch Loss: 0.38465365767478943\n",
      "Epoch 4712, Loss: 1.686193972826004, Final Batch Loss: 0.4329474866390228\n",
      "Epoch 4713, Loss: 1.9204281866550446, Final Batch Loss: 0.47142845392227173\n",
      "Epoch 4714, Loss: 1.435076717287302, Final Batch Loss: 0.03779429569840431\n",
      "Epoch 4715, Loss: 1.7024476677179337, Final Batch Loss: 0.14820928871631622\n",
      "Epoch 4716, Loss: 1.9308531284332275, Final Batch Loss: 0.4694446921348572\n",
      "Epoch 4717, Loss: 1.823123723268509, Final Batch Loss: 0.34714359045028687\n",
      "Epoch 4718, Loss: 1.8756213784217834, Final Batch Loss: 0.47335943579673767\n",
      "Epoch 4719, Loss: 1.868739366531372, Final Batch Loss: 0.30502399802207947\n",
      "Epoch 4720, Loss: 1.6879025399684906, Final Batch Loss: 0.10709601640701294\n",
      "Epoch 4721, Loss: 1.6734783202409744, Final Batch Loss: 0.12078256905078888\n",
      "Epoch 4722, Loss: 1.6900113672018051, Final Batch Loss: 0.08226536214351654\n",
      "Epoch 4723, Loss: 1.7992014437913895, Final Batch Loss: 0.1910160630941391\n",
      "Epoch 4724, Loss: 1.6514772176742554, Final Batch Loss: 0.15424764156341553\n",
      "Epoch 4725, Loss: 1.8998626172542572, Final Batch Loss: 0.41956469416618347\n",
      "Epoch 4726, Loss: 1.7209693044424057, Final Batch Loss: 0.24707268178462982\n",
      "Epoch 4727, Loss: 1.8229622542858124, Final Batch Loss: 0.3828813135623932\n",
      "Epoch 4728, Loss: 1.9394808113574982, Final Batch Loss: 0.4993502199649811\n",
      "Epoch 4729, Loss: 1.8420028686523438, Final Batch Loss: 0.4236586391925812\n",
      "Epoch 4730, Loss: 1.6949534118175507, Final Batch Loss: 0.14008855819702148\n",
      "Epoch 4731, Loss: 1.9674928486347198, Final Batch Loss: 0.36022982001304626\n",
      "Epoch 4732, Loss: 1.8382233083248138, Final Batch Loss: 0.42656755447387695\n",
      "Epoch 4733, Loss: 2.183261424303055, Final Batch Loss: 0.7903082966804504\n",
      "Epoch 4734, Loss: 2.093237578868866, Final Batch Loss: 0.5466892123222351\n",
      "Epoch 4735, Loss: 1.5768909752368927, Final Batch Loss: 0.1692904531955719\n",
      "Epoch 4736, Loss: 1.619020715355873, Final Batch Loss: 0.14499913156032562\n",
      "Epoch 4737, Loss: 1.8005448579788208, Final Batch Loss: 0.4107136130332947\n",
      "Epoch 4738, Loss: 1.6045226454734802, Final Batch Loss: 0.16485664248466492\n",
      "Epoch 4739, Loss: 1.6543052792549133, Final Batch Loss: 0.3448790907859802\n",
      "Epoch 4740, Loss: 1.6194747686386108, Final Batch Loss: 0.3119616210460663\n",
      "Epoch 4741, Loss: 1.732770025730133, Final Batch Loss: 0.3470776677131653\n",
      "Epoch 4742, Loss: 2.058327466249466, Final Batch Loss: 0.6220114827156067\n",
      "Epoch 4743, Loss: 1.865019828081131, Final Batch Loss: 0.32458847761154175\n",
      "Epoch 4744, Loss: 1.9862174093723297, Final Batch Loss: 0.424282044172287\n",
      "Epoch 4745, Loss: 1.9424904584884644, Final Batch Loss: 0.5207028985023499\n",
      "Epoch 4746, Loss: 1.6846959590911865, Final Batch Loss: 0.302460253238678\n",
      "Epoch 4747, Loss: 1.6844044625759125, Final Batch Loss: 0.3109208047389984\n",
      "Epoch 4748, Loss: 1.9670630991458893, Final Batch Loss: 0.5965846180915833\n",
      "Epoch 4749, Loss: 1.6097871512174606, Final Batch Loss: 0.204927459359169\n",
      "Epoch 4750, Loss: 2.146738648414612, Final Batch Loss: 0.5242624282836914\n",
      "Epoch 4751, Loss: 1.9953139424324036, Final Batch Loss: 0.5639997124671936\n",
      "Epoch 4752, Loss: 2.3329928517341614, Final Batch Loss: 0.8672245740890503\n",
      "Epoch 4753, Loss: 1.5325380191206932, Final Batch Loss: 0.10898470133543015\n",
      "Epoch 4754, Loss: 1.9315052926540375, Final Batch Loss: 0.3099246323108673\n",
      "Epoch 4755, Loss: 1.6465037167072296, Final Batch Loss: 0.2535676062107086\n",
      "Epoch 4756, Loss: 1.7117238640785217, Final Batch Loss: 0.3916684091091156\n",
      "Epoch 4757, Loss: 1.5057571902871132, Final Batch Loss: 0.08846605569124222\n",
      "Epoch 4758, Loss: 1.39527453109622, Final Batch Loss: 0.05875144526362419\n",
      "Epoch 4759, Loss: 2.1101783514022827, Final Batch Loss: 0.7245808839797974\n",
      "Epoch 4760, Loss: 1.7268614172935486, Final Batch Loss: 0.32145828008651733\n",
      "Epoch 4761, Loss: 2.0131282210350037, Final Batch Loss: 0.5051266551017761\n",
      "Epoch 4762, Loss: 1.8103280663490295, Final Batch Loss: 0.46797746419906616\n",
      "Epoch 4763, Loss: 1.6552006602287292, Final Batch Loss: 0.3880322277545929\n",
      "Epoch 4764, Loss: 1.4800837188959122, Final Batch Loss: 0.1640055924654007\n",
      "Epoch 4765, Loss: 1.6460039615631104, Final Batch Loss: 0.24370694160461426\n",
      "Epoch 4766, Loss: 1.4237031564116478, Final Batch Loss: 0.05106201022863388\n",
      "Epoch 4767, Loss: 1.5586636662483215, Final Batch Loss: 0.28889888525009155\n",
      "Epoch 4768, Loss: 1.4578705579042435, Final Batch Loss: 0.16625110805034637\n",
      "Epoch 4769, Loss: 1.4438600689172745, Final Batch Loss: 0.06585951149463654\n",
      "Epoch 4770, Loss: 2.0867497324943542, Final Batch Loss: 0.652099072933197\n",
      "Epoch 4771, Loss: 1.6822088956832886, Final Batch Loss: 0.3430745303630829\n",
      "Epoch 4772, Loss: 1.669929414987564, Final Batch Loss: 0.2699471116065979\n",
      "Epoch 4773, Loss: 1.4704290889203548, Final Batch Loss: 0.05488934740424156\n",
      "Epoch 4774, Loss: 1.42953310161829, Final Batch Loss: 0.11789662390947342\n",
      "Epoch 4775, Loss: 1.8095211684703827, Final Batch Loss: 0.28192242980003357\n",
      "Epoch 4776, Loss: 1.8911239206790924, Final Batch Loss: 0.39690375328063965\n",
      "Epoch 4777, Loss: 2.1008305102586746, Final Batch Loss: 0.6636013388633728\n",
      "Epoch 4778, Loss: 1.4874388799071312, Final Batch Loss: 0.0972832664847374\n",
      "Epoch 4779, Loss: 2.1419715583324432, Final Batch Loss: 0.5019378066062927\n",
      "Epoch 4780, Loss: 1.8189038634300232, Final Batch Loss: 0.4198613464832306\n",
      "Epoch 4781, Loss: 2.8523827493190765, Final Batch Loss: 1.1459925174713135\n",
      "Epoch 4782, Loss: 1.8758449256420135, Final Batch Loss: 0.4090500771999359\n",
      "Epoch 4783, Loss: 2.3397931158542633, Final Batch Loss: 0.6260377764701843\n",
      "Epoch 4784, Loss: 1.927019089460373, Final Batch Loss: 0.3495868146419525\n",
      "Epoch 4785, Loss: 1.58311428129673, Final Batch Loss: 0.2003040462732315\n",
      "Epoch 4786, Loss: 1.6787249892950058, Final Batch Loss: 0.21203063428401947\n",
      "Epoch 4787, Loss: 2.3157208263874054, Final Batch Loss: 0.6834554672241211\n",
      "Epoch 4788, Loss: 1.96795454621315, Final Batch Loss: 0.4453992545604706\n",
      "Epoch 4789, Loss: 1.9641742706298828, Final Batch Loss: 0.48374250531196594\n",
      "Epoch 4790, Loss: 2.3337511718273163, Final Batch Loss: 0.8812454342842102\n",
      "Epoch 4791, Loss: 1.6096394881606102, Final Batch Loss: 0.0942477211356163\n",
      "Epoch 4792, Loss: 2.1973240971565247, Final Batch Loss: 0.8117378354072571\n",
      "Epoch 4793, Loss: 1.6557896733283997, Final Batch Loss: 0.265279620885849\n",
      "Epoch 4794, Loss: 1.7389318645000458, Final Batch Loss: 0.13359597325325012\n",
      "Epoch 4795, Loss: 1.9046001434326172, Final Batch Loss: 0.5163442492485046\n",
      "Epoch 4796, Loss: 1.8288585543632507, Final Batch Loss: 0.4187990128993988\n",
      "Epoch 4797, Loss: 2.072687655687332, Final Batch Loss: 0.4683265686035156\n",
      "Epoch 4798, Loss: 1.8407430350780487, Final Batch Loss: 0.34282881021499634\n",
      "Epoch 4799, Loss: 1.636254295706749, Final Batch Loss: 0.2349604219198227\n",
      "Epoch 4800, Loss: 1.8975280821323395, Final Batch Loss: 0.4706248342990875\n",
      "Epoch 4801, Loss: 1.965693473815918, Final Batch Loss: 0.5038151144981384\n",
      "Epoch 4802, Loss: 1.651225209236145, Final Batch Loss: 0.27050191164016724\n",
      "Epoch 4803, Loss: 1.7371161580085754, Final Batch Loss: 0.39088836312294006\n",
      "Epoch 4804, Loss: 1.6481215357780457, Final Batch Loss: 0.3084133565425873\n",
      "Epoch 4805, Loss: 1.4364436119794846, Final Batch Loss: 0.06941719353199005\n",
      "Epoch 4806, Loss: 1.8974506258964539, Final Batch Loss: 0.45794957876205444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4807, Loss: 2.11261647939682, Final Batch Loss: 0.6430339217185974\n",
      "Epoch 4808, Loss: 1.7030923664569855, Final Batch Loss: 0.2754362225532532\n",
      "Epoch 4809, Loss: 2.1001484990119934, Final Batch Loss: 0.5059324502944946\n",
      "Epoch 4810, Loss: 1.6393858790397644, Final Batch Loss: 0.1940610110759735\n",
      "Epoch 4811, Loss: 1.703319013118744, Final Batch Loss: 0.1716073453426361\n",
      "Epoch 4812, Loss: 1.4582674875855446, Final Batch Loss: 0.1121538057923317\n",
      "Epoch 4813, Loss: 1.7599729895591736, Final Batch Loss: 0.3809710144996643\n",
      "Epoch 4814, Loss: 1.6066283583641052, Final Batch Loss: 0.13718730211257935\n",
      "Epoch 4815, Loss: 1.5563574135303497, Final Batch Loss: 0.24620437622070312\n",
      "Epoch 4816, Loss: 1.8052400350570679, Final Batch Loss: 0.4661789536476135\n",
      "Epoch 4817, Loss: 1.8655470311641693, Final Batch Loss: 0.4575268626213074\n",
      "Epoch 4818, Loss: 1.482132077217102, Final Batch Loss: 0.13142791390419006\n",
      "Epoch 4819, Loss: 1.98060941696167, Final Batch Loss: 0.44920921325683594\n",
      "Epoch 4820, Loss: 1.733331710100174, Final Batch Loss: 0.3045956492424011\n",
      "Epoch 4821, Loss: 2.0185305774211884, Final Batch Loss: 0.5169262886047363\n",
      "Epoch 4822, Loss: 2.007097840309143, Final Batch Loss: 0.5230495929718018\n",
      "Epoch 4823, Loss: 1.490987405180931, Final Batch Loss: 0.13110516965389252\n",
      "Epoch 4824, Loss: 1.6430559158325195, Final Batch Loss: 0.315024197101593\n",
      "Epoch 4825, Loss: 1.940445452928543, Final Batch Loss: 0.5270596742630005\n",
      "Epoch 4826, Loss: 1.7553863227367401, Final Batch Loss: 0.34257930517196655\n",
      "Epoch 4827, Loss: 2.0309583246707916, Final Batch Loss: 0.47616904973983765\n",
      "Epoch 4828, Loss: 1.8991898000240326, Final Batch Loss: 0.5304697751998901\n",
      "Epoch 4829, Loss: 2.224470466375351, Final Batch Loss: 0.7784743309020996\n",
      "Epoch 4830, Loss: 2.1068359911441803, Final Batch Loss: 0.8641176223754883\n",
      "Epoch 4831, Loss: 1.5827341824769974, Final Batch Loss: 0.24033822119235992\n",
      "Epoch 4832, Loss: 1.46468186378479, Final Batch Loss: 0.0355057418346405\n",
      "Epoch 4833, Loss: 1.5981573313474655, Final Batch Loss: 0.1866641789674759\n",
      "Epoch 4834, Loss: 1.7248382568359375, Final Batch Loss: 0.24482277035713196\n",
      "Epoch 4835, Loss: 1.8689028322696686, Final Batch Loss: 0.49518996477127075\n",
      "Epoch 4836, Loss: 1.8577491641044617, Final Batch Loss: 0.3417794704437256\n",
      "Epoch 4837, Loss: 1.5973448157310486, Final Batch Loss: 0.24550458788871765\n",
      "Epoch 4838, Loss: 1.600067138671875, Final Batch Loss: 0.24564865231513977\n",
      "Epoch 4839, Loss: 1.74941086769104, Final Batch Loss: 0.3944285809993744\n",
      "Epoch 4840, Loss: 1.7603129595518112, Final Batch Loss: 0.1784394532442093\n",
      "Epoch 4841, Loss: 2.6163547337055206, Final Batch Loss: 1.182888388633728\n",
      "Epoch 4842, Loss: 1.6750708520412445, Final Batch Loss: 0.2907960116863251\n",
      "Epoch 4843, Loss: 1.7204069793224335, Final Batch Loss: 0.29501911997795105\n",
      "Epoch 4844, Loss: 2.184328079223633, Final Batch Loss: 0.5816035270690918\n",
      "Epoch 4845, Loss: 1.5167879164218903, Final Batch Loss: 0.18723025918006897\n",
      "Epoch 4846, Loss: 1.8778956830501556, Final Batch Loss: 0.628041684627533\n",
      "Epoch 4847, Loss: 2.111842632293701, Final Batch Loss: 0.6650426983833313\n",
      "Epoch 4848, Loss: 1.968960553407669, Final Batch Loss: 0.5106281042098999\n",
      "Epoch 4849, Loss: 1.6336569339036942, Final Batch Loss: 0.12888740003108978\n",
      "Epoch 4850, Loss: 2.6923807561397552, Final Batch Loss: 1.2679115533828735\n",
      "Epoch 4851, Loss: 1.6365388929843903, Final Batch Loss: 0.25188302993774414\n",
      "Epoch 4852, Loss: 1.5360575765371323, Final Batch Loss: 0.0989709347486496\n",
      "Epoch 4853, Loss: 1.709436058998108, Final Batch Loss: 0.23432180285453796\n",
      "Epoch 4854, Loss: 1.68694868683815, Final Batch Loss: 0.36630669236183167\n",
      "Epoch 4855, Loss: 1.9554505050182343, Final Batch Loss: 0.5316339731216431\n",
      "Epoch 4856, Loss: 1.6699464321136475, Final Batch Loss: 0.26791873574256897\n",
      "Epoch 4857, Loss: 1.9814865589141846, Final Batch Loss: 0.5914279222488403\n",
      "Epoch 4858, Loss: 2.606504052877426, Final Batch Loss: 1.1930618286132812\n",
      "Epoch 4859, Loss: 2.049148976802826, Final Batch Loss: 0.621303915977478\n",
      "Epoch 4860, Loss: 1.8271399438381195, Final Batch Loss: 0.34084343910217285\n",
      "Epoch 4861, Loss: 1.8996649086475372, Final Batch Loss: 0.46828702092170715\n",
      "Epoch 4862, Loss: 1.473266750574112, Final Batch Loss: 0.17110204696655273\n",
      "Epoch 4863, Loss: 1.6115799993276596, Final Batch Loss: 0.23945678770542145\n",
      "Epoch 4864, Loss: 1.959527462720871, Final Batch Loss: 0.6478424072265625\n",
      "Epoch 4865, Loss: 1.5358474552631378, Final Batch Loss: 0.15014442801475525\n",
      "Epoch 4866, Loss: 1.6262075677514076, Final Batch Loss: 0.11757568269968033\n",
      "Epoch 4867, Loss: 2.307567775249481, Final Batch Loss: 0.8830070495605469\n",
      "Epoch 4868, Loss: 1.810549795627594, Final Batch Loss: 0.49584975838661194\n",
      "Epoch 4869, Loss: 1.6598761081695557, Final Batch Loss: 0.2691093981266022\n",
      "Epoch 4870, Loss: 1.6985100358724594, Final Batch Loss: 0.31925252079963684\n",
      "Epoch 4871, Loss: 1.9545940160751343, Final Batch Loss: 0.5636648535728455\n",
      "Epoch 4872, Loss: 1.6686150431632996, Final Batch Loss: 0.14909657835960388\n",
      "Epoch 4873, Loss: 1.5821583718061447, Final Batch Loss: 0.24105693399906158\n",
      "Epoch 4874, Loss: 1.5764839947223663, Final Batch Loss: 0.24120783805847168\n",
      "Epoch 4875, Loss: 1.8238210380077362, Final Batch Loss: 0.33235424757003784\n",
      "Epoch 4876, Loss: 1.5212902575731277, Final Batch Loss: 0.1524578481912613\n",
      "Epoch 4877, Loss: 1.6136762648820877, Final Batch Loss: 0.18971525132656097\n",
      "Epoch 4878, Loss: 1.6164011359214783, Final Batch Loss: 0.25128233432769775\n",
      "Epoch 4879, Loss: 1.7863142490386963, Final Batch Loss: 0.3934473395347595\n",
      "Epoch 4880, Loss: 1.693024605512619, Final Batch Loss: 0.2815976142883301\n",
      "Epoch 4881, Loss: 1.5530554205179214, Final Batch Loss: 0.08832110464572906\n",
      "Epoch 4882, Loss: 1.8352979719638824, Final Batch Loss: 0.4338039755821228\n",
      "Epoch 4883, Loss: 2.026690900325775, Final Batch Loss: 0.6142075657844543\n",
      "Epoch 4884, Loss: 1.7856066823005676, Final Batch Loss: 0.3513909876346588\n",
      "Epoch 4885, Loss: 1.8417111784219742, Final Batch Loss: 0.21351681649684906\n",
      "Epoch 4886, Loss: 1.6369931101799011, Final Batch Loss: 0.21743997931480408\n",
      "Epoch 4887, Loss: 1.4863212406635284, Final Batch Loss: 0.1881425380706787\n",
      "Epoch 4888, Loss: 1.9552626609802246, Final Batch Loss: 0.5722546577453613\n",
      "Epoch 4889, Loss: 1.766810953617096, Final Batch Loss: 0.42123493552207947\n",
      "Epoch 4890, Loss: 1.6454662084579468, Final Batch Loss: 0.2989770770072937\n",
      "Epoch 4891, Loss: 1.8514056503772736, Final Batch Loss: 0.4032652676105499\n",
      "Epoch 4892, Loss: 1.65341517329216, Final Batch Loss: 0.17797228693962097\n",
      "Epoch 4893, Loss: 1.6745821386575699, Final Batch Loss: 0.2369302362203598\n",
      "Epoch 4894, Loss: 1.8491011261940002, Final Batch Loss: 0.43962690234184265\n",
      "Epoch 4895, Loss: 1.3944520056247711, Final Batch Loss: 0.043147385120391846\n",
      "Epoch 4896, Loss: 2.324616491794586, Final Batch Loss: 0.787874162197113\n",
      "Epoch 4897, Loss: 1.5314452201128006, Final Batch Loss: 0.1754315048456192\n",
      "Epoch 4898, Loss: 1.8043684363365173, Final Batch Loss: 0.29242444038391113\n",
      "Epoch 4899, Loss: 1.9472342729568481, Final Batch Loss: 0.6551852226257324\n",
      "Epoch 4900, Loss: 1.6087991893291473, Final Batch Loss: 0.29351016879081726\n",
      "Epoch 4901, Loss: 1.7131063044071198, Final Batch Loss: 0.5142151713371277\n",
      "Epoch 4902, Loss: 1.7238214015960693, Final Batch Loss: 0.3854890763759613\n",
      "Epoch 4903, Loss: 2.4601346254348755, Final Batch Loss: 1.1233898401260376\n",
      "Epoch 4904, Loss: 2.0053675770759583, Final Batch Loss: 0.46113547682762146\n",
      "Epoch 4905, Loss: 2.2542568743228912, Final Batch Loss: 0.6603088974952698\n",
      "Epoch 4906, Loss: 2.5050316751003265, Final Batch Loss: 0.49057844281196594\n",
      "Epoch 4907, Loss: 2.2609797418117523, Final Batch Loss: 0.13222137093544006\n",
      "Epoch 4908, Loss: 2.4824605584144592, Final Batch Loss: 0.7034584879875183\n",
      "Epoch 4909, Loss: 2.229195773601532, Final Batch Loss: 0.3739096224308014\n",
      "Epoch 4910, Loss: 1.9973738193511963, Final Batch Loss: 0.2682020664215088\n",
      "Epoch 4911, Loss: 1.8295470252633095, Final Batch Loss: 0.08985183387994766\n",
      "Epoch 4912, Loss: 1.7833530455827713, Final Batch Loss: 0.21997155249118805\n",
      "Epoch 4913, Loss: 1.9281567633152008, Final Batch Loss: 0.38080570101737976\n",
      "Epoch 4914, Loss: 1.9173696041107178, Final Batch Loss: 0.2402813732624054\n",
      "Epoch 4915, Loss: 1.7380440831184387, Final Batch Loss: 0.2883423864841461\n",
      "Epoch 4916, Loss: 1.962913602590561, Final Batch Loss: 0.4414026141166687\n",
      "Epoch 4917, Loss: 1.7889186590909958, Final Batch Loss: 0.16013939678668976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4918, Loss: 1.7505069971084595, Final Batch Loss: 0.17431792616844177\n",
      "Epoch 4919, Loss: 2.0588420927524567, Final Batch Loss: 0.3438379764556885\n",
      "Epoch 4920, Loss: 1.69358628988266, Final Batch Loss: 0.22455760836601257\n",
      "Epoch 4921, Loss: 1.8026470243930817, Final Batch Loss: 0.2475675344467163\n",
      "Epoch 4922, Loss: 1.8173997104167938, Final Batch Loss: 0.4056539833545685\n",
      "Epoch 4923, Loss: 1.669244796037674, Final Batch Loss: 0.28702136874198914\n",
      "Epoch 4924, Loss: 1.6758885979652405, Final Batch Loss: 0.1391657292842865\n",
      "Epoch 4925, Loss: 1.7696520686149597, Final Batch Loss: 0.282569944858551\n",
      "Epoch 4926, Loss: 2.0541206002235413, Final Batch Loss: 0.5523090362548828\n",
      "Epoch 4927, Loss: 1.8664812743663788, Final Batch Loss: 0.4691837728023529\n",
      "Epoch 4928, Loss: 1.6348651573061943, Final Batch Loss: 0.10844989866018295\n",
      "Epoch 4929, Loss: 2.072468101978302, Final Batch Loss: 0.5401673913002014\n",
      "Epoch 4930, Loss: 1.7149723768234253, Final Batch Loss: 0.25608885288238525\n",
      "Epoch 4931, Loss: 1.7485096752643585, Final Batch Loss: 0.3260800540447235\n",
      "Epoch 4932, Loss: 2.0386072397232056, Final Batch Loss: 0.5861986875534058\n",
      "Epoch 4933, Loss: 2.7875522673130035, Final Batch Loss: 1.1739838123321533\n",
      "Epoch 4934, Loss: 1.7126787900924683, Final Batch Loss: 0.33911919593811035\n",
      "Epoch 4935, Loss: 1.4955556988716125, Final Batch Loss: 0.10001558065414429\n",
      "Epoch 4936, Loss: 2.1051850616931915, Final Batch Loss: 0.6084938049316406\n",
      "Epoch 4937, Loss: 2.7884978353977203, Final Batch Loss: 1.2417091131210327\n",
      "Epoch 4938, Loss: 1.6766409948468208, Final Batch Loss: 0.10587090998888016\n",
      "Epoch 4939, Loss: 1.871088057756424, Final Batch Loss: 0.23205316066741943\n",
      "Epoch 4940, Loss: 2.020148277282715, Final Batch Loss: 0.4129655659198761\n",
      "Epoch 4941, Loss: 2.1248687505722046, Final Batch Loss: 0.48724564909935\n",
      "Epoch 4942, Loss: 1.7331118136644363, Final Batch Loss: 0.20269693434238434\n",
      "Epoch 4943, Loss: 1.653627634048462, Final Batch Loss: 0.26496607065200806\n",
      "Epoch 4944, Loss: 2.1214267909526825, Final Batch Loss: 0.528103768825531\n",
      "Epoch 4945, Loss: 2.104243576526642, Final Batch Loss: 0.6242061853408813\n",
      "Epoch 4946, Loss: 1.6264664083719254, Final Batch Loss: 0.17905591428279877\n",
      "Epoch 4947, Loss: 1.8658390641212463, Final Batch Loss: 0.5201882123947144\n",
      "Epoch 4948, Loss: 1.8900576531887054, Final Batch Loss: 0.298873633146286\n",
      "Epoch 4949, Loss: 1.913807988166809, Final Batch Loss: 0.34163445234298706\n",
      "Epoch 4950, Loss: 2.503758192062378, Final Batch Loss: 1.0392547845840454\n",
      "Epoch 4951, Loss: 1.554756537079811, Final Batch Loss: 0.13825322687625885\n",
      "Epoch 4952, Loss: 2.1028183102607727, Final Batch Loss: 0.5122002959251404\n",
      "Epoch 4953, Loss: 2.0132473409175873, Final Batch Loss: 0.4190502166748047\n",
      "Epoch 4954, Loss: 1.6748103350400925, Final Batch Loss: 0.23724786937236786\n",
      "Epoch 4955, Loss: 1.6883059740066528, Final Batch Loss: 0.2642713487148285\n",
      "Epoch 4956, Loss: 1.5119656324386597, Final Batch Loss: 0.16737040877342224\n",
      "Epoch 4957, Loss: 1.711694359779358, Final Batch Loss: 0.2749820649623871\n",
      "Epoch 4958, Loss: 1.5772539973258972, Final Batch Loss: 0.29408469796180725\n",
      "Epoch 4959, Loss: 1.8754781186580658, Final Batch Loss: 0.461166650056839\n",
      "Epoch 4960, Loss: 1.6320831328630447, Final Batch Loss: 0.20132292807102203\n",
      "Epoch 4961, Loss: 1.5791110321879387, Final Batch Loss: 0.10765432566404343\n",
      "Epoch 4962, Loss: 2.355303019285202, Final Batch Loss: 1.0620810985565186\n",
      "Epoch 4963, Loss: 1.910380244255066, Final Batch Loss: 0.3860662281513214\n",
      "Epoch 4964, Loss: 2.0905778110027313, Final Batch Loss: 0.549435555934906\n",
      "Epoch 4965, Loss: 1.5299725532531738, Final Batch Loss: 0.10442245006561279\n",
      "Epoch 4966, Loss: 2.02677258849144, Final Batch Loss: 0.5760245323181152\n",
      "Epoch 4967, Loss: 1.8542284667491913, Final Batch Loss: 0.3172408640384674\n",
      "Epoch 4968, Loss: 1.6801557093858719, Final Batch Loss: 0.16567884385585785\n",
      "Epoch 4969, Loss: 2.24892595410347, Final Batch Loss: 0.5987685322761536\n",
      "Epoch 4970, Loss: 2.236986607313156, Final Batch Loss: 0.7494087219238281\n",
      "Epoch 4971, Loss: 1.9827417135238647, Final Batch Loss: 0.36798539757728577\n",
      "Epoch 4972, Loss: 1.9930429458618164, Final Batch Loss: 0.3841884434223175\n",
      "Epoch 4973, Loss: 1.8768017888069153, Final Batch Loss: 0.2938312590122223\n",
      "Epoch 4974, Loss: 1.7127147614955902, Final Batch Loss: 0.2980816960334778\n",
      "Epoch 4975, Loss: 1.8738901913166046, Final Batch Loss: 0.36464181542396545\n",
      "Epoch 4976, Loss: 1.8448961079120636, Final Batch Loss: 0.37847307324409485\n",
      "Epoch 4977, Loss: 1.8930683732032776, Final Batch Loss: 0.3341194689273834\n",
      "Epoch 4978, Loss: 1.5671115666627884, Final Batch Loss: 0.21903444826602936\n",
      "Epoch 4979, Loss: 1.7840677201747894, Final Batch Loss: 0.3313344419002533\n",
      "Epoch 4980, Loss: 1.5715926736593246, Final Batch Loss: 0.13814012706279755\n",
      "Epoch 4981, Loss: 1.946522831916809, Final Batch Loss: 0.4828298091888428\n",
      "Epoch 4982, Loss: 2.0984979569911957, Final Batch Loss: 0.24406063556671143\n",
      "Epoch 4983, Loss: 1.731810212135315, Final Batch Loss: 0.25674858689308167\n",
      "Epoch 4984, Loss: 1.9903582036495209, Final Batch Loss: 0.5595775246620178\n",
      "Epoch 4985, Loss: 1.638490468263626, Final Batch Loss: 0.2710525393486023\n",
      "Epoch 4986, Loss: 1.7057383954524994, Final Batch Loss: 0.3260086178779602\n",
      "Epoch 4987, Loss: 1.8773615658283234, Final Batch Loss: 0.4236563742160797\n",
      "Epoch 4988, Loss: 1.594939649105072, Final Batch Loss: 0.20186886191368103\n",
      "Epoch 4989, Loss: 1.7610017359256744, Final Batch Loss: 0.40196946263313293\n",
      "Epoch 4990, Loss: 1.5396984964609146, Final Batch Loss: 0.14332373440265656\n",
      "Epoch 4991, Loss: 1.8006738126277924, Final Batch Loss: 0.44489529728889465\n",
      "Epoch 4992, Loss: 1.4531525000929832, Final Batch Loss: 0.10378112643957138\n",
      "Epoch 4993, Loss: 1.3994553741067648, Final Batch Loss: 0.03012857399880886\n",
      "Epoch 4994, Loss: 1.7584596574306488, Final Batch Loss: 0.46334147453308105\n",
      "Epoch 4995, Loss: 1.7502461373806, Final Batch Loss: 0.36911505460739136\n",
      "Epoch 4996, Loss: 1.7043744921684265, Final Batch Loss: 0.37746891379356384\n",
      "Epoch 4997, Loss: 1.7439756989479065, Final Batch Loss: 0.32716336846351624\n",
      "Epoch 4998, Loss: 1.7246961146593094, Final Batch Loss: 0.2220197468996048\n",
      "Epoch 4999, Loss: 1.9707826375961304, Final Batch Loss: 0.5709753632545471\n",
      "Epoch 5000, Loss: 1.6694922596216202, Final Batch Loss: 0.24988065659999847\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  0  0  0  4  0  0  0]\n",
      " [ 0 29  1  0  0  0  0  0]\n",
      " [ 0  0 25  3  0  0  0  0]\n",
      " [ 0  0  0 27  0  0  0  0]\n",
      " [ 1  3  2  0 15  4  0  0]\n",
      " [ 0  0  0  0  0 35  0  0]\n",
      " [ 0  2  0  2  0  0 26  0]\n",
      " [ 0  2  0  1  0  0  0 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96875   0.88571   0.92537        35\n",
      "           1    0.80556   0.96667   0.87879        30\n",
      "           2    0.89286   0.89286   0.89286        28\n",
      "           3    0.81818   1.00000   0.90000        27\n",
      "           4    0.78947   0.60000   0.68182        25\n",
      "           5    0.89744   1.00000   0.94595        35\n",
      "           6    1.00000   0.86667   0.92857        30\n",
      "           7    1.00000   0.93182   0.96471        44\n",
      "\n",
      "    accuracy                        0.90157       254\n",
      "   macro avg    0.89653   0.89297   0.88976       254\n",
      "weighted avg    0.90674   0.90157   0.89964       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0  0  0  0  0  0]\n",
      " [ 0 32  0  0  0  0  0  3]\n",
      " [ 0  6 34  2  0  0  0  0]\n",
      " [ 0  0  0 26  0  0  0  0]\n",
      " [ 0  0  0  0 22  0  0 17]\n",
      " [ 0  0  0  0  0 33  0  0]\n",
      " [ 0  0  0  0  0  0 30  0]\n",
      " [ 0  0  0  0  0  0  0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        25\n",
      "           1    0.84211   0.91429   0.87671        35\n",
      "           2    1.00000   0.80952   0.89474        42\n",
      "           3    0.92857   1.00000   0.96296        26\n",
      "           4    1.00000   0.56410   0.72131        39\n",
      "           5    1.00000   1.00000   1.00000        33\n",
      "           6    1.00000   1.00000   1.00000        30\n",
      "           7    0.54545   1.00000   0.70588        24\n",
      "\n",
      "    accuracy                        0.88976       254\n",
      "   macro avg    0.91452   0.91099   0.89520       254\n",
      "weighted avg    0.92798   0.88976   0.89123       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
